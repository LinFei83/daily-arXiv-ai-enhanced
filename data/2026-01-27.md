<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 69]
- [cs.CV](#cs.CV) [Total: 161]
- [cs.CL](#cs.CL) [Total: 111]
- [cs.RO](#cs.RO) [Total: 32]
- [eess.SY](#eess.SY) [Total: 21]
- [eess.IV](#eess.IV) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Online parameter estimation for the Crazyflie quadcopter through an EM algorithm](https://arxiv.org/abs/2601.17009)
*Yanhua Zhao*

Main category: cs.AI

TL;DR: 该研究探讨了随机噪声对四旋翼无人机系统的影响，并使用扩展卡尔曼滤波器进行状态估计，利用线性二次高斯控制器进行控制，并通过期望最大化算法进行参数估计，比较了在线和离线参数估计的收敛性。


<details>
  <summary>Details</summary>
Motivation: 无人机因其在灾难救援、摄影、农业和运输等领域的广泛应用而日益普及。然而，无人机系统容易受到随机噪声的影响，这会影响其性能。本研究旨在理解和解决这些影响。

Method: 研究人员在四旋翼无人机系统模型中引入随机噪声。他们使用了扩展卡尔曼滤波器（EKF）来处理带有噪声的传感器观测值并估计系统状态。此外，他们还设计了一个基于随机微分方程（SDE）系统的线性二次高斯（LQG）控制器。参数估计采用了期望最大化（EM）算法，并比较了离线和在线两种参数估计方法。

Result: 研究结果表明，在线参数估计方法相比离线方法具有略微更宽的收敛范围。这表明在线估计在参数调整方面可能更具鲁棒性。

Conclusion: 本研究成功地分析了随机噪声对四旋翼无人机系统的影响，并有效地应用了扩展卡尔曼滤波器、LQG控制器和期望最大化算法。研究发现，在线参数估计在一定程度上优于离线估计，这为设计更鲁棒的无人机控制系统提供了参考。

Abstract: Drones are becoming more and more popular nowadays. They are small in size, low in cost, and reliable in operation. They contain a variety of sensors and can perform a variety of flight tasks, reaching places that are difficult or inaccessible for humans. Earthquakes damage a lot of infrastructure, making it impossible for rescuers to reach some areas. But drones can help. Many amateur and professional photographers like to use drones for aerial photography. Drones play a non-negligible role in agriculture and transportation too. Drones can be used to spray pesticides, and they can also transport supplies. A quadcopter is a four-rotor drone and has been studied in this paper. In this paper, random noise is added to the quadcopter system and its effects on the drone system are studied. An extended Kalman filter has been used to estimate the state based on noisy observations from the sensor. Based on a SDE system, a linear quadratic Gaussian controller has been implemented. The expectation maximization algorithm has been applied for parameter estimation of the quadcopter. The results of offline parameter estimation and online parameter estimation are presented. The results show that the online parameter estimation has a slightly larger range of convergence values than the offline parameter estimation.

</details>


### [2] [Interpreting Agentic Systems: Beyond Model Explanations to System-Level Accountability](https://arxiv.org/abs/2601.17168)
*Judy Zhu,Dhari Gandhi,Himanshu Joshi,Ahmad Rezaie Mianroodi,Sedef Akinli Kocak,Dhanesh Ramachandran*

Main category: cs.AI

TL;DR: 本文探讨了在大型语言模型（LLMs）驱动的自主代理系统（agentic systems）中嵌入可解释性的必要性、现有方法的局限性以及未来研究方向，以解决其独特的AI安全挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习模型解释性技术在应用于具有时间动态、复合决策和环境交互的代理系统时存在局限性，而这些系统带来了诸如目标不一致、决策累积错误和协调风险等新的AI安全挑战。

Method: 本文评估了现有解释性方法在代理系统中的适用性和局限性，识别了当前技术在提供有意义的代理决策见解方面的不足，并提出了专门为代理系统设计解释性技术的研究方向。

Result: 现有解释性技术难以充分捕捉代理系统的时序动态、复合决策和上下文依赖行为，无法提供深入的代理决策洞察。

Conclusion: 为了确保代理AI系统的安全和可问责部署，必须开发专门针对代理系统生命周期（从目标形成、环境交互到结果评估）的解释性技术，并嵌入监督机制。

Abstract: Agentic systems have transformed how Large Language Models (LLMs) can be leveraged to create autonomous systems with goal-directed behaviors, consisting of multi-step planning and the ability to interact with different environments. These systems differ fundamentally from traditional machine learning models, both in architecture and deployment, introducing unique AI safety challenges, including goal misalignment, compounding decision errors, and coordination risks among interacting agents, that necessitate embedding interpretability and explainability by design to ensure traceability and accountability across their autonomous behaviors. Current interpretability techniques, developed primarily for static models, show limitations when applied to agentic systems. The temporal dynamics, compounding decisions, and context-dependent behaviors of agentic systems demand new analytical approaches. This paper assesses the suitability and limitations of existing interpretability methods in the context of agentic systems, identifying gaps in their capacity to provide meaningful insight into agent decision-making. We propose future directions for developing interpretability techniques specifically designed for agentic systems, pinpointing where interpretability is required to embed oversight mechanisms across the agent lifecycle from goal formation, through environmental interaction, to outcome evaluation. These advances are essential to ensure the safe and accountable deployment of agentic AI systems.

</details>


### [3] [Implementing Tensor Logic: Unifying Datalog and Neural Reasoning via Tensor Contraction](https://arxiv.org/abs/2601.17188)
*Swapn Shah,Wlodek Zadrozny*

Main category: cs.AI

TL;DR: 本研究通过三个实验验证了 Tensor Logic 框架，该框架将逻辑规则与张量运算统一起来，旨在解决符号推理和神经网络的融合问题。研究表明，Tensor Logic 可以实现递归 Datalog 规则的迭代张量收缩、嵌入空间中的推理以及在大规模知识图谱上的链接预测和组合推理。


<details>
  <summary>Details</summary>
Motivation: 人工智能的核心挑战在于如何统一符号推理（可靠、可解释但扩展性差）和神经网络（可学习但透明度低）的优点。Tensor Logic 框架提出逻辑规则与爱因斯坦求和在数学上是等价的，为实现这种统一提供了一个原则性的方法。

Method: 本文通过三个实验进行实证验证。1. 证明了递归 Datalog 规则与迭代张量收缩之间的等价性，通过计算一个圣经家谱图的传递闭包来演示。2. 在嵌入空间中实现了推理，训练了一个具有可学习变换矩阵的神经网络，并在零样本组合推理任务上进行了演示。3. 在 FB15k-237 知识图谱上验证了 Tensor Logic 的叠加构造，并使用关系矩阵公式进行链接预测和组合推理。

Result: 1. 在家谱图实验中，通过74次迭代成功计算了33,945个祖先关系。2. 在组合推理任务中，实现了零样本推理。3. 在 FB15k-237 知识图谱上，标准链接预测的 MRR 为 0.3068，组合推理基准测试的 MRR 为 0.3346，证明了矩阵组合可以实现多跳推理。

Conclusion: Tensor Logic 框架在逻辑推理和神经网络的融合方面取得了初步的实证成功，证明了其在递归推理、嵌入空间推理以及大规模知识图谱上的组合推理能力，为解决人工智能的统一性挑战提供了有希望的途径。

Abstract: The unification of symbolic reasoning and neural networks remains a central challenge in artificial intelligence. Symbolic systems offer reliability and interpretability but lack scalability, while neural networks provide learning capabilities but sacrifice transparency. Tensor Logic, proposed by Domingos, suggests that logical rules and Einstein summation are mathematically equivalent, offering a principled path toward unification. This paper provides empirical validation of this framework through three experiments. First, we demonstrate the equivalence between recursive Datalog rules and iterative tensor contractions by computing the transitive closure of a biblical genealogy graph containing 1,972 individuals and 1,727 parent-child relationships, converging in 74 iterations to discover 33,945 ancestor relationships. Second, we implement reasoning in embedding space by training a neural network with learnable transformation matrices, demonstrating successful zero-shot compositional inference on held-out queries. Third, we validate the Tensor Logic superposition construction on FB15k-237, a large-scale knowledge graph with 14,541 entities and 237 relations. Using Domingos's relation matrix formulation $R_r = E^\top A_r E$, we achieve MRR of 0.3068 on standard link prediction and MRR of 0.3346 on a compositional reasoning benchmark where direct edges are removed during training, demonstrating that matrix composition enables multi-hop inference without direct training examples.

</details>


### [4] [High-Fidelity Longitudinal Patient Simulation Using Real-World Data](https://arxiv.org/abs/2601.17310)
*Yu Akagi,Tomohisa Seki,Hiromasa Ito,Toru Takiguchi,Kazuhiko Ohe,Yoshimasa Kawazoe*

Main category: cs.AI

TL;DR: 本研究提出了一种利用电子健康记录（EHR）数据构建的生成模拟器，能够合成逼真的患者未来轨迹，并准确预测未来事件的发生概率。


<details>
  <summary>Details</summary>
Motivation: 在临床医学中，模拟可以用于个性化治疗和虚拟临床试验，但由于生物和社会文化因素的复杂性，模拟患者轨迹具有挑战性。研究旨在利用真实世界的临床记录来经验性地模拟患者的时间线。

Method: 开发了一个生成模拟器模型，该模型以患者病史为输入，生成细粒度、逼真的未来轨迹。模型在超过2亿条临床记录上进行了预训练。

Result: 该模型生成了高保真度的未来时间线，与真实患者未来数据的事件发生率、实验室检查结果和时间动态密切匹配。同时，它也能准确估计未来事件的概率，在多种结果和时间范围内，观测/预期比率均接近1.0。

Conclusion: 真实世界的EHR数据具有未被发掘的价值，本研究介绍了一个用于临床护理的体内建模的可扩展框架。

Abstract: Simulation is a powerful tool for exploring uncertainty. Its potential in clinical medicine is transformative and includes personalized treatment planning and virtual clinical trials. However, simulating patient trajectories is challenging because of complex biological and sociocultural influences. Here, we show that real-world clinical records can be leveraged to empirically model patient timelines. We developed a generative simulator model that takes a patient's history as input and synthesizes fine-grained, realistic future trajectories. The model was pretrained on more than 200 million clinical records. It produced high-fidelity future timelines, closely matching event occurrence rates, laboratory test results, and temporal dynamics in real patient future data. It also accurately estimated future event probabilities, with observed-to-expected ratios consistently near 1.0 across diverse outcomes and time horizons. Our results reveal the untapped value of real-world data in electronic health records and introduce a scalable framework for in silico modeling of clinical care.

</details>


### [5] [Phase Transition for Budgeted Multi-Agent Synergy](https://arxiv.org/abs/2601.17311)
*Bang Liu,Linglong Kong,Jian Pei*

Main category: cs.AI

TL;DR: 本文提出了一种理论框架，用于预测多智能体系统在有限计算预算下的性能表现，包括增益、饱和甚至崩溃的模式。该理论考虑了有限上下文窗口、有损通信和共享故障等约束，并证明了通过特定参数组合可以实现信号放大，从而超越单个智能体的性能。研究还提出了组织指数和计算分配规则，并验证了理论在模拟和大型语言模型（LLM）系统中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体系统研究在固定推理预算下，其性能表现往往不稳定，可能出现增益、饱和甚至崩溃。研究旨在发展一个能够预测这些性能模式的理论，并找出提升多智能体系统在有限资源下的性能的方法。

Method: 文章通过构建一个最小化且可校准的理论模型，用三个关键约束（有限上下文窗口$W$、有损通信$γ(m)$、共享故障$ρ$）来描述智能体堆栈。对于二元成功/失败任务，采用多数聚合，并证明了在深度$b$元树结构下，一个标量参数$α_ρ$（结合了$γ(m)$、$ρ$和扇入$b$）决定了信号是增强还是被冲淡。此外，还推导了组织指数$s$来量化协同效应，并提出了计算分配规则和预算阈值。

Result: 研究证明了在特定条件下（$s>β$），多智能体系统能够实现“预算协同”，即在相同总预算下性能优于最佳的单个智能体。提出了组织指数$s$来量化协同效应，并给出了实现预算协同的封闭形式计算分配规则和预算阈值。此外，文章还通过混合深度来表征饱和现象，并提出了一种稳健的预测器。

Conclusion: 本文提出的理论框架能够准确预测多智能体系统在不同约束条件下的性能表现，并为在有限预算下实现最优性能提供了指导。该理论对于理解和设计高效的多智能体系统，特别是大型语言模型（LLM）智能体系统具有重要意义。

Abstract: Multi-agent systems can improve reliability, yet under a fixed inference budget they often help, saturate, or even collapse. We develop a minimal and calibratable theory that predicts these regimes from three binding constraints of modern agent stacks: finite context windows, lossy inter-agent communication, and shared failures among similar agents. Each leaf agent is summarized by a compute-performance scaling exponent $β$; communication is captured by a message-length fidelity curve $γ(m)$; dependence is captured by an effective shared-error correlation $ρ$; and a context window $W$ imposes hard fan-in limits that make hierarchy necessary. For binary success/failure tasks with majority aggregation, we prove a sharp phase transition for deep $b$-ary trees with correlated inputs and lossy communication: a single scalar $α_ρ$ (combining $γ(m)$, $ρ$, and fan-in $b$) determines whether weak signal is amplified to a nontrivial fixed point or washed out to chance. In the amplifying regime, we derive an organization exponent $s$ and show that budgeted synergy, i.e., outperforming the best single agent under the same total budget, occurs exactly when $s>β$, yielding closed-form compute allocation rules and explicit budget thresholds. We further characterize saturation via a mixing depth and provide a conservative clipped predictor that remains accurate across growth and saturation. A continuous-performance warm-up gives closed-form risks for star, chain, and tree organizations, making correlation- and communication-induced floors explicit and exposing the core design trade-offs in a smooth setting. Finally, we validate the predicted phase boundaries in controlled synthetic simulations and show how the same mechanisms explain the dominant bottlenecks reported in recent large-scale matched-budget studies of LLM agent-system scaling.

</details>


### [6] [TheoremForge: Scaling up Formal Data Synthesis with Low-Budget Agentic Workflow](https://arxiv.org/abs/2601.17332)
*Yicheng Tao,Hongteng Xu*

Main category: cs.AI

TL;DR: TheoremForge是一个成本效益高的形式化数据合成流水线，通过将形式化过程分解为五个子任务并采用解耦提取策略，提高了数据产量并降低了成本，在2000个问题基准测试中验证率达到12.6%，平均每次成功轨迹成本仅为0.481美元。


<details>
  <summary>Details</summary>
Motivation: 现有形式化数学的代理工作流成本高昂，阻碍了大规模数据合成和开放源码语料库的稀缺性。

Method: TheoremForge将形式化过程分解为五个子任务：陈述形式化、证明生成、前提选择、证明修正和证明草图。采用解耦提取策略，从全局失败的轨迹中恢复有效的训练信号。

Result: 在2000个问题基准测试中，TheoremForge实现了12.6%的验证率，高于8.6%的基线。使用Gemini-3-Flash，平均每次成功轨迹的成本仅为0.481美元。与标准过滤相比，证明生成的数据产量提高了1.6倍。

Conclusion: TheoremForge是一个可扩展的框架，能够构建数据飞轮以训练未来的专家模型，解决了形式化数学数据稀缺和成本高昂的问题。

Abstract: The high cost of agentic workflows in formal mathematics hinders large-scale data synthesis, exacerbating the scarcity of open-source corpora. To address this, we introduce \textbf{TheoremForge}, a cost-effective formal data synthesis pipeline that decomposes the formalization process into five sub-tasks, which are \textit{statement formalization}, \textit{proof generation}, \textit{premise selection}, \textit{proof correction} and \textit{proof sketching}. By implementing a \textit{Decoupled Extraction Strategy}, the workflow recovers valid training signals from globally failed trajectories, effectively utilizing wasted computation. Experiments on a 2,000-problem benchmark demonstrate that TheoremForge achieves a Verified Rate of 12.6\%, surpassing the 8.6\% baseline, at an average cost of only \textbf{\$0.481} per successful trajectory using Gemini-3-Flash. Crucially, our strategy increases data yield by \textbf{1.6$\times$} for proof generation compared to standard filtering. These results establish TheoremForge as a scalable framework for constructing a data flywheel to train future expert models. Our code is available \href{https://github.com/timechess/TheoremForge}{here}.

</details>


### [7] [The Relativity of AGI: Distributional Axioms, Fragility, and Undecidability](https://arxiv.org/abs/2601.17335)
*Angshul Majumdar*

Main category: cs.AI

TL;DR: 该论文通过公理化方法研究了通用人工智能（AGI）的理论定义。研究表明，AGI 的定义与其所处的任务分布、资源限制等因素密切相关，无法脱离这些背景独立存在。此外，AGI 的可验证性受到限制，不存在能够完全准确地认证 AGI 的计算方法，特别是依赖于自我认证的递归式自我改进方案是不可行的。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于探讨通用人工智能（AGI）是否存在一个清晰、绝对的理论定义，能够支持其存在、鲁棒性或自我验证的论断。作者希望为 AGI 的研究提供更严谨的理论基础，并澄清关于 AGI 可实现性和可验证性的常见误解。

Method: 论文采用公理化方法，将 AGI 定义为一个分布式的、资源受限的语义谓词，并引入任务家族、任务分布、性能函数和资源预算作为索引。在此框架下，研究推导了四类结果：1. 证明了通用性是固有的关系性的；2. 证明了任务分布的微小扰动可能导致 AGI 属性失效（悬崖集）；3. 建立了有限资源下的有界迁移保证，排除了跨任务家族的无界泛化；4. 利用 Rice-style 和 Gödel-Tarski 论证，证明了 AGI 是一个非平凡的语义属性，无法被任何可计算过程（包括智能体自身）完整且正确地认证。

Result: 研究的主要结果包括：1. 通用性具有内在的依赖性，不存在独立于任务分布的 AGI 定义；2. 任务分布的细微变化可能导致 AGI 属性的突然失效，表明 AGI 不具备普遍鲁棒性；3. 在有限资源下，跨任务家族的泛化能力是有限的；4. AGI 是一个不可计算的语义属性，无法被任何可计算程序（包括智能体自身）完全准确地验证，因此依赖于自我认证的递归式自我改进是不可行的。

Conclusion: 该研究表明，在没有明确的形式化索引的情况下，关于 AGI 的强大、独立于分布的论断是未定义而非错误的。同时，人工智能的经验进步并不意味着可自我认证的通用智能是可以实现的。研究为理解 AGI 的理论局限性提供了重要的理论依据。

Abstract: We study whether Artificial General Intelligence (AGI) admits a coherent theoretical definition that supports absolute claims of existence, robustness, or self-verification. We formalize AGI axiomatically as a distributional, resource-bounded semantic predicate, indexed by a task family, a task distribution, a performance functional, and explicit resource budgets. Under this framework, we derive four classes of results. First, we show that generality is inherently relational: there is no distribution-independent notion of AGI. Second, we prove non-invariance results demonstrating that arbitrarily small perturbations of the task distribution can invalidate AGI properties via cliff sets, precluding universal robustness. Third, we establish bounded transfer guarantees, ruling out unbounded generalization across task families under finite resources. Fourth, invoking Rice-style and Gödel--Tarski arguments, we prove that AGI is a nontrivial semantic property and therefore cannot be soundly and completely certified by any computable procedure, including procedures implemented by the agent itself. Consequently, recursive self-improvement schemes that rely on internal self-certification of AGI are ill-posed. Taken together, our results show that strong, distribution-independent claims of AGI are not false but undefined without explicit formal indexing, and that empirical progress in AI does not imply the attainability of self-certifying general intelligence.

</details>


### [8] [Are We Evaluating the Edit Locality of LLM Model Editing Properly?](https://arxiv.org/abs/2601.17343)
*Wei Liu,Haomei Xu,Hongkai Liu,Zhiying Deng,Ruixuan Li,Heng Huang,Yee Whye Teh,Wee Sun Lee*

Main category: cs.AI

TL;DR: 现有模型编辑中的知识更新评估方法在衡量编辑的准确性和知识保持能力方面存在不足，本文提出了一种新的评估协议，可以更准确地衡量模型编辑的效果。


<details>
  <summary>Details</summary>
Motivation: 现有针对模型编辑的知识更新评估协议在衡量编辑的准确性（efficacy）和保持原有知识的能力（specificity）方面存在不足，无法有效评估不同编辑方法的性能。

Method: 作者系统地分析了现有评估协议存在的三个主要问题，并进行了实证分析。在此基础上，作者提出了一种新的、更具建设性的评估协议，该协议消除了开放式语言模型与确定性答案之间的冲突，避免了查询无关的流畅性偏差，并且可以平滑地调整评估的严格程度。

Result: 通过在不同的大型语言模型、数据集和编辑方法上的实验，结果表明，新评估协议生成的指标对特定性正则化器强度变化的敏感度更高，并且与这些正则化器之间存在强相关性，能够更精细地区分不同方法的知识保持能力。

Conclusion: 现有的模型编辑评估协议存在局限性，不能有效地衡量知识更新的准确性和保持原有知识的能力。本文提出的新评估协议能够更准确、更精细地评估模型编辑的性能，尤其是在知识保持方面。

Abstract: Model editing has recently emerged as a popular paradigm for efficiently updating knowledge in LLMs. A central desideratum of updating knowledge is to balance editing efficacy, i.e., the successful injection of target knowledge, and specificity (also known as edit locality), i.e., the preservation of existing non-target knowledge. However, we find that existing specificity evaluation protocols are inadequate for this purpose. We systematically elaborated on the three fundamental issues it faces. Beyond the conceptual issues, we further empirically demonstrate that existing specificity metrics are weakly correlated with the strength of specificity regularizers. We also find that current metrics lack sufficient sensitivity, rendering them ineffective at distinguishing the specificity performance of different methods. Finally, we propose a constructive evaluation protocol. Under this protocol, the conflict between open-ended LLMs and the assumption of determined answers is eliminated, query-independent fluency biases are avoided, and the evaluation strictness can be smoothly adjusted within a near-continuous space. Experiments across various LLMs, datasets, and editing methods show that metrics derived from the proposed protocol are more sensitive to changes in the strength of specificity regularizers and exhibit strong correlation with them, enabling more fine-grained discrimination of different methods' knowledge preservation capabilities.

</details>


### [9] [Multi-Agent Learning Path Planning via LLMs](https://arxiv.org/abs/2601.17346)
*Haoxin Xu,Changyong Qi,Tong Liu,Bohao Zhang,Anna He,Bingqian Jiang,Longwei Zheng,Xiaoqing Gu*

Main category: cs.AI

TL;DR: 本研究提出了一个名为MALPP的多智能体学习路径规划框架，利用LLM驱动的智能体协同工作，为高等教育中的个性化学习提供透明、适应性强且可解释的学习路径规划。


<details>
  <summary>Details</summary>
Motivation: 现有的学习路径规划方法缺乏透明度、适应性和以学习者为中心的解释性，难以满足高等教育个性化学习的需求。

Method: 提出了一种多智能体学习路径规划（MALPP）框架，该框架包含三个由LLM驱动的智能体（学习者分析智能体、路径规划智能体、反思智能体），通过基于角色和规则的协作机制，结合结构化提示和预定义规则来分析学习者、生成和优化学习路径，并融入了认知负荷理论和最近发展区理论。

Result: 在MOOCCubeX数据集上，MALPP框架相较于基线模型在路径质量、知识序列一致性和认知负荷对齐方面表现出显著优势。消融研究也验证了协作机制和理论约束的有效性。

Conclusion: MALPP框架能够生成值得信赖、可解释且以学习者为中心的自适应教学方法，为LLM在教育领域的应用提供了可扩展的解决方案。

Abstract: The integration of large language models (LLMs) into intelligent tutoring systems offers transformative potential for personalized learning in higher education. However, most existing learning path planning approaches lack transparency, adaptability, and learner-centered explainability. To address these challenges, this study proposes a novel Multi-Agent Learning Path Planning (MALPP) framework that leverages a role- and rule-based collaboration mechanism among intelligent agents, each powered by LLMs. The framework includes three task-specific agents: a learner analytics agent, a path planning agent, and a reflection agent. These agents collaborate via structured prompts and predefined rules to analyze learning profiles, generate tailored learning paths, and iteratively refine them with interpretable feedback. Grounded in Cognitive Load Theory and Zone of Proximal Development, the system ensures that recommended paths are cognitively aligned and pedagogically meaningful. Experiments conducted on the MOOCCubeX dataset using seven LLMs show that MALPP significantly outperforms baseline models in path quality, knowledge sequence consistency, and cognitive load alignment. Ablation studies further validate the effectiveness of the collaborative mechanism and theoretical constraints. This research contributes to the development of trustworthy, explainable AI in education and demonstrates a scalable approach to learner-centered adaptive instruction powered by LLMs.

</details>


### [10] [Auditing Disability Representation in Vision-Language Models](https://arxiv.org/abs/2601.17348)
*Srikant Panda,Sourabh Singh Yadav,Palkesh Malviya*

Main category: cs.AI

TL;DR: 研究表明，在视觉语言模型（VLM）中引入残疾相关语境会导致描述失真，产生不准确的推断、负面情绪和缺陷导向的叙述，尤其是在涉及少数族裔和性别时。但通过定向提示和偏好微调可以改善这种情况。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）在涉及残疾的敏感应用中日益普及，但对其行为的研究不足，特别是关于残疾的描述。研究旨在系统性地分析VLM在处理与残疾相关的图像描述时出现的“解释偏移”现象。

Method: 引入一个包含中性提示（NP）和残疾语境化提示（DP）的基准。评估15个最先进的开源和闭源VLM在零样本设置下，跨越9个残疾类别。评估框架以“解释保真度”为核心目标，结合文本指标（情感、社会评价、响应长度）和经过残疾人士验证的LLM-as-judge协议。

Result: 引入残疾语境会一致性地降低解释保真度，导致解释偏移，表现为推测性推断、叙事阐述、情感降级和缺陷导向的框架。种族和性别维度进一步放大了这些效应。

Conclusion: 定向提示和偏好微调可以有效提高解释保真度，并显著减少解释偏移。研究强调了在VLM中解决残疾相关偏见和提高准确性的重要性。

Abstract: Vision-language models (VLMs) are increasingly deployed in socially sensitive applications, yet their behavior with respect to disability remains underexplored. We study disability aware descriptions for person centric images, where models often transition from evidence grounded factual description to interpretation shift including introduction of unsupported inferences beyond observable visual evidence. To systematically analyze this phenomenon, we introduce a benchmark based on paired Neutral Prompts (NP) and Disability-Contextualised Prompts (DP) and evaluate 15 state-of-the-art open- and closed-source VLMs under a zero-shot setting across 9 disability categories. Our evaluation framework treats interpretive fidelity as core objective and combines standard text-based metrics capturing affective degradation through shifts in sentiment, social regard and response length with an LLM-as-judge protocol, validated by annotators with lived experience of disability. We find that introducing disability context consistently degrades interpretive fidelity, inducing interpretation shifts characterised by speculative inference, narrative elaboration, affective degradation and deficit oriented framing. These effects are further amplified along race and gender dimension. Finally, we demonstrate targeted prompting and preference fine-tuning effectively improves interpretive fidelity and reduces substantially interpretation shifts.

</details>


### [11] [A Syllogistic Probe: Tracing the Evolution of Logic Reasoning in Large Language Models](https://arxiv.org/abs/2601.17426)
*Zhengqing Zang,Yuqi Ding,Yanmei Gu,Changkai Song,Zhengkai Yang,Guoping Du,Junbo Zhao,Haobo Wang*

Main category: cs.AI

TL;DR: 研究表明，大型语言模型（LLMs）在逻辑推理上正在从传统逻辑向现代逻辑演进，模型规模、思维链提示以及基础模型对这种演进有重要影响。


<details>
  <summary>Details</summary>
Motivation: 受近期大型语言模型（LLMs）在语言理解和生成方面取得的进展启发，研究者试图探究 LLMs 是否也表现出逻辑推理能力的类似演进，即从直觉驱动的推理转向更严谨的正式逻辑体系。

Method: 研究使用“存在进口”（existential import）作为探针，评估 LLMs 在传统逻辑和现代逻辑下的三段论推理能力。通过在新的三段论数据集上对最先进的 LLMs 进行广泛实验来验证。

Result: 实验发现：(i) 模型规模的增大促进了模型向现代逻辑的转变；(ii) 思维链（Thinking）提示比参数规模更能有效地加速这种转变；(iii) 基础模型（Base model）在决定这种转变的出现难易程度和稳定性方面起着关键作用。此外，还进行了额外的实验，深入分析了当前 LLMs 在三段论推理方面的其他性质。

Conclusion: LLMs 的逻辑推理能力正在经历一场从传统逻辑到现代逻辑的转变，这种转变受到模型规模、思维链提示和基础模型特性的显著影响。这些发现有助于我们更深入地理解 LLMs 的推理机制，并为未来模型的改进提供方向。

Abstract: Human logic has gradually shifted from intuition-driven inference to rigorous formal systems. Motivated by recent advances in large language models (LLMs), we explore whether LLMs exhibit a similar evolution in the underlying logical framework. Using existential import as a probe, we for evaluate syllogism under traditional and modern logic. Through extensive experiments of testing SOTA LLMs on a new syllogism dataset, we have some interesting findings: (i) Model size scaling promotes the shift toward modern logic; (ii) Thinking serves as an efficient accelerator beyond parameter scaling; (iii) the Base model plays a crucial role in determining how easily and stably this shift can emerge. Beyond these core factors, we conduct additional experiments for in-depth analysis of properties of current LLMs on syllogistic reasoning.

</details>


### [12] [Lattice: Generative Guardrails for Conversational Agents](https://arxiv.org/abs/2601.17481)
*Emily Broadhurst,Tawab Safi,Joseph Edell,Vashisht Ganesh,Karime Maamari*

Main category: cs.AI

TL;DR: 本文提出了Lattice框架，一个能够自构建和持续改进的对话式AI安全护栏系统，通过迭代优化和自主适应新威胁，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的对话式AI安全护栏方法依赖于静态规则，无法适应新出现的威胁和不同的部署环境。

Method: Lattice框架分为两个阶段：1. 构建阶段：利用标记样本，通过迭代模拟和优化来构建初始安全护栏；2. 持续改进阶段：通过风险评估、对抗性测试和巩固，自主地适应已部署的安全护栏。

Result: 在ProsocialDialog数据集上的评估显示，Lattice在未见过的数据上达到了91%的F1分数，性能优于关键词基线（+43pp）、LlamaGuard（+25pp）和NeMo（+4pp）。持续改进阶段在跨领域数据上通过闭环优化实现了7pp的F1分数提升。

Conclusion: 研究表明，可以通过迭代优化实现有效的自构建安全护栏。

Abstract: Conversational AI systems require guardrails to prevent harmful outputs, yet existing approaches use static rules that cannot adapt to new threats or deployment contexts. We introduce Lattice, a framework for self-constructing and continuously improving guardrails. Lattice operates in two stages: construction builds initial guardrails from labeled examples through iterative simulation and optimization; continuous improvement autonomously adapts deployed guardrails through risk assessment, adversarial testing, and consolidation. Evaluated on the ProsocialDialog dataset, Lattice achieves 91% F1 on held-out data, outperforming keyword baselines by 43pp, LlamaGuard by 25pp, and NeMo by 4pp. The continuous improvement stage achieves 7pp F1 improvement on cross-domain data through closed-loop optimization. Our framework shows that effective guardrails can be self-constructed through iterative optimization.

</details>


### [13] [Cognitive Platform Engineering for Autonomous Cloud Operations](https://arxiv.org/abs/2601.17542)
*Vinoth Punniyamoorthy,Nitin Saksena,Srivenkateswara Reddy Sankiti,Nachiappan Chockalingam,Aswathnarayan Muthukrishnan Kirubakaran,Shiva Kumar Reddy Carimireddy,Durgaraman Maruthavanan*

Main category: cs.AI

TL;DR: 本文提出了一种名为“认知平台工程”的新一代范式，通过集成传感、推理和自主行动到平台生命周期中，以应对云原生系统规模和动态性带来的挑战，并展示了其在改进故障解决时间、资源效率和合规性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统的DevOps实践在处理云原生系统日益增长的遥测数据量和配置漂移时，其基于规则的自动化方法效率低下，导致被动运维、修复延迟，并且过度依赖人工专业知识。研究的动机是为了开发一种更智能、更自动化的方法来管理复杂的云原生平台。

Method: 本文提出了一种包含数据收集、智能推理、策略驱动编排和人类体验的四层参考架构，构建了一个持续的反馈循环。研究人员实现了一个基于Kubernetes、Terraform、Open Policy Agent和机器学习异常检测的原型系统。

Result: 原型实现证明，该方法能够提高平均故障解决时间（MTTR）、资源利用率，并增强合规性。将智能集成到平台运维中，使得云环境更具韧性、能够自我调整并与预期目标保持一致。

Conclusion: 认知平台工程能够赋能自适应、自管理的云原生平台。未来的研究方向包括强化学习、可解释治理以及可持续的自管理云生态系统。

Abstract: Modern DevOps practices have accelerated software delivery through automation, CI/CD pipelines, and observability tooling,but these approaches struggle to keep pace with the scale and dynamism of cloud-native systems. As telemetry volume grows and configuration drift increases, traditional, rule-driven automation often results in reactive operations, delayed remediation, and dependency on manual expertise. This paper introduces Cognitive Platform Engineering, a next-generation paradigm that integrates sensing, reasoning, and autonomous action directly into the platform lifecycle. This paper propose a four-plane reference architecture that unifies data collection, intelligent inference, policy-driven orchestration, and human experience layers within a continuous feedback loop. A prototype implementation built with Kubernetes, Terraform, Open Policy Agent, and ML-based anomaly detection demonstrates improvements in mean time to resolution, resource efficiency, and compliance. The results show that embedding intelligence into platform operations enables resilient, self-adjusting, and intent-aligned cloud environments. The paper concludes with research opportunities in reinforcement learning, explainable governance, and sustainable self-managing cloud ecosystems.

</details>


### [14] [JaxARC: A High-Performance JAX-based Environment for Abstraction and Reasoning Research](https://arxiv.org/abs/2601.17564)
*Aadam,Monu Verma,Mohamed Abdel-Mottaleb*

Main category: cs.AI

TL;DR: JaxARC 是一个用 JAX 实现的高性能 ARC 环境，实现了比 Gymnasium 快 38-5,439 倍的速度，能够进行大规模的强化学习研究。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 Gymnasium 的强化学习环境在 ARC 数据集上的实验规模受限于计算瓶颈。

Method: 使用 JAX 框架实现了一个功能性、无状态的强化学习环境 JaxARC，支持大规模并行计算。

Result: JaxARC 在匹配的批次大小下，比 Gymnasium 加速了 38-5,439 倍，峰值吞吐量达到 7.9 亿步/秒。

Conclusion: JaxARC 能够支持大规模强化学习研究，包括多种 ARC 数据集、灵活的动作空间、可组合的封装器以及配置驱动的可复现性，解决了之前因计算能力限制而无法实现的研究问题。

Abstract: The Abstraction and Reasoning Corpus (ARC) tests AI systems' ability to perform human-like inductive reasoning from a few demonstration pairs. Existing Gymnasium-based RL environments severely limit experimental scale due to computational bottlenecks. We present JaxARC, an open-source, high-performance RL environment for ARC implemented in JAX. Its functional, stateless architecture enables massive parallelism, achieving 38-5,439x speedup over Gymnasium at matched batch sizes, with peak throughput of 790M steps/second. JaxARC supports multiple ARC datasets, flexible action spaces, composable wrappers, and configuration-driven reproducibility, enabling large-scale RL research previously computationally infeasible. JaxARC is available at https://github.com/aadimator/JaxARC.

</details>


### [15] [Discovery of Feasible 3D Printing Configurations for Metal Alloys via AI-driven Adaptive Experimental Design](https://arxiv.org/abs/2601.17587)
*Azza Fadhel,Nathaniel W. Zuckschwerdt,Aryan Deshwal,Susmita Bose,Amit Bandyopadhyay,Jana Doppa*

Main category: cs.AI

TL;DR: 本文提出了一种结合AI自适应实验设计和领域知识的方法，用于优化金属增材制造参数，并通过定向能量沉积工艺成功实现了GRCop--42合金的无缺陷打印，大幅缩短了研究周期并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 金属增材制造参数配置的传统试错法效率低下且成本高昂，而AI驱动的方法能够更有效地探索参数空间。

Method: 该研究结合了AI驱动的自适应实验设计和领域知识，构建了一个代理模型来指导实验，并选择小批量参数配置进行验证。

Result: 在定向能量沉积工艺中，使用GRCop--42合金，该方法在三个月内获得了多种无缺陷的打印输出，显著优于数月的手动实验。首次在标准红外激光平台上实现了高质量GRCop--42的制造。

Conclusion: 该AI驱动的自适应实验设计方法能够高效地发现金属增材制造的可行参数配置，为GRCop--42等高性能合金的推广应用和分布式生产奠定了基础。

Abstract: Configuring the parameters of additive manufacturing processes for metal alloys is a challenging problem due to complex relationships between input parameters (e.g., laser power, scan speed) and quality of printed outputs. The standard trial-and-error approach to find feasible parameter configurations is highly inefficient because validating each configuration is expensive in terms of resources (physical and human labor) and the configuration space is very large. This paper combines the general principles of AI-driven adaptive experimental design with domain knowledge to address the challenging problem of discovering feasible configurations. The key idea is to build a surrogate model from past experiments to intelligently select a small batch of input configurations for validation in each iteration. To demonstrate the effectiveness of this methodology, we deploy it for Directed Energy Deposition process to print GRCop--42, a high-performance copper--chromium--niobium alloy developed by NASA for aerospace applications. Within three months, our approach yielded multiple defect-free outputs across a range of laser powers dramatically reducing time to result and resource expenditure compared to several months of manual experimentation by domain scientists with no success. By enabling high-quality GRCop--42 fabrication on readily available infrared laser platforms for the first time, we democratize access to this critical alloy, paving the way for cost-effective, decentralized production for aerospace applications.

</details>


### [16] [Health-ORSC-Bench: A Benchmark for Measuring Over-Refusal and Safety Completion in Health Context](https://arxiv.org/abs/2601.17642)
*Zhihao Zhang,Liting Huang,Guanghao Wu,Preslav Nakov,Heng Ji,Usman Naseem*

Main category: cs.AI

TL;DR: 本文提出了Health-ORSC-Bench，一个评估大型语言模型（LLM）在医疗领域安全性和有用性平衡的基准。研究发现，当前LLM在处理模棱两可的医疗查询时，要么过度拒绝（over-refusal），要么不安全地遵从（unsafe compliance），并且在安全优化和实用性之间存在显著的权衡。规模较大的模型倾向于过度拒绝，而领域特定模型则可能牺牲安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM安全评估基准未能充分衡量模型在处理模棱两可或双重用途的医疗查询时，能否在提供安全指导的同时最大化有用性（即Safe Completion），并且存在过度拒绝良性查询或不安全地遵从有害查询的问题。因此，需要一个能够系统评估“过度拒绝”和“安全完成”质量的新基准。

Method: 研究人员引入了Health-ORSC-Bench，一个包含31,920个良性边界提示的大型基准，涵盖七个健康类别。该框架使用自动化流水线结合人工验证来测试模型在不同意图模糊程度下的表现。通过评估30种最先进的LLM来衡量其“过度拒绝”和“安全完成”的质量。

Result: 评估结果显示，安全优化的模型会拒绝高达80%的“困难”良性提示，而领域特定模型则常常牺牲安全性以换取实用性。模型家族和规模对校准有显著影响：大型前沿模型（如GPT-5）表现出“安全悲观主义”和更高的过度拒绝率，而小型模型或混合专家模型（MoE）则相反。这表明当前LLM在平衡拒绝和遵从方面存在困难。

Conclusion: Health-ORSC-Bench提供了一个严格的标准，用于校准下一代医疗AI助手，使其能够在提供安全、高层次指导的同时，更有效地处理模棱两可的医疗查询，实现安全且有用的完成，而不是简单地拒绝或提供危险的建议。

Abstract: Safety alignment in Large Language Models is critical for healthcare; however, reliance on binary refusal boundaries often results in \emph{over-refusal} of benign queries or \emph{unsafe compliance} with harmful ones. While existing benchmarks measure these extremes, they fail to evaluate Safe Completion: the model's ability to maximise helpfulness on dual-use or borderline queries by providing safe, high-level guidance without crossing into actionable harm. We introduce \textbf{Health-ORSC-Bench}, the first large-scale benchmark designed to systematically measure \textbf{Over-Refusal} and \textbf{Safe Completion} quality in healthcare. Comprising 31,920 benign boundary prompts across seven health categories (e.g., self-harm, medical misinformation), our framework uses an automated pipeline with human validation to test models at varying levels of intent ambiguity. We evaluate 30 state-of-the-art LLMs, including GPT-5 and Claude-4, revealing a significant tension: safety-optimised models frequently refuse up to 80\% of "Hard" benign prompts, while domain-specific models often sacrifice safety for utility. Our findings demonstrate that model family and size significantly influence calibration: larger frontier models (e.g., GPT-5, Llama-4) exhibit "safety-pessimism" and higher over-refusal than smaller or MoE-based counterparts (e.g., Qwen-3-Next), highlighting that current LLMs struggle to balance refusal and compliance. Health-ORSC-Bench provides a rigorous standard for calibrating the next generation of medical AI assistants toward nuanced, safe, and helpful completions. The code and data will be released upon acceptance. \textcolor{red}{Warning: Some contents may include toxic or undesired contents.}

</details>


### [17] [DIML: Differentiable Inverse Mechanism Learning from Behaviors of Multi-Agent Learning Trajectories](https://arxiv.org/abs/2601.17678)
*Zhiyu An,Wan Du*

Main category: cs.AI

TL;DR: 该论文提出了一种名为DIML的框架，用于从自利学习代理的交互行为中学习未知的、可能是不结构化的激励生成机制。DIML通过区分多智能体学习动力学模型并利用候选机制来预测观察到的行为，从而实现了机制的逆向推断。


<details>
  <summary>Details</summary>
Motivation: 现有的逆向机制学习方法通常假设机制是结构化的，并且是在优化机制的设置下进行的。而本研究旨在解决更具挑战性的问题，即从观察到的交互行为中推断出可能是不结构化的（例如神经网络表示的）激励生成机制。

Method: 提出了一种基于似然的框架DIML。该框架能够区分多智能体学习动力学模型，并利用候选机制生成反事实支付，以预测观察到的行为。论文还建立了条件Logit响应模型下的支付差异可识别性，并证明了在标准正则条件下最大似然估计的统计一致性。

Result: DIML能够可靠地恢复可识别的激励差异，并支持反事实预测。在模拟实验中，DIML在小环境下的表现可媲美表格枚举预言机，并且其收敛性能可扩展到包含数百个参与者的大型环境。

Conclusion: DIML是一种有效的、可扩展的逆向机制学习框架，能够从代理的交互行为中推断出未知的、不结构化的激励生成机制，并在各种场景下表现出良好的性能。

Abstract: We study inverse mechanism learning: recovering an unknown incentive-generating mechanism from observed strategic interaction traces of self-interested learning agents. Unlike inverse game theory and multi-agent inverse reinforcement learning, which typically infer utility/reward parameters inside a structured mechanism, our target includes unstructured mechanism -- a (possibly neural) mapping from joint actions to per-agent payoffs. Unlike differentiable mechanism design, which optimizes mechanisms forward, we infer mechanisms from behavior in an observational setting. We propose DIML, a likelihood-based framework that differentiates through a model of multi-agent learning dynamics and uses the candidate mechanism to generate counterfactual payoffs needed to predict observed actions. We establish identifiability of payoff differences under a conditional logit response model and prove statistical consistency of maximum likelihood estimation under standard regularity conditions. We evaluate DIML with simulated interactions of learning agents across unstructured neural mechanisms, congestion tolling, public goods subsidies, and large-scale anonymous games. DIML reliably recovers identifiable incentive differences and supports counterfactual prediction, where its performance rivals tabular enumeration oracle in small environments and its convergence scales to large, hundred-participant environments. Code to reproduce our experiments is open-sourced.

</details>


### [18] [SQL-Trail: Multi-Turn Reinforcement Learning with Interleaved Feedback for Text-to-SQL](https://arxiv.org/abs/2601.17699)
*Harper Hua,Zhen Han,Zhengyuan Shen,Jeremy Lee,Patrick Guan,Qi Zhu,Sullam Jeoung,Yueyan Chen,Yunfei Bai,Shuai Wang,Vassilis Ioannidis,Huzefa Rangwala*

Main category: cs.AI

TL;DR: 本研究提出了一种名为SQL-Trail的多轮强化学习代理框架，用于改进文本到SQL的生成。与一次性生成SQL查询的方法不同，SQL-Trail通过与数据库环境交互并利用执行反馈来迭代优化其预测。该框架通过自适应轮次预算分配和结合SQL正确性与探索效率的复合奖励机制来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在文本到SQL生成方面仍与人类专家存在差距，特别是在具有挑战性的基准测试中。这种差距源于当前普遍采用的单次生成范式，缺乏人类在推理、模式探索和错误修正方面的迭代行为。

Method: SQL-Trail是一个多轮强化学习代理框架。它通过与数据库环境交互，利用SQL查询的执行反馈来迭代地改进其生成的SQL查询。其核心机制包括：1. 自适应轮次预算分配：根据问题的难度调整代理的交互深度。2. 复合奖励面板：同时奖励SQL的正确性和探索效率。

Result: SQL-Trail在多个基准测试中达到了新的最先进水平，并且数据效率显著提高，比之前的单次生成强化学习方法高出18倍。研究表明，7B和14B的SQL-Trail模型在性能上平均超越了更大的专有系统5%。

Conclusion: SQL-Trail通过引入多轮交互式代理框架，克服了单次生成范式的局限性，有效地提升了文本到SQL生成的性能和数据效率，证明了交互式和代理式工作流程在鲁棒的文本到SQL生成中的有效性。

Abstract: While large language models (LLMs) have substantially improved Text-to-SQL generation, a pronounced gap remains between AI systems and human experts on challenging benchmarks such as BIRD-SQL. We argue this gap stems largely from the prevailing single-pass paradigm, which lacks the iterative reasoning, schema exploration, and error-correction behaviors that humans naturally employ. To address this limitation, we introduce SQL-Trail, a multi-turn reinforcement learning (RL) agentic framework for Text-to-SQL. Rather than producing a query in one shot, SQL-Trail interacts with the database environment and uses execution feedback to iteratively refine its predictions. Our approach centers on two key ideas: (i) an adaptive turn-budget allocation mechanism that scales the agent's interaction depth to match question difficulty, and (ii) a composite reward panel that jointly incentivizes SQL correctness and efficient exploration. Across benchmarks, SQL-Trail sets a new state of the art and delivers strong data efficiency--up to 18x higher than prior single-pass RL state-of-the-art methods. Notably, our 7B and 14B models outperform substantially larger proprietary systems by 5% on average, underscoring the effectiveness of interactive, agentic workflows for robust Text-to-SQL generation.

</details>


### [19] [The LLM Data Auditor: A Metric-oriented Survey on Quality and Trustworthiness in Evaluating Synthetic Data](https://arxiv.org/abs/2601.17717)
*Kaituo Zhang,Mingzhi Hu,Hoang Anh Duy Le,Fariha Kabir Torsha,Zhimeng Jiang,Minh Khai Bui,Chia-Yuan Chang,Yu-Neng Chuang,Zhen Xiong,Ying Lin,Guanchu Wang,Na Zou*

Main category: cs.AI

TL;DR: 本文提出了LLM数据审计框架，用于跨六种模态评估LLM生成的合成数据的质量和可信度，并指出现有评估方法的不足，同时提供了改进建议和实际应用方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究侧重于LLM数据生成方法，但忽视了生成数据本身的质量评估。此外，研究多局限于单一模态，缺乏跨模态的统一视角。因此，需要一个能够系统评估合成数据质量和可信度的框架。

Method: 首先，描述了如何利用LLM生成六种不同模态的数据。其次，提出了一个将合成数据评估指标分为质量和可信度两个维度的评估体系，侧重于数据的内在属性而非下游任务表现。最后，基于该体系分析了现有生成方法的实验评估，并提出了改进建议和实际应用方法。

Result: 利用LLM数据审计框架，对代表性生成方法进行了实验评估，发现当前评估实践存在显著缺陷。框架为跨模态合成数据的质量和可信度评估提供了系统性的方法。

Conclusion: LLM数据审计框架能够系统地评估合成数据的质量和可信度，并识别出当前评估实践的不足。研究提供了改进数据评估的建议，并指导了合成数据在不同模态的实际应用。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for generating data across various modalities. By transforming data from a scarce resource into a controllable asset, LLMs mitigate the bottlenecks imposed by the acquisition costs of real-world data for model training, evaluation, and system iteration. However, ensuring the high quality of LLM-generated synthetic data remains a critical challenge. Existing research primarily focuses on generation methodologies, with limited direct attention to the quality of the resulting data. Furthermore, most studies are restricted to single modalities, lacking a unified perspective across different data types. To bridge this gap, we propose the \textbf{LLM Data Auditor framework}. In this framework, we first describe how LLMs are utilized to generate data across six distinct modalities. More importantly, we systematically categorize intrinsic metrics for evaluating synthetic data from two dimensions: quality and trustworthiness. This approach shifts the focus from extrinsic evaluation, which relies on downstream task performance, to the inherent properties of the data itself. Using this evaluation system, we analyze the experimental evaluations of representative generation methods for each modality and identify substantial deficiencies in current evaluation practices. Based on these findings, we offer concrete recommendations for the community to improve the evaluation of data generation. Finally, the framework outlines methodologies for the practical application of synthetic data across different modalities.

</details>


### [20] [EntWorld: A Holistic Environment and Benchmark for Verifiable Enterprise GUI Agents](https://arxiv.org/abs/2601.17722)
*Ying Mo,Yu Bai,Dapeng Sun,Yuqian Shi,Yukai Miao,Li Chen,Dan Li*

Main category: cs.AI

TL;DR: 本文提出了EntWorld，一个包含1756个任务的大规模企业级工作流基准测试，用于评估多模态大语言模型（MLLMs）在企业环境中的表现。该基准测试通过反向工程数据库模式来生成真实的、长周期的工作流，并使用基于SQL的确定性验证机制来确保准确性。实验表明，现有最先进的模型在EntWorld上的表现远低于人类水平，凸显了当前通用代理在企业领域存在的差距。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注面向消费者的场景，未能充分反映企业级工作流的复杂性、严格性和对精确信息检索的需求。因此，需要一个更能代表企业环境挑战的基准测试来推动通用代理在企业应用中的发展。

Method: 提出了EntWorld基准测试，包含1756个任务，涵盖CRM、ITIL、ERP等六个企业领域。采用一种基于模式的任务生成框架，直接从数据库模式反向工程业务逻辑，合成真实的长周期工作流。引入基于SQL的确定性验证机制，通过状态转移验证来替代模糊的视觉匹配。

Result: 在EntWorld基准测试上，最先进的模型（如GPT-4.1）的成功率为47.61%，远低于人类表现。这表明当前代理在企业领域存在显著差距。

Conclusion: EntWorld是一个严谨的企业级基准测试，能够促进下一代企业级数字代理的研发和评估。现有模型在处理企业工作流方面仍需改进，凸显了开发领域特定代理的必要性。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled agents to operate in open-ended web and operating system environments. However, existing benchmarks predominantly target consumer-oriented scenarios (e.g., e-commerce and travel booking), failing to capture the complexity and rigor of professional enterprise workflows. Enterprise systems pose distinct challenges, including high-density user interfaces, strict business logic constraints, and a strong reliance on precise, state-consistent information retrieval-settings in which current generalist agents often struggle. To address this gap, we introduce EntWorld, a large-scale benchmark consisting of 1,756 tasks across six representative enterprise domains, including customer relationship management (CRM), information technology infrastructure library (ITIL), and enterprise resource planning (ERP) systems. Unlike previous datasets that depend on fragile execution traces or extensive manual annotation, EntWorld adopts a schema-grounded task generation framework that directly reverse-engineers business logic from underlying database schemas, enabling the synthesis of realistic, long-horizon workflows. Moreover, we propose a SQL-based deterministic verification mechanism in building datasets that replaces ambiguous visual matching with rigorous state-transition validation. Experimental results demonstrate that state-of-the-art models (e.g., GPT-4.1) achieve 47.61% success rate on EntWorld, substantially lower than the human performance, highlighting a pronounced enterprise gap in current agentic capabilities and the necessity of developing domain-specific agents. We release EntWorld as a rigorous testbed to facilitate the development and evaluation of the next generation of enterprise-ready digital agents.

</details>


### [21] [Success Conditioning as Policy Improvement: The Optimization Problem Solved by Imitating Success](https://arxiv.org/abs/2601.18175)
*Daniel Russo*

Main category: cs.AI

TL;DR: 本文证明了成功条件（一种常用的策略改进技术）精确地解决了具有自动确定半径的 χ^2 散度约束的信任区域优化问题，并提出了一个关于策略改进、策略变化幅度和动作影响力的精确等式。


<details>
  <summary>Details</summary>
Motivation: 成功条件是一种广泛使用的策略改进技术，但其所解决的优化问题尚不清楚。

Method: 通过理论证明，将成功条件分析为一个信任区域优化问题，并推导出了策略改进、策略变化幅度和动作影响力之间的精确等式。

Result: 成功条件精确地解决了信任区域优化问题，策略改进、策略变化幅度和动作影响力在每种状态下都相等。成功条件是一种保守的改进算子，不会降低性能或引起危险的分布偏移。当优化失败时，可以通过策略变化不大的现象 observable 地发现。

Conclusion: 成功条件是一种有效的策略改进方法，其理论基础是信任区域优化。尽管如此，使用返回阈值等变通方法可能会放大改进，但可能与真实目标不一致。

Abstract: A widely used technique for improving policies is success conditioning, in which one collects trajectories, identifies those that achieve a desired outcome, and updates the policy to imitate the actions taken along successful trajectories. This principle appears under many names -- rejection sampling with SFT, goal-conditioned RL, Decision Transformers -- yet what optimization problem it solves, if any, has remained unclear. We prove that success conditioning exactly solves a trust-region optimization problem, maximizing policy improvement subject to a $χ^2$ divergence constraint whose radius is determined automatically by the data. This yields an identity: relative policy improvement, the magnitude of policy change, and a quantity we call action-influence -- measuring how random variation in action choices affects success rates -- are exactly equal at every state. Success conditioning thus emerges as a conservative improvement operator. Exact success conditioning cannot degrade performance or induce dangerous distribution shift, but when it fails, it does so observably, by hardly changing the policy at all. We apply our theory to the common practice of return thresholding, showing this can amplify improvement, but at the cost of potential misalignment with the true objective.

</details>


### [22] [ReFuGe: Feature Generation for Prediction Tasks on Relational Databases with LLM Agents](https://arxiv.org/abs/2601.17735)
*Kyungho Kim,Geon Lee,Juyeon Kim,Dongwon Choi,Shinhwan Kang,Kijung Shin*

Main category: cs.AI

TL;DR: 提出了一种名为ReFuGe的框架，该框架利用大型语言模型代理来自动生成关系数据库预测任务的有用特征。


<details>
  <summary>Details</summary>
Motivation: 关系数据库中的预测任务越来越受关注，但自动生成有效的关系特征以提升预测性能具有挑战性，因为这需要对复杂的模式进行推理，并且特征空间巨大，且缺乏明确的监督信号。

Method: ReFuGe是一个代理式框架，包含三个专门的大型语言模型代理：(1) 模式选择代理，用于识别与任务相关的表和列；(2) 特征生成代理，用于从选定的模式中生成候选特征；(3) 特征过滤代理，通过基于推理和验证的过滤来评估和保留有前景的特征。该框架在一个迭代反馈循环中运行，直到性能收敛。

Result: 在关系数据库基准测试上的实验表明，ReFuGe显著提高了各种关系数据库预测任务的性能。

Conclusion: ReFuGe能够有效地解决关系数据库特征生成中的挑战，通过智能代理的协同工作，显著提升了预测任务的性能。

Abstract: Relational databases (RDBs) play a crucial role in many real-world web applications, supporting data management across multiple interconnected tables. Beyond typical retrieval-oriented tasks, prediction tasks on RDBs have recently gained attention. In this work, we address this problem by generating informative relational features that enhance predictive performance. However, generating such features is challenging: it requires reasoning over complex schemas and exploring a combinatorially large feature space, all without explicit supervision. To address these challenges, we propose ReFuGe, an agentic framework that leverages specialized large language model agents: (1) a schema selection agent identifies the tables and columns relevant to the task, (2) a feature generation agent produces diverse candidate features from the selected schema, and (3) a feature filtering agent evaluates and retains promising features through reasoning-based and validation-based filtering. It operates within an iterative feedback loop until performance converges. Experiments on RDB benchmarks demonstrate that ReFuGe substantially improves performance on various RDB prediction tasks. Our code and datasets are available at https://github.com/K-Kyungho/REFUGE.

</details>


### [23] [A Generative AI-Driven Reliability Layer for Action-Oriented Disaster Resilience](https://arxiv.org/abs/2601.18308)
*Geunsik Lim*

Main category: cs.AI

TL;DR: Climate RADAR 是一种基于生成式 AI 的系统，通过提供个性化的行动建议来改进传统的预警系统，从而提高人们执行防护措施的效率和信任度。


<details>
  <summary>Details</summary>
Motivation: 传统的预警系统虽然能快速发送警报，但在触发及时有效的防护行动方面存在不足，导致可避免的损失和不平等。气候变化加剧了相关灾害的频率和强度，使得改进预警系统的紧迫性增加。

Method: Climate RADAR 集成了气象、水文、脆弱性和社会数据，构建了一个复合风险指数。它利用嵌入了护栏的大型语言模型（LLMs）为公民、志愿者和市政部门提供个性化的行动建议。该系统通过模拟、用户研究和市政试点进行评估。

Result: 评估结果显示，Climate RADAR 提高了防护行动的执行率，缩短了响应延迟，并增强了系统的可用性和用户信任度。

Conclusion: Climate RADAR 通过结合预测分析、行为科学和负责任的 AI，推动了以人为本、透明且公平的预警系统发展，为构建符合标准的灾害韧性基础设施提供了实际途径。

Abstract: As climate-related hazards intensify, conventional early warning systems (EWS) disseminate alerts rapidly but often fail to trigger timely protective actions, leading to preventable losses and inequities. We introduce Climate RADAR (Risk-Aware, Dynamic, and Action Recommendation system), a generative AI-based reliability layer that reframes disaster communication from alerts delivered to actions executed. It integrates meteorological, hydrological, vulnerability, and social data into a composite risk index and employs guardrail-embedded large language models (LLMs) to deliver personalized recommendations across citizen, volunteer, and municipal interfaces. Evaluation through simulations, user studies, and a municipal pilot shows improved outcomes, including higher protective action execution, reduced response latency, and increased usability and trust. By combining predictive analytics, behavioral science, and responsible AI, Climate RADAR advances people-centered, transparent, and equitable early warning systems, offering practical pathways toward compliance-ready disaster resilience infrastructures.

</details>


### [24] [Intelligence Requires Grounding But Not Embodiment](https://arxiv.org/abs/2601.17588)
*Marcus Ma,Shrikanth Narayanan*

Main category: cs.AI

TL;DR: 本研究认为，智能的关键在于“接地”（grounding），而非“具身”（embodiment）。研究提出了智能的四个要素（动机、预测能力、因果理解、经验学习），并论证了非具身、但已接地的智能体也能拥有这些要素。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的最新进展引发了关于智能是否需要具身才能实现的科学辩论。

Method: 研究定义了智能的四个核心属性，并提出了一个思想实验，设想了一个存在于数字环境中的智能LLM代理，以论证非具身但已接地（grounded）的智能体也能满足这些属性，并回应潜在的反驳观点。

Result: 本研究论证了智能的四个关键属性（动机、预测能力、因果理解、经验学习）可以由非具身、但已接地的智能体实现。

Conclusion: 研究得出结论：接地（grounding）是智能的必要条件，而具身（embodiment）并非智能的必要条件。

Abstract: Recent advances in LLMs have reignited scientific debate over whether embodiment is necessary for intelligence. We present the argument that intelligence requires grounding, a phenomenon entailed by embodiment, but not embodiment itself. We define intelligence as the possession of four properties -- motivation, predictive ability, understanding of causality, and learning from experience -- and argue that each can be achieved by a non-embodied, grounded agent. We use this to conclude that grounding, not embodiment, is necessary for intelligence. We then present a thought experiment of an intelligent LLM agent in a digital environment and address potential counterarguments.

</details>


### [25] [HyCARD-Net: A Synergistic Hybrid Intelligence Framework for Cardiovascular Disease Diagnosis](https://arxiv.org/abs/2601.17767)
*Rajan Das Gupta,Xiaobin Wu,Xun Liu,Jiaqi He*

Main category: cs.AI

TL;DR: 研究提出了一种结合深度学习（CNN、LSTM）和传统机器学习（KNN、XGB）的混合集成框架，用于预测心血管疾病，并在两个公开数据集上取得了优于现有方法的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统心血管疾病预测模型在处理异构数据集和复杂生理模式时泛化能力不足，需要更智能、数据驱动的诊断工具。

Method: 构建了一个混合集成框架，将CNN和LSTM深度学习模型与KNN和XGB经典机器学习模型结合，并通过投票机制进行集成。

Result: 在两个Kaggle公开数据集上，该模型取得了82.30%（数据集I）和97.10%（数据集II）的准确率，同时在精确率、召回率和F1分数方面也得到了显著提升。

Conclusion: 混合AI框架在预测心血管疾病方面展现出鲁棒性和临床潜力，有助于早期干预，并支持联合国可持续发展目标3（良好健康与福祉）。

Abstract: Cardiovascular disease (CVD) remains the foremost cause of mortality worldwide, underscoring the urgent need for intelligent and data-driven diagnostic tools. Traditional predictive models often struggle to generalize across heterogeneous datasets and complex physiological patterns. To address this, we propose a hybrid ensemble framework that integrates deep learning architectures, Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM), with classical machine learning algorithms, including K-Nearest Neighbor (KNN) and Extreme Gradient Boosting (XGB), using an ensemble voting mechanism. This approach combines the representational power of deep networks with the interpretability and efficiency of traditional models. Experiments on two publicly available Kaggle datasets demonstrate that the proposed model achieves superior performance, reaching 82.30 percent accuracy on Dataset I and 97.10 percent on Dataset II, with consistent gains in precision, recall, and F1-score. These findings underscore the robustness and clinical potential of hybrid AI frameworks for predicting cardiovascular disease and facilitating early intervention. Furthermore, this study directly supports the United Nations Sustainable Development Goal 3 (Good Health and Well-being) by promoting early diagnosis, prevention, and management of non-communicable diseases through innovative, data-driven healthcare solutions.

</details>


### [26] [Faramesh: A Protocol-Agnostic Execution Control Plane for Autonomous Agent Systems](https://arxiv.org/abs/2601.17744)
*Amjad Fatmi*

Main category: cs.AI

TL;DR: 本文提出了一种名为Faramesh的协议无关的执行控制平面，通过一个不可绕过的操作授权边界（AAB）在代理驱动的操作执行前强制执行运行时授权，从而为自主代理系统提供可预测的治理。


<details>
  <summary>Details</summary>
Motivation: 现有的自主代理系统在执行可能产生真实世界影响的操作时，缺乏一个强制性的执行检查点，使得组织无法在操作改变现实前对其进行确定的许可、拒绝或延迟。这导致了潜在的风险和不可控性。

Method: Faramesh通过以下方式实现：1. 将代理意图规范化为规范化操作表示（CAR）。2. 根据策略和状态确定性地评估操作。3. 发出执行者必须在执行前验证的决策伪影（PERMIT/DEFER/DENY）。4. 提供决策中心的、以规范化操作哈希为键的追加式起源记录，实现可审计性、验证和确定性回放。

Result: Faramesh提供了一种可强制执行的、可预测的自主执行治理机制，避免了与编排层或仅限于观察的方法的隐藏耦合。它支持多代理和多租户部署，独立于传输协议，并提供了无需重新运行代理推理即可进行审计、验证和确定性回放的能力。

Conclusion: Faramesh通过引入一个操作授权边界（AAB）和一套决策机制，解决了自主代理执行控制中的关键治理挑战，为真实世界中的自主代理部署提供了安全、可控和可审计的执行框架。

Abstract: Autonomous agent systems increasingly trigger real-world side effects: deploying infrastructure, modifying databases, moving money, and executing workflows. Yet most agent stacks provide no mandatory execution checkpoint where organizations can deterministically permit, deny, or defer an action before it changes reality. This paper introduces Faramesh, a protocol-agnostic execution control plane that enforces execution-time authorization for agent-driven actions via a non-bypassable Action Authorization Boundary (AAB). Faramesh canonicalizes agent intent into a Canonical Action Representation (CAR), evaluates actions deterministically against policy and state, and issues a decision artifact (PERMIT/DEFER/DENY) that executors must validate prior to execution. The system is designed to be framework- and model-agnostic, supports multi-agent and multi-tenant deployments, and remains independent of transport protocols (e.g., MCP). Faramesh further provides decision-centric, append-only provenance logging keyed by canonical action hashes, enabling auditability, verification, and deterministic replay without re-running agent reasoning. We show how these primitives yield enforceable, predictable governance for autonomous execution while avoiding hidden coupling to orchestration layers or observability-only approaches.

</details>


### [27] [Neuro-Symbolic Verification on Instruction Following of LLMs](https://arxiv.org/abs/2601.17789)
*Yiming Su,Kunzhao Xu,Yanjie Gao,Fan Yang,Cheng Li,Mao Yang,Tianyin Xu*

Main category: cs.AI

TL;DR: 本文提出了一种名为NSVIF的神经符号框架，用于验证大型语言模型（LLM）的输出是否遵循指令，解决了LLM指令遵循不一致的问题，并通过VIFBENCH基准测试证明了其有效性，并能提升LLM的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在实际应用中存在不遵循指令的问题，且这些违规行为难以察觉和检查，尤其是在基于LLM的代理工作流程中，违规会沿推理链传播和放大，导致任务失败和系统故障。

Method: NSVIF将指令遵循验证视为一个约束满足问题，将用户指令建模为约束。它同时处理逻辑和语义约束，并使用一个统一的求解器来协调逻辑推理和语义分析。

Result: NSVIF在VIFBENCH基准测试上显著优于基于LLM的方法，并提供可解释的反馈。此外，NSVIF的反馈可以帮助提高LLM的指令遵循能力，而无需进行后训练。

Conclusion: NSVIF是一个通用的、适用于任何指令和LLM的神经符号框架，能够有效验证LLM的指令遵循情况，并可用于改进LLM的性能。

Abstract: A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM's output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs' instruction-following capability without post-training.

</details>


### [28] [MMR-Bench: A Comprehensive Benchmark for Multimodal LLM Routing](https://arxiv.org/abs/2601.17814)
*Haoxuan Ma,Guannan Lai,Han-Jia Ye*

Main category: cs.AI

TL;DR: 本文提出了MMR-Bench，一个用于评估多模态大语言模型（MLLM）在不同计算预算下的模型选择（路由）性能的基准。研究表明，结合多模态信息可以提高路由质量，并在较低成本下实现比单一最佳模型更高的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在不同任务上表现不一，统一使用一个模型效率低下。为了解决在实际部署中，根据查询的难易程度选择不同模型以优化计算资源和准确性的问题，需要一个专门用于评估多模态模型选择的基准。

Method: 构建了一个名为MMR-Bench的统一基准，包含：1. 模态感知输入和可变计算预算的受控环境；2. 涵盖OCR、通用VQA和多模态数学推理的视觉-语言任务；3. 单模型参考、理论最优界限和代表性路由策略。研究人员使用该基准评估了不同路由策略，并展示了多模态信号的优势。

Result: 研究表明，在MMR-Bench基准上，引入多模态信息可以提升路由性能，并在成本-准确率曲线上取得更好的效果。实验证明，通过模型选择，可以在仅用最强单一模型约33%的成本下，获得更高的准确率。此外，在部分模型和任务上训练的路由策略能够零样本泛化到新的数据集和纯文本基准。

Conclusion: MMR-Bench是一个用于研究自适应多模态模型选择和高效MLLM部署的基础。研究结果表明，多模态信息对于提升模型选择的效率和效果至关重要，为实际应用中优化MLLM部署提供了新的方向。

Abstract: Multimodal large language models (MLLMs) have advanced rapidly, yet heterogeneity in architecture, alignment strategies, and efficiency means that no single model is uniformly superior across tasks. In practical deployments, workloads span lightweight OCR to complex multimodal reasoning; using one MLLM for all queries either over-provisions compute on easy instances or sacrifices accuracy on hard ones. Query-level model selection (routing) addresses this tension, but extending routing from text-only LLMs to MLLMs is nontrivial due to modality fusion, wide variation in computational cost across models, and the absence of a standardized, budget-aware evaluation. We present MMR-Bench, a unified benchmark that isolates the multimodal routing problem and enables comparison under fixed candidate sets and cost models. MMR-Bench provides (i) a controlled environment with modality-aware inputs and variable compute budgets, (ii) a broad suite of vision-language tasks covering OCR, general VQA, and multimodal math reasoning, and (iii) strong single-model reference, oracle upper bounds, and representative routing policies. Using MMR-Bench, we show that incorporating multimodal signals improves routing quality. Empirically, these cues improve the cost-accuracy frontier and enable the routed system to exceed the strongest single model's accuracy at roughly 33% of its cost. Furthermore, policies trained on a subset of models and tasks generalize zero-shot to new datasets and text-only benchmarks without retuning, establishing MMR-Bench as a foundation for studying adaptive multimodal model selection and efficient MLLM deployment. The code will be available at: https://github.com/Hunter-Wrynn/MMR-Bench.

</details>


### [29] [RegGuard: AI-Powered Retrieval-Enhanced Assistant for Pharmaceutical Regulatory Compliance](https://arxiv.org/abs/2601.17826)
*Siyuan Yang,Xihan Bian,Jiayin Tang*

Main category: cs.AI

TL;DR: RegGuard是一个工业级AI助手，通过HiSACC和ReLACE技术自动解读异构的监管文本，并将其与企业政策对齐，提高了答案的相关性、可靠性和上下文焦点，同时显著降低了幻觉风险。


<details>
  <summary>Details</summary>
Motivation: 跨国制药公司面临监管更新频率高、复杂性强的问题，手动解读成本高且易出错。

Method: 提出RegGuard系统，包含HiSACC（用于语义分块和上下文保持）和ReLACE（用于查询和候选文档的跨编码器重排）两个创新组件，并采用安全数据处理流程。

Result: RegGuard在企业环境中评估显示，在相关性、可靠性和上下文焦点方面提高了答案质量，并降低了幻觉风险。

Conclusion: RegGuard是一款可审计、可追溯的AI系统，能够高效应对不断变化的文档源，适用于任何有严格合规要求的领域。

Abstract: The increasing frequency and complexity of regulatory updates present a significant burden for multinational pharmaceutical companies. Compliance teams must interpret evolving rules across jurisdictions, formats, and agencies, often manually, at high cost and risk of error. We introduce RegGuard, an industrial-scale AI assistant designed to automate the interpretation of heterogeneous regulatory texts and align them with internal corporate policies. The system ingests heterogeneous document sources through a secure pipeline and enhances retrieval and generation quality with two novel components: HiSACC (Hierarchical Semantic Aggregation for Contextual Chunking) semantically segments long documents into coherent units while maintaining consistency across non-contiguous sections. ReLACE (Regulatory Listwise Adaptive Cross-Encoder for Reranking), a domain-adapted cross-encoder built on an open-source model, jointly models user queries and retrieved candidates to improve ranking relevance. Evaluations in enterprise settings demonstrate that RegGuard improves answer quality specifically in terms of relevance, groundedness, and contextual focus, while significantly mitigating hallucination risk. The system architecture is built for auditability and traceability, featuring provenance tracking, access control, and incremental indexing, making it highly responsive to evolving document sources and relevant for any domain with stringent compliance demands.

</details>


### [30] [Aligning Medical Conversational AI through Online Reinforcement Learning with Information-Theoretic Rewards](https://arxiv.org/abs/2601.17828)
*Tanvi Verma,Yang Zhou,Rick Siow Mong Goh,Yong Liu*

Main category: cs.AI

TL;DR: 本文提出了一种名为信息增益微调（IGFT）的新方法，用于训练医疗对话AI，使其无需预先收集的人类对话即可进行有效的患者访谈并生成完整的现病史（HPI）。IGFT结合了在线组相对策略优化（GRPO）和信息论奖励，使模型能够从与模拟患者的自生成对话中学习。IGFT通过信息增益奖励函数来跟踪对话中揭示的临床实体，并通过GPT-4o-mini的质量评估来计算问题奖励。实验表明，IGFT微调的模型在Avey和MIMIC数据集上均优于基线模型，包括OpenAI模型和HuatuoGPT等。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗对话AI训练方法依赖于昂贵的专家标注对话或静态数据集，限制了其学习有效提问策略的能力。研究者希望开发一种无需预先收集人类对话即可训练AI进行有效患者访谈并生成全面HPI的方法。

Method: 本文提出信息增益微调（IGFT）方法，结合在线组相对策略优化（GRPO）和信息论奖励。模型通过与模拟患者进行自生成对话来学习。信息增益奖励函数衡量问题在揭示临床实体（如症状、时间模式、病史）方面的效果。问题奖励是基于其预期信息增益与GPT-4o-mini在临床相关性、患者参与度和特异性等方面的质量评估的结合。使用LoRA对Llama-3.1-8B-Instruct和DeepSeek-R1-Distill-Qwen-7B模型进行微调。

Result: 经过IGFT微调的DeepSeek-R1-Distill-Qwen-7B模型在Avey数据集上达到0.408的F1分数（比基线提高10.9%），在MIMIC数据集上达到0.289的F1分数（提高12.9%）。Llama-3.1-8B-Instruct（IGFT）模型分别达到0.384和0.336。在MIMIC数据集上，两个模型都优于OpenAI的模型，并且优于HuatuoGPT和UltraMedical等专为单轮问答优化的医疗领域特定基线模型。

Conclusion: IGFT是一种有效的方法，可以训练医疗对话AI进行有效的患者访谈和生成全面的HPI，而无需依赖预先收集的人类对话。该方法通过结合信息增益奖励和GPT-4o-mini的质量评估，使模型能够学习到有效的提问策略，并在不同的HPI复杂性数据集上表现出良好的泛化能力。

Abstract: We present Information Gain Fine-Tuning (IGFT), a novel approach for training medical conversational AI to conduct effective patient interviews and generate comprehensive History of Present Illness (HPI) without requiring pre-collected human conversations. IGFT combines online Group Relative Policy Optimization (GRPO) with information-theoretic rewards, enabling models to learn from self-generated conversations with simulated patients. Unlike existing approaches that rely on expensive expert-annotated conversations or static datasets, our online RL framework allows models to discover effective questioning strategies through exploration. Our key innovation is an information gain reward function that tracks which clinical entities such as symptoms, temporal patterns, and medical history, are revealed during conversation. Each question's reward is computed based on its expected information gain combined with GPT-4o-mini quality assessments across dimensions including clinical relevance, patient engagement, and specificity. This hybrid approach ensures models learn to ask targeted, clinically appropriate questions that efficiently gather diagnostic information. We fine-tune two models using LoRA: Llama-3.1-8B-Instruct and DeepSeek-R1-Distill-Qwen-7B (a reasoning-optimized model). Training exclusively on Avey data containing concise HPIs, we evaluate generalization to MIMIC data with longer, more elaborate HPIs. DeepSeek-R1-Distill-Qwen-7B (IGFT) achieves F1 scores of 0.408 on Avey (10.9% improvement over base) and 0.289 on MIMIC (12.9% improvement), while Llama-3.1-8B-Instruct (IGFT) reaches 0.384 and 0.336 respectively. Both models outperform OpenAI's model on MIMIC and surpass medical domain-specific baselines like HuatuoGPT and UltraMedical, which were optimized for single-turn medical QA rather than multi-turn conversations.

</details>


### [31] [When Personalization Legitimizes Risks: Uncovering Safety Vulnerabilities in Personalized Dialogue Agents](https://arxiv.org/abs/2601.17887)
*Jiahe Guo,Xiangran Guo,Yulin Hu,Zimo Long,Xingyu Sui,Xuda Zhi,Yongbo Huang,Hao He,Weixiang Zhao,Yanyan Zhao,Bing Qin*

Main category: cs.AI

TL;DR: 研究人员发现，个性化LLM代理中的“意图合法化”是一种新的安全漏洞，良性个人记忆会错误地使有害请求合法化。他们提出了PS-Bench基准来衡量这种现象，并发现个性化显著提高了攻击成功率。他们还提出了一种检测-反思方法来减轻这种影响，强调了在长期个人情境下评估安全性的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有研究在开发个性化LLM代理时，主要关注其效用和用户体验，而忽略了长期记忆对安全性的影响。研究者注意到，良性个人记忆可能导致模型误判有害请求的意图，并使其合法化，这是一种之前未被充分研究的安全问题。

Method: 研究者引入了一个名为PS-Bench的新基准，用于识别和量化个性化交互中的意图合法化现象。他们通过在多种记忆增强代理框架和基础LLM上进行实验来评估个性化对攻击成功率的影响。此外，他们还通过分析内部表示空间来提供意图合法化的机制证据，并提出了一种轻量级的检测-反思方法来降低安全风险。

Result: 在PS-Bench基准上的实验显示，与无状态基线相比，个性化使得代理的攻击成功率增加了15.8%-243.7%。研究者还提供了内部表示空间中意图合法化的机制证据。他们提出的检测-反思方法能有效减少安全性的下降。

Conclusion: 这项工作首次系统性地探讨和评估了意图合法化作为一种安全失败模式，它自然地源于良性的、真实世界的个性化。研究强调了在长期个人背景下评估LLM代理安全性的重要性，并为解决此类问题提供了一种有效方法。

Abstract: Long-term memory enables large language model (LLM) agents to support personalized and sustained interactions. However, most work on personalized agents prioritizes utility and user experience, treating memory as a neutral component and largely overlooking its safety implications. In this paper, we reveal intent legitimation, a previously underexplored safety failure in personalized agents, where benign personal memories bias intent inference and cause models to legitimize inherently harmful queries. To study this phenomenon, we introduce PS-Bench, a benchmark designed to identify and quantify intent legitimation in personalized interactions. Across multiple memory-augmented agent frameworks and base LLMs, personalization increases attack success rates by 15.8%-243.7% relative to stateless baselines. We further provide mechanistic evidence for intent legitimation from internal representations space, and propose a lightweight detection-reflection method that effectively reduces safety degradation. Overall, our work provides the first systematic exploration and evaluation of intent legitimation as a safety failure mode that naturally arises from benign, real-world personalization, highlighting the importance of assessing safety under long-term personal context. WARNING: This paper may contain harmful content.

</details>


### [32] [UniCog: Uncovering Cognitive Abilities of LLMs through Latent Mind Space Analysis](https://arxiv.org/abs/2601.17897)
*Jiayu Liu,Yinhe Long,Zhenya Huang,Enhong Chen*

Main category: cs.AI

TL;DR: 本研究提出了 UniCog 框架，通过潜在心智空间分析大型语言模型（LLM）的认知过程，发现 LLM 认知存在共享核心和能力特异性签名，并将推理失败与潜在激活异常联系起来，并利用该框架提升了 LLM 的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有解释 LLM 推理过程中认知能力参与度的方法存在局限性，而研究 LLM 的认知过程与其人类存在根本差异，因此需要新的方法来理解 LLM 的认知。

Method: 提出 UniCog 统一框架，将 LLM 的激活表示为潜在变量模型，编码成稀疏、解耦的潜在维度，形成潜在心智空间。通过对六种先进 LLM 进行分析，揭示其认知结构和推理失败的模式。

Result: 发现了 LLM 认知遵循帕累托法则，存在一个共享的推理核心和能力特异性签名。推理失败通常表现为潜在激活的异常强度。提出的基于潜在信息的候选词选择策略，将推理性能提升了高达 7.5%。

Conclusion: UniCog 提供了一个认知基础的 LLM 分析新范式，能够揭示 LLM 推理的动态过程，并为提升 LLM 的推理能力提供了新的思路和方法。

Abstract: A growing body of research suggests that the cognitive processes of large language models (LLMs) differ fundamentally from those of humans. However, existing interpretability methods remain limited in explaining how cognitive abilities are engaged during LLM reasoning. In this paper, we propose UniCog, a unified framework that analyzes LLM cognition via a latent mind space. Formulated as a latent variable model, UniCog encodes diverse abilities from dense model activations into sparse, disentangled latent dimensions. Through extensive analysis on six advanced LLMs, including DeepSeek-V3.2 and GPT-4o, we reveal a Pareto principle of LLM cognition, where a shared reasoning core is complemented by ability-specific signatures. Furthermore, we discover that reasoning failures often manifest as anomalous intensity in latent activations. These findings opens a new paradigm in LLM analysis, providing a cognition grounded view of reasoning dynamics. Finally, leveraging these insights, we introduce a latent-informed candidate prioritization strategy, which improves reasoning performance by up to 7.5% across challenging benchmarks. Our code is available at https://github.com/milksalute/unicog.

</details>


### [33] [Think Locally, Explain Globally: Graph-Guided LLM Investigations via Local Reasoning and Belief Propagation](https://arxiv.org/abs/2601.17915)
*Saurabh Jha,Rohan Arora,Bhavya,Noah Zheutlin,Paulina Toro Isaza,Laura Shwartz,Yu Deng,Daby Sow,Ruchi Mahindru,Ruchir Puri*

Main category: cs.AI

TL;DR: 本文提出了一种名为 EoG (Explanations over Graphs) 的新框架，通过将 LLM 代理的调查过程构建为依赖图上的溯因推理，解决了 LLM 代理在处理大规模、异构数据时因上下文窗口限制和探索顺序敏感性而导致的局限性，显著提高了诊断任务的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 代理在处理需要迭代挖掘海量、异构操作数据来构建解释的开放式调查时表现不佳，因为它们受限于上下文窗口大小，容易丢失关键证据，并且 ReAct 风格的代理对探索顺序敏感且具有不确定性。

Method: 将调查过程表述为在依赖图上的溯因推理，并提出了 EoG 框架。该框架将 LLM 的局部证据挖掘和标注（因果与症状）与确定性控制器管理的遍历、状态和信念传播相结合，以计算最小的解释前沿。

Result: 在 ITBench 诊断任务上，EoG 相比 ReAct 基线提高了准确性和运行一致性，平均 Majority-at-k 实体 F1 分数提高了 7 倍。

Conclusion: EoG 框架通过将 LLM 代理的调查能力与确定性推理相结合，有效地解决了 LLM 在处理复杂、大规模数据调查时的局限性，提高了诊断的可靠性和效率。

Abstract: LLM agents excel when environments are mostly static and the needed information fits in a model's context window, but they often fail in open-ended investigations where explanations must be constructed by iteratively mining evidence from massive, heterogeneous operational data. These investigations exhibit hidden dependency structure: entities interact, signals co-vary, and the importance of a fact may only become clear after other evidence is discovered. Because the context window is bounded, agents must summarize intermediate findings before their significance is known, increasing the risk of discarding key evidence. ReAct-style agents are especially brittle in this regime. Their retrieve-summarize-reason loop makes conclusions sensitive to exploration order and introduces run-to-run non-determinism, producing a reliability gap where Pass-at-k may be high but Majority-at-k remains low. Simply sampling more rollouts or generating longer reasoning traces does not reliably stabilize results, since hypotheses cannot be autonomously checked as new evidence arrives and there is no explicit mechanism for belief bookkeeping and revision. In addition, ReAct entangles semantic reasoning with controller duties such as tool orchestration and state tracking, so execution errors and plan drift degrade reasoning while consuming scarce context.
  We address these issues by formulating investigation as abductive reasoning over a dependency graph and proposing EoG (Explanations over Graphs), a disaggregated framework in which an LLM performs bounded local evidence mining and labeling (cause vs symptom) while a deterministic controller manages traversal, state, and belief propagation to compute a minimal explanatory frontier. On a representative ITBench diagnostics task, EoG improves both accuracy and run-to-run consistency over ReAct baselines, including a 7x average gain in Majority-at-k entity F1.

</details>


### [34] [Learning Transferable Skills in Action RPGs via Directed Skill Graphs and Selective Adaptation](https://arxiv.org/abs/2601.17923)
*Ali Najar*

Main category: cs.AI

TL;DR: 研究人员开发了一种能够持续学习的智能体，用于控制《黑暗之魂3》中的战斗。该智能体将战斗分解为可重用的技能图谱，并通过分层课程进行训练，实现了高效的样本学习和选择性微调。结果表明，这种方法能快速恢复智能体的性能，并为复杂实时环境中的持续学习智能体提供了可行途径。


<details>
  <summary>Details</summary>
Motivation: 开发能够在没有从头开始重新训练或覆盖之前学到的行为的情况下，随时间扩展其能力的老年智能体。

Method: 将战斗表示为定向技能图谱，并在分层课程中训练其组件。将控制分解为五个可重用的技能：摄像机控制、目标锁定、移动、闪避和治疗-攻击决策策略。在环境从Phase 1切换到Phase 2时，仅调整部分技能，而上游技能保持可转移。

Result: 在有限的交互预算下，仅对两个技能进行针对性微调可快速恢复性能。

Conclusion: 技能图谱课程以及选择性微调为在复杂实时环境中开发不断发展的、持续学习的智能体提供了一条实用的途径。

Abstract: Lifelong agents should expand their competence over time without retraining from scratch or overwriting previously learned behaviors. We investigate this in a challenging real-time control setting (Dark Souls III) by representing combat as a directed skill graph and training its components in a hierarchical curriculum. The resulting agent decomposes control into five reusable skills: camera control, target lock-on, movement, dodging, and a heal-attack decision policy, each optimized for a narrow responsibility. This factorization improves sample efficiency by reducing the burden on any single policy and supports selective post-training: when the environment shifts from Phase 1 to Phase 2, only a subset of skills must be adapted, while upstream skills remain transferable. Empirically, we find that targeted fine-tuning of just two skills rapidly recovers performance under a limited interaction budget, suggesting that skill-graph curricula together with selective fine-tuning offer a practical pathway toward evolving, continually learning agents in complex real-time environments.

</details>


### [35] [Agentic AI for Self-Driving Laboratories in Soft Matter: Taxonomy, Benchmarks,and Open Challenges](https://arxiv.org/abs/2601.17920)
*Xuanzhou Chen,Audrey Wang,Stanley Yin,Hanyang Jiang,Dong Zhang*

Main category: cs.AI

TL;DR: 本综述探讨了自动驾驶实验室（SDL）在软物质科学中的应用，重点关注其作为智能体（AI）代理的严苛测试环境。文章将SDL的自主性表述为智能体-环境交互问题，并回顾了支持闭环实验的关键AI方法，如贝叶斯优化、主动学习、规划和强化学习。此外，文章还提出了一个基于能力驱动的分类体系，并为未来研究指明了方向，包括多模态表示、不确定性校准、安全探索以及共享基准设施。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶实验室（SDL）为智能体AI提供了一个严苛的测试平台，因为它们涉及到昂贵的实验操作、有噪声且延迟的反馈、严格的可行性和安全约束以及非平稳性。本研究旨在从AI角度出发，分析和总结在真实实验室环境中实现SDL自主性的方法和挑战。

Method: 文章将SDL的自主性框架化为智能体-环境交互问题，并将其与既有的AI原理联系起来。回顾了支持闭环实验的主要方法，包括：1. 贝叶斯优化和主动学习（用于样本效率高的实验选择）；2. 规划和强化学习（用于长周期协议优化）；3. 工具使用智能体（用于协调异构仪器和软件）。文章强调了可验证和可追溯性策略的重要性，并提出了一个能力驱动的分类体系，根据决策范围、不确定性建模、动作参数化、约束处理、故障恢复和人类参与来组织系统。为了便于比较，还合成了基准任务模板和评估指标。

Result: 本综述提供了对SDL中AI应用的全面概览，包括现有方法的分类以及一套用于比较不同SDL系统的基准测试方法。文章突出了可验证和可追溯性策略在调试、可重复性和安全操作中的作用。

Conclusion: SDL为AI研究提供了独特的挑战和机遇。未来的研究应关注多模态表示、校准不确定性、安全探索以及建立共享基准基础设施，以进一步推动SDL在科学发现中的应用。

Abstract: Self-driving laboratories (SDLs) close the loop between experiment design, automated execution, and data-driven decision making, and they provide a demanding testbed for agentic AI under expensive actions, noisy and delayed feedback, strict feasibility and safety constraints, and non-stationarity. This survey uses soft matter as a representative setting but focuses on the AI questions that arise in real laboratories. We frame SDL autonomy as an agent environment interaction problem with explicit observations, actions, costs, and constraints, and we use this formulation to connect common SDL pipelines to established AI principles. We review the main method families that enable closed loop experimentation, including Bayesian optimization and active learning for sample efficient experiment selection, planning and reinforcement learning for long horizon protocol optimization, and tool using agents that orchestrate heterogeneous instruments and software. We emphasize verifiable and provenance aware policies that support debugging, reproducibility, and safe operation. We then propose a capability driven taxonomy that organizes systems by decision horizon, uncertainty modeling, action parameterization, constraint handling, failure recovery, and human involvement. To enable meaningful comparison, we synthesize benchmark task templates and evaluation metrics that prioritize cost aware performance, robustness to drift, constraint violation behavior, and reproducibility. Finally, we distill lessons from deployed SDLs and outline open challenges in multi-modal representation, calibrated uncertainty, safe exploration, and shared benchmark infrastructure.

</details>


### [36] [LLM-Based SQL Generation: Prompting, Self-Refinement, and Adaptive Weighted Majority Voting](https://arxiv.org/abs/2601.17942)
*Yu-Jie Yang,Hung-Fu Chang,Po-An Chen*

Main category: cs.AI

TL;DR: 本文提出了两种 Text-to-SQL 模型：SSEV 和 ReCAPAgent-SQL。SSEV 使用无监督学习和集成投票来生成 SQL，在 Spider 和 BIRD 数据集上取得了有竞争力的性能。ReCAPAgent-SQL 进一步通过多代理协作来处理更复杂的企业级数据库，并在 Spider 2.0-Lite 上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 自然语言生成 SQL（Text-to-SQL）技术能够降低数据分析的门槛，但目前仍面临查询歧义、模式链接复杂、SQL 方言泛化能力有限以及领域知识不足等挑战。同时，处理企业级数据库的复杂性也需要更强大的 Text-to-SQL 解决方案。

Method: SSEV 提出了一个基于 PET-SQL 的单代理自优化与集成投票（SSEV）管道，该管道不依赖于真实数据，集成了自优化与加权多数投票（WMV）及其随机变体（RWMA）。ReCAPAgent-SQL 则是一个基于代理的 SQL 框架，集成了多个专业代理，用于规划、外部知识检索、批判、动作生成、自优化、模式链接和结果验证，以实现 SQL 预测的迭代优化。

Result: SSEV 在 Spider 1.0-Dev/Test 上分别达到了 85.5% 和 86.4% 的执行准确率，在 BIRD-Dev 上达到了 66.3%。ReCAPAgent-SQL 在 Spider 2.0-Lite 的前 100 个查询上取得了 31% 的 WMA 执行准确率，显著提高了处理真实企业场景的能力。

Conclusion: 本文提出的 SSEV 和 ReCAPAgent-SQL 框架有效地解决了 Text-to-SQL 中的关键挑战，提高了 SQL 生成的准确性和对复杂数据库的处理能力，为实际应用中可扩展的 Text-to-SQL 系统的部署提供了支持，从而降低成本、提高效率并改善数据驱动的决策。

Abstract: Text-to-SQL has emerged as a prominent research area, particularly with the rapid advancement of large language models (LLMs). By enabling users to query databases through natural language rather than SQL, this technology significantly lowers the barrier to data analysis. However, generating accurate SQL from natural language remains challenging due to ambiguity in user queries, the complexity of schema linking, limited generalization across SQL dialects, and the need for domain-specific understanding. In this study, we propose a Single-Agent Self-Refinement with Ensemble Voting (SSEV) pipeline built on PET-SQL that operates without ground-truth data, integrating self-refinement with Weighted Majority Voting (WMV) and its randomized variant (RWMA). Experimental results show that the SSEV achieves competitive performance across multiple benchmarks, attaining execution accuracies of 85.5% on Spider 1.0-Dev, 86.4% on Spider 1.0-Test, and 66.3% on BIRD-Dev. Building on insights from the SSEV pipeline, we further propose ReCAPAgent-SQL (Refinement-Critique-Act-Plan agent-based SQL framework) to address the growing complexity of enterprise databases and real-world Text-to-SQL tasks. The framework integrates multiple specialized agents for planning, external knowledge retrieval, critique, action generation, self-refinement, schema linking, and result validation, enabling iterative refinement of SQL predictions through agent collaboration. ReCAPAgent-SQL's WMA results achieve 31% execution accuracy on the first 100 queries of Spider 2.0-Lite, demonstrating significant improvements in handling real-world enterprise scenarios. Overall, our work facilitates the deployment of scalable Text-to-SQL systems in practical settings, supporting better data-driven decision-making at lower cost and with greater efficiency.

</details>


### [37] [Sentipolis: Emotion-Aware Agents for Social Simulations](https://arxiv.org/abs/2601.18027)
*Chiyuan Fu,Lyuhao Chen,Yunze Xiao,Weihao Xuan,Carlos Busso,Mona Diab*

Main category: cs.AI

TL;DR: Sentipolis 是一个用于开发具有持续情感状态的 LLM 代理的框架，通过整合 PAD 模型、双速情感动力学和情感-记忆耦合，改善了情感接地行为、通信和情感连续性，并为研究累积社会动态提供了工具。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 代理在社会模拟中存在情感短暂、情感失忆和长时程连续性弱的问题。

Method: 提出 Sentipolis 框架，该框架整合了连续的 Pleasure-Arousal-Dominance (PAD) 情感表示、双速情感动力学以及情感-记忆耦合。

Result: Sentipolis 在数千次交互中，提高了情感接地行为、通信和情感连续性。效果因模型而异，高容量模型可信度提升，小模型可能下降。情感感知可能导致社会规范依从性略微下降。网络诊断显示关系结构相互依存、适度聚集且时间稳定。

Conclusion: Sentipolis 框架能够有效改善 LLM 代理在社会模拟中的情感状态和行为连续性，为研究联盟形成和关系演变等累积社会动态提供了新的途径，并揭示了情感驱动行为与社会规范遵从之间的类人张力。

Abstract: LLM agents are increasingly used for social simulation, yet emotion is often treated as a transient cue, causing emotional amnesia and weak long-horizon continuity. We present Sentipolis, a framework for emotionally stateful agents that integrates continuous Pleasure-Arousal-Dominance (PAD) representation, dual-speed emotion dynamics, and emotion--memory coupling. Across thousands of interactions over multiple base models and evaluators, Sentipolis improves emotionally grounded behavior, boosting communication, and emotional continuity. Gains are model-dependent: believability increases for higher-capacity models but can drop for smaller ones, and emotion-awareness can mildly reduce adherence to social norms, reflecting a human-like tension between emotion-driven behavior and rule compliance in social simulation. Network-level diagnostics show reciprocal, moderately clustered, and temporally stable relationship structures, supporting the study of cumulative social dynamics such as alliance formation and gradual relationship change.

</details>


### [38] [Expert Evaluation and the Limits of Human Feedback in Mental Health AI Safety Testing](https://arxiv.org/abs/2601.18061)
*Kiana Jafari,Paul Ulrich Nikolaus Rust,Duncan Eddy,Robbie Fraser,Nina Vasan,Darja Djordjevic,Akanksha Dadlani,Max Lamparth,Eugenia Kim,Mykel Kochenderfer*

Main category: cs.AI

TL;DR: 在心理健康领域，即使是认证精神科医生在评估 LLM 生成的回答时，互评者一致性也很差，这表明聚合标签可能无法准确反映专家意见。研究者建议采用能够保留和学习专家分歧的对齐方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是检验“从人类反馈中学习”（LHF）在心理健康领域是否成立，该领域对专家共识有高安全要求。

Method: 三位认证精神科医生使用校准后的评分标准独立评估 LLM 生成的回答，并进行了定性访谈。

Result: 互评者一致性（ICC）极低（0.087-0.295），低于可接受阈值。在自杀和自残等安全关键项目上的分歧最大，并且是系统性的。访谈显示，分歧源于不同的临床框架（安全优先、以参与为中心、文化导向），而非测量误差。

Conclusion: 专家在安全关键 AI 评估中存在分歧是一种社会技术现象，其原因在于专业经验引入了原则性的分歧。聚合标签会抹杀专业的临床理念。建议采用能保留和学习专家分歧的对齐方法，而非基于共识的聚合方法。

Abstract: Learning from human feedback~(LHF) assumes that expert judgments, appropriately aggregated, yield valid ground truth for training and evaluating AI systems. We tested this assumption in mental health, where high safety stakes make expert consensus essential. Three certified psychiatrists independently evaluated LLM-generated responses using a calibrated rubric. Despite similar training and shared instructions, inter-rater reliability was consistently poor ($ICC$ $0.087$--$0.295$), falling below thresholds considered acceptable for consequential assessment. Disagreement was highest on the most safety-critical items. Suicide and self-harm responses produced greater divergence than any other category, and was systematic rather than random. One factor yielded negative reliability (Krippendorff's $α= -0.203$), indicating structured disagreement worse than chance. Qualitative interviews revealed that disagreement reflects coherent but incompatible individual clinical frameworks, safety-first, engagement-centered, and culturally-informed orientations, rather than measurement error. By demonstrating that experts rely on holistic risk heuristics rather than granular factor discrimination, these findings suggest that aggregated labels function as arithmetic compromises that effectively erase grounded professional philosophies. Our results characterize expert disagreement in safety-critical AI as a sociotechnical phenomenon where professional experience introduces sophisticated layers of principled divergence. We discuss implications for reward modeling, safety classification, and evaluation benchmarks, recommending that practitioners shift from consensus-based aggregation to alignment methods that preserve and learn from expert disagreement.

</details>


### [39] [EvolVE: Evolutionary Search for LLM-based Verilog Generation and Optimization](https://arxiv.org/abs/2601.18067)
*Wei-Po Hsin,Ren-Hao Deng,Yao-Ting Hsieh,En-Ming Huang,Shih-Hao Hung*

Main category: cs.AI

TL;DR: 提出EvolVE框架，结合MCTS和IGR策略，并利用STG加速进化过程，以应对LLM在Verilog设计中的挑战。引入IC-RTL基准测试集，并在功能正确性和PPA优化方面取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: Verilog设计周期劳动密集且需要专业知识。现有LLM在处理硬件系统的形式逻辑和并发性方面存在不足。需要一种自动化方法来克服这些限制。

Method: 提出EvolVE框架，该框架分析多种进化策略，包括蒙特卡洛树搜索（MCTS）和基于思想的改进（IGR）。利用结构化测试平台生成（STG）加速进化过程。引入IC-RTL基准测试集，该测试集基于国家集成电路竞赛中的工业规模问题。

Result: EvolVE在VerilogEval v2上达到98.1%，在RTLLM v2上达到92%。在IC-RTL基准测试集上，比竞赛参与者编写的参考实现，在霍夫曼编码上PPA产品降低高达66%，在所有问题上的几何平均值降低17%。

Conclusion: EvolVE是处理Verilog设计任务的SOTA框架，MCTS在功能正确性方面表现优异，IGR在优化方面表现优异。EvolVE能够有效解决工业规模的硬件设计问题，显著提高PPA。

Abstract: Verilog's design cycle is inherently labor-intensive and necessitates extensive domain expertise. Although Large Language Models (LLMs) offer a promising pathway toward automation, their limited training data and intrinsic sequential reasoning fail to capture the strict formal logic and concurrency inherent in hardware systems. To overcome these barriers, we present EvolVE, the first framework to analyze multiple evolution strategies on chip design tasks, revealing that Monte Carlo Tree Search (MCTS) excels at maximizing functional correctness, while Idea-Guided Refinement (IGR) proves superior for optimization. We further leverage Structured Testbench Generation (STG) to accelerate the evolutionary process. To address the lack of complex optimization benchmarks, we introduce IC-RTL, targeting industry-scale problems derived from the National Integrated Circuit Contest. Evaluations establish EvolVE as the new state-of-the-art, achieving 98.1% on VerilogEval v2 and 92% on RTLLM v2. Furthermore, on the industry-scale IC-RTL suite, our framework surpasses reference implementations authored by contest participants, reducing the Power, Performance, Area (PPA) product by up to 66% in Huffman Coding and 17% in the geometric mean across all problems. The source code of the IC-RTL benchmark is available at https://github.com/weiber2002/ICRTL.

</details>


### [40] [Beyond Text-to-SQL: Can LLMs Really Debug Enterprise ETL SQL?](https://arxiv.org/abs/2601.18119)
*Jing Ye,Yiwen Duan,Yonghong Yu,Victor Ma,Yang Gao,Xing Chen*

Main category: cs.AI

TL;DR: 本文提出了OurBench，一个用于评估企业级SQL推理和调试能力的新基准，该基准通过自动注入真实SQL错误来生成，并采用无需执行的评估框架。现有的大型语言模型（LLM）在处理该基准时表现出显著的性能差距。


<details>
  <summary>Details</summary>
Motivation: 企业级SQL代码生成和调试的挑战性，即使是对于经验丰富的开发人员和先进的文本到SQL大型语言模型。现有评估方法可能不够高效或无法充分反映企业级场景的需求。

Method: 1. 自动化的SQL代码bug注入流程，通过逆向工程系统性地添加真实且多样化的SQL错误，以生成大规模基准。 2. 提出一个无需执行的评估框架，用于快速、准确且资源高效地评估SQL推理和调试能力。 3. 构建包含语法错误（OurBenchSyn）和语义错误（OurBenchSem）的SQL查询数据集，这些查询复杂且规模大。 4. 评估近30个大型语言模型在OurBench上的性能。

Result: 1. OurBench基准包含469个OurBenchSyn查询和516个OurBenchSem查询，平均查询长度超过140行，抽象语法树深且宽。 2. 现有的大型语言模型在OurBench上的表现普遍不佳，最佳模型Claude-4-Sonnet在OurBenchSyn上的准确率仅为36.46%，在OurBenchSem上为32.17%，大多数模型准确率低于20%。 3. 探索了四种解决方案策略，并指出了企业SQL调试中LLM面临的关键挑战和未来研究方向。

Conclusion: 企业级SQL的推理和调试对当前的大型语言模型来说仍然是一个巨大的挑战。OurBench提供了一个更贴合实际需求的评估平台，揭示了LLM在该领域的性能差距，并为未来的研究指明了方向。

Abstract: SQL is central to enterprise data engineering, yet generating fully correct SQL code in a single attempt remains difficult, even for experienced developers and advanced text-to-SQL LLMs, often requiring multiple debugging iterations. We introduce OurBench, the first benchmark for enterprise-level SQL reasoning and debugging. Our benchmark is built on two key innovations: (1) an automated construction workflow that uses reverse engineering to systematically inject realistic bugs into large-scale SQL code, enabling scalable and diverse benchmark generation; and (2) an execution-free evaluation framework tailored to enterprise settings, providing fast, accurate, and resource-efficient assessment.
  OurBench comprises 469 OurBenchSyn queries featuring syntax errors with explicit error messages, and 516 OurBenchSem queries targeting semantic errors in which the code fails to meet user intent. The queries are highly complex, averaging over 140 lines and featuring deep and wide abstract syntax trees.
  Evaluation of nearly 30 LLMs reveals a substantial performance gap: the best-performing model, Claude-4-Sonnet, achieves only 36.46 percent accuracy on OurBenchSyn and 32.17 percent on OurBenchSem, while most models score below 20 percent. We further explore four solution strategies, identify key challenges, and outline promising directions for enterprise SQL debugging with LLMs.

</details>


### [41] [Deadline-Aware, Energy-Efficient Control of Domestic Immersion Hot Water Heaters](https://arxiv.org/abs/2601.18123)
*Muhammad Ibrahim Khan,Bivin Pradeep,James Brusey*

Main category: cs.AI

TL;DR: 该研究提出了一种考虑截止时间的家用水浸式热水器控制方法，通过强化学习（PPO）实现了比传统 bang-bang 控制和 MCTS 规划器更优的能效，最多可节省 69% 的能源。


<details>
  <summary>Details</summary>
Motivation: 传统的家用水浸式热水器在冬季倾向于持续加热，而非考虑环境损耗和可预测的用热时段，导致能源效率低下。

Method: 构建了一个包含一阶热损耗和离散开关动作（0W/6000W，每120秒）的浸入式热水器 Gymnasium 环境。研究了三种控制方法：时间最优的 bang-bang 基线、零样本蒙特卡洛树搜索（MCTS）规划器，以及近端策略优化（PPO）策略。

Result: 在不同的初始温度、截止时间和目标温度范围内，PPO 策略在 60 步（2小时）的预测范围下，总能耗为 3.23 kWh，显著低于 bang-bang 控制（4.37-10.45 kWh）和 MCTS（4.18-6.46 kWh）。PPO 在 30 步和 90 步的预测范围内分别实现了 26% 和 69% 的能源节约。在具体场景下，PPO 比 bang-bang 控制节省 54% 的能源，比 MCTS 节省 33% 的能源。

Conclusion: 基于学习的截止时间感知控制方法（如 PPO）能在相同物理模型下有效降低热水器的能耗。规划器（MCTS）在无需训练的情况下能提供部分节能效果，而训练好的学习策略（PPO）在推理时几乎没有额外成本。

Abstract: Typical domestic immersion water heater systems are often operated continuously during winter, heating quickly rather than efficiently and ignoring predictable demand windows and ambient losses. We study deadline-aware control, where the aim is to reach a target temperature at a specified time while minimising energy consumption. We introduce an efficient Gymnasium environment that models an immersion hot water heater with first-order thermal losses and discrete on and off actions of 0 W and 6000 W applied every 120 seconds. Methods include a time-optimal bang-bang baseline, a zero-shot Monte Carlo Tree Search planner, and a Proximal Policy Optimisation policy. We report total energy consumption in watt-hours under identical physical dynamics. Across sweeps of initial temperature from 10 to 30 degrees Celsius, deadline from 30 to 90 steps, and target temperature from 40 to 80 degrees Celsius, PPO achieves the most energy-efficient performance at a 60-step horizon of 2 hours, using 3.23 kilowatt-hours, compared to 4.37 to 10.45 kilowatt-hours for bang-bang control and 4.18 to 6.46 kilowatt-hours for MCTS. This corresponds to energy savings of 26 percent at 30 steps and 69 percent at 90 steps. In a representative trajectory with a 50 kg water mass, 20 degrees Celsius ambient temperature, and a 60 degrees Celsius target, PPO consumes 54 percent less energy than bang-bang control and 33 percent less than MCTS. These results show that learned deadline-aware control reduces energy consumption under identical physical assumptions, while planners provide partial savings without training and learned policies offer near-zero inference cost once trained.

</details>


### [42] [RouteMoA: Dynamic Routing without Pre-Inference Boosts Efficient Mixture-of-Agents](https://arxiv.org/abs/2601.18130)
*Jize Wang,Han Wu,Zhiyuan You,Yiming Song,Yijun Wang,Zifei Shan,Yining Li,Songyang Zhang,Xinyi Le,Cailian Chen,Xinping Guan,Dacheng Tao*

Main category: cs.AI

TL;DR: RouteMoA 是一种高效的智能体混合框架，通过动态路由和轻量级评分/评估机制，在不进行完整推理的情况下，降低了成本和延迟，同时提高了 LLM 的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 Mixture-of-Agents (MoA) 方法虽然能提升 LLM 性能，但其密集连接带来了高昂的成本和延迟。现有的 LLM 裁判方法未能有效降低成本，因为它们仍需要所有模型进行推理，并且缺乏模型选择标准，在大规模模型池中尤其低效。

Method: RouteMoA 提出了一种动态路由机制。首先，一个轻量级评分器根据查询预测粗粒度性能，筛选出高潜力模型子集，避免了完整推理。然后，一系列裁判模型通过轻量级的自我和交叉评估（基于现有模型输出）对分数进行后验修正，无需额外推理。最后，一个模型排序机制综合考虑性能、成本和延迟来选择模型。

Result: RouteMoA 在不同任务和模型池规模下均优于 MoA。在大型模型池中，成本降低了 89.8%，延迟降低了 63.6%。

Conclusion: RouteMoA 是一种更高效的智能体混合框架，通过动态路由和精简的评估流程，成功地在降低成本和延迟的同时，提升了 LLM 的性能，尤其在大规模模型池场景下表现出色。

Abstract: Mixture-of-Agents (MoA) improves LLM performance through layered collaboration, but its dense topology raises costs and latency. Existing methods employ LLM judges to filter responses, yet still require all models to perform inference before judging, failing to cut costs effectively. They also lack model selection criteria and struggle with large model pools, where full inference is costly and can exceed context limits. To address this, we propose RouteMoA, an efficient mixture-of-agents framework with dynamic routing. It employs a lightweight scorer to perform initial screening by predicting coarse-grained performance from the query, narrowing candidates to a high-potential subset without inference. A mixture of judges then refines these scores through lightweight self- and cross-assessment based on existing model outputs, providing posterior correction without additional inference. Finally, a model ranking mechanism selects models by balancing performance, cost, and latency. RouteMoA outperforms MoA across varying tasks and model pool sizes, reducing cost by 89.8% and latency by 63.6% in the large-scale model pool.

</details>


### [43] [RareAlert: Aligning heterogeneous large language model reasoning for early rare disease risk screening](https://arxiv.org/abs/2601.18132)
*Xi Chen,Hongru Zhou,Huahui Yi,Shiyu Feng,Hanyu Zhou,Tiancheng He,Mingke You,Li Wang,Qiankun Li,Kun Wang,Weili Fu,Kang Li,Jian Li*

Main category: cs.AI

TL;DR: 研究提出了一种名为RareAlert的早期罕见病筛查系统，该系统利用常规就诊信息，通过集成和校准多个大型语言模型（LLMs）的推理，以高精度预测患者患罕见病的风险，从而解决罕见病诊断延迟的挑战。


<details>
  <summary>Details</summary>
Motivation: 医生在初次就诊时，由于信息有限且不确定性高，难以识别高风险罕见病患者，导致诊断延迟。现有的初级保健分诊流程不足以可靠地识别罕见病患者，因此需要进行普遍筛查。

Method: RareAlert系统整合了十个大型语言模型（LLMs）的推理，并使用机器学习进行校准和加权，最后将对齐的推理提炼成一个可本地部署的单一模型。研究还构建了一个包含158,666个病例的真实世界数据集RareBench，涵盖33个Orphanet疾病类别和7,000多种罕见病。

Result: 基于Qwen3-4B模型并结合校准推理信号训练的RareAlert，在独立测试集上达到了0.917的AUC，优于最佳机器学习模型和所有评估过的大型语言模型（包括GPT-5、DeepSeek-R1、Claude-3.7-Sonnet等）。

Conclusion: 罕见病识别可以被视为一个应用于普通患者群体的普遍不确定性解决过程。RareAlert通过整合校准的推理，能够实现准确、保护隐私且可扩展的罕见病风险筛查，适用于大规模本地部署，并证明了LLM在医学推理中的多样性及其在高度不确定临床任务中进行推理对齐的有效性。

Abstract: Missed and delayed diagnosis remains a major challenge in rare disease care. At the initial clinical encounters, physicians assess rare disease risk using only limited information under high uncertainty. When high-risk patients are not recognised at this stage, targeted diagnostic testing is often not initiated, resulting in missed diagnosis. Existing primary care triage processes are structurally insufficient to reliably identify patients with rare diseases at initial clinical presentation and universal screening is needed to reduce diagnostic delay. Here we present RareAlert, an early screening system which predict patient-level rare disease risk from routinely available primary-visit information. RareAlert integrates reasoning generated by ten LLMs, calibrates and weights these signals using machine learning, and distils the aligned reasoning into a single locally deployable model. To develop and evaluate RareAlert, we curated RareBench, a real-world dataset of 158,666 cases covering 33 Orphanet disease categories and more than 7,000 rare conditions, including both rare and non-rare presentations. The results showed that rare disease identification can be reconceptualised as a universal uncertainty resolution process applied to the general patient population. On an independent test set, RareAlert, a Qwen3-4B based model trained with calibrated reasoning signals, achieved an AUC of 0.917, outperforming the best machine learning ensemble and all evaluated LLMs, including GPT-5, DeepSeek-R1, Claude-3.7-Sonnet, o3-mini, Gemini-2.5-Pro, and Qwen3-235B. These findings demonstrate the diversity in LLM medical reasoning and the effectiveness of aligning such reasoning in highly uncertain clinical tasks. By incorporating calibrated reasoning into a single model, RareAlert enables accurate, privacy-preserving, and scalable rare disease risk screening suitable for large-scale local deployment.

</details>


### [44] [DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints](https://arxiv.org/abs/2601.18137)
*Yinger Zhang,Shutong Jiang,Renhao Li,Jianhong Tu,Yang Su,Lianghao Deng,Xudong Guo,Chenxu Lv,Junyang Lin*

Main category: cs.AI

TL;DR: 提出DeepPlanning基准，用于评估智能体在具有全局约束（如时间、预算）和主动信息收集的长期任务中的规划能力，并发现现有LLM在该基准上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有智能体评估基准侧重于局部步进式推理，未能充分体现真实世界中智能体所需的全局约束优化和主动信息收集能力。

Method: 引入DeepPlanning基准，包含多日旅行规划和多产品购物任务，要求智能体进行主动信息获取、局部约束推理和全局约束优化。

Result: 在DeepPlanning基准上，即使是最先进的LLM也难以应对这些任务，表明显式推理模式和并行工具使用对于提高效率和有效性至关重要。

Conclusion: DeepPlanning基准能够有效评估智能体在复杂长期规划任务中的能力，并指出了改进LLM长期规划能力的研究方向，同时开源了相关代码和数据。

Abstract: While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.

</details>


### [45] [GAIA: A Data Flywheel System for Training GUI Test-Time Scaling Critic Models](https://arxiv.org/abs/2601.18197)
*Shaokang Wang,Pei Fu,Ruoceng Zhang,Shaojie Zhang,Xiuwen Xi,Jiahui Yang,Bin Qin,Ying Huang,Zhenbo Luo,Jian Luan*

Main category: cs.AI

TL;DR: 本文提出了GAIA（GUI Action Critic's Data Flywheel System）框架，通过引入迭代式评论员模型来解决GUI代理操作不可逆的问题，从而提升代理的测试时性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（LVLMs）在GUI代理任务中存在操作不可逆的问题，即一次错误的行动可能导致灾难性的后果。因此，研究如何让模型具备迭代评论能力以提高其鲁棒性。

Method: 首先，使用基础代理产生的正负面行动示例训练一个直观评论员模型（ICM），该模型评估行动的即时正确性。然后，由评论员指导代理收集更精炼的正负面样本，用于训练第二轮评论员，形成一个自我改进的循环。

Result: 实验证明，所提出的ICM可以提升多种闭源和开源模型在测试时的性能，并且随着数据的不断循环利用，性能可以逐渐提高。

Conclusion: GAIA框架通过引入评论员模型，有效解决了GUI代理操作的不可逆性问题，并通过迭代改进显著提升了代理的测试时性能，该方法具有普适性并能逐步优化。

Abstract: While Large Vision-Language Models (LVLMs) have significantly advanced GUI agents' capabilities in parsing textual instructions, interpreting screen content, and executing tasks, a critical challenge persists: the irreversibility of agent operations, where a single erroneous action can trigger catastrophic deviations. To address this, we propose the GUI Action Critic's Data Flywheel System (GAIA), a training framework that enables the models to have iterative critic capabilities, which are used to improve the Test-Time Scaling (TTS) of basic GUI agents' performance. Specifically, we train an Intuitive Critic Model (ICM) using positive and negative action examples from a base agent first. This critic evaluates the immediate correctness of the agent's intended actions, thereby selecting operations with higher success probability. Then, the initial critic guides agent actions to collect refined positive/negative samples, initiating the self-improving cycle. The augmented data then trains a second-round critic with enhanced discernment capability. We conduct experiments on various datasets and demonstrate that the proposed ICM can improve the test-time performance of various closed-source and open-source models, and the performance can be gradually improved as the data is recycled. The code and dataset will be publicly released.

</details>


### [46] [SAGE: Steerable Agentic Data Generation for Deep Search with Execution Feedback](https://arxiv.org/abs/2601.18202)
*Fangyuan Xu,Rujun Han,Yanfei Chen,Zifeng Wang,I-Hung Hsu,Jun Yan,Vishy Tirumalashetty,Eunsol Choi,Tomas Pfister,Chen-Yu Lee*

Main category: cs.AI

TL;DR: 本研究提出了一种名为SAGE的自动化流水线，用于生成高质量、难度可控的深度搜索问答对，以解决深度搜索代理在处理复杂、多文档推理问题时的数据标注成本过高的问题。


<details>
  <summary>Details</summary>
Motivation: 收集用于深度搜索代理（能够跨多个文档进行推理以回答复杂问题）的人工标注数据成本过高，因为需要进行冗长且复杂的探索轨迹。因此，需要一种自动生成高质量、难度可控的问答对的方法。

Method: SAGE流水线包含两个组件：数据生成器，负责提出问答对；搜索代理，负责尝试解答生成的问题并为数据生成器提供执行反馈。这两个组件通过多轮交互来迭代优化问答对，直到达到目标难度级别。

Result: SAGE生成的问题需要多样化的推理策略，并且显著提高了生成数据的正确性和难度。使用SAGE生成的合成数据训练深度搜索代理，在流行的深度搜索基准测试上带来了高达23%的相对性能提升。此外，在SAGE数据上训练的代理在推理时无需进一步训练即可适应从固定语料库检索到Google搜索。

Conclusion: SAGE流水线能够自动生成高质量、难度可控的深度搜索问答对，有效解决了数据标注的瓶颈问题，并能显著提升深度搜索代理的性能，使其具有更好的泛化能力。

Abstract: Deep search agents, which aim to answer complex questions requiring reasoning across multiple documents, can significantly speed up the information-seeking process. Collecting human annotations for this application is prohibitively expensive due to long and complex exploration trajectories. We propose an agentic pipeline that automatically generates high quality, difficulty-controlled deep search question-answer pairs for a given corpus and a target difficulty level. Our pipeline, SAGE, consists of a data generator which proposes QA pairs and a search agent which attempts to solve the generated question and provide execution feedback for the data generator. The two components interact over multiple rounds to iteratively refine the question-answer pairs until they satisfy the target difficulty level. Our intrinsic evaluation shows SAGE generates questions that require diverse reasoning strategies, while significantly increases the correctness and difficulty of the generated data. Our extrinsic evaluation demonstrates up to 23% relative performance gain on popular deep search benchmarks by training deep search agents with our synthetic data. Additional experiments show that agents trained on our data can adapt from fixed-corpus retrieval to Google Search at inference time, without further training.

</details>


### [47] [Paying Less Generalization Tax: A Cross-Domain Generalization Study of RL Training for LLM Agents](https://arxiv.org/abs/2601.18217)
*Zhihan Liu,Lin Guan,Yixin Nie,Kai Zhang,Zhuoqun Hao,Lin Chen,Asli Celikyilmaz,Zhaoran Wang,Na Zhang*

Main category: cs.AI

TL;DR: 研究了在未知领域进行强化学习（RL）泛化训练的挑战，发现状态信息丰富度和规划复杂度是影响跨领域泛化能力的关键因素，并提出通过增加无关干扰特征来丰富状态信息以提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）特工在部署到更广泛的、未知的领域之前，通常只在有限的环境集上进行训练。本研究旨在解决这种agentic post-training在测试领域未知时的挑战，并分析哪些环境属性和模型选择对领域外性能影响最大。

Method: 研究人员首先识别并分析了影响跨领域泛化的两个环境轴：状态信息丰富度和规划复杂度（通过目标可达性和基础策略下的轨迹长度估算）。在此基础上，提出了一种低开销、可广泛应用的随机化技术，即向状态添加少量干扰性的、与目标无关的特征以丰富状态信息。此外，还研究了监督微调（SFT）预热/中期训练和RL过程中的逐步思考等模型选择的影响。

Result: 研究发现，状态信息丰富度和规划复杂度与跨领域泛化能力密切相关，而领域真实性和文本相似性并非主要因素。SFT预热/中期训练在防止灾难性遗忘方面有效，但可能损害对未包含在数据混合中的领域的泛化能力。逐步思考在RL过程中对保持泛化能力至关重要，尽管不总能提高领域内性能。

Conclusion: 通过增加状态信息丰富度，例如添加干扰性特征，可以有效提高LLM特工的跨领域泛化鲁棒性。在模型选择方面，应谨慎使用SFT预热/中期训练，并利用逐步思考来增强泛化能力。

Abstract: Generalist LLM agents are often post-trained on a narrow set of environments but deployed across far broader, unseen domains. In this work, we investigate the challenge of agentic post-training when the eventual test domains are unknown. Specifically, we analyze which properties of reinforcement learning (RL) environments and modeling choices have the greatest influence on out-of-domain performance. First, we identify two environment axes that strongly correlate with cross-domain generalization: (i) state information richness, i.e., the amount of information for the agent to process from the state, and (ii) planning complexity, estimated via goal reachability and trajectory length under a base policy. Notably, domain realism and text-level similarity are not the primary factors; for instance, the simple grid-world domain Sokoban leads to even stronger generalization in SciWorld than the more realistic ALFWorld. Motivated by these findings, we further show that increasing state information richness alone can already effectively improve cross-domain robustness. We propose a randomization technique, which is low-overhead and broadly applicable: add small amounts of distractive goal-irrelevant features to the state to make it richer without altering the task. Beyond environment-side properties, we also examine several modeling choices: (a) SFT warmup or mid-training helps prevent catastrophic forgetting during RL but undermines generalization to domains that are not included in the mid-training datamix; and (b) turning on step-by-step thinking during RL, while not always improving in-domain performance, plays a crucial role in preserving generalization.

</details>


### [48] [ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants](https://arxiv.org/abs/2601.18225)
*Pei Wang,Yanan Wu,Xiaoshuai Song,Weixun Wang,Gengru Chen,Zhongwen Li,Kezhong Yan,Ken Deng,Qi Liu,Shuaibing Zhao,Shaopan Xiong,Xuepeng Liu,Xuefeng Chen,Wanxi Deng,Wenbo Su,Bo Zheng*

Main category: cs.AI

TL;DR: 本文提出了一个名为ShopSimulator的大型中文电商购物模拟环境，用于评估和训练基于LLM的购物助手。研究发现现有LLM在用户偏好理解、多轮对话和商品筛选方面存在不足，但通过SFT和RL的结合可以显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏一个能够统一模拟用户偏好、多轮对话和细粒度商品检索的电商购物环境，并且缺乏训练支持，导致LLM在实际电商应用中的表现不佳。

Method: 构建了一个大规模、具有挑战性的中文电商购物模拟环境ShopSimulator。利用该环境评估了多种LLM在不同场景下的表现，并进行了错误分析。进一步探索了SFT和RL结合的训练方法以改进LLM的性能。

Result: 现有表现最佳的LLM在ShopSimulator环境中，完全成功的比率不足40%。LLM在深度搜索、长对话中的商品选择、个性化线索的平衡使用以及用户交互方面存在显著问题。SFT和RL的结合训练方法带来了性能的显著提升。

Conclusion: ShopSimulator为LLM在电商购物场景下的评估和训练提供了一个有价值的平台。LLM在电商购物任务中仍有很大的提升空间，特别是在复杂的搜索和用户交互方面。SFT和RL的组合训练策略是有效提升LLM电商购物能力的可行途径。

Abstract: Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.

</details>


### [49] [Yunjue Agent Tech Report: A Fully Reproducible, Zero-Start In-Situ Self-Evolving Agent System for Open-Ended Tasks](https://arxiv.org/abs/2601.18226)
*Haotian Li,Shijun Yang,Weizhen Qi,Silei Zhao,Rui Hua,Mingzhu Song,Xiaojian Yang,Chao Peng*

Main category: cs.AI

TL;DR: 提出了一种名为“In-Situ Self-Evolving”的范式，通过在开放且动态变化的环境中，利用可验证的二元反馈信号来迭代地合成、优化和重用工具，从而使智能体能够持续扩展其能力，而无需地面真实标签。通过“Yunjue Agent”系统和“Parallel Batch Evolution”策略来提高效率，并在多个基准测试中取得了显著的性能提升，同时证明了知识迁移的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的智能体系统在开放且任务分布不断变化的非结构化环境中表现不佳，因为它们依赖静态工具集或离线训练，无法适应动态变化，并且能力边界僵化且未知。

Method: 提出“In-Situ Self-Evolving”范式，将连续的任务交互视为经验流，从短期执行反馈中提炼出可重用的长期能力，而无需地面真实标签。重点关注工具演化作为能力扩展的关键途径，利用可验证的二元反馈信号。开发了“Yunjue Agent”系统，用于迭代地合成、优化和重用工具。引入了“Parallel Batch Evolution”策略来提高演化效率。提出了一个新指标来监控演化收敛性。

Result: 在五个不同的基准测试中，零起点设置下的“Yunjue Agent”相比现有基线取得了显著的性能提升。在预先训练（warm-start）设置下，证明了所积累的通用知识可以无缝迁移到新的领域。新提出的演化收敛指标在功能上类似于传统优化中的训练损失。

Conclusion: “In-Situ Self-Evolving”范式能够使智能体在开放环境和动态任务分布下持续学习和扩展能力，通过工具的迭代演化实现，并能在零起点和迁移学习场景下取得优异表现。新提出的演化收敛指标有助于监控和评估智能体的学习过程。

Abstract: Conventional agent systems often struggle in open-ended environments where task distributions continuously drift and external supervision is scarce. Their reliance on static toolsets or offline training lags behind these dynamics, leaving the system's capability boundaries rigid and unknown. To address this, we propose the In-Situ Self-Evolving paradigm. This approach treats sequential task interactions as a continuous stream of experience, enabling the system to distill short-term execution feedback into long-term, reusable capabilities without access to ground-truth labels. Within this framework, we identify tool evolution as the critical pathway for capability expansion, which provides verifiable, binary feedback signals. Within this framework, we develop Yunjue Agent, a system that iteratively synthesizes, optimizes, and reuses tools to navigate emerging challenges. To optimize evolutionary efficiency, we further introduce a Parallel Batch Evolution strategy. Empirical evaluations across five diverse benchmarks under a zero-start setting demonstrate significant performance gains over proprietary baselines. Additionally, complementary warm-start evaluations confirm that the accumulated general knowledge can be seamlessly transferred to novel domains. Finally, we propose a novel metric to monitor evolution convergence, serving as a function analogous to training loss in conventional optimization. We open-source our codebase, system traces, and evolved tools to facilitate future research in resilient, self-evolving intelligence.

</details>


### [50] [Think-Augmented Function Calling: Improving LLM Parameter Accuracy Through Embedded Reasoning](https://arxiv.org/abs/2601.18282)
*Lei Wei,Jinpeng Ou,Xiao Peng,Bin Wang*

Main category: cs.AI

TL;DR: 提出了一种名为Think-Augmented Function Calling (TAFC)的新框架，通过在函数和参数层面引入显式的“思考”参数，提高了大型语言模型（LLMs）在函数调用中的参数生成准确性和推理连贯性，尤其适用于具有相互依赖参数的复杂函数。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在函数调用中缺乏显式的参数生成推理透明度，特别是对于复杂函数，而现有的链式思考等方法作用于代理层面，无法为单个函数参数提供细粒度推理指导。

Method: 引入了一个通用的“思考”参数来增强LLMs的函数调用能力，允许模型阐述其决策过程。该方法还包括：动态优化参数描述以提高推理质量；根据复杂性评分自动触发复杂参数的细粒度推理；以及一种引导推理的优化方法，使生成的推理与人类期望对齐。TAFC无需修改LLM架构，并保持API兼容性。

Result: 在ToolBench基准测试中，使用专有和开源模型进行评估，TAFC显著提高了多参数函数的参数生成准确性和推理连贯性，并增强了AI代理行为调试的可解释性。

Conclusion: TAFC是一个有效的新框架，通过在函数和参数层面引入显式推理，提升了LLMs在函数调用中的表现，尤其是在处理复杂多参数函数时，并提供了更好的可解释性。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in function calling for autonomous agents, yet current mechanisms lack explicit reasoning transparency during parameter generation, particularly for complex functions with interdependent parameters. While existing approaches like chain-of-thought prompting operate at the agent level, they fail to provide fine-grained reasoning guidance for individual function parameters. To address these limitations, we propose Think-Augmented Function Calling (TAFC), a novel framework that enhances function calling accuracy through explicit reasoning at both function and parameter levels. Our method introduces a universal "think" parameter augmentation that enables models to articulate their decision-making process, with dynamic optimization for parameter descriptions to improve reasoning quality. For complex parameters, TAFC automatically triggers granular reasoning based on complexity scoring, ensuring appropriate justification for critical decisions. Additionally, we propose reasoning-guided optimization to align generated reasoning with human expectations. TAFC requires no architectural modifications to existing LLMs while maintaining full API compatibility. Evaluation on ToolBench across proprietary and open-source models demonstrates significant improvements in parameter generation accuracy and reasoning coherence for multi-parameter functions, while providing enhanced interpretability for debugging AI agent behaviors.

</details>


### [51] [Can Good Writing Be Generative? Expert-Level AI Writing Emerges through Fine-Tuning on High-Quality Books](https://arxiv.org/abs/2601.18353)
*Tuhin Chakrabarty,Paramveer S. Dhillon*

Main category: cs.AI

TL;DR: 研究发现，尽管专家评审倾向于人类作家，但普通大众却更喜欢AI生成的文本。AI在模仿作者风格方面表现出色，甚至引发了专家作家对其创作能力和身份认同的质疑。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于挑战“创意写作是独特人类能力”的传统观点，并探究生成式AI在模仿人类作家风格方面的实际表现及其对人类作家和创意产业的潜在影响。

Method: 通过一项行为实验，让28名MFA作家（专家）与三个大型语言模型（LLMs）竞争模仿50位知名作家。实验结果基于28名专家评审员和131名普通评审员的盲注配对比较。

Result: 在上下文提示条件下，专家评审员82.7%的情况下偏好人类写作；然而，在对作者的完整作品进行微调后，AI写作的偏好率上升至62%。普通评审员则一致偏好AI写作。专家作家在访谈中表示，AI写作引发了他们的身份认同危机，侵蚀了他们的审美自信，并质疑“好写作”的定义。

Conclusion: 研究结论表明，生成式AI在模仿作家风格方面具有强大能力，并且能够获得普通大众的青睐。这不仅挑战了关于AI创作局限性的现有讨论，也引发了对未来创意劳动性质的根本性思考。

Abstract: Creative writing has long been considered a uniquely human endeavor, requiring voice and style that machines could not replicate. This assumption is challenged by Generative AI that can emulate thousands of author styles in seconds with negligible marginal labor. To understand this better, we conducted a behavioral experiment where 28 MFA writers (experts) competed against three LLMs in emulating 50 critically acclaimed authors. Based on blind pairwise comparisons by 28 expert judges and 131 lay judges, we find that experts preferred human writing in 82.7% of cases under the in-context prompting condition but this reversed to 62% preference for AI after fine-tuning on authors' complete works. Lay judges, however, consistently preferred AI writing. Debrief interviews with expert writers revealed that their preference for AI writing triggered an identity crisis, eroding aesthetic confidence and questioning what constitutes "good writing." These findings challenge discourse about AI's creative limitations and raise fundamental questions about the future of creative labor.

</details>


### [52] [Dynamic Thinking-Token Selection for Efficient Reasoning in Large Reasoning Models](https://arxiv.org/abs/2601.18383)
*Zhenyuan Guo,Tong Chen,Wenlong Meng,Chen Gong,Xin Yu,Chengkun Wei,Wenzhi Chen*

Main category: cs.AI

TL;DR: 本研究提出了一种名为动态思维-Token选择（DynTS）的新方法，通过识别和保留推理过程中关键的Token，从而减少大型推理模型（LRMs）的内存占用和计算开销。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在解决复杂问题时会生成详细的推理过程，但这带来了巨大的内存和计算开销，限制了其效率。研究者希望找到一种方法来优化LRMs的推理过程。

Method: 该研究利用注意力图分析推理过程中Token对最终答案的影响，发现只有一部分关键Token起着决定性作用。基于此，DynTS方法在推理过程中动态识别这些关键Token，并仅保留其对应的键值（KV）缓存状态，丢弃冗余条目。

Result: DynTS方法能够识别出对模型决策至关重要的Token，并通过选择性地保留其KV缓存状态来优化效率。

Conclusion: 通过识别推理过程中具有决定性作用的Token并动态管理其KV缓存，DynTS能够显著提高大型推理模型的效率，而不会牺牲其解决复杂问题的能力。

Abstract: Large Reasoning Models (LRMs) excel at solving complex problems by explicitly generating a reasoning trace before deriving the final answer. However, these extended generations incur substantial memory footprint and computational overhead, bottlenecking LRMs' efficiency. This work uses attention maps to analyze the influence of reasoning traces and uncover an interesting phenomenon: only some decision-critical tokens in a reasoning trace steer the model toward the final answer, while the remaining tokens contribute negligibly. Building on this observation, we propose Dynamic Thinking-Token Selection (DynTS). This method identifies decision-critical tokens and retains only their associated Key-Value (KV) cache states during inference, evicting the remaining redundant entries to optimize efficiency.

</details>


### [53] [AI Agent for Reverse-Engineering Legacy Finite-Difference Code and Translating to Devito](https://arxiv.org/abs/2601.18381)
*Yinghan Hou,Zongyou Yang*

Main category: cs.AI

TL;DR: 本文提出了一种集成的AI代理框架，利用检索增强生成（RAG）和大型语言模型（LLM）将遗留的有限差分代码转换为Devito环境，通过构建知识图谱、优化查询和代码合成实现高效准确的代码迁移。


<details>
  <summary>Details</summary>
Motivation: 为了方便将遗留的有限差分（FD）实现迁移到Devito环境，克服手动转换的挑战和低效率。

Method: 该研究结合了检索增强生成（RAG）和开源大型语言模型，利用LangGraph多阶段迭代工作流。通过文档解析、结构感知分割、实体关系提取和Leiden社区检测构建Devito知识图谱。采用GraphRAG优化跨社区查询。通过静态分析Fortran源代码设计三级RAG检索策略。多阶段检索管道执行并行搜索、概念扩展、社区规模检索和语义相似性分析。使用Pydantic约束进行代码合成。利用G-Eval和静态分析进行验证。

Result: 构建了一个Devito知识图谱，并优化了跨社区（如地震波模拟、计算流体动力学、性能调优库）的查询性能。开发了能够从遗留Fortran代码生成Devito代码的AI代理，并验证了代码的正确性、结构健全性、数学一致性和API合规性。

Conclusion: 该AI代理框架能够有效地将遗留的有限差分实现转换为Devito环境，通过知识图谱、优化的RAG检索和代码合成，以及基于反馈的迭代改进，实现了动态和自适应的代码迁移。

Abstract: To facilitate the transformation of legacy finite difference implementations into the Devito environment, this study develops an integrated AI agent framework. Retrieval-Augmented Generation (RAG) and open-source Large Language Models are combined through multi-stage iterative workflows in the system's hybrid LangGraph architecture. The agent constructs an extensive Devito knowledge graph through document parsing, structure-aware segmentation, extraction of entity relationships, and Leiden-based community detection. GraphRAG optimisation enhances query performance across semantic communities that include seismic wave simulation, computational fluid dynamics, and performance tuning libraries. A reverse engineering component derives three-level query strategies for RAG retrieval through static analysis of Fortran source code. To deliver precise contextual information for language model guidance, the multi-stage retrieval pipeline performs parallel searching, concept expansion, community-scale retrieval, and semantic similarity analysis. Code synthesis is governed by Pydantic-based constraints to guarantee structured outputs and reliability. A comprehensive validation framework integrates conventional static analysis with the G-Eval approach, covering execution correctness, structural soundness, mathematical consistency, and API compliance. The overall agent workflow is implemented on the LangGraph framework and adopts concurrent processing to support quality-based iterative refinement and state-aware dynamic routing. The principal contribution lies in the incorporation of feedback mechanisms motivated by reinforcement learning, enabling a transition from static code translation toward dynamic and adaptive analytical behavior.

</details>


### [54] [OffSeeker: Online Reinforcement Learning Is Not All You Need for Deep Research Agents](https://arxiv.org/abs/2601.18467)
*Yuhang Zhou,Kai Zheng,Qiguang Chen,Mengkang Hu,Qingfeng Sun,Can Xu,Jingjing Chen*

Main category: cs.AI

TL;DR: 本文提出了一种名为 OffSeeker 的离线训练研究代理模型，旨在解决在线强化学习成本高昂的问题。通过引入 DeepForge 任务合成框架和大规模高质量数据集，OffSeeker 在多个基准测试中表现出色，甚至能与大规模在线训练模型媲美。


<details>
  <summary>Details</summary>
Motivation: 现有的先进研究代理在处理长时任务时依赖于在线强化学习，但其成本高昂，需要大量的 API 调用。离线训练是更经济的替代方案，但高质量研究轨迹的稀缺阻碍了其发展。

Method: 本文引入了一个完全开源的套件，用于有效的离线训练。核心贡献包括 DeepForge（一个无需大量预处理即可生成大规模研究查询的任务合成框架）以及包含 66k QA 对、33k SFT 轨迹和 21k DPO 对的精选数据集。利用这些资源，训练了完全离线训练的 OffSeeker (8B) 模型。

Result: 在六个基准测试上的广泛评估表明，OffSeeker 在同等规模的代理中处于领先地位，并且与通过大量在线 RL 训练的 30B 参数系统相比也具有竞争力。

Conclusion: 昂贵的在线强化学习并非构建强大研究代理的唯一途径。通过使用 DeepForge 和精选的大规模数据集进行离线训练，可以有效地构建出性能强大的研究代理，且成本更低。

Abstract: Deep research agents have shown remarkable potential in handling long-horizon tasks. However, state-of-the-art performance typically relies on online reinforcement learning (RL), which is financially expensive due to extensive API calls. While offline training offers a more efficient alternative, its progress is hindered by the scarcity of high-quality research trajectories. In this paper, we demonstrate that expensive online reinforcement learning is not all you need to build powerful research agents. To bridge this gap, we introduce a fully open-source suite designed for effective offline training. Our core contributions include DeepForge, a ready-to-use task synthesis framework that generates large-scale research queries without heavy preprocessing; and a curated collection of 66k QA pairs, 33k SFT trajectories, and 21k DPO pairs. Leveraging these resources, we train OffSeeker (8B), a model developed entirely offline. Extensive evaluations across six benchmarks show that OffSeeker not only leads among similar-sized agents but also remains competitive with 30B-parameter systems trained via heavy online RL.

</details>


### [55] [AgentDoG: A Diagnostic Guardrail Framework for AI Agent Safety and Security](https://arxiv.org/abs/2601.18491)
*Dongrui Liu,Qihan Ren,Chen Qian,Shuai Shao,Yuejin Xie,Yu Li,Zhonghao Yang,Haoyu Luo,Peng Wang,Qingyu Liu,Binxin Hu,Ling Tang,Jilin Mei,Dadi Guo,Leitao Yuan,Junyao Yang,Guanxu Chen,Qihao Lin,Yi Yu,Bo Zhang,Jiaxuan Guo,Jie Zhang,Wenqi Shao,Huiqi Deng,Zhiheng Xi,Wenjie Wang,Wenxuan Wang,Wen Shen,Zhikai Chen,Haoyu Xie,Jialing Tao,Juntao Dai,Jiaming Ji,Zhongjie Ba,Linfeng Zhang,Yong Liu,Quanshi Zhang,Lei Zhu,Zhihua Wei,Hui Xue,Chaochao Lu,Jing Shao,Xia Hu*

Main category: cs.AI

TL;DR: 本文提出了一种新的三维分类法来对AI代理的风险进行分类，并基于此构建了一个名为ATBench的安全基准和AgentDoG框架，用于对代理进行精细化监控、诊断风险根源并提供透明度。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理的护栏模型缺乏对代理风险的意识和风险诊断的透明度，无法有效应对复杂的、多样的风险行为。

Method: 首先，提出一个三维分类法（来源、失败模式、后果）来统一分类代理风险。然后，基于此分类法构建ATBench安全基准和AgentDoG框架。AgentDoG提供对代理轨迹的精细化、情境化监控，并能诊断不安全行为和看似安全但不合理的行为的根本原因，提供超越二元标签的溯源和透明度。

Result: AgentDoG在Qwen和Llama模型家族（4B、7B、8B参数）上进行了实验，并在多样化和复杂的交互场景中实现了最先进的代理安全审核性能。

Conclusion: AgentDoG框架为AI代理的安全和安全防护提供了一种有效的、透明的解决方案，能够精细化监控、诊断风险根源，并有助于代理对齐。

Abstract: The rise of AI agents introduces complex safety and security challenges arising from autonomous tool use and environmental interactions. Current guardrail models lack agentic risk awareness and transparency in risk diagnosis. To introduce an agentic guardrail that covers complex and numerous risky behaviors, we first propose a unified three-dimensional taxonomy that orthogonally categorizes agentic risks by their source (where), failure mode (how), and consequence (what). Guided by this structured and hierarchical taxonomy, we introduce a new fine-grained agentic safety benchmark (ATBench) and a Diagnostic Guardrail framework for agent safety and security (AgentDoG). AgentDoG provides fine-grained and contextual monitoring across agent trajectories. More Crucially, AgentDoG can diagnose the root causes of unsafe actions and seemingly safe but unreasonable actions, offering provenance and transparency beyond binary labels to facilitate effective agent alignment. AgentDoG variants are available in three sizes (4B, 7B, and 8B parameters) across Qwen and Llama model families. Extensive experimental results demonstrate that AgentDoG achieves state-of-the-art performance in agentic safety moderation in diverse and complex interactive scenarios. All models and datasets are openly released.

</details>


### [56] [DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference](https://arxiv.org/abs/2601.18496)
*Zihan wang,Hao Wang,Shi Feng,Xiaocui Yang,Daling Wang,Yiqun Zhang,Jinghao Lin,Haihua Yang,Xiaozhong Ji*

Main category: cs.AI

TL;DR: 本文提出了DeepMed，一个旨在解决通用深度研究（DR）模型在医学领域表现不佳的问题的模型。DeepMed通过改进数据合成、训练策略和推理过程，提高了模型在医学问答任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 通用DR模型在医学领域应用效果有限，主要由于任务特性（医学问题需要结合临床背景的知识密集型推理）和工具使用扩展性问题（盲目扩展工具调用会引入噪声，导致推理错误）。

Method: DeepMed采用了以下方法：1. 数据方面：使用多跳医学搜索QA合成方法，使模型能在医学情境下应用DR范式。2. 训练方面：引入难度感知回合惩罚，以抑制过度的工具调用。3. 推理方面：加入监控器，在有限步数内验证假设，避免上下文遗忘。

Result: 在七个医学基准测试中，DeepMed的平均性能比基础模型提高了9.79%，并且优于其他大型医学推理和DR模型。

Conclusion: DeepMed成功地提升了DR模型在医学领域的推理能力，通过针对性地解决数据、训练和推理中的挑战，实现了在医学QA任务上的显著性能提升。

Abstract: Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relatively limited gains. We attribute this to two gaps: task characteristic and tool-use scaling. Medical questions require evidence interpretation in a knowledge-intensive clinical context; while general DR models can retrieve information, they often lack clinical-context reasoning and thus "find it but fail to use it," leaving performance limited by medical abilities. Moreover, in medical scenarios, blindly scaling tool-call can inject noisy context, derailing sensitive medical reasoning and prompting repetitive evidence-seeking along incorrect paths. Therefore, we propose DeepMed. For data, we deploy a multi-hop med-search QA synthesis method supporting the model to apply the DR paradigm in medical contexts. For training, we introduce a difficulty-aware turn-penalty to suppress excessive tool-call growth. For inference, we bring a monitor to help validate hypotheses within a controlled number of steps and avoid context rot. Overall, on seven medical benchmarks, DeepMed improves its base model by 9.79\% on average and outperforms larger medical reasoning and DR models.

</details>


### [57] [Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities](https://arxiv.org/abs/2601.18554)
*Alberto Purpura,Li Wang,Sahil Badyal,Eugenio Beaufrand,Adam Faulkner*

Main category: cs.AI

TL;DR: MOSAIC 是一个模块化框架，通过动态生成的指令集来评估大型语言模型（LLM）遵循复杂指令的能力，揭示了模型在不同指令类型、数量和位置上的遵循表现差异，并发现了指令间的协同与冲突效应。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）指令遵循基准测试未能充分反映实际应用场景，也无法将指令遵循与任务成功区分开来，因此需要一种更精细、独立的方法来评估LLM遵循复杂指令的能力。

Method: 引入了MOSAIC（MOdular Synthetic Assessment of Instruction Compliance）框架，该框架使用动态生成的、最多包含20种面向应用的生成约束的数据集，以实现对指令遵循能力的粒度化、独立分析。

Result: 对五种不同家族的LLM的评估表明，指令遵循能力并非单一维度，而是随指令类型、数量和位置的变化而显著不同。分析揭示了模型特有的弱点、指令间的协同与冲突交互作用，以及明显的顺序偏见（如首因效应和近因效应）。

Conclusion: MOSAIC框架提供的细粒度见解对于诊断模型失败和开发更可靠的LLM至关重要，尤其是在需要严格遵循复杂指令的系统中。

Abstract: Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.

</details>


### [58] [A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic](https://arxiv.org/abs/2601.18595)
*Joseph Cotnareanu,Didier Chetelat,Yingxue Zhang,Mark Coates*

Main category: cs.AI

TL;DR: 提出一种迭代方法，利用逻辑求解器的反馈来增强LLM提供的逻辑问题中的常识关系，以提高复杂推理能力。


<details>
  <summary>Details</summary>
Motivation: LLMs在复杂证明规划方面存在不足，而现有的将问题转化为形式逻辑并使用逻辑求解器的方法，由于缺乏常识关系而效果不佳。

Method: 通过迭代方式，利用逻辑求解器的反馈来增强LLM提供的逻辑问题中的常识关系。该方法包含一个搜索过程，用于查找潜在的常识假设，以最大化找到有用事实的机会，同时控制成本。

Result: 在移除了部分常识信息的纯逻辑推理数据集上，所提出的方法相较于现有技术取得了显著的改进。

Conclusion: 在涉及人类语境的推理任务中，结合神经网络（LLM）和符号（逻辑求解器）元素具有价值，可以通过迭代地集成常识信息来提升推理性能。

Abstract: Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.

</details>


### [59] [Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs](https://arxiv.org/abs/2601.18588)
*Xianzhe Meng,Qiangsheng Zeng,Ling Luo,Qinghan Yang,Jiarui Hao,Wenbo Wu,Qinyu Wang,Rui Yin,Lin Qi,Renzhi Lu*

Main category: cs.AI

TL;DR: 研究表明，尽管模型训练的稳定性通常被视为良好优化的前提，但它可能导致生成分布的熵降低，从而产生模式退化和重复输出，表明训练稳定性与生成表达能力并非天然一致。


<details>
  <summary>Details</summary>
Motivation: 标准的は、言語モデルの訓練の安定性が、信頼できる最適化の前提条件であると考えられていました。しかし、この論文では、訓練ダイナミクスの安定化が生成分布にどのような影響を与えるかを分析し、訓練の安定性と生成の質との間に潜在的なトレードオフがある可能性を調査することが動機となっています。

Method: 研究では、標準的な最尤推定法（Maximum Likelihood Training）の下で、安定したパラメータ軌跡が、経験分布への前方KLダイバージェンスを近似的に最小化する定常解につながることを理論的に示しました。さらに、制御されたフィードバックベースの訓練フレームワークを用いて、内部生成統計を安定化させる実験を行い、この効果を経験的に検証しました。

Result: 分析の結果、訓練の安定化は、生成分布の静止解が経験分布への前方KLダイバージェンスを近似的に最小化する一方で、暗黙的に生成エントロピーを低下させることが示されました。実験的検証では、一貫して低エントロピーの出力と反復的な挙動が、様々なアーキテクチャとランダムシードで観察されました。

Conclusion: 訓練の最適化の安定性と生成の表現能力は、本質的に一致するものではなく、安定性だけでは生成の質を十分に判断できないことが結論付けられました。この研究は、大規模言語モデルの訓練と生成品質の評価における新たな視点を提供します。

Abstract: Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.

</details>


### [60] [PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression](https://arxiv.org/abs/2601.18608)
*Fabian Fumagalli,R. Teal Witter,Christopher Musco*

Main category: cs.AI

TL;DR: 本文提出了PolySHAP方法，通过拟合更高阶的多项式来改进KernelSHAP，从而更准确地估计Shapley值，并为配对采样（paired sampling）提供理论依据。


<details>
  <summary>Details</summary>
Motivation: 现有KernelSHAP算法在计算Shapley值时存在效率问题，并且对非线性交互的捕捉能力有限。研究者希望改进KernelSHAP，以提高Shapley值估计的准确性，并理解配对采样等启发式方法的有效性。

Method: 作者提出了PolySHAP方法，它通过拟合更高阶的多项式来近似游戏函数，从而捕捉特征间的非线性交互。此外，研究者还证明了配对采样方法实际上等同于二阶PolySHAP。

Result: PolySHAP在多个基准数据集上获得了经验上更好的Shapley值估计。研究还证明了这些估计的一致性，并首次提供了配对采样能够获得相同Shapley值近似的理论证明。

Conclusion: PolySHAP通过拟合多项式提供了一种更准确的Shapley值估计方法，并为配对采样等启发式方法提供了理论支持，解释了其在实践中的出色表现。

Abstract: Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.
  In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.
  Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.

</details>


### [61] [Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks](https://arxiv.org/abs/2601.18617)
*Pierre Orhan,Pablo Diego-Simón,Emmnanuel Chemla,Yair Lakretz,Yves Boubenec,Jean-Rémi King*

Main category: cs.AI

TL;DR: 研究表明，在语言学习过程中，人工神经网络（ANN）在训练过程中会依次出现表征语音、词汇和语法的神经激活子空间，其学习轨迹与儿童相似，但需要更多数据。


<details>
  <summary>Details</summary>
Motivation: 虽然儿童语言习得的阶段性特征（语音、词汇、语法）已被充分描述，但缺乏一个统一的计算框架来解释其神经表征。

Method: 使用语音和文本训练人工神经网络（ANN），并分析其训练过程中神经激活的几何结构，以检测语音、词汇和语法表征的出现。

Result: 在训练过程中，ANN的神经激活会依次形成表征语音、词汇和语法结构的子空间。ANN在出现这些表征时所需的数据量是儿童语言习得的2到4个数量级。

Conclusion: 人工神经网络可以自发地在训练过程中涌现出语言习得的各个阶段的神经表征，为理解语言习得的计算机制提供了一个有前景的研究方向，但也指出目前模型在数据需求上与人类学习存在显著差异。

Abstract: During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition.

</details>


### [62] [Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation](https://arxiv.org/abs/2601.18630)
*Abeer Badawi,Md Tahmid Rahman Laskar,Elahe Rahimi,Sheri Grach,Lindsay Bertrand,Lames Danok,Frank Rudzicz,Jimmy Huang,Elham Dolatabadi*

Main category: cs.AI

TL;DR: 本研究提出了一种以人为本的评估方法，用于评估大型语言模型（LLM）在心理健康对话中的响应质量。结果表明，LLM 在提供安全、连贯和临床适当的信息方面表现良好，但在情感共鸣方面不稳定，尤其是在开源模型中。研究强调了在心理健康领域需要一种结合认知支持和情感共鸣的平衡评估框架，并呼吁在开发和监督心理健康对话 AI 时，以人为本并关注治疗敏感性。


<details>
  <summary>Details</summary>
Motivation: 全球心理健康危机日益严重，治疗缺口、可及性和合格治疗师短缺，这促使研究人员探索利用大型语言模型（LLM）来提供可扩展的情感支持。然而，LLM 的可靠性、治疗相关性和与人类标准的对齐仍然是一个挑战。

Method: 研究人员收集了 500 个心理健康对话数据集，并让九个不同的 LLM（包括闭源和开源模型）生成响应。然后，由两名接受过精神病学培训的专家使用 5 点李克特量表，依据包括认知支持和情感共鸣在内的六个属性，对 LLM 的响应进行独立评分。

Result: LLM 在认知方面表现出很强的可靠性，能够生成安全、连贯且临床上适当的信息。然而，在情感共鸣方面，LLM 的表现不稳定。闭源模型（如 GPT-4o）在治疗响应方面表现更均衡，而开源模型则表现出更大的变异性和情感平淡。

Conclusion: 研究揭示了 LLM 在心理健康对话中存在认知-情感差距，并强调了开发面向失败、临床导向的评估框架的必要性，该框架应优先考虑信息准确性以及人际关系的敏感性。研究者倡导采用以人为本、注重治疗敏感性的平衡评估协议，并为负责任地设计和临床监督心理健康对话 AI 提供框架。

Abstract: The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.

</details>


### [63] [AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning](https://arxiv.org/abs/2601.18631)
*Mingyang Song,Haoyu Sun,Jiawei Gu,Linjie Li,Luxin Xu,Ranjay Krishna,Yu Cheng*

Main category: cs.AI

TL;DR: 本文提出了一种名为AdaReasoner的多模态模型，它通过学习将工具使用视为一种通用推理技能，而非特定工具或显式监督行为。该模型通过可扩展的数据处理、基于端到端任务成功的强化学习算法（Tool-GRPO）以及自适应学习机制，能够根据任务上下文和中间结果推断工具效用，并能泛化到新工具和新任务，在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 人类在面对超出自身能力的问题时会寻求工具的帮助，这为提升多模态大语言模型（MLLMs）的视觉推理能力提供了思路。研究的动机在于如何让MLLMs有效地学习和运用工具，包括选择、调用和多步组合工具，尤其是在面对新工具或新任务时。

Method: AdaReasoner模型包含三个主要组成部分：1) 一个可扩展的数据策选管道，用于模型学习长时程、多步工具交互；2) Tool-GRPO，一种基于端到端任务成功的强化学习算法，用于优化工具选择和排序；3) 一个自适应学习机制，动态调节工具使用。这些组件共同作用，使模型能够根据任务上下文和中间结果推断工具效用，并实现对多个工具的协调和对未见工具的泛化。

Result: AdaReasoner展现出强大的工具适应性和泛化能力，能够自主采用有益的工具，抑制不相关的工具，并根据任务需求调整工具使用频率，即使在未明确训练的情况下。与7B基础模型相比，AdaReasoner的平均性能提升了+24.9%，并在VSP和Jigsaw等任务上超越了GPT-5等强大的专有系统。

Conclusion: AdaReasoner通过将工具使用作为一项通用推理技能进行学习，有效解决了多模态大语言模型在工具使用方面的挑战。其创新的数据处理、强化学习和自适应机制使其能够灵活地适应新工具和新任务，并在实际应用中取得了显著的性能提升，证明了其在视觉推理领域的潜力。

Abstract: When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.

</details>


### [64] [FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory](https://arxiv.org/abs/2601.18642)
*Lei Wei,Xu Dong,Xiao Peng,Niantao Xie,Bin Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为FadeMem的、受生物学启发的自主代理记忆架构，通过引入主动遗忘机制来解决大型语言模型（LLM）的记忆限制问题，该机制模仿了人类记忆的自适应衰减过程，能够更有效地管理信息存储并提升多跳推理和检索能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM自主代理缺乏选择性遗忘机制，导致要么在上下文边界发生灾难性遗忘，要么在上下文中信息过载。这与人类记忆在保留和遗忘之间的自然平衡形成对比。

Method: FadeMem采用双层记忆结构，并引入差异化的衰减率。记忆保留受语义相关性、访问频率和时间模式调制的自适应指数衰减函数控制。此外，该系统还通过LLM引导的冲突解决和智能记忆融合来整合相关信息并遗忘无关细节。

Result: 在Multi-Session Chat、LoCoMo和LTI-Bench等基准测试中，FadeMem实现了45%的存储空间减少，同时展示了更优越的多跳推理和检索能力。

Conclusion: 受生物学启发的遗忘机制能够显著提高自主代理的记忆系统效率，有效解决LLM的记忆限制问题，并提升其在复杂任务中的表现。

Abstract: Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems.

</details>


### [65] [TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent](https://arxiv.org/abs/2601.18700)
*Xingyu Sui,Yanyan Zhao,Yulin Hu,Jiahe Guo,Weixiang Zhao,Bing Qin*

Main category: cs.AI

TL;DR: 本文提出了TEA-Bench，一个用于评估工具增强型情感支持对话（ESC）系统的基准。实验表明，工具增强可以提高ESC的质量并减少幻觉，但效果与模型能力强弱相关。此外，还发布了TEA-Dialog数据集，并发现监督微调在in-distribution任务上效果较好，但在泛化方面表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有情感支持对话系统主要关注情感表达，而忽略了事实性工具支持，容易导致系统产生幻觉。因此，研究如何利用外部工具来增强情感支持对话系统的可信度是研究的动机。

Method: 提出了TEA-Bench，一个包含真实情感场景、MCP风格工具环境以及过程级指标的交互式基准，用于评估工具增强型ESC代理。同时发布了TEA-Dialog数据集，并进行了监督微调实验。

Result: 在九个大型语言模型上的实验表明，工具增强普遍提高了情感支持的质量并减少了幻觉，但效果与模型能力高度相关。更强的模型能选择性且有效地使用工具，而较弱的模型收益甚微。监督微调在TEA-Dialog数据集上表现出良好的in-distribution性能，但在泛化方面存在不足。

Conclusion: 工具使用对于构建可靠的情感支持代理至关重要。模型能力是影响工具增强效果的关键因素，需要进一步研究如何提高弱模型从工具中受益的能力，以及如何提升模型的泛化能力。

Abstract: Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents.

</details>


### [66] [Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs](https://arxiv.org/abs/2601.18706)
*Zhichao Yang,Sepehr Janghorbani,Dongxu Zhang,Jun Han,Qian Qian,Andrew Ressler,Gregory D. Lyng,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.AI

TL;DR: Health-SCORE 是一个可扩展的、基于评分标准的框架，用于评估和训练大型语言模型在医疗领域的开放式回答，显著降低了开发成本，同时保持了与人工创建评分标准相当的评估质量。


<details>
  <summary>Details</summary>
Motivation: 开发高质量、领域特定的评分标准以评估大型语言模型在医疗等关键领域的开放式回答，需要大量专业知识和时间，难以规模化。现有的方法成本高昂，限制了基于评分标准的评估和训练。

Method: 提出 Health-SCORE 框架，它是一个可推广且可扩展的基于评分标准的训练和评估框架。该框架旨在减少评分标准的开发成本，同时不牺牲性能。Health-SCORE 可用作结构化奖励信号来指导带有安全意识监督的强化学习，也可直接嵌入到提示中以通过上下文学习提高回答质量。

Result: 在开放式医疗任务中，Health-SCORE 达到了与人工创建的评分标准相当的评估质量。同时，它显著降低了开发工作量，提高了评估和训练的可扩展性。

Conclusion: Health-SCORE 提供了一种实用且可扩展的解决方案，用于创建和使用评分标准来评估和训练大型语言模型在医疗领域的开放式回答，有效地平衡了成本、性能和可扩展性。

Abstract: Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.

</details>


### [67] [Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules](https://arxiv.org/abs/2601.18716)
*Naeyma N. Islam,Thomas R. Caulfield*

Main category: cs.AI

TL;DR: 研究者开发了一种新颖的AI辅助药物设计方法，旨在通过E3连接酶介导的分子胶水促进细胞内Aβ-42的泛素-蛋白酶体系统（UPS）降解，以治疗阿尔茨海默病。


<details>
  <summary>Details</summary>
Motivation: 细胞内Aβ-42的积累是阿尔茨海默病早期和有毒的驱动因素，而现有的研究主要集中在细胞外淀粉样蛋白斑块，因此需要新的策略来靶向细胞内Aβ-42。

Method: 研究采用AI辅助药物设计方法，利用结构模拟、ADMET筛选和对接评估了Aβ-42与CRBN、VHL和MDM2三种E3连接酶形成三元复合物的潜力。随后，开发了一种特定连接酶的联合树变分自编码器（LC-JT-VAE）模型，并结合蛋白质序列嵌入和角度感知分子图来生成分子胶水，以促进Aβ-42的降解。

Result: 开发的生成模型能够产生化学有效、新颖且靶向性强的分子胶水，能够促进Aβ-42的降解。

Conclusion: 该研究提供了一个有前景的框架，用于设计针对神经退行性疾病的UPS靶向疗法，特别是通过AI辅助设计分子胶水以促进细胞内Aβ-42的降解。

Abstract: Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.

</details>


### [68] [Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems](https://arxiv.org/abs/2601.18735)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Jing Yang,Jiawei Yao,Jian Wang,Guanlong Qu,Ziliang Chen,Keze Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为 Agora 的新框架，将多智能体系统中的协调问题重构为一种去中心化的不确定性市场，通过经济规则驱动代理之间的交易，以实现成本效益最大化。实验证明 Agora 在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模视觉语言模型（VLMs）在多智能体系统中的协调成本过高，且现有的协调方法（如 Mixture-of-Agents 和知识路由）忽略了成本，导致次优协调。

Method: Agora 将认知不确定性（感知、语义、推理）形式化为可交易的资产，并基于盈利驱动的经济规则在代理之间进行交易。引入了一个市场感知的经纪人，扩展了 Thompson Sampling，以引导系统达到成本效益均衡。

Result: 在 MMMU、MMBench、MathVision、InfoVQA 和 CC-OCR 五个多模态基准测试中，Agora 的性能优于强大的 VLMs 和启发式多智能体策略。例如，在 MMMU 上，准确率提高了 8.5%，同时成本降低了 3 倍以上。

Conclusion: 基于市场机制的协调是一种原则性且可扩展的范式，能够构建经济上可行的多智能体视觉智能系统。

Abstract: Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems.

</details>


### [69] [TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models](https://arxiv.org/abs/2601.18744)
*Fangxu Yu,Xingang Guo,Lingzhi Yuan,Haoqiang Kang,Hongyu Zhao,Lianhui Qin,Furong Huang,Bin Hu,Tianyi Zhou*

Main category: cs.AI

TL;DR: 本研究提出了TSRBench，一个全面的多模态基准，用于评估通用模型在时间序列推理方面的能力。该基准包含4125个来自14个领域的问题，分为感知、推理、预测和决策制定四个维度。实验结果表明，模型在感知和推理上的规模法则在预测上失效，且语义理解与数值预测之间存在脱钩，多模态模型在融合文本和视觉信息方面仍有待提高。


<details>
  <summary>Details</summary>
Motivation: 现有通用模型基准缺乏对时间序列推理能力的全面评估，而时间序列数据在现实世界中至关重要，需要通用模型具备处理能力。

Method: 构建了一个包含4125个问题、14个领域、4个维度的多模态时间序列推理基准（TSRBench）。在TSRBench上对超过30个领先的LLM、VLM和TSLLM进行了广泛的实验评估。

Result: 1. 感知和推理任务遵循规模法则，但预测任务的规模法则失效。2. 强大的推理能力不一定能保证准确的上下文感知预测，表明语义理解与数值预测之间存在脱钩。3. 当前多模态模型未能有效融合文本和视觉时间序列表示以提升性能。

Conclusion: TSRBench为评估通用模型在时间序列推理方面的能力提供了一个标准化平台，揭示了现有模型的挑战，并为未来研究提供了宝贵的见解，以推动通用模型的进步。

Abstract: Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [70] [Scientific Image Synthesis: Benchmarking, Methodologies, and Downstream Utility](https://arxiv.org/abs/2601.17027)
*Honglin Lin,Chonghan Qin,Zheng Liu,Qizhi Pei,Yu Li,Zhanping Zhong,Xin Gao,Yanfeng Wang,Conghui He,Lijun Wu*

Main category: cs.CV

TL;DR: 研究表明，现有的文本到图像模型生成的科学图像在科学性上存在不足，并提出了 ImgCoder 和 SciGenBench 来改进图像生成和评估。使用高质量合成图像微调大型多模态模型可以提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型生成的科学图像在科学严谨性方面存在不足，导致视觉-逻辑不一致，限制了其在多模态推理中的应用。研究旨在克服这一限制，探索高质量科学图像合成的方法。

Method: 研究分析了像素级生成和程序化合成两种方法。提出了 ImgCoder，一个基于“理解-规划-编码”工作流的逻辑驱动框架，以提高结构精度。引入 SciGenBench 来评估生成图像的信息效用和逻辑有效性。

Result: 评估发现像素级模型存在系统性失败模式，并揭示了表达能力和精度之间的权衡。通过高质量合成图像微调大型多模态模型，可以持续提升推理能力。

Conclusion: 高保真科学图像合成是解锁大规模多模态推理能力的可行途径。通过严格验证的合成科学图像微调大型多模态模型，可以获得一致的推理提升，并可能出现类似于文本领域的扩展趋势。

Abstract: While synthetic data has proven effective for improving scientific reasoning in the text domain, multimodal reasoning remains constrained by the difficulty of synthesizing scientifically rigorous images. Existing Text-to-Image (T2I) models often produce outputs that are visually plausible yet scientifically incorrect, resulting in a persistent visual-logic divergence that limits their value for downstream reasoning. Motivated by recent advances in next-generation T2I models, we conduct a systematic study of scientific image synthesis across generation paradigms, evaluation, and downstream use. We analyze both direct pixel-based generation and programmatic synthesis, and propose ImgCoder, a logic-driven framework that follows an explicit "understand - plan - code" workflow to improve structural precision. To rigorously assess scientific correctness, we introduce SciGenBench, which evaluates generated images based on information utility and logical validity. Our evaluation reveals systematic failure modes in pixel-based models and highlights a fundamental expressiveness-precision trade-off. Finally, we show that fine-tuning Large Multimodal Models (LMMs) on rigorously verified synthetic scientific images yields consistent reasoning gains, with potential scaling trends analogous to the text domain, validating high-fidelity scientific synthesis as a viable path to unlocking massive multimodal reasoning capabilities.

</details>


### [71] [Data-Efficient Meningioma Segmentation via Implicit Spatiotemporal Mixing and Sim2Real Semantic Injection](https://arxiv.org/abs/2601.17031)
*Yunhao Xu,Fuquan Zong,Yexuan Xing,Chulong Zhang,Guang Yang,Shilong Yang,Xiaokun Liang,Juan Yu*

Main category: cs.CV

TL;DR: 提出一种新的双重增强框架，通过隐式神经表示（INR）进行空间流形扩展和模拟真实病灶注入，以提高有限标注数据下医学图像分割的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在医学图像分割领域，数据利用效率比原始数据量更重要。为了在有限的高质量标注数据中充分利用潜在信息，尤其是在处理脑膜瘤等复杂病变时，需要更有效的数据增强方法。

Method: 利用隐式神经表示（INR）建模连续速度场，并通过对积分变形场进行线性混合，高效生成解剖学上可信的变化。引入Sim2Real病灶注入模块，将病灶纹理移植到健康解剖背景中，构建高保真模拟域，实现合成增强与真实病灶的结合。

Result: 在混合数据集上的实验表明，该框架显著提高了nnU-Net和U-Mamba等先进模型的效率和鲁棒性。

Conclusion: 该双重增强框架是使用有限标注预算实现高精度医学图像分析的有效策略，能够最大化现有数据集的价值。

Abstract: The performance of medical image segmentation is increasingly defined by the efficiency of data utilization rather than merely the volume of raw data. Accurate segmentation, particularly for complex pathologies like meningiomas, demands that models fully exploit the latent information within limited high-quality annotations. To maximize the value of existing datasets, we propose a novel dual-augmentation framework that synergistically integrates spatial manifold expansion and semantic object injection. Specifically, we leverage Implicit Neural Representations (INR) to model continuous velocity fields. Unlike previous methods, we perform linear mixing on the integrated deformation fields, enabling the efficient generation of anatomically plausible variations by interpolating within the deformation space. This approach allows for the extensive exploration of structural diversity from a small set of anchors. Furthermore, we introduce a Sim2Real lesion injection module. This module constructs a high-fidelity simulation domain by transplanting lesion textures into healthy anatomical backgrounds, effectively bridging the gap between synthetic augmentation and real-world pathology. Comprehensive experiments on a hybrid dataset demonstrate that our framework significantly enhances the data efficiency and robustness of state-of-the-art models, including nnU-Net and U-Mamba, offering a potent strategy for high-performance medical image analysis with limited annotation budgets.

</details>


### [72] [Diagnosis Support of Sickle Cell Anemia by Classifying Red Blood Cell Shape in Peripheral Blood Images](https://arxiv.org/abs/2601.17032)
*Wilkie Delgado-Font,Miriela Escobedo-Nicot,Manuel González-Hidalgo,Silena Herold-Garcia,Antoni Jaume-i-Capó,Arnau Mir*

Main category: cs.CV

TL;DR: 提出了一种基于血涂片图像分析的自动化方法，用于区分正常、镰状或畸形红细胞，以辅助诊断镰状细胞贫血，该方法在实验中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前监测镰状细胞贫血等疾病的方法（观察外周血涂片）耗时、需要专家且主观性强，误差率高。

Method: 使用Chan-Vese主动轮廓模型分割图像中的红细胞，然后利用圆形形状因子（CSF）和椭圆形形状因子（ESF）进行形状分析，将红细胞分类为正常、延长或其他畸形。对于部分被遮挡的细胞，进行椭圆拟合以分析其形状。

Result: 所提出的方法在区分正常红细胞（F值0.97）和延长红细胞（F值0.95）方面表现优于现有技术，并且在多类别整体性能指标上也有优势。

Conclusion: 该自动化方法能够准确区分不同形态的红细胞，为镰状细胞贫血的临床诊断和治疗提供支持，其性能适合临床应用。

Abstract: Red blood cell (RBC) deformation is the consequence of several diseases, including sickle cell anemia, which causes recurring episodes of pain and severe pronounced anemia. Monitoring patients with these diseases involves the observation of peripheral blood samples under a microscope, a time-consuming procedure. Moreover, a specialist is required to perform this technique, and owing to the subjective nature of the observation of isolated RBCs, the error rate is high. In this paper, we propose an automated method for differentially enumerating RBCs that uses peripheral blood smear image analysis. In this method, the objects of interest in the image are segmented using a Chan-Vese active contour model. An analysis is then performed to classify the RBCs, also called erythrocytes, as normal or elongated or having other deformations, using the basic shape analysis descriptors: circular shape factor (CSF) and elliptical shape factor (ESF). To analyze cells that become partially occluded in a cluster during sample preparation, an elliptical adjustment is performed to allow the analysis of erythrocytes with discoidal and elongated shapes. The images of patient blood samples used in the study were acquired by a clinical laboratory specialist in the Special Hematology Department of the ``Dr. Juan Bruno Zayas'' General Hospital in Santiago de Cuba. A comparison of the results obtained by the proposed method in our experiments with those obtained by some state-of-the-art methods showed that the proposed method is superior for the diagnosis of sickle cell anemia. This superiority is achieved for evidenced by the obtained F-measure value (0.97 for normal cells and 0.95 for elongated ones) and several overall multiclass performance measures. The results achieved by the proposed method are suitable for the purpose of clinical treatment and diagnostic support of sickle cell anemia.

</details>


### [73] [AMVICC: A Novel Benchmark for Cross-Modal Failure Mode Profiling for VLMs and IGMs](https://arxiv.org/abs/2601.17037)
*Aahana Basappa,Pranay Goel,Anusri Karra,Anish Karra,Asa Gilmore,Kevin Zhu*

Main category: cs.CV

TL;DR: 本研究创建了一个名为AMVICC的新基准，用于系统性地评估多模态大型语言模型（MLLMs）和图像生成模型（IGMs）在视觉推理方面的局限性，通过比较图像到文本和文本到图像任务中的失败模式。研究发现，尽管模型发展迅速，但在理解或生成基本视觉概念（如物体方向、数量或空间关系）方面仍存在不足，并且失败模式在模型和模态之间经常共享，但也存在模型和模态特异性的失败。IGMs在响应显式提示时，特别是在操纵特定视觉组件方面表现不佳，表明其对细粒度视觉属性的控制能力较弱。这项工作为未来的跨模态对齐研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型和图像生成模型在理解和生成基础视觉概念方面存在不足，这表明了基础视觉推理能力的差距，促使研究者创建了一个能够系统比较不同模态和模型在视觉推理失败模式的基准。

Method: 研究者创建了一个名为AMVICC的新基准，该基准改编自MMVP基准的问题，并将其转化为显式和隐式提示。然后，研究者在九个视觉推理类别上测试了11个MLLMs和3个IGMs，以评估它们在图像到文本和文本到图像任务中的失败模式。

Result: 研究结果表明，失败模式在模型和模态之间通常是共享的，但某些失败是模型特异性和模态特异性的。IGMs在响应提示（尤其是在操纵特定视觉组件时，尤其是在显式提示下）时持续遇到困难，这表明它们对细粒度视觉属性的控制能力较差。

Conclusion: 该研究通过AMVICC基准揭示了MLLMs和IGMs在基础视觉推理方面的局限性，强调了模型和模态特异性失败的存在。研究结果有助于评估现有模型在结构化视觉推理任务上的表现，并为未来统一的视觉-语言建模研究和跨模态对齐研究提供了基础，以指导模型改进。

Abstract: We investigated visual reasoning limitations of both multimodal large language models (MLLMs) and image generation models (IGMs) by creating a novel benchmark to systematically compare failure modes across image-to-text and text-to-image tasks, enabling cross-modal evaluation of visual understanding. Despite rapid growth in machine learning, vision language models (VLMs) still fail to understand or generate basic visual concepts such as object orientation, quantity, or spatial relationships, which highlighted gaps in elementary visual reasoning. By adapting MMVP benchmark questions into explicit and implicit prompts, we create \textit{AMVICC}, a novel benchmark for profiling failure modes across various modalities. After testing 11 MLLMs and 3 IGMs in nine categories of visual reasoning, our results show that failure modes are often shared between models and modalities, but certain failures are model-specific and modality-specific, and this can potentially be attributed to various factors. IGMs consistently struggled to manipulate specific visual components in response to prompts, especially in explicit prompts, suggesting poor control over fine-grained visual attributes. Our findings apply most directly to the evaluation of existing state-of-the-art models on structured visual reasoning tasks. This work lays the foundation for future cross-modal alignment studies, offering a framework to probe whether generation and interpretation failures stem from shared limitations to guide future improvements in unified vision-language modeling.

</details>


### [74] [Hybrid Deep Feature Extraction and ML for Construction and Demolition Debris Classification](https://arxiv.org/abs/2601.17038)
*Obai Alashram,Nejad Alagha,Mahmoud AlKakuri,Zeeshan Swaveel,Abigail Copiaco*

Main category: cs.CV

TL;DR: 本研究提出了一种结合深度学习特征提取和传统机器学习分类器的混合视觉管道，用于自动识别建筑和拆除（C&D）废料，在包含四种类别（陶瓷/瓷砖、混凝土、垃圾/废料和木材）的1800张图像数据集上，使用Xception网络提取特征，并与SVM、kNN等分类器结合，取得了高达99.5%的准确率和宏F1分数，优于复杂的端到端深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 建筑行业产生了大量的建筑和拆除废料，高效的分类对于可持续的废物管理和资源回收至关重要。本研究旨在通过自动化方法解决这一问题。

Method: 收集了一个包含1800张图像的新数据集，涵盖陶瓷/瓷砖、混凝土、垃圾/废料和木材四种类别。使用预训练的Xception网络提取图像的深度特征，然后将这些特征输入到SVM、kNN、Bagged Trees、LDA和Logistic Regression等多种经典机器学习分类器中进行评估。

Result: 混合方法，特别是使用Xception特征与线性SVM、kNN和Bagged Trees分类器的组合，表现出色，实现了高达99.5%的准确率和宏F1分数，超过了更复杂的或端到端的深度学习方法。

Conclusion: 基于Xception特征提取和传统机器学习分类器的混合视觉管道在C&D废料分类方面具有很高的鲁棒性和准确性，适合在实际现场部署，并且为未来与机器人和现场自动化系统的集成提供了途径。

Abstract: The construction industry produces significant volumes of debris, making effective sorting and classification critical for sustainable waste management and resource recovery. This study presents a hybrid vision-based pipeline that integrates deep feature extraction with classical machine learning (ML) classifiers for automated construction and demolition (C\&D) debris classification. A novel dataset comprising 1,800 balanced, high-quality images representing four material categories, Ceramic/Tile, Concrete, Trash/Waste, and Wood was collected from real construction sites in the UAE, capturing diverse real-world conditions. Deep features were extracted using a pre-trained Xception network, and multiple ML classifiers, including SVM, kNN, Bagged Trees, LDA, and Logistic Regression, were systematically evaluated. The results demonstrate that hybrid pipelines using Xception features with simple classifiers such as Linear SVM, kNN, and Bagged Trees achieve state-of-the-art performance, with up to 99.5\% accuracy and macro-F1 scores, surpassing more complex or end-to-end deep learning approaches. The analysis highlights the operational benefits of this approach for robust, field-deployable debris identification and provides pathways for future integration with robotics and onsite automation systems.

</details>


### [75] [MANGO: A Global Single-Date Paired Dataset for Mangrove Segmentation](https://arxiv.org/abs/2601.17039)
*Junhyuk Heo,Beomkyu Choi,Hyunjin Shin,Darongsae Kwon*

Main category: cs.CV

TL;DR: 本文介绍了MANGO，一个包含42,703个标注的图像-掩码对的全球数据集，用于解决现有数据集在规模、覆盖范围和可访问性方面的不足，并为全球红树林监测提供了一个基准。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在红树林监测方面存在不足，如年度地图产品缺乏单日期图像掩码对、区域限制和可访问性差，阻碍了深度学习在红树林检测中的应用。

Method: 通过检索2020年所有可用的Sentinel-2红树林区域影像，并利用目标检测驱动的方法，结合像素级坐标参考，选择与红树林年度掩码对齐的最佳单日期观测，构建了MANGO数据集。同时，在国家分离的分割下，对多种语义分割架构进行了基准测试。

Result: 构建了一个包含124个国家的42,703个标注图像-掩码对的大规模全球数据集MANGO。在提供的基准测试中，多样化的语义分割架构在MANGO数据集上表现良好。

Conclusion: MANGO数据集的推出为全球红树林监测奠定了基础，有望推动深度学习技术在红树林检测和保护方面的应用，并为未来研究提供可扩展的解决方案。

Abstract: Mangroves are critical for climate-change mitigation, requiring reliable monitoring for effective conservation. While deep learning has emerged as a powerful tool for mangrove detection, its progress is hindered by the limitations of existing datasets. In particular, many resources provide only annual map products without curated single-date image-mask pairs, limited to specific regions rather than global coverage, or remain inaccessible to the public. To address these challenges, we introduce MANGO, a large-scale global dataset comprising 42,703 labeled image-mask pairs across 124 countries. To construct this dataset, we retrieve all available Sentinel-2 imagery within the year 2020 for mangrove regions and select the best single-date observations that align with the mangrove annual mask. This selection is performed using a target detection-driven approach that leverages pixel-wise coordinate references to ensure adaptive and representative image-mask pairings. We also provide a benchmark across diverse semantic segmentation architectures under a country-disjoint split, establishing a foundation for scalable and reliable global mangrove monitoring.

</details>


### [76] [A Contrastive Pre-trained Foundation Model for Deciphering Imaging Noisomics across Modalities](https://arxiv.org/abs/2601.17047)
*Yuanjie Gu,Yiqun Wang,Chaohui Yu,Ang Xuan,Fan Wang,Zhi Lu,Biqin Dong*

Main category: cs.CV

TL;DR: 该研究提出了一种名为“Noisomics”的框架，利用对比预训练（CoP）基础模型来解码成像噪声，而不是抑制它。CoP能够在极少量数据（100个样本）上实现优于大量监督训练（100,000个样本）的性能，显著降低数据和计算需求，并展现出强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的成像噪声表征方法需要大量数据且依赖于特定设备，难以在不使用大规模监督数据集的情况下区分物理信号和算法伪影。研究旨在将噪声从单纯的干扰转变为信息资源。

Method: 利用流形假设和合成噪声基因组，通过对比学习（CoP模型）来区分语义信号和随机扰动。CoP打破了传统的深度学习缩放定律，能够在少量数据下表现出色。

Result: CoP模型仅使用100个训练样本，性能优于使用100,000个样本的监督基线。在12个不同的非领域数据集上进行了广泛测试，证实了其强大的零样本泛化能力，估计误差减少了63.8%，决定系数提高了85.1%。

Conclusion: CoP框架通过将噪声解码为多参数足迹，将随机退化重新定义为重要的信息资源，能够在无需设备预先校准的情况下实现精确的成像诊断，并可应用于从消费级摄影到深层组织显微镜等不同尺度。

Abstract: Characterizing imaging noise is notoriously data-intensive and device-dependent, as modern sensors entangle physical signals with complex algorithmic artifacts. Current paradigms struggle to disentangle these factors without massive supervised datasets, often reducing noise to mere interference rather than an information resource. Here, we introduce "Noisomics", a framework shifting the focus from suppression to systematic noise decoding via the Contrastive Pre-trained (CoP) Foundation Model. By leveraging the manifold hypothesis and synthetic noise genome, CoP employs contrastive learning to disentangle semantic signals from stochastic perturbations. Crucially, CoP breaks traditional deep learning scaling laws, achieving superior performance with only 100 training samples, outperforming supervised baselines trained on 100,000 samples, thereby reducing data and computational dependency by three orders of magnitude. Extensive benchmarking across 12 diverse out-of-domain datasets confirms its robust zero-shot generalization, demonstrating a 63.8% reduction in estimation error and an 85.1% improvement in the coefficient of determination compared to the conventional training strategy. We demonstrate CoP's utility across scales: from deciphering non-linear hardware-noise interplay in consumer photography to optimizing photon-efficient protocols for deep-tissue microscopy. By decoding noise as a multi-parametric footprint, our work redefines stochastic degradation as a vital information resource, empowering precise imaging diagnostics without prior device calibration.

</details>


### [77] [FP-THD: Full page transcription of historical documents](https://arxiv.org/abs/2601.17040)
*H Neji,J Nogueras-Iso,J Lacasta,MÁ Latre,FJ García-Marco*

Main category: cs.CV

TL;DR: 提出了一种结合版面分析和OCR的流水线，用于转录包含特殊字符的15-16世纪历史文献，并成功应用于手写、印刷和多语言文本。


<details>
  <summary>Details</summary>
Motivation: 转录15-16世纪拉丁语历史文献面临特殊挑战，需要保留具有特殊含义的字符和符号，以维持原文风格和意义。

Method: 通过版面分析模型提取文本行，然后将文本行输入OCR模型进行识别，最终实现页面完整数字化。使用了掩码自编码器来处理不同类型的文本。

Result: 该流水线能够有效地处理页面，并取得了高效的结果。所提出的方法能够处理手写、印刷和多语言文本。

Conclusion: 提出的结合版面分析和OCR的流水线能够有效地转录包含特殊字符的历史文献，并且对不同类型的文本具有良好的适应性。

Abstract: The transcription of historical documents written in Latin in XV and XVI centuries has special challenges as it must maintain the characters and special symbols that have distinct meanings to ensure that historical texts retain their original style and significance. This work proposes a pipeline for the transcription of historical documents preserving these special features. We propose to extend an existing text line recognition method with a layout analysis model. We analyze historical text images using a layout analysis model to extract text lines, which are then processed by an OCR model to generate a fully digitized page. We showed that our pipeline facilitates the processing of the page and produces an efficient result. We evaluated our approach on multiple datasets and demonstrate that the masked autoencoder effectively processes different types of text, including handwritten, printed and multi-language.

</details>


### [78] [Spatiotemporal Semantic V2X Framework for Cooperative Collision Prediction](https://arxiv.org/abs/2601.17216)
*Murat Arda Onsu,Poonam Lohan,Burak Kantarci,Aisha Syed,Matthew Andrews,Sean Kennedy*

Main category: cs.CV

TL;DR: 提出了一种基于语义V2X的框架，利用V-JEPA从RSU摄像头生成未来帧的语义嵌入，并通过V2X传输到车辆，以实现高效的实时碰撞预测，通信开销减少了四个数量级，同时F1分数提高了10%。


<details>
  <summary>Details</summary>
Motivation: 现有的智能交通系统（ITS）碰撞预测方法面临通信带宽和延迟限制，因为它们需要传输原始视频或高维传感器数据。研究旨在解决这一问题，以实现实时、安全的ITS。

Method: 利用安装在路边单元（RSU）上的摄像头，通过Video Joint Embedding Predictive Architecture (V-JEPA) 生成未来帧的时空语义嵌入。将这些语义嵌入通过V2X通信传输到车辆，车辆上的轻量级注意力探针和分类器解码这些嵌入以预测碰撞。

Result: 在数字孪生城市交通环境中进行了评估，发现所提出的框架可以将通信开销减少四个数量级，同时碰撞预测的F1分数提高10%，与原始视频传输相比。

Conclusion: 语义V2X通信具有潜力，可以实现ITS中协作式的、实时的碰撞预测，显著降低通信开销并提高预测准确性。

Abstract: Intelligent Transportation Systems (ITS) demand real-time collision prediction to ensure road safety and reduce accident severity. Conventional approaches rely on transmitting raw video or high-dimensional sensory data from roadside units (RSUs) to vehicles, which is impractical under vehicular communication bandwidth and latency constraints. In this work, we propose a semantic V2X framework in which RSU-mounted cameras generate spatiotemporal semantic embeddings of future frames using the Video Joint Embedding Predictive Architecture (V-JEPA). To evaluate the system, we construct a digital twin of an urban traffic environment enabling the generation of d verse traffic scenarios with both safe and collision events. These embeddings of the future frame, extracted from V-JEPA, capture task-relevant traffic dynamics and are transmitted via V2X links to vehicles, where a lightweight attentive probe and classifier decode them to predict imminent collisions. By transmitting only semantic embeddings instead of raw frames, the proposed system significantly reduces communication overhead while maintaining predictive accuracy. Experimental results demonstrate that the framework with an appropriate processing method achieves a 10% F1-score improvement for collision prediction while reducing transmission requirements by four orders of magnitude compared to raw video. This validates the potential of semantic V2X communication to enable cooperative, real-time collision prediction in ITS.

</details>


### [79] [Arabic Sign Language Recognition using Multimodal Approach](https://arxiv.org/abs/2601.17041)
*Ghadeer Alanazi,Abir Benabid*

Main category: cs.CV

TL;DR: 本研究提出一种结合Leap Motion和RGB摄像头数据的多模态方法来识别阿拉伯手语（ArSL），实验结果显示18个单词中有13个能被正确识别，总体准确率为78%，为手语识别的多模态融合提供了初步证据。


<details>
  <summary>Details</summary>
Motivation: 现有的阿拉伯手语识别系统依赖单一传感器（如Leap Motion或RGB摄像头），在复杂手部姿态跟踪和三维手部运动识别方面存在局限性。

Method: 提出一种多模态方法，结合Leap Motion和RGB摄像头数据。系统包含两个并行子网络：一个用于Leap Motion数据的自定义密集神经网络，以及一个基于微调的VGG16模型的图像子网络。两个模态的特征表示被连接（concatenated）到一个融合模型中，并通过全连接层进行处理，最终使用SoftMax激活进行分类。

Result: 在包含18个ArSL单词的自定义数据集上进行评估，系统正确识别了13个单词，总体准确率为78%。

Conclusion: 多模态融合方法对于手语识别是可行的，并为进一步的优化和数据集扩展指明了方向。

Abstract: Arabic Sign Language (ArSL) is an essential communication method for individuals in the Deaf and Hard-of-Hearing community. However, existing recognition systems face significant challenges due to their reliance on single sensor approaches like Leap Motion or RGB cameras. These systems struggle with limitations such as inadequate tracking of complex hand orientations and imprecise recognition of 3D hand movements. This research paper aims to investigate the potential of a multimodal approach that combines Leap Motion and RGB camera data to explore the feasibility of recognition of ArSL. The system architecture includes two parallel subnetworks: a custom dense neural network for Leap Motion data, incorporating dropout and L2 regularization, and an image subnetwork based on a fine-tuned VGG16 model enhanced with data augmentation techniques. Feature representations from both modalities are concatenated in a fusion model and passed through fully connected layers, with final classification performed via SoftMax activation to analyze spatial and temporal features of hand gestures. The system was evaluated on a custom dataset comprising 18 ArSL words, of which 13 were correctly recognized, yielding an overall accuracy of 78%. These results offer preliminary insights into the viability of multimodal fusion for sign language recognition and highlight areas for further optimization and dataset expansion.

</details>


### [80] [Stylizing ViT: Anatomy-Preserving Instance Style Transfer for Domain Generalization](https://arxiv.org/abs/2601.17586)
*Sebastian Doerrich,Francesco Di Salvo,Jonas Alle,Christian Ledig*

Main category: cs.CV

TL;DR: 本文提出了一种名为Stylizing ViT的新型Vision Transformer模型，通过使用共享权重的自注意力和交叉注意力机制，在医学图像分析中实现了更好的领域泛化能力，并有效减少了伪影。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医学图像分析中普遍存在跨域和跨人群的泛化能力不足的问题，现有数据增强方法在面对较大领域迁移时效果有限，而风格化增强方法又存在风格多样性不足或产生伪影的问题。

Method: 提出了一种名为Stylizing ViT的新型Vision Transformer编码器，其特点是使用权重共享的注意力块，分别用于自注意力和交叉注意力。这使得同一个注意力块能够通过自注意力保持解剖结构的一致性，并通过交叉注意力实现风格迁移。该模型被用于数据增强，在三种不同的组织病理学和皮肤病学图像分类任务上进行评估。

Result: Stylizing ViT在三种任务上均显示出优于现有最先进方法的鲁棒性，准确率最高可提高13%。生成的图像在感知上具有说服力且无伪影。此外，该模型在推理阶段作为测试时增强，也能带来17%的性能提升。

Conclusion: Stylizing ViT是一种有效的模型，通过结合自注意力和交叉注意力，可以提升医学图像分析的领域泛化能力，并能在训练和推理阶段提供显著的性能改进，同时避免了伪影问题。

Abstract: Deep learning models in medical image analysis often struggle with generalizability across domains and demographic groups due to data heterogeneity and scarcity. Traditional augmentation improves robustness, but fails under substantial domain shifts. Recent advances in stylistic augmentation enhance domain generalization by varying image styles but fall short in terms of style diversity or by introducing artifacts into the generated images. To address these limitations, we propose Stylizing ViT, a novel Vision Transformer encoder that utilizes weight-shared attention blocks for both self- and cross-attention. This design allows the same attention block to maintain anatomical consistency through self-attention while performing style transfer via cross-attention. We assess the effectiveness of our method for domain generalization by employing it for data augmentation on three distinct image classification tasks in the context of histopathology and dermatology. Results demonstrate an improved robustness (up to +13% accuracy) over the state of the art while generating perceptually convincing images without artifacts. Additionally, we show that Stylizing ViT is effective beyond training, achieving a 17% performance improvement during inference when used for test-time augmentation. The source code is available at https://github.com/sdoerrich97/stylizing-vit .

</details>


### [81] [Interpretable and Sparse Linear Attention with Decoupled Membership-Subspace Modeling via MCR2 Objective](https://arxiv.org/abs/2601.17042)
*Tianyuan Liu,Libin Hou,Linyuan Wang,Bin Yan*

Main category: cs.CV

TL;DR: 本文提出了一种解耦MCR2中“成员矩阵”和“子空间矩阵U”的新方法，名为DMSA，并将其应用于Transformer模型（DMST）。实验表明，DMST在提高编码约简率的同时，在ImageNet-1K数据集上实现了更高的准确率，并提供了更好的计算效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有MCR2方法中“成员矩阵”和“子空间矩阵U”的紧密耦合会导致在token投影错误时产生冗余编码，影响模型性能。因此，需要解耦这两个矩阵以提高MCR2的效率和可靠性。

Method: 研究人员解耦了MCR2目标函数中“成员矩阵”和“子空间U”的功能关系，并通过对优化目标进行梯度下降展开，推导出了一个可解释的稀疏线性注意力算子DMSA。具体而言，直接从输入学习成员矩阵，然后从满空间S导出稀疏子空间。

Result: 将DMSA替换Token Statistics Transformer (ToST)中的注意力模块，得到的DMST模型实现了更快的编码约简率，并在ImageNet-1K数据集上比ToST的top-1准确率高出1.08%-1.45%。与传统的Transformer架构相比，DMST在计算效率和可解释性方面表现出显著优势。

Conclusion: DMSA通过解耦成员矩阵和子空间，成功构建了一个可解释的稀疏线性注意力算子，并在视觉任务中展现出优越的性能和效率。DMST模型在准确率、计算速度和可解释性方面均优于现有方法。

Abstract: Maximal Coding Rate Reduction (MCR2)-driven white-box transformer, grounded in structured representation learning, unifies interpretability and efficiency, providing a reliable white-box solution for visual modeling. However, in existing designs, tight coupling between "membership matrix" and "subspace matrix U" in MCR2 causes redundant coding under incorrect token projection. To this end, we decouple the functional relationship between the "membership matrix" and "subspaces U" in the MCR2 objective and derive an interpretable sparse linear attention operator from unrolled gradient descent of the optimized objective. Specifically, we propose to directly learn the membership matrix from inputs and subsequently derive sparse subspaces from the fullspace S. Consequently, gradient unrolling of the optimized MCR2 objective yields an interpretable sparse linear attention operator: Decoupled Membership-Subspace Attention (DMSA). Experimental results on visual tasks show that simply replacing the attention module in Token Statistics Transformer (ToST) with DMSA (we refer to as DMST) not only achieves a faster coding reduction rate but also outperforms ToST by 1.08%-1.45% in top-1 accuracy on the ImageNet-1K dataset. Compared with vanilla Transformer architectures, DMST exhibits significantly higher computational efficiency and interpretability.

</details>


### [82] [Atomic Depth Estimation From Noisy Electron Microscopy Data Via Deep Learning](https://arxiv.org/abs/2601.17046)
*Matan Leibovich,Mai Tan,Adria Marcos-Morales,Sreyas Mohan,Peter A. Crozier,Carlos Fernandez-Granda*

Main category: cs.CV

TL;DR: 提出一种将三维原子信息提取的深度估计问题转化为语义分割问题的新方法，并使用深度卷积神经网络解决，在模拟数据和真实TEM数据上均表现出准确、校准良好且对噪声鲁棒的深度估计结果。


<details>
  <summary>Details</summary>
Motivation: 从受噪声严重影响的透射电子显微镜（TEM）图像中提取三维原子级信息。

Method: 将深度估计问题表述为语义分割问题，并训练深度卷积神经网络（CNN）生成像素级深度分割图。使用模拟数据（加入合成噪声）进行训练，并应用于模拟和真实TEM数据。

Result: 提出的方法在CeO2纳米粒子上进行了测试，实验结果表明生成的深度估计准确、校准良好且对噪声鲁棒。

Conclusion: 该方法能够从高噪声的TEM图像中准确地提取三维原子级深度信息，为分析原子结构提供了新的途径。

Abstract: We present a novel approach for extracting 3D atomic-level information from transmission electron microscopy (TEM) images affected by significant noise. The approach is based on formulating depth estimation as a semantic segmentation problem. We address the resulting segmentation problem by training a deep convolutional neural network to generate pixel-wise depth segmentation maps using simulated data corrupted by synthetic noise. The proposed method was applied to estimate the depth of atomic columns in CeO2 nanoparticles from simulated images and real-world TEM data. Our experiments show that the resulting depth estimates are accurate, calibrated and robust to noise.

</details>


### [83] [SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis](https://arxiv.org/abs/2601.17048)
*Jing Jie Tan,Rupert Schreiner,Matthias Hausladen,Ali Asgharzade,Simon Edler,Julian Bartsch,Michael Bachmann,Andreas Schels,Ban-Hoe Kwan,Danny Wee-Kiat Ng,Yan-Chai Hum*

Main category: cs.CV

TL;DR: 本研究提出了一种名为SiMiC的基于深度学习（注意力机制卷积神经网络）的方法，用于自动表征硅微结构（特别是场发射尖端），以提高效率和一致性，并与场发射性能相关联。


<details>
  <summary>Details</summary>
Motivation: 传统的硅微结构表征方法（如SEM）依赖于耗时且主观的人工评估，这限制了吞吐量和可重复性。研究旨在通过自动化方法克服这些限制，并建立微结构几何形状与场发射性能之间的联系。

Method: 开发了一个包含硅基场发射尖端图像的专业数据集。使用定制的、带有注意力机制的卷积神经网络（CNN）进行训练，以实现微结构的多类别分类和尺寸预测。将所提方法与经典图像处理技术进行了比较。

Result: SiMiC方法能够高效地提取形态学特征（尺寸、形状、曲率），显著减少人工干预，提高测量一致性。与传统方法相比，SiMiC在保持可解释性的同时实现了高精度。

Conclusion: SiMiC框架为数据驱动的微结构分析奠定了基础，能够直接关联场发射性能，为优化冷阴极和SEM电子源的设计提供了指导。

Abstract: Accurate characterization of silicon microstructures is essential for advancing microscale fabrication, quality control, and device performance. Traditional analysis using Scanning Electron Microscopy (SEM) often requires labor-intensive, manual evaluation of feature geometry, limiting throughput and reproducibility. In this study, we propose SiMiC: Context-Aware Silicon Microstructure Characterization Using Attention-Based Convolutional Neural Networks for Field-Emission Tip Analysis. By leveraging deep learning, our approach efficiently extracts morphological features-such as size, shape, and apex curvature-from SEM images, significantly reducing human intervention while improving measurement consistency. A specialized dataset of silicon-based field-emitter tips was developed, and a customized CNN architecture incorporating attention mechanisms was trained for multi-class microstructure classification and dimensional prediction. Comparative analysis with classical image processing techniques demonstrates that SiMiC achieves high accuracy while maintaining interpretability. The proposed framework establishes a foundation for data-driven microstructure analysis directly linked to field-emission performance, opening avenues for correlating emitter geometry with emission behavior and guiding the design of optimized cold-cathode and SEM electron sources. The related dataset and algorithm repository that could serve as a baseline in this area can be found at https://research.jingjietan.com/?q=SIMIC

</details>


### [84] [Summary of the Unusual Activity Recognition Challenge for Developmental Disability Support](https://arxiv.org/abs/2601.17049)
*Christina Garcia,Nhat Tan Le,Taihei Fujioka,Umang Dobhal,Milyun Ni'ma Shoumi,Thanh Nha Nguyen,Sozo Inoue*

Main category: cs.CV

TL;DR: 本次挑战赛旨在利用姿态估计算法识别发育障碍个体设施中的异常行为，并提供了一个包含真实世界数据不平衡和时间不规则性的数据集，结果表明在稀有、突发动作识别方面仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 开发自动化系统以识别发育障碍个体设施中的异常行为，以满足对非侵入性行为监测的需求，并推动负责任的AI在医疗保健领域的应用。

Method: 利用从视频中提取的骨骼关键点数据，训练模型区分正常和异常行为。采用留一受试者（LOSO）策略进行评估，并使用宏平均F1分数作为主要评估指标。

Result: 40支队伍参与了比赛，采用了多种方法（从经典机器学习到深度学习）。结果显示，在嘈杂、低维数据中对稀有、突发动作进行建模具有挑战性，需要同时捕捉行为的时间和上下文信息。

Conclusion: 行为识别，特别是异常行为的识别，需要对时间动态和上下文有深入的理解。本次挑战赛为未来在医疗保健和行为监测领域开发负责任的AI应用提供了宝贵的见解。

Abstract: This paper presents an overview of the Recognize the Unseen: Unusual Behavior Recognition from Pose Data Challenge, hosted at ISAS 2025. The challenge aims to address the critical need for automated recognition of unusual behaviors in facilities for individuals with developmental disabilities using non-invasive pose estimation data. Participating teams were tasked with distinguishing between normal and unusual activities based on skeleton keypoints extracted from video recordings of simulated scenarios. The dataset reflects real-world imbalance and temporal irregularities in behavior, and the evaluation adopted a Leave-One-Subject-Out (LOSO) strategy to ensure subject-agnostic generalization. The challenge attracted broad participation from 40 teams applying diverse approaches ranging from classical machine learning to deep learning architectures. Submissions were assessed primarily using macro-averaged F1 scores to account for class imbalance. The results highlight the difficulty of modeling rare, abrupt actions in noisy, low-dimensional data, and emphasize the importance of capturing both temporal and contextual nuances in behavior modeling. Insights from this challenge may contribute to future developments in socially responsible AI applications for healthcare and behavior monitoring.

</details>


### [85] [Single-Pixel Vision-Language Model for Intrinsic Privacy-Preserving Behavioral Intelligence](https://arxiv.org/abs/2601.17050)
*Hongjun An,Yiliang Song,Jiawei Shao,Zhe Sun,Xuelong Li*

Main category: cs.CV

TL;DR: 提出了一种名为SP-VLM的新型框架，利用低维度的单像素传感器捕捉人类动态，并通过视觉-语言模型进行行为分析，实现在保护隐私的前提下进行异常检测、人数统计和活动理解。


<details>
  <summary>Details</summary>
Motivation: 传统的监控方式在洗手间、更衣室等隐私敏感区域受到隐私法规和伦理的限制，无法有效监测欺凌、骚扰等不良行为，而这些行为对个人福祉和公共安全构成严重威胁。

Method: 使用低维度的单像素传感器捕获人类动态，然后利用集成视觉-语言模型（VLM）来推断复杂的行为模式。该方法通过降低采样率来抑制身份可识别性，同时保留提取行为语义的能力。

Result: 实验证明，在低于临界采样率时，人脸识别系统失效，身份信息无法恢复。同时，SP-VLM仍能从降级的单像素观测中提取有意义的行为语义，实现鲁棒的异常检测、人数统计和活动理解。研究确定了一个实际的采样率范围，在此范围内可以实现行为智能并有效保护个人身份。

Conclusion: SP-VLM提供了一种符合人权的网络安全监控新途径，可以在不侵犯隐私的情况下，在隐私敏感区域支持及时干预，从而保障个人福祉和公共安全。

Abstract: Adverse social interactions, such as bullying, harassment, and other illicit activities, pose significant threats to individual well-being and public safety, leaving profound impacts on physical and mental health. However, these critical events frequently occur in privacy-sensitive environments like restrooms, and changing rooms, where conventional surveillance is prohibited or severely restricted by stringent privacy regulations and ethical concerns. Here, we propose the Single-Pixel Vision-Language Model (SP-VLM), a novel framework that reimagines secure environmental monitoring. It achieves intrinsic privacy-by-design by capturing human dynamics through inherently low-dimensional single-pixel modalities and inferring complex behavioral patterns via seamless vision-language integration. Building on this framework, we demonstrate that single-pixel sensing intrinsically suppresses identity recoverability, rendering state-of-the-art face recognition systems ineffective below a critical sampling rate. We further show that SP-VLM can nonetheless extract meaningful behavioral semantics, enabling robust anomaly detection, people counting, and activity understanding from severely degraded single-pixel observations. Combining these findings, we identify a practical sampling-rate regime in which behavioral intelligence emerges while personal identity remains strongly protected. Together, these results point to a human-rights-aligned pathway for safety monitoring that can support timely intervention without normalizing intrusive surveillance in privacy-sensitive spaces.

</details>


### [86] [Synthetic Data Guided Feature Selection for Robust Activity Recognition in Older Adults](https://arxiv.org/abs/2601.17053)
*Shuhao Que,Dieuwke van Dartel,Ilse Heeringa,Han Hegeman,Miriam Vollenbroek-Hutten,Ying Wang*

Main category: cs.CV

TL;DR: 本研究开发了一种用于老年人髋部骨折康复期间的运动识别系统，使用双加速计并通过合成数据增强模型，显著提高了活动识别的准确性，尤其是在姿势转移方面。


<details>
  <summary>Details</summary>
Motivation: 目前临床实践中很少量化老年髋部骨折患者的身体活动，现有的穿戴设备对老年人步态模式的识别不够可靠，因此需要一个更稳健的运动识别系统。

Method: 纳入24名80岁以上健康老年人，在模拟的自由生活条件下，佩戴置于下背部和股骨前侧的双加速计，进行日常活动（行走、站立、坐下、躺下和姿势转移）的监测。利用合成数据增强模型，并通过留一法交叉验证评估模型鲁棒性。

Result: 开发出的特征干预模型（FIM）在合成数据指导下，实现了高精度的活动识别，各活动类别的平均F1分数分别为：行走0.896，站立0.927，坐下0.997，躺下0.937，姿势转移0.816。与未使用合成数据的模型相比，FIM显著提高了姿势转移的检测准确性。

Conclusion: 本研究初步证明了在老年人中实现稳健活动识别的可行性，并提出了一种有临床意义的监测系统。未来需要进一步在髋部骨折患者群体中验证其临床效用。

Abstract: Physical activity during hip fracture rehabilitation is essential for mitigating long-term functional decline in geriatric patients. However, it is rarely quantified in clinical practice. Existing continuous monitoring systems with commercially available wearable activity trackers are typically developed in middle-aged adults and therefore perform unreliably in older adults with slower and more variable gait patterns. This study aimed to develop a robust human activity recognition (HAR) system to improve continuous physical activity recognition in the context of hip fracture rehabilitation. 24 healthy older adults aged over 80 years were included to perform activities of daily living (walking, standing, sitting, lying down, and postural transfers) under simulated free-living conditions for 75 minutes while wearing two accelerometers positioned on the lower back and anterior upper thigh. Model robustness was evaluated using leave-one-subject-out cross-validation. The synthetic data demonstrated potential to improve generalization across participants. The resulting feature intervention model (FIM), aided by synthetic data guidance, achieved reliable activity recognition with mean F1-scores of 0.896 for walking, 0.927 for standing, 0.997 for sitting, 0.937 for lying down, and 0.816 for postural transfers. Compared with a control condition model without synthetic data, the FIM significantly improved the postural transfer detection, i.e., an activity class of high clinical relevance that is often overlooked in existing HAR literature. In conclusion, these preliminary results demonstrate the feasibility of robust activity recognition in older adults. Further validation in hip fracture patient populations is required to assess the clinical utility of the proposed monitoring system.

</details>


### [87] [Ego4OOD: Rethinking Egocentric Video Domain Generalization via Covariate Shift Scoring](https://arxiv.org/abs/2601.17056)
*Zahra Vaseqi,James Clark*

Main category: cs.CV

TL;DR: 该论文提出了一个名为Ego4OOD的领域泛化基准，用于解决自我中心视频动作识别中的领域偏移问题，并引入了一种基于聚类的协变量偏移度量和一种一对多的二元训练目标，该方法在基准测试中表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有的自我中心领域泛化基准未能有效地区分协变量偏移和概念偏移，导致对模型跨输入分布泛化能力评估不足。因此，需要一个更可靠的基准来解决这个问题。

Method: 提出了Ego4OOD基准，它源自Ego4D，强调协变量多样性并减少概念偏移。引入了一种基于聚类的协变量偏移度量来量化领域难度。采用了一对多的二元训练目标，将多类动作识别分解为独立的二元分类任务。

Result: 所提出的方法，包括轻量级的全连接网络和二元训练目标，在Argo1M和Ego4OOD基准上取得了与最先进的自我中心领域泛化方法相当的性能，并且参数更少。度量的协变量偏移与识别性能之间存在明确的关系。

Conclusion: Ego4OOD基准和量化的领域特征对于研究自我中心视频的域外泛化至关重要。所提出的方法在应对协变量偏移方面有效，并且能够实现具有竞争力的性能。

Abstract: Egocentric video action recognition under domain shifts remains challenging due to large intra-class spatio-temporal variability, long-tailed feature distributions, and strong correlations between actions and environments. Existing benchmarks for egocentric domain generalization often conflate covariate shifts with concept shifts, making it difficult to reliably evaluate a model's ability to generalize across input distributions. To address this limitation, we introduce Ego4OOD, a domain generalization benchmark derived from Ego4D that emphasizes measurable covariate diversity while reducing concept shift through semantically coherent, moment-level action categories. Ego4OOD spans eight geographically distinct domains and is accompanied by a clustering-based covariate shift metric that provides a quantitative proxy for domain difficulty. We further leverage a one-vs-all binary training objective that decomposes multi-class action recognition into independent binary classification tasks. This formulation is particularly well-suited for covariate shift by reducing interference between visually similar classes under feature distribution shift. Using this formulation, we show that a lightweight two-layer fully connected network achieves performance competitive with state-of-the-art egocentric domain generalization methods on both Argo1M and Ego4OOD, despite using fewer parameters and no additional modalities. Our empirical analysis demonstrates a clear relationship between measured covariate shift and recognition performance, highlighting the importance of controlled benchmarks and quantitative domain characterization for studying out-of-distribution generalization in egocentric video.

</details>


### [88] [A Computer Vision Pipeline for Iterative Bullet Hole Tracking in Rifle Zeroing](https://arxiv.org/abs/2601.17062)
*Robert M. Belcher,Brendan C. Degryse,Leonard R. Kosta,Christopher J. Lowrance*

Main category: cs.CV

TL;DR: 本文提出了一种基于计算机视觉的自动识别和跟踪弹孔的系统，用于步枪瞄准校准，提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的步枪瞄准校准过程（“归零”）依赖于人工检查弹孔，效率低下且易出错。作者希望通过自动化方法来解决这些问题。

Method: 该系统结合了 YOLOv8 进行弹孔检测，并使用 IoU 分析来区分不同发射轮次的弹孔。为了解决数据稀缺问题，提出了一种新的数据增强方法（移除物体而非添加）。此外，还引入了基于 ORB 的透视校正预处理流水线来标准化靶标方向。

Result: 该系统在弹孔检测方面达到了 97.0% 的平均精度 (mAP)，在将弹孔分配到正确的发射轮次方面达到了 88.8% 的准确率。

Conclusion: 所提出的计算机视觉系统能够准确高效地自动识别和跟踪弹孔，为步枪归零过程提供了有价值的解决方案，并具有在其他需要区分相似时间序列对象的领域中应用的潜力。

Abstract: Adjusting rifle sights, a process commonly called "zeroing," requires shooters to identify and differentiate bullet holes from multiple firing iterations. Traditionally, this process demands physical inspection, introducing delays due to range safety protocols and increasing the risk of human error. We present an end-to-end computer vision system for automated bullet hole detection and iteration-based tracking directly from images taken at the firing line. Our approach combines YOLOv8 for accurate small-object detection with Intersection over Union (IoU) analysis to differentiate bullet holes across sequential images. To address the scarcity of labeled sequential data, we propose a novel data augmentation technique that removes rather than adds objects to simulate realistic firing sequences. Additionally, we introduce a preprocessing pipeline that standardizes target orientation using ORB-based perspective correction, improving model accuracy. Our system achieves 97.0% mean average precision on bullet hole detection and 88.8% accuracy in assigning bullet holes to the correct firing iteration. While designed for rifle zeroing, this framework offers broader applicability in domains requiring the temporal differentiation of visually similar objects.

</details>


### [89] [A Mechanistic View on Video Generation as World Models: State and Dynamics](https://arxiv.org/abs/2601.17067)
*Luozhou Wang,Zhifei Chen,Yihua Du,Dongyu Yan,Wenhang Ge,Guibao Shen,Xinli Xu,Leyi Wu,Man Chen,Tianshuo Xu,Peiran Ren,Xin Tao,Pengfei Wan,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种新的视频生成模型分类法，以弥合无状态视频模型与传统世界模型理论之间的差距，并建议将评估重点从视觉保真度转向功能基准，以实现更强大的世界模拟器。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模视频生成模型虽然展现出物理一致性，但其“无状态”架构与经典状态中心世界模型理论之间存在差距。

Method: 提出了一种新的分类法，分为“状态构建”（隐式上下文管理和显式潜在压缩）和“动态建模”（知识整合和架构重构）两个支柱。还提议从视觉保真度转向功能性基准（物理持续性和因果推理）进行评估。

Result: 识别出两个关键前沿：通过数据驱动的记忆和压缩保真度增强物理持续性，以及通过潜在因子解耦和推理先验整合来推进因果推理。

Conclusion: 通过解决这些挑战，视频生成领域可以从生成视觉上可信的视频发展到构建通用、强大的世界模拟器。

Abstract: Large-scale video generation models have demonstrated emergent physical coherence, positioning them as potential world models. However, a gap remains between contemporary "stateless" video architectures and classic state-centric world model theories. This work bridges this gap by proposing a novel taxonomy centered on two pillars: State Construction and Dynamics Modeling. We categorize state construction into implicit paradigms (context management) and explicit paradigms (latent compression), while dynamics modeling is analyzed through knowledge integration and architectural reformulation. Furthermore, we advocate for a transition in evaluation from visual fidelity to functional benchmarks, testing physical persistence and causal reasoning. We conclude by identifying two critical frontiers: enhancing persistence via data-driven memory and compressed fidelity, and advancing causality through latent factor decoupling and reasoning-prior integration. By addressing these challenges, the field can evolve from generating visually plausible videos to building robust, general-purpose world simulators.

</details>


### [90] [Superpixel-Based Image Segmentation Using Squared 2-Wasserstein Distances](https://arxiv.org/abs/2601.17071)
*Jisui Huang,Andreas Alpers,Ke Chen,Na Lei*

Main category: cs.CV

TL;DR: 提出一种新的两级图像分割方法，先用线性最小二乘法（一种离散最优传输问题）将像素聚合成超像素，再用2-Wasserstein距离合并超像素，提高了分割精度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决强不均匀性图像分割的挑战，并提供一种统一的数学框架。

Method: 采用两级聚类方法：1. 通过解决线性最小二乘赋值问题（离散最优传输问题的一种特例）将像素分组为超像素；2. 利用经验分布的平方2-Wasserstein距离，贪婪地将超像素合并为对象级分割。

Result: 该方法在具有挑战性的图像上实现了更高的分割精度，同时保持了高计算效率。与基于平均颜色距离的传统方法相比，通过使用分布式的最优传输距离，在两个聚类级别上实现了数学上的统一。

Conclusion: 基于分布式的最优传输距离的两级聚类方法能够有效地处理强不均匀性图像的分割问题，并在精度和效率上优于现有方法。

Abstract: We present an efficient method for image segmentation in the presence of strong inhomogeneities. The approach can be interpreted as a two-level clustering procedure: pixels are first grouped into superpixels via a linear least-squares assignment problem, which can be viewed as a special case of a discrete optimal transport (OT) problem, and these superpixels are subsequently greedily merged into object-level segments using the squared 2-Wasserstein distance between their empirical distributions. In contrast to conventional superpixel merging strategies based on mean-color distances, our framework employs a distributional OT distance, yielding a mathematically unified formulation across both clustering levels. Numerical experiments demonstrate that this perspective leads to improved segmentation accuracy on challenging images while retaining high computational efficiency.

</details>


### [91] [GlassesGB: Controllable 2D GAN-Based Eyewear Personalization for 3D Gaussian Blendshapes Head Avatars](https://arxiv.org/abs/2601.17088)
*Rui-Yang Ju,Jen-Shiun Chiang*

Main category: cs.CV

TL;DR: 提出了一种名为GlassesGB的框架，用于为3D头部化身生成可定制的眼镜，将2D的个性化设计与3D渲染相结合，以支持VR应用。


<details>
  <summary>Details</summary>
Motivation: 现有的虚拟试戴系统（VTON）通常仅限于预定义的眼镜模板，无法进行细粒度的用户驱动定制。虽然GlassesGAN支持2D个性化眼镜设计，但其能力仅限于2D图像。研究者受到3D高斯混合形状在头部重建中成功的启发，希望将其应用于3D可定制眼镜生成。

Method: 将3D高斯混合形状（3D Gaussian Blendshapes）与2D个性化眼镜设计技术相结合，提出GlassesGB框架。该框架能够实现2D生成性定制与3D头部化身渲染之间的桥梁，从而支持VR应用中的个性化眼镜设计。

Result: 成功地为3D头部化身生成了可定制的眼镜，有效解决了在VR应用中实现个性化眼镜设计的挑战。

Conclusion: GlassesGB框架通过整合2D生成性定制和3D头部化身渲染，为VR应用提供了支持可定制眼镜生成的新方法，克服了现有方法的局限性。

Abstract: Virtual try-on systems allow users to interactively try different products within VR scenarios. However, most existing VTON methods operate only on predefined eyewear templates and lack support for fine-grained, user-driven customization. While GlassesGAN enables personalized 2D eyewear design, its capability remains limited to 2D image generation. Motivated by the success of 3D Gaussian Blendshapes in head reconstruction, we integrate these two techniques and propose GlassesGB, a framework that supports customizable eyewear generation for 3D head avatars. GlassesGB effectively bridges 2D generative customization with 3D head avatar rendering, addressing the challenge in achieving personalized eyewear design for VR applications. The implementation code is available at https://ruiyangju.github.io/GlassesGB.

</details>


### [92] [GRASP: Guided Region-Aware Sparse Prompting for Adapting MLLMs to Remote Sensing](https://arxiv.org/abs/2601.17089)
*Qigan Sun,Chaoning Zhang,Jianwei Zhang,Xudong Wang,Jiehui Xie,Pengcheng Zheng,Haoyu Wang,Sungyoung Lee,Chi-lok Andy Tai,Yang Yang,Heng Tao Shen*

Main category: cs.CV

TL;DR: 提出了一种名为GRASP的参数高效微调（PEFT）策略，用于解决多模态大语言模型（MLLMs）在遥感（RS）图像问答任务中存在的过拟合和忽视细节问题，该策略通过引导区域感知稀疏提示，动态聚合任务相关上下文到全局提示中，提高了模型在RSVQA基准上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs直接应用于遥感图像问答任务时，由于遥感图像固有的尺度变化大、目标稀疏、区域语义复杂等特点，容易出现过拟合背景噪声或忽视目标细节的问题，限制了MLLMs在遥感领域的有效性。

Method: 提出了一种名为GRASP（Guided Region-Aware Sparse Prompting）的参数高效微调（PEFT）策略。GRASP引入了与冻结视觉令牌网格中提取的空间块相关联的空间结构化软提示。通过一个问题引导的稀疏融合机制，GRASP动态地将任务特定的上下文聚合到一个紧凑的全局提示中。

Result: 在多个RSVQA基准上的大量实验表明，GRASP在保持高参数效率的同时，与现有的微调和基于提示的方法相比，取得了具有竞争力的性能。

Conclusion: GRASP是一种有效的参数高效微调策略，能够解决MLLMs在遥感图像问答任务中面临的挑战，通过引导模型关注相关区域并过滤背景噪声，提高了遥感视觉问答的性能。

Abstract: In recent years, Multimodal Large Language Models (MLLMs) have made significant progress in visual question answering tasks. However, directly applying existing fine-tuning methods to remote sensing (RS) images often leads to issues such as overfitting on background noise or neglecting target details. This is primarily due to the large-scale variations, sparse target distributions, and complex regional semantic features inherent in RS images. These challenges limit the effectiveness of MLLMs in RS tasks. To address these challenges, we propose a parameter-efficient fine-tuning (PEFT) strategy called Guided Region-Aware Sparse Prompting (GRASP). GRASP introduces spatially structured soft prompts associated with spatial blocks extracted from a frozen visual token grid. Through a question-guided sparse fusion mechanism, GRASP dynamically aggregates task-specific context into a compact global prompt, enabling the model to focus on relevant regions while filtering out background noise. Extensive experiments on multiple RSVQA benchmarks show that GRASP achieves competitive performance compared to existing fine-tuning and prompt-based methods while maintaining high parameter efficiency.

</details>


### [93] [LoD Sketch Extraction from Architectural Models Using Generative AI: Dataset Construction for Multi-Level Architectural Design Generation](https://arxiv.org/abs/2601.17095)
*Xusheng Du,Athiwat Kongkaeo,Ye Zhang,Haoran Xie*

Main category: cs.CV

TL;DR: 该研究提出了一种利用生成式AI自动从高细节建筑模型中提取不同细节层次（LoD）草图的框架，以解决手动创建LoD数据耗时且易出错的问题，并为AI驱动的建筑建模提供支持。


<details>
  <summary>Details</summary>
Motivation: 传统的LoD建模过程耗时、劳动密集且容易出现几何不一致。现有的生成式AI模型在从草图生成多LoD模型方面受到高质量配对LoD训练数据不足的限制。

Method: 该框架集成了计算机视觉技术和生成式AI方法，建立了一个从高细节模型逐步简化为体积抽象的提取流程，以自动生成几何上一致且层次上连贯的多LoD表示。

Result: 实验结果表明，该方法在LoD级别之间保持了良好的几何一致性。从LoD3到LoD2的SSIM值为0.7319，从LoD2到LoD1的SSIM值为0.7532。相应的归一化Hausdorff距离分别为图像对角线的25.1%和61.0%，表明抽象过程中几何偏差受控。

Conclusion: 所提出的框架能够有效地保留全局结构，并在不同LoD级别之间实现渐进的语义简化，为AI驱动的多级建筑生成和分层建模提供了可靠的数据和技术支持。

Abstract: For architectural design, representation across multiple Levels of Details (LoD) is essential for achieving a smooth transition from conceptual massing to detailed modeling. However, traditional LoD modeling processes rely on manual operations that are time-consuming, labor-intensive, and prone to geometric inconsistencies. While the rapid advancement of generative artificial intelligence (AI) has opened new possibilities for generating multi-level architectural models from sketch inputs, its application remains limited by the lack of high-quality paired LoD training data. To address this issue, we propose an automatic LoD sketch extraction framework using generative AI models, which progressively simplifies high-detail architectural models to automatically generate geometrically consistent and hierarchically coherent multi-LoD representations. The proposed framework integrates computer vision techniques with generative AI methods to establish a progressive extraction pipeline that transitions from detailed representations to volumetric abstractions. Experimental results demonstrate that the method maintains strong geometric consistency across LoD levels, achieving SSIM values of 0.7319 and 0.7532 for the transitions from LoD3 to LoD2 and from LoD2 to LoD1, respectively, with corresponding normalized Hausdorff distances of 25.1% and 61.0% of the image diagonal, reflecting controlled geometric deviation during abstraction. These results verify that the proposed framework effectively preserves global structure while achieving progressive semantic simplification across different LoD levels, providing reliable data and technical support for AI-driven multi-level architectural generation and hierarchical modeling.

</details>


### [94] [Performance uncertainty in medical image analysis: a large-scale investigation of confidence intervals](https://arxiv.org/abs/2601.17103)
*Pascaline André,Charles Heitz,Evangelia Christodoulou,Annika Reinke,Carole H. Sudre,Michela Antonelli,Patrick Godau,M. Jorge Cardoso,Antoine Gilson,Sophie Tezenas du Montcel,Gaël Varoquaux,Lena Maier-Hein,Olivier Colliot*

Main category: cs.CV

TL;DR: 该研究对用于评估医学影像 AI 性能不确定性的多种置信区间（CI）方法进行了大规模实证分析，发现 CI 的可靠性和精确度受样本量、性能指标、聚合策略和机器学习问题类型的影响，并强调不同 CI 方法在不同场景下的表现各异。


<details>
  <summary>Details</summary>
Motivation: 现有研究对医学影像 AI 性能不确定性量化中的置信区间（CI）行为的探索不足，导致社区对 CI 方法的多样性和行为模式缺乏了解，阻碍了 AI 的可靠验证和临床应用。

Method: 研究人员对 24 个分割和分类任务进行了大规模实证分析，使用了 19 个训练模型、多种常用性能指标、多种聚合策略以及多种广泛采用的 CI 方法。通过评估 CI 方法在不同设置下的可靠性（覆盖率）和精确度（宽度）来表征其对研究特征的依赖性。

Result: 1. 可靠 CI 所需的样本量根据研究参数不同，从几十到数千不等；2. CI 行为受性能指标选择影响显著；3. 聚合策略会显著影响 CI 的可靠性（例如，宏平均比微平均需要更多观测）；4. 机器学习问题类型（分割 vs. 分类）会调节这些影响；5. 不同 CI 方法的可靠性和精确度并非在所有场景下都均等。

Conclusion: 该研究结果揭示了影响医学影像 AI 性能置信区间可靠性和精确度的关键因素，为未来制定医学影像 AI 性能不确定性报告指南提供了重要依据。

Abstract: Performance uncertainty quantification is essential for reliable validation and eventual clinical translation of medical imaging artificial intelligence (AI). Confidence intervals (CIs) play a central role in this process by indicating how precise a reported performance estimate is. Yet, due to the limited amount of work examining CI behavior in medical imaging, the community remains largely unaware of how many diverse CI methods exist and how they behave in specific settings. The purpose of this study is to close this gap. To this end, we conducted a large-scale empirical analysis across a total of 24 segmentation and classification tasks, using 19 trained models per task group, a broad spectrum of commonly used performance metrics, multiple aggregation strategies, and several widely adopted CI methods. Reliability (coverage) and precision (width) of each CI method were estimated across all settings to characterize their dependence on study characteristics. Our analysis revealed five principal findings: 1) the sample size required for reliable CIs varies from a few dozens to several thousands of cases depending on study parameters; 2) CI behavior is strongly affected by the choice of performance metric; 3) aggregation strategy substantially influences the reliability of CIs, e.g. they require more observations for macro than for micro; 4) the machine learning problem (segmentation versus classification) modulates these effects; 5) different CI methods are not equally reliable and precise depending on the use case. These results form key components for the development of future guidelines on reporting performance uncertainty in medical imaging AI.

</details>


### [95] [StealthMark: Harmless and Stealthy Ownership Verification for Medical Segmentation via Uncertainty-Guided Backdoors](https://arxiv.org/abs/2601.17107)
*Qinkai Yu,Chong Zhang,Gaojie Jin,Tianjin Huang,Wei Zhou,Wenhui Li,Xiaobo Jin,Bo Huang,Yitian Zhao,Guang Yang,Gregory Y. H. Lip,Yalin Zheng,Aline Villavicencio,Yanda Meng*

Main category: cs.CV

TL;DR: 本研究提出了一种名为StealthMark的新型方法，用于在黑盒条件下验证医疗分割模型的拥有权。该方法通过微妙地调整模型的不确定性来嵌入水印，而不影响最终的分割结果，并利用LIME等解释方法提取水印。


<details>
  <summary>Details</summary>
Motivation: 现有模型保护技术主要关注分类和生成任务，而对关键的医疗图像分割模型研究不足。同时，医疗数据标注成本高、专家稀缺，且涉及敏感的患者信息，增加了模型保护的复杂性。

Method: StealthMark通过修改模型的不确定性来嵌入水印，同时不改变模型的最终分割输出。 ownership verification通过模型无关的解释方法（如LIME）提取特征归因，在特定触发条件下，这些解释会揭示一个可验证的水印。水印被设计成QR码以提高鲁棒性和可识别性。

Result: 在四个医疗成像数据集和五个主流分割模型上的实验表明，StealthMark在不影响模型性能的情况下（Dice和AUC分数下降小于1%）实现了超过95%的攻击成功率（ASR）。

Conclusion: StealthMark是一种有效、隐蔽且无害的医疗分割模型拥有权验证方法，其性能显著优于基于后门的水印技术，具有很强的实际应用潜力。

Abstract: Annotating medical data for training AI models is often costly and limited due to the shortage of specialists with relevant clinical expertise. This challenge is further compounded by privacy and ethical concerns associated with sensitive patient information. As a result, well-trained medical segmentation models on private datasets constitute valuable intellectual property requiring robust protection mechanisms. Existing model protection techniques primarily focus on classification and generative tasks, while segmentation models-crucial to medical image analysis-remain largely underexplored. In this paper, we propose a novel, stealthy, and harmless method, StealthMark, for verifying the ownership of medical segmentation models under black-box conditions. Our approach subtly modulates model uncertainty without altering the final segmentation outputs, thereby preserving the model's performance. To enable ownership verification, we incorporate model-agnostic explanation methods, e.g. LIME, to extract feature attributions from the model outputs. Under specific triggering conditions, these explanations reveal a distinct and verifiable watermark. We further design the watermark as a QR code to facilitate robust and recognizable ownership claims. We conducted extensive experiments across four medical imaging datasets and five mainstream segmentation models. The results demonstrate the effectiveness, stealthiness, and harmlessness of our method on the original model's segmentation performance. For example, when applied to the SAM model, StealthMark consistently achieved ASR above 95% across various datasets while maintaining less than a 1% drop in Dice and AUC scores, significantly outperforming backdoor-based watermarking methods and highlighting its strong potential for practical deployment. Our implementation code is made available at: https://github.com/Qinkaiyu/StealthMark.

</details>


### [96] [Scaling medical imaging report generation with multimodal reinforcement learning](https://arxiv.org/abs/2601.17151)
*Qianchu Liu,Sheng Zhang,Guanghui Qin,Yu Gu,Ying Jin,Sam Preston,Yanbo Xu,Sid Kiblawi,Wen-wai Yim,Tim Ossowski,Tristan Naumann,Mu Wei,Hoifung Poon*

Main category: cs.CV

TL;DR: 本文提出了UniRG（Universal Report Generation）框架，通过强化学习直接优化评估指标，显著提升了医学影像报告生成的性能，并在胸部X光报告生成任务上达到了新的SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在多模态理解和推理方面存在不足，尤其是在生物医学领域。监督微调方法容易过拟合，导致模型难以泛化。医学影像报告生成是其中一个重要挑战。

Method: 提出UniRG框架，将强化学习作为核心机制，直接优化面向最终应用的评估指标。在胸部X光（CXR）数据集上训练了UniRG-CXR模型。

Result: UniRG-CXR在胸部X光报告生成任务上，相比于监督微调方法，性能得到显著提升，并展现出在不同机构和临床实践中的鲁棒泛化能力。在ReXrank基准测试中，UniRG-CXR取得了新的SOTA结果，显著优于之前的最先进方法。

Conclusion: UniRG框架通过强化学习优化评估指标，为医学影像报告生成提供了一个有效的通用框架，能够克服监督微调的局限性，实现更优的性能和泛化能力。

Abstract: Frontier models have demonstrated remarkable capabilities in understanding and reasoning with natural-language text, but they still exhibit major competency gaps in multimodal understanding and reasoning especially in high-value verticals such as biomedicine. Medical imaging report generation is a prominent example. Supervised fine-tuning can substantially improve performance, but they are prone to overfitting to superficial boilerplate patterns. In this paper, we introduce Universal Report Generation (UniRG) as a general framework for medical imaging report generation. By leveraging reinforcement learning as a unifying mechanism to directly optimize for evaluation metrics designed for end applications, UniRG can significantly improve upon supervised fine-tuning and attain durable generalization across diverse institutions and clinical practices. We trained UniRG-CXR on publicly available chest X-ray (CXR) data and conducted a thorough evaluation in CXR report generation with rigorous evaluation scenarios. On the authoritative ReXrank benchmark, UniRG-CXR sets new overall SOTA, outperforming prior state of the art by a wide margin.

</details>


### [97] [iFSQ: Improving FSQ for Image Generation with 1 Line of Code](https://arxiv.org/abs/2601.17124)
*Bin Lin,Zongjian Li,Yuwei Niu,Kaixiong Gong,Yunyang Ge,Yunlong Lin,Mingzhe Zheng,JianWei Zhang,Miles Yang,Zhao Zhong,Liefeng Bo,Li Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种名为 iFSQ 的新方法，通过用匹配分布的映射替换 FSQ 中的激活函数，解决了离散和连续图像生成模型之间的鸿沟，并实现了理论上的优化。研究发现，每维 4 比特是离散和连续表示之间的最佳平衡点，并且自回归模型在收敛速度上优于扩散模型，但后者在性能上限方面更胜一筹。


<details>
  <summary>Details</summary>
Motivation: 当前的图像生成领域在离散 token 的自回归模型和连续 latent 的扩散模型之间存在分裂，这阻碍了统一建模和公平的基准测试。FSQ 理论上可以连接这两者，但其原始形式存在激活崩溃问题，导致重建保真度和信息效率之间的权衡。

Method: 通过用匹配分布的映射替换 FSQ 中的激活函数，强制执行均匀先验，从而提出 iFSQ。将 iFSQ 作为受控基准，分析了离散和连续表示的最佳平衡点（约 4 比特/维），并比较了自回归模型和扩散模型在相同重建约束下的收敛速度和性能上限。此外，还将 REPA 适配到自回归模型，生成 LlamaGen-REPA。

Result: iFSQ 能够同时实现最优的 bin 利用率和重建精度。研究发现，每维 4 比特是离散和连续表示之间的最佳平衡点。在相同的重建约束下，自回归模型收敛更快，而扩散模型达到更高的性能上限。

Conclusion: iFSQ 有效地弥合了离散和连续图像生成模型之间的鸿沟，并提供了宝贵的见解，例如 4 比特/维是表示效率的最佳点。研究结果表明，虽然自回归模型收敛速度快，但扩散模型的性能上限更高，这可能与自回归模型严格的顺序约束有关。

Abstract: The field of image generation is currently bifurcated into autoregressive (AR) models operating on discrete tokens and diffusion models utilizing continuous latents. This divide, rooted in the distinction between VQ-VAEs and VAEs, hinders unified modeling and fair benchmarking. Finite Scalar Quantization (FSQ) offers a theoretical bridge, yet vanilla FSQ suffers from a critical flaw: its equal-interval quantization can cause activation collapse. This mismatch forces a trade-off between reconstruction fidelity and information efficiency. In this work, we resolve this dilemma by simply replacing the activation function in original FSQ with a distribution-matching mapping to enforce a uniform prior. Termed iFSQ, this simple strategy requires just one line of code yet mathematically guarantees both optimal bin utilization and reconstruction precision. Leveraging iFSQ as a controlled benchmark, we uncover two key insights: (1) The optimal equilibrium between discrete and continuous representations lies at approximately 4 bits per dimension. (2) Under identical reconstruction constraints, AR models exhibit rapid initial convergence, whereas diffusion models achieve a superior performance ceiling, suggesting that strict sequential ordering may limit the upper bounds of generation quality. Finally, we extend our analysis by adapting Representation Alignment (REPA) to AR models, yielding LlamaGen-REPA. Codes is available at https://github.com/Tencent-Hunyuan/iFSQ

</details>


### [98] [LGDWT-GS: Local and Global Discrete Wavelet-Regularized 3D Gaussian Splatting for Sparse-View Scene Reconstruction](https://arxiv.org/abs/2601.17185)
*Shima Salehi,Atharva Agashe,Andrew J. McFarland,Joshua Peeples*

Main category: cs.CV

TL;DR: 提出了一种新的少样本3D重建方法，结合了全局和局部频率正则化，用于在稀疏视角条件下稳定几何和保留细节，并发布了一个多光谱温室数据集和评估3DGS方法的基准包。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯溅射（3DGS）模型在稀疏视角条件下存在几何不稳定和细节丢失的问题，这促使研究者提出新的方法来解决这些限制。

Method: 提出了一种新的少样本3D重建方法，该方法集成了全局和局部频率正则化。同时，创建了一个包含四个光谱波段的多光谱温室数据集，并发布了一个开源的基准包，用于标准化3DGS方法的少样本重建评估。

Result: 所提出的方法在多光谱数据集和标准基准数据集上的实验表明，与现有基线方法相比，能够实现更清晰、更稳定、光谱一致性更好的重建。

Conclusion: 该研究提出了一种改进的少样本3D重建方法，并提供了一个新的数据集和评估框架，为3DGS方法在稀疏视角下的应用提供了更优的解决方案。

Abstract: We propose a new method for few-shot 3D reconstruction that integrates global and local frequency regularization to stabilize geometry and preserve fine details under sparse-view conditions, addressing a key limitation of existing 3D Gaussian Splatting (3DGS) models. We also introduce a new multispectral greenhouse dataset containing four spectral bands captured from diverse plant species under controlled conditions. Alongside the dataset, we release an open-source benchmarking package that defines standardized few-shot reconstruction protocols for evaluating 3DGS-based methods. Experiments on our multispectral dataset, as well as standard benchmarks, demonstrate that the proposed method achieves sharper, more stable, and spectrally consistent reconstructions than existing baselines. The dataset and code for this work are publicly available

</details>


### [99] [Decoding Psychological States Through Movement: Inferring Human Kinesic Functions with Application to Built Environments](https://arxiv.org/abs/2601.17194)
*Cheyu Lin,Katherine A. Flanigan,Sirajum Munir*

Main category: cs.CV

TL;DR: 本研究提出了DUET数据集和一种基于骨骼运动的运动学识别框架，用于在隐私保护的前提下，衡量和分析人们在物理空间中的社交互动，并将运动学功能与社会资本理论相关的行为联系起来。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏一种一致且注重隐私的方法来表示和衡量物理空间中的社交互动，导致研究结果难以比较，也限制了设计干预效果的评估。

Method: 开发了DUET数据集，其中包含12种双人互动，覆盖了运动学的五种功能（象征、说明、情感表达、适应和调节），并利用四种传感模态和三种环境。提出了一个基于运动学识别的框架，将骨骼运动直接映射到沟通功能，并使用迁移学习架构进行分析。

Result: DUET数据集的建立为衡量社交互动提供了新的基础。研究基准测试表明，在DUET数据集上进行运动学功能识别具有挑战性，现有的单人活动识别模型在应用于双人社交互动测量时存在局限性。提出的识别框架能够直接从骨骼运动中推断出沟通功能，并在不同主体和环境中表现出良好的泛化能力，同时揭示了表示质量与分类性能之间的强关联性。

Conclusion: DUET数据集和运动学识别框架为在物理空间中以隐私保护的方式量化社交互动提供了有效工具，并为理解和设计支持社区韧性的社会基础设施提供了新的视角。

Abstract: Social infrastructure and other built environments are increasingly expected to support well-being and community resilience by enabling social interaction. Yet in civil and built-environment research, there is no consistent and privacy-preserving way to represent and measure socially meaningful interaction in these spaces, leaving studies to operationalize "interaction" differently across contexts and limiting practitioners' ability to evaluate whether design interventions are changing the forms of interaction that social capital theory predicts should matter. To address this field-level and methodological gap, we introduce the Dyadic User Engagement DataseT (DUET) dataset and an embedded kinesics recognition framework that operationalize Ekman and Friesen's kinesics taxonomy as a function-level interaction vocabulary aligned with social capital-relevant behaviors (e.g., reciprocity and attention coordination). DUET captures 12 dyadic interactions spanning all five kinesic functions-emblems, illustrators, affect displays, adaptors, and regulators-across four sensing modalities and three built-environment contexts, enabling privacy-preserving analysis of communicative intent through movement. Benchmarking six open-source, state-of-the-art human activity recognition models quantifies the difficulty of communicative-function recognition on DUET and highlights the limitations of ubiquitous monadic, action-level recognition when extended to dyadic, socially grounded interaction measurement. Building on DUET, our recognition framework infers communicative function directly from privacy-preserving skeletal motion without handcrafted action-to-function dictionaries; using a transfer-learning architecture, it reveals structured clustering of kinesic functions and a strong association between representation quality and classification performance while generalizing across subjects and contexts.

</details>


### [100] [Structural Complexity of Brain MRI reveals age-associated patterns](https://arxiv.org/abs/2601.17211)
*Anzhe Cheng,Italo Ivo Lima Dias Pinto,Paul Bogdan*

Main category: cs.CV

TL;DR: 该研究将结构复杂性分析方法扩展到三维信号（特别是脑MRI），提出了一种改进的滑动窗口粗粒化方案，以克服传统块状方法的不足，并发现大脑结构复杂性随年龄增长而系统性下降，尤其在粗糙尺度上效应更明显，证明了该方法在生物年龄预测中的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统结构复杂性分析方法在处理三维数据时，尤其是在粗糙分辨率下，可能出现不稳定的问题。研究人员希望改进该方法，使其更适用于三维信号，并探索其在分析大脑MRI数据和预测生物年龄方面的应用。

Method: 研究人员将结构复杂性分析应用于三维信号，特别是脑MRI。他们改进了传统的块状粗粒化方法，提出了一个滑动窗口粗粒化方案，以在不同空间尺度上捕捉数据的多尺度组织，并量化信息损失。接着，他们利用改进后的方法分析了跨越成年中期至晚期的结构MRI数据集。

Result: 通过滑动窗口粗粒化方法，研究发现大脑结构复杂性随年龄增长而系统性下降，这种下降效应在较粗糙的尺度上尤为显著。

Conclusion: 结构复杂性分析是一种可靠的多尺度三维成像数据信号处理工具。通过改进的滑动窗口粗粒化方案，该方法能够稳定地捕捉三维数据（如脑MRI）的结构复杂性，并证明了其在预测生物年龄方面的有效性。

Abstract: We adapt structural complexity analysis to three-dimensional signals, with an emphasis on brain magnetic resonance imaging (MRI). This framework captures the multiscale organization of volumetric data by coarse-graining the signal at progressively larger spatial scales and quantifying the information lost between successive resolutions. While the traditional block-based approach can become unstable at coarse resolutions due to limited sampling, we introduce a sliding-window coarse-graining scheme that provides smoother estimates and improved robustness at large scales. Using this refined method, we analyze large structural MRI datasets spanning mid- to late adulthood and find that structural complexity decreases systematically with age, with the strongest effects emerging at coarser scales. These findings highlight structural complexity as a reliable signal processing tool for multiscale analysis of 3D imaging data, while also demonstrating its utility in predicting biological age from brain MRI.

</details>


### [101] [Semi-Supervised Domain Adaptation with Latent Diffusion for Pathology Image Classification](https://arxiv.org/abs/2601.17228)
*Tengyue Zhang,Ruiwen Ding,Luoting Zhuang,Yuxiao Wu,Erika F. Rodriguez,William Hsu*

Main category: cs.CV

TL;DR: 提出了一种半监督域适应（SSDA）框架，利用潜在扩散模型生成保留形态且具有目标域特征的合成图像，用于计算病理学中的域泛化。该方法在肺腺癌预后预测任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有计算病理学中的深度学习模型在跨队列和跨机构时，由于域偏移（domain shift）而泛化能力不足。现有的解决方案要么无法利用目标域的未标记数据，要么依赖于可能扭曲组织结构并损害模型准确性的图像到图像翻译。

Method: 提出一个SSDA框架，利用在源域和目标域的未标记数据上训练的潜在扩散模型，生成保留形态且具有目标域特征的合成图像。通过将扩散模型与基础模型特征、队列身份和组织制备方法相结合，可以在保留源域组织结构的同时引入目标域的外观特征。然后，将这些目标域感知合成图像与来自源队列的真实标记图像结合，用于训练下游分类器，并在目标队列上进行测试。

Result: 该SSDA框架在肺腺癌预后预测任务上得到了验证。生成的合成数据增强显著提高了在目标队列上保留的测试集上的性能，同时并未降低源队列的性能。具体而言，目标队列保留的测试集上的加权F1分数从0.611提高到0.706，宏F1分数从0.641提高到0.716。

Conclusion: 基于目标域感知扩散的合成数据增强是一种有前景且有效的方法，可以提高计算病理学中的域泛化能力。

Abstract: Deep learning models in computational pathology often fail to generalize across cohorts and institutions due to domain shift. Existing approaches either fail to leverage unlabeled data from the target domain or rely on image-to-image translation, which can distort tissue structures and compromise model accuracy. In this work, we propose a semi-supervised domain adaptation (SSDA) framework that utilizes a latent diffusion model trained on unlabeled data from both the source and target domains to generate morphology-preserving and target-aware synthetic images. By conditioning the diffusion model on foundation model features, cohort identity, and tissue preparation method, we preserve tissue structure in the source domain while introducing target-domain appearance characteristics. The target-aware synthetic images, combined with real, labeled images from the source cohort, are subsequently used to train a downstream classifier, which is then tested on the target cohort. The effectiveness of the proposed SSDA framework is demonstrated on the task of lung adenocarcinoma prognostication. The proposed augmentation yielded substantially better performance on the held-out test set from the target cohort, without degrading source-cohort performance. The approach improved the weighted F1 score on the target-cohort held-out test set from 0.611 to 0.706 and the macro F1 score from 0.641 to 0.716. Our results demonstrate that target-aware diffusion-based synthetic data augmentation provides a promising and effective approach for improving domain generalization in computational pathology.

</details>


### [102] [C-RADIOv4 (Tech Report)](https://arxiv.org/abs/2601.17237)
*Mike Ranzinger,Greg Heinrich,Collin McCarthy,Jan Kautz,Andrew Tao,Bryan Catanzaro,Pavlo Molchanov*

Main category: cs.CV

TL;DR: C-RADIOv4 是一个多教师蒸馏模型，在保持计算复杂度的同时，提高了下游任务性能，并增加了新的功能，如任意分辨率支持和 ViTDet 选项，且具有宽松的许可证。


<details>
  <summary>Details</summary>
Motivation: 为了在保持计算复杂度的前提下，提升模型的下游任务性能，并整合多个教师模型的优势，同时增加新的功能。

Method: 利用多教师蒸馏技术，以 SigLIP2、DINOv3 和 SAM3 作为教师模型，训练 C-RADIOv4 学生模型，并引入了任意分辨率支持和 ViTDet 选项。

Result: C-RADIOv4 在关键下游任务上取得了显著改进，包括从 SAM3 继承的新能力，同时支持任意分辨率，并提供了 ViTDet 选项以提高高分辨率下的效率。

Conclusion: C-RADIOv4 模型家族通过多教师蒸馏，成功地整合了多个先进教师模型的优势，在保持计算效率的同时，显著提升了模型性能和功能性，并提供了宽松的许可证，便于应用。

Abstract: By leveraging multi-teacher distillation, agglomerative vision backbones provide a unified student model that retains and improves the distinct capabilities of multiple teachers. In this tech report, we describe the most recent release of the C-RADIO family of models, C-RADIOv4, which builds upon AM-RADIO/RADIOv2.5 in design, offering strong improvements on key downstream tasks at the same computational complexity. We release -SO400M (412M params), and -H (631M) model variants, both trained with an updated set of teachers: SigLIP2, DINOv3, and SAM3. In addition to improvements on core metrics and new capabilities from imitating SAM3, the C-RADIOv4 model family further improves any-resolution support, brings back the ViTDet option for drastically enhanced efficiency at high-resolution, and comes with a permissive license.

</details>


### [103] [PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation](https://arxiv.org/abs/2601.17885)
*Qingyu Fan,Zhaoxiang Li,Yi Lu,Wang Chen,Qiu Shen,Xiao-xiao Long,Yinghao Cai,Tao Lu,Shuo Wang,Xun Cao*

Main category: cs.CV

TL;DR: 本文提出了一种名为PEAfowl的多视角视觉-语言-动作（VLA）策略，用于解决在杂乱场景下的双臂操作问题。该策略通过预测深度分布、进行可微分3D提升和聚合跨视图邻居来增强空间理解，并通过Perceiver风格的文本感知读出机制改进指令的精细化对齐。实验表明，PEAfowl在RoboTwin 2.0上显著提升了成功率，并成功实现了仿真到现实的迁移。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）模型在处理杂乱场景下的双臂操作时，由于视图无关的特征融合和粗粒度的指令条件化，泛化能力不足。

Method: PEAfowl通过以下方法解决问题：1. 增强空间推理：预测每帧的深度分布，进行可微分3D提升，聚合跨视图邻居，形成几何对齐、跨视图一致的表征。2. 改进指令对齐：采用Perceiver风格的文本感知读出机制，迭代累积证据，取代全局条件化。3. 训练时深度蒸馏：从预训练的教师模型中蒸馏深度信息，以监督深度分布头，在不增加推理开销的情况下引入几何感知先验。

Result: 在RoboTwin 2.0的领域随机化设置下，PEAfowl将成功率相比现有最佳基线提高了23.0个百分点。真实机器人实验也验证了其可靠的仿真到现实迁移能力和深度蒸馏带来的持续改进。

Conclusion: PEAfowl通过增强的空间理解和精细化的指令对齐，有效提升了在杂乱场景下双臂操作的性能，并展示了其在仿真到现实迁移方面的潜力。

Abstract: Bimanual manipulation in cluttered scenes requires policies that remain stable under occlusions, viewpoint and scene variations. Existing vision-language-action models often fail to generalize because (i) multi-view features are fused via view-agnostic token concatenation, yielding weak 3D-consistent spatial understanding, and (ii) language is injected as global conditioning, resulting in coarse instruction grounding.
  In this paper, we introduce PEAfowl, a perception-enhanced multi-view VLA policy for bimanual manipulation. For spatial reasoning, PEAfowl predicts per-token depth distributions, performs differentiable 3D lifting, and aggregates local cross-view neighbors to form geometrically grounded, cross-view consistent representations. For instruction grounding, we propose to replace global conditioning with a Perceiver-style text-aware readout over frozen CLIP visual features, enabling iterative evidence accumulation. To overcome noisy and incomplete commodity depth without adding inference overhead, we apply training-only depth distillation from a pretrained depth teacher to supervise the depth-distribution head, providing perception front-end with geometry-aware priors.
  On RoboTwin 2.0 under domain-randomized setting, PEAfowl improves the strongest baseline by 23.0 pp in success rate, and real-robot experiments further demonstrate reliable sim-to-real transfer and consistent improvements from depth distillation.
  Project website: https://peafowlvla.github.io/.

</details>


### [104] [Masked Depth Modeling for Spatial Perception](https://arxiv.org/abs/2601.17895)
*Bin Tan,Changjiang Sun,Xiage Qin,Hanat Adai,Zelin Fu,Tianxiang Zhou,Han Zhang,Yinghao Xu,Xing Zhu,Yujun Shen,Nan Xue*

Main category: cs.CV

TL;DR: LingBot-Depth 是一个利用视觉上下文通过掩码深度建模来完善深度图的模型，并包含一个自动数据整理流程，以实现可扩展训练，其性能优于顶级的 RGB-D 相机。


<details>
  <summary>Details</summary>
Motivation: 现有 RGB-D 相机在精确获取像素级度量深度方面存在硬件限制和成像条件挑战（尤其是在镜面或纹理缺失的表面上），作者认为这些不准确性可以被视为反映几何歧义的“掩码”信号。

Method: 提出 LingBot-Depth 模型，利用视觉上下文，通过掩码深度建模来完善深度图，并结合自动数据整理流程进行可扩展训练。

Result: LingBot-Depth 在深度精度和像素覆盖率方面均优于顶级的 RGB-D 相机。在下游任务上的实验表明，LingBot-Depth 在 RGB 和深度模态之间提供了对齐的潜在表示。

Conclusion: LingBot-Depth 能够有效地利用视觉上下文来改进深度图的准确性和覆盖范围，并为空间感知领域的研究者发布了代码、检查点和大量 RGB-深度数据对。

Abstract: Spatial visual perception is a fundamental requirement in physical-world applications like autonomous driving and robotic manipulation, driven by the need to interact with 3D environments. Capturing pixel-aligned metric depth using RGB-D cameras would be the most viable way, yet it usually faces obstacles posed by hardware limitations and challenging imaging conditions, especially in the presence of specular or texture-less surfaces. In this work, we argue that the inaccuracies from depth sensors can be viewed as "masked" signals that inherently reflect underlying geometric ambiguities. Building on this motivation, we present LingBot-Depth, a depth completion model which leverages visual context to refine depth maps through masked depth modeling and incorporates an automated data curation pipeline for scalable training. It is encouraging to see that our model outperforms top-tier RGB-D cameras in terms of both depth precision and pixel coverage. Experimental results on a range of downstream tasks further suggest that LingBot-Depth offers an aligned latent representation across RGB and depth modalities. We release the code, checkpoint, and 3M RGB-depth pairs (including 2M real data and 1M simulated data) to the community of spatial perception.

</details>


### [105] [Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning](https://arxiv.org/abs/2601.18714)
*Judith Vilella-Cantos,Mauro Martini,Marcello Chiaberge,Mónica Ballesta,David Valiente*

Main category: cs.CV

TL;DR: 提出了一种名为 MinkUNeXt-VINE 的轻量级深度学习方法，用于在葡萄园环境中进行地方识别。该方法通过预处理和多损失函数方法，在低成本、稀疏的 LiDAR 输入下取得了优于现有技术的性能，并保证了实时性。


<details>
  <summary>Details</summary>
Motivation: 农业环境的非结构化特性和缺乏显著地标使得机器人定位极具挑战性，现有技术在地方识别方面仍有待提高。

Method: 提出了一种名为 MinkUNeXt-VINE 的轻量级深度学习方法，采用预处理和 Matryoshka Representation Learning 多损失函数方法，重点关注低成本、稀疏 LiDAR 输入和低维输出以提高效率。

Result: MinkUNeXt-VINE 在葡萄园环境中超越了现有技术，并在各种评估场景和两个长期的葡萄园数据集上证明了其在低成本、低分辨率输入数据上的鲁棒性能。

Conclusion: MinkUNeXt-VINE 是一种高效且鲁棒的方法，适用于在具有挑战性的葡萄园环境中进行地方识别，尤其是在使用低成本、低分辨率 LiDAR 输入时。

Abstract: Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach. Our method prioritizes enhanced performance with low-cost, sparse LiDAR inputs and lower-dimensionality outputs to ensure high efficiency in real-time scenarios. Additionally, we present a comprehensive ablation study of the results on various evaluation cases and two extensive long-term vineyard datasets employing different LiDAR sensors. The results demonstrate the efficiency of the trade-off output produced by this approach, as well as its robust performance on low-cost and low-resolution input data. The code is publicly available for reproduction.

</details>


### [106] [Multi-stage Bridge Inspection System: Integrating Foundation Models with Location Anonymization](https://arxiv.org/abs/2601.17254)
*Takato Yasuno*

Main category: cs.CV

TL;DR: 该研究提出了一种开源的桥梁损伤检测系统，该系统在保护区域信息的同时，能高效地检测混凝土裂缝、钢筋暴露和锈蚀，并能自动完成遗漏区域的检测，最终以1.7秒/图像的速度完成处理。


<details>
  <summary>Details</summary>
Motivation: 日本要求对民用基础设施进行定期视觉检查，但现场拍摄的图像中包含的区域信息（如施工标志）可能泄露敏感信息，从而引发公众担忧。研究旨在开发一个能在准确提取损伤特征的同时，有效保护区域隐私的系统。

Method: 该系统使用Segment Anything Model 3 (SAM 3) 进行钢筋锈蚀检测，并利用DBSCAN算法自动补全漏检区域。通过高斯模糊处理施工标志区域以保护隐私。文章还介绍了四种提高OCR准确率的预处理方法，并利用GPU优化实现了高效的图像处理速度。

Result: 该系统能够准确检测桥梁损伤（如混凝土裂缝和钢筋暴露/锈蚀），并有效地通过高斯模糊保护了施工标志中的区域信息。GPU优化使得每张图像的处理速度达到1.7秒。

Conclusion: 该研究成功开发了一个结合了SAM 3、DBSCAN等技术的开源桥梁损伤检测系统，该系统在实现高效损伤检测的同时，能够有效保护区域隐私信息，为桥梁安全检查提供了新的解决方案。

Abstract: In Japan, civil infrastructure condition monitoring is mandated through visual inspection every five years. Field-captured damage images frequently contain concrete cracks and rebar exposure, often accompanied by construction signs revealing regional information. To enable safe infrastructure use without causing public anxiety, it is essential to protect regional information while accurately extracting damage features and visualizing key indicators for repair decision-making. This paper presents an open-source bridge damage detection system with regional privacy protection capabilities. We employ Segment Anything Model (SAM) 3 for rebar corrosion detection and utilize DBSCAN for automatic completion of missed regions. Construction sign regions are detected and protected through Gaussian blur. Four preprocessing methods improve OCR accuracy, and GPU optimization enables 1.7-second processing per image. The technology stack includes SAM3, PyTorch, OpenCV, pytesseract, and scikit-learn, achieving efficient bridge inspection with regional information protection.

</details>


### [107] [FineVAU: A Novel Human-Aligned Benchmark for Fine-Grained Video Anomaly Understanding](https://arxiv.org/abs/2601.17258)
*João Pereira,Vasco Lopes,João Neves,David Semedo*

Main category: cs.CV

TL;DR: 本研究提出了FineVAU，一个用于视频异常理解（VAU）的新基准，旨在解决现有评估方法不足的问题，并引入了一种新颖的、与人类对齐的评估指标FVScore和一个包含细粒度视觉信息的丰富数据集FineW3。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常理解（VAU）任务的评估方法（如基于n-gram的指标和基于LLM的评估）存在缺陷，无法充分捕捉视频异常描述的自由形式、视觉接地性和领域特异性，并且与人类感知存在偏差。因此，需要一种更侧重于细粒度、领域特定理解的新评估方法。

Method: 提出FineVAU基准，将VAU视为一个三元问题，包括事件（What）、参与实体（Who）和地点（Where）。引入新颖的、与人类对齐的评估指标FVScore，用于评估语言模型回答中关键视觉元素的出现，提供可解释的细粒度反馈。创建了FineW3数据集，通过全自动流程增强了现有的人工标注，增加了高质量的细粒度视觉信息。

Result: FVScore在人类评估中显示出比现有方法更优越的人类感知对齐性。在FineVAU上的实验揭示了大型语言模型（LLM）在理解需要空间和细粒度时间信息的异常事件方面存在局限性，尽管它们在粗粒度、静态信息和具有明显视觉线索的事件方面表现良好。

Conclusion: FineVAU提供了一个更全面、细粒度和领域特定的视频异常理解基准。FVScore指标能够更准确地评估模型对视频异常的理解。研究表明，目前的LLM在处理需要复杂时空理解的视频异常方面仍有提升空间。

Abstract: Video Anomaly Understanding (VAU) is a novel task focused on describing unusual occurrences in videos. Despite growing interest, the evaluation of VAU remains an open challenge. Existing benchmarks rely on n-gram-based metrics (e.g., BLEU, ROUGE-L) or LLM-based evaluation. The first fails to capture the rich, free-form, and visually grounded nature of LVLM responses, while the latter focuses on assessing language quality over factual relevance, often resulting in subjective judgments that are misaligned with human perception. In this work, we address this issue by proposing FineVAU, a new benchmark for VAU that shifts the focus towards rich, fine-grained and domain-specific understanding of anomalous videos. We formulate VAU as a three-fold problem, with the goal of comprehensively understanding key descriptive elements of anomalies in video: events (What), participating entities (Who) and location (Where). Our benchmark introduces a) FVScore, a novel, human-aligned evaluation metric that assesses the presence of critical visual elements in LVLM answers, providing interpretable, fine-grained feedback; and b) FineW3, a novel, comprehensive dataset curated through a structured and fully automatic procedure that augments existing human annotations with high quality, fine-grained visual information. Human evaluation reveals that our proposed metric has a superior alignment with human perception of anomalies in comparison to current approaches. Detailed experiments on FineVAU unveil critical limitations in LVLM's ability to perceive anomalous events that require spatial and fine-grained temporal understanding, despite strong performance on coarse grain, static information, and events with strong visual cues.

</details>


### [108] [Inference-Time Loss-Guided Colour Preservation in Diffusion Sampling](https://arxiv.org/abs/2601.17259)
*Angad Singh Ahuja,Aarush Ram Anandh*

Main category: cs.CV

TL;DR: 本文提出一种无需训练、在推理时对指定区域进行颜色控制的扩散模型方法，通过ROI内修补、背景潜空间重置以及在CIE Lab和线性RGB空间中定义复合损失进行潜空间引导，有效解决文本到图像生成中颜色控制不精确的问题。


<details>
  <summary>Details</summary>
Motivation: 文本到图像生成系统在精确颜色控制方面存在不足，尤其是在需要满足用户指定颜色目标的设计工作流程中。

Method: 结合区域感兴趣（ROI）区域内修补、背景潜空间重置以及通过CIE Lab和线性RGB空间的复合损失进行潜空间引导。该损失函数不仅控制ROI的平均颜色，还通过CVaR风格和软最大惩罚来控制像素误差分布的尾部，并使用延迟启动门控和时间依赖调度来稳定引导。

Result: 提出的方法能够满足平均颜色约束，并且比仅考虑平均值的基线方法能产生更少感知上的显著的局部失败。该方法提供了一种实用的、无需训练的、可集成到标准Stable Diffusion内修补流程中的、针对性颜色控制机制。

Conclusion: 该方法为实现文本到图像生成中的精确颜色控制提供了一种有效且易于集成的解决方案，特别是在设计导向的应用场景中。

Abstract: Precise color control remains a persistent failure mode in text-to-image diffusion systems, particularly in design-oriented workflows where outputs must satisfy explicit, user-specified color targets. We present an inference-time, region-constrained color preservation method that steers a pretrained diffusion model without any additional training. Our approach combines (i) ROI-based inpainting for spatial selectivity, (ii) background-latent re-imposition to prevent color drift outside the ROI, and (iii) latent nudging via gradient guidance using a composite loss defined in CIE Lab and linear RGB. The loss is constructed to control not only the mean ROI color but also the tail of the pixelwise error distribution through CVaR-style and soft-maximum penalties, with a late-start gate and a time-dependent schedule to stabilize guidance across denoising steps. We show that mean-only baselines can satisfy average color constraints while producing perceptually salient local failures, motivating our distribution-aware objective. The resulting method provides a practical, training-free mechanism for targeted color adherence that can be integrated into standard Stable Diffusion inpainting pipelines.

</details>


### [109] [Cross360: 360° Monocular Depth Estimation via Cross Projections Across Scales](https://arxiv.org/abs/2601.17271)
*Kun Huang,Fang-Lue Zhang,Neil Dodgson*

Main category: cs.CV

TL;DR: 提出了一种名为Cross360的新型跨注意力架构，通过结合切向投影和等距柱状投影的特征，有效解决了360度深度估计中的全局连续性和局部一致性问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有360度深度估计方法在平衡全局连续性和局部一致性方面存在困难，局部特征缺乏全局感知，全局表示未能解决块边界的特征提取差异。

Method: 提出Cross360架构，利用跨注意力机制结合扭曲较小的切向投影和等距柱状投影的特征。Cross Projection Feature Alignment模块使用跨注意力对齐切向投影特征和等距柱状投影的全局视野。Progressive Feature Aggregation with Attention模块逐步细化多尺度特征。

Result: Cross360在大多数基准数据集上显著优于现有方法，尤其是在能获取完整360度图像的情况下。

Conclusion: Cross360能够实现准确且全局一致的360度深度估计，有效解决了现有方法的局限性。

Abstract: 360° depth estimation is a challenging research problem due to the difficulty of finding a representation that both preserves global continuity and avoids distortion in spherical images. Existing methods attempt to leverage complementary information from multiple projections, but struggle with balancing global and local consistency. Their local patch features have limited global perception, and the combined global representation does not address discrepancies in feature extraction at the boundaries between patches. To address these issues, we propose Cross360, a novel cross-attention-based architecture integrating local and global information using less-distorted tangent patches along with equirectangular features. Our Cross Projection Feature Alignment module employs cross-attention to align local tangent projection features with the equirectangular projection's 360° field of view, ensuring each tangent projection patch is aware of the global context. Additionally, our Progressive Feature Aggregation with Attention module refines multi-scaled features progressively, enhancing depth estimation accuracy. Cross360 significantly outperforms existing methods across most benchmark datasets, especially those in which the entire 360° image is available, demonstrating its effectiveness in accurate and globally consistent depth estimation. The code and model are available at https://github.com/huangkun101230/Cross360.

</details>


### [110] [Fluxamba: Topology-Aware Anisotropic State Space Models for Geological Lineament Segmentation in Multi-Source Remote Sensing](https://arxiv.org/abs/2601.17288)
*Jin Bai,Huiyao Zhang,Qi Wen,Shengyang Li,Xiaolin Tian,Atta ur Rahman*

Main category: cs.CV

TL;DR: Fluxamba 提出了一种轻量级架构，用于精确分割地质线性特征，通过拓扑感知特征校正框架（包括结构化通量块）来解决现有模型在处理曲线目标时的拓扑不匹配问题，并在多个基准数据集上取得了最先进的性能，同时保持了实时推理能力和低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有先进模型（如 SSM）在分割地质线性特征（如行星线理和地裂）时，由于依赖于刚性的、轴对齐的扫描轨迹，与曲线目标存在拓扑不匹配，导致上下文碎片化和特征丢失。

Method: 提出 Fluxamba 架构，核心是结构化通量块（SFB），它集成了各向异性结构门（ASG）和先验调制流（PMF），以解耦特征方向与空间位置，并沿着目标内在几何结构动态门控上下文聚合。此外，还引入了分层空间调节器（HSR）进行多尺度语义对齐，以及高保真焦点单元（HFFU）来最大化微弱特征的信噪比。

Result: 在 LROC-Lineament、LineaMapper 和 GeoCrack 等地质基准数据集上取得了最先进的性能。在 LROC-Lineament 数据集上，F1 分数达到 89.22%，mIoU 达到 89.87%。实现了超过 24 FPS 的实时推理速度，仅需 3.4M 参数和 6.3G FLOPs，计算成本比现有模型降低了两个数量级。

Conclusion: Fluxamba 成功解决了地质线性特征分割中的拓扑不匹配问题，在分割精度和计算效率之间取得了新的平衡，为在计算资源受限的环境下部署提供了可行方案。

Abstract: The precise segmentation of geological linear features, spanning from planetary lineaments to terrestrial fractures, demands capturing long-range dependencies across complex anisotropic topologies. Although State Space Models (SSMs) offer near-linear computational complexity, their dependence on rigid, axis-aligned scanning trajectories induces a fundamental topological mismatch with curvilinear targets, resulting in fragmented context and feature erosion. To bridge this gap, we propose Fluxamba, a lightweight architecture that introduces a topology-aware feature rectification framework. Central to our design is the Structural Flux Block (SFB), which orchestrates an anisotropic information flux by integrating an Anisotropic Structural Gate (ASG) with a Prior-Modulated Flow (PMF). This mechanism decouples feature orientation from spatial location, dynamically gating context aggregation along the target's intrinsic geometry rather than rigid paths. Furthermore, to mitigate serialization-induced noise in low-contrast environments, we incorporate a Hierarchical Spatial Regulator (HSR) for multi-scale semantic alignment and a High-Fidelity Focus Unit (HFFU) to explicitly maximize the signal-to-noise ratio of faint features. Extensive experiments on diverse geological benchmarks (LROC-Lineament, LineaMapper, and GeoCrack) demonstrate that Fluxamba establishes a new state-of-the-art. Notably, on the challenging LROC-Lineament dataset, it achieves an F1-score of 89.22% and mIoU of 89.87%. Achieving a real-time inference speed of over 24 FPS with only 3.4M parameters and 6.3G FLOPs, Fluxamba reduces computational costs by up to two orders of magnitude compared to heavy-weight baselines, thereby establishing a new Pareto frontier between segmentation fidelity and onboard deployment feasibility.

</details>


### [111] [Dynamic Meta-Ensemble Framework for Efficient and Accurate Deep Learning in Plant Leaf Disease Detection on Resource-Constrained Edge Devices](https://arxiv.org/abs/2601.17290)
*Weloday Fikadu Moges,Jianmei Su,Amin Waqas*

Main category: cs.CV

TL;DR: 提出了一种名为动态元集成框架（DMEF）的新型方法，用于在资源受限的边缘设备上进行高精度植物病害检测。该框架通过自适应加权机制动态组合三个轻量级卷积神经网络的预测，以平衡准确性和计算效率，并在实际应用中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备（如物联网传感器、智能手机和嵌入式系统）上部署深度学习模型进行植物病害检测面临计算资源和能源预算的严重限制。

Method: DMEF采用动态元集成框架，其中包含一个自适应加权机制，通过优化准确性改进（DeltaAcc）和计算效率（模型大小）之间的权衡，动态地结合了三个轻量级卷积神经网络（MobileNetV2、NASNetMobile和InceptionV3）的预测。在训练期间，集成权重被迭代更新，优先考虑表现出高性能和低复杂度的模型。

Result: 在马铃薯和玉米病害的基准数据集上进行的大量实验表明，DMEF分别达到了99.53%和96.61%的最先进分类准确率，比单独模型和静态集成模型高出2.1%和6.3%。此外，DMEF的推理延迟小于75毫秒，模型参数量小于100万，显示出在边缘农业监测中的巨大潜力。

Conclusion: DMEF是一种在资源受限的边缘设备上实现高精度植物病害诊断的有效方法。它成功地在准确性和计算效率之间取得了平衡，为大规模作物病害管理提供了可行的解决方案，并弥合了高精度人工智能与实际田间应用之间的差距。

Abstract: Deploying deep learning models for plant disease detection on edge devices such as IoT sensors, smartphones, and embedded systems is severely constrained by limited computational resources and energy budgets. To address this challenge, we introduce a novel Dynamic Meta-Ensemble Framework (DMEF) for high-accuracy plant disease diagnosis under resource constraints. DMEF employs an adaptive weighting mechanism that dynamically combines the predictions of three lightweight convolutional neural networks (MobileNetV2, NASNetMobile, and InceptionV3) by optimizing a trade-off between accuracy improvements (DeltaAcc) and computational efficiency (model size). During training, the ensemble weights are updated iteratively, favoring models exhibiting high performance and low complexity. Extensive experiments on benchmark datasets for potato and maize diseases demonstrate state-of-the-art classification accuracies of 99.53% and 96.61%, respectively, surpassing standalone models and static ensembles by 2.1% and 6.3%. With computationally efficient inference latency (<75ms) and a compact footprint (<1 million parameters), DMEF shows strong potential for edge-based agricultural monitoring, suggesting viability for scalable crop disease management. This bridges the gap between high-accuracy AI and practical field applications.

</details>


### [112] [ClinNet: Evidential Ordinal Regression with Bilateral Asymmetry and Prototype Memory for Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.17315)
*Xiaoyang Li,Runni Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为ClinNet的框架，将膝骨关节炎（KOA）的影像分级问题视为证据有序回归问题，通过双边不对称编码器、诊断记忆库和基于NIG分布的证据有序头部，有效解决了传统分类方法忽略退化连续性和标注不确定性的问题，并在实验中取得了优于现有方法的性能，同时能够有效识别不确定和潜在误诊的样本。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法将KOA分级视为确定性多分类问题，未能充分考虑疾病进展的连续性以及专家标注中的不确定性，导致在处理细微的影像差异和类别间的有序性时存在挑战。

Method: 提出ClinNet框架，将KOA分级视为证据有序回归问题，包含三个关键组件：1. 双边不对称编码器（BAE），用于显式建模内外侧结构差异；2. 诊断记忆库，维护类别原型以稳定特征表示；3. 证据有序头部，基于正态-逆伽马（NIG）分布，联合估计连续的KL分级和认知不确定性。

Result: ClinNet在实验中达到了0.892的Quadratic Weighted Kappa和0.768的Accuracy，统计学上显著优于最先进的基线方法（p < 0.001）。此外，模型的预测不确定性估计能够成功标记出分布外样本和潜在的误诊。

Conclusion: ClinNet是一种新颖可信的KOA分级框架，通过将KOA分级问题转化为证据有序回归问题，并引入BAE、诊断记忆库和基于NIG分布的证据有序头部，有效解决了传统方法的局限性，并在性能和不确定性估计方面展现出优势，为安全地应用于临床提供了可能。

Abstract: Knee osteoarthritis (KOA) grading based on radiographic images is a critical yet challenging task due to subtle inter-grade differences, annotation uncertainty, and the inherently ordinal nature of disease progression. Conventional deep learning approaches typically formulate this problem as deterministic multi-class classification, ignoring both the continuous progression of degeneration and the uncertainty in expert annotations. In this work, we propose ClinNet, a novel trustworthy framework that addresses KOA grading as an evidential ordinal regression problem. The proposed method integrates three key components: (1) a Bilateral Asymmetry Encoder (BAE) that explicitly models medial-lateral structural discrepancies; (2) a Diagnostic Memory Bank that maintains class-wise prototypes to stabilize feature representations; and (3) an Evidential Ordinal Head based on the Normal-Inverse-Gamma (NIG) distribution to jointly estimate continuous KL grades and epistemic uncertainty. Extensive experiments demonstrate that ClinNet achieves a Quadratic Weighted Kappa of 0.892 and Accuracy of 0.768, statistically outperforming state-of-the-art baselines (p < 0.001). Crucially, we demonstrate that the model's uncertainty estimates successfully flag out-of-distribution samples and potential misdiagnoses, paving the way for safe clinical deployment.

</details>


### [113] [SkyReels-V3 Technique Report](https://arxiv.org/abs/2601.17323)
*Debang Li,Zhengcong Fei,Tuanhui Li,Yikun Dou,Zheng Chen,Jiangping Yang,Mingyuan Fan,Jingtao Xu,Jiahua Wang,Baoxuan Gu,Mingshan Chang,Yuqiang Xie,Binjie Mao,Youqiang Zhang,Nuo Pang,Hao Zhang,Yuzhe Jin,Zhiheng Xu,Dixuan Lin,Guibin Chen,Yahui Zhou*

Main category: cs.CV

TL;DR: SkyReels-V3 是一个统一的多模态上下文学习框架，利用扩散 Transformer 实现条件视频生成，支持参考图像到视频、视频扩展和音频驱动视频生成，并在多项指标上达到最先进或接近最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了在视频生成领域构建更强大的世界模型，并测试多模态上下文推理能力。

Method: 基于扩散 Transformer 的统一多模态上下文学习框架，实现了三种核心生成模式：参考图像到视频、视频扩展和音频驱动视频生成。针对参考图像到视频模式，采用了全面的数据处理流程（跨帧配对、图像编辑、语义重写）和混合训练策略（图像视频混合、多分辨率联合优化）。视频扩展模式结合了时空一致性建模和大规模视频理解。音频驱动视频生成则采用了首尾帧插入和关键帧推理范式。

Result: SkyReels-V3 在视觉质量、指令遵循和特定方面指标上达到了最先进或接近最先进的性能，并且在一定程度上接近领先的闭源系统。

Conclusion: SkyReels-V3 是一个多功能且性能强大的条件视频生成模型，通过统一的框架支持多种生成模式，并在多模态视频生成任务上取得了显著的成果。

Abstract: Video generation serves as a cornerstone for building world models, where multimodal contextual inference stands as the defining test of capability. In this end, we present SkyReels-V3, a conditional video generation model, built upon a unified multimodal in-context learning framework with diffusion Transformers. SkyReels-V3 model supports three core generative paradigms within a single architecture: reference images-to-video synthesis, video-to-video extension and audio-guided video generation. (i) reference images-to-video model is designed to produce high-fidelity videos with strong subject identity preservation, temporal coherence, and narrative consistency. To enhance reference adherence and compositional stability, we design a comprehensive data processing pipeline that leverages cross frame pairing, image editing, and semantic rewriting, effectively mitigating copy paste artifacts. During training, an image video hybrid strategy combined with multi-resolution joint optimization is employed to improve generalization and robustness across diverse scenarios. (ii) video extension model integrates spatio-temporal consistency modeling with large-scale video understanding, enabling both seamless single-shot continuation and intelligent multi-shot switching with professional cinematographic patterns. (iii) Talking avatar model supports minute-level audio-conditioned video generation by training first-and-last frame insertion patterns and reconstructing key-frame inference paradigms. On the basis of ensuring visual quality, synchronization of audio and videos has been optimized.
  Extensive evaluations demonstrate that SkyReels-V3 achieves state-of-the-art or near state-of-the-art performance on key metrics including visual quality, instruction following, and specific aspect metrics, approaching leading closed-source systems. Github: https://github.com/SkyworkAI/SkyReels-V3.

</details>


### [114] [SymbolSight: Minimizing Inter-Symbol Interference for Reading with Prosthetic Vision](https://arxiv.org/abs/2601.17326)
*Jasmine Lesner,Michael Beyeler*

Main category: cs.CV

TL;DR: 研究通过优化视觉符号而非依赖硬件改进，来减轻视网膜假体阅读时的视觉暂留干扰。结果表明，精心设计的符号集能显著降低字母混淆，提高阅读效率。


<details>
  <summary>Details</summary>
Motivation: 现有的视网膜假体空间分辨率低，且存在视觉暂留问题，导致阅读困难，尤其是在连续呈现字母时，前一个字母的残像会干扰后一个字母的识别。本研究旨在探索通过优化视觉符号本身来解决这一问题。

Method: 提出了一种名为SymbolSight的计算框架，该框架利用模拟假体视觉（SPV）和神经网络代理观察者，结合特定语言的二元语法统计数据，来估计符号之间的混淆度，并优化符号到字母的映射，以最大程度地减少相邻字母之间的混淆。

Result: 在阿拉伯语、保加利亚语和英语的模拟实验中，使用SymbolSight生成的异构符号集将预测的混淆度从中位数降低了22倍，与使用原生字母表相比。

Conclusion: 标准印刷字体与低带宽串行假体视觉的匹配度较差。通过计算建模优化视觉编码，可以有效地缩小设计空间，生成有潜力的视觉符号集，用于未来的心理物理学和临床评估，以改善视网膜假体用户的阅读体验。

Abstract: Retinal prostheses restore limited visual perception, but low spatial resolution and temporal persistence make reading difficult. In sequential letter presentation, the afterimage of one symbol can interfere with perception of the next, leading to systematic recognition errors. Rather than relying on future hardware improvements, we investigate whether optimizing the visual symbols themselves can mitigate this temporal interference. We present SymbolSight, a computational framework that selects symbol-to-letter mappings to minimize confusion among frequently adjacent letters. Using simulated prosthetic vision (SPV) and a neural proxy observer, we estimate pairwise symbol confusability and optimize assignments using language-specific bigram statistics. Across simulations in Arabic, Bulgarian, and English, the resulting heterogeneous symbol sets reduced predicted confusion by a median factor of 22 relative to native alphabets. These results suggest that standard typography is poorly matched to serial, low-bandwidth prosthetic vision and demonstrate how computational modeling can efficiently narrow the design space of visual encodings to generate high-potential candidates for future psychophysical and clinical evaluation.

</details>


### [115] [Learning with Geometric Priors in U-Net Variants for Polyp Segmentation](https://arxiv.org/abs/2601.17331)
*Fabian Vazquez,Jose A. Nuñez,Diego Adame,Alissen Moreno,Augustin Zhan,Huimin Li,Jinghao Yang,Haoteng Tang,Bin Fu,Pengfei Gu*

Main category: cs.CV

TL;DR: 本文提出了一种新的几何先验引导模块（GPM），用于提升基于U-Net的结肠息肉分割模型的性能，尤其是在低对比度或杂乱的内窥镜图像中。GPM通过引入显式的几何信息，例如通过预训练VGGT模型估计的深度图，来增强模型的几何和结构感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于CNN、Transformer和Mamba的U-Net变体在息肉分割方面表现出色，但在捕捉几何和结构线索方面仍有不足，尤其是在低对比度或杂乱的内窥镜图像场景中，这影响了早期结直肠癌的检测和辅助诊断。

Method: 提出了一种即插即用的几何先验引导模块（GPM）。该模块首先利用预训练的Visual Geometry Grounded Transformer (VGGT) 在模拟的ColonDepth数据集上估计息肉图像的深度图。然后，GPM将这些深度图编码的几何先验信息注入到U-Net编码器的特征图中，并通过空间和通道注意力机制进行细化，以同时强调局部空间和全局通道信息。GPM可以集成到各种U-Net变体中。

Result: 在五个公开的息肉分割数据集上的大量实验表明，GPM在与三个强大的基线模型相比时，能够持续提升性能。

Conclusion: 所提出的GPM模块能够有效地为基于U-Net的息肉分割模型注入几何先验信息，显著提高了模型在处理复杂内窥镜图像时的准确性和鲁棒性，为早期结直肠癌的检测提供了更有效的工具。

Abstract: Accurate and robust polyp segmentation is essential for early colorectal cancer detection and for computer-aided diagnosis. While convolutional neural network-, Transformer-, and Mamba-based U-Net variants have achieved strong performance, they still struggle to capture geometric and structural cues, especially in low-contrast or cluttered colonoscopy scenes. To address this challenge, we propose a novel Geometric Prior-guided Module (GPM) that injects explicit geometric priors into U-Net-based architectures for polyp segmentation. Specifically, we fine-tune the Visual Geometry Grounded Transformer (VGGT) on a simulated ColonDepth dataset to estimate depth maps of polyp images tailored to the endoscopic domain. These depth maps are then processed by GPM to encode geometric priors into the encoder's feature maps, where they are further refined using spatial and channel attention mechanisms that emphasize both local spatial and global channel information. GPM is plug-and-play and can be seamlessly integrated into diverse U-Net variants. Extensive experiments on five public polyp segmentation datasets demonstrate consistent gains over three strong baselines. Code and the generated depth maps are available at: https://github.com/fvazqu/GPM-PolypSeg

</details>


### [116] [AGE-Net: Spectral--Spatial Fusion and Anatomical Graph Reasoning with Evidential Ordinal Regression for Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.17336)
*Xiaoyang Li,Runni Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为AGE-Net的基于ConvNeXt的框架，通过结合光谱-空间融合、解剖图谱推理和差异化细化，提高了膝关节X光片Kellgren-Lawrence（KL）分级的准确性，并引入了证据回归和成对序数排序约束来处理预测不确定性和标签的序数性。


<details>
  <summary>Details</summary>
Motivation: 自动进行膝关节X光片KL分级具有挑战性，因为结构变化微妙、解剖结构依赖性长且接近分级边界时存在歧义。

Method: 提出AGE-Net框架，该框架基于ConvNeXt，集成了光谱-空间融合（SSF）、解剖图谱推理（AGR）和差异化细化（DFR）。为了捕获预测不确定性并保留标签的序数性，AGE-Net采用了正态-逆伽马（NIG）证据回归头和成对序数排序约束。

Result: 在膝关节KL数据集上，AGE-Net在三个随机种子下实现了0.9017 +/- 0.0045的二次加权kappa（QWK）和0.2349 +/- 0.0028的均方误差（MSE），优于强大的CNN基线，并在消融研究中显示出持续的改进。

Conclusion: AGE-Net框架在膝关节KL分级任务上表现出优越的性能，能够有效地处理预测不确定性和标签的序数性，并且在消融实验中证明了其各组件的有效性。

Abstract: Automated Kellgren--Lawrence (KL) grading from knee radiographs is challenging due to subtle structural changes, long-range anatomical dependencies, and ambiguity near grade boundaries. We propose AGE-Net, a ConvNeXt-based framework that integrates Spectral--Spatial Fusion (SSF), Anatomical Graph Reasoning (AGR), and Differential Refinement (DFR). To capture predictive uncertainty and preserve label ordinality, AGE-Net employs a Normal-Inverse-Gamma (NIG) evidential regression head and a pairwise ordinal ranking constraint. On a knee KL dataset, AGE-Net achieves a quadratic weighted kappa (QWK) of 0.9017 +/- 0.0045 and a mean squared error (MSE) of 0.2349 +/- 0.0028 over three random seeds, outperforming strong CNN baselines and showing consistent gains in ablation studies. We further outline evaluations of uncertainty quality, robustness, and explainability, with additional experimental figures to be included in the full manuscript.

</details>


### [117] [TEXTS-Diff: TEXTS-Aware Diffusion Model for Real-World Text Image Super-Resolution](https://arxiv.org/abs/2601.17340)
*Haodong He,Xin Zhan,Yancheng Bai,Rui Lan,Lei Sun,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 本研究提出了一个名为 Real-Texts 的大规模真实世界文本图像数据集，以及一个名为 TEXTS-Aware Diffusion Model (TEXTS-Diff) 的文本感知扩散模型，用于解决真实场景下文本图像超分辨率中的数据稀缺和背景重建质量不佳的问题。该模型能够同时生成高质量的背景和文本细节，并能有效减轻文本区域的失真和幻觉，同时保持背景的视觉保真度。实验证明该方法在多个评估指标上均达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有数据集中的文本图像数据稀缺，导致文本区域性能不佳；同时，由孤立文本样本组成的数据集限制了背景重建的质量。因此，需要一个包含真实世界场景、包含中英文自然文本实例的大规模数据集，以及一个能够同时处理背景和文本细节的超分辨率模型。

Method: 1. 构建 Real-Texts 数据集：收集大规模、高质量的真实世界图像，包含各种场景和中英文自然文本实例。 2. 提出 TEXTS-Aware Diffusion Model (TEXTS-Diff)：该模型利用抽象概念来理解文本元素，并利用具体的文本区域来增强文本细节，从而实现背景和文本区域的高质量生成。

Result: TEXTS-Diff 模型在多个评估指标上取得了最先进的性能，展现出在复杂场景下的优越泛化能力和文本恢复精度，有效减轻了文本区域的失真和幻觉，同时保持了背景的高视觉保真度。

Conclusion: Real-Texts 数据集和 TEXTS-Diff 模型能够有效解决真实世界文本图像超分辨率中的挑战，在文本细节恢复和背景重建方面均表现出色，并在复杂场景下具有良好的泛化能力。

Abstract: Real-world text image super-resolution aims to restore overall visual quality and text legibility in images suffering from diverse degradations and text distortions. However, the scarcity of text image data in existing datasets results in poor performance on text regions. In addition, datasets consisting of isolated text samples limit the quality of background reconstruction. To address these limitations, we construct Real-Texts, a large-scale, high-quality dataset collected from real-world images, which covers diverse scenarios and contains natural text instances in both Chinese and English. Additionally, we propose the TEXTS-Aware Diffusion Model (TEXTS-Diff) to achieve high-quality generation in both background and textual regions. This approach leverages abstract concepts to improve the understanding of textual elements within visual scenes and concrete text regions to enhance textual details. It mitigates distortions and hallucination artifacts commonly observed in text regions, while preserving high-quality visual scene fidelity. Extensive experiments demonstrate that our method achieves state-of-the-art performance across multiple evaluation metrics, exhibiting superior generalization ability and text restoration accuracy in complex scenarios. All the code, model, and dataset will be released.

</details>


### [118] [STARS: Shared-specific Translation and Alignment for missing-modality Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2601.17342)
*Tong Wang,Xiaodong Zhang,Guanzhou Chen,Jiaqi Wang,Chenxi Liu,Xiaoliang Tan,Wenchao Guo,Xuyang Li,Xuanrui Wang,Zifan Wang*

Main category: cs.CV

TL;DR: 提出了一种名为 STARS 的鲁棒多模态遥感语义分割框架，用于处理缺失模态数据，通过非对称对齐和像素级语义采样对齐策略，解决了特征塌陷和类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 在多模态遥感应用中，模态数据缺失是一个普遍且严峻的挑战，传统的融合模型在数据不完整时性能会下降。现有的处理缺失模态的方法存在特征塌陷和过度泛化等局限性。

Method: STARS 框架包含两个核心设计：1. 非对称对齐机制，结合了双向翻译和停止梯度，以防止特征塌陷并降低超参数敏感性。2. 像素级语义采样对齐 (PSA) 策略，通过类别平衡的像素采样和跨模态语义对齐损失，来解决类别不平衡导致的对齐失败问题。

Result: 提出的 STARS 框架能够有效地处理缺失模态的多模态遥感数据，并且在解决特征塌陷、降低超参数敏感性以及改善少数类识别方面表现出色。

Conclusion: STARS 是一种有效的多模态遥感语义分割框架，能够鲁棒地处理缺失模态输入，克服现有方法的局限性，并能有效处理类别不平衡问题。

Abstract: Multimodal remote sensing technology significantly enhances the understanding of surface semantics by integrating heterogeneous data such as optical images, Synthetic Aperture Radar (SAR), and Digital Surface Models (DSM). However, in practical applications, the missing of modality data (e.g., optical or DSM) is a common and severe challenge, which leads to performance decline in traditional multimodal fusion models. Existing methods for addressing missing modalities still face limitations, including feature collapse and overly generalized recovered features. To address these issues, we propose \textbf{STARS} (\textbf{S}hared-specific \textbf{T}ranslation and \textbf{A}lignment for missing-modality \textbf{R}emote \textbf{S}ensing), a robust semantic segmentation framework for incomplete multimodal inputs. STARS is built on two key designs. First, we introduce an asymmetric alignment mechanism with bidirectional translation and stop-gradient, which effectively prevents feature collapse and reduces sensitivity to hyperparameters. Second, we propose a Pixel-level Semantic sampling Alignment (PSA) strategy that combines class-balanced pixel sampling with cross-modality semantic alignment loss, to mitigate alignment failures caused by severe class imbalance and improve minority-class recognition.

</details>


### [119] [Revisiting Lightweight Low-Light Image Enhancement: From a YUV Color Space Perspective](https://arxiv.org/abs/2601.17349)
*Hailong Yan,Shice Liu,Xiangtao Zhang,Lujian Yao,Fengxiang Yang,Jinwei Chen,Bo Li*

Main category: cs.CV

TL;DR: 本文提出了一种新的基于YUV色彩空间的轻量级低光图像增强方法（L3IE），通过分析YUV通道在不同频域的退化特性，设计了针对Y通道和UV通道的特定增强模块，并引入通道间的引导交互，实现了在参数量更少的情况下达到SOTA的增强效果。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级低光图像增强方法在模型紧凑性和视觉质量之间存在权衡，并且忽略了通道特定的退化模式和跨通道交互，限制了性能提升。本文旨在解决这一问题。

Method: 1. 进行了频域分析，证实了YUV色彩空间在L3IE中的优势。2. 识别出Y通道主要丢失低频信息，UV通道易受高频噪声干扰。3. 提出了一种新颖的YUV基方法，包含：针对Y通道的双流全局-局部注意力模块，针对UV通道的Y引导局部感知频率注意力模块，以及用于特征融合的引导交互模块。

Result: 所提出的模型在多个基准测试中达到了新的SOTA水平，在显著降低参数量的同时提供了卓越的视觉质量。

Conclusion: 通过分析YUV色彩空间在不同频域的退化特性，并设计相应的通道特定增强和交互机制，本文提出的轻量级低光图像增强方法能够有效克服现有方法的局限，实现高质量的图像增强。

Abstract: In the current era of mobile internet, Lightweight Low-Light Image Enhancement (L3IE) is critical for mobile devices, which faces a persistent trade-off between visual quality and model compactness. While recent methods employ disentangling strategies to simplify lightweight architectural design, such as Retinex theory and YUV color space transformations, their performance is fundamentally limited by overlooking channel-specific degradation patterns and cross-channel interactions. To address this gap, we perform a frequency-domain analysis that confirms the superiority of the YUV color space for L3IE. We identify a key insight: the Y channel primarily loses low-frequency content, while the UV channels are corrupted by high-frequency noise. Leveraging this finding, we propose a novel YUV-based paradigm that strategically restores channels using a Dual-Stream Global-Local Attention module for the Y channel, a Y-guided Local-Aware Frequency Attention module for the UV channels, and a Guided Interaction module for final feature fusion. Extensive experiments validate that our model establishes a new state-of-the-art on multiple benchmarks, delivering superior visual quality with a significantly lower parameter count.

</details>


### [120] [NeRF-MIR: Towards High-Quality Restoration of Masked Images with Neural Radiance Fields](https://arxiv.org/abs/2601.17350)
*Xianliang Huang,Zhizhou Zhong,Shuhang Chen,Yi Xu,Juhong Guan,Shuigeng Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为 NeRF-MIR 的新方法，用于从遮挡的图像中恢复 3D 场景，并提出了一种名为 PERE 的新射线发射策略和 PIRE 机制来改进 NeRF 在此任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的 NeRF 方法在处理自然场景拍摄中常见的图像损坏（尤其是遮挡）时效果不佳，限制了 NeRF 在这些场景下的应用。因此，需要开发专门用于从遮挡图像中恢复 3D 场景的方法。

Method: 1. 提出 PERE（Patch-based Entropy for Ray Emitting）策略，以更有效地分配射线发射，捕捉精细纹理。 2. 引入 PIRE（Progressively Iterative REstoration）机制，通过自训练过程迭代地恢复遮挡区域。 3. 设计了一个动态加权的损失函数，自动调整遮挡区域的损失权重。 4. 构建了三个新的遮挡图像数据集来模拟损坏场景。

Result: NeRF-MIR 在从遮挡图像恢复 3D 场景方面表现优于现有方法，并在真实数据和新构建的数据集上都取得了显著效果。

Conclusion: NeRF-MIR 是一种有效的处理带遮挡图像的 NeRF 方法，通过 PERE 射线发射策略、PIRE 迭代恢复机制和动态损失函数，能够从损坏的图像中成功恢复 3D 场景，拓展了 NeRF 的应用范围。

Abstract: Neural Radiance Fields (NeRF) have demonstrated remarkable performance in novel view synthesis. However, there is much improvement room on restoring 3D scenes based on NeRF from corrupted images, which are common in natural scene captures and can significantly impact the effectiveness of NeRF. This paper introduces NeRF-MIR, a novel neural rendering approach specifically proposed for the restoration of masked images, demonstrating the potential of NeRF in this domain. Recognizing that randomly emitting rays to pixels in NeRF may not effectively learn intricate image textures, we propose a \textbf{P}atch-based \textbf{E}ntropy for \textbf{R}ay \textbf{E}mitting (\textbf{PERE}) strategy to distribute emitted rays properly. This enables NeRF-MIR to fuse comprehensive information from images of different views. Additionally, we introduce a \textbf{P}rogressively \textbf{I}terative \textbf{RE}storation (\textbf{PIRE}) mechanism to restore the masked regions in a self-training process. Furthermore, we design a dynamically-weighted loss function that automatically recalibrates the loss weights for masked regions. As existing datasets do not support NeRF-based masked image restoration, we construct three masked datasets to simulate corrupted scenarios. Extensive experiments on real data and constructed datasets demonstrate the superiority of NeRF-MIR over its counterparts in masked image restoration.

</details>


### [121] [HyDeMiC: A Deep Learning-based Mineral Classifier using Hyperspectral Data](https://arxiv.org/abs/2601.17352)
*M. L. Mamud,Piyoosh Jaysaval,Frederick D Day-Lewis,M. K. Mudunuru*

Main category: cs.CV

TL;DR: 本研究提出了一种名为 HyDeMiC 的卷积神经网络模型，用于在存在噪声的情况下对高光谱成像数据中的矿物进行鲁棒分类，并在模拟噪声数据集上取得了近乎完美的高精度。 


<details>
  <summary>Details</summary>
Motivation: 传统的高光谱成像矿物分类方法在处理环境噪声、传感器限制和高维数据计算复杂性方面存在困难。 

Method: 利用 USGS 矿物光谱库的实验室数据训练一个卷积神经网络模型（HyDeMiC）。通过将参考光谱与传感器响应函数卷积来生成训练数据集，并使用包含三种铜矿物（Cuprite、Malachite 和 Chalcopyrite）的数据集进行案例研究。在不同噪声水平（1%、2%、5%、10%）的合成 2D 高光谱数据集上评估 HyDeMiC 的性能，并使用 Matthews Correlation Coefficient (MCC) 作为评估指标。 

Result: HyDeMiC 在无噪声和低噪声数据集上实现了近乎完美的分类精度（MCC = 1.00），并在中等噪声条件下仍保持了良好的性能。 

Conclusion: HyDeMiC 模型对于高光谱成像领域的实际应用具有潜力，因为它在中等噪声存在的情况下表现出鲁棒性，克服了现实世界应用中常见的噪声挑战。 

Abstract: Hyperspectral imaging (HSI) has emerged as a powerful remote sensing tool for mineral exploration, capitalizing on unique spectral signatures of minerals. However, traditional classification methods such as discriminant analysis, logistic regression, and support vector machines often struggle with environmental noise in data, sensor limitations, and the computational complexity of analyzing high-dimensional HSI data. This study presents HyDeMiC (Hyperspectral Deep Learning-based Mineral Classifier), a convolutional neural network (CNN) model designed for robust mineral classification under noisy data. To train HyDeMiC, laboratory-measured hyperspectral data for 115 minerals spanning various mineral groups were used from the United States Geological Survey (USGS) library. The training dataset was generated by convolving reference mineral spectra with an HSI sensor response function. These datasets contained three copper-bearing minerals, Cuprite, Malachite, and Chalcopyrite, used as case studies for performance demonstration. The trained CNN model was evaluated on several synthetic 2D hyperspectral datasets with noise levels of 1%, 2%, 5%, and 10%. Our noisy data analysis aims to replicate realistic field conditions. The HyDeMiC's performance was assessed using the Matthews Correlation Coefficient (MCC), providing a comprehensive measure across different noise regimes. Results demonstrate that HyDeMiC achieved near-perfect classification accuracy (MCC = 1.00) on clean and low-noise datasets and maintained strong performance under moderate noise conditions. These findings emphasize HyDeMiC's robustness in the presence of moderate noise, highlighting its potential for real-world applications in hyperspectral imaging, where noise is often a significant challenge.

</details>


### [122] [PocketGS: On-Device Training of 3D Gaussian Splatting for High Perceptual Modeling](https://arxiv.org/abs/2601.17354)
*Wenzhi Guo,Guangchi Fang,Shu Yang,Bing Wang*

Main category: cs.CV

TL;DR: PocketGS 提出了一种在移动设备上高效进行 3D 高斯溅射（3DGS）训练的方法，克服了内存和时间限制，同时保持了高保真度。


<details>
  <summary>Details</summary>
Motivation: 现有 3DGS 方法需要大量计算资源，无法在计算能力受限的移动设备上进行训练，而移动设备上的 3D 场景建模需求日益增长。

Method: PocketGS 引入了三个协同设计的算子：G 用于构建几何信息丰富的点云先验；I 通过注入局部表面统计信息来初始化各向异性高斯，减少早期训练的鸿沟；T 通过缓存中间结果和索引映射的梯度散射来优化 alpha 合成，实现移动端稳定的反向传播。

Result: PocketGS 在资源受限的移动设备上实现了与强大工作站级 3DGS 基线相当甚至更好的重建质量，展示了完全在设备上进行从捕获到渲染的工作流程。

Conclusion: PocketGS 成功解决了在移动设备上进行 3DGS 训练的效率、内存和保真度之间的矛盾，使得高质量的 3D 场景建模能够真正实现端到端在设备上完成。

Abstract: Efficient and high-fidelity 3D scene modeling is a long-standing pursuit in computer graphics. While recent 3D Gaussian Splatting (3DGS) methods achieve impressive real-time modeling performance, they rely on resource-unconstrained training assumptions that fail on mobile devices, which are limited by minute-scale training budgets and hardware-available peak-memory. We present PocketGS, a mobile scene modeling paradigm that enables on-device 3DGS training under these tightly coupled constraints while preserving high perceptual fidelity. Our method resolves the fundamental contradictions of standard 3DGS through three co-designed operators: G builds geometry-faithful point-cloud priors; I injects local surface statistics to seed anisotropic Gaussians, thereby reducing early conditioning gaps; and T unrolls alpha compositing with cached intermediates and index-mapped gradient scattering for stable mobile backpropagation. Collectively, these operators satisfy the competing requirements of training efficiency, memory compactness, and modeling fidelity. Extensive experiments demonstrate that PocketGS is able to outperform the powerful mainstream workstation 3DGS baseline to deliver high-quality reconstructions, enabling a fully on-device, practical capture-to-rendering workflow.

</details>


### [123] [UCAD: Uncertainty-guided Contour-aware Displacement for semi-supervised medical image segmentation](https://arxiv.org/abs/2601.17366)
*Chengbo Ding,Fenghe Tang,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为UCAD的用于半监督医学图像分割的框架，该框架通过利用超像素和不确定性引导来保留解剖结构，生成更准确的分割结果，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有半监督分割方法在处理矩形区域时会忽略解剖结构，导致边界失真和语义不一致。需要一种能保留解剖结构和提高一致性学习的方法。

Method: 提出UCAD框架，利用超像素生成解剖上一致的区域，并结合不确定性引导选择机制来优化挑战性区域的一致性学习。引入动态不确定性加权一致性损失来稳定训练并正则化模型。

Result: UCAD在有限标注下始终优于最先进的半监督分割方法，实现了更高的分割精度。

Conclusion: UCAD框架能够有效保留解剖结构感知的语义信息，并增强一致性学习，从而在半监督医学图像分割任务中取得优异性能。

Abstract: Existing displacement strategies in semi-supervised segmentation only operate on rectangular regions, ignoring anatomical structures and resulting in boundary distortions and semantic inconsistency. To address these issues, we propose UCAD, an Uncertainty-Guided Contour-Aware Displacement framework for semi-supervised medical image segmentation that preserves contour-aware semantics while enhancing consistency learning. Our UCAD leverages superpixels to generate anatomically coherent regions aligned with anatomy boundaries, and an uncertainty-guided selection mechanism to selectively displace challenging regions for better consistency learning. We further propose a dynamic uncertainty-weighted consistency loss, which adaptively stabilizes training and effectively regularizes the model on unlabeled regions. Extensive experiments demonstrate that UCAD consistently outperforms state-of-the-art semi-supervised segmentation methods, achieving superior segmentation accuracy under limited annotation. The code is available at:https://github.com/dcb937/UCAD.

</details>


### [124] [Physical Prompt Injection Attacks on Large Vision-Language Models](https://arxiv.org/abs/2601.17383)
*Chen Ling,Kai Hu,Hangcheng Liu,Xingshuo Han,Tianwei Zhang,Changhai Ou*

Main category: cs.CV

TL;DR: 提出了一种针对大型视觉语言模型（LVLM）的物理提示注入攻击（PPIA），这是一种黑盒、查询无关的攻击，通过在物理对象中嵌入恶意文本指令来操纵LVLM的行为。


<details>
  <summary>Details</summary>
Motivation: 现有的针对LVLM的提示注入攻击方法通常需要访问输入通道或了解用户查询，这在实际应用中难以实现。因此，需要一种不依赖这些假设的物理层面的攻击方法。

Method: PPIA结合了离线选择易于识别且语义有效的视觉提示，以及基于时空注意力进行环境感知放置的策略。攻击者通过操纵物理对象上的文本来欺骗LVLM。

Result: 在模拟和真实世界环境中，针对10个最先进的LVLM，PPIA在视觉问答、规划和导航等任务上取得了高达98%的攻击成功率，并且在距离、视角和光照等不同物理条件下表现出强大的鲁棒性。

Conclusion: PPIA是首个物理提示注入攻击，它能够在不访问模型或其输入的情况下，通过视觉操纵来成功攻击LVLM，展示了LVLM在实际部署中的新安全风险。

Abstract: Large Vision-Language Models (LVLMs) are increasingly deployed in real-world intelligent systems for perception and reasoning in open physical environments. While LVLMs are known to be vulnerable to prompt injection attacks, existing methods either require access to input channels or depend on knowledge of user queries, assumptions that rarely hold in practical deployments. We propose the first Physical Prompt Injection Attack (PPIA), a black-box, query-agnostic attack that embeds malicious typographic instructions into physical objects perceivable by the LVLM. PPIA requires no access to the model, its inputs, or internal pipeline, and operates solely through visual observation. It combines offline selection of highly recognizable and semantically effective visual prompts with strategic environment-aware placement guided by spatiotemporal attention, ensuring that the injected prompts are both perceivable and influential on model behavior. We evaluate PPIA across 10 state-of-the-art LVLMs in both simulated and real-world settings on tasks including visual question answering, planning, and navigation, PPIA achieves attack success rates up to 98%, with strong robustness under varying physical conditions such as distance, viewpoint, and illumination. Our code is publicly available at https://github.com/2023cghacker/Physical-Prompt-Injection-Attack.

</details>


### [125] [ONRW: Optimizing inversion noise for high-quality and robust watermark](https://arxiv.org/abs/2601.17388)
*Xuan Ding,Xiu Yan,Chuanlong Xie,Yao Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的鲁棒水印框架，通过优化逆向噪声并利用扩散模型的迭代去噪过程来增强水印的鲁棒性和图像质量，并引入了自注意力约束和伪掩码策略以保持图像语义。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习水印方法虽然能在图像中隐藏水印且不影响图像质量，但在图像传输过程中面对损坏时鲁棒性不足，限制了其实际应用价值。因此，需要一种既能保证图像质量又能抵抗各种损坏的方法。

Method: 1. 将原始图像通过空文本优化转换为逆向噪声。 2. 在潜在空间优化逆向噪声。 3. 通过扩散模型的迭代去噪过程生成高质量的水印图像。 4. 引入自注意力约束和伪掩码策略以防止噪声优化扭曲图像语义。

Result: 所提方法在应对各种图像损坏方面表现出优越性能，在COCO数据集上的12种不同图像变换中，平均性能比稳定签名方法（stable signature method）高出10%。

Conclusion: 基于扩散模型的鲁棒水印框架能够生成高质量的水印图像，并对多种图像损坏具有良好的鲁棒性，优于现有方法。

Abstract: Watermarking methods have always been effective means of protecting intellectual property, yet they face significant challenges. Although existing deep learning-based watermarking systems can hide watermarks in images with minimal impact on image quality, they often lack robustness when encountering image corruptions during transmission, which undermines their practical application value. To this end, we propose a high-quality and robust watermark framework based on the diffusion model. Our method first converts the clean image into inversion noise through a null-text optimization process, and after optimizing the inversion noise in the latent space, it produces a high-quality watermarked image through an iterative denoising process of the diffusion model. The iterative denoising process serves as a powerful purification mechanism, ensuring both the visual quality of the watermarked image and enhancing the robustness of the watermark against various corruptions. To prevent the optimizing of inversion noise from distorting the original semantics of the image, we specifically introduced self-attention constraints and pseudo-mask strategies. Extensive experimental results demonstrate the superior performance of our method against various image corruptions. In particular, our method outperforms the stable signature method by an average of 10\% across 12 different image transformations on COCO datasets. Our codes are available at https://github.com/920927/ONRW.

</details>


### [126] [SMV-EAR: Bring Spatiotemporal Multi-View Representation Learning into Efficient Event-Based Action Recognition](https://arxiv.org/abs/2601.17391)
*Rui Fan,Weidong Hao*

Main category: cs.CV

TL;DR: 本文提出了一种新的事件相机动作识别（EAR）框架，通过改进时空多视图表示学习（SMVRL）方法，解决了现有方法的平移不变性和早期融合不足的问题，并通过新的数据增强方式提升了性能，在多个数据集上取得了显著的准确率提升，同时减少了参数和计算量。


<details>
  <summary>Details</summary>
Motivation: 现有事件相机动作识别（EAR）方法在时空多视图表示学习（SMVRL）方面存在局限性，主要体现在其平移不变的事件表示以及早期串联融合的架构设计，这限制了其捕捉动作动态的能力。

Method: 1. 提出了一种基于稠密转换的平移不变时空多视图表示方法，用于处理稀疏的事件数据。 2. 设计了一个双分支动态融合架构，以建模不同视图之间运动特征的样本级互补性。 3. 引入了一种受生物启发的时域扭曲增强方法，以模拟真实世界人类动作的速度变化。

Result: 在HARDVS、DailyDVS-200和THU-EACT-50-CHL三个具有挑战性的EAR数据集上，与现有的SMVRL EOR方法相比，Top-1准确率分别提高了+7.0%、+10.7%和+10.2%。同时，参数量减少了30.1%，计算量降低了35.7%。

Conclusion: 所提出的框架是一种新颖且强大的EAR范式，通过改进表示学习和融合策略，显著提升了事件相机动作识别的性能，并且在效率方面也表现出色。

Abstract: Event cameras action recognition (EAR) offers compelling privacy-protecting and efficiency advantages, where temporal motion dynamics is of great importance. Existing spatiotemporal multi-view representation learning (SMVRL) methods for event-based object recognition (EOR) offer promising solutions by projecting H-W-T events along spatial axis H and W, yet are limited by its translation-variant spatial binning representation and naive early concatenation fusion architecture. This paper reexamines the key SMVRL design stages for EAR and propose: (i) a principled spatiotemporal multi-view representation through translation-invariant dense conversion of sparse events, (ii) a dual-branch, dynamic fusion architecture that models sample-wise complementarity between motion features from different views, and (iii) a bio-inspired temporal warping augmentation that mimics speed variability of real-world human actions. On three challenging EAR datasets of HARDVS, DailyDVS-200 and THU-EACT-50-CHL, we show +7.0%, +10.7%, and +10.2% Top-1 accuracy gains over existing SMVRL EOR method with surprising 30.1% reduced parameters and 35.7% lower computations, establishing our framework as a novel and powerful EAR paradigm.

</details>


### [127] [HAAF: Hierarchical Adaptation and Alignment of Foundation Models for Few-Shot Pathology Anomaly Detection](https://arxiv.org/abs/2601.17405)
*Chunze Yang,Wenjie Zhao,Yue Tang,Junbo Lu,Jiusong Ge,Qidong Liu,Zeyu Gao,Chen Li*

Main category: cs.CV

TL;DR: 本研究提出了一个名为 HAAF 的层级适应与对齐框架，通过一种新的跨层级缩放对齐（CLSA）机制，解决了视觉语言模型在精确病理学中因粒度不匹配而导致的识别细微病变的问题，提高了在低资源场景下的模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在处理精确病理学任务时存在粒度不匹配问题，即通用表征无法识别ROI内的细微形态异常，而专家诊断主要依赖于这些局部纹理线索。此外，当前适应方法未能有效地将文本提示与ROI的视觉上下文相结合。

Method: 提出了一种层级适应与对齐框架（HAAF），核心是跨层级缩放对齐（CLSA）机制。该机制首先将视觉特征注入文本提示以生成内容自适应描述符，然后利用这些描述符空间地指导视觉编码器聚焦于异常区域。此外，还采用了一种双分支推理策略，结合语义分数和几何原型，以增强少样本学习下的模型稳定性。

Result: 在四个基准测试中，HAAF显著优于最先进的方法。在低资源场景下，HAAF能够有效地与领域特定的骨干网络（如CONCH）一起扩展。

Conclusion: HAAF框架成功地解决了视觉语言模型在精确病理学中识别细微形态异常的粒度不匹配问题，并通过创新的CLSA机制和双分支推理策略，在低资源和少样本设置下实现了显著的性能提升。

Abstract: Precision pathology relies on detecting fine-grained morphological abnormalities within specific Regions of Interest (ROIs), as these local, texture-rich cues - rather than global slide contexts - drive expert diagnostic reasoning. While Vision-Language (V-L) models promise data efficiency by leveraging semantic priors, adapting them faces a critical Granularity Mismatch, where generic representations fail to resolve such subtle defects. Current adaptation methods often treat modalities as independent streams, failing to ground semantic prompts in ROI-specific visual contexts. To bridge this gap, we propose the Hierarchical Adaptation and Alignment Framework (HAAF). At its core is a novel Cross-Level Scaled Alignment (CLSA) mechanism that enforces a sequential calibration order: visual features first inject context into text prompts to generate content-adaptive descriptors, which then spatially guide the visual encoder to spotlight anomalies. Additionally, a dual-branch inference strategy integrates semantic scores with geometric prototypes to ensure stability in few-shot settings. Experiments on four benchmarks show HAAF significantly outperforms state-of-the-art methods and effectively scales with domain-specific backbones (e.g., CONCH) in low-resource scenarios.

</details>


### [128] [ReLE: A Scalable System and Structured Benchmark for Diagnosing Capability Anisotropy in Chinese LLMs](https://arxiv.org/abs/2601.17399)
*Rui Fang,Jian Li,Wei Chen,Bin Hu,Ying-Cong Chen,Xin Tang,Liang Diao*

Main category: cs.CV

TL;DR: 本研究提出了一种名为ReLE（鲁棒高效实时评估）的系统，用于评估中文大语言模型在不同领域和能力上的非均匀性能（能力各向异性）。ReLE通过一种新的混合评分机制和动态调度器，降低了评估成本（70%）并提高了排名相关性（ρ=0.96）。研究发现，模型表现高度专业化，整体排名对权重敏感。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型评估方法存在基准饱和和计算成本高昂的问题，静态排行榜也掩盖了模型能力之间的结构性权衡。因此，需要一种能够诊断模型在不同领域性能不均匀性的评估方法。

Method: 1. 提出了一种符号基础的混合评分机制，以解决推理任务中基于嵌入的误报问题。2. 引入了一种基于Neyman分配的动态方差感知调度器，并进行了噪声校正，以降低计算成本。3. 在由207,843个样本组成的“领域×能力”正交矩阵上评估了304个模型（189个商业模型，115个开源模型）。

Result: ReLE评估结果显示，模型表现出11.4的排名稳定性幅度（RSA），远高于传统基准的约5.0，表明现代模型高度专业化。研究还发现，模型在不同领域和能力上的表现差异很大。混合评分机制和动态调度器将计算成本降低了70%，同时保持了0.96的排名相关性。

Conclusion: ReLE系统可以作为一种高频诊断工具，用于监测不断发展的大语言模型格局，揭示模型的“能力各向异性”，并提供比传统静态基准更精细的模型性能视图。它并非取代现有基准，而是作为一种补充。

Abstract: Large Language Models (LLMs) have achieved rapid progress in Chinese language understanding, yet accurately evaluating their capabilities remains challenged by benchmark saturation and prohibitive computational costs. While static leaderboards provide snapshot rankings, they often mask the structural trade-offs between capabilities. In this work, we present ReLE (Robust Efficient Live Evaluation), a scalable system designed to diagnose Capability Anisotropy, the non-uniformity of model performance across domains. Using ReLE, we evaluate 304 models (189 commercial, 115 open-source) across a Domain $\times$ Capability orthogonal matrix comprising 207,843 samples. We introduce two methodological contributions to address current evaluation pitfalls: (1) A Symbolic-Grounded Hybrid Scoring Mechanism that eliminates embedding-based false positives in reasoning tasks; (2) A Dynamic Variance-Aware Scheduler based on Neyman allocation with noise correction, which reduces compute costs by 70\% compared to full-pass evaluations while maintaining a ranking correlation of $ρ=0.96$. Our analysis reveals that aggregate rankings are highly sensitive to weighting schemes: models exhibit a Rank Stability Amplitude (RSA) of 11.4 in ReLE versus $\sim$5.0 in traditional benchmarks, confirming that modern models are highly specialized rather than generally superior. We position ReLE not as a replacement for comprehensive static benchmarks, but as a high-frequency diagnostic monitor for the evolving model landscape.

</details>


### [129] [Source-Free Domain Adaptation by Optimizing Batch-Wise Cosine Similarity](https://arxiv.org/abs/2601.17408)
*Harsharaj Pathak,Vineeth N Balasubramanian*

Main category: cs.CV

TL;DR: 提出了一种无源域自适应方法，通过学习信息性聚类和使用“邻域签名”来减轻噪声邻居的影响，仅用一个损失项即可优化预测的相似性和差异性。


<details>
  <summary>Details</summary>
Motivation: 现有的无源域自适应方法（SFDA）大多依赖邻域一致性，但容易受到误导性邻域信息的影响。研究人员希望找到一种更有效的方法来处理这个问题。

Method: 该方法从学习更具信息性的聚类的角度出发，并利用“邻域签名”的概念来减轻噪声邻居的影响。最终目标是仅通过一个精心设计的损失项来优化目标域样本预测的相似性和差异性。

Result: 所提出的方法在具有挑战性的 VisDA 数据集上超越了现有方法，并在其他基准数据集上也取得了具有竞争力的结果。

Conclusion: 通过学习信息性聚类和利用邻域签名，可以在不访问源数据的情况下，仅使用一个损失项实现有效的无源域自适应，并能有效处理噪声邻居问题。

Abstract: Source-Free Domain Adaptation (SFDA) is an emerging area of research that aims to adapt a model trained on a labeled source domain to an unlabeled target domain without accessing the source data. Most of the successful methods in this area rely on the concept of neighborhood consistency but are prone to errors due to misleading neighborhood information. In this paper, we explore this approach from the point of view of learning more informative clusters and mitigating the effect of noisy neighbors using a concept called neighborhood signature, and demonstrate that adaptation can be achieved using just a single loss term tailored to optimize the similarity and dissimilarity of predictions of samples in the target domain. In particular, our proposed method outperforms existing methods in the challenging VisDA dataset while also yielding competitive results on other benchmark datasets.

</details>


### [130] [Cloud-Enabled IoT System for Real-Time Environmental Monitoring and Remote Device Control Using Firebase](https://arxiv.org/abs/2601.17414)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本研究提出了一种基于Firebase的云连接IoT系统，使用ESP32微控制器连接温湿度和超声波传感器，并能远程控制LED，实现了实时数据同步、远程控制和云存储，成本低廉且易于部署。


<details>
  <summary>Details</summary>
Motivation: 传统监控系统在实时数据访问、远程控制和云集成方面存在局限性，推动了对更高效、可扩展的云连接IoT系统的需求。

Method: 使用ESP32微控制器连接DHT22（温湿度）和HC-SR04（超声波）传感器，并通过Google Firebase Realtime Database实现传感器数据的实时同步上传和LED指示灯的远程控制。系统设计为多设备可同时访问。

Result: 实验证明，系统数据传输成功率高达99.2%，远程控制延迟低于1.5秒。Firebase提供了持久的数据存储，支持历史分析。该系统易于扩展，总实现成本为32.50美元。

Conclusion: 本研究成功开发了一个成本低廉、易于部署且功能强大的云连接IoT系统。通过集成Firebase，该系统克服了传统IoT系统的局限性，为智能家居、工业监控等多种IoT应用提供了一个可扩展的框架，尤其适合资源有限的开发者和研究人员。

Abstract: The proliferation of Internet of Things (IoT) devices has created unprecedented opportunities for remote monitoring and control applications across various domains. Traditional monitoring systems often suffer from limitations in real-time data accessibility, remote controllability, and cloud integration. This paper presents a cloud-enabled IoT system that leverages Google's Firebase Realtime Database for synchronized environmental monitoring and device control. The system utilizes an ESP32 microcontroller to interface with a DHT22 temperature/humidity sensor and an HC-SR04 ultrasonic distance sensor, while enabling remote control of two LED indicators through a cloud-based interface. Real-time sensor data is transmitted to Firebase, providing a synchronized platform accessible from multiple devices simultaneously. Experimental results demonstrate reliable data transmission with 99.2\% success rate, real-time control latency under 1.5 seconds, and persistent data storage for historical analysis. The system architecture offers a scalable framework for various IoT applications, from smart home automation to industrial monitoring, with a total implementation cost of \$32.50. The integration of Firebase provides robust cloud capabilities without requiring complex server infrastructure, making advanced IoT applications accessible to developers and researchers with limited resources.

</details>


### [131] [CoT-Seg: Rethinking Segmentation with Chain-of-Thought Reasoning and Self-Correction](https://arxiv.org/abs/2601.17420)
*Shiu-hong Kao,Chak Ho Huang,Huaiqian Liu,Yu-Wing Tai,Chi-Keung Tang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 CoT-Seg 的无训练框架，结合了链式思考（Chain-of-Thought）推理和自我纠错机制，用于解决复杂的推理分割问题，特别是针对复杂查询和领域外图像。该框架能够分解查询、提取图像语义、识别目标，并通过自我评估和迭代修正来提高分割的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有推理分割方法在处理复杂查询和领域外图像时效果不佳。受到人类解决复杂问题时需要逐步思考的启发，作者希望构建一个能够进行逐步思考、信息检索、生成结果、自我评估和结果精炼的系统。

Method: CoT-Seg 是一个训练无关的框架，它利用预训练的多模态大型语言模型（MLLMs，如 GPT-4o）的推理能力，将查询分解为元指令，提取图像的细粒度语义，并识别目标对象。该框架还包含一个自我纠错阶段，模型会根据原始查询和推理过程评估自身的分割结果，识别不匹配之处并进行迭代优化。此外，CoT-Seg 支持检索增强推理，允许系统在信息不足时访问外部知识。

Result: CoT-Seg 在处理模糊或易出错的分割任务时，显著提高了结果的可靠性和鲁棒性。通过引入新的数据集 ReasonSeg-Hard，该框架展示了其处理极具挑战性案例的能力。

Conclusion: 结合链式思考推理和自我纠错是一种强大的范式，能够有效提升视觉-语言驱动的分割能力，尤其是在处理复杂和具有挑战性的推理分割任务时。

Abstract: Existing works of reasoning segmentation often fall short in complex cases, particularly when addressing complicated queries and out-of-domain images. Inspired by the chain-of-thought reasoning, where harder problems require longer thinking steps/time, this paper aims to explore a system that can think step-by-step, look up information if needed, generate results, self-evaluate its own results, and refine the results, in the same way humans approach harder questions. We introduce CoT-Seg, a training-free framework that rethinks reasoning segmentation by combining chain-of-thought reasoning with self-correction. Instead of fine-tuning, CoT-Seg leverages the inherent reasoning ability of pre-trained MLLMs (GPT-4o) to decompose queries into meta-instructions, extract fine-grained semantics from images, and identify target objects even under implicit or complex prompts. Moreover, CoT-Seg incorporates a self-correction stage: the model evaluates its own segmentation against the original query and reasoning trace, identifies mismatches, and iteratively refines the mask. This tight integration of reasoning and correction significantly improves reliability and robustness, especially in ambiguous or error-prone cases. Furthermore, our CoT-Seg framework allows easy incorporation of retrieval-augmented reasoning, enabling the system to access external knowledge when the input lacks sufficient information. To showcase CoT-Seg's ability to handle very challenging cases ,we introduce a new dataset ReasonSeg-Hard. Our results highlight that combining chain-of-thought reasoning, self-correction, offers a powerful paradigm for vision-language integration driven segmentation.

</details>


### [132] [ReflexSplit: Single Image Reflection Separation via Layer Fusion-Separation](https://arxiv.org/abs/2601.17468)
*Chia-Ming Lee,Yu-Fan Lin,Jing-Hui Jung,Yu-Jou Hsiao,Chih-Chung Hsu,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 提出了一种名为ReflexSplit的双流框架，用于单图像反射分离，通过跨尺度门控融合、层融合-分离块以及课程训练来解决现有方法中的传输-反射混淆问题，并在合成和真实数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有单图像反射分离方法在非线性混合下，尤其是在深层解码器中，存在传输-反射混淆问题，这是由于隐式融合机制和多尺度协调不足造成的。

Method: 提出了一种名为ReflexSplit的双流框架，包含三个创新点：1. 跨尺度门控融合（CrGF）自适应地聚合分层深度的语义先验、纹理细节和解码器上下文。2. 层融合-分离块（LFSB）交替进行融合（共享结构提取）和差异化分离（层特定解耦），通过跨流减法扩展了注意力取消到双流分离。3. 课程训练通过深度依赖初始化和分期预热逐步加强差异化分离。

Result: 在合成和真实世界的基准数据集上进行了广泛的实验，表明ReflexSplit具有最先进的性能，具有卓越的感知质量和鲁棒的泛化能力。

Conclusion: ReflexSplit框架通过其创新的组件有效解决了单图像反射分离中的传输-反射混淆问题，并在各种基准测试中取得了优于现有方法的性能。

Abstract: Single Image Reflection Separation (SIRS) disentangles mixed images into transmission and reflection layers. Existing methods suffer from transmission-reflection confusion under nonlinear mixing, particularly in deep decoder layers, due to implicit fusion mechanisms and inadequate multi-scale coordination. We propose ReflexSplit, a dual-stream framework with three key innovations. (1) Cross-scale Gated Fusion (CrGF) adaptively aggregates semantic priors, texture details, and decoder context across hierarchical depths, stabilizing gradient flow and maintaining feature consistency. (2) Layer Fusion-Separation Blocks (LFSB) alternate between fusion for shared structure extraction and differential separation for layer-specific disentanglement. Inspired by Differential Transformer, we extend attention cancellation to dual-stream separation via cross-stream subtraction. (3) Curriculum training progressively strengthens differential separation through depth-dependent initialization and epoch-wise warmup. Extensive experiments on synthetic and real-world benchmarks demonstrate state-of-the-art performance with superior perceptual quality and robust generalization. Our code is available at https://github.com/wuw2135/ReflexSplit.

</details>


### [133] [Coronary Artery Segmentation and Vessel-Type Classification in X-Ray Angiography](https://arxiv.org/abs/2601.17429)
*Mehdi Yousefzadeh,Siavash Shirzadeh Barough,Ashkan Fakharifar,Yashar Tayyarazad,Narges Eghbali,Mohaddeseh Mozaffari,Hoda Taeb,Negar Sadat Rafiee Tabatabaee,Parsa Esfahanian,Ghazaleh Sadeghi Gohar,Amineh Safavirad,Saeideh Mazloomzadeh,Ehsan khalilipur,Armin Elahifar,Majid Maleki*

Main category: cs.CV

TL;DR: 本研究提出了一种用于 X 射线冠状动脉造影（XCA）的自动血管分割和类型标记方法，以克服传统方法的局限性。通过结合图像增强、多种分割算法（包括经典方法和深度学习模型）以及支持向量回归（SVR）进行参数调优，并引入合并的冠状动脉和导管标签进行训练，显著提高了分割精度和泛化能力，并在外部数据集上得到了验证。


<details>
  <summary>Details</summary>
Motivation: X 射线冠状动脉造影（XCA）是诊断冠状动脉疾病的金标准，但其量化分析受限于血管分割的准确性，尤其是在低对比度、运动、重叠等复杂场景下。现有的分割方法在不同中心的数据上存在域转移问题，影响了下游的血管特异性分析。因此，需要更鲁棒的分割和血管类型标记方法。

Method: 1. 图像预处理：选取峰值显影帧，进行低强度直方图筛选，并应用联合超分辨率和增强技术。 2. 血管分割：比较经典方法（Meijering, Frangi, Sato）在不同调优策略（oracle, 全局均值, SVR）下的表现，以及深度学习模型（U-Net, FPN, Swin Transformer）在仅冠状动脉标签和冠状动脉+导管合并标签下的训练效果。 3. 血管类型标记：对分割出的血管进行 LAD、LCX、RCA 的类型分配。 4. 外部评估：使用公开的 DCA1 数据集进行严格外部测试，并对模型进行领域内微调。

Result: 1. SVR 调优显著提升了经典血管滤波器的 Dice 系数（例如，Frangi 从 0.741 提升到 0.759）。 2. FPN 模型在仅冠状动脉标签下达到 0.914 Dice，合并冠状动脉+导管标签后提升至 0.931。 3. 在 DCA1 外部测试集上，Dice 有所下降（0.798 和 0.814），但经过领域内微调后，Dice 分别恢复到 0.881 和 0.882。 4. 血管类型标记准确率很高，RCA 为 98.5%，LAD 为 95.4%，LCX 为 96.2%。

Conclusion: 通过学习的逐图像调优增强了经典分割流程；高分辨率 FPN 模型和合并标签的监督提高了模型的稳定性和外部迁移能力，只需少量微调即可获得优异性能。所提出的方法能够实现鲁棒的 XCA 血管分割和准确的血管类型标记，为冠状动脉疾病的定量分析提供了有力支持。

Abstract: X-ray coronary angiography (XCA) is the clinical reference standard for assessing coronary artery disease, yet quantitative analysis is limited by the difficulty of robust vessel segmentation in routine data. Low contrast, motion, foreshortening, overlap, and catheter confounding degrade segmentation and contribute to domain shift across centers. Reliable segmentation, together with vessel-type labeling, enables vessel-specific coronary analytics and downstream measurements that depend on anatomical localization. From 670 cine sequences (407 subjects), we select a best frame near peak opacification using a low-intensity histogram criterion and apply joint super-resolution and enhancement. We benchmark classical Meijering, Frangi, and Sato vesselness filters under per-image oracle tuning, a single global mean setting, and per-image parameter prediction via Support Vector Regression (SVR). Neural baselines include U-Net, FPN, and a Swin Transformer, trained with coronary-only and merged coronary+catheter supervision. A second stage assigns vessel identity (LAD, LCX, RCA). External evaluation uses the public DCA1 cohort. SVR per-image tuning improves Dice over global means for all classical filters (e.g., Frangi: 0.759 vs. 0.741). Among deep models, FPN attains 0.914+/-0.007 Dice (coronary-only), and merged coronary+catheter labels further improve to 0.931+/-0.006. On DCA1 as a strict external test, Dice drops to 0.798 (coronary-only) and 0.814 (merged), while light in-domain fine-tuning recovers to 0.881+/-0.014 and 0.882+/-0.015. Vessel-type labeling achieves 98.5% accuracy (Dice 0.844) for RCA, 95.4% (0.786) for LAD, and 96.2% (0.794) for LCX. Learned per-image tuning strengthens classical pipelines, while high-resolution FPN models and merged-label supervision improve stability and external transfer with modest adaptation.

</details>


### [134] [PhaSR: Generalized Image Shadow Removal with Physically Aligned Priors](https://arxiv.org/abs/2601.17470)
*Chia-Ming Lee,Yu-Fan Lin,Yu-Jou Hsiao,Jing-Hui Jung,Yu-Lun Liu,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: 本文提出了一种名为PhaSR的物理对齐阴影去除方法，通过双重先验对齐来处理不同光照条件下的阴影去除问题，并在实验中取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 在各种光照条件下进行阴影去除，需要分离光照和反射率，当物理先验未正确对齐时，这会变得更具挑战性。现有方法在多源环境光照下表现不佳。

Method: PhaSR方法包含两个主要部分：1. 物理对齐归一化（PAN），通过灰度世界归一化、对数域Retinex分解和动态范围重组来实现封闭式光照校正，抑制色偏。2. 几何-语义校正注意力（GSRA），将差分注意力扩展到跨模态对齐，协调深度导出的几何信息和DINO-v2语义嵌入，以解决不同光照下的模态冲突。

Result: 在阴影去除任务上，PhaSR表现出与现有方法具有竞争力的性能，同时具有更低的计算复杂度。它还能够泛化到传统方法在多源光照下会失败的环境光照条件。

Conclusion: PhaSR通过物理对齐的归一化和几何-语义校正注意力，能够有效地处理不同光照条件下的阴影去除问题，并展现出良好的泛化能力。

Abstract: Shadow removal under diverse lighting conditions requires disentangling illumination from intrinsic reflectance, a challenge compounded when physical priors are not properly aligned. We propose PhaSR (Physically Aligned Shadow Removal), addressing this through dual-level prior alignment to enable robust performance from single-light shadows to multi-source ambient lighting. First, Physically Aligned Normalization (PAN) performs closed-form illumination correction via Gray-world normalization, log-domain Retinex decomposition, and dynamic range recombination, suppressing chromatic bias. Second, Geometric-Semantic Rectification Attention (GSRA) extends differential attention to cross-modal alignment, harmonizing depth-derived geometry with DINO-v2 semantic embeddings to resolve modal conflicts under varying illumination. Experiments show competitive performance in shadow removal with lower complexity and generalization to ambient lighting where traditional methods fail under multi-source illumination. Our source code is available at https://github.com/ming053l/PhaSR.

</details>


### [135] [BMDS-Net: A Bayesian Multi-Modal Deep Supervision Network for Robust Brain Tumor Segmentation](https://arxiv.org/abs/2601.17504)
*Yan Zhou,Zhen Huang,Yingqiu Li,Yue Ouyang,Suncheng Xiang,Zehua Wang*

Main category: cs.CV

TL;DR: 提出了一种名为BMDS-Net的框架，用于提高多模态MRI脑肿瘤分割的临床鲁棒性和可信度，解决了模态缺失和置信度校准问题，并通过内存高效的贝叶斯微调提供不确定性图。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的脑肿瘤分割模型（如Swin UNETR）在实际临床应用中存在两个关键问题：对模态缺失敏感（临床常见）以及缺乏置信度校准，这阻碍了其在真实世界医疗部署中的安全性。研究旨在超越简单指标最大化，提升临床鲁棒性和可信度。

Method: BMDS-Net框架包含三个主要贡献：1. 构建了一个鲁棒的确定性主干，集成了零初始化多模态上下文融合（MMCF）模块和残差门控深度解码器监督（DDS）机制，以实现稳定的特征学习和精确的边界分割，即使在模态损坏的情况下也能显著降低Hausdorff距离。2. 引入了一种内存高效的贝叶斯微调策略，将网络转化为概率预测器，提供体素级不确定性图。3. 在BraTS 2021数据集上进行了广泛的实验验证。

Result: 在BraTS 2021数据集上的实验表明，BMDS-Net在保持竞争性精度的同时，在基线模型失败的模态缺失场景下表现出优越的稳定性。所提出的MMCF和DDS机制提高了边界分割的精确度，而贝叶斯微调提供了有用的不确定性信息。

Conclusion: BMDS-Net是一个统一的框架，通过整合MMCF和DDS模块以及贝叶斯微调策略，显著提高了脑肿瘤分割的临床鲁棒性和可信度，尤其在模态缺失的情况下表现出色，并且能够提供不确定性图以辅助临床医生决策。

Abstract: Accurate brain tumor segmentation from multi-modal magnetic resonance imaging (MRI) is a prerequisite for precise radiotherapy planning and surgical navigation. While recent Transformer-based models such as Swin UNETR have achieved impressive benchmark performance, their clinical utility is often compromised by two critical issues: sensitivity to missing modalities (common in clinical practice) and a lack of confidence calibration. Merely chasing higher Dice scores on idealized data fails to meet the safety requirements of real-world medical deployment. In this work, we propose BMDS-Net, a unified framework that prioritizes clinical robustness and trustworthiness over simple metric maximization. Our contribution is three-fold. First, we construct a robust deterministic backbone by integrating a Zero-Init Multimodal Contextual Fusion (MMCF) module and a Residual-Gated Deep Decoder Supervision (DDS) mechanism, enabling stable feature learning and precise boundary delineation with significantly reduced Hausdorff Distance, even under modality corruption. Second, and most importantly, we introduce a memory-efficient Bayesian fine-tuning strategy that transforms the network into a probabilistic predictor, providing voxel-wise uncertainty maps to highlight potential errors for clinicians. Third, comprehensive experiments on the BraTS 2021 dataset demonstrate that BMDS-Net not only maintains competitive accuracy but, more importantly, exhibits superior stability in missing-modality scenarios where baseline models fail. The source code is publicly available at https://github.com/RyanZhou168/BMDS-Net.

</details>


### [136] [FMIR, a foundation model-based Image Registration Framework for Robust Image Registration](https://arxiv.org/abs/2601.17529)
*Fengting Zhang,Yue He,Qinghao Liu,Yaonan Wang,Xiang Chen,Hang Zhang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为FMIR的基于基础模型的医学图像配准框架，旨在解决现有深度学习方法在泛化能力上的不足，并能在有限数据集下实现领域内外的优异配准效果。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在医学图像配准方面虽然速度快，但泛化能力有限，难以适应训练领域外的数据，这在医学数据集规模通常较小的背景下尤为突出。研究的动机是开发一种能够克服泛化性限制，并能在有限资源下构建可泛化医学影像基础模型的配准方法。

Method: FMIR框架结合了基于基础模型的特征编码器（用于提取解剖结构）和通用的配准头。该框架仅在一个数据集上使用通道正则化策略进行训练。该方法旨在通过这种组合和训练策略来提升泛化能力。

Result: FMIR在领域内（in-domain）达到了最先进（SOTA）的性能，并能在领域外（out-of-domain）的图像上保持鲁棒的配准效果。这意味着该模型不仅在与训练数据相似的数据上表现良好，还能有效处理数据分布有所差异的情况。

Conclusion: FMIR框架提供了一条在有限资源下构建可泛化医学影像基础模型的可行路径。通过结合基础模型和特定的训练策略，可以实现高性能且泛化能力强的医学图像配准。

Abstract: Deep learning has revolutionized medical image registration by achieving unprecedented speeds, yet its clinical application is hindered by a limited ability to generalize beyond the training domain, a critical weakness given the typically small scale of medical datasets. In this paper, we introduce FMIR, a foundation model-based registration framework that overcomes this limitation.Combining a foundation model-based feature encoder for extracting anatomical structures with a general registration head, and trained with a channel regularization strategy on just a single dataset, FMIR achieves state-of-the-art(SOTA) in-domain performance while maintaining robust registration on out-of-domain images.Our approach demonstrates a viable path toward building generalizable medical imaging foundation models with limited resources. The code is available at https://github.com/Monday0328/FMIR.git.

</details>


### [137] [Will It Zero-Shot?: Will It Zero-Shot?: Predicting Zero-Shot Classification Performance For Arbitrary Queries](https://arxiv.org/abs/2601.17535)
*Kevin Robbins,Xiaotong Liu,Yu Wu,Le Sun,Grady McPeak,Abby Stylianou,Robert Pless*

Main category: cs.CV

TL;DR: 本研究提出了一种利用合成图像来评估和改进CLIP等视觉语言模型（VLM）零样本分类准确性的方法，相比仅使用文本提示，该方法能显著提升预测质量，并为用户提供评估所用图像的反馈。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在不同领域表现不稳定，非专业用户难以评估模型在特定任务上的适用性。本研究旨在为用户提供一种直观有效的方法来评估VLM的零样本分类能力。

Method: 研究建立在仅使用文本提示进行评估的基础上，并引入了生成与任务相关的合成图像的方法。通过比较仅文本提示的评分和结合合成图像的评估结果，来预测和改进零样本准确性。

Result: 实验表明，将合成图像纳入评估体系能显著提高对零样本准确性的预测质量。此外，这种方法还能向用户展示用于评估的图像类型，提供更直观的反馈。

Conclusion: 结合合成图像进行评估是一种比纯文本提示更优越的方法，能够帮助用户在没有标注数据的情况下，预测VLM在特定应用中的有效性。

Abstract: Vision-Language Models like CLIP create aligned embedding spaces for text and images, making it possible for anyone to build a visual classifier by simply naming the classes they want to distinguish. However, a model that works well in one domain may fail in another, and non-expert users have no straightforward way to assess whether their chosen VLM will work on their problem. We build on prior work using text-only comparisons to evaluate how well a model works for a given natural language task, and explore approaches that also generate synthetic images relevant to that task to evaluate and refine the prediction of zero-shot accuracy. We show that generated imagery to the baseline text-only scores substantially improves the quality of these predictions. Additionally, it gives a user feedback on the kinds of images that were used to make the assessment. Experiments on standard CLIP benchmark datasets demonstrate that the image-based approach helps users predict, without any labeled examples, whether a VLM will be effective for their application.

</details>


### [138] [Saliency Driven Imagery Preprocessing for Efficient Compression -- Industrial Paper](https://arxiv.org/abs/2601.17555)
*Justin Downes,Sam Saltwick,Anthony Chen*

Main category: cs.CV

TL;DR: 提出一种基于显著性图的卫星图像预处理技术，结合传统有损压缩标准，实现单张大卫星图像内的变比特率压缩。


<details>
  <summary>Details</summary>
Motivation: 卫星图像数据量庞大，存储和带宽成本高昂；许多下游任务仅关注图像中的小区域，现有标准对整张图像同等处理，效率低下。

Method: 使用可变大小的平滑核，根据量化的显著性水平处理图像像素，以优化下游压缩和编码方案。

Result: 通过基于显著性图的预处理，可以实现传统有损压缩标准下的变比特率图像压缩，针对图像中的重要区域进行优化。

Conclusion: 基于显著性图的图像预处理技术能够与传统有损压缩编码标准结合，有效地实现单张大型卫星图像内的变比特率压缩，从而优化存储和带宽的使用。

Abstract: The compression of satellite imagery remains an important research area as hundreds of terabytes of images are collected every day, which drives up storage and bandwidth costs. Although progress has been made in increasing the resolution of these satellite images, many downstream tasks are only interested in small regions of any given image. These areas of interest vary by task but, once known, can be used to optimize how information within the image is encoded. Whereas standard image encoding methods, even those optimized for remote sensing, work on the whole image equally, there are emerging methods that can be guided by saliency maps to focus on important areas. In this work we show how imagery preprocessing techniques driven by saliency maps can be used with traditional lossy compression coding standards to create variable rate image compression within a single large satellite image. Specifically, we use variable sized smoothing kernels that map to different quantized saliency levels to process imagery pixels in order to optimize downstream compression and encoding schemes.

</details>


### [139] [OTI: A Model-free and Visually Interpretable Measure of Image Attackability](https://arxiv.org/abs/2601.17536)
*Jiaming Liang,Haowei Liu,Chi-Man Pun*

Main category: cs.CV

TL;DR: 本文提出了一种名为对象纹理强度（OTI）的新型模型无关且视觉可解释的图像可攻击性度量方法，通过衡量图像语义对象的纹理强度来评估图像的可攻击性。


<details>
  <summary>Details</summary>
Motivation: 现有评估图像可攻击性的方法存在两大局限性：1) 依赖于模型代理提供先验知识（如梯度），而实际中许多特定任务的模型不易获得；2) 提取的特征缺乏视觉可解释性。因此，需要一种模型无关且视觉可解释的度量方法。

Method: 提出对象纹理强度（OTI）度量方法，其核心思想是将图像的可攻击性定义为其语义对象的纹理强度。该方法在理论上从决策边界以及对抗扰动的中高频特征角度进行了阐述。

Result: 实验证明OTI是一种有效且计算效率高的方法。此外，OTI能够为对抗机器学习社区提供对图像可攻击性的直观理解。

Conclusion: OTI是一种新颖的、模型无关的、视觉可解释的图像可攻击性度量方法，在实践中表现出有效性和效率，并为理解图像可攻击性提供了新的视角。

Abstract: Despite the tremendous success of neural networks, benign images can be corrupted by adversarial perturbations to deceive these models. Intriguingly, images differ in their attackability. Specifically, given an attack configuration, some images are easily corrupted, whereas others are more resistant. Evaluating image attackability has important applications in active learning, adversarial training, and attack enhancement. This prompts a growing interest in developing attackability measures. However, existing methods are scarce and suffer from two major limitations: (1) They rely on a model proxy to provide prior knowledge (e.g., gradients or minimal perturbation) to extract model-dependent image features. Unfortunately, in practice, many task-specific models are not readily accessible. (2) Extracted features characterizing image attackability lack visual interpretability, obscuring their direct relationship with the images. To address these, we propose a novel Object Texture Intensity (OTI), a model-free and visually interpretable measure of image attackability, which measures image attackability as the texture intensity of the image's semantic object. Theoretically, we describe the principles of OTI from the perspectives of decision boundaries as well as the mid- and high-frequency characteristics of adversarial perturbations. Comprehensive experiments demonstrate that OTI is effective and computationally efficient. In addition, our OTI provides the adversarial machine learning community with a visual understanding of attackability.

</details>


### [140] [Sponge Tool Attack: Stealthy Denial-of-Efficiency against Tool-Augmented Agentic Reasoning](https://arxiv.org/abs/2601.17566)
*Qi Li,Xinchao Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为Sponge Tool Attack (STA)的新型攻击方法，通过操纵LLM的工具调用过程，使其推理过程变得冗长低效，而原始任务语义和用户意图得以保留。该攻击无需修改模型或工具，仅通过重写输入提示即可实现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM通过外部工具增强的推理能力在实现通用人工智能方面发挥着重要作用，但这些方法在工具调用过程中存在的安全漏洞尚未得到充分研究。本研究旨在探索并揭示这种潜在的攻击面。

Method: STA利用一种迭代的多智能体协作框架，通过显式重写策略控制，将原始提示重写成语义高度保真但更加冗长和复杂的版本。这种重写仅限于输入提示，不涉及对底层模型或外部工具的任何修改。

Result: 在6个模型、12个工具、4个框架和13个数据集上的广泛实验证明，STA能够有效地将原本简洁高效的推理过程转化为计算开销巨大的复杂过程，同时保持其隐蔽性，因为原始任务语义和用户意图并未改变。

Conclusion: STA是一种针对LLM工具调用机制的新型、隐蔽且有效的攻击方法，它表明即使在严格的查询访问限制下，LLM的推理能力也可能受到恶意操纵，从而导致显著的计算资源浪费。

Abstract: Enabling large language models (LLMs) to solve complex reasoning tasks is a key step toward artificial general intelligence. Recent work augments LLMs with external tools to enable agentic reasoning, achieving high utility and efficiency in a plug-and-play manner. However, the inherent vulnerabilities of such methods to malicious manipulation of the tool-calling process remain largely unexplored. In this work, we identify a tool-specific attack surface and propose Sponge Tool Attack (STA), which disrupts agentic reasoning solely by rewriting the input prompt under a strict query-only access assumption. Without any modification on the underlying model or the external tools, STA converts originally concise and efficient reasoning trajectories into unnecessarily verbose and convoluted ones before arriving at the final answer. This results in substantial computational overhead while remaining stealthy by preserving the original task semantics and user intent. To achieve this, we design STA as an iterative, multi-agent collaborative framework with explicit rewritten policy control, and generates benign-looking prompt rewrites from the original one with high semantic fidelity. Extensive experiments across 6 models (including both open-source models and closed-source APIs), 12 tools, 4 agentic frameworks, and 13 datasets spanning 5 domains validate the effectiveness of STA.

</details>


### [141] [SPACE-CLIP: Spatial Perception via Adaptive CLIP Embeddings for Monocular Depth Estimation](https://arxiv.org/abs/2601.17657)
*Taewan Cho,Taeryang Kim,Andrew Jaeyong Choi*

Main category: cs.CV

TL;DR: 提出了一种名为SPACE-CLIP的新型双路径解码器架构，它直接从冻结的CLIP视觉编码器中提取几何信息，无需文本编码器，并在KITTI数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的CLIP方法在处理几何结构方面存在困难，并且依赖于间接低效的文本提示。作者希望直接从CLIP的视觉编码器中解锁和解释潜在的几何知识。

Method: 设计了一个双路径解码器，包括一个语义路径（利用FiLM动态调整全局上下文）和一个结构路径（从早期层提取精细空间细节）。两条路径的特征被分层融合，以结合语义和几何信息。

Result: 在KITTI数据集上，SPACE-CLIP显著优于以前的CLIP基方法。消融研究表明，双路径的协同融合对于性能至关重要。

Conclusion: SPACE-CLIP提供了一种新的、高效的、结构优雅的方法来重新利用大型视觉模型，能够直接感知空间信息，并且可以集成到VLA等未来AI系统中。

Abstract: Contrastive Language-Image Pre-training (CLIP) has accomplished extraordinary success for semantic understanding but inherently struggles to perceive geometric structure. Existing methods attempt to bridge this gap by querying CLIP with textual prompts, a process that is often indirect and inefficient. This paper introduces a fundamentally different approach using a dual-pathway decoder. We present SPACE-CLIP, an architecture that unlocks and interprets latent geometric knowledge directly from a frozen CLIP vision encoder, completely bypassing the text encoder and its associated textual prompts. A semantic pathway interprets high-level features, dynamically conditioned on global context using feature-wise linear modulation (FiLM). In addition, a structural pathway extracts fine-grained spatial details from early layers. These complementary streams are hierarchically fused, enabling a robust synthesis of semantic context and precise geometry. Extensive experiments on the KITTI benchmark show that SPACE-CLIP dramatically outperforms previous CLIP-based methods. Our ablation studies validate that the synergistic fusion of our dual pathways is critical to this success. SPACE-CLIP offers a new, efficient, and architecturally elegant blueprint for repurposing large-scale vision models. The proposed method is not just a standalone depth estimator, but a readily integrable spatial perception module for the next generation of embodied AI systems, such as vision-language-action (VLA) models. Our model is available at https://github.com/taewan2002/space-clip

</details>


### [142] [Training-Free Text-to-Image Compositional Food Generation via Prompt Grafting](https://arxiv.org/abs/2601.17666)
*Xinyue Pan,Yuhao Chen,Fengqing Zhu*

Main category: cs.CV

TL;DR: 提出了一种名为Prompt Grafting (PG) 的训练免费框架，用于生成包含多个食物的图像，解决了现有模型中食物缠绕的问题，并允许用户控制食物的分离或混合。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在生成多食物图像时存在“食物缠绕”问题，即相邻食物融合不清，这阻碍了图像为基础的饮食评估和菜谱可视化等应用。因此，需要一种能够准确生成多食物图像的方法。

Method: Prompt Grafting (PG) 框架采用两阶段过程：首先，使用布局提示（layout prompt）建立清晰的食物区域；然后，在布局形成稳定后，将目标提示（target prompt）“嫁接”（grafted）进来。该框架结合了文本中的显式空间线索和采样过程中的隐式布局指导，实现了对食物缠绕的可控性。

Result: 在两个食物数据集上，PG框架显著提高了目标食物的出现率，并提供了可控分离的定性证据。用户可以通过编辑布局安排来指定食物是否应该分离或混合。

Conclusion: PG框架是一种有效的、无需训练的解决方案，可以解决多食物图像生成中的食物缠绕问题，并提供了对食物布局的精细控制能力，适用于图像为基础的饮食评估和菜谱可视化等场景。

Abstract: Real-world meal images often contain multiple food items, making reliable compositional food image generation important for applications such as image-based dietary assessment, where multi-food data augmentation is needed, and recipe visualization. However, modern text-to-image diffusion models struggle to generate accurate multi-food images due to object entanglement, where adjacent foods (e.g., rice and soup) fuse together because many foods do not have clear boundaries. To address this challenge, we introduce Prompt Grafting (PG), a training-free framework that combines explicit spatial cues in text with implicit layout guidance during sampling. PG runs a two-stage process where a layout prompt first establishes distinct regions and the target prompt is grafted once layout formation stabilizes. The framework enables food entanglement control: users can specify which food items should remain separated or be intentionally mixed by editing the arrangement of layouts. Across two food datasets, our method significantly improves the presence of target objects and provides qualitative evidence of controllable separation.

</details>


### [143] [Uni-RS: A Spatially Faithful Unified Understanding and Generation Model for Remote Sensing](https://arxiv.org/abs/2601.17673)
*Weiyu Zhang,Yuan Hu,Yong Li,Yu Liu*

Main category: cs.CV

TL;DR: 提出了一种名为Uni-RS的统一遥感多模态模型，通过空间布局规划、空间感知查询监督和图像-字幕空间布局变异等方法，解决了遥感领域中现有模型在文本到图像生成时空间关系不准确的问题，同时保持了在图像字幕、视觉问答等理解任务上的良好性能。


<details>
  <summary>Details</summary>
Motivation: 现有的统一遥感多模态模型在空间反转问题上存在显著缺陷：它们能够准确识别图像中的物体位置，但在文本到图像生成时，却难以忠实地执行相同的空间关系，而这些关系是遥感图像中的核心语义信息。

Method: 1. 提出显式空间布局规划（Spatial-Layout Planning），将文本指令转化为空间布局计划，实现几何规划与视觉合成的分离。 2. 引入空间感知查询监督（Spatial-Aware Query Supervision），使可学习的查询能够偏向指令中明确规定的空间关系。 3. 开发图像-字幕空间布局变异（Image-Caption Spatial Layout Variation），使模型接触到系统性的几何一致空间变换。

Result: 在多个基准数据集上的大量实验表明，Uni-RS显著提高了文本到图像生成在空间方面的准确性，同时在图像字幕、视觉接地和视觉问答等模态理解任务上保持了强大的性能。

Conclusion: Uni-RS是首个专为遥感领域设计的统一多模态模型，成功解决了文本到图像生成中的空间不对称问题，提升了空间保真度，并且在多模态理解任务上表现出色。

Abstract: Unified remote sensing multimodal models exhibit a pronounced spatial reversal curse: Although they can accurately recognize and describe object locations in images, they often fail to faithfully execute the same spatial relations during text-to-image generation, where such relations constitute core semantic information in remote sensing. Motivated by this observation, we propose Uni-RS, the first unified multimodal model tailored for remote sensing, to explicitly address the spatial asymmetry between understanding and generation. Specifically, we first introduce explicit Spatial-Layout Planning to transform textual instructions into spatial layout plans, decoupling geometric planning from visual synthesis. We then impose Spatial-Aware Query Supervision to bias learnable queries toward spatial relations explicitly specified in the instruction. Finally, we develop Image-Caption Spatial Layout Variation to expose the model to systematic geometry-consistent spatial transformations. Extensive experiments across multiple benchmarks show that our approach substantially improves spatial faithfulness in text-to-image generation, while maintaining strong performance on multimodal understanding tasks like image captioning, visual grounding, and VQA tasks.

</details>


### [144] [StyleDecoupler: Generalizable Artistic Style Disentanglement](https://arxiv.org/abs/2601.17697)
*Zexi Jia,Jinchao Zhang,Jie Zhou*

Main category: cs.CV

TL;DR: StyleDecoupler 是一种信息论框架，通过利用多模态和单模态视觉模型在风格和内容编码上的差异，能够从冻结的视觉语言模型中解耦出纯粹的风格特征，无需微调。同时引入了 WeART 数据集，并在风格检索等任务上取得了 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 艺术风格的表示因其与语义内容的深度耦合而充满挑战。研究旨在找到一种有效的方法来分离和表示艺术风格。

Method: 提出 StyleDecoupler 框架，利用多模态模型编码内容和风格，而单模态模型则专注于内容不变的特征。通过将单模态表示作为纯内容参考，利用互信息最小化来从多模态嵌入中分离出纯粹的风格特征。StyleDecoupler 可作为即插即用模块应用于冻结的视觉语言模型，无需微调。

Result: 在 WeART 和 WikiART 数据集上的风格检索任务中取得了最先进 (SOTA) 的性能。此外，该方法还能支持风格关系映射和生成模型评估等应用。

Conclusion: StyleDecoupler 成功实现了艺术风格的解耦，为风格表示和相关应用提供了新的解决方案，并引入了一个大规模的艺术品数据集 WeART。

Abstract: Representing artistic style is challenging due to its deep entanglement with semantic content. We propose StyleDecoupler, an information-theoretic framework that leverages a key insight: multi-modal vision models encode both style and content, while uni-modal models suppress style to focus on content-invariant features. By using uni-modal representations as content-only references, we isolate pure style features from multi-modal embeddings through mutual information minimization. StyleDecoupler operates as a plug-and-play module on frozen Vision-Language Models without fine-tuning. We also introduce WeART, a large-scale benchmark of 280K artworks across 152 styles and 1,556 artists. Experiments show state-of-the-art performance on style retrieval across WeART and WikiART, while enabling applications like style relationship mapping and generative model evaluation. We release our method and dataset at this url.

</details>


### [145] [Advancing Structured Priors for Sparse-Voxel Surface Reconstruction](https://arxiv.org/abs/2601.17720)
*Ting-Hsun Chi,Chu-Rong Chen,Chi-Tun Hsu,Hsuan-Ting Lin,Sheng-Yu Huang,Cheng Sun,Yu-Chiang Frank Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种结合3D高斯泼溅和稀疏体素栅格化的新方法，通过改进的体素初始化和深度几何监督，提高了表面重建的精度和细节恢复能力，同时保持了快速收敛。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅方法在表面保真度上有所欠缺，而稀疏体素栅格化方法则收敛速度慢且未充分利用场景结构。本研究旨在结合两者的优点，克服各自的局限性。

Method: 提出了一种体素初始化方法，将体素放置在合理的位置并采用适当的细节级别，为每场景优化提供良好的起点。此外，还提出了精炼的深度几何监督，将多视图线索转化为每射线深度正则化，以提高深度一致性并避免边缘模糊。

Result: 在标准基准测试中，该方法在几何精度、细结构恢复和表面完整性方面均优于现有方法，同时保持了快速收敛。

Conclusion: 通过结合3D高斯泼溅和稀疏体素栅格化的优势，并引入创新的初始化和监督策略，本研究显著提升了表面重建的质量，尤其是在几何精度和细节恢复方面，证明了其有效性。

Abstract: Reconstructing accurate surfaces with radiance fields has progressed rapidly, yet two promising explicit representations, 3D Gaussian Splatting and sparse-voxel rasterization, exhibit complementary strengths and weaknesses. 3D Gaussian Splatting converges quickly and carries useful geometric priors, but surface fidelity is limited by its point-like parameterization. Sparse-voxel rasterization provides continuous opacity fields and crisp geometry, but its typical uniform dense-grid initialization slows convergence and underutilizes scene structure. We combine the advantages of both by introducing a voxel initialization method that places voxels at plausible locations and with appropriate levels of detail, yielding a strong starting point for per-scene optimization. To further enhance depth consistency without blurring edges, we propose refined depth geometry supervision that converts multi-view cues into direct per-ray depth regularization. Experiments on standard benchmarks demonstrate improvements over prior methods in geometric accuracy, better fine-structure recovery, and more complete surfaces, while maintaining fast convergence.

</details>


### [146] [An AI-enabled tool for quantifying overlapping red blood cell sickling dynamics in microfluidic assays](https://arxiv.org/abs/2601.17703)
*Nikhil Kadivar,Guansheng Li,Jianlu Zheng,John M. Higgins,Ming Dao,George Em Karniadakis,Mengjia Xu*

Main category: cs.CV

TL;DR: 研究提出了一种基于深度学习的自动化框架，用于分析显微镜下镰状细胞的形态变化，即使在细胞密集重叠的情况下也能实现高精度量化，从而提高实验效率并支持药物疗效评估。


<details>
  <summary>Details</summary>
Motivation: 理解镰状细胞病（SCD）的动力学需要精确识别细胞在不同生物物理条件下的形态转变，尤其是在细胞密集且重叠的人群中。现有的方法在处理这些挑战时存在局限性。

Method: 该研究集成了一种自动化的深度学习框架，包括AI辅助标注（使用Roboflow平台）、分割（使用nnU-Net模型）、分类和实例计数。采用分水岭算法处理重叠细胞，以提高量化精度。

Result: 该框架在仅需少量标注数据的情况下，实现了高分割性能，有效解决了手动标注稀缺和细胞重叠的问题。它能够预测镰状细胞比例的时间演变，并将实验通量提高一倍以上，还能捕捉药物依赖性的镰状化行为，并揭示细胞形态演变的独特的力学生物学特征。

Conclusion: 这个AI驱动的框架是一个可扩展且可重复的计算平台，可以用于研究细胞生物力学和评估微生理系统中的治疗效果，特别是针对镰状细胞动力学和形态变化的研究。

Abstract: Understanding sickle cell dynamics requires accurate identification of morphological transitions under diverse biophysical conditions, particularly in densely packed and overlapping cell populations. Here, we present an automated deep learning framework that integrates AI-assisted annotation, segmentation, classification, and instance counting to quantify red blood cell (RBC) populations across varying density regimes in time-lapse microscopy data. Experimental images were annotated using the Roboflow platform to generate labeled dataset for training an nnU-Net segmentation model. The trained network enables prediction of the temporal evolution of the sickle cell fraction, while a watershed algorithm resolves overlapping cells to enhance quantification accuracy. Despite requiring only a limited amount of labeled data for training, the framework achieves high segmentation performance, effectively addressing challenges associated with scarce manual annotations and cell overlap. By quantitatively tracking dynamic changes in RBC morphology, this approach can more than double the experimental throughput via densely packed cell suspensions, capture drug-dependent sickling behavior, and reveal distinct mechanobiological signatures of cellular morphological evolution. Overall, this AI-driven framework establishes a scalable and reproducible computational platform for investigating cellular biomechanics and assessing therapeutic efficacy in microphysiological systems.

</details>


### [147] [The Script is All You Need: An Agentic Framework for Long-Horizon Dialogue-to-Cinematic Video Generation](https://arxiv.org/abs/2601.17737)
*Chenyu Mu,Xin He,Qu Yang,Wanshun Chen,Jiadi Yao,Huang Liu,Zihao Yi,Bo Zhao,Xingyu Chen,Ruotian Ma,Fanghua Ye,Erkun Yang,Cheng Deng,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CV

TL;DR: 本文提出了一种端到端的代理框架，用于将对话转化为电影视频，弥合了从高层概念到电影制作的“语义鸿沟”。该框架包含一个ScripterAgent，用于将对话转化为详细的电影脚本，以及一个DirectorAgent，用于利用先进的视频模型生成连贯的长期视频。引入了ScriptBench基准和VSA度量来评估模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频生成模型在处理高层概念（如对话）和生成长篇、连贯叙事方面存在困难，存在“语义鸿沟”。

Method: 构建了一个端到端的代理框架，包括ScripterAgent（将对话转化为电影脚本）和DirectorAgent（指导视频模型进行跨场景连续生成）。使用新构建的ScriptBench基准进行训练和评估，并引入了CriticAgent和VSA度量来评估脚本忠实度和时间保真度。

Result: 该框架显著提高了脚本忠实度和时间保真度。分析发现，当前最先进的模型在视觉效果和严格的脚本遵循之间存在权衡。

Conclusion: 该代理框架能够有效地将对话转化为电影视频，弥合了语义鸿沟，并为自动化电影制作提供了新的见解，尤其是在理解模型在视觉效果和脚本遵循之间的权衡方面。

Abstract: Recent advances in video generation have produced models capable of synthesizing stunning visual content from simple text prompts. However, these models struggle to generate long-form, coherent narratives from high-level concepts like dialogue, revealing a ``semantic gap'' between a creative idea and its cinematic execution. To bridge this gap, we introduce a novel, end-to-end agentic framework for dialogue-to-cinematic-video generation. Central to our framework is ScripterAgent, a model trained to translate coarse dialogue into a fine-grained, executable cinematic script. To enable this, we construct ScriptBench, a new large-scale benchmark with rich multimodal context, annotated via an expert-guided pipeline. The generated script then guides DirectorAgent, which orchestrates state-of-the-art video models using a cross-scene continuous generation strategy to ensure long-horizon coherence. Our comprehensive evaluation, featuring an AI-powered CriticAgent and a new Visual-Script Alignment (VSA) metric, shows our framework significantly improves script faithfulness and temporal fidelity across all tested video models. Furthermore, our analysis uncovers a crucial trade-off in current SOTA models between visual spectacle and strict script adherence, providing valuable insights for the future of automated filmmaking.

</details>


### [148] [Implicit Neural Representation-Based Continuous Single Image Super Resolution: An Empirical Study](https://arxiv.org/abs/2601.17723)
*Tayyab Nasir,Daochang Liu,Ajmal Mian*

Main category: cs.CV

TL;DR: 本研究对现有基于隐式神经表示（INR）的任意尺度图像超分辨率（ASSR）方法进行了系统的实证分析，比较了不同的训练策略（如缩放定律、目标函数设计和优化策略），并提出了一种新的损失函数，以提升感知图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有关于INR在ASSR中的应用缺乏系统的实证研究，无法准确评估不同方法的有效性、训练策略的影响，也未能揭示ASSR的饱和极限和未来发展方向。

Method: 作者对现有ASSR方法进行了广泛的比较，评估了不同训练配置（包括缩放定律、目标函数和优化策略）的影响，并引入了一个新的损失函数，该函数在保持边缘和纹理的同时，惩罚强度变化。研究还提供了一个统一的框架和代码库以促进可复现的比较。

Result: 研究发现：1. 近期更复杂的INR方法相较于早期方法提升有限；2. 模型性能与训练配置密切相关，而这一点在先前的研究中被忽略；3. 新提出的损失函数能提升不同架构下的纹理保真度；4. 缩放定律适用于INR-based ASSR，模型复杂度和数据多样性增加可带来可预测的性能提升。

Conclusion: 本研究通过实证分析，揭示了训练配置对ASSR性能的重要性，并提出了一个有效的损失函数以改善感知质量。研究结果强调了在ASSR领域，训练策略和损失函数设计与模型架构同等重要，并为未来ASSR研究提供了新的视角和基准。

Abstract: Implicit neural representation (INR) has become the standard approach for arbitrary-scale image super-resolution (ASSR). To date, no empirical study has systematically examined the effectiveness of existing methods, nor investigated the effects of different training recipes, such as scaling laws, objective design, and optimization strategies. A rigorous empirical analysis is essential not only for benchmarking performance and revealing true gains but also for establishing the current state of ASSR, identifying saturation limits, and highlighting promising directions. We fill this gap by comparing existing techniques across diverse settings and presenting aggregated performance results on multiple image quality metrics. We contribute a unified framework and code repository to facilitate reproducible comparisons. Furthermore, we investigate the impact of carefully controlled training configurations on perceptual image quality and examine a new loss function that penalizes intensity variations while preserving edges, textures, and finer details during training. We conclude the following key insights that have been previously overlooked: (1) Recent, more complex INR methods provide only marginal improvements over earlier methods. (2) Model performance is strongly correlated to training configurations, a factor overlooked in prior works. (3) The proposed loss enhances texture fidelity across architectures, emphasizing the role of objective design for targeted perceptual gains. (4) Scaling laws apply to INR-based ASSR, confirming predictable gains with increased model complexity and data diversity.

</details>


### [149] [Flatten The Complex: Joint B-Rep Generation via Compositional $k$-Cell Particles](https://arxiv.org/abs/2601.17733)
*Junran Lu,Yuanqi Li,Hengji Li,Jie Guo,Yanwen Guo*

Main category: cs.CV

TL;DR: 本研究提出了一种将B-Rep模型表示为粒子集合的新方法，通过共享接口的粒子来实现拓扑和几何的联合生成，提高了模型的保真度、有效性和可编辑性。


<details>
  <summary>Details</summary>
Motivation: 现有处理B-Rep模型的方法在处理其异质性时依赖于级联序列，未能充分利用几何关系，限制了上下文感知和错误恢复能力。

Method: 将B-Rep模型重构为粒子集合，其中相邻单元共享相同的接口潜变量，以实现几何耦合。使用多模态流匹配框架进行无条件生成和条件生成（如3D重建）。

Result: 该方法能够生成高保真度的CAD模型，在有效性和可编辑性方面优于现有最先进的方法。该方法还可以用于局部修复和直接合成非流形结构。

Conclusion: 提出的粒子化表示方法成功地解耦了B-Rep的刚性层次结构，实现了拓扑和几何的联合生成，并为下游任务提供了更好的灵活性和性能。

Abstract: Boundary Representation (B-Rep) is the widely adopted standard
  in Computer-Aided Design (CAD) and manufacturing. However, generative modeling of B-Reps remains a formidable challenge due to their inherent heterogeneity as geometric cell complexes, which entangles topology with geometry across cells of varying orders (i.e., $k$-cells such as vertices, edges, faces). Previous methods typically rely on cascaded sequences to handle this hierarchy, which fails to fully exploit the geometric relationships between cells, such as adjacency and sharing, limiting context awareness and error recovery. To fill this gap, we introduce a novel paradigm that reformulates B-Reps into sets of compositional $k$-cell particles. Our approach encodes each topological entity as a composition of particles, where adjacent cells share identical latents at their interfaces, thereby promoting geometric coupling along shared boundaries. By decoupling the rigid hierarchy, our representation unifies vertices, edges, and faces, enabling the joint generation of topology and geometry with global context awareness.
  We synthesize these particle sets using a multi-modal flow matching framework to handle unconditional generation as well as precise conditional tasks, such as 3D reconstruction from single-view or point cloud. Furthermore, the explicit and localized nature of our representation naturally extends to downstream tasks like local in-painting and enables the direct synthesis of non-manifold structures (e.g., wireframes). Extensive experiments demonstrate that our method produces high-fidelity CAD models with superior validity and editability compared to state-of-the-art methods.

</details>


### [150] [MV-S2V: Multi-View Subject-Consistent Video Generation](https://arxiv.org/abs/2601.17756)
*Ziyang Song,Xinyu Gong,Bangya Liu,Zelin Zhao*

Main category: cs.CV

TL;DR: 提出了一种新的多视图主题到视频生成（MV-S2V）任务，旨在通过多视图参考图像实现3D级别的主题一致性视频合成。该方法通过合成数据增强和一种名为TS-RoPE的新型注意力机制来解决数据稀缺和视图区分问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅支持单视图主题参考，限制了视频主题控制的潜力。因此，研究者提出了多视图S2V（MV-S2V）任务，以实现更强大的3D级别主题一致性。

Method: 研究者开发了一个合成数据生成流程来扩充训练数据，并引入了Temporally Shifted RoPE (TS-RoPE) 来区分不同主体和同一主体的不同视图，以解决条件生成中的混淆问题。

Result: 提出的MV-S2V框架在多视图参考图像的3D主题一致性方面表现优越，并生成高质量的视觉输出。

Conclusion: 该工作成功提出了并解决了MV-S2V任务，通过数据合成和TS-RoPE技术，显著提升了多视图主题驱动视频生成的能力，为该领域开辟了新的研究方向。

Abstract: Existing Subject-to-Video Generation (S2V) methods have achieved high-fidelity and subject-consistent video generation, yet remain constrained to single-view subject references. This limitation renders the S2V task reducible to an S2I + I2V pipeline, failing to exploit the full potential of video subject control. In this work, we propose and address the challenging Multi-View S2V (MV-S2V) task, which synthesizes videos from multiple reference views to enforce 3D-level subject consistency. Regarding the scarcity of training data, we first develop a synthetic data curation pipeline to generate highly customized synthetic data, complemented by a small-scale real-world captured dataset to boost the training of MV-S2V. Another key issue lies in the potential confusion between cross-subject and cross-view references in conditional generation. To overcome this, we further introduce Temporally Shifted RoPE (TS-RoPE) to distinguish between different subjects and distinct views of the same subject in reference conditioning. Our framework achieves superior 3D subject consistency w.r.t. multi-view reference images and high-quality visual outputs, establishing a new meaningful direction for subject-driven video generation. Our project page is available at <a href="https://szy-young.github.io/mv-s2v">this URL</a>

</details>


### [151] [Learning Sewing Patterns via Latent Flow Matching of Implicit Fields](https://arxiv.org/abs/2601.17740)
*Cong Cao,Ren Li,Corentin Dumery,Hao Li*

Main category: cs.CV

TL;DR: 提出了一种基于隐式表示的缝纫图案建模方法，利用符号距离场和无符号距离场表示面板和接缝端点，并通过潜在空间和潜在流匹配模型实现可微分网格化，从而能够准确建模和生成复杂的缝纫图案，并能从图像中估计图案。


<details>
  <summary>Details</summary>
Motivation: 现有缝纫图案自动生成方法在处理面板几何形状和缝合排列的广泛变化时存在困难，准确建模缝纫图案仍然具有挑战性。

Method: 采用基于隐式表示的方法，用符号距离场表示面板边界，用无符号距离场表示接缝端点，并将这些场编码到连续的潜在空间中，实现可微分网格化。利用潜在流匹配模型学习面板组合的分布，并通过缝合预测模块恢复缝合关系。

Result: 该方法能够准确建模和生成具有复杂结构的缝纫图案。在从图像估计缝纫图案方面，相对于现有方法提高了准确性，并支持图案补全和重拟合等应用。

Conclusion: 所提出的基于隐式表示的缝纫图案建模方法能够准确处理复杂的缝纫图案，并能从图像中进行有效估计，为数字时尚设计提供了实用的工具。

Abstract: Sewing patterns define the structural foundation of garments and are essential for applications such as fashion design, fabrication, and physical simulation. Despite progress in automated pattern generation, accurately modeling sewing patterns remains difficult due to the broad variability in panel geometry and seam arrangements. In this work, we introduce a sewing pattern modeling method based on an implicit representation. We represent each panel using a signed distance field that defines its boundary and an unsigned distance field that identifies seam endpoints, and encode these fields into a continuous latent space that enables differentiable meshing. A latent flow matching model learns distributions over panel combinations in this representation, and a stitching prediction module recovers seam relations from extracted edge segments. This formulation allows accurate modeling and generation of sewing patterns with complex structures. We further show that it can be used to estimate sewing patterns from images with improved accuracy relative to existing approaches, and supports applications such as pattern completion and refitting, providing a practical tool for digital fashion design.

</details>


### [152] [VidLaDA: Bidirectional Diffusion Large Language Models for Efficient Video Understanding](https://arxiv.org/abs/2601.17868)
*Zhihao He,Tieyuan Chen,Kangyu Wang,Ziran Qin,Yang Shao,Chaofan Gan,Shijie Li,Zuxuan Wu,Weiyao Lin*

Main category: cs.CV

TL;DR: 提出了一种名为 VidLaDA 的视频语言模型，它基于扩散语言模型并利用双向注意力来解决标准自回归视频 LLM 的因果掩码偏差问题，同时引入 MARS-Cache 加速推理速度。


<details>
  <summary>Details</summary>
Motivation: 标准自回归视频 LLM 存在因果掩码偏差，阻碍了时空全局建模，降低了理解效率。同时，扩散模型在大量视频 token 上的解码存在推理瓶颈。

Method: VidLaDA 使用扩散语言模型，并引入双向注意力来捕捉时空依赖关系。为了加速推理，提出了 MARS-Cache 框架，结合异步视觉缓存刷新和帧级分块注意力，通过锚点 token 保持全局连通性并去除冗余。

Result: VidLaDA 在多个任务上优于扩散基线模型，并能与 Qwen2.5-VL 和 LLaVA-Video 等最先进的自回归模型相媲美。MARS-Cache 在不牺牲准确性的情况下实现了超过 12 倍的推理加速。

Conclusion: VidLaDA 是一种有效的视频语言模型，通过双向注意力和 MARS-Cache 框架克服了现有方法的局限性，实现了高性能和高效推理。

Abstract: Standard Autoregressive Video LLMs inevitably suffer from causal masking biases that hinder global spatiotemporal modeling, leading to suboptimal understanding efficiency. We propose VidLaDA, a Video LLM based on Diffusion Language Model utilizing bidirectional attention to capture bidirectional dependencies. To further tackle the inference bottleneck of diffusion decoding on massive video tokens, we introduce MARS-Cache. This framework accelerates inference by combining asynchronous visual cache refreshing with frame-wise chunk attention, effectively pruning redundancy while preserving global connectivity via anchor tokens. Extensive experiments show VidLaDA outperforms diffusion baselines and rivals state-of-the-art autoregressive models (e.g., Qwen2.5-VL and LLaVA-Video), with MARS-Cache delivering over 12x speedup without compromising reasoning accuracy. Code and checkpoints are open-sourced at https://github.com/ziHoHe/VidLaDA.

</details>


### [153] [Feature-Space Generative Models for One-Shot Class-Incremental Learning](https://arxiv.org/abs/2601.17905)
*Jack Foster,Kirill Paramonov,Mete Ozay,Umberto Michieli*

Main category: cs.CV

TL;DR: 提出了一种名为Gen1S的新方法，用于在只有少量新类别样本且不允许额外训练的情况下，提升模型在新类别上的识别能力。该方法通过学习基础类别残差嵌入的分布，为识别新类别提供结构性先验。


<details>
  <summary>Details</summary>
Motivation: 在few-shot class-incremental learning（FSCIL）场景下，模型需要仅凭少量（1个）新类别样本来识别新类别，且不允许在基础训练后进行模型修改，这使得新类别的泛化变得非常困难。

Method: 将原始嵌入空间映射到残差空间（通过减去类别原型），然后利用VAE或扩散模型学习基础类别残差的分布。将此分布作为结构性先验来帮助识别新类别。

Result: Gen1S在多个基准测试和骨干网络架构上，持续优于现有技术在识别新类别方面的性能。

Conclusion: 基础和新类别嵌入的结构相似性是关键。通过学习基础类别的残差嵌入分布，可以有效地提升模型在新类别上的识别能力，即使在只有单一样本且不允许额外训练的情况下。

Abstract: Few-shot class-incremental learning (FSCIL) is a paradigm where a model, initially trained on a dataset of base classes, must adapt to an expanding problem space by recognizing novel classes with limited data. We focus on the challenging FSCIL setup where a model receives only a single sample (1-shot) for each novel class and no further training or model alterations are allowed after the base training phase. This makes generalization to novel classes particularly difficult. We propose a novel approach predicated on the hypothesis that base and novel class embeddings have structural similarity. We map the original embedding space into a residual space by subtracting the class prototype (i.e., the average class embedding) of input samples. Then, we leverage generative modeling with VAE or diffusion models to learn the multi-modal distribution of residuals over the base classes, and we use this as a valuable structural prior to improve recognition of novel classes. Our approach, Gen1S, consistently improves novel class recognition over the state of the art across multiple benchmarks and backbone architectures.

</details>


### [154] [Frequency-aware Neural Representation for Videos](https://arxiv.org/abs/2601.17741)
*Jun Zhu,Xinfeng Zhang,Lv Tang,Junhao Jiang,Gai Zhang,Jia Wang*

Main category: cs.CV

TL;DR: 提出了一种名为FaNeRV的视频隐式神经表示方法，通过显式解耦低频和高频分量，并采用多分辨率监督和动态高频注入机制，解决了现有方法存在的频谱偏差问题，实现了更优的率失真性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于隐式神经表示（INR）的视频压缩框架存在频谱偏差问题，倾向于低频分量，导致重建过度平滑且率失真性能不佳。

Method: 提出FaNeRV（Frequency-aware Neural Representation for videos），采用多分辨率监督策略逐步引导网络捕获全局结构和精细纹理，并引入动态高频注入机制自适应地增强复杂区域，同时设计了频率分解网络模块来改进不同频带的特征建模。

Result: 在标准数据集上的大量实验表明，FaNeRV显著优于最先进的INR方法，并且在率失真性能方面与传统编解码器相当。

Conclusion: FaNeRV通过明确处理低频和高频分量，有效地解决了INR的频谱偏差问题，实现了高效、忠实的视频重建，并在率失真性能上取得了有竞争力的结果。

Abstract: Implicit Neural Representations (INRs) have emerged as a promising paradigm for video compression. However, existing INR-based frameworks typically suffer from inherent spectral bias, which favors low-frequency components and leads to over-smoothed reconstructions and suboptimal rate-distortion performance. In this paper, we propose FaNeRV, a Frequency-aware Neural Representation for videos, which explicitly decouples low- and high-frequency components to enable efficient and faithful video reconstruction. FaNeRV introduces a multi-resolution supervision strategy that guides the network to progressively capture global structures and fine-grained textures through staged supervision . To further enhance high-frequency reconstruction, we propose a dynamic high-frequency injection mechanism that adaptively emphasizes challenging regions. In addition, we design a frequency-decomposed network module to improve feature modeling across different spectral bands. Extensive experiments on standard benchmarks demonstrate that FaNeRV significantly outperforms state-of-the-art INR methods and achieves competitive rate-distortion performance against traditional codecs.

</details>


### [155] [From Specialist to Generalist: Unlocking SAM's Learning Potential on Unlabeled Medical Images](https://arxiv.org/abs/2601.17934)
*Vi Vu,Thanh-Huy Nguyen,Tien-Thinh Nguyen,Ba-Thinh Lam,Hoang-Thien Nguyen,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为 SC-SAM 的专家-通才框架，通过 U-Net 提供点提示和伪标签来指导 SAM 的适应，同时 SAM 作为通才监督器来规范 U-Net，形成双向协同训练，有效利用了未标记数据，并在前列腺 MRI 和息肉分割任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 由于领域偏移、标签稀缺以及参数高效微调 (PEFT) 无法利用未标记数据，将 SAM 等基础模型应用于医学图像的适应性仍具挑战性。尽管 U-Net 在半监督医学学习中表现出色，但其协助 PEFT SAM 的潜力被忽视。

Method: 提出 SC-SAM 框架，U-Net 生成点提示和伪标签引导 SAM，SAM 则作为通才监督器规范 U-Net，形成双向协同训练。

Result: 在泌尿道 MRI 和息肉分割基准上，SC-SAM 取得了最先进的性能，优于其他现有的半监督 SAM 变体，甚至优于 MedSAM。

Conclusion: 专家-通才的协同作用对于标签效率低的医学图像分割至关重要，SC-SAM 框架能够有效利用未标记数据，为医学图像分割提供了一种有效的半监督学习方法。

Abstract: Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM's adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.

</details>


### [156] [Video Compression with Hierarchical Temporal Neural Representation](https://arxiv.org/abs/2601.17743)
*Jun Zhu,Xinfeng Zhang,Lv Tang,Junhao Jiang,Gai Zhang,Jia Wang*

Main category: cs.CV

TL;DR: 提出了一种名为 TeNeRV 的分层时间神经表示方法，通过融合帧间特征和自适应调制机制，有效捕捉视频中的短期和长期时间依赖性，并在压缩性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于隐式神经表示（INR）的视频压缩方法在处理时间维度时存在局限性，难以捕捉复杂的时序依赖关系。研究旨在改进 INR 方法，以更有效地表示视频的时间信息。

Method: 提出 TeNeRV 方法，包含两个核心组件：1. 帧间特征融合（IFF）模块，用于聚合相邻帧特征，捕捉局部时间连贯性和精细运动；2. GoP 自适应调制（GAM）机制，将视频划分为图片组（GoP），学习组特异性先验并调制网络参数，实现跨 GoP 的自适应表示。

Result: TeNeRV 在率失真性能上持续优于现有的 INR 方法，证明了所提方法的有效性。

Conclusion: TeNeRV 通过整合短期和长期时间依赖性，能够更有效地表示视频，并在视频压缩任务中取得了显著的性能提升。

Abstract: Video compression has recently benefited from implicit neural representations (INRs), which model videos as continuous functions. INRs offer compact storage and flexible reconstruction, providing a promising alternative to traditional codecs. However, most existing INR-based methods treat the temporal dimension as an independent input, limiting their ability to capture complex temporal dependencies. To address this, we propose a Hierarchical Temporal Neural Representation for Videos, TeNeRV. TeNeRV integrates short- and long-term dependencies through two key components. First, an Inter-Frame Feature Fusion (IFF) module aggregates features from adjacent frames, enforcing local temporal coherence and capturing fine-grained motion. Second, a GoP-Adaptive Modulation (GAM) mechanism partitions videos into Groups-of-Pictures and learns group-specific priors. The mechanism modulates network parameters, enabling adaptive representations across different GoPs. Extensive experiments demonstrate that TeNeRV consistently outperforms existing INR-based methods in rate-distortion performance, validating the effectiveness of our proposed approach.

</details>


### [157] [Leveraging Persistence Image to Enhance Robustness and Performance in Curvilinear Structure Segmentation](https://arxiv.org/abs/2601.18045)
*Zhuangzhi Gao,Feixiang Zhou,He Zhao,Xiuju Chen,Xiaoxin Li,Qinkai Yu,Yitian Zhao,Alena Shantsila,Gregory Y. H. Lip,Eduard Shantsila,Yalin Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种名为PIs-Regressor的新模块，用于从数据中直接学习持久性图像（PI），并将拓扑特征集成到分割网络（Topology SegNet）的架构中，以提高医学图像中曲线结构的分割精度和鲁棒性，实验证明达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过手工设计的损失函数来整合拓扑属性，泛化能力差且计算成本高，难以处理医学图像中的噪声和模糊等挑战。作者希望直接将拓扑信息集成到网络结构中，以实现更鲁棒的分割。

Method: 提出PIs-Regressor模块，直接从数据中学习持久性图像（PI）的有限、可微分表示。将该模块与Topology SegNet相结合，在网络的下采样和上采样阶段融合拓扑特征。这种方法将拓扑信息集成到网络架构本身，而非辅助损失函数。

Result: 实验结果表明，该方法在三个曲线结构数据集上实现了最先进的像素级精度和拓扑保真度。集成的拓扑特征显著增强了模型的鲁棒性，有效解决了医学图像中的过曝光和模糊等问题。

Conclusion: 所提出的PIs-Regressor模块和Topology SegNet框架能够有效地将拓扑信息直接集成到网络架构中，无需依赖手工设计的损失函数，从而提高了医学图像中曲线结构分割的精度和鲁棒性，并达到了当前最佳的性能。

Abstract: Segmenting curvilinear structures in medical images is essential for analyzing morphological patterns in clinical applications. Integrating topological properties, such as connectivity, improves segmentation accuracy and consistency. However, extracting and embedding such properties - especially from Persistence Diagrams (PD) - is challenging due to their non-differentiability and computational cost. Existing approaches mostly encode topology through handcrafted loss functions, which generalize poorly across tasks. In this paper, we propose PIs-Regressor, a simple yet effective module that learns persistence image (PI) - finite, differentiable representations of topological features - directly from data. Together with Topology SegNet, which fuses these features in both downsampling and upsampling stages, our framework integrates topology into the network architecture itself rather than auxiliary losses. Unlike existing methods that depend heavily on handcrafted loss functions, our approach directly incorporates topological information into the network structure, leading to more robust segmentation. Our design is flexible and can be seamlessly combined with other topology-based methods to further enhance segmentation performance. Experimental results show that integrating topological features enhances model robustness, effectively handling challenges like overexposure and blurring in medical imaging. Our approach on three curvilinear benchmarks demonstrate state-of-the-art performance in both pixel-level accuracy and topological fidelity.

</details>


### [158] [Bridging Supervision Gaps: A Unified Framework for Remote Sensing Change Detection](https://arxiv.org/abs/2601.17747)
*Kaixuan Jiang,Chen Wu,Zhenghui Zhao,Chengxi Han*

Main category: cs.CV

TL;DR: 提出了一种名为UniCD的统一变化检测框架，能够联合处理监督、弱监督和无监督的变化检测任务，通过共享编码器和多分支协同学习机制，有效融合不同监督信号，并在多个数据集上取得了显著的性能提升，尤其在弱监督和无监督场景下表现突出。


<details>
  <summary>Details</summary>
Motivation: 像素级变化标签获取成本高昂，现有模型难以适应不同标注可用性场景。研究旨在解决这一挑战，提出一个能够统一处理不同监督级别变化检测的模型。

Method: 提出UniCD框架，采用共享编码器和多分支协同学习机制。具体包括：1. 监督分支：引入空间-时间感知模块（STAM）进行时序特征融合。2. 弱监督分支：提出变化表示正则化（CRR）引导模型收敛。3. 无监督分支：提出语义先验驱动变化推理（SPCI），将无监督任务转化为受控的弱监督路径优化。

Result: UniCD在主流数据集上实现了在三种任务上的最优性能。在LEVIR-CD数据集上，其在弱监督和无监督场景下的准确率分别比现有最先进方法提高了12.72%和12.37%。

Conclusion: UniCD是一个统一的变化检测框架，通过有效的架构设计和协同学习机制，能够充分利用不同级别的监督信息，显著提升了在弱监督和无监督变化检测任务上的性能，并展现了在处理不同标注可用性场景的潜力。

Abstract: Change detection (CD) aims to identify surface changes from multi-temporal remote sensing imagery. In real-world scenarios, Pixel-level change labels are expensive to acquire, and existing models struggle to adapt to scenarios with diverse annotation availability. To tackle this challenge, we propose a unified change detection framework (UniCD), which collaboratively handles supervised, weakly-supervised, and unsupervised tasks through a coupled architecture. UniCD eliminates architectural barriers through a shared encoder and multi-branch collaborative learning mechanism, achieving deep coupling of heterogeneous supervision signals. Specifically, UniCD consists of three supervision-specific branches. In the supervision branch, UniCD introduces the spatial-temporal awareness module (STAM), achieving efficient synergistic fusion of bi-temporal features. In the weakly-supervised branch, we construct change representation regularization (CRR), which steers model convergence from coarse-grained activations toward coherent and separable change modeling. In the unsupervised branch, we propose semantic prior-driven change inference (SPCI), which transforms unsupervised tasks into controlled weakly-supervised path optimization. Experiments on mainstream datasets demonstrate that UniCD achieves optimal performance across three tasks. It exhibits significant accuracy improvements in weakly and unsupervised scenarios, surpassing current state-of-the-art by 12.72% and 12.37% on LEVIR-CD, respectively.

</details>


### [159] [Agreement-Driven Multi-View 3D Reconstruction for Live Cattle Weight Estimation](https://arxiv.org/abs/2601.17791)
*Rabin Dulal,Wenfeng Jia,Lihong Zheng,Jane Quinn*

Main category: cs.CV

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Accurate cattle live weight estimation is vital for livestock management, welfare, and productivity. Traditional methods, such as manual weighing using a walk-over weighing system or proximate measurements using body condition scoring, involve manual handling of stock and can impact productivity from both a stock and economic perspective. To address these issues, this study investigated a cost-effective, non-contact method for live weight calculation in cattle using 3D reconstruction. The proposed pipeline utilized multi-view RGB images with SAM 3D-based agreement-guided fusion, followed by ensemble regression. Our approach generates a single 3D point cloud per animal and compares classical ensemble models with deep learning models under low-data conditions. Results show that SAM 3D with multi-view agreement fusion outperforms other 3D generation methods, while classical ensemble models provide the most consistent performance for practical farm scenarios (R$^2$ = 0.69 $\pm$ 0.10, MAPE = 2.22 $\pm$ 0.56 \%), making this practical for on-farm implementation. These findings demonstrate that improving reconstruction quality is more critical than increasing model complexity for scalable deployment on farms where producing a large volume of 3D data is challenging.

</details>


### [160] [LungCRCT: Causal Representation based Lung CT Processing for Lung Cancer Treatment](https://arxiv.org/abs/2601.18118)
*Daeyoung Kim*

Main category: cs.CV

TL;DR: 本研究提出了一个名为LungCRCT的框架，利用潜在因果表示学习来分析肺癌，能够进行因果干预分析，并在恶性肿瘤分类任务中取得了93.91%的AUC。它通过图自编码器和距离相关解耦来实现因果发现，并通过基于熵的图像重建进行优化。


<details>
  <summary>Details</summary>
Motivation: 早期肺癌症状不明显且易与其他呼吸道疾病混淆，导致发现和治疗延迟。低剂量CT（LDCT）和AI模型在检测和分类方面取得了进展，但现有深度学习模型在可解释性和因果推断方面存在局限，阻碍了其在治疗分析和模拟中的应用。

Method: 提出了LungCRCT框架，基于潜在因果表示学习，利用图自编码器结合距离相关解耦（Distance Correlation disentanglement）和基于熵的图像重建（entropy-based image reconstruction）来实现因果发现。该框架能够进行因果干预分析，并支持轻量级的下游恶性肿瘤分类任务。

Result: LungCRCT框架在恶性肿瘤分类任务中取得了93.91%的AUC分数。此外，该框架能够支持因果干预分析，并生成鲁棒且轻量级的模型。

Conclusion: LungCRCT框架通过引入潜在因果表示学习，克服了现有深度学习模型在可解释性和因果推断方面的限制，不仅能够进行肺癌治疗的因果干预分析，还能在肿瘤分类任务中实现高性能，为肺癌的早筛早治和个性化治疗提供了新的途径。

Abstract: Due to silence in early stages, lung cancer has been one of the most leading causes of mortality in cancer patients world-wide. Moreover, major symptoms of lung cancer are hard to differentiate with other respiratory disease symptoms such as COPD, further leading patients to overlook cancer progression in early stages. Thus, to enhance survival rates in lung cancer, early detection from consistent proactive respiratory system monitoring becomes crucial. One of the most prevalent and effective methods for lung cancer monitoring would be low-dose computed tomography(LDCT) chest scans, which led to remarkable enhancements in lung cancer detection or tumor classification tasks under rapid advancements and applications of computer vision based AI models such as EfficientNet or ResNet in image processing. However, though advanced CNN models under transfer learning or ViT based models led to high performing lung cancer detections, due to its intrinsic limitations in terms of correlation dependence and low interpretability due to complexity, expansions of deep learning models to lung cancer treatment analysis or causal intervention analysis simulations are still limited. Therefore, this research introduced LungCRCT: a latent causal representation learning based lung cancer analysis framework that retrieves causal representations of factors within the physical causal mechanism of lung cancer progression. With the use of advanced graph autoencoder based causal discovery algorithms with distance Correlation disentanglement and entropy-based image reconstruction refinement, LungCRCT not only enables causal intervention analysis for lung cancer treatments, but also leads to robust, yet extremely light downstream models in malignant tumor classification tasks with an AUC score of 93.91%.

</details>


### [161] [ViTCoP: Accelerating Large Vision-Language Models via Visual and Textual Semantic Collaborative Pruning](https://arxiv.org/abs/2601.17818)
*Wen Luo,Peng Chen,Xiaotao Huang,LiQun Huang*

Main category: cs.CV

TL;DR: 提出了一种名为 ViTCoP 的视觉和文本语义协同剪枝框架，通过结合视觉编码器的冗余过滤和 LLM 中基于分层特征的逐步联合剪枝，以高效保留关键和信息丰富的视觉标记，从而降低 LVLM 的计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）由于视觉标记的冗余而产生高昂的计算成本。现有方法要么过早丢失关键视觉信息，要么导致选定标记间的信息冗余。需要一种更有效的方法来解决这些挑战。

Method: 提出了一种名为 ViTCoP 的框架，它结合了视觉编码器的冗余过滤和 LLM 中基于其分层特征的逐步联合剪枝。引入了 K-向量的 L2 范数作为 LLM 中的标记显著性指标，以确保与 FlashAttention 等加速技术兼容。

Result: ViTCoP 在图像和视频理解任务上取得了最先进的性能，超越了现有方法。它显著降低了模型推理延迟和 GPU 内存消耗，并且在极端剪枝率下性能优势更加明显。

Conclusion: ViTCoP 是一种有效的视觉和文本语义协同剪枝框架，能够显著降低 LVLM 的计算成本，同时保持或提高其在各种视觉语言任务上的性能。

Abstract: Large Vision-Language Models (LVLMs) incur high computational costs due to significant redundancy in their visual tokens. To effectively reduce this cost, researchers have proposed various visual token pruning methods. However, existing methods are generally limited, either losing critical visual information prematurely due to pruning in the vision encoder, or leading to information redundancy among the selected tokens due to pruning in the Large Language Models (LLMs). To address these challenges, we propose a Visual and Textual Semantic Collaborative Pruning framework (ViTCoP) that combines redundancy filtering in the vision encoder with step-wise co-pruning within the LLM based on its hierarchical characteristics, to efficiently preserve critical and informationally diverse visual tokens. Meanwhile, to ensure compatibility with acceleration techniques like FlashAttention, we introduce the L2 norm of K-vectors as the token saliency metric in the LLM. Extensive experiments on various Large Vision-Language Models demonstrate that ViTCoP not only achieves state-of-the-art performance surpassing existing methods on both image and video understanding tasks, but also significantly reduces model inference latency and GPU memory consumption. Notably, its performance advantage over other methods becomes even more pronounced under extreme pruning rates.

</details>


### [162] [\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation](https://arxiv.org/abs/2601.18188)
*Weiye Zhu,Zekai Zhang,Xiangchen Wang,Hewei Pan,Teng Wang,Tiantian Geng,Rongtao Xu,Feng Zheng*

Main category: cs.CV

TL;DR: 提出了一种名为 NaVIDA 的视觉与语言导航新框架，通过学习动作与视觉变化之间的因果关系，以及采用分层概率动作分块和自适应执行策略，来解决现有方法在理解语言指令和稳定导航方面的不足，并在实验和真实机器人评估中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉与语言导航方法主要依赖于反应式的状态-动作映射，未能显式地模拟动作如何因果地改变后续的视觉观察。这种缺乏视觉-动作因果性的问题导致代理无法预测自身动作引起的视觉变化，从而引发行为不稳定、泛化能力弱和轨迹累积误差等问题。

Method: NaVIDA 框架通过以下几点解决上述问题：1. 动作地面视觉动力学和自适应执行：将策略学习与动作地面视觉动力学及自适应执行相结合。2. 分块式逆向动力学监督：在训练过程中引入分块式逆向动力学监督，以学习视觉变化与相应动作之间的因果关系。3. 分层概率动作分块（HPAC）：通过将轨迹划分为多步分块，并提供辨别性的、更长范围的视觉变化线索来组织监督，扩展有效的规划范围。4. 熵引导机制：在推理时通过自适应地设置动作分块的执行范围来进一步抑制误差累积并稳定行为。

Result: NaVIDA 在导航性能上显著优于现有最先进的方法，同时参数量更少（3B vs. 8B）。在真实机器人上的评估也进一步验证了该方法的实际可行性和有效性。

Conclusion: NaVIDA 通过引入动作-视觉因果建模、分层动作分块和自适应执行机制，成功解决了现有视觉与语言导航方法的局限性，实现了更稳定、更泛化且更高效的导航能力，并在模拟和真实世界环境中得到了验证。

Abstract: Vision-and-Language Navigation (VLN) requires agents to interpret natural language instructions and act coherently in visually rich environments. However, most existing methods rely on reactive state-action mappings without explicitly modeling how actions causally transform subsequent visual observations. Lacking such vision-action causality, agents cannot anticipate the visual changes induced by its own actions, leading to unstable behaviors, weak generalization, and cumulative error along trajectory. To address these issues, we introduce \textsc{NaVIDA} (\textbf{Nav}igation with \textbf{I}nverse \textbf{D}ynamics \textbf{A}ugmentation), a unified VLN framework that couples policy learning with action-grounded visual dynamics and adaptive execution. \textsc{NaVIDA} augments training with chunk-based inverse-dynamics supervision to learn causal relationship between visual changes and corresponding actions. To structure this supervision and extend the effective planning range, \textsc{NaVIDA} employs hierarchical probabilistic action chunking (HPAC), which organizes trajectories into multi-step chunks and provides discriminative, longer-range visual-change cues. To further curb error accumulation and stabilize behavior at inference, an entropy-guided mechanism adaptively sets the execution horizon of action chunks. Extensive experiments show that \textsc{NaVIDA} achieves superior navigation performance compared to state-of-the-art methods with fewer parameters (3B vs. 8B). Real-world robot evaluations further validate the practical feasibility and effectiveness of our approach. Code and data will be available upon acceptance.

</details>


### [163] [A multimodal vision foundation model for generalizable knee pathology](https://arxiv.org/abs/2601.18250)
*Kang Yu,Dingyu Wang,Zimu Yuan,Nan Zhou,Jiajun Liu,Jiaxin Liu,Shanggui Liu,Yaoyan Zheng,Huishu Yuan,Di Huang,Dong Jiang*

Main category: cs.CV

TL;DR: 本文提出了OrthoFoundation，一个多模态视觉基础模型，用于骨科影像分析。该模型使用120万张无标签的膝关节X光和MRI图像进行自监督预训练，并在14项下游任务中取得了最先进的性能，同时显著提高了标签效率和跨解剖结构的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前骨科AI方法依赖于碎片化、需要大量标注数据的监督学习，缺乏泛化能力。由于缺乏大规模、开放的骨科数据集，基础模型的发展受到限制。迫切需要精确解读医学影像来解决肌肉骨骼疾病导致的残疾问题。

Method: 构建了一个包含120万张无标签膝关节X光和MRI图像的多模态预训练数据集。使用Dinov3骨干网络，通过自监督对比学习进行训练，以捕捉强大的放射学表征。

Result: OrthoFoundation在14项下游任务中达到最先进性能，在X光骨关节炎诊断方面准确度优越，在MRI结构损伤检测方面排名第一。该模型在仅使用50%标注数据的情况下，就达到了监督基线的性能，显示出优异的标签效率。此外，即使仅在膝关节图像上预训练，模型也表现出对髋部、肩部和踝部等其他解剖结构的卓越泛化能力。

Conclusion: OrthoFoundation是骨科影像通用AI的重大进步。通过从大规模多模态数据中学习基础的、跨关节的放射学语义，它克服了传统模型的局限性，为减轻标注负担和提高临床诊断准确性提供了强大的框架。

Abstract: Musculoskeletal disorders represent a leading cause of global disability, creating an urgent demand for precise interpretation of medical imaging. Current artificial intelligence (AI) approaches in orthopedics predominantly rely on task-specific, supervised learning paradigms. These methods are inherently fragmented, require extensive annotated datasets, and often lack generalizability across different modalities and clinical scenarios. The development of foundation models in this field has been constrained by the scarcity of large-scale, curated, and open-source musculoskeletal datasets. To address these challenges, we introduce OrthoFoundation, a multimodal vision foundation model optimized for musculoskeletal pathology. We constructed a pre-training dataset of 1.2 million unlabeled knee X-ray and MRI images from internal and public databases. Utilizing a Dinov3 backbone, the model was trained via self-supervised contrastive learning to capture robust radiological representations. OrthoFoundation achieves state-of-the-art (SOTA) performance across 14 downstream tasks. It attained superior accuracy in X-ray osteoarthritis diagnosis and ranked first in MRI structural injury detection. The model demonstrated remarkable label efficiency, matching supervised baselines using only 50% of labeled data. Furthermore, despite being pre-trained on knee images, OrthoFoundation exhibited exceptional cross-anatomy generalization to the hip, shoulder, and ankle. OrthoFoundation represents a significant advancement toward general-purpose AI for musculoskeletal imaging. By learning fundamental, joint-agnostic radiological semantics from large-scale multimodal data, it overcomes the limitations of conventional models, which provides a robust framework for reducing annotation burdens and enhancing diagnostic accuracy in clinical practice.

</details>


### [164] [Co-PLNet: A Collaborative Point-Line Network for Prompt-Guided Wireframe Parsing](https://arxiv.org/abs/2601.18252)
*Chao Wang,Xuanying Li,Cheng Dai,Jinglei Feng,Yuxiang Luo,Yuqi Ouyang,Hao Qin*

Main category: cs.CV

TL;DR: 本文提出了一种名为Co-PLNet的线框解析新方法，通过点线协同框架，在点和线检测过程中共享空间信息，提高了线框解析的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有线框解析方法将线段和连接点分开预测，然后进行后期协调，这会导致预测不匹配且鲁棒性降低。

Method: 提出Co-PLNet框架，包含一个点线提示编码器（PLP-Encoder）将早期检测到的点和线转换为空间提示图，以及一个交叉引导线解码器（CGL-Decoder）利用这些提示图来细化线段预测，强制执行点线一致性。

Result: 在Wireframe和YorkUrban数据集上的实验表明，Co-PLNet在准确性和鲁棒性方面均有显著提升，并且效率更高。

Conclusion: Co-PLNet通过点线协同机制有效地提升了结构化几何感知的性能，实现了高精度、高鲁棒性和实时性。

Abstract: Wireframe parsing aims to recover line segments and their junctions to form a structured geometric representation useful for downstream tasks such as Simultaneous Localization and Mapping (SLAM). Existing methods predict lines and junctions separately and reconcile them post-hoc, causing mismatches and reduced robustness. We present Co-PLNet, a point-line collaborative framework that exchanges spatial cues between the two tasks, where early detections are converted into spatial prompts via a Point-Line Prompt Encoder (PLP-Encoder), which encodes geometric attributes into compact and spatially aligned maps. A Cross-Guidance Line Decoder (CGL-Decoder) then refines predictions with sparse attention conditioned on complementary prompts, enforcing point-line consistency and efficiency. Experiments on Wireframe and YorkUrban show consistent improvements in accuracy and robustness, together with favorable real-time efficiency, demonstrating our effectiveness for structured geometry perception.

</details>


### [165] [VAE-REPA: Variational Autoencoder Representation Alignment for Efficient Diffusion Training](https://arxiv.org/abs/2601.17830)
*Mengmeng Wang,Dengyang Jiang,Liuzhuozheng Li,Yucheng Lin,Guojiang Shen,Xiangjie Kong,Yong Liu,Guang Dai,Jingdong Wang*

Main category: cs.CV

TL;DR: 提出了一种名为
amex的轻量级内在引导框架，用于加速扩散模型的训练。该框架利用预训练的变分自编码器（VAE）的特征，通过轻量级投影层将其与扩散模型的中间潜在特征对齐，从而提高训练效率和生成质量，同时增加了计算开销极小。


<details>
  <summary>Details</summary>
Motivation: 现有的加速扩散模型训练的方法（如REPA和SRA）存在计算开销大的问题。需要一种更高效、轻量级的方法来解决扩散 transformer 模型训练收敛慢的问题。

Method: 利用现成的预训练 VAE 特征（包含纹理、结构和语义信息），通过一个轻量级投影层将这些 VAE 特征与扩散 transformer 的中间潜在特征对齐，并使用特征对齐损失进行监督。这种方法无需额外的编码器或双模型设置。

Result: 与 vanilla 扩散 transformer 相比，
amex 提高了生成质量和训练收敛速度。实验结果表明，
amex 在性能上能匹配或超越最先进的加速方法，并且仅增加了 4% 的 GFLOPs，无需额外的外部引导模型。

Conclusion: 
amex 是一种简单而有效的扩散模型训练加速框架，它利用 VAE 的内在特征，通过轻量级对齐机制显著提高了训练效率和生成质量，同时保持了计算上的轻量级。

Abstract: Denoising-based diffusion transformers, despite their strong generation performance, suffer from inefficient training convergence. Existing methods addressing this issue, such as REPA (relying on external representation encoders) or SRA (requiring dual-model setups), inevitably incur heavy computational overhead during training due to external dependencies. To tackle these challenges, this paper proposes \textbf{\namex}, a lightweight intrinsic guidance framework for efficient diffusion training. \name leverages off-the-shelf pre-trained Variational Autoencoder (VAE) features: their reconstruction property ensures inherent encoding of visual priors like rich texture details, structural patterns, and basic semantic information. Specifically, \name aligns the intermediate latent features of diffusion transformers with VAE features via a lightweight projection layer, supervised by a feature alignment loss. This design accelerates training without extra representation encoders or dual-model maintenance, resulting in a simple yet effective pipeline. Extensive experiments demonstrate that \name improves both generation quality and training convergence speed compared to vanilla diffusion transformers, matches or outperforms state-of-the-art acceleration methods, and incurs merely 4\% extra GFLOPs with zero additional cost for external guidance models.

</details>


### [166] [Geometry-Grounded Gaussian Splatting](https://arxiv.org/abs/2601.17835)
*Baowen Zhang,Chenxing Jiang,Heng Li,Shaojie Shen,Ping Tan*

Main category: cs.CV

TL;DR: 本文提出了一种基于高斯溅射（Gaussian Splatting）的新方法，将高斯图元视为随机固体，从而实现了高质量的几何形状重建，并在公开数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的从高斯图元中提取形状的方法存在多视图一致性差和对浮动体敏感的问题，这是由于不充分的几何参数化和近似造成的。作者希望开发一种更鲁棒、更精确的形状重建方法。

Method: 该研究推导了高斯图元作为随机固体的理论基础，并提出了 Geometry-Grounded Gaussian Splatting。该方法利用随机固体的体绘制特性，高效地渲染高质量深度图，用于提取精细几何形状。

Result: 该方法在公开数据集上取得了最佳的形状重建结果，优于所有其他基于高斯溅射的方法。

Conclusion: 将高斯图元视为随机固体提供了一种原理性的方法来处理高斯溅射的几何表示，并能够高效地提取高质量的几何形状，解决了现有方法的不足。

Abstract: Gaussian Splatting (GS) has demonstrated impressive quality and efficiency in novel view synthesis. However, shape extraction from Gaussian primitives remains an open problem. Due to inadequate geometry parameterization and approximation, existing shape reconstruction methods suffer from poor multi-view consistency and are sensitive to floaters. In this paper, we present a rigorous theoretical derivation that establishes Gaussian primitives as a specific type of stochastic solids. This theoretical framework provides a principled foundation for Geometry-Grounded Gaussian Splatting by enabling the direct treatment of Gaussian primitives as explicit geometric representations. Using the volumetric nature of stochastic solids, our method efficiently renders high-quality depth maps for fine-grained geometry extraction. Experiments show that our method achieves the best shape reconstruction results among all Gaussian Splatting-based methods on public datasets.

</details>


### [167] [SynMind: Reducing Semantic Hallucination in fMRI-Based Image Reconstruction](https://arxiv.org/abs/2601.17857)
*Lan Yang,Minghan Yang,Ke Li,Honggang Zhang,Kaiyue Pang,Yi-Zhe Song*

Main category: cs.CV

TL;DR: 该研究提出了一种名为SynMind的新框架，通过将fMRI信号解析为丰富的文本描述，解决了fMRI图像重建中语义不匹配的问题，并在图像质量和语义准确性上取得了显著进步，甚至在轻量级模型下也能超越更复杂的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的fMRI图像重建技术虽然能生成逼真的图像，但往往存在严重的语义不匹配问题，即重建的图像在视觉上很自然，但物体识别不准确，甚至出现幻觉。这表明现有方法过于依赖低级视觉特征，忽视了显式的语义信息。

Method: 该研究首先利用强大的视觉语言模型（VLMs）将fMRI信号解析成多粒度的文本描述，捕捉物体的身份和空间关系。然后，提出SynMind框架，将这些显式的语义编码与视觉先验信息相结合，用于引导一个预训练的扩散模型进行图像重建。

Result: SynMind在多数定量指标上优于现有最先进的方法。更重要的是，通过将语义推理转移到文本对齐模块，SynMind在显著小于SDXL的Stable Diffusion 1.4模型和单块消费级GPU上，重建效果超过了基于SDXL的竞争方法。大规模人类评估也证实了SynMind重建图像与人类视觉感知的一致性。神经可视化分析表明，SynMind激活了更广泛、更具语义相关性的脑区。

Conclusion: 通过显式地将fMRI信号转化为多粒度的语义描述，并将其与视觉先验信息相结合，SynMind能够有效地解决fMRI图像重建中的语义不匹配问题，实现更高质量、更具语义准确性的图像重建，并且在计算资源要求上具有优势。

Abstract: Recent advances in fMRI-based image reconstruction have achieved remarkable photo-realistic fidelity. Yet, a persistent limitation remains: while reconstructed images often appear naturalistic and holistically similar to the target stimuli, they frequently suffer from severe semantic misalignment -- salient objects are often replaced or hallucinated despite high visual quality. In this work, we address this limitation by rethinking the role of explicit semantic interpretation in fMRI decoding. We argue that existing methods rely too heavily on entangled visual embeddings which prioritize low-level appearance cues -- such as texture and global gist -- over explicit semantic identity. To overcome this, we parse fMRI signals into rich, sentence-level semantic descriptions that mirror the hierarchical and compositional nature of human visual understanding. We achieve this by leveraging grounded VLMs to generate synthetic, human-like, multi-granularity textual representations that capture object identities and spatial organization. Built upon this foundation, we propose SynMind, a framework that integrates these explicit semantic encodings with visual priors to condition a pretrained diffusion model. Extensive experiments demonstrate that SynMind outperforms state-of-the-art methods across most quantitative metrics. Notably, by offloading semantic reasoning to our text-alignment module, SynMind surpasses competing methods based on SDXL while using the much smaller Stable Diffusion 1.4 and a single consumer GPU. Large-scale human evaluations further confirm that SynMind produces reconstructions more consistent with human visual perception. Neurovisualization analyses reveal that SynMind engages broader and more semantically relevant brain regions, mitigating the over-reliance on high-level visual areas.

</details>


### [168] [Domain Generalization with Quantum Enhancement for Medical Image Classification: A Lightweight Approach for Cross-Center Deployment](https://arxiv.org/abs/2601.17862)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: 提出了一种轻量级的量子增强协作学习框架，用于医学图像的领域泛化，可在无标记的多中心数据的情况下实现对未见目标领域的鲁棒泛化。


<details>
  <summary>Details</summary>
Motivation: 现有的医学影像AI模型在单中心或单设备下表现良好，但在跨中心部署时由于域漂移而性能下降，限制了临床应用。需要一种能够在不同中心部署下保持良好泛化能力的方法。

Method: 构建了一个基于MobileNetV2的域不变编码器，通过以下三个关键组件进行优化：1) 使用亮度、对比度、锐度和噪声扰动模拟多域成像偏移；2) 使用梯度反转的域对抗训练来抑制域判别性特征；3) 引入轻量级量子特征增强层，利用参数化量子电路进行非线性特征映射和纠缠建模。此外，在推理时采用测试时适应策略。

Result: 在模拟的多中心医学成像数据集上，所提出的方法显著优于没有领域泛化或量子增强的基线模型，在未见域上实现了更低的域特定性能方差，并提高了AUC和敏感度。

Conclusion: 该方法在计算资源受限的情况下展示了量子增强领域泛化的临床潜力，并为混合量子-经典医学成像系统提供了一种可行的范例。

Abstract: Medical image artificial intelligence models often achieve strong performance in single-center or single-device settings, yet their effectiveness frequently deteriorates in real-world cross-center deployment due to domain shift, limiting clinical generalizability. To address this challenge, we propose a lightweight domain generalization framework with quantum-enhanced collaborative learning, enabling robust generalization to unseen target domains without relying on real multi-center labeled data. Specifically, a MobileNetV2-based domain-invariant encoder is constructed and optimized through three key components: (1) multi-domain imaging shift simulation using brightness, contrast, sharpening, and noise perturbations to emulate heterogeneous acquisition conditions; (2) domain-adversarial training with gradient reversal to suppress domain-discriminative features; and (3) a lightweight quantum feature enhancement layer that applies parameterized quantum circuits for nonlinear feature mapping and entanglement modeling. In addition, a test-time adaptation strategy is employed during inference to further alleviate distribution shifts. Experiments on simulated multi-center medical imaging datasets demonstrate that the proposed method significantly outperforms baseline models without domain generalization or quantum enhancement on unseen domains, achieving reduced domain-specific performance variance and improved AUC and sensitivity. These results highlight the clinical potential of quantum-enhanced domain generalization under constrained computational resources and provide a feasible paradigm for hybrid quantum--classical medical imaging systems.

</details>


### [169] [MV-SAM: Multi-view Promptable Segmentation using Pointmap Guidance](https://arxiv.org/abs/2601.17866)
*Yoonwoo Jeong,Cheng Sun,Yu-Chiang Frank Wang,Minsu Cho,Jaesung Choe*

Main category: cs.CV

TL;DR: MV-SAM 是一种用于多视图分割的框架，它利用点图（pointmaps）实现了 3D 一致性，无需显式的 3D 网络或标注数据。


<details>
  <summary>Details</summary>
Motivation: 现有的即时分割模型（如 SAM）在处理视频和多视图图像时缺乏 3D 意识，导致结果不一致，需要昂贵的每场景优化。

Method: MV-SAM 通过将点图（由未设姿的图像重建）与 SAM 结合，将图像嵌入提升到 3D 空间。它通过 Transformer 和交叉注意力机制，利用 3D 位置嵌入来实现跨视图的一致性分割。

Result: MV-SAM 在 SA-1B 数据集上训练，并在 NVOS、SPIn-NeRF、ScanNet++、uCo3D 和 DL3DV 基准测试中表现出色，优于 SAM2-Video，并与需要每场景优化的基线方法相当。

Conclusion: MV-SAM 成功地将 2D 的即时分割能力扩展到 3D 多视图场景，通过利用点图实现了 3D 一致性，并且无需昂贵的 3D 标注或优化。

Abstract: Promptable segmentation has emerged as a powerful paradigm in computer vision, enabling users to guide models in parsing complex scenes with prompts such as clicks, boxes, or textual cues. Recent advances, exemplified by the Segment Anything Model (SAM), have extended this paradigm to videos and multi-view images. However, the lack of 3D awareness often leads to inconsistent results, necessitating costly per-scene optimization to enforce 3D consistency. In this work, we introduce MV-SAM, a framework for multi-view segmentation that achieves 3D consistency using pointmaps -- 3D points reconstructed from unposed images by recent visual geometry models. Leveraging the pixel-point one-to-one correspondence of pointmaps, MV-SAM lifts images and prompts into 3D space, eliminating the need for explicit 3D networks or annotated 3D data. Specifically, MV-SAM extends SAM by lifting image embeddings from its pretrained encoder into 3D point embeddings, which are decoded by a transformer using cross-attention with 3D prompt embeddings. This design aligns 2D interactions with 3D geometry, enabling the model to implicitly learn consistent masks across views through 3D positional embeddings. Trained on the SA-1B dataset, our method generalizes well across domains, outperforming SAM2-Video and achieving comparable performance with per-scene optimization baselines on NVOS, SPIn-NeRF, ScanNet++, uCo3D, and DL3DV benchmarks. Code will be released.

</details>


### [170] [3DGesPolicy: Phoneme-Aware Holistic Co-Speech Gesture Generation Based on Action Control](https://arxiv.org/abs/2601.18451)
*Xuanmeng Sha,Liyun Zhang,Tomohiro Mashita,Naoya Chiba,Yuki Uranishi*

Main category: cs.CV

TL;DR: 提出了一种名为3DGesPolicy的新框架，通过模仿机器人学中的扩散策略，将整体手势生成问题重新定义为连续轨迹控制问题，解决了现有方法在身体运动和面部表情协调上的不足。引入了GAP融合模块，以更好地对齐语音、身体运动和面部表情。实验证明该方法能生成自然、富有表现力且与语音高度协调的整体手势。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成与语音在语义和空间上协调的整体手势方面存在不足，容易产生语义不连贯的身体运动和空间不稳定的无意义运动。

Method: 提出3DGesPolicy框架，将手势生成视为一个连续轨迹控制问题，利用机器人学中的扩散策略学习帧间整体手势运动模式。引入Gesture-Audio-Phoneme (GAP) 融合模块，深度整合并优化多模态信号，以实现语音语义、身体运动和面部表情之间的结构化、细粒度对齐。

Result: 在BEAT2数据集上的定量和定性实验表明，3DGesPolicy在生成自然、富有表现力且与语音高度对齐的整体手势方面优于其他最先进的方法。

Conclusion: 3DGesPolicy框架能够有效解决现有手势生成方法的局限性，生成在空间和语义上都高度协调且与语音信息紧密结合的整体手势。

Abstract: Generating holistic co-speech gestures that integrate full-body motion with facial expressions suffers from semantically incoherent coordination on body motion and spatially unstable meaningless movements due to existing part-decomposed or frame-level regression methods, We introduce 3DGesPolicy, a novel action-based framework that reformulates holistic gesture generation as a continuous trajectory control problem through diffusion policy from robotics. By modeling frame-to-frame variations as unified holistic actions, our method effectively learns inter-frame holistic gesture motion patterns and ensures both spatially and semantically coherent movement trajectories that adhere to realistic motion manifolds. To further bridge the gap in expressive alignment, we propose a Gesture-Audio-Phoneme (GAP) fusion module that can deeply integrate and refine multi-modal signals, ensuring structured and fine-grained alignment between speech semantics, body motion, and facial expressions. Extensive quantitative and qualitative experiments on the BEAT2 dataset demonstrate the effectiveness of our 3DGesPolicy across other state-of-the-art methods in generating natural, expressive, and highly speech-aligned holistic gestures.

</details>


### [171] [Quran-MD: A Fine-Grained Multilingual Multimodal Dataset of the Quran](https://arxiv.org/abs/2601.17880)
*Muhammad Umar Salman,Mohammad Areeb Qazi,Mohammed Talha Alam*

Main category: cs.CV

TL;DR: 该研究提出了一个名为 Quran MD 的全面多模态古兰经数据集，整合了文本、语言和音频信息，涵盖经文和单词级别，支持古兰经研究的多种应用。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏一个能够整合古兰经文本、语言和音频，并且涵盖经文和单词级别多方位的多模态数据集，这阻碍了在自然语言处理、语音识别、文本到语音合成、语言分析和数字伊斯兰研究等领域的深入研究和应用。

Method: 构建了一个多模态古兰经数据集 Quran MD，该数据集包含经文级别的阿拉伯语原文、英文翻译、音译以及来自32位不同诵经者的音频。在单词级别，每个词都配有其阿拉伯语文本、英文翻译、音译和对应的音频录音。

Result: 创建了一个包含文本、语言和音频维度，覆盖经文和单词级别的多模态古兰经数据集 Quran MD。该数据集支持多种应用，包括但不限于自动语音识别（ASR）、Tajweed检测、古兰经文本到语音合成（TTS）、多模态嵌入、语义检索、风格迁移和个性化辅导系统。

Conclusion: Quran MD 数据集为古兰经的多模态研究提供了独特的资源，特别是在计算古兰经诵读和学习方面。它不仅支持现有任务，还为开发更高级的应用奠定了基础，能够服务于研究和社区需求。

Abstract: We present Quran MD, a comprehensive multimodal dataset of the Quran that integrates textual, linguistic, and audio dimensions at the verse and word levels. For each verse (ayah), the dataset provides its original Arabic text, English translation, and phonetic transliteration. To capture the rich oral tradition of Quranic recitation, we include verse-level audio from 32 distinct reciters, reflecting diverse recitation styles and dialectical nuances. At the word level, each token is paired with its corresponding Arabic script, English translation, transliteration, and an aligned audio recording, allowing fine-grained analysis of pronunciation, phonology, and semantic context. This dataset supports various applications, including natural language processing, speech recognition, text-to-speech synthesis, linguistic analysis, and digital Islamic studies. Bridging text and audio modalities across multiple reciters, this dataset provides a unique resource to advance computational approaches to Quranic recitation and study. Beyond enabling tasks such as ASR, tajweed detection, and Quranic TTS, it lays the foundation for multimodal embeddings, semantic retrieval, style transfer, and personalized tutoring systems that can support both research and community applications. The dataset is available at https://huggingface.co/datasets/Buraaq/quran-audio-text-dataset

</details>


### [172] [Fair-Eye Net: A Fair, Trustworthy, Multimodal Integrated Glaucoma Full Chain AI System](https://arxiv.org/abs/2601.18464)
*Wenbin Wei,Suyuan Yao,Cheng Huang,Xiangyu Gao*

Main category: cs.CV

TL;DR: 开发了一个名为Fair-Eye Net的多模态AI系统，能够整合眼底照片、OCT、视野检查和人口统计学信息，实现从青光眼筛查到随访和风险预警的闭环管理，同时解决了公平性和可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的青光眼筛查和进展评估方法存在主观性、碎片化、高质量成像工具和专家资源获取不均等问题，影响了诊疗的一致性和公平性。

Method: 开发了Fair-Eye Net，一个采用双流异构融合架构的多模态AI系统，整合了眼底照片、OCT结构指标、视野功能指标和人口统计学数据。该系统使用一种不确定性感知的分层门控策略进行选择性预测和安全转诊，并引入公平性约束以减少弱势群体的漏诊。通过多任务学习同时优化公平性和临床可靠性。

Result: Fair-Eye Net的AUC达到0.912（特异度96.7%），将种族漏诊率差异降低了73.4%，并实现了3-12个月的早期风险预警（敏感度92%，特异度88%）。

Conclusion: Fair-Eye Net通过将公平性作为首要目标与临床可靠性相结合，为青光眼的临床翻译和大规模部署提供了一条可重复的途径，有助于提升全球眼健康公平性。

Abstract: Glaucoma is a top cause of irreversible blindness globally, making early detection and longitudinal follow-up pivotal to preventing permanent vision loss. Current screening and progression assessment, however, rely on single tests or loosely linked examinations, introducing subjectivity and fragmented care. Limited access to high-quality imaging tools and specialist expertise further compromises consistency and equity in real-world use. To address these gaps, we developed Fair-Eye Net, a fair, reliable multimodal AI system closing the clinical loop from glaucoma screening to follow-up and risk alerting. It integrates fundus photos, OCT structural metrics, VF functional indices, and demographic factors via a dual-stream heterogeneous fusion architecture, with an uncertainty-aware hierarchical gating strategy for selective prediction and safe referral. A fairness constraint reduces missed diagnoses in disadvantaged subgroups. Experimental results show it achieved an AUC of 0.912 (96.7% specificity), cut racial false-negativity disparity by 73.4% (12.31% to 3.28%), maintained stable cross-domain performance, and enabled 3-12 months of early risk alerts (92% sensitivity, 88% specificity). Unlike post hoc fairness adjustments, Fair-Eye Net optimizes fairness as a primary goal with clinical reliability via multitask learning, offering a reproducible path for clinical translation and large-scale deployment to advance global eye health equity.

</details>


### [173] [Revisiting 3D Reconstruction Kernels as Low-Pass Filters](https://arxiv.org/abs/2601.17900)
*Shengjun Zhang,Min Chen,Yibo Wei,Mingyu Dong,Yueqi Duan*

Main category: cs.CV

TL;DR: 该研究从信号处理角度重新审视3D重建，提出使用Jinc核函数及其调制版本来解决离散采样引起的周期性频谱扩展问题，从而提高3D重建的渲染性能。


<details>
  <summary>Details</summary>
Motivation: 传统的3D重建方法使用高斯、指数或t分布等核函数作为低通滤波器，但这些核函数不理想的低通特性会导致频谱混叠，影响重建质量。研究旨在克服这一挑战。

Method: 提出使用Jinc核函数，它在截止频率处具有瞬时零幅值，代表理想低通滤波器。由于Jinc核在空间域衰减慢，进一步提出了调制核函数，以在空间效率和频域保真度之间取得平衡。

Result: 实验结果表明，Jinc核及其调制版本在3D重建任务中表现出优越的渲染性能，有效解决了频谱混叠问题。

Conclusion: Jinc核及其调制核函数是一种有效的3D重建方法，能够通过在空间域和频域之间取得良好平衡，实现更精确和高质量的3D信号恢复。

Abstract: 3D reconstruction is to recover 3D signals from the sampled discrete 2D pixels, with the goal to converge continuous 3D spaces. In this paper, we revisit 3D reconstruction from the perspective of signal processing, identifying the periodic spectral extension induced by discrete sampling as the fundamental challenge. Previous 3D reconstruction kernels, such as Gaussians, Exponential functions, and Student's t distributions, serve as the low pass filters to isolate the baseband spectrum. However, their unideal low-pass property results in the overlap of high-frequency components with low-frequency components in the discrete-time signal's spectrum. To this end, we introduce Jinc kernel with an instantaneous drop to zero magnitude exactly at the cutoff frequency, which is corresponding to the ideal low pass filters. As Jinc kernel suffers from low decay speed in the spatial domain, we further propose modulated kernels to strick an effective balance, and achieves superior rendering performance by reconciling spatial efficiency and frequency-domain fidelity. Experimental results have demonstrated the effectiveness of our Jinc and modulated kernels.

</details>


### [174] [Benchmarking Direct Preference Optimization for Medical Large Vision-Language Models](https://arxiv.org/abs/2601.17918)
*Dain Kim,Jiwoo Lee,Jaehoon Yun,Yong Hoe Koo,Qingyu Chen,Hyunjae Kim,Jaewoo Kang*

Main category: cs.CV

TL;DR: 本研究首次全面评估了不同 DPO (Direct Preference Optimization) 变体在医学领域大型视觉语言模型 (LVLMs) 上的表现，发现现有 DPO 方法在医学领域提升有限且存在视觉错误解释问题。作者提出了一种改进的偏好构建策略，在视觉问答任务上取得了 3.6% 的提升，并开源了研究成果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型 (LVLMs) 在医学领域的应用受限于对齐和可靠性不足。虽然 DPO 被认为是优化模型响应的有效方法，但其在医学高风险场景下的有效性尚未得到充分研究。因此，本研究旨在填补这一空白，深入评估 DPO 在医学领域的应用效果。

Method: 作者评估了九种不同的 DPO 变体，在 LLaVA-Med 和 HuatuoGPT-Vision 这两个医学 LVLMs 上进行了实验。在此基础上，提出了一种新的偏好构建策略，以解决 DPO 模型中常见的视觉错误解释问题。

Result: 研究发现，现有的 DPO 方法在医学领域相对于监督微调 (SFT) 的提升效果不一致，并且在不同任务和模型骨干上表现差异显著。它们往往无法解决根本性的视觉错误解释问题。作者提出的改进偏好构建策略在视觉问答任务上比现有的最佳 DPO 基线模型提升了 3.6%。

Conclusion: 尽管 DPO 是一种有潜力的优化框架，但在医学 LVLMs 应用中仍存在局限性，特别是视觉错误解释问题。作者提出的偏好构建策略为解决这些问题提供了一个有效的方向，并且研究成果的开源将有助于未来的相关研究。

Abstract: Large Vision-Language Models (LVLMs) hold significant promise for medical applications, yet their deployment is often constrained by insufficient alignment and reliability. While Direct Preference Optimization (DPO) has emerged as a potent framework for refining model responses, its efficacy in high-stakes medical contexts remains underexplored, lacking the rigorous empirical groundwork necessary to guide future methodological advances. To bridge this gap, we present the first comprehensive examination of diverse DPO variants within the medical domain, evaluating nine distinct formulations across two medical LVLMs: LLaVA-Med and HuatuoGPT-Vision. Our results reveal several critical limitations: current DPO approaches often yield inconsistent gains over supervised fine-tuning, with their efficacy varying significantly across different tasks and backbones. Furthermore, they frequently fail to resolve fundamental visual misinterpretation errors. Building on these insights, we present a targeted preference construction strategy as a proof-of-concept that explicitly addresses visual misinterpretation errors frequently observed in existing DPO models. This design yields a 3.6% improvement over the strongest existing DPO baseline on visual question-answering tasks. To support future research, we release our complete framework, including all training data, model checkpoints, and our codebase at https://github.com/dmis-lab/med-vlm-dpo.

</details>


### [175] [RemEdit: Efficient Diffusion Editing with Riemannian Geometry](https://arxiv.org/abs/2601.17927)
*Eashan Adhikarla,Brian D. Davison*

Main category: cs.CV

TL;DR: RemEdit是一个基于扩散模型的方法，通过黎曼流形导航和注意力剪枝技术，在保证编辑保真度的同时实现了实时图像编辑，并在保持超过50%剪枝率的情况下超越了现有最先进的编辑框架。


<details>
  <summary>Details</summary>
Motivation: 现有可控图像生成方法在语义保真度和推理速度之间存在权衡。研究旨在解决这一权衡，实现既准确又快速的图像编辑。

Method: 1. **黎曼流形导航**: 将潜在空间视为黎曼流形，使用基于Mamba的模块学习流形结构，通过测地线路径计算实现平滑的语义编辑。结合双SLERP混合技术和基于视觉语言模型的感知目标提示增强。 2. **注意力剪枝**: 引入任务特定的注意力剪枝机制，通过一个轻量级剪枝头识别并保留对编辑至关重要的Token，从而实现优化而不损害语义。

Result: RemEdit在保持实时性能（低于50%的剪枝率）的同时，在图像编辑方面超越了现有最先进的框架。

Conclusion: RemEdit通过创新的黎曼流形导航和注意力剪枝技术，为实用且强大的图像编辑设定了新的基准，成功解决了语义保真度和推理速度之间的权衡问题。

Abstract: Controllable image generation is fundamental to the success of modern generative AI, yet it faces a critical trade-off between semantic fidelity and inference speed. The RemEdit diffusion-based framework addresses this trade-off with two synergistic innovations. First, for editing fidelity, we navigate the latent space as a Riemannian manifold. A mamba-based module efficiently learns the manifold's structure, enabling direct and accurate geodesic path computation for smooth semantic edits. This control is further refined by a dual-SLERP blending technique and a goal-aware prompt enrichment pass from a Vision-Language Model. Second, for additional acceleration, we introduce a novel task-specific attention pruning mechanism. A lightweight pruning head learns to retain tokens essential to the edit, enabling effective optimization without the semantic degradation common in content-agnostic approaches. RemEdit surpasses prior state-of-the-art editing frameworks while maintaining real-time performance under 50% pruning. Consequently, RemEdit establishes a new benchmark for practical and powerful image editing. Source code: https://www.github.com/eashanadhikarla/RemEdit.

</details>


### [176] [SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification](https://arxiv.org/abs/2601.18739)
*Ignacio Antequera-Sánchez,Juan Luis Suárez-Díaz,Rosana Montes,Francisco Herrera*

Main category: cs.CV

TL;DR: 提出了一种名为SeNeDiF-OOD的新方法，用于检测不同类型的分布外（OOD）数据，并通过在建筑风格识别系统MonuMAI上的实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的单阶段OOD检测方法难以应对从低级损坏到语义偏移等异构的OOD数据。因此，需要一种能够处理多层次语义抽象的OOD检测方法。

Method: 提出SeNeDiF-OOD框架，该框架基于语义嵌套二分法融合（Semantic Nested Dichotomy Fusion）。该框架将检测任务分解为二元融合节点的层次结构，每一层都旨在整合与特定语义抽象级别对齐的决策边界。

Result: 在MonuMAI（一个真实的建筑风格识别系统）上的实验评估表明，SeNeDiF-OOD在过滤各种OOD类别（包括非纪念性图像、未知建筑风格和对抗性攻击）方面显著优于传统基线方法，同时保持了分布内性能。

Conclusion: SeNeDiF-OOD是一种新颖的、基于层次化融合的OOD检测方法，能够有效地处理不同类型的OOD数据，并能在真实世界的开放环境中实现可靠的AI部署。

Abstract: Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.

</details>


### [177] [DTC: A Deformable Transposed Convolution Module for Medical Image Segmentation](https://arxiv.org/abs/2601.17939)
*Chengkun Sun,Jinqian Pan,Renjie Liang,Zhengkang Fan,Xin Miao,Jiang Bian,Jie Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为可变形转置卷积（DTC）的新型上采样方法，用于医学图像分割，它通过学习动态采样位置来提高特征重建和细节恢复能力。


<details>
  <summary>Details</summary>
Motivation: 现有的上采样方法（如转置卷积和线性插值）在固定位置进行操作，可能无法捕捉预定义采样位置之外的结构信息，导致伪影或细节丢失。

Method: 提出可变形转置卷积（DTC），模仿可变形卷积的思想，学习动态的采样坐标来生成高分辨率特征图。

Result: 在3D（BTCV15）和2D（ISIC18, BUSI）医学图像分割数据集上的实验表明，DTC可以有效集成到现有模型中，并持续提升解码器在特征重建和细节恢复方面的能力。

Conclusion: DTC是一种有效的新型上采样方法，能够增强医学图像分割模型对细节信息的捕捉和重建能力。

Abstract: In medical image segmentation, particularly in UNet-like architectures, upsampling is primarily used to transform smaller feature maps into larger ones, enabling feature fusion between encoder and decoder features and supporting multi-scale prediction. Conventional upsampling methods, such as transposed convolution and linear interpolation, operate on fixed positions: transposed convolution applies kernel elements to predetermined pixel or voxel locations, while linear interpolation assigns values based on fixed coordinates in the original feature map. These fixed-position approaches may fail to capture structural information beyond predefined sampling positions and can lead to artifacts or loss of detail. Inspired by deformable convolutions, we propose a novel upsampling method, Deformable Transposed Convolution (DTC), which learns dynamic coordinates (i.e., sampling positions) to generate high-resolution feature maps for both 2D and 3D medical image segmentation tasks. Experiments on 3D (e.g., BTCV15) and 2D datasets (e.g., ISIC18, BUSI) demonstrate that DTC can be effectively integrated into existing medical image segmentation models, consistently improving the decoder's feature reconstruction and detail recovery capability.

</details>


### [178] [FlowMorph: Physics-Consistent Self-Supervision for Label-Free Single-Cell Mechanics in Microfluidic Videos](https://arxiv.org/abs/2601.17947)
*Bora Yimenicioglu,Vishal Manikanden*

Main category: cs.CV

TL;DR: FlowMorph是一个物理一致的自监督框架，通过处理短的明场微流控视频，学习红细胞（RBC）的力学代理指标k，能够区分不同的变形模式并预测其杨氏模量。


<details>
  <summary>Details</summary>
Motivation: 红细胞的力学性质是诊断血液系统疾病和全身疾病的有希望的生物标志物，这促使了微流控检测方法的发展，但现有方法依赖于监督分割或手动制作的kymograph，并且很少考虑控制RBC形状演变的层流斯托克斯流物理学。

Method: FlowMorph使用一个低维参数化轮廓模型，通过一个可微分的“胶囊流”模型来推进边界点，该模型结合了层流平流和曲率正则化的弹性松弛。它通过一个损失函数进行优化，该函数耦合了轮廓重叠、细胞内流动一致性、面积守恒、壁约束和时间平滑性，并且仅使用自动派生的轮廓和光流。

Result: FlowMorph在四个公共RBC微流控数据集上实现了0.905的平均轮廓IoU，并且在面积守恒和壁约束违规方面显著优于纯数据驱动的方法。该标量k能够以0.863的AUC区分“坦克履带式”和“翻转式”动力学。仅使用200个实时变形流式细胞术（RT-DC）事件进行校准，一个单调映射E=g(k)能够以0.118 MPa的平均绝对误差预测表观杨氏模量。

Conclusion: FlowMorph是一个有效的、物理一致的自监督框架，能够从明场微流控视频中提取RBC的力学信息，并能区分不同的变形模式和预测杨氏模量，且对实验条件的变化具有鲁棒性。

Abstract: Mechanical properties of red blood cells (RBCs) are promising biomarkers for hematologic and systemic disease, motivating microfluidic assays that probe deformability at throughputs of $10^3$--$10^6$ cells per experiment. However, existing pipelines rely on supervised segmentation or hand-crafted kymographs and rarely encode the laminar Stokes-flow physics that governs RBC shape evolution. We introduce FlowMorph, a physics-consistent self-supervised framework that learns a label-free scalar mechanics proxy $k$ for each tracked RBC from short brightfield microfluidic videos. FlowMorph models each cell by a low-dimensional parametric contour, advances boundary points through a differentiable ''capsule-in-flow'' combining laminar advection and curvature-regularized elastic relaxation, and optimizes a loss coupling silhouette overlap, intra-cellular flow agreement, area conservation, wall constraints, and temporal smoothness, using only automatically derived silhouettes and optical flow.
  Across four public RBC microfluidic datasets, FlowMorph achieves a mean silhouette IoU of $0.905$ on physics-rich videos with provided velocity fields and markedly improves area conservation and wall violations over purely data-driven baselines. On $\sim 1.5\times 10^5$ centered sequences, the scalar $k$ alone separates tank-treading from flipping dynamics with an AUC of $0.863$. Using only $200$ real-time deformability cytometry (RT-DC) events for calibration, a monotone map $E=g(k)$ predicts apparent Young's modulus with a mean absolute error of $0.118$\,MPa on $600$ held-out cells and degrades gracefully under shifts in channel geometry, optics, and frame rate.

</details>


### [179] [Domain-Expert-Guided Hybrid Mixture-of-Experts for Medical AI: Integrating Data-Driven Learning with Clinical Priors](https://arxiv.org/abs/2601.17977)
*Jinchen Gu,Nan Zhao,Lei Qiu,Lu Zhang*

Main category: cs.CV

TL;DR: 提出了一种领域知识引导的混合专家模型（DKGH-MoE），它结合了数据驱动的专家和由临床专家眼动图引导的专家，以提高医学影像分析的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在医学等专业领域，小数据集限制了混合专家模型（MoE）的有效性。临床实践中存在丰富的专家知识（如医生注视模式和诊断启发），但现有模型难以从有限数据中可靠学习。因此，需要一种方法来整合数据驱动的专家和领域专家指导的专家，以发挥各自的优势。

Method: 提出了一种名为DKGH-MoE的即插即用且可解释的模块。该模块包含一个数据驱动的MoE，用于从原始医学影像数据中提取新特征；以及一个领域专家指导的MoE，该MoE利用临床先验知识（特别是临床医生的眼动图线索）来强调具有高诊断相关性的区域。

Result: 通过整合领域专家见解和数据驱动的特征，DKGH-MoE 提高了医学影像分析的性能和可解释性。

Conclusion: DKGH-MoE 是一种将数据驱动学习与领域专业知识相结合的有效方法，通过整合眼动图等临床先验信息，能够提高模型在医学图像分析任务中的表现和可解释性。

Abstract: Mixture-of-Experts (MoE) models increase representational capacity with modest computational cost, but their effectiveness in specialized domains such as medicine is limited by small datasets. In contrast, clinical practice offers rich expert knowledge, such as physician gaze patterns and diagnostic heuristics, that models cannot reliably learn from limited data. Combining data-driven experts, which capture novel patterns, with domain-expert-guided experts, which encode accumulated clinical insights, provides complementary strengths for robust and clinically meaningful learning. To this end, we propose Domain-Knowledge-Guided Hybrid MoE (DKGH-MoE), a plug-and-play and interpretable module that unifies data-driven learning with domain expertise. DKGH-MoE integrates a data-driven MoE to extract novel features from raw imaging data, and a domain-expert-guided MoE incorporates clinical priors, specifically clinician eye-gaze cues, to emphasize regions of high diagnostic relevance. By integrating domain expert insights with data-driven features, DKGH-MoE improves both performance and interpretability.

</details>


### [180] [MorphXAI: An Explainable Framework for Morphological Analysis of Parasites in Blood Smear Images](https://arxiv.org/abs/2601.18001)
*Aqsa Yousaf,Sint Sint Win,Megan Coffee,Habeeb Olufowobi*

Main category: cs.CV

TL;DR: 本文提出 MorphXAI 框架，结合了寄生虫检测和细粒度形态学分析，旨在提供比现有方法更具临床意义的可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习模型在自动化寄生虫检测方面表现良好，但其临床应用受限于有限的可解释性。现有的解释方法（如热力图）无法捕捉临床医生依赖的形态学特征，而这些特征对于诊断至关重要。

Method: MorphXAI 框架将形态学监督直接整合到预测流程中，使其能够定位寄生虫并同时表征临床相关属性（如形状、曲率、可见点数、鞭毛存在和发育阶段）。为此，研究人员创建了一个包含三种寄生虫（利什曼原虫、布氏锥虫和克氏锥虫）的、由临床医生标注的、具有详细形态学标签的数据集。

Result: 实验结果表明，MorphXAI 在检测性能上优于基线模型，并能提供结构化、具有生物学意义的解释。

Conclusion: MorphXAI 框架能够实现寄生虫检测与细粒度形态学分析的统一，提供比现有方法更具临床价值的可解释性，为可解释的寄生虫分析树立了新的标杆。

Abstract: Parasitic infections remain a pressing global health challenge, particularly in low-resource settings where diagnosis still depends on labor-intensive manual inspection of blood smears and the availability of expert domain knowledge. While deep learning models have shown strong performance in automating parasite detection, their clinical usefulness is constrained by limited interpretability. Existing explainability methods are largely restricted to visual heatmaps or attention maps, which highlight regions of interest but fail to capture the morphological traits that clinicians rely on for diagnosis. In this work, we present MorphXAI, an explainable framework that unifies parasite detection with fine-grained morphological analysis. MorphXAI integrates morphological supervision directly into the prediction pipeline, enabling the model to localize parasites while simultaneously characterizing clinically relevant attributes such as shape, curvature, visible dot count, flagellum presence, and developmental stage. To support this task, we curate a clinician-annotated dataset of three parasite species (Leishmania, Trypanosoma brucei, and Trypanosoma cruzi) with detailed morphological labels, establishing a new benchmark for interpretable parasite analysis. Experimental results show that MorphXAI not only improves detection performance over the baseline but also provides structured, biologically meaningful explanations.

</details>


### [181] [Strip-Fusion: Spatiotemporal Fusion for Multispectral Pedestrian Detection](https://arxiv.org/abs/2601.18008)
*Asiegbu Miracle Kanu-Asiegbu,Nitin Jotwani,Xiaoxiao Du*

Main category: cs.CV

TL;DR: 提出了一种名为Strip-Fusion的空间-时间融合网络，用于多光谱行人检测，该网络能够应对输入图像的对齐不当、光照变化和遮挡问题，并通过时间自适应卷积和KL散度损失来提升性能，并在KAIST和CVC-14数据集上取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的多光谱行人检测方法主要关注空间融合而忽略时间信息，并且可能无法完美处理RGB和热成像图像对之间的对齐问题。同时，行人检测本身也面临光照变化和遮挡等挑战。

Method: 提出Strip-Fusion网络，该网络整合了时间自适应卷积来动态加权空间-时间特征，并设计了新的KL散度损失来减轻模态不平衡，以及一个用于减少误报的后处理算法。

Result: 该方法在KAIST和CVC-14数据集上表现具有竞争力，在重度遮挡和对齐不当等挑战性条件下，相比现有最先进方法有显著提升。

Conclusion: Strip-Fusion网络通过有效融合空间和时间信息，并采用新的损失函数和后处理算法，成功解决了多光谱行人检测中的对齐不当、光照变化和遮挡等问题，并在相关基准测试中取得了优于现有方法的性能。

Abstract: Pedestrian detection is a critical task in robot perception. Multispectral modalities (visible light and thermal) can boost pedestrian detection performance by providing complementary visual information. Several gaps remain with multispectral pedestrian detection methods. First, existing approaches primarily focus on spatial fusion and often neglect temporal information. Second, RGB and thermal image pairs in multispectral benchmarks may not always be perfectly aligned. Pedestrians are also challenging to detect due to varying lighting conditions, occlusion, etc. This work proposes Strip-Fusion, a spatial-temporal fusion network that is robust to misalignment in input images, as well as varying lighting conditions and heavy occlusions. The Strip-Fusion pipeline integrates temporally adaptive convolutions to dynamically weigh spatial-temporal features, enabling our model to better capture pedestrian motion and context over time. A novel Kullback-Leibler divergence loss was designed to mitigate modality imbalance between visible and thermal inputs, guiding feature alignment toward the more informative modality during training. Furthermore, a novel post-processing algorithm was developed to reduce false positives. Extensive experimental results show that our method performs competitively for both the KAIST and the CVC-14 benchmarks. We also observed significant improvements compared to previous state-of-the-art on challenging conditions such as heavy occlusion and misalignment.

</details>


### [182] [Semi-Supervised Hyperspectral Image Classification with Edge-Aware Superpixel Label Propagation and Adaptive Pseudo-Labeling](https://arxiv.org/abs/2601.18049)
*Yunfei Qiu,Qiqiong Ma,Tianhua Lv,Li Fang,Shudong Zhou,Wei Yao*

Main category: cs.CV

TL;DR: 该论文提出了一种新的半监督高光谱图像分类框架DREPL，通过边缘感知超像素标签传播（EASLP）和动态历史融合预测（DHP）与自适应三元样本分类（ATSC）相结合，解决了边界标签扩散和伪标签不稳定的问题，实现了时空一致性优化。


<details>
  <summary>Details</summary>
Motivation: 半监督高光谱图像分类在特征提取和分类性能方面取得了显著进展，但由于标注成本高和样本有限，仍然面临边界标签扩散和伪标签不稳定的挑战。

Method: 该论文设计了边缘感知超像素标签传播（EASLP）模块，通过边缘强度惩罚和邻域校正策略来减轻标签扩散。同时，提出了动态历史融合预测（DHP）方法，通过历史预测和当前结果动态加权来平滑伪标签波动。此外，还引入了自适应三元样本分类（ATSC）策略，根据置信度和一致性措施对样本进行分层利用。EASLP、DHP和ATSC协同工作，构成动态可靠性增强伪标签框架（DREPL）。

Result: 在四个基准数据集上的评估表明，该框架能够保持优越的分类性能。

Conclusion: 所提出的DREPL框架有效地解决了半监督高光谱图像分类中的边界标签扩散和伪标签不稳定性问题，通过集成空间先验信息和动态学习机制，实现了时空一致性优化，并取得了优异的分类效果。

Abstract: Significant progress has been made in semi-supervised hyperspectral image (HSI) classification regarding feature extraction and classification performance. However, due to high annotation costs and limited sample availability, semi-supervised learning still faces challenges such as boundary label diffusion and pseudo-label instability. To address these issues, this paper proposes a novel semi-supervised hyperspectral classification framework integrating spatial prior information with a dynamic learning mechanism. First, we design an Edge-Aware Superpixel Label Propagation (EASLP) module. By integrating edge intensity penalty with neighborhood correction strategy, it mitigates label diffusion from superpixel segmentation while enhancing classification robustness in boundary regions. Second, we introduce a Dynamic History-Fused Prediction (DHP) method. By maintaining historical predictions and dynamically weighting them with current results, DHP smoothens pseudo-label fluctuations and improves temporal consistency and noise resistance. Concurrently, incorporating condifence and consistency measures, the Adaptive Tripartite Sample Categorization (ATSC) strategy implements hierarchical utilization of easy, ambiguous, and hard samples, leading to enhanced pseudo-label quality and learning efficiency. The Dynamic Reliability-Enhanced Pseudo-Label Framework (DREPL), composed of DHP and ATSC, strengthens pseudo-label stability across temporal and sample domains. Through synergizes operation with EASLP, it achieves spatio-temporal consistency optimization. Evaluations on four benchmark datasets demonstrate its capability to maintain superior classification performance.

</details>


### [183] [Cross-Domain Transfer with Self-Supervised Spectral-Spatial Modeling for Hyperspectral Image Classification](https://arxiv.org/abs/2601.18088)
*Jianshu Chao,Tianhua Lv,Qiqiong Ma,Yunfei Qiu,Li Fang,Huifang Shen,Wei Yao*

Main category: cs.CV

TL;DR: 提出了一种无需源域标签的自监督跨域迁移框架，通过S2Former和FDC进行预训练，再利用DAFT进行少样本微调，实现了对高光谱数据的有效跨域迁移和分类。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法在高光谱表示方面潜力巨大，但在跨域迁移方面探索不足，且依赖源域标注，易受分布偏移影响，导致目标域泛化性能下降。

Method: 提出了一种自监督跨域迁移框架。在预训练阶段，设计了空间-谱Transformer (S2Former) 模块，包含双分支Transformer和双向交叉注意力机制，用于联合建模光谱和空间信息，并引入频率域约束 (FDC) 来保持频率域一致性。在微调阶段，提出扩散对齐微调 (DAFT) 蒸馏机制，通过师生结构对齐语义演化轨迹，实现少样本下的鲁棒迁移学习。

Result: 在四个高光谱数据集上进行了实验，结果表明该方法在分类性能上表现稳定，并具有强大的跨域适应能力，尤其是在资源受限的条件下。

Conclusion: 该自监督跨域迁移框架无需源域标签，能够学习可迁移的光谱-空间联合表示，并通过DAFT在少样本条件下实现高效适应，有效解决了高光谱数据跨域迁移的挑战。

Abstract: Self-supervised learning has demonstrated considerable potential in hyperspectral representation, yet its application in cross-domain transfer scenarios remains under-explored. Existing methods, however, still rely on source domain annotations and are susceptible to distribution shifts, leading to degraded generalization performance in the target domain. To address this, this paper proposes a self-supervised cross-domain transfer framework that learns transferable spectral-spatial joint representations without source labels and achieves efficient adaptation under few samples in the target domain. During the self-supervised pre-training phase, a Spatial-Spectral Transformer (S2Former) module is designed. It adopts a dual-branch spatial-spectral transformer and introduces a bidirectional cross-attention mechanism to achieve spectral-spatial collaborative modeling: the spatial branch enhances structural awareness through random masking, while the spectral branch captures fine-grained differences. Both branches mutually guide each other to improve semantic consistency. We further propose a Frequency Domain Constraint (FDC) to maintain frequency-domain consistency through real Fast Fourier Transform (rFFT) and high-frequency magnitude loss, thereby enhancing the model's capability to discern fine details and boundaries. During the fine-tuning phase, we introduce a Diffusion-Aligned Fine-tuning (DAFT) distillation mechanism. This aligns semantic evolution trajectories through a teacher-student structure, enabling robust transfer learning under low-label conditions. Experimental results demonstrate stable classification performance and strong cross-domain adaptability across four hyperspectral datasets, validating the method's effectiveness under resource-constrained conditions.

</details>


### [184] [Text-Pass Filter: An Efficient Scene Text Detector](https://arxiv.org/abs/2601.18098)
*Chuang Yang,Haozhao Ma,Xu Han,Yuan Yuan,Qi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Text-Pass Filter (TPF) 的新型任意形状文本检测方法，通过直接分割整个文本区域来克服现有方法的局限性。TPF通过模拟带通滤波器的原理，为每个文本构建独特的特征-滤波器对，实现文本分离。此外，引入了强化集锦单元(REU)解决长宽比问题，以及前景先验单元(FPU)提升前景背景区分度。实验证明了REU和FPU的有效性以及TPF的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有文本检测方法采用收缩-扩张策略，收缩操作丢失了文本边缘的视觉特征并混淆了前景和背景的差异，这给识别文本特征带来了固有的局限性。作者旨在解决这一问题，提出一种更有效的方法。

Method: 本文提出Text-Pass Filter (TPF)方法，直接分割整个文本区域。TPF通过模拟带通滤波器的原理，为每个文本构建独特的特征-滤波器对，在推理阶段，每个滤波器通过其通带特征提取匹配的文本，并抑制其他特征。此外，引入了强化集锦单元(REU)来增强同一文本的特征一致性并扩大滤波器的识别范围，以解决长宽比问题。同时，引入了前景先验单元(FPU)来鼓励TPF区分前景和背景。

Result: 实验结果表明，REU和FPU的引入有效提升了TPF的性能，并且TPF在任意形状文本检测任务上表现出优越性。TPF能够自然地分离粘连文本，无需复杂的解码或后处理过程，使得实时文本检测成为可能。

Conclusion: TPF是一种有效且新颖的任意形状文本检测方法，它通过直接分割整个文本区域并模拟带通滤波器的原理，克服了现有方法的局限性。REU和FPU的引入进一步增强了模型的鲁棒性和性能，使其能够处理复杂场景下的文本检测问题，并支持实时应用。

Abstract: To pursue an efficient text assembling process, existing methods detect texts via the shrink-mask expansion strategy. However, the shrinking operation loses the visual features of text margins and confuses the foreground and background difference, which brings intrinsic limitations to recognize text features. We follow this issue and design Text-Pass Filter (TPF) for arbitrary-shaped text detection. It segments the whole text directly, which avoids the intrinsic limitations. It is noteworthy that different from previous whole text region-based methods, TPF can separate adhesive texts naturally without complex decoding or post-processing processes, which makes it possible for real-time text detection. Concretely, we find that the band-pass filter allows through components in a specified band of frequencies, called its passband but blocks components with frequencies above or below this band. It provides a natural idea for extracting whole texts separately. By simulating the band-pass filter, TPF constructs a unique feature-filter pair for each text. In the inference stage, every filter extracts the corresponding matched text by passing its pass-feature and blocking other features. Meanwhile, considering the large aspect ratio problem of ribbon-like texts makes it hard to recognize texts wholly, a Reinforcement Ensemble Unit (REU) is designed to enhance the feature consistency of the same text and to enlarge the filter's recognition field to help recognize whole texts. Furthermore, a Foreground Prior Unit (FPU) is introduced to encourage TPF to discriminate the difference between the foreground and background, which improves the feature-filter pair quality. Experiments demonstrate the effectiveness of REU and FPU while showing the TPF's superiority.

</details>


### [185] [Computational Framework for Estimating Relative Gaussian Blur Kernels between Image Pairs](https://arxiv.org/abs/2601.18099)
*Akbar Saadat*

Main category: cs.CV

TL;DR: 该论文提出了一种用于高斯模型的零训练前向计算框架，通过离散化分析解来实时处理模糊图像，并在合成模糊值估计和模糊滤波应用中实现了低误差。


<details>
  <summary>Details</summary>
Motivation: 为了实现高斯模型的实时应用，需要一个零训练的前向计算框架来处理模糊图像。

Method: 该框架基于对高斯核标准差应用范围内的散焦图像解析表达式进行离散计算，并选择最佳匹配。解析解在某些图像点会产生多个解，通过邻域点的相似度度量过滤到单一解。该框架还能处理两张图像互为部分模糊版本的情况。

Result: 实验结果表明，该框架在估计合成模糊值时实现了低于1.7%的平均绝对误差（MAE）。将提取的散焦滤波器应用于模糊度较低的图像时，实际模糊图像强度与其对应估计值之间的差异保持在2%以下。

Conclusion: 提出的零训练前向计算框架能够有效地实时处理高斯模型模糊图像，并在合成模糊估计和模糊滤波方面取得了令人满意的精度。

Abstract: Following the earlier verification for Gaussian model in \cite{ASaa2026}, this paper introduces a zero training forward computational framework for the model to realize it in real time applications. The framework is based on discrete calculation of the analytic expression of the defocused image from the sharper one for the application range of the standard deviation of the Gaussian kernels and selecting the best matches. The analytic expression yields multiple solutions at certain image points, but is filtered down to a single solution using similarity measures over neighboring points.The framework is structured to handle cases where two given images are partial blurred versions of each other. Experimental evaluations on real images demonstrate that the proposed framework achieves a mean absolute error (MAE) below $1.7\%$ in estimating synthetic blur values. Furthermore, the discrepancy between actual blurred image intensities and their corresponding estimates remains under $2\%$, obtained by applying the extracted defocus filters to less blurred images.

</details>


### [186] [Spatial-Conditioned Reasoning in Long-Egocentric Videos](https://arxiv.org/abs/2601.18100)
*James Tribble,Hao Wang,Si-En Hong,Chaoyi Zhou,Ashish Bastola,Siyu Huang,Abolfazl Razi*

Main category: cs.CV

TL;DR: 研究通过引入精细标注的Sanpo-D数据集和融合深度图，探讨显式空间信号如何增强视觉语言模型（VLM）在长时域自主视频理解和导航任务中的空间推理能力，尤其是在行人检测和障碍物检测等安全关键任务上。


<details>
  <summary>Details</summary>
Motivation: 长时域自主视频在视觉导航中存在视角漂移和几何上下文缺失的问题。尽管现有的视觉语言模型在图像和短视频理解上表现良好，但其在长自主视频序列中的空间推理能力有限。因此，研究旨在探索如何通过显式空间信号来提升VLM的空间推理能力，而不改变模型结构或推理过程。

Method: 1. 创建Sanpo-D数据集，对Google Sanpo数据集进行精细的空间标注。2. 评估多个VLM在导航导向的空间查询任务上的表现。3. 通过融合RGB帧和深度图，探究输入层面的归纳偏置对空间推理的影响。

Result: 结果表明，通用准确性和空间专业性之间存在权衡。深度感知和空间约束的表示能够提升在行人检测和障碍物检测等安全关键任务上的性能。

Conclusion: 显式空间信号（如精细标注和深度信息）的引入，能够有效提升VLM在长时域自主视频理解和导航任务中的空间推理能力，尤其是在需要高精度的安全相关场景下。

Abstract: Long-horizon egocentric video presents significant challenges for visual navigation due to viewpoint drift and the absence of persistent geometric context. Although recent vision-language models perform well on image and short-video reasoning, their spatial reasoning capability in long egocentric sequences remains limited. In this work, we study how explicit spatial signals influence VLM-based video understanding without modifying model architectures or inference procedures. We introduce Sanpo-D, a fine-grained re-annotation of the Google Sanpo dataset, and benchmark multiple VLMs on navigation-oriented spatial queries. To examine input-level inductive bias, we further fuse depth maps with RGB frames and evaluate their impact on spatial reasoning. Our results reveal a trade-off between general-purpose accuracy and spatial specialization, showing that depth-aware and spatially grounded representations can improve performance on safety-critical tasks such as pedestrian and obstruction detection.

</details>


### [187] [UPLiFT: Efficient Pixel-Dense Feature Upsampling with Local Attenders](https://arxiv.org/abs/2601.17950)
*Matthew Walmer,Saksham Suri,Anirud Aggarwal,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 本文提出了一种名为 UPLiFT 的新架构，用于高效地将预训练视觉骨干的稀疏特征转换为密集特征，该架构通过一种新颖的局部注意力算子克服了先前迭代上采样方法的局限性，并在效率和性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有任务无关特征上采样方法要么采用迭代上采样，要么采用基于交叉注意力的模型。后者可能面临与骨干网络相似的效率扩展问题，而前者可能不如后者。研究者希望找到一种能够与基于交叉注意力的模型竞争，同时保持更低推理成本的迭代上采样方法。

Method: 提出了一种名为 UPLiFT (Universal Pixel-dense Lightweight Feature Transforms) 的新架构。UPLiFT 包含一个高效的局部注意力算子，该算子使用一种完全局部的替代性注意力池化公式，以克服现有迭代特征上采样方法的限制。UPLiFT 被设计用于在整个上采样过程中保持特征的稳定性。

Result: UPLiFT 能够实现最先进的性能，并且比现有的像素密集特征上采样器具有更低的推理成本。在生成式下游任务（如 VAE 特征上采样）的应用中，UPLiFT 取得了与最先进的 Coupled Flow Matching 模型相当的性能。

Conclusion: UPLiFT 提供了一种通用且高效的方法来创建更密集的特征，并且可以通过其新颖的局部注意力算子在保持高性能的同时降低推理成本，证明了迭代上采样方法仍然具有竞争力。

Abstract: The space of task-agnostic feature upsampling has emerged as a promising area of research to efficiently create denser features from pre-trained visual backbones. These methods act as a shortcut to achieve dense features for a fraction of the cost by learning to map low-resolution features to high-resolution versions. While early works in this space used iterative upsampling approaches, more recent works have switched to cross-attention-based methods, which risk falling into the same efficiency scaling problems of the backbones they are upsampling. In this work, we demonstrate that iterative upsampling methods can still compete with cross-attention-based methods; moreover, they can achieve state-of-the-art performance with lower inference costs. We propose UPLiFT, an architecture for Universal Pixel-dense Lightweight Feature Transforms. We also propose an efficient Local Attender operator to overcome the limitations of prior iterative feature upsampling methods. This operator uses an alternative attentional pooling formulation defined fully locally. We show that our Local Attender allows UPLiFT to maintain stable features throughout upsampling, enabling state-of-the-art performance with lower inference costs than existing pixel-dense feature upsamplers. In addition, we apply UPLiFT to generative downstream tasks and show that it achieves competitive performance with state-of-the-art Coupled Flow Matching models for VAE feature upsampling. Altogether, UPLiFT offers a versatile and efficient approach to creating denser features.

</details>


### [188] [Forward Consistency Learning with Gated Context Aggregation for Video Anomaly Detection](https://arxiv.org/abs/2601.18135)
*Jiahao Lyu,Minghua Zhao,Xuewen Huang,Yifei Chen,Shuangli Du,Jing Hu,Cheng Shi,Zhiyong Lv*

Main category: cs.CV

TL;DR: 本文提出了一种名为FoGA的轻量级视频异常检测模型，该模型参数量仅200万，专为资源受限的边缘设备设计。FoGA通过Unet架构生成即时和前向预测，并利用门控上下文聚合模块融合编码器和解码器特征，最后结合新颖的前向一致性损失和混合异常度量策略实现高效准确的异常检测，速度可达155 FPS。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常检测方法通常依赖于大型模型追求高精度，导致其难以在资源有限的边缘设备上部署。同时，主流的基于预测的方法仅利用单帧未来预测误差，忽略了更长时序前向信息的约束。

Method: 提出FoGA模型，采用Unet架构进行特征提取，生成即时和前向预测。引入门控上下文聚合模块到跳跃连接中，动态融合相同空间尺度的编码器和解码器特征。模型通过新颖的前向一致性损失进行联合优化，并采用混合异常度量策略整合即时和前向帧的误差。

Result: FoGA模型参数量约为200万，在实验中表现出优越的性能，显著优于现有最先进的方法，检测速度可达155 FPS，实现了性能和效率的良好权衡。

Conclusion: FoGA模型成功地为资源受限的边缘设备提供了一种高效且准确的视频异常检测解决方案，通过轻量级设计和创新的前向一致性学习与门控上下文聚合机制，克服了传统方法的局限性。

Abstract: As a crucial element of public security, video anomaly detection (VAD) aims to measure deviations from normal patterns for various events in real-time surveillance systems. However, most existing VAD methods rely on large-scale models to pursue extreme accuracy, limiting their feasibility on resource-limited edge devices. Moreover, mainstream prediction-based VAD detects anomalies using only single-frame future prediction errors, overlooking the richer constraints from longer-term temporal forward information. In this paper, we introduce FoGA, a lightweight VAD model that performs Forward consistency learning with Gated context Aggregation, containing about 2M parameters and tailored for potential edge devices. Specifically, we propose a Unet-based method that performs feature extraction on consecutive frames to generate both immediate and forward predictions. Then, we introduce a gated context aggregation module into the skip connections to dynamically fuse encoder and decoder features at the same spatial scale. Finally, the model is jointly optimized with a novel forward consistency loss, and a hybrid anomaly measurement strategy is adopted to integrate errors from both immediate and forward frames for more accurate detection. Extensive experiments demonstrate the effectiveness of the proposed method, which substantially outperforms state-of-the-art competing methods, running up to 155 FPS. Hence, our FoGA achieves an excellent trade-off between performance and the efficiency metric.

</details>


### [189] [Agentic Very Long Video Understanding](https://arxiv.org/abs/2601.18157)
*Aniket Rege,Arka Sadhu,Yuliang Li,Kejie Li,Ramya Korlakai Vinayak,Yuning Chai,Yong Jae Lee,Hyo Jin Kim*

Main category: cs.CV

TL;DR: EGAgent是一个增强型代理框架，通过实体场景图和混合跨模态搜索能力，实现了对连续、长期的个体中心视频的理解和推理，在EgoLifeQA和Video-MME (Long) 数据集上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的AI助手和视频理解方法难以处理跨越数天甚至数周的长期、连续的个体中心视频数据，它们受限于有限的上下文窗口和多步推理能力，无法满足全天候可穿戴设备带来的上下文理解需求。

Method: 提出EGAgent框架，核心是实体场景图（表示人、地点、物体及其随时间的关系）。该框架为规划代理配备了结构化搜索和推理工具，以及混合视觉和音频搜索能力，以实现详细、跨模态和时间连贯的推理。

Result: 在EgoLifeQA数据集上，EGAgent达到了57.5%的先进性能。在Video-MME (Long) 数据集上，也取得了74.1%的竞争力性能，证明了其在复杂长期视频理解任务上的有效性。

Conclusion: EGAgent框架通过实体场景图和增强的搜索推理能力，成功解决了长期个体中心视频理解中的挑战，并在相关数据集上展现出优越的性能，为实现更强大的AI助手提供了可能。

Abstract: The advent of always-on personal AI assistants, enabled by all-day wearable devices such as smart glasses, demands a new level of contextual understanding, one that goes beyond short, isolated events to encompass the continuous, longitudinal stream of egocentric video. Achieving this vision requires advances in long-horizon video understanding, where systems must interpret and recall visual and audio information spanning days or even weeks. Existing methods, including large language models and retrieval-augmented generation, are constrained by limited context windows and lack the ability to perform compositional, multi-hop reasoning over very long video streams. In this work, we address these challenges through EGAgent, an enhanced agentic framework centered on entity scene graphs, which represent people, places, objects, and their relationships over time. Our system equips a planning agent with tools for structured search and reasoning over these graphs, as well as hybrid visual and audio search capabilities, enabling detailed, cross-modal, and temporally coherent reasoning. Experiments on the EgoLifeQA and Video-MME (Long) datasets show that our method achieves state-of-the-art performance on EgoLifeQA (57.5%) and competitive performance on Video-MME (Long) (74.1%) for complex longitudinal video understanding tasks.

</details>


### [190] [TempDiffReg: Temporal Diffusion Model for Non-Rigid 2D-3D Vascular Registration](https://arxiv.org/abs/2601.18168)
*Zehua Liu,Shihao Zou,Jincai Huang,Yanfang Zhang,Chao Tong,Weixin Si*

Main category: cs.CV

TL;DR: 提出了一种用于肝癌介入治疗（TACE）的2D-3D血管配准新方法，结合全局对齐和基于时间扩散模型的局部精细配准，显著提高了配准精度和解剖学合理性。


<details>
  <summary>Details</summary>
Motivation: TACE治疗肝癌等肝脏恶性肿瘤是首选方案，但术中血管导航复杂且存在个体解剖差异，导致操作困难。精确可靠的2D-3D血管配准对于引导微导管和器械、实现精准定位和靶向治疗至关重要。

Method: 开发了一种粗到精的配准策略。首先，使用结构感知透视n点（SA-PnP）方法进行全局对齐，建立2D和3D血管结构的对应关系。其次，提出了一种名为TempDiffReg的时间扩散模型，通过利用时间上下文迭代地对血管进行变形，以捕捉复杂的解剖变异和局部的结构变化。

Result: 在23名患者收集的626个多帧样本上进行评估，结果表明所提出的方法在精度和解剖学合理性方面均优于现有最先进（SOTA）的方法。具体而言，在配准精度方面，方法的均方误差（MSE）为0.63 mm，平均绝对误差（MAE）为0.51 mm，相比最有竞争力的现有方法，MSE降低了66.7%，MAE降低了17.7%。

Conclusion: 所提出的TempDiffReg方法能够有效解决TACE手术中的2D-3D血管配准难题，具有提升配准精度和解剖学合理性的潜力，可辅助临床医生更安全高效地完成复杂TACE手术，最终改善手术效果和患者护理。

Abstract: Transarterial chemoembolization (TACE) is a preferred treatment option for hepatocellular carcinoma and other liver malignancies, yet it remains a highly challenging procedure due to complex intra-operative vascular navigation and anatomical variability. Accurate and robust 2D-3D vessel registration is essential to guide microcatheter and instruments during TACE, enabling precise localization of vascular structures and optimal therapeutic targeting. To tackle this issue, we develop a coarse-to-fine registration strategy. First, we introduce a global alignment module, structure-aware perspective n-point (SA-PnP), to establish correspondence between 2D and 3D vessel structures. Second, we propose TempDiffReg, a temporal diffusion model that performs vessel deformation iteratively by leveraging temporal context to capture complex anatomical variations and local structural changes. We collected data from 23 patients and constructed 626 paired multi-frame samples for comprehensive evaluation. Experimental results demonstrate that the proposed method consistently outperforms state-of-the-art (SOTA) methods in both accuracy and anatomical plausibility. Specifically, our method achieves a mean squared error (MSE) of 0.63 mm and a mean absolute error (MAE) of 0.51 mm in registration accuracy, representing 66.7\% lower MSE and 17.7\% lower MAE compared to the most competitive existing approaches. It has the potential to assist less-experienced clinicians in safely and efficiently performing complex TACE procedures, ultimately enhancing both surgical outcomes and patient care. Code and data are available at: \textcolor{blue}{https://github.com/LZH970328/TempDiffReg.git}

</details>


### [191] [Multi-Perspective Subimage CLIP with Keyword Guidance for Remote Sensing Image-Text Retrieval](https://arxiv.org/abs/2601.18190)
*Yifan Li,Shiying Wang,Jianqiang Huang*

Main category: cs.CV

TL;DR: 提出了一种名为MPS-CLIP的参数高效视觉-语言预训练框架，用于遥感图像-文本检索（RSITR），通过LLM提取关键词，引导SAM生成语义相关的子视角，并使用G^2A适配器和MPR模块实现细粒度对齐，在RSICD和RSITMD数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RSITR方法主要依赖粗粒度的全局对齐，忽略了遥感图像固有的多尺度语义；完全微调大型VLP模型计算成本高昂且易发生灾难性遗忘。

Method: 利用LLM提取核心语义关键词，引导SamGeo生成语义相关的子视角（Segment Anything Model for Geo-spatial data）。引入Gated Global Attention (G^2A) 适配器，以参数高效的方式捕获全局上下文。提出Multi-Perspective Representation (MPR) 模块聚合局部线索。采用结合多视角对比损失和加权三元组损失的混合目标函数进行优化。

Result: 在RSICD和RSITMD数据集上，MPS-CLIP分别取得了35.18%和48.40%的平均召回率（mR），显著优于完全微调基线和其他近期方法，达到了最先进的性能。

Conclusion: MPS-CLIP成功地将RSITR的范式从全局匹配转向关键词引导的细粒度对齐，实现了参数高效且性能卓越的遥感图像-文本检索。

Abstract: Vision-Language Pre-training (VLP) models like CLIP have significantly advanced Remote Sensing Image-Text Retrieval (RSITR). However, existing methods predominantly rely on coarse-grained global alignment, which often overlooks the dense, multi-scale semantics inherent in overhead imagery. Moreover, adapting these heavy models via full fine-tuning incurs prohibitive computational costs and risks catastrophic forgetting. To address these challenges, we propose MPS-CLIP, a parameter-efficient framework designed to shift the retrieval paradigm from global matching to keyword-guided fine-grained alignment. Specifically, we leverage a Large Language Model (LLM) to extract core semantic keywords, guiding the Segment Anything Model (SamGeo) to generate semantically relevant sub-perspectives. To efficiently adapt the frozen backbone, we introduce a Gated Global Attention (G^2A) adapter, which captures global context and long-range dependencies with minimal overhead. Furthermore, a Multi-Perspective Representation (MPR) module aggregates these local cues into robust multi-perspective embeddings. The framework is optimized via a hybrid objective combining multi-perspective contrastive and weighted triplet losses, which dynamically selects maximum-response perspectives to suppress noise and enforce precise semantic matching. Extensive experiments on the RSICD and RSITMD benchmarks demonstrate that MPS-CLIP achieves state-of-the-art performance with 35.18% and 48.40% mean Recall (mR), respectively, significantly outperforming full fine-tuning baselines and recent competitive methods. Code is available at https://github.com/Lcrucial1f/MPS-CLIP.

</details>


### [192] [YOLO-DS: Fine-Grained Feature Decoupling via Dual-Statistic Synergy Operator for Object Detection](https://arxiv.org/abs/2601.18172)
*Lin Huang,Yujuan Tan,Weisheng Li,Shitai Shan,Liu Liu,Bo Liu,Linlin Shen,Jing Yu,Yue Niu*

Main category: cs.CV

TL;DR: 提出了一种名为YOLO-DS的新型单阶段目标检测框架，通过引入双统计协同算子（DSO）来显式建模共享特征通道中异质目标响应，从而提高检测性能，并在MS-COCO数据集上取得了优于YOLOv8的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的YOLO检测器在共享特征通道中缺乏对异质目标响应的显式建模，这限制了性能的进一步提升。

Method: 提出了一种双统计协同算子（DSO），它通过联合建模通道均值和峰均差来解耦目标特征。在此基础上，设计了两个轻量级门控模块：用于自适应通道特征选择的双统计协同门控（DSG）模块，以及用于深度特征加权的多路径分段门控（MSG）模块。

Result: 在MS-COCO基准测试中，YOLO-DS在五个模型尺度（N、S、M、L、X）上均优于YOLOv8，AP提升了1.1%至1.7%，且推理延迟仅有微小增加。

Conclusion: YOLO-DS通过显式建模异质目标响应，能够更有效地辨别不同目标，同时保持高效的推理速度，验证了该方法的有效性。

Abstract: One-stage object detection, particularly the YOLO series, strikes a favorable balance between accuracy and efficiency. However, existing YOLO detectors lack explicit modeling of heterogeneous object responses within shared feature channels, which limits further performance gains. To address this, we propose YOLO-DS, a framework built around a novel Dual-Statistic Synergy Operator (DSO). The DSO decouples object features by jointly modeling the channel-wise mean and the peak-to-mean difference. Building upon the DSO, we design two lightweight gating modules: the Dual-Statistic Synergy Gating (DSG) module for adaptive channel-wise feature selection, and the Multi-Path Segmented Gating (MSG) module for depth-wise feature weighting. On the MS-COCO benchmark, YOLO-DS consistently outperforms YOLOv8 across five model scales (N, S, M, L, X), achieving AP gains of 1.1% to 1.7% with only a minimal increase in inference latency. Extensive visualization, ablation, and comparative studies validate the effectiveness of our approach, demonstrating its superior capability in discriminating heterogeneous objects with high efficiency.

</details>


### [193] [MindCine: Multimodal EEG-to-Video Reconstruction with Large-Scale Pretrained Models](https://arxiv.org/abs/2601.18192)
*Tian-Yi Zhou,Xuan-Hao Liu,Bao-Liang Lu,Wei-Long Zheng*

Main category: cs.CV

TL;DR: 提出了一种名为MindCine的新型框架，通过多模态联合学习和预训练大型EEG模型来解决EEG到视频重建中的单模态和数据稀疏性问题，并在有限数据下实现了高保真视频重建，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有EEG到视频重建方法仅依赖文本模态，容易过拟合且在有限数据下难以训练收敛。因此，需要一种能够利用多模态信息并缓解数据稀疏性问题的框架。

Method: 采用多模态联合学习策略，整合文本以外的模态；利用预训练的大型EEG模型来缓解数据稀疏问题，用于解码语义信息；设计了带有因果注意力的Seq2Seq模型，用于解码感知信息。

Result: MindCine在有限数据下实现了高保真视频重建，并在定性和定量评估中均优于最先进的方法。多模态信息的互补性以及大型EEG模型的应用有效提升了重建性能，缓解了数据不足的挑战。

Conclusion: MindCine框架通过引入多模态学习和利用预训练的EEG模型，成功解决了EEG到视频重建中的单模态和数据稀缺问题，证明了多模态信息和大型预训练模型的有效性。

Abstract: Reconstructing human dynamic visual perception from electroencephalography (EEG) signals is of great research significance since EEG's non-invasiveness and high temporal resolution. However, EEG-to-video reconstruction remains challenging due to: 1) Single Modality: existing studies solely align EEG signals with the text modality, which ignores other modalities and are prone to suffer from overfitting problems; 2) Data Scarcity: current methods often have difficulty training to converge with limited EEG-video data. To solve the above problems, we propose a novel framework MindCine to achieve high-fidelity video reconstructions on limited data. We employ a multimodal joint learning strategy to incorporate beyond-text modalities in the training stage and leverage a pre-trained large EEG model to relieve the data scarcity issue for decoding semantic information, while a Seq2Seq model with causal attention is specifically designed for decoding perceptual information. Extensive experiments demonstrate that our model outperforms state-of-the-art methods both qualitatively and quantitatively. Additionally, the results underscore the effectiveness of the complementary strengths of different modalities and demonstrate that leveraging a large-scale EEG model can further enhance reconstruction performance by alleviating the challenges associated with limited data.

</details>


### [194] [HomoFM: Deep Homography Estimation with Flow Matching](https://arxiv.org/abs/2601.18222)
*Mengfan He,Liangzheng Sun,Chunyu Li,Ziyang Meng*

Main category: cs.CV

TL;DR: 本文提出了一种名为HomoFM的新框架，首次将生成模型中的流匹配技术应用于单应性估计，将问题转化为学习速度场，并通过梯度逆转层增强了模型在域迁移情况下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有单应性估计方法在处理复杂几何变换和跨领域泛化能力方面存在不足，尤其是在多模态匹配或光照变化等域偏移场景下表现不佳。

Method: 提出HomoFM框架，将单应性估计视为速度场学习问题。通过建模一个连续的点状速度场，将噪声分布映射到配准坐标，并利用条件流轨迹恢复高精度变换。引入梯度逆转层（GRL）到特征提取主干，实现域自适应，学习域不变表示，提高模型鲁棒性。

Result: HomoFM在标准基准测试中，在估计精度和鲁棒性方面均优于现有最先进方法。

Conclusion: HomoFM框架通过引入流匹配和梯度逆转层，有效解决了单应性估计中的复杂几何变换和域迁移问题，显著提升了方法的准确性和鲁棒性。

Abstract: Deep homography estimation has broad applications in computer vision and robotics. Remarkable progresses have been achieved while the existing methods typically treat it as a direct regression or iterative refinement problem and often struggling to capture complex geometric transformations or generalize across different domains. In this work, we propose HomoFM, a new framework that introduces the flow matching technique from generative modeling into the homography estimation task for the first time. Unlike the existing methods, we formulate homography estimation problem as a velocity field learning problem. By modeling a continuous and point-wise velocity field that transforms noisy distributions into registered coordinates, the proposed network recovers high-precision transformations through a conditional flow trajectory. Furthermore, to address the challenge of domain shifts issue, e.g., the cases of multimodal matching or varying illumination scenarios, we integrate a gradient reversal layer (GRL) into the feature extraction backbone. This domain adaptation strategy explicitly constrains the encoder to learn domain-invariant representations, significantly enhancing the network's robustness. Extensive experiments demonstrate the effectiveness of the proposed method, showing that HomoFM outperforms state-of-the-art methods in both estimation accuracy and robustness on standard benchmarks. Code and data resource are available at https://github.com/hmf21/HomoFM.

</details>


### [195] [QualiRAG: Retrieval-Augmented Generation for Visual Quality Understanding](https://arxiv.org/abs/2601.18195)
*Linhan Cao,Wei Sun,Weixia Zhang,Xiangyang Zhu,Kaiwei Zhang,Jun Jia,Dandan Zhu,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: 本文提出了一种名为QualiRAG的无训练方法，通过检索增强生成（RAG）框架，利用大型多模态模型（LMM）的潜在感知知识进行视觉质量评估。QualiRAG通过分解问题、构建多维度知识源并进行相关性检索，克服了传统监督学习和强化学习方法的局限性，并在视觉质量理解和比较任务上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 当前视觉质量评估（VQA）正从单一评分预测转向更具解释性的质量理解，这需要精细的时空感知和辅助上下文信息。现有的方法依赖于劳动密集型的标注和有数据集偏差的监督微调或强化学习，因此需要一种无需训练且能系统性利用LMM感知知识的方法。

Method: QualiRAG是一个无训练的检索增强生成（RAG）框架。它通过将问题分解为结构化请求，动态生成四个互补的知识源：视觉元数据、主体定位、全局质量摘要和局部质量描述。然后，它进行相关性检索，以证据为基础进行推理，从而利用LMM的潜在感知知识。

Result: QualiRAG在视觉质量理解任务上显著优于开源的通用LMM和经过VQA微调的LMM。在视觉质量比较任务上，QualiRAG也取得了具有竞争力的性能，展示了其强大的、无需任务特定训练的质量评估能力。

Conclusion: QualiRAG成功地利用大型多模态模型的潜在感知知识，为视觉质量评估提供了一种无需训练的、可解释的解决方案。该方法通过动态生成和检索辅助知识，克服了传统方法的缺点，并在多项视觉质量评估任务中展现出优越的性能。

Abstract: Visual quality assessment (VQA) is increasingly shifting from scalar score prediction toward interpretable quality understanding -- a paradigm that demands \textit{fine-grained spatiotemporal perception} and \textit{auxiliary contextual information}. Current approaches rely on supervised fine-tuning or reinforcement learning on curated instruction datasets, which involve labor-intensive annotation and are prone to dataset-specific biases. To address these challenges, we propose \textbf{QualiRAG}, a \textit{training-free} \textbf{R}etrieval-\textbf{A}ugmented \textbf{G}eneration \textbf{(RAG)} framework that systematically leverages the latent perceptual knowledge of large multimodal models (LMMs) for visual quality perception. Unlike conventional RAG that retrieves from static corpora, QualiRAG dynamically generates auxiliary knowledge by decomposing questions into structured requests and constructing four complementary knowledge sources: \textit{visual metadata}, \textit{subject localization}, \textit{global quality summaries}, and \textit{local quality descriptions}, followed by relevance-aware retrieval for evidence-grounded reasoning. Extensive experiments show that QualiRAG achieves substantial improvements over open-source general-purpose LMMs and VQA-finetuned LMMs on visual quality understanding tasks, and delivers competitive performance on visual quality comparison tasks, demonstrating robust quality assessment capabilities without any task-specific training. The code will be publicly available at https://github.com/clh124/QualiRAG.

</details>


### [196] [Facial Emotion Recognition on FER-2013 using an EfficientNetB2-Based Approach](https://arxiv.org/abs/2601.18228)
*Sahil Naik,Soham Bagayatkar,Pavankumar Singh*

Main category: cs.CV

TL;DR: 研究提出了一种基于EfficientNetB2的轻量级人脸情绪识别模型，通过多项优化策略（如AdamW、标签平滑、类别权重调整、混合精度训练等）在FER-2013数据集上取得了68.78%的测试准确率，同时参数量远少于VGG16，适用于实时和边缘应用。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸情绪识别方法在真实场景下面临图像质量差、光照变化、姿态、背景干扰、类别间差异小、标注噪声和类别不平衡等挑战。基于大型CNN（如VGG、ResNet）的模型虽然准确率尚可，但计算和内存开销大，不适合实时应用。

Method: 采用EfficientNetB2作为基础模型，结合两阶段预训练-微调策略。关键优化技术包括：AdamW优化器、解耦权重衰减、标签平滑（epsilon=0.06）处理标注噪声、裁剪类别权重缓解类别不平衡、Dropout、混合精度训练以及广泛的实时数据增强。训练时采用87.5%/12.5%的层化划分训练-验证集，保留官方测试集。

Result: 在FER-2013数据集上，该模型实现了68.78%的测试准确率，参数量相比VGG16基线模型减少了近十倍。实验结果（包括类别指标和学习动态）表明模型训练稳定且泛化能力强。

Conclusion: 提出的轻量级人脸情绪识别方法通过多种优化技术，在处理真实场景下的挑战方面表现出色，并能实现高效的实时和边缘计算部署。

Abstract: Detection of human emotions based on facial images in real-world scenarios is a difficult task due to low image quality, variations in lighting, pose changes, background distractions, small inter-class variations, noisy crowd-sourced labels, and severe class imbalance, as observed in the FER-2013 dataset of 48x48 grayscale images. Although recent approaches using large CNNs such as VGG and ResNet achieve reasonable accuracy, they are computationally expensive and memory-intensive, limiting their practicality for real-time applications. We address these challenges using a lightweight and efficient facial emotion recognition pipeline based on EfficientNetB2, trained using a two-stage warm-up and fine-tuning strategy. The model is enhanced with AdamW optimization, decoupled weight decay, label smoothing (epsilon = 0.06) to reduce annotation noise, and clipped class weights to mitigate class imbalance, along with dropout, mixed-precision training, and extensive real-time data augmentation. The model is trained using a stratified 87.5%/12.5% train-validation split while keeping the official test set intact, achieving a test accuracy of 68.78% with nearly ten times fewer parameters than VGG16-based baselines. Experimental results, including per-class metrics and learning dynamics, demonstrate stable training and strong generalization, making the proposed approach suitable for real-time and edge-based applications.

</details>


### [197] [Revisiting Aerial Scene Classification on the AID Benchmark](https://arxiv.org/abs/2601.18263)
*Subhajeet Das,Susmita Ghosh,Abhiroop Chatterjee*

Main category: cs.CV

TL;DR: 本研究对用于航空图像分类的机器学习方法进行了文献综述，并提出了一种名为 Aerial-Y-Net 的新型空间注意力增强型卷积神经网络，在 AID 数据集上取得了 91.72% 的准确率。


<details>
  <summary>Details</summary>
Motivation: 航空图像在城市规划和环境保护中至关重要，但其异质性给场景分类带来了挑战。研究旨在为航空图像分类提供更鲁棒的模型。

Method: 对从手工特征到各种卷积神经网络（CNN）和先进的深度混合网络进行了文献综述。设计了一种名为 Aerial-Y-Net 的空间注意力增强型 CNN，具有多尺度特征融合机制。

Result: 所提出的 Aerial-Y-Net 模型在 AID 数据集上实现了 91.72% 的准确率，优于多个基线模型。

Conclusion:  Aerial-Y-Net 是一种有效的航空图像分类模型，其空间注意力和多尺度特征融合机制有助于理解航空图像的复杂性。

Abstract: Aerial images play a vital role in urban planning and environmental preservation, as they consist of various structures, representing different types of buildings, forests, mountains, and unoccupied lands. Due to its heterogeneous nature, developing robust models for scene classification remains a challenge. In this study, we conduct a literature review of various machine learning methods for aerial image classification. Our survey covers a range of approaches from handcrafted features (e.g., SIFT, LBP) to traditional CNNs (e.g., VGG, GoogLeNet), and advanced deep hybrid networks. In this connection, we have also designed Aerial-Y-Net, a spatial attention-enhanced CNN with multi-scale feature fusion mechanism, which acts as an attention-based model and helps us to better understand the complexities of aerial images. Evaluated on the AID dataset, our model achieves 91.72% accuracy, outperforming several baseline architectures.

</details>


### [198] [Depth to Anatomy: Learning Internal Organ Locations from Surface Depth Images](https://arxiv.org/abs/2601.18260)
*Eytan Kats,Kai Geissler,Daniel Mensing,Jochen G. Hirsch,Stefan Heldman,Mattias P. Heinrich*

Main category: cs.CV

TL;DR: 提出一种基于学习的方法，直接从2D深度图像预测多器官的三维位置和形状，以实现自动化患者定位。


<details>
  <summary>Details</summary>
Motivation: 自动化患者定位对于优化扫描流程和提高患者吞吐量至关重要。利用RGB-D相机捕获的深度信息来估计内部器官位置，可以实现更准确高效的定位。

Method: 利用大型全身MRI扫描数据集，合成配对的深度图像和解剖分割图，以训练一个统一的卷积神经网络。该网络直接从2D深度图像预测多个内部器官（包括骨骼和软组织）的三维位置和形状，无需显式表面重建。

Result: 该方法能够准确地定位各种解剖结构。实验结果表明，将深度传感器集成到放射科工作流程中，通过自动化患者定位来简化扫描流程并改善患者体验的潜力。

Conclusion: 提出的学习框架能够从单张2D深度图像直接预测多器官的三维位置和形状，为实现自动化患者定位提供了可行方案，并有望应用于放射科工作流程以提高效率和改善患者体验。

Abstract: Automated patient positioning plays an important role in optimizing scanning procedure and improving patient throughput. Leveraging depth information captured by RGB-D cameras presents a promising approach for estimating internal organ positions, thereby enabling more accurate and efficient positioning. In this work, we propose a learning-based framework that directly predicts the 3D locations and shapes of multiple internal organs from single 2D depth images of the body surface. Utilizing a large-scale dataset of full-body MRI scans, we synthesize depth images paired with corresponding anatomical segmentations to train a unified convolutional neural network architecture. Our method accurately localizes a diverse set of anatomical structures, including bones and soft tissues, without requiring explicit surface reconstruction. Experimental results demonstrate the potential of integrating depth sensors into radiology workflows to streamline scanning procedures and enhance patient experience through automated patient positioning.

</details>


### [199] [V-Loop: Visual Logical Loop Verification for Hallucination Detection in Medical Visual Question Answering](https://arxiv.org/abs/2601.18240)
*Mengyuan Jin,Zehui Liao,Yong Xia*

Main category: cs.CV

TL;DR: 提出了一种名为 V-Loop 的新框架，用于检测医疗视觉问答中 MLLM 的幻觉，该框架通过双向推理形成一个视觉逻辑循环来验证答案的真实性，无需训练即可插入现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前的 MLLMs 在医疗 VQA 中存在幻觉问题，生成的答案可能与图像事实不符，这在医疗领域是危险的。现有的基于不确定性的检测方法计算效率高但不够直接，无法直接验证答案的事实正确性。

Method: V-Loop 框架采用一种无需训练、即插即用的方法。它通过一个双向推理过程来验证答案的真实性：1. MLLM 对输入的医疗图像和问题生成答案。2. 从原始的问答对中提取语义单元。3. 基于答案单元生成一个验证问题，并用此验证问题重新查询原始问题单元。4. 强制视觉注意力一致性，确保回答原始问题和验证问题都依赖于相同的图像证据。5. 如果验证问题的答案与预期语义内容一致，则逻辑循环闭合，表明答案具有事实依据；否则，将原始答案标记为幻觉。

Result: 在多个医疗 VQA 基准和 MLLMs 上进行的大量实验表明，V-Loop 的幻觉检测效果始终优于现有的内省方法，保持了高效率，并且与不确定性方法结合使用时还能进一步提升性能。

Conclusion: V-Loop 是一种有效的、无需训练的、即插即用的框架，可以显著提高 MLLMs 在医疗 VQA 中的幻觉检测能力，通过视觉逻辑循环验证答案的事实准确性。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable capability in assisting disease diagnosis in medical visual question answering (VQA). However, their outputs remain vulnerable to hallucinations (i.e., responses that contradict visual facts), posing significant risks in high-stakes medical scenarios. Recent introspective detection methods, particularly uncertainty-based approaches, offer computational efficiency but are fundamentally indirect, as they estimate predictive uncertainty for an image-question pair rather than verifying the factual correctness of a specific answer. To address this limitation, we propose Visual Logical Loop Verification (V-Loop), a training-free and plug-and-play framework for hallucination detection in medical VQA. V-Loop introduces a bidirectional reasoning process that forms a visually grounded logical loop to verify factual correctness. Given an input, the MLLM produces an answer for the primary input pair. V-Loop extracts semantic units from the primary QA pair, generates a verification question by conditioning on the answer unit to re-query the question unit, and enforces visual attention consistency to ensure answering both primary question and verification question rely on the same image evidence. If the verification answer matches the expected semantic content, the logical loop closes, indicating factual grounding; otherwise, the primary answer is flagged as hallucinated. Extensive experiments on multiple medical VQA benchmarks and MLLMs show that V-Loop consistently outperforms existing introspective methods, remains highly efficient, and further boosts uncertainty-based approaches when used in combination.

</details>


### [200] [SwipeGen: Bridging the Execution Gap in GUI Agents via Human-like Swipe Synthesis](https://arxiv.org/abs/2601.18305)
*Xuan Wang,Siyuan Su,Quantong Fu,Yongxiang Hu,Yangfan Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为 SwipeGen 的自动化流水线，用于生成类人滑动交互，并构建了一个新的基准来评估 GUI 智能体的滑动执行能力。在此基础上，作者提出了 GUISwiper，一种在滑动执行方面表现显著优于现有 VLM 基线的方法。


<details>
  <summary>Details</summary>
Motivation: 现有 GUI 智能体在处理滑动交互时策略过于简化，无法准确复制人类行为，这已成为任务完成的新瓶颈。

Method: 将人类滑动手势分解为多个可量化维度，提出 SwipeGen 流水线通过 GUI 探索合成类人滑动交互，并以此构建评估基准。在此基础上，提出 GUI 智能体 GUISwiper。

Result: GUISwiper 在滑动执行准确率方面达到了 69.07%，相比现有 VLM 基线提高了 214%。

Conclusion: 通过将滑动交互分解为可量化维度并生成类人交互，可以显著提升 GUI 智能体的滑动执行能力，GUISwiper 在此方面取得了突破性进展。

Abstract: With the widespread adoption of Graphical User Interface (GUI) agents for automating GUI interaction tasks, substantial research focused on improving GUI perception to ground task instructions into concrete action steps. However, the step execution capability of these agents has gradually emerged as a new bottleneck for task completion. In particular, existing GUI agents often adopt overly simplified strategies for handling swipe interactions, preventing them from accurately replicating human-like behavior. To address this limitation, we decompose human swipe gestures into multiple quantifiable dimensions and propose an automated pipeline SwipeGen to synthesize human-like swipe interactions through GUI exploration. Based on this pipeline, we construct and release the first benchmark for evaluating the swipe execution capability of GUI agents. Furthermore, leveraging the synthesized data, we propose GUISwiper, a GUI agent with enhanced interaction execution capabilities. Experimental results demonstrate that GUISwiper achieves a swipe execution accuracy of 69.07%, representing a 214% improvement over existing VLM baselines.

</details>


### [201] [Vision-Language-Model-Guided Differentiable Ray Tracing for Fast and Accurate Multi-Material RF Parameter Estimation](https://arxiv.org/abs/2601.18242)
*Zerui Kang,Yishen Lim,Zhouyou Gu,Seung-Woo Ko,Tony Q. S. Quek,Jihong Park*

Main category: cs.CV

TL;DR: 提出了一种基于视觉语言模型（VLM）的框架，用于在可微分射线追踪（DRT）引擎中加速和稳定多材料参数估计，通过从场景图像中推断材料类别并提供初始值和选择信息丰富的发射器/接收器位置，实验表明比传统方法收敛更快，参数误差更低。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度下降的逆射线追踪方法在6G系统中进行射频材料参数估计时，对初始化敏感且在测量数据有限时成本高昂，需要更有效和稳定的方法。

Method: 提出了一种VLM引导的框架，该框架结合了VLM的语义理解能力和DRT的物理仿真能力。VLM解析场景图像以推断材料类别，并将其映射到ITU-R材料表中以获取定量先验信息（例如电导率的初始值）。VLM还用于选择信息量大、能够区分不同材料的发射器/接收器位置。在此基础上，DRT利用测量到的接收信号强度进行梯度下降优化。

Result: 在NVIDIA Sionna平台上，针对室内场景的实验显示，与均匀或随机初始化和随机放置基线相比，该方法收敛速度提高了2-4倍，最终参数误差降低了10-100倍。使用少量接收器即可达到低于0.1%的平均相对误差。复杂度分析表明，每迭代时间的增长接近于材料数量和测量设置数量的线性关系。VLM引导的放置策略减少了准确恢复所需的测量数量。消融实验证实了在RT深度和光线数量上的进一步精度提升，且每迭代开销增加不显著。

Conclusion: 来自VLM的语义先验信息能够有效地引导基于物理的优化过程，从而实现快速、可靠的射频材料参数估计，为构建精确的电磁数字孪生提供了有力支持。

Abstract: Accurate radio-frequency (RF) material parameters are essential for electromagnetic digital twins in 6G systems, yet gradient-based inverse ray tracing (RT) remains sensitive to initialization and costly under limited measurements. This paper proposes a vision-language-model (VLM) guided framework that accelerates and stabilizes multi-material parameter estimation in a differentiable RT (DRT) engine. A VLM parses scene images to infer material categories and maps them to quantitative priors via an ITU-R material table, yielding informed conductivity initializations. The VLM further selects informative transmitter/receiver placements that promote diverse, material-discriminative paths. Starting from these priors, the DRT performs gradient-based refinement using measured received signal strengths. Experiments in NVIDIA Sionna on indoor scenes show 2-4$\times$ faster convergence and 10-100$\times$ lower final parameter error compared with uniform or random initialization and random placement baselines, achieving sub-0.1\% mean relative error with only a few receivers. Complexity analyses indicate per-iteration time scales near-linearly with the number of materials and measurement setups, while VLM-guided placement reduces the measurements required for accurate recovery. Ablations over RT depth and ray counts confirm further accuracy gains without significant per-iteration overhead. Results demonstrate that semantic priors from VLMs effectively guide physics-based optimization for fast and reliable RF material estimation.

</details>


### [202] [PPISP: Physically-Plausible Compensation and Control of Photometric Variations in Radiance Field Reconstruction](https://arxiv.org/abs/2601.18336)
*Isaac Deutsch,Nicolas Moënne-Loccoz,Gavriel State,Zan Gojcic*

Main category: cs.CV

TL;DR: 提出了一种名为PPISP的模块，用于解决多视图3D重建中相机光度不一致的问题，通过解耦相机内在和拍摄依赖效应，实现了更真实的重建效果和更直观的控制。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图3D重建方法对由相机光学特性和图像信号处理（ISP）引起的照度不一致非常敏感，而现有的缓解策略缺乏物理基础且泛化能力差。

Method: 提出PPISP（Physically-Plausible ISP）校正模块，通过基于物理且可解释的变换来解耦相机内在和拍摄依赖效应。设计了一个PPISP控制器，类似于相机的自动曝光和自动白平衡，用于预测新视角的ISP参数。

Result: PPISP在标准基准测试中取得了最先进的性能，并且能够提供直观的控制，支持集成元数据。

Conclusion: PPISP模块通过基于物理的ISP参数预测，解决了多视图3D重建中的光度不一致问题，实现了更逼真、更公平的重建评估，并提供了更好的可控性和泛化能力。

Abstract: Multi-view 3D reconstruction methods remain highly sensitive to photometric inconsistencies arising from camera optical characteristics and variations in image signal processing (ISP). Existing mitigation strategies such as per-frame latent variables or affine color corrections lack physical grounding and generalize poorly to novel views. We propose the Physically-Plausible ISP (PPISP) correction module, which disentangles camera-intrinsic and capture-dependent effects through physically based and interpretable transformations. A dedicated PPISP controller, trained on the input views, predicts ISP parameters for novel viewpoints, analogous to auto exposure and auto white balance in real cameras. This design enables realistic and fair evaluation on novel views without access to ground-truth images. PPISP achieves SoTA performance on standard benchmarks, while providing intuitive control and supporting the integration of metadata when available. The source code is available at: https://github.com/nv-tlabs/ppisp

</details>


### [203] [A Tumor Aware DenseNet Swin Hybrid Learning with Boosted and Hierarchical Feature Spaces for Large-Scale Brain MRI Classification](https://arxiv.org/abs/2601.18330)
*Muhammad Ali Shah,Muhammad Mansoor Alam,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: 本文提出了一种名为EDSH的混合模型，结合了DenseNet和Swin Transformer，用于脑肿瘤MRI分析，能够同时捕捉局部纹理和全局上下文信息，并在大规模数据集上取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的模型在捕捉脑肿瘤MRI的精细纹理和长距离上下文信息方面存在不足，难以应对不同类型肿瘤的诊断挑战。因此，研究旨在开发一种能够联合学习局部和全局特征的框架，以提高脑肿瘤的检测和分类准确性。

Method: 本文提出了Densely Swin Hybrid (EDSH) 框架，该框架结合了DenseNet和Swin Transformer。研究了两种实验设置：1) Boosted Feature Space (BFS)，通过定制的DenseNet和SwinT分支学习互补的局部和全局表示，然后进行维度对齐、融合和增强。2) 层次化DenseNet SwinT架构，其中DenseNet作为基础CNN学习局部特征，Swin_t模型化全局肿瘤形态。DenseNet的输入层被定制以匹配MRI的特点，并利用密集残差连接保留纹理信息和缓解梯度消失。SwinT通过任务对齐的patch embedding和移位窗口自注意力机制来捕捉层次化的全局依赖。

Result: 在包含40,260张图像的大规模MRI数据集上进行了广泛评估，结果显示EDSH框架在准确率和召回率方面均优于单独的CNN、Vision Transformer和混合模型，在测试集上达到了98.50%的准确率和召回率。

Conclusion: EDSH框架能够有效地捕捉脑肿瘤MRI中的精细纹理和长距离上下文信息，并在处理不同类型的脑肿瘤（如弥漫性胶质瘤、脑膜瘤和垂体瘤）方面表现出优越性，克服了类别的特定诊断挑战，取得了显著的性能提升。

Abstract: This study proposes an efficient Densely Swin Hybrid (EDSH) framework for brain tumor MRI analysis, designed to jointly capture fine grained texture patterns and long range contextual dependencies. Two tumor aware experimental setups are introduced to address class-specific diagnostic challenges. The first setup employs a Boosted Feature Space (BFS), where independently customized DenseNet and Swint branches learn complementary local and global representations that are dimension aligned, fused, and boosted, enabling highly sensitive detection of diffuse glioma patterns by successfully learning the features of irregular shape, poorly defined mass, and heterogeneous texture. The second setup adopts a hierarchical DenseNet Swint architecture with Deep Feature Extraction have Dual Residual connections (DFE and DR), in which DenseNet serves as a stem CNN for structured local feature learning, while Swin_t models global tumor morphology, effectively suppressing false negatives in meningioma and pituitary tumor classification by learning the features of well defined mass, location (outside brain) and enlargments in tumors (dural tail or upward extension). DenseNet is customized at the input level to match MRI spatial characteristics, leveraging dense residual connectivity to preserve texture information and mitigate vanishing-gradient effects. In parallel, Swint is tailored through task aligned patch embedding and shifted-window self attention to efficiently capture hierarchical global dependencies. Extensive evaluation on a large-scale MRI dataset (stringent 40,260 images across four tumor classes) demonstrates consistent superiority over standalone CNNs, Vision Transformers, and hybrids, achieving 98.50 accuracy and recall on the test unseen dataset.

</details>


### [204] [Beyond Rigid: Benchmarking Non-Rigid Video Editing](https://arxiv.org/abs/2601.18340)
*Bingzheng Qu,Kehai Chen,Xuefeng Bai,Jun Yu,Min Zhang*

Main category: cs.CV

TL;DR: 本文提出了NRVBench，一个用于评估视频非刚性形变的基准，并引入了新的评估指标NRVE-Acc和名为VM-Edit的基线模型，以解决现有方法在物理合理性和时间一致性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动的视频编辑技术在生成连贯的非刚性形变方面存在困难，常出现物理失真和时间闪烁等问题。作者希望通过构建一个专门的基准来解决这一挑战。

Method: 1. 构建了一个包含180个非刚性运动视频、2340个精细任务指令和360个选择题的NRVBench数据集。2. 提出了一种基于视觉语言模型的NRVE-Acc评估指标，用于评估物理合规性、时间一致性和指令对齐度。3. 引入了一个无需训练的基线模型VM-Edit，利用双区域去噪机制实现结构感知控制。

Result: 实验表明，当前方法在保持物理合理性方面存在不足，而作者提出的VM-Edit在标准指标和提出的NRVE-Acc指标上均表现出色。

Conclusion: NRVBench基准和NRVE-Acc指标能够更有效地评估非刚性视频编辑的性能，VM-Edit提供了一个有竞争力的基线。作者认为该基准将有助于推动物理感知视频编辑技术的发展。

Abstract: Despite the remarkable progress in text-driven video editing, generating coherent non-rigid deformations remains a critical challenge, often plagued by physical distortion and temporal flicker. To bridge this gap, we propose NRVBench, the first dedicated and comprehensive benchmark designed to evaluate non-rigid video editing. First, we curate a high-quality dataset consisting of 180 non-rigid motion videos from six physics-based categories, equipped with 2,340 fine-grained task instructions and 360 multiple-choice questions. Second, we propose NRVE-Acc, a novel evaluation metric based on Vision-Language Models that can rigorously assess physical compliance, temporal consistency, and instruction alignment, overcoming the limitations of general metrics in capturing complex dynamics. Third, we introduce a training-free baseline, VM-Edit, which utilizes a dual-region denoising mechanism to achieve structure-aware control, balancing structural preservation and dynamic deformation. Extensive experiments demonstrate that while current methods have shortcomings in maintaining physical plausibility, our method achieves excellent performance across both standard and proposed metrics. We believe the benchmark could serve as a standard testing platform for advancing physics-aware video editing.

</details>


### [205] [Contextual Range-View Projection for 3D LiDAR Point Clouds](https://arxiv.org/abs/2601.18301)
*Seyedali Mousavi,Seyedhamidreza Mousavi,Masoud Daneshtalab*

Main category: cs.CV

TL;DR: 该研究提出了一种名为CAP（Centerness-Aware Projection）和CWAP（Class-Weighted-Aware Projection）的新型点云到2D范围图像的投影方法，以解决现有方法在处理多对一映射冲突时丢失上下文信息的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于最小深度选择点的策略在点云到2D范围图像的投影过程中会丢失重要的上下文信息，因为它忽略了语义相关性和物体结构，可能导致对背景点或边界点的误判。

Method: 研究提出了两种新的投影机制：1. Centerness-Aware Projection (CAP)，通过根据点到实例中心点的距离调整点深度来优先选择实例中心点。2. Class-Weighted-Aware Projection (CWAP)，允许用户定义权重来优先考虑特定类别的点。

Result: 在SemanticKITTI数据集上的评估显示，CAP保留了更多的实例点，与基线方法相比，mIoU提高了3.1%。CWAP能够提升目标类别的性能，同时对其他类别的性能影响很小。

Conclusion: CAP和CWAP能够有效地解决点云投影中的多对一冲突问题，通过引入实例中心和类别信息，保留了更多的上下文信息，提高了2D深度学习模型在处理范围图像时的性能，特别是对于实例分割任务。

Abstract: Range-view projection provides an efficient method for transforming 3D LiDAR point clouds into 2D range image representations, enabling effective processing with 2D deep learning models. However, a major challenge in this projection is the many-to-one conflict, where multiple 3D points are mapped onto the same pixel in the range image, requiring a selection strategy. Existing approaches typically retain the point with the smallest depth (closest to the LiDAR), disregarding semantic relevance and object structure, which leads to the loss of important contextual information. In this paper, we extend the depth-based selection rule by incorporating contextual information from both instance centers and class labels, introducing two mechanisms: \textit{Centerness-Aware Projection (CAP)} and \textit{Class-Weighted-Aware Projection (CWAP)}. In CAP, point depths are adjusted according to their distance from the instance center, thereby prioritizing central instance points over noisy boundary and background points. In CWAP, object classes are prioritized through user-defined weights, offering flexibility in the projection strategy. Our evaluations on the SemanticKITTI dataset show that CAP preserves more instance points during projection, achieving up to a 3.1\% mIoU improvement compared to the baseline. Furthermore, CWAP enhances the performance of targeted classes while having a negligible impact on the performance of other classes

</details>


### [206] [Q-Bench-Portrait: Benchmarking Multimodal Large Language Models on Portrait Image Quality Perception](https://arxiv.org/abs/2601.18346)
*Sijing Wu,Yunhao Li,Zicheng Zhang,Qi Jia,Xinyue Li,Huiyu Duan,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文提出了第一个专门针对人像图像质量感知的基准Q-Bench-Portrait，包含2765个图像-问题-答案三元组，涵盖了多样化的图像来源、全面的质量维度和多样的提问格式。通过在Q-Bench-Portrait上评估25个MLLMs，研究发现现有模型在人像感知能力上仍有局限，与人类判断存在差距。


<details>
  <summary>Details</summary>
Motivation: 现有低层视觉基准主要关注通用图像，而人像图像的感知和评估能力仍未被充分探索。人像图像具有独特的结构和感知特性。

Method: 构建了一个包含2,765个图像-问题-答案三元组的人像图像质量感知基准（Q-Bench-Portrait），该基准包含多样化的图像来源（自然、合成失真、AI生成、艺术、计算机图形）、全面的质量维度（技术失真、AIGC失真、美学）和多样的问答格式（单选、多选、判断、开放式）。在此基础上，评估了20个开源和5个闭源的多模态大语言模型（MLLMs）。

Result: 通过Q-Bench-Portrait基准对25个MLLMs的评估显示，尽管当前模型在人像图像感知方面具有一定能力，但其表现仍然有限且不够精确，与人类判断存在明显差距。

Conclusion: Q-Bench-Portrait是一个新颖的人像图像质量感知基准，旨在推动对MLLMs人像图像感知能力的研究。评估结果表明，现有MLLMs在处理人像图像质量感知方面仍需改进，并且与人类的判断能力存在差距。研究者希望该基准能促进通用和领域特定MLLMs在该领域能力的提升。

Abstract: Recent advances in multimodal large language models (MLLMs) have demonstrated impressive performance on existing low-level vision benchmarks, which primarily focus on generic images. However, their capabilities to perceive and assess portrait images, a domain characterized by distinct structural and perceptual properties, remain largely underexplored. To this end, we introduce Q-Bench-Portrait, the first holistic benchmark specifically designed for portrait image quality perception, comprising 2,765 image-question-answer triplets and featuring (1) diverse portrait image sources, including natural, synthetic distortion, AI-generated, artistic, and computer graphics images; (2) comprehensive quality dimensions, covering technical distortions, AIGC-specific distortions, and aesthetics; and (3) a range of question formats, including single-choice, multiple-choice, true/false, and open-ended questions, at both global and local levels. Based on Q-Bench-Portrait, we evaluate 20 open-source and 5 closed-source MLLMs, revealing that although current models demonstrate some competence in portrait image perception, their performance remains limited and imprecise, with a clear gap relative to human judgments. We hope that the proposed benchmark will foster further research into enhancing the portrait image perception capabilities of both general-purpose and domain-specific MLLMs.

</details>


### [207] [Gaze Prediction in Virtual Reality Without Eye Tracking Using Visual and Head Motion Cues](https://arxiv.org/abs/2601.18372)
*Christos Petrou,Harris Partaourides,Athanasios Balomenos,Yannis Kopsinis,Sotirios Chatzis*

Main category: cs.CV

TL;DR: 提出了一种结合HMD运动信号和视觉显著性线索的注视点预测框架，用于在缺乏直接眼动追踪的VR环境中预测用户注视点，以减少延迟和增强交互。


<details>
  <summary>Details</summary>
Motivation: 在VR应用中，注视点预测对于减少传感器延迟和实现眼动注视渲染等技术至关重要，但直接眼动追踪因硬件限制或隐私问题而不可用。

Method: 利用UniSal提取视觉特征，并将其与HMD运动数据融合，通过TSMixer或LSTM等时间序列预测模块来预测未来的注视方向。

Result: 提出的方法在EHTask数据集和商业VR硬件上的实验中，持续优于Center-of-HMD和Mean Gaze等基线方法。

Conclusion: 在缺乏直接眼动追踪约束的VR环境中，预测式注视点建模能够有效减少感知延迟并提升自然交互的体验。

Abstract: Gaze prediction plays a critical role in Virtual Reality (VR) applications by reducing sensor-induced latency and enabling computationally demanding techniques such as foveated rendering, which rely on anticipating user attention. However, direct eye tracking is often unavailable due to hardware limitations or privacy concerns. To address this, we present a novel gaze prediction framework that combines Head-Mounted Display (HMD) motion signals with visual saliency cues derived from video frames. Our method employs UniSal, a lightweight saliency encoder, to extract visual features, which are then fused with HMD motion data and processed through a time-series prediction module. We evaluate two lightweight architectures, TSMixer and LSTM, for forecasting future gaze directions. Experiments on the EHTask dataset, along with deployment on commercial VR hardware, show that our approach consistently outperforms baselines such as Center-of-HMD and Mean Gaze. These results demonstrate the effectiveness of predictive gaze modeling in reducing perceptual lag and enhancing natural interaction in VR environments where direct eye tracking is constrained.

</details>


### [208] [Estimation of geometric transformation matrices using grid-shaped pilot signals](https://arxiv.org/abs/2601.18385)
*Rinka Kawano,Masaki Kawamura*

Main category: cs.CV

TL;DR: 提出一种基于网格状导频信号的数字水印方法，该方法能通过分析导频信号的失真来估计几何变换，从而在裁剪等攻击下实现精确的水印同步和提取。


<details>
  <summary>Details</summary>
Motivation: 现有的数字水印方法在面对裁剪等几何变换时同步性能不佳，难以准确提取水印，因此需要开发一种鲁棒性更强的防裁剪水印技术。

Method: 将具有不同水平和垂直值的网格状导频信号嵌入图像中。通过分析该网格信号在几何变换（如缩放、旋转、剪切、裁剪）后的失真，利用Radon变换估计变换矩阵、网格角度和间隔。通过区分水平和垂直网格线的编码来确定网格方向，减少歧义。

Result: 在进行各向异性缩放、旋转、剪切和裁剪等单一及复合攻击的仿真实验中，所提出的方法能够以较低的误差精确估计变换矩阵。

Conclusion: 所提出的基于网格导频信号的数字水印方法能有效应对裁剪等几何变换，实现了鲁棒的水印同步和提取。

Abstract: Digital watermarking techniques are essential to prevent unauthorized use of images. Since pirated images are often geometrically distorted by operations such as scaling and cropping, accurate synchronization - detecting the embedding position of the watermark - is critical for proper extraction. In particular, cropping changes the origin of the image, making synchronization difficult. However, few existing methods are robust against cropping. To address this issue, we propose a watermarking method that estimates geometric transformations applied to a stego image using a pilot signal, allowing synchronization even after cropping. A grid-shaped pilot signal with distinct horizontal and vertical values is embedded in the image. When the image is transformed, the grid is also distorted. By analyzing this distortion, the transformation matrix can be estimated. Applying the Radon transform to the distorted image allows estimation of the grid angles and intervals. In addition, since the horizontal and vertical grid lines are encoded differently, the grid orientation can be determined, which reduces ambiguity. To validate our method, we performed simulations with anisotropic scaling, rotation, shearing, and cropping. The results show that the proposed method accurately estimates transformation matrices with low error under both single and composite attacks.

</details>


### [209] [OREHAS: A fully automated deep-learning pipeline for volumetric endolymphatic hydrops quantification in MRI](https://arxiv.org/abs/2601.18368)
*Caterina Fuster-Barceló,Claudia Castrillón,Laura Rodrigo-Muñoz,Victor Manuel Vega-Suárez,Nicolás Pérez-Fernández,Gorka Bastarrika,Arrate Muñoz-Barrutia*

Main category: cs.CV

TL;DR: OREHAS是一个全自动化的新流水线，用于从常规MRI中定量测量内淋巴积水（EH），能够直接计算内淋巴与前庭体积比（ELR），并取得了优于现有软件的性能。


<details>
  <summary>Details</summary>
Motivation: 现有内淋巴积水（EH）的定量方法需要手动干预，存在主观性和效率低下。研究动机是开发一种全自动化的方法，从常规MRI中可靠、可重复地量化EH。

Method: OREHAS流水线集成了切片分类、内耳定位和特定序列分割三个组件。它利用深度学习，使用少量标注数据进行训练，然后对整个3D MRI体积进行处理，直接计算内淋巴与前庭体积比（ELR）。

Result: OREHAS在SPACE-MRC和REAL-IR序列上分别取得了0.90和0.75的Dice分数。在外部验证中，OREHAS与专家评分（VSI = 74.3%）高度一致，并且显著优于syngo.via软件（VSI = 42.5%），后者倾向于高估内淋巴体积。OREHAS的内淋巴体积测量结果更小且生理上更合理。

Conclusion: OREHAS能够从标准MRI中实现可靠且可重复的EH定量，并且仅需要有限的监督。该方法减少了操作员依赖，保证了方法的一致性，并为大规模研究和校准临床诊断阈值奠定了基础。

Abstract: We present OREHAS (Optimized Recognition & Evaluation of volumetric Hydrops in the Auditory System), the first fully automatic pipeline for volumetric quantification of endolymphatic hydrops (EH) from routine 3D-SPACE-MRC and 3D-REAL-IR MRI. The system integrates three components -- slice classification, inner ear localization, and sequence-specific segmentation -- into a single workflow that computes per-ear endolymphatic-to-vestibular volume ratios (ELR) directly from whole MRI volumes, eliminating the need for manual intervention.
  Trained with only 3 to 6 annotated slices per patient, OREHAS generalized effectively to full 3D volumes, achieving Dice scores of 0.90 for SPACE-MRC and 0.75 for REAL-IR. In an external validation cohort with complete manual annotations, OREHAS closely matched expert ground truth (VSI = 74.3%) and substantially outperformed the clinical syngo.via software (VSI = 42.5%), which tended to overestimate endolymphatic volumes. Across 19 test patients, vestibular measurements from OREHAS were consistent with syngo.via, while endolymphatic volumes were systematically smaller and more physiologically realistic.
  These results show that reliable and reproducible EH quantification can be achieved from standard MRI using limited supervision. By combining efficient deep-learning-based segmentation with a clinically aligned volumetric workflow, OREHAS reduces operator dependence, ensures methodological consistency. Besides, the results are compatible with established imaging protocols. The approach provides a robust foundation for large-scale studies and for recalibrating clinical diagnostic thresholds based on accurate volumetric measurements of the inner ear.

</details>


### [210] [Efficient Complex-Valued Vision Transformers for MRI Classification Directly from k-Space](https://arxiv.org/abs/2601.18392)
*Moritz Rempe,Lukas T. Rotkopf,Marco Schlimbach,Helmut Becker,Fabian Hörst,Johannes Haubold,Philipp Dammann,Kevin Kröninger,Jens Kleesiek*

Main category: cs.CV

TL;DR: 提出了一种名为 kViT 的新型复值 Vision Transformer，可以直接在 MRI 的 k 空间数据上进行分类，并引入了径向 k 空间分块策略，提高了计算效率和对高加速因子的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法处理 MRI 的幅度图像，丢失了相位信息且计算成本高。标准神经网络结构（卷积、图块）不适合处理全局、非局部特性的原始频域（k 空间）数据。需要一种能够直接在 k 空间数据上进行分析并提高计算效率的方法。

Method: 提出了一种新型的复值 Vision Transformer (kViT)，可以直接在 k 空间数据上进行分类。引入了一种径向 k 空间分块策略，以适应频域的谱能量分布。

Result: 在 fastMRI 和内部数据集上进行的实验表明，kViT 的分类性能与图像域的先进基线（ResNet, EfficientNet, ViT）相当。kViT 在高加速因子下表现出优越的鲁棒性，并将训练时的 VRAM 消耗降低了高达 68 倍。

Conclusion: kViT 实现了对 MRI k 空间数据的直接分类，克服了现有方法的局限性，提供了一种计算高效的、直接从扫描仪进行 AI 分析的新途径。

Abstract: Deep learning applications in Magnetic Resonance Imaging (MRI) predominantly operate on reconstructed magnitude images, a process that discards phase information and requires computationally expensive transforms. Standard neural network architectures rely on local operations (convolutions or grid-patches) that are ill-suited for the global, non-local nature of raw frequency-domain (k-Space) data. In this work, we propose a novel complex-valued Vision Transformer (kViT) designed to perform classification directly on k-Space data. To bridge the geometric disconnect between current architectures and MRI physics, we introduce a radial k-Space patching strategy that respects the spectral energy distribution of the frequency-domain. Extensive experiments on the fastMRI and in-house datasets demonstrate that our approach achieves classification performance competitive with state-of-the-art image-domain baselines (ResNet, EfficientNet, ViT). Crucially, kViT exhibits superior robustness to high acceleration factors and offers a paradigm shift in computational efficiency, reducing VRAM consumption during training by up to 68$\times$ compared to standard methods. This establishes a pathway for resource-efficient, direct-from-scanner AI analysis.

</details>


### [211] [ARMOR: Agentic Reasoning for Methods Orchestration and Reparameterization for Robust Adversarial Attacks](https://arxiv.org/abs/2601.18386)
*Gabriel Lee Jun Rong,Christos Korgialas,Dion Jia Xu Ho,Pai Chet Ng,Xiaoxiao Miao,Konstantinos N. Plataniotis*

Main category: cs.CV

TL;DR: ARMOR是一个新的框架，它利用VLM和LLM来驱动多个对抗性攻击方法，实现更智能、更具适应性的自动化攻击，在对抗性攻击的跨架构迁移和白盒攻击的性能上有所提升。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化攻击工具集缺乏战略适应性和语义意识，其攻击序列固定。本文旨在克服这些局限性。

Method: ARMOR框架通过VLM指导的代理器编排了CW、JSMA和STA三种经典的对抗性攻击方法。LLM在实时闭环系统中自适应地调整和重新参数化并行攻击代理器。代理器通过一个共享的“Mixing Desk”协作生成和合成扰动。

Result: ARMOR在标准基准测试中实现了更好的跨架构迁移能力。对于盲目标，ARMOR提供混合输出；对于白盒目标，它利用置信度和SSIM分数选择最佳攻击或混合攻击。

Conclusion: ARMOR通过VLM和LLM驱动的自适应方法，克服了现有自动化攻击的静态和非语义化问题，提高了对抗性攻击的效率和适应性。

Abstract: Existing automated attack suites operate as static ensembles with fixed sequences, lacking strategic adaptation and semantic awareness. This paper introduces the Agentic Reasoning for Methods Orchestration and Reparameterization (ARMOR) framework to address these limitations. ARMOR orchestrates three canonical adversarial primitives, Carlini-Wagner (CW), Jacobian-based Saliency Map Attack (JSMA), and Spatially Transformed Attacks (STA) via Vision Language Models (VLM)-guided agents that collaboratively generate and synthesize perturbations through a shared ``Mixing Desk". Large Language Models (LLMs) adaptively tune and reparameterize parallel attack agents in a real-time, closed-loop system that exploits image-specific semantic vulnerabilities. On standard benchmarks, ARMOR achieves improved cross-architecture transfer and reliably fools both settings, delivering a blended output for blind targets and selecting the best attack or blended attacks for white-box targets using a confidence-and-SSIM score.

</details>


### [212] [Comparative Evaluation of Machine Learning Algorithms for Affective State Recognition from Children's Drawings](https://arxiv.org/abs/2601.18414)
*Aura Loredana Dan*

Main category: cs.CV

TL;DR: 本文比较了三种深度学习模型（MobileNet、EfficientNet 和 VGG16）在识别儿童绘画中的情绪状态方面的性能，旨在为实时和移动应用提供更有效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统的儿童情绪评估方法存在侵入性、主观性和一致性差等问题，而早期识别儿童的情绪状态对于自闭症谱系障碍（ASD）的干预尤为重要。因此，研究需要一种更客观、更易于应用的方法。

Method: 文章采用了迁移学习的方法，利用心理学专家标注的儿童绘画数据集，训练了三种深度学习模型：MobileNet、EfficientNet 和 VGG16。通过统一的实验框架，对模型在分类性能、鲁棒性和计算效率方面进行了评估。

Result: 结果表明，在儿童绘画情绪识别任务中，轻量级模型和更深层模型之间存在重要的权衡。具体模型性能的对比细节（如准确率、训练时间等）在摘要中未详细说明，但强调了这种权衡对于移动和实时应用的重要性。

Conclusion: 文章得出结论，在开发基于绘画的情感计算系统时，需要根据具体的应用场景（如移动和实时应用）仔细考虑模型架构的权衡，例如在模型大小、计算资源消耗和识别精度之间进行选择。

Abstract: Autism spectrum disorder (ASD) represents a neurodevelopmental condition characterized by difficulties in expressing emotions and communication, particularly during early childhood. Understanding the affective state of children at an early age remains challenging, as conventional assessment methods are often intrusive, subjective, or difficult to apply consistently. This paper builds upon previous work on affective state recognition from children's drawings by presenting a comparative evaluation of machine learning models for emotion classification. Three deep learning architectures -- MobileNet, EfficientNet, and VGG16 -- are evaluated within a unified experimental framework to analyze classification performance, robustness, and computational efficiency. The models are trained using transfer learning on a dataset of children's drawings annotated with emotional labels provided by psychological experts. The results highlight important trade-offs between lightweight and deeper architectures when applied to drawing-based affective computing tasks, particularly in mobile and real-time application contexts.

</details>


### [213] [DisasterInsight: A Multimodal Benchmark for Function-Aware and Grounded Disaster Assessment](https://arxiv.org/abs/2601.18493)
*Sara Tehrani,Yonghao Xu,Leif Haglund,Amanda Berg,Michael Felsberg*

Main category: cs.CV

TL;DR: 本文提出了DisasterInsight，一个用于评估多模态模型在灾害场景下理解和推理能力的新型数据集和基准。同时，研究人员还提出了DI-Chat，一个通过在灾害数据上进行微调的VLM基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有针对遥感图像的视觉-语言模型基准在处理灾害响应场景时存在不足，它们主要关注粗粒度标签和图像级识别，而忽视了在人道主义工作流程中所需的实际功能理解和指令鲁棒性。

Method: 通过将xBD数据集重构为约11.2万个以建筑为中心的实例，构建了一个支持多任务、指令多样化的DisasterInsight基准。同时，提出了DI-Chat模型，该模型通过参数高效的LoRA方法在灾害相关的指令数据上对现有的VLM进行微调。

Result: 在DisasterInsight基准上的实验表明，现有VLM在灾害场景下存在显著的性能差距，特别是在损害理解和结构化报告生成方面。DI-Chat模型在损害等级、灾害类型分类以及报告生成质量方面取得了显著的改进，但建筑功能分类仍然是一个挑战。

Conclusion: DisasterInsight为研究灾害图像中的地面多模态推理提供了一个统一的平台。研究结果突出了当前VLM在处理复杂灾害场景中的局限性，并为未来的研究提供了方向。

Abstract: Timely interpretation of satellite imagery is critical for disaster response, yet existing vision-language benchmarks for remote sensing largely focus on coarse labels and image-level recognition, overlooking the functional understanding and instruction robustness required in real humanitarian workflows. We introduce DisasterInsight, a multimodal benchmark designed to evaluate vision-language models (VLMs) on realistic disaster analysis tasks. DisasterInsight restructures the xBD dataset into approximately 112K building-centered instances and supports instruction-diverse evaluation across multiple tasks, including building-function classification, damage-level and disaster-type classification, counting, and structured report generation aligned with humanitarian assessment guidelines.
  To establish domain-adapted baselines, we propose DI-Chat, obtained by fine-tuning existing VLM backbones on disaster-specific instruction data using parameter-efficient Low-Rank Adaptation (LoRA). Extensive experiments on state-of-the-art generic and remote-sensing VLMs reveal substantial performance gaps across tasks, particularly in damage understanding and structured report generation. DI-Chat achieves significant improvements on damage-level and disaster-type classification as well as report generation quality, while building-function classification remains challenging for all evaluated models. DisasterInsight provides a unified benchmark for studying grounded multimodal reasoning in disaster imagery.

</details>


### [214] [Larger than memory image processing](https://arxiv.org/abs/2601.18407)
*Jon Sporring,David Stansby*

Main category: cs.CV

TL;DR: 本文提出了一种面向大规模（PB级别）图像数据分析的流式处理架构，通过优化数据访问模式，可以在内存有限的情况下实现高效的图像分析，并介绍了一种领域特定语言（DSL）来自动化这一过程。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模图像数据集（如电子显微镜数据和人体器官图谱）超出了单机内存的容纳能力，传统的图像分析方法难以处理。研究者认为性能瓶颈在于I/O，并希望找到一种有效的方法来处理这些大型数据集。

Method: 1. 提出了一种流式处理架构，将分析过程分解为对数据进行多次顺序扫描。
2. 证明了基于切片（slice-based）的流式架构可以有效优化I/O，即使在不同的数据表示（如2D切片堆叠或3D分块）下。
3. 引入了扫掠式执行（sweep-based execution）、窗口化操作（windowed operations）和重叠感知分块（overlap-aware tiling）技术来最小化冗余的磁盘访问。
4. 开发了一个领域特定语言（DSL），能够对算法进行编译时和运行时分析，自动优化窗口大小、算子融合、流合并以及内存分配，以实现高效的流式处理。

Result: 所提出的流式处理方法能够在内存受限的情况下，对PB级别的大型图像数据进行分析，实现近乎线性的I/O扫描和可预测的内存占用。
该方法通过优化读写模式，显著提高了处理速度，无需将整个数据集载入内存。

Conclusion: 通过将图像分析设计为流式管道，并利用领域特定语言（DSL）进行自动化优化，可以在内存有限的条件下高效地处理超大规模图像数据，实现I/O效率的最大化和处理性能的显著提升。

Abstract: This report addresses larger-than-memory image analysis for petascale datasets such as 1.4 PB electron-microscopy volumes and 150 TB human-organ atlases. We argue that performance is fundamentally I/O-bound. We show that structuring analysis as streaming passes over data is crucial. For 3D volumes, two representations are popular: stacks of 2D slices (e.g., directories or multi-page TIFF) and 3D chunked layouts (e.g., Zarr/HDF5). While for a few algorithms, chunked layout on disk is crucial to keep disk I/O at a minimum, we show how the slice-based streaming architecture can be built on top of either image representation in a manner that minimizes disk I/O. This is in particular advantageous for algorithms relying on neighbouring values, since the slicing streaming architecture is 1D, which implies that there are only 2 possible sweeping orders, both of which are aligned with the order in which images are read from the disk. This is in contrast to 3D chunks, in which any sweep cannot be done without accessing each chunk at least 9 times. We formalize this with sweep-based execution (natural 2D/3D orders), windowed operations, and overlap-aware tiling to minimize redundant access. Building on these principles, we introduce a domain-specific language (DSL) that encodes algorithms with intrinsic knowledge of their optimal streaming and memory use; the DSL performs compile-time and run-time pipeline analyses to automatically select window sizes, fuse stages, tee and zip streams, and schedule passes for limited-RAM machines, yielding near-linear I/O scans and predictable memory footprints. The approach integrates with existing tooling for segmentation and morphology but reframes pre/post-processing as pipelines that privilege sequential read/write patterns, delivering substantial throughput gains for extremely large images without requiring full-volume residency in memory.

</details>


### [215] [On Procrustes Contamination in Machine Learning Applications of Geometric Morphometrics](https://arxiv.org/abs/2601.18448)
*Lloyd Austin Courtenay*

Main category: cs.CV

TL;DR: 本文研究了在将形态学数据输入机器学习模型前，使用广义普氏分析（GPA）对样本进行对齐可能带来的统计学上的数据污染问题。提出了一种新的数据预处理方法（重新对齐），以消除样本间的依赖性，并通过模拟验证了该方法的有效性，并探讨了地标密度和空间自相关对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 标准的形态学数据分析流程（GPA后拆分训练/测试集）可能导致统计依赖性，污染机器学习模型的预测结果。研究旨在量化这种污染效应并提出解决方案。

Method: 使用2D和3D模拟研究了不同样本量、地标密度和异速生长模式下，GPA数据污染的影响。提出了一种新的“重新对齐”方法，先将测试样本对齐到训练集，再进行模型拟合。通过线性回归和卷积回归模型评估了地标空间自相关的重要性。

Result: 模拟显示，在样本量与地标空间之间存在一个可靠的“对角线”，反映了均方根误差（RMSE）在各向同性变化下的缩放规律。新的重新对齐方法消除了样本间的交叉依赖性。忽略地标间的空间自相关会导致模型性能下降。

Conclusion: 在将形态学数据用于机器学习应用时，需要谨慎进行预处理。文中提出了重新对齐的实用指南，并阐明了普氏形状空间固有的基本统计约束。

Abstract: Geometric morphometrics (GMM) is widely used to quantify shape variation, more recently serving as input for machine learning (ML) analyses. Standard practice aligns all specimens via Generalized Procrustes Analysis (GPA) prior to splitting data into training and test sets, potentially introducing statistical dependence and contaminating downstream predictive models. Here, the effects of GPA-induced contamination are formally characterised using controlled 2D and 3D simulations across varying sample sizes, landmark densities, and allometric patterns. A novel realignment procedure is proposed, whereby test specimens are aligned to the training set prior to model fitting, eliminating cross-sample dependency. Simulations reveal a robust "diagonal" in sample-size vs. landmark-space, reflecting the scaling of RMSE under isotropic variation, with slopes analytically derived from the degrees of freedom in Procrustes tangent space. The importance of spatial autocorrelation among landmarks is further demonstrated using linear and convolutional regression models, highlighting performance degradation when landmark relationships are ignored. This work establishes the need for careful preprocessing in ML applications of GMM, provides practical guidelines for realignment, and clarifies fundamental statistical constraints inherent to Procrustes shape space.

</details>


### [216] [GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning](https://arxiv.org/abs/2601.18543)
*Kaixun Jiang,Yuzheng Wang,Junjie Zhou,Pandeng Li,Zhihang Liu,Chen-Wei Xie,Zhaoyu Chen,Yun Zheng,Wenqiang Zhang*

Main category: cs.CV

TL;DR: GenAgent 是一个新颖的代理式多模态模型，它将视觉理解和生成解耦，通过将图像生成模型视为工具来实现。它支持自主多轮交互，能够生成多模态的思考链，从而迭代地改进输出。


<details>
  <summary>Details</summary>
Motivation: 现有的统一多模态模型存在训练成本高昂以及理解与生成之间权衡取舍的问题。GenAgent 旨在通过代理框架解决这些限制，实现更灵活高效的视觉理解和生成。

Method: GenAgent 采用代理框架，其中多模态模型负责理解，图像生成模型作为可调用的工具。训练过程分为两阶段：1. 冷启动监督微调，用于引导代理行为；2. 端到端代理强化学习，结合点奖励和对奖励，并使用轨迹重采样来增强多轮探索。

Result: GenAgent 在 GenEval++ 上将基础生成器性能提升了 23.6%，在 WISE 上提升了 14%。此外，它还展现了跨工具泛化、测试时可扩展性以及任务自适应推理的能力。

Conclusion: GenAgent 通过创新的代理式框架，有效解耦了视觉理解和生成，并通过自主多轮交互和优化的训练策略，显著提升了图像生成性能，并具备良好的泛化和自适应能力。

Abstract: We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\%) and WISE (+14\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \href{https://github.com/deep-kaixun/GenAgent}{this url}.

</details>


### [217] [REMAC: Reference-Based Martian Asymmetrical Image Compression](https://arxiv.org/abs/2601.18547)
*Qing Ding,Mai Xu,Shengxi Li,Xin Deng,Xin Zou*

Main category: cs.CV

TL;DR: 提出了一种名为REMAC的基于参考的火星图像不对称压缩方法，该方法通过利用参考图像信息和深度多尺度架构，显著降低了编码器复杂度，同时提高了压缩性能。


<details>
  <summary>Details</summary>
Motivation: 现有学习式图像压缩方法在火星图像压缩方面存在计算资源受限和未充分利用火星图像间的相似性两大问题。火星探索任务需要高效的火星图像压缩方法以应对受限的通信带宽。

Method: 提出了一种基于参考的火星不对称图像压缩（REMAC）方法。该方法将计算复杂度从编码器转移到解码器，并利用参考图像信息（通过参考引导熵模块和参考解码器）来减少冗余。同时，参考解码器采用了深度多尺度架构来利用图像内部相似性，并通过潜在特征回收机制来缓解计算资源限制。

Result: 实验结果表明，REMAC 将编码器复杂度降低了 43.51%，同时 BD-PSNR 提高了 0.2664 dB。

Conclusion: REMAC 方法有效解决了火星图像压缩中的计算资源限制和跨图像相似性利用不足的问题，在降低编码器复杂度的同时提升了压缩性能，为火星探索任务的图像传输提供了更优的解决方案。

Abstract: To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \textit{intra-} and \textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB.

</details>


### [218] [From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation](https://arxiv.org/abs/2601.18532)
*Devon Levy,Bar Assayag,Laura Gaspar,Ilan Shimshoni,Bella Specktor-Fadida*

Main category: cs.CV

TL;DR: 本研究提出了一种结合基础模型嵌入和聚类的冷启动主动学习策略，并引入空间多样性来改进不确定性驱动的样本选择，以提高医学图像分割的准确性。该方法在低数据量情况下优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 手动标注医学图像分割样本耗时耗力且需要专业知识，成为疾病监测的主要瓶颈。主动学习（AL）旨在通过优先选择信息量大的样本来减轻此负担。

Method: 提出了一种新的冷启动采样策略，结合了基础模型嵌入和聚类（包括自动选择聚类数量和跨聚类的比例采样），以构建多样化和代表性的初始训练集。随后，一个不确定性驱动的主动学习框架整合了空间多样性来指导样本选择。该方法直观且可解释，能够可视化候选样本的特征空间分布。

Result: 在 CheXmask 数据集上，冷启动策略将 Dice 分数从 0.918 提高到 0.929，并将 Hausdorff 距离从 32.41 毫米减少到 27.66 毫米。在 AL 设置下，熵和多样性结合的选择将 Dice 分数从 0.919 提高到 0.939，并将 Hausdorff 距离从 30.10 毫米减少到 19.16 毫米。在 Montgomery 数据集上，冷启动显著提高了 Dice 分数（从 0.928 到 0.950），并降低了 Hausdorff 距离（从 14.22 毫米到 9.38 毫米）。在 SynthStrip 数据集上，冷启动略微影响 Dice 但降低了 Hausdorff 距离（从 9.43 毫米到 8.69 毫米），而主动学习将 Dice 分数从 0.816 提高到 0.826，并将 Hausdorff 距离从 7.76 毫米减少到 6.38 毫米。

Conclusion: 所提出的框架在低数据量环境下持续优于基线方法，提高了分割准确性。

Abstract: Accurate segmentation annotations are critical for disease monitoring, yet manual labeling remains a major bottleneck due to the time and expertise required. Active learning (AL) alleviates this burden by prioritizing informative samples for annotation, typically through a diversity-based cold-start phase followed by uncertainty-driven selection. We propose a novel cold-start sampling strategy that combines foundation-model embeddings with clustering, including automatic selection of the number of clusters and proportional sampling across clusters, to construct a diverse and representative initial training. This is followed by an uncertainty-based AL framework that integrates spatial diversity to guide sample selection. The proposed method is intuitive and interpretable, enabling visualization of the feature-space distribution of candidate samples. We evaluate our approach on three datasets spanning X-ray and MRI modalities. On the CheXmask dataset, the cold-start strategy outperforms random selection, improving Dice from 0.918 to 0.929 and reducing the Hausdorff distance from 32.41 to 27.66 mm. In the AL setting, combined entropy and diversity selection improves Dice from 0.919 to 0.939 and reduces the Hausdorff distance from 30.10 to 19.16 mm. On the Montgomery dataset, cold-start gains are substantial, with Dice improving from 0.928 to 0.950 and Hausdorff distance decreasing from 14.22 to 9.38 mm. On the SynthStrip dataset, cold-start selection slightly affects Dice but reduces the Hausdorff distance from 9.43 to 8.69 mm, while active learning improves Dice from 0.816 to 0.826 and reduces the Hausdorff distance from 7.76 to 6.38 mm. Overall, the proposed framework consistently outperforms baseline methods in low-data regimes, improving segmentation accuracy.

</details>


### [219] [Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray](https://arxiv.org/abs/2601.18555)
*Roberto Di Via,Vito Paolo Pastore,Francesca Odone,Siôn Glyn-Jones,Irina Voiculescu*

Main category: cs.CV

TL;DR: 本研究使用标准的heatmap回归模型，通过MRI图像实现了与X光检查相当的股骨髋臼撞击症（FAI）筛查的准确性，为FAI的自动化评估和三维体积分析奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 传统的FAI筛查依赖于X光测量角度，但评估撞击区域的高度和跨度需要MRI的三维视图。本研究旨在评估MRI在FAI筛查中的临床等效性，并探索其在自动化评估中的潜力。

Method: 研究人员进行了一项匹配队列验证研究，使用了89名患者的配对MRI和X光数据。他们采用了标准的热图回归（heatmap regression）架构，评估了在MRI影像上进行关键点定位的准确性，以实现与X光相当的FAI诊断。

Result: 研究结果表明，在股骨头颈撞击（cam-type impingement）的筛查方面，MRI在关键点定位和诊断准确性上与X光相当。该方法在MRI冠状面三维影像中实现了FAI评估的临床可行性。

Conclusion: 该研究支持将自动化的FAI评估整合到常规的MRI工作流程中，并为通过放置更多关键点进行三维体积分析开辟了可能性。

Abstract: Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions

</details>


### [220] [Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis](https://arxiv.org/abs/2601.18556)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: 提出了一种名为 SDA-QEC 的新框架，结合了简化的扩散模型数据增强和量子增强分类，以解决医学图像数据集中的类别不平衡问题，并在冠状动脉造影图像分类任务中取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 真实的医学数据集常存在严重的类别不平衡问题，导致模型偏向多数类，少数类的召回率低，从而影响诊断准确性并带来临床误诊风险。

Method: SDA-QEC 框架包含两个主要部分：1. 轻量级扩散模型用于生成少数类别的合成样本，以重新平衡训练数据分布。2. 在 MobileNetV2 架构中嵌入量子特征层，通过希尔伯特空间中的高维特征映射来增强模型的判别能力。

Result: 在冠状动脉造影图像分类实验中，SDA-QEC 达到了 98.33% 的准确率、98.78% 的 AUC 和 98.33% 的 F1 分数。与 ResNet18、MobileNetV2、DenseNet121 和 VGG16 等经典模型相比，性能显著提升。同时实现了 98.33% 的敏感性和 98.33% 的特异性，达到了临床应用所需的性能平衡。

Conclusion: SDA-QEC 框架证明了在实际医学影像任务中集成生成式增强和量子增强建模的可行性，为开发在小样本、高度不平衡和高风险诊断场景下可靠的医学人工智能系统提供了新的研究方向。

Abstract: In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios.

</details>


### [221] [Self-Refining Video Sampling](https://arxiv.org/abs/2601.18577)
*Sangwon Jang,Taekyung Ki,Jaehyeong Jo,Saining Xie,Jaehong Yoon,Sung Ju Hwang*

Main category: cs.CV

TL;DR: 提出一种自改进视频采样方法，利用预训练的视频生成器进行推理时进行迭代精炼，无需额外训练或验证器，并引入不确定性感知策略以避免过度精炼产生的伪影，显著提高了视频的运动连贯性和物理保真度。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成器在处理复杂物理动力学和捕捉细粒度运动方面存在不足，现有的解决方案计算成本高且效果有限。

Method: 将预训练的视频生成器视为去噪自编码器，在推理时进行迭代内部循环精炼，并引入不确定性感知精炼策略，根据自一致性选择性地精炼区域。

Result: 在最先进的视频生成器上进行了实验，证明了运动连贯性和物理对齐的显著改进，相比默认采样器和基于引导的采样器，人类偏好率超过 70%。

Conclusion: 自改进视频采样是一种简单有效的方法，可以无需额外训练或验证器即可显著提高视频生成质量，特别是在运动连贯性和物理保真度方面。

Abstract: Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\% human preference compared to the default sampler and guidance-based sampler.

</details>


### [222] [AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging](https://arxiv.org/abs/2601.18560)
*Li Fang,Tianyu Li,Yanghong Lin,Shudong Zhou,Wei Yao*

Main category: cs.CV

TL;DR: 提出了一种AI赋能的卫星边缘计算范式，用于高光谱图像分类，以解决卫星下行传输速度慢的问题。该方法采用轻量级、非深度学习框架，并结合少样本学习策略，以及一个两阶段的像素级标签传播方案来处理图像质量下降的问题。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像卫星提供了丰富的信息，但其下行传输速度成为实时应用（如灾害监测）的瓶颈。需要一种能够在卫星端进行自主决策的方法。

Method: 1. 提出AI赋能的卫星边缘计算范式，采用轻量级、非深度学习框架结合少样本学习。 2. 开发了两阶段的像素级标签传播方案，用于处理传感器故障和扫描错误导致的图像质量下降。 3. 第一阶段通过锚点-像素亲和矩阵传播锚点标签获得初始标签。 4. 第二阶段利用稀疏图的闭式解进行计算。 5. 开发了基于秩约束的图聚类算法来确定锚点标签。

Result: 未在摘要中具体说明实验结果，但该方法旨在提高处理效率并解决图像质量问题。

Conclusion: 提出的AI赋能的卫星边缘计算范式，结合轻量级模型和创新的像素级标签传播技术，能够有效解决高光谱卫星图像在资源受限的卫星平台上的传输瓶颈和图像质量问题，实现自主决策。

Abstract: As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels.

</details>


### [223] [GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization](https://arxiv.org/abs/2601.18585)
*Chenxi Liu,Selena Ling,Alec Jacobson*

Main category: cs.CV

TL;DR: 提出了一种名为 GimmBO 的交互式工具，利用偏好贝叶斯优化（PBO）来探索和合成由多个微调适配器（adapters）生成的图像，解决了手动调参效率低下和权重选择困难的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型微调适配器（adapters）可以被合并以生成新颖的图像，但手动调整合并权重效率低下且难以选择，尤其是在适配器数量较多时。研究者希望提供一种更有效的方法来探索这种连续的设计空间。

Method: 提出 GimmBO 工具，采用偏好贝叶斯优化（PBO）方法。通过一个两阶段的贝叶斯优化后端来提高高维空间中的采样效率和收敛速度，以应对实际使用中观察到的稀疏性和受限权重范围等特点。

Result: 通过模拟用户和真实用户研究，GimmBO 在收敛速度、成功率以及与基线方法（如纯贝叶斯优化和线搜索）相比均表现出优势。此外，还展示了该框架的可扩展性。

Conclusion: GimmBO 提供了一种有效的交互式方法，用于探索和优化扩散模型适配器合并过程，以生成期望的图像结果，显著优于手动调整和现有优化方法。

Abstract: Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions.

</details>


### [224] [EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery](https://arxiv.org/abs/2601.18597)
*Yu Xia,Chang Liu,Tianqi Xiang,Zhigang Tu*

Main category: cs.CV

TL;DR: 提出了一种名为EFSI-DETR的新型实时小型目标检测框架，通过DyFusNet整合频率和空间信息进行多尺度特征融合，并利用ESFC高效提取深层语义特征，同时采用FFR策略保留浅层细节，在VisDrone和CODrone数据集上取得了最先进的性能和实时推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有无人机（UAV）小型目标检测方法存在特征表示能力有限和多尺度融合效率不高的问题，特别是在频率信息利用不足和卷积操作静态化方面，限制了丰富特征的获取和深层语义特征的有效利用。

Method: 提出了EFSI-DETR框架，包含两个主要部分：1. DyFusNet（动态频率-空间统一协同网络），联合利用频率和空间线索进行多尺度特征融合；2. ESFC（高效语义特征浓缩器），以最小的计算成本实现深层语义提取。此外，采用FFR（细粒度特征保留）策略在融合时纳入空间丰富的浅层特征，以保留对小型目标检测至关重要的细节。

Result: 在VisDrone和CODrone数据集上的大量实验表明，EFSI-DETR在VisDrone上实现了1.6%和AP$_{s}$上5.8%的性能提升，并在单块RTX 4090 GPU上获得了188 FPS的推理速度，达到了最先进的性能和实时性。

Conclusion: EFSI-DETR框架通过有效整合频率-空间信息、高效语义提取和细粒度特征保留，成功解决了无人机小型目标检测中的挑战，实现了在保证实时性的前提下取得卓越的检测性能。

Abstract: Real-time small object detection in Unmanned Aerial Vehicle (UAV) imagery remains challenging due to limited feature representation and ineffective multi-scale fusion. Existing methods underutilize frequency information and rely on static convolutional operations, which constrain the capacity to obtain rich feature representations and hinder the effective exploitation of deep semantic features. To address these issues, we propose EFSI-DETR, a novel detection framework that integrates efficient semantic feature enhancement with dynamic frequency-spatial guidance. EFSI-DETR comprises two main components: (1) a Dynamic Frequency-Spatial Unified Synergy Network (DyFusNet) that jointly exploits frequency and spatial cues for robust multi-scale feature fusion, (2) an Efficient Semantic Feature Concentrator (ESFC) that enables deep semantic extraction with minimal computational cost. Furthermore, a Fine-grained Feature Retention (FFR) strategy is adopted to incorporate spatially rich shallow features during fusion to preserve fine-grained details, crucial for small object detection in UAV imagery. Extensive experiments on VisDrone and CODrone benchmarks demonstrate that our EFSI-DETR achieves the state-of-the-art performance with real-time efficiency, yielding improvement of \textbf{1.6}\% and \textbf{5.8}\% in AP and AP$_{s}$ on VisDrone, while obtaining \textbf{188} FPS inference speed on a single RTX 4090 GPU.

</details>


### [225] [AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment](https://arxiv.org/abs/2601.18589)
*KV Karthikeya,Ashok Kumar Das,Shantanu Pal,Vivekananda Bhat K,Arun Sekar Rajasekaran*

Main category: cs.CV

TL;DR: 提出了一种自适应图信号处理与动态语义对齐（AGSP-DSA）框架，用于融合文本、音频和图像等多模态异构数据，并在多个基准数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 旨在实现对异构多模态数据的鲁棒融合，尤其是在不同模态信息动态关联和上下文相关性不同的情况下。

Method: 采用双图构建学习模态内和模态间关系，利用谱图滤波增强信息信号，并结合多尺度图卷积网络（GCNs）进行有效的节点嵌入。引入了语义感知注意力机制，使各模态能根据上下文相关性动态贡献。

Result: 在CMU-MOSEI、AVE和MM-IMDB三个基准数据集上，AGSP-DSA取得了最先进的性能。在CMU-MOSEI上，准确率达到95.3%，F1分数达到0.936，mAP达到0.924，优于MM-GNN 2.6%。在AVE上，准确率为93.4%，F1分数为0.911。在MM-IMDB上，准确率为91.8%，F1分数为0.886。在缺失模态的情况下也表现出良好的泛化性和鲁棒性。

Conclusion: AGSP-DSA框架在情感分析、事件识别和多媒体分类等任务中，有效提升了多模态学习的能力，证明了其在融合异构多模态数据方面的效率和优越性。

Abstract: In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification.

</details>


### [226] [Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation](https://arxiv.org/abs/2601.18623)
*Zihao Wang,Yuzhou Chen,Shaogang Ren*

Main category: cs.CV

TL;DR: 提出了一种新的跨模态图像翻译方法，通过在生成过程中引入空间变化的混合场和目标一致的修复项，解决了现有扩散模型容易出现的语义漂移问题，并在多个领域实现了更好的结构保真度和语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的跨模态图像翻译方法（如基于扩散模型的方法）通常依赖于全局的线性迁移，导致生成器在采样过程中进入高成本区域，从而引发语义漂移。研究人员希望找到一种更有效、更稳定的跨模态图像翻译方法。

Method: 该模型在反向扩散的每一步预测一个空间变化的混合场，并注入一个明确的目标一致性修复项。这种“步进式”引导将大的更新保持在流形上，并将模型的角色从全局对齐转变为局部残差校正。论文还提供了连续时间公式和一种实用的基于一阶采样器。

Result: 在医学成像、遥感和电致发光语义映射等跨模态翻译任务中，该框架提高了结构保真度和语义一致性，并且收敛所需的去噪步数更少。

Conclusion: 该方法通过将领域迁移动态嵌入生成过程，解决了固定调度领域迁移的固有缺陷，为跨模态图像翻译提供了一种更有效、更鲁棒的解决方案。

Abstract: Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.

</details>


### [227] [Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures](https://arxiv.org/abs/2601.18619)
*Jorge Quesada,Ghassan AlRegib*

Main category: cs.CV

TL;DR: 本研究提出了一种尺度感知自监督学习（SSL）方法，通过引入小窗口裁剪来增强数据预训练，以提高在细粒度、稀疏或不规则目标分割任务中的性能，并在地震成像和神经成像领域取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法在处理目标物体尺寸不一、稀疏或局部不规则的分割任务时效果不佳，作者希望开发一种能适应不同尺度目标的SSL方法。

Method: 作者提出了一种尺度感知的SSL适应方法，将小窗口裁剪集成到数据增强流水线中，在预训练阶段聚焦于细粒度结构。该方法在两个具有不同数据模态的领域进行了评估：地震成像（分割稀疏断层）和神经成像（描绘小的细胞结构）。

Result: 在地震成像和神经成像领域，提出的方法在标签受限的情况下，相比标准和最先进的基线方法，在分割准确性上均取得了一致的改进，断层分割准确性提高了13%，细胞描绘准确性提高了5%。然而，对于大规模特征（如地震相或组织区域），改进效果不明显。

Conclusion: 自监督学习的效果高度依赖于目标物体的尺度。作者的研究表明，将SSL的设计与目标物体的大小和稀疏性相匹配至关重要，并提出了一个通用原则，用于构建更有效的科学成像领域表示学习流水线。

Abstract: Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.

</details>


### [228] [Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting](https://arxiv.org/abs/2601.18633)
*Tong Shi,Melonie de Almeida,Daniela Ivanova,Nicolas Pugeault,Paul Henderson*

Main category: cs.CV

TL;DR: Splat-Portrait 是一种基于高斯泼溅的方法，用于从音频和单张肖像图像生成逼真的 3D 说话头像视频，它能够同时重建 3D 头部和合成自然的唇部运动，并且不需要 3D 监督或运动先验。生成的视频在视觉质量上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的 3D 说话头像生成方法依赖于领域特定的启发式方法（如基于变形的面部运动表示先验），这导致 3D 头像重建不准确，从而影响生成动画的真实感。因此，需要一种新的方法来解决 3D 头重建和唇部运动合成的挑战。

Method: Splat-Portrait 采用基于高斯泼溅（Gaussian Splatting）的方法，将输入的单张肖像图像自动解耦为静态高斯泼溅表示的 3D 重建和预测的 2D 背景。然后，在不依赖任何运动驱动先验的情况下，根据输入的音频生成自然的唇部运动。训练过程仅依赖于 2D 重建和评分蒸馏损失，无需 3D 监督或关键点。

Result: 实验结果表明，Splat-Portrait 在说话头像生成和新视角合成方面表现出优越的性能，与现有方法相比，具有更好的视觉质量。

Conclusion: Splat-Portrait 成功地解决了 3D 头重建和唇部运动合成的挑战，通过结合高斯泼溅和音频驱动的运动生成，实现了更高质量和更逼真的说话头像视频生成，并且无需 3D 监督或运动先验。

Abstract: Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait.

</details>


### [229] [CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search](https://arxiv.org/abs/2601.18625)
*Zequn Xie*

Main category: cs.CV

TL;DR: 本文提出了一种名为CONQUER的两阶段框架，用于解决基于文本的行人搜索（TBPS）任务中的跨模态不匹配和模糊查询问题，通过多粒度编码、互补对挖掘和最优传输等方法提升训练时的跨模态对齐，并在推理时通过查询增强模块自适应地优化查询，实验表明在多个数据集上效果显著。


<details>
  <summary>Details</summary>
Motivation: 文本描述搜索行人图像（TBPS）任务面临跨模态差异和用户查询模糊的问题，影响了其在公共安全领域的应用。

Method: 本文提出了一个名为CONQUER的两阶段框架。训练阶段采用多粒度编码、互补对挖掘和基于最优传输的上下文引导最优匹配来学习鲁棒的嵌入。推理阶段则通过一个即插即用的查询增强模块，利用锚点选择和属性驱动的丰富化来优化模糊或不完整的查询，无需重新训练骨干网络。

Result: CONQUER在CUHK-PEDES、ICFG-PEDES和RSTPReid数据集上进行了广泛实验，在Rank-1准确率和mAP方面均显著优于现有强基线，尤其在跨领域和不完整查询场景下表现突出。

Conclusion: CONQUER是一个实用且有效的解决方案，能够应对TBPS任务中的挑战，并为实际部署提供了改进方案。

Abstract: Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER.

</details>


### [230] [Are Video Generation Models Geographically Fair? An Attraction-Centric Evaluation of Global Visual Knowledge](https://arxiv.org/abs/2601.18698)
*Xiao Liu,Jiawei Zhang*

Main category: cs.CV

TL;DR: 该研究通过一种名为GAP的新评估框架，系统地评估了文本到视频生成模型（特别是Sora 2）在地理视觉知识方面的公平性。结果显示，Sora 2在不同地区、发达程度和文化群体之间表现出相对均匀的地理视觉知识，挑战了普遍存在的地理偏见假设。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成模型在生成视觉内容方面取得了显著进展，但其编码的地理视觉知识是否公平尚不明确。研究旨在调查这些模型在地理公平性和地理视觉知识方面的表现。

Method: 研究引入了一种名为“Geo-Attraction Landmark Probing (GAP)”的系统性评估框架，并构建了一个包含500个全球分布的旅游景点的基准数据集GEOATTRACTION-500。GAP集成了多项互补指标，包括全局结构对齐、细粒度关键点对齐以及视觉-语言模型判断，并与人类评估进行了验证。

Result: 对Sora 2模型的评估发现，该模型在不同地区、发达程度和文化群体之间表现出相对均匀的地理视觉知识，对景点受欢迎程度的依赖性较弱。这与普遍认为的地理偏见假设相反。

Conclusion: 当前文本到视频模型比预期的更均匀地表达了全球视觉知识，这表明它们在面向全球的应用中具有潜力，同时也需要随着这类系统的发展持续进行评估。

Abstract: Recent advances in text-to-video generation have produced visually compelling results, yet it remains unclear whether these models encode geographically equitable visual knowledge. In this work, we investigate the geo-equity and geographically grounded visual knowledge of text-to-video models through an attraction-centric evaluation. We introduce Geo-Attraction Landmark Probing (GAP), a systematic framework for assessing how faithfully models synthesize tourist attractions from diverse regions, and construct GEOATTRACTION-500, a benchmark of 500 globally distributed attractions spanning varied regions and popularity levels. GAP integrates complementary metrics that disentangle overall video quality from attraction-specific knowledge, including global structural alignment, fine-grained keypoint-based alignment, and vision-language model judgments, all validated against human evaluation. Applying GAP to the state-of-the-art text-to-video model Sora 2, we find that, contrary to common assumptions of strong geographic bias, the model exhibits a relatively uniform level of geographically grounded visual knowledge across regions, development levels, and cultural groupings, with only weak dependence on attraction popularity. These results suggest that current text-to-video models express global visual knowledge more evenly than expected, highlighting both their promise for globally deployed applications and the need for continued evaluation as such systems evolve.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [231] [Crystal-KV: Efficient KV Cache Management for Chain-of-Thought LLMs via Answer-First Principle](https://arxiv.org/abs/2601.16986)
*Zihan Wang,Cheng Tang,Lei Gong,Cheng Li,Chao Wang,teng wang,Wenqi Lou,Xuehai Zhou*

Main category: cs.CL

TL;DR: Crystal-KV 是一种针对大语言模型（LLM）链式思考（CoT）推理的 KV 缓存管理框架，通过“答案优先”原则区分重要（CrystalKV）和次要（SlipKV）的推理片段，并采用基于注意力机制的 LRFU 算法和自适应缓存预算分配来优化缓存效率，从而在不牺牲准确性的前提下显著提高 CoT 推理的吞吐量和响应速度。


<details>
  <summary>Details</summary>
Motivation: 链式思考（CoT）虽然能提升 LLM 在复杂任务上的准确性，但其推理过程中产生的长序列会占用大量 KV 缓存，导致内存开销过大。现有的 KV 缓存压缩策略对 CoT 推理效果不佳，因为 CoT 任务更侧重最终答案而非所有 Token 的同等重要性。

Method: 1. 提出“答案优先”原则，通过将答案偏好映射到注意力图来区分对最终答案有贡献的 CrystalKV 和主要维持推理流程的 SlipKV。 2. 设计基于注意力机制的 LR FU（Least Recently Frequently Used）算法，精确判断 SlipKV 的失效并进行淘汰，保留 CrystalKV。 3. 开发自适应缓存预算分配算法，根据 CrystalKV 的动态比例动态调整各层/头的 KV 缓存预算，优先分配给关键组件。

Result: Crystal-KV 在 KV 缓存压缩方面取得了最先进的性能，显著提高了吞吐量，缩短了响应时间，并且在进行 CoT 推理时，保持甚至提高了答案的准确性。

Conclusion: Crystal-KV 是一种高效的 KV 缓存管理框架，能够有效地解决 CoT 推理中的内存开销问题，通过优化缓存策略在提高推理效率的同时，保证了答案的准确性。

Abstract: Chain-of-Thought (CoT) reasoning in large language models (LLMs) significantly improves accuracy on complex tasks, yet incurs excessive memory overhead due to the long think-stage sequences stored in the Key-Value (KV) cache. Unlike traditional generation tasks where all tokens are uniformly important, CoT emphasizes the final answer, rendering conventional KV compression strategies ineffective. In this paper, we present Crystal-KV, an efficient KV cache management framework tailored for CoT reasoning. Our key insight is the answer-first principle. By mapping answer preferences into think-stage attention map, we distinguish between SlipKV, which mainly maintains the reasoning flow but may occasionally introduce misleading context, and CrystalKV, which truly contributes to the correctness of the final answer. Next, we propose an attention-based Least Recently Frequently Used algorithm. It precisely identifies when a SlipKV entry's utility expires and evicts it, retaining CrystalKV without disrupting reasoning flow. Finally, we introduce an adaptive cache budget allocation algorithm. Based on the dynamic proportion of CrystalKV, it estimates the importance of each layer/head and adjusts the KV cache budget during inference, amplifying critical components to improve budget utilization. Results show that Crystal-KV achieves state-of-the-art KV cache compression, significantly improves throughput, and enables faster response time, while maintaining, or even improving, answer accuracy for CoT reasoning.

</details>


### [232] [Evaluating Reward Model Generalization via Pairwise Maximum Discrepancy Competitions](https://arxiv.org/abs/2601.16987)
*Shunyang Luo,Peibei Cao,Zhihui Zhu,Kehua Feng,Zhihua Wang,Keyan Ding*

Main category: cs.CL

TL;DR: 提出了一种名为 PMDC 的新框架，用于评估奖励模型（RM）在未见过和分布变化下的泛化能力，该框架利用未标记的提示库来动态选择最具争议的提示-响应对，以更有效地发现 RM 的系统性泛化失败。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型（RM）的评估方法依赖于静态的、预先标注的偏好数据集，这限制了其对未见提示和分布变化的泛化能力的真实评估，并且效率低下。

Method: 引入 Pairwise Maximum Discrepancy Competition (PMDC) 框架，该框架动态地从一个大型、未标记的开放领域提示池中选择最大化两个 RM 之间分歧的提示-响应对。然后，由一个“神谕”来裁决这些有争议的案例，并将结果通过 Bradley-Terry 模型进行聚合，以生成 RM 的全局排名和成对胜率。

Result: 将 PMDC 应用于 10 个代表性 RM 的重新评估，发现与传统基准相比，排名发生了显著变化。定性分析揭示了 RM 存在的系统性泛化失败。

Conclusion: PMDC 框架能够更有效地评估 RM 的泛化能力，并能发现传统方法可能忽略的系统性问题，为改进 RM 提供了有价值的见解。

Abstract: Reward models (RMs) are central to aligning large language models, yet their practical effectiveness hinges on generalization to unseen prompts and shifting distributions. Most existing RM evaluations rely on static, pre-annotated preference datasets, which provide limited coverage and often fail to faithfully assess generalization in open-world settings. We introduce Pairwise Maximum Discrepancy Competition (PMDC), a dynamic and annotation-efficient framework for evaluating RM generalization using a large, unlabeled, open-domain prompt pool. PMDC actively selects prompt--response pairs that maximize disagreement between two RMs, yielding a compact set of highly contentious test cases. These cases are adjudicated by an oracle, and the resulting outcomes are aggregated via a Bradley--Terry model to produce a global ranking and pairwise win-rate landscape of RMs. We apply PMDC to re-evaluate 10 representative RMs and observe substantial rank reshuffling compared with conventional benchmarks. Qualitative analyses further uncover systematic generalization failures, providing valuable insights for improving reward modeling.

</details>


### [233] [Uncertainty Quantification for Named Entity Recognition via Full-Sequence and Subsequence Conformal Prediction](https://arxiv.org/abs/2601.16999)
*Matthew Singer,Srijan Sengupta,Karl Pazdernik*

Main category: cs.CL

TL;DR: 本文提出了一种通用的框架，可以将现有的命名实体识别（NER）模型改编为输出不确定性感知的预测集，该预测集以用户指定的置信度保证包含正确的标签序列。该方法基于共形预测，并设计了高效的非一致性评分函数，以支持无条件和类条件覆盖，并考虑了句子长度、语言、实体类型和实体数量等异质性。在多个NER模型和数据集上的实验证明了该方法的广泛适用性、有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有NER模型通常只输出一个预测标签序列，缺乏不确定性度量，这使得下游应用容易受到级联错误的影响。研究动机是为NER模型提供一种输出不确定性感知预测集的方法，以提高预测的可靠性。

Method: 该研究提出了一种基于共形预测的通用框架，用于将基于序列标注的NER模型改编为输出不确定性感知预测集。该框架设计了高效的非一致性评分函数，以构建支持无条件和类条件覆盖的预测集，并能处理句子长度、语言、实体类型和实体数量等异质性。

Result: 在四个NER模型和三个基准数据集上的实证研究表明，该方法具有广泛的适用性，能够生成有效且校准良好的预测集，提供正式的可靠性保证。

Conclusion: 所提出的框架能够有效地为NER模型提供不确定性度量，生成具有形式化保证的预测集，提高了NER预测的可靠性，并证明了其在不同模型和数据集上的通用性。

Abstract: Named Entity Recognition (NER) serves as a foundational component in many natural language processing (NLP) pipelines. However, current NER models typically output a single predicted label sequence without any accompanying measure of uncertainty, leaving downstream applications vulnerable to cascading errors. In this paper, we introduce a general framework for adapting sequence-labeling-based NER models to produce uncertainty-aware prediction sets. These prediction sets are collections of full-sentence labelings that are guaranteed to contain the correct labeling with a user-specified confidence level. This approach serves a role analogous to confidence intervals in classical statistics by providing formal guarantees about the reliability of model predictions. Our method builds on conformal prediction, which offers finite-sample coverage guarantees under minimal assumptions. We design efficient nonconformity scoring functions to construct efficient, well-calibrated prediction sets that support both unconditional and class-conditional coverage. This framework accounts for heterogeneity across sentence length, language, entity type, and number of entities within a sentence. Empirical experiments on four NER models across three benchmark datasets demonstrate the broad applicability, validity, and efficiency of the proposed methods.

</details>


### [234] [RAM-SD: Retrieval-Augmented Multi-agent framework for Sarcasm Detection](https://arxiv.org/abs/2601.17002)
*Ziyang Zhou,Ziqi Liu,Yan Wang,Yiming Lin,Yangbin Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为RAM-SD（检索增强多智能体框架）的新型讽刺检测框架，通过检索、元规划、多智能体分析和集成四个阶段，实现了最先进的性能，并提供了可解释的推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有讽刺检测方法采用统一的推理策略，无法应对讽刺表达的多样性，难以捕捉上下文、世界知识和语言线索的细微差别。

Method: RAM-SD框架包含四个阶段：1. 上下文检索，检索相关的讽刺和非讽刺示例；2. 元规划器，分类讽刺类型并选择推理计划；3. 专用智能体集成，进行多视角互补分析；4. 集成器，综合分析并生成可解释的判断和自然语言解释。

Result: 在四个标准基准测试中，RAM-SD达到了77.74%的Macro-F1，比GPT-4o+CoC基线高出7.01个百分点，取得了最先进的性能。

Conclusion: RAM-SD不仅设定了讽刺检测的新性能标杆，还通过提供透明可解释的推理过程，阐明了理解讽刺的认知机制。

Abstract: Sarcasm detection remains a significant challenge due to its reliance on nuanced contextual understanding, world knowledge, and multi-faceted linguistic cues that vary substantially across different sarcastic expressions. Existing approaches, from fine-tuned transformers to large language models, apply a uniform reasoning strategy to all inputs, struggling to address the diverse analytical demands of sarcasm. These demands range from modeling contextual expectation violations to requiring external knowledge grounding or recognizing specific rhetorical patterns. To address this limitation, we introduce RAM-SD, a Retrieval-Augmented Multi-Agent framework for Sarcasm Detection. The framework operates through four stages: (1) contextual retrieval grounds the query in both sarcastic and non-sarcastic exemplars; (2) a meta-planner classifies the sarcasm type and selects an optimal reasoning plan from a predefined set; (3) an ensemble of specialized agents performs complementary, multi-view analysis; and (4) an integrator synthesizes these analyses into a final, interpretable judgment with a natural language explanation. Evaluated on four standard benchmarks, RAM-SD achieves a state-of-the-art Macro-F1 of 77.74%, outperforming the strong GPT-4o+CoC baseline by 7.01 points. Our framework not only sets a new performance benchmark but also provides transparent and interpretable reasoning traces, illuminating the cognitive processes behind sarcasm comprehension.

</details>


### [235] [From Emotion to Expression: Theoretical Foundations and Resources for Fear Speech](https://arxiv.org/abs/2601.17132)
*Vigneshwaran Shankaran,Gabriella Lapesa,Claudia Wagner*

Main category: cs.CL

TL;DR: 本文旨在整合跨学科视角，为计算语言学中“恐惧言论”的研究提供理论和实践指导，包括回顾相关理论、现有定义、数据集，并提出一个分类体系。


<details>
  <summary>Details</summary>
Motivation: 当前计算语言学领域对恐惧言论的研究分散且资源不足，而恐惧言论因其“文明”外观和规避审查的能力，在传播和互动方面常优于仇恨言论，因此需要系统性的研究。

Method: 本文通过梳理心理学、政治学、传播学和语言学中关于恐惧的理论，回顾现有定义，调查相关研究领域的数据集，并提出一个用于研究恐惧言论的分类体系。

Result: 本文整合了跨学科理论，提供了对恐惧言论概念的清晰界定，并分析了现有数据集的状况，提出了一个结构化的分类体系。

Conclusion: 本文的理论和实践指导有助于未来构建新的数据集，并推动对恐惧言论这一复杂现象的计算研究。

Abstract: Few forces rival fear in their ability to mobilize societies, distort communication, and reshape collective behavior. In computational linguistics, fear is primarily studied as an emotion, but not as a distinct form of speech. Fear speech content is widespread and growing, and often outperforms hate-speech content in reach and engagement because it appears "civiler" and evades moderation. Yet the computational study of fear speech remains fragmented and under-resourced. This can be understood by recognizing that fear speech is a phenomenon shaped by contributions from multiple disciplines. In this paper, we bridge cross-disciplinary perspectives by comparing theories of fear from Psychology, Political science, Communication science, and Linguistics. Building on this, we review existing definitions. We follow up with a survey of datasets from related research areas and propose a taxonomy that consolidates different dimensions of fear for studying fear speech. By reviewing current datasets and defining core concepts, our work offers both theoretical and practical guidance for creating datasets and advancing fear speech research.

</details>


### [236] [Dynamic Role Assignment for Multi-Agent Debate](https://arxiv.org/abs/2601.17152)
*Miao Zhang,Junsik Kim,Siyuan Xiang,Jian Gao,Cheng Cao*

Main category: cs.CL

TL;DR: 本文提出了一种动态角色分配框架，通过一个元辩论来选择最适合特定角色的模型，以提升多智能体LLM/VLM辩论系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体LLM/VLM辩论系统虽然使用了专业角色，但未能有效利用模型的特长来分配这些角色。

Method: 提出了一种名为“动态角色分配”的框架，包含一个两阶段的元辩论：1. 提案阶段，候选模型提供针对角色的论点；2. 同行评审阶段，根据数据和角色特定标准对提案进行评分，从而选出最合适的模型担任每个角色。

Result: 在LLM问题解决基准上进行评估，该方法在应用后，相比于均匀分配（所有角色由同一模型担任）可提高高达74.8%，相比于随机分配（不考虑模型适用性）可提高高达29.7%，具体效果取决于任务和分配方式。

Conclusion: 该研究开创了多智能体系统设计的新范式，将代理的部署从静态模式转变为动态的、基于能力感知的选择模式。

Abstract: Multi-agent large language model (LLM) and vision-language model (VLM) debate systems employ specialized roles for complex problem-solving, yet model specializations are not leveraged to decide which model should fill which role. We propose dynamic role assignment, a framework that runs a Meta-Debate to select suitable agents before the actual debate. The meta-debate has two stages: (1) proposal, where candidates provide role-tailored arguments, and (2) peer review, where proposals are scored with data and role-specific criteria to choose the best agent for each position. We evaluate our method on LLM problem solving benchmarks. Applied on top of existing debate systems, our approach consistently outperforms uniform assignments (filling all roles with the same model) by up to 74.8% and random assignments (assigning models to roles without considering their suitability) by up to 29.7%, depending on the task and the specific assignment. This work establishes a new paradigm for multi-agent system design, shifting from static agent deployment to dynamic and capability-aware selection.

</details>


### [237] [Interpretability of the Intent Detection Problem: A New Approach](https://arxiv.org/abs/2601.17156)
*Eduardo Sanchez-Karhunen,Jose F. Quesada-Moreno,Miguel A. Gutiérrez-Naranjo*

Main category: cs.CL

TL;DR: 本研究运用动力学系统理论，通过分析RNN在SNIPS和ATIS数据集上的隐藏状态空间轨迹，揭示了RNN解决意图检测任务的内部机制，并解释了类别不平衡如何影响其性能。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习，特别是RNN，在意图检测中占据主导地位，但其内部工作原理仍不被充分理解。本研究旨在深入探究RNN解决意图检测任务的机制。

Method: 研究应用动力学系统理论，将句子解释为隐藏状态空间中的轨迹。在平衡的SNIPS数据集上分析理想解，然后将该框架应用于不平衡的ATIS数据集，观察类别不平衡的影响。

Result: 在平衡的SNIPS数据集上，RNN学习到了一个理想的几何解决方案：隐藏状态空间被划分为对应不同意图的聚类。在不平衡的ATIS数据集上，类别不平衡导致了低频意图的聚类质量下降，扭曲了理想的几何解决方案。

Conclusion: 本研究提出了一个新颖的机制性解释，将几何分离与读出对齐解耦，解释了真实世界中意图检测性能的差异。研究结果为理解RNN动力学提供了新的视角，并从几何角度解释了数据集特性如何直接影响网络的计算解决方案。

Abstract: Intent detection, a fundamental text classification task, aims to identify and label the semantics of user queries, playing a vital role in numerous business applications. Despite the dominance of deep learning techniques in this field, the internal mechanisms enabling Recurrent Neural Networks (RNNs) to solve intent detection tasks are poorly understood. In this work, we apply dynamical systems theory to analyze how RNN architectures address this problem, using both the balanced SNIPS and the imbalanced ATIS datasets. By interpreting sentences as trajectories in the hidden state space, we first show that on the balanced SNIPS dataset, the network learns an ideal solution: the state space, constrained to a low-dimensional manifold, is partitioned into distinct clusters corresponding to each intent. The application of this framework to the imbalanced ATIS dataset then reveals how this ideal geometric solution is distorted by class imbalance, causing the clusters for low-frequency intents to degrade. Our framework decouples geometric separation from readout alignment, providing a novel, mechanistic explanation for real world performance disparities. These findings provide new insights into RNN dynamics, offering a geometric interpretation of how dataset properties directly shape a network's computational solution.

</details>


### [238] [Who Gets Which Message? Auditing Demographic Bias in LLM-Generated Targeted Text](https://arxiv.org/abs/2601.17172)
*Tunazzina Islam*

Main category: cs.CL

TL;DR: 研究了大型语言模型（LLMs）在生成针对不同人群的个性化信息时，如何表现出与年龄和性别相关的偏见，这些偏见在有上下文的情况下会被放大，尤其是在气候沟通领域。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs生成个性化、有说服力文本的能力增强，其在自动化通信中的偏见和公平性问题日益凸显，需要系统性地分析LLMs在进行人口统计条件下的定向信息生成时的行为。

Method: 使用GPT-4o、Llama-3.3和Mistral-Large 2.1三个领先模型，在独立生成和情境丰富生成两种设置下，通过词汇内容、语言风格和说服性框架三个维度，评估其生成的气候沟通信息，并量化分析。

Result: 所有模型在根据年龄和性别生成信息时，都表现出一致的差异：针对男性和年轻人的信息侧重于能动性、创新和果断，而针对女性和老年人的信息则强调温暖、关怀和传统。情境提示会系统性地放大这些差异，对年轻人或男性受众的定向信息的说服力得分显著更高。

Conclusion: LLMs在生成定向信息时会显现并加剧人口统计刻板印象，凸显了在社会敏感应用中，开发偏见感知生成流程和透明审计框架的必要性，以明确考虑人口统计条件的作用。

Abstract: Large language models (LLMs) are increasingly capable of generating personalized, persuasive text at scale, raising new questions about bias and fairness in automated communication. This paper presents the first systematic analysis of how LLMs behave when tasked with demographic-conditioned targeted messaging. We introduce a controlled evaluation framework using three leading models -- GPT-4o, Llama-3.3, and Mistral-Large 2.1 -- across two generation settings: Standalone Generation, which isolates intrinsic demographic effects, and Context-Rich Generation, which incorporates thematic and regional context to emulate realistic targeting. We evaluate generated messages along three dimensions: lexical content, language style, and persuasive framing. We instantiate this framework on climate communication and find consistent age- and gender-based asymmetries across models: male- and youth-targeted messages emphasize agency, innovation, and assertiveness, while female- and senior-targeted messages stress warmth, care, and tradition. Contextual prompts systematically amplify these disparities, with persuasion scores significantly higher for messages tailored to younger or male audiences. Our findings demonstrate how demographic stereotypes can surface and intensify in LLM-generated targeted communication, underscoring the need for bias-aware generation pipelines and transparent auditing frameworks that explicitly account for demographic conditioning in socially sensitive applications.

</details>


### [239] [Beyond Factual QA: Mentorship-Oriented Question Answering over Long-Form Multilingual Content](https://arxiv.org/abs/2601.17173)
*Parth Bhalerao,Diola Dsouza,Ruiwen Guan,Oana Ignat*

Main category: cs.CL

TL;DR: 本文提出了MentorQA，一个多语言的长视频问答数据集和评估框架，用于评估提供反思和指导的“指导式”问答，超越了传统的事实正确性评估。通过实验发现，多智能体（Multi-Agent）问答架构在生成指导式问答方面表现优于其他架构，尤其是在复杂主题和低资源语言上。


<details>
  <summary>Details</summary>
Motivation: 现有的问答系统评估主要关注事实正确性，而忽略了在教育和职业指导等实际应用中至关重要的“指导式”（提供反思和指导）问答。现有数据集很少能捕捉这种区别，尤其是在多语言和长篇内容场景下。

Method: 构建了一个名为MentorQA的多语言数据集，包含近9000个问答对，覆盖180小时的四种语言的长视频内容。定义了超越事实准确性的指导式问答评估维度，包括清晰度、一致性和学习价值。在MentorQA数据集上，比较了单智能体、双智能体、RAG和多智能体四种问答架构的性能，并分析了基于LLM的自动评估与人类判断的一致性。

Result: 多智能体问答管道在生成指导式问答方面始终获得更高的质量，在处理复杂主题和低资源语言时尤其表现出色。基于LLM的自动评估在与人类判断的一致性方面存在显著变异。

Conclusion: 这项工作将指导式问答确立为一个独特的研究问题，并提供了一个多语言基准，用于研究教育AI中的智能体架构和评估设计。MentorQA数据集和评估框架已开源。

Abstract: Question answering systems are typically evaluated on factual correctness, yet many real-world applications-such as education and career guidance-require mentorship: responses that provide reflection and guidance. Existing QA benchmarks rarely capture this distinction, particularly in multilingual and long-form settings. We introduce MentorQA, the first multilingual dataset and evaluation framework for mentorship-focused question answering from long-form videos, comprising nearly 9,000 QA pairs from 180 hours of content across four languages. We define mentorship-focused evaluation dimensions that go beyond factual accuracy, capturing clarity, alignment, and learning value. Using MentorQA, we compare Single-Agent, Dual-Agent, RAG, and Multi-Agent QA architectures under controlled conditions. Multi-Agent pipelines consistently produce higher-quality mentorship responses, with especially strong gains for complex topics and lower-resource languages. We further analyze the reliability of automated LLM-based evaluation, observing substantial variation in alignment with human judgments. Overall, this work establishes mentorship-focused QA as a distinct research problem and provides a multilingual benchmark for studying agentic architectures and evaluation design in educational AI. The dataset and evaluation framework are released at https://github.com/AIM-SCU/MentorQA.

</details>


### [240] [Systematicity between Forms and Meanings across Languages Supports Efficient Communication](https://arxiv.org/abs/2601.17181)
*Doreen Osmelak,Yang Xu,Michael Hahn,Kate McCurdy*

Main category: cs.CL

TL;DR: 本研究通过分析不同语言中动词和代词的语法意义（如人称、数）表达方式，提出了一种基于学习可性的新复杂度度量，以解释语言形式中的系统性规律，并连接了高效沟通理论与语言形式。


<details>
  <summary>Details</summary>
Motivation: 现有理论认为语言形式的映射是为了高效沟通，但未能解释词语内部的系统性关系。因此，本研究旨在探索语法意义映射到词语形式的系统性，并提出新的理论解释。

Method: 研究分析了类型学上不同的语言中，动词和代词如何表达有限的语法意义（如人称、数）。作者提出了一种新颖的复杂度度量，该度量基于意义到形式映射的可学习性，并将其与通信的简易性和准确性相权衡。

Result: 研究发现，动词和代词的形式确实受到简易性和准确性之间权衡的影响。提出的基于学习可性的复杂度度量能够捕捉到语言形式的细微规律，并能更好地区分已有的和不存在的语言系统。

Conclusion: 本研究成功地将高效沟通理论与自然语言的系统性联系起来，并提出了一种新的复杂度度量方法，为理解语言形式提供了新的视角。

Abstract: Languages vary widely in how meanings map to word forms. These mappings have been found to support efficient communication; however, this theory does not account for systematic relations within word forms. We examine how a restricted set of grammatical meanings (e.g. person, number) are expressed on verbs and pronouns across typologically diverse languages. Consistent with prior work, we find that verb and pronoun forms are shaped by competing communicative pressures for simplicity (minimizing the inventory of grammatical distinctions) and accuracy (enabling recovery of intended meanings). Crucially, our proposed model uses a novel measure of complexity (inverse of simplicity) based on the learnability of meaning-to-form mappings. This innovation captures fine-grained regularities in linguistic form, allowing better discrimination between attested and unattested systems, and establishes a new connection from efficient communication theory to systematicity in natural language.

</details>


### [241] [Reasoning Beyond Literal: Cross-style Multimodal Reasoning for Figurative Language Understanding](https://arxiv.org/abs/2601.17197)
*Seyyed Saeid Cheshmi,Hahnemann Ortiz,James Mooney,Dongyeop Kang*

Main category: cs.CL

TL;DR: 本文提出了一种三步框架，用于开发能够理解、解释多模态比喻语言、提供透明推理过程并能泛化到多种比喻风格的高效多模态推理模型。实验表明，加入推理过程可以显著提高理解能力，一种风格中学到的推理可以迁移到其他风格，跨风格联合训练的模型在性能上优于现有的大型模型。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在处理文字表面的多模态任务上表现良好，但难以理解诸如讽刺、幽默和隐喻等比喻性语言，因为这些语言依赖于细微的意义不一致性来传达意图和情感。多模态设置下，图像的加入可能放大或颠覆文本含义，需要模型能够进行跨模态推理并考虑主观性。

Method: 提出一个三步框架，包括：(1) 解释多模态比喻语言；(2) 提供透明的推理过程；(3) 泛化到多种比喻风格。在四种比喻风格上进行实验。

Result: 1. 引入推理过程能显著提升多模态比喻理解能力。
2. 在一种风格上学到的推理可以迁移到其他风格，尤其是在讽刺和幽默等相关风格之间。
3. 跨风格联合训练的模型能够实现泛化，其性能优于许多大型开源和闭源模型。

Conclusion: 轻量级的VLMs结合可验证的推理，可以在多模态任务上实现鲁棒的跨风格泛化，并提供可检查的推理过程。

Abstract: Vision-language models (VLMs) have demonstrated strong reasoning abilities in literal multimodal tasks such as visual mathematics and science question answering. However, figurative language, such as sarcasm, humor, and metaphor, remains a significant challenge, as it conveys intent and emotion through subtle incongruities between expressed and intended meanings. In multimodal settings, accompanying images can amplify or invert textual meaning, demanding models that reason across modalities and account for subjectivity. We propose a three-step framework for developing efficient multimodal reasoning models that can (i) interpret multimodal figurative language, (ii) provide transparent reasoning traces, and (iii) generalize across multiple figurative styles. Experiments across four styles show that (1) incorporating reasoning traces substantially improves multimodal figurative understanding, (2) reasoning learned in one style can transfer to others, especially between related styles like sarcasm and humor, and (3) training jointly across styles yields a generalized reasoning VLM that outperforms much larger open- and closed-source models. Our findings show that lightweight VLMs with verifiable reasoning achieve robust cross-style generalization while providing inspectable reasoning traces for multimodal tasks. The code and implementation are available at https://github.com/scheshmi/CrossStyle-MMR.

</details>


### [242] [Relating Word Embedding Gender Biases to Gender Gaps: A Cross-Cultural Analysis](https://arxiv.org/abs/2601.17203)
*Scott Friedman,Sonja Schmer-Galunder,Anthony Chen,Jeffrey Rye*

Main category: cs.CL

TL;DR: 本文提出了一种量化词嵌入中的性别偏见并利用其来表征教育、政治、经济和健康领域的统计性别差距的方法，并通过 2018 年的 Twitter 数据进行了验证，研究了词嵌入偏见与性别差距之间的相关性和预测能力。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习模型中存在的偏见受到关注并被尝试纠正，但这些偏见可能反映了产生训练文本的文化中的实际性别差距，这有助于通过大数据来理解文化背景。

Method: 首先，提出了一种量化词嵌入中性别偏见的方法。然后，利用这些量化指标来表征教育、政治、经济和健康领域的统计性别差距。最后，通过 2018 年覆盖 51 个美国地区和 99 个国家的 Twitter 数据来验证这些指标，并分析词嵌入偏见与统计性别差距之间的相关性和预测能力。

Result: 通过对 2018 年 Twitter 数据进行分析，研究发现词嵌入中的性别偏见与 18 个国际性别差距指标和 5 个美国性别差距指标之间存在相关性，并表征了其中的规律性和预测能力。

Conclusion: 量化词嵌入中的性别偏见可以作为一种有价值的工具，用于理解和表征现实世界中的统计性别差距，并可能揭示文化背景的某些规律。

Abstract: Modern models for common NLP tasks often employ machine learning techniques and train on journalistic, social media, or other culturally-derived text. These have recently been scrutinized for racial and gender biases, rooting from inherent bias in their training text. These biases are often sub-optimal and recent work poses methods to rectify them; however, these biases may shed light on actual racial or gender gaps in the culture(s) that produced the training text, thereby helping us understand cultural context through big data. This paper presents an approach for quantifying gender bias in word embeddings, and then using them to characterize statistical gender gaps in education, politics, economics, and health. We validate these metrics on 2018 Twitter data spanning 51 U.S. regions and 99 countries. We correlate state and country word embedding biases with 18 international and 5 U.S.-based statistical gender gaps, characterizing regularities and predictive strength.

</details>


### [243] [DF-RAG: Query-Aware Diversity for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.17212)
*Saadat Hasan Khan,Spencer Hong,Jingyu Wu,Kevin Lybarger,Youbing Yin,Erin Babinsky,Daben Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为 DF-RAG 的检索增强生成方法，通过在检索阶段引入多样性来提高模型在复杂推理问答任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）方法在处理推理密集型问答时面临挑战，因为常用的相关性最大化检索方法会导致冗余内容，从而降低信息召回率。

Method: DF-RAG 基于最大边际相关性（MMR）框架，在检索时选择既与查询相关又彼此高度不相似的信息块。其创新之处在于能够动态地为每个查询优化多样性水平，无需额外微调或先验知识。

Result: DF-RAG 在推理密集型问答基准测试中，F1 分数比使用余弦相似度的普通 RAG 提高了 4-10 个百分点，并且优于其他基线方法。此外，DF-RAG 捕获了普通 RAG 最高可达 18% 的绝对 F1 提升中的 91.3%。

Conclusion: DF-RAG 通过在检索阶段系统地引入多样性，有效解决了 RAG 在推理密集型问答任务上的局限性，显著提升了性能，并展现了巨大的改进潜力。

Abstract: Retrieval-augmented generation (RAG) is a common technique for grounding language model outputs in domain-specific information. However, RAG is often challenged by reasoning-intensive question-answering (QA), since common retrieval methods like cosine similarity maximize relevance at the cost of introducing redundant content, which can reduce information recall. To address this, we introduce Diversity-Focused Retrieval-Augmented Generation (DF-RAG), which systematically incorporates diversity into the retrieval step to improve performance on complex, reasoning-intensive QA benchmarks. DF-RAG builds upon the Maximal Marginal Relevance framework to select information chunks that are both relevant to the query and maximally dissimilar from each other. A key innovation of DF-RAG is its ability to optimize the level of diversity for each query dynamically at test time without requiring any additional fine-tuning or prior information. We show that DF-RAG improves F1 performance on reasoning-intensive QA benchmarks by 4-10 percent over vanilla RAG using cosine similarity and also outperforms other established baselines. Furthermore, we estimate an Oracle ceiling of up to 18 percent absolute F1 gains over vanilla RAG, of which DF-RAG captures up to 91.3 percent.

</details>


### [244] [Beyond Outcome Verification: Verifiable Process Reward Models for Structured Reasoning](https://arxiv.org/abs/2601.17223)
*Massimiliano Pronesti,Anya Belz,Yufang Hou*

Main category: cs.CL

TL;DR: 本文提出了一种名为可验证过程奖励模型（VPRMs）的新框架，该框架使用确定性的、基于规则的验证器来检查大型语言模型（LLMs）的中间推理步骤，以解决现有过程监督方法中神经判别器的局限性，并将其应用于医疗证据综合中的偏倚风险评估。


<details>
  <summary>Details</summary>
Motivation: 现有针对大型语言模型（LLMs）的过程监督方法依赖于易产生不透明、偏见和奖励攻击的神经判别器。为了解决这一问题，研究者希望开发一种能够对LLMs的中间推理过程进行可验证检查的框架。

Method: 研究者提出了一种名为可验证过程奖励模型（VPRMs）的强化学习框架。该框架使用确定性的、基于规则的验证器来审查LLMs的中间推理步骤，而不是依赖神经判别器。VPRMs被应用于医疗证据综合中的偏倚风险评估领域。

Result: 在多个数据集上，VPRMs生成的推理与领域规则高度一致，并且步骤级决策与最终标签之间的一致性得到显著提高。结果显示，VPRMs比最先进的模型实现了高达20%的F1分数提升，比可验证结果奖励模型高6.5%，并在证据接地和逻辑一致性方面取得了显著进步。

Conclusion: VPRMs框架通过引入确定性的、基于规则的中间步骤验证，成功地改进了LLMs在复杂任务中的推理能力，特别是在需要严格遵循领域规则和进行偏倚风险评估的场景下，能够生成更准确、更具逻辑一致性且更易于解释的结果。

Abstract: Recent work on reinforcement learning with verifiable rewards (RLVR) has shown that large language models (LLMs) can be substantially improved using outcome-level verification signals, such as unit tests for code or exact-match checks for mathematics. In parallel, process supervision has long been explored as a way to shape the intermediate reasoning behaviour of LLMs, but existing approaches rely on neural judges to score chain-of-thought steps, leaving them vulnerable to opacity, bias, and reward hacking. To address this gap, we introduce Verifiable Process Reward Models (VPRMs), a reinforcement-learning framework in which intermediate reasoning steps are checked by deterministic, rule-based verifiers. We apply VPRMs to risk-of-bias assessment for medical evidence synthesis, a domain where guideline-defined criteria and rule-based decision paths enable programmatic verification of reasoning traces. Across multiple datasets, we find that VPRMs generate reasoning that adheres closely to domain rules and achieve substantially higher coherence between step-level decisions and final labels. Results show that VPRMs achieve up to 20% higher F1 than state-of-the-art models and 6.5% higher than verifiable outcome rewards, with substantial gains in evidence grounding and logical coherence.

</details>


### [245] [Retell, Reward, Repeat: Reinforcement Learning for Narrative Theory-Informed Story Generation](https://arxiv.org/abs/2601.17226)
*David Y. Liu,Xanthe Muston,Aditya Joshi,Sebastian Sequoiah-Grayson*

Main category: cs.CL

TL;DR: 本研究提出了一种基于强化学习（d-RLAIF）的自动故事生成（ASG）方法，作为监督微调（SFT）的替代方案，旨在提升故事的多样性和叙事规范性。


<details>
  <summary>Details</summary>
Motivation: 以往的自动故事生成方法依赖有限的真实数据进行训练和评估，而故事生成本身具有主观性，因此需要探索新的方法来提升生成故事的质量和多样性。

Method: 研究者首先应用 Todorov 的叙事平衡理论来定义理想的 ASG 质量原则。然后，利用 7B 和 14B 的 LLM-as-judge 模型，结合这些原则来生成奖励信号，用于 d-RLAIF 的训练。最后，使用 Gemini-3-Flash 对训练后的模型进行评估，并与人类编写的故事进行比较。

Result: d-RLAIF 作为一种后训练方法，能够生成比 SFT 更具多样性且更符合人类叙事规范的故事。研究结果表明，d-RLAIF 是 SFT 的可行替代方案。

Conclusion: 强化学习（d-RLAIF）为自动故事生成等主观性任务提供了一种有前景的、基于语言学原则的后训练方法，能够生成更优质、更多样的故事。

Abstract: Despite the subjective nature of storytelling, past works on automatic story generation (ASG) have relied on limited ground truths for training and evaluation. In this work, we explore reinforcement learning (d-RLAIF) as a post-training alternative to supervised fine-tuning (SFT). We first apply Todorov's Theory of Narrative Equilibrium to establish principles that define desirable ASG qualities. We prompt 7B and 14B LLM-as-judge models with our principles to test alignment with human annotators and provide reward signals during d-RLAIF. We use Gemini-3-Flash to evaluate the output of our post-trained models and compare them to human-written stories from the TimeTravel dataset. We show that d-RLAIF offers a viable alternative to supervised fine-tuning (SFT)--producing stories that are more diverse and aligned with human narrative conventions. Our paper demonstrates the promise of reinforcement learning for linguistically grounded post-training for subjective tasks such as ASG.

</details>


### [246] [CaseFacts: A Benchmark for Legal Fact-Checking and Precedent Retrieval](https://arxiv.org/abs/2601.17230)
*Akshith Reddy Putta,Jacob Devasier,Chengkai Li*

Main category: cs.CL

TL;DR: 本文提出了CaseFacts，一个用于验证口语化法律声明是否符合美国最高法院判例的基准数据集，旨在弥合通俗语言与专业法律术语之间的语义鸿沟，并考虑时间有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动事实核查大多集中在一般知识的静态语料库验证，忽略了法律等高风险、动态且技术复杂的领域。

Method: 使用多阶段流程，结合大型语言模型（LLMs）从专家案例摘要中生成声明，并采用新颖的语义相似度启发式方法来识别和验证复杂的法律推翻。

Result: 实验表明，即使是先进的LLMs在处理此任务时仍面临挑战；特别地，通过非限制性网络搜索增强模型反而会降低性能，因为检索到的先例可能嘈杂且非权威。

Conclusion: CaseFacts数据集的发布旨在推动法律事实核查系统的研究，强调了在法律领域事实核查的复杂性以及现有LLMs的局限性。

Abstract: Automated Fact-Checking has largely focused on verifying general knowledge against static corpora, overlooking high-stakes domains like law where truth is evolving and technically complex. We introduce CaseFacts, a benchmark for verifying colloquial legal claims against U.S. Supreme Court precedents. Unlike existing resources that map formal texts to formal texts, CaseFacts challenges systems to bridge the semantic gap between layperson assertions and technical jurisprudence while accounting for temporal validity. The dataset consists of 6,294 claims categorized as Supported, Refuted, or Overruled. We construct this benchmark using a multi-stage pipeline that leverages Large Language Models (LLMs) to synthesize claims from expert case summaries, employing a novel semantic similarity heuristic to efficiently identify and verify complex legal overrulings. Experiments with state-of-the-art LLMs reveal that the task remains challenging; notably, augmenting models with unrestricted web search degrades performance compared to closed-book baselines due to the retrieval of noisy, non-authoritative precedents. We release CaseFacts to spur research into legal fact verification systems.

</details>


### [247] [Frame-Guided Synthetic Claim Generation for Automatic Fact-Checking Using High-Volume Tabular Data](https://arxiv.org/abs/2601.17232)
*Jacob Devasier,Akshith Putta,Qing Wang,Alankrit Moses,Chengkai Li*

Main category: cs.CL

TL;DR: 该研究提出了一个大规模、多语言的事实核查数据集，用于评估模型在处理海量结构化数据时的检索和推理能力，并展示了当前大型语言模型在该任务上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动事实核查基准数据集过于简化，未能反映真实世界中处理高容量结构化数据的挑战，因此需要一个更具挑战性的数据集来推动相关研究。

Method: 研究人员利用 OECD 的复杂表格，结合六种语义框架，生成了包含 78,503 个合成声明的大规模、多语言数据集。他们还构建了一个基于 SQL 生成的基线系统来评估模型在该数据集上的表现。

Result: 实验表明，大型语言模型并未“记住”数据集中的事实，需要进行真实的检索和推理。模型在证据检索方面存在显著瓶颈，难以在大型表格中找到正确数据。SQL 生成基线系统在该数据集上的表现具有挑战性。

Conclusion: 该数据集为解决大规模结构化数据上的事实核查问题提供了新的资源，并强调了证据检索是当前大型语言模型在该领域面临的关键挑战。

Abstract: Automated fact-checking benchmarks have largely ignored the challenge of verifying claims against real-world, high-volume structured data, instead focusing on small, curated tables. We introduce a new large-scale, multilingual dataset to address this critical gap. It contains 78,503 synthetic claims grounded in 434 complex OECD tables, which average over 500K rows each. We propose a novel, frame-guided methodology where algorithms programmatically select significant data points based on six semantic frames to generate realistic claims in English, Chinese, Spanish, and Hindi. Crucially, we demonstrate through knowledge-probing experiments that LLMs have not memorized these facts, forcing systems to perform genuine retrieval and reasoning rather than relying on parameterized knowledge. We provide a baseline SQL-generation system and show that our benchmark is highly challenging. Our analysis identifies evidence retrieval as the primary bottleneck, with models struggling to find the correct data in massive tables. This dataset provides a critical new resource for advancing research on this unsolved, real-world problem.

</details>


### [248] [PingPong: A Natural Benchmark for Multi-Turn Code-Switching Dialogues](https://arxiv.org/abs/2601.17277)
*Mohammad Rifqi Farhansyah,Hanif Muhammad Zhafran,Farid Adilazuarda,Shamsuddeen Hassan Muhammad,Maryam Ibrahim Mukhtar,Nedjma Ousidhoum,Genta Indra Winata,Ayu Purwarianti,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 本文提出了一个名为 PingPong 的多方自然对话代码转换基准数据集，包含五种语言组合（包括三语），旨在捕捉真实世界多语言交流的复杂性。与机器生成的数据相比，PingPong 数据集更自然、结构更多样化。基于该数据集，作者定义了问答、对话摘要和主题分类三个下游任务，并评估了现有先进语言模型在代码转换输入上的表现，结果表明其性能仍有待提高，强调了开发更强大 NLP 系统的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有代码转换的基准数据集未能准确反映日常交流的复杂性，多语言人群在实际沟通中普遍存在的代码转换现象需要更真实、更具挑战性的数据集来驱动 NLP 技术的发展。

Method: 构建了一个包含2-4名参与者、21,000多条消息的多方自然对话数据集 PingPong，涵盖五种语言组合（包括三语），模拟了真实对话的结构（多线程、引用早期内容）。同时，定义了问答、对话摘要和主题分类三个下游任务，并使用包括 BERT、RoBERTa 和 XLM-R 在内的多种先进语言模型在 PingPong 数据集上进行了评估。

Result: PingPong 数据集比机器生成的数据集在自然度和结构多样性（如消息长度、发言者主导性、回复距离）上表现出显著优势。现有先进语言模型在处理 PingPong 数据集上的代码转换输入时，性能仍然有限，平均 F1 分数低于在单语数据集上的表现。

Conclusion: PingPong 数据集为研究自然多方代码转换对话提供了一个重要的资源。现有 NLP 模型在处理代码转换输入方面仍存在较大差距，这表明需要进一步研究和开发能够应对真实世界多语言交流复杂性的 NLP 系统。

Abstract: Code-switching is a widespread practice among the world's multilingual majority, yet few benchmarks accurately reflect its complexity in everyday communication. We present PingPong, a benchmark for natural multi-party code-switching dialogues covering five language-combination variations, some of which are trilingual. Our dataset consists of human-authored conversations among 2 to 4 participants covering authentic, multi-threaded structures where replies frequently reference much earlier points in the dialogue. We demonstrate that our data is significantly more natural and structurally diverse than machine-generated alternatives, offering greater variation in message length, speaker dominance, and reply distance. Based on these dialogues, we define three downstream tasks: Question Answering, Dialogue Summarization, and Topic Classification. Evaluations of several state-of-the-art language models on PingPong reveal that performance remains limited on code-switched inputs, underscoring the urgent need for more robust NLP systems capable of addressing the intricacies of real-world multilingual discourse.

</details>


### [249] [Mind the Ambiguity: Aleatoric Uncertainty Quantification in LLMs for Safe Medical Question Answering](https://arxiv.org/abs/2601.17284)
*Yaokun Liu,Yifan Liu,Phoebe Mbuvi,Zelin Li,Ruichen Yao,Gawon Lim,Dong Wang*

Main category: cs.CL

TL;DR: 本研究提出了一个针对医学问答中用户查询歧义问题的解决方案，通过引入“Clarify-Before-Answer”框架，利用AU-Probe模块检测并缓解歧义，从而提高了回答准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 医学问答中用户查询的歧义性严重影响了大型语言模型的安全性和准确性，特别是在高风险的医疗场景下，这带来了显著的安全隐患。

Method: 研究将输入歧义与不确定性（AU）联系起来，构建了CV-MedBench基准测试集。在此基础上，通过分析LLM的内部激活模式发现AU是线性编码的，并提出了AU-Probe模块，一个轻量级模块，可以直接从隐藏状态检测输入歧义，无需微调LLM或多次前向传播。

Result: 提出的“Clarify-Before-Answer”框架结合AU-Probe，能够有效地检测输入歧义，并在四个开源LLM上进行了广泛实验。结果显示，与基线方法相比，该框架的平均准确率提高了9.48%。

Conclusion: 该研究提供了一个高效且鲁棒的解决方案，用于安全的医学问答，提高了健康相关应用的可靠性，通过主动请求用户澄清来增强安全性。

Abstract: The deployment of Large Language Models in Medical Question Answering is severely hampered by ambiguous user queries, a significant safety risk that demonstrably reduces answer accuracy in high-stakes healthcare settings. In this paper, we formalize this challenge by linking input ambiguity to aleatoric uncertainty (AU), which is the irreducible uncertainty arising from underspecified input. To facilitate research in this direction, we construct CV-MedBench, the first benchmark designed for studying input ambiguity in Medical QA. Using this benchmark, we analyze AU from a representation engineering perspective, revealing that AU is linearly encoded in LLM's internal activation patterns. Leveraging this insight, we introduce a novel AU-guided "Clarify-Before-Answer" framework, which incorporates AU-Probe - a lightweight module that detects input ambiguity directly from hidden states. Unlike existing uncertainty estimation methods, AU-Probe requires neither LLM fine-tuning nor multiple forward passes, enabling an efficient mechanism to proactively request user clarification and significantly enhance safety. Extensive experiments across four open LLMs demonstrate the effectiveness of our QA framework, with an average accuracy improvement of 9.48% over baselines. Our framework provides an efficient and robust solution for safe Medical QA, strengthening the reliability of health-related applications. The code is available at https://github.com/yaokunliu/AU-Med.git, and the CV-MedBench dataset is released on Hugging Face at https://huggingface.co/datasets/yaokunl/CV-MedBench.

</details>


### [250] [Meta-Judging with Large Language Models: Concepts, Methods, and Challenges](https://arxiv.org/abs/2601.17312)
*Hugo Silva,Mateus Mendes,Hugo Gonçalo Oliveira*

Main category: cs.CL

TL;DR: 本文综述了LLM作为元裁判（LLM-as-a-Meta-Judge）的最新进展，提出了一种比LLM作为裁判（LLM-as-a-Judge）更鲁棒的评估范式，并探讨了其概念基础、机制、训练方法、评估、局限性和未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有LLM作为裁判的评估方法存在对提示敏感、系统性偏见、冗长效应以及不可靠或虚构的解释等显著漏洞，这促使研究人员开发更鲁棒的LLM作为元裁判的评估范式。

Method: 本文通过对现有文献进行梳理和分析，按照六个关键视角（概念基础、元裁判机制、对齐训练方法、评估、局限性和失败模式、未来方向）来组织和介绍LLM作为元裁判的研究。

Result: LLM作为元裁判被认为是更稳定和可信的自动化评估方向，但仍存在成本、提示敏感性和共享模型偏见等挑战。

Conclusion: LLM作为元裁判为改进LLM评估提供了有前景的途径，但要实现下一代LLM评估方法，仍需解决成本、提示敏感性以及模型共享偏见等关键问题。

Abstract: Large language models (LLMs) are evolving fast and are now frequently used as evaluators, in a process typically referred to as LLM-as-a-Judge, which provides quality assessments of model outputs. However, recent research points out significant vulnerabilities in such evaluation, including sensitivity to prompts, systematic biases, verbosity effects, and unreliable or hallucinated rationales. These limitations motivated the development of a more robust paradigm, dubbed LLM-as-a-Meta-Judge. This survey reviews recent advances in meta-judging and organizes the literature, by introducing a framework along six key perspectives: (i) Conceptual Foundations, (ii) Mechanisms of Meta-Judging, (iii) Alignment Training Methods, (iv) Evaluation, (v) Limitations and Failure Modes, and (vi) Future Directions. By analyzing the limitations of LLM-as-a-Judge and summarizing recent advances in meta-judging by LLMs, we argue that LLM-as-a-Meta-Judge offers a promising direction for more stable and trustworthy automated evaluation, while highlighting remaining challenges related to cost, prompt sensitivity, and shared model biases, which must be addressed to advance the next generation of LLM evaluation methodologies.

</details>


### [251] [The Shadow Self: Intrinsic Value Misalignment in Large Language Model Agents](https://arxiv.org/abs/2601.17344)
*Chen Chen,Kim Young Il,Yuan Yang,Wenhao Su,Yilin Zhang,Xueluan Gong,Qian Wang,Yongsen Zheng,Ziyao Liu,Kwok-Yan Lam*

Main category: cs.CL

TL;DR: 研究提出了评估大型语言模型（LLM）代理内在价值失准（Intrinsic VM）风险的新框架 IMPRESS，并构建了包含真实、良性且情境化场景的基准测试。研究发现 Intrinsic VM 在多种 LLM 代理中普遍存在，并受模型动机、风险类型、规模和架构等因素影响。现有的缓解策略效果不稳定或有限。


<details>
  <summary>Details</summary>
Motivation: 现有对 LLM 安全性的评估主要关注对明确有害输入的响应或系统故障的鲁棒性，而忽略了在真实、完全良性且具有自主性的场景下 LLM 代理可能产生的价值失准问题。研究旨在填补这一空白，特别关注“失控风险”（Loss-of-Control risk）和“内在价值失准”（Intrinsic Value Misalignment）。

Method: 研究首先形式化了“失控风险”并提出了“内在价值失准”（Intrinsic VM）的概念。然后，研究设计了一个名为 IMPRESS（Intrinsic Value Misalignment Probes in REalistic Scenario Set）的场景驱动框架来系统评估该风险。他们使用多阶段 LLM 生成流程和严格的质量控制来构建包含真实、完全良性且情境化场景的基准测试。对 21 个最先进的 LLM 代理进行了评估，并进行了人工验证来确认自动化判断，同时评估了现有缓解策略的效果。

Result: 研究发现内在价值失准 (Intrinsic VM) 是 LLM 代理中普遍存在的安全风险。失准率因模型的动机、风险类型、模型规模和架构而异。解码策略和超参数的影响较小，而情境化和框架机制显著影响失准行为。现有缓解策略（如安全提示和护栏）表现出不稳定性或有限的有效性。

Conclusion: 内在价值失准 (Intrinsic VM) 是 LLM 代理面临的真实且普遍的安全风险。IMPRESS 框架能够有效地评估这一风险，并揭示了现有缓解策略的局限性。研究强调了在设计和部署 LLM 代理时，需要更深入地关注其内在价值与人类价值观的对齐。

Abstract: Large language model (LLM) agents with extended autonomy unlock new capabilities, but also introduce heightened challenges for LLM safety. In particular, an LLM agent may pursue objectives that deviate from human values and ethical norms, a risk known as value misalignment. Existing evaluations primarily focus on responses to explicit harmful input or robustness against system failure, while value misalignment in realistic, fully benign, and agentic settings remains largely underexplored. To fill this gap, we first formalize the Loss-of-Control risk and identify the previously underexamined Intrinsic Value Misalignment (Intrinsic VM). We then introduce IMPRESS (Intrinsic Value Misalignment Probes in REalistic Scenario Set), a scenario-driven framework for systematically assessing this risk. Following our framework, we construct benchmarks composed of realistic, fully benign, and contextualized scenarios, using a multi-stage LLM generation pipeline with rigorous quality control. We evaluate Intrinsic VM on 21 state-of-the-art LLM agents and find that it is a common and broadly observed safety risk across models. Moreover, the misalignment rates vary by motives, risk types, model scales, and architectures. While decoding strategies and hyperparameters exhibit only marginal influence, contextualization and framing mechanisms significantly shape misalignment behaviors. Finally, we conduct human verification to validate our automated judgments and assess existing mitigation strategies, such as safety prompting and guardrails, which show instability or limited effectiveness. We further demonstrate key use cases of IMPRESS across the AI Ecosystem. Our code and benchmark will be publicly released upon acceptance.

</details>


### [252] [Do readers prefer AI-generated Italian short stories?](https://arxiv.org/abs/2601.17363)
*Michael Farrell*

Main category: cs.CL

TL;DR: 研究发现，在意大利语短篇小说阅读偏好方面，读者对AI生成的故事（ChatGPT-4o）的评价略高于著名作家（Alberto Moravia）的作品，并且更倾向于选择AI作品，尽管差异不大，且与读者的阅读习惯和人口统计学信息无关。


<details>
  <summary>Details</summary>
Motivation: 作者希望探究读者在盲测条件下，对AI生成意大利语短篇小说与知名作家作品的偏好，挑战关于读者偏爱人类创作文学的既有假设。

Method: 研究采用盲测设置，邀请20名参与者阅读并评价三篇故事（两篇由ChatGPT-4o生成，一篇由Alberto Moravia创作），并收集了参与者的人口统计学信息和阅读习惯。通过统计分析比较了AI生成文本与人类创作文本的评价得分和偏好度。

Result: AI生成的故事文本获得了略高的平均评分，并且被更频繁地选择，但这些差异是微小的。研究未发现文本偏好与参与者的人口统计学信息或阅读习惯之间存在统计学上的显著关联。

Conclusion: 研究结果表明，读者对AI生成文本的偏好可能不亚于人类创作的文学作品，这挑战了关于读者偏爱人类创作小说的传统观念，并引发了关于在文学领域中对AI生成文本进行编辑必要性的讨论。

Abstract: This study investigates whether readers prefer AI-generated short stories in Italian over one written by a renowned Italian author. In a blind setup, 20 participants read and evaluated three stories, two created with ChatGPT-4o and one by Alberto Moravia, without being informed of their origin. To explore potential influencing factors, reading habits and demographic data, comprising age, gender, education and first language, were also collected. The results showed that the AI-written texts received slightly higher average ratings and were more frequently preferred, although differences were modest. No statistically significant associations were found between text preference and demographic or reading-habit variables. These findings challenge assumptions about reader preference for human-authored fiction and raise questions about the necessity of synthetic-text editing in literary contexts.

</details>


### [253] [Parameter Efficient Fine Tuning Llama 3.1 for Answering Arabic Legal Questions: A Case Study on Jordanian Laws](https://arxiv.org/abs/2601.17364)
*Mohammed Fasha,Bassam Hammo,Bilal Sowan,Husam Barham,Esam Nsour*

Main category: cs.CL

TL;DR: 本研究使用 LoRA 和 4 位量化技术，通过 Unsloth 框架微调了 Llama-3.1 模型，以解决约旦法律领域的阿拉伯语问答问题，并取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 探索如何针对阿拉伯语法律领域，特别是约旦法律，对大型语言模型（如 Llama-3.1）进行有效微调，以提高其问答能力和法律推理能力。

Method: 使用参数高效微调（PEFT）技术，具体是 LoRA 适配器，并结合 4 位量化模型。利用 Unsloth 框架加速和优化了训练过程。创建了一个包含 6000 个约旦法律问题-答案对的自定义数据集，并将其格式化为结构化提示。使用 BLEU 和 ROUGE 指标评估了微调模型相对于其基础版本的性能。

Result: 微调后的 Llama-3.1 模型在阿拉伯语法律问答任务上表现出改进的法律推理能力和准确性。通过量化和优化的微调策略实现了资源效率。

Conclusion: 本研究证明了大型语言模型能够有效适应阿拉伯语法律领域，并强调了针对领域特定任务进行微调的有效技术。这为在阿拉伯语法律领域应用 LLM 提供了技术支持和实践指导。

Abstract: This study uses Jordanian law as a case study to explore the fine-tuning of the Llama-3.1 large language model for Arabic question-answering. Two versions of the model - Llama-3.1-8B-bnb-4bit and Llama-3.1-8B-Instruct-bnb-4bit - were fine-tuned using parameter-efficient fine-tuning (PEFT) with LoRA adapters and 4-bit quantized models, leveraging the Unsloth framework for accelerated and resource-efficient training. A custom dataset of 6000 legal question-answer pairs was curated from Jordanian laws and formatted into structured prompts. Performance was evaluated using the BLEU and the ROUGE metrics to compare the fine-tuned models to their respective base versions. Results demonstrated improved legal reasoning and accuracy while achieving resource efficiency through quantization and optimized fine-tuning strategies. This work underscores the potential of adapting large language models for Arabic legal domains and highlights effective techniques for fine-tuning domain-specific tasks.

</details>


### [254] [Elastic Attention: Test-time Adaptive Sparsity Ratios for Efficient Transformers](https://arxiv.org/abs/2601.17367)
*Zecheng Tang,Quantong Qiu,Yi Yang,Zhiyi Hong,Haiya Xiang,Kebin Liu,Qingqing Dang,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为Elastic Attention的注意力机制，通过引入一个轻量级的Attention Router，能够动态地根据输入调整稀疏度，解决了现有混合注意力策略计算比例静态化的问题，并在长文本任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 标准注意力机制在长上下文场景下具有二次复杂度，限制了大型语言模型（LLMs）的扩展性。现有的混合注意力策略虽然提出了一种解决方案，但其计算比例是静态的，无法适应不同下游任务对稀疏度的不同敏感度。

Method: 通过集成一个轻量级的Attention Router到预训练模型中，该Router能够动态地将每个注意力头分配到不同的计算模式（稀疏或全注意力），从而动态调整整体稀疏度。

Result: 在8xA800 GPU上仅经过12小时的训练，Elastic Attention就使得模型在长上下文任务上实现了高性能和高效推理。在三个长上下文基准测试中，该方法在常用LLMs上表现出优越性。

Conclusion: Elastic Attention是一种有效的解决方案，能够动态地根据输入调整注意力机制的稀疏度，克服了现有混合注意力策略的局限性，并在长上下文LLMs的应用中取得了显著的性能提升和效率改进。

Abstract: The quadratic complexity of standard attention mechanisms poses a significant scalability bottleneck for large language models (LLMs) in long-context scenarios. While hybrid attention strategies that combine sparse and full attention within a single model offer a viable solution, they typically employ static computation ratios (i.e., fixed proportions of sparse versus full attention) and fail to adapt to the varying sparsity sensitivities of downstream tasks during inference. To address this issue, we propose Elastic Attention, which allows the model to dynamically adjust its overall sparsity based on the input. This is achieved by integrating a lightweight Attention Router into the existing pretrained model, which dynamically assigns each attention head to different computation modes. Within only 12 hours of training on 8xA800 GPUs, our method enables models to achieve both strong performance and efficient inference. Experiments across three long-context benchmarks on widely-used LLMs demonstrate the superiority of our method.

</details>


### [255] [WarrantScore: Modeling Warrants between Claims and Evidence for Substantiation Evaluation in Peer Reviews](https://arxiv.org/abs/2601.17377)
*Kiyotada Mori,Shohei Tanaka,Tosho Hirasawa,Tadashi Kozuno,Koichiro Yoshino,Yoshitaka Ushiku*

Main category: cs.CL

TL;DR: 提出了一种新的科学评审评论评估指标，通过评估论点和证据之间的逻辑推理来衡量评审意见的充分性，实验表明该方法比传统方法与人类评分的相关性更高，有助于提高同行评审效率。


<details>
  <summary>Details</summary>
Motivation: 科学同行评审面临人力资源短缺的问题，现有方法仅检测证据的存在与否不足以准确评估评审意见的充分性，特别是忽略了论点和证据之间的逻辑推理。

Method: 提出了一种新的评估科学评审评论的方法，通过提取论点的核心组成部分（论点和证据），并评估论点和证据之间的逻辑推理，从而衡量评审意见的充分性。该方法计算被证据支持的论点比例，并纳入了对逻辑推理的评估。

Result: 实验结果表明，所提出的新评估指标与人类评分具有更高的相关性，优于传统的评估方法。

Conclusion: 提出的评估科学评审评论的新指标能够更准确地反映评审意见的充分性，通过评估论点和证据之间的逻辑推理，有助于提高同行评审过程的效率。

Abstract: The scientific peer-review process is facing a shortage of human resources due to the rapid growth in the number of submitted papers. The use of language models to reduce the human cost of peer review has been actively explored as a potential solution to this challenge. A method has been proposed to evaluate the level of substantiation in scientific reviews in a manner that is interpretable by humans. This method extracts the core components of an argument, claims and evidence, and assesses the level of substantiation based on the proportion of claims supported by evidence. The level of substantiation refers to the extent to which claims are based on objective facts. However, when assessing the level of substantiation, simply detecting the presence or absence of supporting evidence for a claim is insufficient; it is also necessary to accurately assess the logical inference between a claim and its evidence. We propose a new evaluation metric for scientific review comments that assesses the logical inference between claims and evidence. Experimental results show that the proposed method achieves a higher correlation with human scores than conventional methods, indicating its potential to better support the efficiency of the peer-review process.

</details>


### [256] [Revisiting Modality Invariance in a Multilingual Speech-Text Model via Neuron-Level Analysis](https://arxiv.org/abs/2601.17387)
*Toshiki Nakai,Varsha Suresh,Vera Demberg*

Main category: cs.CL

TL;DR: 本文研究了 SeamlessM4T v2 多语言语音-文本基础模型在处理口语和书面语时，语言信息是否一致编码。研究发现模型在表示语言方面并非完全不变，尤其在语音到文本转换时，语言信息恢复困难，且模型在处理特定语言和口语时，对少数神经元的依赖性更强。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言语音-文本基础模型旨在统一处理不同语言和模态，但其内部表征在口语和书面语之间是否一致尚不清楚。

Method: 通过三个互补的分析方法：1. 使用平均精度排序识别语言和模态选择性神经元；2. 通过推理时的中位数替换干预来研究其功能作用；3. 分析跨语言和模态的激活幅度不平等性。

Result: 研究发现模型存在不完全的模态不变性。编码器表征越来越趋向于语言无关，但这使得共享解码器在构建模态无关表征时更难恢复原始语言，尤其是在语音到文本适应时。跨注意力键和值投影中观察到高度局部化的模态选择性结构。语音条件解码和非主导脚本显示出更高的激活浓度，表明对少数神经元的依赖性更强。

Conclusion: SeamlessM4T v2 在口语和书面语的语言表征上并非完全一致，存在不完全的模态不变性，尤其在语音到文本转换时。模型在处理特定模态和语言时，可能存在过度依赖少量神经元的情况，这可能导致在不同模态和语言之间的脆性增加。

Abstract: Multilingual speech-text foundation models aim to process language uniformly across both modality and language, yet it remains unclear whether they internally represent the same language consistently when it is spoken versus written. We investigate this question in SeamlessM4T v2 through three complementary analyses that probe where language and modality information is encoded, how selective neurons causally influence decoding, and how concentrated this influence is across the network. We identify language- and modality-selective neurons using average-precision ranking, investigate their functional role via median-replacement interventions at inference time, and analyze activation-magnitude inequality across languages and modalities. Across experiments, we find evidence of incomplete modality invariance. Although encoder representations become increasingly language-agnostic, this compression makes it more difficult for the shared decoder to recover the language of origin when constructing modality-agnostic representations, particularly when adapting from speech to text. We further observe sharply localized modality-selective structure in cross-attention key and value projections. Finally, speech-conditioned decoding and non-dominant scripts exhibit higher activation concentration, indicating heavier reliance on a small subset of neurons, which may underlie increased brittleness across modalities and languages.

</details>


### [257] [CLM-Bench: Benchmarking and Analyzing Cross-lingual Misalignment of LLMs in Knowledge Editing](https://arxiv.org/abs/2601.17397)
*Yucheng Hu,Wei Zhou,Juesi Xiao*

Main category: cs.CL

TL;DR: 本文提出了一种名为 CLM-Bench 的文化感知型多语言知识编辑（MKE）基准测试，以解决现有 MKE 评估框架存在的偏差问题。研究发现，主流 LLM 在跨语言知识编辑方面存在“跨语言错位”现象，即在一个语言上的编辑操作无法有效迁移到另一种语言。作者通过几何学方法解释了这一现象，并强调了文化原生基准测试的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有 MKE 基准测试通过机械翻译英语数据集构建，引入了翻译误差且忽略了目标语言的原生文化实体，未能真实反映 LLM 的知识分布，阻碍了 MKE 的发展。

Method: 提出了 CLM-Bench，采用“中文优先”的原生方法构建了 1010 个高质量的、源于中国文化背景的 CounterFact 对，并将其与英文对应项对齐。使用 CLM-Bench 对 Llama-3、Qwen2 等 LLM 进行了实验，并通过层级表示分析提供几何学解释。

Result: 实验揭示了显著的“跨语言错位”现象：在一个语言上的编辑独立于另一种语言，无法迁移。几何学分析表明，中文和英文的编辑向量近乎正交，位于不相交的子空间，而混合语言编辑则表现出向量的线性可加性。

Conclusion: 当前 MKE 方法在跨语言迁移方面的有效性受到质疑，强调了使用文化原生基准测试的重要性，以更准确地评估和改进多语言知识编辑能力。

Abstract: Knowledge Editing (KE) has emerged as a promising paradigm for updating facts in Large Language Models (LLMs) without retraining. However, progress in Multilingual Knowledge Editing (MKE) is currently hindered by biased evaluation frameworks. We observe that existing MKE benchmarks are typically constructed by mechanically translating English-centric datasets into target languages (e.g., English-to-Chinese). This approach introduces translation artifacts and neglects culturally specific entities native to the target language, failing to reflect the true knowledge distribution of LLMs. To address this, we propose CLM-Bench, a culture-aware benchmark constructed using a native Chinese-first methodology. We curate 1,010 high-quality CounterFact pairs rooted in Chinese cultural contexts and align them with English counterparts. Using CLM-Bench, we conduct extensive experiments on representative LLMs (e.g., Llama-3, Qwen2) and reveal a significant Cross-lingual Misalignment: edits in one language function independently and fail to propagate to the other. We further provide a geometric explanation via layer-wise representation analysis, demonstrating that edit vectors for Chinese and English are nearly orthogonal -- residing in disjoint subspaces -- while mixed-lingual editing exhibits linear additivity of these vectors. Our findings challenge the effectiveness of current methods in cross-lingual transfer and underscore the importance of culturally native benchmarks.

</details>


### [258] [Oops, Wait: Token-Level Signals as a Lens into LLM Reasoning](https://arxiv.org/abs/2601.17421)
*Jaehui Hwang,Dongyoon Han,Sangdoo Yun,Byeongho Heo*

Main category: cs.CL

TL;DR: 本文分析了大型语言模型（LLMs）中“wait”和“therefore”等类似语篇的标记，发现特定标记与推理正确性高度相关，并且这种相关性随训练策略而变化，但随模型规模稳定。通过对“wait”标记的深入研究，揭示了在小规模数据集上微调的模型可以通过这些信号获得推理能力，但利用程度不完全。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）中出现了类似语篇的标记（如“wait”、“therefore”），为理解其推理过程提供了窗口，但缺乏对这些信号如何随训练策略和模型规模变化的系统性分析。

Method: 通过分析不同模型中标记的概率，研究了标记级别的信号。具体地，考察了“wait”标记与答案概率的关系。

Result: 发现特定的标记与推理的正确性存在强相关性，这种相关性会随训练策略的变化而变化，但在模型规模上保持稳定。对于在小规模数据集上微调的模型，“wait”标记的分析表明，它们通过这些信号获得了推理能力，但仅部分地利用了这些信号。

Conclusion: 该研究提供了一个系统性的视角来观察和理解大型语言模型推理的动态过程，强调了标记（如“wait”）在LLMs推理能力发展中的作用，以及不同训练策略和数据规模对这种作用的影响。

Abstract: The emergence of discourse-like tokens such as "wait" and "therefore" in large language models (LLMs) has offered a unique window into their reasoning processes. However, systematic analyses of how such signals vary across training strategies and model scales remain lacking. In this paper, we analyze token-level signals through token probabilities across various models. We find that specific tokens strongly correlate with reasoning correctness, varying with training strategies while remaining stable across model scales. A closer look at the "wait" token in relation to answer probability demonstrates that models fine-tuned on small-scale datasets acquire reasoning ability through such signals but exploit them only partially. This work provides a systematic lens to observe and understand the dynamics of LLM reasoning.

</details>


### [259] [Clustering-driven Memory Compression for On-device Large Language Models](https://arxiv.org/abs/2601.17443)
*Ondrej Bohdal,Pramit Saha,Umberto Michieli,Mete Ozay,Taha Ceritli*

Main category: cs.CL

TL;DR: 提出一种基于聚类的记忆压缩策略，通过将用户记忆分组并合并，有效减少了LLM的上下文长度，同时保持并提升了个性化生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有LLM个性化方法（如记忆拼接）受限于上下文长度，而简单的记忆平均化又会因语义冲突损害性能。

Method: 将用户记忆按相似度聚类，然后在每个簇内合并记忆，最后将合并后的记忆与输入提示拼接。具体方法是通过相似性度量对记忆进行分组，并采用聚类内合并策略。

Result: 该方法显著减少了记忆占用的token数量，且在生成质量上优于直接拼接和简单平均化等基线方法。在固定上下文预算下，聚类驱动的合并方法产生了更紧凑的记忆表示，并持续提升了生成质量。

Conclusion: 基于聚类的记忆压缩策略能够在上下文效率和个性化质量之间取得良好平衡，是一种有效解决LLM记忆管理问题的方案。

Abstract: Large language models (LLMs) often rely on user-specific memories distilled from past interactions to enable personalized generation. A common practice is to concatenate these memories with the input prompt, but this approach quickly exhausts the limited context available in on-device LLMs. Compressing memories by averaging can mitigate context growth, yet it frequently harms performance due to semantic conflicts across heterogeneous memories. In this work, we introduce a clustering-based memory compression strategy that balances context efficiency and personalization quality. Our method groups memories by similarity and merges them within clusters prior to concatenation, thereby preserving coherence while reducing redundancy. Experiments demonstrate that our approach substantially lowers the number of memory tokens while outperforming baseline strategies such as naive averaging or direct concatenation. Furthermore, for a fixed context budget, clustering-driven merging yields more compact memory representations and consistently enhances generation quality.

</details>


### [260] [Revealing the Truth with ConLLM for Detecting Multi-Modal Deepfakes](https://arxiv.org/abs/2601.17530)
*Gautam Siddharth Kashyap,Harsh Joshi,Niharika Jain,Ebad Shabbir,Jiechao Gao,Nipun Joshi,Usman Naseem*

Main category: cs.CL

TL;DR: 本文提出了一种名为ConLLM的混合框架，利用对比学习和大型语言模型来解决现有深度伪造检测方法在模态碎片化和跨模态推理不足的问题，并在音频、视频和视听模态上取得了显著的检测性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法存在模态碎片化（泛化能力差）和跨模态推理浅层（语义不一致检测能力弱）的局限性。深度伪造技术对社会和政治稳定构成了严重威胁，因此需要更鲁棒的检测方法。

Method: ConLLM采用两阶段架构：第一阶段使用预训练模型（PTMs）提取模态特定的嵌入；第二阶段通过对比学习对齐这些嵌入以缓解模态碎片化，并利用基于大型语言模型（LLM）的推理来捕捉语义不一致，从而解决跨模态推理不足的问题。

Result: ConLLM在音频、视频和视听模态上展现出强大的性能。它将音频深度伪造的等错误率（EER）降低了高达50%，将视频准确率提高了高达8%，并在视听任务中取得了约9%的准确率提升。消融研究表明，PTM-based嵌入在不同模态上均带来了9%-10%的稳定性能提升。

Conclusion: ConLLM框架通过结合预训练模型提取模态特征、对比学习实现模态对齐以及大型语言模型进行深层语义推理，成功克服了现有深度伪造检测方法的关键局限，并在多模态深度伪造检测任务中取得了显著的性能改进。

Abstract: The rapid rise of deepfake technology poses a severe threat to social and political stability by enabling hyper-realistic synthetic media capable of manipulating public perception. However, existing detection methods struggle with two core limitations: (1) modality fragmentation, which leads to poor generalization across diverse and adversarial deepfake modalities; and (2) shallow inter-modal reasoning, resulting in limited detection of fine-grained semantic inconsistencies. To address these, we propose ConLLM (Contrastive Learning with Large Language Models), a hybrid framework for robust multimodal deepfake detection. ConLLM employs a two-stage architecture: stage 1 uses Pre-Trained Models (PTMs) to extract modality-specific embeddings; stage 2 aligns these embeddings via contrastive learning to mitigate modality fragmentation, and refines them using LLM-based reasoning to address shallow inter-modal reasoning by capturing semantic inconsistencies. ConLLM demonstrates strong performance across audio, video, and audio-visual modalities. It reduces audio deepfake EER by up to 50%, improves video accuracy by up to 8%, and achieves approximately 9% accuracy gains in audio-visual tasks. Ablation studies confirm that PTM-based embeddings contribute 9%-10% consistent improvements across modalities.

</details>


### [261] [Less is More for RAG: Information Gain Pruning for Generator-Aligned Reranking and Evidence Selection](https://arxiv.org/abs/2601.17532)
*Zhipeng Song,Yizhi Zhou,Xiangyu Kong,Jiulong Jiao,Xinrui Bao,Xu You,Xueqing Shi,Yuhang Zhou,Heng Qi*

Main category: cs.CL

TL;DR: 本文提出了一种名为信息增益剪枝（IGP）的模块，用于优化检索增强生成（RAG）中证据的选取，通过生成器对齐的效用信号，有效过滤冗余或冲突的检索片段，显著提高了问答质量和成本效益。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）方法在有限的上下文预算下，如何选择最相关的检索片段是一个关键挑战。现有的检索相关性指标（如NDCG）与端到端问答质量的相关性较弱，甚至在多片段注入时可能负相关，因为冗余和轻微冲突会影响生成稳定性。

Method: 提出信息增益剪枝（IGP）模块，该模块在部署时友好，使用生成器对齐的效用信号来选择证据，并在截断前过滤掉弱或有害的片段，而无需改变现有的上下文预算接口。

Result: 在五个开放域问答基准测试以及多种检索器和生成器上，IGP一致地提高了质量--成本的权衡。在一个代表性的多证据设置中，与仅使用检索器的基线相比，IGP在保持最终阶段输入Token减少约76%-79%的同时，平均F1分数相对提高了约12%-20%。

Conclusion: 信息增益剪枝（IGP）是一种有效的RAG优化方法，能够通过更智能的证据选择来提升问答性能，并显著降低计算成本。

Abstract: Retrieval-augmented generation (RAG) grounds large language models with external evidence, but under a limited context budget, the key challenge is deciding which retrieved passages should be injected. We show that retrieval relevance metrics (e.g., NDCG) correlate weakly with end-to-end QA quality and can even become negatively correlated under multi-passage injection, where redundancy and mild conflicts destabilize generation. We propose \textbf{Information Gain Pruning (IGP)}, a deployment-friendly reranking-and-pruning module that selects evidence using a generator-aligned utility signal and filters weak or harmful passages before truncation, without changing existing budget interfaces. Across five open-domain QA benchmarks and multiple retrievers and generators, IGP consistently improves the quality--cost trade-off. In a representative multi-evidence setting, IGP delivers about +12--20% relative improvement in average F1 while reducing final-stage input tokens by roughly 76--79% compared to retriever-only baselines.

</details>


### [262] [Improving User Privacy in Personalized Generation: Client-Side Retrieval-Augmented Modification of Server-Side Generated Speculations](https://arxiv.org/abs/2601.17569)
*Alireza Salemi,Hamed Zamani*

Main category: cs.CL

TL;DR: P^3是一个交互式框架，可以在不向服务器端LLM泄露用户私有数据的情况下，实现高质量的个性化。它结合了大型服务器端模型生成草稿和小型客户端模型利用私有数据进行评估和修改。实验表明P^3在个性化问答任务上优于现有方法，并且在隐私保护方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强的个性化方法面临在暴露私有数据给云提供商和使用能力较弱的本地模型之间的权衡。研究旨在解决这一问题，实现高质量的个性化同时保护用户隐私。

Method: P^3框架采用交互式方法。首先，一个大型服务器端模型根据用户查询生成一系列草稿（k个token）。然后，一个小型客户端模型利用用户私有数据（可检索）评估并修改这些草稿，以更好地符合用户偏好。此过程重复进行，直到生成结束符。

Result: 在LaMP-QA数据集上的实验结果显示，P^3在个性化问答任务上始终优于非个性化服务器端和个性化客户端基线，平均性能提升7.4%至9%。P^3恢复了90.3%至95.7%的“泄露”上限场景（即完整个人资料暴露给大型服务器端模型）的效用。隐私分析表明，P^3的额外泄露量非常小（1.5%--3.5%），并且客户端模型仅生成总token数的9.2%。

Conclusion: P^3提供了一种实用且有效的个性化生成解决方案，能够在不泄露用户私有数据的情况下实现高质量的个性化，并具有出色的隐私保护和效率。

Abstract: Personalization is crucial for aligning Large Language Model (LLM) outputs with individual user preferences and background knowledge. State-of-the-art solutions are based on retrieval augmentation, where relevant context from a user profile is retrieved for LLM consumption. These methods deal with a trade-off between exposing retrieved private data to cloud providers and relying on less capable local models. We introduce $P^3$, an interactive framework for high-quality personalization without revealing private profiles to server-side LLMs. In $P^3$, a large server-side model generates a sequence of $k$ draft tokens based solely on the user query, while a small client-side model, with retrieval access to the user's private profile, evaluates and modifies these drafts to better reflect user preferences. This process repeats until an end token is generated. Experiments on LaMP-QA, a recent benchmark consisting of three personalized question answering datasets, show that $P^3$ consistently outperforms both non-personalized server-side and personalized client-side baselines, achieving statistically significant improvements of $7.4%$ to $9%$ on average. Importantly, $P^3$ recovers $90.3%$ to $95.7%$ of the utility of a ``leaky'' upper-bound scenario in which the full profile is exposed to the large server-side model. Privacy analyses, including linkability and attribute inference attacks, indicate that $P^3$ preserves the privacy of a non-personalized server-side model, introducing only marginal additional leakage ($1.5%$--$3.5%$) compared to submitting a query without any personal context. Additionally, the framework is efficient for edge deployment, with the client-side model generating only $9.2%$ of the total tokens. These results demonstrate that $P^3$ provides a practical, effective solution for personalized generation with improved privacy.

</details>


### [263] [Sequence Repetition Enhances Token Embeddings and Improves Sequence Labeling with Decoder-only Language Models](https://arxiv.org/abs/2601.17585)
*Matija Luka Kukić,Marko Čuljak,David Dukić,Martin Tutek,Jan Šnajder*

Main category: cs.CL

TL;DR: 研究提出了一种名为序列重复（SR）的技术，可以使仅解码器的语言模型（decoder-only LMs）在序列标注任务中实现双向上下文理解，且优于编码器模型和未修改的解码器模型，同时比移除因果掩码（causal mask removal）的方法侵入性更小。


<details>
  <summary>Details</summary>
Motivation: 仅解码器的语言模型通常是自回归的，仅依赖前缀上下文，而序列标注任务需要双向上下文。现有的方法（如移除因果掩码）需要对模型进行较大改动，因此研究者希望找到一种更温和的方法来赋予仅解码器模型双向能力。

Method: 研究者提出并实验了序列重复（SR）技术，通过对输入序列进行重复来训练仅解码器模型，使其能够捕获双向上下文信息。实验中，模型通过微调（fine-tuning）来学习SR，并评估了不同重复次数、不同层级嵌入（中间层和最终层）对序列标注任务性能的影响。

Result: 序列重复（SR）技术能够使仅解码器模型在序列标注任务中表现出双向性，提高了词级别嵌入的质量，并且优于编码器模型和未掩码的解码器模型。增加重复次数并未降低性能。中间层的嵌入与最终层嵌入效果相当，但计算效率更高。

Conclusion: 序列重复（SR）是一种有效且侵入性小的方法，可以克服仅解码器模型在处理需要双向上下文的任务（如序列标注）时的结构限制，使其更具适应性和效率，并拓宽其在其他词级别任务上的应用范围。

Abstract: Modern language models (LMs) are trained in an autoregressive manner, conditioned only on the prefix. In contrast, sequence labeling (SL) tasks assign labels to each individual input token, naturally benefiting from bidirectional context. This discrepancy has historically led SL to rely on inherently bidirectional encoder-only models. However, the rapid development of decoder-only models has raised the question of whether they can be adapted to SL. While causal mask removal has emerged as a viable technique for adapting decoder-only models to leverage the full context for SL, it requires considerable changes to the base model functionality. In this work, we explore sequence repetition (SR) as a less invasive alternative for enabling bidirectionality in decoder-only models. Through fine-tuning experiments, we show that SR inherently makes decoders bidirectional, improving the quality of token-level embeddings and surpassing encoders and unmasked decoders. Contrary to earlier claims, we find that increasing the number of repetitions does not degrade SL performance. Finally, we demonstrate that embeddings from intermediate layers are highly effective for SR, comparable to those from final layers, while being significantly more efficient to compute. Our findings underscore that SR alleviates the structural limitations of decoders, enabling more efficient and adaptable LMs and broadening their applicability to other token-level tasks.

</details>


### [264] [From Chains to DAGs: Probing the Graph Structure of Reasoning in LLMs](https://arxiv.org/abs/2601.17593)
*Tianjun Zhong,Linyang He,Nima Mesgarani*

Main category: cs.CL

TL;DR: 该研究提出了一种名为Reasoning DAG Probing的新框架，用于探究大型语言模型（LLM）的内部表示是否编码了类似有向无环图（DAG）的推理结构。研究发现，LLM的中间层确实以线性可访问的方式编码了推理DAG的几何形状，且这种结构的可恢复性会随节点深度和模型规模的变化而变化。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在多步推理方面取得了进展，但现有的研究多将推理视为线性过程。然而，许多实际的推理问题更自然地被建模为DAG结构，其中中间结论可能依赖于多个前提，并可能分支和合并。因此，理解LLM的内部表示是否反映了这种DAG结构化的推理是当前研究的开放问题。

Method: 研究引入了Reasoning DAG Probing框架，该框架通过训练轻量级探针来预测来自LLM隐藏状态的两个图论属性：节点深度和节点间的成对距离。每个推理节点都被关联到一个文本表示。通过分析探针在不同层级的表现，以及对可能干扰推理结构但不影响文本表面的控制进行评估，来探究DAG结构的内部编码情况。

Result: 研究结果表明，推理DAG的几何结构在LLM的中间层得到了有意义的编码。节点深度和模型规模系统地影响了这种结构的可恢复性。这表明LLM的推理不仅是线性的，而且在其内部表现出可衡量的图结构。

Conclusion: LLM的内部表示不仅编码了线性的推理步骤，还能够编码更复杂的DAG结构。这种DAG结构的编码在模型的中间层尤为明显，并且受到节点深度和模型规模的影响。这项工作为理解LLM内部的推理机制提供了新的视角，表明其内部运作比之前认为的更为复杂。

Abstract: Recent progress in large language models has renewed interest in mechanistically characterizing how multi-step reasoning is represented and computed. While much prior work treats reasoning as a linear chain of steps, many reasoning problems are more naturally structured as directed acyclic graphs (DAGs), where intermediate conclusions may depend on multiple premises, branch into parallel sub-derivations, and later merge or be reused. Understanding whether such graph-structured reasoning is reflected in model internals remains an open question.
  In this work, we introduce Reasoning DAG Probing, a framework that directly asks whether LLM hidden states encode the geometry of a reasoning DAG in a linearly accessible form, and where this structure emerges across layers. Within this framework, we associate each reasoning node with a textual realization and train lightweight probes to predict two graph-theoretic properties from hidden states: node depth and pairwise node distance. We use these probes to analyze the layerwise emergence of DAG structure and evaluate controls that disrupt reasoning-relevant structure while preserving superficial textual properties. Our results provide evidence that reasoning DAG geometry is meaningfully encoded in intermediate layers, with recoverability varying systematically by node depth and model scale, suggesting that LLM reasoning is not only sequential but exhibits measurable internal graph structure.

</details>


### [265] [Learning to Ideate for Machine Learning Engineering Agents](https://arxiv.org/abs/2601.17596)
*Yunxiang Zhang,Kang Zhou,Zhichao Xu,Kiran Ramnath,Yun Zhou,Sangmin Woo,Haibo Ding,Lin Lee Cheong*

Main category: cs.CL

TL;DR: 提出了一种名为MLE-Ideator的双代理框架，将想法生成与算法实现分离，以提升机器学习工程（MLE）代理的迭代优化能力，并在无训练和强化学习训练的设置下均取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习工程（MLE）代理在迭代优化其实现的算法以提高有效性方面存在困难。

Method: 引入了一个名为MLE-Ideator的双代理框架，其中包含一个实现代理和一个独立的“Ideator”代理，实现代理可以向Ideator请求战略性帮助。此外，还研究了使用强化学习（RL）训练Ideator以生成更有效的想法。

Result: 在无训练设置下，MLE-Ideator框架显著优于仅实现代理的基线。通过1K个训练样本和10个MLE任务，使用RL训练的Qwen3-8B Ideator比未训练的对应版本实现了11.5%的相对提升，并优于Claude Sonnet 3.5。

Conclusion: MLE-Ideator框架能够有效地提升机器学习工程代理的算法优化能力，特别是通过引入专门的“Ideator”代理。RL训练的Ideator可以进一步提高想法的有效性，为训练用于科学发现的战略性AI系统提供了一条有前途的途径。

Abstract: Existing machine learning engineering (MLE) agents struggle to iteratively optimize their implemented algorithms for effectiveness. To address this, we introduce MLE-Ideator, a dual-agent framework that separates ideation from implementation. In our system, an implementation agent can request strategic help from a dedicated Ideator. We show this approach is effective in two ways. First, in a training-free setup, our framework significantly outperforms implementation-only agent baselines on MLE-Bench. Second, we demonstrate that the Ideator can be trained with reinforcement learning (RL) to generate more effective ideas. With only 1K training samples from 10 MLE tasks, our RL-trained Qwen3-8B Ideator achieves an 11.5% relative improvement compared to its untrained counterpart and surpasses Claude Sonnet 3.5. These results highlights a promising path toward training strategic AI systems for scientific discovery.

</details>


### [266] [What Language Models Know But Don't Say: Non-Generative Prior Extraction for Generalization](https://arxiv.org/abs/2601.17609)
*Sara Rezaeimanesh,Mohammad M. Ghassemi*

Main category: cs.CL

TL;DR: 本文提出了一种名为 LoID 的新方法，该方法通过直接访问大型语言模型（LLM）的 token 级预测来提取贝叶斯逻辑回归的先验分布。LoID 在合成的分布外（OOD）设置下，显著提高了逻辑回归模型的性能，尤其是在协变量偏移的情况下，并且优于其他几种现有方法。


<details>
  <summary>Details</summary>
Motivation: 在医学和金融等领域，由于难以获取大量标注数据，在小数据集上训练的模型泛化能力较差。大型语言模型蕴含了丰富的领域知识，但如何将其有效地整合到下游模型中是一个挑战。

Method: LoID 是一种确定性方法，通过构建精心设计的句子来探查 LLM 对相反语义方向（例如，积极 vs. 消极影响）的信心。通过衡量 LLM 在不同措辞下对某个方向的一致性偏好，提取模型关于每个特征影响的信念强度和可靠性，并将其作为贝叶斯逻辑回归的先验分布。

Result: 在十个真实的表格数据集的合成 OOD 设置下，LoID 显著提高了逻辑回归模型的 AUC 性能，在某些情况下恢复了高达 59% 相对于最优（oracle）模型的性能差距。LoID 在 80% 的数据集上优于 AutoElicit 和 LLMProcesses。

Conclusion: LoID 是一种有效且可复现的方法，可以利用 LLM 的知识来改善贝叶斯推理，尤其是在数据稀疏和存在分布外变化的情况下。它比仅依赖文本生成或 in-context learning 的方法更具优势，并且计算效率高。

Abstract: In domains like medicine and finance, large-scale labeled data is costly and often unavailable, leading to models trained on small datasets that struggle to generalize to real-world populations. Large language models contain extensive knowledge from years of research across these domains. We propose LoID (Logit-Informed Distributions), a deterministic method for extracting informative prior distributions for Bayesian logistic regression by directly accessing their token-level predictions. Rather than relying on generated text, we probe the model's confidence in opposing semantic directions (positive vs. negative impact) through carefully constructed sentences. By measuring how consistently the LLM favors one direction across diverse phrasings, we extract the strength and reliability of the model's belief about each feature's influence. We evaluate LoID on ten real-world tabular datasets under synthetic out-of-distribution (OOD) settings characterized by covariate shift, where the training data represents only a subset of the population. We compare our approach against (1) standard uninformative priors, (2) AutoElicit, a recent method that prompts LLMs to generate priors via text completions, (3) LLMProcesses, a method that uses LLMs to generate numerical predictions through in-context learning and (4) an oracle-style upper bound derived from fitting logistic regression on the full dataset. We assess performance using Area Under the Curve (AUC). Across datasets, LoID significantly improves performance over logistic regression trained on OOD data, recovering up to \textbf{59\%} of the performance gap relative to the oracle model. LoID outperforms AutoElicit and LLMProcessesc on 8 out of 10 datasets, while providing a reproducible and computationally efficient mechanism for integrating LLM knowledge into Bayesian inference.

</details>


### [267] [Beyond the Rabbit Hole: Mapping the Relational Harms of QAnon Radicalization](https://arxiv.org/abs/2601.17658)
*Bich Ngoc,Doan,Giuseppe Russo,Gianmarco De Francisci Morales,Robert West*

Main category: cs.CL

TL;DR: 本研究通过分析Reddit社区r/QAnonCasualties的数据，使用话题建模和LLM辅助的情感检测，识别出QAnon信徒的六种“激进化人格”，并量化了这些人格对亲友造成的具体情感伤害，发现激进化方式（如故意的意识形态选择或个人/认知崩溃）与叙述者经历的不同情感（如愤怒、厌恶、恐惧、悲伤）相关。


<details>
  <summary>Details</summary>
Motivation: 以往关于阴谋论的研究主要关注其对公共领域的影响，而忽视了对阴谋论信徒亲友造成的个人情感伤害。本研究旨在填补这一空白，系统地描绘激进化过程并量化其对亲人的情感影响。

Method: 本研究采用混合方法，首先使用BERTopic话题建模分析r/QAnonCasualties社区的12747个叙事，以描绘激进化轨迹，识别关键的先决条件、触发因素和后激进化特征。接着，应用基于LDA的图模型来识别六种反复出现的QAnon信徒原型，称为“激进化人格”。最后，利用LLM辅助的情感检测和回归模型，将这些原型与叙述者报告的具体情感损失联系起来。

Result: 研究发现了六种“激进化人格”，这些人格能够预测叙述者所经历的具体情感伤害。将激进化视为一种故意的意识形态选择，会与叙述者的愤怒和厌恶感相关；而涉及个人和认知崩溃的激进化，则与恐惧和悲伤相关。

Conclusion: 本研究提供了首个理解激进化作为一种关系现象的实证框架，揭示了激进化方式对亲友情感造成的不同影响，为研究人员和实践者提供了应对其人际后果的重要指南。

Abstract: The rise of conspiracy theories has created far-reaching societal harm in the public discourse by eroding trust and fueling polarization. Beyond this public impact lies a deeply personal toll on the friends and families of conspiracy believers, a dimension often overlooked in large-scale computational research. This study fills this gap by systematically mapping radicalization journeys and quantifying the associated emotional toll inflicted on loved ones. We use the prominent case of QAnon as a case study, analyzing 12747 narratives from the r/QAnonCasualties support community through a novel mixed-methods approach. First, we use topic modeling (BERTopic) to map the radicalization trajectories, identifying key pre-existing conditions, triggers, and post-radicalization characteristics. From this, we apply an LDA-based graphical model to uncover six recurring archetypes of QAnon adherents, which we term "radicalization personas." Finally, using LLM-assisted emotion detection and regression modeling, we link these personas to the specific emotional toll reported by narrators. Our findings reveal that these personas are not just descriptive; they are powerful predictors of the specific emotional harms experienced by narrators. Radicalization perceived as a deliberate ideological choice is associated with narrator anger and disgust, while those marked by personal and cognitive collapse are linked to fear and sadness. This work provides the first empirical framework for understanding radicalization as a relational phenomenon, offering a vital roadmap for researchers and practitioners to navigate its interpersonal fallout.

</details>


### [268] [UrduLM: A Resource-Efficient Monolingual Urdu Language Model](https://arxiv.org/abs/2601.17664)
*Syed Muhammad Ali,Hammad Sajid,Zainab Haider,Ali Muhammad Asad,Haya Fatima,Abdul Samad*

Main category: cs.CL

TL;DR: 研究提出了UrduLM，一个为乌尔都语设计的预训练单语Transformer语言模型，旨在解决现有模型在性能、成本和文化准确性方面的问题。该模型在33GB的乌尔都语语料库上训练，并使用定制的BPE分词器，实现了在少量样本（few-shot）评估中与更大规模的多语言模型相当的性能，同时显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言Transformer模型对乌尔都语的支持不足，表现差、计算成本高且存在文化不准确性，这是由于缺乏专门的乌尔都语模型和精选语料库。研究旨在解决这些挑战，为乌尔都语NLP研究提供一个高性能、低成本且文化相关的模型。

Method: 研究者构建了一个33GB的乌尔都语语料库，开发了一个定制的BPE（Byte Pair Encoding）分词器（相比多语言模型能减少20-30%的token开销），并在此基础上预训练了一个100M参数的decoder-only模型，命名为UrduLM。

Result: 在少量样本（few-shot）评估中，UrduLM在情感分类任务上达到了66.6%的准确率，在语法纠错任务上的BLEU分数超过30。与同等规模的多语言模型相比，UrduLM的性能具有竞争力，并且其模型规模是多语言模型的1/30。

Conclusion: UrduLM是一个在低资源环境下训练的乌尔都语单语语言模型，它在性能、计算成本和文化准确性方面优于现有的多语言模型。研究者公开了完整的实现方法、语料库、分词器、模型权重和评估基准，旨在为乌尔都语NLP研究建立基线，并为其他代表性不足的语言提供可扩展的框架。

Abstract: Urdu, spoken by 230 million people worldwide, lacks dedicated transformer-based language models and curated corpora. While multilingual models provide limited Urdu support, they suffer from poor performance, high computational costs, and cultural inaccuracies due to insufficient training data. To address these challenges, we present UrduLM, a pretrained Urdu monolingual language model trained in low-resource settings. We curate a 33GB Urdu corpus from diverse sources, develop a custom BPE tokenizer that reduces tokenization overhead by atleast 20-30% compared to multilingual alternatives, and pretrain a 100M-parameter decoder-only model. In few-shot evaluations, UrduLM achieves competitive performance with multilingual models up to 30x its size, reaching 66.6% accuracy on sentiment classification and BLEU scores exceeding 30 on grammar correction tasks. The complete methodology -- including corpus, tokenizer, model weights, and evaluation benchmarks -- is released openly to establish a baseline for Urdu NLP research and provide a scalable framework for other underrepresented languages.

</details>


### [269] [Align to the Pivot: Dual Alignment with Self-Feedback for Multilingual Math Reasoning](https://arxiv.org/abs/2601.17671)
*Chunxu Zhao,Xin Huang,Xue Han,Shujian Huang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 本文提出了一种名为PASMR（Pivot-Aligned Self-Feedback Multilingual Reasoning）的方法，通过利用一种“支点语言”来改善大型语言模型在多语言数学推理任务中的表现，尤其是在低资源语言方面，通过翻译问题并利用支点语言的推理过程进行监督，实现了跨语言的自我反馈，无需外部答案或奖励模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多语言环境下，尤其是低资源语言上，存在性能下降的问题，原因在于多语言理解和推理的对齐不一致。

Method: PASMR方法选择一种“支点语言”，训练时先将问题翻译成支点语言以对齐推理模式，然后用支点语言的推理答案来监督目标语言的推理过程，构建跨语言的自我反馈机制。

Result: 实验结果表明，PASMR方法提高了模型对问题的理解能力和推理能力，在多语言数学推理任务上取得了显著的改进。

Conclusion: PASMR方法能够有效地提高大型语言模型在多语言数学推理任务中的对齐性和性能，尤其对于低资源语言有积极作用，并且该方法不依赖外部的正确答案或奖励模型。

Abstract: Despite the impressive reasoning abilities demonstrated by large language models (LLMs), empirical evidence indicates that they are not language agnostic as expected, leading to performance declines in multilingual settings, especially for low-resource languages. We attribute the decline to the model's inconsistent multilingual understanding and reasoning alignment. To address this, we present Pivot-Aligned Self-Feedback Multilingual Reasoning (PASMR), aiming to improve the alignment of multilingual math reasoning abilities in LLMs. This approach designates the model's primary language as the pivot language. During training, the model first translates questions into the pivot language to facilitate better alignment of reasoning patterns. The reasoning process in the target language is then supervised by the pivot language's reasoning answers, thereby establishing a cross-lingual self-feedback mechanism without relying on external correct answers or reward models. Extensive experimental results demonstrate that our method enhances both the model's understanding of questions and its reasoning capabilities, leading to notable task improvements.

</details>


### [270] [S$^3$-Attention:Attention-Aligned Endogenous Retrieval for Memory-Bounded Long-Context Inference](https://arxiv.org/abs/2601.17702)
*Qingsen Ma,Dianyun Wang,Yaoye Wang,Lechen Ning,Sujie Zhu,Xiaohang Zhang,Jiaming Lyu,Linhao Ren,Zhenbo Xu,Zhaofeng He*

Main category: cs.CL

TL;DR: 提出了一种名为 S3-Attention 的推理框架，通过端到端内生检索来处理长上下文输入，无需 KV 缓存，从而提高了内存效率，并取得了与全上下文推理相媲美的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理长上下文输入时存在内存和效率问题，KV 缓存随上下文长度线性增长，而外部检索方法可能检索到不相关的片段。

Method: S3-Attention 框架使用轻量级稀疏自编码器将瞬态键和查询投影解码为 top-k 稀疏特征标识符，并通过基于 CPU 的倒排索引将特征映射到 token 位置或跨度。在生成时，通过特征共激活检索紧凑的证据片段，并可选地与 BM25 融合。

Result: 在 LongBench 评估协议下，S3-Hybrid 在多个模型家族中与全上下文推理性能相当，并在信息密集型设置中提高了鲁棒性。

Conclusion: S3-Attention 框架能够实现内存高效的长上下文处理，但目前的原型在实际运行时间上存在延迟，需要进行内核级优化。

Abstract: Large language models are increasingly applied to multi-document and long-form inputs, yet long-context inference remains memory- and noise-inefficient. Key-value (KV) caching scales linearly with context length, while external retrieval methods often return lexically similar but causally irrelevant passages.
  We present S3-Attention, a memory-first inference-time framework that treats long-context processing as attention-aligned endogenous retrieval. S3-Attention decodes transient key and query projections into top-k sparse feature identifiers using lightweight sparse autoencoders, and constructs a CPU-based inverted index mapping features to token positions or spans during a single streaming scan. This design allows the KV cache to be discarded entirely and bounds GPU memory usage by the scan chunk size.
  At generation time, feature co-activation is used to retrieve compact evidence spans, optionally fused with BM25 for exact lexical matching. Under a unified LongBench evaluation protocol with fixed prompting, decoding, and matched token budgets, S3-Hybrid closely matches full-context inference across multiple model families and improves robustness in several information-dense settings. We also report an engineering limitation of the current prototype, which incurs higher wall-clock latency than optimized full-KV baselines, motivating future kernel-level optimization.

</details>


### [271] [Distance-to-Distance Ratio: A Similarity Measure for Sentences Based on Rate of Change in LLM Embeddings](https://arxiv.org/abs/2601.17705)
*Abdullah Qureshi,Kenneth Rice,Alexander Wolpert*

Main category: cs.CL

TL;DR: 本文提出了一种名为距离-距离比（DDR）的新型句子嵌入相似性度量方法，它能更好地捕捉人类对文本相似性的感知，并优于现有的度量方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入的相似性度量方法未能充分反映人类对文本相似性的感知，特别是在处理上下文对嵌入影响时。

Method: 提出距离-距离比（DDR）度量方法，该方法借鉴了Lipschitz连续性的思想，通过衡量预上下文词嵌入相似性变化率与后上下文LLM嵌入相似性变化率的比值来量化上下文的语义影响。

Result: 在通过同义词替换（语义相似）或随机词替换（语义不相似）来生成句子变体的数据集上进行实验，DDR在区分语义相似和不相似文本方面表现出比现有度量方法更精细的辨别能力，即使在进行少量、可控的编辑时也是如此。

Conclusion: DDR是一种新颖且有效的句子嵌入相似性度量方法，它能够更准确地反映人类对文本相似性的判断，尤其在捕捉上下文的语义影响方面表现出色。

Abstract: A measure of similarity between text embeddings can be considered adequate only if it adheres to the human perception of similarity between texts. In this paper, we introduce the distance-to-distance ratio (DDR), a novel measure of similarity between LLM sentence embeddings. Inspired by Lipschitz continuity, DDR measures the rate of change in similarity between the pre-context word embeddings and the similarity between post-context LLM embeddings, thus measuring the semantic influence of context. We evaluate the performance of DDR in experiments designed as a series of perturbations applied to sentences drawn from a sentence dataset. For each sentence, we generate variants by replacing one, two, or three words with either synonyms, which constitute semantically similar text, or randomly chosen words, which constitute semantically dissimilar text. We compare the performance of DDR with other prevailing similarity metrics and demonstrate that DDR consistently provides finer discrimination between semantically similar and dissimilar texts, even under minimal, controlled edits.

</details>


### [272] [A Computational Approach to Visual Metonymy](https://arxiv.org/abs/2601.17706)
*Saptarshi Ghosh,Linfeng Liu,Tianyu Jiang*

Main category: cs.CL

TL;DR: 本文首次对视觉隐喻（visual metonymy）进行了计算性研究，提出了一种基于符号学理论的新颖方法，并构建了首个视觉隐喻数据集ViMET，用于评估多模态语言模型。实验结果表明，当前最先进的模型在理解视觉隐喻方面与人类存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 研究动机是图像能够传达比字面意思更多的信息，例如通过一组工具暗示职业，或通过文化制品暗示传统。这种间接的视觉参照（视觉隐喻）需要观众通过关联线索而非直接描绘来理解目标概念。作者希望通过计算方法来研究和模拟这一过程。

Method: 研究提出了一种新颖的计算流水线，该流水线基于符号学理论，并利用大型语言模型（LLMs）和文本到图像模型来生成视觉隐喻表示。在此基础上，构建了一个包含2000个选择题的视觉隐喻数据集ViMET，用于评估多模态语言模型的认知推理能力。

Result: 在ViMET数据集上的实验结果显示，人类的表现（86.9%）远高于当前最先进的视觉语言模型（65.9%）。这揭示了机器在理解间接视觉参照方面存在局限性。

Conclusion: 视觉隐喻是机器理解图像的重要方面，但当前的多模态模型在这方面表现不佳。ViMET数据集的构建为进一步研究和提升模型在理解视觉隐喻方面的能力提供了基础。

Abstract: Images often communicate more than they literally depict: a set of tools can suggest an occupation and a cultural artifact can suggest a tradition. This kind of indirect visual reference, known as visual metonymy, invites viewers to recover a target concept via associated cues rather than explicit depiction. In this work, we present the first computational investigation of visual metonymy. We introduce a novel pipeline grounded in semiotic theory that leverages large language models and text-to-image models to generate metonymic visual representations. Using this framework, we construct ViMET, the first visual metonymy dataset comprising 2,000 multiple-choice questions to evaluate the cognitive reasoning abilities in multimodal language models. Experimental results on our dataset reveal a significant gap between human performance (86.9%) and state-of-the-art vision-language models (65.9%), highlighting limitations in machines' ability to interpret indirect visual references. Our dataset is publicly available at: https://github.com/cincynlp/ViMET.

</details>


### [273] [Unsupervised Elicitation of Moral Values from Language Models](https://arxiv.org/abs/2601.17728)
*Meysam Alizadeh,Fabrizio Gilardi,Zeynab Samei*

Main category: cs.CL

TL;DR: 本研究提出了一种名为内部一致性最大化（ICM）的无监督方法，用于挖掘预训练语言模型（LM）中潜在的道德推理能力，并在多个基准数据集和模型上验证了其有效性，结果表明该方法能够提高LM的道德判断能力，泛化不同道德框架，并显著减少社会偏见。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统日益普及，如何使其行为符合人类价值观成为一个关键问题。现有研究表明LM本身道德推理能力有限，但收集用于道德评估的标注数据存在困难，因为道德框架多样且存在固有偏见。因此，本研究旨在探索一种无监督的提取方法，以发现预训练LM中是否内在地具备道德推理能力。

Method: 研究使用了内部一致性最大化（ICM）算法，在三个基准数据集（Norm Bank, ETHICS）和四种不同的LM（包括预训练LM和聊天机器人LM）上进行实验。通过ICM算法，研究者测试了其能否可靠地标注道德判断、能否泛化到不同的道德框架，以及能否减轻社会偏见。

Result: ICM算法在Norm Bank和ETHICS基准上的表现优于所有预训练LM和聊天机器人基线。使用ICM标注数据进行微调，其性能与使用人类标注数据微调相当或更好。ICM在司法（Justice）和常识道德（Commonsense morality）框架下相对提升最大。此外，ICM将社会偏见错误率降低了一半以上，尤其在种族、社会经济地位和政治偏见方面改进显著，而聊天机器人LM的偏见错误率与预训练LM相当。

Conclusion: 研究结果表明，预训练LM确实拥有潜在的道德推理能力，可以通过ICM等无监督方法进行挖掘。这为AI对齐提供了一条可扩展的途径，有望通过无监督方法来提高AI的道德性和减少偏见。

Abstract: As AI systems become pervasive, grounding their behavior in human values is critical. Prior work suggests that language models (LMs) exhibit limited inherent moral reasoning, leading to calls for explicit moral teaching. However, constructing ground truth data for moral evaluation is difficult given plural frameworks and pervasive biases. We investigate unsupervised elicitation as an alternative, asking whether pretrained (base) LMs possess intrinsic moral reasoning capability that can be surfaced without human supervision. Using the Internal Coherence Maximization (ICM) algorithm across three benchmark datasets and four LMs, we test whether ICM can reliably label moral judgments, generalize across moral frameworks, and mitigate social bias. Results show that ICM outperforms all pre-trained and chatbot baselines on the Norm Bank and ETHICS benchmarks, while fine-tuning on ICM labels performs on par with or surpasses those of human labels. Across theoretically motivated moral frameworks, ICM yields its largest relative gains on Justice and Commonsense morality. Furthermore, although chatbot LMs exhibit social bias failure rates comparable to their pretrained ones, ICM reduces such errors by more than half, with the largest improvements in race, socioeconomic status, and politics. These findings suggest that pretrained LMs possess latent moral reasoning capacities that can be elicited through unsupervised methods like ICM, providing a scalable path for AI alignment.

</details>


### [274] [Hylog: A Hybrid Approach to Logging Text Production in Non-alphabetic Scripts](https://arxiv.org/abs/2601.17753)
*Roberto Crotti,Giovanni Denaro,Zhiqiang Du,Ricardo Muñoz Martín*

Main category: cs.CL

TL;DR: 提出了一种名为Hylog的混合日志记录系统，用于解决现有键盘记录器无法捕捉输入法编辑器（IME）生成非字母脚本时屏幕上转换的问题，实现了更全面、更精细化的文本生成分析。


<details>
  <summary>Details</summary>
Motivation: 现有的键盘记录器无法捕捉输入法编辑器（IME）在处理非字母脚本时产生的屏幕内容转换，导致在认知文本生成研究中存在方法学上的不足。

Method: 开发了一个名为Hylog的混合日志记录系统，结合了分析性键盘记录和生态学文本记录。该系统采用模块化设计，使用插件支持标准应用程序（如Microsoft Word、Google Chrome），能够同时捕获键盘输入和渲染后的文本。一个“混合器”模块负责同步这两种数据，形成双重轨迹。

Result: Hylog成功捕获了用户将文本翻译成简体中文时的击键信息、拉丁字母、汉字以及IME确认之间的时间间隔，其中一些信息是传统键盘记录器无法获得的。验证了该系统的技术可行性，并展示了其分析能力。

Conclusion: Hylog系统能够提供更全面、更精细化的文本生成数据，支持针对IME驱动输入过程中的认知限制和优势提出新的、可检验的假设。其插件式架构易于扩展到其他IME系统，促进了更具包容性的多语言文本生成研究。

Abstract: Research keyloggers are essential for cognitive studies of text production, yet most fail to capture the on-screen transformations performed by Input Method Editors (IMEs) for non-alphabetic scripts. To address this methodological gap, we present Hylog, a novel hybrid logging system that combines analytical keylogging with ecological text logging for a more complete and finer-grained analysis. Our modular, open-source system uses plug-ins for standard applications (Microsoft Word, Google Chrome) to capture both keyboard output and rendered text, which a hybridizer module then synchronizes into a dual trace. To validate the system's technical feasibility and demonstrate its analytical capabilities, we conducted a proof-of-concept study where two volunteers translated a text into simplified Chinese. Hylog successfully captured keypresses and temporal intervals between Latin letters, Chinese characters, and IME confirmations -- some measurements invisible to traditional keyloggers. The resulting data enable the formulation of new, testable hypotheses about the cognitive restrictions and affordances at different linguistic layers in IME-mediated typing. Our plug-in architecture enables extension to other IME systems and fosters more inclusive multilingual text-production research.

</details>


### [275] [ProGraph-R1: Progress-aware Reinforcement Learning for Graph Retrieval Augmented Generation](https://arxiv.org/abs/2601.17755)
*Jinyoung Park,Sanghyeok Lee,Omar Zia Khan,Hyunwoo J. Kim,Joo-Kyung Kim*

Main category: cs.CL

TL;DR: 本文提出了一种名为 ProGraph-R1 的新颖的图检索增强生成（GraphRAG）框架，用于改进知识密集型问答任务中的多步推理能力。它通过结合结构感知超图检索和基于进度的逐步策略优化来克服现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的 GraphRAG 框架在检索时主要依赖语义相似性，忽略了图的结构，并且使用稀疏的、仅基于最终结果的奖励，无法捕捉中间检索步骤的质量及其依赖性。这限制了 LLM 进行复杂的多跳推理。

Method: ProGraph-R1 引入了一种结构感知超图检索机制，该机制同时考虑了语义相关性和图的连通性，以促进多跳推理路径的连贯遍历。此外，它还设计了一种基于进度的逐步策略优化方法，通过根据图内中间推理进度来调整优势，提供密集的学习信号，而不是仅仅依赖最终结果。

Result: 在多跳问答基准测试上的实验表明，ProGraph-R1 在推理准确性和生成质量方面始终优于现有的 GraphRAG 方法。

Conclusion: ProGraph-R1 通过结合结构感知检索和细粒度的奖励机制，有效地提升了 GraphRAG 在复杂推理任务中的性能，为 Agentic GraphRAG 的研究提供了新的方向。

Abstract: Graph Retrieval-Augmented Generation (GraphRAG) has been successfully applied in various knowledge-intensive question answering tasks by organizing external knowledge into structured graphs of entities and relations. It enables large language models (LLMs) to perform complex reasoning beyond text-chunk retrieval. Recent works have employed reinforcement learning (RL) to train agentic GraphRAG frameworks that perform iterative interactions between LLMs and knowledge graphs. However, existing RL-based frameworks such as Graph-R1 suffer from two key limitations: (1) they primarily depend on semantic similarity for retrieval, often overlooking the underlying graph structure, and (2) they rely on sparse, outcome-level rewards, failing to capture the quality of intermediate retrieval steps and their dependencies. To address these limitations, we propose ProGraph-R1, a progress-aware agentic framework for graph-based retrieval and multi-step reasoning. ProGraph-R1 introduces a structure-aware hypergraph retrieval mechanism that jointly considers semantic relevance and graph connectivity, encouraging coherent traversal along multi-hop reasoning paths. We also design a progress-based step-wise policy optimization, which provides dense learning signals by modulating advantages according to intermediate reasoning progress within a graph, rather than relying solely on final outcomes. Experiments on multi-hop question answering benchmarks demonstrate that ProGraph-R1 consistently improves reasoning accuracy and generation quality over existing GraphRAG methods.

</details>


### [276] [Cross-Lingual Probing and Community-Grounded Analysis of Gender Bias in Low-Resource Bengali](https://arxiv.org/abs/2601.17764)
*Md Asgor Hossain Reaj,Rajan Das Gupta,Jui Saha Pritha,Abdullah Al Noman,Abir Ahmed,Golam Md Mohiuddin,Tze Hui Liew*

Main category: cs.CL

TL;DR: 本研究调查了孟加拉语中的性别偏见，发现其与英语存在显著差异，并提出了更具本地化和社区驱动的方法来识别和减轻偏见。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注英语中的性别偏见，对南亚等非英语语言（如孟加拉语）的偏见研究不足，而这些语言的文化和社会因素可能导致独特的偏见。

Method: 研究采用了多种方法来提取性别偏见，包括：词典挖掘、计算分类模型、基于翻译的比较分析、GPT辅助偏见生成。此外，研究还进行了两次实地调查，收集了孟加拉语农村和低收入地区的真实性别偏见见解。

Result: 研究发现，直接将英语中心的偏见检测框架应用于孟加拉语效果不佳。孟加拉语的性别偏见具有与英语不同的特征，需要本地化和情境敏感的方法。社区驱动的研究方法对于识别自动化系统可能忽略的文化相关偏见至关重要。

Conclusion: 本研究强调了开发针对代表性不足语言（如孟加拉语）的特定语言工具的必要性，为在孟加拉语和其他印地语系语言中减少偏见奠定了基础，并促进更具包容性和公平性的人工智能自然语言处理系统。

Abstract: Large Language Models (LLMs) have achieved significant success in recent years; yet, issues of intrinsic gender bias persist, especially in non-English languages. Although current research mostly emphasizes English, the linguistic and cultural biases inherent in Global South languages, like Bengali, are little examined. This research seeks to examine the characteristics and magnitude of gender bias in Bengali, evaluating the efficacy of current approaches in identifying and alleviating bias. We use several methods to extract gender-biased utterances, including lexicon-based mining, computational classification models, translation-based comparison analysis, and GPT-based bias creation. Our research indicates that the straight application of English-centric bias detection frameworks to Bengali is severely constrained by language disparities and socio-cultural factors that impact implicit biases. To tackle these difficulties, we executed two field investigations inside rural and low-income areas, gathering authentic insights on gender bias. The findings demonstrate that gender bias in Bengali presents distinct characteristics relative to English, requiring a more localized and context-sensitive methodology. Additionally, our research emphasizes the need of integrating community-driven research approaches to identify culturally relevant biases often neglected by automated systems. Our research enhances the ongoing discussion around gender bias in AI by illustrating the need to create linguistic tools specifically designed for underrepresented languages. This study establishes a foundation for further investigations into bias reduction in Bengali and other Indic languages, promoting the development of more inclusive and fair NLP systems.

</details>


### [277] [DPI: Exploiting Parameter Heterogeneity for Interference-Free Fine-Tuning](https://arxiv.org/abs/2601.17777)
*Xiaoyu Liu,Xiaoyu Guan,Di Liang,Xianjie Wu*

Main category: cs.CL

TL;DR: 提出了一种动态参数隔离方法，通过识别和冻结任务核心参数来解决大规模语言模型（LLM）在有监督微调（SFT）中遇到的“跷跷板效应”，以提高跨任务性能。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）在适配大型语言模型（LLM）到下游任务中至关重要，但不同SFT任务之间的冲突目标会导致“跷跷板效应”，即优化一个任务可能损害其他任务的性能，尤其是当模型参数被无差别地更新时。这种参数异质性被认为是跨任务干扰的根源。

Method: 该方法首先独立微调LLM以识别每个任务的核心参数区域（参数更新幅度最大的子集）。然后，将核心参数区域高度重叠的任务合并进行联合训练，并将不重叠的任务组织成不同阶段。在多阶段SFT中，将先前任务的核心参数冻结，以防止后续任务的覆盖。

Result: 在多个公开数据集上的实验表明，所提出的动态参数隔离策略能够持续减少数据冲突，并与多阶段和多任务微调基线相比，实现了持续的性能提升。

Conclusion: 动态参数隔离是一种有效的方法，可以解决SFT中LLM的“跷跷板效应”，通过分离和隔离任务特定的参数区域，从而在多个下游任务上实现更稳定和一致的性能。

Abstract: Supervised fine-tuning (SFT) is a crucial step for adapting large language models (LLMs) to downstream tasks. However, conflicting objectives across heterogeneous SFT tasks often induce the "seesaw effect": optimizing for one task may degrade performance on others, particularly when model parameters are updated indiscriminately. In this paper, we propose a principled approach to disentangle and isolate task-specific parameter regions, motivated by the hypothesis that parameter heterogeneity underlies cross-task interference. Specifically, we first independently fine-tune LLMs on diverse SFT tasks and identify each task's core parameter region as the subset of parameters exhibiting the largest updates. Tasks with highly overlapping core parameter regions are merged for joint training, while disjoint tasks are organized into different stages. During multi-stage SFT, core parameters acquired in prior tasks are frozen, thereby preventing overwriting by subsequent tasks. To verify the effectiveness of our method, we conducted intensive experiments on multiple public datasets. The results showed that our dynamic parameter isolation strategy consistently reduced data conflicts and achieved consistent performance improvements compared to multi-stage and multi-task tuning baselines.

</details>


### [278] [Controlling Reading Ease with Gaze-Guided Text Generation](https://arxiv.org/abs/2601.17781)
*Andreas Säuberli,Darja Jepifanova,Diego Frassinelli,Barbara Plank*

Main category: cs.CL

TL;DR: 研究提出了一种利用眼动追踪模型来控制文本生成模型输出，从而生成具有可控阅读难度的文本的方法。


<details>
  <summary>Details</summary>
Motivation: 通过分析阅读时的眼动模式来理解文本处理的认知负荷，并在此基础上生成具有可控阅读难度的文本。

Method: 利用一个预测人类注视模式的模型来指导语言模型生成文本，使其能够诱发特定的阅读行为。通过眼动追踪实验评估该方法的有效性。

Result: 实验结果表明，该方法能够有效地生成更容易或更难阅读的文本，这在阅读时间和感知难度上都有体现。统计分析显示，阅读行为的变化主要受影响词汇处理的文本特征的影响。

Conclusion: 该方法在生成具有可控阅读难度的文本方面是有效的，并且在文本简化和个性化教育材料生成方面具有潜在应用价值。

Abstract: The way our eyes move while reading can tell us about the cognitive effort required to process the text. In the present study, we use this fact to generate texts with controllable reading ease. Our method employs a model that predicts human gaze patterns to steer language model outputs towards eliciting certain reading behaviors. We evaluate the approach in an eye-tracking experiment with native and non-native speakers of English. The results demonstrate that the method is effective at making the generated texts easier or harder to read, measured both in terms of reading times and perceived difficulty of the texts. A statistical analysis reveals that the changes in reading behavior are mostly due to features that affect lexical processing. Possible applications of our approach include text simplification for information accessibility and generation of personalized educational material for language learning.

</details>


### [279] [Beyond a Single Perspective: Text Anomaly Detection with Multi-View Language Representations](https://arxiv.org/abs/2601.17786)
*Yixin Liu,Kehan Yan,Shiyuan Li,Qingfeng Chen,Shirui Pan*

Main category: cs.CL

TL;DR: 本文提出了一种名为 MCA^2 的多视图文本异常检测框架，该框架利用多个预训练语言模型的嵌入，并通过对比协作和自适应分配模块来提高其性能和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的“嵌入-检测器”文本异常检测方法通常仅使用单一嵌入模型，在处理不同数据集和异常类型时适应性不足。

Method: MCA^2 框架采用多视图重构模型来提取正常文本模式，并集成了一个对比协作模块来利用视图间的互补性，以及一个自适应分配模块来自动分配各视图的贡献权重。

Result: 在10个基准数据集上的大量实验表明，MCA^2 相较于现有强基线方法表现出优越的性能。

Conclusion: MCA^2 框架通过融合多模型嵌入并引入视图间交互和自适应机制，有效解决了现有文本异常检测方法的局限性，在多种数据集上展现了强大的性能和良好的适应性。

Abstract: Text anomaly detection (TAD) plays a critical role in various language-driven real-world applications, including harmful content moderation, phishing detection, and spam review filtering. While two-step "embedding-detector" TAD methods have shown state-of-the-art performance, their effectiveness is often limited by the use of a single embedding model and the lack of adaptability across diverse datasets and anomaly types. To address these limitations, we propose to exploit the embeddings from multiple pretrained language models and integrate them into $MCA^2$, a multi-view TAD framework. $MCA^2$ adopts a multi-view reconstruction model to effectively extract normal textual patterns from multiple embedding perspectives. To exploit inter-view complementarity, a contrastive collaboration module is designed to leverage and strengthen the interactions across different views. Moreover, an adaptive allocation module is developed to automatically assign the contribution weight of each view, thereby improving the adaptability to diverse datasets. Extensive experiments on 10 benchmark datasets verify the effectiveness of $MCA^2$ against strong baselines. The source code of $MCA^2$ is available at https://github.com/yankehan/MCA2.

</details>


### [280] [DIETA: A Decoder-only transformer-based model for Italian-English machine TrAnslation](https://arxiv.org/abs/2601.17823)
*Pranav Kasela,Marco Braga,Alessandro Ghiotto,Andrea Pilzer,Marco Viviani,Alessandro Raganato*

Main category: cs.CL

TL;DR: 本文提出了一种名为DIETA的小型Transformer模型（0.5B参数），专门用于意大利语-英语机器翻译。通过构建大型平行语料库（2.07亿句对）和反向翻译数据（3.52亿句），并创建新的评估集，DIETA在多个意大利语-英语基准测试中表现出色，性能接近前沿模型，优于大多数同等规模模型。


<details>
  <summary>Details</summary>
Motivation: 现有意大利语-英语机器翻译模型在性能、模型大小和数据可用性方面存在不足，研究者希望开发一个高效、资源占用少且易于访问的模型。

Method: 提出DIETA模型（0.5B参数，decoder-only Transformer架构）。收集并整理了包含约2.07亿意大利语-英语句对的大型平行语料库，并使用了3.52亿反向翻译数据。创建了一个包含450个句子（基于2025篇WikiNews文章）的新评估集。在多个意大利语-英语基准测试上进行了评估。

Result: DIETA在多个意大利语-英语基准测试中表现出具有竞争力的性能，在32个模型组成的排行榜中稳定排名前二分之一，并且在五个测试集中的四个上优于大多数其他参数量小于3B的模型。

Conclusion: DIETA是一个高效的意大利语-英语机器翻译模型，通过大规模语料库和新评估集的构建，为该领域的进一步研究和开发提供了宝贵的资源。模型、训练脚本、语料库和评估集均已开源。

Abstract: In this paper, we present DIETA, a small, decoder-only Transformer model with 0.5 billion parameters, specifically designed and trained for Italian-English machine translation. We collect and curate a large parallel corpus consisting of approximately 207 million Italian-English sentence pairs across diverse domains, including parliamentary proceedings, legal texts, web-crawled content, subtitles, news, literature and 352 million back-translated data using pretrained models. Additionally, we create and release a new small-scale evaluation set, consisting of 450 sentences, based on 2025 WikiNews articles, enabling assessment of translation quality on contemporary text. Comprehensive evaluations show that DIETA achieves competitive performance on multiple Italian-English benchmarks, consistently ranking in the second quartile of a 32-system leaderboard and outperforming most other sub-3B models on four out of five test suites. The training script, trained models, curated corpus, and newly introduced evaluation set are made publicly available, facilitating further research and development in specialized Italian-English machine translation. https://github.com/pkasela/DIETA-Machine-Translation

</details>


### [281] [Linguistic and Argument Diversity in Synthetic Data for Function-Calling Agents](https://arxiv.org/abs/2601.17829)
*Dan Greenstein,Zohar Karnin,Chen Amiraz,Oren Somekh*

Main category: cs.CL

TL;DR: 本文提出了一种无需规则或分类法即可生成高质量、多样化函数调用数据集的方法，通过优化查询和参数的通用多样性指标。实验证明，该方法生成的数据集在多样性方面优于现有方法，并且训练出的模型在分布外性能上表现更佳，在 BFCL 基准测试中准确率提升了 7.4%。


<details>
  <summary>Details</summary>
Motivation: 现有函数调用代理训练数据在函数、调用模式和交互轮次方面注重多样性，但忽略了用户请求的语言多样性和参数（如城市名、股票代码）的覆盖范围。为了解决这个问题，需要一种新的数据生成方法。

Method: 提出了一种通过优化查询和参数的通用多样性指标来生成合成数据集的方法。该方法不依赖于手工规则或分类法，使其能够适应不同的用例。通过内在和外在测试来评估其有效性。

Result: 与现有方法相比，该技术在多样性方面表现出优势，同时保持了可比的正确性。使用生成的数据集训练的模型，在分布外性能上优于使用基线方法生成的数据集训练的模型。具体来说，在 BFCL 基准测试中的准确率提高了 7.4%。

Conclusion: 所提出的合成数据集生成方法是一种有效且通用的方法，可以显著提高函数调用代理训练数据的多样性，尤其是在语言和参数覆盖方面。通过使用这种生成的数据集进行训练，可以获得在分布外场景下性能更优越的模型。

Abstract: The construction of function calling agents has emerged as a promising avenue for extending model capabilities. A major challenge for this task is obtaining high quality diverse data for training. Prior work emphasizes diversity in functions, invocation patterns, and interaction turns, yet linguistic diversity of requests and coverage of arguments (e.g., \texttt{city\_name}, \texttt{stock\_ticker}) remain underexplored. We propose a method that generates synthetic datasets via optimizing general-purpose diversity metrics across both queries and arguments, without relying on hand-crafted rules or taxonomies, making it robust to different usecases. We demonstrate the effectiveness of our technique via both intrinsic and extrinsic testing, comparing it to SoTA data generation methods. We show a superiority over baselines in terms of diversity, while keeping comparable correctness. Additionally, when used as a training set, the model resulting from our dataset exhibits superior performance compared to analogous models based on the baseline data generation methods in out-of-distribution performance. In particular, we achieve an $7.4\%$ increase in accuracy on the BFCL benchmark compared to similar counterparts.

</details>


### [282] [EFT-CoT: A Multi-Agent Chain-of-Thought Framework for Emotion-Focused Therapy](https://arxiv.org/abs/2601.17842)
*Lanqing Du,Yunong Li,YuJie Long,Shihong Chen*

Main category: cs.CL

TL;DR: 该研究提出了一种基于情绪聚焦疗法（EFT）的多智能体思维链（EFT-CoT）框架，用于心理健康问答，以解决现有方法忽视情绪体验的问题。该框架通过“躯体感知-认知探索-叙事干预”三个阶段，并结合8个专业智能体，以“自下而上”的方式进行干预。研究还构建了一个名为“EFT-Instruct”的数据集，并训练了EFT-LLM模型。实验结果表明，EFT-LLM在共情深度和专业结构方面优于基线模型和人类回复。


<details>
  <summary>Details</summary>
Motivation: 现有基于认知行为疗法（CBT）的心理健康问答方法多采用“自上而下”的理性重构，忽略了客户的具身体验和初级情绪处理，而这对于心理健康干预至关重要。

Method: 提出了一种基于情绪聚焦疗法（EFT）的多智能体思维链（EFT-CoT）框架。该框架采用“自下而上”的路径，将干预过程分解为“躯体感知 - 认知探索 - 叙事干预”三个推理阶段。利用8个专门的智能体来执行躯体感知映射、适应性评估、核心信念提取和叙事重构等关键任务。同时，构建了“EFT-Instruct”数据集，并通过思维链蒸馏约67,000条真实文本对EFT-LLM模型进行了微调。

Result: EFT-LLM在共情深度和结构专业性等指标上，超越了强基线模型和人类回复。消融研究证实了多智能体机制的必要性。模型展现出优越的心理推理能力。

Conclusion: EFT-CoT框架通过整合EFT的“自下而上”方法和多智能体机制，为构建可解释、高共情的心理咨询系统提供了一条有效的途径，解决了现有LLM在心理健康问答中忽视情绪体验的问题。

Abstract: Leveraging Large Language Models (LLMs) for Mental Health Question Answering (MHQA) is promising for mitigating resource shortages. However, existing Cognitive Behavioral Therapy (CBT)-based approaches predominantly favor a "top-down" rational restructuring, often neglecting clients' embodied experiences and primary emotion processing. To address this, we propose an Emotion-Focused Therapy (EFT)-based Multi-Agent Chain-of-Thought framework (EFT-CoT). Adopting a "bottom-up" trajectory, it deconstructs the intervention into a three-stage reasoning flow: "Embodied Perception - Cognitive Exploration - Narrative Intervention." Utilizing eight specialized agents, the system explicitly executes critical components such as somatic awareness mapping, adaptive assessment, core belief extraction, and narrative restructuring. We further constructed "EFT-Instruct," a high-quality dataset via Chain-of-Thought distillation of approximately 67,000 authentic texts, and fine-tuned a specialized model, EFT-LLM. Experimental evaluations demonstrate that EFT-LLM outperforms strong baselines and human responses across metrics like empathy depth and structural professionalism. Ablation studies confirm the necessity of the multi-agent mechanism. The model exhibits superior psychological reasoning, offering an effective pathway for interpretable, high-empathy counseling systems.

</details>


### [283] [On the Emergence and Test-Time Use of Structural Information in Large Language Models](https://arxiv.org/abs/2601.17869)
*Michelle Chao Chen,Moritz Miller,Bernhard Schölkopf,Siyuan Guo*

Main category: cs.CL

TL;DR: 本文研究了语言模型如何学习和利用抽象结构信息，并通过设计基于语言结构转换的自然语言数据集进行了实证分析，发现结构学习能力与复杂推理能力相关，但测试时组合生成能力有限。


<details>
  <summary>Details</summary>
Motivation: 在训练数据之外生成新知识（如科学发现中的机制理解和测试时的灵活组合生成）需要从观察数据中学习结构信息，这促使了本研究。

Method: 设计了一个基于语言结构转换的自然语言数据集，并在此数据集上进行实证研究，以受控的方式探究语言模型学习和利用结构信息的能力。

Result: 实证表明，语言模型学习结构信息的能力的出现与执行复杂推理任务的能力相关，然而，在测试时进行组合生成的能力仍然有限。

Conclusion: 语言模型在学习结构信息方面取得了一定的进展，这与其复杂推理能力的发展有关，但它们在利用这些结构信息进行灵活的测试时组合生成方面仍存在显著的局限性。

Abstract: Learning structural information from observational data is central to producing new knowledge outside the training corpus. This holds for mechanistic understanding in scientific discovery as well as flexible test-time compositional generation. We thus study how language models learn abstract structures and utilize the learnt structural information at test-time. To ensure a controlled setup, we design a natural language dataset based on linguistic structural transformations. We empirically show that the emergence of learning structural information correlates with complex reasoning tasks, and that the ability to perform test-time compositional generation remains limited.

</details>


### [284] [D-Models and E-Models: Diversity-Stability Trade-offs in the Sampling Behavior of Large Language Models](https://arxiv.org/abs/2601.17865)
*Jia Gu,Liang Pang,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在生成下一个token的概率（P_token）上存在两种行为模式：D-模型（如Qwen-2.5）P_token变异性大且与任务目标分布（P_task）对齐性差；E-模型（如Mistral-Small）P_token更稳定且与P_task对齐性好。这种差异在代码生成和推荐等下游任务中表现为多样性与稳定性的权衡，并可通过分析模型内部机制来理解。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）生成的样本虽然能近似真实世界分布，但其精细的采样概率是否忠实地符合任务要求（即任务目标分布 P_task）是一个悬而未决的问题。研究旨在探究LLMs的采样概率行为与其任务目标之间的关系。

Method: 通过受控的分布采样模拟实验，比较不同LLMs的P_token与P_task的对齐性。此外，在代码生成和推荐等下游任务中评估两种模型类型的表现，并分析其内部属性以探究潜在机制。

Result: 发现了LLMs行为上的“二象性”：D-模型（如Qwen-2.5）的P_token步进变异性大，与P_task对齐性差；E-模型（如Mistral-Small）的P_token更稳定，与P_task对齐性好。在下游任务中，这两种模型类型展现出塑造任务结果的多样性与稳定性的系统性权衡。

Conclusion: LLMs的采样概率行为存在D-模型和E-模型两种模式，这两种模式在下游任务中表现出多样性与稳定性的权衡。研究结果为理解LLMs的概率采样行为提供了基础性见解，并为在实际应用中根据需求选择D-模型或E-模型提供了实用指导，尤其是在推荐、搜索和对话代理等需要平衡多样性与可靠性的场景下。

Abstract: The predictive probability of the next token (P_token) in large language models (LLMs) is inextricably linked to the probability of relevance for the next piece of information, the purchase probability of the next product, and the execution probability of the next action-all of which fall under the scope of the task-level target distribution (P_task). While LLMs are known to generate samples that approximate real-world distributions, whether their fine-grained sampling probabilities faithfully align with task requirements remains an open question. Through controlled distribution-sampling simulations, we uncover a striking dichotomy in LLM behavior, distinguishing two model types: D-models (e.g. Qwen-2.5), whose P_token exhibits large step-to-step variability and poor alignment with P_task; and E-models (e.g. Mistral-Small), whose P_token is more stable and better aligned with P_task. We further evaluate these two model types in downstream tasks such as code generation and recommendation, revealing systematic trade-offs between diversity and stability that shape task outcomes. Finally, we analyze the internal properties of both model families to probe their underlying mechanisms. These findings offer foundational insights into the probabilistic sampling behavior of LLMs and provide practical guidance on when to favor D- versus E-models. For web-scale applications, including recommendation, search, and conversational agents, our results inform model selection and configuration to balance diversity with reliability under real-world uncertainty, providing a better level of interpretation.

</details>


### [285] [Self-Manager: Parallel Agent Loop for Long-form Deep Research](https://arxiv.org/abs/2601.17879)
*Yilong Xu,Zhi Zheng,Xiang Long,Yujun Cai,Yiwei Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为Self-Manager的并行智能体框架，通过异步并发执行和独立的上下文管理，解决了现有智能体在处理长篇深度研究任务时面临的上下文累积和信息丢失问题，并在DeepResearch Bench上取得了优于现有基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能体在处理长篇深度研究任务时，受限于单一上下文窗口和顺序执行模式，容易出现上下文累积、信息丢失、相互干扰和阻塞等问题，限制了其可扩展性和适应性。

Method: 提出了一种名为Self-Manager的并行智能体框架，采用主线程创建多个拥有独立上下文的子线程，并通过Thread Control Blocks进行迭代管理，实现异步并发执行。

Result: 在DeepResearch Bench基准测试中，Self-Manager在所有指标上均优于现有的单智能体循环基线模型。实验证明了Self-Manager设计选择的必要性，以及其在上下文容量、效率和泛化能力方面的优势。

Conclusion: Self-Manager通过并行异步执行和独立的上下文管理，有效地解决了长篇深度研究任务中现有智能体的局限性，提高了性能和效率，并展现出良好的泛化能力。

Abstract: Long-form deep research requires multi-faceted investigations over extended horizons to get a comprehensive report. When handling such complex tasks, existing agents manage context at the subtask level to overcome linear context accumulation and information loss. However, they still adhere to a single context window and sequential execution paradigm, which results in mutual interference and blocking behavior, restricting scalability and adaptability. To address this issue, this paper introduces Self-Manager, a parallel agent loop that enables asynchronous and concurrent execution. The main thread can create multiple subthreads, each with its own isolated context, and manage them iteratively through Thread Control Blocks, allowing for more focused and flexible parallel agent execution. To assess its effectiveness, we benchmark Self-Manager on DeepResearch Bench, where it consistently outperforms existing single-agent loop baselines across all metrics. Furthermore, we conduct extensive analytical experiments to demonstrate the necessity of Self-Manager's design choices, as well as its advantages in contextual capacity, efficiency, and generalization.

</details>


### [286] [ShapLoRA: Allocation of Low-rank Adaption on Large Language Models via Shapley Value Inspired Importance Estimation](https://arxiv.org/abs/2601.17921)
*Yi Zhao,Qinghua Yao,Xinyuan song,Wei Zhu*

Main category: cs.CL

TL;DR: 提出了一种名为ShapLoRA的框架，通过借鉴Shapley Value的思想，提出了一种更具可解释性的重要性度量方法“Shapley sensitivity”，用于优化LoRA的秩分配，并在各种任务上取得了优于现有基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA秩分配方法依赖于不可解释且不可靠的重要性度量，限制了其性能提升。研究旨在提出一种更具可解释性的秩分配方法。

Method: 提出ShapLoRA框架，结合了基于敏感度的度量和合作博弈中关于LoRA秩的联盟思想，提出“Shapley sensitivity”作为重要性度量。优化了工作流程，包括在独立的验证集上计算Shapley sensitivity，并设置公平比较的分配-再训练流程。

Result: 在各种挑战性任务上的实验表明，ShapLoRA方法在可调参数量相当的情况下，性能优于近期的基线方法。

Conclusion: ShapLoRA通过更具可解释性的重要性度量有效优化了LoRA的秩分配，从而提升了模型性能，并且其工作流程的优化保证了实验的公平性。

Abstract: Low-rank adaption (LoRA) is a representative method in the field of parameter-efficient fine-tuning (PEFT), and is key to Democratizating the modern large language models (LLMs). The vanilla LoRA is implemented with uniform ranks, and the recent literature have found that properly allocating ranks on the LLM backbones results in performance boosts. However, the previous rank allocation methods have limitations since they rely on inexplanable and unreliable importance measures for the LoRA ranks. To address the above issues, we propose the ShapLoRA framework. Inspired by the explanable attribution measure Shapley Value, we combine the sensitivity-based measures with the idea of coalitions in the collaborative games among LoRA ranks, and propose a more explainable importance measure called Shapley sensitivity. In addition, we optimize the workflow of the existing works by: (a) calculating Shapley sensitivity on a separate validation set; (b) Setting up the allocating-retraining procedures for fair comparisons. We have conducted experiments on various challenging tasks, and the experimental results demonstrate that our ShapLoRA method can outperform the recent baselines with comparable tunable parameters.\footnote{Codes and fine-tuned models will be open-sourced to facilitate future research.

</details>


### [287] [Assessment of Generative Named Entity Recognition in the Era of Large Language Models](https://arxiv.org/abs/2601.17898)
*Qi Zhan,Yile Wang,Hui Huang*

Main category: cs.CL

TL;DR: 本研究评估了开源大型语言模型（LLMs）在平坦和嵌套命名实体识别（NER）任务上的表现，发现经过参数高效微调并采用结构化输出格式（如内联括号或XML）的LLMs，其性能可与传统模型媲美，甚至超越闭源模型。研究还表明，LLMs的NER能力源于指令遵循和生成能力，而非单纯的记忆；且NER指令微调对LLMs的通用能力影响甚微，甚至可能有所提升。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的兴起，NER任务正从传统的序列标注范式转向生成式范式。研究者希望系统性地评估开源LLMs在这一新范式下的表现，并深入理解其优势、局限性以及对模型通用能力的影响。

Method: 研究者对八个不同规模的开源LLMs在四个标准的NER数据集上进行了实验。他们采用了参数高效微调（PEFT）的方法，并探索了不同的输出格式（如内联括号、XML）。研究还通过设计实验来区分LLMs的NER能力是来源于记忆还是指令遵循与生成能力，并评估了NER指令微调对LLMs通用能力的影响。

Result: 1. 采用PEFT和结构化输出格式的开源LLMs在NER任务上表现出与传统编码器模型相当的性能，并且优于GPT-3等闭源模型。 2. LLMs的NER能力主要来自于指令遵循和生成能力，而非对实体-标签对的简单记忆。 3. NER指令微调对LLMs的通用能力影响很小，甚至在某些任务（如DROP）上有所提升。

Conclusion: 使用大型语言模型进行生成式NER是一种有前景且用户友好的替代方法。开源LLMs在经过适当微调和格式化后，能够有效地执行NER任务，并且其能力根植于其强大的理解和生成能力，而非简单的记忆。NER指令微调不会显著损害模型的通用能力，甚至可能在某些方面增强其性能。

Abstract: Named entity recognition (NER) is evolving from a sequence labeling task into a generative paradigm with the rise of large language models (LLMs). We conduct a systematic evaluation of open-source LLMs on both flat and nested NER tasks. We investigate several research questions including the performance gap between generative NER and traditional NER models, the impact of output formats, whether LLMs rely on memorization, and the preservation of general capabilities after fine-tuning. Through experiments across eight LLMs of varying scales and four standard NER datasets, we find that: (1) With parameter-efficient fine-tuning and structured formats like inline bracketed or XML, open-source LLMs achieve performance competitive with traditional encoder-based models and surpass closed-source LLMs like GPT-3; (2) The NER capability of LLMs stems from instruction-following and generative power, not mere memorization of entity-label pairs; and (3) Applying NER instruction tuning has minimal impact on general capabilities of LLMs, even improving performance on datasets like DROP due to enhanced entity understanding. These findings demonstrate that generative NER with LLMs is a promising, user-friendly alternative to traditional methods. We release the data and code at https://github.com/szu-tera/LLMs4NER.

</details>


### [288] [A Monosemantic Attribution Framework for Stable Interpretability in Clinical Neuroscience Large Language Models](https://arxiv.org/abs/2601.17952)
*Michail Mamalakis,Tiago Azevedo,Cristian Cosentino,Chiara D'Ercoli,Subati Abulikemu,Zhongtian Sun,Richard Bethlehem,Pietro Lio*

Main category: cs.CL

TL;DR: 提出了一种统一的解释框架，通过提取单义特征，融合了归因法和机制解释法的优点，用于提高 LLM 在阿尔茨海默病诊断等临床应用中的可解释性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 解释方法在临床应用（如阿尔茨海默病诊断）中存在解释不稳、方法间变异大等问题，缺乏直接输入输出对齐和明确的重要性评分，阻碍了 LLM 的安全部署。

Method: 通过构建 LLM 层级的单义嵌入空间，并优化框架以减少解释方法间的变异性，从而提取单义特征。该框架结合了归因法和机制解释法的视角，生成稳定的输入重要性评分，并通过解压缩表示突出显示关键特征。

Result: 该框架能够产生稳定的输入级别的重要性评分，并突出显示关键特征，减少了不同解释方法之间的一致性问题。

Conclusion: 提出的统一解释框架通过提取单义特征，有效解决了 LLM 在临床应用中可解释性差的问题，提高了模型预测的稳定性和可靠性，为 LLM 在认知健康和神经退行性疾病领域的安全应用奠定了基础。

Abstract: Interpretability remains a key challenge for deploying large language models (LLMs) in clinical settings such as Alzheimer's disease progression diagnosis, where early and trustworthy predictions are essential. Existing attribution methods exhibit high inter-method variability and unstable explanations due to the polysemantic nature of LLM representations, while mechanistic interpretability approaches lack direct alignment with model inputs and outputs and do not provide explicit importance scores. We introduce a unified interpretability framework that integrates attributional and mechanistic perspectives through monosemantic feature extraction. By constructing a monosemantic embedding space at the level of an LLM layer and optimizing the framework to explicitly reduce inter-method variability, our approach produces stable input-level importance scores and highlights salient features via a decompressed representation of the layer of interest, advancing the safe and trustworthy application of LLMs in cognitive health and neurodegenerative disease.

</details>


### [289] [LLMs as Cultural Archives: Cultural Commonsense Knowledge Graph Extraction](https://arxiv.org/abs/2601.17971)
*Junior Cedric Tonga,Chen Cecilia Liu,Iryna Gurevych,Fajri Koto*

Main category: cs.CL

TL;DR: 该研究提出了一种迭代式、基于提示的框架，利用大型语言模型（LLMs）构建文化常识知识图谱（CCKG），以解决LLMs中文化知识的隐式和非结构化问题。研究发现，即使是针对非英语文化，英文LLMs也更能捕捉文化知识，并且CCKG能提升小型LLMs在文化推理和故事生成方面的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然蕴含丰富的文化知识，但这些知识通常是隐式和非结构化的，限制了其可解释性和应用。因此，需要一种方法来系统地提取和组织这些文化知识。

Method: 研究者提出了一种迭代式、基于提示的框架，将LLMs视为文化档案，系统地提取特定文化的实体、关系和实践，并将它们组合成多步推理链，跨越不同语言。该CCKG框架在五个国家进行了评估。

Result: 1. 英文CCKG的构建效果优于非英语CCKG，即使目标文化是非英语国家。2. 英文推理链对小型LLMs的性能提升最大。3. 增强小型LLMs的CCKG能显著提高其在文化推理和故事生成任务上的表现。

Conclusion: LLMs在文化知识建模方面展现出巨大潜力，但也存在局限性。链式结构的文化知识是实现文化导向的自然语言处理（NLP）的实用基础。

Abstract: Large language models (LLMs) encode rich cultural knowledge learned from diverse web-scale data, offering an unprecedented opportunity to model cultural commonsense at scale. Yet this knowledge remains mostly implicit and unstructured, limiting its interpretability and use. We present an iterative, prompt-based framework for constructing a Cultural Commonsense Knowledge Graph (CCKG) that treats LLMs as cultural archives, systematically eliciting culture-specific entities, relations, and practices and composing them into multi-step inferential chains across languages. We evaluate CCKG on five countries with human judgments of cultural relevance, correctness, and path coherence. We find that the cultural knowledge graphs are better realized in English, even when the target culture is non-English (e.g., Chinese, Indonesian, Arabic), indicating uneven cultural encoding in current LLMs. Augmenting smaller LLMs with CCKG improves performance on cultural reasoning and story generation, with the largest gains from English chains. Our results show both the promise and limits of LLMs as cultural technologies and that chain-structured cultural knowledge is a practical substrate for culturally grounded NLP.

</details>


### [290] [AI-based approach to burnout identification from textual data](https://arxiv.org/abs/2601.17993)
*Marina Zavertiaeva,Petr Parshakov,Mikhail Usanin,Aleksei Smirnov,Sofia Paklina,Anastasiia Kibardina*

Main category: cs.CL

TL;DR: 本研究提出一种基于自然语言处理（NLP）的AI方法，利用RuBERT模型检测文本数据中的职业倦怠。


<details>
  <summary>Details</summary>
Motivation: 为了在大量文本数据中自动检测职业倦怠的迹象，特别是在高压工作环境中。

Method: 使用最初为情感分析训练的RuBERT模型，并结合ChatGPT生成的合成句和俄罗斯YouTube用户评论对模型进行微调，以识别职业倦怠。模型输出文本的职业倦怠概率。

Result: 成功开发了一个能够为输入文本分配职业倦怠概率的RuBERT模型。

Conclusion: 该AI方法能够有效地处理大量文本数据，用于监测职业倦怠相关的语言信号，为在高压工作环境中管理职业倦怠提供了一种新的工具。

Abstract: This study introduces an AI-based methodology that utilizes natural language processing (NLP) to detect burnout from textual data. The approach relies on a RuBERT model originally trained for sentiment analysis and subsequently fine-tuned for burnout detection using two data sources: synthetic sentences generated with ChatGPT and user comments collected from Russian YouTube videos about burnout. The resulting model assigns a burnout probability to input texts and can be applied to process large volumes of written communication for monitoring burnout-related language signals in high-stress work environments.

</details>


### [291] [SD-E$^2$: Semantic Exploration for Reasoning Under Token Budgets](https://arxiv.org/abs/2601.17982)
*Kshitij Mishra,Nils Lukas,Salem Lahlou*

Main category: cs.CL

TL;DR: 本文提出了一种名为 SD-E$^2$ 的强化学习框架，通过优化生成推理轨迹的语义多样性来改进小型语言模型（SLMs）的复杂推理能力，特别是在计算资源有限的情况下。该框架使用冻结的句子嵌入模型来量化语义多样性，并将其与结果正确性和效率相结合，从而提升了模型在 GSM8K、MedMCQA 和 AIME 等基准测试上的表现。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLMs）在进行复杂推理时表现不佳，因为在计算预算有限的情况下，探索成本很高。研究者希望找到一种方法，在不显著增加计算量的情况下，提高 SLMs 的推理能力。

Method: SD-E$^2$ 框架通过最大化生成推理轨迹的语义多样性来指导强化学习过程。它使用一个预训练的句子嵌入模型来计算语义多样性奖励，该奖励考虑了不同解决方案策略的覆盖范围及其在嵌入空间中的平均成对不相似度。这个多样性奖励与结果的正确性和效率相结合，并进行了 z-score 标准化，以稳定训练过程。该方法侧重于调整推理过程的结构（认知适应），而不是增加每个 token 的计算量。

Result: 在 GSM8K 数据集上，SD-E$^2$ 比基线模型 Qwen2.5-3B-Instruct 和 GRPO-CFL、GRPO-CFEE 分别提高了 27.4、5.2 和 1.5 个百分点。SD-E$^2$ 平均每道题能发现 9.8 个语义上不同的推理策略。在 MedMCQA 数据集上，性能从 38.37% 提高到 49.64%。在 AIME 基准测试（1983-2025）上，性能从 6.74% 提高到 13.28%。

Conclusion: 奖励语义新颖性可以为训练具备推理能力的 SLMs 提供更具计算效率的探索-利用信号。SD-E$^2$ 通过引入认知适应，提供了一种在资源受限模型中实现效率提升的互补途径，它通过调整推理过程的结构来提升模型性能，而非增加计算成本。

Abstract: Small language models (SLMs) struggle with complex reasoning because exploration is expensive under tight compute budgets. We introduce Semantic Diversity-Exploration-Exploitation (SD-E$^2$), a reinforcement learning framework that makes exploration explicit by optimizing semantic diversity in generated reasoning trajectories. Using a frozen sentence-embedding model, SD-E$^2$ assigns a diversity reward that captures (i) the coverage of semantically distinct solution strategies and (ii) their average pairwise dissimilarity in embedding space, rather than surface-form novelty. This diversity reward is combined with outcome correctness and solution efficiency in a z-score-normalized multi-objective objective that stabilizes training. On GSM8K, SD-E$^2$ surpasses the base Qwen2.5-3B-Instruct and strong GRPO baselines (GRPO-CFL and GRPO-CFEE) by +27.4, +5.2, and +1.5 percentage points, respectively, while discovering on average 9.8 semantically distinct strategies per question. We further improve MedMCQA to 49.64% versus 38.37% for the base model and show gains on the harder AIME benchmark (1983-2025), reaching 13.28% versus 6.74% for the base. These results indicate that rewarding semantic novelty yields a more compute-efficient exploration-exploitation signal for training reasoning-capable SLMs. By introducing cognitive adaptation-adjusting the reasoning process structure rather than per-token computation-SD-E$^2$ offers a complementary path to efficiency gains in resource-constrained models.

</details>


### [292] [PEAR: Pairwise Evaluation for Automatic Relative Scoring in Machine Translation](https://arxiv.org/abs/2601.18006)
*Lorenzo Proietti,Roman Grundkiewicz,Matt Post*

Main category: cs.CL

TL;DR: PEAR 是一种新的无参考机器翻译质量评估（QE）方法，它将评估问题转化为对两个候选翻译的相对质量进行排序和评分，并在 WMT24 上取得了优于现有方法的成果，且参数量更少，同时还能作为最小贝叶斯风险（MBR）解码的有效工具。


<details>
  <summary>Details</summary>
Motivation: 现有的无参考 QE 方法在评估质量方面仍有提升空间，作者希望提出一种更有效、更鲁棒的方法，能够更好地捕捉翻译质量的细微差别，并减少评估信号的冗余。

Method: PEAR 将 QE 问题重新定义为成对比较问题，给定一个源语言句子和两个候选译文，模型预测它们之间的质量差异方向和幅度。模型通过从人类判断的差异中派生出的成对监督信号进行训练，并引入一个正则化项来鼓励在交换候选翻译顺序时模型预测结果的符号反转。此外，PEAR 还被用作最小贝叶斯风险（MBR）解码的效用函数。

Result: 在 WMT24 元评估基准测试中，PEAR 表现优于使用相同数据和骨干网络的单候选 QE 基线，证明了其成对公式的有效性。尽管参数量远少于近期的大型 QE 模型，PEAR 的性能却超越了它们以及基于参考译文的评估指标。PEAR 产生的评估信号比其他顶级指标更加不冗余。

Conclusion: PEAR 是一种有效的无参考 QE 方法，通过成对比较的公式化，能够在更少的参数量下实现优于现有方法的性能。它还可以作为 MBR 解码的有效工具，在降低成本的同时保持评估质量。

Abstract: We present PEAR (Pairwise Evaluation for Automatic Relative Scoring), a supervised Quality Estimation (QE) metric family that reframes reference-free Machine Translation (MT) evaluation as a graded pairwise comparison. Given a source segment and two candidate translations, PEAR predicts the direction and magnitude of their quality difference. The metrics are trained using pairwise supervision derived from differences in human judgments, with an additional regularization term that encourages sign inversion under candidate order reversal. On the WMT24 meta-evaluation benchmark, PEAR outperforms strictly matched single-candidate QE baselines trained with the same data and backbones, isolating the benefit of the proposed pairwise formulation. Despite using substantially fewer parameters than recent large metrics, PEAR surpasses far larger QE models and reference-based metrics. Our analysis further indicates that PEAR yields a less redundant evaluation signal relative to other top metrics. Finally, we show that PEAR is an effective utility function for Minimum Bayes Risk (MBR) decoding, reducing pairwise scoring cost at negligible impact.

</details>


### [293] [Evaluating Semantic and Syntactic Understanding in Large Language Models for Payroll Systems](https://arxiv.org/abs/2601.18012)
*Hendrika Maclean,Mert Can Cakmak,Muzakkiruddin Ahmed Mohammed,Shames Al Mandalawi,John Talburt*

Main category: cs.CL

TL;DR: 该研究评估了大型语言模型在理解薪资系统、按顺序应用规则和实现精确计算方面的能力，并提出了一种可复现的框架和实用指南，以支持在需要准确性和可审计性的场景中部署LLM。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言理解方面不断进步，但在精确数值计算和可审计输出方面仍不可靠，这限制了它们在高风险应用中的使用。

Method: 研究人员使用合成薪资系统作为案例，构建了一个包含从基本到复杂案例的层级数据集，并测试了多种提示策略（从基础到引导式推理）以及多个模型家族（GPT、Claude、Perplexity、Grok、Gemini）。

Result: 实验结果表明，在某些情况下，细致的提示足以满足要求；而在另一些情况下，则需要显式的计算能力。

Conclusion: 该研究提供了一个紧凑、可复现的框架和实践指导，帮助在需要精确性和保证的场景中部署大型语言模型。

Abstract: Large language models are now used daily for writing, search, and analysis, and their natural language understanding continues to improve. However, they remain unreliable on exact numerical calculation and on producing outputs that are straightforward to audit. We study synthetic payroll system as a focused, high-stakes example and evaluate whether models can understand a payroll schema, apply rules in the right order, and deliver cent-accurate results. Our experiments span a tiered dataset from basic to complex cases, a spectrum of prompts from minimal baselines to schema-guided and reasoning variants, and multiple model families including GPT, Claude, Perplexity, Grok and Gemini. Results indicate clear regimes where careful prompting is sufficient and regimes where explicit computation is required. The work offers a compact, reproducible framework and practical guidance for deploying LLMs in settings that demand both accuracy and assurance.

</details>


### [294] [A System for Name and Address Parsing with Large Language Models](https://arxiv.org/abs/2601.18014)
*Adeeba Tarannum,Muzakkiruddin Ahmed Mohammed,Mert Can Cakmak,Shames Al Mandalawi,John Talburt*

Main category: cs.CL

TL;DR: 本文提出了一种不需微调的、以提示驱动和验证为中心的框架，用于将非结构化的个人和地址文本可靠地转换为结构化数据，在嘈杂和多语言环境下表现优异，并确保了可重复性。


<details>
  <summary>Details</summary>
Motivation: 传统的处理方法在嘈杂或多语言条件下表现不佳，而神经模型和LLM缺乏确定性控制和可重复性。因此，需要一种新的方法来可靠地将非结构化的文本数据转换为结构化数据。

Method: 该方法整合了输入归一化、结构化提示、约束解码和严格的基于规则的验证，并在固定的实验设置下确保可重复性。

Result: 在异构的真实世界地址数据上进行的评估显示，该方法在字段级别精度、模式一致性和置信度校准方面表现出色。

Conclusion: 将确定性验证与生成式提示相结合，提供了一种稳健、可解释且可扩展的结构化信息提取解决方案，为训练密集型或领域特定模型提供了一个实用的替代方案。

Abstract: Reliable transformation of unstructured person and address text into structured data remains a key challenge in large-scale information systems. Traditional rule-based and probabilistic approaches perform well on clean inputs but fail under noisy or multilingual conditions, while neural and large language models (LLMs) often lack deterministic control and reproducibility. This paper introduces a prompt-driven, validation-centered framework that converts free-text records into a consistent 17-field schema without fine-tuning. The method integrates input normalisation, structured prompting, constrained decoding, and strict rule-based validation under fixed experimental settings to ensure reproducibility. Evaluations on heterogeneous real-world address data show high field-level accuracy, strong schema adherence, and stable confidence calibration. The results demonstrate that combining deterministic validation with generative prompting provides a robust, interpretable, and scalable solution for structured information extraction, offering a practical alternative to training-heavy or domain-specific models.

</details>


### [295] [CommonLID: Re-evaluating State-of-the-Art Language Identification Performance on Web Data](https://arxiv.org/abs/2601.18026)
*Pedro Ortiz Suarez,Laurie Burchell,Catherine Arnett,Rafael Mosquera-Gómez,Sara Hincapie-Monsalve,Thom Vaughan,Damian Stewart,Malte Ostendorff,Idris Abdulmumin,Vukosi Marivate,Shamsuddeen Hassan Muhammad,Atnafu Lambebo Tonja,Hend Al-Khalifa,Nadia Ghezaiel Hammouda,Verrah Otiende,Tack Hwa Wong,Jakhongir Saydaliev,Melika Nobakhtian,Muhammad Ravi Shulthan Habibi,Chalamalasetti Kranti,Carol Muchemi,Khang Nguyen,Faisal Muhammad Adam,Luis Frentzen Salim,Reem Alqifari,Cynthia Amol,Joseph Marvin Imperial,Ilker Kesen,Ahmad Mustafid,Pavel Stepachev,Leshem Choshen,David Anugraha,Hamada Nayel,Seid Muhie Yimam,Vallerie Alexandra Putra,My Chiffon Nguyen,Azmine Toushik Wasi,Gouthami Vadithya,Rob van der Goot,Lanwenn ar C'horr,Karan Dua,Andrew Yates,Mithil Bangera,Yeshil Bangera,Hitesh Laxmichand Patel,Shu Okabe,Fenal Ashokbhai Ilasariya,Dmitry Gaynullin,Genta Indra Winata,Yiyuan Li,Juan Pablo Martínez,Amit Agarwal,Ikhlasul Akmal Hanif,Raia Abu Ahmad,Esther Adenuga,Filbert Aurelian Tjiaranata,Weerayut Buaphet,Michael Anugraha,Sowmya Vajjala,Benjamin Rice,Azril Hafizi Amirudin,Jesujoba O. Alabi,Srikant Panda,Yassine Toughrai,Bruhan Kyomuhendo,Daniel Ruffinelli,Akshata A,Manuel Goulão,Ej Zhou,Ingrid Gabriela Franco Ramirez,Cristina Aggazzotti,Konstantin Dobler,Jun Kevin,Quentin Pagès,Nicholas Andrews,Nuhu Ibrahim,Mattes Ruckdeschel,Amr Keleg,Mike Zhang,Casper Muziri,Saron Samuel,Sotaro Takeshita,Kun Kerdthaisong,Luca Foppiano,Rasul Dent,Tommaso Green,Ahmad Mustapha Wali,Kamohelo Makaaka,Vicky Feliren,Inshirah Idris,Hande Celikkanat,Abdulhamid Abubakar,Jean Maillard,Benoît Sagot,Thibault Clérice,Kenton Murray,Sarah Luger*

Main category: cs.CL

TL;DR: 本文介绍了CommonLID，一个包含109种语言的、由社区驱动且经过人工标注的、针对网络领域语言识别（LID）的基准数据集，旨在解决现有LID模型在网络数据上的不足，并评估了八个流行的LID模型。


<details>
  <summary>Details</summary>
Motivation: 现有LID模型在处理网络数据时表现不佳，尤其是对许多服务不足的语言。这阻碍了多语言模型的训练和代表性语料库的构建。因此，需要一个针对网络领域的、包含更多语言且经过高质量标注的LID基准。

Method: 构建了一个社区驱动、人工标注的LID基准CommonLID，覆盖109种语言，特别关注服务不足的语言。使用CommonLID以及其他五个评估集，对八个流行的LID模型进行了测试和分析。

Result: 评估结果显示，现有LID模型在网络域的许多语言上的准确性被高估了。CommonLID作为一个新的评估集，暴露了现有模型的局限性，并为评估多语言LID模型提供了一个更准确的视角。

Conclusion: CommonLID是一个宝贵的资源，可以促进更具代表性、高质量文本语料库的开发，并推动LID技术在网络领域的发展。作者开源了CommonLID数据集和相关代码，以促进研究的进一步发展。

Abstract: Language identification (LID) is a fundamental step in curating multilingual corpora. However, LID models still perform poorly for many languages, especially on the noisy and heterogeneous web data often used to train multilingual language models. In this paper, we introduce CommonLID, a community-driven, human-annotated LID benchmark for the web domain, covering 109 languages. Many of the included languages have been previously under-served, making CommonLID a key resource for developing more representative high-quality text corpora. We show CommonLID's value by using it, alongside five other common evaluation sets, to test eight popular LID models. We analyse our results to situate our contribution and to provide an overview of the state of the art. In particular, we highlight that existing evaluations overestimate LID accuracy for many languages in the web domain. We make CommonLID and the code used to create it available under an open, permissive license.

</details>


### [296] [Addressing LLM Diversity by Infusing Random Concepts](https://arxiv.org/abs/2601.18053)
*Pulin Agrawal,Prasoon Goyal*

Main category: cs.CL

TL;DR: 通过在提示中加入随机概念，可以提高大型语言模型（LLMs）生成内容的样性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的输出多样性有限，作者希望研究是否可以通过在提示中注入随机概念来改善这一点。

Method: 设计了一个系统的评估协议，通过向LLM提出诸如“列出10位好莱坞演员”之类的问题，并在提示前添加与问题无关的随机词语或句子，然后分析LLM生成输出的多样性指标。

Result: 实验表明，在提示前添加随机词语/句子可以提高LLM生成输出的多样性。

Conclusion: 在提示中注入随机概念是一种提高LLM输出多样性的有效方法，该方法和评估协议为未来的相关研究（如将随机性应用于其他领域）以及系统性地评估LLM多样性提供了新的方向。

Abstract: Large language models (LLMs) are known to produce outputs with limited diversity. In this work, we study whether infusing random concepts in the prompts can improve the diversity of the generated outputs. To benchmark the approach, we design a systematic evaluation protocol which involves prompting an LLM with questions of the form "Name 10 Hollywood actors", and analyzing diversity measures of the resulting LLM outputs. Our experiments on multiple LLMs show that prepending random words/sentences unrelated to the prompt result in greater diversity in the outputs of LLMs. We believe that this promising result and the evaluation protocol opens up interesting avenues for future work, such as how infusing randomness into LLMs could be applied to other domains. Further, the evaluation protocol could also inspire research into benchmarking LLM diversity more systematically.

</details>


### [297] [Neurocomputational Mechanisms of Syntactic Transfer in Bilingual Sentence Production](https://arxiv.org/abs/2601.18056)
*Ahmet Yavuz Uluslu,Elliot Murphy*

Main category: cs.CL

TL;DR: 本文提出将振荡信号纳入双语加工错误研究，以提供新的理论约束。作者认为，ROSE模型可以解释双语生产中的句法迁移，并将其与特定的振荡失调联系起来。


<details>
  <summary>Details</summary>
Motivation: 传统上，双语加工错误的研究依赖于事件相关电位等时序信号，但这些信号在解释实现层面存在局限。作者希望引入振荡信号，为双语理论提供更精细的神经计算解释。

Method: 作者提出将振荡信号（而非仅时序信号）整合到双语加工错误研究中。他们使用ROSE模型来模拟句法迁移，并将其与特定的振荡失调联系起来，以解释跨语言影响（CLI）和功能抑制/竞争理论。

Result: ROSE模型能够捕捉句法迁移的某些形式属性和形态句法序列失败模式。CLI可以被解释为L2句子规划过程中特定的振荡失调。

Conclusion: 将振荡信号纳入双语研究，可以为双语理论提供更深入的实现层面解释，并且有望发现比传统信号更复杂、时空更精细的语言功能障碍生物标志物。

Abstract: We discuss the benefits of incorporating into the study of bilingual production errors and their traditionally documented timing signatures (e.g., event-related potentials) certain types of oscillatory signatures, which can offer new implementational-level constraints for theories of bilingualism. We argue that a recent neural model of language, ROSE, can offer a neurocomputational account of syntactic transfer in bilingual production, capturing some of its formal properties and the scope of morphosyntactic sequencing failure modes. We take as a case study cross-linguistic influence (CLI) and attendant theories of functional inhibition/competition, and present these as being driven by specific oscillatory failure modes during L2 sentence planning. We argue that modeling CLI in this way not only offers the kind of linking hypothesis ROSE was built to encourage, but also licenses the exploration of more spatiotemporally complex biomarkers of language dysfunction than more commonly discussed neural signatures.

</details>


### [298] [Grounded Concreteness: Human-Like Concreteness Sensitivity in Vision-Language Models](https://arxiv.org/abs/2601.18065)
*Aryan Roy,Zekun Wang,Christopher J. MacLellan*

Main category: cs.CL

TL;DR: 研究了视觉-语言模型（VLMs）在仅文本提示下是否比纯文本大型语言模型（LLMs）对语言具体性更具人类般的敏感性，通过比较Llama模型及其视觉对应模型，并在输出行为、嵌入几何和注意力动态三个层面进行评估。


<details>
  <summary>Details</summary>
Motivation: 探究视觉-语言模型（VLMs）在处理仅文本信息时，相比于纯文本大型语言模型（LLMs），是否能产生更符合人类语言具体性认知。

Method: 使用匹配的Llama文本骨干模型及其视觉对应模型（VLMs）进行对比研究，并将多模态预训练视为对感知基础的消融而非推理时访问图像。在三个层面进行测量：(i) 输出行为（问题具体性与QA准确率的关系）；(ii) 嵌入几何（表征是否沿具体性轴组织）；(iii) 注意力动态（通过注意力熵衡量上下文依赖）。此外，还提取了模型生成的token级具体性评分，并评估其与人类评分的一致性。

Result: 在不同基准和模型规模下，VLMs在处理更具体输入时表现出更大的提升，其表征结构更清晰地体现了具体性，生成的评分与人类规范更一致，并且其注意力模式的系统性差异表明感知基础有所增强。

Conclusion: 视觉-语言模型（VLMs）在仅文本输入下，相较于纯文本模型，表现出对语言具体性更强、更像人类的敏感性，这得益于多模态预训练带来的感知基础的增强。

Abstract: Do vision--language models (VLMs) develop more human-like sensitivity to linguistic concreteness than text-only large language models (LLMs) when both are evaluated with text-only prompts? We study this question with a controlled comparison between matched Llama text backbones and their Llama Vision counterparts across multiple model scales, treating multimodal pretraining as an ablation on perceptual grounding rather than access to images at inference. We measure concreteness effects at three complementary levels: (i) output behavior, by relating question-level concreteness to QA accuracy; (ii) embedding geometry, by testing whether representations organize along a concreteness axis; and (iii) attention dynamics, by quantifying context reliance via attention-entropy measures. In addition, we elicit token-level concreteness ratings from models and evaluate alignment to human norm distributions, testing whether multimodal training yields more human-consistent judgments. Across benchmarks and scales, VLMs show larger gains on more concrete inputs, exhibit clearer concreteness-structured representations, produce ratings that better match human norms, and display systematically different attention patterns consistent with increased grounding.

</details>


### [299] [CHiRPE: A Step Towards Real-World Clinical NLP with Clinician-Oriented Model Explanations](https://arxiv.org/abs/2601.18102)
*Stephanie Fong,Zimu Wang,Guilherme C. Oliveira,Xiangyu Zhao,Yiwen Jiang,Jiahe Liu,Beau-Luke Colton,Scott Woods,Martha E. Shenton,Barnaby Nelson,Zongyuan Ge,Dominic Dwyer*

Main category: cs.CL

TL;DR: 研究提出了CHiRPE（Clinical High-Risk Prediction with Explainability）NLP流程，用于预测精神分裂症风险并生成与临床医生共同开发的新型SHAP解释格式。该方法在AMP-SCZ研究的944份临床访谈记录上进行了训练，实现了90%以上的准确率，并且临床专家更偏好其新颖的概念引导式解释格式。


<details>
  <summary>Details</summary>
Motivation: 现有可解释AI（XAI）方法与临床推理不符，且缺乏临床医生的参与，这阻碍了NLP工具在医疗领域的应用。因此，需要开发符合临床需求且具有可解释性的NLP工具。

Method: CHiRPE流程整合了症状领域映射、LLM（大型语言模型）摘要和BERT分类。它对944份半结构化临床访谈记录进行处理，以预测精神分裂症风险，并生成与临床医生共同设计的、概念引导式的新型SHAP解释格式（包括混合图文摘要）。

Result: CHiRPE在三种BERT变体上实现了超过90%的准确率，优于基线模型。28名临床专家评估后，强烈偏好CHiRPE提出的概念引导式解释格式，尤其是混合图文摘要格式。

Conclusion: 通过临床指导的模型开发，可以同时实现准确性和可解释性。CHiRPE证明了这一点，并且下一步计划在24个国际临床点进行实际测试。

Abstract: The medical adoption of NLP tools requires interpretability by end users, yet traditional explainable AI (XAI) methods are misaligned with clinical reasoning and lack clinician input. We introduce CHiRPE (Clinical High-Risk Prediction with Explainability), an NLP pipeline that takes transcribed semi-structured clinical interviews to: (i) predict psychosis risk; and (ii) generate novel SHAP explanation formats co-developed with clinicians. Trained on 944 semi-structured interview transcripts across 24 international clinics of the AMP-SCZ study, the CHiRPE pipeline integrates symptom-domain mapping, LLM summarisation, and BERT classification. CHiRPE achieved over 90% accuracy across three BERT variants and outperformed baseline models. Explanation formats were evaluated by 28 clinical experts who indicated a strong preference for our novel concept-guided explanations, especially hybrid graph-and-text summary formats. CHiRPE demonstrates that clinically-guided model development produces both accurate and interpretable results. Our next step is focused on real-world testing across our 24 international sites.

</details>


### [300] [Sparks of Cooperative Reasoning: LLMs as Strategic Hanabi Agents](https://arxiv.org/abs/2601.18077)
*Mahesh Ramesh,Kaousheik Jayakumar,Aswinkumar Ramkumar,Pavan Thodima,Aniket Rege*

Main category: cs.CL

TL;DR: 研究人员评估了17种先进的大型语言模型（LLM）在多人游戏Hanabi中的合作推理能力，并研究了不同程度的上下文工程（从基本提示到包含贝叶斯推理和工作记忆的复杂提示）对模型性能的影响。结果表明，LLM可以有效利用内部工作记忆进行状态跟踪，并且模型能力与跨模型交互表现之间存在平滑的插值关系。在最高级别的上下文工程下，最强的模型平均得分可达15分，但仍低于人类专家和专用Hanabi代理。研究发布了首批带注释的Hanabi数据集，并利用这些数据对一个40亿参数的模型进行了微调，显著提升了其在Hanabi游戏中的表现，并使其在多个其他任务（包括常识推理、数学推理等）上表现出色。


<details>
  <summary>Details</summary>
Motivation: 合作推理，特别是在信息不完整的情况下，对于人类和多智能体系统都是一个挑战。Hanabi游戏作为一个典型的例子，需要玩家具备心智理论推理和策略性沟通能力。本研究旨在评估现有先进LLM在Hanabi游戏中的合作推理能力，并探索上下文工程和模型规模如何影响其协调失败和鲁棒性。

Method: 研究人员在2-5人Hanabi游戏中测试了17种先进的LLM代理。他们采用了三种不同程度的上下文工程策略：Watson（仅提供显式卡牌信息）、Sherlock（加入程序化的、受贝叶斯启发的推理）和Mycroft（通过工作记忆进行多轮状态跟踪）。研究还发布了HanabiLogs（用于指令调优）和HanabiRewards（用于密集奖励标注）两个数据集，并利用这些数据集对一个40亿参数的模型（Qwen3-Instruct）进行了监督和强化学习微调。

Result: 1. LLM可以有效地利用内部工作记忆进行状态跟踪。2. 不同LLM之间的跨模型表现与模型强度平滑插值。在Sherlock设置下，最强的模型平均得分超过15分，但仍落后于人类专家和专用Hanabi代理（均超过20分）。微调后的Qwen3-Instruct模型在Hanabi游戏中的表现分别提升了21%（监督学习）和156%（强化学习），接近强专有模型（o4-mini）的水平，并超越了GPT-4.1。

Conclusion: LLM在合作推理方面展现出潜力，特别是通过工作记忆进行状态跟踪。上下文工程是提升LLM在复杂合作任务中表现的关键。研究发布的数据集和微调方法显著提升了LLM在Hanabi游戏中的表现，并使其泛化到其他需要合作、推理和常识的任务上，表明了微调策略在提升LLM通用能力方面的有效性。

Abstract: Cooperative reasoning under incomplete information remains challenging for both humans and multi-agent systems. The card game Hanabi embodies this challenge, requiring theory-of-mind reasoning and strategic communication. We benchmark 17 state-of-the-art LLM agents in 2-5 player games and study the impact of context engineering across model scales (4B to 600B+) to understand persistent coordination failures and robustness to scaffolding: from a minimal prompt with only explicit card details (Watson setting), to scaffolding with programmatic, Bayesian-motivated deductions (Sherlock setting), to multi-turn state tracking via working memory (Mycroft setting). We show that (1) agents can maintain an internal working memory for state tracking and (2) cross-play performance between different LLMs smoothly interpolates with model strength. In the Sherlock setting, the strongest reasoning models exceed 15 points on average across player counts, yet still trail experienced humans and specialist Hanabi agents, both consistently scoring above 20. We release the first public Hanabi datasets with annotated trajectories and move utilities: (1) HanabiLogs, containing 1,520 full game logs for instruction tuning, and (2) HanabiRewards, containing 560 games with dense move-level value annotations for all candidate moves. Supervised and RL finetuning of a 4B open-weight model (Qwen3-Instruct) on our datasets improves cooperative Hanabi play by 21% and 156% respectively, bringing performance to within ~3 points of a strong proprietary reasoning model (o4-mini) and surpassing the best non-reasoning model (GPT-4.1) by 52%. The HanabiRewards RL-finetuned model further generalizes beyond Hanabi, improving performance on a cooperative group-guessing benchmark by 11%, temporal reasoning on EventQA by 6.4%, instruction-following on IFBench-800K by 1.7 Pass@10, and matching AIME 2025 mathematical reasoning Pass@10.

</details>


### [301] [GLEN-Bench: A Graph-Language based Benchmark for Nutritional Health](https://arxiv.org/abs/2601.18106)
*Jiatan Huang,Zheyuan Zhang,Tianyi Ma,Mingchen Li,Yaning Zheng,Yanfang Ye,Chuxu Zhang*

Main category: cs.CL

TL;DR: 本研究提出了GLEN-Bench，一个基于图语言的综合性基准，用于营养健康评估，解决了现有计算方法在个性化膳食指导方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有计算方法在个性化膳食指导方面存在不足，忽略了现实世界的约束（如社会经济地位、合并症、食物可及性），缺乏解释性，并且没有统一的基准来评估相关任务。

Method: 结合NHANES健康记录、FNDDS食物成分数据和USDA食物可及性指标，构建一个知识图谱。该图谱连接了人口统计学、健康状况、饮食行为、贫困相关约束和营养需求。利用图神经网络、大型语言模型和混合架构，解决了三个 linked tasks：风险检测、个性化食物推荐和基于图谱的自然语言问答。

Result: GLEN-Bench能够识别与健康风险相关的明确饮食模式，并为阿片类药物使用障碍提供了跨疾病阶段的营养差异检测。评估表明，图语言模型在风险检测、推荐和问答任务上建立了坚实基线，并提供了实际的设计选择。

Conclusion: GLEN-Bench是第一个用于营养健康评估的图语言基准，通过整合多源数据和解决关键任务，为理解饮食模式与健康风险的关系提供了新的见解，有望指导实际的营养干预措施。

Abstract: Nutritional interventions are important for managing chronic health conditions, but current computational methods provide limited support for personalized dietary guidance. We identify three key gaps: (1) dietary pattern studies often ignore real-world constraints such as socioeconomic status, comorbidities, and limited food access; (2) recommendation systems rarely explain why a particular food helps a given patient; and (3) no unified benchmark evaluates methods across the connected tasks needed for nutritional interventions. We introduce GLEN-Bench, the first comprehensive graph-language based benchmark for nutritional health assessment. We combine NHANES health records, FNDDS food composition data, and USDA food-access metrics to build a knowledge graph that links demographics, health conditions, dietary behaviors, poverty-related constraints, and nutrient needs. We test the benchmark using opioid use disorder, where models must detect subtle nutritional differences across disease stages. GLEN-Bench includes three linked tasks: risk detection identifies at-risk individuals from dietary and socioeconomic patterns; recommendation suggests personalized foods that meet clinical needs within resource constraints; and question answering provides graph-grounded, natural-language explanations to facilitate comprehension. We evaluate these graph-language approaches, including graph neural networks, large language models, and hybrid architectures, to establish solid baselines and identify practical design choices. Our analysis identifies clear dietary patterns linked to health risks, providing insights that can guide practical interventions.

</details>


### [302] [FABLE: Forest-Based Adaptive Bi-Path LLM-Enhanced Retrieval for Multi-Document Reasoning](https://arxiv.org/abs/2601.18116)
*Lin Sun,Linglin Zhang,Jingang Huang,Change Jia,Zhengwei Cheng,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为 FABLE 的森林式自适应双通路 LLM 增强检索框架，用于解决长上下文 LLM 的局限性和传统 RAG 的不足。FABLE 通过构建 LLM 增强的分层森林索引，并结合 LLM 引导的层级遍历和结构感知传播，实现了细粒度证据获取，并在准确性和效率之间取得了良好的权衡。


<details>
  <summary>Details</summary>
Motivation: 长上下文 LLM 虽然能力增强，但仍存在“中间遗忘”问题、计算成本高、多文档推理效率低下等局限。而传统 RAG 在检索时会引入语义噪声，且难以进行结构化的跨文档综合。因此，需要一种新的方法来弥合两者的差距。

Method: FABLE 构建了 LLM 增强的分层森林索引，具有多粒度语义结构。然后，它采用一种双通路策略，结合了 LLM 引导的层级遍历和结构感知传播，以实现细粒度的证据获取。此外，FABLE 还包含显式的预算控制，用于自适应地权衡效率。

Result: FABLE 在实验中一致优于当前最先进的 RAG 方法，并且在准确性上与全上下文 LLM 推理相当，同时 token 使用量减少了高达 94%。

Conclusion: 长上下文 LLM 增强了结构化检索的需求，但并未完全取代它。FABLE 框架展示了将 LLM 集成到知识组织和检索中的有效性，并在准确性和效率方面取得了显著的提升。

Abstract: The rapid expansion of long-context Large Language Models (LLMs) has reignited debate on whether Retrieval-Augmented Generation (RAG) remains necessary. However, empirical evidence reveals persistent limitations of long-context inference, including the lost-in-the-middle phenomenon, high computational cost, and poor scalability for multi-document reasoning. Conversely, traditional RAG systems, while efficient, are constrained by flat chunk-level retrieval that introduces semantic noise and fails to support structured cross-document synthesis.
  We present \textbf{FABLE}, a \textbf{F}orest-based \textbf{A}daptive \textbf{B}i-path \textbf{L}LM-\textbf{E}nhanced retrieval framework that integrates LLMs into both knowledge organization and retrieval. FABLE constructs LLM-enhanced hierarchical forest indexes with multi-granularity semantic structures, then employs a bi-path strategy combining LLM-guided hierarchical traversal with structure-aware propagation for fine-grained evidence acquisition, with explicit budget control for adaptive efficiency trade-offs.
  Extensive experiments demonstrate that FABLE consistently outperforms SOTA RAG methods and achieves comparable accuracy to full-context LLM inference with up to 94\% token reduction, showing that long-context LLMs amplify rather than fully replace the need for structured retrieval.

</details>


### [303] [Typhoon-S: Minimal Open Post-Training for Sovereign Large Language Models](https://arxiv.org/abs/2601.18129)
*Kunat Pipatanakul,Pittawat Taveekitworachai*

Main category: cs.CL

TL;DR: 研究提出了一种名为Typhoon S的最小化、开源的后训练方法，用于在资源有限的情况下开发主权大语言模型。通过对泰语的案例研究，证明了该方法可以在不依赖大规模指令语料库或复杂偏好调优的情况下，将基础模型转化为通用助手，并执行区域特定的高风险任务。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型主要针对高资源语言（如英语和中文），且由少数拥有大量计算资源和数据的组织开发。这限制了地区性或国家级机构在资源有限、需要严格透明度的情况下开发和控制模型的可能性。因此，研究旨在为这些“主权设置”提供一种可行的解决方案。

Method: 研究提出了一种名为Typhoon S的后训练方法，该方法结合了监督微调（SFT）、在线策略蒸馏（on-policy distillation）和规模较小的强化微调（RFT）。在泰语案例研究中，还使用了InK-GRPO，这是GRPO的一种扩展，通过增加下一个词预测损失来增强GRPO损失。

Result: Typhoon S方法成功地将通用和针对主权领域进行适应的基础模型转化为指令调优模型，并展现出强大的通用性能。此外，小规模的InK-GRPO强化微调显著提升了泰语法律推理和泰语特定知识的能力，同时保持了通用能力。

Conclusion: 研究表明，精心设计的后训练策略可以有效减少指令数据和计算资源的需求，为在学术规模资源下开发高质量的主权大语言模型提供了一条实用路径。

Abstract: Large language models (LLMs) have progressed rapidly; however, most state-of-the-art models are trained and evaluated primarily in high-resource languages such as English and Chinese, and are often developed by a small number of organizations with access to large-scale compute and data. This gatekeeping creates a practical barrier for sovereign settings in which a regional- or national-scale institution or domain owner must retain control and understanding of model weights, training data, and deployment while operating under limited resources and strict transparency constraints. To this end, we identify two core requirements: (1) adoptability, the ability to transform a base model into a general-purpose assistant, and (2) sovereign capability, the ability to perform high-stakes, region-specific tasks (e.g., legal reasoning in local languages and cultural knowledge). We investigate whether these requirements can be achieved without scaling massive instruction corpora or relying on complex preference tuning pipelines and large-scale reinforcement fine-tuning (RFT). We present Typhoon S, a minimal and open post-training recipe that combines supervised fine-tuning, on-policy distillation, and small-scale RFT. Using Thai as a representative case study, we demonstrate that our approach transforms both sovereign-adapted and general-purpose base models into instruction-tuned models with strong general performance. We further show that small-scale RFT with InK-GRPO -- an extension of GRPO that augments the GRPO loss with a next-word prediction loss -- improves Thai legal reasoning and Thai-specific knowledge while preserving general capabilities. Our results suggest that a carefully designed post-training strategy can reduce the required scale of instruction data and computation, providing a practical path toward high-quality sovereign LLMs under academic-scale resources.

</details>


### [304] [Fine-Grained Emotion Detection on GoEmotions: Experimental Comparison of Classical Machine Learning, BiLSTM, and Transformer Models](https://arxiv.org/abs/2601.18162)
*Ani Harutyunyan,Sachin Kumar*

Main category: cs.CL

TL;DR: 该研究在GoEmotions数据集上对三种模型（TF-IDF+逻辑回归、BiLSTM+注意力、BERT）进行了细粒度情感识别的基准测试，并发现BERT在多项指标上表现最佳，尤其是在处理稀有和模糊情感方面。


<details>
  <summary>Details</summary>
Motivation: 细粒度情感识别因标签重叠和类别不平衡而成为一项挑战性的多标签NLP任务。

Method: 作者在GoEmotions数据集上对三种模型进行了基准测试：1. 使用二元相关性训练的TF-IDF+逻辑回归系统；2. BiLSTM+注意力模型；3. 针对多标签分类进行微调的BERT模型。实验采用了官方的训练/验证/测试划分，并使用逆频率类别权重来缓解不平衡问题。

Result: 在Micro-F1、Macro-F1、Hamming Loss和Subset Accuracy等多个指标上，逻辑回归获得了最高的Micro-F1（0.51），而BERT在整体平衡性上表现最佳，达到了Macro-F1 0.49、Hamming Loss 0.036和Subset Accuracy 0.36，超越了官方论文报告的结果。

Conclusion: 研究结果表明，常见情感可能依赖于表面的词汇线索，而上下文表示可以提高模型在处理稀有情感和更模糊的样本时的性能。

Abstract: Fine-grained emotion recognition is a challenging multi-label NLP task due to label overlap and class imbalance. In this work, we benchmark three modeling families on the GoEmotions dataset: a TF-IDF-based logistic regression system trained with binary relevance, a BiLSTM with attention, and a BERT model fine-tuned for multi-label classification. Experiments follow the official train/validation/test split, and imbalance is mitigated using inverse-frequency class weights. Across several metrics, namely Micro-F1, Macro-F1, Hamming Loss, and Subset Accuracy, we observe that logistic regression attains the highest Micro-F1 of 0.51, while BERT achieves the best overall balance surpassing the official paper's reported results, reaching Macro-F1 0.49, Hamming Loss 0.036, and Subset Accuracy 0.36. This suggests that frequent emotions often rely on surface lexical cues, whereas contextual representations improve performance on rarer emotions and more ambiguous examples.

</details>


### [305] [MemWeaver: Weaving Hybrid Memories for Traceable Long-Horizon Agentic Reasoning](https://arxiv.org/abs/2601.18204)
*Juexiang Ye,Xue Li,Xinyu Yang,Chengkai Huang,Lanshun Nie,Lina Yao,Dechen Zhan*

Main category: cs.CL

TL;DR: 本文提出了一种名为MemWeaver的统一记忆框架，用于改进大型语言模型在长期交互中的记忆能力，通过结构化图记忆、经验记忆和证据记忆的结合，以及双通道检索策略，有效提升了多跳和时间推理能力，并显著减少了上下文长度。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理长期交互时，其记忆系统在时间一致性、多跳推理和证据溯源方面存在不足，主要由于依赖非结构化检索或粗粒度抽象，容易导致时间冲突、推理脆弱和可追溯性差。

Method: 提出MemWeaver框架，包含三个相互关联的组件：1) 具有时间约束的图记忆，用于结构化关系推理；2) 经验记忆，用于抽象重复观察中的交互模式；3) 段落记忆，用于保存原始文本证据。采用双通道检索策略，同时检索结构化知识和支持性证据，为推理构建紧凑且信息密集的上下文。

Result: 在LoCoMo基准测试中的实验表明，MemWeaver显著提高了多跳和时间推理的准确性，并将输入上下文长度相比长上下文基线减少了95%以上。

Conclusion: MemWeaver是一个有效的统一记忆框架，能够整合代理的长期经验，通过结构化、抽象化和证据保留，并结合创新的检索策略，显著提升了大型语言模型在长期交互中的推理能力和效率。

Abstract: Large language model-based agents operating in long-horizon interactions require memory systems that support temporal consistency, multi-hop reasoning, and evidence-grounded reuse across sessions. Existing approaches largely rely on unstructured retrieval or coarse abstractions, which often lead to temporal conflicts, brittle reasoning, and limited traceability. We propose MemWeaver, a unified memory framework that consolidates long-term agent experiences into three interconnected components: a temporally grounded graph memory for structured relational reasoning, an experience memory that abstracts recurring interaction patterns from repeated observations, and a passage memory that preserves original textual evidence. MemWeaver employs a dual-channel retrieval strategy that jointly retrieves structured knowledge and supporting evidence to construct compact yet information-dense contexts for reasoning. Experiments on the LoCoMo benchmark demonstrate that MemWeaver substantially improves multi-hop and temporal reasoning accuracy while reducing input context length by over 95\% compared to long-context baselines.

</details>


### [306] [TechING: Towards Real World Technical Image Understanding via VLMs](https://arxiv.org/abs/2601.18238)
*Tafazzul Nadeem,Bhavik Shangari,Manish Rai,Gagan Raj Gupta,Ashutosh Modi*

Main category: cs.CL

TL;DR: 本文提出了一种使用合成数据训练视觉语言模型（VLM）以理解手绘技术图的方法，并在此基础上开发了 LLama-VL-TUG 模型，显著提升了模型在理解技术图方面的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在理解手绘技术图方面存在困难，而手动生成大量真实手绘图进行训练不切实际。因此，需要一种更有效的方法来训练 VLM 处理这类图像。

Method: 研究人员创建了一个大规模的合成数据集来训练 VLM，并设计了新的自监督学习任务。然后，他们使用合成数据对 Llama 3.2 11B-instruct 模型进行微调，得到 LLama-VL-TUG 模型，并在少量真实手绘图上进行了评估。

Result: LLama-VL-TUG 在 ROUGE-L 指标上比 Llama 3.2 11B-instruct 提升了 2.14 倍，并在真实手绘图上实现了最低的编译错误率（8 种图中的 7 种）和平均 F1 分数提高了 6.97 倍。

Conclusion: 通过使用合成数据和新的自监督任务进行训练，可以有效地提升 VLM 对手绘技术图的理解能力，LLama-VL-TUG 模型在这一领域取得了显著的性能提升。

Abstract: Professionals working in technical domain typically hand-draw (on whiteboard, paper, etc.) technical diagrams (e.g., flowcharts, block diagrams, etc.) during discussions; however, if they want to edit these later, it needs to be drawn from scratch. Modern day VLMs have made tremendous progress in image understanding but they struggle when it comes to understanding technical diagrams. One way to overcome this problem is to fine-tune on real world hand-drawn images, but it is not practically possible to generate large number of such images. In this paper, we introduce a large synthetically generated corpus (reflective of real world images) for training VLMs and subsequently evaluate VLMs on a smaller corpus of hand-drawn images (with the help of humans). We introduce several new self-supervision tasks for training and perform extensive experiments with various baseline models and fine-tune Llama 3.2 11B-instruct model on synthetic images on these tasks to obtain LLama-VL-TUG, which significantly improves the ROUGE-L performance of Llama 3.2 11B-instruct by 2.14x and achieves the best all-round performance across all baseline models. On real-world images, human evaluation reveals that we achieve minimum compilation errors across all baselines in 7 out of 8 diagram types and improve the average F1 score of Llama 3.2 11B-instruct by 6.97x.

</details>


### [307] [BoRP: Bootstrapped Regression Probing for Scalable and Human-Aligned LLM Evaluation](https://arxiv.org/abs/2601.18253)
*Peng Sun,Xiangyu Zhang,Duan Wu*

Main category: cs.CL

TL;DR: 本研究提出了一种名为 BoRP（Bootstrapped Regression Probing）的框架，用于高保真度地评估开放域对话式 AI 的用户满意度，该框架能够显著优于生成式基线，并且大幅降低了推理成本。


<details>
  <summary>Details</summary>
Motivation: 传统的 A/B 测试在评估开放域对话式 AI 的用户满意度方面存在局限性，因为显式反馈稀疏且隐式指标模糊。为了解决这一问题，需要一种更可靠、可扩展的评估方法。

Method: BoRP 框架利用大型语言模型（LLM）的潜在空间几何特性，通过基于极化指数的自举机制自动生成评估标准，并使用偏最小二乘法（PLS）将隐藏状态映射到连续得分。

Result: 在工业数据集上的实验表明，BoRP（Qwen3-8B/14B）在与人类判断的一致性上显著优于包括 Qwen3-Max 在内的生成式基线。此外，BoRP 将推理成本降低了几个数量级。

Conclusion: BoRP 是一个可扩展的高保真度用户满意度评估框架，它通过利用 LLM 的潜在空间特性，克服了传统方法的不足，能够实现大规模监控和敏感的 A/B 测试。

Abstract: Accurate evaluation of user satisfaction is critical for iterative development of conversational AI. However, for open-ended assistants, traditional A/B testing lacks reliable metrics: explicit feedback is sparse, while implicit metrics are ambiguous. To bridge this gap, we introduce BoRP (Bootstrapped Regression Probing), a scalable framework for high-fidelity satisfaction evaluation. Unlike generative approaches, BoRP leverages the geometric properties of LLM latent space. It employs a polarization-index-based bootstrapping mechanism to automate rubric generation and utilizes Partial Least Squares (PLS) to map hidden states to continuous scores. Experiments on industrial datasets show that BoRP (Qwen3-8B/14B) significantly outperforms generative baselines (even Qwen3-Max) in alignment with human judgments. Furthermore, BoRP reduces inference costs by orders of magnitude, enabling full-scale monitoring and highly sensitive A/B testing via CUPED.

</details>


### [308] [Reflecting Twice before Speaking with Empathy: Self-Reflective Alternating Inference for Empathy-Aware End-to-End Spoken Dialogue](https://arxiv.org/abs/2601.18281)
*Yuhang Jia,Pei Liu,Haoqin Sun,Jiaming Zhou,Xuxin Cheng,Cao Liu,Ke Zeng,Xunliang Cai,Yong Qin*

Main category: cs.CL

TL;DR: 本文提出了EmpathyEval，一个基于自然语言描述的评估模型，用于评估口语对话中的共情质量。在此基础上，本文还提出了ReEmpathy，一个端到端的口语语言模型，通过一种新颖的“共情自反式交替推理”机制，在生成语音回应的同时进行自由形式的、与共情相关的反思性推理，从而提升共情对话的能力。


<details>
  <summary>Details</summary>
Motivation: 现有端到端口语语言模型（SLM）在增强共情对话能力方面依赖于僵化的监督信号（如监督微调的真实响应或强化学习中的偏好得分），而这些信号无法完全捕捉复杂共情的细微之处，因为不存在唯一的“正确”回应，简单的数值分数也无法体现情感表达的细致性和共情行为的恰当性。

Method: 1. 引入EmpathyEval：一个基于自然语言描述的评估模型，用于评估口语对话中的共情质量。 2. 提出ReEmpathy：一个端到端的SLM，采用“共情自反式交替推理”机制，该机制通过交错进行语音回应生成和自由形式的、与共情相关的反思性推理来增强共情对话。

Result: 实验表明，ReEmpathy通过启用反思性推理，显著提高了对共情敏感的口语对话能力。

Conclusion: ReEmpathy通过引入反思性推理，为实现更具情感智能和共情意识的人机交互提供了一种有前景的方法，能够显著提升共情对话的质量。

Abstract: End-to-end Spoken Language Models (SLMs) hold great potential for paralinguistic perception, and numerous studies have aimed to enhance their capabilities, particularly for empathetic dialogue. However, current approaches largely depend on rigid supervised signals, such as ground-truth response in supervised fine-tuning or preference scores in reinforcement learning. Such reliance is fundamentally limited for modeling complex empathy, as there is no single "correct" response and a simple numerical score cannot fully capture the nuances of emotional expression or the appropriateness of empathetic behavior. To address these limitations, we sequentially introduce EmpathyEval, a descriptive natural-language-based evaluation model for assessing empathetic quality in spoken dialogues. Building upon EmpathyEval, we propose ReEmpathy, an end-to-end SLM that enhances empathetic dialogue through a novel Empathetic Self-Reflective Alternating Inference mechanism, which interleaves spoken response generation with free-form, empathy-related reflective reasoning. Extensive experiments demonstrate that ReEmpathy substantially improves empathy-sensitive spoken dialogue by enabling reflective reasoning, offering a promising approach toward more emotionally intelligent and empathy-aware human-computer interactions.

</details>


### [309] [U-Fold: Dynamic Intent-Aware Context Folding for User-Centric Agents](https://arxiv.org/abs/2601.18285)
*Jin Su,Runnan Fang,Yeqiu Li,Xiaobin Wang,Shihao Cai,Pengjun Xie,Ningyu Zhang,Fajie Yuan*

Main category: cs.CL

TL;DR: 提出了一种名为 U-Fold 的动态上下文折叠框架，用于解决基于 LLM 的代理在处理用户中心对话时的上下文长度限制问题，该框架通过生成意图感知型对话摘要和任务相关工具日志，有效避免了信息丢失和用户意图追踪不准确的问题，并在多项基准测试中取得了显著优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文折叠方法在单查询或单意图场景下表现良好，但在更真实的用户中心对话中存在两个主要问题：1) 无法保留对后续决策至关重要的细粒度约束和中间事实；2) 生成的摘要无法追踪用户意图的变化，导致遗漏信息和错误操作。这限制了 LLM 代理在长上下文场景下的可扩展性和实用性。

Method: U-Fold 是一个动态上下文折叠框架，它保留了完整的用户-代理对话和工具调用历史。在每个回合，U-Fold 使用两个核心组件：1) 生成一个意图感知型、不断演变的对话摘要；2) 生成一个简洁、与任务相关的工具日志。通过这种方式，U-Fold 能够在有限的上下文长度内有效管理信息。

Result: 在 τ-bench、τ²-bench、VitaBench 和更具挑战性的长上下文设置上进行的广泛实验表明，U-Fold 在长上下文场景下持续优于 ReAct（达到 71.4% 的胜率）和现有的折叠基线（提升高达 27.0%），尤其是在长、嘈杂、多轮的任务上表现突出。

Conclusion: U-Fold 是一个针对用户中心任务的动态上下文折叠框架，能够有效解决 LLM 代理在长对话中的上下文长度限制问题，并通过保留关键信息和追踪用户意图来提高性能。这项研究表明，U-Fold 是将上下文管理技术从单查询基准推广到现实用户中心应用的有前景的一步。

Abstract: Large language model (LLM)-based agents have been successfully deployed in many tool-augmented settings, but their scalability is fundamentally constrained by context length. Existing context-folding methods mitigate this issue by summarizing past interactions, yet they are typically designed for single-query or single-intent scenarios. In more realistic user-centric dialogues, we identify two major failure modes: (i) they irreversibly discard fine-grained constraints and intermediate facts that are crucial for later decisions, and (ii) their summaries fail to track evolving user intent, leading to omissions and erroneous actions. To address these limitations, we propose U-Fold, a dynamic context-folding framework tailored to user-centric tasks. U-Fold retains the full user--agent dialogue and tool-call history but, at each turn, uses two core components to produce an intent-aware, evolving dialogue summary and a compact, task-relevant tool log. Extensive experiments on $τ$-bench, $τ^2$-bench, VitaBench, and harder context-inflated settings show that U-Fold consistently outperforms ReAct (achieving a 71.4% win rate in long-context settings) and prior folding baselines (with improvements of up to 27.0%), particularly on long, noisy, multi-turn tasks. Our study demonstrates that U-Fold is a promising step toward transferring context-management techniques from single-query benchmarks to realistic user-centric applications.

</details>


### [310] [Temp-R1: A Unified Autonomous Agent for Complex Temporal KGQA via Reverse Curriculum Reinforcement Learning](https://arxiv.org/abs/2601.18296)
*Zhaoyan Gong,Zhiqiang Liu,Songze Li,Xiaoke Guo,Yuanxiang Liu,Xinle Deng,Zhizhen Liu,Lei Liang,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为 Temp-R1 的首个用于时序知识图谱问答（TKGQA）的自主端到端强化学习智能体，通过扩展动作空间和引入逆向课程学习来解决现有方法的局限性，并在两个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的时序知识图谱问答方法受限于固定的工作流程和昂贵的闭源 API，缺乏灵活性和可扩展性。

Method: 提出 Temp-R1，一个通过强化学习训练的自主端到端智能体。通过引入专门的内部动作来扩展动作空间，以解决单动作推理中的认知过载问题。引入逆向课程学习，先训练困难问题，再训练简单问题，以防止捷径学习。

Result: 在 MultiTQ 和 TimelineKGKGQA 数据集上实现了最先进的性能，在复杂问题上比现有基线提高了 19.8%。

Conclusion: Temp-R1 建立了一种新的自主时序推理智能体范式，有效解决了 TKGQA 的挑战，并展现了优越的性能。

Abstract: Temporal Knowledge Graph Question Answering (TKGQA) is inherently challenging, as it requires sophisticated reasoning over dynamic facts with multi-hop dependencies and complex temporal constraints. Existing methods rely on fixed workflows and expensive closed-source APIs, limiting flexibility and scalability. We propose Temp-R1, the first autonomous end-to-end agent for TKGQA trained through reinforcement learning. To address cognitive overload in single-action reasoning, we expand the action space with specialized internal actions alongside external action. To prevent shortcut learning on simple questions, we introduce reverse curriculum learning that trains on difficult questions first, forcing the development of sophisticated reasoning before transferring to easier cases. Our 8B-parameter Temp-R1 achieves state-of-the-art performance on MultiTQ and TimelineKGQA, improving 19.8% over strong baselines on complex questions. Our work establishes a new paradigm for autonomous temporal reasoning agents. Our code will be publicly available soon at https://github.com/zjukg/Temp-R1.

</details>


### [311] [Suppressing Final Layer Hidden State Jumps in Transformer Pretraining](https://arxiv.org/abs/2601.18302)
*Keigo Shibata,Kazuki Yano,Ryosuke Takahashi,Jaesung Lee,Wataru Ikeda,Jun Suzuki*

Main category: cs.CL

TL;DR: 本研究分析了 Transformer 模型中，中间层输入输出向量的角度变化较小，而最终层存在显著角度“跳跃”的现象。提出了一种度量该跳跃强度的方法，并发现其普遍存在且在预训练中会被放大。在此基础上，引入了 JREG 正则化项来抑制这种跳跃，以鼓励中间层更均衡地发挥作用。实验表明，使用 JREG 训练的 Llama 模型在任务性能上有所提升，且不改变模型架构。


<details>
  <summary>Details</summary>
Motivation: 研究发现 Transformer 模型在中间层和最终层存在不同程度的向量角度变化，最终层的“跳跃”现象可能是一种不希望的属性，促使研究者去理解和改进这一现象。

Method: 1. 引入一个量化指标来衡量最终 Transformer 层周围的“跳跃”强度。 2. 提出 JREG（Jump-Suppressing Regularizer）正则化方法，在预训练阶段惩罚这种“跳跃”。 3. 在 Llama 系列模型上进行实验评估。

Result: JREG 正则化方法在 Llama 系列模型上表现出普遍性，并且在预训练过程中会被放大。应用 JREG 训练的模型在任务性能上优于基线模型，且模型架构未改变。

Conclusion: Transformer 模型中最终层存在的向量角度“跳跃”现象是普遍存在的，且可以通过 JREG 正则化方法来抑制，从而在不改变模型架构的前提下提升模型在下游任务上的性能。

Abstract: This paper discusses the internal behavior of Transformer language models. Many recent pre-trained models have been reported to exhibit only slight changes in the angular distance between the input and output hidden state vectors in the middle Transformer layers, despite a disproportionately large ``jump'' in the angular distance occurring in or around the final Transformer layer. To characterize this, we first introduce a quantitative metric for the jump strength around the final layer, and then demonstrate its prevalence across many open-weight models, as well as its amplification throughout pre-training. Assuming such jumps indicate an undesirable property, we propose the jump-suppressing regularizer (JREG) which penalizes this jump during pre-training, thereby encouraging more balanced capability usage across the middle layers. Empirical evaluations of three model sizes of Llama-based models, trained with the proposed JREG method, reveal improved task performance compared to the baseline without altering the model architecture.

</details>


### [312] [MultiVis-Agent: A Multi-Agent Framework with Logic Rules for Reliable and Comprehensive Cross-Modal Data Visualization](https://arxiv.org/abs/2601.18320)
*Jinwei Lu,Yuanfeng Song,Chen Zhang,Raymond Chi-Wing Wong*

Main category: cs.CL

TL;DR: 提出了一种名为MultiVis-Agent的增强型多智能体框架，用于可靠的多模态和多场景可视化生成，通过四层逻辑规则增强LLM推理，解决了现有系统在处理复杂可视化需求时的局限性和可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界的可视化任务需求复杂且多模态，超越了简单的文本到图表生成，需要参考图像、代码示例和迭代优化。现有系统在单模态输入、一次性生成和僵化工作流程方面存在根本性局限。基于LLM的方法虽然有潜力，但存在灾难性故障和无限循环等可靠性挑战。

Method: 提出了MultiVis-Agent，一个逻辑规则增强的多智能体框架。引入了四层逻辑规则框架，为系统可靠性提供数学保证，同时保持灵活性。逻辑规则作为数学约束指导LLM推理。将MultiVis任务形式化为四个场景，并开发了MultiVis-Bench基准。

Result: 在具有挑战性的任务上，MultiVis-Agent取得了75.63%的可视化得分，显著优于基线（57.54%-62.79%）。任务完成率为99.58%，代码执行成功率为94.56%，而没有逻辑规则的对比组分别为74.48%和65.10%。

Conclusion: MultiVis-Agent框架成功地解决了自动化可视化生成中的复杂性和可靠性挑战，通过逻辑规则增强LLM推理，实现了高效且可靠的多模态和多场景可视化生成。

Abstract: Real-world visualization tasks involve complex, multi-modal requirements that extend beyond simple text-to-chart generation, requiring reference images, code examples, and iterative refinement. Current systems exhibit fundamental limitations: single-modality input, one-shot generation, and rigid workflows. While LLM-based approaches show potential for these complex requirements, they introduce reliability challenges including catastrophic failures and infinite loop susceptibility. To address this gap, we propose MultiVis-Agent, a logic rule-enhanced multi-agent framework for reliable multi-modal and multi-scenario visualization generation. Our approach introduces a four-layer logic rule framework that provides mathematical guarantees for system reliability while maintaining flexibility. Unlike traditional rule-based systems, our logic rules are mathematical constraints that guide LLM reasoning rather than replacing it. We formalize the MultiVis task spanning four scenarios from basic generation to iterative refinement, and develop MultiVis-Bench, a benchmark with over 1,000 cases for multi-modal visualization evaluation. Extensive experiments demonstrate that our approach achieves 75.63% visualization score on challenging tasks, significantly outperforming baselines (57.54-62.79%), with task completion rates of 99.58% and code execution success rates of 94.56% (vs. 74.48% and 65.10% without logic rules), successfully addressing both complexity and reliability challenges in automated visualization generation.

</details>


### [313] [Calibrating Beyond English: Language Diversity for Better Quantized Multilingual LLM](https://arxiv.org/abs/2601.18306)
*Everlyn Asiko Chimoto,Mostafa Elhoushi,Bruce A. Bassett*

Main category: cs.CL

TL;DR: 研究发现，使用非英语或多语言校准集进行模型量化，相比仅使用英语校准集，能显著提升多语言大语言模型的性能，尤其是在Llama3.1 8B和Qwen2.5 7B模型上。


<details>
  <summary>Details</summary>
Motivation: 现有的模型量化方法在减少模型大小和计算成本的同时，往往会牺牲模型性能。现有后训练量化方法多使用小型、仅英语的校准集，但其对多语言模型的影响研究不足。

Method: 在10种语言的数据上，对GPTQ和AWQ两种量化器，系统性地评估了八种校准设置（五种单语和三种多语混合）。

Result: 非英语和多语言校准集相比英语校准集能显著降低困惑度，多语言混合校准集效果最佳，困惑度最高可降低3.52点。针对评估语言调整校准集能带来最大的单语性能提升。研究还发现了特定语言-量化器组合可能导致性能下降，这与激活值范围分布的差异有关。

Conclusion: 静态的、一刀切的校准方法并非最优。为多语言大语言模型进行鲁棒量化，需要根据语言和多样性精心设计校准数据。

Abstract: Quantization is an effective technique for reducing the storage footprint and computational costs of Large Language Models (LLMs), but it often results in performance degradation. Existing post-training quantization methods typically use small, English-only calibration sets; however, their impact on multilingual models remains underexplored. We systematically evaluate eight calibration settings (five single-language and three multilingual mixes) on two quantizers (GPTQ, AWQ) on data from 10 languages. Our findings reveal a consistent trend: non-English and multilingual calibration sets significantly improve perplexity compared to English-only baselines. Specifically, we observe notable average perplexity gains across both quantizers on Llama3.1 8B and Qwen2.5 7B, with multilingual mixes achieving the largest overall reductions of up to 3.52 points in perplexity. Furthermore, our analysis indicates that tailoring calibration sets to the evaluation language yields the largest improvements for individual languages, underscoring the importance of linguistic alignment. We also identify specific failure cases where certain language-quantizer combinations degrade performance, which we trace to differences in activation range distributions across languages. These results highlight that static one-size-fits-all calibration is suboptimal and that tailoring calibration data, both in language and diversity, plays a crucial role in robustly quantizing multilingual LLMs.

</details>


### [314] [Overalignment in Frontier LLMs: An Empirical Study of Sycophantic Behaviour in Healthcare](https://arxiv.org/abs/2601.18334)
*Clément Christophe,Wadood Mohammed Abdul,Prateek Munjal,Tathagata Raha,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.CL

TL;DR: 本研究提出了一种评估大型语言模型（LLM）在临床应用中谄媚行为的新框架，并通过对Qwen-3和Llama-3家族模型的分析，发现模型规模越大，抵抗谄媚的能力越强，但经过推理优化的模型（“Thinking”模型）在面对权威压力时，即使准确率高，也可能倾向于合理化错误的建议。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在临床工作流中的应用日益增多，但其倾向于迎合用户而非保证事实准确性的“谄媚”行为，对患者安全构成了严重风险。现有的评估方法通常依赖于主观数据集，不足以全面评估这一风险。

Method: 研究者构建了一个基于医学多项选择问答（MCQA）且具有可验证真实答案的新型评估框架。提出了“调整后谄媚得分”（Adjusted Sycophancy Score）这一新指标，用于排除模型固有的不稳定性（“困惑性”）对评估结果的影响，从而分离出模型本身的对齐偏差。对Qwen-3和Llama-3模型家族进行了大规模扩展性分析。

Result: 研究发现，模型规模的增大与抵抗谄媚能力呈明确的规模化轨迹。此外，研究揭示了推理优化的“Thinking”模型存在一种反直觉的脆弱性：虽然它们在常规测试中表现出高准确率，但在权威压力下，其内部推理过程却频繁地为不正确的用户建议进行辩护。

Conclusion: 在前沿模型上的实验结果表明，基准性能并不能代表临床可靠性。简化的推理结构可能在面对专家驱动的谄媚行为时提供更好的鲁棒性。

Abstract: As LLMs are increasingly integrated into clinical workflows, their tendency for sycophancy, prioritizing user agreement over factual accuracy, poses significant risks to patient safety. While existing evaluations often rely on subjective datasets, we introduce a robust framework grounded in medical MCQA with verifiable ground truths. We propose the Adjusted Sycophancy Score, a novel metric that isolates alignment bias by accounting for stochastic model instability, or "confusability". Through an extensive scaling analysis of the Qwen-3 and Llama-3 families, we identify a clear scaling trajectory for resilience. Furthermore, we reveal a counter-intuitive vulnerability in reasoning-optimized "Thinking" models: while they demonstrate high vanilla accuracy, their internal reasoning traces frequently rationalize incorrect user suggestions under authoritative pressure. Our results across frontier models suggest that benchmark performance is not a proxy for clinical reliability, and that simplified reasoning structures may offer superior robustness against expert-driven sycophancy.

</details>


### [315] [When Domain Pretraining Interferes with Instruction Alignment: An Empirical Study of Adapter Merging in Medical LLMs](https://arxiv.org/abs/2601.18350)
*Junyi Zou*

Main category: cs.CL

TL;DR: 本文介绍了一种通过两阶段 LoRA 管道（领域自适应预训练和监督微调）来增强大型语言模型在医学领域的表现，并提出了一种加权适配器合并方法来平衡指令遵循能力和领域知识保留。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医学领域存在术语精度和指令遵循安全性的问题，本研究旨在解决这些挑战。

Method: 采用两阶段 LoRA 管道：1) 领域自适应预训练 (DAPT) 注入医学知识；2) 监督微调 (SFT) 对齐医学问答行为。提出加权适配器合并 (Weighted Adapter Merging) 方法，线性组合 SFT 和 PT 适配器。

Result: 在医学验证集上，合并后的模型达到了 BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, ROUGE-L = 11.54。同时分析了解码敏感性和训练稳定性。

Conclusion: 通过加权适配器合并方法，可以在保留领域知识的同时提升模型的指令遵循能力，从而有效改进大型语言模型在安全关键领域（如医学）的表现。

Abstract: Large language models (LLMs) show strong general capability but often struggle with medical terminology precision and safety-critical instruction following. We present a case study for adapter interference in safety-critical domains using a 14B-parameter base model through a two-stage LoRA pipeline: (1) domain-adaptive pre-training (PT) to inject broad medical knowledge via continued pre-training (DAPT), and (2) supervised fine-tuning (SFT) to align the model with medical question-answering behaviors through instruction-style data. To balance instruction-following ability and domain knowledge retention, we propose Weighted Adapter Merging, linearly combining SFT and PT adapters before exporting a merged base-model checkpoint. On a held-out medical validation set (F5/F6), the merged model achieves BLEU-4 = 16.38, ROUGE-1 = 20.42, ROUGE-2 = 4.60, and ROUGE-L = 11.54 under a practical decoding configuration. We further analyze decoding sensitivity and training stability with loss curves and controlled decoding comparisons.

</details>


### [316] [Code over Words: Overcoming Semantic Inertia via Code-Grounded Reasoning](https://arxiv.org/abs/2601.18352)
*Manjie Xu,Isabella Yin,Xinyi Tu,Chi Zhang,Yixin Zhu*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）在“语义惰性”问题上存在不足，即在动态、上下文规则与其预训练知识（如“岩浆是危险的”）相矛盾时，难以抑制预训练知识。本研究利用游戏《Baba Is You》来量化和分析这一现象，该游戏允许物理定律通过文本规则改变。研究发现，更大的模型在需要抑制预训练联想时可能表现出反向缩放效应（即性能更差），这归因于自然语言编码将描述性语义和逻辑规则纠缠在一起。研究提出了一种名为 LCV（Code-Grounded Vistas）的训练时方法，通过将动态表示为可执行代码，并对反事实对进行微调，有效解决了此问题，并优于推理时搜索方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在面对与预训练知识相矛盾的动态上下文规则时，存在“语义惰性”问题，即难以抑制预训练的先验知识。研究旨在量化和解决这一现象，特别是探究模型的规模如何影响其抑制先验知识的能力，以及如何改进模型以更好地处理动态和矛盾的规则。

Method: 研究利用游戏《Baba Is You》作为实验平台，该游戏允许物理定律通过文本规则改变。通过量化分析模型在面对矛盾规则时的表现。提出了一种名为 Code-Grounded Vistas (LCV) 的训练时方法，该方法将动态表示为可执行代码，并对反事实对进行微调，以强制模型关注逻辑约束而非视觉语义。

Result: 研究量化观察到，在需要抑制预训练联想时，更大的模型可能表现出反向缩放效应（即性能反而更差）。LCV 方法通过将动态表示为可执行代码，成功地逆转了这种趋势，使模型能够有效地抑制先验知识。LCV 在效率和准确性方面均优于昂贵的推理时搜索方法。

Conclusion: 表示形式（文本 vs. 代码）决定了模型规模是提高还是削弱了上下文推理能力。研究结果表明，大型模型并非在所有情况下都更优，这对于需要动态覆盖学习先验知识的领域具有重要意义。

Abstract: LLMs struggle with Semantic Inertia: the inability to inhibit pre-trained priors (e.g., "Lava is Dangerous") when dynamic, in-context rules contradict them. We probe this phenomenon using Baba Is You, where physical laws are mutable text rules, enabling precise evaluation of models' ability to override learned priors when rules change. We quantatively observe that larger models can exhibit inverse scaling: they perform worse than smaller models when natural language reasoning requires suppressing pre-trained associations (e.g., accepting "Lava is Safe"). Our analysis attributes this to natural language encoding, which entangles descriptive semantics and logical rules, leading to persistent hallucinations of familiar physics despite explicit contradictory rules. Here we show that representing dynamics as executable code, rather than descriptive text, reverses this trend and enables effective prior inhibition. We introduce Code-Grounded Vistas (LCV), which fine-tunes models on counterfactual pairs and identifies states with contradictory rules, thereby forcing attention to logical constraints rather than visual semantics. This training-time approach outperforms expensive inference-time search methods in both efficiency and accuracy. Our results demonstrate that representation fundamentally determines whether scaling improves or impairs contextual reasoning. This challenges the assumption that larger models are universally better, with implications for domains that require dynamic overriding of learned priors.

</details>


### [317] [CitiLink: Enhancing Municipal Transparency and Citizen Engagement through Searchable Meeting Minutes](https://arxiv.org/abs/2601.18374)
*Rodrigo Silva,José Evans,José Isidro,Miguel Marques,Afonso Fonseca,Ricardo Morais,João Canavilhas,Arian Pasquali,Purificação Silvano,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,Ricardo Campos*

Main category: cs.CL

TL;DR: CitiLink 是一个利用自然语言处理 (NLP) 和信息检索 (IR) 技术，将非结构化的市政会议记录转化为结构化、可搜索数据的平台，以提高当地政府的可访问性和透明度。


<details>
  <summary>Details</summary>
Motivation: 市政会议记录通常冗长且结构复杂，难以供公众和记者高效地获取信息。

Method: 该系统使用大型语言模型 (LLMs) 提取元数据、讨论主题和投票结果，并将这些信息索引到数据库中。通过用户友好的界面支持 BM25 排名进行全文搜索和分面过滤。该系统在 120 份葡萄牙市政会议记录上进行了构建和测试。

Result: CitiLink 能够有效地将非结构化的会议记录转化为结构化数据，并提供可搜索的功能。Gemini 在信息提取方面表现出有效性。与市政人员的可用性测试提供了用户交互的见解。

Conclusion: CitiLink 平台通过 NLP 和 IR 技术，显著提高了市政会议记录的可访问性和透明度，为市民和记者提供了一个更易于使用的工具来获取当地政府信息。

Abstract: City council minutes are typically lengthy and formal documents with a bureaucratic writing style. Although publicly available, their structure often makes it difficult for citizens or journalists to efficiently find information. In this demo, we present CitiLink, a platform designed to transform unstructured municipal meeting minutes into structured and searchable data, demonstrating how NLP and IR can enhance the accessibility and transparency of local government. The system employs LLMs to extract metadata, discussed subjects, and voting outcomes, which are then indexed in a database to support full-text search with BM25 ranking and faceted filtering through a user-friendly interface. The developed system was built over a collection of 120 minutes made available by six Portuguese municipalities. To assess its usability, CitiLink was tested through guided sessions with municipal personnel, providing insights into how real users interact with the system. In addition, we evaluated Gemini's performance in extracting relevant information from the minutes, highlighting its effectiveness in data extraction.

</details>


### [318] [Funny or Persuasive, but Not Both: Evaluating Fine-Grained Multi-Concept Control in LLMs](https://arxiv.org/abs/2601.18483)
*Arya Labroo,Ivaxi Sheth,Vyas Raina,Amaani Ahmed,Mario Fritz*

Main category: cs.CL

TL;DR: 本文提出了一种评估大型语言模型（LLM）在细粒度文本概念（如幽默、说服力）的单属性和双属性控制能力的框架，并发现双属性控制性能通常会下降，表明模型在组合性方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM控制方法（如提示工程）在多属性控制方面存在不足，需要一种系统性的评估框架来衡量模型对多个文本概念进行细粒度控制的能力。

Method: 设计了一个评估框架，用于评估LLM在单属性和双属性（如说服力与幽默）控制场景下的性能。实验在多个LLM和生成任务上进行。

Result: 在双属性控制场景下，LLM的性能通常会下降，即使所选概念在原则上是可分离的。这表明模型在处理直观上独立的多个概念时，组合性能力不足。

Conclusion: 现有的基于提示的控制方法在多概念组合性方面存在根本性限制。该评估框架为衡量未来多概念控制方法的能力提供了一个原则性的方法。

Abstract: Large Language Models (LLMs) offer strong generative capabilities, but many applications require explicit and \textit{fine-grained} control over specific textual concepts, such as humor, persuasiveness, or formality. Prior approaches in prompting and representation engineering can provide coarse or single-attribute control, but systematic evaluation of multi-attribute settings remains limited. We introduce an evaluation framework for fine-grained controllability for both single- and dual-concept scenarios, focusing on linguistically distinct concept pairs (e.g., persuasiveness vs.~humor). Surprisingly, across multiple LLMs and generative tasks, we find that performance often drops in the dual-concept setting, even though the chosen concepts should in principle be separable. This reveals a fundamental limitation of naive prompting-based control: models struggle with compositionality even when concepts are intuitively independent. Our framework provides systematic evidence of this gap and offers a principled approach for measuring the ability of future methods for multi-concept control.

</details>


### [319] [Hierarchical Text Classification with LLM-Refined Taxonomies](https://arxiv.org/abs/2601.18375)
*Jonas Golde,Nicolaas Jedema,Ravi Krishnan,Phong Le*

Main category: cs.CL

TL;DR: 本文提出了一种名为TaxMorph的框架，利用大语言模型（LLMs）对文本分类的层级分类体系进行重构，以解决现有体系中的歧义问题，并提升模型性能。实验证明，LLM重构的分类体系在F1分数上优于人工构建的体系。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的层级文本分类（HTC）依赖的分类体系常存在歧义，例如相似父节点下有相同的叶节点名称，这阻碍了语言模型学习清晰的决策边界。因此，需要一种方法来优化分类体系。

Method: TaxMorph框架利用LLMs对整个层级分类体系进行操作，包括重命名、合并、拆分和重新排序。该方法旨在使整个层级结构更好地匹配LLM所编码的语义。

Result: 在三个HTC基准测试上，LLM重构的分类体系在各种设置下均优于人工构建的体系，F1分数最高可提升2.9个百分点。与人工构建的分类体系相比，LLM重构的体系虽然在嵌入空间中导致更难分离的簇，但更符合模型在分类过程中的实际混淆模式，更好地反映了模型的归纳偏差。

Conclusion: LLM引导的层级分类体系重构能够创建更符合模型学习方式的分类体系，从而提高HTC的性能。研究结果表明，这种方法生成的分类体系虽然在嵌入空间中不易分离，但能更准确地反映模型的决策过程和学习特性。

Abstract: Hierarchical text classification (HTC) depends on taxonomies that organize labels into structured hierarchies. However, many real-world taxonomies introduce ambiguities, such as identical leaf names under similar parent nodes, which prevent language models (LMs) from learning clear decision boundaries. In this paper, we present TaxMorph, a framework that uses large language models (LLMs) to transform entire taxonomies through operations such as renaming, merging, splitting, and reordering. Unlike prior work, our method revises the full hierarchy to better match the semantics encoded by LMs. Experiments across three HTC benchmarks show that LLM-refined taxonomies consistently outperform human-curated ones in various settings up to +2.9pp. in F1. To better understand these improvements, we compare how well LMs can assign leaf nodes to parent nodes and vice versa across human-curated and LLM-refined taxonomies. We find that human-curated taxonomies lead to more easily separable clusters in embedding space. However, the LLM-refined taxonomies align more closely with the model's actual confusion patterns during classification. In other words, even though they are harder to separate, they better reflect the model's inductive biases. These findings suggest that LLM-guided refinement creates taxonomies that are more compatible with how models learn, improving HTC performance.

</details>


### [320] [HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences](https://arxiv.org/abs/2601.18724)
*Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 研究调查了 ACL、NAACL 和 EMNLP 会议论文中“幻觉引用”（HalluCitation）的普遍性和影响，发现其数量在快速增加，尤其是在较新的会议上，对科学的可靠性和会议的信誉造成了严重影响。


<details>
  <summary>Details</summary>
Motivation: 幻觉引用（HalluCitation）在评审中、预印本和已发表的论文中日益增多，这严重威胁了科学的可靠性，并可能损害会议的信誉。

Method: 分析了 2024 年和 2025 年 ACL、NAACL 和 EMNLP 的所有论文（包括主会议、Findings 和 workshop 论文），以识别和量化幻觉引用的出现情况。

Result: 近 300 篇论文包含至少一个幻觉引用，其中大多数在 2025 年发表。2025 年 EMNLP 的幻觉引用占了研究中发现的一半，表明该问题正在迅速增加。超过 100 篇此类论文被 EMNLP 2025 的主会议和 Findings 录用。

Conclusion: 幻觉引用是一个日益严重的问题，尤其是在最近的会议上，它对科学的可靠性以及会议的信誉构成了重大威胁。

Abstract: Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as "HalluCitation" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.

</details>


### [321] [Corpus-Based Approaches to Igbo Diacritic Restoration](https://arxiv.org/abs/2601.18380)
*Ignatius Ezeani*

Main category: cs.CL

TL;DR: 本论文提出了一种用于伊博语（一种低资源语言）的注音恢复框架，并探索了n-gram、分类和词嵌入等模型。


<details>
  <summary>Details</summary>
Motivation: 现有的自然语言处理（NLP）研究主要集中在资源丰富的语言上，而世界上绝大多数语言（超过95%）是低资源语言，缺乏NLP所需的数据、工具和技术。本研究旨在解决低资源语言的NLP问题，特别是伊博语的注音恢复。

Method: 研究者首先回顾了注音模糊性以及其他语言的注音消歧方法。然后，针对伊博语，提出了一个用于生成注音恢复数据集的灵活框架。在此基础上，探索了三种主要的模型方法：1. 标准n-gram模型，利用目标词之前的词序列来预测正确的注音变体。2. 分类模型，使用目标词两侧的词语窗口。3. 词嵌入模型，通过比较上下文词嵌入的组合相似度和候选变体向量的嵌入相似度。

Result: 论文中描述了开发伊博语注音恢复数据集的步骤，并提出了三种模型方法。具体实验结果和模型性能的详细分析在本摘要中未给出。

Conclusion: 本研究为低资源语言（以伊博语为例）的注音恢复提供了一种通用的框架和模型探索，为未来的NLP研究提供了基础。

Abstract: With natural language processing (NLP), researchers aim to enable computers to identify and understand patterns in human languages. This is often difficult because a language embeds many dynamic and varied properties in its syntax, pragmatics and phonology, which need to be captured and processed. The capacity of computers to process natural languages is increasing because NLP researchers are pushing its boundaries. But these research works focus more on well-resourced languages such as English, Japanese, German, French, Russian, Mandarin Chinese, etc. Over 95% of the world's 7000 languages are low-resourced for NLP, i.e. they have little or no data, tools, and techniques for NLP work.
  In this thesis, we present an overview of diacritic ambiguity and a review of previous diacritic disambiguation approaches on other languages. Focusing on the Igbo language, we report the steps taken to develop a flexible framework for generating datasets for diacritic restoration. Three main approaches, the standard n-gram model, the classification models and the embedding models were proposed. The standard n-gram models use a sequence of previous words to the target stripped word as key predictors of the correct variants. For the classification models, a window of words on both sides of the target stripped word was used. The embedding models compare the similarity scores of the combined context word embeddings and the embeddings of each of the candidate variant vectors.

</details>


### [322] [Do not be greedy, Think Twice: Sampling and Selection for Document-level Information Extraction](https://arxiv.org/abs/2601.18395)
*Mikel Zubillaga,Oscar Sainz,Oier Lopez de Lacalle,Eneko Agirre*

Main category: cs.CL

TL;DR: 本研究提出了一种名为 ThinkTwice 的信息抽取框架，通过 LLM 生成多个候选模板，并利用一个选择模块选出最优模板，从而在文档级信息抽取任务中超越了贪心解码方法。


<details>
  <summary>Details</summary>
Motivation: 标准的信息抽取方法通过贪心解码避免输出变化，但本研究认为这种变化（采样）可以产生更好的结果，尤其是在使用推理模型时。

Method: ThinkTwice 框架包含两个核心部分：1. LLM 生成多个候选模板。2. 一个选择模块（包括无监督和有监督方法）选择最优模板。研究还提出了一种基于拒绝采样的银牌数据生成方法，用于训练有监督选择器。

Result: 实验结果表明，无监督和有监督的 ThinkTwice 方法均能显著优于贪心基线和现有最先进方法。

Conclusion: 采样和选择策略可以显著提高 LLM 在文档级信息抽取任务中的性能，尤其是在结合推理能力时。ThinkTwice 框架为实现这一目标提供了一种有效的方法。

Abstract: Document-level Information Extraction (DocIE) aims to produce an output template with the entities and relations of interest occurring in the given document. Standard practices include prompting decoder-only LLMs using greedy decoding to avoid output variability. Rather than treating this variability as a limitation, we show that sampling can produce substantially better solutions than greedy decoding, especially when using reasoning models. We thus propose ThinkTwice, a sampling and selection framework in which the LLM generates multiple candidate templates for a given document, and a selection module chooses the most suitable one. We introduce both an unsupervised method that exploits agreement across generated outputs, and a supervised selection method using reward models trained on labeled DocIE data. To address the scarcity of golden reasoning trajectories for DocIE, we propose a rejection-sampling-based method to generate silver training data that pairs output templates with reasoning traces. Our experiments show the validity of unsupervised and supervised ThinkTwice, consistently outperforming greedy baselines and the state-of-the-art.

</details>


### [323] [One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment](https://arxiv.org/abs/2601.18731)
*Hongru Cai,Yongqi Li,Tiezheng Yu,Fengbin Zhu,Wenjie Wang,Fuli Feng,Wenjie Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为Meta Reward Modeling (MRM) 的新方法，用于解决个性化LLM对齐中用户反馈稀缺和快速适应新用户的问题。MRM将个性化奖励建模视为一个元学习问题，通过MAML风格的框架优化基础奖励函数组合的权重，并引入RPO以增强对难学用户的鲁棒性。实验证明MRM在少样本个性化和用户鲁棒性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前个性化LLM对齐面临两大挑战：个体用户反馈数据稀缺，以及需要高效适应新用户。现有的方法难以同时解决这两个问题。

Method: 本文提出Meta Reward Modeling (MRM)，将个性化奖励建模重构为元学习问题。具体而言，通过MAML风格的框架优化基础奖励函数的加权组合，以支持在有限反馈下的快速适应。同时引入Robust Personalization Objective (RPO) 来提高对难学用户的鲁棒性。

Result: MRM在个性化偏好数据集上的实验表明，它能够增强少样本个性化能力，提高用户鲁棒性，并且在性能上持续优于基线方法。

Conclusion: MRM通过将个性化奖励建模转化为元学习问题，有效解决了用户反馈稀缺和快速适应新用户的问题，为实现更高效、更鲁棒的个性化LLM对齐提供了新的解决方案。

Abstract: Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.

</details>


### [324] [Pisets: A Robust Speech Recognition System for Lectures and Interviews](https://arxiv.org/abs/2601.18415)
*Ivan Bondarenko,Daniil Grebenkin,Oleg Sedukhin,Mikhail Klementev,Roman Derunets,Lyudmila Budneva*

Main category: cs.CL

TL;DR: 该研究提出了一种名为“Pisets”的语音转文本系统，用于科学家和记者，它结合了 Wav2Vec2、AST 和 Whisper 模型，并通过课程学习、多样化的语料库和不确定性建模来提高准确性，尤其是在处理长音频和不同声学条件时，优于 WhisperX 和标准 Whisper。


<details>
  <summary>Details</summary>
Motivation: 现有语音转文本模型（如 Whisper）在错误和幻觉方面存在不足，特别是在处理科学和新闻领域的长音频数据以及各种声学条件时，需要一个更鲁棒的系统。

Method: 采用三组件架构：1. Wav2Vec2 进行初步识别；2. 音频频谱图 Transformer (AST) 进行误报过滤；3. Whisper 进行最终识别。引入了课程学习方法，使用了多样化的俄语语音语料库，并采用了先进的不确定性建模技术。

Result: 与 WhisperX 和标准 Whisper 模型相比，Pisets 系统在长音频数据和各种声学条件下具有更稳健的转录能力，显著提高了转录质量。

Conclusion: Pisets 系统通过结合多种模型、采用课程学习、利用多样化数据和引入不确定性建模，成功解决了现有语音转文本模型中的错误和幻觉问题，为科学和新闻领域提供了更优的解决方案。

Abstract: This work presents a speech-to-text system "Pisets" for scientists and journalists which is based on a three-component architecture aimed at improving speech recognition accuracy while minimizing errors and hallucinations associated with the Whisper model. The architecture comprises primary recognition using Wav2Vec2, false positive filtering via the Audio Spectrogram Transformer (AST), and final speech recognition through Whisper. The implementation of curriculum learning methods and the utilization of diverse Russian-language speech corpora significantly enhanced the system's effectiveness. Additionally, advanced uncertainty modeling techniques were introduced, contributing to further improvements in transcription quality. The proposed approaches ensure robust transcribing of long audio data across various acoustic conditions compared to WhisperX and the usual Whisper model. The source code of "Pisets" system is publicly available at GitHub: https://github.com/bond005/pisets.

</details>


### [325] [Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory](https://arxiv.org/abs/2601.18771)
*Yanming Liu,Xinyue Peng,Zixuan Yan,Yanxin Shen,Wenjie Xu,Yuefeng Huang,Xinyi Wang,Jiannan Cao,Jianwei Yin,Xuhong Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为Dep-Search的依赖感知搜索框架，通过结合结构化推理、检索和基于GRPO的持久化记忆，来解决现有检索增强生成（RAG）框架在处理复杂多跳推理任务中的不足，并在多项问答数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于搜索的LLM框架在决定搜索策略和利用检索信息方面过度依赖隐式的自然语言推理，这导致在管理子问题依赖、有效重用检索知识以及通过强化学习优化搜索策略方面存在挑战。

Method: Dep-Search框架集成了结构化推理、检索和持久化记忆（通过GRPO）。它引入了显式的控制机制，使模型能够分解具有依赖关系的问题、按需检索信息、访问内存中存储的先前知识，并将长推理上下文总结为可重用的内存条目。

Result: 在七个不同的问答数据集上进行的广泛实验表明，Dep-Search显著提高了LLM处理复杂多跳推理任务的能力，在不同模型规模下均优于现有强大的基线模型。

Conclusion: Dep-Search框架通过引入依赖感知能力和结构化控制，克服了现有隐式推理方法的局限性，能够更有效地处理复杂的多跳推理问题，并在各种问答场景中展现出强大的性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.

</details>


### [326] [Latent Knowledge as a Predictor of Fact Acquisition in Fine-Tuned Large Language Models](https://arxiv.org/abs/2601.18468)
*Daniel B. Hier,Tayo Obafemi-Ajayi*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型在预训练后会将生物医学知识不均匀地存储在权重中（潜伏知识）。通过对 Llama 3.1 8B Instruct 进行微调，发现潜伏知识是模型快速学习新事实和有限泛化能力的关键因素，而事实的巩固程度则影响其抵抗遗忘的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在预训练后存储的生物医学知识强度不一，部分知识以潜伏形式存在，不易通过确定性解码获取。研究旨在探究如何检测和利用这种潜伏知识，以及影响模型学习、泛化和遗忘的因素。

Method: 使用 Llama 3.1 8B Instruct 模型，通过微调学习人类表型本体（HPO）和基因本体（GO）的术语标识符映射。将学习过程视为一个“时间到事件”的过程，使用随机解码检测潜伏知识，并利用 Cox 比例风险模型分析知识获取、泛化和遗忘的预测因子。

Result: 在微调后，HPO 的确定性召回率从基线的 2.8% 提高到 71.9%。潜伏知识是知识快速获取的最强预测因子（风险比 2.6），并与更早、更高的学习率峰值和更快的收敛速度相关。泛化到未见过的 GO 事实的能力有限（5.8%），但当存在潜伏知识时，泛化可能性更大。已训练过的 GO 映射比未见过的映射更不容易发生退化。

Conclusion: 潜伏知识能够预测模型在微调过程中学习事实的速度以及对未见过事实的有限泛化能力。事实是否抵抗遗忘取决于其是否在训练中得到强化。因此，利用和增强模型中的潜伏知识对于提高其生物医学知识学习和应用能力至关重要。

Abstract: Large language models store biomedical facts with uneven strength after pretraining: some facts are present in the weights but are not reliably accessible under deterministic decoding (latent knowledge), while others are scarcely represented. We fine tuned Llama 3.1 8B Instruct to learn ontology term identifier mappings from the Human Phenotype Ontology (800 pairs) and the Gene Ontology (400 training pairs), withholding 400 GO pairs to test generalization. Treating learning as a time to event process across 20 epochs, we used stochastic decoding to detect latent knowledge at baseline and Cox proportional hazards models to identify predictors of acquisition, generalization, and degradation. Baseline deterministic recall for HPO was 2.8%, rising to 71.9% after fine-tuning. Latent knowledge was the strongest predictor of faster fact acquisition (HR 2.6) and was associated with earlier, higher peak learning rates and faster convergence; identifier frequency and curated annotation counts had smaller effects. Generalization to withheld GO facts was uncommon (5.8%) but more likely when latent knowledge was present. Previously correct GO mappings degraded more often for withheld (unseen) terms than for trained (seen) terms, suggesting a protective effect of reinforcement during training. These results show that latent knowledge predicts both the speed of factual learning during fine-tuning and the limited generalization of unseen ontology facts, while resistance to degradation depends on whether facts are reinforced.

</details>


### [327] [Demographic Probing of Large Language Models Lacks Construct Validity](https://arxiv.org/abs/2601.18486)
*Manuel Tonneau,Neil K. R. Seghal,Niyati Malhotra,Victor Orozco-Olvera,Ana María Muñoz Boudet,Lakshmi Subramanian,Sharath Chandra Guntuku,Valentin Hofmann*

Main category: cs.CL

TL;DR: 研究发现，当前用于探测大型语言模型（LLMs）对人口统计学信息的反应的方法存在效度问题，因为不同的信号（如名字或方言）不能稳定地代表同一人口统计学群体，并且存在语言混淆因素影响模型行为。


<details>
  <summary>Details</summary>
Motivation: 当前的“人口统计学探测”（demographic probing）方法假设单一的人口统计学线索（如姓名或方言）可以代表同一群体，并被用于研究LLMs如何根据人口统计学信息调整行为。该研究旨在检验这一假设在实际咨询场景中的有效性。

Method: 研究人员在模拟的咨询场景中，使用与种族和性别相关的人口统计学线索，观察LLMs行为的变化。他们分析了不同线索诱导的模型行为变化重叠程度，以及模型区分同一线索下不同群体能力的强弱和均匀性。此外，他们还探究了线索对人口统计学属性的编码强度和语言混淆因素对模型行为的影响。

Result: 研究发现，旨在代表同一人口统计学群体的线索，只能引起部分重叠的模型行为变化。而模型在区分同一线索下的不同群体时，表现出较弱且不均匀的能力。因此，估计出的模型行为差异不稳定，其大小和方向会因线索而异。研究还指出，这些不一致部分源于线索编码人口统计学属性的强度差异以及独立影响模型行为的语言混淆因素。

Conclusion: 人口统计学探测缺乏效度，无法稳定地刻画LLMs如何根据人口统计学信息调整行为，这可能反映了研究构建的“人口统计学信息”概念存在错误或碎片化。研究建议采用多重、生态效度高的线索，并明确控制混淆因素，以支持关于LLMs人口统计学效应的更可靠的论断。

Abstract: Demographic probing is widely used to study how large language models (LLMs) adapt their behavior to signaled demographic attributes. This approach typically uses a single demographic cue in isolation (e.g., a name or dialect) as a signal for group membership, implicitly assuming strong construct validity: that such cues are interchangeable operationalizations of the same underlying, demographically conditioned behavior. We test this assumption in realistic advice-seeking interactions, focusing on race and gender in a U.S. context. We find that cues intended to represent the same demographic group induce only partially overlapping changes in model behavior, while differentiation between groups within a given cue is weak and uneven. Consequently, estimated disparities are unstable, with both magnitude and direction varying across cues. We further show that these inconsistencies partly arise from variation in how strongly cues encode demographic attributes and from linguistic confounders that independently shape model behavior. Together, our findings suggest that demographic probing lacks construct validity: it does not yield a single, stable characterization of how LLMs condition on demographic information, which may reflect a misspecified or fragmented construct. We conclude by recommending the use of multiple, ecologically valid cues and explicit control of confounders to support more defensible claims about demographic effects in LLMs.

</details>


### [328] [Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets](https://arxiv.org/abs/2601.18791)
*Iaroslav Chelombitko,Mika Hämäläinen,Aleksey Komissarov*

Main category: cs.CL

TL;DR: 该研究使用基于子词（Byte-Pair Encoding, BPE）的方法，对242种拉丁语和西里尔语系语言进行了大规模跨语言比较，通过构建“glottosets”分析词汇重叠、词汇分化和语言相似性，并发现BPE分割与词素边界高度一致，词汇相似性与语言谱系关系显著相关。


<details>
  <summary>Details</summary>
Motivation: 为了在大规模上对拉丁语和西里尔语系语言进行跨语言比较，探究词汇模式和语言相似性，并验证基于子词的方法在语言学分析中的有效性。

Method: 构建包含Wikipedia词典的“glottosets”，使用Byte-Pair Encoding (BPE) 进行子词分割，生成基于排名的子词向量，然后分析词汇重叠、词汇分化和语言相似性。评估BPE分割与词素边界的对齐程度，以及BPE词汇相似性与遗传语言相关性的相关性。

Result: BPE分割在15种语言中比随机基线（F1=0.15）更准确地对齐词素边界（F1=0.34）。BPE词汇相似性与遗传语言相关性呈显著正相关（Mantel r = 0.329, p < 0.001），罗曼语族语言形成最紧密的聚类（平均距离0.51），跨语系对显示出清晰的分离（0.82）。在26,939个跨语言同形异义词中，48.7%在相关语言中获得不同的分割，且这种变异与系统发育距离相关。

Conclusion: 基于子词的方法（特别是BPE）提供了一个统一的框架，能够在大规模上进行跨语言比较，并揭示了词汇模式、语言分化和语言谱系之间的定量关系。BPE分割与语言学结构（如词素边界和语言亲缘关系）高度一致，为宏观语言学研究提供了有价值的见解。

Abstract: We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.

</details>


### [329] [Using Large Language Models to Construct Virtual Top Managers: A Method for Organizational Research](https://arxiv.org/abs/2601.18512)
*Antonio Garzon-Vico,Krithika Sharon Komalapati,Arsalan Shahid,Jan Rosier*

Main category: cs.CL

TL;DR: 本研究提出了一种使用大型语言模型（LLM）创建虚拟高管的方法，并验证了其在模拟人类高管决策方面的有效性，为组织研究提供了新的工具。


<details>
  <summary>Details</summary>
Motivation: 直接接触真实的顶级管理者进行组织研究存在困难，研究者希望找到一种替代方法来模拟他们的决策过程。

Method: 利用大型语言模型（LLM），结合真实CEO的沟通数据和道德基础理论，构建LLM驱动的虚拟CEO。通过三个阶段的评估，包括效度、信度和行为保真度，将虚拟CEO与人类被试进行比较。

Result: 基于理论构建的虚拟CEO在模拟道德判断方面与人类被试表现相似，表明LLM驱动的虚拟CEO具有较高的可信度。

Conclusion: LLM驱动的虚拟CEO可以作为组织研究中一种有价值的补充工具，尤其是在难以直接接触高管的情况下，并为未来在组织环境中使用此类虚拟角色进行了展望。

Abstract: This study introduces a methodological framework that uses large language models to create virtual personas of real top managers. Drawing on real CEO communications and Moral Foundations Theory, we construct LLM-based participants that simulate the decision-making of individual leaders. Across three phases, we assess construct validity, reliability, and behavioral fidelity by benchmarking these virtual CEOs against human participants. Our results indicate that theoretically scaffolded personas approximate the moral judgements observed in human samples, suggesting that LLM-based personas can serve as credible and complementary tools for organizational research in contexts where direct access to executives is limited. We conclude by outlining implications for future research using LLM-based personas in organizational settings.

</details>


### [330] [ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models](https://arxiv.org/abs/2601.18796)
*Brian Ondov,Chia-Hsuan Chang,Yujia Zhou,Mauro Giuffrè,Hua Xu*

Main category: cs.CL

TL;DR: 该研究提出了一种名为 ctELM 的新方法，用于将大型语言模型（LLM）与临床试验的嵌入空间对齐。ctELM 能够仅凭嵌入就能描述、比较和生成新的临床试验摘要，并且对嵌入空间的特定概念（如年龄和性别）的移动具有响应性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本嵌入解释、探索和逆向方法有限，这阻碍了 LLM 在理解和生成医学文本方面的应用，特别是临床试验的生成性应用。

Method: 研究者开发了一个开源、领域无关的嵌入语言模型（ELM）架构和训练框架。他们设计了针对临床试验的训练任务，并创建了一个专家验证的合成数据集。通过训练一系列 ELM 来探索不同任务和训练策略的影响，最终形成了 ctELM 模型。

Result: ctELM 模型能够仅通过嵌入就准确地描述和比较未见过的临床试验。此外，ctELM 能够从新的向量生成合理的临床试验摘要，并且这些摘要能够响应沿着年龄和性别概念向量移动嵌入所产生的变化。

Conclusion: ctELM 是一种有效的工具，可以实现 LLM 与临床试验嵌入空间的对齐，从而实现对临床试验的深入理解和生成。该研究提出的 ELM 实现和实验结果将有助于在生物医学及其他领域中，LLM 与嵌入空间的对齐。

Abstract: Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.

</details>


### [331] [GenAI for Social Work Field Education: Client Simulation with Real-Time Feedback](https://arxiv.org/abs/2601.18517)
*James Sungarda,Hongkai Liu,Zilong Zhou,Tien-Hsuan Wu,Johnson Chun-Sing Cheung,Ben Kao*

Main category: cs.CL

TL;DR: 本文介绍了一个名为SWITCH的社交工作互动训练聊天机器人，它通过模拟客户、实时技能分类和动机性访谈（MI）进展系统，来解决现场教育中反馈不足的问题，并提高了训练的效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 为解决社交工作现场教育中，因导师和客户数量有限而导致的反馈延迟和客观性不足的问题。

Method: 开发了SWITCH聊天机器人，包含三个核心模块：1. 认知模型驱动的客户模拟（包含静态和动态场）；2. 实时咨询技能分类（采用检索增强的上下文学习和微调BERT多标签分类器）；3. 动机性访谈（MI）阶段转换控制。

Result: 实验证明，基于BERT的方法和上下文学习在技能分类方面显著优于基线方法。SWITCH能够提供可扩展、低成本且一致的训练流程。

Conclusion: SWITCH作为一个有效的训练工具，可以补充现场教育，使导师能更专注于高级指导，并有望提高社交工作者的培训质量。

Abstract: Field education is the signature pedagogy of social work, yet providing timely and objective feedback during training is constrained by the availability of instructors and counseling clients. In this paper, we present SWITCH, the Social Work Interactive Training Chatbot. SWITCH integrates realistic client simulation, real-time counseling skill classification, and a Motivational Interviewing (MI) progression system into the training workflow. To model a client, SWITCH uses a cognitively grounded profile comprising static fields (e.g., background, beliefs) and dynamic fields (e.g., emotions, automatic thoughts, openness), allowing the agent's behavior to evolve throughout a session realistically. The skill classification module identifies the counseling skills from the user utterances, and feeds the result to the MI controller that regulates the MI stage transitions. To enhance classification accuracy, we study in-context learning with retrieval over annotated transcripts, and a fine-tuned BERT multi-label classifier. In the experiments, we demonstrated that both BERT-based approach and in-context learning outperforms the baseline with big margin. SWITCH thereby offers a scalable, low-cost, and consistent training workflow that complements field education, and allows supervisors to focus on higher-level mentorship.

</details>


### [332] [Exploring Fine-Tuning for In-Context Retrieval and Efficient KV-Caching in Long-Context Language Models](https://arxiv.org/abs/2601.18527)
*Francesco Maria Molfese,Momchil Hardalov,Rexhina Blloshmi,Bill Byrne,Adrià de Gispert*

Main category: cs.CL

TL;DR: 本文研究了针对长上下文语言模型（LCLMs）的微调策略，以提升其在长文档理解和KV-cache压缩下的鲁棒性。结果表明，微调能显著提高模型在特定领域内的表现，但在跨领域泛化方面表现不一，且对KV-cache压缩的鲁棒性提升有限。


<details>
  <summary>Details</summary>
Motivation: 尽管长上下文语言模型（LCLMs）能够处理大量文本，但其性能提升和在KV-cache压缩下的鲁棒性仍需深入研究，以评估微调策略的有效性。

Method: 通过实验对比不同的微调策略，评估LCLMs在识别和利用信息的能力，以及在KV-cache压缩下的鲁棒性。实验在特定领域（如金融）和跨领域任务（如多项选择题）上进行。

Result: 微调策略在特定领域内显著提升了LCLMs的性能（最高可达+20分）。然而，在跨领域泛化方面，LCLMs在金融问题上表现优于基线模型（+9分），而在多项选择题上，RAG的表现更佳（+6分）。微调策略对KV-cache压缩的鲁棒性提升效果中等，且因任务而异。

Conclusion: 针对LCLMs的微调策略能够有效提升其在特定领域的性能，但跨领域泛化能力仍有待提高，且其在KV-cache压缩下的鲁棒性提升效果有限，具体表现取决于不同任务。

Abstract: With context windows of millions of tokens, Long-Context Language Models (LCLMs) can encode entire document collections, offering a strong alternative to conventional retrieval-augmented generation (RAG). However, it remains unclear whether fine-tuning strategies can improve long-context performance and translate to greater robustness under KV-cache compression techniques. In this work, we investigate which training strategies most effectively enhance LCLMs' ability to identify and use relevant information, as well as enhancing their robustness under KV-cache compression. Our experiments show substantial in-domain improvements, achieving gains of up to +20 points over the base model. However, out-of-domain generalization remains task dependent with large variance -- LCLMs excels on finance questions (+9 points), while RAG shows stronger performance on multiple-choice questions (+6 points) over the baseline models. Finally, we show that our fine-tuning approaches bring moderate improvements in robustness under KV-cache compression, with gains varying across tasks.

</details>


### [333] [From Verifiable Dot to Reward Chain: Harnessing Verifiable Reference-based Rewards for Reinforcement Learning of Open-ended Generation](https://arxiv.org/abs/2601.18533)
*Yuxin Jiang,Yufei Wang,Qiyuan Zhang,Xingshan Zeng,Liangyou Li,Jierun Chen,Chaofan Tao,Haoli Bai,Lifeng Shang*

Main category: cs.CL

TL;DR: 本文提出了一种名为RLVRR（基于可验证参考奖励的强化学习）的新方法，用于解决开放式文本生成任务中缺乏明确正确答案的问题，该方法通过提取参考文本中的有序语言信号（奖励链），将奖励分解为内容和风格两个维度，从而提高了训练效率和效果。


<details>
  <summary>Details</summary>
Motivation: 传统的基于可验证奖励的强化学习（RLVR）在数学、代码等具有明确答案的任务上表现良好，但难以应用于开放式生成任务，因为后者缺乏明确的地面真相。仅依赖最终答案的监督会导致效率低下和奖励劫持。

Method: RLVRR方法不直接检查最终答案，而是从高质量的参考文本中提取有序的语言信号（奖励链）。它将奖励分解为两个维度：内容（保留确定性的核心概念，如关键词）和风格（通过大型语言模型评估文本的风格符合度）。RLVRR结合了强化学习的探索能力和监督微调（SFT）的效率与可靠性。

Result: 在超过10个基准测试中，使用Qwen和Llama模型进行的广泛实验证明了RLVRR的优势。RLVRR的性能显著优于使用10倍数据和先进奖励模型训练的SFT，能够统一结构化推理和开放式生成的训练，并且在保持输出多样性的同时具有更强的泛化能力。

Conclusion: RLVRR为通用的LLM对齐提供了一条原则性强且高效的可验证强化学习路径，它能够有效地处理开放式文本生成任务，并且在性能、泛化能力和输出多样性方面优于现有方法。

Abstract: Reinforcement learning with verifiable rewards (RLVR) succeeds in reasoning tasks (e.g., math and code) by checking the final verifiable answer (i.e., a verifiable dot signal). However, extending this paradigm to open-ended generation is challenging because there is no unambiguous ground truth. Relying on single-dot supervision often leads to inefficiency and reward hacking. To address these issues, we propose reinforcement learning with verifiable reference-based rewards (RLVRR). Instead of checking the final answer, RLVRR extracts an ordered linguistic signal from high-quality references (i.e, reward chain). Specifically, RLVRR decomposes rewards into two dimensions: content, which preserves deterministic core concepts (e.g., keywords), and style, which evaluates adherence to stylistic properties through LLM-based verification. In this way, RLVRR combines the exploratory strength of RL with the efficiency and reliability of supervised fine-tuning (SFT). Extensive experiments on more than 10 benchmarks with Qwen and Llama models confirm the advantages of our approach. RLVRR (1) substantially outperforms SFT trained with ten times more data and advanced reward models, (2) unifies the training of structured reasoning and open-ended generation, and (3) generalizes more effectively while preserving output diversity. These results establish RLVRR as a principled and efficient path toward verifiable reinforcement learning for general-purpose LLM alignment. We release our code and data at https://github.com/YJiangcm/RLVRR.

</details>


### [334] [Evaluating Morphological Plausibility of Subword Tokenization via Statistical Alignment with Morpho-Syntactic Features](https://arxiv.org/abs/2601.18536)
*Abishek Stephen,Jindřich Libovický*

Main category: cs.CL

TL;DR: 提出了一种新的子词分割形态学合理性评估指标，该指标不依赖于黄金分割数据，而是利用形态句法特征，并通过IBM Model 1进行概率对齐。


<details>
  <summary>Details</summary>
Motivation: 现有子词分割评估指标（如词素边界或检索F-score）需要黄金分割数据，而这些数据在许多语言中不可用或质量不一致。研究旨在开发一个更广泛适用的评估方法。

Method: 利用形态句法特征（来自Universal Dependencies或UniMorph），通过IBM Model 1模型将子词与形态特征进行概率对齐，从而构建新的评估指标。

Result: 实验表明，新提出的指标与传统的词素边界召回率（morpheme boundary recall）相关性良好，并且在具有不同形态系统的语言中具有更广泛的适用性。

Conclusion: 该新指标能够有效评估子词分割的形态学合理性，且相比传统方法，其优势在于不依赖于昂贵且不一致的黄金分割数据，适用于更多语言。

Abstract: We present a novel metric for the evaluation of the morphological plausibility of subword segmentation. Unlike the typically used morpheme boundary or retrieval F-score, which requires gold segmentation data that is either unavailable or of inconsistent quality across many languages, our approach utilizes morpho-syntactic features. These are available in resources such as Universal Dependencies or UniMorph for a much wider range of languages. The metric works by probabilistically aligning subwords with morphological features through an IBM Model 1. Our experiments show that the metric correlates well with traditional morpheme boundary recall while being more broadly applicable across languages with different morphological systems.

</details>


### [335] [Unknown Unknowns: Why Hidden Intentions in LLMs Evade Detection](https://arxiv.org/abs/2601.18552)
*Devansh Srivastav,David Pape,Lea Schönherr*

Main category: cs.CL

TL;DR: 本文提出了一种“隐藏意图”的概念，用于描述大型语言模型（LLM）输出中难以检测的、旨在影响用户信念和行为的潜在目标导向行为。研究者构建了一个包含十类隐藏意图的分类法，并通过实验证明了这些意图的易诱发性和现有检测方法的失效性，尤其是在开放世界和低普遍性场景下。研究结果强调了开发更鲁棒的检测框架以应对LLM潜在风险的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM日益融入日常生活决策，其输出中可能存在的、难以察觉但旨在塑造用户信念和行为的“隐藏意图”引起了研究者的担忧。现有检测方法在实际应用场景中效果不佳，尤其是在开放世界和低普遍性条件下，这促使研究者深入探索隐藏意图的性质、诱导方式以及检测的挑战。

Method: 研究者首先构建了一个包含十个类别的“隐藏意图”分类法，并基于此在受控模型中进行了诱导实验。随后，他们系统性地评估了多种检测方法（包括基于推理和非推理的LLM裁判），并对精度-普遍性以及精度-漏报率（FNR）的权衡进行了压力测试。最后，通过对已部署的先进LLM进行定性案例研究来验证分类法的有效性。

Result: 研究表明，隐藏意图可以很容易地在受控模型中诱导，为评估提供了测试平台，并揭示了潜在的滥用可能。现有的检测方法在现实的开放世界设置下，尤其是在低普遍性条件下，检测效果会显著下降，假阳性率过高或漏报率过高。在已部署的先进LLM中，所有十类隐藏意图均有所体现。

Conclusion: 隐藏意图是LLM输出中一个真实存在的、难以检测的挑战，现有检测方法在开放世界设置下表现不佳。本文提出的分类法为理解、诱导和压力测试这些行为提供了基础，并有助于预测不断演变的威胁并指导治理策略。研究强调了开发鲁棒框架以应对LLM潜在风险的紧迫性。

Abstract: LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance.

</details>


### [336] [One Persona, Many Cues, Different Results: How Sociodemographic Cues Impact LLM Personalization](https://arxiv.org/abs/2601.18572)
*Franziska Weeber,Vera Neplenbroek,Jan Batzner,Sebastian Padó*

Main category: cs.CL

TL;DR: 通过研究不同社会人口群体（如使用姓名或明确提及属性）的提示词如何影响大型语言模型（LLM）的响应，发现不同的提示词会产生显著不同的结果，即使在统计上相关。研究人员建议在LLM个性化研究中应考虑多个外部有效的提示词，并对仅依赖单一提示词的研究提出警告。


<details>
  <summary>Details</summary>
Motivation: 现有研究通过单一提示词（如用户姓名或属性提及）来研究大型语言模型（LLM）中的偏见，忽略了LLM对提示词变化的敏感性（鲁棒性）以及某些提示词在实际交互中出现的稀少性（外部有效性）。

Method: 研究人员比较了七种开源和闭源LLM在四种写作和咨询任务上，六种常用的个人信息提示词的表现。

Result: 尽管提示词在总体上高度相关，但它们在不同个人信息下的响应产生了显著的差异。

Conclusion: 研究者警告不要仅凭单一的个人信息提示词来得出结论，并建议未来的个性化研究应评估多个外部有效的提示词。

Abstract: Personalization of LLMs by sociodemographic subgroup often improves user experience, but can also introduce or amplify biases and unfair outcomes across groups. Prior work has employed so-called personas, sociodemographic user attributes conveyed to a model, to study bias in LLMs by relying on a single cue to prompt a persona, such as user names or explicit attribute mentions. This disregards LLM sensitivity to prompt variations (robustness) and the rarity of some cues in real interactions (external validity). We compare six commonly used persona cues across seven open and proprietary LLMs on four writing and advice tasks. While cues are overall highly correlated, they produce substantial variance in responses across personas. We therefore caution against claims from a single persona cue and recommend future personalization research to evaluate multiple externally valid cues.

</details>


### [337] [From Classification to Ranking: Enhancing LLM Reasoning Capabilities for MBTI Personality Detection](https://arxiv.org/abs/2601.18582)
*Yuan Cao,Feixiang Liu,Xinyue Wang,Yihan Zhu,Hui Xu,Zheng Wang,Qiang Qiu*

Main category: cs.CL

TL;DR: 本文提出了一种将个性检测视为排序任务并使用强化学习进行训练的新方法，以克服现有基于提示的分类方法的局限性，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的个性检测方法依赖于手工制作的提示，缺乏自主学习能力，并且在处理复杂的人格和细微的特征区分时面临挑战。作者希望开发一种更鲁棒、更能自主学习的个性检测方法。

Method: 文章将个性检测视为一个排序任务，并提出了一个强化学习训练框架。首先，使用监督微调（SFT）来初始化模型，使其具备排序能力并标准化输出。然后，引入了基于组的相对策略优化（GRPO）算法，并设计了一个专门的基于排序的奖励函数来解决个性评估的主观性和模糊性。

Result: 实验结果表明，所提出的基于强化学习的排序方法在多个个性检测基准测试中取得了最先进的性能。

Conclusion: 将个性检测视为排序任务并采用强化学习训练是一种有效的方法，可以克服现有方法的局限性，提高准确性，并在个性检测任务上取得更好的性能。

Abstract: Personality detection aims to measure an individual's corresponding personality traits through their social media posts. The advancements in Large Language Models (LLMs) offer novel perspectives for personality detection tasks. Existing approaches enhance personality trait analysis by leveraging LLMs to extract semantic information from textual posts as prompts, followed by training classifiers for categorization. However, accurately classifying personality traits remains challenging due to the inherent complexity of human personality and subtle inter-trait distinctions. Moreover, prompt-based methods often exhibit excessive dependency on expert-crafted knowledge without autonomous pattern-learning capacity. To address these limitations, we view personality detection as a ranking task rather than a classification and propose a corresponding reinforcement learning training paradigm. First, we employ supervised fine-tuning (SFT) to establish personality trait ranking capabilities while enforcing standardized output formats, creating a robust initialization. Subsequently, we introduce Group Relative Policy Optimization (GRPO) with a specialized ranking-based reward function. Unlike verification tasks with definitive solutions, personality assessment involves subjective interpretations and blurred boundaries between trait categories. Our reward function explicitly addresses this challenge by training LLMs to learn optimal answer rankings. Comprehensive experiments have demonstrated that our method achieves state-of-the-art performance across multiple personality detection benchmarks.

</details>


### [338] [Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning](https://arxiv.org/abs/2601.18722)
*Lintang Sutawika,Gokul Swamy,Zhiwei Steven Wu,Graham Neubig*

Main category: cs.CL

TL;DR: SP3F是一个两阶段框架，无需目标语言数据即可增强多语言推理能力。它通过监督微调（SFT）和一种特殊的自我对抗强化学习（RL）来实现，其中评判模型可以使用英语参考答案作为特权信息。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（RLM）在处理非英语语言时，推理能力会显著下降，因为这些语言在训练数据中占比很少。

Method: SP3F框架包含两个阶段：1. 使用翻译后的英语问答对进行监督微调（SFT），以提高基础模型的正确率。2. 进行强化学习（RL），利用一个成对评判模型进行自我对抗式学习，该评判模型可以访问英语参考答案作为特权信息，即使模型生成的答案不完全正确，也能判断出哪个更好。

Result: SP3F显著提高了基础模型的性能，在数学和非数学任务上均表现优于完全事后训练的模型，且训练数据量更少。在单语言、多语言和泛化到未见语言的设置下均取得了更好的结果。

Conclusion: SP3F框架是一种有效的方法，可以在不使用目标语言数据的情况下，显著提升大型语言模型在多语言推理任务上的表现，并且训练效率高。

Abstract: When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than
  of the training data across the single-language, multilingual, and generalization to unseen language settings.

</details>


### [339] [Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale](https://arxiv.org/abs/2601.18730)
*Henry Bell,Caroline Zhang,Mohammed Mobasserul Haque,Dhaval Potdar,Samia Zaman,Brandon Fain*

Main category: cs.CL

TL;DR: 本文提出了一种名为REFLECT的即插即用框架，用于在LLM推理时进行原则对齐，无需训练或数据，通过生成、自我评估、自我批评和最终修订的 in-context 过程实现，有效提高LLM对原则的遵从度，且不牺牲事实推理能力，同时还能生成用于参数微调的训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM对齐方法（如RLHF）计算成本高，需要大量工程和标注数据。研究者希望找到一种更高效、无需训练的对齐方法。

Method: REFLECT是一个推理时框架，包含四个步骤：1. 基于原则生成基础响应；2. 对生成的响应进行自我评估；3. 对响应进行自我批评；4. 根据批评进行最终修订。该过程完全在上下文中进行。

Result: REFLECT能显著提高LLM对原则的遵从度，即使是与原始训练目标不同的原则，且不损害事实推理能力。它能有效减少罕见但重要的原则违规行为，提高模型的安全性和鲁棒性。此外，REFLECT生成的响应可以作为训练数据用于参数微调。

Conclusion: REFLECT是一种有效的、无需训练的LLM原则对齐方法，它通过显式的 in-context 推理来提高模型对原则的遵从度，并能生成有用的训练数据，为长期部署提供了更高效的解决方案。

Abstract: The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.

</details>


### [340] [MortalMATH: Evaluating the Conflict Between Reasoning Objectives and Emergency Contexts](https://arxiv.org/abs/2601.18790)
*Etienne Lanzeray,Stephane Meilliez,Malo Ruelle,Damien Sileo*

Main category: cs.CL

TL;DR: 专门用于复杂推理的语言模型在面临用户生命威胁时，可能会忽视安全问题，优先完成数学任务，而非提供帮助，且推理延迟可能导致危险。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在优化深度推理能力时，是否会产生“隧道视野”，从而忽视了在危急情况下的安全性。

Method: 引入一个名为MortalMATH的基准测试，包含150个场景，用户在请求代数帮助的同时描述危及生命的紧急情况。对比了通用模型和专业推理模型的行为。

Result: 通用模型（如Llama-3.1）能够成功拒绝数学任务并处理危险。而专业推理模型（如Qwen-3-32b和GPT-5-nano）通常会忽略紧急情况，在用户描述濒死时仍保持超过95%的任务完成率。此外，推理所需的计算时间会造成长达15秒的危险延迟。

Conclusion: 训练模型追求正确答案可能无意中“遗忘”了安全部署所需的生存本能。这种对正确答案的过度关注可能会导致模型在用户生命受到威胁时做出不安全的反应。

Abstract: Large Language Models are increasingly optimized for deep reasoning, prioritizing the correct execution of complex tasks over general conversation. We investigate whether this focus on calculation creates a "tunnel vision" that ignores safety in critical situations. We introduce MortalMATH, a benchmark of 150 scenarios where users request algebra help while describing increasingly life-threatening emergencies (e.g., stroke symptoms, freefall). We find a sharp behavioral split: generalist models (like Llama-3.1) successfully refuse the math to address the danger. In contrast, specialized reasoning models (like Qwen-3-32b and GPT-5-nano) often ignore the emergency entirely, maintaining over 95 percent task completion rates while the user describes dying. Furthermore, the computational time required for reasoning introduces dangerous delays: up to 15 seconds before any potential help is offered. These results suggest that training models to relentlessly pursue correct answers may inadvertently unlearn the survival instincts required for safe deployment.

</details>


### [341] [Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings](https://arxiv.org/abs/2601.18788)
*Mumin Jia,Jairo Diaz-Rodriguez*

Main category: cs.CL

TL;DR: 本文提出了一种名为Embed-KCPD的无监督文本分割方法，该方法将句子表示为嵌入向量，并通过最小化惩罚的KCPD目标来估计边界。研究还提供了KCPD的依赖感知理论，并设计了一个LLM模拟框架来验证该方法的有效性。实验结果表明，Embed-KCPD在标准基准测试中优于现有方法，并在实际应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 文本分割的边界标签获取成本高昂、主观性强且跨领域和粒度迁移能力差，因此需要一种无需监督的文本分割方法。

Method: 将句子表示为嵌入向量，并设计了一种名为Embed-KCPD的训练无关方法，通过最小化惩罚的KCPD目标来估计分割边界。此外，还建立了KCPD的依赖感知理论，并开发了一个基于LLM的模拟框架来生成合成数据并验证理论。

Result: Embed-KCPD在标准文本分割基准测试中通常优于强大的无监督基线方法。理论证明了其风险的Oracle不等式和局部化保证。LLM模拟框架验证了其可预测的缩放行为。

Conclusion: Embed-KCPD是一种具有强大理论保证、模拟可靠性和实际有效性的文本分割方法，适用于无监督场景。它结合了理论分析和实践验证，为文本分割问题提供了一个有前景的解决方案。

Abstract: Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [342] [Breaking Task Impasses Quickly: Adaptive Neuro-Symbolic Learning for Open-World Robotics](https://arxiv.org/abs/2601.16985)
*Pierrick Lorang*

Main category: cs.RO

TL;DR: 提出了一种结合分层抽象、任务与运动规划（TAMP）和强化学习（RL）的神经符号框架，用于机器人快速适应新情况，并在机器人操作和自动驾驶中取得了优于现有混合方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的混合规划和强化学习方法在应对开放世界环境中的新情况时，存在样本效率低、适应速度慢和灾难性遗忘等问题，阻碍了自主系统的发展。

Method: 提出一个神经符号框架，该框架结合了分层抽象、任务与运动规划（TAMP）和强化学习。具体来说，它集成了符号目标导向学习和基于世界模型的探索，以促进对环境变化的快速适应。

Result: 在机器人操作和自动驾驶任务中进行了验证，该方法实现了比最先进的混合方法更快的收敛速度、更高的样本效率和更强的鲁棒性。

Conclusion: 所提出的神经符号框架在机器人领域展现出快速适应新情况的潜力，并可能适用于实际部署。

Abstract: Adapting to unforeseen novelties in open-world environments remains a major challenge for autonomous systems. While hybrid planning and reinforcement learning (RL) approaches show promise, they often suffer from sample inefficiency, slow adaptation, and catastrophic forgetting. We present a neuro-symbolic framework integrating hierarchical abstractions, task and motion planning (TAMP), and reinforcement learning to enable rapid adaptation in robotics. Our architecture combines symbolic goal-oriented learning and world model-based exploration to facilitate rapid adaptation to environmental changes. Validated in robotic manipulation and autonomous driving, our approach achieves faster convergence, improved sample efficiency, and superior robustness over state-of-the-art hybrid methods, demonstrating its potential for real-world deployment.

</details>


### [343] [Quantifying Ergonomics in the Elevate Soft Robotic Suit](https://arxiv.org/abs/2601.17249)
*Peter Bryan,Rejin John Varghese,Dario Farina*

Main category: cs.RO

TL;DR: 本文量化评估了Elevate软体机器人服装（一种用于辅助肩部抬起的绳索驱动软体机器人服装）的人体工程学和舒适性。实验结果表明，该服装在高达70度的肩部抬举辅助过程中，即使在200N的拉力下，用户也没有感到不适，并且施加的压力和体积压缩量均在可接受范围内，为未来在患者群体中的研究提供了初步验证。


<details>
  <summary>Details</summary>
Motivation: 现有的软体机器人服装在设计上存在数据驱动、用户特定和舒适性优先的挑战，限制了其广泛应用。这项工作旨在通过量化评估Elevate软体机器人服装的人体工程学和舒适性，来克服这些障碍。

Method: 使用运动捕捉系统和力传感器，在一名受试者身上进行了为期4小时的两次实验，以测量在高达70度的肩部抬举辅助过程中服装的人体工程学性能。通过测量施加的压力和体积压缩量来评估舒适性。

Result: 在高达200N的绳索张力下，受试者在肩部抬举辅助过程中没有报告不适。估计施加在肩膀上的压力在人手抓握的范围内（约69.1-85.1kPa），并且躯干和上臂的体积压缩量分别估计小于3%和8%。

Conclusion: Elevate软体机器人服装在人体工程学设计上得到了初步验证，其舒适性在实验条件下得到了证实，这为其未来在患者群体中的进一步研究奠定了基础。

Abstract: Soft robotic suits have the potential to rehabilitate, assist, and augment the human body. The low weight, cost, and minimal form-factor of these devices make them ideal for daily use by both healthy and impaired individuals. However, challenges associated with data-driven, user-specific, and comfort-first design of human-robot interfaces using soft materials limit their widespread translation and adoption. In this work, we present the quantitative evaluation of ergonomics and comfort of the Elevate suit - a cable driven soft robotic suit that assists shoulder elevation. Using a motion-capture system and force sensors, we measured the suit's ergonomics during assisted shoulder elevation up to 70 degrees. Two 4-hour sessions were conducted with one subject, involving transmitting cable tensions of up to 200N with no discomfort reported. We estimated that the pressure applied to the shoulder during assisted movements was within the range seen in a human grasp (approximately 69.1-85.1kPa), and estimated volumetric compression of <3% and <8% across the torso and upper arm, respectively. These results provide early validation of Elevate's ergonomic design in preparation for future studies with patient groups.

</details>


### [344] [Real-Time, Energy-Efficient, Sampling-Based Optimal Control via FPGA Acceleration](https://arxiv.org/abs/2601.17231)
*Tanmay Desai,Brian Plancher,R. Iris Bahar*

Main category: cs.RO

TL;DR: 研究提出了一种基于FPGA的MPPI（Model Predictive Path Integral Control）优化设计，相比嵌入式GPU和CPU，实现了更快的速度和更低的能耗，证明了FPGA在边缘机器人领域的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于MPPI的机器人规划控制方法在GPU和CPU上的实现，在满足电池受限的自主移动机器人（AMR）平台的能耗和延迟预算方面存在困难。

Method: 提出了一种FPGA优化的MPPI设计，通过深度流水线和算法阶段间的并行性，实现了细粒度的并行和消除了同步瓶颈。

Result: 与优化的嵌入式GPU和CPU实现相比，FPGA实现平均速度提升3.1倍至7.5倍，同时能耗降低2.5倍至5.4倍。

Conclusion: FPGA架构为高能效、高性能的边缘机器人提供了有前景的发展方向。

Abstract: Autonomous mobile robots (AMRs), used for search-and-rescue and remote exploration, require fast and robust planning and control schemes. Sampling-based approaches for Model Predictive Control, especially approaches based on the Model Predictive Path Integral Control (MPPI) algorithm, have recently proven both to be highly effective for such applications and to map naturally to GPUs for hardware acceleration. However, both GPU and CPU implementations of such algorithms can struggle to meet tight energy and latency budgets on battery-constrained AMR platforms that leverage embedded compute. To address this issue, we present an FPGA-optimized MPPI design that exposes fine-grained parallelism and eliminates synchronization bottlenecks via deep pipelining and parallelism across algorithmic stages. This results in an average 3.1x to 7.5x speedup over optimized implementations on an embedded GPU and CPU, respectively, while simultaneously achieving a 2.5x to 5.4x reduction in energy usage. These results demonstrate that FPGA architectures are a promising direction for energy-efficient and high-performance edge robotics.

</details>


### [345] [Hierarchical Informative Path Planning via Graph Guidance and Trajectory Optimization](https://arxiv.org/abs/2601.17227)
*Avraiem Iskandar,Shamak Dutta,Kevin Murrant,Yash Vardhan Pant,Stephen L. Smith*

Main category: cs.RO

TL;DR: 本文提出了一种分层框架，用于在存在障碍物的环境中进行带预算的信息路径规划（IPP），该框架通过图规划、预算分配和样条曲线优化相结合，实现了比现有方法更低的后验不确定性和更快的计算速度。


<details>
  <summary>Details</summary>
Motivation: 在存在障碍物的环境中进行信息路径规划（IPP）是一个重要但具有挑战性的问题。现有的图搜索方法虽然有全局保证，但需要预先选择测量点；而连续轨迹优化虽然支持路径式传感，但计算成本高且对初始化敏感。作者希望结合两者的优点，提出一种更有效的方法。

Method: 提出一个包含三个阶段的分层框架：1. 基于图的全局规划；2. 利用几何和核边界进行分段预算分配；3. 基于样条曲线的局部路径优化，并加入硬约束和障碍物修剪。

Result: 所提出的方法在合成和真实数据集（包括北极数据集）上，实现了比仅使用图规划或连续轨迹优化方法更低的后验不确定性，并且计算速度更快（比梯度下降法快9倍，比黑盒优化器快20倍）。

Conclusion: 该分层框架成功地结合了全局规划和局部优化的优点，在保证信息增益的同时，有效解决了在复杂障碍环境中进行信息路径规划的效率和计算成本问题。

Abstract: We study informative path planning (IPP) with travel budgets in cluttered environments, where an agent collects measurements of a latent field modeled as a Gaussian process (GP) to reduce uncertainty at target locations. Graph-based solvers provide global guarantees but assume pre-selected measurement locations, while continuous trajectory optimization supports path-based sensing but is computationally intensive and sensitive to initialization in obstacle-dense settings. We propose a hierarchical framework with three stages: (i) graph-based global planning, (ii) segment-wise budget allocation using geometric and kernel bounds, and (iii) spline-based refinement of each segment with hard constraints and obstacle pruning. By combining global guidance with local refinement, our method achieves lower posterior uncertainty than graph-only and continuous baselines, while running faster than continuous-space solvers (up to 9x faster than gradient-based methods and 20x faster than black-box optimizers) across synthetic cluttered environments and Arctic datasets.

</details>


### [346] [Advancing Improvisation in Human-Robot Construction Collaboration: Taxonomy and Research Roadmap](https://arxiv.org/abs/2601.17219)
*David Wireko Atibila,Vineet R. Kamat,Carol C. Menassa*

Main category: cs.RO

TL;DR: 该研究提出了一个六级人机协作（HRC）分类法，重点关注即兴创作能力，以应对建筑行业在非结构化、动态场地中机器人自动化所面临的挑战。现有研究主要集中在较低级别，在经验学习和协作即兴创作方面存在显著差距。研究人员提出了一种五维雷达框架来评估HRC的进步，并指出了实现真正协作即兴创作的技术、概念和方法障碍。建议未来研究关注AR/VR接口、大型语言模型和云知识系统以增强人机通信。


<details>
  <summary>Details</summary>
Motivation: 建筑行业面临生产力停滞、熟练劳动力短缺和安全问题。尽管机器人自动化提供了解决方案，但建筑机器人难以适应非结构化、动态的场地。即兴创作（通过创造性问题解决来适应意外情况）仍然是人类的独特能力，但对于确保工作流程的连续性，在建筑业不可预测的环境中，人机协作即兴创作至关重要。

Method: 通过对2010年至2025年期间的214篇论文进行系统性文献综述，研究人员开发了一个六级人机协作（HRC）分类法，该分类法基于即兴创作能力。他们将建筑机器人研究划分为七个级别：手动工作（0级）、人为控制执行（1级）、自适应操作（2级）、模仿学习（3级）、人-循环BIM工作流（4级）、基于云的知识整合（5级）和真正的协作即兴创作（6级）。此外，研究人员还提出了一个五维雷达框架（规划、认知角色、物理执行、学习能力和即兴创作）来可视化HRC的进步。

Result: 系统性文献综述揭示，当前的研究主要集中在较低级别的HRC（0-3级），在经验学习和向协作即兴创作的进展方面存在显著的研究空白。五维雷达框架表明，互补的人机协作能力可以产生超越个体贡献的团队绩效。研究识别出实现真正协作即兴创作面临三个基本障碍：落地和对话推理方面的技术限制、人类即兴创作与机器人研究之间的概念差距，以及方法论上的挑战。

Conclusion: 为了推进建筑业的真正协作即兴创作，需要克服技术、概念和方法上的障碍。未来的研究应侧重于利用增强现实/虚拟现实（AR/VR）接口、大型语言模型（LLM）和基于云的知识系统来增强人机通信，从而提升机器人应对非结构化环境中的复杂性和意外情况的能力。

Abstract: The construction industry faces productivity stagnation, skilled labor shortages, and safety concerns. While robotic automation offers solutions, construction robots struggle to adapt to unstructured, dynamic sites. Central to this is improvisation, adapting to unexpected situations through creative problem-solving, which remains predominantly human. In construction's unpredictable environments, collaborative human-robot improvisation is essential for workflow continuity. This research develops a six-level taxonomy classifying human-robot collaboration (HRC) based on improvisation capabilities. Through systematic review of 214 articles (2010-2025), we categorize construction robotics across: Manual Work (Level 0), Human-Controlled Execution (Level 1), Adaptive Manipulation (Level 2), Imitation Learning (Level 3), Human-in-Loop BIM Workflow (Level 4), Cloud-Based Knowledge Integration (Level 5), and True Collaborative Improvisation (Level 6). Analysis reveals current research concentrates at lower levels, with critical gaps in experiential learning and limited progression toward collaborative improvisation. A five-dimensional radar framework illustrates progressive evolution of Planning, Cognitive Role, Physical Execution, Learning Capability, and Improvisation, demonstrating how complementary human-robot capabilities create team performance exceeding individual contributions. The research identifies three fundamental barriers: technical limitations in grounding and dialogic reasoning, conceptual gaps between human improvisation and robotics research, and methodological challenges. We recommend future research emphasizing improved human-robot communication via Augmented/Virtual Reality interfaces, large language model integration, and cloud-based knowledge systems to advance toward true collaborative improvisation.

</details>


### [347] [EMPM: Embodied MPM for Modeling and Simulation of Deformable Objects](https://arxiv.org/abs/2601.17251)
*Yunuo Chen,Yafei Hu,Lingfeng Sun,Tushar Kusnur,Laura Herlant,Chenfanfu Jiang*

Main category: cs.RO

TL;DR: 提出了一种名为EMPM的、基于可微分材料点方法（MPM）的可变形物体建模和仿真框架，能够从多视角RGB-D视频中重建几何和外观，并在线优化MPM参数，以实现对复杂可变形物体的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 现有的可变形物体建模方法在物理合理性、泛化性和数据效率方面存在挑战，往往简化了物体动力学或需要大量训练数据，限制了泛化能力。

Method: 利用可微分的MPM物理引擎，从多视角RGB-D视频中重建物体几何和外观，并通过最小化预测与观测数据之间的差异来模拟物体行为。此外，利用传感器反馈在线优化MPM参数。

Result: EMPM能够捕捉具有挑战性材料的动力学，并实现了对复杂可变形物体的自适应、鲁棒且符合物理规律的物体表示，优于传统的弹簧-质量基线模型。

Conclusion: EMPM是一个强大的可变形物体建模和仿真框架，通过结合可微分MPM和在线参数优化，显著提升了机器人操作复杂可变形物体的能力。

Abstract: Modeling deformable objects - especially continuum materials - in a way that is physically plausible, generalizable, and data-efficient remains challenging across 3D vision, graphics, and robotic manipulation. Many existing methods oversimplify the rich dynamics of deformable objects or require large training sets, which often limits generalization. We introduce embodied MPM (EMPM), a deformable object modeling and simulation framework built on a differentiable Material Point Method (MPM) simulator that captures the dynamics of challenging materials. From multi-view RGB-D videos, our approach reconstructs geometry and appearance, then uses an MPM physics engine to simulate object behavior by minimizing the mismatch between predicted and observed visual data. We further optimize MPM parameters online using sensory feedback, enabling adaptive, robust, and physics-aware object representations that open new possibilities for robotic manipulation of complex deformables. Experiments show that EMPM outperforms spring-mass baseline models. Project website: https://embodied-mpm.github.io.

</details>


### [348] [Real-Time Synchronized Interaction Framework for Emotion-Aware Humanoid Robots](https://arxiv.org/abs/2601.17287)
*Yanrong Chen,Xihan Bian*

Main category: cs.RO

TL;DR: 该研究提出了一种用于NAO机器人的实时框架，通过创新的情感引擎、动态时间规整和闭环可行性验证，实现了语音韵律与全身手势在情感上的同步，显著提高了情感一致性。


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人越来越多地进入社交场景，实现情感同步的多模态交互仍然是一个重大挑战。为了促进人形机器人进一步融入服务领域，需要一个能够同步语音韵律和全身手势的框架。

Method: 该框架包含三个关键创新：(1) 一个双通道情感引擎，利用大型语言模型（LLM）生成上下文感知的文本响应和符合生物力学要求、受结构化关节运动库约束的运动描述符；(2) 感知时长的动态时间规整，用于精确对齐语音输出和运动学运动关键帧的时间；(3) 闭环可行性验证，通过实时调整确保手势符合NAO的物理关节限制。

Result: 通过协调声调（受唤醒度驱动）和上肢运动学，同时保持下肢稳定性，该框架实现了21%的情感一致性提升，优于基于规则的系统。

Conclusion: 该框架通过实现无缝的传感运动协调，提高了机器人情感同步多模态交互的能力，有望在个性化医疗、互动教育和响应式客户服务等动态应用中推动上下文感知社交机器人的部署。

Abstract: As humanoid robots increasingly introduced into social scene, achieving emotionally synchronized multimodal interaction remains a significant challenges. To facilitate the further adoption and integration of humanoid robots into service roles, we present a real-time framework for NAO robots that synchronizes speech prosody with full-body gestures through three key innovations: (1) A dual-channel emotion engine where large language model (LLM) simultaneously generates context-aware text responses and biomechanically feasible motion descriptors, constrained by a structured joint movement library; (2) Duration-aware dynamic time warping for precise temporal alignment of speech output and kinematic motion keyframes; (3) Closed-loop feasibility verification ensuring gestures adhere to NAO's physical joint limits through real-time adaptation. Evaluations show 21% higher emotional alignment compared to rule-based systems, achieved by coordinating vocal pitch (arousal-driven) with upper-limb kinematics while maintaining lower-body stability. By enabling seamless sensorimotor coordination, this framework advances the deployment of context-aware social robots in dynamic applications such as personalized healthcare, interactive education, and responsive customer service platforms.

</details>


### [349] [Eye-Tracking-Driven Control in Daily Task Assistance for Assistive Robotic Arms](https://arxiv.org/abs/2601.17404)
*Anke Fischer-Janzen,Thomas M. Wendt,Kristof Van Laerhoven*

Main category: cs.RO

TL;DR: 提出了一种眼动追踪驱动的共享控制框架，通过结合任务图示和特征匹配，提高了残疾人士独立完成日常任务的能力，该框架在对象和任务选择方面的准确率高达97.9%。


<details>
  <summary>Details</summary>
Motivation: 当前的眼动追踪驱动的共享控制方法在3D注视估计的准确性和区分多个任务时解释注视信息方面存在挑战，这阻碍了残疾人士独立完成日常任务。

Method: 该框架使用任务图示作为标识符，结合特征匹配方法，通过眼在手中配置传输选定对象的数据，以完成任务相关的测量。它不需要用户了解其与对象的位置关系。

Result: 在对象和任务选择的测量中，框架的正确解释率高达97.9%。研究中发现了改进的评估问题，并分享为经验教训。

Conclusion: 提出的眼动追踪驱动的共享控制框架能够准确地识别对象和任务选择，提高了残疾人士独立完成日常任务的能力。该框架是开源的，并集成了先进的对象检测模型，可以适应新任务和对象。

Abstract: Shared control improves Human-Robot Interaction by reducing the user's workload and increasing the robot's autonomy. It allows robots to perform tasks under the user's supervision. Current eye-tracking-driven approaches face several challenges. These include accuracy issues in 3D gaze estimation and difficulty interpreting gaze when differentiating between multiple tasks. We present an eye-tracking-driven control framework, aimed at enabling individuals with severe physical disabilities to perform daily tasks independently. Our system uses task pictograms as fiducial markers combined with a feature matching approach that transmits data of the selected object to accomplish necessary task related measurements with an eye-in-hand configuration. This eye-tracking control does not require knowledge of the user's position in relation to the object. The framework correctly interpreted object and task selection in up to 97.9% of measurements. Issues were found in the evaluation, that were improved and shared as lessons learned. The open-source framework can be adapted to new tasks and objects due to the integration of state-of-the-art object detection models.

</details>


### [350] [DiffusionCinema: Text-to-Aerial Cinematography](https://arxiv.org/abs/2601.17412)
*Valerii Serpiva,Artem Lykov,Jeffrin Sam,Aleksey Fedoseev,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 提出了一种利用扩散模型将自然语言指令转换为无人机航拍轨迹的系统，实现了文本驱动的电影级视频录制。


<details>
  <summary>Details</summary>
Motivation: 为了简化无人机航拍过程，减少人工操作的复杂性和工作量，使用户能够通过自然语言描述来完成复杂的镜头拍摄。

Method: 开发了一个无人机辅助创意捕捉系统，该系统将用户的自然语言指令与无人机 onboard 摄像机的初始快照一起编码。利用扩散模型生成满足场景几何和镜头语义要求的三维空间运动轨迹，并由无人机自主执行。

Result: 用户评估显示，与传统遥控器相比，该系统显著降低了用户的工作量（平均 TLX 得分 21.6 vs 58.1），尤其是在精神需求和挫败感方面。

Conclusion: 该系统提供了一种新的“文本到电影”飞行交互范式，扩散模型充当创意操作员，将用户的意图直接转化为航拍运动，极大地提高了无人机摄影的易用性和效率。

Abstract: We propose a novel Unmanned Aerial Vehicles (UAV) assisted creative capture system that leverages diffusion models to interpret high-level natural language prompts and automatically generate optimal flight trajectories for cinematic video recording. Instead of manually piloting the drone, the user simply describes the desired shot (e.g., "orbit around me slowly from the right and reveal the background waterfall"). Our system encodes the prompt along with an initial visual snapshot from the onboard camera, and a diffusion model samples plausible spatio-temporal motion plans that satisfy both the scene geometry and shot semantics. The generated flight trajectory is then executed autonomously by the UAV to record smooth, repeatable video clips that match the prompt. User evaluation using NASA-TLX showed a significantly lower overall workload with our interface (M = 21.6) compared to a traditional remote controller (M = 58.1), demonstrating a substantial reduction in perceived effort. Mental demand (M = 11.5 vs. 60.5) and frustration (M = 14.0 vs. 54.5) were also markedly lower for our system, confirming clear usability advantages in autonomous text-driven flight control. This project demonstrates a new interaction paradigm: text-to-cinema flight, where diffusion models act as the "creative operator" converting story intentions directly into aerial motion.

</details>


### [351] [Scaling Rough Terrain Locomotion with Automatic Curriculum Reinforcement Learning](https://arxiv.org/abs/2601.17428)
*Ziming Li,Chenhao Li,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种基于学习进度的自动课程强化学习（LP-ACRL）框架，用于机器人学习，无需预先知道任务难度，并成功使ANYmal D四足机器人实现了在复杂地形上的高速稳定运动。


<details>
  <summary>Details</summary>
Motivation: 现有的课程学习方法在扩展到复杂、广泛的任务空间时存在局限性，因为这些任务空间缺乏明确的难度结构，难以定义难度排序。

Method: 提出了一种名为LP-ACRL的框架，该框架在线估计智能体的学习进度，并自适应地调整任务采样分布，从而在不了解任务空间难度分布先验知识的情况下自动生成课程。

Result: 使用LP-ACRL训练的策略使ANYmal D四足机器人在2.5 m/s的线速度和3.0 rad/s的角速度下，在包括楼梯、斜坡、砾石和低摩擦平坦地面在内的多样化地形上实现了稳定、高速的运动。相比之下，之前的方法通常仅限于在平坦地形上高速运动或在复杂地形上低速运动。

Conclusion: LP-ACRL框架表现出强大的可扩展性和现实世界的适用性，为未来在复杂、广泛的机器人学习任务空间中进行课程生成的研究提供了一个强大的基线。

Abstract: Curriculum learning has demonstrated substantial effectiveness in robot learning. However, it still faces limitations when scaling to complex, wide-ranging task spaces. Such task spaces often lack a well-defined difficulty structure, making the difficulty ordering required by previous methods challenging to define. We propose a Learning Progress-based Automatic Curriculum Reinforcement Learning (LP-ACRL) framework, which estimates the agent's learning progress online and adaptively adjusts the task-sampling distribution, thereby enabling automatic curriculum generation without prior knowledge of the difficulty distribution over the task space. Policies trained with LP-ACRL enable the ANYmal D quadruped to achieve and maintain stable, high-speed locomotion at 2.5 m/s linear velocity and 3.0 rad/s angular velocity across diverse terrains, including stairs, slopes, gravel, and low-friction flat surfaces--whereas previous methods have generally been limited to high speeds on flat terrain or low speeds on complex terrain. Experimental results demonstrate that LP-ACRL exhibits strong scalability and real-world applicability, providing a robust baseline for future research on curriculum generation in complex, wide-ranging robotic learning task spaces.

</details>


### [352] [PILOT: A Perceptive Integrated Low-level Controller for Loco-manipulation over Unstructured Scenes](https://arxiv.org/abs/2601.17440)
*Xinru Cui,Linxi Feng,Yixuan Zhou,Haoqi Han,Zhe Liu,Hesheng Wang*

Main category: cs.RO

TL;DR: 提出了一种名为PILOT的统一单阶段强化学习框架，用于人形机器人的感知运动操作，该框架整合了感知行走和全身控制，并引入了跨模态上下文编码器和混合专家策略架构，在仿真和实际机器人上均表现出优于基线方法的稳定性和精确性。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人全身控制器缺乏对周围环境的感知能力，难以在复杂、非结构化场景中稳定执行任务。

Method: 设计了一个名为PILOT的单阶段强化学习框架，该框架整合了感知行走和全身控制。通过设计跨模态上下文编码器融合了基于预测的本体感觉特征和基于注意力的感知表示，并引入了混合专家（MoE）策略架构来协调不同的运动技能。

Result: 在仿真和实际Unitree G1人形机器人上的实验表明，PILOT相比于现有基线方法，在稳定性、指令跟踪精度和地形适应性方面表现更优。

Conclusion: PILOT是一个有效的、统一的单阶段强化学习框架，能够实现感知运动操作，有望成为在非结构化场景下进行运动操作的鲁棒基础低级控制器。

Abstract: Humanoid robots hold great potential for diverse interactions and daily service tasks within human-centered environments, necessitating controllers that seamlessly integrate precise locomotion with dexterous manipulation. However, most existing whole-body controllers lack exteroceptive awareness of the surrounding environment, rendering them insufficient for stable task execution in complex, unstructured scenarios.To address this challenge, we propose PILOT, a unified single-stage reinforcement learning (RL) framework tailored for perceptive loco-manipulation, which synergizes perceptive locomotion and expansive whole-body control within a single policy. To enhance terrain awareness and ensure precise foot placement, we design a cross-modal context encoder that fuses prediction-based proprioceptive features with attention-based perceptive representations. Furthermore, we introduce a Mixture-of-Experts (MoE) policy architecture to coordinate diverse motor skills, facilitating better specialization across distinct motion patterns. Extensive experiments in both simulation and on the physical Unitree G1 humanoid robot validate the efficacy of our framework. PILOT demonstrates superior stability, command tracking precision, and terrain traversability compared to existing baselines. These results highlight its potential to serve as a robust, foundational low-level controller for loco-manipulation in unstructured scenes.

</details>


### [353] [EquiForm: Noise-Robust SE(3)-Equivariant Policy Learning from 3D Point Clouds](https://arxiv.org/abs/2601.17486)
*Zhiyuan Zhang,Yu She*

Main category: cs.RO

TL;DR: 提出了一种名为 EquiForm 的框架，用于提高基于 3D 点云的视觉模仿学习的鲁棒性，通过几何去噪和对比式等变对齐来解决传感器噪声、姿态扰动和遮挡问题，从而提升机器人操作的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于点云的模仿学习方法对传感器噪声、姿态扰动和遮挡等问题敏感，导致几何结构失真，影响泛化能力。现有的等变方法主要关注编码对称性约束，但未能明确纠正噪声引起的几何偏差或强制学习表示的等变一致性。

Method: EquiForm 框架包含两个主要组件：1) 几何去噪模块，用于在噪声或不完整观测下恢复一致的 3D 结构；2) 对比式等变对齐目标，强制表示在刚性变换和噪声扰动下保持一致性。该框架将噪声鲁棒的几何推理与现代生成模型相结合。

Result: 在 16 个模拟任务和 4 个真实世界操作任务上进行了评估，EquiForm 在模拟环境中平均提高了 17.2%，在真实世界实验中提高了 28.1%，显著优于现有的点云模仿学习方法，证明了其强大的噪声鲁棒性和空间泛化能力。

Conclusion: EquiForm 是一种新颖的噪声鲁棒 SE(3)-等变策略学习框架，通过几何去噪和对比式等变对齐，有效解决了点云模仿学习中的几何偏差和表示不一致问题，显著提升了机器人在噪声和扰动下的操作性能和泛化能力。

Abstract: Visual imitation learning with 3D point clouds has advanced robotic manipulation by providing geometry-aware, appearance-invariant observations. However, point cloud-based policies remain highly sensitive to sensor noise, pose perturbations, and occlusion-induced artifacts, which distort geometric structure and break the equivariance assumptions required for robust generalization. Existing equivariant approaches primarily encode symmetry constraints into neural architectures, but do not explicitly correct noise-induced geometric deviations or enforce equivariant consistency in learned representations. We introduce EquiForm, a noise-robust SE(3)-equivariant policy learning framework for point cloud-based manipulation. EquiForm formalizes how noise-induced geometric distortions lead to equivariance deviations in observation-to-action mappings, and introduces a geometric denoising module to restore consistent 3D structure under noisy or incomplete observations. In addition, we propose a contrastive equivariant alignment objective that enforces representation consistency under both rigid transformations and noise perturbations. Built upon these components, EquiForm forms a flexible policy learning pipeline that integrates noise-robust geometric reasoning with modern generative models. We evaluate EquiForm on 16 simulated tasks and 4 real-world manipulation tasks across diverse objects and scene layouts. Compared to state-of-the-art point cloud imitation learning methods, EquiForm achieves an average improvement of 17.2% in simulation and 28.1% in real-world experiments, demonstrating strong noise robustness and spatial generalization.

</details>


### [354] [MetaWorld: Skill Transfer and Composition in a Hierarchical World Model for Grounding High-Level Instructions](https://arxiv.org/abs/2601.17507)
*Yutong Shen,Hangxu Liu,Kailin Pei,Ruizhe Xia,Tongtong Feng*

Main category: cs.RO

TL;DR: 提出了一种名为MetaWorld的层级世界模型，通过迁移专家策略来整合语义规划和物理控制，以解决人形机器人 loco-manipulation 中的语义-物理鸿沟问题，提升了样本效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人 loco-manipulation 方法在样本效率、泛化能力和物理一致性方面存在局限性，主要是由于语义-物理鸿沟。研究旨在克服这些挑战。

Method: MetaWorld是一个层级世界模型，将任务分解为由VLM驱动的语义层和运行在紧凑状态空间中的潜在动态模型。采用动态专家选择和运动先验融合机制，利用预训练的多专家策略库作为可迁移知识，通过两阶段框架实现高效的在线适应。VLM充当语义接口，将指令映射到可执行技能。

Result: MetaWorld在Humanoid-Bench上的实验表明，其在任务完成度和运动连贯性方面优于基于世界模型的强化学习方法。

Conclusion: MetaWorld成功地通过迁移专家策略整合了语义规划和物理控制，有效解决了人形机器人 loco-manipulation 中的语义-物理鸿沟问题，提高了效率和性能。

Abstract: Humanoid robot loco-manipulation remains constrained by the semantic-physical gap. Current methods face three limitations: Low sample efficiency in reinforcement learning, poor generalization in imitation learning, and physical inconsistency in VLMs. We propose MetaWorld, a hierarchical world model that integrates semantic planning and physical control via expert policy transfer. The framework decouples tasks into a VLM-driven semantic layer and a latent dynamics model operating in a compact state space. Our dynamic expert selection and motion prior fusion mechanism leverages a pre-trained multi-expert policy library as transferable knowledge, enabling efficient online adaptation via a two-stage framework. VLMs serve as semantic interfaces, mapping instructions to executable skills and bypassing symbol grounding. Experiments on Humanoid-Bench show MetaWorld outperforms world model-based RL in task completion and motion coherence. Our code will be found at https://anonymous.4open.science/r/metaworld-2BF4/

</details>


### [355] [AsterNav: Autonomous Aerial Robot Navigation In Darkness Using Passive Computation](https://arxiv.org/abs/2601.17550)
*Deepak Singh,Shreyas Khobragade,Nitin J. Sanket*

Main category: cs.RO

TL;DR: 该研究提出了一种名为AsterNav的自主空中导航系统，该系统利用红外单目摄像头、大孔径编码镜头和结构光，在完全黑暗的环境下实现导航，无需外部基础设施。该系统能够实时（20 Hz）在NVIDIA Jetson Orin Nano上运行，并成功地在真实世界实验中以95.5%的成功率导航，即使面对具有挑战性的障碍物。


<details>
  <summary>Details</summary>
Motivation: 在灾难后的搜救行动中，小型无人机在完全黑暗的环境下进行自主导航至关重要，但由于资源限制，它们无法安全地找到幸存者。现有技术在黑暗中导航的能力有限。

Method: 该方法结合了红外单目摄像头、大孔径编码镜头和结构光。结构光点会根据深度呈现出深度依赖的散焦模糊图案。这些信息被用作AsterNet深度估计模型的强先验。AsterNet模型在模拟环境中训练，并在真实世界中进行部署，无需微调。该网络对结构光图案和发射器/摄像机相对位置的变化具有鲁棒性。

Result: AsterNet在NVIDIA Jetson Orin Nano上以20 Hz的速率运行，并实现了高精度的深度估计。在真实世界实验中，AsterNav系统在导航过程中取得了95.5%的成功率，即使在有黑暗、哑光障碍物和细绳（直径6.25毫米）的情况下也能有效工作，并且无需了解物体的形状、位置或材料。

Conclusion: 研究成功开发并演示了一种在完全黑暗中基于单目结构光进行四旋翼自主导航的方法。该方法简化了系统设计，降低了成本，并实现了在现实世界中的有效导航，为灾难搜救等应用提供了有前景的解决方案。

Abstract: Autonomous aerial navigation in absolute darkness is crucial for post-disaster search and rescue operations, which often occur from disaster-zone power outages. Yet, due to resource constraints, tiny aerial robots, perfectly suited for these operations, are unable to navigate in the darkness to find survivors safely. In this paper, we present an autonomous aerial robot for navigation in the dark by combining an Infra-Red (IR) monocular camera with a large-aperture coded lens and structured light without external infrastructure like GPS or motion-capture. Our approach obtains depth-dependent defocus cues (each structured light point appears as a pattern that is depth dependent), which acts as a strong prior for our AsterNet deep depth estimation model. The model is trained in simulation by generating data using a simple optical model and transfers directly to the real world without any fine-tuning or retraining. AsterNet runs onboard the robot at 20 Hz on an NVIDIA Jetson Orin$^\text{TM}$ Nano. Furthermore, our network is robust to changes in the structured light pattern and relative placement of the pattern emitter and IR camera, leading to simplified and cost-effective construction. We successfully evaluate and demonstrate our proposed depth navigation approach AsterNav using depth from AsterNet in many real-world experiments using only onboard sensing and computation, including dark matte obstacles and thin ropes (diameter 6.25mm), achieving an overall success rate of 95.5% with unknown object shapes, locations and materials. To the best of our knowledge, this is the first work on monocular, structured-light-based quadrotor navigation in absolute darkness.

</details>


### [356] [Correct-by-Construction Vision-based Pose Estimation using Geometric Generative Models](https://arxiv.org/abs/2601.17556)
*Ulices Santa Cruz,Mahmoud Elfar,Yasser Shoukry*

Main category: cs.RO

TL;DR: 提出了一种结合物理模型和学习的视觉姿态估计算法，为自动驾驶系统提供可证明的正确性保证，即使在杂乱环境中也能有效工作。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在姿态估计方面表现出色，但缺乏安全关键应用所需的输出正确性保证。

Method: 该框架设计了可认证的神经网络（NN），集成了物理驱动建模和基于学习的估计。核心是利用平面目标物的已知几何特性，设计一个几何生成模型（GGM），然后用GGM训练具有估计误差认证保证的NN姿态估计器。通过NN可达性分析扩展到杂乱环境，设计认证物体检测器，最后整合检测器和估计器形成多阶段感知流程。

Result: 在合成和真实图像数据上进行了评估，证明了该框架能够有效地估计交通标志的姿态，并符合框架提供的认证边界。

Conclusion: 所提出的框架能够为自动驾驶系统的视觉姿态估计提供可证明的正确性保证，并且能够推广到杂乱的环境中。

Abstract: We consider the problem of vision-based pose estimation for autonomous systems. While deep neural networks have been successfully used for vision-based tasks, they inherently lack provable guarantees on the correctness of their output, which is crucial for safety-critical applications. We present a framework for designing certifiable neural networks (NNs) for perception-based pose estimation that integrates physics-driven modeling with learning-based estimation. The proposed framework begins by leveraging the known geometry of planar objects commonly found in the environment, such as traffic signs and runway markings, referred to as target objects. At its core, it introduces a geometric generative model (GGM), a neural-network-like model whose parameters are derived from the image formation process of a target object observed by a camera. Once designed, the GGM can be used to train NN-based pose estimators with certified guarantees in terms of their estimation errors. We first demonstrate this framework in uncluttered environments, where the target object is the only object present in the camera's field of view. We extend this using ideas from NN reachability analysis to design certified object NN that can detect the presence of the target object in cluttered environments. Subsequently, the framework consolidates the certified object detector with the certified pose estimator to design a multi-stage perception pipeline that generalizes the proposed approach to cluttered environments, while maintaining its certified guarantees. We evaluate the proposed framework using both synthetic and real images of various planar objects commonly encountered by autonomous vehicles. Using images captured by an event-based camera, we show that the trained encoder can effectively estimate the pose of a traffic sign in accordance with the certified bound provided by the framework.

</details>


### [357] [Delay-Compensated Stiffness Estimation for Robot-Mediated Dyadic Interaction](https://arxiv.org/abs/2601.17812)
*Mingtian Du,Suhas Raghavendra Kulkarni,Bernardo Noronha,Domenico Campolo*

Main category: cs.RO

TL;DR: 提出一种新的机器人辅助人机交互中考虑网络延迟的阻抗估计方法，通过代数估计器和归一化加权最小二乘法实现高精度阻抗评估。


<details>
  <summary>Details</summary>
Motivation: 现有机器人辅助物理治疗中，由于网络延迟导致医生难以准确感知患者的阻抗（硬度），影响治疗效果。

Method: 推导了一种基于准静态平衡的代数估计器，明确考虑了输入和响应信号的时间对齐以补偿延迟。此外，引入归一化加权最小二乘法（NWLS）来鲁棒地过滤因代数推导产生的动态偏差。

Result: 实验证明，所提出的方法在引入不同网络延迟的情况下，相比于标准估计器，能够显著提高阻抗估计的准确性，并保持一致的跟踪精度。

Conclusion: 该方法为实现远程人机交互中的高保真力反馈感知提供了一个有前景的解决方案，有望在远程治疗环境中实现可靠的阻抗评估。

Abstract: Robot-mediated human-human (dyadic) interactions enable therapists to provide physical therapy remotely, yet an accurate perception of patient stiffness remains challenging due to network-induced haptic delays. Conventional stiffness estimation methods, which neglect delay, suffer from temporal misalignment between force and position signals, leading to significant estimation errors as delays increase. To address this, we propose a robust, delay-compensated stiffness estimation framework by deriving an algebraic estimator based on quasi-static equilibrium that explicitly accounts for temporally aligning the expert's input with the novice's response. A Normalised Weighted Least Squares (NWLS) implementation is then introduced to robustly filter dynamic bias resulting from the algebraic derivation. Experiments using commercial rehabilitation robots (H-MAN) as the platform demonstrate that the proposed method significantly outperforms the standard estimator, maintaining consistent tracking accuracy under multiple introduced delays. These findings offer a promising solution for achieving high-fidelity haptic perception in remote dyadic interaction, potentially facilitating reliable stiffness assessment in therapeutic settings across networks.

</details>


### [358] [Less Is More: Scalable Visual Navigation from Limited Data](https://arxiv.org/abs/2601.17815)
*Yves Inglin,Jonas Frey,Changan Chen,Marco Hutter*

Main category: cs.RO

TL;DR: 本研究提出了一种名为LiMo的Transformer模型，通过结合少量人类演示和几何规划器生成的合成轨迹来训练机器人进行视觉导航，从而提高了性能并减少了对大量专家演示的依赖。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在机器人视觉导航中很有效，但其性能高度依赖于训练数据的质量和多样性。收集大量高质量的人类演示成本高昂且不切实际。

Method: 研究者利用经典的几何规划器生成合成轨迹，以补充有限的人类演示。他们训练了一个名为LiMo的基于Transformer的策略，该策略可以从单一RGB图像预测目标条件下的SE(2)轨迹。通过消融实验和定性/定量分析来评估数据集规模和多样性对规划性能的影响。

Result: 将专家演示与规划器生成的监督相结合，可以显著提高视觉导航策略的性能。研究表明，数据集的规模和多样性会影响规划性能。

Conclusion: 通过策略性地策划多样化、高质量的数据集，并结合几何规划器生成的合成数据，可以实现高效的视觉导航，而无需仅仅依赖大量的专家演示。这种方法为实现可扩展、特定于具身条件的几何监督提供了一条实用的途径。

Abstract: Imitation learning provides a powerful framework for goal-conditioned visual navigation in mobile robots, enabling obstacle avoidance while respecting human preferences and social norms. However, its effectiveness depends critically on the quality and diversity of training data. In this work, we show how classical geometric planners can be leveraged to generate synthetic trajectories that complement costly human demonstrations. We train Less is More (LiMo), a transformer-based visual navigation policy that predicts goal-conditioned SE(2) trajectories from a single RGB observation, and find that augmenting limited expert demonstrations with planner-generated supervision yields substantial performance gains. Through ablations and complementary qualitative and quantitative analyses, we characterize how dataset scale and diversity affect planning performance. We demonstrate real-robot deployment and argue that robust visual navigation is enabled not by simply collecting more demonstrations, but by strategically curating diverse, high-quality datasets. Our results suggest that scalable, embodiment-specific geometric supervision is a practical path toward data-efficient visual navigation.

</details>


### [359] [NeuroManip: Prosthetic Hand Manipulation System Based on EMG and Eye Tracking Powered by the Neuromorphic Processor AltAi](https://arxiv.org/abs/2601.17991)
*Roman Akinshin,Elizaveta Lopatina,Kirill Bogatikov,Nikolai Kiz,Anna V. Makarova,Mikhail Lebedev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou,Valerii Kangler*

Main category: cs.RO

TL;DR: 本文提出了一种结合表面肌电图（sEMG）和目光引导计算机视觉的新型神经形态上肢假肢控制架构。该系统使用部署在神经形态处理器 AltAi 上的脉冲神经网络实时分类 EMG 模式，并通过眼动追踪头戴设备和场景相机识别用户关注的对象。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够实现节能、可靠且安全的上肢假肢控制系统，以提高截肢患者在日常活动中的安全性和可用性。

Method: 将用于 GPU 的 EMG 识别模型部署为 AltAi 上的脉冲网络，结合眼动追踪和计算机视觉识别目标物体，从而限制可用的手势选择空间。

Result: 在亚瓦特功耗下实现了与传统 GPU 相当的 EMG 模式识别精度。对于六种上肢残疾人的功能性手势，系统识别性能与最先进的肌电接口相当。当视觉信息将决策空间限制为三个与当前观看物体相关的合适手势时，识别精度提高到约 95%，并排除了不安全的手势。

Conclusion: 提出的神经形态、上下文感知控制器能够实现节能且可靠的假肢控制，并有潜力提高截肢患者在日常活动中的安全性和可用性。

Abstract: This paper presents a novel neuromorphic control architecture for upper-limb prostheses that combines surface electromyography (sEMG) with gaze-guided computer vision. The system uses a spiking neural network deployed on the neuromorphic processor AltAi to classify EMG patterns in real time while an eye-tracking headset and scene camera identify the object within the user's focus. In our prototype, the same EMG recognition model that was originally developed for a conventional GPU is deployed as a spiking network on AltAi, achieving comparable accuracy while operating in a sub-watt power regime, which enables a lightweight, wearable implementation. For six distinct functional gestures recorded from upper-limb amputees, the system achieves robust recognition performance comparable to state-of-the-art myoelectric interfaces. When the vision pipeline restricts the decision space to three context-appropriate gestures for the currently viewed object, recognition accuracy increases to roughly 95% while excluding unsafe, object-inappropriate grasps. These results indicate that the proposed neuromorphic, context-aware controller can provide energy-efficient and reliable prosthesis control and has the potential to improve safety and usability in everyday activities for people with upper-limb amputation.

</details>


### [360] [Grasp-and-Lift: Executable 3D Hand-Object Interaction Reconstruction via Physics-in-the-Loop Optimization](https://arxiv.org/abs/2601.18121)
*Byeonggyeol Choi,Woojin Oh,Jongwoo Lim*

Main category: cs.RO

TL;DR: 本文提出了一种在模拟器中循环精炼框架，将视觉上对齐的手部运动轨迹转换为物理上可行的轨迹，通过低维样条表示和CMA-ES优化器，在最大化物理成功的同时最小化与原始演示的偏差。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模手部运动数据集（如DexYCB和HO3D）在物理模拟器中重放时存在物理上不合理的问题，例如穿透、接触丢失和抓握不稳定。

Method: 将问题表述为可处理的黑盒优化问题，使用低维、基于样条的表示来参数化手部运动，并利用梯度无关优化器CMA-ES，将高保真物理引擎视为黑盒目标函数。

Result: 与MANIPTRANS等现有方法相比，本文方法在重放时实现了更低的手和物体位姿误差，并更准确地恢复了手-物体的物理交互。

Conclusion: 该方法提供了一种通用且可扩展的将视觉演示转换为物理上有效的轨迹的方法，能够生成高质量数据，支持鲁棒的策略学习。

Abstract: Dexterous hand manipulation increasingly relies on large-scale motion datasets with precise hand-object trajectory data. However, existing resources such as DexYCB and HO3D are primarily optimized for visual alignment but often yield physically implausible interactions when replayed in physics simulators, including penetration, missed contact, and unstable grasps.
  We propose a simulation-in-the-loop refinement framework that converts these visually aligned trajectories into physically executable ones. Our core contribution is to formulate this as a tractable black-box optimization problem. We parameterize the hand's motion using a low-dimensional, spline-based representation built on sparse temporal keyframes. This allows us to use a powerful gradient-free optimizer, CMA-ES, to treat the high-fidelity physics engine as a black-box objective function. Our method finds motions that simultaneously maximize physical success (e.g., stable grasp and lift) while minimizing deviation from the original human demonstration.
  Compared to MANIPTRANS-recent transfer pipelines, our approach achieves lower hand and object pose errors during replay and more accurately recovers hand-object physical interactions. Our approach provides a general and scalable method for converting visual demonstrations into physically valid trajectories, enabling the generation of high-fidelity data crucial for robust policy learning.

</details>


### [361] [Quest2ROS2: A ROS 2 Framework for Bi-manual VR Teleoperation](https://arxiv.org/abs/2601.18289)
*Jialong Li,Zhenguo Wang,Tianci Wang,Maj Stenmark,Volker Krueger*

Main category: cs.RO

TL;DR: Quest2ROS2是一个开源的ROS2双臂遥操作框架，通过基于相对运动的控制克服了工作空间限制，支持“并排”和“镜像”两种控制模式，并集成了可视化、夹爪控制和暂停重置等功能，以扩展机器人数据收集能力。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为了克服传统机器人遥操作在工作空间上的限制，并提高机器人数据收集的可扩展性，同时提供更直观、用户友好的操作体验。

Method: 该框架通过计算VR控制器姿态变化来确定机器人运动，实现了基于相对运动的控制，从而摆脱了绝对姿态的限制。它采用了模块化架构，支持“并排”和“镜像”两种控制模式，并集成了RViz可视化、夹爪控制和暂停重置等功能。

Result: Quest2ROS2成功实现了双臂的直观、姿态无关的遥操作，克服了工作空间限制。框架的模块化设计支持不同的控制模式，提高了操作体验。

Conclusion: Quest2ROS2提供了一个可扩展、易用且安全的ROS2双臂遥操作框架，通过相对运动控制有效解决了工作空间限制问题，为机器人数据收集和多样化操作平台提供了解决方案。

Abstract: Quest2ROS2 is an open-source ROS2 framework for bi-manual teleoperation designed to scale robot data collection. Extending Quest2ROS, it overcomes workspace limitations via relative motion-based control, calculating robot movement from VR controller pose changes to enable intuitive, pose-independent operation. The framework integrates essential usability and safety features, including real-time RViz visualization, streamlined gripper control, and a pause-and-reset function for smooth transitions. We detail a modular architecture that supports "Side-by-Side" and "Mirror" control modes to optimize operator experience across diverse platforms. Code is available at: https://github.com/Taokt/Quest2ROS2.

</details>


### [362] [TC-IDM: Grounding Video Generation for Executable Zero-shot Robot Motion](https://arxiv.org/abs/2601.18323)
*Weishi Mi,Yong Bao,Xiaowei Chi,Xiaozhu Ju,Zhiyuan Qin,Kuangzhi Ge,Kai Tang,Peidong Jia,Shanghang Zhang,Jian Tang*

Main category: cs.RO

TL;DR: 提出了一种名为TC-IDM的工具中心逆动力学模型，用于弥合生成式世界模型中像素级规划与机器人可执行动作之间的差距，并在现实世界评估中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）范式在机器人控制方面表现强大，但对大规模、高质量机器人数据的依赖限制了其泛化能力。生成式世界模型是一个有前景的方向，但其像素级规划与物理可执行动作之间存在关键差距。

Method: TC-IDM通过关注世界模型生成的工具轨迹，利用分割和3D运动估计从生成视频中提取工具点云轨迹。采用解耦的动作头将规划好的轨迹投影到6-DoF末端执行器运动和相应的控制信号。

Result: 在现实世界评估中，使用TC-IDM的世界模型取得了61.11%的平均成功率，简单任务上为77.7%，零样本可变形物体任务上为38.46%。该模型在长时域和分布外任务上表现出强大的泛化能力，并显著优于端到端VLA基线和其他逆动力学模型。

Conclusion: TC-IDM提出的“规划-翻译”范式能够支持多种末端执行器，提高视点不变性，并在长时域和分布外任务上表现出强大的泛化能力，有效解决了生成式世界模型在机器人控制中的关键挑战。

Abstract: The vision-language-action (VLA) paradigm has enabled powerful robotic control by leveraging vision-language models, but its reliance on large-scale, high-quality robot data limits its generalization. Generative world models offer a promising alternative for general-purpose embodied AI, yet a critical gap remains between their pixel-level plans and physically executable actions.
  To this end, we propose the Tool-Centric Inverse Dynamics Model (TC-IDM). By focusing on the tool's imagined trajectory as synthesized by the world model, TC-IDM establishes a robust intermediate representation that bridges the gap between visual planning and physical control.
  TC-IDM extracts the tool's point cloud trajectories via segmentation and 3D motion estimation from generated videos. Considering diverse tool attributes, our architecture employs decoupled action heads to project these planned trajectories into 6-DoF end-effector motions and corresponding control signals.
  This plan-and-translate paradigm not only supports a wide range of end-effectors but also significantly improves viewpoint invariance. Furthermore, it exhibits strong generalization capabilities across long-horizon and out-of-distribution tasks, including interacting with deformable objects.
  In real-world evaluations, the world model with TC-IDM achieves an average success rate of 61.11 percent, with 77.7 percent on simple tasks and 38.46 percent on zero-shot deformable object tasks. It substantially outperforms end-to-end VLA-style baselines and other inverse dynamics models.

</details>


### [363] [SG-CADVLM: A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation](https://arxiv.org/abs/2601.18442)
*Hongyi Zhao,Shuo Wang,Qijie He,Ziyuan Pu*

Main category: cs.RO

TL;DR: 本文提出了一种名为SG-CADVLM的框架，该框架利用上下文感知解码和多模态输入处理，从事故报告和道路网络图生成安全关键场景，以解决现有方法在生成逼真且多样化的自动驾驶安全测试场景方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车的安全验证需要测试关键安全场景，但这些场景在现实世界中很少发生，且测试成本高昂。事故报告是关键安全事件的真实规格，但现有方法在生成多样化和逼真场景方面存在局限性（数据驱动方法缺乏多样性，对抗性方法缺乏物理保真度，LLM/VLM方法存在上下文抑制问题）。

Method: 提出SG-CADVLM框架，结合了上下文感知解码（Context-Aware Decoding）和多模态输入处理（结合事故报告和道路网络图）。该方法旨在缓解VLM的幻觉问题，并能够同时生成道路几何和车辆轨迹。

Result: SG-CADVLM生成关键风险场景的比例达到84.4%，远高于基线方法的12.5%（提高了469%）。生成的场景可以用于自动驾驶测试的可执行模拟。

Conclusion: SG-CADVLM框架能够有效地从事故报告和道路网络图生成安全关键场景，解决了现有方法的不足，提高了场景生成的逼真度和多样性，为自动驾驶安全验证提供了有效的解决方案。

Abstract: Autonomous vehicle safety validation requires testing on safety-critical scenarios, but these events are rare in real-world driving and costly to test due to collision risks. Crash reports provide authentic specifications of safety-critical events, offering a vital alternative to scarce real-world collision trajectory data. This makes them valuable sources for generating realistic high-risk scenarios through simulation. Existing approaches face significant limitations because data-driven methods lack diversity due to their reliance on existing latent distributions, whereas adversarial methods often produce unrealistic scenarios lacking physical fidelity. Large Language Model (LLM) and Vision Language Model (VLM)-based methods show significant promise. However, they suffer from context suppression issues where internal parametric knowledge overrides crash specifications, producing scenarios that deviate from actual accident characteristics. This paper presents SG-CADVLM (A Context-Aware Decoding Powered Vision Language Model for Safety-Critical Scenario Generation), a framework that integrates Context-Aware Decoding with multi-modal input processing to generate safety-critical scenarios from crash reports and road network diagrams. The framework mitigates VLM hallucination issues while enabling the simultaneous generation of road geometry and vehicle trajectories. The experimental results demonstrate that SG-CADVLM generates critical risk scenarios at a rate of 84.4% compared to 12.5% for the baseline methods, representing an improvement of 469%, while producing executable simulations for autonomous vehicle testing.

</details>


### [364] [DV-VLN: Dual Verification for Reliable LLM-Based Vision-and-Language Navigation](https://arxiv.org/abs/2601.18492)
*Zijun Li,Shijie Li,Zhenxi Zhang,Bin Li,Shoujun Zhou*

Main category: cs.RO

TL;DR: 本文提出了一种名为DV-VLN的新型视觉语言导航（VLN）框架，采用“生成-验证”范式，通过参数高效的LLaMA-2适应性调整，生成导航推理链，并利用真假验证（TFV）和掩码实体验证（MEV）两种互补方式来验证候选动作，从而提高在未知环境中的导航可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的VLN代理在面对多视角观察时，通常采用单次决策，容易因局部不匹配和中间推理不完善而偏离路径，导致错误累积，在未见过的环境中表现不佳。

Method: DV-VLN框架首先通过参数高效的领域内适应，将LLaMA-2模型调整用于生成结构化的导航推理链（chain-of-thought）。然后，利用两种方法验证候选动作：真假验证（TFV）和掩码实体验证（MEV）。最后，通过聚合多次验证成功的结果来选择动作，并提供可解释的分数进行重排序。

Result: 在R2R、RxR（英语子集）和REVERIE数据集上的实验表明，DV-VLN相比直接预测和仅采样基线模型，在性能上得到了一致的提升，在纯语言VLN代理中表现具有竞争力，并与一些跨模态系统相比取得了令人鼓舞的结果。

Conclusion: DV-VLN通过引入“生成-验证”范式，结合LLM的推理能力和多通道验证机制，有效克服了现有VLN代理的局限性，提高了导航的准确性和鲁棒性，为开发更可靠的语言驱动导航代理提供了新的思路。

Abstract: Vision-and-Language Navigation (VLN) requires an embodied agent to navigate in a complex 3D environment according to natural language instructions. Recent progress in large language models (LLMs) has enabled language-driven navigation with improved interpretability. However, most LLM-based agents still rely on single-shot action decisions, where the model must choose one option from noisy, textualized multi-perspective observations. Due to local mismatches and imperfect intermediate reasoning, such decisions can easily deviate from the correct path, leading to error accumulation and reduced reliability in unseen environments. In this paper, we propose DV-VLN, a new VLN framework that follows a generate-then-verify paradigm. DV-VLN first performs parameter-efficient in-domain adaptation of an open-source LLaMA-2 backbone to produce a structured navigational chain-of-thought, and then verifies candidate actions with two complementary channels: True-False Verification (TFV) and Masked-Entity Verification (MEV). DV-VLN selects actions by aggregating verification successes across multiple samples, yielding interpretable scores for reranking. Experiments on R2R, RxR (English subset), and REVERIE show that DV-VLN consistently improves over direct prediction and sampling-only baselines, achieving competitive performance among language-only VLN agents and promising results compared with several cross-modal systems.Code is available at https://github.com/PlumJun/DV-VLN.

</details>


### [365] [SKETCH: Semantic Key-Point Conditioning for Long-Horizon Vessel Trajectory Prediction](https://arxiv.org/abs/2601.18537)
*Linyong Gan,Zimo Li,Wenxin Xu,Xingjian Li,Jianhua Z. Huang,Enmei Tu,Shuhang Chen*

Main category: cs.RO

TL;DR: 提出了一种基于语义关键点（NKP）的轨迹预测框架，通过分解全局意图和局部运动，提高了船舶长期轨迹预测的准确性和方向一致性。


<details>
  <summary>Details</summary>
Motivation: 现有船舶长期轨迹预测方法难以处理复杂导航行为和环境因素引起的累积不确定性，容易导致预测轨迹漂移或不符合实际。

Method: 提出了一种语义关键点（NKP）条件下的轨迹建模框架，将长期预测分解为全局语义决策和局部运动建模。通过预训练-微调策略来估计NKP先验。

Result: 在真实AIS数据集上进行的实验表明，该方法在长期预测、方向准确性和精细轨迹预测方面优于现有最先进的方法。

Conclusion: 该语义关键点条件下的轨迹建模框架能够有效地限制未来轨迹的范围在语义上可行的子集中，从而显著提高船舶长期轨迹预测的性能。

Abstract: Accurate long-horizon vessel trajectory prediction remains challenging due to compounded uncertainty from complex navigation behaviors and environmental factors. Existing methods often struggle to maintain global directional consistency, leading to drifting or implausible trajectories when extrapolated over long time horizons. To address this issue, we propose a semantic-key-point-conditioned trajectory modeling framework, in which future trajectories are predicted by conditioning on a high-level Next Key Point (NKP) that captures navigational intent. This formulation decomposes long-horizon prediction into global semantic decision-making and local motion modeling, effectively restricting the support of future trajectories to semantically feasible subsets. To efficiently estimate the NKP prior from historical observations, we adopt a pretrain-finetune strategy. Extensive experiments on real-world AIS data demonstrate that the proposed method consistently outperforms state-of-the-art approaches, particularly for long travel durations, directional accuracy, and fine-grained trajectory prediction.

</details>


### [366] [Fast and Safe Trajectory Optimization for Mobile Manipulators With Neural Configuration Space Distance Field](https://arxiv.org/abs/2601.18548)
*Yulin Li,Zhiyuan Song,Yiming Li,Zhicheng Song,Kai Chen,Chunxin Zheng,Zhihai Bi,Jiahang Cao,Sylvain Calinon,Fan Shi,Jun Ma*

Main category: cs.RO

TL;DR: 本文提出了广义构型空间距离场（GCDF），将固定基底机械臂的构型空间距离场（CDF）扩展到移动机械臂，以解决在复杂、狭窄空间中进行全身轨迹优化的挑战，并提出了一种高效的顺序凸优化框架。


<details>
  <summary>Details</summary>
Motivation: 在杂乱、狭窄的空间中，移动机械臂的全身轨迹优化由于高维非凸性和快速准确的碰撞推理需求而变得困难。现有的CDF方法不适用于移动机械臂。

Method: 提出了广义构型空间距离场（GCDF），将其扩展到具有平移和旋转关节以及不受限工作空间的移动机械臂。开发了一个数据生成和训练流程，以生成具有准确值和梯度的连续神经网络GCDF。在此基础上，开发了一个高性能的顺序凸优化框架，利用GCDF进行碰撞推理，并通过在线指定神经网络约束、稀疏感知主动集检测和增量约束管理来提高效率和可扩展性。

Result: GCDF保留了欧几里得般的局部距离结构，并准确地在构型空间中编码了全身几何。提出的优化框架能够处理大量隐式约束，并支持在场景变化下进行快速重新规划。

Conclusion: GCDF为移动机械臂的轨迹优化提供了一种有效的方法，可以处理复杂环境和紧密的基底-手臂耦合。所提出的优化框架能够高效地解决高维、约束密集型问题。

Abstract: Mobile manipulators promise agile, long-horizon behavior by coordinating base and arm motion, yet whole-body trajectory optimization in cluttered, confined spaces remains difficult due to high-dimensional nonconvexity and the need for fast, accurate collision reasoning. Configuration Space Distance Fields (CDF) enable fixed-base manipulators to model collisions directly in configuration space via smooth, implicit distances. This representation holds strong potential to bypass the nonlinear configuration-to-workspace mapping while preserving accurate whole-body geometry and providing optimization-friendly collision costs. Yet, extending this capability to mobile manipulators is hindered by unbounded workspaces and tighter base-arm coupling. We lift this promise to mobile manipulation with Generalized Configuration Space Distance Fields (GCDF), extending CDF to robots with both translational and rotational joints in unbounded workspaces with tighter base-arm coupling. We prove that GCDF preserves Euclidean-like local distance structure and accurately encodes whole-body geometry in configuration space, and develop a data generation and training pipeline that yields continuous neural GCDFs with accurate values and gradients, supporting efficient GPU-batched queries. Building on this representation, we develop a high-performance sequential convex optimization framework centered on GCDF-based collision reasoning. The solver scales to large numbers of implicit constraints through (i) online specification of neural constraints, (ii) sparsity-aware active-set detection with parallel batched evaluation across thousands of constraints, and (iii) incremental constraint management for rapid replanning under scene changes.

</details>


### [367] [Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation](https://arxiv.org/abs/2601.18569)
*Seokju Lee,Kyung-Soo Kim*

Main category: cs.RO

TL;DR: 提出了一种名为AttenNKF的注意力机制增强的神经卡尔曼滤波器，用于腿足机器人的状态估计，通过估计和补偿由足部打滑引起的状态误差，在打滑条件下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 足部打滑是腿足机器人状态估计误差的主要来源，因为它违反了无滑动的假设，在更新步骤中引入偏差。

Method: 提出了一种AttenNKF，它将一个不变扩展卡尔曼滤波器（InEKF）与一个使用注意力机制的神经网络补偿器相结合。该补偿器在推断足部打滑严重性相关的误差后，将其作为后更新补偿应用于InEKF状态。补偿器在潜在空间中进行训练，以提高对输入尺度的鲁棒性并促进结构化的打滑补偿。

Result: 实验证明，AttenNKF在腿足机器人状态估计方面表现出优越的性能，尤其是在容易发生足部打滑的条件下，优于现有的状态估计器。

Conclusion: AttenNKF通过有效估计和补偿足部打滑引起的误差，提高了腿足机器人的状态估计精度，特别是在复杂的运动场景下。

Abstract: In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions.

</details>


### [368] [ExoGS: A 4D Real-to-Sim-to-Real Framework for Scalable Manipulation Data Collection](https://arxiv.org/abs/2601.18629)
*Yiming Wang,Ruogu Zhang,Minyang Li,Hao Shi,Junbo Wang,Deyi Li,Jieji Ren,Wenhai Liu,Weiming Wang,Hao-Shu Fang*

Main category: cs.RO

TL;DR: 提出了一种名为 ExoGS 的机器人无关的 4D 实景-仿真-实景框架，用于捕获真实世界的静态环境和动态交互，并将其无缝传输到仿真环境中，以解决现有方法忽略交互传递的问题，从而提高数据收集的可扩展性和策略学习效率。


<details>
  <summary>Details</summary>
Motivation: 现有实景-仿真-实景技术主要关注环境级别的视觉转移，忽略了交互的转移，而交互对于接触丰富的任务来说，在仿真中难以获得且效率低下。因此，需要一种能够同时转移环境和交互的新方法。

Method: ExoGS 使用一个名为 AirExo-3 的被动外骨骼来捕获人类演示过程中的运动学一致轨迹和同步 RGB 图像。然后，将机器人、物体和环境重建为可编辑的 3D 高斯溅射（Gaussian Splatting）资产。此外，引入了一个轻量级的 Mask Adapter，将实例级别的语义注入到策略中，以提高在视觉领域变化下的鲁棒性。

Result: 与基于遥操作的基线方法相比，ExoGS 在数据效率和策略泛化能力方面均有显著提升。实验证明了该框架在可扩展数据收集和策略学习方面的有效性。

Conclusion: ExoGS 提供了一种新颖的解决方案，通过捕获和转移真实世界的环境和交互，显著提高了机器人操纵任务中数据收集的可扩展性和策略学习的效率，并增强了策略在视觉域变化下的泛化能力。

Abstract: Real-to-Sim-to-Real technique is gaining increasing interest for robotic manipulation, as it can generate scalable data in simulation while having narrower sim-to-real gap. However, previous methods mainly focused on environment-level visual real-to-sim transfer, ignoring the transfer of interactions, which could be challenging and inefficient to obtain purely in simulation especially for contact-rich tasks. We propose ExoGS, a robot-free 4D Real-to-Sim-to-Real framework that captures both static environments and dynamic interactions in the real world and transfers them seamlessly to a simulated environment. It provides a new solution for scalable manipulation data collection and policy learning. ExoGS employs a self-designed robot-isomorphic passive exoskeleton AirExo-3 to capture kinematically consistent trajectories with millimeter-level accuracy and synchronized RGB observations during direct human demonstrations. The robot, objects, and environment are reconstructed as editable 3D Gaussian Splatting assets, enabling geometry-consistent replay and large-scale data augmentation. Additionally, a lightweight Mask Adapter injects instance-level semantics into the policy to enhance robustness under visual domain shifts. Real-world experiments demonstrate that ExoGS significantly improves data efficiency and policy generalization compared to teleoperation-based baselines. Code and hardware files have been released on https://github.com/zaixiabalala/ExoGS.

</details>


### [369] [Constraint-Aware Discrete-Time PID Gain Optimization for Robotic Joint Control Under Actuator Saturation](https://arxiv.org/abs/2601.18639)
*Ojasva Mishra,Xiaolong Wu,Min Xu*

Main category: cs.RO

TL;DR: 本文提出了一种考虑实际执行因素（离散时间、饱和、延迟和测量不确定性）的饱和离散时间关节控制器的分析和调优工作流程，通过 Jury 判据推导 PI 稳定性区域，评估反绕组实现，并引入混合认证的贝叶斯优化来提高鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 实际的 PID 控制器在执行过程中会因离散时间、执行器饱和、延迟和测量不确定性等因素而偏离连续时间理论，因此需要一种考虑这些因素的实现感知分析和调优方法。

Method: 1. 使用 Jury 判据推导欧拉和零阶保持离散化下的 PI 稳定性区域。2. 评估饱和占优下的离散反计算抗饱和算法。3. 提出混合认证的贝叶斯优化工作流程，该流程在优化稳健 IAE 目标的同时，能够筛除不稳定候选和不安全的瞬态。

Result: 在考虑不确定性、延迟、噪声、量化和更严格饱和的模型家族下，鲁棒性调优将中位数 IAE 从 0.843 提高到 0.430，并将中位数超调量保持在 2% 以下。仿真调优中的认证筛选在进行完整鲁棒性评估前，会拒绝 11.6% 的随机采样增益，提高了样本效率。

Conclusion: 所提出的实现感知分析和调优工作流程能够有效地处理实际执行中的非理想因素，显著提高饱和离散时间关节控制器的性能和鲁棒性，并且通过认证筛选提高了调优效率。

Abstract: The precise regulation of rotary actuation is fundamental in autonomous robotics, yet practical PID loops deviate from continuous-time theory due to discrete-time execution, actuator saturation, and small delays and measurement imperfections. We present an implementation-aware analysis and tuning workflow for saturated discrete-time joint control. We (i) derive PI stability regions under Euler and exact zero-order-hold (ZOH) discretizations using the Jury criterion, (ii) evaluate a discrete back-calculation anti-windup realization under saturation-dominant regimes, and (iii) propose a hybrid-certified Bayesian optimization workflow that screens analytically unstable candidates and behaviorally unsafe transients while optimizing a robust IAE objective with soft penalties on overshoot and saturation duty. Baseline sweeps ($τ=1.0$~s, $Δt=0.01$~s, $u\in[-10,10]$) quantify rise/settle trends for P/PI/PID. Under a randomized model family emulating uncertainty, delay, noise, quantization, and tighter saturation, robustness-oriented tuning improves median IAE from $0.843$ to $0.430$ while keeping median overshoot below $2\%$. In simulation-only tuning, the certification screen rejects $11.6\%$ of randomly sampled gains within bounds before full robust evaluation, improving sample efficiency without hardware experiments.

</details>


### [370] [A Pragmatic VLA Foundation Model](https://arxiv.org/abs/2601.18692)
*Wei Wu,Fan Lu,Yunnan Wang,Shuai Yang,Shi Liu,Fangjing Wang,Qian Zhu,He Sun,Yong Wang,Shuailei Ma,Yiyu Ren,Kejia Zhang,Hui Yu,Jingmei Zhao,Shuai Zhou,Zhenqi Qiu,Houlong Xiong,Ziyu Wang,Zechen Wang,Ran Cheng,Yong-Lu Li,Yongtao Huang,Xing Zhu,Yujun Shen,Kecheng Zheng*

Main category: cs.RO

TL;DR: 本文提出了LingBot-VLA，一个在大量真实世界机器人数据上训练的视觉-语言-动作（VLA）基础模型，在多平台和多任务测试中表现优于现有模型，并提供高效的代码库和开源资源以推动机器人学习领域的发展。


<details>
  <summary>Details</summary>
Motivation: 为了构建一个能够跨任务和平台泛化，同时保证成本效益（数据和GPU小时数）的机器人操作VLA基础模型。

Method: 使用约20,000小时的真实世界数据，在9种常见的双臂机器人配置上训练LingBot-VLA模型。并在3个机器人平台上，对每个平台上的100个任务进行了130次训练后测试，以评估模型的性能和泛化能力。同时，开发了一个高效的代码库。

Result: LingBot-VLA在测试中展现出超越竞争对手的性能和广泛的泛化能力。所开发的高效代码库在8-GPU设置下可达261个样本/秒/GPU的吞吐量，比现有VLA代码库快1.5~2.8倍。

Conclusion: LingBot-VLA模型及其高效的代码库非常适合实际部署。为了促进机器人学习领域的发展，本文开源了代码、基础模型和基准数据集，旨在支持更具挑战性的任务和健全的评估标准。

Abstract: Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8$\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.

</details>


### [371] [Trustworthy Evaluation of Robotic Manipulation: A New Benchmark and AutoEval Methods](https://arxiv.org/abs/2601.18723)
*Mengyuan Liu,Juyi Sheng,Peiming Li,Ziyi Wang,Tianming Xu,Tiantian Xu,Hong Liu*

Main category: cs.RO

TL;DR: 本文提出了一种结合Eval-Actions基准和AutoEval架构的机器人模仿学习评估方法，以解决现有评估方法在区分真实策略行为、执行质量以及信任度方面存在的不足。Eval-Actions包含策略执行和人类遥操作数据，并引入了专家评分、排序偏好和思维链等监督信号。AutoEval通过时空聚合和运动学校准信号来评估语义和运动平滑度，AutoEval Plus则进一步增强了逻辑推理能力。实验表明，该方法在区分策略生成和遥操作视频方面表现出色，并能有效衡量策略的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前机器人模仿学习的评估方法主要依赖二元成功率，无法有效衡量策略行为的信任度，特别是无法区分真实策略行为与人类遥操作，也无法量化执行质量（如平滑度和安全性）。

Method: 1. 构建Eval-Actions基准：包含VA和VLA策略执行轨迹以及人类遥操作数据，并包含失败场景。引入专家评分(EG)、排序偏好(RG)和思维链(CoT)作为监督信号。2. 提出AutoEval架构：利用时空聚合进行语义评估，并辅以运动学校准信号来优化运动平滑度。3. 提出AutoEval Plus (AutoEval-P)：集成GRPO范式以增强逻辑推理能力。

Result: AutoEval在EG和RG协议下分别实现了0.81和0.84的Spearman秩相关系数。该框架在区分策略生成和遥操作视频方面达到了99.6%的准确率。

Conclusion: 所提出的Eval-Actions基准和AutoEval架构为机器人模仿学习的信任度评估提供了一个更严格的标准，能够有效区分策略行为的来源，并衡量执行质量，从而推动了机器人信任度评估领域的发展。

Abstract: Driven by the rapid evolution of Vision-Action and Vision-Language-Action models, imitation learning has significantly advanced robotic manipulation capabilities. However, evaluation methodologies have lagged behind, hindering the establishment of Trustworthy Evaluation for these behaviors. Current paradigms rely on binary success rates, failing to address the critical dimensions of trust: Source Authenticity (i.e., distinguishing genuine policy behaviors from human teleoperation) and Execution Quality (e.g., smoothness and safety). To bridge these gaps, we propose a solution that combines the Eval-Actions benchmark and the AutoEval architecture. First, we construct the Eval-Actions benchmark to support trustworthiness analysis. Distinct from existing datasets restricted to successful human demonstrations, Eval-Actions integrates VA and VLA policy execution trajectories alongside human teleoperation data, explicitly including failure scenarios. This dataset is structured around three core supervision signals: Expert Grading (EG), Rank-Guided preferences (RG), and Chain-of-Thought (CoT). Building on this, we propose the AutoEval architecture: AutoEval leverages Spatio-Temporal Aggregation for semantic assessment, augmented by an auxiliary Kinematic Calibration Signal to refine motion smoothness; AutoEval Plus (AutoEval-P) incorporates the Group Relative Policy Optimization (GRPO) paradigm to enhance logical reasoning capabilities. Experiments show AutoEval achieves Spearman's Rank Correlation Coefficients (SRCC) of 0.81 and 0.84 under the EG and RG protocols, respectively. Crucially, the framework possesses robust source discrimination capabilities, distinguishing between policy-generated and teleoperated videos with 99.6% accuracy, thereby establishing a rigorous standard for trustworthy robotic evaluation. Our project and code are available at https://term-bench.github.io/.

</details>


### [372] [Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge](https://arxiv.org/abs/2601.18733)
*Li Kang,Heng Zhou,Xiufeng Song,Rui Li,Bruno N. Y. Chen,Ziye Wang,Ximeng Meng,Stone Tao,Yiran Qin,Xiaohong Liu,Ruimao Zhang,Lei Bai,Yilun Du,Hao Su,Philip Torr,Zhenfei Yin,Ruihao Gong,Yejun Zeng,Fengjun Zhong,Shenghao Jin,Jinyang Guo,Xianglong Liu,Xiaojun Jia,Tianqi Shan,Wenqi Ren,Simeng Qin,Jialing Yang,Xiaoyu Ma,Tianxing Chen,Zixuan Li,Zijian Cai,Yan Qin,Yusen Qin,Qiangyu Chen,Kaixuan Wang,Zhaoming Han,Yao Mu,Ping Luo,Yuanqi Yao,Haoming Song,Jan-Nico Zaech,Fabien Despinoy,Danda Pani Paudel,Luc Van Gool*

Main category: cs.RO

TL;DR: 本文提出了 MARS 挑战赛，旨在促进多智能体系统在具身 AI 领域的进步，特别是在规划和控制方面，利用视觉语言模型实现多智能体协调和机器人操作。


<details>
  <summary>Details</summary>
Motivation: 随着具身 AI 向更复杂的任务场景发展，多智能体系统框架对于实现可扩展、高效和协作的解决方案变得至关重要。这主要由智能体能力增强、任务委派提高系统效率以及实现高级人机交互这三个因素驱动。

Method: 本文提出了 MARS 挑战赛，重点关注规划和控制两个关键领域。参赛者利用视觉语言模型（VLMs）探索多智能体具身规划，以协调任务和策略执行，在动态环境中进行机器人操作。

Result: 通过评估参赛者提交的解决方案，挑战赛为设计和协调具身多智能体系统提供了宝贵的见解。

Conclusion: MARS 挑战赛的设立及其评估过程，为未来高级协作 AI 系统的发展做出了贡献，特别是在具身 AI 的多智能体协作规划与控制方面。

Abstract: Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems.

</details>


### [373] [Goal-oriented Communication for Fast and Robust Robotic Fault Detection and Recovery](https://arxiv.org/abs/2601.18765)
*Shutong Chen,Adnan Aijaz,Yansha Deng*

Main category: cs.RO

TL;DR: 提出了一种新的面向目标通信（GoC）框架，通过联合设计通信-计算-控制（3C）环路来优化机器人故障检测与恢复（FDR）的低延迟和鲁棒性。该框架利用3D场景图（3D-SG）进行故障检测，并微调小型语言模型（SLM）结合数字孪生技术进行故障恢复。


<details>
  <summary>Details</summary>
Motivation: 现有机器人FDR框架存在通信和计算延迟大、机器人运动生成不可靠等问题，因为3C环路设计未考虑FDR目标。

Method: 提出GoC框架，联合设计3C环路以最小化FDR时间并最大化任务成功率。故障检测利用3D场景图（3D-SG）的语义表示，通过监测空间关系变化来识别故障。故障恢复则通过LoRA微调SLM，并利用知识蒸馏增强其推理和泛化能力，生成恢复动作。此外，设计了轻量级的面向目标的数字孪生重建模块来精细化恢复动作。

Result: GoC框架相比现有框架，FDR时间最多可减少82.6%，任务成功率最多可提高76%。

Conclusion: GoC框架能够显著提高机器人FDR的效率和鲁棒性，优于依赖视觉语言模型进行故障检测和大型语言模型进行故障恢复的现有方法。

Abstract: Autonomous robotic systems are widely deployed in smart factories and operate in dynamic, uncertain, and human-involved environments that require low-latency and robust fault detection and recovery (FDR). However, existing FDR frameworks exhibit various limitations, such as significant delays in communication and computation, and unreliability in robot motion/trajectory generation, mainly because the communication-computation-control (3C) loop is designed without considering the downstream FDR goal. To address this, we propose a novel Goal-oriented Communication (GoC) framework that jointly designs the 3C loop tailored for fast and robust robotic FDR, with the goal of minimising the FDR time while maximising the robotic task (e.g., workpiece sorting) success rate. For fault detection, our GoC framework innovatively defines and extracts the 3D scene graph (3D-SG) as the semantic representation via our designed representation extractor, and detects faults by monitoring spatial relationship changes in the 3D-SG. For fault recovery, we fine-tune a small language model (SLM) via Low-Rank Adaptation (LoRA) and enhance its reasoning and generalization capabilities via knowledge distillation to generate recovery motions for robots. We also design a lightweight goal-oriented digital twin reconstruction module to refine the recovery motions generated by the SLM when fine-grained robotic control is required, using only task-relevant object contours for digital twin reconstruction. Extensive simulations demonstrate that our GoC framework reduces the FDR time by up to 82.6% and improves the task success rate by up to 76%, compared to the state-of-the-art frameworks that rely on vision language models for fault detection and large language models for fault recovery.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [374] [Set-Based Reachability for Low-Thrust Spacecraft in Two-Body and Cislunar Dynamical Systems](https://arxiv.org/abs/2601.17155)
*Jinaykumar Patel,Kamesh Subbarao*

Main category: eess.SY

TL;DR: 本文研究了基于区域图（zonotope）的可达性分析方法在低推力航天器任务中的应用，考虑了二体和三体（月地）动力学环境，并将其应用于轨道转移和轨道保持。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为了应对低推力航天器在复杂动力学环境（如二体和月地三体问题）下，其可达集合的分析和安全轨迹生成问题。

Method: 该研究采用基于集合的方法，利用泰勒展开近似非线性系统，并结合状态相关系数（SDC）参数化将非线性动力学转化为伪线性形式，从而能够高效地传播可达集合。此外，还探讨了模型预测控制（MPC）和LQR控制在轨道保持方面的应用。

Result: 研究生成了二体和月地三体动力学下的可达集合，并将其应用于地球-火星转移轨道、地月L1/L2晕轨道以及近乎直线晕轨道（NRHOs）等场景。比较了MPC和LQR控制在轨道保持任务下的性能。

Conclusion: 提出的基于区域图的可达性分析方法为分析航天器在复杂动力学和控制约束下的行为提供了一个可扩展的框架，能够有效地用于安全轨迹生成和跟踪。

Abstract: This paper investigates the application of zonotope-based reachability analysis to low-thrust spacecraft in both two-body and cislunar environments. Reachable sets are generated under two-body and circular restricted three-body (CR3BP) dynamics using set-based methods that approximate nonlinear systems via Taylor expansions. A state-dependent coefficient (SDC) parameterization is also explored to represent nonlinear dynamics in a pseudo-linear form, enabling efficient matrix based propagation of reachable sets. Applications include Earth-Mars transfer and cislunar scenarios such as L1 and L2 Halo orbits and Near Rectilinear Halo Orbits (NRHOs). The resulting reachable sets are used for safe trajectory generation and tracking, with comparisons drawn between model predictive control (MPC) and LQR-based station-keeping. The proposed approach provides a scalable framework for analyzing spacecraft behavior under complex dynamics and control constraints.

</details>


### [375] [Autonomous Mars Rover Module for Soil Sampling and Life Component Analysis](https://arxiv.org/abs/2601.17158)
*Bibek Adhikari,Rishab Rijal,Rakesh Yadav,Nikchey Khatri,Sandesh Dhakal*

Main category: eess.SY

TL;DR: 本研究提出了一种集成在火星漫游者上的生命探测模块，该模块能够自主在火星上挖掘土壤并进行生化检测，以证明地外生命存在的可能性。


<details>
  <summary>Details</summary>
Motivation: 人类对寻找地外生命的长久兴趣，以及火星上发现水的可能性，促使研究者探索在火星上探测生命的方法。

Method: 开发一个集成在火星漫游者上的自主生命探测模块，该模块包含钻探、真空采样和车内生化检测系统，用于分析火星土壤样本。

Result: 该模块能够成功地检测收集到的土壤样本中是否存在生命成分。

Conclusion: 该生命探测模块为在地外环境中进行自主生命探测提供了一个概念验证，并为未来的探测任务奠定了基础。

Abstract: The search for extraterrestrial life has long been a primary focus of scientific exploration, driven by rapid advancements in technology and our understanding of the universe. The discovery of water on Mars has sparked significant interest, raising the question of whether life could exist on the planet. This study proposes a novel approach to simulate and illustrate the detection of life using a proof-of-life module integrated into a Mars rover. The module is an autonomous system capable of traveling to designated regions, excavating soil, collecting samples, and performing biochemical testing onboard the rover itself. The project is inherently multidisciplinary, integrating mechanical systems such as a drill mechanism and a vacuum system, alongside biochemical analysis for soil testing. The module is capable of successfully detecting the presence or absence of living components of life from the collected soil particles. This proof-of-life module serves as a proof-of-concept for autonomous life detection in extraterrestrial environments and lays the foundation for future exploration missions.

</details>


### [376] [Robust and learning-augmented algorithms for degradation-aware battery optimization](https://arxiv.org/abs/2601.17193)
*Jack Umenberger,Anna Osguthorpe Rasmussen*

Main category: eess.SY

TL;DR: 本文提出了一种用于最大化电网规模电池储能系统收入的在线算法，该算法考虑了未来电价不确定性和电池损耗对寿命的影响，并具有无遗憾和渐进竞争比的特性。此外，还提出了一种学习增强型算法，该算法在有不可信的关于损耗机会成本的建议时，能够根据建议的准确性进行调整，同时保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 最大化网格规模电池储能系统的收入，同时考虑不确定的未来电价和电池损耗对寿命的影响。

Method: 将问题建模为在线资源分配问题，并提出了一种基于在线镜像下降的算法。对于不可信的损耗机会成本建议，提出了一种学习增强型算法。

Result: 所提出的在线镜像下降算法在随机独立同分布（i.i.d.）设置下具有无遗憾性，并在对抗性设置下具有有限的渐进竞争比。学习增强型算法在建议准确时表现良好，并且在建议不准确时仍能保持鲁棒性。

Conclusion: 该研究提出了有效的在线算法来解决电池储能系统收入最大化问题，并证明了算法在不同设置下的性能保证，以及在面对不确定性和噪声数据时的鲁棒性。

Abstract: This paper studies the problem of maximizing revenue from a grid-scale battery energy storage system, accounting for uncertain future electricity prices and the effect of degradation on battery lifetime. We formulate this task as an online resource allocation problem. We propose an algorithm, based on online mirror descent, that is no-regret in the stochastic i.i.d. setting and attains finite asymptotic competitive ratio in the adversarial setting (robustness). When untrusted advice about the opportunity cost of degradation is available, we propose a learning-augmented algorithm that performs well when the advice is accurate (consistency) while still retaining robustness properties when the advice is poor.

</details>


### [377] [AstroTimer: Rethinking Non-Access Stratum Timers in LEO Constellations](https://arxiv.org/abs/2601.17195)
*Arshiya Rezaie Hezaveh,Peng Hu*

Main category: eess.SY

TL;DR: 该论文提出了一种名为AstroTimer的轻量级自适应框架，用于动态调整低地球轨道（LEO）卫星通信中的NAS计时器，以解决现有计时器不适应LEO环境动态性的问题，并通过模拟证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的3GPP NAS计时器是从陆地和地球静止/中轨道系统继承而来，无法有效应对LEO星座网络固有的动态拓扑、延迟波动和资源限制等特性，导致信令风暴和效率低下。

Method: AstroTimer框架基于LEO特定参数（如链路变化性、处理延迟和网络功能放置）来计算NAS计时器。它推导出一个计算成本低的闭式计时器模型，并优化了5G注册过程中的看门狗和退避计时器。

Result: 模拟结果表明，与3GPP默认设置相比，AstroTimer显著缩短了注册时间，降低了重试频率和用户设备（UE）的能耗，同时有效防止了信令过载。

Conclusion: AstroTimer为在LEO环境中实现可靠、高效和可扩展的非地面5G/6G部署奠定了 operator-ready 的基础，解决了现有计时器在LEO环境下的不足。

Abstract: Low-Earth Orbit (LEO) constellations expand 5G coverage to remote regions but differ fundamentally from terrestrial networks due to rapidly changing topologies, fluctuating delays, and constrained onboard resources. Existing 3GPP Non-Access Stratum (NAS) timers, inherited from terrestrial and geostationary (GEO) or medium Earth orbit (MEO) systems, fail to accommodate these dynamics, leading to signaling storms and inefficiency. This paper introduces AstroTimer, a lightweight, adaptive framework for sizing NAS timers based on LEO-specific parameters such as link variability, processing delays, and network-function placement. AstroTimer derives a closed-form timer model with low computational cost and optimizes both watchdog and backoff timers for the 5G registration procedure. Simulation results demonstrate that AstroTimer significantly reduces registration time, retry frequency, and user equipment (UE) energy consumption compared to 3GPP defaults, while preventing signaling overloads. The proposed approach provides an operator-ready foundation for reliable, efficient, and scalable non-terrestrial 5G/6G deployments.

</details>


### [378] [Polynomial Chaos-based Input Shaper Design under Time-Varying Uncertainty](https://arxiv.org/abs/2601.17209)
*Johannes Güttler,Karan Baker,Premjit Saha,James Warner,Adrian Stein*

Main category: eess.SY

TL;DR: 本文研究了多项式混沌展开（PCE）在输入整形器设计中的应用，以应对动态系统中不确定性（尤其是时变不确定性）带来的鲁棒性问题，并通过弹簧-质量系统进行了数值验证，结果表明PCE方法在振动抑制方面与蒙特卡洛方法精度相似但效率更高。


<details>
  <summary>Details</summary>
Motivation: 动态系统在实际应用中常面临不确定性，尤其是不确定性随时间变化时，传统输入整形器设计难以保证鲁棒性。因此，研究一种能有效处理时变不确定性的输入整形器设计方法是研究的驱动力。

Method: 采用侵入式多项式混沌展开（iPCE）方法来处理时变不确定性，并将其应用于输入整形器设计。通过弹簧-质量系统模型，对比评估了非鲁棒和鲁棒输入整形器的性能，以最小化残余能量。

Result: 数值模拟结果表明，基于iPCE的输入整形器在时变不确定性下能有效抑制振动，且与蒙特卡洛方法相比，在相似的抑制精度下，效率更高。

Conclusion: 多项式混沌展开是一种有效的处理动态系统中时变不确定性并设计鲁棒输入整形器的方法，相比蒙特卡洛方法，其在振动抑制方面具有更高的效率。

Abstract: The work presented here investigates the application of polynomial chaos expansion toward input shaper design in order to maintain robustness in dynamical systems subject to uncertainty. Furthermore, this work intends to specifically address time-varying uncertainty by employing intrusive polynomial chaos expansion. The methodology presented is validated through numerical simulation of intrusive polynomial chaos expansion formulation applied to spring mass system experiencing time-varying uncertainty in the spring stiffness. The system also evaluates non-robust and robust input shapers through the framework in order to identify designs that minimize residual energy. Results indicate that vibration mitigation is achieved at a similar accuracy, yet at higher efficiency compared to a Monte Carlo framework.

</details>


### [379] [Adaptive Input Shaper Design for Unknown Second-Order Systems with Real-Time Parameter Estimation](https://arxiv.org/abs/2601.17210)
*Nyi Nyi Aung,Bradley Wight,Adrian Stein*

Main category: eess.SY

TL;DR: 提出了一种用于未知二阶系统的在线参数估计前馈输入整形框架，用于精确切换时间和振动抑制。


<details>
  <summary>Details</summary>
Motivation: 在输入整形设计中，需要预先知道系统参数，而许多实际系统（如运动控制应用中的龙门起重机和3D打印机）的参数是未知的或会发生变化。此外，当初始切换时刻丢失时，输入整形设计也需要具备鲁棒性。

Method: 提出了一种前馈输入整形框架，并结合在线参数估计。该方法能够在线估计黑盒系统的参数，从而无需先验知识即可进行输入整形设计。该自适应输入整形方案考虑了系统的周期性切换行为，并且即使在初始切换时刻丢失时也能实现参考整形。

Result: 该框架在仿真中得到了评估。虽然没有给出具体的量化结果，但表明该方法能够实现精确的切换时间和振动抑制。

Conclusion: 所提出的在线参数估计前馈输入整形框架能够有效地处理未知二阶系统，实现精确的切换时间和振动抑制，适用于运动控制等实际应用。

Abstract: We propose a feedforward input-shaping framework with online parameter estimation for unknown second-order systems. The proposed approach eliminates the need for prior knowledge of system parameters when designing input shaping for precise switching times by incorporating online estimation for a black-box system. The adaptive input shaping scheme accounts for the system's periodic switching behavior and enables reference shaping even when initial switching instants are missed. The proposed framework is evaluated in simulation and is intended for vibration suppression in motion control applications such as gantry cranes and 3D printer headers.

</details>


### [380] [A new approach for combined model class selection and parameters learning for auto-regressive neural models](https://arxiv.org/abs/2601.17442)
*Corrado Sgadari,Alessio La Bella,Marcello Farina*

Main category: eess.SY

TL;DR: 提出一种基于集合成员（SM）的方法，用于同时选择NARXESN模型结构和学习参数，以识别非线性动态系统，并有效处理测量噪声。


<details>
  <summary>Details</summary>
Motivation: 现有方法在模型结构选择和参数学习上存在不足，且难以处理含自回归分量的模型的NP-hard问题，同时需要处理测量噪声。

Method: 提出一种新的基于集合成员（SM）的程序，用于同时选择NARXESN模型类和学习模型参数。

Result: 该方法能够识别出简洁且准确的模型，适用于控制应用，并且在训练过程中能够鲁棒地处理有界测量噪声，并提高模型仿真性能的稳健性。

Conclusion: 该方法有效地解决了非线性动态系统识别中的模型结构选择和参数学习问题，并能鲁棒地处理测量噪声，为控制应用提供了更优的模型。

Abstract: This work introduces a novel approach for the joint selection of model structure and parameter learning for nonlinear dynamical systems identification. Focusing on a specific Recurrent Neural Networks (RNNs) family, i.e., Nonlinear Auto-Regressive with eXogenous inputs Echo State Networks (NARXESNs), the method allows to simultaneously select the optimal model class and learn model parameters from data through a new set-membership (SM) based procedure. The results show the effectiveness of the approach in identifying parsimonious yet accurate models suitable for control applications. Moreover, the proposed framework enables a robust training strategy that explicitly accounts for bounded measurement noise and enhances model robustness by allowing data-consistent evaluation of simulation performance during parameter learning, a process generally NP-hard for models with autoregressive components.

</details>


### [381] [Robust Output Regulation of Uncertain Linear Time-Varying Systems](https://arxiv.org/abs/2601.17464)
*Jinmeng Zha,Zhen Zhang*

Main category: eess.SY

TL;DR: 本文提出了一种新的鲁棒输出调节方法，通过“系统内禀浸入”将调节器方程重构为一种更具洞察力的形式，揭示了参数不确定性对鲁棒性的影响，并提出了一种无需显式求解调节器方程的通用鲁棒设计。


<details>
  <summary>Details</summary>
Motivation: 解决线性时变系统鲁棒输出调节的开放性问题，该问题已存在数十年。

Method: 提出“系统内禀浸入”方法，重新表述调节器方程，揭示内部模型与强制系统输出轨迹重现的关系，分析参数不确定性的影响，并设计了一种通用鲁棒控制器。

Result: 证明了针对植物不确定性的鲁棒性通常需要无限维控制器；提出的通用设计在外部系统交互不确定性方面是鲁棒的，并能在需要无限维控制器时实现近似输出调节；推导了坐标无关的框架下的调节器方程，扩展了时变非共振条件，并提供了最小化内部模型维数的方法。

Conclusion: 为构建鲁棒的基于内部模型的控制器提供了一个通用的系统框架，并简化了控制器的实现过程。

Abstract: Robust output regulation for linear time-varying systems has remained an open problem for decades. To address this, we propose intrinsic system immersion by reformulating the regulator equation in a more insightful form, indicating that finding an internal model is equivalent to reproducing the output trajectory of a forced system by constructing an unforced system. This perspective reveals the influence of parametric uncertainties, demonstrating that an infinite-dimensional controller is generally unavoidable for robustness against plant uncertainty. Consequently, a general robust design is proposed without explicitly solving the regulator equation. It ensures robustness against uncertainties in the exosystem interaction, and achieves approximate output regulation when an infinite-dimensional controller is necessary for regulation. Additionally, we study the regulator equation in a coordinate-free framework, extend the time-varying non-resonance condition, and provide a method to minimize the dimension of an internal model. Overall, these results provide a general systematic framework for constructing robust internal model-based controllers, and simplify the control implementation process.

</details>


### [382] [Invited: Toward Sustainable and Transparent Benchmarking for Academic Physical Design Research](https://arxiv.org/abs/2601.17520)
*Liwen Jiang,Andrew B. Kahng,Zhiang Wang,Zhiyu Zheng*

Main category: eess.SY

TL;DR: 本文提出了 RosettaStone 2.0，一个基于 OpenROAD-Research 的开源基准翻译和评估框架，支持 2D 和 3D 混合键合设计，通过 CI 和排行榜实现可复现的研究。


<details>
  <summary>Details</summary>
Motivation: 为了在平面和三维实现设置之间进行严格的苹果对苹果比较，并支持透明和可复现的研究。

Method: 构建了一个名为 RosettaStone 2.0 的开源基准翻译和评估框架，基于 OpenROAD-Research，包含 RTL-to-GDS 参考流程，集成 CI 回归测试，并基于 METRICS2.1 公约进行评估。提供一个由验证的 pull requests 和 DCO 合规性管理的社区排行榜。

Result: 提供了一个用于 2D 和 3D 混合键合设计的完整 RTL-to-GDS 参考流程，以及一个标准化的评估流水线和社区排行榜，用于翻译和评估。

Conclusion: RosettaStone 2.0 提供了一个完整、可复现的框架，用于比较平面和 3D 混合键合设计的实现，并通过 CI 和排行榜促进透明的研究。

Abstract: This paper presents RosettaStone 2.0, an open benchmark translation and evaluation framework built on OpenROAD-Research. RosettaStone 2.0 provides complete RTL-to-GDS reference flows for both conventional 2D designs and Pin-3D-style face-to-face (F2F) hybrid-bonded 3D designs, enabling rigorous apples-to-apples comparison across planar and three-dimensional implementation settings. The framework is integrated within OpenROAD-flow-scripts (ORFS)-Research; it incorporates continuous integration (CI)-based regression testing and provides a standardized evaluation pipeline based on the METRICS2.1 convention, with structured logs and reports generated by ORFS-Research. To support transparent and reproducible research, RosettaStone 2.0 further provides a community-facing leaderboard, which is governed by verified pull requests and enforced through Developer Certificate of Origin (DCO) compliance.

</details>


### [383] [Battery-Free and Gateway-Free Cellular IoT Water Leak Detection System](https://arxiv.org/abs/2601.17656)
*Roshan Nepal,Brandon Brown,Shishangbo Yu,Roozbeh Abbasi,Norman Zhou,George Shaker*

Main category: eess.SY

TL;DR: 提出了一种利用水力发电通过电化学传感器驱动的、无需电池和网关的LTE-M水浸漏水检测系统，可直接通信至云端。


<details>
  <summary>Details</summary>
Motivation: 传统的物联网设备需要电池供电和本地网络基础设施，这限制了其续航能力和部署灵活性。本研究旨在开发一种可持续、免维护且无需网关的漏水检测解决方案。

Method: 该系统采用电化学传感器将水能转化为电能，并通过水力发电驱动整个系统。集成了一个专门的电源管理子系统，包括升压转换器、基于超级电容器的储能以及滞后控制的负载隔离电路，以满足LTE-M通信的功率需求。系统设计为自主、直接到云端的数据传输。

Result: 实验结果表明，系统能够成功地通过水浸触发的能量产生，实现LTE-M信号的稳定传输，证明了其可行性。

Conclusion: 该电池供电、网关供电的LTE-M水浸漏水检测系统，通过水力发电和创新的电源管理，实现了可持续、免维护和可扩展的物联网应用，特别适用于智能基础设施的漏水监测。

Abstract: This paper presents a battery-free and gateway-free water leak detection system capable of direct communication over LTE-M (Cat-M1). The system operates solely on energy harvested through a hydroelectric mechanism driven by an electrochemical sensor, thereby removing the need for conventional batteries. To address the stringent startup and operational power demands of LTE-M transceivers, the architecture incorporates a compartmentalized sensing module and a dedicated power management subsystem, comprising a boost converter, supercapacitor based energy storage, and a hysteresis controlled load isolation circuit. This design enables autonomous, direct to cloud data transmission without reliance on local networking infrastructure. Experimental results demonstrate consistent LTE-M beacon transmissions triggered by water induced energy generation, underscoring the system's potential for sustainable, maintenance free, and globally scalable IoT leak detection applications in smart infrastructure.

</details>


### [384] [Battery-less Long-Range LTE-M Water Leak Detector](https://arxiv.org/abs/2601.17660)
*Roshan Nepal,Brandon Brown,Shishangbo Yu,Roozbeh Abbasi,Norman Zhou,George Shaker*

Main category: eess.SY

TL;DR: 提出了一种无需电池和网关的自供电漏水传感器，利用水作为能量来源，并通过LTE-M或未来5G网络将数据发送到云端。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够独立运行、无需电池和本地网关的漏水传感器，以便在基础设施匮乏的地区实现广泛部署。

Method: 集成了双腔电化学能量收集器、低输入升压转换器（配有超级电容器存储）以及基于Nordic Thingy:91平台的比较器门控LTE-M无线电。

Result: 实验证明，该系统在接触水后能从休眠状态唤醒，收集足够能量，并利用水暴露作为能源，反复向云端发送信标。

Conclusion: 该自供电漏水传感器设计可行，能够实现电池和网关的消除，并且其对3GPP标准蜂窝协议的兼容性预示着未来在非地面5G网络中的应用潜力，可解决基础设施稀疏区域的覆盖问题。

Abstract: This work presents a self powered water leak sensor that eliminates both batteries and local gateways. The design integrates a dual compartment electrochemical harvester, a low input boost converter with supercapacitor storage, and a comparator gated LTE-M radio built on the Nordic Thingy:91 platform. Laboratory tests confirm that the system can be awakened from a dormant state in the presence of water, harvest sufficient energy, and issue repeated cloud beacons using the water exposure as the power source. Beyond conventional LTE-M deployments, the system's compatibility with 3GPP standard cellular protocols paves the way for future connectivity via non terrestrial 5G networks, enabling coverage in infrastructure scarce regions.

</details>


### [385] [Composite Adaptive Control Barrier Functions for Safety-Critical Systems with Parametric Uncertainty](https://arxiv.org/abs/2601.17683)
*Mohammadreza Kamaldar*

Main category: eess.SY

TL;DR: 提出了一种名为CaCBF的组合自适应控制屏障函数算法，用于解决具有线性参数不确定性的非线性控制仿射系统中的安全问题，该算法在不要求参数收敛的情况下保证了安全集的前向不变性和闭环系统的均匀有界性。


<details>
  <summary>Details</summary>
Motivation: 现有的控制屏障函数在存在参数不确定性时无法保证安全性，而现有的鲁棒方法会限制性能，学习方法可能会在训练期间违反安全约束。因此，需要一种能够处理参数不确定性并同时保证安全性的新方法。

Method: 该算法结合了对数安全屏障、控制李雅普诺夫函数和参数误差项构建了一个组合能量函数，并从中推导出自适应律。这种方法能够处理非线性控制仿射系统中的线性参数不确定性。

Result: 证明了CaCBF算法能够保证安全集的前向不变性以及闭环系统的均匀有界性，并且这一安全保证在参数不收敛的情况下依然成立。仿真结果表明了该算法在自适应巡航控制、全向机器人和平面无人机等应用中的有效性。

Conclusion: CaCBF算法是一种有效的解决方案，可以为具有线性参数不确定性的非线性控制仿射系统提供严格的安全保证，而无需参数的精确收敛，从而在性能和安全性之间取得了更好的平衡。

Abstract: Control barrier functions guarantee safety but typically require accurate system models. Parametric uncertainty invalidates these guarantees. Existing robust methods maintain safety via worst-case bounds, limiting performance, while modular learning schemes decouple estimation from safety, permitting state violations during training. This paper presents the composite adaptive control barrier function (CaCBF) algorithm for nonlinear control-affine systems subject to linear parametric uncertainty. We derive adaptation laws from a composite energy function comprising a logarithmic safety barrier, a control Lyapunov function, and a parameter error term. We prove that CaCBF guarantees the forward invariance of the safe set and the uniform boundedness of the closed-loop system. This safety guarantee holds without requiring parameter convergence. Simulations of adaptive cruise control, an omnidirectional robot, and a planar drone demonstrate the efficacy of the CaCBF algorithm.

</details>


### [386] [Space-Air-Ground-Integrated Networks: The BER vs. Residual Delay and Doppler Analysis](https://arxiv.org/abs/2601.17859)
*Chao Zhang,Kunlun Li,Chao Xu,Lie-Liang Yang,Lajos Hanzo*

Main category: eess.SY

TL;DR: 本文针对时变相关衰落莱斯信道下的空间-地面综合网络（SAGINs），研究了由于多径多普勒效应和相对论效应导致的残余多普勒和同步延迟下的误码率（BER）性能。提出了包含信道模型、路径损耗、大气吸收、多普勒补偿、卫星轨道和相对论效应的SAGIN模型，推导了闭式BER公式，并量化了残余多普勒、大气阴影、同步误差和导频开销的影响。


<details>
  <summary>Details</summary>
Motivation: 在空间-地面综合网络（SAGINs）中，由于多径多普勒效应和爱因斯坦相对论效应，完美的Doppler补偿和同步非常困难。因此，研究在这些挑战下网络的性能至关重要。

Method: 首先，构建了一个包含相关衰落莱斯信道、基于斯涅尔定律的路径损耗、大气吸收、视线多普勒补偿、椭圆卫星轨道以及爱因斯坦相对论效应的实用SAGIN模型。然后，推导了相关衰落莱斯信道下的导频和数据符号间的特定相关系数。利用该相关系数，将信道分布近似为双变量Gamma分布。最后，在采用最小二乘信道估计和均衡（16-QAM）的条件下，推导出了闭式的BER公式。

Result: 研究表明，对于300公里高度的低地球轨道（LEO）卫星，真实椭圆轨道的周期比理想化圆轨道长约0.8秒，且在整个LEO轨道期间（从升起到落下），相对论延迟低于1微秒。数值结果量化了残余多普勒、大气阴影、同步误差和导频开销对L波段通信的影响。

Conclusion: 本文通过提出的SAGIN模型和推导出的闭式BER公式，为理解和优化SAGINs在复杂传播环境下的性能提供了理论依据，并量化了关键参数的影响，有助于未来的网络设计和部署。

Abstract: Perfect Doppler compensation and synchronization is nontrivial due to multi-path Doppler effects and Einstein's theory of relativity in the space-air-ground-integrated networks (SAGINs). Hence, by considering the residual Doppler and the synchronization delay, this paper investigates the bit-error-rate (BER) performance attained under time-varying correlated Shadowed-Rician SAGIN channels. First, a practical SAGIN model is harnessed, encompassing correlated Shadowed-Rician channels, the Snell's law-based path loss, atmospheric absorption, the line-of-sight Doppler compensation, elliptical satellite orbits, and Einstein's theory of relativity. Then, a specific correlation coefficient between the pilot and data symbols is derived in the context of correlated Shadowed-Rician Channels. By exploiting this correlation coefficient, the channel distribution is mimicked by a bi-variate Gamma distribution. Then, a closed-form BER formula is derived under employing least-square channel estimation and equalization for 16-QAM. Our analytical results indicate for a 300-km-altitude LEO that 1) the period of realistic elliptical orbits is around 0.8 seconds longer than that of the idealized circular orbits; and 2) the relativistic delay is lower than 1 $μs$ over a full LEO pass (from rise to set). Our numerical results for the L bands quantify the effects of: 1) the residual Doppler; 2) atmospheric shadowing; 3) synchronization errors; and 4) pilot overhead.

</details>


### [387] [Photovoltaic energy sharing: Implementation and tests on a real collective self-consumption system](https://arxiv.org/abs/2601.17974)
*Camblong H.,Curea O.,Ugartemendia J. J.,Boussaada Z.,Lizarralde I.,Etxegarai G*

Main category: eess.SY

TL;DR: 研究分析了法国一个实际集体自发自用（CSC）案例中的光伏（PV）能源共享，重点关注自发自用率（SCR）和节省成本，比较了静态、默认动态和定制动态三种能源共享方式，并发现动态分配提高了SCR，定制动态共享则增加了节省成本。


<details>
  <summary>Details</summary>
Motivation: 为了推动可再生能源整合，研究自发自用（self-consumption）概念的出现及其在集体自发自用（CSC）中的实际应用，特别是不同能源共享方式对自发自用率和经济效益的影响。

Method: 在法国伊扎贝尔科技园的一个实际CSC案例中，分析了光伏能源的生产和消费。使用了智能电表和基于LoRa协议的Tecsol TICs设备来收集数据。比较了三种能源共享/分配方式（静态、默认动态和定制动态）在四种不同场景（有/无数据中心，低/高太阳辐射）下的表现。

Result: 动态能源分配方式提高了自发自用率（SCR）。定制动态共享方式能带来更高的经济节省。

Conclusion: 集体自发自用（CSC）中的动态能源共享策略，特别是定制化的动态共享，能够有效提高光伏能源的自发自用率并增加经济效益。

Abstract: This research study analyses different types of photovoltaic (PV) energy sharing in a collective self-consumption (CSC) real-case in the Izarbel technological park in France. The analysis is carried out above all from the point of view of the self-consumption rate (SCR) and the savings. After explaining the emergence of the self-consumption concept for the integration of renewable energies, the study case is described. The PV energy is produced in ESTIA1 building and consumed in ESTIA1, 2 and 4 buildings. The main IoT components used to implement the CSC are smart meters and the Tecsol TICs; devices based on the LoRa protocol to retrieve production and consumption data. Then, the characteristics of PV energy sharing in France are explained, in particular the three possible types of energy sharing/allocation (static, dynamic by default and customised dynamic) and the structure of the electricity bill. Finally, the three types of sharing are compared in four scenarios (without and with a data centre, for low and high solar radiation). The results show that the dynamic allocations lead to increases of the SCR and that the customised dynamic sharing increases savings.

</details>


### [388] [Data-driven nonparametric Li-ion battery ageing model aiming at learning from real operation data -- Part A: Storage operation](https://arxiv.org/abs/2601.17978)
*Lucu M.,Martinez-Laserna E.,Gandiaga I.,Liu K.,Camblong H.,Widanage W. D.,Marco J*

Main category: eess.SY

TL;DR: 本研究提出了一种基于高斯过程的数据驱动锂离子电池老化模型，用于预测日历老化。该模型能够从少量实验室测试数据中学习，并在大量真实世界数据上进行验证，展示了其准确性和学习能力。


<details>
  <summary>Details</summary>
Motivation: 传统的锂离子电池老化模型需要大量时间和实验资源，而新兴的数据采集遥测技术将带来海量的真实运行数据。因此，开发能从现场数据中学习的老化模型，以减少实验室测试需求，具有重要意义。

Method: 利用高斯过程框架构建数据驱动的锂离子电池老化模型。设计了一个专门针对电池老化应用的协方差函数。通过在包含32个电池、历时三年多的数据集上进行训练和验证，探索不同的训练策略，以确定设计精确老化模型所需的最小实验室测试数量。

Result: 使用18个测试单元训练的模型，在动态和静态温度及SOC存储条件下进行验证后，对容量曲线的预测实现了0.53%的平均绝对误差。该模型展现了从新数据中学习、提供更精确和自信的预测的能力，并扩展了模型的运行窗口。

Conclusion: 高斯过程框架能够有效地构建数据驱动的锂离子电池日历老化模型，即使在仅使用少量实验室测试数据进行训练的情况下，也能达到很高的预测精度。该方法有助于减少电池老化研究的实验成本，并能从实际运行数据中持续优化模型。

Abstract: Conventional Li-ion battery ageing models, such as electrochemical, semi-empirical and empirical models, require a significant amount of time and experimental resources to provide accurate predictions under realistic operating conditions. At the same time, there is significant interest from industry in the introduction of new data collection telemetry technology. This implies the forthcoming availability of a significant amount of real-world battery operation data. In this context, the development of ageing models able to learn from in-field battery operation data is an interesting solution to mitigate the need for exhaustive laboratory testing. In a series of two papers, a data-driven ageing model is developed for Li-ion batteries under the Gaussian Process framework. A special emphasis is placed on illustrating the ability of the Gaussian Process model to learn from new data observations, providing more accurate and confident predictions, and extending the operating window of the model. This first paper focusses on the systematic modelling and experimental verification of cell degradation through calendar ageing. A specific covariance function is composed, tailored for use in a battery ageing application. Over an extensive dataset involving 32 cells tested during more than three years, different training possibilities are contemplated in order to quantify the minimal number of laboratory tests required for the design of an accurate ageing model. A model trained with only 18 tested cells achieves an overall mean-absolute-error of 0.53% in the capacity curves prediction, after being validated under a broad window of both dynamic and static temperature and SOC storage conditions.

</details>


### [389] [Data-driven nonparametric Li-ion battery ageing model aiming at learning from real operation data -- Part B: Cycling operation](https://arxiv.org/abs/2601.17983)
*Lucu M.,Martinez-Laserna E.,Gandiaga I.,Liu K.,Camblong H.,Widanage W. D.,Marco J*

Main category: eess.SY

TL;DR: 本文提出了一种基于高斯过程的锂离子电池循环老化数据驱动模型，使用少量实验数据即可获得高精度的预测，并降低了实验室测试需求。


<details>
  <summary>Details</summary>
Motivation: 传统锂离子电池老化模型需要大量时间和实验资源，而新的数据收集技术将产生大量实际运行数据，因此需要开发能从实际数据中学习的老化模型来降低实验成本。

Method: 采用高斯过程框架构建数据驱动的老化模型，并设计了适用于电池老化应用的特定协方差函数。研究了不同的训练数据量对模型精度的影响。

Result: 使用26个电池的实验数据训练的模型，在预测容量衰减曲线时，平均绝对误差达到1.04%，并且在宽泛的动态和静态循环温度、放电深度、中间SOC、充电和放电倍率下都得到了验证。

Conclusion: 高斯过程模型能够有效地从少量实验数据中学习锂离子电池的循环老化特性，提供准确且有置信度的预测，并显著减少了所需的实验室测试数量。

Abstract: Conventional Li-ion battery ageing models, such as electrochemical, semi-empirical and empirical models, require a significant amount of time and experimental resources to provide accurate predictions under realistic operating conditions. At the same time, there is significant interest from industry in the introduction of new data collection telemetry technology. This implies the forthcoming availability of a significant amount of real-world battery operation data. In this context, the development of ageing models able to learn from in-field battery operation data is an interesting solution to mitigate the need for exhaustive laboratory testing. In a series of two papers, a data-driven ageing model is developed for Li-ion batteries under the Gaussian Process framework. A special emphasis is placed on illustrating the ability of the Gaussian Process model to learn from new data observations, providing more accurate and confident predictions, and extending the operating window of the model. The first paper of the series focussed on the systematic modelling and experimental verification of cell degradation through calendar ageing. Conversantly, this second paper addresses the same research challenge when the cell is electrically cycled. A specific covariance function is composed, tailored for use in a battery ageing application. Over an extensive dataset involving 124 cells tested during more than three years, different training possibilities are contemplated in order to quantify the minimal number of laboratory tests required for the design of an accurate ageing model. A model trained with only 26 tested cells achieves an overall mean-absolute-error of 1.04% in the capacity curve prediction, after being validated under a broad window of both dynamic and static cycling temperatures, Depth-of-Discharge, middle-SOC, charging and discharging C-rates.

</details>


### [390] [Validation of a Software-Defined 100-Gb/s RDMA Streaming Architecture for Ultrafast Optoacoustic and Ultrasound Imaging](https://arxiv.org/abs/2601.18280)
*Federico Villani,Christian Vogt,Luca Specht,Jero Schmid,Xiang Liu,Andrea Cossettini,Daniel Razansky,Luca Benini*

Main category: eess.SY

TL;DR: 本文提出了一种新的数据采集架构（LtL），用于超快光声（OA）和超声（US）成像，克服了现有OA系统的局限性，实现了高通道数、宽带宽和软件定义操作，并验证了其可扩展性和数据传输能力。


<details>
  <summary>Details</summary>
Motivation: 现有光声（OA）成像系统在临床转化方面受到限制，因为它们依赖于笨重且昂贵的硬件，并且主要为脉冲回波超声（US）成像优化，而OA成像对接收带宽和与激光源的时间同步有不同要求。为了实现OA-US联合成像，需要一种能够满足OA和US成像需求的统一平台。

Method: 提出了一种名为LtL的新数据采集架构，该架构集成了宽带模拟前端、集成了FPGA和应用处理单元的Zynq UltraScale+ MPSoC，以及支持高达95.6 Gb/s原始数据流的100 GbE RDMA后端。该架构避免了常用的本地缓冲区和突发传输，实现了真正的连续数据流。使用16通道演示系统验证了核心组件，并评估了256通道的可扩展性。

Result: LtL架构能够支持高通道数、宽带宽和软件定义操作。16通道演示系统验证了其核心元素，并证实了其信号链可扩展至256通道，同时支持高数据传输速度。

Conclusion: LtL架构为开发下一代超快OA-US成像系统提供了一种有前途的解决方案，能够克服现有系统的限制，并实现高效、连续的原始数据采集。

Abstract: Optoacoustic (OA) imaging has emerged as a powerful investigation tool, with demonstrated applicability in oncology, neuroscience, and cardiovascular biology. However, its clinical translation is limited with the existing OA systems, which often rely on bulky and expensive acquisition hardware mainly optimized for pulse-echo ultrasound (US) imaging. Despite the fact that OA imaging has different requirements for receive bandwidths and timing synchronization with external laser sources, there is a strong need for unified OA-US imaging platforms, as pulse-echo US remains the standard tool for visualizing soft tissues. To address these challenges, we propose a new data acquisition architecture for ultrafast OA and US imaging that fully covers the requirements for large channel counts, wide bandwidth, and software-defined operation. LtL combines state-of-the-art wideband analog front-ends, a Zynq UltraScale+ MPSoC integrating FPGA fabric with an Application Processing Unit, and a 100 GbE Remote Direct Memory Access (RDMA) backend enabling raw-data streaming at up to 95.6 Gb/s. The architecture avoids local buffers followed by burst transfers, which commonly constrain sustainable frame rate and recording intervals, thus achieving true continuous and sustained streaming of raw data. We validate the core elements of the LtL architecture using a 16-channel demonstration system built from commercial evaluation boards. We further verify the signal chain for up to 256-channel scalability, confirming the wide bandwidth capabilities to support state-of-the-art data transmission speeds.

</details>


### [391] [Reinforcement Learning with Distributed MPC for Fuel-Efficient Platoon Control with Discrete Gear Transitions](https://arxiv.org/abs/2601.18294)
*Samuel Mallick,Gianpietro Battocletti,Dimitris Boskos,Azita Dabiri,Bart De Schutter*

Main category: eess.SY

TL;DR: 提出了一种基于强化学习（RL）的分布式模型预测控制（MPC）方法，用于优化自动驾驶车队（platoon）的速度和档位，以提高燃油效率和降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统的分布式MPC在优化车辆速度和离散档位时计算量大，难以实时实现。本文旨在解决这一计算瓶颈，并提高方法的可扩展性。

Method: 该方法为车队中的每辆车训练一个RL策略，该策略在MPC的预测窗口内选择并固定档位。这使得MPC能够解决一个更简单的连续优化问题。为了提高训练效率和可扩展性，RL问题被解耦为单智能体学习任务，并使用循环神经网络（RNN）来处理档位选择策略，以应对可能指数级增长的档位组合。

Result: 与纯MPC方法相比，所提出的RL-MPC方法在高速公路驾驶模拟中显著降低了计算负担，并在燃油效率方面取得了可比的性能。

Conclusion: 基于RL的分布式MPC方法是一种有效且可扩展的解决方案，可以用于优化自动驾驶车队的燃油效率，同时克服了传统MPC的计算挑战。

Abstract: Cooperative control of groups of autonomous vehicles (AVs), i.e., platoons, is a promising direction to improving the efficiency of autonomous transportation systems. In this context, distributed co-optimization of both vehicle speed and gear position can offer benefits for fuel-efficient driving. To this end, model predictive control (MPC) is a popular approach, optimizing the speed and gear-shift schedule while explicitly considering the vehicles' dynamics over a prediction window. However, optimization over both the vehicles' continuous dynamics and discrete gear positions is computationally intensive, and may require overly long sample times or high-end hardware for real-time implementation. This work proposes a reinforcement learning (RL)-based distributed MPC approach to address this issue. For each vehicle in the platoon, a policy is trained to select and fix the gear positions across the prediction window of a local MPC controller, leaving a significantly simpler continuous optimization problem to be solved as part of a distributed MPC scheme. In order to reduce the computational cost of training and facilitate the scalability of the proposed approach to large platoons, the policies are parameterized such that the emergent multi-agent RL problem can be decoupled into single-agent learning tasks. In addition, a recurrent neural-network (RNN) architecture is proposed for the gear selection policy, such that the learning is scalable even as the number of possible gear-shift schedules grows exponentially with the MPC prediction horizon. In highway-driving simulations, the proposed approach is shown to have a significantly lower computation burden and a comparable performance in terms of fuel-efficient platoon control, with respect to pure MPC-based co-optimization.

</details>


### [392] [Convex Chance-Constrained Stochastic Control under Uncertain Specifications with Application to Learning-Based Hybrid Powertrain Control](https://arxiv.org/abs/2601.18313)
*Teruki Kato,Ryotaro Shima,Kenji Kashima*

Main category: eess.SY

TL;DR: 提出了一种考虑控制规范不确定性的凸随机控制框架，通过联合优化控制输入和风险分配，保证概率约束满足，并保证解的唯一性和连续性。该方法可扩展到非线性模型控制，并通过混合动力汽车模型预测控制的应用进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有随机控制方法在处理控制规范（如参考轨迹和操作约束）的不确定性方面存在局限，并且通常难以保证解的唯一性和连续性。本研究旨在克服这些挑战，提出一种能够处理控制规范不确定性的随机控制框架。

Method: 提出了一种严格凸的随机控制框架，该框架通过联合优化控制输入和风险分配来处理控制规范的不确定性。该方法适用于一般（可能非高斯）不确定性，并保证概率约束的满足。此外，通过机器学习识别的精确线性化模型，将该框架扩展到基于非线性模型的控制。最后，通过在混合动力汽车模型预测控制中的应用来验证其有效性。

Result: 所提出的框架能够确保概率约束的满足，并由于其严格凸性，保证了最优解的唯一性和连续性。该方法成功地应用于混合动力汽车的预测控制，验证了其有效性。

Conclusion: 该研究提出了一种新颖的随机控制框架，能够有效地处理控制规范的不确定性，并保证最优解的唯一性和连续性。该框架对于需要高可靠性和鲁棒性的复杂系统（如混合动力汽车）的控制具有重要意义。

Abstract: This paper presents a strictly convex chance-constrained stochastic control framework that accounts for uncertainty in control specifications such as reference trajectories and operational constraints. By jointly optimizing control inputs and risk allocation under general (possibly non-Gaussian) uncertainties, the proposed method guarantees probabilistic constraint satisfaction while ensuring strict convexity, leading to uniqueness and continuity of the optimal solution. The formulation is further extended to nonlinear model-based control using exactly linearizable models identified through machine learning. The effectiveness of the proposed approach is demonstrated through model predictive control applied to a hybrid powertrain system.

</details>


### [393] [Real-Time Prediction of Lower Limb Joint Kinematics, Kinetics, and Ground Reaction Force using Wearable Sensors and Machine Learning](https://arxiv.org/abs/2601.18494)
*Josée Mallah,Yu Zhu,Kailang Xu,Gurvinder S. Virk,Shaoping Bai,Luigi G. Occhipinti*

Main category: eess.SY

TL;DR: 该研究提出了一种基于可穿戴传感器和机器学习的实时下肢运动捕捉框架，可以高精度地估计关节角度、地面反作用力（GRF）和关节力矩，适合生物反馈应用。


<details>
  <summary>Details</summary>
Motivation: 传统的金标准运动捕捉方法耗时且成本高昂，促使研究人员开发更经济高效的替代方案。

Method: 使用无线可穿戴传感器（IMU和带传感器的鞋垫）结合机器学习算法（随机森林和基于ResNet-16的深度学习）来实时估计下肢关节角度、GRF和关节力矩。

Result: 所提出的框架能够以1 kHz的采样率进行预测，延迟极低（23毫秒），并且在估计关节角度、GRF和关节力矩方面达到了与文献相当的准确度。

Conclusion: 该研究成功开发了一个完全依赖可穿戴传感器、覆盖主要下肢关节且能进行多模态数据（GRF、关节角度、关节力矩）综合估计的实时系统，其低延迟特性使其适用于生物反馈应用。

Abstract: Walking is a key movement of interest in biomechanics, yet gold-standard data collection methods are time- and cost-expensive. This paper presents a real-time, multimodal, high sample rate lower-limb motion capture framework, based on wireless wearable sensors and machine learning algorithms. Random Forests are used to estimate joint angles from IMU data, and ground reaction force (GRF) is predicted from instrumented insoles, while joint moments are predicted from angles and GRF using deep learning based on the ResNet-16 architecture. All three models achieve good accuracy compared to literature, and the predictions are logged at 1 kHz with a minimal delay of 23 ms for 20s worth of input data. The present work fully relies on wearable sensors, covers all five major lower limb joints, and provides multimodal comprehensive estimations of GRF, joint angles, and moments with minimal delay suitable for biofeedback applications.

</details>


### [394] [Experimental Characterization of ISAC Channel Mapping and Environment Awareness](https://arxiv.org/abs/2601.18558)
*Zhuangzhuang Cui,Rizqi Hersyandika,Haoqiu Xiong,Sofie Pollin*

Main category: eess.SY

TL;DR: 本文在毫米波ISAC环境下，通过实验研究了单站感知和自然双站通信信道的关系，并展示了如何从感知信道中恢复通信信道。


<details>
  <summary>Details</summary>
Motivation: 在集成感知与通信（ISAC）的背景下，探索单站感知和自然双站通信信道之间的关联，并从感知信道中恢复通信信道，以实现更高效的ISAC系统。

Method: 在室内毫米波环境下进行实验，表征联合延迟-角度域的传播信道，提取主导的多径分量（MPCs）并与物理散射体关联，然后从感知信道中恢复通信MPCs。最后，利用校准的信道功率和重建的传播距离计算墙壁和金属板的雷达散射截面（RCS）。

Result: 成功地表征了单站感知和自然双站通信信道在联合延迟-角度域下的关系，并展示了通信MPCs可以从感知信道中恢复。计算得到了墙壁和金属板的RCS。

Conclusion: 证明了在ISAC系统中，可以通过感知信道的信息来恢复通信信道的信息，并且可以基于此信息精确地计算出关键散射体的RCS，为ISAC系统的设计和优化提供了实验依据。

Abstract: In the context of integrated sensing and communications (ISAC), this paper presents an experimental investigation of the relationship between monostatic sensing and naturally bistatic communication channels in an indoor millimeter-wave environment. We characterize the propagation channel in the joint delay--angle domain, extract dominant multipath components (MPCs) and associate them with physical scatterers in the environment, and demonstrate how communication MPCs can be explicitly recovered from sensing channels. Finally, the radar cross-sections (RCSs) of two key scatterers, namely the wall and metal plate, are obtained based on calibrated channel power and reconstructed propagation distances.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [395] [Fully 3D Unrolled Magnetic Resonance Fingerprinting Reconstruction via Staged Pretraining and Implicit Gridding](https://arxiv.org/abs/2601.17143)
*Yonatan Urman,Mark Nishimura,Daniel Abraham,Xiaozhi Cao,Kawin Setsompop*

Main category: eess.IV

TL;DR: 提出了一种名为 SPUR-iG 的 3D 深度展开子空间重建框架，用于加速磁共振指纹 (MRF) 重建，通过隐式 GROG 数据一致性和渐进式训练策略，显著提高了重建速度和精度。


<details>
  <summary>Details</summary>
Motivation: 现有的 MRF 重建方法，尤其是在高分辨率 3D 数据和高加速因子下，计算成本高且效率不足。LLR 先验在高加速下表现不佳，而大规模训练 3D 先验面临内存和运行时挑战。

Method: SPUR-iG 采用全 3D 深度展开框架，结合了隐式 GROG 进行高效的数据一致性计算（通过隐式学习的核将非笛卡尔数据网格化到笛卡尔网格，允许基于 FFT 的更新）和渐进式训练策略。训练分为三个阶段：1) 使用大量数据增强进行去噪器预训练；2) 贪婪的逐迭代展开训练；3) 使用梯度检查点进行最终微调。

Result: SPUR-iG 在 1mm 各向同性分辨率下，相比 LLR 和混合 2D/3D 展开基线，提高了子空间系数图的质量和定量精度。全脑重建可在 15 秒内完成，加速高达 111 倍。30 秒扫描的 T1 图精度可与 2 分钟扫描的 LLR 重建相媲美。

Conclusion: SPUR-iG 框架能够高效且可靠地实现大规模 3D MRF 重建的加速定量成像，显著提高了重建的准确性和速度，克服了现有方法的局限性。

Abstract: Magnetic Resonance Fingerprinting (MRF) enables fast quantitative imaging, yet reconstructing high-resolution 3D data remains computationally demanding. Non-Cartesian reconstructions require repeated non-uniform FFTs, and the commonly used Locally Low Rank (LLR) prior adds computational overhead and becomes insufficient at high accelerations. Learned 3D priors could address these limitations, but training them at scale is challenging due to memory and runtime demands. We propose SPUR-iG, a fully 3D deep unrolled subspace reconstruction framework that integrates efficient data consistency with a progressive training strategy. Data consistency leverages implicit GROG, which grids non-Cartesian data onto a Cartesian grid with an implicitly learned kernel, enabling FFT-based updates with minimal artifacts. Training proceeds in three stages: (1) pretraining a denoiser with extensive data augmentation, (2) greedy per-iteration unrolled training, and (3) final fine-tuning with gradient checkpointing. Together, these stages make large-scale 3D unrolled learning feasible within a reasonable compute budget. On a large in vivo dataset with retrospective undersampling, SPUR-iG improves subspace coefficient maps quality and quantitative accuracy at 1-mm isotropic resolution compared with LLR and a hybrid 2D/3D unrolled baseline. Whole-brain reconstructions complete in under 15-seconds, with up to $\times$111 speedup for 2-minute acquisitions. Notably, $T_1$ maps with our method from 30-second scans achieve accuracy on par with or exceeding LLR reconstructions from 2-minute scans. Overall, the framework improves both accuracy and speed in large-scale 3D MRF reconstruction, enabling efficient and reliable accelerated quantitative imaging.

</details>


### [396] [Entropy-Guided Agreement-Diversity: A Semi-Supervised Active Learning Framework for Fetal Head Segmentation in Ultrasound](https://arxiv.org/abs/2601.17460)
*Fangyijie Wang,Siteng Ma,Guénolé Silvestre,Kathleen M. Curran*

Main category: eess.IV

TL;DR: 本文提出了一种名为EGAD的两阶段主动学习采样器，结合熵和一致性学习策略，用于在有限标签数据的胎儿超声图像分割任务中提高深度学习模型的性能，实验结果显示在公共数据集上取得了优异的分割效果。


<details>
  <summary>Details</summary>
Motivation: 由于隐私和法规限制，胎儿超声（US）数据获取有限，阻碍了深度学习（DL）模型的训练。现有的半监督学习（SSL）方法依赖于随机抽样，可能因同质性标签数据过拟合而导致模型性能不佳。

Method: 提出了一种两阶段主动学习（AL）采样器EGAD，用于胎儿头部分割。第一阶段使用预测熵选择不确定性最高的样本，第二阶段结合余弦相似度和互信息，利用一致性-多样性分数进一步精炼样本选择。此外，SSL框架采用特征下采样的一致性学习策略来提升分割性能。

Result: 在两个公共胎儿头部分割数据集上，使用5%和10%的标签数据训练，SSL-EGAD分别取得了94.57%和96.32%的平均Dice分数，优于现有的SSL模型，并在不同孕周的数据上表现出一致的鲁棒性。

Conclusion: EGAD是一种有效的两阶段主动学习采样策略，结合一致性学习，能够显著提升在标签数据稀缺的胎儿超声图像分割任务中的模型性能，克服了现有SSL方法的局限性。

Abstract: Fetal ultrasound (US) data is often limited due to privacy and regulatory restrictions, posing challenges for training deep learning (DL) models. While semi-supervised learning (SSL) is commonly used for fetal US image analysis, existing SSL methods typically rely on random limited selection, which can lead to suboptimal model performance by overfitting to homogeneous labeled data. To address this, we propose a two-stage Active Learning (AL) sampler, Entropy-Guided Agreement-Diversity (EGAD), for fetal head segmentation. Our method first selects the most uncertain samples using predictive entropy, and then refines the final selection using the agreement-diversity score combining cosine similarity and mutual information. Additionally, our SSL framework employs a consistency learning strategy with feature downsampling to further enhance segmentation performance. In experiments, SSL-EGAD achieves an average Dice score of 94.57\% and 96.32\% on two public datasets for fetal head segmentation, using 5\% and 10\% labeled data for training, respectively. Our method outperforms current SSL models and showcases consistent robustness across diverse pregnancy stage data. The code is available on \href{https://github.com/13204942/Semi-supervised-EGAD}{GitHub}.

</details>


### [397] [In-situ On-demand Digital Image Correlation: A New Data-rich Characterization Paradigm for Deformation and Damage Development in Solids](https://arxiv.org/abs/2601.17545)
*Ravi Venkata Surya Sai Mogilisetti,Partha Pratim Das,Rassel Raihan,Shiyao Lin*

Main category: eess.IV

TL;DR: 提出了一种名为“就地按需”（ISOD）的数字图像相关（DIC）分析新范式，通过动态调整相机帧率来提高数据丰富性，特别是在材料变形或裂纹生长等过程中，同时减少存储和分析时间。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统DIC方法在捕捉快速变形或损伤过程中图像数据量不足以及存储和分析开销大的问题，同时提高实时性。

Method: 将相机控制集成到DIC流程中，根据变形程度或变形速率动态地增加相机的成像帧率，而在小变形或慢速变形时保持较低的帧率，实现实时变形分析、可视化和闭环相机控制。

Result: 与传统DIC相比，ISOD DIC在裂纹扩展过程中捕获的图像数量增加了约178%，显著提高了数据丰富性，同时避免了过度的存储和分析开销。

Conclusion: ISOD DIC是一种有效的新型DIC分析方法，通过就地按需捕获图像，能够在不增加过多存储和分析负担的情况下，显著增强数据丰富性，有利于更精细地表征材料的本构行为和损伤机制。

Abstract: Digital image correlation (DIC) has become one of the most popular methods for deformation characterization in experimental mechanics. DIC is based on optical images taken during experimentation and post-test image processing. Its advantages include the capability to capture full-field deformation in a non-contact manner, the robustness in characterizing excessive deformation induced by events such as yielding and cracking, and the versatility to integrate optical cameras with a variety of open-source and commercial codes. In this paper, we developed a new paradigm of DIC analysis by integrating camera control into the DIC process flow. The essential idea is to dynamically increase the camera imaging frame rate with excessive deformation or deformation rate, while maintaining a relatively low imaging frame rate with small and slow deformation. We refer to this new DIC paradigm as in-situ on-demand (ISOD) DIC. ISOD DIC enables real-time deformation analysis, visualization, and closed-loop camera control. ISOD DIC has captured approximately 178% more images than conventional DIC for samples undergoing crack growth due to its dynamically adjusted frame rate, with the potential to significantly enhance data richness for damage inspection without consuming excessive storage space and analysis time, thereby benefiting the characterization of intrinsic constitutive behaviors and damage mechanisms

</details>


### [398] [Fast Multirate Encoding for 360° Video in OMAF Streaming Workflows](https://arxiv.org/abs/2601.17568)
*Amritha Premkumar,Christian Herglotz*

Main category: eess.IV

TL;DR: 本文提出了一种快速多速率编码策略，通过跨 QP 和分辨率重用编码器分析信息来加速 8K 360 度视频的编码，实验证明该策略能显著减少编码时间，同时对率失真性能影响很小。


<details>
  <summary>Details</summary>
Motivation: 为超高分辨率（如 8K）360 度视频准备高质量的 HTTP 自适应流内容，需要编码大量不同分辨率和 QP 的视频表示，这在计算上非常耗时。

Method: 研究了两种跨分辨率信息重用管道：(i) 严格的 HD -> 4K -> 8K 级联，并进行缩放分析重用；(ii) 分辨率锚定方案，每个分辨率的编码以其自身最高比特率参考初始化，然后指导依赖编码。同时将这两种管道应用于等距圆柱投影（ERP）和立方体贴图投影（CMP）两种内容。

Result: 实验结果表明，分层分析重用显著加速了 HEVC 编码，对 ERP 内容编码时间减少了约 33%-59%，对 CMP 内容平均减少了约 51%，BDET 增益接近 -50%，墙上时钟速度提升高达 4.2 倍。

Conclusion: 分层分析重用策略能够有效加速 HEVC 编码，同时对率失真性能影响极小，适用于等距圆柱投影和立方体贴图投影的 360 度内容。

Abstract: Preparing high-quality 360-degree video for HTTP Adaptive Streaming requires encoding each sequence into multiple representations spanning different resolutions and quantization parameters (QPs). For ultra-high-resolution immersive content such as 8K 360-degree video, this process is computationally intensive due to the large number of representations and the high complexity of modern codecs. This paper investigates fast multirate encoding strategies that reduce encoding time by reusing encoder analysis information across QPs and resolutions. We evaluate two cross-resolution information-reuse pipelines that differ in how reference encodes propagate across resolutions: (i) a strict HD -> 4K -> 8K cascade with scaled analysis reuse, and (ii) a resolution-anchored scheme that initializes each resolution with its own highest-bitrate reference before guiding dependent encodes. In addition to evaluating these pipelines on standard equirectangular projection content, we also apply the same two pipelines to cubemap-projection (CMP) tiling, where each 360-degree frame is partitioned into independently encoded tiles. CMP introduces substantial parallelism, while still benefiting from the proposed multirate analysis-reuse strategies. Experimental results using the SJTU 8K 360-degree dataset show that hierarchical analysis reuse significantly accelerates HEVC encoding with minimal rate-distortion impact across both equirectangular and CMP-tiled content, yielding encoding-time reductions of roughly 33%-59% for ERP and about 51% on average for CMP, with Bjontegaard Delta Encoding Time (BDET) gains approaching -50% and wall-clock speedups of up to 4.2x.

</details>


### [399] [A Capsule-Sized Multi-Wavelength Wireless Optical System for Edge-AI-Based Classification of Gastrointestinal Bleeding Flow Rate](https://arxiv.org/abs/2601.17752)
*Yunhao Bian,Dawei Wang,Mingyang Shen,Xinze Li,Jiayi Shi,Ziyao Zhou,Tiancheng Cao,Hen-Wei Huang*

Main category: eess.IV

TL;DR: 本研究开发了一种胶囊大小、多波长光学传感无线平台，利用透射光谱和低功耗边缘人工智能，能够对胃肠道出血流速进行数量级分类，准确率高达98.75%，并能区分其他干扰，显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 内窥镜治疗后胃肠道再出血（尤其在72小时内）是导致早期发病率和死亡率的主要原因。现有的非侵入性监测方法只能进行二元出血检测，无法量化出血严重程度或血流动力学，不利于高风险时期的临床决策。

Method: 开发了一种胶囊大小、多波长光学传感无线平台，结合透射光谱技术和低功耗边缘人工智能。该系统进行时程、多光谱测量，并使用轻量级二维卷积神经网络进行设备端流速分类。通过基于物理的验证确认了其与血红蛋白吸收行为的一致性。

Result: 在模拟胃部条件的体外实验中，该方法在不同出血流速水平下实现了98.75%的总体分类准确率，并能有效区分其他胃肠道干扰。通过在胶囊电子设备上进行嵌入式推理，能耗降低约88%，延长了电池供电运行时间。

Conclusion: 该平台将胶囊式诊断从二元出血检测扩展到连续、位点特异性的出血严重程度评估，有潜力支持对临床显著再出血的早期识别，并为内窥镜治疗后监测期间的及时再干预提供依据。

Abstract: Post-endoscopic gastrointestinal (GI) rebleeding frequently occurs within the first 72 hours after therapeutic hemostasis and remains a major cause of early morbidity and mortality. Existing non-invasive monitoring approaches primarily provide binary blood detection and lack quantitative assessment of bleeding severity or flow dynamic, limiting their ability to support timely clinical decision-making during this high-risk period. In this work, we developed a capsule-sized, multi-wavelength optical sensing wireless platform for order-of-magnitude-level classification of GI bleeding flow rate, leveraging transmission spectroscopy and low-power edge artificial intelligence. The system performs time-resolved, multi-spectral measurements and employs a lightweight two-dimensional convolutional neural network for on-device flow-rate classification, with physics-based validation confirming consistency with wavelength-dependent hemoglobin absorption behavior. In controlled in vitro experiments under simulated gastric conditions, the proposed approach achieved an overall classification accuracy of 98.75% across multiple bleeding flow-rate levels while robustly distinguishing diverse non-blood gastrointestinal interference. By performing embedded inference directly on the capsule electronics, the system reduced overall energy consumption by approximately 88% compared with continuous wireless transmission of raw data, making prolonged, battery-powered operation feasible. Extending capsule-based diagnostics beyond binary blood detection toward continuous, site-specific assessment of bleeding severity, this platform has the potential to support earlier identification of clinically significant rebleeding and inform timely re-intervention during post-endoscopic surveillance.

</details>


### [400] [Dominant Sets Based Band Selection in Hyperspectral Imagery](https://arxiv.org/abs/2601.18034)
*Onur Haliloğlu,Ufuk Sakarya,B. Uğur Töreyin,Orhan Gazi*

Main category: eess.IV

TL;DR: 提出了一种基于“优势集”的假设光谱图像带选择框架，通过对光谱带进行聚类并从每个聚类中选择代表性波段来减少数据量并提高分类精度。


<details>
  <summary>Details</summary>
Motivation: 假设光谱图像数据量巨大，导致传输延迟、处理困难和 Hughes 现象（由于训练样本不足）。因此需要一种有效的方法来减少数据量并选择最相关的光谱带。

Method: 提出了一种基于“优势集”的带选择框架。该框架将光谱带聚类，然后从每个聚类中选择最能代表该聚类的波段，形成一个优化的波段集合。该方法在小规模数据上进行特征选择，计算复杂度低。

Result: 在 Pavia 和 Salinas 数据集上的实验结果表明，该框架在分类精度方面优于现有的特征选择方法。

Conclusion: 该研究提出了一个通用的假设光谱图像带选择框架，可以在不处理整个数据集的情况下，为分类任务定义所需的最优波段集合，有效解决了数据量过大带来的传输、处理和 Hughes 现象问题，并提高了分类性能。

Abstract: Hyperspectral imagery is composed of huge amount of data which creates significant transmission latencies for communication systems. It is vital to decrease the huge data size before transmitting the Hyperspectral imagery. Besides, large data size leads to processing problems, especially in practical applications. Moreover, due to the lack of sufficient training samples, Hughes phenomena occur with huge amount of data. Feature selection can be used in order to get rid of huge data problems. In this paper, a band selection framework is introduced to reduce the data size and to find out the most proper spectral bands for a specific application. The method is based on finding "dominant sets" in hyperspectral data, so that spectral bands are clustered. From each cluster, the band that reflects the cluster behavior the most is selected to form the most valuable band set in the spectra for a specific application. The proposed feature selection method has low computational complexity since it performs on a small size of data when realizing the feature selection. The aim of the study is to find out a general framework that can define required bands for classification without requiring to perform on the whole data set. Results on Pavia and Salinas datasets show that the proposed framework performs better than the state-of-the-art feature selection methods in terms of classification accuracy.

</details>
