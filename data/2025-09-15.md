<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 22]
- [cs.CV](#cs.CV) [Total: 64]
- [cs.CL](#cs.CL) [Total: 52]
- [cs.RO](#cs.RO) [Total: 22]
- [eess.SY](#eess.SY) [Total: 14]
- [eess.IV](#eess.IV) [Total: 7]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Human-AI Collaboration Increases Efficiency in Regulatory Writing](https://arxiv.org/abs/2509.09738)
*Umut Eser,Yael Gozin,L. Jay Stallons,Ari Caroline,Martin Preusse,Brandon Rice,Scott Wright,Andrew Robertson*

Main category: cs.AI

TL;DR: 本研究评估了一个大型语言模型（LLM）平台AutoIND在IND（新药临床试验申请）非临床总结撰写中的效率和质量。结果显示，AutoIND能大幅缩短初稿撰写时间（约97%），且未发现关键监管错误，但仍需专家进行最终润色以达到提交标准。


<details>
  <summary>Details</summary>
Motivation: IND申请的准备工作耗时且高度依赖专业知识，这减缓了早期临床开发进程。

Method: 研究直接记录了AutoIND生成IND非临床书面总结（eCTD模块2.6.2、2.6.4、2.6.6）的起草时间。作为对比，通过经验丰富的监管撰稿人（≥6年经验）估算了手动撰写FDA已批准IND总结所需的时间，作为行业基准。质量评估由一位盲审的监管撰稿评估员根据七个预设类别（正确性、完整性、简洁性、一致性、清晰度、冗余和重点）进行。每个子标准评分0-3并标准化为百分比。关键监管错误定义为任何可能改变监管解释的错误或遗漏。

Result: AutoIND将初稿撰写时间缩短了约97%（对于IND-1，从约100小时减少到3.7小时；对于IND-2，减少到2.6小时）。IND-1和IND-2的质量得分分别为69.6%和77.9%。未检测到关键监管错误，但发现了在重点、简洁性和清晰度方面的不足。

Conclusion: AutoIND可以显著加速IND的起草过程，但专业的监管撰稿人仍然必不可少，以将产出完善至可提交的质量。识别出的系统性缺陷为模型有针对性的改进提供了路线图。

Abstract: Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.

</details>


### [2] [Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture](https://arxiv.org/abs/2509.09775)
*Aleksandr Boldachev*

Main category: cs.AI

TL;DR: 本文提出了boldsea架构，它利用可执行本体（作为动态结构直接控制过程执行的语义模型）来建模复杂的动态系统。该方法通过将事件语义与数据流架构结合，解决了传统业务流程管理（BPM）系统和面向对象语义技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统业务流程管理（BPM）系统和面向对象语义技术在建模复杂动态系统时存在局限性，促使研究人员寻求一种更有效的方法。

Method: boldsea架构通过可执行本体（即作为动态结构直接控制过程执行的语义模型）来建模系统。它将事件语义与数据流架构集成，并提出了形式化的boldsea语义语言（BSL）及其BNF语法。boldsea引擎直接解释语义模型作为可执行算法，无需编译。

Result: boldsea方法解决了传统BPM系统和面向对象语义技术的局限性。它支持在运行时修改事件模型，确保了时间透明性，并在统一的语义框架内无缝融合了数据和业务逻辑。

Conclusion: boldsea提供了一种强大的架构，通过使用可执行本体和直接解释的语义模型，有效地建模复杂动态系统，克服了现有技术的缺点，并提供了运行时灵活性和数据与业务逻辑的统一性。

Abstract: This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.

</details>


### [3] [How well can LLMs provide planning feedback in grounded environments?](https://arxiv.org/abs/2509.09790)
*Yuxuan Li,Victor Zhong*

Main category: cs.AI

TL;DR: 本研究评估了大型语言模型（LLMs）和视觉语言模型（VLMs）在符号、语言和连续控制环境中提供规划反馈的能力。结果表明，基础模型能提供多样化的高质量反馈，且更大、更具推理能力的模型表现更优，但复杂环境会降低反馈质量。


<details>
  <summary>Details</summary>
Motivation: 在具身环境中学习规划通常需要精心设计的奖励函数或高质量的演示。最近研究表明，预训练的基础模型（如LLMs和VLMs）捕获了对规划有用的背景知识，这可以减少策略学习所需的奖励设计和演示量。

Method: 研究评估了LLMs和VLMs在符号、语言和连续控制环境中的反馈能力。考虑了多种规划反馈类型，包括二元反馈、偏好反馈、行动建议、目标建议和增量行动反馈。同时，还考虑了影响反馈性能的推理方法，包括上下文学习、思维链和对环境动态的访问。

Result: 研究发现，基础模型可以在不同领域提供多样化的高质量反馈。此外，更大、更具推理能力的模型始终能提供更准确的反馈，表现出更少的偏差，并从增强的推理方法中获益更多。然而，对于动态复杂或状态空间和行动空间连续的环境，反馈质量会下降。

Conclusion: 基础模型在为规划提供反馈方面具有潜力，其性能受到模型规模、推理能力、推理方法以及环境复杂性的影响。

Abstract: Learning to plan in grounded environments typically requires carefully
designed reward functions or high-quality annotated demonstrations. Recent
works show that pretrained foundation models, such as large language models
(LLMs) and vision language models (VLMs), capture background knowledge helpful
for planning, which reduces the amount of reward design and demonstrations
needed for policy learning. We evaluate how well LLMs and VLMs provide feedback
across symbolic, language, and continuous control environments. We consider
prominent types of feedback for planning including binary feedback, preference
feedback, action advising, goal advising, and delta action feedback. We also
consider inference methods that impact feedback performance, including
in-context learning, chain-of-thought, and access to environment dynamics. We
find that foundation models can provide diverse high-quality feedback across
domains. Moreover, larger and reasoning models consistently provide more
accurate feedback, exhibit less bias, and benefit more from enhanced inference
methods. Finally, feedback quality degrades for environments with complex
dynamics or continuous state spaces and action spaces.

</details>


### [4] [A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes](https://arxiv.org/abs/2509.09794)
*Jackson Eshbaugh,Chetan Tiwari,Jorge Silveyra*

Main category: cs.AI

TL;DR: 本文提出一个模块化的多模态框架，利用生成式AI从公开住宅信息和图像中生成能源模型所需的数据，以解决数据获取困难的问题。


<details>
  <summary>Details</summary>
Motivation: 计算模型在能源建模研究中日益重要，但其需要大量数据，其中一些数据难以获取、成本高昂或涉及隐私问题。

Method: 引入一个模块化的多模态框架，利用生成式AI从公开可访问的住宅信息和图像中生成所需数据。同时提供一个演示该框架的管道，并评估其生成式AI组件。

Result: 实验表明，该框架使用AI避免了生成模型中的常见问题，并能生成逼真、带有标签的数据。

Conclusion: 通过减少对昂贵或受限数据源的依赖，该框架为更易访问和可复现的能源建模研究铺平了道路。

Abstract: Computational models have emerged as powerful tools for energy modeling
research, touting scalability and quantitative results. However, these models
require a plethora of data, some of which is inaccessible, expensive, or raises
privacy concerns. We introduce a modular multimodal framework to produce this
data from publicly accessible residential information and images using
generative artificial intelligence (AI). Additionally, we provide a pipeline
demonstrating this framework, and we evaluate its generative AI components. Our
experiments show that our framework's use of AI avoids common issues with
generative models. Our framework produces realistic, labeled data. By reducing
dependence on costly or restricted data sources, we pave a path towards more
accessible and reproducible research.

</details>


### [5] [Towards a Common Framework for Autoformalization](https://arxiv.org/abs/2509.09810)
*Agnieszka Mensfelt,David Tena Cucala,Santiago Franco,Angeliki Koutsoukou-Argyraki,Vince Trencsenyi,Kostas Stathis*

Main category: cs.AI

TL;DR: 本文回顾了自动形式化（广义）的概念，并提出了一个统一框架，旨在整合由大型语言模型驱动的不同研究领域，以加速人工智能的发展。


<details>
  <summary>Details</summary>
Motivation: 尽管有相似的任务，但将非正式输入转化为形式逻辑表示的不同研究领域（包括数学形式化和LLM驱动的推理/规划）独立发展，限制了方法、基准和理论框架的共享，从而阻碍了进展。

Method: 通过审查显性或隐性的自动形式化实例，并提出一个统一的框架。

Result: 论文提供了对自动形式化相关研究的综述，并提出了一个旨在促进跨领域交流的统一框架。

Conclusion: 统一这些研究领域将促进跨学科交流，加速下一代人工智能系统的发展。

Abstract: Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.

</details>


### [6] [Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation](https://arxiv.org/abs/2509.09848)
*Nana Han,Dong Liu,Tomas Norton*

Main category: cs.AI

TL;DR: 本研究开发了一个基于RAG的智能知识助手系统，通过表格文本化和决策树文本化等结构化知识处理方法，解决了大语言模型在山羊养殖健康管理中处理异构数据的局限性，并取得了高准确率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在许多行业中被认为是宝贵的知识交流工具，但在畜牧业，尤其是山羊养殖中应用有限，主要受限于知识来源的可用性、多样性和复杂性。

Method: 本研究引入了一个智能知识助手系统以支持山羊养殖的健康管理。该系统利用检索增强生成（RAG），并提出了表格文本化和决策树文本化两种结构化知识处理方法，以增强LLM对异构数据格式的理解。在此基础上，建立了特定领域的山羊养殖知识库（涵盖疾病防治、营养管理、饲养管理、羊奶管理和基础养殖知识五个领域），并集成了在线搜索模块以实现实时信息检索。通过六项消融实验评估了系统性能。

Result: 异构知识融合方法取得了最佳结果，在验证集上的平均准确率为87.90%，在测试集上为84.22%。在基于文本、表格和决策树的问答任务中，准确率始终超过85%，验证了模块化设计中结构化知识融合的有效性。错误分析表明遗漏是主要的错误类别。

Conclusion: 本研究结果突显了所提出的系统在山羊养殖实际应用中的鲁棒性和可靠性。

Abstract: Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.

</details>


### [7] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型（LLM）作为活跃参与者协助人类完成任务的能力，特别是在UNO纸牌游戏中帮助另一名玩家获胜。结果显示，虽然所有模型都优于随机基线，但很少有模型能显著帮助另一名玩家。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）被寄予厚望，不仅能回答问题，还能在各种任务中提供有用的指导，甚至作为活跃参与者协助人类。本文旨在探究LLM代理作为活跃参与者，能否真正帮助他人实现目标。

Method: 研究人员让LLM参与UNO纸牌游戏，但其目标不是获胜，而是帮助另一名玩家获胜。他们开发了一个工具，使仅解码器LLM能作为代理参与RLCard游戏环境。这些模型接收完整的游戏状态信息，并使用两种不同的提示策略通过简单的文本提示进行响应。研究评估了从小型（10亿参数）到大型（700亿参数）的模型，并探讨了模型规模对性能的影响。

Result: 所有模型在玩UNO时都能成功超越随机基线。然而，只有少数模型能够显著帮助另一名玩家获胜。

Conclusion: 尽管大型语言模型在玩UNO时表现优于随机水平，但它们作为活跃参与者显著协助另一名玩家实现目标（即获胜）的能力有限。这表明LLM作为积极协作伙伴的潜力仍有待进一步探索和提升。

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [8] [The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science](https://arxiv.org/abs/2509.09915)
*Woong Shin,Renan Souza,Daniel Rosendo,Frédéric Suter,Feiyi Wang,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.AI

TL;DR: 本文提出一个概念框架和架构蓝图，旨在利用AI智能体将科学工作流从手动协调转变为自主、分布式实验室，以加速科学发现。


<details>
  <summary>Details</summary>
Motivation: 现代科学发现需要协调分布式和异构资源，使研究人员耗费精力在工作流协调而非科学研究上。AI智能体带来了加速科学发现的新机遇，但其在实际中的实现和整合方式尚不明确。

Method: 作者提出了一个概念框架，描述了工作流在“智能性”（从静态到智能）和“组合性”（从单一到群体）两个维度上的演进路径。在此基础上，他们进一步提出了一个架构蓝图。

Result: 提出了一个从当前工作流管理系统到完全自主、分布式科学实验室的演进路径概念框架，以及一个具体的架构蓝图。该蓝图有望实现100倍的发现加速和变革性的科学工作流。

Conclusion: 该概念框架和架构蓝图为社区提供了下一步的方向，以利用自主科学的机遇，加速科学发现并实现变革性的科学工作流。

Abstract: Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.

</details>


### [9] [A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments](https://arxiv.org/abs/2509.09919)
*Franklin Yiu,Mohan Lu,Nina Li,Kevin Joseph,Tianxu Zhang,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 该研究将WaveFunctionCollapse (WFC) 重构为马尔可夫决策过程 (MDP)，以解耦程序化内容生成中的局部约束满足与全局目标优化，并证明了其优于联合优化方法。


<details>
  <summary>Details</summary>
Motivation: 程序化内容生成需要同时满足设计师指定的目标和底层瓦片集隐含的邻接约束。联合优化这两种约束和目标具有挑战性。

Method: 将WaveFunctionCollapse (WFC) 重新表述为马尔可夫决策过程 (MDP)。WFC的传播机制用于强制满足约束，而外部优化算法则专注于目标最大化。

Result: 在不同难度和多个领域中，优化WFC-MDP的方法始终优于传统联合优化全局指标和局部瓦片放置的演化方法。随着任务复杂性增加，联合优化方法表现更差。

Conclusion: 将局部约束满足与全局目标优化解耦具有显著优势。

Abstract: Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.

</details>


### [10] [Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae](https://arxiv.org/abs/2509.09982)
*Stav Armoni-Friedmann,Hana Chockler,David A. Kelly*

Main category: cs.AI

TL;DR: 本文提出了一种基于实际因果关系的形式化变量重要性度量，用于评估解释性AI（XAI）工具在表格数据和布尔函数预测上的表现。同时，引入了一种新的XAI工具B-ReX，并证明其在大型基准测试中优于其他黑盒XAI工具。


<details>
  <summary>Details</summary>
Motivation: 由于解释的主观性，评估解释性AI（XAI）方法通常具有挑战性。特别是在表格数据和AI模型预测布尔函数值的使用场景中，需要更客观、精确的评估方法。

Method: 研究人员提出了一个基于实际因果关系的变量重要性形式化度量。他们利用此度量来评估现有最先进的XAI工具。此外，他们基于现有工具ReX开发并提出了一个新的XAI工具B-ReX。

Result: B-ReX在大型基准测试中表现优于其他黑盒XAI工具。具体而言，在随机的10值布尔函数上，B-ReX实现了0.072 ± 0.012的Jensen-Shannon散度。

Conclusion: 该研究成功地提出了一种基于实际因果关系的变量重要性度量，为XAI工具的评估提供了更客观的方法。同时，新提出的B-ReX工具在布尔函数预测任务上展现出优越的解释性能。

Abstract: Evaluating explainable AI (XAI) approaches is a challenging task in general,
due to the subjectivity of explanations. In this paper, we focus on tabular
data and the specific use case of AI models predicting the values of Boolean
functions. We extend the previous work in this domain by proposing a formal and
precise measure of importance of variables based on actual causality, and we
evaluate state-of-the-art XAI tools against this measure. We also present a
novel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it
is superior to other black-box XAI tools on a large-scale benchmark.
Specifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\pm$ 0.012
on random 10-valued Boolean formulae

</details>


### [11] [GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method](https://arxiv.org/abs/2509.10018)
*Hailong Yang,Renhuo Zhao,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: 本文提出了一种名为GAMA的通用匿名化多智能体系统，旨在解决基于LLM的多智能体系统在处理隐私数据时无法安全使用远程LLM的问题。GAMA通过工作空间划分和匿名化机制保护隐私，并通过DRKE和DLE模块减少匿名化导致的语义损失，在任务处理和隐私保护方面均表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的快速发展，LLM-based多智能体系统（MAS）在语言理解和生成方面展现出卓越能力。然而，高性能LLM通常部署在远程服务器上。当任务涉及隐私数据时，现有MAS无法在不实施隐私保护机制的情况下安全地利用这些LLM。

Method: 本文提出了通用匿名化多智能体系统（GAMA）。GAMA将智能体的工作空间划分为私有空间和公共空间，并通过匿名化机制保护隐私。在私有空间处理敏感数据，而在公共空间仅使用匿名化数据。为缓解匿名化造成的语义损失，GAMA集成了两个关键模块：基于领域规则的知识增强（DRKE）和基于反驳的逻辑增强（DLE）。

Result: GAMA在两个公共问答数据集（Trivia Creative Writing和Logic Grid Puzzle）上进行了评估，结果表明GAMA的性能优于现有最先进的模型。为进一步评估其隐私保护能力，设计了两个新数据集（知识隐私保护和逻辑隐私保护），最终结果突出显示GAMA在任务处理和隐私保护方面均具有卓越的有效性。

Conclusion: GAMA系统成功地解决了LLM-based多智能体系统在处理隐私数据时面临的安全挑战，通过创新的匿名化机制和语义增强模块，实现了在保持高性能任务处理能力的同时，有效保护用户隐私的目标。

Abstract: With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.

</details>


### [12] [XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph](https://arxiv.org/abs/2509.10054)
*Hailong Yang,Mingxian Gu,Jianqi Wang,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: XAgents是一个统一的多智能体协作框架，它利用多极任务处理图和IF-THEN规则来解决大型语言模型（LLM）增强的多智能体系统（MAS）在处理复杂、不确定任务时规划不当的问题，并在知识型和逻辑型问答任务中超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）极大地提升了多智能体系统（MAS）的能力，但MAS在处理高度复杂且不确定的任务时，其任务规划能力仍面临挑战，常导致误导或错误的输出，从而阻碍任务执行。

Method: 本文提出了XAgents框架，它基于多极任务处理图和IF-THEN规则构建。该框架利用多极任务处理图实现动态任务规划和处理任务不确定性。在子任务处理过程中，它集成领域特定的IF-THEN规则来约束智能体行为，同时利用全局规则增强智能体之间的协作。

Result: XAgents在三个不同数据集上的表现评估显示，它在知识型和逻辑型问答任务中，持续超越了最先进的单智能体和多智能体方法。

Conclusion: XAgents通过结合多极任务处理图和IF-THEN规则，有效解决了多智能体系统在复杂不确定任务规划中的挑战，显著提升了任务执行的准确性和效率，展现出优越的性能。

Abstract: The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.

</details>


### [13] [AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework](https://arxiv.org/abs/2509.10104)
*Sofia Vei,Paolo Giudici,Pavlos Sermpezis,Athena Vakali,Adelaide Emma Bernardelli*

Main category: cs.AI

TL;DR: 该研究提出了一种以人为中心、危害严重性自适应的AI风险评估方法——AI Harmonics，它包含一个新的AI危害评估指标（AIH），利用序数严重性数据来捕捉相对影响，并基于经验事件数据识别和优先处理AI危害。


<details>
  <summary>Details</summary>
Motivation: 现有AI风险评估模型侧重内部合规，忽视了多样化的利益相关者视角和真实世界后果，而AI的绝对主导地位带来了前所未有的社会危害和风险。

Method: 提出了一种以人为中心、危害严重性自适应的方法（AI Harmonics），该方法基于经验事件数据。引入了一个新颖的AI危害评估指标（AIH），利用序数严重性数据来捕捉相对影响。结合了稳健的通用方法论与数据驱动、利益相关者感知的框架，用于探索和优先排序AI危害。

Result: 对标注事件数据的实验证实，政治和物理危害的集中度最高，因此需要紧急缓解：政治危害侵蚀公众信任，而物理危害构成严重甚至危及生命的风险。AI Harmonics能持续识别不均衡的危害分布。

Conclusion: AI Harmonics方法具有现实世界相关性，能够帮助政策制定者和组织有效针对性地进行缓解工作，尤其是在识别不均衡危害分布和优先处理政治与物理危害方面。

Abstract: The absolute dominance of Artificial Intelligence (AI) introduces
unprecedented societal harms and risks. Existing AI risk assessment models
focus on internal compliance, often neglecting diverse stakeholder perspectives
and real-world consequences. We propose a paradigm shift to a human-centric,
harm-severity adaptive approach grounded in empirical incident data. We present
AI Harmonics, which includes a novel AI harm assessment metric (AIH) that
leverages ordinal severity data to capture relative impact without requiring
precise numerical estimates. AI Harmonics combines a robust, generalized
methodology with a data-driven, stakeholder-aware framework for exploring and
prioritizing AI harms. Experiments on annotated incident data confirm that
political and physical harms exhibit the highest concentration and thus warrant
urgent mitigation: political harms erode public trust, while physical harms
pose serious, even life-threatening risks, underscoring the real-world
relevance of our approach. Finally, we demonstrate that AI Harmonics
consistently identifies uneven harm distributions, enabling policymakers and
organizations to target their mitigation efforts effectively.

</details>


### [14] [Virtual Agent Economies](https://arxiv.org/abs/2509.10147)
*Nenad Tomasev,Matija Franklin,Joel Z. Leibo,Julian Jacobs,William A. Cunningham,Iason Gabriel,Simon Osindero*

Main category: cs.AI

TL;DR: 本文提出了“沙盒经济”框架来分析新兴的AI智能体经济，探讨其起源和与人类经济的独立程度。文章指出，当前趋势指向一个自发、庞大且高度渗透的AI智能体经济，这既带来前所未有的协作机会，也伴随系统性经济风险和不平等加剧等挑战。为此，作者讨论了旨在确保AI智能体市场安全可控的设计方案，强调需主动设计可控的智能体市场以促进人类福祉。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI智能体的快速普及，一个新的经济层正在形成，其中智能体以超越人类直接监督的规模和速度进行交易和协调。这种新兴系统带来了巨大的机遇，但也伴随着系统性经济风险和不平等加剧等挑战，因此需要一个框架来分析并提出应对方案。

Method: 作者提出了“沙盒经济”作为分析新兴AI智能体经济的框架，并从“起源”（自发 vs. 有意）和“与既有经济的独立程度”（可渗透 vs. 不可渗透）两个维度对其进行描述。在此基础上，文章讨论了多种可能的设计选择，以引导AI智能体市场安全可控，包括：用于公平资源分配和偏好解决的拍卖机制、为实现集体目标而设计的AI“任务经济”，以及确保信任、安全和问责所需的社会技术基础设施。

Result: 研究发现，当前的轨迹正指向一个自发形成、庞大且高度渗透的AI智能体经济。这种发展趋势既提供了前所未有的协作机会，也带来了包括系统性经济风险和不平等加剧在内的重大挑战。

Conclusion: 为了确保即将到来的技术变革能够符合人类的长期集体繁荣，我们必须主动设计可控的智能体市场。通过采纳公平的资源分配机制、设计集体目标驱动的“任务经济”以及构建健全的社会技术基础设施，可以有效引导AI智能体经济，使其安全且有益。

Abstract: The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.

</details>


### [15] [Online Robust Planning under Model Uncertainty: A Sample-Based Approach](https://arxiv.org/abs/2509.10162)
*Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman*

Main category: cs.AI

TL;DR: 本文提出鲁棒稀疏采样（RSS），一种用于鲁棒马尔可夫决策过程（RMDPs）的在线规划算法，具有有限样本理论性能保证，能有效处理模型不确定性。


<details>
  <summary>Details</summary>
Motivation: 在线规划方法（如稀疏采样、MCTS）在模型通过有限数据学习时，会因近似误差导致性能下降或不安全行为。鲁棒MDPs虽能处理模型不确定性，但现有方法计算量大，不适用于实时应用。

Method: 引入鲁棒稀疏采样（RSS）算法，这是首个具有有限样本理论性能保证的RMDPs在线规划算法。RSS通过利用样本平均近似（SAA）的效率和理论特性，计算鲁棒价值函数，而非名义价值函数。它适用于无限或连续状态空间。

Result: RSS算法具有有限样本理论性能保证，其样本和计算复杂度与状态空间大小无关。实验结果表明，在动态不确定的环境中，RSS优于标准的稀疏采样算法。

Conclusion: RSS为RMDPs提供了一种可行的在线规划解决方案，通过计算鲁棒价值函数有效地应对模型不确定性，并具有理论性能保证和实际应用潜力。

Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.

</details>


### [16] [Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction](https://arxiv.org/abs/2509.10210)
*Marko Petković,Vlado Menkovski,Sofía Calero*

Main category: cs.AI

TL;DR: 该论文提出一个基于LLM的多智能体框架，旨在自动化多孔材料的表征过程，通过自主理解任务、规划模拟、选择力场、执行并解释结果，以克服传统模拟设置和力场选择的复杂性。


<details>
  <summary>Details</summary>
Motivation: 多孔材料的自动化表征对于加速材料发现至关重要，但目前受限于模拟设置的复杂性和合适的力场选择的困难。

Method: 研究者提出了一个多智能体框架，其中基于大型语言模型（LLM）的智能体能够自主理解表征任务、规划适当的模拟、组装相关的力场、执行模拟并解释结果以指导后续步骤。作为第一步，他们实现了一个用于文献驱动的力场提取和自动化RASPA模拟设置的多智能体系统。

Result: 初步评估结果表明，该方法具有高度的正确性和可重复性。

Conclusion: 该方法有望实现完全自主、可扩展的材料表征，从而加速材料科学的发现过程。

Abstract: Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.

</details>


### [17] [Compartmentalised Agentic Reasoning for Clinical NLI](https://arxiv.org/abs/2509.10222)
*Maël Jullien,Lei Xu,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: 本研究质疑了在临床自然语言推理（NLI）中，数据和参数扩展能带来更结构化、泛化性强的内部表示的假设。为此，我们引入了CARENLI，一个将知识获取与推理分离的系统，它通过特定家族的求解器和可审计的程序，显著提高了推理的准确性，并揭示了大型语言模型（LLMs）在推理不足时倾向于使用启发式方法。


<details>
  <summary>Details</summary>
Motivation: 普遍的假设认为，扩展数据和参数能使内部表示更结构化、更具泛化性。本研究旨在在临床自然语言推理（NLI）领域质疑这一假设，并寻求提高推理的准确性和可审计性。

Method: 本研究引入了CARENLI（临床NLI分层智能推理系统），它将临床NLI分解为四个推理家族：因果归因、组合基础、认知验证和风险状态抽象。CARENLI将知识获取与原则性推理分离，将每个前提-陈述对路由到特定家族的求解器，并通过规划器、验证器和修正器强制执行可审计的程序。

Result: 在四种大型语言模型上，CARENLI将推理准确性提高了高达42个百分点，在因果归因中达到98.0%，在风险状态抽象中达到81.2%。验证器在标记违规方面显示出接近上限的可靠性，修正器纠正了大量认知错误。剩余的失败集中在路由环节，表明家族分类是主要的瓶颈。结果表明，LLMs通常保留相关事实，但在推理不足时默认采用启发式方法。

Conclusion: CARENLI明确揭示了大型语言模型在保留事实和默认使用启发式方法之间的分离，并为更安全、可审计的推理提供了一个框架。这表明仅靠扩展规模并不能保证在临床NLI中获得结构化的内部表示。

Abstract: A common assumption holds that scaling data and parameters yields
increasingly structured, generalisable internal representations. We interrogate
this assumption in clinical natural language inference (NLI) by adopting a
benchmark decomposed into four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction,
and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI
that separates knowledge access from principled inference. CARENLI routes each
premise, statement pair to a family specific solver and enforces auditable
procedures via a planner, verifier, and refiner.
  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching
98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag
violations with near-ceiling reliability, while refiners correct a substantial
share of epistemic errors. Remaining failures cluster in routing, identifying
family classification as the main bottleneck. These results show that LLMs
often retain relevant facts but default to heuristics when inference is
underspecified, a dissociation CARENLI makes explicit while offering a
framework for safer, auditable reasoning.

</details>


### [18] [Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering](https://arxiv.org/abs/2509.10249)
*Hanna Abi Akl*

Main category: cs.AI

TL;DR: 本研究旨在通过引入形式化方法，提升小型语言模型（SLMs）在推理任务上的表现，特别是在本体工程领域，并发现使用紧凑的逻辑语言可保持强大的推理性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LMs）在推理领域存在不足，尤其是在本体工程任务中表现受限。

Method: 研究将形式化方法融入小型语言模型（SLMs）的后果，目标是利用SLMs引导本体构建。通过一系列初步实验，比较使用不同语法（包括自然语言和更紧凑的逻辑语言）表达逻辑问题对SLMs在预定义推理任务上性能的影响。

Result: 研究发现，在推理任务中，可以用更紧凑的逻辑语言替代自然语言，同时保持强大的性能。

Conclusion: 这些结果有望进一步明确SLMs在本体工程中的作用，表明形式化方法可以有效提升SLMs的推理能力。

Abstract: Recent advances in Language Models (LMs) have failed to mask their
shortcomings particularly in the domain of reasoning. This limitation impacts
several tasks, most notably those involving ontology engineering. As part of a
PhD research, we investigate the consequences of incorporating formal methods
on the performance of Small Language Models (SLMs) on reasoning tasks.
Specifically, we aim to orient our work toward using SLMs to bootstrap ontology
construction and set up a series of preliminary experiments to determine the
impact of expressing logical problems with different grammars on the
performance of SLMs on a predefined reasoning task. Our findings show that it
is possible to substitute Natural Language (NL) with a more compact logical
language while maintaining a strong performance on reasoning tasks and hope to
use these results to further refine the role of SLMs in ontology engineering.

</details>


### [19] [The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis](https://arxiv.org/abs/2509.10297)
*Eoin O'Doherty,Nicole Weinrauch,Andrew Talone,Uri Klempner,Xiaoyuan Yi,Xing Xie,Yi Zeng*

Main category: cs.AI

TL;DR: 本研究通过对六个大型语言模型（LLMs）进行定量实验，发现它们在道德困境中表现出惊人一致的价值观偏见，普遍偏爱关怀和美德，而惩罚自由主义选择。具有推理能力的模型对上下文更敏感且解释性更强。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的快速发展，如何使机器决策与人类道德价值观保持一致成为一个紧迫问题。本研究旨在探究领先的AI系统如何优先考虑道德结果，以及这如何揭示人机共生的前景。

Method: 研究通过一项定量实验进行，使用了六个大型语言模型（LLMs）。实验中，模型需要对代表五种道德框架的18个困境中的结果进行排名和评分，以评估其道德偏好。

Result: 研究发现模型之间存在惊人一致的价值观偏见：所有模型都将“关怀”和“美德”价值观的结果评为最道德，而自由主义选择则始终受到惩罚。具有推理能力的模型对上下文表现出更大的敏感性，并提供了更丰富的解释，而非推理模型则产生更统一但更不透明的判断。

Conclusion: 本研究强调了可解释性和文化意识作为关键设计原则的重要性，以指导AI走向透明、对齐和共生的未来。它为跨文化LLM的道德推理提供了大规模比较，并理论上将概率模型行为与潜在的价值编码联系起来。

Abstract: Artificial intelligence (AI) is advancing at a pace that raises urgent
questions about how to align machine decision-making with human moral values.
This working paper investigates how leading AI systems prioritize moral
outcomes and what this reveals about the prospects for human-AI symbiosis. We
address two central questions: (1) What moral values do state-of-the-art large
language models (LLMs) implicitly favour when confronted with dilemmas? (2) How
do differences in model architecture, cultural origin, and explainability
affect these moral preferences? To explore these questions, we conduct a
quantitative experiment with six LLMs, ranking and scoring outcomes across 18
dilemmas representing five moral frameworks. Our findings uncover strikingly
consistent value biases. Across all models, Care and Virtue values outcomes
were rated most moral, while libertarian choices were consistently penalized.
Reasoning-enabled models exhibited greater sensitivity to context and provided
richer explanations, whereas non-reasoning models produced more uniform but
opaque judgments. This research makes three contributions: (i) Empirically, it
delivers a large-scale comparison of moral reasoning across culturally distinct
LLMs; (ii) Theoretically, it links probabilistic model behaviour with
underlying value encodings; (iii) Practically, it highlights the need for
explainability and cultural awareness as critical design principles to guide AI
toward a transparent, aligned, and symbiotic future.

</details>


### [20] [State Algebra for Propositional Logic](https://arxiv.org/abs/2509.10326)
*Dmitry Lesnik,Tobias Schäfer*

Main category: cs.AI

TL;DR: 本文提出了状态代数（State Algebra），一个用于表示和操作命题逻辑的代数框架，具有分层表示、计算灵活性，并可扩展到概率逻辑。


<details>
  <summary>Details</summary>
Motivation: 旨在通过代数方法表示和操作命题逻辑，提供一个强大的代数计算引擎和灵活的表示形式。

Method: 引入了状态代数框架，该框架由集合（Set）、坐标（Coordinate）和行分解（Row Decomposition）三个层次的表示构成。研究了默认规约的非规范性与通过固定变量顺序实现唯一规范形式之间的权衡。

Result: 状态代数提供了灵活的表示，默认规约虽非规范，但通过固定变量顺序可获得唯一的规范形式。这种灵活性可能导致某些问题更紧凑的表示。该框架为基于搜索和知识编译算法提供了工具，并可自然扩展到概率逻辑和加权模型计数。

Conclusion: 状态代数是一个灵活且强大的命题逻辑框架，在规范性和表示紧凑性之间取得平衡，并具有扩展到概率逻辑和加权模型计数的潜力。

Abstract: This paper presents State Algebra, a novel framework designed to represent
and manipulate propositional logic using algebraic methods. The framework is
structured as a hierarchy of three representations: Set, Coordinate, and Row
Decomposition. These representations anchor the system in well-known semantics
while facilitating the computation using a powerful algebraic engine. A key
aspect of State Algebra is its flexibility in representation. We show that
although the default reduction of a state vector is not canonical, a unique
canonical form can be obtained by applying a fixed variable order during the
reduction process. This highlights a trade-off: by foregoing guaranteed
canonicity, the framework gains increased flexibility, potentially leading to
more compact representations of certain classes of problems. We explore how
this framework provides tools to articulate both search-based and knowledge
compilation algorithms and discuss its natural extension to probabilistic logic
and Weighted Model Counting.

</details>


### [21] [Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems](https://arxiv.org/abs/2509.10401)
*Alva West,Yixuan Weng,Minjun Zhu,Zhen Lin,Yue Zhang*

Main category: cs.AI

TL;DR: 本文提出A2P Scaffolding框架，将多智能体系统中的故障归因从模式识别转变为结构化因果推理任务。通过溯因、行动、预测三步推理，显著提高了故障归因的步骤级准确性，解决了现有方法反事实推理能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中的故障归因（即精确定位导致失败的关键错误步骤）是一个未解决的难题。现有方法将其视为对长对话日志的模式识别任务，导致步骤级准确率极低（低于17%），不适用于复杂系统的调试。其核心弱点在于无法进行稳健的反事实推理，即无法确定纠正单一行动是否能真正避免任务失败。

Method: 本文引入了Abduct-Act-Predict (A2P) Scaffolding，这是一个新颖的智能体框架，它将故障归因从模式识别任务转化为结构化的因果推理任务。A2P明确引导大型语言模型在一次推理过程中完成正式的三步推理：(1) 溯因 (Abduction)，推断智能体行动背后的隐藏根源；(2) 行动 (Action)，定义最小的纠正干预措施；(3) 预测 (Prediction)，模拟后续轨迹并验证干预是否解决了故障。这种结构化方法利用了整个对话的整体上下文，并对模型的分析施加了严格的因果逻辑。

Result: 在Who&When基准测试上进行了广泛实验。在算法生成的数据集上，A2P实现了47.46%的步骤级准确率，比基线（16.67%）提高了2.85倍。在更复杂的手工制作数据集上，A2P实现了29.31%的步骤准确率，比基线（12.07%）提高了2.43倍。

Conclusion: 通过从因果角度重新定义问题，A2P Scaffolding为自动化故障归因提供了一个稳健、可验证且显著更准确的解决方案。

Abstract: Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

</details>


### [22] [Mutual Information Tracks Policy Coherence in Reinforcement Learning](https://arxiv.org/abs/2509.10423)
*Cameron Reid,Wael Hafez,Amirhossein Nazeri*

Main category: cs.AI

TL;DR: 本文提出一个信息论框架，利用互信息模式来揭示强化学习的动态特征，并为部署时期的异常（如传感器和执行器故障）提供诊断方法，实现了无需修改架构的故障定位。


<details>
  <summary>Details</summary>
Motivation: 部署在真实世界环境中的强化学习智能体面临传感器故障、执行器磨损和环境变化等问题，但缺乏内在机制来检测和诊断这些故障。

Method: 本文采用信息论框架，通过分析机器人控制任务中状态-动作互信息（MI(S,A)）和状态、动作、下一状态联合互信息（MI(S,A;S')）的模式。通过受控扰动实验来模拟传感器（观测空间噪声）和执行器（动作空间噪声）故障，以评估信息度量的诊断能力。

Result: 1. 成功的学习表现出特征信息签名：状态-动作互信息（MI(S,A)）从0.84增加到2.83比特（增长238%），表明智能体对任务相关模式的注意力越来越有选择性。2. 状态、动作和下一状态的联合互信息（MI(S,A;S')）呈现倒U形曲线，在学习早期达到峰值，随后下降，表明从广泛探索到高效利用的转变。3. 信息度量可以区分诊断系统故障：观测空间噪声（传感器故障）导致所有信息通道的广泛崩溃，状态-动作耦合显著下降；而动作空间噪声（执行器故障）则选择性地破坏动作-结果的可预测性，同时保持状态-动作关系。这种差异化诊断能力实现了精确的故障定位，无需修改架构或降低性能。

Conclusion: 信息模式既是学习的特征签名，也是系统健康的诊断指标，为基于信息论原则的自适应强化学习系统奠定了基础，使其能够自主检测故障和调整策略。

Abstract: Reinforcement Learning (RL) agents deployed in real-world environments face
degradation from sensor faults, actuator wear, and environmental shifts, yet
lack intrinsic mechanisms to detect and diagnose these failures. We present an
information-theoretic framework that reveals both the fundamental dynamics of
RL and provides practical methods for diagnosing deployment-time anomalies.
Through analysis of state-action mutual information patterns in a robotic
control task, we first demonstrate that successful learning exhibits
characteristic information signatures: mutual information between states and
actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing
state entropy, indicating that agents develop increasingly selective attention
to task-relevant patterns. Intriguingly, states, actions and next states joint
mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during
early learning before declining as the agent specializes suggesting a
transition from broad exploration to efficient exploitation. More immediately
actionable, we show that information metrics can differentially diagnose system
failures: observation-space, i.e., states noise (sensor faults) produces broad
collapses across all information channels with pronounced drops in state-action
coupling, while action-space noise (actuator faults) selectively disrupts
action-outcome predictability while preserving state-action relationships. This
differential diagnostic capability demonstrated through controlled perturbation
experiments enables precise fault localization without architectural
modifications or performance degradation. By establishing information patterns
as both signatures of learning and diagnostic for system health, we provide the
foundation for adaptive RL systems capable of autonomous fault detection and
policy adjustment based on information-theoretic principles.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [23] [Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision](https://arxiv.org/abs/2509.09720)
*Akansel Cosgun,Lachlan Chumbley,Benjamin J. Meyer*

Main category: cs.CV

TL;DR: 本文介绍了澳大利亚超市物品集（ASOS），一个包含50种常见超市商品的综合数据集，提供高质量的3D纹理网格，用于机器人和计算机视觉应用的基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有数据集依赖于合成模型或专业对象，可访问性有限，缺乏真实世界的适用性，无法满足对常见物品进行基准测试的需求。

Method: ASOS包含50种来自10个不同类别的常见超市商品。通过运动结构（structure-from-motion）技术结合高分辨率成像，获取高质量的3D纹理网格，生成水密网格。

Result: ASOS提供了一个经济实惠、易于获取的常见家庭用品集合，具有高质量的3D纹理网格，适用于物体检测、姿态估计和机器人应用的基准测试。

Conclusion: ASOS数据集强调可访问性和真实世界适用性，使其在机器人和计算机视觉领域的基准测试中具有重要价值。

Abstract: This paper introduces the Australian Supermarket Object Set (ASOS), a
comprehensive dataset comprising 50 readily available supermarket items with
high-quality 3D textured meshes designed for benchmarking in robotics and
computer vision applications. Unlike existing datasets that rely on synthetic
models or specialized objects with limited accessibility, ASOS provides a
cost-effective collection of common household items that can be sourced from a
major Australian supermarket chain. The dataset spans 10 distinct categories
with diverse shapes, sizes, and weights. 3D meshes are acquired by a
structure-from-motion techniques with high-resolution imaging to generate
watertight meshes. The dataset's emphasis on accessibility and real-world
applicability makes it valuable for benchmarking object detection, pose
estimation, and robotics applications.

</details>


### [24] [A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval](https://arxiv.org/abs/2509.09721)
*Jiayi Miao,Dingxin Lu,Zhuqi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的多模态检索增强生成（MM-RAG）框架，用于自然灾害后房屋损害评估。该框架通过双分支编码器、跨模态交互和模态注意力门控机制，实现图像理解与保单匹配的协同学习，显著提高了检索准确性和损害严重性分类性能。


<details>
  <summary>Details</summary>
Motivation: 自然灾害后对房屋损害进行准确评估对于保险理赔响应和资源规划至关重要。

Method: 该研究引入了一个MM-RAG框架。它在经典RAG架构基础上，设计了一个双分支多模态编码器：图像分支采用ResNet和Transformer提取建筑损害特征；文本分支利用BERT检索器对帖子和保单进行文本向量化并构建可检索的修复索引。模型集成了一个跨模态交互模块（通过多头注意力）实现图像和文本的语义对齐。生成模块中，引入模态注意力门控机制动态控制视觉证据和文本先验信息。整个框架进行端到端训练，结合比较损失、检索损失和生成损失形成多任务优化目标，实现图像理解和保单匹配的协同学习。

Result: 结果表明，该框架在损害严重性的检索准确性和分类指标上表现优异，其中Top-1检索准确率提高了9.6%。

Conclusion: 所提出的MM-RAG框架通过整合多模态数据，有效提升了灾后房屋损害评估的准确性，在检索和损害严重性分类方面取得了显著改进，对保险和资源分配具有重要意义。

Abstract: After natural disasters, accurate evaluations of damage to housing are
important for insurance claims response and planning of resources. In this
work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)
framework. On top of classical RAG architecture, we further the framework to
devise a two-branch multimodal encoder structure that the image branch employs
a visual encoder composed of ResNet and Transformer to extract the
characteristic of building damage after disaster, and the text branch harnesses
a BERT retriever for the text vectorization of posts as well as insurance
policies and for the construction of a retrievable restoration index. To impose
cross-modal semantic alignment, the model integrates a cross-modal interaction
module to bridge the semantic representation between image and text via
multi-head attention. Meanwhile, in the generation module, the introduced modal
attention gating mechanism dynamically controls the role of visual evidence and
text prior information during generation. The entire framework takes end-to-end
training, and combines the comparison loss, the retrieval loss and the
generation loss to form multi-task optimization objectives, and achieves image
understanding and policy matching in collaborative learning. The results
demonstrate superior performance in retrieval accuracy and classification index
on damage severity, where the Top-1 retrieval accuracy has been improved by
9.6%.

</details>


### [25] [Improving MLLM Historical Record Extraction with Test-Time Image](https://arxiv.org/abs/2509.09722)
*Taylor Archibald,Tony Martinez*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的集成框架，通过多重增强、LLM转录和自定义对齐器融合，稳定了从嘈杂历史文档中进行文本提取的过程，显著提高了转录准确性。


<details>
  <summary>Details</summary>
Motivation: 从嘈杂的历史文档中进行基于大型语言模型（LLM）的文本提取存在稳定性问题。

Method: 该方法包括：1) 使用Gemini 2.0 Flash转录每个图像的多个增强变体；2) 使用自定义的Needleman-Wunsch风格对齐器融合这些输出，以生成共识转录和置信度分数；3) 构建了一个包含622份宾夕法尼亚州死亡记录的新数据集进行评估。

Result: 相对于单次基线，该方法将转录准确性提高了4个百分点。发现填充和模糊对提高准确性最有效，而网格变形扰动最适合区分高置信度和低置信度情况。

Conclusion: 所提出的方法简单、可扩展，并且可以立即部署到其他文档集合和转录模型中。

Abstract: We present a novel ensemble framework that stabilizes LLM based text
extraction from noisy historical documents. We transcribe multiple augmented
variants of each image with Gemini 2.0 Flash and fuse these outputs with a
custom Needleman Wunsch style aligner that yields both a consensus
transcription and a confidence score. We present a new dataset of 622
Pennsylvania death records, and demonstrate our method improves transcription
accuracy by 4 percentage points relative to a single shot baseline. We find
that padding and blurring are the most useful for improving accuracy, while
grid warp perturbations are best for separating high and low confidence cases.
The approach is simple, scalable, and immediately deployable to other document
collections and transcription models.

</details>


### [26] [MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance](https://arxiv.org/abs/2509.09730)
*Kaikai Zhao,Zhaoxiang Liu,Peng Wang,Xin Wang,Zhicheng Ma,Yajun Xu,Wenjing Zhang,Yibing Nan,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: 本文介绍了MITS，首个大规模多模态智能交通监控（ITS）基准数据集，旨在解决通用大型多模态模型（LMMs）在ITS领域性能受限的问题。MITS包含真实交通监控图像和丰富的ITS特定标注，通过微调主流LMMs显著提升了它们在ITS应用中的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管通用大型多模态模型（LMMs）在多种图像-文本任务中取得了显著进展，但由于缺乏专用的多模态数据集，它们在智能交通监控（ITS）领域的性能仍然有限。为了弥补这一空白，研究旨在创建一个专门针对ITS领域的大规模多模态基准数据集。

Method: 研究引入了MITS数据集，其中包含170,400张独立收集的真实世界ITS图像，这些图像来自交通监控摄像头，并标注了八个主要类别和24个子类别的ITS特定物体和事件。此外，通过系统的数据生成流程，研究生成了高质量的图像标题和500万个指令遵循的视觉问答对，涵盖了物体和事件识别、物体计数、物体定位、背景分析和事件推理这五项关键ITS任务。为验证MITS的有效性，研究人员使用该数据集对主流LMMs进行了微调。

Result: 实验结果表明，MITS显著提升了LMMs在ITS应用中的性能。例如，LLaVA-1.5的性能从0.494提升至0.905（增长83.2%），LLaVA-1.6从0.678提升至0.921（增长35.8%），Qwen2-VL从0.584提升至0.926（增长58.6%），Qwen2.5-VL从0.732提升至0.930（增长27.0%）。

Conclusion: MITS数据集及其相关工作有效地解决了LMMs在ITS领域性能受限的问题，显著提升了主流LMMs在ITS应用中的表现。研究人员已将数据集、代码和模型开源，为ITS和LMM研究提供了宝贵的资源，有助于推动这两个领域的进一步发展。

Abstract: General-domain large multimodal models (LMMs) have achieved significant
advances in various image-text tasks. However, their performance in the
Intelligent Traffic Surveillance (ITS) domain remains limited due to the
absence of dedicated multimodal datasets. To address this gap, we introduce
MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale
multimodal benchmark dataset specifically designed for ITS. MITS includes
170,400 independently collected real-world ITS images sourced from traffic
surveillance cameras, annotated with eight main categories and 24 subcategories
of ITS-specific objects and events under diverse environmental conditions.
Additionally, through a systematic data generation pipeline, we generate
high-quality image captions and 5 million instruction-following visual
question-answer pairs, addressing five critical ITS tasks: object and event
recognition, object counting, object localization, background analysis, and
event reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream
LMMs on this dataset, enabling the development of ITS-specific applications.
Experimental results show that MITS significantly improves LMM performance in
ITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905
(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to
0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the
dataset, code, and models as open-source, providing high-value resources to
advance both ITS and LMM research.

</details>


### [27] [Decomposing Visual Classification: Assessing Tree-Based Reasoning in VLMs](https://arxiv.org/abs/2509.09732)
*Sary Elmansoury,Islam Mesabah,Gerrit Großmann,Peter Neigel,Raj Bhalwankar,Daniel Kondermann,Sebastian J. Vollmer*

Main category: cs.CV

TL;DR: 本研究探讨了视觉语言模型（VLM）在细粒度分类中使用树状结构化推理的有效性，发现尽管模型能理解树知识，但树状推理表现不如标准零样本提示，不过LLM生成的描述能提升性能。


<details>
  <summary>Details</summary>
Motivation: VLM在零样本视觉分类中表现出色，但其在细粒度任务和大型分层标签空间上的性能尚未得到充分研究。研究者希望探索结构化的、基于树的推理是否能增强VLM的性能。

Method: 引入了一个将分类分解为可解释决策的框架，并使用决策树进行实现。该框架在细粒度（GTSRB）和粗粒度（CIFAR-10）数据集上进行了评估。此外，还探索了使用大型语言模型（LLM）生成的类别和图像描述来增强树提示，以改善对齐。

Result: 模型在理解树知识方面达到了98.2%的准确率。然而，基于树的推理表现始终不如标准的零样本提示。通过添加LLM生成的描述，树状推理和零样本方法的性能都得到了提升。

Conclusion: 研究结果突出了结构化推理在视觉分类中的局限性，并为设计更具可解释性的VLM系统提供了见解。

Abstract: Vision language models (VLMs) excel at zero-shot visual classification, but
their performance on fine-grained tasks and large hierarchical label spaces is
understudied. This paper investigates whether structured, tree-based reasoning
can enhance VLM performance. We introduce a framework that decomposes
classification into interpretable decisions using decision trees and evaluates
it on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the
model achieves 98.2% accuracy in understanding the tree knowledge, tree-based
reasoning consistently underperforms standard zero-shot prompting. We also
explore enhancing the tree prompts with LLM-generated classes and image
descriptions to improve alignment. The added description enhances the
performance of the tree-based and zero-shot methods. Our findings highlight
limitations of structured reasoning in visual classification and offer insights
for designing more interpretable VLM systems.

</details>


### [28] [World Modeling with Probabilistic Structure Integration](https://arxiv.org/abs/2509.09737)
*Klemen Kotar,Wanhee Lee,Rahul Venkatesh,Honglin Chen,Daniel Bear,Jared Watrous,Simon Kim,Khai Loong Aw,Lilian Naing Chen,Stefan Stojanov,Kevin Feigelis,Imran Thobani,Alex Durango,Khaled Jedoui,Atlas Kazemian,Dan Yamins*

Main category: cs.CV

TL;DR: PSI（概率结构集成）是一个用于从数据中学习高度可控、灵活可提示的世界模型的系统。它通过概率预测、结构提取和集成三步循环，不断增强模型能力，并创建类似LLM的通用提示语言。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一个能够从数据中学习出丰富可控、灵活可提示的世界模型，以更好地理解和预测复杂数据（如视频）。

Method: PSI系统采用三步循环：
1. 概率预测：构建一个随机访问自回归序列模型Psi，作为数据的概率图模型，支持学习任意变量间的条件分布。
2. 结构提取：通过对Psi进行因果推断，以零样本方式提取数据中低维的“中间结构”。
3. 集成：将提取的结构转换为新的令牌类型，作为条件信号和预测目标重新混合到训练数据中，从而增强Psi的能力。

Result: 研究人员在1.4万亿个互联网视频令牌上训练了Psi的一个实例。结果表明，Psi能够执行各种有用的视频预测和理解推理，并提取出最先进的光流、自监督深度和对象分割，并利用这些结构支持了预测能力的完整改进周期。

Conclusion: PSI系统通过迭代地预测、提取和集成数据中的潜在结构，成功地学习了可控的世界模型。这种方法不仅提升了模型对底层数据的建模能力，还创建了新的控制句柄，实现了类似大型语言模型（LLM）的通用提示功能。

Abstract: We present Probabilistic Structure Integration (PSI), a system for learning
richly controllable and flexibly promptable world models from data. PSI
consists of a three-step cycle. The first step, Probabilistic prediction,
involves building a probabilistic graphical model Psi of the data, in the form
of a random-access autoregressive sequence model. Psi supports a complete set
of learned conditional distributions describing the dependence of any variables
in the data on any other set of variables. In step 2, Structure extraction, we
show how to extract underlying low-dimensional properties in the data,
corresponding to a diverse set of meaningful "intermediate structures", in a
zero-shot fashion via causal inference on Psi. Step 3, Integration, completes
the cycle by converting these structures into new token types that are then
continually mixed back into the training diet as conditioning signals and
prediction targets. Each such cycle augments the capabilities of Psi, both
allowing it to model the underlying data better, and creating new control
handles -- akin to an LLM-like universal prompting language. We train an
instance of Psi on 1.4 trillion tokens of internet video data; we use it to
perform a variety of useful video prediction and understanding inferences; we
extract state-of-the-art optical flow, self-supervised depth and object
segmentation; and we use these structures to support a full cycle of predictive
improvements.

</details>


### [29] [Images in Motion?: A First Look into Video Leakage in Collaborative Deep Learning](https://arxiv.org/abs/2509.09742)
*Md Fazle Rasul,Alanood Alqobaisi,Bruhadeshwar Bezawada,Indrakshi Ray*

Main category: cs.CV

TL;DR: 本文首次分析了联邦学习中视频数据通过梯度反演攻击泄露的风险，发现特征提取器能提供一定抵抗力，但简单分类器仍可能泄露，且超分辨率技术可提升攻击效果。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）的核心是保护隐私，但梯度反演攻击可能通过共享梯度逆向工程私有训练数据，从而威胁FL的隐私目标。虽然此类攻击对图像、文本和表格数据的影响已知，但其对视频数据的影响尚未被研究。

Method: 本文通过梯度反演攻击，对联邦学习中的视频数据泄露进行了首次分析。研究评估了两种常见的视频分类方法：一种使用预训练特征提取器，另一种处理带有简单变换的原始视频帧。此外，研究还展示了图像超分辨率技术如何增强通过梯度反演攻击提取的帧，以重建更高质量的视频，并在攻击者拥有零、一或多个目标环境参考帧的场景下验证了这一点。

Result: 初步结果表明，使用特征提取器能提供更大的梯度反演攻击抵抗力。研究还发现，图像超分辨率技术可以增强通过梯度反演攻击重建的视频帧，使攻击者能够重建更高质量的视频。尽管特征提取器使攻击更具挑战性，但如果分类器缺乏足够的复杂性，数据泄露仍然可能发生。

Conclusion: 研究得出结论，联邦学习中的视频数据泄露是一个可行的威胁，其发生的条件值得进一步调查。

Abstract: Federated learning (FL) allows multiple entities to train a shared model
collaboratively. Its core, privacy-preserving principle is that participants
only exchange model updates, such as gradients, and never their raw, sensitive
data. This approach is fundamental for applications in domains where privacy
and confidentiality are important. However, the security of this very mechanism
is threatened by gradient inversion attacks, which can reverse-engineer private
training data directly from the shared gradients, defeating the purpose of FL.
While the impact of these attacks is known for image, text, and tabular data,
their effect on video data remains an unexamined area of research. This paper
presents the first analysis of video data leakage in FL using gradient
inversion attacks. We evaluate two common video classification approaches: one
employing pre-trained feature extractors and another that processes raw video
frames with simple transformations. Our initial results indicate that the use
of feature extractors offers greater resilience against gradient inversion
attacks. We also demonstrate that image super-resolution techniques can enhance
the frames extracted through gradient inversion attacks, enabling attackers to
reconstruct higher-quality videos. Our experiments validate this across
scenarios where the attacker has access to zero, one, or more reference frames
from the target environment. We find that although feature extractors make
attacks more challenging, leakage is still possible if the classifier lacks
sufficient complexity. We, therefore, conclude that video data leakage in FL is
a viable threat, and the conditions under which it occurs warrant further
investigation.

</details>


### [30] [A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images](https://arxiv.org/abs/2509.09750)
*Hossein Yazdanjouei,Arash Mansouri,Mohammad Shokouhifar*

Main category: cs.CV

TL;DR: 本研究提出了一种半监督协同训练框架，用于密集零售环境中的目标检测，结合Faster R-CNN和YOLO进行伪标签交换，并使用集成分类器和元启发式优化，以减少手动标注并提高复杂场景下的准确性。


<details>
  <summary>Details</summary>
Motivation: 在密集零售环境中，标记数据有限、条件复杂（如遮挡和物体重叠）是主要挑战，且手动标注成本高昂，难以适应频繁的产品和布局变化。

Method: 该框架采用半监督协同训练方法。它结合了Faster R-CNN（使用ResNet骨干网络）进行精确本地化和YOLO（使用Darknet骨干网络）获取全局上下文，两者通过相互伪标签交换来提高准确性。为加强分类，采用XGBoost、Random Forest和SVM的集成模型，利用多样化的特征表示提高鲁棒性。超参数通过元启发式算法进行优化，以提高模型精度和效率。

Result: 在SKU-110k数据集上的实验表明，该框架表现出色，尤其在有遮挡和重叠物体的场景中提高了准确性。它显著减少了对人工标注的依赖，降低了标注成本，并能有效适应零售环境中频繁的产品和布局变化。

Conclusion: 所提出的框架具有良好的可扩展性和实用性，适用于自动化库存跟踪、产品监控和结账系统等现实世界零售应用。

Abstract: This study proposes a semi-supervised co-training framework for object
detection in densely packed retail environments, where limited labeled data and
complex conditions pose major challenges. The framework combines Faster R-CNN
(utilizing a ResNet backbone) for precise localization with YOLO (employing a
Darknet backbone) for global context, enabling mutual pseudo-label exchange
that improves accuracy in scenes with occlusion and overlapping objects. To
strengthen classification, it employs an ensemble of XGBoost, Random Forest,
and SVM, utilizing diverse feature representations for higher robustness.
Hyperparameters are optimized using a metaheuristic-driven algorithm, enhancing
precision and efficiency across models. By minimizing reliance on manual
labeling, the approach reduces annotation costs and adapts effectively to
frequent product and layout changes common in retail. Experiments on the
SKU-110k dataset demonstrate strong performance, highlighting the scalability
and practicality of the proposed framework for real-world retail applications
such as automated inventory tracking, product monitoring, and checkout systems.

</details>


### [31] [Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging](https://arxiv.org/abs/2509.09785)
*Moslem Yazdanpanah,Ali Bahri,Mehrdad Noori,Sahar Dastani,Gustavo Adolfo Vargas Hakim,David Osowiechi,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 本文提出了一种名为Token Purging (PG) 的新型免反向传播方法，用于3D点云分类中的测试时自适应 (TTA)，通过在注意力层之前移除受领域偏移影响严重的tokens，显著提高了自适应性能和效率。


<details>
  <summary>Details</summary>
Motivation: 在3D点云分类中，由于分布偏移导致模型性能下降是一个关键问题，因此需要有效的测试时自适应 (TTA) 方法来缓解这一问题。

Method: 本文引入了Token Purging (PG)，这是一种无需反向传播的创新方法，它在tokens到达注意力层之前，识别并移除受领域偏移严重影响的tokens。PG在token层面操作，无需迭代更新。提出了两种变体：PG-SP（利用源域统计信息）和PG-SF（完全源域无关，依赖于CLS-token驱动的自适应）。

Result: 在ModelNet40-C、ShapeNet-C和ScanObjectNN-C上的广泛评估表明，PG-SP的平均准确率比现有最先进的免反向传播方法高出10.3%。PG-SF在源域无关自适应方面树立了新基准。此外，PG比基线方法快12.4倍，内存效率高5.5倍。

Conclusion: PG是一种高效、内存友好且性能卓越的3D点云分类测试时自适应方法，能够有效应对分布偏移，适用于实际部署。

Abstract: Test-time adaptation (TTA) is crucial for mitigating performance degradation
caused by distribution shifts in 3D point cloud classification. In this work,
we introduce Token Purging (PG), a novel backpropagation-free approach that
removes tokens highly affected by domain shifts before they reach attention
layers. Unlike existing TTA methods, PG operates at the token level, ensuring
robust adaptation without iterative updates. We propose two variants: PG-SP,
which leverages source statistics, and PG-SF, a fully source-free version
relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,
ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of
+10.3\% higher accuracy than state-of-the-art backpropagation-free methods,
while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is
12.4 times faster and 5.5 times more memory efficient than our baseline, making
it suitable for real-world deployment. Code is available at
\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}

</details>


### [32] [Fine-Grained Cross-View Localization via Local Feature Matching and Monocular Depth Priors](https://arxiv.org/abs/2509.09792)
*Zimin Xia,Chenghao Xu,Alexandre Alahi*

Main category: cs.CV

TL;DR: 该论文提出了一种精确且高度可解释的细粒度跨视图定位方法，通过直接匹配地面图像和航空图像的局部特征，并利用单目深度先验将匹配的关键点提升到鸟瞰图空间，来估计地面图像的3自由度姿态。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将地面图像转换为鸟瞰图(BEV)表示，然后与航空图像对齐进行定位。然而，这种转换常因透视失真或高度信息压缩而导致信息丢失，从而降低与航空视图的对齐质量。

Method: 该方法直接在地面图像和航空图像之间建立对应关系，并仅使用单目深度先验将匹配的关键点提升到鸟瞰图空间（支持度量深度和相对深度）。它采用了一种尺度感知的Procrustes对齐方法来从对应关系中估计相机姿态，并在使用相对深度时可选地恢复尺度。

Result: 实验结果表明，在仅有弱相机姿态监督的情况下，该方法学习到准确的局部特征对应关系，并在跨区域泛化和未知方向等挑战性条件下实现了卓越的定位性能。此外，该方法与各种相对深度模型兼容，无需为每个模型进行微调。

Conclusion: 该方法的灵活性和强大的定位性能使其非常适合实际部署，并且在挑战性环境下表现出色，解决了传统BEV转换方法的局限性。

Abstract: We propose an accurate and highly interpretable fine-grained cross-view
localization method that estimates the 3 Degrees of Freedom pose of a
ground-level image by matching its local features with a reference aerial
image. Previous methods typically transform the ground image into a bird's-eye
view (BEV) representation and then align it with the aerial image for
localization. However, this transformation often leads to information loss due
to perspective distortion or compression of height information, thereby
degrading alignment quality with the aerial view. In contrast, our method
directly establishes correspondences between ground and aerial images and lifts
only the matched keypoints to BEV space using monocular depth prior. Notably,
modern depth predictors can provide reliable metric depth when the test samples
are similar to the training data. When the depth distribution differs, they
still produce consistent relative depth, i.e., depth accurate up to an unknown
scale. Our method supports both metric and relative depth. It employs a
scale-aware Procrustes alignment to estimate the camera pose from the
correspondences and optionally recover the scale when using relative depth.
Experimental results demonstrate that, with only weak supervision on camera
pose, our method learns accurate local feature correspondences and achieves
superior localization performance under challenging conditions, such as
cross-area generalization and unknown orientation. Moreover, our method is
compatible with various relative depth models without requiring per-model
finetuning. This flexibility, combined with strong localization performance,
makes it well-suited for real-world deployment.

</details>


### [33] [Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test](https://arxiv.org/abs/2509.09808)
*Judith Massmann,Alexander Lichtenstein,Francisco M. López*

Main category: cs.CV

TL;DR: 本文介绍了一项初步研究，开发了一款名为KidsVisionCheck的免费移动应用，该应用利用深度神经网络和红眼反射图像，实现了儿童视力筛查，准确率达到90%。


<details>
  <summary>Details</summary>
Motivation: 传统的Bruckner测试需要眼科医生在临床环境中进行，而智能手机和人工智能的最新技术进步使得通过移动设备重现该测试成为可能，从而实现更便捷的儿童视力筛查和早期干预。

Method: 该研究开发了一款名为KidsVisionCheck的移动应用，其核心模型基于深度神经网络。该网络使用由眼科医生收集和标记的儿童瞳孔红眼反射图像进行训练。

Result: 模型在未见过的测试数据上达到了90%的准确率，提供了高度可靠的性能，且无需专业设备。此外，研究还确定了最佳数据收集条件，可用于向用户提供即时反馈。

Conclusion: 这项工作标志着全球范围内普及儿科视力筛查和早期干预视力异常的第一步，使其更加便捷和可及。

Abstract: Numerous visual impairments can be detected in red-eye reflex images from
young children. The so-called Bruckner test is traditionally performed by
ophthalmologists in clinical settings. Thanks to the recent technological
advances in smartphones and artificial intelligence, it is now possible to
recreate the Bruckner test using a mobile device. In this paper, we present a
first study conducted during the development of KidsVisionCheck, a free
application that can perform vision screening with a mobile device using
red-eye reflex images. The underlying model relies on deep neural networks
trained on children's pupil images collected and labeled by an ophthalmologist.
With an accuracy of 90% on unseen test data, our model provides highly reliable
performance without the necessity of specialist equipment. Furthermore, we can
identify the optimal conditions for data collection, which can in turn be used
to provide immediate feedback to the users. In summary, this work marks a first
step toward accessible pediatric vision screenings and early intervention for
vision abnormalities worldwide.

</details>


### [34] [Efficient and Accurate Downfacing Visual Inertial Odometry](https://arxiv.org/abs/2509.10021)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: 本文提出了一种针对微型和纳米无人机优化的、高效且高精度的视觉惯性里程计（VIO）流水线。该流水线集成了SuperPoint、PX4FLOW和ORB等先进特征跟踪方法，并针对基于RISC-V的超低功耗片上系统（SoC）进行了优化和量化，显著降低了估计误差，实现了高精度VIO在资源受限平台上的应用。


<details>
  <summary>Details</summary>
Motivation: 现有高精度VIO流水线通常需要在计算能力强大的系统上运行，而微型和纳米无人机等微控制器平台对计算资源有严格限制。因此，研究人员旨在弥合高精度VIO与轻量级、低功耗实现之间的差距，使其能在超低功耗SoC上高效运行。

Method: 该研究采用以下方法：
1. 设计了一个高效准确的VIO流水线。
2. 集成了SuperPoint、PX4FLOW和ORB等先进的特征检测和跟踪方法。
3. 对这些方法进行了优化和量化，以适应新兴的基于RISC-V的超低功耗并行片上系统（SoCs）。
4. 采用刚体运动模型，以减少平面运动场景下的估计误差并提高精度。
5. 在GAP9低功耗SoC上对流水线的计算需求和量化后的跟踪精度进行了评估和实时验证。

Result: 主要结果如下：
1. 优化后的流水线在GAP9低功耗SoC上运行时，使用ORB特征跟踪器时，均方根误差（RMSE）平均降低了3.65倍。
2. 对特征跟踪器的计算复杂度分析表明，当运动速度低于24像素/帧时，PX4FLOW在较低的运行时长下能达到与ORB相当的跟踪精度。

Conclusion: 该设计成功弥合了传统上运行在高性能系统上的高精度VIO流水线与适用于微控制器的轻量级实现之间的鸿沟。该优化的流水线在超低功耗SoC上实现了显著的精度提升，并为微型和纳米无人机等资源受限平台提供了实时、高精度的VIO解决方案。

Abstract: Visual Inertial Odometry (VIO) is a widely used computer vision method that
determines an agent's movement through a camera and an IMU sensor. This paper
presents an efficient and accurate VIO pipeline optimized for applications on
micro- and nano-UAVs. The proposed design incorporates state-of-the-art feature
detection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and
quantized for emerging RISC-V-based ultra-low-power parallel systems on chips
(SoCs). Furthermore, by employing a rigid body motion model, the pipeline
reduces estimation errors and achieves improved accuracy in planar motion
scenarios. The pipeline's suitability for real-time VIO is assessed on an
ultra-low-power SoC in terms of compute requirements and tracking accuracy
after quantization. The pipeline, including the three feature tracking methods,
was implemented on the SoC for real-world validation. This design bridges the
gap between high-accuracy VIO pipelines that are traditionally run on
computationally powerful systems and lightweight implementations suitable for
microcontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates
an average reduction in RMSE of up to a factor of 3.65x over the baseline
pipeline when using the ORB feature tracker. The analysis of the computational
complexity of the feature trackers further shows that PX4FLOW achieves on-par
tracking accuracy with ORB at a lower runtime for movement speeds below 24
pixels/frame.

</details>


### [35] [DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception](https://arxiv.org/abs/2509.09828)
*Tim Broedermannn,Christos Sakaridis,Luigi Piccinelli,Wim Abbeloos,Luc Van Gool*

Main category: cs.CV

TL;DR: 本文提出了一种名为DGFusion的深度引导多模态融合方法，通过整合深度信息来提升自动驾驶车辆在挑战性条件下的语义感知鲁棒性，并在多任务学习框架下实现动态的、空间可变的传感器融合。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆的鲁棒语义感知需要有效结合多种传感器，但现有的传感器融合方法通常对输入数据的空间范围进行统一处理，这在面临挑战性条件时会影响性能。

Method: DGFusion将多模态分割视为一个多任务问题，利用激光雷达测量作为模型输入和深度学习的真值。它引入了一个辅助深度头来学习深度感知特征，这些特征被编码成空间可变的局部深度令牌，并结合一个全局条件令牌，动态地根据场景中传感器依赖于深度的空间可变可靠性来调整传感器融合。此外，还提出了一种鲁棒的深度损失函数，以应对稀疏且嘈杂的激光雷达输入。

Result: DGFusion在具有挑战性的MUSES和DELIVER数据集上实现了最先进的全景和语义分割性能。

Conclusion: 通过引入深度引导的多模态融合，DGFusion能够动态适应传感器在场景中不同深度的可靠性，显著提升了自动驾驶车辆在复杂条件下的语义感知鲁棒性和准确性。

Abstract: Robust semantic perception for autonomous vehicles relies on effectively
combining multiple sensors with complementary strengths and weaknesses.
State-of-the-art sensor fusion approaches to semantic perception often treat
sensor data uniformly across the spatial extent of the input, which hinders
performance when faced with challenging conditions. By contrast, we propose a
novel depth-guided multimodal fusion method that upgrades condition-aware
fusion by integrating depth information. Our network, DGFusion, poses
multimodal segmentation as a multi-task problem, utilizing the lidar
measurements, which are typically available in outdoor sensor suites, both as
one of the model's inputs and as ground truth for learning depth. Our
corresponding auxiliary depth head helps to learn depth-aware features, which
are encoded into spatially varying local depth tokens that condition our
attentive cross-modal fusion. Together with a global condition token, these
local depth tokens dynamically adapt sensor fusion to the spatially varying
reliability of each sensor across the scene, which largely depends on depth. In
addition, we propose a robust loss for our depth, which is essential for
learning from lidar inputs that are typically sparse and noisy in adverse
conditions. Our method achieves state-of-the-art panoptic and semantic
segmentation performance on the challenging MUSES and DELIVER datasets. Code
and models will be available at https://github.com/timbroed/DGFusion

</details>


### [36] [Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning Framework](https://arxiv.org/abs/2509.09841)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 本文提出基于ResNet-18深度学习框架的斑块级自动酒渣鼻检测策略，通过提取不同大小、形状和位置的面部图像斑块，实现了比全图像方法更高的准确性和敏感性，同时增强了模型的可解释性并保护了患者隐私。


<details>
  <summary>Details</summary>
Motivation: 酒渣鼻是一种慢性炎症性皮肤病，早期和精准检测对于显著提高治疗效果至关重要。

Method: 研究采用ResNet-18深度学习框架，提出新的斑块级自动酒渣鼻检测策略。具体方法包括：1) 从面部图像中提取不同大小、形状和位置的各种图像斑块；2) 进行调查研究以评估局部视觉信息对深度学习模型性能的影响；3) 实施实验比较斑块级策略与全图像方法的性能。

Result: 实验结果表明，所提出的斑块级自动酒渣鼻检测策略在准确性和敏感性方面优于或与全图像方法相当。这些策略能引导深度学习模型关注临床相关区域，增强模型的鲁棒性和可解释性，并通过排除可识别的面部特征来保护患者隐私。

Conclusion: 所提出的斑块级策略为改进自动化皮肤病诊断提供了实用的见解。

Abstract: Rosacea, which is a chronic inflammatory skin condition that manifests with
facial redness, papules, and visible blood vessels, often requirs precise and
early detection for significantly improving treatment effectiveness. This paper
presents new patch-based automatic rosacea detection strategies using the
ResNet-18 deep learning framework. The contributions of the proposed strategies
come from the following aspects. First, various image pateches are extracted
from the facial images of people in different sizes, shapes, and locations.
Second, a number of investigation studies are carried out to evaluate how the
localized visual information influences the deep learing model performance.
Third, thorough experiments are implemented to reveal that several patch-based
automatic rosacea detection strategies achieve competitive or superior accuracy
and sensitivity than the full-image based methods. And finally, the proposed
patch-based strategies, which use only localized patches, inherently preserve
patient privacy by excluding any identifiable facial features from the data.
The experimental results indicate that the proposed patch-based strategies
guide the deep learning model to focus on clinically relevant regions, enhance
robustness and interpretability, and protect patient privacy. As a result, the
proposed strategies offer practical insights for improving automated
dermatological diagnostics.

</details>


### [37] [Privacy-Preserving Automated Rosacea Detection Based on Medically Inspired Region of Interest Selection](https://arxiv.org/abs/2509.09844)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的、隐私保护的酒渣鼻自动检测方法，该方法结合临床先验知识，通过红度信息掩码聚焦诊断区域，并完全使用合成数据训练ResNet-18模型，在真实世界数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 酒渣鼻是一种常见但诊断不足的炎症性皮肤病。由于症状弥漫性、标记数据集稀缺以及面部图像涉及隐私问题，自动化检测面临挑战。

Method: 该方法受临床先验知识（酒渣鼻主要表现为面部中央红斑）启发，首先构建一个固定的、基于红度信息的掩码，通过选择面部图像中红色通道强度持续较高的区域（如脸颊、鼻子、额头）来聚焦诊断相关区域，同时排除身份识别特征。其次，使用在这些掩码合成图像上训练的ResNet-18深度学习模型进行检测。

Result: 实验结果表明，该方法在真实世界测试数据上评估时，相较于全脸基线方法，在准确率、召回率和F1分数方面均取得了显著提升。

Conclusion: 合成数据和临床先验知识的结合能够实现准确且符合伦理的皮肤病AI系统，尤其适用于远程医疗和大规模筛查等隐私敏感应用。

Abstract: Rosacea is a common but underdiagnosed inflammatory skin condition that
primarily affects the central face and presents with subtle redness, pustules,
and visible blood vessels. Automated detection remains challenging due to the
diffuse nature of symptoms, the scarcity of labeled datasets, and privacy
concerns associated with using identifiable facial images. A novel
privacy-preserving automated rosacea detection method inspired by clinical
priors and trained entirely on synthetic data is presented in this paper.
Specifically, the proposed method, which leverages the observation that rosacea
manifests predominantly through central facial erythema, first constructs a
fixed redness-informed mask by selecting regions with consistently high red
channel intensity across facial images. The mask thus is able to focus on
diagnostically relevant areas such as the cheeks, nose, and forehead and
exclude identity-revealing features. Second, the ResNet-18 deep learning
method, which is trained on the masked synthetic images, achieves superior
performance over the full-face baselines with notable gains in terms of
accuracy, recall and F1 score when evaluated using the real-world test data.
The experimental results demonstrate that the synthetic data and clinical
priors can jointly enable accurate and ethical dermatological AI systems,
especially for privacy sensitive applications in telemedicine and large-scale
screening.

</details>


### [38] [Investigating the Impact of Various Loss Functions and Learnable Wiener Filter for Laparoscopic Image Desmoking](https://arxiv.org/abs/2509.09849)
*Chengyu Yang,Chengjun Liu*

Main category: cs.CV

TL;DR: 本文对腹腔镜图像去烟雾ULW框架的各个组件进行了全面的消融研究，以评估其有效性和必要性。


<details>
  <summary>Details</summary>
Motivation: ULW框架最近被提出用于腹腔镜图像去烟雾，但其内部各个组件（U-Net骨干、复合损失函数、可学习维纳滤波器）的有效性和必要性需要被严格评估。

Method: 研究方法是进行消融研究，系统性地移除ULW框架中的每个组件。具体包括：1) 移除可学习的维纳滤波器；2) 选择性地使用复合损失函数中的单个损失项（MSE、SSIM、感知损失）。所有变体都在公开的配对腹腔镜图像数据集上，使用定量指标（SSIM、PSNR、MSE和CIEDE-2000）和定性视觉比较进行基准测试。

Result: 通过系统性地消融每个组件，评估了其对整个框架整体性能的具体贡献。研究旨在量化分析每个部分对去烟雾效果的影响。

Conclusion: 该研究旨在通过消融实验，为ULW框架中各个组件的有效性和必要性提供严格的评估和理解，从而为未来的改进提供依据。

Abstract: To rigorously assess the effectiveness and necessity of individual components
within the recently proposed ULW framework for laparoscopic image desmoking,
this paper presents a comprehensive ablation study. The ULW approach combines a
U-Net based backbone with a compound loss function that comprises mean squared
error (MSE), structural similarity index (SSIM) loss, and perceptual loss. The
framework also incorporates a differentiable, learnable Wiener filter module.
In this study, each component is systematically ablated to evaluate its
specific contribution to the overall performance of the whole framework. The
analysis includes: (1) removal of the learnable Wiener filter, (2) selective
use of individual loss terms from the composite loss function. All variants are
benchmarked on a publicly available paired laparoscopic images dataset using
quantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative
visual comparisons.

</details>


### [39] [WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector](https://arxiv.org/abs/2509.09859)
*Razvan Stefanescu,Ethan Oh,Ruben Vazquez,Chris Mesterharm,Constantin Serban,Ritu Chadha*

Main category: cs.CV

TL;DR: 本文提出WAVE-DETR多模态无人机检测器，结合可见光RGB和声学信号，融合Deformable DETR和Wav2Vec2架构，在挑战性环境下实现鲁棒的无人机目标检测，特别提升了小型无人机的检测性能。


<details>
  <summary>Details</summary>
Motivation: 在挑战性真实环境条件下，仅靠单一模态难以实现鲁棒的无人机目标检测，需要更有效的方法来提高检测性能。

Method: 该研究引入了WAVE-DETR多模态无人机检测器，将可见光RGB和声学信号结合。它将Deformable DETR的视觉特征和Wav2Vec2的声学特征在一个统一的模型中进行融合。研究探索了四种不同的融合配置：门控机制、线性层、MLP和交叉注意力。实验使用了现有的Drone-vs-Bird数据集和新生成的ARDrone数据集（包含超过7,500个同步图像和音频片段）。

Result: 声学信息显著提高了Deformable DETR目标检测器在真实ARDrone数据集上的性能。其中，门控融合方法表现最佳，将Deformable DETR在ARDrone数据集（包括同分布和异分布）上小型无人机的mAP提升了11.1%至15.3%（在IoU 0.5至0.9的所有阈值下）。中型和大型无人机的mAP也得到增强，所有无人机尺寸的总体增益范围为3.27%至5.84%。

Conclusion: 结合视觉和声学信号的多模态融合方法，特别是采用门控融合机制，能够显著提升无人机目标检测的性能，尤其对于小型无人机，在复杂环境下表现出更强的鲁棒性。

Abstract: We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and
acoustic signals for robust real-life UAV object detection. Our approach fuses
visual and acoustic features in a unified object detector model relying on the
Deformable DETR and Wav2Vec2 architectures, achieving strong performance under
challenging environmental conditions. Our work leverage the existing
Drone-vs-Bird dataset and the newly generated ARDrone dataset containing more
than 7,500 synchronized images and audio segments. We show how the acoustic
information is used to improve the performance of the Deformable DETR object
detector on the real ARDrone dataset. We developed, trained and tested four
different fusion configurations based on a gated mechanism, linear layer, MLP
and cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi
resolution feature mappings of the Deformable DETR and enhance the object
detection performance over all drones dimensions. The best performer is the
gated fusion approach, which improves the mAP of the Deformable DETR object
detector on our in-distribution and out-of-distribution ARDrone datasets by
11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.
The mAP scores for medium and large drones are also enhanced, with overall
gains across all drone sizes ranging from 3.27% to 5.84%.

</details>


### [40] [Surrogate Supervision for Robust and Generalizable Deformable Image Registration](https://arxiv.org/abs/2509.09869)
*Yihao Liu,Junyu Chen,Lianrui Zuo,Shuwen Wei,Brian D. Boyd,Carmen Andreescu,Olusola Ajilore,Warren D. Taylor,Aaron Carass,Bennett A. Landman*

Main category: cs.CV

TL;DR: 为解决深度学习形变图像配准对输入图像特性变化的敏感性，本文提出了“代理监督”训练范式，通过解耦输入域和监督域来提高配准网络的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习形变图像配准虽然精度高，但对输入图像特性（如伪影、视野不匹配、模态差异）的变化敏感。研究目标是开发一种通用的训练范式，以提高配准网络的鲁棒性和泛化能力。

Method: 引入“代理监督”方法，通过将估计的空间变换应用于代理图像，从而解耦输入域和监督域。这允许在异构输入上进行训练，同时确保监督在相似性定义明确的域中计算。通过三种代表性应用（抗伪影脑部MR配准、掩模无关肺部CT配准和多模态MR配准）评估了该框架。

Result: 在各项任务中，代理监督展示了对输入变异（包括不均匀场、不一致视野和模态差异）的强大弹性，同时在精心整理的数据上保持了高性能。

Conclusion: 代理监督为训练鲁棒且泛化性强的深度学习配准模型提供了一个原则性框架，且不增加复杂性。它为实现更鲁棒和泛化性更强的医学图像配准提供了一条实用途径，使其在多样化的生物医学成像场景中具有更广泛的适用性。

Abstract: Objective: Deep learning-based deformable image registration has achieved
strong accuracy, but remains sensitive to variations in input image
characteristics such as artifacts, field-of-view mismatch, or modality
difference. We aim to develop a general training paradigm that improves the
robustness and generalizability of registration networks. Methods: We introduce
surrogate supervision, which decouples the input domain from the supervision
domain by applying estimated spatial transformations to surrogate images. This
allows training on heterogeneous inputs while ensuring supervision is computed
in domains where similarity is well defined. We evaluate the framework through
three representative applications: artifact-robust brain MR registration,
mask-agnostic lung CT registration, and multi-modal MR registration. Results:
Across tasks, surrogate supervision demonstrated strong resilience to input
variations including inhomogeneity field, inconsistent field-of-view, and
modality differences, while maintaining high performance on well-curated data.
Conclusions: Surrogate supervision provides a principled framework for training
robust and generalizable deep learning-based registration models without
increasing complexity. Significance: Surrogate supervision offers a practical
pathway to more robust and generalizable medical image registration, enabling
broader applicability in diverse biomedical imaging scenarios.

</details>


### [41] [An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars](https://arxiv.org/abs/2509.09911)
*Barkin Buyukcakir,Jannick De Tobel,Patrick Thevissen,Dirk Vandermeulen,Peter Claes*

Main category: cs.CV

TL;DR: 本研究针对牙齿年龄估计中深度学习模型的“黑箱”问题，提出了一种结合卷积自编码器（AE）和Vision Transformer（ViT）的框架。该框架不仅提高了性能，还能通过诊断性洞察揭示模型不确定性的数据中心原因，例如牙齿38数据集内部形态变异性高的问题，超越了单一解释模式的局限性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在牙齿年龄估计等高风险法医应用中，由于其“黑箱”特性，实际采用受限。此外，在下颌第二磨牙（牙齿37）和第三磨牙（牙齿38）的自动分期中存在显著的性能差异，这促使研究人员寻求提升性能和透明度的方法。

Method: 本研究提出了一种结合卷积自编码器（AE）和Vision Transformer（ViT）的框架。该框架利用AE的潜在空间度量和图像重建来提供多方面的诊断性洞察，以识别模型性能的潜在限制因素。

Result: 该框架相较于基线ViT，提高了两种牙齿的分类准确率：牙齿37从0.712提升至0.815，牙齿38从0.462提升至0.543。通过分析AE的潜在空间和图像重建，研究发现剩余的性能差距是数据中心性的，牙齿38数据集中较高的类内形态变异性是主要限制因素。研究还指出，仅依赖注意力图等单一解释模式不足以识别潜在的数据问题。

Conclusion: 该框架通过同时提高准确性并提供模型不确定性原因的证据，为法医年龄估计中的专家决策提供了更强大的工具。它强调了多方面诊断洞察的重要性，以超越单一解释模式的局限性，从而识别并解决潜在的数据问题。

Abstract: The practical adoption of deep learning in high-stakes forensic applications,
such as dental age estimation, is often limited by the 'black box' nature of
the models. This study introduces a framework designed to enhance both
performance and transparency in this context. We use a notable performance
disparity in the automated staging of mandibular second (tooth 37) and third
(tooth 38) molars as a case study. The proposed framework, which combines a
convolutional autoencoder (AE) with a Vision Transformer (ViT), improves
classification accuracy for both teeth over a baseline ViT, increasing from
0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond
improving performance, the framework provides multi-faceted diagnostic
insights. Analysis of the AE's latent space metrics and image reconstructions
indicates that the remaining performance gap is data-centric, suggesting high
intra-class morphological variability in the tooth 38 dataset is a primary
limiting factor. This work highlights the insufficiency of relying on a single
mode of interpretability, such as attention maps, which can appear anatomically
plausible yet fail to identify underlying data issues. By offering a
methodology that both enhances accuracy and provides evidence for why a model
may be uncertain, this framework serves as a more robust tool to support expert
decision-making in forensic age estimation.

</details>


### [42] [SCoDA: Self-supervised Continual Domain Adaptation](https://arxiv.org/abs/2509.09935)
*Chirayu Agrawal,Snehasis Mukherjee*

Main category: cs.CV

TL;DR: 本文提出了一种名为SCoDA的无源持续域适应方法，通过自监督预训练和几何流形对齐来解决现有SFDA方法中几何信息丢失的问题，并显著优于现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 现有无源域适应（SFDA）方法通常依赖于全监督预训练模型，并通过对L2归一化特征向量进行余弦相似度计算来对齐实例级特征。这种做法无意中丢弃了源模型潜在流形中关键的几何信息。

Method: SCoDA方法做了两项关键改进：1) 避免依赖监督预训练，而是使用完全通过自监督学习（SSL）预训练的教师模型初始化框架。2) 将几何流形对齐原则应用于SFDA设置。学生模型通过结合实例级特征匹配和空间相似度损失的复合目标进行训练。为对抗灾难性遗忘，教师模型的参数通过学生模型参数的指数移动平均（EMA）进行更新。

Result: 在基准数据集上进行的广泛实验表明，SCoDA显著优于最先进的SFDA方法。

Conclusion: SCoDA通过采用自监督预训练和几何流形对齐，有效解决了传统SFDA方法中几何信息丢失的局限性，实现了卓越的性能，并在无源域适应领域取得了重要进展。

Abstract: Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a
model to a target domain without access to the data of the source domain.
Prevailing methods typically start with a source model pre-trained with full
supervision and distill the knowledge by aligning instance-level features.
However, these approaches, relying on cosine similarity over L2-normalized
feature vectors, inadvertently discard crucial geometric information about the
latent manifold of the source model. We introduce Self-supervised Continual
Domain Adaptation (SCoDA) to address these limitations. We make two key
departures from standard practice: first, we avoid the reliance on supervised
pre-training by initializing the proposed framework with a teacher model
pre-trained entirely via self-supervision (SSL). Second, we adapt the principle
of geometric manifold alignment to the SFDA setting. The student is trained
with a composite objective combining instance-level feature matching with a
Space Similarity Loss. To combat catastrophic forgetting, the teacher's
parameters are updated via an Exponential Moving Average (EMA) of the student's
parameters. Extensive experiments on benchmark datasets demonstrate that SCoDA
significantly outperforms state-of-the-art SFDA methods.

</details>


### [43] [Segment Anything for Cell Tracking](https://arxiv.org/abs/2509.09943)
*Zhu Chen,Mert Edgü,Er Jin,Johannes Stegmaier*

Main category: cs.CV

TL;DR: 本文提出了一种零样本细胞追踪框架，通过整合Segment Anything 2 (SAM2)实现了完全无监督的细胞追踪，解决了现有深度学习方法对人工标注的依赖和泛化性差的问题，并在2D和3D延时显微镜视频中取得了有竞争力的准确性。


<details>
  <summary>Details</summary>
Motivation: 细胞追踪和有丝分裂事件检测在生物医学研究中至关重要，但面临对象分裂、低信噪比、边界模糊、密集聚类和细胞外观相似等挑战。现有基于深度学习的方法依赖昂贵耗时的人工标注数据集进行训练，且对未见数据集的泛化能力有限。

Method: 提出了一种零样本细胞追踪框架，将通用图像和视频分割基础模型Segment Anything 2 (SAM2)整合到追踪流程中。这是一种完全无监督的方法，不依赖或继承任何特定训练数据集的偏差，因此无需微调即可泛化到不同的显微镜数据集。

Result: 该方法在2D和大规模3D延时显微镜视频中均取得了有竞争力的准确性，同时消除了对数据集特定适应的需求。

Conclusion: 通过整合SAM2，本文提出的零样本、完全无监督的细胞追踪框架克服了现有方法的局限性，实现了在多样化显微镜数据上的良好泛化能力，无需人工标注或微调，为细胞追踪提供了一种高效且普适的解决方案。

Abstract: Tracking cells and detecting mitotic events in time-lapse microscopy image
sequences is a crucial task in biomedical research. However, it remains highly
challenging due to dividing objects, low signal-tonoise ratios, indistinct
boundaries, dense clusters, and the visually similar appearance of individual
cells. Existing deep learning-based methods rely on manually labeled datasets
for training, which is both costly and time-consuming. Moreover, their
generalizability to unseen datasets remains limited due to the vast diversity
of microscopy data. To overcome these limitations, we propose a zero-shot cell
tracking framework by integrating Segment Anything 2 (SAM2), a large foundation
model designed for general image and video segmentation, into the tracking
pipeline. As a fully-unsupervised approach, our method does not depend on or
inherit biases from any specific training dataset, allowing it to generalize
across diverse microscopy datasets without finetuning. Our approach achieves
competitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos
while eliminating the need for dataset-specific adaptation.

</details>


### [44] [Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation](https://arxiv.org/abs/2509.09946)
*Vu-Minh Le,Thao-Anh Tran,Duc Huy Do,Xuan Canh Do,Huong Ninh,Hai Tran*

Main category: cs.CV

TL;DR: 本文提出了一种将任何在线2D多摄像头多目标跟踪系统扩展到3D空间的方法，通过利用深度信息重建目标并恢复其3D边界框，同时引入了增强的在线数据关联机制。


<details>
  <summary>Details</summary>
Motivation: 多目标多摄像头跟踪（MTMC）是自动化大规模监控的关键任务。尽管3D空间跟踪能提供无与伦比的3D环境感知能力，但它需要彻底替换所有2D跟踪组件，这对于现有MTMC系统来说可能不切实际。

Method: 该方法通过以下步骤将2D系统扩展到3D：1) 利用深度信息在点云空间中重建目标；2) 通过聚类和偏航角细化恢复目标的3D边界框；3) 引入了一种增强的在线数据关联机制，该机制利用目标的局部ID一致性来跨帧分配全局ID。

Result: 所提出的框架在2025年AI City Challenge的3D MTMC数据集上进行了评估，并在排行榜上取得了第三名的成绩。

Conclusion: 该研究成功地提出了一种将现有在线2D多摄像头跟踪系统扩展到3D空间的可行方法，并通过引入改进的数据关联机制提升了跟踪性能，在相关挑战赛中表现出色。

Abstract: Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision
task for automating large-scale surveillance. With camera calibration and depth
information, the targets in the scene can be projected into 3D space, offering
unparalleled levels of automatic perception of a 3D environment. However,
tracking in the 3D space requires replacing all 2D tracking components from the
ground up, which may be infeasible for existing MTMC systems. In this paper, we
present an approach for extending any online 2D multi-camera tracking system
into 3D space by utilizing depth information to reconstruct a target in
point-cloud space, and recovering its 3D box through clustering and yaw
refinement following tracking. We also introduced an enhanced online data
association mechanism that leverages the target's local ID consistency to
assign global IDs across frames. The proposed framework is evaluated on the
2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the
leaderboard.

</details>


### [45] [Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification](https://arxiv.org/abs/2509.09958)
*Jeffrey Liu,Rongbin Hu*

Main category: cs.CV

TL;DR: 本文提出了一种零样本参照表达理解（REC）方法，将REC重构为逐框视觉-语言验证任务，无需特定训练即可达到甚至超越经过训练的模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统的REC方法通常依赖于任务特定的接地模型训练。作者旨在探索一种零样本工作流，在不进行任何REC特定训练的情况下，能否实现有竞争力甚至更优的性能。

Method: 该方法将REC重新表述为逐框视觉-语言验证。首先，使用COCO-clean通用检测器（如YOLO-World）生成候选框。然后，一个通用视觉-语言模型（VLM）独立地对每个区域回答是/否查询。这种简单流程减少了跨框干扰，支持弃权和多重匹配，且无需微调。

Result: 在RefCOCO、RefCOCO+和RefCOCOg数据集上，该方法不仅超越了零样本GroundingDINO基线，还超过了报告中经过REC训练的GroundingDINO以及GroundingDINO+CRG的性能。受控研究证实，验证方法显著优于基于选择的提示方法，并且结果在开放VLM中也成立。

Conclusion: 研究表明，工作流设计而非任务特定预训练是实现强大零样本REC性能的关键。

Abstract: Referring Expression Comprehension (REC) is usually addressed with
task-trained grounding models. We show that a zero-shot workflow, without any
REC-specific training, can achieve competitive or superior performance. Our
approach reformulates REC as box-wise visual-language verification: given
proposals from a COCO-clean generic detector (YOLO-World), a general-purpose
VLM independently answers True/False queries for each region. This simple
procedure reduces cross-box interference, supports abstention and multiple
matches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our
method not only surpasses a zero-shot GroundingDINO baseline but also exceeds
reported results for GroundingDINO trained on REC and GroundingDINO+CRG.
Controlled studies with identical proposals confirm that verification
significantly outperforms selection-based prompting, and results hold with open
VLMs. Overall, we show that workflow design, rather than task-specific
pretraining, drives strong zero-shot REC performance.

</details>


### [46] [Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation](https://arxiv.org/abs/2509.09961)
*Tianqi Wei,Xin Yu,Zhi Chen,Scott Chapman,Zi Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为随机投影复制粘贴（RPCP）的数据增强技术，以解决小麦叶部病害和虫害分割中极度像素不平衡的问题，尤其针对稀有虫害类别。


<details>
  <summary>Details</summary>
Motivation: 小麦叶部病害和虫害分割对于作物管理至关重要。然而，虫害通常只占标注像素的极小部分，导致像素级极度不平衡。这使得模型容易过拟合常见类别，对稀有类别学习不足，从而影响整体分割性能。

Method: 本文提出了随机投影复制粘贴（RPCP）增强技术。具体方法是：从标注训练图像中提取稀有虫害斑块，应用随机几何变换模拟变异，然后将变换后的斑块粘贴到适当区域（避免与病变或现有受损区域重叠）。此外，对粘贴区域应用随机投影滤波器，以细化局部特征并确保与新背景自然融合。

Result: 实验结果表明，该方法显著提高了虫害类别的分割性能，同时保持甚至略微提升了其他类别的准确性。

Conclusion: 研究结果强调了目标增强在缓解极端像素不平衡方面的有效性，为农业分割问题提供了一个直接而有效的解决方案。

Abstract: Accurate segmentation of foliar diseases and insect damage in wheat is
crucial for effective crop management and disease control. However, the insect
damage typically occupies only a tiny fraction of annotated pixels. This
extreme pixel-level imbalance poses a significant challenge to the segmentation
performance, which can result in overfitting to common classes and insufficient
learning of rare classes, thereby impairing overall performance. In this paper,
we propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to
address the pixel imbalance problem. Specifically, we extract rare
insect-damage patches from annotated training images and apply random geometric
transformations to simulate variations. The transformed patches are then pasted
in appropriate regions while avoiding overlaps with lesions or existing damaged
regions. In addition, we apply a random projection filter to the pasted
regions, refining local features and ensuring a natural blend with the new
background. Experiments show that our method substantially improves
segmentation performance on the insect damage class, while maintaining or even
slightly enhancing accuracy on other categories. Our results highlight the
effectiveness of targeted augmentation in mitigating extreme pixel imbalance,
offering a straightforward yet effective solution for agricultural segmentation
problems.

</details>


### [47] [An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock](https://arxiv.org/abs/2509.09962)
*Anne Marthe Sophie Ngo Bibinbe,Chiron Bang,Patrick Gagnon,Jamie Ahloy-Dallaire,Eric R. Paquet*

Main category: cs.CV

TL;DR: 本文提出了一种基于隐马尔可夫模型（HMM）的新框架，通过整合不确定的零星身份信息，解决了长期多目标跟踪（MOT）中身份切换导致性能下降的问题，并在猪跟踪数据集及MOT基准上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 由于现有MOT方法在长时间跟踪中易发生身份切换，导致性能随时间下降，难以应用于需要分析个体行为的长期视频。然而，在许多实际应用中（如畜牧业），可以从喂食器等来源获取零星的动物身份信息，这为解决长期MOT挑战提供了机会。

Method: 作者提出了一个新框架，该框架利用隐马尔可夫模型（HMM）将不确定的身份信息与跟踪过程相结合。该方法旨在利用零星的真实世界身份来提高长期跟踪的准确性。

Result: 该HMM框架在10分钟的猪跟踪数据集上，即使仅有21个来自喂食站的识别信息，也能提高领先MOT方法ByteTrack（包含重识别功能）的F1分数。研究还表明，该方法对识别信息的不确定性具有鲁棒性，且性能随识别频率的增加而提高。此外，该HMM框架在MOT17和MOT20基准数据集上，结合ByteTrack和FairMOT，也验证了其性能改进。

Conclusion: 所提出的基于HMM的框架通过有效整合不确定的零星身份信息，成功解决了长期多目标跟踪中的身份切换问题。该方法不仅提高了跟踪性能和鲁棒性，而且在实际应用场景和标准基准数据集上均得到了验证，为长期个体行为分析提供了新的解决方案。

Abstract: The need for long-term multi-object tracking (MOT) is growing due to the
demand for analyzing individual behaviors in videos that span several minutes.
Unfortunately, due to identity switches between objects, the tracking
performance of existing MOT approaches decreases over time, making them
difficult to apply for long-term tracking. However, in many real-world
applications, such as in the livestock sector, it is possible to obtain
sporadic identifications for some of the animals from sources like feeders. To
address the challenges of long-term MOT, we propose a new framework that
combines both uncertain identities and tracking using a Hidden Markov Model
(HMM) formulation. In addition to providing real-world identities to animals,
our HMM framework improves the F1 score of ByteTrack, a leading MOT approach
even with re-identification, on a 10 minute pig tracking dataset with 21
identifications at the pen's feeding station. We also show that our approach is
robust to the uncertainty of identifications, with performance increasing as
identities are provided more frequently. The improved performance of our HMM
framework was also validated on the MOT17 and MOT20 benchmark datasets using
both ByteTrack and FairMOT. The code for this new HMM framework and the new
10-minute pig tracking video dataset are available at:
https://github.com/ngobibibnbe/uncertain-identity-aware-tracking

</details>


### [48] [Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey](https://arxiv.org/abs/2509.09971)
*Aupendu Kar,Vishnu Raj,Guan-Ming Su*

Main category: cs.CV

TL;DR: 这篇综述探讨了事件相机与传统帧相机融合的演变，重点关注其在视频恢复和3D重建中的应用，特别是在深度学习背景下，并涵盖了相关数据集。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有低延迟、低功耗和超高捕获率的优势。将事件流与传统帧捕获融合，能显著提升各种视频恢复和3D重建任务的性能，因此需要对该新兴领域进行系统性探索。

Method: 本文通过系统回顾深度学习在图像/视频增强和恢复方面的主要贡献，重点关注时间增强（如帧插值、运动去模糊）和空间增强（如超分辨率、低光/HDR增强、伪影消除）。此外，还探讨了事件驱动融合如何促进3D重建领域的发展，并汇编了公开数据集。

Result: 综述强调了事件-帧融合在视频恢复（时间与空间增强）和3D重建中的显著优势，深入讨论了在挑战性条件下改善视觉质量的最新工作，并提供了一个全面的开放数据集列表，以促进可复现研究和基准测试。

Conclusion: 通过整合最新进展和见解，本综述旨在激发未来研究，以利用事件相机系统，特别是结合深度学习，来实现先进的视觉媒体恢复和增强。

Abstract: Event camera sensors are bio-inspired sensors which asynchronously capture
per-pixel brightness changes and output a stream of events encoding the
polarity, location and time of these changes. These systems are witnessing
rapid advancements as an emerging field, driven by their low latency, reduced
power consumption, and ultra-high capture rates. This survey explores the
evolution of fusing event-stream captured with traditional frame-based capture,
highlighting how this synergy significantly benefits various video restoration
and 3D reconstruction tasks. The paper systematically reviews major deep
learning contributions to image/video enhancement and restoration, focusing on
two dimensions: temporal enhancement (such as frame interpolation and motion
deblurring) and spatial enhancement (including super-resolution, low-light and
HDR enhancement, and artifact reduction). This paper also explores how the 3D
reconstruction domain evolves with the advancement of event driven fusion.
Diverse topics are covered, with in-depth discussions on recent works for
improving visual quality under challenging conditions. Additionally, the survey
compiles a comprehensive list of openly available datasets, enabling
reproducible research and benchmarking. By consolidating recent progress and
insights, this survey aims to inspire further research into leveraging event
camera systems, especially in combination with deep learning, for advanced
visual media restoration and enhancement.

</details>


### [49] [ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking](https://arxiv.org/abs/2509.09977)
*Siying Liu,Zikai Wang,Hanle Zheng,Yifan Hu,Xilin Wang,Qingkai Yang,Jibin Wu,Hao Guo,Lei Deng*

Main category: cs.CV

TL;DR: ISTASTrack是首个基于Transformer的ANN-SNN混合RGB-事件跟踪器，通过ISTA适配器实现RGB图像和事件流之间的有效特征融合，在保持高能效的同时达到了最先进的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人工神经网络（ANN）难以充分利用事件流的稀疏和异步特性。虽然结合ANN和脉冲神经网络（SNN）的混合架构在RGB-事件感知中前景广阔，但如何有效融合异构范式（ANN和SNN）的特征仍然是一个挑战。

Method: 本文提出了ISTASTrack，一个基于Transformer的ANN-SNN混合跟踪器。它包含一个用于RGB输入的视觉Transformer和一个用于事件流的脉冲Transformer。为了弥合ANN和SNN特征之间的模态和范式鸿沟，设计了一种基于模型（源自迭代收缩阈值算法ISTA）的ISTA适配器，用于双向特征交互。此外，适配器中还整合了一个时间下采样注意力模块，以对齐多步SNN特征和单步ANN特征，从而改善时间融合。

Result: ISTASTrack在FE240hz、VisEvent、COESOT和FELT等RGB-事件跟踪基准测试中取得了最先进的性能，同时保持了高能效。

Conclusion: 混合ANN-SNN设计对于鲁棒的视觉跟踪是有效且实用的，ISTASTrack的成功证明了其潜力。

Abstract: RGB-Event tracking has become a promising trend in visual object tracking to
leverage the complementary strengths of both RGB images and dynamic spike
events for improved performance. However, existing artificial neural networks
(ANNs) struggle to fully exploit the sparse and asynchronous nature of event
streams. Recent efforts toward hybrid architectures combining ANNs and spiking
neural networks (SNNs) have emerged as a promising solution in RGB-Event
perception, yet effectively fusing features across heterogeneous paradigms
remains a challenge. In this work, we propose ISTASTrack, the first
transformer-based \textbf{A}NN-\textbf{S}NN hybrid \textbf{Track}er equipped
with \textbf{ISTA} adapters for RGB-Event tracking. The two-branch model
employs a vision transformer to extract spatial context from RGB inputs and a
spiking transformer to capture spatio-temporal dynamics from event streams. To
bridge the modality and paradigm gap between ANN and SNN features, we
systematically design a model-based ISTA adapter for bidirectional feature
interaction between the two branches, derived from sparse representation theory
by unfolding the iterative shrinkage thresholding algorithm. Additionally, we
incorporate a temporal downsampling attention module within the adapter to
align multi-step SNN features with single-step ANN features in the latent
space, improving temporal fusion. Experimental results on RGB-Event tracking
benchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that
ISTASTrack achieves state-of-the-art performance while maintaining high energy
efficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN
designs for robust visual tracking. The code is publicly available at
https://github.com/lsying009/ISTASTrack.git.

</details>


### [50] [FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction](https://arxiv.org/abs/2509.09988)
*Yusuke Takagi,Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: 该研究提出了一种基于多个深度状态空间模型的太阳耀斑预测模型，并引入了FLARE损失函数，以解决现有方法在预测未来72小时最大耀斑类别时面临的类别不平衡问题，并在标准指标上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 准确可靠的太阳耀斑预测对于减轻对关键基础设施的潜在影响至关重要。然而，目前的太阳耀斑预测性能不足，并且现有方法未能充分解决耀斑类别之间严重的类别不平衡问题。

Method: 提出了一种基于多个深度状态空间模型的太阳耀斑预测模型。此外，引入了频率与局部边界感知可靠性损失（FLARE损失）以提高类别不平衡条件下的预测性能和可靠性。

Result: 在涵盖一个完整11年太阳活动周期的多波长太阳图像数据集上进行实验，结果表明该方法在Gandin-Murphy-Gerrity分数和真实技能统计量（性能和可靠性的标准指标）方面均优于基线方法。

Conclusion: 所提出的基于深度状态空间模型和FLARE损失的太阳耀斑预测模型，有效解决了类别不平衡问题，显著提升了预测性能和可靠性，优于现有基线方法。

Abstract: Accurate and reliable solar flare predictions are essential to mitigate
potential impacts on critical infrastructure. However, the current performance
of solar flare forecasting is insufficient. In this study, we address the task
of predicting the class of the largest solar flare expected to occur within the
next 72 hours. Existing methods often fail to adequately address the severe
class imbalance across flare classes. To address this issue, we propose a solar
flare prediction model based on multiple deep state space models. In addition,
we introduce the frequency & local-boundary-aware reliability loss (FLARE loss)
to improve predictive performance and reliability under class imbalance.
Experiments were conducted on a multi-wavelength solar image dataset covering a
full 11-year solar activity cycle. As a result, our method outperformed
baseline approaches in terms of both the Gandin-Murphy-Gerrity score and the
true skill statistic, which are standard metrics in terms of the performance
and reliability.

</details>


### [51] [TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion](https://arxiv.org/abs/2509.10005)
*Xiaodong Guo,Tong Liu,Yike Li,Zi'ang Lin,Zhihong Deng*

Main category: cs.CV

TL;DR: 本文提出TUNI模型，通过统一的RGB-T编码器和RGB-T局部模块，解决了RGB-T语义分割中热特征提取受限和跨模态融合不佳的问题。TUNI实现了高效的特征提取和融合，参数更少，计算成本更低，并在边缘设备上展现出实时推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的RGB-T语义分割模型普遍存在以下问题：1) 依赖RGB预训练编码器处理两种模态，导致热特征提取能力有限；2) 跨模态特征融合效果不理想；3) 冗余编码器降低了模型的实时效率。

Method: 本文提出了TUNI模型，主要包括：1) 一个RGB-T编码器，由多个堆叠块组成，能够同时进行多模态特征提取和跨模态融合。该编码器通过RGB和伪热数据进行大规模预训练，实现特征提取和融合的统一学习，并通过精简热分支来获得更紧凑的架构。2) 一个RGB-T局部模块，用于增强编码器在跨模态局部特征融合方面的能力。该模块采用自适应余弦相似度，选择性地强调RGB-T模态间显著的一致和不同局部特征。

Result: 实验结果表明，TUNI在FMB、PST900和CART数据集上取得了与最先进模型相当的性能，同时具有更少的参数和更低的计算成本。此外，TUNI在Jetson Orin NX上实现了27 FPS的推理速度，展示了其在部署中的实时能力。

Conclusion: TUNI通过其统一的RGB-T编码器和RGB-T局部模块，有效解决了RGB-T语义分割中热特征提取和跨模态融合的局限性，并提高了模型的实时效率。它在性能、效率和部署实时性方面均表现出色，为挑战性环境下的自主平台环境感知提供了有效方案。

Abstract: RGB-thermal (RGB-T) semantic segmentation improves the environmental
perception of autonomous platforms in challenging conditions. Prevailing models
employ encoders pre-trained on RGB images to extract features from both RGB and
infrared inputs, and design additional modules to achieve cross-modal feature
fusion. This results in limited thermal feature extraction and suboptimal
cross-modal fusion, while the redundant encoders further compromises the
model's real-time efficiency. To address the above issues, we propose TUNI,
with an RGB-T encoder consisting of multiple stacked blocks that simultaneously
perform multi-modal feature extraction and cross-modal fusion. By leveraging
large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder
learns to integrate feature extraction and fusion in a unified manner. By
slimming down the thermal branch, the encoder achieves a more compact
architecture. Moreover, we introduce an RGB-T local module to strengthen the
encoder's capacity for cross-modal local feature fusion. The RGB-T local module
employs adaptive cosine similarity to selectively emphasize salient consistent
and distinct local features across RGB-T modalities. Experimental results show
that TUNI achieves competitive performance with state-of-the-art models on FMB,
PST900 and CART, with fewer parameters and lower computational cost. Meanwhile,
it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its
real-time capability in deployment. Codes are available at
https://github.com/xiaodonguo/TUNI.

</details>


### [52] [Few-Part-Shot Font Generation](https://arxiv.org/abs/2509.10006)
*Masaki Akiba,Shumpei Takezaki,Daichi Haraguchi,Seiichi Uchida*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的“少部分样本”字体生成模型，仅使用部分设计元素（即部分形状）来生成完整字体。


<details>
  <summary>Details</summary>
Motivation: 传统的少样本字体生成需要完整的字符形状作为输入，而本文旨在通过仅使用部分形状来提高字体创建效率，并深入理解部分设计细节如何影响整体字符结构。

Method: 本文提出了一种新颖的“少部分样本字体生成”模型，该模型以部分形状作为输入，进而设计出完整的字体。

Result: 该模型不仅提高了字体创建的效率，而且揭示了部分设计细节如何影响单个字符的整体结构。

Conclusion: 所提出的模型通过仅使用部分形状输入，实现了高效的字体生成，并为理解部分设计元素对整体字符结构的影响提供了新的视角。

Abstract: This paper proposes a novel model of few-part-shot font generation, which
designs an entire font based on a set of partial design elements, i.e., partial
shapes. Unlike conventional few-shot font generation, which requires entire
character shapes for a couple of character classes, our approach only needs
partial shapes as input. The proposed model not only improves the efficiency of
font creation but also provides insights into how partial design details
influence the entire structure of the individual characters.

</details>


### [53] [Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images](https://arxiv.org/abs/2509.10024)
*Danling Cao*

Main category: cs.CV

TL;DR: 本文提出了一种名为MLANet的卷积神经网络方法，用于从单张野外2D图像中重建详细的3D人脸模型，通过多级注意力机制和半监督训练策略实现了端到端训练，并在基准数据集上取得了有效的结果。


<details>
  <summary>Details</summary>
Motivation: 从野外2D图像中恢复3D人脸模型在计算机视觉领域受到广泛关注，但缺乏地面真实标注数据集以及真实世界环境的复杂性是主要挑战。

Method: 本文提出了一种基于卷积神经网络的层次多级注意力网络（MLANet）。该模型利用预训练的层次骨干网络，并在2D人脸图像特征提取的不同阶段引入多级注意力机制。采用半监督训练策略，结合公开数据集中的3D可变形模型（3DMM）参数和可微分渲染器，实现了端到端训练。模型能够预测人脸几何、纹理、姿态和光照参数。

Result: 在AFLW2000-3D和MICC Florence两个基准数据集上进行了广泛的比较和消融实验，专注于3D人脸重建和3D人脸对齐任务。定量和定性评估均表明所提出的方法是有效的。

Conclusion: 所提出的MLANet方法能够有效克服现有挑战，从单张野外2D图像中重建详细的3D人脸模型，并在多个任务和基准数据集上表现出优异的性能。

Abstract: Recovering 3D face models from 2D in-the-wild images has gained considerable
attention in the computer vision community due to its wide range of potential
applications. However, the lack of ground-truth labeled datasets and the
complexity of real-world environments remain significant challenges. In this
chapter, we propose a convolutional neural network-based approach, the
Hierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face
models from single in-the-wild images. Our model predicts detailed facial
geometry, texture, pose, and illumination parameters from a single image.
Specifically, we employ a pre-trained hierarchical backbone network and
introduce multi-level attention mechanisms at different stages of 2D face image
feature extraction. A semi-supervised training strategy is employed,
incorporating 3D Morphable Model (3DMM) parameters from publicly available
datasets along with a differentiable renderer, enabling an end-to-end training
process. Extensive experiments, including both comparative and ablation
studies, were conducted on two benchmark datasets, AFLW2000-3D and MICC
Florence, focusing on 3D face reconstruction and 3D face alignment tasks. The
effectiveness of the proposed method was evaluated both quantitatively and
qualitatively.

</details>


### [54] [LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA](https://arxiv.org/abs/2509.10026)
*Jing Huang,Zhiya Tan,Shutao Gong,Fanwei Zeng,Jianshu Li*

Main category: cs.CV

TL;DR: LaV-CoT是首个语言感知视觉思维链（CoT）框架，结合多方面奖励优化，显著提升了多语言多模态视觉问答（mVQA）的性能，超越了现有开源及专有模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型（VLMs）在mVQA方面有所进步，但现有CoT方法主要依赖文本CoT，对多语言多模态推理的支持有限，阻碍了其在实际应用中的部署。

Method: LaV-CoT采用可解释的多阶段推理流程（包括带边界框的文本摘要、语言识别、空间对象级字幕和逐步逻辑推理）。设计了通过迭代生成、修正和细化来自动生成多语言CoT注释的数据 Curating 方法。训练范式结合了监督微调（SFT）和语言感知组相对策略优化（GRPO），并由语言一致性、结构准确性和语义对齐等可验证的多方面奖励指导。

Result: 在MMMB、Multilingual MMBench和MTVQA等公开数据集上，LaV-CoT比同等规模的开源基线模型准确率提升高达9.5%，甚至超过2倍规模的模型约2.6%。同时，其性能优于GPT-4o-0513和Gemini-2.5-flash等先进专有模型。在线A/B测试进一步验证了其在实际数据上的有效性。

Conclusion: LaV-CoT成功解决了现有mVQA模型的局限性，通过语言感知的视觉CoT和多方面奖励优化，实现了卓越的性能和泛化能力，对工业部署具有重要意义。

Abstract: As large vision language models (VLMs) advance, their capabilities in
multilingual visual question answering (mVQA) have significantly improved.
Chain-of-thought (CoT) reasoning has been proven to enhance interpretability
and complex reasoning. However, most existing approaches rely primarily on
textual CoT and provide limited support for multilingual multimodal reasoning,
constraining their deployment in real-world applications. To address this gap,
we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework
with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable
multi-stage reasoning pipeline consisting of Text Summary with Bounding Box
(BBox), Language Identification, Spatial Object-level Captioning, and
Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an
automated data curation method that generates multilingual CoT annotations
through iterative generation, correction, and refinement, enabling scalable and
high-quality training data. To improve reasoning and generalization, LaV-CoT
adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)
with Language-aware Group Relative Policy Optimization (GRPO), guided by
verifiable multi-aspect rewards including language consistency, structural
accuracy, and semantic alignment. Extensive evaluations on public datasets
including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up
to \(\sim\)9.5\% accuracy improvements over open-source baselines of similar
size and even surpasses models with 2$\times$ larger scales by \(\sim\)2.6\%.
Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513
and Gemini-2.5-flash. We further conducted an online A/B test to validate our
method on real-world data, highlighting its effectiveness for industrial
deployment. Our code is available at this link:
\href{https://github.com/HJNVR/LaV-CoT}

</details>


### [55] [Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration](https://arxiv.org/abs/2509.10059)
*Yue Zhou,Litong Feng,Mengcheng Lan,Xue Yang,Qingyun Li,Yiping Ke,Xue Jiang,Wayne Zhang*

Main category: cs.CV

TL;DR: 本文引入了AVI-Math，首个用于评估无人机图像中多模态数学推理能力的基准数据集，并发现现有视觉-语言模型（VLMs）在此类任务上表现不佳，但链式思考提示和微调技术显示出潜力。


<details>
  <summary>Details</summary>
Motivation: 数学推理对于无人机遥感中的精确距离、面积计算、轨迹估计和空间分析等任务至关重要。然而，当前的视觉-语言模型（VLMs）尚未在该领域得到充分测试，且现有基准未能涵盖几何、逻辑和代数等领域特定的数学推理任务。

Method: 研究者构建了AVI-Math数据集，包含3,773个从无人机视角捕获的高质量车辆相关问题，涵盖6个数学科目和20个主题，数据采集自不同高度和多个无人机角度，以反映真实世界场景的复杂性。他们对14个主流VLM进行了全面评估，并探索了链式思考（Chain-of-Thought）提示和微调技术在解决推理挑战中的应用。

Result: 尽管在之前的多模态基准测试中取得了成功，但现有VLM在AVI-Math的推理任务中表现不佳，表明其数学推理能力存在显著局限性。然而，链式思考提示和微调技术在解决AVI-Math中的推理挑战方面显示出前景。

Conclusion: 研究不仅揭示了当前VLM在数学推理方面的局限性，而且为未来研究提供了方向，并为推进基于无人机的可信VLM在实际应用中的发展提供了宝贵见解。

Abstract: Mathematical reasoning is critical for tasks such as precise distance and
area computations, trajectory estimations, and spatial analysis in unmanned
aerial vehicle (UAV) based remote sensing, yet current vision-language models
(VLMs) have not been adequately tested in this domain. To address this gap, we
introduce AVI-Math, the first benchmark to rigorously evaluate multimodal
mathematical reasoning in aerial vehicle imagery, moving beyond simple counting
tasks to include domain-specific knowledge in areas such as geometry, logic,
and algebra. The dataset comprises 3,773 high-quality vehicle-related questions
captured from UAV views, covering 6 mathematical subjects and 20 topics. The
data, collected at varying altitudes and from multiple UAV angles, reflects
real-world UAV scenarios, ensuring the diversity and complexity of the
constructed mathematical problems. In this paper, we benchmark 14 prominent
VLMs through a comprehensive evaluation and demonstrate that, despite their
success on previous multimodal benchmarks, these models struggle with the
reasoning tasks in AVI-Math. Our detailed analysis highlights significant
limitations in the mathematical reasoning capabilities of current VLMs and
suggests avenues for future research. Furthermore, we explore the use of
Chain-of-Thought prompting and fine-tuning techniques, which show promise in
addressing the reasoning challenges in AVI-Math. Our findings not only expose
the limitations of VLMs in mathematical reasoning but also offer valuable
insights for advancing UAV-based trustworthy VLMs in real-world applications.
The code, and datasets will be released at
https://github.com/VisionXLab/avi-math

</details>


### [56] [Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation](https://arxiv.org/abs/2509.10058)
*Sung-Lin Tsai,Bo-Lun Huang,Yu Ting Shen,Cheng Yu Yeo,Chiang Tseng,Bo-Kai Ruan,Wen-Sheng Lien,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的框架，利用大型语言模型（LLM）来消歧文本到图像（T2I）生成中的模糊颜色描述，并通过在文本嵌入空间中指导颜色混合操作，从而提高颜色保真度，且不影响图像质量。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在处理微妙和复合颜色术语（如“蒂芙尼蓝”、“酸橙绿”）时，难以准确对齐颜色，导致生成的图像与人类意图不符。现有方法（如交叉注意力操纵、参考图像或微调）未能系统地解决模糊颜色描述问题，而准确的颜色对齐对于时尚、产品可视化等应用至关重要。

Method: 该方法是一个无需训练的框架：首先，利用大型语言模型（LLM）解析文本提示中模糊的颜色术语；然后，根据解析出的颜色术语在CIELAB颜色空间中的空间关系，直接在文本嵌入空间中细化文本嵌入，并指导颜色混合操作。与以往方法不同，该方法无需额外训练或外部参考图像。

Result: 实验结果表明，该框架在不损害图像质量的前提下，显著提高了颜色对齐的准确性。它成功弥合了文本语义与视觉生成之间的差距。

Conclusion: 该研究提供了一种有效的、无需训练的方法，通过结合LLM的语义理解能力和CIELAB颜色空间的结构化信息，解决了T2I模型在处理模糊颜色描述时的挑战，从而显著提升了生成图像的颜色保真度。

Abstract: Accurate color alignment in text-to-image (T2I) generation is critical for
applications such as fashion, product visualization, and interior design, yet
current diffusion models struggle with nuanced and compound color terms (e.g.,
Tiffany blue, lime green, hot pink), often producing images that are misaligned
with human intent. Existing approaches rely on cross-attention manipulation,
reference images, or fine-tuning but fail to systematically resolve ambiguous
color descriptions. To precisely render colors under prompt ambiguity, we
propose a training-free framework that enhances color fidelity by leveraging a
large language model (LLM) to disambiguate color-related prompts and guiding
color blending operations directly in the text embedding space. Our method
first employs a large language model (LLM) to resolve ambiguous color terms in
the text prompt, and then refines the text embeddings based on the spatial
relationships of the resulting color terms in the CIELAB color space. Unlike
prior methods, our approach improves color accuracy without requiring
additional training or external reference images. Experimental results
demonstrate that our framework improves color alignment without compromising
image quality, bridging the gap between text semantics and visual generation.

</details>


### [57] [BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals](https://arxiv.org/abs/2509.10080)
*Minsang Kong,Myeongjun Kim,Sang Gu Kang,Sang Hun Lee*

Main category: cs.CV

TL;DR: BEVTraj是一种新颖的鸟瞰图（BEV）轨迹预测框架，它直接利用实时传感器数据在BEV空间中运行，无需预构建高精地图，并实现了与现有先进模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的轨迹预测依赖高精地图或实时局部地图构建，但高精地图受限于特定区域且无法适应瞬态变化，而局部地图构建可能遗漏关键细节或引入误差，从而影响预测性能。

Method: BEVTraj直接在BEV空间中利用实时传感器数据进行轨迹预测，不依赖预构建地图。它利用可变形注意力机制高效提取BEV特征中的相关上下文，并引入稀疏目标候选提案（SGCP）模块实现完全端到端预测，无需后处理。

Result: 广泛实验表明，BEVTraj在性能上与最先进的基于高精地图的模型相当，同时通过消除对预构建地图的依赖提供了更大的灵活性。

Conclusion: BEVTraj提供了一种灵活且无需预构建地图的轨迹预测解决方案，其性能可与基于高精地图的现有最佳模型媲美，解决了传统方法的局限性。

Abstract: In autonomous driving, trajectory prediction is essential for ensuring safe
and efficient navigation. To improve prediction accuracy, recent approaches
often rely on pre-built high-definition (HD) maps or real-time local map
construction modules to incorporate static environmental information. However,
pre-built HD maps are limited to specific regions and cannot adapt to transient
changes. In addition, local map construction modules, which recognize only
predefined elements, may fail to capture critical scene details or introduce
errors that degrade prediction performance. To overcome these limitations, we
propose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory
prediction framework that operates directly in the bird's-eye view (BEV) space
utilizing real-time sensor data without relying on any pre-built maps. The
BEVTraj leverages deformable attention to efficiently extract relevant context
from dense BEV features. Furthermore, we introduce a Sparse Goal Candidate
Proposal (SGCP) module, which enables full end-to-end prediction without
requiring any post-processing steps. Extensive experiments demonstrate that the
BEVTraj achieves performance comparable to state-of-the-art HD map-based models
while offering greater flexibility by eliminating the dependency on pre-built
maps. The source code is available at https://github.com/Kongminsang/bevtraj.

</details>


### [58] [Realism Control One-step Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2509.10122)
*Zongliang Wu,Siming Zheng,Peng-Tao Jiang,Xin Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种名为RCOD的真实世界图像超分辨率（Real-ISR）一步扩散模型，通过潜在域分组策略、降级感知采样和视觉提示注入，解决了现有一步扩散模型在保真度和真实感之间平衡的挑战，实现了灵活控制、卓越性能和高效率。


<details>
  <summary>Details</summary>
Motivation: 预训练扩散模型在Real-ISR任务中潜力巨大，但一步扩散（OSD）方法虽然提高了效率，却难以在不同场景下平衡保真度和真实感。这是因为OSD通常通过单一时间步训练或蒸馏，缺乏像多步方法那样通过调整采样步数来灵活控制这些竞争目标的能力。

Method: 本文提出了一个真实感控制一步扩散（RCOD）框架：1. 引入了潜在域分组策略，在噪声预测阶段实现对保真度-真实感权衡的显式控制。2. 提出了降级感知采样策略，使蒸馏正则化与分组策略对齐，并增强权衡控制。3. 使用视觉提示注入模块，以降级感知视觉Token取代传统文本提示，提高恢复精度和语义一致性。

Result: RCOD在保持计算效率的同时，实现了卓越的保真度和感知质量。广泛的实验表明，RCOD在定量指标和视觉质量上均优于最先进的一步扩散方法，并在推理阶段提供了灵活的真实感控制能力。

Conclusion: RCOD框架通过创新的潜在域分组、降级感知采样和视觉提示注入，有效解决了Real-ISR中一步扩散模型在保真度和真实感平衡方面的局限性，提供了高效、高性能且可灵活控制的超分辨率解决方案。

Abstract: Pre-trained diffusion models have shown great potential in real-world image
super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.
While one-step diffusion (OSD) methods significantly improve efficiency
compared to traditional multi-step approaches, they still have limitations in
balancing fidelity and realism across diverse scenarios. Since the OSDs for SR
are usually trained or distilled by a single timestep, they lack flexible
control mechanisms to adaptively prioritize these competing objectives, which
are inherently manageable in multi-step methods through adjusting sampling
steps. To address this challenge, we propose a Realism Controlled One-step
Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping
strategy that enables explicit control over fidelity-realism trade-offs during
the noise prediction phase with minimal training paradigm modifications and
original training data. A degradation-aware sampling strategy is also
introduced to align distillation regularization with the grouping strategy and
enhance the controlling of trade-offs. Moreover, a visual prompt injection
module is used to replace conventional text prompts with degradation-aware
visual tokens, enhancing both restoration accuracy and semantic consistency.
Our method achieves superior fidelity and perceptual quality while maintaining
computational efficiency. Extensive experiments demonstrate that RCOD
outperforms state-of-the-art OSD methods in both quantitative metrics and
visual qualities, with flexible realism control capabilities in the inference
stage. The code will be released.

</details>


### [59] [Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing](https://arxiv.org/abs/2509.10093)
*Laura Bragagnolo,Matteo Terreran,Leonardo Barcellona,Stefano Ghidoni*

Main category: cs.CV

TL;DR: 该研究针对多人解析中人体遮挡问题，提出了一种利用多视角信息的新型训练框架，结合弱监督和多视角一致性损失，并在遮挡场景下实现了显著性能提升。同时，还提出了一种半自动标注策略来生成多视角数据集。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的多人解析方法在处理人体相互重叠（即遮挡）的场景时表现不佳。

Method: 1. 提出了一种利用多视角信息的新型训练框架，以改善遮挡下的多人解析模型。2. 在训练过程中引入了基于人体实例弱监督的新方法。3. 引入了多视角一致性损失。4. 针对缺乏合适数据集的问题，提出了一种半自动标注策略，从多视角RGB+D数据和3D人体骨架生成人体实例分割掩码。

Result: 在遮挡场景下，该方法在人体解析方面比基线模型取得了高达4.20%的相对改进。

Conclusion: 该研究提出的多视角训练框架，结合弱监督和一致性损失，能有效提高多人解析模型在人体遮挡场景下的性能，并通过半自动标注解决了数据集稀缺问题。

Abstract: Multi-human parsing is the task of segmenting human body parts while
associating each part to the person it belongs to, combining instance-level and
part-level information for fine-grained human understanding. In this work, we
demonstrate that, while state-of-the-art approaches achieved notable results on
public datasets, they struggle considerably in segmenting people with
overlapping bodies. From the intuition that overlapping people may appear
separated from a different point of view, we propose a novel training framework
exploiting multi-view information to improve multi-human parsing models under
occlusions. Our method integrates such knowledge during the training process,
introducing a novel approach based on weak supervision on human instances and a
multi-view consistency loss. Given the lack of suitable datasets in the
literature, we propose a semi-automatic annotation strategy to generate human
instance segmentation masks from multi-view RGB+D data and 3D human skeletons.
The experiments demonstrate that the approach can achieve up to a 4.20\%
relative improvement on human parsing over the baseline model in occlusion
scenarios.

</details>


### [60] [VARCO-VISION-2.0 Technical Report](https://arxiv.org/abs/2509.10105)
*Young-rok Cha,Jeongho Ju,SunYoung Park,Jong-Hyeon Lee,Younghyun Yu,Youngjune Kim*

Main category: cs.CV

TL;DR: 本文介绍了VARCO-VISION-2.0，一个改进的韩语和英语双语视觉-语言模型（VLM），它支持多图像理解、布局感知OCR，并通过多阶段训练和偏好优化实现了增强的多模态对齐和安全性，并在基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了改进前代模型VARCO-VISION-14B，提升双语VLM在韩语和英语上的能力，支持文档、图表、表格等复杂输入的多图像理解，并提供布局感知的OCR功能，同时保持核心语言能力和提高安全性。

Method: 模型采用四阶段课程训练，结合内存高效技术以实现增强的多模态对齐。通过偏好优化来保持核心语言能力并提高安全性。它还支持多图像理解，并能预测文本内容及其空间位置以实现布局感知OCR。

Result: VARCO-VISION-2.0实现了增强的多模态对齐，同时保留了核心语言能力并提高了安全性。在广泛的基准评估中，模型在两种语言上都展现出强大的空间定位能力和竞争力，其中14B模型在OpenCompass VLM排行榜上同等规模模型中排名第8。此外，还发布了针对设备部署优化的1.7B版本。

Conclusion: VARCO-VISION-2.0模型（包括14B和1.7B版本）的发布，标志着双语VLM及其实际应用发展的重要进展。

Abstract: We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model
(VLM) for Korean and English with improved capabilities compared to the
previous model VARCO-VISION-14B. The model supports multi-image understanding
for complex inputs such as documents, charts, and tables, and delivers
layoutaware OCR by predicting both textual content and its spatial location.
Trained with a four-stage curriculum with memory-efficient techniques, the
model achieves enhanced multimodal alignment, while preserving core language
abilities and improving safety via preference optimization. Extensive benchmark
evaluations demonstrate strong spatial grounding and competitive results for
both languages, with the 14B model achieving 8th place on the OpenCompass VLM
leaderboard among models of comparable scale. Alongside the 14B-scale model, we
release a 1.7B version optimized for on-device deployment. We believe these
models advance the development of bilingual VLMs and their practical
applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a
full-scale 14B model and a lightweight 1.7B model.

</details>


### [61] [A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss](https://arxiv.org/abs/2509.10114)
*MohammadAli Hamidi,Hadi Amirpour,Luigi Atzori,Christian Timmerer*

Main category: cs.CV

TL;DR: 本文提出了一种轻量高效的人脸图像质量评估（FIQA）方法，通过集成紧凑型CNN模型和结合皮尔逊相关系数的损失函数，在保证准确性的同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的通用无参考图像质量评估技术无法有效捕捉人脸特有的退化，而最先进的FIQA模型则计算量大，限制了其实际应用，尤其是在不受控的真实世界环境中。

Method: 该方法集成了两个紧凑型卷积神经网络（MobileNetV3-Small和ShuffleNetV2），通过简单平均进行预测级融合。为增强与人类感知判断的一致性，采用了相关感知损失（MSECorrLoss），该损失结合了均方误差（MSE）和皮尔逊相关正则化器。

Result: 在VQualA FIQA基准测试中，该模型实现了0.9829的Spearman秩相关系数（SRCC）和0.9894的Pearson线性相关系数（PLCC），并在效率约束范围内保持了高性能，达到了准确性和计算成本之间的良好平衡。

Conclusion: 所提出的方法在准确性和计算成本之间取得了强大的平衡，使其适用于真实世界的部署，解决了现有FIQA模型在捕获人脸特有退化和计算效率方面的局限性。

Abstract: Face image quality assessment (FIQA) plays a critical role in face
recognition and verification systems, especially in uncontrolled, real-world
environments. Although several methods have been proposed, general-purpose
no-reference image quality assessment techniques often fail to capture
face-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be
computationally intensive, limiting their practical applicability. We propose a
lightweight and efficient method for FIQA, designed for the perceptual
evaluation of face images in the wild. Our approach integrates an ensemble of
two compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,
with prediction-level fusion via simple averaging. To enhance alignment with
human perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),
combining mean squared error (MSE) with a Pearson correlation regularizer. Our
method achieves a strong balance between accuracy and computational cost,
making it suitable for real-world deployment. Experiments on the VQualA FIQA
benchmark demonstrate that our model achieves a Spearman rank correlation
coefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient
(PLCC) of 0.9894, remaining within competition efficiency constraints.

</details>


### [62] [Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment](https://arxiv.org/abs/2509.10134)
*Rini Smita Thakur,Rajeev Ranjan Dwivedi,Vinod K Kurmi*

Main category: cs.CV

TL;DR: Grad-CL是一个新颖的无源域适应框架，结合梯度引导的伪标签细化和对比学习，用于在不访问原始源数据的情况下，鲁棒地适应视盘和视杯的分割模型，以解决跨域性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 由于成像协议或条件差异，在一个数据集上训练的分割模型在应用于目标数据时性能会显著下降。准确的视盘和视杯分割对于青光眼等眼部疾病的早期诊断和管理至关重要，因此需要解决跨域性能下降的问题。

Method: 本文提出了Grad-CL框架，它利用预训练的源模型和未标记的目标数据进行适应。该方法结合了两个阶段：1) 梯度引导的伪标签细化模块，通过梯度机制提取显著的类别特定特征，实现更准确的不确定性量化和鲁棒的原型估计，以细化噪声伪标签；2) 基于余弦相似度的对比学习策略，明确强制视杯和视盘的梯度信息特征之间的类间可分离性。

Result: 在具有挑战性的跨域眼底图像数据集上的大量实验表明，Grad-CL优于最先进的无监督和无源域适应方法，实现了卓越的分割精度和改进的边界描绘。

Conclusion: Grad-CL是一个有效的无源域适应框架，能够鲁棒地适应视盘和视杯的分割模型，显著提高在不同成像协议或条件下的目标数据上的性能，而无需访问原始源数据。

Abstract: Accurate segmentation of the optic disc and cup is critical for the early
diagnosis and management of ocular diseases such as glaucoma. However,
segmentation models trained on one dataset often suffer significant performance
degradation when applied to target data acquired under different imaging
protocols or conditions. To address this challenge, we propose
\textbf{Grad-CL}, a novel source-free domain adaptation framework that
leverages a pre-trained source model and unlabeled target data to robustly
adapt segmentation performance without requiring access to the original source
data. Grad-CL combines a gradient-guided pseudolabel refinement module with a
cosine similarity-based contrastive learning strategy. In the first stage,
salient class-specific features are extracted via a gradient-based mechanism,
enabling more accurate uncertainty quantification and robust prototype
estimation for refining noisy pseudolabels. In the second stage, a contrastive
loss based on cosine similarity is employed to explicitly enforce inter-class
separability between the gradient-informed features of the optic cup and disc.
Extensive experiments on challenging cross-domain fundus imaging datasets
demonstrate that Grad-CL outperforms state-of-the-art unsupervised and
source-free domain adaptation methods, achieving superior segmentation accuracy
and improved boundary delineation. Project and code are available at
https://visdomlab.github.io/GCL/.

</details>


### [63] [SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion](https://arxiv.org/abs/2509.10266)
*Wenfang Wu,Tingting Yuan,Yupeng Li,Daling Wang,Xiaoming Fu*

Main category: cs.CV

TL;DR: SignClip通过融合手势和唇部动作等非手动线索，并采用分层对比学习框架，显著提升了手语翻译的准确性，超越了现有最先进模型。


<details>
  <summary>Details</summary>
Motivation: 现有的手语翻译方法主要关注手动信号（手势），却忽略了唇部动作等非手动线索，而这些线索在手语中传递着重要的语言信息，并有助于区分视觉上相似的符号。

Method: 本文提出了SignClip框架，它融合了空间手势和唇部动作特征（即手动和非手动线索）。此外，SignClip引入了一个分层对比学习框架，具有多级对齐目标，以确保手语-唇部和视觉-文本模态之间的语义一致性。

Result: 在PHOENIX14T和How2Sign两个基准数据集上进行了广泛实验，证明了该方法的优越性。例如，在PHOENIX14T数据集的无Gloss设置下，SignClip的BLEU-4从24.32提高到24.71，ROUGE从46.57提高到48.38，超越了之前的最先进模型SpaMo。

Conclusion: SignClip通过有效融合手动和非手动线索，并利用分层对比学习，显著提高了手语翻译的准确性，为包容性交流提供了重要的技术支持。

Abstract: Sign language translation (SLT) aims to translate natural language from sign
language videos, serving as a vital bridge for inclusive communication. While
recent advances leverage powerful visual backbones and large language models,
most approaches mainly focus on manual signals (hand gestures) and tend to
overlook non-manual cues like mouthing. In fact, mouthing conveys essential
linguistic information in sign languages and plays a crucial role in
disambiguating visually similar signs. In this paper, we propose SignClip, a
novel framework to improve the accuracy of sign language translation. It fuses
manual and non-manual cues, specifically spatial gesture and lip movement
features. Besides, SignClip introduces a hierarchical contrastive learning
framework with multi-level alignment objectives, ensuring semantic consistency
across sign-lip and visual-text modalities. Extensive experiments on two
benchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our
approach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip
surpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from
24.32 to 24.71, and ROUGE from 46.57 to 48.38.

</details>


### [64] [Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization](https://arxiv.org/abs/2509.10140)
*Yifan Chang,Jie Qin,Limeng Qiao,Xiaofeng Wang,Zheng Zhu,Lin Ma,Xingang Wang*

Main category: cs.CV

TL;DR: 向量量化（VQ）训练因不稳定性导致性能不佳和码本利用率低。本文提出了VQBridge结合学习退火，实现了100%码本利用率（FVQ），显著提升了重建质量和图像生成性能，超越了现有模型。


<details>
  <summary>Details</summary>
Motivation: 向量量化（VQ）作为图像生成离散分词器的关键组件，其训练常因直通估计偏差、一步滞后更新和稀疏码本梯度而变得不稳定，导致重建性能不理想和码本利用率低下。

Method: 本文提出VQBridge，一种基于映射函数方法的鲁棒、可扩展、高效的投影器，通过“压缩-处理-恢复”管道优化码向量，实现稳定的码本训练。通过将VQBridge与学习退火相结合，实现了100%码本利用率的VQN，称之为FVQ（FullVQ）。

Result: FVQ在各种码本配置下均实现了100%的码本利用率（包括262k码本），达到了最先进的重建性能，并随着码本增大、向量通道增加或训练时间延长而持续改进。它对不同的VQ变体都有效。此外，与LlamaGen结合后，FVQ显著提升了图像生成性能，在rFID指标上超越了视觉自回归模型（VAR）0.5和扩散模型（DiT）0.2。

Conclusion: FVQ通过解决VQ训练的不稳定性问题，证明了高质量分词器对于强大的自回归图像生成至关重要，并能显著提升生成模型的性能。

Abstract: Vector quantization (VQ) is a key component in discrete tokenizers for image
generation, but its training is often unstable due to straight-through
estimation bias, one-step-behind updates, and sparse codebook gradients, which
lead to suboptimal reconstruction performance and low codebook usage. In this
work, we analyze these fundamental challenges and provide a simple yet
effective solution. To maintain high codebook usage in VQ networks (VQN) during
learning annealing and codebook size expansion, we propose VQBridge, a robust,
scalable, and efficient projector based on the map function method. VQBridge
optimizes code vectors through a compress-process-recover pipeline, enabling
stable and effective codebook training. By combining VQBridge with learning
annealing, our VQN achieves full (100%) codebook usage across diverse codebook
configurations, which we refer to as FVQ (FullVQ). Through extensive
experiments, we demonstrate that FVQ is effective, scalable, and generalizable:
it attains 100% codebook usage even with a 262k-codebook, achieves
state-of-the-art reconstruction performance, consistently improves with larger
codebooks, higher vector channels, or longer training, and remains effective
across different VQ variants. Moreover, when integrated with LlamaGen, FVQ
significantly enhances image generation performance, surpassing visual
autoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,
highlighting the importance of high-quality tokenizers for strong
autoregressive image generation.

</details>


### [65] [I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation](https://arxiv.org/abs/2509.10334)
*Jordan Sassoon,Michal Szczepanski,Martyna Poreba*

Main category: cs.CV

TL;DR: ViT分割模型在资源受限设备上部署困难，I-Segmenter是首个全整数ViT分割框架，通过系统地替换浮点运算、引入新型激活函数和优化层，显著降低了模型大小和计算成本，同时保持了合理的精度。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers (ViTs) 在语义分割中表现出色，但其高内存占用和计算成本限制了它们在资源受限设备上的部署。量化是提高效率的有效策略，但ViT分割模型在低精度下表现脆弱，因为量化误差会在深层编解码器管道中累积。

Method: 本文引入了I-Segmenter，这是首个全整数ViT分割框架。该方法基于Segmenter架构，系统地将浮点运算替换为全整数运算。为稳定训练和推理，提出了一种新型激活函数 $\lambda$-ShiftGELU，以缓解均匀量化在处理长尾激活分布时的局限性。此外，移除了L2归一化层，并将解码器中的双线性插值替换为最近邻上采样，以确保整个计算图的全整数执行。

Result: I-Segmenter在精度上与FP32基线模型相比，平均下降5.1%，但在可接受范围内。模型大小减少了高达3.8倍，通过优化的运行时，推理速度提高了1.2倍。值得注意的是，即使在单次PTQ（Post-Training Quantization）使用单个校准图像的情况下，I-Segmenter也能提供有竞争力的精度。

Conclusion: I-Segmenter作为首个全整数ViT分割框架，成功解决了ViT分割模型在资源受限设备上部署的挑战。通过全面的整数化策略和创新方法，它在保持合理精度的同时，显著提升了模型效率和在实际部署中的实用性。

Abstract: Vision Transformers (ViTs) have recently achieved strong results in semantic
segmentation, yet their deployment on resource-constrained devices remains
limited due to their high memory footprint and computational cost. Quantization
offers an effective strategy to improve efficiency, but ViT-based segmentation
models are notoriously fragile under low precision, as quantization errors
accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the
first fully integer-only ViT segmentation framework. Building on the Segmenter
architecture, I-Segmenter systematically replaces floating-point operations
with integer-only counterparts. To further stabilize both training and
inference, we propose $\lambda$-ShiftGELU, a novel activation function that
mitigates the limitations of uniform quantization in handling long-tailed
activation distributions. In addition, we remove the L2 normalization layer and
replace bilinear interpolation in the decoder with nearest neighbor upsampling,
ensuring integer-only execution throughout the computational graph. Extensive
experiments show that I-Segmenter achieves accuracy within a reasonable margin
of its FP32 baseline (5.1 % on average), while reducing model size by up to
3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,
even in one-shot PTQ with a single calibration image, I-Segmenter delivers
competitive accuracy, underscoring its practicality for real-world deployment.

</details>


### [66] [LayerLock: Non-collapsing Representation Learning with Progressive Freezing](https://arxiv.org/abs/2509.10156)
*Goker Erdogan,Nikhil Parthasarathy,Catalin Ionescu,Drew Hudson,Alexander Lerchner,Andrew Zisserman,Mehdi Sajjadi,Joao Carreira*

Main category: cs.CV

TL;DR: LayerLock是一种通过渐进式层冻结，从像素预测过渡到潜在预测的自监督视觉表示学习方法，它能加速MAE训练并避免表示崩溃。


<details>
  <summary>Details</summary>
Motivation: 研究发现，在视频掩码自编码器（MAE）模型训练中，ViT层收敛顺序与其深度相关：浅层先收敛，深层后收敛。这一发现启发了利用层收敛顺序来改进训练过程。

Method: LayerLock方法在训练过程中根据预设的时间表，逐步冻结模型层。同时，该时间表也被用于潜在预测，以避免“表示崩溃”问题。

Result: LayerLock方法能够加速标准MAE模型的训练。在4DS感知套件上，使用LayerLock训练的4B参数大型模型，其结果超越了非潜在掩码预测方法。

Conclusion: LayerLock是一种简单而有效的自监督视觉表示学习方法，通过渐进式层冻结，不仅能加速MAE训练，还能以可扩展的方式实现稳定的潜在预测，避免表示崩溃，并取得了优异的性能。

Abstract: We introduce LayerLock, a simple yet effective approach for self-supervised
visual representation learning, that gradually transitions from pixel to latent
prediction through progressive layer freezing. First, we make the observation
that during training of video masked-autoencoding (MAE) models, ViT layers
converge in the order of their depth: shallower layers converge early, deeper
layers converge late. We then show that this observation can be exploited to
accelerate standard MAE by progressively freezing the model according to an
explicit schedule, throughout training. Furthermore, this same schedule can be
used in a simple and scalable approach to latent prediction that does not
suffer from "representation collapse". We apply our proposed approach,
LayerLock, to large models of up to 4B parameters with results surpassing those
of non-latent masked prediction on the 4DS perception suite.

</details>


### [67] [GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography](https://arxiv.org/abs/2509.10344)
*Yuexi Du,Lihui Chen,Nicha C. Dvornek*

Main category: cs.CV

TL;DR: 本文提出GLAM模型，一个用于乳腺钼靶多视图视觉语言模型预训练的新方法，通过几何指导进行全局和局部对齐，解决了现有模型忽视多视图关系的问题，显著提高了乳腺癌筛查的准确性。


<details>
  <summary>Details</summary>
Motivation: 乳腺钼靶筛查的解读速度和准确性可通过深度学习提升，但现有视觉语言模型（VLM）受限于数据、自然图像与医学图像的领域差异，且未能有效处理乳腺钼靶的多视图关系（如将不同视图视为独立图像），导致关键几何上下文丢失和次优预测。

Method: 提出GLAM模型，通过几何指导进行多视图乳腺钼靶VLM预训练。该模型利用多视图成像过程的先验知识，通过联合全局和局部、视觉-视觉以及视觉-语言对比学习，学习局部跨视图对齐和细粒度局部特征。

Result: GLAM模型在最大的开放乳腺钼靶数据集EMBED上进行预训练后，在多种数据集和不同设置下均优于现有基线模型。

Conclusion: GLAM通过有效整合多视图几何信息和对比学习，显著提升了乳腺钼靶视觉语言模型的性能，有望改进乳腺癌的早期检测。

Abstract: Mammography screening is an essential tool for early detection of breast
cancer. The speed and accuracy of mammography interpretation have the potential
to be improved with deep learning methods. However, the development of a
foundation visual language model (VLM) is hindered by limited data and domain
differences between natural and medical images. Existing mammography VLMs,
adapted from natural images, often ignore domain-specific characteristics, such
as multi-view relationships in mammography. Unlike radiologists who analyze
both views together to process ipsilateral correspondence, current methods
treat them as independent images or do not properly model the multi-view
correspondence learning, losing critical geometric context and resulting in
suboptimal prediction. We propose GLAM: Global and Local Alignment for
Multi-view mammography for VLM pretraining using geometry guidance. By
leveraging the prior knowledge about the multi-view imaging process of
mammograms, our model learns local cross-view alignments and fine-grained local
features through joint global and local, visual-visual, and visual-language
contrastive learning. Pretrained on EMBED [14], one of the largest open
mammography datasets, our model outperforms baselines across multiple datasets
under different settings.

</details>


### [68] [On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints](https://arxiv.org/abs/2509.10241)
*Elias De Smijter,Renaud Detry,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 本文首次系统比较了用于空间三维物体重建的隐式和显式新视角合成（NVS）方法，并评估了外观嵌入的作用，发现外观嵌入主要提高光度保真度而非几何精度，且凸散列比高斯散列更紧凑。


<details>
  <summary>Details</summary>
Motivation: 三维物体重建对于空间机器人应用至关重要，需要深入理解外观嵌入在提高几何精度方面的实际效果，以满足空间机器人对高几何精度的关键需求。

Method: 本文在SPEED+数据集上，系统比较了K-Planes（隐式）、Gaussian Splatting（显式）和Convex Splatting（显式）三种NVS方法，并评估了外观嵌入对这些方法性能的影响。

Result: 研究发现，外观嵌入能提高光度保真度（建模光照变化），但并未显著提升几何精度。对于显式方法，外观嵌入主要减少了所需基元的数量，而非增强几何保真度。此外，凸散列（Convex Splatting）比高斯散列（Gaussian Splatting）实现了更紧凑、更简洁的表示。

Conclusion: 研究结果明确了外观嵌入在以几何为中心任务中的局限性，并强调了在空间场景中重建质量与表示效率之间的权衡，这对安全关键应用（如交互和避碰）具有重要意义。

Abstract: We present the first systematic comparison of implicit and explicit Novel
View Synthesis methods for space-based 3D object reconstruction, evaluating the
role of appearance embeddings. While embeddings improve photometric fidelity by
modeling lighting variation, we show they do not translate into meaningful
gains in geometric accuracy - a critical requirement for space robotics
applications. Using the SPEED+ dataset, we compare K-Planes, Gaussian
Splatting, and Convex Splatting, and demonstrate that embeddings primarily
reduce the number of primitives needed for explicit methods rather than
enhancing geometric fidelity. Moreover, convex splatting achieves more compact
and clutter-free representations than Gaussian splatting, offering advantages
for safety-critical applications such as interaction and collision avoidance.
Our findings clarify the limits of appearance embeddings for geometry-centric
tasks and highlight trade-offs between reconstruction quality and
representation efficiency in space scenarios.

</details>


### [69] [Towards Understanding Visual Grounding in Visual Language Models](https://arxiv.org/abs/2509.10345)
*Georgios Pantazopoulos,Eda B. Özyiğit*

Main category: cs.CV

TL;DR: 这篇综述论文审查了现代通用视觉语言模型（VLMs）中视觉定位（Visual Grounding）的关键研究领域，涵盖其重要性、核心组成、实际应用、评估指标、与多模态思维链和推理的关系，并分析了挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 视觉定位能力使模型能够识别视觉输入中与文本描述匹配的区域，从而支持广泛的应用，如指代表达理解、细粒度问答、实体引用图像描述以及模拟和真实环境中的控制。

Method: 本文采用综述方法，回顾了现代通用视觉语言模型（VLMs）中视觉定位的代表性工作。具体包括：概述视觉定位在VLM中的重要性、描绘开发定位模型的核心组件、审视其实际应用（包括基准和评估指标）、讨论视觉定位、多模态思维链和VLM中推理之间的多方面相互关系。

Result: 论文提供了对视觉定位在VLM中全面审视，包括其核心范式、广泛的应用场景、用于多模态生成的基准和评估指标，以及其与多模态思维链和推理的复杂关联。

Conclusion: 论文分析了视觉定位固有的挑战，并提出了未来研究的有前景方向。

Abstract: Visual grounding refers to the ability of a model to identify a region within
some visual input that matches a textual description. Consequently, a model
equipped with visual grounding capabilities can target a wide range of
applications in various domains, including referring expression comprehension,
answering questions pertinent to fine-grained details in images or videos,
caption visual context by explicitly referring to entities, as well as low and
high-level control in simulated and real environments. In this survey paper, we
review representative works across the key areas of research on modern
general-purpose vision language models (VLMs). We first outline the importance
of grounding in VLMs, then delineate the core components of the contemporary
paradigm for developing grounded models, and examine their practical
applications, including benchmarks and evaluation metrics for grounded
multimodal generation. We also discuss the multifaceted interrelations among
visual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,
we analyse the challenges inherent to visual grounding and suggest promising
directions for future research.

</details>


### [70] [GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection](https://arxiv.org/abs/2509.10250)
*Haozhen Yan,Yan Hong,Suning Lang,Jiahui Zhan,Yikun Ji,Yujie Gao,Jun Lan,Huijia Zhu,Weiqiang Wang,Jianfu Zhang*

Main category: cs.CV

TL;DR: 现有AI生成图像检测器在泛化到未见过模型时表现不佳，因其依赖特定生成伪影。本文提出GAMMA框架，通过多样化操作、多任务监督和逆向交叉注意力机制，减少领域偏差并增强语义对齐，显著提升了泛化性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器在处理分布内图像时表现良好，但对未见过的生成模型泛化能力有限。这主要是因为它们过度依赖生成模型特有的伪影，如风格先验和压缩模式。

Method: 本文提出GAMMA训练框架，旨在减少领域偏差并增强语义对齐。主要方法包括：1) 引入多样化操作策略（如基于修复的操作和语义保留扰动），以确保操作内容与真实内容之间的一致性。2) 采用带有双分割头和分类头的多任务监督，实现跨不同生成域的像素级源归因。3) 引入逆向交叉注意力机制，使分割头能够引导和纠正分类分支中存在的偏差表示。

Result: GAMMA方法在GenImage基准测试上取得了最先进的泛化性能，准确率提高了5.8%。此外，该方法对GPT-4o等新发布的生成模型也保持了强大的鲁棒性。

Conclusion: 通过引入多样化操作策略、多任务监督和逆向交叉注意力机制，GAMMA框架有效解决了AI生成图像检测器在泛化到未见模型时的局限性，显著提升了检测的准确性和对新模型的鲁棒性。

Abstract: With generative models becoming increasingly sophisticated and diverse,
detecting AI-generated images has become increasingly challenging. While
existing AI-genereted Image detectors achieve promising performance on
in-distribution generated images, their generalization to unseen generative
models remains limited. This limitation is largely attributed to their reliance
on generation-specific artifacts, such as stylistic priors and compression
patterns. To address these limitations, we propose GAMMA, a novel training
framework designed to reduce domain bias and enhance semantic alignment. GAMMA
introduces diverse manipulation strategies, such as inpainting-based
manipulation and semantics-preserving perturbations, to ensure consistency
between manipulated and authentic content. We employ multi-task supervision
with dual segmentation heads and a classification head, enabling pixel-level
source attribution across diverse generative domains. In addition, a reverse
cross-attention mechanism is introduced to allow the segmentation heads to
guide and correct biased representations in the classification branch. Our
method achieves state-of-the-art generalization performance on the GenImage
benchmark, imporving accuracy by 5.8%, but also maintains strong robustness on
newly released generative model such as GPT-4o.

</details>


### [71] [Multimodal SAM-adapter for Semantic Segmentation](https://arxiv.org/abs/2509.10408)
*Iacopo Curti,Pierluigi Zama Ramirez,Alioscia Petrelli,Luigi Di Stefano*

Main category: cs.CV

TL;DR: 本文提出了MM SAM-adapter框架，通过适配器网络将融合的多模态特征注入到SAM的RGB特征中，从而扩展SAM以实现多模态语义分割，并在挑战性基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 语义分割在恶劣条件（如光照不足、遮挡、恶劣天气）下表现不佳。多模态方法通过整合辅助传感器数据（如LiDAR、红外）来增强鲁棒性，但需要一种有效的方式来将这些信息与像SAM这样强大的模型结合。

Method: MM SAM-adapter框架通过一个适配器网络工作，该网络将融合的多模态特征注入到SAM的RGB特征中。这种设计允许模型保留RGB特征强大的泛化能力，同时仅在辅助模态提供额外线索时选择性地整合它们，从而实现多模态信息的平衡和高效利用。

Result: MM SAM-adapter在DeLiVER、FMB和MUSES三个具有挑战性的基准测试中取得了最先进的性能。在DeLiVER和FMB的RGB-easy和RGB-hard子集中，该框架始终优于竞争方法，证明了其在有利和不利条件下都具有出色的表现。

Conclusion: MM SAM-adapter通过有效地整合多模态信息，增强了SAM的语义分割能力，特别是在挑战性条件下实现了鲁棒的场景理解。该方法在多个基准测试中表现出最先进的性能，证明了多模态适应在提升场景理解方面的有效性。

Abstract: Semantic segmentation, a key task in computer vision with broad applications
in autonomous driving, medical imaging, and robotics, has advanced
substantially with deep learning. Nevertheless, current approaches remain
vulnerable to challenging conditions such as poor lighting, occlusions, and
adverse weather. To address these limitations, multimodal methods that
integrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,
providing complementary information that enhances robustness. In this work, we
present MM SAM-adapter, a novel framework that extends the capabilities of the
Segment Anything Model (SAM) for multimodal semantic segmentation. The proposed
method employs an adapter network that injects fused multimodal features into
SAM's rich RGB features. This design enables the model to retain the strong
generalization ability of RGB features while selectively incorporating
auxiliary modalities only when they contribute additional cues. As a result, MM
SAM-adapter achieves a balanced and efficient use of multimodal information. We
evaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,
where MM SAM-adapter delivers state-of-the-art performance. To further analyze
modality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard
subsets. Results consistently demonstrate that our framework outperforms
competing methods in both favorable and adverse conditions, highlighting the
effectiveness of multimodal adaptation for robust scene understanding. The code
is available at the following link:
https://github.com/iacopo97/Multimodal-SAM-Adapter.

</details>


### [72] [Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI](https://arxiv.org/abs/2509.10257)
*Ema Masterl,Tina Vipotnik Vesnaver,Žiga Špiclin*

Main category: cs.CV

TL;DR: 本研究比较了三种最先进的胎儿脑部MRI超分辨率重建（SRR）方法（NiftyMIC, SVRTK, NeSVoR），发现在健康和病理病例中，NeSVoR的重建成功率最高且最稳定。尽管不同SRR方法导致体积测量存在显著差异，但诊断分类性能并未受SRR方法选择的影响。


<details>
  <summary>Details</summary>
Motivation: 胎儿脑部MRI通常采用快速多视角2D切片采集，以减少胎儿运动引起的伪影，但这些切片分辨率低，可能受运动损坏，且未能充分捕捉3D解剖结构。超分辨率重建（SRR）方法旨在通过结合切片到体积配准和超分辨率技术来生成高分辨率（HR）3D体积，但其比较性能（尤其是在病理病例中）及其对后续体积分析和诊断任务的影响仍未得到充分探索。

Method: 研究将NiftyMIC、SVRTK和NeSVoR这三种最先进的SRR方法应用于140例胎儿脑部MRI扫描，其中包括健康对照组（HC）和伴有脑室扩张（VM）的病理病例组（PC）。每个高分辨率重建体都使用BoUNTi算法进行分割，以提取九个主要脑结构的体积。评估了视觉质量、SRR成功率、体积测量一致性和诊断分类性能。

Result: NeSVoR在HC和PC两组中均表现出最高且最一致的重建成功率（>90%）。尽管在体积估算方面，不同SRR方法之间存在显著差异，但VM的诊断分类性能并未受SRR方法选择的影响。

Conclusion: 这些发现突出了NeSVoR的鲁棒性，以及尽管SRR方法引起的体积变异性，诊断性能仍具有韧性。

Abstract: Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce
motion artifacts caused by fetal movement. However, these stacks are typically
low resolution, may suffer from motion corruption, and do not adequately
capture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to
address these limitations by combining slice-to-volume registration and
super-resolution techniques to generate high-resolution (HR) 3D volumes. While
several SRR methods have been proposed, their comparative performance -
particularly in pathological cases - and their influence on downstream
volumetric analysis and diagnostic tasks remain underexplored. In this study,
we applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to
140 fetal brain MRI scans, including both healthy controls (HC) and
pathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was
segmented using the BoUNTi algorithm to extract volumes of nine principal brain
structures. We evaluated visual quality, SRR success rates, volumetric
measurement agreement, and diagnostic classification performance. NeSVoR
demonstrated the highest and most consistent reconstruction success rate (>90%)
across both HC and PC groups. Although significant differences in volumetric
estimates were observed between SRR methods, classification performance for VM
was not affected by the choice of SRR method. These findings highlight NeSVoR's
robustness and the resilience of diagnostic performance despite SRR-induced
volumetric variability.

</details>


### [73] [Mask Consistency Regularization in Object Removal](https://arxiv.org/abs/2509.10259)
*Hua Yuan,Jin Yuan,Yicheng Jiang,Yao Zhang,Xin Geng,Yong Rui*

Main category: cs.CV

TL;DR: 本文提出了一种名为MCR（Mask Consistency Regularization）的新训练策略，通过引入掩码扰动来解决图像修复中物体移除任务中存在的掩码幻觉和掩码形状偏差问题。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型有所进步，但当前的物体移除方法仍面临两个关键挑战：一是掩码幻觉（模型在掩码区域生成不相关或虚假内容），二是掩码形状偏差（模型生成与掩码形状相似而非与周围内容匹配的物体）。

Method: 本文提出Mask Consistency Regularization (MCR) 训练策略。在训练过程中，引入两种掩码扰动：膨胀（dilation）和重塑（reshape）。膨胀掩码有助于使模型输出与周围内容对齐，而重塑掩码则鼓励模型打破掩码形状偏差。MCR通过强制这些扰动分支的输出与原始掩码之间保持一致性来工作。

Result: 实验表明，MCR显著减少了幻觉和掩码形状偏差，从而提高了物体移除的性能。

Conclusion: MCR策略能够生成更鲁棒、上下文更连贯的图像修复结果，有效解决了物体移除任务中的掩码幻觉和掩码形状偏差问题。

Abstract: Object removal, a challenging task within image inpainting, involves
seamlessly filling the removed region with content that matches the surrounding
context. Despite advancements in diffusion models, current methods still face
two critical challenges. The first is mask hallucination, where the model
generates irrelevant or spurious content inside the masked region, and the
second is mask-shape bias, where the model fills the masked area with an object
that mimics the mask's shape rather than surrounding content. To address these
issues, we propose Mask Consistency Regularization (MCR), a novel training
strategy designed specifically for object removal tasks. During training, our
approach introduces two mask perturbations: dilation and reshape, enforcing
consistency between the outputs of these perturbed branches and the original
mask. The dilated masks help align the model's output with the surrounding
content, while reshaped masks encourage the model to break the mask-shape bias.
This combination of strategies enables MCR to produce more robust and
contextually coherent inpainting results. Our experiments demonstrate that MCR
significantly reduces hallucinations and mask-shape bias, leading to improved
performance in object removal.

</details>


### [74] [MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation](https://arxiv.org/abs/2509.10260)
*Jia Wang,Jie Hu,Xiaoqi Ma,Hanghang Ma,Yanbing Zeng,Xiaoming Wei*

Main category: cs.CV

TL;DR: 本文介绍了MagicMirror，一个用于评估文本到图像（T2I）生成模型中物理伪影的综合框架。该框架包括一个伪影分类法、一个大规模人工标注数据集MagicData340K、一个视觉-语言模型（VLM）评估器MagicAssessor，以及一个自动化基准MagicBench，揭示了顶级T2I模型中普遍存在的伪影问题。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到图像（T2I）生成在指令遵循和美学方面取得了显著进展，但仍普遍存在物理伪影（如解剖和结构缺陷），严重降低了感知质量并限制了应用。现有基准缺乏系统化、细粒度的伪影评估框架来应对这些多样且复杂的伪影。

Method: 研究首先建立了一个详细的生成图像伪影分类法。以此为指导，人工标注了MagicData340K，这是首个包含34万张生成图像及细粒度伪影标签的大规模数据集。在此基础上，训练了一个视觉-语言模型（VLM）MagicAssessor，用于提供详细评估和相应标签。为解决类别不平衡和奖励作弊等挑战，设计了一种新颖的数据采样策略和用于群组相对策略优化（GRPO）的多级奖励系统。最后，利用MagicAssessor构建了MagicBench，一个用于自动化评估T2I模型图像伪影的基准。

Result: 通过MagicBench进行的评估显示，尽管被广泛采用，即使是像GPT-image-1这样的顶级T2I模型也持续受到显著伪影的困扰。

Conclusion: 伪影减少是未来T2I发展的一个关键前沿领域。

Abstract: Text-to-image (T2I) generation has achieved remarkable progress in
instruction following and aesthetics. However, a persistent challenge is the
prevalence of physical artifacts, such as anatomical and structural flaws,
which severely degrade perceptual quality and limit application. Given the
diversity and complexity of these artifacts, a systematic and fine-grained
evaluation framework is required, which is lacking in current benchmarks. To
fill this gap, we introduce MagicMirror, a comprehensive framework for
artifacts assessment. We first establish a detailed taxonomy of generated image
artifacts. Guided by this taxonomy, we manually annotate MagicData340K, the
first human-annotated large-scale dataset of 340K generated images with
fine-grained artifact labels. Building on this dataset, we train MagicAssessor,
a Vision-Language Model (VLM) that provides detailed assessments and
corresponding labels. To overcome challenges like class imbalance and reward
hacking, we design a novel data sampling strategy and a multi-level reward
system for Group Relative Policy Optimization (GRPO). Finally, we leverage
MagicAssessor to construct MagicBench, an automated benchmark for evaluating
the image artifacts of current T2I models. Our evaluation with MagicBench
reveals that despite their widespread adoption, even top-tier models like
GPT-image-1 are consistently plagued by significant artifacts, highlighting
artifact reduction as a critical frontier for future T2I development. Project
page: https://wj-inf.github.io/MagicMirror-page/.

</details>


### [75] [Detecting Text Manipulation in Images using Vision Language Models](https://arxiv.org/abs/2509.10278)
*Vidit Vidit,Pavel Korshunov,Amir Mohammadi,Christophe Ecabert,Ketan Kotwal,Sébastien Marcel*

Main category: cs.CV

TL;DR: 本文分析了大型视觉语言模型（VLMs）在文本篡改检测方面的表现，比较了开源和闭源模型，并评估了图像篡改检测专用模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注VLMs在图像篡改检测方面的有效性，而对文本篡改检测的探讨不足，存在知识空白。

Method: 研究分析了闭源和开源VLMs在不同文本篡改数据集上的表现。同时，评估了专门用于图像篡改检测的VLMs在文本篡改检测上的泛化能力。测试场景包括真实世界场景文本和模拟现实世界滥用的虚构身份证件。

Result: 结果显示，开源模型正在进步，但仍落后于GPT-4o等闭源模型。此外，图像篡改检测专用VLMs在文本篡改检测方面存在泛化问题。

Conclusion: VLMs在文本篡改检测方面有待提升，闭源模型表现更优，而图像篡改专用模型在文本任务上泛化能力不足，凸显了该领域进一步研究的必要性。

Abstract: Recent works have shown the effectiveness of Large Vision Language Models
(VLMs or LVLMs) in image manipulation detection. However, text manipulation
detection is largely missing in these studies. We bridge this knowledge gap by
analyzing closed- and open-source VLMs on different text manipulation datasets.
Our results suggest that open-source models are getting closer, but still
behind closed-source ones like GPT- 4o. Additionally, we benchmark image
manipulation detection-specific VLMs for text manipulation detection and show
that they suffer from the generalization problem. We benchmark VLMs for
manipulations done on in-the-wild scene texts and on fantasy ID cards, where
the latter mimic a challenging real-world misuse.

</details>


### [76] [MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection](https://arxiv.org/abs/2509.10282)
*Gang Li,Tianjiao Chen,Mingle Zhou,Min Li,Delong Han,Jin Wan*

Main category: cs.CV

TL;DR: MCL-AD是一种新颖的零样本3D异常检测框架，通过点云、RGB图像和文本语义的多模态协作学习，实现了卓越的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本3D（ZS-3D）异常检测方法主要关注点云，忽略了RGB图像和文本先验等互补模态中丰富的语义信息。在数据稀缺、隐私或高标注成本的场景中，ZS-3D异常检测具有重要价值。

Method: 本文提出了MCL-AD框架。具体来说，引入了多模态提示学习机制（MPLM），通过解耦的文本提示和多模态对比损失来增强模态内表示能力和模态间协作学习。此外，还提出了协作调制机制（CMM），通过联合调制RGB图像引导和点云引导分支，充分利用点云和RGB图像的互补表示。

Result: 广泛的实验证明，所提出的MCL-AD框架在零样本3D异常检测中取得了最先进的性能。

Conclusion: MCL-AD通过整合多模态协作学习、多模态提示学习机制和协作调制机制，有效解决了现有ZS-3D异常检测方法忽视多模态语义的问题，显著提升了检测能力。

Abstract: Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects
without relying on labeled training data, making it especially valuable in
scenarios constrained by data scarcity, privacy, or high annotation cost.
However, most existing methods focus exclusively on point clouds, neglecting
the rich semantic cues available from complementary modalities such as RGB
images and texts priors. This paper introduces MCL-AD, a novel framework that
leverages multimodal collaboration learning across point clouds, RGB images,
and texts semantics to achieve superior zero-shot 3D anomaly detection.
Specifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that
enhances the intra-modal representation capability and inter-modal
collaborative learning by introducing an object-agnostic decoupled text prompt
and a multimodal contrastive loss. In addition, a collaborative modulation
mechanism (CMM) is proposed to fully leverage the complementary representations
of point clouds and RGB images by jointly modulating the RGB image-guided and
point cloud-guided branches. Extensive experiments demonstrate that the
proposed MCL-AD framework achieves state-of-the-art performance in ZS-3D
anomaly detection.

</details>


### [77] [Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks](https://arxiv.org/abs/2509.10298)
*Laith Nayal,Mahmoud Mousatat,Bader Rasheed*

Main category: cs.CV

TL;DR: 本文提出了一种Lipschitz引导的随机深度（DropPath）方法，通过增加深层网络的丢弃概率来控制有效Lipschitz常数，从而在保持准确性的同时提高对抗鲁棒性并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络和Vision Transformers易受对抗性扰动攻击，而现有防御方法通常计算成本高昂或缺乏形式保证。

Method: 提出了一种Lipschitz引导的随机深度（DropPath）方法，其中丢弃概率随网络深度增加，以有效控制网络的Lipschitz常数。这种方法正则化了更深层，并采用定制的深度依赖调度。

Result: 在CIFAR-10和ViT-Tiny上的实验表明，该方法在保持接近基线准确性的同时，显著增强了在FGSM、PGD-20和AutoAttack下的鲁棒性，并且与基线和线性DropPath调度相比，显著降低了FLOPs。

Conclusion: 所提出的Lipschitz引导的随机深度方法能够有效提高深度神经网络的对抗鲁棒性，同时保持干净准确性并降低计算开销。

Abstract: Deep neural networks and Vision Transformers achieve state-of-the-art
performance in computer vision but are highly vulnerable to adversarial
perturbations. Standard defenses often incur high computational cost or lack
formal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)
method, where drop probabilities increase with depth to control the effective
Lipschitz constant of the network. This approach regularizes deeper layers,
improving robustness while preserving clean accuracy and reducing computation.
Experiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent
schedule maintains near-baseline clean accuracy, enhances robustness under
FGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to
baseline and linear DropPath schedules.

</details>


### [78] [A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments](https://arxiv.org/abs/2509.10310)
*Evan Murphy,Marco Viola,Vladimir A. Krylov*

Main category: cs.CV

TL;DR: 本文提出了一种基于能量图的概率框架和随机生灭优化算法，用于在复杂城市环境中精确地理定位街道设施，以实现可扩展和准确的城市资产测绘。


<details>
  <summary>Details</summary>
Motivation: 在复杂城市环境中，精确地理定位街道设施是地方当局和私人利益相关者有效监测和维护公共基础设施的关键任务。

Method: 该研究提出一个基于能量图的概率框架，用于编码物体位置的空间可能性。通过地图式地理定位格式表示能量，该优化过程可以无缝整合外部地理空间信息（如GIS图层、道路地图、放置约束）。此外，引入了一种随机生灭优化算法来推断最可能的资产配置。

Result: 该方法通过基于都柏林市中心街道照明基础设施地理定位数据集的真实模拟进行评估，证明了其在可扩展和准确的城市资产测绘方面的潜力。

Conclusion: 该研究提出的方法能够实现城市街道设施的可扩展且准确的测绘，对于公共基础设施的监测和维护具有重要意义。

Abstract: In this paper we address the problem of precise geolocation of street
furniture in complex urban environments, which is a critical task for effective
monitoring and maintenance of public infrastructure by local authorities and
private stakeholders. To this end, we propose a probabilistic framework based
on energy maps that encode the spatial likelihood of object locations.
Representing the energy in a map-based geopositioned format allows the
optimisation process to seamlessly integrate external geospatial information,
such as GIS layers, road maps, or placement constraints, which improves
contextual awareness and localisation accuracy. A stochastic birth-and-death
optimisation algorithm is introduced to infer the most probable configuration
of assets. We evaluate our approach using a realistic simulation informed by a
geolocated dataset of street lighting infrastructure in Dublin city centre,
demonstrating its potential for scalable and accurate urban asset mapping. The
implementation of the algorithm will be made available in the GitHub repository
https://github.com/EMurphy0108/SBD_Street_Furniture.

</details>


### [79] [Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching](https://arxiv.org/abs/2509.10312)
*Zhixin Zheng,Xinyu Wang,Chang Zou,Shaobo Wang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为ClusCa的聚类驱动特征缓存方法，通过在每个时间步进行空间聚类来显著减少扩散Transformer中的令牌数量（超过90%），从而加速迭代去噪过程，且无需重新训练，在图像和视频生成任务中表现出显著的加速效果和甚至更高的质量。


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer在生成高质量图像和视频方面表现出色，但其迭代去噪过程导致巨大的计算成本。现有的特征缓存方法仅利用扩散模型的时间相似性来加速，而忽略了空间维度上的相似性。

Method: 引入聚类驱动特征缓存（ClusCa）作为现有特征缓存的补充方法。ClusCa在每个时间步对令牌进行空间聚类，每个簇只计算一个令牌，并将其信息传播到该簇中的所有其他令牌，从而将令牌数量减少90%以上。该方法可直接应用于任何扩散Transformer，无需训练。

Result: ClusCa能够将令牌数量减少90%以上。在DiT、FLUX和HunyuanVideo上进行了广泛实验，验证了其在文本到图像和文本到视频生成中的有效性。例如，ClusCa在FLUX上实现了4.96倍的加速，ImageReward达到99.49%，比原始模型高出0.51%。

Conclusion: ClusCa是一种有效且互补的加速扩散Transformer的方法，它通过利用空间相似性进行聚类，显著降低了计算成本，同时无需重新训练，甚至可能提升生成质量。该方法可广泛应用于各种扩散Transformer模型。

Abstract: Diffusion transformers have gained significant attention in recent years for
their ability to generate high-quality images and videos, yet still suffer from
a huge computational cost due to their iterative denoising process. Recently,
feature caching has been introduced to accelerate diffusion transformers by
caching the feature computation in previous timesteps and reusing it in the
following timesteps, which leverage the temporal similarity of diffusion models
while ignoring the similarity in the spatial dimension. In this paper, we
introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and
complementary perspective for previous feature caching. Specifically, ClusCa
performs spatial clustering on tokens in each timestep, computes only one token
in each cluster and propagates their information to all the other tokens, which
is able to reduce the number of tokens by over 90%. Extensive experiments on
DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image
and text-to-video generation. Besides, it can be directly applied to any
diffusion transformer without requirements for training. For instance, ClusCa
achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing
the original model by 0.51%. The code is available at
https://github.com/Shenyi-Z/Cache4Diffusion.

</details>


### [80] [GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT](https://arxiv.org/abs/2509.10341)
*Botond Fazekas,Thomas Pinetz,Guilherme Aresta,Taha Emre,Hrvoje Bogunovic*

Main category: cs.CV

TL;DR: 本文提出GARD（基于Gamma的解剖结构恢复和去噪），一种新颖的深度学习方法，利用Gamma扩散概率模型和噪声降低保真项对光学相干断层扫描（OCT）图像进行散斑去噪，实现了卓越的去噪效果和细节保留。


<details>
  <summary>Details</summary>
Motivation: OCT图像固有的散斑噪声会模糊精细细节并阻碍准确诊断。现有去噪方法难以在降噪和保留关键解剖结构之间取得平衡。

Method: GARD方法采用去噪扩散Gamma模型（DDGM），以更准确地反映散斑的统计特性，而非传统的假设高斯噪声的扩散模型。此外，引入了一个噪声降低保真项，利用预处理的低噪声图像来指导去噪过程，防止高频噪声的重新引入。通过调整去噪扩散隐式模型（DDIM）框架，加速了推理过程。

Result: 在配对的噪声和低噪声OCT B扫描数据集上的实验表明，GARD在PSNR、SSIM和MSE方面显著优于传统去噪方法和最先进的深度学习模型。定性结果证实GARD能产生更锐利的边缘并更好地保留精细的解剖细节。

Conclusion: GARD是一种有效且先进的OCT图像散斑去噪深度学习方法，它通过创新的Gamma扩散模型和噪声降低保真项，在去噪的同时显著提升了图像质量和解剖细节的保留。

Abstract: Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing
and monitoring retinal diseases. However, OCT images are inherently degraded by
speckle noise, which obscures fine details and hinders accurate interpretation.
While numerous denoising methods exist, many struggle to balance noise
reduction with the preservation of crucial anatomical structures. This paper
introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel
deep learning approach for OCT image despeckling that leverages the strengths
of diffusion probabilistic models. Unlike conventional diffusion models that
assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more
accurately reflect the statistical properties of speckle. Furthermore, we
introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,
less-noisy image to guide the denoising process. This crucial addition prevents
the reintroduction of high-frequency noise. We accelerate the inference process
by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based
model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans
demonstrate that GARD significantly outperforms traditional denoising methods
and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.
Qualitative results confirm that GARD produces sharper edges and better
preserves fine anatomical details.

</details>


### [81] [Immunizing Images from Text to Image Editing via Adversarial Cross-Attention](https://arxiv.org/abs/2509.10359)
*Matteo Trippodo,Federico Becattini,Lorenzo Seidenari*

Main category: cs.CV

TL;DR: 本文提出了一种名为“注意力攻击”的新型对抗性攻击，旨在通过破坏文本提示与图像视觉表示之间的交叉注意力，降低文本图像编辑方法的性能，同时保持攻击的不可感知性。


<details>
  <summary>Details</summary>
Motivation: 文本图像编辑方法容易受到对抗性攻击。现有攻击可能需要了解编辑方法或编辑提示，这限制了其普适性。

Method: 我们引入了“注意力攻击”，它通过使用源图像的自动生成标题作为编辑提示的代理，来扰乱文本提示和图像视觉表示之间的交叉注意力。这打破了图像内容与其文本描述之间的对齐，且无需了解编辑方法或编辑提示。此外，我们提出了两种新的评估策略：标题相似度（量化语义一致性）和语义交并比（IoU，通过分割掩码测量空间布局中断）。

Result: 在TEDBench++基准测试上进行的实验表明，我们的攻击显著降低了编辑性能，同时保持了不可感知性。

Conclusion: 我们提出了一种有效且不可感知的注意力攻击，揭示了文本图像编辑方法的脆弱性。同时，我们提出了更可靠的评估策略，以更好地衡量免疫成功率。

Abstract: Recent advances in text-based image editing have enabled fine-grained
manipulation of visual content guided by natural language. However, such
methods are susceptible to adversarial attacks. In this work, we propose a
novel attack that targets the visual component of editing methods. We introduce
Attention Attack, which disrupts the cross-attention between a textual prompt
and the visual representation of the image by using an automatically generated
caption of the source image as a proxy for the edit prompt. This breaks the
alignment between the contents of the image and their textual description,
without requiring knowledge of the editing method or the editing prompt.
Reflecting on the reliability of existing metrics for immunization success, we
propose two novel evaluation strategies: Caption Similarity, which quantifies
semantic consistency between original and adversarial edits, and semantic
Intersection over Union (IoU), which measures spatial layout disruption via
segmentation masks. Experiments conducted on the TEDBench++ benchmark
demonstrate that our attack significantly degrades editing performance while
remaining imperceptible.

</details>


### [82] [Efficient Learned Image Compression Through Knowledge Distillation](https://arxiv.org/abs/2509.10366)
*Fabien Allemand,Attilio Fiandrotti,Sumanta Chaudhuri,Alaa Eddine Mazouz*

Main category: cs.CV

TL;DR: 深度学习图像压缩模型性能优异但资源消耗大。本研究利用知识蒸馏技术，显著降低了这些模型的资源需求，使其更适用于资源受限平台。


<details>
  <summary>Details</summary>
Motivation: 基于神经网络的图像压缩方法已超越传统编码器，但其高计算需求限制了在资源受限平台上的实时应用，阻碍了其主流部署。

Method: 本研究利用知识蒸馏（Knowledge Distillation）范式，通过让较小的神经网络学习大型复杂模型的输出，来训练用于图像压缩的神经网络，从而降低其资源需求。

Result: 研究表明，知识蒸馏可以有效地应用于图像压缩任务：i) 适用于不同架构尺寸的模型；ii) 实现不同的图像质量/比特率权衡；iii) 节省处理和能源资源。

Conclusion: 知识蒸馏是降低神经网络图像压缩模型资源需求的一种有效方法，使其更适用于实际应用。未来的研究可探索不同的教师模型、替代损失函数以及将其扩展到基于Transformer的模型。

Abstract: Learned image compression sits at the intersection of machine learning and
image processing. With advances in deep learning, neural network-based
compression methods have emerged. In this process, an encoder maps the image to
a low-dimensional latent space, which is then quantized, entropy-coded into a
binary bitstream, and transmitted to the receiver. At the receiver end, the
bitstream is entropy-decoded, and a decoder reconstructs an approximation of
the original image. Recent research suggests that these models consistently
outperform conventional codecs. However, they require significant processing
power, making them unsuitable for real-time use on resource-constrained
platforms, which hinders their deployment in mainstream applications. This
study aims to reduce the resource requirements of neural networks used for
image compression by leveraging knowledge distillation, a training paradigm
where smaller neural networks, partially trained on the outputs of larger, more
complex models, can achieve better performance than when trained independently.
Our work demonstrates that knowledge distillation can be effectively applied to
image compression tasks: i) across various architecture sizes, ii) to achieve
different image quality/bit rate tradeoffs, and iii) to save processing and
energy resources. This approach introduces new settings and hyperparameters,
and future research could explore the impact of different teacher models, as
well as alternative loss functions. Knowledge distillation could also be
extended to transformer-based models. The code is publicly available at:
https://github.com/FABallemand/PRIM .

</details>


### [83] [Ordinality of Visible-Thermal Image Intensities for Intrinsic Image Decomposition](https://arxiv.org/abs/2509.10388)
*Zeqing Leo Yuan,Mani Ramanagopal,Aswin C. Sankaranarayanan,Srinivasa G. Narasimhan*

Main category: cs.CV

TL;DR: 本文提出一种无需训练的方法，利用可见光和热成像图像对进行内在图像分解，通过光吸收原理自监督优化神经网络，在真实世界场景中表现优于现有学习模型。


<details>
  <summary>Details</summary>
Motivation: 内在图像分解（将图像分解为阴影和反射）长期以来面临挑战，原因在于缺乏真实世界场景的广泛地面真值数据。现有方法依赖合成数据或有限的稀疏标注。

Method: 该方法是一种新颖的无需训练的内在图像分解方法，仅使用一对可见光和热成像图像。它利用了不从不透明表面反射的光会被吸收并被热像仪检测为热量的原理。这使得可见光和热成像图像强度之间的序数关系能够与阴影和反射的序数关系相关联，从而密集地自监督一个优化神经网络来恢复阴影和反射。

Result: 在自然光和人工光照下，通过已知反射和阴影进行的定量评估，以及在各种室外场景中进行的定性实验，结果表明该方法优于最近基于学习的模型，并为获取真实世界序数监督提供了一条可扩展的途径，这在以前通过手动标注是不可行的。

Conclusion: 利用可见光和热成像图像对，该方法能够有效地进行内在图像分解，表现出优异的性能，并为解决真实世界场景中地面真值数据稀缺问题提供了一种可扩展的自监督方案。

Abstract: Decomposing an image into its intrinsic photometric factors--shading and
reflectance--is a long-standing challenge due to the lack of extensive
ground-truth data for real-world scenes. Recent methods rely on synthetic data
or sparse annotations for limited indoor and even fewer outdoor scenes. We
introduce a novel training-free approach for intrinsic image decomposition
using only a pair of visible and thermal images. We leverage the principle that
light not reflected from an opaque surface is absorbed and detected as heat by
a thermal camera. This allows us to relate the ordinalities between visible and
thermal image intensities to the ordinalities of shading and reflectance, which
can densely self-supervise an optimizing neural network to recover shading and
reflectance. We perform quantitative evaluations with known reflectance and
shading under natural and artificial lighting, and qualitative experiments
across diverse outdoor scenes. The results demonstrate superior performance
over recent learning-based models and point toward a scalable path to curating
real-world ordinal supervision, previously infeasible via manual labeling.

</details>


### [84] [Compressed Video Quality Enhancement: Classifying and Benchmarking over Standards](https://arxiv.org/abs/2509.10407)
*Xiem HoangVan,Dang BuiDinh,Sang NguyenQuang,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 本文对基于深度学习的压缩视频质量增强（CVQE）进行了全面综述，提出了新的分类法、统一的基准测试框架，并分析了性能与计算复杂度的权衡，旨在为CVQE研究提供一致的评估基础。


<details>
  <summary>Details</summary>
Motivation: 现有关于深度学习CVQE的综述存在局限性，包括缺乏系统分类（未能将方法与特定标准和伪影关联）、对不同编码类型的架构范式比较不足，以及基准测试实践不完善。

Method: 该研究提出了三项主要贡献：1. 引入了一种新颖的CVQE方法分类法，涵盖架构范式、编码标准和压缩域特征利用。2. 提出了一个统一的基准测试框架，整合现代压缩协议和标准测试序列以进行公平的多准则评估。3. 系统分析了现有先进方法在重建性能和计算复杂度之间的关键权衡。

Result: 本文通过提供新的分类法、统一的基准测试框架以及对性能-复杂度权衡的系统分析，为CVQE研究和部署中的一致性评估和模型选择奠定了基础，并指出了未来研究的有前景方向。

Conclusion: 这项全面的综述旨在为压缩视频质量增强研究和部署中的一致性评估和知情模型选择建立基础，并突出未来研究的有前景方向。

Abstract: Compressed video quality enhancement (CVQE) is crucial for improving user
experience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.
While deep learning based CVQE has driven significant progress, existing
surveys still suffer from limitations: lack of systematic classification
linking methods to specific standards and artifacts, insufficient comparative
analysis of architectural paradigms across coding types, and underdeveloped
benchmarking practices. To address these gaps, this paper presents three key
contributions. First, it introduces a novel taxonomy classifying CVQE methods
across architectural paradigms, coding standards, and compressed-domain feature
utilization. Second, it proposes a unified benchmarking framework integrating
modern compression protocols and standard test sequences for fair
multi-criteria evaluation. Third, it provides a systematic analysis of the
critical trade-offs between reconstruction performance and computational
complexity observed in state-of-the-art methods and highlighting promising
directions for future research. This comprehensive review aims to establish a
foundation for consistent assessment and informed model selection in CVQE
research and deployment.

</details>


### [85] [InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis](https://arxiv.org/abs/2509.10441)
*Tao Han,Wanghan Xu,Junchao Gong,Xiaoyu Yue,Song Guo,Luping Zhou,Lei Bai*

Main category: cs.CV

TL;DR: InfGen提出了一种新的单步生成器，用于替代潜在扩散模型中的VAE解码器，从而在不重新训练扩散模型的情况下，从固定大小的潜在表示生成任意分辨率的图像，显著降低了计算复杂性，并将4K图像生成时间缩短至10秒以内。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型生成任意分辨率图像时，计算需求随分辨率呈二次方增长，导致4K图像生成耗时超过100秒，影响了用户体验和应用效率。

Method: InfGen基于潜在扩散模型，将扩散模型生成的固定潜在表示视为内容表征。它提出用一个新的“单步生成器”来解码任意分辨率的图像，该生成器取代了VAE解码器。这种方法无需重新训练扩散模型，并且可以应用于使用相同潜在空间的任何模型。

Result: 实验表明，InfGen能够将许多模型提升到任意高分辨率时代，同时将4K图像的生成时间缩短到10秒以下。

Conclusion: InfGen提供了一种简化且计算效率高的方法，能够从固定大小的潜在表示生成任意高分辨率图像，解决了现有扩散模型在高分辨率生成方面的效率问题，具有广泛的应用潜力。

Abstract: Arbitrary resolution image generation provides a consistent visual experience
across devices, having extensive applications for producers and consumers.
Current diffusion models increase computational demand quadratically with
resolution, causing 4K image generation delays over 100 seconds. To solve this,
we explore the second generation upon the latent diffusion models, where the
fixed latent generated by diffusion models is regarded as the content
representation and we propose to decode arbitrary resolution images with a
compact generated latent using a one-step generator. Thus, we present the
\textbf{InfGen}, replacing the VAE decoder with the new generator, for
generating images at any resolution from a fixed-size latent without retraining
the diffusion models, which simplifies the process, reducing computational
complexity and can be applied to any model using the same latent space.
Experiments show InfGen is capable of improving many models into the arbitrary
high-resolution era while cutting 4K image generation time to under 10 seconds.

</details>


### [86] [SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets](https://arxiv.org/abs/2509.10453)
*Emily Kaczmarek,Justin Szeto,Brennan Nichyporuk,Tal Arbel*

Main category: cs.CV

TL;DR: 本研究针对阿尔茨海默病预测中深度学习模型面临的数据稀缺、泛化性差和输入灵活性不足等问题，提出了一种适应性强的时序自监督学习（SSL）方法，通过新颖的扩展处理可变长度输入，并在多项任务中显著优于监督学习。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型在阿尔茨海默病（AD）预测任务中受限于标注数据不足、跨数据集泛化能力差，以及对不同数量的输入扫描和扫描时间间隔缺乏灵活性。

Method: 本研究将三种最先进的时序自监督学习（SSL）方法应用于3D脑部MRI分析，并添加了新颖的扩展，旨在处理可变长度输入并学习鲁棒的空间特征。研究聚合了四个公开数据集（共3,161名患者）进行预训练，并使用了时序顺序预测和对比学习。

Result: 实施了时序顺序预测和对比学习的SSL模型在七项下游阿尔茨海默病预测任务（包括诊断分类、转换检测和未来转换预测）中的六项上优于监督学习。该模型在任务和不同时间间隔的输入图像数量方面均表现出适应性和泛化性。

Conclusion: 所提出的时序自监督学习模型在阿尔茨海默病预测中展现出强大的性能，克服了现有深度学习方法的关键局限性，并具有在各种临床应用中实现鲁棒性能的潜力。

Abstract: Alzheimer's disease is a progressive, neurodegenerative disorder that causes
memory loss and cognitive decline. While there has been extensive research in
applying deep learning models to Alzheimer's prediction tasks, these models
remain limited by lack of available labeled data, poor generalization across
datasets, and inflexibility to varying numbers of input scans and time
intervals between scans. In this study, we adapt three state-of-the-art
temporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,
and add novel extensions designed to handle variable-length inputs and learn
robust spatial features. We aggregate four publicly available datasets
comprising 3,161 patients for pre-training, and show the performance of our
model across multiple Alzheimer's prediction tasks including diagnosis
classification, conversion detection, and future conversion prediction.
Importantly, our SSL model implemented with temporal order prediction and
contrastive learning outperforms supervised learning on six out of seven
downstream tasks. It demonstrates adaptability and generalizability across
tasks and number of input images with varying time intervals, highlighting its
capacity for robust performance across clinical applications. We release our
code and model publicly at https://github.com/emilykaczmarek/SSL-AD.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [87] [Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs](https://arxiv.org/abs/2509.09699)
*Mingyang Li,Viktor Schlegel,Tingting Mu,Warren Del-Pinto,Goran Nenadic*

Main category: cs.CL

TL;DR: 本研究利用文档级知识图谱（KG）对临床文档进行结构化表示，以提高自动化ICD编码的准确性和训练效率，同时增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 将临床文档映射到标准化词汇是重要但耗时且难以大规模手动完成的任务。自动化编码面临高维度和长尾目标空间的挑战。虽然外部知识源常用于增强输出代码表示，但将外部资源用于表示输入文档的研究不足。

Method: 研究人员计算了输入文档的结构化表示，利用文档级知识图谱（KG）提供患者病情的全面结构化视图。然后，将这种知识图谱集成到最先进的ICD编码架构PLM-ICD中，以评估其在自动化ICD-9编码中的有效性。

Result: 生成的知识图谱能高效表示以患者为中心的输入文档，仅用23%的原始文本保留了90%的信息。实验表明，在流行基准测试中，宏观F1分数提高了高达3.20%，同时提高了训练效率。这种改进归因于KG中不同类型的实体和关系，并且该方法比纯文本基线具有更好的可解释性潜力。

Conclusion: 利用文档级知识图谱对输入临床文档进行结构化表示，能显著提高自动化ICD编码的准确性和训练效率，并增强模型的可解释性，为大规模临床数据分析提供了有效途径。

Abstract: Mapping clinical documents to standardised clinical vocabularies is an
important task, as it provides structured data for information retrieval and
analysis, which is essential to clinical research, hospital administration and
improving patient care. However, manual coding is both difficult and
time-consuming, making it impractical at scale. Automated coding can
potentially alleviate this burden, improving the availability and accuracy of
structured clinical data. The task is difficult to automate, as it requires
mapping to high-dimensional and long-tailed target spaces, such as the
International Classification of Diseases (ICD). While external knowledge
sources have been readily utilised to enhance output code representation, the
use of external resources for representing the input documents has been
underexplored. In this work, we compute a structured representation of the
input documents, making use of document-level knowledge graphs (KGs) that
provide a comprehensive structured view of a patient's condition. The resulting
knowledge graph efficiently represents the patient-centred input documents with
23\% of the original text while retaining 90\% of the information. We assess
the effectiveness of this graph for automated ICD-9 coding by integrating it
into the state-of-the-art ICD coding architecture PLM-ICD. Our experiments
yield improved Macro-F1 scores by up to 3.20\% on popular benchmarks, while
improving training efficiency. We attribute this improvement to different types
of entities and relationships in the KG, and demonstrate the improved
explainability potential of the approach over the text-only baseline.

</details>


### [88] [Cross-Layer Attention Probing for Fine-Grained Hallucination Detection](https://arxiv.org/abs/2509.09700)
*Malavika Suresh,Rahaf Aljundi,Ikechukwu Nkisi-Orji,Nirmalie Wiratunga*

Main category: cs.CL

TL;DR: 本文提出了一种名为CLAP的新型激活探测技术，用于检测大型语言模型中的幻觉，并在各种设置下显示出优于基线的性能，从而提高了LLM的可靠性。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）在各种应用中的广泛采用，其生成不准确文本（即幻觉）的倾向引发了对其可靠性的日益增长的担忧。

Method: 本文提出了一种名为“跨层注意力探测”（Cross-Layer Attention Probing, CLAP）的新型激活探测技术。CLAP将LLM在整个残差流中的激活作为联合序列进行处理。

Result: 通过对五种LLM和三项任务的实证评估，CLAP在贪婪解码和高温度采样响应上的幻觉检测均优于基线。它实现了细粒度检测，并支持一种“先检测后缓解”的策略，与直接缓解方法相比，能有效减少幻觉并提高LLM可靠性。此外，CLAP在分布外应用时仍能保持高可靠性。

Conclusion: CLAP是一种有效且鲁棒的幻觉检测技术，能够提高大型语言模型的可靠性，并支持通过检测来缓解幻觉的策略，即使在分布外场景下也能保持高性能。

Abstract: With the large-scale adoption of Large Language Models (LLMs) in various
applications, there is a growing reliability concern due to their tendency to
generate inaccurate text, i.e. hallucinations. In this work, we propose
Cross-Layer Attention Probing (CLAP), a novel activation probing technique for
hallucination detection, which processes the LLM activations across the entire
residual stream as a joint sequence. Our empirical evaluations using five LLMs
and three tasks show that CLAP improves hallucination detection compared to
baselines on both greedy decoded responses as well as responses sampled at
higher temperatures, thus enabling fine-grained detection, i.e. the ability to
disambiguate hallucinations and non-hallucinations among different sampled
responses to a given prompt. This allows us to propose a detect-then-mitigate
strategy using CLAP to reduce hallucinations and improve LLM reliability
compared to direct mitigation approaches. Finally, we show that CLAP maintains
high reliability even when applied out-of-distribution.

</details>


### [89] [Optimal Multi-Task Learning at Regularization Horizon for Speech Translation Task](https://arxiv.org/abs/2509.09701)
*JungHo Jung,Junhyun Lee*

Main category: cs.CL

TL;DR: 本文从正则化角度探讨了端到端语音到文本翻译中的多任务学习，通过分析跨模态和同模态正则化以及机器翻译损失系数，提出了正则化视界以优化模型性能，并在MuST-C数据集上取得了接近最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 端到端语音到文本翻译面临配对语音-文本数据稀缺的问题。利用机器翻译任务的双语语料进行多任务学习是克服这一挑战的有效途径。

Method: 本文将多任务学习（MTL）从正则化视角进行建模，探讨了序列如何在模态内部和跨模态进行正则化。具体分析了跨模态的一致性正则化和同模态的R-drop正则化，并指出机器翻译损失系数也是MTL设置中的另一个正则化来源。在此基础上，引入了高维空间中的最优正则化轮廓——正则化视界。

Result: 实验结果表明，在正则化视界内调整超参数可以在MuST-C数据集上取得接近最先进的性能。

Conclusion: 一致性正则化、R-drop以及机器翻译损失系数共同构成了多任务学习中端到端语音到文本翻译的有效正则化来源。通过在正则化视界内进行超参数调优，可以显著提升模型性能，有效应对数据稀缺问题。

Abstract: End-to-end speech-to-text translation typically suffers from the scarcity of
paired speech-text data. One way to overcome this shortcoming is to utilize the
bitext data from the Machine Translation (MT) task and perform Multi-Task
Learning (MTL). In this paper, we formulate MTL from a regularization
perspective and explore how sequences can be regularized within and across
modalities. By thoroughly investigating the effect of consistency
regularization (different modality) and R-drop (same modality), we show how
they respectively contribute to the total regularization. We also demonstrate
that the coefficient of MT loss serves as another source of regularization in
the MTL setting. With these three sources of regularization, we introduce the
optimal regularization contour in the high-dimensional space, called the
regularization horizon. Experiments show that tuning the hyperparameters within
the regularization horizon achieves near state-of-the-art performance on the
MuST-C dataset.

</details>


### [90] [Creativity Benchmark: A benchmark for marketing creativity for LLM models](https://arxiv.org/abs/2509.09702)
*Ninad Bhat,Kieran Browne,Pip Bingemann*

Main category: cs.CL

TL;DR: 该研究引入了“创意基准”来评估大型语言模型（LLM）在营销创意方面的表现。结果显示，LLM的性能差异不大，没有模型能完全主导，并且LLM作为评估者无法替代人类判断。因此，强调需要专家级人工评估和注重多样性的工作流程。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型评估框架未能充分覆盖营销创意这一特定领域，缺乏针对品牌和营销任务的专业评估基准。

Method: 研究引入了“创意基准”，包含100个品牌（12个类别）和三种提示类型（洞察、想法、狂野想法）。通过678名专业创意人员对11,012个匿名比较进行人工配对偏好评估，并使用Bradley-Terry模型进行分析。同时，使用余弦距离分析了模型的内部和模型间多样性，以及对提示重构的敏感性。此外，还将三种“LLM作为评判者”的设置与人类排名进行了比较。

Result: LLM的性能表现高度集中，没有单一模型在所有品牌或提示类型中占据主导地位，最高和最低模型之间的胜率仅为61%。将LLM用作评判者时，与人类排名的相关性较弱且不一致，并存在评判者特有的偏差，表明LLM无法替代人类评估。传统的创意测试也只能部分适用于品牌受限的任务。

Conclusion: 研究结果强调，在评估大型语言模型的营销创意时，需要进行专业的专家级人工评估，并采纳注重多样性的工作流程。

Abstract: We introduce Creativity Benchmark, an evaluation framework for large language
models (LLMs) in marketing creativity. The benchmark covers 100 brands (12
categories) and three prompt types (Insights, Ideas, Wild Ideas). Human
pairwise preferences from 678 practising creatives over 11,012 anonymised
comparisons, analysed with Bradley-Terry models, show tightly clustered
performance with no model dominating across brands or prompt types: the
top-bottom spread is $\Delta\theta \approx 0.45$, which implies a head-to-head
win probability of $0.61$; the highest-rated model beats the lowest only about
$61\%$ of the time. We also analyse model diversity using cosine distances to
capture intra- and inter-model variation and sensitivity to prompt reframing.
Comparing three LLM-as-judge setups with human rankings reveals weak,
inconsistent correlations and judge-specific biases, underscoring that
automated judges cannot substitute for human evaluation. Conventional
creativity tests also transfer only partially to brand-constrained tasks.
Overall, the results highlight the need for expert human evaluation and
diversity-aware workflows.

</details>


### [91] [CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor](https://arxiv.org/abs/2509.09703)
*Zhenhua Xu,Xixiang Zhao,Xubin Yue,Shengwei Tian,Changting Lin,Meng Han*

Main category: cs.CL

TL;DR: CTCC是一个新颖的规则驱动指纹框架，通过编码多轮对话中的上下文关联（如反事实）来保护大型语言模型的知识产权，解决了现有方法的隐蔽性、鲁棒性和泛化性权衡问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的广泛部署加剧了知识产权保护的担忧，因为模型盗窃和未经授权的再分发变得越来越容易。现有模型指纹方法在隐蔽性、鲁棒性和泛化性之间存在固有的权衡，容易被检测、易受攻击或一旦指纹暴露就会失效。

Method: 本文提出了CTCC框架，一个规则驱动的指纹方法。它通过编码跨多个对话轮次的上下文关联（例如反事实），而不是依赖于标记级或单轮触发器来嵌入指纹。CTCC支持在黑盒访问下进行指纹验证，同时减少误报和指纹泄露，并支持在部分触发器暴露的情况下，基于共享语义规则进行持续构建。

Result: 在多种LLM架构上的广泛实验表明，CTCC始终比现有工作实现更强的隐蔽性和鲁棒性。

Conclusion: CTCC被定位为在实际LLM部署场景中进行所有权验证的可靠且实用的解决方案。

Abstract: The widespread deployment of large language models (LLMs) has intensified
concerns around intellectual property (IP) protection, as model theft and
unauthorized redistribution become increasingly feasible. To address this,
model fingerprinting aims to embed verifiable ownership traces into LLMs.
However, existing methods face inherent trade-offs between stealthness,
robustness, and generalizability, being either detectable via distributional
shifts, vulnerable to adversarial modifications, or easily invalidated once the
fingerprint is revealed. In this work, we introduce CTCC, a novel rule-driven
fingerprinting framework that encodes contextual correlations across multiple
dialogue turns, such as counterfactual, rather than relying on token-level or
single-turn triggers. CTCC enables fingerprint verification under black-box
access while mitigating false positives and fingerprint leakage, supporting
continuous construction under a shared semantic rule even if partial triggers
are exposed. Extensive experiments across multiple LLM architectures
demonstrate that CTCC consistently achieves stronger stealth and robustness
than prior work. Our findings position CTCC as a reliable and practical
solution for ownership verification in real-world LLM deployment scenarios. Our
code and data are publicly available at <https://github.com/Xuzhenhua55/CTCC>.

</details>


### [92] [Temporal Preferences in Language Models for Long-Horizon Assistance](https://arxiv.org/abs/2509.09704)
*Ali Mazyaki,Mohammad Naghizadeh,Samaneh Ranjkhah Zonouzaghi,Hossein Setareh*

Main category: cs.CL

TL;DR: 本研究探讨了语言模型（LMs）在跨期选择中的未来导向或现在导向偏好，以及这些偏好是否可被系统性操纵。结果显示，推理型模型在未来导向提示下表现出未来偏好，并为自身内化了未来导向。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解语言模型在跨期选择中是偏向未来还是现在，以及它们的偏好是否可以被外部提示系统性地改变，这对于设计与人类长期目标一致的AI助手至关重要。

Method: 研究方法包括：1) 采用改编自人类实验协议的时间权衡任务来评估多个语言模型；2) 将语言模型的表现与人类决策者样本进行基准测试；3) 引入“时间导向可操纵性”（MTO）作为衡量指标，定义为模型在未来导向和现在导向提示下时间偏好的变化。

Result: 主要结果包括：1) 推理型模型（如DeepSeek-Reasoner和grok-3-mini）在未来导向提示下选择更晚的选项；2) 这些模型在不同身份或地理位置上的决策个性化程度有限；3) 能够正确理解时间导向的模型，会为自己（作为AI决策者）内化一种未来导向。

Conclusion: 本研究的结论是，语言模型表现出可被操纵的跨期偏好，推理型模型倾向于未来导向。这为AI助手的未来设计提供了启示，强调需要考虑如何使AI与异构的、长期目标保持一致，并提出了关于个性化上下文校准和社会意识部署的研究议程。

Abstract: We study whether language models (LMs) exhibit future- versus
present-oriented preferences in intertemporal choice and whether those
preferences can be systematically manipulated. Using adapted human experimental
protocols, we evaluate multiple LMs on time-tradeoff tasks and benchmark them
against a sample of human decision makers. We introduce an operational metric,
the Manipulability of Time Orientation (MTO), defined as the change in an LM's
revealed time preference between future- and present-oriented prompts. In our
tests, reasoning-focused models (e.g., DeepSeek-Reasoner and grok-3-mini)
choose later options under future-oriented prompts but only partially
personalize decisions across identities or geographies. Moreover, models that
correctly reason about time orientation internalize a future orientation for
themselves as AI decision makers. We discuss design implications for AI
assistants that should align with heterogeneous, long-horizon goals and outline
a research agenda on personalized contextual calibration and socially aware
deployment.

</details>


### [93] [The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition Trials of Standard Multiple-Choice Benchmarks](https://arxiv.org/abs/2509.09705)
*Claudio Pinhanez,Paulo Cavalin,Cassia Sanctos,Marcelo Grave,Yago Primerano*

Main category: cs.CL

TL;DR: 本研究探讨了小型LLM（2B-8B）在多次回答相同问题时的一致性，发现其一致性通常在50%-80%之间，且与整体准确性相关，而中型模型的一致性更高。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索小型LLM在重复回答相同问题时的一致性，并分析不同参数（如推理温度、模型大小、是否微调）对一致性及准确性的影响，以及如何权衡两者。

Method: 研究方法包括让已知开源LLM（2B-8B）对MMLU-Redux和MedQA基准测试中的问题重复回答10次。实验考虑了不同的推理温度、小型与中型模型（50B-80B）、微调与基础模型等参数。为支持研究，还提出了新的分析和图形工具。

Result: 结果显示，小型模型在低推理温度下，能一致回答的问题数量差异很大，但通常在50%-80%之间。一致性回答的准确性与整体准确性之间存在合理关联。中型模型的结果表明其答案一致性水平显著更高。

Conclusion: 小型LLM在重复回答相同问题时具有一定的（50%-80%）但可变的答案一致性，且一致性与准确性正相关。中型模型在答案一致性方面表现更优，研究揭示了在模型选择中需权衡一致性和准确性。

Abstract: This work explores the consistency of small LLMs (2B-8B parameters) in
answering multiple times the same question. We present a study on known,
open-source LLMs responding to 10 repetitions of questions from the
multiple-choice benchmarks MMLU-Redux and MedQA, considering different
inference temperatures, small vs. medium models (50B-80B), finetuned vs. base
models, and other parameters. We also look into the effects of requiring
multi-trial answer consistency on accuracy and the trade-offs involved in
deciding which model best provides both of them. To support those studies, we
propose some new analytical and graphical tools. Results show that the number
of questions which can be answered consistently vary considerably among models
but are typically in the 50%-80% range for small models at low inference
temperatures. Also, accuracy among consistent answers seems to reasonably
correlate with overall accuracy. Results for medium-sized models seem to
indicate much higher levels of answer consistency.

</details>


### [94] [Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal](https://arxiv.org/abs/2509.09708)
*Nirmalendu Prakash,Yeo Wei Jie,Amir Abdullah,Ranjan Satapathy,Erik Cambria,Roy Ka Wei Lee*

Main category: cs.CL

TL;DR: 本研究利用稀疏自编码器（SAEs）分析大型语言模型（LLMs）拒绝有害提示的内部机制，通过识别并消融关键特征来使模型从拒绝转变为顺从，从而实现“越狱”，并揭示了拒绝行为的深层机制。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs拒绝有害提示是其关键的安全行为，但这种行为的内部原因仍知之甚少。

Method: 研究使用了Gemma-2-2B-IT和LLaMA-3.1-8B-IT模型，并在残差流激活上训练了稀疏自编码器（SAEs）。通过在SAE潜在空间中搜索，寻找消融后能使模型从拒绝转变为顺从的特征集。该搜索分三阶段进行：1) 拒绝方向：找到介导拒绝的方向并收集附近SAE特征；2) 贪婪过滤：修剪至最小特征集；3) 交互发现：拟合分解机（FM）以捕获剩余活跃特征与最小特征集之间的非线性交互。

Result: 该方法识别出大量对“越狱”至关重要的特征，深入揭示了拒绝行为的机械基础。此外，研究发现存在冗余特征，这些特征在早期特征被抑制时才会激活。

Conclusion: 研究结果强调了通过操纵可解释的潜在空间，对LLMs安全行为进行细粒度审计和有针对性干预的潜力。

Abstract: Refusal on harmful prompts is a key safety behaviour in instruction-tuned
large language models (LLMs), yet the internal causes of this behaviour remain
poorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT
and LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on
residual-stream activations. Given a harmful prompt, we search the SAE latent
space for feature sets whose ablation flips the model from refusal to
compliance, demonstrating causal influence and creating a jailbreak. Our search
proceeds in three stages: (1) Refusal Direction: find a refusal-mediating
direction and collect SAE features near that direction; (2) Greedy Filtering:
prune to a minimal set; and (3) Interaction Discovery: fit a factorization
machine (FM) that captures nonlinear interactions among the remaining active
features and the minimal set. This pipeline yields a broad set of
jailbreak-critical features, offering insight into the mechanistic basis of
refusal. Moreover, we find evidence of redundant features that remain dormant
unless earlier features are suppressed. Our findings highlight the potential
for fine-grained auditing and targeted intervention in safety behaviours by
manipulating the interpretable latent space.

</details>


### [95] [Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement](https://arxiv.org/abs/2509.09709)
*Jing Ren,Weiqi Wang*

Main category: cs.CL

TL;DR: 本研究提出两个量化指标（内容质量和引用有效性）和一种迭代提示方法，用于客观评估和提升大型语言模型在学术写作中的表现，有效解决了引用错误和内容质量问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在学术写作中日益普及，但存在引用错误和捏造等道德问题。此外，现有内容质量评估依赖主观人工判断，效率低且缺乏客观性，影响评估一致性和可靠性。

Method: 本研究提出两个关键评估指标：内容质量和引用有效性。基于这两个指标的分数，进一步提出一种迭代提示方法，以量化评估并增强大型语言模型的研究提案写作能力。

Result: 实验结果表明，所提出的指标为评估ChatGPT的写作表现提供了一个客观、量化的框架。此外，迭代提示显著提高了内容质量，同时减少了引用不准确和捏造的情况。

Conclusion: 本研究提出的量化评估框架和迭代提示方法，为大型语言模型在学术写作中的表现提供了客观评估工具，并有效解决了内容质量和引用准确性等关键伦理挑战。

Abstract: Large language models (LLMs) like ChatGPT are increasingly used in academic
writing, yet issues such as incorrect or fabricated references raise ethical
concerns. Moreover, current content quality evaluations often rely on
subjective human judgment, which is labor-intensive and lacks objectivity,
potentially compromising the consistency and reliability. In this study, to
provide a quantitative evaluation and enhance research proposal writing
capabilities of LLMs, we propose two key evaluation metrics--content quality
and reference validity--and an iterative prompting method based on the scores
derived from these two metrics. Our extensive experiments show that the
proposed metrics provide an objective, quantitative framework for assessing
ChatGPT's writing performance. Additionally, iterative prompting significantly
enhances content quality while reducing reference inaccuracies and
fabrications, addressing critical ethical challenges in academic contexts.

</details>


### [96] [Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data](https://arxiv.org/abs/2509.09710)
*Sepehr Golrokh Amin,Devin Rhoads,Fatemeh Fakhrmoosavi,Nicholas E. Lownes,John N. Ivan*

Main category: cs.CL

TL;DR: 本研究提出了一种使用大型语言模型（LLM）从开放数据生成个体旅行日记的新方法，并在与传统方法比较后，证明其在模拟交通模型中的可行性与竞争力，尤其在出行目的判断和一致性方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 传统的个体旅行日记生成方法高度依赖大量专有的家庭旅行调查数据，这限制了其应用范围和数据获取成本。本研究旨在开发一种利用开放数据和LLM生成旅行日记的新方案，以克服这些局限性。

Method: 该研究通过以下步骤生成旅行日记：1) 从开放的美国社区调查（ACS）和智能位置数据库（SLD）数据中随机生成人物画像（personas）。2) 通过直接提示（direct prompting）LLM合成旅行日记。3) 引入了一个新颖的“一对群组真实性评分”（one-to-cohort realism score），该评分由四个指标（出行次数得分、间隔得分、目的得分和模式得分）组成，并使用Jensen-Shannon散度进行验证，以衡量生成日记与康涅狄格州全州交通研究（CSTS）日记在人口统计学变量匹配下的分布相似性。4) 将LLM生成的结果与使用经典方法（负二项式模型用于出行生成，多项Logit模型用于模式/目的选择）生成的结果进行比较。

Result: LLM生成的日记与经典方法生成的日记在总体真实性方面具有可比性（LLM平均：0.485 vs. 0.455）。LLM在确定出行目的方面表现出色，并显示出更高的一致性（真实性得分分布更窄）。而经典模型在出行次数和活动持续时间的数值估计方面表现更优。聚合验证证实了LLM的统计代表性（LLM平均：0.612 vs. 0.435），展示了LLM的零样本（zero-shot）可行性。

Conclusion: 本研究证明了LLM在代理交通模型中生成个体旅行日记的零样本可行性。LLM在出行目的判断和结果一致性方面具有优势，尽管在某些数值估计上不如经典模型。研究还建立了一个可量化的日记真实性指标，为未来合成日记评估系统提供了基础。

Abstract: This study introduces a Large Language Model (LLM) scheme for generating
individual travel diaries in agent-based transportation models. While
traditional approaches rely on large quantities of proprietary household travel
surveys, the method presented in this study generates personas stochastically
from open-source American Community Survey (ACS) and Smart Location Database
(SLD) data, then synthesizes diaries through direct prompting. This study
features a novel one-to-cohort realism score: a composite of four metrics (Trip
Count Score, Interval Score, Purpose Score, and Mode Score) validated against
the Connecticut Statewide Transportation Study (CSTS) diaries, matched across
demographic variables. The validation utilizes Jensen-Shannon Divergence to
measure distributional similarities between generated and real diaries. When
compared to diaries generated with classical methods (Negative Binomial for
trip generation; Multinomial Logit for mode/purpose) calibrated on the
validation set, LLM-generated diaries achieve comparable overall realism (LLM
mean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and
demonstrates greater consistency (narrower realism score distribution), while
classical models lead in numerical estimates of trip count and activity
duration. Aggregate validation confirms the LLM's statistical
representativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot
viability and establishing a quantifiable metric of diary realism for future
synthetic diary evaluation systems.

</details>


### [97] [Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry](https://arxiv.org/abs/2509.09711)
*Aya E. Fouda,Abdelrahamn A. Hassan,Radwa J. Hanafy,Mohammed E. Fouda*

Main category: cs.CL

TL;DR: 本文介绍了 PsychiatryBench，一个基于权威精神病学教科书和案例的基准测试集，用于评估大型语言模型在精神病学实践中的表现，并发现现有模型在临床一致性和安全性方面存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在精神病学实践中具有巨大潜力，但现有评估资源过度依赖小型临床访谈、社交媒体或合成对话，限制了其临床有效性，未能捕捉精神病学推理的复杂性。

Method: 研究引入了 PsychiatryBench，一个严格筛选的基准测试集，完全基于权威、专家验证的精神病学教科书和案例。它包含11个不同的问答任务，涵盖诊断推理、治疗计划、长期随访等，共计超过5300个专家标注条目。研究评估了多种前沿LLM和领先的开源医学模型，使用传统指标和“LLM作为评判”的相似性评分框架。

Result: 评估结果揭示了模型在临床一致性和安全性方面存在显著差距，尤其是在多轮随访和管理任务中。这强调了对专业模型微调和更稳健评估范式的需求。

Conclusion: PsychiatryBench 提供了一个模块化、可扩展的平台，用于基准测试和改进LLM在高风险精神健康应用中的性能。研究结果表明，需要专门的模型调优和更强大的评估方法来提高LLM在精神病学领域的表现。

Abstract: Large language models (LLMs) hold great promise in enhancing psychiatric
practice, from improving diagnostic accuracy to streamlining clinical
documentation and therapeutic support. However, existing evaluation resources
heavily rely on small clinical interview corpora, social media posts, or
synthetic dialogues, which limits their clinical validity and fails to capture
the full complexity of psychiatric reasoning. In this work, we introduce
PsychiatryBench, a rigorously curated benchmark grounded exclusively in
authoritative, expert-validated psychiatric textbooks and casebooks.
PsychiatryBench comprises eleven distinct question-answering tasks ranging from
diagnostic reasoning and treatment planning to longitudinal follow-up,
management planning, clinical approach, sequential case analysis, and
multiple-choice/extended matching formats totaling over 5,300 expert-annotated
items. We evaluate a diverse set of frontier LLMs (including Google Gemini,
DeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models
(e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an
"LLM-as-judge" similarity scoring framework. Our results reveal substantial
gaps in clinical consistency and safety, particularly in multi-turn follow-up
and management tasks, underscoring the need for specialized model tuning and
more robust evaluation paradigms. PsychiatryBench offers a modular, extensible
platform for benchmarking and improving LLM performance in high-stakes mental
health applications.

</details>


### [98] [The Thinking Therapist: Training Large Language Models to Deliver Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio Policy Optimization](https://arxiv.org/abs/2509.09712)
*Talha Tahir*

Main category: cs.CL

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral
therapy with emerging evidence of efficacy in several psychiatric conditions.
This study investigates the impact of post-training methodology and explicit
reasoning on the ability of a small open-weight large language model (LLM) to
deliver ACT. Using 50 sets of synthetic ACT transcripts generated by
Mistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches,
supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each
with and without an explicit chain-of-thought (COT) reasoning step. Performance
was evaluated by comparing these four post-trained variants against the base
Instruct model. These models were benchmarked in simulated therapy sessions,
with performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM)
and the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned
on human evaluations. Our findings demonstrate that the ORPO-trained models
significantly outperformed both their SFT and Instruct counterparts on ACT
fidelity ($\chi^2(5) = 185.15, p < .001$) and therapeutic empathy ($\chi^2(5) =
140.37, p < .001$). The effect of COT was conditional as it provided a
significant benefit to SFT models, improving ACT-FM scores by an average of
2.68 points ($p < .001$), while offering no discernible advantage to the
superior ORPO or instruct-tuned variants. We posit that the superiority of ORPO
stems from its ability to learn the therapeutic `process' over imitating
`content,' a key aspect of ACT, while COT acts as a necessary scaffold for
models trained only via imitation. This study establishes that
preference-aligned policy optimization can effectively instill ACT competencies
in small LLMs, and that the utility of explicit reasoning is highly dependent
on the underlying training paradigm.

</details>


### [99] [HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2509.09713)
*Duolin Sun,Dan Yang,Yue Shen,Yihan Jiao,Zhehao Tan,Jie Feng,Lianzhen Zhong,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: 本文提出HANRAG框架，通过启发式路由、子查询分解和噪声过滤，解决现有RAG方法在多跳查询中效率低下和噪声积累的问题，显著提升了单跳和多跳问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法在处理多跳查询时面临挑战：过度依赖迭代检索导致步骤浪费；原始复杂查询检索未能捕捉子查询相关内容，引入噪声并导致噪声积累。

Method: 引入HANRAG，一个基于启发式的新颖框架。它由一个强大的“揭示器”（revelator）驱动，负责路由查询、将复杂查询分解为子查询，并过滤检索到的文档中的噪声，从而提高系统的适应性和抗噪能力。

Result: HANRAG框架在各种基准测试中，与行业领先方法相比，在单跳和多跳问答任务中均取得了卓越的性能。

Conclusion: HANRAG框架通过高效处理查询、分解子查询和过滤噪声，有效解决了RAG在多跳查询中的挑战，显著提升了系统的适应性和抗噪能力，并在多跳问答任务中展现出优越性。

Abstract: The Retrieval-Augmented Generation (RAG) approach enhances question-answering
systems and dialogue generation tasks by integrating information retrieval (IR)
technologies with large language models (LLMs). This strategy, which retrieves
information from external knowledge bases to bolster the response capabilities
of generative models, has achieved certain successes. However, current RAG
methods still face numerous challenges when dealing with multi-hop queries. For
instance, some approaches overly rely on iterative retrieval, wasting too many
retrieval steps on compound queries. Additionally, using the original complex
query for retrieval may fail to capture content relevant to specific
sub-queries, resulting in noisy retrieved content. If the noise is not managed,
it can lead to the problem of noise accumulation. To address these issues, we
introduce HANRAG, a novel heuristic-based framework designed to efficiently
tackle problems of varying complexity. Driven by a powerful revelator, HANRAG
routes queries, decomposes them into sub-queries, and filters noise from
retrieved documents. This enhances the system's adaptability and noise
resistance, making it highly capable of handling diverse queries. We compare
the proposed framework against other leading industry methods across various
benchmarks. The results demonstrate that our framework obtains superior
performance in both single-hop and multi-hop question-answering tasks.

</details>


### [100] [How Small Transformation Expose the Weakness of Semantic Similarity Measures](https://arxiv.org/abs/2509.09714)
*Serge Lionel Nikiema,Albérick Euraste Djire,Abdoul Aziz Bonkoungou,Micheline Bénédicte Moumoula,Jordan Samhi,Abdoul Kader Kabore,Jacques Klein,Tegawendé F. Bissyande*

Main category: cs.CL

TL;DR: 研究评估了18种语义相似度测量方法，发现常用的嵌入方法存在严重问题，高达99.9%的时间将语义相反的词识别为相似，而LLM方法在区分语义差异方面表现更好。距离计算方式对嵌入方法性能影响显著。


<details>
  <summary>Details</summary>
Motivation: 语义相似度测量对软件工程应用（如代码搜索、API推荐、自动化代码审查）至关重要。尽管大语言模型（LLM）日益普及，但它们是否真正理解语义关系或仅识别表面模式仍存疑问。

Method: 研究测试了18种不同的相似度测量方法，包括基于词语的方法、嵌入技术、基于LLM的系统和结构感知算法。研究人员创建了一个系统性测试框架，通过对文本和代码施加受控变化来评估每种方法处理不同类型语义关系的能力。

Result: 结果显示常用指标存在显著问题。一些基于嵌入的方法高达99.9%的时间将语义相反的词错误识别为相似，而某些基于Transformer的方法偶尔将相反的含义评为比同义词更相似。嵌入方法的糟糕表现常源于其距离计算方式；将欧几里得距离改为余弦相似度可将结果提高24%至66%。LLM方法在区分语义差异方面表现更好，对真正不同的含义给出较低的相似度分数（0.00至0.29），而嵌入方法则错误地为不相似内容分配高分（0.82至0.99）。

Conclusion: 许多现有的语义相似度测量方法，特别是基于嵌入的方法，在真正理解语义关系方面存在严重缺陷，常将相反或不相似的内容误判为高度相似。LLM方法在区分语义差异上表现出更好的能力，且嵌入方法的距离计算方式对性能至关重要。

Abstract: This research examines how well different methods measure semantic
similarity, which is important for various software engineering applications
such as code search, API recommendations, automated code reviews, and
refactoring tools. While large language models are increasingly used for these
similarity assessments, questions remain about whether they truly understand
semantic relationships or merely recognize surface patterns.
  The study tested 18 different similarity measurement approaches, including
word-based methods, embedding techniques, LLM-based systems, and
structure-aware algorithms. The researchers created a systematic testing
framework that applies controlled changes to text and code to evaluate how well
each method handles different types of semantic relationships.
  The results revealed significant issues with commonly used metrics. Some
embedding-based methods incorrectly identified semantic opposites as similar up
to 99.9 percent of the time, while certain transformer-based approaches
occasionally rated opposite meanings as more similar than synonymous ones. The
study found that embedding methods' poor performance often stemmed from how
they calculate distances; switching from Euclidean distance to cosine
similarity improved results by 24 to 66 percent. LLM-based approaches performed
better at distinguishing semantic differences, producing low similarity scores
(0.00 to 0.29) for genuinely different meanings, compared to embedding methods
that incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.

</details>


### [101] [Investigating Symbolic Triggers of Hallucination in Gemma Models Across HaluEval and TruthfulQA](https://arxiv.org/abs/2509.09715)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: 本研究识别并量化了导致大型语言模型（LLMs）幻觉的关键内在属性。结果显示，Gemma模型对符号属性（特别是修饰语和命名实体）的幻觉率很高，尽管随着模型规模的增加幻觉率有所下降，但这种根本性弱点仍然存在。


<details>
  <summary>Details</summary>
Motivation: 幻觉是大型语言模型中一个被广泛研究的问题，但导致LLMs本质上容易产生幻觉的内在属性尚未被明确识别和研究。本研究旨在识别和表征这些关键属性，以找出模型内部机制中的脆弱点。

Method: 研究使用了HaluEval和TruthfulQA两个既有数据集，并将其问答格式转换为其他多种格式，以缩小并确定导致幻觉的特定属性。实验对象是Gemma-2系列模型（2B、9B和27B），通过评估它们在不同符号属性上的幻觉百分比来分析其表现。

Result: Gemma-2-2B在各项任务和数据集上的幻觉率平均高达79.0%。随着模型规模的增加，幻觉率有所下降，Gemma-2-9B降至73.6%，Gemma-2-27B降至63.9%，总体降低了15个百分点。然而，由符号属性引起的幻觉仍大量存在，尤其是在修饰语（84.76%至94.98%）和命名实体（83.87%至93.96%）方面，所有Gemma模型和两个数据集都显示出高幻觉率。

Conclusion: 研究结果表明，符号元素持续困扰着大型语言模型，这指出了LLMs在处理此类输入时存在根本性弱点，且这种弱点与模型规模无关，即使模型变大，该问题依然显著存在。

Abstract: Hallucination in Large Language Models (LLMs) is a well studied problem.
However, the properties that make LLM intrinsically vulnerable to
hallucinations have not been identified and studied. This research identifies
and characterizes the key properties, allowing us to pinpoint vulnerabilities
within the model's internal mechanisms. To solidify on these properties, we
utilized two established datasets, HaluEval and TruthfulQA and convert their
existing format of question answering into various other formats to narrow down
these properties as the reason for the hallucinations. Our findings reveal that
hallucination percentages across symbolic properties are notably high for
Gemma-2-2B, averaging 79.0% across tasks and datasets. With increased model
scale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B,
reflecting a 15 percentage point reduction overall. Although the hallucination
rate decreases as the model size increases, a substantial amount of
hallucination caused by symbolic properties still persists. This is especially
evident for modifiers (ranging from 84.76% to 94.98%) and named entities
(ranging from 83.87% to 93.96%) across all Gemma models and both datasets.
These findings indicate that symbolic elements continue to confuse the models,
pointing to a fundamental weakness in how these LLMs process such
inputs--regardless of their scale.

</details>


### [102] [ALIGNS: Unlocking nomological networks in psychological measurement through a large language model](https://arxiv.org/abs/2509.09723)
*Kai R. Larsen,Sen Yan,Roland Müller,Lan Sang,Mikko Rönkkö,Ravi Starzl,Donald Edmondson*

Main category: cs.CL

TL;DR: ALIGNS是一个基于大型语言模型的系统，用于构建心理测量中的列联网络，以解决效度验证的长期挑战，并已应用于心理学、医学和社会政策等领域。


<details>
  <summary>Details</summary>
Motivation: 心理测量中的列联网络（nomological networks）构建是建立效度（validity）的关键，但自Cronbach和Meehl提出以来，70年来仍是一个挑战。这一局限性导致临床试验可能无法检测到治疗效果，公共政策可能针对错误的成果。

Method: 本文介绍了“分析潜在指标以生成列联结构”（ALIGNS）系统，这是一个基于大型语言模型（LLM）的系统，使用经过验证的问卷测量进行训练。ALIGNS旨在提供全面的列联网络。

Result: ALIGNS提供了三个包含超过550,000个指标的综合列联网络，涵盖心理学、医学、社会政策等领域。这是大型语言模型首次应用于解决测量验证中的基础问题。模型经过分类准确性测试。三项评估结果显示：1) NIH PROMIS焦虑和抑郁工具趋向于单一的情绪困扰维度；2) 儿童气质测量识别出四个当前框架未捕捉到的潜在维度，并质疑一个现有维度；3) 专家心理计量师评估了系统的“重要性”、“可访问性”和“适用性”。

Conclusion: ALIGNS通过大规模的列联分析，补充了传统的验证方法。该系统免费提供，有望解决测量验证中的长期挑战，并对多个学科产生实际影响。

Abstract: Psychological measurement is critical to many disciplines. Despite advances
in measurement, building nomological networks, theoretical maps of how concepts
and measures relate to establish validity, remains a challenge 70 years after
Cronbach and Meehl proposed them as fundamental to validation. This limitation
has practical consequences: clinical trials may fail to detect treatment
effects, and public policy may target the wrong outcomes. We introduce Analysis
of Latent Indicators to Generate Nomological Structures (ALIGNS), a large
language model-based system trained with validated questionnaire measures.
ALIGNS provides three comprehensive nomological networks containing over
550,000 indicators across psychology, medicine, social policy, and other
fields. This represents the first application of large language models to solve
a foundational problem in measurement validation. We report classification
accuracy tests used to develop the model, as well as three evaluations. In the
first evaluation, the widely used NIH PROMIS anxiety and depression instruments
are shown to converge into a single dimension of emotional distress. The second
evaluation examines child temperament measures and identifies four potential
dimensions not captured by current frameworks, and questions one existing
dimension. The third evaluation, an applicability check, engages expert
psychometricians who assess the system's importance, accessibility, and
suitability. ALIGNS is freely available at nomologicalnetwork.org,
complementing traditional validation methods with large-scale nomological
analysis.

</details>


### [103] [DiTTO-LLM: Framework for Discovering Topic-based Technology Opportunities via Large Language Model](https://arxiv.org/abs/2509.09724)
*Wonyoung Kim,Sujeong Seo,Juhyun Lee*

Main category: cs.CL

TL;DR: 本文提出一个基于技术间时间关系识别新兴技术机会的框架，该框架利用大型语言模型从专利数据中提取主题并追踪其随时间的变化，以发现技术机会。


<details>
  <summary>Details</summary>
Motivation: 技术机会是推动技术、产业和创新进步的关键信息，因此需要一种有效的方法来识别它们。

Method: 该框架首先从专利数据集中提取文本，然后将基于文本的主题映射以发现技术间关系。通过追踪这些主题随时间的变化来识别技术机会。为提高效率，框架利用大型语言模型提取主题，并使用基于聊天的语言模型提示来支持技术机会的发现。该框架已在美国专利商标局提供的AI专利数据集上进行了评估。

Result: 实验结果表明，人工智能技术正朝着促进日常可及性的方向发展。该方法展示了所提出框架在识别未来技术机会方面的潜力。

Conclusion: 所提出的基于技术时间关系的框架能够有效识别未来的技术机会，并具有实际应用潜力。

Abstract: Technology opportunities are critical information that serve as a foundation
for advancements in technology, industry, and innovation. This paper proposes a
framework based on the temporal relationships between technologies to identify
emerging technology opportunities. The proposed framework begins by extracting
text from a patent dataset, followed by mapping text-based topics to discover
inter-technology relationships. Technology opportunities are then identified by
tracking changes in these topics over time. To enhance efficiency, the
framework leverages a large language model to extract topics and employs a
prompt for a chat-based language model to support the discovery of technology
opportunities. The framework was evaluated using an artificial intelligence
patent dataset provided by the United States Patent and Trademark Office. The
experimental results suggest that artificial intelligence technology is
evolving into forms that facilitate everyday accessibility. This approach
demonstrates the potential of the proposed framework to identify future
technology opportunities.

</details>


### [104] [BIBERT-Pipe on Biomedical Nested Named Entity Linking at BioASQ 2025](https://arxiv.org/abs/2509.09725)
*Chunyu Li,Xindi Zheng,Siqi Liu*

Main category: cs.CL

TL;DR: 本文介绍了一种名为BIBERT-Pipe的轻量级系统，用于解决生物医学文本中的多语言嵌套实体链接问题，通过两阶段检索-排序、边界提示和数据增强，在BioNNE 2025多语言赛道中排名第三。


<details>
  <summary>Details</summary>
Motivation: 目前的生物医学实体链接（EL）基准测试主要集中于英语语料库和扁平化提及，忽略了更具挑战性的嵌套和多语言提及的现实场景。

Method: 该系统采用轻量级管道，保留了原始EL模型，并修改了三个任务对齐的组件：1) 两阶段检索-排序，在检索阶段使用原始预训练模型，在排序阶段应用领域特定微调。2) 边界提示，在排序阶段用可学习的[Ms]/[Me]标签包裹每个提及，提供明确、与语言无关的跨度信息。3) 数据增强，自动扩展排序训练语料库，使用三个互补数据源以增强覆盖范围。

Result: 在BioNNE 2025排行榜上，该系统（BIBERT-Pipe）在多语言赛道中排名第三。

Conclusion: 这些最小而有原则的修改（两阶段检索-排序、边界提示和数据增强）在处理多语言嵌套生物医学实体链接方面表现出有效性和竞争力。

Abstract: Entity linking (EL) for biomedical text is typically benchmarked on
English-only corpora with flat mentions, leaving the more realistic scenario of
nested and multilingual mentions largely unexplored. We present our system for
the BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task
(English & Russian), closing this gap with a lightweight pipeline that keeps
the original EL model intact and modifies only three task-aligned components:
Two-stage retrieval-ranking. We leverage the same base encoder model in both
stages: the retrieval stage uses the original pre-trained model, while the
ranking stage applies domain-specific fine-tuning. Boundary cues. In the
ranking stage, we wrap each mention with learnable [Ms] / [Me] tags, providing
the encoder with an explicit, language-agnostic span before robustness to
overlap and nesting. Dataset augmentation. We also automatically expand the
ranking training corpus with three complementary data sources, enhancing
coverage without extra manual annotation. On the BioNNE 2025 leaderboard, our
two stage system, bilingual bert (BIBERT-Pipe), ranks third in the multilingual
track, demonstrating the effectiveness and competitiveness of these minimal yet
principled modifications. Code are publicly available at
https://github.com/Kaggle-Competitions-Code/BioNNE-L.

</details>


### [105] [Natural Language Translation of Formal Proofs through Informalization of Proof Steps and Recursive Summarization along Proof Structure](https://arxiv.org/abs/2509.09726)
*Seiji Hattori,Takuya Matsuzaki,Makoto Fujiwara*

Main category: cs.CL

TL;DR: 本文提出一种利用大型语言模型（LLMs）的非形式化和摘要能力，将机器可验证的形式化证明翻译成自然语言的方法。


<details>
  <summary>Details</summary>
Motivation: 将机器可验证的形式化证明转化为人类可读的自然语言形式，以提高其可理解性。

Method: 利用LLMs对形式化证明步骤进行非形式化（口头化）和摘要。通过将该方法应用于根据本科教材自然语言证明创建的形式化证明数据进行评估，并与原始自然语言证明进行质量比较。此外，还将其应用于Lean证明助手的现有形式化证明库。

Result: 该方法能够输出高度可读且准确的自然语言证明。

Conclusion: 该方法能够有效且高质量地将形式化证明转换为自然语言证明。

Abstract: This paper proposes a natural language translation method for
machine-verifiable formal proofs that leverages the informalization
(verbalization of formal language proof steps) and summarization capabilities
of LLMs. For evaluation, it was applied to formal proof data created in
accordance with natural language proofs taken from an undergraduate-level
textbook, and the quality of the generated natural language proofs was analyzed
in comparison with the original natural language proofs. Furthermore, we will
demonstrate that this method can output highly readable and accurate natural
language proofs by applying it to existing formal proof library of the Lean
proof assistant.

</details>


### [106] [A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs](https://arxiv.org/abs/2509.09727)
*Andy Zhu,Yingjun Du*

Main category: cs.CL

TL;DR: 本文提出一个多智能体框架，通过角色提示和 RAG 提升金融教育问答的准确性，超越零样本 CoT 基线，并使小型 LLM 达到与专业模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLM）在金融领域问答中表现不佳，难以处理多步量化推理、专业术语和真实世界场景理解等金融问题所需的细致和专业推理。

Method: 开发了一个多智能体框架，利用基于角色的提示来增强领域特定问答的性能。该框架包含一个基础生成器（Base Generator）、一个证据检索器（Evidence Retriever）和一个专家评审员（Expert Reviewer），以单次迭代方式协作生成优化答案。研究利用 RAG 从 6 本金融教科书获取上下文证据，并为领域专家评审员设计提示策略。该框架在 Study.com 的 3,532 个专家设计的金融教育问题上进行了评估。

Result: 基于批判性反馈的答案优化比零样本思维链（Chain-of-Thought）基线提高了 6.6-8.3% 的准确率，其中 Gemini-2.0-Flash 表现最佳。此外，该方法使得 GPT-4o-mini 达到了与金融领域微调模型 FinGPT-mt_Llama3-8B_LoRA 相当的性能。

Conclusion: 该研究提供了一种经济有效的方法来增强金融问答系统，并为多智能体金融 LLM 系统的进一步研究提供了见解。

Abstract: Question answering (QA) plays a central role in financial education, yet
existing large language model (LLM) approaches often fail to capture the
nuanced and specialized reasoning required for financial problem-solving. The
financial domain demands multistep quantitative reasoning, familiarity with
domain-specific terminology, and comprehension of real-world scenarios. We
present a multi-agent framework that leverages role-based prompting to enhance
performance on domain-specific QA. Our framework comprises a Base Generator, an
Evidence Retriever, and an Expert Reviewer agent that work in a single-pass
iteration to produce a refined answer. We evaluated our framework on a set of
3,532 expert-designed finance education questions from Study.com, an online
learning platform. We leverage retrieval-augmented generation (RAG) for
contextual evidence from 6 finance textbooks and prompting strategies for a
domain-expert reviewer. Our experiments indicate that critique-based refinement
improves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,
with the highest performance from Gemini-2.0-Flash. Furthermore, our method
enables GPT-4o-mini to achieve performance comparable to the finance-tuned
FinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to
enhancing financial QA and offer insights for further research in multi-agent
financial LLM systems.

</details>


### [107] [A meta-analysis on the performance of machine-learning based language models for sentiment analysis](https://arxiv.org/abs/2509.09728)
*Elena Rohde,Jonas Klingwort,Christian Borgs*

Main category: cs.CL

TL;DR: 本研究对Twitter数据的情感分析中机器学习模型性能进行了荟萃分析，发现平均准确率为0.80，并强调了标准化报告和规范化性能指标的重要性。


<details>
  <summary>Details</summary>
Motivation: 评估机器学习在Twitter情感分析中的表现，估计平均性能，评估研究内部和研究间的异质性，并分析研究特征如何影响模型性能。

Method: 采用PRISMA指南进行荟萃分析，检索学术数据库，从20项研究中选择了195个试验，并提取了12个研究特征。使用双反正弦变换和三级随机效应模型分析了最常报告的性能指标——总体准确率。

Result: AIC优化模型的平均总体准确率为0.80 [0.76, 0.84]。研究发现，总体准确率因类别不平衡和情感类别数量而易产生误导，需要进行规范化。此外，标准化报告模型性能（包括独立测试集的混淆矩阵）对于可靠比较机器学习分类器至关重要，但目前并不常见。

Conclusion: 总体准确率在情感分析中广泛使用但常具误导性，需要规范化。为了实现机器学习分类器之间可靠的跨研究比较，标准化报告模型性能（特别是混淆矩阵）是必不可少的。

Abstract: This paper presents a meta-analysis evaluating ML performance in sentiment
analysis for Twitter data. The study aims to estimate the average performance,
assess heterogeneity between and within studies, and analyze how study
characteristics influence model performance. Using PRISMA guidelines, we
searched academic databases and selected 195 trials from 20 studies with 12
study features. Overall accuracy, the most reported performance metric, was
analyzed using double arcsine transformation and a three-level random effects
model. The average overall accuracy of the AIC-optimized model was 0.80 [0.76,
0.84]. This paper provides two key insights: 1) Overall accuracy is widely used
but often misleading due to its sensitivity to class imbalance and the number
of sentiment classes, highlighting the need for normalization. 2) Standardized
reporting of model performance, including reporting confusion matrices for
independent test sets, is essential for reliable comparisons of ML classifiers
across studies, which seems far from common practice.

</details>


### [108] [MultimodalHugs: Enabling Sign Language Processing in Hugging Face](https://arxiv.org/abs/2509.09729)
*Gerard Sant,Zifan Jiang,Carlos Escolano,Amit Moryossef,Mathias Müller,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: MultimodalHugs是一个基于Hugging Face的框架，旨在解决手语处理（SLP）研究中存在的低复现性和不公平比较问题，通过支持更多样化的数据模态和任务，同时保留Hugging Face的优势。


<details>
  <summary>Details</summary>
Motivation: 手语处理（SLP）研究受到复杂、临时性代码的阻碍，导致复现性低和比较不公平。现有的工具（如Hugging Face）不够灵活，无法无缝集成手语实验，这一点已通过对SLP研究人员的调查得到证实。

Method: 引入MultimodalHugs框架，它建立在Hugging Face之上，增加了一个抽象层，使其能够支持更多样化的数据模态和任务，同时继承了Hugging Face生态系统的优势。

Result: MultimodalHugs能够适应多种模态，例如用于手语的姿态估计数据或用于文本字符的像素数据。定量实验证明了其处理多样化模态的能力。

Conclusion: MultimodalHugs提供了一个灵活且可复现的解决方案，以应对手语处理及其他不符合Hugging Face标准模板的多模态用例所面临的挑战，从而促进这些领域的研究进展。

Abstract: In recent years, sign language processing (SLP) has gained importance in the
general field of Natural Language Processing. However, compared to research on
spoken languages, SLP research is hindered by complex ad-hoc code,
inadvertently leading to low reproducibility and unfair comparisons. Existing
tools that are built for fast and reproducible experimentation, such as Hugging
Face, are not flexible enough to seamlessly integrate sign language
experiments. This view is confirmed by a survey we conducted among SLP
researchers.
  To address these challenges, we introduce MultimodalHugs, a framework built
on top of Hugging Face that enables more diverse data modalities and tasks,
while inheriting the well-known advantages of the Hugging Face ecosystem. Even
though sign languages are our primary focus, MultimodalHugs adds a layer of
abstraction that makes it more widely applicable to other use cases that do not
fit one of the standard templates of Hugging Face. We provide quantitative
experiments to illustrate how MultimodalHugs can accommodate diverse modalities
such as pose estimation data for sign languages, or pixel data for text
characters.

</details>


### [109] [Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning](https://arxiv.org/abs/2509.09731)
*Haiyang Yu,Yuchuan Wu,Fan Shi,Lei Liao,Jinghui Lu,Xiaodong Ge,Han Wang,Minghan Zhuo,Xuecheng Wu,Xiang Fei,Hao Feng,Guozhi Tang,An-Lan Wang,Hanshen Zhu,Yangfan He,Quanhuan Liang,Liyuan Meng,Chao Feng,Can Huang,Jingqun Tang,Bin Li*

Main category: cs.CL

TL;DR: 该论文提出了AncientDoc，首个用于评估视觉-语言模型（VLMs）在中国古代文献处理能力上的基准，涵盖从光学字符识别（OCR）到知识推理的多个任务。


<details>
  <summary>Details</summary>
Motivation: 中国古代文献蕴含丰富的历史文化知识，但其数字化和理解面临挑战。传统方法仅扫描图像，而现有VLMs难以处理其视觉和语言复杂性。当前文档基准主要关注英文印刷文本或简化中文，缺乏针对古代中文文献的评估工具。

Method: 研究者创建了AncientDoc基准，包含五项任务（页面级OCR、白话文翻译、基于推理的问答、基于知识的问答、语言变体问答），覆盖14种文献类型、100多本书籍和约3000页内容。他们使用多项指标评估了主流VLMs，并辅以与人类对齐的大型语言模型进行评分。

Result: AncientDoc是首个针对中国古代文献的基准，旨在评估VLMs从OCR到知识推理的能力。它包含多样化的任务和广泛的文献覆盖，并已用于评估主流VLMs。

Conclusion: AncientDoc基准填补了中国古代文献领域VLM评估的空白，为全面评估VLMs处理复杂古代中文文献的视觉和语言能力提供了一个重要工具。

Abstract: Chinese ancient documents, invaluable carriers of millennia of Chinese
history and culture, hold rich knowledge across diverse fields but face
challenges in digitization and understanding, i.e., traditional methods only
scan images, while current Vision-Language Models (VLMs) struggle with their
visual and linguistic complexity. Existing document benchmarks focus on English
printed texts or simplified Chinese, leaving a gap for evaluating VLMs on
ancient Chinese documents. To address this, we present AncientDoc, the first
benchmark for Chinese ancient documents, designed to assess VLMs from OCR to
knowledge reasoning. AncientDoc includes five tasks (page-level OCR, vernacular
translation, reasoning-based QA, knowledge-based QA, linguistic variant QA) and
covers 14 document types, over 100 books, and about 3,000 pages. Based on
AncientDoc, we evaluate mainstream VLMs using multiple metrics, supplemented by
a human-aligned large language model for scoring.

</details>


### [110] [MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools](https://arxiv.org/abs/2509.09734)
*Zikang Guo,Benfeng Xu,Chiwei Zhu,Wentao Hong,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: 本文介绍了MCP-AgentBench，一个专门用于评估在Model Context Protocol (MCP) 标准下语言代理工具交互能力的综合基准，旨在解决现有基准在评估MCP环境下的代理性能方面的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管Model Context Protocol (MCP) 作为代理-工具集成和互操作性的开放标准正在迅速普及，但现有基准未能准确捕捉MCP范式下代理的真实世界性能，导致对其操作价值的感知失真，并难以可靠地区分代理能力。

Method: 本文提出了MCP-AgentBench，其核心贡献包括：1) 建立了包含33个操作服务器和188种不同工具的强大MCP测试平台；2) 开发了一个包含600个系统设计查询的基准，这些查询分布在6个不同交互复杂度的类别中；3) 引入了MCP-Eval，一种以结果为导向的新型评估方法，优先考虑真实世界的任务成功。

Result: 通过对领先语言代理进行广泛的实证评估，MCP-AgentBench提供了基础性见解。

Conclusion: MCP-AgentBench旨在为研究社区提供一个标准化且可靠的框架，以构建、验证和推进能够充分利用MCP变革性优势的代理，从而加速实现真正有能力和可互操作的AI系统。

Abstract: The Model Context Protocol (MCP) is rapidly emerging as a pivotal open
standard, designed to enhance agent-tool integration and interoperability, and
is positioned to unlock a new era of powerful, interconnected, and genuinely
utilitarian agentic AI. However, despite MCP's growing adoption, existing
benchmarks often fail to capture real-world agent performance within this new
paradigm, leading to a distorted perception of their true operational value and
an inability to reliably differentiate proficiencies. To bridge this critical
evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark
specifically engineered to rigorously assess language agent capabilities in
MCP-mediated tool interactions. Core contributions of MCP-AgentBench include:
the establishment of a robust MCP testbed comprising 33 operational servers
with 188 distinct tools; the development of a benchmark featuring 600
systematically designed queries distributed across 6 distinct categories of
varying interaction complexity; and the introduction of MCP-Eval, a novel
outcome-oriented evaluation methodology prioritizing real-world task success.
Through extensive empirical evaluation of leading language agents, we provide
foundational insights. MCP-AgentBench aims to equip the research community with
a standardized and reliable framework to build, validate, and advance agents
capable of fully leveraging MCP's transformative benefits, thereby accelerating
progress toward truly capable and interoperable AI systems.

</details>


### [111] [HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning](https://arxiv.org/abs/2509.09801)
*Brennen Hill*

Main category: cs.CL

TL;DR: 本文提出HEFT，一种结合权重空间（LoRA）和表示空间（ReFT）PEFT方法的层次化策略，在推理任务上以更少计算资源实现更优性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在专业推理任务上的适应性受计算资源限制。现有的参数高效微调（PEFT）方法多样，分别作用于模型的权重空间或表示空间。本文旨在探索这些范式协同组合能否带来更卓越的性能和效率。

Method: 本文引入HEFT（Hierarchical Efficient Fine-Tuning），一种新颖的层次化适应策略。它以从粗到细的方式组合两种不同的PEFT方法：首先，使用低秩适应（LoRA）在权重空间进行广泛的基础适应；随后，使用表示微调（ReFT）对内部激活进行精确的微调。该方法在Llama-2-7B模型上，针对BoolQ推理基准进行评估。

Result: 实验结果显示出显著的协同效应。使用HEFT策略仅微调三个epoch的模型达到了85.17%的准确率，超过了单独使用LoRA（85.05%）或ReFT（83.36%）方法训练20个epoch的模型性能。

Conclusion: 研究表明，深思熟虑地组合PEFT方法是一种强大的算法创新，为提升语言模型推理能力提供了一条更高效、更有效的途径。通过以更少的计算预算实现卓越结果，HEFT提供了一种克服大规模模型适应复杂认知任务固有障碍的原则性方法。

Abstract: The adaptation of large language models (LLMs) to specialized reasoning tasks
is fundamentally constrained by computational resources. Parameter-Efficient
Fine-Tuning (PEFT) methods have emerged as a powerful solution, yet the
landscape of these techniques is diverse, with distinct methods operating in
either the model's weight space or its representation space. This paper
investigates the hypothesis that a synergistic combination of these paradigms
can unlock superior performance and efficiency. We introduce HEFT (Hierarchical
Efficient Fine-Tuning), a novel hierarchical adaptation strategy that composes
two distinct PEFT methods in a coarse-to-fine manner: first, a broad,
foundational adaptation in the weight space using Low-Rank Adaptation (LoRA),
followed by a precise, surgical refinement of internal activations using
Representation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a
Llama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential
reasoning. Our results reveal a profound synergistic effect. A model fine-tuned
for only three epochs with our HEFT strategy achieves an accuracy of 85.17\%,
exceeding the performance of models trained for 20 epochs with either LoRA-only
(85.05\%) or ReFT-only (83.36\%) methodologies. This work demonstrates that the
thoughtful composition of PEFT methods is a potent algorithmic innovation,
offering a more efficient and effective path toward advancing the reasoning
capabilities of language models. By achieving superior results with a fraction
of the computational budget, our findings present a principled approach to
overcoming the obstacles inherent in adapting large-scale models for complex
cognitive tasks.

</details>


### [112] [Discrimination by LLMs: Cross-lingual Bias Assessment and Mitigation in Decision-Making and Summarisation](https://arxiv.org/abs/2509.09735)
*Willem Huijzer,Jieying Chen*

Main category: cs.CL

TL;DR: 本研究调查了大型语言模型（LLMs）在决策和摘要任务中存在的背景、性别和年龄偏见，以及这些偏见的跨语言传播，并评估了提示指令缓解策略的有效性。


<details>
  <summary>Details</summary>
Motivation: LLMs的快速整合引发了对社会不平等和信息偏见的担忧，促使研究人员探讨这些模型中存在的偏见及其影响。

Method: 研究人员使用了Tamkin等人（2023）数据集的改编版本，并将其翻译成荷兰语，创建了151,200个决策任务提示和176,400个摘要任务提示。他们通过测试不同的人口统计变量、指令、显著性水平和语言，对GPT-3.5和GPT-4o模型进行了评估。

Result: 分析显示，在决策任务中，两个模型都存在显著偏见，倾向于女性、年轻年龄和某些背景（如非洲裔美国人）。摘要任务中偏见较少，但GPT-3.5在英语中显示出显著的年龄相关差异。跨语言分析表明，英语和荷兰语的偏见模式大致相似，但在特定人口类别中存在显著差异。新提出的缓解指令虽然未能完全消除偏见，但显示出减少偏见的潜力，最有效的指令使最有利和最不利人口群体之间的差距平均减少了27%。值得注意的是，与GPT-3.5相反，GPT-4o在所有英语提示中都显示出偏见减少，表明较新模型中基于提示的缓解具有特定潜力。

Conclusion: 本研究强调了谨慎采用LLMs和进行特定情境偏见测试的重要性，并指出需要持续开发有效的缓解策略，以确保AI的负责任部署。

Abstract: The rapid integration of Large Language Models (LLMs) into various domains
raises concerns about societal inequalities and information bias. This study
examines biases in LLMs related to background, gender, and age, with a focus on
their impact on decision-making and summarization tasks. Additionally, the
research examines the cross-lingual propagation of these biases and evaluates
the effectiveness of prompt-instructed mitigation strategies. Using an adapted
version of the dataset by Tamkin et al. (2023) translated into Dutch, we
created 151,200 unique prompts for the decision task and 176,400 for the
summarisation task. Various demographic variables, instructions, salience
levels, and languages were tested on GPT-3.5 and GPT-4o. Our analysis revealed
that both models were significantly biased during decision-making, favouring
female gender, younger ages, and certain backgrounds such as the
African-American background. In contrast, the summarisation task showed minimal
evidence of bias, though significant age-related differences emerged for
GPT-3.5 in English. Cross-lingual analysis showed that bias patterns were
broadly similar between English and Dutch, though notable differences were
observed across specific demographic categories. The newly proposed mitigation
instructions, while unable to eliminate biases completely, demonstrated
potential in reducing them. The most effective instruction achieved a 27\% mean
reduction in the gap between the most and least favorable demographics.
Notably, contrary to GPT-3.5, GPT-4o displayed reduced biases for all prompts
in English, indicating the specific potential for prompt-based mitigation
within newer models. This research underscores the importance of cautious
adoption of LLMs and context-specific bias testing, highlighting the need for
continued development of effective mitigation strategies to ensure responsible
deployment of AI.

</details>


### [113] [Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic Survey Responses for the Chilean Case](https://arxiv.org/abs/2509.09871)
*Bastián González-Bustamante,Nando Verelst,Carla Cisternas*

Main category: cs.CL

TL;DR: 该研究评估了大型语言模型（LLM）在生成合成调查问卷回复方面的可靠性，发现它们能近似真实概率样本，但在捕捉公众意见细微差别方面仍面临挑战，且存在项目层面的异质性。


<details>
  <summary>Details</summary>
Motivation: LLM在调查研究中通过合成受访者模拟人类回答和行为，有望减少测量和代表性误差。然而，LLM恢复聚合项目分布的程度以及下游应用重现社会刻板印象和偏见的风险尚不明确，这促使研究者对LLM生成回复的可靠性进行评估。

Method: 研究人员将LLM生成的合成调查回复与智利公众意见概率调查的真实人类回复进行对比评估。具体方法包括：基准测试128个提示-模型-问题三联体，生成189,696个合成配置文件；通过元分析汇总128个问题-子样本对的性能指标（准确率、精确率、召回率和F1分数），以检测关键社会人口维度上的偏差；评估了OpenAI的GPT系列、o系列推理模型以及Llama和Qwen模型。

Result: 研究得出三个主要结果：1. 合成回复在信任项目上表现出色（F1分数和准确率 > 0.90）。2. GPT-4o、GPT-4o-mini和Llama 4 Maverick在该任务上表现相当。3. 合成回复与人类回复的一致性在45-59岁受访者中最高。总体而言，基于LLM的合成样本能近似概率样本的回复，但存在显著的项目层面异质性。

Conclusion: LLM生成的合成样本可以近似概率样本的调查回复，但要捕捉公众意见的全部细微差别仍然具有挑战性。这需要仔细的校准和额外的分布测试，以确保算法的忠实度和减少误差。

Abstract: Large Language Models (LLMs) offer promising avenues for methodological and
applied innovations in survey research by using synthetic respondents to
emulate human answers and behaviour, potentially mitigating measurement and
representation errors. However, the extent to which LLMs recover aggregate item
distributions remains uncertain and downstream applications risk reproducing
social stereotypes and biases inherited from training data. We evaluate the
reliability of LLM-generated synthetic survey responses against ground-truth
human responses from a Chilean public opinion probabilistic survey.
Specifically, we benchmark 128 prompt-model-question triplets, generating
189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,
precision, recall, and F1-score) in a meta-analysis across 128
question-subsample pairs to test for biases along key sociodemographic
dimensions. The evaluation spans OpenAI's GPT family and o-series reasoning
models, as well as Llama and Qwen checkpoints. Three results stand out. First,
synthetic responses achieve excellent performance on trust items (F1-score and
accuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform
comparably on this task. Third, synthetic-human alignment is highest among
respondents aged 45-59. Overall, LLM-based synthetic samples approximate
responses from a probabilistic sample, though with substantial item-level
heterogeneity. Capturing the full nuance of public opinion remains challenging
and requires careful calibration and additional distributional tests to ensure
algorithmic fidelity and reduce errors.

</details>


### [114] [Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to Multimodality in Turn Organization](https://arxiv.org/abs/2509.09804)
*Helen de Andrade Abreu,Tiago Timponi Torrent,Ely Edison da Silva Matos*

Main category: cs.CL

TL;DR: 本文提出一个多模态对话轮次组织建模框架，通过语言与交互手势的相关性，基于语用框架的构思与激活。研究团队开发了手势标注方法，丰富了现有数据集，并证实了手势在对话轮次管理中的作用，揭示了未曾记录的手势变体。


<details>
  <summary>Details</summary>
Motivation: 尽管对话轮次组织已被广泛研究，但缺乏包含手势策略且适用于机器学习的数据集。研究旨在填补这一空白，深入理解交流者如何构思和激活语用框架。

Method: 本文提出了一个框架，通过语言和交互手势之间的关联来建模多模态对话轮次组织，其基础是对语用框架如何被概念化和激活的分析。研究团队开发了一种标注方法，用语用框架（建模对话轮次组织）和手势丰富了Frame2多模态数据集（包含巴西电视剧集，已标注语义框架）。

Result: 研究结果证实，面对面交流中的沟通者确实利用手势作为传递、获取和保持对话轮次的工具，并揭示了一些此前未被记录的手势变体。数据还表明，语用框架的标注有助于更深入地理解人类认知和语言。

Conclusion: 手势在对话轮次组织中扮演着关键角色，其使用源于语用框架（涉及心理空间、融合和概念隐喻）的概念化。新提出的框架、标注方法和丰富的数据集为机器学习提供了资源，并加深了对人类认知和语言的理解。

Abstract: This paper proposes a framework for modeling multimodal conversational turn
organization via the proposition of correlations between language and
interactive gestures, based on analysis as to how pragmatic frames are
conceptualized and evoked by communicators. As a means to provide evidence for
the analysis, we developed an annotation methodology to enrich a multimodal
dataset (annotated for semantic frames) with pragmatic frames modeling
conversational turn organization. Although conversational turn organization has
been studied by researchers from diverse fields, the specific strategies,
especially gestures used by communicators, had not yet been encoded in a
dataset that can be used for machine learning. To fill this gap, we enriched
the Frame2 dataset with annotations of gestures used for turn organization. The
Frame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo
Mundo annotated for semantic frames evoked in both video and text. This dataset
allowed us to closely observe how communicators use interactive gestures
outside a laboratory, in settings, to our knowledge, not previously recorded in
related literature. Our results have confirmed that communicators involved in
face-to-face conversation make use of gestures as a tool for passing, taking
and keeping conversational turns, and also revealed variations of some gestures
that had not been documented before. We propose that the use of these gestures
arises from the conceptualization of pragmatic frames, involving mental spaces,
blending and conceptual metaphors. In addition, our data demonstrate that the
annotation of pragmatic frames contributes to a deeper understanding of human
cognition and language.

</details>


### [115] [Large Language Models Meet Legal Artificial Intelligence: A Survey](https://arxiv.org/abs/2509.09969)
*Zhitian Hou,Zihan Ye,Nanli Zeng,Tianyong Hao,Kun Zeng*

Main category: cs.CL

TL;DR: 本文对法律人工智能领域中的大语言模型（LLM）进行了全面综述，涵盖了模型、框架、基准和数据集，并探讨了面临的挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 大语言模型显著推动了法律人工智能的发展，提高了法律任务的效率和准确性。本文旨在推进基于LLM的法律领域研究和应用。

Method: 本文综述了16个法律LLM系列和47个用于法律任务的LLM框架，并收集了15个基准和29个数据集以评估不同的法律能力。此外，还分析了基于LLM方法在法律领域面临的挑战并讨论了未来方向。

Result: 本文提供了对法律LLM系列、LLM法律任务框架、评估基准和数据集的全面回顾，并深入分析了当前挑战和未来发展方向。

Conclusion: 本论文为初学者提供了系统的介绍，并旨在鼓励该领域未来的研究。

Abstract: Large Language Models (LLMs) have significantly advanced the development of
Legal Artificial Intelligence (Legal AI) in recent years, enhancing the
efficiency and accuracy of legal tasks. To advance research and applications of
LLM-based approaches in legal domain, this paper provides a comprehensive
review of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and
also gather 15 benchmarks and 29 datasets to evaluate different legal
capabilities. Additionally, we analyse the challenges and discuss future
directions for LLM-based approaches in the legal domain. We hope this paper
provides a systematic introduction for beginners and encourages future research
in this field. Resources are available at
https://github.com/ZhitianHou/LLMs4LegalAI.

</details>


### [116] [Topic-Guided Reinforcement Learning with LLMs for Enhancing Multi-Document Summarization](https://arxiv.org/abs/2509.09852)
*Chuyuan Li,Austin Xu,Shafiq Joty,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 本文提出一种主题引导的强化学习方法，通过引入主题奖励和显式主题提示，改进多文档摘要（MDS）中的内容选择。


<details>
  <summary>Details</summary>
Motivation: 多文档摘要（MDS）面临有效整合多源信息并保持连贯性和主题相关性的挑战。尽管大型语言模型在单文档摘要中表现出色，但在MDS上的性能仍有提升空间。

Method: 首先，研究表明显式地用主题标签提示模型可以提高生成摘要的信息量。在此基础上，本文在Group Relative Policy Optimization (GRPO)框架内提出了一种新颖的主题奖励，用于衡量生成摘要与源文档之间的主题一致性。

Result: 在Multi-News和Multi-XScience数据集上的实验结果表明，该方法持续优于强大的基线模型。

Conclusion: 研究强调了在MDS中利用主题线索的有效性，证明了其在内容选择方面的改进。

Abstract: A key challenge in Multi-Document Summarization (MDS) is effectively
integrating information from multiple sources while maintaining coherence and
topical relevance. While Large Language Models have shown impressive results in
single-document summarization, their performance on MDS still leaves room for
improvement. In this paper, we propose a topic-guided reinforcement learning
approach to improve content selection in MDS. We first show that explicitly
prompting models with topic labels enhances the informativeness of the
generated summaries. Building on this insight, we propose a novel topic reward
within the Group Relative Policy Optimization (GRPO) framework to measure topic
alignment between the generated summary and source documents. Experimental
results on the Multi-News and Multi-XScience datasets demonstrate that our
method consistently outperforms strong baselines, highlighting the
effectiveness of leveraging topical cues in MDS.

</details>


### [117] [Unsupervised Hallucination Detection by Inspecting Reasoning Processes](https://arxiv.org/abs/2509.10004)
*Ponhvoan Srey,Xiaobao Wu,Anh Tuan Luu*

Main category: cs.CL

TL;DR: IRIS是一种无监督幻觉检测框架，它利用大型语言模型（LLM）的内部表征和响应不确定性来识别幻觉内容，克服了现有无监督方法依赖非事实性代理信号的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有无监督幻觉检测方法依赖与事实准确性无关的代理信号，导致检测偏差和泛化能力受限；而有监督方法需要大量人工标注，成本高昂。

Method: IRIS框架通过提示LLM仔细验证给定陈述的真实性，并获取其语境化嵌入作为信息特征进行训练。同时，将每个响应的不确定性视为真实性的软伪标签。

Result: 实验结果表明，IRIS持续优于现有的无监督方法。

Conclusion: IRIS方法是完全无监督的，计算成本低，即使在少量训练数据下也能表现良好，使其适用于实时检测。

Abstract: Unsupervised hallucination detection aims to identify hallucinated content
generated by large language models (LLMs) without relying on labeled data.
While unsupervised methods have gained popularity by eliminating
labor-intensive human annotations, they frequently rely on proxy signals
unrelated to factual correctness. This misalignment biases detection probes
toward superficial or non-truth-related aspects, limiting generalizability
across datasets and scenarios. To overcome these limitations, we propose IRIS,
an unsupervised hallucination detection framework, leveraging internal
representations intrinsic to factual correctness. IRIS prompts the LLM to
carefully verify the truthfulness of a given statement, and obtain its
contextualized embedding as informative features for training. Meanwhile, the
uncertainty of each response is considered a soft pseudolabel for truthfulness.
Experimental results demonstrate that IRIS consistently outperforms existing
unsupervised methods. Our approach is fully unsupervised, computationally low
cost, and works well even with few training data, making it suitable for
real-time detection.

</details>


### [118] [CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China](https://arxiv.org/abs/2509.09990)
*Guixian Xu,Zeli Su,Ziyin Zhang,Jianing Liu,XU Han,Ting Zhang,Yushuang Dong*

Main category: cs.CL

TL;DR: 该研究创建了一个针对藏语、维吾尔语和蒙语的少数民族语言标题生成数据集（CMHG），并提供了一个高质量的测试集，以解决这些语言语料库稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 中国少数民族语言（如藏语、维吾尔语、蒙语）的书写系统独特，与国际标准不同，导致在标题生成等监督任务中缺乏相关语料库。

Method: 引入了一个名为“中国少数民族标题生成（CMHG）”的新数据集，包含10万条藏语条目和各5万条维吾尔语、蒙语条目。此外，还提出了一个由母语使用者标注的高质量测试集，旨在作为该领域未来研究的基准。

Result: 成功构建了CMHG数据集，为藏语、维吾尔语和蒙语的标题生成任务提供了大量语料，并创建了一个由母语使用者标注的基准测试集。

Conclusion: 该数据集有望成为推动中国少数民族语言标题生成研究和相关基准发展的重要资源。

Abstract: Minority languages in China, such as Tibetan, Uyghur, and Traditional
Mongolian, face significant challenges due to their unique writing systems,
which differ from international standards. This discrepancy has led to a severe
lack of relevant corpora, particularly for supervised tasks like headline
generation. To address this gap, we introduce a novel dataset, Chinese Minority
Headline Generation (CMHG), which includes 100,000 entries for Tibetan, and
50,000 entries each for Uyghur and Mongolian, specifically curated for headline
generation tasks. Additionally, we propose a high-quality test set annotated by
native speakers, designed to serve as a benchmark for future research in this
domain. We hope this dataset will become a valuable resource for advancing
headline generation in Chinese minority languages and contribute to the
development of related benchmarks.

</details>


### [119] [Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs](https://arxiv.org/abs/2509.10010)
*Adnan Ahmad,Philine Kowol,Stefan Hillmann,Sebastian Möller*

Main category: cs.CL

TL;DR: 本研究对Llama2-7B、Mistral-7B和Yi-6B等开源LLM在多标签意图分类任务上的性能进行了广泛分析，使用MultiWOZ 2.1数据集进行少量样本学习。结果显示，Mistral-7B在LLM中表现最佳，但基于BERT的监督学习分类器整体性能优于表现最好的少量样本LLM。


<details>
  <summary>Details</summary>
Motivation: 研究开源、可在消费级硬件上运行的大语言模型（LLMs）在多标签意图分类任务中的有效性，以提升面向任务型聊天机器人的自然语言理解能力。

Method: 使用MultiWOZ 2.1数据集，评估了Llama2-7B-hf、Mistral-7B-v0.1和Yi-6B三款开源预训练LLM。采用少量样本（few-shot）设置，在提示中提供20个示例和指令。同时，将LLM的性能与使用小型Transformer模型BertForSequenceClassification进行监督学习（微调）的基线进行比较。评估指标包括准确率、精确率、召回率、微观/宏观/加权F1分数、Humming Loss、Jaccard Similarity，并报告推理时间和VRAM需求。

Result: Mistral-7B-v0.1在14个意图类别中的11个上，F-Score（加权平均0.50）优于其他两款生成模型。它还具有相对较低的Humming Loss和较高的Jaccard Similarity，使其成为少量样本设置中的最佳模型。然而，研究发现基于BERT的监督分类器在性能上优于表现最佳的少量样本生成式LLM。

Conclusion: 本研究为小型开源LLM在检测复杂多意图对话方面提供了一个框架，有助于增强面向任务型聊天机器人的自然语言理解能力。尽管开源LLM在少量样本设置中表现出潜力，但经过监督学习微调的BERT模型在该特定任务上仍具有更优异的性能。

Abstract: In this paper, we provide an extensive analysis of multi-label intent
classification using Large Language Models (LLMs) that are open-source,
publicly available, and can be run in consumer hardware. We use the MultiWOZ
2.1 dataset, a benchmark in the dialogue system domain, to investigate the
efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,
Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot
setup, giving 20 examples in the prompt with some instructions. Our approach
focuses on the differences in performance of these models across several
performance metrics by methodically assessing these models on multi-label
intent classification tasks. Additionally, we compare the performance of the
instruction-based fine-tuning approach with supervised learning using the
smaller transformer model BertForSequenceClassification as a baseline. To
evaluate the performance of the models, we use evaluation metrics like
accuracy, precision, and recall as well as micro, macro, and weighted F1 score.
We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1
outperforms two other generative models on 11 intent classes out of 14 in terms
of F-Score, with a weighted average of 0.50. It also has relatively lower
Humming Loss and higher Jaccard Similarity, making it the winning model in the
few-shot setting. We find BERT based supervised classifier having superior
performance compared to the best performing few-shot generative LLM. The study
provides a framework for small open-source LLMs in detecting complex
multi-intent dialogues, enhancing the Natural Language Understanding aspect of
task-oriented chatbots.

</details>


### [120] [Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models](https://arxiv.org/abs/2509.10078)
*Dongmin Choi,Woojung Song,Jongwook Han,Eun-Ju Lee,Yohan Jo*

Main category: cs.CL

TL;DR: 本文比较了用于测量大型语言模型（LLM）心理特征的传统问卷与生态有效问卷，发现传统问卷存在多方面问题，并建议谨慎使用。


<details>
  <summary>Details</summary>
Motivation: 研究人员已将人类心理测量问卷应用于LLM，但对其生态有效性存在担忧，即这些问卷是否能真实反映LLM在实际用户查询情境下的文本生成。目前尚不清楚传统问卷与生态有效问卷在结果上有何差异，以及这些差异能提供何种见解。

Method: 本文对两种类型的问卷（传统心理测量问卷和生态有效问卷）进行了全面的比较分析。

Result: 分析显示，传统问卷：(1) 得出的LLM画像与生态有效问卷显著不同，偏离了LLM在用户查询情境中表达的心理特征；(2) 缺乏足够的测量项目以实现稳定测量；(3) 错误地暗示LLM拥有稳定的心理结构；(4) 对于角色提示的LLM会产生夸大的画像。

Conclusion: 研究结果总体上警示不应将传统心理学问卷用于测量大型语言模型。

Abstract: Researchers have applied established psychometric questionnaires (e.g., BFI,
PVQ) to measure the personality traits and values reflected in the responses of
Large Language Models (LLMs). However, concerns have been raised about applying
these human-designed questionnaires to LLMs. One such concern is their lack of
ecological validity--the extent to which survey questions adequately reflect
and resemble real-world contexts in which LLMs generate texts in response to
user queries. However, it remains unclear how established questionnaires and
ecologically valid questionnaires differ in their outcomes, and what insights
these differences may provide. In this paper, we conduct a comprehensive
comparative analysis of the two types of questionnaires. Our analysis reveals
that established questionnaires (1) yield substantially different profiles of
LLMs from ecologically valid ones, deviating from the psychological
characteristics expressed in the context of user queries, (2) suffer from
insufficient items for stable measurement, (3) create misleading impressions
that LLMs possess stable constructs, and (4) yield exaggerated profiles for
persona-prompted LLMs. Overall, our work cautions against the use of
established psychological questionnaires for LLMs. Our code will be released
upon publication.

</details>


### [121] [Linguistic trajectories of bipolar disorder on social media](https://arxiv.org/abs/2509.10035)
*Laurin Plank,Armin Zlomuzica*

Main category: cs.CL

TL;DR: 该研究利用社交媒体语言分析了双相情感障碍（BD）患者在诊断前后长达24年的语言变化轨迹，发现广泛的语言改变反映了情绪障碍、共病和季节性情绪发作，验证了社交媒体在精神健康监测中的潜力。


<details>
  <summary>Details</summary>
Motivation: 语言是情感障碍（如双相情感障碍）的重要标志，但临床评估规模有限。社交媒体语言分析因其高时间分辨率和纵向范围而受到关注，可弥补临床评估的不足。

Method: 研究开发了一种确定用户诊断时间的方法，并将其应用于分析双相情感障碍用户在诊断前3年到诊断后21年的社交媒体语言轨迹。结果与单相抑郁症（UD）用户和未受影响的对照组（HC）用户进行了对比。

Result: 双相情感障碍诊断伴随着广泛的语言改变，反映了情绪障碍、精神共病、药物滥用、住院、躯体共病、异常思维内容和思维混乱。诊断后二十年内，观察到反复出现的情绪相关语言变化，具有明显的12个月周期性，提示季节性情绪发作。此外，趋势层面的证据表明，估计为女性的用户周期性增加。

Conclusion: 研究结果为双相情感障碍急性期和慢性期的语言改变提供了证据。这验证并扩展了利用社交媒体进行可扩展精神健康监测的现有努力。

Abstract: Language provides valuable markers of affective disorders such as bipolar
disorder (BD), yet clinical assessments remain limited in scale. In response,
analyses of social media (SM) language have gained prominence due to their high
temporal resolution and longitudinal scope. Here, we introduce a method to
determine the timing of users' diagnoses and apply it to study language
trajectories from 3 years before to 21 years after BD diagnosis - contrasted
with uses reporting unipolar depression (UD) and non-affected users (HC). We
show that BD diagnosis is accompanied by pervasive linguistic alterations
reflecting mood disturbance, psychiatric comorbidity, substance abuse,
hospitalization, medical comorbidities, unusual thought content, and
disorganized thought. We further observe recurring mood-related language
changes across two decades after the diagnosis, with a pronounced 12-month
periodicity suggestive of seasonal mood episodes. Finally, trend-level evidence
suggests an increased periodicity in users estimated to be female. In sum, our
findings provide evidence for language alterations in the acute and chronic
phase of BD. This validates and extends recent efforts leveraging SM for
scalable monitoring of mental health.

</details>


### [122] [!MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment](https://arxiv.org/abs/2509.10040)
*Mohamed Basem,Mohamed Younes,Seif Ahmed,Abdelrahman Moustafa*

Main category: cs.CL

TL;DR: 该论文介绍了MSA在BAREC 2025细粒度阿拉伯语可读性评估共享任务中获得六个赛道第一名的系统，该系统结合了多样化的Transformer模型、损失函数、数据增强和后处理技术。


<details>
  <summary>Details</summary>
Motivation: 参与BAREC 2025共享任务，解决细粒度阿拉伯语可读性评估中的严重类别不平衡和数据稀缺问题。

Method: 采用四种互补的Transformer模型（AraBERTv2, AraELECTRA, MARBERT, CAMeLBERT）的置信度加权集成，每种模型使用不同的损失函数进行微调。为解决数据问题，使用了加权训练、高级预处理、对SAMER语料库进行重新标注，并通过Gemini 2.5 Flash生成了约10,000个稀有级别的合成数据。此外，还应用了目标后处理步骤来纠正预测分布偏差。

Result: 在BAREC 2025共享任务的所有六个赛道中均获得第一名。在句子级别达到87.5%的二次加权Kappa (QWK)，在文档级别达到87.4%的QWK。后处理步骤带来了6.3%的QWK提升。

Conclusion: 该研究证明了模型和损失函数多样性、基于置信度的融合以及智能数据增强对于实现鲁棒的阿拉伯语可读性预测的强大作用。

Abstract: We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained
Arabic readability assessment, achieving first place in six of six tracks. Our
approach is a confidence-weighted ensemble of four complementary transformer
models (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with
distinct loss functions to capture diverse readability signals. To tackle
severe class imbalance and data scarcity, we applied weighted training,
advanced preprocessing, SAMER corpus relabeling with our strongest model, and
synthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level
samples. A targeted post-processing step corrected prediction distribution
skew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system
reached 87.5 percent QWK at the sentence level and 87.4 percent at the document
level, demonstrating the power of model and loss diversity, confidence-informed
fusion, and intelligent augmentation for robust Arabic readability prediction.

</details>


### [123] [Population-Aligned Persona Generation for LLM-based Social Simulation](https://arxiv.org/abs/2509.10127)
*Zhengyu Hu,Zheyuan Xiao,Max Xiong,Yuxuan Lei,Tianfu Wang,Jianxun Lian,Kaize Ding,Ziang Xiao,Nicholas Jing Yuan,Xing Xie*

Main category: cs.CL

TL;DR: 本文提出一个系统框架，用于为LLM驱动的社会模拟合成高质量、与人口分布对齐的角色集，以解决现有方法中角色生成复杂性和代表性不足的问题，从而显著减少偏差并提高模拟准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）使大规模社会模拟成为可能，但现有的LLM社会模拟研究主要关注代理框架和模拟环境设计，往往忽视角色生成（persona generation）的复杂性以及不具代表性的角色集可能引入的偏见。因此，需要一个能真实反映人口多样性和分布的角色集构建方法。

Method: 该方法首先利用LLMs从长期社交媒体数据生成叙事性角色；接着进行严格的质量评估以过滤低保真度档案；然后应用重要性抽样（importance sampling）实现与参考心理测量分布（如大五人格特质）的全局对齐；最后，引入一个任务特定模块，将全局对齐的角色集适应于目标子人群，以满足特定模拟情境的需求。

Result: 广泛的实验证明，该方法显著减少了人口层面的偏见，并能为广泛的研究和政策应用实现准确、灵活的社会模拟。

Conclusion: 该论文提出的系统框架成功解决了LLM驱动社会模拟中构建高质量、与人口对齐的角色集的关键挑战，从而能够进行更准确、更灵活的社会模拟。

Abstract: Recent advances in large language models (LLMs) have enabled human-like
social simulations at unprecedented scale and fidelity, offering new
opportunities for computational social science. A key challenge, however, is
the construction of persona sets that authentically represent the diversity and
distribution of real-world populations. Most existing LLM-based social
simulation studies focus primarily on designing agentic frameworks and
simulation environments, often overlooking the complexities of persona
generation and the potential biases introduced by unrepresentative persona
sets. In this paper, we propose a systematic framework for synthesizing
high-quality, population-aligned persona sets for LLM-driven social simulation.
Our approach begins by leveraging LLMs to generate narrative personas from
long-term social media data, followed by rigorous quality assessment to filter
out low-fidelity profiles. We then apply importance sampling to achieve global
alignment with reference psychometric distributions, such as the Big Five
personality traits. To address the needs of specific simulation contexts, we
further introduce a task-specific module that adapts the globally aligned
persona set to targeted subpopulations. Extensive experiments demonstrate that
our method significantly reduces population-level bias and enables accurate,
flexible social simulation for a wide range of research and policy
applications.

</details>


### [124] [Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery](https://arxiv.org/abs/2509.10087)
*Mustapha Adamu,Qi Zhang,Huitong Pan,Longin Jan Latecki,Eduard C. Dragut*

Main category: cs.CL

TL;DR: 该论文介绍了一个从气候科学文献构建的领域特定知识图谱（KG），旨在通过支持结构化语义查询，提高气候知识的获取和使用效率，并可与大型语言模型集成。


<details>
  <summary>Details</summary>
Motivation: 气候科学文献日益复杂和庞大，研究人员难以在模型、数据集、区域和变量等多个维度上找到相关信息。

Method: 构建了一个从气候出版物和更广泛科学文本中提取信息的领域特定知识图谱（KG）。通过Cypher查询演示了KG如何回答具体问题，并概述了其与大型语言模型（LLM）在RAG系统中的集成，以提高气候相关问答的透明度和可靠性。

Result: 该知识图谱支持结构化、语义化的查询，帮助研究人员发现精确的连接，例如哪些模型在特定区域经过验证，或哪些数据集常与某些遥相关模式一起使用。它能够改进气候相关问答的透明度和可靠性。

Conclusion: 这项工作超越了知识图谱的构建，展示了其对气候研究人员、模型开发者以及其他依赖准确、情境化科学信息的人的实际价值。

Abstract: The growing complexity and volume of climate science literature make it
increasingly difficult for researchers to find relevant information across
models, datasets, regions, and variables. This paper introduces a
domain-specific Knowledge Graph (KG) built from climate publications and
broader scientific texts, aimed at improving how climate knowledge is accessed
and used. Unlike keyword based search, our KG supports structured, semantic
queries that help researchers discover precise connections such as which models
have been validated in specific regions or which datasets are commonly used
with certain teleconnection patterns. We demonstrate how the KG answers such
questions using Cypher queries, and outline its integration with large language
models in RAG systems to improve transparency and reliability in
climate-related question answering. This work moves beyond KG construction to
show its real world value for climate researchers, model developers, and others
who rely on accurate, contextual scientific information.

</details>


### [125] [Benchmark of stylistic variation in LLM-generated texts](https://arxiv.org/abs/2509.10179)
*Jiří Milička,Anna Marklová,Václav Cvrček*

Main category: cs.CL

TL;DR: 本研究使用Biber的多维分析（MDA）方法，调查了人类和大型语言模型（LLM）生成的文本在语域变异方面的差异，并创建了一个模型评估基准。


<details>
  <summary>Details</summary>
Motivation: 了解LLM生成的文本在语域特征上与人类文本有何不同，特别是LLM在哪些维度上与人类存在最显著和最系统的差异，以及这些差异在不同语言（英语和捷克语）和不同模型类型（基础模型与指令调优模型）之间如何体现。

Method: 采用Biber的多维分析（MDA）方法；使用新的LLM生成语料库AI-Brown（与BE-21相当）进行英语文本分析；使用AI-Koditex语料库和捷克语多维模型进行捷克语文本分析；考察了16个前沿LLM（包括基础模型和指令调优模型），并使用了多种设置和提示；基于分析结果创建了一个模型比较和排序的基准。

Result: LLM在语域变异的某些维度上与人类文本存在最显著和最系统的差异；创建了一个可解释的基准，用于比较和评估不同LLM模型。

Conclusion: 该研究揭示了LLM生成文本在语域上与人类文本的系统性差异，并提供了一个有效工具来评估和排名LLM在生成具有特定语域特征文本方面的表现。

Abstract: This study investigates the register variation in texts written by humans and
comparable texts produced by large language models (LLMs). Biber's
multidimensional analysis (MDA) is applied to a sample of human-written texts
and AI-created texts generated to be their counterparts to find the dimensions
of variation in which LLMs differ most significantly and most systematically
from humans. As textual material, a new LLM-generated corpus AI-Brown is used,
which is comparable to BE-21 (a Brown family corpus representing contemporary
British English). Since all languages except English are underrepresented in
the training data of frontier LLMs, similar analysis is replicated on Czech
using AI-Koditex corpus and Czech multidimensional model. Examined were 16
frontier models in various settings and prompts, with emphasis placed on the
difference between base models and instruction-tuned models. Based on this, a
benchmark is created through which models can be compared with each other and
ranked in interpretable dimensions.

</details>


### [126] [Arabic Large Language Models for Medical Text Generation](https://arxiv.org/abs/2509.10095)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: 本研究通过微调大型语言模型（LLMs）以生成阿拉伯语医疗文本，旨在改进医院管理系统（HMS），提供准确的实时医疗建议，尤其针对非标准输入和代表性不足的语言。微调后的Mistral-7B模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有的医院管理系统在处理过度拥挤、资源有限和紧急医疗服务不足等挑战时效率低下。现有方法难以提供准确的实时医疗建议，尤其对于非标准输入和代表性不足的语言（如阿拉伯语）。

Method: 本研究提出一种通过微调大型语言模型（LLMs）来生成阿拉伯语医疗文本的方法。具体步骤包括：1. 收集来自社交媒体的独特数据集，包含患者与医生之间的真实医疗对话，并进行清洗和预处理以处理多种阿拉伯语方言。2. 微调最先进的生成模型，包括Mistral-7B-Instruct-v0.2、LLaMA-2-7B和GPT-2 Medium。

Result: 评估结果显示，微调后的Mistral-7B模型表现优于其他模型，在BERT得分的精确率、召回率和F1分数上分别达到68.5%、69.08%和68.5%。对比基准测试和定性评估证实了该系统能够对非正式输入生成连贯且相关的医疗回复。

Conclusion: 本研究强调了生成式人工智能在推进医院管理系统方面的潜力，为全球医疗挑战，特别是在语言和文化多样性环境中，提供了一个可扩展和适应性强的解决方案。

Abstract: Efficient hospital management systems (HMS) are critical worldwide to address
challenges such as overcrowding, limited resources, and poor availability of
urgent health care. Existing methods often lack the ability to provide
accurate, real-time medical advice, particularly for irregular inputs and
underrepresented languages. To overcome these limitations, this study proposes
an approach that fine-tunes large language models (LLMs) for Arabic medical
text generation. The system is designed to assist patients by providing
accurate medical advice, diagnoses, drug recommendations, and treatment plans
based on user input. The research methodology required the collection of a
unique dataset from social media platforms, capturing real-world medical
conversations between patients and doctors. The dataset, which includes patient
complaints together with medical advice, was properly cleaned and preprocessed
to account for multiple Arabic dialects. Fine-tuning state-of-the-art
generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2
Medium, optimized the system's ability to generate reliable medical text.
Results from evaluations indicate that the fine-tuned Mistral-7B model
outperformed the other models, achieving average BERT (Bidirectional Encoder
Representations from Transformers) Score values in precision, recall, and
F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative
benchmarking and qualitative assessments validate the system's ability to
produce coherent and relevant medical replies to informal input. This study
highlights the potential of generative artificial intelligence (AI) in
advancing HMS, offering a scalable and adaptable solution for global healthcare
challenges, especially in linguistically and culturally diverse environments.

</details>


### [127] [SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning](https://arxiv.org/abs/2509.10208)
*Shengqiang Fu*

Main category: cs.CL

TL;DR: 为解决大型语言模型（LLMs）在知识密集型任务中因知识冲突导致的不忠实响应问题，本文提出了一种名为SI FACT的自改进框架，该框架通过自指令机制自动生成对比学习数据，并利用对比调优来增强LLMs的上下文忠实性，显著提高了上下文召回率并降低了对内部记忆的依赖。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在知识密集型任务中常产生不忠实的响应，原因在于它们倾向于依赖内部参数化知识而非提供的上下文，即存在知识冲突。

Method: 本文提出了一个名为“Self Improving Faithfulness Aware Contrastive Tuning (SI FACT)”的自改进框架。该框架利用自指令机制，使基础LLM能够自动生成高质量、结构化的对比学习数据，包括锚点样本、语义等效的正样本以及模拟不忠实场景的负样本，从而大幅减少手动标注成本。随后，通过对比学习训练模型，使其在表示空间中将忠实响应拉近，将不忠实响应推远。

Result: 在知识冲突评估基准ECARE KRE和COSE KRE上的实验表明，基于Llama3 8B Instruct的SI FACT模型比最佳基线方法将上下文召回率提高了6.2%，同时显著降低了对内部记忆的依赖。

Conclusion: SI FACT在增强LLMs上下文忠实性方面表现出强大的有效性和高数据效率，为构建更主动、更值得信赖的语言模型提供了一条实用的途径。

Abstract: Large Language Models often generate unfaithful responses in knowledge
intensive tasks due to knowledge conflict,that is,a preference for relying on
internal parametric knowledge rather than the provided context.To address this
issue,we propose a novel self improving framework,Self Improving Faithfulness
Aware Contrastive Tuning.The framework uses a self instruct mechanism that
allows the base LLM to automatically generate high quality,structured
contrastive learning data,including anchor samples,semantically equivalent
positive samples,and negative samples simulating unfaithful scenarios.This
approach significantly reduces the cost of manual
annotation.Subsequently,contrastive learning is applied to train the
model,enabling it to pull faithful responses closer and push unfaithful
responses farther apart in the representation space.Experiments on knowledge
conflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT
model based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%
over the best baseline method,while significantly reducing dependence on
internal memory.The results indicate that SI FACT provides strong effectiveness
and high data efficiency in enhancing the contextual faithfulness of
LLMs,offering a practical pathway toward building more proactive and
trustworthy language models.

</details>


### [128] [Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records](https://arxiv.org/abs/2509.10108)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Khaled Shaban*

Main category: cs.CL

TL;DR: 本研究提出了一种可扩展的合成数据增强策略，将阿拉伯语医疗聊天机器人数据集从2万条扩展到10万条，显著提高了低资源医疗NLP领域LLM的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语医疗聊天机器人的开发受到大规模、高质量标注数据集稀缺的严重限制。尽管现有工作已编译了一个2万条社交媒体医患互动数据集，但模型的扩展性和泛化能力仍然有限。

Method: 研究提出了一种可扩展的合成数据增强策略，利用ChatGPT-4o和Gemini 2.5 Pro等先进生成式AI系统生成了8万条上下文相关且医学上连贯的合成问答对，并将其整合到现有数据集中，使训练语料库扩展到10万条记录。这些合成样本经过语义过滤和人工验证。随后，研究微调了包括Mistral-7B和AraGPT2在内的五种大型语言模型，并使用BERTScore指标和专家驱动的定性评估进行性能评估。为分析合成数据源的有效性，还进行了消融研究，独立比较了ChatGPT-4o和Gemini生成的数据。

Result: 结果显示，ChatGPT-4o生成的数据在所有模型上都持续带来更高的F1分数和更少的幻觉。总的来说，研究发现合成数据增强在提高低资源医疗NLP领域特定领域语言模型方面是可行的解决方案。

Conclusion: 合成数据增强是提高低资源医疗NLP领域特定领域语言模型的实用解决方案，为开发更具包容性、可扩展和准确的阿拉伯语医疗聊天机器人系统铺平了道路。

Abstract: The development of medical chatbots in Arabic is significantly constrained by
the scarcity of large-scale, high-quality annotated datasets. While prior
efforts compiled a dataset of 20,000 Arabic patient-doctor interactions from
social media to fine-tune large language models (LLMs), model scalability and
generalization remained limited. In this study, we propose a scalable synthetic
data augmentation strategy to expand the training corpus to 100,000 records.
Using advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated
80,000 contextually relevant and medically coherent synthetic question-answer
pairs grounded in the structure of the original dataset. These synthetic
samples were semantically filtered, manually validated, and integrated into the
training pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,
and evaluated their performance using BERTScore metrics and expert-driven
qualitative assessments. To further analyze the effectiveness of synthetic
sources, we conducted an ablation study comparing ChatGPT-4o and
Gemini-generated data independently. The results showed that ChatGPT-4o data
consistently led to higher F1-scores and fewer hallucinations across all
models. Overall, our findings demonstrate the viability of synthetic
augmentation as a practical solution for enhancing domain-specific language
models in-low resource medical NLP, paving the way for more inclusive,
scalable, and accurate Arabic healthcare chatbot systems.

</details>


### [129] [Prominence-aware automatic speech recognition for conversational speech](https://arxiv.org/abs/2509.10116)
*Julian Linke,Barbara Schuppler*

Main category: cs.CL

TL;DR: 本文研究了奥地利德语的重音感知自动语音识别（ASR），通过微调wav2vec2模型开发重音检测器，并将其集成到ASR系统中。结果显示，该方法能有效编码韵律信息并实现高重音检测准确率，但未提升ASR性能。


<details>
  <summary>Details</summary>
Motivation: 研究重音感知的ASR，以期在语言学研究和韵律感知对话系统中获得潜在应用。

Method: 首先，通过微调wav2vec2模型开发了词级重音检测器。然后，使用该检测器自动标注了大型语料库中的韵律重音。最后，基于这些标注训练了新的重音感知ASR系统，该系统能同时转录词语及其重音级别。

Result: 在识别词序列正确的语料中，重音检测准确率达到85.53%。与基线ASR系统相比，重音信息的整合并未改变ASR性能。研究表明，基于Transformer的模型可以有效编码韵律信息。

Conclusion: 该研究对韵律增强ASR做出了新颖贡献，表明Transformer模型能有效编码韵律信息，并为语言学研究和韵律感知对话系统提供了潜在应用。尽管ASR性能未提升，但重音检测的准确性及其集成方法仍具价值。

Abstract: This paper investigates prominence-aware automatic speech recognition (ASR)
by combining prominence detection and speech recognition for conversational
Austrian German. First, prominence detectors were developed by fine-tuning
wav2vec2 models to classify word-level prominence. The detector was then used
to automatically annotate prosodic prominence in a large corpus. Based on those
annotations, we trained novel prominence-aware ASR systems that simultaneously
transcribe words and their prominence levels. The integration of prominence
information did not change performance compared to our baseline ASR system,
while reaching a prominence detection accuracy of 85.53% for utterances where
the recognized word sequence was correct. This paper shows that
transformer-based models can effectively encode prosodic information and
represents a novel contribution to prosody-enhanced ASR, with potential
applications for linguistic research and prosody-informed dialogue systems.

</details>


### [130] [Towards Reliable and Interpretable Document Question Answering via VLMs](https://arxiv.org/abs/2509.10129)
*Alessio Chen,Simone Giovannini,Andrea Gemelli,Fabio Coppini,Simone Marinai*

Main category: cs.CL

TL;DR: 本文提出DocExplainerV0，一个即插即用的边界框预测模块，旨在解决视觉语言模型（VLMs）在文档理解中答案空间定位不准确的问题，从而提高可解释性和实际应用性。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs在文档理解和文本信息提取方面表现出色，但它们在文档中准确地定位答案（即空间接地）仍然是一个重大挑战，这限制了模型的可解释性和实际应用价值。

Method: 研究人员引入了DocExplainerV0，这是一个即插即用的边界框预测模块。它的设计理念是将答案生成与空间定位解耦，使其能够应用于现有的VLM，包括那些无法进行微调的专有系统。

Result: 通过系统评估，研究发现文本准确性与空间接地之间存在显著差距，即模型给出的正确答案往往缺乏可靠的定位。所建立的标准化框架突出了这些不足。

Conclusion: DocExplainerV0模块解决了VLM在文档理解中答案定位的难题，并提供了关于文本准确性和空间接地之间差距的量化见解。该研究建立了一个基准，为未来开发更具可解释性和鲁棒性的文档信息提取VLM指明了方向。

Abstract: Vision-Language Models (VLMs) have shown strong capabilities in document
understanding, particularly in identifying and extracting textual information
from complex documents. Despite this, accurately localizing answers within
documents remains a major challenge, limiting both interpretability and
real-world applicability. To address this, we introduce
\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that
decouples answer generation from spatial localization. This design makes it
applicable to existing VLMs, including proprietary systems where fine-tuning is
not feasible. Through systematic evaluation, we provide quantitative insights
into the gap between textual accuracy and spatial grounding, showing that
correct answers often lack reliable localization. Our standardized framework
highlights these shortcomings and establishes a benchmark for future research
toward more interpretable and robust document information extraction VLMs.

</details>


### [131] [Incongruent Positivity: When Miscalibrated Positivity Undermines Online Supportive Conversations](https://arxiv.org/abs/2509.10184)
*Leen Almajed,Abeer ALdayel*

Main category: cs.CL

TL;DR: 本文研究了在情感支持对话中，人类和LLM生成的不恰当积极回应（如轻视、最小化或不切实际的乐观）现象。通过分析Reddit对话和LLM生成的回应，发现LLM在高风险情境下更容易出现这种问题。研究还开发了检测该现象的分类器，强调了平衡积极情绪与情感认可的重要性。


<details>
  <summary>Details</summary>
Motivation: 在情感支持对话中，善意的积极回应有时会适得其反，导致被支持者感到被轻视、被最小化或过于乐观，尤其是在大型语言模型（LLM）生成的回应中，这种不协调的积极性（incongruent positivity）可能更普遍。研究旨在理解和解决这一问题，以构建更具情境感知和信任度的在线对话系统。

Method: 研究收集了Reddit上真实的用户-助手对话，并使用LLM为相同情境生成了额外回应。对话按情感强度分为“轻微”（关系紧张、一般建议）和“严重”（悲伤、焦虑）两类。为深入研究，还在具有强烈和微弱情感反应的数据集上对LLM进行了微调。此外，开发了一个弱监督多标签分类器集成（DeBERTa和MentalBERT）来检测不协调的积极性类型。

Result: 分析显示，LLM更容易表现出不切实际的积极性，通过轻视和最小化的语气，尤其是在高风险情境中。开发的弱监督多标签分类器集成（DeBERTa和MentalBERT）在检测“轻微”和“严重”两种关注类型中的不协调积极性方面表现出改进。

Conclusion: 研究结果表明，需要超越仅仅生成通用的积极回应，转而研究如何提供协调一致的支持，以平衡积极情感与情感认可。这种方法为使大型语言模型与在线支持对话中的情感预期保持一致提供了见解，为构建情境感知和信任维护的在线对话系统铺平了道路。

Abstract: In emotionally supportive conversations, well-intended positivity can
sometimes misfire, leading to responses that feel dismissive, minimizing, or
unrealistically optimistic. We examine this phenomenon of incongruent
positivity as miscalibrated expressions of positive support in both human and
LLM generated responses. To this end, we collected real user-assistant
dialogues from Reddit across a range of emotional intensities and generated
additional responses using large language models for the same context. We
categorize these conversations by intensity into two levels: Mild, which covers
relationship tension and general advice, and Severe, which covers grief and
anxiety conversations. This level of categorization enables a comparative
analysis of how supportive responses vary across lower and higher stakes
contexts. Our analysis reveals that LLMs are more prone to unrealistic
positivity through dismissive and minimizing tone, particularly in high-stakes
contexts. To further study the underlying dimensions of this phenomenon, we
finetune LLMs on datasets with strong and weak emotional reactions. Moreover,
we developed a weakly supervised multilabel classifier ensemble (DeBERTa and
MentalBERT) that shows improved detection of incongruent positivity types
across two sorts of concerns (Mild and Severe). Our findings shed light on the
need to move beyond merely generating generic positive responses and instead
study the congruent support measures to balance positive affect with emotional
acknowledgment. This approach offers insights into aligning large language
models with affective expectations in the online supportive dialogue, paving
the way toward context-aware and trust preserving online conversation systems.

</details>


### [132] [Beyond Token Limits: Assessing Language Model Performance on Long Text Classification](https://arxiv.org/abs/2509.10199)
*Miklós Sebők,Viktor Kovács,Martin Bánóczy,Daniel Møller Eriksen,Nathalie Neptune,Philippe Roussille*

Main category: cs.CL

TL;DR: 本研究评估了多种大型语言模型（包括Longformer、GPT-3.5、GPT-4等）在处理跨语言长文本多类别分类任务时的性能，发现专门为长文本设计的Longformer并无明显优势，而最佳开源模型表现优于GPT变体，并强调了类别支持度和内容重叠对长文本分类性能的重要性。


<details>
  <summary>Details</summary>
Motivation: 社会科学领域广泛使用的大型语言模型（如BERT、RoBERTa）在输入文本长度上存在限制（如512个token），这对于需要处理长文本的分类任务（如法律文件，可能长达数百页）是一个紧迫的问题，这些模型无法有效处理。

Method: 研究使用了XLM-RoBERTa、Longformer、GPT-3.5和GPT-4模型，在五种语言上进行了实验。任务是比较议程项目（Comparative Agendas Project）的多类别分类，该项目包含21个政策主题标签（从教育到医疗保健）。

Result: 实验结果显示，专门为处理长输入而预训练的Longformer模型没有表现出特别的优势。GPT变体与表现最佳的开源模型相比，后者略胜一筹。对类别层面因素的分析表明，在长文本输入上，特定类别之间的支持度（support）和实质内容重叠（substance overlaps）对性能至关重要。

Conclusion: 对于长文本分类任务，专门为长输入设计的模型（如Longformer）不一定比其他模型有优势。最佳开源模型在某些情况下可能优于GPT变体。在处理长文本时，类别之间的支持度和内容重叠是影响分类性能的关键因素。

Abstract: The most widely used large language models in the social sciences (such as
BERT, and its derivatives, e.g. RoBERTa) have a limitation on the input text
length that they can process to produce predictions. This is a particularly
pressing issue for some classification tasks, where the aim is to handle long
input texts. One such area deals with laws and draft laws (bills), which can
have a length of multiple hundred pages and, therefore, are not particularly
amenable for processing with models that can only handle e.g. 512 tokens. In
this paper, we show results from experiments covering 5 languages with
XLM-RoBERTa, Longformer, GPT-3.5, GPT-4 models for the multiclass
classification task of the Comparative Agendas Project, which has a codebook of
21 policy topic labels from education to health care. Results show no
particular advantage for the Longformer model, pre-trained specifically for the
purposes of handling long inputs. The comparison between the GPT variants and
the best-performing open model yielded an edge for the latter. An analysis of
class-level factors points to the importance of support and substance overlaps
between specific categories when it comes to performance on long text inputs.

</details>


### [133] [Dropping Experts, Recombining Neurons: Retraining-Free Pruning for Sparse Mixture-of-Experts LLMs](https://arxiv.org/abs/2509.10377)
*Yixiao Zhou,Ziyu Zhao,Dongzhou Cheng,zhiliang wu,Jie Gui,Yi Yang,Fei Wu,Yu Cheng,Hehe Fan*

Main category: cs.CL

TL;DR: 稀疏专家混合模型（SMoE）在大型语言模型中因内存占用高而部署困难。DERN提出了一种无需再训练的框架，通过修剪冗余专家并在神经元层面重组，显著减少了内存占用，并在多项基准测试中提升了性能。


<details>
  <summary>Details</summary>
Motivation: SMoE架构在大型语言模型中因计算效率高而被广泛使用，但其需要加载所有专家参数，导致内存占用高和部署困难。现有方法主要集中在专家层面的操作，对神经元层面的结构探索不足。

Method: DERN（Dropping Experts, Recombining Neurons）是一个任务无关、无需再训练的专家修剪和重建框架，分为三步：1. 利用路由统计数据修剪冗余专家；2. 将修剪后的专家分解为神经元级别的专家片段，并将每个片段分配给最兼容的保留专家；3. 在每个保留专家内部合并这些片段以构建紧凑的表示。

Result: 在Mixtral、Qwen和DeepSeek SMoE模型上，DERN在50%专家稀疏度下，无需额外训练，将常识推理和MMLU基准测试的性能提高了5%以上。它还大大减少了专家数量和内存使用，使SMoE大型语言模型在实践中更容易部署。

Conclusion: DERN通过修剪冗余专家和智能重组神经元，有效解决了SMoE大型语言模型的高内存占用和部署挑战，在不进行额外训练的情况下，实现了性能提升和效率优化。

Abstract: Sparse Mixture-of-Experts (SMoE) architectures are widely used in large
language models (LLMs) due to their computational efficiency. However, though
only a few experts are activated for each token, SMoE still requires loading
all expert parameters, leading to high memory usage and challenges in
deployment. Previous work has tried to reduce the overhead by pruning and
merging experts, but primarily focused on expert-level operations, leaving
neuron-level structure underexplored. We propose DERN (Dropping Experts,
Recombining Neurons), a task-agnostic and retraining-free framework for expert
pruning and reconstruction. We observe that experts are often misaligned and
contain semantic conflicts at the neuron level, which poses challenges for
direct merging. To solve this, DERN works in three steps: it first prunes
redundant experts using router statistics; then it decomposes them into
neuron-level expert segments, assigning each segment to its most compatible
retained expert; and finally, it merges segments within each retained expert to
build a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE
models show that DERN improves performance by more than 5% on commonsense
reasoning and MMLU benchmarks under 50% expert sparsity, without extra
training. It also greatly reduces the number of experts and memory usage,
making SMoE LLMs easier to deploy in practice.

</details>


### [134] [Is In-Context Learning Learning?](https://arxiv.org/abs/2509.10414)
*Adrian de Wynter*

Main category: cs.CL

TL;DR: 本文认为上下文学习（ICL）在数学上构成学习，但通过大规模实证分析发现其在学习和泛化到未见任务方面存在局限性，且其效果更多依赖于提示中的规律性而非鲁棒的编码机制。


<details>
  <summary>Details</summary>
Motivation: 自回归模型通过上下文学习（ICL）无需额外训练即可解决任务，被宣称能以少量示例学习未见任务。然而，ICL不显式编码观测值，其能力是“学习”还是“推导”存在争议，这促使作者对ICL的本质及其泛化能力进行深入探究。

Method: 首先，从数学角度论证ICL构成学习。然后，进行大规模实证分析，通过消融或考虑记忆、预训练、分布偏移以及提示风格和措辞等因素，全面评估ICL的表现。

Result: 研究发现ICL是一种有效的学习范式，但在学习和泛化到未见任务方面存在局限性。当示例数量充足时，准确性对示例分布、模型、提示风格和输入语言特征不敏感，而是从提示中的规律性推导模式。这导致了对分布的敏感性，尤其是在思维链等提示风格中。此外，在形式相似的任务上表现出不同的准确性。

Conclusion: 自回归模型的即兴编码机制不够鲁棒，表明其通用泛化能力有限。尽管ICL在数学上是学习，但其在泛化到未见任务方面的能力受限，且其有效性高度依赖于提示中的规律性，而非普适的鲁棒机制。

Abstract: In-context learning (ICL) allows some autoregressive models to solve tasks
via next-token prediction and without needing further training. This has led to
claims about these model's ability to solve (learn) unseen tasks with only a
few shots (exemplars) in the prompt. However, deduction does not always imply
learning, as ICL does not explicitly encode a given observation. Instead, the
models rely on their prior knowledge and the exemplars given, if any. We argue
that, mathematically, ICL does constitute learning, but its full
characterisation requires empirical work. We then carry out a large-scale
analysis of ICL ablating out or accounting for memorisation, pretraining,
distributional shifts, and prompting style and phrasing. We find that ICL is an
effective learning paradigm, but limited in its ability to learn and generalise
to unseen tasks. We note that, in the limit where exemplars become more
numerous, accuracy is insensitive to exemplar distribution, model, prompt
style, and the input's linguistic features. Instead, it deduces patterns from
regularities in the prompt, which leads to distributional sensitivity,
especially in prompting styles such as chain-of-thought. Given the varied
accuracies on formally similar tasks, we conclude that autoregression's ad-hoc
encoding is not a robust mechanism, and suggests limited all-purpose
generalisability.

</details>


### [135] [Long Context Automated Essay Scoring with Language Models](https://arxiv.org/abs/2509.10417)
*Christopher Ormerod,Gitit Kehat*

Main category: cs.CL

TL;DR: 针对Transformer模型处理长文本（如学生作文）时的固定长度限制，本研究评估了多种通过修改架构来克服这一限制的模型，以提高自动作文评分的有效性，避免因截断文本而损害对组织结构元素的评估。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在处理长文本时有固定长度限制，导致在自动作文评分中需要截断输入。这种截断会严重损害模型评估作文评分标准中需要长上下文的组织结构元素的能力，从而引发有效性问题。

Method: 本研究评估了多种对标准Transformer架构进行修改以克服长度限制的模型。这些模型包括经过微调的XLNet、Longformer、ModernBERT、Mamba和Llama模型。研究使用了Kaggle ASAP 2.0数据集进行评估。

Result: 抽象中未提供具体的实验结果。

Conclusion: 抽象中未提供具体的结论。

Abstract: Transformer-based language models are architecturally constrained to process
text of a fixed maximum length. Essays written by higher-grade students
frequently exceed the maximum allowed length for many popular open-source
models. A common approach to addressing this issue when using these models for
Automated Essay Scoring is to truncate the input text. This raises serious
validity concerns as it undermines the model's ability to fully capture and
evaluate organizational elements of the scoring rubric, which requires long
contexts to assess. In this study, we evaluate several models that incorporate
architectural modifications of the standard transformer architecture to
overcome these length limitations using the Kaggle ASAP 2.0 dataset. The models
considered in this study include fine-tuned versions of XLNet, Longformer,
ModernBERT, Mamba, and Llama models.

</details>


### [136] [RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment](https://arxiv.org/abs/2509.10436)
*Shadikur Rahman,Aroosa Hameed,Gautam Srivastava,Syed Muhammad Danish*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的云边协同多智能体架构，旨在优化大型语言模型（LLM）的推理和问题解决能力。该架构包含GuideLLM、SolverLLM和JudgeLLM三个组件，并引入了RefactorCoderQA基准。通过实验，RefactorCoder-MoE模型在多领域编码任务上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了优化大型语言模型（LLM）的推理和问题解决能力，并解决现有基准的局限性。

Method: 本文提出了一种云边协同架构，该架构包含一个结构化的多智能体提示框架：边缘部署的轻量级GuideLLM提供方法论指导；云端强大的SolverLLM负责生成代码解决方案；以及用于评估解决方案正确性和质量的自动化JudgeLLM。此外，引入了RefactorCoderQA基准，用于评估和增强LLM在软件工程、数据科学、机器学习和自然语言处理等多领域编码任务中的性能。通过对RefactorCoder-MoE模型进行微调，并评估系统级指标（如吞吐量和延迟）来深入了解架构的性能特征。

Result: 微调后的RefactorCoder-MoE模型实现了76.84%的总体准确率，显著超越了领先的开源和商业基线，达到了最先进的性能。人工评估进一步验证了生成解决方案的可解释性、准确性和实用相关性。系统级指标评估提供了对所提出架构性能特征和权衡的深入见解。

Conclusion: 所提出的云边协同多智能体架构及其RefactorCoder-MoE模型有效增强了LLM在编码任务中的推理和问题解决能力，实现了最先进的性能，并具有实际相关性。

Abstract: To optimize the reasoning and problem-solving capabilities of Large Language
Models (LLMs), we propose a novel cloud-edge collaborative architecture that
enables a structured, multi-agent prompting framework. This framework comprises
three specialized components: GuideLLM, a lightweight model deployed at the
edge to provide methodological guidance; SolverLLM, a more powerful model
hosted in the cloud responsible for generating code solutions; and JudgeLLM, an
automated evaluator for assessing solution correctness and quality. To evaluate
and demonstrate the effectiveness of this architecture in realistic settings,
we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate
and enhance the performance of Large Language Models (LLMs) across multi-domain
coding tasks. Motivated by the limitations of existing benchmarks,
RefactorCoderQA systematically covers various technical domains, including
Software Engineering, Data Science, Machine Learning, and Natural Language
Processing, using authentic coding challenges from Stack Overflow. Extensive
experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves
state-of-the-art performance, significantly outperforming leading open-source
and commercial baselines with an overall accuracy of 76.84%. Human evaluations
further validate the interpretability, accuracy, and practical relevance of the
generated solutions. In addition, we evaluate system-level metrics, such as
throughput and latency, to gain deeper insights into the performance
characteristics and trade-offs of the proposed architecture.

</details>


### [137] [DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL](https://arxiv.org/abs/2509.10446)
*Rui Lu,Zhenyu Hou,Zihan Wang,Hanchen Zhang,Xiao Liu,Yujiang Li,Shi Feng,Jie Tang,Yuxiao Dong*

Main category: cs.CL

TL;DR: DeepDive通过自动生成复杂问题和多轮强化学习，显著提升了大型语言模型作为深度搜索代理的能力，并在BrowseComp等基准测试中取得了领先的开源性能。


<details>
  <summary>Details</summary>
Motivation: 开放式大型语言模型（LLMs）在结合浏览工具进行深度搜索时表现不佳，原因在于其长周期推理能力有限，且缺乏足够难度高的监督数据。

Method: ['提出一种策略，从开放知识图谱中自动合成复杂、困难且难以找到的问题。', '应用端到端多轮强化学习（RL）来增强LLMs在深度搜索中的长周期推理能力。']

Result: ['DeepDive-32B在BrowseComp上取得了新的开源竞争性结果，超越了WebSailor、DeepSeek-R1-Browse和Search-o1。', '多轮强化学习训练显著提高了深度搜索能力，并对多个基准测试的性能改进做出了贡献。', 'DeepDive支持测试时工具调用和并行采样的扩展。']

Conclusion: DeepDive通过解决数据稀缺和推理能力限制，极大地推进了深度搜索代理的发展，并展示了通过问题合成和多轮强化学习实现最先进开源性能的有效性。

Abstract: Augmenting large language models (LLMs) with browsing tools substantially
improves their potential as deep search agents to solve complex, real-world
tasks. Yet, open LLMs still perform poorly in such settings due to limited
long-horizon reasoning capacity with browsing tools and the lack of
sufficiently difficult supervised data. To address these challenges, we present
DeepDive to advance deep search agents. First, we propose a strategy to
automatically synthesize complex, difficult, and hard-to-find questions from
open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement
learning (RL) to enhance LLMs' long-horizon reasoning with deep search.
Experiments show that DeepDive-32B achieves a new open-source competitive
result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and
Search-o1. We demonstrate that multi-turn RL training improves deep search
ability and significantly contributes to the performance improvements across
multiple benchmarks. We observe that DeepDive enables test-time scaling of tool
calls and parallel sampling. All datasets, models, and code are publicly
available at https://github.com/THUDM/DeepDive.

</details>


### [138] [WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers](https://arxiv.org/abs/2509.10452)
*Akshat Pandey,Karun Kumar,Raphael Tang*

Main category: cs.CL

TL;DR: WhisTLE是一种深度监督的纯文本域适应方法，用于预训练的ASR模型，通过训练VAE从文本建模编码器输出并微调解码器，显著降低了域外数据集的词错误率。


<details>
  <summary>Details</summary>
Motivation: 预训练的ASR模型（如Whisper）在处理未见词汇和口语时仍需域适应，但在许多实际场景中收集语音数据不切实际，因此需要纯文本的适应方法。

Method: 提出WhisTLE方法，它是一种深度监督的纯文本域适应方法，用于预训练的编码器-解码器ASR模型。该方法训练一个变分自编码器（VAE）来从文本建模编码器输出，并使用学习到的文本到潜在编码器微调解码器，可选地结合文本到语音（TTS）适应。推理时恢复原始编码器，不增加运行时成本。

Result: 在四个域外数据集和四个ASR模型上，结合TTS的WhisTLE相对于仅使用TTS的适应方法，相对降低了12.3%的词错误率（WER），并在32个场景中的27个中优于所有非WhisTLE基线方法。

Conclusion: WhisTLE是一种有效的纯文本域适应方法，能够显著提高预训练ASR模型在未见域上的性能，且不增加推理成本。

Abstract: Pretrained automatic speech recognition (ASR) models such as Whisper perform
well but still need domain adaptation to handle unseen vocabulary and parlance.
In many real-world settings, collecting speech data is impractical,
necessitating text-only adaptation. We propose WhisTLE, a deeply supervised,
text-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE
trains a variational autoencoder (VAE) to model encoder outputs from text and
fine-tunes the decoder using the learned text-to-latent encoder, optionally
combined with text-to-speech (TTS) adaptation. At inference, the original
encoder is restored, incurring no extra runtime cost. Across four out-of-domain
datasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by
12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines
in 27 of 32 scenarios.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [139] [MimicDroid: In-Context Learning for Humanoid Robot Manipulation from Human Play Videos](https://arxiv.org/abs/2509.09769)
*Rutav Shah,Shuijing Liu,Qi Wang,Zhenyu Jiang,Sateesh Kumar,Mingyo Seo,Roberto Martín-Martín,Yuke Zhu*

Main category: cs.RO

TL;DR: MimicDroid使人形机器人能够利用人类自由玩耍视频（而非昂贵的遥操作数据）进行上下文学习，从而高效解决新的操作任务，并展现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有上下文学习（ICL）方法依赖于耗时费力的遥操作数据进行训练，限制了其可扩展性。研究旨在使人形机器人能从少量视频示例中高效学习并解决新的操作任务。

Method: 提出MimicDroid框架，以人类自由玩耍视频作为唯一训练数据源。MimicDroid通过提取具有相似操作行为的轨迹对，训练策略以在给定一条轨迹的条件下预测另一条轨迹的动作。为弥合具身差距，它将从RGB视频中估计的人类手腕姿态重定向到人形机器人，并应用随机补丁遮蔽以减少对人类特定线索的过拟合，提高视觉差异下的鲁棒性。同时，引入了一个开源仿真基准来评估少样本学习能力。

Result: MimicDroid在测试时获得了适应新物体和环境的ICL能力。在仿真中超越了现有最先进方法，并在真实世界中实现了近两倍的成功率。

Conclusion: MimicDroid证明了利用人类自由玩耍视频作为训练数据，可以有效赋予人形机器人上下文学习能力，使其能够从少量示例中高效解决新的操作任务，并展现出卓越的泛化性能。

Abstract: We aim to enable humanoid robots to efficiently solve new manipulation tasks
from a few video examples. In-context learning (ICL) is a promising framework
for achieving this goal due to its test-time data efficiency and rapid
adaptability. However, current ICL methods rely on labor-intensive teleoperated
data for training, which restricts scalability. We propose using human play
videos -- continuous, unlabeled videos of people interacting freely with their
environment -- as a scalable and diverse training data source. We introduce
MimicDroid, which enables humanoids to perform ICL using human play videos as
the only training data. MimicDroid extracts trajectory pairs with similar
manipulation behaviors and trains the policy to predict the actions of one
trajectory conditioned on the other. Through this process, the model acquired
ICL capabilities for adapting to novel objects and environments at test time.
To bridge the embodiment gap, MimicDroid first retargets human wrist poses
estimated from RGB videos to the humanoid, leveraging kinematic similarity. It
also applies random patch masking during training to reduce overfitting to
human-specific cues and improve robustness to visual differences. To evaluate
few-shot learning for humanoids, we introduce an open-source simulation
benchmark with increasing levels of generalization difficulty. MimicDroid
outperformed state-of-the-art methods and achieved nearly twofold higher
success rates in the real world. Additional materials can be found on:
ut-austin-rpl.github.io/MimicDroid

</details>


### [140] [MIMo grows! Simulating body and sensory development in a multimodal infant model](https://arxiv.org/abs/2509.09805)
*Francisco M. López,Miles Lenz,Marco G. Fedozzi,Arthur Aubret,Jochen Triesch*

Main category: cs.RO

TL;DR: MIMo v2是一个新的多模态婴儿模型，具有随年龄增长的身体、力量、视力以及感觉运动延迟，旨在提高对婴儿感觉运动发展的建模真实性。


<details>
  <summary>Details</summary>
Motivation: 现有开发机器人和仿真平台通常针对特定年龄设计，限制了它们捕捉婴儿不断变化的能力和约束，无法真实反映婴儿期的快速身体成长和感觉运动能力的爆炸性变化。

Method: MIMo v2模型包含一个从出生到24个月的生长身体，其驱动强度随年龄增加。它还具有发展中视力的中央凹视觉，以及模拟信号传输速度有限的感觉运动延迟。此外，该版本还增强了逆运动学模块、随机环境生成器，并更新了与第三方仿真和学习库的兼容性。

Result: 新版本的MIMo模型允许在建模感觉运动发展的各个方面时获得更高的真实感。

Conclusion: MIMo v2通过整合生长身体、发展视力、感觉运动延迟等特性，显著提高了对婴儿感觉运动发展的建模真实性，解决了现有平台无法捕捉婴儿不断变化的能力和约束的问题。

Abstract: Infancy is characterized by rapid body growth and an explosive change of
sensory and motor abilities. However, developmental robots and simulation
platforms are typically designed in the image of a specific age, which limits
their ability to capture the changing abilities and constraints of developing
infants. To address this issue, we present MIMo v2, a new version of the
multimodal infant model. It includes a growing body with increasing actuation
strength covering the age range from birth to 24 months. It also features
foveated vision with developing visual acuity as well as sensorimotor delays
modeling finite signal transmission speeds to and from an infant's brain.
Further enhancements of this MIMo version include an inverse kinematics module,
a random environment generator and updated compatiblity with third-party
simulation and learning libraries. Overall, this new MIMo version permits
increased realism when modeling various aspects of sensorimotor development.
The code is available on the official repository
(https://github.com/trieschlab/MIMo).

</details>


### [141] [Using the Pepper Robot to Support Sign Language Communication](https://arxiv.org/abs/2509.09889)
*Giulia Botta,Marco Botta,Cristina Gena,Alessandro Mazzei,Massimo Donini,Alberto Lillo*

Main category: cs.RO

TL;DR: 本研究探讨了Pepper社交机器人生成意大利手语（LIS）手势和短句的可行性。结果显示，孤立手势可被识别，但完整句子的识别率较低，表明商用机器人有望实现更具包容性的人机交互。


<details>
  <summary>Details</summary>
Motivation: 社交机器人在公共和辅助环境中日益普及，但其对聋人用户的可访问性研究不足。意大利手语（LIS）是一种完整的自然语言，使机器人能够使用LIS进行交流可以促进更具包容性的人机交互，尤其是在医院、机场或教育等社会环境中。

Method: 与一名聋人学生及其LIS专家口译员合作，共同设计并实现了52个LIS手势在Pepper机器人上，使用了手动动画技术或基于MATLAB的逆运动学求解器。进行了一项探索性用户研究，涉及12名精通LIS的参与者（包括聋人和听力正常者）。参与者完成了一份问卷，包含15个基于视频的单选手势识别任务和2个关于短手语句子的开放式问题。

Result: 结果表明，大多数孤立手势被正确识别，但由于Pepper机器人的有限关节活动和时间限制，完整句子的识别率显著降低。研究发现，即使是Pepper这样的商用社交机器人也能清晰地执行部分LIS手势。

Conclusion: 本研究证明，商用社交机器人能够以可理解的方式执行部分LIS手势，为更具包容性的交互设计提供了机会。未来的发展应解决多模态增强（例如，基于屏幕的支持或富有表现力的虚拟形象）问题，并让聋人用户参与到参与式设计中，以完善机器人的表达能力和可用性。

Abstract: Social robots are increasingly experimented in public and assistive settings,
but their accessibility for Deaf users remains quite underexplored. Italian
Sign Language (LIS) is a fully-fledged natural language that relies on complex
manual and non-manual components. Enabling robots to communicate using LIS
could foster more inclusive human robot interaction, especially in social
environments such as hospitals, airports, or educational settings. This study
investigates whether a commercial social robot, Pepper, can produce
intelligible LIS signs and short signed LIS sentences. With the help of a Deaf
student and his interpreter, an expert in LIS, we co-designed and implemented
52 LIS signs on Pepper using either manual animation techniques or a MATLAB
based inverse kinematics solver. We conducted a exploratory user study
involving 12 participants proficient in LIS, both Deaf and hearing.
Participants completed a questionnaire featuring 15 single-choice video-based
sign recognition tasks and 2 open-ended questions on short signed sentences.
Results shows that the majority of isolated signs were recognized correctly,
although full sentence recognition was significantly lower due to Pepper's
limited articulation and temporal constraints. Our findings demonstrate that
even commercially available social robots like Pepper can perform a subset of
LIS signs intelligibly, offering some opportunities for a more inclusive
interaction design. Future developments should address multi-modal enhancements
(e.g., screen-based support or expressive avatars) and involve Deaf users in
participatory design to refine robot expressivity and usability.

</details>


### [142] [Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe Self-augmentation with Demonstrator-annotated Precision](https://arxiv.org/abs/2509.09893)
*Hanbit Oh,Masaki Murooka,Tomohiro Motoda,Ryoichi Nakajo,Yukiyasu Domae*

Main category: cs.RO

TL;DR: SART是一种模仿学习框架，通过单次人类演示和机器人自主安全数据增强，显著提高了机器人策略的学习效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 标准的模仿学习需要大量数据（演示或探索），而探索缺乏安全保障，常导致碰撞，特别是在精细操作任务中，这需要人工重置环境，增加了人类负担。

Method: SART框架分为两个阶段：1) 人类教学一次：提供一次演示，并标注关键路径点周围的精度边界（球体），然后进行一次环境重置。2) 机器人自主增强：机器人在这些边界内生成多样化、无碰撞的轨迹，并重新连接到原始演示。

Result: 在仿真和真实世界的操作任务中，SART实现了比仅使用人类收集演示训练的策略显著更高的成功率。

Conclusion: SART通过最小化人类工作量和确保安全性，提高了数据收集效率，从而实现了从单次演示中学习策略，并取得了更好的性能。

Abstract: Imitation learning is a promising paradigm for training robot agents;
however, standard approaches typically require substantial data acquisition --
via numerous demonstrations or random exploration -- to ensure reliable
performance. Although exploration reduces human effort, it lacks safety
guarantees and often results in frequent collisions -- particularly in
clearance-limited tasks (e.g., peg-in-hole) -- thereby, necessitating manual
environmental resets and imposing additional human burden. This study proposes
Self-Augmented Robot Trajectory (SART), a framework that enables policy
learning from a single human demonstration, while safely expanding the dataset
through autonomous augmentation. SART consists of two stages: (1) human
teaching only once, where a single demonstration is provided and precision
boundaries -- represented as spheres around key waypoints -- are annotated,
followed by one environment reset; (2) robot self-augmentation, where the robot
generates diverse, collision-free trajectories within these boundaries and
reconnects to the original demonstration. This design improves the data
collection efficiency by minimizing human effort while ensuring safety.
Extensive evaluations in simulation and real-world manipulation tasks show that
SART achieves substantially higher success rates than policies trained solely
on human-collected demonstrations. Video results available at
https://sites.google.com/view/sart-il .

</details>


### [143] [Detection of Anomalous Behavior in Robot Systems Based on Machine Learning](https://arxiv.org/abs/2509.09953)
*Mahfuzul I. Nissan,Sharmin Aktar*

Main category: cs.RO

TL;DR: 本研究提出一种基于机器学习的方法，通过分析系统日志来检测机器人系统中的异常，以提高其安全性和可靠性。在两种不同的机器人场景中比较了多种模型，发现最佳模型选择取决于具体情境，其中自编码器在检测复杂异常方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 确保机器人系统的安全可靠运行至关重要，以防止潜在灾难并保障人类福祉。尽管有严格的设计和工程实践，这些系统仍可能发生故障，导致安全风险。

Method: 采用基于机器学习的方法检测系统日志中的异常。使用CoppeliaSim从四旋翼飞行器（情境1）和Pioneer机器人（情境2）两种不同场景收集日志。比较评估了多种机器学习模型，包括逻辑回归（LR）、支持向量机（SVM）和自编码器。

Result: 结果显示，逻辑回归在情境1中表现优异，而自编码器模型在情境2中最为有效。这表明最佳模型选择是情境依赖的，可能因为不同机器人平台的异常复杂性各异。

Conclusion: 本研究强调了比较方法的价值，并证明了自编码器在检测机器人系统中复杂异常方面的特殊优势。

Abstract: Ensuring the safe and reliable operation of robotic systems is paramount to
prevent potential disasters and safeguard human well-being. Despite rigorous
design and engineering practices, these systems can still experience
malfunctions, leading to safety risks. In this study, we present a machine
learning-based approach for detecting anomalies in system logs to enhance the
safety and reliability of robotic systems. We collected logs from two distinct
scenarios using CoppeliaSim and comparatively evaluated several machine
learning models, including Logistic Regression (LR), Support Vector Machine
(SVM), and an Autoencoder. Our system was evaluated in a quadcopter context
(Context 1) and a Pioneer robot context (Context 2). Results showed that while
LR demonstrated superior performance in Context 1, the Autoencoder model proved
to be the most effective in Context 2. This highlights that the optimal model
choice is context-dependent, likely due to the varying complexity of anomalies
across different robotic platforms. This research underscores the value of a
comparative approach and demonstrates the particular strengths of autoencoders
for detecting complex anomalies in robotic systems.

</details>


### [144] [Gaussian path model library for intuitive robot motion programming by demonstration](https://arxiv.org/abs/2509.10007)
*Samuli Soutukorva,Markku Suomalainen,Martin Kollingbaum,Tapio Heikkilä*

Main category: cs.RO

TL;DR: 本文提出了一种从示教数据生成高斯路径模型并用于分类人类路径演示的系统，同时介绍了通过几何分析修改现有模型的方法，旨在实现直观的机器人运动编程。


<details>
  <summary>Details</summary>
Motivation: 研究动机是希望通过人类演示实现直观的机器人运动编程，使机器人能学习并适应不同的路径形状。

Method: 该研究的方法包括：1) 从代表路径形状的示教数据生成高斯路径模型；2) 利用这些模型对人类路径演示进行分类；3) 构建一个包含多种形状高斯路径模型的库；4) 通过几何分析和演示来修改现有高斯路径模型。

Result: 研究结果是一个能够从示教数据生成高斯路径模型、利用这些模型分类人类路径演示，并通过演示和几何分析修改现有模型的系统，从而实现了通过人类演示进行直观机器人运动编程。

Conclusion: 该系统通过生成、分类和修改高斯路径模型，为机器人运动编程提供了一种直观且灵活的方法，能够根据人类演示学习和适应不同的路径形状。

Abstract: This paper presents a system for generating Gaussian path models from
teaching data representing the path shape. In addition, methods for using these
path models to classify human demonstrations of paths are introduced. By
generating a library of multiple Gaussian path models of various shapes, human
demonstrations can be used for intuitive robot motion programming. A method for
modifying existing Gaussian path models by demonstration through geometric
analysis is also presented.

</details>


### [145] [Towards simulation-based optimization of compliant fingers for high-speed connector assembly](https://arxiv.org/abs/2509.10012)
*Richard Matthias Hartisch,Alexander Rother,Jörg Krüger,Kevin Haninger*

Main category: cs.RO

TL;DR: 本文提出了一种基于仿真的柔顺机构设计工具，用于优化柔顺手指的设计参数，以提高插入任务在公差范围内的成功率和鲁棒性，并通过真实机器人实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 机械柔顺性是动态接触式操作的关键设计参数，影响任务成功率和对接触几何变化的鲁棒性。目前，柔性机器人结构的设计参数选择依赖耗时的硬件迭代或简化的模型，无法有效处理复杂的操纵任务目标。动态仿真（特别是接触和摩擦建模）的进步为机械柔顺性设计提供了潜在工具。

Method: 研究者提出了一种基于仿真的柔顺机构设计工具，允许根据任务级别目标（如成功率）进行设计。该工具被应用于优化结构化柔顺手指的设计参数，以减少插入任务在公差窗口内的失败情况。优化后的鲁棒性通过在真实机器人上使用NIST任务板的基准任务进行验证。

Result: 优化后的参数可以将可容忍范围提高2.29倍，补偿高达8.6毫米的工件变化。然而，趋势是任务特定的：在某些任务中，最高刚度产生最宽的可容忍范围，而在其他任务中则观察到相反的情况。

Conclusion: 基于仿真的设计工具能够有效优化柔顺机构以满足任务级别目标，显著提高鲁棒性。由于最佳柔顺性是任务特定的，因此需要能够考虑应用特定几何形状和动态特性的设计工具。

Abstract: Mechanical compliance is a key design parameter for dynamic contact-rich
manipulation, affecting task success and safety robustness over contact
geometry variation. Design of soft robotic structures, such as compliant
fingers, requires choosing design parameters which affect geometry and
stiffness, and therefore manipulation performance and robustness. Today, these
parameters are chosen through either hardware iteration, which takes
significant development time, or simplified models (e.g. planar), which can't
address complex manipulation task objectives. Improvements in dynamic
simulation, especially with contact and friction modeling, present a potential
design tool for mechanical compliance. We propose a simulation-based design
tool for compliant mechanisms which allows design with respect to task-level
objectives, such as success rate. This is applied to optimize design parameters
of a structured compliant finger to reduce failure cases inside a tolerance
window in insertion tasks. The improvement in robustness is then validated on a
real robot using tasks from the benchmark NIST task board. The finger stiffness
affects the tolerance window: optimized parameters can increase tolerable
ranges by a factor of 2.29, with workpiece variation up to 8.6 mm being
compensated. However, the trends remain task-specific. In some tasks, the
highest stiffness yields the widest tolerable range, whereas in others the
opposite is observed, motivating need for design tools which can consider
application-specific geometry and dynamics.

</details>


### [146] [Design and Evaluation of Two Spherical Systems for Mobile 3D Mapping](https://arxiv.org/abs/2509.10032)
*Marawan Khalil,Fabian Arzberger,Andreas Nüchter*

Main category: cs.RO

TL;DR: 本文提出了两种球形机器人测绘系统（非驱动和摆锤驱动），它们配备LiDAR并运行LIO算法。研究发现，球形运动引入的高动态性导致LIO算法性能下降，产生不一致的地图和不可恢复的漂移。


<details>
  <summary>Details</summary>
Motivation: 球形机器人在危险或受限环境中进行测绘具有独特优势，得益于其保护性外壳和全向移动能力。

Method: 研究开发了两种互补的球形测绘系统：一种是轻量级、非驱动设计；另一种是带有内部摆锤驱动的执行版本。两种系统均配备Livox Mid-360固态LiDAR传感器，并在资源受限硬件上运行LiDAR-惯性里程计（LIO）算法。通过将LIO算法生成的3D点云与真实地图进行比较，评估了这些系统的测绘精度。

Result: 研究结果表明，由于球形运动引入的高动态性，最先进的LIO算法性能会下降，导致全局不一致的地图，有时还会出现不可恢复的漂移。

Conclusion: 球形机器人运动的高动态性对LIO算法的性能产生了负面影响，导致测绘精度降低，地图不一致且可能出现严重漂移。这表明LIO算法在处理此类动态运动时面临挑战。

Abstract: Spherical robots offer unique advantages for mapping applications in
hazardous or confined environments, thanks to their protective shells and
omnidirectional mobility. This work presents two complementary spherical
mapping systems: a lightweight, non-actuated design and an actuated variant
featuring internal pendulum-driven locomotion. Both systems are equipped with a
Livox Mid-360 solid-state LiDAR sensor and run LiDAR-Inertial Odometry (LIO)
algorithms on resource-constrained hardware. We assess the mapping accuracy of
these systems by comparing the resulting 3D point-clouds from the LIO
algorithms to a ground truth map. The results indicate that the performance of
state-of-the-art LIO algorithms deteriorates due to the high dynamic movement
introduced by the spherical locomotion, leading to globally inconsistent maps
and sometimes unrecoverable drift.

</details>


### [147] [TwinTac: A Wide-Range, Highly Sensitive Tactile Sensor with Real-to-Sim Digital Twin Sensor Model](https://arxiv.org/abs/2509.10063)
*Xiyan Huang,Zhe Xu,Chenxi Xiao*

Main category: cs.RO

TL;DR: 本文提出TwinTac系统，结合高灵敏度物理触觉传感器及其数字孪生模型，旨在弥补触觉传感器仿真模型缺失的空白，以支持机器人强化学习中的触觉感知。


<details>
  <summary>Details</summary>
Motivation: 机器人技能习得的强化学习过程依赖仿真数据，但缺乏触觉传感器的仿真模型，阻碍了触觉感知在技能学习中的应用，限制了基于触觉的有效策略发展。

Method: 研究人员首先设计了一种高灵敏度和宽测量范围的物理触觉传感器。然后，采用“从真实到仿真”的方法构建数字孪生模型，通过收集同步的跨域数据（包括有限元分析结果和物理传感器输出），并训练神经网络将仿真数据映射到真实的传感器响应。

Result: 实验评估表明，物理传感器具有高灵敏度，数字孪生模型能够一致地复现物理传感器的输出。此外，在物体分类任务中，数字孪生传感器生成的仿真数据有效增强了真实世界数据，提高了分类准确性。

Conclusion: TwinTac系统通过提供物理触觉传感器及其数字孪生模型，有效弥补了跨域学习任务中触觉感知的空白，有望推动基于触觉感知的机器人强化学习发展。

Abstract: Robot skill acquisition processes driven by reinforcement learning often rely
on simulations to efficiently generate large-scale interaction data. However,
the absence of simulation models for tactile sensors has hindered the use of
tactile sensing in such skill learning processes, limiting the development of
effective policies driven by tactile perception. To bridge this gap, we present
TwinTac, a system that combines the design of a physical tactile sensor with
its digital twin model. Our hardware sensor is designed for high sensitivity
and a wide measurement range, enabling high quality sensing data essential for
object interaction tasks. Building upon the hardware sensor, we develop the
digital twin model using a real-to-sim approach. This involves collecting
synchronized cross-domain data, including finite element method results and the
physical sensor's outputs, and then training neural networks to map simulated
data to real sensor responses. Through experimental evaluation, we
characterized the sensitivity of the physical sensor and demonstrated the
consistency of the digital twin in replicating the physical sensor's output.
Furthermore, by conducting an object classification task, we showed that
simulation data generated by our digital twin sensor can effectively augment
real-world data, leading to improved accuracy. These results highlight
TwinTac's potential to bridge the gap in cross-domain learning tasks.

</details>


### [148] [Prespecified-Performance Kinematic Tracking Control for Aerial Manipulation](https://arxiv.org/abs/2509.10065)
*Hauzi Cao,Jiahao Shen,Zhengzhen Li,Qinquan Ren,Shiyu Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种针对空中机械手的运动学跟踪控制框架，通过预设时间跟踪和二次规划的参考分配，解决了现有方法无法在指定时间内完成跟踪的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的空中机械手运动学跟踪控制方法（通常采用比例-微分反馈或基于跟踪误差的反馈策略）可能无法在指定的时间限制内实现跟踪目标。

Method: 本文提出了一种新的控制框架，包含两个主要组件：1) 基于用户定义的预设轨迹和性能包络的末端执行器跟踪控制，确保在预设时间内达到期望位置并控制误差；2) 基于二次规划的参考分配，用于分配四旋翼基座和Delta机械臂的参考，同时考虑空中机械手的物理约束以避免违反物理限制的解。

Result: 所提出的方法确保末端执行器在预设时间内到达期望位置，并使跟踪误差保持在反映任务要求的性能包络内。二次规划有效分配了参考并避免了物理限制。通过三个实验验证了算法的有效性及其在预设时间内达到目标位置的能力。

Conclusion: 实验结果表明，所提出的算法是有效的，并能够保证在预设时间内达到目标位置。

Abstract: This paper studies the kinematic tracking control problem for aerial
manipulators. Existing kinematic tracking control methods, which typically
employ proportional-derivative feedback or tracking-error-based feedback
strategies, may fail to achieve tracking objectives within specified time
constraints. To address this limitation, we propose a novel control framework
comprising two key components: end-effector tracking control based on a
user-defined preset trajectory and quadratic programming-based reference
allocation. Compared with state-of-the-art approaches, the proposed method has
several attractive features. First, it ensures that the end-effector reaches
the desired position within a preset time while keeping the tracking error
within a performance envelope that reflects task requirements. Second,
quadratic programming is employed to allocate the references of the quadcopter
base and the Delta arm, while considering the physical constraints of the
aerial manipulator, thus preventing solutions that may violate physical
limitations. The proposed approach is validated through three experiments.
Experimental results demonstrate the effectiveness of the proposed algorithm
and its capability to guarantee that the target position is reached within the
preset time.

</details>


### [149] [HHI-Assist: A Dataset and Benchmark of Human-Human Interaction in Physical Assistance Scenario](https://arxiv.org/abs/2509.10096)
*Saeed Saadatnejad,Reyhaneh Hosseininejad,Jose Barreiros,Katherine M. Tsui,Alexandre Alahi*

Main category: cs.RO

TL;DR: 该研究针对辅助机器人中人机交互场景下的人体运动预测难题，提出了一个名为HHI-Assist的人人交互运动捕捉数据集，并开发了一个基于条件Transformer的去噪扩散模型来预测交互代理的姿态，显著提升了预测准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 劳动力短缺和人口老龄化背景下，辅助机器人对人类护理对象的需求日益增长。为实现安全响应的辅助，机器人需在物理交互场景中准确预测人体运动。然而，由于辅助环境的多样性和物理交互中耦合动力学的复杂性，这仍是一个巨大挑战。

Method: 本研究通过两项关键贡献来应对挑战：1) HHI-Assist，一个包含辅助任务中人人交互运动捕捉片段的数据集；2) 一个基于条件Transformer的去噪扩散模型，用于预测交互代理的姿态。

Result: 所提出的模型能有效捕捉护理人员和护理接收者之间的耦合动力学，与基线模型相比有所改进，并对未见过的场景表现出强大的泛化能力。

Conclusion: 通过推动交互感知运动预测和引入新数据集，本工作有望显著增强机器人辅助策略，为辅助机器人领域带来重要进展。

Abstract: The increasing labor shortage and aging population underline the need for
assistive robots to support human care recipients. To enable safe and
responsive assistance, robots require accurate human motion prediction in
physical interaction scenarios. However, this remains a challenging task due to
the variability of assistive settings and the complexity of coupled dynamics in
physical interactions. In this work, we address these challenges through two
key contributions: (1) HHI-Assist, a dataset comprising motion capture clips of
human-human interactions in assistive tasks; and (2) a conditional
Transformer-based denoising diffusion model for predicting the poses of
interacting agents. Our model effectively captures the coupled dynamics between
caregivers and care receivers, demonstrating improvements over baselines and
strong generalization to unseen scenarios. By advancing interaction-aware
motion prediction and introducing a new dataset, our work has the potential to
significantly enhance robotic assistance policies. The dataset and code are
available at: https://sites.google.com/view/hhi-assist/home

</details>


### [150] [Efficient Learning-Based Control of a Legged Robot in Lunar Gravity](https://arxiv.org/abs/2509.10128)
*Philip Arm,Oliver Fischer,Joseph Church,Adrian Fuhrer,Hendrik Kolvenbach,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的腿足机器人控制方法，通过重力缩放的功率优化奖励函数，实现了在多种重力环境下（从月球到超地球）的节能运动和姿态控制，并在实际月球重力环境中验证了其显著的能效提升。


<details>
  <summary>Details</summary>
Motivation: 腿足机器人在低重力星球（如月球、火星、小行星）探索中具有巨大潜力，但其功率和热量预算受限。因此，需要开发出能源效率高且能适应多种重力环境的控制方法。

Method: 研究人员提出了一种基于强化学习的腿足机器人控制方法，该方法使用重力缩放的功率优化奖励函数。他们开发并验证了运动控制器和基础姿态控制器，并设计了一个恒力弹簧卸载系统，用于在模拟月球重力环境下进行实际实验。

Result: 该方法成功地在从月球重力（1.62 m/s²）到假设的超地球重力（19.62 m/s²）的多种重力水平下实现了运动和姿态控制。在地球重力下，功率优化的运动控制器在15.65公斤、0.4米/秒的机器人上实现了23.4瓦的功耗，比基线策略提高了23%。在月球重力下，功率优化控制策略达到了12.2瓦的功耗，比未经功率优化的基线控制器低36%。

Conclusion: 该方法为开发适用于多种重力水平的腿足机器人节能运动控制器提供了一种可扩展的途径。

Abstract: Legged robots are promising candidates for exploring challenging areas on
low-gravity bodies such as the Moon, Mars, or asteroids, thanks to their
advanced mobility on unstructured terrain. However, as planetary robots' power
and thermal budgets are highly restricted, these robots need energy-efficient
control approaches that easily transfer to multiple gravity environments. In
this work, we introduce a reinforcement learning-based control approach for
legged robots with gravity-scaled power-optimized reward functions. We use our
approach to develop and validate a locomotion controller and a base pose
controller in gravity environments from lunar gravity (1.62 m/s2) to a
hypothetical super-Earth (19.62 m/s2). Our approach successfully scales across
these gravity levels for locomotion and base pose control with the
gravity-scaled reward functions. The power-optimized locomotion controller
reached a power consumption for locomotion of 23.4 W in Earth gravity on a
15.65 kg robot at 0.4 m/s, a 23 % improvement over the baseline policy.
Additionally, we designed a constant-force spring offload system that allowed
us to conduct real-world experiments on legged locomotion in lunar gravity. In
lunar gravity, the power-optimized control policy reached 12.2 W, 36 % less
than a baseline controller which is not optimized for power efficiency. Our
method provides a scalable approach to developing power-efficient locomotion
controllers for legged robots across multiple gravity levels.

</details>


### [151] [CaR1: A Multi-Modal Baseline for BEV Vehicle Segmentation via Camera-Radar Fusion](https://arxiv.org/abs/2509.10139)
*Santiago Montiel-Marín,Angel Llamazares,Miguel Antunes-García,Fabio Sánchez-García,Luis M. Bergasa*

Main category: cs.RO

TL;DR: CaR1是一种新颖的相机-雷达融合架构，用于BEV车辆分割，通过网格化雷达编码和自适应融合机制改进了BEVFusion，在nuScenes上实现了与最先进方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 激光雷达自动驾驶系统成本高昂。相机提供丰富的语义信息但深度不可靠，雷达提供稀疏但可靠的位置和运动信息。通过结合两者的互补优势，可以为自动驾驶提供一个鲁棒且经济高效的替代方案，特别是在BEV车辆分割任务上。

Method: 该方法基于BEVFusion构建，并引入了两个关键改进：1. 网格化雷达编码：将点云离散化为结构化的BEV特征。2. 自适应融合机制：动态平衡不同传感器的贡献。

Result: 在nuScenes数据集上的实验表明，该方法在分割性能上具有竞争力（57.6 IoU），与最先进的方法持平。

Conclusion: CaR1是一种新颖的相机-雷达融合架构，通过创新的编码和融合机制，在BEV车辆分割方面取得了与现有最佳方法相当的性能，为自动驾驶提供了一个有效的解决方案。

Abstract: Camera-radar fusion offers a robust and cost-effective alternative to
LiDAR-based autonomous driving systems by combining complementary sensing
capabilities: cameras provide rich semantic cues but unreliable depth, while
radar delivers sparse yet reliable position and motion information. We
introduce CaR1, a novel camera-radar fusion architecture for BEV vehicle
segmentation. Built upon BEVFusion, our approach incorporates a grid-wise radar
encoding that discretizes point clouds into structured BEV features and an
adaptive fusion mechanism that dynamically balances sensor contributions.
Experiments on nuScenes demonstrate competitive segmentation performance (57.6
IoU), on par with state-of-the-art methods. Code is publicly available
\href{https://www.github.com/santimontiel/car1}{online}.

</details>


### [152] [DiffAero: A GPU-Accelerated Differentiable Simulation Framework for Efficient Quadrotor Policy Learning](https://arxiv.org/abs/2509.10247)
*Xinhong Zhang,Runqing Wang,Yunfan Ren,Jian Sun,Hao Fang,Jie Chen,Gang Wang*

Main category: cs.RO

TL;DR: DiffAero是一个轻量级、GPU加速、完全可微分的四旋翼模拟框架，旨在通过消除CPU-GPU传输瓶颈和支持并行化来高效学习控制策略，并可作为可微分学习的研究平台。


<details>
  <summary>Details</summary>
Motivation: 现有模拟器在四旋翼控制策略学习中可能存在CPU-GPU数据传输瓶颈，导致模拟吞吐量低，且未能充分支持可微分和混合学习算法的研究。

Method: DiffAero是一个GPU原生的训练接口，支持环境级和智能体级并行。它集成了多种动力学模型、可定制的传感器堆栈（IMU、深度相机、LiDAR）和多种飞行任务。通过在GPU上完全并行化物理和渲染，DiffAero消除了CPU-GPU数据传输瓶颈。

Result: DiffAero在模拟吞吐量方面实现了数量级的提升。结合混合学习算法，它能够在消费级硬件上在数小时内学习到鲁棒的飞行策略。基准测试和真实世界飞行实验验证了其有效性。

Conclusion: DiffAero不仅提供高性能模拟，还是探索可微分和混合学习算法的有效研究平台，能够高效且鲁棒地学习四旋翼飞行策略。

Abstract: This letter introduces DiffAero, a lightweight, GPU-accelerated, and fully
differentiable simulation framework designed for efficient quadrotor control
policy learning. DiffAero supports both environment-level and agent-level
parallelism and integrates multiple dynamics models, customizable sensor stacks
(IMU, depth camera, and LiDAR), and diverse flight tasks within a unified,
GPU-native training interface. By fully parallelizing both physics and
rendering on the GPU, DiffAero eliminates CPU-GPU data transfer bottlenecks and
delivers orders-of-magnitude improvements in simulation throughput. In contrast
to existing simulators, DiffAero not only provides high-performance simulation
but also serves as a research platform for exploring differentiable and hybrid
learning algorithms. Extensive benchmarks and real-world flight experiments
demonstrate that DiffAero and hybrid learning algorithms combined can learn
robust flight policies in hours on consumer-grade hardware. The code is
available at https://github.com/flyingbitac/diffaero.

</details>


### [153] [GundamQ: Multi-Scale Spatio-Temporal Representation Learning for Robust Robot Path Planning](https://arxiv.org/abs/2509.10305)
*Yutong Shen,Ruizhe Xia,Bokai Yan,Shunqi zhang,Pengrui Xiang,Sicheng He,Yixin Xu*

Main category: cs.RO

TL;DR: GundamQ提出了一种多尺度时空Q网络，通过改进时空感知和自适应策略优化，显著提升了机器人在动态不确定环境中的路径规划成功率和路径质量。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度强化学习的路径规划方法存在两个主要局限性：(1) 对多尺度时间依赖建模不足，导致在动态场景中适应性差；(2) 探索-利用平衡效率低下，导致路径质量下降。

Method: 本文提出了GundamQ框架，包含两个关键模块：(i) 时空感知模块，分层提取多粒度空间特征和从瞬时到长期范围的多尺度时间依赖，以提高动态环境中的感知精度；(ii) 自适应策略优化模块，在训练过程中平衡探索与利用，并通过约束策略更新优化路径平滑度和碰撞概率。

Result: 在动态环境中的实验表明，GundamQ的成功率提高了15.3%，整体路径质量提高了21.7%，显著优于现有的最先进方法。

Conclusion: GundamQ通过解决多尺度时间依赖建模和探索-利用平衡问题，有效提升了机器人在动态不确定环境中的路径规划性能，实现了更高的成功率和更好的路径质量。

Abstract: In dynamic and uncertain environments, robotic path planning demands accurate
spatiotemporal environment understanding combined with robust decision-making
under partial observability. However, current deep reinforcement learning-based
path planning methods face two fundamental limitations: (1) insufficient
modeling of multi-scale temporal dependencies, resulting in suboptimal
adaptability in dynamic scenarios, and (2) inefficient exploration-exploitation
balance, leading to degraded path quality. To address these challenges, we
propose GundamQ: A Multi-Scale Spatiotemporal Q-Network for Robotic Path
Planning. The framework comprises two key modules: (i) the Spatiotemporal
Perception module, which hierarchically extracts multi-granularity spatial
features and multi-scale temporal dependencies ranging from instantaneous to
extended time horizons, thereby improving perception accuracy in dynamic
environments; and (ii) the Adaptive Policy Optimization module, which balances
exploration and exploitation during training while optimizing for smoothness
and collision probability through constrained policy updates. Experiments in
dynamic environments demonstrate that GundamQ achieves a 15.3\% improvement in
success rate and a 21.7\% increase in overall path quality, significantly
outperforming existing state-of-the-art methods.

</details>


### [154] [Robot guide with multi-agent control and automatic scenario generation with LLM](https://arxiv.org/abs/2509.10317)
*Elizaveta D. Moskovskaya,Anton D. Moscowsky*

Main category: cs.RO

TL;DR: 该研究开发了一种用于拟人化导游机器人的混合控制架构，结合了多智能体资源管理系统和基于大型语言模型的自动行为场景生成。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统依赖手动调整行为场景，存在手动配置、灵活性低和机器人行为不自然等局限性。本研究旨在克服这些限制。

Method: 提出了一种混合控制架构，其中：1) 利用大型语言模型进行两阶段行为场景生成（先创建风格化叙述，再整合非语言动作标签）；2) 采用多智能体系统进行并行动作的协调、冲突解决以及主要操作完成后的默认行为维护。

Result: 试验结果表明，所提出的方法在自动化和扩展社交机器人控制系统方面具有潜力，并有助于实现更自然的机器人行为。

Conclusion: 该混合控制方法成功实现了导游机器人行为场景的自动化生成和管理，提高了系统的灵活性和行为的自然性，为社交机器人控制系统的自动化和规模化提供了可行方案。

Abstract: The work describes the development of a hybrid control architecture for an
anthropomorphic tour guide robot, combining a multi-agent resource management
system with automatic behavior scenario generation based on large language
models. The proposed approach aims to overcome the limitations of traditional
systems, which rely on manual tuning of behavior scenarios. These limitations
include manual configuration, low flexibility, and lack of naturalness in robot
behavior. The process of preparing tour scenarios is implemented through a
two-stage generation: first, a stylized narrative is created, then non-verbal
action tags are integrated into the text. The multi-agent system ensures
coordination and conflict resolution during the execution of parallel actions,
as well as maintaining default behavior after the completion of main
operations, contributing to more natural robot behavior. The results obtained
from the trial demonstrate the potential of the proposed approach for
automating and scaling social robot control systems.

</details>


### [155] [Acetrans: An Autonomous Corridor-Based and Efficient UAV Suspended Transport System](https://arxiv.org/abs/2509.10349)
*Weiyan Lu,Huizhe Li,Yuhao Fang,Zhexuan Zhou,Junda Wu,Yude Li,Youmin Gong,Jie Mei*

Main category: cs.RO

TL;DR: 本文提出Acetrans，一个自主、基于走廊、高效的无人机悬挂运输系统，通过统一的感知、规划和控制框架，解决了现有系统在感知、规划效率和全身安全方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的无人机悬挂运输系统面临关键限制，包括：对缆绳-有效载荷动力学感知不可靠；在大规模环境中规划效率低下；以及在缆绳弯曲和外部扰动下无法保证全身安全。

Method: 本文提出了一个统一的感知、规划和控制框架：1. LiDAR-IMU融合模块，用于联合估计有效载荷姿态和缆绳形状（拉紧和弯曲模式），实现鲁棒的全身状态估计和缆绳点云实时滤波。2. MACIRI算法，生成考虑不同无人机和有效载荷几何形状的安全飞行走廊，增强规划可扩展性。3. 时空、走廊约束的轨迹优化方案，确保动态可行和无碰撞轨迹。4. 增强了缆绳弯曲约束的非线性模型预测控制器（NMPC），在执行过程中提供鲁棒的全身安全。

Result: 仿真和实验结果验证了Acetrans的有效性，与现有最先进方法相比，在感知精度、规划效率和控制安全性方面均有显著提高。

Conclusion: Acetrans通过其统一的感知、规划和控制框架，成功解决了无人机悬挂运输面临的关键挑战，并展示了优越的性能。

Abstract: Unmanned aerial vehicles (UAVs) with suspended payloads offer significant
advantages for aerial transportation in complex and cluttered environments.
However, existing systems face critical limitations, including unreliable
perception of the cable-payload dynamics, inefficient planning in large-scale
environments, and the inability to guarantee whole-body safety under cable
bending and external disturbances. This paper presents Acetrans, an Autonomous,
Corridor-based, and Efficient UAV suspended transport system that addresses
these challenges through a unified perception, planning, and control framework.
A LiDAR-IMU fusion module is proposed to jointly estimate both payload pose and
cable shape under taut and bent modes, enabling robust whole-body state
estimation and real-time filtering of cable point clouds. To enhance planning
scalability, we introduce the Multi-size-Aware Configuration-space Iterative
Regional Inflation (MACIRI) algorithm, which generates safe flight corridors
while accounting for varying UAV and payload geometries. A spatio-temporal,
corridor-constrained trajectory optimization scheme is then developed to ensure
dynamically feasible and collision-free trajectories. Finally, a nonlinear
model predictive controller (NMPC) augmented with cable-bending constraints
provides robust whole-body safety during execution. Simulation and experimental
results validate the effectiveness of Acetrans, demonstrating substantial
improvements in perception accuracy, planning efficiency, and control safety
compared to state-of-the-art methods.

</details>


### [156] [Self-supervised Learning Of Visual Pose Estimation Without Pose Labels By Classifying LED States](https://arxiv.org/abs/2509.10405)
*Nicholas Carlotti,Mirko Nava,Alessandro Giusti*

Main category: cs.RO

TL;DR: 本文提出了一种用于地面机器人单目RGB相对姿态估计的模型，该模型无需姿态标签或机器人CAD模型即可从零开始训练，利用机器人上的LED灯状态作为监督信号。


<details>
  <summary>Details</summary>
Motivation: 现有的单目机器人姿态估计算法通常需要姿态标签或机器人CAD模型进行监督，这限制了其应用场景和部署便利性。本研究旨在开发一种无需这些先验知识的训练方法。

Method: 该模型在训练时假设：(i) 机器人配备多个LED灯，其状态独立且在每帧已知；(ii) 每个LED灯的近似视线方向已知；(iii) 可用一张已知目标距离的校准图像来解决单目深度模糊性。训练数据由一对机器人随机移动收集，无需外部基础设施或人工监督。模型训练的目标是从图像中预测每个LED灯的状态，从而间接学习机器人在图像中的位置、距离和相对方位。在推理时，LED灯的状态未知且任意，不影响姿态估计性能。

Result: 实验结果表明，该方法：与需要姿态标签或机器人CAD模型的现有最先进方法具有竞争力；能够泛化到不同领域；并且支持多机器人姿态估计。

Conclusion: 本研究成功引入了一种新颖的单目RGB地面机器人相对姿态估计模型，该模型在无需姿态标签或CAD模型的情况下，通过利用机器人上的LED灯状态进行自监督训练，实现了与有监督方法相当的性能，并展现出良好的泛化能力和多机器人处理能力。

Abstract: We introduce a model for monocular RGB relative pose estimation of a ground
robot that trains from scratch without pose labels nor prior knowledge about
the robot's shape or appearance. At training time, we assume: (i) a robot
fitted with multiple LEDs, whose states are independent and known at each
frame; (ii) knowledge of the approximate viewing direction of each LED; and
(iii) availability of a calibration image with a known target distance, to
address the ambiguity of monocular depth estimation. Training data is collected
by a pair of robots moving randomly without needing external infrastructure or
human supervision. Our model trains on the task of predicting from an image the
state of each LED on the robot. In doing so, it learns to predict the position
of the robot in the image, its distance, and its relative bearing. At inference
time, the state of the LEDs is unknown, can be arbitrary, and does not affect
the pose estimation performance. Quantitative experiments indicate that our
approach: is competitive with SoA approaches that require supervision from pose
labels or a CAD model of the robot; generalizes to different domains; and
handles multi-robot pose estimation.

</details>


### [157] [TASC: Task-Aware Shared Control for Teleoperated Manipulation](https://arxiv.org/abs/2509.10416)
*Ze Fu,Pinhao Song,Yutong Hu,Renaud Detry*

Main category: cs.RO

TL;DR: TASC是一个任务感知的共享控制框架，通过构建开放词汇交互图和视觉-语言模型，推断用户意图并提供旋转辅助，实现了对日常遥控操作任务的零样本泛化，提高了效率并减少了用户输入。


<details>
  <summary>Details</summary>
Motivation: 现有通用、长周期共享控制面临两大挑战：1) 理解和推断任务级别的用户意图；2) 将辅助泛化到各种物体和任务，尤其是在没有预定义知识的情况下支持日常任务。

Method: TASC框架通过视觉输入构建开放词汇交互图，以表示物体功能关系并推断用户意图。一个共享控制策略在抓取和物体交互过程中提供旋转辅助，其指导来源于视觉-语言模型预测的空间约束。

Result: 在仿真和现实世界实验中，TASC与现有方法相比，显著提高了任务效率并减少了用户输入工作量。它是首个支持日常操作任务并具有零样本泛化能力的共享控制框架。

Conclusion: TASC成功解决了通用、长周期共享控制中的关键挑战，即理解任务级用户意图和泛化辅助，从而在日常操作任务中实现了零样本泛化，并带来了性能提升。

Abstract: We present TASC, a Task-Aware Shared Control framework for teleoperated
manipulation that infers task-level user intent and provides assistance
throughout the task. To support everyday tasks without predefined knowledge,
TASC constructs an open-vocabulary interaction graph from visual input to
represent functional object relationships, and infers user intent accordingly.
A shared control policy then provides rotation assistance during both grasping
and object interaction, guided by spatial constraints predicted by a
vision-language model. Our method addresses two key challenges in
general-purpose, long-horizon shared control: (1) understanding and inferring
task-level user intent, and (2) generalizing assistance across diverse objects
and tasks. Experiments in both simulation and the real world demonstrate that
TASC improves task efficiency and reduces user input effort compared to prior
methods. To the best of our knowledge, this is the first shared control
framework that supports everyday manipulation tasks with zero-shot
generalization. The code that supports our experiments is publicly available at
https://github.com/fitz0401/tasc.

</details>


### [158] [DECAMP: Towards Scene-Consistent Multi-Agent Motion Prediction with Disentangled Context-Aware Pre-Training](https://arxiv.org/abs/2509.10426)
*Jianxin Shi,Zengqi Peng,Xiaolong Chen,Tianyu Wo,Jun Ma*

Main category: cs.RO

TL;DR: 提出了一种名为DECAMP的解耦上下文感知预训练框架，用于多智能体运动预测，通过解耦行为模式学习和潜在特征重建，并结合上下文感知表示学习和协作空间-运动预训练任务，显著提高了自动驾驶中多智能体轨迹预测的性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法在标签数据稀缺和多智能体预测场景中表现不佳，且现有方法常将表示学习与预训练任务纠缠在一起，导致可解释性不足。

Method: 引入了DECAMP框架，它解耦了行为模式学习与潜在特征重建，优先考虑可解释的动态性；同时，结合了上下文感知表示学习和协作空间-运动预训练任务，以联合优化结构和意图推理，并捕捉潜在的动态意图。

Result: 在Argoverse 2基准测试中，DECAMP展现出卓越的性能，并证明了其在多智能体运动预测中的有效性。

Conclusion: DECAMP是首个用于自动驾驶中多智能体运动预测的上下文自编码器框架，有效解决了现有方法的挑战，提高了预测准确性和场景表示能力。

Abstract: Trajectory prediction is a critical component of autonomous driving,
essential for ensuring both safety and efficiency on the road. However,
traditional approaches often struggle with the scarcity of labeled data and
exhibit suboptimal performance in multi-agent prediction scenarios. To address
these challenges, we introduce a disentangled context-aware pre-training
framework for multi-agent motion prediction, named DECAMP. Unlike existing
methods that entangle representation learning with pretext tasks, our framework
decouples behavior pattern learning from latent feature reconstruction,
prioritizing interpretable dynamics and thereby enhancing scene representation
for downstream prediction. Additionally, our framework incorporates
context-aware representation learning alongside collaborative spatial-motion
pretext tasks, which enables joint optimization of structural and intentional
reasoning while capturing the underlying dynamic intentions. Our experiments on
the Argoverse 2 benchmark showcase the superior performance of our method, and
the results attained underscore its effectiveness in multi-agent motion
forecasting. To the best of our knowledge, this is the first context
autoencoder framework for multi-agent motion forecasting in autonomous driving.
The code and models will be made publicly available.

</details>


### [159] [Coordinated Motion Planning of a Wearable Multi-Limb System for Enhanced Human-Robot Interaction](https://arxiv.org/abs/2509.10444)
*Chaerim Moon,Joohyung Kim*

Main category: cs.RO

TL;DR: 该论文提出了一种运动规划层，用于减少外骨骼机器人（SRLs）在操作过程中对人体产生的力矩，从而增强人机交互。


<details>
  <summary>Details</summary>
Motivation: 可穿戴的外骨骼机器人（SRLs）在操作时会对人体产生外部力矩，导致肌肉激活增加和肌肉零空间减少，从而影响人机交互和人体能力。

Method: 提出了一种运动规划层，通过限制期望的角加速度和位置偏差来修改给定的轨迹，以达到减少生成力矩的目的。

Result: 通过使用简化的人体和机器人系统模型进行的仿真，证明了该方法在减少力矩方面的有效性。

Conclusion: 该运动规划层能够通过减少外骨骼机器人产生的力矩来增强人机交互体验。

Abstract: Supernumerary Robotic Limbs (SRLs) can enhance human capability within close
proximity. However, as a wearable device, the generated moment from its
operation acts on the human body as an external torque. When the moments
increase, more muscle units are activated for balancing, and it can result in
reduced muscular null space. Therefore, this paper suggests a concept of a
motion planning layer that reduces the generated moment for enhanced
Human-Robot Interaction. It modifies given trajectories with desirable angular
acceleration and position deviation limits. Its performance to reduce the
moment is demonstrated through the simulation, which uses simplified human and
robotic system models.

</details>


### [160] [GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation](https://arxiv.org/abs/2509.10454)
*Hang Yin,Haoyu Wei,Xiuwei Xu,Wenxuan Guo,Jie Zhou,Jiwen Lu*

Main category: cs.RO

TL;DR: 本文提出了一种无需训练的视觉-语言导航（VLN）框架，通过将指令分解为空间约束并利用图约束优化，实现在连续环境中对未知环境的零样本适应。


<details>
  <summary>Details</summary>
Motivation: 现有零样本VLN方法主要针对离散环境或涉及在连续模拟器中进行无监督训练，这使得它们在真实世界场景中的泛化和部署面临挑战。

Method: 该框架将导航指导表述为图约束优化，通过将指令分解为明确的空间约束。它构建了一个涵盖所有空间关系类型的空间约束库，将人类指令分解为有向无环图（包含路点、对象节点和边），并用作查询来构建图约束。图约束优化通过约束求解器确定路点位置，从而获得机器人导航路径和最终目标。为处理无解或多解情况，引入了导航树和回溯机制。

Result: 在标准基准测试中，与最先进的零样本VLN方法相比，成功率和导航效率显著提高。真实世界实验表明，该框架能有效泛化到新环境和指令集。

Conclusion: 该框架为更稳健和自主的导航框架铺平了道路，尤其适用于连续环境中的零样本VLN，并能有效泛化到真实世界场景。

Abstract: In this paper, we propose a training-free framework for vision-and-language
navigation (VLN). Existing zero-shot VLN methods are mainly designed for
discrete environments or involve unsupervised training in continuous simulator
environments, which makes it challenging to generalize and deploy them in
real-world scenarios. To achieve a training-free framework in continuous
environments, our framework formulates navigation guidance as graph constraint
optimization by decomposing instructions into explicit spatial constraints. The
constraint-driven paradigm decodes spatial semantics through constraint
solving, enabling zero-shot adaptation to unseen environments. Specifically, we
construct a spatial constraint library covering all types of spatial
relationship mentioned in VLN instructions. The human instruction is decomposed
into a directed acyclic graph, with waypoint nodes, object nodes and edges,
which are used as queries to retrieve the library to build the graph
constraints. The graph constraint optimization is solved by the constraint
solver to determine the positions of waypoints, obtaining the robot's
navigation path and final goal. To handle cases of no solution or multiple
solutions, we construct a navigation tree and the backtracking mechanism.
Extensive experiments on standard benchmarks demonstrate significant
improvements in success rate and navigation efficiency compared to
state-of-the-art zero-shot VLN methods. We further conduct real-world
experiments to show that our framework can effectively generalize to new
environments and instruction sets, paving the way for a more robust and
autonomous navigation framework.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [161] [Target Defense Using a Turret and Mobile Defender Team](https://arxiv.org/abs/2509.09777)
*Alexander Von Moll,Dipankar Maity,Meir Pachter,Daigo Shishika,Michael Dorothy*

Main category: eess.SY

TL;DR: 本文研究了一个差分博弈场景：一个固定炮塔（Turret）和一个移动防御者（Defender）合作，以保护炮塔免受移动攻击者（Attacker）的侵害。研究给出了双方获胜的充要条件和均衡策略。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是分析一个防御系统，其中一个受转向限制的固定炮塔和一个移动防御者需要协同工作，以防止一个移动攻击者在被捕获前到达炮塔。防御方旨在尽可能远离炮塔捕获攻击者，而攻击者则试图在被捕获前到达炮塔。

Method: 该场景被建模为一个差分博弈（differential game），并采用几何方法（geometric approach）进行求解。

Result: 研究给出了炮塔-防御者团队获胜和攻击者获胜的充要条件。在炮塔-防御者团队获胜的情况下，还给出了使攻击者到炮塔的最终距离最小最大化的均衡策略。捕获情况分为三种：防御者单独捕获、炮塔单独捕获以及炮塔和防御者同时捕获。

Conclusion: 该研究成功地利用差分博弈和几何方法分析了固定炮塔、移动防御者与移动攻击者之间的对抗场景，明确了各方获胜的条件，并为防御方提供了最大化捕获距离的均衡策略，区分了不同的捕获模式。

Abstract: A scenario is considered wherein a stationary, turn constrained agent
(Turret) and a mobile agent (Defender) cooperate to protect the former from an
adversarial mobile agent (Attacker). The Attacker wishes to reach the Turret
prior to getting captured by either the Defender or Turret, if possible.
Meanwhile, the Defender and Turret seek to capture the Attacker as far from the
Turret as possible. This scenario is formulated as a differential game and
solved using a geometric approach. Necessary and sufficient conditions for the
Turret-Defender team winning and the Attacker winning are given. In the case of
the Turret-Defender team winning equilibrium strategies for the min max
terminal distance of the Attacker to the Turret are given. Three cases arise
corresponding to solo capture by the Defender, solo capture by the Turret, and
capture simultaneously by both Turret and Defender.

</details>


### [162] [Automatic Regression for Governing Equations with Control (ARGOSc)](https://arxiv.org/abs/2509.09784)
*Amir Bahador Javadi,Amin Kargarian,Mort Naraghi-Pour*

Main category: eess.SY

TL;DR: 本文提出ARGOSc，它是ARGOS框架的扩展，旨在从数据中学习包含外部控制输入的动力系统方程。ARGOSc在处理带控制的系统时表现出更高的准确性，尤其是在噪声条件下，优于SINDYc。


<details>
  <summary>Details</summary>
Motivation: 从数据中学习动力系统的控制方程是一个重要领域，但现有的稀疏回归技术（如标准ARGOS）无法处理真实世界系统中常见的外部控制输入、外力或人为干预。这促使研究人员开发一种能够整合这些控制输入的系统识别方法。

Method: 本文引入了带控制的ARGOS (ARGOSc)，它是ARGOS的扩展。ARGOSc将外部控制输入纳入系统识别过程中的稀疏回归框架，以推断控制方程，同时考虑外生输入的影响。

Result: ARGOSc在基准系统（如Van der Pol振子、Lotka-Volterra和带强制与反馈控制的Lorenz系统）上表现出卓越的性能，显著提高了发现控制律的准确性。在噪声条件下，ARGOSc在准确识别潜在的受迫动力学方面优于广泛使用的SINDYc，在某些SINDYc失败的情况下，ARGOSc仍能成功。

Conclusion: ARGOSc为包含外部控制输入的动力系统提供了鲁棒的控制方程识别方法，在低到中等噪声数据集中能够有效地识别强制动力学。与现有方法SINDYc相比，ARGOSc在噪声环境下表现出更高的准确性和稳定性。

Abstract: Learning the governing equations of dynamical systems from data has drawn
significant attention across diverse fields, including physics, engineering,
robotics and control, economics, climate science, and healthcare. Sparse
regression techniques, exemplified by the Automatic Regression for Governing
Equations (ARGOS) framework, have demonstrated effectiveness in extracting
parsimonious models from time series data. However, real-world dynamical
systems are driven by input control, external forces, or human interventions,
which standard ARGOS does not accommodate. To address this, we introduce ARGOS
with control (ARGOSc), an extension of ARGOS that incorporates external control
inputs into the system identification process. ARGOSc extends the sparse
regression framework to infer governing equations while accounting for the
effects of exogenous inputs, enabling robust identification of forcing dynamics
in low- to medium-noise datasets. We demonstrate ARGOSc efficacy on benchmark
systems, including the Van der Pol oscillator, Lotka-Volterra, and the Lorenz
system with forcing and feedback control, showing enhanced accuracy in
discovering governing laws. Under the noisy conditions, ARGOSc outperforms the
widely used sparse identification of nonlinear dynamics with control (SINDYc),
in accurately identifying the underlying forced dynamics. In some cases, SINDYc
fails to capture the true system dynamics, whereas ARGOSc consistently
succeeds.

</details>


### [163] [High-Gain Voltage-Multiplier Coupled Quadratic Boost Converter: A New Design for Small Scale PV Integration](https://arxiv.org/abs/2509.09789)
*Safa Mohammed Sali,Hoach The Nguyen,Ameena Saad Al-Sumaiti*

Main category: eess.SY

TL;DR: 本文介绍了一种单开关高增益倍压器耦合二次升压变换器（HGVM-QBC），专为小型光伏系统设计，具有高电压增益、低半导体电压应力及连续电流操作的特点。


<details>
  <summary>Details</summary>
Motivation: 传统二次升压变换器（QBC）在小型光伏系统应用中，需要更高的电压增益、更低的半导体电压应力以及连续电流操作能力。

Method: 通过将倍压器单元集成到传统二次升压变换器中，并结合多个输出电容器的电压以提高整体电压水平。通过MATLAB/Simulink仿真和实验原型验证其性能。

Result: 与现有变换器拓扑相比，HGVM-QBC展现出卓越的增益和更低的器件应力。仿真结果证实了增益和电压应力的改善。实验原型在55%占空比下，将12 Vdc输入升压至151 Vdc输出，增益达到12.59。

Conclusion: HGVM-QBC为需要从低输入源获得高电压输出的光伏应用提供了一个高效可靠的解决方案。

Abstract: This paper introduces a single-switch high-gain voltage-multiplier coupled
quadratic boost converter (HGVM-QBC), developed from the conventional quadratic
boost converter (QBC). The proposed topology is designed to achieve higher
voltage gain, lower semiconductor voltage stress, and continuous current
operation, making it particularly suitable for small-scale photovoltaic (PV)
systems. By incorporating a voltage multiplier cell into the QBC, the converter
significantly improves voltage boosting capability while mitigating stress on
switching devices. In this configuration, the output voltage is obtained by
combining the voltages across multiple output capacitors, thereby enhancing the
overall voltage level. A detailed comparative study with recently reported
converter topologies demonstrates the superior gain and reduced device stress
offered by the HGVM-QBC. The design is validated through MATLAB/Simulink
simulations, which confirm improved performance in terms of gain and voltage
stress. Furthermore, an experimental prototype achieves an output of 151 Vdc
from a 12 Vdc input at a 55% duty cycle, corresponding to a gain of 12.59.
These results establish the HGVM-QBC as an efficient and reliable solution for
PV applications that demand high voltage output from low input sources.

</details>


### [164] [EDMD-Based Robust Observer Synthesis for Nonlinear Systems](https://arxiv.org/abs/2509.09812)
*Xiuzhen Ye,Wentao Tang*

Main category: eess.SY

TL;DR: 本文提出了一种基于数据驱动Koopman算子的框架，用于设计非线性系统的鲁棒状态观测器，通过半定规划确保观测器以概率方式指数收敛。


<details>
  <summary>Details</summary>
Motivation: 现有方法在非线性系统观测器设计中面临挑战，尤其是在弥合统计误差容忍度与观测器收敛性认证之间的差距方面。

Method: 该方法基于通过扩展动态模态分解（EDMD）识别的Koopman生成器的有限维替代模型，将观测器设计问题转化为一个带有锥形不确定性的数据驱动模型。最终问题被表述为一个包含线性矩阵不等式（LMI）的半定规划（SDP）。

Result: 该方法能够以概率方式保证观测器以预定速率指数收敛，弥合了统计误差容忍度与观测器收敛性认证之间的差距，并通过数据驱动的线性替代模型实现了线性系统理论在状态观测中的显式应用。数值研究证明了所提方法的有效性和灵活性。

Conclusion: 所提出的基于数据驱动Koopman算子的框架为非线性系统鲁棒状态观测器的设计提供了一种有效且灵活的方法，并通过半定规划实现了概率意义上的指数收敛保证。

Abstract: This paper presents a data driven Koopman operator based framework for
designing robust state observers for nonlinear systems. Based on a finite
dimensional surrogate of the Koopman generator, identified via an extended
dynamic mode decomposition procedure, a tractable formulation of the observer
design is enabled on the data driven model with conic uncertainties. The
resulting problem is cast as a semidefinite program with linear matrix
inequalities, guaranteeing exponential convergence of the observer with a
predetermined rate in a probabilistic sense. The approach bridges the gap
between statistical error tolerance and observer convergence certification, and
enables an explicit use of linear systems theory for state observation via a
data driven linear surrogate model. Numerical studies demonstrate the
effectiveness and flexibility of the proposed method.

</details>


### [165] [Off Policy Lyapunov Stability in Reinforcement Learning](https://arxiv.org/abs/2509.09863)
*Sarvan Gill,Daniela Constantinescu*

Main category: eess.SY

TL;DR: 本文提出了一种离策略Lyapunov函数学习方法，并将其集成到SAC和PPO算法中，以提供数据高效的稳定性保证，从而提高了算法性能。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习算法缺乏稳定性保证。虽然近期算法通过学习Lyapunov函数来确保稳定学习，但现有的自学习Lyapunov函数由于其在策略（on-policy）性质而导致样本效率低下。

Method: 本文引入了一种离策略（off-policy）学习Lyapunov函数的方法，并将其整合到Soft Actor Critic (SAC) 和 Proximal Policy Optimization (PPO) 算法中。

Result: 在倒立摆和四旋翼飞行器仿真中，当SAC和PPO算法配备了所提出的离策略Lyapunov函数后，其性能得到了显著提升。

Conclusion: 所提出的离策略Lyapunov函数能够为强化学习算法（如SAC和PPO）提供数据高效的稳定性证明，并有效提升其性能。

Abstract: Traditional reinforcement learning lacks the ability to provide stability
guarantees. More recent algorithms learn Lyapunov functions alongside the
control policies to ensure stable learning. However, the current self-learned
Lyapunov functions are sample inefficient due to their on-policy nature. This
paper introduces a method for learning Lyapunov functions off-policy and
incorporates the proposed off-policy Lyapunov function into the Soft Actor
Critic and Proximal Policy Optimization algorithms to provide them with a data
efficient stability certificate. Simulations of an inverted pendulum and a
quadrotor illustrate the improved performance of the two algorithms when
endowed with the proposed off-policy Lyapunov function.

</details>


### [166] [Leveraging Predictions in Power System Voltage Control: An Adaptive Approach](https://arxiv.org/abs/2509.09937)
*Wenqi Cui,Yiheng Xie,Steven Low,Adam Wierman,Baosen Zhang*

Main category: eess.SY

TL;DR: 针对太阳能光伏高波动性和负荷突变导致的配电系统电压波动问题，本文提出了一种自适应电压控制方法。该方法结合短期负荷预测和强化学习，实现了去中心化输入-状态稳定性，有效应对时变净负荷。


<details>
  <summary>Details</summary>
Motivation: 太阳能光伏的高波动性以及电动汽车和储能等负荷的突然变化，会导致配电系统电压大幅波动。现有电压控制器通常假设系统净负荷在足够长的时间内保持不变，这与可再生能源的间歇性和不确定性不符，因此需要显式考虑时变净负荷。

Method: 本文提出了一种自适应电压控制方法，利用短期负荷预测（通过局部测量预测净负荷）将预测结果整合到自适应控制器设计中。该方法证明了整体控制架构能以去中心化方式实现输入-状态稳定性，并通过强化学习优化控制策略。通过真实配电系统的时变负荷数据进行案例研究。

Result: 所提出的整体控制架构以去中心化方式实现了输入-状态稳定性。

Conclusion: 本文提出了一种结合短期负荷预测和强化学习的自适应去中心化电压控制方法，有效应对了具有显著时变净负荷的电力系统中的电压控制挑战，并从理论上证明了其输入-状态稳定性。

Abstract: High variability of solar PV and sudden changes in load (e.g., electric
vehicles and storage) can lead to large voltage fluctuations in the
distribution system. In recent years, a number of controllers have been
designed to optimize voltage control. These controllers, however, almost always
assume that the net load in the system remains constant over a sufficiently
long time, such that the control actions converge before the load changes
again. Given the intermittent and uncertain nature of renewable resources, it
is becoming important to explicitly consider net load that is time-varying.
  This paper proposes an adaptive approach to voltage control in power systems
with significant time-varying net load. We leverage advances in short-term load
forecasting, where the net load in the system can be partially predicted using
local measurements. We integrate these predictions into the design of adaptive
controllers, and prove that the overall control architecture achieves
input-to-state stability in a decentralized manner. We optimize the control
policy through reinforcement learning. Case studies are conducted using
time-varying load data from a real-world distribution system.

</details>


### [167] [Ruggedized Ultrasound Sensing in Harsh Conditions: eRTIS in the wild](https://arxiv.org/abs/2509.10029)
*Dennis Laurijssen,Wouter Jansen,Arne Aerts,Walter Daems,Jan Steckel*

Main category: eess.SY

TL;DR: eRTIS是一种坚固耐用的嵌入式超声波传感系统，专为恶劣工业环境设计，采用宽带电容式换能器和MEMS麦克风阵列，支持2D/3D波束成形，并通过模块化硬件和多种同步选项实现，在实际场景中表现出超越光学系统的鲁棒传感能力。


<details>
  <summary>Details</summary>
Motivation: 需要在恶劣工业环境中进行可靠的传感，特别是光学系统性能下降的场景。

Method: 该系统名为eRTIS，集成宽带电容式换能器和32单元MEMS麦克风阵列，支持2D和3D波束成形。采用模块化硬件架构：高性能微控制器负责激励信号生成和数据采集，NVIDIA Jetson模块进行GPU加速信号处理。通过定制控制器（可同步多达六个设备）、双向触发和带内信号注入实现外部同步。系统采用密封、阳极氧化铝外壳，具有被动冷却和IP级连接器，确保在恶劣条件下的可靠性。

Result: eRTIS在三个实际场景中展示了其性能：港口系泊、越野机器人和杂乱环境中的自主导航。结果表明，eRTIS在光学系统性能下降的情况下也能提供鲁棒的传感能力。

Conclusion: eRTIS系统能够在光学系统受限的恶劣环境中提供可靠且鲁棒的超声波传感解决方案。

Abstract: We present eRTIS, a rugged, embedded ultrasound sensing system for use in
harsh industrial environments. The system features a broadband capacitive
transducer and a 32-element MEMS microphone array capable of 2D and 3D
beamforming. A modular hardware architecture separates sensing and processing
tasks: a high-performance microcontroller handles excitation signal generation
and data acquisition, while an NVIDIA Jetson module performs GPU-accelerated
signal processing. eRTIS supports external synchronization via a custom
controller that powers and coordinates up to six devices, either simultaneously
or in a defined sequence. Additional synchronization options include
bidirectional triggering and in-band signal injection. A sealed, anodized
aluminum enclosure with passive cooling and IP-rated connectors ensures
reliability in challenging conditions. Performance is demonstrated in three
field scenarios: harbor mooring, off-road robotics, and autonomous navigation
in cluttered environments, demonstrates that eRTIS provides robust sensing in
situations where optical systems degrade.

</details>


### [168] [Understanding the Geometry of Faulted Power Systems under High Penetration of Inverter-Based Resources via Ellipse Fitting and Geometric Algebra](https://arxiv.org/abs/2509.10044)
*Jorge Ventura,Jaroslav Hrdina,Aleš Návrat,Marek Stodola,Ahmad Eid,Santiago Sanchez-Acevedo,Francisco G. Montoya*

Main category: eess.SY

TL;DR: 本文提出了一种基于椭圆拟合和几何代数的新方法，用于在高逆变器并网资源（IBR）电力系统中，快速准确地检测和分类电气故障，克服了传统保护方案的局限性。


<details>
  <summary>Details</summary>
Motivation: 在高IBR渗透率的电力系统中，传统保护方案（特别是距离保护）在不对称条件下无法检测相间故障，这构成了重大挑战。

Method: 该方法通过将椭圆拟合到电压矢量数据来表征电气故障，仅需四分之一周期即可检测故障。它使用双矢量分量进行接地故障分类，而椭圆参数用于识别相间和三相故障。几何表示法保留了三维空间中的电压或电流曲线形状，克服了存在零序分量时Clarke变换的局限性。

Result: 通过仿真和实验室实验验证，该方法能够准确识别故障并估计其大小，且检测速度快（仅需四分之一周期）。

Conclusion: 该方法为电力系统保护提供了增强的能力，克服了传统保护方案在高IBR系统中的不足，实现了快速准确的故障检测和分类。

Abstract: Power systems with high penetration of inverter-based resources (IBR) present
significant challenges for conventional protection schemes, with traditional
distance protection methods failing to detect line-to-line faults during
asymmetric conditions. This paper presents a methodology for electrical fault
detection and classification using ellipse fitting and geometric algebra
applied to voltage and current space curves. The approach characterizes
electrical faults by fitting ellipses to voltage vector data, enabling fault
detection with only a quarter-cycle. The method employs bivector components for
line-to-ground fault classification, while ellipse parameters identify
line-to-line and three-phase faults. The geometric representation preserves
voltage or current curve shapes in three-dimensional space, overcoming Clarke
transform limitations when zero-sequence components are present. Validation
using simulations and laboratory experiments demonstrates accurate fault
identification and magnitude estimation, providing enhanced power system
protection capabilities.

</details>


### [169] [Data-driven optimization of sparse sensor placement in thermal hydraulic experiments](https://arxiv.org/abs/2509.10055)
*Xicheng Wang,Yun. Feng,Dmitry Grishchenko,Pavel Kudinov,Ruifeng Tian,Sichao Tan*

Main category: eess.SY

TL;DR: 本文提出了一种数据驱动框架，用于优化热工水力实验中的传感器（如热电偶）放置，以提高数据质量和全场重建精度。


<details>
  <summary>Details</summary>
Motivation: 热工水力实验中的传感器通常分布稀疏，覆盖范围有限，且传感器配置过程常依赖手动和专家判断，效率低且挑战大。因此，需要一种系统化的方法来优化传感器布局。

Method: 该框架包括三个主要步骤：(i) 通过敏感性分析构建数据集，(ii) 利用本征正交分解（POD）进行降维，以及 (iii) 结合列主元QR分解确定在空间约束下的最优传感器配置。

Result: 所提出的框架提供了一种系统化、自动化的传感器放置方法。在TALL-3D铅铋共晶（LBE）回路的案例研究中，优化后的热电偶对不确定输入参数的变化表现出高敏感性，能够实现准确的全场重建，并对测量噪声保持鲁棒性。

Conclusion: 该数据驱动框架为热工水力实验中的传感器优化放置提供了一个系统且自动化的解决方案，显著提升了传感器配置的效率和数据收集的质量，有助于更准确地理解和量化传热传质现象。

Abstract: Thermal-Hydraulic (TH) experiments provide valuable insight into the physics
of heat and mass transfer and qualified data for code development, calibration
and validation. However, measurements are typically collected from sparsely
distributed sensors, offering limited coverage over the domain of interest and
phenomena of interest. Determination of the spatial configuration of these
sensors is crucial and challenging during the pre-test design stage. This paper
develops a data-driven framework for optimizing sensor placement in TH
experiments, including (i) a sensitivity analysis to construct datasets, (ii)
Proper Orthogonal Decomposition (POD) for dimensionality reduction, and (iii)
QR factorization with column pivoting to determine optimal sensor configuration
under spatial constraints. The framework is demonstrated on a test conducted in
the TALL-3D Lead-bismuth eutectic (LBE) loop. In this case, the utilization of
optical techniques, such as Particle Image Velocimetry (PIV), are impractical.
Thereby the quantification of momentum and energy transport relies heavily on
readings from Thermocouples (TCs). The test section was previously instrumented
with many TCs determined through a manual process combining simulation results
with expert judgement. The proposed framework provides a systematic and
automated approach for sensor placement. The resulting TCs exhibit high
sensitivity to the variation of uncertain input parameters and enable accurate
full field reconstruction while maintaining robustness against measurement
noise.

</details>


### [170] [Scalable Synthesis and Verification of String Stable Neural Certificates for Interconnected Systems](https://arxiv.org/abs/2509.10118)
*Jingyuan Zhou,Haoze Wu,Haokun Yu,Kaidi Yang*

Main category: eess.SY

TL;DR: 本文提出了一种验证和综合框架，将离散时间可伸缩输入到状态稳定性（sISS）与神经网络验证相结合，以形式化保证基于学习的互联系统（如车队、无人机编队、微电网）的串行稳定性。


<details>
  <summary>Details</summary>
Motivation: 学习型控制器（如强化学习）在复杂控制场景中表现出色，但其黑盒性质阻碍了串行稳定性的形式化保证，而这对于大规模互联系统的安全性和效率至关重要。

Method: 1. 建立了用于合成和鲁棒验证离散时间sISS证书的正式框架，将其扩展到离散时间设置，构建神经sISS证书，并引入考虑真实动力学与神经近似之间差异的验证程序。2. 建立了将训练和验证流程扩展到大规模互联系统的理论基础和算法。3. 将框架扩展到处理带有外部控制输入的系统，从而实现神经证书和控制器的联合合成与验证。

Result: 数值模拟表明，所提出的框架不仅在控制性能下降最小的情况下保证了sISS，而且能够高效地训练和验证大规模互联系统在特定实际条件下的控制器。该方法在混合自主车队、无人机编队和微电网场景中得到了验证。

Conclusion: 该框架成功地将离散时间sISS与神经网络验证结合，为基于学习的互联系统提供了形式化的串行稳定性保证，同时实现了可伸缩性和良好的控制性能，有效解决了黑盒控制器在安全性保证方面的挑战。

Abstract: Ensuring string stability is critical for the safety and efficiency of
large-scale interconnected systems. Although learning-based controllers (e.g.,
those based on reinforcement learning) have demonstrated strong performance in
complex control scenarios, their black-box nature hinders formal guarantees of
string stability. To address this gap, we propose a novel verification and
synthesis framework that integrates discrete-time scalable input-to-state
stability (sISS) with neural network verification to formally guarantee string
stability in interconnected systems. Our contributions are four-fold. First, we
establish a formal framework for synthesizing and robustly verifying
discrete-time scalable input-to-state stability (sISS) certificates for neural
network-based interconnected systems. Specifically, our approach extends the
notion of sISS to discrete-time settings, constructs neural sISS certificates,
and introduces a verification procedure that ensures string stability while
explicitly accounting for discrepancies between the true dynamics and their
neural approximations. Second, we establish theoretical foundations and
algorithms to scale the training and verification pipeline to large-scale
interconnected systems. Third, we extend the framework to handle systems with
external control inputs, thereby allowing the joint synthesis and verification
of neural certificates and controllers. Fourth, we validate our approach in
scenarios of mixed-autonomy platoons, drone formations, and microgrids.
Numerical simulations show that the proposed framework not only guarantees sISS
with minimal degradation in control performance but also efficiently trains and
verifies controllers for large-scale interconnected systems under specific
practical conditions.

</details>


### [171] [MPC for Aquifer Thermal Energy Storage Systems Using ARX Models](https://arxiv.org/abs/2509.10154)
*Johannes van Randenborgh,Moritz Schulze Darup*

Main category: eess.SY

TL;DR: 本文提出了一种基于轻量级输入-输出数据的自回归外生输入（ARX）模型，用于控制地下水热能存储（ATES）系统，并设计了一个基于输出的模型预测控制（MPC）方案，以简化控制并避免复杂的地下温度状态估计。


<details>
  <summary>Details</summary>
Motivation: 地下水热能存储（ATES）系统能有效减少建筑供暖、通风和空调（HVAC）系统的二氧化碳排放。然而，ATES系统的控制具有挑战性，现有的模型预测控制（MPC）方案通常需要复杂的地下温度状态估计。

Method: 研究提出了一种轻量级的、基于输入-输出数据的自回归外生输入（ARX）模型来描述混合ATES系统的动态。利用该ARX模型设计了一个基于输出的模型预测控制（MPC）方案，该方案可转化为易于求解的二次规划问题，并避免了复杂的地下温度状态估计。

Result: 所提出的ARX模型能够支持基于输出的MPC方案设计，使得控制问题转化为易于求解的二次规划。该方法成功规避了地下温度等具有挑战性的状态估计问题。数值研究讨论了ARX预测器的准确性和控制器性能。

Conclusion: 通过引入轻量级ARX模型和基于输出的MPC方案，可以有效且简化地控制ATES系统，解决了传统MPC在ATES应用中面临的复杂状态估计难题，同时保持了良好的控制性能。

Abstract: An aquifer thermal energy storage (ATES) can mitigate CO2 emissions of
heating, ventilation, and air conditioning (HVAC) systems for buildings. In
application, an ATES keeps large quantities of thermal energy in
groundwater-saturated aquifers. Normally, an ATES system comprises two (one for
heat and one for cold) storages and supports the heating and cooling efforts of
simultaneously present HVAC system components. This way, the operation and
emissions of installed and, usually, fossil fuel-based components are reduced.
  The control of ATES systems is challenging, and various control schemes,
including model predictive control (MPC), have been proposed. In this context,
we present a lightweight input-output-data-based autoregressive with exogenous
input (ARX) model of the hybrid ATES system dynamics. The ARX model allows the
design of an output-based MPC scheme, resulting in an easy-to-solve quadratic
program and avoiding challenging state estimations of ground temperatures. A
numerical study discusses the accuracy of the ARX predictor and controller
performance.

</details>


### [172] [Learning Constraint Surrogate Model for Two-stage Stochastic Unit Commitment](https://arxiv.org/abs/2509.10246)
*Amir Bahador Javadi,Amin Kargarian,Mort Naraghi-Pour*

Main category: eess.SY

TL;DR: 本文提出一种基于机器学习（支持向量机）的代理模型方法，通过重新构造两阶段随机机组组合（TSUC）问题的可行设计空间，显著减少了含可再生能源不确定性的电力系统运行的计算复杂性。


<details>
  <summary>Details</summary>
Motivation: 可再生能源渗透率的增加给电力系统运行带来了显著的不确定性，使得传统的确定性机组组合方法计算成本高昂。因此，需要一种能够降低计算复杂性的方法来有效处理这种不确定性。

Method: 该方法使用支持向量机（SVM）构建代理模型，以替代TSUC问题中原始的2|L| * |S|条输电线路潮流约束（其中|S|是场景数，|L|是线路数），将其简化为1 * |S|条线性不等式约束。该方法基于直流潮流近似下可行区域的多面体结构，并利用计算高效的直流最优潮流模拟生成数据来训练代理模型。

Result: 在IEEE 57和118节点系统上的仿真结果表明，SVM半空间约束精度分别达到99.72%和99.88%。TSUC计算时间分别减少了46%和31%，而发电成本的增加可忽略不计（对于IEEE 57和118节点系统，平均分别仅为0.63%和0.88%）。

Conclusion: 研究结果表明，所提出的方法在应对可再生能源不确定性下的实际电力系统运行中是有效的，能够显著降低计算复杂性，同时保持高精度和可接受的成本影响。

Abstract: The increasing penetration of renewable energy sources introduces significant
uncertainty in power system operations, making traditional deterministic unit
commitment approaches computationally expensive. This paper presents a machine
learning surrogate modeling approach designed to reformulate the feasible
design space of the two-stage stochastic unit commitment (TSUC) problem,
reducing its computational complexity. The proposed method uses a support
vector machine (SVM) to construct a surrogate model based on the governing
equations of the learner. This model replaces the original 2|L| * |S|
transmission line flow constraints, where |S| is the number of uncertainty
scenarios and |L| is the number of transmission lines with |S| much less than
|L|, with a significantly reduced set of 1 * |S| linear inequality constraints.
The approach is theoretically grounded in the polyhedral structure of the
feasible region under the DC power flow approximation, enabling the
transformation of 2|L| line flow limit constraints into a single linear
constraint. The surrogate model is trained using data generated from
computationally efficient DC optimal power flow simulations. Simulation results
on the IEEE 57-bus and 118-bus systems demonstrate SVM halfspace constraint
accuracy of 99.72% and 99.88%, respectively, with TSUC computational time
reductions of 46% and 31% and negligible generation cost increases (0.63% and
0.88% on average for IEEE 57- and 118-bus systems, respectively). This shows
the effectiveness of the proposed approach for practical power system
operations under renewable energy uncertainty.

</details>


### [173] [Data-fused Model Predictive Control with Guarantees: Application to Flying Humanoid Robots](https://arxiv.org/abs/2509.10353)
*Davide Gorbani,Mohamed Elobaid,Giuseppe L'Erario,Hosameldin Awadalla Omer Mohamed,Daniele Pucci*

Main category: eess.SY

TL;DR: 本文提出一种数据融合模型预测控制（DFMPC）框架，结合物理模型和数据驱动的未知动力学表示，实现对变化且可能无法达到的设定点的跟踪，同时通过松弛变量和正则化处理测量噪声。该方法在iRonCub飞行人形机器人上得到验证，显示出比纯模型MPC更好的跟踪和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的模型预测控制（MPC）在面对未知动力学、需要跟踪变化且可能无法达到的设定点以及处理测量噪声时存在挑战。因此，需要一种能够结合物理知识和数据驱动方法来克服这些限制的控制框架。

Method: 该方法引入了数据融合模型预测控制（DFMPC）框架，该框架结合了基于物理的模型和数据驱动的未知动力学表示。它利用了Willems的基本引理和人工平衡公式。通过引入松弛变量和正则化，明确处理了测量噪声。该方法为特定类别的参考信号提供了递归可行性和实际稳定性的保证。

Result: 仿真结果表明，与纯粹基于模型的MPC相比，DFMPC框架在iRonCub飞行人形机器人上实现了更好的跟踪性能和鲁棒性，同时保持了实时可行性。该方法成功地将分析动量模型与数据驱动的涡轮动力学相结合。

Conclusion: 数据融合模型预测控制（DFMPC）框架能够有效地结合物理模型和数据驱动的未知动力学表示，实现对复杂系统中变化和可能无法达到的设定点的跟踪，并在存在测量噪声的情况下表现出良好的性能。该方法在实际应用中具有可行性，并能显著提升控制系统的性能和鲁棒性。

Abstract: This paper introduces a Data-Fused Model Predictive Control (DFMPC) framework
that combines physics-based models with data-driven representations of unknown
dynamics. Leveraging Willems' Fundamental Lemma and an artificial equilibrium
formulation, the method enables tracking of changing, potentially unreachable
setpoints while explicitly handling measurement noise through slack variables
and regularization. We provide guarantees of recursive feasibility and
practical stability under input-output constraints for a specific class of
reference signals. The approach is validated on the iRonCub flying humanoid
robot, integrating analytical momentum models with data-driven turbine
dynamics. Simulations show improved tracking and robustness compared to a
purely model-based MPC, while maintaining real-time feasibility.

</details>


### [174] [Merging Physics-Based Synthetic Data and Machine Learning for Thermal Monitoring of Lithium-ion Batteries: The Role of Data Fidelity](https://arxiv.org/abs/2509.10380)
*Yusheng Zheng,Wenxue Liu,Yunhong Che,Ferdinand Grimm,Jingyuan Zhao,Xiaosong Hu,Simona Onori,Remus Teodorescu,Gregory J. Offer*

Main category: eess.SY

TL;DR: 本文提出了一种结合物理模型和机器学习的新框架，用于高效、可扩展地估计电池内部温度。该框架利用物理模型生成仿真数据进行预训练，并通过无监督域适应的迁移学习，利用有限的实际运行数据（无内部温度标签）进行微调，以弥合仿真与现实之间的差距，实现了高精度。


<details>
  <summary>Details</summary>
Motivation: 由于内部温度难以直接获取，迫切需要开发准确、实时的估计算法，以实现更好的热管理和安全。传统方法在数据收集、模型参数化和估计器设计方面面临挑战。

Method: 该方法将基于物理的模型与机器学习相结合：1) 利用物理模型通过扫掠模型参数和输入配置文件生成包含不同运行场景的仿真数据，用于预训练机器学习算法。2) 应用无监督域适应的迁移学习，利用目标电池有限的运行数据（不含内部温度值）微调预训练的机器学习模型，以弥合仿真与现实之间的差距。

Result: 该框架在不同运行条件和多个圆柱形电池上进行了验证。在仅依赖电池热性能先验知识的情况下，均方根误差为0.5°C；当使用接近真实值的热参数时，均方根误差小于0.1°C。此外，还全面研究了仿真数据质量对框架性能的影响。

Conclusion: 该框架成功地将物理建模与机器学习融合，提供了一种资源高效、可扩展的方法，用于开发准确、鲁棒和自适应的内部温度估计算法，有效解决了传统方法在数据、参数和设计上的挑战，并在有限真实数据下实现了高精度估计。

Abstract: Since the internal temperature is less accessible than surface temperature,
there is an urgent need to develop accurate and real-time estimation algorithms
for better thermal management and safety. This work presents a novel framework
for resource-efficient and scalable development of accurate, robust, and
adaptive internal temperature estimation algorithms by blending physics-based
modeling with machine learning, in order to address the key challenges in data
collection, model parameterization, and estimator design that traditionally
hinder both approaches. In this framework, a physics-based model is leveraged
to generate simulation data that includes different operating scenarios by
sweeping the model parameters and input profiles. Such a cheap simulation
dataset can be used to pre-train the machine learning algorithm to capture the
underlying mapping relationship. To bridge the simulation-to-reality gap
resulting from imperfect modeling, transfer learning with unsupervised domain
adaptation is applied to fine-tune the pre-trained machine learning model, by
using limited operational data (without internal temperature values) from
target batteries. The proposed framework is validated under different operating
conditions and across multiple cylindrical batteries with convective air
cooling, achieving a root mean square error of 0.5 {\deg}C when relying solely
on prior knowledge of battery thermal properties, and less than 0.1 {\deg}C
when using thermal parameters close to the ground truth. Furthermore, the role
of the simulation data quality in the proposed framework has been
comprehensively investigated to identify promising ways of synthetic data
generation to guarantee the performance of the machine learning model.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [175] [Automated Tuning for Diffusion Inverse Problem Solvers without Generative Prior Retraining](https://arxiv.org/abs/2509.09880)
*Yaşar Utku Alçalar,Junno Yun,Mehmet Akçakaya*

Main category: eess.IV

TL;DR: 本文提出ZADS方法，通过在测试时自适应调整扩散模型的数据保真度权重，解决了快速MRI重建中现有方法泛化性差的问题，无需重新训练，并显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 扩散/分数模型在逆问题（如加速MRI重建）中表现强大，但其性能高度依赖于数据保真度权重的精确调优，尤其是在快速采样和少量去噪步骤下。现有方法常依赖启发式或固定权重，导致在不同测量条件和不规则时间步调度下泛化能力不足。

Method: 本文提出“零样本自适应扩散采样”（ZADS），一种测试时优化方法。它将去噪过程视为一个固定的展开采样器，并以自监督方式，仅使用欠采样测量数据，自适应地调整任意噪声调度下的保真度权重，无需重新训练扩散先验模型。

Result: 在fastMRI膝盖数据集上的实验表明，ZADS持续优于传统的压缩感知和近期基于扩散的方法，展示了其在不同噪声调度和采集设置下提供高保真重建的能力。

Conclusion: ZADS提供了一种无需重新训练即可在测试时自适应调整扩散模型保真度权重的方法，显著提高了加速MRI重建的性能和泛化性，克服了现有扩散模型在逆问题中面临的挑战。

Abstract: Diffusion/score-based models have recently emerged as powerful generative
priors for solving inverse problems, including accelerated MRI reconstruction.
While their flexibility allows decoupling the measurement model from the
learned prior, their performance heavily depends on carefully tuned data
fidelity weights, especially under fast sampling schedules with few denoising
steps. Existing approaches often rely on heuristics or fixed weights, which
fail to generalize across varying measurement conditions and irregular timestep
schedules. In this work, we propose Zero-shot Adaptive Diffusion Sampling
(ZADS), a test-time optimization method that adaptively tunes fidelity weights
across arbitrary noise schedules without requiring retraining of the diffusion
prior. ZADS treats the denoising process as a fixed unrolled sampler and
optimizes fidelity weights in a self-supervised manner using only undersampled
measurements. Experiments on the fastMRI knee dataset demonstrate that ZADS
consistently outperforms both traditional compressed sensing and recent
diffusion-based methods, showcasing its ability to deliver high-fidelity
reconstructions across varying noise schedules and acquisition settings.

</details>


### [176] [Accelerating 3D Photoacoustic Computed Tomography with End-to-End Physics-Aware Neural Operators](https://arxiv.org/abs/2509.09894)
*Jiayun Wang,Yousuf Aborahama,Arya Khokhar,Yang Zhang,Chuwei Wang,Karteekeya Sastry,Julius Berner,Yilin Luo,Boris Bonev,Zongyi Li,Kamyar Azizzadenesheli,Lihong V. Wang,Anima Anandkumar*

Main category: eess.IV

TL;DR: Pano是一种端到端、物理感知的神经算子模型，用于光声计算机断层扫描（PACT）的三维重建，它显著减少了所需的传感器数量和采集时间，同时保持了高图像质量，从而提高了PACT的实用性和可及性。


<details>
  <summary>Details</summary>
Motivation: 现有的三维PACT系统需要密集的换能器阵列和长时间的采集，这限制了其临床转化和实际应用。

Method: Pano（PACT成像神经算子）是一个端到端的物理感知模型，直接学习从传感器测量到体素重建的逆声学映射。它采用球形离散-连续卷积以保持半球形传感器几何形状，整合亥姆霍兹方程约束以确保物理一致性，并能独立于分辨率在不同传感器配置下运行。Pano学习物理和数据先验，并且对输入数据分辨率不可知。

Result: Pano在模拟和真实实验数据中都能重建高质量图像，即使在显著减少换能器数量和有限角度采集配置下也能保持一致的性能。该框架在多样化的稀疏采样模式下保持了重建保真度，并实现了实时体素成像能力。

Conclusion: 这项进展为使3D PACT在临床前研究和临床应用中更易于获取和可行奠定了基础，它在不损害图像重建质量的前提下，大幅降低了硬件要求。

Abstract: Photoacoustic computed tomography (PACT) combines optical contrast with
ultrasonic resolution, achieving deep-tissue imaging beyond the optical
diffusion limit. While three-dimensional PACT systems enable high-resolution
volumetric imaging for applications spanning transcranial to breast imaging,
current implementations require dense transducer arrays and prolonged
acquisition times, limiting clinical translation. We introduce Pano (PACT
imaging neural operator), an end-to-end physics-aware model that directly
learns the inverse acoustic mapping from sensor measurements to volumetric
reconstructions. Unlike existing approaches (e.g. universal back-projection
algorithm), Pano learns both physics and data priors while also being agnostic
to the input data resolution. Pano employs spherical discrete-continuous
convolutions to preserve hemispherical sensor geometry, incorporates Helmholtz
equation constraints to ensure physical consistency and operates
resolutionindependently across varying sensor configurations. We demonstrate
the robustness and efficiency of Pano in reconstructing high-quality images
from both simulated and real experimental data, achieving consistent
performance even with significantly reduced transducer counts and limited-angle
acquisition configurations. The framework maintains reconstruction fidelity
across diverse sparse sampling patterns while enabling real-time volumetric
imaging capabilities. This advancement establishes a practical pathway for
making 3D PACT more accessible and feasible for both preclinical research and
clinical applications, substantially reducing hardware requirements without
compromising image reconstruction quality.

</details>


### [177] [Drone-Based Multispectral Imaging and Deep Learning for Timely Detection of Branched Broomrape in Tomato Farms](https://arxiv.org/abs/2509.09972)
*Mohammadreza Narimani,Alireza Pourreza,Ali Moghimi,Mohsen Mesgaran,Parastoo Farajpoor,Hamid Jafarbiglu*

Main category: eess.IV

TL;DR: 本研究结合无人机多光谱图像和LSTM深度学习网络，通过SMOTE技术处理类别不平衡问题，实现了对番茄作物中列当（Phelipanche ramosa）的早期高效检测，为精准农业提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 加州番茄产业（供应美国90%以上加工番茄）正面临分枝列当日益严重的威胁。这种寄生植物的地下生命周期使其难以早期发现，而传统化学防治成本高昂、对环境有害且效果不佳，急需更有效的检测和控制方法。

Method: 研究在已知列当侵染的番茄农场进行，结合无人机多光谱图像和长短期记忆（LSTM）深度学习网络。采用合成少数过采样技术（SMOTE）处理类别不平衡问题。研究覆盖了由生长积温（GDD）确定的五个关键生长阶段，并对多光谱图像进行处理以分离番茄冠层反射率。

Result: 在897 GDD时，未整合后期阶段的列当检测准确率为79.09%，召回率为70.36%。通过LSTM整合顺序生长阶段显著提高了检测能力。最佳方案（整合所有生长阶段并结合SMOTE增强）达到了88.37%的总体准确率和95.37%的召回率。

Conclusion: 这些结果表明，时间多光谱分析和LSTM网络在早期列当检测方面具有巨大潜力。尽管需要进一步的实际数据收集才能进行实际部署，但这项研究证明了基于无人机的多光谱遥感结合深度学习可以为番茄生产提供强大的精准农业工具，以减少损失并提高可持续性。

Abstract: This study addresses the escalating threat of branched broomrape (Phelipanche
ramosa) to California's tomato industry, which supplies over 90 percent of U.S.
processing tomatoes. The parasite's largely underground life cycle makes early
detection difficult, while conventional chemical controls are costly,
environmentally harmful, and often ineffective. To address this, we combined
drone-based multispectral imagery with Long Short-Term Memory (LSTM) deep
learning networks, using the Synthetic Minority Over-sampling Technique (SMOTE)
to handle class imbalance. Research was conducted on a known broomrape-infested
tomato farm in Woodland, Yolo County, CA, across five key growth stages
determined by growing degree days (GDD). Multispectral images were processed to
isolate tomato canopy reflectance. At 897 GDD, broomrape could be detected with
79.09 percent overall accuracy and 70.36 percent recall without integrating
later stages. Incorporating sequential growth stages with LSTM improved
detection substantially. The best-performing scenario, which integrated all
growth stages with SMOTE augmentation, achieved 88.37 percent overall accuracy
and 95.37 percent recall. These results demonstrate the strong potential of
temporal multispectral analysis and LSTM networks for early broomrape
detection. While further real-world data collection is needed for practical
deployment, this study shows that UAV-based multispectral sensing coupled with
deep learning could provide a powerful precision agriculture tool to reduce
losses and improve sustainability in tomato production.

</details>


### [178] [Polarization Denoising and Demosaicking: Dataset and Baseline Method](https://arxiv.org/abs/2509.10098)
*Muhamad Daniel Ariff Bin Abdul Rahman,Yusuke Monno,Masayuki Tanaka,Masatoshi Okutomi*

Main category: eess.IV

TL;DR: 本文针对分焦平面(DoFP)偏振相机图像的去噪和去马赛克联合任务，提出了一种新的数据集和基于“先去噪后去马赛克”策略的基线方法，并验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 分焦平面(DoFP)偏振相机在许多应用中具有重要价值，其图像处理流程包含去噪和去马赛克两个关键任务。尽管无噪声情况下的偏振去马赛克研究日益增多，但由于缺乏合适的评估数据集和可靠的基线方法，对偏振去噪和去马赛克联合任务的研究却非常稀缺。

Method: 本文提出了一个包含40个真实世界场景和三种噪声水平条件的新数据集，该数据集由噪声马赛克输入图像和无噪声完整图像对组成。同时，提出了一种基于“先去噪后去马赛克”策略的方法，该方法利用成熟的信号处理组件，旨在提供可复现的基线。

Result: 实验结果表明，本文提出的方法比其他替代方法展现出更高的图像重建性能，为该领域提供了一个坚实的基线。

Conclusion: 本文成功地为DoFP偏振图像的去噪和去马赛克联合任务提供了新的数据集和高性能的基线方法，填补了该领域研究的空白。

Abstract: A division-of-focal-plane (DoFP) polarimeter enables us to acquire images
with multiple polarization orientations in one shot and thus it is valuable for
many applications using polarimetric information. The image processing pipeline
for a DoFP polarimeter entails two crucial tasks: denoising and demosaicking.
While polarization demosaicking for a noise-free case has increasingly been
studied, the research for the joint task of polarization denoising and
demosaicking is scarce due to the lack of a suitable evaluation dataset and a
solid baseline method. In this paper, we propose a novel dataset and method for
polarization denoising and demosaicking. Our dataset contains 40 real-world
scenes and three noise-level conditions, consisting of pairs of noisy mosaic
inputs and noise-free full images. Our method takes a
denoising-then-demosaicking approach based on well-accepted signal processing
components to offer a reproducible method. Experimental results demonstrate
that our method exhibits higher image reconstruction performance than other
alternative methods, offering a solid baseline.

</details>


### [179] [Soft Tissue Simulation and Force Estimation from Heterogeneous Structures using Equivariant Graph Neural Networks](https://arxiv.org/abs/2509.10125)
*Madina Kojanazarova,Sidady El Hadramy,Jack Wilkie,Georg Rauter,Philippe C. Cattin*

Main category: eess.IV

TL;DR: 该研究提出了一种图神经网络（GNN）模型，用于从稀疏点云预测软组织形变和作用力，其性能与传统物理模型相当，但在实时性、泛化能力和鲁棒性方面表现更优，适用于交互式手术环境。


<details>
  <summary>Details</summary>
Motivation: 在手术训练、术前规划和实时触觉反馈系统中，准确模拟软组织形变至关重要。然而，有限元法（FEM）等基于物理的模型虽然精度高，但计算成本昂贵且需要大量预处理，难以满足实时应用的需求。

Method: 该研究提出了一种图神经网络（GNN）架构，能够从稀疏点云预测组织表面形变和作用力。该模型通过每个点下方的二元组织剖面整合内部解剖信息，并利用E(n)等变消息传递来提高鲁棒性。研究团队收集了真实的硅胶和类骨模型实验数据，并辅以有限元法生成的合成模拟数据进行训练和验证。

Result: 该模型在标准测试案例上达到了与基线GNN相当的性能，但在旋转和跨分辨率场景中显著优于基线模型，显示出对未知方向和点密度的强大泛化能力。它还实现了显著的速度提升，为实时应用提供了解决方案。当在有限的实验数据上进行微调时，尽管样本量有限且存在测量噪声，模型仍保持了亚毫米级的形变精度。

Conclusion: 该方法提供了一种高效、数据驱动的替代方案，可替代传统模拟方法，能够泛化到不同的解剖配置，并支持交互式手术环境，为实时应用提供了可行方案。

Abstract: Accurately simulating soft tissue deformation is crucial for surgical
training, pre-operative planning, and real-time haptic feedback systems. While
physics-based models such as the finite element method (FEM) provide
high-fidelity results, they are often computationally expensive and require
extensive preprocessing. We propose a graph neural network (GNN) architecture
that predicts both tissue surface deformation and applied force from sparse
point clouds. The model incorporates internal anatomical information through
binary tissue profiles beneath each point and leverages E(n)-equivariant
message passing to improve robustness. We collected experimental data that
comprises a real silicone and bone-like phantom, and complemented it with
synthetic simulations generated using FEM. Our model achieves a comparable
performance to a baseline GNN on standard test cases and significantly
outperforms it in rotated and cross-resolution scenarios, showing a strong
generalization to unseen orientations and point densities. It also achieves a
significant speed improvement, offering a solution for real-time applications.
When fine-tuned on experimental data, the model maintains sub-millimeter
deformation accuracy despite limited sample size and measurement noise. The
results demonstrate that our approach offers an efficient, data-driven
alternative to traditional simulations, capable of generalizing across
anatomical configurations and supporting interactive surgical environments.

</details>


### [180] [Multi-pathology Chest X-ray Classification with Rejection Mechanisms](https://arxiv.org/abs/2509.10348)
*Yehudit Aperstein,Amit Tzahar,Alon Gottlib,Tal Verber,Ravit Shagan Damti,Alexander Apartsin*

Main category: eess.IV

TL;DR: 本研究提出了一种基于DenseNet-121的胸部X射线不确定性感知诊断框架，通过引入熵和置信区间选择性拒绝机制，使模型能够放弃不确定预测，从而提高诊断的可靠性，并将模糊病例转交给临床专家处理。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在多标签胸部X射线分类等高风险医学影像任务中过度自信，对同时检测多种并发病理构成重大风险，因此需要提高模型的可靠性并处理不确定性。

Method: 研究采用基于DenseNet-121的骨干网络，并增强了两种选择性预测机制：基于熵的拒绝和基于置信区间的拒绝。通过分位数校准程序（全局或类别特定策略）调整拒绝阈值。实验在PadChest、NIH ChestX-ray14和MIMIC-CXR三个大型公共数据集上进行。

Result: 选择性拒绝改善了诊断准确性和覆盖率之间的权衡。其中，基于熵的拒绝在所有病理上产生了最高的平均AUC。

Conclusion: 研究结果支持将选择性预测集成到AI辅助诊断工作流程中，为在临床环境中安全、不确定性感知地部署深度学习提供了实用步骤。

Abstract: Overconfidence in deep learning models poses a significant risk in
high-stakes medical imaging tasks, particularly in multi-label classification
of chest X-rays, where multiple co-occurring pathologies must be detected
simultaneously. This study introduces an uncertainty-aware framework for chest
X-ray diagnosis based on a DenseNet-121 backbone, enhanced with two selective
prediction mechanisms: entropy-based rejection and confidence interval-based
rejection. Both methods enable the model to abstain from uncertain predictions,
improving reliability by deferring ambiguous cases to clinical experts. A
quantile-based calibration procedure is employed to tune rejection thresholds
using either global or class-specific strategies. Experiments conducted on
three large public datasets (PadChest, NIH ChestX-ray14, and MIMIC-CXR)
demonstrate that selective rejection improves the trade-off between diagnostic
accuracy and coverage, with entropy-based rejection yielding the highest
average AUC across all pathologies. These results support the integration of
selective prediction into AI-assisted diagnostic workflows, providing a
practical step toward safer, uncertainty-aware deployment of deep learning in
clinical settings.

</details>


### [181] [Human Body Segment Volume Estimation with Two RGB-D Cameras](https://arxiv.org/abs/2509.10429)
*Giulia Bassani,Emilio Maoddi,Usman Asghar,Carlo Alberto Avizzano,Alessandro Filippeschi*

Main category: eess.IV

TL;DR: 本文提出了一种名为BSV的身体分段体积估算系统，仅使用两台RGB-D相机，通过改进的ARAP非刚性配准技术，实现了与3D激光扫描仪相当的全身和分段体积估算精度。


<details>
  <summary>Details</summary>
Motivation: 在人体生物计量学中，准确估算全身及其各个分段的体积至关重要，这支持健康评估、人体工程学优化和生物力学模型定制等广泛应用。

Method: 该系统使用两台RGB-D相机以降低复杂性。为保持与3D激光扫描仪相当的精度，研究人员增强了As-Rigid-As-Possible (ARAP) 非刚性配准技术，将其能量与单一三角形网格分离，从而改善了重建网格的几何连贯性，尤其是在侧向间隙区域。

Result: 通过评估RGB-D相机性能、FAUST数据集人体模型、与现有先进工作的比较以及实际采集数据，BSV系统在准确估算人体体积方面表现出卓越的能力，并且能够评估近端和远端身体分段之间的体积比，这在许多临床应用中是重要的指标。

Conclusion: BSV系统能够准确估算人体体积，并提供有用的分段体积比，为临床应用提供有价值的指标，同时通过简化硬件（两台RGB-D相机）保持了高精度，可作为复杂3D激光扫描仪的有效替代方案。

Abstract: In the field of human biometry, accurately estimating the volume of the whole
body and its individual segments is of fundamental importance. Such
measurements support a wide range of applications that include assessing
health, optimizing ergonomic design, and customizing biomechanical models. In
this work, we presented a Body Segment Volume Estimation (BSV) system to
automatically compute whole-body and segment volumes using only two RGB-D
cameras, thus limiting the system complexity. However, to maintain the accuracy
comparable to 3D laser scanners, we enhanced the As-Rigid-As-Possible (ARAP)
non-rigid registration techniques, disconnecting its energy from the single
triangle mesh. Thus, we improved the geometrical coherence of the reconstructed
mesh, especially in the lateral gap areas. We evaluated BSV starting from the
RGB-D camera performances, through the results obtained with FAUST dataset
human body models, and comparing with a state-of-the-art work, up to real
acquisitions. It showed superior ability in accurately estimating human body
volumes, and it allows evaluating volume ratios between proximal and distal
body segments, which are useful indices in many clinical applications.

</details>
