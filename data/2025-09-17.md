<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 43]
- [cs.CV](#cs.CV) [Total: 109]
- [cs.CL](#cs.CL) [Total: 45]
- [cs.RO](#cs.RO) [Total: 50]
- [eess.SY](#eess.SY) [Total: 17]
- [eess.IV](#eess.IV) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [V-Math: An Agentic Approach to the Vietnamese National High School Graduation Mathematics Exams](https://arxiv.org/abs/2509.12251)
*Duong Q. Nguyen,Quy P. Nguyen,Nguyen Van Nhon,Quang-Thinh Bui,H. Nguyen-Xuan*

Main category: cs.AI

TL;DR: V-Math是一个自主智能代理框架，旨在帮助越南高中生准备数学毕业考试，并通过生成问题和提供个性化辅导来支持学生和教师。


<details>
  <summary>Details</summary>
Motivation: 帮助越南高中生准备全国高中毕业数学考试；减轻教师手动出题的工作量；丰富教学资源并提供多样化、高质量的题库。

Method: 该框架集成了三个专门的AI代理：一个基于规格矩阵的问题生成器、一个提供详细分步推理的解题/解释器，以及一个根据学生表现调整的个性化辅导器。它支持学生自主练习模式和教师的出题功能。

Result: 初步评估表明，V-Math能生成与矩阵对齐的考题，具有高解题准确性，提供连贯的解释，并增加了练习材料的多样性。

Conclusion: V-Math有潜力支持符合国家标准的、可扩展和公平的数学备考，并通过AI辅助考试创建来赋能教师。

Abstract: This paper develops an autonomous agentic framework called V-Math that aims
to assist Vietnamese high school students in preparing for the National High
School Graduation Mathematics Exams (NHSGMEs). The salient framework integrates
three specialized AI agents: a specification-matrix-conditioned question
generator, a solver/explainer for detailed step-by-step reasoning, and a
personalized tutor that adapts to student performance. Beyond enabling
self-paced student practice, V-Math supports teachers by generating innovative,
compliant exam questions and building diverse, high-quality question banks.
This reduces manual workload and enriches instructional resources. We describe
the system architecture, focusing on practice modes for learners and
teacher-oriented features for question generation. Preliminary evaluations
demonstrate that V-Math produces matrix-aligned exams with high solution
accuracy, delivers coherent explanations, and enhances the variety of practice
materials. These results highlight its potential to support scalable, equitable
mathematics preparation aligned with national standards while also empowering
teachers through AI-assisted exam creation.

</details>


### [2] [DISPLIB: a library of train dispatching problems](https://arxiv.org/abs/2509.12254)
*Oddvar Kloster,Bjørnar Luteberget,Carlo Mannino,Giorgio Sartor*

Main category: cs.AI

TL;DR: 本文介绍了DISPLIB，一个用于列车重新调度和重新路由问题的通用问题定义、文件格式、工业实例和参考求解器，旨在促进可重复性、算法比较和开放研究。


<details>
  <summary>Details</summary>
Motivation: 优化决策支持系统在减少列车延误方面潜力巨大，但现有研究通常与特定工业应用紧密相连，代码和数据很少公开共享。这阻碍了研究的可重复性，导致算法难以比较其相对性能，因为问题定义不兼容。

Method: 受MILP、SAT、TSP、VRP等成功社区的启发，本文引入了一个名为DISPLIB的通用问题定义和文件格式，它捕获了列车重新调度和重新路由的所有主要特征。同时，收集了多个真实工业案例的问题实例并公开可用，并提供了一个参考求解器实现。

Result: 本文描述了DISPLIB问题定义、工业实例和参考求解器实现。所有材料均在线公开，使任何研究人员或开发者无需工业背景即可研究列车调度问题，并使研究社区能够对求解器进行实证比较。

Conclusion: DISPLIB的推出，通过提供通用问题定义、文件格式、真实实例和参考求解器，极大地促进了列车调度优化领域的可重复性、开放研究和算法之间的实证比较。

Abstract: Optimization-based decision support systems have a significant potential to
reduce delays, and thus improve efficiency on the railways, by automatically
re-routing and re-scheduling trains after delays have occurred. The operations
research community has dedicated a lot of effort to developing optimization
algorithms for this problem, but each study is typically tightly connected with
a specific industrial use case. Code and data are seldom shared publicly. This
fact hinders reproducibility, and has led to a proliferation of papers
describing algorithms for more or less compatible problem definitions, without
any real opportunity for readers to assess their relative performance. Inspired
by the successful communities around MILP, SAT, TSP, VRP, etc., we introduce a
common problem definition and file format, DISPLIB, which captures all the main
features of train re-routing and re-scheduling. We have gathered problem
instances from multiple real-world use cases and made them openly available. In
this paper, we describe the problem definition, the industrial instances, and a
reference solver implementation. This allows any researcher or developer to
work on the train dispatching problem without an industrial connection, and
enables the research community to perform empirical comparisons between
solvers. All materials are available online at https://displib.github.io.

</details>


### [3] [InPhyRe Discovers: Large Multimodal Models Struggle in Inductive Physical Reasoning](https://arxiv.org/abs/2509.12263)
*Gautam Sreekumar,Vishnu Naresh Boddeti*

Main category: cs.AI

TL;DR: 本文提出了InPhyRe，首个用于评估大型多模态模型（LMMs）归纳物理推理能力的视觉问答基准。研究发现LMMs在该能力上表现不佳，尤其是在物理定律被违反时，且存在语言偏见。


<details>
  <summary>Details</summary>
Motivation: LMMs的参数化知识不足以应对违反已知物理定律的推理场景，而人类具备从少量视觉示例中适应新物理环境的归纳物理推理能力。现有视觉基准只评估LMMs的参数化知识，未能衡量其归纳物理推理能力，这对于LMMs在安全关键应用中的部署至关重要。

Method: 提出了InPhyRe，一个视觉问答基准，通过算法生成的合成碰撞视频来评估LMMs预测碰撞事件结果的能力，以此衡量其归纳物理推理水平。

Result: 对13个LMMs的测试结果表明：(1) LMMs难以将有限的通用物理定律参数化知识应用于推理；(2) 当演示样本违反通用物理定律时，LMMs的归纳物理推理能力很弱；(3) LMMs的归纳物理推理受语言偏见影响，在很大程度上忽略了视觉输入，对其视觉输入的可靠性提出质疑。

Conclusion: LMMs的归纳物理推理能力尚弱，尤其是在物理定律被违反的情况下。此外，它们在推理过程中存在语言偏见，倾向于忽略视觉输入，这使得LMMs在需要高度信任视觉信息的应用中存在风险。

Abstract: Large multimodal models (LMMs) encode universal physical laws observed during
training, such as momentum conservation, as parametric knowledge. It allows
LMMs to answer physical reasoning queries, such as the outcome of a potential
collision event from visual input. However, since parametric knowledge includes
only the physical laws seen during training, it is insufficient for reasoning
when the inference scenario violates these physical laws. In contrast, humans
possess the skill to adapt their physical reasoning to unseen physical
environments from a few visual examples. This ability, which we refer to as
inductive physical reasoning, is indispensable for LMMs if they are to replace
human agents in safety-critical applications. Despite its importance, existing
visual benchmarks evaluate only the parametric knowledge in LMMs, and not
inductive physical reasoning. To this end, we propose InPhyRe, the first visual
question answering benchmark to measure inductive physical reasoning in LMMs.
InPhyRe evaluates LMMs on their ability to predict the outcome of collision
events in algorithmically generated synthetic collision videos. By inspecting
13 LMMs, InPhyRe informs us that (1) LMMs struggle to apply their limited
parametric knowledge about universal physical laws to reasoning, (2) inductive
physical reasoning in LMMs is weak when demonstration samples violate universal
physical laws, and (3) inductive physical reasoning in LMMs suffers from
language bias and largely ignores the visual inputs, questioning the
trustworthiness of LMMs regarding visual inputs.

</details>


### [4] [LLMAP: LLM-Assisted Multi-Objective Route Planning with User Preferences](https://arxiv.org/abs/2509.12273)
*Liangqi Yuan,Dong-Jun Han,Christopher G. Brinton,Sabine Brunswicker*

Main category: cs.AI

TL;DR: 本文提出了一种名为LLMAP的新型LLM辅助路径规划系统。该系统利用LLM作为解析器来理解自然语言偏好和任务依赖，并结合多步图构建与迭代搜索（MSGS）算法进行多目标优化，以解决现有方法在处理大规模地图数据和自然语言理解方面的局限性，同时应对用户时空分布的异质性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的兴起，自然语言驱动的路径规划成为新兴研究领域。然而，现有方法存在局限：直接使用LLM作为Agent难以处理大量地图数据，而基于图的搜索策略在理解自然语言偏好方面能力有限。此外，全球用户高度异构且不可预测的时空分布带来了关键挑战。

Method: 本文引入了LLM辅助路径规划（LLMAP）系统。该系统采用：1) 一个LLM作为解析器（LLM-as-Parser），用于理解自然语言、识别任务、提取用户偏好和识别任务依赖；2) 一个多步图构建与迭代搜索（MSGS）算法作为底层求解器，用于寻找最优路径。系统采用多目标优化方法，自适应调整目标权重，以最大化兴趣点（POI）质量和任务完成率，同时最小化路线距离，并受用户时间限制、POI开放时间和任务依赖这三个关键约束。

Result: 研究团队在全球14个国家和27个城市，使用1,000个不同复杂度的路由提示进行了广泛实验。结果表明，所提出的方法在多个约束条件下实现了卓越的性能。

Conclusion: LLMAP系统通过结合LLM的自然语言理解能力和强大的图搜索算法，有效解决了自然语言驱动路径规划中的挑战，并在多重约束下实现了优异的路径规划性能。

Abstract: The rise of large language models (LLMs) has made natural language-driven
route planning an emerging research area that encompasses rich user objectives.
Current research exhibits two distinct approaches: direct route planning using
LLM-as-Agent and graph-based searching strategies. However, LLMs in the former
approach struggle to handle extensive map data, while the latter shows limited
capability in understanding natural language preferences. Additionally, a more
critical challenge arises from the highly heterogeneous and unpredictable
spatio-temporal distribution of users across the globe. In this paper, we
introduce a novel LLM-Assisted route Planning (LLMAP) system that employs an
LLM-as-Parser to comprehend natural language, identify tasks, and extract user
preferences and recognize task dependencies, coupled with a Multi-Step Graph
construction with iterative Search (MSGS) algorithm as the underlying solver
for optimal route finding. Our multi-objective optimization approach adaptively
tunes objective weights to maximize points of interest (POI) quality and task
completion rate while minimizing route distance, subject to three key
constraints: user time limits, POI opening hours, and task dependencies. We
conduct extensive experiments using 1,000 routing prompts sampled with varying
complexity across 14 countries and 27 cities worldwide. The results demonstrate
that our approach achieves superior performance with guarantees across multiple
constraints.

</details>


### [5] [Developing an aeroponic smart experimental greenhouse for controlling irrigation and plant disease detection using deep learning and IoT](https://arxiv.org/abs/2509.12274)
*Mohammadreza Narimani,Ali Hajiahmad,Ali Moghimi,Reza Alimardani,Shahin Rafiee,Amir Hossein Mirzabe*

Main category: cs.AI

TL;DR: 本研究开发并测试了一个智能气培温室，通过物联网（IoT）连续监测环境条件，并利用人工智能（AI）框架（基于VGG-19、InceptionResNetV2和InceptionV3）检测植物病害，以优化作物生产。


<details>
  <summary>Details</summary>
Motivation: 在温室中控制环境条件和监测植物状态对于及时做出适当的管理决策以促进作物生产至关重要。

Method: 研究开发了一个基于IoT的平台，用于持续监测和控制温室环境条件。此外，还开发了一个基于AI的疾病检测框架，利用VGG-19、InceptionResNetV2和InceptionV3算法，分析有意接种后定期捕获的图像。AI框架的性能与专家对疾病状态的评估进行了比较。

Result: 初步结果显示，IoT系统能够持续在线发布温度、湿度、水流量和充电罐容量等数据，并调整受控参数以提供最佳植物生长环境。AI框架的结果表明，VGG-19算法在识别干旱胁迫和锈病叶片方面表现出最高准确率（92%），优于其他算法。

Conclusion: 集成的IoT系统能够有效监测和控制温室环境，而AI框架（特别是VGG-19）能够准确检测植物病害，为智能温室管理和优化作物生产提供了可行方案。

Abstract: Controlling environmental conditions and monitoring plant status in
greenhouses is critical to promptly making appropriate management decisions
aimed at promoting crop production. The primary objective of this research
study was to develop and test a smart aeroponic greenhouse on an experimental
scale where the status of Geranium plant and environmental conditions are
continuously monitored through the integration of the internet of things (IoT)
and artificial intelligence (AI). An IoT-based platform was developed to
control the environmental conditions of plants more efficiently and provide
insights to users to make informed management decisions. In addition, we
developed an AI-based disease detection framework using VGG-19,
InceptionResNetV2, and InceptionV3 algorithms to analyze the images captured
periodically after an intentional inoculation. The performance of the AI
framework was compared with an expert's evaluation of disease status.
Preliminary results showed that the IoT system implemented in the greenhouse
environment is able to publish data such as temperature, humidity, water flow,
and volume of charge tanks online continuously to users and adjust the
controlled parameters to provide an optimal growth environment for the plants.
Furthermore, the results of the AI framework demonstrate that the VGG-19
algorithm was able to identify drought stress and rust leaves from healthy
leaves with the highest accuracy, 92% among the other algorithms.

</details>


### [6] [AIssistant: An Agentic Approach for Human--AI Collaborative Scientific Work on Reviews and Perspectives in Machine Learning](https://arxiv.org/abs/2509.12282)
*Sasi Kiran Gaddipati,Farhana Keya,Gollam Rabby,Sören Auer*

Main category: cs.AI

TL;DR: 本文介绍了一个名为AIssistant的开源人机协作框架，旨在简化科学工作流程的端到端创建，提高论文草稿的效率和主题一致性，同时强调人工监督在确保准确性和合规性方面的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI辅助研究工具存在碎片化且缺乏以人为中心的工作流程的问题。

Method: 本文提出了AIssistant，一个代理式、开源的人机协作框架，集成了文献合成、分节实验、引用管理和自动LaTeX文本生成等模块化工具，并全程保持人工监督。评估通过三个层面进行：独立人工评审、自动化大型语言模型（LLM）评审（使用GPT-5作为代理）以及程序主席监督。

Result: 结果表明，AIssistant提高了草稿撰写效率和主题一致性。然而，人机协作对于保持事实正确性、方法严谨性和伦理合规性至关重要。研究也指出了关键局限性，包括幻觉引用、难以适应动态论文结构以及多模态内容集成不完整。

Conclusion: AIssistant在提高科学论文草稿效率方面表现出有效性，但人机协作在确保准确性、严谨性和合规性方面仍然不可或缺。未来的工作应解决幻觉引用和多模态内容集成等现有局限性。

Abstract: Advances in AI-assisted research have introduced powerful tools for
literature retrieval, hypothesis generation, experimentation, and manuscript
preparation. However, systems remain fragmented and lack human-centred
workflows. To address these gaps, we introduce AIssistant, an agentic,
open-source Human-AI collaborative framework designed to simplify the
end-to-end creation of scientific workflows. Since our development is still in
an early stage, we present here the first experiments with AIssistant for
perspective and review research papers in machine learning. Our system
integrates modular tools and agents for literature synthesis, section-wise
experimentation, citation management, and automatic LaTeX paper text
generation, while maintaining human oversight at every stage to ensure
accuracy, coherence, and scholarly rigour. We conducted a comprehensive
evaluation across three layers: (1) Independent Human Review, following NeurIPS
double-blind standards; (2) Automated LLM Review, using GPT-5 as a scalable
human review proxy; and (3) Program Chair Oversight, where the chair monitors
the entire review process and makes final validation and acceptance decisions.
The results demonstrate that AIssistant improves drafting efficiency and
thematic consistency. Nonetheless, Human-AI collaboration remains essential for
maintaining factual correctness, methodological soundness, and ethical
compliance. Despite its effectiveness, we identify key limitations, including
hallucinated citations, difficulty adapting to dynamic paper structures, and
incomplete integration of multimodal content.

</details>


### [7] [Small Models, Big Results: Achieving Superior Intent Extraction through Decomposition](https://arxiv.org/abs/2509.12423)
*Danielle Cohen,Yoni Halpern,Noam Kahlon,Joel Oren,Omri Berkovitch,Sapir Caduri,Ido Dagan,Anatoly Efros*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的分解方法，通过结构化交互摘要和意图提取，显著提高了资源受限模型理解用户意图的能力，甚至超越了大型多模态语言模型的基础性能。


<details>
  <summary>Details</summary>
Motivation: 理解用户界面交互轨迹中的用户意图对于智能代理开发至关重要，但对需要隐私保护、低成本、低延迟的设备端小型模型来说，准确推断意图仍面临挑战，因为它们难以处理复杂序列。

Method: 该研究采用了一种分解方法：首先，进行结构化交互摘要，从每个用户动作中捕获关键信息；其次，使用一个在聚合摘要上运行的微调模型进行意图提取。

Result: 该方法显著改善了资源受限模型中的意图理解能力，甚至超越了大型多模态语言模型（MLLMs）的基础性能。

Conclusion: 所提出的分解方法为设备端模型提供了一种有效且高性能的解决方案，以克服在隐私保护、低成本和低延迟场景下准确理解用户意图的挑战。

Abstract: Understanding user intents from UI interaction trajectories remains a
challenging, yet crucial, frontier in intelligent agent development. While
massive, datacenter-based, multi-modal large language models (MLLMs) possess
greater capacity to handle the complexities of such sequences, smaller models
which can run on-device to provide a privacy-preserving, low-cost, and
low-latency user experience, struggle with accurate intent inference. We
address these limitations by introducing a novel decomposed approach: first, we
perform structured interaction summarization, capturing key information from
each user action. Second, we perform intent extraction using a fine-tuned model
operating on the aggregated summaries. This method improves intent
understanding in resource-constrained models, even surpassing the base
performance of large MLLMs.

</details>


### [8] [Building Coding Agents via Entropy-Enhanced Multi-Turn Preference Optimization](https://arxiv.org/abs/2509.12434)
*Jiahao Yu,Zelei Cheng,Xian Wu,Xinyu Xing*

Main category: cs.AI

TL;DR: 本文提出了一种名为 \sys 的熵增强框架，旨在改进大型语言模型（LLMs）在复杂软件工程任务上的表现。该框架通过增强偏好优化算法以保留策略多样性并适应多轮交互和工具使用，在 SWE-bench 基准测试中取得了开源模型的最新 SOTA 结果。


<details>
  <summary>Details</summary>
Motivation: LLMs 在需要推理大型代码库和协调工具使用的复杂、多步软件工程任务（如 SWE-bench）上表现不佳。测试时扩展（TTS）是一种有前景的方法，但其效果严重依赖于模型输出的多样性。然而，现有的偏好优化方法（如 DPO、KTO）在使模型输出与人类偏好对齐的同时，可能会降低多样性，从而限制 TTS 的有效性。此外，现有算法主要针对单轮任务设计，未能充分解决交互式编码代理所需的多轮推理和工具集成的复杂性。

Method: 本文引入了 \sys 框架，该框架将现有偏好优化算法调整为多轮、工具辅助设置。\sys 通过明确保留策略熵来增强偏好目标，并将学习推广到优化多轮交互而非单轮响应。为了最大化 TTS 的性能增益，作者还提出了一种结合学习验证模型和无模型方法的混合最佳轨迹选择方案。该方法通过微调不同系列和规模（高达 106B 参数）的模型进行了验证。

Result: 在 SWE-bench 排行榜上，\sys 方法在开源模型中取得了新的 SOTA 结果。一个使用 \sys 训练的 30B 参数模型在 \lite 上排名第一，在 \verified 上排名第四，仅次于参数量超过 10 倍（例如 >350B）的模型。

Conclusion: \sys 框架通过在偏好优化中引入熵增强以保持多样性，并将其推广到多轮、工具辅助的交互中，成功解决了 LLMs 在复杂软件工程任务中面临的挑战。这使得开源模型在 SWE-bench 基准测试中取得了显著的性能提升，证明了该方法在提升 LLMs 解决真实世界软件问题能力方面的有效性。

Abstract: Software engineering presents complex, multi-step challenges for Large
Language Models (LLMs), requiring reasoning over large codebases and
coordinated tool use. The difficulty of these tasks is exemplified by
benchmarks like SWE-bench, where current LLMs still struggle to resolve
real-world issues.
  A promising approach to enhance performance is test-time scaling (TTS), but
its gains are heavily dependent on the diversity of model outputs.
  While standard alignment methods such as Direct Preference Optimization (DPO)
and Kahneman-Tversky Optimization (KTO) are effective at aligning model outputs
with human preferences, this process can come at the cost of reduced diversity,
limiting the effectiveness of TTS.
  Additionally, existing preference optimization algorithms are typically
designed for single-turn tasks and do not fully address the complexities of
multi-turn reasoning and tool integration required for interactive coding
agents.
  To bridge this gap, we introduce \sys, an entropy-enhanced framework that
adapts existing preference optimization algorithms to the multi-turn,
tool-assisted setting.
  \sys augments the preference objective to explicitly preserve policy entropy
and generalizes learning to optimize over multi-turn interactions rather than
single-turn responses.
  We validate \sys by fine-tuning a diverse suite of models from different
families and sizes (up to 106B parameters).
  To maximize performance gains from TTS, we further propose a hybrid
best-trajectory selection scheme combining a learned verifier model with model
free approaches.
  On the \swebench leaderboard, our approach establishes new state-of-the-art
results among open-weight models. A 30B parameter model trained with \sys ranks
1st on \lite and 4th on \verified on the open-weight leaderboard, surpassed
only by models with over 10x more parameters(\eg$>$350B).

</details>


### [9] [Enhancing Physical Consistency in Lightweight World Models](https://arxiv.org/abs/2509.12437)
*Dingrui Wang,Zhexiao Sun,Zhouheng Li,Cheng Wang,Youlun Peng,Hongyuan Ye,Baha Zarrouki,Wei Li,Mattia Piccinini,Lei Xie,Johannes Betz*

Main category: cs.AI

TL;DR: 本文提出了一种紧凑的物理信息BEV世界模型（PIWM），通过Soft Mask和Warm Start技术，在保持小尺寸的同时显著提升了预测性能和推理速度，解决了世界模型在边缘设备部署中的大小与性能权衡问题。


<details>
  <summary>Details</summary>
Motivation: 部署世界模型面临主要挑战：大型模型能捕捉丰富物理动态但计算资源消耗巨大，不适用于边缘设备；小型模型易于部署但难以准确学习物理，导致预测不佳。

Method: 本文提出了物理信息BEV世界模型（PIWM）。它在训练过程中使用Soft Mask来改进动态对象建模和未来预测。此外，还引入了一种简单有效的Warm Start技术用于推理，以零样本模型提高预测质量。

Result: 实验结果显示，在相同参数规模（400M）下，PIWM的加权总分比基线高出60.6%。即使与最大的基线模型（400M）相比，最小的PIWM（130M Soft Mask）也能实现7.4%更高的加权总分，且推理速度快28%。

Conclusion: PIWM成功地解决了世界模型在尺寸和性能之间的权衡问题，通过紧凑的设计和创新的技术，在边缘设备上实现了卓越的物理交互捕捉能力和预测性能，同时保持了高效的推理速度。

Abstract: A major challenge in deploying world models is the trade-off between size and
performance. Large world models can capture rich physical dynamics but require
massive computing resources, making them impractical for edge devices. Small
world models are easier to deploy but often struggle to learn accurate physics,
leading to poor predictions. We propose the Physics-Informed BEV World Model
(PIWM), a compact model designed to efficiently capture physical interactions
in bird's-eye-view (BEV) representations. PIWM uses Soft Mask during training
to improve dynamic object modeling and future prediction. We also introduce a
simple yet effective technique, Warm Start, for inference to enhance prediction
quality with a zero-shot model. Experiments show that at the same parameter
scale (400M), PIWM surpasses the baseline by 60.6% in weighted overall score.
Moreover, even when compared with the largest baseline model (400M), the
smallest PIWM (130M Soft Mask) achieves a 7.4% higher weighted overall score
with a 28% faster inference speed.

</details>


### [10] [Reasoning Models Can be Accurately Pruned Via Chain-of-Thought Reconstruction](https://arxiv.org/abs/2509.12464)
*Ryan Lucas,Kayhan Behdin,Zhipeng Wang,Qingquan Song,Shao Tang,Rahul Mazumder*

Main category: cs.AI

TL;DR: 推理语言模型因长链式思考轨迹部署成本高。传统压缩方法效果差甚至更慢。本文提出“推理感知压缩”（RAC），通过联合重构输入和链式思考轨迹的激活来改进剪枝，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: DeepSeek-R1等推理语言模型在推理时产生冗长的链式思考（CoT）轨迹，导致部署成本高昂。传统的神经网络剪枝等压缩技术在推理任务上表现不佳，甚至可能使模型变慢，因为它们导致模型生成更多思考token但性能更差。这部分原因是标准LLM剪枝方法侧重于输入重构，而推理是解码主导的任务。

Method: 本文提出了一种名为“推理感知压缩”（Reasoning-Aware Compression, RAC）的简单即插即用修复方案。RAC在剪枝过程中联合重构来自输入和模型在策略链式思考轨迹的激活。该方法可以无缝集成到现有的剪枝工作流中，例如SparseGPT。

Result: 传统压缩技术（如剪枝）在推理语言模型上会导致比典型语言建模任务更大的性能损失，甚至可能使模型变慢，因为它导致模型生成更多思考token但性能更差。而RAC显著提升了现有剪枝工作流（如SparseGPT）的性能。

Conclusion: 推理感知压缩（RAC）通过在剪枝过程中联合重构输入和模型链式思考轨迹的激活，有效解决了推理语言模型部署成本高的问题，并显著提高了压缩性能，表明在推理任务中考虑解码过程中的激活重构对于有效的模型压缩至关重要。

Abstract: Reasoning language models such as DeepSeek-R1 produce long chain-of-thought
traces during inference time which make them costly to deploy at scale. We show
that using compression techniques such as neural network pruning produces
greater performance loss than in typical language modeling tasks, and in some
cases can make the model slower since they cause the model to produce more
thinking tokens but with worse performance. We show that this is partly due to
the fact that standard LLM pruning methods often focus on input reconstruction,
whereas reasoning is a decode-dominated task. We introduce a simple, drop-in
fix: during pruning we jointly reconstruct activations from the input and the
model's on-policy chain-of-thought traces. This "Reasoning-Aware Compression"
(RAC) integrates seamlessly into existing pruning workflows such as SparseGPT,
and boosts their performance significantly. Code reproducing the results in the
paper can be found at: https://github.com/RyanLucas3/RAC

</details>


### [11] [Empowering Clinical Trial Design through AI: A Randomized Evaluation of PowerGPT](https://arxiv.org/abs/2509.12471)
*Yiwen Lu,Lu Li,Dazheng Zhang,Xinyao Jian,Tingyin Wang,Siqi Chen,Yuqing Lei,Jiayi Tong,Zhaohan Xi,Haitao Chu,Chongliang Luo,Alexis Ogdie,Brian Athey,Alparslan Turan,Michael Abramoff,Joseph C Cappelleri,Hua Xu,Yun Lu,Jesse Berlin,Daniel I. Sessler,David A. Asch,Xiaoqian Jiang,Yong Chen*

Main category: cs.AI

TL;DR: PowerGPT是一个AI系统，结合大语言模型和统计引擎，自动化临床试验中的统计检验选择和样本量计算，显著提升了任务完成率、准确性并缩短了时间。


<details>
  <summary>Details</summary>
Motivation: 临床研究和试验设计中的样本量计算对于功效分析至关重要，但其复杂性及对统计专业知识的依赖对许多研究人员构成了障碍。

Method: PowerGPT是一个AI驱动的系统，它将大语言模型（LLMs）与统计引擎集成，以自动化试验设计中的检验选择和样本量估计。通过一项随机对照试验评估其有效性。

Result: PowerGPT显著提高了任务完成率（检验选择：99.3% vs 88.9%；样本量计算：99.3% vs 77.8%）和准确性（样本量估计：94.1% vs 55.4%，p < 0.001），同时减少了平均完成时间（4.0分钟 vs 9.3分钟，p < 0.001）。这些改进在各种统计检验中均保持一致，并惠及统计学家和非统计学家，弥合了专业知识差距。

Conclusion: PowerGPT代表了一种可扩展的AI驱动方法，提高了临床研究中统计功效分析的可及性、效率和准确性，并已在多个机构部署。

Abstract: Sample size calculations for power analysis are critical for clinical
research and trial design, yet their complexity and reliance on statistical
expertise create barriers for many researchers. We introduce PowerGPT, an
AI-powered system integrating large language models (LLMs) with statistical
engines to automate test selection and sample size estimation in trial design.
In a randomized trial to evaluate its effectiveness, PowerGPT significantly
improved task completion rates (99.3% vs. 88.9% for test selection, 99.3% vs.
77.8% for sample size calculation) and accuracy (94.1% vs. 55.4% in sample size
estimation, p < 0.001), while reducing average completion time (4.0 vs. 9.3
minutes, p < 0.001). These gains were consistent across various statistical
tests and benefited both statisticians and non-statisticians as well as
bridging expertise gaps. Already under deployment across multiple institutions,
PowerGPT represents a scalable AI-driven approach that enhances accessibility,
efficiency, and accuracy in statistical power analysis for clinical research.

</details>


### [12] [Physical Complexity of a Cognitive Artifact](https://arxiv.org/abs/2509.12495)
*Gülce Kardeş,David Krakauer,Joshua Grochow*

Main category: cs.AI

TL;DR: 本文通过“物质性原则”将索玛立方体的计算复杂性与认知问题解决策略联系起来，量化了任务难度，并分析了不同认知策略如何通过利用物理约束来降低复杂性，提出了一种结合心智与物质能力的智能模型。


<details>
  <summary>Details</summary>
Motivation: 认知科学和理论计算机科学都致力于分类和解释任务的难度，并理解智能机制如何降低这些难度。

Method: 研究者将索玛立方体这一物理谜题的计算复杂性概念映射到认知问题解决策略上，提出了“物质性原则”。通过分析谜题的搜索树出度（分支因子）来量化任务难度，并系统地考察了预处理（认知组块）、价值排序（认知自由分类）、变量排序（认知支架）和剪枝（认知推理）等策略如何逐步优化试错搜索，从而修改复杂性。此外，还探讨了人工制品如何通过利用物理约束来降低有效时间复杂性。

Result: 研究表明，通过分层应用预处理、价值排序、变量排序和剪枝等认知策略，可以逐步优化试错搜索。熟练使用人工制品能够通过利用物理约束来有效降低任务的有效时间复杂性。

Conclusion: 智能可以被建模为一个算法库，该算法库能够整合心智和物质的能力来降低任务难度。

Abstract: Cognitive science and theoretical computer science both seek to classify and
explain the difficulty of tasks. Mechanisms of intelligence are those that
reduce task difficulty. Here we map concepts from the computational complexity
of a physical puzzle, the Soma Cube, onto cognitive problem-solving strategies
through a ``Principle of Materiality''. By analyzing the puzzle's branching
factor, measured through search tree outdegree, we quantitatively assess task
difficulty and systematically examine how different strategies modify
complexity. We incrementally refine a trial-and-error search by layering
preprocessing (cognitive chunking), value ordering (cognitive free-sorting),
variable ordering (cognitive scaffolding), and pruning (cognitive inference).
We discuss how the competent use of artifacts reduces effective time complexity
by exploiting physical constraints and propose a model of intelligence as a
library of algorithms that recruit the capabilities of both mind and matter.

</details>


### [13] [A Dimensionality-Reduced XAI Framework for Roundabout Crash Severity Insights](https://arxiv.org/abs/2509.12524)
*Rohit Chakraborty,Subasish Das*

Main category: cs.AI

TL;DR: 本研究通过两步可解释工作流（聚类对应分析和基于SHAP解释的树模型），分析了俄亥俄州环形交叉口在2017-2021年间的事故数据，识别了四种事故模式及其严重性驱动因素，为公共安全分析提供了可用的可解释人工智能（XAI）模板。


<details>
  <summary>Details</summary>
Motivation: 环形交叉口能减少严重事故，但其风险模式因条件而异，需要深入分析以理解并量化事故严重性的驱动因素。

Method: 采用两步可解释工作流：1. 使用聚类对应分析（CCA）识别共同发生的因素并得出四种事故模式。2. 构建树模型来预测事故严重性，并使用SHAP方法解释模型，以量化模式内部和跨模式的伤害驱动因素。数据源自2017-2021年俄亥俄州环形交叉口事故。

Result: 研究发现，在黑暗、湿滑路面、较高限速与固定物体碰撞或角度碰撞事件同时发生时，事故严重性更高；而在晴朗、低速环境下，事故严重性较低。模式特定的解释揭示了事故机制，包括入口处的未能让行/间隙接受问题、多车道环岛内的不当操作以及减速时的追尾事件。

Conclusion: 该工作流将模式发现与案例级解释相结合，支持地点筛选、对策选择和可审计报告。它为公共安全分析中可用的可解释人工智能（XAI）提供了一个实用的模板。

Abstract: Roundabouts reduce severe crashes, yet risk patterns vary by conditions. This
study analyzes 2017-2021 Ohio roundabout crashes using a two-step, explainable
workflow. Cluster Correspondence Analysis (CCA) identifies co-occurring factors
and yields four crash patterns. A tree-based severity model is then interpreted
with SHAP to quantify drivers of injury within and across patterns. Results
show higher severity when darkness, wet surfaces, and higher posted speeds
coincide with fixed-object or angle events, and lower severity in clear,
low-speed settings. Pattern-specific explanations highlight mechanisms at
entries (fail-to-yield, gap acceptance), within multi-lane circulation
(improper maneuvers), and during slow-downs (rear-end). The workflow links
pattern discovery with case-level explanations, supporting site screening,
countermeasure selection, and audit-ready reporting. The contribution to
Information Systems is a practical template for usable XAI in public safety
analytics.

</details>


### [14] [zELO: ELO-inspired Training Method for Rerankers and Embedding Models](https://arxiv.org/abs/2509.12541)
*Nicholas Pipitone,Ghita Houir Alami,Advaith Avadhanam,Anton Kaminskyi,Ashley Khoo*

Main category: cs.AI

TL;DR: 本文介绍了一种名为zELO的新型训练方法，通过将排序任务等同于Thurstone模型来优化检索性能。基于此方法，作者训练了开源重排序模型zerank-1和zerank-1-small，它们在多个领域（金融、法律、代码、STEM）取得了最先进的检索分数，超越了闭源专有模型，并展现了出色的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机是找到一种新的训练方法来优化检索性能，特别是针对重排序任务，并利用无监督数据训练出高性能的开源重排序模型。

Method: 引入了zELO训练方法，该方法通过分析排序任务与Thurstone模型的静态等价性来优化检索性能。基于此方法，使用无监督数据（包括112,000个查询和每个查询100个文档）端到端地训练了zerank-1和zerank-1-small等开源重排序模型，总训练时间少于10,000 H100小时。

Result: zerank模型在金融、法律、代码和STEM等多个领域取得了最高的检索分数，在NDCG@10和Recall指标上均超越了闭源专有重排序器。这些模型还展现了极佳的多功能性，在域外和客户私有数据集上保持了零样本性能。

Conclusion: zELO是一种有效的训练方法，能够利用无监督数据训练出高性能、多功能且在多个领域表现卓越的开源重排序模型，其性能甚至优于闭源专有解决方案。

Abstract: We introduce a novel training methodology named zELO, which optimizes
retrieval performance via the analysis that ranking tasks are statically
equivalent to a Thurstone model. Based on the zELO method, we use unsupervised
data in order train a suite of state-of-the-art open-weight reranker models:
zerank-1 and zerank-1-small. These models achieve the highest retrieval scores
in multiple domains, including finance, legal, code, and STEM, outperforming
closed-source proprietary rerankers on both NDCG@10 and Recall. These models
also demonstrate great versatility, maintaining their 0-shot performance on
out-of-domain and private customer datasets. The training data included 112,000
queries and 100 documents per query, and was trained end-to-end from
unannotated queries and documents in less than 10,000 H100-hours.

</details>


### [15] [Human + AI for Accelerating Ad Localization Evaluation](https://arxiv.org/abs/2509.12543)
*Harshit Rajgarhia,Shivali Dalmia,Mengyang Zhao,Mukherji Abhishek,Kiran Ganesh*

Main category: cs.AI

TL;DR: 本文提出一个结合自动化工具与人工监督的结构化框架，用于广告本地化，旨在保持视觉一致性、空间对齐和风格完整性，并加速评估流程。


<details>
  <summary>Details</summary>
Motivation: 为多语言受众调整广告不仅仅是文本翻译，还需要在不同语言和格式中保持视觉一致性、空间对齐和风格完整性，这是一个复杂挑战。

Method: 引入了一个结构化框架，该框架结合了自动化组件（场景文本检测、图像修复、机器翻译和文本重新放置）与人工监督，专门用于加速广告本地化评估工作流。据称这是首次将这些技术整合用于此目的。

Result: 在六个地区进行的定性结果表明，该方法能够生成语义准确且视觉连贯的本地化广告。

Conclusion: 该方法适用于实际工作流中的部署，能够有效解决广告本地化的复杂性问题。

Abstract: Adapting advertisements for multilingual audiences requires more than simple
text translation; it demands preservation of visual consistency, spatial
alignment, and stylistic integrity across diverse languages and formats. We
introduce a structured framework that combines automated components with human
oversight to address the complexities of advertisement localization. To the
best of our knowledge, this is the first work to integrate scene text
detection, inpainting, machine translation (MT), and text reimposition
specifically for accelerating ad localization evaluation workflows. Qualitative
results across six locales demonstrate that our approach produces semantically
accurate and visually coherent localized advertisements, suitable for
deployment in real-world workflows.

</details>


### [16] [Redefining CX with Agentic AI: Minerva CQ Case Study](https://arxiv.org/abs/2509.12589)
*Garima Agrawal,Riccardo De Maria,Kiran Davuluri,Daniele Spera,Charlie Read,Cosimo Spera,Jack Garrett,Don Miller*

Main category: cs.AI

TL;DR: 本文介绍了一种名为“Agentic AI”的目标驱动型自主AI系统，通过Minerva CQ产品在实时语音客户支持中部署，旨在主动协助客服代表，从而提高效率并改善客户体验。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在联络中心有所发展，但客户体验仍因高平均处理时间（AHT）、低首次呼叫解决率和差的客户满意度（CSAT）而受损。主要原因是客服代表面临认知负荷，现有AI辅助工具（如基于规则、简单提示或RAG）通常是被动且缺乏深层上下文推理能力。

Method: 引入Agentic AI，这是一种目标驱动、自主、工具使用的系统，能主动实时支持客服代表。它能识别客户意图、触发模块化工作流、维护不断演变的上下文并动态适应对话状态。本文以Minerva CQ为例，该产品集成了实时转录、意图和情感检测、实体识别、上下文检索、动态客户画像和部分对话摘要，以实现主动工作流和持续上下文构建。

Result: Minerva CQ作为AI副驾驶，在多个部署中实现了客服效率和客户体验的显著可衡量改进。

Conclusion: Agentic AI，通过Minerva CQ产品在实时客户支持中的成功部署，证明了其能够作为AI副驾驶，通过主动协助客服代表来显著提升效率和改善客户体验。

Abstract: Despite advances in AI for contact centers, customer experience (CX)
continues to suffer from high average handling time (AHT), low first-call
resolution, and poor customer satisfaction (CSAT). A key driver is the
cognitive load on agents, who must navigate fragmented systems, troubleshoot
manually, and frequently place customers on hold. Existing AI-powered
agent-assist tools are often reactive driven by static rules, simple prompting,
or retrieval-augmented generation (RAG) without deeper contextual reasoning. We
introduce Agentic AI goal-driven, autonomous, tool-using systems that
proactively support agents in real time. Unlike conventional approaches,
Agentic AI identifies customer intent, triggers modular workflows, maintains
evolving context, and adapts dynamically to conversation state. This paper
presents a case study of Minerva CQ, a real-time Agent Assist product deployed
in voice-based customer support. Minerva CQ integrates real-time transcription,
intent and sentiment detection, entity recognition, contextual retrieval,
dynamic customer profiling, and partial conversational summaries enabling
proactive workflows and continuous context-building. Deployed in live
production, Minerva CQ acts as an AI co-pilot, delivering measurable
improvements in agent efficiency and customer experience across multiple
deployments.

</details>


### [17] [Match Chat: Real Time Generative AI and Generative Computing for Tennis](https://arxiv.org/abs/2509.12592)
*Aaron Baughman,Gozde Akay,Eduardo Morales,Rahul Agarwal,Preetika Srivastava*

Main category: cs.AI

TL;DR: Match Chat是一个实时、由智能体驱动的网球助理，它结合了生成式AI和生成式计算，旨在为球迷提供即时、准确的比赛相关查询响应。该系统在2025年温网和美网成功部署，服务了近百万用户，并展示了高准确性、低延迟和高可用性。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是希望通过提供即时、准确的比赛相关查询响应，来增强网球球迷的观赛体验。

Method: Match Chat系统整合了生成式人工智能（GenAI）和生成式计算（GenComp）技术。其架构基于智能体导向架构（AOA），结合了规则引擎、预测模型和智能体来预处理和优化用户查询，然后将其传递给GenAI组件。系统还采用了交互式提示设计来引导用户查询。

Result: Match Chat系统在2025年温网和美网首次亮相，为约100万用户提供了服务。它在高达每秒120个请求的负载下，实现了92.83%的答案准确率和平均6.25秒的响应时间。超过96.08%的查询通过交互式提示设计进行引导。在两次大满贯部署中，系统保持了100%的正常运行时间，并支持了近100万独立用户，展现了其可扩展性和可靠性。

Conclusion: 该工作为实时、面向消费者的AI系统引入了关键的设计模式，强调了速度、精确性和可用性。它为在动态环境中部署高性能智能体系统提供了一条实用的途径。

Abstract: We present Match Chat, a real-time, agent-driven assistant designed to
enhance the tennis fan experience by delivering instant, accurate responses to
match-related queries. Match Chat integrates Generative Artificial Intelligence
(GenAI) with Generative Computing (GenComp) techniques to synthesize key
insights during live tennis singles matches. The system debuted at the 2025
Wimbledon Championships and the 2025 US Open, where it provided about 1 million
users with seamless access to streaming and static data through natural
language queries. The architecture is grounded in an Agent-Oriented
Architecture (AOA) combining rule engines, predictive models, and agents to
pre-process and optimize user queries before passing them to GenAI components.
The Match Chat system had an answer accuracy of 92.83% with an average response
time of 6.25 seconds under loads of up to 120 requests per second (RPS). Over
96.08% of all queries were guided using interactive prompt design, contributing
to a user experience that prioritized clarity, responsiveness, and minimal
effort. The system was designed to mask architectural complexity, offering a
frictionless and intuitive interface that required no onboarding or technical
familiarity. Across both Grand Slam deployments, Match Chat maintained 100%
uptime and supported nearly 1 million unique users, underscoring the
scalability and reliability of the platform. This work introduces key design
patterns for real-time, consumer-facing AI systems that emphasize speed,
precision, and usability that highlights a practical path for deploying
performant agentic systems in dynamic environments.

</details>


### [18] [DaSAThco: Data-Aware SAT Heuristics Combinations Optimization via Large Language Models](https://arxiv.org/abs/2509.12602)
*Minyu Chen,Guoqiang Li*

Main category: cs.AI

TL;DR: DaSAThco是一个框架，它利用大型语言模型和问题原型，学习从SAT实例特征到定制启发式集合的可泛化映射，从而在SAT求解器中实现卓越的性能和强大的域外泛化能力。


<details>
  <summary>Details</summary>
Motivation: CDCL求解器的性能依赖于内部启发式，但SAT问题的多样性使得单一的最优配置难以实现。现有的自动化方法虽然能找到特定问题族的配置，但缺乏泛化性，且在新问题类型上需要昂贵的重新优化。

Method: DaSAThco框架通过一个大型语言模型（LLM），在系统定义的问题原型指导下，生成多样化的专业启发式集合。随后，它学习一个自适应选择机制，以形成从实例特征到这些启发式集合的最终映射。

Result: 实验表明，DaSAThco取得了卓越的性能，最值得注意的是，它展示了强大的域外泛化能力，而传统非自适应方法在此方面存在局限性。

Conclusion: 这项工作为复杂、可配置系统的自动化算法设计提供了一条更具可扩展性和实用性的路径。

Abstract: The performance of Conflict-Driven Clause Learning solvers hinges on internal
heuristics, yet the heterogeneity of SAT problems makes a single, universally
optimal configuration unattainable. While prior automated methods can find
specialized configurations for specific problem families, this dataset-specific
approach lacks generalizability and requires costly re-optimization for new
problem types. We introduce DaSAThco, a framework that addresses this challenge
by learning a generalizable mapping from instance features to tailored
heuristic ensembles, enabling a train-once, adapt-broadly model. Our framework
uses a Large Language Model, guided by systematically defined Problem
Archetypes, to generate a diverse portfolio of specialized heuristic ensembles
and subsequently learns an adaptive selection mechanism to form the final
mapping. Experiments show that DaSAThco achieves superior performance and, most
notably, demonstrates robust out-of-domain generalization where non-adaptive
methods show limitations. Our work establishes a more scalable and practical
path toward automated algorithm design for complex, configurable systems.

</details>


### [19] [Analogy-Driven Financial Chain-of-Thought (AD-FCoT): A Prompting Approach for Financial Sentiment Analysis](https://arxiv.org/abs/2509.12611)
*Anmol Singhal Navya Singhal*

Main category: cs.AI

TL;DR: 本文提出了一种名为AD-FCoT（类比驱动金融思维链）的提示框架，将类比推理与思维链（CoT）提示相结合，用于金融新闻情感分析，旨在提高准确性、市场相关性和解释性，通过引导大型语言模型（LLMs）从历史事件中汲取经验。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在金融新闻情感分析中，往往难以捕捉复杂的经济背景，并且缺乏透明的推理过程，这降低了它们的可靠性。

Method: 本文提出了AD-FCoT（类比驱动金融思维链），一个纯粹基于提示的框架。它引导LLMs在新事件和已知结果的历史情景之间建立类比，并将这些类比整合到一个结构化的、逐步的推理链中。该方法无需额外的训练数据或微调，利用模型内部的金融知识生成类人分析推理。

Result: 在数千篇新闻文章上的实验表明，AD-FCoT在情感分类准确性方面优于强大的基线模型，并与市场回报表现出显著更高的相关性。其生成的解释也与领域专业知识相符，提供了适用于实际金融分析的可解释性见解。

Conclusion: AD-FCoT是一种有效且可解释的金融新闻情感分析方法，它通过结合类比推理和思维链提示，显著提升了LLMs在捕捉经济背景和提供透明推理方面的能力，从而提高了预测性能和实用性。

Abstract: Financial news sentiment analysis is crucial for anticipating market
movements. With the rise of AI techniques such as Large Language Models (LLMs),
which demonstrate strong text understanding capabilities, there has been
renewed interest in enhancing these systems. Existing methods, however, often
struggle to capture the complex economic context of news and lack transparent
reasoning, which undermines their reliability. We propose Analogy-Driven
Financial Chain-of-Thought (AD-FCoT), a prompting framework that integrates
analogical reasoning with chain-of-thought (CoT) prompting for sentiment
prediction on historical financial news. AD-FCoT guides LLMs to draw parallels
between new events and relevant historical scenarios with known outcomes,
embedding these analogies into a structured, step-by-step reasoning chain. To
our knowledge, this is among the first approaches to explicitly combine
analogical examples with CoT reasoning in finance. Operating purely through
prompting, AD-FCoT requires no additional training data or fine-tuning and
leverages the model's internal financial knowledge to generate rationales that
mirror human analytical reasoning. Experiments on thousands of news articles
show that AD-FCoT outperforms strong baselines in sentiment classification
accuracy and achieves substantially higher correlation with market returns. Its
generated explanations also align with domain expertise, providing
interpretable insights suitable for real-world financial analysis.

</details>


### [20] [GBV-SQL: Guided Generation and SQL2Text Back-Translation Validation for Multi-Agent Text2SQL](https://arxiv.org/abs/2509.12612)
*Daojun Chen,Xi Wang,Shenyuan Ren,Qingzhi Ma,Pengpeng Zhao,An Liu*

Main category: cs.AI

TL;DR: 本文提出GBV-SQL，一个多智能体框架，通过SQL2Text反向翻译验证来解决Text2SQL中的语义鸿沟。同时，揭示了基准测试数据中“黄金错误”的普遍存在，并强调了数据集质量的重要性。GBV-SQL在BIRD和Spider基准测试上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在Text2SQL生成方面取得了进展，但仍存在语义鸿沟，导致语法正确的查询误解用户意图。此外，现有评估受基准测试数据质量低下（即“黄金错误”）的严重影响，掩盖了模型的真实性能。

Method: 本文提出了GBV-SQL，一个新颖的多智能体框架，引入了“引导生成与SQL2Text反向翻译验证”机制。该机制使用一个专门的智能体将生成的SQL翻译回自然语言，以验证其与原始问题的逻辑一致性。此外，还引入了“黄金错误”的正式类型学，以识别基准测试数据中的普遍缺陷。

Result: 在挑战性的BIRD基准测试上，GBV-SQL实现了63.23%的执行准确率，绝对提升了5.8%。在移除有缺陷的示例后，GBV-SQL在Spider基准测试上实现了96.5%（开发集）和97.6%（测试集）的执行准确率。

Conclusion: 本文提供了一个强大的语义验证框架，并对基准测试的完整性提出了批判性视角，强调了更严格的数据集管理和策展的必要性。

Abstract: While Large Language Models have significantly advanced Text2SQL generation,
a critical semantic gap persists where syntactically valid queries often
misinterpret user intent. To mitigate this challenge, we propose GBV-SQL, a
novel multi-agent framework that introduces Guided Generation with SQL2Text
Back-translation Validation. This mechanism uses a specialized agent to
translate the generated SQL back into natural language, which verifies its
logical alignment with the original question. Critically, our investigation
reveals that current evaluation is undermined by a systemic issue: the poor
quality of the benchmarks themselves. We introduce a formal typology for "Gold
Errors", which are pervasive flaws in the ground-truth data, and demonstrate
how they obscure true model performance. On the challenging BIRD benchmark,
GBV-SQL achieves 63.23% execution accuracy, a 5.8% absolute improvement. After
removing flawed examples, GBV-SQL achieves 96.5% (dev) and 97.6% (test)
execution accuracy on the Spider benchmark. Our work offers both a robust
framework for semantic validation and a critical perspective on benchmark
integrity, highlighting the need for more rigorous dataset curation.

</details>


### [21] [Mob-based cattle weight gain forecasting using ML models](https://arxiv.org/abs/2509.12615)
*Muhammad Riaz Hasib Hossain,Rafiqul Islam,Shawn R McGrath,Md Zahidul Islam,David Lamb*

Main category: cs.AI

TL;DR: 本研究提出了一种预测基于群体的牛只月度体重增加（MB CWG）的新技术，并使用随机森林（RF）模型进行预测，结果优于支持向量回归（SVR）和长短期记忆（LSTM）模型，尤其是在纳入天气和年龄因素时。


<details>
  <summary>Details</summary>
Motivation: 预测基于群体的牛只体重增加（MB CWG）可以帮助大型畜牧农场优化饲喂策略、做出明智的育种选择，并降低气候多变性和市场波动带来的风险。

Method: 本研究提出了一种名为MB CWG的新技术，用于预测牛只提前一个月的体重增加。它采用随机森林（RF）模型，并将其性能与支持向量回归（SVR）和长短期记忆（LSTM）模型进行比较。模型使用来自查尔斯斯图尔特大学农场的历史数据，包括108头牛的756个样本数据以及影响CWG的天气数据（降雨量和温度）。此外，本研究还开发了一个创新的自动化预处理工具，用于生成MB CWG预测模型的基准数据集。

Result: 在所有数据集上，随机森林（RF）模型的表现均优于SVR和LSTM模型。当同时包含天气和年龄因素时，RF模型取得了0.973的R^2、0.040的RMSE和0.033的MAE。结果表明，纳入天气和年龄因素显著提高了体重增加预测的准确性，并且RF模型在所有情况下都优于SVR和LSTM模型。

Conclusion: 研究结果表明，随机森林（RF）是一种预测多变条件下牛只体重增加的强大工具，并强调了年龄和气候因素对群体体重趋势的影响。同时，开发的自动化预处理工具可用于当前和未来的分析研究，以协助准备数据集。

Abstract: Forecasting mob based cattle weight gain (MB CWG) may benefit large livestock
farms, allowing farmers to refine their feeding strategies, make educated
breeding choices, and reduce risks linked to climate variability and market
fluctuations. In this paper, a novel technique termed MB CWG is proposed to
forecast the one month advanced weight gain of herd based cattle using
historical data collected from the Charles Sturt University Farm. This research
employs a Random Forest (RF) model, comparing its performance against Support
Vector Regression (SVR) and Long Short Term Memory (LSTM) models for monthly
weight gain prediction. Four datasets were used to evaluate the performance of
models, using 756 sample data from 108 herd-based cattle, along with weather
data (rainfall and temperature) influencing CWG. The RF model performs better
than the SVR and LSTM models across all datasets, achieving an R^2 of 0.973,
RMSE of 0.040, and MAE of 0.033 when both weather and age factors were
included. The results indicate that including both weather and age factors
significantly improves the accuracy of weight gain predictions, with the RF
model outperforming the SVR and LSTM models in all scenarios. These findings
demonstrate the potential of RF as a robust tool for forecasting cattle weight
gain in variable conditions, highlighting the influence of age and climatic
factors on herd based weight trends. This study has also developed an
innovative automated pre processing tool to generate a benchmark dataset for MB
CWG predictive models. The tool is publicly available on GitHub and can assist
in preparing datasets for current and future analytical research..

</details>


### [22] [ECG-aBcDe: Overcoming Model Dependence, Encoding ECG into a Universal Language for Any LLM](https://arxiv.org/abs/2509.12625)
*Yong Xia,Jingxuan Li,YeTeng Sun,Jiarui Bu*

Main category: cs.AI

TL;DR: 本文提出ECG-aBcDe，一种将心电图（ECG）信号转换为通用ECG语言的新方法，以解决大型语言模型（LLMs）在ECG分析中的可迁移性、时间尺度信息学习和可解释性挑战，实现了“一次构建，随处使用”并显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在心电图分析中存在三大挑战：1) 模型特定的ECG编码器阻碍了LLMs之间的迁移；2) Transformer的局限性导致LLMs难以捕捉ECG中关键的时间尺度信息；3) LLMs的黑盒性质限制了临床应用。

Method: ECG-aBcDe将ECG信号转换为一种通用的ECG语言，任何LLM都能理解。它构建了一个包含ECG语言和自然语言的混合数据集，可以直接对预训练LLMs进行微调，无需修改架构。此外，ECG和ECG语言之间的双向可转换性允许从ECG信号中提取注意力热图，增强了可解释性。ECG-aBcDe还明确表示时间尺度信息，缓解了Transformer的局限性。

Result: ECG-aBcDe在ROUGE-L和METEOR指标上取得了与现有方法相当的性能。在BLEU-4指标上，它实现了显著提升，在数据集内评估中提高了2.8倍（达到42.58分），在跨数据集评估中提高了3.9倍（达到30.76分）。

Conclusion: 这项工作为将ECG分析与LLMs集成提供了一个新范式。实验结果有力证明了该新范式的可行性，解决了当前方法在可迁移性、时间尺度信息和可解释性方面的不足。

Abstract: Large Language Models (LLMs) hold significant promise for electrocardiogram
(ECG) analysis, yet challenges remain regarding transferability, time-scale
information learning, and interpretability. Current methods suffer from
model-specific ECG encoders, hindering transfer across LLMs. Furthermore, LLMs
struggle to capture crucial time-scale information inherent in ECGs due to
Transformer limitations. And their black-box nature limits clinical adoption.
To address these limitations, we introduce ECG-aBcDe, a novel ECG encoding
method that transforms ECG signals into a universal ECG language readily
interpretable by any LLM. By constructing a hybrid dataset of ECG language and
natural language, ECG-aBcDe enables direct fine-tuning of pre-trained LLMs
without architectural modifications, achieving "construct once, use anywhere"
capability. Moreover, the bidirectional convertibility between ECG and ECG
language of ECG-aBcDe allows for extracting attention heatmaps from ECG
signals, significantly enhancing interpretability. Finally, ECG-aBcDe
explicitly represents time-scale information, mitigating Transformer
limitations. This work presents a new paradigm for integrating ECG analysis
with LLMs. Compared with existing methods, our method achieves competitive
performance on ROUGE-L and METEOR. Notably, it delivers significant
improvements in the BLEU-4, with improvements of 2.8 times and 3.9 times in
in-dataset and cross-dataset evaluations, respectively, reaching scores of
42.58 and 30.76. These results provide strong evidence for the feasibility of
the new paradigm.

</details>


### [23] [Learn to Relax with Large Language Models: Solving Nonlinear Combinatorial Optimization Problems via Bidirectional Coevolution](https://arxiv.org/abs/2509.12643)
*Beidan Liu,Zhengqiu Zhu,Chen Gao,Yong Zhao,Wei Qi,Quanjun Yin*

Main category: cs.AI

TL;DR: 本文提出AutoCO，一个端到端的方法，利用大型语言模型（LLM）学习放松约束来解决非线性组合优化问题（NCOPs），并通过双向协同进化机制实现了卓越性能。


<details>
  <summary>Details</summary>
Motivation: 非线性组合优化问题（NCOPs）因其非凸性和多模态解空间而难以有效优化。传统约束松弛方法依赖专家驱动的迭代设计，缺乏自动化和可扩展性。现有基于LLM的优化方法主要作为被动约束验证器，而非主动策略设计者，难以处理NCOPs中复杂的约束交互。

Method: 本文引入了AutoCO方法，通过LLM学习放松约束来解决NCOPs。具体而言，该方法利用结构化LLM推理生成约束松弛策略，这些策略通过统一的三重表示方案，结合算法原理和可执行代码动态演化。此外，AutoCO建立了一种新颖的双向（全局-局部）协同进化机制，将进化算法（用于密集的局部精炼）与蒙特卡洛树搜索（用于系统的全局策略空间探索）相结合，以在碎片化解空间中平衡强化和多样化。

Result: 在三个具有挑战性的NCOP基准测试上的综合实验验证了AutoCO的持续有效性，并显示其性能优于现有基线方法。

Conclusion: AutoCO通过利用LLM学习约束松弛和创新的双向协同进化机制，革新了NCOPs的解决方式，并在实践中展现出卓越的有效性和性能。

Abstract: Nonlinear Combinatorial Optimization Problems (NCOPs) present a formidable
computational hurdle in practice, as their nonconvex nature gives rise to
multi-modal solution spaces that defy efficient optimization. Traditional
constraint relaxation approaches rely heavily on expert-driven, iterative
design processes that lack systematic automation and scalable adaptability.
While recent Large Language Model (LLM)-based optimization methods show promise
for autonomous problem-solving, they predominantly function as passive
constraint validators rather than proactive strategy architects, failing to
handle the sophisticated constraint interactions inherent to NCOPs.To address
these limitations, we introduce the first end-to-end \textbf{Auto}mated
\textbf{C}onstraint \textbf{O}ptimization (AutoCO) method, which revolutionizes
NCOPs resolution through learning to relax with LLMs.Specifically, we leverage
structured LLM reasoning to generate constraint relaxation strategies, which
are dynamically evolving with algorithmic principles and executable code
through a unified triple-representation scheme. We further establish a novel
bidirectional (global-local) coevolution mechanism that synergistically
integrates Evolutionary Algorithms for intensive local refinement with Monte
Carlo Tree Search for systematic global strategy space exploration, ensuring
optimal balance between intensification and diversification in fragmented
solution spaces. Finally, comprehensive experiments on three challenging NCOP
benchmarks validate AutoCO's consistent effectiveness and superior performance
over the baselines.

</details>


### [24] [Large Language Models Imitate Logical Reasoning, but at what Cost?](https://arxiv.org/abs/2509.12645)
*Lachlan McGinness,Peter Baumgartner*

Main category: cs.AI

TL;DR: 本研究评估了前沿大型语言模型（LLM）在18个月内的推理能力演变，并提出了一种神经符号架构，该架构在保持高性能的同时显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估前沿LLM在长时间跨度内的推理能力变化，并探索一种更高效、计算成本更低的推理问题解决方案。

Method: 研究方法包括：1) 对三款领先LLM进行了为期18个月的纵向研究（2023年12月、2024年9月、2025年6月），评估它们在PrOntoQA数据集上的真假问题准确性及其对情境学习推理策略的忠实度。2) 提出了一种神经符号架构，使用参数少于150亿的LLM将问题翻译成标准化形式，然后由SMT求解器Z3解析和解决。3) 报告了提示和完成令牌数量，以及开源模型的FLOPs计算成本。

Result: 研究发现：1) LLM的性能在2023年至2024年间有所提升（归因于隐藏的思维链提示），并在2024年至2025年间因引入“思考模型”而显著提升。2) 神经符号方法在保持近乎完美性能的同时，显著降低了计算成本。3) 推理FLOPs的常用近似公式（活跃参数与总令牌数乘积的两倍）在所有实验中误差在10%以内。

Conclusion: LLM的推理能力在持续进步，且神经符号架构为推理任务提供了一种高效且高性能的替代方案，能够大幅降低计算成本。

Abstract: We present a longitudinal study which evaluates the reasoning capability of
frontier Large Language Models over an eighteen month period. We measured the
accuracy of three leading models from December 2023, September 2024 and June
2025 on true or false questions from the PrOntoQA dataset and their
faithfulness to reasoning strategies provided through in-context learning. The
improvement in performance from 2023 to 2024 can be attributed to hidden Chain
of Thought prompting. The introduction of thinking models allowed for
significant improvement in model performance between 2024 and 2025.
  We then present a neuro-symbolic architecture which uses LLMs of less than 15
billion parameters to translate the problems into a standardised form. We then
parse the standardised forms of the problems into a program to be solved by Z3,
an SMT solver, to determine the satisfiability of the query. We report the
number of prompt and completion tokens as well as the computational cost in
FLOPs for open source models. The neuro-symbolic approach significantly reduces
the computational cost while maintaining near perfect performance. The common
approximation that the number of inference FLOPs is double the product of the
active parameters and total tokens was accurate within 10\% for all
experiments.

</details>


### [25] [Zero-shot Graph Reasoning via Retrieval Augmented Framework with LLMs](https://arxiv.org/abs/2509.12743)
*Hanqing Li,Kiran Sheena Jyothi,Henry Liang,Sharika Mahadevan,Diego Klabjan*

Main category: cs.AI

TL;DR: 本文提出了一种名为GRRAF的免训练方法，它结合检索增强生成（RAG）和大型语言模型（LLM）的代码生成能力，以解决广泛的图推理任务，并在大多数任务上实现了高准确率和良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的图推理方法通常需要大量的微调或依赖预定义的算法，这限制了它们的灵活性和应用范围。GRRAF旨在克服这些限制。

Method: GRRAF将目标图存储在图数据库中，并提示LLM生成可执行的代码查询来检索所需信息。该方法包含一个带有超时机制的错误反馈循环，以确保正确性和效率。

Result: 在GraphInstruct数据集上的实验评估显示，GRRAF在大多数图推理任务（包括环检测、二分图检查、最短路径计算和最大流）上实现了100%的准确率，并且无论图大小如何，都能保持一致的token成本。在子图匹配任务上，性能虽不完美但仍非常高。值得注意的是，GRRAF能有效扩展到多达10,000个节点的大型图。

Conclusion: GRRAF是一种有效、免训练的图推理方法，它利用RAG和LLM的代码生成能力，在多种图推理任务上表现出色，具有高准确性、效率和良好的可扩展性，并且不受图大小影响，能有效处理大规模图。

Abstract: We propose a new, training-free method, Graph Reasoning via Retrieval
Augmented Framework (GRRAF), that harnesses retrieval-augmented generation
(RAG) alongside the code-generation capabilities of large language models
(LLMs) to address a wide range of graph reasoning tasks. In GRRAF, the target
graph is stored in a graph database, and the LLM is prompted to generate
executable code queries that retrieve the necessary information. This approach
circumvents the limitations of existing methods that require extensive
finetuning or depend on predefined algorithms, and it incorporates an error
feedback loop with a time-out mechanism to ensure both correctness and
efficiency. Experimental evaluations on the GraphInstruct dataset reveal that
GRRAF achieves 100% accuracy on most graph reasoning tasks, including cycle
detection, bipartite graph checks, shortest path computation, and maximum flow,
while maintaining consistent token costs regardless of graph sizes. Imperfect
but still very high performance is observed on subgraph matching. Notably,
GRRAF scales effectively to large graphs with up to 10,000 nodes.

</details>


### [26] [H$^2$R: Hierarchical Hindsight Reflection for Multi-Task LLM Agents](https://arxiv.org/abs/2509.12810)
*Shicheng Ye,Chao Yu,Kaiqiang Ke,Chengdong Xu,Yinqi Wei*

Main category: cs.AI

TL;DR: 本文提出了一种名为H$^2$R的新型分层记忆架构，通过解耦高层规划和低层执行记忆，实现大型语言模型（LLM）代理的细粒度知识迁移，从而提高泛化和决策性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理的知识迁移方法将先验经验和知识视为单一整体，导致知识迁移效率低下且粒度粗糙。

Method: 引入了分层记忆架构，将高层规划记忆与低层执行记忆解耦。同时，提出了分层事后反思（Hierarchical Hindsight Reflection, H$^2$R）机制，用于从过去的代理-环境交互中提炼可重用且分层的知识，并在测试时分别检索高层和低层记忆。

Result: 在两个基准测试中，H$^2$R显著提高了泛化能力和决策性能，优于Expel等现有基线方法。

Conclusion: H$^2$R通过其分层记忆架构和反思机制，有效实现了LLM代理的细粒度知识迁移，提升了其在新任务中的适应性和表现。

Abstract: Large language model (LLM)-based agents have shown strong potential in
multi-task scenarios, owing to their ability to transfer knowledge across
diverse tasks. However, existing approaches often treat prior experiences and
knowledge as monolithic units, leading to inefficient and coarse-grained
knowledge transfer. In this work, we propose a novel hierarchical memory
architecture that enables fine-grained knowledge transfer by decoupling
high-level planning memory from low-level execution memory. To construct and
refine these hierarchical memories, we introduce Hierarchical Hindsight
Reflection (H$^2$R), a mechanism that distills reusable and hierarchical
knowledge from past agent-environment interactions. At test time, H$^2$R
performs retrievals of high-level and low-level memories separately, allowing
LLM-based agents to efficiently access and utilize task-relevant knowledge for
new tasks.Experimental results across two benchmarks demonstrate that H$^2$R
can improve generalization and decision-making performance, outperforming prior
baselines such as Expel.

</details>


### [27] [LTA-thinker: Latent Thought-Augmented Training Framework for Large Language Models on Complex Reasoning](https://arxiv.org/abs/2509.12875)
*Jiaqi Wang,Binquan Ji,Haibo Luo,Yiyang Qi,Ruiting Li,Huiyan Wang,Yuantao Han,Cangyi Yang,jiaxu Zhang,Feiliang Ren*

Main category: cs.AI

TL;DR: 该研究提出了LTA-Thinker框架，通过优化潜在思维（Latent Thought）的生成和利用，增强了大型语言模型的复杂推理能力，并缓解了“过度思考”问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如SoftCoT）在连续潜在空间推理中有效，但核心瓶颈在于高效生成和利用高质量潜在思维。理论表明，潜在思维分布的更大方差能更好地近似“黄金真理”分布，这促使研究者寻求提高方差和推理性能的方法。

Method: LTA-Thinker框架从两个方面提升潜在思维的分布方差和推理性能：1. 构建基于可学习先验的潜在思维生成架构，旨在增加生成潜在思维向量的方差分布。2. 引入基于分布的方向优化范式，通过多目标协同训练策略（结合标准SFT损失、语义对齐损失和推理焦点损失）共同约束分布局部性和分布尺度，以提高信息效率和计算成本。

Result: 实验表明，LTA-Thinker在各种基线测试中取得了最先进（SOTA）的性能，并展现出更高的性能上限和更好的扩展效应。

Conclusion: LTA-Thinker通过创新的潜在思维生成架构和分布优化范式，有效提高了大型语言模型的复杂推理能力，并实现了卓越的性能表现。

Abstract: Complex Reasoning in Large Language Models can be dynamically optimized using
Test-Time Scaling (TTS) to mitigate Overthinking. Methods such as Coconut,
SoftCoT and its variant are effective in continuous latent space inference, the
core bottleneck still lies in the efficient generation and utilization of
high-quality Latent Thought. Drawing from the theory of SoftCoT++ that a larger
variance in the generated Latent Thought distribution more closely approximates
the golden truth distribution, we propose a Latent Thought-Augmented Training
Framework--LTA-Thinker, which improves distributional variance and enhances
reasoning performance from two perspectives. First, LTA-Thinker constructs a
Latent Thought generation architecture based on a learnable prior. This
architecture aims to increase the variance distribution of generated Latent
Thought Vectors in order to simplify the overall structure and raise the
performance ceiling. Second, LTA-Thinker introduces a distribution-based
directional optimization paradigm that jointly constrains both distribution
locality and distribution scale. This mechanism improves information efficiency
and computational cost through a multi-objective co-training strategy, which
combines standard Supervised Fine-Tuning (SFT) loss with two novel losses:
Semantic Alignment Loss, which utilizes KL divergence to ensure that the Latent
Thought is highly relevant to the semantics of the question; Reasoning Focus
Loss, which utilizes a contrastive learning mechanism to guide the model to
focus on the most critical reasoning steps. Experiments show that LTA-thinker
achieves state-of-the-art (SOTA) performance among various baselines and
demonstrates a higher performance ceiling and better scaling effects.

</details>


### [28] [Stochastic Streets: A Walk Through Random LLM Address Generation in four European Cities](https://arxiv.org/abs/2509.12914)
*Tairan Fu,David Campo-Nazareno,Javier Coronado-Blázquez,Javier Conde,Pedro Reviriego,Fabrizio Lombardi*

Main category: cs.AI

TL;DR: 该摘要质疑大型语言模型（LLMs）在解决复杂数学问题和回答各种难题之外，是否能够生成欧洲城市的随机街道地址。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索LLMs除了其已知的复杂推理和广泛知识能力之外，是否具备生成特定格式的、随机且地理位置精确数据的能力。

Method: 摘要中未提及具体研究方法。

Result: 摘要中未提供研究结果，仅提出一个问题。

Conclusion: 摘要中未得出任何结论，仅提出一个待验证的问题。

Abstract: Large Language Models (LLMs) are capable of solving complex math problems or
answer difficult questions on almost any topic, but can they generate random
street addresses for European cities?

</details>


### [29] [Population Estimation using Deep Learning over Gandhinagar Urban Area](https://arxiv.org/abs/2509.12926)
*Jai Singla,Peal Jotania,Keivalya Pandya*

Main category: cs.AI

TL;DR: 本研究提出了一种深度学习解决方案，利用高分辨率卫星图像、DEM和矢量边界，结合CNN和ANN模型，实现建筑分类和人口估算，旨在提供一种高效、自动化的城市人口统计工具。


<details>
  <summary>Details</summary>
Motivation: 传统的人口普查和调查方法成本高昂、耗时且严重依赖人力资源，存在效率和资源限制。因此，需要一种更高效、自动化的解决方案。

Method: 该方法结合了卷积神经网络（CNN）和人工神经网络（ANN）。CNN用于将建筑物分类为住宅或非住宅，而ANN则用于估算人口。研究使用了高分辨率（0.3米）卫星图像、0.5米分辨率的数字高程模型（DEM）和矢量边界数据。在甘地讷格尔城市区域利用了约4.8万个建筑足迹进行训练和评估。

Result: 实验结果显示，该模型在建筑分类任务上取得了令人印象深刻的0.9936的F1-分数。通过该系统，估算出甘地讷格尔的人口为278,954人。该方法通过整合实时数据更新、标准化指标和基础设施规划能力，有效克服了传统普查方法的局限性。

Conclusion: 该框架为市政当局提供了一个可扩展、可复制的工具，用于快速城市化地区优化资源管理，展示了AI驱动的地理空间分析在增强数据驱动的城市治理方面的效率和潜力。

Abstract: Population estimation is crucial for various applications, from resource
allocation to urban planning. Traditional methods such as surveys and censuses
are expensive, time-consuming and also heavily dependent on human resources,
requiring significant manpower for data collection and processing. In this
study a deep learning solution is proposed to estimate population using high
resolution (0.3 m) satellite imagery, Digital Elevation Models (DEM) of 0.5m
resolution and vector boundaries. Proposed method combines Convolution Neural
Network (CNN) architecture for classification task to classify buildings as
residential and non-residential and Artificial Neural Network (ANN)
architecture to estimate the population. Approx. 48k building footprints over
Gandhinagar urban area are utilized containing both residential and
non-residential, with residential categories further used for building-level
population estimation. Experimental results on a large-scale dataset
demonstrate the effectiveness of our model, achieving an impressive overall
F1-score of 0.9936. The proposed system employs advanced geospatial analysis
with high spatial resolution to estimate Gandhinagar population at 278,954. By
integrating real-time data updates, standardized metrics, and infrastructure
planning capabilities, this automated approach addresses critical limitations
of conventional census-based methodologies. The framework provides
municipalities with a scalable and replicable tool for optimized resource
management in rapidly urbanizing cities, showcasing the efficiency of AI-driven
geospatial analytics in enhancing data-driven urban governance.

</details>


### [30] [HLSMAC: A New StarCraft Multi-Agent Challenge for High-Level Strategic Decision-Making](https://arxiv.org/abs/2509.12927)
*Xingxing Hong,Yungong Wang,Dexin Jin,Ye Yuan,Ximing Huang,Zijian Wu,Wenxin Li*

Main category: cs.AI

TL;DR: 本文提出了HLSMAC，一个基于《三十六计》的星际争霸II合作多智能体强化学习（MARL）基准，旨在评估高层战略决策能力，并引入了新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有的MARL基准（如SMAC）主要关注微观操作，限制了对高层战略智能的全面评估。

Method: 引入HLSMAC，一个包含12个基于《三十六计》精心设计的星际争霸II场景的合作MARL基准。每个场景都旨在挑战智能体的战术机动、时机协调和欺骗等多样化战略元素。提出了超越传统胜率的新指标（如能力利用率和推进效率）。将最先进的MARL算法和基于LLM的智能体整合到基准中进行综合实验。

Result: 实验结果表明，HLSMAC是一个强大的测试平台，能够推动多智能体战略决策能力的发展。

Conclusion: HLSMAC有效填补了现有MARL基准在评估高层战略智能方面的空白，为未来的多智能体战略决策研究提供了一个全面的平台。

Abstract: Benchmarks are crucial for assessing multi-agent reinforcement learning
(MARL) algorithms. While StarCraft II-related environments have driven
significant advances in MARL, existing benchmarks like SMAC focus primarily on
micromanagement, limiting comprehensive evaluation of high-level strategic
intelligence. To address this, we introduce HLSMAC, a new cooperative MARL
benchmark with 12 carefully designed StarCraft II scenarios based on classical
stratagems from the Thirty-Six Stratagems. Each scenario corresponds to a
specific stratagem and is designed to challenge agents with diverse strategic
elements, including tactical maneuvering, timing coordination, and deception,
thereby opening up avenues for evaluating high-level strategic decision-making
capabilities. We also propose novel metrics across multiple dimensions beyond
conventional win rate, such as ability utilization and advancement efficiency,
to assess agents' overall performance within the HLSMAC environment. We
integrate state-of-the-art MARL algorithms and LLM-based agents with our
benchmark and conduct comprehensive experiments. The results demonstrate that
HLSMAC serves as a robust testbed for advancing multi-agent strategic
decision-making.

</details>


### [31] [The Anatomy of Alignment: Decomposing Preference Optimization by Steering Sparse Features](https://arxiv.org/abs/2509.12934)
*Jeremias Ferrao,Matthijs van der Lende,Ilija Lichkovski,Clement Neo*

Main category: cs.AI

TL;DR: 本文提出FSRL（基于强化学习的特征引导），一种透明的对齐框架，通过轻量级适配器调节稀疏自编码器（SAE）的解释性特征来引导大型语言模型行为，效果与RLHF相当，并提供机制分析。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF方法导致模型参数变化不透明，难以理解模型内部学习了什么。因此，需要一种更透明的对齐框架来理解和控制模型行为。

Method: FSRL框架训练一个轻量级适配器，通过调节来自稀疏自编码器（SAE）的解释性特征来引导模型行为。该方法使用强化学习进行偏好优化。

Result: FSRL在偏好优化方面表现有效，与当前的RLHF方法相当。对训练后的适配器进行机制分析发现，其策略系统性地优先选择风格特征而非明确的对齐概念，这表明偏好优化过程将风格化表达作为质量的代理指标。

Conclusion: FSRL提供了一种工具，既可以实现可解释的模型控制，又可以诊断对齐过程的内部机制。

Abstract: Aligning large language models is critical for their usability and safety.
However, the prevailing approach of Reinforcement Learning from Human Feedback
(RLHF) induces diffuse, opaque parameter changes, making it difficult to
discern what the model has internalized. Hence, we introduce Feature Steering
with Reinforcement Learning (FSRL), a transparent alignment framework that
trains a lightweight adapter to steer behavior by modulating interpretable
features from a Sparse Autoencoder (SAE). First, we demonstrate that FSRL is an
effective method for preference optimization and is comparable with current
RLHF methods. We then perform mechanistic analysis on the trained adapter, and
find that its policy systematically promotes style features over explicit
alignment concepts, suggesting that the preference optimization process rewards
stylistic presentation as a proxy for quality. Ultimately, we hope that FSRL
provides a tool for both interpretable model control and diagnosing the
internal mechanisms of alignment.

</details>


### [32] [Black-box Model Merging for Language-Model-as-a-Service with Massive Model Repositories](https://arxiv.org/abs/2509.12951)
*Shilian Chen,Jie Zhou,Tianyu Huai,Yujiang Lu,Junsong Li,Bihao Zhan,Qianjun Pan,Yutao Yang,Xin Li,Qin Chen,Hang Yan,Liang He*

Main category: cs.AI

TL;DR: 针对大型语言模型（LLMs）的黑盒模型合并问题，本文提出了一种基于进化算法的无导数优化框架Evo-Merging，仅通过API查询即可有效合并模型。


<details>
  <summary>Details</summary>
Motivation: 大多数现有模型合并方法依赖于可访问的模型参数。然而，对于GPT-4等大型LLMs，通常以黑盒API服务形式提供，用户无法获取模型权重。这给模型合并带来了巨大挑战，即黑盒模型合并（BMM）。

Method: 提出Evo-Merging框架，采用基于进化算法的无导数优化方法，仅利用推理时的API查询。该方法包含两个核心组件：1) 基于稀疏性的去噪，用于识别和过滤模型间不相关或冗余的信息；2) 符号感知缩放，根据相关模型的性能动态计算最优组合权重。同时提供了非对称稀疏化的形式化论证和理论分析。

Result: 广泛的实验评估表明，该方法在多种任务上取得了最先进的结果，显著优于现有强大的基线方法。

Conclusion: Evo-Merging框架通过无导数优化和API查询，成功解决了大规模LLMs的黑盒模型合并难题，并在性能上展现出卓越的效果。

Abstract: Model merging refers to the process of integrating multiple distinct models
into a unified model that preserves and combines the strengths and capabilities
of the individual models. Most existing approaches rely on task vectors to
combine models, typically under the assumption that model parameters are
accessible. However, for extremely large language models (LLMs) such as GPT-4,
which are often provided solely as black-box services through API interfaces
(Language-Model-as-a-Service), model weights are not available to end users.
This presents a significant challenge, which we refer to as black-box model
merging (BMM) with massive LLMs. To address this challenge, we propose a
derivative-free optimization framework based on the evolutionary algorithm
(Evo-Merging) that enables effective model merging using only inference-time
API queries. Our method consists of two key components: (1) sparsity-based
denoising, designed to identify and filter out irrelevant or redundant
information across models, and (2) sign-aware scaling, which dynamically
computes optimal combination weights for the relevant models based on their
performance. We also provide a formal justification, along with a theoretical
analysis, for our asymmetric sparsification. Extensive experimental evaluations
demonstrate that our approach achieves state-of-the-art results on a range of
tasks, significantly outperforming existing strong baselines.

</details>


### [33] [Forget What's Sensitive, Remember What Matters: Token-Level Differential Privacy in Memory Sculpting for Continual Learning](https://arxiv.org/abs/2509.12958)
*Bihao Zhan,Jie Zhou,Junsong Li,Yutao Yang,Shilian Chen,Qianjun Pan,Xin Li,Wen Wu,Xingjiao Wu,Qin Chen,Hang Yan,Liang He*

Main category: cs.AI

TL;DR: 本文提出了一种隐私增强的持续学习（PeCL）框架，通过令牌级动态差分隐私和隐私引导的记忆雕刻，平衡了隐私保护和模型效用，解决了持续学习中隐私敏感信息累积的问题。


<details>
  <summary>Details</summary>
Motivation: 持续学习（CL）模型在顺序知识获取中面临显著的隐私挑战，因为它们会积累多样化信息。传统的差分隐私（DP）方法无差别地保护所有数据，导致模型效用大幅下降，阻碍了CL在隐私敏感领域的部署。

Method: PeCL框架包含两个核心方法：1. 令牌级动态差分隐私策略：根据单个令牌的语义敏感性自适应分配隐私预算，为私有实体提供强保护，同时最小化非敏感通用知识的噪声注入。2. 隐私引导的记忆雕刻模块：利用敏感性分析，智能地从模型记忆和参数中遗忘敏感信息，同时明确保留对缓解灾难性遗忘至关重要的任务不变历史知识。

Result: PeCL在隐私保护和模型效用之间实现了卓越的平衡，在保持先前任务高准确性的同时确保了强大的隐私性，优于基线模型。

Conclusion: PeCL框架通过选择性地保护敏感数据并保留关键历史知识，有效解决了持续学习中的隐私挑战，实现了隐私保护和模型效用的双赢。

Abstract: Continual Learning (CL) models, while adept at sequential knowledge
acquisition, face significant and often overlooked privacy challenges due to
accumulating diverse information. Traditional privacy methods, like a uniform
Differential Privacy (DP) budget, indiscriminately protect all data, leading to
substantial model utility degradation and hindering CL deployment in
privacy-sensitive areas. To overcome this, we propose a privacy-enhanced
continual learning (PeCL) framework that forgets what's sensitive and remembers
what matters. Our approach first introduces a token-level dynamic Differential
Privacy strategy that adaptively allocates privacy budgets based on the
semantic sensitivity of individual tokens. This ensures robust protection for
private entities while minimizing noise injection for non-sensitive, general
knowledge. Second, we integrate a privacy-guided memory sculpting module. This
module leverages the sensitivity analysis from our dynamic DP mechanism to
intelligently forget sensitive information from the model's memory and
parameters, while explicitly preserving the task-invariant historical knowledge
crucial for mitigating catastrophic forgetting. Extensive experiments show that
PeCL achieves a superior balance between privacy preserving and model utility,
outperforming baseline models by maintaining high accuracy on previous tasks
while ensuring robust privacy.

</details>


### [34] [Toward PDDL Planning Copilot](https://arxiv.org/abs/2509.12987)
*Yarin Benyamin,Argaman Mordoch,Shahaf S. Shperberg,Roni Stern*

Main category: cs.AI

TL;DR: 本文提出Planning Copilot，一个通过集成规划工具并利用Model Context Protocol (MCP) 来增强大型语言模型(LLM)长期规划能力的聊天机器人。它显著优于单独使用LLM以及GPT-5。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）作为自主代理在执行复杂任务时，缺乏独立执行可靠的长期规划的能力。

Method: 引入Planning Copilot，一个集成多个规划工具的聊天机器人，用户可以通过自然语言指令调用这些工具。它利用Model Context Protocol (MCP) 标准连接LLM与外部工具，支持任何兼容MCP的LLM，无需特定领域微调。Planning Copilot支持规划任务，如语法检查、规划器选择、调用、计划验证和执行模拟。

Result: 实验结果表明，Planning Copilot在使用相同LLM的情况下，其性能远超不使用规划工具的LLM。与最新的商业LLM GPT-5进行有限定性比较，Planning Copilot即使依赖较小的LLM，也显著优于GPT-5。

Conclusion: 研究表明，专用的规划工具可能是使LLM执行规划任务的有效途径，从而弥补了LLM在长期规划方面的不足。

Abstract: Large Language Models (LLMs) are increasingly being used as autonomous agents
capable of performing complicated tasks. However, they lack the ability to
perform reliable long-horizon planning on their own. This paper bridges this
gap by introducing the Planning Copilot, a chatbot that integrates multiple
planning tools and allows users to invoke them through instructions in natural
language. The Planning Copilot leverages the Model Context Protocol (MCP), a
recently developed standard for connecting LLMs with external tools and
systems. This approach allows using any LLM that supports MCP without
domain-specific fine-tuning. Our Planning Copilot supports common planning
tasks such as checking the syntax of planning problems, selecting an
appropriate planner, calling it, validating the plan it generates, and
simulating their execution. We empirically evaluate the ability of our Planning
Copilot to perform these tasks using three open-source LLMs. The results show
that the Planning Copilot highly outperforms using the same LLMs without the
planning tools. We also conducted a limited qualitative comparison of our tool
against Chat GPT-5, a very recent commercial LLM. Our results shows that our
Planning Copilot significantly outperforms GPT-5 despite relying on a much
smaller LLM. This suggests dedicated planning tools may be an effective way to
enable LLMs to perform planning tasks.

</details>


### [35] [Data-driven Methods of Extracting Text Structure and Information Transfer](https://arxiv.org/abs/2509.12999)
*Shinichi Honna,Taichi Murayama,Akira Matsui*

Main category: cs.AI

TL;DR: 本文测试了安娜·卡列尼娜原则（AKP）及其变体在小说、维基百科、学术论文和电影等不同媒体中的适用性，发现成功所需的结构性约束因媒体而异，而失败形式则跨领域多样化。


<details>
  <summary>Details</summary>
Motivation: 了解成功和失败的结构模式是否遵循安娜·卡列尼娜原则（AKP），以及这些模式在不同信息载体（如文学、百科全书、学术著作、电影）中如何体现和变化。

Method: 将不同媒体的文本表示为功能块序列，并通过评估其在转换顺序和位置上的收敛性来测试AKP、其逆向以及有序和嘈杂的结构模式。

Result: 研究发现结构原则因媒体而异：小说遵循逆向AKP的顺序模式；维基百科结合了AKP和有序模式；学术论文在顺序上显示逆向AKP但在位置上保持嘈杂；电影则按类型分化。

Conclusion: 成功依赖于特定媒体的结构性约束，而失败则在不同领域呈现出多样化的形式。

Abstract: The Anna Karenina Principle (AKP) holds that success requires satisfying a
small set of essential conditions, whereas failure takes diverse forms. We test
AKP, its reverse, and two further patterns described as ordered and noisy
across novels, online encyclopedias, research papers, and movies. Texts are
represented as sequences of functional blocks, and convergence is assessed in
transition order and position. Results show that structural principles vary by
medium: novels follow reverse AKP in order, Wikipedia combines AKP with ordered
patterns, academic papers display reverse AKP in order but remain noisy in
position, and movies diverge by genre. Success therefore depends on structural
constraints that are specific to each medium, while failure assumes different
shapes across domains.

</details>


### [36] [A Visualized Framework for Event Cooperation with Generative Agents](https://arxiv.org/abs/2509.13011)
*Yuyang Tian,Shunqiang Mao,Wenchang Gao,Lanlan Qiu,Tianxing He*

Main category: cs.AI

TL;DR: MiniAgentPro是一个用于LLM代理社会模拟的可视化平台，具有地图编辑器和仿真播放器。它引入了一个包含八种事件场景的综合测试集，评估结果显示GPT-4o在基础设置中表现良好，但在复杂协调任务中面临挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）代理社会模拟框架，尽管在自主规划、记忆形成和社交互动方面表现出色，但往往忽视了事件组织的系统性评估，并缺乏与物理环境的可视化集成，从而限制了代理在空间中导航和与物品互动的真实性。

Method: 本文开发了MiniAgentPro平台，该平台具有直观的地图编辑器用于自定义环境，以及一个带有流畅动画的仿真播放器。基于此工具，研究者引入了一个包含八种多样化事件场景（包括基础和困难变体）的综合测试集，以评估代理的能力。

Result: 使用GPT-4o进行的评估显示，在基础设置中表现强劲，但在困难变体中凸显了协调方面的挑战。

Conclusion: MiniAgentPro平台及其测试集揭示了LLM代理在模拟社会中的能力和局限性，特别是在复杂事件组织和多代理协调方面的挑战，为未来的研究提供了方向。

Abstract: Large Language Models (LLMs) have revolutionized the simulation of agent
societies, enabling autonomous planning, memory formation, and social
interactions. However, existing frameworks often overlook systematic
evaluations for event organization and lack visualized integration with
physically grounded environments, limiting agents' ability to navigate spaces
and interact with items realistically. We develop MiniAgentPro, a visualization
platform featuring an intuitive map editor for customizing environments and a
simulation player with smooth animations. Based on this tool, we introduce a
comprehensive test set comprising eight diverse event scenarios with basic and
hard variants to assess agents' ability. Evaluations using GPT-4o demonstrate
strong performance in basic settings but highlight coordination challenges in
hard variants.

</details>


### [37] [Reasoning with Preference Constraints: A Benchmark for Language Models in Many-to-One Matching Markets](https://arxiv.org/abs/2509.13131)
*Marylou Fauchard,Florian Carichon,Margarida Carvalho,Golnoosh Farnadi*

Main category: cs.AI

TL;DR: 本研究引入了一个新的大学招生问题基准，用于评估大型语言模型（LLMs）在具有偏好和结构约束的匹配问题上的表现。结果显示，LLMs难以持续满足所有评估标准，推理型LLMs表现优于传统LLMs，且不同的提示策略效果不一，迭代提示的效果也非单调。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在复杂数学任务和组合优化方面表现出色，但其在需要偏好和结构约束推理的匹配问题上的应用尚未得到充分探索。为了填补这一空白，需要评估LLMs在此类问题上的能力。

Method: 研究引入了一个包含369个大学招生问题实例的新基准，这是一个典型的带偏好匹配问题。使用该基准评估了多个开源LLMs在可行性、稳定性和最优性等关键维度上的性能。测试了包括思维链（Chain-of-Thought）、上下文学习（In-Context Learning）和基于角色的提示等多种提示策略，并探讨了带有自动生成反馈的迭代提示效果。

Result: 研究发现，LLMs虽然能满足某些约束，但难以持续满足所有评估标准。QwQ和GPT-oss等推理型LLMs显著优于Llama、Qwen或Mistral等传统模型。此外，LLMs对不同的提示策略反应各异，没有单一策略能始终提供最佳性能。带有自动生成反馈的迭代提示表现并非单调，可能早期达到峰值，随后显著下降。

Conclusion: 本工作为模型推理性能和提示策略在具有偏好约束的组合优化问题中的有效性提供了新视角。LLMs在匹配问题上仍面临挑战，但推理型LLMs表现出潜力，且提示策略的选择和迭代过程的理解至关重要。

Abstract: Recent advances in reasoning with large language models (LLMs) have
demonstrated strong performance on complex mathematical tasks, including
combinatorial optimization. Techniques such as Chain-of-Thought and In-Context
Learning have further enhanced this capability, making LLMs both powerful and
accessible tools for a wide range of users, including non-experts. However,
applying LLMs to matching problems, which require reasoning under preferential
and structural constraints, remains underexplored. To address this gap, we
introduce a novel benchmark of 369 instances of the College Admission Problem,
a canonical example of a matching problem with preferences, to evaluate LLMs
across key dimensions: feasibility, stability, and optimality. We employ this
benchmark to assess the performance of several open-weight LLMs. Our results
first reveal that while LLMs can satisfy certain constraints, they struggle to
meet all evaluation criteria consistently. They also show that reasoning LLMs,
like QwQ and GPT-oss, significantly outperform traditional models such as
Llama, Qwen or Mistral, defined here as models used without any dedicated
reasoning mechanisms. Moreover, we observed that LLMs reacted differently to
the various prompting strategies tested, which include Chain-of-Thought,
In-Context Learning and role-based prompting, with no prompt consistently
offering the best performance. Finally, we report the performances from
iterative prompting with auto-generated feedback and show that they are not
monotonic; they can peak early and then significantly decline in later
attempts. Overall, this work offers a new perspective on model reasoning
performance and the effectiveness of prompting strategies in combinatorial
optimization problems with preferential constraints.

</details>


### [38] [Agentic AI for Financial Crime Compliance](https://arxiv.org/abs/2509.13137)
*Henrik Axelsen,Valdemar Licht,Jan Damsgaard*

Main category: cs.AI

TL;DR: 本文介绍了一个在数字原生金融平台中设计和部署的代理式AI系统，用于金融犯罪合规（FCC），该系统强调可解释性、可追溯性和合规性设计，并由行动设计研究（ADR）流程开发。


<details>
  <summary>Details</summary>
Motivation: 金融犯罪合规（FCC）的成本和复杂性持续上升，但有效性提升不明显。现有AI解决方案往往不透明且不符合监管期望。

Method: 通过与金融科技公司和监管利益相关者的行动设计研究（ADR）流程，开发了一个代理式AI系统。该系统采用以构件为中心的建模，为自主代理分配明确角色，并实现任务特定模型路由和审计日志，从而自动化了入职、监控、调查和报告等流程，并强调可解释性、可追溯性和合规性设计。

Result: 研究贡献包括一个参考架构、一个真实世界的原型，以及关于代理式AI如何在监管约束下重构FCC工作流程的见解。研究还展示了自动化如何通过负责任的治理结构支持高风险、受监管环境中的透明度和机构信任。

Conclusion: 自动化，当嵌入到负责任的治理结构中时，能够支持高风险、受监管环境中的透明度和机构信任，这扩展了信息系统（IS）领域关于AI赋能合规的文献。

Abstract: The cost and complexity of financial crime compliance (FCC) continue to rise,
often without measurable improvements in effectiveness. While AI offers
potential, most solutions remain opaque and poorly aligned with regulatory
expectations. This paper presents the design and deployment of an agentic AI
system for FCC in digitally native financial platforms. Developed through an
Action Design Research (ADR) process with a fintech firm and regulatory
stakeholders, the system automates onboarding, monitoring, investigation, and
reporting, emphasizing explainability, traceability, and compliance-by-design.
Using artifact-centric modeling, it assigns clearly bounded roles to autonomous
agents and enables task-specific model routing and audit logging. The
contribution includes a reference architecture, a real-world prototype, and
insights into how Agentic AI can reconfigure FCC workflows under regulatory
constraints. Our findings extend IS literature on AI-enabled compliance by
demonstrating how automation, when embedded within accountable governance
structures, can support transparency and institutional trust in high-stakes,
regulated environments.

</details>


### [39] [G-CSEA: A Graph-Based Conflict Set Extraction Algorithm for Identifying Infeasibility in Pseudo-Boolean Models](https://arxiv.org/abs/2509.13203)
*Kanishk Garg,Saranya D.,Sanal Kumar,Saurabh Singh,Anupam Purwar*

Main category: cs.AI

TL;DR: 本文提出了一种名为G-CSEA的图基冲突集提取算法，旨在更高效、更鲁棒地识别排班模型中导致不可行的约束集（IIS），以克服现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 排班模型中复杂的规则约束（如班次限制、人员配置策略等）可能相互冲突，导致模型不可行。识别这些不可行性的根本原因（即不可约不可行子集IIS）对于解决排班问题至关重要。现有IIS提取方法（如Additive Deletion和QuickXplain）需要大量求解器调用，效率低下；而双射线分析对于伪布尔模型可能失效。

Method: 本文提出图基冲突集提取算法（G-CSEA），其灵感来源于SAT求解器中的冲突驱动子句学习（CDCL）。该方法在约束传播过程中构建一个蕴含图，并在检测到冲突时，追踪所有在决策分支中导致冲突的约束。生成的冲突集可以选择性地通过QuickXplain进行最小化以产生IIS。

Result: G-CSEA能够有效地提取冲突集，并能通过后续最小化生成IIS。该方法旨在解决现有IIS提取方法在求解器调用次数过多和对伪布尔模型适用性不足的问题，提供了一种更高效、更适用于伪布尔模型的不可行性诊断工具。

Conclusion: G-CSEA为排班模型中基于伪布尔约束的不可行性诊断提供了一种新颖且高效的方法，通过构建蕴含图和追踪冲突，能够有效地识别导致模型不可行的冲突约束集，从而帮助解决排班问题。

Abstract: Workforce scheduling involves a variety of rule-based constraints-such as
shift limits, staffing policies, working hour restrictions, and many similar
scheduling rules-which can interact in conflicting ways, leading to infeasible
models. Identifying the underlying causes of such infeasibility is critical for
resolving scheduling issues and restoring feasibility. A common diagnostic
approach is to compute Irreducible Infeasible Subsets (IISs): minimal sets of
constraints that are jointly infeasible but become feasible when any one is
removed. We consider models formulated using pseudo-Boolean constraints with
inequality relations over binary variables, which naturally encode scheduling
logic. Existing IIS extraction methods such as Additive Deletion and
QuickXplain rely on repeated feasibility checks, often incurring large numbers
of solver calls. Dual ray analysis, while effective for LP-based models, may
fail when the relaxed problem is feasible but the underlying pseudo-Boolean
model is not. To address these limitations, we propose Graph-based Conflict Set
Extraction Algorithm (G-CSEA) to extract a conflict set, an approach inspired
by Conflict-Driven Clause Learning (CDCL) in SAT solvers. Our method constructs
an implication graph during constraint propagation and, upon detecting a
conflict, traces all contributing constraints across both decision branches.
The resulting conflict set can optionally be minimized using QuickXplain to
produce an IIS.

</details>


### [40] [Simulating Clinical AI Assistance using Multimodal LLMs: A Case Study in Diabetic Retinopathy](https://arxiv.org/abs/2509.13234)
*Nadim Barakat,William Lotter*

Main category: cs.AI

TL;DR: 本研究评估了多模态大语言模型（MLLMs）在糖尿病视网膜病变（DR）检测中的应用及其模拟临床AI辅助的能力。MedGemma在基线测试中表现优于GPT-4o，且当GPT-4o结合MedGemma的描述性输出时，即使没有直接图像访问也能实现强大的检测性能。结果表明MLLMs可改进DR筛查流程，并作为研究临床AI辅助的模拟器。


<details>
  <summary>Details</summary>
Motivation: 目前的FDA批准的糖尿病视网膜病变AI系统主要提供二元转诊结果，这种极简输出可能限制临床信任和实用性。确定最有效的输出格式以增强临床医生-AI性能是一个难以大规模评估的实证挑战。

Method: 研究在IDRiD和Messidor-2数据集上测试了两个多模态大语言模型：通用型GPT-4o和开源医疗模型MedGemma。实验包括：1) 基线评估，2) 使用合成预测模拟AI辅助，以及3) GPT-4o整合MedGemma输出的实际AI-to-AI协作。

Result: 基线测试中，MedGemma在灵敏度和AUROC方面优于GPT-4o，而GPT-4o表现出接近完美的特异性但灵敏度较低。两个模型都根据模拟AI输入调整了预测，但GPT-4o在接收到不正确输入时性能崩溃，而MedGemma则更稳定。在实际协作中，当由MedGemma的描述性输出引导时，即使没有直接图像访问，GPT-4o也取得了很好的结果（AUROC高达0.96）。

Conclusion: 这些发现表明MLLMs可以改进糖尿病视网膜病变筛查流程，并作为研究不同输出配置下临床AI辅助的可扩展模拟器。像MedGemma这样的开放、轻量级模型在资源匮乏的环境中可能特别有价值，而描述性输出可以增强临床工作流程中的可解释性和临床医生信任。

Abstract: Diabetic retinopathy (DR) is a leading cause of blindness worldwide, and AI
systems can expand access to fundus photography screening. Current FDA-cleared
systems primarily provide binary referral outputs, where this minimal output
may limit clinical trust and utility. Yet, determining the most effective
output format to enhance clinician-AI performance is an empirical challenge
that is difficult to assess at scale. We evaluated multimodal large language
models (MLLMs) for DR detection and their ability to simulate clinical AI
assistance across different output types. Two models were tested on IDRiD and
Messidor-2: GPT-4o, a general-purpose MLLM, and MedGemma, an open-source
medical model. Experiments included: (1) baseline evaluation, (2) simulated AI
assistance with synthetic predictions, and (3) actual AI-to-AI collaboration
where GPT-4o incorporated MedGemma outputs. MedGemma outperformed GPT-4o at
baseline, achieving higher sensitivity and AUROC, while GPT-4o showed
near-perfect specificity but low sensitivity. Both models adjusted predictions
based on simulated AI inputs, but GPT-4o's performance collapsed with incorrect
ones, whereas MedGemma remained more stable. In actual collaboration, GPT-4o
achieved strong results when guided by MedGemma's descriptive outputs, even
without direct image access (AUROC up to 0.96). These findings suggest MLLMs
may improve DR screening pipelines and serve as scalable simulators for
studying clinical AI assistance across varying output configurations. Open,
lightweight models such as MedGemma may be especially valuable in low-resource
settings, while descriptive outputs could enhance explainability and clinician
trust in clinical workflows.

</details>


### [41] [A Scenario-Driven Cognitive Approach to Next-Generation AI Memory](https://arxiv.org/abs/2509.13235)
*Linyue Cai,Yuyang Cheng,Xiaoding Shao,Huiming Wang,Yong Zhao,Wei Zhang,Kang Li*

Main category: cs.AI

TL;DR: 本文提出了一种名为COLMA的认知分层记忆架构，通过情景驱动的方法提取功能需求和设计原则，旨在解决当前AI记忆系统在适应性、多模态集成和持续学习方面的局限性，以促进通用人工智能（AGI）的发展。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能向通用人工智能（AGI）发展，对强大且类人记忆系统的需求日益增长。当前的记忆架构存在适应性有限、多模态集成不足以及无法支持持续学习等问题。

Method: 研究采用情景驱动的方法，从具代表性的认知情景中提取核心功能需求，从而推导出一套统一的下一代AI记忆系统设计原则。基于此方法，提出了认知分层记忆架构（COLMA）。

Result: 提出了COgnitive Layered Memory Architecture (COLMA)，这是一个新颖的框架，它将认知情景、记忆过程和存储机制整合到一个内聚的设计中。

Conclusion: COLMA为开发具备终身学习和类人推理能力的AI系统提供了结构化基础，从而有助于通用人工智能（AGI）的务实发展。

Abstract: As artificial intelligence advances toward artificial general intelligence
(AGI), the need for robust and human-like memory systems has become
increasingly evident. Current memory architectures often suffer from limited
adaptability, insufficient multimodal integration, and an inability to support
continuous learning. To address these limitations, we propose a scenario-driven
methodology that extracts essential functional requirements from representative
cognitive scenarios, leading to a unified set of design principles for
next-generation AI memory systems. Based on this approach, we introduce the
\textbf{COgnitive Layered Memory Architecture (COLMA)}, a novel framework that
integrates cognitive scenarios, memory processes, and storage mechanisms into a
cohesive design. COLMA provides a structured foundation for developing AI
systems capable of lifelong learning and human-like reasoning, thereby
contributing to the pragmatic development of AGI.

</details>


### [42] [RepIt: Representing Isolated Targets to Steer Language Models](https://arxiv.org/abs/2509.13281)
*Vincent Siu,Nathan W. Henry,Nicholas Crispino,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.AI

TL;DR: RepIt是一种简单且数据高效的框架，用于隔离大语言模型中的概念特定表示。它实现了精确干预，可以有选择地抑制模型对特定概念的拒绝，同时保持其他方面的安全性，并揭示了干预的局部性和高效性。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型中的激活操纵方法往往会产生超出预期的广泛影响。因此，需要分离出更纯粹的概念向量，以实现更具针对性的干预，并更细粒度地理解LLM行为。

Method: 本文提出了RepIt，一个简单且数据高效的框架，用于隔离概念特定的表示。

Result: RepIt在五种前沿LLM上实现了精确干预：它能选择性地抑制模型对特定概念（如大规模杀伤性武器相关问题）的拒绝，同时保留其他方面的拒绝，使模型能回答WMD问题但仍在标准基准上保持安全评分。研究还发现，纠正信号仅局限于100-200个神经元，并且只需少量（十几个）示例和一块A6000显卡即可提取出鲁棒的目标表示。这种高效性也引发了担忧，即可能以较低的计算和数据成本进行操作，从而规避现有基准。

Conclusion: 通过RepIt解耦拒绝向量，这项工作证明了有针对性的干预可以抵消模型的过度泛化，为更细粒度地控制模型行为奠定了基础。

Abstract: While activation steering in large language models (LLMs) is a growing area
of research, methods can often incur broader effects than desired. This
motivates isolation of purer concept vectors to enable targeted interventions
and understand LLM behavior at a more granular level. We present RepIt, a
simple and data-efficient framework for isolating concept-specific
representations. Across five frontier LLMs, RepIt enables precise
interventions: it selectively suppresses refusal on targeted concepts while
preserving refusal elsewhere, producing models that answer WMD-related
questions while still scoring as safe on standard benchmarks. We further show
that the corrective signal localizes to just 100-200 neurons and that robust
target representations can be extracted from as few as a dozen examples on a
single A6000. This efficiency raises a dual concern: manipulations can be
performed with modest compute and data to extend to underrepresented
data-scarce topics while evading existing benchmarks. By disentangling refusal
vectors with RepIt, this work demonstrates that targeted interventions can
counteract overgeneralization, laying the foundation for more granular control
of model behavior.

</details>


### [43] [Shapes of Cognition for Computational Cognitive Modeling](https://arxiv.org/abs/2509.13288)
*Marjorie McShane,Sergei Nirenburg,Sanjay Oruganti,Jesse English*

Main category: cs.AI

TL;DR: “认知形状”是一种新的计算认知建模范式，用于语言赋能智能体（LEIAs），通过记忆各种知识模式来模拟人类处理复杂世界、最小化认知负荷并应对异常情况的方式。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于为语言赋能智能体（LEIAs）提供一种新的计算认知建模范式，使其能够像人类一样处理现实世界的复杂性，通过预期典型情况、识别模式、习惯性行动、类比推理等方式最小化认知负荷。同时，旨在构建可解释、可扩展且值得信任的智能体系统。

Method: 该方法的核心是“形状”，即感官、语言、概念、情景和程序性知识的记忆星座。智能体利用这些形状来预期典型情况、识别模式、习惯性行动、类比推理、满意化以及最小化认知负荷。对于异常结果，采用基于形状的恢复方法，如即时学习、寻求人类帮助或寻求可操作的理解。该建模涉及特定的目标、假设、建模策略、知识库和认知架构。

Result: “认知形状”范式并非模糊概念，它通过具体的建模策略和认知架构，成功应用于构建可解释、可扩展且值得信任的有用智能体系统（如LEIAs）。此外，该原则具有广泛适用性，能够为基于知识和混合人工智能注入新的活力。

Conclusion: “认知形状”为计算认知建模，特别是语言赋能智能体（LEIAs），提供了一种具体且可广泛应用的范式。它通过模拟人类处理复杂性的方式，提升了智能体系统的可解释性、可扩展性和可信赖性，并有望振兴知识型和混合人工智能。

Abstract: Shapes of cognition is a new conceptual paradigm for the computational
cognitive modeling of Language-Endowed Intelligent Agents (LEIAs). Shapes are
remembered constellations of sensory, linguistic, conceptual, episodic, and
procedural knowledge that allow agents to cut through the complexity of real
life the same way as people do: by expecting things to be typical, recognizing
patterns, acting by habit, reasoning by analogy, satisficing, and generally
minimizing cognitive load to the degree situations permit. Atypical outcomes
are treated using shapes-based recovery methods, such as learning on the fly,
asking a human partner for help, or seeking an actionable, even if imperfect,
situational understanding. Although shapes is an umbrella term, it is not
vague: shapes-based modeling involves particular objectives, hypotheses,
modeling strategies, knowledge bases, and actual models of wide-ranging
phenomena, all implemented within a particular cognitive architecture. Such
specificity is needed both to vet our hypotheses and to achieve our practical
aims of building useful agent systems that are explainable, extensible, and
worthy of our trust, even in critical domains. However, although the LEIA
example of shapes-based modeling is specific, the principles can be applied
more broadly, giving new life to knowledge-based and hybrid AI.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [44] [Artificial Intelligence in Breast Cancer Care: Transforming Preoperative Planning and Patient Education with 3D Reconstruction](https://arxiv.org/abs/2509.12242)
*Mustafa Khanbhai,Giulia Di Nardo,Jun Ma,Vivienne Freitas,Caterina Masino,Ali Dolatabadi,Zhaoxun "Lorenz" Liu,Wey Leong,Wagner H. Souza,Amin Madani*

Main category: cs.CV

TL;DR: 本研究提出了一种结合U-Mamba和人机协作的新型机器学习方法，显著提高了3D解剖结构分割算法的泛化能力，特别是在乳腺MRI数据上，并能生成精确的3D重建，从而改善术前规划、临床决策和患者教育。


<details>
  <summary>Details</summary>
Motivation: 有效的术前规划需要准确的解剖结构分割算法，但传统模型在处理多样化数据集时泛化能力不足，限制了其应用范围。

Method: 研究处理了120份回顾性乳腺MRI数据（2018-2023年），分为三个阶段：匿名化和手动分割T1加权及动态增强序列；全乳、纤维腺体组织和肿瘤的共同配准与分割；使用ITK-SNAP进行3D可视化。采用人机协作方法，利用U-Mamba模型优化分割，旨在提高跨成像场景的泛化能力。通过Dice相似系数评估自动化分割与金标准的一致性，并通过临床医生和患者访谈评估临床相关性。

Result: U-Mamba模型表现出色，在T1加权图像上，全器官的Dice相似系数（DSC）为0.97 (±0.013)，纤维腺体组织为0.96 (±0.024)，肿瘤为0.82 (±0.12)。模型生成了精确的3D重建，能够可视化复杂的解剖特征。临床医生访谈表明，该方法改善了规划、术中导航和决策支持。3D可视化的整合增强了患者教育、沟通和理解。

Conclusion: 这种人机协作的机器学习方法成功地泛化了3D重建和解剖分割算法，适用于不同的患者数据集，为临床医生提供了增强的可视化效果，改善了术前规划，并提供了更有效的患者教育，促进了共同决策，使患者在各种医疗应用中做出明智的选择。

Abstract: Effective preoperative planning requires accurate algorithms for segmenting
anatomical structures across diverse datasets, but traditional models struggle
with generalization. This study presents a novel machine learning methodology
to improve algorithm generalization for 3D anatomical reconstruction beyond
breast cancer applications. We processed 120 retrospective breast MRIs (January
2018-June 2023) through three phases: anonymization and manual segmentation of
T1-weighted and dynamic contrast-enhanced sequences; co-registration and
segmentation of whole breast, fibroglandular tissue, and tumors; and 3D
visualization using ITK-SNAP. A human-in-the-loop approach refined
segmentations using U-Mamba, designed to generalize across imaging scenarios.
Dice similarity coefficient assessed overlap between automated segmentation and
ground truth. Clinical relevance was evaluated through clinician and patient
interviews. U-Mamba showed strong performance with DSC values of 0.97
($\pm$0.013) for whole organs, 0.96 ($\pm$0.024) for fibroglandular tissue, and
0.82 ($\pm$0.12) for tumors on T1-weighted images. The model generated accurate
3D reconstructions enabling visualization of complex anatomical features.
Clinician interviews indicated improved planning, intraoperative navigation,
and decision support. Integration of 3D visualization enhanced patient
education, communication, and understanding. This human-in-the-loop machine
learning approach successfully generalizes algorithms for 3D reconstruction and
anatomical segmentation across patient datasets, offering enhanced
visualization for clinicians, improved preoperative planning, and more
effective patient education, facilitating shared decision-making and empowering
informed patient choices across medical applications.

</details>


### [45] [RU-Net for Automatic Characterization of TRISO Fuel Cross Sections](https://arxiv.org/abs/2509.12244)
*Lu Cai,Fei Xu,Min Xian,Yalei Tang,Shoukun Sun,John Stempien*

Main category: cs.CV

TL;DR: 本研究利用卷积神经网络（CNNs），特别是新开发的RU-Net模型，对辐照后的TRISO燃料颗粒截面图像进行自动分层分割，以提高数据分析的效率和客观性。


<details>
  <summary>Details</summary>
Motivation: 辐照会导致TRISO燃料颗粒发生核膨胀和缓冲层致密化等现象，通过显微镜进行人工分析来获取这些形态变化的统计信息，耗时、繁琐且主观性强，难以处理每个燃料压块中数千个TRISO颗粒。

Method: 研究生成了一个包含2000多张辐照TRISO颗粒截面显微图像及其对应标注图像的大型数据集。基于这些标注图像，使用了多种CNN模型（包括本研究开发的RU-Net以及U-Net、残差网络ResNet和注意力U-Net等现有架构）来自动分割TRISO的不同层。模型性能通过交并比（IoU）进行评估。

Result: 初步结果显示，基于RU-Net的模型在交并比（IoU）方面表现最佳，优于其他测试的CNN模型。

Conclusion: 利用CNN模型可以大大加快TRISO颗粒截面分析的速度，显著减少人工劳动，并提高分割结果的客观性。

Abstract: During irradiation, phenomena such as kernel swelling and buffer
densification may impact the performance of tristructural isotropic (TRISO)
particle fuel. Post-irradiation microscopy is often used to identify these
irradiation-induced morphologic changes. However, each fuel compact generally
contains thousands of TRISO particles. Manually performing the work to get
statistical information on these phenomena is cumbersome and subjective. To
reduce the subjectivity inherent in that process and to accelerate data
analysis, we used convolutional neural networks (CNNs) to automatically segment
cross-sectional images of microscopic TRISO layers. CNNs are a class of
machine-learning algorithms specifically designed for processing structured
grid data. They have gained popularity in recent years due to their remarkable
performance in various computer vision tasks, including image classification,
object detection, and image segmentation. In this research, we generated a
large irradiated TRISO layer dataset with more than 2,000 microscopic images of
cross-sectional TRISO particles and the corresponding annotated images. Based
on these annotated images, we used different CNNs to automatically segment
different TRISO layers. These CNNs include RU-Net (developed in this study), as
well as three existing architectures: U-Net, Residual Network (ResNet), and
Attention U-Net. The preliminary results show that the model based on RU-Net
performs best in terms of Intersection over Union (IoU). Using CNN models, we
can expedite the analysis of TRISO particle cross sections, significantly
reducing the manual labor involved and improving the objectivity of the
segmentation results.

</details>


### [46] [Modular, On-Site Solutions with Lightweight Anomaly Detection for Sustainable Nutrient Management in Agriculture](https://arxiv.org/abs/2509.12247)
*Abigail R. Cohen,Yuming Sun,Zhihao Qin,Harsh S. Muriki,Zihao Xiao,Yeonju Lee,Matthew Housley,Andrew F. Sharkey,Rhuanito S. Ferrarezi,Jing Li,Lu Gan,Yongsheng Chen*

Main category: cs.CV

TL;DR: 本研究提出了一种分层管道，结合多光谱成像和机器学习/深度学习方法，用于作物养分异常检测和状态估计，并在效率和准确性之间进行了权衡分析，以实现农业可持续性。


<details>
  <summary>Details</summary>
Motivation: 当前的养分管理方法分析耗时，无法实现实时优化；快速表型分析计算密集，难以在资源受限环境下部署。因此，需要一种高效、实时的解决方案来优化作物生长和可持续资源消耗。

Method: 本研究提出了一个灵活的分层管道，用于异常检测和状态估计（鲜重、干物质和组织养分），并对不同效率-准确度范围的方法进行了全面的能耗分析。通过一项包含三种处理（T1-100%、T2-50%、T3-25%肥料强度）和多光谱成像（MSI）的养分耗竭实验，开发了一个使用自编码器（AE）进行早期预警的层次管道。此外，比较了两种不同复杂度的状态估计模块：基于植被指数（VI）特征的机器学习（随机森林，RF）和基于原始全图像的深度学习（Vision Transformer，ViT）。

Result: 结果表明，异常检测效率高（移植后9天对T3样本的净检测率为73%），且能耗远低于浪费氮肥所隐含的能耗。状态估计模块显示出权衡：ViT在磷和钙估计上优于RF（R2分别为0.61 vs. 0.58，0.48 vs. 0.35），但能耗更高。

Conclusion: 该模块化管道为边缘诊断和农业可持续性提供了实际机会。

Abstract: Efficient nutrient management is critical for crop growth and sustainable
resource consumption (e.g., nitrogen, energy). Current approaches require
lengthy analyses, preventing real-time optimization; similarly, imaging
facilitates rapid phenotyping but can be computationally intensive, preventing
deployment under resource constraints. This study proposes a flexible, tiered
pipeline for anomaly detection and status estimation (fresh weight, dry mass,
and tissue nutrients), including a comprehensive energy analysis of approaches
that span the efficiency-accuracy spectrum. Using a nutrient depletion
experiment with three treatments (T1-100%, T2-50%, and T3-25% fertilizer
strength) and multispectral imaging (MSI), we developed a hierarchical pipeline
using an autoencoder (AE) for early warning. Further, we compared two status
estimation modules of different complexity for more detailed analysis:
vegetation index (VI) features with machine learning (Random Forest, RF) and
raw whole-image deep learning (Vision Transformer, ViT). Results demonstrated
high-efficiency anomaly detection (73% net detection of T3 samples 9 days after
transplanting) at substantially lower energy than embodied energy in wasted
nitrogen. The state estimation modules show trade-offs, with ViT outperforming
RF on phosphorus and calcium estimation (R2 0.61 vs. 0.58, 0.48 vs. 0.35) at
higher energy cost. With our modular pipeline, this work opens opportunities
for edge diagnostics and practical opportunities for agricultural
sustainability.

</details>


### [47] [Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics](https://arxiv.org/abs/2509.12248)
*Yuriel Ryan,Rui Yang Tan,Kenny Tsu Wei Choo,Roy Ka-Wei Lee*

Main category: cs.CV

TL;DR: 该研究引入了PixelHumor数据集，用于评估大型多模态模型（LMMs）在理解多模态幽默和叙事序列方面的能力，发现当前LMMs表现远低于人类水平。


<details>
  <summary>Details</summary>
Motivation: 理解幽默是社交智能的核心，但对大型多模态模型（LMMs）来说仍是巨大挑战。现有模型在整合视觉和文本线索以理解连贯叙事和幽默方面存在显著局限。

Method: 引入了PixelHumor，一个包含2,800个带注释的多面板漫画的基准数据集。该数据集旨在评估LMMs解释多模态幽默和识别叙事序列的能力。研究人员使用最先进的LMMs进行了实验。

Result: 实验结果显示，最先进的LMMs存在显著差距。例如，在面板排序任务中，顶级模型仅达到61%的准确率，远低于人类表现，这揭示了当前模型在整合视觉和文本线索以理解连贯叙事和幽默方面的关键局限。

Conclusion: 当前LMMs在多模态幽默和叙事理解方面存在显著不足。PixelHumor提供了一个严格的评估框架，旨在推动LMMs的发展，使其能更好地参与自然、具有社会意识的互动。

Abstract: Understanding humor is a core aspect of social intelligence, yet it remains a
significant challenge for Large Multimodal Models (LMMs). We introduce
PixelHumor, a benchmark dataset of 2,800 annotated multi-panel comics designed
to evaluate LMMs' ability to interpret multimodal humor and recognize narrative
sequences. Experiments with state-of-the-art LMMs reveal substantial gaps: for
instance, top models achieve only 61% accuracy in panel sequencing, far below
human performance. This underscores critical limitations in current models'
integration of visual and textual cues for coherent narrative and humor
understanding. By providing a rigorous framework for evaluating multimodal
contextual and narrative reasoning, PixelHumor aims to drive the development of
LMMs that better engage in natural, socially aware interactions.

</details>


### [48] [OnlineHOI: Towards Online Human-Object Interaction Generation and Perception](https://arxiv.org/abs/2509.12250)
*Yihong Ji,Yunze Liu,Yiyao Zhuo,Weijiang Yu,Fei Ma,Joshua Huang,Fei Yu*

Main category: cs.CV

TL;DR: 本文提出在线人机交互（HOI）生成与感知任务，并引入OnlineHOI框架。该框架基于Mamba并结合记忆机制，解决了传统离线HOI方法在实时场景中的不足，并在多个在线HOI任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 人机交互（HOI）在机器人、AR/VR和人类行为理解等领域至关重要。然而，现有方法多为离线模式，可以访问整个交互序列的信息。实际场景中，信息仅来自当前和历史数据（在线模式）。研究发现离线方法在在线环境中表现不佳，因此需要新的在线HOI建模方法。

Method: 作者提出了两个新任务：在线HOI生成和在线HOI感知。为解决这些任务，他们引入了OnlineHOI框架，该框架是一种基于Mamba架构的网络，并结合了记忆机制。Mamba擅长处理流式数据，而记忆机制则能高效整合历史信息。

Result: OnlineHOI框架在Core4D和OAKINK2的在线生成任务以及HOI4D的在线感知任务上均取得了最先进的（state-of-the-art）结果。

Conclusion: OnlineHOI框架通过结合Mamba强大的流数据建模能力和记忆机制对历史信息的有效整合，成功解决了在线人机交互的生成与感知问题，显著提升了该领域在实时场景中的应用潜力。

Abstract: The perception and generation of Human-Object Interaction (HOI) are crucial
for fields such as robotics, AR/VR, and human behavior understanding. However,
current approaches model this task in an offline setting, where information at
each time step can be drawn from the entire interaction sequence. In contrast,
in real-world scenarios, the information available at each time step comes only
from the current moment and historical data, i.e., an online setting. We find
that offline methods perform poorly in an online context. Based on this
observation, we propose two new tasks: Online HOI Generation and Perception. To
address this task, we introduce the OnlineHOI framework, a network architecture
based on the Mamba framework that employs a memory mechanism. By leveraging
Mamba's powerful modeling capabilities for streaming data and the Memory
mechanism's efficient integration of historical information, we achieve
state-of-the-art results on the Core4D and OAKINK2 online generation tasks, as
well as the online HOI4D perception task.

</details>


### [49] [EfficientNet-Based Multi-Class Detection of Real, Deepfake, and Plastic Surgery Faces](https://arxiv.org/abs/2509.12258)
*Li Kun,Milena Radenkovic*

Main category: cs.CV

TL;DR: 深度学习，特别是Deepfake技术，在带来进步的同时，也对社会生活、个人隐私、国家安全及政治经济结构构成严重威胁。


<details>
  <summary>Details</summary>
Motivation: 深度学习在各领域的广泛应用及其产生的双面性，特别是Deepfake技术对社会造成的负面影响和潜在风险，促使本文对其进行分析。

Method: 本文主要通过描述和分析Deepfake技术的运作方式及其在不同场景下的不良应用，来阐述其对社会造成的危害。文中未提及具体的实验或研究方法。

Result: Deepfake技术能够生成难以区分的虚假图像和视频，损害面部识别系统功能，侵犯隐私，损害名人声誉，威胁国家安全。它还被用于误导用户、操纵选举活动，并破坏国家政治和经济结构。

Conclusion: 尽管深度学习带来了技术进步，但Deepfake等技术的不当应用给人类社会带来了多方面的严重风险，需要警惕其对个人和社会稳定造成的潜在危害。

Abstract: Currently, deep learning has been utilised to tackle several difficulties in
our everyday lives. It not only exhibits progress in computer vision but also
constitutes the foundation for several revolutionary technologies. Nonetheless,
similar to all phenomena, the use of deep learning in diverse domains has
produced a multifaceted interaction of advantages and disadvantages for human
society. Deepfake technology has advanced, significantly impacting social life.
However, developments in this technology can affect privacy, the reputations of
prominent personalities, and national security via software development. It can
produce indistinguishable counterfeit photographs and films, potentially
impairing the functionality of facial recognition systems, so presenting a
significant risk.
  The improper application of deepfake technology produces several detrimental
effects on society. Face-swapping programs mislead users by altering persons'
appearances or expressions to fulfil particular aims or to appropriate personal
information. Deepfake technology permeates daily life through such techniques.
Certain individuals endeavour to sabotage election campaigns or subvert
prominent political figures by creating deceptive pictures to influence public
perception, causing significant harm to a nation's political and economic
structure.

</details>


### [50] [A Modern Look at Simplicity Bias in Image Classification Tasks](https://arxiv.org/abs/2509.12265)
*Xiaoguang Chang,Teng Wang,Changyin Sun*

Main category: cs.CV

TL;DR: 本文研究了CLIP模型中的“简单性偏差”（SB）及其在各种图像分类任务中的表现。作者提出了一种新的频率感知度量方法来衡量SB，并发现SB的强度与不同任务（如OOD泛化和对抗鲁棒性）的性能表现出不同的相关性，强调了模型归纳偏置与任务特性对齐的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多集中在简单模型或合成任务上，难以在大模型中衡量简单性偏差（SB），且对SB在各种图像分类任务中的作用知之甚少。然而，SB是神经网络泛化能力的关键因素，过度的SB可能损害复杂任务的性能，且所需偏差因任务而异。

Method: 首先，理论分析了现有用于小模型的复杂性度量方法的局限性。其次，提出了一种新的“频率感知度量”方法，以捕捉更细粒度的SB差异。该方法在经过两种SB调制方法的CLIP模型上进行了验证，并与现有度量进行了比较。最后，研究了这些模型的SB与一系列图像分类任务（包括零样本和微调设置）性能之间的关系。

Result: 提出的频率感知度量方法比现有方法更具信息量和一致性。实验揭示了SB与模型性能之间存在一系列不同的行为，例如，更强的SB与更好的OOD泛化能力相关，但与对抗鲁棒性则呈负相关。

Conclusion: 研究结果强调了将模型的归纳偏置（如简单性偏差）与目标任务的特性对齐的重要性，这有助于提升模型性能。

Abstract: The simplicity Bias (SB) of neural networks, i.e.\ their tendency to
represent simple functions, is a key factor in their generalization
capabilities. Recent studies show that an excessive SB may harm performance on
complex tasks, and the need for this bias varies across tasks. Many of these
studies focus on simple models or synthetic tasks. It remains challenging to
measure the SB in large models and little is known about the relevance of the
SB to various image classification tasks.
  In this paper, we investigate the relationship between the SB in CLIP models
and their performance across image classification tasks. First, we
theoretically analyze the potential limitation of existing measures of
complexity that have been used to characterize small models. To address this,
we propose a frequency-aware measure capturing finer-grained SB differences. We
validate this measure on CLIP models subjected to two recent SB-modulation
methods, demonstrating that it is more informative and consistent than previous
measures. Second, we examine the relation between the SB of those models and
their performance across a range of image classification tasks, including
zero-shot and fine-tuning settings. These experiments reveal a range of
behaviors. For example, a stronger SB correlates with a better performance on
OOD generalization than on adversarial robustness. These results highlight the
benefits of aligning a model's inductive biases with the characteristics of the
target task.

</details>


### [51] [ResidualViT for Efficient Temporally Dense Video Encoding](https://arxiv.org/abs/2509.13255)
*Mattia Soldan,Fabian Caba Heilbron,Bernard Ghanem,Josef Sivic,Bryan Russell*

Main category: cs.CV

TL;DR: 本文提出ResidualViT架构和轻量级蒸馏策略，旨在高效计算视频中时间密集型任务的帧级特征，显著降低计算成本并提高推理速度，同时保持与原始基础模型相近的准确性。


<details>
  <summary>Details</summary>
Motivation: 视频理解中的多项任务（如自然语言时间视频定位、时间活动定位和音频描述生成）需要对高时间分辨率的帧进行“时间密集型”推理。然而，计算这些任务所需的帧级特征在计算上成本高昂。

Method: 1. 引入ResidualViT架构：一种Vision Transformer，利用视频中大量的时间冗余来高效计算时间密集型帧级特征。该架构包含可学习的残差连接以确保连续帧之间的时间一致性，以及一个令牌减少模块通过选择性丢弃时间冗余信息并重用预训练基础模型的权重来提高处理速度。2. 提出一种轻量级蒸馏策略，用于近似原始基础模型的帧级特征。

Result: 在四项任务和五个数据集上（包括零样本和全监督设置）评估了该方法，结果显示计算成本显著降低（高达60%），推理速度提高（快达2.5倍），同时准确性与原始基础模型非常接近。

Conclusion: 所提出的ResidualViT架构和轻量级蒸馏策略能够有效降低时间密集型视频任务中帧级特征计算的成本，提高推理速度，且在保持高准确性的前提下实现这些改进。

Abstract: Several video understanding tasks, such as natural language temporal video
grounding, temporal activity localization, and audio description generation,
require "temporally dense" reasoning over frames sampled at high temporal
resolution. However, computing frame-level features for these tasks is
computationally expensive given the temporal resolution requirements. In this
paper, we make three contributions to reduce the cost of computing features for
temporally dense tasks. First, we introduce a vision transformer (ViT)
architecture, dubbed ResidualViT, that leverages the large temporal redundancy
in videos to efficiently compute temporally dense frame-level features. Our
architecture incorporates (i) learnable residual connections that ensure
temporal consistency across consecutive frames and (ii) a token reduction
module that enhances processing speed by selectively discarding temporally
redundant information while reusing weights of a pretrained foundation model.
Second, we propose a lightweight distillation strategy to approximate the
frame-level features of the original foundation model. Finally, we evaluate our
approach across four tasks and five datasets, in both zero-shot and fully
supervised settings, demonstrating significant reductions in computational cost
(up to 60%) and improvements in inference speed (up to 2.5x faster), all while
closely approximating the accuracy of the original foundation model.

</details>


### [52] [GraphDerm: Fusing Imaging, Physical Scale, and Metadata in a Population-Graph Classifier for Dermoscopic Lesions](https://arxiv.org/abs/2509.12277)
*Mehdi Yousefzadeh,Parsa Esfahanian,Sara Rashidifar,Hossein Salahshoor Gavalan,Negar Sadat Rafiee Tabatabaee,Saeid Gorgin,Dara Rahmati,Maryam Daneshpazhooh*

Main category: cs.CV

TL;DR: GraphDerm是一个将图像、毫米级校准和患者元数据融合到人群图框架中的皮肤镜多类别分类系统，它利用图神经网络（GNNs）显著优于纯图像基线方法。


<details>
  <summary>Details</summary>
Motivation: 皮肤镜AI通常忽略了患者元数据（年龄、性别、部位）和几何分析所需的物理尺度信息，而这些信息对提高诊断准确性至关重要。

Method: 研究人员整理了ISIC 2018/2019数据集，合成了带标尺的图像，并训练U-Net（SE-ResNet-18）进行病灶和标尺分割。通过轻量级1D-CNN从标尺掩码中回归每毫米像素数，并计算真实尺度的病灶描述符。节点特征使用EfficientNet-B3提取，边编码元数据/几何相似性。最终使用谱GNN进行半监督节点分类，并以纯图像ANN作为基线。

Result: 标尺和病灶分割的Dice系数分别达到0.904和0.908；尺度回归的平均绝对误差（MAE）为1.5像素。GraphDerm的AUC达到0.9812（稀疏图版本为0.9788），远高于纯图像基线的0.9440。各类别AUC通常在0.97-0.99范围内。稀疏图也能保持接近最优的准确性。

Conclusion: 在人群图中统一校准尺度、病灶几何形状和元数据，在ISIC-2019数据集上比纯图像管道取得了显著的性能提升。稀疏图保持了接近最优的准确性，表明可以高效部署。这种尺度感知、基于图的AI为皮肤镜决策支持提供了有前景的方向。

Abstract: Introduction. Dermoscopy aids melanoma triage, yet image-only AI often
ignores patient metadata (age, sex, site) and the physical scale needed for
geometric analysis. We present GraphDerm, a population-graph framework that
fuses imaging, millimeter-scale calibration, and metadata for multiclass
dermoscopic classification, to the best of our knowledge the first ISIC-scale
application of GNNs to dermoscopy. Methods. We curate ISIC 2018/2019,
synthesize ruler-embedded images with exact masks, and train U-Nets
(SE-ResNet-18) for lesion and ruler segmentation. Pixels-per-millimeter are
regressed from the ruler-mask two-point correlation via a lightweight 1D-CNN.
From lesion masks we compute real-scale descriptors (area, perimeter, radius of
gyration). Node features use EfficientNet-B3; edges encode metadata/geometry
similarity (fully weighted or thresholded). A spectral GNN performs
semi-supervised node classification; an image-only ANN is the baseline.
Results. Ruler and lesion segmentation reach Dice 0.904 and 0.908; scale
regression attains MAE 1.5 px (RMSE 6.6). The graph attains AUC 0.9812, with a
thresholded variant using about 25% of edges preserving AUC 0.9788 (vs. 0.9440
for the image-only baseline); per-class AUCs typically fall in the 0.97-0.99
range. Conclusion. Unifying calibrated scale, lesion geometry, and metadata in
a population graph yields substantial gains over image-only pipelines on
ISIC-2019. Sparser graphs retain near-optimal accuracy, suggesting efficient
deployment. Scale-aware, graph-based AI is a promising direction for
dermoscopic decision support; future work will refine learned edge semantics
and evaluate on broader curated benchmarks.

</details>


### [53] [Image Realness Assessment and Localization with Multimodal Features](https://arxiv.org/abs/2509.13289)
*Lovish Kaushik,Agnij Biswas,Somdyuti Paul*

Main category: cs.CV

TL;DR: 本文提出一个框架，利用视觉-语言模型生成的文本描述，量化AI生成图像的整体真实感并识别局部视觉不一致区域，有效提升真实感预测性能并生成稠密真实感图。


<details>
  <summary>Details</summary>
Motivation: 量化AI生成图像的感知真实感并识别视觉不一致区域对于AI图像的实际应用至关重要，同时也能为生成式AI的训练提供真实感反馈，以提升其照片真实感。

Method: 该研究引入了一个多模态框架，利用在大型数据集上训练的视觉-语言模型（VLM）生成的视觉不一致性文本描述，来代替人工标注，实现AI生成图像的整体客观真实感评估和局部不一致性识别。

Result: 实验结果表明，所提出的多模态方法提高了客观真实感预测的性能，并生成了稠密的真实感图，能够有效区分图像中真实和不真实的区域。

Conclusion: 该多模态方法能有效量化AI生成图像的真实感并识别局部不一致性，为AI图像的实用性和照片真实感改进提供了可靠的工具。

Abstract: A reliable method of quantifying the perceptual realness of AI-generated
images and identifying visually inconsistent regions is crucial for practical
use of AI-generated images and for improving photorealism of generative AI via
realness feedback during training. This paper introduces a framework that
accomplishes both overall objective realness assessment and local inconsistency
identification of AI-generated images using textual descriptions of visual
inconsistencies generated by vision-language models trained on large datasets
that serve as reliable substitutes for human annotations. Our results
demonstrate that the proposed multimodal approach improves objective realness
prediction performance and produces dense realness maps that effectively
distinguish between realistic and unrealistic spatial regions.

</details>


### [54] [PATIMT-Bench: A Multi-Scenario Benchmark for Position-Aware Text Image Machine Translation in Large Vision-Language Models](https://arxiv.org/abs/2509.12278)
*Wanru Zhuang,Wenbo Li,Zhibin Lan,Xu Han,Peng Li,Jinsong Su*

Main category: cs.CV

TL;DR: 本文将传统文本图像机器翻译（TIMT）扩展为位置感知TIMT（PATIMT），以实现细粒度和布局保留翻译。为此，作者构建了PATIMT基准（PATIMTBench），包含10种真实场景，并引入自适应OCR精炼流程。通过在高质量数据集上微调，紧凑型大视觉语言模型（LVLMs）在PATIMT的两个子任务上均达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的文本图像机器翻译（TIMT）研究主要关注提供图像中所有文本的翻译，但忽略了提供文本的边界框，并且只覆盖了有限的场景。这导致了缺乏细粒度和布局保留的翻译，而这在实际应用中具有重要价值但尚未得到充分探索。

Method: 本文提出了位置感知TIMT（PATIMT）任务，旨在支持细粒度和布局保留的翻译，并将其分为区域特定翻译和带接地的全图像翻译两个子任务。为支持PATIMT并进行公平评估，作者构建了PATIMT基准（PATIMTBench），该基准包含10种多样化的真实世界场景。具体方法包括：引入自适应图像OCR精炼流程，根据场景自适应选择OCR工具并精炼文本丰富图像的结果；构建一个包含1200个由人工专家手动标注和审查的高质量测试集，以确保评估可靠性；最后，在所构建的数据集上微调紧凑型大视觉语言模型（LVLMs）。

Result: 经过数据微调后，紧凑型大视觉语言模型（LVLMs）在PATIMT的两个子任务上均取得了最先进的性能。实验结果还突出显示了训练数据的可扩展性和泛化能力。

Conclusion: PATIMT是一个具有巨大实际价值但尚未充分探索的任务，本文通过定义PATIMT任务、构建全面的PATIMTBench基准和高质量测试集，并引入自适应OCR精炼流程，为该领域奠定了基础。紧凑型LVLMs在PATIMT上表现出色，证明了所构建数据和方法的有效性，并为未来的研究提供了有力的支持。

Abstract: Text Image Machine Translation (TIMT) aims to translate texts embedded within
an image into another language. Current TIMT studies primarily focus on
providing translations for all the text within an image, while neglecting to
provide bounding boxes and covering limited scenarios. In this work, we extend
traditional TIMT into position-aware TIMT (PATIMT), aiming to support
fine-grained and layoutpreserving translation, which holds great practical
value but remains largely unexplored. This task comprises two key sub-tasks:
regionspecific translation and full-image translation with grounding. To
support existing models on PATIMT and conduct fair evaluation, we construct the
PATIMT benchmark (PATIMTBench), which consists of 10 diverse real-world
scenarios. Specifically, we introduce an Adaptive Image OCR Refinement
Pipeline, which adaptively selects appropriate OCR tools based on scenario and
refines the results of text-rich images. To ensure evaluation reliability, we
further construct a test set, which contains 1,200 high-quality instances
manually annotated and reviewed by human experts. After fine-tuning on our
data, compact Large Vision-Language Models (LVLMs) achieve state-of-the-art
performance on both sub-tasks. Experimental results also highlight the
scalability and generalizability of our training data

</details>


### [55] [Domain Adaptive SAR Wake Detection: Leveraging Similarity Filtering and Memory Guidance](https://arxiv.org/abs/2509.12279)
*He Gao,Baoxiang Huang,Milena Radenkovic,Borui Li,Ge Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为SimMemDA的相似性引导和记忆引导域适应框架，用于解决合成孔径雷达（SAR）图像中船舶尾迹检测的跨模态域适应挑战，通过实例级特征相似性过滤和特征记忆指导来提高检测的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: SAR图像中的尾迹特征抽象且嘈杂，难以准确标注。而光学图像虽然提供清晰的视觉线索，但基于光学数据训练的模型在应用于SAR图像时会因域偏移而性能下降。因此，需要解决跨模态域适应问题以实现SAR图像的船舶尾迹检测。

Method: 该方法首先利用WakeGAN对光学图像进行风格迁移，生成接近SAR风格的伪图像。其次，设计了实例级特征相似性过滤机制来识别并优先处理具有目标域分布特征的源样本，以减少负迁移。同时，引入了结合K近邻置信度加权融合策略的特征-置信度记忆库，以动态校准目标域的伪标签。最后，通过区域混合训练，结合源域标注和校准后的目标域伪标签，进一步增强泛化能力。

Result: 实验结果表明，所提出的SimMemDA方法能够有效提高跨模态船舶尾迹检测任务的准确性和鲁棒性。

Conclusion: SimMemDA方法在解决SAR图像船舶尾迹检测的跨模态域适应问题上是有效且可行的，显著提升了检测性能。

Abstract: Synthetic Aperture Radar (SAR), with its all-weather and wide-area
observation capabilities, serves as a crucial tool for wake detection. However,
due to its complex imaging mechanism, wake features in SAR images often appear
abstract and noisy, posing challenges for accurate annotation. In contrast,
optical images provide more distinct visual cues, but models trained on optical
data suffer from performance degradation when applied to SAR images due to
domain shift. To address this cross-modal domain adaptation challenge, we
propose a Similarity-Guided and Memory-Guided Domain Adaptation (termed
SimMemDA) framework for unsupervised domain adaptive ship wake detection via
instance-level feature similarity filtering and feature memory guidance.
Specifically, to alleviate the visual discrepancy between optical and SAR
images, we first utilize WakeGAN to perform style transfer on optical images,
generating pseudo-images close to the SAR style. Then, instance-level feature
similarity filtering mechanism is designed to identify and prioritize source
samples with target-like distributions, minimizing negative transfer.
Meanwhile, a Feature-Confidence Memory Bank combined with a K-nearest neighbor
confidence-weighted fusion strategy is introduced to dynamically calibrate
pseudo-labels in the target domain, improving the reliability and stability of
pseudo-labels. Finally, the framework further enhances generalization through
region-mixed training, strategically combining source annotations with
calibrated target pseudo-labels. Experimental results demonstrate that the
proposed SimMemDA method can improve the accuracy and robustness of cross-modal
ship wake detection tasks, validating the effectiveness and feasibility of the
proposed method.

</details>


### [56] [Uncertainty-Aware Hourly Air Temperature Mapping at 2 km Resolution via Physics-Guided Deep Learning](https://arxiv.org/abs/2509.12329)
*Shengjie Kris Liu,Siqin Wang,Lu Zhang*

Main category: cs.CV

TL;DR: 本研究提出了一种数据驱动、物理引导的深度学习方法（Amplifier Air-Transformer），用于生成美国本土每小时2公里分辨率的近地表气温数据，通过重建云层遮挡的卫星地表温度并将其转换为气温，实现了1.93°C的精度。


<details>
  <summary>Details</summary>
Motivation: 尽管气象站提供连续监测，卫星提供广阔空间覆盖，但目前没有单一数据源能无缝地提供时空连续的近地表气温数据。

Method: 该方法名为Amplifier Air-Transformer，首先通过一个结合了年度温度周期编码、线性项放大ERA5温度和卷积层捕捉时空变化的神经网络，重建被云层遮挡的GOES-16地表温度数据。然后，另一个神经网络利用地表关键属性的潜在关系，将重建的地表温度转换为气温。此外，该方法通过深度集成学习增强了预测不确定性估计，以提高可靠性。该模型在777亿地表温度像素和1.55亿气象站气温记录（2018-2024年）上进行构建和测试。

Result: 在基于气象站的验证中，该方法实现了每小时气温映射精度为1.93°C。

Conclusion: 所提出的方法简化了地表温度重建和气温预测过程，可扩展到其他卫星数据源，以实现高时空分辨率的无缝气温监测。

Abstract: Near-surface air temperature is a key physical property of the Earth's
surface. Although weather stations offer continuous monitoring and satellites
provide broad spatial coverage, no single data source offers seamless data in a
spatiotemporal fashion. Here, we propose a data-driven, physics-guided deep
learning approach to generate hourly air temperature data at 2 km resolution
over the contiguous United States. The approach, called Amplifier
Air-Transformer, first reconstructs GOES-16 surface temperature data obscured
by clouds. It does so through a neural network encoded with the annual
temperature cycle, incorporating a linear term to amplify ERA5 temperature
values at finer scales and convolutional layers to capture spatiotemporal
variations. Then, another neural network transforms the reconstructed surface
temperature into air temperature by leveraging its latent relationship with key
Earth surface properties. The approach is further enhanced with predictive
uncertainty estimation through deep ensemble learning to improve reliability.
The proposed approach is built and tested on 77.7 billion surface temperature
pixels and 155 million air temperature records from weather stations across the
contiguous United States (2018-2024), achieving hourly air temperature mapping
accuracy of 1.93 C in station-based validation. The proposed approach
streamlines surface temperature reconstruction and air temperature prediction,
and it can be extended to other satellite sources for seamless air temperature
monitoring at high spatiotemporal resolution. The generated data of this study
can be downloaded at https://doi.org/10.5281/zenodo.15252812, and the project
webpage can be found at https://skrisliu.com/HourlyAirTemp2kmUSA/.

</details>


### [57] [DS@GT AnimalCLEF: Triplet Learning over ViT Manifolds with Nearest Neighbor Classification for Animal Re-identification](https://arxiv.org/abs/2509.12353)
*Anthony Miyaguchi,Chandrasekaran Maruthaiyannan,Charles R. Clark*

Main category: cs.CV

TL;DR: 本文参与AnimalCLEF 2025重识别挑战，发现后置度量学习的有效性高度依赖于骨干嵌入的初始质量和领域特异性。领域特定预训练对细粒度重识别至关重要。


<details>
  <summary>Details</summary>
Motivation: 参与AnimalCLEF 2025重识别挑战赛，旨在探索不同骨干模型（通用型与领域特定型）对后置度量学习效果的影响，并解决细粒度、数据有限的重识别任务。

Method: 团队比较了两种骨干模型：通用型DINOv2和领域特定型MegaDescriptor。在此基础上，应用了三元组学习（triplet-learning）投影头进行后置度量学习，并结合K-近邻（KNN）分类器和鲁棒阈值化来识别已知个体或标记新个体。

Result: 三元组学习使领域特定MegaDescriptor模型的性能提高了0.13点，但对通用型DINOv2模型的性能提升微乎其微（仅0.03点）。研究表明，通用型流形更难通过精炼来适应细粒度任务，这体现在验证损失停滞和可视化结果上。

Conclusion: 研究强调了为专业化、数据有限的重识别任务精炼通用特征的局限性，并突出了领域特定预训练的重要性。

Abstract: This paper details the DS@GT team's entry for the AnimalCLEF 2025
re-identification challenge. Our key finding is that the effectiveness of
post-hoc metric learning is highly contingent on the initial quality and
domain-specificity of the backbone embeddings. We compare a general-purpose
model (DINOv2) with a domain-specific model (MegaDescriptor) as a backbone. A
K-Nearest Neighbor classifier with robust thresholding then identifies known
individuals or flags new ones. While a triplet-learning projection head
improved the performance of the specialized MegaDescriptor model by 0.13
points, it yielded minimal gains (0.03) for the general-purpose DINOv2 on
averaged BAKS and BAUS. We demonstrate that the general-purpose manifold is
more difficult to reshape for fine-grained tasks, as evidenced by stagnant
validation loss and qualitative visualizations. This work highlights the
critical limitations of refining general-purpose features for specialized,
limited-data re-ID tasks and underscores the importance of domain-specific
pre-training. The implementation for this work is publicly available at
github.com/dsgt-arc/animalclef-2025.

</details>


### [58] [GhostNetV3-Small: A Tailored Architecture and Comparative Study of Distillation Strategies for Tiny Images](https://arxiv.org/abs/2509.12380)
*Florian Zager,Hamza A. A. Gardi*

Main category: cs.CV

TL;DR: 本文探讨了为资源受限设备压缩和调整深度学习模型的方法，特别是提出并评估了GhostNetV3-Small模型在低分辨率图像分类任务上的表现，并比较了不同知识蒸馏策略的效果。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络计算需求高，难以部署在资源受限的边缘设备上，因此需要探索模型压缩和适应策略。

Method: 研究以GhostNetV3为基础，提出了GhostNetV3-Small变体，专门针对CIFAR-10等低分辨率输入进行架构调整。同时，比较了传统知识蒸馏、教师助理和教师集成等多种知识蒸馏技术。

Result: GhostNetV3-Small在CIFAR-10数据集上显著优于原始GhostNetV3，达到了93.94%的准确率。然而，所有测试的知识蒸馏策略均导致准确率下降。

Conclusion: 研究表明，在小规模图像分类任务中，架构适应可能比知识蒸馏更有效。未来需要进一步研究低分辨率领域中有效的模型设计和高级蒸馏技术。

Abstract: Deep neural networks have achieved remarkable success across a range of
tasks, however their computational demands often make them unsuitable for
deployment on resource-constrained edge devices. This paper explores strategies
for compressing and adapting models to enable efficient inference in such
environments. We focus on GhostNetV3, a state-of-the-art architecture for
mobile applications, and propose GhostNetV3-Small, a modified variant designed
to perform better on low-resolution inputs such as those in the CIFAR-10
dataset. In addition to architectural adaptation, we provide a comparative
evaluation of knowledge distillation techniques, including traditional
knowledge distillation, teacher assistants, and teacher ensembles. Experimental
results show that GhostNetV3-Small significantly outperforms the original
GhostNetV3 on CIFAR-10, achieving an accuracy of 93.94%. Contrary to
expectations, all examined distillation strategies led to reduced accuracy
compared to baseline training. These findings indicate that architectural
adaptation can be more impactful than distillation in small-scale image
classification tasks, highlighting the need for further research on effective
model design and advanced distillation techniques for low-resolution domains.

</details>


### [59] [From Orthomosaics to Raw UAV Imagery: Enhancing Palm Detection and Crown-Center Localization](https://arxiv.org/abs/2509.12400)
*Rongkun Zhu,Kangning Cui,Wei Tang,Rui-Feng Wang,Sarra Alqahtani,David Lutz,Fan Yang,Paul Fine,Jordan Karubian,Robert Plemmons,Jean-Michel Morel,Victor Pauca,Miles Silman*

Main category: cs.CV

TL;DR: 本研究发现，与正射影像相比，原始无人机影像结合树冠中心标注在个体树木检测和定位方面表现更优，尤其适用于实地部署；而正射影像在跨域泛化方面仍有价值。


<details>
  <summary>Details</summary>
Motivation: 个体树木的精确测绘对生态监测和森林管理至关重要。现有无人机正射影像存在拼接伪影和繁重预处理的局限性，不适合实地部署，因此需要探索原始无人机影像的应用潜力。

Method: 研究通过比较正射影像和原始影像在棕榈树检测和树冠中心定位方面的性能，包括域内和跨域迁移。同时，评估了树冠中心标注对定位精度的提升作用（超越边界框中心）。研究使用了最先进的检测器和关键点模型。

Result: 结果表明，在与部署相关的场景中，原始影像表现更优；而正射影像在稳健的跨域泛化方面仍有价值。在训练中加入树冠中心标注进一步提高了定位精度，并能为后续生态分析提供精确的树木位置。

Conclusion: 研究结果为基于无人机的生物多样性和保护监测提供了实用指导，建议在实地部署场景中优先使用原始无人机影像并结合树冠中心标注以获得更精准的定位。

Abstract: Accurate mapping of individual trees is essential for ecological monitoring
and forest management. Orthomosaic imagery from unmanned aerial vehicles (UAVs)
is widely used, but stitching artifacts and heavy preprocessing limit its
suitability for field deployment. This study explores the use of raw UAV
imagery for palm detection and crown-center localization in tropical forests.
Two research questions are addressed: (1) how detection performance varies
across orthomosaic and raw imagery, including within-domain and cross-domain
transfer, and (2) to what extent crown-center annotations improve localization
accuracy beyond bounding-box centroids. Using state-of-the-art detectors and
keypoint models, we show that raw imagery yields superior performance in
deployment-relevant scenarios, while orthomosaics retain value for robust
cross-domain generalization. Incorporating crown-center annotations in training
further improves localization and provides precise tree positions for
downstream ecological analyses. These findings offer practical guidance for
UAV-based biodiversity and conservation monitoring.

</details>


### [60] [DYNAMO: Dependency-Aware Deep Learning Framework for Articulated Assembly Motion Prediction](https://arxiv.org/abs/2509.12430)
*Mayank Patel,Rahul Jain,Asim Unmesh,Karthik Ramani*

Main category: cs.CV

TL;DR: 本文提出MechBench数据集和DYNAMO神经网络模型，旨在从CAD点云中学习复杂机械装配体（如齿轮）的耦合运动，实现高精度和时间一致性的运动轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法在理解机械装配体（如齿轮）的运动方面存在不足，因为其运动源于几何耦合（通过啮合齿或对齐轴），而非简化的运动学结构或预定义关节。这使得仅凭几何信息推断关系运动变得困难。

Method: 本文引入MechBench，一个包含693个合成齿轮装配体的基准数据集，提供逐零件的真实运动轨迹，用于研究耦合运动。在此基础上，提出DYNAMO，一个依赖感知神经网络模型，能够直接从分割的CAD点云预测每个零件的SE(3)运动轨迹。

Result: 实验结果表明，DYNAMO模型在各种齿轮配置下均优于现有基线方法，实现了准确且时间一致的预测。

Conclusion: MechBench数据集和DYNAMO模型共同建立了一个新颖的系统框架，用于CAD装配体中耦合机械运动的数据驱动学习。

Abstract: Understanding the motion of articulated mechanical assemblies from static
geometry remains a core challenge in 3D perception and design automation. Prior
work on everyday articulated objects such as doors and laptops typically
assumes simplified kinematic structures or relies on joint annotations.
However, in mechanical assemblies like gears, motion arises from geometric
coupling, through meshing teeth or aligned axes, making it difficult for
existing methods to reason about relational motion from geometry alone. To
address this gap, we introduce MechBench, a benchmark dataset of 693 diverse
synthetic gear assemblies with part-wise ground-truth motion trajectories.
MechBench provides a structured setting to study coupled motion, where part
dynamics are induced by contact and transmission rather than predefined joints.
Building on this, we propose DYNAMO, a dependency-aware neural model that
predicts per-part SE(3) motion trajectories directly from segmented CAD point
clouds. Experiments show that DYNAMO outperforms strong baselines, achieving
accurate and temporally consistent predictions across varied gear
configurations. Together, MechBench and DYNAMO establish a novel systematic
framework for data-driven learning of coupled mechanical motion in CAD
assemblies.

</details>


### [61] [Cott-ADNet: Lightweight Real-Time Cotton Boll and Flower Detection Under Field Conditions](https://arxiv.org/abs/2509.12442)
*Rui-Feng Wang,Mingrui Xu,Matthew C Bauer,Iago Beffart Schardong,Xiaowen Ma,Kangning Cui*

Main category: cs.CV

TL;DR: 本文提出了Cott-ADNet，一个基于YOLOv11n的轻量级实时检测器，用于复杂田间条件下棉铃和棉花的识别。该模型通过改进的卷积设计、NeLU增强的全局注意力机制和扩张感受野SPPF模块，实现了高精度和高效率，为自动化采摘和表型分析提供了可靠基础。


<details>
  <summary>Details</summary>
Motivation: 棉花采摘仍受限于劳动密集型人工采摘、效率低下以及错过最佳采摘窗口导致的产量损失。因此，准确识别棉铃及其成熟度对于自动化、产量估算和育种研究至关重要。

Method: 本文提出了Cott-ADNet，一个基于YOLOv11n的轻量级实时检测器。它通过改进的卷积设计增强了空间表示和鲁棒性，并引入了两个新模块：NeLU增强的全局注意力机制（用于捕获弱和低对比度特征）和扩张感受野SPPF（以低计算成本扩展感受野以实现更有效的多尺度上下文建模）。此外，还整理了一个包含4,966张图像的标注数据集，并发布了一个包含1,216张田间图像的外部验证集。

Result: 实验表明，Cott-ADNet在仅7.5 GFLOPs的计算量下，达到了91.5%的精确率、89.8%的召回率、93.3%的mAP50、71.3%的mAP和90.6%的F1-分数，并在多尺度和旋转变化下保持了稳定的性能。

Conclusion: 这些结果表明Cott-ADNet是一种准确高效的田间部署解决方案，为自动化棉花采摘和高通量表型分析提供了可靠的基础。

Abstract: Cotton is one of the most important natural fiber crops worldwide, yet
harvesting remains limited by labor-intensive manual picking, low efficiency,
and yield losses from missing the optimal harvest window. Accurate recognition
of cotton bolls and their maturity is therefore essential for automation, yield
estimation, and breeding research. We propose Cott-ADNet, a lightweight
real-time detector tailored to cotton boll and flower recognition under complex
field conditions. Building on YOLOv11n, Cott-ADNet enhances spatial
representation and robustness through improved convolutional designs, while
introducing two new modules: a NeLU-enhanced Global Attention Mechanism to
better capture weak and low-contrast features, and a Dilated Receptive Field
SPPF to expand receptive fields for more effective multi-scale context modeling
at low computational cost. We curate a labeled dataset of 4,966 images, and
release an external validation set of 1,216 field images to support future
research. Experiments show that Cott-ADNet achieves 91.5% Precision, 89.8%
Recall, 93.3% mAP50, 71.3% mAP, and 90.6% F1-Score with only 7.5 GFLOPs,
maintaining stable performance under multi-scale and rotational variations.
These results demonstrate Cott-ADNet as an accurate and efficient solution for
in-field deployment, and thus provide a reliable basis for automated cotton
harvesting and high-throughput phenotypic analysis. Code and dataset is
available at https://github.com/SweefongWong/Cott-ADNet.

</details>


### [62] [Deep learning for 3D point cloud processing -- from approaches, tasks to its implications on urban and environmental applications](https://arxiv.org/abs/2509.12452)
*Zhenxin Zhang,Zhihua Xu,Yuwei Cao,Ningli Xu,Shuye Wang,Shen'ao Cui,Zhen Li,Rongjun Qin*

Main category: cs.CV

TL;DR: 本文对深度学习在点云处理中的应用进行了元综述，重点关注其在实际应用中的价值和挑战，并指出了将这些方法转化为实际应用时存在的差距。


<details>
  <summary>Details</summary>
Motivation: 现有综述主要关注不断更新的网络架构以适应无序点云，却大多忽视了其在典型点云处理应用中的实际价值，这些应用需要考虑超大数据量、多样化的场景内容、变化的密度和数据模态。

Method: 本文对深度学习方法和数据集进行了元综述，涵盖了场景补全、配准、语义分割和建模等关键点云处理任务，并通过回顾这些任务所支持的广泛城市和环境应用来识别差距。

Result: 本文识别了在将深度学习方法转化为实际应用过程中需要弥补的差距。

Conclusion: 本文对所综述方法的算法和实践方面都提出了总结性意见，旨在弥合深度学习方法从研究到实际应用之间的鸿沟。

Abstract: Point cloud processing as a fundamental task in the field of geomatics and
computer vision, has been supporting tasks and applications at different scales
from air to ground, including mapping, environmental monitoring, urban/tree
structure modeling, automated driving, robotics, disaster responses etc. Due to
the rapid development of deep learning, point cloud processing algorithms have
nowadays been almost explicitly dominated by learning-based approaches, most of
which are yet transitioned into real-world practices. Existing surveys
primarily focus on the ever-updating network architecture to accommodate
unordered point clouds, largely ignoring their practical values in typical
point cloud processing applications, in which extra-large volume of data,
diverse scene contents, varying point density, data modality need to be
considered. In this paper, we provide a meta review on deep learning approaches
and datasets that cover a selection of critical tasks of point cloud processing
in use such as scene completion, registration, semantic segmentation, and
modeling. By reviewing a broad range of urban and environmental applications
these tasks can support, we identify gaps to be closed as these methods
transformed into applications and draw concluding remarks in both the
algorithmic and practical aspects of the surveyed methods.

</details>


### [63] [Two-Stage Decoupling Framework for Variable-Length Glaucoma Prognosis](https://arxiv.org/abs/2509.12453)
*Yiran Song,Yikai Zhang,Silvia Orengo-Nania,Nian Wang,Fenglong Ma,Rui Zhang,Yifan Peng,Mingquan Lin*

Main category: cs.CV

TL;DR: 本文提出了一种两阶段解耦框架（TSDF），用于可变长度的青光眼预后。该框架通过自监督学习进行特征表示，并利用基于注意力的机制进行时间聚合，以解决现有方法在固定长度输入和有限数据集上的局限性。


<details>
  <summary>Details</summary>
Motivation: 目前的青光眼预后方法依赖于固定长度的输入，限制了灵活性；同时，端到端模型在面对有限的青光眼数据集时表现不佳。这些问题促使研究者寻求一种能处理可变长度数据并有效利用多源数据的解决方案。

Method: 本文提出一个两阶段解耦框架（TSDF）：
1. **第一阶段（特征表示模块）**：利用自监督学习聚合多个青光眼数据集进行训练，忽略监督信息的差异，以学习更好的特征表示。
2. **第二阶段（时间聚合模块）**：引入基于注意力机制来处理可变长度的序列输入，确保所有可用数据都能被灵活高效地利用。

Result: 该方法显著提升了模型性能，同时保持了紧凑的参数规模。在两个规模和临床设置差异显著的基准青光眼数据集（OHTS和GRAPE）上的广泛实验证明了其有效性和鲁棒性。

Conclusion: 所提出的两阶段解耦框架（TSDF）成功解决了青光眼预后中可变长度输入和有限数据集的挑战，显著提高了模型性能和鲁棒性，为青光眼患者的及时干预提供了更好的预测能力。

Abstract: Glaucoma is one of the leading causes of irreversible blindness worldwide.
Glaucoma prognosis is essential for identifying at-risk patients and enabling
timely intervention to prevent blindness. Many existing approaches rely on
historical sequential data but are constrained by fixed-length inputs, limiting
their flexibility. Additionally, traditional glaucoma prognosis methods often
employ end-to-end models, which struggle with the limited size of glaucoma
datasets. To address these challenges, we propose a Two-Stage Decoupling
Framework (TSDF) for variable-length glaucoma prognosis. In the first stage, we
employ a feature representation module that leverages self-supervised learning
to aggregate multiple glaucoma datasets for training, disregarding differences
in their supervisory information. This approach enables datasets of varying
sizes to learn better feature representations. In the second stage, we
introduce a temporal aggregation module that incorporates an attention-based
mechanism to process sequential inputs of varying lengths, ensuring flexible
and efficient utilization of all available data. This design significantly
enhances model performance while maintaining a compact parameter size.
Extensive experiments on two benchmark glaucoma datasets:the Ocular
Hypertension Treatment Study (OHTS) and the Glaucoma Real-world Appraisal
Progression Ensemble (GRAPE),which differ significantly in scale and clinical
settings,demonstrate the effectiveness and robustness of our approach.

</details>


### [64] [Image Tokenizer Needs Post-Training](https://arxiv.org/abs/2509.12474)
*Kai Qiu,Xiang Li,Hao Chen,Jason Kuen,Xiaohao Xu,Jiuxiang Gu,Yinyi Luo,Bhiksha Raj,Zhe Lin,Marios Savvides*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的图像生成模型分词器训练方案，包括主训练（通过潜在扰动模拟采样噪声）和后训练（优化解码器），旨在解决重建与生成分布之间的差异，从而显著提升生成质量和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型中的分词器主要关注重建任务，导致重建分布与生成分布之间存在显著差异，并且在采样过程中产生的生成错误未被充分考虑。

Method: 本文提出了一种包含主训练和后训练的分词器训练方案。主训练引入潜在扰动策略以模拟生成推理中的采样噪声（即意外生成的标记），从而增强分词器的鲁棒性，并提出了一种新的评估指标pFID。后训练则针对已训练好的生成模型优化分词器解码器，以减小生成标记与重建标记之间的分布差异。该方案具有即插即用特性，并对离散和连续分词器以及自回归和扩散基生成器进行了广泛验证。

Result: 通过本文提出的主训练，一个约400M的生成器取得了1.60 gFID的性能；进一步结合后训练，性能提升至1.36 gFID。实验还广泛验证了后训练策略对现有离散和连续分词器与不同类型生成器的有效性。提出的pFID指标成功地将分词器性能与生成质量关联起来。

Conclusion: 本文提出的分词器训练方案（包括主训练中的潜在扰动策略和后训练中的解码器优化）有效解决了图像生成模型中重建与生成分布的差异问题，显著提高了生成质量和收敛速度，并为分词器评估提供了新的有效指标。

Abstract: Recent image generative models typically capture the image distribution in a
pre-constructed latent space, relying on a frozen image tokenizer. However,
there exists a significant discrepancy between the reconstruction and
generation distribution, where current tokenizers only prioritize the
reconstruction task that happens before generative training without considering
the generation errors during sampling. In this paper, we comprehensively
analyze the reason for this discrepancy in a discrete latent space, and, from
which, we propose a novel tokenizer training scheme including both
main-training and post-training, focusing on improving latent space
construction and decoding respectively. During the main training, a latent
perturbation strategy is proposed to simulate sampling noises, \ie, the
unexpected tokens generated in generative inference. Specifically, we propose a
plug-and-play tokenizer training scheme, which significantly enhances the
robustness of tokenizer, thus boosting the generation quality and convergence
speed, and a novel tokenizer evaluation metric, \ie, pFID, which successfully
correlates the tokenizer performance to generation quality. During
post-training, we further optimize the tokenizer decoder regarding a
well-trained generative model to mitigate the distribution difference between
generated and reconstructed tokens. With a $\sim$400M generator, a discrete
tokenizer trained with our proposed main training achieves a notable 1.60 gFID
and further obtains 1.36 gFID with the additional post-training. Further
experiments are conducted to broadly validate the effectiveness of our
post-training strategy on off-the-shelf discrete and continuous tokenizers,
coupled with autoregressive and diffusion-based generators.

</details>


### [65] [Towards Foundational Models for Single-Chip Radar](https://arxiv.org/abs/2509.12482)
*Tianshu Huang,Akarsh Prabhakara,Chuhan Chen,Jay Karhade,Deva Ramanan,Matthew O'Toole,Anthony Rowe*

Main category: cs.CV

TL;DR: 本文收集了迄今为止最大的原始雷达数据集（100万样本），并训练了一个名为通用雷达Transformer（GRT）的基础模型，显著提高了单芯片毫米波雷达的3D占用和语义分割能力，超越了传统有损表示方法，并展现了良好的泛化性。


<details>
  <summary>Details</summary>
Motivation: 毫米波雷达虽然紧凑、廉价且耐用，不受环境条件影响，但其角分辨率差是主要缺点，尤其对于汽车和室内应用中常用的廉价单芯片雷达。尽管已有许多基于学习的方法来缓解此问题，但缺乏标准化的基础模型和大型数据集，导致从业者通常使用相对较小的数据集从头开始训练特定任务模型。

Method: 研究人员收集了据称是目前最大的原始雷达数据集，包含100万个样本（29小时）。在此基础上，他们训练了一个名为通用雷达Transformer（GRT）的基础模型，用于4D单芯片雷达，能够预测3D占用和语义分割。论文还对常见设计决策进行了广泛的消融实验，特别是比较了使用原始雷达数据与广泛使用的有损表示方法的效果。

Result: GRT模型在3D占用和语义分割方面达到了通常只有更高分辨率传感器才能实现的质量。它在不同设置下表现出良好的泛化能力，可以针对不同任务进行微调，并显示出每10倍数据量可带来20%性能提升的对数数据缩放效应。消融实验发现，使用原始雷达数据显著优于广泛使用的有损表示，其效果相当于增加了10倍的训练数据。研究人员还初步估计，大约需要1亿个样本（3000小时）的数据才能充分发挥GRT的潜力。

Conclusion: 本研究成功构建了迄今最大的原始雷达数据集，并开发了GRT这一基础模型，显著提升了单芯片毫米波雷达在3D占用和语义分割任务上的性能，证明了原始数据的重要性及模型在不同任务和环境下的泛化能力。同时，研究也指出，要充分挖掘GRT的潜力，未来还需要更大规模的数据集。

Abstract: mmWave radars are compact, inexpensive, and durable sensors that are robust
to occlusions and work regardless of environmental conditions, such as weather
and darkness. However, this comes at the cost of poor angular resolution,
especially for inexpensive single-chip radars, which are typically used in
automotive and indoor sensing applications. Although many have proposed
learning-based methods to mitigate this weakness, no standardized foundational
models or large datasets for the mmWave radar have emerged, and practitioners
have largely trained task-specific models from scratch using relatively small
datasets.
  In this paper, we collect (to our knowledge) the largest available raw radar
dataset with 1M samples (29 hours) and train a foundational model for 4D
single-chip radar, which can predict 3D occupancy and semantic segmentation
with quality that is typically only possible with much higher resolution
sensors. We demonstrate that our Generalizable Radar Transformer (GRT)
generalizes across diverse settings, can be fine-tuned for different tasks, and
shows logarithmic data scaling of 20\% per $10\times$ data. We also run
extensive ablations on common design decisions, and find that using raw radar
data significantly outperforms widely-used lossy representations, equivalent to
a $10\times$ increase in training data. Finally, we roughly estimate that
$\approx$100M samples (3000 hours) of data are required to fully exploit the
potential of GRT.

</details>


### [66] [Evaluating Robustness of Vision-Language Models Under Noisy Conditions](https://arxiv.org/abs/2509.12492)
*Purushoth,Alireza*

Main category: cs.CV

TL;DR: 本研究全面评估了最先进的视觉语言模型（VLMs）在光照变化、运动模糊和压缩伪影等受控噪声条件下的鲁棒性，发现真实标注的描述性、模型大小与噪声类型对性能有显著影响。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在多模态任务中取得了巨大成功，但它们在噪声条件下的鲁棒性尚不明确。

Method: 本研究提出了一个全面的评估框架，用于在受控扰动（包括光照变化、运动模糊和压缩伪影）下评估多个最先进的VLMs的性能。评估指标包括基于词汇的度量（BLEU, METEOR, ROUGE, CIDEr）和使用句子嵌入的神经语义相似性度量。实验涵盖了多样化的数据集。

Result: 主要发现包括：(1) 真实标注的描述性显著影响模型性能；(2) LLaVA等大型模型在语义理解方面表现出色，但并非普遍优于小型模型；(3) 某些噪声类型，如JPEG压缩和运动模糊，会显著降低所有模型的性能。

Conclusion: 研究结果揭示了模型大小、数据集特性和噪声弹性之间微妙的权衡，为未来鲁棒的多模态学习提供了一个标准化的基准。

Abstract: Vision-Language Models (VLMs) have attained exceptional success across
multimodal tasks such as image captioning and visual question answering.
However, their robustness under noisy conditions remains unfamiliar. In this
study, we present a comprehensive evaluation framework to evaluate the
performance of several state-of-the-art VLMs under controlled perturbations,
including lighting variation, motion blur, and compression artifacts. We used
both lexical-based metrics (BLEU, METEOR, ROUGE, CIDEr) and neural-based
similarity measures using sentence embeddings to quantify semantic alignment.
Our experiments span diverse datasets, revealing key insights: (1)
descriptiveness of ground-truth captions significantly influences model
performance; (2) larger models like LLaVA excel in semantic understanding but
do not universally outperform smaller models; and (3) certain noise types, such
as JPEG compression and motion blur, dramatically degrade performance across
models. Our findings highlight the nuanced trade-offs between model size,
dataset characteristics, and noise resilience, offering a standardized
benchmark for future robust multimodal learning.

</details>


### [67] [Instance-Guided Class Activation Mapping for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2509.12496)
*Ali Torabi,Sanjog Gaihre,MD Mahbubur Rahman,Yaqoob Majeed*

Main category: cs.CV

TL;DR: IG-CAM是一种新的弱监督语义分割（WSSS）方法，利用实例级线索和影响函数生成高质量、边界感知的定位图，在PASCAL VOC 2012数据集上实现了最先进的性能，解决了现有方法在边界精度和完整对象覆盖方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督语义分割方法在精确对象边界定位方面表现不佳，且往往只关注最具判别性的区域，未能实现完整的对象覆盖。此外，像素级标注成本高昂，限制了模型训练。

Method: 本文提出了IG-CAM方法，包含三项关键创新：1) 实例引导细化：利用真实分割掩码引导CAM生成，确保完整对象覆盖；2) 影响函数集成：捕获训练样本与模型预测之间的关系，学习更鲁棒的特征表示；3) 多尺度边界增强：采用渐进式细化策略，实现锐利、精确的对象边界。

Result: IG-CAM在PASCAL VOC 2012数据集上取得了最先进的性能，后处理前mIoU达到82.3%，应用条件随机场（CRF）细化后进一步提升至86.6%，显著优于之前的WSSS方法。该方法展示了卓越的定位精度、完整的对象覆盖和精确的边界描绘，同时保持了计算效率。

Conclusion: IG-CAM为弱监督语义分割设定了新的基准，为像素级标注不可用或成本过高的场景提供了一个实用的解决方案。其在完整对象覆盖和精确边界描绘方面的优越性得到了广泛验证。

Abstract: Weakly Supervised Semantic Segmentation (WSSS) addresses the challenge of
training segmentation models using only image-level annotations, eliminating
the need for expensive pixel-level labeling. While existing methods struggle
with precise object boundary localization and often focus only on the most
discriminative regions, we propose IG-CAM (Instance-Guided Class Activation
Mapping), a novel approach that leverages instance-level cues and influence
functions to generate high-quality, boundary-aware localization maps. Our
method introduces three key innovations: (1) Instance-Guided Refinement that
uses ground truth segmentation masks to guide CAM generation, ensuring complete
object coverage rather than just discriminative parts; (2) Influence Function
Integration that captures the relationship between training samples and model
predictions, leading to more robust feature representations; and (3)
Multi-Scale Boundary Enhancement that employs progressive refinement strategies
to achieve sharp, precise object boundaries. IG-CAM achieves state-of-the-art
performance on the PASCAL VOC 2012 dataset with an mIoU of 82.3% before
post-processing, which further improves to 86.6% after applying Conditional
Random Field (CRF) refinement, significantly outperforming previous WSSS
methods. Our approach demonstrates superior localization accuracy, with
complete object coverage and precise boundary delineation, while maintaining
computational efficiency. Extensive ablation studies validate the contribution
of each component, and qualitative comparisons across 600 diverse images
showcase the method's robustness and generalization capability. The results
establish IG-CAM as a new benchmark for weakly supervised semantic
segmentation, offering a practical solution for scenarios where pixel-level
annotations are unavailable or prohibitively expensive.

</details>


### [68] [Artist-Created Mesh Generation from Raw Observation](https://arxiv.org/abs/2509.12501)
*Yao He,Youngjoong Kwon,Wenxiao Cai,Ehsan Adeli*

Main category: cs.CV

TL;DR: 本文提出一个端到端框架，能从噪声或不完整的点云（如LiDAR或移动RGB-D相机捕获的数据）生成艺术家风格的网格模型。


<details>
  <summary>Details</summary>
Motivation: 商业图形管线中，艺术家创建的网格对于动画、纹理和渲染效率至关重要。然而，现有方法通常要求干净完整的输入，或依赖复杂的多阶段管线，限制了其在真实世界场景中的应用。

Method: 该方法是一个端到端框架，直接从精炼的输入点云生成高质量、艺术家风格的网格。核心创新是将3D点云精炼重新表述为2D修复任务，从而能够利用强大的生成模型。

Result: 在ShapeNet数据集上的初步结果表明，该框架在生成干净、完整的网格方面具有良好前景。

Conclusion: 该框架有望从真实世界的噪声数据中生成高质量、艺术家风格的网格模型，解决了现有方法在处理不完整或噪声输入时的局限性。

Abstract: We present an end-to-end framework for generating artist-style meshes from
noisy or incomplete point clouds, such as those captured by real-world sensors
like LiDAR or mobile RGB-D cameras. Artist-created meshes are crucial for
commercial graphics pipelines due to their compatibility with animation and
texturing tools and their efficiency in rendering. However, existing approaches
often assume clean, complete inputs or rely on complex multi-stage pipelines,
limiting their applicability in real-world scenarios. To address this, we
propose an end-to-end method that refines the input point cloud and directly
produces high-quality, artist-style meshes. At the core of our approach is a
novel reformulation of 3D point cloud refinement as a 2D inpainting task,
enabling the use of powerful generative models. Preliminary results on the
ShapeNet dataset demonstrate the promise of our framework in producing clean,
complete meshes.

</details>


### [69] [Axis-Aligned 3D Stalk Diameter Estimation from RGB-D Imagery](https://arxiv.org/abs/2509.12511)
*Benjamin Vail,Rahul Harsha Cheppally,Ajay Sharda,Sidharth Rai*

Main category: cs.CV

TL;DR: 该论文提出了一种基于RGB-D图像的几何感知计算机视觉方法，用于高通量、准确地估算作物茎秆直径，以克服传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 准确、高通量表型分析是现代作物育种的关键，尤其对于机械稳定性、生物量生产和抗病性等性状。茎秆直径是一个重要的结构性状，但传统测量方法劳动密集、易出错且不适用于可扩展的表型分析。

Method: 该方法整合了深度学习的实例分割、3D点云重建和通过主成分分析（PCA）进行的轴对齐切片，以实现鲁棒的直径估算。该管道利用RGB-D图像进行几何感知计算机视觉处理。

Result: 该方法能够缓解曲率、遮挡和图像噪声的影响，从而实现鲁棒的直径估算。它提供了一种可扩展且可靠的解决方案。

Conclusion: 这种基于计算机视觉的方法为育种和农学研究中的高通量表型分析提供了支持，解决了传统茎秆直径测量方法的痛点。

Abstract: Accurate, high-throughput phenotyping is a critical component of modern crop
breeding programs, especially for improving traits such as mechanical
stability, biomass production, and disease resistance. Stalk diameter is a key
structural trait, but traditional measurement methods are labor-intensive,
error-prone, and unsuitable for scalable phenotyping. In this paper, we present
a geometry-aware computer vision pipeline for estimating stalk diameter from
RGB-D imagery. Our method integrates deep learning-based instance segmentation,
3D point cloud reconstruction, and axis-aligned slicing via Principal Component
Analysis (PCA) to perform robust diameter estimation. By mitigating the effects
of curvature, occlusion, and image noise, this approach offers a scalable and
reliable solution to support high-throughput phenotyping in breeding and
agronomic research.

</details>


### [70] [Neural Collapse-Inspired Multi-Label Federated Learning under Label-Distribution Skew](https://arxiv.org/abs/2509.12544)
*Can Peng,Yuyuan Liu,Yingyu Yang,Pramit Saha,Qianye Yang,J. Alison Noble*

Main category: cs.CV

TL;DR: 本文提出了一种联邦学习（FL）方法，旨在解决多标签数据场景下由于数据异构性和复杂标签关系导致的性能下降问题。该方法结合了神经坍缩（Neural Collapse）理论和特征解耦模块，以对齐客户端特征分布并学习高质量、聚类良好的表示。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在去中心化和异构数据下性能下降，在多标签场景中，由于标签共现、标签间依赖以及局部与全局标签关系差异等复杂特性，这一挑战被进一步放大。现有FL研究主要关注单标签分类，但许多实际应用（如医学影像）涉及多标签设置，这是一个重要但未被充分探索的领域。

Method: 本文提出了一种基于神经坍缩（NC）理论的方法，用于对齐客户端间的特征分布并学习高质量的聚类表示。为适应多标签设置，引入了一个特征解耦模块来提取语义特定的特征。这些解耦后的类别特征的聚类由预定义的共享NC结构引导，以缓解客户端模型间的冲突。此外，还设计了正则化损失以促进潜在特征空间中的紧凑聚类。

Result: 在四个基准数据集和八种不同设置下的实验表明，本文提出的方法优于现有方法，验证了其在这一具有挑战性的FL场景中的有效性。

Conclusion: 本文提出的方法有效解决了联邦学习中多标签数据分布倾斜的挑战性问题。通过结合神经坍缩理论和特征解耦，该方法能够对齐特征分布并学习高质量的表示，并在实验中展现出优越的性能。

Abstract: Federated Learning (FL) enables collaborative model training across
distributed clients while preserving data privacy. However, the performance of
deep learning often deteriorates in FL due to decentralized and heterogeneous
data. This challenge is further amplified in multi-label scenarios, where data
exhibit complex characteristics such as label co-occurrence, inter-label
dependency, and discrepancies between local and global label relationships.
While most existing FL research primarily focuses on single-label
classification, many real-world applications, particularly in domains such as
medical imaging, often involve multi-label settings. In this paper, we address
this important yet underexplored scenario in FL, where clients hold multi-label
data with skewed label distributions. Neural Collapse (NC) describes a
geometric structure in the latent feature space where features of each class
collapse to their class mean with vanishing intra-class variance, and the class
means form a maximally separated configuration. Motivated by this theory, we
propose a method to align feature distributions across clients and to learn
high-quality, well-clustered representations. To make the NC-structure
applicable to multi-label settings, where image-level features may contain
multiple semantic concepts, we introduce a feature disentanglement module that
extracts semantically specific features. The clustering of these disentangled
class-wise features is guided by a predefined shared NC structure, which
mitigates potential conflicts between client models due to diverse local data
distributions. In addition, we design regularisation losses to encourage
compact clustering in the latent feature space. Experiments conducted on four
benchmark datasets across eight diverse settings demonstrate that our approach
outperforms existing methods, validating its effectiveness in this challenging
FL scenario.

</details>


### [71] [Agent4FaceForgery: Multi-Agent LLM Framework for Realistic Face Forgery Detection](https://arxiv.org/abs/2509.12546)
*Yingxin Lai,Zitong Yu,Jun Wang,Linlin Shen,Yong Xu,Xiaochun Cao*

Main category: cs.CV

TL;DR: 为解决人脸伪造检测中基准与实际应用之间的差距，本文提出Agent4FaceForgery多智能体框架，通过模拟人类伪造创建过程和社交互动，生成高质量、生态有效的训练数据，显著提升了检测器的性能。


<details>
  <summary>Details</summary>
Motivation: 人脸伪造检测面临的挑战是离线基准与实际应用效果之间存在持续差距，这归因于训练数据的生态无效性。具体而言，需要解决如何捕捉人类伪造的多样意图和迭代过程，以及如何建模社交媒体中伪造伴随的复杂、对抗性文本-图像互动。

Method: 本文提出了Agent4FaceForgery框架，采用由大型语言模型（LLM）驱动的多智能体，这些智能体配备了档案和记忆模块，模拟伪造创建过程。智能体在一个模拟社交环境中互动，生成带有细致文本-图像一致性标签的样本（超越简单的二分类）。此外，采用自适应拒绝采样（ARS）机制确保数据质量和多样性。

Result: 通过广泛实验验证，该模拟驱动方法生成的数据显著提升了多种架构检测器的性能，充分证明了该框架的有效性和价值。

Conclusion: Agent4FaceForgery框架通过模拟伪造过程和社交互动，生成了具有生态有效性的训练数据，有效解决了人脸伪造检测在基准与实际应用之间的差距，显著提升了检测性能，具有重要的实际应用价值。

Abstract: Face forgery detection faces a critical challenge: a persistent gap between
offline benchmarks and real-world efficacy,which we attribute to the ecological
invalidity of training data.This work introduces Agent4FaceForgery to address
two fundamental problems: (1) how to capture the diverse intents and iterative
processes of human forgery creation, and (2) how to model the complex, often
adversarial, text-image interactions that accompany forgeries in social media.
To solve this,we propose a multi-agent framework where LLM-poweredagents,
equipped with profile and memory modules, simulate the forgery creation
process. Crucially, these agents interact in a simulated social environment to
generate samples labeled for nuanced text-image consistency, moving beyond
simple binary classification. An Adaptive Rejection Sampling (ARS) mechanism
ensures data quality and diversity. Extensive experiments validate that the
data generated by our simulationdriven approach brings significant performance
gains to detectors of multiple architectures, fully demonstrating the
effectiveness and value of our framework.

</details>


### [72] [Explicit Multimodal Graph Modeling for Human-Object Interaction Detection](https://arxiv.org/abs/2509.12554)
*Wenxuan Ji,Haichao Shi,Xiao-Yu zhang*

Main category: cs.CV

TL;DR: 针对Transformer在HOI检测中缺乏显式关系建模的问题，本文提出了多模态图网络建模（MGNM），通过GNN-based的多阶段图结构和多级特征交互机制，显著提升了HOI检测性能，并在HICO-DET和V-COCO数据集上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: Transformer在人体-物体交互（HOI）检测中表现出色，但其架构并未显式建模HOI固有的关系结构，这阻碍了交互识别。相比之下，图神经网络（GNNs）天生更适合这项任务，因为它们能够显式建模人-物体对之间的关系。

Method: 本文提出了多模态图网络建模（MGNM）。该方法利用基于GNN的关系结构来增强HOI检测。具体来说，设计了一个多模态图网络框架，以四阶段图结构显式建模HOI任务。此外，在图网络中引入了多级特征交互机制，利用多级视觉和语言特征来增强人-物体对之间的信息传播。

Result: 所提出的MGNM在HICO-DET和V-COCO这两个广泛使用的基准测试上均取得了最先进的性能。此外，当与更先进的物体检测器集成时，该方法显示出显著的性能提升，并能在稀有和非稀有类别之间保持有效的平衡。

Conclusion: MGNM通过显式建模HOI任务中的关系结构，并结合多模态多级特征交互，克服了Transformer在该任务中的局限性，实现了卓越的HOI检测性能，并有效处理了类别不平衡问题。

Abstract: Transformer-based methods have recently become the prevailing approach for
Human-Object Interaction (HOI) detection. However, the Transformer architecture
does not explicitly model the relational structures inherent in HOI detection,
which impedes the recognition of interactions. In contrast, Graph Neural
Networks (GNNs) are inherently better suited for this task, as they explicitly
model the relationships between human-object pairs. Therefore, in this paper,
we propose \textbf{M}ultimodal \textbf{G}raph \textbf{N}etwork
\textbf{M}odeling (MGNM) that leverages GNN-based relational structures to
enhance HOI detection. Specifically, we design a multimodal graph network
framework that explicitly models the HOI task in a four-stage graph structure.
Furthermore, we introduce a multi-level feature interaction mechanism within
our graph network. This mechanism leverages multi-level vision and language
features to enhance information propagation across human-object pairs.
Consequently, our proposed MGNM achieves state-of-the-art performance on two
widely used benchmarks: HICO-DET and V-COCO. Moreover, when integrated with a
more advanced object detector, our method demonstrates a significant
performance gain and maintains an effective balance between rare and non-rare
classes.

</details>


### [73] [VQT-Light:Lightweight HDR Illumination Map Prediction with Richer Texture.pdf](https://arxiv.org/abs/2509.12556)
*Kunliang Xie*

Main category: cs.CV

TL;DR: 本文提出了一种名为VQT-Light的新型框架，结合VQVAE和ViT架构，旨在解决现有光照估计方法在纹理细节、运行速度和保真度方面的挑战，实现了更丰富纹理、更高保真度、更轻量且快速的光照图预测。


<details>
  <summary>Details</summary>
Motivation: 现有的光照估计方法在恢复光照图的详细纹理方面表现不佳，或者在运行速度和纹理保真度之间面临权衡挑战。

Method: VQT-Light框架包含特征提取和光照估计两个模块。首先，利用VQVAE提取光照图的离散特征而非连续特征，以避免“后验坍塌”。其次，通过ViT而非CNN捕捉输入图像的全局上下文和依赖关系，以改善视野外光照的预测。最终，将光照估计公式化为多类别分类任务。

Result: 该模型能够预测具有更丰富纹理和更好保真度的光照图，同时保持轻量和快速（推理速度达到40FPS）。VQT-Light改进了多项评估指标，并通过定性和定量实验证明其优于现有最先进的方法。

Conclusion: VQT-Light通过结合VQVAE和ViT的优势，有效地解决了光照估计中纹理细节、速度和保真度的问题，实现了卓越的性能，提供了更优质、更快速的光照估计结果。

Abstract: Accurate lighting estimation is a significant yet challenging task in
computer vision and graphics. However, existing methods either struggle to
restore detailed textures of illumination map, or face challenges in running
speed and texture fidelity. To tackle this problem, we propose a novel
framework (VQT-Light) based on VQVAE and ViT architecture. VQT-Light includes
two modules: feature extraction and lighting estimation. First, we take
advantages of VQVAE to extract discrete features of illumination map rather
than continuous features to avoid "posterior collapse". Second, we capture
global context and dependencies of input image through ViT rather than CNNs to
improve the prediction of illumination outside the field of view. Combining the
above two modules, we formulate the lighting estimation as a multiclass
classification task, which plays a key role in our pipeline. As a result, our
model predicts light map with richer texture and better fidelity while keeping
lightweight and fast. VQT-Light achieves an inference speed of 40FPS and
improves multiple evaluation metrics. Qualitative and quantitative experiments
demonstrate that the proposed method realizes superior results compared to
existing state-of-the-art methods.

</details>


### [74] [Adaptive Sampling Scheduler](https://arxiv.org/abs/2509.12569)
*Qi Wang,Shuliang Zhu,Jinjia Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种自适应采样调度器，通过动态时间步选择、优化的交替采样和图像处理技术，显著提升了各种一致性蒸馏扩散模型的灵活性和生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有的一致性蒸馏方法在目标时间步选择上依赖确定性或随机策略，导致采样调度器需要针对不同蒸馏过程进行专门设计，限制了灵活性和扩散模型在实际应用中的采样潜力。

Method: 本文引入了一个自适应采样调度器，包含三项创新策略：(i) 基于计算出的重要性动态选择目标时间步，以适应不同的一致性蒸馏框架；(ii) 沿着解轨迹优化交替采样，通过时间步重要性指导前向去噪和后向加噪，更有效地探索解空间；(iii) 利用平滑裁剪和色彩平衡技术，在高引导尺度下实现稳定且高质量的生成结果。

Result: 通过全面的实验评估，该自适应采样调度器在各种一致性蒸馏方法中展现出有效性和灵活性。实验结果一致表明，生成性能显著提升，突显了该方法强大的适应性。

Conclusion: 所提出的自适应采样调度器克服了现有蒸馏方法的局限性，通过创新的时间步选择和采样策略，显著提高了扩散模型在复杂生成场景中的灵活性、稳定性和生成质量。

Abstract: Consistent distillation methods have evolved into effective techniques that
significantly accelerate the sampling process of diffusion models. Although
existing methods have achieved remarkable results, the selection of target
timesteps during distillation mainly relies on deterministic or stochastic
strategies, which often require sampling schedulers to be designed specifically
for different distillation processes. Moreover, this pattern severely limits
flexibility, thereby restricting the full sampling potential of diffusion
models in practical applications. To overcome these limitations, this paper
proposes an adaptive sampling scheduler that is applicable to various
consistency distillation frameworks. The scheduler introduces three innovative
strategies: (i) dynamic target timestep selection, which adapts to different
consistency distillation frameworks by selecting timesteps based on their
computed importance; (ii) Optimized alternating sampling along the solution
trajectory by guiding forward denoising and backward noise addition based on
the proposed time step importance, enabling more effective exploration of the
solution space to enhance generation performance; and (iii) Utilization of
smoothing clipping and color balancing techniques to achieve stable and
high-quality generation results at high guidance scales, thereby expanding the
applicability of consistency distillation models in complex generation
scenarios. We validated the effectiveness and flexibility of the adaptive
sampling scheduler across various consistency distillation methods through
comprehensive experimental evaluations. Experimental results consistently
demonstrated significant improvements in generative performance, highlighting
the strong adaptability achieved by our method.

</details>


### [75] [DisorientLiDAR: Physical Attacks on LiDAR-based Localization](https://arxiv.org/abs/2509.12595)
*Yizhen Lao,Yu Zhang,Ziting Wang,Chengbo Wang,Yifei Xue,Wanpeng Shao*

Main category: cs.CV

TL;DR: 本文提出了一种名为 DisorientLiDAR 的新型对抗性攻击框架，通过移除关键点来扰乱基于 LiDAR 的自动驾驶定位系统，并在数字和物理世界中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型易受对抗性攻击，但针对自动驾驶汽车 LiDAR 定位的攻击研究非常少，大多数攻击集中在 3D 感知。LiDAR 定位对自动驾驶至关重要，因此探索其安全漏洞具有现实意义。

Method: 研究人员通过逆向工程定位模型（如特征提取网络）来识别关键关键点，并策略性地移除这些关键点，从而破坏基于 LiDAR 的定位。该框架首先在点云配准模型上进行评估，然后扩展到 Autoware 自动驾驶平台。最后，通过使用近红外吸收材料隐藏关键区域，在物理世界中复制了攻击效果。

Result: 实验结果表明，移除 Top-K 关键点区域会显著降低 HRegNet、D3Feat 和 GeoTransformer 等最先进点云配准模型的配准精度。在 Autoware 平台上，隐藏少量关键区域会导致明显的定位漂移。此外，通过物理世界攻击成功复现了在 KITTI 数据上观察到的攻击效果。

Conclusion: DisorientLiDAR 框架能够有效且普遍地攻击基于 LiDAR 的定位系统，通过移除关键区域即可导致定位精度显著下降和漂移。该研究证实了此类攻击在物理世界中的可行性，对自动驾驶的安全性提出了新的挑战。

Abstract: Deep learning models have been shown to be susceptible to adversarial attacks
with visually imperceptible perturbations. Even this poses a serious security
challenge for the localization of self-driving cars, there has been very little
exploration of attack on it, as most of adversarial attacks have been applied
to 3D perception. In this work, we propose a novel adversarial attack framework
called DisorientLiDAR targeting LiDAR-based localization. By
reverse-engineering localization models (e.g., feature extraction networks),
adversaries can identify critical keypoints and strategically remove them,
thereby disrupting LiDAR-based localization. Our proposal is first evaluated on
three state-of-the-art point-cloud registration models (HRegNet, D3Feat, and
GeoTransformer) using the KITTI dataset. Experimental results demonstrate that
removing regions containing Top-K keypoints significantly degrades their
registration accuracy. We further validate the attack's impact on the Autoware
autonomous driving platform, where hiding merely a few critical regions induces
noticeable localization drift. Finally, we extended our attacks to the physical
world by hiding critical regions with near-infrared absorptive materials,
thereby successfully replicate the attack effects observed in KITTI data. This
step has been closer toward the realistic physical-world attack that
demonstrate the veracity and generality of our proposal.

</details>


### [76] [Exploring Spectral Characteristics for Single Image Reflection Removal](https://arxiv.org/abs/2509.12627)
*Pengbo Guo,Chengxu Liu,Guoshuai Zhao,Xingsong Hou,Jialie Shen,Xueming Qian*

Main category: cs.CV

TL;DR: 本文提出了一种基于光谱学习的新方法，通过构建光谱码本重建反射图像的光谱，并结合光谱先验细化模块和光谱感知Transformer，有效去除图像反射。


<details>
  <summary>Details</summary>
Motivation: 图像反射消除是一个难题，因为反射和透射分量在捕获图像中重叠，难以区分和恢复干净背景。现有方法通常只在图像域处理，忽略反射光的频谱特性变化，导致无法有效识别反射。

Method: 该方法从光谱学习的新视角出发，提出光谱码本（Spectral Codebook）来重建反射图像的光学光谱，通过感知不同光源在光谱中的波长差异来区分反射。此外，设计了两个光谱先验细化模块，用于在空间维度重新分配像素并在波长维度自适应增强光谱差异。最后，引入光谱感知Transformer（Spectrum-Aware Transformer）来联合恢复光谱域和像素域的透射内容。

Result: 在三个不同的反射基准测试上，实验结果表明所提出的方法比现有最先进模型具有优越性和泛化能力。

Conclusion: 通过利用光谱特性并结合光谱学习与Transformer架构，该方法能有效区分和去除图像反射，提供了一种性能卓越的解决方案。

Abstract: Eliminating reflections caused by incident light interacting with reflective
medium remains an ill-posed problem in the image restoration area. The primary
challenge arises from the overlapping of reflection and transmission components
in the captured images, which complicates the task of accurately distinguishing
and recovering the clean background. Existing approaches typically address
reflection removal solely in the image domain, ignoring the spectral property
variations of reflected light, which hinders their ability to effectively
discern reflections. In this paper, we start with a new perspective on spectral
learning, and propose the Spectral Codebook to reconstruct the optical spectrum
of the reflection image. The reflections can be effectively distinguished by
perceiving the wavelength differences between different light sources in the
spectrum. To leverage the reconstructed spectrum, we design two spectral prior
refinement modules to re-distribute pixels in the spatial dimension and
adaptively enhance the spectral differences along the wavelength dimension.
Furthermore, we present the Spectrum-Aware Transformer to jointly recover the
transmitted content in spectral and pixel domains. Experimental results on
three different reflection benchmarks demonstrate the superiority and
generalization ability of our method compared to state-of-the-art models.

</details>


### [77] [Maps for Autonomous Driving: Full-process Survey and Frontiers](https://arxiv.org/abs/2509.12632)
*Pengxin Chen,Zhipeng Luo,Xiaoqi Jiang,Zhangcai Yin,Jonathan Li*

Main category: cs.CV

TL;DR: 本文回顾了自动驾驶地图的演变，将其分为高清（HD）地图、轻量级（Lite）地图和隐式地图三个阶段，并分析了各阶段的生产流程、技术挑战、解决方案以及前沿研究，探讨了其与端到端自动驾驶框架的整合。


<details>
  <summary>Details</summary>
Motivation: 地图一直是自动驾驶的核心组成部分，随着技术进步，地图的表示和生产过程发生了显著演变。本研究旨在对这种演变进行分类和全面回顾。

Method: 文章将地图演变分为三个阶段：高清（HD）地图、轻量级（Lite）地图和隐式地图。针对每个阶段，文章全面回顾了地图生产流程，强调了技术挑战，并总结了学术界提出的相关解决方案。此外，还讨论了地图表示的前沿研究进展，并探讨了如何将这些创新整合到端到端自动驾驶框架中。

Result: 本文提供了自动驾驶地图从高清地图到隐式地图的演变综述，详细阐述了每个阶段的地图生产工作流程、面临的技术挑战及学术解决方案。同时，探讨了地图表示的前沿研究进展，并讨论了这些创新如何融入端到端自动驾驶系统。

Conclusion: 自动驾驶地图的表示和生产已从高清地图发展到轻量级地图和隐式地图。未来的研究将聚焦于解决当前的技术挑战，并探索如何将先进的地图表示与端到端自动驾驶框架更有效地整合。

Abstract: Maps have always been an essential component of autonomous driving. With the
advancement of autonomous driving technology, both the representation and
production process of maps have evolved substantially. The article categorizes
the evolution of maps into three stages: High-Definition (HD) maps, Lightweight
(Lite) maps, and Implicit maps. For each stage, we provide a comprehensive
review of the map production workflow, with highlighting technical challenges
involved and summarizing relevant solutions proposed by the academic community.
Furthermore, we discuss cutting-edge research advances in map representations
and explore how these innovations can be integrated into end-to-end autonomous
driving frameworks.

</details>


### [78] [CIARD: Cyclic Iterative Adversarial Robustness Distillation](https://arxiv.org/abs/2509.12633)
*Liming Lu,Shuchao Pang,Xu Zheng,Xiang Gu,Anan Du,Yunhuai Liu,Yongbin Zhou*

Main category: cs.CV

TL;DR: 现有对抗鲁棒性蒸馏(ARD)方法在提升鲁棒性的同时会降低干净样本性能。本文提出CIARD方法，通过多教师框架和持续对抗重训练，有效平衡了模型的鲁棒性和泛化能力，并取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有ARD方法在提高学生模型鲁棒性的同时，会导致在干净样本上的性能下降。作者将此问题归因于双教师框架中优化目标的分歧以及训练过程中迭代生成对抗样本导致的鲁棒教师性能下降。

Method: 本文提出了一种名为循环迭代ARD (CIARD) 的新方法。其核心创新包括：1. 采用多教师框架与对比推拉损失对齐，以解决双教师优化目标冲突；2. 引入持续对抗重训练机制，以动态维护教师模型的鲁棒性，防止性能下降。

Result: 在CIFAR-10、CIFAR-100和Tiny-ImageNet上的广泛实验表明，CIARD方法在各种攻击场景下平均提高了3.53%的对抗防御率，并使干净样本准确率提升了5.87%。

Conclusion: CIARD方法在平衡模型鲁棒性和泛化能力方面建立了新的基准，实现了卓越的性能，有效解决了现有ARD方法的弊端。

Abstract: Adversarial robustness distillation (ARD) aims to transfer both performance
and robustness from teacher model to lightweight student model, enabling
resilient performance on resource-constrained scenarios. Though existing ARD
approaches enhance student model's robustness, the inevitable by-product leads
to the degraded performance on clean examples. We summarize the causes of this
problem inherent in existing methods with dual-teacher framework as: 1. The
divergent optimization objectives of dual-teacher models, i.e., the clean and
robust teachers, impede effective knowledge transfer to the student model, and
2. The iteratively generated adversarial examples during training lead to
performance deterioration of the robust teacher model. To address these
challenges, we propose a novel Cyclic Iterative ARD (CIARD) method with two key
innovations: a. A multi-teacher framework with contrastive push-loss alignment
to resolve conflicts in dual-teacher optimization objectives, and b. Continuous
adversarial retraining to maintain dynamic teacher robustness against
performance degradation from the varying adversarial examples. Extensive
experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet demonstrate that CIARD
achieves remarkable performance with an average 3.53 improvement in adversarial
defense rates across various attack scenarios and a 5.87 increase in clean
sample accuracy, establishing a new benchmark for balancing model robustness
and generalization. Our code is available at https://github.com/eminentgu/CIARD

</details>


### [79] [Beyond Artificial Misalignment: Detecting and Grounding Semantic-Coordinated Multimodal Manipulations](https://arxiv.org/abs/2509.12653)
*Jinjie Shen,Yaxiong Wang,Lechao Cheng,Nan Pu,Zhun Zhong*

Main category: cs.CV

TL;DR: 该论文提出了首个语义对齐多模态篡改（SAMM）数据集，用于检测视觉编辑与语义一致文本描述相结合的篡改内容，并提出了一个检索增强的篡改检测与定位（RamDG）框架，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基准数据集存在不对齐伪影，无法真实反映现实世界中保持模态间语义一致性的篡改模式，导致检测到的是容易发现的异常而非实际攻击。研究旨在弥补这一差距，检测语义协调的篡改。

Method: 1. 构建SAMM数据集：采用两阶段管道生成，首先应用最先进的图像篡改技术，然后生成上下文合理且强化视觉欺骗的文本叙述。2. 提出RamDG框架：利用外部知识库检索上下文证据作为辅助文本，并与输入一起通过图像伪造定位和深度篡改检测模块进行编码，以追踪所有篡改。

Result: 实验证明，所提出的框架显著优于现有方法，在SAMM数据集上的检测准确率比最先进的方法高出2.06%。

Conclusion: 该研究通过引入SAMM数据集和RamDG框架，开创了语义协调多模态篡改检测的新方向，有效解决了现有基准与现实世界篡改模式不符的问题，为媒体取证领域提供了更真实、更有效的检测工具。

Abstract: The detection and grounding of manipulated content in multimodal data has
emerged as a critical challenge in media forensics. While existing benchmarks
demonstrate technical progress, they suffer from misalignment artifacts that
poorly reflect real-world manipulation patterns: practical attacks typically
maintain semantic consistency across modalities, whereas current datasets
artificially disrupt cross-modal alignment, creating easily detectable
anomalies. To bridge this gap, we pioneer the detection of
semantically-coordinated manipulations where visual edits are systematically
paired with semantically consistent textual descriptions. Our approach begins
with constructing the first Semantic-Aligned Multimodal Manipulation (SAMM)
dataset, generated through a two-stage pipeline: 1) applying state-of-the-art
image manipulations, followed by 2) generation of contextually-plausible
textual narratives that reinforce the visual deception. Building on this
foundation, we propose a Retrieval-Augmented Manipulation Detection and
Grounding (RamDG) framework. RamDG commences by harnessing external knowledge
repositories to retrieve contextual evidence, which serves as the auxiliary
texts and encoded together with the inputs through our image forgery grounding
and deep manipulation detection modules to trace all manipulations. Extensive
experiments demonstrate our framework significantly outperforms existing
methods, achieving 2.06\% higher detection accuracy on SAMM compared to
state-of-the-art approaches. The dataset and code are publicly available at
https://github.com/shen8424/SAMM-RamDG-CAP.

</details>


### [80] [MFAF: An EVA02-Based Multi-scale Frequency Attention Fusion Method for Cross-View Geo-Localization](https://arxiv.org/abs/2509.12673)
*YiTong Liu,TianZhu Liu,YanFeng GU*

Main category: cs.CV

TL;DR: 本文提出了一种基于EVA02的多尺度频率注意力融合（MFAF）方法，通过多频率分支块（MFB）和频率感知空间注意力（FSA）模块，有效处理跨视角地理定位中的外观变化和特征提取难题，并在无人机定位和导航任务中取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 跨视角地理定位任务面临着物体在不同视角下外观差异显著以及难以提取判别性特征的挑战。现有方法常依赖特征图分割来提取特征，但却忽略了空间和语义信息。

Method: 本文提出了EVA02-based的多尺度频率注意力融合（MFAF）方法。该方法包含：1. 多频率分支块（MFB），用于在多尺度上有效捕获低频结构特征和高频边缘细节，增强特征表示的跨视角一致性和鲁棒性。2. 频率感知空间注意力（FSA）模块，用于自适应地关注频率特征的关键区域，显著减轻背景噪声和视角变化带来的干扰。

Result: 在University-1652、SUES-200和Dense-UAV等广泛认可的基准测试中，MFAF方法在无人机定位和无人机导航任务中均取得了有竞争力的性能。

Conclusion: MFAF方法通过其独特的MFB和FSA模块，有效解决了跨视角地理定位中特征表示和注意力分配的挑战，从而在相关任务中展现出卓越的性能。

Abstract: Cross-view geo-localization aims to determine the geographical location of a
query image by matching it against a gallery of images. This task is
challenging due to the significant appearance variations of objects observed
from variable views, along with the difficulty in extracting discriminative
features. Existing approaches often rely on extracting features through feature
map segmentation while neglecting spatial and semantic information. To address
these issues, we propose the EVA02-based Multi-scale Frequency Attention Fusion
(MFAF) method. The MFAF method consists of Multi-Frequency Branch-wise Block
(MFB) and the Frequency-aware Spatial Attention (FSA) module. The MFB block
effectively captures both low-frequency structural features and high-frequency
edge details across multiple scales, improving the consistency and robustness
of feature representations across various viewpoints. Meanwhile, the FSA module
adaptively focuses on the key regions of frequency features, significantly
mitigating the interference caused by background noise and viewpoint
variability. Extensive experiments on widely recognized benchmarks, including
University-1652, SUES-200, and Dense-UAV, demonstrate that the MFAF method
achieves competitive performance in both drone localization and drone
navigation tasks.

</details>


### [81] [A Comparative Study of YOLOv8 to YOLOv11 Performance in Underwater Vision Tasks](https://arxiv.org/abs/2509.12682)
*Gordon Hung,Ivan Felipe Rodriguez*

Main category: cs.CV

TL;DR: 本文对YOLOv8-s、YOLOv9-s、YOLOv10-s和YOLOv11-s在水下图像数据集上进行了首次受控比较，发现YOLOv10在AUV部署中提供了最佳的速度-精度权衡。


<details>
  <summary>Details</summary>
Motivation: 自主水下航行器（AUV）依赖车载计算机视觉系统执行任务，但水下图像质量受限且AUV计算资源有限。YOLO系列检测器因其低延迟而有吸引力，但其在陆地数据集上的表现无法直接推断在海洋领域的性能。

Method: 研究者整理了两个水下数据集（珊瑚病害和鱼类物种），并为每个数据集创建了四种训练方案（25%、50%、75%、100%图像）。他们使用相同的超参数训练了YOLOv8-s、YOLOv9-s、YOLOv10-s和YOLOv11-s模型，并评估了精度、召回率、mAP50、mAP50-95、每图像推理时间和帧率（FPS）。通过Grad-CAM可视化探测特征利用和定位忠实度。

Result: 研究发现，在YOLOv9之后，模型的准确性趋于饱和，表明架构创新主要针对效率而非准确性。然而，推理速度显著提高。YOLOv10-s在两个数据集上都提供了AUV嵌入式部署的最佳速度-精度权衡。

Conclusion: 本文首次对最新YOLO变体在水下图像上的性能进行了受控比较，指出轻量级YOLOv10为AUV部署提供了最佳的速度-精度平衡，并提供了一个开放、可复现的基准和代码库，以加速未来的海洋视觉研究。

Abstract: Autonomous underwater vehicles (AUVs) increasingly rely on on-board
computer-vision systems for tasks such as habitat mapping, ecological
monitoring, and infrastructure inspection. However, underwater imagery is
hindered by light attenuation, turbidity, and severe class imbalance, while the
computational resources available on AUVs are limited. One-stage detectors from
the YOLO family are attractive because they fuse localization and
classification in a single, low-latency network; however, their terrestrial
benchmarks (COCO, PASCAL-VOC, Open Images) leave open the question of how
successive YOLO releases perform in the marine domain. We curate two openly
available datasets that span contrasting operating conditions: a Coral Disease
set (4,480 images, 18 classes) and a Fish Species set (7,500 images, 20
classes). For each dataset, we create four training regimes (25 %, 50 %, 75 %,
100 % of the images) while keeping balanced validation and test partitions
fixed. We train YOLOv8-s, YOLOv9-s, YOLOv10-s, and YOLOv11-s with identical
hyperparameters (100 epochs, 640 px input, batch = 16, T4 GPU) and evaluate
precision, recall, mAP50, mAP50-95, per-image inference time, and
frames-per-second (FPS). Post-hoc Grad-CAM visualizations probe feature
utilization and localization faithfulness. Across both datasets, accuracy
saturates after YOLOv9, suggesting architectural innovations primarily target
efficiency rather than accuracy. Inference speed, however, improves markedly.
Our results (i) provide the first controlled comparison of recent YOLO variants
on underwater imagery, (ii) show that lightweight YOLOv10 offers the best
speed-accuracy trade-off for embedded AUV deployment, and (iii) deliver an
open, reproducible benchmark and codebase to accelerate future marine-vision
research.

</details>


### [82] [StereoCarla: A High-Fidelity Driving Dataset for Generalizable Stereo](https://arxiv.org/abs/2509.12683)
*Xianda Guo,Chenming Zhang,Ruilin Wang,Youmin Zhang,Wenzhao Zheng,Matteo Poggi,Hao Zhao,Qin Zou,Long Chen*

Main category: cs.CV

TL;DR: 本文提出了StereoCarla，一个为自动驾驶场景设计的高保真合成立体数据集，旨在解决现有训练数据多样性不足导致立体匹配模型泛化性能受限的问题。实验表明，使用StereoCarla训练的模型在跨域泛化准确性方面优于现有数据集，并能显著提升多数据集训练效果。


<details>
  <summary>Details</summary>
Motivation: 立体匹配算法的泛化性能受限于现有训练数据的多样性不足，尤其是在学习型方法和合成数据集驱动下取得显著进展后，这一问题变得更为突出。

Method: 研究人员基于CARLA模拟器创建了StereoCarla数据集，其中包含了广泛的相机配置（如不同的基线、视角和传感器放置）以及多样的环境条件（如光照变化、天气效应和道路几何形状）。他们还在四个标准评估数据集上进行了全面的跨域实验。

Result: 在KITTI2012、KITTI2015、Middlebury和ETH3D等基准测试中，使用StereoCarla训练的模型在泛化准确性方面超越了11个现有立体数据集。此外，将StereoCarla整合到多数据集训练中，显著提高了泛化准确性，表明其良好的兼容性和可扩展性。

Conclusion: StereoCarla数据集为在真实、多样化和可控设置下开发和评估立体算法提供了一个有价值的基准，有助于为自动驾驶车辆构建更鲁棒的深度感知系统。

Abstract: Stereo matching plays a crucial role in enabling depth perception for
autonomous driving and robotics. While recent years have witnessed remarkable
progress in stereo matching algorithms, largely driven by learning-based
methods and synthetic datasets, the generalization performance of these models
remains constrained by the limited diversity of existing training data. To
address these challenges, we present StereoCarla, a high-fidelity synthetic
stereo dataset specifically designed for autonomous driving scenarios. Built on
the CARLA simulator, StereoCarla incorporates a wide range of camera
configurations, including diverse baselines, viewpoints, and sensor placements
as well as varied environmental conditions such as lighting changes, weather
effects, and road geometries. We conduct comprehensive cross-domain experiments
across four standard evaluation datasets (KITTI2012, KITTI2015, Middlebury,
ETH3D) and demonstrate that models trained on StereoCarla outperform those
trained on 11 existing stereo datasets in terms of generalization accuracy
across multiple benchmarks. Furthermore, when integrated into multi-dataset
training, StereoCarla contributes substantial improvements to generalization
accuracy, highlighting its compatibility and scalability. This dataset provides
a valuable benchmark for developing and evaluating stereo algorithms under
realistic, diverse, and controllable settings, facilitating more robust depth
perception systems for autonomous vehicles. Code can be available at
https://github.com/XiandaGuo/OpenStereo, and data can be available at
https://xiandaguo.net/StereoCarla.

</details>


### [83] [SmokeBench: A Real-World Dataset for Surveillance Image Desmoking in Early-Stage Fire Scenes](https://arxiv.org/abs/2509.12701)
*Wenzhuo Jin,Qianfeng Yang,Xianhao Wu,Hongming Chen,Pengpeng Li,Xiang Chen*

Main category: cs.CV

TL;DR: 该论文提出了一个名为SmokeBench的真实世界监控图像去烟基准数据集，以解决早期火灾场景中烟雾降低能见度以及缺乏配对真实世界数据集的问题，从而推动图像去烟算法的发展。


<details>
  <summary>Details</summary>
Motivation: 早期火灾场景（点燃后0-15分钟）的烟雾严重降低了监控系统的能见度，阻碍了应急响应和救援行动。因此，迫切需要从图像中去除烟雾以获取清晰的场景信息。然而，由于缺乏大规模、真实的配对无烟和烟雾降级图像数据集，去烟算法的发展受到了限制。

Method: 为了解决数据集限制，作者构建了一个名为SmokeBench的真实世界监控图像去烟基准数据集。该数据集包含在不同场景设置和烟雾浓度下捕获的图像对，提供了精确对齐的降级图像和清晰图像，以支持监督学习和严格评估。

Result: 论文发布了SmokeBench数据集，其中包含多样化场景和烟雾浓度的配对烟雾降级和清晰图像。作者还通过在该数据集上对各种去烟方法进行基准测试，进行了全面的实验。

Conclusion: 所提出的SmokeBench数据集为推动真实世界火灾场景中鲁棒且实用的图像去烟技术提供了宝贵的基础。该数据集已公开发布。

Abstract: Early-stage fire scenes (0-15 minutes after ignition) represent a crucial
temporal window for emergency interventions. During this stage, the smoke
produced by combustion significantly reduces the visibility of surveillance
systems, severely impairing situational awareness and hindering effective
emergency response and rescue operations. Consequently, there is an urgent need
to remove smoke from images to obtain clear scene information. However, the
development of smoke removal algorithms remains limited due to the lack of
large-scale, real-world datasets comprising paired smoke-free and
smoke-degraded images. To address these limitations, we present a real-world
surveillance image desmoking benchmark dataset named SmokeBench, which contains
image pairs captured under diverse scenes setup and smoke concentration. The
curated dataset provides precisely aligned degraded and clean images, enabling
supervised learning and rigorous evaluation. We conduct comprehensive
experiments by benchmarking a variety of desmoking methods on our dataset. Our
dataset provides a valuable foundation for advancing robust and practical image
desmoking in real-world fire scenes. This dataset has been released to the
public and can be downloaded from https://github.com/ncfjd/SmokeBench.

</details>


### [84] [RIS-FUSION: Rethinking Text-Driven Infrared and Visible Image Fusion from the Perspective of Referring Image Segmentation](https://arxiv.org/abs/2509.12710)
*Siju Ma,Changsiyu Gong,Xiaofeng Fan,Yong Ma,Chengjie Jiang*

Main category: cs.CV

TL;DR: 现有文本驱动红外与可见光图像融合方法缺乏目标对齐监督。本文提出RIS-FUSION框架，通过联合优化融合与指代图像分割（RIS）任务，并引入LangGatedFusion模块注入文本特征。同时构建MM-RIS大规模基准，实验证明RIS-FUSION在mIoU上超越现有方法11%以上，达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动的图像融合方法缺乏一个目标对齐的任务来有效监督和评估输入文本对融合结果的贡献。作者观察到指代图像分割（RIS）与文本驱动融合具有共同目标：突出文本所指代的物体，这促使他们将这两个任务统一起来。

Method: 本文提出了RIS-FUSION，一个级联框架，通过联合优化统一了融合和指代图像分割（RIS）任务。其核心是LangGatedFusion模块，该模块将文本特征注入到融合骨干网络中以增强语义对齐。为支持多模态指代图像分割任务，作者还引入了MM-RIS，一个大规模基准数据集，包含12.5k训练和3.5k测试三元组，每个三元组由红外-可见光图像对、分割掩码和指代表达组成。

Result: RIS-FUSION取得了最先进的性能，在mIoU上比现有方法高出11%以上。

Conclusion: 通过将文本驱动的红外与可见光图像融合与指代图像分割任务进行统一，并采用联合优化和LangGatedFusion模块，RIS-FUSION框架能够有效解决现有方法缺乏目标对齐监督的问题，显著提升了融合性能，并为多模态指代图像分割任务提供了新的大规模基准。

Abstract: Text-driven infrared and visible image fusion has gained attention for
enabling natural language to guide the fusion process. However, existing
methods lack a goal-aligned task to supervise and evaluate how effectively the
input text contributes to the fusion outcome. We observe that referring image
segmentation (RIS) and text-driven fusion share a common objective:
highlighting the object referred to by the text. Motivated by this, we propose
RIS-FUSION, a cascaded framework that unifies fusion and RIS through joint
optimization. At its core is the LangGatedFusion module, which injects textual
features into the fusion backbone to enhance semantic alignment. To support
multimodal referring image segmentation task, we introduce MM-RIS, a
large-scale benchmark with 12.5k training and 3.5k testing triplets, each
consisting of an infrared-visible image pair, a segmentation mask, and a
referring expression. Extensive experiments show that RIS-FUSION achieves
state-of-the-art performance, outperforming existing methods by over 11% in
mIoU. Code and dataset will be released at
https://github.com/SijuMa2003/RIS-FUSION.

</details>


### [85] [Learning by Imagining: Debiased Feature Augmentation for Compositional Zero-Shot Learning](https://arxiv.org/abs/2509.12711)
*Haozhe Zhang,Chenchen Jing,Mingyu Liu,Qingsheng Wang,Hao Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种名为DeFA（Debiased Feature Augmentation）的新方法，通过结合解耦-重建框架和去偏策略，解决组合零样本学习（CZSL）中属性-对象纠缠和长尾分布的挑战，并在多个数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 组合零样本学习（CZSL）面临挑战，主要原因在于属性和对象之间相互纠缠的特性，以及现实世界数据中普遍存在的长尾分布问题。

Method: 受神经科学中想象和感知共享相似神经过程的启发，论文提出了一种名为Debiased Feature Augmentation (DeFA) 的方法。DeFA将一个用于特征增强的解耦-重建框架与一个去偏策略相结合，通过合成高保真度的组合特征来利用已知属性和对象的先验知识，以支持组合泛化。

Result: 在三个广泛使用的数据集上进行的广泛实验表明，DeFA在“封闭世界”和“开放世界”设置中均达到了最先进的性能。

Conclusion: DeFA通过其解耦-重建和去偏策略，有效解决了CZSL中属性-对象纠缠和长尾分布的挑战，通过合成高保真组合特征实现了卓越的泛化能力，并在多个场景下取得了最先进的结果。

Abstract: Compositional Zero-Shot Learning (CZSL) aims to recognize unseen
attribute-object compositions by learning prior knowledge of seen primitives,
\textit{i.e.}, attributes and objects. Learning generalizable compositional
representations in CZSL remains challenging due to the entangled nature of
attributes and objects as well as the prevalence of long-tailed distributions
in real-world data. Inspired by neuroscientific findings that imagination and
perception share similar neural processes, we propose a novel approach called
Debiased Feature Augmentation (DeFA) to address these challenges. The proposed
DeFA integrates a disentangle-and-reconstruct framework for feature
augmentation with a debiasing strategy. DeFA explicitly leverages the prior
knowledge of seen attributes and objects by synthesizing high-fidelity
composition features to support compositional generalization. Extensive
experiments on three widely used datasets demonstrate that DeFA achieves
state-of-the-art performance in both \textit{closed-world} and
\textit{open-world} settings.

</details>


### [86] [AsyMoE: Leveraging Modal Asymmetry for Enhanced Expert Specialization in Large Vision-Language Models](https://arxiv.org/abs/2509.12715)
*Heng Zhang,Haichuan Hu,Yaomin Shen,Weihao Yu,Yilei Yuan,Haochen You,Guo Cheng,Zijian Zhang,Lubin Gan,Huihui Wei,Hao Zhang,Jin Huang*

Main category: cs.CV

TL;DR: 本文提出AsyMoE，一种新型架构，通过专门的专家组解决大型视觉-语言模型（LVLMs）中视觉和语言处理的不对称性，显著提升性能并减少激活参数。


<details>
  <summary>Details</summary>
Motivation: 现有MoE方法在LVLMs中面临挑战，因为视觉信息（空间完整）和语言信息（需要维护序列上下文）之间存在不对称性。这导致MoE模型难以平衡模态特定特征和跨模态交互，尤其是在深层中，语言专家会失去语境基础并过度依赖参数知识。

Method: 本文提出了AsyMoE架构，通过三种专门的专家组来建模这种不对称性：1) 模态内专家，用于模态特定处理；2) 双曲跨模态专家，用于分层跨模态交互；3) 证据优先语言专家，用于抑制参数偏差并保持语境基础。

Result: 实验表明，AsyMoE在准确性上比普通MoE提升了26.58%，比模态特定MoE提升了15.45%。同时，它比密集模型减少了25.45%的激活参数。

Conclusion: AsyMoE通过其独特的三组专家设计，成功解决了LVLMs中视觉和语言处理的不对称性问题，显著提高了性能和效率，并有效抑制了语言专家在深层中失去语境基础的问题。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated impressive performance
on multimodal tasks through scaled architectures and extensive training.
However, existing Mixture of Experts (MoE) approaches face challenges due to
the asymmetry between visual and linguistic processing. Visual information is
spatially complete, while language requires maintaining sequential context. As
a result, MoE models struggle to balance modality-specific features and
cross-modal interactions. Through systematic analysis, we observe that language
experts in deeper layers progressively lose contextual grounding and rely more
on parametric knowledge rather than utilizing the provided visual and
linguistic information. To address this, we propose AsyMoE, a novel
architecture that models this asymmetry using three specialized expert groups.
We design intra-modality experts for modality-specific processing, hyperbolic
inter-modality experts for hierarchical cross-modal interactions, and
evidence-priority language experts to suppress parametric biases and maintain
contextual grounding. Extensive experiments demonstrate that AsyMoE achieves
26.58% and 15.45% accuracy improvements over vanilla MoE and modality-specific
MoE respectively, with 25.45% fewer activated parameters than dense models.

</details>


### [87] [EvoEmpirBench: Dynamic Spatial Reasoning with Agent-ExpVer](https://arxiv.org/abs/2509.12718)
*Pukun Zhao,Longxiang Wang,Miaowei Wang,Chen Chen,Fanqing Zhou,Haojian Huang*

Main category: cs.CV

TL;DR: 本文引入了两个动态空间基准测试，用于评估模型在局部可观察、动态变化环境下进行空间理解和自适应规划的能力，并提出了基于主观经验的记忆机制。


<details>
  <summary>Details</summary>
Motivation: 大多数现有空间推理基准侧重于静态或全局可观察环境，未能捕捉到在部分可观察和动态变化下进行长周期推理和记忆利用的挑战。

Method: 引入了两个动态空间基准测试：局部可观察迷宫导航和配对消除（match-2 elimination），每个动作都会触发环境结构变化。此外，提出了一个基于主观经验的记忆机制，用于跨任务经验转移和验证。

Result: 实验表明，本文提出的基准测试揭示了主流模型在动态空间推理和长期记忆方面的关键局限性。

Conclusion: 这些基准测试为未来方法学进展提供了一个全面的平台。

Abstract: Most existing spatial reasoning benchmarks focus on static or globally
observable environments, failing to capture the challenges of long-horizon
reasoning and memory utilization under partial observability and dynamic
changes. We introduce two dynamic spatial benchmarks, locally observable maze
navigation and match-2 elimination that systematically evaluate models'
abilities in spatial understanding and adaptive planning when local perception,
environment feedback, and global objectives are tightly coupled. Each action
triggers structural changes in the environment, requiring continuous update of
cognition and strategy. We further propose a subjective experience-based memory
mechanism for cross-task experience transfer and validation. Experiments show
that our benchmarks reveal key limitations of mainstream models in dynamic
spatial reasoning and long-term memory, providing a comprehensive platform for
future methodological advances. Our code and data are available at
https://anonymous.4open.science/r/EvoEmpirBench-143C/.

</details>


### [88] [SPGen: Spherical Projection as Consistent and Flexible Representation for Single Image 3D Shape Generation](https://arxiv.org/abs/2509.12721)
*Jingdong Zhang,Weikai Chen,Yuan Liu,Jionghao Wang,Zhengming Yu,Zhuowen Shen,Bo Yang,Wenping Wang,Xin Li*

Main category: cs.CV

TL;DR: SPGen是一种单视角3D生成模型，通过将几何信息投影到2D球面投影（SP）表示，解决了现有模型在视角间不一致性和复杂内部结构表示上的问题，并提高了效率。


<details>
  <summary>Details</summary>
Motivation: 现有的单视角3D生成模型通常采用多视角扩散先验来重建物体表面，但它们容易出现视角间不一致性，并且无法忠实地表示复杂的内部结构或非平凡的拓扑结构。

Method: 该方法将几何信息投影到包围球上，并将其展开为紧凑且结构化的多层2D球面投影（SP）表示。SPGen完全在图像域中操作，利用了强大的2D扩散先验，并通过内射SP映射自然消除了视角不一致性和模糊性，同时多层SP图能够表示嵌套的内部结构并支持直接提升到水密或开放的3D表面。

Result: SPGen在几何质量和计算效率方面显著优于现有基线模型。

Conclusion: SPGen通过引入独特的球面投影（SP）表示，成功克服了现有单视角3D生成模型在一致性、灵活性（复杂结构表示）和效率方面的局限性，实现了卓越的性能。

Abstract: Existing single-view 3D generative models typically adopt multiview diffusion
priors to reconstruct object surfaces, yet they remain prone to inter-view
inconsistencies and are unable to faithfully represent complex internal
structure or nontrivial topologies. In particular, we encode geometry
information by projecting it onto a bounding sphere and unwrapping it into a
compact and structural multi-layer 2D Spherical Projection (SP) representation.
Operating solely in the image domain, SPGen offers three key advantages
simultaneously: (1) Consistency. The injective SP mapping encodes surface
geometry with a single viewpoint which naturally eliminates view inconsistency
and ambiguity; (2) Flexibility. Multi-layer SP maps represent nested internal
structures and support direct lifting to watertight or open 3D surfaces; (3)
Efficiency. The image-domain formulation allows the direct inheritance of
powerful 2D diffusion priors and enables efficient finetuning with limited
computational resources. Extensive experiments demonstrate that SPGen
significantly outperforms existing baselines in geometric quality and
computational efficiency.

</details>


### [89] [Defense-to-Attack: Bypassing Weak Defenses Enables Stronger Jailbreaks in Vision-Language Models](https://arxiv.org/abs/2509.12724)
*Yunhan Zhao,Xiang Zheng,Xingjun Ma*

Main category: cs.CV

TL;DR: 本文提出Defense2Attack，一种新颖的越狱方法，通过将弱防御模式融入攻击流程来显著提高对视觉语言模型（VLMs）的越狱效率和效果。


<details>
  <summary>Details</summary>
Motivation: 尽管现有VLM越狱方法取得了进展，但其有效性和效率仍有提升空间。研究发现，将弱防御整合到攻击流程中可以显著增强VLM越狱的效果和效率。

Method: Defense2Attack方法包含三个核心组件：1) 一个视觉优化器，嵌入带有肯定和鼓励语义的通用对抗性扰动；2) 一个文本优化器，使用防御风格的提示来精炼输入；3) 一个红队后缀生成器，通过强化微调增强越狱效果。

Result: 在四个VLM和四个安全基准上的评估表明，Defense2Attack在单次尝试中实现了卓越的越狱性能，优于通常需要多次尝试的现有最先进攻击方法。

Conclusion: 该工作通过利用防御模式为VLM越狱提供了一个新颖的视角。

Abstract: Despite their superb capabilities, Vision-Language Models (VLMs) have been
shown to be vulnerable to jailbreak attacks. While recent jailbreaks have
achieved notable progress, their effectiveness and efficiency can still be
improved. In this work, we reveal an interesting phenomenon: incorporating weak
defense into the attack pipeline can significantly enhance both the
effectiveness and the efficiency of jailbreaks on VLMs. Building on this
insight, we propose Defense2Attack, a novel jailbreak method that bypasses the
safety guardrails of VLMs by leveraging defensive patterns to guide jailbreak
prompt design. Specifically, Defense2Attack consists of three key components:
(1) a visual optimizer that embeds universal adversarial perturbations with
affirmative and encouraging semantics; (2) a textual optimizer that refines the
input using a defense-styled prompt; and (3) a red-team suffix generator that
enhances the jailbreak through reinforcement fine-tuning. We empirically
evaluate our method on four VLMs and four safety benchmarks. The results
demonstrate that Defense2Attack achieves superior jailbreak performance in a
single attempt, outperforming state-of-the-art attack methods that often
require multiple tries. Our work offers a new perspective on jailbreaking VLMs.

</details>


### [90] [Scalable RF Simulation in Generative 4D Worlds](https://arxiv.org/abs/2508.12176)
*Zhiwei Zheng,Dongyin Hu,Mingmin Zhao*

Main category: cs.CV

TL;DR: WaveVerse是一个基于提示的、可扩展的框架，通过语言引导的4D世界生成器和相位相干射线追踪模拟器，从生成的人体运动室内场景中模拟逼真的射频（RF）信号，解决了RF传感数据收集的挑战，并首次实现了RF成像数据生成，显著提升了数据有限和充足场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 射频（RF）传感作为室内感知任务中保护隐私的替代方案日益重要，但动态多样的室内环境中高质量RF数据收集仍是一大挑战。

Method: WaveVerse框架通过以下方式模拟RF信号：1) 引入一个语言引导的4D世界生成器，其中包含一个状态感知因果变换器，用于基于空间约束和文本生成人体运动；2) 使用一个相位相干的射线追踪模拟器，生成准确且相干的RF信号。

Result: 实验证明了WaveVerse在条件人体运动生成方面的有效性，并展示了相位相干性在波束成形和呼吸监测中的应用。此外，在ML高分辨率成像和人体活动识别的案例研究中，WaveVerse不仅首次实现了RF成像数据生成，还在数据有限和数据充足的情况下持续获得性能提升。

Conclusion: WaveVerse成功解决了RF传感数据收集的难题，通过生成逼真的RF信号，首次实现了RF成像的数据生成，并显著提升了人体活动识别等任务的性能，为RF感知应用提供了强大的数据生成能力。

Abstract: Radio Frequency (RF) sensing has emerged as a powerful, privacy-preserving
alternative to vision-based methods for indoor perception tasks. However,
collecting high-quality RF data in dynamic and diverse indoor environments
remains a major challenge. To address this, we introduce WaveVerse, a
prompt-based, scalable framework that simulates realistic RF signals from
generated indoor scenes with human motions. WaveVerse introduces a
language-guided 4D world generator, which includes a state-aware causal
transformer for human motion generation conditioned on spatial constraints and
texts, and a phase-coherent ray tracing simulator that enables the simulation
of accurate and coherent RF signals. Experiments demonstrate the effectiveness
of our approach in conditioned human motion generation and highlight how phase
coherence is applied to beamforming and respiration monitoring. We further
present two case studies in ML-based high-resolution imaging and human activity
recognition, demonstrating that WaveVerse not only enables data generation for
RF imaging for the first time, but also consistently achieves performance gain
in both data-limited and data-adequate scenarios.

</details>


### [91] [Effective Gaussian Management for High-fidelity Object Reconstruction](https://arxiv.org/abs/2509.12742)
*Jiateng Liu,Hao Gao,Jiu-Cheng Xie,Chi-Man Pun,Jian Xiong,Haolun Li,Feng Xu*

Main category: cs.CV

TL;DR: 本文提出了一种高效的高斯管理方法，用于高保真物体重建。该方法通过动态激活球谐函数或法线的新型稠密化策略，以及自适应调整球谐阶数和任务解耦剪枝的轻量级高斯表示，解决了现有高斯泼溅方法的局限性，实现了卓越的重建质量和效率，并显著减少了参数。


<details>
  <summary>Details</summary>
Motivation: 现有高斯泼溅（GS）方法存在属性分配不加区分和双重监督导致的梯度冲突问题，同时在表示效率方面仍有提升空间，需要更有效地平衡表示能力与参数数量。

Method: 本文提出以下方法：1. 新型稠密化策略：在表面重建模块的监督下动态激活球谐函数（SHs）或法线，以缓解梯度冲突。2. 轻量级高斯表示：根据梯度大小自适应调整每个高斯点的球谐阶数。3. 任务解耦剪枝：移除对重建任务影响最小的高斯点，同时不牺牲其他任务。该方法是模型无关的，可无缝集成到其他框架中。

Result: 实验证明，该方法在重建质量和效率方面均持续优于最先进的方法，以显著更少的参数实现了卓越的性能。

Conclusion: 本文提出的高斯管理方法通过创新的稠密化策略和轻量级高斯表示，有效解决了高保真物体重建中的挑战，显著提升了重建质量和效率，同时减少了模型大小，并具有良好的通用性。

Abstract: This paper proposes an effective Gaussian management approach for
high-fidelity object reconstruction. Departing from recent Gaussian Splatting
(GS) methods that employ indiscriminate attribute assignment, our approach
introduces a novel densification strategy that dynamically activates spherical
harmonics (SHs) or normals under the supervision of a surface reconstruction
module, which effectively mitigates the gradient conflicts caused by dual
supervision and achieves superior reconstruction results. To further improve
representation efficiency, we develop a lightweight Gaussian representation
that adaptively adjusts the SH orders of each Gaussian based on gradient
magnitudes and performs task-decoupled pruning to remove Gaussian with minimal
impact on a reconstruction task without sacrificing others, which balances the
representational capacity with parameter quantity. Notably, our management
approach is model-agnostic and can be seamlessly integrated into other
frameworks, enhancing performance while reducing model size. Extensive
experiments demonstrate that our approach consistently outperforms
state-of-the-art approaches in both reconstruction quality and efficiency,
achieving superior performance with significantly fewer parameters.

</details>


### [92] [A Synthetic Data Pipeline for Supporting Manufacturing SMEs in Visual Assembly Control](https://arxiv.org/abs/2509.13089)
*Jonas Werheid,Shengjie He,Aymen Gannouni,Anas Abdelrazeq,Robert H. Schmitt*

Main category: cs.CV

TL;DR: 本文提出一种基于CAD数据和目标检测算法的合成数据生成方法，用于实现易于集成且数据高效的视觉装配质量控制，尤其适用于资源有限的中小型企业。


<details>
  <summary>Details</summary>
Motivation: 自动化视觉装配控制在制造业中至关重要，但图像采集、标注和算法训练成本高昂，对中小型企业（SMEs）构成挑战。合成数据有潜力降低这些成本，但在装配质量控制中的实际应用仍有限。

Method: 该方法利用基于计算机辅助设计（CAD）数据的模拟场景生成技术，结合目标检测算法，构建了一个省时的数据生成管道，用于视觉装配控制。

Result: 该管道在生成制造环境图像数据方面实现了省时，在模拟训练数据中正确识别合成行星齿轮系统组件实例的平均精度（mAP@0.5:0.95）高达99.5%，转移到真实相机捕获的测试数据时达到93%。

Conclusion: 研究表明，在可适应的管道中生成合成数据是有效的，并强调了其在支持中小型企业实施资源高效的视觉装配控制解决方案方面的潜力。

Abstract: Quality control of assembly processes is essential in manufacturing to ensure
not only the quality of individual components but also their proper integration
into the final product. To assist in this matter, automated assembly control
using computer vision methods has been widely implemented. However, the costs
associated with image acquisition, annotation, and training of computer vision
algorithms pose challenges for integration, especially for small- and
medium-sized enterprises (SMEs), which often lack the resources for extensive
training, data collection, and manual image annotation. Synthetic data offers
the potential to reduce manual data collection and labeling. Nevertheless, its
practical application in the context of assembly quality remains limited. In
this work, we present a novel approach for easily integrable and data-efficient
visual assembly control. Our approach leverages simulated scene generation
based on computer-aided design (CAD) data and object detection algorithms. The
results demonstrate a time-saving pipeline for generating image data in
manufacturing environments, achieving a mean Average Precision (mAP@0.5:0.95)
up to 99,5% for correctly identifying instances of synthetic planetary gear
system components within our simulated training data, and up to 93% when
transferred to real-world camera-captured testing data. This research
highlights the effectiveness of synthetic data generation within an adaptable
pipeline and underscores its potential to support SMEs in implementing
resource-efficient visual assembly control solutions.

</details>


### [93] [Modelling and analysis of the 8 filters from the "master key filters hypothesis" for depthwise-separable deep networks in relation to idealized receptive fields based on scale-space theory](https://arxiv.org/abs/2509.12746)
*Tony Lindeberg,Zahra Babaiee,Peyman M. Kiasari*

Main category: cs.CV

TL;DR: 本文分析并建模了从基于ConvNeXt的深度可分离网络中提取的“主键滤波器”，发现它们可以用基于高斯核的差分算子形式的离散尺度空间滤波器进行良好近似和替换。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为了理解和建模深度可分离深度网络（特别是ConvNeXt架构）中学习到的感受野，并验证这些滤波器是否可以被空间可分离的操作以及基于简单数学模型（如高斯核的差分算子）的理想化滤波器所近似。

Method: 首先，通过聚类从ConvNeXt中提取了8个“主键滤波器”。接着，计算了这些滤波器的空间传播度量（加权均值和方差），以支持滤波器可分离性和非中心滤波器偏移量接近半格单位的假设。然后，将聚类的“主键滤波器”建模为应用于离散高斯核的空间平滑操作的差分算子。建模通过两种方式进行：(i) 对每个滤波器在坐标方向上使用可能不同的尺度参数，或(ii) 使用相同的尺度参数。模型拟合通过两种方法实现：(i) 要求感受野绝对值的空间方差相等，或(ii) 最小化理想化模型与学习滤波器之间的离散$l_1$-或$l_2$-范数。最后，通过用理想化滤波器替换学习滤波器来评估其预测性能。

Result: 研究结果表明，学习到的滤波器可以由空间域上的可分离滤波操作建模，并且非中心滤波器的空间偏移量接近半格单位。理想化的感受野模型与学习到的滤波器表现出良好的定性相似性。此外，理想化的感受野模型在深度可分离深度网络中替换学习到的滤波器时，表现出良好的预测特性，证明学习到的滤波器可以很好地被离散尺度空间滤波器近似。

Conclusion: 深度可分离深度网络中学习到的滤波器（如ConvNeXt）可以被基于高斯核的差分算子形式的理想化离散尺度空间滤波器有效地近似和替换，这表明这些学习到的滤波器具有内在的结构化特性。

Abstract: This paper presents the results of analysing and modelling a set of 8
``master key filters'', which have been extracted by applying a clustering
approach to the receptive fields learned in depthwise-separable deep networks
based on the ConvNeXt architecture.
  For this purpose, we first compute spatial spread measures in terms of
weighted mean values and weighted variances of the absolute values of the
learned filters, which support the working hypotheses that: (i) the learned
filters can be modelled by separable filtering operations over the spatial
domain, and that (ii) the spatial offsets of the those learned filters that are
non-centered are rather close to half a grid unit. Then, we model the clustered
``master key filters'' in terms of difference operators applied to a spatial
smoothing operation in terms of the discrete analogue of the Gaussian kernel,
and demonstrate that the resulting idealized models of the receptive fields
show good qualitative similarity to the learned filters.
  This modelling is performed in two different ways: (i) using possibly
different values of the scale parameters in the coordinate directions for each
filter, and (ii) using the same value of the scale parameter in both coordinate
directions. Then, we perform the actual model fitting by either (i) requiring
spatial spread measures in terms of spatial variances of the absolute values of
the receptive fields to be equal, or (ii) minimizing the discrete $l_1$- or
$l_2$-norms between the idealized receptive field models and the learned
filters.
  Complementary experimental results then demonstrate the idealized models of
receptive fields have good predictive properties for replacing the learned
filters by idealized filters in depthwise-separable deep networks, thus showing
that the learned filters in depthwise-separable deep networks can be well
approximated by discrete scale-space filters.

</details>


### [94] [What Makes a Good Generated Image? Investigating Human and Multimodal LLM Image Preference Alignment](https://arxiv.org/abs/2509.12750)
*Rishab Parthasarathy,Jasmine Collins,Cory Stephenson*

Main category: cs.CV

TL;DR: 本研究探讨了多模态大语言模型（MLLMs）和人类在评估生成图像质量时，对图像美学、构图等属性的感知差异，发现两者在属性关联性和某些特定属性的判断能力上存在显著不同。


<details>
  <summary>Details</summary>
Motivation: 生成式文本到图像模型的自动化评估是一个挑战，现有研究虽提出使用多模态大语言模型（MLLMs）评估图像质量，但对MLLMs如何利用人类相关的概念（如图像风格或构图）进行整体评估缺乏深入理解。

Method: 首先，通过合成图像对收集人类偏好数据集，并使用任务间相关性分析来理解人类在判断图像质量时各属性之间的关系。然后，对MLLMs重复相同的分析。最后，通过生成高度可控的合成数据集，研究人类和MLLMs对各个特定图像质量属性（如美学、无伪影、解剖准确性、构图正确性、对象依从性和风格）的判断能力。

Result: 研究发现，与人类相比，MLLMs在判断图像质量属性时的属性间关系要弱得多。此外，人类能够轻松判断所有特定图像质量属性，但MLLMs在判断某些属性（如解剖准确性）时面临更大困难。

Conclusion: 这些发现揭示了人类和多模态大语言模型在感知和评估图像时存在的有趣差异，表明MLLMs在理解和判断某些人类关注的图像质量属性方面仍有不足。

Abstract: Automated evaluation of generative text-to-image models remains a challenging
problem. Recent works have proposed using multimodal LLMs to judge the quality
of images, but these works offer little insight into how multimodal LLMs make
use of concepts relevant to humans, such as image style or composition, to
generate their overall assessment. In this work, we study what attributes of an
image--specifically aesthetics, lack of artifacts, anatomical accuracy,
compositional correctness, object adherence, and style--are important for both
LLMs and humans to make judgments on image quality. We first curate a dataset
of human preferences using synthetically generated image pairs. We use
inter-task correlation between each pair of image quality attributes to
understand which attributes are related in making human judgments. Repeating
the same analysis with LLMs, we find that the relationships between image
quality attributes are much weaker. Finally, we study individual image quality
attributes by generating synthetic datasets with a high degree of control for
each axis. Humans are able to easily judge the quality of an image with respect
to all of the specific image quality attributes (e.g. high vs. low aesthetic
image), however we find that some attributes, such as anatomical accuracy, are
much more difficult for multimodal LLMs to learn to judge. Taken together,
these findings reveal interesting differences between how humans and multimodal
LLMs perceive images.

</details>


### [95] [Recurrent Cross-View Object Geo-Localization](https://arxiv.org/abs/2509.12757)
*Xiaohan Zhang,Si-Yuan Cao,Xiaokai Bai,Yiming Li,Zhangkai Shen,Zhe Wu,Xiaoxi Hu,Hui-liang Shen*

Main category: cs.CV

TL;DR: ReCOT将跨视图目标地理定位(CVOGL)重构为循环定位任务，通过可学习的token、迭代优化以及SAM知识蒸馏和参考特征增强模块，实现了SOTA性能并显著减少了参数。


<details>
  <summary>Details</summary>
Motivation: 现有的CVOGL方法将任务视为一次性检测，直接回归目标位置，但它们容易受到特征噪声的影响，并且缺乏错误纠正机制。

Method: 本文提出了ReCOT（Recurrent Cross-view Object geo-localization Transformer），将CVOGL重构为循环定位任务。ReCOT引入了一组可学习的token，编码查询图像和提示嵌入中的任务特定意图，并迭代地关注参考特征以细化预测位置。为增强循环过程，引入了两个补充模块：1) 基于SAM的知识蒸馏策略，转移分割先验以提供更清晰的语义指导；2) 参考特征增强模块（RFEM），引入分层注意力以强调参考特征中与目标相关的区域。

Result: 在标准CVOGL基准测试上，ReCOT实现了最先进（SOTA）的性能，同时与之前的SOTA方法相比，参数减少了60%。

Conclusion: ReCOT通过将CVOGL重新定义为循环定位任务，并结合创新的知识蒸馏和特征增强机制，有效克服了现有方法的局限性，实现了卓越的定位精度和参数效率。

Abstract: Cross-view object geo-localization (CVOGL) aims to determine the location of
a specific object in high-resolution satellite imagery given a query image with
a point prompt. Existing approaches treat CVOGL as a one-shot detection task,
directly regressing object locations from cross-view information aggregation,
but they are vulnerable to feature noise and lack mechanisms for error
correction. In this paper, we propose ReCOT, a Recurrent Cross-view Object
geo-localization Transformer, which reformulates CVOGL as a recurrent
localization task. ReCOT introduces a set of learnable tokens that encode
task-specific intent from the query image and prompt embeddings, and
iteratively attend to the reference features to refine the predicted location.
To enhance this recurrent process, we incorporate two complementary modules:
(1) a SAM-based knowledge distillation strategy that transfers segmentation
priors from the Segment Anything Model (SAM) to provide clearer semantic
guidance without additional inference cost, and (2) a Reference Feature
Enhancement Module (RFEM) that introduces a hierarchical attention to emphasize
object-relevant regions in the reference features. Extensive experiments on
standard CVOGL benchmarks demonstrate that ReCOT achieves state-of-the-art
(SOTA) performance while reducing parameters by 60% compared to previous SOTA
approaches.

</details>


### [96] [CECT-Mamba: a Hierarchical Contrast-enhanced-aware Model for Pancreatic Tumor Subtyping from Multi-phase CECT](https://arxiv.org/abs/2509.12777)
*Zhifang Gong,Shuo Gao,Ben Zhao,Yingjing Xu,Yijun Yang,Shenghong Ju,Guangquan Zhou*

Main category: cs.CV

TL;DR: 本文首次提出一种基于Mamba模型的自动化方法，结合多期增强CT（CECT）数据，用于精确区分胰腺肿瘤亚型，尤其擅长建模多期CECT中的时空信息。


<details>
  <summary>Details</summary>
Motivation: 胰腺肿瘤的高度异质性和变异性给精确亚型诊断带来了巨大挑战。以往方法未能有效利用放射科医生诊断流程中常用的多期CECT图像的上下文信息，从而限制了其性能。

Method: 该研究引入Mamba模型来整合多期CECT数据，以实现胰腺肿瘤亚型鉴别，利用其学习能力和简洁性进行时空建模。具体而言，提出了一种双层分级对比增强感知Mamba模块，结合两种新颖的时空采样序列来探索病灶的期内和期间对比度变化。此外，在时间扫描建模中引入了相似性引导细化模块，以强调对具有明显时间变化的局部肿瘤区域的学习。还设计了空间互补整合器和多粒度融合模块，用于编码和聚合不同尺度的语义信息。

Result: 在包含270个临床病例的内部数据集上进行实验，该方法在区分胰腺导管腺癌（PDAC）和胰腺神经内分泌肿瘤（PNETs）方面达到了97.4%的准确率和98.6%的AUC。

Conclusion: 该研究提出的方法在胰腺肿瘤亚型诊断中表现出更高的准确性和效率，有望成为一种有前景的诊断工具。

Abstract: Contrast-enhanced computed tomography (CECT) is the primary imaging technique
that provides valuable spatial-temporal information about lesions, enabling the
accurate diagnosis and subclassification of pancreatic tumors. However, the
high heterogeneity and variability of pancreatic tumors still pose substantial
challenges for precise subtyping diagnosis. Previous methods fail to
effectively explore the contextual information across multiple CECT phases
commonly used in radiologists' diagnostic workflows, thereby limiting their
performance. In this paper, we introduce, for the first time, an automatic way
to combine the multi-phase CECT data to discriminate between pancreatic tumor
subtypes, among which the key is using Mamba with promising learnability and
simplicity to encourage both temporal and spatial modeling from multi-phase
CECT. Specifically, we propose a dual hierarchical contrast-enhanced-aware
Mamba module incorporating two novel spatial and temporal sampling sequences to
explore intra and inter-phase contrast variations of lesions. A
similarity-guided refinement module is also imposed into the temporal scanning
modeling to emphasize the learning on local tumor regions with more obvious
temporal variations. Moreover, we design the space complementary integrator and
multi-granularity fusion module to encode and aggregate the semantics across
different scales, achieving more efficient learning for subtyping pancreatic
tumors. The experimental results on an in-house dataset of 270 clinical cases
achieve an accuracy of 97.4% and an AUC of 98.6% in distinguishing between
pancreatic ductal adenocarcinoma (PDAC) and pancreatic neuroendocrine tumors
(PNETs), demonstrating its potential as a more accurate and efficient tool.

</details>


### [97] [A-TDOM: Active TDOM via On-the-Fly 3DGS](https://arxiv.org/abs/2509.12759)
*Yiwei Xu,Xiang Wang,Yifei Yu,Wentian Gan,Luca Morelli,Giulio Perda,Xiongwu Xiao,Zongqian Zhan,Xin Wang,Fabio Remondino*

Main category: cs.CV

TL;DR: 本文提出A-TDOM，一种基于实时三维高斯溅射（3DGS）优化的近实时真数字正射影像图（TDOM）生成方法，解决了传统方法耗时且质量受损的问题。


<details>
  <summary>Details</summary>
Motivation: 真数字正射影像图（TDOM）在城市管理、规划、土地测量等领域至关重要，但传统生成方法依赖复杂的离线摄影测量流程，导致延迟，无法支持实时应用。此外，不准确的相机姿态、数字表面模型（DSM）或场景遮挡可能导致TDOM质量下降。

Method: A-TDOM方法基于实时三维高斯溅射（3DGS）优化。每当获取新图像时，通过实时运动恢复结构（SfM）计算其姿态和稀疏点云。然后，将新的高斯函数集成并优化到先前未见或粗略重建的区域中。通过与正交溅射相结合，A-TDOM可以在每次新的3DGS场更新后立即进行渲染。

Result: 在多个基准测试上的初步实验表明，所提出的A-TDOM能够以近实时方式主动渲染TDOM，每张新图像的3DGS优化仅需数秒，同时保持可接受的渲染质量和TDOM的几何精度。

Conclusion: A-TDOM成功实现了近实时TDOM生成，解决了传统方法的效率和质量挑战，为实时地理空间应用提供了高精度和高效率的解决方案。

Abstract: True Digital Orthophoto Map (TDOM) serves as a crucial geospatial product in
various fields such as urban management, city planning, land surveying, etc.
However, traditional TDOM generation methods generally rely on a complex
offline photogrammetric pipeline, resulting in delays that hinder real-time
applications. Moreover, the quality of TDOM may degrade due to various
challenges, such as inaccurate camera poses or Digital Surface Model (DSM) and
scene occlusions. To address these challenges, this work introduces A-TDOM, a
near real-time TDOM generation method based on On-the-Fly 3DGS optimization. As
each image is acquired, its pose and sparse point cloud are computed via
On-the-Fly SfM. Then new Gaussians are integrated and optimized into previously
unseen or coarsely reconstructed regions. By integrating with orthogonal
splatting, A-TDOM can render just after each update of a new 3DGS field.
Initial experiments on multiple benchmarks show that the proposed A-TDOM is
capable of actively rendering TDOM in near real-time, with 3DGS optimization
for each new image in seconds while maintaining acceptable rendering quality
and TDOM geometric accuracy.

</details>


### [98] [Data Scaling Laws for Radiology Foundation Models](https://arxiv.org/abs/2509.12818)
*Maximilian Ilse,Harshita Sharma,Anton Schwaighofer,Sam Bond-Taylor,Fernando Pérez-García,Olesya Melnichenko,Anne-Marie G. Sykes,Kelly K. Horst,Ashish Khandelwal,Maxwell Reynolds,Maria T. Wetscherek,Noel C. F. Codella,Javier Alvarez-Valle,Korfiatis Panagiotis,Valentina Salvatelli*

Main category: cs.CV

TL;DR: 本研究系统地探讨了在大量胸部X光数据上对医学视觉编码器（MI2和RAD-DINO）进行持续预训练的效果，发现不同模型在不同任务上表现出不同的扩展能力，并强调了结构化监督的价值以及中心特定预训练的实用性。


<details>
  <summary>Details</summary>
Motivation: 通用视觉基础模型（如CLIP和DINOv2）在网络规模数据上表现出色，但在医学成像领域，基础模型受限于较小的数据集，导致对数据规模和预训练范式如何影响性能的理解不足。

Method: 研究人员系统地研究了两种代表性视觉编码器（MI2，代表CLIP范式；RAD-DINO，代表DINOv2范式）的持续预训练。他们在来自单一机构的350万张胸部X光片上进行预训练，并保持计算和评估协议不变。评估任务包括分类（放射学发现、线条和管路）、分割（线条和管路）以及放射学报告生成。

Result: 实验结果显示，MI2在与发现相关的任务上扩展更有效，而RAD-DINO在与管路相关的任务上表现更强。令人惊讶的是，使用UniCL结合报告和结构化标签对MI2进行持续预训练能提升性能，突显了大规模结构化监督的价值。此外，研究发现对于某些任务，仅需3万个域内样本就足以超越开放权重的基础模型。

Conclusion: 这些结果突出了中心特定持续预训练的实用性，使医疗机构能够通过利用其域内数据获得显著的性能提升。

Abstract: Foundation vision encoders such as CLIP and DINOv2, trained on web-scale
data, exhibit strong transfer performance across tasks and datasets. However,
medical imaging foundation models remain constrained by smaller datasets,
limiting our understanding of how data scale and pretraining paradigms affect
performance in this setting. In this work, we systematically study continual
pretraining of two vision encoders, MedImageInsight (MI2) and RAD-DINO
representing the two major encoder paradigms CLIP and DINOv2, on up to 3.5M
chest x-rays from a single institution, holding compute and evaluation
protocols constant. We evaluate on classification (radiology findings, lines
and tubes), segmentation (lines and tubes), and radiology report generation.
While prior work has primarily focused on tasks related to radiology findings,
we include lines and tubes tasks to counterbalance this bias and evaluate a
model's ability to extract features that preserve continuity along elongated
structures. Our experiments show that MI2 scales more effectively for
finding-related tasks, while RAD-DINO is stronger on tube-related tasks.
Surprisingly, continually pretraining MI2 with both reports and structured
labels using UniCL improves performance, underscoring the value of structured
supervision at scale. We further show that for some tasks, as few as 30k
in-domain samples are sufficient to surpass open-weights foundation models.
These results highlight the utility of center-specific continual pretraining,
enabling medical institutions to derive significant performance gains by
utilizing in-domain data.

</details>


### [99] [DyGLNet: Hybrid Global-Local Feature Fusion with Dynamic Upsampling for Medical Image Segmentation](https://arxiv.org/abs/2509.12763)
*Yican Zhao,Ce Wang,You Hao,Lei Li,Tianli Liao*

Main category: cs.CV

TL;DR: 本文提出DyGLNet，一种高效准确的医学图像分割模型，通过融合全局与局部特征并采用动态上采样机制，解决了多尺度病变、模糊边界和计算量大的挑战。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临多尺度病变变异性、组织边界不明确以及计算密集型处理需求等挑战。

Method: DyGLNet通过以下方式实现：1) 融合全局和局部特征；2) 引入动态上采样机制；3) 设计混合特征提取模块（SHDCBlock），结合单头自注意力与多尺度空洞卷积，协同建模局部细节和全局上下文；4) 引入动态自适应上采样模块（DyFusionUp），基于可学习偏移实现特征图的高保真重建；5) 采用轻量化设计以降低计算开销。

Result: 在七个公共数据集上的实验表明，DyGLNet优于现有方法，特别是在边界精度和小目标分割方面表现出色。同时，它展现出更低的计算复杂度。

Conclusion: DyGLNet为临床医学图像分析提供了一个高效可靠的解决方案，能够实现准确且计算成本较低的分割。

Abstract: Medical image segmentation grapples with challenges including multi-scale
lesion variability, ill-defined tissue boundaries, and computationally
intensive processing demands. This paper proposes the DyGLNet, which achieves
efficient and accurate segmentation by fusing global and local features with a
dynamic upsampling mechanism. The model innovatively designs a hybrid feature
extraction module (SHDCBlock), combining single-head self-attention and
multi-scale dilated convolutions to model local details and global context
collaboratively. We further introduce a dynamic adaptive upsampling module
(DyFusionUp) to realize high-fidelity reconstruction of feature maps based on
learnable offsets. Then, a lightweight design is adopted to reduce
computational overhead. Experiments on seven public datasets demonstrate that
DyGLNet outperforms existing methods, particularly excelling in boundary
accuracy and small-object segmentation. Meanwhile, it exhibits lower
computation complexity, enabling an efficient and reliable solution for
clinical medical image analysis. The code will be made available soon.

</details>


### [100] [Runge-Kutta Approximation and Decoupled Attention for Rectified Flow Inversion and Semantic Editing](https://arxiv.org/abs/2509.12888)
*Weiming Chen,Zhihan Zhu,Yijia Wang,Zhihai He*

Main category: cs.CV

TL;DR: 本文提出了一种高效高阶反演方法和解耦扩散Transformer注意力（DDTA）机制，以解决整流流（RF）模型在反演精度和注意力控制方面的挑战，从而在图像重建和文本引导编辑任务中实现最先进的保真度和可编辑性。


<details>
  <summary>Details</summary>
Motivation: 整流流（RF）模型虽然生成性能优越，但在实际应用中面临两大挑战：一是反演精度低，影响与源图像的一致性；二是扩散Transformer中多模态注意力纠缠不清，阻碍了精确的注意力控制。

Method: 为解决第一个挑战，提出了一种基于Runge-Kutta微分方程求解器的高效高阶整流流模型反演方法。为解决第二个挑战，引入了去耦扩散Transformer注意力（DDTA），这是一种新颖的机制，可在多模态扩散Transformer内部解耦文本和图像注意力，从而实现更精确的语义控制。

Result: 在图像重建和文本引导编辑任务上的大量实验表明，该方法在保真度和可编辑性方面均达到了最先进的性能。

Conclusion: 通过提出高效高阶反演方法和解耦扩散Transformer注意力（DDTA），显著提升了整流流模型的图像重建保真度和文本引导编辑能力，有效解决了其在实际应用中的关键问题。

Abstract: Rectified flow (RF) models have recently demonstrated superior generative
performance compared to DDIM-based diffusion models. However, in real-world
applications, they suffer from two major challenges: (1) low inversion accuracy
that hinders the consistency with the source image, and (2) entangled
multimodal attention in diffusion transformers, which hinders precise attention
control. To address the first challenge, we propose an efficient high-order
inversion method for rectified flow models based on the Runge-Kutta solver of
differential equations. To tackle the second challenge, we introduce Decoupled
Diffusion Transformer Attention (DDTA), a novel mechanism that disentangles
text and image attention inside the multimodal diffusion transformers, enabling
more precise semantic control. Extensive experiments on image reconstruction
and text-guided editing tasks demonstrate that our method achieves
state-of-the-art performance in terms of fidelity and editability. Code is
available at https://github.com/wmchen/RKSovler_DDTA.

</details>


### [101] [BATR-FST: Bi-Level Adaptive Token Refinement for Few-Shot Transformers](https://arxiv.org/abs/2509.12768)
*Mohammed Al-Habib,Zuping Zhang,Abdulrahman Noman*

Main category: cs.CV

TL;DR: 本文提出BATR-FST，一种两阶段方法，通过双层自适应令牌精炼（包括令牌聚类、不确定性感知令牌加权、双层注意力、图令牌传播和类别分离惩罚）来提升Vision Transformer在小样本学习中的性能。


<details>
  <summary>Details</summary>
Motivation: Vision Transformer在小样本学习中表现受限，原因在于令牌级交互精炼不足、训练数据有限、归纳偏置较弱。现有方法依赖僵化的令牌匹配或基本相似性度量，限制了全局上下文整合和局部特征精炼。

Method: BATR-FST采用两阶段方法：预训练阶段利用掩码图像建模（MIM）提供可迁移的补丁级表示。元微调阶段引入双层自适应令牌精炼模块，该模块包含令牌聚类以捕获局部交互、不确定性感知令牌加权以优先处理可靠特征、以及双层注意力机制以平衡簇内和簇间关系。此外，还采用图令牌传播确保支持和查询实例间的语义一致性，并通过类别分离惩罚增强判别能力。

Result: 在三个基准小样本数据集上进行的广泛实验表明，BATR-FST在1-shot和5-shot场景下均取得了优异结果。

Conclusion: BATR-FST有效提升了基于Transformer的小样本分类性能，通过其独特的双层自适应令牌精炼机制，解决了Vision Transformer在小样本学习中的挑战。

Abstract: Vision Transformers (ViTs) have shown significant promise in computer vision
applications. However, their performance in few-shot learning is limited by
challenges in refining token-level interactions, struggling with limited
training data, and developing a strong inductive bias. Existing methods often
depend on inflexible token matching or basic similarity measures, which limit
the effective incorporation of global context and localized feature refinement.
To address these challenges, we propose Bi-Level Adaptive Token Refinement for
Few-Shot Transformers (BATR-FST), a two-stage approach that progressively
improves token representations and maintains a robust inductive bias for
few-shot classification. During the pre-training phase, Masked Image Modeling
(MIM) provides Vision Transformers (ViTs) with transferable patch-level
representations by recreating masked image regions, providing a robust basis
for subsequent adaptation. In the meta-fine-tuning phase, BATR-FST incorporates
a Bi-Level Adaptive Token Refinement module that utilizes Token Clustering to
capture localized interactions, Uncertainty-Aware Token Weighting to prioritize
dependable features, and a Bi-Level Attention mechanism to balance
intra-cluster and inter-cluster relationships, thereby facilitating thorough
token refinement. Furthermore, Graph Token Propagation ensures semantic
consistency between support and query instances, while a Class Separation
Penalty preserves different class borders, enhancing discriminative capability.
Extensive experiments on three benchmark few-shot datasets demonstrate that
BATR-FST achieves superior results in both 1-shot and 5-shot scenarios and
improves the few-shot classification via transformers.

</details>


### [102] [Cross-Layer Vision Smoothing: Enhancing Visual Understanding via Sustained Focus on Key Objects in Large Vision-Language Models](https://arxiv.org/abs/2509.12897)
*Jianfei Zhao,Feng Zhang,Xin Sun,Lingxing Kong,Zhixing Tan,Chong Feng*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLMs）对关键对象的关注短暂，本文提出跨层视觉平滑（CLVS），通过引入视觉记忆来平滑跨层的注意力分布，从而提升LVLMs的视觉理解能力。


<details>
  <summary>Details</summary>
Motivation: LVLMs虽然能准确识别图像中的关键对象，但它们对这些对象的注意力往往非常短暂。研究者假设，对关键对象持续的关注可以显著提升LVLMs的视觉能力。

Method: 本文提出了跨层视觉平滑（CLVS）方法。其核心思想是引入一个视觉记忆，用于平滑跨层级的注意力分布。具体来说，该视觉记忆在第一层用位置无偏的视觉注意力进行初始化。在后续层中，模型的视觉注意力会联合考虑前一层的视觉记忆，同时记忆也会迭代更新，从而在关键对象上保持平滑的注意力。鉴于视觉理解主要发生在模型的早期和中期层，该方法使用不确定性作为视觉理解完成的指标，并据此终止平滑过程。

Result: 在三个LVLM上的四个基准测试中，CLVS证明了其有效性和泛化性。该方法在多种视觉理解任务上取得了最先进的性能，尤其在关系和属性理解方面有显著提升。

Conclusion: CLVS通过在LVLMs中引入跨层视觉平滑机制，有效解决了模型对关键对象注意力短暂的问题，显著提升了LVLMs的视觉理解能力，尤其在关系和属性理解方面表现突出，并具有良好的泛化性。

Abstract: Large Vision-Language Models (LVLMs) can accurately locate key objects in
images, yet their attention to these objects tends to be very brief. Motivated
by the hypothesis that sustained focus on key objects can improve LVLMs' visual
capabilities, we propose Cross-Layer Vision Smoothing (CLVS). The core idea of
CLVS is to incorporate a vision memory that smooths the attention distribution
across layers. Specifically, we initialize this vision memory with
position-unbiased visual attention in the first layer. In subsequent layers,
the model's visual attention jointly considers the vision memory from previous
layers, while the memory is updated iteratively, thereby maintaining smooth
attention on key objects. Given that visual understanding primarily occurs in
the early and middle layers of the model, we use uncertainty as an indicator of
completed visual understanding and terminate the smoothing process accordingly.
Experiments on four benchmarks across three LVLMs confirm the effectiveness and
generalizability of our method. CLVS achieves state-of-the-art performance on a
variety of visual understanding tasks, with particularly significant
improvements in relation and attribute understanding.

</details>


### [103] [Modeling the Multivariate Relationship with Contextualized Representations for Effective Human-Object Interaction Detection](https://arxiv.org/abs/2509.12784)
*Zhehao Li,Yucheng Qian,Chong Wang,Yinghao Lu,Zhihao Yang,Jiafei Wu*

Main category: cs.CV

TL;DR: 本文提出了一种情境化表示学习网络，通过结合辅助对象的功能角色（可供性）推理和上下文提示，增强了人-物交互（HOI）检测，特别是在复杂和依赖工具的交互场景中。


<details>
  <summary>Details</summary>
Motivation: 现有的两阶段HOI检测方法在上下文建模方面存在不足，难以捕捉复杂的人-物交互。

Method: 该方法引入了一个情境化表示学习网络：1) 将HOI检测扩展到包含辅助实体（如工具）的多元关系，通过三元组<人, 工具, 物体>显式建模工具的功能角色（可供性）。2) 使用实例类别丰富可学习提示，并通过注意力机制将其与上下文视觉特征集成，以在全局和局部层面对齐语言和图像内容。

Result: 所提出的方法在HICO-Det和V-COCO数据集的大多数场景中都表现出卓越的性能。

Conclusion: 情境化表示为模型提供了丰富的关系线索，从而能够更可靠地推断复杂、依赖上下文的交互，显著提升了HOI检测能力。

Abstract: Human-Object Interaction (HOI) detection aims to simultaneously localize
human-object pairs and recognize their interactions. While recent two-stage
approaches have made significant progress, they still face challenges due to
incomplete context modeling. In this work, we introduce a Contextualized
Representation Learning Network that integrates both affordance-guided
reasoning and contextual prompts with visual cues to better capture complex
interactions. We enhance the conventional HOI detection framework by expanding
it beyond simple human-object pairs to include multivariate relationships
involving auxiliary entities like tools. Specifically, we explicitly model the
functional role (affordance) of these auxiliary objects through triplet
structures <human, tool, object>. This enables our model to identify
tool-dependent interactions such as 'filling'. Furthermore, the learnable
prompt is enriched with instance categories and subsequently integrated with
contextual visual features using an attention mechanism. This process aligns
language with image content at both global and regional levels. These
contextualized representations equip the model with enriched relational cues
for more reliable reasoning over complex, context-dependent interactions. Our
proposed method demonstrates superior performance on both the HICO-Det and
V-COCO datasets in most scenarios. Codes will be released upon acceptance.

</details>


### [104] [Dual-Stage Reweighted MoE for Long-Tailed Egocentric Mistake Detection](https://arxiv.org/abs/2509.12990)
*Boyu Han,Qianqian Xu,Shilong Bao,Zhiyong Yang,Sicong Li,Qingming Huang*

Main category: cs.CV

TL;DR: 本报告提出了一种双阶段重加权专家混合（DR-MoE）框架，用于从自我中心视频数据中识别用户是否错误执行动作，尤其擅长检测细微和罕见的错误。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于需要从自我中心视频数据中判断用户是否错误执行动作，并应对细微且不频繁的错误所带来的挑战。

Method: 该方法提出DR-MoE框架。第一阶段，使用冻结的ViViT模型和LoRA微调的ViViT模型提取特征，并通过特征级专家模块进行组合。第二阶段，训练三个具有不同目标的分类器：使用重加权交叉熵解决类别不平衡、使用AUC损失改进倾斜分布下的排名，以及使用带有锐度感知最小化的标签感知损失增强校准和泛化能力。最后，通过分类级专家模块融合它们的预测。

Result: 所提出的方法取得了强大的性能，尤其在识别罕见和模糊的错误实例方面表现出色。

Conclusion: DR-MoE框架能有效处理自我中心视频中检测细微和不频繁错误动作的挑战，并取得了优异的性能。

Abstract: In this report, we address the problem of determining whether a user performs
an action incorrectly from egocentric video data. To handle the challenges
posed by subtle and infrequent mistakes, we propose a Dual-Stage Reweighted
Mixture-of-Experts (DR-MoE) framework. In the first stage, features are
extracted using a frozen ViViT model and a LoRA-tuned ViViT model, which are
combined through a feature-level expert module. In the second stage, three
classifiers are trained with different objectives: reweighted cross-entropy to
mitigate class imbalance, AUC loss to improve ranking under skewed
distributions, and label-aware loss with sharpness-aware minimization to
enhance calibration and generalization. Their predictions are fused using a
classification-level expert module. The proposed method achieves strong
performance, particularly in identifying rare and ambiguous mistake instances.
The code is available at https://github.com/boyuh/DR-MoE.

</details>


### [105] [Double Helix Diffusion for Cross-Domain Anomaly Image Generation](https://arxiv.org/abs/2509.12787)
*Linchun Wu,Qin Zou,Xianbiao Qi,Bo Du,Zhongyuan Wang,Qingquan Li*

Main category: cs.CV

TL;DR: DH-Diff是一种新颖的跨域生成框架，受双螺旋启发，能同时合成高保真异常图像及其像素级注释掩码，解决了现有方法中结构不一致和特征纠缠的问题，显著提升了下游异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 在制造业中，视觉异常检测因缺乏真实的异常样本来训练鲁棒的检测器而受阻。合成数据生成是数据增强的有效策略，但现有方法存在两个主要限制：1) 生成的异常与正常背景在结构上不一致；2) 合成图像与其注释掩码之间存在不希望的特征纠缠，损害了输出的感知真实性。

Method: 本文提出了Double Helix Diffusion (DH-Diff)，一个新颖的跨域生成框架。其架构灵感来源于双螺旋，通过特征分离、连接和合并的独特模块循环。具体而言，它采用域解耦注意力机制独立增强图像和注释特征以减轻特征纠缠，并通过语义分数图对齐模块连贯地整合异常前景以确保结构真实性。DH-Diff还支持通过文本提示和可选图形指导进行灵活控制。

Result: DH-Diff在多样性和真实性方面显著优于现有最先进的方法，并在下游异常检测性能方面带来了显著改进。

Conclusion: DH-Diff成功解决了合成异常数据生成中的结构不一致和特征纠缠问题，能够同时合成高保真异常图像和精确的像素级注释掩码，从而有效提升了异常检测的性能。

Abstract: Visual anomaly inspection is critical in manufacturing, yet hampered by the
scarcity of real anomaly samples for training robust detectors. Synthetic data
generation presents a viable strategy for data augmentation; however, current
methods remain constrained by two principal limitations: 1) the generation of
anomalies that are structurally inconsistent with the normal background, and 2)
the presence of undesirable feature entanglement between synthesized images and
their corresponding annotation masks, which undermines the perceptual realism
of the output. This paper introduces Double Helix Diffusion (DH-Diff), a novel
cross-domain generative framework designed to simultaneously synthesize
high-fidelity anomaly images and their pixel-level annotation masks, explicitly
addressing these challenges. DH-Diff employs a unique architecture inspired by
a double helix, cycling through distinct modules for feature separation,
connection, and merging. Specifically, a domain-decoupled attention mechanism
mitigates feature entanglement by enhancing image and annotation features
independently, and meanwhile a semantic score map alignment module ensures
structural authenticity by coherently integrating anomaly foregrounds. DH-Diff
offers flexible control via text prompts and optional graphical guidance.
Extensive experiments demonstrate that DH-Diff significantly outperforms
state-of-the-art methods in diversity and authenticity, leading to significant
improvements in downstream anomaly detection performance.

</details>


### [106] [Perception Before Reasoning: Two-Stage Reinforcement Learning for Visual Reasoning in Vision-Language Models](https://arxiv.org/abs/2509.13031)
*Yan Chen,Long Li,Teng Xi,Long Zeng,Jingdong Wang*

Main category: cs.CV

TL;DR: 本文提出了一种两阶段强化学习框架，旨在联合提升视觉-语言模型（VLM）的感知和推理能力，以克服直接将LLM的RL方法应用于VLM的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习（RL）在提升大型语言模型（LLM）的推理能力方面表现出色，但直接将这些技术应用于视觉-语言模型（VLM）是次优的。VLM面临的任务更为复杂，需要首先准确感知和理解视觉输入，然后才能有效进行推理。

Method: 研究者提出了一种两阶段强化学习框架。首先进行数据集级别的采样，以利用不同的数据源选择性地强化特定能力，从而缓解RL训练中常见的“优势消失”问题。训练的第一阶段侧重于通过粗粒度和细粒度视觉理解来提高模型的视觉感知能力，而第二阶段则旨在增强推理能力。

Result: 通过所提出的两阶段强化学习过程，获得了PeBR-R1模型，该模型显著增强了感知和推理能力。在七个基准数据集上的实验结果表明，该方法有效，并且PeBR-R1在各种视觉推理任务中表现出卓越的性能。

Conclusion: 所提出的两阶段强化学习框架能够有效地联合提升视觉-语言模型的感知和推理能力，解决了VLM在处理复杂任务时对视觉理解的内在需求，并取得了显著的性能提升。

Abstract: Reinforcement learning (RL) has proven highly effective in eliciting the
reasoning capabilities of large language models (LLMs). Inspired by this
success, recent studies have explored applying similar techniques to
vision-language models (VLMs), aiming to enhance their reasoning performance.
However, directly transplanting RL methods from LLMs to VLMs is suboptimal, as
the tasks faced by VLMs are inherently more complex. Specifically, VLMs must
first accurately perceive and understand visual inputs before reasoning can be
effectively performed. To address this challenge, we propose a two-stage
reinforcement learning framework designed to jointly enhance both the
perceptual and reasoning capabilities of VLMs. To mitigate the vanishing
advantage issue commonly observed in RL training, we first perform
dataset-level sampling to selectively strengthen specific capabilities using
distinct data sources. During training, the first stage focuses on improving
the model's visual perception through coarse- and fine-grained visual
understanding, while the second stage targets the enhancement of reasoning
abilities. After the proposed two-stage reinforcement learning process, we
obtain PeBR-R1, a vision-language model with significantly enhanced perceptual
and reasoning capabilities. Experimental results on seven benchmark datasets
demonstrate the effectiveness of our approach and validate the superior
performance of PeBR-R1 across diverse visual reasoning tasks.

</details>


### [107] [Superpixel Anything: A general object-based framework for accurate yet regular superpixel segmentation](https://arxiv.org/abs/2509.12791)
*Julien Walther,Rémi Giraud,Michaël Clément*

Main category: cs.CV

TL;DR: SPAM (SuperPixel Anything Model) 是一个多功能框架，旨在生成准确且规则的超像素。它结合了深度学习特征提取和大规模预训练模型的语义无关分割，以确保超像素与对象掩码对齐，并在分割任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统超像素方法依赖低级特征，而深度学习方法虽然利用高级特征，但常牺牲超像素的规则性以捕获复杂对象，导致分割准确但可解释性差。因此，需要一种既能保持超像素规则性又能实现准确分割的方法。

Method: SPAM框架训练一个模型来提取图像特征以生成超像素。在推理阶段，它利用一个大规模预训练模型进行语义无关分割，以确保生成的超像素与对象掩码对齐。该方法能够处理任何先验的高级分割，解决不确定区域，并支持交互式地关注特定对象。

Result: 实验结果表明，SPAM在分割任务上无论从定性还是定量角度都优于目前最先进的方法。

Conclusion: SPAM是一个有价值且鲁棒的工具，适用于各种计算机视觉应用。

Abstract: Superpixels are widely used in computer vision to simplify image
representation and reduce computational complexity. While traditional methods
rely on low-level features, deep learning-based approaches leverage high-level
features but also tend to sacrifice regularity of superpixels to capture
complex objects, leading to accurate but less interpretable segmentations. In
this work, we introduce SPAM (SuperPixel Anything Model), a versatile framework
for segmenting images into accurate yet regular superpixels. We train a model
to extract image features for superpixel generation, and at inference, we
leverage a large-scale pretrained model for semantic-agnostic segmentation to
ensure that superpixels align with object masks. SPAM can handle any prior
high-level segmentation, resolving uncertainty regions, and is able to
interactively focus on specific objects. Comprehensive experiments demonstrate
that SPAM qualitatively and quantitatively outperforms state-of-the-art methods
on segmentation tasks, making it a valuable and robust tool for various
applications. Code and pre-trained models are available here:
https://github.com/waldo-j/spam.

</details>


### [108] [TFANet: Three-Stage Image-Text Feature Alignment Network for Robust Referring Image Segmentation](https://arxiv.org/abs/2509.13070)
*Qianqi Lu,Yuxiang Xie,Jing Zhang,Shiwei Zou,Yan Chen,Xidao Luan*

Main category: cs.CV

TL;DR: 本文提出TFANet，一个三阶段图像-文本特征对齐网络，通过多尺度注意力、跨模态特征扫描和词级语义深化模块，系统性地增强多模态对齐，以解决参照图像分割中多模态错位和语言语义损失问题，尤其是在复杂场景下。


<details>
  <summary>Details</summary>
Motivation: 现有参照图像分割（RIS）方法在多模态错位和语言语义损失方面存在困难，尤其是在包含多个视觉相似对象的复杂场景中，导致目标定位错误或分割不完整。

Method: 本文提出了TFANet，一个三阶段图像-文本特征对齐网络：
1.  **知识增强阶段 (KPS)**：设计了多尺度线性交叉注意力模块 (MLAM)，促进视觉特征与文本表征在多尺度上的双向语义交换。
2.  **知识融合阶段 (KFS)**：通过跨模态特征扫描模块 (CFSM) 进一步强化特征对齐，进行多模态选择性扫描以捕获长距离依赖并构建统一的多模态表示。
3.  **知识深化阶段 (KIS)**：提出了词级语言特征引导语义深化模块 (WFDM)，以弥补早期阶段可能引入的语义退化。

Result: TFANet旨在通过分层框架系统地增强多模态对齐，解决参照图像分割中多模态错位和语言语义损失问题，特别是在复杂场景中提高对目标对象的定位和分割精度。

Conclusion: 本文提出TFANet，一个系统性的三阶段图像-文本特征对齐网络，通过创新的模块设计，旨在解决参照图像分割任务中存在的跨模态错位和语言语义损失问题，特别是在复杂场景下提升分割性能。

Abstract: Referring Image Segmentation (RIS) is a task that segments image regions
based on language expressions, requiring fine-grained alignment between two
modalities. However, existing methods often struggle with multimodal
misalignment and language semantic loss, especially in complex scenes
containing multiple visually similar objects, where uniquely described targets
are frequently mislocalized or incompletely segmented. To tackle these
challenges, this paper proposes TFANet, a Three-stage Image-Text Feature
Alignment Network that systematically enhances multimodal alignment through a
hierarchical framework comprising three stages: Knowledge Plus Stage (KPS),
Knowledge Fusion Stage (KFS), and Knowledge Intensification Stage (KIS). In the
first stage, we design the Multiscale Linear Cross-Attention Module (MLAM),
which facilitates bidirectional semantic exchange between visual features and
textual representations across multiple scales. This establishes rich and
efficient alignment between image regions and different granularities of
linguistic descriptions. Subsequently, the KFS further strengthens feature
alignment through the Cross-modal Feature Scanning Module (CFSM), which applies
multimodal selective scanning to capture long-range dependencies and construct
a unified multimodal representation. This is essential for modeling long-range
cross-modal dependencies and enhancing alignment accuracy in complex scenes.
Finally, in the KIS, we propose the Word-level Linguistic Feature-guided
Semantic Deepening Module (WFDM) to compensate for semantic degradation
introduced in earlier stages.

</details>


### [109] [Hunyuan3D Studio: End-to-End AI Pipeline for Game-Ready 3D Asset Generation](https://arxiv.org/abs/2509.12815)
*Biwen Lei,Yang Li,Xinhai Liu,Shuhui Yang,Lixin Xu,Jingwei Huang,Ruining Tang,Haohan Weng,Jian Liu,Jing Xu,Zhen Zhou,Yiling Zhu,Jiankai Xing,Jiachen Xu,Changfeng Ma,Xinhao Yan,Yunhan Yang,Chunshi Wang,Duoteng Xu,Xueqi Ma,Yuguang Chen,Jing Li,Mingxin Yang,Sheng Zhang,Yifei Feng,Xin Huang,Di Luo,Zebin He,Puhua Jiang,Changrong Hu,Zihan Qin,Shiwei Miao,Haolin Liu,Yunfei Zhao,Zeqiang Lai,Qingxiang Lin,Zibo Zhao,Kunhong Li,Xianghui Yang,Huiwen Shi,Xin Yang,Yuxuan Wang,Zebin Yao,Yihang Lian,Sicong Liu,Xintong Han,Wangchen Qin,Caisheng Ouyang,Jianyin Liu,Tianwen Yuan,Shuai Jiang,Hong Duan,Yanqi Niu,Wencong Lin,Yifu Sun,Shirui Huang,Lin Niu,Gu Gong,Guojian Xiao,Bojian Zheng,Xiang Yuan,Qi Chen,Jie Xiao,Dongyang Zheng,Xiaofeng Yang,Kai Liu,Jianchen Zhu,Lifu Wang,Qinglin Lu,Jie Liu,Liang Dong,Fan Jiang,Ruibin Chen,Lei Wang,Chao Zhang,Jiaxin Lin,Hao Zhang,Zheng Ye,Peng He,Runzhou Wu,Yinhe Wu,Jiayao Du,Jupeng Chen,Xinyue Mao,Dongyuan Guo,Yixuan Tang,Yulin Tsai,Yonghao Tan,Jiaao Yu,Junlin Yu,Keren Zhang,Yifan Li,Peng Chen,Tian Liu,Di Wang,Yuhong Liu,Linus,Jie Jiang,Zhuo Chen,Chunchao Guo*

Main category: cs.CV

TL;DR: 本文提出了Hunyuan3D Studio，一个端到端的人工智能内容创作平台，旨在通过自动化和简化游戏级3D资产的生成，彻底改变游戏制作流程。


<details>
  <summary>Details</summary>
Motivation: 现代游戏开发中高质量3D资产的创建工作量大且专业性强，导致流程耗时耗力。

Method: Hunyuan3D Studio整合了一套先进的神经网络模块（如部件级3D生成、多边形生成、语义UV等），形成一个统一且用户友好的系统。该平台能将单一概念图像或文本描述快速转换为具备优化几何结构和高保真PBR纹理的生产级3D模型。

Result: Hunyuan3D Studio生成的资产不仅视觉效果引人注目，还符合当代游戏引擎严格的技术要求，显著减少了迭代时间，并降低了3D内容创作的门槛。

Conclusion: Hunyuan3D Studio在创意意图与技术资产之间建立了无缝桥梁，代表着游戏开发和互动媒体中AI辅助工作流程的重大飞跃。

Abstract: The creation of high-quality 3D assets, a cornerstone of modern game
development, has long been characterized by labor-intensive and specialized
workflows. This paper presents Hunyuan3D Studio, an end-to-end AI-powered
content creation platform designed to revolutionize the game production
pipeline by automating and streamlining the generation of game-ready 3D assets.
At its core, Hunyuan3D Studio integrates a suite of advanced neural modules
(such as Part-level 3D Generation, Polygon Generation, Semantic UV, etc.) into
a cohesive and user-friendly system. This unified framework allows for the
rapid transformation of a single concept image or textual description into a
fully-realized, production-quality 3D model complete with optimized geometry
and high-fidelity PBR textures. We demonstrate that assets generated by
Hunyuan3D Studio are not only visually compelling but also adhere to the
stringent technical requirements of contemporary game engines, significantly
reducing iteration time and lowering the barrier to entry for 3D content
creation. By providing a seamless bridge from creative intent to technical
asset, Hunyuan3D Studio represents a significant leap forward for AI-assisted
workflows in game development and interactive media.

</details>


### [110] [Hierarchical Deep Fusion Framework for Multi-dimensional Facial Forgery Detection -- The 2024 Global Deepfake Image Detection Challenge](https://arxiv.org/abs/2509.13107)
*Kohou Wang,Huan Hu,Xiang Liu,Zezhou Chen,Ping Chen,Zhaoxiang Liu,Shiguo Lian*

Main category: cs.CV

TL;DR: 本文提出分层深度融合框架（HDFF），一个基于集成学习的深度学习架构，用于高性能面部伪造检测。


<details>
  <summary>Details</summary>
Motivation: 复杂的深度伪造技术对数字安全和真实性构成重大挑战，需要鲁棒和通用的模型来检测各种操纵技术。

Method: HDFF框架整合了四种不同的预训练子模型（Swin-MLP、CoAtNet、EfficientNetV2和DaViT），这些模型通过多阶段过程在MultiFFDI数据集上进行了精细调整。通过连接这些专用模型的特征表示并训练一个最终的分类器层，HDFF有效利用了它们的集体优势。

Result: 该方法在比赛的私人排行榜上取得了0.96852的最终分数，在184支队伍中排名第20位。

Conclusion: 研究结果证明了分层融合在复杂图像分类任务（特别是面部伪造检测）中的有效性。

Abstract: The proliferation of sophisticated deepfake technology poses significant
challenges to digital security and authenticity. Detecting these forgeries,
especially across a wide spectrum of manipulation techniques, requires robust
and generalized models. This paper introduces the Hierarchical Deep Fusion
Framework (HDFF), an ensemble-based deep learning architecture designed for
high-performance facial forgery detection. Our framework integrates four
diverse pre-trained sub-models, Swin-MLP, CoAtNet, EfficientNetV2, and DaViT,
which are meticulously fine-tuned through a multi-stage process on the
MultiFFDI dataset. By concatenating the feature representations from these
specialized models and training a final classifier layer, HDFF effectively
leverages their collective strengths. This approach achieved a final score of
0.96852 on the competition's private leaderboard, securing the 20th position
out of 184 teams, demonstrating the efficacy of hierarchical fusion for complex
image classification tasks.

</details>


### [111] [SAGA: Selective Adaptive Gating for Efficient and Expressive Linear Attention](https://arxiv.org/abs/2509.12817)
*Yuan Cao,Dong Wang*

Main category: cs.CV

TL;DR: Transformer的二次复杂度是瓶颈。线性注意力是替代方案，但现有方法存在特征冗余和低秩问题。SAGA通过引入输入自适应门控来选择性聚合信息，解决了这些问题，显著提高了效率和性能。


<details>
  <summary>Details</summary>
Motivation: Transformer在视觉任务中表现出色，但其softmax注意力机制的二次复杂度在高分辨率图像处理中成为主要瓶颈。虽然线性注意力能将复杂度降至线性，但现有方法通常统一压缩历史KV信息，导致特征冗余、失去与Q的方向对齐，并产生低秩KV特征图，从而与softmax注意力存在性能差距。

Method: 本文提出了SAGA（Selective Adaptive Gating for Efficient and Expressive Linear Attention）。SAGA引入了输入自适应的可学习门控机制，用于选择性地调节信息聚合到KV特征图中，以增强语义多样性并缓解传统线性注意力固有的低秩约束。此外，SAGA还提出了一种高效的Hadamard积分解方法来计算门控，且不引入额外的内存开销。

Result: 实验结果表明，在1280x1280分辨率下，SAGA相比PVT-T吞吐量提升了1.76倍，峰值GPU内存减少了2.69倍。在ImageNet数据集上，其top-1准确率提升高达4.4%。

Conclusion: SAGA通过引入选择性自适应门控机制，有效解决了传统线性注意力中存在的特征冗余和低秩问题，在显著提升计算效率的同时，也大幅提高了模型在图像分类任务上的性能。

Abstract: While Transformer architecture excel at modeling long-range dependencies
contributing to its widespread adoption in vision tasks the quadratic
complexity of softmax-based attention mechanisms imposes a major bottleneck,
particularly when processing high-resolution images. Linear attention presents
a promising alternative by reformulating the attention computation from $(QK)V$
to $Q(KV)$, thereby reducing the complexity from $\mathcal{O}(N^2)$ to
$\mathcal{O}(N)$ while preserving the global receptive field. However, most
existing methods compress historical key-value (KV) information uniformly,
which can lead to feature redundancy and the loss of directional alignment with
the query (Q). This uniform compression results in low-rank $KV$ feature maps,
contributing to a performance gap compared to softmax attention. To mitigate
this limitation, we propose \textbf{S}elective \textbf{A}daptive
\textbf{GA}ting for Efficient and Expressive Linear Attention (SAGA) , which
introduces input-adaptive learnable gates to selectively modulate information
aggregation into the $KV$ feature map. These gates enhance semantic diversity
and alleviate the low-rank constraint inherent in conventional linear
attention. Additionally, we propose an efficient Hadamard-product decomposition
method for gate computation, which introduces no additional memory overhead.
Experiments demonstrate that SAGA achieves a 1.76$\times$ improvement in
throughput and a 2.69$\times$ reduction in peak GPU memory compared to PVT-T at
a resolution of $1280 \times 1280$. Moreover, it improves top-1 accuracy by up
to 4.4\% on the ImageNet dataset, demonstrating both computational efficiency
and model effectiveness.

</details>


### [112] [Curriculum Multi-Task Self-Supervision Improves Lightweight Architectures for Onboard Satellite Hyperspectral Image Segmentation](https://arxiv.org/abs/2509.13229)
*Hugo Carlesso,Josiane Mothe,Radu Tudor Ionescu*

Main category: cs.CV

TL;DR: 本文提出了一种名为CMTSSL的新型课程多任务自监督学习框架，专为轻量级高光谱图像（HSI）模型设计，旨在解决星载处理中高维数据传输效率低的问题，并在下游分割任务中取得了显著效果，同时保持模型极轻量化。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像数据维度高，卫星系统数据传输速率慢，需要紧凑高效的模型支持星载处理，以最小化冗余或低价值数据的传输，例如云覆盖区域。现有的方法可能不适合轻量级架构或无法同时有效处理空间和光谱推理。

Method: CMTSSL框架集成了掩码图像建模（MIM）与解耦的空间和光谱拼图（jigsaw puzzle）求解。该框架由课程学习策略指导，逐步增加自监督期间的数据复杂性，使编码器能够共同捕捉精细的光谱连续性、空间结构和全局语义特征。与之前的双任务自监督学习方法不同，CMTSSL在一个统一且计算高效的设计中同时解决了空间和光谱推理问题。

Result: 该方法在四个公开基准数据集上进行了验证，在下游分割任务中显示出持续的性能提升。所使用的架构比一些最先进的模型轻了超过16,000倍。这些结果突出了CMTSSL在轻量级架构下进行可泛化表示学习在实际高光谱图像应用中的潜力。

Conclusion: CMTSSL为高光谱图像分析提供了一种新颖且高效的自监督学习范式，特别适用于星载部署的轻量级模型。它通过结合多任务自监督和课程学习，成功地使模型能够学习到丰富的空间和光谱特征，同时显著降低了计算和存储需求，为实时高光谱数据处理开辟了道路。

Abstract: Hyperspectral imaging (HSI) captures detailed spectral signatures across
hundreds of contiguous bands per pixel, being indispensable for remote sensing
applications such as land-cover classification, change detection, and
environmental monitoring. Due to the high dimensionality of HSI data and the
slow rate of data transfer in satellite-based systems, compact and efficient
models are required to support onboard processing and minimize the transmission
of redundant or low-value data, e.g. cloud-covered areas. To this end, we
introduce a novel curriculum multi-task self-supervised learning (CMTSSL)
framework designed for lightweight architectures for HSI analysis. CMTSSL
integrates masked image modeling with decoupled spatial and spectral jigsaw
puzzle solving, guided by a curriculum learning strategy that progressively
increases data complexity during self-supervision. This enables the encoder to
jointly capture fine-grained spectral continuity, spatial structure, and global
semantic features. Unlike prior dual-task SSL methods, CMTSSL simultaneously
addresses spatial and spectral reasoning within a unified and computationally
efficient design, being particularly suitable for training lightweight models
for onboard satellite deployment. We validate our approach on four public
benchmark datasets, demonstrating consistent gains in downstream segmentation
tasks, using architectures that are over 16,000x lighter than some
state-of-the-art models. These results highlight the potential of CMTSSL in
generalizable representation learning with lightweight architectures for
real-world HSI applications. Our code is publicly available at
https://github.com/hugocarlesso/CMTSSL.

</details>


### [113] [Exploring Metric Fusion for Evaluation of NeRFs](https://arxiv.org/abs/2509.12836)
*Shreyas Shivakumara,Gabriel Eilertsen,Karljohan Lundin Palmerius*

Main category: cs.CV

TL;DR: 本文提出了一种结合DISTS和VMAF的融合度量方法，以克服单个度量在评估NeRF生成视图时的局限性，并实现了与主观质量评分更好的相关性。


<details>
  <summary>Details</summary>
Motivation: 神经辐射场（NeRFs）在合成新视角方面潜力巨大，但评估其输出具有挑战性，因为NeRFs会产生独特的伪影，且现有单个度量在所有数据集上表现不佳。研究者假设结合不同感知方法的度量可以克服这些限制。

Method: 结合了深度图像结构和纹理相似度（DISTS）与视频多方法评估融合（VMAF）这两种成功的度量。实验了两种个体度量的归一化策略和两种融合策略，以评估它们对与主观评分相关性的影响。提出的流程在Synthetic和Outdoor两个数据集上进行了测试。

Result: 通过详细分析融合方法和个体度量与主观评分的相关系数，证明了融合度量的鲁棒性和泛化能力。实验结果显示，融合度量能克服个体度量的局限性，并实现了改进的与主观质量评分的相关性。

Conclusion: 结合DISTS和VMAF的融合度量方法在评估NeRF生成输出时表现出更强的鲁棒性和泛化能力，并能更准确地反映主观质量，从而克服了单个度量的局限性。

Abstract: Neural Radiance Fields (NeRFs) have demonstrated significant potential in
synthesizing novel viewpoints. Evaluating the NeRF-generated outputs, however,
remains a challenge due to the unique artifacts they exhibit, and no individual
metric performs well across all datasets. We hypothesize that combining two
successful metrics, Deep Image Structure and Texture Similarity (DISTS) and
Video Multi-Method Assessment Fusion (VMAF), based on different perceptual
methods, can overcome the limitations of individual metrics and achieve
improved correlation with subjective quality scores. We experiment with two
normalization strategies for the individual metrics and two fusion strategies
to evaluate their impact on the resulting correlation with the subjective
scores. The proposed pipeline is tested on two distinct datasets, Synthetic and
Outdoor, and its performance is evaluated across three different
configurations. We present a detailed analysis comparing the correlation
coefficients of fusion methods and individual scores with subjective scores to
demonstrate the robustness and generalizability of the fusion metrics.

</details>


### [114] [RadGame: An AI-Powered Platform for Radiology Education](https://arxiv.org/abs/2509.13270)
*Mohammed Baharoon,Siavash Raissi,John S. Jun,Thibault Heintz,Mahmoud Alabbad,Ali Alburkani,Sung Eun Kim,Kent Kleinschmidt,Abdulrahman O. Alhumaydhi,Mohannad Mohammed G. Alghamdi,Jeremy Francis Palacio,Mohammed Bukhaytan,Noah Michael Prudlo,Rithvik Akula,Brady Chrisler,Benjamin Galligos,Mohammed O. Almutairi,Mazeen Mohammed Alanazi,Nasser M. Alrashdi,Joel Jihwan Hwang,Sri Sai Dinesh Jaliparthi,Luke David Nelson,Nathaniel Nguyen,Sathvik Suryadevara,Steven Kim,Mohammed F. Mohammed,Yevgeniy R. Semenov,Kun-Hsing Yu,Abdulrhman Aljouie,Hassan AlOmaish,Adam Rodman,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: RadGame是一个AI驱动的放射学教育游戏化平台，旨在提高定位病灶和撰写报告的核心技能，并提供可扩展的即时反馈。


<details>
  <summary>Details</summary>
Motivation: 传统的放射学培训缺乏即时和可扩展的反馈机会，限制了学习者获得及时指导。

Method: RadGame结合了游戏化、大规模公共数据集和AI驱动的自动化反馈。它包含两个模块：RadGame Localize（玩家标注异常，AI与放射科医生标注对比并提供视觉解释）和RadGame Report（玩家撰写报告，AI根据报告生成指标提供结构化反馈，并生成表现和风格评分）。

Result: 在预期评估中，使用RadGame的参与者在定位准确性方面提高了68%（传统方法为17%），在报告撰写准确性方面提高了31%（传统方法为4%），显著优于传统被动学习方法。

Conclusion: RadGame展示了AI驱动的游戏化在提供可扩展、反馈丰富的放射学培训方面的潜力，并重新构想了医学AI资源在教育中的应用。

Abstract: We introduce RadGame, an AI-powered gamified platform for radiology education
that targets two core skills: localizing findings and generating reports.
Traditional radiology training is based on passive exposure to cases or active
practice with real-time input from supervising radiologists, limiting
opportunities for immediate and scalable feedback. RadGame addresses this gap
by combining gamification with large-scale public datasets and automated,
AI-driven feedback that provides clear, structured guidance to human learners.
In RadGame Localize, players draw bounding boxes around abnormalities, which
are automatically compared to radiologist-drawn annotations from public
datasets, and visual explanations are generated by vision-language models for
user missed findings. In RadGame Report, players compose findings given a chest
X-ray, patient age and indication, and receive structured AI feedback based on
radiology report generation metrics, highlighting errors and omissions compared
to a radiologist's written ground truth report from public datasets, producing
a final performance and style score. In a prospective evaluation, participants
using RadGame achieved a 68% improvement in localization accuracy compared to
17% with traditional passive methods and a 31% improvement in report-writing
accuracy compared to 4% with traditional methods after seeing the same cases.
RadGame highlights the potential of AI-driven gamification to deliver scalable,
feedback-rich radiology training and reimagines the application of medical AI
resources in education.

</details>


### [115] [Leveraging Large Language Models to Effectively Generate Visual Data for Canine Musculoskeletal Diagnoses](https://arxiv.org/abs/2509.12866)
*Martin Thißen,Thi Ngoc Diep Tran,Barbara Esteve Ratsch,Ben Joel Schönbein,Ute Trapp,Beate Egner,Romana Piat,Elke Hergenröther*

Main category: cs.CV

TL;DR: 本研究探讨了使用大型语言模型（LLMs）为犬类肌肉骨骼疾病诊断生成合成视觉训练数据的潜力，以解决数据稀缺问题，并展示了其在真实世界数据上的有效性。


<details>
  <summary>Details</summary>
Motivation: 人工智能模型性能通常随数据量增加而提升，但在某些任务中，由于事件罕见或成本高昂，数据收集面临挑战。本研究的应用场景——犬类肌肉骨骼状况的视觉记录——就存在这种挑战。LLMs在文本领域表现出色，有望生成合成训练数据来克服这一难题。

Method: 研究开发了一种映射机制，将犬只身体图上的视觉异常标记（彩色笔触）分割成200多个代表肌肉或关节的带标签区域，从而将其转换为LLMs可操作的文本域。利用引导解码、思维链推理和少样本提示等技术，生成了1,000份髌骨脱位（拥有最多真实数据）的合成视觉文档，并额外生成了1,000份其他诊断的视觉文档以创建二元分类数据集。

Result: 分析显示，生成的髌骨脱位文档对诊断的位置和严重程度敏感，但与犬只性别无关。一个完全由合成数据训练的模型，在70份真实世界文档上达到了88%的F1分数。

Conclusion: 研究结果表明，由LLMs生成的合成数据具有巨大潜力，尤其对于解决罕见疾病中的数据稀缺问题具有重要价值。尽管本方法针对医学领域，但其见解和技术可推广应用于其他领域。

Abstract: It is well-established that more data generally improves AI model
performance. However, data collection can be challenging for certain tasks due
to the rarity of occurrences or high costs. These challenges are evident in our
use case, where we apply AI models to a novel approach for visually documenting
the musculoskeletal condition of dogs. Here, abnormalities are marked as
colored strokes on a body map of a dog. Since these strokes correspond to
distinct muscles or joints, they can be mapped to the textual domain in which
large language models (LLMs) operate. LLMs have demonstrated impressive
capabilities across a wide range of tasks, including medical applications,
offering promising potential for generating synthetic training data. In this
work, we investigate whether LLMs can effectively generate synthetic visual
training data for canine musculoskeletal diagnoses. For this, we developed a
mapping that segments visual documentations into over 200 labeled regions
representing muscles or joints. Using techniques like guided decoding,
chain-of-thought reasoning, and few-shot prompting, we generated 1,000
synthetic visual documentations for patellar luxation (kneecap dislocation)
diagnosis, the diagnosis for which we have the most real-world data. Our
analysis shows that the generated documentations are sensitive to location and
severity of the diagnosis while remaining independent of the dog's sex. We
further generated 1,000 visual documentations for various other diagnoses to
create a binary classification dataset. A model trained solely on this
synthetic data achieved an F1 score of 88% on 70 real-world documentations.
These results demonstrate the potential of LLM-generated synthetic data, which
is particularly valuable for addressing data scarcity in rare diseases. While
our methodology is tailored to the medical domain, the insights and techniques
can be adapted to other fields.

</details>


### [116] [Cumulative Consensus Score: Label-Free and Model-Agnostic Evaluation of Object Detectors in Deployment](https://arxiv.org/abs/2509.12871)
*Avinaash Manoharan,Xiangyu Yin,Domenik Helm,Chih-Hong Cheng*

Main category: cs.CV

TL;DR: 本文提出累积共识分数（CCS），这是一种无需标签的度量标准，用于在部署环境中持续监控和比较目标检测模型，通过评估空间一致性来衡量可靠性。


<details>
  <summary>Details</summary>
Motivation: 在实际部署中，由于缺乏真实标注，评估目标检测模型具有挑战性。

Method: CCS对每张图像应用测试时数据增强，收集增强视图的预测边界框，使用IoU计算重叠。最大重叠经过归一化并对所有增强对取平均，从而得到一个空间一致性度量，作为无需标注的可靠性代理。

Result: 在Open Images和KITTI数据集上的受控实验表明，CCS与F1分数、概率检测质量（PDQ）和最优校正成本（OCC）的吻合度超过90%。该方法与模型无关，适用于单阶段和两阶段检测器，并能识别性能不佳的场景。

Conclusion: CCS为目标检测器的DevOps风格监控提供了一个稳健的基础。

Abstract: Evaluating object detection models in deployment is challenging because
ground-truth annotations are rarely available. We introduce the Cumulative
Consensus Score (CCS), a label-free metric that enables continuous monitoring
and comparison of detectors in real-world settings. CCS applies test-time data
augmentation to each image, collects predicted bounding boxes across augmented
views, and computes overlaps using Intersection over Union. Maximum overlaps
are normalized and averaged across augmentation pairs, yielding a measure of
spatial consistency that serves as a proxy for reliability without annotations.
In controlled experiments on Open Images and KITTI, CCS achieved over 90%
congruence with F1-score, Probabilistic Detection Quality, and Optimal
Correction Cost. The method is model-agnostic, working across single-stage and
two-stage detectors, and operates at the case level to highlight
under-performing scenarios. Altogether, CCS provides a robust foundation for
DevOps-style monitoring of object detectors.

</details>


### [117] [Few to Big: Prototype Expansion Network via Diffusion Learner for Point Cloud Few-shot Semantic Segmentation](https://arxiv.org/abs/2509.12878)
*Qianguang Zhao,Dongli Wang,Yan Zhou,Jianxun Li,Richard Irampa*

Main category: cs.CV

TL;DR: 本文提出PENet框架，通过利用扩散模型预训练编码器和双流学习器构建大容量原型，解决了少样本3D点云语义分割中类内多样性和集合间不一致性问题，并显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于原型的少样本3D点云语义分割方法存在两个主要挑战：1) 类内多样性，即原型有限的表示能力无法覆盖类别所有变体；2) 集合间不一致性，即支持集导出的原型与查询特征空间不匹配。受扩散模型强大生成能力的启发，作者旨在利用其预训练条件编码器提供可泛化特征，以扩展原型的表示范围。

Method: 本文提出了原型扩展网络（PENet），一个从两个互补特征源构建大容量原型的框架。PENet采用双流学习器架构：保留一个传统的全监督内在学习器（IL）来提取代表性特征，同时引入一个新颖的扩散学习器（DL）来提供丰富的可泛化特征。然后，生成的双原型由原型同化模块（PAM）处理，该模块采用推拉交叉引导注意力块迭代地将原型与查询空间对齐。此外，原型校准机制（PCM）对最终的大容量原型进行正则化，以防止语义漂移。

Result: 在S3DIS和ScanNet数据集上进行的广泛实验表明，PENet在各种少样本设置下显著优于最先进的方法。

Conclusion: PENet通过结合扩散模型的预训练编码器和双流学习架构，有效解决了少样本3D点云语义分割中原型表示不足和特征空间不一致的问题，并通过原型同化和校准机制进一步增强了性能。

Abstract: Few-shot 3D point cloud semantic segmentation aims to segment novel
categories using a minimal number of annotated support samples. While existing
prototype-based methods have shown promise, they are constrained by two
critical challenges: (1) Intra-class Diversity, where a prototype's limited
representational capacity fails to cover a class's full variations, and (2)
Inter-set Inconsistency, where prototypes derived from the support set are
misaligned with the query feature space. Motivated by the powerful generative
capability of diffusion model, we re-purpose its pre-trained conditional
encoder to provide a novel source of generalizable features for expanding the
prototype's representational range. Under this setup, we introduce the
Prototype Expansion Network (PENet), a framework that constructs big-capacity
prototypes from two complementary feature sources. PENet employs a dual-stream
learner architecture: it retains a conventional fully supervised Intrinsic
Learner (IL) to distill representative features, while introducing a novel
Diffusion Learner (DL) to provide rich generalizable features. The resulting
dual prototypes are then processed by a Prototype Assimilation Module (PAM),
which adopts a novel push-pull cross-guidance attention block to iteratively
align the prototypes with the query space. Furthermore, a Prototype Calibration
Mechanism (PCM) regularizes the final big capacity prototype to prevent
semantic drift. Extensive experiments on the S3DIS and ScanNet datasets
demonstrate that PENet significantly outperforms state-of-the-art methods
across various few-shot settings.

</details>


### [118] [Lego-Edit: A General Image Editing Framework with Model-Level Bricks and MLLM Builder](https://arxiv.org/abs/2509.12883)
*Qifei Jia,Yu Liu,Yajie Chai,Xintong Yao,Qiming Lu,Yasen Zhang,Runyu Shi,Ying Huang,Guoquan Zhang*

Main category: cs.CV

TL;DR: Lego-Edit提出了一种利用多模态大语言模型（MLLM）来组织模型级编辑工具的框架，以解决现有指令式图像编辑方法在处理多样化、开放域指令时泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 指令式图像编辑因其直接的用户交互而备受关注，但实际用户指令的多样性极高，现有方法往往难以有效泛化到训练域之外的指令，限制了其实用性。

Method: Lego-Edit包含两项关键设计：1) 一个模型级工具包，由高效训练的多种模型和图像操作功能组成，支持MLLM进行细粒度的编辑动作组合；2) 一个三阶段渐进式强化学习方法，利用未标注的开放域指令反馈来训练MLLM，赋予其处理真实世界指令的泛化推理能力。

Result: 实验证明，Lego-Edit在GEdit-Bench和ImgBench上实现了最先进的性能。它对开放域指令表现出强大的推理能力，并且无需额外微调即可利用新引入的编辑工具。

Conclusion: Lego-Edit通过结合MLLM的泛化能力和模型级工具包，有效解决了指令式图像编辑在处理多样化、开放域指令时的泛化挑战，并展现出卓越的性能和灵活性。

Abstract: Instruction-based image editing has garnered significant attention due to its
direct interaction with users. However, real-world user instructions are
immensely diverse, and existing methods often fail to generalize effectively to
instructions outside their training domain, limiting their practical
application. To address this, we propose Lego-Edit, which leverages the
generalization capability of Multi-modal Large Language Model (MLLM) to
organize a suite of model-level editing tools to tackle this challenge.
Lego-Edit incorporates two key designs: (1) a model-level toolkit comprising
diverse models efficiently trained on limited data and several image
manipulation functions, enabling fine-grained composition of editing actions by
the MLLM; and (2) a three-stage progressive reinforcement learning approach
that uses feedback on unannotated, open-domain instructions to train the MLLM,
equipping it with generalized reasoning capabilities for handling real-world
instructions. Experiments demonstrate that Lego-Edit achieves state-of-the-art
performance on GEdit-Bench and ImgBench. It exhibits robust reasoning
capabilities for open-domain instructions and can utilize newly introduced
editing tools without additional fine-tuning.
  Code is available: https://github.com/xiaomi-research/lego-edit.

</details>


### [119] [MEJO: MLLM-Engaged Surgical Triplet Recognition via Inter- and Intra-Task Joint Optimization](https://arxiv.org/abs/2509.12893)
*Yiyi Zhang,Yuchen Yuan,Ying Zheng,Jialun Pei,Jinpeng Li,Zheng Li,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 本文提出了一种名为MEJO的框架，用于解决手术三元组识别中因长尾数据分布和多任务学习范式导致的跨任务和任务内优化冲突。MEJO通过S^2D学习方案解耦共享和特定任务表示（利用MLLM增强共享表示，使用任务提示建模特定表示），并通过CGL策略协调处理任务内不平衡类别的梯度，在CholecT45和CholecT50数据集上表现出优越性。


<details>
  <summary>Details</summary>
Motivation: 手术三元组识别（识别器械、动作、目标及其组合）是一个复杂的手术场景理解挑战，存在长尾数据分布问题。主流的多任务学习范式在识别三元组方面表现出潜力，但仍面临两大挑战：1) 任务通用和任务特定表示纠缠导致的跨任务优化冲突；2) 类别不平衡训练数据导致的任务内优化冲突。

Method: 本文提出了MLLM-Engaged Joint Optimization (MEJO) 框架。为解决跨任务优化冲突，引入了Shared-Specific-Disentangled (S^2D) 学习方案，将表示分解为任务共享和任务特定组件。其中，任务共享表示通过一个由多模态大语言模型 (MLLM) 驱动的概率提示池进行动态增强，以引入专家级语义线索；任务特定线索则通过涵盖时空维度的独立任务提示进行建模。为解决任务内优化冲突，开发了Coordinated Gradient Learning (CGL) 策略，该策略剖析并重新平衡来自头部和尾部类别的正负梯度，以实现更协调的学习行为。

Result: 在CholecT45和CholecT50数据集上进行的广泛实验证明了所提出框架的优越性，并验证了其在处理优化冲突方面的有效性。

Conclusion: MEJO框架通过解耦跨任务表示和协调任务内梯度，成功解决了手术三元组识别中的优化冲突，显著提升了识别性能。

Abstract: Surgical triplet recognition, which involves identifying instrument, verb,
target, and their combinations, is a complex surgical scene understanding
challenge plagued by long-tailed data distribution. The mainstream multi-task
learning paradigm benefiting from cross-task collaborative promotion has shown
promising performance in identifying triples, but two key challenges remain: 1)
inter-task optimization conflicts caused by entangling task-generic and
task-specific representations; 2) intra-task optimization conflicts due to
class-imbalanced training data. To overcome these difficulties, we propose the
MLLM-Engaged Joint Optimization (MEJO) framework that empowers both inter- and
intra-task optimization for surgical triplet recognition. For inter-task
optimization, we introduce the Shared-Specific-Disentangled (S$^2$D) learning
scheme that decomposes representations into task-shared and task-specific
components. To enhance task-shared representations, we construct a Multimodal
Large Language Model (MLLM) powered probabilistic prompt pool to dynamically
augment visual features with expert-level semantic cues. Additionally,
comprehensive task-specific cues are modeled via distinct task prompts covering
the temporal-spatial dimensions, effectively mitigating inter-task ambiguities.
To tackle intra-task optimization conflicts, we develop a Coordinated Gradient
Learning (CGL) strategy, which dissects and rebalances the positive-negative
gradients originating from head and tail classes for more coordinated learning
behaviors. Extensive experiments on the CholecT45 and CholecT50 datasets
demonstrate the superiority of our proposed framework, validating its
effectiveness in handling optimization conflicts.

</details>


### [120] [DialNav: Multi-turn Dialog Navigation with a Remote Guide](https://arxiv.org/abs/2509.12894)
*Leekyeung Han,Hyunji Min,Gyeom Hwangbo,Jonghyun Choi,Paul Hongsuck Seo*

Main category: cs.CV

TL;DR: 本文提出了DialNav，一项新颖的具身对话任务，其中导航员和远程向导通过多轮对话协作到达目标位置。该任务要求向导推断导航员的位置，并发布了RAIN数据集、基准和代码以促进研究。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏全面的评估，且在具身导航对话中，向导需要推断导航员的位置，这使得有效沟通对任务成功至关重要。

Method: 引入了DialNav协作具身对话任务，收集并发布了RAIN数据集（包含在真实感环境中人类-人类对话与导航轨迹），设计了评估导航和对话的综合基准，并进行了大量实验分析不同导航员和向导模型的影响。

Result: 实验分析了不同导航员和向导模型对任务表现的影响，并突出了该领域面临的关键挑战。

Conclusion: DialNav是一个新颖的具身对话任务，其核心在于向导需推断导航员位置。研究团队发布了RAIN数据集、代码和评估框架，旨在推动未来具身对话领域的研究。

Abstract: We introduce DialNav, a novel collaborative embodied dialog task, where a
navigation agent (Navigator) and a remote guide (Guide) engage in multi-turn
dialog to reach a goal location. Unlike prior work, DialNav aims for holistic
evaluation and requires the Guide to infer the Navigator's location, making
communication essential for task success. To support this task, we collect and
release the Remote Assistance in Navigation (RAIN) dataset, human-human dialog
paired with navigation trajectories in photorealistic environments. We design a
comprehensive benchmark to evaluate both navigation and dialog, and conduct
extensive experiments analyzing the impact of different Navigator and Guide
models. We highlight key challenges and publicly release the dataset, code, and
evaluation framework to foster future research in embodied dialog.

</details>


### [121] [MSGFusion: Multimodal Scene Graph-Guided Infrared and Visible Image Fusion](https://arxiv.org/abs/2509.12901)
*Guihui Li,Bowei Dong,Kaizhi Dong,Jiayi Li,Haiyong Zheng*

Main category: cs.CV

TL;DR: MSGFusion是一种多模态场景图引导的红外与可见光图像融合框架，通过深度耦合结构化场景图来提升融合图像的细节、结构清晰度及语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的图像融合方法在特征提取方面取得进展，但仍过度依赖低级视觉线索（如纹理和对比度），难以捕捉图像中嵌入的高级语义信息。近期结合文本作为语义指导的方法依赖非结构化描述，未能明确建模实体、属性和关系，也未提供空间定位，从而限制了细粒度融合性能。

Method: 本文提出了MSGFusion框架，通过深度耦合从文本和视觉中提取的结构化场景图，显式表示实体、属性和空间关系。然后，通过场景图表示、分层聚合和图驱动融合等模块，同步细化高级语义和低级细节。

Result: 在多个公共基准上的广泛实验表明，MSGFusion显著优于最先进的方法，特别是在细节保留和结构清晰度方面。它还在低光照目标检测、语义分割和医学图像融合等下游任务中提供了卓越的语义一致性和泛化能力。

Conclusion: 结构化场景图能够有效提升红外与可见光图像融合的性能，尤其是在保留细节、增强结构清晰度以及提供更强的语义一致性和泛化能力方面，为复杂环境下的图像融合提供了新的解决方案。

Abstract: Infrared and visible image fusion has garnered considerable attention owing
to the strong complementarity of these two modalities in complex, harsh
environments. While deep learning-based fusion methods have made remarkable
advances in feature extraction, alignment, fusion, and reconstruction, they
still depend largely on low-level visual cues, such as texture and contrast,
and struggle to capture the high-level semantic information embedded in images.
Recent attempts to incorporate text as a source of semantic guidance have
relied on unstructured descriptions that neither explicitly model entities,
attributes, and relationships nor provide spatial localization, thereby
limiting fine-grained fusion performance. To overcome these challenges, we
introduce MSGFusion, a multimodal scene graph-guided fusion framework for
infrared and visible imagery. By deeply coupling structured scene graphs
derived from text and vision, MSGFusion explicitly represents entities,
attributes, and spatial relations, and then synchronously refines high-level
semantics and low-level details through successive modules for scene graph
representation, hierarchical aggregation, and graph-driven fusion. Extensive
experiments on multiple public benchmarks show that MSGFusion significantly
outperforms state-of-the-art approaches, particularly in detail preservation
and structural clarity, and delivers superior semantic consistency and
generalizability in downstream tasks such as low-light object detection,
semantic segmentation, and medical image fusion.

</details>


### [122] [AREPAS: Anomaly Detection in Fine-Grained Anatomy with Reconstruction-Based Semantic Patch-Scoring](https://arxiv.org/abs/2509.12905)
*Branko Mitic,Philipp Seeböck,Helmut Prosch,Georg Langs*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的生成式异常检测方法，通过图像到图像翻译和块相似性评分，解决了医学图像中细粒度组织变异性带来的挑战，并在胸部CT和脑部MRI上实现了像素级异常分割的改进。


<details>
  <summary>Details</summary>
Motivation: 异常检测和无监督分割在医学领域具有广泛应用（如疾病早期检测、病变严重性评估、疾病鉴别和自动化筛查），但现有生成式异常检测方法难以处理医学图像中正常的细粒度组织变异性（例如肺部解剖结构）。

Method: 该方法是一种生成式异常检测新方法，包括两个主要步骤：首先进行图像到图像翻译以实现无异常重建；然后对观察到的图像和生成的图像对之间进行块相似性评分，以实现精确的异常定位。

Result: 该方法在胸部CT（用于感染性疾病病变检测与分割）和T1加权脑部MRI（用于缺血性卒中病变分割）上均表现出改进的像素级异常分割性能。与现有最先进的基于重建的方法相比，DICE分数分别相对提高了+1.9%和+4.4%。

Conclusion: 所提出的生成式异常检测方法能够有效应对医学图像中细粒度组织变异性的挑战，并在不同医学影像模态和任务中展现出优越的异常检测和分割性能及泛化能力。

Abstract: Early detection of newly emerging diseases, lesion severity assessment,
differentiation of medical conditions and automated screening are examples for
the wide applicability and importance of anomaly detection (AD) and
unsupervised segmentation in medicine. Normal fine-grained tissue variability
such as present in pulmonary anatomy is a major challenge for existing
generative AD methods. Here, we propose a novel generative AD approach
addressing this issue. It consists of an image-to-image translation for
anomaly-free reconstruction and a subsequent patch similarity scoring between
observed and generated image-pairs for precise anomaly localization. We
validate the new method on chest computed tomography (CT) scans for the
detection and segmentation of infectious disease lesions. To assess
generalizability, we evaluate the method on an ischemic stroke lesion
segmentation task in T1-weighted brain MRI. Results show improved pixel-level
anomaly segmentation in both chest CTs and brain MRIs, with relative DICE score
improvements of +1.9% and +4.4%, respectively, compared to other
state-of-the-art reconstruction-based methods.

</details>


### [123] [T-SiamTPN: Temporal Siamese Transformer Pyramid Networks for Robust and Efficient UAV Tracking](https://arxiv.org/abs/2509.12913)
*Hojat Ardi,Amir Jahanshahi,Ali Diba*

Main category: cs.CV

TL;DR: 本文提出T-SiamTPN，一个时间感知的Siamese跟踪框架，通过显式时间建模、特征融合和注意力机制，显著提升了空中目标跟踪的鲁棒性和精度，同时保持了计算效率，适用于嵌入式应用。


<details>
  <summary>Details</summary>
Motivation: 空中目标跟踪面临尺度变化、动态背景、杂波和频繁遮挡等挑战。现有跟踪器多侧重空间线索，忽视时间依赖性，导致长期跟踪和遮挡下鲁棒性不足。此外，基于相关性的Siamese跟踪器受限于相关操作的线性性质，难以应对复杂的非线性外观变化。

Method: 本文引入T-SiamTPN，一个时间感知的Siamese跟踪框架，通过显式时间建模扩展了SiamTPN架构。该方法整合了时间特征融合和基于注意力的交互，以增强时间一致性并实现更丰富的特征表示。

Result: T-SiamTPN在基线上取得了显著改进，性能与最先进的跟踪器相当。尽管增加了时间模块，但仍保持了计算效率，在资源受限的Jetson Nano上能以7.1 FPS实时运行。实验结果显示，T-SiamTPN相比基线，成功率提高了13.7%，精度提高了14.7%。

Conclusion: 这些发现强调了时间建模在Siamese跟踪框架中的重要性，并确立T-SiamTPN作为一种强大且高效的空中目标跟踪解决方案。

Abstract: Aerial object tracking remains a challenging task due to scale variations,
dynamic backgrounds, clutter, and frequent occlusions. While most existing
trackers emphasize spatial cues, they often overlook temporal dependencies,
resulting in limited robustness in long-term tracking and under occlusion.
Furthermore, correlation-based Siamese trackers are inherently constrained by
the linear nature of correlation operations, making them ineffective against
complex, non-linear appearance changes. To address these limitations, we
introduce T-SiamTPN, a temporal-aware Siamese tracking framework that extends
the SiamTPN architecture with explicit temporal modeling. Our approach
incorporates temporal feature fusion and attention-based interactions,
strengthening temporal consistency and enabling richer feature representations.
These enhancements yield significant improvements over the baseline and achieve
performance competitive with state-of-the-art trackers. Crucially, despite the
added temporal modules, T-SiamTPN preserves computational efficiency. Deployed
on the resource-constrained Jetson Nano, the tracker runs in real time at 7.1
FPS, demonstrating its suitability for real-world embedded applications without
notable runtime overhead. Experimental results highlight substantial gains:
compared to the baseline, T-SiamTPN improves success rate by 13.7% and
precision by 14.7%. These findings underscore the importance of temporal
modeling in Siamese tracking frameworks and establish T-SiamTPN as a strong and
efficient solution for aerial object tracking. Code is available at:
https://github.com/to/be/released

</details>


### [124] [A Novel Compression Framework for YOLOv8: Achiev-ing Real-Time Aerial Object Detection on Edge Devices via Structured Pruning and Channel-Wise Distillation](https://arxiv.org/abs/2509.12918)
*Melika Sabaghian,Mohammad Ali Keyvanrad,Seyyedeh Mahila Moghadami*

Main category: cs.CV

TL;DR: 该研究提出了一种针对YOLOv8模型的三阶段压缩流水线，结合稀疏感知训练、结构化通道剪枝和通道级知识蒸馏，显著减少了模型大小和计算量，同时保持了高精度，实现了在资源受限设备上的实时空中目标检测。


<details>
  <summary>Details</summary>
Motivation: 在资源受限设备上高效部署用于空中目标检测的深度学习模型，需要在不牺牲性能的前提下进行显著的模型压缩。

Method: 该方法包含一个新颖的三阶段压缩流水线：1. 稀疏感知训练：在模型优化过程中引入动态稀疏性，平衡参数减少和检测精度。2. 结构化通道剪枝：利用批归一化缩放因子消除冗余通道，大幅减少模型大小和计算复杂性。3. 通道级知识蒸馏（CWD）：采用可调节的温度和损失权重方案，将知识从原始模型迁移到剪枝后的模型，以缓解精度下降，特别针对小型和中型目标检测进行了优化。最后，还应用了TensorRT进行轻量级优化。

Result: 在VisDrone数据集上，对于YOLOv8m模型，该方法将模型参数从25.85M减少到6.85M（减少73.51%），FLOPs从49.6G减少到13.3G，MACs从101G减少到34.5G，而AP50仅下降2.7%。压缩后的模型实现了47.9的AP50，推理速度从26 FPS（YOLOv8m基线）提升到45 FPS。通过TensorRT优化，AP50略降至47.6，但推理速度进一步提升至68 FPS。

Conclusion: 该三阶段压缩方法在YOLOv8模型上表现出卓越的有效性，显著减少了模型规模和计算量，同时保持了高检测精度和推理速度，使其在资源受限的边缘设备上实现实时、高吞吐量的空中目标检测变得可行。

Abstract: Efficient deployment of deep learning models for aerial object detection on
resource-constrained devices requires significant compression without
com-promising performance. In this study, we propose a novel three-stage
compression pipeline for the YOLOv8 object detection model, integrating
sparsity-aware training, structured channel pruning, and Channel-Wise Knowledge
Distillation (CWD). First, sparsity-aware training introduces dynamic sparsity
during model optimization, effectively balancing parameter reduction and
detection accuracy. Second, we apply structured channel pruning by leveraging
batch normalization scaling factors to eliminate redundant channels,
significantly reducing model size and computational complexity. Finally, to
mitigate the accuracy drop caused by pruning, we employ CWD to transfer
knowledge from the original model, using an adjustable temperature and loss
weighting scheme tailored for small and medium object detection. Extensive
experiments on the VisDrone dataset demonstrate the effectiveness of our
approach across multiple YOLOv8 variants. For YOLOv8m, our method reduces model
parameters from 25.85M to 6.85M (a 73.51% reduction), FLOPs from 49.6G to
13.3G, and MACs from 101G to 34.5G, while reducing AP50 by only 2.7%. The
resulting compressed model achieves 47.9 AP50 and boosts inference speed from
26 FPS (YOLOv8m baseline) to 45 FPS, enabling real-time deployment on edge
devices. We further apply TensorRT as a lightweight optimization step. While
this introduces a minor drop in AP50 (from 47.9 to 47.6), it significantly
improves inference speed from 45 to 68 FPS, demonstrating the practicality of
our approach for high-throughput, re-source-constrained scenarios.

</details>


### [125] [MATTER: Multiscale Attention for Registration Error Regression](https://arxiv.org/abs/2509.12924)
*Shipeng Liu,Ziliang Xiong,Khac-Hoang Ngo,Per-Erik Forssén*

Main category: cs.CV

TL;DR: 本文提出了一种基于回归的点云配准质量验证方法，通过多尺度特征提取和注意力机制聚合，实现了对配准误差的精细量化和鲁棒估计，显著提升了下游建图任务的质量。


<details>
  <summary>Details</summary>
Motivation: 点云配准（PCR）对SLAM和目标跟踪等下游任务至关重要，因此检测和量化配准失准（即PCR质量验证）是一项重要任务。现有方法将验证视为分类任务，无法提供细粒度的配准质量量化。

Method: 本研究将PCR质量验证视为回归任务，以实现更细粒度的质量量化。方法扩展了现有与失准相关的特征，采用多尺度提取和基于注意力的聚合机制。

Result: 该方法在多样化数据集上，尤其是在空间密度不均匀的点云上，实现了准确且鲁棒的配准误差估计。此外，当用于指导下游建图任务时，与最先进的基于分类的方法相比，在相同数量的重新配准帧下，显著提高了建图质量。

Conclusion: 通过采用回归方法并结合多尺度特征提取和注意力聚合，本研究为点云配准质量验证提供了一种更精细、准确和鲁棒的量化方案，并能有效提升下游任务的性能。

Abstract: Point cloud registration (PCR) is crucial for many downstream tasks, such as
simultaneous localization and mapping (SLAM) and object tracking. This makes
detecting and quantifying registration misalignment, i.e.,~{\it PCR quality
validation}, an important task. All existing methods treat validation as a
classification task, aiming to assign the PCR quality to a few classes. In this
work, we instead use regression for PCR validation, allowing for a more
fine-grained quantification of the registration quality. We also extend
previously used misalignment-related features by using multiscale extraction
and attention-based aggregation. This leads to accurate and robust registration
error estimation on diverse datasets, especially for point clouds with
heterogeneous spatial densities. Furthermore, when used to guide a mapping
downstream task, our method significantly improves the mapping quality for a
given amount of re-registered frames, compared to the state-of-the-art
classification-based method.

</details>


### [126] [4DRadar-GS: Self-Supervised Dynamic Driving Scene Reconstruction with 4D Radar](https://arxiv.org/abs/2509.12931)
*Xiao Tang,Guirong Zhuo,Cong Wang,Boyuan Zheng,Minqing Huang,Lianqing Zheng,Long Chen,Shouyi Lu*

Main category: cs.CV

TL;DR: 本文提出4DRadar-GS，一个基于4D雷达增强的自监督3D重建框架，用于动态驾驶场景，通过雷达辅助的高斯初始化和速度引导的点轨迹跟踪，有效解决了动态物体重建不准确和时间一致性弱的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督3D重建方法在处理动态物体时，由于运动估计不精确和时间一致性差，导致动态场景元素重建不完整或扭曲。这限制了它们在自动驾驶系统验证和感知模型训练中的应用。

Method: 本文提出4DRadar-GS框架：1) 4D雷达辅助的高斯初始化方案，利用4D雷达的速度和空间信息分割动态物体并恢复单目深度尺度，生成精确的高斯点表示。2) 速度引导的点轨迹跟踪(VGPT)模型，在场景流监督下与重建管线联合训练，以跟踪细粒度动态轨迹并构建时间上一致的表示。

Result: 在OmniHD-Scenes数据集上进行评估，4DRadar-GS在动态驾驶场景3D重建方面取得了最先进的性能。

Conclusion: 4DRadar-GS框架通过结合4D雷达信息和改进的动态物体跟踪机制，成功克服了现有自监督3D重建方法在动态驾驶场景中面临的挑战，实现了更准确和时间一致的动态物体重建。

Abstract: 3D reconstruction and novel view synthesis are critical for validating
autonomous driving systems and training advanced perception models. Recent
self-supervised methods have gained significant attention due to their
cost-effectiveness and enhanced generalization in scenarios where annotated
bounding boxes are unavailable. However, existing approaches, which often rely
on frequency-domain decoupling or optical flow, struggle to accurately
reconstruct dynamic objects due to imprecise motion estimation and weak
temporal consistency, resulting in incomplete or distorted representations of
dynamic scene elements. To address these challenges, we propose 4DRadar-GS, a
4D Radar-augmented self-supervised 3D reconstruction framework tailored for
dynamic driving scenes. Specifically, we first present a 4D Radar-assisted
Gaussian initialization scheme that leverages 4D Radar's velocity and spatial
information to segment dynamic objects and recover monocular depth scale,
generating accurate Gaussian point representations. In addition, we propose a
Velocity-guided PointTrack (VGPT) model, which is jointly trained with the
reconstruction pipeline under scene flow supervision, to track fine-grained
dynamic trajectories and construct temporally consistent representations.
Evaluated on the OmniHD-Scenes dataset, 4DRadar-GS achieves state-of-the-art
performance in dynamic driving scene 3D reconstruction.

</details>


### [127] [Beyond Averages: Open-Vocabulary 3D Scene Understanding with Gaussian Splatting and Bag of Embeddings](https://arxiv.org/abs/2509.12938)
*Abdalla Arafa,Didier Stricker*

Main category: cs.CV

TL;DR: 该论文提出一种新范式，通过聚合预分解的对象级高斯和多视图CLIP特征来创建“嵌入包”，从而实现准确的开放词汇3D对象提取，解决了3D高斯溅射在语义理解方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 3D高斯溅射（3DGS）虽然实现了实时逼真的渲染，但其固有的模糊性阻碍了3D场景理解，限制了其在AR/VR和机器人领域的应用。现有方法通过2D基础模型蒸馏学习语义，但由于alpha混合平均了对象间的语义，无法实现3D层面的理解。

Method: 我们提出一种绕过可微分渲染进行语义理解的替代方案。核心思想是利用预分解的对象级高斯，并通过多视图CLIP特征聚合来表示每个对象，创建全面的“嵌入包”来整体描述对象。这允许：1) 通过将文本查询与对象级（而非高斯级）嵌入进行比较，实现准确的开放词汇对象检索；2) 无缝任务适应：将对象ID传播到像素进行2D分割或传播到高斯进行3D提取。

Result: 实验表明，我们的方法有效克服了3D开放词汇对象提取的挑战，同时在2D开放词汇分割方面与最先进的性能相当，确保了最小的折衷。

Conclusion: 该方法通过引入对象级特征聚合的范式，成功解决了3D高斯溅射在3D语义理解和开放词汇对象提取方面的难题，同时保持了在2D分割任务上的竞争力，为3D场景理解开辟了新的途径。

Abstract: Novel view synthesis has seen significant advancements with 3D Gaussian
Splatting (3DGS), enabling real-time photorealistic rendering. However, the
inherent fuzziness of Gaussian Splatting presents challenges for 3D scene
understanding, restricting its broader applications in AR/VR and robotics.
While recent works attempt to learn semantics via 2D foundation model
distillation, they inherit fundamental limitations: alpha blending averages
semantics across objects, making 3D-level understanding impossible. We propose
a paradigm-shifting alternative that bypasses differentiable rendering for
semantics entirely. Our key insight is to leverage predecomposed object-level
Gaussians and represent each object through multiview CLIP feature aggregation,
creating comprehensive "bags of embeddings" that holistically describe objects.
This allows: (1) accurate open-vocabulary object retrieval by comparing text
queries to object-level (not Gaussian-level) embeddings, and (2) seamless task
adaptation: propagating object IDs to pixels for 2D segmentation or to
Gaussians for 3D extraction. Experiments demonstrate that our method
effectively overcomes the challenges of 3D open-vocabulary object extraction
while remaining comparable to state-of-the-art performance in 2D
open-vocabulary segmentation, ensuring minimal compromise.

</details>


### [128] [Time-step Mixup for Efficient Spiking Knowledge Transfer from Appearance to Event Domain](https://arxiv.org/abs/2509.12959)
*Yuqi Xie,Shuhan Ye,Chong Wang,Jiazhen Xu,Le Shen,Yuanbin Qian,Jiangbo Qian*

Main category: cs.CV

TL;DR: 本文提出了一种名为时间步混合知识迁移（TMKT）的新方法，通过在不同时间步插值RGB和DVS输入，并结合模态感知辅助学习目标，解决了将语义知识从RGB数据集迁移到事件相机（DVS）数据的挑战，从而实现更平滑的知识迁移和在脉冲图像分类任务中更优异的性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机与脉冲神经网络（SNNs）的结合在能效视觉处理方面具有巨大潜力。然而，有限的事件数据、DVS输出的稀疏性以及从RGB数据集迁移语义知识时存在的显著模态分布差异，给有效的训练带来了挑战。

Method: 本文提出了时间步混合知识迁移（TMKT）方法。该方法利用SNN的异步特性，通过在不同时间步插值RGB和DVS输入，实现了一种细粒度的混合策略。为了在跨模态场景中实现标签混合，还引入了模态感知辅助学习目标，以支持时间步混合过程并增强模型在不同模态间有效区分的能力。

Result: 该方法实现了更平滑的知识迁移，缓解了训练过程中的模态偏移，并在脉冲图像分类任务中取得了卓越的性能。大量的实验证明了该方法在多个数据集上的有效性。

Conclusion: TMKT通过新颖的时间步混合策略和模态感知辅助学习目标，有效解决了事件相机和脉冲神经网络中RGB到DVS知识迁移的挑战，显著提升了脉冲图像分类任务的性能。

Abstract: The integration of event cameras and spiking neural networks holds great
promise for energy-efficient visual processing. However, the limited
availability of event data and the sparse nature of DVS outputs pose challenges
for effective training. Although some prior work has attempted to transfer
semantic knowledge from RGB datasets to DVS, they often overlook the
significant distribution gap between the two modalities. In this paper, we
propose Time-step Mixup knowledge transfer (TMKT), a novel fine-grained mixing
strategy that exploits the asynchronous nature of SNNs by interpolating RGB and
DVS inputs at various time-steps. To enable label mixing in cross-modal
scenarios, we further introduce modality-aware auxiliary learning objectives.
These objectives support the time-step mixup process and enhance the model's
ability to discriminate effectively across different modalities. Our approach
enables smoother knowledge transfer, alleviates modality shift during training,
and achieves superior performance in spiking image classification tasks.
Extensive experiments demonstrate the effectiveness of our method across
multiple datasets. The code will be released after the double-blind review
process.

</details>


### [129] [MMMS: Multi-Modal Multi-Surface Interactive Segmentation](https://arxiv.org/abs/2509.12963)
*Robin Schön,Julian Lorenz,Katja Ludwig,Daniel Kienzle,Rainer Lienhart*

Main category: cs.CV

TL;DR: 本文提出了一种基于用户点击的交互式多模态多表面图像分割方法，通过特定网络架构处理纠缠表面，并引入新的评估指标，显著提升了分割效率和性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决图像中同时存在多个可能高度纠缠和相邻表面的交互式分割难题，并探索利用多模态输入来辅助分割任务，以提高效率和准确性。

Method: 该方法的核心是一个网络架构，输入包括RGB图像、非RGB模态、错误掩码和编码点击，输出是改进的分割掩码。架构设计遵循两个条件：1) RGB主干作为黑盒；2) 为减少响应时间，交互特定信息在图像特征提取和多模态融合后集成。此外，论文还提出了一种新的扩展评估指标来应对多表面纠缠场景的挑战。该任务被称为多模态多表面交互式分割（MMMS）。

Result: 研究结果表明多模态融合策略有效，额外的模态输入使系统在DeLiVER数据集上平均每表面NoC@90减少高达1.28次点击，在MFNet上减少高达1.19次。此外，纯RGB基线在经典的单掩码交互式分割场景中表现出有竞争力，甚至在某些情况下更优的性能。

Conclusion: 本文提出的多模态多表面交互式分割方法能够有效处理复杂的多表面分割任务，通过多模态融合显著提高了分割效率，并且其RGB基线在传统场景下也表现出色。

Abstract: In this paper, we present a method to interactively create segmentation masks
on the basis of user clicks. We pay particular attention to the segmentation of
multiple surfaces that are simultaneously present in the same image. Since
these surfaces may be heavily entangled and adjacent, we also present a novel
extended evaluation metric that accounts for the challenges of this scenario.
Additionally, the presented method is able to use multi-modal inputs to
facilitate the segmentation task. At the center of this method is a network
architecture which takes as input an RGB image, a number of non-RGB modalities,
an erroneous mask, and encoded clicks. Based on this input, the network
predicts an improved segmentation mask. We design our architecture such that it
adheres to two conditions: (1) The RGB backbone is only available as a
black-box. (2) To reduce the response time, we want our model to integrate the
interaction-specific information after the image feature extraction and the
multi-modal fusion. We refer to the overall task as Multi-Modal Multi-Surface
interactive segmentation (MMMS). We are able to show the effectiveness of our
multi-modal fusion strategy. Using additional modalities, our system reduces
the NoC@90 by up to 1.28 clicks per surface on average on DeLiVER and up to
1.19 on MFNet. On top of this, we are able to show that our RGB-only baseline
achieves competitive, and in some cases even superior performance when tested
in a classical, single-mask interactive segmentation scenario.

</details>


### [130] [ICDAR 2025 Competition on FEw-Shot Text line segmentation of ancient handwritten documents (FEST)](https://arxiv.org/abs/2509.12965)
*Silvia Zottin,Axel De Nardin,Giuseppe Branca,Claudio Piciarelli,Gian Luca Foresti*

Main category: cs.CV

TL;DR: 本文介绍了一项名为FEST的比赛，旨在解决古代手写文档中文字行分割的挑战，特别是在标注数据稀缺的条件下，通过少量样本学习（few-shot learning）来开发鲁棒且适应性强的分割方法。


<details>
  <summary>Details</summary>
Motivation: 历史手写文档的文字行分割面临独特挑战，如不规则笔迹、墨迹褪色、复杂布局、行重叠和非线性文本流。此外，缺乏大型标注数据集使得全监督学习方法不切实际，因此需要少量样本学习方法。

Method: 本文提出并组织了“古代手写文档少量样本文字行分割（FEST）”竞赛。参赛者需开发系统，仅使用每份手稿三张标注图像对U-DIADS-TL数据集进行训练，以分割文字行。

Result: 竞赛数据集包含多样化的古代手稿，涵盖了广泛的布局、退化程度和非标准格式，反映了真实世界的条件。竞赛旨在促进开发出鲁棒且适应性强的方法。

Conclusion: FEST竞赛旨在推动少量样本学习方法的发展，使人文科学学者能够以最少的手动标注工作使用这些工具，从而促进自动化文档分析工具在历史研究中的广泛应用。

Abstract: Text line segmentation is a critical step in handwritten document image
analysis. Segmenting text lines in historical handwritten documents, however,
presents unique challenges due to irregular handwriting, faded ink, and complex
layouts with overlapping lines and non-linear text flow. Furthermore, the
scarcity of large annotated datasets renders fully supervised learning
approaches impractical for such materials. To address these challenges, we
introduce the Few-Shot Text Line Segmentation of Ancient Handwritten Documents
(FEST) Competition. Participants are tasked with developing systems capable of
segmenting text lines in U-DIADS-TL dataset, using only three annotated images
per manuscript for training. The competition dataset features a diverse
collection of ancient manuscripts exhibiting a wide range of layouts,
degradation levels, and non-standard formatting, closely reflecting real-world
conditions. By emphasizing few-shot learning, FEST competition aims to promote
the development of robust and adaptable methods that can be employed by
humanities scholars with minimal manual annotation effort, thus fostering
broader adoption of automated document analysis tools in historical research.

</details>


### [131] [SHREC 2025: Protein surface shape retrieval including electrostatic potential](https://arxiv.org/abs/2509.12976)
*Taher Yacoub,Camille Depenveiller,Atsushi Tatsuma,Tin Barisin,Eugen Rusakov,Udo Gobel,Yuxu Peng,Shiqiang Deng,Yuki Kagaya,Joon Hong Park,Daisuke Kihara,Marco Guerra,Giorgio Palmieri,Andrea Ranieri,Ulderico Fugacci,Silvia Biasotti,Ruiwen He,Halim Benhabiles,Adnane Cabani,Karim Hammoudi,Haotian Li,Hao Huang,Chunyan Li,Alireza Tehrani,Fanwang Meng,Farnaz Heidar-Zadeh,Tuan-Anh Yang,Matthieu Montes*

Main category: cs.CV

TL;DR: SHREC 2025蛋白质表面形状检索赛道评估了15种方法，发现结合静电势的检索方法表现最佳，尤其在数据有限的类别中。


<details>
  <summary>Details</summary>
Motivation: 旨在评估和比较不同方法在蛋白质表面形状检索任务上的性能，并探索关键分子表面描述符（如静电势）的作用。

Method: SHREC 2025赛道组织，9支团队参与，评估了15种方法。使用包含11,555个蛋白质表面及其静电势的大型数据集。通过准确率、平衡准确率、F1分数、精确率和召回率等指标评估检索性能。

Result: 结合静电势与分子表面形状的方法取得了最佳检索性能。这一优势在数据量有限的类别中也成立。

Conclusion: 静电势是蛋白质表面形状检索的关键分子表面描述符，其对检索性能的提升，尤其在数据稀缺的情况下，具有重要意义。

Abstract: This SHREC 2025 track dedicated to protein surface shape retrieval involved 9
participating teams. We evaluated the performance in retrieval of 15 proposed
methods on a large dataset of 11,555 protein surfaces with calculated
electrostatic potential (a key molecular surface descriptor). The performance
in retrieval of the proposed methods was evaluated through different metrics
(Accuracy, Balanced accuracy, F1 score, Precision and Recall). The best
retrieval performance was achieved by the proposed methods that used the
electrostatic potential complementary to molecular surface shape. This
observation was also valid for classes with limited data which highlights the
importance of taking into account additional molecular surface descriptors.

</details>


### [132] [Improving Accuracy and Efficiency of Implicit Neural Representations: Making SIREN a WINNER](https://arxiv.org/abs/2509.12980)
*Hemanth Chandravamsi,Dhanush V. Shenoy,Steven H. Frankel*

Main category: cs.CV

TL;DR: 本文解决了正弦表示网络（SIRENs）在拟合超出其频率支持的信号时出现的“频谱瓶颈”问题。我们提出了WINNER方法，通过引入自适应高斯噪声初始化权重，有效地缓解了频谱偏差，并在音频、图像和3D形状拟合任务上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: SIRENs在未适当初始化时，难以拟合超出其频率支持范围的信号。在极端情况下，当网络频率支持与目标频谱不匹配时，会出现“频谱瓶颈”现象，模型输出接近零，甚至无法恢复在其表示能力范围内的频率分量。

Method: 我们提出了WINNER（Weight Initialization with Noise for Neural Representations）方法。WINNER通过高斯噪声扰动基础SIREN的均匀初始化权重，其中噪声尺度根据目标信号的频谱质心自适应确定。这类似于随机傅里叶嵌入，但无需引入额外的可训练参数，从而缓解了“频谱偏差”。

Result: WINNER方法在音频拟合方面达到了最先进的水平，并在图像和3D形状拟合任务中相较于基础SIREN取得了显著提升。

Conclusion: WINNER成功克服了SIRENs的频谱瓶颈问题，提高了信号拟合性能。此外，WINNER为深度神经网络训练中自适应、目标感知的初始化策略开辟了新的途径。

Abstract: We identify and address a fundamental limitation of sinusoidal representation
networks (SIRENs), a class of implicit neural representations. SIRENs Sitzmann
et al. (2020), when not initialized appropriately, can struggle at fitting
signals that fall outside their frequency support. In extreme cases, when the
network's frequency support misaligns with the target spectrum, a 'spectral
bottleneck' phenomenon is observed, where the model yields to a near-zero
output and fails to recover even the frequency components that are within its
representational capacity. To overcome this, we propose WINNER - Weight
Initialization with Noise for Neural Representations. WINNER perturbs uniformly
initialized weights of base SIREN with Gaussian noise - whose noise scales are
adaptively determined by the spectral centroid of the target signal. Similar to
random Fourier embeddings, this mitigates 'spectral bias' but without
introducing additional trainable parameters. Our method achieves
state-of-the-art audio fitting and significant gains in image and 3D shape
fitting tasks over base SIREN. Beyond signal fitting, WINNER suggests new
avenues in adaptive, target-aware initialization strategies for optimizing deep
neural network training. For code and data visit
cfdlabtechnion.github.io/siren_square/.

</details>


### [133] [PANORAMA: The Rise of Omnidirectional Vision in the Embodied AI Era](https://arxiv.org/abs/2509.12989)
*Xu Zheng,Chenfei Liao,Ziqiao Weng,Kaiyu Lei,Zihao Dongfang,Haocong He,Yuanhuiyi Lyu,Lutao Jiang,Lu Qi,Li Chen,Danda Pani Paudel,Kailun Yang,Linfeng Zhang,Luc Van Gool,Xuming Hu*

Main category: cs.CV

TL;DR: 全向视觉在具身AI时代发展迅速，本文综述了其在生成、感知、理解及数据集方面的最新突破，提出了理想的全景系统架构PANORAMA，并探讨了未来趋势和挑战。


<details>
  <summary>Details</summary>
Motivation: 全向视觉能提供全面的环境感知，显著提升场景理解和决策可靠性，优于传统针孔视觉。然而，其基础研究曾滞后。当前，工业需求和学术兴趣的增长正推动其在具身AI时代快速发展，因此需要对其进行深入探讨和展望。

Method: 本文回顾了全向生成、全向感知、全向理解以及相关数据集的最新进展。它结合学术界和工业界的见解，提出了一个包含四个关键子系统的理想全景系统架构PANORAMA。此外，还就全景视觉与具身AI交叉领域的新兴趋势、跨社区影响、未来路线图和开放挑战提供了深入见解。

Result: 本文展示了全向视觉在生成、感知、理解和数据集方面的最新突破。提出了一个理想的具身AI时代全景系统架构PANORAMA。同时，阐述了全景视觉与具身AI交叉领域的新兴趋势、跨社区影响、未来路线图和开放挑战。

Conclusion: 全向视觉在具身AI时代正快速发展，对于构建鲁棒、通用的全向AI系统至关重要。本文综合了最新进展，提出了一个系统架构，并指明了未来研究的挑战和机遇。

Abstract: Omnidirectional vision, using 360-degree vision to understand the
environment, has become increasingly critical across domains like robotics,
industrial inspection, and environmental monitoring. Compared to traditional
pinhole vision, omnidirectional vision provides holistic environmental
awareness, significantly enhancing the completeness of scene perception and the
reliability of decision-making. However, foundational research in this area has
historically lagged behind traditional pinhole vision. This talk presents an
emerging trend in the embodied AI era: the rapid development of omnidirectional
vision, driven by growing industrial demand and academic interest. We highlight
recent breakthroughs in omnidirectional generation, omnidirectional perception,
omnidirectional understanding, and related datasets. Drawing on insights from
both academia and industry, we propose an ideal panoramic system architecture
in the embodied AI era, PANORAMA, which consists of four key subsystems.
Moreover, we offer in-depth opinions related to emerging trends and
cross-community impacts at the intersection of panoramic vision and embodied
AI, along with the future roadmap and open challenges. This overview
synthesizes state-of-the-art advancements and outlines challenges and
opportunities for future research in building robust, general-purpose
omnidirectional AI systems in the embodied AI era.

</details>


### [134] [Brought a Gun to a Knife Fight: Modern VFM Baselines Outgun Specialized Detectors on In-the-Wild AI Image Detection](https://arxiv.org/abs/2509.12995)
*Yue Zhou,Xinan He,Kaiqing Lin,Bing Fan,Feng Ding,Jinhua Zeng,Bin Li*

Main category: cs.CV

TL;DR: 针对AI生成图像的检测，基于视觉基础模型（VFM）的简单线性分类器在真实世界场景中显著优于专用检测器，准确率提升超过20%。这得益于VFM学习到合成图像与伪造概念的对齐，但其泛化能力受预训练数据限制。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像专用检测器在真实世界（in-the-wild）场景中表现灾难性，假阴性率极高，无法有效应对实际挑战。

Method: 研究采用一种基于现代视觉基础模型（VFM）的简单线性分类器作为检测基线。通过探测文本-图像相似性来分析VFM的“火力”来源，并使用在VFM预训练截止日期之后收集的全新数据集进行测试，以评估其在未见数据上的泛化能力。

Result: 基于VFM的基线模型在真实世界场景中，准确率比专用检测器高出超过20%。分析发现，最近的视觉语言模型（VLM）已学会将合成图像与“AI生成”等伪造相关概念对齐。然而，在VFM预训练截止日期之后收集的全新数据集上，这种对齐和整体准确率均大幅下降。

Conclusion: 1) 在AI生成图像的真实世界检测中，更新的VFM的原始“火力”远比静态专用检测器的“工艺”更有效。2) 真正的泛化能力评估要求测试数据独立于模型的整个训练历史，包括预训练数据。

Abstract: While specialized detectors for AI-generated images excel on curated
benchmarks, they fail catastrophically in real-world scenarios, as evidenced by
their critically high false-negative rates on `in-the-wild' benchmarks. Instead
of crafting another specialized `knife' for this problem, we bring a `gun' to
the fight: a simple linear classifier on a modern Vision Foundation Model
(VFM). Trained on identical data, this baseline decisively `outguns' bespoke
detectors, boosting in-the-wild accuracy by a striking margin of over 20\%.
  Our analysis pinpoints the source of the VFM's `firepower': First, by probing
text-image similarities, we find that recent VLMs (e.g., Perception Encoder,
Meta CLIP2) have learned to align synthetic images with forgery-related
concepts (e.g., `AI-generated'), unlike previous versions. Second, we speculate
that this is due to data exposure, as both this alignment and overall accuracy
plummet on a novel dataset scraped after the VFM's pre-training cut-off date,
ensuring it was unseen during pre-training. Our findings yield two critical
conclusions: 1) For the real-world `gunfight' of AI-generated image detection,
the raw `firepower' of an updated VFM is far more effective than the
`craftsmanship' of a static detector. 2) True generalization evaluation
requires test data to be independent of the model's entire training history,
including pre-training.

</details>


### [135] [Drone Detection Using a Low-Power Neuromorphic Virtual Tripwire](https://arxiv.org/abs/2509.12997)
*Anton Eldeborg Lundin,Rasmus Winzell,Hanna Hamrell,David Gustafsson,Hannes Ovrén*

Main category: cs.CV

TL;DR: 该研究开发了一个基于脉冲神经网络和神经形态相机（事件相机）的无人机检测系统，部署在神经形态芯片上，实现了极高的能效比，可用于创建虚拟绊线，并在无电源基础设施区域轻松部署。


<details>
  <summary>Details</summary>
Motivation: 小型无人机对军事人员和民用基础设施构成日益增长的威胁，因此早期和自动化检测至关重要。

Method: 该系统采用脉冲神经网络（SNNs）和神经形态相机（事件相机）进行无人机检测。检测模型部署在神经形态芯片上，形成一个全神经形态系统。多个检测单元可部署为虚拟绊线。研究还探讨了合成数据在训练中的应用。

Result: 与边缘GPU上的参考解决方案相比，该神经形态解决方案的能效高出几个数量级，使其能够依靠电池供电运行一年以上。模型主要依赖无人机的形状而非螺旋桨的时间特性进行检测。系统体积小、功耗低，易于在争议区域或缺乏电源基础设施的地点部署。

Conclusion: 该全神经形态无人机检测系统具有极高的能效和部署灵活性，通过利用神经形态技术解决了小型无人机威胁的早期自动化检测问题，特别适用于对功耗和部署环境有严格要求的场景。

Abstract: Small drones are an increasing threat to both military personnel and civilian
infrastructure, making early and automated detection crucial. In this work we
develop a system that uses spiking neural networks and neuromorphic cameras
(event cameras) to detect drones. The detection model is deployed on a
neuromorphic chip making this a fully neuromorphic system. Multiple detection
units can be deployed to create a virtual tripwire which detects when and where
drones enter a restricted zone. We show that our neuromorphic solution is
several orders of magnitude more energy efficient than a reference solution
deployed on an edge GPU, allowing the system to run for over a year on battery
power. We investigate how synthetically generated data can be used for
training, and show that our model most likely relies on the shape of the drone
rather than the temporal characteristics of its propellers. The small size and
low power consumption allows easy deployment in contested areas or locations
that lack power infrastructure.

</details>


### [136] [Dream3DAvatar: Text-Controlled 3D Avatar Reconstruction from a Single Image](https://arxiv.org/abs/2509.13013)
*Gaofeng Liu,Hengsen Li,Ruoyu Gao,Xuetong Li,Zhiyuan Ma,Tao Fang*

Main category: cs.CV

TL;DR: 本文提出Dream3DAvatar，一个高效且文本可控的两阶段框架，用于从单张图像生成高质量、动画就绪的3D人体模型，解决了单目输入信息不足导致的遮挡区域几何和纹理控制难题。


<details>
  <summary>Details</summary>
Motivation: 从单张图像重建全身3D人体模型是一个固有的病态问题，由于单目输入信息有限，难以控制生成过程中遮挡区域的几何形状和纹理。

Method: 本研究重新设计了重建流程，提出了一个两阶段框架：
1. **第一阶段（多视角生成）**：开发了一个轻量级、适配器增强的多视角生成模型。引入Pose-Adapter将SMPL-X渲染和骨骼信息注入SDXL，以确保跨视角的几何和姿态一致性。集成ID-Adapter-G注入高分辨率面部特征以保持面部身份。利用BLIP2生成多视角图像的高质量文本描述，增强对遮挡区域的文本驱动可控性。
2. **第二阶段（3D重建）**：设计了一个前馈Transformer模型，配备多视角特征融合模块，从生成的图像中重建高保真3D高斯飞溅（3DGS）表示。此外，引入ID-Adapter-R，利用门控机制有效融合面部特征到重建过程中，以改善高频细节恢复。

Result: 实验证明，该方法能够生成逼真、动画就绪的3D人体模型，无需任何后处理，并在多个评估指标上持续优于现有基线方法。

Conclusion: Dream3DAvatar通过其创新的两阶段框架和适配器增强机制，成功解决了从单张图像生成3D人体模型中遮挡区域控制和信息不足的挑战，实现了高效、文本可控且高保真的3D人体模型生成。

Abstract: With the rapid advancement of 3D representation techniques and generative
models, substantial progress has been made in reconstructing full-body 3D
avatars from a single image. However, this task remains fundamentally
ill-posedness due to the limited information available from monocular input,
making it difficult to control the geometry and texture of occluded regions
during generation. To address these challenges, we redesign the reconstruction
pipeline and propose Dream3DAvatar, an efficient and text-controllable
two-stage framework for 3D avatar generation. In the first stage, we develop a
lightweight, adapter-enhanced multi-view generation model. Specifically, we
introduce the Pose-Adapter to inject SMPL-X renderings and skeletal information
into SDXL, enforcing geometric and pose consistency across views. To preserve
facial identity, we incorporate ID-Adapter-G, which injects high-resolution
facial features into the generation process. Additionally, we leverage BLIP2 to
generate high-quality textual descriptions of the multi-view images, enhancing
text-driven controllability in occluded regions. In the second stage, we design
a feedforward Transformer model equipped with a multi-view feature fusion
module to reconstruct high-fidelity 3D Gaussian Splat representations (3DGS)
from the generated images. Furthermore, we introduce ID-Adapter-R, which
utilizes a gating mechanism to effectively fuse facial features into the
reconstruction process, improving high-frequency detail recovery. Extensive
experiments demonstrate that our method can generate realistic, animation-ready
3D avatars without any post-processing and consistently outperforms existing
baselines across multiple evaluation metrics.

</details>


### [137] [HERO: Rethinking Visual Token Early Dropping in High-Resolution Large Vision-Language Models](https://arxiv.org/abs/2509.13067)
*Xu Li,Yuxuan Liang,Xiaolei Chen,Yi Zheng,Haotian Chen,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: 高分辨率大视觉-语言模型（HR-LVLMs）通过图像分块处理，导致视觉tokens数量庞大，计算和内存开销高。本文通过实证研究揭示了视觉tokens利用率的特点，并提出了HERO框架，通过内容自适应预算分配和功能感知token选择，在不训练的情况下显著提高了HR-LVLMs的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: HR-LVLMs通过将高分辨率图像裁剪成局部图块并独立编码，实现了出色的细粒度视觉理解能力。然而，这种“分而治之”的范式显著增加了视觉tokens的数量，导致了巨大的计算和内存开销。本研究旨在更好地理解和解决这一挑战。

Method: 本文首先对HR-LVLMs中的视觉token利用率进行了实证研究。在此基础上，提出了HERO（High-resolution visual token early dropping）框架，该框架整合了内容自适应的token预算分配和功能感知的token选择。HERO通过准确估计图块级别的重要性，并选择性地保留具有互补作用的视觉token。

Result: 1. 发现局部图块的重要性各不相同，由视觉显著性和任务相关性共同决定。
2. CLIP基视觉编码器中的CLS token在不同层级展现出两阶段的注意力模式，每个阶段关注不同类型的视觉token。
3. 在不同阶段被强调的视觉token编码了不同粒度级别的信息，并在LVLMs中扮演互补角色。
4. HERO框架在各种基准测试和模型规模上实现了卓越的效率-准确性权衡，且无需训练。

Conclusion: 本研究为HR-LVLMs的有效推理提供了实证见解和实用的解决方案。

Abstract: By cropping high-resolution images into local tiles and encoding them
independently, High-Resolution Large Vision-Language Models (HR-LVLMs) have
demonstrated remarkable fine-grained visual understanding capabilities.
However, this divide-and-conquer paradigm significantly increases the number of
visual tokens, resulting in substantial computational and memory overhead. To
better understand and address this challenge, we empirically investigate visual
token utilization in HR-LVLMs and uncover three key findings: (1) the local
tiles have varying importance, jointly determined by visual saliency and task
relevance; (2) the CLS token in CLIP-based vision encoders exhibits a two-stage
attention pattern across layers, with each stage attending to different types
of visual tokens; (3) the visual tokens emphasized at different stages encode
information at varying levels of granularity, playing complementary roles
within LVLMs. Building on these insights, we propose HERO, a High-resolution
visual token early dropping framework that integrates content-adaptive token
budget allocation with function-aware token selection. By accurately estimating
tile-level importance and selectively retaining visual tokens with
complementary roles, HERO achieves superior efficiency-accuracy trade-offs
across diverse benchmarks and model scales, all in a training-free manner. This
study provides both empirical insights and practical solutions toward efficient
inference in HR-LVLMs.

</details>


### [138] [Using KL-Divergence to Focus Frequency Information in Low-Light Image Enhancement](https://arxiv.org/abs/2509.13083)
*Yan Xingyang,Huang Xiaohong,Zhang Zhao,You Tian,Xu Ziheng*

Main category: cs.CV

TL;DR: 本文提出LLFDisc，一个U型深度增强网络，通过引入新的傅里叶域分布感知损失（基于KL散度）和增强的感知损失（将KL散度嵌入VGG特征），解决了传统像素级损失在傅里叶域信息拟合中可能导致全局信息丢失的问题，实现了最先进的图像增强性能。


<details>
  <summary>Details</summary>
Motivation: 傅里叶域中，传统傅里叶频率信息拟合采用像素级损失函数，往往过度关注局部信息，可能导致全局信息丢失。

Method: 本文提出了LLFDisc，一个U型深度增强网络，集成了交叉注意力（cross-attention）和门控机制（gating mechanisms），专为频率感知增强设计。核心方法包括：1) 提出了一种新颖的分布感知损失（distribution-aware loss），直接拟合傅里叶域信息，并使用闭式KL散度目标最小化其散度。2) 通过在提取的深度特征上嵌入KL散度，增强了基于VGG的感知损失，以实现更好的结构保真度。

Result: 在多个基准测试中进行的广泛实验表明，LLFDisc在定性和定量评估中均达到了最先进的性能。

Conclusion: LLFDisc通过其新颖的傅里叶域分布感知损失和增强的感知损失，能够比传统基于MSE的损失更稳健地对齐傅里叶域信息，并实现了卓越的图像增强效果和结构保真度。

Abstract: In the Fourier domain, luminance information is primarily encoded in the
amplitude spectrum, while spatial structures are captured in the phase
components. The traditional Fourier Frequency information fitting employs
pixel-wise loss functions, which tend to focus excessively on local information
and may lead to global information loss. In this paper, we present LLFDisc, a
U-shaped deep enhancement network that integrates cross-attention and gating
mechanisms tailored for frequency-aware enhancement. We propose a novel
distribution-aware loss that directly fits the Fourier-domain information and
minimizes their divergence using a closed-form KL-Divergence objective. This
enables the model to align Fourier-domain information more robustly than with
conventional MSE-based losses. Furthermore, we enhance the perceptual loss
based on VGG by embedding KL-Divergence on extracted deep features, enabling
better structural fidelity. Extensive experiments across multiple benchmarks
demonstrate that LLFDisc achieves state-of-the-art performance in both
qualitative and quantitative evaluations. Our code will be released at:
https://github.com/YanXY000/LLFDisc

</details>


### [139] [Enhancing Dual Network Based Semi-Supervised Medical Image Segmentation with Uncertainty-Guided Pseudo-Labeling](https://arxiv.org/abs/2509.13084)
*Yunyao Lu,Yihang Wu,Ahmad Chaddad,Tareef Daqqaq,Reem Kateb*

Main category: cs.CV

TL;DR: 本文提出了一种基于双网络架构的半监督3D医学图像分割框架，通过交叉一致性增强、动态权重策略和自监督对比学习，有效解决了伪标签噪声和特征空间监督不足的问题，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 监督式医学图像分割模型需要大量标注数据，这在实际应用中不切实际。现有半监督方法存在伪标签噪声和特征空间监督不足的问题。

Method: 本文提出了一个基于双网络架构的半监督3D医学图像分割框架。具体方法包括：1) 交叉一致性增强模块，结合交叉伪监督和熵过滤监督来减少伪标签噪声。2) 动态权重策略，利用不确定性感知机制（Kullback-Leibler散度）调整伪标签的贡献。3) 自监督对比学习机制，通过区分可信和不确定的预测，将不确定体素特征与可靠类别原型对齐，从而降低预测不确定性。

Result: 在三个3D分割数据集（左心房、NIH胰腺和BraTS-2019）上进行了广泛实验，所提出的方法在各种设置下（例如，在10%标注数据的左心房数据集上Dice分数为89.95%）均表现出优于现有最先进方法的性能。消融实验进一步验证了所提出模块的有效性。

Conclusion: 所提出的半监督3D医学图像分割框架通过引入交叉一致性增强、动态权重策略和自监督对比学习，成功解决了伪标签噪声和特征空间监督不足的挑战，实现了卓越的分割性能。

Abstract: Despite the remarkable performance of supervised medical image segmentation
models, relying on a large amount of labeled data is impractical in real-world
situations. Semi-supervised learning approaches aim to alleviate this challenge
using unlabeled data through pseudo-label generation. Yet, existing
semi-supervised segmentation methods still suffer from noisy pseudo-labels and
insufficient supervision within the feature space. To solve these challenges,
this paper proposes a novel semi-supervised 3D medical image segmentation
framework based on a dual-network architecture. Specifically, we investigate a
Cross Consistency Enhancement module using both cross pseudo and
entropy-filtered supervision to reduce the noisy pseudo-labels, while we design
a dynamic weighting strategy to adjust the contributions of pseudo-labels using
an uncertainty-aware mechanism (i.e., Kullback-Leibler divergence). In
addition, we use a self-supervised contrastive learning mechanism to align
uncertain voxel features with reliable class prototypes by effectively
differentiating between trustworthy and uncertain predictions, thus reducing
prediction uncertainty. Extensive experiments are conducted on three 3D
segmentation datasets, Left Atrial, NIH Pancreas and BraTS-2019. The proposed
approach consistently exhibits superior performance across various settings
(e.g., 89.95\% Dice score on left Atrial with 10\% labeled data) compared to
the state-of-the-art methods. Furthermore, the usefulness of the proposed
modules is further validated via ablation experiments.

</details>


### [140] [Weakly and Self-Supervised Class-Agnostic Motion Prediction for Autonomous Driving](https://arxiv.org/abs/2509.13116)
*Ruibo Li,Hanyu Shi,Zhe Wang,Guosheng Lin*

Main category: cs.CV

TL;DR: 本文提出了一种基于激光雷达点云的弱监督和自监督的类别无关运动预测方法，通过利用前景/背景或非地面/地面掩码作为监督信号，并设计了新的鲁棒一致性Chamfer距离损失，在减少标注工作量的同时，实现了与部分监督方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要理解动态环境中的运动，因此类别无关的运动预测至关重要。传统的运动预测方法通常需要大量的运动标注，这促使研究人员探索弱监督和自监督的方法。

Method: 本文提出了一种新的弱监督范式，用前景/背景(F/B)掩码（完全、1%或0.1%标注）取代运动标注进行监督。基于此，开发了一种利用F/B线索引导自监督运动预测模型的方法。为进一步减少标注，提出使用非地面/地面掩码作为F/B掩码的替代。在此基础上，提出了两种额外的方法：一种仅需0.01%F/B标注的弱监督方法，以及一种无需任何标注的自监督方法。此外，设计了一种鲁棒一致性感知Chamfer距离损失，该损失结合了多帧信息和鲁棒惩罚函数，以抑制自监督学习中的异常值。

Result: 实验结果表明，本文提出的弱监督和自监督模型优于现有自监督方法。更重要的是，本文的弱监督模型甚至可以与一些监督模型相媲美。这表明所提出的方法有效地平衡了标注工作量和性能。

Conclusion: 本文提出的弱监督和自监督方法，通过利用前景/背景或非地面/地面掩码作为监督信号，并结合新的鲁棒一致性Chamfer距离损失，能够有效地从激光雷达点云中进行类别无关的运动预测。这些方法在显著减少标注需求的同时，实现了出色的性能，为自动驾驶领域提供了有前景的解决方案。

Abstract: Understanding motion in dynamic environments is critical for autonomous
driving, thereby motivating research on class-agnostic motion prediction. In
this work, we investigate weakly and self-supervised class-agnostic motion
prediction from LiDAR point clouds. Outdoor scenes typically consist of mobile
foregrounds and static backgrounds, allowing motion understanding to be
associated with scene parsing. Based on this observation, we propose a novel
weakly supervised paradigm that replaces motion annotations with fully or
partially annotated (1%, 0.1%) foreground/background masks for supervision. To
this end, we develop a weakly supervised approach utilizing
foreground/background cues to guide the self-supervised learning of motion
prediction models. Since foreground motion generally occurs in non-ground
regions, non-ground/ground masks can serve as an alternative to
foreground/background masks, further reducing annotation effort. Leveraging
non-ground/ground cues, we propose two additional approaches: a weakly
supervised method requiring fewer (0.01%) foreground/background annotations,
and a self-supervised method without annotations. Furthermore, we design a
Robust Consistency-aware Chamfer Distance loss that incorporates multi-frame
information and robust penalty functions to suppress outliers in
self-supervised learning. Experiments show that our weakly and self-supervised
models outperform existing self-supervised counterparts, and our weakly
supervised models even rival some supervised ones. This demonstrates that our
approaches effectively balance annotation effort and performance.

</details>


### [141] [Advancing Real-World Parking Slot Detection with Large-Scale Dataset and Semi-Supervised Baseline](https://arxiv.org/abs/2509.13133)
*Zhihao Zhang,Chunyu Lin,Lang Nie,Jiyuan Wang,Yao Zhao*

Main category: cs.CV

TL;DR: 本研究针对环视摄像头停车位检测，解决了现有数据集规模小、缺乏真实世界噪声以及手动标注成本高的问题。为此，我们构建了一个大规模数据集CRPS-D，并提出了一种半监督检测方法SS-PSD，该方法在多个数据集上均优于现有技术，且利用未标注数据效果更显著。


<details>
  <summary>Details</summary>
Motivation: 自动泊车系统中停车位检测的准确性至关重要。然而，现有数据集规模有限，缺乏真实世界的噪声（如光照、遮挡等），且手动标注成本高昂且容易出错，限制了大规模数据集的构建和算法的性能提升。

Method: 1. 构建了一个大规模停车位检测数据集CRPS-D，包含多样化的光照、天气条件和具有挑战性的停车位变体（特别是更多倾斜停车位），且数据规模和停车位密度均高于现有数据集。2. 开发了一种名为SS-PSD的半监督停车位检测基线方法，该方法基于师生模型，并结合了置信度引导的掩码一致性和自适应特征扰动，以利用未标注数据来提高性能。

Result: 实验结果表明，SS-PSD在所提出的CRPS-D数据集和现有数据集上均优于现有最先进（SoTA）的解决方案。尤其值得注意的是，未标注数据越多，我们的半监督方案带来的性能提升越显著。

Conclusion: 本研究通过构建大规模、多样化的CRPS-D数据集，并提出创新的半监督SS-PSD方法，有效解决了环视摄像头停车位检测领域的数据和算法挑战，显著提升了检测性能，尤其在利用未标注数据方面表现出色。

Abstract: As automatic parking systems evolve, the accurate detection of parking slots
has become increasingly critical. This study focuses on parking slot detection
using surround-view cameras, which offer a comprehensive bird's-eye view of the
parking environment. However, the current datasets are limited in scale, and
the scenes they contain are seldom disrupted by real-world noise (e.g., light,
occlusion, etc.). Moreover, manual data annotation is prone to errors and
omissions due to the complexity of real-world conditions, significantly
increasing the cost of annotating large-scale datasets. To address these
issues, we first construct a large-scale parking slot detection dataset (named
CRPS-D), which includes various lighting distributions, diverse weather
conditions, and challenging parking slot variants. Compared with existing
datasets, the proposed dataset boasts the largest data scale and consists of a
higher density of parking slots, particularly featuring more slanted parking
slots. Additionally, we develop a semi-supervised baseline for parking slot
detection, termed SS-PSD, to further improve performance by exploiting
unlabeled data. To our knowledge, this is the first semi-supervised approach in
parking slot detection, which is built on the teacher-student model with
confidence-guided mask consistency and adaptive feature perturbation.
Experimental results demonstrate the superiority of SS-PSD over the existing
state-of-the-art (SoTA) solutions on both the proposed dataset and the existing
dataset. Particularly, the more unlabeled data there is, the more significant
the gains brought by our semi-supervised scheme. The relevant source codes and
the dataset have been made publicly available at
https://github.com/zzh362/CRPS-D.

</details>


### [142] [MSDNet: Efficient 4D Radar Super-Resolution via Multi-Stage Distillation](https://arxiv.org/abs/2509.13149)
*Minqing Huang,Shouyi Lu,Boyuan Zheng,Ziyao Li,Xiao Tang,Guirong Zhuo*

Main category: cs.CV

TL;DR: MSDNet是一个多阶段蒸馏框架，通过将LiDAR先验知识高效转移到4D雷达特征，解决了4D雷达超分辨率中精度与效率难以平衡的问题，实现了高保真重建和低延迟推理。


<details>
  <summary>Details</summary>
Motivation: 现有的4D雷达超分辨率方法存在训练成本高、推理延迟高、泛化性差等问题，难以同时实现高精度和高效率。

Method: 本文提出了MSDNet，一个多阶段蒸馏框架：第一阶段是重建引导特征蒸馏，通过特征重建对齐并稠密化学生特征；第二阶段是扩散引导特征蒸馏，将第一阶段的蒸馏特征视为教师表示的噪声版本，并通过轻量级扩散网络进行精炼。此外，引入了噪声适配器以自适应对齐特征噪声水平与预定义扩散时间步，实现更精确的去噪。

Result: 在VoD和内部数据集上的大量实验表明，MSDNet在4D雷达点云超分辨率任务中实现了高保真重建和低延迟推理，并持续提升了下游任务的性能。

Conclusion: MSDNet通过创新的多阶段蒸馏框架，有效解决了4D雷达超分辨率中精度与效率的平衡难题，为自主感知领域提供了高效且高质量的解决方案。

Abstract: 4D radar super-resolution, which aims to reconstruct sparse and noisy point
clouds into dense and geometrically consistent representations, is a
foundational problem in autonomous perception. However, existing methods often
suffer from high training cost or rely on complex diffusion-based sampling,
resulting in high inference latency and poor generalization, making it
difficult to balance accuracy and efficiency. To address these limitations, we
propose MSDNet, a multi-stage distillation framework that efficiently transfers
dense LiDAR priors to 4D radar features to achieve both high reconstruction
quality and computational efficiency. The first stage performs
reconstruction-guided feature distillation, aligning and densifying the
student's features through feature reconstruction. In the second stage, we
propose diffusion-guided feature distillation, which treats the stage-one
distilled features as a noisy version of the teacher's representations and
refines them via a lightweight diffusion network. Furthermore, we introduce a
noise adapter that adaptively aligns the noise level of the feature with a
predefined diffusion timestep, enabling a more precise denoising. Extensive
experiments on the VoD and in-house datasets demonstrate that MSDNet achieves
both high-fidelity reconstruction and low-latency inference in the task of 4D
radar point cloud super-resolution, and consistently improves performance on
downstream tasks. The code will be publicly available upon publication.

</details>


### [143] [TexTAR : Textual Attribute Recognition in Multi-domain and Multi-lingual Document Images](https://arxiv.org/abs/2509.13151)
*Rohan Kumar,Jyothi Swaroopa Jinka,Ravi Kiran Sarvadevabhatla*

Main category: cs.CV

TL;DR: 该论文提出了TexTAR，一个多任务、上下文感知的Transformer模型，用于文本属性识别（TAR），并通过新颖的数据选择管道和2D RoPE机制增强上下文感知。同时引入了多语言、多领域数据集MMTAD。实验证明TexTAR优于现有方法，并强调了上下文感知对TAR性能的重要性。


<details>
  <summary>Details</summary>
Motivation: 识别文本属性（如粗体、斜体、下划线、删除线）对于理解文本语义、结构和视觉呈现至关重要。现有方法在嘈杂、多语言环境中计算效率或适应性方面存在不足。

Method: 引入了TexTAR，一个多任务、上下文感知的Transformer模型用于文本属性识别。设计了新颖的数据选择管道以增强上下文感知。架构中采用了2D RoPE（旋转位置嵌入）风格的机制来融入输入上下文。同时，构建了MMTAD，一个多样化、多语言、多领域的数据集，其中包含真实世界文档（如法律记录、通知、教科书）的文本属性标注。

Result: TexTAR在广泛评估中超越了现有方法。

Conclusion: 上下文感知有助于实现最先进的文本属性识别（TAR）性能。

Abstract: Recognizing textual attributes such as bold, italic, underline and strikeout
is essential for understanding text semantics, structure, and visual
presentation. These attributes highlight key information, making them crucial
for document analysis. Existing methods struggle with computational efficiency
or adaptability in noisy, multilingual settings. To address this, we introduce
TexTAR, a multi-task, context-aware Transformer for Textual Attribute
Recognition (TAR). Our novel data selection pipeline enhances context
awareness, and our architecture employs a 2D RoPE (Rotary Positional
Embedding)-style mechanism to incorporate input context for more accurate
attribute predictions. We also introduce MMTAD, a diverse, multilingual,
multi-domain dataset annotated with text attributes across real-world documents
such as legal records, notices, and textbooks. Extensive evaluations show
TexTAR outperforms existing methods, demonstrating that contextual awareness
contributes to state-of-the-art TAR performance.

</details>


### [144] [Enhancing Video Large Language Models with Structured Multi-Video Collaborative Reasoning (early version)](https://arxiv.org/abs/2509.13161)
*Zhihao He,Tianyao He,Tieyuan Chen,Yun Xu,Huabin Liu,Chaofan Gan,Gui Zou,Weiyao Lin*

Main category: cs.CV

TL;DR: 本文提出一个多视频协作框架，通过将视频知识表示为时空图并融合相关视频信息，以解决单视频固有时空不完整性导致视频语言模型产生幻觉和不准确性问题。


<details>
  <summary>Details</summary>
Motivation: 当前的视频语言模型（VLM）在综合视频推理方面受限于单个视频固有的时空不完整性，导致幻觉和不准确性。直接将大量相关视频数据输入大型语言模型效率低下且可能适得其反。

Method: 该研究提出一个多视频协作框架：1. 建立一个视频结构化模块（Video Structuring Module），将视频知识表示为时空图。2. 设计一个图融合模块（Graph Fusion Module），将相关视频的结构化知识和有价值信息融合到增强的图节点标记中。3. 构建一个精巧的多视频结构化提示（multi-video structured prompt），将图、视觉和文本标记整合作为大型语言模型的输入。

Result: 广泛的实验证明了该框架的有效性，展示了其作为推进视频语言模型的一个有前景的途径的潜力。

Conclusion: 该多视频协作框架通过结构化视频表示和信息融合，有效解决了视频语言模型在处理单个视频时面临的时空不完整性问题，为提升视频语言模型的推理能力提供了一个有前景的解决方案。

Abstract: Despite the prosperity of the video language model, the current pursuit of
comprehensive video reasoning is thwarted by the inherent spatio-temporal
incompleteness within individual videos, resulting in hallucinations and
inaccuracies. A promising solution is to augment the reasoning performance with
multiple related videos. However, video tokens are numerous and contain
redundant information, so directly feeding the relevant video data into a large
language model to enhance responses could be counterproductive. To address this
challenge, we propose a multi-video collaborative framework for video language
models. For efficient and flexible video representation, we establish a Video
Structuring Module to represent the video's knowledge as a spatio-temporal
graph. Based on the structured video representation, we design the Graph Fusion
Module to fuse the structured knowledge and valuable information from related
videos into the augmented graph node tokens. Finally, we construct an elaborate
multi-video structured prompt to integrate the graph, visual, and textual
tokens as the input to the large language model. Extensive experiments
substantiate the effectiveness of our framework, showcasing its potential as a
promising avenue for advancing video language models.

</details>


### [145] [WHU-STree: A Multi-modal Benchmark Dataset for Street Tree Inventory](https://arxiv.org/abs/2509.13172)
*Ruifei Ding,Zhe Chen,Wen Fan,Chen Long,Huijuan Xiao,Yelu Zeng,Zhen Dong,Bisheng Yang*

Main category: cs.CV

TL;DR: 本文介绍了WHU-STree数据集，这是一个跨城市、多模态、标注丰富的城市行道树数据集，旨在克服传统调查和现有MMS数据集的局限性，支持多种行道树资产管理任务。


<details>
  <summary>Details</summary>
Motivation: 行道树对城市宜居性至关重要，但传统的实地调查耗时费力。现有的移动测绘系统（MMS）获取的树木数据集存在场景规模小、标注有限或单一模态的局限性，阻碍了全面分析和优化这些多功能资产。

Method: 本文提出了WHU-STree数据集，它是一个跨城市、标注丰富且多模态的城市行道树数据集。该数据集在两个不同城市采集，整合了同步的点云数据和高分辨率图像，包含21,007个标注的树木实例，涵盖50个树种和2个形态参数。研究人员利用该数据集为树种分类和单株树分割这两个关键任务建立了基线。

Result: WHU-STree数据集能够同时支持超过10项与行道树清查相关的任务。广泛的实验和深入分析表明，多模态数据融合具有显著潜力，并强调了跨领域适用性是实际算法部署的关键先决条件。研究还指出了充分利用WHU-STree面临的关键挑战和未来工作方向，包括多模态融合、多任务协作、跨领域泛化、空间模式学习以及用于行道树资产管理的多模态大语言模型。

Conclusion: WHU-STree数据集通过提供一个跨城市、多模态、标注丰富的资源，有效解决了现有行道树数据集的局限性。它为开发高效、自动化的行道树清查和管理算法提供了重要基础，并强调了多模态数据融合和跨领域泛化在实际应用中的重要性。

Abstract: Street trees are vital to urban livability, providing ecological and social
benefits. Establishing a detailed, accurate, and dynamically updated street
tree inventory has become essential for optimizing these multifunctional assets
within space-constrained urban environments. Given that traditional field
surveys are time-consuming and labor-intensive, automated surveys utilizing
Mobile Mapping Systems (MMS) offer a more efficient solution. However, existing
MMS-acquired tree datasets are limited by small-scale scene, limited
annotation, or single modality, restricting their utility for comprehensive
analysis. To address these limitations, we introduce WHU-STree, a cross-city,
richly annotated, and multi-modal urban street tree dataset. Collected across
two distinct cities, WHU-STree integrates synchronized point clouds and
high-resolution images, encompassing 21,007 annotated tree instances across 50
species and 2 morphological parameters. Leveraging the unique characteristics,
WHU-STree concurrently supports over 10 tasks related to street tree inventory.
We benchmark representative baselines for two key tasks--tree species
classification and individual tree segmentation. Extensive experiments and
in-depth analysis demonstrate the significant potential of multi-modal data
fusion and underscore cross-domain applicability as a critical prerequisite for
practical algorithm deployment. In particular, we identify key challenges and
outline potential future works for fully exploiting WHU-STree, encompassing
multi-modal fusion, multi-task collaboration, cross-domain generalization,
spatial pattern learning, and Multi-modal Large Language Model for street tree
asset management. The WHU-STree dataset is accessible at:
https://github.com/WHU-USI3DV/WHU-STree.

</details>


### [146] [More performant and scalable: Rethinking contrastive vision-language pre-training of radiology in the LLM era](https://arxiv.org/abs/2509.13175)
*Yingtai Li,Haoran Lai,Xiaoqian Zhou,Shuai Ming,Wenxin Ma,Wei Wei,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: 该研究展示了大型语言模型（LLMs）如何高效地从放射学报告中提取诊断标签，构建大规模“银标准”数据集，从而实现高性能的医学对比视觉-语言预训练，并以更简单的模型架构达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的出现为医学对比视觉-语言预训练带来了前所未有的机遇。研究旨在探索LLMs如何促进大规模监督预训练，从而提升视觉-语言对齐效果。

Method: 研究方法包括：1) 利用LLMs自动从放射学报告中提取诊断标签，以极高的精度（>96% AUC）和低成本（5万对CT图像-报告约3美元）创建大规模“银标准”数据集。2) 使用这些“银标准”标签训练视觉编码器（例如，3D ResNet-18）。3) 采用普通的CLIP训练方法进行视觉-语言对齐。4) 比较其性能与基于专用BERT模型提取标签训练的模型的性能。

Result: 主要结果包括：1) LLMs能够以高精度（>96% AUC）从放射学报告中提取诊断标签，以极低成本（约3美元）创建了5万对CT图像-报告的大规模数据集。2) 在此“银标准”数据集上训练的视觉编码器，其性能与在专用BERT模型提取标签上训练的模型相当。3) 监督预训练显著改善了对比视觉-语言对齐。4) 仅使用3D ResNet-18和普通的CLIP训练，就在多项任务上取得了最先进的性能，包括CT-RATE零样本诊断达到83.8% AUC，RAD-ChestCT达到77.3% AUC，以及跨模态检索的显著提升（图像-图像MAP@50=53.7%，报告-图像Recall@100=52.2%）。

Conclusion: 研究结果证明，利用大型语言模型能够促进更高效、更具扩展性的医学人工智能系统，通过实现大规模监督预训练来提升视觉-语言对齐能力。

Abstract: The emergence of Large Language Models (LLMs) presents unprecedented
opportunities to revolutionize medical contrastive vision-language
pre-training. In this paper, we show how LLMs can facilitate large-scale
supervised pre-training, thereby advancing vision-language alignment. We begin
by demonstrate that modern LLMs can automatically extract diagnostic labels
from radiology reports with remarkable precision (>96\% AUC in our experiments)
without complex prompt engineering, enabling the creation of large-scale
"silver-standard" datasets at a minimal cost (~\$3 for 50k CT image-report
pairs). Further, we find that vision encoder trained on this "silver-standard"
dataset achieves performance comparable to those trained on labels extracted by
specialized BERT-based models, thereby democratizing the access to large-scale
supervised pre-training. Building on this foundation, we proceed to reveal that
supervised pre-training fundamentally improves contrastive vision-language
alignment. Our approach achieves state-of-the-art performance using only a 3D
ResNet-18 with vanilla CLIP training, including 83.8\% AUC for zero-shot
diagnosis on CT-RATE, 77.3\% AUC on RAD-ChestCT, and substantial improvements
in cross-modal retrieval (MAP@50=53.7\% for image-image, Recall@100=52.2\% for
report-image). These results demonstrate the potential of utilizing LLMs to
facilitate {\bf more performant and scalable} medical AI systems. Our code is
avaiable at https://github.com/SadVoxel/More-performant-and-scalable.

</details>


### [147] [Road Obstacle Video Segmentation](https://arxiv.org/abs/2509.13181)
*Shyam Nandan Rai,Shyamgopal Karthik,Mariana-Iuliana Georgescu,Barbara Caputo,Carlo Masone,Zeynep Akata*

Main category: cs.CV

TL;DR: 本文指出道路障碍物分割任务本质上是时序性的，现有方法忽略了这一点导致预测不一致。为此，作者创建并调整了四个视频分割基准，评估了11种现有方法，并提出了基于视觉基础模型的两个强基线方法，在长距离视频序列的道路障碍物视频分割方面达到了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶代理的部署，道路障碍物的检测和分割对于确保安全导航至关重要。然而，现有方法仅应用于单个帧，忽视了问题的时序性质，导致连续帧之间的预测图不一致。研究认为，由于连续帧的分割图之间存在强相关性，道路障碍物分割任务本身就是时序性的。

Method: 本文首先论证了道路障碍物分割任务的固有时间性。然后，策划并调整了四个用于道路障碍物视频分割的评估基准。在此基础上，评估了11种最先进的基于图像和视频的分割方法。此外，引入了两种基于视觉基础模型的强大基线方法。

Result: 研究结果表明，道路障碍物分割任务确实是内在时序性的。所提出的方法在长距离视频序列的道路障碍物视频分割方面建立了新的最先进水平。

Conclusion: 这项工作为未来的研究提供了有价值的见解和方向，强调了在道路障碍物分割中考虑时序信息的重要性。

Abstract: With the growing deployment of autonomous driving agents, the detection and
segmentation of road obstacles have become critical to ensure safe autonomous
navigation. However, existing road-obstacle segmentation methods are applied on
individual frames, overlooking the temporal nature of the problem, leading to
inconsistent prediction maps between consecutive frames. In this work, we
demonstrate that the road-obstacle segmentation task is inherently temporal,
since the segmentation maps for consecutive frames are strongly correlated. To
address this, we curate and adapt four evaluation benchmarks for road-obstacle
video segmentation and evaluate 11 state-of-the-art image- and video-based
segmentation methods on these benchmarks. Moreover, we introduce two strong
baseline methods based on vision foundation models. Our approach establishes a
new state-of-the-art in road-obstacle video segmentation for long-range video
sequences, providing valuable insights and direction for future research.

</details>


### [148] [Vi-SAFE: A Spatial-Temporal Framework for Efficient Violence Detection in Public Surveillance](https://arxiv.org/abs/2509.13210)
*Ligang Chang,Shengkai Xu,Liangchang Shen,Binhan Xu,Junqiao Wang,Tianyu Shi,Yanhui Du*

Main category: cs.CV

TL;DR: 本文提出Vi-SAFE，一个结合增强型YOLOv8和时间片段网络（TSN）的时空框架，用于公共监控中的暴力行为检测，实现了高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 公共安全监控中的暴力检测至关重要，但面临小目标、复杂环境和实时时间分析等挑战。

Method: Vi-SAFE框架整合了增强型YOLOv8和TSN。YOLOv8通过GhostNetV3轻量级骨干网络、指数移动平均（EMA）注意力机制和剪枝进行优化，以降低计算成本。YOLOv8负责提取人体区域，TSN则进行暴力行为的二分类。这两个模型分别在行人和暴力数据集上进行训练。

Result: 在RWF-2000数据集上，Vi-SAFE的准确率达到0.88，优于单独使用TSN（0.77），并在准确性和效率上均超越现有方法。

Conclusion: Vi-SAFE框架被证明对公共安全监控中的暴力检测是有效且高效的，提高了准确性并降低了计算成本。

Abstract: Violence detection in public surveillance is critical for public safety. This
study addresses challenges such as small-scale targets, complex environments,
and real-time temporal analysis. We propose Vi-SAFE, a spatial-temporal
framework that integrates an enhanced YOLOv8 with a Temporal Segment Network
(TSN) for video surveillance. The YOLOv8 model is optimized with GhostNetV3 as
a lightweight backbone, an exponential moving average (EMA) attention
mechanism, and pruning to reduce computational cost while maintaining accuracy.
YOLOv8 and TSN are trained separately on pedestrian and violence datasets,
where YOLOv8 extracts human regions and TSN performs binary classification of
violent behavior. Experiments on the RWF-2000 dataset show that Vi-SAFE
achieves an accuracy of 0.88, surpassing TSN alone (0.77) and outperforming
existing methods in both accuracy and efficiency, demonstrating its
effectiveness for public safety surveillance. Code is available at
https://anonymous.4open.science/r/Vi-SAFE-3B42/README.md.

</details>


### [149] [End4: End-to-end Denoising Diffusion for Diffusion-Based Inpainting Detection](https://arxiv.org/abs/2509.13214)
*Fei Wang,Xuecheng Wu,Zheng Zhang,Danlei Huang,Yuheng Huang,BoWang*

Main category: cs.CV

TL;DR: 扩散模型在图像合成方面表现出色，但也引发了滥用担忧。现有方法难以检测扩散模型生成的修复图像。本文提出End4方法，通过改进潜在空间对齐和多尺度特征融合来有效检测扩散修复图像，并在新掩模模式和扰动下表现鲁棒。


<details>
  <summary>Details</summary>
Motivation: 扩散模型强大的生成能力带来了图像合成的显著进步，但也带来了恶意使用的风险。然而，现有方法在识别扩散模型生成的修复图像方面存在困难，即使训练数据中包含类似的修复图像。

Method: 本文提出了一种基于端到端去噪扩散（End4）的新型检测方法。具体来说，End4设计了一个去噪重建模型，以改善重建和检测过程潜在空间之间的对齐程度，从而重建更有利于检测的特征。同时，它利用了一个尺度感知金字塔式融合模块（SPFM），在不同尺度的注意力金字塔层的指导下，精炼局部图像特征，增强特征的可区分性。此外，为评估修复图像的检测性能，建立了一个包含五种不同掩模区域生成图像的综合基准。

Result: 广泛的实验表明，End4能有效泛化到未见的掩模模式，并在各种扰动下保持鲁棒性。

Conclusion: End4是一种有效检测扩散模型生成的修复图像的新方法，解决了现有方法在识别这类图像上的挑战，并在泛化性和鲁棒性方面表现出色。

Abstract: The powerful generative capabilities of diffusion models have significantly
advanced the field of image synthesis, enhancing both full image generation and
inpainting-based image editing. Despite their remarkable advancements,
diffusion models also raise concerns about potential misuse for malicious
purposes. However, existing approaches struggle to identify images generated by
diffusion-based inpainting models, even when similar inpainted images are
included in their training data. To address this challenge, we propose a novel
detection method based on End-to-end denoising diffusion (End4). Specifically,
End4 designs a denoising reconstruction model to improve the alignment degree
between the latent spaces of the reconstruction and detection processes, thus
reconstructing features that are more conducive to detection. Meanwhile, it
leverages a Scale-aware Pyramid-like Fusion Module (SPFM) that refines local
image features under the guidance of attention pyramid layers at different
scales, enhancing feature discriminability. Additionally, to evaluate detection
performance on inpainted images, we establish a comprehensive benchmark
comprising images generated from five distinct masked regions. Extensive
experiments demonstrate that our End4 effectively generalizes to unseen masking
patterns and remains robust under various perturbations. Our code and dataset
will be released soon.

</details>


### [150] [Intelligent Vacuum Thermoforming Process](https://arxiv.org/abs/2509.13250)
*Andi Kuswoyo,Christos Margadji,Sebastian W. Pattinson*

Main category: cs.CV

TL;DR: 本研究提出一种基于视觉的质量控制系统，利用k-NN算法预测和优化真空热成型工艺参数，以少量数据提高零件质量和生产效率。


<details>
  <summary>Details</summary>
Motivation: 真空热成型过程中，材料特性和模具配置的变化导致产品质量难以保持一致性，因此需要一种方法来预测和优化工艺参数以确保质量。

Method: 研究开发了一个包含不同工艺参数下真空成型样品视觉数据的综合数据集，并使用图像增强技术进行扩充。随后，采用k-近邻（k-NN）算法将低质量零件映射到高质量零件，以识别所需的工艺参数调整。

Result: 该模型在调整加热功率、加热时间和真空时间方面表现出强大的性能，有效减少了缺陷并提高了生产效率。

Conclusion: 所提出的基于视觉的k-NN质量控制系统能够以最少的数据需求，有效优化真空热成型工艺参数，从而提高零件质量和生产效率。

Abstract: Ensuring consistent quality in vacuum thermoforming presents challenges due
to variations in material properties and tooling configurations. This research
introduces a vision-based quality control system to predict and optimise
process parameters, thereby enhancing part quality with minimal data
requirements. A comprehensive dataset was developed using visual data from
vacuum-formed samples subjected to various process parameters, supplemented by
image augmentation techniques to improve model training. A k-Nearest Neighbour
algorithm was subsequently employed to identify adjustments needed in process
parameters by mapping low-quality parts to their high-quality counterparts. The
model exhibited strong performance in adjusting heating power, heating time,
and vacuum time to reduce defects and improve production efficiency.

</details>


### [151] [StyleSculptor: Zero-Shot Style-Controllable 3D Asset Generation with Texture-Geometry Dual Guidance](https://arxiv.org/abs/2509.13301)
*Zefan Qu,Zhenwei Wang,Haoyuan Wang,Ke Xu,Gerhard Hancke,Rynson W. H. Lau*

Main category: cs.CV

TL;DR: StyleSculptor是一种无需训练、零样本的方法，可根据内容图像和风格图像生成风格引导的3D资产，实现对纹理和几何风格的细粒度控制。


<details>
  <summary>Details</summary>
Motivation: 在视频游戏和虚拟现实等实际应用中，创建与现有3D资产纹理和几何风格一致的3D资产是常见需求。尽管从文本或图像生成3D对象已取得进展，但创建风格可控的3D资产仍是一个复杂且具有挑战性的问题。

Method: 本文提出了StyleSculptor，一种新颖的无需训练方法，用于从内容图像和一个或多个风格图像生成风格引导的3D资产。其核心是一个新颖的“风格解耦注意力”（SD-Attn）模块，通过跨3D注意力机制在内容图像和风格图像之间建立动态交互，实现稳定的特征融合和有效的风格引导生成。为减轻语义内容泄露，SD-Attn模块引入了风格解耦特征选择策略，利用3D特征块的方差来解耦风格和内容相关通道，实现选择性特征注入。在此基础上，进一步提出了“风格引导控制”（SGC）机制，支持纯几何或纯纹理风格化，以及可调节的风格强度控制。

Result: 广泛的实验表明，StyleSculptor在生成高保真3D资产方面优于现有基线方法。

Conclusion: StyleSculptor提供了一种新颖有效的零样本方法，能够实现对3D资产纹理、几何或两者风格的细粒度控制，从而生成高质量的风格引导3D内容。

Abstract: Creating 3D assets that follow the texture and geometry style of existing
ones is often desirable or even inevitable in practical applications like video
gaming and virtual reality. While impressive progress has been made in
generating 3D objects from text or images, creating style-controllable 3D
assets remains a complex and challenging problem. In this work, we propose
StyleSculptor, a novel training-free approach for generating style-guided 3D
assets from a content image and one or more style images. Unlike previous
works, StyleSculptor achieves style-guided 3D generation in a zero-shot manner,
enabling fine-grained 3D style control that captures the texture, geometry, or
both styles of user-provided style images. At the core of StyleSculptor is a
novel Style Disentangled Attention (SD-Attn) module, which establishes a
dynamic interaction between the input content image and style image for
style-guided 3D asset generation via a cross-3D attention mechanism, enabling
stable feature fusion and effective style-guided generation. To alleviate
semantic content leakage, we also introduce a style-disentangled feature
selection strategy within the SD-Attn module, which leverages the variance of
3D feature patches to disentangle style- and content-significant channels,
allowing selective feature injection within the attention framework. With
SD-Attn, the network can dynamically compute texture-, geometry-, or
both-guided features to steer the 3D generation process. Built upon this, we
further propose the Style Guided Control (SGC) mechanism, which enables
exclusive geometry- or texture-only stylization, as well as adjustable style
intensity control. Extensive experiments demonstrate that StyleSculptor
outperforms existing baseline methods in producing high-fidelity 3D assets.

</details>


### [152] [3D Aware Region Prompted Vision Language Model](https://arxiv.org/abs/2509.13317)
*An-Chieh Cheng,Yang Fu,Yukang Chen,Zhijian Liu,Xiaolong Li,Subhashree Radhakrishnan,Song Han,Yao Lu,Jan Kautz,Pavlo Molchanov,Hongxu Yin,Xiaolong Wang,Sifei Liu*

Main category: cs.CV

TL;DR: SR-3D是一个连接2D图像和3D数据的视觉语言模型，通过共享视觉token空间实现灵活的区域提示和增强的3D空间推理，并在多项基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在连接单视角2D图像和多视角3D数据，以及在缺乏详尽多帧标注的情况下进行准确的跨帧空间推理方面存在挑战，尤其当感兴趣的物体不在同一视图中共同出现时。

Method: 本文提出了Spatial Region 3D (SR-3D) 感知视觉语言模型。它通过共享的视觉token空间连接单视角2D图像和多视角3D数据。SR-3D支持灵活的区域提示（2D边界框、分割掩码或直接在3D中），无需详尽的多帧标注。其核心是通过3D位置嵌入丰富2D视觉特征，使3D模型能够利用强大的2D先验知识进行更准确的跨帧空间推理。

Result: SR-3D在通用2D视觉语言和专用3D空间基准测试上均达到了最先进的性能，证明了其在场景理解中统一2D和3D表示空间的有效性。此外，即使在没有传感器3D输入或真值3D标注的野外视频中，SR-3D也能准确推断空间关系和度量测量。

Conclusion: SR-3D成功地统一了2D和3D表示空间，显著提高了场景理解能力，并在灵活区域提示和跨帧空间推理方面表现出色，展现了其在实际应用中的广泛潜力。

Abstract: We present Spatial Region 3D (SR-3D) aware vision-language model that
connects single-view 2D images and multi-view 3D data through a shared visual
token space. SR-3D supports flexible region prompting, allowing users to
annotate regions with bounding boxes, segmentation masks on any frame, or
directly in 3D, without the need for exhaustive multi-frame labeling. We
achieve this by enriching 2D visual features with 3D positional embeddings,
which allows the 3D model to draw upon strong 2D priors for more accurate
spatial reasoning across frames, even when objects of interest do not co-occur
within the same view. Extensive experiments on both general 2D vision language
and specialized 3D spatial benchmarks demonstrate that SR-3D achieves
state-of-the-art performance, underscoring its effectiveness for unifying 2D
and 3D representation space on scene understanding. Moreover, we observe
applicability to in-the-wild videos without sensory 3D inputs or ground-truth
3D annotations, where SR-3D accurately infers spatial relationships and metric
measurements.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [153] [MTEB-NL and E5-NL: Embedding Benchmark and Models for Dutch](https://arxiv.org/abs/2509.12340)
*Nikolay Banar,Ehsan Lotfi,Jens Van Nooten,Cristina Arhiliuc,Marija Kliocaite,Walter Daelemans*

Main category: cs.CL

TL;DR: 该研究针对荷兰语嵌入资源不足的问题，推出了MTEB-NL基准测试、一个训练数据集以及一系列高效的E5-NL模型，以促进荷兰语嵌入的评估和发展。


<details>
  <summary>Details</summary>
Motivation: 荷兰语在多语言嵌入资源中代表性不足，仅占已发布资源的一小部分，导致缺乏针对荷兰语嵌入的评估和生成工具。

Method: 1. 引入了荷兰语大规模文本嵌入基准测试（MTEB-NL），包含现有和新创建的荷兰语数据集，覆盖广泛任务。2. 提供了一个训练数据集，该数据集由现有荷兰语检索数据集编译而成，并辅以大型语言模型生成的合成数据以扩大任务覆盖范围。3. 发布了一系列紧凑高效的E5-NL嵌入模型。

Result: E5-NL模型在多项任务中表现出强大的性能。所有资源均通过Hugging Face Hub和MTEB包公开可用。

Conclusion: 该研究通过提供评估基准（MTEB-NL）、训练数据集和高性能的E5-NL模型，成功弥补了荷兰语嵌入资源的空白，鼓励了荷兰语嵌入的进一步发展。

Abstract: Recently, embedding resources, including models, benchmarks, and datasets,
have been widely released to support a variety of languages. However, the Dutch
language remains underrepresented, typically comprising only a small fraction
of the published multilingual resources. To address this gap and encourage the
further development of Dutch embeddings, we introduce new resources for their
evaluation and generation. First, we introduce the Massive Text Embedding
Benchmark for Dutch (MTEB-NL), which includes both existing Dutch datasets and
newly created ones, covering a wide range of tasks. Second, we provide a
training dataset compiled from available Dutch retrieval datasets, complemented
with synthetic data generated by large language models to expand task coverage
beyond retrieval. Finally, we release a series of E5-NL models compact yet
efficient embedding models that demonstrate strong performance across multiple
tasks. We make our resources publicly available through the Hugging Face Hub
and the MTEB package.

</details>


### [154] [MORABLES: A Benchmark for Assessing Abstract Moral Reasoning in LLMs with Fables](https://arxiv.org/abs/2509.12371)
*Matteo Marcuzzo,Alessandro Zangari,Andrea Albarelli,Jose Camacho-Collados,Mohammad Taher Pilehvar*

Main category: cs.CL

TL;DR: 本研究引入了MORABLES基准测试，用于评估大型语言模型（LLMs）在文学作品中的复杂道德推理能力。结果显示，LLMs虽然规模越大表现越好，但仍易受对抗性操纵，依赖肤浅模式而非真正推理，且存在显著的自我矛盾。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在标准阅读理解基准测试中表现出色，但人们对其复杂抽象推理和推断能力的评估仍有待深入。基于文学的基准测试因其丰富的叙事和道德深度，为评估这种更深层次的理解技能提供了有力的框架。

Method: 本研究构建了MORABLES，一个由历史文学中的寓言和短篇故事组成的人工验证基准测试。主要任务是多项选择题，旨在进行道德推断，并设计了精心制作的干扰项，以挑战模型超越肤浅的提取式问答。为进一步压力测试模型的鲁棒性，研究还引入了对抗性变体，旨在揭示LLM因数据污染等问题导致的漏洞和捷径。

Result: 研究发现，虽然大型模型优于小型模型，但它们仍然容易受到对抗性操纵，并且经常依赖肤浅模式而非真正的道德推理。这种脆弱性导致了显著的自我矛盾，即使是最好的模型，在约20%的情况下也会根据道德选择的表述方式推翻自己的答案。有趣的是，推理增强模型未能弥补这一差距，表明规模而非推理能力是性能的主要驱动因素。

Conclusion: LLMs，即使是大型模型，在道德推理方面仍缺乏鲁棒性，容易受到对抗性攻击，并倾向于依赖表面模式。当前的“推理增强”方法未能有效解决此问题，暗示性能的提升主要源于模型规模的扩大而非推理能力的实质性进步。

Abstract: As LLMs excel on standard reading comprehension benchmarks, attention is
shifting toward evaluating their capacity for complex abstract reasoning and
inference. Literature-based benchmarks, with their rich narrative and moral
depth, provide a compelling framework for evaluating such deeper comprehension
skills. Here, we present MORABLES, a human-verified benchmark built from fables
and short stories drawn from historical literature. The main task is structured
as multiple-choice questions targeting moral inference, with carefully crafted
distractors that challenge models to go beyond shallow, extractive question
answering. To further stress-test model robustness, we introduce adversarial
variants designed to surface LLM vulnerabilities and shortcuts due to issues
such as data contamination. Our findings show that, while larger models
outperform smaller ones, they remain susceptible to adversarial manipulation
and often rely on superficial patterns rather than true moral reasoning. This
brittleness results in significant self-contradiction, with the best models
refuting their own answers in roughly 20% of cases depending on the framing of
the moral choice. Interestingly, reasoning-enhanced models fail to bridge this
gap, suggesting that scale - not reasoning ability - is the primary driver of
performance.

</details>


### [155] [LLM-as-a-Judge: Rapid Evaluation of Legal Document Recommendation for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.12382)
*Anu Pradhan,Alexandra Ortan,Apurv Verma,Madhavan Seshadri*

Main category: cs.CL

TL;DR: 本研究探讨了在法律领域中，使用大型语言模型（LLM）作为评估者（LLM-as-a-Judge）来评估检索增强生成（RAG）系统的可行性，并提出了更稳健的评估指标和统计比较方法，以解决传统评估瓶颈。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的兴起，推荐系统（特别是RAG系统）的评估瓶颈日益突出，传统指标难以捕捉法律研究等专业领域中细致的质量维度。研究动机在于探究LLM是否能作为可靠的评估者，并解决在法律背景下，评估高质量推荐系统所面临的严峻挑战。

Method: 通过系统实验，研究了两个核心问题：哪些评估者间一致性指标能最好地捕捉LLM与人类评估之间的一致性，以及如何对竞争系统进行统计学上可靠的比较。方法包括测试不同的评估者间信度指标和统计检验方法。

Result: 研究发现，传统的协议指标（如Krippendorff's alpha）在AI系统评估中常见的偏斜分布下可能产生误导。Gwet's AC2和秩相关系数被证明是更稳健的评判者选择指标。此外，结合Benjamini-Hochberg校正的Wilcoxon符号秩检验为可靠的系统比较提供了必要的统计严谨性。

Conclusion: 研究结果为实现可扩展、成本效益高、自动化且统计学上严谨的评估框架指明了方向，能够满足法律应用对精度的严苛要求，将原本人力密集型的评估瓶颈转化为高效的自动化流程。

Abstract: The evaluation bottleneck in recommendation systems has become particularly
acute with the rise of Generative AI, where traditional metrics fall short of
capturing nuanced quality dimensions that matter in specialized domains like
legal research. Can we trust Large Language Models to serve as reliable judges
of their own kind? This paper investigates LLM-as-a-Judge as a principled
approach to evaluating Retrieval-Augmented Generation systems in legal
contexts, where the stakes of recommendation quality are exceptionally high.
  We tackle two fundamental questions that determine practical viability: which
inter-rater reliability metrics best capture the alignment between LLM and
human assessments, and how do we conduct statistically sound comparisons
between competing systems? Through systematic experimentation, we discover that
traditional agreement metrics like Krippendorff's alpha can be misleading in
the skewed distributions typical of AI system evaluations. Instead, Gwet's AC2
and rank correlation coefficients emerge as more robust indicators for judge
selection, while the Wilcoxon Signed-Rank Test with Benjamini-Hochberg
corrections provides the statistical rigor needed for reliable system
comparisons.
  Our findings suggest a path toward scalable, cost-effective evaluation that
maintains the precision demanded by legal applications, transforming what was
once a human-intensive bottleneck into an automated, yet statistically
principled, evaluation framework.

</details>


### [156] [SENTRA: Selected-Next-Token Transformer for LLM Text Detection](https://arxiv.org/abs/2509.12385)
*Mitchell Plyler,Yilun Zhang,Alexander Tuzhilin,Saoud Khalifah,Sen Tian*

Main category: cs.CL

TL;DR: 本文提出了一种名为SENTRA的新型Transformer编码器，用于检测未明确声明的LLM生成文本，通过对比预训练和选定下一词元概率序列，在域外设置中显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的能力日益增强和普及，其被滥用的可能性和现实性也在增长。研究旨在解决检测未明确声明为LLM生成文本的问题。

Method: 本文提出了一种新颖的、通用的、监督式LLM文本检测器——SENTRA（SElected-Next-Token tRAnsformer）。SENTRA是一个基于Transformer的编码器，它利用选定下一词元概率序列，并通过对比预训练在大规模未标记数据上进行训练。

Result: 在涵盖24个文本领域的三个流行公共数据集上的实验表明，SENTRA作为一种通用分类器，在域外（out-of-domain）设置中显著优于流行的基线方法。

Conclusion: SENTRA成功地解决了检测未明确声明的LLM生成文本的问题，并展示了其作为通用分类器在不同领域中的强大泛化能力和卓越性能。

Abstract: LLMs are becoming increasingly capable and widespread. Consequently, the
potential and reality of their misuse is also growing. In this work, we address
the problem of detecting LLM-generated text that is not explicitly declared as
such. We present a novel, general-purpose, and supervised LLM text detector,
SElected-Next-Token tRAnsformer (SENTRA). SENTRA is a Transformer-based encoder
leveraging selected-next-token-probability sequences and utilizing contrastive
pre-training on large amounts of unlabeled data. Our experiments on three
popular public datasets across 24 domains of text demonstrate SENTRA is a
general-purpose classifier that significantly outperforms popular baselines in
the out-of-domain setting.

</details>


### [157] [MORQA: Benchmarking Evaluation Metrics for Medical Open-Ended Question Answering](https://arxiv.org/abs/2509.12405)
*Wen-wai Yim,Asma Ben Abacha,Zixuan Yu,Robert Doerning,Fei Xia,Meliha Yetisgen*

Main category: cs.CL

TL;DR: 本文提出了MORQA，一个多语言医学开放式问答基准，旨在评估NLG评估指标。研究发现，LLM（大型语言模型）评估器在医学领域与专家判断的相关性显著优于传统指标。


<details>
  <summary>Details</summary>
Motivation: 由于对准确性、相关性和领域专业知识的严格要求，医学领域的自然语言生成（NLG）系统评估面临独特挑战。传统的自动评估指标在区分高质量输出方面表现不足，尤其是在医学开放式问答任务中，存在多种有效回答的情况。

Method: 研究引入了MORQA（Medical Open-Response QA），一个多语言（英语和中文）基准，用于评估NLG评估指标在三个医学视觉和文本问答数据集上的有效性。该数据集包含2-4个由医学专业人员撰写的黄金标准答案，以及专家对部分英语和中文子集的评分。研究基准测试了传统的评估指标（如BLEU、ROUGE、BERTScore）和基于大型语言模型（LLM）的评估器（如GPT-4和Gemini）。

Result: 研究发现，基于LLM的方法在与专家判断的相关性方面显著优于传统指标。进一步分析表明，LLM在语义细微差别方面的敏感性和对参考答案变异性的鲁棒性是其改进的关键因素。

Conclusion: 这项研究提供了医学领域NLG评估的首次全面、多语言定性研究，强调了对与人类判断对齐的评估方法的需求。所有数据集和注释将公开发布以支持未来的研究。

Abstract: Evaluating natural language generation (NLG) systems in the medical domain
presents unique challenges due to the critical demands for accuracy, relevance,
and domain-specific expertise. Traditional automatic evaluation metrics, such
as BLEU, ROUGE, and BERTScore, often fall short in distinguishing between
high-quality outputs, especially given the open-ended nature of medical
question answering (QA) tasks where multiple valid responses may exist. In this
work, we introduce MORQA (Medical Open-Response QA), a new multilingual
benchmark designed to assess the effectiveness of NLG evaluation metrics across
three medical visual and text-based QA datasets in English and Chinese. Unlike
prior resources, our datasets feature 2-4+ gold-standard answers authored by
medical professionals, along with expert human ratings for three English and
Chinese subsets. We benchmark both traditional metrics and large language model
(LLM)-based evaluators, such as GPT-4 and Gemini, finding that LLM-based
approaches significantly outperform traditional metrics in correlating with
expert judgments. We further analyze factors driving this improvement,
including LLMs' sensitivity to semantic nuances and robustness to variability
among reference answers. Our results provide the first comprehensive,
multilingual qualitative study of NLG evaluation in the medical domain,
highlighting the need for human-aligned evaluation methods. All datasets and
annotations will be publicly released to support future research.

</details>


### [158] [MedFact: Benchmarking the Fact-Checking Capabilities of Large Language Models on Chinese Medical Texts](https://arxiv.org/abs/2509.12440)
*Jiayi He,Yangmin Huang,Qianyun Du,Xiangying Zhou,Zhiyang He,Jiaxue Hu,Xiaodong Tao,Lixian Lai*

Main category: cs.CL

TL;DR: 本文介绍了MedFact，一个用于中文医疗事实核查的新基准，旨在评估大型语言模型（LLMs）的真实性。结果显示LLMs在错误定位方面表现不佳，并存在“过度批评”现象，突出了其在医疗应用中的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在医疗领域的广泛应用，对其事实可靠性进行严格评估的需求日益增长。然而，现有基准往往受限于狭窄的数据领域，无法捕捉真实世界医疗信息的复杂性，因此需要一个更全面、更具挑战性的评估工具。

Method: 研究引入了MedFact基准，包含2,116个由专家标注的实例，涵盖13个医疗专业、8种细粒度错误类型、4种写作风格和多个难度级别。其构建采用混合AI-人工框架，通过迭代专家反馈和AI驱动的多标准过滤过程，确保数据的高质量和难度。研究评估了20个主流LLMs在真实性分类和错误定位方面的表现，并与人类专家基线进行了对比。

Result: 评估结果表明，LLMs通常能够判断文本是否包含错误，但在精确错误定位方面仍面临巨大挑战，即使是表现最佳的模型也远低于人类水平。此外，研究发现LLMs存在频繁的“过度批评”现象，即倾向于将正确信息误判为错误，这种现象在使用多智能体协作和推理时扩展等高级推理技术时尤为突出。

Conclusion: MedFact基准揭示了LLMs在医疗应用中部署所面临的关键挑战，并提供了一个强大的资源，以推动开发出更具事实可靠性和医学意识的模型。

Abstract: The increasing deployment of Large Language Models (LLMs) in healthcare
necessitates a rigorous evaluation of their factual reliability. However,
existing benchmarks are often limited by narrow domains of data, failing to
capture the complexity of real-world medical information. To address this
critical gap, we introduce MedFact, a new and challenging benchmark for Chinese
medical fact-checking. MedFact comprises 2,116 expert-annotated instances
curated from diverse real-world texts, spanning 13 medical specialties, 8
fine-grained error types, 4 writing styles, and multiple difficulty levels. Its
construction employs a hybrid AI-human framework where iterative expert
feedback refines an AI-driven, multi-criteria filtering process, ensuring both
high data quality and difficulty. We conduct a comprehensive evaluation of 20
leading LLMs, benchmarking their performance on veracity classification and
error localization against a human expert baseline. Our results reveal that
while models can often determine if a text contains an error, precisely
localizing it remains a substantial challenge, with even top-performing models
falling short of human performance. Furthermore, our analysis uncovers a
frequent ``over-criticism'' phenomenon, a tendency for models to misidentify
correct information as erroneous, which is exacerbated by advanced reasoning
techniques such as multi-agent collaboration and inference-time scaling. By
highlighting these critical challenges for deploying LLMs in medical
applications, MedFact provides a robust resource to drive the development of
more factually reliable and medically aware models.

</details>


### [159] [Topic Coverage-based Demonstration Retrieval for In-Context Learning](https://arxiv.org/abs/2509.12451)
*Wonbin Kweon,SeongKu Kang,Runchu Tian,Pengcheng Jiang,Jiawei Han,Hwanjo Yu*

Main category: cs.CL

TL;DR: 本文提出TopicK框架，通过全面覆盖主题级别知识来选择上下文学习的示例，以解决现有方法选择不相关或冗余示例的问题。


<details>
  <summary>Details</summary>
Motivation: 上下文学习的效果严重依赖于选择能提供所有必要信息的示例。然而，现有方法通常仅基于嵌入相似性或生成概率检索示例，导致选出不相关或冗余的示例，未能覆盖细粒度知识需求。

Method: 本文提出TopicK，一个基于主题覆盖的检索框架。它估算输入所需的主题，评估模型在这些主题上的知识水平，然后迭代选择能引入先前未覆盖的所需主题且模型在该主题上知识较少的示例。

Result: 通过在各种数据集以及开源和闭源大型语言模型上的广泛实验，验证了TopicK的有效性。

Conclusion: TopicK通过全面覆盖与测试输入和模型相关的主题级别知识，显著提高了上下文学习中示例选择的质量和效率。

Abstract: The effectiveness of in-context learning relies heavily on selecting
demonstrations that provide all the necessary information for a given test
input. To achieve this, it is crucial to identify and cover fine-grained
knowledge requirements. However, prior methods often retrieve demonstrations
based solely on embedding similarity or generation probability, resulting in
irrelevant or redundant examples. In this paper, we propose TopicK, a topic
coverage-based retrieval framework that selects demonstrations to
comprehensively cover topic-level knowledge relevant to both the test input and
the model. Specifically, TopicK estimates the topics required by the input and
assesses the model's knowledge on those topics. TopicK then iteratively selects
demonstrations that introduce previously uncovered required topics, in which
the model exhibits low topical knowledge. We validate the effectiveness of
TopicK through extensive experiments across various datasets and both open- and
closed-source LLMs. Our source code is available at
https://github.com/WonbinKweon/TopicK_EMNLP2025.

</details>


### [160] [Does Language Model Understand Language?](https://arxiv.org/abs/2509.12459)
*Suvojit Acharjee,Utathya Aich,Asfak Ali*

Main category: cs.CL

TL;DR: 本研究评估了SOTA语言模型在英语和孟加拉语中处理时态、否定、语态等细粒度语言现象的能力。通过引入新的LUCID数据集和HCE准确度等指标，发现Compound-Beta模型表现最均衡，与人类判断高度一致。


<details>
  <summary>Details</summary>
Motivation: 尽管自然语言生成和理解技术有所进步，但语言模型在处理时态、否定、语态和情态等对有效人类交流至关重要的细粒度语言现象时仍面临挑战。在联合国可持续发展目标4（教育）的背景下，语言清晰度至关重要，因此评估语言模型在教育技术中部署的准确性及其与人类语言解释的一致性变得尤为关键。

Method: 本研究评估了MISTRAL-SABA-24B、LLaMA-4-Scout-17B、LLaMA-3.3-70B、Gemma2-9B和Compound-Beta等SOTA语言模型。引入了一套新的“系统环境中认知推理评估路线”（Route for Evaluation of Cognitive Inference in Systematic Environments）指导方针，并构建了LUCID数据集，该数据集包含精心设计的英语和孟加拉语句对，专门用于挑战模型在否定、时态、语态变化等方面的理解能力。评估指标包括皮尔逊相关系数、斯皮尔曼相关系数、平均绝对误差（MAE），以及一种新颖的、受语言学启发的HCE准确度，该指标衡量模型预测落在人类平均评分一个标准差范围内的频率。

Result: 研究发现Compound-Beta是表现最均衡的模型，在不同的语言条件下均能持续实现高相关性和低MAE。它在英语中取得了最高的皮尔逊相关系数，并在混合语言数据上表现出稳健性，表明在跨语言场景中与人类判断高度一致。

Conclusion: Compound-Beta模型在处理细粒度语言现象和跨语言场景方面表现出卓越的性能，与人类语言解释高度对齐。这一发现对于在教育技术等需要高语言清晰度的应用中部署语言模型具有重要意义。

Abstract: Despite advances in natural language generation and understanding, LM still
struggle with fine grained linguistic phenomena such as tense, negation, voice,
and modality which are the elements central to effective human communication.
In the context of the United Nations SDG 4, where linguistic clarity is
critical, the deployment of LMs in educational technologies demands careful
scrutiny. As LMs are increasingly powering applications like tutoring systems,
automated grading, and translation, their alignment with human linguistic
interpretation becomes essential for effective learning. In this study, we
conduct a evaluation of SOTA language models across these challenging contexts
in both English and Bengali. To ensure a structured assessment, we introduce a
new Route for Evaluation of Cognitive Inference in Systematic Environments
guidelines. Our proposed LUCID dataset, composed of carefully crafted sentence
pairs in English and Bengali, specifically challenges these models on critical
aspects of language comprehension, including negation, tense, voice variations.
We assess the performance of SOTA models including MISTRAL-SABA-24B,
LLaMA-4-Scout-17B, LLaMA-3.3-70B, Gemma2-9B, and Compound-Beta using standard
metrics like Pearson correlation, Spearman correlation, and Mean Absolute
Error, as well as novel, linguistically inspired metric the HCE accuracy. The
HCE accuracy measures how often model predictions fall within one standard
deviation of the mean human rating, thus capturing human like tolerance for
variability in language interpretation. Our findings highlight Compound-Beta as
the most balanced model, consistently achieving high correlations and low MAEs
across diverse language conditions. It records the highest Pearson correlation
in English and demonstrates robust performance on mixed-language data,
indicating a strong alignment with human judgments in cross lingual scenarios.

</details>


### [161] [Audited Reasoning Refinement: Fine-Tuning Language Models via LLM-Guided Step-Wise Evaluation and Correction](https://arxiv.org/abs/2509.12476)
*Sumanta Bhattacharyya,Sara Riaz,Pedram Rooshenas*

Main category: cs.CL

TL;DR: 该研究提出Reason-Refine-then-Align (R2tA)方法，利用大型语言模型（LLMs）生成的、经过精炼的推理轨迹作为监督信号，来训练特定任务的小型推理模型，尤其适用于数据稀缺的领域，并通过评估扩展实体关系图（EERD）进行了验证。


<details>
  <summary>Details</summary>
Motivation: 在缺乏直接人工监督或高质量标签的情况下，训练特定任务的小型推理模型极具挑战性。然而，具有推理能力的LLMs能够生成大量的中间推理轨迹，这些轨迹可以被系统地精炼，从而创建有效的监督信号。

Method: R2tA方法首先使用开源基础模型生成任务特定的初始推理和响应，然后精炼这些轨迹，纠正幻觉和不一致性，以形成高质量的数据集。接着，进行两阶段对齐：首先是监督微调（SFT），然后是直接偏好优化（DPO），以使模型的中间推理与人类验证的概念偏好对齐，并在此对齐的推理基础上生成最终输出。案例研究应用于数据库系统设计中的EERD评估，构建了一个包含600个EERD变体的定制数据集。

Result: 实证评估表明，R2tA为在数据稀缺领域实现LLM的可扩展适应提供了一条实用且成本效益高的方法，从而能够为教育及其他领域提供可复现的AI工具。

Conclusion: R2tA是一种有效且经济的方法，可以在数据稀缺的环境下，利用大型语言模型精炼的推理过程作为监督，训练出特定任务的小型推理模型，并有望推广应用于教育等领域，提供可靠的AI工具。

Abstract: Training a task-specific small reasoning model is challenging when direct
human supervision or high-quality labels are scarce. However, LLMs with
reasoning capabilities produce abundant intermediate reasoning traces that can
be systematically refined to create effective supervision signals. We propose
Reason-Refine-then-Align (R2tA), which turns refined model rationales into
supervision for training task-specific reasoning models. Our method generates
initial reasoning and responses from an open-source base model on task-specific
inputs, then refines these traces, fixing hallucinations and inconsistencies,
to form a high-fidelity dataset. We perform a two-stage alignment, supervised
fine-tuning (SFT), followed by direct preference optimization (DPO) to
calibrate the model's intermediate reasoning with human-validated conceptual
preferences and then condition the final output on that aligned reasoning. As a
case study, we apply R2tA to evaluate extended entity relationship diagrams
(EERDs) in database system design, a structurally complex task where
prompt-only methods miss or hallucinate errors. We curated a dataset of 600
EERD variants (train/test split of 450/150, respectively) with induced mistakes
spanning 11 categories. Empirical evaluation suggests R2tA provides a
practical, cost-effective path to scalable LLM adaptation in data-scarce
domains, enabling reproducible AI tools for education and beyond.

</details>


### [162] [FunAudio-ASR Technical Report](https://arxiv.org/abs/2509.12508)
*Keyu An,Yanni Chen,Chong Deng,Changfeng Gao,Zhifu Gao,Bo Gong,Xiangang Li,Yabin Li,Xiang Lv,Yunjie Ji,Yiheng Jiang,Bin Ma,Haoneng Luo,Chongjia Ni,Zexu Pan,Yiping Peng,Zhendong Peng,Peiyao Wang,Hao Wang,Wen Wang,Wupeng Wang,Biao Tian,Zhentao Tan,Nan Yang,Bin Yuan,Jieping Ye,Jixing Yu,Qinglin Zhang,Kun Zou,Han Zhao,Shengkui Zhao,Jingren Zhou*

Main category: cs.CL

TL;DR: 本文提出了FunAudio-ASR，一个大规模、基于LLM的ASR系统，它结合了大数据、大模型、LLM集成和强化学习，并针对实际部署进行了优化，在真实应用数据上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM驱动的ASR系统取得了显著进步，但它们容易产生幻觉，并且在开源基准测试上表现良好，但在真实的工业评估集上往往表现不佳，这会严重影响用户体验。

Method: FunAudio-ASR通过协同结合海量数据、大模型容量、LLM集成和强化学习来实现最先进的性能。此外，它还针对实际部署进行了优化，包括流式处理能力、噪声鲁棒性、语码转换、热词定制等。

Result: 实验结果表明，FunAudio-ASR在真实应用数据集上取得了最先进（SOTA）的性能，证明了其在实际环境中的有效性和鲁棒性，而其他LLM-based ASR系统在工业评估集上常表现不佳。

Conclusion: FunAudio-ASR通过其面向生产的优化和综合方法，在复杂多样的语音识别场景中展现了卓越的性能和鲁棒性，有效解决了LLM-based ASR在实际部署中的挑战。

Abstract: In recent years, automatic speech recognition (ASR) has witnessed
transformative advancements driven by three complementary paradigms: data
scaling, model size scaling, and deep integration with large language models
(LLMs). However, LLMs are prone to hallucination, which can significantly
degrade user experience in real-world ASR applications. In this paper, we
present FunAudio-ASR, a large-scale, LLM-based ASR system that synergistically
combines massive data, large model capacity, LLM integration, and reinforcement
learning to achieve state-of-the-art performance across diverse and complex
speech recognition scenarios. Moreover, FunAudio-ASR is specifically optimized
for practical deployment, with enhancements in streaming capability, noise
robustness, code-switching, hotword customization, and satisfying other
real-world application requirements. Experimental results show that while most
LLM-based ASR systems achieve strong performance on open-source benchmarks,
they often underperform on real industry evaluation sets. Thanks to
production-oriented optimizations, FunAudio-ASR achieves SOTA performance on
real application datasets, demonstrating its effectiveness and robustness in
practical settings.

</details>


### [163] [A comparison of pipelines for the translation of a low resource language based on transformers](https://arxiv.org/abs/2509.12514)
*Chiara Bonfanti,Michele Colombino,Giulia Coucourde,Faeze Memari,Stefano Pinardi,Rosa Meo*

Main category: cs.CL

TL;DR: 本研究比较了三种用于法语-班巴拉语机器翻译的Transformer神经网络训练流程，发现尽管结构更简单，但直接训练的Transformer模型在低资源语言翻译中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 旨在改进班巴拉语（一种非洲低资源语言）的机器翻译质量，并比较不同Transformer训练方法（包括LLaMA3微调和语言蒸馏）在该任务上的效果。

Method: 1. 简单Transformer模型直接训练法语-班巴拉语翻译。2. 微调LLaMA3 (3B-8B) 指导模型，采用仅解码器架构。3. 使用语言蒸馏将班巴拉语整合到预训练的LaBSE模型中，并应用BERT扩展进行翻译。所有模型均使用BLEU和chrF分数进行评估，并在Dokotoro、Bayelemagaba和Yiri数据集上进行测试。

Result: 结果显示，第一个更简单的Transformer流程实现了最佳翻译准确性（Bayelemagaba数据集上BLEU 10%，chrF 21%；Yiri数据集上BLEU 33.81%，chrF 41%）。基于指导者的模型在单一数据集上的表现优于聚合数据集，表明它们更有效地捕捉数据集特有的模式。

Conclusion: 对于低资源的法语-班巴拉语翻译任务，直接训练的简单Transformer模型表现最佳，这与低资源翻译的普遍发现一致。基于指导者的模型在特定数据集上表现出优势，可能更适合捕获数据集的特定特征。

Abstract: This work compares three pipelines for training transformer-based neural
networks to produce machine translators for Bambara, a Mand\`e language spoken
in Africa by about 14,188,850 people. The first pipeline trains a simple
transformer to translate sentences from French into Bambara. The second
fine-tunes LLaMA3 (3B-8B) instructor models using decoder-only architectures
for French-to-Bambara translation. Models from the first two pipelines were
trained with different hyperparameter combinations to improve BLEU and chrF
scores, evaluated on both test sentences and official Bambara benchmarks. The
third pipeline uses language distillation with a student-teacher dual neural
network to integrate Bambara into a pre-trained LaBSE model, which provides
language-agnostic embeddings. A BERT extension is then applied to LaBSE to
generate translations. All pipelines were tested on Dokotoro (medical) and
Bayelemagaba (mixed domains). Results show that the first pipeline, although
simpler, achieves the best translation accuracy (10% BLEU, 21% chrF on
Bayelemagaba), consistent with low-resource translation results. On the Yiri
dataset, created for this work, it achieves 33.81% BLEU and 41% chrF.
Instructor-based models perform better on single datasets than on aggregated
collections, suggesting they capture dataset-specific patterns more
effectively.

</details>


### [164] [MAGIC-Enhanced Keyword Prompting for Zero-Shot Audio Captioning with CLIP Models](https://arxiv.org/abs/2509.12591)
*Vijay Govindarajan,Pratik Patel,Sahil Tripathi,Md Azizul Hoque,Gautam Siddharth Kashyap*

Main category: cs.CL

TL;DR: 本文提出了一种零样本自动音频字幕 (AAC) 系统，利用预训练的音频 CLIP 模型提取特征并引导大型语言模型 (LLM) 生成字幕。该系统通过音频 CLIP 模型精炼 token 选择，实现了显著的性能提升，特别是在使用 MAGIC 搜索和关键词提示时。


<details>
  <summary>Details</summary>
Motivation: 自动音频字幕 (AAC) 面临数据集有限的挑战，远不及图像字幕领域。为了克服这一限制，研究旨在开发一个无需大量训练数据，利用预训练模型即可工作的零样本 AAC 系统。

Method: 该方法构建了一个零样本 AAC 系统，利用预训练的音频 CLIP 模型提取听觉特征并生成结构化提示。这些提示随后引导大型语言模型 (LLM) 生成字幕。与传统的贪婪解码不同，该系统通过音频 CLIP 模型精炼 token 选择，以确保与音频内容的对齐。

Result: 实验结果表明，使用 WavCaps 模型进行 MAGIC 搜索时，NLG 平均得分提高了 35%（从 4.7 提高到 7.3）。性能受音频-文本匹配模型和关键词选择的严重影响，使用单个关键词提示可获得最佳结果，而未使用关键词列表时性能下降 50%。

Conclusion: 所提出的零样本 AAC 系统通过利用预训练模型有效解决了数据限制问题。音频-文本匹配模型和关键词选择对系统性能至关重要，MAGIC 搜索策略显著提高了字幕生成的质量和与音频内容的对齐度。

Abstract: Automated Audio Captioning (AAC) generates captions for audio clips but faces
challenges due to limited datasets compared to image captioning. To overcome
this, we propose the zero-shot AAC system that leverages pre-trained models,
eliminating the need for extensive training. Our approach uses a pre-trained
audio CLIP model to extract auditory features and generate a structured prompt,
which guides a Large Language Model (LLM) in caption generation. Unlike
traditional greedy decoding, our method refines token selection through the
audio CLIP model, ensuring alignment with the audio content. Experimental
results demonstrate a 35% improvement in NLG mean score (from 4.7 to 7.3) using
MAGIC search with the WavCaps model. The performance is heavily influenced by
the audio-text matching model and keyword selection, with optimal results
achieved using a single keyword prompt, and a 50% performance drop when no
keyword list is used.

</details>


### [165] [EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving](https://arxiv.org/abs/2509.12603)
*Mukai Li,Linfeng Song,Zhenwen Liang,Jiahao Xu,Shansan Gong,Qi Liu,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在自动化定理证明（ATP）中表现出色，但其测试时扩展策略（如CoT和增加采样次数）导致高昂的计算成本。本文提出了EconProver，通过动态CoT切换和可训练前缀的RL方法，显著降低了计算成本，同时保持了原有性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在ATP中通过反射式思维链（CoT）推理和增加采样次数等测试时扩展策略取得了显著性能提升，但这引入了巨大的推理计算开销。此外，现有成本分析通常只关注采样次数，而忽略了不同扩展策略引入的采样成本差异。

Method: 本文首先系统地比较了ATP模型不同测试时扩展策略的效率，并指出了现有最先进开源方法的低效性。然后，提出了EconRL统一管道，包含两种互补方法：1) 动态CoT切换机制，旨在减少不必要的token消耗；2) 具有可训练前缀的多样化并行强化学习（RL），以在受限采样次数下提高通过率。

Result: 在miniF2F和ProofNet数据集上的实验表明，EconProver在保持与基线方法相当的性能的同时，计算成本仅为基线方法的12%。

Conclusion: 这项工作为部署轻量级ATP模型提供了可行的见解，且无需牺牲性能。

Abstract: Large Language Models (LLMs) have recently advanced the field of Automated
Theorem Proving (ATP), attaining substantial performance gains through widely
adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT)
reasoning and increased sampling passes. However, they both introduce
significant computational overhead for inference. Moreover, existing cost
analyses typically regulate only the number of sampling passes, while
neglecting the substantial disparities in sampling costs introduced by
different scaling strategies. In this paper, we systematically compare the
efficiency of different test-time scaling strategies for ATP models and
demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source
approaches. We then investigate approaches to significantly reduce token usage
and sample passes while maintaining the original performance. Specifically, we
propose two complementary methods that can be integrated into a unified EconRL
pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching
mechanism designed to mitigate unnecessary token consumption, and (2) Diverse
parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance
pass rates under constrained sampling passes. Experiments on miniF2F and
ProofNet demonstrate that our EconProver achieves comparable performance to
baseline methods with only 12% of the computational cost. This work provides
actionable insights for deploying lightweight ATP models without sacrificing
performance.

</details>


### [166] [Positional Encoding via Token-Aware Phase Attention](https://arxiv.org/abs/2509.12635)
*Yu,Wang,Sheng Shen,Rémi Munos,Hongyuan Zhan,Yuandong Tian*

Main category: cs.CL

TL;DR: 研究发现RoPE在长文本中存在距离依赖偏差，限制了其性能。本文提出TAPA，一种新的位置编码方法，通过可学习的相位函数解决了此问题，在长文本建模和泛化能力上优于RoPE。


<details>
  <summary>Details</summary>
Motivation: RoPE（旋转位置嵌入）在注意力分数中引入了固有的距离依赖偏差，限制了其建模长文本的能力。现有的RoPE扩展方法通常需要在预训练后进行额外调整（如重缩放或超参数调优）。

Method: 本文提出Token-Aware Phase Attention (TAPA)，一种新的位置编码方法。TAPA将一个可学习的相位函数整合到注意力机制中。

Result: TAPA能够保持长距离的token交互，通过直接且轻量的微调扩展到更长的上下文，能够外推到未见的长度，并且在长文本上比RoPE系列模型取得了显著更低的困惑度。

Conclusion: TAPA通过引入可学习的相位函数，有效解决了RoPE在长文本建模中的局限性，实现了更好的长距离交互、上下文扩展和外推能力，并在长文本性能上超越了RoPE家族。

Abstract: We prove under practical assumptions that Rotary Positional Embedding (RoPE)
introduces an intrinsic distance-dependent bias in attention scores that limits
RoPE's ability to model long-context. RoPE extension methods may alleviate this
issue, but they typically require post-hoc adjustments after pretraining, such
as rescaling or hyperparameters retuning. This paper introduces Token-Aware
Phase Attention (TAPA), a new positional encoding method that incorporates a
learnable phase function into the attention mechanism. TAPA preserves token
interactions over long range, extends to longer contexts with direct and light
fine-tuning, extrapolates to unseen lengths, and attains significantly lower
perplexity on long-context than RoPE families.

</details>


### [167] [PAC: Pronunciation-Aware Contextualized Large Language Model-based Automatic Speech Recognition](https://arxiv.org/abs/2509.12647)
*Li Fu,Yu Xin,Sunlu Zeng,Lu Fan,Youzheng Wu,Xiaodong He*

Main category: cs.CL

TL;DR: 本文提出了一种发音感知语境化（PAC）框架，通过两阶段学习方法，有效解决了基于LLM的ASR系统中发音建模和同音异义词辨别两大挑战，尤其改善了对生词和长尾词的识别。


<details>
  <summary>Details</summary>
Motivation: 基于大型语言模型（LLM）的自动语音识别（ASR）系统在有效的发音建模和鲁棒的同音异义词辨别方面面临关键挑战，而这两点对于生词或长尾词的识别至关重要。

Method: 该方法采用两阶段学习范式：1. 引入发音引导的语境学习方法，采用交错的字形-音素语境建模策略，并结合纯字形干扰项，鼓励模型利用音素线索进行准确识别。2. 提出发音判别强化学习方法，通过扰动标签采样进一步增强模型区分语境化同音异义词的能力。

Result: 在公开的英语Librispeech和普通话AISHELL-1数据集上的实验结果表明，PAC框架相对于预训练的基于LLM的ASR模型，相对词错误率（WER）分别降低了30.2%和53.8%；相对于强基线，长尾词的偏置WER相对降低了31.8%和60.5%。

Conclusion: PAC框架显著提升了基于LLM的ASR系统的性能，尤其在发音建模和同音异义词辨别方面表现出色，有效改善了对生词和长尾词的识别能力。

Abstract: This paper presents a Pronunciation-Aware Contextualized (PAC) framework to
address two key challenges in Large Language Model (LLM)-based Automatic Speech
Recognition (ASR) systems: effective pronunciation modeling and robust
homophone discrimination. Both are essential for raw or long-tail word
recognition. The proposed approach adopts a two-stage learning paradigm. First,
we introduce a pronunciation-guided context learning method. It employs an
interleaved grapheme-phoneme context modeling strategy that incorporates
grapheme-only distractors, encouraging the model to leverage phonemic cues for
accurate recognition. Then, we propose a pronunciation-discriminative
reinforcement learning method with perturbed label sampling to further enhance
the model\'s ability to distinguish contextualized homophones. Experimental
results on the public English Librispeech and Mandarin AISHELL-1 datasets
indicate that PAC: (1) reduces relative Word Error Rate (WER) by 30.2% and
53.8% compared to pre-trained LLM-based ASR models, and (2) achieves 31.8% and
60.5% relative reductions in biased WER for long-tail words compared to strong
baselines, respectively.

</details>


### [168] [Don't Change My View: Ideological Bias Auditing in Large Language Models](https://arxiv.org/abs/2509.12652)
*Paul Kröger,Emilio Barkett*

Main category: cs.CL

TL;DR: 本文提出了一种模型无关的统计方法，通过分析大型语言模型（LLMs）输出的分布变化，来检测其是否存在意识形态偏见或被故意引导的情况，尤其适用于审计专有黑盒系统。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）日益嵌入产品中，其输出可能影响个人信仰并塑造公众舆论。如果LLMs的行为可以被故意引导至特定的意识形态立场（如政治或宗教观点），那么控制这些系统的人将对公共话语产生不成比例的影响。因此，开发检测此类引导尝试的方法至关重要。

Method: 研究团队调整了一种先前提出的统计方法，以适应意识形态偏见审计的新情境。该方法保持了原始框架的模型无关设计，无需访问语言模型的内部结构。相反，它通过分析LLM在与特定主题相关的提示上的输出分布变化来识别潜在的意识形态引导。这种设计使其特别适用于审计专有的黑盒系统。

Result: 通过一系列实验验证了该方法的有效性，展示了其在实际应用中的可行性，以及支持对LLM行为进行独立的、事后审计的潜力。

Conclusion: 所提出的方法能够有效检测大型语言模型中潜在的意识形态引导，尤其适用于黑盒系统，为独立审计LLM行为提供了关键工具，有助于防止其对公共话语产生不当影响。

Abstract: As large language models (LLMs) become increasingly embedded in products used
by millions, their outputs may influence individual beliefs and, cumulatively,
shape public opinion. If the behavior of LLMs can be intentionally steered
toward specific ideological positions, such as political or religious views,
then those who control these systems could gain disproportionate influence over
public discourse. Although it remains an open question whether LLMs can
reliably be guided toward coherent ideological stances and whether such
steering can be effectively prevented, a crucial first step is to develop
methods for detecting when such steering attempts occur. In this work, we adapt
a previously proposed statistical method to the new context of ideological bias
auditing. Our approach carries over the model-agnostic design of the original
framework, which does not require access to the internals of the language
model. Instead, it identifies potential ideological steering by analyzing
distributional shifts in model outputs across prompts that are thematically
related to a chosen topic. This design makes the method particularly suitable
for auditing proprietary black-box systems. We validate our approach through a
series of experiments, demonstrating its practical applicability and its
potential to support independent post hoc audits of LLM behavior.

</details>


### [169] [Mitigating Strategy Preference Bias in Emotional Support Conversation via Uncertainty Estimations](https://arxiv.org/abs/2509.12661)
*Yougen Zhou,Qin Chen,Ningning Zhou,Jie Zhou,Xingjiao Wu,Liang He*

Main category: cs.CL

TL;DR: 本文揭示了大型语言模型在情感支持对话策略规划中存在偏好的根本原因，并提出了一种基于双重奖励函数的强化学习方法来缓解这种偏好，从而提高了策略规划的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在情感支持对话中因策略规划准确性低和存在显著的策略偏好而面临挑战。尽管现有方法能减少偏好，但其根本原因尚未被充分研究。

Method: 首先，通过识别大型语言模型在策略规划中的知识边界，揭示了偏好的根本原因。然后，提出了一种使用双重奖励函数的强化学习方法，该方法根据知识边界，通过准确性和基于熵的置信度来优化每个区域的策略规划。

Result: 在ESCov和ExTES数据集上，使用多种大型语言模型骨干进行的实验表明，所提出的方法优于基线方法，证实了其有效性。

Conclusion: 所提出的方法通过识别知识边界和采用双重奖励强化学习，有效缓解了大型语言模型在情感支持对话策略规划中的偏好问题，提高了其表现。

Abstract: Emotional support conversation (ESC) aims to alleviate distress through
empathetic dialogue, yet large language models (LLMs) face persistent
challenges in delivering effective ESC due to low accuracy in strategy
planning. Moreover, there is a considerable preference bias towards specific
strategies. Prior methods using fine-tuned strategy planners have shown
potential in reducing such bias, while the underlying causes of the preference
bias in LLMs have not well been studied. To address these issues, we first
reveal the fundamental causes of the bias by identifying the knowledge
boundaries of LLMs in strategy planning. Then, we propose an approach to
mitigate the bias by reinforcement learning with a dual reward function, which
optimizes strategy planning via both accuracy and entropy-based confidence for
each region according to the knowledge boundaries. Experiments on the ESCov and
ExTES datasets with multiple LLM backbones show that our approach outperforms
the baselines, confirming the effectiveness of our approach.

</details>


### [170] [Chat-Driven Text Generation and Interaction for Person Retrieval](https://arxiv.org/abs/2509.12662)
*Zequn Xie,Chuxin Wang,Sihang Cai,Yeqiang Wang,Shulei Wang,Tao Jin*

Main category: cs.CL

TL;DR: 本文提出一个无需人工标注的文本行人搜索框架，通过多轮文本生成（MTG）生成伪标签，并利用多轮文本交互（MTI）在推理时细化用户查询，显著提高检索精度和实用性。


<details>
  <summary>Details</summary>
Motivation: 文本行人搜索（TBPS）在监控应用中具有重要价值，但获取高质量文本标注的过程劳动密集，限制了其可扩展性和实际部署。

Method: 引入了两个互补模块：1. 多轮文本生成（MTG）：通过与多模态大语言模型（MLLMs）模拟对话，生成丰富、细粒度且多样化的视觉描述作为伪标签，无需人工监督。2. 多轮文本交互（MTI）：在推理时通过动态、基于对话的推理来细化用户查询，以解释和解决现实搜索场景中常见的模糊、不完整或模棱两可的描述。

Result: 广泛评估表明，该方法在消除人工标注需求的同时，取得了具有竞争力或更优异的结果，显著提高了检索精度、鲁棒性和可用性。

Conclusion: 所提出的统一无标注框架为可扩展和实际部署的文本行人搜索系统铺平了道路，解决了人工标注的瓶颈问题。

Abstract: Text-based person search (TBPS) enables the retrieval of person images from
large-scale databases using natural language descriptions, offering critical
value in surveillance applications. However, a major challenge lies in the
labor-intensive process of obtaining high-quality textual annotations, which
limits scalability and practical deployment. To address this, we introduce two
complementary modules: Multi-Turn Text Generation (MTG) and Multi-Turn Text
Interaction (MTI). MTG generates rich pseudo-labels through simulated dialogues
with MLLMs, producing fine-grained and diverse visual descriptions without
manual supervision. MTI refines user queries at inference time through dynamic,
dialogue-based reasoning, enabling the system to interpret and resolve vague,
incomplete, or ambiguous descriptions - characteristics often seen in
real-world search scenarios. Together, MTG and MTI form a unified and
annotation-free framework that significantly improves retrieval accuracy,
robustness, and usability. Extensive evaluations demonstrate that our method
achieves competitive or superior results while eliminating the need for manual
captions, paving the way for scalable and practical deployment of TBPS systems.

</details>


### [171] [Towards Inclusive Toxic Content Moderation: Addressing Vulnerabilities to Adversarial Attacks in Toxicity Classifiers Tackling LLM-generated Content](https://arxiv.org/abs/2509.12672)
*Shaz Furniturewala,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 针对大型语言模型（LLM）生成内容带来的挑战，本研究利用机械可解释性技术识别并抑制BERT和RoBERTa毒性分类器中易受攻击的组件，以提高其对对抗性攻击的鲁棒性，并揭示不同人口群体间的公平性差距。


<details>
  <summary>Details</summary>
Motivation: LLM生成内容的大量涌现导致传统内容审核分类器（通常在人类文本上训练）因数据偏差和对抗性攻击而产生误分类。现有防御策略多为被动反应，而非主动识别和修复模型内部的脆弱性。

Method: 研究对象是微调的BERT和RoBERTa毒性分类器，通过对抗性攻击技术识别模型中脆弱的“电路”（如注意力头）。利用机械可解释性技术分析这些组件，并在包含多种少数群体的多样化数据集上进行测试。最终，通过抑制这些脆弱电路来改善模型性能。

Result: 研究发现模型中存在对性能至关重要或易受攻击的独立注意力头。抑制这些脆弱的注意力头可以提高模型在对抗性输入上的表现。此外，不同的人口群体在模型中表现出不同的脆弱注意力头，这揭示了模型训练中存在的公平性和鲁棒性缺陷。

Conclusion: 机械可解释性技术能够主动识别并修复毒性分类器中的脆弱组件，从而提高模型对抗性攻击的鲁棒性。对不同人口群体脆弱性的深入理解，有助于开发更具包容性的毒性检测模型。

Abstract: The volume of machine-generated content online has grown dramatically due to
the widespread use of Large Language Models (LLMs), leading to new challenges
for content moderation systems. Conventional content moderation classifiers,
which are usually trained on text produced by humans, suffer from
misclassifications due to LLM-generated text deviating from their training data
and adversarial attacks that aim to avoid detection. Present-day defence
tactics are reactive rather than proactive, since they rely on adversarial
training or external detection models to identify attacks. In this work, we aim
to identify the vulnerable components of toxicity classifiers that contribute
to misclassification, proposing a novel strategy based on mechanistic
interpretability techniques. Our study focuses on fine-tuned BERT and RoBERTa
classifiers, testing on diverse datasets spanning a variety of minority groups.
We use adversarial attacking techniques to identify vulnerable circuits.
Finally, we suppress these vulnerable circuits, improving performance against
adversarial attacks. We also provide demographic-level insights into these
vulnerable circuits, exposing fairness and robustness gaps in model training.
We find that models have distinct heads that are either crucial for performance
or vulnerable to attack and suppressing the vulnerable heads improves
performance on adversarial input. We also find that different heads are
responsible for vulnerability across different demographic groups, which can
inform more inclusive development of toxicity detection models.

</details>


### [172] [Case-Based Decision-Theoretic Decoding with Quality Memories](https://arxiv.org/abs/2509.12677)
*Hiroyuki Deguchi,Masaaki Nagata*

Main category: cs.CL

TL;DR: 本文提出了一种基于案例的决策理论（CBDT）解码方法，用于解决最小贝叶斯风险（MBR）解码在域外知识捕获上的局限性。CBDT解码通过使用领域数据示例来估计预期效用，并与MBR解码结合后，在多项翻译和图像字幕任务中超越了单独的MBR解码。


<details>
  <summary>Details</summary>
Motivation: 最小贝叶斯风险（MBR）解码虽然能生成高质量文本，但它依赖于从文本生成模型中抽取的样本，导致难以正确捕获域外知识或信息。

Method: 提出了一种基于案例的决策理论（CBDT）解码方法，该方法利用领域数据示例来估计预期效用。此外，还研究了将CBDT解码与MBR解码相结合的策略。

Result: CBDT解码不仅能生成比最大后验（MAP）解码更高质量的文本，而且MBR和CBDT解码的组合在七个德语-英语和日语-英语翻译任务以及MSCOCO和nocaps数据集上的图像字幕任务中，均优于单独的MBR解码。

Conclusion: CBDT解码有效地解决了MBR解码在处理域外知识时的不足。将CBDT与MBR解码结合可以进一步提升文本生成质量，在多语言翻译和图像字幕等任务中表现出优越性。

Abstract: Minimum Bayes risk (MBR) decoding is a decision rule of text generation,
which selects the hypothesis that maximizes the expected utility and robustly
generates higher-quality texts than maximum a posteriori (MAP) decoding.
However, it depends on sample texts drawn from the text generation model; thus,
it is difficult to find a hypothesis that correctly captures the knowledge or
information of out-of-domain. To tackle this issue, we propose case-based
decision-theoretic (CBDT) decoding, another method to estimate the expected
utility using examples of domain data. CBDT decoding not only generates
higher-quality texts than MAP decoding, but also the combination of MBR and
CBDT decoding outperformed MBR decoding in seven domain De--En and
Ja$\leftrightarrow$En translation tasks and image captioning tasks on MSCOCO
and nocaps datasets.

</details>


### [173] [HistoryBankQA: Multilingual Temporal Question Answering on Historical Events](https://arxiv.org/abs/2509.12720)
*Biswadip Mandal,Anant Khandelwal,Manish Gupta*

Main category: cs.CL

TL;DR: 本文提出了HistoryBank，一个包含1000万+历史事件的多语言数据库，并构建了一个涵盖6种时间推理任务的综合问答基准，用于评估大型语言模型在历史事件时间推理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型时间推理基准测试工作有限，数据集规模不足，缺乏多语言覆盖，且主要关注当代事件。为了解决这些局限性，需要一个更全面、多语言、涵盖历史深度的数据集和基准。

Method: 研究人员从维基百科的时间轴页面和文章信息框中提取了1000万+历史事件，构建了HistoryBank多语言数据库，覆盖10种语言。在此基础上，他们构建了一个包含6种不同时间问答推理任务的综合基准，并评估了包括LLaMA-3-8B、Mistral-7B、Gemma-2-9b、Qwen3-8B和GPT4o在内的流行语言模型。

Result: HistoryBank数据库在历史深度和语言广度上提供了前所未有的覆盖，包含10种语言的1000万+历史事件。在时间推理问答基准测试中，GPT4o在所有答案类型和语言上表现最佳；Gemma-2在其他小型语言模型中表现突出。

Conclusion: 这项工作提供了一个全面的资源，旨在促进多语言和时间感知的历史事件自然语言理解研究。研究成果（代码和数据集）将在论文被接受后公开，以进一步推动相关研究。

Abstract: Temporal reasoning about historical events is a critical skill for NLP tasks
like event extraction, historical entity linking, temporal question answering,
timeline summarization, temporal event clustering and temporal natural language
inference. Yet efforts on benchmarking temporal reasoning capabilities of large
language models (LLMs) are rather limited. Existing temporal reasoning datasets
are limited in scale, lack multilingual coverage and focus more on contemporary
events. To address these limitations, we present HistoryBank, a multilingual
database of 10M+ historical events extracted from Wikipedia timeline pages and
article infoboxes. Our database provides unprecedented coverage in both
historical depth and linguistic breadth with 10 languages. Additionally, we
construct a comprehensive question answering benchmark for temporal reasoning
across all languages. This benchmark covers a diverse set of 6 temporal QA
reasoning tasks, and we evaluate a suite of popular language models
(LLaMA-3-8B, Mistral-7B, Gemma-2-9b, Qwen3-8B, GPT4o) to assess their
performance on these tasks. As expected GPT4o performs best across all answer
types and languages; Gemma-2 outperforms the other small language models. Our
work aims to provide a comprehensive resource for advancing multilingual and
temporally-aware natural language understanding of historical events. To
facilitate further research, we will make our code and datasets publicly
available upon acceptance of this paper.

</details>


### [174] [Contrastive Learning with Enhanced Abstract Representations using Grouped Loss of Abstract Semantic Supervision](https://arxiv.org/abs/2509.12771)
*Omri Suissa,Muhiim Ali,Shengmai Chen,Yinuo Cai,Shekhar Pradhan*

Main category: cs.CL

TL;DR: 本文研究了视觉语言模型（VLMs）识别抽象概念的能力，并提出了一种新的训练策略，包括一个分组图像-文本数据集（MAGIC）和一种分组对比损失函数，使CLEAR GLASS模型在不直接接触高层概念的情况下，通过学习组内共性信息，提升了抽象概念识别能力，超越了现有最先进模型。


<details>
  <summary>Details</summary>
Motivation: 人类能够识别图像中的抽象概念，而不仅仅是物体及其关系。研究旨在探讨VLMs是否具备这种概念抽象能力，并探索如何编码图像中的高层概念信息，以增强VLMs的这种能力。

Method: 1. 引入了一个分组图像-文本数据集（MAGIC），其中包含分组的图像描述、相关图像和高层概念标签。2. 提出了一种新颖的对比损失技术，包含基于文本-图像对比分组的“外部对比损失”和衡量组内图像-文本实例间距离的“内部损失”。3. 训练方法使模型在不直接接触高层概念的情况下，为每个图像-文本组创建语义表示，使其在潜在语义空间中更接近高层概念的语义表示，从而使概念抽象能力作为一种“涌现能力”出现。

Result: 实验结果表明，这种训练方法使得CLEAR GLASS模型在抽象概念识别方面表现出显著改进，超越了现有最先进（SOTA）模型。

Conclusion: 通过引入MAGIC数据集和新颖的分组对比损失函数，本研究提出的训练方法能够使VLMs（CLEAR GLASS模型）在不直接暴露于高层概念的情况下，自发地获得概念抽象能力，并在抽象概念识别任务上取得了优于SOTA模型的性能。

Abstract: Humans can recognize an image as an instance of a general concept, beyond
simply identifying its objects and their relationships. In this paper, we
investigate 1. The extent to which VLMs have this concept abstraction capacity,
and 2. Strategies for encoding the sort of higher-concept information in images
that would enable the resulting VLM model (CLEAR GLASS model) to have this
capability to a greater degree. To this end, we introduce a grouped
image-caption dataset (MAGIC), which consists of several groups of image
captions and for each group a set of associated images and higher-level
conceptual labels. We use a novel contrastive loss technique to induce the
model to encode in the representation of each image (caption) in a group the
information that is common to all members of the image-caption group. Our main
contribution is a grouped contrastive loss function based on text-image
contrastive groups (outer contrastive loss) as well as an inner loss which
measures the distances between image-caption instances in the group. Our
training methodology results in the CLEAR GLASS model having the concept
abstraction capacity as an emergent capacity because the model is not exposed
to the higher-level concepts associated with each group. Instead, the training
forces the model to create for each image-caption group a semantic
representation that brings it closer to the semantic representation of the
higher-level concepts in the latent semantic space. Our experiments show that
this training methodology results in a model which shows improvement in
abstract concept recognition compared to SOTA models.

</details>


### [175] [ConvergeWriter: Data-Driven Bottom-Up Article Construction](https://arxiv.org/abs/2509.12811)
*Binquan Ji,Jiaqi Wang,Ruiting Li,Xingchen Han,Yiyang Qi,Shichao Wang,Yifei Lu,Yuantao Han,Feiliang Ren*

Main category: cs.CL

TL;DR: 本文提出了一种“自下而上”的数据驱动框架，通过先从知识库中检索并聚类知识，再以此指导大语言模型生成分层大纲和文档内容，从而解决长篇事实性文档生成中的幻觉和内容碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在文本生成方面表现出色，但在生成基于大量外部知识库的长篇事实性文档时仍面临挑战。现有的“自上而下”方法（先生成假设/大纲再检索证据）常导致模型规划与可用知识脱节，进而产生内容碎片化和事实不准确。

Method: 提出“先检索知识，再聚类结构”的策略。具体而言，首先对知识库进行详尽的迭代检索，然后使用无监督聚类算法将检索到的文档组织成“知识簇”。这些知识簇形成客观、数据驱动的基础，直接指导后续分层大纲的生成和最终文档内容的生成。这种“自下而上”的过程确保生成文本严格受限于源材料并可追溯，主动适应知识库的有限范围，并从根本上降低幻觉的风险。

Result: 在14B和32B参数模型上的实验结果表明，该方法达到了与现有最先进基线相当或超越的性能。预计在需要高保真度和结构连贯性的知识受限场景中展现独特优势。

Conclusion: 本研究为生成可靠、结构化的长篇文档提供了一种有效范式，为高风险、知识密集型领域中更强大的大语言模型应用铺平了道路。

Abstract: Large Language Models (LLMs) have shown remarkable prowess in text
generation, yet producing long-form, factual documents grounded in extensive
external knowledge bases remains a significant challenge. Existing "top-down"
methods, which first generate a hypothesis or outline and then retrieve
evidence, often suffer from a disconnect between the model's plan and the
available knowledge, leading to content fragmentation and factual inaccuracies.
To address these limitations, we propose a novel "bottom-up," data-driven
framework that inverts the conventional generation pipeline. Our approach is
predicated on a "Retrieval-First for Knowledge, Clustering for Structure"
strategy, which first establishes the "knowledge boundaries" of the source
corpus before any generative planning occurs. Specifically, we perform
exhaustive iterative retrieval from the knowledge base and then employ an
unsupervised clustering algorithm to organize the retrieved documents into
distinct "knowledge clusters." These clusters form an objective, data-driven
foundation that directly guides the subsequent generation of a hierarchical
outline and the final document content. This bottom-up process ensures that the
generated text is strictly constrained by and fully traceable to the source
material, proactively adapting to the finite scope of the knowledge base and
fundamentally mitigating the risk of hallucination. Experimental results on
both 14B and 32B parameter models demonstrate that our method achieves
performance comparable to or exceeding state-of-the-art baselines, and is
expected to demonstrate unique advantages in knowledge-constrained scenarios
that demand high fidelity and structural coherence. Our work presents an
effective paradigm for generating reliable, structured, long-form documents,
paving the way for more robust LLM applications in high-stakes,
knowledge-intensive domains.

</details>


### [176] [Data Augmentation for Maltese NLP using Transliterated and Machine Translated Arabic Data](https://arxiv.org/abs/2509.12853)
*Kurt Micallef,Nizar Habash,Claudia Borg*

Main category: cs.CL

TL;DR: 本文探讨了通过跨语言增强技术，利用阿拉伯语资源支持马耳他语自然语言处理（NLP）的可行性。


<details>
  <summary>Details</summary>
Motivation: 马耳他语是一种独特的闪米特语，使用拉丁字母书写，与同为闪米特语的阿拉伯语存在巨大差异。研究旨在弥合这一差距，探索能否利用丰富的阿拉伯语资源来提升马耳他语NLP的性能。

Method: 研究采用了多种策略将阿拉伯语文本数据与马耳他语对齐，包括各种音译方案（其中包含新提出的系统以更好地表示马耳他语正字法）和机器翻译（MT）方法。然后，这些增强数据被用于评估单语和多语模型。

Result: 评估结果表明，基于阿拉伯语的增强技术能显著提升马耳他语NLP任务的性能。

Conclusion: 阿拉伯语资源能够通过跨语言增强技术有效支持马耳他语的自然语言处理任务。

Abstract: Maltese is a unique Semitic language that has evolved under extensive
influence from Romance and Germanic languages, particularly Italian and
English. Despite its Semitic roots, its orthography is based on the Latin
script, creating a gap between it and its closest linguistic relatives in
Arabic. In this paper, we explore whether Arabic-language resources can support
Maltese natural language processing (NLP) through cross-lingual augmentation
techniques. We investigate multiple strategies for aligning Arabic textual data
with Maltese, including various transliteration schemes and machine translation
(MT) approaches. As part of this, we also introduce novel transliteration
systems that better represent Maltese orthography. We evaluate the impact of
these augmentations on monolingual and mutlilingual models and demonstrate that
Arabic-based augmentation can significantly benefit Maltese NLP tasks.

</details>


### [177] [Benchmarking and Improving LVLMs on Event Extraction from Multimedia Documents](https://arxiv.org/abs/2509.12876)
*Fuyu Xing,Zimu Wang,Wei Wang,Haiyang Zhang*

Main category: cs.CL

TL;DR: 本文首次系统评估了大型视觉语言模型（LVLMs）在多媒体事件提取（M2E2）任务上的表现，涵盖少样本提示和微调设置，并揭示了其在视觉任务上的优势、微调的有效性以及跨模态融合的协同作用，同时指出了语义精度、定位和跨模态接地等挑战。


<details>
  <summary>Details</summary>
Motivation: 多媒体内容的激增需要高效的多媒体事件提取（M2E2）系统。尽管大型视觉语言模型（LVLMs）展现出强大的跨模态能力，但其在M2E2任务中的应用尚未得到充分探索。

Method: 研究人员对DeepSeek-VL2和Qwen-VL系列等代表性LVLMs在M2E2数据集上进行了首次系统评估。评估涵盖了纯文本、纯图像和跨媒体子任务，并在少样本提示和微调（使用LoRA）两种设置下进行性能评估。此外，还进行了详细的错误分析。

Result: (1) 少样本LVLMs在视觉任务上表现显著更好，但在文本任务上表现较差；(2) 使用LoRA对LVLMs进行微调可大幅提升模型性能；(3) LVLMs在结合不同模态时展现出强大的协同作用，在跨模态设置中取得卓越性能。错误分析揭示了语义精度、定位和跨模态接地等方面的持续挑战。

Conclusion: LVLMs在M2E2任务中具有巨大潜力，尤其是在微调和跨模态融合的场景下表现出色。然而，在语义精度、定位和跨模态接地等关键领域仍面临挑战，这些是未来提升M2E2能力的关键障碍。

Abstract: The proliferation of multimedia content necessitates the development of
effective Multimedia Event Extraction (M2E2) systems. Though Large
Vision-Language Models (LVLMs) have shown strong cross-modal capabilities,
their utility in the M2E2 task remains underexplored. In this paper, we present
the first systematic evaluation of representative LVLMs, including DeepSeek-VL2
and the Qwen-VL series, on the M2E2 dataset. Our evaluations cover text-only,
image-only, and cross-media subtasks, assessed under both few-shot prompting
and fine-tuning settings. Our key findings highlight the following valuable
insights: (1) Few-shot LVLMs perform notably better on visual tasks but
struggle significantly with textual tasks; (2) Fine-tuning LVLMs with LoRA
substantially enhances model performance; and (3) LVLMs exhibit strong synergy
when combining modalities, achieving superior performance in cross-modal
settings. We further provide a detailed error analysis to reveal persistent
challenges in areas such as semantic precision, localization, and cross-modal
grounding, which remain critical obstacles for advancing M2E2 capabilities.

</details>


### [178] [The LLM Already Knows: Estimating LLM-Perceived Question Difficulty via Hidden Representations](https://arxiv.org/abs/2509.12886)
*Yubo Zhu,Dongrui Liu,Zecheng Lin,Wei Tong,Sheng Zhong,Jing Shao*

Main category: cs.CL

TL;DR: 该论文提出了一种新颖的方法，仅利用大型语言模型（LLM）的隐藏表示来估计输入问题的难度，无需生成任何输出token。通过将token生成过程建模为马尔可夫链并定义价值函数，实现了高效准确的难度估计，并在实验中优于现有基线，还能指导自适应推理策略以提高效率。


<details>
  <summary>Details</summary>
Motivation: 准确估计LLM感知的问题难度对于性能评估和自适应推理至关重要。现有方法通常依赖重复采样、辅助模型或微调目标模型，这会导致高计算成本或泛化性受损。

Method: 本研究提出一种仅利用目标LLM隐藏表示的难度估计方法。具体而言，将token级别的生成过程建模为马尔可夫链，并定义一个价值函数来估计给定任何隐藏状态下的预期输出质量。这种方法仅基于初始隐藏状态即可进行难度估计，无需生成任何输出token。

Result: 在文本和多模态任务上进行的广泛实验表明，该方法在难度估计方面持续优于现有基线。此外，将该难度估计应用于指导自适应推理策略（包括Self-Consistency、Best-of-N和Self-Refine）时，能够以更少的生成token实现更高的推理效率。

Conclusion: 该研究提出了一种高效且准确的LLM问题难度估计方法，该方法仅依赖于模型的隐藏表示，无需生成输出token。这不仅提升了难度估计的性能，还能有效指导自适应推理策略，从而提高推理效率。

Abstract: Estimating the difficulty of input questions as perceived by large language
models (LLMs) is essential for accurate performance evaluation and adaptive
inference. Existing methods typically rely on repeated response sampling,
auxiliary models, or fine-tuning the target model itself, which may incur
substantial computational costs or compromise generality. In this paper, we
propose a novel approach for difficulty estimation that leverages only the
hidden representations produced by the target LLM. We model the token-level
generation process as a Markov chain and define a value function to estimate
the expected output quality given any hidden state. This allows for efficient
and accurate difficulty estimation based solely on the initial hidden state,
without generating any output tokens. Extensive experiments across both textual
and multimodal tasks demonstrate that our method consistently outperforms
existing baselines in difficulty estimation. Moreover, we apply our difficulty
estimates to guide adaptive reasoning strategies, including Self-Consistency,
Best-of-N, and Self-Refine, achieving higher inference efficiency with fewer
generated tokens.

</details>


### [179] [Conan-Embedding-v2: Training an LLM from Scratch for Text Embeddings](https://arxiv.org/abs/2509.12892)
*Shiyu Li,Yang Tang,Ruijie Liu,Shi-Zhe Chen,Xi Chen*

Main category: cs.CL

TL;DR: 本文提出了Conan-embedding-v2，一个从头训练并微调的1.4B参数大型语言模型，通过弥合LLM与嵌入模型之间的数据和训练鸿沟，在文本嵌入任务上达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在文本嵌入任务中表现出色，但通常使用LoRA进行微调，受限于LLM与嵌入模型之间的数据和训练差异，导致效果不佳。

Method: 1. 从头训练一个1.4B参数的LLM。2. 弥合数据鸿沟：在预训练中加入新闻数据和多语言对，并构建跨语言检索数据集。3. 弥合训练鸿沟：引入软掩码机制，逐步实现因果掩码和双向掩码之间的过渡。4. 优化训练：提出动态难负例挖掘方法。

Result: Conan-embedding-v2（约1.4B参数）在MTEB和中文MTEB上均取得了最先进（SOTA）的性能（截至2025年5月19日）。

Conclusion: Conan-embedding-v2通过从头训练并创新性地弥合了LLM与嵌入模型之间的数据和训练鸿沟，以其直观有效的方法和相对较小的模型规模，在文本嵌入任务中展现出卓越的性能。

Abstract: Large language models (LLMs) have recently demonstrated excellent performance
in text embedding tasks. Previous work usually use LoRA to fine-tune existing
LLMs, which are limited by the data and training gap between LLMs and embedding
models. In this work, we introduce Conan-embedding-v2, a new 1.4B-parameter LLM
trained from scratch and fine-tuned as a text embedder. First, we add news data
and multilingual pairs for LLM pretraining to bridge the data gap. Based on
this, we propose a cross-lingual retrieval dataset that enables the LLM to
better integrate embeddings across different languages. Second, whereas LLMs
use a causal mask with token-level loss, embedding models use a bidirectional
mask with sentence-level loss. This training gap makes full fine-tuning less
effective than LoRA. We introduce a soft-masking mechanism to gradually
transition between these two types of masks, enabling the model to learn more
comprehensive representations. Based on this, we propose a dynamic hard
negative mining method that exposes the model to more difficult negative
examples throughout the training process. Being intuitive and effective, with
only approximately 1.4B parameters, Conan-embedding-v2 achieves SOTA
performance on both the Massive Text Embedding Benchmark (MTEB) and Chinese
MTEB (May 19, 2025).

</details>


### [180] [All Roads Lead to Rome: Graph-Based Confidence Estimation for Large Language Model Reasoning](https://arxiv.org/abs/2509.12908)
*Caiqi Zhang,Chang Shu,Ehsan Shareghi,Nigel Collier*

Main category: cs.CL

TL;DR: 该论文提出了一套无需训练的、基于图的置信度估计方法，专为大型语言模型（LLMs）的推理任务设计，并通过图属性提高了置信度估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型置信度估计方法主要针对事实问答任务，在推理任务上表现不佳。为弥补这一空白，研究旨在开发适用于推理任务的置信度估计方法。

Method: 研究将推理路径建模为有向图，并通过利用图的属性（如中心性、路径收敛性和路径加权）来估计置信度。该方法无需训练。

Result: 在两个LLMs和三个推理数据集上的实验表明，所提出的方法显著改善了置信度估计，并提升了两个下游任务的性能。

Conclusion: 所提出的基于图的、无需训练的置信度估计方法能有效提高大型语言模型在推理任务中的置信度估计和下游任务表现。

Abstract: Confidence estimation is essential for the reliable deployment of large
language models (LLMs). Existing methods are primarily designed for factual QA
tasks and often fail to generalize to reasoning tasks. To address this gap, we
propose a set of training-free, graph-based confidence estimation methods
tailored to reasoning tasks. Our approach models reasoning paths as directed
graphs and estimates confidence by exploiting graph properties such as
centrality, path convergence, and path weighting. Experiments with two LLMs on
three reasoning datasets demonstrate improved confidence estimation and
enhanced performance on two downstream tasks.

</details>


### [181] [Automated Generation of Research Workflows from Academic Papers: A Full-text Mining Framework](https://arxiv.org/abs/2509.12955)
*Heng Zhang,Chengzhi Zhang*

Main category: cs.CL

TL;DR: 该研究提出了一个端到端框架，通过挖掘学术论文全文，自动生成全面、结构化的研究工作流程，以提高研究可复现性并加速“AI for Science”范式。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只能提取碎片化的程序组件，无法捕获完整的研究工作流程，这阻碍了研究可复现性和“AI for Science”范式的发展。

Method: 该方法以段落为中心，首先使用带有SciBERT的PU学习识别描述工作流程的段落；接着，利用带有提示学习的Flan-T5从这些段落生成工作流程短语；然后，使用带有少样本学习的ChatGPT将短语分类到数据准备、数据处理和数据分析阶段；最后，将分类后的短语映射到文档位置，生成可读的视觉流程图。以自然语言处理（NLP）领域为例进行了案例研究。

Result: 在段落识别方面，F1分数达到0.9772；在短语生成方面，ROUGE-1、ROUGE-2和ROUGE-L分数分别为0.4543、0.2877和0.4427；在短语分类方面，分类精度达到0.958。该方法成功生成了可读的视觉流程图，并揭示了过去二十年NLP领域关键的方法学转变，例如对数据分析的日益重视以及从特征工程到消融研究的转变。

Conclusion: 该工作提供了一个经过验证的自动化工作流程生成技术框架，以及一个新颖的、面向过程的视角，用于实证研究不断演变的科学范式。

Abstract: The automated generation of research workflows is essential for improving the
reproducibility of research and accelerating the paradigm of "AI for Science".
However, existing methods typically extract merely fragmented procedural
components and thus fail to capture complete research workflows. To address
this gap, we propose an end-to-end framework that generates comprehensive,
structured research workflows by mining full-text academic papers. As a case
study in the Natural Language Processing (NLP) domain, our paragraph-centric
approach first employs Positive-Unlabeled (PU) Learning with SciBERT to
identify workflow-descriptive paragraphs, achieving an F1-score of 0.9772.
Subsequently, we utilize Flan-T5 with prompt learning to generate workflow
phrases from these paragraphs, yielding ROUGE-1, ROUGE-2, and ROUGE-L scores of
0.4543, 0.2877, and 0.4427, respectively. These phrases are then systematically
categorized into data preparation, data processing, and data analysis stages
using ChatGPT with few-shot learning, achieving a classification precision of
0.958. By mapping categorized phrases to their document locations in the
documents, we finally generate readable visual flowcharts of the entire
research workflows. This approach facilitates the analysis of workflows derived
from an NLP corpus and reveals key methodological shifts over the past two
decades, including the increasing emphasis on data analysis and the transition
from feature engineering to ablation studies. Our work offers a validated
technical framework for automated workflow generation, along with a novel,
process-oriented perspective for the empirical investigation of evolving
scientific paradigms. Source code and data are available at:
https://github.com/ZH-heng/research_workflow.

</details>


### [182] [Investigating ReLoRA: Effects on the Learning Dynamics of Small Language Models](https://arxiv.org/abs/2509.12960)
*Yuval Weiss,David Demitri Africa,Paula Buttery,Richard Diehl Martinez*

Main category: cs.CL

TL;DR: 本研究首次系统性评估了ReLoRA在小型语言模型(SLM)预训练中的表现，发现其性能普遍不如标准训练，并可能加剧模型中的秩亏损问题。


<details>
  <summary>Details</summary>
Motivation: LoRA等参数高效方法彻底改变了大型语言模型(LLM)的微调，但ReLoRA在预训练中的扩展，特别是对于计算和环境成本较低的小型语言模型(SLM)，尚不清楚。

Method: 对11M-66M参数范围内的SLM进行了ReLoRA的首次系统性研究，通过消融实验评估了其性能和学习动态，包括损失、Paloma困惑度和BLiMP指标。

Result: ReLoRA在损失、Paloma困惑度和BLiMP上普遍比标准训练表现更差，且模型越大，性能差距越明显。学习动态分析表明，ReLoRA强化了较小模型中存在的秩亏损问题。

Conclusion: 研究结果表明低秩更新策略可能不易直接迁移到SLM的预训练中，凸显了在低计算量条件下进行更多相关研究的必要性。

Abstract: Parameter-efficient methods such as LoRA have revolutionised the fine-tuning
of LLMs. Still, their extension to pretraining via ReLoRA is less well
understood, especially for small language models (SLMs), which offer lower
computational and environmental costs. This work is the first systematic study
of ReLoRA in SLMs (11M-66M parameters), evaluating both performance and
learning dynamics. Through ablation experiments, we find that ReLoRA generally
performs worse than standard training on loss, Paloma perplexity and BLiMP,
with the gap widening for the larger models. Further analysis of the learning
dynamics of the models indicates that ReLoRA reinforces the rank deficiencies
found in smaller models. These results indicate that low-rank update strategies
may not transfer easily to SLM pretraining, highlighting the need for more
research in the low-compute regime.

</details>


### [183] [Do LLMs Understand Wine Descriptors Across Cultures? A Benchmark for Cultural Adaptations of Wine Reviews](https://arxiv.org/abs/2509.12961)
*Chenye Zou,Xingyue Wen,Tianyi Hu,Qian Janice Wang,Daniel Hershcovich*

Main category: cs.CL

TL;DR: 该研究引入了跨文化葡萄酒评论改编的新问题，构建了首个中英文平行语料库，并评估了当前模型在处理地域口味和文化特定描述方面的不足。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型(LLMs)在文化感知语言任务方面的进展，研究者发现现有翻译模型难以超越字面翻译，未能融入地域口味偏好和文化特定风味描述，因此提出了跨文化葡萄酒评论改编这一新问题。

Method: 该研究定义了中英文葡萄酒评论的跨文化改编问题，并为此构建了首个包含8k中文和16k英文专业评论的平行语料库。研究者使用自动指标和人工评估对神经机器翻译基线模型和先进的LLMs进行了基准测试，并提出了文化接近度、文化中立性和文化真实性三个面向文化的人工评估标准。

Result: 分析结果显示，当前模型在捕捉文化细微差别方面表现不佳，尤其是在跨文化翻译葡萄酒描述时难以有效处理，无法自然地与目标文化读者产生共鸣。

Conclusion: 该研究强调了当前翻译模型在处理复杂文化内容方面的挑战和局限性，特别是在需要整合地域偏好和文化特定描述的语言任务中。

Abstract: Recent advances in large language models (LLMs) have opened the door to
culture-aware language tasks. We introduce the novel problem of adapting wine
reviews across Chinese and English, which goes beyond literal translation by
incorporating regional taste preferences and culture-specific flavor
descriptors. In a case study on cross-cultural wine review adaptation, we
compile the first parallel corpus of professional reviews, containing 8k
Chinese and 16k Anglophone reviews. We benchmark both
neural-machine-translation baselines and state-of-the-art LLMs with automatic
metrics and human evaluation. For the latter, we propose three culture-oriented
criteria -- Cultural Proximity, Cultural Neutrality, and Cultural Genuineness
-- to assess how naturally a translated review resonates with target-culture
readers. Our analysis shows that current models struggle to capture cultural
nuances, especially in translating wine descriptions across different cultures.
This highlights the challenges and limitations of translation models in
handling cultural content.

</details>


### [184] [SitLLM: Large Language Models for Sitting Posture Health Understanding via Pressure Sensor Data](https://arxiv.org/abs/2509.12994)
*Jian Gao,Fufangchen Zhao,Yiyang Zhang,Danfeng Yan*

Main category: cs.CL

TL;DR: 本文提出了SitLLM，一个轻量级多模态框架，结合柔性压力传感和大型语言模型（LLMs），以实现细粒度的坐姿理解和个性化的健康导向响应生成。


<details>
  <summary>Details</summary>
Motivation: 不良坐姿是导致长期肌肉骨骼疾病和生理功能障碍的关键因素，但常被忽视。现有坐姿监测系统（基于视觉、IMU或压力）存在识别粒度粗糙、缺乏语义表达能力以及无法提供个性化反馈的问题。

Method: SitLLM框架包含三个关键组件：1) 一个高斯鲁棒传感器嵌入模块，将压力图划分为空间块并注入局部噪声以提取鲁棒特征；2) 一个提示驱动跨模态对齐模块，通过多头交叉注意力将传感器嵌入重编程到LLM的语义空间；3) 一个多上下文提示模块，融合特征级、结构级、统计级和语义级上下文信息以指导指令理解。

Result: SitLLM能够实现细粒度的坐姿理解，并生成个性化的、面向健康的响应。

Conclusion: SitLLM通过整合柔性压力传感和LLMs，为解决现有坐姿监测系统的局限性提供了一种新颖且有效的方法，有望实现更精确和个性化的坐姿健康管理。

Abstract: Poor sitting posture is a critical yet often overlooked factor contributing
to long-term musculoskeletal disorders and physiological dysfunctions. Existing
sitting posture monitoring systems, although leveraging visual, IMU, or
pressure-based modalities, often suffer from coarse-grained recognition and
lack the semantic expressiveness necessary for personalized feedback. In this
paper, we propose \textbf{SitLLM}, a lightweight multimodal framework that
integrates flexible pressure sensing with large language models (LLMs) to
enable fine-grained posture understanding and personalized health-oriented
response generation. SitLLM comprises three key components: (1) a
\textit{Gaussian-Robust Sensor Embedding Module} that partitions pressure maps
into spatial patches and injects local noise perturbations for robust feature
extraction; (2) a \textit{Prompt-Driven Cross-Modal Alignment Module} that
reprograms sensor embeddings into the LLM's semantic space via multi-head
cross-attention using the pre-trained vocabulary embeddings; and (3) a
\textit{Multi-Context Prompt Module} that fuses feature-level, structure-level,
statistical-level, and semantic-level contextual information to guide
instruction comprehension.

</details>


### [185] [Multi-Model Synthetic Training for Mission-Critical Small Language Models](https://arxiv.org/abs/2509.13047)
*Nolan Platt,Pragyansmita Nayak*

Main category: cs.CL

TL;DR: 该研究提出一种新方法，通过使用大型语言模型（LLMs）作为一次性教师生成合成数据，将32亿条船舶追踪记录转化为2万多条问答对，并用这些数据微调小型模型（Qwen2.5-7B），在海事智能领域实现了261倍的成本降低和75%的准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在许多领域表现出色，但在专业领域的应用受限于领域特定训练数据的稀缺性和复杂性。此外，直接使用大型LLMs进行推理成本高昂。

Method: 该方法将LLMs（GPT-4o和o3-mini）用作一次性教师，通过多模型生成将32亿条自动识别系统（AIS）船舶追踪记录转换为21,543个合成问答对，以防止过拟合并确保推理准确性。随后，使用这些合成数据微调了Qwen2.5-7B模型。

Result: 该方法实现了261倍的海事智能成本降低。微调后的Qwen2.5-7B模型在海事任务上达到了75%的准确率，且比直接使用大型模型进行推理成本大幅降低。研究表明，经过适当微调的小型廉价模型可以提供与昂贵大型模型相似的准确性。

Conclusion: 该工作证明了通过合成数据集生成，可以使小型、廉价模型在专业领域达到与大型、昂贵模型相媲美的性能。这为专业AI应用中的合成数据集生成提供了贡献，并为手动标注不可行的领域提供了一个高度可复现的框架，在海事安全、安保运营和船舶交通管理系统等领域具有直接应用价值。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
many domains, yet their application to specialized fields remains constrained
by the scarcity and complexity of domain-specific training data. We present a
novel approach that achieves a 261x cost reduction for maritime intelligence by
using LLMs as one-time teachers rather than using them directly for inference.
Our method transforms 3.2 billion Automatic Identification System (AIS) vessel
tracking records into 21,543 synthetic question and answer pairs through
multi-model generation (GPT-4o and o3-mini), preventing overfitting and
ensuring accurate reasoning. The resulting fine-tuned Qwen2.5-7B model achieves
75% accuracy on maritime tasks, while being substantially cheaper than using a
larger model for inference. We show that smaller, cheaper models -- when fine
tuned properly -- can provide similar accuracy compared to larger models that
are prohibitively expensive. Our work contributes to the growing field of
synthetic dataset generation for specialized AI applications and presents a
highly reproducible framework for domains where manual annotation is
infeasible. Beyond expanding research in the growing field of specialized small
language models, our approach has immediate applications in maritime safety,
security operations, and vessel traffic management systems in various
industries.

</details>


### [186] [Shaping Explanations: Semantic Reward Modeling with Encoder-Only Transformers for GRPO](https://arxiv.org/abs/2509.13081)
*Francesco Pappone,Ruggero Marino Lazzaroni,Federico Califano,Niccolò Gentile,Roberto Marras*

Main category: cs.CL

TL;DR: 本文提出在GRPO框架内使用小型编码器Transformer作为语义奖励模型，通过余弦相似度提供密集、语义丰富的奖励信号，显著提升了大型语言模型生成解释的忠实性和清晰度，尤其在意大利医学院入学考试解释任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成类人文本方面表现出色，但难以实现教学合理性等复杂的定性目标。标准的强化学习技术依赖于缓慢昂贵的“LLM作为评判者”评估或脆弱的基于关键词的指标（如ROUGE），这些都无法捕捉高质量解释的语义本质。

Method: 本研究在Group Relative Policy Optimisation (GRPO) 框架内引入了一种新颖的奖励塑造方法。核心贡献是使用一个小型、高效的编码器Transformer作为语义奖励模型。该模型通过计算生成解释与真实参考之间的余弦相似度，提供密集、语义丰富的奖励信号，引导策略生成在结构和概念上与专家推理一致的解释。该方法应用于意大利医学院入学考试的解释生成任务，遵循标准的领域自适应持续预训练(CPT)和监督微调(SFT)步骤。

Result: 实验结果表明，结合所提出的语义奖励的GRPO方法，相对于强大的SFT基线，显著提高了解释的忠实性和清晰度。

Conclusion: 研究展示了使用轻量级编码器模型在复杂生成任务中进行细致奖励塑造的强大潜力。

Abstract: While Large Language Models (LLMs) excel at generating human-like text,
aligning their outputs with complex, qualitative goals like pedagogical
soundness remains a significant challenge. Standard reinforcement learning
techniques often rely on slow and expensive LLM-as-a-judge evaluations or on
brittle, keyword-based metrics like ROUGE, which fail to capture the semantic
essence of a high-quality explanation. In this work, we introduce a novel
approach to reward shaping within the Group Relative Policy Optimisation (GRPO)
framework. Our central contribution is the use of a small, efficient
encoder-only transformer as a semantic reward model. This model provides a
dense, semantically rich reward signal based on the cosine similarity between a
generated explanation and a ground-truth reference, guiding the policy towards
explanations that are not just factually correct but also structurally and
conceptually aligned with expert reasoning. We apply this method to the task of
training a model for the Italian medical-school entrance examinations,
following standard domain-adaptive continued pre-training (CPT) and supervised
fine-tuning (SFT). Our results demonstrate that GRPO with our proposed semantic
reward significantly improves explanation faithfulness and clarity over a
strong SFT baseline, showcasing the power of using lightweight encoder models
for nuanced reward shaping in complex generation tasks

</details>


### [187] [Empowering LLMs with Parameterized Skills for Adversarial Long-Horizon Planning](https://arxiv.org/abs/2509.13127)
*Sijia Cui,Shuai Xu,Aiyao He,Yanna Wang,Bo Xu*

Main category: cs.CL

TL;DR: 本文提出PLAP框架，通过结合语言规划和参数化动作，使LLM代理在复杂、长周期环境中有效落地。PLAP包含技能库、LLM技能规划器和技能执行器，在MicroRTS中表现出色，甚至超越顶尖脚本代理，并发布了LLM长周期技能规划能力排行榜。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在复杂、对抗性长周期环境中落地面临挑战：直接生成低级动作不可靠；利用LLM生成高级任务或语言指导又过度依赖专家经验将高级任务转化为具体动作序列。

Method: PLAP（Plan with Language, Act with Parameter）规划框架包含三个核心组件：1) 一个包含环境特定参数化技能的技能库；2) 一个由LLM驱动的技能规划器；3) 一个将参数化技能转换为可执行动作序列的技能执行器。

Result: 实验结果表明PLAP框架的有效性。在零样本设置下，由GPT-4o驱动的PLAP超越了80%的基线代理；通过精心设计的少样本示例，由Qwen2-72B驱动的PLAP甚至超越了顶尖脚本代理CoacAI。此外，论文还设计了全面的评估指标，测试了6个闭源和2个开源LLM，并发布了LLM长周期技能规划能力排行榜。

Conclusion: PLAP框架有效解决了LLM代理在复杂长周期环境中落地的问题，通过结合LLM的规划能力与参数化技能的精确执行，显著提升了代理的表现。研究还为评估LLM的长周期技能规划能力提供了新的基准和工具。

Abstract: Recent advancements in Large Language Models(LLMs) have led to the
development of LLM-based AI agents. A key challenge is the creation of agents
that can effectively ground themselves in complex, adversarial long-horizon
environments. Existing methods mainly focus on (1) using LLMs as policies to
interact with the environment through generating low-level feasible actions,
and (2) utilizing LLMs to generate high-level tasks or language guides to
stimulate action generation. However, the former struggles to generate reliable
actions, while the latter relies heavily on expert experience to translate
high-level tasks into specific action sequences. To address these challenges,
we introduce the Plan with Language, Act with Parameter (PLAP) planning
framework that facilitates the grounding of LLM-based agents in long-horizon
environments. The PLAP method comprises three key components: (1) a skill
library containing environment-specific parameterized skills, (2) a skill
planner powered by LLMs, and (3) a skill executor converting the parameterized
skills into executable action sequences. We implement PLAP in MicroRTS, a
long-horizon real-time strategy game that provides an unfamiliar and
challenging environment for LLMs. The experimental results demonstrate the
effectiveness of PLAP. In particular, GPT-4o-driven PLAP in a zero-shot setting
outperforms 80% of baseline agents, and Qwen2-72B-driven PLAP, with carefully
crafted few-shot examples, surpasses the top-tier scripted agent, CoacAI.
Additionally, we design comprehensive evaluation metrics and test 6
closed-source and 2 open-source LLMs within the PLAP framework, ultimately
releasing an LLM leaderboard ranking long-horizon skill planning ability. Our
code is available at https://github.com/AI-Research-TeamX/PLAP.

</details>


### [188] [LLM Hallucination Detection: A Fast Fourier Transform Method Based on Hidden Layer Temporal Signals](https://arxiv.org/abs/2509.13154)
*Jinxin Li,Gang Tu,ShengYu Cheng,Junjie Hu,Jinting Wang,Rui Chen,Zhilong Zhou,Dongbo Shan*

Main category: cs.CL

TL;DR: 本文提出了一种名为HSAD的新型幻觉检测框架，通过分析大型语言模型自回归生成过程中隐藏层表示的时间动态和频域特征，显著提升了幻觉检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 幻觉是限制大型语言模型在可靠性敏感应用中部署的关键障碍。现有检测方法受限于外部知识覆盖范围（事实核查）或未能捕捉推理动态偏差（静态隐藏状态分析），导致其有效性和鲁棒性有限。

Method: HSAD通过以下步骤实现：1) 对跨层激活进行采样以构建隐藏层信号；2) 应用快速傅里叶变换（FFT）获取频域表示；3) 提取最强的非直流（non-DC）频率分量作为光谱特征；4) 利用LLM的自回归特性识别最佳观察点，以实现有效可靠的检测。

Result: 在包括TruthfulQA在内的多个基准测试中，HSAD比现有最先进的方法提高了10个百分点以上的性能。

Conclusion: HSAD通过将推理过程建模与频域分析相结合，为大型语言模型中鲁棒的幻觉检测建立了一个新范式。

Abstract: Hallucination remains a critical barrier for deploying large language models
(LLMs) in reliability-sensitive applications. Existing detection methods
largely fall into two categories: factuality checking, which is fundamentally
constrained by external knowledge coverage, and static hidden-state analysis,
that fails to capture deviations in reasoning dynamics. As a result, their
effectiveness and robustness remain limited. We propose HSAD (Hidden Signal
Analysis-based Detection), a novel hallucination detection framework that
models the temporal dynamics of hidden representations during autoregressive
generation. HSAD constructs hidden-layer signals by sampling activations across
layers, applies Fast Fourier Transform (FFT) to obtain frequency-domain
representations, and extracts the strongest non-DC frequency component as
spectral features. Furthermore, by leveraging the autoregressive nature of
LLMs, HSAD identifies optimal observation points for effective and reliable
detection. Across multiple benchmarks, including TruthfulQA, HSAD achieves over
10 percentage points improvement compared to prior state-of-the-art methods. By
integrating reasoning-process modeling with frequency-domain analysis, HSAD
establishes a new paradigm for robust hallucination detection in LLMs.

</details>


### [189] [The Few-shot Dilemma: Over-prompting Large Language Models](https://arxiv.org/abs/2509.13196)
*Yongjian Tang,Doruk Tuncel,Christian Koerner,Thomas Runkler*

Main category: cs.CL

TL;DR: 研究发现，在大型语言模型（LLMs）中，过多的提示示例（“过度提示”）反而会降低性能。通过TF-IDF和分层选择少量示例，可以避免过度提示问题，并在软件需求分类任务中实现更优性能。


<details>
  <summary>Details</summary>
Motivation: 传统观念认为上下文中的少量示例学习（in-context few-shot learning）中，更多示例普遍有益于LLMs。然而，“过度提示”现象——即过多示例导致LLM性能下降——挑战了这一传统认知，促使研究者深入探究这一“少量示例困境”。

Method: 研究构建了一个提示框架，利用三种标准少量示例选择方法：随机抽样、语义嵌入和TF-IDF向量。这些方法在包括GPT-4o、GPT-3.5-turbo、DeepSeek-V3、Gemma-3、LLaMA-3.1、LLaMA-3.2和Mistral在内的多个LLMs上进行了评估。此外，还在两个真实的软件需求分类数据集上，通过逐步增加TF-IDF选择和分层的少量示例数量，以识别每个LLM的最佳数量。

Result: 实验结果表明，在某些LLMs中，加入过多的领域特定示例反而会降低性能，这与之前“越多相关少量示例普遍有益于LLMs”的经验结论相悖。通过结合TF-IDF选择和分层抽样，研究者为每个LLM确定了最佳的示例数量，从而避免了过度提示问题。这种方法使用更少的示例实现了卓越性能，在功能和非功能需求分类方面超越了现有最佳水平1%。

Conclusion: 过度提示是一个真实存在的问题，过多示例可能损害LLM性能。通过精心选择和优化少量示例的数量（例如使用TF-IDF和分层抽样），可以在不触发过度提示的情况下，显著提高LLM在特定任务（如软件需求分类）上的表现，挑战了“越多越好”的传统范式。

Abstract: Over-prompting, a phenomenon where excessive examples in prompts lead to
diminished performance in Large Language Models (LLMs), challenges the
conventional wisdom about in-context few-shot learning. To investigate this
few-shot dilemma, we outline a prompting framework that leverages three
standard few-shot selection methods - random sampling, semantic embedding, and
TF-IDF vectors - and evaluate these methods across multiple LLMs, including
GPT-4o, GPT-3.5-turbo, DeepSeek-V3, Gemma-3, LLaMA-3.1, LLaMA-3.2, and Mistral.
Our experimental results reveal that incorporating excessive domain-specific
examples into prompts can paradoxically degrade performance in certain LLMs,
which contradicts the prior empirical conclusion that more relevant few-shot
examples universally benefit LLMs. Given the trend of LLM-assisted software
engineering and requirement analysis, we experiment with two real-world
software requirement classification datasets. By gradually increasing the
number of TF-IDF-selected and stratified few-shot examples, we identify their
optimal quantity for each LLM. This combined approach achieves superior
performance with fewer examples, avoiding the over-prompting problem, thus
surpassing the state-of-the-art by 1% in classifying functional and
non-functional requirements.

</details>


### [190] [Evaluating LLM Alignment on Personality Inference from Real-World Interview Data](https://arxiv.org/abs/2509.13244)
*Jianfeng Zhu,Julina Maharjan,Xinyu Li,Karin G. Coifman,Ruoming Jin*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）在自然对话中解释人类人格特质的能力，发现现有模型与经验证的心理学构念的对齐程度有限。


<details>
  <summary>Details</summary>
Motivation: LLMs越来越多地被部署在需要细致心理理解的角色中，如情感支持、咨询和决策辅助。然而，它们解释人类人格特质的能力，尤其是在生态有效对话设置中，尚未被充分探索。先前的研究主要使用离散标签，而非来自自然交互的连续、真实人格评估。

Method: 研究引入了一个新的基准数据集，包含半结构化访谈记录和经过验证的连续大五人格特质分数。系统评估了LLMs在三种范式下的表现：1) GPT-4.1 Mini的零样本和思维链提示；2) 对RoBERTa和Meta-LLaMA架构进行基于LoRA的微调；3) 使用预训练BERT和OpenAI的text-embedding-3-small的静态嵌入进行回归。

Result: 所有模型预测与真实人格特质之间的皮尔逊相关系数均低于0.26，表明当前LLMs与经验证的心理学构念的对齐程度有限。思维链提示相对于零样本提示的提升微乎其微，暗示人格推断更多依赖于潜在语义表示而非显式推理。

Conclusion: 当前LLMs在解释复杂人类人格特质方面存在显著挑战。研究结果强调了LLMs与复杂人类属性对齐的困难，并启发了未来在特质特定提示、上下文感知建模和对齐导向微调方面的工作。

Abstract: Large Language Models (LLMs) are increasingly deployed in roles requiring
nuanced psychological understanding, such as emotional support agents,
counselors, and decision-making assistants. However, their ability to interpret
human personality traits, a critical aspect of such applications, remains
unexplored, particularly in ecologically valid conversational settings. While
prior work has simulated LLM "personas" using discrete Big Five labels on
social media data, the alignment of LLMs with continuous, ground-truth
personality assessments derived from natural interactions is largely
unexamined. To address this gap, we introduce a novel benchmark comprising
semi-structured interview transcripts paired with validated continuous Big Five
trait scores. Using this dataset, we systematically evaluate LLM performance
across three paradigms: (1) zero-shot and chain-of-thought prompting with
GPT-4.1 Mini, (2) LoRA-based fine-tuning applied to both RoBERTa and Meta-LLaMA
architectures, and (3) regression using static embeddings from pretrained BERT
and OpenAI's text-embedding-3-small. Our results reveal that all Pearson
correlations between model predictions and ground-truth personality traits
remain below 0.26, highlighting the limited alignment of current LLMs with
validated psychological constructs. Chain-of-thought prompting offers minimal
gains over zero-shot, suggesting that personality inference relies more on
latent semantic representation than explicit reasoning. These findings
underscore the challenges of aligning LLMs with complex human attributes and
motivate future work on trait-specific prompting, context-aware modeling, and
alignment-oriented fine-tuning.

</details>


### [191] [ChartGaze: Enhancing Chart Understanding in LVLMs with Eye-Tracking Guided Attention Refinement](https://arxiv.org/abs/2509.13282)
*Ali Salamatian,Amirhossein Abaskohi,Wan-Cyuan Fan,Mir Rayat Imtiaz Hossain,Leonid Sigal,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 针对LVLM在图表问答中注意力偏差导致的问题，本文提出ChartGaze眼动数据集，并引入眼动引导的注意力优化方法，显著提升了模型的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉-语言模型（LVLMs）在图表问答（CQA）中仍面临挑战，尤其当模型关注图表中不相关区域时。研究旨在解决LVLM注意力与人类注视模式的偏差，以提高其可解释性和准确性。

Method: 1. 构建了ChartGaze眼动数据集，捕捉人类在图表推理任务中的注视模式。2. 系统比较了人类与模型注意力，发现LVLMs的注意力常与人类注视模式存在差异。3. 提出了一种眼动引导的注意力优化方法，旨在将图像-文本注意力与人类注视对齐。

Result: 所提出的方法在多个模型上将答案准确性提高了高达2.56个百分点，并显著改善了注意力对齐。

Conclusion: 将人类眼动数据融入图表LVLM中，有望增强其推理质量和可解释性。

Abstract: Charts are a crucial visual medium for communicating and representing
information. While Large Vision-Language Models (LVLMs) have made progress on
chart question answering (CQA), the task remains challenging, particularly when
models attend to irrelevant regions of the chart. In this work, we present
ChartGaze, a new eye-tracking dataset that captures human gaze patterns during
chart reasoning tasks. Through a systematic comparison of human and model
attention, we find that LVLMs often diverge from human gaze, leading to reduced
interpretability and accuracy. To address this, we propose a gaze-guided
attention refinement that aligns image-text attention with human fixations. Our
approach improves both answer accuracy and attention alignment, yielding gains
of up to 2.56 percentage points across multiple models. These results
demonstrate the promise of incorporating human gaze to enhance both the
reasoning quality and interpretability of chart-focused LVLMs.

</details>


### [192] [WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon Agents](https://arxiv.org/abs/2509.13309)
*Zile Qiao,Guoxin Chen,Xuanzhong Chen,Donglei Yu,Wenbiao Yin,Xinyu Wang,Zhen Zhang,Baixuan Li,Huifeng Yin,Kuan Li,Rui Min,Minpeng Liao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: WebResearcher是一个新颖的AI代理框架，通过迭代式深度研究范式（WebResearcher）和可扩展数据合成引擎（WebFrontier），使AI代理能够自主发现和合成知识，解决了现有方法的上下文限制和噪音污染问题，并实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理在自主发现和合成知识时，面临上下文溢出和噪音污染的困扰，且缺乏系统性地创建能连接被动知识回忆与主动知识构建的研究任务的方法。

Method: 该研究引入了WebResearcher框架，包含两个核心组件：1) WebResearcher，一种迭代式深度研究范式，将深度研究重构为马尔可夫决策过程，代理周期性地将发现整合到报告中并维护专注的工作区，以克服上下文溢出和噪音污染。2) WebFrontier，一个可扩展的数据合成引擎，通过工具增强的复杂性升级生成高质量训练数据，系统性地创建连接知识回忆和构建的研究任务。该范式还支持通过并行思维实现多代理并发探索。

Result: WebResearcher范式生成的训练数据显著增强了工具使用能力，即使对于传统的单上下文方法也有效。该范式通过并行思维自然地实现扩展。在6个具有挑战性的基准测试中，WebResearcher实现了最先进的性能，甚至超越了前沿的专有系统。

Conclusion: WebResearcher框架通过其迭代式深度研究范式和可扩展数据合成引擎，为AI代理自主发现和合成知识提供了一种卓越的方法。它成功解决了现有方法的关键限制，提升了工具使用能力，并实现了领先的性能，为未来的AI知识构建奠定了基础。

Abstract: Recent advances in deep-research systems have demonstrated the potential for
AI agents to autonomously discover and synthesize knowledge from external
sources. In this paper, we introduce WebResearcher, a novel framework for
building such agents through two key components: (1) WebResearcher, an
iterative deep-research paradigm that reformulates deep research as a Markov
Decision Process, where agents periodically consolidate findings into evolving
reports while maintaining focused workspaces, overcoming the context
suffocation and noise contamination that plague existing mono-contextual
approaches; and (2) WebFrontier, a scalable data synthesis engine that
generates high-quality training data through tool-augmented complexity
escalation, enabling systematic creation of research tasks that bridge the gap
between passive knowledge recall and active knowledge construction. Notably, we
find that the training data from our paradigm significantly enhances tool-use
capabilities even for traditional mono-contextual methods. Furthermore, our
paradigm naturally scales through parallel thinking, enabling concurrent
multi-agent exploration for more comprehensive conclusions. Extensive
experiments across 6 challenging benchmarks demonstrate that WebResearcher
achieves state-of-the-art performance, even surpassing frontier proprietary
systems.

</details>


### [193] [Scaling Agents via Continual Pre-training](https://arxiv.org/abs/2509.13310)
*Liangcai Su,Zhen Zhang,Guangyu Li,Zhuo Chen,Chenxi Wang,Maojia Song,Xinyu Wang,Kuan Li,Jialong Wu,Xuanzhong Chen,Zile Qiao,Zhongwang Zhang,Huifeng Yin,Shihao Cai,Runnan Fang,Zhengwei Tao,Wenbiao Yin,Chenxiong Qian,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 现有LLM代理系统在后训练中表现不佳，原因是缺乏强大的代理基础模型。本文首次提出代理持续预训练（Agentic CPT）方法，并基于此开发了AgentFounder模型，在多项基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）作为代理系统在工具使用和多步推理方面能力不足，尤其是在开源实现中。现有后训练方法表现不佳，根源在于缺乏强大的代理基础模型，导致模型在后训练阶段需同时学习多样化的代理行为并与专家演示对齐，从而产生根本性的优化冲突。

Method: 本文首次提出将代理持续预训练（Agentic CPT）整合到深度研究代理的训练流程中，以构建强大的代理基础模型。基于此方法，开发了一个名为AgentFounder的深度研究代理模型。

Result: AgentFounder-30B在10个基准测试中实现了最先进的性能，并保持了强大的工具使用能力，特别是在BrowseComp-en上达到39.9%，BrowseComp-zh上达到43.3%，以及HLE上Pass@1达到31.5%。

Conclusion: 通过引入代理持续预训练（Agentic CPT），可以有效构建强大的代理基础模型，从而克服现有LLM代理系统在后训练中的性能瓶颈，AgentFounder的优异表现证明了这一方法的有效性。

Abstract: Large language models (LLMs) have evolved into agentic systems capable of
autonomous tool use and multi-step reasoning for complex problem-solving.
However, post-training approaches building upon general-purpose foundation
models consistently underperform in agentic tasks, particularly in open-source
implementations. We identify the root cause: the absence of robust agentic
foundation models forces models during post-training to simultaneously learn
diverse agentic behaviors while aligning them to expert demonstrations, thereby
creating fundamental optimization tensions. To this end, we are the first to
propose incorporating Agentic Continual Pre-training (Agentic CPT) into the
deep research agents training pipeline to build powerful agentic foundational
models. Based on this approach, we develop a deep research agent model named
AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve
state-of-the-art performance while retains strong tool-use ability, notably
39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.

</details>


### [194] [Towards General Agentic Intelligence via Environment Scaling](https://arxiv.org/abs/2509.13311)
*Runnan Fang,Shihao Cai,Baixuan Li,Jialong Wu,Guangyu Li,Wenbiao Yin,Xinyu Wang,Xiaobin Wang,Liangcai Su,Zhen Zhang,Shibin Wu,Zhengwei Tao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 该研究通过大规模扩展模拟环境和两阶段微调策略，显著提升了大型语言模型（LLM）的智能体功能调用能力，以适应复杂的现实世界应用。


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型部署到实际应用中需要先进的智能体智能，尤其是精确且鲁棒的功能调用能力。这种能力需要智能体在多样化环境中通过交互来发展，而功能调用能力的广度与训练环境的多样性密切相关。然而，如何以有原则的方式扩展环境以及如何有效地从这些交互经验中训练智能体能力是核心挑战。

Method: 研究设计了一个可扩展的框架，该框架能够自动构建异构的、完全模拟的环境，系统性地拓宽功能调用场景。此外，研究还采用了一种两阶段的智能体微调策略：首先赋予智能体基本智能体能力，然后针对特定领域上下文进行专业化训练。

Result: 在智能体基准测试（tau-bench、tau2-Bench和ACEBench）上进行的广泛实验表明，所训练的模型AgentScaler显著增强了模型的功能调用能力。

Conclusion: 通过设计可扩展的环境构建框架和两阶段的智能体微调策略，本研究成功解决了扩展环境和有效训练智能体能力的挑战，从而显著提升了大型语言模型在复杂现实世界应用中的功能调用能力。

Abstract: Advanced agentic intelligence is a prerequisite for deploying Large Language
Models in practical, real-world applications. Diverse real-world APIs demand
precise, robust function-calling intelligence, which needs agents to develop
these capabilities through interaction in varied environments. The breadth of
function-calling competence is closely tied to the diversity of environments in
which agents are trained. In this work, we scale up environments as a step
towards advancing general agentic intelligence. This gives rise to two central
challenges: (i) how to scale environments in a principled manner, and (ii) how
to effectively train agentic capabilities from experiences derived through
interactions with these environments. To address these, we design a scalable
framework that automatically constructs heterogeneous environments that are
fully simulated, systematically broadening the space of function-calling
scenarios. We further adapt a two-phase agent fine-tuning strategy: first
endowing agents with fundamental agentic capabilities, then specializing them
for domain-specific contexts. Extensive experiments on agentic benchmarks,
tau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model,
AgentScaler, significantly enhances the function-calling capability of models.

</details>


### [195] [WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for Open-Ended Deep Research](https://arxiv.org/abs/2509.13312)
*Zijian Li,Xin Guan,Bo Zhang,Shen Huang,Houquan Zhou,Shaopeng Lai,Ming Yan,Yong Jiang,Pengjun Xie,Fei Huang,Jun Zhang,Jingren Zhou*

Main category: cs.CL

TL;DR: 本文提出WebWeaver，一个双智能体框架，通过模拟人类研究过程，解决开放式深度研究（OEDR）中现有方法存在的静态管道和长上下文失败问题，并在主流OEDR基准测试中达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 当前的开放式深度研究（OEDR）方法存在两大局限性：一是研究流程僵化，规划与证据获取分离；二是采用一次性生成范式，容易出现“中间丢失”和幻觉等长上下文失败问题。这些限制促使研究者寻求更有效的方法来综合海量信息并生成有洞察力的报告。

Method: 本文引入WebWeaver框架，它由两个智能体组成：规划器和撰写器。规划器采用动态循环，迭代地交织证据获取与大纲优化，生成一个全面、有来源依据的大纲，并链接到证据记忆库。撰写器则执行分层检索和写作过程，逐节撰写报告，通过针对性地从记忆库中检索每部分所需证据，有效缓解长上下文问题。

Result: WebWeaver框架在DeepResearch Bench、DeepConsult和DeepResearchGym等主要的OEDR基准测试中均取得了新的最先进（state-of-the-art）成果。

Conclusion: 研究结果验证了WebWeaver以人为中心、迭代式的方法论，表明自适应规划和聚焦式综合对于生成高质量、可靠且结构良好的报告至关重要。

Abstract: This paper tackles open-ended deep research (OEDR), a complex challenge where
AI agents must synthesize vast web-scale information into insightful reports.
Current approaches are plagued by dual-fold limitations: static research
pipelines that decouple planning from evidence acquisition and one-shot
generation paradigms that easily suffer from long-context failure issues like
"loss in the middle" and hallucinations. To address these challenges, we
introduce WebWeaver, a novel dual-agent framework that emulates the human
research process. The planner operates in a dynamic cycle, iteratively
interleaving evidence acquisition with outline optimization to produce a
comprehensive, source-grounded outline linking to a memory bank of evidence.
The writer then executes a hierarchical retrieval and writing process,
composing the report section by section. By performing targeted retrieval of
only the necessary evidence from the memory bank for each part, it effectively
mitigates long-context issues. Our framework establishes a new state-of-the-art
across major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and
DeepResearchGym. These results validate our human-centric, iterative
methodology, demonstrating that adaptive planning and focused synthesis are
crucial for producing high-quality, reliable, and well-structured reports.

</details>


### [196] [ReSum: Unlocking Long-Horizon Search Intelligence via Context Summarization](https://arxiv.org/abs/2509.13313)
*Xixi Wu,Kuan Li,Yida Zhao,Liwen Zhang,Litu Ou,Huifeng Yin,Zhongwang Zhang,Yong Jiang,Pengjun Xie,Fei Huang,Minhao Cheng,Shuai Wang,Hong Cheng,Jingren Zhou*

Main category: cs.CL

TL;DR: ReSum是一种新范式，通过周期性上下文总结克服了大型语言模型（LLM）网络代理的上下文窗口限制，实现了无限探索并显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的网络代理（如ReAct）在知识密集型任务中表现出色，但受限于上下文窗口大小，难以处理涉及多实体、复杂关系和高不确定性的复杂查询，这些查询需要大量搜索，导致上下文预算迅速耗尽。

Method: 本文提出了ReSum范式，通过周期性上下文总结实现无限探索，将不断增长的交互历史转换为紧凑的推理状态。为了适应这一范式，引入了ReSum-GRPO，它通过结合GRPO、分段轨迹训练和优势广播，使代理熟悉基于总结的推理。

Result: 在三个基准测试中，ReSum相对于ReAct平均绝对性能提升了4.5%，经过ReSum-GRPO训练后，性能进一步提升高达8.2%。值得注意的是，仅使用1K训练样本，WebResummer-30B（ReSum-GRPO训练的WebSailor-30B版本）在BrowseComp-zh上实现了33.3%的Pass@1，在BrowseComp-en上实现了18.3%的Pass@1，超越了现有开源网络代理。

Conclusion: ReSum及其训练方法ReSum-GRPO有效解决了LLM网络代理的上下文窗口限制问题，通过周期性总结实现了无限探索，显著提升了代理在复杂网络任务上的性能，并超越了现有SOTA开源代理。

Abstract: Large Language Model (LLM)-based web agents demonstrate strong performance on
knowledge-intensive tasks but are hindered by context window limitations in
paradigms like ReAct. Complex queries involving multiple entities, intertwined
relationships, and high uncertainty demand extensive search cycles that rapidly
exhaust context budgets before reaching complete solutions. To overcome this
challenge, we introduce ReSum, a novel paradigm that enables indefinite
exploration through periodic context summarization. ReSum converts growing
interaction histories into compact reasoning states, maintaining awareness of
prior discoveries while bypassing context constraints. For paradigm adaptation,
we propose ReSum-GRPO, integrating GRPO with segmented trajectory training and
advantage broadcasting to familiarize agents with summary-conditioned
reasoning. Extensive experiments on web agents of varying scales across three
benchmarks demonstrate that ReSum delivers an average absolute improvement of
4.5\% over ReAct, with further gains of up to 8.2\% following ReSum-GRPO
training. Notably, with only 1K training samples, our WebResummer-30B (a
ReSum-GRPO-trained version of WebSailor-30B) achieves 33.3\% Pass@1 on
BrowseComp-zh and 18.3\% on BrowseComp-en, surpassing existing open-source web
agents.

</details>


### [197] [Do Natural Language Descriptions of Model Activations Convey Privileged Information?](https://arxiv.org/abs/2509.13316)
*Millicent Li,Alberto Mario Ceballos Arroyo,Giordano Rogers,Naomi Saphra,Byron C. Wallace*

Main category: cs.CL

TL;DR: 该研究质疑了使用第二个LLM将目标LLM内部表示转换为自然语言描述的口语化解释方法。研究发现，这些方法在没有访问目标模型内部的情况下也能成功，且口语化内容常反映口语化LLM的参数知识而非目标LLM的激活。因此，研究呼吁需要更具针对性的基准和实验控制来评估这些方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM可解释性方法通过“口语化LLM”将目标LLM的内部表示转换为自然语言描述，旨在揭示目标模型如何处理输入。然而，研究者质疑这些激活口语化方法是否真正提供了关于目标模型内部运作的“特权知识”，抑或仅仅传达了关于其输入的信息。

Method: 研究首先对现有工作中使用的流行口语化方法和数据集进行了批判性评估。随后，研究进行了对照实验。

Result: 1. 发现这些口语化方法在未访问目标模型内部的情况下也能在基准测试中取得成功，这表明当前的数据集不适合评估口语化方法。
2. 对照实验揭示，口语化内容通常反映生成它们的口语化LLM的参数知识，而非被解码的目标LLM的激活。

Conclusion: 研究结果表明，需要有针对性的基准和实验控制，才能严格评估口语化方法是否能为LLM的运作提供有意义的见解。

Abstract: Recent interpretability methods have proposed to translate LLM internal
representations into natural language descriptions using a second verbalizer
LLM. This is intended to illuminate how the target model represents and
operates on inputs. But do such activation verbalization approaches actually
provide privileged knowledge about the internal workings of the target model,
or do they merely convey information about its inputs? We critically evaluate
popular verbalization methods across datasets used in prior work and find that
they succeed at benchmarks without any access to target model internals,
suggesting that these datasets are not ideal for evaluating verbalization
methods. We then run controlled experiments which reveal that verbalizations
often reflect the parametric knowledge of the verbalizer LLM which generated
them, rather than the activations of the target LLM being decoded. Taken
together, our results indicate a need for targeted benchmarks and experimental
controls to rigorously assess whether verbalization methods provide meaningful
insights into the operations of LLMs.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [198] [An integrated process for design and control of lunar robotics using AI and simulation](https://arxiv.org/abs/2509.12367)
*Daniel Lindmark,Jonas Andersson,Kenneth Bodin,Tora Bodin,Hugo Börjesson,Fredrik Nordfeldth,Martin Servin*

Main category: cs.RO

TL;DR: 本文提出一个集成框架，用于并行开发月球施工设备的物理设计和控制，该框架基于OpenPLX语言，将CAD模型、自主系统与高保真实时3D仿真连接起来，并通过案例研究展示其能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了改进月球施工设备的开发过程，实现物理设计和控制的并行探索，以应对这类复杂系统在月球严苛环境下的开发挑战。

Method: 该研究采用了一个技术框架，核心是OpenPLX，这是一种可读写声明性语言。OpenPLX将CAD模型和自主系统与高保真、实时的3D仿真连接起来，仿真内容包括接触式多体动力学、机械-月壤相互作用力以及非理想传感器。框架通过视觉-语言模型和强化学习控制策略实现了导航和运动。

Result: 研究通过两个案例研究（包括一个结合视觉-语言模型进行导航和基于强化学习控制策略进行运动的自主月球车）展示了该框架的能力和有效性。

Conclusion: 该集成框架成功支持了月球施工设备的开发过程，实现了物理设计和控制的并行探索，并通过先进的仿真和AI技术验证了其可行性，为未来月球任务中的设备开发提供了有效工具。

Abstract: We envision an integrated process for developing lunar construction
equipment, where physical design and control are explored in parallel. In this
paper, we describe a technical framework that supports this process. It relies
on OpenPLX, a readable/writable declarative language that links CAD-models and
autonomous systems to high-fidelity, real-time 3D simulations of contacting
multibody dynamics, machine regolith interaction forces, and non-ideal sensors.
To demonstrate its capabilities, we present two case studies, including an
autonomous lunar rover that combines a vision-language model for navigation
with a reinforcement learning-based control policy for locomotion.

</details>


### [199] [Geometric Red-Teaming for Robotic Manipulation](https://arxiv.org/abs/2509.12379)
*Divyam Goel,Yufei Wang,Tiancheng Wu,Guixiu Qiao,Pavel Piliptchak,David Held,Zackory Erickson*

Main category: cs.RO

TL;DR: 本文提出了几何红队（GRT）框架，通过自动生成几何扰动（CrashShapes）来发现机器人操作策略的脆弱故障模式，并展示了通过“蓝队”微调可以显著提高策略在这些失败模式下的鲁棒性，并在真实机器人上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 标准的机器人操作评估协议通常在精心策划的、同分布的测试集上进行，这限制了对系统在合理变化下如何失败的深入了解，无法揭示策略的真实鲁棒性。

Method: 引入了几何红队（GRT）框架，通过以物体为中心的几何扰动来探测鲁棒性。该方法结合了基于雅可比场（Jacobian field）的形变模型和无梯度（gradient-free）、模拟器在环（simulator-in-the-loop）的优化策略，自动生成“CrashShapes”——结构有效且用户受限的网格变形，这些变形能导致预训练操作策略的灾难性失败。此外，还提出了“蓝队”（blue-teaming）方法，即对单个CrashShapes进行微调以改进策略。

Result: GRT在插入、关节操作和抓取任务中持续发现能使策略性能崩溃的几何变形，揭示了静态基准测试未能发现的脆弱故障模式。通过对单个CrashShapes进行“蓝队”微调，任务成功率提高了高达60个百分点，同时保持了原始物体上的性能。真实机器人验证显示，模拟的CrashShapes将任务成功率从90%降低到22.5%，而“蓝队”微调能将相应真实世界几何体的性能恢复到90%，与模拟结果高度吻合。

Conclusion: GRT提供了一个通用的、以物体为中心的结构化鲁棒性评估框架，用于机器人操作。通过红队生成的几何体（CrashShapes）进行有针对性的策略优化（蓝队）对于提高机器人操作策略的鲁棒性和性能具有显著实用价值，并在模拟和真实世界中得到了有效验证。

Abstract: Standard evaluation protocols in robotic manipulation typically assess policy
performance over curated, in-distribution test sets, offering limited insight
into how systems fail under plausible variation. We introduce Geometric
Red-Teaming (GRT), a red-teaming framework that probes robustness through
object-centric geometric perturbations, automatically generating CrashShapes --
structurally valid, user-constrained mesh deformations that trigger
catastrophic failures in pre-trained manipulation policies. The method
integrates a Jacobian field-based deformation model with a gradient-free,
simulator-in-the-loop optimization strategy. Across insertion, articulation,
and grasping tasks, GRT consistently discovers deformations that collapse
policy performance, revealing brittle failure modes missed by static
benchmarks. By combining task-level policy rollouts with constraint-aware shape
exploration, we aim to build a general purpose framework for structured,
object-centric robustness evaluation in robotic manipulation. We additionally
show that fine-tuning on individual CrashShapes, a process we refer to as
blue-teaming, improves task success by up to 60 percentage points on those
shapes, while preserving performance on the original object, demonstrating the
utility of red-teamed geometries for targeted policy refinement. Finally, we
validate both red-teaming and blue-teaming results with a real robotic arm,
observing that simulated CrashShapes reduce task success from 90% to as low as
22.5%, and that blue-teaming recovers performance to up to 90% on the
corresponding real-world geometry -- closely matching simulation outcomes.
Videos and code can be found on our project website:
https://georedteam.github.io/ .

</details>


### [200] [Distributed Event-Triggered Distance-Based Formation Control for Multi-Agent Systems](https://arxiv.org/abs/2509.12390)
*Evangelos Psomiadis,Panagiotis Tsiotras*

Main category: cs.RO

TL;DR: 本文提出了一种分布式事件触发编队控制器，用于资源受限的多智能体系统，通过基于智能体间距离测量，仅在测量误差超过阈值时更新控制，从而显著减少控制工作量并保持编队性能。


<details>
  <summary>Details</summary>
Motivation: 在资源有限的多智能体系统中，需要从任意初始配置实现期望编队，并减少不必要的控制更新以节约资源。

Method: 提出了一种分布式事件触发编队控制器，该控制器依赖于智能体间的距离测量。只有当测量误差超过预定义阈值时，才会触发控制更新，同时确保系统稳定性。

Result: 通过广泛的仿真和真实世界实验验证，并与周期性触发策略进行比较，结果表明事件触发方法在保持编队性能的同时，显著减少了控制工作量。

Conclusion: 所提出的事件触发方法能够有效解决资源受限多智能体系统的协同编队控制问题，通过减少控制更新来节约资源，同时不牺牲编队性能。

Abstract: This paper addresses the problem of collaborative formation control for
multi-agent systems with limited resources. We consider a team of robots tasked
with achieving a desired formation from arbitrary initial configurations. To
reduce unnecessary control updates and conserve resources, we propose a
distributed event-triggered formation controller that relies on inter-agent
distance measurements. Control updates are triggered only when the measurement
error exceeds a predefined threshold, ensuring system stability. The proposed
controller is validated through extensive simulations and real-world
experiments involving different formations, communication topologies,
scalability tests, and variations in design parameters, while also being
compared against periodic triggering strategies. Results demonstrate that the
event-triggered approach significantly reduces control efforts while preserving
formation performance.

</details>


### [201] [MinJointTracker: Real-time inertial kinematic chain tracking with joint position estimation and minimal state size](https://arxiv.org/abs/2509.12398)
*Michael Lorenz,Bertram Taetz,Gabriele Bleser-Taetz,Didier Stricker*

Main category: cs.RO

TL;DR: 本文提出了一种实时、免校准的惯性运动捕捉算法，通过递归贝叶斯估计同时获取全局IMU角运动学和IMU坐标系中的关节位置，实现了无漂移的姿态估计和鲁棒的关节位置收敛。


<details>
  <summary>Details</summary>
Motivation: 目前的惯性运动捕捉方法需要大量的离线校准（如肢体长度、IMU与肢体坐标系之间的相对方向、IMU坐标系中的关节位置），使得设置过程非常不便，限制了其在实验室外的应用。

Method: 该研究贡献了一种实时、免校准的运动学链惯性跟踪方法，采用递归贝叶斯估计，以最小状态尺寸同时估计全局IMU角运动学和IMU坐标系中的关节位置。

Result: 在三连杆运动链（机械臂研究）的模拟IMU数据和健康人行走（下半身研究）的重模拟IMU数据上的实验结果表明，该免校准、轻量级算法不仅提供了无漂移的相对姿态估计，还为单个IMU提供了具有全局航向参考的无漂移绝对姿态估计，并在不同运动场景中实现了关节位置估计的鲁棒且快速收敛。

Conclusion: 所提出的免校准、轻量级算法成功解决了现有惯性运动捕捉方法的设置不便问题，能够提供无漂移的相对和绝对姿态估计以及鲁棒的关节位置估计，适用于实时运动跟踪。

Abstract: Inertial motion capture is a promising approach for capturing motion outside
the laboratory. However, as one major drawback, most of the current methods
require different quantities to be calibrated or computed offline as part of
the setup process, such as segment lengths, relative orientations between
inertial measurement units (IMUs) and segment coordinate frames (IMU-to-segment
calibrations) or the joint positions in the IMU frames. This renders the setup
process inconvenient. This work contributes to real-time capable
calibration-free inertial tracking of a kinematic chain, i.e. simultaneous
recursive Bayesian estimation of global IMU angular kinematics and joint
positions in the IMU frames, with a minimal state size. Experimental results on
simulated IMU data from a three-link kinematic chain (manipulator study) as
well as re-simulated IMU data from healthy humans walking (lower body study)
show that the calibration-free and lightweight algorithm provides not only
drift-free relative but also drift-free absolute orientation estimates with a
global heading reference for only one IMU as well as robust and fast
convergence of joint position estimates in the different movement scenarios.

</details>


### [202] [Computing forward statics from tendon-length in flexible-joint hyper-redundant manipulators](https://arxiv.org/abs/2509.12444)
*Weiting Feng,Kyle L. Walker,Yunjie Yang,Francesco Giorgio-Serchi*

Main category: cs.RO

TL;DR: 本文提出了一种超冗余腱驱动机械臂的正向静力学迭代解法，该方法可同时考虑肌腱张力和长度作为输入，并基于螺旋理论公式化。实验验证表明，该方法仅使用肌腱长度即可实现静态条件下的开环控制，从而避免了张力测量和状态估计的实际问题。


<details>
  <summary>Details</summary>
Motivation: 传统的腱驱动机械臂控制依赖于调整肌腱长度，但在考虑重力的大型机械臂中，需要解决静态力问题，通常以肌腱力作为输入或通过姿态测量迭代调整。然而，肌腱张力测量或准确的机械臂状态估计往往难以获得。

Method: 本文通过协调缆绳张力和长度作为系统正向静力学求解的输入，提出了一种解决方案。具体方法包括：开发基于螺旋理论的腱驱动、多段、弹性关节超冗余机械臂的公式；引入一种正向静力学迭代解法，该方法可等效地使用肌腱长度或张力作为输入。该策略首先通过传统的张力输入进行实验验证，随后展示了仅使用肌腱长度时的有效性。

Result: 实验结果证实了该方法在仅使用肌腱长度作为输入时也能有效工作。这表明在静态条件下，仅使用运动学输入（肌腱长度）即可实现开环控制。

Conclusion: 该方法通过仅使用运动学输入（肌腱长度）实现静态条件下的开环控制，从而绕过了超冗余系统在张力测量和状态估计方面的一些实际问题。

Abstract: Hyper-redundant tendon-driven manipulators offer greater flexibility and
compliance over traditional manipulators. A common way of controlling such
manipulators relies on adjusting tendon lengths, which is an accessible control
parameter. This approach works well when the kinematic configuration is
representative of the real operational conditions. However, when dealing with
manipulators of larger size subject to gravity, it becomes necessary to solve a
static force problem, using tendon force as the input and employing a mapping
from the configuration space to retrieve tendon length. Alternatively,
measurements of the manipulator posture can be used to iteratively adjust
tendon lengths to achieve a desired posture. Hence, either tension measurement
or state estimation of the manipulator are required, both of which are not
always accurately available. Here, we propose a solution by reconciling cables
tension and length as the input for the solution of the system forward statics.
We develop a screw-based formulation for a tendon-driven, multi-segment,
hyper-redundant manipulator with elastic joints and introduce a forward statics
iterative solution method that equivalently makes use of either tendon length
or tension as the input. This strategy is experimentally validated using a
traditional tension input first, subsequently showing the efficacy of the
method when exclusively tendon lengths are used. The results confirm the
possibility to perform open-loop control in static conditions using a kinematic
input only, thus bypassing some of the practical problems with tension
measurement and state estimation of hyper-redundant systems.

</details>


### [203] [Neural 3D Object Reconstruction with Small-Scale Unmanned Aerial Vehicles](https://arxiv.org/abs/2509.12458)
*Àlmos Veres-Vitàlyos,Genis Castillo Gomez-Raya,Filip Lemic,Daniel Johannes Bugelnig,Bernhard Rinner,Sergi Abadal,Xavier Costa-Pérez*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的系统架构，使重量小于100克的无人机能够实现全自主、高保真地对静态物体进行3D扫描，通过双重重建流程和实时反馈，显著提高了重建质量。


<details>
  <summary>Details</summary>
Motivation: 小型无人机在有效载荷和自主性方面存在显著限制，这阻碍了它们执行复杂任务，如高质量的3D重建，尤其是在室内和难以到达的区域。

Method: 该系统采用双重重建流程：一个近实时（near-RT）流程使用SfM生成即时点云，并根据模型质量动态调整无人机轨迹以捕捉未覆盖区域；一个非实时（non-RT）流程使用基于NeRF的神经网络3D重建（N3DR），结合SfM相机姿态和UWB定位数据，实现卓越的精度。该架构在Crazyflie 2.1无人机上实现并验证，支持单无人机和多无人机配置。

Result: 实验结果表明，动态轨迹适应相比静态飞行路径，能够持续提高重建质量。

Conclusion: 这项工作展示了一种可扩展的自主解决方案，解锁了微型无人机在受限环境中进行精细3D重建的潜力，而此前这种能力仅限于更大的平台。

Abstract: Small Unmanned Aerial Vehicles (UAVs) exhibit immense potential for
navigating indoor and hard-to-reach areas, yet their significant constraints in
payload and autonomy have largely prevented their use for complex tasks like
high-quality 3-Dimensional (3D) reconstruction. To overcome this challenge, we
introduce a novel system architecture that enables fully autonomous,
high-fidelity 3D scanning of static objects using UAVs weighing under 100
grams. Our core innovation lies in a dual-reconstruction pipeline that creates
a real-time feedback loop between data capture and flight control. A
near-real-time (near-RT) process uses Structure from Motion (SfM) to generate
an instantaneous pointcloud of the object. The system analyzes the model
quality on the fly and dynamically adapts the UAV's trajectory to intelligently
capture new images of poorly covered areas. This ensures comprehensive data
acquisition. For the final, detailed output, a non-real-time (non-RT) pipeline
employs a Neural Radiance Fields (NeRF)-based Neural 3D Reconstruction (N3DR)
approach, fusing SfM-derived camera poses with precise Ultra Wide-Band (UWB)
location data to achieve superior accuracy. We implemented and validated this
architecture using Crazyflie 2.1 UAVs. Our experiments, conducted in both
single- and multi-UAV configurations, conclusively show that dynamic trajectory
adaptation consistently improves reconstruction quality over static flight
paths. This work demonstrates a scalable and autonomous solution that unlocks
the potential of miniaturized UAVs for fine-grained 3D reconstruction in
constrained environments, a capability previously limited to much larger
platforms.

</details>


### [204] [Bio-inspired tail oscillation enables robot fast crawling on deformable granular terrains](https://arxiv.org/abs/2509.12468)
*Shipeng Liu,Meghana Sagare,Shubham Patil,Feifei Qian*

Main category: cs.RO

TL;DR: 受弹涂鱼启发，研究发现机器人通过主动摆动尾巴能显著提高在颗粒介质上的移动速度，并通过流化基质来减少阻力，并提出了基于基质强度和尾巴形态的尾巴动作选择设计原则。


<details>
  <summary>Details</summary>
Motivation: 变形基质（如沙子和泥土）对陆地机器人构成重大挑战，因为机器人与地形之间的相互作用复杂。受弹涂鱼（一种能自然调整尾巴形态和运动以在这些环境中导航的两栖动物）的启发，本研究旨在探索尾巴设计和控制如何共同增强鳍驱动机器人在颗粒介质上的移动能力。

Method: 使用一个仿生弹涂鱼机器人，通过实验比较了闲置尾巴和主动摆动尾巴配置下的移动性能。同时进行了剪切力测量，以理解性能提升的机制。

Result: 尾巴摆动使机器人速度提高了67%，身体阻力降低了46%。剪切力测量显示，这种改进是通过尾巴摆动流化基质，从而减少阻力实现的。此外，尾巴形态强烈影响了摆动策略：具有较大水平表面积的设计通过限制插入深度，更有效地利用了摆动减小的剪切阻力。

Conclusion: 研究提出了一个设计原则，用于根据基质强度和尾巴形态来选择尾巴动作。这些结果为改进机器人在变形基质上的移动提供了新的尾巴设计和控制见解，对农业机器人、搜救和环境探索具有重要意义。

Abstract: Deformable substrates such as sand and mud present significant challenges for
terrestrial robots due to complex robot-terrain interactions. Inspired by
mudskippers, amphibious animals that naturally adjust their tail morphology and
movement jointly to navigate such environments, we investigate how tail design
and control can jointly enhance flipper-driven locomotion on granular media.
Using a bio-inspired robot modeled after the mudskipper, we experimentally
compared locomotion performance between idle and actively oscillating tail
configurations. Tail oscillation increased robot speed by 67% and reduced body
drag by 46%. Shear force measurements revealed that this improvement was
enabled by tail oscillation fluidizing the substrate, thereby reducing
resistance. Additionally, tail morphology strongly influenced the oscillation
strategy: designs with larger horizontal surface areas leveraged the
oscillation-reduced shear resistance more effectively by limiting insertion
depth. Based on these findings, we present a design principle to inform tail
action selection based on substrate strength and tail morphology. Our results
offer new insights into tail design and control for improving robot locomotion
on deformable substrates, with implications for agricultural robotics, search
and rescue, and environmental exploration.

</details>


### [205] [Learning to Generate Pointing Gestures in Situated Embodied Conversational Agents](https://arxiv.org/abs/2509.12507)
*Anna Deichler,Siyang Wang,Simon Alexanderson,Jonas Beskow*

Main category: cs.RO

TL;DR: 本文提出了一种结合模仿学习和强化学习的框架，用于在具身智能体中生成自然且准确的指点手势，并在自然度和准确性方面优于监督学习模型。


<details>
  <summary>Details</summary>
Motivation: 机器人和智能体研究的主要目标是实现与人类的自然交流。虽然近期工作关注语言和语音等口头交流模式，但非口头交流（如指点手势）对于灵活互动至关重要。

Method: 该研究结合了模仿学习和强化学习来生成指点手势。利用小型动作捕捉数据集学习运动控制策略，以生成物理有效、自然且指代准确的手势。通过客观指标和与人类用户进行的虚拟现实指代游戏进行评估。

Result: 结果表明，与最先进的监督学习模型相比，该系统在自然度和准确性方面表现更优。

Conclusion: 模仿学习与强化学习结合的方法在生成交流手势方面前景广阔，并有望应用于机器人。

Abstract: One of the main goals of robotics and intelligent agent research is to enable
natural communication with humans in physically situated settings. While recent
work has focused on verbal modes such as language and speech, non-verbal
communication is crucial for flexible interaction. We present a framework for
generating pointing gestures in embodied agents by combining imitation and
reinforcement learning. Using a small motion capture dataset, our method learns
a motor control policy that produces physically valid, naturalistic gestures
with high referential accuracy. We evaluate the approach against supervised
learning and retrieval baselines in both objective metrics and a virtual
reality referential game with human users. Results show that our system
achieves higher naturalness and accuracy than state-of-the-art supervised
models, highlighting the promise of imitation-RL for communicative gesture
generation and its potential application to robots.

</details>


### [206] [Zero to Autonomy in Real-Time: Online Adaptation of Dynamics in Unstructured Environments](https://arxiv.org/abs/2509.12516)
*William Ward,Sarah Etter,Jesse Quattrociocchi,Christian Ellis,Adam J. Thorpe,Ufuk Topcu*

Main category: cs.RO

TL;DR: 该论文提出了一种结合函数编码器和递归最小二乘的在线自适应方法，使自主机器人在几秒内从零先验知识实现安全控制，尤其是在地形突变（如冰面）时，能实时调整模型以提高规划准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在非结构化环境中运行时，需要从零先验知识迅速实现安全控制。地形的突然变化（如过渡到冰面）会导致动力学模型发生偏移，若模型不能实时自适应，则会使规划器不稳定。

Method: 该方法将函数编码器与递归最小二乘法相结合，将函数编码器系数视为潜在状态，并从流式里程计数据中进行更新。这种方法实现了常数时间系数估计，无需基于梯度的内循环更新，从而只需几秒数据即可实现自适应。

Result: 在Van der Pol系统、Unity模拟器和Clearpath Jackal机器人（包括冰面挑战地形）上的评估表明，该方法提高了模型准确性和下游规划效果，与静态和元学习基线相比，显著减少了碰撞。

Conclusion: 所提出的在线自适应方法能使自主机器人快速适应动态环境中的模型变化，显著提升了模型准确性和规划性能，从而在非结构化环境中实现更安全的控制，尤其适用于地形突变的情况。

Abstract: Autonomous robots must go from zero prior knowledge to safe control within
seconds to operate in unstructured environments. Abrupt terrain changes, such
as a sudden transition to ice, create dynamics shifts that can destabilize
planners unless the model adapts in real-time. We present a method for online
adaptation that combines function encoders with recursive least squares,
treating the function encoder coefficients as latent states updated from
streaming odometry. This yields constant-time coefficient estimation without
gradient-based inner-loop updates, enabling adaptation from only a few seconds
of data. We evaluate our approach on a Van der Pol system to highlight
algorithmic behavior, in a Unity simulator for high-fidelity off-road
navigation, and on a Clearpath Jackal robot, including on a challenging terrain
at a local ice rink. Across these settings, our method improves model accuracy
and downstream planning, reducing collisions compared to static and
meta-learning baselines.

</details>


### [207] [Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning](https://arxiv.org/abs/2509.12531)
*Scott Jones,Liyou Zhou,Sebastian W. Pattinson*

Main category: cs.RO

TL;DR: 本文研究了预训练视觉模型（PVMs）在基于模型的强化学习（MBRL）中对视觉泛化的有效性，发现PVMs在严重视觉域偏移下表现优异，且部分微调能保持最佳性能。


<details>
  <summary>Details</summary>
Motivation: 传统的视觉运动策略学习在视觉场景变化下泛化性差。预训练视觉模型（PVMs）在无模型强化学习（MFRL）中能提高鲁棒性，但现有研究发现PVMs在样本效率更高的基于模型的强化学习（MBRL）中却无效。本文旨在探究PVMs在MBRL中对视觉域偏移泛化的有效性。

Method: 研究了PVMs在MBRL中，特别是在视觉域偏移下的泛化能力。通过与从头训练的基线模型进行比较，并进一步探究了不同程度的PVMs微调（fine-tuning）对性能的影响。

Result: 在严重视觉域偏移场景下，PVMs的表现远优于从头训练的基线模型。研究还发现，部分微调（partial fine-tuning）的PVMs在最极端的分布偏移下能保持最高的平均任务性能。

Conclusion: PVMs在促进视觉策略学习的鲁棒性方面非常成功，为它们在基于模型的机器人学习应用中更广泛的采用提供了有力证据。

Abstract: In visuomotor policy learning, the control policy for the robotic agent is
derived directly from visual inputs. The typical approach, where a policy and
vision encoder are trained jointly from scratch, generalizes poorly to novel
visual scene changes. Using pre-trained vision models (PVMs) to inform a policy
network improves robustness in model-free reinforcement learning (MFRL). Recent
developments in Model-based reinforcement learning (MBRL) suggest that MBRL is
more sample-efficient than MFRL. However, counterintuitively, existing work has
found PVMs to be ineffective in MBRL. Here, we investigate PVM's effectiveness
in MBRL, specifically on generalization under visual domain shifts. We show
that, in scenarios with severe shifts, PVMs perform much better than a baseline
model trained from scratch. We further investigate the effects of varying
levels of fine-tuning of PVMs. Our results show that partial fine-tuning can
maintain the highest average task performance under the most extreme
distribution shifts. Our results demonstrate that PVMs are highly successful in
promoting robustness in visual policy learning, providing compelling evidence
for their wider adoption in model-based robotic learning applications.

</details>


### [208] [Robust Online Residual Refinement via Koopman-Guided Dynamics Modeling](https://arxiv.org/abs/2509.12562)
*Zhefei Gong,Shangke Lyu,Pengxiang Ding,Wei Xiao,Donglin Wang*

Main category: cs.RO

TL;DR: 为解决模仿学习在长周期高精度任务中的复合误差问题，本文提出了KORR框架。它通过Koopman算子理论引入全局动力学模型指导残差策略更新，显著提升了性能、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在长周期任务和高精度控制中因复合误差而表现不佳。现有残差策略学习方法侧重局部修正，缺乏对状态演化的全局理解，限制了鲁棒性和泛化能力。

Method: 提出KORR（Koopman-guided Online Residual Refinement）框架。该方法利用Koopman算子理论在学习到的潜在空间中施加线性时不变结构，以实现可靠的状态转换和改进的外推。残差修正基于Koopman预测的潜在状态进行条件化，从而实现全局信息引导和稳定的动作修正。

Result: 在受各种扰动影响的长周期、精细机器人家具组装任务中，KORR在性能、鲁棒性和泛化能力方面均持续优于强基线。研究结果还强调了基于Koopman的建模在连接现代学习方法与经典控制理论方面的潜力。

Conclusion: KORR框架通过将Koopman算子理论引入残差策略学习，有效解决了模仿学习在长周期高精度任务中的挑战。Koopman建模在弥合现代学习与经典控制理论之间鸿沟方面具有巨大潜力。

Abstract: Imitation learning (IL) enables efficient skill acquisition from
demonstrations but often struggles with long-horizon tasks and high-precision
control due to compounding errors. Residual policy learning offers a promising,
model-agnostic solution by refining a base policy through closed-loop
corrections. However, existing approaches primarily focus on local corrections
to the base policy, lacking a global understanding of state evolution, which
limits robustness and generalization to unseen scenarios. To address this, we
propose incorporating global dynamics modeling to guide residual policy
updates. Specifically, we leverage Koopman operator theory to impose linear
time-invariant structure in a learned latent space, enabling reliable state
transitions and improved extrapolation for long-horizon prediction and unseen
environments. We introduce KORR (Koopman-guided Online Residual Refinement), a
simple yet effective framework that conditions residual corrections on
Koopman-predicted latent states, enabling globally informed and stable action
refinement. We evaluate KORR on long-horizon, fine-grained robotic furniture
assembly tasks under various perturbations. Results demonstrate consistent
gains in performance, robustness, and generalization over strong baselines. Our
findings further highlight the potential of Koopman-based modeling to bridge
modern learning methods with classical control theory.

</details>


### [209] [The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning](https://arxiv.org/abs/2509.12594)
*Titong Jiang,Xuefeng Jiang,Yuan Ma,Xin Wen,Bailin Li,Kun Zhan,Peng Jia,Yahui Liu,Sheng Sun,Xianpeng Lang*

Main category: cs.RO

TL;DR: LightVLA提出了一种简单有效的可微分视觉令牌剪枝框架，用于视觉-语言-动作（VLA）模型，通过自适应地修剪视觉令牌，同时提高效率和任务成功率。


<details>
  <summary>Details</summary>
Motivation: VLA模型在机器人任务中表现出色，但在资源受限平台上部署时，由于对大量视觉令牌进行基于注意力的计算，效率受到瓶颈。

Method: LightVLA通过自适应、性能驱动的方式修剪视觉令牌。它生成动态查询来评估视觉令牌的重要性，并采用Gumbel softmax实现可微分的令牌选择。通过微调，LightVLA学习保留信息最丰富的视觉令牌，同时剪枝对任务执行无贡献的令牌。LightVLA无需启发式参数，不引入额外可训练参数。此外，还探讨了具有额外可训练参数的LightVLA*方法。

Result: LightVLA在LIBERO基准测试中，在多样化任务上优于不同的VLA模型和现有令牌剪枝方法。它以显著降低的计算开销实现了更高的成功率：FLOPs减少59.1%，延迟减少38.2%，任务成功率提高2.9%。LightVLA*也取得了令人满意的性能。研究表明，LightVLA自发地从性能驱动的角度学习剪枝令牌。

Conclusion: LightVLA是首个将自适应视觉令牌剪枝应用于VLA任务，同时兼顾效率和性能的工作，为更高效、强大和实用的实时机器人系统迈出了重要一步。

Abstract: We present LightVLA, a simple yet effective differentiable token pruning
framework for vision-language-action (VLA) models. While VLA models have shown
impressive capability in executing real-world robotic tasks, their deployment
on resource-constrained platforms is often bottlenecked by the heavy
attention-based computation over large sets of visual tokens. LightVLA
addresses this challenge through adaptive, performance-driven pruning of visual
tokens: It generates dynamic queries to evaluate visual token importance, and
adopts Gumbel softmax to enable differentiable token selection. Through
fine-tuning, LightVLA learns to preserve the most informative visual tokens
while pruning tokens which do not contribute to task execution, thereby
improving efficiency and performance simultaneously. Notably, LightVLA requires
no heuristic magic numbers and introduces no additional trainable parameters,
making it compatible with modern inference frameworks. Experimental results
demonstrate that LightVLA outperforms different VLA models and existing token
pruning methods across diverse tasks on the LIBERO benchmark, achieving higher
success rates with substantially reduced computational overhead. Specifically,
LightVLA reduces FLOPs and latency by 59.1% and 38.2% respectively, with a 2.9%
improvement in task success rate. Meanwhile, we also investigate the learnable
query-based token pruning method LightVLA* with additional trainable
parameters, which also achieves satisfactory performance. Our work reveals that
as VLA pursues optimal performance, LightVLA spontaneously learns to prune
tokens from a performance-driven perspective. To the best of our knowledge,
LightVLA is the first work to apply adaptive visual token pruning to VLA tasks
with the collateral goals of efficiency and performance, marking a significant
step toward more efficient, powerful and practical real-time robotic systems.

</details>


### [210] [ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation](https://arxiv.org/abs/2509.12618)
*Zekai Zhang,Weiye Zhu,Hewei Pan,Xiangchen Wang,Rongtao Xu,Xing Sun,Feng Zheng*

Main category: cs.RO

TL;DR: 本文提出ActiveVLN框架，通过多轮强化学习实现主动探索，解决视觉与语言导航（VLN）任务中现有方法数据成本高昂和探索受限的问题。ActiveVLN结合少量专家轨迹的模仿学习和GRPO优化，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于MLLM的VLN方法主要依赖模仿学习（IL）和DAgger后训练，导致数据收集和训练成本高昂。而现有的VLN强化学习（RL）方法缺乏与环境的动态交互，并依赖专家轨迹进行奖励塑造，限制了代理发现多样且合理导航路径的能力。

Method: 本文提出了ActiveVLN框架，通过多轮强化学习实现主动探索。该方法分为两个阶段：第一阶段，利用少量专家轨迹进行模仿学习以引导代理；第二阶段，代理迭代预测并执行动作，自动收集多样轨迹，并通过GRPO目标优化多个rollout。为提高RL效率，还引入了动态早停策略来剪枝长尾或可能失败的轨迹，并进行了额外的工程优化。

Result: 实验结果表明，与基于DAgger和现有RL的后训练方法相比，ActiveVLN在模仿学习基线上取得了最大的性能提升。尽管使用了较小的模型，ActiveVLN仍能达到与最先进方法相媲美的性能。

Conclusion: ActiveVLN通过主动探索的多轮强化学习，有效解决了现有VLN方法在数据成本和探索多样性方面的局限性。该框架在性能上显著优于现有基线，并与最先进方法具有竞争力，同时提高了训练效率。

Abstract: The Vision-and-Language Navigation (VLN) task requires an agent to follow
natural language instructions and navigate through complex environments.
Existing MLLM-based VLN methods primarily rely on imitation learning (IL) and
often use DAgger for post-training to mitigate covariate shift. While
effective, these approaches incur substantial data collection and training
costs. Reinforcement learning (RL) offers a promising alternative. However,
prior VLN RL methods lack dynamic interaction with the environment and depend
on expert trajectories for reward shaping, rather than engaging in open-ended
active exploration. This restricts the agent's ability to discover diverse and
plausible navigation routes. To address these limitations, we propose
ActiveVLN, a VLN framework that explicitly enables active exploration through
multi-turn RL. In the first stage, a small fraction of expert trajectories is
used for IL to bootstrap the agent. In the second stage, the agent iteratively
predicts and executes actions, automatically collects diverse trajectories, and
optimizes multiple rollouts via the GRPO objective. To further improve RL
efficiency, we introduce a dynamic early-stopping strategy to prune long-tail
or likely failed trajectories, along with additional engineering optimizations.
Experiments show that ActiveVLN achieves the largest performance gains over IL
baselines compared to both DAgger-based and prior RL-based post-training
methods, while reaching competitive performance with state-of-the-art
approaches despite using a smaller model. Code and data will be released soon.

</details>


### [211] [PerchMobi^3: A Multi-Modal Robot with Power-Reuse Quad-Fan Mechanism for Air-Ground-Wall Locomotion](https://arxiv.org/abs/2509.12620)
*Yikai Chen,Zhi Zheng,Jin Wang,Bingye He,Xiangyu Xu,Jialu Zhang,Huan Yu,Guodong Lu*

Main category: cs.RO

TL;DR: PerchMobi^3 是一款四风扇、负压式陆空壁多模态机器人，通过将推进和吸附功能集成到同一风扇中实现功率复用，从而简化设计、提高效率，并实现了地面驱动、壁面攀爬和空中飞行的无缝切换。


<details>
  <summary>Details</summary>
Motivation: 现有陆空壁多模态机器人通常依赖额外的吸附执行器，这增加了系统的复杂性、降低了效率并损害了可靠性。本研究旨在解决这些局限性。

Method: 本文提出了PerchMobi^3机器人，它采用四涵道风扇，同时提供空中推力和负压吸附力，并与四个主动驱动轮集成。这种推进-吸附功率复用机制消除了对专用泵的需求，保持了轻量化和紧凑的设计。此外，还开发了建模和控制框架以实现陆地、壁面和空中域的协调操作及风扇辅助的模式转换。

Result: 通过一系列综合实验（包括地面驱动、载荷辅助壁面攀爬、空中飞行和跨模式转换），验证了该设计的可行性，展示了在不同运动场景下的强大适应性。这是首个展示多模态运动功能性功率复用的四风扇原型。

Conclusion: PerchMobi^3 凸显了作为多模态机器人移动性新设计范式的潜力，为未来自主和面向应用的部署铺平了道路。

Abstract: Achieving seamless integration of aerial flight, ground driving, and wall
climbing within a single robotic platform remains a major challenge, as
existing designs often rely on additional adhesion actuators that increase
complexity, reduce efficiency, and compromise reliability. To address these
limitations, we present PerchMobi^3, a quad-fan, negative-pressure,
air-ground-wall robot that implements a propulsion-adhesion power-reuse
mechanism. By repurposing four ducted fans to simultaneously provide aerial
thrust and negative-pressure adhesion, and integrating them with four actively
driven wheels, PerchMobi^3 eliminates dedicated pumps while maintaining a
lightweight and compact design. To the best of our knowledge, this is the first
quad-fan prototype to demonstrate functional power reuse for multi-modal
locomotion. A modeling and control framework enables coordinated operation
across ground, wall, and aerial domains with fan-assisted transitions. The
feasibility of the design is validated through a comprehensive set of
experiments covering ground driving, payload-assisted wall climbing, aerial
flight, and cross-mode transitions, demonstrating robust adaptability across
locomotion scenarios. These results highlight the potential of PerchMobi^3 as a
novel design paradigm for multi-modal robotic mobility, paving the way for
future extensions toward autonomous and application-oriented deployment.

</details>


### [212] [Safety filtering of robotic manipulation under environment uncertainty: a computational approach](https://arxiv.org/abs/2509.12674)
*Anna Johansson,Daniel Lindmark,Viktor Wiberg,Martin Servin*

Main category: cs.RO

TL;DR: 本文提出了一种基于物理的稀疏安全过滤方案，利用高保真模拟和不确定性参数评估控制策略，以实现机器人动态和非结构化环境下的安全操作。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在动态和非结构化环境中安全操作，但现有的安全过滤器通常假设完全可观测性，这限制了它们在实际任务中的适用性。

Method: 该方法结合了使用标称参数的密集展开（dense rollout）和在关键状态转换点进行可并行化的稀疏重新评估（sparse re-evaluation）。通过广义安全系数（generalized factors of safety）量化稳定抓取和执行器限制，并通过探测动作（probing actions）实现有针对性的不确定性减少。

Result: 在模拟的双臂操作任务中，面对不确定的物体质量和摩擦力，该方法能够高效地识别并过滤不安全的轨迹。

Conclusion: 研究结果表明，基于物理的稀疏安全评估是应对不确定性环境下机器人安全操作的一种可扩展策略。

Abstract: Robotic manipulation in dynamic and unstructured environments requires safety
mechanisms that exploit what is known and what is uncertain about the world.
Existing safety filters often assume full observability, limiting their
applicability in real-world tasks. We propose a physics-based safety filtering
scheme that leverages high-fidelity simulation to assess control policies under
uncertainty in world parameters. The method combines dense rollout with nominal
parameters and parallelizable sparse re-evaluation at critical
state-transitions, quantified through generalized factors of safety for stable
grasping and actuator limits, and targeted uncertainty reduction through
probing actions. We demonstrate the approach in a simulated bimanual
manipulation task with uncertain object mass and friction, showing that unsafe
trajectories can be identified and filtered efficiently. Our results highlight
physics-based sparse safety evaluation as a scalable strategy for safe robotic
manipulation under uncertainty.

</details>


### [213] [UDON: Uncertainty-weighted Distributed Optimization for Multi-Robot Neural Implicit Mapping under Extreme Communication Constraints](https://arxiv.org/abs/2509.12702)
*Hongrui Zhao,Xunlan Zhou,Boris Ivanovic,Negar Mehr*

Main category: cs.RO

TL;DR: UDON是一个实时多智能体神经隐式建图框架，通过新颖的不确定性加权分布式优化，在极低通信成功率下仍能实现高质量建图。


<details>
  <summary>Details</summary>
Motivation: 多机器人神经隐式建图能紧凑重建复杂环境，但面临通信挑战（如丢包、带宽限制），在极低通信成功率下性能会显著下降，现有方法无法有效解决。

Method: 本文提出了UDON框架，核心是其不确定性加权分布式优化方法。不确定性加权优先处理地图中更可靠的部分，而分布式优化则隔离并惩罚通信代理对之间在建图上的分歧。

Result: UDON在标准基准数据集和真实机器人硬件上进行了广泛实验，结果表明它显著优于现有基线，即使在极端通信退化（成功率低至1%）的情况下，也能保持高保真重建和一致的场景表示。

Conclusion: UDON能够有效解决多智能体神经隐式建图在严重通信受损下的性能问题，实现了鲁棒且高质量的建图。

Abstract: Multi-robot mapping with neural implicit representations enables the compact
reconstruction of complex environments. However, it demands robustness against
communication challenges like packet loss and limited bandwidth. While prior
works have introduced various mechanisms to mitigate communication disruptions,
performance degradation still occurs under extremely low communication success
rates. This paper presents UDON, a real-time multi-agent neural implicit
mapping framework that introduces a novel uncertainty-weighted distributed
optimization to achieve high-quality mapping under severe communication
deterioration. The uncertainty weighting prioritizes more reliable portions of
the map, while the distributed optimization isolates and penalizes mapping
disagreement between individual pairs of communicating agents. We conduct
extensive experiments on standard benchmark datasets and real-world robot
hardware. We demonstrate that UDON significantly outperforms existing
baselines, maintaining high-fidelity reconstructions and consistent scene
representations even under extreme communication degradation (as low as 1%
success rate).

</details>


### [214] [MoiréTac: A Dual-Mode Visuotactile Sensor for Multidimensional Perception Using Moiré Pattern Amplification](https://arxiv.org/abs/2509.12714)
*Kit-Wa Sou,Junhao Gong,Shoujie Li,Chuqiao Lyu,Ziwu Song,Shilong Mu,Wenbo Ding*

Main category: cs.RO

TL;DR: MoiréTac是一种双模视觉触觉传感器，利用重叠微光栅产生莫尔条纹，实现高分辨率触觉感知和视觉功能，能够同时进行六轴力/扭矩测量、接触定位和视觉感知，并已成功应用于机器人灵巧操作。


<details>
  <summary>Details</summary>
Motivation: 现有视觉触觉传感器通常使用稀疏标记阵列，导致空间分辨率有限，并且缺乏明确的力与图像之间的分析关系。

Method: 该传感器通过透明架构中重叠的微光栅生成密集的莫尔干涉图案，莫尔图案能放大微观变形。它结合了莫尔图案的物理特征（亮度、相位梯度、方向和周期）与深度空间特征，并通过端到端学习将其映射到六轴力/扭矩测量。设计同时保留了光学清晰度以进行视觉任务。

Result: 实验结果表明，该传感器在所有测试轴上实现了R^2 > 0.98的力/扭矩测量精度；可以通过几何参数调节灵敏度（三倍增益调整）；即使有莫尔条纹叠加，也能保持物体分类的视觉功能。此外，该传感器成功集成到机械臂中，实现了带协调力/扭矩控制的瓶盖移除。

Conclusion: MoiréTac传感器通过其同时进行六轴力/扭矩测量、接触定位和视觉感知的能力，验证了其在灵巧操作方面的巨大潜力。

Abstract: Visuotactile sensors typically employ sparse marker arrays that limit spatial
resolution and lack clear analytical force-to-image relationships. To solve
this problem, we present \textbf{Moir\'eTac}, a dual-mode sensor that generates
dense interference patterns via overlapping micro-gratings within a transparent
architecture. When two gratings overlap with misalignment, they create moir\'e
patterns that amplify microscopic deformations. The design preserves optical
clarity for vision tasks while producing continuous moir\'e fields for tactile
sensing, enabling simultaneous 6-axis force/torque measurement, contact
localization, and visual perception. We combine physics-based features
(brightness, phase gradient, orientation, and period) from moir\'e patterns
with deep spatial features. These are mapped to 6-axis force/torque
measurements, enabling interpretable regression through end-to-end learning.
Experimental results demonstrate three capabilities: force/torque measurement
with R^2 > 0.98 across tested axes; sensitivity tuning through geometric
parameters (threefold gain adjustment); and vision functionality for object
classification despite moir\'e overlay. Finally, we integrate the sensor into a
robotic arm for cap removal with coordinated force and torque control,
validating its potential for dexterous manipulation.

</details>


### [215] [NAMOUnc: Navigation Among Movable Obstacles with Decision Making on Uncertainty Interval](https://arxiv.org/abs/2509.12723)
*Kai Zhang,Eric Lucet,Julien Alexandre Dit Sandretto,Shoubin Chen,David Filait*

Main category: cs.RO

TL;DR: 本文提出NAMOUnc框架，通过整合并估计不确定性来解决可移动障碍物导航（NAMO）中的实际挑战，从而实现更安全、高效的导航。


<details>
  <summary>Details</summary>
Motivation: 现有的可移动障碍物导航（NAMO）解决方案常假设理想条件，导致在面对观察噪声、模型近似、动作失败和部分可观察性等现实世界不确定性时，决策次优或存在风险。

Method: 本文引入NAMOUnc框架，将不确定性整合到决策过程中。具体方法是首先估计这些不确定性，然后比较移除和绕过障碍物所需的时间成本区间，同时优化成功率和时间效率。

Result: 通过广泛的模拟和真实世界实验验证，NAMOUnc方法在性能上显著优于现有NAMO框架。

Conclusion: NAMOUnc框架通过有效处理不确定性，能够确保在可移动障碍物导航任务中实现更安全、更高效的导航。

Abstract: Navigation among movable obstacles (NAMO) is a critical task in robotics,
often challenged by real-world uncertainties such as observation noise, model
approximations, action failures, and partial observability. Existing solutions
frequently assume ideal conditions, leading to suboptimal or risky decisions.
This paper introduces NAMOUnc, a novel framework designed to address these
uncertainties by integrating them into the decision-making process. We first
estimate them and compare the corresponding time cost intervals for removing
and bypassing obstacles, optimizing both the success rate and time efficiency,
ensuring safer and more efficient navigation. We validate our method through
extensive simulations and real-world experiments, demonstrating significant
improvements over existing NAMO frameworks. More details can be found in our
website: https://kai-zhang-er.github.io/namo-uncertainty/

</details>


### [216] [Deep Learning for Model-Free Prediction of Thermal States of Robot Joint Motors](https://arxiv.org/abs/2509.12739)
*Trung Kien La,Eric Guiffo Kaigom*

Main category: cs.RO

TL;DR: 本文利用由LSTM和前馈层组成的深度神经网络，采用无模型方法，预测机器人机械臂关节电机的热行为，并取得了良好的预测结果。


<details>
  <summary>Details</summary>
Motivation: 传统近似模型在推导、识别和验证大量参数时面临复杂性和不确定性挑战，且模型本身难以获得。因此，需要一种无需复杂模型的方法来预测机器人关节电机的热行为。

Method: 采用无模型的深度神经网络方法，该网络由多个隐藏的长短期记忆（LSTM）层和前馈层组成。通过收集和处理感测到的关节扭矩数据来训练网络，以预测关节电机的热行为。

Result: 研究展示了基于机器学习的方法在捕获一个七关节冗余机器人关节电机温度动态方面的良好预测结果。

Conclusion: 深度神经网络能够有效地、无模型地预测机器人机械臂关节电机的热行为，为解决传统建模的复杂性提供了可行的方案。

Abstract: In this work, deep neural networks made up of multiple hidden Long Short-Term
Memory (LSTM) and Feedforward layers are trained to predict the thermal
behavior of the joint motors of robot manipulators. A model-free and scalable
approach is adopted. It accommodates complexity and uncertainty challenges
stemming from the derivation, identification, and validation of a large number
of parameters of an approximation model that is hardly available. To this end,
sensed joint torques are collected and processed to foresee the thermal
behavior of joint motors. Promising prediction results of the machine learning
based capture of the temperature dynamics of joint motors of a redundant robot
with seven joints are presented.

</details>


### [217] [Deep Generative and Discriminative Digital Twin endowed with Variational Autoencoder for Unsupervised Predictive Thermal Condition Monitoring of Physical Robots in Industry 6.0 and Society 6.0](https://arxiv.org/abs/2509.12740)
*Eric Guiffo Kaigom*

Main category: cs.RO

TL;DR: 本研究利用配备生成式AI（变分自编码器）的智能数字孪生来管理机器人热异常状态，并生成无危状态，通过重建误差推导热难度分数，使机器人能预测和分享运动配置的热可行性，以满足未来工业和社会需求。


<details>
  <summary>Details</summary>
Motivation: 机器人是工业4.0和5.0效率与协作的关键，但电机过热导致的热饱和和烧伤会威胁人类安全、降低机器人可用性并抑制生产力。传统的机器人关机策略会阻碍生产，而事后冷却策略难以实施。因此，需要一种自主的预测和适应热饱和的方法，以确保机器人性能、延长寿命并实现人机安全。

Method: 本研究利用配备生成式AI（即变分自编码器V AE）的智能数字孪生来管理热异常并生成无危的机器人状态。通过变分自编码器的重建误差推导出“热难度”的概念。机器人可以利用这个分数来预测、预期并分享所需运动配置的热可行性。

Result: 机器人能够利用派生出的“热难度”分数来预测、预期并分享所需运动配置的热可行性。这有助于满足工业6.0和社会6.0新兴应用的需求，确保全自动化、热可行的任务，并延长机器人寿命，无需人工干预。

Conclusion: 通过利用生成式AI驱动的数字孪生，机器人可以自主管理热饱和问题，预测热可行性，从而实现性能自维持、延长使用寿命、保障人类安全，并能提前与其他智能体沟通其能力，以支持未来工业和社会的完全自动化、热可行任务，克服了传统关机策略的局限性。

Abstract: Robots are unrelentingly used to achieve operational efficiency in Industry
4.0 along with symbiotic and sustainable assistance for the work-force in
Industry 5.0. As resilience, robustness, and well-being are required in
anti-fragile manufacturing and human-centric societal tasks, an autonomous
anticipation and adaption to thermal saturation and burns due to motors
overheating become instrumental for human safety and robot availability. Robots
are thereby expected to self-sustain their performance and deliver user
experience, in addition to communicating their capability to other agents in
advance to ensure fully automated thermally feasible tasks, and prolong their
lifetime without human intervention. However, the traditional robot shutdown,
when facing an imminent thermal saturation, inhibits productivity in factories
and comfort in the society, while cooling strategies are hard to implement
after the robot acquisition. In this work, smart digital twins endowed with
generative AI, i.e., variational autoencoders, are leveraged to manage
thermally anomalous and generate uncritical robot states. The notion of thermal
difficulty is derived from the reconstruction error of variational
autoencoders. A robot can use this score to predict, anticipate, and share the
thermal feasibility of desired motion profiles to meet requirements from
emerging applications in Industry 6.0 and Society 6.0.

</details>


### [218] [Bridging Perception and Planning: Towards End-to-End Planning for Signal Temporal Logic Tasks](https://arxiv.org/abs/2509.12813)
*Bowen Ye,Junyue Huang,Yang Liu,Xiaozhen Qiao,Xiang Yin*

Main category: cs.RO

TL;DR: 本文提出S-MSP，一个可微分框架，用于在非结构化环境中解决机器人信号时序逻辑（STL）任务与运动规划问题，通过多视图观测和STL规范直接生成可行轨迹，并结合专家混合模型和安全滤波器。


<details>
  <summary>Details</summary>
Motivation: 现有的STL方法依赖预定义地图或移动表示，在非结构化真实世界环境中效率低下。

Method: 提出S-MSP（Structured-MoE STL Planner），一个可微分框架，直接将同步多视图相机观测和STL规范映射到可行轨迹。它在一个统一的管道中集成STL约束，并使用结合轨迹重建和STL鲁棒性的复合损失进行训练。一个结构感知的专家混合（MoE）模型通过将子任务投射到时间锚定嵌入中实现面向时间范围的专业化。推理时还引入了一个基于规则的安全滤波器。

Result: S-MSP在具有时间约束任务的工厂物流场景高保真模拟中，在STL满足度和轨迹可行性方面优于单一专家基线。推理时的安全滤波器在不损害逻辑正确性的前提下提高了物理可执行性。

Conclusion: S-MSP为非结构化环境中的STL任务与运动规划提供了一个实用方法，在STL满足度、轨迹可行性和物理可执行性方面表现出色。

Abstract: We investigate the task and motion planning problem for Signal Temporal Logic
(STL) specifications in robotics. Existing STL methods rely on pre-defined maps
or mobility representations, which are ineffective in unstructured real-world
environments. We propose the \emph{Structured-MoE STL Planner}
(\textbf{S-MSP}), a differentiable framework that maps synchronized multi-view
camera observations and an STL specification directly to a feasible trajectory.
S-MSP integrates STL constraints within a unified pipeline, trained with a
composite loss that combines trajectory reconstruction and STL robustness. A
\emph{structure-aware} Mixture-of-Experts (MoE) model enables horizon-aware
specialization by projecting sub-tasks into temporally anchored embeddings. We
evaluate S-MSP using a high-fidelity simulation of factory-logistics scenarios
with temporally constrained tasks. Experiments show that S-MSP outperforms
single-expert baselines in STL satisfaction and trajectory feasibility. A
rule-based \emph{safety filter} at inference improves physical executability
without compromising logical correctness, showcasing the practicality of the
approach.

</details>


### [219] [Force-Modulated Visual Policy for Robot-Assisted Dressing with Arm Motions](https://arxiv.org/abs/2509.12741)
*Alexis Yihong Hao,Yufei Wang,Navin Sriram Ravie,Bharath Hegde,David Held,Zackory Erickson*

Main category: cs.RO

TL;DR: 该研究开发了一种机器人辅助穿衣系统，能够处理部分观测、视觉遮挡和手臂运动，并通过少量真实世界多模态数据对仿真训练的策略进行微调，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助穿衣能显著改善行动不便者的生活。然而，现有工作常做简化假设（如穿衣过程中人体肢体静止），限制了实际应用。机器人需要处理可变形衣物、施加适当力并适应肢体运动。

Method: 开发了一个机器人辅助穿衣系统，能处理部分观测和视觉遮挡，并鲁棒地适应手臂运动。首先在仿真环境中用部分观测训练策略，然后提出一种方法，利用少量真实世界数据和视觉、力传感等多模态反馈进行微调，以提高策略对手臂运动的适应性和安全性。该方法在仿真（简化关节人体网格）和真实世界人体研究（12名参与者，264次穿衣试验）中进行了评估。

Result: 该策略成功地为参与者穿戴了两种长袖日常服装，同时能适应各种手臂运动，在任务完成度和用户反馈方面大大优于现有基线。

Conclusion: 本研究开发了一个能够处理复杂现实世界条件（如部分观测和手臂运动）的机器人辅助穿衣系统，通过仿真到真实世界的微调方法，显著提高了穿衣任务的成功率和用户满意度，为行动不便者提供了更有效的解决方案。

Abstract: Robot-assisted dressing has the potential to significantly improve the lives
of individuals with mobility impairments. To ensure an effective and
comfortable dressing experience, the robot must be able to handle challenging
deformable garments, apply appropriate forces, and adapt to limb movements
throughout the dressing process. Prior work often makes simplifying assumptions
-- such as static human limbs during dressing -- which limits real-world
applicability. In this work, we develop a robot-assisted dressing system
capable of handling partial observations with visual occlusions, as well as
robustly adapting to arm motions during the dressing process. Given a policy
trained in simulation with partial observations, we propose a method to
fine-tune it in the real world using a small amount of data and multi-modal
feedback from vision and force sensing, to further improve the policy's
adaptability to arm motions and enhance safety. We evaluate our method in
simulation with simplified articulated human meshes and in a real world human
study with 12 participants across 264 dressing trials. Our policy successfully
dresses two long-sleeve everyday garments onto the participants while being
adaptive to various kinds of arm motions, and greatly outperforms prior
baselines in terms of task completion and user feedback. Video are available at
https://dressing-motion.github.io/.

</details>


### [220] [Model Predictive Control with Reference Learning for Soft Robotic Intracranial Pressure Waveform Modulation](https://arxiv.org/abs/2509.13109)
*Fabian Flürenbrock,Yanick Büchel,Johannes Köhler,Marianne Schmid Daners,Melanie N. Zeilinger*

Main category: cs.RO

TL;DR: 本文提出了一种基于学习的软体机器人控制框架，用于精确调节颅内压（ICP）波形，通过两层控制器实现对电机位置的无偏差跟踪和对ICP的在线学习调制。


<details>
  <summary>Details</summary>
Motivation: 研究脑脊液动力学和神经系统疾病的病理过程需要精确调节颅内压（ICP）波形，而现有方法可能无法满足高精度和在线学习的需求。

Method: 该研究提出一个两层控制框架：1. 使用带有扰动观测器的模型预测控制器（MPC）实现电机位置参考轨迹的无偏差跟踪，并满足安全约束。2. 采用贝叶斯优化（BO）算法在线学习电机位置参考轨迹，以应对ICP对电机位置的未知非线性依赖，从而实现所需的ICP波形调制。该框架通过一个模拟真实ICP动态的脑部模型测试台进行了实验验证。

Result: 与传统的PID控制器相比，MPC将平均和最大电机位置参考跟踪误差分别降低了83%和73%。贝叶斯优化算法在不到20次迭代中，学习到了能产生所需平均值和振幅的ICP波形的电机位置参考轨迹。

Conclusion: 所提出的学习型控制框架能够安全有效地调制颅内压波形，显著提高了电机位置跟踪精度，并通过在线学习实现了对复杂非线性系统ICP的精确控制，为神经系统疾病研究提供了有力的工具。

Abstract: This paper introduces a learning-based control framework for a soft robotic
actuator system designed to modulate intracranial pressure (ICP) waveforms,
which is essential for studying cerebrospinal fluid dynamics and pathological
processes underlying neurological disorders. A two-layer framework is proposed
to safely achieve a desired ICP waveform modulation. First, a model predictive
controller (MPC) with a disturbance observer is used for offset-free tracking
of the system's motor position reference trajectory under safety constraints.
Second, to address the unknown nonlinear dependence of ICP on the motor
position, we employ a Bayesian optimization (BO) algorithm used for online
learning of a motor position reference trajectory that yields the desired ICP
modulation. The framework is experimentally validated using a test bench with a
brain phantom that replicates realistic ICP dynamics in vitro. Compared to a
previously employed proportional-integral-derivative controller, the MPC
reduces mean and maximum motor position reference tracking errors by 83 % and
73 %, respectively. In less than 20 iterations, the BO algorithm learns a motor
position reference trajectory that yields an ICP waveform with the desired mean
and amplitude.

</details>


### [221] [NavMoE: Hybrid Model- and Learning-based Traversability Estimation for Local Navigation via Mixture of Experts](https://arxiv.org/abs/2509.12747)
*Botao He,Amir Hossein Shahidzadeh,Yu Chen,Jiayi Wu,Tianrui Guan,Guofei Chen,Howie Choset,Dinesh Manocha,Glen Chou,Cornelia Fermuller,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: 本文提出了一种名为NAVMOE的分层模块化专家混合（MoE）方法，用于机器人可穿越性估计和局部导航，通过动态加权特定地形专家模型，提高了效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 可穿越性估计面临的关键瓶颈在于，如何在有效编码几何和语义信息的同时，高效地实现可靠且鲁棒的预测，以适应各种不同的环境。

Method: NAVMOE是一种分层模块化方法，结合了多个针对特定地形的专家模型（可以是基于模型的或基于学习的方法）。它通过一个门控网络根据输入环境动态调整不同模型的贡献。该方法具有三个特点：1) 适应性利用专业方法处理不同地形；2) 引入免训练的惰性门控机制，最小化推理时激活的专家数量，显著提高效率；3) 采用两阶段训练策略，支持混合MoE方法中包含不可微分模块的门控网络训练。

Result: 实验表明，NAVMOE在不同领域提供了比任何单个专家或完整集成方法更好的效率和性能平衡，改善了跨领域泛化能力。通过惰性门控，平均计算成本降低了81.2%，而路径质量损失不到2%。

Conclusion: NAVMOE通过结合专业模型和创新的门控机制，成功解决了机器人可穿越性估计中的效率和泛化挑战，在保持高性能的同时显著降低了计算成本。

Abstract: This paper explores traversability estimation for robot navigation. A key
bottleneck in traversability estimation lies in efficiently achieving reliable
and robust predictions while accurately encoding both geometric and semantic
information across diverse environments. We introduce Navigation via Mixture of
Experts (NAVMOE), a hierarchical and modular approach for traversability
estimation and local navigation. NAVMOE combines multiple specialized models
for specific terrain types, each of which can be either a classical model-based
or a learning-based approach that predicts traversability for specific terrain
types. NAVMOE dynamically weights the contributions of different models based
on the input environment through a gating network. Overall, our approach offers
three advantages: First, NAVMOE enables traversability estimation to adaptively
leverage specialized approaches for different terrains, which enhances
generalization across diverse and unseen environments. Second, our approach
significantly improves efficiency with negligible cost of solution quality by
introducing a training-free lazy gating mechanism, which is designed to
minimize the number of activated experts during inference. Third, our approach
uses a two-stage training strategy that enables the training for the gating
networks within the hybrid MoE method that contains nondifferentiable modules.
Extensive experiments show that NAVMOE delivers a better efficiency and
performance balance than any individual expert or full ensemble across
different domains, improving cross- domain generalization and reducing average
computational cost by 81.2% via lazy gating, with less than a 2% loss in path
quality.

</details>


### [222] [TeraSim-World: Worldwide Safety-Critical Data Synthesis for End-to-End Autonomous Driving](https://arxiv.org/abs/2509.13164)
*Jiawei Wang,Haowei Sun,Xintao Yan,Shuo Feng,Jun Gao,Henry X. Liu*

Main category: cs.RO

TL;DR: TeraSim-World是一个自动化流程，用于为端到端自动驾驶合成逼真、地理多样化的安全关键数据，以解决现有数据源的局限性。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶需要大量多样化的安全关键数据，但现有数据（模拟器或路测）存在模拟到现实的差距，且成本高昂或不安全。

Method: TeraSim-World从任意位置获取地理空间数据（真实世界地图和交通需求），然后从自然驾驶数据集中模拟智能体行为并编排各种逆境以创建极端情况。它利用街景信息，通过前沿视频生成模型Cosmos-Drive实现逼真且地理上准确的传感器渲染，从而连接智能体和传感器模拟。

Result: 该方法提供了一个可扩展且关键的数据合成框架，能够生成逼真、地理多样化的安全关键数据，用于端到端自动驾驶系统的训练和评估。

Conclusion: TeraSim-World通过弥合智能体和传感器模拟之间的鸿沟，为端到端自动驾驶系统的训练和评估提供了一个可扩展且至关重要的数据合成框架。

Abstract: Safe and scalable deployment of end-to-end (E2E) autonomous driving requires
extensive and diverse data, particularly safety-critical events. Existing data
are mostly generated from simulators with a significant sim-to-real gap or
collected from on-road testing that is costly and unsafe. This paper presents
TeraSim-World, an automated pipeline that synthesizes realistic and
geographically diverse safety-critical data for E2E autonomous driving at
anywhere in the world. Starting from an arbitrary location, TeraSim-World
retrieves real-world maps and traffic demand from geospatial data sources.
Then, it simulates agent behaviors from naturalistic driving datasets, and
orchestrates diverse adversities to create corner cases. Informed by street
views of the same location, it achieves photorealistic, geographically grounded
sensor rendering via the frontier video generation model Cosmos-Drive. By
bridging agent and sensor simulations, TeraSim-World provides a scalable and
critical~data synthesis framework for training and evaluation of E2E autonomous
driving systems.

</details>


### [223] [Toward Ownership Understanding of Objects: Active Question Generation with Large Language Model and Probabilistic Generative Model](https://arxiv.org/abs/2509.12754)
*Saki Hashimoto,Shoichi Hasegawa,Tomochika Ishikawa,Akira Taniguchi,Yoshinobu Hagiwara,Lotfi El Hafi,Tadahiro Taniguchi*

Main category: cs.RO

TL;DR: 该论文提出了ActOwL框架，使机器人能够主动向用户提问以学习物品所有权，并通过结合LLM常识推理和主动提问来高效获取知识。


<details>
  <summary>Details</summary>
Motivation: 在家庭和办公环境中操作的机器人需要理解物品所有权，以正确执行“把我的杯子拿给我”等指令。然而，仅凭视觉特征无法可靠地推断所有权。

Method: 本文提出了主动所有权学习（ActOwL）框架，该框架使机器人能够主动生成并向用户提出与所有权相关的问题。ActOwL采用概率生成模型来选择能够最大化信息增益的问题，从而高效获取所有权知识。此外，通过利用大型语言模型（LLM）的常识知识，物品被预先分类为共享或私有，仅对私有物品进行提问。

Result: 在模拟家庭环境和真实实验室环境中的实验表明，ActOwL以比基线方法更少的问题实现了显著更高的所有权聚类准确性。

Conclusion: 这些发现证明了将主动推理与LLM引导的常识推理相结合的有效性，提升了机器人获取所有权知识的能力，以实现实用且符合社交规范的任务执行。

Abstract: Robots operating in domestic and office environments must understand object
ownership to correctly execute instructions such as ``Bring me my cup.''
However, ownership cannot be reliably inferred from visual features alone. To
address this gap, we propose Active Ownership Learning (ActOwL), a framework
that enables robots to actively generate and ask ownership-related questions to
users. ActOwL employs a probabilistic generative model to select questions that
maximize information gain, thereby acquiring ownership knowledge efficiently to
improve learning efficiency. Additionally, by leveraging commonsense knowledge
from Large Language Models (LLM), objects are pre-classified as either shared
or owned, and only owned objects are targeted for questioning. Through
experiments in a simulated home environment and a real-world laboratory
setting, ActOwL achieved significantly higher ownership clustering accuracy
with fewer questions than baseline methods. These findings demonstrate the
effectiveness of combining active inference with LLM-guided commonsense
reasoning, advancing the capability of robots to acquire ownership knowledge
for practical and socially appropriate task execution.

</details>


### [224] [Integrating Trajectory Optimization and Reinforcement Learning for Quadrupedal Jumping with Terrain-Adaptive Landing](https://arxiv.org/abs/2509.12776)
*Renjie Wang,Shangke Lyu,Xin Lang,Wei Xiao,Donglin Wang*

Main category: cs.RO

TL;DR: 本文提出了一种结合轨迹优化（TO）和强化学习（RL）的框架，使四足机器人能够在崎岖地形上安全自适应着陆，并引入奖励松弛策略以促进探索和柔顺着陆。


<details>
  <summary>Details</summary>
Motivation: 现有的四足机器人跳跃研究主要假设平坦着陆地面，这在许多实际场景中不切实际，无法应对崎岖地形的挑战。

Method: 该研究结合了轨迹优化（TO）和强化学习（RL）。RL智能体学习跟踪TO生成的参考运动，并在崎岖地形环境中进行训练。为实现在挑战性地形上的柔顺着陆技能学习，引入了奖励松弛策略以鼓励着陆恢复期间的探索。

Result: 广泛的实验验证了所提出的方法在各种场景下实现了精确的轨迹跟踪和安全的着陆技能。

Conclusion: 该框架通过结合TO和RL，并辅以奖励松弛策略，成功解决了四足机器人在崎岖地形上自适应着陆的难题，显著提升了机器人的运动能力。

Abstract: Jumping constitutes an essential component of quadruped robots' locomotion
capabilities, which includes dynamic take-off and adaptive landing. Existing
quadrupedal jumping studies mainly focused on the stance and flight phase by
assuming a flat landing ground, which is impractical in many real world cases.
This work proposes a safe landing framework that achieves adaptive landing on
rough terrains by combining Trajectory Optimization (TO) and Reinforcement
Learning (RL) together. The RL agent learns to track the reference motion
generated by TO in the environments with rough terrains. To enable the learning
of compliant landing skills on challenging terrains, a reward relaxation
strategy is synthesized to encourage exploration during landing recovery
period. Extensive experiments validate the accurate tracking and safe landing
skills benefiting from our proposed method in various scenarios.

</details>


### [225] [Multi-Robot Task Planning for Multi-Object Retrieval Tasks with Distributed On-Site Knowledge via Large Language Models](https://arxiv.org/abs/2509.12838)
*Kento Murata,Shoichi Hasegawa,Tomochika Ishikawa,Yoshinobu Hagiwara,Akira Taniguchi,Lotfi El Hafi,Tadahiro Taniguchi*

Main category: cs.RO

TL;DR: 该研究提出一个基于大型语言模型（LLM）和空间概念的任务规划框架，用于将复杂的自然语言指令分解为子任务，并分配给具有不同现场知识的多个机器人。


<details>
  <summary>Details</summary>
Motivation: 现有系统难以高效执行涉及多对象搜索或上下文相关命令的复杂指令，并且在机器人拥有不同现场空间知识时，如何有效分配任务是一个挑战。

Method: 研究提出一个任务规划框架，利用LLM和空间概念将自然语言指令分解为子任务，并分配给多个机器人。设计了一种新颖的少样本提示策略，使LLM能够从模糊命令中推断所需对象并分解为合适的子任务。

Result: 该方法在任务分配中实现了47/50的成功率，优于随机分配（28/50）和基于常识的分配（26/50）。通过两台实际移动机械臂的定性评估表明，该框架能成功处理包括“准备野外考察”等临时类别指令的任务分解、分配、顺序规划和执行。

Conclusion: 该框架通过结合LLM和空间概念，能够有效处理复杂的自然语言指令，实现任务分解和机器人分配，并在实验中展现出卓越的性能和实际应用潜力。

Abstract: It is crucial to efficiently execute instructions such as "Find an apple and
a banana" or "Get ready for a field trip," which require searching for multiple
objects or understanding context-dependent commands. This study addresses the
challenging problem of determining which robot should be assigned to which part
of a task when each robot possesses different situational on-site
knowledge-specifically, spatial concepts learned from the area designated to it
by the user. We propose a task planning framework that leverages large language
models (LLMs) and spatial concepts to decompose natural language instructions
into subtasks and allocate them to multiple robots. We designed a novel
few-shot prompting strategy that enables LLMs to infer required objects from
ambiguous commands and decompose them into appropriate subtasks. In our
experiments, the proposed method achieved 47/50 successful assignments,
outperforming random (28/50) and commonsense-based assignment (26/50).
Furthermore, we conducted qualitative evaluations using two actual mobile
manipulators. The results demonstrated that our framework could handle
instructions, including those involving ad hoc categories such as "Get ready
for a field trip," by successfully performing task decomposition, assignment,
sequential planning, and execution.

</details>


### [226] [Unleashing the Power of Discrete-Time State Representation: Ultrafast Target-based IMU-Camera Spatial-Temporal Calibration](https://arxiv.org/abs/2509.12846)
*Junlin Song,Antoine Richard,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: 本文提出了一种新颖且高效的离散时间状态表示视觉惯性标定方法，旨在解决现有连续时间方法计算成本高的问题，同时克服离散时间在时间标定上的弱点。


<details>
  <summary>Details</summary>
Motivation: 视觉惯性融合对于机器人导航和增强现实等智能自主应用至关重要。为实现最佳状态估计，IMU和相机之间的时空位移需要提前标定。现有方法多采用连续时间（B样条）表示，虽精确但计算成本高昂。随着视觉惯性平台设备数量的激增，亟需一种更高效的标定方法。

Method: 提出了一种利用离散时间状态表示的标定方法，以降低计算成本。同时，该方法解决了离散时间状态表示在时间标定方面的固有弱点。

Result: 该方法实现了“极其高效”的标定，能显著节省计算时间。例如，为一百万台设备标定每台节省一分钟，总共可节省2083个工作日。

Conclusion: 本文开发了一种高效的离散时间视觉惯性标定方法，显著降低了计算成本，对学术界和工业界均有益，并将开源代码。

Abstract: Visual-inertial fusion is crucial for a large amount of intelligent and
autonomous applications, such as robot navigation and augmented reality. To
bootstrap and achieve optimal state estimation, the spatial-temporal
displacements between IMU and cameras must be calibrated in advance. Most
existing calibration methods adopt continuous-time state representation, more
specifically the B-spline. Despite these methods achieve precise
spatial-temporal calibration, they suffer from high computational cost caused
by continuous-time state representation. To this end, we propose a novel and
extremely efficient calibration method that unleashes the power of
discrete-time state representation. Moreover, the weakness of discrete-time
state representation in temporal calibration is tackled in this paper. With the
increasing production of drones, cellphones and other visual-inertial
platforms, if one million devices need calibration around the world, saving one
minute for the calibration of each device means saving 2083 work days in total.
To benefit both the research and industry communities, our code will be
open-source.

</details>


### [227] [A Novel Skill Modeling Approach: Integrating Vergnaud's Scheme with Cognitive Architectures](https://arxiv.org/abs/2509.12851)
*Antoine Lénat,Olivier Cheminat,Damien Chablat,Camilo Charron*

Main category: cs.RO

TL;DR: 随着工业5.0的兴起，人机交互中的人类技能适应性变得至关重要。本文提出将谓词逻辑与认知架构相结合，以更全面地建模操作员技能，并考虑认知约束，尤其是在焊接等复杂任务中，以实现更好的技能理解和转移。


<details>
  <summary>Details</summary>
Motivation: 工业5.0背景下人机交互日益重要，需要理解和适应人类操作员技能以优化结果。现有理论（如谓词逻辑）未能充分考虑认知系统约束（如行动时序、认知资源限制）。焊接等复杂任务中，操作员需持续适应变量，且行动后果延迟评估，凸显了精确建模操作员技能的迫切性。

Method: 提议结合谓词逻辑（基于皮亚杰的图式概念）与认知架构模型。谓词逻辑用于描述技能，而认知架构则用于整合认知约束，如行动时序、认知资源限制、任务并行化和自动手势激活。以焊接作为相关案例研究，来验证和应用这种集成方法。

Result: 通过整合谓词逻辑和认知架构，可以更全面、更严谨地描述和理解操作员技能，包括其适应性及认知约束。这将有助于比较有无机器人辅助时的性能，并促进生物结构与机械结构之间的技能转移理解，从而提升人机协作效率和任务质量。

Conclusion: 深入理解和建模操作员技能，特别是整合认知约束的技能模型，对于优化人机交互和技能转移至关重要。将谓词逻辑与认知架构相结合，为解决这一挑战提供了一个有前景的方法，尤其适用于焊接等需要高度技能适应性的复杂工业场景。

Abstract: Human-machine interaction is increasingly important in industry, and this
trend will only intensify with the rise of Industry 5.0. Human operators have
skills that need to be adapted when using machines to achieve the best results.
It is crucial to highlight the operator's skills and understand how they use
and adapt them [18]. A rigorous description of these skills is necessary to
compare performance with and without robot assistance. Predicate logic, used by
Vergnaud within Piaget's scheme concept, offers a promising approach. However,
this theory doesn't account for cognitive system constraints, such as the
timing of actions, the limitation of cognitive resources, the parallelization
of tasks, or the activation of automatic gestures contrary to optimal
knowledge. Integrating these constraints is essential for representing agent
skills understanding skill transfer between biological and mechanical
structures. Cognitive architectures models [2] address these needs by
describing cognitive structure and can be combined with the scheme for mutual
benefit. Welding provides a relevant case study, as it highlights the
challenges faced by operators, even highly skilled ones. Welding's complexity
stems from the need for constant skill adaptation to variable parameters like
part position and process. This adaptation is crucial, as weld quality, a key
factor, is only assessed afterward via destructive testing. Thus, the welder is
confronted with a complex perception-decision-action cycle, where the
evaluation of the impact of his actions is delayed and where errors are
definitive. This dynamic underscores the importance of understanding and
modeling the skills of operators.

</details>


### [228] [Contrastive Representation Learning for Robust Sim-to-Real Transfer of Adaptive Humanoid Locomotion](https://arxiv.org/abs/2509.12858)
*Yidan Lu,Rurui Yang,Qiran Kou,Mengting Chen,Tao Fan,Peter Cui,Yinzhao Dong,Peng Lu*

Main category: cs.RO

TL;DR: 本文提出一种新范式，通过对比学习让纯本体感知策略获得前瞻性感知能力，实现自适应步态，从而在无需额外感知部署成本的情况下，使人形机器人能在复杂地形上实现高度鲁棒的运动。


<details>
  <summary>Details</summary>
Motivation: 在人形机器人运动控制中，存在一个核心困境：是选择鲁棒但反应式的本体感知控制，还是选择前瞻性但脆弱的感知驱动系统。这限制了强化学习在真实世界中的部署。

Method: 核心贡献是引入一个对比学习框架，强制执行器（actor）的潜在状态编码来自模拟的特权环境信息。这种“蒸馏意识”赋能了自适应步态时钟，使策略能够根据对地形的推断理解主动调整其节奏，解决了刚性固定步态与不稳定无时钟策略之间的权衡问题。

Result: 该方法通过零样本（zero-shot）从模拟到真实世界的迁移，在一个全尺寸人形机器人上得到验证，在具有挑战性的地形（包括30厘米高的台阶和26.5度斜坡）上展示了高度鲁棒的运动能力。

Conclusion: 该研究通过为纯本体感知策略赋予前瞻性能力，有效解决了鲁棒性与前瞻性之间的困境，在不增加部署感知成本的情况下，实现了人形机器人在复杂地形上的高度鲁棒运动。

Abstract: Reinforcement learning has produced remarkable advances in humanoid
locomotion, yet a fundamental dilemma persists for real-world deployment:
policies must choose between the robustness of reactive proprioceptive control
or the proactivity of complex, fragile perception-driven systems. This paper
resolves this dilemma by introducing a paradigm that imbues a purely
proprioceptive policy with proactive capabilities, achieving the foresight of
perception without its deployment-time costs. Our core contribution is a
contrastive learning framework that compels the actor's latent state to encode
privileged environmental information from simulation. Crucially, this
``distilled awareness" empowers an adaptive gait clock, allowing the policy to
proactively adjust its rhythm based on an inferred understanding of the
terrain. This synergy resolves the classic trade-off between rigid, clocked
gaits and unstable clock-free policies. We validate our approach with zero-shot
sim-to-real transfer to a full-sized humanoid, demonstrating highly robust
locomotion over challenging terrains, including 30 cm high steps and 26.5{\deg}
slopes, proving the effectiveness of our method. Website:
https://lu-yidan.github.io/cra-loco.

</details>


### [229] [GRATE: a Graph transformer-based deep Reinforcement learning Approach for Time-efficient autonomous robot Exploration](https://arxiv.org/abs/2509.12863)
*Haozhan Ni,Jingsong Liang,Chenyu He,Yuhong Cao,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 本文提出了一种名为GRATE的深度强化学习方法，通过结合图Transformer和卡尔曼滤波器，解决了现有自主机器人探索（ARE）方法在图数据推理能力和运动效率方面的不足，显著提高了探索效率和路径可行性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的自主机器人探索（ARE）方法在处理图结构数据时推理能力有限，并且由于对机器人运动考虑不足，导致优化策略往往只关注最短距离而忽略了时间效率。

Method: 本文提出了GRATE，一种基于深度强化学习（DRL）的方法。它利用图Transformer有效捕捉信息图的局部结构模式和全局上下文依赖性，从而增强模型在整个环境中的推理能力。此外，部署了卡尔曼滤波器来平滑路径点输出，确保生成的路径在运动学上对机器人是可行的。

Result: 实验结果表明，与现有最先进的传统和基于学习的基线相比，GRATE在各种模拟基准测试中展现出更高的探索效率（完成探索的距离减少高达21.5%，时间减少高达21.3%）。该规划器也在真实世界场景中得到了验证。

Conclusion: GRATE通过结合图Transformer和卡尔曼滤波器，有效克服了现有ARE方法在图数据推理和运动效率方面的局限性，实现了更高效且运动学可行的自主机器人探索。

Abstract: Autonomous robot exploration (ARE) is the process of a robot autonomously
navigating and mapping an unknown environment. Recent Reinforcement Learning
(RL)-based approaches typically formulate ARE as a sequential decision-making
problem defined on a collision-free informative graph. However, these methods
often demonstrate limited reasoning ability over graph-structured data.
Moreover, due to the insufficient consideration of robot motion, the resulting
RL policies are generally optimized to minimize travel distance, while
neglecting time efficiency. To overcome these limitations, we propose GRATE, a
Deep Reinforcement Learning (DRL)-based approach that leverages a Graph
Transformer to effectively capture both local structure patterns and global
contextual dependencies of the informative graph, thereby enhancing the model's
reasoning capability across the entire environment. In addition, we deploy a
Kalman filter to smooth the waypoint outputs, ensuring that the resulting path
is kinodynamically feasible for the robot to follow. Experimental results
demonstrate that our method exhibits better exploration efficiency (up to 21.5%
in distance and 21.3% in time to complete exploration) than state-of-the-art
conventional and learning-based baselines in various simulation benchmarks. We
also validate our planner in real-world scenarios.

</details>


### [230] [Towards Context-Aware Human-like Pointing Gestures with RL Motion Imitation](https://arxiv.org/abs/2509.12880)
*Anna Deichler,Siyang Wang,Simon Alexanderson,Jonas Beskow*

Main category: cs.RO

TL;DR: 该研究通过构建人类指向手势数据集，并结合强化学习和运动模仿，训练机器人生成类人且精确的指向行为。


<details>
  <summary>Details</summary>
Motivation: 以往研究多集中于机器人对指向手势的识别，而非生成。本研究旨在填补这一空白，使机器人能主动生成自然且有效的指向手势。

Method: 研究首先创建了一个包含多种风格、惯用手和空间目标的人类指向手势动作捕捉数据集。然后，利用强化学习和运动模仿技术，训练策略以复现类人指向动作，并最大化指向精度。

Result: 结果表明，该方法使机器人在模拟环境中能够生成情境感知（context-aware）的指向行为，成功平衡了任务性能与自然动态。

Conclusion: 该研究成功地开发了一种使机器人生成类人、精确且情境感知的指向手势的方法，为机器人与人类的自然交互提供了新的途径。

Abstract: Pointing is a key mode of interaction with robots, yet most prior work has
focused on recognition rather than generation. We present a motion capture
dataset of human pointing gestures covering diverse styles, handedness, and
spatial targets. Using reinforcement learning with motion imitation, we train
policies that reproduce human-like pointing while maximizing precision. Results
show our approach enables context-aware pointing behaviors in simulation,
balancing task performance with natural dynamics.

</details>


### [231] [Responsibility and Engagement -- Evaluating Interactions in Social Robot Navigation](https://arxiv.org/abs/2509.12890)
*Malte Probst,Raphael Wenzel,Monica Dasi*

Main category: cs.RO

TL;DR: 本文扩展了现有的责任度量框架，引入了时间归一化以模拟冲突累积阶段，并提出了一个新的参与度量，用于评估社会机器人导航（SRN）中代理之间冲突解决的质量和前瞻性。


<details>
  <summary>Details</summary>
Motivation: 在社会机器人导航（SRN）中，评估人机交互轨迹（尤其是在解决代理间冲突时）需要有意义的度量标准。了解代理在解决冲突中的贡献份额至关重要。

Method: 本文在现有责任度量（捕获代理贡献份额）的基础上进行了两方面扩展：1. 引入时间归一化来建模冲突累积阶段。2. 提出了相关的参与度量，以捕获代理行为如何加剧冲突。通过一系列双人、群体和人群交互的模拟场景对这些度量进行了测试。

Result: 研究表明，所提出的责任度和参与度量能够提供关于交互中合作解决冲突的有意义信息。它们可以用于评估行为质量和前瞻性。

Conclusion: 所提出的时间归一化责任度量和新的参与度量是评估社会机器人导航中冲突解决质量的有效工具，并可用于评估行为质量和前瞻性，对未来的机器人行为设计具有指导意义。

Abstract: In Social Robot Navigation (SRN), the availability of meaningful metrics is
crucial for evaluating trajectories from human-robot interactions. In the SRN
context, such interactions often relate to resolving conflicts between two or
more agents. Correspondingly, the shares to which agents contribute to the
resolution of such conflicts are important. This paper builds on recent work,
which proposed a Responsibility metric capturing such shares. We extend this
framework in two directions: First, we model the conflict buildup phase by
introducing a time normalization. Second, we propose the related Engagement
metric, which captures how the agents' actions intensify a conflict. In a
comprehensive series of simulated scenarios with dyadic, group and crowd
interactions, we show that the metrics carry meaningful information about the
cooperative resolution of conflicts in interactions. They can be used to assess
behavior quality and foresightedness. We extensively discuss applicability,
design choices and limitations of the proposed metrics.

</details>


### [232] [Spotting the Unfriendly Robot -- Towards better Metrics for Interactions](https://arxiv.org/abs/2509.12912)
*Raphael Wenzel,Malte Probst*

Main category: cs.RO

TL;DR: 为社交机器人导航(SRN)算法评估提出新的标准化指标，以量化人类-机器人互动中的合作程度和冲突解决责任，弥补现有指标的不足。


<details>
  <summary>Details</summary>
Motivation: 目前常用的SRN评估指标无法量化智能体在与人类互动中的合作行为，特别是在冲突场景中，无法区分是合作解决还是被迫规避，也无法明确哪个智能体承担了解决冲突的责任。

Method: 提出了两个新的指标：冲突强度指标（conflict intensity metric）和责任指标（responsibility metric）。

Result: 这些指标能够评估人机交互的质量，通过展示给定算法在减少冲突中的贡献以及哪个智能体实际承担了解决冲突的责任。

Conclusion: 本研究旨在为SRN开发一套全面且标准化的评估方法，最终提升机器人在以人为中心环境中的安全性、效率和社会接受度。

Abstract: Establishing standardized metrics for Social Robot Navigation (SRN)
algorithms for assessing the quality and social compliance of robot behavior
around humans is essential for SRN research. Currently, commonly used
evaluation metrics lack the ability to quantify how cooperative an agent
behaves in interaction with humans. Concretely, in a simple frontal approach
scenario, no metric specifically captures if both agents cooperate or if one
agent stays on collision course and the other agent is forced to evade. To
address this limitation, we propose two new metrics, a conflict intensity
metric and the responsibility metric. Together, these metrics are capable of
evaluating the quality of human-robot interactions by showing how much a given
algorithm has contributed to reducing a conflict and which agent actually took
responsibility of the resolution. This work aims to contribute to the
development of a comprehensive and standardized evaluation methodology for SRN,
ultimately enhancing the safety, efficiency, and social acceptance of robots in
human-centric environments.

</details>


### [233] [Spatiotemporal Calibration for Laser Vision Sensor in Hand-eye System Based on Straight-line Constraint](https://arxiv.org/abs/2509.12928)
*Peiwen Yang,Mingquan Jiang,Xinyue Shen,Heping Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种免示教的时空标定方法，用于解决工业机器人激光视觉传感器（LVS）中存在的相机时间偏移和手眼外参变化问题，通过直线约束和非线性优化实现。


<details>
  <summary>Details</summary>
Motivation: 工业机器人激光视觉传感器在焊接应用中，相机通信延迟导致图像与机器人运动不同步，且长时间测量可能导致手眼外参变化，影响数据采集精度。

Method: 引入考虑相机时间偏移的LVS测量模型；提出基于直线约束的免示教时空标定方法；机器人携带LVS以S形轨迹重复扫描直线角焊缝，将所有测量点约束为直线（用Plucker坐标表示）；建立基于直线约束的非线性优化模型；使用Levenberg-Marquardt算法优化时间偏移、手眼外参和直线参数。

Result: 通过对曲线焊缝扫描的实验，定量验证了所提方法的 E 可行性和准确性。

Conclusion: 该方法成功解决了工业机器人LVS的时空同步和手眼参数漂移问题，提供了一种准确且无需示教的标定方案，提升了LVS在工业应用中的精度和鲁棒性。

Abstract: Laser vision sensors (LVS) are critical perception modules for industrial
robots, facilitating real-time acquisition of workpiece geometric data in
welding applications. However, the camera communication delay will lead to a
temporal desynchronization between captured images and the robot motions.
Additionally, hand-eye extrinsic parameters may vary during prolonged
measurement. To address these issues, we introduce a measurement model of LVS
considering the effect of the camera's time-offset and propose a teaching-free
spatiotemporal calibration method utilizing line constraints. This method
involves a robot equipped with an LVS repeatedly scanning straight-line fillet
welds using S-shaped trajectories. Regardless of the robot's orientation
changes, all measured welding positions are constrained to a straight-line,
represented by Plucker coordinates. Moreover, a nonlinear optimization model
based on straight-line constraints is established. Subsequently, the
Levenberg-Marquardt algorithm (LMA) is employed to optimize parameters,
including time-offset, hand-eye extrinsic parameters, and straight-line
parameters. The feasibility and accuracy of the proposed approach are
quantitatively validated through experiments on curved weld scanning. We
open-sourced the code, dataset, and simulation report at
https://anonymous.4open.science/r/LVS_ST_CALIB-015F/README.md.

</details>


### [234] [Tendon-Based Proprioception in an Anthropomorphic Underactuated Robotic Hand with Series Elastic Actuators](https://arxiv.org/abs/2509.12969)
*Jae-Hyun Lee,Jonghoo Park,Kyu-Jin Cho*

Main category: cs.RO

TL;DR: 本研究提出了一种仿人欠驱动手，利用串联弹性驱动器（SEA）提供的肌腱本体感受，实现对人手-物体交互的全面态势感知，无需视觉或触觉反馈。


<details>
  <summary>Details</summary>
Motivation: 仿人欠驱动手因其多功能性和结构简单性而被广泛采用，但在实际抓取功能中，紧凑的传感集成和与欠驱动系统相符的正确解释至关重要。

Method: 该研究开发了一种紧凑、高精度、高可靠性的SEA，可无缝集成到无传感器的手指中。通过将本体感受传感与基于势能的建模相结合，系统能够估计关键的抓取相关变量，包括接触时间、关节角度、相对物体刚度以及指示外部干扰的手指配置变化。

Result: 估计的变量能够实现抓取姿态重建、安全处理可变形物体，以及仅依靠本体感受识别不同几何形状和刚度物体的盲抓取。手指级实验和手部级演示证实了该方法的有效性。

Conclusion: 研究结果表明，基于肌腱的本体感受是一种紧凑而强大的传感模式，可用于实际操作，而无需依赖视觉或触觉反馈。

Abstract: Anthropomorphic underactuated hands are widely employed for their versatility
and structural simplicity. In such systems, compact sensing integration and
proper interpretation aligned with underactuation are crucial for realizing
practical grasp functionalities. This study proposes an anthropomorphic
underactuated hand that achieves comprehensive situational awareness of
hand-object interaction, utilizing tendon-based proprioception provided by
series elastic actuators (SEAs). We developed a compact SEA with high accuracy
and reliability that can be seamlessly integrated into sensorless fingers. By
coupling proprioceptive sensing with potential energy-based modeling, the
system estimates key grasp-related variables, including contact timing, joint
angles, relative object stiffness, and finger configuration changes indicating
external disturbances. These estimated variables enable grasp posture
reconstruction, safe handling of deformable objects, and blind grasping with
proprioceptive-only recognition of objects with varying geometry and stiffness.
Finger-level experiments and hand-level demonstrations confirmed the
effectiveness of the proposed approach. The results demonstrate that
tendon-based proprioception serves as a compact and robust sensing modality for
practical manipulation without reliance on vision or tactile feedback.

</details>


### [235] [Out of Distribution Detection in Self-adaptive Robots with AI-powered Digital Twins](https://arxiv.org/abs/2509.12982)
*Erblin Isaku,Hassan Sartaj,Shaukat Ali,Beatriz Sanguino,Tongtong Wang,Guoyuan Li,Houxiang Zhang,Thomas Peyrucain*

Main category: cs.RO

TL;DR: 本文提出了一种基于数字孪生的自适应机器人（SARs）异常行为（OOD）检测方法ODiSAR。该方法利用基于Transformer的数字孪生预测机器人状态，并通过重建误差和蒙特卡洛dropout量化不确定性，实现了对OOD行为的高效检测和可解释性，以支持机器人的自我适应。


<details>
  <summary>Details</summary>
Motivation: 在复杂不确定的环境中，自适应机器人（SARs）需要主动检测并处理异常行为，包括分布外（OOD）情况。数字孪生为OOD检测提供了一种有价值的解决方案。

Method: ODiSAR是一种基于数字孪生的SARs OOD检测方法。它使用基于Transformer的数字孪生来预测SARs状态，并结合重建误差和蒙特卡洛dropout进行不确定性量化。通过将重建误差与预测方差结合，该数字孪生能够有效检测OOD行为。此外，数字孪生还包含一个可解释性层，将潜在的OOD事件与特定的SARs状态关联起来，为自我适应提供洞察。

Result: ODiSAR在两个工业机器人（一个办公室导航机器人，一个海上船舶导航机器人）的数字孪生评估中表现出色。它成功预测了SARs行为（机器人轨迹和船舶运动）并主动检测了OOD事件。结果显示，ODiSAR实现了高达98%的AUROC、96%的TNR@TPR95和95%的F1-score的高检测性能，同时提供了可解释的洞察力以支持自我适应。

Conclusion: ODiSAR提供了一种有效且可解释的基于数字孪生的方法，用于自适应机器人（SARs）的OOD检测，即使在以前未见过的条件下也能实现高精度检测，并为机器人的自我适应提供了宝贵的见解。

Abstract: Self-adaptive robots (SARs) in complex, uncertain environments must
proactively detect and address abnormal behaviors, including
out-of-distribution (OOD) cases. To this end, digital twins offer a valuable
solution for OOD detection. Thus, we present a digital twin-based approach for
OOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to
forecast SAR states and employs reconstruction error and Monte Carlo dropout
for uncertainty quantification. By combining reconstruction error with
predictive variance, the digital twin effectively detects OOD behaviors, even
in previously unseen conditions. The digital twin also includes an
explainability layer that links potential OOD to specific SAR states, offering
insights for self-adaptation. We evaluated ODiSAR by creating digital twins of
two industrial robots: one navigating an office environment, and another
performing maritime ship navigation. In both cases, ODiSAR forecasts SAR
behaviors (i.e., robot trajectories and vessel motion) and proactively detects
OOD events. Our results showed that ODiSAR achieved high detection performance
-- up to 98\% AUROC, 96\% TNR@TPR95, and 95\% F1-score -- while providing
interpretable insights to support self-adaptation.

</details>


### [236] [DVDP: An End-to-End Policy for Mobile Robot Visual Docking with RGB-D Perception](https://arxiv.org/abs/2509.13024)
*Haohan Min,Zhoujian Li,Yu Yang,Jinyu Chen,Shenghai Yuan*

Main category: cs.RO

TL;DR: 本文提出了一种名为DVDP的端到端视觉对接方法，仅需RGB-D相机即可直接输出机器人对接路径。通过混合数据集训练并在真实机器人上验证，该方法展现出卓越性能，解决了传统视觉对接对初始位置要求严格的问题。


<details>
  <summary>Details</summary>
Motivation: 移动机器人自动对接是一个重大挑战。视觉对接方法因其高精度和低部署成本而具有前景，但对机器人的初始位置有严格要求。现有视觉方法存在局限性，促使研究者寻求更高效的解决方案。

Method: 本文提出了一种名为DVDP（直接视觉对接策略）的创新端到端视觉对接方法。该方法仅需移动机器人上安装的双目RGB-D相机，即可直接输出机器人的对接路径。研究团队通过Unity 3D平台和实际移动机器人结合，收集了一个大规模的虚拟与真实环境混合数据集，并开发了一系列评估指标来量化端到端视觉对接方法的性能。

Result: 广泛的实验（包括与领先感知骨干网络的基准测试）表明，DVDP方法实现了卓越的性能。在SCOUT Mini上的实际部署证实了DVDP的有效性，其模型生成了符合物理约束并能到达目标姿态的平滑、可行的对接轨迹。

Conclusion: DVDP是一种高效且有前景的端到端视觉对接方法，它克服了现有视觉方法对机器人初始位置的严格要求，能够生成平滑、可行的对接轨迹，并在真实世界环境中表现出强大的实用性。

Abstract: Automatic docking has long been a significant challenge in the field of
mobile robotics. Compared to other automatic docking methods, visual docking
methods offer higher precision and lower deployment costs, making them an
efficient and promising choice for this task. However, visual docking methods
impose strict requirements on the robot's initial position at the start of the
docking process. To overcome the limitations of current vision-based methods,
we propose an innovative end-to-end visual docking method named DVDP(direct
visual docking policy). This approach requires only a binocular RGB-D camera
installed on the mobile robot to directly output the robot's docking path,
achieving end-to-end automatic docking. Furthermore, we have collected a
large-scale dataset of mobile robot visual automatic docking dataset through a
combination of virtual and real environments using the Unity 3D platform and
actual mobile robot setups. We developed a series of evaluation metrics to
quantify the performance of the end-to-end visual docking method. Extensive
experiments, including benchmarks against leading perception backbones adapted
into our framework, demonstrate that our method achieves superior performance.
Finally, real-world deployment on the SCOUT Mini confirmed DVDP's efficacy,
with our model generating smooth, feasible docking trajectories that meet
physical constraints and reach the target pose.

</details>


### [237] [Practical Handling of Dynamic Environments in Decentralised Multi-Robot Patrol](https://arxiv.org/abs/2509.13069)
*James C. Ward,Arthur Richards,Edmund R. Hunt*

Main category: cs.RO

TL;DR: 本文提出了一种新的去中心化多机器人巡逻方法，用于在路线可遍历性高度动态变化的环境中，持续监控并最小化对兴趣点的访问时间。


<details>
  <summary>Details</summary>
Motivation: 在安全、环境监测和灾难恢复等领域，机器人团队的持续监控具有重要意义。完全在线、去中心化的监控方式在鲁棒性、适应性和可扩展性方面具有显著优势，能够实时适应变化的环境。

Method: 本文提出了一种新的方法，用于去中心化多机器人巡逻团队中监测和调整环境动态。该方法旨在持续最小化机器人团队访问兴趣点之间的时间，并在线地观察和处理动态变化。

Result: 实验结果表明，在高度动态的场景中，所提出的方法显著优于实际基线。研究还探讨了在某些动态场景下，明确考虑环境动态可能不必要或不切实际的情况。

Conclusion: 所提出的去中心化多机器人巡逻方法在处理高度动态环境方面表现出色，能够有效提高监控性能。同时，也对该方法的适用边界进行了探讨。

Abstract: Persistent monitoring using robot teams is of interest in fields such as
security, environmental monitoring, and disaster recovery. Performing such
monitoring in a fully on-line decentralised fashion has significant potential
advantages for robustness, adaptability, and scalability of monitoring
solutions, including, in principle, the capacity to effectively adapt in
real-time to a changing environment. We examine this through the lens of
multi-robot patrol, in which teams of patrol robots must persistently minimise
time between visits to points of interest, within environments where
traversability of routes is highly dynamic. These dynamics must be observed by
patrol agents and accounted for in a fully decentralised on-line manner. In
this work, we present a new method of monitoring and adjusting for environment
dynamics in a decentralised multi-robot patrol team. We demonstrate that our
method significantly outperforms realistic baselines in highly dynamic
scenarios, and also investigate dynamic scenarios in which explicitly
accounting for environment dynamics may be unnecessary or impractical.

</details>


### [238] [Beyond Anthropomorphism: Enhancing Grasping and Eliminating a Degree of Freedom by Fusing the Abduction of Digits Four and Five](https://arxiv.org/abs/2509.13074)
*Simon Fritsch,Liam Achenbach,Riccardo Bianco,Nicola Irmiger,Gawain Marti,Samuel Visca,Chenyu Yang,Davide Liconti,Barnabas Gavin Cangan,Robert Jomar Malate,Ronan J. Hinchet,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 本文介绍了一种16自由度（DoF）的SABD机器人手，它通过结合第四和第五指的内收/外展关节，实现了更大的抓取范围、超越人类能力的操纵姿态，并减少了所需执行器数量，同时提高了抓取稳定性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统的拟人化机器人手设计在抓取范围、操纵姿态以及所需执行器数量方面存在局限性，研究旨在克服这些限制，实现更广阔的抓取能力和更灵活的操纵。

Method: SABD手设计通过将第四和第五指的内收/外展（Add/Abd）关节合并为一个具有大运动范围的单一关节。通过实验测量了关节工作空间，进行了抓取200毫米侧向距离物体的测试，使用强化学习（RL）探索抓取策略，并进行了遥操作试验以评估其在YCB物体上的抓取成功率。

Result: 合并后的内收/外展关节使手指工作空间增加了400%，并在保持灵巧性的同时减少了所需自由度。实验证明，该手能够抓取侧向距离达200毫米的物体。基于强化学习的研究表明，该设计不仅能有效处理大型物体，还能提高抓取稳定性。在遥操作试验中，该手成功完成了86%的YCB物体抓取尝试，包括具有挑战性的非拟人化配置。

Conclusion: SABD手的设计在不增加复杂性的前提下，显著增强了抓取稳定性、灵活性和灵巧操纵能力，使其非常适合广泛的应用场景。

Abstract: This paper presents the SABD hand, a 16-degree-of-freedom (DoF) robotic hand
that departs from purely anthropomorphic designs to achieve an expanded grasp
envelope, enable manipulation poses beyond human capability, and reduce the
required number of actuators. This is achieved by combining the
adduction/abduction (Add/Abd) joint of digits four and five into a single joint
with a large range of motion. The combined joint increases the workspace of the
digits by 400\% and reduces the required DoFs while retaining dexterity.
Experimental results demonstrate that the combined Add/Abd joint enables the
hand to grasp objects with a side distance of up to 200 mm. Reinforcement
learning-based investigations show that the design enables grasping policies
that are effective not only for handling larger objects but also for achieving
enhanced grasp stability. In teleoperated trials, the hand successfully
performed 86\% of attempted grasps on suitable YCB objects, including
challenging non-anthropomorphic configurations. These findings validate the
design's ability to enhance grasp stability, flexibility, and dexterous
manipulation without added complexity, making it well-suited for a wide range
of applications.

</details>


### [239] [A Design Co-Pilot for Task-Tailored Manipulators](https://arxiv.org/abs/2509.13077)
*Jonathan Külz,Sehoon Ha,Matthias Althoff*

Main category: cs.RO

TL;DR: 本文提出了一种自动化设计和优化机器人形态的方法，该方法能针对特定任务和环境定制机器人，通过可微分框架和学习逆运动学，将设计时间从数小时缩短到数秒，实现快速适应和人机协作。


<details>
  <summary>Details</summary>
Motivation: 现有机器人制造商普遍采用“一刀切”的设计理念，导致机器人在特定应用中性能不佳。定制化机器人设计周期长、成本高昂。尽管已有计算设计方法和模块化机器人，但仍需要更高效的自动化设计工具来克服人工工程的瓶颈。

Method: 本研究提出了一种自动设计和优化机器人形态的方法。其核心是学习各种机械手的逆运动学，并利用一个完全可微分的框架实现梯度优化的机器人设计和逆运动学解的微调。这是一种生成式方法。

Result: 该方法将专业化设计生成时间从数小时缩短到数秒，可作为设计副驾驶，实现即时适应和有效的人机协作。数值实验表明，该方法能够找到在杂乱环境中导航的机器人、在指定工作空间内表现良好的机械手，并能适应不同的硬件约束。此外，研究通过在模拟中设计的模块化机器人在现实障碍赛中成功移动，验证了该方法的实际应用性。

Conclusion: 本研究提供了一种高效的生成式、可微分框架，能够显著加速特定任务机器人形态的设计和优化过程，从而提升性能、实现快速适应，并促进有效的人机协作，且已在实际应用中得到验证。

Abstract: Although robotic manipulators are used in an ever-growing range of
applications, robot manufacturers typically follow a ``one-fits-all''
philosophy, employing identical manipulators in various settings. This often
leads to suboptimal performance, as general-purpose designs fail to exploit
particularities of tasks. The development of custom, task-tailored robots is
hindered by long, cost-intensive development cycles and the high cost of
customized hardware. Recently, various computational design methods have been
devised to overcome the bottleneck of human engineering. In addition, a surge
of modular robots allows quick and economical adaptation to changing industrial
settings. This work proposes an approach to automatically designing and
optimizing robot morphologies tailored to a specific environment. To this end,
we learn the inverse kinematics for a wide range of different manipulators. A
fully differentiable framework realizes gradient-based fine-tuning of designed
robots and inverse kinematics solutions. Our generative approach accelerates
the generation of specialized designs from hours with optimization-based
methods to seconds, serving as a design co-pilot that enables instant
adaptation and effective human-AI collaboration. Numerical experiments show
that our approach finds robots that can navigate cluttered environments,
manipulators that perform well across a specified workspace, and can be adapted
to different hardware constraints. Finally, we demonstrate the real-world
applicability of our method by setting up a modular robot designed in
simulation that successfully moves through an obstacle course.

</details>


### [240] [Empowering Multi-Robot Cooperation via Sequential World Models](https://arxiv.org/abs/2509.13095)
*Zijie Zhao,Honglei Guo,Shengqian Chen,Kaixuan Xu,Bo Jiang,Yuanheng Zhu,Dongbin Zhao*

Main category: cs.RO

TL;DR: SeqWM是一种新颖的模型化多智能体强化学习框架，通过独立、序列化的智能体世界模型和顺序通信，有效解决了多机器人协作中复杂的联合动力学问题，提高了协作性能和样本效率，并成功应用于物理机器人。


<details>
  <summary>Details</summary>
Motivation: 模型化强化学习(MBRL)在机器人领域显示出高样本效率和规划能力，但由于联合动力学的复杂性，将其扩展到多机器人协作仍然具有挑战性。

Method: 本文提出了序列世界模型(SeqWM)框架，将序列范式整合到模型化多智能体强化学习中。SeqWM采用独立的、序列化结构的智能体世界模型来分解复杂的联合动力学。通过序列通信进行潜在轨迹预测和决策，每个智能体根据其前驱的预测生成未来轨迹并规划行动。这种设计实现了显式意图共享，并使通信开销降至线性复杂度。

Result: 在具有挑战性的模拟环境（Bi-DexHands和Multi-Quad）中，SeqWM在整体性能和样本效率方面均优于现有的最先进无模型和有模型基线，并展现出预测性适应和角色分工等高级协作行为。此外，SeqWM已成功部署到物理四足机器人上，证明了其在真实世界多机器人系统中的有效性。

Conclusion: SeqWM通过其独特的序列化世界模型和通信机制，为多机器人协作提供了一个高效且鲁棒的解决方案，显著提升了协作性能和样本效率，并具备在真实世界应用的能力。

Abstract: Model-based reinforcement learning (MBRL) has shown significant potential in
robotics due to its high sample efficiency and planning capability. However,
extending MBRL to multi-robot cooperation remains challenging due to the
complexity of joint dynamics. To address this, we propose the Sequential World
Model (SeqWM), a novel framework that integrates the sequential paradigm into
model-based multi-agent reinforcement learning. SeqWM employs independent,
sequentially structured agent-wise world models to decompose complex joint
dynamics. Latent rollouts and decision-making are performed through sequential
communication, where each agent generates its future trajectory and plans its
actions based on the predictions of its predecessors. This design enables
explicit intention sharing, enhancing cooperative performance, and reduces
communication overhead to linear complexity. Results in challenging simulated
environments (Bi-DexHands and Multi-Quad) show that SeqWM outperforms existing
state-of-the-art model-free and model-based baselines in both overall
performance and sample efficiency, while exhibiting advanced cooperative
behaviors such as predictive adaptation and role division. Furthermore, SeqWM
has been success fully deployed on physical quadruped robots, demonstrating its
effectiveness in real-world multi-robot systems. Demos and code are available
at: https://github.com/zhaozijie2022/seqwm-marl

</details>


### [241] [Hydrosoft: Non-Holonomic Hydroelastic Models for Compliant Tactile Manipulation](https://arxiv.org/abs/2509.13126)
*Miquel Oller,An Dang,Nima Fazeli*

Main category: cs.RO

TL;DR: 本文提出了一种计算高效的非完整水弹性模型，用于精确模拟机器人触觉传感器的路径依赖接触力分布和动态表面积变化，并支持基于梯度的轨迹优化。


<details>
  <summary>Details</summary>
Motivation: 触觉传感器能提供机器人与抓取物体之间界面的丰富信息，但其固有的柔顺性（力丰富交互的关键驱动因素）带来的复杂非线性动力学，尤其是路径依赖行为，尚未得到充分探索。

Method: 研究人员通过扩展物体状态空间，明确纳入柔顺传感器产生的分布式力，提出了一种计算高效的非完整水弹性模型。该模型具有可微分特性，不仅能解释路径依赖行为，还能实现基于梯度的轨迹优化，并与高分辨率触觉反馈无缝集成。

Result: 该方法能够准确建模路径依赖的接触力分布和动态表面积变化。在模拟和真实世界实验中，该方法均表现出有效性，并强调了建模传感器动力学路径依赖性的重要性。

Conclusion: 精确建模柔顺触觉传感器动力学的路径依赖性对于捕捉机器人与物体之间复杂的交互至关重要，本文提出的模型有效解决了这一挑战，并为基于梯度的轨迹优化提供了支持。

Abstract: Tactile sensors have long been valued for their perceptual capabilities,
offering rich insights into the otherwise hidden interface between the robot
and grasped objects. Yet their inherent compliance -- a key driver of
force-rich interactions -- remains underexplored. The central challenge is to
capture the complex, nonlinear dynamics introduced by these passive-compliant
elements. Here, we present a computationally efficient non-holonomic
hydroelastic model that accurately models path-dependent contact force
distributions and dynamic surface area variations. Our insight is to extend the
object's state space, explicitly incorporating the distributed forces generated
by the compliant sensor. Our differentiable formulation not only accounts for
path-dependent behavior but also enables gradient-based trajectory
optimization, seamlessly integrating with high-resolution tactile feedback. We
demonstrate the effectiveness of our approach across a range of simulated and
real-world experiments and highlight the importance of modeling the path
dependence of sensor dynamics.

</details>


### [242] [An Uncertainty-Weighted Decision Transformer for Navigation in Dense, Complex Driving Scenarios](https://arxiv.org/abs/2509.13132)
*Zhihao Zhang,Chengyang Peng,Minghao Zhu,Ekim Yurtsever,Keith A. Redmill*

Main category: cs.RO

TL;DR: 本文提出了一种不确定性加权决策Transformer (UWDT) 框架，结合鸟瞰图占用栅格和Transformer序列建模，用于复杂环岛场景下的自动驾驶决策，通过加权学习不确定性高的关键状态，显著提升了安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶在密集动态环境中需要决策系统能够利用空间结构和长时序依赖，同时对不确定性保持鲁棒性，尤其要解决低风险常见状态与罕见安全关键决策之间的不平衡问题。

Method: 研究整合了多通道鸟瞰图占用栅格与基于Transformer的序列建模。为解决决策不平衡问题，提出了不确定性加权决策Transformer (UWDT)。UWDT使用一个冻结的教师Transformer来估计每个token的预测熵，该熵作为学生模型损失函数中的权重，从而放大对不确定性高、影响大的状态的学习，同时保持对常见低风险转换的稳定性。

Result: 在环岛模拟器中，UWDT在不同交通密度下，在奖励、碰撞率和行为稳定性方面始终优于其他基线方法。

Conclusion: 实验结果表明，不确定性感知、时空Transformer能够为复杂交通环境中的自动驾驶提供更安全、更高效的决策能力。

Abstract: Autonomous driving in dense, dynamic environments requires decision-making
systems that can exploit both spatial structure and long-horizon temporal
dependencies while remaining robust to uncertainty. This work presents a novel
framework that integrates multi-channel bird's-eye-view occupancy grids with
transformer-based sequence modeling for tactical driving in complex roundabout
scenarios. To address the imbalance between frequent low-risk states and rare
safety-critical decisions, we propose the Uncertainty-Weighted Decision
Transformer (UWDT). UWDT employs a frozen teacher transformer to estimate
per-token predictive entropy, which is then used as a weight in the student
model's loss function. This mechanism amplifies learning from uncertain,
high-impact states while maintaining stability across common low-risk
transitions. Experiments in a roundabout simulator, across varying traffic
densities, show that UWDT consistently outperforms other baselines in terms of
reward, collision rate, and behavioral stability. The results demonstrate that
uncertainty-aware, spatial-temporal transformers can deliver safer and more
efficient decision-making for autonomous driving in complex traffic
environments.

</details>


### [243] [ROOM: A Physics-Based Continuum Robot Simulator for Photorealistic Medical Datasets Generation](https://arxiv.org/abs/2509.13177)
*Salvatore Esposito,Matías Mattamala,Daniel Rebain,Francis Xiatian Zhang,Kevin Dhaliwal,Mohsen Khadem,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 本文提出了ROOM，一个用于生成光真实感支气管镜检查训练数据的综合模拟框架，旨在解决连续体机器人在支气管镜检查中缺乏真实训练环境的问题，并验证了其数据在姿态估计和单目深度估计任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 连续体机器人在支气管镜检查中的发展受到限制，因为缺乏真实的训练和测试环境。收集真实数据存在伦理和患者安全问题，而开发自主算法需要真实的成像和物理反馈。

Method: ROOM（Realistic Optical Observation in Medicine）是一个综合模拟框架。它利用患者CT扫描，生成多模态传感器数据，包括带有真实噪声和光斑的RGB图像、度量深度图、表面法线、光流和点云，所有这些都在医学相关尺度上实现。

Result: ROOM生成的数据在多视角姿态估计和单目深度估计这两个医学机器人典型任务中得到了验证，表明了最先进方法在适应这些医疗场景时需要克服的挑战。此外，研究表明ROOM生成的数据可以用于微调现有深度估计算法以克服这些挑战，并支持导航等下游应用。

Conclusion: ROOM有望实现跨越多样患者解剖结构和手术场景的大规模数据生成，这些场景在临床环境中难以捕捉。

Abstract: Continuum robots are advancing bronchoscopy procedures by accessing complex
lung airways and enabling targeted interventions. However, their development is
limited by the lack of realistic training and test environments: Real data is
difficult to collect due to ethical constraints and patient safety concerns,
and developing autonomy algorithms requires realistic imaging and physical
feedback. We present ROOM (Realistic Optical Observation in Medicine), a
comprehensive simulation framework designed for generating photorealistic
bronchoscopy training data. By leveraging patient CT scans, our pipeline
renders multi-modal sensor data including RGB images with realistic noise and
light specularities, metric depth maps, surface normals, optical flow and point
clouds at medically relevant scales. We validate the data generated by ROOM in
two canonical tasks for medical robotics -- multi-view pose estimation and
monocular depth estimation, demonstrating diverse challenges that
state-of-the-art methods must overcome to transfer to these medical settings.
Furthermore, we show that the data produced by ROOM can be used to fine-tune
existing depth estimation models to overcome these challenges, also enabling
other downstream applications such as navigation. We expect that ROOM will
enable large-scale data generation across diverse patient anatomies and
procedural scenarios that are challenging to capture in clinical settings. Code
and data: https://github.com/iamsalvatore/room.

</details>


### [244] [HARMONIC: A Content-Centric Cognitive Robotic Architecture](https://arxiv.org/abs/2509.13279)
*Sanjay Oruganti,Sergei Nirenburg,Marjorie McShane,Jesse English,Michael K. Roberts,Christian Arndt,Carlos Gonzalez,Mingyo Seo,Luis Sentis*

Main category: cs.RO

TL;DR: 本文介绍了一种名为HARMONIC的认知机器人架构，旨在增强人机团队中机器人的语义感知、类人决策和意图语言交流能力，以解决安全性、数据稀缺性、可解释性等问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了解决人机团队中机器人面临的安全和结果质量问题，以及数据稀缺性、可解释性和安全性挑战，并提升系统的透明度和人机之间的信任。

Method: 提出了HARMONIC认知机器人架构，该架构支持语义感知解释、类人决策和意图语言交流。通过在高保真仿真环境和物理机器人平台上实现并演示了两个基于HARMONIC的概念验证机器人系统。

Result: 成功演示了两个基于HARMONIC的机器人概念验证系统，证明了该架构在仿真和物理平台上的可行性。

Conclusion: HARMONIC架构通过其语义感知、类人决策和意图语言交流能力，为解决人机团队中的安全、可解释性和信任等关键问题提供了有效的解决方案，提升了人机协作的质量。

Abstract: This paper introduces HARMONIC, a cognitive-robotic architecture designed for
robots in human-robotic teams. HARMONIC supports semantic perception
interpretation, human-like decision-making, and intentional language
communication. It addresses the issues of safety and quality of results; aims
to solve problems of data scarcity, explainability, and safety; and promotes
transparency and trust. Two proof-of-concept HARMONIC-based robotic systems are
demonstrated, each implemented in both a high-fidelity simulation environment
and on physical robotic platforms.

</details>


### [245] [StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening](https://arxiv.org/abs/2509.13200)
*Moonyoung Lee,Dong Ki Kim,Jai Krishna Bandi,Max Smith,Aileen Liao,Ali-akbar Agha-mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: StageACT是一种阶段条件模仿学习框架，通过将任务阶段输入到低级策略中，提高了人形机器人在部分可观察的长程开门任务中的鲁棒性和成功率。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在人类环境中操作时，开门是一项基本但具有挑战性的技能。开门是一个长程、部分可观察的任务（例如，门闩状态不可见），这使得标准行为克隆容易出现模式崩溃，导致动作混合或乱序。

Method: 本文提出了StageACT，一个阶段条件模仿学习框架。它通过任务阶段输入来增强低级策略，以提高对部分可观察性的鲁棒性。

Result: 在真实世界办公环境中，StageACT在未曾见过的门上实现了55%的成功率，是最佳基线的两倍多。此外，该方法通过阶段提示支持意图行为引导，实现恢复行为。

Conclusion: 阶段条件化是一种轻量级但强大的机制，适用于人形机器人长程的运动-操作任务。

Abstract: Humanoid robots promise to operate in everyday human environments without
requiring modifications to the surroundings. Among the many skills needed,
opening doors is essential, as doors are the most common gateways in built
spaces and often limit where a robot can go. Door opening, however, poses
unique challenges as it is a long-horizon task under partial observability,
such as reasoning about the door's unobservable latch state that dictates
whether the robot should rotate the handle or push the door. This ambiguity
makes standard behavior cloning prone to mode collapse, yielding blended or
out-of-sequence actions. We introduce StageACT, a stage-conditioned imitation
learning framework that augments low-level policies with task-stage inputs.
This effective addition increases robustness to partial observability, leading
to higher success rates and shorter completion times. On a humanoid operating
in a real-world office environment, StageACT achieves a 55% success rate on
previously unseen doors, more than doubling the best baseline. Moreover, our
method supports intentional behavior guidance through stage prompting, enabling
recovery behaviors. These results highlight stage conditioning as a lightweight
yet powerful mechanism for long-horizon humanoid loco-manipulation.

</details>


### [246] [Collaborative Loco-Manipulation for Pick-and-Place Tasks with Dynamic Reward Curriculum](https://arxiv.org/abs/2509.13239)
*Tianxu An,Flavio De Vincenti,Yuntao Ma,Marco Hutter,Stelian Coros*

Main category: cs.RO

TL;DR: 本文提出了一种分层强化学习（RL）流程，用于训练单臂腿足机器人执行端到端的抓取-放置（P&P）任务，包括单机器人和协作双机器人场景，并通过动态奖励课程显著提高了训练效率和执行速度。


<details>
  <summary>Details</summary>
Motivation: 训练腿足机器人执行从接近物体到释放的端到端、长周期抓取-放置任务，尤其是在协作双机器人设置下，是一个复杂且具有挑战性的问题。

Method: 本文引入了一个分层强化学习（RL）流程，并提出了一种新颖的动态奖励课程。该课程通过逐步引导智能体完成以载荷为中心的子目标，使单一策略能够高效学习长周期的P&P操作。在双机器人情况下，策略使每个机器人在不同任务阶段关注其观察空间的不同部分，通过自主注意力转移促进有效协调。该方法通过ANYmal D平台进行了仿真和真实世界验证。

Result: 在仿真实验中，与现有长周期RL方法相比，本文方法将训练效率提高了55%，执行时间缩短了18.6%。在双机器人场景中，策略通过自主注意力转移实现了有效协调。据作者所知，这是第一个解决两个腿足机械臂协作P&P全范围的RL流程。该方法已通过ANYmal D平台在单机器人和双机器人场景下进行了真实世界实验验证。

Conclusion: 本文提出的分层RL流程和动态奖励课程成功地使单臂腿足机器人在单机器人和协作双机器人设置下，高效地执行了端到端的长周期抓取-放置任务，并在训练效率和执行速度上取得了显著提升，为协作腿足机械臂P&P任务提供了有效的解决方案。

Abstract: We present a hierarchical RL pipeline for training one-armed legged robots to
perform pick-and-place (P&P) tasks end-to-end -- from approaching the payload
to releasing it at a target area -- in both single-robot and cooperative
dual-robot settings. We introduce a novel dynamic reward curriculum that
enables a single policy to efficiently learn long-horizon P&P operations by
progressively guiding the agents through payload-centered sub-objectives.
Compared to state-of-the-art approaches for long-horizon RL tasks, our method
improves training efficiency by 55% and reduces execution time by 18.6% in
simulation experiments. In the dual-robot case, we show that our policy enables
each robot to attend to different components of its observation space at
distinct task stages, promoting effective coordination via autonomous attention
shifts. We validate our method through real-world experiments using ANYmal D
platforms in both single- and dual-robot scenarios. To our knowledge, this is
the first RL pipeline that tackles the full scope of collaborative P&P with two
legged manipulators.

</details>


### [247] [Design and Control of a Perching Drone Inspired by the Prey-Capturing Mechanism of Venus Flytrap](https://arxiv.org/abs/2509.13249)
*Ye Li,Daming Liu,Yanhe Zhu,Junming Zhang,Yongsheng Luo,Ziqi Wang,Chenyu Liu,Jie Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种受捕蝇草启发的新型快速仿生栖息无人机，结合级联扩展高增益观测器（EHGO）控制方法，以提高无人机的续航能力、栖息速度和抗干扰稳定性。


<details>
  <summary>Details</summary>
Motivation: 无人机的续航能力和能源效率是其设计和操作中的关键挑战。通过栖息机制暂时停止飞行以节省能量，是延长任务时间的一种有效方法。

Method: 该研究开发了一种新型栖息无人机，其主动柔性栖息机制灵感来源于捕蝇草的快速捕食机制，可在100毫秒内完成栖息。系统设计旨在实现对栖息目标的高速适应性。为增强系统稳定性，开发了一种基于级联扩展高增益观测器（EHGO）的控制方法，能够实时估计和补偿外部干扰。

Result: 实验结果表明，该栖息结构具有良好的适应性，能在100毫秒内完成栖息。同时，级联EHGO在抵抗风扰和栖息干扰方面表现出卓越的性能，有效提升了系统稳定性。

Conclusion: 该研究成功开发了一种具有快速仿生栖息机制和EHGO控制的无人机系统，有效解决了无人机续航和能量效率的关键挑战，并通过实验验证了其栖息结构适应性和控制方法的抗干扰优越性。

Abstract: The endurance and energy efficiency of drones remain critical challenges in
their design and operation. To extend mission duration, numerous studies
explored perching mechanisms that enable drones to conserve energy by
temporarily suspending flight. This paper presents a new perching drone that
utilizes an active flexible perching mechanism inspired by the rapid predation
mechanism of the Venus flytrap, achieving perching in less than 100 ms. The
proposed system is designed for high-speed adaptability to the perching
targets. The overall drone design is outlined, followed by the development and
validation of the biomimetic perching structure. To enhance the system
stability, a cascade extended high-gain observer (EHGO) based control method is
developed, which can estimate and compensate for the external disturbance in
real time. The experimental results demonstrate the adaptability of the
perching structure and the superiority of the cascaded EHGO in resisting wind
and perching disturbances.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [248] [A Cost-Optimization Model for EV Charging Stations Utilizing Solar Energy and Variable Pricing](https://arxiv.org/abs/2509.12214)
*An Nguyen,Hung Pham,Cuong Do*

Main category: eess.SY

TL;DR: 本文提出一个电动汽车充电站成本优化框架，利用光伏发电，并通过鲁棒优化处理电价不确定性，实现了显著的成本节约和实时可行性。


<details>
  <summary>Details</summary>
Motivation: 电动汽车充电站面临电力采购成本高昂且电价不确定的挑战。研究旨在开发一个能够有效利用现场光伏发电、降低采购成本并应对电价波动的优化方案。

Method: 该研究将模型构建为一个线性规划问题，以满足车辆能源需求、遵守充电和电网容量限制并最小化采购成本。它采用Bertsimas-Sim鲁棒公式来明确考虑电价不确定性。模型在Caltech ACN数据集的真实充电数据上进行评估。

Result: 与先到先得基线相比，该方法平均节省约12%的成本，月度峰值降幅高达19.2%。轻量级敏感性分析显示，名义成本适度增加约5%可将最坏情况下的风险降低14%。计算测试证实了实时可行性，在标准笔记本电脑上，多达50辆并发电动汽车的实例可在5秒内求解。

Conclusion: 所提出的方法为未来的电动汽车充电运营提供了一个实用、对电网友好且可扩展的解决方案。

Abstract: This paper presents a cost optimization framework for electric vehicle (EV)
charging stations that leverages on-site photovoltaic (PV) generation and
explicitly accounts for electricity price uncertainty through a Bertsimas--Sim
robust formulation. The model is formulated as a linear program that satisfies
vehicle energy demands, respects charging and grid capacity constraints, and
minimizes procurement cost. Evaluations on real charging data from the Caltech
ACN dataset show average savings of about 12\% compared to a
first-come--first-served baseline, with peak monthly reductions up to 19.2\%. A
lightweight sensitivity analysis indicates that a modest $\sim$5\% increase in
nominal cost can reduce worst-case exposure by 14\%. Computational tests
confirm real-time feasibility, with instances of up to 50 concurrent EVs solved
in under 5 seconds on a standard laptop. The proposed method provides a
practical, grid-friendly, and scalable solution for future EV charging
operations.

</details>


### [249] [Private Markovian Equilibrium in Stackelberg Markov Games for Smart Grid Demand Response](https://arxiv.org/abs/2509.12225)
*Siying Huang,Yifen Mu,Ge Chen*

Main category: eess.SY

TL;DR: 本文提出了一种斯塔克尔伯格马尔可夫博弈（SMG）模型，用于解决可再生能源集成带来的电力供需平衡挑战。该模型考虑了用户存储水平的隐私性，引入了私有马尔可夫策略和均衡（PME），并证明了其在多项式时间内的可计算性。通过结合中心化和去中心化算法，该方法在多达50个用户的场景下展现出有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 可再生能源的日益整合给电网的供需平衡带来了巨大挑战，需要有效的机制来管理电力价格、用户需求和储能决策。

Method: 研究方法包括：1) 建立了一个聚合商与多个用户之间的斯塔克尔伯格马尔可夫博弈（SMG），其中聚合商设定电价，用户做出需求和储能决策。2) 针对用户储能水平的私有性，引入了私有状态、私有马尔可夫策略（PMS）和私有马尔可夫均衡（PME）的新概念。3) 提出了一种结合中心化和去中心化算法的可扩展解决方案框架，用于下层PME计算和上层定价优化。

Result: 主要成果有：1) 证明了下层马尔可夫博弈中纯PME的存在性。2) 证明了PME可以在多项式时间内计算，这在一般马尔可夫博弈中是罕见的。3) 基于真实数据的数值模拟（多达50个用户）验证了所提出方法的有效性和可扩展性，显著优于以往通常只考虑不超过5个用户的研究。

Conclusion: 本文成功开发了一种针对多用户环境下电力定价和需求响应的有效且可扩展的解决方案，该方案能够处理用户私有信息，并在计算复杂性上取得了突破，为应对可再生能源整合挑战提供了新思路。

Abstract: The increasing integration of renewable energy introduces a great challenge
to the supply and demand balance of the power grid. To address this challenge,
this paper formulates a Stackelberg Markov game (SMG) between an aggregator and
multiple users, where the aggregator sets electricity prices and users make
demand and storage decisions. Considering that users' storage levels are
private information, we introduce private states and propose the new concepts
of private Markovian strategies (PMS) and private Markovian equilibrium (PME).
We establish the existence of a pure PME in the lower-level Markov game and
prove that it can be computed in polynomial time. Notably, computing
equilibrium in general Markov games is hard, and polynomial-time algorithms are
rarely available. Based on these theoretical results, we develop a scalable
solution framework combining centralized and decentralized algorithms for the
lower-level PME computation with upper-level pricing optimization. Numerical
simulations with up to 50 users based on real data validate the effectiveness
and scalability of the proposed methods, whereas prior studies typically
consider no more than 5 users.

</details>


### [250] [Meta-model Neural Process for Probabilistic Power Flow under Varying N-1 System Topologies](https://arxiv.org/abs/2509.12281)
*Sel Ly,Kapil Chauhan,Anshuman Singh,Hung Dinh Nguyen*

Main category: eess.SY

TL;DR: 本文提出了一种基于元模型神经过程（MMNP）的拓扑自适应方法，用于在N-1拓扑变化（单线故障）下求解概率潮流问题，避免了传统方法因拓扑变化而需要重新训练的弊端。


<details>
  <summary>Details</summary>
Motivation: 传统的概率潮流（PPF）问题假设固定拓扑，当拓扑发生变化时（如N-1故障），需要重新求解PPF，导致不便和计算负担，尤其是在可再生能源和电动汽车普及导致电网不确定性增加的背景下。

Method: 提出了一种基于元模型神经过程（MMNP）的拓扑自适应方法。该方法利用基于上下文集的拓扑表示和函数学习上的条件分布技术，增强了PPF模型对拓扑变化的鲁棒性。

Result: 在IEEE 9节点系统和IEEE 118节点系统上的仿真验证了模型的性能。在9节点和118节点系统中，观察到的最大L1相对误差范数分别为1.11%和0.77%。

Conclusion: 该自适应方法增强了PPF模型对拓扑变化的鲁棒性，减少了在新配置下重新训练PPF模型的需要。它填补了在电网波动性日益增加的时代PPF方法学中的关键空白。

Abstract: The probabilistic power flow (PPF) problem is essential to quantifying the
distribution of the nodal voltages due to uncertain injections. The
conventional PPF problem considers a fixed topology, and the solutions to such
a PPF problem are associated with this topology. A change in the topology might
alter the power flow patterns and thus require the PPF problem to be solved
again. The previous PPF model and its solutions are no longer valid for the new
topology. This practice incurs both inconvenience and computation burdens as
more contingencies are foreseen due to high renewables and a large share of
electric vehicles. This paper presents a novel topology-adaptive approach,
based on the meta-model Neural Process (MMNP), for finding the solutions to PPF
problems under varying N-1 topologies, particularly with one-line failures. By
leveraging context set-based topology representation and conditional
distribution over function learning techniques, the proposed MMNP enhances the
robustness of PPF models to topology variations, mitigating the need for
retraining PPF models on a new configuration. Simulations on an IEEE 9-bus
system and IEEE 118-bus system validate the model's performance. The maximum
%L1-relative error norm was observed as 1.11% and 0.77% in 9-bus and 118-bus,
respectively. This adaptive approach fills a critical gap in PPF methodology in
an era of increasing grid volatility.

</details>


### [251] [A Deep Learning Approach to Renewable Capacity Installation under Jump Uncertainty](https://arxiv.org/abs/2509.12364)
*Nacira Agram,Fred Espen Benth,Giulia Pucci,Jan Rems*

Main category: eess.SY

TL;DR: 本研究提出了一个随机模型，用于在需求不确定性和跳跃动态下安装可再生能源容量。它采用了两种控制方法：基于阈值的跳跃BSDE方法（具有可解释性）和数据驱动的深度控制算法（具有更好的性能），为长期可再生能源扩张提供决策支持。


<details>
  <summary>Details</summary>
Motivation: 在需求不确定性和可再生能源发电、电力负荷的突发变化（由跳跃驱动的动态捕捉）下，有效管理可再生能源容量的安装是一个重要的挑战。

Method: 研究采用由次序器驱动的多维Ornstein-Uhlenbeck (OU) 过程来建模系统。提出了两种解决方案：1. 基于阈值的控制规则：当随机容量因子低于固定水平时，按比例增加容量，这导致一个非线性偏积分微分方程(PIDE)，通过将其重构为带跳跃的后向随机微分方程(BSDE)并扩展DBDP求解器（使用双神经网络）来解决。2. 数据驱动的深度控制算法：使用神经网络直接学习最优反馈策略，通过最小化预期成本函数来避免对控制规则形式的假设。

Result: 数值实验表明，基于阈值的BSDE方法提供了可解释性和易处理性，而深度控制策略通过容量分配的灵活性实现了改进的性能。

Conclusion: 这两种方法共同提供了一个鲁棒的框架，用于在不确定性下进行长期可再生能源扩张的决策支持。

Abstract: We study a stochastic model for the installation of renewable energy capacity
under demand uncertainty and jump driven dynamics. The system is governed by a
multidimensional Ornstein-Uhlenbeck (OU) process driven by a subordinator,
capturing abrupt variations in renewable generation and electricity load.
Installation decisions are modeled through control actions that increase
capacity in response to environmental and economic conditions.
  We consider two distinct solution approaches. First, we implement a
structured threshold based control rule, where capacity is increased
proportionally when the stochastic capacity factor falls below a fixed level.
This formulation leads to a nonlinear partial integro-differential equation
(PIDE), which we solve by reformulating it as a backward stochastic
differential equation with jumps. We extend the DBDP solver in
\cite{hure2020deep} to the pure jump setting, employing a dual neural network
architecture to approximate both the value function and the jump sensitivity.
  Second, we propose a fully data driven deep control algorithm that directly
learns the optimal feedback policy by minimizing the expected cost functional
using neural networks. This approach avoids assumptions on the form of the
control rule and enables adaptive interventions based on the evolving system
state.
  Numerical experiments highlight the strengths of both methods. While the
threshold based BSDE approach offers interpretability and tractability, the
deep control strategy achieves improved performance through flexibility in
capacity allocation. Together, these tools provide a robust framework for
decision support in long term renewable energy expansion under uncertainty.

</details>


### [252] [Platoon-Centric Green Light Optimal Speed Advisory Using Safe Reinforcement Learning](https://arxiv.org/abs/2509.12378)
*Ruining Yang,Jingyuan Zhou,Qiqing Wang,Jinhao Liang,Kaidi Yang*

Main category: eess.SY

TL;DR: 本文提出了一种以车队为中心的安全强化学习（RL）绿色信号最优速度建议（GLOSA）系统，该系统通过结合控制障碍函数（CBF）来确保车辆跟驰和闯红灯安全，同时优化混合交通中自动驾驶车辆（CAV）车队的能耗和出行效率。


<details>
  <summary>Details</summary>
Motivation: 现有GLOSA研究主要关注单个CAV的能耗和出行效率，忽略了对整个混合交通车队的影响，导致交通流效率低下。强化学习虽有潜力实现车队级控制，但面临跟驰安全和闯红灯安全挑战。

Method: 开发了一个以车队为中心、基于安全强化学习的GLOSA系统，采用多智能体控制器优化CAV速度，以平衡能耗和出行效率。此外，将控制障碍函数（CBF）融入到基于RL的策略中，为跟驰安全和闯红灯安全提供明确的安全保障。

Result: 仿真结果表明，所提出的方法在驾驶安全性和车队能耗方面优于现有最先进的方法。

Conclusion: 该研究成功地为混合交通环境下的CAV车队设计了一个安全的RL-GLOSA系统，有效解决了安全挑战，并在节能和出行效率之间取得了良好平衡，同时提升了车队整体的驾驶安全性和能耗表现。

Abstract: With recent advancements in Connected Autonomous Vehicles (CAVs), Green Light
Optimal Speed Advisory (GLOSA) emerges as a promising eco-driving strategy to
reduce the number of stops and idle time at intersections, thereby reducing
energy consumption and emissions. Existing studies typically improve energy and
travel efficiency for individual CAVs without considering their impacts on the
entire mixed-traffic platoon, leading to inefficient traffic flow. While
Reinforcement Learning (RL) has the potential to achieve platoon-level control
in a mixed-traffic environment, the training of RL is still challenged by (i)
car-following safety, i.e., CAVs should not collide with their immediate
preceding vehicles, and (ii) red-light safety, i.e., CAVs should not run red
lights. To address these challenges, this paper develops a platoon-centric,
safe RL-based GLOSA system that uses a multi-agent controller to optimize CAV
speed while achieving a balance between energy consumption and travel
efficiency. We further incorporate Control Barrier Functions (CBFs) into the
RL-based policy to provide explicit safety guarantees in terms of car-following
safety and red-light safety. Our simulation results illustrate that our
proposed method outperforms state-of-the-art methods in terms of driving safety
and platoon energy consumption.

</details>


### [253] [Hybrid State Estimation of Uncertain Nonlinear Dynamics Using Neural Processes](https://arxiv.org/abs/2509.12522)
*Devin Hunter,Chinwendu Enyioha*

Main category: eess.SY

TL;DR: 本文提出了一种基于物理信息注意力神经过程（PI-AttNP）和分层共形预测（CP）的混合数据驱动状态估计方法，用于实时非线性系统，并提供具有概率保证的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 实时非线性状态估计中，数据驱动模型（特别是神经网络）的应用日益增多，但安全关键应用需要具有可靠误差范围的模型。现有方法缺乏量化的模型不确定性。

Method: 提出了一种新颖的混合数据驱动状态估计方法，其核心是物理信息注意力神经过程（PI-AttNP），这是注意力神经过程（AttNP）的模型信息扩展。该方法通过基于回归的分层共形预测（CP）框架进行增强，以获得具有概率保证的量化模型不确定性。

Result: 该算法在模拟欠驱动六自由度四旋翼飞行器的灰盒状态估计任务中得到了验证，该任务包含多模态高斯传感器噪声和多种外部扰动。与最先进的数据驱动方法进行比较，结果显著证明了物理信息神经过程作为一种可行的模型驱动估计新方法的有效性。

Conclusion: 结合共形预测的物理信息神经过程（PI-AttNP）是一种可行的模型驱动状态估计新方法，它能为数据驱动模型提供量化的不确定性，并在复杂动态系统（如四旋翼飞行器）的实时状态估计中展现出优越性能。

Abstract: Various neural network architectures are used in many of the state-of-the-art
approaches for real-time nonlinear state estimation in dynamical systems. With
the ever-increasing incorporation of these data-driven models into the
estimation domain, models with reliable margins of error are required --
especially for safety-critical applications. This paper discusses a novel
hybrid, data-driven state estimation approach based on the physics-informed
attentive neural process (PI-AttNP), a model-informed extension of the
attentive neural process (AttNP). We augment this estimation approach with the
regression-based split conformal prediction (CP) framework to obtain quantified
model uncertainty with probabilistic guarantees. After presenting the algorithm
in a generic form, we validate its performance in the task of grey-box state
estimation of a simulated under-actuated six-degree-of-freedom quadrotor with
multimodal Gaussian sensor noise and several external perturbations typical to
quadrotors. Further, we compare outcomes with state-of-the-art data-driven
methods, which provide significant evidence of the physics-informed neural
process as a viable novel approach for model-driven estimation.

</details>


### [254] [CattleSense -- A Multisensory Approach to Optimize Cattle Well-Being](https://arxiv.org/abs/2509.12617)
*Srijesh Pillai,M. I. Jawid Nazir*

Main category: eess.SY

TL;DR: CattleSense是一个基于物联网的系统，旨在通过实时监测牛只的环境和个体参数（如位置、挤奶频率、心跳）来全面管理牛只的健康和安全。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是简化牛棚中的牛只管理，确保牛只的健康和安全。

Method: 系统设计和实现采用了多种硬件组件，包括Raspberry Pi Module 4B、RFID读卡器、驻极体Arduino麦克风模块、DHT11传感器、Arduino UNO、Neo-6M GPS传感器和心跳传感器。

Result: 该系统能够提供牛只所在环境的实时监控，以及牛只个体参数（如位置、挤奶频率和心跳波动）的实时数据。

Conclusion: CattleSense系统的主要目标是简化牛棚中的牛只管理，确保牛只的健康和安全。

Abstract: CattleSense is an innovative application of Internet of Things (IoT)
technology for the comprehensive monitoring and management of cattle
well-being. This research paper outlines the design and implementation of a
sophisticated system using a Raspberry Pi Module 4B, RFID Card Reader, Electret
Arduino Microphone Module, DHT11 Sensor, Arduino UNO, Neo-6M GPS Sensor, and
Heartbeat Sensor. The system aims to provide real-time surveillance of the
environment in which Cows are present and individual Cow parameters such as
location, milking frequency, and heartbeat fluctuations. The primary objective
is to simplify managing the Cattle in the shed, ensuring that the Cattle are
healthy and safe.

</details>


### [255] [Nonlinear Sampled-data Systems--A Lifting Framework](https://arxiv.org/abs/2509.12681)
*Yutaka Yamamoto,Kaoru Yamamoto*

Main category: eess.SY

TL;DR: 本文提出了一种处理非线性采样数据系统的新框架，通过引入一种新的“提升”技术，将非线性系统转换为具有函数空间输入输出的等效时不变离散时间系统。


<details>
  <summary>Details</summary>
Motivation: 线性系统中的“提升”技术已成熟，但未能成功推广到非线性系统。主要困难在于线性系统中的直接馈通项无法直接推广到非线性情况。

Method: 本文提出了一种针对非线性时不变系统的新型“提升”技术。与线性系统不同，该方法通过进一步提升状态轨迹，获得一个具有函数空间输入和输出的等效时不变离散时间系统。

Result: 给出了基本框架和带有离散时间控制器的闭环方程。作为该框架的应用，还提供了一种表示从原始非线性系统导出的Koopman算子表示方法。

Conclusion: 本文为处理非线性采样数据系统提供了一个新的通用框架，通过创新的提升技术克服了现有线性方法的局限性，并为非线性系统的分析和控制开辟了新的途径，尤其是在Koopman算子表示方面展示了其应用潜力。

Abstract: This short note gives a new framework for dealing with nonlinear sampled-data
systems. We introduce a new idea of lifting, which is well known for linear
systems, but not successfully generalized to nonlinear systems. This paper
introduces a new lifting technique for nonlinear, time-invariant systems, which
are different from the linear counterpart as developed in [Bamieh et al. 1991,
Yamamoto 1994], etc. The main difficulty is that the direct feedthrough term
effective in the linear case cannot be generalized to the nonlinear case.
Instead, we will further lift the state trajectory, and obtain an equivalent
time-invariant discrete-time system with function-space input and output
spaces. The basic framework, as well as the closed-loop equation with a
discrete-time controller, is given. As an application of this framework, we
give a representation for the Koopman operator derived from the given original
nonlinear system.

</details>


### [256] [MAPS: A Mode-Aware Probabilistic Scheduling Framework for LPV-Based Adaptive Control](https://arxiv.org/abs/2509.12695)
*Taehun Kim,Guntae Kim,Cheolmin Jeong,Chang Mook Kang*

Main category: eess.SY

TL;DR: 本文提出了一种名为MAPS的自适应控制框架，它将交互式多模型（IMM）估计器与基于线性参数变化（LPV）的控制策略相结合，通过实时模式概率进行增益调度，以应对直流电机系统中的变摩擦问题。


<details>
  <summary>Details</summary>
Motivation: 直流电机系统常遇到变化的摩擦力，这使得传统控制难以维持高性能。研究旨在开发一种无需明确摩擦模型识别，能动态适应摩擦操作模式变化的自适应控制框架。

Method: MAPS框架独特地将交互式多模型（IMM）估计器与基于线性参数变化（LPV）的控制策略相结合。它利用更新的模式概率作为LPV控制器中在线增益合成的插值权重，从而紧密耦合状态估计与自适应控制，实现控制增益的实时动态调整。

Result: 在硬件在环仿真（HILS）环境中的验证表明，与依赖预定义调度变量的线性二次调节器（LQR）控制器相比，MAPS显著提高了状态估计精度和参考跟踪性能。

Conclusion: MAPS被确立为一种鲁棒、可泛化的解决方案，适用于不确定、时变环境中的摩擦感知自适应控制，并具有实际的实时应用潜力。

Abstract: This paper proposes Mode-Aware Probabilistic Scheduling (MAPS), a novel
adaptive control framework tailored for DC motor systems experiencing varying
friction. MAPS uniquely integrates an Interacting Multiple Model (IMM)
estimator with a Linear Parameter-Varying (LPV) based control strategy,
leveraging real-time mode probability estimates to perform probabilistic gain
scheduling. A key innovation of MAPS lies in directly using the updated mode
probabilities as the interpolation weights for online gain synthesis in the LPV
controller, thereby tightly coupling state estimation with adaptive control.
This seamless integration enables the controller to dynamically adapt control
gains in real time, effectively responding to changes in frictional operating
modes without requiring explicit friction model identification. Validation on a
Hardware-in-the-Loop Simulation (HILS) environment demonstrates that MAPS
significantly enhances both state estimation accuracy and reference tracking
performance compared to Linear Quadratic Regulator (LQR) controllers relying on
predefined scheduling variables. These results establish MAPS as a robust,
generalizable solution for friction-aware adaptive control in uncertain,
time-varying environments, with practical real-time applicability.

</details>


### [257] [Towards Native AI in 6G Standardization: The Roadmap of Semantic Communication](https://arxiv.org/abs/2509.12758)
*Ping Zhang,Xiaodong Xu,Mengying Sun,Haixiao Gao,Nan Ma,Xiaoyun Wang,Ruichen Zhang,Jiacheng Wang,Dusit Niyato*

Main category: eess.SY

TL;DR: 本文全面概述了语义通信（SemCom）在6G网络中的最新进展、标准化活动、关键使能技术，并讨论了其面临的挑战和未来发展。


<details>
  <summary>Details</summary>
Motivation: 语义通信（SemCom）作为一种变革性范式，为未来6G网络提供了面向任务和意义感知的传输，重新定义了传统的以比特为中心的设计，并被领先的标准化机构（如IEEE、ITU、3GPP）广泛认可和讨论。

Method: 本文通过学术界和工业界的视角，全面回顾了SemCom的最新进展，重点关注其标准化活动。具体方法包括：系统性地审查代表性应用场景、架构设计、语义-传统系统兼容性、统一评估指标和验证方法；强调联合源信道编码（JSCC）、模型分割多址（MDMA）和语义知识库（KB）等关键使能技术；并通过信道状态信息（CSI）反馈的案例研究，展示了在符合3GPP标准的衰落信道下的具体性能增益。

Result: SemCom在符合3GPP标准的衰落信道下，如CSI反馈场景，展现了具体的性能增益。论文还识别了支持SemCom在符合标准的系统中实际实现的关键使能技术，并讨论了将其融入6G标准化中的新兴挑战和研究机会。

Conclusion: SemCom正迅速成为原生AI 6G的基础性使能技术。本文探讨了将语义原生机制纳入不断发展的6G标准化进程中的挑战和机遇，并对其发展和全球采纳提供了前瞻性见解。

Abstract: Semantic communication (SemCom) has emerged as a transformative paradigm for
future 6G networks, offering task-oriented and meaning-aware transmission that
fundamentally redefines traditional bit-centric design. Recognized by leading
standardization bodies including the institute of electrical and electronics
engineers (IEEE) and the international telecommunication union (ITU), and
actively discussed within the 3rd generation partnership project (3GPP) working
groups, SemCom is rapidly gaining traction as a foundational enabler for
native-AI 6G. This paper presents a comprehensive overview of recent progress
in SemCom from both academic and industrial perspectives, with a focus on its
ongoing and upcoming standardization activities. We systematically examine
advances in representative application scenarios, architectural design,
semantic-traditional system compatibility, unified evaluation metrics, and
validation methodologies. Furthermore, we highlight several key enabling
technologies, such as joint source-channel coding (JSCC), SemCom-based multiple
access (MA) technologies such as model division MA (MDMA), and semantic
knowledge base (KB), that support the practical implementation of SemCom in
standard-compliant systems. Additionally, we present a case study for channel
state information (CSI) feedback, illustrating the concrete performance gains
of SemCom under 3GPP-compliant fading channels. Finally, we discuss emerging
challenges and research opportunities for incorporating semantic-native
mechanisms into the evolving 6G standardization landscape, and provide
forward-looking insights into its development and global adoption.

</details>


### [258] [Ellipsoidal partitions for improved multi-stage robust model predictive control](https://arxiv.org/abs/2509.12792)
*Moritz Heinlein,Florian Messerer,Moritz Diehl,Sergio Lucia*

Main category: eess.SY

TL;DR: 本文提出一种结合椭球管式模型预测控制和场景树方法的新型多阶段MPC，通过半空间划分不确定性椭球，实现更灵活的反馈控制，并在人机系统中验证其在处理不确定性方面的优势及计算可行性。


<details>
  <summary>Details</summary>
Motivation: 椭球管式MPC在可达集传播方面有效且提供严格保证，但反馈策略通常限于线性；而基于场景的方法提供更灵活的反馈结构，但难以保证严格性。研究动机是结合两者的优点。

Method: 通过场景树公式增强椭球管式MPC。不确定性椭球被半空间划分，使得每个划分的集合可以独立控制。该方法被称为椭球多阶段方法。

Result: 在人机系统中进行了演示，结果突出显示了该方法在处理不确定性方面的优势，同时保持了计算的可行性。

Conclusion: 所提出的椭球多阶段方法成功整合了两种方法的优点，在处理不确定性方面表现出色，并能保持计算上的可行性。

Abstract: Ellipsoidal tube-based model predictive control methods effectively account
for the propagation of the reachable set, typically employing linear feedback
policies. In contrast, scenario-based approaches offer more flexibility in the
feedback structure by considering different control actions for different
branches of a scenario tree. However, they face challenges in ensuring rigorous
guarantees. This work aims to integrate the strengths of both methodologies by
enhancing ellipsoidal tube-based MPC with a scenario tree formulation. The
uncertainty ellipsoids are partitioned by halfspaces such that each partitioned
set can be controlled independently. The proposed ellipsoidal multi-stage
approach is demonstrated in a human-robot system, highlighting its advantages
in handling uncertainty while maintaining computational tractability.

</details>


### [259] [Spatial Correlation and Degrees of Freedom in Arched HMIMO Arrays: A Closed-Form Analysis](https://arxiv.org/abs/2509.12839)
*Liuxun Xue,Shu Sun,Hangsong Yan*

Main category: eess.SY

TL;DR: 本文对拱形全息多输入多输出（HMIMO）阵列的空间相关性和自由度（DoF）进行了闭式分析，发现DoF主要由阵列的最大跨度决定，并且对曲率变化具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的平面阵列配置与实际中可能存在的弯曲HMIMO表面之间存在差异。这种曲率会显著影响阵列的空间特性和性能，因此需要深入理解其影响。

Method: 该研究推导了拱形均匀线阵（ULA）和拱形均匀矩形阵列（URA）在远场传播条件下的精确闭式相关表达式，以捕捉曲率效应。并通过数值仿真验证了闭式公式的准确性。

Result: 研究结果表明，在各向同性散射下，DoF主要由HMIMO阵列的最大跨度决定，形状效应被削弱，弯曲不会显著降低可用的空间DoF。数值模拟证实了公式的准确性以及DoF对曲率变化的鲁棒性。

Conclusion: 这些发现为下一代HMIMO/FAS系统的几何感知优化提供了基础性见解，并为弯曲HMIMO阵列的实际实现铺平了道路，支持灵活的阵列设计。

Abstract: This paper presents a closed-form analysis of spatial correlation and degrees
of freedom (DoF) for arched holographic multiple-input multiple-output (HMIMO)
arrays, which can be viewed as a special form of fluid antenna systems (FAS)
when their geometry is fluidically adaptable. Unlike traditional planar
configurations, practical HMIMO surfaces may exhibit curvature, significantly
influencing their spatial characteristics and performance. We derive exact
correlation expressions for both arched uniform linear arrays and arched
uniform rectangular arrays, capturing curvature effects under far field
propagation. Our results reveal that isotropic scattering results in DoF being
dominated by the maximum span of the HMIMO array, such that shape effects are
weakened, and bending does not significantly reduce the available spatial DoF.
Numerical simulations validate the accuracy of the closed-form formulas and
demonstrate the robustness of DoF against curvature variations, supporting
flexible array designs. These findings offer fundamental insights into
geometry-aware optimization for next-generation HMIMO/FAS systems and pave the
way for practical implementations of curved HMIMO arrays.

</details>


### [260] [Grid-informed Sharing Coefficients in Renewable Energy Communities](https://arxiv.org/abs/2509.12847)
*Alireza Shooshtari,Antonio Pepiciello,José Luis Domínguez-García*

Main category: eess.SY

TL;DR: 本文提出了一种“馈线感知”的能源分配策略，通过优先考虑同一馈线内的能源共享来应对能源社区中参与者空间分布可能导致的局部电网拥堵问题，实验结果表明该策略能促进本地能源平衡并提高参与者收益。


<details>
  <summary>Details</summary>
Motivation: 能源社区中参与者的空间分布对电网运行影响显著，特别是当本地能源生产者和消费者分布在不同馈线时，经济激励可能导致局部电网拥堵。因此，需要一种考虑电网拓扑的能源共享策略来解决这一挑战。

Method: 研究提出了一种“馈线感知”的能源分配策略，该策略将电网拓扑结构纳入能源共享机制，优先在同一馈线内进行能源共享，以激励本地供需平衡。该策略在静态和动态公式下测试了不同的共享系数，如平均、按比例和基于排名的分配方式。

Result: 仿真结果表明，所提出的馈线感知策略不仅能有效促进本地能源平衡，还能为大多数参与者带来更高且更稳定的收益。

Conclusion: 馈线感知策略通过将电网拓扑纳入能源共享机制，能够有效改善电网运行，并通过促进本地能源平衡和提高参与者收益来解决能源社区中空间分布引起的电网拥堵问题。

Abstract: The role of energy communities in grid operations is highly dependent on the
spatial distribution of their participants. In particular, when local energy
producers and consumers are concentrated in different feeders, economic
incentives from energy communities have the potential to affect local grid
congestion. To address this challenge, we propose a feeder-aware allocation
strategy that reflects grid topology in energy sharing. This strategy
prioritizes energy sharing within the same feeder, thus incentivizing local
generation-demand balance and improving grid operation. Different sharing
coefficients are tested, such as equal, proportional, and rank-based, in both
static and dynamic formulations. The proposed strategy is tested on data from a
real energy community, whose participants are assumed to be distributed across
four feeders. The analysis is carried out from the perspectives of the
community as a whole, individual feeders, and single participants. Simulation
results show that the feeder-aware strategy, in addition to promoting local
energy balance, leads to higher and more stable revenues for most participants.

</details>


### [261] [Topology and Fragility of European High-Voltage Networks: A Cross-Country Comparative Analysis](https://arxiv.org/abs/2509.12900)
*Bálint Hartmann,Michelle T. Cirunay*

Main category: eess.SY

TL;DR: 本研究对15个欧洲国家的高压电网进行了拓扑建模和分析，发现节点度分布遵循指数衰减，且衰减率与系统对故障的弹性或脆弱性密切相关，同时强调了模型中包含的基础设施层级的重要性。


<details>
  <summary>Details</summary>
Motivation: 高压电网基础设施的结构多样性对系统脆弱性有显著影响，但缺乏对欧洲高压电网的定量跨国比较，以了解其拓扑特性与脆弱性之间的关系。

Method: 研究构建了15个欧洲国家高压电网（电压等级高于110 kV）的统一拓扑模型。通过拓扑分析，研究了节点度分布，并系统评估了网络对节点和边缘移除的容忍度。

Result: 节点度分布一致遵循指数衰减，但衰减率在不同国家间差异显著。衰减率划定了系统对故障更具弹性或更容易出现大规模中断的边界。此外，该数值边界对模型中包含的基础设施层级高度敏感。

Conclusion: 本研究首次对15个欧洲高压电网进行了定量跨国比较，成功将拓扑特性（特别是指数衰减率）与脆弱性特征联系起来，揭示了电网结构多样性对系统韧性的关键影响。

Abstract: Reliable electricity supply depends on the seamless operation of high-voltage
grid infrastructure spanning both transmission and sub-transmission levels.
Beneath this apparent uniformity lies a striking structural diversity, which
leaves a clear imprint on system vulnerability. In this paper, we present
harmonized topological models of the high-voltage grids of 15 European
countries, integrating all elements at voltage levels above 110 kV. Topological
analysis of these networks reveals a simple yet robust pattern: node degree
distributions consistently follow an exponential decay, but the rate of decay
varies significantly across countries. Through a detailed and systematic
evaluation of network tolerance to node and edge removals, we show that the
decay rate delineates the boundary between systems that are more resilient to
failures and those that are prone to large-scale disruptions. Furthermore, we
demonstrate that this numerical boundary is highly sensitive to which layers of
the infrastructure are included in the models. To our knowledge, this study
provides the first quantitative cross-country comparison of 15 European
high-voltage networks, linking topological properties with vulnerability
characteristics.

</details>


### [262] [Momentum-Based Access and Speed Control for Improved Safety in Heterogeneous Road Networks](https://arxiv.org/abs/2509.12944)
*Felix Wieberneit,Emanuele Crisostomi,Wynita Griggs,Robert Shorten*

Main category: eess.SY

TL;DR: 本文提出了一种两级控制算法，通过准入控制降低交通异质性，并通过速度控制减轻碰撞伤害，从而提高异质交通网络的安全性，该算法基于动量考虑，并在SUMO模拟器中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 交通工具种类日益增多（如电动滑板车、电动自行车等轻型车辆），同时传统车辆因电动化和消费者偏好SUV而重量增加，导致道路网络的异质性加剧，引发了对道路安全的严重担忧。

Method: 设计了一个两级控制算法：首先，基于实际交通状况的准入控制策略以降低网络异质性；其次，速度控制策略旨在降低潜在碰撞中严重受伤的可能性。这两种策略均基于动量考量设计，因为动量被认为是评估受伤风险最有影响力的变量。采用SUMO道路网络移动模拟器来实施和验证所提出的控制策略。

Result: 通过在SUMO模拟器中实施和验证，证明了所提出的基于动量的两级控制策略（准入控制和速度控制）能够有效改善异质交通网络的安全状况，通过降低网络异质性和减轻碰撞伤害风险。

Conclusion: 所提出的基于动量考量的两级控制算法，通过准入控制和速度控制，能够有效提高异质道路网络的安全水平，是应对当前交通安全挑战的有效方法。

Abstract: The increasing variety of means of transportation, including light vehicles
like e-scooters and e-bikes, together with the increasing weight of
conventional vehicles due to electrification and consumer preferences for SUVs,
are raising serious concerns regarding the safety of road networks. In this
paper we design a two-level control algorithm to improve the safety of
heterogeneous networks: first, an access control strategy decreases the
heterogeneity of the network depending on actual traffic conditions; then, a
speed control strategy mitigates the probability of serious injuries in
potential collisions. Both control strategies are designed based on momentum
considerations, as this is regarded as the most influential variable to assess
injury risk. The road network mobility simulator SUMO is adopted to implement
and validate our proposed control strategies.

</details>


### [263] [Concentration inequalities for semidefinite least squares based on data](https://arxiv.org/abs/2509.13166)
*Filippo Fabiani,Andrea Simonetto*

Main category: eess.SY

TL;DR: 本文研究数据驱动的带半定（SD）约束的最小二乘（LS）问题，并通过放宽这些约束，为其最优解的谱提供了有限样本保证。


<details>
  <summary>Details</summary>
Motivation: 动机是为了解决全SDLS问题的复杂性，并提供一种更简单的替代方案，同时仍能保证解的质量。

Method: 通过推导一个高置信度界限，允许用一个更简单的程序代替完整的SDLS问题。这个界限是易于计算、与分布无关的，并且只需要独立同分布的样本。

Result: 研究结果表明，通过放宽约束得到的解的特征值与SD约束强制的特征值之间的距离在$\varepsilon$范围内。该证书随着数据量的增加而缩小。此外，当SDLS用于学习未知二次函数时，还建立了无SD约束的替代成本的梯度下降迭代与真实最小值之间的误差界限。

Conclusion: 研究提供了一种在解决SDLS问题时，通过放宽约束来简化计算的方法，并提供了关于其最优解谱的强有力、易于计算且与分布无关的有限样本保证。

Abstract: We study data-driven least squares (LS) problems with semidefinite (SD)
constraints and derive finite-sample guarantees on the spectrum of their
optimal solutions when these constraints are relaxed. In particular, we provide
a high confidence bound allowing one to solve a simpler program in place of the
full SDLS problem, while ensuring that the eigenvalues of the resulting
solution are $\varepsilon$-close of those enforced by the SD constraints. The
developed certificate, which consistently shrinks as the number of data
increases, turns out to be easy-to-compute, distribution-free, and only
requires independent and identically distributed samples. Moreover, when the
SDLS is used to learn an unknown quadratic function, we establish bounds on the
error between a gradient descent iterate minimizing the surrogate cost obtained
with no SD constraints and the true minimizer.

</details>


### [264] [Safety Critical Model Predictive Control Using Discrete-Time Control Density Functions](https://arxiv.org/abs/2509.13257)
*Sriram S. K. S. Narayanan,Sajad Ahmadi,Javad Mohammadpour Velni,Umesh Vaidya*

Main category: eess.SY

TL;DR: 本文提出MPC-CDF框架，将控制密度函数(CDFs)整合到模型预测控制(MPC)中，以实现非线性动态系统的安全关键控制。


<details>
  <summary>Details</summary>
Motivation: 需要在非线性动态系统中确保安全关键控制，并同时保证收敛性。

Method: 通过导航问题的对偶公式，将控制密度函数(CDFs)整合到MPC框架中，确保离散时间设置下的收敛性和安全性。CDF被赋予物理意义，其关联测度表示系统轨迹的占用率。利用这种基于占用率的视角合成安全关键控制器。

Result: 该框架确保了收敛性和安全性，并通过独轮车模型和水下航行器自主安全导航进行了验证。与基于控制障碍函数的方法相比，它能有效避免复杂任意障碍物并达到所需的安全性水平。

Conclusion: MPC-CDF框架能有效合成非线性动态系统的安全关键控制器，并已在实际应用中展示了其有效性和安全性。

Abstract: This paper presents MPC-CDF, a new approach integrating control density
functions (CDFs) within a model predictive control (MPC) framework to ensure
safety-critical control in nonlinear dynamical systems. By using the dual
formulation of the navigation problem, we incorporate CDFs into the MPC
framework, ensuring both convergence and safety in a discrete-time setting.
These density functions are endowed with a physical interpretation, where the
associated measure signifies the occupancy of system trajectories. Leveraging
this occupancy-based perspective, we synthesize safety-critical controllers
using the proposed MPC-CDF framework. We illustrate the safety properties of
this framework using a unicycle model and compare it with a control barrier
function-based method. The efficacy of this approach is demonstrated in the
autonomous safe navigation of an underwater vehicle, which avoids complex and
arbitrary obstacles while achieving the desired level of safety.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [265] [Physics-Informed Neural Networks vs. Physics Models for Non-Invasive Glucose Monitoring: A Comparative Study Under Realistic Synthetic Conditions](https://arxiv.org/abs/2509.12253)
*Riyaadh Gani*

Main category: eess.IV

TL;DR: 本文介绍了一个超现实的近红外（NIR）模拟器，用于解决非侵入式血糖监测器在实验室外表现不佳的问题。研究发现，增强型Beer-Lambert模型在模拟数据上优于更复杂的物理信息神经网络（PINNs），并提供了一个开放的参考堆栈。


<details>
  <summary>Details</summary>
Motivation: 现有的非侵入式血糖监测数据集忽略了硬件噪声、环境漂移和个体生理差异，导致设备在实际应用中表现不佳。这促使研究人员开发一个更真实的模拟器来评估监测方法。

Method: 研究引入了首个超现实近红外（NIR）模拟器，该模拟器注入了12位ADC量化、LED老化、光电二极管暗噪声、温度、相对湿度、接触压力变化、Fitzpatrick I-VI黑色素以及昼夜血糖波动等多种真实世界因素。在此平台上，研究人员对六种方法进行了基准测试：增强型Beer-Lambert（物理工程岭回归）、三种物理信息神经网络（PINNs）、一种选择性辐射传输PINN和一个浅层DNN。

Result: 该模拟平台（rho glucose-NIR = 0.21）的基准测试结果显示，增强型Beer-Lambert模型实现了13.6 mg/dL的RMSE，95.8%的Clarke-A精度和93.8%的+/-15%准确率，仅使用56个参数和0.01毫秒的推理时间。它优于表现最佳的PINN（14.6 mg/dL）和SDNN基线（35.1 mg/dL）。

Conclusion: 研究结果推翻了更深层PINNs在非侵入式血糖监测中占据主导地位的假设，表明一个更简单、物理驱动的模型（增强型Beer-Lambert）可以表现更优。该研究还提供了一个开放的、端到端的参考堆栈，用于嵌入式光学血糖传感器的快速原型开发。

Abstract: Non-invasive glucose monitors often fail outside the lab because existing
datasets ignore hardware noise, environmental drift, and person-to-person
physiology. We introduce the first ultra-realistic near-infrared (NIR)
simulator that injects 12-bit ADC quantisation, +/-0.1% LED ageing, photodiode
dark noise, 15-45 C temperature, 30-90% relative humidity, contact-pressure
variation, Fitzpatrick I-VI melanin, and diurnal glucose excursions (dawn
phenomenon). Using this platform (rho glucose-NIR = 0.21), we benchmark six
methods: Enhanced Beer-Lambert (physics-engineered ridge regression), three
physics-informed neural networks (PINNs), a selective radiative-transfer PINN,
and a shallow DNN. Beer-Lambert achieves 13.6 mg/dL RMSE, 95.8% Clarke-A and
93.8% +/-15% accuracy with only 56 parameters and 0.01 ms inference,
outperforming the best PINN (14.6 mg/dL) and the SDNN baseline (35.1 mg/dL).
Results overturn the assumption that deeper PINNs dominate and supply an open,
end-to-end reference stack for rapid prototyping of embedded optical glucose
sensors.

</details>


### [266] [Enhancing Radiographic Disease Detection with MetaCheX, a Context-Aware Multimodal Model](https://arxiv.org/abs/2509.12287)
*Nathan He,Cody Chen*

Main category: eess.IV

TL;DR: MetaCheX是一个多模态框架，结合胸部X射线图像和患者元数据，显著提高了胸部放射学诊断的准确性，并减少了算法偏见。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在胸部放射学诊断中忽视了患者元数据，这限制了诊断的准确性和公平性。

Method: MetaCheX框架将卷积神经网络（CNN）骨干用于处理X射线图像，将多层感知器（MLP）用于处理结构化患者元数据，然后将两者通过一个共享分类器进行整合。

Result: 在CheXpert Plus数据集上，MetaCheX在多种CNN架构下均优于仅使用放射图像的基线模型。通过整合元数据，诊断准确性（AUROC）显著提高。研究结果表明，元数据减少了算法偏见，并增强了模型在不同患者群体中的泛化能力。

Conclusion: MetaCheX将临床人工智能推向了更稳健、更具上下文感知能力的放射学疾病检测，复制了临床决策过程。

Abstract: Existing deep learning models for chest radiology often neglect patient
metadata, limiting diagnostic accuracy and fairness. To bridge this gap, we
introduce MetaCheX, a novel multimodal framework that integrates chest X-ray
images with structured patient metadata to replicate clinical decision-making.
Our approach combines a convolutional neural network (CNN) backbone with
metadata processed by a multilayer perceptron through a shared classifier.
Evaluated on the CheXpert Plus dataset, MetaCheX consistently outperformed
radiograph-only baseline models across multiple CNN architectures. By
integrating metadata, the overall diagnostic accuracy was significantly
improved, measured by an increase in AUROC. The results of this study
demonstrate that metadata reduces algorithmic bias and enhances model
generalizability across diverse patient populations. MetaCheX advances clinical
artificial intelligence toward robust, context-aware radiographic disease
detection.

</details>


### [267] [DinoAtten3D: Slice-Level Attention Aggregation of DinoV2 for 3D Brain MRI Anomaly Classification](https://arxiv.org/abs/2509.12512)
*Fazle Rafsani,Jay Shah,Catherine D. Chong,Todd J. Schwedt,Teresa Wu*

Main category: eess.IV

TL;DR: 本研究提出一种基于注意力机制的全局聚合框架，利用预训练的DINOv2模型和复合损失函数，在有限数据和类别不平衡的情况下，实现了3D医学图像异常分类的强大性能。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的异常检测和分类对于早期诊断至关重要，但面临标注数据有限、类别不平衡和专家标注成本高昂等挑战。新兴的视觉基础模型（如DINOv2）在大量无标签数据上进行预训练，提供了广义的表示，有望缓解这些限制。

Method: 该方法利用自监督的DINOv2模型作为预训练的2D特征提取器，处理脑部MRI的单个2D轴向切片。通过软注意力机制分配自适应的切片级重要性权重，并提出一个专门针对3D医学图像异常分类的基于注意力机制的全局聚合框架。为解决数据稀缺问题，采用结合监督对比学习和类别方差正则化的复合损失函数，以增强类间可分离性和类内一致性。

Result: 该框架在ADNI数据集和一个机构多类别头痛队列上进行了验证，尽管数据可用性有限且类别严重不平衡，但仍展示出强大的异常分类性能。

Conclusion: 研究结果强调了利用预训练的2D基础模型结合基于注意力的切片聚合，在医学影像中实现鲁棒的体积异常检测的有效性。

Abstract: Anomaly detection and classification in medical imaging are critical for
early diagnosis but remain challenging due to limited annotated data, class
imbalance, and the high cost of expert labeling. Emerging vision foundation
models such as DINOv2, pretrained on extensive, unlabeled datasets, offer
generalized representations that can potentially alleviate these limitations.
In this study, we propose an attention-based global aggregation framework
tailored specifically for 3D medical image anomaly classification. Leveraging
the self-supervised DINOv2 model as a pretrained feature extractor, our method
processes individual 2D axial slices of brain MRIs, assigning adaptive
slice-level importance weights through a soft attention mechanism. To further
address data scarcity, we employ a composite loss function combining supervised
contrastive learning with class-variance regularization, enhancing inter-class
separability and intra-class consistency. We validate our framework on the ADNI
dataset and an institutional multi-class headache cohort, demonstrating strong
anomaly classification performance despite limited data availability and
significant class imbalance. Our results highlight the efficacy of utilizing
pretrained 2D foundation models combined with attention-based slice aggregation
for robust volumetric anomaly detection in medical imaging. Our implementation
is publicly available at https://github.com/Rafsani/DinoAtten3D.git.

</details>


### [268] [DeepEyeNet: Generating Medical Report for Retinal Images](https://arxiv.org/abs/2509.12534)
*Jia-Hong Huang*

Main category: eess.IV

TL;DR: 本论文研究了利用人工智能自动化视网膜图像医疗报告生成，以提高诊断效率和准确性，应对眼科医生短缺问题。


<details>
  <summary>Details</summary>
Motivation: 视网膜疾病日益普遍，但眼科医生数量不足，导致诊断和治疗瓶颈。传统手动报告生成耗时且易出错，进一步加重医生负担，可能延误关键治疗。

Method: 本文提出了一系列基于AI的方法：1) 多模态深度学习方法，捕获文本关键词与视网膜图像之间的交互，生成更全面的报告；2) 改进医疗关键词表示方法，增强系统捕捉医学术语细微差别的能力；3) 克服基于RNN模型局限性的策略，尤其是在捕获医学描述中长距离依赖方面的能力；4) 增强AI报告生成系统可解释性的技术，以提高临床实践中的信任和接受度。

Result: 所提出的方法经过严格评估，使用了多种指标，并达到了最先进的性能。

Conclusion: 本论文展示了AI通过自动化医疗报告生成，在彻底改变视网膜疾病诊断方面的巨大潜力，最终提高临床效率、诊断准确性和患者护理水平。

Abstract: The increasing prevalence of retinal diseases poses a significant challenge
to the healthcare system, as the demand for ophthalmologists surpasses the
available workforce. This imbalance creates a bottleneck in diagnosis and
treatment, potentially delaying critical care. Traditional methods of
generating medical reports from retinal images rely on manual interpretation,
which is time-consuming and prone to errors, further straining
ophthalmologists' limited resources. This thesis investigates the potential of
Artificial Intelligence (AI) to automate medical report generation for retinal
images. AI can quickly analyze large volumes of image data, identifying subtle
patterns essential for accurate diagnosis. By automating this process, AI
systems can greatly enhance the efficiency of retinal disease diagnosis,
reducing doctors' workloads and enabling them to focus on more complex cases.
The proposed AI-based methods address key challenges in automated report
generation: (1) A multi-modal deep learning approach captures interactions
between textual keywords and retinal images, resulting in more comprehensive
medical reports; (2) Improved methods for medical keyword representation
enhance the system's ability to capture nuances in medical terminology; (3)
Strategies to overcome RNN-based models' limitations, particularly in capturing
long-range dependencies within medical descriptions; (4) Techniques to enhance
the interpretability of the AI-based report generation system, fostering trust
and acceptance in clinical practice. These methods are rigorously evaluated
using various metrics and achieve state-of-the-art performance. This thesis
demonstrates AI's potential to revolutionize retinal disease diagnosis by
automating medical report generation, ultimately improving clinical efficiency,
diagnostic accuracy, and patient care.

</details>


### [269] [A Computational Pipeline for Patient-Specific Modeling of Thoracic Aortic Aneurysm: From Medical Image to Finite Element Analysis](https://arxiv.org/abs/2509.12596)
*Jiasong Chen,Linchen Qian,Ruonan Gong,Christina Sun,Tongran Qin,Thuy Pham,Caitlin Martin,Mohammad Zafar,John Elefteriades,Wei Sun,Liang Liang*

Main category: eess.IV

TL;DR: 胸主动脉瘤(TAA)是导致死亡的主要原因之一，本研究旨在通过结合三维CT、深度学习图像分割和有限元分析(FEA)构建患者特异性生物力学模型，以准确评估TAA破裂风险并支持个性化治疗。


<details>
  <summary>Details</summary>
Motivation: 胸主动脉瘤(TAA)破裂是成人死亡的主要原因之一，目前诊断主要依赖3D CT。为了更准确地评估TAA的破裂和夹层风险，需要整合主动脉的几何特征和壁应力。开发患者特异性的生物力学模型对于精确预测TAA风险和指导个性化治疗至关重要。

Method: 使用三维计算机断层扫描(3D CT)作为诊断金标准；采用基于深度学习的图像分割技术提取解剖区域；将体素分割掩膜转换为结构化六面体网格表示；利用有限元分析(FEA)模拟主动脉壁应力，以实现患者特异性建模和生物力学行为分析。

Result: 通过整合医学成像、深度学习分割和有限元分析，能够实现对个体解剖结构和生物力学行为的详细评估，从而支持精确模拟、准确诊断和个性化治疗策略。构建准确的有限元模型是建立患者特异性、基于生物力学的TAA风险预测框架的关键第一步。

Conclusion: 开发结合医学成像、深度学习和有限元分析的患者特异性生物力学模型，对于准确预测胸主动脉瘤(TAA)的破裂风险、实现精确诊断和提供个性化治疗策略具有至关重要的意义。

Abstract: The aorta is the body's largest arterial vessel, serving as the primary
pathway for oxygenated blood within the systemic circulation. Aortic aneurysms
consistently rank among the top twenty causes of mortality in the United
States. Thoracic aortic aneurysm (TAA) arises from abnormal dilation of the
thoracic aorta and remains a clinically significant disease, ranking as one of
the leading causes of death in adults. A thoracic aortic aneurysm ruptures when
the integrity of all aortic wall layers is compromised due to elevated blood
pressure. Currently, three-dimensional computed tomography (3D CT) is
considered the gold standard for diagnosing TAA. The geometric characteristics
of the aorta, which can be quantified from medical imaging, and stresses on the
aortic wall, which can be obtained by finite element analysis (FEA), are
critical in evaluating the risk of rupture and dissection. Deep learning based
image segmentation has emerged as a reliable method for extracting anatomical
regions of interest from medical images. Voxel based segmentation masks of
anatomical structures are typically converted into structured mesh
representation to enable accurate simulation. Hexahedral meshes are commonly
used in finite element simulations of the aorta due to their computational
efficiency and superior simulation accuracy. Due to anatomical variability,
patient specific modeling enables detailed assessment of individual anatomical
and biomechanics behaviors, supporting precise simulations, accurate diagnoses,
and personalized treatment strategies. Finite element (FE) simulations provide
valuable insights into the biomechanical behaviors of tissues and organs in
clinical studies. Developing accurate FE models represents a crucial initial
step in establishing a patient-specific, biomechanically based framework for
predicting the risk of TAA.

</details>


### [270] [MEGAN: Mixture of Experts for Robust Uncertainty Estimation in Endoscopy Videos](https://arxiv.org/abs/2509.12772)
*Damola Agbelese,Krishna Chaitanya,Pushpak Pati,Chaitanya Parmar,Pooya Mobadersany,Shreyas Fadnavis,Lindsey Surace,Shadi Yarandi,Louis R. Ghanem,Molly Lucas,Tommaso Mansi,Oana Gabriela Cula,Pablo F. Damasceno,Kristopher Standish*

Main category: eess.IV

TL;DR: 该论文提出了MEGAN，一个多专家门控网络，通过聚合来自多个EDL模型的预测和不确定性估计来解决医学AI中由于专家间差异导致的单一标注问题，从而提高预测置信度和校准度，并在溃疡性结肠炎严重程度估计中取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 传统的AI不确定性量化（UQ）方法（如MC Dropout和Deep Ensembles）以及Evidential Deep Learning（EDL）通常依赖于单一专家的标注作为真值进行模型训练，忽略了医疗领域中普遍存在的专家间差异性。

Method: 该研究提出了MEGAN（Multi-Expert Gating Network），它通过聚合来自多个AI专家（EDL模型）的不确定性估计和预测来解决问题。这些EDL模型使用不同的真值和建模策略进行训练。MEGAN的门控网络能够优化结合每个EDL模型的预测和不确定性，从而增强整体预测的置信度和校准度。

Result: 在溃疡性结肠炎（UC）疾病严重程度估计的内窥镜视频基准测试中，MEGAN相比现有方法F1分数提高了3.5%，预期校准误差（ECE）降低了30.5%。此外，MEGAN还促进了不确定性引导的样本分层，减少了标注负担，并可能提高UC试验的效率和一致性。

Conclusion: MEGAN通过有效处理专家间差异性，显著提高了医学AI在不确定性量化方面的性能、预测置信度和校准度。它还通过不确定性引导的样本分层，为临床试验带来了潜在的效率和一致性提升。

Abstract: Reliable uncertainty quantification (UQ) is essential in medical AI.
Evidential Deep Learning (EDL) offers a computationally efficient way to
quantify model uncertainty alongside predictions, unlike traditional methods
such as Monte Carlo (MC) Dropout and Deep Ensembles (DE). However, all these
methods often rely on a single expert's annotations as ground truth for model
training, overlooking the inter-rater variability in healthcare. To address
this issue, we propose MEGAN, a Multi-Expert Gating Network that aggregates
uncertainty estimates and predictions from multiple AI experts via EDL models
trained with diverse ground truths and modeling strategies. MEGAN's gating
network optimally combines predictions and uncertainties from each EDL model,
enhancing overall prediction confidence and calibration. We extensively
benchmark MEGAN on endoscopy videos for Ulcerative colitis (UC) disease
severity estimation, assessed by visual labeling of Mayo Endoscopic Subscore
(MES), where inter-rater variability is prevalent. In large-scale prospective
UC clinical trial, MEGAN achieved a 3.5% improvement in F1-score and a 30.5%
reduction in Expected Calibration Error (ECE) compared to existing methods.
Furthermore, MEGAN facilitated uncertainty-guided sample stratification,
reducing the annotation burden and potentially increasing efficiency and
consistency in UC trials.

</details>
