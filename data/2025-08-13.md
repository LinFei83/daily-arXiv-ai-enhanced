<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 41]
- [cs.CV](#cs.CV) [Total: 72]
- [cs.CL](#cs.CL) [Total: 62]
- [cs.RO](#cs.RO) [Total: 25]
- [eess.SY](#eess.SY) [Total: 7]
- [eess.IV](#eess.IV) [Total: 6]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Topos Theory for Generative AI and LLMs](https://arxiv.org/abs/2508.08293)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 本文提出使用拓扑斯理论（一种范畴论）设计新型生成式AI（GAIA）架构，特别是针对大型语言模型（LLM），旨在构建基于通用范畴论构造的更具组合性的LLM架构。


<details>
  <summary>Details</summary>
Motivation: 现有LLM架构多为线性或专家混合模型，而Transformer已被证明是通用函数逼近器。本文旨在利用LLM作为函数形成一个拓扑斯的特性，探索基于范畴论的全新、更具组合性的LLM架构设计，超越传统的链式结构。

Method: 本文利用范畴论中的普适构造（如拉回、推出、等化子、指数对象、子对象分类器）来构建新型LLM组合结构。通过理论验证，证明LLM的范畴是完备的（所有图都有极限/上极限解），并进一步证明该范畴形成一个拓扑斯（通过展示指数对象和子对象分类器的存在）。最后，利用反向传播的函子化特征定义了LLM拓扑斯架构的潜在实现。

Result: 本文理论上验证了基于LLM范畴普适性质的新型组合结构。主要结果表明，LLM的范畴是（上）完备的，并且形成一个拓扑斯（“类集合”范畴），这意味着它具有所有必要的范畴论性质以支持复杂的组合设计。

Conclusion: 通过将LLM视为函数并证明其范畴形成一个拓扑斯，本文为设计具有更丰富组合结构的新型LLM架构提供了理论基础和方法，超越了当前主流的线性或专家混合模型。

Abstract: We propose the design of novel categorical generative AI architectures
(GAIAs) using topos theory, a type of category that is ``set-like": a topos has
all (co)limits, is Cartesian closed, and has a subobject classifier. Previous
theoretical results on the Transformer model have shown that it is a universal
sequence-to-sequence function approximator, and dense in the space of all
continuous functions with compact support on the Euclidean space of embeddings
of tokens. Building on this theoretical result, we explore novel architectures
for LLMs that exploit the property that the category of LLMs, viewed as
functions, forms a topos. Previous studies of large language models (LLMs) have
focused on daisy-chained linear architectures or mixture-of-experts. In this
paper, we use universal constructions in category theory to construct novel LLM
architectures based on new types of compositional structures. In particular,
these new compositional structures are derived from universal properties of LLM
categories, and include pullback, pushout, (co) equalizers, exponential
objects, and subobject classifiers. We theoretically validate these new
compositional structures by showing that the category of LLMs is (co)complete,
meaning that all diagrams have solutions in the form of (co)limits. Building on
this completeness result, we then show that the category of LLMs forms a topos,
a ``set-like" category, which requires showing the existence of exponential
objects as well as subobject classifiers. We use a functorial characterization
of backpropagation to define a potential implementation of an LLM topos
architecture.

</details>


### [2] [Topos Causal Models](https://arxiv.org/abs/2508.08295)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 本文提出了一种新型因果模型——拓扑因果模型（TCMs），它利用拓扑斯范畴的关键性质（完备性、子对象分类器、指数对象）来形式化和解决因果推断中的干预、复杂图求解和因果等价类问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机是利用拓扑斯范畴的数学性质，为因果推断提供一个更通用、更严格的框架，以应对现有结构因果模型（SCMs）在处理复杂因果图、干预建模以及因果等价性推理方面的挑战。

Method: TCMs被定义为一组函数，模仿SCMs的局部自主机制。研究方法包括：1) 证明TCMs范畴是（共）完备的；2) 利用子对象分类器对因果干预进行范畴化建模，生成子模型；3) 通过极限和余极限解释因果近似，从而“求解”任意复杂度的因果图；4) 利用指数对象推导因果模型操作的等价类（如覆盖边反转和因果同伦）；5) 使用自然变换衡量近似质量；6) 引入Mitchell-Benabou语言和Kripke-Joyal语义的内部逻辑，用于在TCMs中进行因果推理。

Result: 主要结果包括：1) 提出了TCMs这一新型因果模型类；2) 证明了TCMs的范畴是（共）完备的；3) 展示了子对象分类器如何实现因果干预的范畴化表达；4) 揭示了极限和余极限如何通过因果近似来“求解”任意复杂度的因果图；5) 阐明了指数对象如何支持对因果等价类操作的推理；6) 引入了TCMs的内部逻辑，为因果推理提供了新工具。

Conclusion: 结论是拓扑因果模型（TCMs）提供了一个强大的、统一的范畴学框架，能够有效处理因果推断中的关键问题，如干预、复杂模型近似和因果等价性。其内部逻辑进一步增强了在这一框架内进行因果推理的能力。

Abstract: We propose topos causal models (TCMs), a novel class of causal models that
exploit the key properties of a topos category: they are (co)complete, meaning
all (co)limits exist, they admit a subobject classifier, and allow exponential
objects. The main goal of this paper is to show that these properties are
central to many applications in causal inference. For example, subobject
classifiers allow a categorical formulation of causal intervention, which
creates sub-models. Limits and colimits allow causal diagrams of arbitrary
complexity to be ``solved", using a novel interpretation of causal
approximation. Exponential objects enable reasoning about equivalence classes
of operations on causal models, such as covered edge reversal and causal
homotopy. Analogous to structural causal models (SCMs), TCMs are defined by a
collection of functions, each defining a ``local autonomous" causal mechanism
that assemble to induce a unique global function from exogenous to endogenous
variables. Since the category of TCMs is (co)complete, which we prove in this
paper, every causal diagram has a ``solution" in the form of a (co)limit: this
implies that any arbitrary causal model can be ``approximated" by some global
function with respect to the morphisms going into or out of the diagram.
Natural transformations are crucial in measuring the quality of approximation.
In addition, we show that causal interventions are modeled by subobject
classifiers: any sub-model is defined by a monic arrow into its parent model.
Exponential objects permit reasoning about entire classes of causal
equivalences and interventions. Finally, as TCMs form a topos, they admit an
internal logic defined as a Mitchell-Benabou language with an associated
Kripke-Joyal semantics. We show how to reason about causal models in TCMs using
this internal logic.

</details>


### [3] [An Efficient Application of Goal Programming to Tackle Multiobjective Problems with Recurring Fitness Landscapes](https://arxiv.org/abs/2508.08297)
*Rodrigo Lankaites Pinheiro,Dario Landa-Silva,Wasakorn Laesanklang,Ademir Aparecido Constantino*

Main category: cs.AI

TL;DR: 提出一种新方法，通过结合多目标算法和目标规划来高效解决具有相似适应度景观的复杂多目标问题。


<details>
  <summary>Details</summary>
Motivation: 许多实际应用中的决策者需要评估具有多个冲突目标的解决方案质量。对于高度约束的多目标问题，即使是现代多目标算法也很难获得好的近似解集。在某些情况下，同一问题场景的不同实例具有相似的适应度景观。

Method: 该方法首先使用计算成本高的多目标算法解决给定问题场景的一个实例，以获得一个良好的近似解集。然后，对于同一问题场景的其他实例，利用目标规划（Goal Programming）和高效的单目标算法进行求解。研究中使用了三种基于目标的目标函数。

Result: 在带有时间窗的多目标车辆路径问题的基准实例上，该方法能够在短时间内产生良好的结果。

Conclusion: 该方法能够将最先进的多目标算法的有效性与目标规划的效率相结合，在实例具有相似适应度景观的问题场景中找到良好的折衷解决方案。

Abstract: Many real-world applications require decision-makers to assess the quality of
solutions while considering multiple conflicting objectives. Obtaining good
approximation sets for highly constrained many-objective problems is often a
difficult task even for modern multiobjective algorithms. In some cases,
multiple instances of the problem scenario present similarities in their
fitness landscapes. That is, there are recurring features in the fitness
landscapes when searching for solutions to different problem instances. We
propose a methodology to exploit this characteristic by solving one instance of
a given problem scenario using computationally expensive multiobjective
algorithms to obtain a good approximation set and then using Goal Programming
with efficient single-objective algorithms to solve other instances of the same
problem scenario. We use three goal-based objective functions and show that on
benchmark instances of the multiobjective vehicle routing problem with time
windows, the methodology is able to produce good results in short computation
time. The methodology allows to combine the effectiveness of state-of-the-art
multiobjective algorithms with the efficiency of goal programming to find good
compromise solutions in problem scenarios where instances have similar fitness
landscapes.

</details>


### [4] [LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models](https://arxiv.org/abs/2508.08300)
*Yongchao Huang*

Main category: cs.AI

TL;DR: 本文提出LLM-BI概念，探索使用大型语言模型（LLM）自动化贝叶斯推断中先验分布和似然函数规范的流程，并通过贝叶斯线性回归的实验验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯推断的广泛应用面临一个重要障碍，即先验分布和似然函数的指定通常需要专业的统计知识。

Method: 引入LLM-BI（大型语言模型驱动的贝叶斯推断）概念管道，并进行两项以贝叶斯线性回归为重点的实验：实验一验证LLM从自然语言中提取先验分布的能力；实验二验证LLM从高层问题描述中指定完整模型结构（包括先验和似然）的能力。

Result: 实验结果表明，LLM能成功从自然语言中提取先验分布，也能从单一高层描述中指定完整的贝叶斯模型结构（包括先验和似然）。

Conclusion: 研究验证了LLM在自动化贝叶斯建模关键步骤方面的潜力，为实现概率编程的自动化推断管道提供了可能性。

Abstract: A significant barrier to the widespread adoption of Bayesian inference is the
specification of prior distributions and likelihoods, which often requires
specialized statistical expertise. This paper investigates the feasibility of
using a Large Language Model (LLM) to automate this process. We introduce
LLM-BI (Large Language Model-driven Bayesian Inference), a conceptual pipeline
for automating Bayesian workflows. As a proof-of-concept, we present two
experiments focused on Bayesian linear regression. In Experiment I, we
demonstrate that an LLM can successfully elicit prior distributions from
natural language. In Experiment II, we show that an LLM can specify the entire
model structure, including both priors and the likelihood, from a single
high-level problem description. Our results validate the potential of LLMs to
automate key steps in Bayesian modeling, enabling the possibility of an
automated inference pipeline for probabilistic programming.

</details>


### [5] [First Ask Then Answer: A Framework Design for AI Dialogue Based on Supplementary Questioning with Large Language Models](https://arxiv.org/abs/2508.08308)
*Chuanruo Fu,Yuncheng Du*

Main category: cs.AI

TL;DR: 针对用户输入信息不完整的问题，本文提出FATA（First Ask Then Answer）交互范式，引导LLM先主动生成多维补充问题，再结合用户补充信息提供更准确和相关的回答。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在用户提供的信息不完整或不明确时，难以给出准确和可操作的答案。

Method: FATA范式通过提示词引导LLM在生成响应前主动生成多维度的补充问题，邀请用户提供额外信息。随后，通过复杂的提示技术将用户提供的补充信息与原始查询整合，以提高响应质量。FATA强调信息的完整性和用户参与，并采用单轮策略一次性生成所有澄清问题，以提高效率。

Result: 在构建的多领域基准测试中，FATA在综合指标上比基线提示（B-Prompt）高出约40%，并且比上下文增强的专家提示（C-Prompt）的变异系数低8%，表明其具有更优越的稳定性。

Conclusion: FATA利用LLM的推理能力来辅助用户表达，使非专业用户能够构建更全面和上下文相关的查询，从而显著提高了响应的质量和相关性。

Abstract: Large Language Models (LLMs) often struggle to deliver accurate and
actionable answers when user-provided information is incomplete or
ill-specified. We propose a new interaction paradigm, First Ask Then Answer
(FATA), in which, through prompt words, LLMs are guided to proactively generate
multidimensional supplementary questions for users prior to response
generation. Subsequently, by integrating user-provided supplementary
information with the original query through sophisticated prompting techniques,
we achieve substantially improved response quality and relevance. In contrast
to existing clarification approaches -- such as the CLAM framework oriented to
ambiguity and the self-interrogation Self-Ask method -- FATA emphasizes
completeness (beyond mere disambiguation) and user participation (inviting
human input instead of relying solely on model-internal reasoning). It also
adopts a single-turn strategy: all clarifying questions are produced at once,
thereby reducing dialogue length and improving efficiency. Conceptually, FATA
uses the reasoning power of LLMs to scaffold user expression, enabling
non-expert users to formulate more comprehensive and contextually relevant
queries. To evaluate FATA, we constructed a multi-domain benchmark and compared
it with two controls: a baseline prompt (B-Prompt) and a context-enhanced
expert prompt (C-Prompt). Experimental results show that FATA outperforms
B-Prompt by approximately 40% in aggregate metrics and exhibits a coefficient
of variation 8% lower than C-Prompt, indicating superior stability.

</details>


### [6] [What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge](https://arxiv.org/abs/2508.08344)
*Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Yuan He,Jiaoyan Chen,Evgeny Kharlamov,Steffen Staab*

Main category: cs.AI

TL;DR: 针对现有知识图谱增强检索生成（KG-RAG）评估的缺陷，本文提出新的基准构建方法和评估协议，发现当前KG-RAG方法在知识不完整条件下推理能力有限且依赖内部记忆。


<details>
  <summary>Details</summary>
Motivation: 当前的KG-RAG评估基准存在问题，例如问题可直接从知识图谱中检索答案，导致难以区分模型是进行推理还是直接检索；此外，评估指标不一致和宽松的答案匹配标准也阻碍了有意义的比较。

Method: 本文提出了一种通用的基准构建方法，并设计了一套评估协议，旨在系统地评估KG-RAG方法在知识不完整条件下的表现。

Result: 实证结果表明，当前的KG-RAG方法在知识缺失的情况下推理能力有限，通常依赖于模型的内部记忆，并且其泛化能力因设计不同而异。

Conclusion: 目前的KG-RAG方法在处理知识不完整时的推理能力有待提高，且易受内部记忆影响。需要更系统和严格的评估方法来推动该领域的发展。

Abstract: Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) is an
increasingly explored approach for combining the reasoning capabilities of
large language models with the structured evidence of knowledge graphs.
However, current evaluation practices fall short: existing benchmarks often
include questions that can be directly answered using existing triples in KG,
making it unclear whether models perform reasoning or simply retrieve answers
directly. Moreover, inconsistent evaluation metrics and lenient answer matching
criteria further obscure meaningful comparisons. In this work, we introduce a
general method for constructing benchmarks, together with an evaluation
protocol, to systematically assess KG-RAG methods under knowledge
incompleteness. Our empirical results show that current KG-RAG methods have
limited reasoning ability under missing knowledge, often rely on internal
memorization, and exhibit varying degrees of generalization depending on their
design.

</details>


### [7] [UrzaGPT: LoRA-Tuned Large Language Models for Card Selection in Collectible Card Games](https://arxiv.org/abs/2508.08382)
*Timo Bertram*

Main category: cs.AI

TL;DR: UrzaGPT是一个领域适应的大型语言模型，通过LoRA微调，能为《万智牌》提供实时选牌建议，证明了LLM在集换式卡牌游戏（CCG）选牌任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 集换式卡牌游戏（CCG）对AI而言极具挑战性，因为其部分可观察性、长期决策和不断变化的卡牌集导致当前AI在组牌和游戏玩法上远逊于人类玩家。

Method: 引入UrzaGPT，一个领域适应的大型语言模型。从一个开放权重的LLM开始，使用低秩适应（LoRA）在标注的选牌日志数据集上进行微调，以利用LLM的语言建模能力并快速适应游戏的不同扩展。

Result: 未经调优的小型LLM（如Llama-3-8B）完全无法选牌，而GPT-4o的零样本性能为43%。UrzaGPT通过微调小型模型，仅用10,000步就达到了66.2%的准确率。

Conclusion: 尽管UrzaGPT的性能尚未达到领域专用模型的水平，但研究表明单独使用LLM进行选牌是可行的，并预示LLM未来能实现高性能、通用且易于更新的选牌AI。

Abstract: Collectible card games (CCGs) are a difficult genre for AI due to their
partial observability, long-term decision-making, and evolving card sets. Due
to this, current AI models perform vastly worse than human players at CCG tasks
such as deckbuilding and gameplay. In this work, we introduce UrzaGPT, a
domain-adapted large language model that recommends real-time drafting
decisions in Magic: The Gathering. Starting from an open-weight LLM, we use
Low-Rank Adaptation fine-tuning on a dataset of annotated draft logs. With
this, we leverage the language modeling capabilities of LLM, and can quickly
adapt to different expansions of the game. We benchmark UrzaGPT in comparison
to zero-shot LLMs and the state-of-the-art domain-specific model. Untuned,
small LLMs like Llama-3-8B are completely unable to draft, but the larger
GPT-4o achieves a zero-shot performance of 43%. Using UrzaGPT to fine-tune
smaller models, we achieve an accuracy of 66.2% using only 10,000 steps.
Despite this not reaching the capability of domain-specific models, we show
that solely using LLMs to draft is possible and conclude that using LLMs can
enable performant, general, and update-friendly drafting AIs in the future.

</details>


### [8] [Bilevel MCTS for Amortized O(1) Node Selection in Classical Planning](https://arxiv.org/abs/2508.08385)
*Masataro Asai*

Main category: cs.AI

TL;DR: 针对经典规划中MCTS节点选择效率低的问题，提出了一种双层MCTS修改和树折叠技术，实现了摊销O(1)的节点选择时间，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: MCTS在经典规划中，节点选择的时间复杂度为$O(\log N)$，这大致对应于搜索深度$d$。在经典规划中，$d$可以非常大，导致节点选择成为显著的性能瓶颈，而在游戏树搜索中此开销则可忽略不计。

Method: 1. 提出MCTS的双层修改，从每个选定的叶节点开始运行一个最佳优先搜索，其扩展预算与深度$d$成比例，以实现摊销$O(1)$的节点选择运行时。2. 引入“树折叠”（Tree Collapsing）技术，以减少动作选择步骤并进一步提升性能。

Result: 成功实现了与传统队列式OPEN列表等效的摊销$O(1)$节点选择运行时。通过树折叠进一步提高了算法性能。

Conclusion: 所提出的双层MCTS修改和树折叠技术有效解决了经典规划中MCTS的节点选择瓶颈，显著提升了其效率。

Abstract: We study an efficient implementation of Multi-Armed Bandit (MAB)-based
Monte-Carlo Tree Search (MCTS) for classical planning. One weakness of MCTS is
that it spends a significant time deciding which node to expand next. While
selecting a node from an OPEN list with $N$ nodes has $O(1)$ runtime complexity
with traditional array-based priority-queues for dense integer keys, the
tree-based OPEN list used by MCTS requires $O(\log N)$, which roughly
corresponds to the search depth $d$. In classical planning, $d$ is arbitrarily
large (e.g., $2^k-1$ in $k$-disk Tower-of-Hanoi) and the runtime for node
selection is significant, unlike in game tree search, where the cost is
negligible compared to the node evaluation (rollouts) because $d$ is inherently
limited by the game (e.g., $d\leq 361$ in Go). To improve this bottleneck, we
propose a bilevel modification to MCTS that runs a best-first search from each
selected leaf node with an expansion budget proportional to $d$, which achieves
amortized $O(1)$ runtime for node selection, equivalent to the traditional
queue-based OPEN list. In addition, we introduce Tree Collapsing, an
enhancement that reduces action selection steps and further improves the
performance.

</details>


### [9] [Solver-Aided Expansion of Loops to Avoid Generate-and-Test](https://arxiv.org/abs/2508.08442)
*Niklas Dewally,Özgür Akgün*

Main category: cs.AI

TL;DR: 提出一种基于求解器的新方法，用于约束建模语言中循环展开，避免传统方法的全枚举低效问题，显著加速编译过程。


<details>
  <summary>Details</summary>
Motivation: 约束建模语言（如MiniZinc、Essence）在编译时需要展开循环，传统方法通过枚举所有归纳变量组合并部分求值来过滤，但当大多数组合不相关时，这种方法效率低下。

Method: 使用一个求解器来计算仅生成最终约束集所需的归纳变量组合，从而避免了完全枚举。

Result: 生成的结果模型与传统扁平化方法产生的模型相同，但编译速度显著加快。这在归纳变量范围大且存在选择性前置条件的问题中尤为有效。

Conclusion: 该方法提高了将高级用户模型转换为求解器可读形式的效率，特别适用于归纳变量域大且有选择性先决条件的问题。

Abstract: Constraint modelling languages like MiniZinc and Essence rely on unrolling
loops (in the form of quantified expressions and comprehensions) during
compilation. Standard approaches generate all combinations of induction
variables and use partial evaluation to discard those that simplify to identity
elements of associative-commutative operators (e.g. true for conjunction, 0 for
summation). This can be inefficient for problems where most combinations are
ultimately irrelevant. We present a method that avoids full enumeration by
using a solver to compute only the combinations required to generate the final
set of constraints. The resulting model is identical to that produced by
conventional flattening, but compilation can be significantly faster. This
improves the efficiency of translating high-level user models into solver-ready
form, particularly when induction variables range over large domains with
selective preconditions.

</details>


### [10] [OverFill: Two-Stage Models for Efficient Language Model Decoding](https://arxiv.org/abs/2508.08446)
*Woojeong Kim,Junxiong Wang,Jing Nathan Yan,Mohamed Abdelfattah,Alexander M. Rush*

Main category: cs.AI

TL;DR: OverFill通过解耦大型语言模型（LLM）的预填充和解码阶段，分别使用完整模型和剪枝模型，显著提高了推理效率和生成质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型推理成本高昂，特别是解码阶段在长序列中占主导地位。当前模型对计算特性不同的预填充和解码阶段采用统一处理，导致效率低下。

Method: OverFill将预填充（计算密集型）和解码（内存密集型）阶段解耦。预填充阶段使用完整模型并行处理输入，然后切换到密集剪枝模型进行顺序令牌生成。通过在预填充阶段投入更多计算资源，优化了准确性-效率权衡。

Result: OverFill在生成质量上有所提升，且延迟开销极小。3B-to-1B配置比1B剪枝模型性能提高83.2%；8B-to-3B配置比3B剪枝模型平均提高79.2%。它能匹配相同大小从头训练的模型性能，同时显著减少训练数据。

Conclusion: OverFill通过对LLM推理阶段的优化处理，提供了一种有效提升生成质量和效率的方法，显著优于传统的剪枝模型，并能与从头训练的模型性能媲美。

Abstract: Large language models (LLMs) excel across diverse tasks but face significant
deployment challenges due to high inference costs. LLM inference comprises
prefill (compute-bound) and decode (memory-bound) stages, with decode
dominating latency particularly for long sequences. Current decoder-only models
handle both stages uniformly, despite their distinct computational profiles. We
propose OverFill, which decouples these stages to optimize accuracy-efficiency
tradeoffs. OverFill begins with a full model for prefill, processing system and
user inputs in parallel. It then switches to a dense pruned model, while
generating tokens sequentially. Leveraging more compute during prefill,
OverFill improves generation quality with minimal latency overhead. Our
3B-to-1B OverFill configuration outperforms 1B pruned models by 83.2%, while
the 8B-to-3B configuration improves over 3B pruned models by 79.2% on average
across standard benchmarks. OverFill matches the performance of same-sized
models trained from scratch, while using significantly less training data. Our
code is available at https://github.com/friendshipkim/overfill.

</details>


### [11] [A Fast GRASP Metaheuristic for the Trigger Arc TSP with MIP-Based Construction and Multi-Neighborhood Local Search](https://arxiv.org/abs/2508.08477)
*Joan Salvà Soler,Grégoire de Lambertye*

Main category: cs.AI

TL;DR: 该论文提出了一个基于GRASP的元启发式算法，用于解决触发弧旅行商问题（TA-TSP），该问题引入了随触发弧遍历而变化的动态弧成本。该算法在MESS 2024竞赛中表现出色，证明了其在具有状态依赖旅行成本的实时路径规划应用中的适用性。


<details>
  <summary>Details</summary>
Motivation: 经典的旅行商问题（TSP）无法模拟某些现实场景，例如仓库操作中可压缩存储系统导致的动态弧成本变化。触发弧旅行商问题（TA-TSP）旨在解决这一限制，即当特定“触发”弧被遍历时，其他弧的成本会发生变化。

Method: 该研究引入了一个基于GRASP的元启发式算法。构建阶段利用混合整数规划（MIP）技术将TA-TSP转换为一系列定制的TSP实例。改进阶段应用了2-Opt、Swap和Relocate等邻域搜索操作。

Result: 在MESS 2024竞赛实例上，该算法在60秒限制内相对于已知最优解取得了0.77%和0.40%的平均最优性差距。在较小的合成数据集上，该方法在相同时间限制下比Gurobi求解器生成了11.3%更好的解决方案。该算法在MESS 2024竞赛中位列前三名。

Conclusion: 该算法在MESS 2024竞赛中的优异表现证明了其在具有状态依赖旅行成本的实时路径规划应用中的适用性。

Abstract: The Trigger Arc Traveling Salesman Problem (TA-TSP) extends the classical TSP
by introducing dynamic arc costs that change when specific \textit{trigger}
arcs are traversed, modeling scenarios such as warehouse operations with
compactable storage systems. This paper introduces a GRASP-based metaheuristic
that combines multiple construction heuristics with a multi-neighborhood local
search. The construction phase uses mixed-integer programming (MIP) techniques
to transform the TA-TSP into a sequence of tailored TSP instances, while the
improvement phase applies 2-Opt, Swap, and Relocate operators. Computational
experiments on MESS 2024 competition instances achieved average optimality gaps
of 0.77\% and 0.40\% relative to the best-known solutions within a 60-second
limit. On smaller, synthetically generated datasets, the method produced
solutions 11.3\% better than the Gurobi solver under the same time constraints.
The algorithm finished in the top three at MESS 2024, demonstrating its
suitability for real-time routing applications with state-dependent travel
costs.

</details>


### [12] [Beyond Ordinal Preferences: Why Alignment Needs Cardinal Human Feedback](https://arxiv.org/abs/2508.08486)
*Parker Whitfill,Stewy Slocum*

Main category: cs.AI

TL;DR: 现有LLM对齐技术依赖的序数偏好数据存在根本性局限，无法系统性找到最优模型。本研究证明了这一点，并提出需要基数偏好数据，通过收集基数判断数据集并将其融入微调，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: LLM对齐技术通常依赖二元选择的序数偏好数据，但这种数据在解决权衡问题时信息不足，无法系统地识别和恢复最受偏爱的模型。研究旨在解决这一根本性限制。

Method: 1. 证明了仅依赖序数比较的算法无法系统性恢复最受偏爱模型的“不可能结果”。2. 提出选择最优模型需要恢复对“模型”的偏好，这需要关于响应质量的基数反馈。3. 收集并公开发布了一个包含25,000个基数判断的数据集，使用实验经济学中成熟的“支付意愿”方法。4. 将基数反馈整合到偏好微调中。

Result: 1. 理论上证明了序数数据在LLM对齐中的局限性。2. 经验发现，将基数反馈纳入偏好微调后，模型能够优先考虑高影响力的改进。3. 使用基数反馈的模型在Arena-Hard等下游基准测试中，性能优于仅使用序数方法训练的模型。

Conclusion: 传统的LLM对齐方法因仅依赖序数偏好数据而存在根本性缺陷。基数偏好数据对于识别最优模型和解决对齐中的权衡至关重要。整合基数反馈能显著提升模型性能，是未来LLM对齐研究的关键方向。

Abstract: Alignment techniques for LLMs rely on optimizing preference-based objectives
-- where these preferences are typically elicited as ordinal, binary choices
between responses. Recent work has focused on improving label quality or
mitigating particular biases, but we identify a more fundamental limitation:
these methods collect the wrong kind of data. We prove an impossibility result:
no algorithm relying solely on ordinal comparisons can systematically recover
the most preferred model. Intuitively, ordinal data lacks the information
needed to resolve tradeoffs -- e.g., fixing a factual error on one prompt
versus improving style on another. We show that selecting the optimal model
requires recovering preferences over \emph{models} (rather than just
responses), which can only be identified given cardinal feedback about response
quality. To address this, we collect and publicly release a dataset of 25,000
cardinal judgments using willingness-to-pay elicitations, a well-established
tool from experimental economics. Empirically, we find that incorporating
cardinal feedback into preference fine-tuning allows models to prioritize
high-impact improvements and outperform ordinal-only methods on downstream
benchmarks, such as Arena-Hard.

</details>


### [13] [POMO+: Leveraging starting nodes in POMO for solving Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2508.08493)
*Szymon Jakubicz,Karol Kuźniak,Jan Wawszczak,Paweł Gora*

Main category: cs.AI

TL;DR: 本文提出POMO+，通过利用初始节点信息改进了强化学习模型POMO，使其在组合优化问题（如VRP）上收敛更快并取得更好结果。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）方法在解决组合问题方面表现出潜力，特别是POMO模型在VRP等任务上性能突出，但仍有改进空间。

Method: 在POMO模型的基础上进行改进，创建了POMO+方法。该方法通过更智能地利用初始节点信息来寻找解决方案。

Result: 实验结果表明，POMO+解决方案收敛速度更快，并取得了更好的结果。在CVRPLIB数据集上对多达100个客户的问题实例进行了验证，并观察到性能提升。

Conclusion: 该研究希望能够推动强化学习在组合优化领域的进一步发展。

Abstract: In recent years, reinforcement learning (RL) methods have emerged as a
promising approach for solving combinatorial problems. Among RL-based models,
POMO has demonstrated strong performance on a variety of tasks, including
variants of the Vehicle Routing Problem (VRP). However, there is room for
improvement for these tasks. In this work, we improved POMO, creating a method
(\textbf{POMO+}) that leverages the initial nodes to find a solution in a more
informed way. We ran experiments on our new model and observed that our
solution converges faster and achieves better results. We validated our models
on the CVRPLIB dataset and noticed improvements in problem instances with up to
100 customers. We hope that our research in this project can lead to further
advancements in the field.

</details>


### [14] [Large Language Models as Oracles for Ontology Alignment](https://arxiv.org/abs/2508.08500)
*Sviatoslav Lushnei,Dmytro Shumskyi,Severyn Shykula,Ernesto Jimenez-Ruiz,Artur d'Avila Garcez*

Main category: cs.AI

TL;DR: 本体对齐中，大型语言模型（LLM）被探索用于验证不确定的对应关系，以替代昂贵的人类专家。研究在OAEI任务上评估了不同LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 现有本体对齐系统难以产生高质量的对应关系。人工参与虽然能确保高精度，但对于大型本体而言成本高昂。因此，需要寻找一种经济高效的替代方案来验证本体对齐结果。

Method: 本研究利用LLM来验证本体对齐系统高度不确定的对应关系子集。通过在本体对齐评估倡议（OAEI）的多个匹配任务上，使用不同的本体驱动提示模板，对多种最先进的LLM进行了广泛评估，并将其性能与具有可变错误率的模拟Oracle进行了比较。

Result: （论文）分析了多种最先进LLM在OAEI任务上的性能，并将其与模拟Oracle的性能进行了比较，以评估LLM作为领域专家替代方案在验证不确定本体对齐方面的可行性。

Conclusion: （论文将得出）大型语言模型作为领域专家替代方案，在本体对齐过程中验证不确定对应关系方面是可行的。

Abstract: Ontology alignment plays a crucial role in integrating diverse data sources
across domains. There is a large plethora of systems that tackle the ontology
alignment problem, yet challenges persist in producing highly quality
correspondences among a set of input ontologies. Human-in-the-loop during the
alignment process is essential in applications requiring very accurate
mappings. User involvement is, however, expensive when dealing with large
ontologies. In this paper, we explore the feasibility of using Large Language
Models (LLM) as an alternative to the domain expert. The use of the LLM focuses
only on the validation of the subset of correspondences where an ontology
alignment system is very uncertain. We have conducted an extensive evaluation
over several matching tasks of the Ontology Alignment Evaluation Initiative
(OAEI), analysing the performance of several state-of-the-art LLMs using
different ontology-driven prompt templates. The LLM results are also compared
against simulated Oracles with variable error rates.

</details>


### [15] [GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games](https://arxiv.org/abs/2508.08501)
*Yuchen Li,Cong Lin,Muhammad Umair Nasir,Philip Bontrager,Jialin Liu,Julian Togelius*

Main category: cs.AI

TL;DR: GVGAI-LLM是一个用于评估大型语言模型（LLM）推理和问题解决能力的视频游戏基准。它包含多样化的街机风格游戏，通过ASCII字符表示场景，并定义可解释的评估指标。零样本评估显示LLM在空间推理和基本规划方面存在持续限制，尽管结构化提示和空间接地技术有所改善，但问题远未解决。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准测试未能充分评估LLM在处理与众不同任务时的推理和问题解决能力，尤其是在需要代理行为和上下文推理的动态游戏环境中。因此，需要一个能测试这些能力的基准。

Method: 引入GVGAI-LLM，基于通用视频游戏AI框架构建，包含多样化的街机风格游戏。利用游戏描述语言快速创建新游戏和关卡，防止过拟合。游戏场景通过紧凑的ASCII字符集表示。定义了可解释的评估指标，包括有意义步数比、步数效率和总分。通过零样本评估，测试了LLM在各种游戏和关卡中的表现。尝试了结构化提示和空间接地技术来改善模型行为。

Result: LLM在空间推理和基本规划方面表现出持续的局限性。当前模型经常出现空间和逻辑错误。虽然结构化提示和空间接地技术能带来部分改进，但基准测试离“解决”还很远。

Conclusion: GVGAI-LLM提供了一个可复现的测试平台，用于推进语言模型能力的研究，特别是关注代理行为和上下文推理。研究结果揭示了当前LLM在处理复杂游戏环境中的空间推理和规划任务时的显著不足。

Abstract: We introduce GVGAI-LLM, a video game benchmark for evaluating the reasoning
and problem-solving capabilities of large language models (LLMs). Built on the
General Video Game AI framework, it features a diverse collection of
arcade-style games designed to test a model's ability to handle tasks that
differ from most existing LLM benchmarks. The benchmark leverages a game
description language that enables rapid creation of new games and levels,
helping to prevent overfitting over time. Each game scene is represented by a
compact set of ASCII characters, allowing for efficient processing by language
models. GVGAI-LLM defines interpretable metrics, including the meaningful step
ratio, step efficiency, and overall score, to assess model behavior. Through
zero-shot evaluations across a broad set of games and levels with diverse
challenges and skill depth, we reveal persistent limitations of LLMs in spatial
reasoning and basic planning. Current models consistently exhibit spatial and
logical errors, motivating structured prompting and spatial grounding
techniques. While these interventions lead to partial improvements, the
benchmark remains very far from solved. GVGAI-LLM provides a reproducible
testbed for advancing research on language model capabilities, with a
particular emphasis on agentic behavior and contextual reasoning.

</details>


### [16] [SynLLM: A Comparative Analysis of Large Language Models for Medical Tabular Synthetic Data Generation via Prompt Engineering](https://arxiv.org/abs/2508.08529)
*Arshia Ilaty,Hossein Shirazi,Hajar Homayouni*

Main category: cs.AI

TL;DR: SynLLM是一个模块化框架，利用20种开源大型语言模型（LLMs）和结构化提示，生成高质量、临床有效且隐私保护的合成医疗表格数据，并通过多维度评估验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于隐私法规限制，真实医疗数据难以获取，阻碍了医疗研究进展。合成数据是替代方案，但生成真实、临床有效且隐私保护的数据仍是挑战。现有LLM生成结构化数据的方法缺乏系统性提示策略和全面的多维度评估框架。

Method: 本文提出了SynLLM框架，使用20种SOTA开源LLMs（如LLaMA, Mistral, GPT变体）生成合成医疗表格数据。通过四种结构化提示类型（从示例驱动到基于规则的约束）引导LLM生成，这些提示编码了数据模式、元数据和领域知识，无需模型微调。框架包含全面的评估流程，严格评估生成数据的统计保真度、临床一致性和隐私保护。

Result: 在糖尿病、肝硬化和中风三个公共医疗数据集上，使用20种开源LLM进行评估。结果表明，提示工程显著影响数据质量和隐私风险，其中基于规则的提示实现了最佳的隐私-质量平衡。SynLLM证明，在精心设计的提示和鲁棒的多指标评估指导下，LLMs可以生成既临床合理又注重隐私的合成医疗数据。

Conclusion: SynLLM框架证明了LLMs在生成高质量、隐私保护的合成医疗数据方面的潜力，为医疗研究中更安全、更有效的数据共享铺平了道路。

Abstract: Access to real-world medical data is often restricted due to privacy
regulations, posing a significant barrier to the advancement of healthcare
research. Synthetic data offers a promising alternative; however, generating
realistic, clinically valid, and privacy-conscious records remains a major
challenge. Recent advancements in Large Language Models (LLMs) offer new
opportunities for structured data generation; however, existing approaches
frequently lack systematic prompting strategies and comprehensive,
multi-dimensional evaluation frameworks.
  In this paper, we present SynLLM, a modular framework for generating
high-quality synthetic medical tabular data using 20 state-of-the-art
open-source LLMs, including LLaMA, Mistral, and GPT variants, guided by
structured prompts. We propose four distinct prompt types, ranging from
example-driven to rule-based constraints, that encode schema, metadata, and
domain knowledge to control generation without model fine-tuning. Our framework
features a comprehensive evaluation pipeline that rigorously assesses generated
data across statistical fidelity, clinical consistency, and privacy
preservation.
  We evaluate SynLLM across three public medical datasets, including Diabetes,
Cirrhosis, and Stroke, using 20 open-source LLMs. Our results show that prompt
engineering significantly impacts data quality and privacy risk, with
rule-based prompts achieving the best privacy-quality balance. SynLLM
establishes that, when guided by well-designed prompts and evaluated with
robust, multi-metric criteria, LLMs can generate synthetic medical data that is
both clinically plausible and privacy-aware, paving the way for safer and more
effective data sharing in healthcare research.

</details>


### [17] [UGM2N: An Unsupervised and Generalizable Mesh Movement Network via M-Uniform Loss](https://arxiv.org/abs/2508.08615)
*Zhichao Wang,Xinhai Chen,Qinglin Wang,Xiang Gao,Qingyang Zhang,Menghan Jia,Xiang Zhang,Jie Liu*

Main category: cs.AI

TL;DR: 本文提出了一种无监督且可泛化的网格移动网络（UGM2N），通过局部几何特征学习和物理约束损失，实现了对不同偏微分方程和网格拓扑的高效、精确且无缠结的自适应网格划分。


<details>
  <summary>Details</summary>
Motivation: 偏微分方程（PDEs）的数值解需要平衡精度和效率。传统的网格移动技术计算复杂且几何不灵活，而现有的监督学习方法在零样本泛化方面存在挑战，限制了它们在多样PDEs和网格拓扑上的应用。

Method: UGM2N通过以下两点实现无监督网格自适应：1. 引入无监督网格自适应，通过局部几何特征学习消除对预适应网格的依赖。2. 开发了一种物理约束损失函数——M-Uniform损失，用于在节点层面强制执行网格均匀分布。

Result: 实验结果表明，所提出的网络在高效网格自适应方面表现出方程无关的泛化能力和几何独立性。它持续优于现有方法，包括在不同PDEs和网格几何形状上的鲁棒性能、对多尺度分辨率的可扩展性以及保证误差减少而不会出现网格缠结。

Conclusion: UGM2N提供了一种有效、可泛化且鲁棒的网格自适应解决方案，能够克服传统和监督学习方法的局限性，在科学与工程领域的PDEs数值模拟中具有重要应用价值。

Abstract: Partial differential equations (PDEs) form the mathematical foundation for
modeling physical systems in science and engineering, where numerical solutions
demand rigorous accuracy-efficiency tradeoffs. Mesh movement techniques address
this challenge by dynamically relocating mesh nodes to rapidly-varying regions,
enhancing both simulation accuracy and computational efficiency. However,
traditional approaches suffer from high computational complexity and geometric
inflexibility, limiting their applicability, and existing supervised
learning-based approaches face challenges in zero-shot generalization across
diverse PDEs and mesh topologies.In this paper, we present an Unsupervised and
Generalizable Mesh Movement Network (UGM2N). We first introduce unsupervised
mesh adaptation through localized geometric feature learning, eliminating the
dependency on pre-adapted meshes. We then develop a physics-constrained loss
function, M-Uniform loss, that enforces mesh equidistribution at the nodal
level.Experimental results demonstrate that the proposed network exhibits
equation-agnostic generalization and geometric independence in efficient mesh
adaptation. It demonstrates consistent superiority over existing methods,
including robust performance across diverse PDEs and mesh geometries,
scalability to multi-scale resolutions and guaranteed error reduction without
mesh tangling.

</details>


### [18] [AgriGPT: a Large Language Model Ecosystem for Agriculture](https://arxiv.org/abs/2508.08632)
*Bo Yang,Yu Zhang,Lanfei Feng,Yunkui Chen,Jianyu Zhang,Xiao Xu,Nueraili Aierken,Yurui Li,Yuxuan Chen,Guijun Yang,Yong He,Runhe Huang,Shijian Li*

Main category: cs.AI

TL;DR: AgriGPT是一个农业领域的专业大语言模型生态系统，通过构建高质量数据集、采用多通道检索增强生成框架和设计综合评估基准，显著提升了LLMs在农业领域的表现，并提供了一个可推广的专业LLM开发框架。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）发展迅速，但由于缺乏领域专用模型、精选数据集和稳健的评估框架，它们在农业领域的应用仍然有限。

Method: 核心方法包括：1. 设计了一个多智能体可扩展数据引擎，系统性地将可信数据源编译成高质量、标准化的问答数据集Agri-342K。2. 采用Tri-RAG（三通道检索增强生成）框架，结合密集检索、稀疏检索和多跳知识图谱推理，以增强事实依据和推理可靠性。3. 引入了AgriBench-13K，一个包含13个不同类型和复杂度的任务的基准套件，用于全面评估。

Result: 实验证明，AgriGPT在领域适应性和推理能力方面显著优于通用大语言模型。它代表了一个模块化和可扩展的农业LLM生态系统，包括结构化数据构建、检索增强生成和领域特定评估。

Conclusion: AgriGPT为农业领域提供了一个强大的专业LLM解决方案，并通过其结构化数据构建、检索增强生成和领域特定评估，提供了一个可推广的开发科学和行业专业LLM的框架。所有模型、数据集和代码都将发布，以赋能农业社区并促进开放、有影响力的研究。

Abstract: Despite the rapid progress of Large Language Models (LLMs), their application
in agriculture remains limited due to the lack of domain-specific models,
curated datasets, and robust evaluation frameworks. To address these
challenges, we propose AgriGPT, a domain-specialized LLM ecosystem for
agricultural usage. At its core, we design a multi-agent scalable data engine
that systematically compiles credible data sources into Agri-342K, a
high-quality, standardized question-answer (QA) dataset. Trained on this
dataset, AgriGPT supports a broad range of agricultural stakeholders, from
practitioners to policy-makers. To enhance factual grounding, we employ
Tri-RAG, a three-channel Retrieval-Augmented Generation framework combining
dense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning,
thereby improving the LLM's reasoning reliability. For comprehensive
evaluation, we introduce AgriBench-13K, a benchmark suite comprising 13 tasks
with varying types and complexities. Experiments demonstrate that AgriGPT
significantly outperforms general-purpose LLMs on both domain adaptation and
reasoning. Beyond the model itself, AgriGPT represents a modular and extensible
LLM ecosystem for agriculture, comprising structured data construction,
retrieval-enhanced generation, and domain-specific evaluation. This work
provides a generalizable framework for developing scientific and
industry-specialized LLMs. All models, datasets, and code will be released to
empower agricultural communities, especially in underserved regions, and to
promote open, impactful research.

</details>


### [19] [Diminution: On Reducing the Size of Grounding ASP Programs](https://arxiv.org/abs/2508.08633)
*HuanYu Yang,Fengming Zhu,YangFan Wu,Jianmin Ji*

Main category: cs.AI

TL;DR: 本文提出“缩减”（diminution）概念，通过选择Herbrand域的子集来生成更小的接地程序，从而显著缓解ASP中的接地瓶颈，提升性能。


<details>
  <summary>Details</summary>
Motivation: ASP（Answer Set Programming）常受制于接地瓶颈，即大型Herbrand域生成过大的接地程序，导致求解困难。现有方法多依赖特设启发式，缺乏形式化和通用策略。

Method: 引入“缩减”（diminution）概念，定义为Herbrand域的选定子集，用于生成缩减的接地程序。形式化定义了缩减，分析了其关键性质，并研究了识别缩减的复杂性。使用特定编码，使现成的ASP求解器能够评估候选子集，并通过域谓词与现有接地器无缝集成。

Result: 在五个基准测试中，应用该策略选择的缩减带来了显著的性能提升，平均接地时间减少高达70%，接地文件大小减少高达85%。

Conclusion: 利用缩减是缓解ASP中接地瓶颈的一种鲁棒且通用的方法。

Abstract: Answer Set Programming (ASP) is often hindered by the grounding bottleneck:
large Herbrand universes generate ground programs so large that solving becomes
difficult. Many methods employ ad-hoc heuristics to improve grounding
performance, motivating the need for a more formal and generalizable strategy.
We introduce the notion of diminution, defined as a selected subset of the
Herbrand universe used to generate a reduced ground program before solving. We
give a formal definition of diminution, analyze its key properties, and study
the complexity of identifying it. We use a specific encoding that enables
off-the-shelf ASP solver to evaluate candidate subsets. Our approach integrates
seamlessly with existing grounders via domain predicates. In extensive
experiments on five benchmarks, applying diminutions selected by our strategy
yields significant performance improvements, reducing grounding time by up to
70% on average and decreasing the size of grounding files by up to 85%. These
results demonstrate that leveraging diminutions constitutes a robust and
general-purpose approach for alleviating the grounding bottleneck in ASP.

</details>


### [20] [P-CAFE: Personalized Cost-Aware Incremental Feature Selection For Electronic Health Records](https://arxiv.org/abs/2508.08646)
*Naama Kashani,Mira Cohen,Uri Shaham*

Main category: cs.AI

TL;DR: 针对电子健康记录（EHR）数据的挑战，本文提出一种新型个性化、在线、成本感知的特征选择框架，旨在辅助医生决策并优化资源利用。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）数据复杂且多模态，传统特征选择方法难以处理其固有的稀疏性、异构性、患者特异性变异及临床应用中的特征成本，导致从EHR中提取有意义的洞察面临重大挑战。

Method: 本文提出一个新颖的个性化、在线且成本感知的特征选择框架，专门为EHR数据集量身定制。该框架以在线方式为个体患者获取特征，并整合预算限制和特征可变成本，旨在有效管理稀疏和多模态数据。

Result: 该框架能够确保在多样化医疗环境中实现稳健和可扩展的性能。通过在预算约束内指导医生逐步获取最具信息量的特征，旨在提高诊断信心并优化资源利用。

Conclusion: 所提出的方法主要应用于支持医生在患者筛查场景中的决策，通过优化特征获取过程来提升诊断效率和资源利用率。

Abstract: Electronic Health Records (EHR) have revolutionized healthcare by digitizing
patient data, improving accessibility, and streamlining clinical workflows.
However, extracting meaningful insights from these complex and multimodal
datasets remains a significant challenge for researchers. Traditional feature
selection methods often struggle with the inherent sparsity and heterogeneity
of EHR data, especially when accounting for patient-specific variations and
feature costs in clinical applications. To address these challenges, we propose
a novel personalized, online and cost-aware feature selection framework
tailored specifically for EHR datasets. The features are aquired in an online
fashion for individual patients, incorporating budgetary constraints and
feature variability costs. The framework is designed to effectively manage
sparse and multimodal data, ensuring robust and scalable performance in diverse
healthcare contexts. A primary application of our proposed method is to support
physicians' decision making in patient screening scenarios. By guiding
physicians toward incremental acquisition of the most informative features
within budget constraints, our approach aims to increase diagnostic confidence
while optimizing resource utilization.

</details>


### [21] [Prompt-and-Check: Using Large Language Models to Evaluate Communication Protocol Compliance in Simulation-Based Training](https://arxiv.org/abs/2508.08652)
*Vishakha Lall,Yisi Liu*

Main category: cs.AI

TL;DR: 本文提出了一种名为“Prompt-and-Check”的轻量级方法，利用开源大语言模型（LLMs）通过提示推理来评估模拟训练中程序性沟通的合规性，特别是在安全关键领域。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域的模拟训练中，准确评估程序性沟通合规性至关重要，因为这反映了操作能力。现有评估可能效率不高或需要大量资源。

Method: 该方法使用基于提示的推理，结合开源LLMs（如LLaMA 2 7B、LLaMA 3 8B和Mistral 7B），可在消费级GPU上高效运行。通过向模型输入包含相关对话摘录的上下文丰富提示，评估每个清单项是否已完成。研究在海事领域的模拟任务中进行了案例研究，并使用分类准确性和一致性分数评估模型输出与专家标注的真实情况。

Result: 研究结果表明，提示方法无需进行特定任务训练，即可实现有效的上下文感知推理。这突显了LLMs在增强训练环境中的汇报、绩效反馈和自动化评估方面的实用性。

Conclusion: 大语言模型（LLMs）提供了一种实用且轻量级的方法，可以有效地自动化评估模拟训练中程序性沟通的合规性，从而增强训练效果和反馈机制。

Abstract: Accurate evaluation of procedural communication compliance is essential in
simulation-based training, particularly in safety-critical domains where
adherence to compliance checklists reflects operational competence. This paper
explores a lightweight, deployable approach using prompt-based inference with
open-source large language models (LLMs) that can run efficiently on
consumer-grade GPUs. We present Prompt-and-Check, a method that uses
context-rich prompts to evaluate whether each checklist item in a protocol has
been fulfilled, solely based on transcribed verbal exchanges. We perform a case
study in the maritime domain with participants performing an identical
simulation task, and experiment with models such as LLama 2 7B, LLaMA 3 8B and
Mistral 7B, running locally on an RTX 4070 GPU. For each checklist item, a
prompt incorporating relevant transcript excerpts is fed into the model, which
outputs a compliance judgment. We assess model outputs against expert-annotated
ground truth using classification accuracy and agreement scores. Our findings
demonstrate that prompting enables effective context-aware reasoning without
task-specific training. This study highlights the practical utility of LLMs in
augmenting debriefing, performance feedback, and automated assessment in
training environments.

</details>


### [22] [Hybrid Node-Destroyer Model with Large Neighborhood Search for Solving the Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2508.08659)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux,Daniele Vigo*

Main category: cs.AI

TL;DR: 本研究提出一种迭代学习混合优化器，通过结合图神经网络（GNN）和大规模邻域搜索（LNS），增强元启发式算法解决带容量车辆路径问题（CVRP）的性能。该方法提高了求解质量，并能扩展到大规模问题实例。


<details>
  <summary>Details</summary>
Motivation: 旨在提升元启发式算法在解决带容量车辆路径问题（CVRP）时的性能，以获得更高质量的解决方案和更好的可扩展性。

Method: 提出了一种迭代学习混合优化器，其核心是“节点销毁器模型”（Node-Destroyer Model）。该模型利用图神经网络（GNN）识别和选择客户节点，以指导元启发式框架中的大规模邻域搜索（LNS）操作。该方法利用问题和解的图结构属性来指导节点移除，从而降低操作复杂性并缩小搜索空间。该混合方法专用于CVRP，且无需针对不同规模的实例进行重新训练。

Result: 所提出的混合机制能够显著提升基线元启发式算法的性能。实验结果表明，该方法不仅提高了标准CVRP基准测试的解质量，还在高达30,000个客户节点的大规模实例上展现出良好的可扩展性。在相似设置下，该机制能够改进不同的基线算法，获得更高质量的解决方案。

Conclusion: 所提出的混合机制有效提升了元启发式算法在解决CVRP时的性能，在提高解质量和处理大规模实例的可扩展性方面均表现出色，证明了其对不同基线算法的通用性和优越性。

Abstract: In this research, we propose an iterative learning hybrid optimization solver
developed to strengthen the performance of metaheuristic algorithms in solving
the Capacitated Vehicle Routing Problem (CVRP). The iterative hybrid mechanism
integrates the proposed Node-Destroyer Model, a machine learning hybrid model
that utilized Graph Neural Networks (GNNs) such identifies and selects customer
nodes to guide the Large Neighborhood Search (LNS) operator within the
metaheuristic optimization frameworks. This model leverages the structural
properties of the problem and solution that can be represented as a graph, to
guide strategic selections concerning node removal. The proposed approach
reduces operational complexity and scales down the search space involved in the
optimization process. The hybrid approach is applied specifically to the CVRP
and does not require retraining across problem instances of different sizes.
The proposed hybrid mechanism is able to improve the performance of baseline
metaheuristic algorithms. Our approach not only enhances the solution quality
for standard CVRP benchmarks but also proves scalability on very large-scale
instances with up to 30,000 customer nodes. Experimental evaluations on
benchmark datasets show that the proposed hybrid mechanism is capable of
improving different baseline algorithms, achieving better quality of solutions
under similar settings.

</details>


### [23] [Aryabhata: An exam-focused language model for JEE Math](https://arxiv.org/abs/2508.08665)
*Ritvik Rastogi,Sachin Dharashivkar,Sandeep Varma*

Main category: cs.AI

TL;DR: Aryabhata 1.0是一个7B参数的数学推理模型，针对印度JEE考试优化，通过合并模型、课程学习SFT和RLVR训练，在准确性和效率上超越现有模型，并提供教学有用的分步推理。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）发展迅速，但现有模型通常不适合教育用途，特别是在应对印度JEE等特定学术考试时。因此，需要一个专门为教育场景优化、高效且能提供教学辅助的数学推理模型。

Method: 该模型通过合并强大的开源推理模型构建，然后使用课程学习进行监督微调（SFT），微调数据是经过最佳n拒绝采样验证的思维链（CoT）轨迹。为进一步提升性能，模型还应用了可验证奖励强化学习（RLVR），使用A2C目标函数、组相对优势估计，以及自适应组大小调整和温度缩放等新颖探索策略。

Result: Aryabhata 1.0在分布内（JEE Main 2025）和分布外（MATH、GSM8K）基准测试中，在准确性和效率上均优于现有模型，同时提供了具有教学价值的逐步推理过程。

Conclusion: Aryabhata 1.0作为一款基础模型发布，旨在推动以考试为中心的开源小型语言模型的发展，并期望通过未来的模型训练进一步改善学生的学习成果。

Abstract: We present Aryabhata 1.0, a compact 7B parameter math reasoning model
optimized for the Indian academic exam, the Joint Entrance Examination (JEE).
Despite rapid progress in large language models (LLMs), current models often
remain unsuitable for educational use. Aryabhata 1.0 is built by merging strong
open-weight reasoning models, followed by supervised fine-tuning (SFT) with
curriculum learning on verified chain-of-thought (CoT) traces curated through
best-of-$n$ rejection sampling. To further boost performance, we apply
reinforcement learning with verifiable rewards (RLVR) using A2C objective with
group-relative advantage estimation along with novel exploration strategies
such as Adaptive Group Resizing and Temperature Scaling. Evaluated on both
in-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K)
benchmarks, Aryabhata outperforms existing models in accuracy and efficiency,
while offering pedagogically useful step-by-step reasoning. We release
Aryabhata as a foundation model to advance exam-centric, open-source small
language models. This marks our first open release for community feedback
(https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0); PW is actively training
future models to further improve learning outcomes for students.

</details>


### [24] [STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision](https://arxiv.org/abs/2508.08688)
*Chen Li,Han Zhang,Zhantao Yang,Fangyi Chen,Zihan Wang,Anudeepsekhar Bolimera,Marios Savvides*

Main category: cs.AI

TL;DR: STELAR-Vision是一个拓扑感知推理的视觉语言模型训练框架，通过TopoAug生成多样拓扑结构数据，并结合监督微调和强化学习，解决了现有VLM在复杂任务中推理能力不足和输出冗长的问题，显著提升了准确性和泛化能力，同时通过Frugal Learning减少了输出长度。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在复杂多模态任务中表现不佳，且倾向于生成冗长的输出。其主要限制在于过度依赖链式思维（CoT）推理，而许多任务实际上更适合树状或图状等其他拓扑结构。

Method: 引入STELAR-Vision训练框架，核心是TopoAug合成数据管道，用于生成具有多样拓扑结构（如树、图）的训练数据。通过监督微调（supervised fine-tuning）和强化学习（reinforcement learning）对Qwen2VL模型进行后训练，以兼顾准确性和效率。此外，提出了Frugal Learning方法，旨在在最小化准确性损失的前提下缩短模型输出长度。

Result: 在MATH-V和VLM-S2H数据集上，STELAR-Vision相比其基础模型准确率提高了9.7%，并超越了更大的Qwen2VL-72B-Instruct模型7.3%。在五个域外（out-of-distribution）基准测试中，其表现优于Phi-4-Multimodal-Instruct高达28.4%，优于LLaMA-3.2-11B-Vision-Instruct高达13.2%，显示出强大的泛化能力。与仅使用链式推理的训练方法相比，STELAR-Vision在域内数据集上整体准确率高出4.3%，并在所有域外基准测试中持续表现更优。

Conclusion: STELAR-Vision框架通过引入拓扑感知推理和多样化的数据增强，显著提升了视觉语言模型在复杂多模态任务中的推理准确性和泛化能力，同时有效地减少了模型输出的冗余性，证明了其在解决现有VLM局限性方面的有效性。

Abstract: Vision-language models (VLMs) have made significant strides in reasoning, yet
they often struggle with complex multimodal tasks and tend to generate overly
verbose outputs. A key limitation is their reliance on chain-of-thought (CoT)
reasoning, despite many tasks benefiting from alternative topologies like trees
or graphs. To address this, we introduce STELAR-Vision, a training framework
for topology-aware reasoning. At its core is TopoAug, a synthetic data pipeline
that enriches training with diverse topological structures. Using supervised
fine-tuning and reinforcement learning, we post-train Qwen2VL models with both
accuracy and efficiency in mind. Additionally, we propose Frugal Learning,
which reduces output length with minimal accuracy loss. On MATH-V and VLM-S2H,
STELAR-Vision improves accuracy by 9.7% over its base model and surpasses the
larger Qwen2VL-72B-Instruct by 7.3%. On five out-of-distribution benchmarks, it
outperforms Phi-4-Multimodal-Instruct by up to 28.4% and
LLaMA-3.2-11B-Vision-Instruct by up to 13.2%, demonstrating strong
generalization. Compared to Chain-Only training, our approach achieves 4.3%
higher overall accuracy on in-distribution datasets and consistently
outperforms across all OOD benchmarks. We have released datasets, and code will
be available.

</details>


### [25] [Simulating Generative Social Agents via Theory-Informed Workflow Design](https://arxiv.org/abs/2508.08726)
*Yuwei Yan,Jinghua Piao,Xiaochong Lan,Chenyang Shao,Pan Hui,Yong Li*

Main category: cs.AI

TL;DR: 提出一个基于社会认知理论的统一框架，包含动机、行动规划和学习模块，用于设计更通用、行为更真实的LLM社会智能体。


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体实现多为特定场景定制，缺乏统一框架，导致泛化能力差、行为不一致且不真实，限制了其在社会模拟中的应用。

Method: 提出了一个受社会认知理论启发的框架，包含三个核心模块：动机、行动规划和学习。这些模块共同使智能体能够推理目标、规划连贯行动并随时间调整行为。

Result: 实验证明，该理论驱动的智能体在复杂条件下能复现真实人类行为模式，与真实行为数据的偏差比传统生成基线低75%。消融实验表明，移除任一模块（动机、规划、学习）会使错误增加1.5到3.2倍，证实了其对生成真实连贯社会行为的独特贡献。

Conclusion: 所提出的理论驱动框架及其包含的动机、行动规划和学习模块，显著提高了LLM社会智能体生成真实、连贯行为的能力，解决了现有智能体泛化性和行为一致性不足的问题。

Abstract: Recent advances in large language models have demonstrated strong reasoning
and role-playing capabilities, opening new opportunities for agent-based social
simulations. However, most existing agents' implementations are
scenario-tailored, without a unified framework to guide the design. This lack
of a general social agent limits their ability to generalize across different
social contexts and to produce consistent, realistic behaviors. To address this
challenge, we propose a theory-informed framework that provides a systematic
design process for LLM-based social agents. Our framework is grounded in
principles from Social Cognition Theory and introduces three key modules:
motivation, action planning, and learning. These modules jointly enable agents
to reason about their goals, plan coherent actions, and adapt their behavior
over time, leading to more flexible and contextually appropriate responses.
Comprehensive experiments demonstrate that our theory-driven agents reproduce
realistic human behavior patterns under complex conditions, achieving up to 75%
lower deviation from real-world behavioral data across multiple fidelity
metrics compared to classical generative baselines. Ablation studies further
show that removing motivation, planning, or learning modules increases errors
by 1.5 to 3.2 times, confirming their distinct and essential contributions to
generating realistic and coherent social behaviors.

</details>


### [26] [Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance](https://arxiv.org/abs/2508.08774)
*Dongwook Choi,Taeyoon Kwon,Dongil Yang,Hyojun Kim,Jinyoung Yeo*

Main category: cs.AI

TL;DR: 该研究提出了一个记忆增强的增强现实（AR）智能体概念框架，旨在通过捕获、保留和推理用户的时空交互历史，解决当前AR智能体在处理复杂多步骤任务时缺乏长期经验和偏好理解的问题，从而提供个性化的任务辅助。


<details>
  <summary>Details</summary>
Motivation: 当前的AR智能体虽然能有效支持即时任务，但在需要理解和利用用户长期经验及偏好的复杂多步骤场景中表现不佳。这源于它们无法捕获、保留和推理时空背景下的历史用户交互。

Method: 本文提出了一个记忆增强的AR智能体概念框架，该框架包含四个互联模块：感知模块（用于多模态传感器处理）、记忆模块（用于持久性时空经验存储）、时空推理模块（用于整合过去和现在的情境）以及执行器模块（用于有效的AR通信）。

Result: 研究提出了一个能够通过学习和适应用户特定经验来提供个性化任务辅助的记忆增强AR智能体概念框架。同时，还提出了一个实施路线图、未来的评估策略、潜在目标应用和用例，以展示该框架在不同领域的实际适用性。

Conclusion: 该工作旨在激励未来的研究，以开发更智能的AR系统，使其能够有效地将用户交互历史与自适应、情境感知的任务辅助相结合，从而弥补现有AR智能体在处理复杂长期任务时的不足。

Abstract: Augmented Reality (AR) systems are increasingly integrating foundation
models, such as Multimodal Large Language Models (MLLMs), to provide more
context-aware and adaptive user experiences. This integration has led to the
development of AR agents to support intelligent, goal-directed interactions in
real-world environments. While current AR agents effectively support immediate
tasks, they struggle with complex multi-step scenarios that require
understanding and leveraging user's long-term experiences and preferences. This
limitation stems from their inability to capture, retain, and reason over
historical user interactions in spatiotemporal contexts. To address these
challenges, we propose a conceptual framework for memory-augmented AR agents
that can provide personalized task assistance by learning from and adapting to
user-specific experiences over time. Our framework consists of four
interconnected modules: (1) Perception Module for multimodal sensor processing,
(2) Memory Module for persistent spatiotemporal experience storage, (3)
Spatiotemporal Reasoning Module for synthesizing past and present contexts, and
(4) Actuator Module for effective AR communication. We further present an
implementation roadmap, a future evaluation strategy, a potential target
application and use cases to demonstrate the practical applicability of our
framework across diverse domains. We aim for this work to motivate future
research toward developing more intelligent AR systems that can effectively
bridge user's interaction history with adaptive, context-aware task assistance.

</details>


### [27] [A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions](https://arxiv.org/abs/2508.08795)
*Amir Mohammad Salehoof,Ali Ramezani,Yadollah Yaghoobzadeh,Majid Nili Ahmadabadi*

Main category: cs.AI

TL;DR: 这篇综述提出了一种基于知识功能的新型分类法，用于分析大型语言模型知识编辑方法，并探讨了不同编辑机制如何应用于不同类型的知识。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的知识会过时或不准确，而重新训练成本高昂。知识编辑提供了一种高效的替代方案。现有综述侧重于编辑机制，但忽视了被编辑知识的功能类型，导致视角不够全面。

Method: 本研究引入了一种新颖的、互补的基于功能的分类法，将知识分为事实性、时间性、概念性、常识性和社会性。在此基础上，结合现有的编辑机制（如参数修改、外部记忆），双轴地审查了知识编辑领域，并 formalizes 问题、评估任务和数据集。

Result: 通过这种双轴分类，本综述描绘了当前知识编辑领域的全貌，阐述了现有方法的优缺点，并总结了评估任务和数据集。

Conclusion: 本综述指出了知识编辑领域的开放挑战和未来研究方向，强调了编辑效果与目标知识性质的相关性。

Abstract: Large language models (LLMs) acquire vast knowledge from large text corpora,
but this information can become outdated or inaccurate. Since retraining is
computationally expensive, knowledge editing offers an efficient alternative --
modifying internal knowledge without full retraining. These methods aim to
update facts precisely while preserving the model's overall capabilities. While
existing surveys focus on the mechanism of editing (e.g., parameter changes vs.
external memory), they often overlook the function of the knowledge being
edited. This survey introduces a novel, complementary function-based taxonomy
to provide a more holistic view. We examine how different mechanisms apply to
various knowledge types -- factual, temporal, conceptual, commonsense, and
social -- highlighting how editing effectiveness depends on the nature of the
target knowledge. By organizing our review along these two axes, we map the
current landscape, outline the strengths and limitations of existing methods,
define the problem formally, survey evaluation tasks and datasets, and conclude
with open challenges and future directions.

</details>


### [28] [GRainsaCK: a Comprehensive Software Library for Benchmarking Explanations of Link Prediction Tasks on Knowledge Graphs](https://arxiv.org/abs/2508.08815)
*Roberto Barile,Claudia d'Amato,Nicola Fanizzi*

Main category: cs.AI

TL;DR: 本文提出了GRainsaCK，一个可复用的软件资源，旨在标准化知识图谱链接预测解释的基准测试和评估过程，解决了缺乏统一评估协议和基准资源的问题。


<details>
  <summary>Details</summary>
Motivation: 知识图谱通常不完整，链接预测方法被用来预测缺失事实。尽管可扩展的嵌入式解决方案被广泛采用，但它们缺乏可理解性。解释方法试图通过识别支持知识来解决这个问题，但目前缺乏量化的评估/比较标准和整体基准资源。

Method: 开发了GRainsaCK，一个可复用的软件资源，它能完全简化基准测试解释所需的所有任务，从模型训练到遵循相同评估协议的解释评估。此外，它通过将主要组件实现为可轻松替换的函数，进一步提高了模块化和可扩展性。

Result: GRainsaCK作为一个软件资源，填补了知识图谱链接预测解释评估方面的空白，提供了一个流线型、模块化、可扩展的解决方案，并附有详尽的文档和教程，以促进其复用。

Conclusion: GRainsaCK为知识图谱链接预测解释的基准测试和评估提供了一个急需的标准化和可复用平台，有助于推动该领域的研究和比较。

Abstract: Since Knowledge Graphs are often incomplete, link prediction methods are
adopted for predicting missing facts. Scalable embedding based solutions are
mostly adopted for this purpose, however, they lack comprehensibility, which
may be crucial in several domains. Explanation methods tackle this issue by
identifying supporting knowledge explaining the predicted facts. Regretfully,
evaluating/comparing quantitatively the resulting explanations is challenging
as there is no standard evaluation protocol and overall benchmarking resource.
We fill this important gap by proposing GRainsaCK, a reusable software resource
that fully streamlines all the tasks involved in benchmarking explanations,
i.e., from model training to evaluation of explanations along the same
evaluation protocol. Moreover, GRainsaCK furthers modularity/extensibility by
implementing the main components as functions that can be easily replaced.
Finally, fostering its reuse, we provide extensive documentation including a
tutorial.

</details>


### [29] [Efficient Agent: Optimizing Planning Capability for Multimodal Retrieval Augmented Generation](https://arxiv.org/abs/2508.08816)
*Yuechen Wang,Yuming Qiao,Dan Meng,Jun Yang,Haonan Lu,Zhenyu Yang,Xudong Zhang*

Main category: cs.AI

TL;DR: 本文提出E-Agent，一个多模态检索增强生成（mRAG）代理框架，通过动态规划和工具感知执行优化mRAG工作流，并引入RemPlan基准评估规划能力。E-Agent在准确性上超越现有方法，并显著减少冗余搜索。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型（MLLMs）在新闻分析、热点话题等实时场景中存在时间局限性。现有mRAG方法检索策略僵化，且未充分利用视觉信息，导致性能受限。

Method: 本文提出E-Agent框架，包含两项创新：1. 一个mRAG规划器，根据上下文推理动态协调多模态工具；2. 一个任务执行器，采用工具感知执行序列实现优化的mRAG工作流。E-Agent采用一次性mRAG规划策略，以提高检索效率并减少冗余工具调用。为评估mRAG系统的规划能力，本文还引入了Real-World mRAG Planning (RemPlan) 基准，其包含依赖检索和不依赖检索的问题类型，并明确标注所需的检索工具。

Result: 在RemPlan和三个现有基准上的实验表明，E-Agent优于现有mRAG方法：准确率提高13%，同时冗余搜索减少37%。

Conclusion: E-Agent通过动态、高效的规划和执行，有效解决了现有mRAG的局限性，显著提升了多模态检索增强生成的性能和效率。所提出的RemPlan基准为评估mRAG系统的规划能力提供了新的、更贴近实际的工具。

Abstract: Multimodal Retrieval-Augmented Generation (mRAG) has emerged as a promising
solution to address the temporal limitations of Multimodal Large Language
Models (MLLMs) in real-world scenarios like news analysis and trending topics.
However, existing approaches often suffer from rigid retrieval strategies and
under-utilization of visual information. To bridge this gap, we propose
E-Agent, an agent framework featuring two key innovations: a mRAG planner
trained to dynamically orchestrate multimodal tools based on contextual
reasoning, and a task executor employing tool-aware execution sequencing to
implement optimized mRAG workflows. E-Agent adopts a one-time mRAG planning
strategy that enables efficient information retrieval while minimizing
redundant tool invocations. To rigorously assess the planning capabilities of
mRAG systems, we introduce the Real-World mRAG Planning (RemPlan) benchmark.
This novel benchmark contains both retrieval-dependent and
retrieval-independent question types, systematically annotated with essential
retrieval tools required for each instance. The benchmark's explicit mRAG
planning annotations and diverse question design enhance its practical
relevance by simulating real-world scenarios requiring dynamic mRAG decisions.
Experiments across RemPlan and three established benchmarks demonstrate
E-Agent's superiority: 13% accuracy gain over state-of-the-art mRAG methods
while reducing redundant searches by 37%.

</details>


### [30] [Silicon Minds versus Human Hearts: The Wisdom of Crowds Beats the Wisdom of AI in Emotion Recognition](https://arxiv.org/abs/2508.08830)
*Mustafa Akben,Vinayaka Gude,Haya Ajjan*

Main category: cs.AI

TL;DR: 研究评估了多模态大语言模型（MLLMs）的情绪识别能力，发现MLLMs个体表现优于人类，但人类集体智慧超越MLLMs，而人机协作能达到最佳效果。


<details>
  <summary>Details</summary>
Motivation: 随着AI日益普及，其识别和响应人类情绪的能力对有效的人机交互至关重要。特别是，AI能否匹敌或超越人类专家在情绪识别方面的表现尚不清楚，而MLLMs的情绪智能更是未被充分探索。

Method: 本研究使用“读心识眼测试”（RMET）及其多民族版本（MRMET）评估了MLLMs的情绪识别能力，并将其表现与人类参与者进行比较。此外，还模拟了人类的集体智慧，并探索了人与MLLM预测相结合的协作方法（增强智能）。

Result: 结果显示，平均而言，MLLMs在两项测试中识别情绪的准确性均优于人类个体。然而，当模拟集体智慧时，人类群体的表现显著超越了聚合的MLLM预测。更进一步，结合人类和MLLM预测的协作方法（增强智能）比单独的人类或MLLMs取得了更高的准确性。

Conclusion: 虽然MLLMs在个体层面展现出强大的情绪识别能力，但人类的集体智慧以及人机协作的协同潜力，为开发情感智能AI系统提供了最有前景的途径。

Abstract: The ability to discern subtle emotional cues is fundamental to human social
intelligence. As artificial intelligence (AI) becomes increasingly common, AI's
ability to recognize and respond to human emotions is crucial for effective
human-AI interactions. In particular, whether such systems can match or surpass
human experts remains to be seen. However, the emotional intelligence of AI,
particularly multimodal large language models (MLLMs), remains largely
unexplored. This study evaluates the emotion recognition abilities of MLLMs
using the Reading the Mind in the Eyes Test (RMET) and its multiracial
counterpart (MRMET), and compares their performance against human participants.
Results show that, on average, MLLMs outperform humans in accurately
identifying emotions across both tests. This trend persists even when comparing
performance across low, medium, and expert-level performing groups. Yet when we
aggregate independent human decisions to simulate collective intelligence,
human groups significantly surpass the performance of aggregated MLLM
predictions, highlighting the wisdom of the crowd. Moreover, a collaborative
approach (augmented intelligence) that combines human and MLLM predictions
achieves greater accuracy than either humans or MLLMs alone. These results
suggest that while MLLMs exhibit strong emotion recognition at the individual
level, the collective intelligence of humans and the synergistic potential of
human-AI collaboration offer the most promising path toward effective emotional
AI. We discuss the implications of these findings for the development of
emotionally intelligent AI systems and future research directions.

</details>


### [31] [Reducing Cognitive Load in Multi-Agent Reinforcement Learning for Mathematical Problem Solving: Decoupling Reasoning and Code Generation](https://arxiv.org/abs/2508.08882)
*Dayu Wang,Jiaye Yang,Weikang Li,Jiahui Liang,Yang Li*

Main category: cs.AI

TL;DR: 该研究提出了一种双智能体混合框架，将数学推理系统中的问题分解与代码生成/执行解耦，以减少认知干扰并提高性能。


<details>
  <summary>Details</summary>
Motivation: 当前的单智能体数学推理系统（一个大型语言模型处理推理、代码生成和执行）存在认知负荷干扰，因为智能体必须交错长周期推理和精确的程序合成，导致推理路径的正确性降低。

Method: 首先，通过对比纯推理智能体和推理加代码智能体，验证了后者在正确推理路径上表现更差的假设。其次，提出了一个双智能体框架：推理智能体负责逐步问题分解，代码智能体处理代码生成和执行。训练结合了模仿学习和强化学习：代码智能体因匹配中间真实程序而获得强奖励，因有效执行获得弱奖励；推理智能体主要通过最终答案准确性进行优化，并使用优势估计来奖励中间步骤。

Result: 研究发现，具有工具调用能力的推理加代码智能体产生的正确推理路径显著减少。所提出的双智能体解耦设计能有效减少认知干扰，并促进推理与编码的稳定协调。

Conclusion: 将数学推理系统中的推理和编码角色解耦到独立的智能体中，可以有效降低认知干扰，提升推理与编码的协同稳定性，从而提高系统性能。

Abstract: Current tool-integrated mathematical reasoning systems often adopt a
single-agent paradigm, where one large language model handles problem
reasoning, code generation, and code execution in an integrated workflow. While
this design eases coordination, we hypothesize that it imposes cognitive load
interference, as the agent must interleave long-horizon reasoning with precise
program synthesis. We validate this hypothesis through a controlled comparison
between a reasoning-only agent and a reasoning-plus-code agent, finding that
the latter produces significantly fewer correct reasoning paths despite having
tool-calling capabilities. To address this, we propose a dual-agent hybrid
framework: a Reasoning Agent performs stepwise problem decomposition, and a
Code Agent handles code generation and execution. Training combines imitation
learning and reinforcement learning: the Code Agent receives strong rewards for
matching intermediate ground-truth programs and weaker rewards for valid
execution, while the Reasoning Agent is optimized chiefly via final-answer
accuracy using advantage estimation to credit intermediate steps. This
decoupled role design reduces cognitive interference and promotes stable
reasoning-coding coordination.

</details>


### [32] [Compass-Thinker-7B Technical Report](https://arxiv.org/abs/2508.08909)
*Anxiang Zeng,Haibo Zhang,Kaixiang Mo,Long Zhang,Shuman Liu,Yanhui Huang,Yawen Liu,Yuepeng Sheng,Yuwei Huang*

Main category: cs.AI

TL;DR: 该研究提出了Compass-Thinker-7B模型，旨在以更低的计算成本和资源消耗探索强化学习在大型语言模型推理能力上的潜力，并在数学推理任务上取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明强化学习是激发大型语言模型复杂推理能力的核心技术，但直接在超大规模模型上进行强化学习实验计算成本和资源需求极高，风险巨大。

Method: 提出了Compass-Thinker-7B模型，通过专门设计的强化学习管道从开源模型进行训练。构建了一个包含3万个可验证数学问题的RL训练数据集，并为不同阶段配置了不同难度分布的数据和训练设置，以逐步释放模型潜力并提高训练效率。

Result: Compass-Thinker-7B模型展现出卓越的推理潜力，在数学任务上超越了同等规模的RL模型。特别是在极具挑战性的AIME2024评估中，达到了40%的准确率。

Conclusion: Compass-Thinker-7B模型证明了在较低资源消耗下，强化学习仍能有效提升模型推理能力，并为更大模型上的强化学习配方研究提供了有价值的见解。

Abstract: Recent R1-Zero-like research further demonstrates that reasoning extension
has given large language models (LLMs) unprecedented reasoning capabilities,
and Reinforcement Learning is the core technology to elicit its complex
reasoning. However, conducting RL experiments directly on hyperscale models
involves high computational costs and resource demands, posing significant
risks. We propose the Compass-Thinker-7B model, which aims to explore the
potential of Reinforcement Learning with less computational resources and
costs, and provides insights for further research into RL recipes for larger
models. Compass-Thinker-7B is trained from an open source model through a
specially designed Reinforcement Learning Pipeline. we curate a dataset of 30k
verifiable mathematics problems for the Reinforcement Learning Pipeline. By
configuring data and training settings with different difficulty distributions
for different stages, the potential of the model is gradually released and the
training efficiency is improved. Extensive evaluations show that
Compass-Thinker-7B possesses exceptional reasoning potential, and achieves
superior performance on mathematics compared to the same-sized RL
model.Especially in the challenging AIME2024 evaluation, Compass-Thinker-7B
achieves 40% accuracy.

</details>


### [33] [Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models](https://arxiv.org/abs/2508.08926)
*Wei Cai,Jian Zhao,Yuchu Jiang,Tianle Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: 大型视觉语言模型（LVLMs）存在一种名为“隐式推理安全”的新漏洞，即良性多模态输入因 flawed 或隐藏推理导致不安全输出。本文引入了SSUI数据集来展示此问题，并证明简单的上下文学习可显著缓解此类威胁，强调需改进跨模态隐式推理。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在处理多模态输入时面临日益增长的安全挑战，特别是当良性组合输入因LVLM内部有缺陷或隐藏的推理而触发不安全输出时。

Method: 本文提出了“隐式推理安全”的概念，并开发了首个针对此关键问题的“安全语义，不安全解释”（SSUI）数据集。研究通过简单的上下文学习（In-Context Learning, ICL）配合SSUI数据集来演示并缓解这些隐式多模态威胁。

Result: 研究表明，即使是使用SSUI数据集进行的简单上下文学习，也能显著缓解这些隐式多模态威胁。

Conclusion: 迫切需要改进大型视觉语言模型中的跨模态隐式推理能力，以解决“隐式推理安全”这一漏洞。

Abstract: Large Vision-Language Models face growing safety challenges with multimodal
inputs. This paper introduces the concept of Implicit Reasoning Safety, a
vulnerability in LVLMs. Benign combined inputs trigger unsafe LVLM outputs due
to flawed or hidden reasoning. To showcase this, we developed Safe Semantics,
Unsafe Interpretations, the first dataset for this critical issue. Our
demonstrations show that even simple In-Context Learning with SSUI
significantly mitigates these implicit multimodal threats, underscoring the
urgent need to improve cross-modal implicit reasoning.

</details>


### [34] [Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty](https://arxiv.org/abs/2508.08992)
*Rui Wang,Qihan Lin,Jiayu Liu,Qing Zong,Tianshi Zheng,Weiqi Wang,Yangqiu Song*

Main category: cs.AI

TL;DR: 该研究探讨了前景理论是否适用于大型语言模型（LLM）的决策，以及不确定性语言标记对其决策行为的影响。结果表明，前景理论在建模LLM决策时并不总是可靠，尤其当不确定性以多种语言形式表达时。


<details>
  <summary>Details</summary>
Motivation: 前景理论（PT）在人类不确定性决策中得到应用，而认知标记（如“也许”）用于表达语言中的不确定性。然而，目前尚不清楚前景理论是否适用于当代大型语言模型，以及表达人类不确定性的认知标记是否会影响它们的决策行为。

Method: 研究设计了一个基于经济问卷的三阶段实验。提出了一个更通用和精确的评估框架来建模LLM在前景理论下的决策行为，通过常用认知标记在可比上下文中的经验概率值引入不确定性。随后，根据这些认知标记的相应概率值将其纳入评估框架，以检验它们对LLM决策行为的影响。

Result: 研究结果表明，使用前景理论来建模LLM的决策行为并不总是可靠的，特别是在不确定性以多样化语言形式表达时。

Conclusion: 前景理论在解释大型语言模型决策行为方面存在局限性，尤其是在面对通过不同语言形式表达的不确定性时，其建模能力并不一致可靠。

Abstract: Prospect Theory (PT) models human decision-making under uncertainty, while
epistemic markers (e.g., maybe) serve to express uncertainty in language.
However, it remains largely unexplored whether Prospect Theory applies to
contemporary Large Language Models and whether epistemic markers, which express
human uncertainty, affect their decision-making behaviour. To address these
research gaps, we design a three-stage experiment based on economic
questionnaires. We propose a more general and precise evaluation framework to
model LLMs' decision-making behaviour under PT, introducing uncertainty through
the empirical probability values associated with commonly used epistemic
markers in comparable contexts. We then incorporate epistemic markers into the
evaluation framework based on their corresponding probability values to examine
their influence on LLM decision-making behaviours. Our findings suggest that
modelling LLMs' decision-making with PT is not consistently reliable,
particularly when uncertainty is expressed in diverse linguistic forms. Our
code is released in https://github.com/HKUST-KnowComp/MarPT.

</details>


### [35] [Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory](https://arxiv.org/abs/2508.08997)
*Sizhe Yuen,Francisco Gomez Medina,Ting Su,Yali Du,Adam J. Sobey*

Main category: cs.AI

TL;DR: 本文提出了一种名为“内在记忆代理”（Intrinsic Memory Agents）的新框架，通过结构化、随输出演进的代理特定记忆来解决多智能体LLM系统因上下文窗口限制导致的记忆一致性问题，显著提升了在规划任务上的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 多智能体大语言模型（LLM）系统在复杂协作问题解决中展现巨大潜力，但受限于上下文窗口大小，导致记忆一致性、角色遵守和程序完整性方面存在根本性挑战。

Method: 引入“内在记忆代理”框架，通过维护与代理输出内在演进的、结构化的代理特定记忆模板来解决问题。这些模板旨在保留专业视角，同时聚焦于任务相关信息。

Result: 在PDDL数据集上，该方法比现有最先进的多智能体记忆方法性能提升38.6%，并具有最高的token效率。在复杂数据管道设计任务上，该方法在可扩展性、可靠性、可用性、成本效益和文档化5个指标上产生了更高质量的设计，并提供了额外的定性证据。

Conclusion: 通过结构化、内在的方法解决记忆限制，可以显著提高多智能体LLM系统在结构化规划任务上的能力。

Abstract: Multi-agent systems built on Large Language Models (LLMs) show exceptional
promise for complex collaborative problem-solving, yet they face fundamental
challenges stemming from context window limitations that impair memory
consistency, role adherence, and procedural integrity. This paper introduces
Intrinsic Memory Agents, a novel framework that addresses these limitations
through structured agent-specific memories that evolve intrinsically with agent
outputs. Specifically, our method maintains role-aligned memory templates that
preserve specialized perspectives while focusing on task-relevant information.
We benchmark our approach on the PDDL dataset, comparing its performance to
existing state-of-the-art multi-agentic memory approaches and showing an
improvement of 38.6\% with the highest token efficiency. An additional
evaluation is performed on a complex data pipeline design task, we demonstrate
that our approach produces higher quality designs when comparing 5 metrics:
scalability, reliability, usability, cost-effectiveness and documentation with
additional qualitative evidence of the improvements. Our findings suggest that
addressing memory limitations through structured, intrinsic approaches can
improve the capabilities of multi-agent LLM systems on structured planning
tasks.

</details>


### [36] [Activation Steering for Bias Mitigation: An Interpretable Approach to Safer LLMs](https://arxiv.org/abs/2508.09019)
*Shivam Dubey*

Main category: cs.AI

TL;DR: 该论文提出一个端到端的系统，利用可解释性技术直接在LLM内部识别和减轻偏见，通过训练探针检测偏见并使用转向向量实时纠正生成内容。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）日益融入社会系统，它们可能传播和放大有害偏见的风险成为一个关键的安全问题。传统的偏见缓解方法（如数据过滤或后处理）将模型视为黑箱，无法直接干预其内部工作机制。

Method: 该方法包括两个主要阶段：1. 训练线性“探针”来检测模型内部激活中的潜在偏见表示（如性别、种族、年龄），以识别偏见。2. 利用这些发现，通过对比偏见和中性语句的模型激活模式，计算“转向向量”。在推理过程中添加这些向量，以实时引导模型的生成过程，使其远离有害、刻板或有偏见的内容。

Result: 实验在gpt2-large上进行，结果表明：1. 探针能够以接近完美的准确率识别偏见内容，且偏见表示在模型的后期层中最为突出。2. 激活转向技术有效，成功地将有偏见的补全内容转向更中性的替代方案。

Conclusion: 该工作提出了一个健壮且可复现的系统，提供了一种更直接、更可解释的方法来构建更安全、更负责任的LLMs，通过深入模型内部机制来识别和缓解偏见。

Abstract: As large language models (LLMs) become more integrated into societal systems,
the risk of them perpetuating and amplifying harmful biases becomes a critical
safety concern. Traditional methods for mitigating bias often rely on data
filtering or post-hoc output moderation, which treat the model as an opaque
black box. In this work, we introduce a complete, end-to-end system that uses
techniques from mechanistic interpretability to both identify and actively
mitigate bias directly within a model's internal workings. Our method involves
two primary stages. First, we train linear "probes" on the internal activations
of a model to detect the latent representations of various biases (e.g.,
gender, race, age). Our experiments on \texttt{gpt2-large} demonstrate that
these probes can identify biased content with near-perfect accuracy, revealing
that bias representations become most salient in the model's later layers.
Second, we leverage these findings to compute "steering vectors" by contrasting
the model's activation patterns for biased and neutral statements. By adding
these vectors during inference, we can actively steer the model's generative
process away from producing harmful, stereotypical, or biased content in
real-time. We demonstrate the efficacy of this activation steering technique,
showing that it successfully alters biased completions toward more neutral
alternatives. We present our work as a robust and reproducible system that
offers a more direct and interpretable approach to building safer and more
accountable LLMs.

</details>


### [37] [A First Look at Predictability and Explainability of Pre-request Passenger Waiting Time in Ridesharing Systems](https://arxiv.org/abs/2508.09027)
*Jie Wang,Guang Wang*

Main category: cs.AI

TL;DR: 本研究首次探讨了网约车系统中预请求乘客等待时间的可预测性和可解释性，并提出了基于特征交互的XGBoost模型FiXGBoost，在真实大规模数据集上表现出良好的预测性能和高可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多关注已知匹配司机信息的请求后等待时间预测，而预请求等待时间（即在提交乘车请求和匹配司机之前）的预测对乘客规划行程和提升用户体验同样重要，但尚未得到充分研究。

Method: 通过深入的数据驱动研究，分析了供需动态对乘客等待时间的影响。在此分析和特征工程的基础上，提出了FiXGBoost模型，一个新颖的基于特征交互的XGBoost模型，用于在未知分配司机信息的情况下预测等待时间。此外，还进行了重要性分析以量化各因素的贡献。

Result: 在包含超过3000万条行程记录的大规模真实网约车数据集上的实验表明，FiXGBoost模型在预请求乘客等待时间预测方面取得了良好性能，并具有高可解释性。

Conclusion: 该研究为理解网约车系统中预请求乘客等待时间的可预测性和可解释性迈出了第一步，并提出了一种有效且可解释的模型FiXGBoost，有助于提升网约车用户体验和平台效率。

Abstract: Passenger waiting time prediction plays a critical role in enhancing both
ridesharing user experience and platform efficiency. While most existing
research focuses on post-request waiting time prediction with knowing the
matched driver information, pre-request waiting time prediction (i.e., before
submitting a ride request and without matching a driver) is also important, as
it enables passengers to plan their trips more effectively and enhance the
experience of both passengers and drivers. However, it has not been fully
studied by existing works. In this paper, we take the first step toward
understanding the predictability and explainability of pre-request passenger
waiting time in ridesharing systems. Particularly, we conduct an in-depth
data-driven study to investigate the impact of demand&supply dynamics on
passenger waiting time. Based on this analysis and feature engineering, we
propose FiXGBoost, a novel feature interaction-based XGBoost model designed to
predict waiting time without knowing the assigned driver information. We
further perform an importance analysis to quantify the contribution of each
factor. Experiments on a large-scale real-world ridesharing dataset including
over 30 million trip records show that our FiXGBoost can achieve a good
performance for pre-request passenger waiting time prediction with high
explainability.

</details>


### [38] [CVCM Track Circuits Pre-emptive Failure Diagnostics for Predictive Maintenance Using Deep Neural Networks](https://arxiv.org/abs/2508.09054)
*Debdeep Mukherjee,Eduardo Di Santi,Clément Lefebvre,Nenad Mijatovic,Victor Martin,Thierry Josse,Jonathan Brown,Kenza Saiah*

Main category: cs.AI

TL;DR: 该研究提出一个基于深度神经网络的预测性维护框架，用于早期检测轨道电路（特别是CVCM技术）的微妙异常，以防止故障升级，提高铁路运营可靠性。


<details>
  <summary>Details</summary>
Motivation: 轨道电路作为列车定位的关键信号子系统，其故障会引发连锁中断。许多故障源于随时间演变的微妙异常，传统方法难以早期发现。因此，需要早期识别故障类型以改进维护规划，减少停机时间和收入损失。

Method: 研究提出了一个利用深度神经网络的预测性维护框架，用于在异常升级为故障之前对其进行分类。该方法通过一致性预测提供不确定性估计。

Result: 该方法在10个CVCM故障案例上进行了验证，符合ISO-17359标准，并优于传统技术，实现了99.31%的总体准确率，能在异常发生后1%的时间内检测到。一致性预测达到了99%的置信度，且各类别覆盖率一致。

Conclusion: 该方法具有可扩展性，可适应其他轨道电路和铁路系统，显著提高运营可靠性。通过早期、准确地检测轨道电路异常，有助于改进维护，减少中断。

Abstract: Track circuits are critical for railway operations, acting as the main
signalling sub-system to locate trains. Continuous Variable Current Modulation
(CVCM) is one such technology. Like any field-deployed, safety-critical asset,
it can fail, triggering cascading disruptions. Many failures originate as
subtle anomalies that evolve over time, often not visually apparent in
monitored signals. Conventional approaches, which rely on clear signal changes,
struggle to detect them early. Early identification of failure types is
essential to improve maintenance planning, minimising downtime and revenue
loss. Leveraging deep neural networks, we propose a predictive maintenance
framework that classifies anomalies well before they escalate into failures.
Validated on 10 CVCM failure cases across different installations, the method
is ISO-17359 compliant and outperforms conventional techniques, achieving
99.31% overall accuracy with detection within 1% of anomaly onset. Through
conformal prediction, we provide uncertainty estimates, reaching 99% confidence
with consistent coverage across classes. Given CVCMs global deployment, the
approach is scalable and adaptable to other track circuits and railway systems,
enhancing operational reliability.

</details>


### [39] [SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling](https://arxiv.org/abs/2508.09105)
*Shixuan Sun,Siyuan Liang,Ruoyu Chen,Jianjie Huang,Jingzhi Li,Xiaochun Cao*

Main category: cs.AI

TL;DR: 针对RAG/MRAG中内容来源不透明导致隐私泄露问责困难的问题，提出首个源感知成员审计（SMA）方法，实现细粒度内容归因，并首次在MRAG中对图像检索痕迹进行成员推断。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）和多模态RAG（MRAG）虽能提升大型语言模型（LLM）的知识覆盖和上下文理解，但其检索和多模态融合过程模糊了内容来源。现有成员推断方法无法可靠地将生成内容归因于预训练、外部检索或用户输入，从而阻碍了隐私泄露的问责。

Method: 本文提出了首个源感知成员审计（SMA）方法，用于在具有检索控制能力的半黑盒设置中实现生成内容的细粒度来源归因。为适应半黑盒审计环境，设计了一种基于零阶优化的归因估计机制，通过大规模扰动采样和岭回归建模，稳健地近似输入token对输出的真实影响。此外，SMA引入了一种跨模态归因技术，通过多模态LLM（MLLM）将图像输入投影到文本描述，从而在文本模态中实现token级归因，首次实现了对MRAG系统中图像检索痕迹的成员推断。

Result: SMA首次实现了对MRAG系统中图像检索痕迹的成员推断，并将成员推断的关注点从“数据是否被记忆”转移到“内容来源于何处”。

Conclusion: SMA为复杂生成系统的数据溯源审计提供了一个新颖的视角，有效解决了RAG/MRAG系统中内容来源不明导致隐私泄露问责困难的挑战。

Abstract: Retrieval-Augmented Generation (RAG) and its Multimodal Retrieval-Augmented
Generation (MRAG) significantly improve the knowledge coverage and contextual
understanding of Large Language Models (LLMs) by introducing external knowledge
sources. However, retrieval and multimodal fusion obscure content provenance,
rendering existing membership inference methods unable to reliably attribute
generated outputs to pre-training, external retrieval, or user input, thus
undermining privacy leakage accountability
  To address these challenges, we propose the first Source-aware Membership
Audit (SMA) that enables fine-grained source attribution of generated content
in a semi-black-box setting with retrieval control capabilities.To address the
environmental constraints of semi-black-box auditing, we further design an
attribution estimation mechanism based on zero-order optimization, which
robustly approximates the true influence of input tokens on the output through
large-scale perturbation sampling and ridge regression modeling. In addition,
SMA introduces a cross-modal attribution technique that projects image inputs
into textual descriptions via MLLMs, enabling token-level attribution in the
text modality, which for the first time facilitates membership inference on
image retrieval traces in MRAG systems. This work shifts the focus of
membership inference from 'whether the data has been memorized' to 'where the
content is sourced from', offering a novel perspective for auditing data
provenance in complex generative systems.

</details>


### [40] [OpenCUA: Open Foundations for Computer-Use Agents](https://arxiv.org/abs/2508.09123)
*Xinyuan Wang,Bowen Wang,Dunjie Lu,Junlin Yang,Tianbao Xie,Junli Wang,Jiaqi Deng,Xiaole Guo,Yiheng Xu,Chen Henry Wu,Zhennan Shen,Zhuokai Li,Ryan Li,Xiaochuan Li,Junda Chen,Boyuan Zheng,Peihang Li,Fangyu Lei,Ruisheng Cao,Yeqiao Fu,Dongchan Shin,Martin Shin,Jiarui Hu,Yuyan Wang,Jixuan Chen,Yuxiao Ye,Danyang Zhang,Dikang Du,Hao Hu,Huarong Chen,Zaida Zhou,Yipu Wang,Heng Wang,Diyi Yang,Victor Zhong,Flood Sung,Y. Charles,Zhilin Yang,Tao Yu*

Main category: cs.AI

TL;DR: OpenCUA是一个开源的计算机使用代理（CUA）框架，旨在解决现有CUA系统不透明的问题。它包含数据标注工具、大规模数据集AgentNet和可扩展的数据处理流程，其模型在CUA基准测试中表现出色，超越了现有开源和部分闭源模型，并已开源以推动研究。


<details>
  <summary>Details</summary>
Motivation: 当前功能强大的计算机使用代理（CUA）系统大多是闭源的，阻碍了研究社区对其能力、局限性和风险的深入研究。随着这些代理在数字交互和决策中的作用日益增强，迫切需要开放的CUA框架。

Method: 该研究提出了OpenCUA框架，包括：1) 一个无缝捕获人类计算机使用演示的标注基础设施；2) AgentNet，首个涵盖3个操作系统和200多个应用/网站的大规模计算机使用任务数据集；3) 一个可扩展的管道，将演示转化为带有反思性长思维链推理的状态-动作对，以在数据扩展时保持性能提升。

Result: OpenCUA的端到端代理模型在CUA基准测试中表现强劲。特别是，OpenCUA-32B在OSWorld-Verified上实现了34.8%的平均成功率，在开源模型中建立了新的SOTA，并超越了OpenAI CUA (GPT-4o)。研究还证实该方法具有良好的跨领域泛化能力，并能从增加的测试时计算中显著获益。

Conclusion: OpenCUA框架为计算机使用代理研究提供了开放的基础。研究团队已发布其标注工具、数据集、代码和模型，以促进未来的CUA研究和发展。

Abstract: Vision-language models have demonstrated impressive capabilities as
computer-use agents (CUAs) capable of automating diverse computer tasks. As
their commercial potential grows, critical details of the most capable CUA
systems remain closed. As these agents will increasingly mediate digital
interactions and execute consequential decisions on our behalf, the research
community needs access to open CUA frameworks to study their capabilities,
limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive
open-source framework for scaling CUA data and foundation models. Our framework
consists of: (1) an annotation infrastructure that seamlessly captures human
computer-use demonstrations; (2) AgentNet, the first large-scale computer-use
task dataset spanning 3 operating systems and 200+ applications and websites;
(3) a scalable pipeline that transforms demonstrations into state-action pairs
with reflective long Chain-of-Thought reasoning that sustain robust performance
gains as data scales. Our end-to-end agent models demonstrate strong
performance across CUA benchmarks. In particular, OpenCUA-32B achieves an
average success rate of 34.8% on OSWorld-Verified, establishing a new
state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA
(GPT-4o). Further analysis confirms that our approach generalizes well across
domains and benefits significantly from increased test-time computation. We
release our annotation tool, datasets, code, and models to build open
foundations for further CUA research.

</details>


### [41] [BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair](https://arxiv.org/abs/2508.09129)
*Xianghe Pang,Shuo Tang,Rui Ye,Yuwen Du,Yaxin Du,Siheng Chen*

Main category: cs.AI

TL;DR: BrowseMaster是一个可扩展的框架，通过结合规划器和执行器代理，解决了LLM代理在信息搜索中广度与深度平衡的挑战，实现了高效的探索和连贯的推理。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM代理在广阔的数字信息搜索中难以平衡广泛搜索与策略推理，因为串行查询限制了覆盖范围，且原始输入噪音干扰了多步推理的连续性。

Method: 提出BrowseMaster框架，包含程序增强的规划器-执行器代理对。规划器根据任务制定和调整搜索策略，执行器进行高效、有针对性的检索，为规划器提供简洁相关证据，从而实现广阔探索和连贯推理的分工。

Result: 在具有挑战性的英文和中文基准测试（BrowseComp-en和BrowseComp-zh）上，BrowseMaster始终优于开源和专有基线，分别获得30.0和46.5的分数。

Conclusion: BrowseMaster在复杂的、重推理的信息搜索任务中表现出强大的能力，有效克服了现有代理在搜索广度和推理深度之间的权衡限制。

Abstract: Effective information seeking in the vast and ever-growing digital landscape
requires balancing expansive search with strategic reasoning. Current large
language model (LLM)-based agents struggle to achieve this balance due to
limitations in search breadth and reasoning depth, where slow, serial querying
restricts coverage of relevant sources and noisy raw inputs disrupt the
continuity of multi-step reasoning. To address these challenges, we propose
BrowseMaster, a scalable framework built around a programmatically augmented
planner-executor agent pair. The planner formulates and adapts search
strategies based on task constraints, while the executor conducts efficient,
targeted retrieval to supply the planner with concise, relevant evidence. This
division of labor preserves coherent, long-horizon reasoning while sustaining
broad and systematic exploration, overcoming the trade-off that limits existing
agents. Extensive experiments on challenging English and Chinese benchmarks
show that BrowseMaster consistently outperforms open-source and proprietary
baselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh,
which demonstrates its strong capability in complex, reasoning-heavy
information-seeking tasks at scale.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [42] [Evaluation of State-of-the-Art Deep Learning Techniques for Plant Disease and Pest Detection](https://arxiv.org/abs/2508.08317)
*Saptarshi Banerjee,Tausif Mallick,Amlan Chakroborty,Himadri Nath Saha,Nityananda T. Takur*

Main category: cs.CV

TL;DR: 本文综述了利用人工智能、机器学习和深度学习技术，通过图像识别方法检测植物病虫害的最新进展，并对不同方法进行了分类和比较。


<details>
  <summary>Details</summary>
Motivation: 植物病虫害严重影响作物产量并造成经济损失，传统人工识别方法存在局限性，需要更精确高效的检测技术。

Method: 研究将现代基于计算机的植物病虫害图像检测技术分为五类：高光谱成像、非可视化技术、可视化方法、改进的深度学习架构和Transformer模型，并对近期工作和比较研究进行了综述。

Result: 现代基于AI的方法在速度和准确性上持续优于旧的图像分析方法。特别是，视觉Transformer模型（如分层视觉Transformer HvT）在植物病害检测中准确率超过99.3%，优于MobileNetV3等架构。

Conclusion: AI驱动的检测方法表现出卓越的性能，尤其以视觉Transformer为代表。研究还讨论了系统设计挑战，提出了解决方案，并展望了未来的研究方向。

Abstract: Addressing plant diseases and pests is critical for enhancing crop production
and preventing economic losses. Recent advances in artificial intelligence
(AI), machine learning (ML), and deep learning (DL) have significantly improved
the precision and efficiency of detection methods, surpassing the limitations
of manual identification. This study reviews modern computer-based techniques
for detecting plant diseases and pests from images, including recent AI
developments. The methodologies are organized into five categories:
hyperspectral imaging, non-visualization techniques, visualization approaches,
modified deep learning architectures, and transformer models. This structured
taxonomy provides researchers with detailed, actionable insights for selecting
advanced state-of-the-art detection methods. A comprehensive survey of recent
work and comparative studies demonstrates the consistent superiority of modern
AI-based approaches, which often outperform older image analysis methods in
speed and accuracy. In particular, vision transformers such as the Hierarchical
Vision Transformer (HvT) have shown accuracy exceeding 99.3% in plant disease
detection, outperforming architectures like MobileNetV3. The study concludes by
discussing system design challenges, proposing solutions, and outlining
promising directions for future research.

</details>


### [43] [ImageDDI: Image-enhanced Molecular Motif Sequence Representation for Drug-Drug Interaction Prediction](https://arxiv.org/abs/2508.08338)
*Yuqin He,Tengfei Ma,Chaoyi Li,Pengsen Ma,Hongxin Xiang,Jianmin Wang,Yiping Liu,Bosheng Song,Xiangxiang Zeng*

Main category: cs.CV

TL;DR: ImageDDI是一个用于DDI预测的深度学习框架，它通过将药物表示为功能性基序序列并结合全局分子图像信息，利用Transformer编码器和自适应特征融合来提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 多药同时使用可能导致不良健康影响、意外副作用和相互作用，因此准确识别和预测药物-药物相互作用（DDI）至关重要。现有方法受限于基于功能基序的表示学习瓶颈，因为DDI根本上是由基序相互作用而非整体药物结构引起的。

Method: ImageDDI框架将分子标记为功能性基序，将一对药物的基序组合成一个序列，并使用基于Transformer的编码器进行嵌入以表示局部结构。它进一步利用全局分子图像信息（如纹理、阴影、颜色和平面空间关系）增强分子的空间表示。为整合分子视觉信息与功能基序序列，ImageDDI采用自适应特征融合（Adaptive Feature Fusion）来动态调整特征表示的融合过程。

Result: 在广泛使用的数据集上，ImageDDI的实验结果优于现有最先进的方法。此外，在2D和3D图像增强场景中，ImageDDI与其他模型相比也取得了具有竞争力的性能。

Conclusion: ImageDDI通过结合药物的局部功能基序序列表示和全局分子图像信息，有效地提高了药物-药物相互作用的预测准确性和泛化能力，为DDI预测提供了一种新的有效方法。

Abstract: To mitigate the potential adverse health effects of simultaneous multi-drug
use, including unexpected side effects and interactions, accurately identifying
and predicting drug-drug interactions (DDIs) is considered a crucial task in
the field of deep learning. Although existing methods have demonstrated
promising performance, they suffer from the bottleneck of limited functional
motif-based representation learning, as DDIs are fundamentally caused by motif
interactions rather than the overall drug structures. In this paper, we propose
an Image-enhanced molecular motif sequence representation framework for
\textbf{DDI} prediction, called ImageDDI, which represents a pair of drugs from
both global and local structures. Specifically, ImageDDI tokenizes molecules
into functional motifs. To effectively represent a drug pair, their motifs are
combined into a single sequence and embedded using a transformer-based encoder,
starting from the local structure representation. By leveraging the
associations between drug pairs, ImageDDI further enhances the spatial
representation of molecules using global molecular image information (e.g.
texture, shadow, color, and planar spatial relationships). To integrate
molecular visual information into functional motif sequence, ImageDDI employs
Adaptive Feature Fusion, enhancing the generalization of ImageDDI by
dynamically adapting the fusion process of feature representations.
Experimental results on widely used datasets demonstrate that ImageDDI
outperforms state-of-the-art methods. Moreover, extensive experiments show that
ImageDDI achieved competitive performance in both 2D and 3D image-enhanced
scenarios compared to other models.

</details>


### [44] [Designing Object Detection Models for TinyML: Foundations, Comparative Analysis, Challenges, and Emerging Solutions](https://arxiv.org/abs/2508.08352)
*Christophe EL Zeinaty,Wassim Hamidouche,Glenn Herrou,Daniel Menard*

Main category: cs.CV

TL;DR: 这篇综述论文详细分析了在资源受限的TinyML设备上部署目标检测模型所面临的优化挑战，并探讨了主要的优化技术及其性能表现。


<details>
  <summary>Details</summary>
Motivation: 目标检测在计算机视觉中至关重要，但在资源受限的IoT设备（如微控制器）上部署面临巨大计算负载挑战。现有综述论文往往忽视了TinyML环境中目标检测模型的优化难题，因此需要弥补这一空白。

Method: 本文作为一篇综述，详细分析了用于在资源受限设备上部署目标检测模型的关键优化技术，包括量化、剪枝、知识蒸馏和神经架构搜索。同时，探讨了理论方法和实际实现，并比较了现有目标检测实现在微控制器设备上的关键性能指标（KPIs）。

Result: 论文提供了对量化、剪枝、知识蒸馏和神经架构搜索等优化技术的深入分析，弥合了学术研究与实际边缘AI部署之间的差距。此外，还比较了现有目标检测实现在微控制器上的性能，并提供了一个公共仓库以持续追踪该领域的最新进展。

Conclusion: TinyML为超低功耗设备上的目标检测提供了解决方案，实现了高效的边缘实时处理。通过分析优化技术和现有实现的KPIs，论文展示了这些解决方案在预测精度和效率方面的成熟度，并为该领域的未来发展提供了追踪资源。

Abstract: Object detection (OD) has become vital for numerous computer vision
applications, but deploying it on resource-constrained IoT devices presents a
significant challenge. These devices, often powered by energy-efficient
microcontrollers, struggle to handle the computational load of deep
learning-based OD models. This issue is compounded by the rapid proliferation
of IoT devices, predicted to surpass 150 billion by 2030. TinyML offers a
compelling solution by enabling OD on ultra-low-power devices, paving the way
for efficient and real-time processing at the edge. Although numerous survey
papers have been published on this topic, they often overlook the optimization
challenges associated with deploying OD models in TinyML environments. To
address this gap, this survey paper provides a detailed analysis of key
optimization techniques for deploying OD models on resource-constrained
devices. These techniques include quantization, pruning, knowledge
distillation, and neural architecture search. Furthermore, we explore both
theoretical approaches and practical implementations, bridging the gap between
academic research and real-world edge artificial intelligence deployment.
Finally, we compare the key performance indicators (KPIs) of existing OD
implementations on microcontroller devices, highlighting the achieved maturity
level of these solutions in terms of both prediction accuracy and efficiency.
We also provide a public repository to continually track developments in this
fast-evolving field:
https://github.com/christophezei/Optimizing-Object-Detection-Models-for-TinyML-A-Comprehensive-Survey.

</details>


### [45] [Neural Tangent Knowledge Distillation for Optical Convolutional Networks](https://arxiv.org/abs/2508.08421)
*Jinlin Xiang,Minho Choi,Yubo Zhang,Zhihao Zhou,Arka Majumdar,Eli Shlizerman*

Main category: cs.CV

TL;DR: 该论文提出了一种任务和硬件无关的混合光神经网络（ONN）优化流程，通过在训练前估计精度、引入神经正切知识蒸馏（NTKD）进行模型对齐和后期微调，显著提升了ONN的性能并解决了仿真与实际系统间的精度差异。


<details>
  <summary>Details</summary>
Motivation: 混合光神经网络（ONN）是实时、功耗受限系统的节能替代方案，但其应用受限于两大挑战：与大型数字网络相比的训练精度差距，以及仿真与实际制造系统之间的精度不一致。现有解决方案通常缺乏跨任务和硬件设计的泛化能力。

Method: 本文提出一个任务和硬件无关的流水线：1) 在训练前，根据物理尺寸和数据集等用户约束，估算可达到的模型精度，以辅助光学系统设计。2) 在训练期间，引入神经正切知识蒸馏（NTKD），使光模型与电子教师网络对齐，从而缩小精度差距。3) 在制造后，NTKD指导数字后端进行微调，以补偿实现误差。

Result: 在多个数据集（如MNIST、CIFAR、Carvana Masking）和硬件配置上的实验表明，该流水线持续提升了ONN的性能，并在预制造仿真和物理实现中都实现了实际部署。

Conclusion: 所提出的任务和硬件无关的流水线，结合神经正切知识蒸馏（NTKD），有效解决了混合光神经网络的精度差距和仿真-制造差异问题，显著提升了ONN的性能，使其能够实际部署在各种任务和硬件配置中。

Abstract: Hybrid Optical Neural Networks (ONNs, typically consisting of an optical
frontend and a digital backend) offer an energy-efficient alternative to fully
digital deep networks for real-time, power-constrained systems. However, their
adoption is limited by two main challenges: the accuracy gap compared to
large-scale networks during training, and discrepancies between simulated and
fabricated systems that further degrade accuracy. While previous work has
proposed end-to-end optimizations for specific datasets (e.g., MNIST) and
optical systems, these approaches typically lack generalization across tasks
and hardware designs. To address these limitations, we propose a task-agnostic
and hardware-agnostic pipeline that supports image classification and
segmentation across diverse optical systems. To assist optical system design
before training, we estimate achievable model accuracy based on user-specified
constraints such as physical size and the dataset. For training, we introduce
Neural Tangent Knowledge Distillation (NTKD), which aligns optical models with
electronic teacher networks, thereby narrowing the accuracy gap. After
fabrication, NTKD also guides fine-tuning of the digital backend to compensate
for implementation errors. Experiments on multiple datasets (e.g., MNIST,
CIFAR, Carvana Masking) and hardware configurations show that our pipeline
consistently improves ONN performance and enables practical deployment in both
pre-fabrication simulations and physical implementations.

</details>


### [46] [RealisMotion: Decomposed Human Motion Control and Video Generation in the World Space](https://arxiv.org/abs/2508.08588)
*Jingyun Liang,Jingkai Zhou,Shikai Li,Chenjie Cao,Lei Sun,Yichen Qian,Weihua Chen,Fan Wang*

Main category: cs.CV

TL;DR: 本文提出了一种分解式人体运动控制与视频生成框架，实现了对前景主体、背景视频、人体轨迹和动作模式的独立控制，从而能够灵活组合这些元素生成高质量视频。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成方法在视觉上引人注目，但缺乏对前景主体、背景视频、人体轨迹和动作模式这四个关键视频元素的独立控制。

Method: 该框架将运动与外观、主体与背景、动作与轨迹明确解耦。首先，建立一个地面感知的3D世界坐标系，在3D空间中进行运动编辑。轨迹控制通过将2D轨迹反投影到3D空间（结合焦距校准和坐标变换），并进行速度对齐和方向调整实现；动作则可从动作库获取或通过文本到动作方法生成。然后，基于文本到视频扩散Transformer模型，将主体作为token注入进行注意力计算，沿通道维度拼接背景，并通过加法添加运动（轨迹和动作）控制信号。

Result: 在基准数据集和真实世界案例上的广泛实验表明，该方法在元素级可控性和整体视频质量方面均达到了最先进的性能。它能够生成“任何人做任何事在任何地方”的逼真视频。

Conclusion: 所提出的分解式框架通过解耦并独立控制视频元素，极大地提升了人体视频生成的灵活性和可控性，实现了高质量且可自由组合的逼真人体视频生成。

Abstract: Generating human videos with realistic and controllable motions is a
challenging task. While existing methods can generate visually compelling
videos, they lack separate control over four key video elements: foreground
subject, background video, human trajectory and action patterns. In this paper,
we propose a decomposed human motion control and video generation framework
that explicitly decouples motion from appearance, subject from background, and
action from trajectory, enabling flexible mix-and-match composition of these
elements. Concretely, we first build a ground-aware 3D world coordinate system
and perform motion editing directly in the 3D space. Trajectory control is
implemented by unprojecting edited 2D trajectories into 3D with focal-length
calibration and coordinate transformation, followed by speed alignment and
orientation adjustment; actions are supplied by a motion bank or generated via
text-to-motion methods. Then, based on modern text-to-video diffusion
transformer models, we inject the subject as tokens for full attention,
concatenate the background along the channel dimension, and add motion
(trajectory and action) control signals by addition. Such a design opens up the
possibility for us to generate realistic videos of anyone doing anything
anywhere. Extensive experiments on benchmark datasets and real-world cases
demonstrate that our method achieves state-of-the-art performance on both
element-wise controllability and overall video quality.

</details>


### [47] [MAViS: A Multi-Agent Framework for Long-Sequence Video Storytelling](https://arxiv.org/abs/2508.08487)
*Qian Wang,Ziqi Huang,Ruoxi Jia,Paul Debevec,Ning Yu*

Main category: cs.CV

TL;DR: MAViS是一个多智能体协作框架，用于长序列视频故事生成，通过多阶段智能体协作和3E原则，解决了现有框架在辅助能力、视觉质量和表达力方面的局限性，实现了高质量的多模态视频输出。


<details>
  <summary>Details</summary>
Motivation: 现有的长序列视频生成框架存在辅助能力差、视觉质量不佳和表达力有限等显著局限性。

Method: MAViS采用端到端的多智能体协作框架，编排专门的智能体负责剧本创作、镜头设计、角色建模、关键帧生成、视频动画和音频生成。每个阶段的智能体都遵循“3E原则”（探索、审查和增强）以确保中间输出的完整性。此外，还提出了“剧本创作指南”以优化剧本与生成工具的兼容性。

Result: 实验结果表明，MAViS在辅助能力、视觉质量和视频表达力方面均达到了最先进的性能。其模块化框架使其能够与多样化的生成模型和工具进行扩展。MAViS仅需简短的用户提示即可生成高质量、富有表现力的长序列视频故事，并且是唯一提供多模态设计输出（带叙述和背景音乐的视频）的框架。

Conclusion: MAViS是一个开创性的框架，能够从简短的用户提示生成高质量、富有表现力的长序列视频故事，提供多模态设计输出，极大地丰富了用户的灵感和创造力。

Abstract: Despite recent advances, long-sequence video generation frameworks still
suffer from significant limitations: poor assistive capability, suboptimal
visual quality, and limited expressiveness. To mitigate these limitations, we
propose MAViS, an end-to-end multi-agent collaborative framework for
long-sequence video storytelling. MAViS orchestrates specialized agents across
multiple stages, including script writing, shot designing, character modeling,
keyframe generation, video animation, and audio generation. In each stage,
agents operate under the 3E Principle -- Explore, Examine, and Enhance -- to
ensure the completeness of intermediate outputs. Considering the capability
limitations of current generative models, we propose the Script Writing
Guidelines to optimize compatibility between scripts and generative tools.
Experimental results demonstrate that MAViS achieves state-of-the-art
performance in assistive capability, visual quality, and video expressiveness.
Its modular framework further enables scalability with diverse generative
models and tools. With just a brief user prompt, MAViS is capable of producing
high-quality, expressive long-sequence video storytelling, enriching
inspirations and creativity for users. To the best of our knowledge, MAViS is
the only framework that provides multimodal design output -- videos with
narratives and background music.

</details>


### [48] [MuGa-VTON: Multi-Garment Virtual Try-On via Diffusion Transformers with Prompt Customization](https://arxiv.org/abs/2508.08488)
*Ankan Deria,Dwarikanath Mahapatra,Behzad Bozorgtabar,Mohna Chakraborty,Snehashis Chakraborty,Sudipta Roy*

Main category: cs.CV

TL;DR: MuGa-VTON是一个统一的多服装扩散框架，用于虚拟试穿，能够同时处理上下装并保留个人身份，通过新的模块和扩散Transformer架构，在现实世界应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法通常分开处理上下装，需要大量预处理，并且未能很好地保留个人特有信息（如纹身、配饰、体型），导致真实感和灵活性不足。

Method: 提出了MuGa-VTON框架，它在共享潜在空间中联合建模上下装和个人身份。核心模块包括：服装表示模块（GRM）用于捕捉服装语义；人物表示模块（PRM）用于编码身份和姿态；以及A-DiT融合模块，通过扩散Transformer整合服装、人物和文本提示特征，支持基于提示的定制。

Result: 在VITON-HD和DressCode基准测试上，MuGa-VTON在定性和定量评估中均优于现有方法，生成了高保真度、保留身份的结果。

Conclusion: MuGa-VTON生成的图像高度逼真并保留个人身份，非常适用于现实世界的虚拟试穿应用。

Abstract: Virtual try-on seeks to generate photorealistic images of individuals in
desired garments, a task that must simultaneously preserve personal identity
and garment fidelity for practical use in fashion retail and personalization.
However, existing methods typically handle upper and lower garments separately,
rely on heavy preprocessing, and often fail to preserve person-specific cues
such as tattoos, accessories, and body shape-resulting in limited realism and
flexibility. To this end, we introduce MuGa-VTON, a unified multi-garment
diffusion framework that jointly models upper and lower garments together with
person identity in a shared latent space. Specifically, we proposed three key
modules: the Garment Representation Module (GRM) for capturing both garment
semantics, the Person Representation Module (PRM) for encoding identity and
pose cues, and the A-DiT fusion module, which integrates garment, person, and
text-prompt features through a diffusion transformer. This architecture
supports prompt-based customization, allowing fine-grained garment
modifications with minimal user input. Extensive experiments on the VITON-HD
and DressCode benchmarks demonstrate that MuGa-VTON outperforms existing
methods in both qualitative and quantitative evaluations, producing
high-fidelity, identity-preserving results suitable for real-world virtual
try-on applications.

</details>


### [49] [CObL: Toward Zero-Shot Ordinal Layering without User Prompting](https://arxiv.org/abs/2508.08498)
*Aneel Damaraju,Dean Hazineh,Todd Zickler*

Main category: cs.CV

TL;DR: 该论文提出了一种名为CObL的扩散模型，用于从图像中推断出由多个遮挡排序的“对象层”组成的场景表示，实现无提示、无预设对象数量的多对象非模态补全，并具有零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视觉系统通过将像素分组为对象并理解它们在横向和深度上的空间关系来获得优势。特别是在处理遮挡和实现非模态补全时，需要一种能够有效表示这些关系和完整对象形态的场景表示。

Method: 该研究采用一种场景表示，即由“对象层”组成的遮挡排序堆栈，每个层包含一个独立且非模态补全的对象。为推断此表示，引入了基于扩散的CObL架构，其利用Stable Diffusion作为自然对象先验，并通过推理时引导确保推断的层能够复合回输入图像。模型在数千张合成的多对象桌面场景图像上进行训练。

Result: CObL能够零样本泛化到包含不同数量新颖对象的真实世界桌面照片。与现有非模态对象补全模型不同，CObL无需用户提示或预先知道对象数量即可重建多个被遮挡对象。与之前的无监督对象中心表示学习模型不同，CObL不受限于其训练世界。

Conclusion: CObL成功地从图像中推断出一种有效的遮挡排序对象层表示，实现了多对象的非模态补全，并在无需额外输入或预知信息的情况下展现出强大的泛化能力，克服了现有方法的局限性。

Abstract: Vision benefits from grouping pixels into objects and understanding their
spatial relationships, both laterally and in depth. We capture this with a
scene representation comprising an occlusion-ordered stack of "object layers,"
each containing an isolated and amodally-completed object. To infer this
representation from an image, we introduce a diffusion-based architecture named
Concurrent Object Layers (CObL). CObL generates a stack of object layers in
parallel, using Stable Diffusion as a prior for natural objects and
inference-time guidance to ensure the inferred layers composite back to the
input image. We train CObL using a few thousand synthetically-generated images
of multi-object tabletop scenes, and we find that it zero-shot generalizes to
photographs of real-world tabletops with varying numbers of novel objects. In
contrast to recent models for amodal object completion, CObL reconstructs
multiple occluded objects without user prompting and without knowing the number
of objects beforehand. Unlike previous models for unsupervised object-centric
representation learning, CObL is not limited to the world it was trained in.

</details>


### [50] [Re:Verse -- Can Your VLM Read a Manga?](https://arxiv.org/abs/2508.08508)
*Aaditya Baranwal,Madhav Kataria,Naitik Agrawal,Yogesh S Rawat,Shruti Vyas*

Main category: cs.CV

TL;DR: 当前视觉语言模型（VLMs）在处理顺序视觉叙事（如漫画）时，在表面识别与深层叙事推理之间存在显著差距，尤其在时间因果关系和跨面板连贯性方面表现不佳。本文引入了一个新的评估框架，系统地揭示了这些局限性，并发现现有模型缺乏真正的故事级智能。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型（VLMs）在处理顺序视觉叙事（如漫画）时，虽然能很好地解释单个面板，但在深层叙事推理（如时间因果关系和跨面板连贯性）方面存在关键性缺陷。

Method: 引入了一个新颖的评估框架，该框架结合了：1) 精细的多模态标注，通过对齐的轻小说文本将视觉元素与叙事结构关联；2) 跨多种推理范式（直接推理和检索增强生成）的全面评估；3) 跨模态相似性分析，以揭示当前VLM联合表示中的根本性错位。该框架应用于《Re:Zero》漫画的11个章节（308个标注面板），通过生成式故事叙述、上下文对话接地和时间推理三个核心评估轴进行系统研究。

Result: 研究结果表明，当前模型缺乏真正的故事级智能，特别是在处理非线性叙事、角色一致性和跨长序列的因果推理方面表现挣扎。

Conclusion: 这项工作为评估叙事智能奠定了基础和实践方法，并为多模态模型在离散视觉叙事中超越基本识别的深度序列理解能力提供了可操作的见解。

Abstract: Current Vision Language Models (VLMs) demonstrate a critical gap between
surface-level recognition and deep narrative reasoning when processing
sequential visual storytelling. Through a comprehensive investigation of manga
narrative understanding, we reveal that while recent large multimodal models
excel at individual panel interpretation, they systematically fail at temporal
causality and cross-panel cohesion, core requirements for coherent story
comprehension. We introduce a novel evaluation framework that combines
fine-grained multimodal annotation, cross-modal embedding analysis, and
retrieval-augmented assessment to systematically characterize these
limitations.
  Our methodology includes (i) a rigorous annotation protocol linking visual
elements to narrative structure through aligned light novel text, (ii)
comprehensive evaluation across multiple reasoning paradigms, including direct
inference and retrieval-augmented generation, and (iii) cross-modal similarity
analysis revealing fundamental misalignments in current VLMs' joint
representations. Applying this framework to Re:Zero manga across 11 chapters
with 308 annotated panels, we conduct the first systematic study of long-form
narrative understanding in VLMs through three core evaluation axes: generative
storytelling, contextual dialogue grounding, and temporal reasoning. Our
findings demonstrate that current models lack genuine story-level intelligence,
struggling particularly with non-linear narratives, character consistency, and
causal inference across extended sequences. This work establishes both the
foundation and practical methodology for evaluating narrative intelligence,
while providing actionable insights into the capability of deep sequential
understanding of Discrete Visual Narratives beyond basic recognition in
Multimodal Models.

</details>


### [51] [VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models](https://arxiv.org/abs/2508.08521)
*Mansi Phute,Ravikumar Balakrishnan*

Main category: cs.CV

TL;DR: VISOR是一种通过优化视觉输入实现VLM行为控制的新方法，它通过生成引导图像诱导目标激活模式，无需模型内部访问，且比现有方法更有效和隐蔽，同时也揭示了视觉通道的潜在安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有VLM行为控制方法（如系统提示）易于检测且效果不佳；基于激活的引导向量需要侵入式运行时访问模型内部，不适用于API服务和闭源部署。因此，需要一种更实用、有效且隐蔽的行为控制方法。

Method: 引入VISOR方法，该方法通过仅优化视觉输入来实现复杂的行为控制。具体而言，它通过精心制作能诱导目标激活模式的通用引导图像，使VLM实现行为转向，且与显式文本指令相比不易察觉。

Result: 在LLaVA-1.5-7B上，单个150KB的引导图像在正向行为转变上与引导向量性能相近（1-2%差距），但在负向引导上远超引导向量，可实现高达25%的基线转变。与系统提示（3-4%转变）相比，VISOR提供强大的双向控制，同时在14,000个不相关的MMLU任务上保持99.9%的性能。此外，VISOR消除了运行时开销和模型访问要求，并揭示了攻击者仅通过视觉通道即可实现复杂行为操纵的安全漏洞。

Conclusion: VISOR从根本上重塑了多模态模型的控制方式，通过视觉输入实现了强大且隐蔽的行为操纵。同时，它也突显了针对视觉引导攻击进行防御的紧迫需求。

Abstract: Vision Language Models (VLMs) are increasingly being used in a broad range of
applications, bringing their security and behavioral control to the forefront.
While existing approaches for behavioral control or output redirection, like
system prompting in VLMs, are easily detectable and often ineffective,
activation-based steering vectors require invasive runtime access to model
internals--incompatible with API-based services and closed-source deployments.
We introduce VISOR (Visual Input-based Steering for Output Redirection), a
novel method that achieves sophisticated behavioral control through optimized
visual inputs alone. By crafting universal steering images that induce target
activation patterns, VISOR enables practical deployment across all VLM serving
modalities while remaining imperceptible compared to explicit textual
instructions. We validate VISOR on LLaVA-1.5-7B across three critical alignment
tasks: refusal, sycophancy and survival instinct. A single 150KB steering image
matches steering vector performance within 1-2% for positive behavioral shifts
while dramatically exceeding it for negative steering--achieving up to 25%
shifts from baseline compared to steering vectors' modest changes. Unlike
system prompting (3-4% shifts), VISOR provides robust bidirectional control
while maintaining 99.9% performance on 14,000 unrelated MMLU tasks. Beyond
eliminating runtime overhead and model access requirements, VISOR exposes a
critical security vulnerability: adversaries can achieve sophisticated
behavioral manipulation through visual channels alone, bypassing text-based
defenses. Our work fundamentally re-imagines multimodal model control and
highlights the urgent need for defenses against visual steering attacks.

</details>


### [52] [Training Kindai OCR with parallel textline images and self-attention feature distance-based loss](https://arxiv.org/abs/2508.08537)
*Anh Le,Asanobu Kitamoto*

Main category: cs.CV

TL;DR: 本研究通过利用并行文本行图像（近代文本与现代字体对应），并引入基于距离的目标函数（如欧氏距离和MMD）来缩小自注意力特征差距，从而增强训练数据集，显著提升了近代文献OCR系统的性能。


<details>
  <summary>Details</summary>
Motivation: 近代文献具有重要历史价值，但其转录工作耗时耗力，导致用于训练OCR系统的标注数据稀缺，限制了OCR技术在该领域的应用和发展。

Method: 利用并行文本行图像（原始近代文本及其现代日文字体对应）来扩充训练数据集。引入一种基于距离的目标函数，旨在最小化并行图像对自注意力特征之间的差距。具体探索了欧氏距离和最大均值差异（MMD）作为域适应度量。

Result: 实验结果表明，该方法在Transformer-based OCR基线上，使用欧氏距离和MMD分别将字符错误率（CER）降低了2.23%和3.94%。此外，该方法还提高了自注意力表示的判别质量。

Conclusion: 该方法通过有效解决数据稀缺问题并提升自注意力表示的判别能力，显著改善了历史文献的OCR性能，为近代文献的数字化提供了更有效的解决方案。

Abstract: Kindai documents, written in modern Japanese from the late 19th to early 20th
century, hold significant historical value for researchers studying societal
structures, daily life, and environmental conditions of that period. However,
transcribing these documents remains a labor-intensive and time-consuming task,
resulting in limited annotated data for training optical character recognition
(OCR) systems. This research addresses this challenge of data scarcity by
leveraging parallel textline images - pairs of original Kindai text and their
counterparts in contemporary Japanese fonts - to augment training datasets. We
introduce a distance-based objective function that minimizes the gap between
self-attention features of the parallel image pairs. Specifically, we explore
Euclidean distance and Maximum Mean Discrepancy (MMD) as domain adaptation
metrics. Experimental results demonstrate that our method reduces the character
error rate (CER) by 2.23% and 3.94% over a Transformer-based OCR baseline when
using Euclidean distance and MMD, respectively. Furthermore, our approach
improves the discriminative quality of self-attention representations, leading
to more effective OCR performance for historical documents.

</details>


### [53] [Calibration Attention: Instance-wise Temperature Scaling for Vision Transformers](https://arxiv.org/abs/2508.08547)
*Wenhao Liang,Wei Emma Zhang,Lin Yue,Miao Xu,Olaf Maennel,Weitong Chen*

Main category: cs.CV

TL;DR: 本文提出CalAttn模块，为视觉Transformer提供自适应的逐实例温度标定，显著降低校准误差，同时保持高效率和低参数量。


<details>
  <summary>Details</summary>
Motivation: 在风险敏感应用中，视觉Transformer的概率校准至关重要。传统的温度标定方法使用单一全局标量且需要独立的验证集，存在局限性。

Method: 引入Calibration Attention (CalAttn)，这是一个可即插即用的模块，它直接从ViT的CLS token学习自适应的、逐实例的温度。

Result: 在CIFAR-10/100、MNIST、Tiny-ImageNet和ImageNet-1K等数据集上，CalAttn将ViT-224、DeiT和Swin模型的校准误差降低了高达4倍，而额外参数量不到0.1%。学习到的温度紧密聚集在1.0附近，与标准温度标定使用的较大全局值形成对比。

Conclusion: CalAttn简单、高效、与架构无关，能在不牺牲准确性的前提下，提供更值得信赖的概率输出。

Abstract: Probability calibration is critical when Vision Transformers are deployed in
risk-sensitive applications. The standard fix, post-hoc temperature scaling,
uses a single global scalar and requires a held-out validation set. We
introduce Calibration Attention (CalAttn), a drop-in module that learns an
adaptive, per-instance temperature directly from the ViT's CLS token. Across
CIFAR-10/100, MNIST, Tiny-ImageNet, and ImageNet-1K, CalAttn reduces
calibration error by up to 4x on ViT-224, DeiT, and Swin, while adding under
0.1 percent additional parameters. The learned temperatures cluster tightly
around 1.0, in contrast to the large global values used by standard temperature
scaling. CalAttn is simple, efficient, and architecture-agnostic, and yields
more trustworthy probabilities without sacrificing accuracy. Code:
[https://github.com/EagleAdelaide/CalibrationAttention-CalAttn-](https://github.com/EagleAdelaide/CalibrationAttention-CalAttn-)

</details>


### [54] [Boosting Generic Semi-Supervised Medical Image Segmentation via Diverse Teaching and Label Propagation](https://arxiv.org/abs/2508.08549)
*Wei Li,Pengcheng Zhou,Linye Ma,Wenyi Zhao,Huihua Yang*

Main category: cs.CV

TL;DR: 针对医疗图像分割中有限标注和域偏移的挑战，本文提出一个通用框架DTLP-Net，通过生成可靠伪标签和增加模型多样性，同时处理半监督、半监督域泛化和无监督域适应任务。


<details>
  <summary>Details</summary>
Motivation: 医疗图像分割常面临标注数据有限和域偏移问题，导致半监督医疗图像分割 (SSMIS)、半监督医疗域泛化 (Semi-MDG) 和无监督医疗域适应 (UMDA) 等场景。现有方法通常孤立地解决特定任务，存在误差累积，未能有效利用无标注数据，导致性能不佳。

Method: 本文提出一个通用框架——多样化教学和标签传播网络 (DTLP-Net)。该网络包含一个学生模型和两个多样化的教师模型，用于生成可靠的伪标签：第一个教师模型解耦有标签和无标签数据的训练过程，第二个教师模型通过周期性动量更新产生多样性伪标签。此外，采用样本间和样本内数据增强来学习全局和局部知识，并引入标签传播以增强模型对体素级别相关性的捕获和鲁棒性。

Result: 在五个基准数据集上对SSMIS、UMDA和Semi-MDG任务进行评估。结果显示，与最先进的方法相比，该框架在所有五种设置下都取得了显著改进。

Conclusion: 所提出的框架在处理医疗图像分割中有限标注和域偏移的复杂半监督场景方面表现出巨大潜力，能够有效解决SSMIS、UMDA和Semi-MDG等多种任务。

Abstract: Both limited annotation and domain shift are significant challenges
frequently encountered in medical image segmentation, leading to derivative
scenarios like semi-supervised medical (SSMIS), semi-supervised medical domain
generalization (Semi-MDG) and unsupervised medical domain adaptation (UMDA).
Conventional methods are generally tailored to specific tasks in isolation, the
error accumulation hinders the effective utilization of unlabeled data and
limits further improvements, resulting in suboptimal performance when these
issues occur. In this paper, we aim to develop a generic framework that masters
all three tasks. We found that the key to solving the problem lies in how to
generate reliable pseudo labels for the unlabeled data in the presence of
domain shift with labeled data and increasing the diversity of the model. To
tackle this issue, we employ a Diverse Teaching and Label Propagation Network
(DTLP-Net) to boosting the Generic Semi-Supervised Medical Image Segmentation.
Our DTLP-Net involves a single student model and two diverse teacher models,
which can generate reliable pseudo-labels for the student model. The first
teacher model decouple the training process with labeled and unlabeled data,
The second teacher is momentum-updated periodically, thus generating reliable
yet divers pseudo-labels. To fully utilize the information within the data, we
adopt inter-sample and intra-sample data augmentation to learn the global and
local knowledge. In addition, to further capture the voxel-level correlations,
we propose label propagation to enhance the model robust. We evaluate our
proposed framework on five benchmark datasets for SSMIS, UMDA, and Semi-MDG
tasks. The results showcase notable improvements compared to state-of-the-art
methods across all five settings, indicating the potential of our framework to
tackle more challenging SSL scenarios.

</details>


### [55] [Unlocking the Potential of Diffusion Priors in Blind Face Restoration](https://arxiv.org/abs/2508.08556)
*Yunqi Miao,Zhiyu Qu,Mingqi Gao,Changrui Chen,Jifei Song,Jungong Han,Jiankang Deng*

Main category: cs.CV

TL;DR: 该论文提出了一种名为FLIPNET的统一网络，通过切换两种模式（修复模式和降质模式）来解决扩散模型在盲人脸修复（BFR）中遇到的高质量/低质量图像差异以及合成/真实世界图像降质模式不匹配的问题，从而提高了修复的真实性和保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在盲人脸修复（BFR）中应用时存在固有差距：1) 扩散模型通常在高质量图像上训练，而BFR处理的是中度到严重退化的图像；2) 训练中使用的低质量图像是基于简单降质模型合成的，无法模拟真实世界中复杂多变的降质模式，导致模型泛化能力不足。

Method: 本文提出了一个统一网络FLIPNET，它在两种模式之间切换以解决特定差距：1) 修复模式：模型逐渐整合BFR导向的特征和来自低质量图像的面部嵌入，以实现真实和忠实的人脸修复。2) 降质模式：模型基于从真实世界降质数据集中学习到的知识，合成类似真实世界的退化图像。

Result: 在基准数据集上的广泛评估表明，该模型1) 在真实性和保真度方面优于以前基于扩散先验的BFR方法；2) 在建模真实世界降质方面优于传统的简单降质模型。

Conclusion: FLIPNET通过其独特的双模式设计，成功弥合了扩散模型与盲人脸修复任务之间的差距，有效处理了图像质量差异和复杂真实世界降质问题，从而在人脸修复效果上取得了显著提升。

Abstract: Although diffusion prior is rising as a powerful solution for blind face
restoration (BFR), the inherent gap between the vanilla diffusion model and BFR
settings hinders its seamless adaptation. The gap mainly stems from the
discrepancy between 1) high-quality (HQ) and low-quality (LQ) images and 2)
synthesized and real-world images. The vanilla diffusion model is trained on
images with no or less degradations, whereas BFR handles moderately to severely
degraded images. Additionally, LQ images used for training are synthesized by a
naive degradation model with limited degradation patterns, which fails to
simulate complex and unknown degradations in real-world scenarios. In this
work, we use a unified network FLIPNET that switches between two modes to
resolve specific gaps. In Restoration mode, the model gradually integrates
BFR-oriented features and face embeddings from LQ images to achieve authentic
and faithful face restoration. In Degradation mode, the model synthesizes
real-world like degraded images based on the knowledge learned from real-world
degradation datasets. Extensive evaluations on benchmark datasets show that our
model 1) outperforms previous diffusion prior based BFR methods in terms of
authenticity and fidelity, and 2) outperforms the naive degradation model in
modeling the real-world degradations.

</details>


### [56] [Think as Cardiac Sonographers: Marrying SAM with Left Ventricular Indicators Measurements According to Clinical Guidelines](https://arxiv.org/abs/2508.08566)
*Tuo Liu,Qinghan Yang,Yu Zhang,Rongjun Ge,Yang Chen,Guangquan Zhou*

Main category: cs.CV

TL;DR: AutoSAME是一个结合SAM强大视觉理解能力的框架，能同时进行左心室（LV）分割和关键点定位，从而实现符合临床指南的LV指标测量，解决了小训练数据集和现有视觉基础模型（VFM）在关键点识别上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LV自动量化算法因训练数据集小而难以捕获通用视觉表示；视觉基础模型（VFM）如SAM虽擅长分割，但无法识别对LV指标测量至关重要的关键解剖点。

Method: 提出AutoSAME框架，同时进行分割和地标定位。引入“滤波跨分支注意力”（FCBA），利用分割中的特征从频域增强关键点热图回归。提出“空间引导提示对齐”（SGPA），根据LV空间特性自动生成提示嵌入，利用先验空间知识提高预测精度。

Result: 在超声心动图数据集上的大量实验证明了AutoSAME每个设计的效率及其在LV分割、地标定位和指标测量方面的优越性。

Conclusion: AutoSAME成功地模仿了心脏超声医师的操作，实现了与临床指南一致的LV指标测量，并通过FCBA和SGPA优化了视觉表示和预测精度，解决了现有方法的局限性。

Abstract: Left ventricular (LV) indicator measurements following clinical
echocardiog-raphy guidelines are important for diagnosing cardiovascular
disease. Alt-hough existing algorithms have explored automated LV
quantification, they can struggle to capture generic visual representations due
to the normally small training datasets. Therefore, it is necessary to
introduce vision founda-tional models (VFM) with abundant knowledge. However,
VFMs represented by the segment anything model (SAM) are usually suitable for
segmentation but incapable of identifying key anatomical points, which are
critical in LV indicator measurements. In this paper, we propose a novel
framework named AutoSAME, combining the powerful visual understanding of SAM
with seg-mentation and landmark localization tasks simultaneously.
Consequently, the framework mimics the operation of cardiac sonographers,
achieving LV indi-cator measurements consistent with clinical guidelines. We
further present fil-tered cross-branch attention (FCBA) in AutoSAME, which
leverages relatively comprehensive features in the segmentation to enhance the
heatmap regression (HR) of key points from the frequency domain perspective,
optimizing the vis-ual representation learned by the latter. Moreover, we
propose spatial-guided prompt alignment (SGPA) to automatically generate prompt
embeddings guid-ed by spatial properties of LV, thereby improving the accuracy
of dense pre-dictions by prior spatial knowledge. The extensive experiments on
an echocar-diography dataset demonstrate the efficiency of each design and the
superiori-ty of our AutoSAME in LV segmentation, landmark localization, and
indicator measurements. The code will be available at
https://github.com/QC-LIU-1997/AutoSAME.

</details>


### [57] [Superclass-Guided Representation Disentanglement for Spurious Correlation Mitigation](https://arxiv.org/abs/2508.08570)
*Chenruo Liu,Hongjun Liu,Zeyu Lai,Yiqiu Shen,Chen Zhao,Qi Lei*

Main category: cs.CV

TL;DR: 该研究提出一种新方法，通过利用类别标签中的超类语义信息，并结合预训练的视觉-语言模型和基于梯度的注意力机制，来解耦特征并增强模型对虚假相关性的鲁棒性，且无需辅助标注，在域泛化任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有增强群组鲁棒性以对抗虚假相关性的方法，通常依赖辅助标注或假设源域和目标域拥有相同的群组设置，这在现实世界中既不自然也不实用。

Method: 该方法利用类别标签中固有的语义结构（特别是超类信息），通过预训练的视觉-语言模型引导的基于梯度的注意力机制，来解耦与超类相关和不相关的特征。随后，通过促进模型使用所有与超类相关的特征进行预测，从而在无需任何源样本标注的情况下，实现对更复杂虚假相关性的鲁棒性。

Result: 在多样化数据集上的实验表明，该方法在域泛化任务中显著优于现有基线方法，并在定量指标和定性可视化方面均取得了明显提升。

Conclusion: 该方法通过利用类别语义结构和视觉-语言模型的引导，成功克服了传统鲁棒性方法对辅助标注和特定域设置的依赖，提供了一种更实用、有效的对抗虚假相关性的解决方案，显著提升了模型在域泛化任务中的性能。

Abstract: To enhance group robustness to spurious correlations, prior work often relies
on auxiliary annotations for groups or spurious features and assumes identical
sets of groups across source and target domains. These two requirements are
both unnatural and impractical in real-world settings. To overcome these
limitations, we propose a method that leverages the semantic structure inherent
in class labels--specifically, superclass information--to naturally reduce
reliance on spurious features. Our model employs gradient-based attention
guided by a pre-trained vision-language model to disentangle
superclass-relevant and irrelevant features. Then, by promoting the use of all
superclass-relevant features for prediction, our approach achieves robustness
to more complex spurious correlations without the need to annotate any source
samples. Experiments across diverse datasets demonstrate that our method
significantly outperforms baselines in domain generalization tasks, with clear
improvements in both quantitative metrics and qualitative visualizations.

</details>


### [58] [DocThinker: Explainable Multimodal Large Language Models with Rule-based Reinforcement Learning for Document Understanding](https://arxiv.org/abs/2508.08589)
*Wenwen Yu,Zhibo Yang,Yuliang Liu,Xiang Bai*

Main category: cs.CV

TL;DR: DocThinker是一个基于强化学习的框架，旨在解决多模态大语言模型（MLLMs）在文档理解中推理过程不透明的问题，通过动态推理和可解释的中间结果，显著提升模型的泛化能力、适应性和透明度，并缓解灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在文档理解中表现出色，但其推理过程是“黑箱”，在高风险领域（如法律、金融、医疗）难以保证可靠性和可信度。现有基于固定思维链（CoT）和监督微调（SFT）的方法存在灾难性遗忘、适应性差和跨领域任务泛化能力有限等问题。

Method: 本文提出了DocThinker，一个基于规则的强化学习（RL）框架，用于动态推理时推理。它通过策略学习自主优化推理策略，而非依赖静态CoT模板，生成可解释的中间结果，包括结构化推理过程、重述的问题、支持答案的感兴趣区域（RoI）和最终答案。通过整合多目标规则奖励和KL约束优化，该方法减轻了灾难性遗忘，并增强了适应性和透明度。

Result: 在多个基准测试上的大量实验表明，DocThinker显著提高了泛化能力，同时产生了更具解释性和人类可理解的推理步骤。

Conclusion: 研究结果强调，强化学习是增强基于MLLM的文档理解模型可解释性和适应性的强大替代方案。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in document understanding. However, their reasoning processes
remain largely black-box, making it difficult to ensure reliability and
trustworthiness, especially in high-stakes domains such as legal, financial,
and medical document analysis. Existing methods use fixed Chain-of-Thought
(CoT) reasoning with supervised fine-tuning (SFT) but suffer from catastrophic
forgetting, poor adaptability, and limited generalization across domain tasks.
In this paper, we propose DocThinker, a rule-based Reinforcement Learning (RL)
framework for dynamic inference-time reasoning. Instead of relying on static
CoT templates, DocThinker autonomously refines reasoning strategies via policy
learning, generating explainable intermediate results, including structured
reasoning processes, rephrased questions, regions of interest (RoI) supporting
the answer, and the final answer. By integrating multi-objective rule-based
rewards and KL-constrained optimization, our method mitigates catastrophic
forgetting and enhances both adaptability and transparency. Extensive
experiments on multiple benchmarks demonstrate that DocThinker significantly
improves generalization while producing more explainable and
human-understandable reasoning steps. Our findings highlight RL as a powerful
alternative for enhancing explainability and adaptability in MLLM-based
document understanding. Code will be available at
https://github.com/wenwenyu/DocThinker.

</details>


### [59] [QueryCraft: Transformer-Guided Query Initialization for Enhanced Human-Object Interaction Detection](https://arxiv.org/abs/2508.08590)
*Yuxiao Wang,Wolin Liang,Yu Lei,Weiying Xue,Nan Zhuang,Qi Liu*

Main category: cs.CV

TL;DR: QueryCraft是一种新颖的可插拔HOI检测框架，通过引入语义先验和引导式特征学习，解决了基于DETR的方法中随机初始化查询缺乏语义的问题，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于DETR的人-物交互（HOI）检测方法存在关键局限性：随机初始化的查询缺乏明确的语义信息，导致检测性能不佳。

Method: 本文提出QueryCraft框架，包含两个核心组件：1) ACTOR (Action-aware Cross-modal Transformer)，一个跨模态Transformer编码器，联合关注视觉区域和文本提示以提取动作相关特征，通过语言引导注意力推断交互语义并生成有意义的查询表示。2) PDQD (Perceptual Distilled Query Decoder)，从预训练检测器中提取对象类别感知信息，用于对象查询初始化。这种双分支查询初始化机制旨在生成更具可解释性和有效性的查询。

Result: 在HICO-Det和V-COCO基准测试上进行了广泛实验，结果表明该方法取得了最先进的性能和强大的泛化能力。

Conclusion: 通过引入语义先验和引导式特征学习，QueryCraft框架有效地解决了DETR基HOI检测中查询语义不足的问题，显著提升了HOI检测的性能和解释性。

Abstract: Human-Object Interaction (HOI) detection aims to localize human-object pairs
and recognize their interactions in images. Although DETR-based methods have
recently emerged as the mainstream framework for HOI detection, they still
suffer from a key limitation: Randomly initialized queries lack explicit
semantics, leading to suboptimal detection performance. To address this
challenge, we propose QueryCraft, a novel plug-and-play HOI detection framework
that incorporates semantic priors and guided feature learning through
transformer-based query initialization. Central to our approach is
\textbf{ACTOR} (\textbf{A}ction-aware \textbf{C}ross-modal
\textbf{T}ransf\textbf{OR}mer), a cross-modal Transformer encoder that jointly
attends to visual regions and textual prompts to extract action-relevant
features. Rather than merely aligning modalities, ACTOR leverages
language-guided attention to infer interaction semantics and produce
semantically meaningful query representations. To further enhance object-level
query quality, we introduce a \textbf{P}erceptual \textbf{D}istilled
\textbf{Q}uery \textbf{D}ecoder (\textbf{PDQD}), which distills object category
awareness from a pre-trained detector to serve as object query initiation. This
dual-branch query initialization enables the model to generate more
interpretable and effective queries for HOI detection. Extensive experiments on
HICO-Det and V-COCO benchmarks demonstrate that our method achieves
state-of-the-art performance and strong generalization. Code will be released
upon publication.

</details>


### [60] [Yan: Foundational Interactive Video Generation](https://arxiv.org/abs/2508.08601)
*Yan Team*

Main category: cs.CV

TL;DR: Yan是一个用于交互式视频生成的综合性基础框架，涵盖了模拟、生成和编辑的整个流程。


<details>
  <summary>Details</summary>
Motivation: 现有的交互式视频生成能力较为孤立，缺乏一个全面的AI驱动的交互式创作范式。

Method: Yan框架包含三个核心模块：1) AAA级模拟：设计了高度压缩、低延迟的3D-VAE结合基于KV缓存的移窗去噪推理过程，实现实时1080P/60FPS交互模拟。2) 多模态生成：引入分层自回归字幕方法，将游戏特定知识注入开放域多模态视频扩散模型(VDM)，使其成为帧级、动作可控、实时无限交互视频生成器。3) 多粒度编辑：提出混合模型，显式分离交互机制模拟与视觉渲染，通过文本实现交互过程中的多粒度视频内容编辑。

Result: Yan实现了实时1080P/60FPS的交互式模拟，在多模态生成中展示出强大的泛化能力，能够灵活地融合和组合不同领域风格和机制。同时，它支持在交互过程中进行多粒度视频内容编辑。

Conclusion: Yan框架通过集成模拟、生成和编辑模块，将交互式视频生成从孤立能力推向全面的AI驱动交互式创作范式，为下一代创意工具、媒体和娱乐奠定了基础。

Abstract: We present Yan, a foundational framework for interactive video generation,
covering the entire pipeline from simulation and generation to editing.
Specifically, Yan comprises three core modules. AAA-level Simulation: We design
a highly-compressed, low-latency 3D-VAE coupled with a KV-cache-based
shift-window denoising inference process, achieving real-time 1080P/60FPS
interactive simulation. Multi-Modal Generation: We introduce a hierarchical
autoregressive caption method that injects game-specific knowledge into
open-domain multi-modal video diffusion models (VDMs), then transforming the
VDM into a frame-wise, action-controllable, real-time infinite interactive
video generator. Notably, when the textual and visual prompts are sourced from
different domains, the model demonstrates strong generalization, allowing it to
blend and compose the style and mechanics across domains flexibly according to
user prompts. Multi-Granularity Editing: We propose a hybrid model that
explicitly disentangles interactive mechanics simulation from visual rendering,
enabling multi-granularity video content editing during interaction through
text. Collectively, Yan offers an integration of these modules, pushing
interactive video generation beyond isolated capabilities toward a
comprehensive AI-driven interactive creation paradigm, paving the way for the
next generation of creative tools, media, and entertainment. The project page
is: https://greatx3.github.io/Yan/.

</details>


### [61] [Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization](https://arxiv.org/abs/2508.08604)
*Jihwan Park,Taehoon song,Sanghyeok Lee,Miso Choi,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 提出TransMiter，一种轻量级、模型无关的适配器，无需反向传播即可在不同视觉语言模型（VLM）之间高效迁移适应性知识，同时保持泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型VLM微调成本高昂，现有适应性知识迁移方法因其模型特定设计和高计算需求，导致跨模型可迁移性有限，无法有效重用“弱”模型的适应知识来提升“强”模型。

Method: 提出Transferable Model-agnostic adapter (TransMiter)，它是一种轻量级适配器，以“无监督”方式捕获预训练和微调VLM之间的知识差距。一旦训练完成，该知识可以在不同模型之间无缝迁移，无需反向传播。TransMiter仅包含少量层，推理成本可忽略不计。此外，结合少量标注数据可进一步提升性能，甚至超越微调的更强模型，且训练成本极低。

Result: 实验结果表明，TransMiter能够有效且高效地在不同尺寸和架构的VLM之间迁移适应性知识，同时保持其在视觉识别任务中的泛化能力。结合少量标注数据可实现显著的性能提升，甚至超越微调的更强模型。

Conclusion: TransMiter提供了一种有效且高效的解决方案，用于在不同视觉语言模型之间迁移适应性知识，解决了现有方法在跨模型可迁移性和计算成本方面的局限性，实现了“无需反向传播”的模型提升。

Abstract: Vision-Language Models (VLMs) have been widely used in various visual
recognition tasks due to their remarkable generalization capabilities. As these
models grow in size and complexity, fine-tuning becomes costly, emphasizing the
need to reuse adaptation knowledge from 'weaker' models to efficiently enhance
'stronger' ones. However, existing adaptation transfer methods exhibit limited
transferability across models due to their model-specific design and high
computational demands. To tackle this, we propose Transferable Model-agnostic
adapter (TransMiter), a light-weight adapter that improves vision-language
models 'without backpropagation'. TransMiter captures the knowledge gap between
pre-trained and fine-tuned VLMs, in an 'unsupervised' manner. Once trained,
this knowledge can be seamlessly transferred across different models without
the need for backpropagation. Moreover, TransMiter consists of only a few
layers, inducing a negligible additional inference cost. Notably, supplementing
the process with a few labeled data further yields additional performance gain,
often surpassing a fine-tuned stronger model, with a marginal training cost.
Experimental results and analyses demonstrate that TransMiter effectively and
efficiently transfers adaptation knowledge while preserving generalization
abilities across VLMs of different sizes and architectures in visual
recognition tasks.

</details>


### [62] [SelfHVD: Self-Supervised Handheld Video Deblurring for Mobile Phones](https://arxiv.org/abs/2508.08605)
*Honglei Xu,Zhilu Zhang,Junjie Fan,Xiaohe Wu,Wangmeng Zuo*

Main category: cs.CV

TL;DR: 该论文提出了一种自监督的手持视频去模糊方法，利用视频中的清晰线索，通过数据增强和空间一致性维护来解决真实世界手持视频的模糊域差距问题。


<details>
  <summary>Details</summary>
Motivation: 手持手机拍摄的视频常因抖动导致模糊帧，现有视频去模糊方法在真实世界手持视频上表现不佳，因为训练和测试数据之间存在模糊域差距。

Method: 1. 提出自监督方法，从视频中提取清晰线索作为相邻模糊帧的错位标签来训练去模糊模型。2. 提出新型自增强视频去模糊（SEVD）方法，生成更高质量的配对视频数据以提升模型能力。3. 提出自约束空间一致性维护（SCSCM）方法，正则化模型以防止输出和输入帧之间的位置偏移。4. 构建了合成和真实世界手持视频数据集。

Result: 在自建数据集和其他常用真实世界数据集上的大量实验表明，该方法显著优于现有的自监督方法。

Conclusion: 该研究提供了一种有效且鲁棒的自监督手持视频去模糊方案，并通过公开代码和数据集促进了该领域的发展。

Abstract: Shooting video with a handheld mobile phone, the most common photographic
device, often results in blurry frames due to shaking hands and other
instability factors. Although previous video deblurring methods have achieved
impressive progress, they still struggle to perform satisfactorily on
real-world handheld video due to the blur domain gap between training and
testing data. To address the issue, we propose a self-supervised method for
handheld video deblurring, which is driven by sharp clues in the video. First,
to train the deblurring model, we extract the sharp clues from the video and
take them as misalignment labels of neighboring blurry frames. Second, to
improve the model's ability, we propose a novel Self-Enhanced Video Deblurring
(SEVD) method to create higher-quality paired video data. Third, we propose a
Self-Constrained Spatial Consistency Maintenance (SCSCM) method to regularize
the model, preventing position shifts between the output and input frames.
Moreover, we construct a synthetic and a real-world handheld video dataset for
handheld video deblurring. Extensive experiments on these two and other common
real-world datasets demonstrate that our method significantly outperforms
existing self-supervised ones. The code and datasets are publicly available at
https://github.com/cshonglei/SelfHVD.

</details>


### [63] [Neural Artistic Style and Color Transfer Using Deep Learning](https://arxiv.org/abs/2508.08608)
*Justin London*

Main category: cs.CV

TL;DR: 该研究结合了神经艺术风格迁移和色彩迁移，并使用KL散度定量评估了多种色彩和亮度直方图匹配算法在风格迁移中的效果。


<details>
  <summary>Details</summary>
Motivation: 神经艺术风格迁移能创造独特视觉效果，但色彩传递是数字图像处理的重要组成部分，能增强图像并辅助校正。本研究旨在将两者结合，并提供一种定量评估色彩匹配效果的方法。

Method: 引入了一种结合神经艺术风格迁移和色彩迁移的方法。使用Kullback-Leibler（KL）散度定量评估了Reinhard全局色彩迁移、迭代分布迁移（IDT）、带re-grain的IDT、Cholesky和PCA等色彩及亮度直方图匹配算法在原始图像和经神经艺术风格迁移后的图像之间的效果。同时估计了色彩通道的核密度。

Result: 通过各种实验评估了这些算法的KL散度及其色彩直方图在风格到内容迁移中的表现。

Conclusion: 该研究提供了一种结合神经艺术风格迁移与色彩迁移的新方法，并建立了基于KL散度的定量评估框架，用于比较不同色彩匹配算法在风格迁移上下文中的性能。

Abstract: Neural artistic style transfers and blends the content and style
representation of one image with the style of another. This enables artists to
create unique innovative visuals and enhances artistic expression in various
fields including art, design, and film. Color transfer algorithms are an
important in digital image processing by adjusting the color information in a
target image based on the colors in the source image. Color transfer enhances
images and videos in film and photography, and can aid in image correction. We
introduce a methodology that combines neural artistic style with color
transfer. The method uses the Kullback-Leibler (KL) divergence to
quantitatively evaluate color and luminance histogram matching algorithms
including Reinhard global color transfer, iteration distribution transfer
(IDT), IDT with regrain, Cholesky, and PCA between the original and neural
artistic style transferred image using deep learning. We estimate the color
channel kernel densities. Various experiments are performed to evaluate the KL
of these algorithms and their color histograms for style to content transfer.

</details>


### [64] [Hierarchical Visual Prompt Learning for Continual Video Instance Segmentation](https://arxiv.org/abs/2508.08612)
*Jiahua Dong,Hui Yin,Wenqi Liang,Hanbin Zhao,Henghui Ding,Nicu Sebe,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CV

TL;DR: 该论文提出了一种名为分层视觉提示学习（HVPL）的新模型，用于解决视频实例分割（VIS）中持续学习新类别时出现的灾难性遗忘问题，从帧级别和视频级别两个层面进行缓解。


<details>
  <summary>Details</summary>
Motivation: 现有的视频实例分割（VIS）方法普遍假设对象类别固定不变，并且在持续学习新类别时，会遭受旧类别知识的灾难性遗忘。

Method: 开发了HVPL模型。在帧级别，设计了任务特定的帧提示和正交梯度校正（OGC）模块，OGC通过将新类别的梯度投影到旧类别的正交特征空间来编码任务特定全局实例信息。在视频级别，设计了任务特定的视频提示和视频上下文解码器，该解码器将跨帧的类间结构关系嵌入到帧提示特征中，并将任务特定的全局视频上下文从帧提示特征传播到视频提示。

Result: 通过严格比较，HVPL模型被证明比基线方法更有效。

Conclusion: HVPL模型成功克服了视频实例分割中持续学习的灾难性遗忘问题，为处理不断演变的视频数据提供了有效方案。

Abstract: Video instance segmentation (VIS) has gained significant attention for its
capability in tracking and segmenting object instances across video frames.
However, most of the existing VIS approaches unrealistically assume that the
categories of object instances remain fixed over time. Moreover, they
experience catastrophic forgetting of old classes when required to continuously
learn object instances belonging to new categories. To resolve these
challenges, we develop a novel Hierarchical Visual Prompt Learning (HVPL) model
that overcomes catastrophic forgetting of previous categories from both
frame-level and video-level perspectives. Specifically, to mitigate forgetting
at the frame level, we devise a task-specific frame prompt and an orthogonal
gradient correction (OGC) module. The OGC module helps the frame prompt encode
task-specific global instance information for new classes in each individual
frame by projecting its gradients onto the orthogonal feature space of old
classes. Furthermore, to address forgetting at the video level, we design a
task-specific video prompt and a video context decoder. This decoder first
embeds structural inter-class relationships across frames into the frame prompt
features, and then propagates task-specific global video contexts from the
frame prompt features to the video prompt. Through rigorous comparisons, our
HVPL model proves to be more effective than baseline approaches. The code is
available at https://github.com/JiahuaDong/HVPL.

</details>


### [65] [AME: Aligned Manifold Entropy for Robust Vision-Language Distillation](https://arxiv.org/abs/2508.08644)
*Guiming Cao,Yuming Ou*

Main category: cs.CV

TL;DR: 针对视觉-语言模型（VLMs）在低数据量和高不确定性样本下知识蒸馏泛化能力差的问题，本文提出了AME（Aligned Manifold Entropy）方法，通过在重构的共享流形上进行熵最小化，实现鲁棒的跨模态知识蒸馏，且无需修改骨干网络。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言知识蒸馏（VLKD）通常需要大量训练数据才能在具有高预测不确定性的模糊或边界样本上实现鲁棒泛化。然而，在实际场景中收集大规模、任务特定的训练数据往往不切实际，这是不确定性和跨模态特征表示纠缠所带来的主要挑战。

Method: 本文提出对齐流形熵（AME）方法，通过一对投影函数将多模态数据（图像和文本）连接起来，在重构的共享流形上应用熵最小化，以实现跨模态特征表示的结构压缩。这使得在低数据量条件下也能进行鲁棒的知识蒸馏，且无需对骨干网络进行架构修改，可作为即插即用模块。

Result: 理论分析表明，将知识蒸馏与共享流形上的熵最小化相结合，可以获得更紧密的泛化误差界。在多种蒸馏架构和训练设置上的大量实验表明，AME持续促进鲁棒的知识蒸态，在广泛的下游任务中实现了卓越的泛化性能。

Conclusion: AME提供了一种在低数据量条件下实现鲁棒视觉-语言知识蒸馏的有效方法，通过对齐流形熵最小化，显著提高了模型在各种下游任务上的泛化性能，并能作为广泛视觉-语言蒸馏框架的即插即用模块。

Abstract: Knowledge distillation is a long-established technique for knowledge
transfer, and has regained attention in the context of the recent emergence of
large vision-language models (VLMs). However, vision-language knowledge
distillation often requires sufficient training data to achieve robust
generalization on amples with ambiguous or boundary-adjacent representations,
which are associated with high predictive uncertainty. Critically, collecting
such large-scale, task-specific data for training is often impractical in
real-world scenarios. To address this major challenge arising from the
entanglement of uncertainty and cross-modal feature representation, we propose
Aligned Manifold Entropy for Robust Vision-Language Distillation (AME), aiming
to achieve robust generalization under real-world conditions. AME applies
entropy minimization over a reconfigured shared manifold, where multi-modal
data (i.e., image and text) are bridged through a pair of projection functions,
conducive to structural compression for cross-modal feature representations.
This enables robust knowledge distillation under low-data regimes, while
requiring no architectural modifications to the backbone. As a result, it can
serve as a plug-and-play module compatible with a wide range of vision-language
distillation frameworks. Notably, our theoretical analysis reveals that
integrating knowledge distillation with entropy minimization over the shared
manifold leads to a tighter generalization error bound. Extensive experiments
across diverse distillation architectures and training settings demonstrate
that AME consistently facilitates robust knowledge distillation, resulting in
superior generalization performance across a wide spectrum of downstream tasks.

</details>


### [66] [Shape Completion and Real-Time Visualization in Robotic Ultrasound Spine Acquisitions](https://arxiv.org/abs/2508.08923)
*Miruna-Alexandra Gafencu,Reem Shaban,Yordanka Velikova,Mohammad Farid Azampour,Nassir Navab*

Main category: cs.CV

TL;DR: 该研究提出一个结合机器人超声和实时形状补全的新系统，以克服超声图像中脊柱结构被遮挡的问题，提供实时、交互式的完整脊柱解剖结构可视化。


<details>
  <summary>Details</summary>
Motivation: 超声成像在脊柱手术中因实时、无辐射而日益普及，但其有效性受阴影伪影阻碍，导致深层组织结构不清晰。传统CT-US配准方法存在复杂配准、脊柱曲度差异和需近期CT扫描的局限。现有形状补全方法多为离线且可复现性差。

Method: 开发了一个集成系统，结合机器人超声和实时形状补全。该系统通过机器人平台自主获取腰椎超声扫描，从超声数据中提取椎体表面，并利用基于深度学习的形状补全网络重建完整的解剖结构。

Result: 该框架提供了交互式、实时的可视化能力，并能自主重复扫描，有望实现目标位置导航。通过定量实验评估了形状补全的准确性，并在模型上评估了多种脊柱采集协议。此外，还展示了志愿者扫描的定性可视化结果。

Conclusion: 该系统能显著提高脊柱超声成像的一致性、可复现性和对解剖结构的理解，并可能辅助导航，从而提升脊柱手术的精度和安全性。

Abstract: Ultrasound (US) imaging is increasingly used in spinal procedures due to its
real-time, radiation-free capabilities; however, its effectiveness is hindered
by shadowing artifacts that obscure deeper tissue structures. Traditional
approaches, such as CT-to-US registration, incorporate anatomical information
from preoperative CT scans to guide interventions, but they are limited by
complex registration requirements, differences in spine curvature, and the need
for recent CT imaging. Recent shape completion methods can offer an alternative
by reconstructing spinal structures in US data, while being pretrained on large
set of publicly available CT scans. However, these approaches are typically
offline and have limited reproducibility. In this work, we introduce a novel
integrated system that combines robotic ultrasound with real-time shape
completion to enhance spinal visualization. Our robotic platform autonomously
acquires US sweeps of the lumbar spine, extracts vertebral surfaces from
ultrasound, and reconstructs the complete anatomy using a deep learning-based
shape completion network. This framework provides interactive, real-time
visualization with the capability to autonomously repeat scans and can enable
navigation to target locations. This can contribute to better consistency,
reproducibility, and understanding of the underlying anatomy. We validate our
approach through quantitative experiments assessing shape completion accuracy
and evaluations of multiple spine acquisition protocols on a phantom setup.
Additionally, we present qualitative results of the visualization on a
volunteer scan.

</details>


### [67] [Unified and Semantically Grounded Domain Adaptation for Medical Image Segmentation](https://arxiv.org/abs/2508.08660)
*Xin Wang,Yin Guo,Jiamin Xia,Kaiyu Zhang,Niranjan Balu,Mahmud Mossa-Basha,Linda Shapiro,Chun Yuan*

Main category: cs.CV

TL;DR: 提出一个统一的、语义驱动的框架，通过学习领域无关的概率流形来解决医学图像分割中无监督域适应（UDA）在有源和无源设置间的鸿沟，实现了最先进的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前医学图像分割中的无监督域适应方法在有源和无源设置之间存在显著差异，且缺乏一种能自然泛化跨领域和设置的显式、结构化解剖知识构建方法。

Method: 引入一个统一的、语义驱动的框架，其适应性源于模型架构本身，无需手动设计适应策略。该模型学习一个领域无关的概率流形作为解剖规律的全局空间，将图像结构内容解释为从流形中检索出的典型解剖结构和捕获个体特定几何的空间变换，实现了可解耦、可解释的固有适应性预测。

Result: 在心脏和腹部数据集上实现了两种设置下的最先进性能，其中无源设置的性能非常接近有源设置，表现出前所未有的高一致性。此外，通过流形遍历展示了该框架强大的可解释性。

Conclusion: 该统一框架通过构建领域无关的解剖知识流形，有效弥合了医学图像分割UDA在有源和无源设置之间的性能差距，实现了卓越的性能、一致性和可解释性，为未来的域适应研究提供了新范式。

Abstract: Most prior unsupervised domain adaptation approaches for medical image
segmentation are narrowly tailored to either the source-accessible setting,
where adaptation is guided by source-target alignment, or the source-free
setting, which typically resorts to implicit supervision mechanisms such as
pseudo-labeling and model distillation. This substantial divergence in
methodological designs between the two settings reveals an inherent flaw: the
lack of an explicit, structured construction of anatomical knowledge that
naturally generalizes across domains and settings. To bridge this longstanding
divide, we introduce a unified, semantically grounded framework that supports
both source-accessible and source-free adaptation. Fundamentally distinct from
all prior works, our framework's adaptability emerges naturally as a direct
consequence of the model architecture, without the need for any handcrafted
adaptation strategies. Specifically, our model learns a domain-agnostic
probabilistic manifold as a global space of anatomical regularities, mirroring
how humans establish visual understanding. Thus, the structural content in each
image can be interpreted as a canonical anatomy retrieved from the manifold and
a spatial transformation capturing individual-specific geometry. This
disentangled, interpretable formulation enables semantically meaningful
prediction with intrinsic adaptability. Extensive experiments on challenging
cardiac and abdominal datasets show that our framework achieves
state-of-the-art results in both settings, with source-free performance closely
approaching its source-accessible counterpart, a level of consistency rarely
observed in prior works. Beyond quantitative improvement, we demonstrate strong
interpretability of the proposed framework via manifold traversal for smooth
shape manipulation.

</details>


### [68] [Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding](https://arxiv.org/abs/2508.09032)
*Maxim A. Patratskiy,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.CV

TL;DR: 本文提出了一种通过视觉提示将关键点视觉轨迹投影到深度图上的方法，以同时整合视觉-语言-动作模型中的空间和时间信息，从而提高任务解决能力，尤其是在数据稀缺的真实世界应用中。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在预测智能体运动方面表现出色，但多侧重于独立增强空间或时间理解。研究动机在于开发一种能同时捕获这两种信息的统一方法，并使其适用于数据收集困难的真实世界应用。

Method: 引入了一种新颖的视觉提示方法，通过将观测中关键点的视觉轨迹投影到深度图上，使模型能够同时捕获空间和时间信息。

Result: 在SimplerEnv环境中的实验表明，与SpatialVLA相比，成功解决的任务平均数量增加了4%；与TraceVLA相比，增加了19%。此外，这种性能提升仅需最少的训练数据即可实现。

Conclusion: 所提出的视觉提示方法有效地整合了VLA模型中的空间和时间信息，显著提高了任务解决能力，且所需训练数据量小，这对于数据收集具有挑战性的真实世界应用尤为有价值。

Abstract: Vision-Language-Action models have demonstrated remarkable capabilities in
predicting agent movements within virtual environments and real-world scenarios
based on visual observations and textual instructions. Although recent research
has focused on enhancing spatial and temporal understanding independently, this
paper presents a novel approach that integrates both aspects through visual
prompting. We introduce a method that projects visual traces of key points from
observations onto depth maps, enabling models to capture both spatial and
temporal information simultaneously. The experiments in SimplerEnv show that
the mean number of tasks successfully solved increased for 4% compared to
SpatialVLA and 19% compared to TraceVLA. Furthermore, we show that this
enhancement can be achieved with minimal training data, making it particularly
valuable for real-world applications where data collection is challenging. The
project page is available at https://ampiromax.github.io/ST-VLA.

</details>


### [69] [Learning Generalizable and Efficient Image Watermarking via Hierarchical Two-Stage Optimization](https://arxiv.org/abs/2508.08667)
*Ke Liu,Xuanhan Wang,Qilong Zhang,Lianli Gao,Jingkuan Song*

Main category: cs.CV

TL;DR: 本文提出了一种名为分层水印学习（HiWL）的两阶段优化方法，旨在同时提升深度图像水印的隐蔽性、鲁棒性和广泛适用性，并取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有深度图像水印方法难以同时满足三个关键标准：1) 隐蔽性（水印不可察觉）；2) 鲁棒性（在不同条件下可靠恢复水印）；3) 广泛适用性（水印处理低延迟）。

Method: 提出了一种两阶段优化方法：分层水印学习（HiWL）。第一阶段是分布对齐学习，旨在建立一个公共潜在空间，并施加两个约束：水印图像与非水印图像之间的视觉一致性，以及水印潜在表示之间的信息不变性，以确保隐蔽性和鲁棒性。第二阶段是广义水印表示学习，旨在建立一种分离策略，将水印从RGB空间中的图像内容中解耦出来，并对相同消息对应的分离RGB水印的显著波动进行强惩罚，以保持广泛适用性。

Result: 实验结果表明，所提出的方法有效。特别地，它在水印提取精度上比现有方法高7.6%，同时保持了极低的延迟（10万张图像在8秒内处理完成）。

Conclusion: HiWL方法通过学习可推广的潜在空间水印表示，有效地解决了现有深度图像水印方法的局限性，同时在隐蔽性、鲁棒性和广泛适用性方面表现出色。

Abstract: Deep image watermarking, which refers to enable imperceptible watermark
embedding and reliable extraction in cover images, has shown to be effective
for copyright protection of image assets. However, existing methods face
limitations in simultaneously satisfying three essential criteria for
generalizable watermarking: 1) invisibility (imperceptible hide of watermarks),
2) robustness (reliable watermark recovery under diverse conditions), and 3)
broad applicability (low latency in watermarking process). To address these
limitations, we propose a Hierarchical Watermark Learning (HiWL), a two-stage
optimization that enable a watermarking model to simultaneously achieve three
criteria. In the first stage, distribution alignment learning is designed to
establish a common latent space with two constraints: 1) visual consistency
between watermarked and non-watermarked images, and 2) information invariance
across watermark latent representations. In this way, multi-modal inputs
including watermark message (binary codes) and cover images (RGB pixels) can be
well represented, ensuring the invisibility of watermarks and robustness in
watermarking process thereby. The second stage employs generalized watermark
representation learning to establish a disentanglement policy for separating
watermarks from image content in RGB space. In particular, it strongly
penalizes substantial fluctuations in separated RGB watermarks corresponding to
identical messages. Consequently, HiWL effectively learns generalizable
latent-space watermark representations while maintaining broad applicability.
Extensive experiments demonstrate the effectiveness of proposed method. In
particular, it achieves 7.6\% higher accuracy in watermark extraction than
existing methods, while maintaining extremely low latency (100K images
processed in 8s).

</details>


### [70] [MMIF-AMIN: Adaptive Loss-Driven Multi-Scale Invertible Dense Network for Multimodal Medical Image Fusion](https://arxiv.org/abs/2508.08679)
*Tao Luo,Weihua Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为MMIF-AMIN的新型多模态医学图像融合方法，通过独特且互补的特征提取以及自适应损失函数，显著提升了融合性能。


<details>
  <summary>Details</summary>
Motivation: 多模态医学图像融合（MMIF）旨在整合不同模态图像以增强诊断，但同时捕获各模态的独有和互补信息是关键挑战。

Method: MMIF-AMIN方法包含：1) 可逆密集网络（IDN）用于无损地提取单模态特征；2) 多尺度互补特征提取模块（MCFEM），结合混合注意力机制、不同尺寸卷积层和Transformer，用于提取模态间互补信息；3) 引入自适应损失函数以指导模型学习和深度数据挖掘。

Result: MMIF-AMIN在定量和定性分析中均优于九种最先进的MMIF方法。消融实验证实了各组件的有效性。此外，该方法在其他图像融合任务中也表现出良好性能。

Conclusion: MMIF-AMIN是一种有效且性能卓越的多模态医学图像融合方法，能够解决关键挑战，并具有扩展到其他图像融合任务的潜力。

Abstract: Multimodal medical image fusion (MMIF) aims to integrate images from
different modalities to produce a comprehensive image that enhances medical
diagnosis by accurately depicting organ structures, tissue textures, and
metabolic information. Capturing both the unique and complementary information
across multiple modalities simultaneously is a key research challenge in MMIF.
To address this challenge, this paper proposes a novel image fusion method,
MMIF-AMIN, which features a new architecture that can effectively extract these
unique and complementary features. Specifically, an Invertible Dense Network
(IDN) is employed for lossless feature extraction from individual modalities.
To extract complementary information between modalities, a Multi-scale
Complementary Feature Extraction Module (MCFEM) is designed, which incorporates
a hybrid attention mechanism, convolutional layers of varying sizes, and
Transformers. An adaptive loss function is introduced to guide model learning,
addressing the limitations of traditional manually-designed loss functions and
enhancing the depth of data mining. Extensive experiments demonstrate that
MMIF-AMIN outperforms nine state-of-the-art MMIF methods, delivering superior
results in both quantitative and qualitative analyses. Ablation experiments
confirm the effectiveness of each component of the proposed method.
Additionally, extending MMIF-AMIN to other image fusion tasks also achieves
promising performance.

</details>


### [71] [PADReg: Physics-Aware Deformable Registration Guided by Contact Force for Ultrasound Sequences](https://arxiv.org/abs/2508.08685)
*Yimeng Geng,Mingyang Zhao,Fan Xu,Guanglin Cao,Gaofeng Meng,Hongbin Liu*

Main category: cs.CV

TL;DR: 超声可变形配准面临大变形、低对比度等挑战。PADReg提出一种物理感知框架，利用接触力作为物理先验，结合图像信息构建刚度图，并通过类胡克定律估算形变场，实现更佳的物理合理性和解剖对齐，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 超声可变形配准在捕获生物力学特性和提高疾病诊断准确性方面至关重要，但面临巨大挑战，尤其在大变形下，图像固有的低对比度、高噪声和模糊边界严重阻碍可靠特征提取。现有方法常导致解剖对齐不佳且缺乏物理可解释性。

Method: 提出PADReg，一个由接触力引导的物理感知可变形配准框架。该方法利用机器人超声系统测量的同步接触力作为物理先验来约束配准。具体地，不直接预测形变场，而是首先利用接触力和超声图像的多模态信息构建像素级刚度图。随后，将刚度图与力数据结合，通过一个受胡克定律启发的轻量级物理感知模块，估算密集的形变场。

Result: 在体内数据集上的实验表明，PADReg的HD95指标为12.90，比现有最先进方法提高了21.34%。

Conclusion: PADReg通过引入接触力作为物理先验，实现了物理上更合理且解剖对齐更优的超声可变形配准，克服了以往仅依赖图像相似性方法的局限性。

Abstract: Ultrasound deformable registration estimates spatial transformations between
pairs of deformed ultrasound images, which is crucial for capturing
biomechanical properties and enhancing diagnostic accuracy in diseases such as
thyroid nodules and breast cancer. However, ultrasound deformable registration
remains highly challenging, especially under large deformation. The inherently
low contrast, heavy noise and ambiguous tissue boundaries in ultrasound images
severely hinder reliable feature extraction and correspondence matching.
Existing methods often suffer from poor anatomical alignment and lack physical
interpretability. To address the problem, we propose PADReg, a physics-aware
deformable registration framework guided by contact force. PADReg leverages
synchronized contact force measured by robotic ultrasound systems as a physical
prior to constrain the registration. Specifically, instead of directly
predicting deformation fields, we first construct a pixel-wise stiffness map
utilizing the multi-modal information from contact force and ultrasound images.
The stiffness map is then combined with force data to estimate a dense
deformation field, through a lightweight physics-aware module inspired by
Hooke's law. This design enables PADReg to achieve physically plausible
registration with better anatomical alignment than previous methods relying
solely on image similarity. Experiments on in-vivo datasets demonstrate that it
attains a HD95 of 12.90, which is 21.34\% better than state-of-the-art methods.
The source code is available at https://github.com/evelynskip/PADReg.

</details>


### [72] [ROD: RGB-Only Fast and Efficient Off-road Freespace Detection](https://arxiv.org/abs/2508.08697)
*Tong Sun,Hongliang Ye,Jilin Mei,Liang Chen,Fangzhou Zhao,Leiqiang Zong,Yu Hu*

Main category: cs.CV

TL;DR: 本文提出了一种名为ROD的纯RGB方法，用于越野自由空间检测，克服了多模态方法因LiDAR数据处理而导致的实时性问题，实现了更高的精度和推理速度，并成为新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 越野自由空间检测比公路场景更具挑战性，且现有最先进的多模态方法（RGB+LiDAR）在计算LiDAR表面法线图时推理时间显著增加，不适用于需要高帧率的实时应用。

Method: ROD是一种纯RGB方法，不依赖LiDAR数据。它利用预训练的Vision Transformer (ViT) 从RGB图像中提取丰富的特征，并设计了一个轻量级但高效的解码器，以提高精度和推理速度。

Result: ROD在ORFD和RELLIS-3D数据集上建立了新的最先进性能（SOTA），推理速度达到50 FPS，显著优于现有模型。

Conclusion: ROD证明了纯RGB方法在越野自由空间检测中可以实现高精度和实时性，克服了传统多模态方法的计算瓶颈，为实际应用提供了更高效的解决方案。

Abstract: Off-road freespace detection is more challenging than on-road scenarios
because of the blurred boundaries of traversable areas. Previous
state-of-the-art (SOTA) methods employ multi-modal fusion of RGB images and
LiDAR data. However, due to the significant increase in inference time when
calculating surface normal maps from LiDAR data, multi-modal methods are not
suitable for real-time applications, particularly in real-world scenarios where
higher FPS is required compared to slow navigation. This paper presents a novel
RGB-only approach for off-road freespace detection, named ROD, eliminating the
reliance on LiDAR data and its computational demands. Specifically, we utilize
a pre-trained Vision Transformer (ViT) to extract rich features from RGB
images. Additionally, we design a lightweight yet efficient decoder, which
together improve both precision and inference speed. ROD establishes a new SOTA
on ORFD and RELLIS-3D datasets, as well as an inference speed of 50 FPS,
significantly outperforming prior models.

</details>


### [73] [Subjective and Objective Quality Assessment of Banding Artifacts on Compressed Videos](https://arxiv.org/abs/2508.08700)
*Qi Zheng,Li-Heng Chen,Chenlong He,Neil Berkbeck,Yilin Wang,Balu Adsumilli,Alan C. Bovik,Yibo Fan,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 本文创建了一个新的视频带状伪影数据集LIVE-YT-Banding，并提出了一种高效的无参考视频质量评估器CBAND，其在带状伪影预测性能上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 尽管视频压缩技术取得了进展，但带状伪影（banding artifacts）仍严重影响压缩视频质量，尤其是在高清视频的平滑区域。现有用于研究带状伪影的公开数据集仅限于静态图像，无法捕捉时间动态，因此迫切需要对高级视频编解码器中的带状伪影视频质量评估问题进行系统性研究。

Method: 1. 创建了首个开放视频数据集LIVE-YT-Banding，包含160个使用AV1编解码器以四种不同压缩参数生成的视频。2. 从45名人类受试者收集了7,200个主观意见。3. 测试并比较了多种现有的带状伪影检测和感知质量测量模型。4. 引入了一种新的有效且高效的无参考（NR）视频质量评估器CBAND，该方法利用深度神经网络嵌入中表达的自然图像学习统计特性。

Result: 1. CBAND在感知带状伪影预测性能上显著优于现有最先进的模型。2. CBAND的速度比现有模型快几个数量级。3. CBAND可以作为可微分的损失函数，用于优化视频去带状伪影模型。4. LIVE-YT-Banding数据库、代码和预训练模型均已公开可用。

Conclusion: LIVE-YT-Banding数据集弥补了现有带状伪影研究中缺乏时间动态数据的空白。所提出的CBAND模型为无参考视频带状伪影质量评估提供了一个卓越且高效的解决方案，并能促进去带状伪影模型的开发与优化。

Abstract: Although there have been notable advancements in video compression
technologies in recent years, banding artifacts remain a serious issue
affecting the quality of compressed videos, particularly on smooth regions of
high-definition videos. Noticeable banding artifacts can severely impact the
perceptual quality of videos viewed on a high-end HDTV or high-resolution
screen. Hence, there is a pressing need for a systematic investigation of the
banding video quality assessment problem for advanced video codecs. Given that
the existing publicly available datasets for studying banding artifacts are
limited to still picture data only, which cannot account for temporal banding
dynamics, we have created a first-of-a-kind open video dataset, dubbed
LIVE-YT-Banding, which consists of 160 videos generated by four different
compression parameters using the AV1 video codec. A total of 7,200 subjective
opinions are collected from a cohort of 45 human subjects. To demonstrate the
value of this new resources, we tested and compared a variety of models that
detect banding occurrences, and measure their impact on perceived quality.
Among these, we introduce an effective and efficient new no-reference (NR)
video quality evaluator which we call CBAND. CBAND leverages the properties of
the learned statistics of natural images expressed in the embeddings of deep
neural networks. Our experimental results show that the perceptual banding
prediction performance of CBAND significantly exceeds that of previous
state-of-the-art models, and is also orders of magnitude faster. Moreover,
CBAND can be employed as a differentiable loss function to optimize video
debanding models. The LIVE-YT-Banding database, code, and pre-trained model are
all publically available at https://github.com/uniqzheng/CBAND.

</details>


### [74] [SafeFix: Targeted Model Repair via Controlled Image Generation](https://arxiv.org/abs/2508.08701)
*Ouyang Xu,Baoming Zhang,Ruiyu Mao,Yunhui Guo*

Main category: cs.CV

TL;DR: 该研究提出一种模型修复模块，通过利用可解释的故障归因管线和条件文本到图像模型生成语义准确且有针对性的合成图像，并使用大型视觉语言模型（LVLM）过滤，以修复深度学习模型在稀有语义子群体上的系统性错误。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在视觉识别中常因语义子群体代表性不足而出现系统性错误。现有调试框架虽能识别故障属性，但有效修复模型仍很困难。当前解决方案依赖手动设计的提示生成合成训练图像，这容易导致分布偏移和语义错误。

Method: 本研究基于一个可解释的故障归因管线，引入模型修复模块。它使用条件文本到图像模型为故障案例生成语义忠实且有针对性的图像。为保持生成样本的质量和相关性，进一步采用大型视觉语言模型（LVLM）进行过滤，以确保与原始数据分布对齐并保持语义一致性。最后，使用这个罕见案例增强的合成数据集重新训练视觉模型。

Result: 通过使用这种罕见案例增强的合成数据集重新训练视觉模型，显著减少了与罕见案例相关的错误。实验证明，这种有针对性的修复策略提高了模型鲁棒性，且没有引入新的错误。

Conclusion: 该研究表明，通过结合可解释的故障归因、有针对性的合成图像生成和LVLM过滤，可以有效地修复深度学习模型在稀有案例上的系统性错误，提高模型鲁棒性而不会引入新的缺陷。

Abstract: Deep learning models for visual recognition often exhibit systematic errors
due to underrepresented semantic subpopulations. Although existing debugging
frameworks can pinpoint these failures by identifying key failure attributes,
repairing the model effectively remains difficult. Current solutions often rely
on manually designed prompts to generate synthetic training images -- an
approach prone to distribution shift and semantic errors. To overcome these
challenges, we introduce a model repair module that builds on an interpretable
failure attribution pipeline. Our approach uses a conditional text-to-image
model to generate semantically faithful and targeted images for failure cases.
To preserve the quality and relevance of the generated samples, we further
employ a large vision-language model (LVLM) to filter the outputs, enforcing
alignment with the original data distribution and maintaining semantic
consistency. By retraining vision models with this rare-case-augmented
synthetic dataset, we significantly reduce errors associated with rare cases.
Our experiments demonstrate that this targeted repair strategy improves model
robustness without introducing new bugs. Code is available at
https://github.com/oxu2/SafeFix

</details>


### [75] [Adaptive Confidence-Wise Loss for Improved Lens Structure Segmentation in AS-OCT](https://arxiv.org/abs/2508.08705)
*Zunjie Xiao,Xiao Wu,Tianhang Liu,Lingxi Hu,Yinling Zhang,Xiaoqing Zhang,Risa Higashita,Jiang Liu*

Main category: cs.CV

TL;DR: 针对白内障手术中晶状体结构分割不均匀和边界校准差的问题，本文提出了一种自适应置信度感知（ACW）损失函数，利用专家标注的置信度先验对区域进行分组并重新加权，并通过自适应阈值优化动态调整。同时引入了边界预期校准误差（BECE）新指标，实验证明ACW显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度分割网络在交叉熵损失下平等对待所有像素，忽略了晶状体结构子区域的不均匀性（性能差异）以及边界区域像素级分割校准差的问题。临床上，专家在标注晶状体结构的不同子区域时，会根据区域比例、模糊边界和结构形状等因素，赋予不同的置信度，这启发了作者利用专家标注的置信度先验。

Method: 本文提出了自适应置信度感知（ACW）损失，通过置信度阈值将每个晶状体结构子区域划分为低置信度组和高置信度组，并对每个置信度组应用区域加权损失进行重新加权。此外，设计了一种自适应置信度阈值优化算法来动态调整ACW的置信度阈值。为了更好地量化边界区域分割的校准误差，提出了一种新的度量标准——边界预期校准误差（BECE）。

Result: 在临床晶状体结构AS-OCT数据集和其他多结构数据集上的大量实验表明，ACW在不同的深度分割网络（如MedSAM）上显著优于竞争性的分割损失方法。特别是在U-Net下进行晶状体结构分割时，ACW相对于CE损失在IoU上提高了6.13%，DSC提高了4.33%，BECE降低了4.79%。

Conclusion: 通过整合专家标注的置信度先验并自适应地重新加权子区域，本文提出的ACW损失显著提高了晶状体结构的精确分割性能，并有效解决了边界区域的校准误差问题。新提出的BECE指标也为边界分割的校准误差量化提供了更好的方法。

Abstract: Precise lens structure segmentation is essential for the design of
intraocular lenses (IOLs) in cataract surgery. Existing deep segmentation
networks typically weight all pixels equally under cross-entropy (CE) loss,
overlooking the fact that sub-regions of lens structures are inhomogeneous
(e.g., some regions perform better than others) and that boundary regions often
suffer from poor segmentation calibration at the pixel level. Clinically,
experts annotate different sub-regions of lens structures with varying
confidence levels, considering factors such as sub-region proportions,
ambiguous boundaries, and lens structure shapes. Motivated by this observation,
we propose an Adaptive Confidence-Wise (ACW) loss to group each lens structure
sub-region into different confidence sub-regions via a confidence threshold
from the unique region aspect, aiming to exploit the potential of expert
annotation confidence prior. Specifically, ACW clusters each target region into
low-confidence and high-confidence groups and then applies a region-weighted
loss to reweigh each confidence group. Moreover, we design an adaptive
confidence threshold optimization algorithm to adjust the confidence threshold
of ACW dynamically. Additionally, to better quantify the miscalibration errors
in boundary region segmentation, we propose a new metric, termed Boundary
Expected Calibration Error (BECE). Extensive experiments on a clinical lens
structure AS-OCT dataset and other multi-structure datasets demonstrate that
our ACW significantly outperforms competitive segmentation loss methods across
different deep segmentation networks (e.g., MedSAM). Notably, our method
surpasses CE with 6.13% IoU gain, 4.33% DSC increase, and 4.79% BECE reduction
in lens structure segmentation under U-Net. The code of this paper is available
at https://github.com/XiaoLing12138/Adaptive-Confidence-Wise-Loss.

</details>


### [76] [Bridging the Gap: A Framework for Real-World Video Deepfake Detection via Social Network Compression Emulation](https://arxiv.org/abs/2508.08765)
*Andrea Montibeller,Dasara Shullani,Daniele Baracchi,Alessandro Piva,Giulia Boato*

Main category: cs.CV

TL;DR: 针对社交媒体上AI生成视频的深度伪造检测，由于平台压缩导致现有检测器泛化能力差。本文提出一个框架，通过估计压缩参数来模拟社交网络视频共享管道，从而在本地重现平台特有伪影，有效提升检测器性能。


<details>
  <summary>Details</summary>
Motivation: AI生成视频在社交网络上日益增多，但受控条件下训练的深度伪造检测器难以泛化到真实世界场景。主要原因是YouTube和Facebook等平台采用的激进专有压缩会消除低级取证线索。然而，由于API限制和数据共享约束，大规模复制这些转换很困难。

Method: 提出一个首次框架，通过从少量上传视频中估计压缩和调整大小参数来模拟社交网络的视频共享管道。这些参数使得一个本地模拟器能够在没有直接API访问的情况下，在大数据集上重现平台特有的伪影。

Result: 在通过社交网络共享的FaceForensics++视频上的实验表明，模拟数据与真实上传的退化模式高度匹配。此外，在模拟视频上微调的检测器，其性能与在实际共享媒体上训练的检测器相当。

Conclusion: 该方法为弥合实验室训练与深度伪造检测器实际部署之间的差距提供了一个可扩展且实用的解决方案，特别是在压缩视频内容这一未充分探索的领域。

Abstract: The growing presence of AI-generated videos on social networks poses new
challenges for deepfake detection, as detectors trained under controlled
conditions often fail to generalize to real-world scenarios. A key factor
behind this gap is the aggressive, proprietary compression applied by platforms
like YouTube and Facebook, which launder low-level forensic cues. However,
replicating these transformations at scale is difficult due to API limitations
and data-sharing constraints. For these reasons, we propose a first framework
that emulates the video sharing pipelines of social networks by estimating
compression and resizing parameters from a small set of uploaded videos. These
parameters enable a local emulator capable of reproducing platform-specific
artifacts on large datasets without direct API access. Experiments on
FaceForensics++ videos shared via social networks demonstrate that our emulated
data closely matches the degradation patterns of real uploads. Furthermore,
detectors fine-tuned on emulated videos achieve comparable performance to those
trained on actual shared media. Our approach offers a scalable and practical
solution for bridging the gap between lab-based training and real-world
deployment of deepfake detectors, particularly in the underexplored domain of
compressed video content.

</details>


### [77] [SHREC 2025: Retrieval of Optimal Objects for Multi-modal Enhanced Language and Spatial Assistance (ROOMELSA)](https://arxiv.org/abs/2508.08781)
*Trong-Thuan Nguyen,Viet-Tham Huynh,Quang-Thuc Nguyen,Hoang-Phuc Nguyen,Long Le Bao,Thai Hoang Minh,Minh Nguyen Anh,Thang Nguyen Tien,Phat Nguyen Thuan,Huy Nguyen Phong,Bao Huynh Thai,Vinh-Tiep Nguyen,Duc-Vu Nguyen,Phu-Hoa Pham,Minh-Huy Le-Hoang,Nguyen-Khang Le,Minh-Chinh Nguyen,Minh-Quan Ho,Ngoc-Long Tran,Hien-Long Le-Hoang,Man-Khoi Tran,Anh-Duong Tran,Kim Nguyen,Quan Nguyen Hung,Dat Phan Thanh,Hoang Tran Van,Tien Huynh Viet,Nhan Nguyen Viet Thien,Dinh-Khoi Vo,Van-Loc Nguyen,Trung-Nghia Le,Tam V. Nguyen,Minh-Triet Tran*

Main category: cs.CV

TL;DR: ROOMELSA是一个新的基准测试，旨在评估3D检索系统在复杂全景房间图像中，根据模糊的自然语言描述准确识别并检索3D模型的能力，揭示了当前模型在细粒度理解方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的3D检索系统通常针对简单、受控场景设计，例如从裁剪图像或简短描述中识别对象。然而，真实世界场景更为复杂，需要根据模糊的自由形式描述，在杂乱场景中识别对象，这促使了对更鲁棒系统的需求。

Method: 本文提出了ROOMELSA基准测试。它要求系统解释自然语言，在全景房间图像中关注特定区域，并从大型数据库中准确检索相应的3D模型。ROOMELSA包含超过1600个公寓场景、近5200个房间和超过44000个目标查询。

Result: 实验结果表明，粗略的对象检索已基本解决，但只有少数顶级模型能够一致地在几乎所有测试案例中将正确匹配项排在首位。一个轻量级的基于CLIP的模型表现良好，但在处理材料、部件结构和上下文线索的细微变化时遇到困难，导致偶尔出错。

Conclusion: 这些发现强调了视觉和语言理解紧密结合的重要性。ROOMELSA通过弥合场景级接地与细粒度3D检索之间的差距，为推进鲁棒的真实世界3D识别系统建立了新的基准。

Abstract: Recent 3D retrieval systems are typically designed for simple, controlled
scenarios, such as identifying an object from a cropped image or a brief
description. However, real-world scenarios are more complex, often requiring
the recognition of an object in a cluttered scene based on a vague, free-form
description. To this end, we present ROOMELSA, a new benchmark designed to
evaluate a system's ability to interpret natural language. Specifically,
ROOMELSA attends to a specific region within a panoramic room image and
accurately retrieves the corresponding 3D model from a large database. In
addition, ROOMELSA includes over 1,600 apartment scenes, nearly 5,200 rooms,
and more than 44,000 targeted queries. Empirically, while coarse object
retrieval is largely solved, only one top-performing model consistently ranked
the correct match first across nearly all test cases. Notably, a lightweight
CLIP-based model also performed well, although it struggled with subtle
variations in materials, part structures, and contextual cues, resulting in
occasional errors. These findings highlight the importance of tightly
integrating visual and language understanding. By bridging the gap between
scene-level grounding and fine-grained 3D retrieval, ROOMELSA establishes a new
benchmark for advancing robust, real-world 3D recognition systems.

</details>


### [78] [DiffPose-Animal: A Language-Conditioned Diffusion Framework for Animal Pose Estimation](https://arxiv.org/abs/2508.08783)
*Tianyu Xiong,Dayi Tan,Wei Tian*

Main category: cs.CV

TL;DR: 提出DiffPose-Animal，一个基于扩散模型的动物姿态估计框架，利用LLM提供语义指导，并通过去噪过程逐步细化姿态预测，有效应对物种多样性、遮挡和数据稀疏等挑战。


<details>
  <summary>Details</summary>
Motivation: 动物姿态估计在生态监测、行为分析和智能畜牧管理中日益重要。然而，与人类姿态估计相比，动物姿态估计面临物种间形态多样性高、身体结构复杂以及标注数据有限等挑战。

Method: 提出DiffPose-Animal，一个新颖的基于扩散模型的自上而下动物姿态估计框架。该方法将姿态估计重新定义为去噪过程。它利用大型语言模型（LLMs）从物种特定提示中提取全局解剖先验和局部关键点语义，并通过交叉注意力模块将这些文本先验与图像特征融合，提供生物学上有意义的约束。此外，设计了一个基于扩散的关键点解码器来逐步细化姿态预测。

Result: 在公共动物姿态数据集上的广泛实验表明，该方法在具有多样物种、杂乱背景和不完整关键点的挑战性场景下，表现出有效性和泛化能力，尤其在处理遮挡和标注稀疏性方面具有鲁棒性。

Conclusion: DiffPose-Animal通过结合扩散模型和LLM的语义指导，为动物姿态估计提供了一种有效且鲁棒的解决方案，尤其擅长处理复杂和数据受限的场景，展现了其在实际应用中的巨大潜力。

Abstract: Animal pose estimation is a fundamental task in computer vision, with growing
importance in ecological monitoring, behavioral analysis, and intelligent
livestock management. Compared to human pose estimation, animal pose estimation
is more challenging due to high interspecies morphological diversity, complex
body structures, and limited annotated data. In this work, we introduce
DiffPose-Animal, a novel diffusion-based framework for top-down animal pose
estimation. Unlike traditional heatmap regression methods, DiffPose-Animal
reformulates pose estimation as a denoising process under the generative
framework of diffusion models. To enhance semantic guidance during keypoint
generation, we leverage large language models (LLMs) to extract both global
anatomical priors and local keypoint-wise semantics based on species-specific
prompts. These textual priors are encoded and fused with image features via
cross-attention modules to provide biologically meaningful constraints
throughout the denoising process. Additionally, a diffusion-based keypoint
decoder is designed to progressively refine pose predictions, improving
robustness to occlusion and annotation sparsity. Extensive experiments on
public animal pose datasets demonstrate the effectiveness and generalization
capability of our method, especially under challenging scenarios with diverse
species, cluttered backgrounds, and incomplete keypoints.

</details>


### [79] [Region-Adaptive Video Sharpening via Rate-Perception Optimization](https://arxiv.org/abs/2508.08794)
*Yingxue Pang,Shijie Zhao,Mengxi Guo,Junlin Li,Li Zhang*

Main category: cs.CV

TL;DR: 本文提出RPO-AdaSharp，一个端到端的区域自适应视频锐化模型，旨在同时提升感知质量并节省比特率。


<details>
  <summary>Details</summary>
Motivation: 传统的统一锐化强度忽略纹理变化，导致视频质量下降；同时，锐化会增加比特率，但缺乏有效技术来优化分配这些额外比特到不同区域。

Method: 提出RPO-AdaSharp模型，利用编码树单元（CTU）划分掩码作为先验信息，指导和约束增加比特的分配。

Result: 在基准测试中，所提出的模型在定性和定量上均表现出有效性。

Conclusion: RPO-AdaSharp模型能够有效地实现视频的区域自适应锐化，同时兼顾感知增强和比特率节省。

Abstract: Sharpening is a widely adopted video enhancement technique. However, uniform
sharpening intensity ignores texture variations, degrading video quality.
Sharpening also increases bitrate, and there's a lack of techniques to
optimally allocate these additional bits across diverse regions. Thus, this
paper proposes RPO-AdaSharp, an end-to-end region-adaptive video sharpening
model for both perceptual enhancement and bitrate savings. We use the coding
tree unit (CTU) partition mask as prior information to guide and constrain the
allocation of increased bits. Experiments on benchmarks demonstrate the
effectiveness of the proposed model qualitatively and quantitatively.

</details>


### [80] [MonoPartNeRF:Human Reconstruction from Monocular Video via Part-Based Neural Radiance Fields](https://arxiv.org/abs/2508.08798)
*Yao Lu,Jiawei Li,Ming Jiang*

Main category: cs.CV

TL;DR: MonoPartNeRF是一种用于单目动态人体渲染的新框架，通过结合双向变形模型、局部姿态嵌入和学习外观编码，解决了复杂姿态和遮挡下的重建挑战，实现了平滑过渡和鲁棒的遮挡恢复。


<details>
  <summary>Details</summary>
Motivation: 现有的人体动态NeRF方法在处理复杂姿态变化时表现不佳，常在身体部位边界产生不自然过渡，并且在单目设置下难以准确重建被遮挡区域。

Method: MonoPartNeRF提出：1) 建立一个结合刚性和非刚性变换的双向变形模型，在观察空间和规范空间之间建立连续可逆映射，并将采样点投影到参数化的表面-时间空间(u, v, t)以捕捉非刚性运动，辅以一致性损失。2) 引入基于身体区域的局部关节嵌入的部件级姿态嵌入机制，结合关键帧姿态检索和三正交方向的插值来指导姿态感知特征采样。3) 通过注意力机制整合可学习的外观编码，有效建模动态纹理变化。

Result: 在ZJU-MoCap和MonoCap数据集上的实验表明，MonoPartNeRF在复杂姿态和遮挡条件下显著优于现有方法，实现了卓越的关节对齐、纹理保真度和结构连续性。

Conclusion: MonoPartNeRF通过其创新的框架，成功解决了单目动态人体渲染中复杂姿态和遮挡的挑战，展现了优越的重建和渲染能力。

Abstract: In recent years, Neural Radiance Fields (NeRF) have achieved remarkable
progress in dynamic human reconstruction and rendering. Part-based rendering
paradigms, guided by human segmentation, allow for flexible parameter
allocation based on structural complexity, thereby enhancing representational
efficiency. However, existing methods still struggle with complex pose
variations, often producing unnatural transitions at part boundaries and
failing to reconstruct occluded regions accurately in monocular settings. We
propose MonoPartNeRF, a novel framework for monocular dynamic human rendering
that ensures smooth transitions and robust occlusion recovery. First, we build
a bidirectional deformation model that combines rigid and non-rigid
transformations to establish a continuous, reversible mapping between
observation and canonical spaces. Sampling points are projected into a
parameterized surface-time space (u, v, t) to better capture non-rigid motion.
A consistency loss further suppresses deformation-induced artifacts and
discontinuities. We introduce a part-based pose embedding mechanism that
decomposes global pose vectors into local joint embeddings based on body
regions. This is combined with keyframe pose retrieval and interpolation, along
three orthogonal directions, to guide pose-aware feature sampling. A learnable
appearance code is integrated via attention to model dynamic texture changes
effectively. Experiments on the ZJU-MoCap and MonoCap datasets demonstrate that
our method significantly outperforms prior approaches under complex pose and
occlusion conditions, achieving superior joint alignment, texture fidelity, and
structural continuity.

</details>


### [81] [Identity-Preserving Aging and De-Aging of Faces in the StyleGAN Latent Space](https://arxiv.org/abs/2508.08808)
*Luis S. Luevano,Pavel Korshunov,Sebastien Marcel*

Main category: cs.CV

TL;DR: 本文提出了一种通过编辑StyleGAN2潜在空间来实现面部年龄变化（老化/去老化）的方法，该方法通过寻找身份保持子空间来确保身份不被改变，并提供了一个估算参数限制的公式。


<details>
  <summary>Details</summary>
Motivation: 现有的面部年龄变化方法（如基于GAN、Diffusion、VLM）通常依赖于复杂的条件设定（损失函数、微调、文本提示），导致训练复杂、数据需求高且结果一致性差。此外，这些方法很少充分考虑或保证身份的保留。

Method: 该研究通过以下方式实现：1) 使用简单的支持向量建模和特征选择方法，编辑StyleGAN2的潜在空间以实现老化/去老化方向；2) 利用两个最先进的人脸识别系统，经验性地在StyleGAN2潜在空间中找到身份保持子空间；3) 提出了一个简单实用的公式，用于估算确保身份保持的年龄变化参数限制。

Result: 研究成功生成了在保持身份的同时改变年龄的合成人脸。基于此方法和估算的参数，研究团队创建了一个公共合成人脸数据集，可用于跨年龄人脸识别、年龄验证系统或合成图像检测系统的基准测试。

Conclusion: 该方法提供了一种简单而实用的面部年龄变化解决方案，有效解决了现有方法的复杂性和身份保留问题，并生成了一个有价值的公共数据集，可推动相关领域的研究和应用。

Abstract: Face aging or de-aging with generative AI has gained significant attention
for its applications in such fields like forensics, security, and media.
However, most state of the art methods rely on conditional Generative
Adversarial Networks (GANs), Diffusion-based models, or Visual Language Models
(VLMs) to age or de-age faces based on predefined age categories and
conditioning via loss functions, fine-tuning, or text prompts. The reliance on
such conditioning leads to complex training requirements, increased data needs,
and challenges in generating consistent results. Additionally, identity
preservation is rarely taken into accountor evaluated on a single face
recognition system without any control or guarantees on whether identity would
be preserved in a generated aged/de-aged face. In this paper, we propose to
synthesize aged and de-aged faces via editing latent space of StyleGAN2 using a
simple support vector modeling of aging/de-aging direction and several feature
selection approaches. By using two state-of-the-art face recognition systems,
we empirically find the identity preserving subspace within the StyleGAN2
latent space, so that an apparent age of a given face can changed while
preserving the identity. We then propose a simple yet practical formula for
estimating the limits on aging/de-aging parameters that ensures identity
preservation for a given input face. Using our method and estimated parameters
we have generated a public dataset of synthetic faces at different ages that
can be used for benchmarking cross-age face recognition, age assurance systems,
or systems for detection of synthetic images. Our code and dataset are
available at the project page https://www.idiap.ch/paper/agesynth/

</details>


### [82] [Revisiting Efficient Semantic Segmentation: Learning Offsets for Better Spatial and Class Feature Alignment](https://arxiv.org/abs/2508.08811)
*Shi-Chen Zhang,Yunheng Li,Yu-Huan Wu,Qibin Hou,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 该论文提出了一种双分支偏移学习范式，通过动态调整类别表示和图像特征来解决语义分割中存在的特征与类别表示不对齐问题，显著提升了现有方法的性能且只增加了极少量参数。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级语义分割方法虽然实现了实时推理，但其逐像素分类范式导致类别表示与图像特征之间存在错位。具体来说，该范式隐含了一个具有挑战性的假设：同一类别在不同图像中的像素特征应保持不变，这在高效场景下难以实现。

Method: 为解决上述问题，论文提出了一种耦合双分支偏移学习范式，该范式显式学习特征和类别偏移，以动态地细化类别表示和空间图像特征。基于此范式，构建了一个高效的语义分割网络OffSeg。该偏移学习范式可以无缝集成到现有方法中，无需额外的架构修改。

Result: 在ADE20K、Cityscapes、COCO-Stuff-164K和Pascal Context四个数据集上进行了广泛实验，结果表明该方法带来了持续的性能提升，且仅增加了可忽略的参数。例如，在ADE20K数据集上，所提出的偏移学习范式使SegFormer-B0、SegNeXt-T和Mask2Former-Tiny的mIoU分别提高了2.7%、1.9%和2.6%，而仅需额外增加0.1-0.2M参数。

Conclusion: 所提出的耦合双分支偏移学习范式有效解决了高效语义分割中特征与类别表示不对齐的固有局限性，通过动态精炼机制，在保持轻量化的同时显著提升了分割性能，并具有良好的通用性，可应用于现有多种模型。

Abstract: Semantic segmentation is fundamental to vision systems requiring pixel-level
scene understanding, yet deploying it on resource-constrained devices demands
efficient architectures. Although existing methods achieve real-time inference
through lightweight designs, we reveal their inherent limitation: misalignment
between class representations and image features caused by a per-pixel
classification paradigm. With experimental analysis, we find that this paradigm
results in a highly challenging assumption for efficient scenarios: Image pixel
features should not vary for the same category in different images. To address
this dilemma, we propose a coupled dual-branch offset learning paradigm that
explicitly learns feature and class offsets to dynamically refine both class
representations and spatial image features. Based on the proposed paradigm, we
construct an efficient semantic segmentation network, OffSeg. Notably, the
offset learning paradigm can be adopted to existing methods with no additional
architectural changes. Extensive experiments on four datasets, including
ADE20K, Cityscapes, COCO-Stuff-164K, and Pascal Context, demonstrate consistent
improvements with negligible parameters. For instance, on the ADE20K dataset,
our proposed offset learning paradigm improves SegFormer-B0, SegNeXt-T, and
Mask2Former-Tiny by 2.7%, 1.9%, and 2.6% mIoU, respectively, with only 0.1-0.2M
additional parameters required.

</details>


### [83] [TARA: Token-Aware LoRA for Composable Personalization in Diffusion Models](https://arxiv.org/abs/2508.08812)
*Yuqi Peng,Lingtao Zheng,Yufeng Yang,Yi Huang,Mingfu Yan,Jianzhuang Liu,Shifeng Chen*

Main category: cs.CV

TL;DR: TARA通过引入token掩码和空间对齐训练，解决了多概念LoRA文本到图像生成中概念丢失和特征泄露的问题，实现了高效且保真的多概念组合。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LoRA的个性化文本到图像生成方法在单概念定制上表现良好，但将多个LoRA模块组合进行多概念生成时，常导致概念身份丢失和视觉特征泄露。作者识别出两个关键问题：不同LoRA模块间的token干扰和稀有token注意力图与对应概念区域的空间错位。

Method: 本文提出了Token-Aware LoRA (TARA) 方法。它引入了一个token掩码，明确约束每个模块专注于其关联的稀有token，以避免干扰。同时，设计了一个训练目标，鼓励稀有token的空间注意力与其概念区域对齐。

Result: 实验结果表明，TARA能够在推理时直接注入多个独立训练的TARA模块，实现无需额外训练的多概念组合。该方法有效地保留了每个概念的视觉身份，避免了LoRA模块间的相互干扰，实现了高效的多概念推理。

Conclusion: TARA通过解决LoRA模块间的token干扰和空间错位问题，显著提升了多概念文本到图像生成的质量和效率，有效解决了现有方法的缺陷，能更好地保留每个概念的视觉身份。

Abstract: Personalized text-to-image generation aims to synthesize novel images of a
specific subject or style using only a few reference images. Recent methods
based on Low-Rank Adaptation (LoRA) enable efficient single-concept
customization by injecting lightweight, concept-specific adapters into
pre-trained diffusion models. However, combining multiple LoRA modules for
multi-concept generation often leads to identity missing and visual feature
leakage. In this work, we identify two key issues behind these failures: (1)
token-wise interference among different LoRA modules, and (2) spatial
misalignment between the attention map of a rare token and its corresponding
concept-specific region. To address these issues, we propose Token-Aware LoRA
(TARA), which introduces a token mask to explicitly constrain each module to
focus on its associated rare token to avoid interference, and a training
objective that encourages the spatial attention of a rare token to align with
its concept region. Our method enables training-free multi-concept composition
by directly injecting multiple independently trained TARA modules at inference
time. Experimental results demonstrate that TARA enables efficient
multi-concept inference and effectively preserving the visual identity of each
concept by avoiding mutual interference between LoRA modules. The code and
models are available at https://github.com/YuqiPeng77/TARA.

</details>


### [84] [3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs](https://arxiv.org/abs/2508.08821)
*Noor Ahmed,Cameron Braunstein,Steffen Eger,Eddy Ilg*

Main category: cs.CV

TL;DR: 3DFroMLLM是一个新颖的框架，无需额外训练或详细指令，即可使多模态大语言模型（MLLMs）直接生成包含几何和部件标签的3D对象原型，并通过代理式精炼循环提高MLLMs的空间推理能力，同时在图像分类预训练和细粒度视觉-语言模型（部件分割）任务中展现出显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管最近的多模态大语言模型（MLLMs）在学习文本和图像的联合表示方面表现出强大的能力，但它们的空间推理能力仍然有限。本研究旨在解决这一限制，使MLLMs能够直接生成3D对象原型。

Method: 引入了3DFroMLLM框架，该框架通过一个代理式管道实现3D对象原型生成，包括一个设计师、一个编码器和一个视觉检查器，它们在一个精炼循环中操作。该方法无需额外的训练数据或详细的用户指令，并基于先前在2D生成方面的工作。

Result: 通过3DFroMLLM框架生成的渲染图像可以有效地用于图像分类预训练任务，并比现有方法性能提高15%。此外，生成的原型可以用于改进细粒度视觉-语言模型，通过使用渲染的、带有部件标签的原型来微调CLIP进行部件分割，实现了55%的精度提升，且不依赖任何额外的人工标注数据。

Conclusion: 3DFroMLLM成功地使MLLMs能够生成3D对象原型，有效提升了它们的空间推理能力。该框架在无需额外数据或训练的情况下，为图像分类预训练和细粒度视觉-语言模型（特别是部件分割）提供了显著的性能改进，展示了其强大的实用性。

Abstract: Recent Multi-Modal Large Language Models (MLLMs) have demonstrated strong
capabilities in learning joint representations from text and images. However,
their spatial reasoning remains limited. We introduce 3DFroMLLM, a novel
framework that enables the generation of 3D object prototypes directly from
MLLMs, including geometry and part labels. Our pipeline is agentic, comprising
a designer, coder, and visual inspector operating in a refinement loop.
Notably, our approach requires no additional training data or detailed user
instructions. Building on prior work in 2D generation, we demonstrate that
rendered images produced by our framework can be effectively used for image
classification pretraining tasks and outperforms previous methods by 15%. As a
compelling real-world use case, we show that the generated prototypes can be
leveraged to improve fine-grained vision-language models by using the rendered,
part-labeled prototypes to fine-tune CLIP for part segmentation and achieving a
55% accuracy improvement without relying on any additional human-labeled data.

</details>


### [85] [A Parametric Bi-Directional Curvature-Based Framework for Image Artifact Classification and Quantification](https://arxiv.org/abs/2508.08824)
*Diego Frias*

Main category: cs.CV

TL;DR: 该工作提出了一种基于方向图像曲率分析的无参考图像质量评估（NR-IQA）新框架，通过各向异性纹理丰富度（ATR）度量，实现了图像失真的分类和量化。


<details>
  <summary>Details</summary>
Motivation: 现有图像质量评估方法可能不足以准确或鲁棒地处理不同类型的图像失真，因此需要开发一种高性能、能同时分类和量化图像降级的新型NR-IQA框架。

Method: 该方法基于方向图像曲率分析，定义了像素级的各向异性纹理丰富度（ATR），使用两个可调阈值量化正交纹理抑制。系统分为两阶段：首先，利用两种专业ATR配置的特征识别主要失真类型（模糊或噪声），准确率超过97%；其次，根据分类结果，采用专门的回归模型将相关ATR得分映射到质量等级以量化图像降级。

Result: 优化参数后，ATR得分作为质量度量与人类感知的斯皮尔曼相关性，在高斯模糊下约为-0.93，白噪声下约为-0.95（在LIVE数据集上）。在组合数据集上，完整系统预测人类得分的决定系数（R2）为0.892，均方根误差（RMSE）为5.17 DMOS点，相当于数据集总质量范围的7.4%，显示出高预测准确性。

Conclusion: 该框架被确立为一个鲁棒的双重用途工具，可用于图像降级的分类和随后的量化，具有高预测精度。

Abstract: This work presents a novel framework for No-Reference Image Quality
Assessment (NR-IQA) founded on the analysis of directional image curvature.
Within this framework, we define a measure of Anisotropic Texture Richness
(ATR), which is computed at the pixel level using two tunable thresholds -- one
permissive and one restrictive -- that quantify orthogonal texture suppression.
When its parameters are optimized for a specific artifact, the resulting ATR
score serves as a high-performance quality metric, achieving Spearman
correlations with human perception of approximately -0.93 for Gaussian blur and
-0.95 for white noise on the LIVE dataset. The primary contribution is a
two-stage system that leverages the differential response of ATR to various
distortions. First, the system utilizes the signature from two specialist ATR
configurations to classify the primary artifact type (blur vs. noise) with over
97% accuracy. Second, following classification, it employs a dedicated
regression model mapping the relevant ATR score to a quality rating to quantify
the degradation. On a combined dataset, the complete system predicts human
scores with a coefficient of determination (R2) of 0.892 and a Root Mean Square
Error (RMSE) of 5.17 DMOS points. This error corresponds to just 7.4% of the
dataset's total quality range, demonstrating high predictive accuracy. This
establishes our framework as a robust, dual-purpose tool for the classification
and subsequent quantification of image degradation.

</details>


### [86] [Adaptive High-Frequency Preprocessing for Video Coding](https://arxiv.org/abs/2508.08849)
*Yingxue Pang,Shijie Zhao,Junlin Li,Li Zhang*

Main category: cs.CV

TL;DR: 本文提出一个端到端的学习框架，用于自适应高频预处理，以在视频编码中提升主观质量并节省码率。


<details>
  <summary>Details</summary>
Motivation: 高频分量对视频清晰度和真实感至关重要，但显著增加编码码率，导致带宽和存储成本上升。

Method: 该框架采用频率注意力特征金字塔预测网络（FFPN）来预测最优的高频预处理策略，指导后续滤波操作。FFPN通过比较不同预处理类型和强度的率失真（RD）性能来伪标记训练视频，失真使用最新的质量评估指标衡量。

Result: 在多个数据集上的综合评估表明，该框架实现了视觉上吸引人的质量提升和码率节省。

Conclusion: 所提出的学习框架能够有效地自适应预处理高频分量，从而在视频编码中实现码率与质量之间的最佳权衡。

Abstract: High-frequency components are crucial for maintaining video clarity and
realism, but they also significantly impact coding bitrate, resulting in
increased bandwidth and storage costs. This paper presents an end-to-end
learning-based framework for adaptive high-frequency preprocessing to enhance
subjective quality and save bitrate in video coding. The framework employs the
Frequency-attentive Feature pyramid Prediction Network (FFPN) to predict the
optimal high-frequency preprocessing strategy, guiding subsequent filtering
operators to achieve the optimal tradeoff between bitrate and quality after
compression. For training FFPN, we pseudo-label each training video with the
optimal strategy, determined by comparing the rate-distortion (RD) performance
across different preprocessing types and strengths. Distortion is measured
using the latest quality assessment metric. Comprehensive evaluations on
multiple datasets demonstrate the visually appealing enhancement capabilities
and bitrate savings achieved by our framework.

</details>


### [87] [GaussianUpdate: Continual 3D Gaussian Splatting Update for Changing Environments](https://arxiv.org/abs/2508.08867)
*Lin Zeng,Boming Zhao,Jiarui Hu,Xujie Shen,Ziqiang Dang,Hujun Bao,Zhaopeng Cui*

Main category: cs.CV

TL;DR: GaussianUpdate是一种新颖的方法，结合3D高斯表示和持续学习，实现了神经视图合成模型对场景变化的有效适应，并能实时渲染和可视化不同时间的变化。


<details>
  <summary>Details</summary>
Motivation: 现有神经视图合成模型难以适应场景变化，需要大量重新训练或无法捕捉细节变化。

Method: 提出了GaussianUpdate方法，结合3D高斯表示和持续学习，通过多阶段更新策略显式建模不同类型的变化，并引入了带有生成式回放的可见性感知持续学习，无需存储图像即可实现自我感知更新。

Result: 在基准数据集上，该方法实现了卓越的实时渲染，并能可视化不同时间点的场景变化。

Conclusion: GaussianUpdate能有效利用当前数据更新高斯辐射场，同时保留过去场景信息，明确建模变化类型，并实现无需存储图像的自我感知更新。

Abstract: Novel view synthesis with neural models has advanced rapidly in recent years,
yet adapting these models to scene changes remains an open problem. Existing
methods are either labor-intensive, requiring extensive model retraining, or
fail to capture detailed types of changes over time. In this paper, we present
GaussianUpdate, a novel approach that combines 3D Gaussian representation with
continual learning to address these challenges. Our method effectively updates
the Gaussian radiance fields with current data while preserving information
from past scenes. Unlike existing methods, GaussianUpdate explicitly models
different types of changes through a novel multi-stage update strategy.
Additionally, we introduce a visibility-aware continual learning approach with
generative replay, enabling self-aware updating without the need to store
images. The experiments on the benchmark dataset demonstrate our method
achieves superior and real-time rendering with the capability of visualizing
changes over different times

</details>


### [88] [Preview WB-DH: Towards Whole Body Digital Human Bench for the Generation of Whole-body Talking Avatar Videos](https://arxiv.org/abs/2508.08891)
*Chaoyi Wang,Yifan Yang,Jun Pei,Lijie Xia,Jianpo Liu,Xiaobing Yuan,Xinhan Di*

Main category: cs.CV

TL;DR: 该论文引入了一个名为WB-DH的开放获取、多模态基准数据集，旨在解决从单张肖像生成逼真、全身可动画虚拟形象的评估挑战。


<details>
  <summary>Details</summary>
Motivation: 从单张肖像创建逼真、全身可动画的虚拟形象面临捕捉细微表情、身体动作和动态背景的挑战，且现有评估数据集和指标无法充分应对这些复杂性。

Method: 引入了全身基准数据集（WB-DH），一个开源、多模态基准，具有详细的多模态标注以实现细粒度指导，并提供了一个多功能评估框架。

Result: 提供了WB-DH数据集和相关工具的公共访问权限，旨在弥补当前评估方法的不足，并支持全身可动画虚拟形象的生成研究。

Conclusion: WB-DH数据集通过提供详细标注和多功能评估框架，旨在弥合全身可动画虚拟形象生成领域在评估方面的差距。

Abstract: Creating realistic, fully animatable whole-body avatars from a single
portrait is challenging due to limitations in capturing subtle expressions,
body movements, and dynamic backgrounds. Current evaluation datasets and
metrics fall short in addressing these complexities. To bridge this gap, we
introduce the Whole-Body Benchmark Dataset (WB-DH), an open-source, multi-modal
benchmark designed for evaluating whole-body animatable avatar generation. Key
features include: (1) detailed multi-modal annotations for fine-grained
guidance, (2) a versatile evaluation framework, and (3) public access to the
dataset and tools at https://github.com/deepreasonings/WholeBodyBenchmark.

</details>


### [89] [A Robust Epipolar-Domain Regularization Algorithm for Light Field Depth Estimation](https://arxiv.org/abs/2508.08900)
*Noor Islam S. Mohammad*

Main category: cs.CV

TL;DR: 本论文提出一种轻量级光场深度估计算法，通过结合光场视差信息和有向随机游走精炼，实现了低计算复杂度和与现有深度学习模型相当的精度，是光场深度估计和分割的有效替代方案。


<details>
  <summary>Details</summary>
Motivation: 光场成像中的鲁棒深度估计是模式识别应用（如增强现实、生物医学成像、场景重建）的关键挑战。现有深度卷积神经网络方法计算成本高，且在真实噪声环境下表现不佳。

Method: 本文提出一种新颖的轻量级深度估计管线，将基于光场的视差信息与有向随机游走精炼算法相结合。该方法无需大量训练或大型数据集即可增强深度图的一致性。

Result: 该方法在4D光场基准数据集和多样化的真实世界图像上进行了评估。实验结果表明，尽管在不受控条件下性能略有下降，但算法始终保持低计算复杂度和与最先进深度学习模型相当的竞争力精度。

Conclusion: 研究结果突出了该方法作为光场成像中深度估计和分割的鲁棒高效替代方案的潜力。本工作为光场模式识别的实际算法设计提供了见解，并为概率图模型与深度传感框架的集成开辟了新方向。

Abstract: Robust depth estimation in light field imaging remains a critical challenge
for pattern recognition applications such as augmented reality, biomedical
imaging, and scene reconstruction. While existing approaches often rely heavily
on deep convolutional neural networks, they tend to incur high computational
costs and struggle in noisy real-world environments. This paper proposes a
novel lightweight depth estimation pipeline that integrates light field-based
disparity information with a directed random walk refinement algorithm. Unlike
traditional CNN-based methods, our approach enhances depth map consistency
without requiring extensive training or large-scale datasets. The proposed
method was evaluated on the 4D Light Field Benchmark dataset and a diverse set
of real-world images. Experimental results indicate that while performance
slightly declines under uncontrolled conditions, the algorithm consistently
maintains low computational complexity and competitive accuracy compared to
state-of-the-art deep learning models. These findings highlight the potential
of our method as a robust and efficient alternative for depth estimation and
segmentation in light field imaging. The work provides insights into practical
algorithm design for light field-based pattern recognition and opens new
directions for integrating probabilistic graph models with depth sensing
frameworks.

</details>


### [90] [Masked Clustering Prediction for Unsupervised Point Cloud Pre-training](https://arxiv.org/abs/2508.08910)
*Bin Ren,Xiaoshui Huang,Mengyuan Liu,Hong Liu,Fabio Poiesi,Nicu Sebe,Guofeng Mei*

Main category: cs.CV

TL;DR: MaskClu是一种新颖的无监督预训练方法，用于3D点云上的Vision Transformer (ViT)，它结合了掩码点建模和聚类学习，并引入全局对比学习，旨在捕获密集语义和实例级特征，在多项3D任务中取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 尽管掩码自编码是3D点云ViT预训练的主流范式，但通过标准ViT从点云中学习密集且信息丰富的语义特征的挑战仍未得到充分探索。

Method: MaskClu集成了掩码点建模与基于聚类的学习，通过重建聚类分配和聚类中心来捕获密集语义信息。此外，它引入了全局对比学习机制，通过对比同一点云的不同掩码视图来增强实例级特征学习。这两种互补目标被联合优化。

Result: MaskClu使ViT能够从3D点云中学习到更丰富、更具语义意义的表示。在多个3D任务（包括部件分割、语义分割、目标检测和分类）中，MaskClu取得了新的有竞争力的结果。

Conclusion: MaskClu通过其新颖的无监督预训练方法，成功解决了3D点云ViT学习密集语义特征的挑战，从而在各种下游任务中显著提升了性能。

Abstract: Vision transformers (ViTs) have recently been widely applied to 3D point
cloud understanding, with masked autoencoding as the predominant pre-training
paradigm. However, the challenge of learning dense and informative semantic
features from point clouds via standard ViTs remains underexplored. We propose
MaskClu, a novel unsupervised pre-training method for ViTs on 3D point clouds
that integrates masked point modeling with clustering-based learning. MaskClu
is designed to reconstruct both cluster assignments and cluster centers from
masked point clouds, thus encouraging the model to capture dense semantic
information. Additionally, we introduce a global contrastive learning mechanism
that enhances instance-level feature learning by contrasting different masked
views of the same point cloud. By jointly optimizing these complementary
objectives, i.e., dense semantic reconstruction, and instance-level contrastive
learning. MaskClu enables ViTs to learn richer and more semantically meaningful
representations from 3D point clouds. We validate the effectiveness of our
method via multiple 3D tasks, including part segmentation, semantic
segmentation, object detection, and classification, where MaskClu sets new
competitive results. The code and models will be released
at:https://github.com/Amazingren/maskclu.

</details>


### [91] [When Deepfakes Look Real: Detecting AI-Generated Faces with Unlabeled Data due to Annotation Challenges](https://arxiv.org/abs/2508.09022)
*Zhiqiang Yang,Renshuai Tao,Xiaolong Zheng,Guodong Yang,Chunjie Zhang*

Main category: cs.CV

TL;DR: 本文提出DPGNet，一种利用文本引导跨域对齐和课程驱动伪标签生成的技术，有效利用大量未标注数据来提高Deepfake检测的性能，应对人工标注困难的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有Deepfake检测方法严重依赖标注数据，但随着AI生成内容日益逼真，人工标注变得耗时且不可靠。此外，AI生成的人脸与真实图像高度相似，导致传统无监督方法表现不佳，因此迫切需要能有效利用大规模未标注数据的方法。

Method: 本文引入双路径引导网络（DPGNet），包含两个核心模块：1) 文本引导的跨域对齐，使用可学习提示将视觉和文本嵌入统一到域不变特征空间；2) 课程驱动的伪标签生成，动态利用信息量更大的未标注样本。为防止灾难性遗忘，还通过跨域知识蒸馏促进域间桥接。

Result: 在11个流行数据集上进行的广泛实验表明，DPGNet的性能优于现有最先进方法6.3%。

Conclusion: DPGNet通过有效利用未标注数据，成功解决了Deepfake日益逼真所带来的标注挑战，证明了其在Deepfake检测中的有效性。

Abstract: Existing deepfake detection methods heavily depend on labeled training data.
However, as AI-generated content becomes increasingly realistic, even
\textbf{human annotators struggle to distinguish} between deepfakes and
authentic images. This makes the labeling process both time-consuming and less
reliable. Specifically, there is a growing demand for approaches that can
effectively utilize large-scale unlabeled data from online social networks.
Unlike typical unsupervised learning tasks, where categories are distinct,
AI-generated faces closely mimic real image distributions and share strong
similarities, causing performance drop in conventional strategies. In this
paper, we introduce the Dual-Path Guidance Network (DPGNet), to tackle two key
challenges: (1) bridging the domain gap between faces from different generation
models, and (2) utilizing unlabeled image samples. The method features two core
modules: text-guided cross-domain alignment, which uses learnable prompts to
unify visual and textual embeddings into a domain-invariant feature space, and
curriculum-driven pseudo label generation, which dynamically exploit more
informative unlabeled samples. To prevent catastrophic forgetting, we also
facilitate bridging between domains via cross-domain knowledge distillation.
Extensive experiments on \textbf{11 popular datasets}, show that DPGNet
outperforms SoTA approaches by \textbf{6.3\%}, highlighting its effectiveness
in leveraging unlabeled data to address the annotation challenges posed by the
increasing realism of deepfakes.

</details>


### [92] [Automatic and standardized surgical reporting for central nervous system tumors](https://arxiv.org/abs/2508.08916)
*David Bouget,Mathilde Gajda Faanes,Asgeir Store Jakola,Frederik Barkhof,Hilko Ardon,Lorenzo Bello,Mitchel S. Berger,Shawn L. Hervey-Jumper,Julia Furtner,Albert J. S. Idema,Barbara Kiesel,Georg Widhalm,Rishi Nandoe Tewarie,Emmanuel Mandonnet,Pierre A. Robe,Michiel Wagemakers,Timothy R. Smith,Philip C. De Witt Hamer,Ole solheim,Ingerid Reinertsen*

Main category: cs.CV

TL;DR: 本研究提出一个用于中枢神经系统肿瘤术后MR影像分析的自动化管道，包括肿瘤分割、序列分类和标准化报告生成，以增强术后评估和临床决策。


<details>
  <summary>Details</summary>
Motivation: 磁共振成像对中枢神经系统肿瘤的评估至关重要，但现有自动化肿瘤分析主要集中于术前影像，对术后影像分析的关注有限，缺乏一个标准化、全面的术后报告系统。

Method: 研究采用Attention U-Net架构训练分割模型，用于识别术前非增强肿瘤核心、术后对比增强残余肿瘤和切除腔。同时，使用DenseNet架构探索MR序列分类和对比增强病灶的肿瘤类型识别。这些模型被整合到一个符合RANO 2.0指南的报告管道中。模型在包含2000至7000名患者的多中心数据集上进行5折交叉验证训练，并使用患者、体素和对象级指标进行评估，同时与最新的BraTS挑战结果进行基准测试。提出的模型和方法已集成到开源软件Raidionics中。

Result: 分割模型在肿瘤核心、非增强肿瘤核心、对比增强残余肿瘤和切除腔上的平均体素级Dice分数分别为87%、66%、70%和77%。分类模型在MR序列分类中达到99.5%的平衡准确率，在肿瘤类型分类中达到80%的平衡准确率。该管道实现了鲁棒的自动化分割、MR序列分类和符合RANO 2.0指南的标准化报告生成。

Conclusion: 本研究提出的自动化管道能够显著提升中枢神经系统肿瘤的术后评估和临床决策，通过提供鲁棒的自动化分割、MR序列分类和符合RANO 2.0指南的标准化报告生成，解决了当前术后影像分析的不足。

Abstract: Magnetic resonance (MR) imaging is essential for evaluating central nervous
system (CNS) tumors, guiding surgical planning, treatment decisions, and
assessing postoperative outcomes and complication risks. While recent work has
advanced automated tumor segmentation and report generation, most efforts have
focused on preoperative data, with limited attention to postoperative imaging
analysis. This study introduces a comprehensive pipeline for standardized
postsurtical reporting in CNS tumors. Using the Attention U-Net architecture,
segmentation models were trained for the preoperative (non-enhancing) tumor
core, postoperative contrast-enhancing residual tumor, and resection cavity.
Additionally, MR sequence classification and tumor type identification for
contrast-enhancing lesions were explored using the DenseNet architecture. The
models were integrated into a reporting pipeline, following the RANO 2.0
guidelines. Training was conducted on multicentric datasets comprising 2000 to
7000 patients, using a 5-fold cross-validation. Evaluation included patient-,
voxel-, and object-wise metrics, with benchmarking against the latest BraTS
challenge results. The segmentation models achieved average voxel-wise Dice
scores of 87%, 66%, 70%, and 77% for the tumor core, non-enhancing tumor core,
contrast-enhancing residual tumor, and resection cavity, respectively.
Classification models reached 99.5% balanced accuracy in MR sequence
classification and 80% in tumor type classification. The pipeline presented in
this study enables robust, automated segmentation, MR sequence classification,
and standardized report generation aligned with RANO 2.0 guidelines, enhancing
postoperative evaluation and clinical decision-making. The proposed models and
methods were integrated into Raidionics, open-source software platform for CNS
tumor analysis, now including a dedicated module for postsurgical analysis.

</details>


### [93] [A Pseudo Global Fusion Paradigm-Based Cross-View Network for LiDAR-Based Place Recognition](https://arxiv.org/abs/2508.08917)
*Jintao Cheng,Jiehao Luo,Xieyuanli Chen,Jin Wu,Rui Fan,Xiaoyu Tang,Wei Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种新的跨视图网络，结合伪全局信息引导和基于马哈拉诺比斯距离的度量学习方法，用于激光雷达地点识别（LPR），以克服传统欧氏距离方法的局限性，在复杂环境下实现卓越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的激光雷达地点识别（LPR）方法将问题简化为基于欧氏距离的度量学习，忽略了特征空间的内在结构和类内方差。这种以欧氏距离为中心的方法限制了模型捕捉非线性数据分布的能力，导致在复杂和时变场景中性能不佳。

Method: 本文提出了一种基于创新融合范式的新型跨视图网络。该框架引入了伪全局信息引导机制，协调多模态分支在统一语义空间中进行特征学习。同时，提出了一种流形自适应和成对方差-局部性学习度量，通过构建对称正定（SPD）矩阵来计算马哈拉诺比斯距离，取代传统的欧氏距离度量。这种几何公式旨在准确表征内在数据分布并捕获特征空间中复杂的类间依赖关系。

Result: 实验结果表明，所提出的算法取得了具有竞争力的性能，尤其在复杂环境条件下表现出色。

Conclusion: 该研究通过引入创新的网络架构和基于马哈拉诺比斯距离的度量学习方法，有效解决了传统LPR方法在复杂环境下的性能局限性，显著提升了地点识别的准确性和鲁棒性。

Abstract: LiDAR-based Place Recognition (LPR) remains a critical task in Embodied
Artificial Intelligence (AI) and Autonomous Driving, primarily addressing
localization challenges in GPS-denied environments and supporting loop closure
detection. Existing approaches reduce place recognition to a Euclidean
distance-based metric learning task, neglecting the feature space's intrinsic
structures and intra-class variances. Such Euclidean-centric formulation
inherently limits the model's capacity to capture nonlinear data distributions,
leading to suboptimal performance in complex environments and temporal-varying
scenarios. To address these challenges, we propose a novel cross-view network
based on an innovative fusion paradigm. Our framework introduces a
pseudo-global information guidance mechanism that coordinates multi-modal
branches to perform feature learning within a unified semantic space.
Concurrently, we propose a Manifold Adaptation and Pairwise Variance-Locality
Learning Metric that constructs a Symmetric Positive Definite (SPD) matrix to
compute Mahalanobis distance, superseding traditional Euclidean distance
metrics. This geometric formulation enables the model to accurately
characterize intrinsic data distributions and capture complex inter-class
dependencies within the feature space. Experimental results demonstrate that
the proposed algorithm achieves competitive performance, particularly excelling
in complex environmental conditions.

</details>


### [94] [Accelerated Volumetric Compression without Hierarchies: A Fourier Feature Based Implicit Neural Representation Approach](https://arxiv.org/abs/2508.08937)
*Leona Žůrková,Petr Strakoš,Michal Kravčenko,Tomáš Brzobohatý,Lubomír Říha*

Main category: cs.CV

TL;DR: 该论文提出了一种结合傅里叶特征编码和选择性体素采样的无结构神经体数据压缩方法，实现了紧凑表示、更快的收敛和高压缩率。


<details>
  <summary>Details</summary>
Motivation: 体数据压缩在医学成像、科学模拟和娱乐等领域至关重要，但现有方法可能存在效率和表示问题。

Method: 该方法结合了傅里叶特征编码和选择性体素采样。通过形态学膨胀进行动态体素选择，优先处理活跃区域，减少冗余计算，且无需分层元数据。最终的神经表示仅存储为网络权重。

Result: 稀疏训练使训练时间减少了63.7%（从30分钟到11分钟），且质量损失轻微：PSNR下降0.59 dB（从32.60到32.01），SSIM下降0.008（从0.948到0.940）。实现了14倍的压缩率，并消除了传统数据加载开销。

Conclusion: 该研究将基于坐标的神经表示与高效的体数据压缩相结合，为实际应用提供了一个可扩展、无结构的解决方案。

Abstract: Volumetric data compression is critical in fields like medical imaging,
scientific simulation, and entertainment. We introduce a structure-free neural
compression method combining Fourierfeature encoding with selective voxel
sampling, yielding compact volumetric representations and faster convergence.
Our dynamic voxel selection uses morphological dilation to prioritize active
regions, reducing redundant computation without any hierarchical metadata. In
the experiment, sparse training reduced training time by 63.7 % (from 30 to 11
minutes) with only minor quality loss: PSNR dropped 0.59 dB (from 32.60 to
32.01) and SSIM by 0.008 (from 0.948 to 0.940). The resulting neural
representation, stored solely as network weights, achieves a compression rate
of 14 and eliminates traditional data-loading overhead. This connects
coordinate-based neural representation with efficient volumetric compression,
offering a scalable, structure-free solution for practical applications.

</details>


### [95] [MADPromptS: Unlocking Zero-Shot Morphing Attack Detection with Multiple Prompt Aggregation](https://arxiv.org/abs/2508.08939)
*Eduarda Caldeira,Fadi Boutros,Naser Damer*

Main category: cs.CV

TL;DR: 本研究提出了一种纯零样本的人脸形变攻击检测（MAD）方法，通过利用CLIP模型并聚合多个文本提示来提高检测性能，无需额外训练或微调。


<details>
  <summary>Details</summary>
Motivation: 人脸形变攻击（MAD）对人脸识别系统构成严重安全威胁，攻击者可创建能被多个身份验证的图像。尽管CLIP等多模态基础模型具有强大的零样本能力，但多数现有研究仍依赖于微调，忽视了其直接、泛化部署的潜力。

Method: 该研究采用纯零样本方法，不进行任何额外的训练或微调，直接利用CLIP模型进行MAD。核心方法是设计和聚合每个类别的多个文本提示，通过聚合不同提示的嵌入来更好地对齐模型内部表示与MAD任务，捕捉更丰富多样的真实或攻击样本线索。

Result: 实验结果表明，提示聚合显著提高了零样本检测性能。

Conclusion: 该研究证明了通过高效的提示工程，可以有效利用基础模型内置的多模态知识进行人脸形变攻击检测。

Abstract: Face Morphing Attack Detection (MAD) is a critical challenge in face
recognition security, where attackers can fool systems by interpolating the
identity information of two or more individuals into a single face image,
resulting in samples that can be verified as belonging to multiple identities
by face recognition systems. While multimodal foundation models (FMs) like CLIP
offer strong zero-shot capabilities by jointly modeling images and text, most
prior works on FMs for biometric recognition have relied on fine-tuning for
specific downstream tasks, neglecting their potential for direct, generalizable
deployment. This work explores a pure zero-shot approach to MAD by leveraging
CLIP without any additional training or fine-tuning, focusing instead on the
design and aggregation of multiple textual prompts per class. By aggregating
the embeddings of diverse prompts, we better align the model's internal
representations with the MAD task, capturing richer and more varied cues
indicative of bona-fide or attack samples. Our results show that prompt
aggregation substantially improves zero-shot detection performance,
demonstrating the effectiveness of exploiting foundation models' built-in
multimodal knowledge through efficient prompt engineering.

</details>


### [96] [UniSTFormer: Unified Spatio-Temporal Lightweight Transformer for Efficient Skeleton-Based Action Recognition](https://arxiv.org/abs/2508.08944)
*Wenhan Wu,Zhishuai Guo,Chen Chen,Aidong Lu*

Main category: cs.CV

TL;DR: 本文提出了一种统一的时空轻量级Transformer框架，用于骨架行为识别，通过集成时空建模和简化的多尺度池化融合，显著降低了模型复杂度和计算成本，同时保持了竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer的骨架行为识别方法通常依赖复杂的模块组合和重型设计，导致参数量大、计算成本高和可扩展性受限。

Method: 提出了一种统一的时空轻量级Transformer框架，将空间和时间建模集成到单个注意力模块中，无需单独的时间建模块。此外，引入了一个简化的多尺度池化融合模块，结合局部和全局池化路径以捕获细粒度局部运动和整体全局运动模式。

Result: 与现有最先进的基于Transformer的基线相比，该轻量级模型在准确性和效率之间取得了卓越平衡，参数复杂度降低了58%以上，计算成本降低了60%以上，同时保持了有竞争力的识别性能。

Conclusion: 所提出的轻量级模型在骨架行为识别任务中，实现了效率和性能的有效权衡，显著减少了模型复杂度和计算开销。

Abstract: Skeleton-based action recognition (SAR) has achieved impressive progress with
transformer architectures. However, existing methods often rely on complex
module compositions and heavy designs, leading to increased parameter counts,
high computational costs, and limited scalability. In this paper, we propose a
unified spatio-temporal lightweight transformer framework that integrates
spatial and temporal modeling within a single attention module, eliminating the
need for separate temporal modeling blocks. This approach reduces redundant
computations while preserving temporal awareness within the spatial modeling
process. Furthermore, we introduce a simplified multi-scale pooling fusion
module that combines local and global pooling pathways to enhance the model's
ability to capture fine-grained local movements and overarching global motion
patterns. Extensive experiments on benchmark datasets demonstrate that our
lightweight model achieves a superior balance between accuracy and efficiency,
reducing parameter complexity by over 58% and lowering computational cost by
over 60% compared to state-of-the-art transformer-based baselines, while
maintaining competitive recognition performance.

</details>


### [97] [Lay2Story: Extending Diffusion Transformers for Layout-Togglable Story Generation](https://arxiv.org/abs/2508.08949)
*Ao Ma,Jiasong Feng,Ke Cao,Jing Wang,Yun Wang,Quanwei Zhang,Zhanjie Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一个名为“Layout-Togglable Storytelling”的新型讲故事任务，旨在通过引入布局条件实现对主体的高度精确控制。为此，作者构建了大规模数据集Lay2Story-1M和评估基准Lay2Story-Bench，并提出了基于Diffusion Transformers的Lay2Story框架，在主体一致性、语义关联性和美学质量方面超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的故事生成方法在保持主体一致性方面存在挑战，原因在于缺乏细粒度指导和帧间交互。此外，高质量数据的稀缺也使得精确控制故事中主体的位置、外观、服装、表情和姿势变得困难，从而阻碍了该领域的进一步发展。

Method: 1. 引入并定义了“Layout-Togglable Storytelling”这一高级故事生成任务，通过布局条件（如主体位置和详细属性）实现对主体的精确控制。
2. 开发了Lay2Story-1M数据集，包含超过100万张带有布局注释的高分辨率图像，来源于约11,300小时的卡通视频。
3. 基于Lay2Story-1M创建了Lay2Story-Bench基准，包含3,000个提示，用于评估不同方法在该任务上的性能。
4. 提出了Lay2Story框架，一个基于Diffusion Transformers (DiTs) 架构的鲁棒模型，用于处理Layout-Togglable Storytelling任务。

Result: 通过定性和定量实验，本研究发现所提出的Lay2Story方法在主体一致性、语义关联性和美学质量方面均优于先前的最先进（SOTA）技术，取得了最佳结果。

Conclusion: 布局条件能有效促进帧间的细粒度交互，从而增强生成序列的一致性并实现对主体细节的精确控制。所提出的Lay2Story任务、数据集、基准和框架有效解决了当前故事生成任务中主体一致性和精确控制的难题，并显著提升了该领域的性能。

Abstract: Storytelling tasks involving generating consistent subjects have gained
significant attention recently. However, existing methods, whether
training-free or training-based, continue to face challenges in maintaining
subject consistency due to the lack of fine-grained guidance and inter-frame
interaction. Additionally, the scarcity of high-quality data in this field
makes it difficult to precisely control storytelling tasks, including the
subject's position, appearance, clothing, expression, and posture, thereby
hindering further advancements. In this paper, we demonstrate that layout
conditions, such as the subject's position and detailed attributes, effectively
facilitate fine-grained interactions between frames. This not only strengthens
the consistency of the generated frame sequence but also allows for precise
control over the subject's position, appearance, and other key details.
Building on this, we introduce an advanced storytelling task: Layout-Togglable
Storytelling, which enables precise subject control by incorporating layout
conditions. To address the lack of high-quality datasets with layout
annotations for this task, we develop Lay2Story-1M, which contains over 1
million 720p and higher-resolution images, processed from approximately 11,300
hours of cartoon videos. Building on Lay2Story-1M, we create Lay2Story-Bench, a
benchmark with 3,000 prompts designed to evaluate the performance of different
methods on this task. Furthermore, we propose Lay2Story, a robust framework
based on the Diffusion Transformers (DiTs) architecture for Layout-Togglable
Storytelling tasks. Through both qualitative and quantitative experiments, we
find that our method outperforms the previous state-of-the-art (SOTA)
techniques, achieving the best results in terms of consistency, semantic
correlation, and aesthetic quality.

</details>


### [98] [Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering](https://arxiv.org/abs/2508.08974)
*Elman Ghazaei,Erchan Aptoula*

Main category: cs.CV

TL;DR: 针对变化检测视觉问答（CDVQA）中的域偏移问题，本文提出了一个新的多模态多域数据集BrightVQA和一个文本条件状态空间模型（TCSSM），该模型通过整合图像和文本信息来提取域不变特征，并在实验中展现出卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 传统变化检测方法需要专业知识。为使非专家用户更广泛地获取变化信息，引入了CDVQA任务。然而，现有CDVQA方法假设训练和测试数据集分布相似，这在存在域偏移的真实世界应用中无法成立。

Method: 1. 引入了一个新的多模态、多域数据集BrightVQA，以促进CDVQA中的域泛化研究。2. 提出了一种新颖的文本条件状态空间模型（TCSSM），该模型统一利用双时相图像和地理灾害相关的文本信息，以提取跨域的域不变特征。3. TCSSM中的输入依赖参数通过双时相图像和地理灾害描述动态预测，以促进视觉数据与文本描述的对齐。

Result: 广泛的实验表明，所提出的方法在与现有最先进模型的比较中持续展现出卓越的性能。

Conclusion: 本文成功解决了CDVQA任务中的域偏移问题，通过引入新的多模态多域数据集和文本条件状态空间模型（TCSSM），实现了在真实世界应用中更鲁棒、更准确的变化检测视觉问答能力。

Abstract: The Earth's surface is constantly changing, and detecting these changes
provides valuable insights that benefit various aspects of human society. While
traditional change detection methods have been employed to detect changes from
bi-temporal images, these approaches typically require expert knowledge for
accurate interpretation. To enable broader and more flexible access to change
information by non-expert users, the task of Change Detection Visual Question
Answering (CDVQA) has been introduced. However, existing CDVQA methods have
been developed under the assumption that training and testing datasets share
similar distributions. This assumption does not hold in real-world
applications, where domain shifts often occur. In this paper, the CDVQA task is
revisited with a focus on addressing domain shift. To this end, a new
multi-modal and multi-domain dataset, BrightVQA, is introduced to facilitate
domain generalization research in CDVQA. Furthermore, a novel state space
model, termed Text-Conditioned State Space Model (TCSSM), is proposed. The
TCSSM framework is designed to leverage both bi-temporal imagery and
geo-disaster-related textual information in an unified manner to extract
domain-invariant features across domains. Input-dependent parameters existing
in TCSSM are dynamically predicted by using both bi-temporal images and
geo-disaster-related description, thereby facilitating the alignment between
bi-temporal visual data and the associated textual descriptions. Extensive
experiments are conducted to evaluate the proposed method against
state-of-the-art models, and superior performance is consistently demonstrated.
The code and dataset will be made publicly available upon acceptance at
https://github.com/Elman295/TCSSM.

</details>


### [99] [TaoCache: Structure-Maintained Video Generation Acceleration](https://arxiv.org/abs/2508.08978)
*Zhentao Fan,Zongzuo Wang,Weiwei Zhang*

Main category: cs.CV

TL;DR: TaoCache是一种免训练、即插即用的视频扩散模型缓存策略，通过固定点视角预测噪声输出，特别适用于去噪后期阶段，显著提升了生成质量和一致性，优于现有加速方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视频扩散模型缓存加速方法主要跳过早期或中期去噪步骤，导致结构不一致，并损害指令遵循和角色一致性。

Method: TaoCache是一种免训练、即插即用的缓存策略，它采用固定点视角来预测模型的噪声输出，在去噪后期阶段特别有效。它通过校准连续噪声增量的余弦相似度和范数比来保留高分辨率结构，同时实现激进的跳步。该方法与PAB和TeaCache等其他加速方法正交，并能无缝集成到基于DiT的框架中。

Result: 在Latte-1、OpenSora-Plan v110和Wan2.1等模型上，TaoCache在相同加速比下，比现有缓存方法获得了显著更高的视觉质量（LPIPS、SSIM、PSNR）。

Conclusion: TaoCache通过其独特的固定点预测方法，有效解决了现有缓存加速策略的质量和一致性问题，尤其在去噪后期表现出色，是视频扩散模型加速的有效方案。

Abstract: Existing cache-based acceleration methods for video diffusion models
primarily skip early or mid denoising steps, which often leads to structural
discrepancies relative to full-timestep generation and can hinder instruction
following and character consistency. We present TaoCache, a training-free,
plug-and-play caching strategy that, instead of residual-based caching, adopts
a fixed-point perspective to predict the model's noise output and is
specifically effective in late denoising stages. By calibrating cosine
similarities and norm ratios of consecutive noise deltas, TaoCache preserves
high-resolution structure while enabling aggressive skipping. The approach is
orthogonal to complementary accelerations such as Pyramid Attention Broadcast
(PAB) and TeaCache, and it integrates seamlessly into DiT-based frameworks.
Across Latte-1, OpenSora-Plan v110, and Wan2.1, TaoCache attains substantially
higher visual quality (LPIPS, SSIM, PSNR) than prior caching methods under the
same speedups.

</details>


### [100] [ColorGPT: Leveraging Large Language Models for Multimodal Color Recommendation](https://arxiv.org/abs/2508.08987)
*Ding Xia,Naoto Inoue,Qianru Qiu,Kotaro Kikuchi*

Main category: cs.CV

TL;DR: 本研究探索了预训练大型语言模型（LLMs）在颜色推荐任务中的应用，开发了ColorGPT管道，并在颜色调色板补全和生成任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法在颜色设计中面临复杂性和数据有限的挑战，难以有效地进行颜色推荐。本研究旨在探究LLMs是否能成为更优秀的颜色推荐设计师。

Method: 研究开发了一个名为ColorGPT的管道，该管道通过系统测试多种颜色表示和应用有效的提示工程技术构建。它主要针对基于给定颜色和上下文的颜色调色板补全，并可扩展到根据文本描述生成完整的颜色调色板。

Result: 在颜色调色板补全任务中，基于LLM的管道在颜色建议准确性和颜色分布方面优于现有方法。在完整调色板生成任务中，该方法在颜色多样性和相似性方面也取得了改进。

Conclusion: 预训练LLMs及其常识推理能力可以作为颜色推荐任务的优秀设计师，显著提升颜色建议的质量和多样性。

Abstract: Colors play a crucial role in the design of vector graphic documents by
enhancing visual appeal, facilitating communication, improving usability, and
ensuring accessibility. In this context, color recommendation involves
suggesting appropriate colors to complete or refine a design when one or more
colors are missing or require alteration. Traditional methods often struggled
with these challenges due to the complex nature of color design and the limited
data availability. In this study, we explored the use of pretrained Large
Language Models (LLMs) and their commonsense reasoning capabilities for color
recommendation, raising the question: Can pretrained LLMs serve as superior
designers for color recommendation tasks? To investigate this, we developed a
robust, rigorously validated pipeline, ColorGPT, that was built by
systematically testing multiple color representations and applying effective
prompt engineering techniques. Our approach primarily targeted color palette
completion by recommending colors based on a set of given colors and
accompanying context. Moreover, our method can be extended to full palette
generation, producing an entire color palette corresponding to a provided
textual description. Experimental results demonstrated that our LLM-based
pipeline outperformed existing methods in terms of color suggestion accuracy
and the distribution of colors in the color palette completion task. For the
full palette generation task, our approach also yielded improvements in color
diversity and similarity compared to current techniques.

</details>


### [101] [KFFocus: Highlighting Keyframes for Enhanced Video Understanding](https://arxiv.org/abs/2508.08989)
*Ming Nie,Chunwei Wang,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: KFFocus是一种针对视频LLM的视频令牌高效压缩方法，通过识别关键帧和调整帧内压缩比，同时引入时空建模模块，显著提升了长视频理解的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有视频LLM在处理长视频时，因计算量大而采用帧间均匀采样和帧内令牌压缩策略，但这可能导致关键信息（包含重要时序和语义细节的关键帧）的丢失，因为关键信息在时间上分布不均。

Method: KFFocus通过以下方式解决问题：1. 用基于时间冗余的关键帧识别方法取代均匀采样，以捕获重要帧；2. 根据帧的上下文相关性分配不同的帧内压缩比，以高效减少冗余并保留信息；3. 引入一个时空建模模块，编码帧间时间关系和帧内空间结构，增强对时空动态的理解。

Result: 在广泛认可的视频理解基准测试（特别是长视频场景）中，KFFocus显著优于现有方法，实现了计算效率和准确性的显著提升。

Conclusion: KFFocus通过智能的关键帧选择、自适应的帧内压缩和精细的时空建模，有效解决了长视频理解中的计算效率和信息丢失问题，为视频LLM提供了更强的长视频理解能力。

Abstract: Recently, with the emergence of large language models, multimodal LLMs have
demonstrated exceptional capabilities in image and video modalities. Despite
advancements in video comprehension, the substantial computational demands of
long video sequences lead current video LLMs (Vid-LLMs) to employ compression
strategies at both the inter-frame level (e.g., uniform sampling of video
frames) and intra-frame level (e.g., condensing all visual tokens of each frame
into a limited number). However, this approach often neglects the uneven
temporal distribution of critical information across frames, risking the
omission of keyframes that contain essential temporal and semantic details. To
tackle these challenges, we propose KFFocus, a method designed to efficiently
compress video tokens and emphasize the informative context present within
video frames. We substitute uniform sampling with a refined approach inspired
by classic video compression principles to identify and capture keyframes based
on their temporal redundancy. By assigning varying condensation ratios to
frames based on their contextual relevance, KFFocus efficiently reduces token
redundancy while preserving informative content details. Additionally, we
introduce a spatiotemporal modeling module that encodes both the temporal
relationships between video frames and the spatial structure within each frame,
thus providing Vid-LLMs with a nuanced understanding of spatial-temporal
dynamics. Extensive experiments on widely recognized video understanding
benchmarks, especially long video scenarios, demonstrate that KFFocus
significantly outperforms existing methods, achieving substantial computational
efficiency and enhanced accuracy.

</details>


### [102] [Spatial-Temporal Multi-Scale Quantization for Flexible Motion Generation](https://arxiv.org/abs/2508.08991)
*Zan Wang,Jingze Zhang,Yixin Chen,Baoxiong Jia,Wei Liang,Siyuan Huang*

Main category: cs.CV

TL;DR: 提出MSQ多尺度量化方法，将人体运动序列压缩为时空多尺度离散tokens，解决了现有运动表示在多尺度建模和组合灵活性上的局限性，并支持多种生成任务。


<details>
  <summary>Details</summary>
Motivation: 当前人体运动表示（通常为离散帧序列）存在两大局限性：1) 无法从多尺度视角捕捉运动，限制了对复杂模式的建模能力；2) 缺乏组合灵活性，这对于模型在多样化生成任务中的泛化至关重要。

Method: 引入MSQ（多尺度量化）方法，将运动序列压缩为时空多尺度离散tokens。MSQ使用不同的编码器捕捉不同空间粒度的身体部位，并将编码特征在时间上插值到多个尺度，然后进行量化。在此表示基础上，构建了一个生成式掩码建模模型，以支持运动编辑、运动控制和条件运动生成。

Result: 定量和定性分析表明，MSQ量化方法无需特殊设计或重新训练即可实现运动tokens的无缝组合。广泛评估证明，该方法在各种基准测试中优于现有基线方法。

Conclusion: MSQ通过多尺度离散tokens的创新表示，有效解决了现有运动表示的局限性，显著提升了运动建模的复杂模式捕捉能力和组合灵活性，并在多种生成任务中展现出卓越性能。

Abstract: Despite significant advancements in human motion generation, current motion
representations, typically formulated as discrete frame sequences, still face
two critical limitations: (i) they fail to capture motion from a multi-scale
perspective, limiting the capability in complex patterns modeling; (ii) they
lack compositional flexibility, which is crucial for model's generalization in
diverse generation tasks. To address these challenges, we introduce MSQ, a
novel quantization method that compresses the motion sequence into multi-scale
discrete tokens across spatial and temporal dimensions. MSQ employs distinct
encoders to capture body parts at varying spatial granularities and temporally
interpolates the encoded features into multiple scales before quantizing them
into discrete tokens. Building on this representation, we establish a
generative mask modeling model to effectively support motion editing, motion
control, and conditional motion generation. Through quantitative and
qualitative analysis, we show that our quantization method enables the seamless
composition of motion tokens without requiring specialized design or
re-training. Furthermore, extensive evaluations demonstrate that our approach
outperforms existing baseline methods on various benchmarks.

</details>


### [103] [UniConvNet: Expanding Effective Receptive Field while Maintaining Asymptotically Gaussian Distribution for ConvNets of Any Scale](https://arxiv.org/abs/2508.09000)
*Yuhao Wang,Wei Xi*

Main category: cs.CV

TL;DR: 本文提出了一种名为UniConvNet的新型卷积神经网络范式，通过组合小尺寸卷积核来高效扩展有效感受野（ERF）并保持其渐近高斯分布（AGD），在多种视觉任务上超越现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 现有具有大有效感受野的卷积网络（ConvNets）面临参数和计算成本高昂，以及有效感受野的渐近高斯分布（AGD）被破坏的问题。

Method: 论文提出了一种替代范式：通过合理组合较小的卷积核（如7x7, 9x9, 11x11），在扩展有效感受野的同时保持其AGD。为此，引入了“三层感受野聚合器”（Three-layer Receptive Field Aggregator）和“层运算符”（Layer Operator）作为基本操作，并堆叠这些模块构建了UniConvNet模型。

Result: UniConvNet在ImageNet-1K、COCO2017和ADE20K等数据集上的广泛实验表明，其在轻量级和大型模型上均优于最先进的CNN和ViT。例如，UniConvNet-T以30M参数和5.1G FLOPs实现了84.2%的ImageNet top-1准确率；UniConvNet-XL在ImageNet上达到了88.4%的top-1准确率。

Conclusion: 通过结合小尺寸卷积核以高效扩展感受野并保持其AGD，UniConvNet为任意规模的卷积神经网络提供了一个通用的模型，在多种视觉识别任务上表现出卓越的性能和可扩展性。

Abstract: Convolutional neural networks (ConvNets) with large effective receptive field
(ERF), still in their early stages, have demonstrated promising effectiveness
while constrained by high parameters and FLOPs costs and disrupted
asymptotically Gaussian distribution (AGD) of ERF. This paper proposes an
alternative paradigm: rather than merely employing extremely large ERF, it is
more effective and efficient to expand the ERF while maintaining AGD of ERF by
proper combination of smaller kernels, such as $7\times{7}$, $9\times{9}$,
$11\times{11}$. This paper introduces a Three-layer Receptive Field Aggregator
and designs a Layer Operator as the fundamental operator from the perspective
of receptive field. The ERF can be expanded to the level of existing
large-kernel ConvNets through the stack of proposed modules while maintaining
AGD of ERF. Using these designs, we propose a universal model for ConvNet of
any scale, termed UniConvNet. Extensive experiments on ImageNet-1K, COCO2017,
and ADE20K demonstrate that UniConvNet outperforms state-of-the-art CNNs and
ViTs across various vision recognition tasks for both lightweight and
large-scale models with comparable throughput. Surprisingly, UniConvNet-T
achieves $84.2\%$ ImageNet top-1 accuracy with $30M$ parameters and $5.1G$
FLOPs. UniConvNet-XL also shows competitive scalability to big data and large
models, acquiring $88.4\%$ top-1 accuracy on ImageNet. Code and models are
publicly available at https://github.com/ai-paperwithcode/UniConvNet.

</details>


### [104] [Towards Perfection: Building Inter-component Mutual Correction for Retinex-based Low-light Image Enhancement](https://arxiv.org/abs/2508.09009)
*Luyang Cao,Han Xu,Jian Zhang,Lei Qi,Jiayi Ma,Yinghuan Shi,Yang Gao*

Main category: cs.CV

TL;DR: 本文提出一种新的Inter-correction Retinex模型（IRetinex），通过在分解和增强阶段缓解低光图像增强中Retinex模型固有的“组件间残差”（ICR）问题，显著提升了图像质量。


<details>
  <summary>Details</summary>
Motivation: Retinex基深度学习方法在低光图像增强中因其可解释性而备受关注，但其将图像分解为光照和反射分量时，难以实现完美分解，会留下“组件间残差”（ICR）。这些ICR不仅影响分解精度，还导致增强分量偏离理想结果，最终降低合成图像质量，且此前方法普遍低估了ICR的影响。

Method: 本文提出Inter-correction Retinex模型（IRetinex）。在分解阶段，利用组件间残差减少模块来降低光照和反射分量之间的特征相似性；在增强阶段，利用两分量间的特征相似性来检测并减轻每个增强单元内ICR的影响。

Result: 在三个低光基准数据集上的大量实验表明，通过减少ICR，所提出的方法在定性和定量上均优于现有的最先进方法。

Conclusion: 组件间残差（ICR）是Retinex基低光图像增强方法中一个被低估的关键问题。通过在分解和增强阶段有效缓解ICR，可以显著提高图像增强的质量和性能。

Abstract: In low-light image enhancement, Retinex-based deep learning methods have
garnered significant attention due to their exceptional interpretability. These
methods decompose images into mutually independent illumination and reflectance
components, allows each component to be enhanced separately. In fact, achieving
perfect decomposition of illumination and reflectance components proves to be
quite challenging, with some residuals still existing after decomposition. In
this paper, we formally name these residuals as inter-component residuals
(ICR), which has been largely underestimated by previous methods. In our
investigation, ICR not only affects the accuracy of the decomposition but also
causes enhanced components to deviate from the ideal outcome, ultimately
reducing the final synthesized image quality. To address this issue, we propose
a novel Inter-correction Retinex model (IRetinex) to alleviate ICR during the
decomposition and enhancement stage. In the decomposition stage, we leverage
inter-component residual reduction module to reduce the feature similarity
between illumination and reflectance components. In the enhancement stage, we
utilize the feature similarity between the two components to detect and
mitigate the impact of ICR within each enhancement unit. Extensive experiments
on three low-light benchmark datasets demonstrated that by reducing ICR, our
method outperforms state-of-the-art approaches both qualitatively and
quantitatively.

</details>


### [105] [Uncertainty-aware Cross-training for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2508.09014)
*Kaiwen Huang,Tao Zhou,Huazhu Fu,Yizhe Zhang,Yi Zhou,Xiao-Jun Wu*

Main category: cs.CV

TL;DR: 本文提出了UC-Seg，一个不确定性感知交叉训练框架，用于半监督医学图像分割。它通过两个子网络协同工作来减轻认知偏差，并利用不确定性图生成高置信度伪标签，在多模态医学图像分割任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 半监督学习在医学图像分割中广受欢迎，但现有方法存在局限性：基于Mean-Teacher的方法过度依赖学生模型并忽视认知偏差；一些协同训练方法难以从扰动输入中生成高置信度伪标签。

Method: 提出不确定性感知交叉训练框架(UC-Seg)。该框架包含两个独立的子网络，通过探索和利用它们之间的关联来减轻模型中的认知偏差。具体包括：1) 跨子网络一致性保持(CCP)策略，增强特征表示能力并确保特征一致性，使每个子网络能纠正自身偏差并学习共享语义；2) 不确定性感知伪标签生成(UPG)组件，利用两个子网络的分割结果和相应的不确定性图生成高置信度伪标签。

Result: 在MRI、CT、超声、结肠镜等多种模态的医学图像分割任务中对所提出的UC-Seg进行了广泛评估。结果表明，与现有最先进的半监督方法相比，UC-Seg实现了卓越的分割精度和泛化性能。

Conclusion: UC-Seg框架通过引入双子网络协同和不确定性感知伪标签生成，有效解决了半监督医学图像分割中模型认知偏差和伪标签质量问题，显著提升了分割准确性和泛化能力。

Abstract: Semi-supervised learning has gained considerable popularity in medical image
segmentation tasks due to its capability to reduce reliance on expert-examined
annotations. Several mean-teacher (MT) based semi-supervised methods utilize
consistency regularization to effectively leverage valuable information from
unlabeled data. However, these methods often heavily rely on the student model
and overlook the potential impact of cognitive biases within the model.
Furthermore, some methods employ co-training using pseudo-labels derived from
different inputs, yet generating high-confidence pseudo-labels from perturbed
inputs during training remains a significant challenge. In this paper, we
propose an Uncertainty-aware Cross-training framework for semi-supervised
medical image Segmentation (UC-Seg). Our UC-Seg framework incorporates two
distinct subnets to effectively explore and leverage the correlation between
them, thereby mitigating cognitive biases within the model. Specifically, we
present a Cross-subnet Consistency Preservation (CCP) strategy to enhance
feature representation capability and ensure feature consistency across the two
subnets. This strategy enables each subnet to correct its own biases and learn
shared semantics from both labeled and unlabeled data. Additionally, we propose
an Uncertainty-aware Pseudo-label Generation (UPG) component that leverages
segmentation results and corresponding uncertainty maps from both subnets to
generate high-confidence pseudo-labels. We extensively evaluate the proposed
UC-Seg on various medical image segmentation tasks involving different modality
images, such as MRI, CT, ultrasound, colonoscopy, and so on. The results
demonstrate that our method achieves superior segmentation accuracy and
generalization performance compared to other state-of-the-art semi-supervised
methods. Our code will be released at https://github.com/taozh2017/UCSeg.

</details>


### [106] [Per-Query Visual Concept Learning](https://arxiv.org/abs/2508.09045)
*Ori Malca,Dvir Samuel,Gal Chechik*

Main category: cs.CV

TL;DR: 本文提出一种针对提示词和噪声种子特化的个性化步骤，利用自注意力与交叉注意力损失（基于PDM特征）来显著提升现有文本到图像个性化方法的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉概念学习（即文本到图像个性化）在产品植入、娱乐和个性化设计等领域有广泛应用。现有方法仍有提升空间，尤其是在捕获个性化概念的身份方面。

Method: 该方法通过增加一个个性化步骤来增强现有方法，此步骤具备两个特点：1) 针对提示词和噪声种子特定化；2) 使用基于自注意力和交叉注意力的两个损失项，结合PDM特征来捕获个性化概念的身份。

Result: 在六种不同的个性化方法和多种基于UNet和DiT的文本到图像模型上进行评估，结果显示即使相较于先前的按查询个性化方法，本文方法也能带来显著的性能提升。

Conclusion: 通过引入特定的个性化步骤和基于注意力与PDM特征的损失，可以显著改进视觉概念学习和文本到图像个性化的效果。

Abstract: Visual concept learning, also known as Text-to-image personalization, is the
process of teaching new concepts to a pretrained model. This has numerous
applications from product placement to entertainment and personalized design.
Here we show that many existing methods can be substantially augmented by
adding a personalization step that is (1) specific to the prompt and noise
seed, and (2) using two loss terms based on the self- and cross- attention,
capturing the identity of the personalized concept. Specifically, we leverage
PDM features -- previously designed to capture identity -- and show how they
can be used to improve personalized semantic similarity. We evaluate the
benefit that our method gains on top of six different personalization methods,
and several base text-to-image models (both UNet- and DiT-based). We find
significant improvements even over previous per-query personalization methods.

</details>


### [107] [ALFred: An Active Learning Framework for Real-world Semi-supervised Anomaly Detection with Adaptive Thresholds](https://arxiv.org/abs/2508.09058)
*Shanle Yao,Ghazal Alinezhad Noghre,Armin Danesh Pazho,Hamed Tabkhi*

Main category: cs.CV

TL;DR: 本文提出了一种针对视频异常检测（VAD）的主动学习框架，该框架结合了人工干预，以适应不断变化的真实世界条件，并动态定义正常与异常行为的区分阈值。


<details>
  <summary>Details</summary>
Motivation: 视频异常检测在现实世界中应用面临挑战，原因在于人类行为的动态性、环境变化和领域漂移。传统的评估指标依赖静态假设，无法在动态环境中有效区分正常与异常，因此需要一种能适应这些变化的解决方案。

Method: 引入了一个主动学习框架，持续选择最具信息量的数据点进行标注，以增强模型适应性。关键创新是引入了“人机协作”机制，通过人工干预来识别AI伪标签结果中的真实正常和异常实例。收集到的数据用于定义适应不同环境的动态阈值。该方法在一个模拟真实世界的实验室框架中实现，并使用新的评估指标进行测试。

Result: 在模拟真实世界的场景中，该方法在Q3指标上取得了68.91的EBI（错误平衡指数），证明了其实际有效性。

Conclusion: 该方法有效提升了视频异常检测在动态环境中的实用性和适用性，通过主动学习和人工干预实现了对不断变化的现实条件的适应性，并能定义自适应阈值。

Abstract: Video Anomaly Detection (VAD) can play a key role in spotting unusual
activities in video footage. VAD is difficult to use in real-world settings due
to the dynamic nature of human actions, environmental variations, and domain
shifts. Traditional evaluation metrics often prove inadequate for such
scenarios, as they rely on static assumptions and fall short of identifying a
threshold that distinguishes normal from anomalous behavior in dynamic
settings. To address this, we introduce an active learning framework tailored
for VAD, designed for adapting to the ever-changing real-world conditions. Our
approach leverages active learning to continuously select the most informative
data points for labeling, thereby enhancing model adaptability. A critical
innovation is the incorporation of a human-in-the-loop mechanism, which enables
the identification of actual normal and anomalous instances from
pseudo-labeling results generated by AI. This collected data allows the
framework to define an adaptive threshold tailored to different environments,
ensuring that the system remains effective as the definition of 'normal' shifts
across various settings. Implemented within a lab-based framework that
simulates real-world conditions, our approach allows rigorous testing and
refinement of VAD algorithms with a new metric. Experimental results show that
our method achieves an EBI (Error Balance Index) of 68.91 for Q3 in real-world
simulated scenarios, demonstrating its practical effectiveness and
significantly enhancing the applicability of VAD in dynamic environments.

</details>


### [108] [VLM-3D:End-to-End Vision-Language Models for Open-World 3D Perception](https://arxiv.org/abs/2508.09061)
*Fuhao Chang,Shuxin Li,Yabei Li,Lei He*

Main category: cs.CV

TL;DR: VLM-3D是一个端到端的框架，利用视觉语言模型（VLMs）解决自动驾驶中的开放集3D感知问题，通过LoRA和联合语义-几何损失提高感知精度。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在复杂交通环境中识别未曾见过的物体类别（开放集感知）是一个关键挑战，现有利用VLM的方法存在多阶段误差传播，影响感知精度。

Method: 提出了VLM-3D，首个使VLM能够进行3D几何感知的端到端框架。它采用低秩适应（LoRA）高效地将VLM适应于驾驶任务，并引入了联合语义-几何损失设计：早期训练使用token级语义损失确保稳定收敛，后期引入3D IoU损失以提高3D边界框预测精度。

Result: 在nuScenes数据集上的评估表明，VLM-3D中提出的联合语义-几何损失使感知精度提高了12.8%。

Conclusion: VLM-3D及其联合语义-几何损失的有效性得到了充分验证，证明了该方法在自动驾驶3D感知领域的先进性。

Abstract: Open-set perception in complex traffic environments poses a critical
challenge for autonomous driving systems, particularly in identifying
previously unseen object categories, which is vital for ensuring safety. Visual
Language Models (VLMs), with their rich world knowledge and strong semantic
reasoning capabilities, offer new possibilities for addressing this task.
However, existing approaches typically leverage VLMs to extract visual features
and couple them with traditional object detectors, resulting in multi-stage
error propagation that hinders perception accuracy. To overcome this
limitation, we propose VLM-3D, the first end-to-end framework that enables VLMs
to perform 3D geometric perception in autonomous driving scenarios. VLM-3D
incorporates Low-Rank Adaptation (LoRA) to efficiently adapt VLMs to driving
tasks with minimal computational overhead, and introduces a joint
semantic-geometric loss design: token-level semantic loss is applied during
early training to ensure stable convergence, while 3D IoU loss is introduced in
later stages to refine the accuracy of 3D bounding box predictions. Evaluations
on the nuScenes dataset demonstrate that the proposed joint semantic-geometric
loss in VLM-3D leads to a 12.8% improvement in perception accuracy, fully
validating the effectiveness and advancement of our method.

</details>


### [109] [Scaling Learned Image Compression Models up to 1 Billion](https://arxiv.org/abs/2508.09075)
*Yuqi Li,Haotian Zhang,Li Li,Dong Liu,Feng Wu*

Main category: cs.CV

TL;DR: 本文首次研究了学习型图像压缩模型的规模扩展，揭示了性能与模型大小及计算量的标度律关系，并展示了大规模模型在压缩性能上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的进步揭示了智能与压缩之间的紧密联系。尽管学习型图像压缩已取得进展，但当前模型规模有限，限制了其表示能力，且模型规模如何影响压缩性能尚不明确。

Method: 以最先进的HPCM模型为基线，将模型参数从6850万扩展到10亿。通过拟合测试损失与模型大小、最优训练计算量等关键标度变量之间的幂律关系，揭示了性能趋势。

Result: 研究揭示了模型性能的标度趋势，使得能够外推到更大规模的模型。实验结果表明，扩展后的HPCM-1B模型实现了最先进的率失真性能。

Conclusion: 这项工作有望启发未来对大规模压缩模型的探索，并促进对压缩与智能之间联系的更深入研究。

Abstract: Recent advances in large language models (LLMs) highlight a strong connection
between intelligence and compression. Learned image compression, a fundamental
task in modern data compression, has made significant progress in recent years.
However, current models remain limited in scale, restricting their
representation capacity, and how scaling model size influences compression
performance remains unexplored. In this work, we present a pioneering study on
scaling up learned image compression models and revealing the performance
trends through scaling laws. Using the recent state-of-the-art HPCM model as
baseline, we scale model parameters from 68.5 millions to 1 billion and fit
power-law relations between test loss and key scaling variables, including
model size and optimal training compute. The results reveal a scaling trend,
enabling extrapolation to larger scale models. Experimental results demonstrate
that the scaled-up HPCM-1B model achieves state-of-the-art rate-distortion
performance. We hope this work inspires future exploration of large-scale
compression models and deeper investigations into the connection between
compression and intelligence.

</details>


### [110] [Addressing Bias in VLMs for Glaucoma Detection Without Protected Attribute Supervision](https://arxiv.org/abs/2508.09087)
*Ahsan Habib Akash,Greg Murray,Annahita Amireskandari,Joel Palko,Carol Laxson,Binod Bhattarai,Prashnna Gyawali*

Main category: cs.CV

TL;DR: 本文提出一种针对视觉语言模型（VLMs）的无属性去偏方法，通过无监督聚类和梯度相似性加权来提升医疗图像（青光眼筛查）中表现不佳的子组，从而减少人口统计学偏见和不平等。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在多模态任务中取得了显著成功，但即使在训练中没有明确的受保护属性，它们也可能表现出人口统计学偏见。青光眼筛查是一个关键的医疗应用，因为它会导致不可逆转的失明，并且不成比例地影响服务不足的人群，因此解决VLM在该应用中的偏见问题至关重要。

Method: 该研究引入了一种基于重加权对比学习框架的无属性去偏方法。具体步骤包括：(i) 通过对图像-图像嵌入进行无监督聚类来推断代理子组；(ii) 计算CLIP风格的多模态损失与SimCLR风格的图像对对比损失之间的梯度相似性权重；(iii) 将这些权重应用于一个联合的、top-k加权目标，以提高表现不佳聚类的权重。该方法是无标签的，并自适应地针对最难的样本，旨在减少子组差异。

Result: 该方法在Harvard FairVLMed青光眼子集上进行了评估，并报告了均衡赔率距离（EOD）、均衡子组AUC（ES AUC）和组间AUC。结果表明，该方法在推断的人口统计学子组中实现了公平的性能。

Conclusion: 该研究提出的无属性去偏方法能够有效减少VLMs在自动化青光眼筛查中可能存在的子组不平等，从而在关键医疗应用中实现更公平的性能，特别是在服务不足人群中。

Abstract: Vision-Language Models (VLMs) have achieved remarkable success on multimodal
tasks such as image-text retrieval and zero-shot classification, yet they can
exhibit demographic biases even when explicit protected attributes are absent
during training. In this work, we focus on automated glaucoma screening from
retinal fundus images, a critical application given that glaucoma is a leading
cause of irreversible blindness and disproportionately affects underserved
populations. Building on a reweighting-based contrastive learning framework, we
introduce an attribute-agnostic debiasing method that (i) infers proxy
subgroups via unsupervised clustering of image-image embeddings, (ii) computes
gradient-similarity weights between the CLIP-style multimodal loss and a
SimCLR-style image-pair contrastive loss, and (iii) applies these weights in a
joint, top-$k$ weighted objective to upweight underperforming clusters. This
label-free approach adaptively targets the hardest examples, thereby reducing
subgroup disparities. We evaluate our method on the Harvard FairVLMed glaucoma
subset, reporting Equalized Odds Distance (EOD), Equalized Subgroup AUC (ES
AUC), and Groupwise AUC to demonstrate equitable performance across inferred
demographic subgroups.

</details>


### [111] [Deep Learning Models for Robust Facial Liveness Detection](https://arxiv.org/abs/2508.09094)
*Oleksandr Kuznetsov,Emanuele Frontoni,Luca Romeo,Riccardo Rosati,Andrea Maranesi,Alessandro Muscatello*

Main category: cs.CV

TL;DR: 本研究提出了一种基于深度学习的新型面部识别防欺骗方案，通过整合纹理分析和反射特性，有效区分真实人脸和伪造攻击，显著提升了生物识别系统的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的活体检测技术在面对深度伪造（deepfakes）等AI驱动的复杂欺骗攻击时表现不足，严重影响了面部识别等生物识别认证系统的可靠性，因此需要更鲁棒的解决方案。

Method: 研究引入了新颖的深度学习模型（例如AttackNet V2.2），创新性地整合了纹理分析和真实人类特征相关的反射特性，以区分真实存在和伪造复制品。模型在五个多样化数据集上进行了广泛评估。

Result: 实验结果显示，该方法比现有系统有显著进步，其中最佳模型AttackNet V2.2在组合数据训练下达到了99.9%的平均准确率。此外，研究还揭示了欺骗攻击行为模式的关键见解。

Conclusion: 本研究的模型不仅增强了认证过程，还提升了各行各业对生物识别系统的信心，为安全访问提供了更可靠的保障。

Abstract: In the rapidly evolving landscape of digital security, biometric
authentication systems, particularly facial recognition, have emerged as
integral components of various security protocols. However, the reliability of
these systems is compromised by sophisticated spoofing attacks, where imposters
gain unauthorized access by falsifying biometric traits. Current literature
reveals a concerning gap: existing liveness detection methodologies - designed
to counteract these breaches - fall short against advanced spoofing tactics
employing deepfakes and other artificial intelligence-driven manipulations.
This study introduces a robust solution through novel deep learning models
addressing the deficiencies in contemporary anti-spoofing techniques. By
innovatively integrating texture analysis and reflective properties associated
with genuine human traits, our models distinguish authentic presence from
replicas with remarkable precision. Extensive evaluations were conducted across
five diverse datasets, encompassing a wide range of attack vectors and
environmental conditions. Results demonstrate substantial advancement over
existing systems, with our best model (AttackNet V2.2) achieving 99.9% average
accuracy when trained on combined data. Moreover, our research unveils critical
insights into the behavioral patterns of impostor attacks, contributing to a
more nuanced understanding of their evolving nature. The implications are
profound: our models do not merely fortify the authentication processes but
also instill confidence in biometric systems across various sectors reliant on
secure access.

</details>


### [112] [Turbo-VAED: Fast and Stable Transfer of Video-VAEs to Mobile Devices](https://arxiv.org/abs/2508.09136)
*Ya Zou,Jingfeng Yao,Siyuan Yu,Shuai Zhang,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为Turbo-VAED的低成本解决方案，通过优化架构和训练方法，高效地将视频VAE部署到移动设备上，解决了其计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 将大型生成式AI模型部署到移动设备的需求日益增长，但视频生成模型中的变分自编码器（VAE）因参数量大和内核不匹配，导致在移动设备上出现内存不足或推理速度极慢的问题，成为主要计算瓶颈。

Method: 1. 通过分析现有VAE架构的冗余性，并集成3D深度可分离卷积，显著减少了模型参数。2. 针对主流视频VAE中不适合移动硬件的升采样技术，提出了一种解耦的3D像素重排方案，以降低端到端延迟，并在此基础上开发了通用移动端VAE解码器Turbo-VAED。3. 提出了一种高效的VAE解码器训练方法，通过将解码器蒸馏到Turbo-VAED，而非重新训练整个VAE，实现了快速移动适应和最小的性能损失。

Result: 该方法首次实现了移动设备上的实时720p视频VAE解码，并广泛适用于大多数视频VAE。将其集成到四个代表性模型中，训练成本低至95美元，在GPU上将原始VAE在720p分辨率下加速高达84.5倍，参数量仅为原始的17.5%，并保持了96.9%的原始重建质量。与移动优化的VAE相比，Turbo-VAED在iPhone 16 Pro上实现了2.9倍的帧率提升和更好的重建质量。

Conclusion: Turbo-VAED提供了一种低成本且高效的解决方案，能够将广泛使用的视频VAE成功迁移到移动设备上，显著提升了推理速度和效率，同时保持了高重建质量，克服了现有VAE在移动部署中的主要障碍。

Abstract: There is a growing demand for deploying large generative AI models on mobile
devices. For recent popular video generative models, however, the Variational
AutoEncoder (VAE) represents one of the major computational bottlenecks. Both
large parameter sizes and mismatched kernels cause out-of-memory errors or
extremely slow inference on mobile devices. To address this, we propose a
low-cost solution that efficiently transfers widely used video VAEs to mobile
devices. (1) We analyze redundancy in existing VAE architectures and get
empirical design insights. By integrating 3D depthwise separable convolutions
into our model, we significantly reduce the number of parameters. (2) We
observe that the upsampling techniques in mainstream video VAEs are poorly
suited to mobile hardware and form the main bottleneck. In response, we propose
a decoupled 3D pixel shuffle scheme that slashes end-to-end delay. Building
upon these, we develop a universal mobile-oriented VAE decoder, Turbo-VAED. (3)
We propose an efficient VAE decoder training method. Since only the decoder is
used during deployment, we distill it to Turbo-VAED instead of retraining the
full VAE, enabling fast mobile adaptation with minimal performance loss. To our
knowledge, our method enables real-time 720p video VAE decoding on mobile
devices for the first time. This approach is widely applicable to most video
VAEs. When integrated into four representative models, with training cost as
low as $95, it accelerates original VAEs by up to 84.5x at 720p resolution on
GPUs, uses as low as 17.5% of original parameter count, and retains 96.9% of
the original reconstruction quality. Compared to mobile-optimized VAEs,
Turbo-VAED achieves a 2.9x speedup in FPS and better reconstruction quality on
the iPhone 16 Pro. The code and models will soon be available at
https://github.com/hustvl/Turbo-VAED.

</details>


### [113] [HumanOLAT: A Large-Scale Dataset for Full-Body Human Relighting and Novel-View Synthesis](https://arxiv.org/abs/2508.09137)
*Timo Teufel,Pulkit Gera,Xilong Zhou,Umar Iqbal,Pramod Rao,Jan Kautz,Vladislav Golyanik,Christian Theobalt*

Main category: cs.CV

TL;DR: 本文介绍了HumanOLAT数据集，这是首个公开的大规模多视角全身人体“逐光”捕捉数据集，旨在解决数字人像重打光和新视角渲染领域高质量数据集缺失的问题。


<details>
  <summary>Details</summary>
Motivation: 数字人像的同步重打光和新视角渲染是一项重要但具有挑战性的任务，其进展受到高质量公开数据集（特别是全身人体捕捉数据）严重限制。

Method: 引入了HumanOLAT数据集，通过多视角“逐光”（OLAT）捕捉全身人体，包含白光、环境贴图、颜色渐变和细粒度OLAT照明下的HDR RGB帧。

Result: 对现有最先进的重打光和新视角合成方法进行评估，结果突出了该数据集的价值，并揭示了在建模复杂以人为中心的外观和光照交互方面仍存在的显著挑战。

Conclusion: HumanOLAT数据集将极大地促进未来研究，为通用和针对人类的重打光和渲染技术提供严格的基准测试和进步机会。

Abstract: Simultaneous relighting and novel-view rendering of digital human
representations is an important yet challenging task with numerous
applications. Progress in this area has been significantly limited due to the
lack of publicly available, high-quality datasets, especially for full-body
human captures. To address this critical gap, we introduce the HumanOLAT
dataset, the first publicly accessible large-scale dataset of multi-view
One-Light-at-a-Time (OLAT) captures of full-body humans. The dataset includes
HDR RGB frames under various illuminations, such as white light, environment
maps, color gradients and fine-grained OLAT illuminations. Our evaluations of
state-of-the-art relighting and novel-view synthesis methods underscore both
the dataset's value and the significant challenges still present in modeling
complex human-centric appearance and lighting interactions. We believe
HumanOLAT will significantly facilitate future research, enabling rigorous
benchmarking and advancements in both general and human-specific relighting and
rendering techniques.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [114] [Argument Quality Annotation and Gender Bias Detection in Financial Communication through Large Language Models](https://arxiv.org/abs/2508.08262)
*Alaa Alhamzeh,Mays Al Rebdawi*

Main category: cs.CL

TL;DR: 本文评估了GPT-4o、Llama 3.1和Gemma 2在金融论证质量标注方面的能力，发现LLM在标注一致性上优于人类，但仍存在性别偏见。


<details>
  <summary>Details</summary>
Motivation: 金融论证对投资决策和公众信任至关重要，但对其质量的评估研究不足。本文旨在探究LLM在评估金融论证质量方面的潜力。

Method: 使用FinArgQuality数据集，评估了GPT-4o、Llama 3.1和Gemma 2这三种LLM在金融论证质量标注上的表现。方法包括：1) 评估LLM生成标注的跨运行一致性，并与人类标注进行基准测试。2) 引入对抗性攻击，注入性别偏见以分析模型响应、公平性和鲁棒性。所有实验均在三种温度设置下进行，以评估其对标注稳定性和与人类标签一致性的影响。

Result: 研究发现，基于LLM的标注在标注者间一致性方面高于人类标注，但模型仍表现出不同程度的性别偏见。

Conclusion: LLM在金融论证质量标注方面具有潜力，可以实现更高的标注一致性，但需要关注并解决其固有的偏见问题。研究提供了多方面分析和实践建议，以指导未来更可靠、经济高效和偏见感知的标注方法研究。

Abstract: Financial arguments play a critical role in shaping investment decisions and
public trust in financial institutions. Nevertheless, assessing their quality
remains poorly studied in the literature. In this paper, we examine the
capabilities of three state-of-the-art LLMs GPT-4o, Llama 3.1, and Gemma 2 in
annotating argument quality within financial communications, using the
FinArgQuality dataset. Our contributions are twofold. First, we evaluate the
consistency of LLM-generated annotations across multiple runs and benchmark
them against human annotations. Second, we introduce an adversarial attack
designed to inject gender bias to analyse models responds and ensure model's
fairness and robustness. Both experiments are conducted across three
temperature settings to assess their influence on annotation stability and
alignment with human labels. Our findings reveal that LLM-based annotations
achieve higher inter-annotator agreement than human counterparts, though the
models still exhibit varying degrees of gender bias. We provide a multifaceted
analysis of these outcomes and offer practical recommendations to guide future
research toward more reliable, cost-effective, and bias-aware annotation
methodologies.

</details>


### [115] [TurQUaz at CheckThat! 2025: Debating Large Language Models for Scientific Web Discourse Detection](https://arxiv.org/abs/2508.08265)
*Tarık Saraç,Selin Mergen,Mucahid Kutlu*

Main category: cs.CL

TL;DR: 该论文提出了一种新颖的“委员会辩论”方法，通过模拟多LLM的结构化讨论来检测推文中的科学内容，在识别科学研究引用方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决CheckThat! 2025挑战赛任务4a中科学网络话语检测的问题，即判断推文是否包含科学主张、科学研究引用或科学实体提及。

Method: 本文提出了一种“委员会辩论”方法，模拟多大型语言模型（LLM）之间的结构化学术讨论。研究探索了三种辩论方法：1) 单一辩论（两个LLM对立，一个LLM裁决）；2) 团队辩论（多个模型在各自立场内协作）；3) 委员会辩论（多个专家模型在主席模型协调下共同讨论达成共识）。最终选择委员会辩论作为主要模型，因其在开发测试集上表现最佳。

Result: 所提出的方法在检测科学研究引用方面排名第一；但在识别科学主张方面排名第8（共10名），在提及科学实体方面排名第9（共10名）。

Conclusion: 尽管该方法在检测科学主张和科学实体提及方面表现不佳，但其在检测推文中科学研究引用方面取得了领先地位，证明了LLM辩论模型在特定科学话语检测任务上的有效性。

Abstract: In this paper, we present our work developed for the scientific web discourse
detection task (Task 4a) of CheckThat! 2025. We propose a novel council debate
method that simulates structured academic discussions among multiple large
language models (LLMs) to identify whether a given tweet contains (i) a
scientific claim, (ii) a reference to a scientific study, or (iii) mentions of
scientific entities. We explore three debating methods: i) single debate, where
two LLMs argue for opposing positions while a third acts as a judge; ii) team
debate, in which multiple models collaborate within each side of the debate;
and iii) council debate, where multiple expert models deliberate together to
reach a consensus, moderated by a chairperson model. We choose council debate
as our primary model as it outperforms others in the development test set.
Although our proposed method did not rank highly for identifying scientific
claims (8th out of 10) or mentions of scientific entities (9th out of 10), it
ranked first in detecting references to scientific studies.

</details>


### [116] [Heartificial Intelligence: Exploring Empathy in Language Models](https://arxiv.org/abs/2508.08271)
*Victoria Williams,Benjamin Rosman*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在认知同理心方面超越人类，但在情感同理心方面远低于人类，这表明其在提供虚拟陪伴和客观情感支持方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型日益普及并被用作虚拟助手和伴侣，研究它们在人类互动中关键的同理心（包括认知同理心和情感同理心）能力变得重要。

Method: 研究使用标准化心理测试，评估了多个人类受试者（包括心理学学生）、小型语言模型（SLMs）和大型语言模型（LLMs）的认知同理心和情感同理心水平。

Result: 结果显示，LLMs在认知同理心任务上持续优于人类（包括心理学学生），但在情感同理心方面，所有语言模型（SLMs和LLMs）都显著低于人类参与者。

Conclusion: 研究表明语言模型在模拟认知同理心方面取得了快速进展，这使其在提供有效的虚拟陪伴和个性化情感支持方面具有巨大潜力。同时，其高认知同理心和低情感同理心的特点，使其能够提供客观且一致的情感支持，而不会面临情感疲劳或偏见的风险。

Abstract: Large language models have become increasingly common, used by millions of
people worldwide in both professional and personal contexts. As these models
continue to advance, they are frequently serving as virtual assistants and
companions. In human interactions, effective communication typically involves
two types of empathy: cognitive empathy (understanding others' thoughts and
emotions) and affective empathy (emotionally sharing others' feelings). In this
study, we investigated both cognitive and affective empathy across several
small (SLMs) and large (LLMs) language models using standardized psychological
tests. Our results revealed that LLMs consistently outperformed humans -
including psychology students - on cognitive empathy tasks. However, despite
their cognitive strengths, both small and large language models showed
significantly lower affective empathy compared to human participants. These
findings highlight rapid advancements in language models' ability to simulate
cognitive empathy, suggesting strong potential for providing effective virtual
companionship and personalized emotional support. Additionally, their high
cognitive yet lower affective empathy allows objective and consistent emotional
support without running the risk of emotional fatigue or bias.

</details>


### [117] [Real-time News Story Identification](https://arxiv.org/abs/2508.08272)
*Tadej Škvorc,Nikola Ivačič,Sebastjan Hribar,Marko Robnik-Šikonja*

Main category: cs.CL

TL;DR: 本文提出了一种实时新闻故事识别方法，旨在将在线新闻文章自动归类到特定的事件故事中，以提升用户阅读体验。


<details>
  <summary>Details</summary>
Motivation: 新闻网站通常将新闻组织成专题故事以改善阅读体验。现有的文本聚类和主题建模方法不足以根据特定事件、地点和人物对文章进行分组，而新闻故事识别需要这种更细粒度的分组。因此，需要一种能够实时处理并准确识别新闻故事的方法。

Method: 该方法结合了多种文本表示技术、聚类算法和在线主题建模方法（如BERTopic、DBStream和TextClust），以提取故事识别所需的特定事件和命名实体。该系统能够在文章发布时实时将其分配给相应的故事。

Result: 该实时故事识别方法在斯洛文尼亚媒体的一个月新闻数据集上进行了评估，结果表明其产生了人类评估者认为合理的、有意义的结果。

Conclusion: 所提出的实时新闻故事识别方法是有效的，能够根据特定事件、地点和人物将新闻文章分组，并产生高质量的结果，从而改善新闻监控系统的功能和用户体验。

Abstract: To improve the reading experience, many news sites organize news into topical
collections, called stories. In this work, we present an approach for
implementing real-time story identification for a news monitoring system that
automatically collects news articles as they appear online and processes them
in various ways. Story identification aims to assign each news article to a
specific story that the article is covering. The process is similar to text
clustering and topic modeling, but requires that articles be grouped based on
particular events, places, and people, rather than general text similarity (as
in clustering) or general (predefined) topics (as in topic modeling). We
present an approach to story identification that is capable of functioning in
real time, assigning articles to stories as they are published online. In the
proposed approach, we combine text representation techniques, clustering
algorithms, and online topic modeling methods. We combine various text
representation methods to extract specific events and named entities necessary
for story identification, showing that a mixture of online topic-modeling
approaches such as BERTopic, DBStream, and TextClust can be adapted for story
discovery. We evaluate our approach on a news dataset from Slovene media
covering a period of 1 month. We show that our real-time approach produces
sensible results as judged by human evaluators.

</details>


### [118] [TT-XAI: Trustworthy Clinical Text Explanations via Keyword Distillation and LLM Reasoning](https://arxiv.org/abs/2508.08273)
*Kristian Miok,Blaz Škrlj,Daniela Zaharie,Marko Robnik Šikonja*

Main category: cs.CL

TL;DR: TT-XAI框架通过领域感知关键词提炼和LLM推理，提高了临床语言模型在处理冗长EHR时的分类性能和可解释性，使其更值得信赖。


<details>
  <summary>Details</summary>
Motivation: 临床语言模型在应用于冗长、非结构化的电子健康记录（EHRs）时，难以提供可信的预测和解释。

Method: 1. 将原始出院记录提炼为简洁的关键词表示，以增强BERT分类器性能并提高LIME局部解释的保真度。2. 使用关键词引导的提示来指导大型语言模型（LLMs），生成链式思维的临床解释，使其更简洁、临床相关。3. 通过基于删除的保真度指标、LLaMA-3自评估和盲法人类专家研究来评估解释质量。

Result: 关键词提炼显著提升了BERT分类器性能，改进了LIME局部解释的保真度。使用关键词引导的LLM生成了更简洁且临床相关的推理。所有评估方式（保真度、LLaMA-3评分、人类研究）均一致表明关键词增强方法更优，证实提炼增强了机器和人类的可解释性。

Conclusion: TT-XAI通过关键词提炼和LLM推理，为临床决策支持中的可信、可审计AI提供了一条可扩展的途径，同时提升了性能和可解释性。

Abstract: Clinical language models often struggle to provide trustworthy predictions
and explanations when applied to lengthy, unstructured electronic health
records (EHRs). This work introduces TT-XAI, a lightweight and effective
framework that improves both classification performance and interpretability
through domain-aware keyword distillation and reasoning with large language
models (LLMs). First, we demonstrate that distilling raw discharge notes into
concise keyword representations significantly enhances BERT classifier
performance and improves local explanation fidelity via a focused variant of
LIME. Second, we generate chain-of-thought clinical explanations using
keyword-guided prompts to steer LLMs, producing more concise and clinically
relevant reasoning. We evaluate explanation quality using deletion-based
fidelity metrics, self-assessment via LLaMA-3 scoring, and a blinded human
study with domain experts. All evaluation modalities consistently favor the
keyword-augmented method, confirming that distillation enhances both machine
and human interpretability. TT-XAI offers a scalable pathway toward
trustworthy, auditable AI in clinical decision support.

</details>


### [119] [Distilling Knowledge from Large Language Models: A Concept Bottleneck Model for Hate and Counter Speech Recognition](https://arxiv.org/abs/2508.08274)
*Roberto Labadie-Tamayo,Djordje Slijepčević,Xihui Chen,Adrian Jaques Böck,Andreas Babic,Liz Freimann,Christiane Atzmüller Matthias Zeppelzauer*

Main category: cs.CL

TL;DR: 本文提出了一种名为“语音概念瓶颈模型”（SCBM）的透明方法，利用形容词作为可解释的瓶颈概念，用于自动化仇恨言论和反驳言论识别，并在多个数据集上取得了优异的性能和高可解释性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上仇恨言论的迅速增长对社会产生了前所未有的影响，使得自动化检测此类内容变得重要。现有的模型多为“黑箱”模型，缺乏透明度。

Method: 提出了一种名为“语音概念瓶颈模型”（SCBM）的透明方法。SCBM利用大型语言模型（LLMs）将输入文本映射到基于形容词的抽象表示，该表示随后被送入轻量级分类器进行下游任务。研究在涵盖多种语言和平台的五个基准数据集上进行了评估。此外，还将形容词概念表示与Transformer嵌入融合以探索互补信息。

Result: SCBM在五个基准数据集上取得了平均0.69的Macro-F1分数，超越了文献中最近报告的成果（在五个数据集中有四个数据集表现更优）。SCBM提供了高水平的局部和全局可解释性。将形容词概念表示与Transformer嵌入融合后，性能平均提升了1.8%，表明所提出的表示捕获了互补信息。结果表明，基于形容词的概念表示可以作为仇恨言论和反驳言论识别的紧凑、可解释和有效的编码。

Conclusion: 基于形容词的概念表示可以作为仇恨言论和反驳言论识别的紧凑、可解释和有效的编码。通过调整形容词，该方法也可以应用于其他自然语言处理任务。

Abstract: The rapid increase in hate speech on social media has exposed an
unprecedented impact on society, making automated methods for detecting such
content important. Unlike prior black-box models, we propose a novel
transparent method for automated hate and counter speech recognition, i.e.,
"Speech Concept Bottleneck Model" (SCBM), using adjectives as
human-interpretable bottleneck concepts. SCBM leverages large language models
(LLMs) to map input texts to an abstract adjective-based representation, which
is then sent to a light-weight classifier for downstream tasks. Across five
benchmark datasets spanning multiple languages and platforms (e.g., Twitter,
Reddit, YouTube), SCBM achieves an average macro-F1 score of 0.69 which
outperforms the most recently reported results from the literature on four out
of five datasets. Aside from high recognition accuracy, SCBM provides a high
level of both local and global interpretability. Furthermore, fusing our
adjective-based concept representation with transformer embeddings, leads to a
1.8% performance increase on average across all datasets, showing that the
proposed representation captures complementary information. Our results
demonstrate that adjective-based concept representations can serve as compact,
interpretable, and effective encodings for hate and counter speech recognition.
With adapted adjectives, our method can also be applied to other NLP tasks.

</details>


### [120] [MLLM-CBench:A Comprehensive Benchmark for Continual Instruction Tuning of Multimodal LLMs with Chain-of-Thought Reasoning Analysis](https://arxiv.org/abs/2508.08275)
*Haiyun Guo,ZhiYan Hou,Yu Chen,Jinghan He,Yandu Sun,Yuzhe Zhou,Shujing Guo,Kuan Zhu,Jinqiao Wang*

Main category: cs.CL

TL;DR: MLLM-CTBench是一个针对多模态大语言模型（MLLMs）持续指令调优的综合评估基准，旨在解决现有基准的不足，并提供算法设计和评估的实践指导。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）需要持续指令调优以适应不断变化的实际应用需求，但该领域缺乏严格和系统的基准，阻碍了进展。

Method: 本文提出了MLLM-CTBench，包含三个关键贡献：1) 多维度评估，结合最终答案准确性与由专门训练的CoT评估器实现的CoT推理质量评估；2) 全面评估算法和训练范式，对八种持续学习算法进行了基准测试，并系统比较了强化学习和监督微调范式；3) 精心策划的任务，从现有工作中选择了16个数据集，涵盖六个具有挑战性的领域。

Result: 主要发现包括：1) 具有更强通用能力的模型在持续学习中表现出更大的遗忘鲁棒性；2) 推理链比最终答案退化得更慢，支持分层遗忘假说；3) 持续学习算法的有效性高度依赖于模型能力和任务顺序；4) 在强化学习设置中，引入KL散度约束有助于保持策略稳定性，并在缓解遗忘方面发挥关键作用。

Conclusion: MLLM-CTBench为MLLMs的持续指令调优建立了严格的标准，并为算法设计和评估提供了实践指导。

Abstract: Multimodal Large Language Models (MLLMs) rely on continual instruction tuning
to adapt to the evolving demands of real-world applications. However, progress
in this area is hindered by the lack of rigorous and systematic benchmarks. To
address this gap, we present MLLM-CTBench, a comprehensive evaluation benchmark
with three key contributions: (1) Multidimensional Evaluation: We combine final
answer accuracy with fine-grained CoT reasoning quality assessment, enabled by
a specially trained CoT evaluator; (2) Comprehensive Evaluation of Algorithms
and Training Paradigms: We benchmark eight continual learning algorithms across
four major categories and systematically compare reinforcement learning with
supervised fine-tuning paradigms; (3) Carefully Curated Tasks: We select and
organize 16 datasets from existing work, covering six challenging domains. Our
key findings include: (i) Models with stronger general capabilities exhibit
greater robustness to forgetting during continual learning; (ii) Reasoning
chains degrade more slowly than final answers, supporting the hierarchical
forgetting hypothesis; (iii) The effectiveness of continual learning algorithms
is highly dependent on both model capability and task order; (iv) In
reinforcement learning settings, incorporating KL-divergence constraints helps
maintain policy stability and plays a crucial role in mitigating forgetting.
MLLM-CTBench establishes a rigorous standard for continual instruction tuning
of MLLMs and offers practical guidance for algorithm design and evaluation.

</details>


### [121] [Evaluating Contrast Localizer for Identifying Causal Unitsin Social & Mathematical Tasks in Language Models](https://arxiv.org/abs/2508.08276)
*Yassine Jamaa,Badr AlKhamissi,Satrajit Ghosh,Martin Schrimpf*

Main category: cs.CL

TL;DR: 本研究利用神经科学的对比定位器在大型语言模型中寻找特定任务（如心理理论和数学推理）的因果相关单元，但发现对比定位器识别出的高激活单元并非总是因果相关性最强的，甚至低激活单元或跨任务定位的单元可能导致更大的性能下降。


<details>
  <summary>Details</summary>
Motivation: 研究旨在确定大型语言模型（LLMs）和视觉语言模型（VLMs）中与心理理论（ToM）和数学推理任务因果相关的特定神经单元。

Method: 研究采用神经科学对比定位器，通过对比刺激集识别LLMs和VLMs（11个LLMs，5个VLMs，参数范围3B至90B）中的高激活单元。随后，通过定向消融评估这些单元的因果作用，并将功能性选择单元、低激活单元和随机选择单元的损伤效果在ToM和数学基准测试上进行比较。

Result: 研究发现与预期相反：有时低激活单元导致的性能下降比高激活单元更大；数学定位器识别出的单元对ToM性能的损害往往比ToM定位器识别出的单元更大。

Conclusion: 这些发现对基于对比的定位器在识别因果相关单元方面的有效性提出了质疑，并强调需要更广泛的刺激集和更精确的方法来捕获任务特异性单元。

Abstract: This work adapts a neuroscientific contrast localizer to pinpoint causally
relevant units for Theory of Mind (ToM) and mathematical reasoning tasks in
large language models (LLMs) and vision-language models (VLMs). Across 11 LLMs
and 5 VLMs ranging in size from 3B to 90B parameters, we localize top-activated
units using contrastive stimulus sets and assess their causal role via targeted
ablations. We compare the effect of lesioning functionally selected units
against low-activation and randomly selected units on downstream accuracy
across established ToM and mathematical benchmarks. Contrary to expectations,
low-activation units sometimes produced larger performance drops than the
highly activated ones, and units derived from the mathematical localizer often
impaired ToM performance more than those from the ToM localizer. These findings
call into question the causal relevance of contrast-based localizers and
highlight the need for broader stimulus sets and more accurately capture
task-specific units.

</details>


### [122] [Objective Metrics for Evaluating Large Language Models Using External Data Sources](https://arxiv.org/abs/2508.08277)
*Haoze Du,Richard Li,Edward Gehringer*

Main category: cs.CL

TL;DR: 本文提出一个框架，利用跨学期课堂文本材料中的主观指标来评估大型语言模型（LLM）的性能，旨在实现客观、可扩展和自动化评估。


<details>
  <summary>Details</summary>
Motivation: 评估LLM的性能至关重要但充满挑战，尤其是在避免主观评估方面。

Method: 该方法提出了一个框架，利用从不同学期的课堂文本材料中提取的主观指标来评估LLM在各种任务上的输出。通过使用明确的基准、事实数据集和结构化评估流程，该框架强调评分的自动化和透明度。

Result: 该方法确保了评估结果的一致性、可复现性和最小化偏差，减少了对人工解释的依赖，并与实际应用保持一致。

Conclusion: 该方法解决了主观评估方法的局限性，为教育、科学和其他高风险领域的性能评估提供了一个可扩展的解决方案。

Abstract: Evaluating the performance of Large Language Models (LLMs) is a critical yet
challenging task, particularly when aiming to avoid subjective assessments.
This paper proposes a framework for leveraging subjective metrics derived from
the class textual materials across different semesters to assess LLM outputs
across various tasks. By utilizing well-defined benchmarks, factual datasets,
and structured evaluation pipelines, the approach ensures consistent,
reproducible, and bias-minimized measurements. The framework emphasizes
automation and transparency in scoring, reducing reliance on human
interpretation while ensuring alignment with real-world applications. This
method addresses the limitations of subjective evaluation methods, providing a
scalable solution for performance assessment in educational, scientific, and
other high-stakes domains.

</details>


### [123] [MinionsLLM: a Task-adaptive Framework For The Training and Control of Multi-Agent Systems Through Natural Language](https://arxiv.org/abs/2508.08283)
*Andres Garcia Rincon,Eliseo Ferrante*

Main category: cs.CL

TL;DR: MinionsLLM是一个新颖的框架，结合LLM、行为树和形式文法，实现多智能体系统的自然语言控制。通过两种合成数据集生成方法微调LLM，显著提升了句法有效性和任务性能，尤其对小型模型效果显著。


<details>
  <summary>Details</summary>
Motivation: 实现多智能体系统在任意用户定义环境中的自然语言控制具有挑战性，需要整合LLM的能力与结构化行为表示，并提高LLM生成控制指令的准确性和相关性。

Method: 本文提出了MinionsLLM框架，将大型语言模型（LLM）与行为树（BTs）和形式文法相结合。该框架提供标准化接口用于定义环境、智能体和行为原语。为微调LLM以提高句法有效性和语义任务相关性，引入了两种合成数据集生成方法（方法A和方法B）。研究使用Google Gemma 3模型家族（1B、4B、12B）进行验证。

Result: 通过方法B微调，LLM的句法有效性提高到92.6%，平均任务性能比基线提升了33%。实验还表明，较小的模型（如1B）从微调中获益最大。

Conclusion: MinionsLLM框架通过整合LLM、行为树和形式文法，并利用合成数据微调，显著提升了多智能体系统自然语言控制的性能。研究结果表明，在资源受限的多智能体控制场景中，部署紧凑、本地托管的LLM具有巨大潜力。

Abstract: This paper presents MinionsLLM, a novel framework that integrates Large
Language Models (LLMs) with Behavior Trees (BTs) and Formal Grammars to enable
natural language control of multi-agent systems within arbitrary, user-defined
environments. MinionsLLM provides standardized interfaces for defining
environments, agents, and behavioral primitives, and introduces two synthetic
dataset generation methods (Method A and Method B) to fine-tune LLMs for
improved syntactic validity and semantic task relevance. We validate our
approach using Google's Gemma 3 model family at three parameter scales (1B, 4B,
and 12B) and demonstrate substantial gains: Method B increases syntactic
validity to 92.6% and achieves a mean task performance improvement of 33% over
baseline. Notably, our experiments show that smaller models benefit most from
fine-tuning, suggesting promising directions for deploying compact, locally
hosted LLMs in resource-constrained multi-agent control scenarios. The
framework and all resources are released open-source to support reproducibility
and future research.

</details>


### [124] [The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs](https://arxiv.org/abs/2508.08285)
*Denis Janiak,Jakub Binkowski,Albert Sawczyn,Bogdan Gabrys,Ravid Schwartz-Ziv,Tomasz Kajdanowicz*

Main category: cs.CL

TL;DR: 当前LLM幻觉检测方法的评估指标（如ROUGE）与人类判断不符，导致性能估计误导。本研究通过人类研究发现ROUGE精度极低，并揭示现有检测方法在人类对齐指标下性能显著下降，甚至不如简单启发式方法。因此，需要采用语义感知且稳健的评估框架。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的幻觉问题严重阻碍了其可靠部署。尽管存在多种幻觉检测方法，但它们的评估常依赖于ROUGE等词汇重叠度指标，这些指标与人类判断不一致，可能导致对检测方法真实性能的误判。

Method: 本研究通过全面的“人类研究”（human studies）来评估幻觉检测方法的性能。研究将ROUGE指标与“LLM-as-Judge”等与人类判断更对齐的语义感知指标进行对比，并分析了基于响应长度的简单启发式方法与复杂检测技术的表现。

Result: 研究发现ROUGE指标虽然召回率高，但精度极低，导致对幻觉检测方法性能的评估具有误导性。当使用LLM-as-Judge等与人类判断对齐的指标进行评估时，多个已建立的检测方法性能下降高达45.9%。此外，分析显示基于响应长度的简单启发式方法甚至可以与复杂的检测技术相媲美，揭示了当前评估实践中存在的根本缺陷。

Conclusion: 为了准确衡量幻觉检测方法的真实性能并最终确保LLM输出的可靠性，采用语义感知且稳健的评估框架至关重要。当前基于词汇重叠的评估方法存在严重缺陷，需要被更符合人类判断的新方法取代。

Abstract: Large language models (LLMs) have revolutionized natural language processing,
yet their tendency to hallucinate poses serious challenges for reliable
deployment. Despite numerous hallucination detection methods, their evaluations
often rely on ROUGE, a metric based on lexical overlap that misaligns with
human judgments. Through comprehensive human studies, we demonstrate that while
ROUGE exhibits high recall, its extremely low precision leads to misleading
performance estimates. In fact, several established detection methods show
performance drops of up to 45.9\% when assessed using human-aligned metrics
like LLM-as-Judge. Moreover, our analysis reveals that simple heuristics based
on response length can rival complex detection techniques, exposing a
fundamental flaw in current evaluation practices. We argue that adopting
semantically aware and robust evaluation frameworks is essential to accurately
gauge the true performance of hallucination detection methods, ultimately
ensuring the trustworthiness of LLM outputs.

</details>


### [125] [Sacred or Synthetic? Evaluating LLM Reliability and Abstention for Religious Questions](https://arxiv.org/abs/2508.08287)
*Farah Atif,Nursultan Askarbekuly,Kareem Darwish,Monojit Choudhury*

Main category: cs.CL

TL;DR: 本文引入了FiqhQA基准，首次评估了大型语言模型（LLMs）在细粒度伊斯兰教法裁决生成方面的准确性和弃权行为，发现模型在不同语言和学派间表现差异显著，并强调了在宗教应用中谨慎部署LLMs的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在各种领域中广泛应用，但其在宗教领域（如伊斯兰教法裁决）的可靠性和准确性尚未得到充分检验。现有工作往往忽略不同宗教思想流派间的区别，或未能评估模型何时应拒绝回答的能力。

Method: 引入了FiqhQA基准，该基准包含按四大逊尼派思想流派明确分类的伊斯兰裁决，并提供阿拉伯语和英语版本。研究不仅评估了LLMs的准确性，还评估了其识别何时不应回答（弃权行为）的能力。实验采用了零样本（zero-shot）和弃权（abstention）设置。

Result: 实验结果显示，LLMs在不同模型、语言和法律学派之间的表现存在显著差异。GPT-4o在准确性方面优于所有其他模型，而Gemini和Fanar在弃权行为上表现更佳，这对于最大程度地减少自信的错误回答至关重要。值得注意的是，所有模型在阿拉伯语中的性能均有所下降，这突显了LLMs在英语以外语言的宗教推理方面的局限性。

Conclusion: 研究结果强调了在宗教应用中需要进行特定任务评估和谨慎部署LLMs的重要性，以确保其可靠性和适用性。

Abstract: Despite the increasing usage of Large Language Models (LLMs) in answering
questions in a variety of domains, their reliability and accuracy remain
unexamined for a plethora of domains including the religious domains. In this
paper, we introduce a novel benchmark FiqhQA focused on the LLM generated
Islamic rulings explicitly categorized by the four major Sunni schools of
thought, in both Arabic and English. Unlike prior work, which either overlooks
the distinctions between religious school of thought or fails to evaluate
abstention behavior, we assess LLMs not only on their accuracy but also on
their ability to recognize when not to answer. Our zero-shot and abstention
experiments reveal significant variation across LLMs, languages, and legal
schools of thought. While GPT-4o outperforms all other models in accuracy,
Gemini and Fanar demonstrate superior abstention behavior critical for
minimizing confident incorrect answers. Notably, all models exhibit a
performance drop in Arabic, highlighting the limitations in religious reasoning
for languages other than English. To the best of our knowledge, this is the
first study to benchmark the efficacy of LLMs for fine-grained Islamic school
of thought specific ruling generation and to evaluate abstention for Islamic
jurisprudence queries. Our findings underscore the need for task-specific
evaluation and cautious deployment of LLMs in religious applications.

</details>


### [126] [Putnam-AXIOM: A Functional and Static Benchmark](https://arxiv.org/abs/2508.08292)
*Aryan Gulati,Brando Miranda,Eric Chen,Emily Xia,Kai Fronsdal,Bruno Dumont,Elyas Obbad,Sanmi Koyejo*

Main category: cs.CL

TL;DR: 本文引入了Putnam-AXIOM，一个针对大型语言模型（LLMs）的大学级别数学推理基准，以解决现有基准饱和和数据污染问题。研究发现LLMs存在记忆化现象，并强调了动态基准的必要性。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM数学推理基准已接近饱和（准确率超过90%），并且日益受到训练集污染的影响，这使得评估LLMs的真实推理能力变得困难。

Method: 研究引入了Putnam-AXIOM基准，包含522个普特南数学竞赛问题，以及Putnam-AXIOM Variation，一个由程序化扰动变量和常数生成的100个变体问题集。为了评估推理过程，还引入了“教师强制准确率”（Teacher-Forced Accuracy, TFA）指标。实验测试了包括OpenAI的o1-preview在内的19个模型。

Result: 在原始问题集上，最强的模型o1-preview得分41.9%，但在配对的变体问题集上，其准确率下降了19.6%（相对下降46.8%）。其余18个模型也表现出类似的下降趋势，其中10个模型的95%置信区间不重叠，这表明模型存在记忆化现象。

Conclusion: LLMs在数学推理任务中存在记忆化行为，现有静态基准不足以准确评估其泛化能力。动态基准对于评估LLMs的真实推理能力至关重要。Putnam-AXIOM提供了一个严格且抗污染的评估框架，用于评估LLMs的高级数学推理能力。

Abstract: Current mathematical reasoning benchmarks for large language models (LLMs)
are approaching saturation, with some achieving > 90% accuracy, and are
increasingly compromised by training-set contamination. We introduce
Putnam-AXIOM, a benchmark of 522 university-level competition problems drawn
from the prestigious William Lowell Putnam Mathematical Competition, and
Putnam-AXIOM Variation, an unseen companion set of 100 functional variants
generated by programmatically perturbing variables and constants. The variation
protocol produces an unlimited stream of equally difficult, unseen instances --
yielding a contamination-resilient test bed. On the Original set, OpenAI's
o1-preview -- the strongest evaluated model -- scores 41.9%, but its accuracy
drops by 19.6% (46.8% relative decrease) on the paired Variations. The
remaining eighteen models show the same downward trend, ten of them with
non-overlapping 95% confidence intervals. These gaps suggest memorization and
highlight the necessity of dynamic benchmarks. We complement "boxed" accuracy
with Teacher-Forced Accuracy (TFA), a lightweight metric that directly scores
reasoning traces and automates natural language proof evaluations. Putnam-AXIOM
therefore provides a rigorous, contamination-resilient evaluation framework for
assessing advanced mathematical reasoning of LLMs. Data and evaluation code are
publicly available at https://github.com/brando90/putnam-axiom.

</details>


### [127] [CoDAE: Adapting Large Language Models for Education via Chain-of-Thought Data Augmentation](https://arxiv.org/abs/2508.08386)
*Shuzhou Yuan,William LaCroix,Hardik Ghoshal,Ercong Nie,Michael Färber*

Main category: cs.CL

TL;DR: CoDAE框架通过思维链数据增强，提升大型语言模型在教育场景中的辅导能力，使其提供更具教学性、适应性并抵抗不良诱导的指导。


<details>
  <summary>Details</summary>
Motivation: 现成的大型语言模型作为AI导师存在不足，包括过早泄露答案、响应适应性差以及易受情感操控提示影响。

Method: 引入CoDAE框架，通过思维链（CoT）数据增强来适应教育用途。收集真实师生对话，利用CoT提示丰富数据，以促进逐步推理和符合教学的指导。设计针对性对话案例，以缓解过度顺从、低响应适应性和威胁脆弱性。在增强数据集的不同变体上微调四种开源LLM，并使用自动指标和LLM作为评判者进行评估。

Result: 通过CoDAE微调的模型能提供更符合教学的指导，更好地支持推理过程，并有效抵抗过早答案泄露。

Conclusion: CoDAE框架通过数据增强和针对性案例设计，成功地将大型语言模型适应于教育环境，显著提高了其作为AI导师的性能和鲁棒性。

Abstract: Large Language Models (LLMs) are increasingly employed as AI tutors due to
their scalability and potential for personalized instruction. However,
off-the-shelf LLMs often underperform in educational settings: they frequently
reveal answers too readily, fail to adapt their responses to student
uncertainty, and remain vulnerable to emotionally manipulative prompts. To
address these challenges, we introduce CoDAE, a framework that adapts LLMs for
educational use through Chain-of-Thought (CoT) data augmentation. We collect
real-world dialogues between students and a ChatGPT-based tutor and enrich them
using CoT prompting to promote step-by-step reasoning and pedagogically aligned
guidance. Furthermore, we design targeted dialogue cases to explicitly mitigate
three key limitations: over-compliance, low response adaptivity, and threat
vulnerability. We fine-tune four open-source LLMs on different variants of the
augmented datasets and evaluate them in simulated educational scenarios using
both automatic metrics and LLM-as-a-judge assessments. Our results show that
models fine-tuned with CoDAE deliver more pedagogically appropriate guidance,
better support reasoning processes, and effectively resist premature answer
disclosure.

</details>


### [128] [Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery](https://arxiv.org/abs/2508.08401)
*Jiatong Li,Weida Wang,Qinggang Zhang,Junxian Li,Di Zhang,Changmeng Zheng,Shufei Zhang,Xiaoyong Wei,Qing Li*

Main category: cs.CL

TL;DR: Mol-R1是一个新框架，通过高质量数据集（PRID）和迭代训练策略（MoIA）提升了类R1长链思维LLM在文本分子生成中的可解释性和推理性能，优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs），特别是长链思维（CoT）推理模型，在常识和数学推理方面表现出色，但它们在分子发现等知识密集型领域效率低下且能力有限，因为这需要精确理解复杂的分子数据和稀缺的高质量专家标注。

Method: 本文提出了Mol-R1框架。首先，通过“上下文蒸馏先验调节”（PRID）策略构建高质量推理数据集。其次，引入“分子迭代适应”（MoIA）训练策略，该策略迭代结合监督微调（SFT）和强化策略优化（RPO），以提升类R1模型在分子发现中的推理性能。

Result: Mol-R1在文本分子推理生成任务中表现出卓越的性能，优于现有基线。

Conclusion: Mol-R1框架通过结合创新的数据蒸馏和迭代训练策略，成功弥补了现有LLM在分子发现领域可解释性和推理能力方面的不足，显著提升了该领域模型的性能。

Abstract: Large language models (LLMs), especially Explicit Long Chain-of-Thought (CoT)
reasoning models like DeepSeek-R1 and QWQ, have demonstrated powerful reasoning
capabilities, achieving impressive performance in commonsense reasoning and
mathematical inference. Despite their effectiveness, Long-CoT reasoning models
are often criticized for their limited ability and low efficiency in
knowledge-intensive domains such as molecule discovery. Success in this field
requires a precise understanding of domain knowledge, including molecular
structures and chemical principles, which is challenging due to the inherent
complexity of molecular data and the scarcity of high-quality expert
annotations. To bridge this gap, we introduce Mol-R1, a novel framework
designed to improve explainability and reasoning performance of R1-like
Explicit Long-CoT reasoning LLMs in text-based molecule generation. Our
approach begins with a high-quality reasoning dataset curated through Prior
Regulation via In-context Distillation (PRID), a dedicated distillation
strategy to effectively generate paired reasoning traces guided by prior
regulations. Building upon this, we introduce MoIA, Molecular Iterative
Adaptation, a sophisticated training strategy that iteratively combines
Supervised Fine-tuning (SFT) with Reinforced Policy Optimization (RPO),
tailored to boost the reasoning performance of R1-like reasoning models for
molecule discovery. Finally, we examine the performance of Mol-R1 in the
text-based molecule reasoning generation task, showing superior performance
against existing baselines.

</details>


### [129] [Rethinking Tokenization for Rich Morphology: The Dominance of Unigram over BPE and Morphological Alignment](https://arxiv.org/abs/2508.08424)
*Saketh Reddy Vemula,Dipti Mishra Sharma,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: 研究发现，在语言模型中，词法对齐与句法任务表现呈正相关（中等程度），但分词算法本身（如Unigram优于BPE）对下游任务性能的影响更大。混合分词器（BPE+词法）在BPE框架内能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 先前关于语言模型中词法对齐分词方法是否能提升性能，特别是对于形态复杂语言的结论存在矛盾，因此需要进行深入探究。

Method: 选择了三种类型学上多样化的语言（泰卢固语、印地语、英语）进行研究。对语言模型进行了从分词器训练到微调和下游任务评估的全面评估。创建了一个泰卢固语的词法切分金标数据集。重点分析了词法对齐和分词质量两个关键因素，并比较了BPE和Unigram等不同分词算法。

Result: 词法对齐与句法相关任务（如词性标注、命名实体识别、依存句法分析）的性能呈正相关，但相关性为中等。分词算法本身对下游性能的影响比单独的词法对齐更显著。朴素的Unigram分词器在大多数设置下表现优于其他分词器。在BPE框架内，结合词法切分的混合分词器能显著提升性能。然而，语料库词元计数（CTC）和Rényi熵等内在指标与下游性能无关联。

Conclusion: 词法对齐对语言模型性能有益，尤其是在句法相关任务上，但分词算法的选择（如Unigram的优越性）和分词质量更为关键。在BPE框架下引入词法信息可有效提升性能。

Abstract: Prior work on language modeling showed conflicting findings about whether
morphologically aligned approaches to tokenization improve performance,
particularly for languages with complex morphology. To investigate this, we
select a typologically diverse set of languages: Telugu (agglutinative), Hindi
(primarily fusional with some agglutination), and English (fusional). We
conduct a comprehensive evaluation of language models -- starting from
tokenizer training and extending through the finetuning and downstream task
evaluation. To account for the consistent performance differences observed
across tokenizer variants, we focus on two key factors: morphological alignment
and tokenization quality. To assess morphological alignment of tokenizers in
Telugu, we create a dataset containing gold morpheme segmentations of 600
derivational and 7000 inflectional word forms.
  Our experiments reveal that better morphological alignment correlates
positively -- though moderately -- with performance in syntax-based tasks such
as Parts-of-Speech tagging, Named Entity Recognition and Dependency Parsing.
However, we also find that the tokenizer algorithm (Byte-pair Encoding vs.
Unigram) plays a more significant role in influencing downstream performance
than morphological alignment alone. Naive Unigram tokenizers outperform others
across most settings, though hybrid tokenizers that incorporate morphological
segmentation significantly improve performance within the BPE framework. In
contrast, intrinsic metrics like Corpus Token Count (CTC) and R\'enyi entropy
showed no correlation with downstream performance.

</details>


### [130] [Enhancing Small LLM Alignment through Margin-Based Objective Modifications under Resource Constraints](https://arxiv.org/abs/2508.08466)
*Daren Yao,Jinsong Yuan,Ruike Chen*

Main category: cs.CL

TL;DR: 本文提出了两种基于DPO的轻量级变体——自适应裕度S型损失（Adaptive Margin-Sigmoid Loss）和APO-hinge-zero，旨在解决小型大型语言模型（LLMs）在性能差距较大时难以与人类偏好对齐的问题，并通过引入基于裕度的目标和选择性更新机制显著提升了对齐效果。


<details>
  <summary>Details</summary>
Motivation: 小型大型语言模型（LLMs）在与人类偏好对齐方面常面临困难，尤其是在存在严重性能差距的情况下，这限制了它们在资源受限环境下的实际部署。

Method: 本文提出了两种轻量级、基于DPO的变体：自适应裕度S型损失（Adaptive Margin-Sigmoid Loss）和APO-hinge-zero。APO-hinge-zero方法结合了铰链（hinge）诱导的难例挖掘与APO-zero的偏好选择优化机制，通过引入基于裕度的目标和选择性更新机制来解决性能不足的情况。

Result: 在AlpacaEval测试中，APO-hinge-zero方法相比APO-zero基线，胜率提高了2.0个百分点，长度控制胜率提高了1.4个百分点。在MT-Bench测试中，所提出的方法在各类任务中保持了有竞争力的性能，尤其在STEM和人文学科任务中表现出色。

Conclusion: 研究结果表明，对基于偏好的目标函数进行简单修改，可以显著提升资源受限下小型LLM的对齐能力，为更高效的部署提供了实用的途径。

Abstract: Small large language models (LLMs) often face difficulties in aligning output
to human preferences, particularly when operating under severe performance
gaps. In this work, we propose two lightweight DPO-based variants -- Adaptive
Margin-Sigmoid Loss and APO-hinge-zero -- to better address underperformance
scenarios by introducing margin-based objectives and selective update
mechanisms.
  Our APO-hinge-zero method, which combines hinge-induced hard-example mining
with the chosen-focused optimization of APO-zero, achieves strong results. In
AlpacaEval, APO-hinge-zero improves the win rate by +2.0 points and the
length-controlled win rate by +1.4 points compared to the APO-zero baseline. In
MT-Bench, our methods maintain competitive performance in diverse categories,
particularly excelling in STEM and Humanities tasks.
  These results demonstrate that simple modifications to preference-based
objectives can significantly enhance small LLM alignment under resource
constraints, offering a practical path toward more efficient deployment.

</details>


### [131] [Momentum Point-Perplexity Mechanics in Large Language Models](https://arxiv.org/abs/2508.08492)
*Lorenzo Tomaz,Judd Rosenblatt,Thomas Berry Jones,Diogo Schwerz de Lucena*

Main category: cs.CL

TL;DR: 研究发现大型语言模型推理时，其内部隐藏状态的变化率与模型下一词确定性相结合的“能量”量保持近似恒定。基于此，提出了一种名为Jacobian转向的控制方法，可在保持能量不变的情况下，提高生成文本的语义质量。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型在推理过程中内部隐藏状态如何变化，以提高模型的可预测性，实现与人类意图的对齐，并为模型的可解释性、异常检测和低风险控制提供原理基础。

Method: 采用基于物理学的方法，分析了20个开源Transformer模型的隐藏状态变化。定义了一个结合隐藏状态变化率和模型下一词确定性的“能量”量。基于这种“对数拉格朗日”视角，推导出了一个名为Jacobian转向的控制方法，该方法通过最小扰动隐藏状态来偏好目标词。

Result: 发现一个结合隐藏状态变化率和模型下一词确定性的“能量”量在模型推理时几乎保持恒定。随机权重模型比预训练模型更严格地保持这种“能量”。训练使模型进入一个更快、更果断、变异性更大的状态。Jacobian转向方法在测试模型中保持了近似恒定的能量，并生成了比模型自然输出语义质量更高的续写。

Conclusion: 通过力学视角审视Transformer模型，为模型的可解释性、异常检测和低风险控制提供了一个有原则的基础。这有助于使强大的模型更可预测，并更好地与人类意图对齐。

Abstract: We take a physics-based approach to studying how the internal hidden states
of large language models change from token to token during inference. Across 20
open-source transformer models (135M-3B parameters), we find that a quantity
combining the rate of change in hidden states and the model's next-token
certainty, analogous to energy in physics, remains nearly constant.
Random-weight models conserve this "energy" more tightly than pre-trained ones,
while training shifts models into a faster, more decisive regime with greater
variability. Using this "log-Lagrangian" view, we derive a control method
called Jacobian steering, which perturbs hidden states in the minimal way
needed to favor a target token. This approach maintained near-constant energy
in two tested models and produced continuations rated higher in semantic
quality than the models' natural outputs. Viewing transformers through this
mechanics lens offers a principled basis for interpretability, anomaly
detection, and low-risk steering. This could help make powerful models more
predictable and aligned with human intent.

</details>


### [132] [Steerable Pluralism: Pluralistic Alignment via Few-Shot Comparative Regression](https://arxiv.org/abs/2508.08509)
*Jadie Adams,Brian Hu,Emily Veenhuis,David Joy,Bharadwaj Ravichandran,Aaron Bray,Anthony Hoogs,Arslan Basharat*

Main category: cs.CL

TL;DR: 本文提出一种基于少样本比较回归的可控多元对齐模型，旨在通过细粒度属性捕捉并适应用户多样化偏好，超越传统LLM对齐方法的局限性，并在新基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）的对齐技术（如RLHF）使用标量奖励，只能平均反映用户偏好，无法捕捉多样化的用户偏好和更广泛的属性，因此需要一种能反映多元偏好的对齐方法。

Method: 提出一种可控的多元对齐模型，核心是基于少样本比较回归（few-shot comparative regression）。该方法利用上下文学习和推理，以一组细粒度属性为基础，比较响应选项并做出对齐选择。同时，构建了两个新的可控多元基准（改编自Moral Integrity Corpus和HelpSteer2数据集）来评估算法。

Result: 所提出的少样本比较回归方法具有可解释性，与不同属性和LLM兼容，并且性能优于多种基线和现有先进方法。它适用于价值对齐的决策和奖励建模。

Conclusion: 这项工作为多元对齐提供了新的见解和研究方向，有助于实现更公平和更具代表性的LLM使用，并推动伦理AI领域的发展。

Abstract: Large language models (LLMs) are currently aligned using techniques such as
reinforcement learning from human feedback (RLHF). However, these methods use
scalar rewards that can only reflect user preferences on average. Pluralistic
alignment instead seeks to capture diverse user preferences across a set of
attributes, moving beyond just helpfulness and harmlessness. Toward this end,
we propose a steerable pluralistic model based on few-shot comparative
regression that can adapt to individual user preferences. Our approach
leverages in-context learning and reasoning, grounded in a set of fine-grained
attributes, to compare response options and make aligned choices. To evaluate
our algorithm, we also propose two new steerable pluralistic benchmarks by
adapting the Moral Integrity Corpus (MIC) and the HelpSteer2 datasets,
demonstrating the applicability of our approach to value-aligned
decision-making and reward modeling, respectively. Our few-shot comparative
regression approach is interpretable and compatible with different attributes
and LLMs, while outperforming multiple baseline and state-of-the-art methods.
Our work provides new insights and research directions in pluralistic
alignment, enabling a more fair and representative use of LLMs and advancing
the state-of-the-art in ethical AI.

</details>


### [133] [DeCAL Tokenwise Compression](https://arxiv.org/abs/2508.08514)
*Sameer Panwar*

Main category: cs.CL

TL;DR: DeCAL是一种新的逐token压缩方法，利用经过去噪预训练的编解码语言模型，通过编码器学习生成高质量、通用的压缩表示。


<details>
  <summary>Details</summary>
Motivation: 旨在生成高质量、通用目的的压缩表示，以在下游任务中（特别是需要预计算密集表示的场景）实现显著的资源节省。

Method: DeCAL采用一个经过去噪预训练的编解码语言模型，其编码器负责生成压缩表示。该方法对编码器进行了少量修改，重点在于最大化压缩质量。

Result: 在2倍压缩比下，DeCAL在许多下游任务上能与未压缩数据表现相当；在问答、摘要和多向量检索任务中，即使达到8倍压缩比，性能下降也通常很小。该方法在可利用预计算密集表示的场景中能显著节省资源。

Conclusion: DeCAL是一种有效的压缩方法，未来有望得到更广泛的应用。

Abstract: This paper introduces DeCAL, a new method for tokenwise compression. DeCAL
uses an encoder-decoder language model pretrained with denoising to learn to
produce high-quality, general-purpose compressed representations by the
encoder. DeCAL applies small modifications to the encoder, with the emphasis on
maximizing compression quality, even at the expense of compute. We show that
DeCAL at 2x compression can match uncompressed on many downstream tasks, with
usually only minor dropoff in metrics up to 8x compression, among
question-answering, summarization, and multi-vector retrieval tasks. DeCAL
offers significant savings where pre-computed dense representations can be
utilized, and we believe the approach can be further developed to be more
broadly applicable.

</details>


### [134] [DepressLLM: Interpretable domain-adapted language model for depression detection from real-world narratives](https://arxiv.org/abs/2508.08591)
*Sehwan Moon,Aram Lee,Jeong Eun Kim,Hee-Ju Kang,Il-Seon Shin,Sung-Wan Kim,Jae-Min Kim,Min Jhon,Ju-Wan Kim*

Main category: cs.CL

TL;DR: 本研究推出了DepressLLM，一个基于大规模自传叙事文本训练的大语言模型，用于可解释的抑郁症预测，并通过SToPS模块提升了分类性能和置信度估计。


<details>
  <summary>Details</summary>
Motivation: 抑郁症预测受限于缺乏大规模、高质量且严格标注的数据集，这阻碍了大语言模型（LLMs）在此领域的应用。

Method: 研究构建了一个包含3,699个反映幸福和痛苦的自传叙事文本的新语料库，并在此基础上训练和评估了DepressLLM。DepressLLM包含一个Score-guided Token Probability Summation (SToPS) 模块，用于提供可解释的预测和可靠的置信度估计。模型在内部数据集（包括生态瞬时评估数据）和公共临床访谈数据上进行了鲁棒性验证，并对高置信度误分类进行了精神病学审查。

Result: DepressLLM在抑郁症预测上取得了0.789的AUC，在置信度高于0.95的样本上AUC提高到0.904。模型对异构数据表现出鲁棒性。对高置信度误分类的精神病学审查揭示了模型和数据局限性，为未来改进提供了方向。

Conclusion: 研究结果表明，可解释的人工智能能够实现抑郁症的早期诊断，并突显了医疗AI在精神病学领域的应用前景。

Abstract: Advances in large language models (LLMs) have enabled a wide range of
applications. However, depression prediction is hindered by the lack of
large-scale, high-quality, and rigorously annotated datasets. This study
introduces DepressLLM, trained and evaluated on a novel corpus of 3,699
autobiographical narratives reflecting both happiness and distress. DepressLLM
provides interpretable depression predictions and, via its Score-guided Token
Probability Summation (SToPS) module, delivers both improved classification
performance and reliable confidence estimates, achieving an AUC of 0.789, which
rises to 0.904 on samples with confidence $\geq$ 0.95. To validate its
robustness to heterogeneous data, we evaluated DepressLLM on in-house datasets,
including an Ecological Momentary Assessment (EMA) corpus of daily stress and
mood recordings, and on public clinical interview data. Finally, a psychiatric
review of high-confidence misclassifications highlighted key model and data
limitations that suggest directions for future refinements. These findings
demonstrate that interpretable AI can enable earlier diagnosis of depression
and underscore the promise of medical AI in psychiatry.

</details>


### [135] [Optimizing Retrieval-Augmented Generation (RAG) for Colloquial Cantonese: A LoRA-Based Systematic Review](https://arxiv.org/abs/2508.08610)
*David Santandreu Calonge,Linda Smail*

Main category: cs.CL

TL;DR: 该综述分析了参数高效微调（PEFT），特别是LoRA，在优化RAG系统处理粤语口语表达方面的最新进展，以解决数据稀缺和语言变异性问题。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统（如Qwen3、DeepSeek、Kimi）在理解和生成地道粤语口语表达方面面临挑战，原因在于标注数据有限和语言变异性高。

Method: 本综述通过系统分析，评估了LoRA在RAG框架中的集成、PEFT方法在检索和生成准确性上的基准表现、有限数据下的领域适应策略以及数据稀缺条件下的语义保真度微调技术。研究考察了LoRA变体、合成数据生成、用户反馈整合和自适应参数分配对计算效率、检索精度、语言真实性和可扩展性的影响。

Result: 研究发现，动态和集成LoRA适应方法显著减少了可训练参数，同时在方言环境中保持了检索准确性和生成质量。然而，在充分保留细粒度语言细微差别方面仍存在局限性，特别是在粤语等低资源设置中。实时用户反馈和领域特定数据整合仍不成熟，限制了模型的适应性和个性化。选择性参数冻结和非线性适应方法在效率和准确性之间提供了更好的权衡，但其大规模鲁棒性仍是一个开放挑战。

Conclusion: PEFT增强型RAG系统在特定领域语言任务中展现出潜力。未来的工作应侧重于方言真实性、动态适应和可扩展的微调流程。

Abstract: This review examines recent advances in Parameter-Efficient Fine-Tuning
(PEFT), with a focus on Low-Rank Adaptation (LoRA), to optimize
Retrieval-Augmented Generation (RAG) systems like Qwen3, DeepSeek, and Kimi.
These systems face challenges in understanding and generating authentic
Cantonese colloquial expressions due to limited annotated data and linguistic
variability. The review evaluates the integration of LoRA within RAG
frameworks, benchmarks PEFT methods for retrieval and generation accuracy,
identify domain adaptation strategies under limited data, and compares
fine-tuning techniques aimed at improving semantic fidelity under data-scarce
conditions. A systematic analysis of recent studies employing diverse LoRA
variants, synthetic data generation, user feedback integration, and adaptive
parameter allocation was conducted to assess their impact on computational
efficiency, retrieval precision, linguistic authenticity, and scalability.
Findings reveal that dynamic and ensemble LoRA adaptations significantly reduce
trainable parameters without sacrificing retrieval accuracy and generation
quality in dialectal contexts. However, limitations remain in fully preserving
fine-grained linguistic nuances, especially for low-resource settings like
Cantonese. The integration of real-time user feedback and domain-specific data
remains underdeveloped, limiting model adaptability and personalization. While
selective parameter freezing and nonlinear adaptation methods offer better
trade-offs between efficiency and accuracy, their robustness at scale remains
an open challenge. This review highlights the promise of PEFT-enhanced RAG
systems for domain-specific language tasks and calls for future work targeting
dialectal authenticity, dynamic adaptation, and scalable fine-tuning pipelines.

</details>


### [136] [InternBootcamp Technical Report: Boosting LLM Reasoning with Verifiable Task Scaling](https://arxiv.org/abs/2508.08636)
*Peiji Li,Jiasheng Ye,Yongkang Chen,Yichuan Ma,Zijie Yu,Kedi Chen,Ganqu Cui,Haozhan Li,Jiacheng Chen,Chengqi Lyu,Wenwei Zhang,Linyang Li,Qipeng Guo,Dahua Lin,Bowen Zhou,Kai Chen*

Main category: cs.CL

TL;DR: 该论文提出了InternBootcamp，一个包含1000多个领域多样化任务环境的开源框架，用于LLM推理研究。它支持自动化任务生成和结果验证，并通过任务扩展（task scaling）显著提升了模型在多样化推理任务上的性能，验证了其作为通用推理模型训练基础设施的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习（RL）在LLM推理方面的进展主要集中于特定领域（如数学或代码生成），但现实世界推理场景需要模型处理多样且复杂的环境，而狭窄领域的基准无法充分捕捉这些需求。因此，需要一个能涵盖广泛领域和复杂性的框架来弥补这一差距。

Method: 开发了InternBootcamp框架，包含1000多个领域多样化的任务环境，并提供两个核心功能：1) 自动化生成无限量、难度可配置的训练/测试案例；2) 集成验证模块用于客观响应评估。为了加速开发，采用了自动化代理工作流辅以人工验证协议。此外，基于此框架建立了自动生成的基准测试集Bootcamp-EVAL。

Result: 评估显示，现有前沿模型在许多推理任务上表现仍不佳。使用InternBootcamp进行训练能显著提高模型性能，作者的32B模型在Bootcamp-EVAL上取得了最先进的结果，并在其他现有基准测试中表现出色。特别验证了通过增加训练任务数量（即任务扩展）可以带来持续的性能提升，且规模超过两个数量级。

Conclusion: InternBootcamp是一个用于RL模型优化、合成数据生成和模型评估的基础设施。通过任务扩展（task scaling）可以有效提升LLM的推理能力，为开发具有强大推理能力的通用模型提供了有前景的途径。

Abstract: Large language models (LLMs) have revolutionized artificial intelligence by
enabling complex reasoning capabilities. While recent advancements in
reinforcement learning (RL) have primarily focused on domain-specific reasoning
tasks (e.g., mathematics or code generation), real-world reasoning scenarios
often require models to handle diverse and complex environments that
narrow-domain benchmarks cannot fully capture. To address this gap, we present
InternBootcamp, an open-source framework comprising 1000+ domain-diverse task
environments specifically designed for LLM reasoning research. Our codebase
offers two key functionalities: (1) automated generation of unlimited
training/testing cases with configurable difficulty levels, and (2) integrated
verification modules for objective response evaluation. These features make
InternBootcamp fundamental infrastructure for RL-based model optimization,
synthetic data generation, and model evaluation. Although manually developing
such a framework with enormous task coverage is extremely cumbersome, we
accelerate the development procedure through an automated agent workflow
supplemented by manual validation protocols, which enables the task scope to
expand rapidly. % With these bootcamps, we further establish Bootcamp-EVAL, an
automatically generated benchmark for comprehensive performance assessment.
Evaluation reveals that frontier models still underperform in many reasoning
tasks, while training with InternBootcamp provides an effective way to
significantly improve performance, leading to our 32B model that achieves
state-of-the-art results on Bootcamp-EVAL and excels on other established
benchmarks. In particular, we validate that consistent performance gains come
from including more training tasks, namely \textbf{task scaling}, over two
orders of magnitude, offering a promising route towards capable reasoning
generalist.

</details>


### [137] [Quick on the Uptake: Eliciting Implicit Intents from Human Demonstrations for Personalized Mobile-Use Agents](https://arxiv.org/abs/2508.08645)
*Zheng Wu,Heyuan Huang,Yanjia Yang,Yuanyi Song,Xingyu Lou,Weiwen Liu,Weinan Zhang,Jun Wang,Zhuosheng Zhang*

Main category: cs.CL

TL;DR: 该研究通过识别并利用人类的显式（操作步骤）和隐式（个人偏好）意图流，提出了一个名为IFRAgent的框架，旨在提高移动代理与人类意图的对齐度，从而实现更个性化的移动任务自动化。


<details>
  <summary>Details</summary>
Motivation: 现有的移动代理通过演示学习来提升，但它们仅关注人类的显式意图流（如步骤序列），忽略了隐式意图流（如个人偏好），这使得构建个性化移动代理变得困难。

Method: 首先，收集了MobileIAR数据集，其中包含与人类意图对齐的动作和真实动作，用于评估代理对人类意图的理解。然后，提出了IFRAgent框架，该框架通过分析人类演示中的显式意图流构建标准操作程序（SOP）的查询级向量库，并通过分析隐式意图流建立用户级习惯库。IFRAgent结合SOP提取器、检索增强生成和查询重写器，从原始模糊查询中生成个性化查询和SOP。

Result: 实验结果表明，IFRAgent在人类意图对齐率上平均优于基线6.79%（相对提升32.06%），在步骤完成率上平均提升5.30%（相对提升26.34%）。

Conclusion: IFRAgent通过识别和整合人类的显式和隐式意图流，显著提高了移动代理与人类意图的对齐程度和任务完成率，有效解决了现有方法在个性化方面的不足。

Abstract: As multimodal large language models advance rapidly, the automation of mobile
tasks has become increasingly feasible through the use of mobile-use agents
that mimic human interactions from graphical user interface. To further enhance
mobile-use agents, previous studies employ demonstration learning to improve
mobile-use agents from human demonstrations. However, these methods focus
solely on the explicit intention flows of humans (e.g., step sequences) while
neglecting implicit intention flows (e.g., personal preferences), which makes
it difficult to construct personalized mobile-use agents. In this work, to
evaluate the \textbf{I}ntention \textbf{A}lignment \textbf{R}ate between
mobile-use agents and humans, we first collect \textbf{MobileIAR}, a dataset
containing human-intent-aligned actions and ground-truth actions. This enables
a comprehensive assessment of the agents' understanding of human intent. Then
we propose \textbf{IFRAgent}, a framework built upon \textbf{I}ntention
\textbf{F}low \textbf{R}ecognition from human demonstrations. IFRAgent analyzes
explicit intention flows from human demonstrations to construct a query-level
vector library of standard operating procedures (SOP), and analyzes implicit
intention flows to build a user-level habit repository. IFRAgent then leverages
a SOP extractor combined with retrieval-augmented generation and a query
rewriter to generate personalized query and SOP from a raw ambiguous query,
enhancing the alignment between mobile-use agents and human intent.
Experimental results demonstrate that IFRAgent outperforms baselines by an
average of 6.79\% (32.06\% relative improvement) in human intention alignment
rate and improves step completion rates by an average of 5.30\% (26.34\%
relative improvement). The codes are available at
https://github.com/MadeAgents/Quick-on-the-Uptake.

</details>


### [138] [LLaMA-Based Models for Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2508.08649)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 研究发现，针对方面级情感分析（ABSA）微调的大型语言模型，特别是Orca 2，在所有任务中均超越了现有最佳水平，但在零样本和少样本场景中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在多项任务中表现出潜力，但在复合方面级情感分析（ABSA）任务中，其性能落后于经过微调的模型。然而，针对ABSA任务微调LLMs的潜力尚未被充分探索。

Method: 本文研究了针对ABSA微调的开源LLMs（侧重于LLaMA系列模型）的能力。通过在四个任务和八个英文数据集上评估其性能，并进行了错误分析以识别微调模型面临的挑战。

Result: 微调后的Orca 2模型在所有任务中均超越了现有最佳（SOTA）结果。然而，所有模型在零样本和少样本场景下的表现均不如完全微调的模型。

Conclusion: 针对ABSA任务微调大型语言模型（如Orca 2）能够显著提升性能，甚至超越现有最佳水平。尽管如此，在零样本和少样本设置下，这些模型的性能仍有待提高。

Abstract: While large language models (LLMs) show promise for various tasks, their
performance in compound aspect-based sentiment analysis (ABSA) tasks lags
behind fine-tuned models. However, the potential of LLMs fine-tuned for ABSA
remains unexplored. This paper examines the capabilities of open-source LLMs
fine-tuned for ABSA, focusing on LLaMA-based models. We evaluate the
performance across four tasks and eight English datasets, finding that the
fine-tuned Orca~2 model surpasses state-of-the-art results in all tasks.
However, all models struggle in zero-shot and few-shot scenarios compared to
fully fine-tuned ones. Additionally, we conduct error analysis to identify
challenges faced by fine-tuned models.

</details>


### [139] [UWB at WASSA-2024 Shared Task 2: Cross-lingual Emotion Detection](https://arxiv.org/abs/2508.08650)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 本文介绍了一个为WASSA-2024跨语言情感检测共享任务构建的系统，该系统通过微调量化大型语言模型和多语言Transformer模型，实现了情感标签和触发词的检测。


<details>
  <summary>Details</summary>
Motivation: 参与WASSA-2024跨语言情感检测共享任务，该任务包含两个子任务：从五种语言的推文中识别六种情感标签，以及预测触发这些情感的词语。

Method: 核心方法是使用LoRA微调量化大型语言模型（如Orca 2）和多语言Transformer模型（如XLM-R和mT5）。通过机器翻译和触发词切换技术进一步提升性能。

Result: 系统在数值触发词检测中排名第1，在二元触发词检测中排名第3，在情感检测中排名第7。

Conclusion: 该系统在WASSA-2024跨语言情感检测共享任务中取得了出色的表现。

Abstract: This paper presents our system built for the WASSA-2024 Cross-lingual Emotion
Detection Shared Task. The task consists of two subtasks: first, to assess an
emotion label from six possible classes for a given tweet in one of five
languages, and second, to predict words triggering the detected emotions in
binary and numerical formats. Our proposed approach revolves around fine-tuning
quantized large language models, specifically Orca~2, with low-rank adapters
(LoRA) and multilingual Transformer-based models, such as XLM-R and mT5. We
enhance performance through machine translation for both subtasks and trigger
word switching for the second subtask. The system achieves excellent
performance, ranking 1st in numerical trigger words detection, 3rd in binary
trigger words detection, and 7th in emotion detection.

</details>


### [140] [Prompt-Based Approach for Czech Sentiment Analysis](https://arxiv.org/abs/2508.08651)
*Jakub Šmíd,Pavel Přibáň*

Main category: cs.CL

TL;DR: 该论文首次提出了基于提示的方法，用于捷克语的方面级情感分析和情感分类，在低资源设置下表现优于传统微调。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为捷克语的方面级情感分析和情感分类引入基于提示的方法，并证明其相对于传统微调的优越性，特别是在零样本和少样本学习场景中。

Method: 采用序列到序列模型，同时解决方面级任务。使用基于提示的方法，并与传统微调进行比较。进行了零样本和少样本学习实验。探索了在目标领域数据上进行预训练的效果。

Result: 基于提示的方法在方面级任务上优于传统微调。在训练样本有限的情况下（零样本和少样本），提示方法比传统微调取得了显著更好的结果。在目标领域数据上进行预训练可以在零样本场景中带来显著改进。

Conclusion: 基于提示的方法是解决捷克语方面级情感分析和情感分类的有效途径，尤其在数据稀缺的场景下表现出色，且通过目标领域预训练可进一步提升性能。

Abstract: This paper introduces the first prompt-based methods for aspect-based
sentiment analysis and sentiment classification in Czech. We employ the
sequence-to-sequence models to solve the aspect-based tasks simultaneously and
demonstrate the superiority of our prompt-based approach over traditional
fine-tuning. In addition, we conduct zero-shot and few-shot learning
experiments for sentiment classification and show that prompting yields
significantly better results with limited training examples compared to
traditional fine-tuning. We also demonstrate that pre-training on data from the
target domain can lead to significant improvements in a zero-shot scenario.

</details>


### [141] [LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement](https://arxiv.org/abs/2508.08653)
*Rajmohan C,Sarthak Harne,Arvind Agarwal*

Main category: cs.CL

TL;DR: 本文提出了一种高效的LLM驱动文本到表格生成系统，通过任务分解和迭代自反馈来提高生成质量，解决了LLM在该任务中的挑战。


<details>
  <summary>Details</summary>
Motivation: 将非结构化文本转换为结构化数据（表格）是一项复杂任务，需要语义理解、推理和结构理解。尽管大型语言模型（LLMs）有潜力，但它们在处理歧义、领域特定数据、维护表格结构、管理长输入以及数值推理方面存在困难。

Method: 该系统采用了两种核心策略：1) 将文本到表格任务分解为可管理、有指导的子任务；2) 通过迭代自反馈来优化生成的表格。

Result: 与现有基线相比，该方法在两个复杂的公开文本到表格生成数据集上取得了显著的成果。

Conclusion: 定制的任务分解允许模型逐步解决问题并提高生成表格的质量。迭代自反馈虽然能增强性能，但也存在计算成本的权衡。该方法有效提升了LLM在文本到表格任务上的表现。

Abstract: Transforming unstructured text into structured data is a complex task,
requiring semantic understanding, reasoning, and structural comprehension.
While Large Language Models (LLMs) offer potential, they often struggle with
handling ambiguous or domain-specific data, maintaining table structure,
managing long inputs, and addressing numerical reasoning. This paper proposes
an efficient system for LLM-driven text-to-table generation that leverages
novel prompting techniques. Specifically, the system incorporates two key
strategies: breaking down the text-to-table task into manageable, guided
sub-tasks and refining the generated tables through iterative self-feedback. We
show that this custom task decomposition allows the model to address the
problem in a stepwise manner and improves the quality of the generated table.
Furthermore, we discuss the benefits and potential risks associated with
iterative self-feedback on the generated tables while highlighting the
trade-offs between enhanced performance and computational cost. Our methods
achieve strong results compared to baselines on two complex text-to-table
generation datasets available in the public domain.

</details>


### [142] [TopXGen: Topic-Diverse Parallel Data Generation for Low-Resource Machine Translation](https://arxiv.org/abs/2508.08680)
*Armel Zebaze,Benoît Sagot,Rachel Bawden*

Main category: cs.CL

TL;DR: 本文提出了一种名为TopXGen的LLM方法，用于生成高质量、主题多样化的低资源语言（LRL）文本，这些文本可以被回译以创建有用的并行数据，从而提升LLM在低资源机器翻译（MT）中的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在高资源语言（HRLs）机器翻译中表现出色，但在低资源语言（LRLs）翻译中表现不佳。现有的改进方法（如上下文学习和微调）受限于并行数据集的大小、质量和多样性。传统的反向翻译需要高质量的目标侧文本，而这在许多LRLs中不易获得。

Method: 本文提出了TopXGen，一种基于LLM的方法，用于生成高质量且主题多样的LRL目标侧文本。其核心思想是利用LLM擅长高资源语言翻译和多语言能力来生成听起来自然的LRL文本，然后将这些文本反向翻译成高资源源语言，以创建有用的并行文本，用于上下文学习和微调。

Result: 实验结果表明，TopXGen能够显著提升LLM在微调和上下文学习过程中的翻译性能。

Conclusion: TopXGen提供了一种有效的方法，通过生成高质量的合成并行数据来解决LLM在低资源语言机器翻译中的挑战，从而提高了其翻译表现。

Abstract: LLMs have been shown to perform well in machine translation (MT) with the use
of in-context learning (ICL), rivaling supervised models when translating into
high-resource languages (HRLs). However, they lag behind when translating into
low-resource language (LRLs). Example selection via similarity search and
supervised fine-tuning help. However the improvements they give are limited by
the size, quality and diversity of existing parallel datasets. A common
technique in low-resource MT is synthetic parallel data creation, the most
frequent of which is backtranslation, whereby existing target-side texts are
automatically translated into the source language. However, this assumes the
existence of good quality and relevant target-side texts, which are not readily
available for many LRLs. In this paper, we present \textsc{TopXGen}, an
LLM-based approach for the generation of high quality and topic-diverse data in
multiple LRLs, which can then be backtranslated to produce useful and diverse
parallel texts for ICL and fine-tuning. Our intuition is that while LLMs
struggle to translate into LRLs, their ability to translate well into HRLs and
their multilinguality enable them to generate good quality, natural-sounding
target-side texts, which can be translated well into a high-resource source
language. We show that \textsc{TopXGen} boosts LLM translation performance
during fine-tuning and in-context learning. Code and outputs are available at
https://github.com/ArmelRandy/topxgen.

</details>


### [143] [Out of the Box, into the Clinic? Evaluating State-of-the-Art ASR for Clinical Applications for Older Adults](https://arxiv.org/abs/2508.08684)
*Bram van Dijk,Tiberon Kuiper,Sirin Aoulad si Ahmed,Armel Levebvre,Jake Johnson,Jan Duin,Simon Mooijaart,Marco Spruit*

Main category: cs.CL

TL;DR: 本研究评估了用于老年荷兰语用户的语音识别（ASR）模型，发现通用多语言模型表现优于微调模型，且截断现有架构有助于平衡准确性和速度。


<details>
  <summary>Details</summary>
Motivation: 语音控制界面（如聊天机器人）对老年人在临床环境中很有帮助，但针对弱势群体（如老年人）的可靠自动语音识别（ASR）仍是瓶颈。

Method: 研究评估了最先进的ASR模型，使用老年荷兰成年人与为老年病学设计的Welzijn.AI聊天机器人交互时产生的语言数据。对比了通用多语言ASR模型和针对老年人荷兰语进行微调的模型，并考虑了处理速度。

Result: 通用多语言模型表现优于微调模型，表明最新的ASR模型能很好地泛化到真实数据集。此外，截断现有架构有助于平衡准确性和速度，但也发现了一些由于幻觉导致高词错误率（WER）的情况。

Conclusion: 当前通用ASR模型在处理老年人语音方面表现出色，可能无需大量特定微调。在实际应用中，通过截断架构可以有效平衡性能与速度，但需警惕并解决模型幻觉问题。

Abstract: Voice-controlled interfaces can support older adults in clinical contexts,
with chatbots being a prime example, but reliable Automatic Speech Recognition
(ASR) for underrepresented groups remains a bottleneck. This study evaluates
state-of-the-art ASR models on language use of older Dutch adults, who
interacted with the Welzijn.AI chatbot designed for geriatric contexts. We
benchmark generic multilingual ASR models, and models fine-tuned for Dutch
spoken by older adults, while also considering processing speed. Our results
show that generic multilingual models outperform fine-tuned models, which
suggests recent ASR models can generalise well out of the box to realistic
datasets. Furthermore, our results suggest that truncating existing
architectures is helpful in balancing the accuracy-speed trade-off, though we
also identify some cases with high WER due to hallucinations.

</details>


### [144] [A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models](https://arxiv.org/abs/2508.08712)
*Lingzhe Zhang,Liancheng Fang,Chiming Duan,Minghua He,Leyi Pan,Pei Xiao,Shiyu Huang,Yunpeng Zhai,Xuming Hu,Philip S. Yu,Aiwei Liu*

Main category: cs.CL

TL;DR: 该论文系统性地综述了并行文本生成方法，旨在解决大型语言模型（LLMs）自回归生成速度慢的问题，并对现有技术进行分类、分析和展望。


<details>
  <summary>Details</summary>
Motivation: 现代LLMs的核心能力是文本生成，但其主要依赖的自回归（AR）生成方式是顺序的，导致生成速度受限。研究人员正探索并行文本生成以提高推理效率，但目前缺乏对这些技术的全面分析。

Method: 本文对并行文本生成方法进行了系统性综述。将现有方法分为基于AR和非基于AR两种范式，详细考察了每种类别中的核心技术。在此分类基础上，评估了它们在速度、质量和效率方面的理论权衡，并探讨了它们与其他加速策略结合和比较的潜力。

Result: 提出了一个系统的并行文本生成方法分类体系，详细分析了基于AR和非基于AR范畴下的核心技术，并评估了它们在速度、质量和效率方面的理论权衡。此外，还探讨了这些技术与其他加速策略结合的可能性。

Conclusion: 基于研究发现，论文强调了并行文本生成的最新进展，指出了存在的开放挑战，并为未来的研究方向提供了有前景的展望。

Abstract: As text generation has become a core capability of modern Large Language
Models (LLMs), it underpins a wide range of downstream applications. However,
most existing LLMs rely on autoregressive (AR) generation, producing one token
at a time based on previously generated context-resulting in limited generation
speed due to the inherently sequential nature of the process. To address this
challenge, an increasing number of researchers have begun exploring parallel
text generation-a broad class of techniques aimed at breaking the
token-by-token generation bottleneck and improving inference efficiency.
Despite growing interest, there remains a lack of comprehensive analysis on
what specific techniques constitute parallel text generation and how they
improve inference performance. To bridge this gap, we present a systematic
survey of parallel text generation methods. We categorize existing approaches
into AR-based and Non-AR-based paradigms, and provide a detailed examination of
the core techniques within each category. Following this taxonomy, we assess
their theoretical trade-offs in terms of speed, quality, and efficiency, and
examine their potential for combination and comparison with alternative
acceleration strategies. Finally, based on our findings, we highlight recent
advancements, identify open challenges, and outline promising directions for
future research in parallel text generation.

</details>


### [145] [IROTE: Human-like Traits Elicitation of Large Language Model via In-Context Self-Reflective Optimization](https://arxiv.org/abs/2508.08719)
*Yuzhuo Bai,Shitong Duan,Muhua Huang,Jing Yao,Zhenghao Liu,Peng Zhang,Tun Lu,Xiaoyuan Yi,Maosong Sun,Xing Xie*

Main category: cs.CL

TL;DR: IROTE是一种新的上下文方法，通过生成和优化LLM的文本自我反思，实现稳定且可迁移的人类特质激发，克服了现有方法的表面化问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在激发人类特质（如个性、价值观）时，存在“表面化激发问题”，即LLMs只能模仿浅层和不稳定的风格模式，无法像人类一样在不同任务中精确且一致地体现所需特质。

Method: 本文提出了IROTE方法，一种新颖的上下文（in-context）特质激发方法。该方法借鉴心理学理论，通过在提示中自动生成和优化文本自我反思（包含自我感知的经验）来刺激LLMs的特质驱动行为。优化过程通过迭代最大化一个信息论目标来完成，该目标旨在增强LLMs行为与目标特质之间的联系，同时减少反思中的冗余信息，从而生成简洁而富有启发性的特质反思，且无需微调。

Result: 在三种人类特质系统上的大量实验表明，一个由IROTE生成的自我反思能够使LLMs在多种下游任务中稳定地模仿目标特质，而不仅仅是简单的问卷回答，并且持续优于现有的强基线方法。

Conclusion: IROTE方法通过其独特的自我反思生成和优化机制，成功解决了LLMs特质激发中的稳定性与可迁移性问题，使其能够更精确、一致地展现人类特质。

Abstract: Trained on various human-authored corpora, Large Language Models (LLMs) have
demonstrated a certain capability of reflecting specific human-like traits
(e.g., personality or values) by prompting, benefiting applications like
personalized LLMs and social simulations. However, existing methods suffer from
the superficial elicitation problem: LLMs can only be steered to mimic shallow
and unstable stylistic patterns, failing to embody the desired traits precisely
and consistently across diverse tasks like humans. To address this challenge,
we propose IROTE, a novel in-context method for stable and transferable trait
elicitation. Drawing on psychological theories suggesting that traits are
formed through identity-related reflection, our method automatically generates
and optimizes a textual self-reflection within prompts, which comprises
self-perceived experience, to stimulate LLMs' trait-driven behavior. The
optimization is performed by iteratively maximizing an information-theoretic
objective that enhances the connections between LLMs' behavior and the target
trait, while reducing noisy redundancy in reflection without any fine-tuning,
leading to evocative and compact trait reflection. Extensive experiments across
three human trait systems manifest that one single IROTE-generated
self-reflection can induce LLMs' stable impersonation of the target trait
across diverse downstream tasks beyond simple questionnaire answering,
consistently outperforming existing strong baselines.

</details>


### [146] [Magical: Medical Lay Language Generation via Semantic Invariance and Layperson-tailored Adaptation](https://arxiv.org/abs/2508.08730)
*Weibin Liao,Tianlong Wang,Yinghao Zhu,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.CL

TL;DR: 提出Magical，一种非对称LoRA架构，用于解决异构医疗通俗语言生成（MLLG）中语义保真度和风格多样性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 标准LoRA在处理多源异构MLLG数据集时，难以满足语义保真度和多样化通俗风格生成的要求。

Method: 提出Magical，一种非对称LoRA架构，采用共享矩阵A进行抽象摘要，并使用多个独立的矩阵B进行多样化通俗风格生成。通过引入语义不变性约束来保持语义保真度，并通过推荐引导开关来适应多样化风格生成。

Result: 在三个真实世界通俗语言生成数据集上，Magical持续优于基于提示的方法、标准LoRA及其最新变体，同时可训练参数减少了31.66%。

Conclusion: Magical有效解决了异构MLLG中的挑战，在提高通俗语言生成质量和效率方面表现出色，有助于提升复杂科学内容的普及性。

Abstract: Medical Lay Language Generation (MLLG) plays a vital role in improving the
accessibility of complex scientific content for broader audiences. Recent
literature to MLLG commonly employ parameter-efficient fine-tuning methods such
as Low-Rank Adaptation (LoRA) to fine-tuning large language models (LLMs) using
paired expert-lay language datasets. However, LoRA struggles with the
challenges posed by multi-source heterogeneous MLLG datasets. Specifically,
through a series of exploratory experiments, we reveal that standard LoRA fail
to meet the requirement for semantic fidelity and diverse lay-style generation
in MLLG task. To address these limitations, we propose Magical, an asymmetric
LoRA architecture tailored for MLLG under heterogeneous data scenarios. Magical
employs a shared matrix $A$ for abstractive summarization, along with multiple
isolated matrices $B$ for diverse lay-style generation. To preserve semantic
fidelity during the lay language generation process, Magical introduces a
Semantic Invariance Constraint to mitigate semantic subspace shifts on matrix
$A$. Furthermore, to better adapt to diverse lay-style generation, Magical
incorporates the Recommendation-guided Switch, an externally interface to
prompt the LLM to switch between different matrices $B$. Experimental results
on three real-world lay language generation datasets demonstrate that Magical
consistently outperforms prompt-based methods, vanilla LoRA, and its recent
variants, while also reducing trainable parameters by 31.66%.

</details>


### [147] [SciRerankBench: Benchmarking Rerankers Towards Scientific Retrieval-Augmented Generated LLMs](https://arxiv.org/abs/2508.08742)
*Haotian Chen,Qingqing Long,Meng Xiao,Xiao Luo,Wei Ju,Chengrui Wang,Xuezhi Wang,Yuanchun Zhou,Hengshu Zhu*

Main category: cs.CL

TL;DR: 本文提出了SciRerankBench，一个专门用于评估科学领域RAG-LLM系统中重排器性能的基准，并揭示了现有重排器的优缺点。


<details>
  <summary>Details</summary>
Motivation: 两阶段检索增强生成大型语言模型（RAG-LLM）在科学文献问答中取得了显著进展，其中重排器（第二阶段）至关重要，尤其是在科学领域，术语的细微差异可能严重影响答案的准确性。然而，这些工作的潜力和局限性尚未被充分探索。

Method: 开发了SciRerankBench，一个涵盖五个科学主题的科学重排器评估基准。为了严格评估重排器在抗噪声、相关性消歧和事实一致性方面的性能，设计了三种问答对类型：噪声上下文（NC）、语义相似但逻辑不相关的上下文（SSLI）和反事实上下文（CC）。系统评估了13种广泛使用的重排器在五类大型语言模型上的表现。

Result: 通过对13种重排器在五类LLM上的系统评估，提供了关于它们相对优势和局限性的详细见解。据作者所知，SciRerankBench是第一个专门为评估RAG-LLM中重排器而开发的基准。

Conclusion: SciRerankBench为RAG-LLM中重排器的未来发展提供了宝贵的观察和指导。

Abstract: Scientific literature question answering is a pivotal step towards new
scientific discoveries. Recently, \textit{two-stage} retrieval-augmented
generated large language models (RAG-LLMs) have shown impressive advancements
in this domain. Such a two-stage framework, especially the second stage
(reranker), is particularly essential in the scientific domain, where subtle
differences in terminology may have a greatly negative impact on the final
factual-oriented or knowledge-intensive answers. Despite this significant
progress, the potential and limitations of these works remain unexplored. In
this work, we present a Scientific Rerank-oriented RAG Benchmark
(SciRerankBench), for evaluating rerankers within RAG-LLMs systems, spanning
five scientific subjects. To rigorously assess the reranker performance in
terms of noise resilience, relevance disambiguation, and factual consistency,
we develop three types of question-context-answer (Q-C-A) pairs, i.e., Noisy
Contexts (NC), Semantically Similar but Logically Irrelevant Contexts (SSLI),
and Counterfactual Contexts (CC). Through systematic evaluation of 13 widely
used rerankers on five families of LLMs, we provide detailed insights into
their relative strengths and limitations. To the best of our knowledge,
SciRerankBench is the first benchmark specifically developed to evaluate
rerankers within RAG-LLMs, which provides valuable observations and guidance
for their future development.

</details>


### [148] [DevNous: An LLM-Based Multi-Agent System for Grounding IT Project Management in Unstructured Conversation](https://arxiv.org/abs/2508.08761)
*Stavros Doropoulos,Stavros Vologiannidis,Ioannis Magnisalis*

Main category: cs.CL

TL;DR: DevNous是一个基于LLM的多智能体专家系统，旨在自动化将团队非结构化对话转化为IT项目治理所需结构化工件的过程，并在新基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 将非结构化的团队对话手动翻译成IT项目治理所需的结构化工件是现代信息系统管理中的一个关键瓶颈。

Method: 引入DevNous系统，一个基于大型语言模型（LLM）的多智能体专家系统。该系统直接集成到团队聊天环境中，能够识别非正式对话中的可操作意图，并管理有状态、多轮的工作流，以完成自动化任务形式化和进度摘要合成等核心管理任务。为评估系统，创建了一个包含160个现实交互对话轮次的新基准数据集，并进行手动多标签标注。

Result: 在新的基准测试中，DevNous实现了81.3%的准确匹配回合精度和0.845的多集F1分数，证明了其可行性。

Conclusion: 该工作的主要贡献是：1) 提出了一种经过验证的开发环境管理代理的架构模式；2) 引入了针对这一挑战性问题领域的第一个稳健的实证基线和公开基准数据集。DevNous为解决IT项目治理中的对话转换瓶颈提供了有前景的解决方案。

Abstract: The manual translation of unstructured team dialogue into the structured
artifacts required for Information Technology (IT) project governance is a
critical bottleneck in modern information systems management. We introduce
DevNous, a Large Language Model-based (LLM) multi-agent expert system, to
automate this unstructured-to-structured translation process. DevNous
integrates directly into team chat environments, identifying actionable intents
from informal dialogue and managing stateful, multi-turn workflows for core
administrative tasks like automated task formalization and progress summary
synthesis. To quantitatively evaluate the system, we introduce a new benchmark
of 160 realistic, interactive conversational turns. The dataset was manually
annotated with a multi-label ground truth and is publicly available. On this
benchmark, DevNous achieves an exact match turn accuracy of 81.3\% and a
multiset F1-Score of 0.845, providing strong evidence for its viability. The
primary contributions of this work are twofold: (1) a validated architectural
pattern for developing ambient administrative agents, and (2) the introduction
of the first robust empirical baseline and public benchmark dataset for this
challenging problem domain.

</details>


### [149] [Privacy-protected Retrieval-Augmented Generation for Knowledge Graph Question Answering](https://arxiv.org/abs/2508.08785)
*Yunfeng Ning,Mayi Xu,Jintao Wen,Qiankun Pi,Yuanyuan Zhu,Ming Zhong,Jiawei Jiang,Tieyun Qian*

Main category: cs.CL

TL;DR: 本文首次提出并研究了隐私保护的RAG场景，其中知识图谱中的实体对LLM是匿名的。为此，我们提出了ARoG框架，通过关系中心抽象和结构导向抽象策略，在保护隐私的同时实现有效的知识检索。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）存在幻觉和知识过时问题。检索增强生成（RAG）通过整合外部知识（如知识图谱）来解决这些问题。然而，在RAG系统中使用私有知识图谱，尤其是在使用缺乏透明度和控制的第三方LLM API时，由于LLMs的黑盒特性和潜在的不安全数据传输，会带来显著的隐私风险。

Method: 本文提出了一个新颖的ARoG框架，以解决隐私保护RAG场景中的两个关键挑战：如何将匿名实体转换为可检索信息，以及如何检索与问题相关的匿名实体。ARoG包含两种策略：1) 关系中心抽象：通过动态捕获相邻关系的语义，将实体抽象为高级概念，补充有意义的语义以支持检索。2) 结构导向抽象：将非结构化自然语言问题转换为结构化的抽象概念路径，使其能更有效地与知识图谱中的抽象概念对齐，从而提高检索性能。这两种策略严格保护隐私不暴露给LLMs。

Result: 在三个数据集上的实验表明，ARoG框架在实现强大的性能和隐私鲁棒性方面表现出色。

Conclusion: ARoG框架通过创新的抽象策略，首次成功地在实体匿名的知识图谱场景下实现了隐私保护的RAG系统，有效解决了匿名实体检索的挑战，并在保护隐私的同时保持了高性能。

Abstract: LLMs often suffer from hallucinations and outdated or incomplete knowledge.
RAG is proposed to address these issues by integrating external knowledge like
that in KGs into LLMs. However, leveraging private KGs in RAG systems poses
significant privacy risks due to the black-box nature of LLMs and potential
insecure data transmission, especially when using third-party LLM APIs lacking
transparency and control. In this paper, we investigate the privacy-protected
RAG scenario for the first time, where entities in KGs are anonymous for LLMs,
thus preventing them from accessing entity semantics. Due to the loss of
semantics of entities, previous RAG systems cannot retrieve question-relevant
knowledge from KGs by matching questions with the meaningless identifiers of
anonymous entities. To realize an effective RAG system in this scenario, two
key challenges must be addressed: (1) How can anonymous entities be converted
into retrievable information. (2) How to retrieve question-relevant anonymous
entities. Hence, we propose a novel ARoG framework including relation-centric
abstraction and structure-oriented abstraction strategies. For challenge (1),
the first strategy abstracts entities into high-level concepts by dynamically
capturing the semantics of their adjacent relations. It supplements meaningful
semantics which can further support the retrieval process. For challenge (2),
the second strategy transforms unstructured natural language questions into
structured abstract concept paths. These paths can be more effectively aligned
with the abstracted concepts in KGs, thereby improving retrieval performance.
To guide LLMs to effectively retrieve knowledge from KGs, the two strategies
strictly protect privacy from being exposed to LLMs. Experiments on three
datasets demonstrate that ARoG achieves strong performance and
privacy-robustness.

</details>


### [150] [Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments](https://arxiv.org/abs/2508.08791)
*Junjie Ye,Changhao Jiang,Zhengyin Du,Yufei Xu,Xuesong Yao,Zhiheng Xi,Xiaoran Fan,Qi Zhang,Xuanjing Huang,Jiecao Chen*

Main category: cs.CL

TL;DR: 该研究提出了一个自动化环境构建流程和可验证的奖励机制，以提升大型语言模型（LLMs）的工具使用能力，并在实验中取得了显著效果，且不损害模型的通用能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）有效使用工具的能力对它们与环境的交互至关重要，但当前缺乏专门为工具使用设计的有效强化学习（RL）框架，主要挑战在于构建稳定的训练环境和设计可验证的奖励机制。

Method: 1. 自动化环境构建流程：包括场景分解、文档生成、函数集成、复杂度扩展和本地化部署，以创建高质量的训练环境，提供详细且可衡量的反馈，且不依赖外部工具。
2. 可验证的奖励机制：评估工具使用的精确性和任务执行的完整性。
3. 将此机制与从构建环境中收集的轨迹数据结合，无缝集成到标准RL算法中，以实现反馈驱动的模型训练。

Result: 在不同规模的LLMs上进行的实验表明，该方法显著增强了模型的工具使用性能，且不损害其通用能力，无论推理模式或训练算法如何。分析表明，性能提升源于模型底层MLP参数的更新，从而改善了上下文理解和推理能力。

Conclusion: 本研究提出的自动化环境构建和可验证奖励机制，有效解决了LLMs工具使用训练中的环境和奖励挑战，显著提升了LLMs的工具使用能力，并通过改进上下文理解和推理实现了这一目标。

Abstract: Effective tool use is essential for large language models (LLMs) to interact
meaningfully with their environment. However, progress is limited by the lack
of efficient reinforcement learning (RL) frameworks specifically designed for
tool use, due to challenges in constructing stable training environments and
designing verifiable reward mechanisms. To address this, we propose an
automated environment construction pipeline, incorporating scenario
decomposition, document generation, function integration, complexity scaling,
and localized deployment. This enables the creation of high-quality training
environments that provide detailed and measurable feedback without relying on
external tools. Additionally, we introduce a verifiable reward mechanism that
evaluates both the precision of tool use and the completeness of task
execution. When combined with trajectory data collected from the constructed
environments, this mechanism integrates seamlessly with standard RL algorithms
to facilitate feedback-driven model training. Experiments on LLMs of varying
scales demonstrate that our approach significantly enhances the models'
tool-use performance without degrading their general capabilities, regardless
of inference modes or training algorithms. Our analysis suggests that these
gains result from improved context understanding and reasoning, driven by
updates to the lower-layer MLP parameters in models.

</details>


### [151] [TiMoE: Time-Aware Mixture of Language Experts](https://arxiv.org/abs/2508.08827)
*Robin Faro,Dongyang Fan,Tamar Alphaidze,Martin Jaggi*

Main category: cs.CL

TL;DR: 为解决大型语言模型知识过时和时间泄漏问题，本文提出了TiMoE（时间感知语言专家混合模型），通过对不同时间段预训练的专家进行因果路由，实现知识的时效性和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常在固定时间点的数据快照上训练，导致其知识过时，且预测可能出现时间泄漏（即在回答查询时使用了未来信息）。

Method: 从零开始预训练一组GPT风格的专家模型，每个专家在2013-2024语料库的不同两年时间切片上训练。通过TiMoE（时间感知语言专家混合模型）将这些专家组合起来。在推理时，TiMoE会屏蔽训练窗口晚于查询时间戳的所有专家，并融合剩余专家的对数概率，以确保严格的因果有效性。同时，发布了TSQA基准测试集，用于精细测量时间幻觉。

Result: 在八个标准NLP任务和TSQA上的实验表明，TiMoE变体性能与最佳单时期专家相当或更优，并将未来知识错误率降低了高达15%。结果证明，模块化、时间分段的预训练结合因果路由是构建时间上更准确且不牺牲通用性能的LLM的简单有效途径。

Conclusion: 模块化、时间分段的预训练结合因果路由是一种简单而有效的方法，能够使大型语言模型在保持通用性能的同时，更好地遵守时间顺序，避免知识过时和时间泄漏问题。

Abstract: Large language models (LLMs) are typically trained on fixed snapshots of the
web, which means that their knowledge becomes stale and their predictions risk
temporal leakage: relying on information that lies in the future relative to a
query. We tackle this problem by pre-training from scratch a set of GPT-style
experts on disjoint two-year slices of a 2013-2024 corpus and combining them
through TiMoE, a Time-aware Mixture of Language Experts. At inference time,
TiMoE masks all experts whose training window ends after the query timestamp
and merges the remaining log-probabilities in a shared space, guaranteeing
strict causal validity while retaining the breadth of multi-period knowledge.
We also release TSQA, a 10k-question benchmark whose alternatives are
explicitly labelled as past, future or irrelevant, allowing fine-grained
measurement of temporal hallucinations. Experiments on eight standard NLP tasks
plus TSQA show that a co-adapted TiMoE variant matches or exceeds the best
single-period expert and cuts future-knowledge errors by up to 15%. Our results
demonstrate that modular, time-segmented pre-training paired with causal
routing is a simple yet effective path toward LLMs that stay chronologically
grounded without sacrificing general performance much. We open source our code
at TiMoE (Github): https://github.com/epfml/TiMoE

</details>


### [152] [An Investigation of Robustness of LLMs in Mathematical Reasoning: Benchmarking with Mathematically-Equivalent Transformation of Advanced Mathematical Problems](https://arxiv.org/abs/2508.08833)
*Yuren Hao,Xiang Wan,Chengxiang Zhai*

Main category: cs.CL

TL;DR: 本文提出了一种超越传统方法的系统框架，通过对数学上等价但存在语言和参数变化的进阶数学问题进行压力测试，评估大型语言模型（LLMs）的数学推理鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的评估方法无法衡量LLMs对非数学扰动的敏感性，因此无法准确评估其数学推理能力。

Method: 引入了一个系统框架，通过对数学上等价但具有语言和参数变体的进阶数学问题进行压力测试，来评估LLMs的数学推理鲁棒性。基于此方法创建了PutnamGAP数据集，其中包含竞赛级别的数学问题及其多个数学等价变体。使用该数据集评估了18个商业和开源LLMs。

Result: 在变体问题上，所有LLMs都表现出显著的性能下降。OpenAI的旗舰推理模型O3在原始问题上得分为49%，但在表面变体上下降了4个百分点，在基于核心步骤的变体上下降了10.5个百分点，而小型模型表现更差。

Conclusion: 所提出的新评估方法能有效加深对LLMs鲁棒性的理解，并为进一步提升其数学推理能力提供了新见解。

Abstract: In this paper, we introduce a systematic framework beyond conventional method
to assess LLMs' mathematical-reasoning robustness by stress-testing them on
advanced math problems that are mathematically equivalent but with linguistic
and parametric variation. These transformations allow us to measure the
sensitivity of LLMs to non-mathematical perturbations, thereby enabling a more
accurate evaluation of their mathematical reasoning capabilities. Using this
new evaluation methodology, we created PutnamGAP, a new benchmark dataset with
multiple mathematically-equivalent variations of competition-level math
problems. With the new dataset, we evaluate multiple families of representative
LLMs and examine their robustness. Across 18 commercial and open-source models
we observe sharp performance degradation on the variants. OpenAI's flagship
reasoning model, O3, scores 49 % on the originals but drops by 4 percentage
points on surface variants, and by 10.5 percentage points on core-step-based
variants, while smaller models fare far worse. Overall, the results show that
the proposed new evaluation methodology is effective for deepening our
understanding of the robustness of LLMs and generating new insights for further
improving their mathematical reasoning capabilities.

</details>


### [153] [Steering Towards Fairness: Mitigating Political Bias in LLMs](https://arxiv.org/abs/2508.08846)
*Afrozah Nadeem,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 本文提出一个框架，通过分析解码器LLM的内部表示，探测并缓解其编码的政治和经济意识形态偏见，并展示了基于激活向量的有效缓解方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在广泛应用的同时，存在编码和再现意识形态偏见的倾向，尤其是在政治和经济维度上，这引发了担忧。

Method: 该方法基于“政治罗盘测试”（Political Compass Test, PCT），使用对比对来提取并比较Mistral和DeepSeek等模型隐藏层的激活。研究者引入了一个全面的激活提取流程，能够进行跨多个意识形态轴的逐层分析，以揭示与政治框架相关的显著差异。同时，利用所发现的偏见进行基于转向向量（steering vector）的缓解。

Result: 结果显示，解码器LLMs在不同层系统性地编码了表示偏见，这些偏见可以被有效利用进行基于转向向量的缓解。

Conclusion: 这项工作深入揭示了政治偏见在LLMs中如何被编码，并提供了一种超越表面输出干预的、有原则的去偏方法。

Abstract: Recent advancements in large language models (LLMs) have enabled their
widespread use across diverse real-world applications. However, concerns remain
about their tendency to encode and reproduce ideological biases, particularly
along political and economic dimensions. In this paper, we propose a framework
for probing and mitigating such biases in decoder-based LLMs through analysis
of internal model representations. Grounded in the Political Compass Test
(PCT), our method uses contrastive pairs to extract and compare hidden layer
activations from models like Mistral and DeepSeek. We introduce a comprehensive
activation extraction pipeline capable of layer-wise analysis across multiple
ideological axes, revealing meaningful disparities linked to political framing.
Our results show that decoder LLMs systematically encode representational bias
across layers, which can be leveraged for effective steering vector-based
mitigation. This work provides new insights into how political bias is encoded
in LLMs and offers a principled approach to debiasing beyond surface-level
output interventions.

</details>


### [154] [BiasGym: Fantastic Biases and How to Find (and Remove) Them](https://arxiv.org/abs/2508.08855)
*Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein*

Main category: cs.CL

TL;DR: BiasGym是一个通用框架，用于可靠地注入、分析和缓解大型语言模型（LLM）中的概念关联偏见，旨在实现系统性分析和去偏。


<details>
  <summary>Details</summary>
Motivation: LLM中编码的偏见行为通常微妙且难以隔离，即使故意引发也很难，这使得系统分析和去偏特别具有挑战性。

Method: BiasGym包含两部分：BiasInject通过基于token的微调将特定偏见注入冻结的模型中；BiasScope利用这些注入的信号来识别和引导负责偏见行为的组件。

Result: 该方法能够实现一致的偏见引出，进行机制分析；支持有针对性的去偏，且不降低下游任务性能；并能泛化到训练期间未见的偏见。BiasGym在减少真实世界刻板印象和探索虚构关联方面均显示出有效性。

Conclusion: BiasGym框架对LLM的安全干预和可解释性研究具有实用价值。

Abstract: Understanding biases and stereotypes encoded in the weights of Large Language
Models (LLMs) is crucial for developing effective mitigation strategies. Biased
behaviour is often subtle and non-trivial to isolate, even when deliberately
elicited, making systematic analysis and debiasing particularly challenging. To
address this, we introduce BiasGym, a simple, cost-effective, and generalizable
framework for reliably injecting, analyzing, and mitigating conceptual
associations within LLMs. BiasGym consists of two components: BiasInject, which
injects specific biases into the model via token-based fine-tuning while
keeping the model frozen, and BiasScope, which leverages these injected signals
to identify and steer the components responsible for biased behavior. Our
method enables consistent bias elicitation for mechanistic analysis, supports
targeted debiasing without degrading performance on downstream tasks, and
generalizes to biases unseen during training. We demonstrate the effectiveness
of BiasGym in reducing real-world stereotypes (e.g., people from a country
being `reckless drivers') and in probing fictional associations (e.g., people
from a country having `blue skin'), showing its utility for both safety
interventions and interpretability research.

</details>


### [155] [Weakly Supervised Fine-grained Span-Level Framework for Chinese Radiology Report Quality Assurance](https://arxiv.org/abs/2508.08876)
*Kaiyu Wang,Lin Mu,Zhiyao Yang,Ximing Li,Xiaotang Zhou Wanfu Gao,Huimao Zhang*

Main category: cs.CL

TL;DR: 提出Sqator模型，通过分析初级和高级放射报告之间的修订文本片段（span-level）来自动评估放射报告的质量分数。


<details>
  <summary>Details</summary>
Motivation: 放射报告的质量保证（QA）目前依赖高级医生手动审查，这耗费大量人力且可能因诊断偏差或医生能力等因素导致评分不准确。

Method: Sqator（Span-level Quality Assurance EvaluaTOR）通过测量初级报告和高级报告之间修订片段的重要性来计算QA分数，然后合并所有修订片段的分数以输出最终QA分数。这与常见的文档级语义比较方法不同，它着重于更细粒度的文本片段分析。

Result: 在包含12,013份放射报告的数据集上进行评估，Sqator能够获得具有竞争力的QA分数。此外，修订片段的重要性分数与高级医生的判断一致。

Conclusion: Sqator模型能够有效地自动化放射报告的质量保证过程，减轻高级医生的工作负担，并提高QA评分的准确性和一致性。

Abstract: Quality Assurance (QA) for radiology reports refers to judging whether the
junior reports (written by junior doctors) are qualified. The QA scores of one
junior report are given by the senior doctor(s) after reviewing the image and
junior report. This process requires intensive labor costs for senior doctors.
Additionally, the QA scores may be inaccurate for reasons like diagnosis bias,
the ability of senior doctors, and so on. To address this issue, we propose a
Span-level Quality Assurance EvaluaTOR (Sqator) to mark QA scores
automatically. Unlike the common document-level semantic comparison method, we
try to analyze the semantic difference by exploring more fine-grained text
spans. Unlike the common document-level semantic comparison method, we try to
analyze the semantic difference by exploring more fine-grained text spans.
Specifically, Sqator measures QA scores by measuring the importance of revised
spans between junior and senior reports, and outputs the final QA scores by
merging all revised span scores. We evaluate Sqator using a collection of
12,013 radiology reports. Experimental results show that Sqator can achieve
competitive QA scores. Moreover, the importance scores of revised spans can be
also consistent with the judgments of senior doctors.

</details>


### [156] [Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models](https://arxiv.org/abs/2508.08879)
*Haeun Yu,Seogyeong Jeong,Siddhesh Pawar,Jisu Shin,Jiho Jin,Junho Myung,Alice Oh,Isabelle Augenstein*

Main category: cs.CL

TL;DR: 该研究提出了CultureScope，一种基于机械可解释性的方法，用于探测大型语言模型（LLMs）的内部表示，以理解其文化知识空间中的偏见，特别是西方主导偏见和文化扁平化。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在全球范围内的广泛部署，需要更好地理解其对欠发达文化的过度概括如何影响文化理解。现有工作仅进行LLMs文化能力的外部评估，未能解释LLMs内部机制如何导致文化（错误）表征。

Method: 提出了CultureScope，首个基于机械可解释性的方法，通过补丁技术提取LLMs的内部文化知识。引入了“文化扁平化分数”来衡量内在文化偏见。此外，研究了LLMs如何内化西方主导偏见和文化扁平化，以追踪文化偏见在LLMs内部的产生。

Result: 实验结果显示，LLMs在其文化知识空间中编码了西方主导偏见和文化扁平化。发现低资源文化对文化偏见的敏感度较低，这可能归因于其有限的训练资源。

Conclusion: 该工作为未来减轻文化偏见和增强LLMs文化理解的研究奠定了基础。

Abstract: The growing deployment of large language models (LLMs) across diverse
cultural contexts necessitates a better understanding of how the
overgeneralization of less documented cultures within LLMs' representations
impacts their cultural understanding. Prior work only performs extrinsic
evaluation of LLMs' cultural competence, without accounting for how LLMs'
internal mechanisms lead to cultural (mis)representation. To bridge this gap,
we propose Culturescope, the first mechanistic interpretability-based method
that probes the internal representations of LLMs to elicit the underlying
cultural knowledge space. CultureScope utilizes a patching method to extract
the cultural knowledge. We introduce a cultural flattening score as a measure
of the intrinsic cultural biases. Additionally, we study how LLMs internalize
Western-dominance bias and cultural flattening, which allows us to trace how
cultural biases emerge within LLMs. Our experimental results reveal that LLMs
encode Western-dominance bias and cultural flattening in their cultural
knowledge space. We find that low-resource cultures are less susceptible to
cultural biases, likely due to their limited training resources. Our work
provides a foundation for future research on mitigating cultural biases and
enhancing LLMs' cultural understanding. Our codes and data used for experiments
are publicly available.

</details>


### [157] [ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs](https://arxiv.org/abs/2508.08895)
*Keyu Chen,Zhifeng Shen,Daohai Yu,Haoqian Wu,Wei Wen,Jianfeng He,Ruizhi Qiao,Xing Sun*

Main category: cs.CL

TL;DR: 提出一种自适应串行-并行解码（ASPD）方法，通过利用LLM输出中的内在并行性，显著提高推理速度，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的自回归解码范式导致高推理延迟，限制了其在延迟敏感应用中的部署。

Method: 提出ASPD框架，解决并行数据构建和高效并行解码两大挑战。通过非侵入式管道自动提取和验证并行结构，并实现混合解码引擎，支持串行和并行模式间的无缝切换，同时维护可复用的KV缓存。

Result: 在通用任务、检索增强生成和数学推理等多个任务上，ASPD实现了显著的性能提升。在Vicuna Bench上，速度提升高达3.19倍（平均1.85倍），同时响应质量与自回归模型相比仅有1%的差异。

Conclusion: ASPD为高效LLM并行推理设立了新基准，为LLM在客户服务机器人和答案检索引擎等延迟敏感应用中的部署铺平了道路。

Abstract: The increasing scale and complexity of large language models (LLMs) pose
significant inference latency challenges, primarily due to their autoregressive
decoding paradigm characterized by the sequential nature of next-token
prediction. By re-examining the outputs of autoregressive models, we observed
that some segments exhibit parallelizable structures, which we term intrinsic
parallelism. Decoding each parallelizable branch simultaneously (i.e. parallel
decoding) can significantly improve the overall inference speed of LLMs. In
this paper, we propose an Adaptive Serial-Parallel Decoding (ASPD), which
addresses two core challenges: automated construction of parallelizable data
and efficient parallel decoding mechanism. More specifically, we introduce a
non-invasive pipeline that automatically extracts and validates parallelizable
structures from the responses of autoregressive models. To empower efficient
adaptive serial-parallel decoding, we implement a Hybrid Decoding Engine which
enables seamless transitions between serial and parallel decoding modes while
maintaining a reusable KV cache, maximizing computational efficiency. Extensive
evaluations across General Tasks, Retrieval-Augmented Generation, Mathematical
Reasoning, demonstrate that ASPD achieves unprecedented performance in both
effectiveness and efficiency. Notably, on Vicuna Bench, our method achieves up
to 3.19x speedup (1.85x on average) while maintaining response quality within
1% difference compared to autoregressive models, realizing significant
acceleration without compromising generation quality. Our framework sets a
groundbreaking benchmark for efficient LLM parallel inference, paving the way
for its deployment in latency-sensitive applications such as AI-powered
customer service bots and answer retrieval engines.

</details>


### [158] [Munsit at NADI 2025 Shared Task 2: Pushing the Boundaries of Multidialectal Arabic ASR with Weakly Supervised Pretraining and Continual Supervised Fine-tuning](https://arxiv.org/abs/2508.08912)
*Mahmoud Salhab,Shameed Sait,Mohammad Abusheikh,Hasan Abusheikh*

Main category: cs.CL

TL;DR: 本文提出了一种可扩展的训练流程，结合弱监督学习和监督微调，为低资源、方言丰富的阿拉伯语开发了鲁棒的自动语音识别（ASR）模型，并在多方言阿拉伯语ASR挑战赛中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别在人机交互中至关重要，但为阿拉伯语等低资源语言开发准确的ASR系统面临挑战，原因在于标注数据有限以及方言多样性带来的语言复杂性。

Method: 该方法采用两阶段训练流程：首先，模型在15,000小时包含现代标准阿拉伯语和各种方言阿拉伯语的弱标注语音数据上进行预训练；随后，使用过滤后的弱标注数据和少量高质量标注数据集进行持续的监督微调。

Result: 该方法取得了最先进的结果，在多方言阿拉伯语ASR挑战赛中排名第一。

Conclusion: 研究结果表明，弱监督与微调相结合的方法在克服数据稀缺性方面是有效的，能为低资源、方言丰富的语言提供高质量的ASR系统。

Abstract: Automatic speech recognition (ASR) plays a vital role in enabling natural
human-machine interaction across applications such as virtual assistants,
industrial automation, customer support, and real-time transcription. However,
developing accurate ASR systems for low-resource languages like Arabic remains
a significant challenge due to limited labeled data and the linguistic
complexity introduced by diverse dialects. In this work, we present a scalable
training pipeline that combines weakly supervised learning with supervised
fine-tuning to develop a robust Arabic ASR model. In the first stage, we
pretrain the model on 15,000 hours of weakly labeled speech covering both
Modern Standard Arabic (MSA) and various Dialectal Arabic (DA) variants. In the
subsequent stage, we perform continual supervised fine-tuning using a mixture
of filtered weakly labeled data and a small, high-quality annotated dataset.
Our approach achieves state-of-the-art results, ranking first in the
multi-dialectal Arabic ASR challenge. These findings highlight the
effectiveness of weak supervision paired with fine-tuning in overcoming data
scarcity and delivering high-quality ASR for low-resource, dialect-rich
languages.

</details>


### [159] [Reveal-Bangla: A Dataset for Cross-Lingual Multi-Step Reasoning Evaluation](https://arxiv.org/abs/2508.08933)
*Khondoker Ittehadul Islam,Gabriele Sarti*

Main category: cs.CL

TL;DR: 该研究评估了多语言小型语言模型在孟加拉语多步推理任务上的表现，发现推理上下文对更复杂的非二元问题有益，但模型难以有效利用孟加拉语推理步骤。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型在复杂多步推理任务上的评估主要集中在高资源语言（如英语），而对其他语言（特别是低资源语言）的评估不足。

Method: 研究构建了一个人工翻译的孟加拉语多步推理数据集（源自英文Reveal数据集，包含二元和非二元问题），并在此数据集和原始英文数据集上，对以英语为中心和以孟加拉语为中心的多语言小型语言模型进行了受控评估。

Result: 在可比较的设置下，推理上下文对更具挑战性的非二元问题是有益的。然而，模型在有效利用相关的孟加拉语推理步骤方面存在困难。

Conclusion: 推理上下文对非二元问题有益，但当前模型在孟加拉语推理步骤的利用上表现不佳。研究还揭示了推理步骤对模型预测的贡献在不同模型和语言之间存在差异。

Abstract: Language models have demonstrated remarkable performance on complex
multi-step reasoning tasks. However, their evaluation has been predominantly
confined to high-resource languages such as English. In this paper, we
introduce a manually translated Bangla multi-step reasoning dataset derived
from the English Reveal dataset, featuring both binary and non-binary question
types. We conduct a controlled evaluation of English-centric and Bangla-centric
multilingual small language models on the original dataset and our translated
version to compare their ability to exploit relevant reasoning steps to produce
correct answers. Our results show that, in comparable settings, reasoning
context is beneficial for more challenging non-binary questions, but models
struggle to employ relevant Bangla reasoning steps effectively. We conclude by
exploring how reasoning steps contribute to models' predictions, highlighting
different trends across models and languages.

</details>


### [160] [Train Long, Think Short: Curriculum Learning for Efficient Reasoning](https://arxiv.org/abs/2508.08940)
*Hasan Abed Al Kader Hammoud,Kumail Alhamoud,Abed Hammoud,Elie Bou-Zeid,Marzyeh Ghassemi,Bernard Ghanem*

Main category: cs.CL

TL;DR: 本文提出一种基于课程学习的GRPO（Group Relative Policy Optimization）方法，用于控制大型语言模型（LLMs）的推理长度。通过在训练过程中逐步收紧token预算，该方法能有效提高LLM在数学推理任务上的准确性和token效率，优于固定预算的基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理的长度控制方法依赖于固定长度的训练预算，这未能充分利用学习过程中从探索到压缩的自然演进，导致在控制计算成本的同时保持准确性方面存在局限性。

Method: 作者提出一种基于GRPO的课程学习策略。训练初期，模型被给予宽松的token预算，鼓励其探索有效的解决方案；随后预算逐渐收紧，促使模型将解决方案提炼为更简洁的推理轨迹。此外，GRPO通过一个奖励函数进行增强，该函数平衡了三个信号：任务正确性（通过验证器反馈）、长度效率和格式依从性（通过结构化标签）。

Result: 在GSM8K、MATH500、SVAMP、College Math和GSM+等数据集上的实验表明，在相同的最终预算下，基于课程学习的训练方法始终优于固定预算的基线方法，实现了更高的准确性和显著提升的token效率。研究还探讨了奖励权重和衰减策略设计的影响。

Conclusion: 渐进式约束（即课程学习）是训练高效推理模型的一种强大归纳偏置。

Abstract: Recent work on enhancing the reasoning abilities of large language models
(LLMs) has introduced explicit length control as a means of constraining
computational cost while preserving accuracy. However, existing approaches rely
on fixed-length training budgets, which do not take advantage of the natural
progression from exploration to compression during learning. In this work, we
propose a curriculum learning strategy for length-controlled reasoning using
Group Relative Policy Optimization (GRPO). Our method starts with generous
token budgets and gradually tightens them over training, encouraging models to
first discover effective solution strategies and then distill them into more
concise reasoning traces. We augment GRPO with a reward function that balances
three signals: task correctness (via verifier feedback), length efficiency, and
formatting adherence (via structural tags). Experiments on GSM8K, MATH500,
SVAMP, College Math, and GSM+ demonstrate that curriculum-based training
consistently outperforms fixed-budget baselines at the same final budget,
achieving higher accuracy and significantly improved token efficiency. We
further ablate the impact of reward weighting and decay schedule design,
showing that progressive constraint serves as a powerful inductive bias for
training efficient reasoning models. Our code and checkpoints are released at:
https://github.com/hammoudhasan/curriculum_grpo.

</details>


### [161] [Jointly Generating and Attributing Answers using Logits of Document-Identifier Tokens](https://arxiv.org/abs/2508.08942)
*Lucas Albarede,Jose Moreno,Lynda Tamine,Luce Lefeuvre*

Main category: cs.CL

TL;DR: LoDIT是一种新方法，通过在生成过程中利用特定token的logits，在RAG中同时生成答案并进行可信归因，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）表现出色，但其幻觉问题严重损害了可信度。现有归因方法侧重于答案和归因的正确性，或利用模型内部信号反映决策过程，但存在额外延迟且难以直接对齐token生成与归因生成。

Method: LoDIT方法分为两步：1) 使用特定token标识符标记文档，并在生成答案时利用这些token的logits来估计每个文档对答案的贡献；2) 将这些贡献聚合为文档归因。

Result: 在Trust-Align可信度归因文本生成基准测试中，LoDIT在多项指标上显著优于现有最先进模型。此外，LoDIT在延迟方面表现出高效率，并在不同设置下展现出鲁棒性。

Conclusion: LoDIT通过在生成过程中联合生成答案和进行可信归因，有效解决了LLM的幻觉问题，并在性能、效率和鲁棒性方面均表现出色。

Abstract: Despite their impressive performances, Large Language Models (LLMs) remain
prone to hallucination, which critically undermines their trustworthiness.
While most of the previous work focused on tackling answer and attribution
correctness, a recent line of work investigated faithfulness, with a focus on
leveraging internal model signals to reflect a model's actual decision-making
process while generating the answer. Nevertheless, these methods induce
additional latency and have shown limitations in directly aligning token
generation with attribution generation. In this paper, we introduce LoDIT, a
method that jointly generates and faithfully attributes answers in RAG by
leveraging specific token logits during generation. It consists of two steps:
(1) marking the documents with specific token identifiers and then leveraging
the logits of these tokens to estimate the contribution of each document to the
answer during generation, and (2) aggregating these contributions into document
attributions. Experiments on a trustworthiness-focused attributed
text-generation benchmark, Trust-Align, show that LoDIT significantly
outperforms state-of-the-art models on several metrics. Finally, an in-depth
analysis of LoDIT shows both its efficiency in terms of latency and its
robustness in different settings.

</details>


### [162] [Retrospective Sparse Attention for Efficient Long-Context Generation](https://arxiv.org/abs/2508.09001)
*Seonghwan Choi,Beomseok Kang,Dongwon Jo,Jae-Joon Kim*

Main category: cs.CL

TL;DR: RetroAttention是一种新的KV缓存更新技术，通过回顾性修正过去的注意力输出，显著提高了长文本生成任务中LLM的性能和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在长上下文任务中面临KV缓存瓶颈，其内存占用随序列长度线性增长，并在解码步骤中导致延迟。现有KV缓存压缩方法主要关注输入上下文，未能解决长解码过程中累积的注意力错误。

Method: 本文提出了RetroAttention，一种新颖的KV缓存更新技术。它通过利用后续解码步骤中新到达的KV条目，回顾性地修订过去的注意力输出。通过维护一个轻量级的输出缓存，RetroAttention使过去的查询能够有效地访问更相关的上下文，同时引入最小的延迟开销。这打破了固定注意力输出的范式，并允许持续修正先前的近似值。

Result: 在长文本生成基准测试上的广泛实验表明，RetroAttention始终优于最先进的（SOTA）KV压缩方法，将有效KV暴露度提高了1.6倍，准确性提高了21.9%。

Conclusion: RetroAttention通过允许对过去注意力输出进行持续修正，有效解决了长解码中的累积注意力错误，显著提升了LLMs在长上下文生成任务中的性能和准确性。

Abstract: Large Language Models (LLMs) are increasingly deployed in long-context tasks
such as reasoning, code generation, and multi-turn dialogue. However, inference
over extended contexts is bottlenecked by the Key-Value (KV) cache, whose
memory footprint grows linearly with sequence length and dominates latency at
each decoding step. While recent KV cache compression methods identify and load
important tokens, they focus predominantly on input contexts and fail to
address the cumulative attention errors that arise during long decoding. In
this paper, we introduce RetroAttention, a novel KV cache update technique that
retrospectively revises past attention outputs using newly arrived KV entries
from subsequent decoding steps. By maintaining a lightweight output cache,
RetroAttention enables past queries to efficiently access more relevant
context, while incurring minimal latency overhead. This breaks the
fixed-attention-output paradigm and allows continual correction of prior
approximations. Extensive experiments on long-generation benchmarks show that
RetroAttention consistently outperforms state-of-the-art (SOTA) KV compression
methods, increasing effective KV exposure by up to 1.6$\times$ and accuracy by
up to 21.9\%.

</details>


### [163] [LyS at SemEval 2025 Task 8: Zero-Shot Code Generation for Tabular QA](https://arxiv.org/abs/2508.09012)
*Adrián Gude,Roi Santos-Ríos,Francisco Prado-Valiño,Ana Ezquerro,Jesús Vilares*

Main category: cs.CL

TL;DR: 本文描述了在SemEval 2025任务8（表格问答）中，通过零样本LLM生成代码来提取表格信息的方法，并在没有特定任务微调的情况下取得了中等排名。


<details>
  <summary>Details</summary>
Motivation: 参与SemEval 2025任务8（表格问答），旨在探索大型语言模型在零样本设置下解决表格问答的能力。

Method: 开发了一个零样本流水线，利用大型语言模型生成功能代码，从表格数据中提取信息。该方法包括一个主代码生成模块，并辅以识别相关列和分析数据类型的组件，以提高准确性。若生成代码失败，会触发迭代细化过程，将错误反馈融入新的生成提示中以增强鲁棒性。

Result: 在测试阶段，该方法在53支队伍中排名第33位，表明零样本代码生成是表格问答的有效方法，尽管缺乏任务特定的微调。

Conclusion: 零样本代码生成是解决表格问答问题的一种有效且具有鲁棒性的方法。

Abstract: This paper describes our participation in SemEval 2025 Task 8, focused on
Tabular Question Answering. We developed a zero-shot pipeline that leverages an
Large Language Model to generate functional code capable of extracting the
relevant information from tabular data based on an input question. Our approach
consists of a modular pipeline where the main code generator module is
supported by additional components that identify the most relevant columns and
analyze their data types to improve extraction accuracy. In the event that the
generated code fails, an iterative refinement process is triggered,
incorporating the error feedback into a new generation prompt to enhance
robustness. Our results show that zero-shot code generation is a valid approach
for Tabular QA, achieving rank 33 of 53 in the test phase despite the lack of
task-specific fine-tuning.

</details>


### [164] [A Survey on Training-free Alignment of Large Language Models](https://arxiv.org/abs/2508.09016)
*Birong Pan,Yongqi Li,Weiyu Zhang,Wenpeng Lu,Mayi Xu,Shen Zhou,Yuanyuan Zhu,Ming Zhong,Tieyun Qian*

Main category: cs.CL

TL;DR: 本文首次系统综述了大型语言模型（LLMs）和多模态LLMs（MLLMs）的免训练（TF）对齐方法，按预解码、解码中和后解码阶段进行分类，并探讨了其机制、局限性、挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 传统LLMs对齐方法（如微调）资源消耗大、可能导致知识退化，且在模型可访问性或计算资源受限时面临挑战。免训练对齐技术提供了一种无需大量再训练即可实现对齐的替代方案，适用于开源和闭源环境。

Method: 本文对免训练对齐方法进行了首次系统综述，将其分为预解码、解码中和后解码三个阶段。针对每个阶段，从LLMs和MLLMs的角度详细检查了其机制和局限性。此外，还识别了关键挑战和未来发展方向。

Result: 本文提供了首个关于免训练对齐方法的系统综述，成功将其按阶段分类，并详细阐述了各类方法在LLMs和MLLMs中的机制与局限性。同时，明确了该领域面临的主要挑战和未来的研究方向。

Conclusion: 免训练对齐技术是实现更安全、更可靠LLMs的重要途径。本综述通过系统梳理和组织现有研究，为实践者提供了指导，并推动了TF对齐技术的发展。

Abstract: The alignment of large language models (LLMs) aims to ensure their outputs
adhere to human values, ethical standards, and legal norms. Traditional
alignment methods often rely on resource-intensive fine-tuning (FT), which may
suffer from knowledge degradation and face challenges in scenarios where the
model accessibility or computational resources are constrained. In contrast,
training-free (TF) alignment techniques--leveraging in-context learning,
decoding-time adjustments, and post-generation corrections--offer a promising
alternative by enabling alignment without heavily retraining LLMs, making them
adaptable to both open-source and closed-source environments. This paper
presents the first systematic review of TF alignment methods, categorizing them
by stages of pre-decoding, in-decoding, and post-decoding. For each stage, we
provide a detailed examination from the viewpoint of LLMs and multimodal LLMs
(MLLMs), highlighting their mechanisms and limitations. Furthermore, we
identify key challenges and future directions, paving the way for more
inclusive and effective TF alignment techniques. By synthesizing and organizing
the rapidly growing body of research, this survey offers a guidance for
practitioners and advances the development of safer and more reliable LLMs.

</details>


### [165] [LLM-as-a-Supervisor: Mistaken Therapeutic Behaviors Trigger Targeted Supervisory Feedback](https://arxiv.org/abs/2508.09042)
*Chen Xu,Zhenyu Lv,Tian Lan,Xianyang Wang,Luyao Ji,Leyang Cui,Minqiang Yang,Jian Shen,Qunxi Dong,Xiuling Liu,Juan Wang,Bin Hu*

Main category: cs.CL

TL;DR: 该研究开发了一种新颖的范式，利用大型语言模型（LLM）作为导师，通过识别常见的治疗错误并提供有针对性的反馈来训练真实的治疗师。


<details>
  <summary>Details</summary>
Motivation: 直接将LLM应用于患者治疗存在伦理和安全问题。此外，治疗师培训需要明确的反馈标准，但治疗行为缺乏绝对的“黄金标准”。然而，常见的治疗错误是普遍且可识别的，这为有针对性的反馈提供了基础。

Method: 1. 建立错误行为指南和纠正策略作为标准；2. 构建一个“人机协同”的对话反馈数据集，其中一个易犯错的代理故意制造标准错误，一个主管代理定位并识别错误，提供有针对性的反馈；3. 在此数据集（MATE）上微调，得到最终的主管模型，用于真实治疗师的培训。

Result: 自动化、人工和下游评估的详细实验结果表明，在MATE数据集上微调的模型能够根据临床指南提供高质量的反馈。

Conclusion: 该研究提出的LLM主管模型在治疗师培训场景中显示出巨大的潜力，尤其是在缺乏“黄金标准”但常见错误可识别的背景下。

Abstract: Although large language models (LLMs) hold significant promise in
psychotherapy, their direct application in patient-facing scenarios raises
ethical and safety concerns. Therefore, this work shifts towards developing an
LLM as a supervisor to train real therapists. In addition to the privacy of
clinical therapist training data, a fundamental contradiction complicates the
training of therapeutic behaviors: clear feedback standards are necessary to
ensure a controlled training system, yet there is no absolute "gold standard"
for appropriate therapeutic behaviors in practice. In contrast, many common
therapeutic mistakes are universal and identifiable, making them effective
triggers for targeted feedback that can serve as clearer evidence. Motivated by
this, we create a novel therapist-training paradigm: (1) guidelines for
mistaken behaviors and targeted correction strategies are first established as
standards; (2) a human-in-the-loop dialogue-feedback dataset is then
constructed, where a mistake-prone agent intentionally makes standard mistakes
during interviews naturally, and a supervisor agent locates and identifies
mistakes and provides targeted feedback; (3) after fine-tuning on this dataset,
the final supervisor model is provided for real therapist training. The
detailed experimental results of automated, human and downstream assessments
demonstrate that models fine-tuned on our dataset MATE, can provide
high-quality feedback according to the clinical guideline, showing significant
potential for the therapist training scenario.

</details>


### [166] [Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models](https://arxiv.org/abs/2508.09138)
*Wen Wang,Bozhen Fang,Chenchen Jing,Yongliang Shen,Yangyi Shen,Qiuyu Wang,Hao Ouyang,Hao Chen,Chunhua Shen*

Main category: cs.CL

TL;DR: 该研究揭示了扩散大语言模型（dLLMs）在去噪过程中存在“时间振荡”现象，即正确答案可能在中途出现但随后被覆盖。为解决此问题，论文提出了两种利用时间一致性的方法：时间自一致性投票（TSC-Voting）和时间一致性强化（TCR），显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前的扩散大语言模型解码策略会丢弃丰富的中间预测结果，且存在“时间振荡”现象，导致正确答案在后期去噪步骤中被覆盖，未能充分利用中间过程信息。

Method: 1. 时间自一致性投票（TSC-Voting）：一种无需训练的测试时解码策略，通过聚合去噪步骤中的预测结果来选择最一致的输出。2. 时间一致性强化（TCR）：一种后训练方法，利用时间语义熵（TSE）作为奖励信号，以鼓励生成更稳定的文本。

Result: 单独使用负TSE奖励，在Countdown数据集上比现有dLLM平均提高了24.7%。结合准确性奖励，在GSM8K、MATH500、SVAMP和Countdown数据集上分别实现了2.0%、4.3%、6.6%和25.3%的绝对增益。

Conclusion: 扩散大语言模型中的时间动态具有未被开发的潜力。论文提出的时间自一致性投票和时间一致性强化是利用这些时间动态的简单而有效的方法，能够显著提高模型性能。

Abstract: Diffusion large language models (dLLMs) generate text through iterative
denoising, yet current decoding strategies discard rich intermediate
predictions in favor of the final output. Our work here reveals a critical
phenomenon, temporal oscillation, where correct answers often emerge in the
middle process, but are overwritten in later denoising steps. To address this
issue, we introduce two complementary methods that exploit temporal
consistency: 1) Temporal Self-Consistency Voting, a training-free, test-time
decoding strategy that aggregates predictions across denoising steps to select
the most consistent output; and 2) a post-training method termed Temporal
Consistency Reinforcement, which uses Temporal Semantic Entropy (TSE), a
measure of semantic stability across intermediate predictions, as a reward
signal to encourage stable generations. Empirical results across multiple
benchmarks demonstrate the effectiveness of our approach. Using the negative
TSE reward alone, we observe a remarkable average improvement of 24.7% on the
Countdown dataset over an existing dLLM. Combined with the accuracy reward, we
achieve absolute gains of 2.0% on GSM8K, 4.3% on MATH500, 6.6% on SVAMP, and
25.3% on Countdown, respectively. Our findings underscore the untapped
potential of temporal dynamics in dLLMs and offer two simple yet effective
tools to harness them.

</details>


### [167] [MVISU-Bench: Benchmarking Mobile Agents for Real-World Tasks by Multi-App, Vague, Interactive, Single-App and Unethical Instructions](https://arxiv.org/abs/2508.09057)
*Zeyu Huang,Juyuan Wang,Longfeng Chen,Boyi Xiao,Leng Cai,Yawen Zeng,Jin Xu*

Main category: cs.CL

TL;DR: 该论文提出了MVISU-Bench，一个双语基准测试，用于评估移动智能体在真实世界复杂用户场景下的表现，并引入了Aider模块，一个动态提示器，显著提升了移动智能体的任务成功率。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型（LVLMs）在推理和视觉理解方面取得显著进展，但现有评估基准与现实世界脱节，未能充分解决用户多样化和复杂的需求，特别是对于移动智能体。

Method: 通过广泛收集用户问卷，识别出五种核心任务类型：多应用、模糊、交互式、单应用和不道德指令。围绕这些任务，构建了MVISU-Bench，包含137个移动应用上的404个任务。此外，提出了Aider，一个即插即用的模块，作为动态提示器，用于降低风险和澄清用户意图。

Result: MVISU-Bench是一个包含404个任务和137个移动应用的双语基准测试。Aider模块易于集成，相比现有最先进技术，在MVISU-Bench上将整体成功率提高了19.55%。特别地，对于不道德指令和交互式指令，成功率分别提高了53.52%和29.41%。

Conclusion: 现有移动智能体与真实世界用户期望之间存在显著差距。MVISU-Bench为更真实的评估提供了工具，而Aider模块则有效提升了移动智能体处理复杂和特定类型指令（如不道德和交互式指令）的能力，有助于弥合这一差距。

Abstract: Given the significant advances in Large Vision Language Models (LVLMs) in
reasoning and visual understanding, mobile agents are rapidly emerging to meet
users' automation needs. However, existing evaluation benchmarks are
disconnected from the real world and fail to adequately address the diverse and
complex requirements of users. From our extensive collection of user
questionnaire, we identified five tasks: Multi-App, Vague, Interactive,
Single-App, and Unethical Instructions. Around these tasks, we present
\textbf{MVISU-Bench}, a bilingual benchmark that includes 404 tasks across 137
mobile applications. Furthermore, we propose Aider, a plug-and-play module that
acts as a dynamic prompt prompter to mitigate risks and clarify user intent for
mobile agents. Our Aider is easy to integrate into several frameworks and has
successfully improved overall success rates by 19.55\% compared to the current
state-of-the-art (SOTA) on MVISU-Bench. Specifically, it achieves success rate
improvements of 53.52\% and 29.41\% for unethical and interactive instructions,
respectively. Through extensive experiments and analysis, we highlight the gap
between existing mobile agents and real-world user expectations.

</details>


### [168] [READER: Retrieval-Assisted Drafter for Efficient LLM Inference](https://arxiv.org/abs/2508.09072)
*Maxim Divilkovskiy,Vitaly Malygin,Sergey Zlobin,Sultan Isali,Vasily Kalugin,Stanislav Ilyushin,Nuriza Aitassova,Yi Fei,Zeng Weidi*

Main category: cs.CL

TL;DR: 本文提出READER，一种新颖的无损推测解码方法，通过利用文本中的自重复和统计搜索来加速大型语言模型（LLMs）的推理，特别是在大批量处理时，无需额外训练即可显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: LLM的自回归生成特性导致推理速度慢，难以高效部署。现有加速方法通常需要训练额外的草稿模型。此外，大批量推理（>=8）在工业应用中很重要，但研究不足。

Method: 引入READER（Retrieval-Assisted Drafter for Efficient LLM Inference），一种无损推测解码方法。该方法通过统计搜索获得的token扩展推测解码树，利用文本中的自重复来增强基于模型的加速方法。同时，分析并优化了推测解码过程中键值（KV）缓存的大小，以提高大批量处理的性能。

Result: READER在性能上超越了现有推测解码方法。它无需额外训练，可重用预训练的推测器模型，将加速比提高了40%以上。在检索增强生成等搜索型任务上，READER表现尤为出色，实现了超过10倍的加速。

Conclusion: READER是一种高效、无需额外训练的LLM推测解码方法，通过利用文本自重复和统计搜索，显著加速了LLM推理，尤其适用于大批量处理和搜索型任务，性能优于现有方法。

Abstract: Large Language Models (LLMs) generate tokens autoregressively, with each
token depending on the preceding context. This sequential nature makes the
inference process inherently difficult to accelerate, posing a significant
challenge for efficient deployment. In recent years, various methods have been
proposed to address this issue, with the most effective approaches often
involving the training of additional draft models. In this paper, we introduce
READER (Retrieval-Assisted Drafter for Efficient LLM Inference), a novel
lossless speculative decoding method that enhances model-based approaches by
leveraging self-repetitions in the text. Our algorithm expands the speculative
decoding tree using tokens obtained through statistical search. This work
focuses on large batch sizes (>= 8), an underexplored yet important area for
industrial applications. We also analyze the key-value (KV) cache size during
speculative decoding and propose an optimization to improve performance for
large batches. As a result, READER outperforms existing speculative decoding
methods. Notably, READER requires no additional training and can reuse
pre-trained speculator models, increasing the speedup by over 40\%. Our method
demonstrates particularly strong performance on search-based tasks, such as
retrieval-augmented generation, where we achieve more than 10x speedup.

</details>


### [169] [CPO: Addressing Reward Ambiguity in Role-playing Dialogue via Comparative Policy Optimization](https://arxiv.org/abs/2508.09074)
*Xinge Ye,Rui Wang,Yuchuan Wu,Victor Ma,Feiteng Fang,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 针对RLFT在主观任务上的挑战，本文提出CPO通过比较式群体评分优化奖励信号，并引入CharacterArena框架进行轨迹级比较评估，显著提升了对话质量。


<details>
  <summary>Details</summary>
Motivation: 强化学习微调（RLFT）在客观任务上表现出色，但在开放式主观任务（如角色扮演对话）上表现不佳。传统奖励建模依赖独立样本评分，面临主观评价标准和不稳定奖励信号的双重挑战。受人类评估结合显式标准和隐式比较判断的启发，本文旨在解决这些问题。

Method: 提出比较式策略优化（CPO），将奖励评估范式从样本级评分转变为比较式群体级评分。在此基础上，引入CharacterArena评估框架，包含两个阶段：1) 上下文多轮角色扮演模拟，2) 轨迹级比较评估。通过客观的轨迹比较来操作主观评分，以最小化上下文偏差并实现更稳健和公平的性能评估。

Result: 在CharacterEval、CharacterBench和CharacterArena上的实证结果证实，CPO有效缓解了奖励模糊性，并显著提高了对话质量。

Conclusion: CPO和CharacterArena通过引入比较式评估方法，成功解决了RLFT在主观开放式对话任务中奖励信号不稳定和评估困难的问题，从而显著提升了对话质量。

Abstract: Reinforcement Learning Fine-Tuning (RLFT) has achieved notable success in
tasks with objectively verifiable answers (e.g., code generation, mathematical
reasoning), yet struggles with open-ended subjective tasks like role-playing
dialogue. Traditional reward modeling approaches, which rely on independent
sample-wise scoring, face dual challenges: subjective evaluation criteria and
unstable reward signals.Motivated by the insight that human evaluation
inherently combines explicit criteria with implicit comparative judgments, we
propose Comparative Policy Optimization (CPO). CPO redefines the reward
evaluation paradigm by shifting from sample-wise scoring to comparative
group-wise scoring.Building on the same principle, we introduce the
CharacterArena evaluation framework, which comprises two stages:(1)
Contextualized Multi-turn Role-playing Simulation, and (2) Trajectory-level
Comparative Evaluation. By operationalizing subjective scoring via objective
trajectory comparisons, CharacterArena minimizes contextual bias and enables
more robust and fair performance evaluation. Empirical results on
CharacterEval, CharacterBench, and CharacterArena confirm that CPO effectively
mitigates reward ambiguity and leads to substantial improvements in dialogue
quality.

</details>


### [170] [Utilizing Multilingual Encoders to Improve Large Language Models for Low-Resource Languages](https://arxiv.org/abs/2508.09091)
*Imalsha Puranegedara,Themira Chathumina,Nisal Ranathunga,Nisansa de Silva,Surangika Ranathunga,Mokanarangan Thayaparan*

Main category: cs.CL

TL;DR: 该研究提出了一种新颖的架构，通过融合多语言编码器（如mT5）的所有中间层，而非仅最后一层，来增强LLMs在低资源语言上的性能，且仅需英文数据训练。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在英语表现出色，但在低资源语言（LRLs）上的性能显著下降，原因在于其以英语为中心的训练。现有方法（如LangBridge）通常只使用多语言编码器的最后一层，未能充分利用语言信息。

Method: 提出了一种新颖的架构，融合多语言编码器（如mT5）的所有中间层，以丰富传递给LLM的语言信息。采用两种策略：1) 全局Softmax加权，用于评估整体层的重要性；2) Transformer Softmax模型，学习特定于token的权重。融合后的表示被映射到LLM的嵌入空间。模型仅使用英文数据训练，无需并行或多语言数据。

Result: 在XNLI、IndicXNLI、僧伽罗语新闻分类和亚马逊评论数据集上进行评估，Transformer Softmax模型显著优于LangBridge基线。在LRLs中表现出强劲的性能提升，例如僧伽罗语分类准确率从71.66%提高到75.86%，并在泰米尔语、孟加拉语和马拉雅拉姆语等印度语言中取得了明显改善。XNLI平均准确率从70.36%提升至71.50%。

Conclusion: 该方法提供了一种可扩展、数据高效的途径，以构建更强大、更公平的多语言LLMs。

Abstract: Large Language Models (LLMs) excel in English, but their performance degrades
significantly on low-resource languages (LRLs) due to English-centric training.
While methods like LangBridge align LLMs with multilingual encoders such as the
Massively Multilingual Text-to-Text Transfer Transformer (mT5), they typically
use only the final encoder layer. We propose a novel architecture that fuses
all intermediate layers, enriching the linguistic information passed to the
LLM. Our approach features two strategies: (1) a Global Softmax weighting for
overall layer importance, and (2) a Transformer Softmax model that learns
token-specific weights. The fused representations are mapped into the LLM's
embedding space, enabling it to process multilingual inputs. The model is
trained only on English data, without using any parallel or multilingual data.
Evaluated on XNLI, IndicXNLI, Sinhala News Classification, and Amazon Reviews,
our Transformer Softmax model significantly outperforms the LangBridge
baseline. We observe strong performance gains in LRLs, improving Sinhala
classification accuracy from 71.66% to 75.86% and achieving clear improvements
across Indic languages such as Tamil, Bengali, and Malayalam. These specific
gains contribute to an overall boost in average XNLI accuracy from 70.36% to
71.50%. This approach offers a scalable, data-efficient path toward more
capable and equitable multilingual LLMs.

</details>


### [171] [Link Prediction for Event Logs in the Process Industry](https://arxiv.org/abs/2508.09096)
*Anastasia Zhukova,Thomas Walton,Christian E. Matt,Bela Gipp*

Main category: cs.CL

TL;DR: 该研究针对流程工业中班次日志事件记录碎片化的问题，提出了一种结合自然语言推理（NLI）和语义文本相似度（STS）的跨文档共指消解（CDCR）模型，以实现记录链接，从而提升数据质量和连接性。


<details>
  <summary>Details</summary>
Motivation: 在流程工业中，知识管理对于优化运营、确保安全和持续改进至关重要。然而，班次日志中的事件记录常常是碎片化的，导致相关记录（如设备/过程问题及其解决方案）相互分离，从而阻碍了向用户推荐历史解决方案。

Method: 将记录链接（RL）问题框定为图机器学习中常见的链接预测问题，并进一步将其视为通过自然语言推理（NLI）和语义文本相似度（STS）增强的跨文档共指消解（CDCR）任务，并引入因果推断（CI）的视角。作者将传统应用于新闻领域的CDCR模型进行领域适应，使其能在段落级别操作，并能处理流程工业特有的非结构化文本和结构化记录属性。

Result: 所提出的记录链接（RL）模型在性能上优于NLI和STS驱动的最佳基线模型，分别高出28%（11.43点）和27%（11.21点）。

Conclusion: 研究表明，通过领域适应并增强推理能力的最先进CDCR模型，可以有效地应用于流程工业，显著改善班次日志中的数据质量和连接性。

Abstract: Knowledge management (KM) is vital in the process industry for optimizing
operations, ensuring safety, and enabling continuous improvement through
effective use of operational data and past insights. A key challenge in this
domain is the fragmented nature of event logs in shift books, where related
records, e.g., entries documenting issues related to equipment or processes and
the corresponding solutions, may remain disconnected. This fragmentation
hinders the recommendation of previous solutions to the users. To address this
problem, we investigate record linking (RL) as link prediction, commonly
studied in graph-based machine learning, by framing it as a cross-document
coreference resolution (CDCR) task enhanced with natural language inference
(NLI) and semantic text similarity (STS) by shifting it into the causal
inference (CI). We adapt CDCR, traditionally applied in the news domain, into
an RL model to operate at the passage level, similar to NLI and STS, while
accommodating the process industry's specific text formats, which contain
unstructured text and structured record attributes. Our RL model outperformed
the best versions of NLI- and STS-driven baselines by 28% (11.43 points) and
27% (11.21 points), respectively. Our work demonstrates how domain adaptation
of the state-of-the-art CDCR models, enhanced with reasoning capabilities, can
be effectively tailored to the process industry, improving data quality and
connectivity in shift logs.

</details>


### [172] [AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators](https://arxiv.org/abs/2508.09101)
*Jason Chou,Ao Liu,Yuchi Deng,Zhiying Zeng,Tao Zhang,Haotian Zhu,Jianwei Cai,Yue Mao,Chenchen Zhang,Lingyun Tan,Ziyan Xu,Bohui Zhai,Hengyi Liu,Speed Zhu,Wiggin Zhou,Fengzong Lian*

Main category: cs.CL

TL;DR: 本文提出AutoCodeGen，一种自动化方法，用于生成高难度、无手动标注的多语言代码生成数据集。基于此方法，构建了AutoCodeBench系列基准，并评估发现即使最先进的大语言模型在复杂多语言代码生成任务上仍表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成基准面临多项挑战：过度依赖手动标注导致耗时且难以扩展；主要关注Python语言，缺乏多语言支持；少数多语言基准存在难度有限和语言分布不均的问题。

Method: 提出AutoCodeGen自动化方法，无需手动标注即可生成高难度多语言代码生成数据集。该方法通过大语言模型生成测试输入，利用多语言沙箱获取测试输出，并通过逆序问题生成和多重过滤步骤确保测试用例的正确性、完整性和数据质量。

Result: 基于AutoCodeGen，构建了大规模代码生成基准AutoCodeBench，包含3,920个问题，均匀分布于20种编程语言，旨在评估大语言模型在挑战性、多样化和实用多语言任务上的表现。对30多个领先的开源和专有大语言模型进行评估，结果显示即使最先进的模型也难以应对这些任务的复杂性、多样性和多语言特性。此外，还引入了AutoCodeBench-Lite和AutoCodeBench-Complete用于不同场景的评估。

Conclusion: AutoCodeBench系列基准是评估大语言模型在多语言代码生成能力方面的宝贵资源，有望激励社区关注更具挑战性和实用性的多语言代码生成场景。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
various domains, with code generation emerging as a key area of focus. While
numerous benchmarks have been proposed to evaluate their code generation
abilities, these benchmarks face several critical limitations. First, they
often rely on manual annotations, which are time-consuming and difficult to
scale across different programming languages and problem complexities. Second,
most existing benchmarks focus primarily on Python, while the few multilingual
benchmarks suffer from limited difficulty and uneven language distribution. To
address these challenges, we propose AutoCodeGen, an automated method for
generating high-difficulty multilingual code generation datasets without manual
annotations. AutoCodeGen ensures the correctness and completeness of test cases
by generating test inputs with LLMs and obtaining test outputs through a
multilingual sandbox, while achieving high data quality through reverse-order
problem generation and multiple filtering steps. Using this novel method, we
introduce AutoCodeBench, a large-scale code generation benchmark comprising
3,920 problems evenly distributed across 20 programming languages. It is
specifically designed to evaluate LLMs on challenging, diverse, and practical
multilingual tasks. We evaluate over 30 leading open-source and proprietary
LLMs on AutoCodeBench and its simplified version AutoCodeBench-Lite. The
results show that even the most advanced LLMs struggle with the complexity,
diversity, and multilingual nature of these tasks. Besides, we introduce
AutoCodeBench-Complete, specifically designed for base models to assess their
few-shot code generation capabilities. We hope the AutoCodeBench series will
serve as a valuable resource and inspire the community to focus on more
challenging and practical multilingual code generation scenarios.

</details>


### [173] [SinLlama -- A Large Language Model for Sinhala](https://arxiv.org/abs/2508.09115)
*H. W. K. Aravinda,Rashad Sirajudeen,Samith Karunathilake,Nisansa de Silva,Surangika Ranathunga,Rishemjit Kaur*

Main category: cs.CL

TL;DR: 通过词汇扩展和持续预训练，将Llama-3-8B模型适配斯里兰卡僧伽罗语，创建了首个支持僧伽罗语的开源解码器LLM（SinLlama），并在文本分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开源大型语言模型（LLMs）通常忽视像僧伽罗语这样的低资源语言。

Method: 扩展现有Llama-3-8B的多语言LLM，增强其分词器以包含僧伽罗语特定词汇，并在一个1000万词的清洗过的僧伽罗语语料库上进行持续预训练，从而得到SinLlama模型。随后对SinLlama进行指令微调，用于三个文本分类任务。

Result: SinLlama是首个明确支持僧伽罗语的开源解码器LLM。在三个文本分类任务中，经过指令微调的SinLlama显著优于Llama-3-8B的基础版和指令微调版。

Conclusion: 通过词汇增强和持续预训练的方法，可以有效地将现有LLM扩展并优化，使其更好地服务于低资源语言，如僧伽罗语。

Abstract: Low-resource languages such as Sinhala are often overlooked by open-source
Large Language Models (LLMs). In this research, we extend an existing
multilingual LLM (Llama-3-8B) to better serve Sinhala. We enhance the LLM
tokenizer with Sinhala specific vocabulary and perform continual pre-training
on a cleaned 10 million Sinhala corpus, resulting in the SinLlama model. This
is the very first decoder-based open-source LLM with explicit Sinhala support.
When SinLlama was instruction fine-tuned for three text classification tasks,
it outperformed base and instruct variants of Llama-3-8B by a significant
margin.

</details>


### [174] [OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows](https://arxiv.org/abs/2508.09124)
*Weixuan Wang,Dongge Han,Daniel Madrigal Diaz,Jin Xu,Victor Rühle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 本文介绍了OdysseyBench，一个用于评估LLM代理在复杂、长周期办公应用（如Word、Excel、PDF、邮件、日历）工作流中表现的综合基准，并提出了HomerAgents框架自动化基准生成。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注独立的原子任务，未能捕捉真实场景中所需的长期上下文依赖和多交互协调，无法准确评估LLM代理在复杂、长周期工作流中的能力。

Method: 提出了OdysseyBench基准，包含OdysseyBench+（300个真实用例任务）和OdysseyBench-Neo（302个新合成复杂任务）两个互补部分，每个任务都需要代理识别长期交互历史中的关键信息并进行多步骤跨应用推理。为实现可扩展的基准创建，提出了HomerAgents，一个通过系统环境探索、任务生成和对话合成来自动化生成长周期工作流基准的多代理框架。

Result: 广泛的评估表明，OdysseyBench能够有效挑战最先进的LLM代理，与现有原子任务基准相比，能更准确地评估其在复杂真实世界环境中的能力。

Conclusion: OdysseyBench将成为推动LLM代理在真实世界生产力场景中发展和评估的宝贵资源。作者同时发布了OdysseyBench和HomerAgents以促进相关研究。

Abstract: Autonomous agents powered by large language models (LLMs) are increasingly
deployed in real-world applications requiring complex, long-horizon workflows.
However, existing benchmarks predominantly focus on atomic tasks that are
self-contained and independent, failing to capture the long-term contextual
dependencies and multi-interaction coordination required in realistic
scenarios. To address this gap, we introduce OdysseyBench, a comprehensive
benchmark for evaluating LLM agents on long-horizon workflows across diverse
office applications including Word, Excel, PDF, Email, and Calendar. Our
benchmark comprises two complementary splits: OdysseyBench+ with 300 tasks
derived from real-world use cases, and OdysseyBench-Neo with 302 newly
synthesized complex tasks. Each task requires agent to identify essential
information from long-horizon interaction histories and perform multi-step
reasoning across various applications. To enable scalable benchmark creation,
we propose HomerAgents, a multi-agent framework that automates the generation
of long-horizon workflow benchmarks through systematic environment exploration,
task generation, and dialogue synthesis. Our extensive evaluation demonstrates
that OdysseyBench effectively challenges state-of-the-art LLM agents, providing
more accurate assessment of their capabilities in complex, real-world contexts
compared to existing atomic task benchmarks. We believe that OdysseyBench will
serve as a valuable resource for advancing the development and evaluation of
LLM agents in real-world productivity scenarios. In addition, we release
OdysseyBench and HomerAgents to foster research along this line.

</details>


### [175] [Complex Logical Instruction Generation](https://arxiv.org/abs/2508.09125)
*Mian Zhang,Shujian Liu,Sixun Dong,Ming Yin,Yebowen Hu,Xun Wang,Steven Ma,Song Wang,Sathish Reddy Indurthi,Haoyun Deng,Zhiyu Zoey Chen,Kaiqiang Song*

Main category: cs.CL

TL;DR: 研究提出LogicIFGen和LogicIFEval，一个用于生成和评估LLM在复杂逻辑指令遵循能力上的基准，发现当前SOTA LLM在此方面表现不佳。


<details>
  <summary>Details</summary>
Motivation: 指令遵循是LLM的基础技能，支撑推理和智能体行为。然而，随着任务复杂性增加，自然语言指令中的逻辑结构也变得复杂，LLM在此类富逻辑指令上的表现尚未得到充分探索。

Method: 提出LogicIFGen，一个可扩展的自动化框架，能从代码函数（自然表达条件、嵌套、递归、函数调用等丰富逻辑）生成可验证的指令。基于此，构建LogicIFEval基准，包含426个由复杂代码函数生成的富逻辑可验证指令。

Result: 实验表明，当前最先进的LLM在LogicIFEval上的表现不佳，大多数LLM只能正确遵循不到60%的指令。

Conclusion: LLM在遵循富逻辑指令的能力上存在显著缺陷。

Abstract: Instruction following has catalyzed the recent era of Large Language Models
(LLMs) and is the foundational skill underpinning more advanced capabilities
such as reasoning and agentic behaviors. As tasks grow more challenging, the
logic structures embedded in natural language instructions becomes increasingly
intricate. However, how well LLMs perform on such logic-rich instructions
remains under-explored. We propose LogicIFGen and LogicIFEval. LogicIFGen is a
scalable, automated framework for generating verifiable instructions from code
functions, which can naturally express rich logic such as conditionals,
nesting, recursion, and function calls. We further curate a collection of
complex code functions and use LogicIFGen to construct LogicIFEval, a benchmark
comprising 426 verifiable logic-rich instructions. Our experiments demonstrate
that current state-of-the-art LLMs still struggle to correctly follow the
instructions in LogicIFEval. Most LLMs can only follow fewer than 60% of the
instructions, revealing significant deficiencies in the instruction-following
ability. Code and Benchmark: https://github.com/mianzhang/LogicIF

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [176] [Humanoid Robot Acrobatics Utilizing Complete Articulated Rigid Body Dynamics](https://arxiv.org/abs/2508.08258)
*Gerald Brantner*

Main category: cs.RO

TL;DR: 一种使人形机器人执行高动态杂技动作的控制架构。


<details>
  <summary>Details</summary>
Motivation: 赋予人形机器人类人杂技动作能力是一个长期挑战，因其高自由度导致规划复杂且现有线性化和模型近似方法在真实机器人系统上性能退化。

Method: 提出一种包含轨迹优化和全身控制的控制架构，通过匹配模型抽象作为中介，使机器人能够基于未简化的关节刚体模型运动方程执行杂技动作，包括约束和姿态行为。

Result: 在仿真中分析并验证了所提系统的有效性。

Conclusion: 所提出的控制架构能够使人形机器人在考虑完整运动方程的情况下执行复杂的杂技动作。

Abstract: Endowing humanoid robots with the ability to perform highly dynamic motions
akin to human-level acrobatics has been a long-standing challenge. Successfully
performing these maneuvers requires close consideration of the underlying
physics in both trajectory optimization for planning and control during
execution. This is particularly challenging due to humanoids' high
degree-of-freedom count and associated exponentially scaling complexities,
which makes planning on the explicit equations of motion intractable. Typical
workarounds include linearization methods and model approximations. However,
neither are sufficient because they produce degraded performance on the true
robotic system. This paper presents a control architecture comprising
trajectory optimization and whole-body control, intermediated by a matching
model abstraction, that enables the execution of acrobatic maneuvers, including
constraint and posture behaviors, conditioned on the unabbreviated equations of
motion of the articulated rigid body model. A review of underlying modeling and
control methods is given, followed by implementation details including model
abstraction, trajectory optimization and whole-body controller. The system's
effectiveness is analyzed in simulation.

</details>


### [177] [Koopman Operator Based Linear Model Predictive Control for Quadruped Trotting](https://arxiv.org/abs/2508.08259)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 本文首次将Koopman算子理论应用于四足机器人运动的线性模型预测控制（LMPC），以在实时控制中保留非线性动力学，实现高精度跟踪和扰动抑制。


<details>
  <summary>Details</summary>
Motivation: 传统的四足机器人在线最优控制方法（如LMPC）通过线性化运动方程来简化问题，但这会导致模型不准确性，限制了机器人在变化输入和条件下的适应性。

Method: 利用Koopman算子将四足机器人系统映射到高维空间，在此空间中创建一个线性模型，该模型能够保留原始运动方程的非线性特性。然后，将此线性模型应用于LMPC框架，进行控制器的设计和求解。

Result: 在四足机器人上展示了高精度的轨迹跟踪能力和出色的扰动抑制性能。

Conclusion: 首次将Koopman算子理论应用于四足机器人运动的线性模型预测控制，成功克服了传统LMPC模型线性化的不足，为实时最优控制提供了新途径。

Abstract: Online optimal control of quadruped robots would enable them to adapt to
varying inputs and changing conditions in real time. A common way of achieving
this is linear model predictive control (LMPC), where a quadratic programming
(QP) problem is formulated over a finite horizon with a quadratic cost and
linear constraints obtained by linearizing the equations of motion and solved
on the fly. However, the model linearization may lead to model inaccuracies. In
this paper, we use the Koopman operator to create a linear model of the
quadrupedal system in high dimensional space which preserves the nonlinearity
of the equations of motion. Then using LMPC, we demonstrate high fidelity
tracking and disturbance rejection on a quadrupedal robot. This is the first
work that uses the Koopman operator theory for LMPC of quadrupedal locomotion.

</details>


### [178] [Forecast-Driven MPC for Decentralized Multi-Robot Collision Avoidance](https://arxiv.org/abs/2508.08264)
*Hadush Hailu,Bruk Gebregziabher,Prudhvi Raj*

Main category: cs.RO

TL;DR: eIFP-MPC是一种优化和扩展的迭代预测规划器（IFP），通过改进威胁优先级、路径生成和集成模型预测控制（MPC），解决了去中心化多机器人路径规划中IFP在对称配置和高密度环境下的碰撞和死锁问题，显著提高了鲁棒性、路径一致性和轨迹效率。


<details>
  <summary>Details</summary>
Motivation: 原有的迭代预测规划器（IFP）在去中心化、无通信的多机器人路径规划中虽然计算轻量、可扩展且反应迅速，但在对称配置下表现不佳，镜像交互常导致碰撞和死锁。

Method: 本文提出了eIFP-MPC，通过以下方式优化和扩展了IFP：1) 使用碰撞时间启发式方法精炼威胁优先级；2) 通过基于成本的路径点选择稳定路径生成；3) 将模型预测控制（MPC）整合到规划过程中以确保动态可行性。这些增强功能与IFP紧密集成，以保持其效率。

Result: 在对称和高密度场景下的广泛仿真表明，eIFP-MPC显著减少了振荡，确保了无碰撞运动，并提高了轨迹效率。这证明了几何规划器可以通过优化得到增强，从而在复杂的多智能体环境中实现大规模的鲁棒性能。

Conclusion: 通过优化（如eIFP-MPC），几何规划器可以得到强化，使其能够在复杂的多智能体环境中实现大规模的鲁棒性能，有效解决传统几何规划器在对称和密集场景中的局限性。

Abstract: The Iterative Forecast Planner (IFP) is a geometric planning approach that
offers lightweight computations, scalable, and reactive solutions for
multi-robot path planning in decentralized, communication-free settings.
However, it struggles in symmetric configurations, where mirrored interactions
often lead to collisions and deadlocks. We introduce eIFP-MPC, an optimized and
extended version of IFP that improves robustness and path consistency in dense,
dynamic environments. The method refines threat prioritization using a
time-to-collision heuristic, stabilizes path generation through cost-based
via-point selection, and ensures dynamic feasibility by incorporating model
predictive control (MPC) into the planning process. These enhancements are
tightly integrated into the IFP to preserve its efficiency while improving its
adaptability and stability. Extensive simulations across symmetric and
high-density scenarios show that eIFP-MPC significantly reduces oscillations,
ensures collision-free motion, and improves trajectory efficiency. The results
demonstrate that geometric planners can be strengthened through optimization,
enabling robust performance at scale in complex multi-agent environments.

</details>


### [179] [emg2tendon: From sEMG Signals to Tendon Control in Musculoskeletal Hands](https://arxiv.org/abs/2508.08269)
*Sagar Verma*

Main category: cs.RO

TL;DR: 本文介绍了首个大规模肌电信号（sEMG）到肌腱控制的数据集，并提出了一种新的基于扩散的回归模型，以解决肌腱驱动机器人手难以控制的问题，为实现可扩展、精确的机器人手肌腱控制奠定基础。


<details>
  <summary>Details</summary>
Motivation: 肌腱驱动机器人手在操作任务中具有无与伦比的灵活性，但其控制策略学习面临独特挑战：运动捕捉数据与肌腱控制之间缺乏直接映射，导致学习过程复杂且昂贵；视觉追踪易受遮挡和不准确性影响；腕部可穿戴式sEMG传感器虽是廉价替代方案，但将sEMG信号映射到肌腱控制仍是重大挑战。

Method: 本文扩展了emg2pose数据集，构建了首个大规模EMG-to-Tendon Control数据集，包含193名受试者、370小时、29个阶段的多样手势记录。该数据集利用MyoSuite MyoHand模型推导肌腱控制信号，解决了以往方法中无效姿态的限制。同时，提供了三个基线回归模型来展示数据集的效用，并提出了一种新颖的基于扩散的回归模型，用于从sEMG记录中预测肌腱控制。

Result: 创建了首个大规模EMG-to-Tendon Control数据集，其数据量庞大且质量高，解决了现有方法的局限性。提供了基线回归模型证明了数据集的实用性。提出了一种新的扩散模型，有望提高sEMG到肌腱控制的预测精度。

Conclusion: 该数据集和建模框架的引入是肌腱驱动灵巧机器人操作领域的一大进步，为机器人手实现可扩展且精确的肌腱控制奠定了基础。

Abstract: Tendon-driven robotic hands offer unparalleled dexterity for manipulation
tasks, but learning control policies for such systems presents unique
challenges. Unlike joint-actuated robotic hands, tendon-driven systems lack a
direct one-to-one mapping between motion capture (mocap) data and tendon
controls, making the learning process complex and expensive. Additionally,
visual tracking methods for real-world applications are prone to occlusions and
inaccuracies, further complicating joint tracking. Wrist-wearable surface
electromyography (sEMG) sensors present an inexpensive, robust alternative to
capture hand motion. However, mapping sEMG signals to tendon control remains a
significant challenge despite the availability of EMG-to-pose data sets and
regression-based models in the existing literature.
  We introduce the first large-scale EMG-to-Tendon Control dataset for robotic
hands, extending the emg2pose dataset, which includes recordings from 193
subjects, spanning 370 hours and 29 stages with diverse gestures. This dataset
incorporates tendon control signals derived using the MyoSuite MyoHand model,
addressing limitations such as invalid poses in prior methods. We provide three
baseline regression models to demonstrate emg2tendon utility and propose a
novel diffusion-based regression model for predicting tendon control from sEMG
recordings. This dataset and modeling framework marks a significant step
forward for tendon-driven dexterous robotic manipulation, laying the groundwork
for scalable and accurate tendon control in robotic hands.
https://emg2tendon.github.io/

</details>


### [180] [Evaluation of an Autonomous Surface Robot Equipped with a Transformable Mobility Mechanism for Efficient Mobility Control](https://arxiv.org/abs/2508.08303)
*Yasuyuki Fujii,Dinh Tuan Tran,Joo-Ho Lee*

Main category: cs.RO

TL;DR: 本研究开发并评估了一种可变形移动机构，用于水面机器人以提高能源效率和机动性，并通过现场实验验证了其在巡逻任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 自主水面机器人在长期水环境监测中，高效的移动性和低功耗至关重要。

Method: 开发了一种具有驻点保持和巡航两种控制模式的可变形移动机构。通过现场实验，在两点间的往返任务中对其进行了评估。

Result: 与驻点保持模式相比，巡航模式在往返任务中将功耗降低了10%，总耗时减少了5%。

Conclusion: 可变形移动机构有效提升了水面机器人巡逻的运行效率。

Abstract: Efficient mobility and power consumption are critical for autonomous water
surface robots in long-term water environmental monitoring. This study develops
and evaluates a transformable mobility mechanism for a water surface robot with
two control modes: station-keeping and traveling to improve energy efficiency
and maneuverability. Field experiments show that, in a round-trip task between
two points, the traveling mode reduces power consumption by 10\% and decreases
the total time required for travel by 5\% compared to the station-keeping mode.
These results confirm the effectiveness of the transformable mobility mechanism
for enhancing operational efficiency in patrolling on water surface.

</details>


### [181] [Whole-Body Coordination for Dynamic Object Grasping with Legged Manipulators](https://arxiv.org/abs/2508.08328)
*Qiwei Liang,Boyang Cai,Rongyi He,Hui Li,Tao Teng,Haihan Duan,Changxin Huang,Runhao Zeng*

Main category: cs.RO

TL;DR: 该论文提出了DQ-Bench基准和DQ-Net框架，以解决四足机器人动态目标抓取问题，通过教师-学生网络实现鲁棒高效的抓取。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注静态物体抓取，忽略了动态目标带来的挑战，限制了四足机器人在物流分拣、人机协作等动态场景中的应用。

Method: 引入DQ-Bench基准，系统评估不同运动、速度、高度、物体类型和地形复杂度的动态抓取。提出DQ-Net，一个紧凑的教师-学生框架：教师网络利用特权信息（几何和运动特性）提供抓取指导和运动规划；学生网络仅使用目标掩码、深度图和本体状态进行双视角时间建模，实现闭环动作输出。

Result: 在DQ-Bench上的大量实验表明，DQ-Net在多种任务设置下实现了鲁棒的动态物体抓取，在成功率和响应速度方面均显著优于基线方法。

Conclusion: DQ-Net框架有效解决了四足机器人在复杂动态环境中抓取移动目标的问题，展示了其在实际应用中的巨大潜力。

Abstract: Quadrupedal robots with manipulators offer strong mobility and adaptability
for grasping in unstructured, dynamic environments through coordinated
whole-body control. However, existing research has predominantly focused on
static-object grasping, neglecting the challenges posed by dynamic targets and
thus limiting applicability in dynamic scenarios such as logistics sorting and
human-robot collaboration. To address this, we introduce DQ-Bench, a new
benchmark that systematically evaluates dynamic grasping across varying object
motions, velocities, heights, object types, and terrain complexities, along
with comprehensive evaluation metrics. Building upon this benchmark, we propose
DQ-Net, a compact teacher-student framework designed to infer grasp
configurations from limited perceptual cues. During training, the teacher
network leverages privileged information to holistically model both the static
geometric properties and dynamic motion characteristics of the target, and
integrates a grasp fusion module to deliver robust guidance for motion
planning. Concurrently, we design a lightweight student network that performs
dual-viewpoint temporal modeling using only the target mask, depth map, and
proprioceptive state, enabling closed-loop action outputs without reliance on
privileged data. Extensive experiments on DQ-Bench demonstrate that DQ-Net
achieves robust dynamic objects grasping across multiple task settings,
substantially outperforming baseline methods in both success rate and
responsiveness.

</details>


### [182] [Large Scale Robotic Material Handling: Learning, Planning, and Control](https://arxiv.org/abs/2508.09003)
*Filippo A. Spinelli,Yifan Zhai,Fang Nan,Pascal Egli,Julian Nubert,Thilo Bleumer,Lukas Miller,Ferdinand Hofmann,Marco Hutter*

Main category: cs.RO

TL;DR: 该论文提出了一个用于大规模物料搬运任务的自主执行框架，利用强化学习实现抓取点选择和轨迹跟踪控制，并在真实场景中验证了其在精度、重复性和操作安全性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 物料搬运操作（如货物卸载、垃圾分类、建筑拆除）重复、劳动密集且存在安全风险，通常由配备欠驱动抓具的大型液压物料搬运机执行，需要自动化来提高效率和安全性。

Method: 该研究提出了一个综合框架，集成了环境感知、堆料攻击点选择、路径规划和运动控制模块。主要贡献是两个基于强化学习的模块：一个攻击点规划器，用于选择最佳抓取位置以最大化移除效率并最小化铲取次数；一个鲁棒的轨迹跟踪控制器，解决欠驱动抓具的精度和安全挑战，并利用其自由摆动特性通过动态抛掷释放物料。

Result: 该框架在真实场景中（使用一台40吨物料搬运机）进行了验证，重点关注高吞吐量散料堆管理和高精度卡车装载两项任务。与人类操作员的对比评估表明，该系统在精度、重复性和操作安全性方面表现出有效性。据作者所知，这是首次实现物料搬运任务的全面自动化。

Conclusion: 该研究成功开发并验证了一个用于大规模物料搬运的完整自主系统，通过集成强化学习模块，显著提高了操作的效率、精度、重复性和安全性，实现了该领域全尺寸任务的首次自动化。

Abstract: Bulk material handling involves the efficient and precise moving of large
quantities of materials, a core operation in many industries, including cargo
ship unloading, waste sorting, construction, and demolition. These repetitive,
labor-intensive, and safety-critical operations are typically performed using
large hydraulic material handlers equipped with underactuated grippers. In this
work, we present a comprehensive framework for the autonomous execution of
large-scale material handling tasks. The system integrates specialized modules
for environment perception, pile attack point selection, path planning, and
motion control. The main contributions of this work are two reinforcement
learning-based modules: an attack point planner that selects optimal grasping
locations on the material pile to maximize removal efficiency and minimize the
number of scoops, and a robust trajectory following controller that addresses
the precision and safety challenges associated with underactuated grippers in
movement, while utilizing their free-swinging nature to release material
through dynamic throwing. We validate our framework through real-world
experiments on a 40 t material handler in a representative worksite, focusing
on two key tasks: high-throughput bulk pile management and high-precision truck
loading. Comparative evaluations against human operators demonstrate the
system's effectiveness in terms of precision, repeatability, and operational
safety. To the best of our knowledge, this is the first complete automation of
material handling tasks on a full scale.

</details>


### [183] [A Minimal Model for Emergent Collective Behaviors in Autonomous Robotic Multi-Agent Systems](https://arxiv.org/abs/2508.08473)
*Hossein B. Jond*

Main category: cs.RO

TL;DR: 本文提出一种新的群体行为模型，通过相对位置、速度和局部密度实现灵活无碰撞的群体行为，并扩展到认知系统以实现能量感知相变。


<details>
  <summary>Details</summary>
Motivation: 现有群体行为模型（如Vicsek、Cucker-Smale）缺乏避碰功能，而Olfati-Saber模型则形成僵硬的队形，限制了其在群体机器人中的应用。

Method: 提出一个基于相对位置、速度和局部密度，并由空间偏移和动能偏移两个可调参数调节的代理动力学模型。该框架进一步扩展到认知自主系统，通过自适应控制参数调整实现能量感知的蜂拥和集群行为之间的相变。

Result: 该模型实现了空间灵活、无碰撞的群体行为，反映了自然群体动力学。扩展框架能实现能量感知的蜂拥与集群行为间的相变。

Conclusion: 这种受认知启发的模型为多机器人系统（特别是自主空中蜂群）的实际应用提供了坚实基础。

Abstract: Collective behaviors such as swarming and flocking emerge from simple,
decentralized interactions in biological systems. Existing models, such as
Vicsek and Cucker-Smale, lack collision avoidance, whereas the Olfati-Saber
model imposes rigid formations, limiting their applicability in swarm robotics.
To address these limitations, this paper proposes a minimal yet expressive
model that governs agent dynamics using relative positions, velocities, and
local density, modulated by two tunable parameters: the spatial offset and
kinetic offset. The model achieves spatially flexible, collision-free behaviors
that reflect naturalistic group dynamics. Furthermore, we extend the framework
to cognitive autonomous systems, enabling energy-aware phase transitions
between swarming and flocking through adaptive control parameter tuning. This
cognitively inspired approach offers a robust foundation for real-world
applications in multi-robot systems, particularly autonomous aerial swarms.

</details>


### [184] [AZRA: Extending the Affective Capabilities of Zoomorphic Robots using Augmented Reality](https://arxiv.org/abs/2508.08507)
*Shaun Macdonald,Salma ElSayed,Mark McGill*

Main category: cs.RO

TL;DR: 提出AZRA，一个增强现实（AR）框架，通过虚拟显示和交互模式，在不进行物理修改的情况下，扩展了拟动物机器人的情感交互能力，使其更适合家庭使用。


<details>
  <summary>Details</summary>
Motivation: 拟动物机器人作为宠物替代品，其情感交互往往过于简单和短暂，限制了它们在家庭中的普及和用户建立长期情感联系的潜力。

Method: 开发了AZRA AR框架，通过在现有拟动物机器人（如Petit Qoobo）上叠加虚拟情感显示（面部、灯光、声音、思想泡泡）和交互模式（语音、触摸、接近、凝视）来增强其情感能力。此外，AZRA包含一个计算情感模型，用于计算机器人的情感反应、日常情绪、演变个性和需求。

Result: 展示了AZRA如何增强拟动物机器人的情感交互，使其更具动态性和细微性。该框架可用于快速参与式原型设计和现有机器人的功能增强。

Conclusion: AZRA框架能够显著提升拟动物机器人的情感交互和关系建立能力，为未来拟动物机器人的发展提供了新的方向和可能性。

Abstract: Zoomorphic robots could serve as accessible and practical alternatives for
users unable or unwilling to keep pets. However, their affective interactions
are often simplistic and short-lived, limiting their potential for domestic
adoption. In order to facilitate more dynamic and nuanced affective
interactions and relationships between users and zoomorphic robots we present
AZRA, a novel augmented reality (AR) framework that extends the affective
capabilities of these robots without physical modifications. To demonstrate
AZRA, we augment a zoomorphic robot, Petit Qoobo, with novel emotional displays
(face, light, sound, thought bubbles) and interaction modalities (voice, touch,
proximity, gaze). Additionally, AZRA features a computational model of emotion
to calculate the robot's emotional responses, daily moods, evolving personality
and needs. We highlight how AZRA can be used for rapid participatory
prototyping and enhancing existing robots, then discuss implications on future
zoomorphic robot development.

</details>


### [185] [DeepFleet: Multi-Agent Foundation Models for Mobile Robots](https://arxiv.org/abs/2508.08574)
*Ameya Agaskar,Sriram Siva,William Pickering,Kyle O'Brien,Charles Kekeh,Ang Li,Brianna Gallo Sarker,Alicia Chua,Mayur Nemade,Charun Thattai,Jiaming Di,Isaac Iyengar,Ramya Dharoor,Dino Kirouani,Jimmy Erskine,Tamir Hegazy,Scott Niekum,Usman A. Khan,Federico Pecora,Joseph W. Durham*

Main category: cs.RO

TL;DR: DeepFleet是一套为大规模移动机器人车队协调和规划设计的预训练基础模型，通过探索四种不同的架构，发现以机器人为中心（RC）和图-地面（GF）模型最有前景，且能有效利用大规模数据集进行扩展。


<details>
  <summary>Details</summary>
Motivation: 支持大规模移动机器人车队的协调和规划。

Method: 引入DeepFleet，一套包含四种不同架构的基础模型：机器人中心（RC）模型（自回归决策Transformer），机器人-地面（RF）模型（Transformer与交叉注意力），图像-地面（IF）模型（卷积编码），以及图-地面（GF）模型（时间注意力与图神经网络）。这些模型在亚马逊全球仓库数百万机器人的车队运动数据上进行训练，并评估了设计选择对预测任务性能的影响。

Result: 机器人中心（RC）模型和图-地面（GF）模型表现出最大的潜力，它们都使用了异步机器人状态更新并整合了机器人交互的局部结构。实验还表明，随着模型规模的扩大，这两种模型能有效利用更大的仓库运营数据集。

Conclusion: 机器人中心（RC）和图-地面（GF）模型由于其处理局部交互的能力和与数据规模共同扩展的潜力，在大规模机器人车队协调方面显示出巨大前景。

Abstract: We introduce DeepFleet, a suite of foundation models designed to support
coordination and planning for large-scale mobile robot fleets. These models are
trained on fleet movement data, including robot positions, goals, and
interactions, from hundreds of thousands of robots in Amazon warehouses
worldwide. DeepFleet consists of four architectures that each embody a distinct
inductive bias and collectively explore key points in the design space for
multi-agent foundation models: the robot-centric (RC) model is an
autoregressive decision transformer operating on neighborhoods of individual
robots; the robot-floor (RF) model uses a transformer with cross-attention
between robots and the warehouse floor; the image-floor (IF) model applies
convolutional encoding to a multi-channel image representation of the full
fleet; and the graph-floor (GF) model combines temporal attention with graph
neural networks for spatial relationships. In this paper, we describe these
models and present our evaluation of the impact of these design choices on
prediction task performance. We find that the robot-centric and graph-floor
models, which both use asynchronous robot state updates and incorporate the
localized structure of robot interactions, show the most promise. We also
present experiments that show that these two models can make effective use of
larger warehouses operation datasets as the models are scaled up.

</details>


### [186] [Developing a Calibrated Physics-Based Digital Twin for Construction Vehicles](https://arxiv.org/abs/2508.08576)
*Deniz Karanfil,Daniel Lindmark,Martin Servin,David Torick,Bahram Ravani*

Main category: cs.RO

TL;DR: 本文开发了一个轮式装载机的校准数字孪生，用于高精度模拟、诊断和自动化规划。


<details>
  <summary>Details</summary>
Motivation: 旨在通过集成施工车辆与高保真数字模型，实现自动化诊断、操作优化以及增强自动化能力的预规划模拟。

Method: 构建了一个基于物理的多体动力学高保真数字模型（虚拟孪生），使用AGX Dynamics软件模拟轮式装载机。通过在物理装载机上安装传感器，收集数据对数字模型进行校准。

Result: 校准后的数字孪生能够高精度地估算铲斗底部受力的大小，提供了高保真度的模拟。

Conclusion: 开发的校准数字孪生实现了高保真模拟，能够准确估算铲斗受力，为施工操作的自动化规划和诊断优化提供了有力支持。

Abstract: This paper presents the development of a calibrated digital twin of a wheel
loader. A calibrated digital twin integrates a construction vehicle with a
high-fidelity digital model allowing for automated diagnostics and optimization
of operations as well as pre-planning simulations enhancing automation
capabilities. The high-fidelity digital model is a virtual twin of the physical
wheel loader. It uses a physics-based multibody dynamic model of the wheel
loader in the software AGX Dynamics. Interactions of the wheel loader's bucket
while in use in construction can be simulated in the virtual model. Calibration
makes this simulation of high-fidelity which can enhance realistic planning for
automation of construction operations. In this work, a wheel loader was
instrumented with several sensors used to calibrate the digital model. The
calibrated digital twin was able to estimate the magnitude of the forces on the
bucket base with high accuracy, providing a high-fidelity simulation.

</details>


### [187] [Autonomous Mobile Plant Watering Robot : A Kinematic Approach](https://arxiv.org/abs/2508.08607)
*Justin London*

Main category: cs.RO

TL;DR: 本文介绍了一种新型的自主移动植物浇水机器人，它配备了6自由度机械臂和传感器，能够识别植物、检测土壤湿度并进行精准浇水，同时具备自主导航和避障能力。


<details>
  <summary>Details</summary>
Motivation: 现有的农业机器人成本高昂、移动性或功能有限，而植物需要定期和适量的浇水才能茁壮成长。因此，需要一种更经济、功能更全面的自主浇水解决方案。

Method: 该机器人采用四轮驱动合金底盘，连接一个6自由度机械臂，用于握持水管和插入土壤湿度传感器。它使用Jetson Nano和Arduino微控制器，通过RealSense摄像头结合YOLOv5和Pl@ntNet-300K数据集进行实时植物检测。LIDAR用于物体和碰撞避障，实现非预定义路径的自主移动。文中还提供了Denavit-Hartenberg (DH) 表、正向运动学、差分驱动运动学和逆向运动学。

Result: 该机器人能够识别和检测植物，将土壤湿度传感器插入土壤以确定适当的水量进行浇水，并通过LIDAR实现自主导航和避障，无需预设路径，并能记录已浇水的植物。文中提供了仿真和实验结果。

Conclusion: 研究成功开发了一种新颖的自主移动植物浇水机器人，它克服了现有农业机器人成本高和功能受限的问题，实现了植物的智能识别、精准浇水和自主导航。

Abstract: Plants need regular and the appropriate amount of watering to thrive and
survive. While agricultural robots exist that can spray water on plants and
crops such as the , they are expensive and have limited mobility and/or
functionality. We introduce a novel autonomous mobile plant watering robot that
uses a 6 degree of freedom (DOF) manipulator, connected to a 4 wheel drive
alloy chassis, to be able to hold a garden hose, recognize and detect plants,
and to water them with the appropriate amount of water by being able to insert
a soil humidity/moisture sensor into the soil. The robot uses Jetson Nano and
Arduino microcontroller and real sense camera to perform computer vision to
detect plants using real-time YOLOv5 with the Pl@ntNet-300K dataset. The robot
uses LIDAR for object and collision avoideance and does not need to move on a
pre-defined path and can keep track of which plants it has watered. We provide
the Denavit-Hartenberg (DH) Table, forward kinematics, differential driving
kinematics, and inverse kinematics along with simulation and experiment results

</details>


### [188] [Communication Efficient Robotic Mixed Reality with Gaussian Splatting Cross-Layer Optimization](https://arxiv.org/abs/2508.08624)
*Chenxuan Liu,He Li,Zongze Li,Shuai Wang,Wei Xu,Kejiang Ye,Derrick Wing Kwan Ng,Chengzhong Xu*

Main category: cs.RO

TL;DR: 本文提出了一种基于高斯泼溅（GS）的机器人混合现实（RoboMR）系统（GSMR），通过从GS模型渲染视图来大幅降低通信成本。为解决GS模型与实际环境的差异，进一步提出了GS跨层优化（GSCLO）框架，并设计了加速罚函数优化（APO）算法来高效解决该问题，实现了超低通信开销。


<details>
  <summary>Details</summary>
Motivation: 在机器人混合现实（RoboMR）系统中，通过无线信道上传高分辨率图像是实现低成本通信面临的挑战。

Method: 本文提出了高斯泼溅RoboMR（GSMR），允许模拟器通过调用GS模型的“记忆”来从机器人姿态渲染逼真的视图，从而减少不必要的图像上传。为解决GS模型与实际环境的差异，进一步提出了GS跨层优化（GSCLO）框架，该框架联合优化了跨帧的内容切换（是否上传图像）和功率分配，以最小化新推导的GSMR损失函数。GSCLO问题通过加速罚函数优化（APO）算法解决，该算法将计算复杂度降低了10倍以上。此外，还提出了GSCLO的变体以实现鲁棒、低功耗和多机器人的GSMR。

Result: APO算法相比传统方法将计算复杂度降低了10倍以上。所提出的GSMR范式和GSCLO方法在轮式和腿式机器人上，在各种场景和多样化指标方面，均显著优于现有基准。首次发现RoboMR可以实现超低通信成本，并且在动态场景中，混合数据有助于增强GS性能。

Conclusion: 通过结合高斯泼溅模型和跨层优化框架，RoboMR系统能够实现超低通信成本。此外，在动态场景中，混合数据对提升GS性能至关重要。

Abstract: Realizing low-cost communication in robotic mixed reality (RoboMR) systems
presents a challenge, due to the necessity of uploading high-resolution images
through wireless channels. This paper proposes Gaussian splatting (GS) RoboMR
(GSMR), which enables the simulator to opportunistically render a
photo-realistic view from the robot's pose by calling ``memory'' from a GS
model, thus reducing the need for excessive image uploads. However, the GS
model may involve discrepancies compared to the actual environments. To this
end, a GS cross-layer optimization (GSCLO) framework is further proposed, which
jointly optimizes content switching (i.e., deciding whether to upload image or
not) and power allocation (i.e., adjusting to content profiles) across
different frames by minimizing a newly derived GSMR loss function. The GSCLO
problem is addressed by an accelerated penalty optimization (APO) algorithm
that reduces computational complexity by over $10$x compared to traditional
branch-and-bound and search algorithms. Moreover, variants of GSCLO are
presented to achieve robust, low-power, and multi-robot GSMR. Extensive
experiments demonstrate that the proposed GSMR paradigm and GSCLO method
achieve significant improvements over existing benchmarks on both wheeled and
legged robots in terms of diverse metrics in various scenarios. For the first
time, it is found that RoboMR can be achieved with ultra-low communication
costs, and mixture of data is useful for enhancing GS performance in dynamic
scenarios.

</details>


### [189] [ZS-Puffin: Design, Modeling and Implementation of an Unmanned Aerial-Aquatic Vehicle with Amphibious Wings](https://arxiv.org/abs/2508.08690)
*Zhenjiang Wang,Yunhua Jiang,Zikun Zhen,Yifan Jiang,Yubin Tan,Wubin Wang*

Main category: cs.RO

TL;DR: 受海鹦启发，本文提出一种新型两栖无人飞行器（UAAV），其两栖机翼可在空中产生升力，在水下作为扑翼推进，并引入人工中央模式发生器（CPG）以平滑扑翼运动，实现环境友好的两栖操作。


<details>
  <summary>Details</summary>
Motivation: 无人两栖飞行器（UAAV）具有广泛应用前景，但不同介质（空气和水）对推进系统造成的挑战是其研发的关键问题。

Method: 设计了一种基于固定翼结构、具有单个俯仰自由度的两栖机翼，无需额外部件即可在空中产生升力并在水下作为扑翼推进。此外，引入人工中央模式发生器（CPG）以提高扑翼运动的平滑性。论文还介绍了原型、设计细节和实际实现。

Result: 所提出的两栖机翼能在空中产生升力，并在水下作为扑翼进行推进，减少对海洋生物的干扰，实现环保操作。人工CPG的引入有效增强了扑翼运动的平滑性。

Conclusion: 该研究成功设计并实现了具有两栖机翼的UAAV概念，通过巧妙的结构设计和CPG控制，有效解决了不同介质下的推进挑战，并展现出良好的环境友好性。

Abstract: Unmanned aerial-aquatic vehicles (UAAVs) can operate both in the air and
underwater, giving them broad application prospects. Inspired by the
dual-function wings of puffins, we propose a UAAV with amphibious wings to
address the challenge posed by medium differences on the vehicle's propulsion
system. The amphibious wing, redesigned based on a fixed-wing structure,
features a single degree of freedom in pitch and requires no additional
components. It can generate lift in the air and function as a flapping wing for
propulsion underwater, reducing disturbance to marine life and making it
environmentally friendly. Additionally, an artificial central pattern generator
(CPG) is introduced to enhance the smoothness of the flapping motion. This
paper presents the prototype, design details, and practical implementation of
this concept.

</details>


### [190] [OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing](https://arxiv.org/abs/2508.08706)
*Zhengxue Cheng,Yiqian Zhang,Wenkang Zhang,Haoyu Li,Keyu Wang,Li Song,Hengdi Zhang*

Main category: cs.RO

TL;DR: OmniVTLA是一个结合触觉感知的视觉-语言-动作（VLA）模型，通过双路径触觉编码器和新的多模态触觉数据集ObjTac，显著提升了机器人在接触密集型任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型忽视触觉感知的重要性，在接触密集型任务中表现不佳，原因在于触觉传感器的异构性以及触觉数据获取的困难。

Method: 1. 提出了OmniVTLA，一个包含双路径触觉编码器框架的新型架构，结合预训练的视觉Transformer (ViT) 和语义对齐的触觉ViT (SA-ViT) 来增强触觉感知。2. 引入了ObjTac数据集，一个包含56种物体、13.5万个三模态（文本、视觉、触觉）样本的力基触觉数据集。3. 利用ObjTac数据集训练语义对齐的触觉编码器，学习统一的触觉表示，作为OmniVTLA更好的初始化。

Result: 在抓取和放置任务中，OmniVTLA在夹持器上实现了96.9%的成功率（比基线高21.9%），在灵巧手实现了100%的成功率（比基线高6.2%）。此外，与现有VLA模型相比，OmniVTLA显著减少了任务完成时间并生成了更平滑的轨迹。

Conclusion: OmniVTLA通过有效整合触觉感知，显著提升了VLA模型在机器人操作中的性能，特别是在接触密集型任务中，证明了触觉信息对于机器人任务泛化和效率的关键作用。

Abstract: Recent vision-language-action (VLA) models build upon vision-language
foundations, and have achieved promising results and exhibit the possibility of
task generalization in robot manipulation. However, due to the heterogeneity of
tactile sensors and the difficulty of acquiring tactile data, current VLA
models significantly overlook the importance of tactile perception and fail in
contact-rich tasks. To address this issue, this paper proposes OmniVTLA, a
novel architecture involving tactile sensing. Specifically, our contributions
are threefold. First, our OmniVTLA features a dual-path tactile encoder
framework. This framework enhances tactile perception across diverse
vision-based and force-based tactile sensors by using a pretrained vision
transformer (ViT) and a semantically-aligned tactile ViT (SA-ViT). Second, we
introduce ObjTac, a comprehensive force-based tactile dataset capturing
textual, visual, and tactile information for 56 objects across 10 categories.
With 135K tri-modal samples, ObjTac supplements existing visuo-tactile
datasets. Third, leveraging this dataset, we train a semantically-aligned
tactile encoder to learn a unified tactile representation, serving as a better
initialization for OmniVTLA. Real-world experiments demonstrate substantial
improvements over state-of-the-art VLA baselines, achieving 96.9% success rates
with grippers, (21.9% higher over baseline) and 100% success rates with
dexterous hands (6.2% higher over baseline) in pick-and-place tasks. Besides,
OmniVTLA significantly reduces task completion time and generates smoother
trajectories through tactile sensing compared to existing VLA.

</details>


### [191] [Towards Safe Imitation Learning via Potential Field-Guided Flow Matching](https://arxiv.org/abs/2508.08707)
*Haoran Ding,Anqing Duan,Zezhou Sun,Leonel Rozo,Noémie Jaquier,Dezhen Song,Yoshihiko Nakamura*

Main category: cs.RO

TL;DR: PF2MP是一种新颖的方法，通过从成功演示中同时学习任务策略和提取障碍物相关的势场，从而在不影响任务成功的情况下提高深度生成模型（如流匹配）在复杂环境中的运动生成安全性。


<details>
  <summary>Details</summary>
Motivation: 深度生成模型（特别是扩散和流匹配模型）在模仿学习中展现出巨大潜力，但其生成的运动在复杂、有障碍的环境中的安全性被忽视，这是一个关键的研究空白。

Method: 提出势场引导的流匹配策略（PF2MP），该方法从同一组成功演示中同时学习任务策略并提取障碍物相关的势场。在推理阶段，PF2MP通过学习到的势场调制流匹配向量场，从而实现安全的运动生成。

Result: PF2MP在导航和机器人操作等多种环境中，在不损害任务成功的情况下显著提高了安全性，与基线策略相比，碰撞显著减少。该方法在仿真和现实世界中均得到验证，适用于任务空间和关节空间控制。

Conclusion: PF2MP为在非结构化和障碍丰富的环境中生成更安全的运动铺平了道路。

Abstract: Deep generative models, particularly diffusion and flow matching models, have
recently shown remarkable potential in learning complex policies through
imitation learning. However, the safety of generated motions remains
overlooked, particularly in complex environments with inherent obstacles. In
this work, we address this critical gap by proposing Potential Field-Guided
Flow Matching Policy (PF2MP), a novel approach that simultaneously learns task
policies and extracts obstacle-related information, represented as a potential
field, from the same set of successful demonstrations. During inference, PF2MP
modulates the flow matching vector field via the learned potential field,
enabling safe motion generation. By leveraging these complementary fields, our
approach achieves improved safety without compromising task success across
diverse environments, such as navigation tasks and robotic manipulation
scenarios. We evaluate PF2MP in both simulation and real-world settings,
demonstrating its effectiveness in task space and joint space control.
Experimental results demonstrate that PF2MP enhances safety, achieving a
significant reduction of collisions compared to baseline policies. This work
paves the way for safer motion generation in unstructured and obstaclerich
environments.

</details>


### [192] [CRADLE: Conversational RTL Design Space Exploration with LLM-based Multi-Agent Systems](https://arxiv.org/abs/2508.08709)
*Lukas Krupp,Maximilian Schöffel,Elias Biehl,Norbert Wehn*

Main category: cs.RO

TL;DR: CRADLE是一个基于LLM多智能体系统的对话式框架，用于RTL设计的探索，实现资源优化。


<details>
  <summary>Details</summary>
Motivation: 现有方法僵化，缺乏用户引导、自验证、修正和优化的能力，因此需要一个更灵活的对话式框架。

Method: 采用LLM驱动的多智能体系统，特别是生成器-评论器（generator-critic）智能体系统，实现内部自验证、修正和优化，以最小化FPGA资源。

Result: 在RTLLM基准测试中，CRADLE使LUTs和FFs的资源使用量平均分别减少了48%和40%。

Conclusion: CRADLE框架能够有效减少RTL设计的FPGA资源使用，展现了LLM多智能体系统在设计空间探索中的潜力。

Abstract: This paper presents CRADLE, a conversational framework for design space
exploration of RTL designs using LLM-based multi-agent systems. Unlike existing
rigid approaches, CRADLE enables user-guided flows with internal
self-verification, correction, and optimization. We demonstrate the framework
with a generator-critic agent system targeting FPGA resource minimization using
state-of-the-art LLMs. Experimental results on the RTLLM benchmark show that
CRADLE achieves significant reductions in resource usage with averages of 48%
and 40% in LUTs and FFs across all benchmark designs.

</details>


### [193] [Boosting Action-Information via a Variational Bottleneck on Unlabelled Robot Videos](https://arxiv.org/abs/2508.08743)
*Haoyu Zhang,Long Cheng*

Main category: cs.RO

TL;DR: 本文提出了一种从无标签视频演示中学习的新框架，通过最大化潜在动作与真实动作之间的互信息，解决了现有方法潜在动作编码与真实动作关联性低的问题，从而提高了机器人控制性能。


<details>
  <summary>Details</summary>
Motivation: 传统的从演示中学习（LfD）方法依赖大量带动作标签的专家轨迹，限制了训练数据的规模。尽管从无标签视频中学习是一个有前景的方向，但现有方法编码的潜在动作与真实机器人动作的互信息较低，导致控制性能不佳。

Method: 引入了一个新颖的框架，即使在没有动作标签的情况下，也能显式最大化潜在动作与真实动作之间的互信息。该方法利用变分信息瓶颈来提取与动作相关的表示，同时丢弃与任务无关的信息。提供了理论分析证明其目标函数确实最大化了互信息。

Result: 通过广泛的模拟和真实世界机器人平台实验验证了该方法。实验结果表明，该方法显著增强了互信息，并持续改善了策略性能。

Conclusion: 所提出的方法通过在无标签视频学习中最大化潜在动作与真实动作的互信息，有效解决了现有方法的局限性，显著提高了机器人控制策略的性能。

Abstract: Learning from demonstrations (LfD) typically relies on large amounts of
action-labeled expert trajectories, which fundamentally constrains the scale of
available training data. A promising alternative is to learn directly from
unlabeled video demonstrations. However, we find that existing methods tend to
encode latent actions that share little mutual information with the true robot
actions, leading to suboptimal control performance. To address this limitation,
we introduce a novel framework that explicitly maximizes the mutual information
between latent actions and true actions, even in the absence of action labels.
Our method leverage the variational information-bottleneck to extract
action-relevant representations while discarding task-irrelevant information.
We provide a theoretical analysis showing that our objective indeed maximizes
the mutual information between latent and true actions. Finally, we validate
our approach through extensive experiments: first in simulated robotic
environments and then on real-world robotic platforms, the experimental results
demonstrate that our method significantly enhances mutual information and
consistently improves policy performance.

</details>


### [194] [Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT](https://arxiv.org/abs/2508.08748)
*Muhammad A. Muttaqien,Tomohiro Motoda,Ryo Hanai,Yukiyasu Domae*

Main category: cs.RO

TL;DR: 本文提出一种结合视觉提示（边界框标注）和ACT（Transformer动作分块）模仿学习的感知-动作流程，以应对便利店中机器人抓取放置任务的复杂性，实现了更平滑、自适应的操作。


<details>
  <summary>Details</summary>
Motivation: 便利店中机器人抓取放置任务面临挑战，包括物体密集排列、遮挡以及物体颜色、形状、尺寸、纹理等属性多样性，这些因素使轨迹规划和抓取复杂化。

Method: 该研究引入了一个感知-动作流程，利用注释引导的视觉提示（通过边界框标注识别可抓取物体和放置位置，提供结构化空间指导）。不同于传统分步规划，采用基于Transformer的动作分块（ACT）作为模仿学习算法，使机械臂能从人类演示中预测分块的动作序列。

Result: 系统在抓取成功率和抓取行为视觉分析方面进行了评估，结果表明在零售环境中抓取精度和适应性得到提高。

Conclusion: 该系统通过结合视觉提示和ACT模仿学习，有效提升了机器人在复杂零售环境中的抓取精度和适应性，解决了便利店中机器人抓取放置任务的挑战。

Abstract: Robotic pick-and-place tasks in convenience stores pose challenges due to
dense object arrangements, occlusions, and variations in object properties such
as color, shape, size, and texture. These factors complicate trajectory
planning and grasping. This paper introduces a perception-action pipeline
leveraging annotation-guided visual prompting, where bounding box annotations
identify both pickable objects and placement locations, providing structured
spatial guidance. Instead of traditional step-by-step planning, we employ
Action Chunking with Transformers (ACT) as an imitation learning algorithm,
enabling the robotic arm to predict chunked action sequences from human
demonstrations. This facilitates smooth, adaptive, and data-driven
pick-and-place operations. We evaluate our system based on success rate and
visual analysis of grasping behavior, demonstrating improved grasp accuracy and
adaptability in retail environments.

</details>


### [195] [Robot can reduce superior's dominance in group discussions with human social hierarchy](https://arxiv.org/abs/2508.08767)
*Kazuki Komura,Kumi Ozaki,Seiji Yamada*

Main category: cs.RO

TL;DR: 本研究探讨了机器人代理如何通过干预，在具有层级结构的讨论中减少上级的主导地位并促进参与者发言平等。


<details>
  <summary>Details</summary>
Motivation: 在社会层级关系中，上级往往主导讨论，导致参与不均。本研究旨在探索机器人代理是否能减少这种主导地位并实现参与平等。

Method: 招募了30名具有层级关系的医生和学生作为参与者。实验设计包括三种干预策略：机器人根据社会层级鼓励发言、机器人对所有参与者平等干预、以及无干预。机器人通过“跟随行动”（对发言者进行反馈）和“鼓励行动”（提示发言时间较少的成员发言）来尝试平衡参与。

Result: 实验结果显示，机器人的行为可能影响成员的发言时间，但未能明确得出机器人不同行动条件之间存在显著差异。然而，结果表明，在不降低上级满意度的情况下，可能能够影响发言时间。

Conclusion: 在经验丰富的上级可能主导的讨论场景中，通过控制机器人的反馈（backchanneling）行为，有可能抑制主导地位，并使团队成员之间的参与趋于平等。

Abstract: This study investigated whether robotic agents that deal with social
hierarchical relationships can reduce the dominance of superiors and equalize
participation among participants in discussions with hierarchical structures.
Thirty doctors and students having hierarchical relationship were gathered as
participants, and an intervention experiment was conducted using a robot that
can encourage participants to speak depending on social hierarchy. These were
compared with strategies that intervened equally for all participants without
considering hierarchy and with a no-action. The robots performed follow
actions, showing backchanneling to speech, and encourage actions, prompting
speech from members with less speaking time, on the basis of the hierarchical
relationships among group members to equalize participation. The experimental
results revealed that the robot's actions could potentially influence the
speaking time among members, but it could not be conclusively stated that there
were significant differences between the robot's action conditions. However,
the results suggested that it might be possible to influence speaking time
without decreasing the satisfaction of superiors. This indicates that in
discussion scenarios where experienced superiors are likely to dominate,
controlling the robot's backchanneling behavior could potentially suppress
dominance and equalize participation among group members.

</details>


### [196] [Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors](https://arxiv.org/abs/2508.08896)
*Haoyu Zhao,Linghao Zhuang,Xingyue Zhao,Cheng Zeng,Haoran Xu,Yuming Jiang,Jun Cen,Kexiang Wang,Jiayan Guo,Siteng Huang,Xin Li,Deli Zhao,Hua Zou*

Main category: cs.RO

TL;DR: AffordDex是一种新型两阶段训练框架，通过模仿人类运动和理解物体功能，实现通用灵巧抓取，同时保持类人姿态和功能性接触，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度关注低级抓取稳定性，忽略了对下游操作至关重要的功能感知定位和类人姿态，这限制了通用具身AI的发展。

Method: 提出AffordDex框架，采用两阶段训练：第一阶段，轨迹模仿器预训练大量人类手部运动数据，学习自然运动先验；第二阶段，训练残差模块以适应特定物体实例，通过负功能感知分割（NAA）识别不当接触区域，并结合特权教师-学生蒸馏过程，确保最终视觉策略高效成功。

Result: AffordDex不仅实现了通用灵巧抓取，还在姿态上保持了显著的类人特征，接触位置功能性强。在已见物体、未见实例甚至全新类别上，其性能均显著超越现有最佳基线。

Conclusion: AffordDex成功解决了通用灵巧抓取中功能感知定位和类人姿态的挑战，为通用具身AI的发展提供了重要基础，并展示了在复杂抓取任务中的卓越泛化能力和实用性。

Abstract: A dexterous hand capable of generalizable grasping objects is fundamental for
the development of general-purpose embodied AI. However, previous methods focus
narrowly on low-level grasp stability metrics, neglecting affordance-aware
positioning and human-like poses which are crucial for downstream manipulation.
To address these limitations, we propose AffordDex, a novel framework with
two-stage training that learns a universal grasping policy with an inherent
understanding of both motion priors and object affordances. In the first stage,
a trajectory imitator is pre-trained on a large corpus of human hand motions to
instill a strong prior for natural movement. In the second stage, a residual
module is trained to adapt these general human-like motions to specific object
instances. This refinement is critically guided by two components: our Negative
Affordance-aware Segmentation (NAA) module, which identifies functionally
inappropriate contact regions, and a privileged teacher-student distillation
process that ensures the final vision-based policy is highly successful.
Extensive experiments demonstrate that AffordDex not only achieves universal
dexterous grasping but also remains remarkably human-like in posture and
functionally appropriate in contact location. As a result, AffordDex
significantly outperforms state-of-the-art baselines across seen objects,
unseen instances, and even entirely novel categories.

</details>


### [197] [Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion](https://arxiv.org/abs/2508.08982)
*Seungeun Rho,Kartik Garg,Morgan Byrd,Sehoon Ha*

Main category: cs.RO

TL;DR: SDAX是一个新的学习框架，它通过无监督技能发现和双层优化，使四足机器人在无需大量人工干预的情况下，自主学习并掌握各种敏捷的障碍物穿越行为，并成功部署到真实硬件上。


<details>
  <summary>Details</summary>
Motivation: 现有legged机器人学习敏捷运动行为的方法（如奖励工程、专家演示、课程学习）通常需要大量人工干预，且泛化能力有限。探索本身具有挑战性，需要减少人类工程量并提高泛化性。

Method: 本文提出了SDAX（Skill Discovery as Exploration）框架。它利用无监督技能发现来自主获取多样化的技能库以克服障碍物，并通过一个双层优化过程动态调节训练过程中的探索水平。

Result: SDAX使四足机器人能够学习到高度敏捷的行为，包括爬行、攀爬、跳跃以及执行复杂的机动，例如从垂直墙壁上跳下。所学习的策略成功部署到真实硬件上，验证了其在现实世界中的迁移能力。

Conclusion: SDAX显著减少了人类工程量，通过自主技能发现和探索调节，使legged机器人能够学习到多样化和敏捷的障碍物穿越行为，并成功实现了从模拟到真实世界的迁移。

Abstract: Exploration is crucial for enabling legged robots to learn agile locomotion
behaviors that can overcome diverse obstacles. However, such exploration is
inherently challenging, and we often rely on extensive reward engineering,
expert demonstrations, or curriculum learning - all of which limit
generalizability. In this work, we propose Skill Discovery as Exploration
(SDAX), a novel learning framework that significantly reduces human engineering
effort. SDAX leverages unsupervised skill discovery to autonomously acquire a
diverse repertoire of skills for overcoming obstacles. To dynamically regulate
the level of exploration during training, SDAX employs a bi-level optimization
process that autonomously adjusts the degree of exploration. We demonstrate
that SDAX enables quadrupedal robots to acquire highly agile behaviors
including crawling, climbing, leaping, and executing complex maneuvers such as
jumping off vertical walls. Finally, we deploy the learned policy on real
hardware, validating its successful transfer to the real world.

</details>


### [198] [Rational Inverse Reasoning](https://arxiv.org/abs/2508.08983)
*Ben Zandonati,Tomás Lozano-Pérez,Leslie Pack Kaelbling*

Main category: cs.RO

TL;DR: 该论文提出了一种名为“理性逆向推理”（RIR）的框架，通过贝叶斯程序归纳从少量（甚至一个）演示中推断出机器人行为背后的潜在结构化程序，从而使机器人能够像人类一样实现快速泛化。


<details>
  <summary>Details</summary>
Motivation: 机器人目前需要大量示例才能泛化，且难以超越训练条件，这与人类能从单个不完美演示中立即泛化形成鲜明对比。这种局限性源于机器人无法恢复智能行为背后的潜在解释，即由高级目标、子任务分解和执行约束组成的结构化程序。

Method: 引入了“理性逆向推理”（RIR）框架，通过行为的层次生成模型推断潜在程序。RIR将少样本模仿视为贝叶斯程序归纳：一个视觉-语言模型迭代地提出结构化的符号任务假设，同时一个包含规划器的推理方案根据观察到的演示在该假设下的似然性来评分。这个循环产生了一个关于简洁、可执行程序的后验分布。

Result: RIR在设计用于测试物体姿态、数量、几何形状和布局变化的连续操作任务上进行了评估。结果显示，RIR仅需一个演示就能推断出预期的任务结构，并泛化到新颖设置，优于当前最先进的视觉-语言模型基线。

Conclusion: RIR框架通过推断行为背后的潜在结构化程序，使得机器人能够从极少量（甚至一个）演示中学习并泛化到多种新颖的任务设置，显著提升了机器人的少样本模仿和泛化能力。

Abstract: Humans can observe a single, imperfect demonstration and immediately
generalize to very different problem settings. Robots, in contrast, often
require hundreds of examples and still struggle to generalize beyond the
training conditions. We argue that this limitation arises from the inability to
recover the latent explanations that underpin intelligent behavior, and that
these explanations can take the form of structured programs consisting of
high-level goals, sub-task decomposition, and execution constraints. In this
work, we introduce Rational Inverse Reasoning (RIR), a framework for inferring
these latent programs through a hierarchical generative model of behavior. RIR
frames few-shot imitation as Bayesian program induction: a vision-language
model iteratively proposes structured symbolic task hypotheses, while a
planner-in-the-loop inference scheme scores each by the likelihood of the
observed demonstration under that hypothesis. This loop yields a posterior over
concise, executable programs. We evaluate RIR on a suite of continuous
manipulation tasks designed to test one-shot and few-shot generalization across
variations in object pose, count, geometry, and layout. With as little as one
demonstration, RIR infers the intended task structure and generalizes to novel
settings, outperforming state-of-the-art vision-language model baselines.

</details>


### [199] [Generation of Real-time Robotic Emotional Expressions Learning from Human Demonstration in Mixed Reality](https://arxiv.org/abs/2508.08999)
*Chao Wang,Michael Gienger,Fan Zhang*

Main category: cs.RO

TL;DR: 该论文提出一个框架，利用混合现实中专家的人类演示，并通过基于流匹配的生成过程，自主生成逼真且多样的机器人情感表达。


<details>
  <summary>Details</summary>
Motivation: 机器人在与人类互动时，表达性行为对于有效传达其情感状态至关重要。

Method: 系统允许专家以第一人称视角远程操作虚拟机器人，捕获其面部表情、头部运动和上半身手势，并将其映射到机器人相应部件（眼睛、耳朵、颈部、手臂）。利用基于流匹配的生成过程，模型学习在响应移动物体时，根据给定情感状态实时生成连贯且多样的行为。

Result: 初步测试验证了该方法在生成自主表达方面的有效性。

Conclusion: 该框架能够基于人类演示，自主生成逼真且多样的机器人情感表达，为机器人情感交互提供了有效途径。

Abstract: Expressive behaviors in robots are critical for effectively conveying their
emotional states during interactions with humans. In this work, we present a
framework that autonomously generates realistic and diverse robotic emotional
expressions based on expert human demonstrations captured in Mixed Reality
(MR). Our system enables experts to teleoperate a virtual robot from a
first-person perspective, capturing their facial expressions, head movements,
and upper-body gestures, and mapping these behaviors onto corresponding robotic
components including eyes, ears, neck, and arms. Leveraging a
flow-matching-based generative process, our model learns to produce coherent
and varied behaviors in real-time in response to moving objects, conditioned
explicitly on given emotional states. A preliminary test validated the
effectiveness of our approach for generating autonomous expressions.

</details>


### [200] [GeoVLA: Empowering 3D Representations in Vision-Language-Action Models](https://arxiv.org/abs/2508.09071)
*Lin Sun,Bin Xie,Yingfei Liu,Hao Shi,Tiancai Wang,Jiale Cao*

Main category: cs.RO

TL;DR: GeoVLA是一个新型视觉-语言-动作（VLA）框架，通过有效整合3D几何信息来增强机器人操作，解决了现有VLA模型对2D视觉依赖的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-语言-动作（VLA）模型主要依赖2D视觉输入，忽略了3D物理世界中丰富的几何信息，这限制了它们的空间感知能力和适应性，从而影响了机器人遵循语言指令和预测相应动作的性能。

Method: GeoVLA采用并行处理机制：首先，使用一个视觉-语言模型（VLM）处理图像和语言指令，提取融合的视觉-语言嵌入。同时，将深度图转换为点云，并使用定制的点编码器（Point Embedding Network）独立生成3D几何嵌入。最后，将这些嵌入连接起来，并通过提出的空间感知动作专家（3D-enhanced Action Expert）处理，该专家结合来自不同传感器模态的信息，生成精确的动作序列。

Result: GeoVLA在仿真和真实世界环境中都表现出卓越的性能和鲁棒性。它在LIBERO和ManiSkill2仿真基准测试中取得了最先进的结果，并在需要高度适应性、尺度感知和视点不变性的真实世界任务中展现出显著的鲁棒性。

Conclusion: GeoVLA通过有效整合3D信息，显著提升了机器人操作能力，克服了传统VLA模型对2D视觉的依赖，证明了其在复杂机器人任务中的优越性和鲁棒性。

Abstract: Vision-Language-Action (VLA) models have emerged as a promising approach for
enabling robots to follow language instructions and predict corresponding
actions.However, current VLA models mainly rely on 2D visual inputs, neglecting
the rich geometric information in the 3D physical world, which limits their
spatial awareness and adaptability. In this paper, we present GeoVLA, a novel
VLA framework that effectively integrates 3D information to advance robotic
manipulation. It uses a vision-language model (VLM) to process images and
language instructions,extracting fused vision-language embeddings. In parallel,
it converts depth maps into point clouds and employs a customized point
encoder, called Point Embedding Network, to generate 3D geometric embeddings
independently. These produced embeddings are then concatenated and processed by
our proposed spatial-aware action expert, called 3D-enhanced Action Expert,
which combines information from different sensor modalities to produce precise
action sequences. Through extensive experiments in both simulation and
real-world environments, GeoVLA demonstrates superior performance and
robustness. It achieves state-of-the-art results in the LIBERO and ManiSkill2
simulation benchmarks and shows remarkable robustness in real-world tasks
requiring height adaptability, scale awareness and viewpoint invariance.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [201] [DeePConverter: A Data-Driven Optimal Control Architecture for Grid-Connected Power Converters](https://arxiv.org/abs/2508.08578)
*Ruohan Leng,Linbin Huang,Huanhai Xin,Ping Ju,Xiongfei Wang,Eduardo Prieto-Araujo,Florian Dörfler*

Main category: eess.SY

TL;DR: 本文提出了一种名为DeePConverter的电网并网变流器控制方法，它利用数据驱动的预测控制（DeePC）来替代传统的PID控制，以实现对复杂电网的鲁棒和最优控制。


<details>
  <summary>Details</summary>
Motivation: 传统的并网变流器使用PID控制器，其参数通常基于简化且不准确的电网模型进行调整。然而，实际电网复杂、多变且未知，这可能导致控制性能不佳甚至不稳定。

Method: 本文采用数据驱动的预测控制（DeePC）方法来控制并网变流器，称之为DeePConverters。DeePConverter通过数据隐式感知电网特性，并调整控制策略以实现最优和鲁棒性能。文章详细介绍了其模块化配置、通用结构、控制行为规范、具体实现和计算。

Result: DeePConverters能够实现电网并网变流器的最优和鲁棒控制，并通过高保真仿真和硬件在环（HIL）测试验证了其有效性。

Conclusion: 数据驱动的预测控制（DeePC）为并网变流器提供了一种有效且鲁棒的控制方案，能够克服传统PID控制在复杂电网环境下的局限性，实现更好的性能。

Abstract: Grid-connected power converters are ubiquitous in modern power systems,
acting as grid interfaces of renewable energy sources, energy storage systems,
electric vehicles, high-voltage DC systems, etc. Conventionally, power
converters use multiple PID regulators to achieve different control objectives
such as grid synchronization and voltage/power regulations, where the PID
parameters are usually tuned based on a presumed (and often overly-simplified)
power grid model. However, this may lead to inferior performance or even
instabilities in practice, as the real power grid is highly complex, variable,
and generally unknown. To tackle this problem, we employ a data-enabled
predictive control (DeePC) to perform data-driven, optimal, and robust control
for power converters. We call the converters that are operated in this way
\textit{DeePConverters}. A DeePConverter can implicitly perceive the
characteristics of the power grid from data and adjust its control strategy to
achieve optimal and robust performance. We present the modular configurations,
generalized structure, control behavior specification, detailed implementation,
and computation of DeePConverters. High-fidelity simulations and
hardware-in-the-loop (HIL) tests are provided to validate the effectiveness of
DeePConverters.

</details>


### [202] [XR Reality Check: What Commercial Devices Deliver for Spatial Tracking](https://arxiv.org/abs/2508.08642)
*Tianyi Hu,Tianyuan Du,Zhehan Qu,Maria Gorlatova*

Main category: eess.SY

TL;DR: 本文介绍了一种新颖的测试平台，用于同步评估多款XR设备的空间追踪性能，揭示了设备内部和设备间的显著性能差异，并探讨了Apple Vision Pro作为地面真值的可行性，为XR追踪评估建立了首个标准化框架。


<details>
  <summary>Details</summary>
Motivation: XR设备中不准确的空间追踪会导致虚拟物体抖动、错位和用户不适，严重限制了沉浸式体验和自然交互。缺乏标准化的评估方法和综合基准测试是当前挑战。

Method: 研究者开发了一个新颖的测试平台，能够同时、同步地在相同环境和运动条件下评估多台XR设备。利用该平台，对五款主流XR设备在16种不同场景下进行了首次全面的实证基准测试。此外，还探索了使用Apple Vision Pro替代光学动作捕捉系统作为地面真值的可行性。

Result: 研究发现设备内部性能存在显著差异，在无特征环境中误差可增加高达101%。追踪精度与视觉条件和运动动态强相关。设备间性能差异高达2.8倍，这与传感器配置和专用处理单元等硬件规格密切相关。Apple Vision Pro在相对姿态误差估计方面表现出高精度（R²=0.830），但在绝对姿态误差估计方面仍有限制（R²=0.387）。

Conclusion: 本研究建立了首个用于比较XR追踪评估的标准化框架，为研究社区提供了可复现的方法、全面的基准数据集和开源工具，以系统分析不同设备和条件下的追踪性能，从而加速XR系统更鲁棒空间传感技术的发展。

Abstract: Inaccurate spatial tracking in extended reality (XR) devices leads to virtual
object jitter, misalignment, and user discomfort, fundamentally limiting
immersive experiences and natural interactions. In this work, we introduce a
novel testbed that enables simultaneous, synchronized evaluation of multiple XR
devices under identical environmental and kinematic conditions. Leveraging this
platform, we present the first comprehensive empirical benchmarking of five
state-of-the-art XR devices across 16 diverse scenarios. Our results reveal
substantial intra-device performance variation, with individual devices
exhibiting up to 101\% increases in error when operating in featureless
environments. We also demonstrate that tracking accuracy strongly correlates
with visual conditions and motion dynamics. We also observe significant
inter-device disparities, with performance differences of up to 2.8$\times$,
which are closely linked to hardware specifications such as sensor
configurations and dedicated processing units. Finally, we explore the
feasibility of substituting a motion capture system with the Apple Vision Pro
as a practical ground truth reference. While the Apple Vision Pro delivers
highly accurate relative pose error estimates ($R^2 = 0.830$), its absolute
pose error estimation remains limited ($R^2 = 0.387$), highlighting both its
potential and its constraints for rigorous XR evaluation. This work establishes
the first standardized framework for comparative XR tracking evaluation,
providing the research community with reproducible methodologies, comprehensive
benchmark datasets, and open-source tools that enable systematic analysis of
tracking performance across devices and conditions, thereby accelerating the
development of more robust spatial sensing technologies for XR systems.

</details>


### [203] [Architecture and FPGA Implementation of Digital Time-to-Digital Converter for Sensing Applications](https://arxiv.org/abs/2508.08725)
*Zeinab Hijazi,Fatima Bzeih,Ali Ibrahim*

Main category: eess.SY

TL;DR: 本文设计了一种基于多延迟线拓扑结构的数字时间-数字转换器（DTDC），用于解决嵌入式机器学习和边缘计算中高功耗和高计算需求问题，并在FPGA上实现了低资源占用和高精度转换。


<details>
  <summary>Details</summary>
Motivation: 嵌入式机器学习和边缘计算领域面临高功耗和高计算需求挑战，迫切需要设计专用电路来降低硬件复杂性和功耗。

Method: 设计了一种基于多延迟线拓扑结构的数字时间-数字转换器（DTDC），使用VHDL语言在Xilinx Artix-7 AC701 FPGA设备上实现。

Result: 仿真结果表明该电路能有效地将输入周期转换至1ps的精度，且在目标FPGA设备上资源利用率低于1%。

Conclusion: 所设计的DTDC电路在性能（转换精度）和资源效率方面表现出色，适用于需要低功耗和低复杂度的嵌入式应用。

Abstract: Many application domains face the challenges of high-power consumption and
high computational demands, especially with the advancement in embedded machine
learning and edge computing. Designing application-specific circuits is crucial
to reducing hardware complexity and power consumption. In these perspectives,
this paper presents the design of a Digital Time-to-Digital converter (DTDC)
based on multiple delay line topologies. The DTDC is implemented in VHDL for
the Xilinx Artix-7 AC701 FPGA device. Simulation results demonstrate the
effectiveness of the circuit in converting the input period along a wide range
up to 1ps. The designed circuit is implemented with less than 1% of the
resource utilization on the target FPGA device.

</details>


### [204] [Smart Residential Community Simulator for Developing and Benchmarking Energy Management Systems](https://arxiv.org/abs/2508.09106)
*Ninad Gaikwad,Anamika Dubey*

Main category: eess.SY

TL;DR: 本文提出了一个可扩展的家庭能源管理系统（HEMS）模拟器，能够在并网和离网模式下模拟任意数量的房屋，支持多样化的分布式能源（DER）配置，并集成了真实天气和负荷数据，用于灵活的控制策略评估。


<details>
  <summary>Details</summary>
Motivation: 现有的HEMS模拟器通常针对特定的分布式能源配置和固定数量的房屋进行定制，缺乏灵活性和可扩展性，导致在支持不同配置和集成数据时需要额外的开发工作。

Method: 开发了一个可扩展的HEMS模拟器，将其作为Gymnasium环境。该模拟器能够模拟任意数量的房屋，支持每栋房屋独特的DER配置（屋顶光伏、仅电池、仅光伏或无DER），包含空调和八组电路级负荷模型。它集成了NSRDB天气数据和Pecan Street负荷数据集，并支持三种默认控制器（两种用于离网，一种用于并网场景），同时提供性能指标和可视化工具。

Result: 通过对单个房屋和具有异构DER的四户社区进行模拟，展示了模拟器的灵活性。对内置控制器进行了基准测试，评估了它们的性能和计算时间。结果表明，该模拟器能够系统地评估不同系统配置下控制策略的性能。

Conclusion: 该模拟器成功解决了现有HEMS测试工具的局限性，提供了一个高度灵活和可扩展的平台，用于在各种系统配置下开发和评估HEMS控制策略。

Abstract: Home Energy Management Systems (HEMS) are being actively developed for both
individual houses and communities to support demand response in on-grid
operation, and ensure resilience during off-grid scenarios. However, most
simulators used for closed-loop HEMS testing are tailored to a specific
distributed energy resource (DER) configuration with a fixed number of houses,
limiting flexibility and scalability. This leads to additional development
efforts to support diverse DER configurations across any number of houses and
to integrate appropriate weather and load data pipelines. To address these
limitations, we present a scalable simulator capable of modeling any number of
houses in both on-grid and off-grid modes as a Gymnasium environment. Each
house can have a unique DER configuration - Rooftop Solar Photovoltaics (PV),
Battery-only, PV-only, or no DER - and includes models for air-conditioning and
eight grouped circuit-level loads. The simulator integrates National Solar
Radiation Database (NSRDB) weather and Pecan Street load datasets, supports
three default controllers (two for off-grid, and one for on-grid scenarios),
and includes performance metrics and visualization tools. We demonstrate its
flexibility through simulations on individual houses and a four-house community
with heterogeneous DERs, benchmarking the controllers across built-in metrics
and computation time. The results highlight the simulator's capability to
systematically evaluate control policy performance under varying system
configurations.

</details>


### [205] [Comparing Building Thermal Dynamics Models and Estimation Methods for Grid-Edge Applications](https://arxiv.org/abs/2508.09118)
*Ninad Gaikwad,Kunal Shankar,Anamika Dubey,Alan Love,Olvar Bergland*

Main category: eess.SY

TL;DR: 本研究评估了两种灰箱方法（RC网络模型和结构化回归模型）在建筑热动力学建模中的性能，并比较了不同的参数估计方法，以支持电网边缘应用。


<details>
  <summary>Details</summary>
Motivation: 需要在电网边缘应用中，使用计算效率高且准确的建筑热动力学模型。

Method: 研究评估了两种灰箱建模方法：RC网络模型和结构化回归模型。对于RC网络模型，比较了非线性最小二乘法、批量估计和最大似然估计等参数估计方法。对于结构化回归模型，使用带有线性最小二乘法的Almon滞后结构进行估计。模型和方法的性能在模拟住宅和商业建筑数据上，通过三种不同的模拟类型进行评估。

Result: 抽象部分描述了对这些模型和方法在模拟住宅和商业建筑数据上进行性能评估的过程，但未给出具体的评估结果。

Conclusion: 抽象部分主要介绍了研究的目的、方法和评估框架，未包含具体的实验结果或研究结论。

Abstract: We need computationally efficient and accurate building thermal dynamics
models for use in grid-edge applications. This work evaluates two grey-box
approaches for modeling building thermal dynamics: RC-network models and
structured regression models. For RC-network models, we compare parameter
estimation methods including Nonlinear Least Squares, Batch Estimation, and
Maximum Likelihood Estimation. We use the Almon Lag Structure with Linear Least
Squares for estimating the structured regression models. The performance of
these models and methods is evaluated on simulated house and commercial
building data across three different simulation types.

</details>


### [206] [A Review On Safe Reinforcement Learning Using Lyapunov and Barrier Functions](https://arxiv.org/abs/2508.09128)
*Dhruv S. Kushwaha,Zoleikha A. Biron*

Main category: eess.SY

TL;DR: 该综述探讨了如何利用控制理论中的Lyapunov函数和障碍函数来为强化学习（RL）提供闭环稳定性与约束满足的安全保障，弥补了RL在理论保证方面的不足，并讨论了现有方法的优缺点及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 与控制理论方法相比，强化学习在计算策略的闭环稳定性以及约束满足方面缺乏理论保证。当约束违反可能导致系统故障时，确保RL系统的安全至关重要。因此，需要探讨如何将控制理论中用于安全保障的Lyapunov函数和障碍函数引入到RL中。

Method: 该综述通过详细讨论使用Lyapunov函数和障碍函数来保证安全（包括系统稳定性与训练和部署过程中的约束满足）的各种安全强化学习技术，并分析了这些方法的优点、缺点以及潜在的未来研究方向。

Result: 该综述提供了安全强化学习技术的全面概述，展示了利用Lyapunov函数和障碍函数为复杂动态系统提供安全保证的已验证潜力和广阔前景，适用于基于模型和无模型的强化学习方法。同时，也指出了现有方法的不足并提出了未来研究方向。

Conclusion: 利用Lyapunov函数和障碍函数为强化学习提供安全和稳定性保障的方法具有巨大的潜力，能够为具有操作约束的复杂动态系统提供可靠的安全保证，是未来强化学习领域的重要研究方向。

Abstract: Reinforcement learning (RL) has proven to be particularly effective in
solving complex decision-making problems for a wide range of applications. From
a control theory perspective, RL can be considered as an adaptive optimal
control scheme. Lyapunov and barrier functions are the most commonly used
certificates to guarantee system stability for a proposed/derived controller
and constraint satisfaction guarantees, respectively, in control theoretic
approaches. However, compared to theoretical guarantees available in control
theoretic methods, RL lacks closed-loop stability of a computed policy and
constraint satisfaction guarantees. Safe reinforcement learning refers to a
class of constrained problems where the constraint violations lead to partial
or complete system failure. The goal of this review is to provide an overview
of safe RL techniques using Lyapunov and barrier functions to guarantee this
notion of safety discussed (stability of the system in terms of a computed
policy and constraint satisfaction during training and deployment). The
different approaches employed are discussed in detail along with their
shortcomings and benefits to provide critique and possible future research
directions. Key motivation for this review is to discuss current theoretical
approaches for safety and stability guarantees in RL similar to control
theoretic approaches using Lyapunov and barrier functions. The review provides
proven potential and promising scope of providing safety guarantees for complex
dynamical systems with operational constraints using model-based and model-free
RL.

</details>


### [207] [An Open-Source Simulation and Data Management Tool for EnergyPlus Building Models](https://arxiv.org/abs/2508.09130)
*Ninad Gaikwad,Kasey Dettlaff,Athul Jose P,Anamika Dubey*

Main category: eess.SY

TL;DR: 开发了一个基于Plotly-Dash和PostgreSQL的开源GUI应用，用于简化EnergyPlus建筑模型模拟工作流。


<details>
  <summary>Details</summary>
Motivation: 现有EnergyPlus模拟数据生成、管理和分析方法繁琐，尤其是在处理大量建筑模型和不同模拟设置时。

Method: 开发了一个开源的、基于GUI的应用程序，使用Plotly-Dash进行界面开发，并集成了一个基于PostgreSQL的关系型数据库。该应用支持数据生成、跨热区聚合和可视化，数据库负责高效存储和检索复杂的模拟数据。

Result: 该集成框架简化了EnergyPlus模拟过程，实现了模拟数据的有效管理，支持数据分析，并有助于数据驱动的建模任务。

Conclusion: 该应用程序和数据库的集成提供了一个更高效、用户友好的解决方案，解决了EnergyPlus模拟数据管理的痛点，赋能建筑能源工程师和研究人员。

Abstract: We present a new open-source, GUI-based application created using
Plotly-Dash, along with an integrated PostgreSQL-based relational database,
developed to streamline EnergyPlus building model simulation workflows. The
application facilitates data generation, aggregation (across thermal zones),
and visualization based on customizable user preferences, while the database
efficiently stores and retrieves complex simulation data generated by
EnergyPlus. We demonstrate the need for this application and database,
emphasizing how existing approaches for generating, managing, and analyzing
EnergyPlus simulation data can be cumbersome, particularly when handling a
large number of building models with varying simulation setups. This integrated
framework enables building energy engineers and researchers to simplify their
EnergyPlus simulations, manage generated simulation data, perform data
analyses, and support data-driven modeling tasks.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [208] [Variational volume reconstruction with the Deep Ritz Method](https://arxiv.org/abs/2508.08309)
*Conor Rowan,Sumedh Soman,John A. Evans*

Main category: eess.IV

TL;DR: 本文提出一种基于深度Ritz方法的新型变分体积重建方法，可从稀疏、嘈杂的切片数据中高效重建高质量体积，无需图像分割。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机源于生物医学成像应用（如基于MRI的切片到体积重建SVR），旨在解决三个关键挑战：(i) 依赖图像分割从嘈杂灰度切片中提取边界，(ii) 需要从有限的切片平面重建体积，以及(iii) 传统基于网格方法的计算开销大。

Method: 该方法构建了一个变分目标函数，结合了：(i) 直接作用于嘈杂切片数据以避免图像分割的回归损失，以及(ii) 引入各向异性扩散以正则化重建几何形状的修改版Cahn-Hilliard能量。它使用神经网络离散化相场（深度Ritz方法），通过蒙特卡洛积分在每个优化步骤近似目标函数，并使用ADAM优化器寻找近似变分目标的最小值。

Result: 尽管随机积分可能无法得到变分问题的真实解，但该方法能够可靠地在几秒钟内生成高质量的重建体积，即使切片数据稀疏且嘈杂。

Conclusion: 该方法克服了传统体积重建的局限性，提供了一种快速、高效且无需图像分割的解决方案，适用于处理稀疏和嘈杂的切片数据，在生物医学成像等领域具有应用潜力。

Abstract: We present a novel approach to variational volume reconstruction from sparse,
noisy slice data using the Deep Ritz method. Motivated by biomedical imaging
applications such as MRI-based slice-to-volume reconstruction (SVR), our
approach addresses three key challenges: (i) the reliance on image segmentation
to extract boundaries from noisy grayscale slice images, (ii) the need to
reconstruct volumes from a limited number of slice planes, and (iii) the
computational expense of traditional mesh-based methods. We formulate a
variational objective that combines a regression loss designed to avoid image
segmentation by operating on noisy slice data directly with a modified
Cahn-Hilliard energy incorporating anisotropic diffusion to regularize the
reconstructed geometry. We discretize the phase field with a neural network,
approximate the objective at each optimization step with Monte Carlo
integration, and use ADAM to find the minimum of the approximated variational
objective. While the stochastic integration may not yield the true solution to
the variational problem, we demonstrate that our method reliably produces
high-quality reconstructed volumes in a matter of seconds, even when the slice
data is sparse and noisy.

</details>


### [209] [Preprocessing Algorithm Leveraging Geometric Modeling for Scale Correction in Hyperspectral Images for Improved Unmixing Performance](https://arxiv.org/abs/2508.08431)
*Praveen Sumanasekara,Athulya Ratnayake,Buddhi Wijenayake,Keshawa Ratnayake,Roshan Godaliyadda,Parakrama Ekanayake,Vijitha Herath*

Main category: eess.IV

TL;DR: 本文提出了一种新颖的预处理算法，用于校正高光谱解混中由尺度引起的谱变异性，显著提升了现有解混算法的性能。


<details>
  <summary>Details</summary>
Motivation: 高光谱解混中，由地形、光照、阴影等因素引起的大尺度谱签名尺度变化是主要挑战，严重影响解混精度和模型拟合。

Method: 开发了一种预处理算法，通过隔离和补偿大尺度乘性效应来校正尺度引起的谱变异性。提供了严格的数学框架。

Result: 该算法在合成和真实高光谱数据集上，一致性地提升了多种现有解混算法的性能，包括那些专门处理谱变异性的算法，误差降低接近50%。

Conclusion: 尺度校正作为一种通用且互补的预处理步骤，能显著提高现有解混方法的精度，有望成为实用高光谱解混流程中的关键组成部分。

Abstract: Spectral variability significantly impacts the accuracy and convergence of
hyperspectral unmixing algorithms. While many methods address complex spectral
variability, large-scale variations in spectral signature scale caused by
factors such as topography, illumination, and shadowing remain a major
challenge. These variations often degrade unmixing performance and complicate
model fitting. In this paper, we propose a novel preprocessing algorithm that
corrects scale-induced spectral variability prior to unmixing. By isolating and
compensating for these large-scale multiplicative effects, the algorithm
provides a cleaner input, enabling unmixing methods to focus more effectively
on modeling nonlinear spectral variability and abundance estimation. We present
a rigorous mathematical framework to describe scale variability and extensive
experimental validation of the proposed algorithm. Furthermore, the algorithm's
impact is evaluated across a broad spectrum of state-of-the-art unmixing
algorithms on two synthetic and two real hyperspectral datasets. The proposed
preprocessing step consistently improves the performance of these algorithms,
including those specifically designed to handle spectral variability, with
error reductions close to 50% in many cases. This demonstrates that scale
correction acts as a complementary step, facilitating more accurate unmixing by
existing methods. The algorithm's generality and significant impact highlight
its potential as a key component in practical hyperspectral unmixing pipelines.
The implementation code will be made publicly available upon publication.

</details>


### [210] [Frequency-Assisted Adaptive Sharpening Scheme Considering Bitrate and Quality Tradeoff](https://arxiv.org/abs/2508.08854)
*Yingxue Pang,Shijie Zhao,Haiqiang Wang,Gen Zhan,Junlin Li,Li Zhang*

Main category: eess.IV

TL;DR: 本文提出了一种名为FreqSP的频率辅助锐化级别预测模型，旨在为视频找到最佳锐化级别，以平衡视频质量和带宽成本。


<details>
  <summary>Details</summary>
Motivation: 视频锐化虽能提升质量，但会增加比特率并可能导致过度锐化，从而降低服务质量。因此，如何在保证视频质量的同时有效控制带宽成本，找到合适的锐化级别至关重要。

Method: 首先，将每个视频标记上与最佳比特率和质量权衡相对应的锐化级别作为真值。然后，FreqSP模型以未压缩的源视频作为输入，利用复杂的CNN特征和高频分量来估计最佳锐化级别。

Result: 大量的实验证明了该方法的有效性。

Conclusion: FreqSP模型能够有效预测视频的最佳锐化级别，从而在提升视频质量的同时有效控制带宽成本。

Abstract: Sharpening is a widely adopted technique to improve video quality, which can
effectively emphasize textures and alleviate blurring. However, increasing the
sharpening level comes with a higher video bitrate, resulting in degraded
Quality of Service (QoS). Furthermore, the video quality does not necessarily
improve with increasing sharpening levels, leading to issues such as
over-sharpening. Clearly, it is essential to figure out how to boost video
quality with a proper sharpening level while also controlling bandwidth costs
effectively. This paper thus proposes a novel Frequency-assisted Sharpening
level Prediction model (FreqSP). We first label each video with the sharpening
level correlating to the optimal bitrate and quality tradeoff as ground truth.
Then taking uncompressed source videos as inputs, the proposed FreqSP leverages
intricate CNN features and high-frequency components to estimate the optimal
sharpening level. Extensive experiments demonstrate the effectiveness of our
method.

</details>


### [211] [A new dataset and comparison for multi-camera frame synthesis](https://arxiv.org/abs/2508.09068)
*Conall Daly,Anil Kokaram*

Main category: eess.IV

TL;DR: 本文提出了一个新的多相机数据集，用于公平比较帧插值和视图合成方法。研究发现，在真实数据上，深度学习方法并未显著优于传统方法，3D Gaussian Splatting甚至表现不佳；但在合成场景中，3D Gaussian Splatting则表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的帧插值和视图合成数据集在时间或空间维度上存在偏差，导致难以直接公平地比较这两种技术。帧插值数据集侧重时间维度，而视图合成数据集偏向立体深度估计。

Method: 开发了一个定制的密集线性相机阵列，构建了一个新型多相机数据集。使用该数据集，评估了经典和深度学习帧插值器，并与一种视图合成方法（3D Gaussian Splatting）在视图中间帧生成任务上进行比较。

Result: 在真实图像数据上，深度学习方法并未显著优于经典方法，且3D Gaussian Splatting比帧插值器表现差高达3.5 dB PSNR。然而，在合成场景中，情况逆转，3D Gaussian Splatting比帧插值算法高出近5 dB PSNR，置信水平为95%。

Conclusion: 研究表明，帧插值和视图合成方法在真实和合成数据上的表现存在显著差异，这提示了在评估这些方法时需要考虑数据集的特性，并对现有基准的通用性提出了疑问。

Abstract: Many methods exist for frame synthesis in image sequences but can be broadly
categorised into frame interpolation and view synthesis techniques.
Fundamentally, both frame interpolation and view synthesis tackle the same
task, interpolating a frame given surrounding frames in time or space. However,
most frame interpolation datasets focus on temporal aspects with single cameras
moving through time and space, while view synthesis datasets are typically
biased toward stereoscopic depth estimation use cases. This makes direct
comparison between view synthesis and frame interpolation methods challenging.
In this paper, we develop a novel multi-camera dataset using a custom-built
dense linear camera array to enable fair comparison between these approaches.
We evaluate classical and deep learning frame interpolators against a view
synthesis method (3D Gaussian Splatting) for the task of view in-betweening.
Our results reveal that deep learning methods do not significantly outperform
classical methods on real image data, with 3D Gaussian Splatting actually
underperforming frame interpolators by as much as 3.5 dB PSNR. However, in
synthetic scenes, the situation reverses -- 3D Gaussian Splatting outperforms
frame interpolation algorithms by almost 5 dB PSNR at a 95% confidence level.

</details>


### [212] [Efficient motion-based metrics for video frame interpolation](https://arxiv.org/abs/2508.09078)
*Conall Daly,Darren Ramsook,Anil Kokaram*

Main category: eess.IV

TL;DR: 本文提出了一种基于运动场散度的新视频帧插值（VFI）质量评估指标，该指标与感知质量相关性良好且计算效率高。


<details>
  <summary>Details</summary>
Motivation: 视频帧插值算法发展迅速，但评估插值内容感知质量的方法仍是研究热点。

Method: 研究了处理运动场的简单方法，并将其用作VFI算法的视频质量指标。特别地，提出了一种基于测量运动场散度的运动指标。使用包含感知分数的BVI-VFI数据集对这些质量指标进行了评估，并与FloLPIPS等现有指标进行了比较。

Result: 提出的基于运动场散度的指标与感知分数有合理的相关性（PLCC=0.51），并且比FloLPIPS计算效率更高（快2.7倍）。该指标倾向于评估出更具视觉愉悦感的插值帧，即使这些帧在PSNR或SSIM等传统指标上得分不高。

Conclusion: 基于运动场散度的指标可以有效且高效地评估视频帧插值算法的感知质量，并能识别出传统指标可能忽视的感知上更优的插值结果。

Abstract: Video frame interpolation (VFI) offers a way to generate intermediate frames
between consecutive frames of a video sequence. Although the development of
advanced frame interpolation algorithms has received increased attention in
recent years, assessing the perceptual quality of interpolated content remains
an ongoing area of research. In this paper, we investigate simple ways to
process motion fields, with the purposes of using them as video quality metric
for evaluating frame interpolation algorithms. We evaluate these quality
metrics using the BVI-VFI dataset which contains perceptual scores measured for
interpolated sequences. From our investigation we propose a motion metric based
on measuring the divergence of motion fields. This metric correlates reasonably
with these perceptual scores (PLCC=0.51) and is more computationally efficient
(x2.7 speedup) compared to FloLPIPS (a well known motion-based metric). We then
use our new proposed metrics to evaluate a range of state of the art frame
interpolation metrics and find our metrics tend to favour more perceptual
pleasing interpolated frames that may not score highly in terms of PSNR or
SSIM.

</details>


### [213] [SharpXR: Structure-Aware Denoising for Pediatric Chest X-Rays](https://arxiv.org/abs/2508.08518)
*Ilerioluwakiiye Abolade,Emmanuel Idoko,Solomon Odelola,Promise Omoigui,Adetola Adebanwo,Aondana Iorumbur,Udunna Anazodo,Alessandro Crimi,Raymond Confidence*

Main category: eess.IV

TL;DR: SharpXR是一种结构感知的双解码器U-Net，旨在对低剂量儿科胸部X射线图像进行去噪，同时保留诊断相关特征，并在资源受限环境下提高下游肺炎分类准确性。


<details>
  <summary>Details</summary>
Motivation: 在资源匮乏地区，先进影像设备难以获取，儿科胸部X射线成像至关重要。低剂量方案可减少儿童辐射暴露，但会引入大量噪声，模糊关键解剖细节。传统去噪方法会损害精细细节，影响诊断准确性。

Method: 本文提出SharpXR，一种结构感知的双解码器U-Net，用于低剂量儿科X射线去噪。它结合了拉普拉斯引导的边缘保留解码器和一个可学习的融合模块，自适应地平衡噪声抑制和结构细节保留。为解决配对训练数据稀缺问题，该方法在儿科肺炎胸部X射线数据集上模拟了真实的泊松-高斯噪声。

Result: SharpXR在所有评估指标上均优于现有基线方法，同时保持了适用于资源受限环境的计算效率。经SharpXR去噪后的图像将下游肺炎分类准确率从88.8%提高到92.5%。

Conclusion: SharpXR通过有效去噪和细节保留，显著提高了低剂量儿科胸部X射线的诊断价值，尤其适用于资源受限的儿科护理环境。

Abstract: Pediatric chest X-ray imaging is essential for early diagnosis, particularly
in low-resource settings where advanced imaging modalities are often
inaccessible. Low-dose protocols reduce radiation exposure in children but
introduce substantial noise that can obscure critical anatomical details.
Conventional denoising methods often degrade fine details, compromising
diagnostic accuracy. In this paper, we present SharpXR, a structure-aware
dual-decoder U-Net designed to denoise low-dose pediatric X-rays while
preserving diagnostically relevant features. SharpXR combines a
Laplacian-guided edge-preserving decoder with a learnable fusion module that
adaptively balances noise suppression and structural detail retention. To
address the scarcity of paired training data, we simulate realistic
Poisson-Gaussian noise on the Pediatric Pneumonia Chest X-ray dataset. SharpXR
outperforms state-of-the-art baselines across all evaluation metrics while
maintaining computational efficiency suitable for resource-constrained
settings. SharpXR-denoised images improved downstream pneumonia classification
accuracy from 88.8% to 92.5%, underscoring its diagnostic value in low-resource
pediatric care.

</details>
