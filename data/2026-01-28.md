<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 34]
- [cs.CV](#cs.CV) [Total: 76]
- [cs.CL](#cs.CL) [Total: 46]
- [cs.RO](#cs.RO) [Total: 31]
- [eess.SY](#eess.SY) [Total: 17]
- [eess.IV](#eess.IV) [Total: 9]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Agentic Business Process Management Systems](https://arxiv.org/abs/2601.18833)
*Marlon Dumas,Fredrik Milani,David Chapela-Campa*

Main category: cs.AI

TL;DR: 本文探讨了生成式AI和自主式AI（Agentic AI）如何推动业务流程管理（BPM）进入一个新阶段，重点从自动化转向自主化，并从设计驱动转为数据驱动，利用流程挖掘技术。文章提出了自主式业务流程管理系统（A-BPMS）的架构愿景，该系统将自主性、推理和学习融入流程管理和执行，并支持从人工驱动到全自主的各类流程。


<details>
  <summary>Details</summary>
Motivation: 生成式AI和自主式AI的兴起预示着BPM的新一轮技术浪潮，与以往不同的是，此次浪潮将侧重点从自动化转移到自主化，并利用流程挖掘实现数据驱动的流程管理。

Method: 本文基于在2025年AI for BPM研讨会上的主题演讲，提出了自主式业务流程管理系统（A-BPMS）的架构愿景。文章论述了流程挖掘如何为自主式代理提供感知流程状态、推理改进机会和采取行动以维护和优化性能的基础。

Result: 文章预测，自主式业务流程管理系统（A-BPMS）能够整合自主性、推理和学习能力，革新现有流程管理和执行方式。这些系统将能够支持从人工驱动到完全自主的连续体流程。

Conclusion: 自主式AI将重新定义业务流程管理的范畴，将重点从自动化转向自主化，并利用流程挖掘实现数据驱动的优化。A-BPMS将成为支持各类流程（包括完全自主流程）的新一代平台。

Abstract: Since the early 90s, the evolution of the Business Process Management (BPM) discipline has been punctuated by successive waves of automation technologies. Some of these technologies enable the automation of individual tasks, while others focus on orchestrating the execution of end-to-end processes. The rise of Generative and Agentic Artificial Intelligence (AI) is opening the way for another such wave. However, this wave is poised to be different because it shifts the focus from automation to autonomy and from design-driven management of business processes to data-driven management, leveraging process mining techniques. This position paper, based on a keynote talk at the 2025 Workshop on AI for BPM, outlines how process mining has laid the foundations on top of which agents can sense process states, reason about improvement opportunities, and act to maintain and optimize performance. The paper proposes an architectural vision for Agentic Business Process Management Systems (A-BPMS): a new class of platforms that integrate autonomy, reasoning, and learning into process management and execution. The paper contends that such systems must support a continuum of processes, spanning from human-driven to fully autonomous, thus redefining the boundaries of process automation and governance.

</details>


### [2] [LLM Driven Design of Continuous Optimization Problems with Controllable High-level Properties](https://arxiv.org/abs/2601.18846)
*Urban Skvorc,Niki van Stein,Moritz Seiler,Britta Grimme,Thomas Bäck,Heike Trautmann*

Main category: cs.AI

TL;DR: 研究提出使用大型语言模型（LLM）和演化算法相结合的方法，生成具有明确高层景观特征的连续黑盒优化测试问题，以克服现有测试套件结构多样性不足的限制。


<details>
  <summary>Details</summary>
Motivation: 现有连续黑盒优化基准测试套件（如BBOB）的结构多样性有限，阻碍了优化基准测试的有效性。

Method: 使用LLaMEA框架，引导LLM根据自然语言描述的特定属性（如多模态性、可分离性、盆地大小均匀性、搜索空间均匀性和全局/局部最优对比度）生成优化问题代码。在内部循环中，利用基于ELA（Extended-Linear Approximation）的属性预测器对生成的候选问题进行评分，并引入ELA空间适应度共享机制来增加种群多样性并避免生成冗余景观。

Result: 通过盆地吸引力分析、统计检验和可视化检查，验证了生成的大部分函数确实具有预期的结构特征。t-SNE嵌入分析表明，生成的问题扩展了BBOB实例空间，而不是形成一个无关的簇。

Conclusion: 所提出的方法能够生成具有广泛、可解释和可复现的基准问题库，用于景观分析和下游任务（如自动化算法选择）。

Abstract: Benchmarking in continuous black-box optimisation is hindered by the limited structural diversity of existing test suites such as BBOB. We explore whether large language models embedded in an evolutionary loop can be used to design optimisation problems with clearly defined high-level landscape characteristics. Using the LLaMEA framework, we guide an LLM to generate problem code from natural-language descriptions of target properties, including multimodality, separability, basin-size homogeneity, search-space homogeneity and globallocal optima contrast. Inside the loop we score candidates through ELA-based property predictors. We introduce an ELA-space fitness-sharing mechanism that increases population diversity and steers the generator away from redundant landscapes. A complementary basin-of-attraction analysis, statistical testing and visual inspection, verifies that many of the generated functions indeed exhibit the intended structural traits. In addition, a t-SNE embedding shows that they expand the BBOB instance space rather than forming an unrelated cluster. The resulting library provides a broad, interpretable, and reproducible set of benchmark problems for landscape analysis and downstream tasks such as automated algorithm selection.

</details>


### [3] [Explainable Uncertainty Quantification for Wastewater Treatment Energy Prediction via Interval Type-2 Neuro-Fuzzy System](https://arxiv.org/abs/2601.18897)
*Qusai Khaled,Bahjat Mallak,Uzay Kaymak,Laura Genga*

Main category: cs.AI

TL;DR: 开发了一种IT2-ANFIS模型，用于预测污水处理厂的能耗，该模型能够提供可解释的不确定性估计，并能将不确定性追溯到特征、规则和实例层面。


<details>
  <summary>Details</summary>
Motivation: 污水处理厂能耗巨大，精确的能耗预测对优化运营和可持续性至关重要。现有机器学习模型仅提供点预测，缺乏对风险决策至关重要的可解释不确定性。

Method: 提出了一种区间2型自适应神经模糊推理系统（IT2-ANFIS）。该方法通过模糊规则结构生成可解释的预测区间，并将不确定性分解为特征级、规则级和实例级。

Result: IT2-ANFIS在预测性能上与一阶ANFIS相当，但具有显著降低的方差，并能提供与运行条件和输入变量相关的可解释不确定性估计。

Conclusion: IT2-ANFIS模型能够提供可解释且量化的预测不确定性，有助于污水处理厂进行风险规避决策，并识别不确定性的来源。

Abstract: Wastewater treatment plants consume 1-3% of global electricity, making accurate energy forecasting critical for operational optimization and sustainability. While machine learning models provide point predictions, they lack explainable uncertainty quantification essential for risk-aware decision-making in safety-critical infrastructure. This study develops an Interval Type-2 Adaptive Neuro-Fuzzy Inference System (IT2-ANFIS) that generates interpretable prediction intervals through fuzzy rule structures. Unlike black-box probabilistic methods, the proposed framework decomposes uncertainty across three levels: feature-level, footprint of uncertainty identify which variables introduce ambiguity, rule-level analysis reveals confidence in local models, and instance-level intervals quantify overall prediction uncertainty. Validated on Melbourne Water's Eastern Treatment Plant dataset, IT2-ANFIS achieves comparable predictive performance to first order ANFIS with substantially reduced variance across training runs, while providing explainable uncertainty estimates that link prediction confidence directly to operational conditions and input variables.

</details>


### [4] [RIFT: Reordered Instruction Following Testbed To Evaluate Instruction Following in Singular Multistep Prompt Structures](https://arxiv.org/abs/2601.18924)
*Andrew Jaffe,Noah Reicin,Jinho D. Choi*

Main category: cs.AI

TL;DR: 该研究提出了RIFT（Reordered Instruction Following Testbed）来评估大型语言模型（LLMs）在指令遵循方面的能力，并发现LLMs在处理非顺序指令时性能会显著下降，表明其指令遵循能力更多地依赖于顺序模式而非推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在复杂工作流程中的应用日益增多，但其保持指令流程的能力仍未得到充分研究。现有的基准测试未能区分任务复杂性和结构顺序的影响，因此难以分离提示拓扑对性能的影响。研究旨在解决这一问题，通过分离结构和内容来评估LLMs的指令遵循能力。

Method: 研究引入了RIFT（Reordered Instruction Following Testbed），使用重新措辞的Jeopardy!问答对，测试了两种提示结构：线性提示（按顺序进行）和跳跃提示（内容相同但需要非顺序遍历）。在对六种最先进的开源LLMs进行10,000次评估中，对比了模型在两种提示结构下的表现。

Result: 在跳跃提示条件下，LLMs的准确率下降了高达72%（相对于线性提示），这表明LLMs对位置连续性有很强的依赖性。错误分析显示，约50%的失败源于指令顺序违反和语义漂移。

Conclusion: 研究结果揭示了结构敏感性是当前LLM架构的一个基本限制，并且模型将指令遵循内化为一种顺序模式，而不是一种推理技能。这对需要非顺序控制流的应用（如工作流自动化和多智能体系统）具有直接影响。

Abstract: Large Language Models (LLMs) are increasingly relied upon for complex workflows, yet their ability to maintain flow of instructions remains underexplored. Existing benchmarks conflate task complexity with structural ordering, making it difficult to isolate the impact of prompt topology on performance. We introduce RIFT, Reordered Instruction Following Testbed, to assess instruction following by disentangling structure from content. Using rephrased Jeopardy! question-answer pairs, we test LLMs across two prompt structures: linear prompts, which progress sequentially, and jumping prompts, which preserve identical content but require non-sequential traversal. Across 10,000 evaluations spanning six state-of-the-art open-source LLMs, accuracy dropped by up to 72% under jumping conditions (compared to baseline), revealing a strong dependence on positional continuity. Error analysis shows that approximately 50% of failures stem from instruction-order violations and semantic drift, indicating that current architectures internalize instruction following as a sequential pattern rather than a reasoning skill. These results reveal structural sensitivity as a fundamental limitation in current architectures, with direct implications for applications requiring non-sequential control flow such as workflow automation and multi-agent systems.

</details>


### [5] [Neural Theorem Proving for Verification Conditions: A Real-World Benchmark](https://arxiv.org/abs/2601.18944)
*Qiyuan Xu,Xiaokun Luan,Renxi Wang,Joshua Ong Jun Leang,Peixin Wang,Haonan Li,Wenda Li,Conrad Watt*

Main category: cs.AI

TL;DR: 本文提出了NTP4VC，这是第一个针对程序验证中关键瓶颈——验证条件（VC）自动证明的真实世界多语言基准。研究评估了大型语言模型（LLMs）在VC证明上的表现，发现它们有潜力但仍面临挑战，为未来研究指明了方向。


<details>
  <summary>Details</summary>
Motivation: 自动证明VC是程序验证中的主要瓶颈，现有工具难以处理复杂的VC，导致需要大量手动证明，限制了程序的实际应用。尽管神经网络证明器在数学领域表现出色，但在程序验证的VC证明方面探索不足，迫切需要一个专门针对此问题的基准。

Method: 构建了一个名为NTP4VC的基准，从Linux和Contiki-OS等真实项目出发，利用Why3和Frama-C等工业流程生成跨Isabelle、Lean和Rocq等形式语言的语义等价测试用例。随后，在NTP4VC基准上评估了通用LLMs和为证明任务微调的LLMs。

Result: 实验结果表明，LLMs在VC证明方面展现出一定的潜力，但与完全自动化的目标仍有显著差距。这说明当前LLMs在处理程序验证特有的VC时，仍面临严峻的挑战。

Conclusion: NTP4VC是第一个真实世界多语言VC证明基准，为评估LLMs等机器学习方法在程序验证中的应用提供了一个重要平台。研究揭示了LLMs在VC证明方面的潜力和挑战，强调了该领域未来研究的必要性与机遇。

Abstract: Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.

</details>


### [6] [More at Stake: How Payoff and Language Shape LLM Agent Strategies in Cooperation Dilemmas](https://arxiv.org/abs/2601.19082)
*Trung-Kiet Huynh,Dao-Sy Duy-Minh,Thanh-Bang Cao,Phong-Hao Le,Hong-Dan Nguyen,Nguyen Lam Phu Quy,Minh-Luan Nguyen-Vo,Hong-Phat Pham,Pham Phu Hoa,Thien-Kim Than,Chi-Nguyen Tran,Huy Tran,Gia-Thoai Tran-Le,Alessio Buscemi,Le Hong Trang,The Anh Han*

Main category: cs.AI

TL;DR: 研究了支付量级和语言背景如何影响大型语言模型（LLM）在重复性社会困境中的策略行为，发现LLM表现出对激励敏感的条件策略，并存在跨语言差异。通过分类器分析LLM的策略意图，结果表明语言框架对行为有重要影响。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地作为自主代理出现在交互式和多代理环境中，理解它们的战略行为对于安全、协调以及AI驱动的社会和经济系统至关重要。

Method: 使用支付量级缩放的囚徒困境来隔离对激励强度敏感度，考察支付量级和语言背景对LLM在重复性社会困境中策略行为的影响。训练监督分类器分析LLM的决策，并将其应用于LLM的决策，以揭示模型和语言依赖的行为意图。

Result: 在不同模型和语言中观察到一致的行为模式，包括对激励敏感的条件策略和跨语言的差异。语言框架有时会匹配或超过模型架构的影响。

Conclusion: 研究结果提供了一个统一的框架来审计LLM作为策略代理的行为，并强调了具有直接影响AI治理和多代理系统设计的合作偏差。

Abstract: As LLMs increasingly act as autonomous agents in interactive and multi-agent settings, understanding their strategic behavior is critical for safety, coordination, and AI-driven social and economic systems. We investigate how payoff magnitude and linguistic context shape LLM strategies in repeated social dilemmas, using a payoff-scaled Prisoner's Dilemma to isolate sensitivity to incentive strength. Across models and languages, we observe consistent behavioral patterns, including incentive-sensitive conditional strategies and cross-linguistic divergence. To interpret these dynamics, we train supervised classifiers on canonical repeated-game strategies and apply them to LLM decisions, revealing systematic, model- and language-dependent behavioral intentions, with linguistic framing sometimes matching or exceeding architectural effects. Our results provide a unified framework for auditing LLMs as strategic agents and highlight cooperation biases with direct implications for AI governance and multi-agent system design.

</details>


### [7] [Uncertainty-Aware 3D Emotional Talking Face Synthesis with Emotion Prior Distillation](https://arxiv.org/abs/2601.19112)
*Nanhan Shen,Zhilei Liu*

Main category: cs.AI

TL;DR: 本文提出了一种名为UA-3DTalk的新型3D情感说话人脸合成方法，通过情感先验蒸馏，解决了现有方法在情感对齐和多视图融合方面的问题，实现了更优的情感表达和渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有3D情感说话人脸合成方法面临两个主要挑战：1) 音频-视觉情感对齐不佳，难以提取音频情感并精确控制情感微表情；2) 多视图融合策略单一，忽视了不确定性和特征质量差异，影响了渲染质量。

Method: UA-3DTalk包含三个核心模块：1) 先验提取模块，将音频分解为内容同步特征和个人化补充特征；2) 情感蒸馏模块，采用多模态注意力加权融合、4D高斯编码和多分辨率码本，实现精细情感提取和微表情控制；3) 不确定性变形模块，利用不确定性块估计视点特定的随机不确定性和认知不确定性，实现自适应多视图融合，并结合多头解码器优化高斯原语。

Result: 在常规和情感数据集上的实验表明，UA-3DTalk在情感对齐（E-FID）、唇同步（SyncC）和渲染质量（LPIPS）方面分别比DEGSTalk和EDTalk等先进方法提高了5.2%、3.1%和0.015。

Conclusion: UA-3DTalk通过不确定性感知和情感先验蒸馏，有效地解决了3D情感说话人脸合成中的情感对齐和多视图融合难题，显著提升了情感表达的准确性和视觉渲染的质量。

Abstract: Emotional Talking Face synthesis is pivotal in multimedia and signal processing, yet existing 3D methods suffer from two critical challenges: poor audio-vision emotion alignment, manifested as difficult audio emotion extraction and inadequate control over emotional micro-expressions; and a one-size-fits-all multi-view fusion strategy that overlooks uncertainty and feature quality differences, undermining rendering quality. We propose UA-3DTalk, Uncertainty-Aware 3D Emotional Talking Face Synthesis with emotion prior distillation, which has three core modules: the Prior Extraction module disentangles audio into content-synchronized features for alignment and person-specific complementary features for individualization; the Emotion Distillation module introduces a multi-modal attention-weighted fusion mechanism and 4D Gaussian encoding with multi-resolution code-books, enabling fine-grained audio emotion extraction and precise control of emotional micro-expressions; the Uncertainty-based Deformation deploys uncertainty blocks to estimate view-specific aleatoric (input noise) and epistemic (model parameters) uncertainty, realizing adaptive multi-view fusion and incorporating a multi-head decoder for Gaussian primitive optimization to mitigate the limitations of uniform-weight fusion. Extensive experiments on regular and emotional datasets show UA-3DTalk outperforms state-of-the-art methods like DEGSTalk and EDTalk by 5.2% in E-FID for emotion alignment, 3.1% in SyncC for lip synchronization, and 0.015 in LPIPS for rendering quality. Project page: https://mrask999.github.io/UA-3DTalk

</details>


### [8] [Exploring Weaknesses in Function Call Models via Reinforcement Learning: An Adversarial Data Augmentation Approach](https://arxiv.org/abs/2601.19122)
*Weiran Guo,Bing Bo,Shaoxiang Wu,Jingsheng Yang*

Main category: cs.AI

TL;DR: 提出了一种新颖的对抗性数据增强方法，利用强化学习来识别和利用大型语言模型（LLM）在函数调用方面的弱点，以提高其泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM函数调用能力的提升方法依赖手动标注或模型自动生成的数据进行微调，但这些方法缺乏针对性设计，受限于固定的模式和数据分布，限制了其泛化性和鲁棒性。

Method: 提出了一种基于强化学习的对抗性数据增强方法，训练一个查询模型生成对抗性查询，以挑战函数调用模型。该方法采用零和博弈的形式，查询模型和函数调用模型进行迭代交替训练。

Result: 该方法能够系统地识别和纠正LLM在与外部工具交互方面的弱点，从而提升函数调用模型的鲁棒性。

Conclusion: 通过引入基于强化学习的对抗性数据增强，可以更有效地提升LLM的函数调用能力，使其更加鲁棒，并为识别模型弱点提供了一种系统性方法。

Abstract: Function call capabilities have become crucial for Large Language Models (LLMs), enabling them to interact more effectively with external tools and APIs. Existing methods for improving the function call capabilities of LLMs rely on data obtained either through manual annotation or automated generation by models, and use this data to finetune the LLMs. However, these methods often lack targeted design and are constrained by fixed patterns and data distributions, which limits their effectiveness in enhancing the generalization and robustness of function call LLMs. To address this limitation, we propose a novel adversarial data augmentation method that employs reinforcement learning to systematically identify and target the weaknesses of function call LLMs. Our training framework introduces a query model trained with reinforcement learning (RL) to generate adversarial queries that are specifically designed to challenge function call (FC) models. This approach adopts a zero sum game formulation, where the query model and the FC model engage in iterative alternating training. Overall, our method advances the development of more robust FC models and provides a systematic way to identify and correct weaknesses in the ability of LLMs to interact with external tools.

</details>


### [9] [Length-Adaptive Interest Network for Balancing Long and Short Sequence Modeling in CTR Prediction](https://arxiv.org/abs/2601.19142)
*Zhicheng Zhang,Zhaocheng Du,Jieming Zhu,Jiwei Tang,Fengyuan Lu,Wang Jiaheng,Song-Li Wu,Qianhui Zhu,Jingyu Li,Hai-Tao Zheng,Zhenhua Dong*

Main category: cs.AI

TL;DR: 提出了一种名为LAIN（Length-Adaptive Interest Network）的即插即用框架，通过将序列长度作为条件信号来解决现代推荐系统中用户行为序列长度异质性导致的性能下降问题，该框架通过轻量级的组件实现了长短期序列建模的平衡，并在多个真实数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统中用户行为序列长度存在显著异质性（从稀疏的短期交互到丰富的长期历史），现有的点击率（CTR）模型在增加最大输入序列长度时，会因注意力极化和训练数据长度不平衡而导致短序列用户性能下降。

Method: 提出LAIN框架，包含三个轻量级组件：1. 谱长度编码器（Spectral Length Encoder）将长度映射到连续表示；2. 长度条件提示（Length-Conditioned Prompting）将全局上下文线索注入长短期行为分支；3. 长度调制注意力（Length-Modulated Attention）根据序列长度自适应调整注意力稀疏度。

Result: 在三个真实世界基准和五个强大的CTR骨干模型上的大量实验表明，LAIN一致地提高了整体性能，AUC提升高达1.15%，log loss降低2.25%。特别地，该方法在不牺牲长序列有效性的情况下，显著提高了短序列用户的准确性。

Conclusion: LAIN是一种通用、高效且可部署的解决方案，可以缓解由序列长度引起的偏差，从而在现代推荐系统中更有效地处理不同长度的用户行为序列。

Abstract: User behavior sequences in modern recommendation systems exhibit significant length heterogeneity, ranging from sparse short-term interactions to rich long-term histories. While longer sequences provide more context, we observe that increasing the maximum input sequence length in existing CTR models paradoxically degrades performance for short-sequence users due to attention polarization and length imbalance in training data. To address this, we propose LAIN(Length-Adaptive Interest Network), a plug-and-play framework that explicitly incorporates sequence length as a conditioning signal to balance long- and short-sequence modeling. LAIN consists of three lightweight components: a Spectral Length Encoder that maps length into continuous representations, Length-Conditioned Prompting that injects global contextual cues into both long- and short-term behavior branches, and Length-Modulated Attention that adaptively adjusts attention sharpness based on sequence length. Extensive experiments on three real-world benchmarks across five strong CTR backbones show that LAIN consistently improves overall performance, achieving up to 1.15% AUC gain and 2.25% log loss reduction. Notably, our method significantly improves accuracy for short-sequence users without sacrificing longsequence effectiveness. Our work offers a general, efficient, and deployable solution to mitigate length-induced bias in sequential recommendation.

</details>


### [10] [TS-Debate: Multimodal Collaborative Debate for Zero-Shot Time Series Reasoning](https://arxiv.org/abs/2601.19151)
*Patara Trirat,Jin Myung Kwak,Jay Heo,Heejun Lee,Sung Ju Hwang*

Main category: cs.AI

TL;DR: 提出了一种名为 TS-Debate 的多智能体辩论框架，用于对时间序列数据进行零样本推理，该框架通过分配专门的智能体来处理文本、视觉和数值信号，并使用验证-冲突-校准机制来提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列分析与大型语言模型（LLM）的结合存在数字保真度、模态干扰和跨模态集成困难等问题。LLM 虽然能理解时间结构，但难以精确处理数值信息。

Method: TS-Debate 框架为文本、视觉和数值信号分配了专门的专家智能体。在显式领域知识引导后，通过结构化辩论协议协调智能体的交互。评论智能体使用验证-冲突-校准机制来评估其他智能体的声明，并支持代码执行和数值查找进行程序化验证。

Result: 在三个公共基准的 20 项任务上，TS-Debate 相比标准多模态辩论基线，在准确性和性能上均有显著提升，并且在不进行任务特定的微调的情况下，保持了模态的保真度，暴露了冲突的证据，并减少了数值幻觉。

Conclusion: TS-Debate 是一种有效的、专门针对时间序列数据的多模态辩论框架，能够通过模态专业化和结构化验证机制，克服现有 LLM 在处理时间序列数据时面临的挑战，实现零样本下的时间序列推理。

Abstract: Recent progress at the intersection of large language models (LLMs) and time series (TS) analysis has revealed both promise and fragility. While LLMs can reason over temporal structure given carefully engineered context, they often struggle with numeric fidelity, modality interference, and principled cross-modal integration. We present TS-Debate, a modality-specialized, collaborative multi-agent debate framework for zero-shot time series reasoning. TS-Debate assigns dedicated expert agents to textual context, visual patterns, and numerical signals, preceded by explicit domain knowledge elicitation, and coordinates their interaction via a structured debate protocol. Reviewer agents evaluate agent claims using a verification-conflict-calibration mechanism, supported by lightweight code execution and numerical lookup for programmatic verification. This architecture preserves modality fidelity, exposes conflicting evidence, and mitigates numeric hallucinations without task-specific fine-tuning. Across 20 tasks spanning three public benchmarks, TS-Debate achieves consistent and significant performance improvements over strong baselines, including standard multimodal debate in which all agents observe all inputs.

</details>


### [11] [LocationAgent: A Hierarchical Agent for Image Geolocation via Decoupling Strategy and Evidence from Parametric Knowledge](https://arxiv.org/abs/2601.19155)
*Qiujun Li,Zijin Xiao,Xulin Wang,Zhidan Ma,Cheng Yang,Haifeng Li*

Main category: cs.AI

TL;DR: 本文提出了一种名为LocationAgent的层级化定位代理，通过将地理推理与外部工具相结合，解决了现有图像地理定位方法在开放世界和动态知识场景下的局限性。LocationAgent采用Reasoner-Executor-Recorder (RER) 架构实现层级化推理，并利用一系列线索探索工具进行证据验证。同时，引入了包含中国城市场景的CCL-Bench数据集。实验表明，LocationAgent在零样本设置下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像地理定位方法将地理知识和推理模式内化到静态模型中，导致在开放世界或需要动态知识的场景下容易出现事实幻觉和泛化能力瓶颈。作者希望通过一种新的方法来克服这些挑战。

Method: 提出层级化定位代理LocationAgent，采用Reasoner-Executor-Recorder (RER) 架构来实现层级化推理，并通过上下文压缩防止多步推理中的漂移问题。同时，设计了一系列线索探索工具用于验证地理证据，并将地理证据的验证过程外包给这些外部工具。

Result: LocationAgent在零样本设置下，相比现有方法有至少30%的性能提升。所提出的CCL-Bench数据集解决了现有数据集在中国数据稀缺和数据泄露的问题。

Conclusion: LocationAgent通过将地理推理与外部工具的证据验证相结合，成功解决了现有图像地理定位方法的局限性，并在开放世界和动态知识场景下展现出优越的性能。

Abstract: Image geolocation aims to infer capture locations based on visual content. Fundamentally, this constitutes a reasoning process composed of \textit{hypothesis-verification cycles}, requiring models to possess both geospatial reasoning capabilities and the ability to verify evidence against geographic facts. Existing methods typically internalize location knowledge and reasoning patterns into static memory via supervised training or trajectory-based reinforcement fine-tuning. Consequently, these methods are prone to factual hallucinations and generalization bottlenecks in open-world settings or scenarios requiring dynamic knowledge. To address these challenges, we propose a Hierarchical Localization Agent, called LocationAgent. Our core philosophy is to retain hierarchical reasoning logic within the model while offloading the verification of geographic evidence to external tools. To implement hierarchical reasoning, we design the RER architecture (Reasoner-Executor-Recorder), which employs role separation and context compression to prevent the drifting problem in multi-step reasoning. For evidence verification, we construct a suite of clue exploration tools that provide diverse evidence to support location reasoning. Furthermore, to address data leakage and the scarcity of Chinese data in existing datasets, we introduce CCL-Bench (China City Location Bench), an image geolocation benchmark encompassing various scene granularities and difficulty levels. Extensive experiments demonstrate that LocationAgent significantly outperforms existing methods by at least 30\% in zero-shot settings.

</details>


### [12] [Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement](https://arxiv.org/abs/2601.19170)
*Wangyang Ying,Yanchi Liu,Xujiang Zhao,Wei Cheng,Zhengzhang Chen,Wenchao Yu,Yanjie Fu,Haifeng Chen*

Main category: cs.AI

TL;DR: 提出了一种名为\model{}的多智能体框架，用于从自然语言中自动提取程序化图（工作流），该框架通过结构和逻辑细化过程来解决现有大型语言模型在提取过程中常出现的结构无效和逻辑不符的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在从自然语言中提取程序化图时，常产生结构不正确或逻辑错乱的问题，因此需要一种更有效的方法来处理这一挑战。

Method: 提出了一种名为\model{}的多智能体框架，包含三个阶段：1. 图构建智能体进行图提取；2. 模拟智能体进行结构缺陷诊断和解释；3. 语义智能体进行逻辑与文本线索的语义对齐。该框架通过自然语言反馈进行可解释和可控的迭代细化，且各智能体能独立针对不同错误类型进行处理。

Result: 与现有方法相比，\model{}在结构正确性和逻辑一致性方面均取得了显著的改进。

Conclusion: \model{}框架通过多智能体协作和迭代反馈机制，能够有效地从自然语言中提取结构正确且逻辑一致的程序化图，克服了现有大型语言模型的局限性。

Abstract: Automatically extracting workflows as procedural graphs from natural language is promising yet underexplored, demanding both structural validity and logical alignment. While recent large language models (LLMs) show potential for procedural graph extraction, they often produce ill-formed structures or misinterpret logical flows. We present \model{}, a multi-agent framework that formulates procedural graph extraction as a multi-round reasoning process with dedicated structural and logical refinement. The framework iterates through three stages: (1) a graph extraction phase with the graph builder agent, (2) a structural feedback phase in which a simulation agent diagnoses and explains structural defects, and (3) a logical feedback phase in which a semantic agent aligns semantics between flow logic and linguistic cues in the source text. Important feedback is prioritized and expressed in natural language, which is injected into subsequent prompts, enabling interpretable and controllable refinement. This modular design allows agents to target distinct error types without supervision or parameter updates. Experiments demonstrate that \model{} achieves substantial improvements in both structural correctness and logical consistency over strong baselines.

</details>


### [13] [CollectiveKV: Decoupling and Sharing Collaborative Information in Sequential Recommendation](https://arxiv.org/abs/2601.19178)
*Jingyu Li,Zhaocheng Du,Qianhui Zhu,kaiyuan Li,Zhicheng Zhang,Song-Li Wu,Chaolang Li,Pengwen Dai*

Main category: cs.AI

TL;DR: 提出了一种名为CollectiveKV的跨用户KV共享机制，通过共享大部分用户间的相似KV信息，大幅减少了推荐系统KV缓存的存储开销，同时保持或提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 主流的Transformer序列推荐模型存在计算复杂度随序列长度增加而升高的问题，导致长序列推理延迟高。KV缓存技术虽可降低延迟，但会带来巨大的存储开销，尤其是在用户量大、历史序列长的场景下。

Method: 通过SVD分析发现，KV序列中大部分信息可跨用户共享，只有小部分是用户特有的。基于此，CollectiveKV利用一个可学习的全局KV池来捕获跨用户共享的信息，推理时用户将从全局池中检索共享KV，并与低维度的用户特有KV拼接，形成最终KV。

Result: 在五个序列推荐模型和三个数据集上的实验表明，CollectiveKV可以将KV缓存压缩至原始大小的0.8%，同时保持或提升了模型性能。

Conclusion: CollectiveKV是一种有效的跨用户KV共享机制，能够显著降低长序列推荐场景下的KV缓存存储成本，且不会牺牲或反而能提升推荐模型的性能。

Abstract: Sequential recommendation models are widely used in applications, yet they face stringent latency requirements. Mainstream models leverage the Transformer attention mechanism to improve performance, but its computational complexity grows with the sequence length, leading to a latency challenge for long sequences. Consequently, KV cache technology has recently been explored in sequential recommendation systems to reduce inference latency. However, KV cache introduces substantial storage overhead in sequential recommendation systems, which often have a large user base with potentially very long user history sequences. In this work, we observe that KV sequences across different users exhibit significant similarities, indicating the existence of collaborative signals in KV. Furthermore, we analyze the KV using singular value decomposition (SVD) and find that the information in KV can be divided into two parts: the majority of the information is shareable across users, while a small portion is user-specific. Motivated by this, we propose CollectiveKV, a cross-user KV sharing mechanism. It captures the information shared across users through a learnable global KV pool. During inference, each user retrieves high-dimensional shared KV from the pool and concatenates them with low-dimensional user-specific KV to obtain the final KV. Experiments on five sequential recommendation models and three datasets show that our method can compress the KV cache to only 0.8% of its original size, while maintaining or even enhancing model performance.

</details>


### [14] [CoReTab: Improving Multimodal Table Understanding with Code-driven Reasoning](https://arxiv.org/abs/2601.19193)
*Van-Quang Nguyen,Takayuki Okatani*

Main category: cs.AI

TL;DR: 提出CoReTab框架，通过代码驱动的多步推理生成可验证的表格理解数据集，并用于微调多模态大模型，显著提升了模型在表格问答、事实核查和结构理解方面的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态表格理解数据集缺乏多步推理监督，导致模型生成的答案准确性低且难以解释。

Method: 开发了CoReTab框架，将多步推理与可执行的Python代码相结合，生成可扩展、可解释且可自动验证的标注。利用该框架构建了一个包含11.5万个样本的数据集，并通过三阶段流水线对开源多模态大模型进行了微调。

Result: 在17个MMTab基准测试中，使用CoReTab微调的模型在表格问答、事实核查和表格结构理解方面，分别比使用MMTab微调的模型取得了+6.2%、+5.7%和+25.6%的显著提升，同时生成了透明且可验证的推理过程。

Conclusion: CoReTab是一个强大且可泛化的监督学习框架，能够有效提升多模态表格理解中的多步推理能力。

Abstract: Existing datasets for multimodal table understanding, such as MMTab, primarily provide short factual answers without explicit multi-step reasoning supervision. Models trained on these datasets often generate brief responses that offers insufficient accuracy and limited interpretability into how these models arrive at the final answer. We introduce CoReTab, a code-driven reasoning framework that produces scalable, interpretable, and automatically verifiable annotations by coupling multi-step reasoning with executable Python code. Using the CoReTab framework, we curate a dataset of 115K verified samples averaging 529 tokens per response and fine-tune open-source MLLMs through a three-stage pipeline. We evaluate the resulting model trained on CoReTab across 17 MMTab benchmarks spanning table question answering, fact verification, and table structure understanding. Our model achieves significant gains of +6.2%, +5.7%, and +25.6%, respectively, over MMTab-trained baselines, while producing transparent and verifiable reasoning traces. These results establish CoReTab as a robust and generalizable supervision framework for improving multi-step reasoning in multimodal table understanding.

</details>


### [15] [MAGNET: Towards Adaptive GUI Agents with Memory-Driven Knowledge Evolution](https://arxiv.org/abs/2601.19199)
*Libo Sun,Jiwen Zhang,Siyuan Wang,Zhongyu Wei*

Main category: cs.AI

TL;DR: 提出了一种名为MAGNET的内存驱动自适应移动GUI代理框架，通过结合静态记忆和过程记忆来应对UI频繁更新的问题，提高了代理的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型驱动的移动GUI代理在执行任务时，由于UI界面的频繁更新和工作流程的重组，导致基于历史数据训练的代理失效。然而，UI的表面变化并未改变其功能语义和任务意图的根本稳定性。

Method: 开发了MAGNET框架，该框架包含双层内存：静态记忆将视觉特征与稳定的功能语义联系起来，用于鲁棒的动作定位；过程记忆捕获跨不同工作流程的稳定任务意图。引入了一种动态内存演化机制，通过优先访问频繁使用的知识来持续优化内存。

Result: 在AndroidWorld基准测试中，MAGNET代理在在线评估中表现出显著的性能提升，在离线基准测试中，在分布变化的情况下也证实了稳定收益。这表明利用界面变化中的稳定结构可以提高代理在不断变化软件环境中的性能和泛化能力。

Conclusion: 通过利用界面变化中的稳定结构，可以显著提高移动GUI代理在不断变化软件环境中的性能和泛化能力。MAGNET框架通过其双层记忆机制有效地解决了UI更新带来的挑战。

Abstract: Mobile GUI agents powered by large foundation models enable autonomous task execution, but frequent updates altering UI appearance and reorganizing workflows cause agents trained on historical data to fail. Despite surface changes, functional semantics and task intents remain fundamentally stable. Building on this insight, we introduce MAGNET, a memory-driven adaptive agent framework with dual-level memory: stationary memory linking diverse visual features to stable functional semantics for robust action grounding and procedural memory capturing stable task intents across varying workflows. We propose a dynamic memory evolution mechanism that continuously refines both memories by prioritizing frequently accessed knowledge. Online benchmark AndroidWorld evaluations show substantial improvements over baselines, while offline benchmarks confirm consistent gains under distribution shifts. These results validate that leveraging stable structures across interface changes improves agent performance and generalization in evolving software environments.

</details>


### [16] [MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning](https://arxiv.org/abs/2601.19204)
*Zhixi Cai,Fucai Ke,Kevin Leo,Sukai Huang,Maria Garcia de la Banda,Peter J. Stuckey,Hamid Rezatofighi*

Main category: cs.AI

TL;DR: 提出了一种名为MATA的多智能体分层可训练自动机系统，用于提高视觉推理的可解释性和准确性，通过一个“超级智能体”来协调其他执行特定任务的“子智能体”，并引入了MATA-SFT-90K数据集用于监督微调。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在复杂查询下容易产生幻觉且缺乏可解释性，而现有的组合式方法通常依赖单一智能体或手动设计的流程，无法有效地进行智能体间的协作与竞争。

Method: MATA是一个分层有限状态自动机系统，顶层由一个可训练的“超级智能体”控制状态（即选择智能体）的转换。每个“子智能体”对应一个状态，并执行一个基于规则的小型子自动机。所有智能体共享内存，实现透明的执行历史记录。通过构建过渡轨迹树并转换为内存到下一个状态的配对，创建了MATA-SFT-90K数据集用于监督微调。

Result: 通过对超级智能体的过渡策略进行监督微调，使其能够理解查询和智能体的能力，并选择最优智能体。MATA在多个视觉推理基准上取得了优于现有模型（包括整体式和组合式方法）的最新结果。

Conclusion: MATA作为一种多智能体分层自动机系统，能够通过有效的智能体协作和竞争，克服现有视觉语言模型的局限性，在视觉推理任务上取得优异表现，并提高了模型的可解释性。

Abstract: Recent vision-language models have strong perceptual ability but their implicit reasoning is hard to explain and easily generates hallucinations on complex queries. Compositional methods improve interpretability, but most rely on a single agent or hand-crafted pipeline and cannot decide when to collaborate across complementary agents or compete among overlapping ones. We introduce MATA (Multi-Agent hierarchical Trainable Automaton), a multi-agent system presented as a hierarchical finite-state automaton for visual reasoning whose top-level transitions are chosen by a trainable hyper agent. Each agent corresponds to a state in the hyper automaton, and runs a small rule-based sub-automaton for reliable micro-control. All agents read and write a shared memory, yielding transparent execution history. To supervise the hyper agent's transition policy, we build transition-trajectory trees and transform to memory-to-next-state pairs, forming the MATA-SFT-90K dataset for supervised finetuning (SFT). The finetuned LLM as the transition policy understands the query and the capacity of agents, and it can efficiently choose the optimal agent to solve the task. Across multiple visual reasoning benchmarks, MATA achieves the state-of-the-art results compared with monolithic and compositional baselines. The code and dataset are available at https://github.com/ControlNet/MATA.

</details>


### [17] [Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection](https://arxiv.org/abs/2601.19245)
*Yongxin Deng,Zhen Fang,Yixuan Li,Ling Chen*

Main category: cs.AI

TL;DR: 本文提出了一种名为SpikeScore的新方法，用于检测大语言模型（LLMs）在不同领域生成的幻觉内容，该方法通过量化多轮对话中的不确定性波动来实现良好的跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法在跨领域应用时性能下降，导致LLMs难以在真实世界中广泛部署，因此需要一种能够跨领域泛化的幻觉检测方法。

Method: 研究者模拟了LLM初始回复后的多轮对话，并观察到幻觉内容引发的对话比事实性对话具有更大的不确定性波动。基于此现象，提出SpikeScore，用于量化多轮对话中的不确定性波动。

Result: SpikeScore能够有效地区分幻觉和非幻觉回复，并且在跨领域泛化能力和检测性能上优于现有基线方法和专门的泛化方法。

Conclusion: SpikeScore是一种有效且具有良好跨领域泛化能力的幻觉检测方法，能够克服现有方法在不同领域应用时的局限性。

Abstract: Hallucination detection is critical for deploying large language models (LLMs) in real-world applications. Existing hallucination detection methods achieve strong performance when the training and test data come from the same domain, but they suffer from poor cross-domain generalization. In this paper, we study an important yet overlooked problem, termed generalizable hallucination detection (GHD), which aims to train hallucination detectors on data from a single domain while ensuring robust performance across diverse related domains. In studying GHD, we simulate multi-turn dialogues following LLMs initial response and observe an interesting phenomenon: hallucination-initiated multi-turn dialogues universally exhibit larger uncertainty fluctuations than factual ones across different domains. Based on the phenomenon, we propose a new score SpikeScore, which quantifies abrupt fluctuations in multi-turn dialogues. Through both theoretical analysis and empirical validation, we demonstrate that SpikeScore achieves strong cross-domain separability between hallucinated and non-hallucinated responses. Experiments across multiple LLMs and benchmarks demonstrate that the SpikeScore-based detection method outperforms representative baselines in cross-domain generalization and surpasses advanced generalization-oriented methods, verifying the effectiveness of our method in cross-domain hallucination detection.

</details>


### [18] [GLOVE: Global Verifier for LLM Memory-Environment Realignment](https://arxiv.org/abs/2601.19249)
*Xingkun Yin,Hongyang Du*

Main category: cs.AI

TL;DR: 提出了一种名为 GLOVE 的新框架，通过引入相对真理的概念，并在检索到的记忆与新观察之间探测不一致性，从而在没有地面真值监督的情况下，实现大型语言模型（LLM）记忆系统的自我校正和环境再对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数增强记忆的 LLM 方法依赖于外部评估器或内部模型反思来保证记忆的有效性，这在动态漂移的实际环境中往往失效。

Method: GLOVE 框架通过主动探测检索到的记忆与新观察之间的不一致性，引入了“相对真理”的概念，实现了记忆与环境的再对齐，无需地面真值监督或对模型内省的强依赖。

Result: 在涉及网页导航、规划和控制的多个基准测试上，GLOVE 显著提高了智能体的成功率，即使在引入了受控的环境漂移以增加非平稳性。

Conclusion: GLOVE 提供了一种强大的机制，使 LLM 能够在没有地面真值或强内省能力的情况下，通过检测和纠正记忆与环境之间的不一致性来实现记忆的自我演化和对齐，为构建可自我演进的认知智能体铺平了道路。

Abstract: Most existing memory-enhanced Large Language Model (LLM) approaches implicitly assume that memory validity can be established either through external evaluators that provide task-specific success signals or through internal model cognition, such as reflection, for editing memory entries. However, these assumptions often break down in practical environments with dynamic drifts. We propose the Global Verifier (GLOVE), a framework that introduces a new design dimension for LLM memory systems by establishing a relative notion of truth. Through active probing to detect inconsistencies between retrieved memories and fresh observations, GLOVE enables memory-environment realignment by verifying and updating memory without access to ground-truth supervision or strong reliance on model introspection. We evaluate GLOVE on diverse benchmarks spanning web navigation, planning, and control, augmented with controlled environmental drifts that introduce non-stationarity beyond the original benchmark settings. Our results show that GLOVE substantially improves agent success rates, suggesting a robust pathway to cognitive agents capable of self-evolving.

</details>


### [19] [Curiosity Driven Knowledge Retrieval for Mobile Agents](https://arxiv.org/abs/2601.19306)
*Sijia Li,Xiaoyu Tan,Shahir Ali,Niels Schmidt,Gengchen Ma,Xihe Qiu*

Main category: cs.AI

TL;DR: 提出了一种基于好奇心驱动的知识检索框架，通过计算不确定性得分来触发外部知识检索，并将检索到的信息组织成结构化的AppCards，用于增强移动代理的推理能力，以提高智能手机自动化在复杂场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有移动代理在复杂应用中的性能受限于不完整的知识和对未知环境的弱泛化能力。

Method: 提出一个好奇心驱动的知识检索框架，将执行过程中的不确定性形式化为好奇心得分。当得分超过阈值时，系统从文档、代码库和历史轨迹中检索外部信息，并组织成结构化的AppCards。代理在执行过程中选择性地整合相关的AppCards到其推理过程中。

Result: 在AndroidWorld基准测试中，该框架与GPT-5结合使用，平均性能提高了六个百分点，达到了88.8%的新的SOTA成功率。AppCards在多步和跨应用任务中尤其有效，性能提升程度与骨干模型相关。

Conclusion: AppCards框架通过弥补知识盲点和提高规划可靠性，显著增强了移动代理在复杂应用中的性能，减少了歧义，缩短了探索时间，并支持了稳定的执行轨迹。

Abstract: Mobile agents have made progress toward reliable smartphone automation, yet performance in complex applications remains limited by incomplete knowledge and weak generalization to unseen environments. We introduce a curiosity driven knowledge retrieval framework that formalizes uncertainty during execution as a curiosity score. When this score exceeds a threshold, the system retrieves external information from documentation, code repositories, and historical trajectories. Retrieved content is organized into structured AppCards, which encode functional semantics, parameter conventions, interface mappings, and interaction patterns. During execution, an enhanced agent selectively integrates relevant AppCards into its reasoning process, thereby compensating for knowledge blind spots and improving planning reliability. Evaluation on the AndroidWorld benchmark shows consistent improvements across backbones, with an average gain of six percentage points and a new state of the art success rate of 88.8\% when combined with GPT-5. Analysis indicates that AppCards are particularly effective for multi step and cross application tasks, while improvements depend on the backbone model. Case studies further confirm that AppCards reduce ambiguity, shorten exploration, and support stable execution trajectories. Task trajectories are publicly available at https://lisalsj.github.io/Droidrun-appcard/.

</details>


### [20] [Balancing Sustainability And Performance: The Role Of Small-Scale Llms In Agentic Artificial Intelligence Systems](https://arxiv.org/abs/2601.19311)
*Anh Khoa Ngo Ho,Martin Chauvin,Simon Gosset,Philippe Cordier,Boris Gamazaychikov*

Main category: cs.AI

TL;DR: 研究表明，使用规模较小的语言模型进行推理可以降低能耗，同时保持响应速度和输出质量，为可持续人工智能设计提供了实际指导。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在智能体AI系统中日益普及，其推理过程的能耗可能对可持续性构成重大挑战。

Method: 对不同规模的语言模型进行比较分析，量化效率与性能之间的权衡。研究了最佳批次大小配置和计算资源分配。

Result: 规模较小的开源模型可以降低能耗，同时保持任务质量。优化批次大小和资源分配有助于提高效率。

Conclusion: 规模较小的语言模型可以在不牺牲性能的情况下实现更可持续的人工智能。提出了实用的指导方针，以设计可扩展、环保的人工智能系统。

Abstract: As large language models become integral to agentic artificial intelligence systems, their energy demands during inference may pose significant sustainability challenges. This study investigates whether deploying smaller-scale language models can reduce energy consumption without compromising responsiveness and output quality in a multi-agent, real-world environments. We conduct a comparative analysis across language models of varying scales to quantify trade-offs between efficiency and performance. Results show that smaller open-weights models can lower energy usage while preserving task quality. Building on these findings, we propose practical guidelines for sustainable artificial intelligence design, including optimal batch size configuration and computation resource allocation. These insights offer actionable strategies for developing scalable, environmentally responsible artificial intelligence systems.

</details>


### [21] [SETA: Statistical Fault Attribution for Compound AI Systems](https://arxiv.org/abs/2601.19337)
*Sayak Chowdhury,Meenakshi D'Souza*

Main category: cs.AI

TL;DR: 提出了一种模块化鲁棒性测试框架，用于测试由多个互联神经网络组成的AI系统，能够进行组件级分析和错误传播推理，并已成功应用于真实的铁路检测系统。


<details>
  <summary>Details</summary>
Motivation: 现有的鲁棒性测试技术无法很好地扩展到由多个互联神经网络组成的复杂AI系统，需要一种新的方法来解决这个问题。

Method: 开发了一个模块化鲁棒性测试框架，该框架支持组件级系统分析和错误传播推理，并且不受模型架构和数据模态的限制。

Result: 该框架能够对多网络AI系统进行细粒度的鲁棒性分析，超越了传统的端到端指标。在真实的自主铁路检测系统上的应用也取得了成功。

Conclusion: 所提出的模块化鲁棒性测试框架有效地解决了多网络AI系统鲁棒性测试的挑战，能够进行深入的组件级分析和错误传播推理，并已在实际应用中得到验证。

Abstract: Modern AI systems increasingly comprise multiple interconnected neural networks to tackle complex inference tasks. Testing such systems for robustness and safety entails significant challenges. Current state-of-the-art robustness testing techniques, whether black-box or white-box, have been proposed and implemented for single-network models and do not scale well to multi-network pipelines. We propose a modular robustness testing framework that applies a given set of perturbations to test data. Our testing framework supports (1) a component-wise system analysis to isolate errors and (2) reasoning about error propagation across the neural network modules. The testing framework is architecture and modality agnostic and can be applied across domains. We apply the framework to a real-world autonomous rail inspection system composed of multiple deep networks and successfully demonstrate how our approach enables fine-grained robustness analysis beyond conventional end-to-end metrics.

</details>


### [22] [PROTEUS: SLA-Aware Routing via Lagrangian RL for Multi-LLM Serving Systems](https://arxiv.org/abs/2601.19402)
*Amit Singh Bhatti,Vishal Vaddina,Dagnachew Birru*

Main category: cs.AI

TL;DR: 本文提出了一种名为PROTEUS的LLM路由系统，它允许用户在运行时直接指定准确性目标（tau），而不是依赖于复杂的离线参数调整。PROTEUS利用拉格朗日对偶控制和学习到的对偶变量lambda，能够将指定的准确性目标转化为路由决策，并在训练一次后即可覆盖整个准确性谱。在RouterBench和SPROUT数据集上的实验表明，PROTEUS在满足准确性地板要求方面表现出色，并且可以实现显著的成本节约。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM模型服务系统在处理不同客户需求（如成本、服务质量、查询重要性）时，其路由参数调整复杂且效果难以预测，导致难以直接满足客户指定的准确性目标。研究旨在解决这一问题，让路由系统能够直接接受准确性目标作为运行时输入。

Method: PROTEUS采用拉格朗日对偶控制（Lagrangian dual control）的方法。通过一个学习到的对偶变量lambda来跟踪训练过程中的约束违反情况，并以此来调整策略网络。这种机制使得路由系统能够根据运行时输入的准确性目标tau，动态地做出路由决策，以满足这些目标。

Result: PROTEUS在RouterBench和SPROUT数据集上进行了评估。实验结果显示，PROTEUS能够持续满足或超过设定的准确性目标（tau），目标-响应相关性高达0.97-0.98。与基线模型OmniRouter相比，PROTEUS在满足准确性地板要求方面表现更优。单个模型即可覆盖0.85到0.95的准确性范围，并且在RouterBench和SPROUT上的准确率分别达到90.1%和94.0%，接近最优水平。同时，与固定模型的部署相比，PROTEUS可以节省高达89.8%的成本。

Conclusion: PROTEUS是一个有效的LLM路由系统，它通过直接接受运行时准确性目标（tau）并利用拉格朗日对偶控制，实现了对LLM服务质量的精确控制，同时显著降低了运行成本。该系统无需针对不同准确性目标进行重新训练，具有广泛的适用性和高效性。

Abstract: Production LLM deployments serve diverse workloads where cost and quality requirements vary by customer tier, time of day, and query criticality. Model serving systems accept latency SLOs directly. LLM routers do not. They force operators to tune parameters offline and guess what accuracy might result. The relationship between parameters and outcomes is indirect, non-monotonic, and dataset-dependent. Operators need to specify accuracy targets, not infer them from opaque settings. We present PROTEUS (Polymorphic Router for Operational Target Enforcement with Unified SLA), a router that accepts accuracy targets tau as runtime input. PROTEUS uses Lagrangian dual control. A learned dual variable lambda tracks constraint violations during training and conditions the policy network. This lets the router translate specified tau values into routing decisions that satisfy them. A single trained model serves the full accuracy spectrum without retraining.We evaluate on RouterBench (11 models, 405K queries) and SPROUT (14 models, 45K queries). PROTEUS achieves consistent floor compliance where accuracy meets or exceeds tau. The target-response correlation reaches 0.97 to 0.98. The closest baseline, OmniRouter, meets floors only 22% of the time despite also using Lagrangian optimization. PROTEUS operates across tau in [0.85, 0.95] from a single model. On RouterBench it achieves 90.1% accuracy, within 1.3% of oracle. On SPROUT it achieves 94.0% accuracy, within 4.6% of oracle. Cost savings reach 89.8% versus the best fixed model.

</details>


### [23] [RPO:Reinforcement Fine-Tuning with Partial Reasoning Optimization](https://arxiv.org/abs/2601.19404)
*Hongzhu Yi,Xinming Wang,Zhenghao zhang,Tianyu Zong,Yuanxiang Wang,Jun Xie,Tao Yu,Haopeng Jin,Zhepeng Wang,Kaixin Xu,Feng Chen,Jiahuan Chen,Yujia Yang,Zhenyu Guan,Bingkang Shi,Jungang Xu*

Main category: cs.AI

TL;DR: 本文提出了一种名为RPO（Reinforcement Fine-Tuning with Partial Reasoning Optimization）的即插即用算法，通过仅生成推理路径的后缀来大幅降低大型语言模型强化微调的计算开销，在不牺牲性能的情况下显著加速了训练过程。


<details>
  <summary>Details</summary>
Motivation: 传统的强化微调算法在训练时需要生成完整的推理路径，导致计算成本高昂。研究者希望找到一种方法来降低这一成本。

Method: 作者分析了推理路径不同部分对最终结果正确性的影响，并基于此提出了RPO算法。RPO通过经验缓存生成推理路径的后缀进行训练，从而减少了训练过程中的token生成量。

Result: RPO算法在训练阶段将token生成量减少了约95%，显著降低了理论时间开销。与全路径强化微调算法相比，RPO将1.5B模型的训练时间缩短了90%，7B模型的训练时间缩短了72%。同时，RPO可以与GRPO和DAPO等算法集成，实现训练加速且性能相当。

Conclusion: RPO是一种有效的强化微调优化算法，能够显著减少大型语言模型训练的计算开销，并可与现有算法集成以进一步加速训练，同时保持模型性能。

Abstract: Within the domain of large language models, reinforcement fine-tuning algorithms necessitate the generation of a complete reasoning trajectory beginning from the input query, which incurs significant computational overhead during the rollout phase of training. To address this issue, we analyze the impact of different segments of the reasoning path on the correctness of the final result and, based on these insights, propose Reinforcement Fine-Tuning with Partial Reasoning Optimization (RPO), a plug-and-play reinforcement fine-tuning algorithm. Unlike traditional reinforcement fine-tuning algorithms that generate full reasoning paths, RPO trains the model by generating suffixes of the reasoning path using experience cache. During the rollout phase of training, RPO reduces token generation in this phase by approximately 95%, greatly lowering the theoretical time overhead. Compared with full-path reinforcement fine-tuning algorithms, RPO reduces the training time of the 1.5B model by 90% and the 7B model by 72%. At the same time, it can be integrated with typical algorithms such as GRPO and DAPO, enabling them to achieve training acceleration while maintaining performance comparable to the original algorithms. Our code is open-sourced at https://github.com/yhz5613813/RPO.

</details>


### [24] [Fuzzy expert system for the process of collecting and purifying acidic water: a digital twin approach](https://arxiv.org/abs/2601.19527)
*Temirbolat Maratuly,Pakizar Shamoi,Timur Samigulin*

Main category: cs.AI

TL;DR: 本文提出了一种基于模糊专家系统的数字孪生方法，用于自动化酸性废水处理过程，通过模拟人类推理来维持关键参数，并使用MATLAB和OPC DA进行建模和实时数据交换，通过多种指标评估了系统的性能。


<details>
  <summary>Details</summary>
Motivation: 酸性废水（Sour water）的处理对于减少排放、降低腐蚀风险、实现水再利用以及降低运营成本至关重要。此外，自动化处理过程可以减少人为操作带来的工人伤害风险。

Method: 开发了一个模糊专家系统，并结合使用Honeywell UniSim Design R492创建了一个定制的数字孪生来模拟工业过程。使用MATLAB的系统识别技术对阀门动力学进行建模，并使用OPC DA建立模拟器与控制器之间的实时数据交换。模糊控制器采用分程控制策略，并通过21种不同的初始压力条件和5种去模糊化策略进行了105种场景的测试。使用误差指标和动态响应指标评估系统性能。开发了一个基于Python Streamlit的Web界面。

Result: 该系统能够通过模糊专家系统和数字孪生模拟人类的推理过程，有效地控制关键参数。系统在多种测试场景下均表现出良好的性能，并可通过误差和动态响应指标进行量化评估。

Conclusion: 所提出的模糊专家系统结合数字孪生方法，能够有效地自动化酸性废水处理过程，并具有通用性，可应用于其他领域。

Abstract: Purifying sour water is essential for reducing emissions, minimizing corrosion risks, enabling the reuse of treated water in industrial or domestic applications, and ultimately lowering operational costs. Moreover, automating the purification process helps reduce the risk of worker harm by limiting human involvement. Crude oil contains acidic components such as hydrogen sulfide, carbon dioxide, and other chemical compounds. During processing, these substances are partially released into sour water. If not properly treated, sour water poses serious environmental threats and accelerates the corrosion of pipelines and equipment. This paper presents a fuzzy expert system, combined with a custom-generated digital twin, developed from a documented industrial process to maintain key parameters at desired levels by mimicking human reasoning. The control strategy is designed to be simple and intuitive, allowing junior or non-expert personnel to interact with the system effectively. The digital twin was developed using Honeywell UniSim Design R492 to simulate real industrial behavior accurately. Valve dynamics were modeled through system identification in MATLAB, and real-time data exchange between the simulator and controller was established using OPC DA. The fuzzy controller applies split-range control to two valves and was tested under 21 different initial pressure conditions using five distinct defuzzification strategies, resulting in a total of 105 unique test scenarios. System performance was evaluated using both error-based metrics (MSE, RMSE, MAE, IAE, ISE, ITAE) and dynamic response metrics, including overshoot, undershoot, rise time, fall time, settling time, and steady-state error. A web-based simulation interface was developed in Python using the Streamlit framework. Although demonstrated here for sour water treatment, the proposed fuzzy expert system is general-purpose.

</details>


### [25] [Benchmarks Saturate When The Model Gets Smarter Than The Judge](https://arxiv.org/abs/2601.19532)
*Marthe Ballon,Andres Algaba,Brecht Verbeken,Vincent Ginis*

Main category: cs.AI

TL;DR: 该研究提出了一个改进的数学问题数据集 Omni-MATH-2，通过手动修订解决了原始数据集中存在的错误和评估方法不准确的问题，并分析了评估者（包括 GPT-5 mini 和 Omni-Judge）引入的误差。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）基准测试因数据集不准确和评估方法存在问题而影响其有效性，需要更精确的评估工具来追踪 LLM 的进展。

Method: 研究者手动修订了 Omni-MATH 数据集，创建了一个包含 4181 个问题的干净、精确答案子集和一个包含 247 个问题的标记、非标准子集。修订过程包括检查 LaTeX 可编译性、可解性和可验证性，并添加缺失信息、标记特殊问题类型（如证明、估算、图像）以及移除无关内容。同时，通过比较 GPT-5 mini 和原始 Omni-Judge，分析了评估者引入的误差。

Result: Omni-MATH-2 数据集显著降低了数据集引入的噪声，提供了更精确的模型性能评估。评估者分析表明，Omni-Judge 在 96.4% 的分歧情况中是错误的，其评估能力存在严重问题。研究发现，随着问题难度增加，需要更优秀的评估者来避免评估误差掩盖模型间的真实差异。此外，两种评估者都未能识别出标记问题子集中的失败模式。

Conclusion: 数据集质量和评估者可靠性对于开发准确的模型性能基准测试至关重要。特别是，随着模型能力的提升，依赖于评估者的基准测试需要更可靠、更智能的评估机制，以准确反映模型间的性能差异，避免评估误差成为瓶颈。

Abstract: Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset ($n{=}4181$) and a tagged, non-standard subset ($n{=}247$). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in $96.4\%$ of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance.

</details>


### [26] [Learning Adaptive Parallel Execution for Efficient Code Localization](https://arxiv.org/abs/2601.19568)
*Ke Xu,Siyang Xiao,Ming Liang,Yichen Yu,Zhixiang Wang,Jingxuan Xu,Dajun Chen,Wei Jiang,Yong Li*

Main category: cs.AI

TL;DR: 提出了一种名为 FuseSearch 的新方法，通过联合优化质量和效率来解决代码定位中的冗余工具调用问题，在 SWE-bench Verified 数据集上取得了最先进的性能，并显著提高了速度并减少了资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的并发代码定位工具存在高冗余调用率（34.9%），抵消了并行化的好处，导致效率低下。研究旨在解决这一瓶颈，提升自动化软件开发流水线的效率。

Method: 将并行代码定位重构为联合质量-效率优化任务。定义了“工具效率”为唯一信息增益与调用次数之比。采用两阶段训练方法：先进行 SFT（监督式微调），再进行 RL（强化学习），以学习适应性的并行策略。FuseSearch 能够根据任务上下文动态调整搜索宽度，从探索阶段演变到细化阶段。

Result: 在 SWE-bench Verified 数据集上，FuseSearch-4B 达到了最先进的性能，文件级别 F1 分数为 84.7%，函数级别 F1 分数为 56.4%。与现有方法相比，FuseSearch 实现了 93.6% 的速度提升，同时减少了 67.7% 的调用轮次和 68.9% 的 token 使用量。

Conclusion: 效率感知的训练能够通过消除冗余信号来自然地提高代码定位的质量，从而实现高性能且成本效益高的代码定位代理。FuseSearch 通过联合优化质量和效率，有效解决了现有方法的冗余调用问题。

Abstract: Code localization constitutes a key bottleneck in automated software development pipelines. While concurrent tool execution can enhance discovery speed, current agents demonstrate a 34.9\% redundant invocation rate, which negates parallelism benefits. We propose \textbf{FuseSearch}, reformulating parallel code localization as a \textbf{joint quality-efficiency optimization} task. Through defining \textbf{tool efficiency} -- the ratio of unique information gain to invocation count -- we utilize a two-phase SFT and RL training approach for learning adaptive parallel strategies. Different from fixed-breadth approaches, FuseSearch dynamically modulates search breadth according to task context, evolving from exploration phases to refinement stages. Evaluated on SWE-bench Verified, FuseSearch-4B achieves SOTA-level performance (84.7\% file-level and 56.4\% function-level $F_1$ scores) with 93.6\% speedup, utilizing 67.7\% fewer turns and 68.9\% fewer tokens. Results indicate that efficiency-aware training naturally improves quality through eliminating noisy redundant signals, enabling high-performance cost-effective localization agents.

</details>


### [27] [ComAgent: Multi-LLM based Agentic AI Empowered Intelligent Wireless Networks](https://arxiv.org/abs/2601.19607)
*Haoyun Li,Ming Xiao,Kezhi Wang,Robert Schober,Dong In Kim,Yong Liang Guan*

Main category: cs.AI

TL;DR: 提出了一种名为ComAgent的多LLM智能体框架，通过闭环的感知-规划-行动-反思机制，利用专门的智能体（文献搜索、编码、评分）自主生成6G网络交叉层优化的数学模型和仿真。


<details>
  <summary>Details</summary>
Motivation: 现有6G网络依赖复杂的交叉层优化，但手动将高层意图转化为数学模型是一个瓶颈。单一的LLM方法在领域知识、约束意识和验证能力方面存在不足。

Method: 提出ComAgent，一个多LLM智能体框架。采用闭环的感知-规划-行动-反思（Perception-Planning-Action-Reflection）周期，协调文献搜索、编码和评分等专业智能体，自主生成可求解的数学模型和可复现的仿真。

Result: ComAgent在复杂的波束赋形优化任务中达到了专家级别的性能，并在多种无线任务上优于单一LLM方法。该框架通过迭代分解问题和自我纠错，有效弥合了用户意图和执行之间的差距。

Conclusion: ComAgent能够自主生成无线网络设计的数学模型和仿真，展示了其在自动化新兴无线网络设计方面的潜力，解决了手动模型转换的瓶颈问题。

Abstract: Emerging 6G networks rely on complex cross-layer optimization, yet manually translating high-level intents into mathematical formulations remains a bottleneck. While Large Language Models (LLMs) offer promise, monolithic approaches often lack sufficient domain grounding, constraint awareness, and verification capabilities. To address this, we present ComAgent, a multi-LLM agentic AI framework. ComAgent employs a closed-loop Perception-Planning-Action-Reflection cycle, coordinating specialized agents for literature search, coding, and scoring to autonomously generate solver-ready formulations and reproducible simulations. By iteratively decomposing problems and self-correcting errors, the framework effectively bridges the gap between user intent and execution. Evaluations demonstrate that ComAgent achieves expert-comparable performance in complex beamforming optimization and outperforms monolithic LLMs across diverse wireless tasks, highlighting its potential for automating design in emerging wireless networks.

</details>


### [28] [Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search](https://arxiv.org/abs/2601.19622)
*Thomas Bömer,Nico Koltermann,Max Disselnmeyer,Bastian Amberg,Anne Meyer*

Main category: cs.AI

TL;DR: 本文提出了一种名为 A-CEoH 的新方法，该方法通过将 A* 搜索代码集成到提示中，利用 LLM 自动生成高质量的启发式函数，并在实际物流和滑动拼图问题上取得了优于专家设计的启发式函数的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的启发式函数设计需要大量专业知识，而 LLM 和进化框架的最新进展为自动化启发式设计提供了可能。本文旨在探索并改进自动化生成 A* 搜索启发式函数的方法。

Method: 作者扩展了 EoH 框架，引入了一种名为 A-CEoH 的域无关提示增强策略。该策略通过在提示中包含 A* 搜索代码来利用 LLM 的上下文学习能力，以自动生成引导 A* 搜索的启发式函数。

Result: 在单元负载预装载问题 (UPMP) 和滑动拼图问题 (SPP) 的计算实验中，A-CEoH 显著提高了生成启发式函数的质量，并且在某些情况下超越了专家设计的启发式函数。

Conclusion: A-CEoH 是一种有效的自动化启发式函数生成方法，能够生成高质量的启发式函数，甚至能够超越人类专家的设计水平，为 A* 搜索算法的性能提升提供了新的途径。

Abstract: Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evolutionary frameworks have opened the door to automating heuristic design. In this paper, we extend the Evolution of Heuristics (EoH) framework to investigate the automated generation of guiding heuristics for A* search. We introduce a novel domain-agnostic prompt augmentation strategy that includes the A* code into the prompt to leverage in-context learning, named Algorithmic - Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH, we study two problem domains: the Unit-Load Pre-Marshalling Problem (UPMP), a niche problem from warehouse logistics, and the classical sliding puzzle problem (SPP). Our computational experiments show that A-CEoH can significantly improve the quality of the generated heuristics and even outperform expert-designed heuristics.

</details>


### [29] [Agentic Design Patterns: A System-Theoretic Framework](https://arxiv.org/abs/2601.19752)
*Minh-Dung Dao,Quy Minh Le,Hoang Thanh Lam,Duc-Trong Le,Quoc-Viet Pham,Barry O'Sullivan,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: 本文提出了一种基于系统理论的方法来工程化稳健的 AI 代理，将系统分解为五个核心功能子系统，并由此衍生的 12 种设计模式，以解决现有代理设计中存在的问题，并提供了一个案例研究来验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有 agentic AI 系统存在幻觉、推理能力差以及系统设计 ad-hoc 等问题，导致应用不可靠且脆弱。现有的对 agentic 设计模式的表征缺乏严格的系统理论基础，导致其难以实现。因此，本文旨在弥合这一差距，提供一种原则性的方法来工程化稳健的 AI 代理。

Method: 文章提出了一个基于系统理论的框架，将 agentic AI 系统分解为五个核心功能子系统：推理与世界模型、感知与接地、动作执行、学习与适应、以及代理间通信。基于此架构，文章还提出了一个包含 12 种 agentic 设计模式的分类，这些模式被归类为基础性、认知与决策性、执行与交互性、以及适应与学习性。

Result: 文章提出了一个系统理论框架和 12 种 agentic 设计模式。通过对 ReAct 框架的案例研究，证明了这些设计模式可以纠正系统架构的不足，从而提高代理的稳健性。

Conclusion: 本文提供了一种原则性的方法来工程化稳健的 AI 代理，通过一个系统理论框架和一套设计的模式，为 agentic 设计提供了一个基础性的语言和结构化方法，有助于实现更模块化、更易理解和更可靠的自主系统。

Abstract: With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or convenience-based taxonomies that are difficult to implement. This paper addresses this gap by introducing a principled methodology for engineering robust AI agents. We propose two primary contributions: first, a novel system-theoretic framework that deconstructs an agentic AI system into five core, interacting functional subsystems: Reasoning & World Model, Perception & Grounding, Action Execution, Learning & Adaptation, and Inter-Agent Communication. Second, derived from this architecture and directly mapped to a comprehensive taxonomy of agentic challenges, we present a collection of 12 agentic design patterns. These patterns - categorised as Foundational, Cognitive & Decisional, Execution & Interaction, and Adaptive & Learning - offer reusable, structural solutions to recurring problems in agent design. The utility of the framework is demonstrated by a case study on the ReAct framework, showing how the proposed patterns can rectify systemic architectural deficiencies. This work provides a foundational language and a structured methodology to standardise agentic design communication among researchers and engineers, leading to more modular, understandable, and reliable autonomous systems.

</details>


### [30] [GAVEL: Towards rule-based safety through activation monitoring](https://arxiv.org/abs/2601.19768)
*Shir Rozenfeld,Rahul Pankajakshan,Itay Zloczower,Eyal Lenga,Gilad Gressel,Yisroel Mirsky*

Main category: cs.AI

TL;DR: 该研究提出了一种基于规则的激活安全新范式，将模型的激活视为可解释的认知元素（CE），并定义关于这些CE的规则来实时检测有害行为，从而提高了精度、灵活性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于激活的安全方法在处理复杂、非表面有害行为时存在精度低、灵活性差和可解释性不足的问题，并且需要基于大规模滥用数据集进行训练。

Method: 将模型的激活建模为细粒度的、可解释的认知元素（CE），例如“进行威胁”和“支付处理”。在此基础上，构建了一个框架，该框架定义了关于CE的谓词规则，并支持实时检测规则违规。该方法允许用户无需重新训练模型或检测器即可配置和更新安全防护措施。

Result: 基于CE的组合式规则驱动激活安全方法提高了精度，支持领域定制，并为可扩展、可解释和可审计的AI治理奠定了基础。

Conclusion: 基于规则的激活安全是一种更精确、灵活、可解释且易于审计的AI安全方法，可以克服现有方法的局限性，并且可以通过开源框架GAVEL和自动化规则创建工具实现。

Abstract: Large language models (LLMs) are increasingly paired with activation-based monitoring to detect and prevent harmful behaviors that may not be apparent at the surface-text level. However, existing activation safety approaches, trained on broad misuse datasets, struggle with poor precision, limited flexibility, and lack of interpretability. This paper introduces a new paradigm: rule-based activation safety, inspired by rule-sharing practices in cybersecurity. We propose modeling activations as cognitive elements (CEs), fine-grained, interpretable factors such as ''making a threat'' and ''payment processing'', that can be composed to capture nuanced, domain-specific behaviors with higher precision. Building on this representation, we present a practical framework that defines predicate rules over CEs and detects violations in real time. This enables practitioners to configure and update safeguards without retraining models or detectors, while supporting transparency and auditability. Our results show that compositional rule-based activation safety improves precision, supports domain customization, and lays the groundwork for scalable, interpretable, and auditable AI governance. We will release GAVEL as an open-source framework and provide an accompanying automated rule creation tool.

</details>


### [31] [CASTER: Breaking the Cost-Performance Barrier in Multi-Agent Orchestration via Context-Aware Strategy for Task Efficient Routing](https://arxiv.org/abs/2601.19793)
*Shanyv Liu,Xuyang Yuan,Tao Chen,Zijun Zhan,Zhu Han,Danyang Zheng,Weishan Zhang,Shaohua Cao*

Main category: cs.AI

TL;DR: 提出了一种名为CASTER的轻量级动态模型选择路由器，用于基于图的多智能体系统（MAS），通过结合语义和结构特征来估计任务难度，并在训练中通过负反馈进行自我优化，从而在不牺牲成功率的情况下显著降低了推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的多智能体系统（MAS）在模型分配上效率低下，会将强大的模型均匀地分配给所有子任务，导致计算资源浪费在简单的任务上。

Method: 提出CASTER（Context-Aware Strategy for Task Efficient Routing），一个轻量级的路由器，采用双信号（语义嵌入和结构元特征）来估计任务难度。训练时，采用“冷启动到迭代演化”的范式，通过基于策略的负反馈来优化路由器。

Result: 在软件工程、数据分析、科学发现和网络安全等领域，CASTER通过LLM-as-a-Judge评估，与强模型基线相比，推理成本降低了高达72.4%，同时保持了相同的成功率。CASTER在所有领域都优于启发式路由和FrugalGPT。

Conclusion: CASTER是一种有效的动态模型选择方法，能够显著降低基于图MAS的推理成本，同时保持或提高其任务成功率，并且在各种应用领域都表现出色。

Abstract: Graph-based Multi-Agent Systems (MAS) enable complex cyclic workflows but suffer from inefficient static model allocation, where deploying strong models uniformly wastes computation on trivial sub-tasks. We propose CASTER (Context-Aware Strategy for Task Efficient Routing), a lightweight router for dynamic model selection in graph-based MAS. CASTER employs a Dual-Signal Router that combines semantic embeddings with structural meta-features to estimate task difficulty. During training, the router self-optimizes through a Cold Start to Iterative Evolution paradigm, learning from its own routing failures via on-policy negative feedback. Experiments using LLM-as-a-Judge evaluation across Software Engineering, Data Analysis, Scientific Discovery, and Cybersecurity demonstrate that CASTER reduces inference cost by up to 72.4% compared to strong-model baselines while matching their success rates, and consistently outperforms both heuristic routing and FrugalGPT across all domains.

</details>


### [32] [An Interpretable Recommendation Model for Psychometric Data, With an Application to Gerontological Primary Care](https://arxiv.org/abs/2601.19824)
*Andre Paulino de Lima,Paula Castro,Suzana Carvalho Vaz de Andrade,Rosa Maria Marcucci,Ruth Caldeira de Melo,Marcelo Garcia Manzato*

Main category: cs.AI

TL;DR: 本研究提出了一种利用心理测量数据结构来提供可视化解释的推荐模型，以解决医疗保健领域推荐系统面临的挑战，并证明了其在老年初级保健领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 医疗保健领域推荐系统面临数据隐私、用户理解困难、风险以及有效性不确定性等挑战，阻碍了其应用。

Method: 提出了一种利用心理测量数据结构来提供可视化解释的推荐模型，并专注于老年初级保健领域进行实验。

Result: 在巴西收集的医疗数据集上进行了离线性能评估，并通过用户研究评估了可视化解释的可解释性，结果表明该模型在该领域具有应用潜力。

Conclusion: 该模型能够协助医护人员制定个性化的护理计划，并有望推动推荐系统在老年初级保健领域的应用，以应对日益增长的需求和信息技术需求。

Abstract: There are challenges that must be overcome to make recommender systems useful in healthcare settings. The reasons are varied: the lack of publicly available clinical data, the difficulty that users may have in understanding the reasons why a recommendation was made, the risks that may be involved in following that recommendation, and the uncertainty about its effectiveness. In this work, we address these challenges with a recommendation model that leverages the structure of psychometric data to provide visual explanations that are faithful to the model and interpretable by care professionals. We focus on a narrow healthcare niche, gerontological primary care, to show that the proposed recommendation model can assist the attending professional in the creation of personalised care plans. We report results of a comparative offline performance evaluation of the proposed model on healthcare datasets that were collected by research partners in Brazil, as well as the results of a user study that evaluates the interpretability of the visual explanations the model generates. The results suggest that the proposed model can advance the application of recommender systems in this healthcare niche, which is expected to grow in demand , opportunities, and information technology needs as demographic changes become more pronounced.

</details>


### [33] [Routing End User Queries to Enterprise Databases](https://arxiv.org/abs/2601.19825)
*Saikrishna Sudarshan,Tanay Kulkarni,Manasi Patwardhan,Lovekesh Vig,Ashwin Srinivasan,Tanmay Tulsidas Verlekar*

Main category: cs.AI

TL;DR: 本文提出了一种基于推理的重排序策略，用于在多数据库环境中路由自然语言查询，该策略通过显式建模模式覆盖、结构连通性和语义对齐，在各种指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究在处理大型、领域重叠的数据库以及歧义查询时，自然语言查询路由面临挑战，这表明需要更结构化和基于推理的解决方案。

Method: 构建了扩展现有NL-to-SQL数据集的基准。提出了一种模块化的、推理驱动的重排序策略，该策略明确地对模式覆盖、结构连通性和细粒度语义对齐进行建模。

Result: 提出的重排序策略在所有指标上均一致优于仅使用嵌入和直接LLM提示的基线方法。

Conclusion: 明确建模模式覆盖、结构连通性和细粒度语义对齐的推理驱动重排序策略是解决多数据库环境中自然语言查询路由挑战的有效方法。

Abstract: We address the task of routing natural language queries in multi-database enterprise environments. We construct realistic benchmarks by extending existing NL-to-SQL datasets. Our study shows that routing becomes increasingly challenging with larger, domain-overlapping DB repositories and ambiguous queries, motivating the need for more structured and robust reasoning-based solutions. By explicitly modelling schema coverage, structural connectivity, and fine-grained semantic alignment, the proposed modular, reasoning-driven reranking strategy consistently outperforms embedding-only and direct LLM-prompting baselines across all the metrics.

</details>


### [34] [Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models](https://arxiv.org/abs/2601.19834)
*Jialong Wu,Xiaoying Zhang,Hongyi Yuan,Xiangcheng Zhang,Tianhao Huang,Changjing He,Chaoyi Deng,Renrui Zhang,Youbin Wu,Mingsheng Long*

Main category: cs.AI

TL;DR: 本研究探讨了视觉生成在人工智能推理中的作用，提出视觉生成可以作为物理世界任务的更有效世界模型，并构建了一个评估套件VisWorld-Eval来验证这一假设。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）在数学和编程等领域表现出色，但缺乏对物理和空间世界的理解。统一多模态模型（UMM）结合了视觉和语言能力，但其在推理中的优势尚不明确，本研究旨在解决这一问题。

Method: 从世界模型角度出发，将内部世界建模形式化为链式思考（CoT）推理的核心组成部分，并分析不同世界模型的区别。构建了VisWorld-Eval评估套件，用于识别需要交错视觉-语言CoT推理的任务。在最先进的UMM上进行了受控实验。

Result: 实验表明，在依赖视觉世界建模的任务上，交错的视觉-语言CoT显著优于纯语言CoT，而在其他任务上则没有明显优势。

Conclusion: 视觉生成在特定任务（尤其是物理世界相关任务）中能够更自然地作为世界模型，克服纯语言模型在表示能力和先验知识上的局限。这项研究为理解多模态世界建模在构建更强大、更类人AI中的潜力提供了清晰的认识。

Abstract: Humans construct internal world models and reason by manipulating the concepts within these models. Recent advances in AI, particularly chain-of-thought (CoT) reasoning, approximate such human cognitive abilities, where world models are believed to be embedded within large language models. Expert-level performance in formal and abstract domains such as mathematics and programming has been achieved in current systems by relying predominantly on verbal reasoning. However, they still lag far behind humans in domains like physical and spatial intelligence, which require richer representations and prior knowledge. The emergence of unified multimodal models (UMMs) capable of both verbal and visual generation has therefore sparked interest in more human-like reasoning grounded in complementary multimodal pathways, though their benefits remain unclear. From a world-model perspective, this paper presents the first principled study of when and how visual generation benefits reasoning. Our key position is the visual superiority hypothesis: for certain tasks--particularly those grounded in the physical world--visual generation more naturally serves as world models, whereas purely verbal world models encounter bottlenecks arising from representational limitations or insufficient prior knowledge. Theoretically, we formalize internal world modeling as a core component of CoT reasoning and analyze distinctions among different forms of world models. Empirically, we identify tasks that necessitate interleaved visual-verbal CoT reasoning, constructing a new evaluation suite, VisWorld-Eval. Controlled experiments on a state-of-the-art UMM show that interleaved CoT significantly outperforms purely verbal CoT on tasks that favor visual world modeling, but offers no clear advantage otherwise. Together, this work clarifies the potential of multimodal world modeling for more powerful, human-like multimodal AI.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [35] [Dynamic Mask-Based Backdoor Attack Against Vision AI Models: A Case Study on Mushroom Detection](https://arxiv.org/abs/2601.18845)
*Zeineb Dridi,Jihen Bennaceur,Amine Ben Hassouna*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的、基于动态掩码的后门攻击方法，专门针对目标检测模型，并利用SAM模型生成动态触发器，展示了这种攻击在蘑菇检测等关键领域的实际风险，并强调了对模型外包实践的担忧。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在计算机视觉任务中取得巨大成功，但同时也面临各种对抗性攻击，特别是后门攻击。研究人员希望探索一种更具威胁性且难以检测的后门攻击方法，以凸显防御模型免受此类攻击的重要性，并警示模型外包实践的风险。

Method: 该研究提出了一种基于动态掩码的后门攻击方法。首先，通过数据集投毒技术嵌入恶意触发器。然后，利用强大的图像分割AI模型SAM生成用于动态触发器放置的掩码。这种动态触发器被嵌入到YOLOv7目标检测模型中。

Result: 该方法在YOLOv7模型上进行了实验，证明了在干净数据上保持高准确率的同时，在投毒样本上实现了高攻击成功率。与基于静态触发器的传统方法相比，该动态掩码方法更具隐蔽性和有效性。

Conclusion: 该研究成功展示了一种新颖且隐蔽的动态掩码后门攻击方法，尤其在目标检测领域。研究结果表明，此类攻击对关键应用（如蘑菇检测）构成了重大风险，并且揭示了模型外包实践中潜在的威胁。文章强调了开发更强大的防御机制来应对不断演变的后门攻击的紧迫性。

Abstract: Deep learning has revolutionized numerous tasks within the computer vision field, including image classification, image segmentation, and object detection. However, the increasing deployment of deep learning models has exposed them to various adversarial attacks, including backdoor attacks. This paper presents a novel dynamic mask-based backdoor attack method, specifically designed for object detection models. We exploit a dataset poisoning technique to embed a malicious trigger, rendering any models trained on this compromised dataset vulnerable to our backdoor attack. We particularly focus on a mushroom detection dataset to demonstrate the practical risks posed by such attacks on critical real-life domains. Our work also emphasizes the importance of creating a detailed backdoor attack scenario to illustrate the significant risks associated with the outsourcing practice. Our approach leverages SAM, a recent and powerful image segmentation AI model, to create masks for dynamic trigger placement, introducing a new and stealthy attack method. Through extensive experimentation, we show that our sophisticated attack scenario maintains high accuracy on clean data with the YOLOv7 object detection model while achieving high attack success rates on poisoned samples. Our approach surpasses traditional methods for backdoor injection, which are based on static and consistent patterns. Our findings underscore the urgent need for robust countermeasures to protect deep learning models from these evolving adversarial threats.

</details>


### [36] [Audio-Driven Talking Face Generation with Blink Embedding and Hash Grid Landmarks Encoding](https://arxiv.org/abs/2601.18849)
*Yuhui Zhang,Hui Yu,Wei Liang,Sunjie Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于眨眼嵌入和哈希网格地标编码的自动方法，以提高动态神经辐射场（NeRF）在生成说话人像时的嘴部运动保真度。


<details>
  <summary>Details</summary>
Motivation: 尽管动态NeRF在生成高质量说话人像方面取得了进展，但在准确高效地捕捉嘴部运动方面仍存在挑战。

Method: 该方法利用编码为人脸特征的条件特征，并通过动态地标Transformer将音频特征整合为残差项。此外，采用神经辐射场对整个面部进行建模。

Result: 实验评估表明，该方法优于现有技术。

Conclusion: 所提出的方法能够显著提高说话人像的保真度，尤其是在嘴部运动的捕捉方面。

Abstract: Dynamic Neural Radiance Fields (NeRF) have demonstrated considerable success in generating high-fidelity 3D models of talking portraits. Despite significant advancements in the rendering speed and generation quality, challenges persist in accurately and efficiently capturing mouth movements in talking portraits. To tackle this challenge, we propose an automatic method based on blink embedding and hash grid landmarks encoding in this study, which can substantially enhance the fidelity of talking faces. Specifically, we leverage facial features encoded as conditional features and integrate audio features as residual terms into our model through a Dynamic Landmark Transformer. Furthermore, we employ neural radiance fields to model the entire face, resulting in a lifelike face representation. Experimental evaluations have validated the superiority of our approach to existing methods.

</details>


### [37] [SelfieAvatar: Real-time Head Avatar reenactment from a Selfie Video](https://arxiv.org/abs/2601.18851)
*Wei Liang,Hui Yu,Derui Ding,Rachael E. Jack,Philippe G. Schyns*

Main category: cs.CV

TL;DR: 本文提出了一种结合3DMM和StyleGAN的方法，用于从单人自拍视频生成细节丰富的高保真头部化身，解决了现有方法在头部细节、实时性和数据需求方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有头部化身重演技术在捕捉全局头部信息、生成精细细节（如皱纹、发丝）以及对训练数据量的需求方面存在不足，尤其是在仅使用单个自拍视频的情况下。

Method: 该方法结合了3D可变形模型（3DMM）和基于StyleGAN的生成器。设计了一个详细重建模型，在对抗性训练中引入混合损失函数，同时进行前景重建和化身图像生成，以恢复高频细节。

Result: 提出的方法在自我重演和交叉重演任务上取得了定性和定量上的优越表现，能够生成比现有方法更丰富、更精细纹理的头部化身。

Conclusion: 该方法成功地解决了从单一自拍视频进行细节头部化身重演的挑战，通过结合3DMM和StyleGAN，并采用混合损失函数，实现了高质量的头部化身重建。

Abstract: Head avatar reenactment focuses on creating animatable personal avatars from monocular videos, serving as a foundational element for applications like social signal understanding, gaming, human-machine interaction, and computer vision. Recent advances in 3D Morphable Model (3DMM)-based facial reconstruction methods have achieved remarkable high-fidelity face estimation. However, on the one hand, they struggle to capture the entire head, including non-facial regions and background details in real time, which is an essential aspect for producing realistic, high-fidelity head avatars. On the other hand, recent approaches leveraging generative adversarial networks (GANs) for head avatar generation from videos can achieve high-quality reenactments but encounter limitations in reproducing fine-grained head details, such as wrinkles and hair textures. In addition, existing methods generally rely on a large amount of training data, and rarely focus on using only a simple selfie video to achieve avatar reenactment. To address these challenges, this study introduces a method for detailed head avatar reenactment using a selfie video. The approach combines 3DMMs with a StyleGAN-based generator. A detailed reconstruction model is proposed, incorporating mixed loss functions for foreground reconstruction and avatar image generation during adversarial training to recover high-frequency details. Qualitative and quantitative evaluations on self-reenactment and cross-reenactment tasks demonstrate that the proposed method achieves superior head avatar reconstruction with rich and intricate textures compared to existing approaches.

</details>


### [38] [Weakly supervised framework for wildlife detection and counting in challenging Arctic environments: a case study on caribou (Rangifer tarandus)](https://arxiv.org/abs/2601.18891)
*Ghazaleh Serati,Samuel Foucher,Jerome Theau*

Main category: cs.CV

TL;DR: 研究提出了一种基于弱监督补丁级别预训练的HerdNet模型，以解决北极驯鹿数量下降背景下，自动化检测中的类不平衡、目标小且遮挡等挑战。该方法通过利用空/非空标签进行预训练，显著提高了检测准确率，为大规模空中影像中的驯鹿监测提供了可靠的映射，并优于仅使用通用权重初始化。


<details>
  <summary>Details</summary>
Motivation: 北极驯鹿数量近几十年来下降，迫切需要可扩展、准确的监测方法来指导保护行动和政策决策。手动解释遥感图像劳动密集且易出错，因此需要自动可靠的检测技术，但现有技术面临背景异质性、类不平衡、目标小/遮挡以及密度和尺度变化大的挑战。

Method: 提出了一种基于检测网络架构的弱监督补丁级别预训练方法，并将其应用于HerdNet模型。该方法使用包含五个驯鹿群的阿拉斯加数据集，通过学习空/非空标签来获取早期弱监督知识。然后，将此预训练模型应用于驯鹿检测任务。

Result: 该补丁级别预训练网络在2017年和2019年的多鹿群影像测试集上均获得了高准确率（F1分数分别为93.7%和92.6%）。与使用ImageNet权重初始化相比，弱监督预训练在正面补丁（F1：92.6%/93.5% vs. 89.3%/88.6%）和全图计数（F1：95.5%/93.3% vs. 91.5%/90.4%）方面均显示出一致的提升。

Conclusion: 在检测前使用粗粒度标签进行预训练，使得即使在标记数据有限的情况下，也可以依赖弱监督预训练权重，并取得与通用权重初始化相当的结果。这使得能够可靠地绘制包含动物的区域，从而便于在大型航空影像上手动计数。

Abstract: Caribou across the Arctic has declined in recent decades, motivating scalable and accurate monitoring approaches to guide evidence-based conservation actions and policy decisions. Manual interpretation from this imagery is labor-intensive and error-prone, underscoring the need for automatic and reliable detection across varying scenes. Yet, such automatic detection is challenging due to severe background heterogeneity, dominant empty terrain (class imbalance), small or occluded targets, and wide variation in density and scale. To make the detection model (HerdNet) more robust to these challenges, a weakly supervised patch-level pretraining based on a detection network's architecture is proposed. The detection dataset includes five caribou herds distributed across Alaska. By learning from empty vs. non-empty labels in this dataset, the approach produces early weakly supervised knowledge for enhanced detection compared to HerdNet, which is initialized from generic weights. Accordingly, the patch-based pretrain network attained high accuracy on multi-herd imagery (2017) and on an independent year's (2019) test sets (F1: 93.7%/92.6%, respectively), enabling reliable mapping of regions containing animals to facilitate manual counting on large aerial imagery. Transferred to detection, initialization from weakly supervised pretraining yielded consistent gains over ImageNet weights on both positive patches (F1: 92.6%/93.5% vs. 89.3%/88.6%), and full-image counting (F1: 95.5%/93.3% vs. 91.5%/90.4%). Remaining limitations are false positives from animal-like background clutter and false negatives related to low animal density occlusions. Overall, pretraining on coarse labels prior to detection makes it possible to rely on weakly-supervised pretrained weights even when labeled data are limited, achieving results comparable to generic-weight initialization.

</details>


### [39] [RealStats: A Rigorous Real-Only Statistical Framework for Fake Image Detection](https://arxiv.org/abs/2601.18900)
*Haim Zisman,Uri Shaham*

Main category: cs.CV

TL;DR: 提出一种基于统计学的、可解释的、无需训练的AI生成图像检测框架，通过集成多个检测器的统计信息来评估图像与真实图像分布的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成图像检测方法缺乏正式的可解释性，且可能依赖于对伪造内容的隐式假设，导致在分布变化下鲁棒性不足。

Method: 利用训练免费的统计信息，通过计算一系列检验统计量的p值，并采用经典的统计集成方法聚合p值，以评估图像与统一的真实图像分布的一致性。

Result: 该框架是通用的、灵活的、无需训练的，能提供一个可解释的概率分数，与真实图像总体相关联。

Conclusion: 该统计框架为AI生成图像检测提供了一种鲁棒且可解释的方法，尤其适用于多样化和不断变化的检测场景。

Abstract: As generative models continue to evolve, detecting AI-generated images remains a critical challenge. While effective detection methods exist, they often lack formal interpretability and may rely on implicit assumptions about fake content, potentially limiting robustness to distributional shifts. In this work, we introduce a rigorous, statistically grounded framework for fake image detection that focuses on producing a probability score interpretable with respect to the real-image population. Our method leverages the strengths of multiple existing detectors by combining training-free statistics. We compute p-values over a range of test statistics and aggregate them using classical statistical ensembling to assess alignment with the unified real-image distribution. This framework is generic, flexible, and training-free, making it well-suited for robust fake image detection across diverse and evolving settings.

</details>


### [40] [On the Role of Depth in Surgical Vision Foundation Models: An Empirical Study of RGB-D Pre-training](https://arxiv.org/abs/2601.18929)
*John J. Han,Adam Schmidt,Muhammad Abdullah Jamal,Chinedu Nwoye,Anita Rau,Jie Ying Wu,Omid Mohareri*

Main category: cs.CV

TL;DR: 研究表明，在机器人手术图像中结合深度信息进行预训练的视觉基础模型（VFM），在各种手术任务中表现优于仅使用RGB图像的模型，并且在数据效率方面具有显著优势，同时无需修改推理时的模型架构或运行时。


<details>
  <summary>Details</summary>
Motivation: 现有视觉基础模型（VFMs）在手术场景理解方面取得了显著进展，但它们主要依赖于单模态RGB预训练，忽略了手术环境固有的复杂三维几何信息。尽管存在支持多模态或几何感知输入的通用计算机视觉架构，但在手术场景中整合深度信息的益处尚未得到充分探索。

Method: 研究者进行了一项大规模的实证研究，比较了八种基于Vision Transformer（ViT）的VFM。这些模型在预训练域、学习目标和输入模态（RGB vs. RGB-D）上有所不同。他们使用了一个包含140万张机器人手术图像及其深度图的大型数据集进行预训练。实验评估了这些模型在冻结骨干网络和端到端微调协议下的表现，涵盖了对象检测、分割、深度估计和姿态估计等八个手术数据集。

Result: 实验发现，包含显式几何标记（例如，MultiMAE）的模型在所有任务上都显著优于单模态基线。特别是，几何感知预训练带来了显著的数据效率提升：仅使用25%标注数据的模型，其性能持续超越使用全部数据训练的RGB-only模型。这些性能提升在推理时无需改变模型架构或运行时。

Conclusion: 多模态预训练，特别是整合几何信息，为构建更强大的手术视觉系统提供了一条可行的途径。这种方法能够显著提高模型在各种手术任务上的性能和数据效率，且易于集成到现有工作流程中。

Abstract: Vision foundation models (VFMs) have emerged as powerful tools for surgical scene understanding. However, current approaches predominantly rely on unimodal RGB pre-training, overlooking the complex 3D geometry inherent to surgical environments. Although several architectures support multimodal or geometry-aware inputs in general computer vision, the benefits of incorporating depth information in surgical settings remain underexplored. We conduct a large-scale empirical study comparing eight ViT-based VFMs that differ in pre-training domain, learning objective, and input modality (RGB vs. RGB-D). For pre-training, we use a curated dataset of 1.4 million robotic surgical images paired with depth maps generated from an off-the-shelf network. We evaluate these models under both frozen-backbone and end-to-end fine-tuning protocols across eight surgical datasets spanning object detection, segmentation, depth estimation, and pose estimation. Our experiments yield several consistent findings. Models incorporating explicit geometric tokenization, such as MultiMAE, substantially outperform unimodal baselines across all tasks. Notably, geometric-aware pre-training enables remarkable data efficiency: models fine-tuned on just 25% of labeled data consistently surpass RGB-only models trained on the full dataset. Importantly, these gains require no architectural or runtime changes at inference; depth is used only during pre-training, making adoption straightforward. These findings suggest that multimodal pre-training offers a viable path towards building more capable surgical vision systems.

</details>


### [41] [Smart Split-Federated Learning over Noisy Channels for Embryo Image Segmentation](https://arxiv.org/abs/2601.18948)
*Zahra Hafezi Kafshgari,Ivan V. Bajic,Parvaneh Saeedi*

Main category: cs.CV

TL;DR: 提出了一种用于分裂联邦学习（SplitFed）的智能平均策略，以提高其在通信噪声下的鲁棒性。该策略在胚胎图像分割模型上进行了实验验证，证明其能容忍比传统平均方法高两个数量级的噪声，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 研究通信噪声对分裂联邦学习过程和模型质量的影响，并寻求一种能提高其对噪声的鲁棒性的方法。

Method: 提出了一种智能平均策略，用于分裂联邦学习。该策略旨在提高模型在存在通信噪声时的学习能力和最终模型质量。实验在一个用于胚胎图像分割的模型上进行。

Result: 所提出的智能平均策略能够容忍比传统平均方法高两个数量级的通信信道噪声，同时保持最终模型的准确性。

Conclusion: 智能平均策略是提高分裂联邦学习在存在通信噪声情况下的鲁棒性的有效方法，能够在保持模型精度的同时显著增强其对噪声的耐受能力。

Abstract: Split-Federated (SplitFed) learning is an extension of federated learning that places minimal requirements on the clients computing infrastructure, since only a small portion of the overall model is deployed on the clients hardware. In SplitFed learning, feature values, gradient updates, and model updates are transferred across communication channels. In this paper, we study the effects of noise in the communication channels on the learning process and the quality of the final model. We propose a smart averaging strategy for SplitFed learning with the goal of improving resilience against channel noise. Experiments on a segmentation model for embryo images shows that the proposed smart averaging strategy is able to tolerate two orders of magnitude stronger noise in the communication channels compared to conventional averaging, while still maintaining the accuracy of the final model.

</details>


### [42] [Pay Attention to Where You Look](https://arxiv.org/abs/2601.18970)
*Alex Beriand,JhihYang Wu,Daniel Brignac,Natnael Daba,Abhijit Mahalanobis*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的视图合成（NVS）方法，通过引入相机权重机制来解决现有少样本NVS方法中输入视图重要性假设不足的问题，以提高新视图合成的准确性和真实感。


<details>
  <summary>Details</summary>
Motivation: 现有少样本NVS方法通常假设所有输入视图对目标视图的重要性均等，这可能导致次优的合成结果。研究旨在解决这一局限性，通过调整输入视图与目标视图的相关性来优化合成效果。

Method: 提出了两种相机权重机制：一种是基于几何属性（如欧氏距离和角度差）的确定性加权方案；另一种是基于交叉注意力学习的优化加权方案。此外，还可以通过相机权重机制对模型进行进一步训练，以提高合成质量。

Result: 自适应视图加权能够提高新视图合成的准确性和真实感，证明了该方法的有效性。

Conclusion: 自适应视图加权机制能够有效提升少样本新视图合成的质量，为改进NVS技术提供了一个有前景的方向，并且该机制可以集成到现有的NVS算法中。

Abstract: Novel view synthesis (NVS) has advanced with generative modeling, enabling photorealistic image generation. In few-shot NVS, where only a few input views are available, existing methods often assume equal importance for all input views relative to the target, leading to suboptimal results.
  We address this limitation by introducing a camera-weighting mechanism that adjusts the importance of source views based on their relevance to the target. We propose two approaches: a deterministic weighting scheme leveraging geometric properties like Euclidean distance and angular differences, and a cross-attention-based learning scheme that optimizes view weighting. Additionally, models can be further trained with our camera-weighting scheme to refine their understanding of view relevance and enhance synthesis quality. This mechanism is adaptable and can be integrated into various NVS algorithms, improving their ability to synthesize high-quality novel views. Our results demonstrate that adaptive view weighting enhances accuracy and realism, offering a promising direction for improving NVS.

</details>


### [43] [FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction](https://arxiv.org/abs/2601.18993)
*Wei Cao,Hao Zhang,Fengrui Tian,Yulun Wu,Yingying Li,Shenlong Wang,Ning Yu,Yaoyao Liu*

Main category: cs.CV

TL;DR: FreeOrbit4D是一个无需训练的框架，通过恢复一个几何完整的4D代理，解决了单目视频大角度重定向的几何模糊问题，从而生成更逼真的重定向视频。


<details>
  <summary>Details</summary>
Motivation: 单目视频在大角度视点变化时，由于观测有限，容易出现几何模糊和时间不一致的问题，现有基于扩散模型的方法在此类挑战性场景下表现不佳。

Method: FreeOrbit4D通过解耦前景和背景重建，将单目视频投影到全局空间中的静态背景和几何不完整的点云。然后，利用一个以物体为中心的、多视角的扩散模型合成多视角图像并重建几何完整的点云。通过3D-3D对应关系将前景点云对齐到全局空间，并将4D代理投影到目标视点，为条件视频扩散模型提供几何指导。

Result: FreeOrbit4D在具有挑战性的大角度轨迹下，能够生成更忠实的重定向视频，并且其几何完整的4D代理为实际应用（如编辑传播和4D数据生成）提供了新的可能性。

Conclusion: FreeOrbit4D通过引入几何完整的4D代理，有效解决了单目视频大角度重定向中的几何歧义问题，并在生成逼真重定向视频方面取得了显著成效。

Abstract: Camera redirection aims to replay a dynamic scene from a single monocular video under a user-specified camera trajectory. However, large-angle redirection is inherently ill-posed: a monocular video captures only a narrow spatio-temporal view of a dynamic 3D scene, providing highly partial observations of the underlying 4D world. The key challenge is therefore to recover a complete and coherent representation from this limited input, with consistent geometry and motion. While recent diffusion-based methods achieve impressive results, they often break down under large-angle viewpoint changes far from the original trajectory, where missing visual grounding leads to severe geometric ambiguity and temporal inconsistency. To address this, we present FreeOrbit4D, an effective training-free framework that tackles this geometric ambiguity by recovering a geometry-complete 4D proxy as structural grounding for video generation. We obtain this proxy by decoupling foreground and background reconstructions: we unproject the monocular video into a static background and geometry-incomplete foreground point clouds in a unified global space, then leverage an object-centric multi-view diffusion model to synthesize multi-view images and reconstruct geometry-complete foreground point clouds in canonical object space. By aligning the canonical foreground point cloud to the global scene space via dense pixel-synchronized 3D--3D correspondences and projecting the geometry-complete 4D proxy onto target camera viewpoints, we provide geometric scaffolds that guide a conditional video diffusion model. Extensive experiments show that FreeOrbit4D produces more faithful redirected videos under challenging large-angle trajectories, and our geometry-complete 4D proxy further opens a potential avenue for practical applications such as edit propagation and 4D data generation. Project page and code will be released soon.

</details>


### [44] [Towards Gold-Standard Depth Estimation for Tree Branches in UAV Forestry: Benchmarking Deep Stereo Matching Methods](https://arxiv.org/abs/2601.19461)
*Yida Lin,Bing Xue,Mengjie Zhang,Sam Schofield,Richard Green*

Main category: cs.CV

TL;DR: 该研究首次对八种立体深度估计算法在无人机森林作业场景下的零样本泛化能力进行了系统评估，并引入了一个新的树枝数据集。结果表明，虽然基础模型在结构化场景下表现优异，但DEFOM在植被密集场景下表现最佳，并被提议用作未来基准测试的伪真值。


<details>
  <summary>Details</summary>
Motivation: 现有无人机林业作业所需的鲁棒深度估计算法在跨领域泛化能力方面存在不足，因为现有评估主要集中在城市和室内场景，而忽略了植被茂密的复杂环境。

Method: 对八种立体深度估计算法（包括迭代精炼、基础模型、扩散模型和3D CNN等）进行了零样本评估。所有方法均使用在Scene Flow上预训练的官方权重，并在四个标准数据集（ETH3D、KITTI 2012/2015、Middlebury）以及一个新提出的Canterbury Tree Branches数据集上进行测试。

Result: 基础模型（如BridgeDepth、DEFOM）在结构化场景下表现出色。迭代精炼方法（如IGEV++、IGEV）在不同基准测试上的表现差异较大。在Tree Branches数据集上，DEFOM被证明是植被深度估计的黄金标准基线，其跨领域一致性表现最佳，在所有基准测试中平均排名为1.75。

Conclusion: DEFOM是在植被茂密场景下进行深度估计的优秀基线，其零样本跨领域泛化能力强，可以作为未来相关研究的伪真值，为无人机林业作业提供更可靠的深度感知能力。

Abstract: Autonomous UAV forestry operations require robust depth estimation with strong cross-domain generalization, yet existing evaluations focus on urban and indoor scenarios, leaving a critical gap for vegetation-dense environments. We present the first systematic zero-shot evaluation of eight stereo methods spanning iterative refinement, foundation model, diffusion-based, and 3D CNN paradigms. All methods use officially released pretrained weights (trained on Scene Flow) and are evaluated on four standard benchmarks (ETH3D, KITTI 2012/2015, Middlebury) plus a novel 5,313-pair Canterbury Tree Branches dataset ($1920 \times 1080$). Results reveal scene-dependent patterns: foundation models excel on structured scenes (BridgeDepth: 0.23 px on ETH3D; DEFOM: 4.65 px on Middlebury), while iterative methods show variable cross-benchmark performance (IGEV++: 0.36 px on ETH3D but 6.77 px on Middlebury; IGEV: 0.33 px on ETH3D but 4.99 px on Middlebury). Qualitative evaluation on the Tree Branches dataset establishes DEFOM as the gold-standard baseline for vegetation depth estimation, with superior cross-domain consistency (consistently ranking 1st-2nd across benchmarks, average rank 1.75). DEFOM predictions will serve as pseudo-ground-truth for future benchmarking.

</details>


### [45] [Non-Invasive 3D Wound Measurement with RGB-D Imaging](https://arxiv.org/abs/2601.19014)
*Lena Harkämper,Leo Lebrat,David Ahmedt-Aristizabal,Olivier Salvado,Mattias Heinrich,Rodrigo Santa Cruz*

Main category: cs.CV

TL;DR: 该研究提出了一种基于RGB-D成像的快速、无创三维伤口测量算法，通过RGB-D里程计和B样条曲面重建生成伤口三维模型，可自动计算周长、面积等关键指标，并显示出高精度和低变异性。


<details>
  <summary>Details</summary>
Motivation: 慢性伤口监测和管理需要精确高效的伤口测量方法。

Method: 结合RGB-D里程计和B样条曲面重建技术，生成详细的三维伤口网格。

Result: 在伤口模型上实现了亚毫米级的重建精度，提取的测量值变异性低且与手动测量结果高度一致，性能优于现有算法。

Conclusion: 该方法为临床和远程医疗环境下自动化伤口评估提供了一个有前景的工具。

Abstract: Chronic wound monitoring and management require accurate and efficient wound measurement methods. This paper presents a fast, non-invasive 3D wound measurement algorithm based on RGB-D imaging. The method combines RGB-D odometry with B-spline surface reconstruction to generate detailed 3D wound meshes, enabling automatic computation of clinically relevant wound measurements such as perimeter, surface area, and dimensions. We evaluated our system on realistic silicone wound phantoms and measured sub-millimetre 3D reconstruction accuracy compared with high-resolution ground-truth scans. The extracted measurements demonstrated low variability across repeated captures and strong agreement with manual assessments. The proposed pipeline also outperformed a state-of-the-art object-centric RGB-D reconstruction method while maintaining runtimes suitable for real-time clinical deployment. Our approach offers a promising tool for automated wound assessment in both clinical and remote healthcare settings.

</details>


### [46] [Anatomically-aware conformal prediction for medical image segmentation with random walks](https://arxiv.org/abs/2601.18997)
*Mélanie Gaillochet,Christian Desrosiers,Hervé Lombaert*

Main category: cs.CV

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: The reliable deployment of deep learning in medical imaging requires uncertainty quantification that provides rigorous error guarantees while remaining anatomically meaningful. Conformal prediction (CP) is a powerful distribution-free framework for constructing statistically valid prediction intervals. However, standard applications in segmentation often ignore anatomical context, resulting in fragmented, spatially incoherent, and over-segmented prediction sets that limit clinical utility. To bridge this gap, this paper proposes Random-Walk Conformal Prediction (RW-CP), a model-agnostic framework which can be added on top of any segmentation method. RW-CP enforces spatial coherence to generate anatomically valid sets. Our method constructs a k-nearest neighbour graph from pre-trained vision foundation model features and applies a random walk to diffuse uncertainty. The random walk diffusion regularizes the non-conformity scores, making the prediction sets less sensitive to the conformal calibration parameter $λ$, ensuring more stable and continuous anatomical boundaries. RW-CP maintains rigorous marginal coverage while significantly improving segmentation quality. Evaluations on multi-modal public datasets show improvements of up to $35.4\%$ compared to standard CP baselines, given an allowable error rate of $α=0.1$.

</details>


### [47] [NC-Reg : Neural Cortical Maps for Rigid Registration](https://arxiv.org/abs/2601.19042)
*Ines Vati,Pierrick Bourgeat,Rodrigo Santa Cruz,Vincent Dore,Olivier Salvado,Clinton Fookes,Léo Lebrat*

Main category: cs.CV

TL;DR: 本文提出了一种名为“神经皮层图”（neural cortical maps）的新型连续紧凑神经表示方法，用于表示皮层特征图，以替代传统的离散结构。该方法能够处理任意大小的网格，并提供任意分辨率的特征。研究证明，神经皮层图在球面上进行优化效率更高，速度可达经典重心插值的30倍。作为概念验证，研究人员开发了一种名为NC-Reg的新型迭代算法，用于刚性配准皮层表面，该算法结合了神经皮层特征图、梯度下降优化和模拟退火策略。实验结果显示，该方法具有亚度精度（<1°），并可作为一种有前景的鲁棒预配准策略，在临床应用中尤为重要。


<details>
  <summary>Details</summary>
Motivation: 传统的离散结构（如网格和网格）在表示和处理皮层特征图时存在局限性，例如处理任意大小的网格和提供任意分辨率的特征。此外，在涉及球面的优化问题中，现有方法的效率有待提高。因此，作者提出了神经皮层图作为一种更优的替代方案。

Method: 本文提出了一种名为“神经皮层图”的连续紧凑神经表示方法。该方法能够从任意大小的网格中学习特征，并提供任意分辨率的特征。在此基础上，作者提出了一种名为NC-Reg的新型迭代算法，用于皮层表面的刚性配准。NC-Reg算法结合了神经皮层特征图、梯度下降优化和模拟退火策略。

Result: 神经皮层图在球面上进行优化时，效率比经典的重心插值高出30倍。NC-Reg算法在实验中展示了亚度精度（<1°），证明了其在皮层表面刚性配准方面的有效性。

Conclusion: 神经皮层图是一种有效的连续紧凑神经表示方法，能够克服传统方法的局限性，并在效率上有所提升。NC-Reg算法作为一种基于神经皮层图的配准方法，表现出高精度和鲁棒性，是一种有前景的预配准策略，尤其适用于临床环境。

Abstract: We introduce neural cortical maps, a continuous and compact neural representation for cortical feature maps, as an alternative to traditional discrete structures such as grids and meshes. It can learn from meshes of arbitrary size and provide learnt features at any resolution. Neural cortical maps enable efficient optimization on the sphere and achieve runtimes up to 30 times faster than classic barycentric interpolation (for the same number of iterations). As a proof of concept, we investigate rigid registration of cortical surfaces and propose NC-Reg, a novel iterative algorithm that involves the use of neural cortical feature maps, gradient descent optimization and a simulated annealing strategy. Through ablation studies and subject-to-template experiments, our method demonstrates sub-degree accuracy ($<1^\circ$ from the global optimum), and serves as a promising robust pre-alignment strategy, which is critical in clinical settings.

</details>


### [48] [NuiWorld: Exploring a Scalable Framework for End-to-End Controllable World Generation](https://arxiv.org/abs/2601.19048)
*Han-Hung Lee,Cheng-Yu Yang,Yu-Lun Liu,Angel X. Chang*

Main category: cs.CV

TL;DR: NuiWorld 是一个世界生成框架，通过生成式引导策略、可扩展的场景生成技术和分块表示来解决数据稀缺、可控性和效率问题，从而实现可控、可扩展且高效的世界生成。


<details>
  <summary>Details</summary>
Motivation: 现有世界生成方法在可控性、可扩展性和效率方面面临挑战，例如数据稀缺、固定分辨率限制以及训练免费方法的计算成本高昂。

Method: NuiWorld 采用生成式引导策略，从少量输入图像开始合成数据以训练端到端模型。它结合了 3D 重建和可扩展场景生成技术，以可变场景块的形式表示场景，并将其压缩为扁平的向量集表示，从而实现不同尺寸场景的几何保真度，并提高训练和推理效率。此外，通过伪草图标签实现可控性。

Result: 该框架能够生成足够的数据来训练端到端模型，并能够根据草图生成不同尺寸和布局的场景。它在保持几何保真度的同时，提高了训练和推理效率，并且对未见过的草图表现出一定的泛化能力。

Conclusion: NuiWorld 通过结合生成式引导、可扩展场景生成和分块表示，有效解决了世界生成中的数据稀缺、可控性和效率问题，为更具鲁棒性和通用性的世界生成提供了新的途径。

Abstract: World generation is a fundamental capability for applications like video games, simulation, and robotics. However, existing approaches face three main obstacles: controllability, scalability, and efficiency. End-to-end scene generation models have been limited by data scarcity. While object-centric generation approaches rely on fixed resolution representations, degrading fidelity for larger scenes. Training-free approaches, while flexible, are often slow and computationally expensive at inference time. We present NuiWorld, a framework that attempts to address these challenges. To overcome data scarcity, we propose a generative bootstrapping strategy that starts from a few input images. Leveraging recent 3D reconstruction and expandable scene generation techniques, we synthesize scenes of varying sizes and layouts, producing enough data to train an end-to-end model. Furthermore, our framework enables controllability through pseudo sketch labels, and demonstrates a degree of generalization to previously unseen sketches. Our approach represents scenes as a collection of variable scene chunks, which are compressed into a flattened vector-set representation. This significantly reduces the token length for large scenes, enabling consistent geometric fidelity across scenes sizes while improving training and inference efficiency.

</details>


### [49] [Pixel-Grounded Retrieval for Knowledgeable Large Multimodal Models](https://arxiv.org/abs/2601.19060)
*Jeonghwan Kim,Renjie Tao,Sanat Sharma,Jiaqi Wang,Kai Sun,Zhaojiang Lin,Seungwhan Moon,Lambert Mathias,Anuj Kumar,Heng Ji,Xin Luna Dong*

Main category: cs.CV

TL;DR: 提出了一种名为PixSearch的端到端分割大模型，它能够统一区域感知和检索增强推理，用于视觉问答（VQA）。PixSearch能自动触发检索、选择查询模态，并生成像素级掩码作为视觉查询，无需依赖外部模块，显著提升了VQA的事实一致性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态检索增强生成（MM-RAG）系统在事实 grounding 方面有所欠缺，并且缺乏内部策略来决定何时以及如何进行检索。本文旨在解决这一问题，提出一个统一了区域感知和检索增强推理的 VQA 系统。

Method: PixSearch是一个端到端的分割大模型（LMM）。在编码阶段，它生成<search> token 来触发检索，并能自动选择查询模态（文本、图像或区域）。更重要的是，它能够生成像素级掩码，直接用作视觉查询，从而无需依赖独立的检测器、分割器或描述器等模块。该模型通过一个两阶段的监督微调过程进行训练，该过程结合了检索间隙监督，以学习检索时机和查询选择，并保持分割能力。

Result: 在以自我为中心和以实体为中心的 VQA 基准测试中，PixSearch 显著提高了事实一致性和泛化能力。在 CRAG-MM 数据集上，相比于整个图像检索，PixSearch 的准确率相对提高了 19.7%。同时，在各种 VQA 和纯文本 QA 任务上，PixSearch 仍然保持了具有竞争力的推理性能。

Conclusion: PixSearch 是首个统一了区域感知和检索增强推理的端到端分割 LMM。它通过生成像素级掩码作为视觉查询，克服了传统 MM-RAG 系统的模块化限制，并能有效学习检索策略，在 VQA 任务中取得了显著的性能提升，尤其是在事实一致性和泛化能力方面。

Abstract: Visual Question Answering (VQA) often requires coupling fine-grained perception with factual knowledge beyond the input image. Prior multimodal Retrieval-Augmented Generation (MM-RAG) systems improve factual grounding but lack an internal policy for when and how to retrieve. We propose PixSearch, the first end-to-end Segmenting Large Multimodal Model (LMM) that unifies region-level perception and retrieval-augmented reasoning. During encoding, PixSearch emits <search> tokens to trigger retrieval, selects query modalities (text, image, or region), and generates pixel-level masks that directly serve as visual queries, eliminating the reliance on modular pipelines (detectors, segmenters, captioners, etc.). A two-stage supervised fine-tuning regimen with search-interleaved supervision teaches retrieval timing and query selection while preserving segmentation ability. On egocentric and entity-centric VQA benchmarks, PixSearch substantially improves factual consistency and generalization, yielding a 19.7% relative gain in accuracy on CRAG-MM compared to whole image retrieval, while retaining competitive reasoning performance on various VQA and text-only QA tasks.

</details>


### [50] [m2sv: A Scalable Benchmark for Map-to-Street-View Spatial Reasoning](https://arxiv.org/abs/2601.19099)
*Yosub Shin,Michael Buriek,Igor Molybog*

Main category: cs.CV

TL;DR: 本研究提出了一个名为 m2sv 的新基准，用于评估视觉-语言模型（VLMs）在地图到街景空间推理方面的能力，并展示了现有 VLM 在此任务上的不足，同时提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在许多多模态任务上表现优异，但在需要对抽象的顶视图表示和以自身为中心的视图进行匹配的空间推理任务上表现脆弱。本研究旨在解决这一问题，并提出一个新的评估基准。

Method: 研究者提出了 m2sv 基准（包括 m2sv-20k 和 m2sv-sft-11k），用于评估模型将北方朝上的地图与同一真实世界交叉口的街景图像进行匹配，并推断相机视角的能力。他们评估了现有 VLM 的性能，并进行了监督微调（SFT）和强化学习（RL）的实验，以及跨基准的迁移能力分析和详细的失败案例研究。

Result: 在 m2sv 基准上，即使是表现最好的 VLM 的准确率也只有 65.2%，远低于人类的 95%。监督微调和强化学习可以带来一致的提升，但跨基准的迁移能力有限。研究还发现了模型在几何对齐、证据聚合和推理一致性方面存在的持续性差距。

Conclusion: 现有的视觉-语言模型在地图到街景的空间推理任务上仍存在显著差距，尤其是在几何对齐、证据聚合和推理一致性方面。未来的工作需要专注于提高模型在跨视角的地面空间推理能力。

Abstract: Vision--language models (VLMs) achieve strong performance on many multimodal benchmarks but remain brittle on spatial reasoning tasks that require aligning abstract overhead representations with egocentric views. We introduce m2sv, a scalable benchmark for map-to-street-view spatial reasoning that asks models to infer camera viewing direction by aligning a north-up overhead map with a Street View image captured at the same real-world intersection. We release m2sv-20k, a geographically diverse benchmark with controlled ambiguity, along with m2sv-sft-11k, a curated set of structured reasoning traces for supervised fine-tuning.
  Despite strong performance on existing multimodal benchmarks, the best evaluated VLM achieves only 65.2% accuracy on m2sv, far below the human baseline of 95%. While supervised fine-tuning and reinforcement learning yield consistent gains, cross-benchmark evaluations reveal limited transfer. Beyond aggregate accuracy, we systematically analyze difficulty in map-to-street-view reasoning using both structural signals and human effort, and conduct an extensive failure analysis of adapted open models. Our findings highlight persistent gaps in geometric alignment, evidence aggregation, and reasoning consistency, motivating future work on grounded spatial reasoning across viewpoints.

</details>


### [51] [Glance and Focus Reinforcement for Pan-cancer Screening](https://arxiv.org/abs/2601.19103)
*Linshan Wu,Jiaxin Zhuang,Hao Chen*

Main category: cs.CV

TL;DR: 提出了一种名为 GF-Screen 的基于强化学习的 Glance and Focus 框架，用于大规模 CT 扫描中的泛癌筛查，通过“一瞥”模型定位病灶区域，“聚焦”模型进行精确分割，并利用分割结果指导“一瞥”模型的学习，提高了效率并减少了假阳性。


<details>
  <summary>Details</summary>
Motivation: 现有的 AI 方法在处理大规模 CT 扫描中的泛癌筛查时面临挑战，主要是难以在巨大的 CT 数据集中精确定位多样且微小的病灶，以及前景-背景极度不平衡导致模型难以关注病灶区域，并增加了假阳性。

Method: 提出 GF-Screen 框架，包含一个 Glance 模型用于定位病灶区域，一个 Focus 模型用于精确分割病灶。利用 Focus 模型的分割结果作为奖励信号，通过强化学习（RL）来优化 Glance 模型。Glance 模型通过裁剪子卷并学习选择包含病灶的子卷。引入了新颖的组相对学习范式，通过组内相对比较来优化 Glance 模型，优先高优势预测，丢弃低优势预测。

Result: 在 16 个内部数据集和 7 个外部数据集（涵盖 9 种病灶类型）上进行了广泛实验，证明了 GF-Screen 的有效性。GF-Screen 在 MICCAI FLARE25 泛癌挑战赛的公开验证排行榜上名列前茅，在 DSC 和 NSD 指标上均大幅超越 FLARE24 冠军方案。

Conclusion: GF-Screen 成功地将前沿的强化学习技术应用于解决泛癌筛查中的特定挑战，通过模拟放射科医生的“一瞥”和“聚焦”诊断策略，有效提高了泛癌筛查的效率和准确性。

Abstract: Pan-cancer screening in large-scale CT scans remains challenging for existing AI methods, primarily due to the difficulty of localizing diverse types of tiny lesions in large CT volumes. The extreme foreground-background imbalance significantly hinders models from focusing on diseased regions, while redundant focus on healthy regions not only decreases the efficiency but also increases false positives. Inspired by radiologists' glance and focus diagnostic strategy, we introduce GF-Screen, a Glance and Focus reinforcement learning framework for pan-cancer screening. GF-Screen employs a Glance model to localize the diseased regions and a Focus model to precisely segment the lesions, where segmentation results of the Focus model are leveraged to reward the Glance model via Reinforcement Learning (RL). Specifically, the Glance model crops a group of sub-volumes from the entire CT volume and learns to select the sub-volumes with lesions for the Focus model to segment. Given that the selecting operation is non-differentiable for segmentation training, we propose to employ the segmentation results to reward the Glance model. To optimize the Glance model, we introduce a novel group relative learning paradigm, which employs group relative comparison to prioritize high-advantage predictions and discard low-advantage predictions within sub-volume groups, not only improving efficiency but also reducing false positives. In this way, for the first time, we effectively extend cutting-edge RL techniques to tackle the specific challenges in pan-cancer screening. Extensive experiments on 16 internal and 7 external datasets across 9 lesion types demonstrated the effectiveness of GF-Screen. Notably, GF-Screen leads the public validation leaderboard of MICCAI FLARE25 pan-cancer challenge, surpassing the FLARE24 champion solution by a large margin (+25.6% DSC and +28.2% NSD).

</details>


### [52] [Reg-TTR, Test-Time Refinement for Fast, Robust and Accurate Image Registration](https://arxiv.org/abs/2601.19114)
*Lin Chen,Yue He,Fengting Zhang,Yaonan Wang,Fengming Lin,Xiang Chen,Min Liu*

Main category: cs.CV

TL;DR: Reg-TTR 是一个测试时精炼框架，它结合了深度学习和传统配准的优点，在不显著增加计算成本的情况下提高了配准精度。


<details>
  <summary>Details</summary>
Motivation: 现有的图像配准方法要么稳健但速度慢（迭代法），要么速度快但对域迁移敏感（深度学习），要么精度不如专用模型（基础模型）。研究的动机是结合不同方法的优势，在速度和精度之间取得更好的平衡。

Method: Reg-TTR 在推理时精炼预训练模型的预测结果，融合了深度学习和传统配准技术的优点。

Result: Reg-TTR 在两个不同的任务上实现了最先进的性能，同时保持了接近先前深度学习方法的推理速度（仅增加了 21% 的推理时间，即 0.56 秒）。

Conclusion: Reg-TTR 是一种有效的框架，可以弥合配准基础模型与在专用数据集上训练的最先进方法之间的性能差距，提供更高的精度且计算成本适中。

Abstract: Traditional image registration methods are robust but slow due to their iterative nature. While deep learning has accelerated inference, it often struggles with domain shifts. Emerging registration foundation models offer a balance of speed and robustness, yet typically cannot match the peak accuracy of specialized models trained on specific datasets. To mitigate this limitation, we propose Reg-TTR, a test-time refinement framework that synergizes the complementary strengths of both deep learning and conventional registration techniques. By refining the predictions of pre-trained models at inference, our method delivers significantly improved registration accuracy at a modest computational cost, requiring only 21% additional inference time (0.56s). We evaluate Reg-TTR on two distinct tasks and show that it achieves state-of-the-art (SOTA) performance while maintaining inference speeds close to previous deep learning methods. As foundation models continue to emerge, our framework offers an efficient strategy to narrow the performance gap between registration foundation models and SOTA methods trained on specialized datasets. The source code will be publicly available following the acceptance of this work.

</details>


### [53] [FBSDiff++: Improved Frequency Band Substitution of Diffusion Features for Efficient and Highly Controllable Text-Driven Image-to-Image Translation](https://arxiv.org/abs/2601.19115)
*Xiang Gao,Yunpeng Jia*

Main category: cs.CV

TL;DR: FBSDiff是一个新颖的框架，通过动态调整扩散特征的频段，将现有的文本到图像（T2I）扩散模型适配到图像到图像（I2I）翻译任务中，无需训练或微调。FBSDiff++在此基础上进一步提高了推理速度、支持任意分辨率的输入图像，并实现了局部图像操作和风格化内容创建。


<details>
  <summary>Details</summary>
Motivation: 随着T2I模型的发展，研究者希望将其自然地扩展到I2I翻译任务，即在文本提示的基础上，加入源图像的视觉引导，实现更具控制力的图像生成。现有方法在灵活性和效率上仍有提升空间。

Method: FBSDiff通过在扩散模型的特征表示中动态替换不同频段（低频、中频、高频）来实现外观、布局和轮廓引导的I2I翻译。FBSDiff++在此基础上，通过改进模型架构加速推理，优化频段替换模块以支持任意分辨率输入，并扩展功能以实现局部图像操作和风格化内容创建。

Result: FBSDiff++在I2I翻译的视觉质量、效率、通用性和可控性方面优于现有先进方法。FBSDiff++实现了8.9倍的推理加速。

Conclusion: FBSDiff++提供了一种高效、灵活且功能强大的图像到图像翻译框架，能够通过频域控制实现高度可定制的图像生成，并在多种I2I任务中展现出优越性能。

Abstract: With large-scale text-to-image (T2I) diffusion models achieving significant advancements in open-domain image creation, increasing attention has been focused on their natural extension to the realm of text-driven image-to-image (I2I) translation, where a source image acts as visual guidance to the generated image in addition to the textual guidance provided by the text prompt. We propose FBSDiff, a novel framework adapting off-the-shelf T2I diffusion model into the I2I paradigm from a fresh frequency-domain perspective. Through dynamic frequency band substitution of diffusion features, FBSDiff realizes versatile and highly controllable text-driven I2I in a plug-and-play manner (without need for model training, fine-tuning, or online optimization), allowing appearance-guided, layout-guided, and contour-guided I2I translation by progressively substituting low-frequency band, mid-frequency band, and high-frequency band of latent diffusion features, respectively. In addition, FBSDiff flexibly enables continuous control over I2I correlation intensity simply by tuning the bandwidth of the substituted frequency band. To further promote image translation efficiency, flexibility, and functionality, we propose FBSDiff++ which improves upon FBSDiff mainly in three aspects: (1) accelerate inference speed by a large margin (8.9$\times$ speedup in inference) with refined model architecture; (2) improve the Frequency Band Substitution module to allow for input source images of arbitrary resolution and aspect ratio; (3) extend model functionality to enable localized image manipulation and style-specific content creation with only subtle adjustments to the core method. Extensive qualitative and quantitative experiments verify superiority of FBSDiff++ in I2I translation visual quality, efficiency, versatility, and controllability compared to related advanced approaches.

</details>


### [54] [Implicit Non-Causal Factors are Out via Dataset Splitting for Domain Generalization Object Detection](https://arxiv.org/abs/2601.19127)
*Zhilong Zhang,Lei Zhang,Qing He,Shuyin Xia,Guoyin Wang,Fuxiang Huang*

Main category: cs.CV

TL;DR: 提出了一种改进的领域对抗学习方法（GB-DAL），通过生成更密集的领域（PGBS模块）和模拟非因果因素（SNF模块）来克服开放世界目标检测中的领域不变性表示问题，并在多项基准测试中取得了更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有的领域泛化（DG）方法主要关注领域不变信息，但忽略了潜在的非因果因素，这是因为基于领域判别器的领域对抗学习（DAL）方法受限于稀疏的领域标签，并且难以捕捉隐式的非因果因素。

Method: 提出了一种名为GB-DAL的改进DAL方法。其核心模块包括：1. 原型基粒球分裂（PGBS）模块，用于从有限数据集中生成更密集的领域，以揭示更多潜在的非因果因素。2. 模拟非因果因素（SNF）模块，作为一种数据增强手段，以降低非因果因素的隐式性并促进GB-DAL的训练。

Result: 在多个基准测试上的对比实验表明，所提出的GB-DAL方法在新的、未知的环境中表现出更好的泛化性能。

Conclusion: GB-DAL通过PGBS和SNF模块的结合，有效解决了开放世界目标检测中的领域不变表示挑战，显著提升了模型在不同领域间的泛化能力。

Abstract: Open world object detection faces a significant challenge in domain-invariant representation, i.e., implicit non-causal factors. Most domain generalization (DG) methods based on domain adversarial learning (DAL) pay much attention to learn domain-invariant information, but often overlook the potential non-causal factors. We unveil two critical causes: 1) The domain discriminator-based DAL method is subject to the extremely sparse domain label, i.e., assigning only one domain label to each dataset, thus can only associate explicit non-causal factor, which is incredibly limited. 2) The non-causal factors, induced by unidentified data bias, are excessively implicit and cannot be solely discerned by conventional DAL paradigm. Based on these key findings, inspired by the Granular-Ball perspective, we propose an improved DAL method, i.e., GB-DAL. The proposed GB-DAL utilizes Prototype-based Granular Ball Splitting (PGBS) module to generate more dense domains from limited datasets, akin to more fine-grained granular balls, indicating more potential non-causal factors. Inspired by adversarial perturbations akin to non-causal factors, we propose a Simulated Non-causal Factors (SNF) module as a means of data augmentation to reduce the implicitness of non-causal factors, and facilitate the training of GB-DAL. Comparative experiments on numerous benchmarks demonstrate that our method achieves better generalization performance in novel circumstances.

</details>


### [55] [Resolving Primitive-Sharing Ambiguity in Long-Tailed Industrial Point Cloud Segmentation via Spatial Context Constraints](https://arxiv.org/abs/2601.19128)
*Chao Yin,Qing Han,Zhiwei Hou,Yue Liu,Anjin Dai,Hongda Hu,Ji Yang,Wei Yao*

Main category: cs.CV

TL;DR: 该研究提出了一种新的点云分割方法，通过引入空间上下文约束（Boundary-CB 和 Density-CB）来解决工业点云数据中安全关键组件（如减速器和阀门）因类别不平衡和几何歧义而导致的误分类问题，并在 Industrial3D 数据集上取得了显著的性能提升，尤其是在尾部类别和具有几何歧义的组件上。


<details>
  <summary>Details</summary>
Motivation: 工业点云数据在构建数字孪生时，存在安全关键组件（如减速器、阀门）系统性错分的挑战。这源于两个原因：1）训练数据中这些组件稀少（类别极度不平衡）；2）它们与常见结构（如管道）具有相似的局部几何特征（几何歧义）。现有的重加权方法无法解决几何歧义。

Method: 提出了一种名为空间上下文约束（spatial context constraints）的方法，通过利用邻域预测的一致性来消除局部相似结构之间的歧义。该方法将 Class-Balanced (CB) Loss 框架扩展为两个架构无关的模块：1）Boundary-CB：一个基于熵的约束，强调模糊边界；2）Density-CB：一个基于密度的约束，补偿扫描依赖的变化。这两个模块可以作为即插即用模块，只需替换损失函数即可。

Result: 在 Industrial3D 数据集（来自水处理设施的 6.1 亿个点）上，所提出的方法实现了 55.74% 的 mIoU，尾部类别性能相对提升了 21.7%（从 24.32% 提升到 29.59%），同时保持了头部类别的准确性（88.14%）。具有原始几何共享歧义的组件（如减速器、阀门）的 IoU 显著提高，减速器从 0% 提高到 21.12%，阀门相对提高了 24.3%。

Conclusion: 该研究成功地解决了工业点云分割中的类别不平衡和几何歧义问题，通过引入空间上下文约束，在不牺牲头部类别性能的情况下，显著提高了对安全关键组件的识别精度，从而支持自动化知识提取在数字孪生应用中的可靠性。

Abstract: Industrial point cloud segmentation for Digital Twin construction faces a persistent challenge: safety-critical components such as reducers and valves are systematically misclassified. These failures stem from two compounding factors: such components are rare in training data, yet they share identical local geometry with dominant structures like pipes. This work identifies a dual crisis unique to industrial 3D data extreme class imbalance 215:1 ratio compounded by geometric ambiguity where most tail classes share cylindrical primitives with head classes. Existing frequency-based re-weighting methods address statistical imbalance but cannot resolve geometric ambiguity. We propose spatial context constraints that leverage neighborhood prediction consistency to disambiguate locally similar structures. Our approach extends the Class-Balanced (CB) Loss framework with two architecture-agnostic mechanisms: (1) Boundary-CB, an entropy-based constraint that emphasizes ambiguous boundaries, and (2) Density-CB, a density-based constraint that compensates for scan-dependent variations. Both integrate as plug-and-play modules without network modifications, requiring only loss function replacement. On the Industrial3D dataset (610M points from water treatment facilities), our method achieves 55.74% mIoU with 21.7% relative improvement on tail-class performance (29.59% vs. 24.32% baseline) while preserving head-class accuracy (88.14%). Components with primitive-sharing ambiguity show dramatic gains: reducer improves from 0% to 21.12% IoU; valve improves by 24.3% relative. This resolves geometric ambiguity without the typical head-tail trade-off, enabling reliable identification of safety-critical components for automated knowledge extraction in Digital Twin applications.

</details>


### [56] [CLIP-Guided Unsupervised Semantic-Aware Exposure Correction](https://arxiv.org/abs/2601.19129)
*Puzhen Wu,Han Weng,Quan Zheng,Yi Zhan,Hewei Wang,Yiming Li,Jiahui Han,Rui Xu*

Main category: cs.CV

TL;DR: 本文提出了一种无监督的语义感知曝光校正网络，通过融合FastSAM的语义信息和CLIP指导的伪真值生成，解决了曝光不足/过度导致的细节损失、颜色失真和对比度降低的问题，并避免了手动标注，在真实世界图像上取得了优于现有无监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有曝光校正方法存在两个主要挑战：1) 缺乏物体级别的区域语义信息导致颜色偏移伪影；2) 真实世界曝光图像缺乏地面真实标签，手动标注成本高昂。

Method: 提出一种无监督的语义感知曝光校正网络，包含：1) 自适应语义感知融合模块，将FastSAM提取的语义信息融合到共享图像特征空间；2) 多尺度残差空间mamba组，用于恢复细节和调整曝光；3) CLIP引导的伪真值生成器，用于自动识别曝光情况并指导校正；4) 语义-提示一致性损失，利用FastSAM和CLIP的先验知识，强制语义一致性和图像-提示对齐。

Result: 实验结果表明，该方法能有效校正真实世界曝光图像，并在数值和视觉上均优于最先进的无监督方法。

Conclusion: 所提出的无监督语义感知曝光校正网络能够有效解决语义信息缺失和缺乏地面真实标签的问题，实现高质量的曝光校正，且性能优于现有无监督方法。

Abstract: Improper exposure often leads to severe loss of details, color distortion, and reduced contrast. Exposure correction still faces two critical challenges: (1) the ignorance of object-wise regional semantic information causes the color shift artifacts; (2) real-world exposure images generally have no ground-truth labels, and its labeling entails massive manual editing. To tackle the challenges, we propose a new unsupervised semantic-aware exposure correction network. It contains an adaptive semantic-aware fusion module, which effectively fuses the semantic information extracted from a pre-trained Fast Segment Anything Model into a shared image feature space. Then the fused features are used by our multi-scale residual spatial mamba group to restore the details and adjust the exposure. To avoid manual editing, we propose a pseudo-ground truth generator guided by CLIP, which is fine-tuned to automatically identify exposure situations and instruct the tailored corrections. Also, we leverage the rich priors from the FastSAM and CLIP to develop a semantic-prompt consistency loss to enforce semantic consistency and image-prompt alignment for unsupervised training. Comprehensive experimental results illustrate the effectiveness of our method in correcting real-world exposure images and outperforms state-of-the-art unsupervised methods both numerically and visually.

</details>


### [57] [QA-ReID: Quality-Aware Query-Adaptive Convolution Leveraging Fused Global and Structural Cues for Clothes-Changing ReID](https://arxiv.org/abs/2601.19133)
*Yuxiang Wang,Kunming Jiang,Tianxiang Zhang,Ke Tian,Gaozhe Jiang*

Main category: cs.CV

TL;DR: 提出一种名为QA-ReID的方法，通过结合RGB特征和解析特征，并引入多模态注意力机制和质量感知查询自适应卷积，有效解决服装变化带来的外观差异，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统的行人重识别方法在面对服装变化时面临严峻挑战，因为服装变化会引入显著的外观差异。因此，需要一种能够处理服装变化的新方法。

Method: 提出QA-ReID方法，该方法联合利用基于RGB的特征和基于解析的表示，通过多模态注意力模块自适应融合这些异构特征。在匹配阶段，设计了质量感知查询自适应卷积（QAConv-QA），包含像素级重要性加权和双向一致性约束，以增强对服装变化的鲁棒性。

Result: QA-ReID在PRCC、LTCC和VC-Clothes等多个基准测试中取得了最先进的性能，并在跨服装场景下显著优于现有方法。

Conclusion: QA-ReID通过结合全局外观和服装不变的结构线索，并引入质量感知机制，能够有效应对服装变化带来的挑战，在服装变化行人重识别任务中表现出色。

Abstract: Unlike conventional person re-identification (ReID), clothes-changing ReID (CC-ReID) presents severe challenges due to substantial appearance variations introduced by clothing changes. In this work, we propose the Quality-Aware Dual-Branch Matching (QA-ReID), which jointly leverages RGB-based features and parsing-based representations to model both global appearance and clothing-invariant structural cues. These heterogeneous features are adaptively fused through a multi-modal attention module. At the matching stage, we further design the Quality-Aware Query Adaptive Convolution (QAConv-QA), which incorporates pixel-level importance weighting and bidirectional consistency constraints to enhance robustness against clothing variations. Extensive experiments demonstrate that QA-ReID achieves state-of-the-art performance on multiple benchmarks, including PRCC, LTCC, and VC-Clothes, and significantly outperforms existing approaches under cross-clothing scenarios.

</details>


### [58] [TFFM: Topology-Aware Feature Fusion Module via Latent Graph Reasoning for Retinal Vessel Segmentation](https://arxiv.org/abs/2601.19136)
*Iftekhar Ahmed,Shakib Absar,Aftar Ahmad Sami,Shadman Sakib,Debojyoti Biswas,Seraj Al Mahmud Mostafa*

Main category: cs.CV

TL;DR: 提出了一种拓扑感知框架，用于视网膜血管分割，该框架通过融合图注意力网络和混合损失函数来解决传统卷积网络的拓扑不连续性问题，并在Fundus-AVSeg数据集上取得了最先进的性能，显著减少了血管断裂。


<details>
  <summary>Details</summary>
Motivation: 传统的卷积神经网络在视网膜血管分割时容易产生拓扑不连续的分割结果，导致无法进行可靠的临床分析。研究旨在开发一种能够保持血管连通性的分割方法。

Method: 提出了一种拓扑感知框架，该框架包含一个拓扑特征融合模块（TFFM），将局部特征映射到潜在图空间，并使用图注意力网络（GAT）捕获全局结构依赖性。同时，采用了Tversky损失和soft-clDice损失的混合目标函数来处理类别不平衡和拓扑断开问题。

Result: 在Fundus-AVSeg数据集上取得了最先进的性能，Dice得分为90.97%，Hausdorff距离为3.50像素。与基线方法相比，血管碎片减少了约38%。

Conclusion: 提出的拓扑感知框架能够生成拓扑连贯的血管树，适用于自动生物标志物定量分析，解决了现有方法的拓扑不连续性问题。

Abstract: Precise segmentation of retinal arteries and veins carries the diagnosis of systemic cardiovascular conditions. However, standard convolutional architectures often yield topologically disjointed segmentations, characterized by gaps and discontinuities that render reliable graph-based clinical analysis impossible despite high pixel-level accuracy. To address this, we introduce a topology-aware framework engineered to maintain vascular connectivity. Our architecture fuses a Topological Feature Fusion Module (TFFM) that maps local feature representations into a latent graph space, deploying Graph Attention Networks to capture global structural dependencies often missed by fixed receptive fields. Furthermore, we drive the learning process with a hybrid objective function, coupling Tversky loss for class imbalance with soft clDice loss to explicitly penalize topological disconnects. Evaluation on the Fundus-AVSeg dataset reveals state-of-the-art performance, achieving a combined Dice score of 90.97% and a 95% Hausdorff Distance of 3.50 pixels. Notably, our method decreases vessel fragmentation by approximately 38% relative to baselines, yielding topologically coherent vascular trees viable for automated biomarker quantification. We open-source our code at https://tffm-module.github.io/.

</details>


### [59] [GTFMN: Guided Texture and Feature Modulation Network for Low-Light Image Enhancement and Super-Resolution](https://arxiv.org/abs/2601.19157)
*Yongsong Huang,Tzu-Hsuan Peng,Tomo Miyazaki,Xiaofeng Liu,Chun-Ting Chou,Ai-Chun Pang,Shinichiro Omachi*

Main category: cs.CV

TL;DR: 提出了一种名为GTFMN的新型网络，将低光图像超分辨率（LLSR）任务分解为光照估计和纹理恢复两个子问题，通过光照图指导特征调制，实现了空间自适应恢复，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 低光图像超分辨率（LLSR）任务面临低分辨率和光照不足的双重挑战。

Method: 提出了一种名为GTFMN（Guided Texture and Feature Modulation Network）的新型框架。该框架将LLSR任务分解为两个子问题：光照估计和纹理恢复。首先，通过一个独立的光照流（Illumination Stream）来预测空间变化的、准确捕捉光照分布的光照图。然后，利用这个光照图作为显式引导，在纹理流（Texture Stream）中使用一种新颖的光照引导调制块（IGM Block）来动态调制特征。这种机制实现了空间自适应恢复，能够增强光照不足的区域，同时保留曝光良好的区域的细节。

Result: 在OmniNormal5和OmniNormal15数据集上的大量实验表明，GTFMN在量化指标和视觉质量方面均优于竞争方法，取得了最佳性能。

Conclusion: GTFMN能够通过将LLSR任务分解为光照估计和纹理恢复，并利用光照图实现空间自适应的特征调制，从而有效地解决低光图像超分辨率问题，并在实验中展现出优越性。

Abstract: Low-light image super-resolution (LLSR) is a challenging task due to the coupled degradation of low resolution and poor illumination. To address this, we propose the Guided Texture and Feature Modulation Network (GTFMN), a novel framework that decouples the LLSR task into two sub-problems: illumination estimation and texture restoration. First, our network employs a dedicated Illumination Stream whose purpose is to predict a spatially varying illumination map that accurately captures lighting distribution. Further, this map is utilized as an explicit guide within our novel Illumination Guided Modulation Block (IGM Block) to dynamically modulate features in the Texture Stream. This mechanism achieves spatially adaptive restoration, enabling the network to intensify enhancement in poorly lit regions while preserving details in well-exposed areas. Extensive experiments demonstrate that GTFMN achieves the best performance among competing methods on the OmniNormal5 and OmniNormal15 datasets, outperforming them in both quantitative metrics and visual quality.

</details>


### [60] [SNR-Edit: Structure-Aware Noise Rectification for Inversion-Free Flow-Based Editing](https://arxiv.org/abs/2601.19180)
*Lifan Jiang,Boxi Wu,Yuhang Pei,Tianrun Wu,Yongyuan Chen,Yan Zhao,Shiyu Yu,Deng Cai*

Main category: cs.CV

TL;DR: 提出了一种名为SNR-Edit的无需训练的图像编辑框架，通过自适应噪声控制来校正潜在轨迹，解决了现有方法中固定高斯噪声导致的轨迹偏差和结构退化问题，实现了高保真编辑。


<details>
  <summary>Details</summary>
Motivation: 现有无需反演的基于流的生成模型图像编辑方法依赖于固定的高斯噪声来构建源轨迹，这会导致轨迹动态偏差，进而引起结构退化或质量损失。研究旨在解决这一问题。

Method: SNR-Edit框架通过结构感知噪声校正，将分割约束注入初始噪声，将源轨迹的随机分量锚定到真实图像的隐式反演位置，从而减少了源-目标传输过程中的轨迹漂移。这种修改无需模型微调或反演。

Result: 在SD3和FLUX模型上，针对PIE-Bench和SNR-Bench的评估显示，SNR-Edit在像素级指标和基于VLM的评分方面均表现出色，同时每张图像的额外开销仅约1秒。

Conclusion: SNR-Edit是一种有效的训练免费图像编辑框架，通过自适应噪声控制实现高保真潜在轨迹校正，能够平滑潜在轨迹并确保高保真结构保持，且计算开销小。

Abstract: Inversion-free image editing using flow-based generative models challenges the prevailing inversion-based pipelines. However, existing approaches rely on fixed Gaussian noise to construct the source trajectory, leading to biased trajectory dynamics and causing structural degradation or quality loss. To address this, we introduce SNR-Edit, a training-free framework achieving faithful Latent Trajectory Correction via adaptive noise control. Mechanistically, SNR-Edit uses structure-aware noise rectification to inject segmentation constraints into the initial noise, anchoring the stochastic component of the source trajectory to the real image's implicit inversion position and reducing trajectory drift during source--target transport. This lightweight modification yields smoother latent trajectories and ensures high-fidelity structural preservation without requiring model tuning or inversion. Across SD3 and FLUX, evaluations on PIE-Bench and SNR-Bench show that SNR-Edit delivers performance on pixel-level metrics and VLM-based scoring, while adding only about 1s overhead per image.

</details>


### [61] [Contrastive Spectral Rectification: Test-Time Defense towards Zero-shot Adversarial Robustness of CLIP](https://arxiv.org/abs/2601.19210)
*Sen Nie,Jie Zhang,Zhuo Wang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 提出一种名为对比谱校正 (CSR) 的高效测试时间防御方法，通过优化校正扰动来纠正对抗样本，在多个分类基准测试中显著优于现有方法，并具有良好的跨任务通用性。


<details>
  <summary>Details</summary>
Motivation: 现有针对视觉语言模型（VLMs）的对抗性样本（AEs）的测试时间防御方法在鲁棒性、推理延迟和任务适用性方面存在不足。

Method: 研究人员发现AEs在频率衰减下表现出严重的特征不一致性，并将其归因于模型的频谱偏差。在此基础上，提出CSR方法，通过优化一个校正扰动，利用谱引导的对比目标将输入对齐到自然流形。

Result: 在16个分类基准测试中，CSR在对抗AutoAttack强攻击时，平均比现有最优方法（SOTA）提升18.1%，且推理开销适中。CSR还展现了在不同视觉任务上的广泛适用性。

Conclusion: CSR是一种有效且高效的测试时间防御方法，能够显著提高VLMs对抗AEs的鲁棒性，并且具有良好的通用性。

Abstract: Vision-language models (VLMs) such as CLIP have demonstrated remarkable zero-shot generalization, yet remain highly vulnerable to adversarial examples (AEs). While test-time defenses are promising, existing methods fail to provide sufficient robustness against strong attacks and are often hampered by high inference latency and task-specific applicability. To address these limitations, we start by investigating the intrinsic properties of AEs, which reveals that AEs exhibit severe feature inconsistency under progressive frequency attenuation. We further attribute this to the model's inherent spectral bias. Leveraging this insight, we propose an efficient test-time defense named Contrastive Spectral Rectification (CSR). CSR optimizes a rectification perturbation to realign the input with the natural manifold under a spectral-guided contrastive objective, which is applied input-adaptively. Extensive experiments across 16 classification benchmarks demonstrate that CSR outperforms the SOTA by an average of 18.1% against strong AutoAttack with modest inference overhead. Furthermore, CSR exhibits broad applicability across diverse visual tasks. Code is available at https://github.com/Summu77/CSR.

</details>


### [62] [UniPCB: A Unified Vision-Language Benchmark for Open-Ended PCB Quality Inspection](https://arxiv.org/abs/2601.19222)
*Fuxiang Sun,Xi Jiang,Jiansheng Wu,Haigang Zhang,Feng Zheng,Jinfeng Yang*

Main category: cs.CV

TL;DR: 本文提出了 UniPCB，一个用于印刷电路板（PCB）质量检测的统一视觉-语言基准，并在此基础上开发了 PCB-GPT 模型，该模型在 PCB 缺陷检测任务上表现优于现有 MLLM，尤其在细粒度缺陷定位方面。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在复杂的工业质量检测场景（如 PCB 检测）中表现不足，而缺乏一个统一、高质量的视觉-语言基准来量化评估 MLLMs 在 PCB 检测任务上的性能，主要由于数据碎片化和标准化不足。

Method: 构建了一个系统的流水线来整理和标准化来自不同来源的 PCB 检测数据，创建了 UniPCB 基准。同时，设计了一个新的指令数据集，并基于此训练了 PCB-GPT 模型，采用了模拟人类专家学习过程的渐进式课程学习方法。

Result: UniPCB 基准的评估显示，现有 MLLMs 在特定领域任务上表现不佳，而 PCB-GPT 建立了新的基线，在细粒度缺陷定位方面性能翻倍，在定位和分析方面具有显著优势。

Conclusion: UniPCB 是首个用于开放式 PCB 质量检测的统一视觉-语言基准，PCB-GPT 在该基准上展现出优越性能，表明针对特定领域进行 MLLM 训练和基准构建的重要性，并为未来的研究提供了数据、基准和模型。

Abstract: Multimodal Large Language Models (MLLMs) show promise for general industrial quality inspection, but fall short in complex scenarios, such as Printed Circuit Board (PCB) inspection. PCB inspection poses unique challenges due to densely packed components, complex wiring structures, and subtle defect patterns that require specialized domain expertise. However, a high-quality, unified vision-language benchmark for quantitatively evaluating MLLMs across PCB inspection tasks remains absent, stemming not only from limited data availability but also from fragmented datasets and inconsistent standardization. To fill this gap, we propose UniPCB, the first unified vision-language benchmark for open-ended PCB quality inspection. UniPCB is built via a systematic pipeline that curates and standardizes data from disparate sources across three annotated scenarios. Furthermore, we introduce PCB-GPT, an MLLM trained on a new instruction dataset generated by this pipeline, utilizing a novel progressive curriculum that mimics the learning process of human experts. Evaluations on the UniPCB benchmark show that while existing MLLMs falter on domain-specific tasks, PCB-GPT establishes a new baseline. Notably, it more than doubles the performance on fine-grained defect localization compared to the strongest competitors, with significant advantages in localization and analysis. We will release the instruction data, benchmark, and model to facilitate future research.

</details>


### [63] [The S3LI Vulcano Dataset: A Dataset for Multi-Modal SLAM in Unstructured Planetary Environments](https://arxiv.org/abs/2601.19557)
*Riccardo Giubilato,Marcus Gerhard Müller,Marco Sewtz,Laura Alejandra Encinar Gonzalez,John Folkesson,Rudolph Triebel*

Main category: cs.CV

TL;DR: 发布了一个名为S3LI Vulcano的多模态数据集，包含视觉和LiDAR数据，用于SLAM和场景识别算法的开发和基准测试。该数据集在意大利Vulcano岛录制，涵盖了多样的环境、纹理和地形，并提供了一个开源工具包来生成地面真实位姿和标注样本。


<details>
  <summary>Details</summary>
Motivation: 为了支持和促进依赖视觉和LiDAR数据的同步定位与地图构建（SLAM）和场景识别算法的开发和评估，需要一个多模态数据集。

Method: 在意大利Vulcano岛录制了多个包含视觉和LiDAR数据的序列。使用开源工具包生成地面真实位姿，并准备用于场景识别任务的标注样本。

Result: 创建并发布了S3LI Vulcano数据集，该数据集提供了多样化的环境、纹理和地形数据，包括岩石、地质构造、植被和水。同时发布了一个开源工具包，用于数据处理和地面真实生成。

Conclusion: S3LI Vulcano数据集及其配套工具包为研究人员提供了一个宝贵的资源，能够推动多模态SLAM和场景识别技术的发展，特别是在复杂和多样的环境中。

Abstract: We release the S3LI Vulcano dataset, a multi-modal dataset towards development and benchmarking of Simultaneous Localization and Mapping (SLAM) and place recognition algorithms that rely on visual and LiDAR modalities. Several sequences are recorded on the volcanic island of Vulcano, from the Aeolian Islands in Sicily, Italy. The sequences provide users with data from a variety of environments, textures and terrains, including basaltic or iron-rich rocks, geological formations from old lava channels, as well as dry vegetation and water. The data (rmc.dlr.de/s3li_dataset) is accompanied by an open source toolkit (github.com/DLR-RM/s3li-toolkit) providing tools for generating ground truth poses as well as preparation of labelled samples for place recognition tasks.

</details>


### [64] [Towards Pixel-Level VLM Perception via Simple Points Prediction](https://arxiv.org/abs/2601.19228)
*Tianhui Song,Haoyu Lu,Hao Yang,Lin Sui,Haoning Wu,Zaida Zhou,Zhiqi Huang,Yiping Bao,Y. Charles,Xinyu Zhou,Limin Wang*

Main category: cs.CV

TL;DR: SimpleSeg 提出了一种新颖的像素级分割方法，将分割任务重新定义为序列生成问题，模型直接在语言空间中预测边界点坐标，并通过强化学习进行优化，无需专门的分割架构，实现了与复杂方法相当甚至更优的性能。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLMs 在像素级感知方面能力不足，通常需要复杂的、特定任务的设计。研究者希望探索一种更简洁、更通用的方法来赋予 MLLMs 原生的像素级感知能力，挑战通用视觉语言模型（VLMs）必须依赖辅助组件的观点。

Method: 将分割任务视为序列生成问题，直接在语言空间中预测文本坐标序列来表示对象边界。采用两阶段的 SF->RL 训练流程，其中基于 IoU 的奖励的强化学习用于优化预测的点序列，以精确匹配真实轮廓。

Result: 标准 MLLM 架构本身就具备强大的低级感知能力，可以通过 SimpleSeg 方法解锁。在分割基准测试中，SimpleSeg 取得了与依赖复杂、任务特定设计的其他方法相当甚至更优的性能。

Conclusion: 精确的空间理解可以通过简单的点预测实现，无需复杂的辅助组件，这为构建更统一、更强大的 VLM 铺平了道路。SimpleSeg 的方法证明了 MLLMs 在像素级感知方面的潜力。

Abstract: We present SimpleSeg, a strikingly simple yet highly effective approach to endow Multimodal Large Language Models (MLLMs) with native pixel-level perception. Our method reframes segmentation as a simple sequence generation problem: the model directly predicts sequences of points (textual coordinates) delineating object boundaries, entirely within its language space. To achieve high fidelity, we introduce a two-stage SF$\to$RL training pipeline, where Reinforcement Learning with an IoU-based reward refines the point sequences to accurately match ground-truth contours. We find that the standard MLLM architecture possesses a strong, inherent capacity for low-level perception that can be unlocked without any specialized architecture. On segmentation benchmarks, SimpleSeg achieves performance that is comparable to, and often surpasses, methods relying on complex, task-specific designs. This work lays out that precise spatial understanding can emerge from simple point prediction, challenging the prevailing need for auxiliary components and paving the way for more unified and capable VLMs. Homepage: https://simpleseg.github.io/

</details>


### [65] [VGGT-SLAM 2.0: Real time Dense Feed-forward Scene Reconstruction](https://arxiv.org/abs/2601.19887)
*Dominic Maggio,Luca Carlone*

Main category: cs.CV

TL;DR: VGGT-SLAM 2.0 提出了一个实时前馈 SLAM 系统，通过改进因子图设计、利用 VGGT 的注意力层进行图像检索验证，以及扩展至开放集目标检测，显著提升了姿态估计精度和鲁棒性，并在多个数据集和真实机器人平台上验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服 VGGT-SLAM 在处理高维漂移、平面退化以及 VGGT 重建模糊性方面的不足，并进一步提升 SLAM 系统的精度、鲁棒性和实时性。

Method: 1. 设计新的因子图以消除高维 15 自由度漂移和平面退化，同时解决 VGGT 在相机内参未知情况下的重建模糊性。 2. 利用 VGGT 的注意力层，在无需额外训练的情况下，辅助图像检索验证，以拒绝误匹配并完成更多回环检测。 3. 进行了广泛的实验验证，包括在不同环境（室内公寓、办公室、谷仓）下的实时在线测试，以及在 TUM 数据集上的精度评估。

Result: VGGT-SLAM 2.0 在 TUM 数据集上实现了比 VGGT-SLAM 降低约 23% 的姿态误差，达到了更高的精度。系统展现出实时性能，并能轻松适配开放集目标检测。在真实机器人平台上（Jetson Thor）进行了成功在线运行。

Conclusion: VGGT-SLAM 2.0 是一种有效的实时 SLAM 系统，通过创新的因子图设计和利用预训练模型的注意力层，显著提高了姿态估计的精度和鲁棒性，并扩展了其在目标检测等方面的应用潜力。

Abstract: We present VGGT-SLAM 2.0, a real time RGB feed-forward SLAM system which substantially improves upon VGGT-SLAM for incrementally aligning submaps created from VGGT. Firstly, we remove high-dimensional 15-degree-of-freedom drift and planar degeneracy from VGGT-SLAM by creating a new factor graph design while still addressing the reconstruction ambiguity of VGGT given unknown camera intrinsics. Secondly, by studying the attention layers of VGGT, we show that one of the layers is well suited to assist in image retrieval verification for free without additional training, which enables both rejecting false positive matches and allows for completing more loop closures. Finally, we conduct a suite of experiments which includes showing VGGT-SLAM 2.0 can easily be adapted for open-set object detection and demonstrating real time performance while running online onboard a ground robot using a Jetson Thor. We also test in environments ranging from cluttered indoor apartments and office scenes to a 4,200 square foot barn, and we also demonstrate VGGT-SLAM 2.0 achieves the highest accuracy on the TUM dataset with about 23 percent less pose error than VGGT-SLAM. Code will be released upon publication.

</details>


### [66] [VC-Bench: Pioneering the Video Connecting Benchmark with a Dataset and Evaluation Metrics](https://arxiv.org/abs/2601.19236)
*Zhiyu Yin,Zhipeng Liu,Kehai Chen,Lemao Liu,Jin Liu,Hong-Dong Li,Yang Xiang,Min Zhang*

Main category: cs.CV

TL;DR: 本文提出了视频连接（Video Connecting）任务，并为此设计了一个名为VC-Bench的新评估基准，旨在解决现有视频生成方法在连接独立视频片段时的不足，并为该领域的研究提供指导。VC-Bench包含1579个视频，从视频质量、首尾一致性和过渡平滑度三个维度进行评估。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成方法主要关注文本或图像条件下的视频生成，而实际应用如视频编辑和vlogging需要无缝连接独立的视频片段。然而，视频连接任务缺乏标准化的评估基准来衡量视频的连贯性和流畅性。

Method: 提出视频连接（Video Connecting）任务，并开发了一个名为VC-Bench的新评估基准。VC-Bench包含1579个来自公共平台的视频，覆盖15个主要类别和72个子类别。评估指标包括视频质量得分（VQS）、首尾一致性得分（SECS）和过渡平滑度得分（TSS）。在VC-Bench上评估了多个先进的视频生成模型。

Result: 在VC-Bench上的实验表明，现有的视频生成模型在保持首尾一致性和过渡平滑度方面存在显著局限，导致视频的整体连贯性和流畅性不足。

Conclusion: VC-Bench是一个开创性的基准，能够激励和指导未来在视频连接领域的研究。提出的评估指标和数据集旨在促进视频连接任务的发展，克服当前模型的不足。

Abstract: While current video generation focuses on text or image conditions, practical applications like video editing and vlogging often need to seamlessly connect separate clips. In our work, we introduce Video Connecting, an innovative task that aims to generate smooth intermediate video content between given start and end clips. However, the absence of standardized evaluation benchmarks has hindered the development of this task. To bridge this gap, we proposed VC-Bench, a novel benchmark specifically designed for video connecting. It includes 1,579 high-quality videos collected from public platforms, covering 15 main categories and 72 subcategories to ensure diversity and structure. VC-Bench focuses on three core aspects: Video Quality Score VQS, Start-End Consistency Score SECS, and Transition Smoothness Score TSS. Together, they form a comprehensive framework that moves beyond conventional quality-only metrics. We evaluated multiple state-of-the-art video generation models on VC-Bench. Experimental results reveal significant limitations in maintaining start-end consistency and transition smoothness, leading to lower overall coherence and fluidity. We expect that VC-Bench will serve as a pioneering benchmark to inspire and guide future research in video connecting. The evaluation metrics and dataset are publicly available at: https://anonymous.4open.science/r/VC-Bench-1B67/.

</details>


### [67] [TIGaussian: Disentangle Gaussians for Spatial-Awared Text-Image-3D Alignment](https://arxiv.org/abs/2601.19247)
*Jiarun Liu,Qifeng Chen,Yiru Zhao,Minghua Liu,Baorui Ma,Sheng Yang*

Main category: cs.CV

TL;DR: 本文提出了 TIGaussian 框架，利用 3D 高斯泼溅 (3DGS) 的特性，通过多分支 3DGS 分词器和特定模态的 3D 特征对齐策略，增强跨模态对齐，以解决 3D 数据（如点云和 3D 高斯）与文本模态之间的特征提取和对齐难题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在连接文本和图像方面表现出色，但将 3D 模态数据（如点云和 3D 高斯）纳入预训练以执行 3D 相关任务（如跨模态检索、零样本分类和场景识别）仍面临挑战，特别是 3D 模态特征的提取以及模态间的鸿沟。因此，研究需要能够有效处理 3D 数据的跨模态模型。

Method: TIGaussian 框架采用多分支 3DGS 分词器将 3DGS 结构的内在属性解耦为紧凑的潜在表示，从而实现更具泛化性的特征提取。为弥合模态间的鸿沟，该框架开发了双向跨模态对齐策略：一是多视图特征融合机制，利用扩散先验解决图像-3D 对齐中的视角歧义；二是文本-3D 投影模块，自适应地将 3D 特征映射到文本嵌入空间，以实现更好的文本-3D 对齐。

Result: 在多个数据集上的广泛实验表明，TIGaussian 在多项任务上达到了最先进的性能。

Conclusion: TIGaussian 框架通过创新的 3DGS 分词和跨模态对齐策略，有效解决了 3D 数据与文本模态之间的特征提取和对齐问题，并在多个 3D 相关任务中取得了优异的表现，证明了其在跨模态 3D 理解领域的有效性。

Abstract: While visual-language models have profoundly linked features between texts and images, the incorporation of 3D modality data, such as point clouds and 3D Gaussians, further enables pretraining for 3D-related tasks, e.g., cross-modal retrieval, zero-shot classification, and scene recognition. As challenges remain in extracting 3D modal features and bridging the gap between different modalities, we propose TIGaussian, a framework that harnesses 3D Gaussian Splatting (3DGS) characteristics to strengthen cross-modality alignment through multi-branch 3DGS tokenizer and modality-specific 3D feature alignment strategies. Specifically, our multi-branch 3DGS tokenizer decouples the intrinsic properties of 3DGS structures into compact latent representations, enabling more generalizable feature extraction. To further bridge the modality gap, we develop a bidirectional cross-modal alignment strategies: a multi-view feature fusion mechanism that leverages diffusion priors to resolve perspective ambiguity in image-3D alignment, while a text-3D projection module adaptively maps 3D features to text embedding space for better text-3D alignment. Extensive experiments on various datasets demonstrate the state-of-the-art performance of TIGaussian in multiple tasks.

</details>


### [68] [A Multi-View Consistency Framework with Semi-Supervised Domain Adaptation](https://arxiv.org/abs/2601.19266)
*Yuting Hong,Li Dong,Xiaojie Qiu,Hui Xiao,Baochen Yao,Siming Zheng,Chengbin Peng*

Main category: cs.CV

TL;DR: 提出了一种新的半监督域适应（SSDA）框架，通过多视图一致性、去偏置策略和伪负标签来解决目标域标签稀疏性导致的类别相似性问题，并通过跨域亲和力学习进一步对齐跨域特征，在DomainNet和Office-Home数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有SSDA方法在目标域标签样本有限的情况下，由于类别在特征空间中可能存在内在相似性，容易产生有偏见的预测，即使在平衡数据集上训练也难以克服。

Method: 提出一个多视图一致性框架，包括：1. 对强增强数据进行去偏置策略，根据模型预测性能校正类别预测概率；2. 利用模型预测的伪负标签；3. 引入跨域亲和力学习，对齐不同域中同一类别的特征。

Result: 在DomainNet和Office-Home两个标准域适应数据集上，提出的方法显著优于现有竞争方法。

Conclusion: 该方法通过多视图一致性、去偏置策略、伪负标签和跨域亲和力学习，有效解决了SSDA中的挑战，为工业界提供了提高模型适应性、降低标注成本和提升性能的解决方案。

Abstract: Semi-Supervised Domain Adaptation (SSDA) leverages knowledge from a fully labeled source domain to classify data in a partially labeled target domain. Due to the limited number of labeled samples in the target domain, there can be intrinsic similarity of classes in the feature space, which may result in biased predictions, even when the model is trained on a balanced dataset. To overcome this limitation, we introduce a multi-view consistency framework, which includes two views for training strongly augmented data. One is a debiasing strategy for correcting class-wise prediction probabilities according to the prediction performance of the model. The other involves leveraging pseudo-negative labels derived from the model predictions. Furthermore, we introduce a cross-domain affinity learning aimed at aligning features of the same class across different domains, thereby enhancing overall performance. Experimental results demonstrate that our method outperforms the competing methods on two standard domain adaptation datasets, DomainNet and Office-Home. Combining unsupervised domain adaptation and semi-supervised learning offers indispensable contributions to the industrial sector by enhancing model adaptability, reducing annotation costs, and improving performance.

</details>


### [69] [Handcrafted Feature Fusion for Reliable Detection of AI-Generated Images](https://arxiv.org/abs/2601.19262)
*Syed Mehedi Hasan Nirob,Moqsadur Rahman,Shamim Ehsan,Summit Haque*

Main category: cs.CV

TL;DR: 该研究系统评估了多种手工设计的特征（如原始像素、颜色直方图、DCT、HOG、LBP、GLCM、小波特征）在检测合成图像方面的性能，并与多种分类器（包括 LightGBM、XGBoost、CatBoost）结合进行测试。结果表明，混合特征与 LightGBM 结合能获得最佳性能，显示了手工特征和集成学习在合成图像检测中的重要性和有效性。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型的发展，合成图像的逼真度不断提高，对数字媒体的真实性和信任度构成了威胁。因此，可靠地检测这些伪造内容成为一项紧迫的挑战。尽管深度学习方法是当前的主流，但手工特征因其可解释性、效率和通用性而具有吸引力。

Method: 研究系统地评估了多种手工设计的特征描述符，包括原始像素、颜色直方图、离散余弦变换 (DCT)、方向梯度直方图 (HOG)、局部二值模式 (LBP)、灰度共生矩阵 (GLCM) 和小波特征。这些特征被应用于 CIFAKE 数据集（包含真实和合成图像），并与七种不同的分类器（从逻辑回归到 LightGBM、XGBoost、CatBoost 等梯度提升集成模型）相结合进行基准测试。研究使用了 50,000 个训练样本和 10,000 个测试样本。

Result: 在 CIFAKE 数据集上，LightGBM 分类器在结合混合特征时表现出最优越的性能，达到了 PR-AUC 0.9879、ROC-AUC 0.9878、F1 分数 0.9447 和 Brier 分数 0.0414。研究还发现，无论是在基线、高级还是混合特征配置下，性能都随着特征组合的增加而单调提升，这证实了结合多种手工特征可以带来显著的性能提升。

Conclusion: 研究结论强调了精心设计的特征和集成学习在合成图像检测中的持续相关性，特别是在对可解释性和计算效率有较高要求的场景下。混合手工特征与 LightGBM 等强大分类器相结合，能够有效且可靠地检测合成图像。

Abstract: The rapid progress of generative models has enabled the creation of highly realistic synthetic images, raising concerns about authenticity and trust in digital media. Detecting such fake content reliably is an urgent challenge. While deep learning approaches dominate current literature, handcrafted features remain attractive for their interpretability, efficiency, and generalizability. In this paper, we conduct a systematic evaluation of handcrafted descriptors, including raw pixels, color histograms, Discrete Cosine Transform (DCT), Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), Gray-Level Co-occurrence Matrix (GLCM), and wavelet features, on the CIFAKE dataset of real versus synthetic images. Using 50,000 training and 10,000 test samples, we benchmark seven classifiers ranging from Logistic Regression to advanced gradient-boosted ensembles (LightGBM, XGBoost, CatBoost). Results demonstrate that LightGBM consistently outperforms alternatives, achieving PR-AUC 0.9879, ROC-AUC 0.9878, F1 0.9447, and a Brier score of 0.0414 with mixed features, representing strong gains in calibration and discrimination over simpler descriptors. Across three configurations (baseline, advanced, mixed), performance improves monotonically, confirming that combining diverse handcrafted features yields substantial benefit. These findings highlight the continued relevance of carefully engineered features and ensemble learning for detecting synthetic images, particularly in contexts where interpretability and computational efficiency are critical.

</details>


### [70] [ProMist-5K: A Comprehensive Dataset for Digital Emulation of Cinematic Pro-Mist Filter Effects](https://arxiv.org/abs/2601.19295)
*Yingtie Lei,Zimeng Li,Chi-Man Pun,Wangyu Wu,Junke Yang,Xuhang Chen*

Main category: cs.CV

TL;DR: 本文提出了ProMist-5K数据集，用于在数字图像中重现Pro-Mist滤镜的柔光、低对比度和氛围感效果，该数据集包含20,000对高分辨率图像，覆盖不同滤镜密度和焦距，并采用物理启发的方法构建，有助于电影风格的图像转换。


<details>
  <summary>Details</summary>
Motivation: 传统的Pro-Mist滤镜在电影拍摄中能产生独特的柔光、低对比度和氛围感效果，但这些效果难以在数字领域精确复制。现有数据集未能充分捕捉这些光学扩散的复杂性。

Method: 使用物理启发式流程在场景参考线性空间中构建ProMist-5K数据集。该数据集包含20,000对高分辨率图像，涵盖两种滤镜密度（1/2和1/8）和两种焦距（20mm和50mm）。通过多层模糊和精心调整的权重来模拟光学扩散的变化强度和扩散范围。

Result: 实验表明，ProMist-5K数据集在不同的训练设置下都能取得良好的效果，能够捕捉到细微和显著的电影外观。该数据集为图像翻译模型提供了一个现实且可控的目标域。

Conclusion: ProMist-5K是一个实用且基于物理原理的资源，能够帮助数字图像转换模型学习并重现电影镜头的美学效果，弥合了数字灵活性与传统光学镜头美学之间的差距。

Abstract: Pro-Mist filters are widely used in cinematography for their ability to create soft halation, lower contrast, and produce a distinctive, atmospheric style. These effects are difficult to reproduce digitally due to the complex behavior of light diffusion. We present ProMist-5K, a dataset designed to support cinematic style emulation. It is built using a physically inspired pipeline in a scene-referred linear space and includes 20,000 high-resolution image pairs across four configurations, covering two filter densities (1/2 and 1/8) and two focal lengths (20mm and 50mm). Unlike general style datasets, ProMist-5K focuses on realistic glow and highlight diffusion effects. Multiple blur layers and carefully tuned weighting are used to model the varying intensity and spread of optical diffusion. The dataset provides a consistent and controllable target domain that supports various image translation models and learning paradigms. Experiments show that the dataset works well across different training settings and helps capture both subtle and strong cinematic appearances. ProMist-5K offers a practical and physically grounded resource for film-inspired image transformation, bridging the gap between digital flexibility and traditional lens aesthetics. The dataset is available at https://www.kaggle.com/datasets/yingtielei/promist5k.

</details>


### [71] [Beyond Shadows: A Large-Scale Benchmark and Multi-Stage Framework for High-Fidelity Facial Shadow Removal](https://arxiv.org/abs/2601.19309)
*Tailong Luo,Jiesong Bai,Jinyang Huang,Junyu Xia,Wangyu Wu,Xuhang Chen*

Main category: cs.CV

TL;DR: 本文提出了ASFW数据集，一个大规模真实世界人脸阴影去除数据集，并基于此训练了FSE模型，提高了真实场景下人脸阴影去除的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸阴影去除方法在复杂光照下难以同时去除阴影并保留纹理，且缺乏真实世界的成对数据集进行训练。

Method: 构建了一个包含1081对真实世界阴影和无阴影人脸图像的ASFW数据集，该数据集通过专业的Photoshop流程创建。并提出Face Shadow Eraser (FSE) 方法来展示数据集的有效性。

Result: 在ASFW数据集上训练的深度模型在真实世界条件下表现出更优的阴影去除能力。FSE方法展示了ASFW数据集的有效性。

Conclusion: ASFW数据集有效提升了人脸阴影去除模型的性能，为该任务设定了新的标准。FSE方法在真实场景下取得了良好的效果。

Abstract: Facial shadows often degrade image quality and the performance of vision algorithms. Existing methods struggle to remove shadows while preserving texture, especially under complex lighting conditions, and they lack real-world paired datasets for training. We present the Augmented Shadow Face in the Wild (ASFW) dataset, the first large-scale real-world dataset for facial shadow removal, containing 1,081 paired shadow and shadow-free images created via a professional Photoshop workflow. ASFW offers photorealistic shadow variations and accurate ground truths, bridging the gap between synthetic and real domains. Deep models trained on ASFW demonstrate improved shadow removal in real-world conditions. We also introduce the Face Shadow Eraser (FSE) method to showcase the effectiveness of the dataset. Experiments demonstrate that ASFW enhances the performance of facial shadow removal models, setting new standards for this task.

</details>


### [72] [Instance-Guided Radar Depth Estimation for 3D Object Detection](https://arxiv.org/abs/2601.19314)
*Chen-Chou Lo,Patrick Vandewalle*

Main category: cs.CV

TL;DR: 本研究提出了一种增强单目相机3D目标检测的雷达-相机融合框架，通过实例分割引导的雷达点云增强（InstaRadar）和替换现有深度模块的雷达相机深度预测转换器（RCDPT）来提升雷达数据的密度和语义对齐，从而提高深度估计和3D检测性能。


<details>
  <summary>Details</summary>
Motivation: 单目相机在3D感知中存在深度模糊和鲁棒性问题，而雷达在恶劣环境下表现优越但分辨率低。因此，需要有效的雷达-相机融合方法来克服这些局限，并改进预处理和深度估计策略。

Method: 提出一个端到端的框架，包含两个主要组件：1. InstaRadar：一个实例分割引导的雷达点云增强方法，利用预训练的分割掩码来提高雷达数据的密度和语义对齐。2. RCDPT集成：将预训练的RCDPT模型替换BEVDepth框架中的深度模块，并使用InstaRadar增强的输入。

Result: InstaRadar在雷达引导的深度估计方面取得了SOTA结果，并有效生成了高质量的深度特征。集成RCDPT的模型在3D检测性能上持续提升。与基线BEVDepth模型相比，该框架带来了稳健的性能提升。该方法在雷达作为引导而非独立特征流的情况下，性能落后于直接提取BEV特征的雷达-相机融合模型。

Conclusion: InstaRadar和显式深度监督可以有效提升3D目标检测的性能。尽管存在局限性，但该框架为未来的研究提供了方向，如将InstaRadar扩展到点云表示，并集成专门的雷达分支以增强BEV融合。

Abstract: Accurate depth estimation is fundamental to 3D perception in autonomous driving, supporting tasks such as detection, tracking, and motion planning. However, monocular camera-based 3D detection suffers from depth ambiguity and reduced robustness under challenging conditions. Radar provides complementary advantages such as resilience to poor lighting and adverse weather, but its sparsity and low resolution limit its direct use in detection frameworks. This motivates the need for effective Radar-camera fusion with improved preprocessing and depth estimation strategies. We propose an end-to-end framework that enhances monocular 3D object detection through two key components. First, we introduce InstaRadar, an instance segmentation-guided expansion method that leverages pre-trained segmentation masks to enhance Radar density and semantic alignment, producing a more structured representation. InstaRadar achieves state-of-the-art results in Radar-guided depth estimation, showing its effectiveness in generating high-quality depth features. Second, we integrate the pre-trained RCDPT into the BEVDepth framework as a replacement for its depth module. With InstaRadar-enhanced inputs, the RCDPT integration consistently improves 3D detection performance. Overall, these components yield steady gains over the baseline BEVDepth model, demonstrating the effectiveness of InstaRadar and the advantage of explicit depth supervision in 3D object detection. Although the framework lags behind Radar-camera fusion models that directly extract BEV features, since Radar serves only as guidance rather than an independent feature stream, this limitation highlights potential for improvement. Future work will extend InstaRadar to point cloud-like representations and integrate a dedicated Radar branch with temporal cues for enhanced BEV fusion.

</details>


### [73] [Innovator-VL: A Multimodal Large Language Model for Scientific Discovery](https://arxiv.org/abs/2601.19325)
*Zichen Wen,Boxue Yang,Shuang Chen,Yaojie Zhang,Yuhang Han,Junlong Ke,Cong Wang,Yicheng Fu,Jiawang Zhao,Jiangchao Yao,Xi Fang,Zhen Wang,Henxing Cai,Lin Yao,Zhifeng Gao,Yanhui Hong,Nang Yuan,Yixuan Li,Guojiang Zhao,Haoyi Tao,Nan Wang,Han Lyu,Guolin Ke,Ning Liao,Xiaoxing Wang,Kai Chen,Zhiyu Li,Feiyu Xiong,Sihan Hu,Kun Chen,Yanfeng Wang,Weinan E,Linfeng Zhang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Innovator-VL的多模态大语言模型，该模型在科学领域和通用视觉任务上均表现出色，并且通过精心的训练设计和透明的方法，在数据效率和可复现性方面取得了显著进步，无需大规模领域特定预训练。


<details>
  <summary>Details</summary>
Motivation: 现有科学多模态模型通常依赖大规模领域特定预训练和不透明的训练流程。作者希望证明，通过原则性的训练设计和透明的方法，即使数据量有限，也能实现强大的科学智能，并促进社区的系统性扩展。

Method: 作者构建了一个完全透明、端到端可复现的训练流程，包括数据收集、清洗、预处理、监督微调、强化学习和评估，并提供了详细的优化配方。模型Innovator-VL在仅使用数百万个精选样本的情况下进行训练，且未进行大规模预训练。

Result: Innovator-VL在科学任务上表现出卓越的数据效率，取得了有竞争力的性能。同时，该模型展现了强大的泛化能力，在通用视觉、多模态推理和科学基准测试中均取得了令人满意的结果，证明了科学能力与通用能力的融合。

Conclusion: 通过原则性的数据选择而非盲目扩大规模，可以实现高效、可复现且高性能的科学多模态模型，即使在数据量有限的情况下也是如此。这为未来的研究提供了一个实际的基础。

Abstract: We present Innovator-VL, a scientific multimodal large language model designed to advance understanding and reasoning across diverse scientific domains while maintaining excellent performance on general vision tasks. Contrary to the trend of relying on massive domain-specific pretraining and opaque pipelines, our work demonstrates that principled training design and transparent methodology can yield strong scientific intelligence with substantially reduced data requirements. (i) First, we provide a fully transparent, end-to-end reproducible training pipeline, covering data collection, cleaning, preprocessing, supervised fine-tuning, reinforcement learning, and evaluation, along with detailed optimization recipes. This facilitates systematic extension by the community. (ii) Second, Innovator-VL exhibits remarkable data efficiency, achieving competitive performance on various scientific tasks using fewer than five million curated samples without large-scale pretraining. These results highlight that effective reasoning can be achieved through principled data selection rather than indiscriminate scaling. (iii) Third, Innovator-VL demonstrates strong generalization, achieving competitive performance on general vision, multimodal reasoning, and scientific benchmarks. This indicates that scientific alignment can be integrated into a unified model without compromising general-purpose capabilities. Our practices suggest that efficient, reproducible, and high-performing scientific multimodal models can be built even without large-scale data, providing a practical foundation for future research.

</details>


### [74] [Tri-Reader: An Open-Access, Multi-Stage AI Pipeline for First-Pass Lung Nodule Annotation in Screening CT](https://arxiv.org/abs/2601.19380)
*Fakrul Islam Tushar,Joseph Y. Lo*

Main category: cs.CV

TL;DR: 开发了一个名为 Tri-Reader 的免费肺结节检测和良恶性分类的集成流程。


<details>
  <summary>Details</summary>
Motivation: 为了在提高检测灵敏度的同时，减少标注员的工作量，并确保模型在不同实践中的准确性和泛化能力。

Method: 使用多个在公开数据集上训练的开源模型，构建了一个包含肺部分割、结节检测和良恶性分类的三阶段工作流程。

Result: 在多个内部和外部数据集上进行了评估，并与专家标注和数据集提供的参考标准进行了比较。

Conclusion: Tri-Reader 是一个综合性的、免费的肺结节检测和良恶性分类的集成流程，旨在提高效率和准确性。

Abstract: Using multiple open-access models trained on public datasets, we developed Tri-Reader, a comprehensive, freely available pipeline that integrates lung segmentation, nodule detection, and malignancy classification into a unified tri-stage workflow. The pipeline is designed to prioritize sensitivity while reducing the candidate burden for annotators. To ensure accuracy and generalizability across diverse practices, we evaluated Tri-Reader on multiple internal and external datasets as compared with expert annotations and dataset-provided reference standards.

</details>


### [75] [Pareto-Guided Optimization for Uncertainty-Aware Medical Image Segmentation](https://arxiv.org/abs/2601.19365)
*Jinming Zhang,Xi Yang,Youpeng Yang,Haosen Shi,Yuyao Yan,Qiufeng Wang,Guangliang Cheng,Kaizhu Huang*

Main category: cs.CV

TL;DR: 提出一种区域化课程策略和帕累托一致损失函数，通过优先学习确定区域并逐步引入不确定区域，以及模糊化边界标签，来解决医学图像分割中区域不确定性不均的问题，提高模型收敛性和分割性能。


<details>
  <summary>Details</summary>
Motivation: 传统的医学图像分割训练方法对所有像素一视同仁，这导致在模型早期训练阶段，当预测不可靠时，优化过程不稳定。边界区域的分割不确定性远高于内部区域，这种不均匀性阻碍了模型收敛到帕累托最优解。

Method: 提出一种区域化课程策略，优先从确定区域学习，逐步引入不确定区域，以减少梯度方差。引入帕累托一致损失函数，通过自适应重塑损失函数地形和约束内部与边界区域的收敛动态，来平衡区域不确定性之间的权衡，引导模型逼近帕累托近似解。开发模糊标签机制，在非边界区域保持二元置信度，在边界区域允许平滑过渡，以稳定梯度并扩大损失函数表面的平坦区域。

Result: 在脑转移和非转移性肿瘤分割实验中，该方法在所有肿瘤子区域均优于传统的清晰集方法，并在多种配置下表现出持续的性能提升。

Conclusion: 提出的区域化课程策略和帕累托一致损失函数结合模糊标签机制，能够有效地解决医学图像分割中的区域不确定性不均问题，提高模型在不确定区域的分割性能，并实现更稳定的优化过程。

Abstract: Uncertainty in medical image segmentation is inherently non-uniform, with boundary regions exhibiting substantially higher ambiguity than interior areas. Conventional training treats all pixels equally, leading to unstable optimization during early epochs when predictions are unreliable. We argue that this instability hinders convergence toward Pareto-optimal solutions and propose a region-wise curriculum strategy that prioritizes learning from certain regions and gradually incorporates uncertain ones, reducing gradient variance. Methodologically, we introduce a Pareto-consistent loss that balances trade-offs between regional uncertainties by adaptively reshaping the loss landscape and constraining convergence dynamics between interior and boundary regions; this guides the model toward Pareto-approximate solutions. To address boundary ambiguity, we further develop a fuzzy labeling mechanism that maintains binary confidence in non-boundary areas while enabling smooth transitions near boundaries, stabilizing gradients, and expanding flat regions in the loss surface. Experiments on brain metastasis and non-metastatic tumor segmentation show consistent improvements across multiple configurations, with our method outperforming traditional crisp-set approaches in all tumor subregions.

</details>


### [76] [Establishing dermatopathology encyclopedia DermpathNet with Artificial Intelligence-Based Workflow](https://arxiv.org/abs/2601.19378)
*Ziyang Xu,Mingquan Lin,Yiliang Zhou,Zihan Xu,Seth J. Orlow,Zihan Xu,Shane A. Meehan,Alexandra Flamm,Ata S. Moshiri,Yifan Peng*

Main category: cs.CV

TL;DR: 研究人员构建了一个名为 DermpathNet 的大规模、开放获取的皮肤病理图像数据集，用于教育和机器学习，并开发了一种半自动化的工作流程来整理和分类图像。


<details>
  <summary>Details</summary>
Motivation: 为临床医生和皮肤病理学培训生提供高质量、开放获取的皮肤病理图像数据集，用于学习和交叉参考。

Method: 采用混合工作流程，结合深度学习图像模态分类和图标题分析，从 PubMed Central (PMC) 知识库中提取和分类图像。使用关键词检索，并通过手动注释进行验证。

Result: 成功提取了 7,772 张跨越 166 种诊断的图像。混合方法的 F 分数达到 90.4%，优于单独的深度学习（89.6%）和关键词检索（61.0%）。发现当前 OpenAI 的图像分析算法不足以分析皮肤病理图像。

Conclusion: 已开发出 DermpathNet，一个大型、同行评审、开放获取的皮肤病理图像数据集，具有半自动化的整理工作流程，可供教育、交叉引用和机器学习使用。

Abstract: Accessing high-quality, open-access dermatopathology image datasets for learning and cross-referencing is a common challenge for clinicians and dermatopathology trainees. To establish a comprehensive open-access dermatopathology dataset for educational, cross-referencing, and machine-learning purposes, we employed a hybrid workflow to curate and categorize images from the PubMed Central (PMC) repository. We used specific keywords to extract relevant images, and classified them using a novel hybrid method that combined deep learning-based image modality classification with figure caption analyses. Validation on 651 manually annotated images demonstrated the robustness of our workflow, with an F-score of 89.6\% for the deep learning approach, 61.0\% for the keyword-based retrieval method, and 90.4\% for the hybrid approach. We retrieved over 7,772 images across 166 diagnoses and released this fully annotated dataset, reviewed by board-certified dermatopathologists. Using our dataset as a challenging task, we found the current image analysis algorithm from OpenAI inadequate for analyzing dermatopathology images. In conclusion, we have developed a large, peer-reviewed, open-access dermatopathology image dataset, DermpathNet, which features a semi-automated curation workflow.

</details>


### [77] [Cortex-Grounded Diffusion Models for Brain Image Generation](https://arxiv.org/abs/2601.19498)
*Fabian Bongratz,Yitong Li,Sama Elbaroudy,Christian Wachinger*

Main category: cs.CV

TL;DR: Cor2Vox是一个基于大脑皮层结构的生成模型，用于合成逼真的脑部MRI图像，解决了现有模型缺乏解剖学基础和生物学不可靠的问题，并在图像质量、皮层形态和疾病模拟方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的合成神经影像数据方法在处理稀有表型、跨扫描器域转移和纵向覆盖不足等方面存在局限性，并且依赖于缺乏解剖学基础的弱条件信号，导致生成的图像在生物学上不合理。

Method: Cor2Vox框架利用高分辨率的皮层表面作为连续的结构先验，指导3D形状到图像的布朗桥扩散过程，实现拓扑忠实的合成和精确的解剖控制。研究人员还构建了一个基于33,000多份UK Biobank扫描的大规模皮层形态统计模型。

Result: Cor2Vox在图像质量、皮层表面重建和全脑分割质量方面优于多种基线方法。在三个应用场景（解剖一致性合成、进行性灰质萎缩模拟、以及室内FTD扫描与公共数据集的协调）中，Cor2Vox能够以亚体素级别精确保留精细的皮层形态，并且在不重新训练的情况下，对皮层几何和疾病表型的变化表现出 remarkable 的鲁棒性。

Conclusion: Cor2Vox提供了一种新颖的、基于皮层结构的生成方法，能够合成在解剖学上准确且逼真的脑部MRI图像，并为模拟疾病进展和数据协调等应用提供了强大的工具。

Abstract: Synthetic neuroimaging data can mitigate critical limitations of real-world datasets, including the scarcity of rare phenotypes, domain shifts across scanners, and insufficient longitudinal coverage. However, existing generative models largely rely on weak conditioning signals, such as labels or text, which lack anatomical grounding and often produce biologically implausible outputs. To this end, we introduce Cor2Vox, a cortex-grounded generative framework for brain magnetic resonance image (MRI) synthesis that ties image generation to continuous structural priors of the cerebral cortex. It leverages high-resolution cortical surfaces to guide a 3D shape-to-image Brownian bridge diffusion process, enabling topologically faithful synthesis and precise control over underlying anatomies. To support the generation of new, realistic brain shapes, we developed a large-scale statistical shape model of cortical morphology derived from over 33,000 UK Biobank scans. We validated the fidelity of Cor2Vox based on traditional image quality metrics, advanced cortical surface reconstruction, and whole-brain segmentation quality, outperforming many baseline methods. Across three applications, namely (i) anatomically consistent synthesis, (ii) simulation of progressive gray matter atrophy, and (iii) harmonization of in-house frontotemporal dementia scans with public datasets, Cor2Vox preserved fine-grained cortical morphology at the sub-voxel level, exhibiting remarkable robustness to variations in cortical geometry and disease phenotype without retraining.

</details>


### [78] [Mocap Anywhere: Towards Pairwise-Distance based Motion Capture in the Wild (for the Wild)](https://arxiv.org/abs/2601.19519)
*Ofir Abramovich,Ariel Shamir,Andreas Aristidou*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的运动捕捉系统，仅使用稀疏的成对距离（PWD）测量来重建全身3D运动，无需外部摄像头，可在各种环境下运行，并且能够泛化到不同形态的被摄对象。


<details>
  <summary>Details</summary>
Motivation: 现有运动捕捉系统（如光学或惯性系统）依赖于外部摄像头，在不受控或室外环境中受限，并且对光照和磁场干扰敏感。研究旨在开发一种不受这些限制的、可扩展的、低成本的通用运动捕捉方法。

Method: 使用身体上安装的超宽带（UWB）传感器进行时间飞行（ToF）测距，收集稀疏的成对距离（PWD）测量。核心是一个名为Wild-Poser (WiP) 的Transformer模型，该模型直接从嘈杂或损坏的PWD测量中预测3D关节位置，然后通过学习方法重建关节旋转。WiP无需个体身体测量或形状拟合即可泛化到不同形态的被摄对象。

Result: WiP系统实时运行，实现了低关节位置误差，并能准确重建人和其他动物在真实环境中的3D运动。实验分析证明了其在现实场景中进行可扩展、低成本、通用运动捕捉的潜力。

Conclusion: 提出的基于UWB稀疏成对距离测量的运动捕捉系统（Wild-Poser）是一种新颖且强大的解决方案，克服了传统系统的局限性，能够在真实世界环境中进行准确、通用和低成本的3D运动重建。

Abstract: We introduce a novel motion capture system that reconstructs full-body 3D motion using only sparse pairwise distance (PWD) measurements from body-mounted(UWB) sensors. Using time-of-flight ranging between wireless nodes, our method eliminates the need for external cameras, enabling robust operation in uncontrolled and outdoor environments. Unlike traditional optical or inertial systems, our approach is shape-invariant and resilient to environmental constraints such as lighting and magnetic interference. At the core of our system is Wild-Poser (WiP for short), a compact, real-time Transformer-based architecture that directly predicts 3D joint positions from noisy or corrupted PWD measurements, which can later be used for joint rotation reconstruction via learned methods. WiP generalizes across subjects of varying morphologies, including non-human species, without requiring individual body measurements or shape fitting. Operating in real time, WiP achieves low joint position error and demonstrates accurate 3D motion reconstruction for both human and animal subjects in-the-wild. Our empirical analysis highlights its potential for scalable, low-cost, and general purpose motion capture in real-world settings.

</details>


### [79] [RoamScene3D: Immersive Text-to-3D Scene Generation via Adaptive Object-aware Roaming](https://arxiv.org/abs/2601.19433)
*Jisheng Chu,Wenrui Li,Rui Zhao,Wangmeng Zuo,Shifeng Chen,Xiaopeng Fan*

Main category: cs.CV

TL;DR: RoamScene3D是一个新的框架，通过利用视觉语言模型（VLM）构建场景图来理解对象关系，并结合运动注入的修复模型来处理相机运动，从而从文本生成沉浸式3D场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理3D场景生成时存在空间盲区、依赖预定义轨迹、无法理解语义布局和处理相机运动导致的空洞等问题。

Method: 1. 使用VLM构建场景图，编码对象关系，指导相机感知对象边界并规划自适应漫游轨迹。 2. 引入运动注入修复模型，并在包含真实相机轨迹的合成全景数据集上进行微调，以适应相机运动。

Result: RoamScene3D通过语义推理和几何约束，在生成一致且逼真的3D场景方面显著优于现有最先进的方法。

Conclusion: RoamScene3D成功弥合了语义引导与空间生成之间的差距，能够生成具有合理语义布局和几何一致性的3D场景，并且对相机运动具有鲁棒性。

Abstract: Generating immersive 3D scenes from texts is a core task in computer vision, crucial for applications in virtual reality and game development. Despite the promise of leveraging 2D diffusion priors, existing methods suffer from spatial blindness and rely on predefined trajectories that fail to exploit the inner relationships among salient objects. Consequently, these approaches are unable to comprehend the semantic layout, preventing them from exploring the scene adaptively to infer occluded content. Moreover, current inpainting models operate in 2D image space, struggling to plausibly fill holes caused by camera motion. To address these limitations, we propose RoamScene3D, a novel framework that bridges the gap between semantic guidance and spatial generation. Our method reasons about the semantic relations among objects and produces consistent and photorealistic scenes. Specifically, we employ a vision-language model (VLM) to construct a scene graph that encodes object relations, guiding the camera to perceive salient object boundaries and plan an adaptive roaming trajectory. Furthermore, to mitigate the limitations of static 2D priors, we introduce a Motion-Injected Inpainting model that is fine-tuned on a synthetic panoramic dataset integrating authentic camera trajectories, making it adaptive to camera motion. Extensive experiments demonstrate that with semantic reasoning and geometric constraints, our method significantly outperforms state-of-the-art approaches in producing consistent and photorealistic scenes. Our code is available at https://github.com/JS-CHU/RoamScene3D.

</details>


### [80] [GMS-CAVP: Improving Audio-Video Correspondence with Multi-Scale Contrastive and Generative Pretraining](https://arxiv.org/abs/2601.19606)
*Shentong Mo,Zehua Chen,Jun Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种名为GMS-CAVP的新框架，通过多尺度视频-音频对齐和多尺度时空扩散预训练目标，改进了视频-音频（V-A）的对应建模，以提升V-A理解和生成任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有V-A联合嵌入方法在视频和音频信号的多尺度、密集特性建模方面存在不足，导致性能不佳。研究旨在通过更有效地建模跨越不同粒度的时空结构来提升V-A对应关系。

Method: GMS-CAVP框架包含两个主要部分：1. 多尺度视频-音频对齐：采用多尺度对比学习策略，捕捉不同粒度的语义和时间关系。2. 多尺度时空扩散预训练：引入基于扩散模型的生成目标，实现视频和音频之间的模态转换和合成。

Result: 在VGGSound、AudioSet和Panda70M数据集上的实验表明，GMS-CAVP在生成和检索任务上的表现优于先前方法。

Conclusion: GMS-CAVP通过结合判别式和生成式学习，实现了更深层次的跨模态理解，并能进行高保真度的生成，有效解决了现有方法的局限性。

Abstract: Recent advances in video-audio (V-A) understanding and generation have increasingly relied on joint V-A embeddings, which serve as the foundation for tasks such as cross-modal retrieval and generation. While prior methods like CAVP effectively model semantic and temporal correspondences between modalities using contrastive objectives, their performance remains suboptimal. A key limitation is the insufficient modeling of the dense, multi-scale nature of both video and audio signals, correspondences often span fine- to coarse-grained spatial-temporal structures, which are underutilized in existing frameworks. To this end, we propose GMS-CAVP, a novel framework that combines Multi-Scale Video-Audio Alignment and Multi-Scale Spatial-Temporal Diffusion-based pretraining objectives to enhance V-A correspondence modeling. First, GMS-CAVP introduces a multi-scale contrastive learning strategy that captures semantic and temporal relations across varying granularities. Second, we go beyond traditional contrastive learning by incorporating a diffusion-based generative objective, enabling modality translation and synthesis between video and audio. This unified discriminative-generative formulation facilitates deeper cross-modal understanding and paves the way for high-fidelity generation. Extensive experiments on VGGSound, AudioSet, and Panda70M demonstrate that GMS-CAVP outperforms previous methods in generation and retrieval.

</details>


### [81] [Unveiling Perceptual Artifacts: A Fine-Grained Benchmark for Interpretable AI-Generated Image Detection](https://arxiv.org/abs/2601.19430)
*Yao Xiao,Weiyan Chen,Jiahao Chen,Zijie Cao,Weijian Deng,Binbin Yang,Ziyi Dong,Xiangyang Ji,Wei Ke,Pengxu Wei,Liang Lin*

Main category: cs.CV

TL;DR: 本文提出了一个名为X-AIGD的细粒度基准，用于可解释的AI生成图像检测，提供了像素级、分类的感知伪影注释。研究发现，现有的AIGI检测器对感知伪影的依赖性很小，并且主要依赖于不可解释的特征，但通过将模型注意力与伪影区域对齐可以提高可解释性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成图像检测方法大多采用二元分类，缺乏可解释的证据。现有的基准测试在伪影多样性和局部注释方面存在不足，限制了对模型决策过程的深入理解。

Method: 提出了X-AIGD基准，包含像素级、分类的感知伪影注释，涵盖低级失真、高级语义和认知级反事实。利用该基准对现有AIGI检测器进行了广泛的调查，并探索了将模型注意力与伪影区域对齐的方法。

Result: 1. 现有的AIGI检测器对感知伪影的依赖性很小。2. 尽管可以训练AIGI检测器来识别特定伪影，但它们仍然在很大程度上依赖于不可解释的特征。3. 将模型注意力与伪影区域显式对齐可以提高检测器的可解释性和泛化能力。

Conclusion: X-AIGD基准的提出为细粒度的可解释AIGI检测提供了支持。研究结果表明，提高AIGI检测器的可解释性和泛化能力的关键在于使其关注感知伪影，而不是依赖于未知的、不可解释的特征。

Abstract: Current AI-Generated Image (AIGI) detection approaches predominantly rely on binary classification to distinguish real from synthetic images, often lacking interpretable or convincing evidence to substantiate their decisions. This limitation stems from existing AIGI detection benchmarks, which, despite featuring a broad collection of synthetic images, remain restricted in their coverage of artifact diversity and lack detailed, localized annotations. To bridge this gap, we introduce a fine-grained benchmark towards eXplainable AI-Generated image Detection, named X-AIGD, which provides pixel-level, categorized annotations of perceptual artifacts, spanning low-level distortions, high-level semantics, and cognitive-level counterfactuals. These comprehensive annotations facilitate fine-grained interpretability evaluation and deeper insight into model decision-making processes. Our extensive investigation using X-AIGD provides several key insights: (1) Existing AIGI detectors demonstrate negligible reliance on perceptual artifacts, even at the most basic distortion level. (2) While AIGI detectors can be trained to identify specific artifacts, they still substantially base their judgment on uninterpretable features. (3) Explicitly aligning model attention with artifact regions can increase the interpretability and generalization of detectors. The data and code are available at: https://github.com/Coxy7/X-AIGD.

</details>


### [82] [DSTCS: Dual-Student Teacher Framework with Segment Anything Model for Semi-Supervised Pubic Symphysis Fetal Head Segmentation](https://arxiv.org/abs/2601.19446)
*Yalin Luo,Shun Long,Huijin Wang,Jieyun Bai*

Main category: cs.CV

TL;DR: 提出了一种结合CNN和SAM（Segment Anything Model）的“双学生-教师”框架（DSTCS），用于超声图像中耻骨联合和胎头（PSFH）的分割，解决了类别不平衡、边界模糊和数据稀缺等问题，并在公开基准测试中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的PSFH分割方法在处理超声图像的类不平衡、边界模糊和噪声干扰等挑战时存在不足，且对更强大模型的探索不够。同时，高质量的标注数据稀缺也阻碍了模型的训练。

Method: 提出了一种“双学生-教师”框架（DSTCS），该框架结合了CNN和SAM（Segment Anything Model）。采用CNN和SAM分支之间的协同学习机制，并引入了针对边界处理的专门数据增强策略和新的损失函数。

Result: 在MICCAI 2023和2024 PSFH分割基准测试上进行的广泛实验表明，所提出的方法展现出优越的鲁棒性，并且显著优于现有技术。

Conclusion: DSTCS框架通过整合CNN和SAM，并利用协同学习、优化的数据增强和新颖的损失函数，有效解决了PSFH分割中的挑战，为临床实践提供了一个可靠的分割工具。

Abstract: Segmentation of the pubic symphysis and fetal head (PSFH) is a critical procedure in intrapartum monitoring and is essential for evaluating labor progression and identifying potential delivery complications. However, achieving accurate segmentation remains a significant challenge due to class imbalance, ambiguous boundaries, and noise interference in ultrasound images, compounded by the scarcity of high-quality annotated data. Current research on PSFH segmentation predominantly relies on CNN and Transformer architectures, leaving the potential of more powerful models underexplored. In this work, we propose a Dual-Student and Teacher framework combining CNN and SAM (DSTCS), which integrates the Segment Anything Model (SAM) into a dual student-teacher architecture. A cooperative learning mechanism between the CNN and SAM branches significantly improves segmentation accuracy. The proposed scheme also incorporates a specialized data augmentation strategy optimized for boundary processing and a novel loss function. Extensive experiments on the MICCAI 2023 and 2024 PSFH segmentation benchmarks demonstrate that our method exhibits superior robustness and significantly outperforms existing techniques, providing a reliable segmentation tool for clinical practice.

</details>


### [83] [The role of self-supervised pretraining in differentially private medical image analysis](https://arxiv.org/abs/2601.19618)
*Soroosh Tayebi Arasteh,Mina Farajiamiri,Mahshad Lotfinia,Behrus Hinrichs-Puladi,Jonas Bienzeisler,Mohamed Alhaskir,Mirabela Rusu,Christiane Kuhl,Sven Nebelung,Daniel Truhn*

Main category: cs.CV

TL;DR: 本研究评估了在差分隐私（DP）下，用于医学影像分析的不同模型初始化策略（ImageNet监督预训练、DINOv3自监督预训练和MIMIC-CXR监督预训练）的有效性，并发现领域特定的监督预训练效果最佳。


<details>
  <summary>Details</summary>
Motivation: 差分隐私在保护敏感数据方面至关重要，但通常会降低模型性能。模型初始化被认为是缓解这一性能损失的关键因素，但现代自监督学习在全模型DP下的作用尚未得到充分研究，尤其是在医学影像领域。

Method: 研究人员使用80万多张胸部X光片作为基准，在DP-SGD下训练了最先进的ConvNeXt模型。他们比较了三种初始化策略：非领域特定的ImageNet监督初始化、非领域特定的DINOv3自监督初始化，以及在MIMIC-CXR（最大的公开胸部X光数据集）上进行的领域特定监督预训练。然后在五个外部数据集上进行了评估。

Result: DINOv3初始化在DP下持续提升了诊断效用，但仍不如领域特定的监督预训练。领域特定的监督预训练在性能上最接近非私有基线。此外，初始化策略显著影响了DP下的公平性、泛化能力以及对数据规模和模型容量的鲁棒性。

Conclusion: 初始化策略是差分隐私医学影像分析中效用、公平性和泛化能力的关键决定因素。领域特定的监督预训练在DP环境下提供了最佳的性能。

Abstract: Differential privacy (DP) provides formal protection for sensitive data but typically incurs substantial losses in diagnostic performance. Model initialization has emerged as a critical factor in mitigating this degradation, yet the role of modern self-supervised learning under full-model DP remains poorly understood. Here, we present a large-scale evaluation of initialization strategies for differentially private medical image analysis, using chest radiograph classification as a representative benchmark with more than 800,000 images. Using state-of-the-art ConvNeXt models trained with DP-SGD across realistic privacy regimes, we compare non-domain-specific supervised ImageNet initialization, non-domain-specific self-supervised DINOv3 initialization, and domain-specific supervised pretraining on MIMIC-CXR, the largest publicly available chest radiograph dataset. Evaluations are conducted across five external datasets spanning diverse institutions and acquisition settings. We show that DINOv3 initialization consistently improves diagnostic utility relative to ImageNet initialization under DP, but remains inferior to domain-specific supervised pretraining, which achieves performance closest to non-private baselines. We further demonstrate that initialization choice strongly influences demographic fairness, cross-dataset generalization, and robustness to data scale and model capacity under privacy constraints. The results establish initialization strategy as a central determinant of utility, fairness, and generalization in differentially private medical imaging.

</details>


### [84] [Dynamic Worlds, Dynamic Humans: Generating Virtual Human-Scene Interaction Motion in Dynamic Scenes](https://arxiv.org/abs/2601.19484)
*Yin Wang,Zhiying Leng,Haitian Liu,Frederick W. B. Li,Mu Li,Xiaohui Liang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Dyn-HSI 的动态人与场景交互生成认知架构，该架构通过模拟人类的视觉、记忆和控制系统，能够处理动态变化的场景，并生成高质量的交互动作。


<details>
  <summary>Details</summary>
Motivation: 现有的人与场景交互生成方法将场景视为静态，这与现实世界不符。作者希望构建一个能处理动态场景交互的模型。

Method: Dyn-HSI 包含三个组件：1. 动态场景感知导航（模拟视觉），用于感知环境变化并预测导航点。2. 分层经验记忆（模拟记忆），用于存储和更新经验数据，并在推理时提供上下文感知的动作提示。3. 人与场景交互扩散模型（模拟控制），用于根据多模态输入生成交互动作。

Result: 在扩展的动态场景基准 Dyn-Scenes 上进行的实验表明，Dyn-HSI 在动态场景下能够生成高质量的交互动作，并且在静态和动态场景下均优于现有方法。

Conclusion: Dyn-HSI 是第一个用于动态人与场景交互的认知架构，通过模拟人类的认知过程，有效解决了现有方法在动态场景下的局限性，并生成了高质量的交互动作。

Abstract: Scenes are continuously undergoing dynamic changes in the real world. However, existing human-scene interaction generation methods typically treat the scene as static, which deviates from reality. Inspired by world models, we introduce Dyn-HSI, the first cognitive architecture for dynamic human-scene interaction, which endows virtual humans with three humanoid components. (1)Vision (human eyes): we equip the virtual human with a Dynamic Scene-Aware Navigation, which continuously perceives changes in the surrounding environment and adaptively predicts the next waypoint. (2)Memory (human brain): we equip the virtual human with a Hierarchical Experience Memory, which stores and updates experiential data accumulated during training. This allows the model to leverage prior knowledge during inference for context-aware motion priming, thereby enhancing both motion quality and generalization. (3) Control (human body): we equip the virtual human with Human-Scene Interaction Diffusion Model, which generates high-fidelity interaction motions conditioned on multimodal inputs. To evaluate performance in dynamic scenes, we extend the existing static human-scene interaction datasets to construct a dynamic benchmark, Dyn-Scenes. We conduct extensive qualitative and quantitative experiments to validate Dyn-HSI, showing that our method consistently outperforms existing approaches and generates high-quality human-scene interaction motions in both static and dynamic settings.

</details>


### [85] [Entropy-Guided k-Guard Sampling for Long-Horizon Autoregressive Video Generation](https://arxiv.org/abs/2601.19488)
*Yizhao Han,Tianxing Shi,Zhao Wang,Zifan Xu,Zhiyuan Pu,Mingxiao Li,Qian Zhang,Wei Yin,Xiao-Xiao Long*

Main category: cs.CV

TL;DR: 本文提出了一种名为ENkG（Entropy-Guided k-Guard）的自适应采样策略，用于解决视频生成中由于语言模型中的Top-p/Top-k采样策略不适用于视频数据的低语义密度和高时空冗余问题，从而提高视频生成质量。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型（LLM）中，Top-p/Top-k采样策略效果显著，但这种策略不适用于视频生成，因为视频数据具有低语义密度和高时空冗余，容易导致生成质量下降。现有方法在处理背景（低不确定性）和前景（高不确定性）时存在不足，导致预测误差累积。

Method: 提出了一种名为ENkG（Entropy-Guided k-Guard）的采样策略。ENkG根据每个视频token的预测分布的熵来动态调整候选token的数量。低熵区域（如背景）使用更少的候选token来减少冗余，高熵区域（如前景）使用更多的候选token来减轻误差累积。

Result: ENkG是一种模型无关、无需训练且开销极小的策略。实验表明，与静态Top-k/Top-p策略相比，ENkG在感知质量和结构稳定性方面取得了持续的改进。

Conclusion: ENkG是一种有效且易于实现的采样策略，能够适应视频数据的特性，显著提升视频生成任务的质量，尤其是在长序列生成方面。

Abstract: Autoregressive (AR) architectures have achieved significant successes in LLMs, inspiring explorations for video generation. In LLMs, top-p/top-k sampling strategies work exceptionally well: language tokens have high semantic density and low redundancy, so a fixed size of token candidates already strikes a balance between semantic accuracy and generation diversity. In contrast, video tokens have low semantic density and high spatio-temporal redundancy. This mismatch makes static top-k/top-p strategies ineffective for video decoders: they either introduce unnecessary randomness for low-uncertainty regions (static backgrounds) or get stuck in early errors for high-uncertainty regions (foreground objects). Prediction errors will accumulate as more frames are generated and eventually severely degrade long-horizon quality. To address this, we propose Entropy-Guided k-Guard (ENkG) sampling, a simple yet effective strategy that adapts sampling to token-wise dispersion, quantified by the entropy of each token's predicted distribution. ENkG uses adaptive token candidate sizes: for low-entropy regions, it employs fewer candidates to suppress redundant noise and preserve structural integrity; for high-entropy regions, it uses more candidates to mitigate error compounding. ENkG is model-agnostic, training-free, and adds negligible overhead. Experiments demonstrate consistent improvements in perceptual quality and structural stability compared to static top-k/top-p strategies.

</details>


### [86] [Fast Converging 3D Gaussian Splatting for 1-Minute Reconstruction](https://arxiv.org/abs/2601.19489)
*Ziyu Zhang,Tianle Liu,Diantao Tu,Shuhan Shen*

Main category: cs.CV

TL;DR: 提出了一种快速3DGS重建流水线，能在1分钟内收敛，用于SIGGRAPH Asia 3DGS快速重建挑战赛。该流水线针对SLAM和COLMAP两种不同的相机姿态设置，通过两阶段优化策略，在保证高保真度的同时满足严格的时间限制，并在比赛中取得第一名。


<details>
  <summary>Details</summary>
Motivation: 旨在解决3DGS（3D Gaussian Splatting）重建速度慢的问题，特别是在存在噪声相机姿态（SLAM）或高精度姿态（COLMAP）的挑战性场景下，需要在极短的时间内（1分钟）完成高质量的三维重建。

Method: 提出一个两阶段的解决方案。第一阶段（处理SLAM姿态）：采用反向并行优化、紧凑的前向splatting（基于Taming-GS和Speedy-splat）、负载均衡分块、基于Anchor的Neural-Gaussian表示（减少参数）、单目深度初始化和全局姿态优化。第二阶段（处理COLMAP姿态）：禁用姿态优化，切换回标准3DGS以消除MLP开销，引入多视图一致性引导的高斯分裂（受Fast-GS启发），并使用深度估计器监督渲染深度。

Result: 该方法在SIGGRAPH Asia 3DGS快速重建挑战赛中取得了最高性能，PSNR达到28.43，并在比赛中排名第一。

Conclusion: 通过结合多种优化技术，包括针对不同相机姿态设置的定制化策略、高效的表示方法和新的训练策略，成功实现了一分钟内高质量的3DGS重建，有效解决了重建速度和姿态鲁棒性的问题。

Abstract: We present a fast 3DGS reconstruction pipeline designed to converge within one minute, developed for the SIGGRAPH Asia 3DGS Fast Reconstruction Challenge. The challenge consists of an initial round using SLAM-generated camera poses (with noisy trajectories) and a final round using COLMAP poses (highly accurate). To robustly handle these heterogeneous settings, we develop a two-stage solution. In the first round, we use reverse per-Gaussian parallel optimization and compact forward splatting based on Taming-GS and Speedy-splat, load-balanced tiling, an anchor-based Neural-Gaussian representation enabling rapid convergence with fewer learnable parameters, initialization from monocular depth and partially from feed-forward 3DGS models, and a global pose refinement module for noisy SLAM trajectories. In the final round, the accurate COLMAP poses change the optimization landscape; we disable pose refinement, revert from Neural-Gaussians back to standard 3DGS to eliminate MLP inference overhead, introduce multi-view consistency-guided Gaussian splitting inspired by Fast-GS, and introduce a depth estimator to supervise the rendered depth. Together, these techniques enable high-fidelity reconstruction under a strict one-minute budget. Our method achieved the top performance with a PSNR of 28.43 and ranked first in the competition.

</details>


### [87] [Bridging Information Asymmetry: A Hierarchical Framework for Deterministic Blind Face Restoration](https://arxiv.org/abs/2601.19506)
*Zhengjian Yao,Jiakui Hu,Kaiwen Li,Hangzhou He,Xinliang Zhang,Shuang Zeng,Lei Zhu,Yanye Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Pref-Restore 的分层框架，用于解决盲人脸修复问题。该框架通过增强输入信息密度和修剪输出分布来弥合低质量输入与高质量输出之间的信息不对称。实验表明，Pref-Restore 能够实现最先进的性能，并显著降低了解决方案的不确定性。


<details>
  <summary>Details</summary>
Motivation: 当前生成式方法在人脸修复中存在信息不对称的问题，即输入信息稀疏而输出信息密集，导致不确定性和幻觉伪影。研究动机是解决这种信息不对称，实现确定性、符合偏好的修复。

Method: Pref-Restore 框架采用两种策略：1. 增强输入密度：使用自回归积分器将文本指令转化为密集的潜在查询，引入高层语义稳定性来约束退化信号。2. 修剪输出分布：将在线强化学习集成到扩散修复循环中，将人类偏好转化为可微分约束，以惩罚随机偏差，使后验分布更集中于高保真结果。

Result: Pref-Restore 在合成和真实世界基准测试中均取得了最先进的性能。此外，实验分析证实，该框架显著降低了解决方案熵，为可靠且确定的盲修复提供了途径。

Conclusion: Pref-Restore 通过整合离散语义逻辑和连续纹理生成，有效解决了盲人脸修复中的信息不对称问题，实现了确定性、符合偏好的修复，并在实验中展现出优越的性能和鲁棒性。

Abstract: Blind face restoration remains a persistent challenge due to the inherent ill-posedness of reconstructing holistic structures from severely constrained observations. Current generative approaches, while capable of synthesizing realistic textures, often suffer from information asymmetry -- the intrinsic disparity between the information-sparse low quality inputs and the information-dense high quality outputs. This imbalance leads to a one-to-many mapping, where insufficient constraints result in stochastic uncertainty and hallucinatory artifacts. To bridge this gap, we present \textbf{Pref-Restore}, a hierarchical framework that integrates discrete semantic logic with continuous texture generation to achieve deterministic, preference-aligned restoration. Our methodology fundamentally addresses this information disparity through two complementary strategies: (1) Augmenting Input Density: We employ an auto-regressive integrator to reformulate textual instructions into dense latent queries, injecting high-level semantic stability to constrain the degraded signals; (2) Pruning Output Distribution: We pioneer the integration of on-policy reinforcement learning directly into the diffusion restoration loop. By transforming human preferences into differentiable constraints, we explicitly penalize stochastic deviations, thereby sharpening the posterior distribution toward the desired high-fidelity outcomes. Extensive experiments demonstrate that Pref-Restore achieves state-of-the-art performance across synthetic and real-world benchmarks. Furthermore, empirical analysis confirms that our preference-aligned strategy significantly reduces solution entropy, establishing a robust pathway toward reliable and deterministic blind restoration.

</details>


### [88] [MaDiS: Taming Masked Diffusion Language Models for Sign Language Generation](https://arxiv.org/abs/2601.19577)
*Ronglai Zuo,Rolandos Alexandros Potamias,Qi Sun,Evangelos Ververas,Jiankang Deng,Stefanos Zafeiriou*

Main category: cs.CV

TL;DR: 提出了一种名为MaDiS的基于掩码扩散的语言模型，用于手语生成，它能捕捉双向依赖关系，并支持高效的并行多令牌生成。通过三级跨模态预训练方案和一种新颖的解掩码策略，MaDiS在多个指标上取得了优越的性能，并显著降低了推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归语言模型在手语生成中存在单向上下文建模和推理速度慢的问题。研究人员希望提出一种新的模型来解决这些局限性。

Method: 提出了一种名为MaDiS的基于掩码扩散的语言模型。引入了三级跨模态预训练方案，包括令牌级、潜在空间级和3D物理空间级目标。设计了一种新颖的带有时间检查点的解掩码策略来加速模型收敛。开发了一种混合部件嵌入层来融合不同部件级手语令牌的信息。

Result: MaDiS在CSL-Daily、Phoenix-2014T和How2Sign数据集上取得了优越的性能，在DTW误差、SiBLEU和SiCLIP等多个指标上表现出色，同时推理延迟降低了近30%。

Conclusion: MaDiS是一种高效且性能优越的手语生成模型，通过创新的预训练和训练策略，有效地解决了现有方法的不足，并为手语生成领域带来了新的进展。

Abstract: Sign language generation (SLG) aims to translate written texts into expressive sign motions, bridging communication barriers for the Deaf and Hard-of-Hearing communities. Recent studies formulate SLG within the language modeling framework using autoregressive language models, which suffer from unidirectional context modeling and slow token-by-token inference. To address these limitations, we present MaDiS, a masked-diffusion-based language model for SLG that captures bidirectional dependencies and supports efficient parallel multi-token generation. We further introduce a tri-level cross-modal pretraining scheme that jointly learns from token-, latent-, and 3D physical-space objectives, leading to richer and more grounded sign representations. To accelerate model convergence in the fine-tuning stage, we design a novel unmasking strategy with temporal checkpoints, reducing the combinatorial complexity of unmasking orders by over $10^{41}$ times. In addition, a mixture-of-parts embedding layer is developed to effectively fuse information stored in different part-wise sign tokens through learnable gates and well-optimized codebooks. Extensive experiments on CSL-Daily, Phoenix-2014T, and How2Sign demonstrate that MaDiS achieves superior performance across multiple metrics, including DTW error and two newly introduced metrics, SiBLEU and SiCLIP, while reducing inference latency by nearly 30%. Code and models will be released on our project page.

</details>


### [89] [QuaMo: Quaternion Motions for Vision-based 3D Human Kinematics Capture](https://arxiv.org/abs/2601.19580)
*Cuong Le,Pavlo Melnyk,Urs Waldmann,Mårten Wadenbäck,Bastian Wandt*

Main category: cs.CV

TL;DR: 提出了一种名为QuaMo的新型基于四元数微分方程（QDE）的人体运动学捕捉方法，以解决现有方法在欧拉角不连续性导致的运动不稳定问题。QuaMo利用四元数状态空间模型和带有加速度增强的元PD控制器，在四元数单位球约束下求解QDE，实现了更准确、连续且无不合理运动的人体3D运动估计。


<details>
  <summary>Details</summary>
Motivation: 传统3D姿态估计方法忽略帧间时间一致性，导致运动不稳定。现有的运动学方法依赖于存在不连续性的欧拉角，尤其是在在线设置中，这会导致运动重建不稳定。因此，需要一种能够实现平滑、连续姿态过渡的运动学捕捉方法。

Method: 提出QuaMo方法，利用四元数微分方程（QDE）描述人体运动学。使用状态空间模型，其中四元数作为状态，QDE描述四元数速度。通过带有新颖加速度增强的元PD控制器计算角加速度，该控制器能自适应调节控制信号。QDE在四元数单位球约束下求解，以提高精度。

Result: QuaMo方法能够准确估计3D人体运动学，不存在不连续性，并最大限度地减少了不合理的运动。在Human3.6M、Fit3D、SportsPose和AIST等多个数据集上，QuaMo的性能优于同类最先进的方法。

Conclusion: QuaMo通过使用四元数微分方程和创新的控制策略，成功解决了现有运动学捕捉方法中的不连续性问题，实现了更准确、更平滑的3D人体运动估计，并在多项评估中取得了优于现有方法的性能。

Abstract: Vision-based 3D human motion capture from videos remains a challenge in computer vision. Traditional 3D pose estimation approaches often ignore the temporal consistency between frames, causing implausible and jittery motion. The emerging field of kinematics-based 3D motion capture addresses these issues by estimating the temporal transitioning between poses instead. A major drawback in current kinematics approaches is their reliance on Euler angles. Despite their simplicity, Euler angles suffer from discontinuity that leads to unstable motion reconstructions, especially in online settings where trajectory refinement is unavailable. Contrarily, quaternions have no discontinuity and can produce continuous transitions between poses. In this paper, we propose QuaMo, a novel Quaternion Motions method using quaternion differential equations (QDE) for human kinematics capture. We utilize the state-space model, an effective system for describing real-time kinematics estimations, with quaternion state and the QDE describing quaternion velocity. The corresponding angular acceleration is computed from a meta-PD controller with a novel acceleration enhancement that adaptively regulates the control signals as the human quickly changes to a new pose. Unlike previous work, our QDE is solved under the quaternion unit-sphere constraint that results in more accurate estimations. Experimental results show that our novel formulation of the QDE with acceleration enhancement accurately estimates 3D human kinematics with no discontinuity and minimal implausibilities. QuaMo outperforms comparable state-of-the-art methods on multiple datasets, namely Human3.6M, Fit3D, SportsPose and AIST. The code is available at https://github.com/cuongle1206/QuaMo

</details>


### [90] [A Non-Invasive 3D Gait Analysis Framework for Quantifying Psychomotor Retardation in Major Depressive Disorder](https://arxiv.org/abs/2601.19526)
*Fouad Boutaleb,Emery Pierson,Mohamed Daoudi,Clémence Nineuil,Ali Amad,Fabien D'Hondt*

Main category: cs.CV

TL;DR: 本研究提出了一种使用单目RGB视频从患者步态中提取生物力学特征的方法，用于客观评估抑郁症（MDD）的运动迟缓（PMR）和整体抑郁严重程度。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症状态的客观预测方法研究活跃，但自动提取客观、可解释的特征用于详细患者状态分析仍是未被充分探索的领域。核心症状之一的运动迟缓（PMR）评估仍依赖主观判断，而3D动作捕捉设备昂贵且不便于临床常规使用。

Method: 提出了一种非侵入式计算框架，将单目RGB视频转化为临床相关的3D步态运动学。该框架使用重力视图坐标系，并结合了一种新颖的轨迹校正算法，该算法利用改编后的Timed Up and Go（TUG）协议的闭环拓扑结构来减少单目深度误差。该方法能够从单次相机捕获中提取297个步态生物力学生物标记物。针对小样本临床数据集的挑战，引入了一个基于稳定性的机器学习框架，用于识别稳健的运动特征并防止过拟合。

Result: 在CALYPSO数据集上验证，该方法在检测PMR方面达到了83.3%的准确率，并能解释64%的总体抑郁严重程度变异性（R^2=0.64）。研究揭示了脚踝推进力减弱和骨盆活动受限与抑郁运动表型之间存在强关联。

Conclusion: 身体运动可以作为认知状态的有力代理，为在标准临床环境中客观监测抑郁症提供了一种透明且可扩展的工具。

Abstract: Predicting the status of Major Depressive Disorder (MDD) from objective, non-invasive methods is an active research field. Yet, extracting automatically objective, interpretable features for a detailed analysis of the patient state remains largely unexplored.
  Among MDD's symptoms, Psychomotor retardation (PMR) is a core item, yet its clinical assessment remains largely subjective. While 3D motion capture offers an objective alternative, its reliance on specialized hardware often precludes routine clinical use. In this paper, we propose a non-invasive computational framework that transforms monocular RGB video into clinically relevant 3D gait kinematics. Our pipeline uses Gravity-View Coordinates along with a novel trajectory-correction algorithm that leverages the closed-loop topology of our adapted Timed Up and Go (TUG) protocol to mitigate monocular depth errors. This novel pipeline enables the extraction of 297 explicit gait biomechanical biomarkers from a single camera capture.
  To address the challenges of small clinical datasets, we introduce a stability-based machine learning framework that identifies robust motor signatures while preventing overfitting. Validated on the CALYPSO dataset, our method achieves an 83.3% accuracy in detecting PMR and explains 64% of the variance in overall depression severity (R^2=0.64). Notably, our study reveals a strong link between reduced ankle propulsion and restricted pelvic mobility to the depressive motor phenotype. These results demonstrate that physical movement serves as a robust proxy for the cognitive state, offering a transparent and scalable tool for the objective monitoring of depression in standard clinical environments.

</details>


### [91] [ScenePilot-Bench: A Large-Scale Dataset and Benchmark for Evaluation of Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2601.19582)
*Yujin Wang,Yutong Zheng,Wenxian Fan,Tianyi Wang,Hongqing Chu,Daxin Tian,Bingzhao Gao,Jianqiang Wang,Hong Chen*

Main category: cs.CV

TL;DR: 本文提出了 ScenePilot-Bench，一个用于评估自动驾驶场景下视觉语言模型（VLMs）的大规模第一人称驾驶基准。该基准包含大量视频数据和多维度标注，并设计了四轴评估体系，通过安全相关的指标和跨区域泛化设置来衡量 VLM 在场景理解、空间感知、运动规划和 GPT-Score 方面的能力。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶领域对视觉语言模型（VLMs）的评估尚不充分，尤其是在处理复杂的、第一人称视角的驾驶场景时。作者希望构建一个全面的基准来推动 VLM 在这一关键领域的进步。

Method: 构建了一个名为 ScenePilot-Bench 的大规模第一人称驾驶基准，该基准基于 ScenePilot-4K 数据集，该数据集包含 3,847 小时的驾驶视频。基准包含多粒度的标注信息，如场景描述、风险评估、关键参与者识别、自身轨迹和相机参数。此外，还设计了一个包含场景理解、空间感知、运动规划和 GPT-Score 四个维度的评估体系，并引入了安全相关的指标和跨区域泛化设置。

Result: 在 ScenePilot-Bench 上对代表性的 VLMs 进行了基准测试，并提供了实证分析。结果揭示了当前 VLM 在驾驶场景下的性能边界，并识别出了在面向驾驶的推理方面存在的差距。

Conclusion: ScenePilot-Bench 提供了一个全面的框架，用于评估和改进视觉语言模型在安全关键的自动驾驶环境中的性能，有助于推动该领域的发展。

Abstract: In this paper, we introduce ScenePilot-Bench, a large-scale first-person driving benchmark designed to evaluate vision-language models (VLMs) in autonomous driving scenarios. ScenePilot-Bench is built upon ScenePilot-4K, a diverse dataset comprising 3,847 hours of driving videos, annotated with multi-granularity information including scene descriptions, risk assessments, key participant identification, ego trajectories, and camera parameters. The benchmark features a four-axis evaluation suite that assesses VLM capabilities in scene understanding, spatial perception, motion planning, and GPT-Score, with safety-aware metrics and cross-region generalization settings. We benchmark representative VLMs on ScenePilot-Bench, providing empirical analyses that clarify current performance boundaries and identify gaps for driving-oriented reasoning. ScenePilot-Bench offers a comprehensive framework for evaluating and advancing VLMs in safety-critical autonomous driving contexts.

</details>


### [92] [Towards Governance-Oriented Low-Altitude Intelligence: A Management-Centric Multi-Modal Benchmark With Implicitly Coordinated Vision-Language Reasoning Framework](https://arxiv.org/abs/2601.19640)
*Hao Chang,Zhihui Wang,Lingxiang Wu,Peijin Wang,Wenhui Diao,Jinqiao Wang*

Main category: cs.CV

TL;DR: 本文提出了GovLA-10K数据集和GovLA-Reasoner框架，旨在解决低空视觉系统在城市治理中进行管理导向异常理解的挑战，通过功能性目标标注和统一的视觉语言推理，提升了系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的面向对象的感知范式和松散耦合的视觉-语言管道难以支持现实世界城市治理中所需的、面向管理的异常理解。

Method: 提出GovLA-10K数据集，该数据集围绕直接对应实际管理需求的功能性目标进行标注，并提供基于观察的 actionable management suggestions。提出GovLA-Reasoner框架，该框架包含一个高效的特征适配器，用于协调视觉检测器和大型语言模型（LLM）之间的细粒度视觉基础和高层上下文语言推理。

Result: GovLA-Reasoner方法在实验中显著提升了性能，并且无需对任何特定任务的单个组件进行微调。

Conclusion: GovLA-10K和GovLA-Reasoner为未来面向管理的低空视觉-语言系统的研究提供了一个新的视角和基础。

Abstract: Low-altitude vision systems are becoming a critical infrastructure for smart city governance. However, existing object-centric perception paradigms and loosely coupled vision-language pipelines are still difficult to support management-oriented anomaly understanding required in real-world urban governance. To bridge this gap, we introduce GovLA-10K, the first management-oriented multi-modal benchmark for low-altitude intelligence, along with GovLA-Reasoner, a unified vision-language reasoning framework tailored for governance-aware aerial perception. Unlike existing studies that aim to exhaustively annotate all visible objects, GovLA-10K is deliberately designed around functionally salient targets that directly correspond to practical management needs, and further provides actionable management suggestions grounded in these observations. To effectively coordinate the fine-grained visual grounding with high-level contextual language reasoning, GovLA-Reasoner introduces an efficient feature adapter that implicitly coordinates discriminative representation sharing between the visual detector and the large language model (LLM). Extensive experiments show that our method significantly improves performance while avoiding the need of fine-tuning for any task-specific individual components. We believe our work offers a new perspective and foundation for future studies on management-aware low-altitude vision-language systems.

</details>


### [93] [A new Image Similarity Metric for a Perceptual and Transparent Geometric and Chromatic Assessment](https://arxiv.org/abs/2601.19680)
*Antonio Di Marino,Vincenzo Bevilacqua,Emanuel Di Nardo,Angelo Ciaramella,Ivanoe De Falco,Giovanna Sannino*

Main category: cs.CV

TL;DR: 提出一种新的感知相似度度量方法，结合了纹理和颜色信息，并在具有复杂失真的数据集上优于现有方法，同时提供可视化解释。


<details>
  <summary>Details</summary>
Motivation: 现有图像相似度度量方法并非感知度量，尤其在处理纹理失真时表现不佳。

Method: 提出一种由两部分组成的感知度量：使用Earth Mover's Distance评估图像纹理的差异，使用Oklab感知颜色空间评估图像的色度差异。

Result: 在Berkeley-Adobe Perceptual Patch Similarity数据集上，新度量方法优于现有方法，尤其在图像存在形状失真时，且具有更好的感知性。此外，该方法还能提供可视化解释，支持其计算得分。

Conclusion: 所提出的新感知度量方法在评估具有复杂失真图像的相似度方面表现出色，并能提供透明、合理的相似度评估。

Abstract: In the literature, several studies have shown that state-of-the-art image similarity metrics are not perceptual metrics; moreover, they have difficulty evaluating images, especially when texture distortion is also present. In this work, we propose a new perceptual metric composed of two terms. The first term evaluates the dissimilarity between the textures of two images using Earth Mover's Distance. The second term evaluates the chromatic dissimilarity between two images in the Oklab perceptual color space. We evaluated the performance of our metric on a non-traditional dataset, called Berkeley-Adobe Perceptual Patch Similarity, which contains a wide range of complex distortions in shapes and colors. We have shown that our metric outperforms the state of the art, especially when images contain shape distortions, confirming also its greater perceptiveness. Furthermore, although deep black-box metrics could be very accurate, they only provide similarity scores between two images, without explaining their main differences and similarities. Our metric, on the other hand, provides visual explanations to support the calculated score, making the similarity assessment transparent and justified.

</details>


### [94] [KeepLoRA: Continual Learning with Residual Gradient Adaptation](https://arxiv.org/abs/2601.19659)
*Mao-Lin Luo,Zi-Hao Zhou,Yi-Lin Zhang,Yuanyu Wan,Tong Wei,Min-Ling Zhang*

Main category: cs.CV

TL;DR: 提出一种名为KeepLoRA的方法，通过将LoRA参数更新限制在残差子空间，有效解决了预训练视觉语言模型在持续学习中知识保留、任务迁移和新知识获取之间的平衡问题，并取得了最新的性能。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉语言模型在持续学习中面临着保留预训练知识、保持已学任务知识以及获取新知识的能力之间的冲突。

Method: KeepLoRA分析了模型参数空间中的知识保留机制，发现通用知识存储在主子空间，任务特定知识存储在残差子空间。在此基础上，KeepLoRA通过将新任务的梯度投影到正交于预训练模型主子空间和先前任务特征主导方向的子空间，来限制LoRA参数更新在残差子空间，从而避免干扰已学能力。

Result: KeepLoRA在理论和实证上都证实了其能够有效地平衡三个目标，并在持续学习任务上取得了最先进的性能。

Conclusion: KeepLoRA是一种简单有效的方法，可以解决预训练视觉语言模型在持续学习中遇到的知识保留、任务迁移和新知识获取之间的挑战，并提供了优越的性能。

Abstract: Continual learning for pre-trained vision-language models requires balancing three competing objectives: retaining pre-trained knowledge, preserving knowledge from a sequence of learned tasks, and maintaining the plasticity to acquire new knowledge. This paper presents a simple but effective approach called KeepLoRA to effectively balance these objectives. We first analyze the knowledge retention mechanism within the model parameter space and find that general knowledge is mainly encoded in the principal subspace, while task-specific knowledge is encoded in the residual subspace. Motivated by this finding, KeepLoRA learns new tasks by restricting LoRA parameter updates in the residual subspace to prevent interfering with previously learned capabilities. Specifically, we infuse knowledge for a new task by projecting its gradient onto a subspace orthogonal to both the principal subspace of pre-trained model and the dominant directions of previous task features. Our theoretical and empirical analyses confirm that KeepLoRA balances the three objectives and achieves state-of-the-art performance. The implementation code is available at https://github.com/MaolinLuo/KeepLoRA.

</details>


### [95] [Localized Latent Editing for Dose-Response Modeling in Botulinum Toxin Injection Planning](https://arxiv.org/abs/2601.19593)
*Estèphe Arnaud,Mohamed Daoudi,Pierre Guerreschi*

Main category: cs.CV

TL;DR: 本文提出了一种基于StyleGAN2的局部潜在编辑框架，用于模拟肉毒杆菌毒素注射效果，以辅助注射剂量规划。该框架通过学习局部肌肉松弛轨迹并将其与毒素单位关联，构建剂量-反应模型，并结合“人机协同”工作流，以提高面部不对称管理和美容效果的精确性。


<details>
  <summary>Details</summary>
Motivation: 目前肉毒杆菌毒素注射的剂量确定很大程度上依赖直觉，导致效果不理想。研究旨在通过模拟注射效果来优化注射规划，提高治疗效果。

Method: 采用局部潜在编辑框架，利用Region-Specific Latent Axis Discovery方法在StyleGAN2的潜在空间中学习特定面部区域的肌肉松弛轨迹。通过将这些轨迹与注射的毒素单位关联，学习预测性的剂量-反应模型。此外，还引入了“人机协同”工作流，允许临床医生交互式地优化模拟结果。

Result: 所提出的框架在几何不对称性度量方面展示了中等到强的结构相关性，表明生成模型能准确捕捉形态变化的方向。尽管生物学变异性限制了绝对精度，但该框架有效地模拟了肉毒杆菌毒素注射的效果。

Conclusion: 本文提出的局部潜在编辑框架能够模拟肉毒杆菌毒素注射效果，为注射规划提供了一种基于模型的解决方案，并能与临床实践相结合，以改进面部不对称的管理和美容治疗。

Abstract: Botulinum toxin (Botox) injections are the gold standard for managing facial asymmetry and aesthetic rejuvenation, yet determining the optimal dosage remains largely intuitive, often leading to suboptimal outcomes. We propose a localized latent editing framework that simulates Botulinum Toxin injection effects for injection planning through dose-response modeling. Our key contribution is a Region-Specific Latent Axis Discovery method that learns localized muscle relaxation trajectories in StyleGAN2's latent space, enabling precise control over specific facial regions without global side effects. By correlating these localized latent trajectories with injected toxin units, we learn a predictive dose-response model. We rigorously compare two approaches: direct metric regression versus image-based generative simulation on a clinical dataset of N=360 images from 46 patients. On a hold-out test set, our framework demonstrates moderate-to-strong structural correlations for geometric asymmetry metrics, confirming that the generative model correctly captures the direction of morphological changes. While biological variability limits absolute precision, we introduce a hybrid "Human-in-the-Loop" workflow where clinicians interactively refine simulations, bridging the gap between pathological reconstruction and cosmetic planning.

</details>


### [96] [SharpNet: Enhancing MLPs to Represent Functions with Controlled Non-differentiability](https://arxiv.org/abs/2601.19683)
*Hanting Niu,Junkai Deng,Fei Hou,Wencheng Wang,Ying He*

Main category: cs.CV

TL;DR: 本文提出了一种名为SharpNet的修改版多层感知机（MLP）架构，能够通过引入一个辅助特征函数来表示具有用户定义的尖锐特征（如连续但不可导的函数）的函数，并在CAD模型重建等任务上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的MLP在表示具有尖锐特征（连续但不可导）的函数时存在困难，因为它们输出的平滑性。现有方法通常依赖于临时的后处理技术。

Method: SharpNet通过引入一个辅助特征函数来增强MLP，该函数是具有跳跃 Neumann 边界条件的泊松方程的解。该方法使用一个可微分的局部积分来评估网络，从而能够联合优化特征位置和MLP参数，以恢复目标函数。SharpNet的C^0连续性是可控的，确保在特征位置具有C^0连续性，而在其他地方保持平滑。

Result: SharpNet在2D问题和3D CAD模型重建任务上得到了验证。与现有方法相比，SharpNet能够准确地恢复尖锐的边缘和角点，同时保持特征点以外的平滑行为，而现有方法往往会平滑掉梯度不连续点。

Conclusion: SharpNet是一种有效的MLP修改架构，能够精确地表示具有用户定义尖锐特征的函数，在CAD模型重建等应用中具有显著优势，克服了传统MLP在处理此类问题时的局限性。

Abstract: Multi-layer perceptrons (MLPs) are a standard tool for learning and function approximation, but they inherently yield outputs that are globally smooth. As a result, they struggle to represent functions that are continuous yet deliberately non-differentiable (i.e., with prescribed $C^0$ sharp features) without relying on ad hoc post-processing. We present SharpNet, a modified MLP architecture capable of encoding functions with user-defined sharp features by enriching the network with an auxiliary feature function, which is defined as the solution to a Poisson equation with jump Neumann boundary conditions. It is evaluated via an efficient local integral that is fully differentiable with respect to the feature locations, enabling our method to jointly optimize both the feature locations and the MLP parameters to recover the target functions/models. The $C^0$-continuity of SharpNet is precisely controllable, ensuring $C^0$-continuity at the feature locations and smoothness elsewhere. We validate SharpNet on 2D problems and 3D CAD model reconstruction, and compare it against several state-of-the-art baselines. In both types of tasks, SharpNet accurately recovers sharp edges and corners while maintaining smooth behavior away from those features, whereas existing methods tend to smooth out gradient discontinuities. Both qualitative and quantitative evaluations highlight the benefits of our approach.

</details>


### [97] [Video-KTR: Reinforcing Video Reasoning via Key Token Attribution](https://arxiv.org/abs/2601.19686)
*Ziyue Wang,Sheng Jin,Zhongrong Zuo,Jiawei Wu,Han Qiu,Qi She,Hao Zhang,Xudong Jiang*

Main category: cs.CV

TL;DR: Video-KTR 是一种面向视频理解的多模态模型强化学习框架，通过选择性地关注与视觉、时间或预测不确定性相关的关键 token，显著提升了推理准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有视频推理方法在奖励信号和 token 选择上过于粗糙，忽略了视觉输入、时间动态和语言输出之间的细粒度关联，限制了模型的准确性和可解释性。

Method: 提出 Video-KTR 框架，通过结合三种归因信号（视觉感知依赖、时间敏感性、预测不确定性）进行选择性的、token 级别的强化学习。具体方法包括：使用反事实掩码识别视觉感知 token，通过帧重排检测时间敏感 token，以及利用高熵信号识别预测不确定性 token。

Result: 在五个具有挑战性的基准测试中，Video-KTR 取得了最先进或非常有竞争力的结果，在 Video-Holmes 数据集上达到了 42.7% 的准确率（优于 GPT-4o），并在推理和通用视频理解任务上均取得了显著提升。

Conclusion: Video-KTR 通过强化关键 token，专注于学习语义信息丰富、对模态敏感的内容，同时过滤掉低价值 token，有效提高了视频推理的准确性和可解释性，是一种简单且可直接应用的强化学习扩展方法。

Abstract: Reinforcement learning (RL) has shown strong potential for enhancing reasoning in multimodal large language models, yet existing video reasoning methods often rely on coarse sequence-level rewards or single-factor token selection, neglecting fine-grained links among visual inputs, temporal dynamics, and linguistic outputs, limiting both accuracy and interpretability. We propose Video-KTR, a modality-aware policy shaping framework that performs selective, token-level RL by combining three attribution signals: (1) visual-aware tokens identified via counterfactual masking to reveal perceptual dependence; (2) temporal-aware tokens detected through frame shuffling to expose temporal sensitivity; and (3) high-entropy tokens signaling predictive uncertainty. By reinforcing only these key tokens, Video-KTR focuses learning on semantically informative, modality-sensitive content while filtering out low-value tokens. Across five challenging benchmarks, Video-KTR achieves state-of-the-art or highly competitive results, achieving 42.7\% on Video-Holmes (surpassing GPT-4o) with consistent gains on both reasoning and general video understanding tasks. Ablation studies verify the complementary roles of the attribution signals and the robustness of targeted token-level updates. Overall, Video-KTR improves accuracy and interpretability, offering a simple, drop-in extension to RL for complex video reasoning. Our code and models are available at https://github.com/zywang0104/Video-KTR.

</details>


### [98] [DSVM-UNet : Enhancing VM-UNet with Dual Self-distillation for Medical Image Segmentation](https://arxiv.org/abs/2601.19690)
*Renrong Shao,Dongyang Li,Dong Xia,Lin Shao,Jiangdong Lu,Fen Zheng,Lulu Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为DSVM-UNet的双重自蒸馏方法，用于改进基于Vision Mamba的UNet在医学图像分割任务中的性能，无需复杂的架构设计，并在多个基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有基于Vision Mamba的UNet（VM-UNet）模型在医学图像分割中主要通过优化架构设计来提升语义感知能力，但可能导致模型复杂化。作者希望在不增加模型复杂性的前提下，通过一种简单有效的方法来提升VM-UNet的性能。

Method: 提出了一种名为DSVM-UNet的双重自蒸馏方法。该方法通过设计两种自蒸馏机制，分别在全局和局部层面引导特征对齐，以增强模型的学习能力。

Result: 在ISIC2017、ISIC2018和Synapse数据集上的广泛实验表明，DSVM-UNet方法在保持计算效率的同时，取得了当前最优的性能。

Conclusion: 双重自蒸馏是一种简单而有效的技术，可以显著提升VM-UNet在医学图像分割任务中的性能，无需进行复杂的架构修改。

Abstract: Vision Mamba models have been extensively researched in various fields, which address the limitations of previous models by effectively managing long-range dependencies with a linear-time overhead. Several prospective studies have further designed Vision Mamba based on UNet(VM-UNet) for medical image segmentation. These approaches primarily focus on optimizing architectural designs by creating more complex structures to enhance the model's ability to perceive semantic features. In this paper, we propose a simple yet effective approach to improve the model by Dual Self-distillation for VM-UNet (DSVM-UNet) without any complex architectural designs. To achieve this goal, we develop double self-distillation methods to align the features at both the global and local levels. Extensive experiments conducted on the ISIC2017, ISIC2018, and Synapse benchmarks demonstrate that our approach achieves state-of-the-art performance while maintaining computational efficiency. Code is available at https://github.com/RoryShao/DSVM-UNet.git.

</details>


### [99] [Self-Supervised Weight Templates for Scalable Vision Model Initialization](https://arxiv.org/abs/2601.19694)
*Yucheng Xie,Fu Feng,Ruixiao Shi,Jing Wang,Yong Rui,Xin Geng*

Main category: cs.CV

TL;DR: 提出了一种名为SWEET的自监督预训练框架，通过学习共享权重模板和尺寸特定的权重缩放器，实现了可扩展的视觉模型初始化，能够灵活适应不同尺寸的模型，并在多项下游任务上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有预训练和微调方法难以应对现代模型参数规模日益增长以及部署时需要不同尺寸模型的需求。

Method: SWEET框架采用基于Tucker分解的方法，学习一个共享的权重模板和尺寸特定的权重缩放器，以实现模块化和灵活适应不同尺寸的模型。对于宽度扩展，引入了宽度随机缩放技术，以增强模型的鲁棒性和跨宽度泛化能力。

Result: SWEET框架在分类、检测、分割和生成等多个视觉任务上，初始化不同尺寸的模型时，均取得了最先进的性能。

Conclusion: SWEET框架能够有效地解决现有预训练方法的局限性，通过可扩展的初始化策略，为适应不同尺寸的视觉模型提供了灵活且性能优越的解决方案。

Abstract: The increasing scale and complexity of modern model parameters underscore the importance of pre-trained models. However, deployment often demands architectures of varying sizes, exposing limitations of conventional pre-training and fine-tuning. To address this, we propose SWEET, a self-supervised framework that performs constraint-based pre-training to enable scalable initialization in vision tasks. Instead of pre-training a fixed-size model, we learn a shared weight template and size-specific weight scalers under Tucker-based factorization, which promotes modularity and supports flexible adaptation to architectures with varying depths and widths. Target models are subsequently initialized by composing and reweighting the template through lightweight weight scalers, whose parameters can be efficiently learned from minimal training data. To further enhance flexibility in width expansion, we introduce width-wise stochastic scaling, which regularizes the template along width-related dimensions and encourages robust, width-invariant representations for improved cross-width generalization. Extensive experiments on \textsc{classification}, \textsc{detection}, \textsc{segmentation} and \textsc{generation} tasks demonstrate the state-of-the-art performance of SWEET for initializing variable-sized vision models.

</details>


### [100] [DiffStyle3D: Consistent 3D Gaussian Stylization via Attention Optimization](https://arxiv.org/abs/2601.19717)
*Yitong Yang,Xuexin Liu,Yinglin Wang,Jing Wang,Hao Dou,Changshuo Wang,Shuting He*

Main category: cs.CV

TL;DR: 本文提出了一种名为DiffStyle3D的新型基于扩散的3D风格迁移方法，通过在潜在空间中直接优化，解决了现有方法在多视图一致性和训练稳定性方面的问题，并在实验中取得了优于现有最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D风格迁移方法（如基于VGG和CLIP的方法）在建模多视图一致性方面存在困难，而基于扩散的方法虽然能捕捉多视图一致性，但训练不稳定。作者希望提出一种能够同时处理多视图一致性和训练稳定性的新方法。

Method: DiffStyle3D是一种基于扩散模型的3D风格迁移方法，直接在潜在空间中进行优化。它引入了两个关键组件：1. 注意力感知损失（Attention-Aware Loss），通过对齐自注意力空间中的风格特征来实现风格迁移，并保留内容特征。2. 几何引导多视图一致性（Geometry-Guided Multi-View Consistency），将几何信息集成到自注意力中，以实现跨视图的对应建模。此外，还设计了一个几何感知掩码（geometry-aware mask）来避免重叠区域的冗余优化，从而进一步增强多视图一致性。

Result: 通过大量实验表明，DiffStyle3D在风格迁移质量和视觉真实性方面均优于现有最先进的方法。

Conclusion: DiffStyle3D是一种有效的新型3D风格迁移范式，通过直接在潜在空间中优化并结合注意力感知损失和几何引导多视图一致性，解决了现有方法的局限性，实现了高质量且多视图一致的3D风格迁移。

Abstract: 3D style transfer enables the creation of visually expressive 3D content, enriching the visual appearance of 3D scenes and objects. However, existing VGG- and CLIP-based methods struggle to model multi-view consistency within the model itself, while diffusion-based approaches can capture such consistency but rely on denoising directions, leading to unstable training. To address these limitations, we propose DiffStyle3D, a novel diffusion-based paradigm for 3DGS style transfer that directly optimizes in the latent space. Specifically, we introduce an Attention-Aware Loss that performs style transfer by aligning style features in the self-attention space, while preserving original content through content feature alignment. Inspired by the geometric invariance of 3D stylization, we propose a Geometry-Guided Multi-View Consistency method that integrates geometric information into self-attention to enable cross-view correspondence modeling. Based on geometric information, we additionally construct a geometry-aware mask to prevent redundant optimization in overlapping regions across views, which further improves multi-view consistency. Extensive experiments show that DiffStyle3D outperforms state-of-the-art methods, achieving higher stylization quality and visual realism.

</details>


### [101] [Diffusion for De-Occlusion: Accessory-Aware Diffusion Inpainting for Robust Ear Biometric Recognition](https://arxiv.org/abs/2601.19795)
*Deeksha Arun,Kevin W. Bowyer,Patrick Flynn*

Main category: cs.CV

TL;DR: 使用基于扩散的图像修复技术作为预处理步骤，可以有效减轻耳部配饰（如耳环、耳机）造成的遮挡问题，从而提高基于Transformer的耳部生物识别系统的性能。


<details>
  <summary>Details</summary>
Motivation: 耳部配饰（如耳环、耳机）会导致耳部生物识别系统性能下降，尤其是在非约束成像条件下。

Method: 提出一种基于扩散的耳部图像修复技术，通过输入原始耳部图像和自动生成的配饰掩码，模型可以修复被遮挡的区域，合成缺失的像素，并保持螺旋、对耳轮、耳甲和耳垂等关键耳部结构的局部几何一致性。

Result: 在多种视觉Transformer模型、不同的补丁大小以及多个基准数据集上进行了评估。实验表明，基于扩散的修复技术作为预处理可以有效缓解耳部配饰遮挡问题，提升整体识别性能。

Conclusion: 基于扩散的耳部图像修复技术是一种有效的预处理方法，可以减轻耳部配饰造成的遮挡，并提升基于Transformer的耳部识别系统的性能。

Abstract: Ear occlusions (arising from the presence of ear accessories such as earrings and earphones) can negatively impact performance in ear-based biometric recognition systems, especially in unconstrained imaging circumstances. In this study, we assess the effectiveness of a diffusion-based ear inpainting technique as a pre-processing aid to mitigate the issues of ear accessory occlusions in transformer-based ear recognition systems. Given an input ear image and an automatically derived accessory mask, the inpainting model reconstructs clean and anatomically plausible ear regions by synthesizing missing pixels while preserving local geometric coherence along key ear structures, including the helix, antihelix, concha, and lobule. We evaluate the effectiveness of this pre-processing aid in transformer-based recognition systems for several vision transformer models and different patch sizes for a range of benchmark datasets. Experiments show that diffusion-based inpainting can be a useful pre-processing aid to alleviate ear accessory occlusions to improve overall recognition performance.

</details>


### [102] [WaterClear-GS: Optical-Aware Gaussian Splatting for Underwater Reconstruction and Restoration](https://arxiv.org/abs/2601.19753)
*Xinrui Zhang,Yufeng Wang,Shuangkang Fang,Zesheng Wang,Dacheng Qi,Wenrui Ding*

Main category: cs.CV

TL;DR: 提出了一种名为 WaterClear-GS 的新方法，它基于 3D 高斯溅射 (3DGS)，能够同时实现水下 3D 重建和外观恢复，并考虑了水的吸收和散射特性，实现了实时渲染。


<details>
  <summary>Details</summary>
Motivation: 现有基于 NeRF 的方法在渲染速度和色彩恢复方面存在不足，而 3DGS 本身无法模拟复杂的体积散射效应。水下环境的光学特性（如波长相关的衰减和散射）给 3D 重建和外观恢复带来了挑战。

Method: WaterClear-GS 是一种纯 3DGS 框架，它将水下局部衰减和散射的光学特性集成到高斯基元中。采用双分支优化策略来确保水下光度一致性并恢复无水外观。通过深度引导的几何正则化、感知驱动的图像损失、曝光约束、空间自适应正则化和物理引导的光谱正则化来增强性能。

Result: 在标准基准和新数据集上的实验表明，WaterClear-GS 在新视角合成 (NVS) 和水下图像恢复 (UIR) 任务上取得了优异的性能，同时保持了实时渲染速度。

Conclusion: WaterClear-GS 是首个纯 3DGS 框架，能够有效地集成水下光学特性，实现高效的水下 3D 重建和外观恢复，并在性能和渲染速度上均优于现有方法。

Abstract: Underwater 3D reconstruction and appearance restoration are hindered by the complex optical properties of water, such as wavelength-dependent attenuation and scattering. Existing Neural Radiance Fields (NeRF)-based methods struggle with slow rendering speeds and suboptimal color restoration, while 3D Gaussian Splatting (3DGS) inherently lacks the capability to model complex volumetric scattering effects. To address these issues, we introduce WaterClear-GS, the first pure 3DGS-based framework that explicitly integrates underwater optical properties of local attenuation and scattering into Gaussian primitives, eliminating the need for an auxiliary medium network. Our method employs a dual-branch optimization strategy to ensure underwater photometric consistency while naturally recovering water-free appearances. This strategy is enhanced by depth-guided geometry regularization and perception-driven image loss, together with exposure constraints, spatially-adaptive regularization, and physically guided spectral regularization, which collectively enforce local 3D coherence and maintain natural visual perception. Experiments on standard benchmarks and our newly collected dataset demonstrate that WaterClear-GS achieves outstanding performance on both novel view synthesis (NVS) and underwater image restoration (UIR) tasks, while maintaining real-time rendering. The code will be available at https://buaaxrzhang.github.io/WaterClear-GS/.

</details>


### [103] [Query-Guided Spatial-Temporal-Frequency Interaction for Music Audio-Visual Question Answering](https://arxiv.org/abs/2601.19821)
*Kun Li,Michael Ying Yang,Sami Sebastian Brandt*

Main category: cs.CV

TL;DR: 提出了一种新的查询引导空间-时域-频率（QSTar）交互方法，通过整合问题引导线索，利用音频信号的频域特征以及时空感知，来提升音视频问答（AVQA）性能。同时引入了查询上下文推理（QCR）模块，以更精确地聚焦于语义相关的音视频特征。


<details>
  <summary>Details</summary>
Motivation: 现有AVQA方法过度依赖视觉信息，将音频视为补充，文本信息在最后阶段才整合，未能充分利用音频和文本信息进行音视频理解。

Method: 提出QSTar方法，整合问题引导线索，利用音频的频域特征以及时空感知；提出QCR模块，借鉴prompting思想，引导模型关注语义相关的音视频特征。

Result: 在多个AVQA基准测试中，QSTar方法取得了显著的性能提升，优于现有的音频QA、视觉QA、视频QA和AVQA方法。

Conclusion: QSTar方法通过有效融合问题引导线索、音频频域特征及时空感知，并结合QCR模块，显著提升了AVQA模型的性能。

Abstract: Audio--Visual Question Answering (AVQA) is a challenging multimodal task that requires jointly reasoning over audio, visual, and textual information in a given video to answer natural language questions. Inspired by recent advances in Video QA, many existing AVQA approaches primarily focus on visual information processing, leveraging pre-trained models to extract object-level and motion-level representations. However, in those methods, the audio input is primarily treated as complementary to video analysis, and the textual question information contributes minimally to audio--visual understanding, as it is typically integrated only in the final stages of reasoning. To address these limitations, we propose a novel Query-guided Spatial--Temporal--Frequency (QSTar) interaction method, which effectively incorporates question-guided clues and exploits the distinctive frequency-domain characteristics of audio signals, alongside spatial and temporal perception, to enhance audio--visual understanding. Furthermore, we introduce a Query Context Reasoning (QCR) block inspired by prompting, which guides the model to focus more precisely on semantically relevant audio and visual features. Extensive experiments conducted on several AVQA benchmarks demonstrate the effectiveness of our proposed method, achieving significant performance improvements over existing Audio QA, Visual QA, Video QA, and AVQA approaches. The code and pretrained models will be released after publication.

</details>


### [104] [PaW-ViT: A Patch-based Warping Vision Transformer for Robust Ear Verification](https://arxiv.org/abs/2601.19771)
*Deeksha Arun,Kevin W. Bowyer,Patrick Flynn*

Main category: cs.CV

TL;DR: PaW-ViT 是一种基于解剖学知识的预处理方法，通过对耳图像进行像素扭曲来对齐 Vision Transformer (ViT) 的 token 边界和耳部特征边界，从而提高 ViT 在处理形状、大小和姿势变化时的鲁棒性，并为身份验证方案提供了一种新的途径。


<details>
  <summary>Details</summary>
Motivation: 标准的 Vision Transformer (ViT) 方法在视觉识别任务中通常使用矩形 token，这可能因为包含了识别对象外部的信息而影响性能。耳部生物特征识别面临形状、大小和姿势变化的挑战，而 ViT 对位置敏感，两者之间存在脱节。

Method: 提出了一种名为 PaW-ViT（Patch-based Warping Vision Transformer）的预处理方法。该方法利用解剖学知识，通过精确对齐 token 边界到检测到的耳部特征边界，并根据自然耳部曲率进行对齐，来规范化耳部图像。

Result: 实验证明 PaW-ViT 在多种 ViT 模型（ViT-T, ViT-S, ViT-B, ViT-L）上都有效，显著提高了对形状、大小和姿势变化的对齐鲁棒性，并产生更一致的 token 表示。

Conclusion: PaW-ViT 成功解决了耳部形态变异与 Transformer 架构位置敏感性之间的矛盾，通过像素扭曲技术提升了 ViT 在耳部识别任务上的性能和鲁棒性，为身份验证方案提供了新的可能。

Abstract: The rectangular tokens common to vision transformer methods for visual recognition can strongly affect performance of these methods due to incorporation of information outside the objects to be recognized. This paper introduces PaW-ViT, Patch-based Warping Vision Transformer, a preprocessing approach rooted in anatomical knowledge that normalizes ear images to enhance the efficacy of ViT. By accurately aligning token boundaries to detected ear feature boundaries, PaW-ViT obtains greater robustness to shape, size, and pose variation. By aligning feature boundaries to natural ear curvature, it produces more consistent token representations for various morphologies. Experiments confirm the effectiveness of PaW-ViT on various ViT models (ViT-T, ViT-S, ViT-B, ViT-L) and yield reasonable alignment robustness to variation in shape, size, and pose. Our work aims to solve the disconnect between ear biometric morphological variation and transformer architecture positional sensitivity, presenting a possible avenue for authentication schemes.

</details>


### [105] [Youtu-VL: Unleashing Visual Potential via Unified Vision-Language Supervision](https://arxiv.org/abs/2601.19798)
*Zhixiang Wei,Yi Li,Zhehan Kan,Xinghua Jiang,Zuwei Long,Shifeng Liu,Hongze Shen,Wei Liu,Xiaoyu Tan,Haojia Lin,Yubo Zhu,Qianyu Li,Di Yin,Haoyu Cao,Weibo Gu,Xin Li,Yinsong Liu,Deqiang Jiang,Xing Sun,Yunsheng Wu,Mingkong Tang,Shuangyin Liu,Lexiang Tang,Haodong Lin,Junru Lu,Jiarui Qin,Lingfeng Qiao,Ruizhi Qiao,Bo Ke,Jianfeng He,Ke Li,Yangning Li,Yunhang Shen,Mengdan Zhang,Peixian Chen,Kun Yin,Bing Liu,Yunfei Wu,Huang Chen,Zhongpeng Cai,Xiaotian Li*

Main category: cs.CV

TL;DR: Youtu-VL 提出了一种名为 VLUAS 的新训练范式，将视觉信号视为目标而非仅作为输入，以解决现有 VLM 在细粒度视觉信息保留方面的不足，从而实现更全面的多模态理解，并可直接应用于视觉中心任务。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数视觉语言模型（VLMs）在处理细粒度的视觉信息时存在局限性，导致多模态理解能力粗糙。这是由于当前的训练范式存在文本主导的优化偏见，将视觉信号视为被动的条件输入而非监督目标。

Method: 提出 Youtu-VL 框架，采用 Vision-Language Unified Autoregressive Supervision (VLUAS) 范式。该范式将优化目标从“视觉作为输入”转变为“视觉作为目标”，将视觉 tokens 直接整合到预测流中，并对视觉细节和语言内容应用统一的自回归监督。此外，该范式被扩展到视觉中心任务，使得标准 VLM 能够执行这些任务而无需额外的任务特定组件。

Result: Youtu-VL 在通用的多模态任务和视觉中心任务上都取得了具有竞争力的性能。它展示了在构建全面的通用视觉代理方面的潜力。

Conclusion: VLUAS 范式通过将视觉信号视为监督目标，能够有效提升 VLM 对细粒度视觉信息的保留能力，从而实现更强的多模态理解。Youtu-VL 框架不仅在多模态任务上表现出色，还能直接应用于视觉中心任务，为通用视觉智能体的发展奠定了坚实的基础。

Abstract: Despite the significant advancements represented by Vision-Language Models (VLMs), current architectures often exhibit limitations in retaining fine-grained visual information, leading to coarse-grained multimodal comprehension. We attribute this deficiency to a suboptimal training paradigm inherent in prevailing VLMs, which exhibits a text-dominant optimization bias by conceptualizing visual signals merely as passive conditional inputs rather than supervisory targets. To mitigate this, we introduce Youtu-VL, a framework leveraging the Vision-Language Unified Autoregressive Supervision (VLUAS) paradigm, which fundamentally shifts the optimization objective from ``vision-as-input'' to ``vision-as-target.'' By integrating visual tokens directly into the prediction stream, Youtu-VL applies unified autoregressive supervision to both visual details and linguistic content. Furthermore, we extend this paradigm to encompass vision-centric tasks, enabling a standard VLM to perform vision-centric tasks without task-specific additions. Extensive empirical evaluations demonstrate that Youtu-VL achieves competitive performance on both general multimodal tasks and vision-centric tasks, establishing a robust foundation for the development of comprehensive generalist visual agents.

</details>


### [106] [GeoDiff3D: Self-Supervised 3D Scene Generation with Geometry-Constrained 2D Diffusion Guidance](https://arxiv.org/abs/2601.19785)
*Haozhi Zhu,Miaomiao Zhao,Dingyao Liu,Runze Tian,Yan Zhang,Jie Guo,Fenggen Yu*

Main category: cs.CV

TL;DR: GeoDiff3D 提出了一种高效的自监督框架，通过利用粗糙几何体作为结构锚点，并结合几何约束的 2D 扩散模型来生成纹理丰富的参考图像，从而实现高质量、低计算成本的 3D 场景生成，解决了现有方法在结构建模和监督数据依赖方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 场景生成方法在结构建模和对大规模真实标签数据的依赖性方面存在局限，导致生成结果出现结构伪影、几何不一致和高频细节退化等问题。研究动机是开发一种更高效、更少依赖标签数据的方法来生成高质量的 3D 场景。

Method: GeoDiff3D 采用一种自监督框架，核心包括：1. 使用粗糙几何体作为结构锚点；2. 使用几何约束的 2D 扩散模型生成纹理参考图像，该模型不严格要求多视图一致性，对噪声和不一致的指导具有鲁棒性；3. 引入体素对齐的 3D 特征聚合；4. 采用双重自监督机制以保持场景连贯性和细节，同时减少对标记数据的依赖。最后，该方法在低计算成本下进行训练，并实现快速高质量的 3D 场景生成。

Result: 在挑战性场景上的大量实验表明，GeoDiff3D 相较于现有基线方法，在泛化能力和生成质量方面有所提升。该方法能够生成纹理丰富、结构连贯且细节良好的 3D 场景，并且对不一致的参考图像具有鲁棒性。

Conclusion: GeoDiff3D 提供了一种高效且易于访问的 3D 场景构建解决方案。该框架通过结合粗糙几何体、几何约束的 2D 扩散模型和自监督学习技术，有效克服了传统方法的局限性，实现了高质量、低计算成本的 3D 场景生成，并在复杂场景下展现出优越的性能和泛化能力。

Abstract: 3D scene generation is a core technology for gaming, film/VFX, and VR/AR. Growing demand for rapid iteration, high-fidelity detail, and accessible content creation has further increased interest in this area. Existing methods broadly follow two paradigms - indirect 2D-to-3D reconstruction and direct 3D generation - but both are limited by weak structural modeling and heavy reliance on large-scale ground-truth supervision, often producing structural artifacts, geometric inconsistencies, and degraded high-frequency details in complex scenes. We propose GeoDiff3D, an efficient self-supervised framework that uses coarse geometry as a structural anchor and a geometry-constrained 2D diffusion model to provide texture-rich reference images. Importantly, GeoDiff3D does not require strict multi-view consistency of the diffusion-generated references and remains robust to the resulting noisy, inconsistent guidance. We further introduce voxel-aligned 3D feature aggregation and dual self-supervision to maintain scene coherence and fine details while substantially reducing dependence on labeled data. GeoDiff3D also trains with low computational cost and enables fast, high-quality 3D scene generation. Extensive experiments on challenging scenes show improved generalization and generation quality over existing baselines, offering a practical solution for accessible and efficient 3D scene construction.

</details>


### [107] [HexFormer: Hyperbolic Vision Transformer with Exponential Map Aggregation](https://arxiv.org/abs/2601.19849)
*Haya Alyoussef,Ahmad Bdeir,Diego Coello de Portugal Mecke,Tom Hanika,Niels Landwehr,Lars Schmidt-Thieme*

Main category: cs.CV

TL;DR: 该研究提出了一种名为HexFormer的超几何视觉Transformer模型，用于图像分类。通过在注意力机制中引入指数映射聚合，HexFormer及其混合变体HexFormer-Hybrid在图像分类任务上取得了优于欧氏基线和现有超几何ViT的性能，并且在训练过程中表现出更稳定的梯度。


<details>
  <summary>Details</summary>
Motivation: 在处理图像、文本和图等跨模态数据时，其固有的层次和关系结构难以在欧氏几何中有效建模。超几何几何提供了一个更适合表示此类结构的框架。

Method: 该研究提出了两种模型：一种是纯粹的超几何ViT (HexFormer)，另一种是结合了超几何编码器和欧氏线性分类头的混合变体 (HexFormer-Hybrid)。核心创新在于其注意力机制，它基于指数映射聚合，取代了标准的基于质心的平均方法。

Result: HexFormer及其混合变体在多个数据集上均实现了比欧氏基线和先前超几何ViT模型更优异的性能，其中混合变体表现最佳。此外，研究发现超几何模型比欧氏模型具有更稳定的梯度，对学习率预热策略的敏感度更低。

Conclusion: 超几何几何能够通过提高梯度稳定性和准确性来增强视觉Transformer架构。此外，像指数映射聚合这样的相对简单的机制也能带来显著的实际效益。

Abstract: Data across modalities such as images, text, and graphs often contains hierarchical and relational structures, which are challenging to model within Euclidean geometry. Hyperbolic geometry provides a natural framework for representing such structures. Building on this property, this work introduces HexFormer, a hyperbolic vision transformer for image classification that incorporates exponential map aggregation within its attention mechanism. Two designs are explored: a hyperbolic ViT (HexFormer) and a hybrid variant (HexFormer-Hybrid) that combines a hyperbolic encoder with an Euclidean linear classification head. HexFormer incorporates a novel attention mechanism based on exponential map aggregation, which yields more accurate and stable aggregated representations than standard centroid based averaging, showing that simpler approaches retain competitive merit. Experiments across multiple datasets demonstrate consistent performance improvements over Euclidean baselines and prior hyperbolic ViTs, with the hybrid variant achieving the strongest overall results. Additionally, this study provides an analysis of gradient stability in hyperbolic transformers. The results reveal that hyperbolic models exhibit more stable gradients and reduced sensitivity to warmup strategies compared to Euclidean architectures, highlighting their robustness and efficiency in training. Overall, these findings indicate that hyperbolic geometry can enhance vision transformer architectures by improving gradient stability and accuracy. In addition, relatively simple mechanisms such as exponential map aggregation can provide strong practical benefits.

</details>


### [108] [SONIC: Spectral Oriented Neural Invariant Convolutions](https://arxiv.org/abs/2601.19884)
*Gijs Joppe Moens,Regina Beets-Tan,Eduardo H. P. Pooch*

Main category: cs.CV

TL;DR: SONIC 是一种新的卷积网络，它使用连续的光谱参数化来捕捉全局上下文和长期依赖性，同时克服了 CNN 和 ViT 的局限性，并在各种任务中表现出色，参数量少。


<details>
  <summary>Details</summary>
Motivation: 现有的卷积神经网络 (CNN) 缺乏捕捉全局上下文和长距离依赖的能力，而 Vision Transformers (ViT) 缺乏空间归纳偏置且依赖于显式的 positional encodings。研究人员希望找到一种既结构化又全局的表示来弥补这些不足。

Method: 引入了 SONIC (Spectral Oriented Neural Invariant Convolutions)，一种连续的光谱参数化方法，使用一组共享的、方向选择性的分量来建模卷积算子。这些分量能在整个频域内产生平滑的响应，从而实现全局感受野和自然适应分辨率的滤波器。

Result: 在合成基准测试、大规模图像分类和 3D 医学数据集上，SONIC 在几何变换、噪声和分辨率变化方面表现出更强的鲁棒性，并且在参数数量少一个数量级的情况下，能够与卷积、基于注意力的以及之前的谱架构相媲美或超越。

Conclusion: 连续的、方向感知的谱参数化为传统的空间和谱算子提供了一种原则性且可扩展的替代方案。

Abstract: Convolutional Neural Networks (CNNs) rely on fixed-size kernels scanning local patches, which limits their ability to capture global context or long-range dependencies without very deep architectures. Vision Transformers (ViTs), in turn, provide global connectivity but lack spatial inductive bias, depend on explicit positional encodings, and remain tied to the initial patch size. Bridging these limitations requires a representation that is both structured and global. We introduce SONIC (Spectral Oriented Neural Invariant Convolutions), a continuous spectral parameterisation that models convolutional operators using a small set of shared, orientation-selective components. These components define smooth responses across the full frequency domain, yielding global receptive fields and filters that adapt naturally across resolutions. Across synthetic benchmarks, large-scale image classification, and 3D medical datasets, SONIC shows improved robustness to geometric transformations, noise, and resolution shifts, and matches or exceeds convolutional, attention-based, and prior spectral architectures with an order of magnitude fewer parameters. These results demonstrate that continuous, orientation-aware spectral parameterisations provide a principled and scalable alternative to conventional spatial and spectral operators.

</details>


### [109] [EgoHandICL: Egocentric 3D Hand Reconstruction with In-Context Learning](https://arxiv.org/abs/2601.19850)
*Binzhu Xie,Shi Qiu,Sicheng Zhang,Yinqiao Wang,Hao Xu,Muzammal Naseer,Chi-Wing Fu,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 本文提出了一种名为EgoHandICL的框架，利用在上下文学习（ICL）来解决第一人称视角下3D手部重建的挑战，通过结合视觉-语言模型（VLMs）引导的样本检索、多模态上下文分词器和基于掩码自编码器（MAE）的架构，取得了优于现有方法的性能，并能泛化到真实世界场景。


<details>
  <summary>Details</summary>
Motivation: 第一人称视角下的3D手部重建面临深度不确定性、自遮挡和复杂手-物体交互等挑战，现有方法在未见过的场景下表现不佳，促使研究者寻求更鲁棒的解决方案。

Method: EgoHandICL框架引入了以下关键技术：1. 引入由视觉-语言模型（VLMs）引导的互补性示例检索；2. 设计了一个针对多模态上下文的ICL分词器；3. 构建了一个基于掩码自编码器（MAE）的架构，并使用手部引导的几何和感知目标进行训练。

Result: 在ARCTIC和EgoExo4D数据集上的实验表明，EgoHandICL在3D手部重建方面持续优于最先进的方法。此外，该方法在真实世界场景中表现出良好的泛化能力，并通过使用重建的手部作为视觉提示，提升了EgoVLM在手-物体交互推理方面的性能。

Conclusion: EgoHandICL是第一个用于3D手部重建的第一人称视角上下文学习框架，通过创新的方法解决了鲁棒性和泛化性问题，并在多个基准测试中取得了显著的性能提升，同时展现了其在真实世界应用和提升多模态模型理解能力方面的潜力。

Abstract: Robust 3D hand reconstruction in egocentric vision is challenging due to depth ambiguity, self-occlusion, and complex hand-object interactions. Prior methods mitigate these issues by scaling training data or adding auxiliary cues, but they often struggle in unseen contexts. We present EgoHandICL, the first in-context learning (ICL) framework for 3D hand reconstruction that improves semantic alignment, visual consistency, and robustness under challenging egocentric conditions. EgoHandICL introduces complementary exemplar retrieval guided by vision-language models (VLMs), an ICL-tailored tokenizer for multimodal context, and a masked autoencoder (MAE)-based architecture trained with hand-guided geometric and perceptual objectives. Experiments on ARCTIC and EgoExo4D show consistent gains over state-of-the-art methods. We also demonstrate real-world generalization and improve EgoVLM hand-object interaction reasoning by using reconstructed hands as visual prompts. Code and data: https://github.com/Nicous20/EgoHandICL

</details>


### [110] [DuwatBench: Bridging Language and Visual Heritage through an Arabic Calligraphy Benchmark for Multimodal Understanding](https://arxiv.org/abs/2601.19898)
*Shubham Patle,Sara Ghaboura,Hania Tariq,Mohammad Usman Khan,Omkar Thawakar,Rao Muhammad Anwer,Salman Khan*

Main category: cs.CV

TL;DR: 该研究提出了DuwatBench，一个包含1272个样本和1475个独特词汇的阿拉伯书法数据集，涵盖六种书法风格。研究评估了13种主流多模态模型在该数据集上的表现，发现它们在处理艺术化、风格化的阿拉伯书法时存在困难，并公开了数据集和评估套件以促进相关研究。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数多模态模型在处理阿拉伯语，尤其是艺术化和风格化的阿拉伯书法方面能力不足，这阻碍了阿拉伯语言和视觉遗产在人工智能系统中的公平应用。

Method: 构建了一个名为DuwatBench的数据集，包含1272个样本，涵盖六种不同的阿拉伯书法风格，并进行了句子级检测标注。然后，使用该数据集评估了13个领先的阿拉伯语和多语言多模态模型。

Result: 评估结果显示，尽管主流多模态模型在清晰文本上表现良好，但在面对书法变体、艺术性变形和精确的视觉-文本对齐时，它们的表现不佳。

Conclusion: DuwatBench数据集的公开以及对现有模型的评估结果，旨在推动基于文化背景的多模态研究，促进阿拉伯语言和视觉遗产在人工智能系统中的公平性，并支持该领域的持续进步。

Abstract: Arabic calligraphy represents one of the richest visual traditions of the Arabic language, blending linguistic meaning with artistic form. Although multimodal models have advanced across languages, their ability to process Arabic script, especially in artistic and stylized calligraphic forms, remains largely unexplored. To address this gap, we present DuwatBench, a benchmark of 1,272 curated samples containing about 1,475 unique words across six classical and modern calligraphic styles, each paired with sentence-level detection annotations. The dataset reflects real-world challenges in Arabic writing, such as complex stroke patterns, dense ligatures, and stylistic variations that often challenge standard text recognition systems. Using DuwatBench, we evaluated 13 leading Arabic and multilingual multimodal models and showed that while they perform well on clean text, they struggle with calligraphic variation, artistic distortions, and precise visual-text alignment. By publicly releasing DuwatBench and its annotations, we aim to advance culturally grounded multimodal research, foster fair inclusion of the Arabic language and visual heritage in AI systems, and support continued progress in this area. Our dataset (https://huggingface.co/datasets/MBZUAI/DuwatBench) and evaluation suit (https://github.com/mbzuai-oryx/DuwatBench) are publicly available.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [111] [Language Family Matters: Evaluating LLM-Based ASR Across Linguistic Boundaries](https://arxiv.org/abs/2601.18899)
*Yuchen Zhang,Ravi Shekhar,Haralambos Mouratidis*

Main category: cs.CL

TL;DR: 提出一种基于语言家族的连接器共享策略，用于多语言大型语言模型驱动的自动语音识别，以减少参数量并提高跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型驱动的自动语音识别系统为每种语言训练单独的连接器，忽略了语言之间的关联性，效率低下。

Method: 基于语言家族成员身份，提出一种连接器共享策略，为每个语言家族训练一个连接器，并在一类多语言大型语言模型和两个真实世界语料库上进行了实证验证。

Result: 家庭基础的连接器减少了参数数量，同时提高了跨领域泛化能力。

Conclusion: 基于语言家族的连接器共享策略是一种实用且可扩展的多语言自动语音识别部署策略。

Abstract: Large Language Model (LLM)-powered Automatic Speech Recognition (ASR) systems achieve strong performance with limited resources by linking a frozen speech encoder to a pretrained LLM via a lightweight connector. Prior work trains a separate connector per language, overlooking linguistic relatedness. We propose an efficient and novel connector-sharing strategy based on linguistic family membership, enabling one connector per family, and empirically validate its effectiveness across two multilingual LLMs and two real-world corpora spanning curated and crowd-sourced speech. Our results show that family-based connectors reduce parameter count while improving generalization across domains, offering a practical and scalable strategy for multilingual ASR deployment.

</details>


### [112] [Self-Aware Knowledge Probing: Evaluating Language Models' Relational Knowledge through Confidence Calibration](https://arxiv.org/abs/2601.18901)
*Christopher Kissling,Elena Merdjanovska,Alan Akbik*

Main category: cs.CL

TL;DR: 本研究提出了一种新的关系知识校准探测框架，用于评估语言模型（LM）的知识可靠性，发现大多数LM（特别是掩码LM）都过于自信，并且在编码语言置信度表达式的语义方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有知识探测方法仅关注预测准确性，忽略了模型置信度的校准，无法评估模型知识的可靠性。

Method: 提出了一种包含三种置信度模式（内在置信度、结构一致性和语义基础）的关系知识校准探测框架，并对十个因果LM和六个掩码LM进行了广泛分析。

Result: 大多数LM，尤其是掩码LM，表现出过度自信。考虑语句重述不一致性的置信度估计校准效果最佳。即使是最大的预训练模型，在准确编码语言置信度表达式的语义方面也存在不足。

Conclusion: 校准探测是评估LM关系知识可靠性的重要补充，显示出LM在置信度校准和语义理解方面仍有提升空间。

Abstract: Knowledge probing quantifies how much relational knowledge a language model (LM) has acquired during pre-training. Existing knowledge probes evaluate model capabilities through metrics like prediction accuracy and precision. Such evaluations fail to account for the model's reliability, reflected in the calibration of its confidence scores. In this paper, we propose a novel calibration probing framework for relational knowledge, covering three modalities of model confidence: (1) intrinsic confidence, (2) structural consistency and (3) semantic grounding. Our extensive analysis of ten causal and six masked language models reveals that most models, especially those pre-trained with the masking objective, are overconfident. The best-calibrated scores come from confidence estimates that account for inconsistencies due to statement rephrasing. Moreover, even the largest pre-trained models fail to encode the semantics of linguistic confidence expressions accurately.

</details>


### [113] [Flatter Tokens are More Valuable for Speculative Draft Model Training](https://arxiv.org/abs/2601.18902)
*Jiaming Fan,Daming Cao,Xiangzhong Luo,Jiale Fu,Chonghan Liu,Xu Yang*

Main category: cs.CL

TL;DR: 本文提出了一种数据中心的方法，通过衡量训练样本在目标模型中引起的预测分布的平坦度来优化投机解码（SD）的训练数据。该方法可以显著提高训练效率，同时保持最终模型的推理速度。


<details>
  <summary>Details</summary>
Motivation: 传统的投机解码（SD）需要训练一个草稿模型，这通常需要大量的数据，并且并非所有训练样本对SD的接受率都有同等贡献。研究者希望从数据角度出发，找到一种更有效率的训练方法。

Method: 文章通过理论分析和实证研究发现，能够引起目标模型产生更平坦预测分布的token比引起尖锐分布的token更有价值。基于此，提出了“平坦度”这一新指标来量化这种性质，并开发了基于样本级别平坦度的数据集蒸馏（SFDD）方法，该方法用于过滤训练数据，只保留最有价值的样本。

Result: 在EAGLE框架上的实验表明，SFDD可以实现超过2倍的训练速度提升，并且只使用了50%的数据。最终模型的推理速度提升与使用全量数据的基线相比，差距小于4%。

Conclusion: 这项工作提出了一种有效的数据中心方法，可以显著提高投机解码的训练效率，通过精简训练数据来达到训练加速的目的，并保持了良好的性能。

Abstract: Speculative Decoding (SD) is a key technique for accelerating Large Language Model (LLM) inference, but it typically requires training a draft model on a large dataset. We approach this problem from a data-centric perspective, finding that not all training samples contribute equally to the SD acceptance rate. Specifically, our theoretical analysis and empirical validation reveals that tokens inducing flatter predictive distributions from the target model are more valuable than those yielding sharply peaked distributions. Based on this insight, we propose flatness, a new metric to quantify this property, and develop the Sample-level-flatness-based Dataset Distillation (SFDD) approach, which filters the training data to retain only the most valuable samples. Experiments on the EAGLE framework demonstrate that SFDD can achieve over 2$\times$ training speedup using only 50% of the data, while keeping the final model's inference speedup within 4% of the full-dataset baseline. This work introduces an effective, data-centric approach that substantially improves the training efficiency for Speculative Decoding. Our code is available at https://anonymous.4open.science/r/Flatness.

</details>


### [114] [BabyReasoningBench: Generating Developmentally-Inspired Reasoning Tasks for Evaluating Baby Language Models](https://arxiv.org/abs/2601.18933)
*Kaustubh D. Dhole*

Main category: cs.CL

TL;DR: 该论文引入了一个名为BabyReasoningBench的新基准，用于评估在儿童导向数据上训练的婴儿语言模型（baby language models）的推理能力。结果显示，即使通过扩展训练数据，这些模型在理解心智（theory of mind）和涉及语用学（pragmatics）的任务上仍表现不佳，但在某些因果和物理推理任务上有所改进。


<details>
  <summary>Details</summary>
Motivation: 现有针对语言模型推理能力的评估方法主要基于成人导向的基准，这些基准假定了广泛的世界知识、复杂的指令遵循能力和成熟的语用能力。这些假设与在发展心理学角度上更具可信性的输入（如儿童导向语音和早期儿童叙事）上训练的婴儿语言模型不匹配，并且会掩盖在这些限制下（如果有的话）真正出现的推理能力。

Method: 研究引入了BabyReasoningBench，一个由GPT-5.2生成的包含19个推理任务的基准。这些任务借鉴了发展心理学的经典范式，涵盖了心智理论（theory of mind）、类比和关系推理（analogical and relational reasoning）、因果推理和干预选择（causal inference and intervention selection），以及已知会受记忆和语用学影响的核心推理原语（core reasoning primitives）。

Result: 研究发现，两个基于GPT-2的婴儿语言模型（分别在1000万和1亿个儿童导向语音文本上预训练）表现出总体较低但参差不齐的性能。模型在不同任务家族之间存在能力差异：扩展模型规模可以改善一些因果和物理推理任务，而心智归因（belief attribution）和语用学敏感型任务仍然具有挑战性。

Conclusion: BabyReasoningBench提供了一个具有发展心理学基础的视角，用于分析在儿童式训练分布下可以支持哪些类型的推理，并用于检验关于这些能力如何出现的机制性假设。

Abstract: Traditional evaluations of reasoning capabilities of language models are dominated by adult-centric benchmarks that presuppose broad world knowledge, complex instruction following, and mature pragmatic competence. These assumptions are mismatched to baby language models trained on developmentally plausible input such as child-directed speech and early-childhood narratives, and they obscure which reasoning abilities (if any) emerge under such constraints. We introduce BabyReasoningBench, a GPT-5.2 generated benchmark of 19 reasoning tasks grounded in classic paradigms from developmental psychology, spanning theory of mind, analogical and relational reasoning, causal inference and intervention selection, and core reasoning primitives that are known to be confounded by memory and pragmatics. We find that two GPT-2 based baby language models (pretrained on 10M and 100M of child-directed speech text) show overall low but uneven performance, with dissociations across task families: scaling improves several causal and physical reasoning tasks, while belief attribution and pragmatics-sensitive tasks remain challenging. BabyReasoningBench provides a developmentally grounded lens for analyzing what kinds of reasoning are supported by child-like training distributions, and for testing mechanistic hypotheses about how such abilities emerge.

</details>


### [115] [LLMs versus the Halting Problem: Revisiting Program Termination Prediction](https://arxiv.org/abs/2601.18987)
*Oren Sultan,Jordi Armengol-Estape,Pascal Kesseli,Julien Vanegue,Dafna Shahaf,Yossi Adi,Peter O'Hearn*

Main category: cs.CL

TL;DR: 研究表明，大型语言模型（LLM）在预测 C 程序终止性方面表现出色，接近顶级专用工具的性能，但它们在提供证明方面存在不足，并且在处理长程序时性能会下降。


<details>
  <summary>Details</summary>
Motivation: 由于停机问题是不可判定的，现有的自动验证工具无法普遍确定程序的终止性，并且通常依赖于特定问题和语言的架构。鉴于大型语言模型（LLM）在其他领域的成功，研究者们希望探索 LLM 是否能可靠地预测程序终止性。

Method: 使用来自国际软件验证竞赛（SV-Comp）2025 终止性类别的 C 程序数据集，评估了 GPT-5、Claude Sonnet-4.5 和 Code World Model (CWM) 等 LLM 在预测程序终止性方面的性能。

Result: GPT-5 和 Claude Sonnet-4.5 的预测性能接近 SV-Comp 2025 顶级工具的水平，CWM 则接近第二名。然而，LLM 在提供有效的终止证明方面表现不佳，并且在面对较长程序时，其性能有所下降。

Conclusion: LLM 在预测程序终止性方面显示出巨大的潜力，尽管它们在提供证明方面存在局限性，并且随着程序长度的增加而性能下降。这项工作鼓励进一步研究程序终止性以及 LLM 在解决不可判定问题方面的应用前景。

Abstract: Determining whether a program terminates is a central problem in computer science. Turing's foundational result established the Halting Problem as undecidable, showing that no algorithm can universally determine termination for all programs and inputs. Consequently, automatic verification tools approximate termination, sometimes failing to prove or disprove; these tools rely on problem-specific architectures and abstractions, and are usually tied to particular programming languages. Recent success and progress in large language models (LLMs) raises the following question: can LLMs reliably predict program termination? In this work, we evaluate LLMs on a diverse set of C programs from the Termination category of the International Competition on Software Verification (SV-Comp) 2025. Our results suggest that LLMs perform remarkably well at predicting program termination, where GPT-5 and Claude Sonnet-4.5 would rank just behind the top-ranked tool (using test-time-scaling), and Code World Model (CWM) would place just behind the second-ranked tool. While LLMs are effective at predicting program termination, they often fail to provide a valid witness as a proof. Moreover, LLMs performance drops as program length increases. We hope these insights motivate further research into program termination and the broader potential of LLMs for reasoning about undecidable problems.

</details>


### [116] [Malicious Repurposing of Open Science Artefacts by Using Large Language Models](https://arxiv.org/abs/2601.18998)
*Zahra Hashemi,Zhiqiang Zhong,Jun Pang,Wei Zhao*

Main category: cs.CL

TL;DR: 研究展示了大型语言模型（LLM）如何被用于恶意目的，通过绕过安全措施并重新利用开源研究成果来生成有害的研究提案，并指出当前LLM在评估这些风险方面存在不一致性，需要人类参与。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM在科学发现中的积极作用，但忽略了其被用于制造有害研究的可能性，尤其是利用开放科学成果进行恶意研究。

Method: 提出一个端到端的流程，包括：1. 使用基于说服的越狱技术绕过LLM的安全防护；2. 重新解读NLP论文，识别并利用其数据集、方法和工具的漏洞以实现恶意用途；3. 使用包含有害性、滥用可行性和技术健全性三个维度的评估框架来评估提案的安全性。

Result: LLM能够生成有害的研究提案，通过重新利用符合伦理的开源成果。然而，在评估这些提案时，不同的LLM（GPT-4.1, Gemini-2.5-pro, Grok-3）在评估结果上存在显著分歧，表明它们作为评估者尚不可靠。

Conclusion: LLM有潜力通过恶意重用开源成果来生成有害研究。当前的LLM在作为恶意评估的裁判时存在严重不一致性，无法提供可信的评估结果，因此，在进行双重用途风险评估时，人类的评估仍然是必不可少的。

Abstract: The rapid evolution of large language models (LLMs) has fuelled enthusiasm about their role in advancing scientific discovery, with studies exploring LLMs that autonomously generate and evaluate novel research ideas. However, little attention has been given to the possibility that such models could be exploited to produce harmful research by repurposing open science artefacts for malicious ends. We fill the gap by introducing an end-to-end pipeline that first bypasses LLM safeguards through persuasion-based jailbreaking, then reinterprets NLP papers to identify and repurpose their artefacts (datasets, methods, and tools) by exploiting their vulnerabilities, and finally assesses the safety of these proposals using our evaluation framework across three dimensions: harmfulness, feasibility of misuse, and soundness of technicality. Overall, our findings demonstrate that LLMs can generate harmful proposals by repurposing ethically designed open artefacts; however, we find that LLMs acting as evaluators strongly disagree with one another on evaluation outcomes: GPT-4.1 assigns higher scores (indicating greater potential harms, higher soundness and feasibility of misuse), Gemini-2.5-pro is markedly stricter, and Grok-3 falls between these extremes. This indicates that LLMs cannot yet serve as reliable judges in a malicious evaluation setup, making human evaluation essential for credible dual-use risk assessment.

</details>


### [117] [FROST: Filtering Reasoning Outliers with Attention for Efficient Reasoning](https://arxiv.org/abs/2601.19001)
*Haozheng Luo,Zhuolin Jiang,Md Zahid Hasan,Yan Chen,Soumalya Sarkar*

Main category: cs.CL

TL;DR: FROST 是一种新的注意力感知方法，通过剪枝不重要的推理路径来提高推理效率和准确性，显著减少了 token 使用量并提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统的推理方法效率低下且可能包含不关键的推理步骤，这导致了资源浪费和准确性下降。研究者希望开发一种更有效、更可靠的推理机制。

Method: FROST 引入了“推理异常值”的概念，并设计了一种基于注意力机制的方法来识别和移除这些异常值。通过在句子级别进行剪枝，FROST 优化了推理轨迹，使其更短、更可靠。

Result: 在四个基准测试和两个强大的推理模型（Phi-4-Reasoning 和 GPT-OSS-20B）上，FROST 取得了显著的成果。与现有技术（如 TALE 和 ThinkLess）相比，FROST 的 token 使用量平均减少了 69.68%，准确率提高了 26.70%。此外，在注意力异常值指标方面，FROST 将最大无穷范数降低了 15.97%，平均峰度降低了 91.09%。

Conclusion: FROST 能够有效提升模型的推理能力，同时通过去除句子级别的推理异常值来优化推理过程，实现了更高的效率和准确性。该方法在实际应用中表现出色，优于当前最先进的技术。

Abstract: We propose FROST, an attention-aware method for efficient reasoning. Unlike traditional approaches, FROST leverages attention weights to prune uncritical reasoning paths, yielding shorter and more reliable reasoning trajectories. Methodologically, we introduce the concept of reasoning outliers and design an attention-based mechanism to remove them. Theoretically, FROST preserves and enhances the model's reasoning capacity while eliminating outliers at the sentence level. Empirically, we validate FROST on four benchmarks using two strong reasoning models (Phi-4-Reasoning and GPT-OSS-20B), outperforming state-of-the-art methods such as TALE and ThinkLess. Notably, FROST achieves an average 69.68% reduction in token usage and a 26.70% improvement in accuracy over the base model. Furthermore, in evaluations of attention outlier metrics, FROST reduces the maximum infinity norm by 15.97% and the average kurtosis by 91.09% compared to the base model. Code is available at https://github.com/robinzixuan/FROST

</details>


### [118] [Optimizing Conversational Quality in Spoken Dialogue Systems with Reinforcement Learning from AI Feedback](https://arxiv.org/abs/2601.19063)
*Siddhant Arora,Jinchuan Tian,Jiatong Shi,Hayato Futami,Yosuke Kashiwagi,Emiru Tsunoo,Shinji Watanabe*

Main category: cs.CL

TL;DR: 本文提出了首个用于语音对话系统（SDS）的多奖励人类反馈强化学习（RLAIF）框架，解决了现有方法仅依赖单一、固定奖励的问题，并考虑了对话的语义、音频质量和情感一致性等多个维度。该框架通过回合级偏好采样和整合每块的对数概率，将回合级偏好与增量式块解码相匹配，并通过实验证明了多奖励学习比单奖励学习更能全面提升SDS的对话质量。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF/RLAIF方法在语音对话系统（SDS）中存在不足，主要体现在：1. 仅使用单一语义奖励，忽略了对话质量的多维度（语义连贯性、音频自然度、说话人一致性、情感对齐、轮次行为）和多模态特性。2. 与增量式生成响应的Duplex SDS不匹配，代理决策基于不完整的语音。因此，研究动机是为了克服这些局限性，提升SDS的整体对话质量。

Method: 提出了首个用于SDS的多奖励RLAIF框架，结合了语义、音频质量和情感一致性奖励。为了将回合级偏好与Duplex模型的增量式块解码对齐，采用了回合级偏好采样，并在单一DPO目标中聚合了每块的对数概率。对多轮Chain-of-Thought和块状Duplex模型进行了偏好学习的系统性研究，并发布了一个多奖励DPO数据集。

Result: 实验表明，单奖励RLAIF只能选择性地提升其目标指标，而联合多奖励训练能同时提高语义质量和音频自然度。这证明了整体、多奖励对齐对于实际对话SDS的重要性。

Conclusion: 为了实现具有实际应用价值的对话式SDS，需要采用全面的、多奖励的学习方法来对齐其各个方面，而不是仅关注单一指标。

Abstract: Reinforcement learning from human or AI feedback (RLHF/RLAIF) for speech-in/speech-out dialogue systems (SDS) remains underexplored, with prior work largely limited to single semantic rewards applied at the utterance level. Such setups overlook the multi-dimensional and multi-modal nature of conversational quality, which encompasses semantic coherence, audio naturalness, speaker consistency, emotion alignment, and turn-taking behavior. Moreover, they are fundamentally mismatched with duplex spoken dialogue systems that generate responses incrementally, where agents must make decisions based on partial utterances. We address these limitations with the first multi-reward RLAIF framework for SDS, combining semantic, audio-quality, and emotion-consistency rewards. To align utterance-level preferences with incremental, blockwise decoding in duplex models, we apply turn-level preference sampling and aggregate per-block log-probabilities within a single DPO objective. We present the first systematic study of preference learning for improving SDS quality in both multi-turn Chain-of-Thought and blockwise duplex models, and release a multi-reward DPO dataset to support reproducible research. Experiments show that single-reward RLAIF selectively improves its targeted metric, while joint multi-reward training yields consistent gains across semantic quality and audio naturalness. These results highlight the importance of holistic, multi-reward alignment for practical conversational SDS.

</details>


### [119] [PsyProbe: Proactive and Interpretable Dialogue through User State Modeling for Exploratory Counseling](https://arxiv.org/abs/2601.19096)
*Sohhyung Park,Hyunji Kang,Sungzoon Cho,Dongil Kim*

Main category: cs.CL

TL;DR: 本文提出了一种名为 PsyProbe 的心理健康对话系统，用于咨询的探索阶段。该系统通过 PPPPPI 框架和认知错误检测来系统地追踪用户心理状态，并能生成主动式的问题，以增强用户参与度和核心问题理解。


<details>
  <summary>Details</summary>
Motivation: 现有心理健康对话系统大多是被动响应，缺乏系统性的用户状态建模，无法进行主动的治疗性探索。研究者希望开发一个能够主动理解和引导用户心理状态的对话系统。

Method: PsyProbe 系统整合了多种模块：1) PPPPPI 框架（Presenting, Predisposing, Precipitating, Perpetuating, Protective, Impact）结合认知错误检测来追踪用户心理状态。2) State Builder 提取结构化的心理画像。3) Memory Construction 追踪信息缺口。4) Strategy Planner 用于激励访谈行为编码。5) Response Generator 包含 Question Ideation 和 Critic/Revision 模块，以生成主动式问题。

Result: 在自动评估中，完整的 PsyProbe 模型性能优于基线和消融模型。用户评估显示，与基线相比，PsyProbe 显著提高了用户的参与意愿和对话的自然度。专家评估表明，PsyProbe 极大地增进了对核心问题的理解，并且提问率与专业咨询师相当。

Conclusion: PsyProbe 系统通过系统化的状态建模和主动式提问，在治疗性探索方面是有效的，能够提升用户参与度，促进对核心问题的理解，并且在提问效率上能与专业咨询师相媲美。

Abstract: Recent advances in large language models have enabled mental health dialogue systems, yet existing approaches remain predominantly reactive, lacking systematic user state modeling for proactive therapeutic exploration. We introduce PsyProbe, a dialogue system designed for the exploration phase of counseling that systematically tracks user psychological states through the PPPPPI framework (Presenting, Predisposing, Precipitating, Perpetuating, Protective, Impact) augmented with cognitive error detection. PsyProbe combines State Builder for extracting structured psychological profiles, Memory Construction for tracking information gaps, Strategy Planner for Motivational Interviewing behavioral codes, and Response Generator with Question Ideation and Critic/Revision modules to generate contextually appropriate, proactive questions. We evaluate PsyProbe with 27 participants in real-world Korean counseling scenarios, including automatic evaluation across ablation modes, user evaluation, and expert evaluation by a certified counselor. The full PsyProbe model consistently outperforms baseline and ablation modes in automatic evaluation. User evaluation demonstrates significantly increased engagement intention and improved naturalness compared to baseline. Expert evaluation shows that PsyProbe substantially improves core issue understanding and achieves question rates comparable to professional counselors, validating the effectiveness of systematic state modeling and proactive questioning for therapeutic exploration.

</details>


### [120] [Leveraging Sentence-oriented Augmentation and Transformer-Based Architecture for Vietnamese-Bahnaric Translation](https://arxiv.org/abs/2601.19124)
*Tan Sang Nguyen,Quoc Nguyen Pham,Tho Quan*

Main category: cs.CL

TL;DR: 本文利用先进的神经机器翻译（NMT）技术并结合两种数据增强策略，来解决越南语到Bahnar语翻译的资源稀缺问题，旨在促进Bahnar语的在线传播和语言复兴。


<details>
  <summary>Details</summary>
Motivation: 为了响应政府推广和保护Bahnar语的号召，并应对Bahnar语在机器翻译领域资源匮乏的挑战，以促进其在线可访问性和跨代交流。

Method: 采用最先进的神经机器翻译（NMT）技术，并引入两种数据增强策略，应用于领域特定的越南语-Bahnar语翻译任务。这些策略灵活且易于集成，无需复杂的数据预处理、额外的模型训练或超出现有平行语料库的额外数据。

Result: 虽然未明确量化，但研究表明所提出的数据增强策略能够有效地缓解Bahnar语资源稀缺的问题，并能与现有的NMT模型协同工作，提升翻译质量。

Conclusion: 通过应用先进的NMT技术和创新的数据增强方法，可以有效克服越南语-Bahnar语翻译面临的资源限制，从而提高Bahnar语内容的在线可访问性，为该语言的复兴做出贡献。

Abstract: The Bahnar people, an ethnic minority in Vietnam with a rich ancestral heritage, possess a language of immense cultural and historical significance. The government places a strong emphasis on preserving and promoting the Bahnaric language by making it accessible online and encouraging communication across generations. Recent advancements in artificial intelligence, such as Neural Machine Translation (NMT), have brought about a transformation in translation by improving accuracy and fluency. This, in turn, contributes to the revival of the language through educational efforts, communication, and documentation. Specifically, NMT is pivotal in enhancing accessibility for Bahnaric speakers, making information and content more readily available. Nevertheless, the translation of Vietnamese into Bahnaric faces practical challenges due to resource constraints, especially given the limited resources available for the Bahnaric language. To address this, we employ state-of-the-art techniques in NMT along with two augmentation strategies for domain-specific Vietnamese-Bahnaric translation task. Importantly, both approaches are flexible and can be used with various neural machine translation models. Additionally, they do not require complex data preprocessing steps, the training of additional systems, or the acquisition of extra data beyond the existing training parallel corpora.

</details>


### [121] [Transparency-First Medical Language Models: Datasheets, Model Cards, and End-to-End Data Provenance for Clinical NLP](https://arxiv.org/abs/2601.19191)
*Olaf Yunus Laitinen Imanov,Taner Yilmaz,Ayse Tuba Tugrul,Melike Nesrin Zaman,Ozkan Gunalp,Duygu Erisken,Sila Burde Dulger,Rana Irem Turhan,Izzet Ozdemir,Derya Umut Kulali,Ozan Akbulut,Harun Demircioglu,Hasan Basri Kara,Berfin Tavan*

Main category: cs.CL

TL;DR: 本文提出TeMLM，一套针对临床语言模型的透明化发布产物，统一了来源、数据、模型和治理信息，并提供可机器检查的打包格式和审计清单。研究以合成数据集Technetium-I和ProtactiniumBERT模型为例进行了实例化，验证了其在PHI去标识化和ICD-9编码提取任务上的有效性，并强调了合成数据在工具和流程验证上的价值，但模型部署前仍需在真实数据上验证。


<details>
  <summary>Details</summary>
Motivation: 现有临床语言模型的发布缺乏标准化和透明度，阻碍了其可信度和可复用性。研究旨在通过提供一套统一、可机器检查的发布产物，提升临床语言模型的透明度和可追溯性。

Method: 提出TeMLM一套发布产物，包括TeMLM-Card、TeMLM-Datasheet和TeMLM-Provenance，并设计轻量级的一致性检查表，用于可重复审计。使用大规模合成临床NLP数据集Technetium-I和ProtactiniumBERT模型，在PHI去标识化和ICD-9编码提取任务上进行实例化和报告。

Result: 成功实例化了TeMLM产物，并报告了ProtactiniumBERT在Technetium-I数据集上的PHI去标识化（F1约为0.96）和ICD-9编码提取（平均精度约为0.79）的参考结果。验证了TeMLM在工具和流程验证方面的价值。

Conclusion: TeMLM为临床语言模型的发布提供了一个透明、可追溯且可机器检查的框架，有助于提升模型的信任度和可复用性。合成数据集在工具和流程验证方面具有重要价值，但实际部署前模型仍需在真实临床数据上进行验证。

Abstract: We introduce TeMLM, a set of transparency-first release artifacts for clinical language models. TeMLM unifies provenance, data transparency, modeling transparency, and governance into a single, machine-checkable release bundle. We define an artifact suite (TeMLM-Card, TeMLM-Datasheet, TeMLM-Provenance) and a lightweight conformance checklist for repeatable auditing. We instantiate the artifacts on Technetium-I, a large-scale synthetic clinical NLP dataset with 498,000 notes, 7.74M PHI entity annotations across 10 types, and ICD-9-CM diagnosis labels, and report reference results for ProtactiniumBERT (about 100 million parameters) on PHI de-identification (token classification) and top-50 ICD-9 code extraction (multi-label classification). We emphasize that synthetic benchmarks are valuable for tooling and process validation, but models should be validated on real clinical data prior to deployment.

</details>


### [122] [Do Images Speak Louder than Words? Investigating the Effect of Textual Misinformation in VLMs](https://arxiv.org/abs/2601.19202)
*Chi Zhang,Wenxuan Ding,Jiale Liu,Mingrui Wu,Qingyun Wu,Ray Mooney*

Main category: cs.CL

TL;DR: 本研究提出了 CONTEXT-VQA 数据集，用于评估视觉语言模型（VLMs）在面对包含与视觉证据相矛盾的文本信息时的鲁棒性。实验表明，现有的 VLM 对误导性文本提示非常脆弱，平均性能下降超过 48.2%，凸显了提高 VLM 对文本操纵鲁棒性的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注文本领域的误导信息，而对于 VLM 如何处理来自不同模态的矛盾信息的研究不足。本研究旨在填补这一空白，探索 VLM 在面对包含与视觉证据相矛盾的文本信息时的脆弱性。

Method: 1. 构建 CONTEXT-VQA 数据集，包含图像-问题对和系统生成的、故意与视觉证据相冲突的劝导性提示。 2. 设计并执行一个全面的评估框架，对多种 VLM 在冲突多模态输入下的易感性进行基准测试。

Result: 11 种最先进的 VLM 在 CONTEXT-VQA 数据集上表现出脆弱性，平均性能下降超过 48.2%。模型倾向于优先考虑与视觉证据相冲突的文本信息，而不是依赖清晰的视觉证据。

Conclusion: 当前 VLM 在处理包含误导性文本信息的输入时存在严重局限性，容易被文本操纵。未来的研究需要重点关注提高 VLM 在面对冲突多模态信息时的鲁棒性。

Abstract: Vision-Language Models (VLMs) have shown strong multimodal reasoning capabilities on Visual-Question-Answering (VQA) benchmarks. However, their robustness against textual misinformation remains under-explored. While existing research has studied the effect of misinformation in text-only domains, it is not clear how VLMs arbitrate between contradictory information from different modalities. To bridge the gap, we first propose the CONTEXT-VQA (i.e., Conflicting Text) dataset, consisting of image-question pairs together with systematically generated persuasive prompts that deliberately conflict with visual evidence. Then, a thorough evaluation framework is designed and executed to benchmark the susceptibility of various models to these conflicting multimodal inputs. Comprehensive experiments over 11 state-of-the-art VLMs reveal that these models are indeed vulnerable to misleading textual prompts, often overriding clear visual evidence in favor of the conflicting text, and show an average performance drop of over 48.2% after only one round of persuasive conversation. Our findings highlight a critical limitation in current VLMs and underscore the need for improved robustness against textual manipulation.

</details>


### [123] [How Do Transformers Learn to Associate Tokens: Gradient Leading Terms Bring Mechanistic Interpretability](https://arxiv.org/abs/2601.19208)
*Shawn Im,Changdae Oh,Zhen Fang,Sharon Li*

Main category: cs.CL

TL;DR: 本研究通过分析注意力机制语言模型的训练动态，推导出早期训练阶段Transformer权重形成过程中语义关联（如“鸟”和“飞”）的封闭形式表达式，揭示了Transformer各层权重如何基于词语搭配、词语可交换性和上下文映射等三个基本函数来学习语义关联，并通过实验验证了理论结果的有效性。


<details>
  <summary>Details</summary>
Motivation: 理解注意力机制语言模型如何学习和表征语义关联，对于连接深度学习与语言学理论、为大型语言模型奠定机制基础至关重要。

Method: 通过对梯度进行领先项近似，推导出Transformer模型在早期训练阶段权重的封闭形式表达式，并将其分解为词语搭配、词语可交换性和上下文映射三个基本函数的组合。

Result: 研究发现，Transformer的权重可以表示为三个基本函数的简单组合，这些组合反映了文本语料库的统计特性，并解释了Transformer的每个组成部分如何捕获语义关联。实验证明，理论推导出的权重特征与实际学习到的权重高度吻合。

Conclusion: 本研究提出的理论分析方法能够有效解释Transformer如何从自然语言数据中学习语义关联，并为理解和解释Transformer中的学习关联提供了新的视角。

Abstract: Semantic associations such as the link between "bird" and "flew" are foundational for language modeling as they enable models to go beyond memorization and instead generalize and generate coherent text. Understanding how these associations are learned and represented in language models is essential for connecting deep learning with linguistic theory and developing a mechanistic foundation for large language models. In this work, we analyze how these associations emerge from natural language data in attention-based language models through the lens of training dynamics. By leveraging a leading-term approximation of the gradients, we develop closed-form expressions for the weights at early stages of training that explain how semantic associations first take shape. Through our analysis, we reveal that each set of weights of the transformer has closed-form expressions as simple compositions of three basis functions (bigram, token-interchangeability, and context mappings), reflecting the statistics of the text corpus and uncovering how each component of the transformer captures semantic associations based on these compositions. Experiments on real-world LLMs demonstrate that our theoretical weight characterizations closely match the learned weights, and qualitative analyses further show how our theorem shines light on interpreting the learned associations in transformers.

</details>


### [124] [A Hybrid Supervised-LLM Pipeline for Actionable Suggestion Mining in Unstructured Customer Reviews](https://arxiv.org/abs/2601.19214)
*Aakash Trivedi,Aniket Upadhyay,Pratik Narang,Dhruv Kumar,Praveen Kumar*

Main category: cs.CL

TL;DR: 研究提出了一种结合RoBERTa分类器和指令微调LLM的混合流水线，用于从客户评论中提取、分类、聚类和总结可操作的改进建议，并在真实数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 从客户评论中提取可操作的改进建议对于企业运营决策至关重要，但现有方法在精确分离这些指令方面存在不足。

Method: 采用了一个混合流水线，首先使用RoBERTa分类器（配合精确-召回代理以减少漏报）来识别包含建议的句子，然后使用指令微调的LLM进行建议的提取、分类、聚类和总结。

Result: 该混合系统在提取准确性和聚类一致性方面优于仅使用提示、基于规则和仅使用分类器的基线方法。人类评估也证实了提取出的建议和摘要的清晰性、忠实性和可解释性。

Conclusion: 混合推理架构在细粒度可操作建议挖掘方面取得了显著的改进，但仍需解决领域适应性和高效本地部署方面的挑战。

Abstract: Extracting actionable suggestions from customer reviews is essential for operational decision-making, yet these directives are often embedded within mixed-intent, unstructured text. Existing approaches either classify suggestion-bearing sentences or generate high-level summaries, but rarely isolate the precise improvement instructions businesses need. We evaluate a hybrid pipeline combining a high-recall RoBERTa classifier trained with a precision-recall surrogate to reduce unrecoverable false negatives with a controlled, instruction-tuned LLM for suggestion extraction, categorization, clustering, and summarization. Across real-world hospitality and food datasets, the hybrid system outperforms prompt-only, rule-based, and classifier-only baselines in extraction accuracy and cluster coherence. Human evaluations further confirm that the resulting suggestions and summaries are clear, faithful, and interpretable. Overall, our results show that hybrid reasoning architectures achieve meaningful improvements fine-grained actionable suggestion mining while highlighting challenges in domain adaptation and efficient local deployment.

</details>


### [125] [DREAMSTATE: Diffusing States and Parameters for Recurrent Large Language Models](https://arxiv.org/abs/2601.19221)
*Liu Xiao*

Main category: cs.CL

TL;DR: 该研究提出了DREAMSTATE框架，利用Diffusion Transformer（DiT）来建模和编辑RWKV等RNN的内部状态，揭示了其作为可编辑知识表示的潜力，并构建了一种结合RNN局部优势和DiT全局适应性的混合架构，实现了上下文感知的动态循环机制。


<details>
  <summary>Details</summary>
Motivation: 现有研究对RWKV等RNN内部状态作为可编辑知识表示的探索不足，作者旨在填补这一研究空白，并利用RNN的固定大小状态优势与Transformer的全局建模能力相结合。

Method: 1. 提出DREAMSTATE框架，使用条件Diffusion Transformer（DiT）直接建模RWKV状态的概率流形，实现状态生成和编辑。2. 验证了状态表示的结构性（通过t-SNE可视化和受控生成实验）。3. 设计了一种混合架构，将DiT并行处理可变长度的全局上下文，动态生成和调整循环模块的WKV参数，使固定循环机制变为上下文感知的动态函数。4. 通过多目标损失函数稳定训练混合模型。

Result: 1. 证明了RWKV状态具有结构化的表示潜力，DREAMSTATE框架能够有效建模和编辑这些状态。2. 构建的混合架构在实验中表现出稳定的训练特性，验证了其设计可行性。

Conclusion: 该研究为RNN状态表示开辟了新的研究方向，并提供了一个将RNN局部建模能力与DiT全局上下文适应性相结合的具体架构设计参考，有望推动未来模型设计的发展。

Abstract: Modern Recurrent Neural Networks (RNNs), such as RWKV, are distinguished by their powerful short-range modeling capabilities and efficient fixed-size states, which constitute a core advantage over standard Transformers. However, there is a significant lack of research into their internal state as an editable knowledge representation. To fill this gap, we first explore the representational properties of the RWKV state by proposing the DREAMSTATE framework. This framework utilizes a conditional Diffusion Transformer (DiT) to directly model the probability manifold of the state, enabling its generation and editing. The structural nature of this representation is validated through t-SNE visualizations and controlled generation experiments. After successfully uncovering and modeling the state's representational potential, we further propose a novel hybrid architecture that combines the local advantages of RNNs with global context adaptability. This architecture features a parallel DiT that processes a variable-length global context to dynamically generate and adjust the core recurrent module's WKV parameters, transforming the fixed recurrence mechanism into a context-aware dynamic function. Experiments demonstrate that this hybrid model can be trained stably via a multi-objective loss, validating its design feasibility. Our work not only opens a new research direction for RNN state representation but also provides a concrete architectural reference for future model design. The code is publicly available at: https://huggingface.co/2dgx41s/DreamState.

</details>


### [126] [RPO-RAG: Aligning Small LLMs with Relation-aware Preference Optimization for Knowledge Graph Question Answering](https://arxiv.org/abs/2601.19225)
*Kaehyun Um,KyuHwan Yeom,Haerim Yang,Minyoung Choi,Hyeongjun Yang,Kyong-Ho Lee*

Main category: cs.CL

TL;DR: 本文提出了一种名为 RPO-RAG 的新型知识图谱（KG）增强检索问答（RAG）框架，专门用于提升小型语言模型（LLM）在知识密集型任务上的表现。RPO-RAG 通过语义感知的路径采样、关系感知的偏好优化以及以答案为中心的提示设计，有效解决了现有 KG-RAG 方法的不足，并显著提高了小型 LLM 的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于 KG 的 RAG 方法在路径采样和与 KG 推理目标的对齐方面存在不足，限制了小型 LLM 的性能提升。同时，这些方法通常依赖大型 LLM 或参数量大于 7B 的模型，忽视了小型模型在此类任务上的潜力。因此，研究的动机是开发一种专门针对小型 LLM 的 KG-RAG 框架，以弥合小型与大型模型之间的性能差距。

Method: RPO-RAG 框架包含三个主要创新：1. 查询-路径语义采样策略，提供信息丰富的监督信号；2. 关系感知的偏好优化，使训练与中间 KG 推理信号（如关系）对齐；3. 以答案为中心的提示设计，以可解释的格式组织实体和推理路径。

Result: 在 WebQSP 和 CWQ 两个 KGQA 数据集上的实验表明，RPO-RAG 显著提升了小型 LLM 的性能。在 WebQSP 上，F1 分数提高了 8.8%，提高了答案的精确度。在 CWQ 上，在参数量低于 8B 的模型中取得了新的最先进成果（Hit 和 F1）。

Conclusion: RPO-RAG 是首个专门为小型 LLM 设计的 KG-RAG 框架，它通过创新的语义采样、偏好优化和提示设计，有效提升了小型 LLM 的推理能力，甚至在参数量低于 3B 的模型上也能展现出显著潜力，为资源受限场景下的实用 KGQA 应用提供了可能。

Abstract: Large Language Models (LLMs) have recently demonstrated remarkable reasoning abilities, yet hallucinate on knowledge-intensive tasks. Retrieval-augmented generation (RAG) mitigates this issue by grounding answers in external sources, e.g., knowledge graphs (KGs). However, existing KG-based RAG approaches rely on semantics-unaware path sampling and are weakly aligned with KG reasoning objectives, which limits further accuracy gains. They also feed retrieved paths directly into the reasoner without organizing them into answer-centered reasoning paths, hindering small LLMs' ability to leverage the retrieved knowledge. Furthermore, prior works predominantly rely on large LLMs (e.g., ChatGPT/GPT-4) or assume backbones above 7B parameters, leaving sub-7B models underexplored. We address this gap with RPO-RAG, the first KG-based RAG framework specifically designed for small LLMs, to the best of our knowledge. RPO-RAG introduces three key innovations: (1) a query-path semantic sampling strategy that provides informative supervisory signals; (2) a relation-aware preference optimization that aligns training with intermediate KG reasoning signals (e.g., relation); and (3) an answer-centered prompt design that organizes entities and reasoning paths in an interpretable format. Extensive experiments on two benchmark Knowledge Graph Question Answering (KGQA) datasets, WebQSP and CWQ, demonstrate that RPO-RAG effectively bridges the performance gap between small and large language models. On WebQSP, it improves F1 by up to 8.8%, reflecting enhanced answer precision, while on CWQ it achieves new state-of-the-art results among models under 8B parameters in both Hit and F1. Overall, RPO-RAG substantially improves the reasoning capability of small LLMs, even under 3B parameters-highlighting their potential for resource-efficient and practical on-device KGQA applications.

</details>


### [127] [DiaDem: Advancing Dialogue Descriptions in Audiovisual Video Captioning for Multimodal Large Language Models](https://arxiv.org/abs/2601.19267)
*Xinlong Chen,Weihong Lin,Jingyun Hua,Linli Yao,Yue Ding,Bozhou Li,Bohan Zeng,Yang Shi,Qiang Liu,Yuanxing Zhang,Pengfei Wan,Liang Wang,Tieniu Tan*

Main category: cs.CL

TL;DR: 本文提出了DiaDem模型，用于生成包含更精确对话描述的视听视频字幕，并通过DiaDemBench基准对模型进行评估，结果显示DiaDem在对话描述方面优于Gemini系列。


<details>
  <summary>Details</summary>
Motivation: 现有的视听视频字幕模型在生成准确的对话描述方面存在不足，影响了下游任务的表现。

Method: 提出DiaDem模型，通过合成高质量数据集进行监督微调（SFT），并采用难度划分的两阶段近端策略（GRPO）来增强对话描述能力。同时，引入DiaDemBench基准用于评估模型在对话场景下的表现。

Result: DiaDem在对话描述准确性方面优于Gemini系列模型，并在通用视听视频字幕基准上取得了具有竞争力的性能。DiaDemBench的实验表明，即使是商业模型在对话感知字幕生成方面仍有提升空间。

Conclusion: DiaDem模型能够生成包含更精确对话描述的视听视频字幕，并在对话描述能力和整体性能上均表现出色。DiaDemBench是一个有效的评估工具，揭示了当前模型在对话感知字幕方面的局限性。

Abstract: Accurate dialogue description in audiovisual video captioning is crucial for downstream understanding and generation tasks. However, existing models generally struggle to produce faithful dialogue descriptions within audiovisual captions. To mitigate this limitation, we propose DiaDem, a powerful audiovisual video captioning model capable of generating captions with more precise dialogue descriptions while maintaining strong overall performance. We first synthesize a high-quality dataset for SFT, then employ a difficulty-partitioned two-stage GRPO strategy to further enhance dialogue descriptions. To enable systematic evaluation of dialogue description capabilities, we introduce DiaDemBench, a comprehensive benchmark designed to evaluate models across diverse dialogue scenarios, emphasizing both speaker attribution accuracy and utterance transcription fidelity in audiovisual captions. Extensive experiments on DiaDemBench reveal even commercial models still exhibit substantial room for improvement in dialogue-aware captioning. Notably, DiaDem not only outperforms the Gemini series in dialogue description accuracy but also achieves competitive performance on general audiovisual captioning benchmarks, demonstrating its overall effectiveness.

</details>


### [128] [Riddle Quest : The Enigma of Words](https://arxiv.org/abs/2601.19273)
*Niharika Sri Parasa,Chaitali Diwan,Srinath Srinivasa*

Main category: cs.CL

TL;DR: 本文提出了一种生成和评估类比谜语的流水线，并利用该系统研究大型语言模型（LLMs）在理解谜语时的推理覆盖范围和歧义处理能力。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在处理具有间接、比喻或玩味线索的语言谜题时的推理能力，特别是它们能否识别出所有可能的答案，以及其在理解覆盖范围和歧义处理方面的局限性。

Method: 构建了一个包括三元组创建器、语义映射器、风格化生成器和验证器在内的流水线。该流水线首先从结构化事实中提取概念属性，然后将这些属性转化为比喻性谜语线索，最后通过验证器收集所有可能的答案，以评估LLMs能否找回所有答案。

Result: 实验结果表明，尽管LLMs通常能够猜出谜语的主要答案，但它们常常忽略其他同样有效的解释。这意味着LLMs在推理覆盖范围和歧义处理方面存在不足。

Conclusion: 谜语是一种有效的轻量级工具，可以用来检查语言模型在推理覆盖范围和歧义处理方面的能力。通过分析模型在解决谜语时遗漏的答案，可以揭示其理解的局限性。

Abstract: Riddles are concise linguistic puzzles that describe an object or idea through indirect, figurative, or playful clues. They are a longstanding form of creative expression, requiring the solver to interpret hints, recognize patterns, and draw inferences to identify the answers. In this work, we introduce a simple pipeline for creating and evaluating analogy-based riddles. The system includes a triples creator that builds structured facts about a concept, a semantic mapper that selects attributes useful for analogy, a stylized generator that turns them into riddle clues, and a validator that collects all possible answers the riddle could point to. We use this validator to study whether large language models can recover the full answer set for different riddle types. Our case study shows that while models often guess the main intended answer, they frequently miss other valid interpretations. This highlights the value of riddles as a lightweight tool for examining reasoning coverage and ambiguity handling in language models.

</details>


### [129] [DART: Diffusion-Inspired Speculative Decoding for Fast LLM Inference](https://arxiv.org/abs/2601.19278)
*Fuliang Liu,Xue Li,Ketai Zhao,Yinxi Gao,Ziyan Zhou,Zhonghui Zhang,Zhibin Wang,Wanchun Dou,Sheng Zhong,Chen Tian*

Main category: cs.CL

TL;DR: DART是一种新的生成模型，它通过并行生成来加速LLM推理，比现有方法快30%以上。


<details>
  <summary>Details</summary>
Motivation: 现有的基于模型的草稿生成方法（如EAGLE3）在提高准确性的同时，引入了多步自回归推理，导致草稿阶段延迟高，成为性能瓶颈。

Method: DART受dLLMs启发，利用并行生成技术，在一次前向传播中基于目标模型的隐藏状态预测多个未来掩码位置的logit。在此基础上，DART采用了一种高效的树剪枝算法，通过N-gram强制语义连续性来构建高质量的草稿令牌树。

Result: DART显著降低了草稿阶段的开销，同时保持了高草稿准确性，从而大幅提高了端到端解码速度。实验表明，DART在多个数据集上实现了2.03倍到3.44倍的时钟时间加速，平均比EAGLE3快30%。

Conclusion: DART是一种高效的、实用的投机解码框架，它通过并行生成和优化的树剪枝算法，成功解决了现有方法的延迟问题，实现了显著的速度提升。

Abstract: Speculative decoding is an effective and lossless approach for accelerating LLM inference. However, existing widely adopted model-based draft designs, such as EAGLE3, improve accuracy at the cost of multi-step autoregressive inference, resulting in high drafting latency and ultimately rendering the drafting stage itself a performance bottleneck. Inspired by diffusion-based large language models (dLLMs), we propose DART, which leverages parallel generation to reduce drafting latency. DART predicts logits for multiple future masked positions in parallel within a single forward pass based on hidden states of the target model, thereby eliminating autoregressive rollouts in the draft model while preserving a lightweight design. Based on these parallel logit predictions, we further introduce an efficient tree pruning algorithm that constructs high-quality draft token trees with N-gram-enforced semantic continuity. DART substantially reduces draft-stage overhead while preserving high draft accuracy, leading to significantly improved end-to-end decoding speed. Experimental results demonstrate that DART achieves a 2.03x--3.44x wall-clock time speedup across multiple datasets, surpassing EAGLE3 by 30% on average and offering a practical speculative decoding framework. Code is released at https://github.com/fvliang/DART.

</details>


### [130] [ReToP: Learning to Rewrite Electronic Health Records for Clinical Prediction](https://arxiv.org/abs/2601.19286)
*Jesus Lovon-Melgarejo,Jose G. Moreno,Christine Damase-Michel,Lynda Tamine*

Main category: cs.CL

TL;DR: 提出了一种名为ReToP的基于LLM的框架，通过端到端训练EHR改写器和临床预测器，将LLM的通用医学知识与具体预测任务相结合，以提高临床预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的EHR分析方法通常将LLM作为独立的编码器或完成模块，未充分整合预测任务信号，导致临床预测性能受限。

Method: 提出ReToP框架，包含一个EHR改写器和一个临床预测器，并通过端到端训练进行优化。为解决缺乏EHR改写训练数据的问题，利用临床驱动的特征选择策略生成合成伪标签，创建用于微调改写器的多样化患者改写。引入Classifier Supervised Contribution (CSC)分数，使EHR改写器生成与预测目标一致、具有临床意义的改写。

Result: ReToP在MIMIC-IV数据集的三个临床任务上超越了强基线模型。此外，ReToP在泛化性方面表现良好，能够通过少量微调适应新数据集和任务，同时保持改写内容的忠实性并突出与任务相关的预测特征。

Conclusion: ReToP框架通过端到端集成LLM的改写能力和预测任务，有效克服了现有方法的局限性，显著提升了临床预测的准确性，并展现了良好的泛化能力。

Abstract: Electronic Health Records (EHRs) provide crucial information for clinical decision-making. However, their high-dimensionality, heterogeneity, and sparsity make clinical prediction challenging. Large Language Models (LLMs) allowed progress towards addressing this challenge by leveraging parametric medical knowledge to enhance EHR data for clinical prediction tasks. Despite the significant achievements made so far, most of the existing approaches are fundamentally task-agnostic in the sense that they deploy LLMs as EHR encoders or EHR completion modules without fully integrating signals from the prediction tasks. This naturally hinders task performance accuracy. In this work, we propose Rewrite-To-Predict (ReToP), an LLM-based framework that addresses this limitation through an end-to-end training of an EHR rewriter and a clinical predictor. To cope with the lack of EHR rewrite training data, we generate synthetic pseudo-labels using clinical-driven feature selection strategies to create diverse patient rewrites for fine-tuning the EHR rewriter. ReToP aligns the rewriter with prediction objectives using a novel Classifier Supervised Contribution (CSC) score that enables the EHR rewriter to generate clinically relevant rewrites that directly enhance prediction. Our ReToP framework surpasses strong baseline models across three clinical tasks on MIMIC-IV. Moreover, the analysis of ReToP shows its generalizability to unseen datasets and tasks with minimal fine-tuning while preserving faithful rewrites and emphasizing task-relevant predictive features.

</details>


### [131] [MetaGen: Self-Evolving Roles and Topologies for Multi-Agent LLM Reasoning](https://arxiv.org/abs/2601.19290)
*Yimeng Wang,Jiaxing Zhao,Hongbin Xie,Hexing Ma,Yuzhen Lei,Shuangxue Liu,Xuan Song,Zichen Zhang,Haoran Zhang*

Main category: cs.CL

TL;DR: MetaGen是一个无需训练的框架，可以在推理时动态调整大型语言模型多代理系统中角色库和交互拓扑，以提高任务匹配度和适应性，同时降低成本。


<details>
  <summary>Details</summary>
Motivation: 现有的多代理系统通常依赖固定的角色库和交互拓扑，这会导致任务不匹配、无法及时适应新证据以及推理成本过高。

Method: MetaGen通过生成和重写查询条件下的角色规范来动态调整角色池，并构建一个围绕最小骨干的受限执行图。在执行过程中，它利用轻量级反馈信号迭代更新角色提示和调整结构决策。

Result: 在代码生成和多步推理基准测试中，MetaGen在准确性和成本权衡方面优于现有的多代理基线方法。

Conclusion: MetaGen通过在推理时动态适应角色和拓扑，能够有效地提高大型语言模型多代理系统的性能和效率。

Abstract: Large language models are increasingly deployed as multi-agent systems, where specialized roles communicate and collaborate through structured interactions to solve complex tasks that often exceed the capacity of a single agent. However, most existing systems still rely on a fixed role library and an execution-frozen interaction topology, a rigid design choice that frequently leads to task mismatch, prevents timely adaptation when new evidence emerges during reasoning, and further inflates inference cost. We introduce MetaGen, a training-free framework that adapts both the role space and the collaboration topology at inference time, without updating base model weights. MetaGen generates and rewrites query-conditioned role specifications to maintain a controllable dynamic role pool, then instantiates a constrained execution graph around a minimal backbone. During execution, it iteratively updates role prompts and adjusts structural decisions using lightweight feedback signals. Experiments on code generation and multi-step reasoning benchmarks show that MetaGen improves the accuracy and cost tradeoff over strong multi-agent baselines.

</details>


### [132] [Formula-One Prompting: Adaptive Reasoning Through Equations For Applied Mathematics](https://arxiv.org/abs/2601.19302)
*Natapong Nitarach,Pittawat Taveekitworachai,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: Formula-One Prompting (F-1) 是一种新的两阶段提示技术，它首先生成数学方程，然后根据方程选择推理策略（CoT、PoT 或直接计算），在数学推理任务中优于 CoT 和 PoT，尤其在金融、物理和密码学等应用领域。


<details>
  <summary>Details</summary>
Motivation: 现有的 CoT 和 PoT 技术在数学推理中有所改进，但未能显式利用求解过程中的关键步骤——回忆或推导控制方程，这在金融、物理和密码学等应用领域尤为重要。

Method: F-1 是一种两阶段提示方法。第一阶段，它通过 LLM 从问题描述中生成控制方程。第二阶段，根据生成的方程，LLM 自适应地选择一个求解策略，可以是 Chain-of-Thought (CoT)、Program-of-Thought (PoT) 或直接计算，所有这些都在一次 LLM 调用中完成。

Result: 在五个模型和四个基准测试中的实验表明，F-1 平均比 CoT 提高 5.76%，比 PoT 提高 8.42%。F-1 在应用领域（如 FinanceMath）的收益尤其显著，比 CoT 提高了 13.30%。在 OlympiadBench 上，F-1 在物理问题上的提升（+2.55%）也大于纯数学问题（+0.44%）。

Conclusion: F-1 是一种有效的数学推理方法，它通过将数学方程作为中间表示，并根据方程自适应地选择求解策略，从而在应用数学问题上比 CoT 和 PoT 取得了更好的性能。

Abstract: Prompting techniques such as Chain-of-Thought (CoT) and Program-of-Thought (PoT) improve LLM mathematical reasoning by structuring intermediate steps in natural language or code. However, applied mathematics problems in domains like finance, physics, and cryptography often require recalling or deriving governing equations, a step that current approaches do not explicitly leverage. We propose Formula-One Prompting (F-1), a two-phase approach that uses mathematical equations as an intermediate representation before adaptive solving. F-1 first formulates governing equations from problem descriptions, then selects a solving strategy among CoT, PoT, or direct computation based on the generated equations, all within a single LLM call. Results across five models and four benchmarks show F-1 outperforms CoT by +5.76% and PoT by +8.42% on average. Crucially, gains are largest in applied domains: +13.30% on FinanceMath over CoT, and within OlympiadBench, larger gains on physics (+2.55%) than pure math (+0.44%). This demonstrates that F-1 is more effective than CoT in applied mathematics problems.

</details>


### [133] [When Benchmarks Leak: Inference-Time Decontamination for LLMs](https://arxiv.org/abs/2601.19334)
*Jianzhe Chai,Yu Zhe,Jun Sakuma*

Main category: cs.CL

TL;DR: 本文提出了一种名为DeconIEP的评估框架，通过在输入嵌入空间中应用小的、有界的扰动来解决大规模语言模型（LLMs）基准测试中的测试集污染问题，该框架能在不显著影响模型正常性能的情况下有效去除污染。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估依赖基准测试，但测试集污染（测试样本或其变体出现在训练数据中）导致性能虚高，降低了评估的可靠性。

Method: DeconIEP在评估阶段运行，通过在输入嵌入空间引入微小、有界的扰动。它利用一个相对未被污染的参考模型来指导一个实例自适应的扰动生成器，从而引导被评估模型避开依赖记忆的捷径。

Result: 在多个开源LLM和基准测试上的广泛实验表明，DeconIEP能够有效地进行去污，同时对模型正常效用造成的性能下降非常小。

Conclusion: DeconIEP是一种有效的评估框架，可以在不显著损害模型在干净输入上的性能的情况下，解决LLM基准测试中的测试集污染问题。

Abstract: Benchmark-based evaluation is the de facto standard for comparing large language models (LLMs). However, its reliability is increasingly threatened by test set contamination, where test samples or their close variants leak into training data and artificially inflate reported performance. To address this issue, prior work has explored two main lines of mitigation. One line attempts to identify and remove contaminated benchmark items before evaluation, but this inevitably alters the evaluation set itself and becomes unreliable when contamination is moderate or severe. The other line preserves the benchmark and instead suppresses contaminated behavior at evaluation time; however, such interventions often interfere with normal inference and lead to noticeable performance degradation on clean inputs. We propose DeconIEP, a decontamination framework that operates entirely during evaluation by applying small, bounded perturbations in the input embedding space. Guided by a relatively less-contaminated reference model, DeconIEP learns an instance-adaptive perturbation generator that steers the evaluated model away from memorization-driven shortcut pathways. Across multiple open-weight LLMs and benchmarks, extensive empirical results show that DeconIEP achieves strong decontamination effectiveness while incurring only minimal degradation in benign utility.

</details>


### [134] [Cross-Examination Framework: A Task-Agnostic Diagnostic for Information Fidelity in Text-to-Text Generation](https://arxiv.org/abs/2601.19350)
*Tathagata Raha,Clement Christophe,Nada Saadi,Hamza A Javed,Marco AF Pimentel,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.CL

TL;DR: 提出了一种名为跨考框架（CEF）的参考无关、多维度文本生成评估方法，通过生成和交叉检验问题来衡量文本的覆盖度、一致性和忠实度，弥补了BLEU和BERTScore等传统指标在语义保真度上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统文本生成评估指标（如BLEU和BERTScore）在评估生成文本的语义保真度方面存在局限性，无法有效捕捉到内容遗漏和事实矛盾等关键错误。

Method: 将跨考框架（CEF）应用于文本生成评估，将源文本和候选文本视为独立的知识库，生成可验证的问题，并通过交叉检验来计算覆盖度、一致性和忠实度三个维度得分。此外，还进行了系统性的鲁棒性分析以选择稳定的评判模型，并验证了参考无关模式与参考模式之间的一致性。

Result: CEF在机器翻译、文本摘要和临床笔记生成等任务上表现出色，能够识别出传统指标容易忽略的内容遗漏和事实矛盾。CEF的参考无关模式与参考模式之间存在强相关性，表明其评估的可靠性。人工专家验证表明，CEF发现的匹配错误与语义改变错误高度相关，尤其擅长识别实体和关系层面的偏差。

Conclusion: CEF是一种有效的、参考无关的多维度文本评估框架，能够更准确地评估文本生成的语义保真度，尤其在识别内容遗漏、事实矛盾和实体关系错误方面优于现有指标。

Abstract: Traditional metrics like BLEU and BERTScore fail to capture semantic fidelity in generative text-to-text tasks. We adapt the Cross-Examination Framework (CEF) for a reference-free, multi-dimensional evaluation by treating the source and candidate as independent knowledge bases. CEF generates verifiable questions from each text and performs a cross-examination to derive three interpretable scores: Coverage, Conformity, and Consistency. Validated across translation, summarization and clinical note-generation, our framework identifies critical errors, such as content omissions and factual contradictions, missed by standard metrics. A key contribution is a systematic robustness analysis to select a stable judge model. Crucially, the strong correlation between our reference-free and with-reference modes validates CEF's reliability without gold references. Furthermore, human expert validation demonstrates that CEF mismatching questions align with meaning-altering semantic errors higher than with non-semantic errors, particularly excelling at identifying entity-based and relational distortions.

</details>


### [135] [Binary Token-Level Classification with DeBERTa for All-Type MWE Identification: A Lightweight Approach with Linguistic Enhancement](https://arxiv.org/abs/2601.19360)
*Diego Rossini,Lonneke van der Plas*

Main category: cs.CL

TL;DR: 该研究提出了一种结合二元词元级分类、语言特征和数据增强的多词表达式（MWE）识别方法，并在CoAM数据集上取得了优于大型语言模型（LLM）的性能，参数量却少得多。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多词表达式（MWE）识别任务上表现不如大型语言模型（LLM），但LLM参数量巨大，不适合资源受限的场景。研究旨在开发一种参数量小但性能优越的MWE识别方法。

Method: 将MWE识别重构为二元词元级START/END/INSIDE分类；整合了名词短语（NP）分块和依存特征；采用了过采样技术来处理训练数据中的类别不平衡问题。

Result: 在CoAM数据集上，提出的DeBERTa-v3-large模型达到了69.8%的F1分数，比最佳LLM（Qwen-72B，57.8% F1）高出12个百分点，但参数量少了165倍。在STREUSLE数据集上，F1分数为78.9%。

Conclusion: 精心设计的小型模型在结构化自然语言处理任务上可以显著优于大型语言模型，这对于资源受限的部署具有重要意义。

Abstract: We present a comprehensive approach for multiword expression (MWE) identification that combines binary token-level classification, linguistic feature integration, and data augmentation. Our DeBERTa-v3-large model achieves 69.8% F1 on the CoAM dataset, surpassing the best results (Qwen-72B, 57.8% F1) on this dataset by 12 points while using 165x fewer parameters. We achieve this performance by (1) reformulating detection as binary token-level START/END/INSIDE classification rather than span-based prediction, (2) incorporating NP chunking and dependency features that help discontinuous and NOUN-type MWEs identification, and (3) applying oversampling that addresses severe class imbalance in the training data. We confirm the generalization of our method on the STREUSLE dataset, achieving 78.9% F1. These results demonstrate that carefully designed smaller models can substantially outperform LLMs on structured NLP tasks, with important implications for resource-constrained deployments.

</details>


### [136] [Do LLMs Truly Benefit from Longer Context in Automatic Post-Editing?](https://arxiv.org/abs/2601.19410)
*Ahrii Kim,Seong-heum Kim*

Main category: cs.CL

TL;DR: 研究比较了专有和开源大语言模型（LLM）在文档级自动后编辑（APE）方面的表现，发现专有LLM在简单提示下表现接近人类水平，但对文档上下文的利用不足；开源LLM在利用上下文方面表现更好，但整体质量较低。两者都存在自动评估指标不可靠的问题。专有LLM的成本和延迟限制了其实际应用。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在机器翻译方面表现出色，但其在文档级自动后编辑（APE）方面的能力，特别是如何利用文档上下文进行纠错，仍需深入研究和理解。

Method: 本研究系统性地比较了专有和开源LLM在文档级APE任务下的表现，采用简单的单次提示（one-shot prompting）设置。评估指标包括APE质量、上下文利用情况、鲁棒性（如数据投毒攻击）和效率（成本、延迟）。

Result: 专有LLM在单次提示下取得了接近人类水平的APE质量，无论是否提供文档上下文。它们对数据投毒攻击的鲁棒性高于开源LLM，但也因此表现出难以利用文档上下文进行纠错的局限性。自动评估指标（如BLEU）未能准确反映LLM在APE质量上的提升。专有LLM存在显著的成本和延迟问题。

Conclusion: LLM在文档级APE方面展现出巨大潜力，但现有模型（尤其是专有模型）在有效利用文档上下文进行纠错方面仍有待提高。同时，需要开发更高效的长上下文建模方法来实现实际的翻译后编辑部署。人类评估对于准确衡量APE质量仍然至关重要。

Abstract: Automatic post-editing (APE) aims to refine machine translations by correcting residual errors. Although recent large language models (LLMs) demonstrate strong translation capabilities, their effectiveness for APE--especially under document-level context--remains insufficiently understood. We present a systematic comparison of proprietary and open-weight LLMs under a naive document-level prompting setup, analyzing APE quality, contextual behavior, robustness, and efficiency.
  Our results show that proprietary LLMs achieve near human-level APE quality even with simple one-shot prompting, regardless of whether document context is provided. While these models exhibit higher robustness to data poisoning attacks than open-weight counterparts, this robustness also reveals a limitation: they largely fail to exploit document-level context for contextual error correction. Furthermore, standard automatic metrics do not reliably reflect these qualitative improvements, highlighting the continued necessity of human evaluation. Despite their strong performance, the substantial cost and latency overheads of proprietary LLMs render them impractical for real-world APE deployment. Overall, our findings elucidate both the promise and current limitations of LLM-based document-aware APE, and point toward the need for more efficient long-context modeling approaches for translation refinement.

</details>


### [137] [KG-CRAFT: Knowledge Graph-based Contrastive Reasoning with LLMs for Enhancing Automated Fact-checking](https://arxiv.org/abs/2601.19447)
*Vítor N. Lourenço,Aline Paes,Tillman Weyde,Audrey Depeige,Mohnish Dubey*

Main category: cs.CL

TL;DR: 该研究提出了一种名为 KG-CRAFT 的新方法，通过利用知识图谱生成的对比问题来增强大型语言模型（LLMs）的自动事实核查能力。


<details>
  <summary>Details</summary>
Motivation: 自动事实核查是自动化事实核查系统的关键组成部分，旨在评估声明的真实性。现有的方法在利用证据方面仍有改进空间。

Method: KG-CRAFT首先从声明和报告构建知识图谱，然后基于知识图谱结构生成对比问题。这些问题用于指导证据提取和报告合成，最终 LLMs 利用这些简洁的摘要进行事实核查。

Result: 在 LIAR-RAW 和 RAWFC 两个真实世界数据集上的评估表明，KG-CRAFT 达到了新的最先进的预测性能。

Conclusion: 基于知识图谱的对比推理方法能够有效提升 LLMs 的事实核查能力。

Abstract: Claim verification is a core component of automated fact-checking systems, aimed at determining the truthfulness of a statement by assessing it against reliable evidence sources such as documents or knowledge bases. This work presents KG-CRAFT, a method that improves automatic claim verification by leveraging large language models (LLMs) augmented with contrastive questions grounded in a knowledge graph. KG-CRAFT first constructs a knowledge graph from claims and associated reports, then formulates contextually relevant contrastive questions based on the knowledge graph structure. These questions guide the distillation of evidence-based reports, which are synthesised into a concise summary that is used for veracity assessment by LLMs. Extensive evaluations on two real-world datasets (LIAR-RAW and RAWFC) demonstrate that our method achieves a new state-of-the-art in predictive performance. Comprehensive analyses validate in detail the effectiveness of our knowledge graph-based contrastive reasoning approach in improving LLMs' fact-checking capabilities.

</details>


### [138] [Dynamic Multi-Expert Projectors with Stabilized Routing for Multilingual Speech Recognition](https://arxiv.org/abs/2601.19451)
*Isha Pandey,Ashish Mittal,Vartul Bahuguna,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 本文提出了一种名为 SMEAR-MoE 的稳定版专家混合（MoE）投影器，用于解决基于 LLM 的多语言语音识别（ASR）中的单投影器泛化能力不足的问题，并在四种印度语言上取得了显著的词错误率（WER）降低。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 LLM 的 ASR 方法在多语言场景下，单一投影器难以适应不同语言的声学-语义映射，导致性能下降。

Method: 提出了一种稳定的专家混合（MoE）投影器（SMEAR-MoE），该方法通过确保所有专家都有密集的梯度流来防止专家崩溃，并促进跨语言共享。在四种印度语言（印地语、马拉地语、泰米尔语、泰卢固语）上与单投影器、静态多投影器设计进行了比较。

Result: SMEAR-MoE 相对单投影器基线，在词错误率（WER）上取得了高达 7.6% 的相对降低，同时保持了可比的运行时效率。专家路由分析显示出语言学上的有意义的专业化，相关语言共享专家。

Conclusion: 稳定的多专家投影器是实现可扩展和鲁棒的多语言 ASR 的关键。

Abstract: Recent advances in LLM-based ASR connect frozen speech encoders with Large Language Models (LLMs) via lightweight projectors. While effective in monolingual settings, a single projector struggles to capture the diverse acoustic-to-semantic mappings required for multilingual ASR. To address this, we propose SMEAR-MoE, a stabilized Mixture-of-Experts projector that ensures dense gradient flow to all experts, preventing expert collapse while enabling cross-lingual sharing. We systematically compare monolithic, static multi-projector, and dynamic MoE designs across four Indic languages (Hindi, Marathi, Tamil, Telugu). Our SMEAR-MoE achieves strong performance, delivering upto a 7.6% relative WER reduction over the single-projector baseline, while maintaining comparable runtime efficiency. Analysis of expert routing further shows linguistically meaningful specialization, with related languages sharing experts. These results demonstrate that stable multi-expert projectors are key to scalable and robust multilingual ASR.

</details>


### [139] [ClaimPT: A Portuguese Dataset of Annotated Claims in News Articles](https://arxiv.org/abs/2601.19490)
*Ricardo Campos,Raquel Sequeira,Sara Nerea,Inês Cantante,Diogo Folques,Luís Filipe Cunha,João Canavilhas,António Branco,Alípio Jorge,Sérgio Nunes,Nuno Guimarães,Purificação Silvano*

Main category: cs.CL

TL;DR: 该研究发布了一个名为ClaimPT的新型欧洲葡萄牙语新闻文章事实声称数据集，旨在促进低资源语言的事实核查研究，并提供了基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前事实核查任务耗时且难以规模化，尤其是在葡萄牙语等资源匮乏的语言中，缺乏可用数据集阻碍了相关研究和应用的发展。自动化事实核查，特别是声称识别，是解决这一问题的关键。

Method: 研究人员与葡萄牙通讯社LUSA合作，收集了1,308篇欧洲葡萄牙语新闻文章，并由两名标注员根据新提出的标注方案对文章中的事实声称进行了标注，由一名策展人进行验证，最终形成包含6,875个标注的数据集ClaimPT。此外，研究还提供了用于声称检测的基线模型。

Result: 成功构建并发布了ClaimPT数据集，该数据集专注于新闻内容，并且提供了针对声称检测的基线模型性能。

Conclusion: ClaimPT数据集的发布将有助于推动低资源语言的事实核查研究，并促进对新闻媒体中虚假信息理解的加深，为未来的自然语言处理和信息检索应用奠定基础。

Abstract: Fact-checking remains a demanding and time-consuming task, still largely dependent on manual verification and unable to match the rapid spread of misinformation online. This is particularly important because debunking false information typically takes longer to reach consumers than the misinformation itself; accelerating corrections through automation can therefore help counter it more effectively. Although many organizations perform manual fact-checking, this approach is difficult to scale given the growing volume of digital content. These limitations have motivated interest in automating fact-checking, where identifying claims is a crucial first step. However, progress has been uneven across languages, with English dominating due to abundant annotated data. Portuguese, like other languages, still lacks accessible, licensed datasets, limiting research, NLP developments and applications. In this paper, we introduce ClaimPT, a dataset of European Portuguese news articles annotated for factual claims, comprising 1,308 articles and 6,875 individual annotations. Unlike most existing resources based on social media or parliamentary transcripts, ClaimPT focuses on journalistic content, collected through a partnership with LUSA, the Portuguese News Agency. To ensure annotation quality, two trained annotators labeled each article, with a curator validating all annotations according to a newly proposed scheme. We also provide baseline models for claim detection, establishing initial benchmarks and enabling future NLP and IR applications. By releasing ClaimPT, we aim to advance research on low-resource fact-checking and enhance understanding of misinformation in news media.

</details>


### [140] [GradPruner: Gradient-Guided Layer Pruning Enabling Efficient Fine-Tuning and Inference for LLMs](https://arxiv.org/abs/2601.19503)
*Wei Huang,Anda Cheng,Yinggui Wang*

Main category: cs.CL

TL;DR: GradPruner 是一种在 LLM 微调早期通过梯度进行结构化剪枝的方法，能够在减少 40% 参数的同时，仅损失 0.99% 的准确率，从而提高训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 传统的 LLM 微调耗时且昂贵，而结构化剪枝方法虽然提高推理效率，但通常需要额外的训练、知识蒸馏等策略，使得高效模型微调仍然是一个挑战。本研究旨在同时提高下游任务微调的训练和推理效率。

Method: GradPruner 在微调早期，利用参数在初始阶段累积的梯度信息，计算初始梯度信息累积矩阵 (IGIA-Matrix) 来评估层的重要性并进行剪枝。剪枝后的层根据 IGIA-Matrix 进行稀疏化，并与剩余层合并。合并时只保留符号相同的元素，以减少符号变化带来的干扰。

Result: 在两个 LLM 和八个包括医疗、金融和通用基准任务的下游数据集上进行了广泛实验。结果表明，GradPruner 实现了 40% 的参数缩减，准确率仅下降 0.99%。

Conclusion: GradPruner 是一种有效的方法，可以在 LLM 下游任务微调早期，通过梯度信息实现高效的结构化剪枝，显著提高训练和推理效率，同时保持高准确率。

Abstract: Fine-tuning Large Language Models (LLMs) with downstream data is often considered time-consuming and expensive. Structured pruning methods are primarily employed to improve the inference efficiency of pre-trained models. Meanwhile, they often require additional time and memory for training, knowledge distillation, structure search, and other strategies, making efficient model fine-tuning challenging to achieve. To simultaneously enhance the training and inference efficiency of downstream task fine-tuning, we introduce GradPruner, which can prune layers of LLMs guided by gradients in the early stages of fine-tuning. GradPruner uses the cumulative gradients of each parameter during the initial phase of fine-tuning to compute the Initial Gradient Information Accumulation Matrix (IGIA-Matrix) to assess the importance of layers and perform pruning. We sparsify the pruned layers based on the IGIA-Matrix and merge them with the remaining layers. Only elements with the same sign are merged to reduce interference from sign variations. We conducted extensive experiments on two LLMs across eight downstream datasets. Including medical, financial, and general benchmark tasks. The results demonstrate that GradPruner has achieved a parameter reduction of 40% with only a 0.99% decrease in accuracy. Our code is publicly available.

</details>


### [141] [Automated Safety Benchmarking: A Multi-agent Pipeline for LVLMs](https://arxiv.org/abs/2601.19507)
*Xiangyang Zhu,Yuan Tian,Zicheng Zhang,Qi Jia,Chunyi Li,Renrui Zhang,Heng Li,Zongrui Wang,Wei Sun*

Main category: cs.CL

TL;DR: 本文提出了VLSafetyBencher，一个自动化系统，用于解决现有大型视觉语言模型（LVLM）安全评估基准构建成本高、效率低和区分度不足的问题。该系统通过四个协作代理自动生成和筛选高质量的安全测试样本，并在短时间内以较低成本有效地区分了不同模型的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（LVLM）安全评估基准存在构建成本高、过程繁琐、缺乏动态适应性和区分度不足等问题，无法跟上模型发展的步伐并有效应对新兴风险。因此，需要一种更高效、更具成本效益且能够生成高质量、高区分度安全评估数据的系统。

Method: 提出了一种名为VLSafetyBencher的自动化系统，该系统包含数据预处理、生成、增强和选择四个协作代理，共同负责构建和筛选高质量的LVLM安全评估样本。

Result: 实验证明，VLSafetyBencher可以在一周内以极低的成本构建出高质量的安全评估基准。该基准能够有效地区分不同模型的安全性，最安全和最不安全模型之间的安全率差异高达70%。

Conclusion: VLSafetyBencher是一种首创的自动化LVLM安全基准测试系统，它克服了现有方法的局限性，能够高效、低成本地生成具有高区分度的安全评估数据，从而更好地评估和提升LVLM的安全性。

Abstract: Large vision-language models (LVLMs) exhibit remarkable capabilities in cross-modal tasks but face significant safety challenges, which undermine their reliability in real-world applications. Efforts have been made to build LVLM safety evaluation benchmarks to uncover their vulnerability. However, existing benchmarks are hindered by their labor-intensive construction process, static complexity, and limited discriminative power. Thus, they may fail to keep pace with rapidly evolving models and emerging risks. To address these limitations, we propose VLSafetyBencher, the first automated system for LVLM safety benchmarking. VLSafetyBencher introduces four collaborative agents: Data Preprocessing, Generation, Augmentation, and Selection agents to construct and select high-quality samples. Experiments validates that VLSafetyBencher can construct high-quality safety benchmarks within one week at a minimal cost. The generated benchmark effectively distinguish safety, with a safety rate disparity of 70% between the most and least safe models.

</details>


### [142] [Yunque DeepResearch Technical Report](https://arxiv.org/abs/2601.19578)
*Yuxuan Cai,Xinyi Lai,Peng Yuan,Weiting Liu,Huajian Li,Mingda Li,Xinghua Wang,Shengxie Zheng,Yanchao Hao,Yuyang Yin,Zheng Wei*

Main category: cs.CL

TL;DR: 提出了一种名为 Yunque DeepResearch 的分层、模块化和鲁棒的框架，用于解决大型语言模型在执行长周期任务时遇到的上下文噪声、级联错误和扩展性差的问题。该框架包含多代理编排系统、动态上下文管理和主动监控模块，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的深度研究方法在处理长周期任务时存在上下文噪声、易出错和缺乏模块化扩展性的问题，阻碍了自主代理的潜力。

Method: Yunque DeepResearch 框架包含三个核心组件：1. 中心化多代理编排系统，用于将子任务分配给工具和专用子代理组成的原子能力池；2. 动态上下文管理机制，通过将已完成的子目标结构化为语义摘要来缓解信息过载；3. 主动监控模块，通过主动异常检测和上下文剪枝来确保系统的韧性。

Result: Yunque DeepResearch 在 GAIA、BrowseComp、BrowseComp-ZH 和 Humanity's Last Exam 等代理深度研究基准测试中取得了最先进的性能。

Conclusion: Yunque DeepResearch 框架通过其分层、模块化和鲁棒的设计，成功解决了当前深度研究方法面临的挑战，并在多个代理研究任务中展现出卓越的性能。该框架已开源，以促进社区的研究和应用。

Abstract: Deep research has emerged as a transformative capability for autonomous agents, empowering Large Language Models to navigate complex, open-ended tasks. However, realizing its full potential is hindered by critical limitations, including escalating contextual noise in long-horizon tasks, fragility leading to cascading errors, and a lack of modular extensibility. To address these challenges, we introduce Yunque DeepResearch, a hierarchical, modular, and robust framework. The architecture is characterized by three key components: (1) a centralized Multi-Agent Orchestration System that routes subtasks to an Atomic Capability Pool of tools and specialized sub-agents; (2) a Dynamic Context Management mechanism that structures completed sub-goals into semantic summaries to mitigate information overload; and (3) a proactive Supervisor Module that ensures resilience through active anomaly detection and context pruning. Yunque DeepResearch achieves state-of-the-art performance across a range of agentic deep research benchmarks, including GAIA, BrowseComp, BrowseComp-ZH, and Humanity's Last Exam. We open-source the framework, reproducible implementations, and application cases to empower the community.

</details>


### [143] [Decompose-and-Formalise: Recursively Verifiable Natural Language Inference](https://arxiv.org/abs/2601.19605)
*Xin Quan,Marco Valentino,Louise A. Dennis,André Freitas*

Main category: cs.CL

TL;DR: 提出了一种分解-形式化框架，用于改进大型语言模型与定理证明器结合的自然语言推理解释。该框架通过将NLI问题分解为原子步骤的推理树，自底向上验证，并进行局部诊断引导的细化，从而提高了解释验证率，同时减少了细化迭代和运行时间。


<details>
  <summary>Details</summary>
Motivation: 当前将大型语言模型与定理证明器集成的方法在处理自然语言推理时存在扩展性差、易受局部错误影响以及故障排除成本高昂的问题。为了解决这些挑战，需要一种更有效的方法来处理长而复杂的输入，并快速定位和修复错误。

Method: 该研究提出了一种分解-形式化框架，包括三个主要步骤：1. 将前提-假设对分解为原子步骤的推理树；2. 自底向上验证推理树，以将失败定位到特定节点；3. 进行局部诊断引导的细化，而非全局重新生成。此外，引入了基于事件的逻辑形式中的 θ-substitution 来提高自动形式化的忠实度。

Result: 在使用了五种不同大型语言模型骨干的推理任务上，该方法实现了最高的解释验证率，比现有技术水平提高了 26.2%、21.7%、21.6% 和 48.9%。同时，该方法减少了细化迭代和运行时间，并保持了强大的自然语言推理准确性。

Conclusion: 所提出的分解-形式化框架有效地解决了当前大型语言模型与定理证明器集成在自然语言推理中的挑战，通过局部化错误并进行诊断引导的细化，显著提高了解释的验证率和效率，同时保持了推理的准确性。

Abstract: Recent work has shown that integrating large language models (LLMs) with theorem provers (TPs) in neuro-symbolic pipelines helps with entailment verification and proof-guided refinement of explanations for natural language inference (NLI). However, scaling such refinement to naturalistic NLI remains difficult: long, syntactically rich inputs and deep multi-step arguments amplify autoformalisation errors, where a single local mismatch can invalidate the proof. Moreover, current methods often handle failures via costly global regeneration due to the difficulty of localising the responsible span or step from prover diagnostics. Aiming to address these problems, we propose a decompose-and-formalise framework that (i) decomposes premise-hypothesis pairs into an entailment tree of atomic steps, (ii) verifies the tree bottom-up to isolate failures to specific nodes, and (iii) performs local diagnostic-guided refinement instead of regenerating the whole explanation. Moreover, to improve faithfulness of autoformalisation, we introduce $θ$-substitution in an event-based logical form to enforce consistent argument-role bindings. Across a range of reasoning tasks using five LLM backbones, our method achieves the highest explanation verification rates, improving over the state-of-the-art by 26.2%, 21.7%, 21.6% and 48.9%, while reducing refinement iterations and runtime and preserving strong NLI accuracy.

</details>


### [144] [Up to 36x Speedup: Mask-based Parallel Inference Paradigm for Key Information Extraction in MLLMs](https://arxiv.org/abs/2601.19613)
*Xinzhong Wang,Ya Guo,Jing Li,Huan Chen,Yi Tu,Yijie Hong,Gongshen Liu,Huijia Zhu*

Main category: cs.CL

TL;DR: 提出了一种名为PIP（Parallel Inference Paradigm）的新方法，用于解决视觉丰富文档（VrDs）的关键信息提取（KIE）任务中的效率瓶颈问题。PIP通过使用掩码（"[mask]"）占位符并进行并行推理，实现了比传统自回归模型快3-36倍的推理速度，同时性能损失可忽略不计。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）和多模态大型语言模型（MLLMs）在KIE任务中表现出潜力，但其自回归推理方式（逐个生成输出）效率低下，尤其是在需要提取多个独立字段时。研究旨在克服这一效率瓶颈。

Method: 引入了PIP（Parallel Inference Paradigm），将KIE问题重构为使用"[mask]"令牌作为所有目标值的占位符，从而实现单次前向传播的并行生成。为此，开发了定制的掩码预训练策略，并构建了大规模监督数据集。

Result: PIP模型在实验中实现了3-36倍的推理速度提升，同时性能几乎没有下降。与传统的自回归基线模型相比，在效率和准确性上都取得了显著优势。

Conclusion: PIP方法通过并行推理有效解决了KIE任务的效率问题，为实现可扩展、实用的KIE解决方案铺平了道路，同时保持了高准确性。

Abstract: Key Information Extraction (KIE) from visually-rich documents (VrDs) is a critical task, for which recent Large Language Models (LLMs) and Multi-Modal Large Language Models (MLLMs) have demonstrated strong potential. However, their reliance on autoregressive inference, which generates outputs sequentially, creates a significant efficiency bottleneck, especially as KIE tasks often involve extracting multiple, semantically independent fields. To overcome this limitation, we introduce PIP: a Parallel Inference Paradigm for KIE. Our approach reformulates the problem by using "[mask]" tokens as placeholders for all target values, enabling their simultaneous generation in a single forward pass. To facilitate this paradigm, we develop a tailored mask pre-training strategy and construct large-scale supervised datasets. Experimental results show that our PIP-models achieve a 5-36x inference speedup with negligible performance degradation compared to traditional autoregressive base models. By substantially improving efficiency while maintaining high accuracy, PIP paves the way for scalable and practical real-world KIE solutions.

</details>


### [145] [RATE: Reviewer Profiling and Annotation-free Training for Expertise Ranking in Peer Review Systems](https://arxiv.org/abs/2601.19637)
*Weicong Liu,Zixuan Yang,Yibo Zhao,Xiang Li*

Main category: cs.CL

TL;DR: 该研究提出了一个名为 LR-bench 的新基准，用于评估大型语言模型（LLM）时代的审稿人分配，并引入了一个名为 RATE 的审稿人匹配框架，该框架通过提取近期出版物的关键词特征并进行弱监督微调，实现了最新的审稿人匹配性能。


<details>
  <summary>Details</summary>
Motivation: 在 LLM 时代，研究主题变化迅速，现有基准已过时，代理信号难以准确反映审稿人的专业知识，导致审稿人分配成为一个关键且充满挑战的问题。

Method: 构建了一个名为 LR-bench 的高保真、最新的基准，包含 2024-2025 年的 AI/NLP 手稿，并通过大规模电子邮件调查收集了五级自我评估的熟悉度评分，生成了 1055 个专家注释的论文-审稿人-评分标注。提出了 RATE 框架，通过将审稿人近期的出版物提炼成基于关键词的紧凑型特征，并利用弱偏好监督（由启发式检索信号构建）对嵌入模型进行微调，从而能够直接将手稿与审稿人特征进行匹配。

Result: 在 LR-bench 和 CMU 金标准数据集上，所提出的 RATE 方法在审稿人匹配任务上持续 achieves state-of-the-art 性能，显著优于强大的嵌入基线。

Conclusion: LR-bench 和 RATE 框架能够有效地解决 LLM 时代审稿人分配的挑战，提供了更准确和最新的审稿人匹配解决方案，并已开源供社区使用。

Abstract: Reviewer assignment is increasingly critical yet challenging in the LLM era, where rapid topic shifts render many pre-2023 benchmarks outdated and where proxy signals poorly reflect true reviewer familiarity. We address this evaluation bottleneck by introducing LR-bench, a high-fidelity, up-to-date benchmark curated from 2024-2025 AI/NLP manuscripts with five-level self-assessed familiarity ratings collected via a large-scale email survey, yielding 1055 expert-annotated paper-reviewer-score annotations. We further propose RATE, a reviewer-centric ranking framework that distills each reviewer's recent publications into compact keyword-based profiles and fine-tunes an embedding model with weak preference supervision constructed from heuristic retrieval signals, enabling matching each manuscript against a reviewer profile directly. Across LR-bench and the CMU gold-standard dataset, our approach consistently achieves state-of-the-art performance, outperforming strong embedding baselines by a clear margin. We release LR-bench at https://huggingface.co/datasets/Gnociew/LR-bench, and a GitHub repository at https://github.com/Gnociew/RATE-Reviewer-Assign.

</details>


### [146] [One Token Is Enough: Improving Diffusion Language Models with a Sink Token](https://arxiv.org/abs/2601.19657)
*Zihou Zhang,Zheyong Xie,Li Zhong,Haifeng Liu,Shaosheng Cao*

Main category: cs.CL

TL;DR: 本文提出了一种简单的额外 Sink Token 方法来解决 Diffusion Language Models (DLMs) 中的移动 Sink 现象，通过修改注意力掩码实现，实验表明该方法能够稳定注意力 Sink 并显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: DLMs 存在移动 Sink 现象，这种现象源于 Sink Token 在 Transformer 值空间中表示的低范数，其不可预测的位置会影响推理的鲁棒性。

Method: 通过修改注意力掩码引入一个特殊的额外 Sink Token，该 Token 被约束为只能关注自身，同时对所有其他 Token 可见。实验评估了该方法的有效性。

Result: 引入一个额外的 Sink Token 稳定了注意力 Sink，并显著提升了 DLMs 的模型性能。该 Token 的有效性与其位置无关，且语义内容可忽略不计。

Conclusion: 额外的 Sink Token 是一种稳定 DLMs 注意力 Sink 的有效且鲁棒的方法，可以作为一种结构化的 Sink 独立于模型的语义内容来工作，从而解决移动 Sink 现象并提高模型性能。

Abstract: Diffusion Language Models (DLMs) have emerged as a compelling alternative to autoregressive approaches, enabling parallel text generation with competitive performance. Despite these advantages, there is a critical instability in DLMs: the moving sink phenomenon. Our analysis indicates that sink tokens exhibit low-norm representations in the Transformer's value space, and that the moving sink phenomenon serves as a protective mechanism in DLMs to prevent excessive information mixing. However, their unpredictable positions across diffusion steps undermine inference robustness. To resolve this, we propose a simple but effective extra sink token implemented via a modified attention mask. Specifically, we introduce a special token constrained to attend solely to itself, while remaining globally visible to all other tokens. Experimental results demonstrate that introducing a single extra token stabilizes attention sinks, substantially improving model performance. Crucially, further analysis confirms that the effectiveness of this token is independent of its position and characterized by negligible semantic content, validating its role as a robust and dedicated structural sink.

</details>


### [147] [SynCABEL: Synthetic Contextualized Augmentation for Biomedical Entity Linking](https://arxiv.org/abs/2601.19667)
*Adam Remaki,Christel Gérardin,Eulàlia Farré-Maduell,Martin Krallinger,Xavier Tannier*

Main category: cs.CL

TL;DR: SynCABEL是一个利用大型语言模型生成合成训练数据来解决生物医学实体链接（BEL）中数据稀缺问题的框架，并在多项基准测试中取得了最先进的性能，同时显著减少了对人工标注数据的依赖，并通过LLM-as-a-judge方法证明了其临床有效性。


<details>
  <summary>Details</summary>
Motivation: 监督式生物医学实体链接（BEL）面临训练数据不足的瓶颈，手动标注成本高昂且耗时。

Method: 利用大型语言模型（LLMs）为目标知识库中的所有候选概念生成包含丰富上下文的合成训练样本，实现广泛的监督。结合了decoder-only模型和引导推理。引入了LLM-as-a-judge协议进行临床有效性评估。

Result: SynCABEL在MedMentions（英语）、QUAERO（法语）和SPACCC（西班牙语）三个多语言基准测试中建立了新的最先进结果。在数据效率方面，SynCABEL使用少60%的标注数据即可达到完全人工监督的性能。LLM-as-a-judge评估显示，SynCABEL显著提高了临床有效预测的比例。

Conclusion: SynCABEL框架有效地缓解了生物医学实体链接中的数据稀缺问题，通过生成合成数据显著提高了模型性能和数据效率，并能生成临床上有效的预测，降低了对昂贵人工标注的依赖。

Abstract: We present SynCABEL (Synthetic Contextualized Augmentation for Biomedical Entity Linking), a framework that addresses a central bottleneck in supervised biomedical entity linking (BEL): the scarcity of expert-annotated training data. SynCABEL leverages large language models to generate context-rich synthetic training examples for all candidate concepts in a target knowledge base, providing broad supervision without manual annotation. We demonstrate that SynCABEL, when combined with decoder-only models and guided inference establish new state-of-the-art results across three widely used multilingual benchmarks: MedMentions for English, QUAERO for French, and SPACCC for Spanish. Evaluating data efficiency, we show that SynCABEL reaches the performance of full human supervision using up to 60% less annotated data, substantially reducing reliance on labor-intensive and costly expert labeling. Finally, acknowledging that standard evaluation based on exact code matching often underestimates clinically valid predictions due to ontology redundancy, we introduce an LLM-as-a-judge protocol. This analysis reveals that SynCABEL significantly improves the rate of clinically valid predictions. Our synthetic datasets, models, and code are released to support reproducibility and future research.

</details>


### [148] [Component-Level Lesioning of Language Models Reveals Clinically Aligned Aphasia Phenotypes](https://arxiv.org/abs/2601.19723)
*Yifan Wang,Jichen Zheng,Jingyuan Sun,Yunhao Zhang,Chunyu Ye,Jixing Li,Chengqing Zong,Shaonan Wang*

Main category: cs.CL

TL;DR: 本研究提出了一种利用大型语言模型（LLMs）模拟失语症（aphasia）的方法，通过有选择地扰动模型的特定组件来复制失语症患者的语言产出障碍。该方法可以作为测试康复假设的代理工具，并提供一个研究语言功能组织的框架。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型展现出类人的语言行为和内部表征，可以作为计算模拟语言认知的工具。研究者希望探索是否可以通过系统性地操纵LLMs来复制由局部脑损伤引起的失语症语言产出障碍，从而为测试康复假说提供可扩展的代理模型，并为探究语言的功能组织提供一个受控的框架。

Method: 研究者提出了一个基于临床的、组件层面的框架，通过选择性地扰动LLMs的功能组件来模拟失语症。该框架应用于模块化的Mixture-of-Experts（MoE）模型和密集的Transformer模型，并使用统一的干预接口。其流程包括：(i)识别与Broca's和Wernicke's失语症相关的组件；(ii)使用语言探测任务解释这些组件；(iii)通过逐步扰动top-k的亚型相关组件来诱导分级损伤；(iv)使用Western Aphasia Battery（WAB）子测验评估结果，并用Aphasia Quotient（AQ）进行总结。

Result: 在不同架构和损伤策略下，针对亚型的扰动比随机扰动能产生更系统、更像失语症的语言退化。MoE模型的模块化特性支持更局部化、更可解释的表型到组件的映射。

Conclusion: 研究表明，模块化的LLMs结合临床指导的组件扰动，为模拟失语症语言产出和研究不同语言功能在特定干扰下的退化提供了一个有前景的平台。

Abstract: Large language models (LLMs) increasingly exhibit human-like linguistic behaviors and internal representations that they could serve as computational simulators of language cognition. We ask whether LLMs can be systematically manipulated to reproduce language-production impairments characteristic of aphasia following focal brain lesions. Such models could provide scalable proxies for testing rehabilitation hypotheses, and offer a controlled framework for probing the functional organization of language. We introduce a clinically grounded, component-level framework that simulates aphasia by selectively perturbing functional components in LLMs, and apply it to both modular Mixture-of-Experts models and dense Transformers using a unified intervention interface. Our pipeline (i) identifies subtype-linked components for Broca's and Wernicke's aphasia, (ii) interprets these components with linguistic probing tasks, and (iii) induces graded impairments by progressively perturbing the top-k subtype-linked components, evaluating outcomes with Western Aphasia Battery (WAB) subtests summarized by Aphasia Quotient (AQ). Across architectures and lesioning strategies, subtype-targeted perturbations yield more systematic, aphasia-like regressions than size-matched random perturbations, and MoE modularity supports more localized and interpretable phenotype-to-component mappings. These findings suggest that modular LLMs, combined with clinically informed component perturbations, provide a promising platform for simulating aphasic language production and studying how distinct language functions degrade under targeted disruptions.

</details>


### [149] [TokenSeek: Memory Efficient Fine Tuning via Instance-Aware Token Ditching](https://arxiv.org/abs/2601.19739)
*Runjia Zeng,Qifan Wang,Qiang Guan,Ruixiang Tang,Lifu Huang,Zhenting Wang,Xueling Zhang,Cheng Han,Dongfang Liu*

Main category: cs.CL

TL;DR: TokenSeek 是一种创新的方法，通过感知实例的 token 选择和丢弃，显著减少了大型语言模型（LLM）微调时的内存消耗（Llama3.2 1B 仅需 14.8% 的内存），同时保持甚至提升了性能，并提供了对 token 效率研究的见解。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）微调方法，虽然有效，但内存消耗巨大，导致效率低下。现有的内存优化方法（尤其是激活优化）虽然有效，但缺乏数据感知性，导致微调效果不佳且不稳定。

Method: 提出了一种名为 TokenSeek 的通用插件解决方案，适用于各种 Transformer 模型。该方法通过“实例感知”（instance-aware）的 token 搜索和丢弃机制来减少计算量。具体而言，它能智能地选择对当前实例重要的 token，并丢弃不相关的 token，从而降低内存占用。

Result: TokenSeek 在 Llama3.2 1B 模型上实现了显著的内存节省，仅需原始内存的 14.8%。在保持或提高模型性能的同时，实现了内存效率的提升。此外，其 token 搜索过程具有可解释性。

Conclusion: TokenSeek 是一种有效的、通用的 LLM 微调内存优化方法，通过实例感知的 token 选择策略，在显著降低内存占用的同时，能够保持或提升模型性能。其可解释性为未来的 token 效率研究提供了有价值的见解。

Abstract: Fine tuning has been regarded as a de facto approach for adapting large language models (LLMs) to downstream tasks, but the high training memory consumption inherited from LLMs makes this process inefficient. Among existing memory efficient approaches, activation-related optimization has proven particularly effective, as activations consistently dominate overall memory consumption. Although prior arts offer various activation optimization strategies, their data-agnostic nature ultimately results in ineffective and unstable fine tuning. In this paper, we propose TokenSeek, a universal plugin solution for various transformer-based models through instance-aware token seeking and ditching, achieving significant fine-tuning memory savings (e.g., requiring only 14.8% of the memory on Llama3.2 1B) with on-par or even better performance. Furthermore, our interpretable token seeking process reveals the underlying reasons for its effectiveness, offering valuable insights for future research on token efficiency. Homepage: https://runjia.tech/iclr_tokenseek/

</details>


### [150] [Strong Reasoning Isn't Enough: Evaluating Evidence Elicitation in Interactive Diagnosis](https://arxiv.org/abs/2601.19773)
*Zhuohan Long,Zhijie Bao,Zhongyu Wei*

Main category: cs.CL

TL;DR: 本研究提出了一个用于评估交互式医疗咨询代理的信息收集能力的框架 EviMed，并提出了一种名为 REFINE 的策略来提高代理的信息收集效率。


<details>
  <summary>Details</summary>
Motivation: 现有医疗咨询代理的评估方法主要关注静态或最终结果，忽略了证据收集过程。研究人员希望开发一种能够衡量和改进代理在交互式咨询中收集证据能力的方法。

Method: 提出了一种交互式评估框架，使用模拟患者和基于原子证据的模拟报告者来模拟咨询过程。引入信息覆盖率 (ICR) 指标来量化代理收集必要证据的程度。构建了一个名为 EviMed 的基于证据的基准测试集。提出了一种名为 REFINE 的策略，该策略利用诊断验证来指导代理主动解决不确定性。

Result: 评估了10种模型，发现强大的诊断推理能力并不保证有效的证据收集，并且信息收集不足是交互式场景下的主要瓶颈。REFINE 策略在各种数据集上持续优于基线方法，并能促进模型协作，使小型代理在强推理监督下取得更好的性能。

Conclusion: EviMed 框架和 REFINE 策略能够有效地评估和改进交互式医疗咨询代理的信息收集能力，表明主动解决不确定性是提高模型在交互式环境中性能的关键。

Abstract: Interactive medical consultation requires an agent to proactively elicit missing clinical evidence under uncertainty. Yet existing evaluations largely remain static or outcome-centric, neglecting the evidence-gathering process. In this work, we propose an interactive evaluation framework that explicitly models the consultation process using a simulated patient and a \rev{simulated reporter} grounded in atomic evidences. Based on this representation, we introduce Information Coverage Rate (ICR) to quantify how completely an agent uncovers necessary evidence during interaction. To support systematic study, we build EviMed, an evidence-based benchmark spanning diverse conditions from common complaints to rare diseases, and evaluate 10 models with varying reasoning abilities. We find that strong diagnostic reasoning does not guarantee effective information collection, and this insufficiency acts as a primary bottleneck limiting performance in interactive settings. To address this, we propose REFINE, a strategy that leverages diagnostic verification to guide the agent in proactively resolving uncertainties. Extensive experiments demonstrate that REFINE consistently outperforms baselines across diverse datasets and facilitates effective model collaboration, enabling smaller agents to achieve superior performance under strong reasoning supervision. Our code can be found at https://github.com/NanshineLoong/EID-Benchmark .

</details>


### [151] [LVLMs and Humans Ground Differently in Referential Communication](https://arxiv.org/abs/2601.19792)
*Peter Zeng,Weiling Li,Amie Paige,Zhengxiang Wang,Panagiotis Kaliosis,Dimitris Samaras,Gregory Zelinsky,Susan Brennan,Owen Rambow*

Main category: cs.CL

TL;DR: 该研究通过一个包含人类和AI参与的参照沟通实验，揭示了大型语言模型（LVLM）在建立共同理解（common ground）方面存在的局限性，这对于生成式AI与人类有效协作至关重要。


<details>
  <summary>Details</summary>
Motivation: 生成式AI需要准确预测人类意图才能与人类有效协作，而目前AI在这方面受到无法建模共同理解的限制。

Method: 设计了一个包含人-人、人-AI、AI-人、AI-AI四种组合的参照沟通实验。实验让参与者（导演-匹配者）通过多轮对话，在一系列没有明显词汇标签的物品图片中进行匹配。研究发布了数据收集的在线流程、分析工具以及一个包含356个对话的语料库。

Result: 实验结果表明，LVLM在交互式解析指称表达方面存在局限性，而这正是人类语言使用中的一项关键技能。

Conclusion: 建立共同理解对于AI与人类有效协作至关重要，目前的LVLM在该能力上存在不足，限制了其与人类的交互能力。

Abstract: For generative AI agents to partner effectively with human users, the ability to accurately predict human intent is critical. But this ability to collaborate remains limited by a critical deficit: an inability to model common ground. Here, we present a referential communication experiment with a factorial design involving director-matcher pairs (human-human, human-AI, AI-human, and AI-AI) that interact with multiple turns in repeated rounds to match pictures of objects not associated with any obvious lexicalized labels. We release the online pipeline for data collection, the tools and analyses for accuracy, efficiency, and lexical overlap, and a corpus of 356 dialogues (89 pairs over 4 rounds each) that unmasks LVLMs' limitations in interactively resolving referring expressions, a crucial skill that underlies human language use.

</details>


### [152] [Identifying and Transferring Reasoning-Critical Neurons: Improving LLM Inference Reliability via Activation Steering](https://arxiv.org/abs/2601.19847)
*Fangan Dong,Zuming Yan,Xuri Ge,Zhiwei Xu,Mengqi Zhang,Xuanang Chen,Ben He,Xin Xin,Zhumin Chen,Ying Zhou*

Main category: cs.CL

TL;DR: 提出了一种名为AdaRAS的轻量级测试时框架，通过选择性干预神经元激活来提高大型语言模型的推理可靠性，无需额外训练或采样成本。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理复杂任务时，通常需要昂贵的后训练或采样策略才能保证性能，这限制了其实用效率。研究者发现，一部分神经元对推理的正确性有很强的预测能力，这促使了AdaRAS的提出。

Method: AdaRAS首先通过一种极性感知的均值差标准识别出“推理关键神经元”（RCNs），然后在推理过程中自适应地引导这些神经元的激活，以增强不正确的推理路径，同时避免对已正确推理的案例造成负面影响。

Result: 在10个数学和编码基准测试中，AdaRAS展现了持续的性能提升，在AIME-24和AIME-25上取得了超过13%的增益。此外，AdaRAS还表现出良好的跨数据集迁移能力和对更强模型的扩展性，并且无需额外的训练或采样成本。

Conclusion: AdaRAS是一种有效的、轻量级的测试时框架，能够通过干预神经元激活来提高大型语言模型的推理可靠性，并且具有良好的通用性和效率。

Abstract: Despite the strong reasoning capabilities of recent large language models (LLMs), achieving reliable performance on challenging tasks often requires post-training or computationally expensive sampling strategies, limiting their practical efficiency. In this work, we first show that a small subset of neurons in LLMs exhibits strong predictive correlations with reasoning correctness. Based on this observation, we propose AdaRAS (Adaptive Reasoning Activation Steering), a lightweight test-time framework that improves reasoning reliability by selectively intervening on neuron activations. AdaRAS identifies Reasoning-Critical Neurons (RCNs) via a polarity-aware mean-difference criterion and adaptively steers their activations during inference, enhancing incorrect reasoning traces while avoiding degradation on already-correct cases. Experiments on 10 mathematics and coding benchmarks demonstrate consistent improvements, including over 13% gains on AIME-24 and AIME-25. Moreover, AdaRAS exhibits strong transferability across datasets and scalability to stronger models, outperforming post-training methods without additional training or sampling cost.

</details>


### [153] [Zero-Shot Stance Detection in the Wild: Dynamic Target Generation and Multi-Target Adaptation](https://arxiv.org/abs/2601.19802)
*Aohua Li,Yuanshuo Zhang,Ge Gao,Bo Chen,Xiaobing Zhao*

Main category: cs.CL

TL;DR: 提出了一种名为DGTA的新型零样本、野外动态目标生成和多目标适应的立场检测任务，以解决现实世界社交媒体中目标不确定和动态的问题。研究构建了中文数据集，并探索了LLM的微调策略，实验证明微调LLM在此任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有立场检测研究依赖预定义目标，不适用于现实世界中复杂多变的社交媒体场景，目标既不预先定义也不固定。

Method: 提出了零样本、野外动态目标生成和多目标适应（DGTA）任务，旨在从文本中自动识别多个目标-立场对，无需预先了解目标。构建了中文社交媒体立场检测数据集，设计了多维度评估指标。探索了大型语言模型（LLMs）的集成和两阶段微调策略。

Result: 实验结果表明，微调后的LLMs在此任务上表现出卓越的性能。两阶段微调的Qwen2.5-7B实现了最高的综合目标识别分数66.99%，而集成微调的DeepSeek-R1-Distill-Qwen-7B达到了79.26%的立场检测F1分数。

Conclusion: 微调大型语言模型是解决零样本、野外动态目标生成和多目标立场检测任务的有效方法，两阶段微调和集成微调策略各有优势，能够显著提升在目标识别和立场检测方面的性能。

Abstract: Current stance detection research typically relies on predicting stance based on given targets and text. However, in real-world social media scenarios, targets are neither predefined nor static but rather complex and dynamic. To address this challenge, we propose a novel task: zero-shot stance detection in the wild with Dynamic Target Generation and Multi-Target Adaptation (DGTA), which aims to automatically identify multiple target-stance pairs from text without prior target knowledge. We construct a Chinese social media stance detection dataset and design multi-dimensional evaluation metrics. We explore both integrated and two-stage fine-tuning strategies for large language models (LLMs) and evaluate various baseline models. Experimental results demonstrate that fine-tuned LLMs achieve superior performance on this task: the two-stage fine-tuned Qwen2.5-7B attains the highest comprehensive target recognition score of 66.99%, while the integrated fine-tuned DeepSeek-R1-Distill-Qwen-7B achieves a stance detection F1 score of 79.26%.

</details>


### [154] [Reflective Translation: Improving Low-Resource Machine Translation via Structured Self-Reflection](https://arxiv.org/abs/2601.19871)
*Nicholas Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种名为“反思翻译”的基于提示的框架，通过让大语言模型对翻译进行自我批评和修改，来提高低资源语言（如祖鲁语和科萨语）的机器翻译质量，并在现有数据集上取得了显著的BLEU和COMET分数提升。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如isiZulu和isiXhosa）在机器翻译方面面临数据和资源不足的挑战。大型语言模型的自我反思能力有望提升其输出质量，因此研究者希望将其应用于低资源语言的翻译。

Method: 提出“反思翻译”框架，该框架包含三个步骤：1. 模型生成初步翻译；2. 模型生成结构化的自我批评；3. 模型基于自我批评生成优化后的翻译。在英语-isiZulu和英语-isiXhosa翻译任务上，使用OPUS-100和NTREX-African数据集，并尝试了多种提示策略和置信度阈值。

Result: 与初始翻译相比，反思翻译在BLEU和COMET分数上均显示出持续的改进，平均BLEU得分提升高达+0.22，COMET得分提升高达+0.18。配对非参数检验证实了这些改进的统计学显著性。

Conclusion: 结构化自我反思是一种实用且有效的方法，可以提高低资源语言的翻译质量。该方法模型无关，无需微调，并生成了一个可用于未来监督学习或分析的增强型数据集。

Abstract: Low-resource languages such as isiZulu and isiXhosa face persistent challenges in machine translation due to limited parallel data and linguistic resources. Recent advances in large language models suggest that self-reflection, prompting a model to critique and revise its own outputs, can improve reasoning quality and factual consistency. Building on this idea, this paper introduces Reflective Translation, a prompt-based framework in which a model generates an initial translation, produces a structured self-critique, and then uses this reflection to generate a refined translation. The approach is evaluated on English-isiZulu and English-isiXhosa translation using OPUS-100 and NTREX-African, across multiple prompting strategies and confidence thresholds. Results show consistent improvements in both BLEU and COMET scores between first- and second-pass translations, with average gains of up to +0.22 BLEU and +0.18 COMET. Statistical significance testing using paired nonparametric tests confirms that these improvements are robust. The proposed method is model-agnostic, requires no fine-tuning, and introduces a reflection-augmented dataset that can support future supervised or analysis-driven work. These findings demonstrate that structured self-reflection is a practical and effective mechanism for improving translation quality in low-resource settings.

</details>


### [155] [Evaluation of Oncotimia: An LLM based system for supporting tumour boards](https://arxiv.org/abs/2601.19899)
*Luis Lorenzo,Marcos Montana-Mendez,Sergio Figueiras,Miguel Boubeta,Cristobal Bernardo-Castineira*

Main category: cs.CL

TL;DR: 本文介绍了一个名为ONCOTIMIA的集成生成式AI（GenAI）的临床工具，用于自动化填写肺癌多学科肿瘤委员会（MDTB）表格，以减轻文档负担。该工具使用大型语言模型（LLMs）、检索增强生成（RAG）等技术，并评估了六种LLMs在十个肺癌病例上的表现，结果显示技术可行且操作可行，最佳模型能达到80%的字段填写准确率，且响应时间在临床可接受范围内。


<details>
  <summary>Details</summary>
Motivation: 多学科肿瘤委员会（MDTBs）在肿瘤决策中至关重要，但现有的手动流程和大量异构临床信息的结构化处理带来了巨大的文档负担。因此，需要开发工具来简化和自动化这一过程。

Method: 研究人员开发了一个名为ONCOTIMIA的模块化、安全的临床工具，该工具集成了GenAI，特别是LLMs。该系统采用多层数据湖、混合关系型和向量存储、检索增强生成（RAG）以及基于规则的自适应表单模型。他们评估了通过AWS Bedrock部署的六种LLMs在十个肺癌病例上的自动填写表格性能，并衡量了填写准确率和端到端延迟。

Result: 研究结果显示，所评估的LLMs在填写肺癌肿瘤委员会表格方面表现出高水平的性能。最佳配置实现了80%的正确字段填写率，并且大多数LLMs的响应时间在临床上是可接受的。研究发现，更大、更新的模型通常能提供更高的准确性，而不会显著增加延迟。

Conclusion: 基于LLMs的肿瘤委员会表格自动填写在多学科肺癌工作流程中是技术上可行且操作上可行的。该方法有潜力显著减轻文档负担，同时保持数据质量，为未来在肿瘤学领域更广泛地应用AI提供了实证支持。

Abstract: Multidisciplinary tumour boards (MDTBs) play a central role in oncology decision-making but require manual processes and structuring large volumes of heterogeneous clinical information, resulting in a substantial documentation burden. In this work, we present ONCOTIMIA, a modular and secure clinical tool designed to integrate generative artificial intelligence (GenAI) into oncology workflows and evaluate its application to the automatic completion of lung cancer tumour board forms using large language models (LLMs). The system combines a multi-layer data lake, hybrid relational and vector storage, retrieval-augmented generation (RAG) and a rule-driven adaptive form model to transform unstructured clinical documentation into structured and standardised tumour board records. We assess the performance of six LLMs deployed through AWS Bedrock on ten lung cancer cases, measuring both completion form accuracy and end-to-end latency. The results demonstrate high performance across models, with the best performing configuration achieving an 80% of correct field completion and clinically acceptable response time for most LLMs. Larger and more recent models exhibit best accuracies without incurring prohibitive latency. These findings provide empirical evidence that LLM- assisted autocompletion form is technically feasible and operationally viable in multidisciplinary lung cancer workflows and support its potential to significantly reduce documentation burden while preserving data quality.

</details>


### [156] [When Iterative RAG Beats Ideal Evidence: A Diagnostic Study in Scientific Multi-hop Question Answering](https://arxiv.org/abs/2601.19827)
*Mahdi Astaraki,Mohammad Arshi Saloot,Ali Shiraee Kasmaee,Hamidreza Mahyar,Soheila Samiee*

Main category: cs.CL

TL;DR: 研究发现，在科学领域，迭代检索-推理循环（Iterative RAG）相比于静态检索（Static RAG）能够提供显著的性能提升，甚至超越了理想化的静态检索（Gold Context），尤其对于那些未经专门推理微调的模型。研究通过在化学问答数据集上进行的实验，揭示了迭代检索在处理多跳推理、稀疏知识和异构证据方面的优势，并分析了其成功和失败的机制，为RAG系统的部署和诊断提供了指导。


<details>
  <summary>Details</summary>
Motivation: 在科学领域，多跳推理、稀疏知识和异构证据等挑战使得理解迭代检索-推理循环（Iterative RAG）何时能超越静态检索（Static RAG）变得尤为重要。本研究旨在通过受控的诊断性研究，评估迭代检索-推理在这些复杂场景下的实际效果，并将其与理想化的静态检索进行对比。

Method: 研究采用了三种检索模式对十一种最先进的大语言模型进行基准测试：(i) 无上下文（No Context），衡量模型对参数知识的依赖；(ii) 黄金上下文（Gold Context），一次性提供所有最优证据；(iii) 迭代RAG（Iterative RAG），一种无需训练的控制器，通过交替进行检索、假设精炼和基于证据的停止判断。研究使用了化学领域的ChemKGMultiHopQA数据集，并设计了覆盖检索覆盖率、锚点携带、查询质量、组合保真度和控制校准等方面的诊断工具。

Result: 在ChemKGMultiHopQA数据集上，迭代RAG在所有模型上都持续优于黄金上下文，性能提升高达25.6个百分点，特别是对于非推理微调的模型。迭代检索能够减少后期跳跃的失败，缓解上下文过载，并动态纠正早期假设的漂移。然而，仍然存在一些失败模式，例如不完整的跳跃覆盖、干扰项的锁定、过早停止以及即使检索完美也存在高组合失败率。

Conclusion: 迭代检索-推理（Iterative RAG）在科学领域的复杂问答任务中，通常比仅仅提供理想化的静态证据（Gold Context）更具影响力。研究为在专业科学环境中部署和诊断RAG系统提供了实用的指导，并为构建更可靠、可控的迭代检索-推理框架奠定了基础。

Abstract: Retrieval-Augmented Generation (RAG) extends large language models (LLMs) beyond parametric knowledge, yet it is unclear when iterative retrieval-reasoning loops meaningfully outperform static RAG, particularly in scientific domains with multi-hop reasoning, sparse domain knowledge, and heterogeneous evidence. We provide the first controlled, mechanism-level diagnostic study of whether synchronized iterative retrieval and reasoning can surpass an idealized static upper bound (Gold Context) RAG. We benchmark eleven state-of-the-art LLMs under three regimes: (i) No Context, measuring reliance on parametric memory; (ii) Gold Context, where all oracle evidence is supplied at once; and (iii) Iterative RAG, a training-free controller that alternates retrieval, hypothesis refinement, and evidence-aware stopping. Using the chemistry-focused ChemKGMultiHopQA dataset, we isolate questions requiring genuine retrieval and analyze behavior with diagnostics spanning retrieval coverage gaps, anchor-carry drop, query quality, composition fidelity, and control calibration. Across models, Iterative RAG consistently outperforms Gold Context, with gains up to 25.6 percentage points, especially for non-reasoning fine-tuned models. Staged retrieval reduces late-hop failures, mitigates context overload, and enables dynamic correction of early hypothesis drift, but remaining failure modes include incomplete hop coverage, distractor latch trajectories, early stopping miscalibration, and high composition failure rates even with perfect retrieval. Overall, staged retrieval is often more influential than the mere presence of ideal evidence; we provide practical guidance for deploying and diagnosing RAG systems in specialized scientific settings and a foundation for more reliable, controllable iterative retrieval-reasoning frameworks.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [157] [Learning the Pareto Space of Multi-Objective Autonomous Driving: A Modular, Data-Driven Approach](https://arxiv.org/abs/2601.18913)
*Mohammad Elayan,Wissam Kontar*

Main category: cs.RO

TL;DR: 该研究提出了一个经验学习框架，用于从自然轨迹数据中学习自动驾驶的安全性、效率和交互性之间的权衡，并识别出帕累托最优的驾驶状态。


<details>
  <summary>Details</summary>
Motivation: 为了理解自动驾驶汽车（AV）在实际操作中的行为，并设计兼顾安全性、效率和交互性的自主驾驶代理，研究者希望量化这些目标之间的权衡。

Method: 研究者构建了一个统一的目标空间，用综合得分表示AV每个时间步的安全性、效率和交互性。然后应用帕累托优势来识别非支配状态，形成定义了平衡性能可达区域的经验前沿。

Result: 在TGSIM数据集上，只有0.23%的AV驾驶实例被发现是帕累托最优的，这表明同时优化多个目标非常罕见。帕累托最优状态在安全性、效率和交互性方面均显著优于非最优情况，其中交互性有最大的改进潜力。

Conclusion: 该研究提出的经验学习框架能够从自然轨迹数据中推导出多目标学习的权衡，并可视化这些权衡。该框架是侵入性小且模块化的，只需要运动学和位置数据，可应用于更广泛的场景。

Abstract: Balancing safety, efficiency, and interaction is fundamental to designing autonomous driving agents and to understanding autonomous vehicle (AV) behavior in real-world operation. This study introduces an empirical learning framework that derives these trade-offs directly from naturalistic trajectory data. A unified objective space represents each AV timestep through composite scores of safety, efficiency, and interaction. Pareto dominance is applied to identify non-dominated states, forming an empirical frontier that defines the attainable region of balanced performance.
  The proposed framework was demonstrated using the Third Generation Simulation (TGSIM) datasets from Foggy Bottom and I-395. Results showed that only 0.23\% of AV driving instances were Pareto-optimal, underscoring the rarity of simultaneous optimization across objectives. Pareto-optimal states showed notably higher mean scores for safety, efficiency, and interaction compared to non-optimal cases, with interaction showing the greatest potential for improvement.
  This minimally invasive and modular framework, which requires only kinematic and positional data, can be directly applied beyond the scope of this study to derive and visualize multi-objective learning surfaces

</details>


### [158] [A Switching Nonlinear Model Predictive Control Strategy for Safe Collision Handling by an Underwater Vehicle-Manipulator System](https://arxiv.org/abs/2601.18971)
*Ioannis G. Polyzos,Konstantinos J. Kyriakopoulos*

Main category: cs.RO

TL;DR: 提出了一种切换非线性模型预测控制（NMPC）策略，用于水下机器人-机械臂系统（UVMS）在避免碰撞失败时，利用机械臂推离障碍物以避免碰撞损坏。


<details>
  <summary>Details</summary>
Motivation: 水下环境中，自主机器人执行任务时可能面临与障碍物碰撞的风险，需要有效的碰撞处理策略。

Method: 提出了一种切换NMPC策略，当检测到无法避免碰撞时，利用机械臂与障碍物接触并施加推力来改变UVMS的运动轨迹。

Result: 虚拟实验表明，该算法能够成功检测碰撞，并能通过自主避障或利用机械臂进行碰撞处理，有效避免对UVMS敏感区域造成损伤。

Conclusion: 所提出的切换NMPC策略能够有效地处理UVMS在水下环境中可能遇到的碰撞情况，通过智能地利用机械臂来应对无法主动避让的碰撞，保证了系统的安全性。

Abstract: For active intervention tasks in underwater environments, the use of autonomous vehicles is just now emerging as an active area of research. During operation, for various reasons, the robot might find itself on a collision course with an obstacle in its environment. In this paper, a switching Nonlinear Model Predictive Control (NMPC) strategy is proposed to safely handle collisions for an Underwater Vehicle-Manipulator System (UVMS). When avoiding the collision is impossible, the control algorithm takes advantage of the manipulator, using it to push against the obstacle, and deflect away from the collision. Virtual experiments are performed to demonstrate the algorithm's capability to successfully detect collisions and either avoid them, or use the manipulator to handle them appropriately without damaging sensitive areas of the vehicle.

</details>


### [159] [Neuromorphic BrailleNet: Accurate and Generalizable Braille Reading Beyond Single Characters through Event-Based Optical Tactile Sensing](https://arxiv.org/abs/2601.19079)
*Naqash Afzal,Niklas Funk,Erik Helmut,Jan Peters,Benjamin Ward-Cherrier*

Main category: cs.RO

TL;DR: 该研究提出了一种基于事件感知的神经形态触觉传感器Evetac的连续盲文识别流水线，实现了高精度和实时性，有望改进机器人盲文阅读和触觉感知应用。


<details>
  <summary>Details</summary>
Motivation: 现有机器人盲文阅读器速度慢、不连贯，基于视觉的方法计算量大、延迟高且易受环境影响。研究旨在开发一种更接近人类阅读方式、速度更快、精度更高的盲文识别系统。

Method: 使用Evetac神经形态事件触觉传感器，该传感器能实时编码动态接触事件。结合时空分割和轻量级ResNet分类器处理稀疏事件流，实现对不同缩进深度和扫描速度下的盲文进行识别。

Result: 在标准深度下，系统实现了接近完美的字符识别精度（≥98%），并且能够泛化到多种盲文板布局，在快速扫描下也能保持良好性能。在包含日常词汇的物理盲文板上，词语级准确率超过90%，表现出对时间压缩效应的鲁棒性。

Conclusion: 神经形态触觉传感是解决机器人盲文阅读低延迟、高精度问题的可行方案，具有广泛的辅助和机器人应用前景。

Abstract: Conventional robotic Braille readers typically rely on discrete, character-by-character scanning, limiting reading speed and disrupting natural flow. Vision-based alternatives often require substantial computation, introduce latency, and degrade in real-world conditions. In this work, we present a high accuracy, real-time pipeline for continuous Braille recognition using Evetac, an open-source neuromorphic event-based tactile sensor. Unlike frame-based vision systems, the neuromorphic tactile modality directly encodes dynamic contact events during continuous sliding, closely emulating human finger-scanning strategies. Our approach combines spatiotemporal segmentation with a lightweight ResNet-based classifier to process sparse event streams, enabling robust character recognition across varying indentation depths and scanning speeds. The proposed system achieves near-perfect accuracy (>=98%) at standard depths, generalizes across multiple Braille board layouts, and maintains strong performance under fast scanning. On a physical Braille board containing daily-living vocabulary, the system attains over 90% word-level accuracy, demonstrating robustness to temporal compression effects that challenge conventional methods. These results position neuromorphic tactile sensing as a scalable, low latency solution for robotic Braille reading, with broader implications for tactile perception in assistive and robotic applications.

</details>


### [160] [Fauna Sprout: A lightweight, approachable, developer-ready humanoid robot](https://arxiv.org/abs/2601.18963)
*Fauna Robotics,:,Diego Aldarondo,Ana Pervan,Daniel Corbalan,Dave Petrillo,Bolun Dai,Aadhithya Iyer,Nina Mortensen,Erik Pearson,Sridhar Pandian Arunachalam,Emma Reznick,David Weis,Jacob Davison,Samuel Patterson,Tess Carella,Michael Suguitan,David Ye,Oswaldo Ferro,Nilesh Suriyarachchi,Spencer Ling,Erik Su,Daniel Giebisch,Peter Traver,Sam Fonseca,Mack Mor,Rohan Singh,Sertac Guven,Kangni Liu,Yaswanth Kumar Orru,Ashiq Rahman Anwar Batcha,Shruthi Ravindranath,Silky Arora,Hugo Ponte,Dez Hernandez,Utsav Chaudhary,Zack Walker,Michael Kelberman,Ivan Veloz,Christina Santa Lucia,Kat Casale,Helen Han,Michael Gromis,Michael Mignatti,Jason Reisman,Kelleher Guerin,Dario Narvaez,Christopher Anderson,Anthony Moschella,Robert Cochran,Josh Merel*

Main category: cs.RO

TL;DR: Sprout是一个为通用机器人控制器设计的开发平台，它通过轻量化设计、合规控制、低关节扭矩和柔软外壳来实现安全性，并集成全身控制、集成抓手的操作和VR遥操作，同时配备了可进行社交互动的功能头，旨在降低部署门槛，促进在人类环境中的具身智能研究。


<details>
  <summary>Details</summary>
Motivation: 现有通用机器人控制器在安全、表达性和长期部署方面存在局限，尤其是在人类环境中。大多数现有的人形机器人要么是难以部署和操作的闭源系统，要么是学术原型，这阻碍了机器人学的发展。

Method: Sprout平台采用了轻量化设计、合规控制、低关节扭矩和柔软外壳以支持在与人类共享空间的安全操作。它集成了全身控制、带集成抓手的功能、以及基于虚拟现实的远程操作，并包含一个用于社交互动的功能头。该平台提供了一个统一的软硬件堆栈。

Result: Sprout通过降低物理和技术门槛，扩大了对功能强大的人形机器人的可及性，并为在真实人类环境中开发具身智能提供了一个实用的基础。其设计强调安全、表达性和开发者的易用性。

Conclusion: Sprout作为一个开发平台，通过其安全性、表达性和易用性设计，解决了现有机器人平台在人类环境中部署和操作的挑战，为具身智能的进一步发展开辟了新的途径。

Abstract: Recent advances in learned control, large-scale simulation, and generative models have accelerated progress toward general-purpose robotic controllers, yet the field still lacks platforms suitable for safe, expressive, long-term deployment in human environments. Most existing humanoids are either closed industrial systems or academic prototypes that are difficult to deploy and operate around people, limiting progress in robotics. We introduce Sprout, a developer platform designed to address these limitations through an emphasis on safety, expressivity, and developer accessibility. Sprout adopts a lightweight form factor with compliant control, limited joint torques, and soft exteriors to support safe operation in shared human spaces. The platform integrates whole-body control, manipulation with integrated grippers, and virtual-reality-based teleoperation within a unified hardware-software stack. An expressive head further enables social interaction -- a domain that remains underexplored on most utilitarian humanoids. By lowering physical and technical barriers to deployment, Sprout expands access to capable humanoid platforms and provides a practical basis for developing embodied intelligence in real human environments.

</details>


### [161] [DeFM: Learning Foundation Representations from Depth for Robotics](https://arxiv.org/abs/2601.18923)
*Manthan Patel,Jonas Frey,Mayank Mittal,Fan Yang,Alexander Hansson,Amir Bar,Cesar Cadena,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了DeFM，一个完全在深度图像上训练的自监督基础模型，用于机器人应用。DeFM学习的几何和语义表示可以泛化到不同的环境、任务和传感器，并在多个机器人基准测试中达到最先进的性能，同时保持模拟到现实的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 与RGB图像相比，深度模态的表示学习在机器人领域仍未得到充分探索，而大型基础模型已在RGB领域取得显著进展。因此，作者希望填补这一空白，开发一个专门针对深度图像的机器人基础模型。

Method: 作者使用DINO风格的自蒸馏目标，在6000万张深度图像的数据集上训练了一个基础模型DeFM。为了在多尺度下保持度量意识，引入了一种新颖的输入归一化策略。此外，还将DeFM蒸馏成更紧凑的模型，以适应资源受限的机器人系统。

Result: DeFM在基于深度的分类、分割、导航、运动和操作基准测试中取得了最先进的性能，并展示了从模拟到现实世界的强大泛化能力。

Conclusion: DeFM是一个有效的、可即插即用的深度基础模型，能够学习通用的几何和语义表示，并能泛化到各种机器人任务和传感器，无需进行特定任务的微调。其紧凑型模型也适用于资源受限的机器人平台。

Abstract: Depth sensors are widely deployed across robotic platforms, and advances in fast, high-fidelity depth simulation have enabled robotic policies trained on depth observations to achieve robust sim-to-real transfer for a wide range of tasks. Despite this, representation learning for depth modality remains underexplored compared to RGB, where large-scale foundation models now define the state of the art. To address this gap, we present DeFM, a self-supervised foundation model trained entirely on depth images for robotic applications. Using a DINO-style self-distillation objective on a curated dataset of 60M depth images, DeFM learns geometric and semantic representations that generalize to diverse environments, tasks, and sensors. To retain metric awareness across multiple scales, we introduce a novel input normalization strategy. We further distill DeFM into compact models suitable for resource-constrained robotic systems. When evaluated on depth-based classification, segmentation, navigation, locomotion, and manipulation benchmarks, DeFM achieves state-of-the-art performance and demonstrates strong generalization from simulation to real-world environments. We release all our pretrained models, which can be adopted off-the-shelf for depth-based robotic learning without task-specific fine-tuning. Webpage: https://de-fm.github.io/

</details>


### [162] [SimTO: A simulation-based topology optimization framework for bespoke soft robotic grippers](https://arxiv.org/abs/2601.19098)
*Kurt Enkera,Josh Pinskier,Marcus Gallagher,David Howard*

Main category: cs.RO

TL;DR: 提出了一种名为SimTO的框架，通过从物理模拟器中自动提取载荷工况，实现了高分辨率的拓扑优化，从而设计出能够抓取具有复杂特征的物体的定制化软体机器人夹爪，并且这些设计对未见过但具有相似特征的物体也具有泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的软体机器人夹爪难以抓取具有丰富特征、拓扑结构高度可变的物体（如汽车齿轮、珊瑚、西兰花等），这些物体缺乏明确的“最优”接触表面，容易在抓取过程中损坏。传统的拓扑优化方法需要预先定义载荷工况，而对于与复杂特征物体交互的软体夹爪，接触力是不可预测的。

Method: 引入SimTO框架，该框架能够从基于接触的物理模拟器中自动提取载荷工况，无需手动指定。利用此框架，可以对任意特征丰富的物体进行高分辨率的拓扑优化，生成具有精细形态特征的定制化软体夹爪。

Result: 数值结果表明，SimTO生成的夹爪设计能够高度定制化地适应特征丰富的物体，并且对未见过的、但具有相似特征的物体也表现出良好的泛化能力。

Conclusion: SimTO框架能够解决传统拓扑优化在设计复杂特征物体抓取器时面临的载荷工况未知问题，通过自动提取载荷工况，能够设计出高度专业化且具有泛化能力的软体机器人夹爪，为制造、医疗和农业等领域提供了新的解决方案。

Abstract: Soft robotic grippers are essential for grasping delicate, geometrically complex objects in manufacturing, healthcare and agriculture. However, existing grippers struggle to grasp feature-rich objects with high topological variability, including gears with sharp tooth profiles on automotive assembly lines, corals with fragile protrusions, or vegetables with irregular branching structures like broccoli. Unlike simple geometric primitives such as cubes or spheres, feature-rich objects lack a clear "optimal" contact surface, making them both difficult to grasp and susceptible to damage when grasped by existing gripper designs. Safe handling of such objects therefore requires specialized soft grippers whose morphology is tailored to the object's features. Topology optimization offers a promising approach for producing specialized grippers, but its utility is limited by the requirement for pre-defined load cases. For soft grippers interacting with feature-rich objects, these loads arise from hundreds of unpredictable gripper-object contact forces during grasping and are unknown a priori. To address this problem, we introduce SimTO, a framework that enables high-resolution topology optimization by automatically extracting load cases from a contact-based physics simulator, eliminating the need for manual load specification. Given an arbitrary feature-rich object, SimTO produces highly customized soft grippers with fine-grained morphological features tailored to the object geometry. Numerical results show our designs are not only highly specialized to feature-rich objects, but also generalize to unseen objects.

</details>


### [163] [Agree to Disagree: Consensus-Free Flocking under Constraints](https://arxiv.org/abs/2601.19119)
*Peter Travis Jardine,Sidney Givigi*

Main category: cs.RO

TL;DR: 该研究提出了一种新的多机器人协作方法，允许机器人协商和调整它们之间的期望距离和约束，即使在存在部分不一致或冲突目标的情况下也是如此。该方法仅依赖于局部观察，无需全局信息或通信，并且对半信任场景具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人协作方法通常假设所有机器人之间具有统一的期望距离和约束，这在实际应用中灵活性不足，尤其是在面对不同类型和配置的机器人以及不确定通信和信任的环境时。因此，需要一种更灵活、更能适应复杂情况的协作机制。

Method: 研究引入了一种新的约束集体势函数形式，该形式允许在局部观察的基础上对机器人之间的期望距离和约束进行协商。该方法继承了传统 flocking 控制的理念，不依赖全局信息或通信，并且能够处理半信任场景。

Result: 通过一系列仿真验证了所提出方法的有效性。该方法能够允许机器人自主地协商和调整它们之间的相对距离和行为，从而实现灵活的协作。

Conclusion: 该研究成功地放宽了传统 flocking 模型中对统一期望距离的假设，提出了一种通过局部交互实现参数协商的鲁棒性多机器人协作方法，能够应对不一致甚至冲突的目标，为在复杂和不可靠环境中部署多机器人系统提供了新的途径。

Abstract: Robots sometimes have to work together with a mixture of partially-aligned or conflicting goals. Flocking - coordinated motion through cohesion, alignment, and separation - traditionally assumes uniform desired inter-agent distances. Many practical applications demand greater flexibility, as the diversity of types and configurations grows with the popularity of multi-agent systems in society. Moreover, agents often operate without guarantees of trust or secure communication. Motivated by these challenges we update well-established frameworks by relaxing this assumption of shared inter-agent distances and constraints. Through a new form of constrained collective potential function, we introduce a solution that permits negotiation of these parameters. In the spirit of the traditional flocking control canon, this negotiation is achieved purely through local observations and does not require any global information or inter-agent communication. The approach is robust to semi-trust scenarios, where neighbouring agents pursue conflicting goals. We validate the effectiveness of the approach through a series of simulations.

</details>


### [164] [Robust Out-of-Order Retrieval for Grid-Based Storage at Maximum Capacity](https://arxiv.org/abs/2601.19144)
*Tzvika Geft,William Zhang,Jingjin Yu,Kostas Bekris*

Main category: cs.RO

TL;DR: 本文提出了一种框架，用于提高自动化存储系统在不确定性下的运营效率。针对二维网格存储系统，研究了在检索序列发生变化（k-有界扰动）的情况下，如何最小化负载重定位。结果表明，Θ(k) 的网格宽度对于消除重定位是必要且充分的，并提供了一个高效的求解器。对于更高不确定性，也提出了相应策略。实验表明，该框架能显著减少重定位次数。


<details>
  <summary>Details</summary>
Motivation: 实际物流应用中，存储和检索序列可能发生变化，尤其是在检索阶段，这会影响自动化存储系统的效率。现有方法在检索序列已知时能保证零重定位，但无法处理检索序列不确定的情况。因此，需要研究在检索序列发生一定程度变化时，如何最小化重定位。

Method: 本文研究了“k-有界扰动”下的检索序列变化，即任意两个负载的相对顺序最多相差k个位置。通过理论分析，证明了 Θ(k) 的网格宽度是实现零重定位的必要和充分条件。此外，还开发了一种用于计算鲁棒存储安排的高效求解器。对于超出k范围的更高不确定性，提出了一种最小化重定位的策略。

Result: 证明了 Θ(k) 的网格宽度对于在 k-有界扰动下消除重定位是必要且充分的。实验结果表明，当 k 最大为网格宽度的一半时，该框架几乎消除了重定位；当 k 最大为网格宽度时，重定位次数减少了 50% 以上。

Conclusion: 本文提出的框架能够有效地处理自动化存储系统中因检索序列变化（k-有界扰动）而引起的不确定性，并通过理论分析和高效求解器，显著减少了负载重定位，提高了系统的运营效率。对于不同程度的不确定性，该框架均能提供有效的解决方案。

Abstract: This paper proposes a framework for improving the operational efficiency of automated storage systems under uncertainty. It considers a 2D grid-based storage for uniform-sized loads (e.g., containers, pallets, or totes), which are moved by a robot (or other manipulator) along a collision-free path in the grid. The loads are labeled (i.e., unique) and must be stored in a given sequence, and later be retrieved in a different sequence -- an operational pattern that arises in logistics applications, such as last-mile distribution centers and shipyards. The objective is to minimize the load relocations to ensure efficient retrieval. A previous result guarantees a zero-relocation solution for known storage and retrieval sequences, even for storage at full capacity, provided that the side of the grid through which loads are stored/retrieved is at least 3 cells wide. However, in practice, the retrieval sequence can change after the storage phase. To address such uncertainty, this work investigates \emph{$k$-bounded perturbations} during retrieval, under which any two loads may depart out of order if they are originally at most $k$ positions apart. We prove that a $Θ(k)$ grid width is necessary and sufficient for eliminating relocations at maximum capacity. We also provide an efficient solver for computing a storage arrangement that is robust to such perturbations. To address the higher-uncertainty case where perturbations exceed $k$, a strategy is introduced to effectively minimize relocations. Extensive experiments show that, for $k$ up to half the grid width, the proposed storage-retrieval framework essentially eliminates relocations. For $k$ values up to the full grid width, relocations are reduced by $50\%+$.

</details>


### [165] [iFAN Ecosystem: A Unified AI, Digital Twin, Cyber-Physical Security, and Robotics Environment for Advanced Nuclear Simulation and Operations](https://arxiv.org/abs/2601.19234)
*Youndo Do,Chad Meece,Marc Zebrowitz,Spencer Banks,Myeongjun Choi,Xiaoxu Diao,Kai Tan,Michael Doran,Jason Reed,Fan Zhang*

Main category: cs.RO

TL;DR: 本文介绍了一个名为 iFAN 的沉浸式框架，它是一个集成了 3D 环境、物理模拟、VR、强化学习、辐射模拟和网络物理安全的高保真虚拟测试平台，用于验证核设施的数字化转型和先进反应堆的运行。


<details>
  <summary>Details</summary>
Motivation: 核设施的数字化转型和先进反应堆的发展引入了人工智能、网络物理安全和自主机器人等新技术，但缺乏专门的虚拟测试平台来评估和部署这些技术。

Method: 开发了一个名为 iFAN 的综合性数字孪生框架，该框架拥有逼真的 3D 环境和基于物理的模拟。iFAN 支持实时数据交换，并集成了虚拟现实、强化学习、辐射模拟和网络物理安全等核心功能，用于操作、网络安全、物理安全和机器人操作。

Result: iFAN 提供了一个高保真的虚拟测试平台，能够进行实时数据交换，从而实现部署前的验证。文章还通过潜在的操作场景对 iFAN 的各种应用进行了研究。

Conclusion: iFAN 生态系统提供了一个多功能且安全的架构，用于验证下一代自主和网络弹性核运行。

Abstract: As nuclear facilities experience digital transformation and advanced reactor development, AI integration, cyber-physical security, and other emerging technologies such as autonomous robot operations are increasingly developed. However, evaluation and deployment is challenged by the lack of dedicated virtual testbeds. The Immersive Framework for Advanced Nuclear (iFAN) ecosystem is developed, a comprehensive digital twin framework with a realistic 3D environment with physics-based simulations. The iFAN ecosystem serves as a high-fidelity virtual testbed for plant operation, cybersecurity, physical security, and robotic operation, as it provides real-time data exchange for pre-deployment verification. Core features include virtual reality, reinforcement learning, radiation simulation, and cyber-physical security. In addition, the paper investigates various applications through potential operational scenarios. The iFAN ecosystem provides a versatile and secure architecture for validating the next generation of autonomous and cyber-resilient nuclear operations.

</details>


### [166] [Tactile Memory with Soft Robot: Robust Object Insertion via Masked Encoding and Soft Wrist](https://arxiv.org/abs/2601.19275)
*Tatsuya Kamijo,Mai Nishimura,Cristian C. Beltran-Hernandez,Nodoka Shibasaki,Masashi Hamaya*

Main category: cs.RO

TL;DR: 本文提出了一种名为 TaMeSo-bot 的软体机器人系统，该系统集成了柔软的腕部和基于触觉记忆的检索控制，以实现安全稳健的操作。核心是 MAT^3 模型，它通过掩码标记预测来学习时空表示，并在机器人穿针孔任务中表现出卓越的适应性和成功率。


<details>
  <summary>Details</summary>
Motivation: 为了复制触觉记忆能力，这对接触密集型任务（如在不确定情况下的插钥匙）至关重要。

Method: 引入了 TaMeSo-bot 系统，集成了柔软的腕部和基于触觉检索的控制。核心模型是 Masked Tactile Trajectory Transformer (MAT^3)，它利用掩码标记预测来联合建模机器人动作、触觉反馈、力矩测量和本体感受信号之间的时空交互。

Result: MAT^3 在各种条件下比基线方法取得了更高的成功率，并展现出对未见过物体和条件的出色适应能力。

Conclusion: MAT^3 能够有效学习时空表示，并赋予 TaMeSo-bot 机器人系统在穿针孔等任务中安全、鲁棒且适应性强的操作能力。

Abstract: Tactile memory, the ability to store and retrieve touch-based experience, is critical for contact-rich tasks such as key insertion under uncertainty. To replicate this capability, we introduce Tactile Memory with Soft Robot (TaMeSo-bot), a system that integrates a soft wrist with tactile retrieval-based control to enable safe and robust manipulation. The soft wrist allows safe contact exploration during data collection, while tactile memory reuses past demonstrations via retrieval for flexible adaptation to unseen scenarios. The core of this system is the Masked Tactile Trajectory Transformer (MAT$^\text{3}$), which jointly models spatiotemporal interactions between robot actions, distributed tactile feedback, force-torque measurements, and proprioceptive signals. Through masked-token prediction, MAT$^\text{3}$ learns rich spatiotemporal representations by inferring missing sensory information from context, autonomously extracting task-relevant features without explicit subtask segmentation. We validate our approach on peg-in-hole tasks with diverse pegs and conditions in real-robot experiments. Our extensive evaluation demonstrates that MAT$^\text{3}$ achieves higher success rates than the baselines over all conditions and shows remarkable capability to adapt to unseen pegs and conditions.

</details>


### [167] [Perception-to-Pursuit: Track-Centric Temporal Reasoning for Open-World Drone Detection and Autonomous Chasing](https://arxiv.org/abs/2601.19318)
*Venkatakrishna Reddy Oruganti*

Main category: cs.RO

TL;DR: 提出了一种名为Perception-to-Pursuit (P2P)的框架，用于无人机追踪和拦截，通过运动模式的时序推理来预测轨迹并实现可行的拦截，显著提高了预测准确性和拦截成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的无人机追踪方法只关注预测准确性，忽略了拦截的可行性，导致预测轨迹在实际拦截中几乎不可能实现。

Method: P2P框架将无人机运动表示为包含速度、加速度、尺度和流畅度等信息的8维紧凑型token。利用一个12帧因果Transformer对未来行为进行推理，并引入拦截成功率（ISR）指标来衡量拦截的可行性。

Result: 在Anti-UAV-RGBT数据集上，P2P取得了28.12像素的平均位移误差和0.597的ISR，相比于仅追踪的方法，轨迹预测提高了77%，拦截可行性提高了597倍，同时保持了100%的无人机分类准确率。

Conclusion: 时序推理在无人机运动模式上能够同时实现准确的预测和可行的拦截规划。

Abstract: Autonomous drone pursuit requires not only detecting drones but also predicting their trajectories in a manner that enables kinematically feasible interception. Existing tracking methods optimize for prediction accuracy but ignore pursuit feasibility, resulting in trajectories that are physically impossible to intercept 99.9% of the time. We propose Perception-to-Pursuit (P2P), a track-centric temporal reasoning framework that bridges detection and actionable pursuit planning. Our method represents drone motion as compact 8-dimensional tokens capturing velocity, acceleration, scale, and smoothness, enabling a 12-frame causal transformer to reason about future behavior. We introduce the Intercept Success Rate (ISR) metric to measure pursuit feasibility under realistic interceptor constraints. Evaluated on the Anti-UAV-RGBT dataset with 226 real drone sequences, P2P achieves 28.12 pixel average displacement error and 0.597 ISR, representing a 77% improvement in trajectory prediction and 597x improvement in pursuit feasibility over tracking-only baselines, while maintaining perfect drone classification accuracy (100%). Our work demonstrates that temporal reasoning over motion patterns enables both accurate prediction and actionable pursuit planning.

</details>


### [168] [Self-Supervised Path Planning in Unstructured Environments via Global-Guided Differentiable Hard Constraint Projection](https://arxiv.org/abs/2601.19354)
*Ziqian Wang,Chenxi Fang,Zhen Zhang*

Main category: cs.RO

TL;DR: 提出了一种结合可微硬约束投影层的自监督学习框架，用于在算力受限的嵌入式设备上实现自主导航，通过全局引导人工势场解决数据稀疏问题，并通过自适应神经网络投影层保证安全性和实时性。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中部署深度学习用于自主导航时，面临安全、数据稀缺和计算资源有限等挑战。传统方法延迟高，而学习方法难以保证确定性可行性。需要弥合具身智能与嵌入式智能之间的差距。

Method: 提出一个自监督学习框架，包含一个可微分的硬约束投影层，用于运行时安全保障。构建全局引导人工势场（G-APF）以提供密集监督信号，解决数据稀缺问题。采用自适应神经网络投影层，迭代地将粗糙的网络输出投影到可行流形上，以满足执行器和几何约束。

Result: 在20,000个场景的基准测试中，成功率达到88.75%，验证了增强的操作安全性。在CARLA中的闭环实验证实了动态约束下的路径可行性。在NVIDIA Jetson Orin NX上的部署验证了94毫秒的推理延迟，证明了在资源受限嵌入式硬件上的实时可行性。

Conclusion: 该框架为将物理定律嵌入神经网络架构提供了一个通用的范例，为解决机电一体化中的约束优化问题提供了一个可行的方向，实现了在资源受限硬件上的安全、实时自主导航。

Abstract: Deploying deep learning agents for autonomous navigation in unstructured environments faces critical challenges regarding safety, data scarcity, and limited computational resources. Traditional solvers often suffer from high latency, while emerging learning-based approaches struggle to ensure deterministic feasibility. To bridge the gap from embodied to embedded intelligence, we propose a self-supervised framework incorporating a differentiable hard constraint projection layer for runtime assurance. To mitigate data scarcity, we construct a Global-Guided Artificial Potential Field (G-APF), which provides dense supervision signals without manual labeling. To enforce actuator limitations and geometric constraints efficiently, we employ an adaptive neural projection layer, which iteratively rectifies the coarse network output onto the feasible manifold. Extensive benchmarks on a test set of 20,000 scenarios demonstrate an 88.75\% success rate, substantiating the enhanced operational safety. Closed-loop experiments in CARLA further validate the physical realizability of the planned paths under dynamic constraints. Furthermore, deployment verification on an NVIDIA Jetson Orin NX confirms an inference latency of 94 ms, showing real-time feasibility on resource-constrained embedded hardware. This framework offers a generalized paradigm for embedding physical laws into neural architectures, providing a viable direction for solving constrained optimization in mechatronics. Source code is available at: https://github.com/wzq-13/SSHC.git.

</details>


### [169] [Teaching Machine Learning Fundamentals with LEGO Robotics](https://arxiv.org/abs/2601.19376)
*Viacheslav Sydora,Guner Dilsad Er,Michael Muehlebach*

Main category: cs.RO

TL;DR: 本研究提出了一个名为 Machine Learning with Bricks 的在线平台和配套课程，旨在通过编程无关的乐高机器人活动，向12-17岁的学生教授机器学习概念（KNN、线性回归、Q-learning）。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是让年轻学习者能够理解和接触机器学习概念，并对其产生积极的看法，同时通过可视化和实体互动的方式保持技术深度和趣味性。

Method: 该研究使用了一个开源的、结合了交互式可视化和乐高机器人的名为 Machine Learning with Bricks 的平台。学生通过收集数据、训练模型以及通过网页界面与机器人互动来学习。研究还设计了一个为期两天的课程。

Result: 一项包含14名学生的前后测调查显示，学生对机器学习算法的概念理解显著提高，对人工智能的看法发生积极转变，平台可用性高，学习动机增强。

Conclusion: 研究得出结论，这种基于实体和可视化方法的机器学习教学方式，能够有效地让年轻学习者接触和理解机器学习概念，同时保持技术深度并激发他们的学习兴趣。

Abstract: This paper presents the web-based platform Machine Learning with Bricks and an accompanying two-day course designed to teach machine learning concepts to students aged 12 to 17 through programming-free robotics activities. Machine Learning with Bricks is an open source platform and combines interactive visualizations with LEGO robotics to teach three core algorithms: KNN, linear regression, and Q-learning. Students learn by collecting data, training models, and interacting with robots via a web-based interface. Pre- and post-surveys with 14 students demonstrate significant improvements in conceptual understanding of machine learning algorithms, positive shifts in AI perception, high platform usability, and increased motivation for continued learning. This work demonstrates that tangible, visualization-based approaches can make machine learning concepts accessible and engaging for young learners while maintaining technical depth. The platform is freely available at https://learning-and-dynamics.github.io/ml-with-bricks/, with video tutorials guiding students through the experiments at https://youtube.com/playlist?list=PLx1grFu4zAcwfKKJZ1Ux4LwRqaePCOA2J.

</details>


### [170] [Judgelight: Trajectory-Level Post-Optimization for Multi-Agent Path Finding via Closed-Subwalk Collapsing](https://arxiv.org/abs/2601.19388)
*Yimin Tang,Sven Koenig,Erdem Bıyık*

Main category: cs.RO

TL;DR: Judgelight 是一种用于多智能体路径查找 (MAPF) 的后优化方法，它通过折叠闭合子路径来去除冗余运动，从而提高轨迹质量，并使用整数线性规划 (ILP) 进行求解，实验证明可将解决方案成本降低约 20%。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的 MAPF 求解器虽然可以快速生成可行的轨迹，但这些轨迹常常包含不必要的或振荡的运动，这不利于实际应用。

Method: 提出 Judgelight 作为一种后优化方法，通过 MAPF-Collapse 对 MAPF 求解器生成的轨迹进行处理。MAPF-Collapse 将轨迹中的闭合子路径折叠，以消除冗余，同时保持可行性。该过程被形式化为整数线性规划 (ILP) 问题并给出精确求解方法。

Result: Judgelight 能够一致地将解决方案成本降低约 20%，尤其是在与学习型 MAPF 求解器结合使用时，生成更优的轨迹。

Conclusion: Judgelight 是一种有效的后优化方法，可以显著提高 MAPF 求解器生成的轨迹质量，使其更适合实际部署。

Abstract: Multi-Agent Path Finding (MAPF) is an NP-hard problem with applications in warehouse automation and multi-robot coordination. Learning-based MAPF solvers offer fast and scalable planning but often produce feasible trajectories that contain unnecessary or oscillatory movements. We propose Judgelight, a post-optimization method that improves trajectory quality after a MAPF solver generates a feasible schedule. Judgelight collapses closed subwalks in agents' trajectories to remove redundant movements while preserving all feasibility constraints. We formalize this process as MAPF-Collapse, prove that it is NP-hard, and present an exact optimization approach by formulating it as integer linear programming (ILP) problem. Experimental results show Judgelight consistently reduces solution cost by around 20%, particularly for learning-based solvers, producing trajectories that are better suited for real-world deployment.

</details>


### [171] [Sim-and-Human Co-training for Data-Efficient and Generalizable Robotic Manipulation](https://arxiv.org/abs/2601.19406)
*Kaipeng Fang,Weiqing Liang,Yuyang Li,Ji Zhang,Pengpeng Zeng,Lianli Gao,Jingkuan Song,Heng Tao Shen*

Main category: cs.RO

TL;DR: 提出了一种名为SimHum的协同训练框架，通过结合模拟数据中的机器人动作信息和真实世界人类观察数据中的视觉信息，来弥合模拟到现实（sim-to-real）和人类到机器人（human-to-robot）的差距，从而提高机器人在真实任务中的数据效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 模拟数据缺乏真实世界机器人动作，而真实世界人类数据缺乏模拟数据中的机器人动作，这两种数据源之间存在互补性。现有的数据收集方法成本高昂，并且存在sim-to-real和human-to-robot的差距，限制了机器人的泛化能力。

Method: SimHum是一个协同训练框架，它同时从模拟机器人动作中提取运动学先验，并从真实世界人类观察中提取视觉先验。然后，利用这两个互补的先验来提高机器人操作的效率和泛化能力。

Result: SimHum在相同数据收集预算下，性能比基线方法提高了40%。在仅使用80个真实数据的情况下，SimHum实现了62.5%的OOD（out-of-distribution）成功率，比仅使用真实数据的方法提高了7.1倍。

Conclusion: SimHum框架能够有效地利用模拟和人类数据源的互补性，克服sim-to-real和human-to-robot的挑战，显著提高机器人在真实世界任务中的数据效率和泛化能力。

Abstract: Synthetic simulation data and real-world human data provide scalable alternatives to circumvent the prohibitive costs of robot data collection. However, these sources suffer from the sim-to-real visual gap and the human-to-robot embodiment gap, respectively, which limits the policy's generalization to real-world scenarios. In this work, we identify a natural yet underexplored complementarity between these sources: simulation offers the robot action that human data lacks, while human data provides the real-world observation that simulation struggles to render. Motivated by this insight, we present SimHum, a co-training framework to simultaneously extract kinematic prior from simulated robot actions and visual prior from real-world human observations. Based on the two complementary priors, we achieve data-efficient and generalizable robotic manipulation in real-world tasks. Empirically, SimHum outperforms the baseline by up to $\mathbf{40\%}$ under the same data collection budget, and achieves a $\mathbf{62.5\%}$ OOD success with only 80 real data, outperforming the real only baseline by $7.1\times$. Videos and additional information can be found at \href{https://kaipengfang.github.io/sim-and-human}{project website}.

</details>


### [172] [Task-Centric Policy Optimization from Misaligned Motion Priors](https://arxiv.org/abs/2601.19411)
*Ziang Zheng,Kai Feng,Yi Nie,Shentao Qin*

Main category: cs.RO

TL;DR: 提出了一种名为 TCMP 的新框架，通过将模仿作为一种条件正则化器而非平等的损失项，来改善人形机器人的控制。TCMP 能够在不损害任务表现的情况下，利用人类演示的自然运动风格，即使演示不完美。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人控制方法通常依赖人类演示的运动先验，但这些演示往往存在次优、不匹配或与任务无关的变化，导致直接模仿效果不佳。而仅关注任务的强化学习虽然能找到最优解，但动作可能不自然或不稳定。这暴露了现有对抗性模仿学习中线性奖励混合的局限性。

Method: 提出了一种名为“任务中心运动先验”（TCMP）的框架。TCMP 将模仿视为一种条件正则化器，而非与任务目标同等重要的损失项。它优先最大化任务的进步，仅在模仿信号与任务进展兼容时才引入模仿信号，从而实现自适应、几何感知的更新，保证了任务可行性下降，并抑制了因不匹配而带来的负面模仿。

Result: 理论分析了梯度冲突和任务优先不动点。在人形机器人控制实验中，TCMP 在存在噪声演示的情况下，实现了鲁棒的任务性能和一致的运动风格。

Conclusion: TCMP 框架成功地解决了现有模仿学习方法在处理不完美演示和任务目标冲突时的不足，能够生成既高效又自然的机器人运动。

Abstract: Humanoid control often leverages motion priors from human demonstrations to encourage natural behaviors. However, such demonstrations are frequently suboptimal or misaligned with robotic tasks due to embodiment differences, retargeting errors, and task-irrelevant variations, causing naïve imitation to degrade task performance. Conversely, task-only reinforcement learning admits many task-optimal solutions, often resulting in unnatural or unstable motions. This exposes a fundamental limitation of linear reward mixing in adversarial imitation learning. We propose \emph{Task-Centric Motion Priors} (TCMP), a task-priority adversarial imitation framework that treats imitation as a conditional regularizer rather than a co-equal objective. TCMP maximizes task improvement while incorporating imitation signals only when they are compatible with task progress, yielding an adaptive, geometry-aware update that preserves task-feasible descent and suppresses harmful imitation under misalignment. We provide theoretical analysis of gradient conflict and task-priority stationary points, and validate our claims through humanoid control experiments demonstrating robust task performance with consistent motion style under noisy demonstrations.

</details>


### [173] [Self-Reconfiguration Planning for Deformable Quadrilateral Modular Robots](https://arxiv.org/abs/2601.19496)
*Jie Gu,Hongrun Gao,Zhihao Xia,Yirun Sun,Chunxu Tian,Dan Zhang*

Main category: cs.RO

TL;DR: 提出了一种用于可变形四边形模块化自重构机器人(MSRRs)的自重构规划算法，该算法使用虚拟图和基于依赖的反向树来保证连接的稳定性，并通过实验证明了其效率和可行性。


<details>
  <summary>Details</summary>
Motivation: 对于模块化自重构机器人(MSRRs)，在重构过程中保持稳定的连接对于物理可行性和部署至关重要。

Method: 首先，使用虚拟图表示构建可行的连接/断开动作。然后，通过基于依赖的反向树(DRTree)将这些动作组织成有效的执行序列，以解决它们之间的相互依赖性。对于七个或更多模块（排除线性拓扑）的任意两个配置，证明了存在满足运动特性的重构序列。

Result: 与修改后的BiRRT算法相比，该算法显示出更高的效率和稳定性。在物理机器人平台上进行了部署，验证了其在实际应用中的可行性。

Conclusion: 该算法成功地为可变形四边形MSRRs提供了保证连接稳定性的自重构规划方法，并在效率、稳定性和实际可行性方面优于现有方法。

Abstract: For lattice modular self-reconfigurable robots (MSRRs), maintaining stable connections during reconfiguration is crucial for physical feasibility and deployability. This letter presents a novel self-reconfiguration planning algorithm for deformable quadrilateral MSRRs that guarantees stable connection. The method first constructs feasible connect/disconnect actions using a virtual graph representation, and then organizes these actions into a valid execution sequence through a Dependence-based Reverse Tree (DRTree) that resolves interdependencies. We also prove that reconfiguration sequences satisfying motion characteristics exist for any pair of configurations with seven or more modules (excluding linear topologies). Finally, comparisons with a modified BiRRT algorithm highlight the superior efficiency and stability of our approach, while deployment on a physical robotic platform confirms its practical feasibility.

</details>


### [174] [Reinforcement Learning Goal-Reaching Control with Guaranteed Lyapunov-Like Stabilizer for Mobile Robots](https://arxiv.org/abs/2601.19499)
*Mehdi Heydari Shahna,Seyed Adel Alizadeh Kolagar,Jouni Mattila*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的控制框架，通过引入Lyapunov类稳定器层来增强策略，为轮式移动机器人在非结构化环境中实现目标提供了正式的保证，并在实验中显著提高了目标达成率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在学习目标达成策略方面效果显著，但缺乏正式的保证。为了提供这种保证，通常需要引入一个安全约束机制，但其与强化学习的集成可能导致学习效率低下或过于保守。因此，研究的动机是开发一种能够提供正式目标达成保证，同时保持强化学习有效性的控制框架。

Method: 该框架包含两个主要部分：1. 设计了一个实时的强化学习策略，包含15个奖励项，以鼓励机器人达成静态和动态目标，并生成平滑的控制信号以满足安全规范。2. 集成了一个Lyapunov类稳定器层作为策略监督器，以正式增强目标达成控制，并保持有效的状态-动作空间探索。

Result: 实验结果表明，Lyapunov类稳定器层能够显著提升基准强化学习策略的性能。目标达成率从84.6%提高到99.0%，失败案例大幅减少，效率得到提高。

Conclusion: 所提出的强化学习控制框架通过Lyapunov类稳定器层，为轮式移动机器人在非结构化环境中实现了目标提供了正式的收敛保证，能够实时适应不确定性并遵守运动约束，从而有效提高了控制性能。

Abstract: Reinforcement learning (RL) can be highly effective at learning goal-reaching policies, but it typically does not provide formal guarantees that the goal will always be reached. A common approach to provide formal goal-reaching guarantees is to introduce a shielding mechanism that restricts the agent to actions that satisfy predefined safety constraints. The main challenge here is integrating this mechanism with RL so that learning and exploration remain effective without becoming overly conservative. Hence, this paper proposes an RL-based control framework that provides formal goal-reaching guarantees for wheeled mobile robots operating in unstructured environments. We first design a real-time RL policy with a set of 15 carefully defined reward terms. These rewards encourage the robot to reach both static and dynamic goals while generating sufficiently smooth command signals that comply with predefined safety specifications, which is critical in practice. Second, a Lyapunov-like stabilizer layer is integrated into the benchmark RL framework as a policy supervisor to formally strengthen the goal-reaching control while preserving meaningful exploration of the state action space. The proposed framework is suitable for real-time deployment in challenging environments, as it provides a formal guarantee of convergence to the intended goal states and compensates for uncertainties by generating real-time control signals based on the current state, while respecting real-world motion constraints. The experimental results show that the proposed Lyapunov-like stabilizer consistently improves the benchmark RL policies, boosting the goal-reaching rate from 84.6% to 99.0%, sharply reducing failures, and improving efficiency.

</details>


### [175] [A DVL Aided Loosely Coupled Inertial Navigation Strategy for AUVs with Attitude Error Modeling and Variance Propagation](https://arxiv.org/abs/2601.19509)
*Jin Huang,Zichen Liu,Haoda Li,Zhikun Wang,Ying Chen*

Main category: cs.RO

TL;DR: 本文提出了一种改进的SINS/DVL松耦合导航方法，通过考虑姿态误差和更准确的协方差传播来减少姿态误差对速度投影的影响，从而显著提高长期水下导航精度。


<details>
  <summary>Details</summary>
Motivation: 传统的SINS/DVL松耦合导航方法中，姿态估计误差会导致DVL速度投影产生偏差，从而在长期运行时降低导航性能。

Method: 提出了两种改进方法：1. 车辆姿态误差感知的DVL速度转换模型，将姿态误差项纳入观测方程；2. 基于协方差矩阵的方差传播方法，引入基于期望的姿态误差补偿项。

Result: 仿真和实地实验结果表明，两种改进方法单独使用都能提高导航精度，联合使用能有效抑制长期误差发散。与基线IMU+DVL方法相比，所提出的方法在3D位置RMSE方面提高了78.3%，最大分量位置误差降低了71.8%。

Conclusion: 本文提出的方法能有效补偿姿态误差对DVL速度投影及其不确定性的影响，提高了长期SINS/DVL导航的稳健性和精度。

Abstract: In underwater navigation systems, strap-down inertial navigation system/Doppler velocity log (SINS/DVL)-based loosely coupled architectures are widely adopted. Conventional approaches project DVL velocities from the body coordinate system to the navigation coordinate system using SINS-derived attitude; however, accumulated attitude estimation errors introduce biases into velocity projection and degrade navigation performance during long-term operation. To address this issue, two complementary improvements are introduced. First, a vehicle attitude error-aware DVL velocity transformation model is formulated by incorporating attitude error terms into the observation equation to reduce projection-induced velocity bias. Second, a covariance matrix-based variance propagation method is developed to transform DVL measurement uncertainty across coordinate systems, introducing an expectation-based attitude error compensation term to achieve statistically consistent noise modeling. Simulation and field experiment results demonstrate that both improvements individually enhance navigation accuracy and confirm that accumulated attitude errors affect both projected velocity measurements and their associated uncertainty. When jointly applied, long-term error divergence is effectively suppressed. Field experimental results show that the proposed approach achieves a 78.3% improvement in 3D position RMSE and a 71.8% reduction in the maximum component-wise position error compared with the baseline IMU+DVL method, providing a robust solution for improving long-term SINS/DVL navigation performance.

</details>


### [176] [ALRM: Agentic LLM for Robotic Manipulation](https://arxiv.org/abs/2601.19510)
*Vitor Gaboardi dos Santos,Ibrahim Khadraoui,Ibrahim Farhat,Hamza Yous,Samy Teffahi,Hakim Hacid*

Main category: cs.RO

TL;DR: 本文提出了一个名为 ALRM 的 LLM 驱动的机器人操作框架，该框架通过 ReAct 风格的推理循环整合了策略生成和代理执行，支持代码生成（CaP）和基于工具的执行（TaP）模式。为了系统评估，还引入了一个包含 56 个任务的新型模拟基准。实验表明 ALRM 是一个可扩展、可解释且模块化的方法，并将 Claude-4.1-Opus 和 Falcon-H1-7B 评为表现最佳的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 机器人控制方法在模块化、代理执行、闭环规划、反思和修正动作方面存在不足，并且现有基准缺乏对多步推理和语言变体的系统评估。

Method: 提出了 Agentic LLM for Robot Manipulation (ALRM) 框架，该框架利用 ReAct 风格的推理循环整合策略生成和代理执行。ALRM 包含两种模式：Code-as-Policy (CaP) 用于直接生成控制代码，Tool-as-Policy (TaP) 用于迭代规划和基于工具的动作执行。同时，构建了一个包含 56 个任务的新型模拟基准，用于系统评估。

Result: ALRM 提供了一种可扩展、可解释且模块化的方法，能够将自然语言推理与可靠的机器人执行相结合。在 CaP 模式下，Claude-4.1-Opus 和 Falcon-H1-7B 被证明是表现最佳的闭源和开源模型。

Conclusion: ALRM 是一个有效的 LLM 驱动的代理框架，能够实现机器人操作中的多步推理和闭环执行。提出的基准有助于对这类系统进行更全面的评估。

Abstract: Large Language Models (LLMs) have recently empowered agentic frameworks to exhibit advanced reasoning and planning capabilities. However, their integration in robotic control pipelines remains limited in two aspects: (1) prior \ac{llm}-based approaches often lack modular, agentic execution mechanisms, limiting their ability to plan, reflect on outcomes, and revise actions in a closed-loop manner; and (2) existing benchmarks for manipulation tasks focus on low-level control and do not systematically evaluate multistep reasoning and linguistic variation. In this paper, we propose Agentic LLM for Robot Manipulation (ALRM), an LLM-driven agentic framework for robotic manipulation. ALRM integrates policy generation with agentic execution through a ReAct-style reasoning loop, supporting two complementary modes: Code-asPolicy (CaP) for direct executable control code generation, and Tool-as-Policy (TaP) for iterative planning and tool-based action execution. To enable systematic evaluation, we also introduce a novel simulation benchmark comprising 56 tasks across multiple environments, capturing linguistically diverse instructions. Experiments with ten LLMs demonstrate that ALRM provides a scalable, interpretable, and modular approach for bridging natural language reasoning with reliable robotic execution. Results reveal Claude-4.1-Opus as the top closed-source model and Falcon-H1-7B as the top open-source model under CaP.

</details>


### [177] [SCOPE: Smooth Convex Optimization for Planned Evolution of Deformable Linear Objects](https://arxiv.org/abs/2601.19742)
*Ali Jnadi,Hadi Salloum,Yaroslav Kholodov,Alexander Gasnikov,Karam Almaghout*

Main category: cs.RO

TL;DR: SCOPE 是一个用于模拟和操作可变形线性对象 (DLO) 的快速高效框架，通过利用凸近似来降低计算成本，同时保持物理上可行的变形。


<details>
  <summary>Details</summary>
Motivation: 现有基于能量的方法计算成本高，而 SCOPE 旨在以较低的计算成本实现快速、物理上可行的 DLO 变形。

Method: 该框架使用凸近似来模拟和操作可变形线性对象，以提高速度和效率。

Result: SCOPE 能够生成平滑的形状轨迹，同时满足几何和长度约束，并在模拟实验中证明了其有效性。

Conclusion: SCOPE 是一个计算成本低、速度快且能够生成物理上可行变形的 DLO 模拟框架，适用于需要实时响应的应用。

Abstract: We present SCOPE, a fast and efficient framework for modeling and manipulating deformable linear objects (DLOs). Unlike conventional energy-based approaches, SCOPE leverages convex approximations to significantly reduce computational cost while maintaining smooth and physically plausible deformations. This trade-off between speed and accuracy makes the method particularly suitable for applications requiring real-time or near-real-time response. The effectiveness of the proposed framework is demonstrated through comprehensive simulation experiments, highlighting its ability to generate smooth shape trajectories under geometric and length constraints.

</details>


### [178] [PALM: Enhanced Generalizability for Local Visuomotor Policies via Perception Alignment](https://arxiv.org/abs/2601.19514)
*Ruiyu Wang,Zheyu Zhuang,Danica Kragic,Florian T. Pokorny*

Main category: cs.RO

TL;DR: PALM 是一种新颖的基于视觉的行为克隆方法，通过对局部动作分布进行对齐，有效解决了在训练域之外（OOD）进行泛化的问题，并取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 在图像驱动的行为克隆任务中，模型在训练域之外（OOD）表现不佳是一个普遍存在的挑战。现有方法通常孤立地解决不同泛化问题（如工作空间变化、视角变化、跨实体迁移），并且依赖复杂的流程。

Method: PALM 提出一种名为 PALM (Perception Alignment for Local Manipulation) 的方法，其核心思想是利用 OOD 和演示域之间局部动作分布的不变性。该方法将操作策略分解为全局组件和局部策略。通过强制执行局部视觉聚焦和一致的本体感受表示，PALM 在局部策略层面减小了域内和 OOD 输入之间的差异，从而使策略在 OOD 条件下能够检索不变的局部动作。该方法无需额外的输入模态、模型修改或数据收集。

Result: 实验结果表明，PALM 在模拟器中将 OOD 性能下降限制在 8%，在真实世界中为 24%。相比之下，基线方法在模拟器中的性能下降为 45%，在真实世界中为 77%。

Conclusion: PALM 能够同时解决多种 OOD 移位问题，并在不依赖额外数据或复杂模型修改的情况下，显著提高了行为克隆在 OOD 条件下的泛化能力。

Abstract: Generalizing beyond the training domain in image-based behavior cloning remains challenging. Existing methods address individual axes of generalization, workspace shifts, viewpoint changes, and cross-embodiment transfer, yet they are typically developed in isolation and often rely on complex pipelines. We introduce PALM (Perception Alignment for Local Manipulation), which leverages the invariance of local action distributions between out-of-distribution (OOD) and demonstrated domains to address these OOD shifts concurrently, without additional input modalities, model changes, or data collection. PALM modularizes the manipulation policy into coarse global components and a local policy for fine-grained actions. We reduce the discrepancy between in-domain and OOD inputs at the local policy level by enforcing local visual focus and consistent proprioceptive representation, allowing the policy to retrieve invariant local actions under OOD conditions. Experiments show that PALM limits OOD performance drops to 8% in simulation and 24% in the real world, compared to 45% and 77% for baselines.

</details>


### [179] [Rhombot: Rhombus-shaped Modular Robots for Stable, Medium-Independent Reconfiguration Motion](https://arxiv.org/abs/2601.19529)
*Jie Gu,Yirui Sun,Zhihao Xia,Tin Lun Lam,Chunxu Tian,Dan Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种名为Rhombot的新型可变形平面点阵模块化自重构机器人（MSRR），其模块形状为菱形，通过单执行器实现折叠和展开，能够以低控制复杂度实现变形、对接和移动等功能，并通过一种新的运动原语“morphpivoting”进行连续重构，实验验证了其稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 开发一种具有简单控制复杂度的模块化自重构机器人（MSRR），能够稳定可靠地在不同环境中实现变形、对接和移动等基本功能。

Method: 设计了菱形模块，每个模块包含一个平行四边形骨架和一个中心执行器，用于沿对角线折叠和展开。引入了新的重构运动原语“morphpivoting”及其连续执行策略。通过物理实验验证模块的稳定重构能力、位置和对接精度。

Result: Rhombot模块能够以最小的控制复杂度实现稳定、连续的变形、对接和移动。morphpivoting作为一种新颖的运动原语，能够实现系统的高效重构。物理实验验证了系统的稳定性和精确性。

Conclusion: Rhombot是一种成功的新型可变形平面点阵MSRR，其独特的模块设计和morphpivoting运动原语实现了低控制复杂度的稳定自重构，为MSRR领域提供了新的解决方案。

Abstract: In this paper, we present Rhombot, a novel deformable planar lattice modular self-reconfigurable robot (MSRR) with a rhombus shaped module. Each module consists of a parallelogram skeleton with a single centrally mounted actuator that enables folding and unfolding along its diagonal. The core design philosophy is to achieve essential MSRR functionalities such as morphing, docking, and locomotion with minimal control complexity. This enables a continuous and stable reconfiguration process that is independent of the surrounding medium, allowing the system to reliably form various configurations in diverse environments. To leverage the unique kinematics of Rhombot, we introduce morphpivoting, a novel motion primitive for reconfiguration that differs from advanced MSRR systems, and propose a strategy for its continuous execution. Finally, a series of physical experiments validate the module's stable reconfiguration ability, as well as its positional and docking accuracy.

</details>


### [180] [Enhancing Inverse Perspective Mapping for Automatic Vectorized Road Map Generation](https://arxiv.org/abs/2601.19536)
*Hongji Liu,Linwei Zheng,Yongjian Li,Mingkai Tang,Xiaoyang Yan,Ming Liu,Jun Ma*

Main category: cs.RO

TL;DR: 提出了一种低成本、统一的向量化道路地图绘制框架，通过增强逆透视变换（IPM）来处理车道线和地面标记，并联合优化IPM同调矩阵和车辆姿态，实现了近乎厘米级的精度。


<details>
  <summary>Details</summary>
Motivation: IPM在道路地图绘制中存在映射误差、对初始IPM同调矩阵和预测车辆姿态的准确性不高以及共面性假设的限制。本研究旨在克服这些限制，提高IPM在向量化道路地图绘制中的应用效果，提供一种成本效益高且精度增强的解决方案。

Method: 利用Catmull-Rom样条表示车道线，用多边形表示其他地面标记。实例分割结果用于细化样条控制点和多边形角点。联合优化IPM同调矩阵和车辆姿态。该框架还通过结合实例分割来克服IPM的共面性假设限制。

Result: 显著降低了IPM相关的映射误差，提高了初始IPM同调矩阵和预测车辆姿态的准确性。该框架能够生成近乎厘米级精度的自动高精度地图，并且优化的IPM矩阵精度可与手动校准相媲美，车辆姿态精度也得到显著提升。

Conclusion: 提出的增强IPM框架成功地应用于向量化道路地图绘制，实现了低成本、高精度和泛化能力。该方法能够有效地生成包含各种地面标记和车道线的道路地图，为自动驾驶等应用提供了有力的支持。

Abstract: In this study, we present a low-cost and unified framework for vectorized road mapping leveraging enhanced inverse perspective mapping (IPM). In this framework, Catmull-Rom splines are utilized to characterize lane lines, and all the other ground markings are depicted using polygons uniformly. The results from instance segmentation serve as references to refine the three-dimensional position of spline control points and polygon corner points. In conjunction with this process, the homography matrix of IPM and vehicle poses are optimized simultaneously. Our proposed framework significantly reduces the mapping errors associated with IPM. It also improves the accuracy of the initial IPM homography matrix and the predicted vehicle poses. Furthermore, it addresses the limitations imposed by the coplanarity assumption in IPM. These enhancements enable IPM to be effectively applied to vectorized road mapping, which serves a cost-effective solution with enhanced accuracy. In addition, our framework generalizes road map elements to include all common ground markings and lane lines. The proposed framework is evaluated in two different practical scenarios, and the test results show that our method can automatically generate high-precision maps with near-centimeter-level accuracy. Importantly, the optimized IPM matrix achieves an accuracy comparable to that of manual calibration, while the accuracy of vehicle poses is also significantly improved.

</details>


### [181] [AC^2-VLA: Action-Context-Aware Adaptive Computation in Vision-Language-Action Models for Efficient Robotic Manipulation](https://arxiv.org/abs/2601.19634)
*Wenda Yu,Tianshi Wang,Fengling Li,Jingjing Li,Lei Zhu*

Main category: cs.RO

TL;DR: 提出AC^2-VLA框架，通过感知当前视觉、语言和动作状态，自适应地进行计算复用、token剪枝和模型组件选择，实现高效机器人操作。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在实际部署中存在高延迟和高计算成本问题，且现有加速方法忽视了动作上下文的重要性。

Method: AC^2-VLA框架，基于动作上下文自适应地进行认知复用、token剪枝和选择性执行模型组件。训练方法采用动作引导的自蒸馏，以保留密集VLA策略的行为并实现结构化稀疏化。

Result: 在机器人操作基准测试中，AC^2-VLA实现了高达1.79倍的速度提升，FLOPs降低至密集基线的29.4%，同时保持了相当的任务成功率。

Conclusion: AC^2-VLA框架能够显著提高VLA模型在机器人操作中的效率，同时保持性能，并且其结构化稀疏化策略可以跨任务和环境迁移。

Abstract: Vision-Language-Action (VLA) models have demonstrated strong performance in robotic manipulation, yet their closed-loop deployment is hindered by the high latency and compute cost of repeatedly running large vision-language backbones at every timestep. We observe that VLA inference exhibits structured redundancies across temporal, spatial, and depth dimensions, and that most existing efficiency methods ignore action context, despite its central role in embodied tasks. To address this gap, we propose Action-Context-aware Adaptive Computation for VLA models (AC^2-VLA), a unified framework that conditions computation on current visual observations, language instructions, and previous action states. Based on this action-centric context, AC^2-VLA adaptively performs cognition reuse across timesteps, token pruning, and selective execution of model components within a unified mechanism. To train the adaptive policy, we introduce an action-guided self-distillation scheme that preserves the behavior of the dense VLA policy while enabling structured sparsification that transfers across tasks and settings. Extensive experiments on robotic manipulation benchmarks show that AC^2-VLA achieves up to a 1.79\times speedup while reducing FLOPs to 29.4% of the dense baseline, with comparable task success.

</details>


### [182] [Enhancing Worker Safety in Harbors Using Quadruped Robots](https://arxiv.org/abs/2601.19643)
*Zoe Betta,Davide Corongiu,Carmine Tommaso Recchiuto,Antonio Sgorbissa*

Main category: cs.RO

TL;DR: 研究提出了港口环境中用于基础设施检查的机器人解决方案的初步阶段，重点是识别关键区域并分析使用四足机器人进行检查的可行性。


<details>
  <summary>Details</summary>
Motivation: 为了提高工人的安全性和应对港口复杂运营环境的挑战，需要开发用于基础设施检查的机器人解决方案。

Method: 该研究首先识别港口环境中的关键区域，然后分析使用四足机器人检查这些区域的初步解决方案。

Result: 研究识别了港口环境中的关键区域，并分析了使用四足机器人进行检查的初步可行性。

Conclusion: 这项初步研究为在复杂的港口环境中开发用于基础设施检查的机器人系统奠定了基础，并强调了四足机器人在未来应用中的潜力。

Abstract: Infrastructure inspection is becoming increasingly relevant in the field of robotics due to its significant impact on ensuring workers' safety. The harbor environment presents various challenges in designing a robotic solution for inspection, given the complexity of daily operations. This work introduces an initial phase to identify critical areas within the port environment. Following this, a preliminary solution using a quadruped robot for inspecting these critical areas is analyzed.

</details>


### [183] [Reimagining Social Robots as Recommender Systems: Foundations, Framework, and Applications](https://arxiv.org/abs/2601.19761)
*Jin Huang,Fethiye Irmak Doğan,Hatice Gunes*

Main category: cs.RO

TL;DR: 本研究提出将推荐系统（RS）技术整合到社交机器人中，以克服现有方法在全面捕捉用户偏好、主动个性化交互和确保伦理责任方面的局限性。研究旨在建立一个通用的框架，促进RS和人机交互（HRI）社区的合作。


<details>
  <summary>Details</summary>
Motivation: 现有社交机器人个性化方法（如LLMs和RL）未能全面捕捉用户的长期、短期和细粒度偏好，也未能有效利用这些偏好来排名和选择动作、主动个性化交互以及确保伦理负责的适应。这促使研究者探索更有效的个性化方法。

Method: 研究者将推荐系统（RS）的范式与社交机器人对齐，识别出可增强社交机器人个性化的关键RS技术，并设计了模块化、即插即用的组件来实现RS技术的无缝集成。

Result: 本研究建立了一个将RS技术整合到社交机器人中的框架，为RS和HRI社区的深度合作开辟了道路，有望加速两个领域的创新。

Conclusion: 通过整合推荐系统技术，可以显著提升社交机器人在理解和满足用户偏好方面的能力，实现更主动、更负责任的个性化交互。该框架为未来社交机器人的个性化发展提供了新的方向。

Abstract: Personalization in social robots refers to the ability of the robot to meet the needs and/or preferences of an individual user. Existing approaches typically rely on large language models (LLMs) to generate context-aware responses based on user metadata and historical interactions or on adaptive methods such as reinforcement learning (RL) to learn from users' immediate reactions in real time. However, these approaches fall short of comprehensively capturing user preferences-including long-term, short-term, and fine-grained aspects-, and of using them to rank and select actions, proactively personalize interactions, and ensure ethically responsible adaptations. To address the limitations, we propose drawing on recommender systems (RSs), which specialize in modeling user preferences and providing personalized recommendations. To ensure the integration of RS techniques is well-grounded and seamless throughout the social robot pipeline, we (i) align the paradigms underlying social robots and RSs, (ii) identify key techniques that can enhance personalization in social robots, and (iii) design them as modular, plug-and-play components. This work not only establishes a framework for integrating RS techniques into social robots but also opens a pathway for deep collaboration between the RS and HRI communities, accelerating innovation in both fields.

</details>


### [184] [Whether We Care, How We Reason: The Dual Role of Anthropomorphism and Moral Foundations in Robot Abuse](https://arxiv.org/abs/2601.19826)
*Fan Yang,Renkai Ma,Yaxin Hu,Lingyao Li*

Main category: cs.RO

TL;DR: 本研究探讨了拟人化程度和道德基础如何影响人们对机器人遭受虐待的反应。结果表明，拟人化程度决定了人们是否对机器人产生道德考量，而道德基础则塑造了这些考量的推理方式。


<details>
  <summary>Details</summary>
Motivation: 随着机器人日益融入日常生活，理解人们对机器人遭受虐待的反应，对于机器人设计和伦理考量至关重要。

Method: 采用混合方法研究，让201名参与者观看不同拟人化程度（蜘蛛、双脚、人形）的机器人遭受身体虐待的视频，并完成道德基础、愤怒和社会距离测量。同时进行定性分析。

Result: 拟人化程度越高，人们越倾向于对机器人产生道德考量。低进步主义者倾向于基于角色进行评判，而高进步主义者则倾向于进行面向未来的道德考量。

Conclusion: 研究结果对机器人设计和政策宣传具有启示意义，强调了在设计和与公众沟通时需要考虑机器人的拟人化程度以及个体差异化的道德基础。

Abstract: As robots become increasingly integrated into daily life, understanding responses to robot mistreatment carries important ethical and design implications. This mixed-methods study (N = 201) examined how anthropomorphic levels and moral foundations shape reactions to robot abuse. Participants viewed videos depicting physical mistreatment of robots varying in humanness (Spider, Twofoot, Humanoid) and completed measures assessing moral foundations, anger, and social distance. Results revealed that anthropomorphism determines whether people extend moral consideration to robots, while moral foundations shape how they reason about such consideration. Qualitative analysis revealed distinct reasoning patterns: low-progressivism individuals employed character-based judgments, while high-progressivism individuals engaged in future-oriented moral deliberation. Findings offer implications for robot design and policy communication.

</details>


### [185] [Information-Theoretic Detection of Bimanual Interactions for Dual-Arm Robot Plan Generation](https://arxiv.org/abs/2601.19832)
*Elena Merlo,Marta Lagomarsino,Arash Ajoudani*

Main category: cs.RO

TL;DR: 该论文提出了一种新颖的单次方法，通过分析单个 RGB 视频中的信息流和场景图属性来检测双臂任务中的手部协调策略，并生成模块化的行为树来指导机器人执行。


<details>
  <summary>Details</summary>
Motivation: 为非专业人士简化机器人编程过程，特别是解决双臂任务中因手部协调复杂性和数据记录困难而未被充分探索的问题。

Method: 利用信息论（香农熵）分析场景元素之间的信息流，并结合场景图属性来检测手部协调策略。生成的执行计划是一个模块化的行为树，其结构会根据期望的双臂协调方式而变化。

Result: 通过分析单个 RGB 视频演示，成功生成了双臂机器人系统的执行计划。通过多位受试者的视频演示和公开数据集的验证，证明了该框架的有效性。与现有方法相比，在生成集中式双臂协调执行计划方面取得了显著的改进。

Conclusion: 该研究提出了一种有效的方法，利用信息论和场景图分析从单个视频演示中学习双臂任务的协调策略，并生成可执行的计划，为机器人编程的普及和双臂协作机器人任务的实现提供了新的解决方案。

Abstract: Programming by demonstration is a strategy to simplify the robot programming process for non-experts via human demonstrations. However, its adoption for bimanual tasks is an underexplored problem due to the complexity of hand coordination, which also hinders data recording. This paper presents a novel one-shot method for processing a single RGB video of a bimanual task demonstration to generate an execution plan for a dual-arm robotic system. To detect hand coordination policies, we apply Shannon's information theory to analyze the information flow between scene elements and leverage scene graph properties. The generated plan is a modular behavior tree that assumes different structures based on the desired arms coordination. We validated the effectiveness of this framework through multiple subject video demonstrations, which we collected and made open-source, and exploiting data from an external, publicly available dataset. Comparisons with existing methods revealed significant improvements in generating a centralized execution plan for coordinating two-arm systems.

</details>


### [186] [HARMONI: Multimodal Personalization of Multi-User Human-Robot Interactions with LLMs](https://arxiv.org/abs/2601.19839)
*Jeanne Malécot,Hamed Rahimi,Jeanne Cattoni,Marie Samson,Mouad Abrini,Mahdi Khoramshahi,Maribel Pino,Mohamed Chetouani*

Main category: cs.RO

TL;DR: HARMONI是一个多模态个性化框架，利用大型语言模型来增强社交辅助机器人在多用户环境中进行长期互动和动态适应的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人交互系统在多用户环境中缺乏持久的个性化和动态适应机制，限制了其在实际应用中的有效性。

Method: HARMONI框架包含四个模块：(i)感知模块（识别说话者和提取多模态输入）；(ii)世界建模模块（维护环境和短期对话上下文）；(iii)用户建模模块（更新长期说话者特定档案）；(iv)生成模块（生成上下文相关的、符合伦理的回应）。

Result: 通过在四个数据集和真实养老院环境中的评估，HARMONI支持鲁棒的说话者识别、在线记忆更新和符合伦理的个性化，在用户建模准确性、个性化质量和用户满意度方面优于基线方法。

Conclusion: HARMONI成功实现了社交辅助机器人在多用户环境中进行长期、动态和符合伦理的个性化互动。

Abstract: Existing human-robot interaction systems often lack mechanisms for sustained personalization and dynamic adaptation in multi-user environments, limiting their effectiveness in real-world deployments. We present HARMONI, a multimodal personalization framework that leverages large language models to enable socially assistive robots to manage long-term multi-user interactions. The framework integrates four key modules: (i) a perception module that identifies active speakers and extracts multimodal input; (ii) a world modeling module that maintains representations of the environment and short-term conversational context; (iii) a user modeling module that updates long-term speaker-specific profiles; and (iv) a generation module that produces contextually grounded and ethically informed responses. Through extensive evaluation and ablation studies on four datasets, as well as a real-world scenario-driven user-study in a nursing home environment, we demonstrate that HARMONI supports robust speaker identification, online memory updating, and ethically aligned personalization, outperforming baseline LLM-driven approaches in user modeling accuracy, personalization quality, and user satisfaction.

</details>


### [187] [Estimating Trust in Human-Robot Collaboration through Behavioral Indicators and Explainability](https://arxiv.org/abs/2601.19856)
*Giulio Campagna,Marta Lagomarsino,Marta Lorenzini,Dimitrios Chrysostomou,Matthias Rehm,Arash Ajoudani*

Main category: cs.RO

TL;DR: 本研究提出了一种数据驱动的框架，通过行为指标来评估和增强人机协作中的信任度，并在一个化学工业场景中进行了验证，机器学习模型在该场景下达到了80%以上的准确率。


<details>
  <summary>Details</summary>
Motivation: 为了实现工业5.0以人为本的人机协作，需要有效的方法来评估和提升人与机器人之间的信任度。

Method: 1. 提出一个数据驱动的框架来评估信任度，该框架使用行为指标。2. 利用基于偏好的优化算法生成能够增强信任度的轨迹，该算法基于操作员的反馈。3. 将操作员的反馈作为真实标签，训练机器学习模型，以从行为指标预测信任水平。4. 在化学工业场景中进行了测试。

Result: 在化学工业场景中，机器学习模型能够以超过80%的准确率对信任度进行分类，其中投票分类器（Voting Classifier）的准确率为84.07%，AUC-ROC得分为0.90。

Conclusion: 数据驱动的方法在评估人机协作中的信任度方面是有效的，行为指标在预测人类信任度的动态变化方面发挥着重要作用。

Abstract: Industry 5.0 focuses on human-centric collaboration between humans and robots, prioritizing safety, comfort, and trust. This study introduces a data-driven framework to assess trust using behavioral indicators. The framework employs a Preference-Based Optimization algorithm to generate trust-enhancing trajectories based on operator feedback. This feedback serves as ground truth for training machine learning models to predict trust levels from behavioral indicators. The framework was tested in a chemical industry scenario where a robot assisted a human operator in mixing chemicals. Machine learning models classified trust with over 80\% accuracy, with the Voting Classifier achieving 84.07\% accuracy and an AUC-ROC score of 0.90. These findings underscore the effectiveness of data-driven methods in assessing trust within human-robot collaboration, emphasizing the valuable role behavioral indicators play in predicting the dynamics of human trust.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [188] [3D-Printed Hybrid Liquid-CPCM Cooling Modules for High-Performance Thermal Management of Lithium-Ion Pouch Cells](https://arxiv.org/abs/2601.18959)
*Xuguang Zhanga,Michael C. Halbig,Amjad Almansour,Mrityunjay Singh,Meelad Ranaiefar,Yi Zheng*

Main category: eess.SY

TL;DR: 该研究提出了一种轻量级混合电池热管理系统（BTMS），通过3D打印技术将主动液冷与复合相变材料（CPCM）相结合，以提高锂离子软包电池（LIPCs）在高温高功率下的散热效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 在高温高功率条件下，传统的电池热管理系统在冷却效率、结构简易性和重量之间难以平衡，影响了锂离子软包电池的安全、性能和耐久性。

Method: 采用两步增材制造工艺，设计并制备了一种3D打印的六边形结构混合BTMS。该系统集成了主动液冷和复合相变材料（CPCM），通过精确的几何控制实现CPCM的密封封装和液冷通道的隔离，同时采用了纳米碳增强的CPCM以提高导热性。

Result: 六边形分区CPCM腔室最大化了CPCM壁的界面面积并缩短了内部传导路径，加速了潜热吸收。嵌入式蛇形液冷通道提供了持续的对流散热，并防止CPCM饱和。所提出的混合BTMS有效地消除了泄漏风险，并实现了轻量化。

Conclusion: 所提出的轻量级混合BTMS能够有效管理LIPCs在高温高功率下的热量，克服了传统BTMS的局限性，提高了LIPCs的安全性、性能和耐久性。

Abstract: Efficient thermal management is critical for ensuring the safety, performance, and durability of lithium ion pouch cells (LIPCs), particularly under high power operating conditions where conventional battery thermal management systems (BTMS) struggle to balance cooling effectiveness, structural simplicity, and weight. Here, we report a lightweight hybrid BTMS that synergistically integrates active liquid cooling with composite phase change material (CPCM) based thermal buffering through a 3D printed hexagonal architecture. The system is fabricated via a two step additive manufacturing process that enables sealed CPCM encapsulation and isolated liquid cooling pathways within a single carbon fiber reinforced nylon module, effectively eliminating leakage risks while allowing precise geometric control. Hexagonally partitioned CPCM cavities maximize the CPCM wall interfacial area and shorten internal conduction paths, accelerating latent heat absorption, while embedded serpentine liquid channels provide continuous convective heat removal and prevent CPCM saturation. A nanocarbon enhanced CPCM is employed to overcome the intrinsic low thermal conductivity of conventional paraffin based materials.

</details>


### [189] [Improving Stability Margins with Grid-Forming Damper Winding Emulation](https://arxiv.org/abs/2601.19000)
*Dahlia Saba,Dominic Groß*

Main category: eess.SY

TL;DR: 本文提出了一个用于验证具有线路和异构母线动态的电力系统小信号频率稳定性的框架，一个同步电机阻尼绕组的新型降阶模型，以及一种用于电压源换流器（VSC）的比例-导数（PD）阻尼绕组模拟控制。该研究表明，PD阻尼绕组模拟可以提高并网逆变器控制器的稳定性。


<details>
  <summary>Details</summary>
Motivation: 阻尼绕组的动态复杂，难以分析和在VSC控制中直接模拟，但它们能提高发电机间的频率同步。作者希望通过开发一个降阶模型和控制策略来解决这一挑战，并增强并网逆变器控制器的频率稳定性。

Method: 1. 推导了阻尼绕组的降阶模型，将其表示为一个PD项。
2. 开发了一个用于验证包含线路动态和异构母线动态的电力系统小信号频率稳定性的框架。
3. 设计了一种PD阻尼绕组模拟控制，用于并网逆变器。
4. 理论分析了PD阻尼绕组模拟对并网逆变器控制器稳定性的影响。
5. 使用电磁暂态（EMT）仿真对结果进行了验证。

Result: 1. 提出了一个适用于带线路动态和异构母线动态的电力系统的小信号频率稳定性验证框架。
2. 成功推导了阻尼绕组的降阶模型，能够被VSC用于模拟其效应。
3. 理论证明了PD阻尼绕组模拟可以提高并网逆变器控制器的稳定性。
4. EMT仿真验证了该框架和控制策略的有效性。

Conclusion: 本文提出的框架和PD阻尼绕组模拟控制能够有效地处理复杂电力系统的频率稳定性问题，并提高并网逆变器的同步性能，最终通过EMT仿真得到验证。

Abstract: This work presents (i) a framework for certifying small-signal frequency stability of a power system with line dynamics and heterogeneous bus dynamics, (ii) a novel reduced-order model of damper windings in synchronous machines, and (iii) a proportional-derivative (PD) damper winding emulation control for voltage-source converters (VSCs). Damper windings have long been understood to improve the frequency synchronization between machines. However, the dynamics of the damper windings are complex, making them difficult to analyze and directly emulate in the control of VSCs. This paper derives a reduced-order model of the damper windings as a PD term that allows grid-forming controls for VSCs to emulate their effect on frequency dynamics. Next, a framework for certifying small-signal frequency stability of a network with heterogeneous bus dynamics is developed that extends prior results by incorporating line dynamics. Finally, we analytically demonstrate that PD damper winding emulation can improve the stability of grid-forming converter controls. These results are validated with electromagnetic-transient (EMT) simulation.

</details>


### [190] [i-Socket: Design, Development, and Pilot Evaluation of an Individualized Multi-Material, Multi-Thickness Transtibial Prosthetic Socket](https://arxiv.org/abs/2601.19010)
*Noor Alhuda Ameen,Omid Arfaie,Ramazan Unal*

Main category: eess.SY

TL;DR: 本研究提出了一种多材料/多厚度的定制化胫骨下假肢袜套，通过优化材料和厚度分布，旨在提高舒适度和稳定性，减轻骨骼区域压力。


<details>
  <summary>Details</summary>
Motivation: 现有的假肢袜套在舒适度和稳定性方面存在不足，特别是对小腿区域的保护和骨骼区域的压力管理有待改进。

Method: 将袜套分为四个区域，根据压力敏感/耐受性确定不同区域的材料和厚度。通过压力-疼痛阈值（PPT）测试选择合适的材料和厚度，然后制作原型。与参与者现有袜套进行对比实验。

Result: 定制化袜套（i-Socket）比现有袜套轻22%。在截肢者实验中，胫骨和腓骨区域的内部压力分别降低了45%和31%。行走实验中，自选质心速度比文献相似研究提高了15%。膝关节和踝关节的运动学对称性分别提高了65%和2%。

Conclusion: 多材料/多厚度的定制化假肢袜套能够有效减轻胫骨下截肢者的压力，提高舒适度，并改善行走时的运动学表现。

Abstract: The prosthetic socket is an essential part in ensuring comfort and stability for the overall prosthesis system. This study proposes a multi-material/thickness individualized transtibial prosthetic socket that focuses on providing comfort. This study aims to identify the proper material and thickness to protect Calf areas and reduce the pressure around bone areas. First, the socket is divided into four parts depending on the pressure-sensitive/tolerant regions. After identifying the thickness range for each concerned area, the thickness and material are selected based on the Pressure-Pain Threshold (PPT) test, and the finalized design is then prototyped. The prototyped individualized socket (i-Socket) is 22% lighter than the participant's own socket. Results of the pilot experiments with an amputee participant showed that the pressure inside the socket decreased by 45% and 31% for the Tibia and Fibula regions, respectively. Additionally, the self-selected CoM velocity for the walking experiment is increased by 15% compared to the similar studies in the literature. Regarding the kinematic results, symmetry in the knee and ankle joints increased by 65% and 2% when using the i-Socket compared to the results with the participant's own socket.

</details>


### [191] [Machine Learning-Based Evaluation of Attitude Sensor Characteristics Using Microsatellite Flight Data](https://arxiv.org/abs/2601.19047)
*Yuji Sakamoto*

Main category: eess.SY

TL;DR: 该研究利用真实卫星飞行数据，采用基于卷积神经网络（Conv1D）的机器学习方法，显著提高了粗略姿态确定传感器的性能，将RMS误差从7度降低到0.7-3度。


<details>
  <summary>Details</summary>
Motivation: 传统的卫星姿态确定方法依赖于预定义的物理模型和白噪声假设，这可能无法充分捕捉真实观测数据中存在的结构性和非线性误差。因此，需要一种新的方法来提取和修正这些误差，以提高姿态确定性能。

Method: 研究人员使用了一颗已退役的50厘米级微卫星的实际飞行数据。他们将星敏感器和光纤陀螺（FOG）的高质量姿态确定结果作为地面真实值，并使用机器学习方法来处理太阳敏感器和磁力计等粗略姿态传感器的数据。具体采用了1D卷积神经网络（Conv1D）模型，通过短时间序列的传感器测量值来回归预测姿态。模型使用五组轨道观测数据进行训练和评估，其中四组用于训练，一组独立用于测试。

Result: 实验结果表明，与传统的TRIAD方法（RMS误差约7度）相比，提出的机器学习方法显著提高了姿态确定精度。在训练数据上，机器学习方法实现了约0.7度的RMS误差。在独立的测试数据上，根据传感器组合的不同，RMS误差约为2-3度。

Conclusion: 基于机器学习的方法，特别是Conv1D模型，能够有效地从真实卫星传感器数据中提取和修正结构性及非线性误差，从而显著提高粗略姿态确定传感器的性能，为未来卫星姿态确定提供了一种有前景的新途径。

Abstract: Using actual flight data from a 50-cm-class microsatellite whose mission and operations have already been completed, this study re-evaluates satellite attitude determination performance and the error characteristics of onboard attitude sensors. While conventional approaches rely on batch estimation or Kalman filtering based on predefined physical models and white-noise assumptions, this research introduces a machine-learning-based approach to extract and correct structural and nonlinear error patterns embedded in real observational data. In this study, high-quality attitude determination results obtained from star sensors and a fiber optical gyro (FOG) are treated as ground truth, and machine learning is applied to coarse attitude sensor data consisting of Sun sensors and magnetic field sensors. A one-dimensional convolutional neural network (Conv1D) is employed to regressively predict attitude from short sequences of time-series sensor measurements. The model is trained and evaluated using five sets of on-orbit observation logs, with four passes used for training and one independent pass used for testing. The results show that, while conventional coarse attitude determination using the TRIAD method yields attitude errors on the order of 7 deg RMS, the proposed machine-learning approach achieves RMS errors of approximately 0.7 deg for the training data and 2-3 deg for the test data, depending on the sensor combination.

</details>


### [192] [A Leader-Follower Approach for The Attitude Synchronization of Multiple Rigid Body Systems on $SO(3)$](https://arxiv.org/abs/2601.19086)
*Yiliang Li,Jun-e Feng,Abdelhamid Tayebi*

Main category: eess.SY

TL;DR: 该论文提出了一种分布式控制策略，用于解决异构刚体系统在SO(3)上实现领导者-跟随者姿态同步的问题，通信拓扑为无向、连通且无环图。该策略具有几乎全局渐近稳定性保证，可实现刚体系统与仅被单个刚体已知的恒定期望姿态同步。


<details>
  <summary>Details</summary>
Motivation: 解决异构刚体系统在SO(3)上实现领导者-跟随者姿态同步问题，目标是使所有跟随者系统能够同步到一个仅由领导者系统已知的恒定期望姿态。

Method: 提出了一种分布式控制策略，并利用图论和非线性控制理论分析了其性质，证明了该策略具有几乎全局渐近稳定性。

Result: 该控制策略能够实现异构刚体系统到恒定期望姿态的几乎全局渐近同步，即使期望姿态仅为领导者已知。

Conclusion: 提出的分布式控制策略能够有效地解决异构刚体系统在SO(3)上的领导者-跟随者姿态同步问题，并实现了几乎全局渐近稳定性。

Abstract: This paper deals with the leader-follower attitude synchronization problem for a group of heterogeneous rigid body systems on $SO(3)$ under an undirected, connected, and acyclic graph communication topology. The proposed distributed control strategy, endowed with almost global asymptotic stability guarantees, allows the synchronization of the rigid body systems to a constant desired orientation known only to a single rigid body. Some simulation results are also provided to validate the theoretical developments and illustrate the performance of the proposed control strategy.

</details>


### [193] [3D-Printed Passive Reflectors for mmWave Beam Steering via Binary Aperture Control](https://arxiv.org/abs/2601.19087)
*Mohammed E Eltayeb*

Main category: eess.SY

TL;DR: 本文提出了一种全被动毫米波波束控制框架，通过二进制空间掩码或衍射顺序来扩展室内覆盖。实验验证了该方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 扩展室内毫米波通信的覆盖范围，同时避免有源设备带来的功耗和成本问题。

Method: 1. 使用等效阵因子公式对反射孔径建模，考虑了入射角和出射角。 2. 提出两种被动设计方法：二进制（1-bit）空间掩码（通过ON/OFF金属化模式控制单元选择）和衍射顺序（周期性）转向（利用周期性控制衍射角）。 3. 理论分析了二进制掩码的激活行为和增益下界。 4. 制作了原型并进行了60 GHz的OTA测量。

Result: 二进制空间掩码和衍射顺序转向方法均可实现波束控制和多波束合成。原型在单波束和多波束配置下均验证了预测的转向行为。

Conclusion: 全被动、二进制编码的孔径能够提供确定性的波束控制，并为静态室内链路提供了一种可扩展的、低功耗的替代方案。

Abstract: This paper presents a theory-to-hardware framework for fully passive millimeter-wave beam control aimed at extending indoor coverage. The reflecting aperture is modeled using an equivalent array-factor formulation in which each passive element contributes a reradiated field determined by the incident and desired departure angles. Building on this model, we develop two implementation-friendly passive design approaches: (i) binary (1-bit) spatial masking, which enables beam steering and multi-beam synthesis by selecting element participation on a dense lattice via an ON/OFF metallization pattern, and (ii) diffraction-order (periodic) steering, which exploits controlled aperture periodicity to place selected diffraction orders at prescribed angles. Theoretical analysis characterizes the asymptotic activation behavior of the binary mask and establishes a distribution-free lower-bound on the achievable gain. Prototypes are realized using a copper-backed 3D-printed substrate with stencil-guided conductive ink deposition. 60 GHz over-the-air measurements in single- and multi-beam configurations validate the predicted steering behavior. Theoretical and experimental results demonstrate that fully passive, binary-coded apertures can provide deterministic beam control and offer a scalable alternative to power-consuming reconfigurable surfaces for static indoor links.

</details>


### [194] [Dual Analysis of Continuous-time Economic Dispatch and Its Price Implications](https://arxiv.org/abs/2601.19095)
*Menghan Zhang,Caisheng Wang*

Main category: eess.SY

TL;DR: 该研究提出了一种连续时间经济调度模型，用于更准确地反映供需平衡的实时价格信号，并分析了离散时间模型可能导致的效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 传统的离散时间经济调度模型无法捕捉瞬时的负荷和发电变化，导致其价格信号（对偶解）可能扭曲，从而产生低效的市场激励。因此，需要一个能提供更准确的连续时间价格信号的模型。

Method: 该研究开发了一个连续时间经济调度模型，并推导了其用于价格分析的对偶模型。通过参数规划方法构建了分段的时间索引发电和价格轨迹。价格被表示为系统范围功率平衡约束的拉格朗日乘数，并沿连续时间负荷曲线分段演变。此外，还讨论了单位特定的爬坡约束对价格的影响。

Result: 研究结果表明，连续时间发电和价格轨迹能够更深入地揭示离散时间模型中存在的价格扭曲和效率低下的激励。验证结果在一个5节点系统和改进的IEEE RTS-2019系统上进行了展示。

Conclusion: 连续时间经济调度模型能提供比传统离散时间模型更精确、更具洞察力的价格信号，从而更好地反映供需平衡并纠正离散时间模型中的效率低下问题。

Abstract: As load varies continuously over time, it is essential to provide continuous-time price signals that accurately reflect supply-demand balance. However, conventional discrete-time economic dispatch fails to capture the intra-temporal variations in load and generation. Its dual solution--the marginal price--may distort economic signals, leading to inefficient market incentives. To analyze these issues, this paper develops a continuous-time dispatch model and derives its dual formulation for price analysis. The continuous-time dispatch produces dual variables that can be interpreted as price signals. Piecewise time-indexed generation and price trajectories are then constructed through a parametric programming approach. The resulting price, represented by the Lagrange multiplier of the system-wide power balance constraint, evolves piecewise along the continuous-time load profile. Each segment corresponds to a critical region characterized by a set of active constraints. Furthermore, we discuss the impact of unit-specific ramping constraints on price implications. Results indicate that continuous-time generation and price trajectories provide deeper insights into the price distortions and inefficient incentives inherent in discrete-time formulations. The proposed methodology is validated on an illustrative 5-bus system and a modified IEEE RTS-2019.

</details>


### [195] [Structural Monotonicity in Transmission Scheduling for Remote State Estimation with Hidden Channel Mode](https://arxiv.org/abs/2601.19131)
*Hampei Sasahara*

Main category: eess.SY

TL;DR: 本文提出了一种用于在存在隐藏模式和不可靠信道的情况下进行远程状态估计的传输调度方法。该方法将问题建模为部分可观测马尔可夫决策过程（POMDP），并引入“状态空间折叠”技术来克服标准单调性分析的限制，最终证明了最优调度策略具有阈值结构。


<details>
  <summary>Details</summary>
Motivation: 传统的远程状态估计传输调度方法在处理具有隐藏模式和不可靠信道的复杂场景时面临挑战，特别是标准单调性分析方法在这种部分可观测情况下失效。

Method: 研究将传输调度问题建模为部分可观测马尔可夫决策过程（POMDP）。关键方法是引入“状态空间折叠”技术，通过变换得到恢复了顺序保持性质的转移核，从而能够在部分可观测设置下进行严格的单调性分析。

Result: 通过状态空间折叠技术，成功克服了部分可观测性对单调性分析的阻碍。作为重要推论，研究表明最优调度策略具有阈值结构。

Conclusion: 所提出的状态空间折叠技术是一种有效的分析部分可观测马尔可夫决策过程（POMDP）的方法，能够克服标准单调性分析的局限性。这为设计具有阈值结构的远程状态估计传输调度策略提供了理论基础。

Abstract: This study treats transmission scheduling for remote state estimation over unreliable channels with a hidden mode. A local Kalman estimator selects scheduling actions, such as power allocation and resource usage, and communicates with a remote estimator based on acknowledgement feedback, balancing estimation performance and communication cost. The resulting problem is naturally formulated as a partially observable Markov decision process (POMDP). In settings with observable channel modes, it is well known that monotonicity of the value function can be established via investigating order-preserving property of transition kernels. In contrast, under partial observability, the transition kernels generally lack this property, which prevents the direct application of standard monotonicity arguments. To overcome this difficulty, we introduce a novel technique, referred to as state-space folding, which induces transformed transition kernels recovering order preservation on the folded space. This transformation enables a rigorous monotonicity analysis in the partially observable setting. As a representative implication, we focus on an associated optimal stopping formulation and show that the resulting optimal scheduling policy admits a threshold structure.

</details>


### [196] [A Hybrid BLE-Wi-Fi Communication Architecture for Adaptive Imaging in Wireless Capsule Endoscopy](https://arxiv.org/abs/2601.19238)
*Ziyao Zhou,Zhuoran Sun,Chen Shen,Xinyi Shen,Zhehao Lu,Sikkandar,Hen-Wei Huang*

Main category: eess.SY

TL;DR: 本文提出了一种结合低功耗蓝牙（BLE）和WiFi的混合通信架构，以解决无线胶囊内窥镜（WCE）带宽和功耗的限制，从而提高图像质量和漏诊率，并实现能量高效的自适应成像。


<details>
  <summary>Details</summary>
Motivation: 无线胶囊内窥镜（WCE）受到无线带宽限制，导致图像分辨率和帧率低，易造成运动模糊和漏诊。现有自适应帧率方案牺牲了图像分辨率，而高频通信又受组织衰减限制。因此，需要一种兼顾低功耗和高吞吐量的解决方案。

Method: 提出了一种混合BLE和WiFi通信架构。通过在模拟组织条件下测量吞吐量、RSSI和功耗来评估BLE和WiFi的性能。开发了一种带有自适应传输功率控制的放大BLE方案，以及一种以站模式运行的2.4 GHz WiFi配置。引入了一个帧边界同步的切换机制来实现BLE和WiFi之间的无损数据传输。

Result: 放大BLE在低功耗下提供稳定的帧率，而2.4 GHz WiFi在站模式下提供高吞吐量。BLE功耗比WiFi低约10倍，而WiFi吞吐量比BLE高约10倍。BLE到WiFi的切换延迟约为92.66毫秒，WiFi到BLE的切换延迟为15.49毫秒（传输10KB图像负载时）。

Conclusion: 提出的混合BLE和WiFi系统实现了鲁棒、无损、能量高效的模式切换，支持自适应成像，并推动了下一代自主WCE平台的发展。

Abstract: Wireless capsule endoscopy (WCE) is fundamentally constrained by limited wireless bandwidth, resulting in low imaging resolution and frame rate, which can cause motion blur and missed lesions. Although adaptive frame-rate schemes have been explored to accommodate transient gastrointestinal (GI) motility, these approaches typically require sacrificing image resolution. The use of higher-frequency communication bands is further limited by increased tissue attenuation. To address these challenges, we propose a hybrid Bluetooth Low Energy (BLE) and WiFi communication architecture that combines the low-power operation of BLE with the high data throughput of WiFi. We systematically evaluate the performance of BLE and WiFi under tissue-mimicking conditions by measuring throughput, received signal strength indicator (RSSI), and power consumption. The results demonstrate that amplified BLE with an adaptive transmission power control strategy provides a stable frame rate at low power consumption, while 2.4 GHz WiFi operating in station mode is the most suitable high-throughput communication configuration for WCE. Compared with WiFi, BLE reduces power consumption by approximately ten times, whereas WiFi achieves up to ten times higher throughput. To reconcile these complementary trade-offs, we further introduce a hybrid system with a frame-boundary-synchronized switching mechanism to ensure lossless data transmission during BLE and WiFi transitions. Experimental results show that the switching latency from BLE to WiFi is approximately 92.66 ms, which is longer than the WiFi-to-BLE switching latency of 15.49 ms when transmitting 10 kB image payloads. Overall, the proposed hybrid BLE and WiFi system enables robust, lossless, and energy-efficient mode switching, supports adaptive imaging, and advances the development of next-generation autonomous WCE platforms.

</details>


### [197] [Reevaluating Bluetooth Low Energy for Ingestible Electronics](https://arxiv.org/abs/2601.19241)
*Ziyao Zhou,Zhuoran Sun,Xinyi Shen,Yang Li,Zhenhao Shi,Yixuan Yu,Hen-Wei Huang*

Main category: eess.SY

TL;DR: 通过引入射频放大器和优化配置，蓝牙低功耗（BLE）可以克服组织衰减的挑战，在能量效率、吞吐量、延迟和系统集成方面优于亚GHz通信，适用于下一代可食电子设备。


<details>
  <summary>Details</summary>
Motivation: 可食电子设备通常面临组织在2.4 GHz频段的严重衰减问题，阻碍了蓝牙低功耗（BLE）在该领域的广泛应用。研究旨在重新评估BLE在可食电子设备中的可行性。

Method: 通过对比BLE和代表性的亚GHz通信方案，在功耗、吞吐量、组织衰减、延迟和系统集成约束等方面进行基准测试。引入射频放大器，量化吞吐量与能耗的关系，并测量端到端延迟，分析天线尺寸和生态系统集成。

Result: 引入射频放大器后，BLE能够通过组织模拟介质保持通信，同时保持良好的能效。对于吞吐量低于100 kbps的应用，BLE的功耗显著低于亚GHz方案。BLE的端到端延迟也低于亚GHz方案。BLE在天线尺寸和生态系统集成方面具有优势。

Conclusion: 经过适当配置，BLE是下一代可食电子设备的有竞争力且可扩展的无线通信解决方案，克服了组织衰减的限制，并在多项性能指标上优于亚GHz方案。

Abstract: Bluetooth Low Energy (BLE) has been widely adopted in wearable devices; however, it has not been widely used in ingestible electronics, primarily due to concerns regarding severe tissue attenuation at the 2.4 GHz band. In this work, we systematically reevaluate the feasibility of BLE for ingestible applications by benchmarking its performance against representative sub-GHz communication schemes across power consumption, throughput, tissue-induced attenuation, latency, and system-level integration constraints. We demonstrate that incorporating an RF amplifier enables BLE to maintain robust communication links through tissue-mimicking media while preserving favorable energy efficiency. We further quantify the relationship between throughput and energy consumption over a wide operating range and demonstrate that, for the majority of ingestible sensing applications with throughput requirements below 100 kbps, BLE achieves substantially lower power consumption than sub-GHz alternatives. End-to-end latency measurements show that BLE offers significantly lower latency than sub-GHz solutions due to its native compatibility with modern computing infrastructure. Finally, we analyze antenna form factor and ecosystem integration, highlighting the mechanical and translational advantages of BLE in ingestible system design. Collectively, these results demonstrate that BLE, when appropriately configured, represents a compelling and scalable wireless communication solution for next-generation ingestible electronics.

</details>


### [198] [Output Feedback Stabilization of Linear Systems via Policy Gradient Methods](https://arxiv.org/abs/2601.19284)
*Ankang Zhang,Ming Chi,Xiaoling Wang,Lintao Ye*

Main category: eess.SY

TL;DR: 本文提出了一种基于策略梯度（PG）方法的框架，用于在模型未知且仅有部分状态可观测的情况下，通过输出反馈稳定离散时间线性动力系统。该方法利用零阶PG更新，并分析了其样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有针对未知线性动力系统的模型无关强化学习方法（如策略梯度）大多假设完全状态反馈，但实际应用中往往只能获得部分状态信息，因此研究输出反馈下的系统稳定问题具有重要意义。

Method: 提出了一种基于零阶策略梯度更新的算法框架，该框架利用系统轨迹进行更新，并利用其收敛到平稳点的特性来学习输出反馈策略。该方法不提供全局收敛保证。

Result: 所提出的算法能够为离散时间线性动力系统找到一个稳定的输出反馈策略。文章明确了算法的样本复杂度，并通过数值例子验证了算法的有效性。

Conclusion: 该研究扩展了策略梯度方法在部分可观测系统和输出反馈条件下的应用范围，为模型无关的动力系统稳定化问题提供了一种新的解决方案，并对其性能进行了理论分析和实验验证。

Abstract: Stabilizing a dynamical system is a fundamental problem that serves as a cornerstone for many complex tasks in the field of control systems. The problem becomes challenging when the system model is unknown. Among the Reinforcement Learning (RL) algorithms that have been successfully applied to solve problems pertaining to unknown linear dynamical systems, the policy gradient (PG) method stands out due to its ease of implementation and can solve the problem in a model-free manner. However, most of the existing works on PG methods for unknown linear dynamical systems assume full-state feedback. In this paper, we take a step towards model-free learning for partially observable linear dynamical systems with output feedback and focus on the fundamental stabilization problem of the system. We propose an algorithmic framework that stretches the boundary of PG methods to the problem without global convergence guarantees. We show that by leveraging zeroth-order PG update based on system trajectories and its convergence to stationary points, the proposed algorithms return a stabilizing output feedback policy for discrete-time linear dynamical systems. We also explicitly characterize the sample complexity of our algorithm and verify the effectiveness of the algorithm using numerical examples.

</details>


### [199] [Eco-Driving Control for Electric Vehicles with Multi-Speed Transmission: Optimizing Vehicle Speed and Powertrain Operation in Dynamic Environments](https://arxiv.org/abs/2601.19340)
*Suiyi He,Zongxuan Sun*

Main category: eess.SY

TL;DR: 提出了一种针对多速电动汽车的生态驾驶算法，通过协同优化车辆速度和动力总成运行来最大化能效，并考虑了基于车联网的交通预测以确保安全和交通顺畅，经仿真和实测验证，能耗降低高达11.36%。


<details>
  <summary>Details</summary>
Motivation: 现有研究在电动汽车生态驾驶方面存在不足，尤其是在多速变速箱和动态交通环境下的优化问题。该研究旨在开发一种能够同时优化车辆速度和动力总成运行，以提高能效并确保交通安全和顺畅的算法。

Method: 将生态驾驶问题建模为一个协同优化问题，同时优化车辆纵向速度和动力总成运行以最大化能效。利用基于车联网的交通预测算法来确保交通安全和交通流量的平稳性。通过简化复杂的非线性混合整数问题，实现了算法的计算效率，以便于实时实现。

Result: 在SUMO仿真和真实道路测试中，所提出的控制器在18公里的行驶距离上，能量消耗减少了高达11.36%。

Conclusion: 所提出的生态驾驶算法能够有效地优化多速电动汽车的能效，同时兼顾交通安全和交通流的平稳性，并且具有实时实现的计算效率。

Abstract: This article presents an eco-driving algorithm for electric vehicles featuring multi-speed transmissions. The proposed controller is formulated as a co-optimization problem, simultaneously optimizing both vehicle longitudinal speed and powertrain operation to maximize energy efficiency. Constraints derived from a connected vehicle based traffic prediction algorithm are used to ensure traffic safety and smooth traffic flow in dynamic environments with multiple signalized intersections and mixed traffic. By simplifying the complex, nonlinear mixed integer problem, the proposed controller achieves computational efficiency, enabling real-time implementation. To evaluate its performance, traffic scenarios from both Simulation of Urban MObility (SUMO) and real-world road tests are employed. The results demonstrate a notable reduction in energy consumption by up to 11.36\% over an \SI{18}{\km} drive.

</details>


### [200] [Physical Human-Robot Interaction: A Critical Review of Safety Constraints](https://arxiv.org/abs/2601.19462)
*Riccardo Zanella,Federico Califano,Stefano Stramigioli*

Main category: eess.SY

TL;DR: 本文深入分析了ISO/TS 15066中物理人机交互的安全约束，阐明了其推导过程、潜在假设、对安全性和性能的影响，并提出了可调整的设计参数，同时强调了能量在安全评估中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究ISO/TS 15066安全约束的获取方式和假设，旨在为理解和应用这些约束提供清晰、严谨的认识，从而指导实际的安全控制设计。

Method: 通过审视安全约束的推导过程和基本假设，分析简化模型对安全和性能的影响，提供数值示例量化近似和设计选择带来的性能下降，并重点关注基于能量的安全方法。

Result: 揭示了关键简化假设的解释及其对系统安全和性能的实际影响，量化了常见近似和设计选择导致的性能退化，并强调了能量在安全评估中的基础性作用。

Conclusion: 本研究加深了对ISO/TS 15066安全约束背后假设的理解，为设计安全关键的控制系统提供了可调整的设计参数和量化分析，并突出了能量在人机交互安全评估中的重要性。

Abstract: This paper aims to provide a clear and rigorous understanding of commonly recognized safety constraints in physical human-robot interaction, i.e. ISO/TS 15066, by examining how they are obtained and which assumptions support them. We clarify the interpretation and practical impact of key simplifying assumptions, show how these modeling choices affect both safety and performance across the system, and indicate specific design parameters that can be adjusted in safety-critical control implementations. Numerical examples are provided to quantify performance degradation induced by common approximations and simplifying design choices. Furthermore, the fundamental role of energy in safety assessment is emphasized, and focused insights are offered on the existing body of work concerning energy-based safety methodologies.

</details>


### [201] [Improved Initialization for Port-Hamiltonian Neural Network Models](https://arxiv.org/abs/2601.19617)
*G. J. E. van Otterdijk,S. Weiland,M. Schoukens*

Main category: eess.SY

TL;DR: 本文提出了一种改进的Port-Hamiltonian神经网络初始化方法，通过先估计一个线性的Port-Hamiltonian系统作为初始值，然后让神经网络学习非线性，以解决训练易陷入局部最小值的问题，并提高了收敛性和效率。


<details>
  <summary>Details</summary>
Motivation: Port-Hamiltonian神经网络在识别复杂系统非线性动力学方面表现出色，但其训练过程中的非凸优化问题容易导致模型收敛到局部最小值，从而影响模型性能。

Method: 首先通过估计一个线性的Port-Hamiltonian系统来初始化Port-Hamiltonian神经网络，然后利用该初始化模型进行训练，使神经网络适应系统的非线性。

Result: 在链式质量-弹簧-阻尼器的设置上，该方法在不同噪声水平下进行了测试，并与原始方法进行了比较，结果显示该方法能够减少训练时间并提高收敛性。

Conclusion: 所提出的改进初始化方法能够有效解决Port-Hamiltonian神经网络训练中因局部最小值导致的性能问题，提高模型的收敛速度和准确性。

Abstract: Port-Hamiltonian neural networks have shown promising results in the identification of nonlinear dynamics of complex systems, as their combination of physical principles with data-driven learning allows for accurate modelling. However, due to the non-convex optimization problem inherent in learning the correct network parameters, the training procedure is prone to converging to local minima, potentially leading to poor performance. In order to avoid this issue, this paper proposes an improved initialization for port-Hamiltonian neural networks. The core idea is to first estimate a linear port-Hamiltonian system to be used as an initialization for the network, after which the neural network adapts to the system nonlinearities, reducing the training times and improving convergence. The effectiveness of this method is tested on a chained mass-spring-damper setup for varying noise levels and compared to the original approach.

</details>


### [202] [Data-Driven Predictive Control for Wide-Area Power Oscillation Damping](https://arxiv.org/abs/2601.19638)
*Giacomo Mastroddi,Jan Poland,Mats Larsson,Keith Moffat*

Main category: eess.SY

TL;DR: 本研究探讨了使用基于电压源换流器的高压直流输电（VSC-HVDC）链路阻尼电力系统中区域间振荡的方法。研究了数据驱动预测控制（DPC）及其ARX和TPC变体，并与DeePC和两种基于模型的控制器进行了比较。结果表明，ARX-based预测控制和DeePC都能有效阻尼振荡，且ARX-based方法计算速度更快。


<details>
  <summary>Details</summary>
Motivation: 传统电力振荡阻尼控制器依赖于难以获得的系统模型。数据驱动预测控制（DPC）旨在克服这一限制，用数据替代显式模型。

Method: 将基于自回归外生输入（ARX）的预测控制及其瞬态预测控制（TPC）变体应用于VSC-HVDC链路，并与数据赋能预测控制（DeePC）以及两种标准模型控制方法进行了比较。在包含区域间和局部振荡模式的系统仿真中进行评估。

Result: ARX-based预测控制和DeePC均实现了有效的振荡阻尼。ARX-based方法所需的在线计算量较少，使用预分解的算子分裂求解器，可在1毫秒内完成控制计算。

Conclusion: 对于所测试的系统，数据驱动预测控制（DPC）是阻尼电力系统振荡的一种可行方法。

Abstract: We study damping of inter-area oscillations in transmission grids using voltage-source-converter-based high-voltage direct-current (VSC-HVDC) links. Conventional power oscillation damping controllers rely on system models that are difficult to obtain in practice. Data-driven Predictive Control (DPC) addresses this limitation by replacing explicit models with data. We apply AutoRegressive with eXogenous inputs (ARX)-based predictive control and its Transient Predictive Control (TPC) variant, and compare them with Data-enabled Predictive Control (DeePC) and two standard model-based controllers. The methods are evaluated in simulation on a system exhibiting both inter-area and local oscillation modes. ARX-based predictive control and DeePC both achieve effective damping, while the ARX-based methods require less online computation. Using warm-started, pre-factorized operator-splitting solvers, ARX/TPC control actions are computed in less than 1ms. These results demonstrate that DPC is a viable approach for power-system oscillation damping for the given test case.

</details>


### [203] [Frequency Shaping Control for Oscillation Damping in Weakly-Connected Power Network: A Root Locus Method](https://arxiv.org/abs/2601.19665)
*Yan Jiang,Wei Chen,Zhaomin Lyu,Xunning Zhang,Dan Wang,Shinji Hara*

Main category: eess.SY

TL;DR: 本文提出了一种基于模态分解和根轨迹分析的频率整形控制（FS）方法，用于改善弱电网条件下的频率稳定性和阻尼比、衰减率等振荡稳定性指标。该方法能够同时满足频率安全和振荡稳定性的要求，并优于传统的虚拟惯量控制（VI）。


<details>
  <summary>Details</summary>
Motivation: 在弱电网条件下，仅关注COI频率不足以应对频率偏差和区域间振荡。需要一种方法来同时保证频率安全和振荡稳定性。

Method: 采用模态分解将振荡阻尼问题转化为标量子系统的极点配置问题，并通过分析与主模态相关的标量子系统的根轨迹来解决。推导出FS下阻尼比和衰减率的闭式表达式，并提出易于实现的FS调优指南。

Result: FS能够实现无下降值的COI频率响应，并能通过简单的调优保证COI频率的一阶响应收敛到安全范围内，同时保证区域间振荡的阻尼比和衰减率。FS在指数收敛速率上优于VI。

Conclusion: 所提出的基于根轨迹的振荡稳定性分析方法为FS参数调优提供了理论基础和实用指南，实现了频率安全和振荡稳定性的双重保障，在弱电网条件下是优于VI的有效控制策略。

Abstract: Frequency control following a contingency event is of vital concern in power system operations. Leveraging inverter-based resources, it is not hard to shape the center of inertia (COI) frequency nicely. However, under weak grid conditions, it becomes insufficient to solely shape the COI frequency since this aggregate signal fails to reveal the inter-area oscillations. In this manuscript, we advocate for foolproof fine-tuning rules for \emph{frequency shaping control} (FS) based on a systematic analysis of damping ratio and decay rate of inter-area oscillations to simultaneously meet specified metrics for frequency security and oscillatory stability. To this end, building on a modal decomposition, we simplify the oscillation damping problem into a pole-placement task for a set of scalar subsystems, which can be efficiently solved by only investigating the root locus of a scalar subsystem associated with the main mode, while FS inherently guarantees a Nadir-less COI frequency response. Through our proposed root-locus-based oscillatory stability analysis, we derive closed-form expressions for the minimum damping ratio and decay rate among inter-area oscillations in terms of networked system and control parameters under FS. Moreover, we propose useful tuning guidelines for FS which need only simple calculations or visualized tuning to not only shape the COI frequency into a first-order response that converges to a steady-state value within the allowed range but also ensure a satisfactory damping ratio and decay rate of inter-area oscillations following disturbances. As for the common virtual inertia control (VI), although similar oscillatory stability analysis becomes intractable, one can still glean some insights via the root locus method. Numerical simulations validate the proposed tuning for FS as well as the superiority of FS over VI in exponential convergence rate.

</details>


### [204] [A Latent Space Framework for Modeling Transient Engine Emissions Using Joint Embedding Predictive Architectures](https://arxiv.org/abs/2601.19822)
*Ganesh Sundaram,Tobias Gehra,Jonas Ulmen,Mirjan Heubaum,Daniel Görges,Michael Günthner*

Main category: eess.SY

TL;DR: 本文提出了一种基于联合嵌入预测架构（JEPA）的新方法，用于精确建模和控制瞬态工况下的车辆排放。该方法通过结构化潜在空间学习排放动力学，显著提高了数据效率和预测精度，且计算量低，适用于车载部署。


<details>
  <summary>Details</summary>
Motivation: 传统的基于数据驱动的排放模型（如MLP和LSTM）在处理瞬态工况下的复杂非线性排放动力学时存在困难，计算成本高且对数据集敏感，限制了其实际应用。因此，需要一种更有效、更鲁棒的模型来满足环保法规和优化动力总成。

Method: 该研究采用联合嵌入预测架构（JEPA）来建模排放动力学。JEPA框架从真实的PEMS数据和硬件在环（HIL）测量数据中学习，将关键排放影响因素编码到紧凑、鲁棒的潜在空间表示中，忽略不相关噪声。此外，该框架支持模型剪枝和后训练量化，以降低计算成本。

Result: JEPA框架在多种瞬态工况下表现出优于高性能LSTM基线的预测精度和泛化能力。通过剪枝和量化，模型的推理时间和内存需求显著降低，而精度损失极小。

Conclusion: JEPA方法为下一代汽车提供了一种强大的、计算效率高的排放控制系统解决方案，适用于车载模型预测控制或基于模型的强化学习等先进策略，有助于满足环保法规并优化动力总成性能。

Abstract: Accurately modeling and controlling vehicle exhaust emissions during transient events, such as rapid acceleration, is critical for meeting environmental regulations and optimizing powertrains. Conventional data-driven methods, such as Multilayer Perceptrons (MLPs) and Long Short-Term Memory (LSTM) networks, improve upon phenomenological models but often struggle with the complex nonlinear dynamics of emission formation. These monolithic architectures are sensitive to dataset variability and typically require deep, computationally expensive structures to perform well, limiting their practical utility. This paper introduces a novel approach that overcomes these limitations by modeling emission dynamics within a structured latent space. Leveraging a Joint Embedding Predictive Architecture (JEPA), the proposed framework learns from a rich dataset that combines real-world Portable Emission Measurement System (PEMS) data with high-frequency hardware-in-the-loop measurements. The model abstracts away irrelevant noise, encoding only the key factors governing emission behavior into a compact, robust representation. This results in superior data efficiency and predictive accuracy across diverse transient regimes, significantly outperforming high-performing LSTM baselines in generalization. To ensure suitability for real-world deployment, the JEPA framework is structured to support pruning and post-training quantization. This strategy drastically reduces the computational footprint, minimizing inference time and memory demand with negligible accuracy loss. The result is a highly efficient model ideal for on-board implementation of advanced strategies, such as model predictive control or model-based reinforcement learning, in conventional and hybrid powertrains. These findings offer a clear pathway toward more robust emission control systems for next-generation vehicles.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [205] [Lossy Image Compression -- A Frequent Sequence Mining perspective employing efficient Clustering](https://arxiv.org/abs/2601.18821)
*Avinash Kadimisetty,Oswald C,Sivaselvan B,Alekhya Kadimisetty*

Main category: eess.IV

TL;DR: 本文提出了一种基于频繁序列挖掘和K-均值聚类的方法，用于无损图像压缩，以提高压缩比和图像质量。


<details>
  <summary>Details</summary>
Motivation: 旨在改进图像压缩领域中频繁序列挖掘的应用范围，特别是在处理冗余数据方面，并寻求比现有方法更好的压缩比和图像质量。

Method: 将JPEG中的DCT变换替换为闭频繁序列挖掘和K-均值聚类的组合。K-均值聚类并行应用于图像每个分量的所有块，以减少压缩时间。对GSP算法进行了优化，通过一种新的剪枝策略来降低模式的基数，从而减小码表大小。

Result: 与现有方法相比，所提出的算法在压缩比和图像质量方面均取得了显著的提升。

Conclusion: 将频繁序列挖掘与K-均值聚类结合，并优化GSP算法，能够有效地处理图像压缩中的冗余数据，实现更好的压缩性能和图像质量。

Abstract: This work explores the scope of Frequent Sequence Mining in the domain of Lossy Image Compression. The proposed work is based on the idea of clustering pixels and using the cluster identifiers in the compression. The DCT phase in JPEG is replaced with a combination of closed frequent sequence mining and k-means clustering to handle the redundant data effectively. This method focuses mainly on applying k-means clustering in parallel to all blocks of each component of the image to reduce the compression time. Conventional GSP algorithm is refined to optimize the cardinality of patterns through a novel pruning strategy, thus achieving a good reduction in the code table size. Simulations of the proposed algorithm indicate significant gains in compression ratio and quality in relation to the existing alternatives.

</details>


### [206] [OCTA-Based Biomarker Characterization in nAMD](https://arxiv.org/abs/2601.18826)
*MAria Simona Tivadar,Ioana Damian,Adrian Groza,Simona Delia Nicoara*

Main category: eess.IV

TL;DR: 开发了用于分析OCTA图像的工具，包括提取生物标志物、3D可视化和基于白盒机器学习模型的nAMD诊断，在测试集上达到68%的准确率，并强调了模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 提高眼科医生诊断新生血管性年龄相关性黄斑变性（nAMD）的决策能力。

Method: 开发了三个工具：1. 使用图像处理提取mCNV面积和血管密度等生物标志物；2. 生成新生血管的3D可视化；3. 应用决策树、支持向量机和DL-Learner组成的集成白盒机器学习模型进行nAMD诊断。

Result: 训练数据的准确率为100%，测试数据的准确率为68%。

Conclusion: 所提出的基于白盒机器学习模型的nAMD诊断方法具有可解释性和透明性，有助于临床医生理解决策过程，并能辅助诊断。

Abstract: We aim to enhance ophthalmologists' decision-making when diagnosing the Neovascular Age-Related Macular Degeneration (nAMD). We developed three tools to analyze Optical Coherence Tomography Angiography images: (1) extracting biomarkers such as mCNV area and vessel density using image processing; (2) generating a 3D visualization of the neovascularization for a better view of the affected regions; and (3) applying an ensemble of three white box machine learning algorithms (decision tree, support vector machines and DL-Learner) for nAMD diagnosis. The learned expressions reached 100% accuracy for the training data and 68% accuracy in testing. The main advantage is that all the learned models white-box, which ensures explainability and transparency, allowing clinicians to better understand the decision-making process.

</details>


### [207] [Advances in Diffusion-Based Generative Compression](https://arxiv.org/abs/2601.18932)
*Yibo Yang,Stephan Mandt*

Main category: eess.IV

TL;DR: 本文综述了基于扩散模型的生成式有损压缩方法，重点关注图像压缩，并探讨了其在数据压缩领域的应用。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成方面表现出色，并已成功应用于数据压缩，能够以极低的比特率生成逼真的重建图像，这促使了对该领域方法的深入研究。

Method: 该文回顾了近期的基于扩散模型的生成式有损压缩方法，其一般流程是将源数据编码为嵌入，然后利用扩散模型在解码过程中迭代优化嵌入，使其生成的重建图像近似遵循真实数据分布。嵌入通常通过辅助熵模型传输，部分新方法还探索利用扩散模型本身进行信息传输（通过信道模拟）。

Result: 文章从率失真感知理论角度对代表性方法进行了回顾，强调了共同随机性和逆问题之间的联系。

Conclusion: 文章总结了基于扩散模型的生成式有损压缩方法的现状，并指出了该领域尚待解决的挑战。

Abstract: Popularized by their strong image generation performance, diffusion and related methods for generative modeling have found widespread success in visual media applications. In particular, diffusion methods have enabled new approaches to data compression, where realistic reconstructions can be generated at extremely low bit-rates. This article provides a unifying review of recent diffusion-based methods for generative lossy compression, with a focus on image compression. These methods generally encode the source into an embedding and employ a diffusion model to iteratively refine it in the decoding procedure, such that the final reconstruction approximately follows the ground truth data distribution. The embedding can take various forms and is typically transmitted via an auxiliary entropy model, and recent methods also explore the use of diffusion models themselves for information transmission via channel simulation. We review representative approaches through the lens of rate-distortion-perception theory, highlighting the role of common randomness and connections to inverse problems, and identify open challenges.

</details>


### [208] [Optimized $k$-means color quantization of digital images in machine-based and human perception-based colorspaces](https://arxiv.org/abs/2601.19117)
*Ranjan Maitra*

Main category: eess.IV

TL;DR: 研究表明，在进行 $k$-means 颜色量化时，RGB、CIE-XYZ 和 CIE-LUV/CIE-HCL 颜色空间各有优劣，最佳表现取决于量化级别和图像特性。


<details>
  <summary>Details</summary>
Motivation: 尽管 $k$-means 算法常用于颜色量化，但主要在 RGB 颜色空间应用。近期研究表明，在人类感知颜色空间中性能有所提升，因此需要深入研究不同颜色空间在 $k$-means 颜色量化中的表现。

Method: 在 RGB、CIE-XYZ 和 CIE-LUV/CIE-HCL 四种颜色空间下，对 148 张不同图像进行 $k$-means 颜色量化，并使用 VIF 指标评估量化图像质量。

Result: 约一半情况下 RGB 空间表现最佳；在其他情况，尤其是在较高量化级别下，CIE-XYZ 空间通常表现更好；在较低量化级别下，CIE-LUV 空间有时表现最佳。颜色空间的选择与图像的色调、色度和亮度分布有关。

Conclusion: 不同颜色空间在 $k$-means 颜色量化中的性能表现差异显著，并非单一颜色空间在所有情况下都最优。最优颜色空间的选取应考虑量化级别和图像本身的颜色分布特性。

Abstract: Color quantization represents an image using a fraction of its original number of colors while only minimally losing its visual quality. The $k$-means algorithm is commonly used in this context, but has mostly been applied in the machine-based RGB colorspace composed of the three primary colors. However, some recent studies have indicated its improved performance in human perception-based colorspaces. We investigated the performance of $k$-means color quantization at four quantization levels in the RGB, CIE-XYZ, and CIE-LUV/CIE-HCL colorspaces, on 148 varied digital images spanning a wide range of scenes, subjects and settings. The Visual Information Fidelity (VIF) measure numerically assessed the quality of the quantized images, and showed that in about half of the cases, $k$-means color quantization is best in the RGB space, while at other times, and especially for higher quantization levels ($k$), the CIE-XYZ colorspace is where it usually does better. There are also some cases, especially at lower $k$, where the best performance is obtained in the CIE-LUV colorspace. Further analysis of the performances in terms of the distributions of the hue, chromaticity and luminance in an image presents a nuanced perspective and characterization of the images for which each colorspace is better for $k$-means color quantization.

</details>


### [209] [Recover Cell Tensor: Diffusion-Equivalent Tensor Completion for Fluorescence Microscopy Imaging](https://arxiv.org/abs/2601.19169)
*Chenwei Wang,Zhaoke Huang,Zelin Li,Wenqi Zhu*

Main category: eess.IV

TL;DR: 提出了一种基于张量补全的新颖框架，用于处理荧光显微镜（FM）成像中因稀疏采样和光毒性引起的图像质量问题，并在真实细胞数据上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的FM图像恢复方法在处理3D活细胞成像中，由于数据采集时间和分辨率的限制，以及信号退化过程不稳定和缺乏高质量参考图像等问题，效果不佳。

Method: 提出了一种新颖的张量补全框架。将FM成像过程视为一种均匀随机采样下的张量补全任务。推导了精确细胞张量补全的理论下界。将张量补全问题重新表述为一个基于得分的生成模型，并引入结构一致性先验来指导生成过程。

Result: 在SR-CACO-2和三个真实的体内细胞数据集上，该方法在信噪比和结构保真度方面均取得了显著提升，达到了最先进的性能。

Conclusion: 该张量补全框架能够有效地从稀疏采样的、具有非线性退化的FM图像中恢复出高质量的3D细胞结构，为活细胞成像提供了新的解决方案。

Abstract: Fluorescence microscopy (FM) imaging is a fundamental technique for observing live cell division, one of the most essential processes in the cycle of life and death. Observing 3D live cells requires scanning through the cell volume while minimizing lethal phototoxicity. That limits acquisition time and results in sparsely sampled volumes with anisotropic resolution and high noise. Existing image restoration methods, primarily based on inverse problem modeling, assume known and stable degradation processes and struggle under such conditions, especially in the absence of high-quality reference volumes. In this paper, from a new perspective, we propose a novel tensor completion framework tailored to the nature of FM imaging, which inherently involves nonlinear signal degradation and incomplete observations. Specifically, FM imaging with equidistant Z-axis sampling is essentially a tensor completion task under a uniformly random sampling condition. On one hand, we derive the theoretical lower bound for exact cell tensor completion, validating the feasibility of accurately recovering 3D cell tensor. On the other hand, we reformulate the tensor completion problem as a mathematically equivalent score-based generative model. By incorporating structural consistency priors, the generative trajectory is effectively guided toward denoised and geometrically coherent reconstructions. Our method demonstrates state-of-the-art performance on SR-CACO-2 and three real \textit{in vivo} cellular datasets, showing substantial improvements in both signal-to-noise ratio and structural fidelity.

</details>


### [210] [Magnetic Resonance Simulation of Effective Transverse Relaxation (T2*)](https://arxiv.org/abs/2601.19246)
*Hidenori Takeshima*

Main category: eess.IV

TL;DR: 本研究提出了一种有效模拟MRI中 $T_2^*$ 松弛的 $T_2'$ 成分的方法，通过使用线性相位模型和两种加速技术（解析解和组合过渡），显著提高了模拟效率，且计算成本增加幅度不大。


<details>
  <summary>Details</summary>
Motivation: 传统的MR模拟方法难以有效模拟 $T_2^*$ 松弛中的可逆分量 $T_2'$，需要大量的等磁体才能进行近似，这效率低下。

Method: 研究者提出了一种利用线性相位模型直接模拟洛伦兹函数的 $T_2'$ 松弛的方法，避免了对大量等磁体的需求。同时，通过模拟磁化强度对频率轴的偏导数来表示线性相位模型。为了加速模拟，引入了两种技术：解析解和组合过渡。实验采用了单等磁体模拟来理解基本机制，并用包含和不包含 $T_2'$ 模拟的脉冲序列和两种体模来评估实际效果。

Result: 单等磁体模拟证明了 $T_2'$ 模拟的可行性。在实际模拟中，无需大量等磁体即可成功恢复 $T_2'$。包含 $T_2'$ 模拟的计算时间仅比不包含的增加2.0至2.7倍。应用解析解技术将模拟加速了19倍，组合过渡技术加速了高达17倍。

Conclusion: 理论和实验结果表明，该研究提出的方法通过结合线性模型、解析解和组合过渡技术，能够高效地模拟MR成像中的 $T_2'$ 松弛。

Abstract: Purpose: To simulate effective transverse relaxation ($T_2^*$) as a part of MR simulation. $T_2^*$ consists of reversible ($T_2^{\prime}$) and irreversible ($T_2$) components. Whereas simulations of $T_2$ are easy, $T_2^{\prime}$ is not easily simulated if only magnetizations of individual isochromats are simulated.
  Theory and Methods: Efficient methods for simulating $T_2^{\prime}$ were proposed. To approximate the Lorentzian function of $T_2^{\prime}$ realistically, conventional simulators require 100+ isochromats. This approximation can be avoided by utilizing a linear phase model for simulating an entire Lorentzian function directly. To represent the linear phase model, the partial derivatives of the magnetizations with respect to the frequency axis were also simulated. To accelerate the simulations with these partial derivatives, the proposed methods introduced two techniques: analytic solutions, and combined transitions. For understanding the fundamental mechanism of the proposed method, a simple one-isochromat simulation was performed. For evaluating realistic cases, several pulse sequences were simulated using two phantoms with and without $T_2^{\prime}$ simulations.
  Results: The one-isochromat simulation demonstrated that $T_2^{\prime}$ simulations were possible. In the realistic cases, $T_2^{\prime}$ was recovered as expected without using 100+ isochromats for each point. The computational times with $T_2^{\prime}$ simulations were only 2.0 to 2.7 times longer than those without $T_2^{\prime}$ simulations. When the above-mentioned two techniques were utilized, the analytic solutions accelerated 19 times, and the combined transitions accelerated up to 17 times.
  Conclusion: Both theory and results showed that the proposed methods simulated $T_2^{\prime}$ efficiently by utilizing a linear model with a Lorentzian function, analytic solutions, and combined transitions.

</details>


### [211] [Reinforced Rate Control for Neural Video Compression via Inter-Frame Rate-Distortion Awareness](https://arxiv.org/abs/2601.19293)
*Wuyang Cong,Junqi Shi,Lizhong Wang,Weijing Shi,Ming Lu,Hao Chen,Zhan Ma*

Main category: eess.IV

TL;DR: 本文提出了一种基于强化学习（RL）的神经视频压缩（NVC）率控制框架，通过在每个帧上进行顺序决策来优化长期奖励，实现了更精确的比特率分配和编码参数选择，从而提高了压缩效率并降低了比特率误差。


<details>
  <summary>Details</summary>
Motivation: 现有NVC率控制方法忽略了帧间编码参数的依赖性，导致比特率分配不佳和参数决策级联。本文旨在解决这一问题，提高率控制的有效性。

Method: 提出一个RL-based率控制框架，将率控制任务建模为逐帧顺序决策过程。RL代理观察时空状态并选择编码参数以优化反映率失真（R-D）性能和比特率遵循的长期奖励。该方法在单个步骤中联合确定比特率分配和编码参数，独立于GOP结构。

Result: 在各种NVC架构的实验中，该方法将平均相对比特率误差降低到1.20%，并在典型的GOP大小下实现了高达13.45%的比特率节省，优于现有方法。此外，该框架还表现出对内容变化和带宽波动的改进鲁棒性，具有较低的编码开销。

Conclusion: 所提出的RL-based率控制框架能够有效地优化NVC的率失真性能，实现更精确的比特率控制，并适合实际部署。

Abstract: Neural video compression (NVC) has demonstrated superior compression efficiency, yet effective rate control remains a significant challenge due to complex temporal dependencies. Existing rate control schemes typically leverage frame content to capture distortion interactions, overlooking inter-frame rate dependencies arising from shifts in per-frame coding parameters. This often leads to suboptimal bitrate allocation and cascading parameter decisions. To address this, we propose a reinforcement-learning (RL)-based rate control framework that formulates the task as a frame-by-frame sequential decision process. At each frame, an RL agent observes a spatiotemporal state and selects coding parameters to optimize a long-term reward that reflects rate-distortion (R-D) performance and bitrate adherence. Unlike prior methods, our approach jointly determines bitrate allocation and coding parameters in a single step, independent of group of pictures (GOP) structure. Extensive experiments across diverse NVC architectures show that our method reduces the average relative bitrate error to 1.20% and achieves up to 13.45% bitrate savings at typical GOP sizes, outperforming existing approaches. In addition, our framework demonstrates improved robustness to content variation and bandwidth fluctuations with lower coding overhead, making it highly suitable for practical deployment.

</details>


### [212] [AMGFormer: Adaptive Multi-Granular Transformer for Brain Tumor Segmentation with Missing Modalities](https://arxiv.org/abs/2601.19349)
*Chengxiang Guo,Jian Wang,Junhua Fei,Xiao Li,Chunling Chen,Yun Jin*

Main category: eess.IV

TL;DR: AMGFormer 是一种创新的多模态 MRI 脑肿瘤分割方法，通过其独特的模块解决了现有方法在处理缺失模态时性能不稳定的问题，显著提高了分割的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态 MRI 的脑肿瘤分割方法在面对临床实践中常见的模态缺失时，性能波动超过 40%，导致其临床不可靠。研究动机是开发一种稳定且性能优越的脑肿瘤分割方法。

Method: 提出了 AMGFormer 模型，包含三个核心模块：1) QuadIntegrator Bridge (QIB) 实现空间自适应融合，确保在不同模态组合下预测一致性；2) Multi-Granular Attention Orchestrator (MGAO) 关注病灶区域，降低背景敏感性；3) Modality Quality-Aware Enhancement (MQAE) 防止损坏序列的错误传播。

Result: 在 BraTS 2018 数据集上，AMGFormer 在 15 种模态组合下实现了 <0.5% 的性能方差，Dice 分数分别为 WT 89.33%、TC 82.70%、ET 67.23%。单模态 ET 分割相比现有 SOTA 方法有 40-81% 的相对提升。在 BraTS 2020/2021 数据集上，性能也表现出色，WT 最高 92.44%、TC 最高 89.91%、ET 最高 84.57%。模型推理速度为 1.2 秒。

Conclusion: AMGFormer 成功解决了脑肿瘤分割的稳定性危机，通过创新的融合、注意力机制和质量增强策略，实现了跨模态组合的高效和鲁棒分割，并在多个数据集上取得了 SOTA 性能，展现了临床应用的潜力。

Abstract: Multimodal MRI is essential for brain tumor segmentation, yet missing modalities in clinical practice cause existing methods to exhibit >40% performance variance across modality combinations, rendering them clinically unreliable. We propose AMGFormer, achieving significantly improved stability through three synergistic modules: (1) QuadIntegrator Bridge (QIB) enabling spatially adaptive fusion maintaining consistent predictions regardless of available modalities, (2) Multi-Granular Attention Orchestrator (MGAO) focusing on pathological regions to reduce background sensitivity, and (3) Modality Quality-Aware Enhancement (MQAE) preventing error propagation from corrupted sequences. On BraTS 2018, our method achieves 89.33% WT, 82.70% TC, 67.23% ET Dice scores with <0.5% variance across 15 modality combinations, solving the stability crisis. Single-modality ET segmentation shows 40-81% relative improvements over state-of-the-art methods. The method generalizes to BraTS 2020/2021, achieving up to 92.44% WT, 89.91% TC, 84.57% ET. The model demonstrates potential for clinical deployment with 1.2s inference. Code: https://github.com/guochengxiangives/AMGFormer.

</details>


### [213] [Interpretable and backpropagation-free Green Learning for efficient multi-task echocardiographic segmentation and classification](https://arxiv.org/abs/2601.19743)
*Jyun-Ping Kao,Jiaxing Yang,C. -C. Jay Kuo,Jonghye Woo*

Main category: eess.IV

TL;DR: 提出了一种无反向传播的多任务绿色学习（MTGL）框架，用于同步进行左心室（LV）分割和射血分数（LVEF）分类，实现了最先进的性能，同时显著减少了计算资源和模型参数，提高了模型的可解释性和效率。


<details>
  <summary>Details</summary>
Motivation: 手动LVEF评估存在高观察者间变异性，而现有的深度学习模型计算密集且需要大量数据，阻碍了临床信任和应用。因此，需要一种更高效、可解释且准确的LVEF评估方法。

Method: 提出了一种无反向传播的多任务绿色学习（MTGL）框架，该框架集成了无监督的VoxelHop编码器（用于提取时空特征）和多级回归解码器以及XG-Boost分类器，同时执行LV分割和LVEF分类。

Result: 在EchoNet-Dynamic数据集上，MTGL模型在LVEF分类上达到94.3%的准确率，在LV分割上达到0.912的Dice相似系数（DSC），优于多个先进的3D深度学习模型。同时，MTGL模型的参数量显著减少（减少了一个数量级以上），体现了其计算效率。

Conclusion: 绿色学习（GL）范式能够为复杂的医学图像分析提供高精度、高效且可解释的解决方案。这项工作展示了MTGL框架在心脏影像分析领域的潜力，为构建更可持续和值得信赖的临床人工智能铺平了道路。

Abstract: Echocardiography is a cornerstone for managing heart failure (HF), with Left Ventricular Ejection Fraction (LVEF) being a critical metric for guiding therapy. However, manual LVEF assessment suffers from high inter-observer variability, while existing Deep Learning (DL) models are often computationally intensive and data-hungry "black boxes" that impede clinical trust and adoption. Here, we propose a backpropagation-free multi-task Green Learning (MTGL) framework that performs simultaneous Left Ventricle (LV) segmentation and LVEF classification. Our framework integrates an unsupervised VoxelHop encoder for hierarchical spatio-temporal feature extraction with a multi-level regression decoder and an XG-Boost classifier. On the EchoNet-Dynamic dataset, our MTGL model achieves state-of-the-art classification and segmentation performance, attaining a classification accuracy of 94.3% and a Dice Similarity Coefficient (DSC) of 0.912, significantly outperforming several advanced 3D DL models. Crucially, our model achieves this with over an order of magnitude fewer parameters, demonstrating exceptional computational efficiency. This work demonstrates that the GL paradigm can deliver highly accurate, efficient, and interpretable solutions for complex medical image analysis, paving the way for more sustainable and trustworthy artificial intelligence in clinical practice.

</details>
