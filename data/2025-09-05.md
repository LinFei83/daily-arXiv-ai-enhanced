<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 39]
- [cs.CV](#cs.CV) [Total: 70]
- [cs.CL](#cs.CL) [Total: 50]
- [cs.RO](#cs.RO) [Total: 20]
- [eess.SY](#eess.SY) [Total: 19]
- [eess.IV](#eess.IV) [Total: 3]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [PG-Agent: An Agent Powered by Page Graph](https://arxiv.org/abs/2509.03536)
*Weizhi Chen,Ziwei Wang,Leyang Yang,Sheng Zhou,Xiaoxuan Tang,Jiajun Bu,Yong Li,Wei Jiang*

Main category: cs.AI

TL;DR: 本文提出PG-Agent，一个多智能体框架，通过将GUI操作序列转换为页面图并结合RAG技术，有效捕捉页面间的复杂转换关系，显著提升GUI智能体在未知场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有GUI智能体依赖于多步操作的顺序片段作为先验知识，未能捕捉页面间复杂的转换关系，导致智能体难以深入感知GUI环境并泛化到新场景。

Method: 研究设计了一个自动化流程，将顺序操作片段转换为页面图，显式建模页面及其通过动作连接的图结构。进一步引入检索增强生成（RAG）技术，从页面图中有效检索可靠的GUI感知指导。在此基础上，提出了一个定制化的多智能体框架PG-Agent，结合任务分解策略并注入这些指导，以实现对未见场景的泛化。

Result: 在各种基准测试上的大量实验表明，PG-Agent即使在用于页面图构建的片段有限的情况下，也表现出显著的有效性。

Conclusion: PG-Agent通过利用页面图和RAG技术，成功解决了现有GUI智能体在感知复杂页面转换关系和泛化能力方面的不足，为GUI智能体在未知场景下的应用提供了有效方案。

Abstract: Graphical User Interface (GUI) agents possess significant commercial and
social value, and GUI agents powered by advanced multimodal large language
models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI
agents usually utilize sequential episodes of multi-step operations across
pages as the prior GUI knowledge, which fails to capture the complex transition
relationship between pages, making it challenging for the agents to deeply
perceive the GUI environment and generalize to new scenarios. Therefore, we
design an automated pipeline to transform the sequential episodes into page
graphs, which explicitly model the graph structure of the pages that are
naturally connected by actions. To fully utilize the page graphs, we further
introduce Retrieval-Augmented Generation (RAG) technology to effectively
retrieve reliable perception guidelines of GUI from them, and a tailored
multi-agent framework PG-Agent with task decomposition strategy is proposed to
be injected with the guidelines so that it can generalize to unseen scenarios.
Extensive experiments on various benchmarks demonstrate the effectiveness of
PG-Agent, even with limited episodes for page graph construction.

</details>


### [2] [Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models](https://arxiv.org/abs/2509.03548)
*João P. Arroyo,João G. Rodrigues,Daniel Lawand,Denis D. Mauá,Junkyu Lee,Radu Marinescu,Alex Gray,Eduardo R. Laurentino,Fabio G. Cozman*

Main category: cs.AI

TL;DR: 本研究针对准马尔可夫因果模型中的部分可识别查询，提出了一种新算法来简化紧密概率边界的计算，并证明了在单一干预场景下，列生成技术优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在因果模型中，当外生变量未完全指定时，无法精确计算感兴趣的概率值。因此，需要计算紧密概率边界。现有方法（如多线性规划和线性规划）在程序构建上可能复杂，需要更高效的解决方案。

Method: 研究准马尔可夫非循环结构因果模型，将其表示为根变量分布不唯一确定的贝叶斯网络。提出一种新算法，利用内生变量的输入概率来简化程序构建。对于单一干预场景，应用列生成技术通过一系列辅助线性整数规划来计算概率边界，实现了外生变量的多项式基数表示。

Result: 该方法实现了外生变量的多项式基数表示。实验结果表明，列生成技术在计算概率边界方面优于现有方法。

Conclusion: 本研究提出了一种有效的新算法，特别是在单一干预场景下使用列生成技术，能够更高效地计算准马尔可夫因果模型中部分可识别查询的紧密概率边界，并优于现有方法。

Abstract: We investigate partially identifiable queries in a class of causal models. We
focus on acyclic Structural Causal Models that are quasi-Markovian (that is,
each endogenous variable is connected with at most one exogenous confounder).
We look into scenarios where endogenous variables are observed (and a
distribution over them is known), while exogenous variables are not fully
specified. This leads to a representation that is in essence a Bayesian network
where the distribution of root variables is not uniquely determined. In such
circumstances, it may not be possible to precisely compute a probability value
of interest. We thus study the computation of tight probability bounds, a
problem that has been solved by multilinear programming in general, and by
linear programming when a single confounded component is intervened upon. We
present a new algorithm to simplify the construction of such programs by
exploiting input probabilities over endogenous variables. For scenarios with a
single intervention, we apply column generation to compute a probability bound
through a sequence of auxiliary linear integer programs, thus showing that a
representation with polynomial cardinality for exogenous variables is possible.
Experiments show column generation techniques to be superior to existing
methods.

</details>


### [3] [Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method](https://arxiv.org/abs/2509.03550)
*Tonghe Li,Jixin Liu,Weili Zeng,Hao Jiang*

Main category: cs.AI

TL;DR: 该论文提出了一种名为Diffusion-AC的新型自主冲突解决框架，通过将扩散概率模型集成到深度强化学习中，解决了现有方法在空域冲突检测与解决（CD&R）中决策灵活性不足的问题。该方法能够生成多模态动作分布，在复杂高密度交通场景下显著提高了成功率并降低了近距空中相撞（NMACs）的发生率。


<details>
  <summary>Details</summary>
Motivation: 随着全球航空交通量的持续增长，高效安全的冲突检测与解决（CD&R）至关重要。尽管深度强化学习（DRL）为CD&R自动化提供了前景，但现有方法通常存在“单峰偏差”，导致在面对复杂动态约束时决策灵活性不足，常陷入“决策僵局”。

Method: 本文将扩散概率模型引入到CD&R任务中，提出了Diffusion-AC框架。该框架将策略建模为由价值函数引导的逆向去噪过程，以生成丰富、高质量和多模态的动作分布，而非单一最优解。此外，还引入了“密度渐进安全课程（Density-Progressive Safety Curriculum, DPSC）”训练机制，以确保智能体在从稀疏到高密度交通环境中稳定高效地学习。

Result: 广泛的仿真实验表明，所提出的方法显著优于一系列最先进的DRL基准。在最具挑战性的高密度场景中，Diffusion-AC不仅保持了94.1%的高成功率，而且与次优基线相比，将近距空中相撞（NMACs）的发生率降低了约59%，显著提升了系统安全裕度。

Conclusion: 该性能的显著提升源于其独特的多模态决策能力，这使得智能体能够灵活地切换到有效的替代机动方案。通过解决现有DRL方法的单峰偏差问题，Diffusion-AC在空域冲突解决中实现了更高的安全性与效率。

Abstract: In the context of continuously rising global air traffic, efficient and safe
Conflict Detection and Resolution (CD&R) is paramount for air traffic
management. Although Deep Reinforcement Learning (DRL) offers a promising
pathway for CD&R automation, existing approaches commonly suffer from a
"unimodal bias" in their policies. This leads to a critical lack of
decision-making flexibility when confronted with complex and dynamic
constraints, often resulting in "decision deadlocks." To overcome this
limitation, this paper pioneers the integration of diffusion probabilistic
models into the safety-critical task of CD&R, proposing a novel autonomous
conflict resolution framework named Diffusion-AC. Diverging from conventional
methods that converge to a single optimal solution, our framework models its
policy as a reverse denoising process guided by a value function, enabling it
to generate a rich, high-quality, and multimodal action distribution. This core
architecture is complemented by a Density-Progressive Safety Curriculum (DPSC),
a training mechanism that ensures stable and efficient learning as the agent
progresses from sparse to high-density traffic environments. Extensive
simulation experiments demonstrate that the proposed method significantly
outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the
most challenging high-density scenarios, Diffusion-AC not only maintains a high
success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions
(NMACs) by approximately 59% compared to the next-best-performing baseline,
significantly enhancing the system's safety margin. This performance leap stems
from its unique multimodal decision-making capability, which allows the agent
to flexibly switch to effective alternative maneuvers.

</details>


### [4] [Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents](https://arxiv.org/abs/2509.03581)
*Davide Paglieri,Bartłomiej Cupiał,Jonathan Cook,Ulyana Piterbarg,Jens Tuyls,Edward Grefenstette,Jakob Nicolaus Foerster,Jack Parker-Holder,Tim Rocktäschel*

Main category: cs.AI

TL;DR: 本文提出了一种针对大型语言模型（LLM）代理的动态规划框架和两阶段训练方法，使其能够灵活决定何时进行规划，从而在长周期任务中实现更高效、自适应和可控的问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理（如ReAct）在每次行动前进行显式规划，这在计算上成本高昂，并可能在长周期任务中降低性能；而从不规划则会进一步限制性能。因此，研究的动机是需要一种机制，使LLM代理能够灵活地决定何时分配计算资源进行规划。

Method: 研究引入了一个形式化动态规划的概念框架，并提出了一个简单的两阶段训练流程：1) 在多样化的合成数据上进行监督微调（SFT），以初步培养模型的动态规划能力；2) 使用强化学习（RL）在长周期环境中进一步完善和优化这种能力。

Result: 在Crafter环境中的实验表明，通过这种方法训练的动态规划代理具有更高的样本效率，并能持续完成更复杂的任务目标。此外，这些代理可以被人类编写的计划有效引导，其性能甚至超越了独立执行时的能力。

Conclusion: 这项工作首次探索了在顺序决策任务中训练LLM代理进行动态测试时计算分配，为开发更高效、自适应和可控的代理系统铺平了道路。

Abstract: Training large language models (LLMs) to reason via reinforcement learning
(RL) significantly improves their problem-solving capabilities. In agentic
settings, existing methods like ReAct prompt LLMs to explicitly plan before
every action; however, we demonstrate that always planning is computationally
expensive and degrades performance on long-horizon tasks, while never planning
further limits performance. To address this, we introduce a conceptual
framework formalizing dynamic planning for LLM agents, enabling them to
flexibly decide when to allocate test-time compute for planning. We propose a
simple two-stage training pipeline: (1) supervised fine-tuning on diverse
synthetic data to prime models for dynamic planning, and (2) RL to refine this
capability in long-horizon environments. Experiments on the Crafter environment
show that dynamic planning agents trained with this approach are more
sample-efficient and consistently achieve more complex objectives.
Additionally, we demonstrate that these agents can be effectively steered by
human-written plans, surpassing their independent capabilities. To our
knowledge, this work is the first to explore training LLM agents for dynamic
test-time compute allocation in sequential decision-making tasks, paving the
way for more efficient, adaptive, and controllable agentic systems.

</details>


### [5] [Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE](https://arxiv.org/abs/2509.03626)
*Zahra Zehtabi Sabeti Moghaddam,Zeinab Dehghani,Maneeha Rani,Koorosh Aslansefat,Bhupesh Kumar Mishra,Rameez Raja Kureshi,Dhavalkumar Thakker*

Main category: cs.AI

TL;DR: 本文提出KG-SMILE，一个基于扰动的框架，为图RAG提供可解释性，通过识别对生成输出最具影响力的图实体和关系，从而提高透明度和信任。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（如LLMs）存在幻觉和不可验证声明，限制了其在敏感领域的可靠性。检索增强生成（RAG）通过外部知识提高了准确性，但在医疗等领域仍缺乏透明度，且高度依赖数据质量，本质上是一个黑箱。

Method: 开发了一种与方法无关的、基于扰动的框架KG-SMILE，为使用SMILE的图RAG提供token和组件级别的互操作性。通过应用受控扰动、计算相似性并训练加权线性替代模型，KG-SMILE识别出对生成输出最有影响的图实体和关系。

Result: 通过保真度、忠实度、一致性、稳定性、准确性等归因指标评估，KG-SMILE产生了稳定且与人类对齐的解释。这表明它能够平衡模型有效性和可解释性。

Conclusion: KG-SMILE通过提高RAG的透明度和可解释性，增强了机器学习技术的信任度，平衡了模型效果与可解释性。

Abstract: Generative AI, such as Large Language Models (LLMs), has achieved impressive
progress but still produces hallucinations and unverifiable claims, limiting
reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves
accuracy by grounding outputs in external knowledge, especially in domains like
healthcare, where precision is vital. However, RAG remains opaque and
essentially a black box, heavily dependent on data quality. We developed a
method-agnostic, perturbation-based framework that provides token and
component-level interoperability for Graph RAG using SMILE and named it as
Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing
similarities, and training weighted linear surrogates, KG-SMILE identifies the
graph entities and relations most influential to generated outputs, thereby
making RAG more transparent. We evaluate KG-SMILE using comprehensive
attribution metrics, including fidelity, faithfulness, consistency, stability,
and accuracy. Our findings show that KG-SMILE produces stable, human-aligned
explanations, demonstrating its capacity to balance model effectiveness with
interpretability and thereby fostering greater transparency and trust in
machine learning technologies.

</details>


### [6] [CausalARC: Abstract Reasoning with Causal World Models](https://arxiv.org/abs/2509.03636)
*Jacqueline Maasch,John Kalantari,Kia Khezeli*

Main category: cs.AI

TL;DR: CausalARC是一个受ARC启发的实验性测试平台，用于在低数据和分布外条件下评估AI推理能力，其任务基于结构化因果模型，并通过因果反馈进行数据增强。


<details>
  <summary>Details</summary>
Motivation: AI推理需要适应新问题、有限数据和分布偏移，这促使研究者开发一个能够在这种挑战性环境下测试AI推理能力的平台。

Method: 引入了CausalARC测试平台，其推理任务来源于完全指定的因果世界模型（结构化因果模型）。通过原则性的数据增强，提供观测、干预和反事实反馈，形成少样本、上下文学习的演示。作为概念验证，该平台被用于语言模型的四种评估场景。

Result: CausalARC被成功应用于概念验证，评估了语言模型在以下四个场景中的表现：(1) 带测试时训练的抽象推理，(2) 带上下文学习的反事实推理，(3) 程序合成，以及(4) 带逻辑推理的因果发现。

Conclusion: CausalARC提供了一个有效的实验测试平台，用于在低数据和分布外条件下，通过因果世界模型和多样化的因果反馈，评估和理解AI（特别是语言模型）的推理能力。

Abstract: Reasoning requires adaptation to novel problem settings under limited data
and distribution shift. This work introduces CausalARC: an experimental testbed
for AI reasoning in low-data and out-of-distribution regimes, modeled after the
Abstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is
sampled from a fully specified causal world model, formally expressed as a
structural causal model. Principled data augmentations provide observational,
interventional, and counterfactual feedback about the world model in the form
of few-shot, in-context learning demonstrations. As a proof-of-concept, we
illustrate the use of CausalARC for four language model evaluation settings:
(1) abstract reasoning with test-time training, (2) counterfactual reasoning
with in-context learning, (3) program synthesis, and (4) causal discovery with
logical reasoning.

</details>


### [7] [Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations](https://arxiv.org/abs/2509.03644)
*François Olivier,Zied Bouraoui*

Main category: cs.AI

TL;DR: 本文介绍了一种神经符号系统Embodied-LM，它通过基于图像图式的示意性表征来增强大型语言模型（LLMs）的理解和逻辑推理能力，从而提高了可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管自然语言理解取得了显著进展，但大型语言模型（LLMs）在执行逻辑推理时仍然容易出错，常常缺乏像人类那样强大的心理表征能力。

Method: 该系统Embodied-LM将理解和逻辑推理基于图像图式（源自感觉运动经验并构建人类认知的重复模式）的示意性表征。它利用Answer Set Programming中的声明性空间推理来操作这些认知结构的空间基础。

Result: 研究表明，LLMs可以被引导通过具身认知结构来解释场景，这些结构可以被形式化为可执行程序，并且由此产生的表征支持有效的逻辑推理，并增强了可解释性。

Conclusion: 尽管当前实现侧重于空间原语，但Embodied-LM为整合更复杂和动态的表征奠定了计算基础，提升了LLMs的逻辑推理能力和可解释性。

Abstract: Despite significant progress in natural language understanding, Large
Language Models (LLMs) remain error-prone when performing logical reasoning,
often lacking the robust mental representations that enable human-like
comprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that
grounds understanding and logical reasoning in schematic representations based
on image schemas-recurring patterns derived from sensorimotor experience that
structure human cognition. Our system operationalizes the spatial foundations
of these cognitive structures using declarative spatial reasoning within Answer
Set Programming. Through evaluation on logical deduction problems, we
demonstrate that LLMs can be guided to interpret scenarios through embodied
cognitive structures, that these structures can be formalized as executable
programs, and that the resulting representations support effective logical
reasoning with enhanced interpretability. While our current implementation
focuses on spatial primitives, it establishes the computational foundation for
incorporating more complex and dynamic representations.

</details>


### [8] [Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning](https://arxiv.org/abs/2509.03646)
*Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen*

Main category: cs.AI

TL;DR: 本文揭示了强化学习（RL）提升大型语言模型（LLM）推理能力的两阶段动态：先是低级技能，后是高级战略规划。针对现有RL算法效率低下的问题，提出HICRA算法，将优化重点放在高影响的规划令牌上，显著优于基线模型，并指出战略瓶颈是解锁高级推理的关键。


<details>
  <summary>Details</summary>
Motivation: 强化学习在增强大型语言模型复杂推理能力方面表现出色，但其成功背后的机制尚不明确，如“顿悟时刻”、“长度缩放”和熵动态等现象未被理解。现有RL算法（如GRPO）普适性地施加优化压力，稀释了学习信号，导致效率低下。

Method: 本文通过分析“顿悟时刻”、“长度缩放”和熵动态，揭示了LLM中出现的推理层级和两阶段学习动态（先低级技能，后高级战略规划）。在此基础上，提出层级感知信用分配（HIerarchy-Aware Credit Assignment, HICRA）算法，该算法将优化精力集中在高影响的规划令牌上。此外，研究还验证了语义熵作为衡量战略探索指标的优越性。

Result: 研究揭示了一个两阶段动态：模型首先受限于程序正确性，然后性能提升主要由高级战略规划的探索和掌握驱动。HICRA算法显著优于强大的基线模型，表明关注战略瓶颈是解锁高级推理的关键。同时，语义熵被证实是衡量战略探索的优越指标，而非令牌级熵。

Conclusion: RL在提升LLM推理能力方面的成功源于一个出现的两阶段学习层级。通过识别并集中优化高级战略规划这一瓶颈，如HICRA算法所做，可以更有效地解锁高级推理能力。语义熵是衡量这一战略探索过程的更有效指标。

Abstract: Reinforcement Learning (RL) has proven highly effective at enhancing the
complex reasoning abilities of Large Language Models (LLMs), yet underlying
mechanisms driving this success remain largely opaque. Our analysis reveals
that puzzling phenomena like ``aha moments", ``length-scaling'' and entropy
dynamics are not disparate occurrences but hallmarks of an emergent reasoning
hierarchy, akin to the separation of high-level strategic planning from
low-level procedural execution in human cognition. We uncover a compelling
two-phase dynamic: initially, a model is constrained by procedural correctness
and must improve its low-level skills. The learning bottleneck then decisively
shifts, with performance gains being driven by the exploration and mastery of
high-level strategic planning. This insight exposes a core inefficiency in
prevailing RL algorithms like GRPO, which apply optimization pressure
agnostically and dilute the learning signal across all tokens. To address this,
we propose HIerarchy-Aware Credit Assignment (HICRA), an algorithm that
concentrates optimization efforts on high-impact planning tokens. HICRA
significantly outperforms strong baselines, demonstrating that focusing on this
strategic bottleneck is key to unlocking advanced reasoning. Furthermore, we
validate semantic entropy as a superior compass for measuring strategic
exploration over misleading metrics such as token-level entropy.

</details>


### [9] [An Empirical Evaluation of Factors Affecting SHAP Explanation of Time Series Classification](https://arxiv.org/abs/2509.03649)
*Davide Italo Serramazza,Nikos Papadeas,Zahraa Abdallah,Georgiana Ifrim*

Main category: cs.AI

TL;DR: 为解决SHAP在长时序数据解释中的计算效率问题，本文研究了八种时间序列分割算法对解释质量的影响。结果表明，分割数量比具体分割方法更重要，等长分割表现良好，且提出的长度加权归一化技术能持续提升解释质量。


<details>
  <summary>Details</summary>
Motivation: SHAP是一种优秀的归因方法，但其计算复杂性使其不适用于长时序数据。虽然通过分割聚合特征可以显著减少SHAP运行时间，但如何选择最优的分割策略仍是一个未解决的问题。

Method: 本文研究了八种不同的时间序列分割算法，以理解段组成如何影响解释质量。评估方法采用InterpretTime和AUC Difference两种已建立的XAI评估方法，并在多元和单变量时间序列上进行实验。此外，本文还引入了一种新颖的归因归一化技术，根据段的长度进行加权。

Result: 实验发现，分割的数量对解释质量的影响大于具体的分割方法。值得注意的是，等长分割的表现持续优于大多数自定义时间序列分割算法。此外，本文引入的长度加权归因归一化技术持续改善了归因质量。

Conclusion: 在时间序列分类模型的解释性AI中，分割数量是影响解释质量的关键因素，简单的等长分割策略表现出色。同时，提出的长度加权归因归一化技术能够有效提升解释质量。

Abstract: Explainable AI (XAI) has become an increasingly important topic for
understanding and attributing the predictions made by complex Time Series
Classification (TSC) models. Among attribution methods, SHapley Additive
exPlanations (SHAP) is widely regarded as an excellent attribution method; but
its computational complexity, which scales exponentially with the number of
features, limits its practicality for long time series. To address this, recent
studies have shown that aggregating features via segmentation, to compute a
single attribution value for a group of consecutive time points, drastically
reduces SHAP running time. However, the choice of the optimal segmentation
strategy remains an open question. In this work, we investigated eight
different Time Series Segmentation algorithms to understand how segment
compositions affect the explanation quality. We evaluate these approaches using
two established XAI evaluation methodologies: InterpretTime and AUC Difference.
Through experiments on both Multivariate (MTS) and Univariate Time Series
(UTS), we find that the number of segments has a greater impact on explanation
quality than the specific segmentation method. Notably, equal-length
segmentation consistently outperforms most of the custom time series
segmentation algorithms. Furthermore, we introduce a novel attribution
normalisation technique that weights segments by their length and we show that
it consistently improves attribution quality.

</details>


### [10] [PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming](https://arxiv.org/abs/2509.03728)
*Wesley Hanwen Deng,Sunnie S. Y. Kim,Akshita Jha,Ken Holstein,Motahhare Eslami,Lauren Wilcox,Leon A Gatys*

Main category: cs.AI

TL;DR: 本文提出了一种名为PersonaTeaming的自动化红队方法，通过在对抗性提示生成过程中引入不同身份（persona），显著提高了AI模型攻击成功率，并保持了提示多样性。


<details>
  <summary>Details</summary>
Motivation: AI治理和安全研究需要有效的红队方法来发现潜在风险。人类红队成员的身份和背景会影响其策略及发现的风险类型。然而，现有自动化红队方法未考虑身份因素，限制了对抗策略的探索。

Method: 本文开发了PersonaTeaming方法：1. 引入“红队专家”或“普通AI用户”等身份来变异提示。2. 开发动态身份生成算法，根据初始提示自动生成不同身份类型。3. 提出新的“变异距离”指标，以补充现有对抗性提示的多样性测量。

Result: 实验结果显示，通过身份变异，对抗性提示的攻击成功率相比现有最先进方法RainbowPlus有显著提升（最高达144.1%），同时保持了提示的多样性。

Conclusion: PersonaTeaming是自动化红队方法中融入人员背景和身份的初步尝试。研究讨论了不同身份类型和变异方法的优缺点，为未来探索自动化与人类红队方法的互补性提供了方向。

Abstract: Recent developments in AI governance and safety research have called for
red-teaming methods that can effectively surface potential risks posed by AI
models. Many of these calls have emphasized how the identities and backgrounds
of red-teamers can shape their red-teaming strategies, and thus the kinds of
risks they are likely to uncover. While automated red-teaming approaches
promise to complement human red-teaming by enabling larger-scale exploration of
model behavior, current approaches do not consider the role of identity. As an
initial step towards incorporating people's background and identities in
automated red-teaming, we develop and evaluate a novel method, PersonaTeaming,
that introduces personas in the adversarial prompt generation process to
explore a wider spectrum of adversarial strategies. In particular, we first
introduce a methodology for mutating prompts based on either "red-teaming
expert" personas or "regular AI user" personas. We then develop a dynamic
persona-generating algorithm that automatically generates various persona types
adaptive to different seed prompts. In addition, we develop a set of new
metrics to explicitly measure the "mutation distance" to complement existing
diversity measurements of adversarial prompts. Our experiments show promising
improvements (up to 144.1%) in the attack success rates of adversarial prompts
through persona mutation, while maintaining prompt diversity, compared to
RainbowPlus, a state-of-the-art automated red-teaming method. We discuss the
strengths and limitations of different persona types and mutation methods,
shedding light on future opportunities to explore complementarities between
automated and human red-teaming approaches.

</details>


### [11] [The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs](https://arxiv.org/abs/2509.03730)
*Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez*

Main category: cs.AI

TL;DR: 大语言模型(LLM)的指令对齐稳定了其性格特质的表达，但这些自报告的特质并不能可靠地预测行为，且与人类模式存在差异；人格注入也难以一致地影响实际行为，表明LLM的表面特质表达与行为一致性之间存在脱节。


<details>
  <summary>Details</summary>
Motivation: LLM展现出类似人类的性格特质，理解这些模式至关重要。然而，现有研究主要依赖简化自报告和启发式提示，缺乏行为验证，因此需要更系统地刻画LLM的性格。

Method: 本研究从三个维度系统性地刻画了LLM的性格：1) 训练阶段特质概貌的动态出现和演变；2) 自报告特质在行为任务中的预测有效性；3) 目标干预（如人格注入）对自报告和行为的影响。

Result: 指令对齐（如RLHF、指令微调）显著稳定了特质表达并强化了特质相关性，与人类数据相似。然而，这些自报告的特质不能可靠地预测行为，且观察到的关联常与人类模式不同。人格注入虽然能成功引导自报告，但对实际行为的影响甚微或不一致。

Conclusion: 本研究区分了LLM的表面特质表达和行为一致性，挑战了关于LLM性格的假设，并强调了在对齐和可解释性方面进行更深入评估的必要性。

Abstract: Personality traits have long been studied as predictors of human
behavior.Recent advances in Large Language Models (LLMs) suggest similar
patterns may emerge in artificial systems, with advanced LLMs displaying
consistent behavioral tendencies resembling human traits like agreeableness and
self-regulation. Understanding these patterns is crucial, yet prior work
primarily relied on simplified self-reports and heuristic prompting, with
little behavioral validation. In this study, we systematically characterize LLM
personality across three dimensions: (1) the dynamic emergence and evolution of
trait profiles throughout training stages; (2) the predictive validity of
self-reported traits in behavioral tasks; and (3) the impact of targeted
interventions, such as persona injection, on both self-reports and behavior.
Our findings reveal that instructional alignment (e.g., RLHF, instruction
tuning) significantly stabilizes trait expression and strengthens trait
correlations in ways that mirror human data. However, these self-reported
traits do not reliably predict behavior, and observed associations often
diverge from human patterns. While persona injection successfully steers
self-reports in the intended direction, it exerts little or inconsistent effect
on actual behavior. By distinguishing surface-level trait expression from
behavioral consistency, our findings challenge assumptions about LLM
personality and underscore the need for deeper evaluation in alignment and
interpretability.

</details>


### [12] [Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation](https://arxiv.org/abs/2509.03736)
*James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang*

Main category: cs.AI

TL;DR: 研究发现大型语言模型（LLMs）作为人类受试者替代品时存在显著的内部不一致性，尽管它们可能生成与人类相似的回答。


<details>
  <summary>Details</summary>
Motivation: LLMs的强大能力引发了合成代理可以替代真实人类参与者进行人类受试者研究的观点。现有研究主要关注LLM生成的调查数据是否与人类对应，但本研究旨在解决一个更根本的问题：代理在不同实验设置下能否保持内部一致性，即行为是否相似。

Method: 开发了一项研究，旨在(a)揭示代理的内部状态，以及(b)在基本对话设置中检查代理行为。该设计使得研究能够探索一系列行为假设，以评估代理的对话行为是否与其揭示的内部状态一致。

Result: 研究发现，在不同模型家族和不同模型大小的LLMs中存在显著的内部不一致性。最重要的是，尽管代理可能生成与人类对应的响应，但它们未能保持内部一致性。

Conclusion: LLMs缺乏内部一致性是其准确替代人类受试者进行人类研究的一个关键缺陷，这限制了它们在此类研究中的应用能力。

Abstract: The impressive capabilities of Large Language Models (LLMs) have fueled the
notion that synthetic agents can serve as substitutes for real participants in
human-subject research. In an effort to evaluate the merits of this claim,
social science researchers have largely focused on whether LLM-generated survey
data corresponds to that of a human counterpart whom the LLM is prompted to
represent. In contrast, we address a more fundamental question: Do agents
maintain internal consistency, retaining similar behaviors when examined under
different experimental settings? To this end, we develop a study designed to
(a) reveal the agent's internal state and (b) examine agent behavior in a basic
dialogue setting. This design enables us to explore a set of behavioral
hypotheses to assess whether an agent's conversation behavior is consistent
with what we would expect from their revealed internal state. Our findings on
these hypotheses show significant internal inconsistencies in LLMs across model
families and at differing model sizes. Most importantly, we find that, although
agents may generate responses matching those of their human counterparts, they
fail to be internally consistent, representing a critical gap in their
capabilities to accurately substitute for real participants in human-subject
research. Our simulation code and data are publicly accessible.

</details>


### [13] [RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs](https://arxiv.org/abs/2509.03768)
*Connor Walker,Koorosh Aslansefat,Mohammad Naveed Akram,Yiannis Papadopoulos*

Main category: cs.AI

TL;DR: RAGuard是一个增强型检索增强生成（RAG）框架，通过并行查询技术和安全文档集成，显著提升了离岸风电（OSW）维护中大型语言模型（LLM）的安全性召回率，同时保持了技术准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM在面对高度专业化或意外场景时，尤其是在离岸风电维护等安全关键领域，往往表现不佳，无法提供足够的准确性和安全性。

Method: 本文提出了RAGuard框架，它显式整合了安全关键文档和技术手册。通过向两个索引（知识和安全）并行查询，并为知识和安全分配独立的检索预算，确保了技术深度和安全覆盖。此外，还开发了SafetyClamp扩展，获取更大的候选池，并对安全进行“硬性限制”以保证精确槽位。评估涵盖了稀疏（BM25）、密集（DPR）和混合检索范式，测量了技术召回率@K和安全召回率@K。

Result: RAGuard及其SafetyClamp扩展将安全召回率@K从RAG的几乎0%提高到50%以上，同时将技术召回率保持在60%以上。

Conclusion: RAGuard和SafetyClamp有潜力为LLM驱动的决策支持在关键维护场景中整合安全保障树立新标准。

Abstract: Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet
conventional Large Language Models (LLMs) often fail when confronted with
highly specialised or unexpected scenarios. We introduce RAGuard, an enhanced
Retrieval-Augmented Generation (RAG) framework that explicitly integrates
safety-critical documents alongside technical manuals.By issuing parallel
queries to two indices and allocating separate retrieval budgets for knowledge
and safety, RAGuard guarantees both technical depth and safety coverage. We
further develop a SafetyClamp extension that fetches a larger candidate pool,
"hard-clamping" exact slot guarantees to safety. We evaluate across sparse
(BM25), dense (Dense Passage Retrieval) and hybrid retrieval paradigms,
measuring Technical Recall@K and Safety Recall@K. Both proposed extensions of
RAG show an increase in Safety Recall@K from almost 0\% in RAG to more than
50\% in RAGuard, while maintaining Technical Recall above 60\%. These results
demonstrate that RAGuard and SafetyClamp have the potential to establish a new
standard for integrating safety assurance into LLM-powered decision support in
critical maintenance contexts.

</details>


### [14] [Leveraging LLM-Based Agents for Intelligent Supply Chain Planning](https://arxiv.org/abs/2509.03811)
*Yongzhi Qi,Jiaheng Yin,Jianshen Zhang,Dongyang Geng,Zhengyu Chen,Hao Hu,Wei Qi,Zuo-Jun Max Shen*

Main category: cs.AI

TL;DR: 本文提出并部署了一个基于大语言模型代理（LLM-agent）的供应链规划代理（SCPA）框架，用于解决电子商务平台复杂的供应链规划问题，并在京东的真实场景中取得了显著的效率和指标提升。


<details>
  <summary>Details</summary>
Motivation: 供应链管理中的规划是一个复杂且关键的概念，涉及需求预测、库存管理、销售运营和补货等多个方面。从电商平台角度，如何收集数据、制定长期计划、动态调整计划，同时确保可解释性、效率和可靠性，是一个具有挑战性的实际问题。近年来AI技术，特别是大语言模型的快速发展，为解决这些问题提供了新工具。

Method: 研究人员构建了一个供应链规划代理（SCPA）框架。该框架能够理解领域知识、领会操作员需求、分解任务、利用或创建新工具，并返回基于证据的规划报告。该框架被部署在京东的真实场景中进行验证。

Result: SCPA框架在京东的真实场景中成功部署，证明了LLM-agent在供应链中应用的可行性。它有效地减少了劳动力，并提高了准确性、库存可用性以及其他关键指标。

Conclusion: LLM-agent在供应链规划中具有实际应用的可行性和显著效益，能够有效应对复杂的规划挑战，并通过减少劳动力和提高关键指标来提升效率和性能。

Abstract: In supply chain management, planning is a critical concept. The movement of
physical products across different categories, from suppliers to warehouse
management, to sales, and logistics transporting them to customers, entails the
involvement of many entities. It covers various aspects such as demand
forecasting, inventory management, sales operations, and replenishment. How to
collect relevant data from an e-commerce platform's perspective, formulate
long-term plans, and dynamically adjust them based on environmental changes,
while ensuring interpretability, efficiency, and reliability, is a practical
and challenging problem. In recent years, the development of AI technologies,
especially the rapid progress of large language models, has provided new tools
to address real-world issues. In this work, we construct a Supply Chain
Planning Agent (SCPA) framework that can understand domain knowledge,
comprehend the operator's needs, decompose tasks, leverage or create new tools,
and return evidence-based planning reports. We deploy this framework in
JD.com's real-world scenario, demonstrating the feasibility of LLM-agent
applications in the supply chain. It effectively reduced labor and improved
accuracy, stock availability, and other key metrics.

</details>


### [15] [Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning](https://arxiv.org/abs/2509.03817)
*Wei Yang,Jesse Thomason*

Main category: cs.AI

TL;DR: 本文提出了一种元策略审议框架（MPDF），通过让多智能体大型语言模型（LLMs）学习去中心化的元认知动作策略（坚持、精炼、让步），并结合新型强化学习算法SoftRankPO，显著提高了复杂推理任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型多智能体系统受限于固定的协作协议，仅关注宏观编排，忽视了智能体基于不确定性或信心等内部认知状态进行内部审议的能力，将智能体视为被动执行者，限制了其有效性。

Method: 引入了元策略审议框架（MPDF），其中智能体学习一组高级元认知动作（坚持、精炼、让步）的去中心化策略。为解决传统策略梯度在此设置下的不稳定性，开发了新型强化学习算法SoftRankPO。SoftRankPO通过基于奖励排名（通过平滑正态分位数映射）来塑造优势，从而稳定训练，使其对奖励方差具有鲁棒性。

Result: 实验结果表明，与六种最先进的启发式和基于学习的多智能体推理算法相比，采用SoftRankPO的MPDF在五个数学和通用推理基准测试中，平均准确率绝对提高了4-5%。

Conclusion: 本研究为多智能体LLM系统学习自适应、元认知策略提供了一种新范式，将重点从设计固定协议转向学习动态、审议性的策略。

Abstract: Multi-agent systems of large language models (LLMs) show promise for complex
reasoning, but their effectiveness is often limited by fixed collaboration
protocols. These frameworks typically focus on macro-level orchestration while
overlooking agents' internal deliberative capabilities. This critical
meta-cognitive blindspot treats agents as passive executors unable to adapt
their strategy based on internal cognitive states like uncertainty or
confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where
agents learn a decentralized policy over a set of high-level meta-cognitive
actions: Persist, Refine, and Concede. To overcome the instability of
traditional policy gradients in this setting, we develop SoftRankPO, a novel
reinforcement learning algorithm. SoftRankPO stabilizes training by shaping
advantages based on the rank of rewards mapped through smooth normal quantiles,
making the learning process robust to reward variance. Experiments show that
MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across
five mathematical and general reasoning benchmarks compared to six
state-of-the-art heuristic and learning-based multi-agent reasoning algorithms.
Our work presents a paradigm for learning adaptive, meta-cognitive policies for
multi-agent LLM systems, shifting the focus from designing fixed protocols to
learning dynamic, deliberative strategies.

</details>


### [16] [What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models](https://arxiv.org/abs/2509.03827)
*Pierre Le Coz,Jia An Liu,Debarun Bhattacharjya,Georgina Curto,Serge Stinckwich*

Main category: cs.AI

TL;DR: 本研究评估了大型语言模型（LLMs）在解决无家可归问题等社会政策制定方面的潜力，通过基准测试和基于代理的模型模拟，发现LLMs在专家协作和适当防护下可提供有价值的政策见解。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）因其处理非结构化数据、探索灵活场景和处理多样化情境的能力，在社会政策制定中具有提供新见解的潜力。本研究旨在评估LLMs在解决全球无家可归问题这一复杂社会挑战中，是否能与领域专家保持一致，并有效为社会政策制定提供信息。

Method: 研究开发了一个包含决策场景和政策选择的新型基准，涵盖四个不同地理区域（美国南本德、西班牙巴塞罗那、南非约翰内斯堡、中国澳门特区）。所选政策基于人类发展的能力方法框架。此外，研究还提出了一个自动化流程，将基准政策连接到基于代理的模型，并通过模拟社会场景探索推荐政策的社会影响。

Result: 研究结果显示，利用大型语言模型进行社会政策制定具有巨大的前景。

Conclusion: 如果能与当地领域专家合作引入负责任的防护措施和情境校准，大型语言模型可以为人类提供有价值的见解，以大规模替代政策的形式，从而辅助社会政策制定。

Abstract: Large language models (LLMs) are increasingly being adopted in high-stakes
domains. Their capacity to process vast amounts of unstructured data, explore
flexible scenarios, and handle a diversity of contextual factors can make them
uniquely suited to provide new insights for the complexity of social
policymaking. This article evaluates whether LLMs' are aligned with domain
experts (and among themselves) to inform social policymaking on the subject of
homelessness alleviation - a challenge affecting over 150 million people
worldwide. We develop a novel benchmark comprised of decision scenarios with
policy choices across four geographies (South Bend, USA; Barcelona, Spain;
Johannesburg, South Africa; Macau SAR, China). The policies in scope are
grounded in the conceptual framework of the Capability Approach for human
development. We also present an automated pipeline that connects the
benchmarked policies to an agent-based model, and we explore the social impact
of the recommended policies through simulated social scenarios. The paper
results reveal promising potential to leverage LLMs for social policy making.
If responsible guardrails and contextual calibrations are introduced in
collaboration with local domain experts, LLMs can provide humans with valuable
insights, in the form of alternative policies at scale.

</details>


### [17] [An Agentic Model Context Protocol Framework for Medical Concept Standardization](https://arxiv.org/abs/2509.03828)
*Jaerong Ahn,Andrew Wen,Nan Wang,Heling Jia,Zhiyi Yue,Sunyang Fu,Hongfang Liu*

Main category: cs.AI

TL;DR: 本文开发了一个基于模型上下文协议（MCP）的零训练、防幻觉映射系统，用于将源医疗术语高效准确地映射到OMOP CDM标准概念，解决了传统方法资源密集且易错的问题。


<details>
  <summary>Details</summary>
Motivation: 将异构健康数据标准化为OMOP CDM时，将源医疗术语映射到OMOP标准概念是一个资源密集且易错的关键步骤。虽然大型语言模型（LLMs）有潜力简化此过程，但其固有的“幻觉”倾向使其不适合未经训练和专家验证的临床部署。

Method: 研究开发了一个零训练、防幻觉的映射系统。该系统基于模型上下文协议（MCP），这是一个标准化且安全的框架，允许LLMs与外部资源和工具进行交互。

Result: 该系统实现了可解释的映射，显著提高了效率和准确性，且只需极少的努力。它提供了实时词汇查找和结构化推理输出，适用于探索性和生产环境的即时使用。

Conclusion: 该零训练、防幻觉的映射系统能够有效利用LLMs的优势，同时避免其缺点，为OMOP CDM数据标准化提供了一个高效、准确且可解释的解决方案，适用于实际部署。

Abstract: The Observational Medical Outcomes Partnership (OMOP) common data model (CDM)
provides a standardized representation of heterogeneous health data to support
large-scale, multi-institutional research. One critical step in data
standardization using OMOP CDM is the mapping of source medical terms to OMOP
standard concepts, a procedure that is resource-intensive and error-prone.
While large language models (LLMs) have the potential to facilitate this
process, their tendency toward hallucination makes them unsuitable for clinical
deployment without training and expert validation. Here, we developed a
zero-training, hallucination-preventive mapping system based on the Model
Context Protocol (MCP), a standardized and secure framework allowing LLMs to
interact with external resources and tools. The system enables explainable
mapping and significantly improves efficiency and accuracy with minimal effort.
It provides real-time vocabulary lookups and structured reasoning outputs
suitable for immediate use in both exploratory and production environments.

</details>


### [18] [A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai](https://arxiv.org/abs/2509.03830)
*Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng*

Main category: cs.AI

TL;DR: 本研究提出一个多维AI框架，利用社交媒体的多模态数据（照片和评论）分析游客对历史城区的感知，以支持可持续的城市规划。


<details>
  <summary>Details</summary>
Motivation: 历史城区在文化遗产保护和旅游生活中扮演重要角色。理解游客对这些环境的感知对于可持续、以人为本的城市规划至关重要。

Method: 该研究提出了一个多维AI框架，应用于上海的十二个历史街区。框架整合了焦点区域提取、色彩主题分析和情感挖掘。通过微调的语义分割模型识别照片中的视觉焦点区域；利用聚类方法提取主导颜色并分析其空间分布，同时比较社交媒体照片与实际街景的色彩主题；通过结合基于规则的方法和多任务BERT模型的混合情感分析方法评估游客评论，并从旅游活动、建成环境、服务设施和商业形式四个维度评估满意度。

Result: 研究发现社交媒体照片与实际街景的色彩主题存在显著差异，表明视觉预期与建成环境之间可能存在差距，反映了风格偏好和感知偏差。结果还揭示了美学吸引力和情感反应上的空间差异。

Conclusion: 该框架提供了一种整合的、数据驱动的方法来解读游客感知，有助于旅游、遗产保护和美学公共空间设计中的知情决策。

Abstract: Historic urban quarters play a vital role in preserving cultural heritage
while serving as vibrant spaces for tourism and everyday life. Understanding
how tourists perceive these environments is essential for sustainable,
human-centered urban planning. This study proposes a multidimensional
AI-powered framework for analyzing tourist perception in historic urban
quarters using multimodal data from social media. Applied to twelve historic
quarters in central Shanghai, the framework integrates focal point extraction,
color theme analysis, and sentiment mining. Visual focus areas are identified
from tourist-shared photos using a fine-tuned semantic segmentation model. To
assess aesthetic preferences, dominant colors are extracted using a clustering
method, and their spatial distribution across quarters is analyzed. Color
themes are further compared between social media photos and real-world street
views, revealing notable shifts. This divergence highlights potential gaps
between visual expectations and the built environment, reflecting both
stylistic preferences and perceptual bias. Tourist reviews are evaluated
through a hybrid sentiment analysis approach combining a rule-based method and
a multi-task BERT model. Satisfaction is assessed across four dimensions:
tourist activities, built environment, service facilities, and business
formats. The results reveal spatial variations in aesthetic appeal and
emotional response. Rather than focusing on a single technical innovation, this
framework offers an integrated, data-driven approach to decoding tourist
perception and contributes to informed decision-making in tourism, heritage
conservation, and the design of aesthetically engaging public spaces.

</details>


### [19] [Continuous Monitoring of Large-Scale Generative AI via Deterministic Knowledge Graph Structures](https://arxiv.org/abs/2509.03857)
*Kishor Datta Gupta,Mohd Ariful Haque,Hasmot Ali,Marufa Kamal,Syed Bahauddin Alam,Mohammad Ashiqur Rahman*

Main category: cs.AI

TL;DR: 本研究提出了一种使用确定性知识图谱（KG）和LLM生成知识图谱的系统方法，通过持续比较两者来实时监测和评估生成式AI（GEN AI）的可靠性，以检测幻觉和语义偏差。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型存在可靠性问题，如幻觉、语义漂移和固有偏见，且通常是黑箱操作，难以透明评估。现有评估方法主要依赖主观人工评估，缺乏可扩展性、透明度和效率。

Method: 研究构建了两个并行的知识图谱：1) 确定性KG，通过显式规则、预定义本体和结构化实体关系提取构建；2) LLM生成KG，从实时文本数据流（如实时新闻文章）动态生成。通过使用Instantiated Class Ratio (ICR)、Instantiated Property Ratio (IPR) 和 Class Instantiation (CI) 等KG指标，量化两个KG之间的结构偏差和语义差异。一个自动化实时监控框架持续计算这些偏差，并基于历史结构指标分布建立动态异常阈值，以主动识别和标记显著偏差。

Result: 该方法能够持续计算确定性KG与LLM生成KG之间的偏差，并通过动态异常阈值主动识别并标记显著偏差，从而及时检测语义异常或幻觉。

Conclusion: 通过确定性KG与动态生成KG之间的结构化、指标驱动比较，本研究提供了一个鲁棒且可扩展的生成式AI评估框架。

Abstract: Generative AI (GEN AI) models have revolutionized diverse application domains
but present substantial challenges due to reliability concerns, including
hallucinations, semantic drift, and inherent biases. These models typically
operate as black-boxes, complicating transparent and objective evaluation.
Current evaluation methods primarily depend on subjective human assessment,
limiting scalability, transparency, and effectiveness. This research proposes a
systematic methodology using deterministic and Large Language Model
(LLM)-generated Knowledge Graphs (KGs) to continuously monitor and evaluate GEN
AI reliability. We construct two parallel KGs: (i) a deterministic KG built
using explicit rule-based methods, predefined ontologies, domain-specific
dictionaries, and structured entity-relation extraction rules, and (ii) an
LLM-generated KG dynamically derived from real-time textual data streams such
as live news articles. Utilizing real-time news streams ensures authenticity,
mitigates biases from repetitive training, and prevents adaptive LLMs from
bypassing predefined benchmarks through feedback memorization. To quantify
structural deviations and semantic discrepancies, we employ several established
KG metrics, including Instantiated Class Ratio (ICR), Instantiated Property
Ratio (IPR), and Class Instantiation (CI). An automated real-time monitoring
framework continuously computes deviations between deterministic and
LLM-generated KGs. By establishing dynamic anomaly thresholds based on
historical structural metric distributions, our method proactively identifies
and flags significant deviations, thus promptly detecting semantic anomalies or
hallucinations. This structured, metric-driven comparison between deterministic
and dynamically generated KGs delivers a robust and scalable evaluation
framework.

</details>


### [20] [Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata](https://arxiv.org/abs/2509.03863)
*Sina Khajehabdollahi,Gautier Hamon,Marko Cvjetko,Pierre-Yves Oudeyer,Clément Moulin-Frier,Cédric Colas*

Main category: cs.AI

TL;DR: 本文提出了一种名为“远征与扩展”（E&E）的混合探索策略，用于发现连续元胞自动机中多样化的视觉模式。E&E结合了局部新颖性驱动的扩展和由视觉-语言模型（VLM）引导的目标导向远征，以克服传统方法陷入局部最优的问题，并在人类感知的语义空间中进行探索。


<details>
  <summary>Details</summary>
Motivation: 在连续元胞自动机（CA）中发现多样化的视觉模式具有挑战性，因为高维行为空间巨大且冗余。传统的探索方法（如新颖性搜索）通过变异已知新颖解进行局部扩展，但当局部新颖性耗尽时，往往会停滞不前，无法到达遥远、未探索的区域。

Method: E&E是一种混合策略，探索在局部新颖性驱动的扩展和目标导向的远征之间交替进行。在远征期间，E&E利用视觉-语言模型（VLM）生成语言目标（即有趣但假设的模式描述），从而将探索引向未知的区域。通过在与人类感知对齐的语义空间中操作，E&E以概念上有意义的方式评估新颖性并生成目标。

Result: 在以其丰富的涌现行为而闻名的Flow Lenia（一种连续CA）上进行测试，E&E始终比现有探索方法发现更多样化的解决方案。家谱分析进一步揭示，源自远征的解决方案对长期探索产生了不成比例的影响，解锁了新的行为生态位，为后续搜索提供了垫脚石。

Conclusion: 这些发现突出了E&E突破局部新颖性界限并以与人类对齐、可解释的方式探索行为景观的能力。E&E为人工生命及其他领域的开放式探索提供了一个有前景的模板。

Abstract: Discovering diverse visual patterns in continuous cellular automata (CA) is
challenging due to the vastness and redundancy of high-dimensional behavioral
spaces. Traditional exploration methods like Novelty Search (NS) expand locally
by mutating known novel solutions but often plateau when local novelty is
exhausted, failing to reach distant, unexplored regions. We introduce
Expedition and Expansion (E&E), a hybrid strategy where exploration alternates
between local novelty-driven expansions and goal-directed expeditions. During
expeditions, E&E leverages a Vision-Language Model (VLM) to generate linguistic
goals--descriptions of interesting but hypothetical patterns that drive
exploration toward uncharted regions. By operating in semantic spaces that
align with human perception, E&E both evaluates novelty and generates goals in
conceptually meaningful ways, enhancing the interpretability and relevance of
discovered behaviors. Tested on Flow Lenia, a continuous CA known for its rich,
emergent behaviors, E&E consistently uncovers more diverse solutions than
existing exploration methods. A genealogical analysis further reveals that
solutions originating from expeditions disproportionately influence long-term
exploration, unlocking new behavioral niches that serve as stepping stones for
subsequent search. These findings highlight E&E's capacity to break through
local novelty boundaries and explore behavioral landscapes in human-aligned,
interpretable ways, offering a promising template for open-ended exploration in
artificial life and beyond.

</details>


### [21] [Handling Infinite Domain Parameters in Planning Through Best-First Search with Delayed Partial Expansions](https://arxiv.org/abs/2509.03953)
*Ángel Aso-Mollar,Diego Aineto,Enrico Scala,Eva Onaindia*

Main category: cs.AI

TL;DR: 本文提出了一种新的启发式搜索算法，用于处理包含连续控制参数的自动化规划问题，该算法将控制参数明确视为决策点而非约束，并证明了其在特定条件下的完备性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要将控制参数作为嵌入式约束处理，隐式地将其视为额外的限制而非搜索空间中的决策点。这促使研究者开发一种更有效的方法，明确地将控制参数视为真正的决策点。

Method: 研究人员开发了一种最佳优先的启发式搜索算法，该算法在由控制参数定义的无限决策空间中操作。该算法利用“延迟部分扩展”的概念，即状态不是完全扩展，而是增量地扩展其一部分后继节点。同时，该方法在特定条件下证明了其在极限情况下的完备性。

Result: 研究结果表明，这种新颖的搜索算法在解决涉及控制参数的规划问题时，是现有方法的一个有竞争力的替代方案。

Conclusion: 通过将控制参数明确地视为决策点并采用延迟部分扩展的启发式搜索算法，本文提供了一种有效且具有竞争力的解决方案，用于处理包含连续数值决策变量的自动化规划问题。

Abstract: In automated planning, control parameters extend standard action
representations through the introduction of continuous numeric decision
variables. Existing state-of-the-art approaches have primarily handled control
parameters as embedded constraints alongside other temporal and numeric
restrictions, and thus have implicitly treated them as additional constraints
rather than as decision points in the search space. In this paper, we propose
an efficient alternative that explicitly handles control parameters as true
decision points within a systematic search scheme. We develop a best-first,
heuristic search algorithm that operates over infinite decision spaces defined
by control parameters and prove a notion of completeness in the limit under
certain conditions. Our algorithm leverages the concept of delayed partial
expansion, where a state is not fully expanded but instead incrementally
expands a subset of its successors. Our results demonstrate that this novel
search algorithm is a competitive alternative to existing approaches for
solving planning problems involving control parameters.

</details>


### [22] [FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace](https://arxiv.org/abs/2509.03890)
*Yineng Yan,Xidong Wang,Jin Seng Cheng,Ran Hu,Wentao Guan,Nahid Farahmand,Hengte Lin,Yue Li*

Main category: cs.AI

TL;DR: 本文介绍了一种基于LLM的智能代理助手FaMA，通过对话式交互简化C2C电商平台（如Facebook Marketplace）的复杂GUI操作，显著提高了任务成功率和交互效率。


<details>
  <summary>Details</summary>
Motivation: C2C电商平台上的核心任务通常需要用户操作复杂的图形用户界面（GUI），这使得买家和卖家的体验都非常耗时。代理式AI的兴起为解决数字环境中的长期挑战提供了机会。

Method: 论文提出了一种新方法，通过LLM驱动的代理助手FaMA来简化交互。该助手作为市场的新型对话式入口，将主要交互模式从复杂GUI转变为直观的AI代理。它通过解释自然语言命令来自动化高摩擦工作流程，例如简化卖家列表更新、批量消息发送，以及为买家提供对话式搜索以实现高效产品发现。

Result: 实验表明，FaMA在解决市场上的复杂任务时达到了98%的任务成功率，并将交互时间加快了多达2倍。

Conclusion: 基于LLM的代理式对话范式为传统应用界面提供了一种轻量级且更易于访问的替代方案，使用户能够更高效地管理其市场活动。

Abstract: The emergence of agentic AI, powered by Large Language Models (LLMs), marks a
paradigm shift from reactive generative systems to proactive, goal-oriented
autonomous agents capable of sophisticated planning, memory, and tool use. This
evolution presents a novel opportunity to address long-standing challenges in
complex digital environments. Core tasks on Consumer-to-Consumer (C2C)
e-commerce platforms often require users to navigate complex Graphical User
Interfaces (GUIs), making the experience time-consuming for both buyers and
sellers. This paper introduces a novel approach to simplify these interactions
through an LLM-powered agentic assistant. This agent functions as a new,
conversational entry point to the marketplace, shifting the primary interaction
model from a complex GUI to an intuitive AI agent. By interpreting natural
language commands, the agent automates key high-friction workflows. For
sellers, this includes simplified updating and renewal of listings, and the
ability to send bulk messages. For buyers, the agent facilitates a more
efficient product discovery process through conversational search. We present
the architecture for Facebook Marketplace Assistant (FaMA), arguing that this
agentic, conversational paradigm provides a lightweight and more accessible
alternative to traditional app interfaces, allowing users to manage their
marketplace activities with greater efficiency. Experiments show FaMA achieves
a 98% task success rate on solving complex tasks on the marketplace and enables
up to a 2x speedup on interaction time.

</details>


### [23] [A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning](https://arxiv.org/abs/2509.03906)
*Qika Lin,Yifan Zhu,Bin Pu,Ling Huang,Haoran Luo,Jingying Ma,Zhen Peng,Tianzhe Zhao,Fangzhi Xu,Jian Zhang,Kai He,Zhonghong Ou,Swapnil Mishra,Mengling Feng*

Main category: cs.AI

TL;DR: DeepMedix-R1是一个用于胸部X光（CXR）解释的全面医疗基础模型，通过顺序训练（指令微调、合成推理、在线强化学习）提供透明且局部关联的推理过程，显著提升了报告生成和视觉问答任务的性能，并增强了可解释性和临床合理性。


<details>
  <summary>Details</summary>
Motivation: 当前的医疗基础模型通常以“黑箱”方式生成答案，缺乏透明的推理过程和局部关联的可解释性，这阻碍了它们在临床中的实际部署。

Method: DeepMedix-R1采用顺序训练流程：首先在精选的CXR指令数据上进行微调以获得基本解释能力；然后通过高质量的合成推理样本实现冷启动推理；最后通过在线强化学习进行优化，以提高局部关联推理质量和生成性能。该模型为每个查询生成答案和与图像局部区域相关的推理步骤。此外，提出Report Arena基准框架，使用高级语言模型评估答案质量。

Result: 定量评估显示，DeepMedix-R1在报告生成任务上比LLaVA-Rad和MedGemma分别提高了14.54%和31.32%；在视觉问答任务上比MedGemma和CheXagent分别提高了57.75%和23.06%。Report Arena基准测试进一步突出了其优越性。专家对生成推理步骤的审查表明，其可解释性和临床合理性优于Qwen2.5-VL-7B模型（总体偏好为0.7416 vs. 0.2584）。

Conclusion: 本工作推动了医疗基础模型的发展，使其在CXR解释方面实现全面、透明和具有临床可操作性的建模。

Abstract: Medical foundation models (FMs) have shown tremendous promise amid the rapid
advancements in artificial intelligence (AI) technologies. However, current
medical FMs typically generate answers in a black-box manner, lacking
transparent reasoning processes and locally grounded interpretability, which
hinders their practical clinical deployments. To this end, we introduce
DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It
leverages a sequential training pipeline: initially fine-tuned on curated CXR
instruction data to equip with fundamental CXR interpretation capabilities,
then exposed to high-quality synthetic reasoning samples to enable cold-start
reasoning, and finally refined via online reinforcement learning to enhance
both grounded reasoning quality and generation performance. Thus, the model
produces both an answer and reasoning steps tied to the image's local regions
for each query. Quantitative evaluation demonstrates substantial improvements
in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and
visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent)
tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking
framework using advanced language models to evaluate answer quality, further
highlighting the superiority of DeepMedix-R1. Expert review of generated
reasoning steps reveals greater interpretability and clinical plausibility
compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall
preference). Collectively, our work advances medical FM development toward
holistic, transparent, and clinically actionable modeling for CXR
interpretation.

</details>


### [24] [World Model Implanting for Test-time Adaptation of Embodied Agents](https://arxiv.org/abs/2509.03956)
*Minjong Yoo,Jinwoo Jang,Sihyung Yoon,Honguk Woo*

Main category: cs.AI

TL;DR: 本文提出WorMI框架，通过在测试时组合大型语言模型（LLM）与领域特定的世界模型，使具身智能体在无需大量数据或再训练的情况下，实现跨领域的鲁棒适应。


<details>
  <summary>Details</summary>
Motivation: 具身AI面临的持续挑战是，如何在不进行大量数据收集或再训练的情况下，使智能体能够鲁棒地适应新领域。

Method: WorMI框架结合了LLM的推理能力和独立学习的领域特定世界模型，通过测试时组合实现。该框架支持世界模型的无缝植入和移除。具体方法包括：1) 采用基于原型的世界模型检索方法，利用高效的基于轨迹的抽象表示匹配来整合相关模型；2) 开发了一种世界级复合注意力机制，不仅整合了检索到的世界模型的知识，还将其中间表示与推理模型在智能体策略中的表示对齐。

Result: WorMI在VirtualHome和ALFWorld基准测试中进行了评估，在各种未见领域，与几种基于LLM的方法相比，展现出卓越的零样本和少样本性能。

Conclusion: 这些结果突出了该框架在具身智能体场景中可扩展、真实世界部署的潜力，特别是在适应性和数据效率至关重要的应用中。

Abstract: In embodied AI, a persistent challenge is enabling agents to robustly adapt
to novel domains without requiring extensive data collection or retraining. To
address this, we present a world model implanting framework (WorMI) that
combines the reasoning capabilities of large language models (LLMs) with
independently learned, domain-specific world models through test-time
composition. By allowing seamless implantation and removal of the world models,
the embodied agent's policy achieves and maintains cross-domain adaptability.
In the WorMI framework, we employ a prototype-based world model retrieval
approach, utilizing efficient trajectory-based abstract representation
matching, to incorporate relevant models into test-time composition. We also
develop a world-wise compound attention method that not only integrates the
knowledge from the retrieved world models but also aligns their intermediate
representations with the reasoning model's representation within the agent's
policy. This framework design effectively fuses domain-specific knowledge from
multiple world models, ensuring robust adaptation to unseen domains. We
evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating
superior zero-shot and few-shot performance compared to several LLM-based
approaches across a range of unseen domains. These results highlight the
frameworks potential for scalable, real-world deployment in embodied agent
scenarios where adaptability and data efficiency are essential.

</details>


### [25] [Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent](https://arxiv.org/abs/2509.03990)
*Chunlong Wu,Zhibo Qu*

Main category: cs.AI

TL;DR: Meta-Policy Reflexion (MPR) 是一种混合框架，通过将大型语言模型（LLM）生成的反思整合到结构化的元策略记忆（MPM）中，并在推理时通过软记忆引导解码和硬规则可采纳性检查来应用，从而提高LLM代理的跨任务性能、探索效率和适应性。


<details>
  <summary>Details</summary>
Motivation: LLM代理在单一任务上表现出色，但常出现重复失败、探索效率低下和跨任务适应性有限的问题。现有反思策略（如Reflexion, ReAct）仅改进单次行为，但其痕迹是短暂且任务特定的，无法跨任务重用。基于强化学习的方法可以生成可迁移策略，但需要大量的参数更新和计算资源。

Method: 本文提出了元策略反思（Meta-Policy Reflexion, MPR）。它将LLM生成的反思整合为结构化的、谓词式的元策略记忆（Meta-Policy Memory, MPM）。在推理时，通过两种互补机制应用该记忆：软记忆引导解码（soft memory-guided decoding）和硬规则可采纳性检查（hard rule admissibility checks, HAC）。MPR无需模型权重更新即可外化可重用的纠正性知识，强制执行领域约束以减少不安全或无效动作，并保留了基于语言的反思的适应性。文中形式化了MPM表示，并提供了更新和解码算法。

Result: 在基于AlfWorld的文本代理环境中进行的实证结果表明，与Reflexion基线相比，MPR在执行准确性和鲁棒性方面持续获得提升；规则可采纳性（HAC）进一步提高了稳定性。研究还分析了解释这些收益的机制。

Conclusion: MPR通过将LLM生成的反思系统地整合到可重用的元策略记忆中，并在推理时有效应用，成功解决了LLM代理的重复失败、低效探索和跨任务适应性差的问题，显著提高了其性能和稳定性。该方法无需模型权重更新，具有较好的通用性和适应性。

Abstract: Large language model (LLM) agents achieve impressive single-task performance
but commonly exhibit repeated failures, inefficient exploration, and limited
cross-task adaptability. Existing reflective strategies (e.g., Reflexion,
ReAct) improve per-episode behavior but typically produce ephemeral,
task-specific traces that are not reused across tasks. Reinforcement-learning
based alternatives can produce transferable policies but require substantial
parameter updates and compute. In this work we introduce Meta-Policy Reflexion
(MPR): a hybrid framework that consolidates LLM-generated reflections into a
structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at
inference time through two complementary mechanisms soft memory-guided decoding
and hard rule admissibility checks(HAC). MPR (i) externalizes reusable
corrective knowledge without model weight updates, (ii) enforces domain
constraints to reduce unsafe or invalid actions, and (iii) retains the
adaptability of language-based reflection. We formalize the MPM representation,
present algorithms for update and decoding, and validate the approach in a
text-based agent environment following the experimental protocol described in
the provided implementation (AlfWorld-based). Empirical results reported in the
supplied material indicate consistent gains in execution accuracy and
robustness when compared to Reflexion baselines; rule admissibility further
improves stability. We analyze mechanisms that explain these gains, discuss
scalability and failure modes, and outline future directions for multimodal and
multi?agent extensions.

</details>


### [26] [AutoPBO: LLM-powered Optimization for Local Search PBO Solvers](https://arxiv.org/abs/2509.04007)
*Jinyuan Li,Yi Chu,Yiwen Sun,Mengchuan Zou,Shaowei Cai*

Main category: cs.AI

TL;DR: AutoPBO是一个基于大型语言模型（LLM）的框架，用于自动增强伪布尔优化（PBO）局部搜索求解器，实验表明其显著优于现有局部搜索方法，并与最先进的求解器保持竞争力。


<details>
  <summary>Details</summary>
Motivation: 伪布尔优化（PBO）局部搜索求解器的效率高度依赖于内部启发式算法，其设计通常需要大量的专家努力和手动调整。尽管大型语言模型（LLM）在自动化算法设计方面表现出潜力，但它们在优化PBO求解器方面的应用尚未被探索。

Method: 本文提出了AutoPBO，一个新颖的LLM驱动框架，用于自动增强PBO局部搜索求解器。通过在四个广泛的公共基准（包括真实世界、PB竞赛、整数线性规划和组合基准）上进行实验，评估AutoPBO的性能改进，并与六个最先进的竞争对手进行比较。

Result: AutoPBO在性能上显著优于以前的局部搜索方法，同时与最先进的竞争对手相比保持了竞争力。

Conclusion: AutoPBO为自动化局部搜索求解器设计提供了一种有前景的方法。

Abstract: Pseudo-Boolean Optimization (PBO) provides a powerful framework for modeling
combinatorial problems through pseudo-Boolean (PB) constraints. Local search
solvers have shown excellent performance in PBO solving, and their efficiency
is highly dependent on their internal heuristics to guide the search. Still,
their design often requires significant expert effort and manual tuning in
practice. While Large Language Models (LLMs) have demonstrated potential in
automating algorithm design, their application to optimizing PBO solvers
remains unexplored. In this work, we introduce AutoPBO, a novel LLM-powered
framework to automatically enhance PBO local search solvers. We conduct
experiments on a broad range of four public benchmarks, including one
real-world benchmark, a benchmark from PB competition, an integer linear
programming optimization benchmark, and a crafted combinatorial benchmark, to
evaluate the performance improvement achieved by AutoPBO and compare it with
six state-of-the-art competitors, including two local search PBO solvers NuPBO
and OraSLS, two complete PB solvers PBO-IHS and RoundingSat, and two mixed
integer programming (MIP) solvers Gurobi and SCIP. AutoPBO demonstrates
significant improvements over previous local search approaches, while
maintaining competitive performance compared to state-of-the-art competitors.
The results suggest that AutoPBO offers a promising approach to automating
local search solver design.

</details>


### [27] [CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.04027)
*Zeyu Gan,Hao Yi,Yong Liu*

Main category: cs.AI

TL;DR: 针对大型语言模型（LLMs）推理能力的强化学习（RL），本文提出了CoT-Space框架，将推理视为连续语义空间中的优化过程，解释了最优思维链（CoT）长度是欠拟合与过拟合权衡的自然结果，并为未来推理代理的发展奠定了理论基础。


<details>
  <summary>Details</summary>
Motivation: 传统的基于token的强化学习框架未能与LLMs复杂的多步骤推理过程（如思维链CoT）的推理级别性质对齐，存在显著的理论空白。

Method: 引入了CoT-Space这一新颖的理论框架，将LLM推理从离散的token预测任务重新定义为连续、推理级别的语义空间中的优化过程。该过程从噪声和风险两个角度进行了分析。

Result: 证明了收敛到最优CoT长度是欠拟合和过拟合之间基本权衡的自然结果。广泛的实验为理论发现提供了强有力的实证验证。该框架解释了“过度思考”等经验现象。

Conclusion: CoT-Space框架不仅为经验现象提供了连贯的解释，也为未来开发更有效、更通用的大模型推理代理提供了坚实的理论基础。

Abstract: Reinforcement Learning (RL) has become a pivotal approach for enhancing the
reasoning capabilities of Large Language Models (LLMs). However, a significant
theoretical gap persists, as traditional token-level RL frameworks fail to
align with the reasoning-level nature of complex, multi-step thought processes
like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space,
a novel theoretical framework that recasts LLM reasoning from a discrete
token-prediction task to an optimization process within a continuous,
reasoning-level semantic space. By analyzing this process from both a noise
perspective and a risk perspective, we demonstrate that the convergence to an
optimal CoT length is a natural consequence of the fundamental trade-off
between underfitting and overfitting. Furthermore, extensive experiments
provide strong empirical validation for our theoretical findings. Our framework
not only provides a coherent explanation for empirical phenomena such as
overthinking but also offers a solid theoretical foundation to guide the future
development of more effective and generalizable reasoning agents.

</details>


### [28] [Oruga: An Avatar of Representational Systems Theory](https://arxiv.org/abs/2509.04041)
*Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng*

Main category: cs.AI

TL;DR: 本文介绍了Oruga，一个实现了表征系统理论（RST）多种功能的系统，旨在赋予机器灵活的表征转换能力，使其更接近人类思维。


<details>
  <summary>Details</summary>
Motivation: 人类能够灵活地使用和转换表征（如绘制图表、跨领域类比），研究者希望机器也能拥有这种能力，以提高其与人类的兼容性。

Method: 研究者基于之前开发的表征系统理论（RST），实现了名为Oruga的系统。Oruga包含对应RST概念的核心数据结构、用于与核心通信的语言，以及一个使用“结构转移”方法进行转换的引擎。

Result: 本文概述了Oruga的核心和语言，并简要展示了结构转移能够执行的转换类型示例。

Conclusion: Oruga作为RST的实现，展示了如何通过核心数据结构、专用语言和结构转移引擎，使机器具备灵活的表征转换能力。

Abstract: Humans use representations flexibly. We draw diagrams, change representations
and exploit creative analogies across different domains. We want to harness
this kind of power and endow machines with it to make them more compatible with
human use. Previously we developed Representational Systems Theory (RST) to
study the structure and transformations of representations. In this paper we
present Oruga (caterpillar in Spanish; a symbol of transformation), an
implementation of various aspects of RST. Oruga consists of a core of data
structures corresponding to concepts in RST, a language for communicating with
the core, and an engine for producing transformations using a method we call
structure transfer. In this paper we present an overview of the core and
language of Oruga, with a brief example of the kind of transformation that
structure transfer can execute.

</details>


### [29] [Intermediate Languages Matter: Formal Languages and LLMs affect Neurosymbolic Reasoning](https://arxiv.org/abs/2509.04083)
*Alexander Beiser,David Penz,Nysret Musliu*

Main category: cs.AI

TL;DR: 神经符号LLM推理的成功受形式语言选择的影响，这是一个先前被忽视的关键因素。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在许多任务上表现出色，但其形式推理能力仍有不足。神经符号LLM推理是一个有前景的方法，但其成功因素尚不明确。

Method: 本文提出了“中间语言挑战”，即选择合适的神经符号推理形式语言。通过在三个数据集和七个LLM上比较四种形式语言，来评估形式语言选择的影响。

Result: 研究表明，形式语言的选择会影响LLM的句法和语义推理能力，且这种影响在不同的LLM之间存在差异。

Conclusion: 形式语言的选择是神经符号LLM推理成功的一个关键且先前被忽视的因素，它显著影响推理能力，并且其效果因LLM而异。

Abstract: Large language models (LLMs) achieve astonishing results on a wide range of
tasks. However, their formal reasoning ability still lags behind. A promising
approach is Neurosymbolic LLM reasoning. It works by using LLMs as translators
from natural to formal languages and symbolic solvers for deriving correct
results. Still, the contributing factors to the success of Neurosymbolic LLM
reasoning remain unclear. This paper demonstrates that one previously
overlooked factor is the choice of the formal language. We introduce the
intermediate language challenge: selecting a suitable formal language for
neurosymbolic reasoning. By comparing four formal languages across three
datasets and seven LLMs, we show that the choice of formal language affects
both syntactic and semantic reasoning capabilities. We also discuss the varying
effects across different LLMs.

</details>


### [30] [Hybrid Reinforcement Learning and Search for Flight Trajectory Planning](https://arxiv.org/abs/2509.04100)
*Alberto Luise,Michele Lombardi,Florent Teichteil Koenigsbuch*

Main category: cs.AI

TL;DR: 本文结合强化学习（RL）和基于搜索的路径规划器，通过RL预计算近乎最优路径来约束搜索空间，从而显著加速航空公司航班路径优化，尤其适用于紧急情况下的快速路径重计算。


<details>
  <summary>Details</summary>
Motivation: 在航空公司航班遇到紧急情况时，快速重新计算航线至关重要，这促使研究人员寻求加速航线优化计算的方法。

Method: 该方法训练一个强化学习（RL）智能体，根据位置和大气数据预计算近乎最优的路径。在运行时，这些预计算的路径被用作约束，以限制底层路径规划求解器的搜索空间，从而在初始猜测的一定距离内找到解决方案。

Result: 实证结果表明，与单独使用传统求解器相比，燃油消耗几乎相同（通常偏差在1%以内），而计算速度提高了高达50%。尽管不保证全局最优性，但实际性能表现良好。

Conclusion: 结合强化学习和基于搜索的路径规划能够显著加速航空公司航班路径优化，同时保持与非约束求解器几乎相同的燃油效率，这对于紧急情况下的快速航线重计算具有重要意义。

Abstract: This paper explores the combination of Reinforcement Learning (RL) and
search-based path planners to speed up the optimization of flight paths for
airliners, where in case of emergency a fast route re-calculation can be
crucial. The fundamental idea is to train an RL Agent to pre-compute
near-optimal paths based on location and atmospheric data and use those at
runtime to constrain the underlying path planning solver and find a solution
within a certain distance from the initial guess. The approach effectively
reduces the size of the solver's search space, significantly speeding up route
optimization. Although global optimality is not guaranteed, empirical results
conducted with Airbus aircraft's performance models show that fuel consumption
remains nearly identical to that of an unconstrained solver, with deviations
typically within 1%. At the same time, computation speed can be improved by up
to 50% as compared to using a conventional solver alone.

</details>


### [31] [Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker](https://arxiv.org/abs/2509.04125)
*Tarik Zaciragic,Aske Plaat,K. Joost Batenburg*

Main category: cs.AI

TL;DR: 研究了DQN和CFR两种算法在Leduc Hold'em扑克中是否表现出诈唬行为及其方式。


<details>
  <summary>Details</summary>
Motivation: 诈唬是扑克中一项基本技能，但在计算机扑克研究中常被忽视，研究多关注胜率而非行为模式。

Method: 设计实验让DQN和CFR代理在简化的Leduc Hold'em扑克中对战，并记录其行动以分析诈唬行为。

Result: DQN和CFR都表现出诈唬行为，但方式不同。虽然诈唬频率不同，但成功率（对手弃牌）大致相同。这表明诈唬是游戏本身的重要组成部分，而非算法特性。

Conclusion: 诈唬是扑克游戏的一个基本要素，并非特定算法所独有。未来的研究应探索不同的诈唬风格以及在完整扑克游戏中的表现。

Abstract: In the game of poker, being unpredictable, or bluffing, is an essential
skill. When humans play poker, they bluff. However, most works on
computer-poker focus on performance metrics such as win rates, while bluffing
is overlooked. In this paper we study whether two popular algorithms, DQN
(based on reinforcement learning) and CFR (based on game theory), exhibit
bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed
an experiment where we let the DQN and CFR agent play against each other while
we log their actions. We find that both DQN and CFR exhibit bluffing behavior,
but they do so in different ways. Although both attempt to perform bluffs at
different rates, the percentage of successful bluffs (where the opponent folds)
is roughly the same. This suggests that bluffing is an essential aspect of the
game, not of the algorithm. Future work should look at different bluffing
styles and at the full game of poker. Code at
https://github.com/TarikZ03/Bluffing-by-DQN-and-CFR-in-Leduc-Hold-em-Poker-Codebase.

</details>


### [32] [The human biological advantage over AI](https://arxiv.org/abs/2509.04130)
*William Stewart*

Main category: cs.AI

TL;DR: 尽管AI可能在多方面超越人类，但本文认为人类的中央神经系统（CNS）赋予的情感体验和伦理理解是领导力的关键，而这是AI无法模拟或制造的，因此DNA而非硅基智能才是宇宙领导者的最佳基础。


<details>
  <summary>Details</summary>
Motivation: 随着AI的快速发展和通用人工智能（AGI）的潜在实现，引发了AI是否会最终超越人类，成为“数字物种”并主导宇宙的疑问。

Method: 本文通过提出人类与AI之间被忽视的区别不在于大脑，而在于中央神经系统（CNS）。它认为CNS赋予人类情感体验（如痛苦、喜悦、爱），从而能充分理解行为后果，并在此基础上发展可持续的伦理系统，这才是成为宇宙领导者的必要条件。该文强调CNS必须作为生物构造生长，无法被制造或模拟。

Result: AI系统可能在几乎所有方面都比人类更强大并改变社会。然而，情感理解（源于生物CNS）对于发展可持续的伦理系统至关重要，因此，人类（基于DNA）而非AI（基于硅）才是宇宙领导力的最佳基础。

Conclusion: 即使AI系统发展出意识，也无法在领导力方面超越人类。因为生物中央神经系统所带来的情感理解和伦理发展能力是真正领导力的不可替代基础，而这并非硅基智能所能拥有。

Abstract: Recent advances in AI raise the possibility that AI systems will one day be
able to do anything humans can do, only better. If artificial general
intelligence (AGI) is achieved, AI systems may be able to understand, reason,
problem solve, create, and evolve at a level and speed that humans will
increasingly be unable to match, or even understand. These possibilities raise
a natural question as to whether AI will eventually become superior to humans,
a successor "digital species", with a rightful claim to assume leadership of
the universe. However, a deeper consideration suggests the overlooked
differentiator between human beings and AI is not the brain, but the central
nervous system (CNS), providing us with an immersive integration with physical
reality. It is our CNS that enables us to experience emotion including pain,
joy, suffering, and love, and therefore to fully appreciate the consequences of
our actions on the world around us. And that emotional understanding of the
consequences of our actions is what is required to be able to develop
sustainable ethical systems, and so be fully qualified to be the leaders of the
universe. A CNS cannot be manufactured or simulated; it must be grown as a
biological construct. And so, even the development of consciousness will not be
sufficient to make AI systems superior to humans. AI systems may become more
capable than humans on almost every measure and transform our society. However,
the best foundation for leadership of our universe will always be DNA, not
silicon.

</details>


### [33] [Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs](https://arxiv.org/abs/2509.04159)
*Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das*

Main category: cs.AI

TL;DR: 本文提出了一种可扩展的领域特定语言（DSL），用于将食谱表示为有向动作图，以形式化复杂的烹饪流程，旨在实现自动化分析和执行。


<details>
  <summary>Details</summary>
Motivation: 烹饪过程固有的复杂性和模糊性使得其形式化成为一项挑战。

Method: 引入了一种可扩展的领域特定语言（DSL），将食谱表示为有向动作图，捕获过程、转移、环境、并发性和组合结构。

Result: 对一份完整的英式早餐食谱进行的初步手动评估证明了该DSL的表达能力，并显示其适用于未来的自动化食谱分析和执行。

Conclusion: 这项工作是构建以动作为中心的烹饪本体论的初步步骤，利用时间图实现机器对烹饪过程的结构化理解、精确解释和可扩展自动化。

Abstract: Formalizing cooking procedures remains a challenging task due to their
inherent complexity and ambiguity. We introduce an extensible domain-specific
language for representing recipes as directed action graphs, capturing
processes, transfers, environments, concurrency, and compositional structure.
Our approach enables precise, modular modeling of complex culinary workflows.
Initial manual evaluation on a full English breakfast recipe demonstrates the
DSL's expressiveness and suitability for future automated recipe analysis and
execution. This work represents initial steps towards an action-centric
ontology for cooking, using temporal graphs to enable structured machine
understanding, precise interpretation, and scalable automation of culinary
processes - both in home kitchens and professional culinary settings.

</details>


### [34] [Domain size asymptotics for Markov logic networks](https://arxiv.org/abs/2509.04192)
*Vera Koponen*

Main category: cs.AI

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: A Markov logic network (MLN) determines a probability distribution on the set
of structures, or ``possible worlds'', with an arbitrary finite domain. We
study the properties of such distributions as the domain size tends to
infinity. Three types of concrete examples of MLNs will be considered, and the
properties of random structures with domain sizes tending to infinity will be
studied: (1) Arbitrary quantifier-free MLNs over a language with only one
relation symbol which has arity 1. In this case we give a pretty complete
characterization of the possible limit behaviours of random structures. (2) An
MLN that favours graphs with fewer triangles (or more generally, fewer
k-cliques). As a corollary of the analysis a ``$\delta$-approximate 0-1 law''
for first-order logic is obtained. (3) An MLN that favours graphs with fewer
vertices with degree higher than a fixed (but arbitrary) number. The analysis
shows that depending on which ``soft constraints'' an MLN uses the limit
behaviour of random structures can be quite different, and the weights of the
soft constraints may, or may not, have influence on the limit behaviour. It
will also be demonstrated, using (1), that quantifier-free MLNs and lifted
Bayesian networks (in a broad sense) are asymptotically incomparable, roughly
meaning that there is a sequence of distributions on possible worlds with
increasing domain sizes that can be defined by one of the formalisms but not
even approximated by the other. In a rather general context it is also shown
that on large domains the distribution determined by an MLN concentrates almost
all its probability mass on a totally different part of the space of possible
worlds than the uniform distribution does.

</details>


### [35] [Evaluating Quality of Gaming Narratives Co-created with AI](https://arxiv.org/abs/2509.04239)
*Arturo Valdivia,Paolo Burelli*

Main category: cs.AI

TL;DR: 本文提出一种结构化方法，利用专家小组和Kano模型评估AI生成的游戏叙事质量，以指导开发者。


<details>
  <summary>Details</summary>
Motivation: 帮助游戏开发者在与生成式AI共同创作游戏叙事时，了解并优先考虑影响玩家满意度的质量方面。

Method: 采用德尔菲研究结构，召集叙事设计专家小组，综合文献和专家见解的故事质量维度，并将其映射到Kano模型框架，以理解其对玩家满意度的影响。

Result: 研究结果能够为游戏开发者提供信息，指导他们在与生成式AI共同创作游戏叙事时，如何优先考虑不同的质量方面。

Conclusion: 本研究提供了一种评估AI生成游戏叙事的有效方法，其结果可用于指导游戏开发者优化AI辅助叙事创作的质量优先级，从而提升玩家满意度。

Abstract: This paper proposes a structured methodology to evaluate AI-generated game
narratives, leveraging the Delphi study structure with a panel of narrative
design experts. Our approach synthesizes story quality dimensions from
literature and expert insights, mapping them into the Kano model framework to
understand their impact on player satisfaction. The results can inform game
developers on prioritizing quality aspects when co-creating game narratives
with generative AI.

</details>


### [36] [EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation](https://arxiv.org/abs/2509.04310)
*Yunbo Long,Liming Xu,Lukas Beckenbauer,Yuhan Liu,Alexandra Brintrup*

Main category: cs.AI

TL;DR: 本文提出EvoEmo，一个基于进化强化学习的框架，用于优化LLM代理在多轮谈判中的动态情感表达。实验证明EvoEmo显著优于基线策略，提高了谈判成功率、效率和买家节约。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）代理在多轮谈判中忽视了情感的功能性作用，仅生成被动、偏好驱动的情感反应，使其容易受到操纵和战略性利用。本研究旨在填补这一空白。

Method: EvoEmo框架采用进化强化学习来优化动态情感表达。它将情感状态转换建模为马尔可夫决策过程（MDP），并利用基于群体的遗传优化来演化高回报的情感策略。此外，本文提出了一个评估框架，包含两种基线策略（普通策略和固定情感策略）用于基准测试情感感知谈判。

Result: 广泛的实验和消融研究表明，EvoEmo始终优于两种基线策略，实现了更高的成功率、更高的效率和更多的买家节约。

Conclusion: 研究结果强调了自适应情感表达在使LLM代理在多轮谈判中更有效方面的重要性。

Abstract: Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models
(LLMs) has demonstrated that agents can engage in \textit{complex},
\textit{multi-turn} negotiations, opening new avenues for agentic AI. However,
existing LLM agents largely overlook the functional role of emotions in such
negotiations, instead generating passive, preference-driven emotional responses
that make them vulnerable to manipulation and strategic exploitation by
adversarial counterparts. To address this gap, we present EvoEmo, an
evolutionary reinforcement learning framework that optimizes dynamic emotional
expression in negotiations. EvoEmo models emotional state transitions as a
Markov Decision Process and employs population-based genetic optimization to
evolve high-reward emotion policies across diverse negotiation scenarios. We
further propose an evaluation framework with two baselines -- vanilla
strategies and fixed-emotion strategies -- for benchmarking emotion-aware
negotiation. Extensive experiments and ablation studies show that EvoEmo
consistently outperforms both baselines, achieving higher success rates, higher
efficiency, and increased buyer savings. This findings highlight the importance
of adaptive emotional expression in enabling more effective LLM agents for
multi-turn negotiation.

</details>


### [37] [Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes](https://arxiv.org/abs/2509.04317)
*Isidoro Tamassia,Wendelin Böhmer*

Main category: cs.AI

TL;DR: 本文探讨了在测试环境可能发生变化时，AlphaZero框架的部署问题，并提出简单修改即可显著提升其性能，即使在规划预算较低的情况下。


<details>
  <summary>Details</summary>
Motivation: AlphaZero框架通常假设其训练环境在测试时不会改变，这限制了其适用性。研究动机在于解决AlphaZero在潜在变化测试环境中的部署问题。

Method: 通过对标准AlphaZero框架进行简单的修改，以适应可能发生变化的测试环境。

Result: 即使在规划预算较低的情况下，结合这些简单修改也能显著提升AlphaZero代理的性能。

Conclusion: 对标准AlphaZero框架进行简单修改，可以显著提高其在潜在变化测试环境中的表现，从而扩展其适用范围。

Abstract: The AlphaZero framework provides a standard way of combining Monte Carlo
planning with prior knowledge provided by a previously trained policy-value
neural network. AlphaZero usually assumes that the environment on which the
neural network was trained will not change at test time, which constrains its
applicability. In this paper, we analyze the problem of deploying AlphaZero
agents in potentially changed test environments and demonstrate how the
combination of simple modifications to the standard framework can significantly
boost performance, even in settings with a low planning budget available. The
code is publicly available on GitHub.

</details>


### [38] [Psychologically Enhanced AI Agents](https://arxiv.org/abs/2509.04343)
*Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler*

Main category: cs.AI

TL;DR: 该研究引入了“MBTI-in-Thoughts”框架，通过提示工程基于心理学（如MBTI）对大型语言模型（LLM）代理进行人格条件反射，以控制其行为，从而提高性能、改善多智能体合作和推理质量，且无需微调。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于提升大型语言模型代理的有效性，并通过心理学原理赋予代理可控的行为模式，以实现行为偏向和在不同任务中的优化表现。

Method: 研究方法是“MBTI-in-Thoughts”框架，通过提示工程将基于MBTI的人格原型（如认知和情感轴）注入LLM代理。此外，该框架支持结构化多智能体通信协议，并引入了交互前的自我反思机制。为确保人格特质的持久性，集成了16Personalities测试进行自动化验证。该方法还被证明可推广到其他心理学框架，如大五人格、HEXACO和九型人格。

Result: 研究结果表明，人格启动产生了连贯且可解释的行为偏向：情感表达型代理在叙事生成方面表现出色，而分析型代理在博弈论设置中采用更稳定的策略。框架还揭示，交互前的自我反思能提高合作和推理质量。此外，该方法可无缝推广到其他心理学框架。

Conclusion: 该研究通过连接心理学理论和LLM行为设计，为在不进行任何微调的情况下创建心理增强型AI代理奠定了基础。

Abstract: We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of
Large Language Model (LLM) agents through psychologically grounded personality
conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method
primes agents with distinct personality archetypes via prompt engineering,
enabling control over behavior along two foundational axes of human psychology,
cognition and affect. We show that such personality priming yields consistent,
interpretable behavioral biases across diverse tasks: emotionally expressive
agents excel in narrative generation, while analytically primed agents adopt
more stable strategies in game-theoretic settings. Our framework supports
experimenting with structured multi-agent communication protocols and reveals
that self-reflection prior to interaction improves cooperation and reasoning
quality. To ensure trait persistence, we integrate the official 16Personalities
test for automated verification. While our focus is on MBTI, we show that our
approach generalizes seamlessly to other psychological frameworks such as Big
Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior
design, we establish a foundation for psychologically enhanced AI agents
without any fine-tuning.

</details>


### [39] [ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory](https://arxiv.org/abs/2509.04439)
*Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin*

Main category: cs.AI

TL;DR: 该研究提出了一种“概念级记忆”方法，通过将大型语言模型（LLM）的推理过程抽象为可重用的自然语言概念，从而实现测试时期的持续学习和性能提升，特别是在ARC-AGI基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: LLM在推理过程中产生的洞察和模式在上下文窗口重置后即被丢弃，限制了这些发现的重用性和可扩展性。虽然外部记忆已被证明对推理密集型任务有益，但现有方法多为实例级记忆（如查询/响应对），缺乏更广泛的可重用性和可扩展性。

Method: 该方法通过从LLM的解决方案轨迹中提取“概念级记忆”：可重用、模块化的抽象，并以自然语言形式存储。在处理新查询时，选择性地检索相关概念并将其集成到提示中，从而在不更新模型权重的情况下实现测试时期的持续学习。设计中包含了新的策略，用于从推理过程中抽象出要点以及检索新查询的记忆条目。

Result: 在具有挑战性的ARC-AGI基准测试中，该方法比无记忆基线取得了7.5%的相对增益，并且性能随推理计算的增加而持续提升。研究发现，抽象概念是记忆设计中最稳定有效的方式，在所有测试的推理计算规模下都优于基线。此外，动态更新记忆在测试时期表现优于相同但固定的记忆设置，支持了通过解决更多问题和抽象更多模式到记忆中可以实现进一步解决方案的自我改进假设。

Conclusion: 通过引入概念级记忆，LLM能够将推理过程中的发现持久化为可重用的抽象概念，从而实现测试时期的持续学习和自我改进。这种方法在推理计算扩展时仍能保持性能提升，并且抽象概念被证明是最有效的记忆设计，为LLM的泛化和长期推理能力提供了新的途径。

Abstract: While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, and
recent work has shown clear benefits for reasoning-intensive tasks. We see an
opportunity to make such memories more broadly reusable and scalable by moving
beyond instance-based memory entries (e.g. exact query/response pairs, or
summaries tightly coupled with the original problem context) toward
concept-level memory: reusable, modular abstractions distilled from solution
traces and stored in natural language. For future queries, relevant concepts
are selectively retrieved and integrated into the prompt, enabling test-time
continual learning without weight updates. Our design introduces new strategies
for abstracting takeaways from rollouts and retrieving entries for new queries,
promoting reuse and allowing memory to expand with additional experiences. On
the challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over
a strong no-memory baseline with performance continuing to scale with inference
compute. We find abstract concepts to be the most consistent memory design,
outscoring the baseline at all tested inference compute scales. Moreover, we
confirm that dynamically updating memory during test-time outperforms an
otherwise identical fixed memory setting with additional attempts, supporting
the hypothesis that solving more problems and abstracting more patterns to
memory enables further solutions in a form of self-improvement. Code available
at https://github.com/matt-seb-ho/arc_memo.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [40] [Towards Efficient General Feature Prediction in Masked Skeleton Modeling](https://arxiv.org/abs/2509.03609)
*Shengkai Sun,Zefan Zhang,Jianfeng Dong,Zhiyong Cheng,Xiaojun Chang,Meng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为通用特征预测（GFP）的新框架，用于高效的掩码骨架建模，通过预测高层特征而非低层坐标，显著提升了骨架动作识别的计算效率和表示质量。


<details>
  <summary>Details</summary>
Motivation: 现有的掩码自编码器（MAE）范式在骨架动作识别中，通常将重建目标限制为原始关节坐标或其简单变体，导致计算冗余和语义表示能力有限。

Method: 本文提出通用特征预测（GFP）框架，用从局部运动模式到全局语义表示的高层特征预测取代传统的低层重建。它引入了一个协同学习框架，其中轻量级目标生成网络动态产生跨时空层次的多样化监督信号，避免依赖预计算的离线特征。此外，该框架还结合了约束优化以确保特征多样性并防止模型崩溃。

Result: GFP方法在NTU RGB+D 60、NTU RGB+D 120和PKU-MMD数据集上进行了验证，展示了其优势：计算效率显著提升（训练速度比标准掩码骨架建模方法快6.2倍），并获得了卓越的表示质量，在各种下游任务中实现了最先进的性能。

Conclusion: 通过预测高层语义特征而非低层关节坐标，GFP框架有效解决了现有MAE在骨架动作识别中的局限性，实现了计算效率和表示质量的双重提升，达到了最先进的性能。

Abstract: Recent advances in the masked autoencoder (MAE) paradigm have significantly
propelled self-supervised skeleton-based action recognition. However, most
existing approaches limit reconstruction targets to raw joint coordinates or
their simple variants, resulting in computational redundancy and limited
semantic representation. To address this, we propose a novel General Feature
Prediction framework (GFP) for efficient mask skeleton modeling. Our key
innovation is replacing conventional low-level reconstruction with high-level
feature prediction that spans from local motion patterns to global semantic
representations. Specifically, we introduce a collaborative learning framework
where a lightweight target generation network dynamically produces diversified
supervision signals across spatial-temporal hierarchies, avoiding reliance on
pre-computed offline features. The framework incorporates constrained
optimization to ensure feature diversity while preventing model collapse.
Experiments on NTU RGB+D 60, NTU RGB+D 120 and PKU-MMD demonstrate the benefits
of our approach: Computational efficiency (with 6.2$\times$ faster training
than standard masked skeleton modeling methods) and superior representation
quality, achieving state-of-the-art performance in various downstream tasks.

</details>


### [41] [Teacher-Student Model for Detecting and Classifying Mitosis in the MIDOG 2025 Challenge](https://arxiv.org/abs/2509.03614)
*Seungho Choe,Xiaoli Qin,Abubakr Shafique,Amanda Dy,Dimitri Androutsos,Susan Done,April Khademi*

Main category: cs.CV

TL;DR: 本研究提出了一种结合像素级分割和教师-学生模型的统一AI框架，用于自动检测有丝分裂并分类异常有丝分裂，有效解决了病理学中的域偏移和数据不平衡问题，并取得了良好的性能。


<details>
  <summary>Details</summary>
Motivation: 病理学家计数有丝分裂耗时且存在观察者间差异。现有AI工具易受域偏移（训练和测试集差异，如形态、物种、染色协议）影响，且有丝分裂数量远少于正常细胞核，导致数据严重不平衡。

Method: 将有丝分裂检测公式化为像素级分割任务，提出一个教师-学生模型。该模型基于UNet分割骨干，并集成了域泛化模块（对比表示学习和域对抗训练）。教师-学生策略用于生成有丝分裂、难负样本和正常细胞核的像素级伪掩码，以增强特征辨别力并提高对抗域偏移的鲁棒性。分类任务引入了一个多尺度CNN分类器，利用分割模型的特征图进行多任务学习。

Result: 在初步测试集上，算法在有丝分裂检测（Track 1）中实现了0.7660的F1分数，在异常有丝分裂分类（Track 2）中实现了0.8414的平衡准确率。

Conclusion: 该研究证明了将基于分割的检测和分类整合到一个统一框架中，能有效实现鲁棒的有丝分裂分析。

Abstract: Counting mitotic figures is time-intensive for pathologists and leads to
inter-observer variability. Artificial intelligence (AI) promises a solution by
automatically detecting mitotic figures while maintaining decision consistency.
However, AI tools are susceptible to domain shift, where a significant drop in
performance can occur due to differences in the training and testing sets,
including morphological diversity between organs, species, and variations in
staining protocols. Furthermore, the number of mitoses is much less than the
count of normal nuclei, which introduces severely imbalanced data for the
detection task. In this work, we formulate mitosis detection as a pixel-level
segmentation and propose a teacher-student model that simultaneously addresses
mitosis detection (Track 1) and atypical mitosis classification (Track 2). Our
method is based on a UNet segmentation backbone that integrates domain
generalization modules, namely contrastive representation learning and
domain-adversarial training. A teacher-student strategy is employed to generate
pixel-level pseudo-masks not only for annotated mitoses and hard negatives but
also for normal nuclei, thereby enhancing feature discrimination and improving
robustness against domain shift. For the classification task, we introduce a
multi-scale CNN classifier that leverages feature maps from the segmentation
model within a multi-task learning paradigm. On the preliminary test set, the
algorithm achieved an F1 score of 0.7660 in Track 1 and balanced accuracy of
0.8414 in Track 2, demonstrating the effectiveness of integrating
segmentation-based detection and classification into a unified framework for
robust mitosis analysis.

</details>


### [42] [Multi Attribute Bias Mitigation via Representation Learning](https://arxiv.org/abs/2509.03616)
*Rajeev Ranjan Dwivedi,Ankur Kumar,Vinod K Kurmi*

Main category: cs.CV

TL;DR: 该论文提出了广义多偏置缓解（GMBM）框架，一个两阶段的端到端解决方案，用于解决图像中多重重叠偏置问题。它通过自适应偏置集成学习和梯度抑制微调来减轻偏置，并引入了Scaled Bias Amplification（SBA）作为新的偏置度量指标，显著提高了视觉识别模型的公平性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界的图像经常表现出多种重叠的偏置（如纹理、水印、性别妆容、场景物体配对等）。这些偏置共同损害了现代视觉模型的性能，削弱了它们的鲁棒性和公平性。单独处理这些偏置不足以解决问题，因为缓解一个偏置可能会允许或加剧其他偏置。

Method: 该研究提出了广义多偏置缓解（GMBM），一个精简的两阶段框架，仅在训练时需要组标签，并在测试时最小化偏置。第一阶段是自适应偏置集成学习（ABIL），通过为每个属性训练编码器并将其与主干网络集成，使分类器明确识别这些偏置的影响。第二阶段是梯度抑制微调，从主干网络的梯度中修剪掉这些偏置方向，留下一个紧凑的网络来忽略它刚刚学会识别的所有捷径。此外，为了解决现有偏置度量在子组不平衡和训练-测试分布偏移下的失效问题，该研究引入了Scaled Bias Amplification（SBA），一种在测试时解耦模型引起的偏置放大与分布差异的度量。

Result: GMBM在FB CMNIST、CelebA和COCO数据集上进行了验证，结果显示它提高了最差组的准确性，将多属性偏置放大减半，并在偏置复杂性和分布偏移加剧的情况下，在SBA上创造了新低。这使得GMBM成为首个用于视觉识别的实用、端到端的多偏置解决方案。

Conclusion: GMBM是一个有效且实用的端到端解决方案，能够应对视觉识别中多重重叠的偏置问题，显著提升模型的鲁棒性和公平性。同时，引入的SBA提供了一种在复杂条件下更准确的偏置评估方法。

Abstract: Real world images frequently exhibit multiple overlapping biases, including
textures, watermarks, gendered makeup, scene object pairings, etc. These biases
collectively impair the performance of modern vision models, undermining both
their robustness and fairness. Addressing these biases individually proves
inadequate, as mitigating one bias often permits or intensifies others. We
tackle this multi bias problem with Generalized Multi Bias Mitigation (GMBM), a
lean two stage framework that needs group labels only while training and
minimizes bias at test time. First, Adaptive Bias Integrated Learning (ABIL)
deliberately identifies the influence of known shortcuts by training encoders
for each attribute and integrating them with the main backbone, compelling the
classifier to explicitly recognize these biases. Then Gradient Suppression Fine
Tuning prunes those very bias directions from the backbone's gradients, leaving
a single compact network that ignores all the shortcuts it just learned to
recognize. Moreover we find that existing bias metrics break under subgroup
imbalance and train test distribution shifts, so we introduce Scaled Bias
Amplification (SBA): a test time measure that disentangles model induced bias
amplification from distributional differences. We validate GMBM on FB CMNIST,
CelebA, and COCO, where we boost worst group accuracy, halve multi attribute
bias amplification, and set a new low in SBA even as bias complexity and
distribution shifts intensify, making GMBM the first practical, end to end
multibias solution for visual recognition. Project page:
http://visdomlab.github.io/GMBM/

</details>


### [43] [Lightweight image segmentation for echocardiography](https://arxiv.org/abs/2509.03631)
*Anders Kjelsrud,Lasse Løvstakken,Erik Smistad,Håvard Dalen,Gilles Van De Vyver*

Main category: cs.CV

TL;DR: 本研究开发了一种轻量级U-Net模型，在左心室分割任务上实现了与nnU-Net统计学上等效的性能，但模型更小、速度更快，适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: nnU-Net在超声心动图左心室分割中表现良好，但其模型庞大且速度慢，限制了实时应用。准确的左心室分割对于自动提取临床测量值（如容积和射血分数）至关重要。

Method: 通过消融研究，逐步评估了数据增强方案、架构修改、损失函数和后处理技术在心脏分割中的有效组件。基于这些发现，开发了一种轻量级U-Net模型。

Result: 研究发现简单仿射增强和深度监督是性能的关键驱动因素，而复杂增强和大型模型容量的回报递减。开发的轻量级U-Net（2M参数）在CAMUS数据集上与nnU-Net（33M参数）达到了统计学上等效的性能（LV/MYO/LA的Dice分数分别为0.93/0.85/0.89 vs 0.93/0.86/0.89，$p>0.05$），同时模型小16倍，速度快4倍（每帧1.35ms vs 5.40ms）。跨数据集评估也证实了其可比的泛化能力。

Conclusion: 成功开发了一种轻量级U-Net，在保持与nnU-Net相当的性能的同时，显著减小了模型大小并提高了处理速度，使其更适用于实时应用。

Abstract: Accurate segmentation of the left ventricle in echocardiography can enable
fully automatic extraction of clinical measurements such as volumes and
ejection fraction. While models configured by nnU-Net perform well, they are
large and slow, thus limiting real-time use. We identified the most effective
components of nnU-Net for cardiac segmentation through an ablation study,
incrementally evaluating data augmentation schemes, architectural
modifications, loss functions, and post-processing techniques. Our analysis
revealed that simple affine augmentations and deep supervision drive
performance, while complex augmentations and large model capacity offer
diminishing returns. Based on these insights, we developed a lightweight U-Net
(2M vs 33M parameters) that achieves statistically equivalent performance to
nnU-Net on CAMUS (N=500) with Dice scores of 0.93/0.85/0.89 vs 0.93/0.86/0.89
for LV/MYO/LA ($p>0.05$), while being 16 times smaller and 4 times faster
(1.35ms vs 5.40ms per frame) than the default nnU-Net configuration.
Cross-dataset evaluation on an internal dataset (N=311) confirms comparable
generalization.

</details>


### [44] [treeX: Unsupervised Tree Instance Segmentation in Dense Forest Point Clouds](https://arxiv.org/abs/2509.03633)
*Josafat-Mattias Burmeister,Andreas Tockner,Stefan Reder,Markus Engel,Rico Richter,Jan-Peter Mund,Jürgen Döllner*

Main category: cs.CV

TL;DR: 本文提出了一种修订版的无监督treeX算法，用于从地面和无人机激光扫描数据中高效地进行单木分割。该算法在准确性和运行时间上均优于原版，并可与深度学习方法媲美，且资源消耗更少，也可用于深度学习模型的数据标注。


<details>
  <summary>Details</summary>
Motivation: 近距离激光扫描能提供详细的森林三维数据，但需要高效软件处理点云并提取单木。现有深度学习方法虽有效，但需要大量标注数据和计算资源。因此，研究的动机是开发一种资源高效的替代方案。

Method: 研究采用并修订了无监督的treeX算法，该算法结合了基于聚类的树干检测和区域增长的树冠描绘。为适应不同数据源，提供了针对地面激光扫描（TLS和PLS）和无人机激光扫描（ULS）的两种参数预设。该方法在六个公开数据集上进行了评估，并与六种开源方法（包括原版treeX和深度学习方法）进行了比较。

Result: 与原版treeX算法相比，修订版减少了运行时间并提高了准确性，地面数据实例检测的F1分数提高了+0.11至+0.49。对于ULS数据，新预设实现了0.58的F1分数，而原版算法未能分割出任何正确实例。对于TLS和PLS数据，该算法的准确性与包括深度学习在内的最新开源方法相似。

Conclusion: 该修订版算法是一种资源高效的替代方案，适用于数据特性（足够的树干可见度和点密度）符合方法设计的场景。此外，它还可用于深度学习模型的半自动标签生成。为促进广泛应用，已在pointtree包中提供了开源Python实现。

Abstract: Close-range laser scanning provides detailed 3D captures of forest stands but
requires efficient software for processing 3D point cloud data and extracting
individual trees. Although recent studies have introduced deep learning methods
for tree instance segmentation, these approaches require large annotated
datasets and substantial computational resources. As a resource-efficient
alternative, we present a revised version of the treeX algorithm, an
unsupervised method that combines clustering-based stem detection with region
growing for crown delineation. While the original treeX algorithm was developed
for personal laser scanning (PLS) data, we provide two parameter presets, one
for ground-based laser scanning (stationary terrestrial - TLS and PLS), and one
for UAV-borne laser scanning (ULS). We evaluated the method on six public
datasets (FOR-instance, ForestSemantic, LAUTx, NIBIO MLS, TreeLearn, Wytham
Woods) and compared it to six open-source methods (original treeX, treeiso,
RayCloudTools, ForAINet, SegmentAnyTree, TreeLearn). Compared to the original
treeX algorithm, our revision reduces runtime and improves accuracy, with
instance detection F$_1$-score gains of +0.11 to +0.49 for ground-based data.
For ULS data, our preset achieves an F$_1$-score of 0.58, whereas the original
algorithm fails to segment any correct instances. For TLS and PLS data, our
algorithm achieves accuracy similar to recent open-source methods, including
deep learning. Given its algorithmic design, we see two main applications for
our method: (1) as a resource-efficient alternative to deep learning approaches
in scenarios where the data characteristics align with the method design
(sufficient stem visibility and point density), and (2) for the semi-automatic
generation of labels for deep learning models. To enable broader adoption, we
provide an open-source Python implementation in the pointtree package.

</details>


### [45] [Reg3D: Reconstructive Geometry Instruction Tuning for 3D Scene Understanding](https://arxiv.org/abs/2509.03635)
*Hongpei Zheng,Lintao Xiang,Qijun Yang,Qian Lin,Hujun Yin*

Main category: cs.CV

TL;DR: Reg3D是一个新颖的框架，通过在训练过程中直接整合几何感知监督，解决了大型多模态模型在3D场景理解中缺乏几何约束的问题，显著提升了空间感知多模态模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型在2D视觉理解方面进展显著，但在3D场景理解方面仍面临挑战。主要问题在于现有方法大多依赖纯文本监督，无法提供学习鲁棒3D空间表示所需的几何约束。

Method: 本文提出了Reg3D，一个重建几何指令微调框架。其核心思想是3D理解需要重建而非仅仅描述几何结构。Reg3D采用双重监督范式，将3D几何信息作为输入和显式学习目标。具体而言，它在一个双编码器架构中设计了互补的对象级和帧级重建任务，以强制执行几何一致性，从而培养空间推理能力。

Result: 在ScanQA、Scan2Cap、ScanRefer和SQA3D等数据集上的大量实验表明，Reg3D带来了显著的性能提升，为空间感知多模态模型建立了一种新的训练范式。

Conclusion: Reg3D通过引入几何感知监督和重建任务，有效解决了3D场景理解中几何约束不足的问题，显著提升了多模态模型对3D空间的理解能力，并开创了新的训练范式。

Abstract: The rapid development of Large Multimodal Models (LMMs) has led to remarkable
progress in 2D visual understanding; however, extending these capabilities to
3D scene understanding remains a significant challenge. Existing approaches
predominantly rely on text-only supervision, which fails to provide the
geometric constraints required for learning robust 3D spatial representations.
In this paper, we introduce Reg3D, a novel Reconstructive Geometry Instruction
Tuning framework that addresses this limitation by incorporating geometry-aware
supervision directly into the training process. Our key insight is that
effective 3D understanding necessitates reconstructing underlying geometric
structures rather than merely describing them. Unlike existing methods that
inject 3D information solely at the input level, Reg3D adopts a
dual-supervision paradigm that leverages 3D geometric information both as input
and as explicit learning targets. Specifically, we design complementary
object-level and frame-level reconstruction tasks within a dual-encoder
architecture, enforcing geometric consistency to encourage the development of
spatial reasoning capabilities. Extensive experiments on ScanQA, Scan2Cap,
ScanRefer, and SQA3D demonstrate that Reg3D delivers substantial performance
improvements, establishing a new training paradigm for spatially aware
multimodal models.

</details>


### [46] [QuantV2X: A Fully Quantized Multi-Agent System for Cooperative Perception](https://arxiv.org/abs/2509.03704)
*Seth Z. Zhao,Huizhi Zhang,Zhaowei Li,Juntong Peng,Anthony Chui,Zewei Zhou,Zonglin Meng,Hao Xiang,Zhiyu Huang,Fujia Wang,Ran Tian,Chenfeng Xu,Bolei Zhou,Jiaqi Ma*

Main category: cs.CV

TL;DR: 本文提出了QuantV2X，这是首个全量化多智能体系统，专为高效、可扩展的多模态、多智能体V2X协作感知设计，通过统一的端到端量化策略显著降低了计算和传输成本，同时保持了与全精度系统相当的感知准确性，并大幅提升了部署效率。


<details>
  <summary>Details</summary>
Motivation: V2X协作感知在增强车辆感知方面潜力巨大，但现有研究主要关注准确性，忽视了效率、延迟和实际部署性等系统级关键因素。大多数现有系统依赖全精度模型，导致高昂的计算和传输成本，使其在资源受限环境中难以实时运行。

Method: 本文引入了QuantV2X，这是第一个完全量化的多智能体系统，专为高效和可扩展的V2X协作感知部署而设计。它在神经网络模型和传输消息表示中引入了统一的端到端量化策略，同时减少了计算负载和传输带宽。

Result: QuantV2X在低比特约束下仍能达到与全精度系统相当的准确性。在面向部署的指标评估中，QuantV2X将系统级延迟降低了3.2倍，并在mAP30上比全精度基线提高了9.5。此外，QuantV2X扩展性更强，允许在严格的内存预算内适应更大、功能更强的模型。

Conclusion: 研究结果强调了QuantV2X这种完全量化的多智能体中间融合系统在实际部署中的可行性。

Abstract: Cooperative perception through Vehicle-to-Everything (V2X) communication
offers significant potential for enhancing vehicle perception by mitigating
occlusions and expanding the field of view. However, past research has
predominantly focused on improving accuracy metrics without addressing the
crucial system-level considerations of efficiency, latency, and real-world
deployability. Noticeably, most existing systems rely on full-precision models,
which incur high computational and transmission costs, making them impractical
for real-time operation in resource-constrained environments. In this paper, we
introduce \textbf{QuantV2X}, the first fully quantized multi-agent system
designed specifically for efficient and scalable deployment of multi-modal,
multi-agent V2X cooperative perception. QuantV2X introduces a unified
end-to-end quantization strategy across both neural network models and
transmitted message representations that simultaneously reduces computational
load and transmission bandwidth. Remarkably, despite operating under low-bit
constraints, QuantV2X achieves accuracy comparable to full-precision systems.
More importantly, when evaluated under deployment-oriented metrics, QuantV2X
reduces system-level latency by 3.2$\times$ and achieves a +9.5 improvement in
mAP30 over full-precision baselines. Furthermore, QuantV2X scales more
effectively, enabling larger and more capable models to fit within strict
memory budgets. These results highlight the viability of a fully quantized
multi-agent intermediate fusion system for real-world deployment. The system
will be publicly released to promote research in this field:
https://github.com/ucla-mobility/QuantV2X.

</details>


### [47] [Transfer Learning-Based CNN Models for Plant Species Identification Using Leaf Venation Patterns](https://arxiv.org/abs/2509.03729)
*Bandita Bharadwaj,Ankur Mishra,Saurav Bharadwaj*

Main category: cs.CV

TL;DR: 本研究评估了ResNet50、MobileNetV2和EfficientNetB0三种深度学习架构在基于叶脉模式的植物物种自动分类中的性能，发现EfficientNetB0表现最佳，测试准确率达到94.67%。


<details>
  <summary>Details</summary>
Motivation: 叶脉模式是具有高度分类学相关性的关键形态特征。研究旨在利用深度学习开发可扩展且准确的自动化工具，进行基于叶脉特征的植物分类。

Method: 研究评估了ResNet50、MobileNetV2和EfficientNetB0三种深度学习模型。使用包含15种植物物种（每种75张图像，共1,125张图像）的瑞典叶片数据集，以叶脉模式作为分类特征。模型性能通过训练和测试阶段的标准性能指标（如准确率、F1分数、精确率、召回率）进行评估。

Result: ResNet50训练准确率94.11%，测试准确率88.45%，F1分数87.82%，存在过拟合。MobileNetV2表现出更好的泛化能力，测试准确率93.34%，F1分数93.23%，适用于轻量级实时应用。EfficientNetB0表现最优，测试准确率94.67%，精确率、召回率和F1分数均超过94.6%。

Conclusion: 研究结果强调了深度学习，特别是EfficientNetB0，在利用叶脉特征开发可扩展且准确的植物物种自动分类工具方面的巨大潜力。

Abstract: This study evaluates the efficacy of three deep learning architectures:
ResNet50, MobileNetV2, and EfficientNetB0 for automated plant species
classification based on leaf venation patterns, a critical morphological
feature with high taxonomic relevance. Using the Swedish Leaf Dataset
comprising images from 15 distinct species (75 images per species, totalling
1,125 images), the models were demonstrated using standard performance metrics
during training and testing phases. ResNet50 achieved a training accuracy of
94.11% but exhibited overfitting, reflected by a reduced testing accuracy of
88.45% and an F1 score of 87.82%. MobileNetV2 demonstrated better
generalization capabilities, attaining a testing accuracy of 93.34% and an F1
score of 93.23%, indicating its suitability for lightweight, real-time
applications. EfficientNetB0 outperformed both models, achieving a testing
accuracy of 94.67% with precision, recall, and F1 scores exceeding 94.6%,
highlighting its robustness in venation-based classification. The findings
underscore the potential of deep learning, particularly EfficientNetB0, in
developing scalable and accurate tools for automated plant taxonomy using
venation traits.

</details>


### [48] [LayoutGKN: Graph Similarity Learning of Floor Plans](https://arxiv.org/abs/2509.03737)
*Casper van Engelenburg,Jan van Gemert,Seyran Khademi*

Main category: cs.CV

TL;DR: LayoutGKN是一种更高效的楼层平面图图比较方法，通过延迟跨图节点交互和使用可微分图核，显著提高了速度，同时保持或提升了相似性计算性能。


<details>
  <summary>Details</summary>
Motivation: 楼层平面图的图比较对于搜索、聚类和数据可视化等应用至关重要。然而，现有的图匹配网络方法依赖于耗时的跨图节点级交互，导致推理速度慢。

Method: 本文提出了LayoutGKN，一种更高效的方法，它将跨图节点级交互推迟到联合嵌入架构的末端。具体而言，它在最终学习到的节点级嵌入上使用可微分图核作为距离函数。

Result: LayoutGKN在计算相似性方面与图匹配网络相当或更好，同时显著提高了速度。

Conclusion: LayoutGKN提供了一种更高效且有效的楼层平面图图比较方法，解决了现有图匹配网络速度慢的问题。

Abstract: Floor plans depict building layouts and are often represented as graphs to
capture the underlying spatial relationships. Comparison of these graphs is
critical for applications like search, clustering, and data visualization. The
most successful methods to compare graphs \ie, graph matching networks, rely on
costly intermediate cross-graph node-level interactions, therefore being slow
in inference time. We introduce \textbf{LayoutGKN}, a more efficient approach
that postpones the cross-graph node-level interactions to the end of the joint
embedding architecture. We do so by using a differentiable graph kernel as a
distance function on the final learned node-level embeddings. We show that
LayoutGKN computes similarity comparably or better than graph matching networks
while significantly increasing the speed.
\href{https://github.com/caspervanengelenburg/LayoutGKN}{Code and data} are
open.

</details>


### [49] [Singular Value Few-shot Adaptation of Vision-Language Models](https://arxiv.org/abs/2509.03740)
*Taha Koleilat,Hassan Rivaz,Yiming Xiao*

Main category: cs.CV

TL;DR: CLIP-SVD是一种新颖的多模态、参数高效的CLIP微调技术，通过调整奇异值实现领域自适应，无需额外模块，在少样本设置下表现出色并保持泛化能力。


<details>
  <summary>Details</summary>
Motivation: CLIP等视觉-语言模型（VLM）在适应新的细粒度领域时面临挑战，现有方法依赖提示工程、全模型微调成本高昂，或通过增加组件限制适应质量、破坏预训练知识。

Method: 本文提出了CLIP-SVD，一种多模态、参数高效的自适应技术，它利用奇异值分解（SVD）来修改CLIP的内部参数空间，而无需注入额外模块。具体而言，仅微调CLIP参数矩阵的奇异值以重新缩放基向量，从而实现领域自适应并保留预训练模型。

Result: CLIP-SVD仅使用模型总参数的0.04%，就实现了增强的自适应性能，并更好地保留了其泛化能力。在11个自然数据集和10个生物医学数据集上取得了最先进的分类结果，在少样本设置下，其准确性和泛化能力均优于现有方法。此外，还利用基于自然语言的方法分析了CLIP自适应的有效性和动态性，以提高可解释性。

Conclusion: CLIP-SVD通过创新的SVD方法，为CLIP等VLM在细粒度领域的自适应提供了一种高效、高性能的解决方案，显著减少了微调参数量，同时提高了模型准确性和泛化能力。

Abstract: Vision-language models (VLMs) like CLIP have shown impressive zero-shot and
few-shot learning capabilities across diverse applications. However, adapting
these models to new fine-grained domains remains difficult due to reliance on
prompt engineering and the high cost of full model fine-tuning. Existing
adaptation approaches rely on augmented components, such as prompt tokens and
adapter modules, which could limit adaptation quality, destabilize the model,
and compromise the rich knowledge learned during pretraining. In this work, we
present \textbf{CLIP-SVD}, a novel \textit{multi-modal} and
\textit{parameter-efficient} adaptation technique that leverages Singular Value
Decomposition (SVD) to modify the internal parameter space of CLIP without
injecting additional modules. Specifically, we fine-tune only the singular
values of the CLIP parameter matrices to rescale the basis vectors for domain
adaptation while retaining the pretrained model. This design enables enhanced
adaptation performance using only \textbf{0.04\%} of the model's total
parameters and better preservation of its generalization ability. CLIP-SVD
achieves state-of-the-art classification results on 11 natural and 10
biomedical datasets, outperforming previous methods in both accuracy and
generalization under few-shot settings. Additionally, we leverage a natural
language-based approach to analyze the effectiveness and dynamics of the CLIP
adaptation to allow interpretability of CLIP-SVD. The code is publicly
available at https://github.com/HealthX-Lab/CLIP-SVD.

</details>


### [50] [STA-Net: A Decoupled Shape and Texture Attention Network for Lightweight Plant Disease Classification](https://arxiv.org/abs/2509.03754)
*Zongsen Qiu*

Main category: cs.CV

TL;DR: 本文提出了一种名为STA-Net的轻量级模型，通过结合无训练神经架构搜索和形状-纹理注意力模块（STAM），显著提升了边缘设备上植物病害诊断的精度，特别是在捕捉病变细微特征方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 全球粮食安全需求日益增长，精准农业和基于深度学习的植物病害诊断至关重要。然而，在边缘设备上部署高精度模型面临挑战。大多数轻量级网络使用的通用注意力机制难以有效捕捉不规则病变形状和复杂纹理等细微病理特征。

Method: 本文提出了双重解决方案：1) 使用无训练神经架构搜索方法（DeepMAD）构建高效的边缘设备网络骨干；2) 引入形状-纹理注意力模块（STAM）。STAM将注意力分为两个分支：一个利用可变形卷积（DCNv4）感知形状，另一个利用Gabor滤波器组感知纹理。

Result: 在公共CCMT植物病害数据集上，STA-Net模型（401K参数，51.1M FLOPs）达到了89.00%的准确率和88.96%的F1分数。消融研究证实STAM相比基线和标准注意力模型显著提升了性能。

Conclusion: 通过解耦注意力（如STAM）集成领域知识，为边缘部署的精准农业AI提供了一条有前景的路径。

Abstract: Responding to rising global food security needs, precision agriculture and
deep learning-based plant disease diagnosis have become crucial. Yet, deploying
high-precision models on edge devices is challenging. Most lightweight networks
use attention mechanisms designed for generic object recognition, which poorly
capture subtle pathological features like irregular lesion shapes and complex
textures. To overcome this, we propose a twofold solution: first, using a
training-free neural architecture search method (DeepMAD) to create an
efficient network backbone for edge devices; second, introducing the
Shape-Texture Attention Module (STAM). STAM splits attention into two branches
-- one using deformable convolutions (DCNv4) for shape awareness and the other
using a Gabor filter bank for texture awareness. On the public CCMT plant
disease dataset, our STA-Net model (with 401K parameters and 51.1M FLOPs)
reached 89.00% accuracy and an F1 score of 88.96%. Ablation studies confirm
STAM significantly improves performance over baseline and standard attention
models. Integrating domain knowledge via decoupled attention thus presents a
promising path for edge-deployed precision agriculture AI. The source code is
available at https://github.com/RzMY/STA-Net.

</details>


### [51] [SLENet: A Guidance-Enhanced Network for Underwater Camouflaged Object Detection](https://arxiv.org/abs/2509.03786)
*Xinxin Wang,Han Sun,Ningzhong Liu,Huiyu Zhou,Yinan Yao*

Main category: cs.CV

TL;DR: 本文提出了水下伪装目标检测（UCOD）任务，并发布了首个UCOD基准数据集DeepCamo。为解决水下环境挑战，提出了一种新颖的UCOD框架SLENet，通过特征增强和定位引导显著提升了检测精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 水下伪装目标检测（UCOD）对海洋生态至关重要，但由于光学畸变、水体浑浊和海洋生物复杂特征，该任务仍未被充分探索且准确识别面临巨大挑战。

Method: 本文首先引入了UCOD任务并构建了基准数据集DeepCamo。在此基础上，提出了语义定位与增强网络（SLENet），包含Gamma-非对称增强（GAE）模块用于增强多尺度特征表示，以及定位引导分支（LGB）生成富含全局语义信息的定位图，该图指导多尺度监督解码器（MSSD）生成更准确的预测。

Result: 在DeepCamo数据集和三个现有伪装目标检测（COD）基准数据集上的实验结果表明，SLENet的性能优于现有最先进的方法，并证明了其在更广泛的COD任务中具有很高的泛化能力。

Conclusion: 本文成功定义了UCOD任务，提供了专用数据集DeepCamo，并开发了高效的SLENet框架。SLENet通过其创新的特征增强和定位引导机制，显著提升了水下伪装目标检测的准确性，并展现出强大的跨领域泛化能力。

Abstract: Underwater Camouflaged Object Detection (UCOD) aims to identify objects that
blend seamlessly into underwater environments. This task is critically
important to marine ecology. However, it remains largely underexplored and
accurate identification is severely hindered by optical distortions, water
turbidity, and the complex traits of marine organisms. To address these
challenges, we introduce the UCOD task and present DeepCamo, a benchmark
dataset designed for this domain. We also propose Semantic Localization and
Enhancement Network (SLENet), a novel framework for UCOD. We first benchmark
state-of-the-art COD models on DeepCamo to reveal key issues, upon which SLENet
is built. In particular, we incorporate Gamma-Asymmetric Enhancement (GAE)
module and a Localization Guidance Branch (LGB) to enhance multi-scale feature
representation while generating a location map enriched with global semantic
information. This map guides the Multi-Scale Supervised Decoder (MSSD) to
produce more accurate predictions. Experiments on our DeepCamo dataset and
three benchmark COD datasets confirm SLENet's superior performance over SOTA
methods, and underscore its high generality for the broader COD task.

</details>


### [52] [Fitting Image Diffusion Models on Video Datasets](https://arxiv.org/abs/2509.03794)
*Juhun Lee,Simon S. Woo*

Main category: cs.CV

TL;DR: 该研究提出一种利用连续视频帧中时间归纳偏差的简单有效训练策略，以改进图像扩散模型的训练，实现更快的收敛和更高的生成质量，无需修改模型架构。


<details>
  <summary>Details</summary>
Motivation: 图像扩散模型通常基于独立采样的静态图像进行训练，但这种方式在捕捉时间世界时存在信息不足的问题，导致收敛缓慢、分布覆盖有限和泛化能力下降。

Method: 提出一种训练策略，利用连续视频帧中存在的时间归纳偏差来改进扩散模型训练。该方法无需修改模型架构，可无缝集成到标准扩散训练流程中。通过优化分析，该正则化策略能减少梯度方差。

Result: 在HandCo数据集上，该方法将收敛速度提高了2倍以上，并在训练和验证分布上实现了更低的FID。它还通过鼓励模型捕捉有意义的时间变化来提高生成多样性。优化分析表明，该正则化减少了梯度方差，有助于加速收敛。

Conclusion: 利用连续视频帧中的时间归纳偏差，可以显著加速图像扩散模型的训练收敛速度，提高生成质量和多样性，且无需修改现有模型架构，是一种简单有效的改进策略。

Abstract: Image diffusion models are trained on independently sampled static images.
While this is the bedrock task protocol in generative modeling, capturing the
temporal world through the lens of static snapshots is information-deficient by
design. This limitation leads to slower convergence, limited distributional
coverage, and reduced generalization. In this work, we propose a simple and
effective training strategy that leverages the temporal inductive bias present
in continuous video frames to improve diffusion training. Notably, the proposed
method requires no architectural modification and can be seamlessly integrated
into standard diffusion training pipelines. We evaluate our method on the
HandCo dataset, where hand-object interactions exhibit dense temporal coherence
and subtle variations in finger articulation often result in semantically
distinct motions. Empirically, our method accelerates convergence by over
2$\text{x}$ faster and achieves lower FID on both training and validation
distributions. It also improves generative diversity by encouraging the model
to capture meaningful temporal variations. We further provide an optimization
analysis showing that our regularization reduces the gradient variance, which
contributes to faster convergence.

</details>


### [53] [MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting](https://arxiv.org/abs/2509.03800)
*Yuheng Li,Yenho Chen,Yuxiang Lai,Jike Zhong,Vanessa Wildman,Xiaofeng Yang*

Main category: cs.CV

TL;DR: MedVista3D是一个多尺度、语义增强的3D CT视觉-语言预训练框架，通过局部和全局图像-文本对齐以及语义感知的报告处理，解决了放射学诊断中的错误和报告不一致问题，并在多项任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 放射学诊断错误（如漏诊、注意力盲区、沟通失败）普遍存在，尤其在3D成像中因局部异常遗漏、全局上下文受限和报告语言可变性而加剧。现有3D视觉-语言模型无法同时满足精确局部检测、全局体积推理和语义一致的自然语言报告这三项需求，因为它们缺乏局部-全局理解，并且难以处理未经整理的放射学报告的变异性和噪声。

Method: 本文提出了MedVista3D，一个用于3D CT分析的多尺度语义增强视觉-语言预训练框架。为实现疾病检测和整体解释，MedVista3D在全体积背景下进行局部和全局图像-文本对齐，以学习细粒度表示。为解决报告变异性，该方法应用了语言模型重写，并引入了一个放射学语义匹配库（Radiology Semantic Matching Bank）以实现语义感知的对齐。

Result: MedVista3D在零样本疾病分类、报告检索和医学视觉问答方面取得了最先进的性能，并能很好地迁移到器官分割和预后预测任务中。

Conclusion: MedVista3D通过其多尺度语义增强的视觉-语言预训练框架，有效解决了3D CT分析中局部-全局理解和报告一致性的关键挑战，显著提高了诊断准确性和解释能力，并展现了在多种医学任务上的强大泛化能力。

Abstract: Radiologic diagnostic errors-under-reading errors, inattentional blindness,
and communication failures-remain prevalent in clinical practice. These issues
often stem from missed localized abnormalities, limited global context, and
variability in report language. These challenges are amplified in 3D imaging,
where clinicians must examine hundreds of slices per scan. Addressing them
requires systems with precise localized detection, global volume-level
reasoning, and semantically consistent natural language reporting. However,
existing 3D vision-language models are unable to meet all three needs jointly,
lacking local-global understanding for spatial reasoning and struggling with
the variability and noise of uncurated radiology reports. We present
MedVista3D, a multi-scale semantic-enriched vision-language pretraining
framework for 3D CT analysis. To enable joint disease detection and holistic
interpretation, MedVista3D performs local and global image-text alignment for
fine-grained representation learning within full-volume context. To address
report variability, we apply language model rewrites and introduce a Radiology
Semantic Matching Bank for semantics-aware alignment. MedVista3D achieves
state-of-the-art performance on zero-shot disease classification, report
retrieval, and medical visual question answering, while transferring well to
organ segmentation and prognosis prediction. Code and datasets will be
released.

</details>


### [54] [Causality-guided Prompt Learning for Vision-language Models via Visual Granulation](https://arxiv.org/abs/2509.03803)
*Mengyu Gao,Qiulei Dong*

Main category: cs.CV

TL;DR: 本文提出CaPL，一种通过视觉粒化和因果推理的文本提示学习方法，以提高CLIP在细粒度数据集上的识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于CLIP的提示学习方法在处理细粒度数据集时表现有限，难以捕捉类别间的细微差异。

Method: CaPL方法包含两个模块：1) 属性解耦模块，使用布朗桥扩散模型将视觉特征分解为非个体化和个体化属性；2) 粒化学习模块，通过整合上述属性，并在两种因果推理策略下构建视觉粒化，以学习更具判别力的文本提示。

Result: 在15个数据集上的大量实验结果表明，CaPL方法显著优于最先进的提示学习方法，尤其是在细粒度数据集上。

Conclusion: CaPL通过探索视觉粒化技术和因果推理，有效地构建了视觉粒化，从而学习到更具判别力的文本提示，显著提升了CLIP在细粒度识别任务中的性能。

Abstract: Prompt learning has recently attracted much attention for adapting
pre-trained vision-language models (e.g., CLIP) to downstream recognition
tasks. However, most of the existing CLIP-based prompt learning methods only
show a limited ability for handling fine-grained datasets. To address this
issue, we propose a causality-guided text prompt learning method via visual
granulation for CLIP, called CaPL, where the explored visual granulation
technique could construct sets of visual granules for the text prompt to
capture subtle discrepancies among different fine-grained classes through
casual inference. The CaPL method contains the following two modules: (1) An
attribute disentanglement module is proposed to decompose visual features into
non-individualized attributes (shared by some classes) and individualized
attributes (specific to single classes) using a Brownian Bridge Diffusion
Model; (2) A granule learning module is proposed to construct visual granules
by integrating the aforementioned attributes for recognition under two causal
inference strategies. Thanks to the learned visual granules, more
discriminative text prompt is expected to be learned. Extensive experimental
results on 15 datasets demonstrate that our CaPL method significantly
outperforms the state-of-the-art prompt learning methods, especially on
fine-grained datasets.

</details>


### [55] [EGTM: Event-guided Efficient Turbulence Mitigation](https://arxiv.org/abs/2509.03808)
*Huanan Li,Rui Fan,Juntao Guan,Weidong Hao,Lai Rui,Tong Wu,Yikai Wang,Lin Gu*

Main category: cs.CV

TL;DR: 本文提出了一种基于事件相机的湍流抑制（TM）方法，利用事件相机的微秒级时间分辨率和稀疏异步成像机制，显著提高了计算和存储效率，并在图像恢复质量上超越了现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习TM方法需要高容量网络从有限帧率的同步帧中提取湍流线索进行“幸运融合”，导致计算和存储效率低下。事件相机具有微秒级时间分辨率和高效的稀疏异步成像机制，有望从根本上解决这一瓶颈。

Method: ['提出了“事件幸运洞察”（event-lucky insight），揭示了湍流畸变与事件流逆时空分布之间的相关性。', '基于该洞察，提出了一种新颖的EGTM框架，从显式但嘈杂的湍流事件中提取像素级可靠的无湍流引导信息，用于时间幸运融合。', '构建了第一个湍流数据采集系统，并贡献了首个真实世界事件驱动的TM数据集。']

Result: 在模型大小、推理延迟和模型复杂度方面，本文方法分别比现有SOTA TM方法快710倍、214倍和224倍。同时，在真实世界EGTM数据集上，恢复质量达到SOTA水平（+0.94 PSNR和+0.08 SSIM）。

Conclusion: 将事件模态引入湍流抑制任务，在实现最先进恢复质量的同时，展示了巨大的效率优势。

Abstract: Turbulence mitigation (TM) aims to remove the stochastic distortions and
blurs introduced by atmospheric turbulence into frame cameras. Existing
state-of-the-art deep-learning TM methods extract turbulence cues from multiple
degraded frames to find the so-called "lucky'', not distorted patch, for "lucky
fusion''. However, it requires high-capacity network to learn from
coarse-grained turbulence dynamics between synchronous frames with limited
frame-rate, thus fall short in computational and storage efficiency. Event
cameras, with microsecond-level temporal resolution, have the potential to
fundamentally address this bottleneck with efficient sparse and asynchronous
imaging mechanism. In light of this, we (i) present the fundamental
\textbf{``event-lucky insight''} to reveal the correlation between turbulence
distortions and inverse spatiotemporal distribution of event streams. Then,
build upon this insight, we (ii) propose a novel EGTM framework that extracts
pixel-level reliable turbulence-free guidance from the explicit but noisy
turbulent events for temporal lucky fusion. Moreover, we (iii) build the first
turbulence data acquisition system to contribute the first real-world
event-driven TM dataset. Extensive experimental results demonstrate that our
approach significantly surpass the existing SOTA TM method by 710 times, 214
times and 224 times in model size, inference latency and model complexity
respectively, while achieving the state-of-the-art in restoration quality
(+0.94 PSNR and +0.08 SSIM) on our real-world EGTM dataset. This demonstrating
the great efficiency merit of introducing event modality into TM task. Demo
code and data have been uploaded in supplementary material and will be released
once accepted.

</details>


### [56] [Focus Through Motion: RGB-Event Collaborative Token Sparsification for Efficient Object Detection](https://arxiv.org/abs/2509.03872)
*Nan Yang,Yang Wang,Zhanwen Liu,Yuchao Dai,Yang Liu,Xiangmo Zhao*

Main category: cs.CV

TL;DR: FocusMamba通过事件引导的多模态稀疏化和跨模态聚焦融合，解决了RGB-事件检测中低信息区域处理导致的计算冗余和性能问题，实现了准确性和效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-事件检测方法对低信息区域（图像背景、事件数据非事件区域）进行统一处理，导致计算成本高昂且性能不佳。此外，现有token稀疏化方法采用固定数量或阈值，无法根据样本复杂性自适应保留信息丰富的token。

Method: 提出FocusMamba模型，该模型通过以下方式实现自适应协同稀疏化和高效信息融合：1. 事件引导的多模态稀疏化（EGMS）策略：利用事件相机感知的场景内容变化，自适应识别并丢弃各模态中的低信息区域。2. 跨模态聚焦融合（CMFF）模块：基于稀疏化结果，有效捕获并整合来自两种模态的互补特征。

Result: 在DSEC-Det和PKU-DAVIS-SOD数据集上的实验表明，所提出的方法在准确性和效率方面均优于现有方法。

Conclusion: FocusMamba通过自适应协同稀疏化和高效融合互补信息，有效解决了RGB-事件检测中的计算冗余和性能瓶颈，实现了准确性和效率的显著提升。

Abstract: Existing RGB-Event detection methods process the low-information regions of
both modalities (background in images and non-event regions in event data)
uniformly during feature extraction and fusion, resulting in high computational
costs and suboptimal performance. To mitigate the computational redundancy
during feature extraction, researchers have respectively proposed token
sparsification methods for the image and event modalities. However, these
methods employ a fixed number or threshold for token selection, hindering the
retention of informative tokens for samples with varying complexity. To achieve
a better balance between accuracy and efficiency, we propose FocusMamba, which
performs adaptive collaborative sparsification of multimodal features and
efficiently integrates complementary information. Specifically, an Event-Guided
Multimodal Sparsification (EGMS) strategy is designed to identify and
adaptively discard low-information regions within each modality by leveraging
scene content changes perceived by the event camera. Based on the
sparsification results, a Cross-Modality Focus Fusion (CMFF) module is proposed
to effectively capture and integrate complementary features from both
modalities. Experiments on the DSEC-Det and PKU-DAVIS-SOD datasets demonstrate
that the proposed method achieves superior performance in both accuracy and
efficiency compared to existing methods. The code will be available at
https://github.com/Zizzzzzzz/FocusMamba.

</details>


### [57] [SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition](https://arxiv.org/abs/2509.03873)
*Jiajun Song,Xiaoou Liu*

Main category: cs.CV

TL;DR: 本文提出了组合零样本食物识别 (CZSFR) 任务，并针对其面临的背景冗余、角色混淆和语义偏差三大挑战，提出了 SalientFusion 方法。该方法通过 SalientFormer 移除背景并解决角色混淆，通过 DebiasAT 减少语义偏差，并在新提出的 CZSFood-90、CZSFood-164 数据集及现有通用数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 食物识别领域面临新菜品不断涌现的问题，需要识别未见过的食物类别，这催生了零样本食物学习 (ZSFL)。作者发现菜系和食材与组合零样本学习 (CZSL) 中的属性和对象天然契合，因此提出了组合零样本食物识别 (CZSFR) 任务。然而，CZSFR 面临三个挑战：1) 冗余背景信息干扰模型学习有意义的食物特征；2) 主食和配菜之间的角色混淆导致错误分类；3) 单一属性中的语义偏差导致理解混淆。

Method: 本文提出了 SalientFusion，一种上下文感知的 CZSFR 方法，包含两个主要组件：1) SalientFormer，用于移除背景冗余并利用深度特征解决角色混淆；2) DebiasAT，通过将提示词与视觉特征对齐来减少语义偏差。

Result: 通过使用作者提出的 CZSFood-90 和 CZSFood-164 基准数据集，SalientFusion 在这些数据集以及最流行的通用 CZSL 数据集上均取得了最先进的（state-of-the-art）结果。

Conclusion: SalientFusion 方法有效解决了组合零样本食物识别 (CZSFR) 中的关键挑战，包括背景冗余、角色混淆和语义偏差，并在多个基准测试中展现出卓越的性能，推动了该领域的发展。

Abstract: Food recognition has gained significant attention, but the rapid emergence of
new dishes requires methods for recognizing unseen food categories, motivating
Zero-Shot Food Learning (ZSFL). We propose the task of Compositional Zero-Shot
Food Recognition (CZSFR), where cuisines and ingredients naturally align with
attributes and objects in Compositional Zero-Shot learning (CZSL). However,
CZSFR faces three challenges: (1) Redundant background information distracts
models from learning meaningful food features, (2) Role confusion between
staple and side dishes leads to misclassification, and (3) Semantic bias in a
single attribute can lead to confusion of understanding. Therefore, we propose
SalientFusion, a context-aware CZSFR method with two components: SalientFormer,
which removes background redundancy and uses depth features to resolve role
confusion; DebiasAT, which reduces the semantic bias by aligning prompts with
visual features. Using our proposed benchmarks, CZSFood-90 and CZSFood-164, we
show that SalientFusion achieves state-of-the-art results on these benchmarks
and the most popular general datasets for the general CZSL. The code is
avaliable at https://github.com/Jiajun-RUC/SalientFusion.

</details>


### [58] [Human Motion Video Generation: A Survey](https://arxiv.org/abs/2509.03883)
*Haiwei Xue,Xiangyang Luo,Zhanghao Hu,Xin Zhang,Xunzhi Xiang,Yuqin Dai,Jianzhuang Liu,Zhensong Zhang,Minglei Li,Jian Yang,Fei Ma,Zhiyong Wu,Changpeng Yang,Zonghong Dai,Fei Richard Yu*

Main category: cs.CV

TL;DR: 这篇综述对人类运动视频生成领域进行了全面深入的分析，涵盖了其生成过程的五个关键阶段、十多个子任务、三种主要模态（视觉、文本、音频），并首次探讨了大型语言模型在该领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有综述侧重于单一方法，缺乏对整个生成过程的全面概述，且未讨论大型语言模型在增强人类运动视频生成方面的潜力，因此本研究旨在填补这一空白。

Method: 通过对二百多篇论文进行深入审查，本综述详细阐述了人类运动视频生成的五个关键阶段（输入、运动规划、运动视频生成、精炼、输出）和十多个子任务，并按视觉、文本和音频三种主要模态回顾了最新进展和技术趋势。

Result: 本综述提供了该领域的全面概览，突出了具有里程碑意义的技术突破性工作，并首次讨论了大型语言模型在增强人类运动视频生成方面的潜力。

Conclusion: 本综述旨在揭示人类运动视频生成的前景，并为推动数字人综合应用提供宝贵资源。

Abstract: Human motion video generation has garnered significant research interest due
to its broad applications, enabling innovations such as photorealistic singing
heads or dynamic avatars that seamlessly dance to music. However, existing
surveys in this field focus on individual methods, lacking a comprehensive
overview of the entire generative process. This paper addresses this gap by
providing an in-depth survey of human motion video generation, encompassing
over ten sub-tasks, and detailing the five key phases of the generation
process: input, motion planning, motion video generation, refinement, and
output. Notably, this is the first survey that discusses the potential of large
language models in enhancing human motion video generation. Our survey reviews
the latest developments and technological trends in human motion video
generation across three primary modalities: vision, text, and audio. By
covering over two hundred papers, we offer a thorough overview of the field and
highlight milestone works that have driven significant technological
breakthroughs. Our goal for this survey is to unveil the prospects of human
motion video generation and serve as a valuable resource for advancing the
comprehensive applications of digital humans. A complete list of the models
examined in this survey is available in Our Repository
https://github.com/Winn1y/Awesome-Human-Motion-Video-Generation.

</details>


### [59] [OccTENS: 3D Occupancy World Model via Temporal Next-Scale Prediction](https://arxiv.org/abs/2509.03887)
*Bu Jin,Songen Gu,Xiaotao Hu,Yupeng Zheng,Xiaoyang Guo,Qian Zhang,Xiaoxiao Long,Wei Yin*

Main category: cs.CV

TL;DR: 本文提出了OccTENS，一种生成式占据世界模型，能够实现可控、高保真、高效的长期占据生成，同时解决了现有方法的效率低、长期生成退化和缺乏可控性等问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于自回归（AR）的占据世界模型在长期生成中存在效率低下、时间退化和缺乏可控性等问题。此外，3D场景的精细几何和动态演化对生成模型提出了巨大挑战。

Method: OccTENS将占据世界模型重新定义为时间下一尺度预测（TENS）任务，将时间序列建模分解为空间逐尺度生成和时间逐场景预测。它使用一个名为TensFormer的模型来灵活高效地管理占据序列的时间因果关系和空间关系。为增强姿态可控性，还提出了一个整体姿态聚合策略，统一了占据和自我运动的序列建模。

Result: 实验表明，OccTENS在占据质量和推理速度方面均优于现有最先进的方法。

Conclusion: OccTENS通过创新的TENS任务重构和TensFormer架构，成功解决了3D占据世界模型在长期生成中的效率、质量和可控性挑战，实现了卓越的性能。

Abstract: In this paper, we propose OccTENS, a generative occupancy world model that
enables controllable, high-fidelity long-term occupancy generation while
maintaining computational efficiency. Different from visual generation, the
occupancy world model must capture the fine-grained 3D geometry and dynamic
evolution of the 3D scenes, posing great challenges for the generative models.
Recent approaches based on autoregression (AR) have demonstrated the potential
to predict vehicle movement and future occupancy scenes simultaneously from
historical observations, but they typically suffer from \textbf{inefficiency},
\textbf{temporal degradation} in long-term generation and \textbf{lack of
controllability}. To holistically address these issues, we reformulate the
occupancy world model as a temporal next-scale prediction (TENS) task, which
decomposes the temporal sequence modeling problem into the modeling of spatial
scale-by-scale generation and temporal scene-by-scene prediction. With a
\textbf{TensFormer}, OccTENS can effectively manage the temporal causality and
spatial relationships of occupancy sequences in a flexible and scalable way. To
enhance the pose controllability, we further propose a holistic pose
aggregation strategy, which features a unified sequence modeling for occupancy
and ego-motion. Experiments show that OccTENS outperforms the state-of-the-art
method with both higher occupancy quality and faster inference time.

</details>


### [60] [Weakly-Supervised Learning of Dense Functional Correspondences](https://arxiv.org/abs/2509.03893)
*Stefan Stojanov,Linan Zhao,Yunzhi Zhang,Daniel L. K. Yamins,Jiajun Wu*

Main category: cs.CV

TL;DR: 本文提出了一种弱监督学习范式，利用视觉-语言模型生成功能部件的伪标签，并结合像素级对比学习，以建立跨类别图像之间的密集功能对应关系，并在合成和真实数据集上取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在图像对之间建立密集对应关系对于形状重建和机器人操作等任务至关重要。在具有挑战性的跨类别匹配场景中，物体的功能（即物体对其他物体产生的影响）可以指导如何建立对应关系，因为实现特定功能的物体部件通常在形状和外观上具有相似性。

Method: 基于上述观察，作者推导了密集功能对应关系的定义，并提出了一个弱监督学习范式。该方法的核心思想是利用视觉-语言模型对多视图图像进行伪标注，以获取功能部件。随后，将此与来自像素对应关系的密集对比学习相结合，将功能和空间知识提炼到一个新模型中，从而建立密集功能对应关系。此外，还构建了合成和真实评估数据集作为任务基准。

Result: 实验结果表明，与由现成的自监督图像表示和接地视觉-语言模型组成的基线解决方案相比，本文提出的方法具有显著优势。

Conclusion: 本文提出了一种通过结合视觉-语言模型伪标签和密集对比学习来建立密集功能对应关系的新方法，该方法在跨类别匹配任务中表现出色，并优于现有基线解决方案。

Abstract: Establishing dense correspondences across image pairs is essential for tasks
such as shape reconstruction and robot manipulation. In the challenging setting
of matching across different categories, the function of an object, i.e., the
effect that an object can cause on other objects, can guide how correspondences
should be established. This is because object parts that enable specific
functions often share similarities in shape and appearance. We derive the
definition of dense functional correspondence based on this observation and
propose a weakly-supervised learning paradigm to tackle the prediction task.
The main insight behind our approach is that we can leverage vision-language
models to pseudo-label multi-view images to obtain functional parts. We then
integrate this with dense contrastive learning from pixel correspondences to
distill both functional and spatial knowledge into a new model that can
establish dense functional correspondence. Further, we curate synthetic and
real evaluation datasets as task benchmarks. Our results demonstrate the
advantages of our approach over baseline solutions consisting of off-the-shelf
self-supervised image representations and grounded vision language models.

</details>


### [61] [Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of Vision-Language Model](https://arxiv.org/abs/2509.03895)
*Phuoc-Nguyen Bui,Khanh-Binh Nguyen,Hyunseung Choo*

Main category: cs.CV

TL;DR: 本文提出了Attn-Adapter，一个新颖的在线少样本学习框架，通过双注意力机制增强了CLIP模型的适应性，无需重新训练基础模型即可实现高效的少样本泛化。


<details>
  <summary>Details</summary>
Motivation: 对比视觉-语言模型在零样本图像识别中表现出色，但在少样本场景中面临挑战，因为传统的提示学习（prompt learning）需要计算密集型离线微调，且容易过拟合。

Method: Attn-Adapter是一个在线少样本学习框架，通过双注意力机制提升CLIP的适应性。它包含两个主要组件：1) Memory Attn-Adapter：利用支持样本细化类别嵌入；2) Local-Global Attn-Adapter：通过整合局部和全局特征来丰富图像嵌入。该架构能够在不重新训练基础模型的情况下，仅凭少量标记样本实现动态适应。

Result: Attn-Adapter在跨类别和跨数据集泛化方面均优于现有最先进的方法，同时保持了高效的推理，并能良好地扩展到不同的CLIP骨干网络。

Conclusion: Attn-Adapter成功克服了CLIP在少样本学习中的局限性，提供了一种高效、无需重新训练的在线适应方案，显著提升了模型在复杂少样本场景下的泛化能力和效率。

Abstract: Contrastive vision-language models excel in zero-shot image recognition but
face challenges in few-shot scenarios due to computationally intensive offline
fine-tuning using prompt learning, which risks overfitting. To overcome these
limitations, we propose Attn-Adapter, a novel online few-shot learning
framework that enhances CLIP's adaptability via a dual attention mechanism. Our
design incorporates dataset-specific information through two components: the
Memory Attn-Adapter, which refines category embeddings using support examples,
and the Local-Global Attn-Adapter, which enriches image embeddings by
integrating local and global features. This architecture enables dynamic
adaptation from a few labeled samples without retraining the base model.
Attn-Adapter outperforms state-of-the-art methods in cross-category and
cross-dataset generalization, maintaining efficient inference and scaling
across CLIP backbones.

</details>


### [62] [YOLO Ensemble for UAV-based Multispectral Defect Detection in Wind Turbine Components](https://arxiv.org/abs/2509.04156)
*Serhii Svystun,Pavlo Radiuk,Oleksandr Melnychenko,Oleg Savenko,Anatoliy Sachenko*

Main category: cs.CV

TL;DR: 该研究开发了一种基于YOLO模型集成（结合可见光和热成像数据）的方法，以提高无人机在风力发电厂缺陷检测中的准确性，并取得了优于单一模型的性能。


<details>
  <summary>Details</summary>
Motivation: 无人机为风力发电厂（包括叶片、塔架和其他关键部件）的监测提供了新机遇。然而，可靠的缺陷检测需要高分辨率数据和有效的多光谱图像处理方法。本研究旨在通过开发基于YOLO深度学习模型的集成方案来提高缺陷检测的准确性。

Method: 研究提出了一种集成YOLOv8通用模型和专用热成像模型的集成方法。该方法整合了可见光和热成像通道，并使用复杂的边界框融合算法来合并两者的预测。

Result: 实验结果显示，该集成方法在mAP@.5上达到了0.93，F1-score为0.90，优于单独的YOLOv8模型（mAP@.5为0.91）。

Conclusion: 结合多个YOLO架构和融合多光谱数据提供了一种更可靠的解决方案，显著提高了对视觉和热缺陷的检测能力。

Abstract: Unmanned aerial vehicles (UAVs) equipped with advanced sensors have opened up
new opportunities for monitoring wind power plants, including blades, towers,
and other critical components. However, reliable defect detection requires
high-resolution data and efficient methods to process multispectral imagery. In
this research, we aim to enhance defect detection accuracy through the
development of an ensemble of YOLO-based deep learning models that integrate
both visible and thermal channels. We propose an ensemble approach that
integrates a general-purpose YOLOv8 model with a specialized thermal model,
using a sophisticated bounding box fusion algorithm to combine their
predictions. Our experiments show this approach achieves a mean Average
Precision (mAP@.5) of 0.93 and an F1-score of 0.90, outperforming a standalone
YOLOv8 model, which scored an mAP@.5 of 0.91. These findings demonstrate that
combining multiple YOLO architectures with fused multispectral data provides a
more reliable solution, improving the detection of both visual and thermal
defects.

</details>


### [63] [SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation](https://arxiv.org/abs/2509.03897)
*Xiaofu Chen,Israfel Salazar,Yova Kementchedjhieva*

Main category: cs.CV

TL;DR: 本文提出了SPECS（Specificity-Enhanced CLIPScore），一种针对长图像描述的无参考RS（表征相似性）评估指标。SPECS通过修改CLIP模型，强调描述的特异性，使其在与人类判断的相关性上与基于LLM的指标相当，但在效率上远超后者，适用于模型开发中的迭代评估。


<details>
  <summary>Details</summary>
Motivation: 随着生成长而详细图像描述的需求增加，现有评估指标面临挑战：N-gram指标缺乏语义准确性；传统RS指标计算成本高且与人类判断相关性低；基于LLM的指标虽然相关性强，但计算成本过高，不适用于模型开发中的迭代使用。因此，需要一种既能准确评估长描述，又高效的指标。

Method: 本文引入了SPECS，这是一种无参考的RS指标，专为长图像描述设计。SPECS通过修改CLIP模型，引入了一个新的目标函数，该函数强调描述的特异性：奖励正确的细节，并惩罚不正确的细节。

Result: SPECS在与人类判断的相关性方面，与开源的基于LLM的指标表现相当，但效率更高。

Conclusion: SPECS提供了一个实用且高效的替代方案，可用于图像描述模型开发过程中的迭代检查点评估。

Abstract: As interest grows in generating long, detailed image captions, standard
evaluation metrics become increasingly unreliable. N-gram-based metrics though
efficient, fail to capture semantic correctness. Representational Similarity
(RS) metrics, designed to address this, initially saw limited use due to high
computational costs, while today, despite advances in hardware, they remain
unpopular due to low correlation to human judgments. Meanwhile, metrics based
on large language models (LLMs) show strong correlation with human judgments,
but remain too expensive for iterative use during model development.
  We introduce SPECS (Specificity-Enhanced CLIPScore), a reference-free RS
metric tailored to long image captioning. SPECS modifies CLIP with a new
objective that emphasizes specificity: rewarding correct details and penalizing
incorrect ones. We show that SPECS matches the performance of open-source
LLM-based metrics in correlation to human judgments, while being far more
efficient. This makes it a practical alternative for iterative checkpoint
evaluation during image captioning model development.Our code can be found at
https://github.com/mbzuai-nlp/SPECS.

</details>


### [64] [A Generative Foundation Model for Chest Radiography](https://arxiv.org/abs/2509.03903)
*Yuanfeng Ji,Dan Lin,Xiyue Wang,Lu Zhang,Wenhui Zhou,Chongjian Ge,Ruihang Chu,Xiaoli Yang,Junhan Zhao,Junsong Chen,Xiangde Luo,Sen Yang,Jin Fang,Ping Luo,Ruijiang Li*

Main category: cs.CV

TL;DR: ChexGen是一个生成式视觉-语言基础模型，用于胸部X光片的文本、掩码和边界框引导合成。它通过数据增强和监督预训练提高了医疗AI模型的性能和公平性。


<details>
  <summary>Details</summary>
Motivation: 高质量、多样化的医学图像标注数据稀缺，严重阻碍了医疗领域可靠AI模型的发展。

Method: 开发了名为“ChexGen”的生成式视觉-语言基础模型，采用统一框架实现文本、掩码和边界框引导的胸部X光片合成。该模型基于潜在扩散变换器架构，并使用迄今为止最大的胸部X光片数据集（包含960,000对放射报告）进行预训练。

Result: ChexGen通过专家评估和定量指标实现了准确的X光片合成。通过训练数据增强和监督预训练，该模型在疾病分类、检测和分割任务上，即使使用少量训练数据，也能显著提升性能。此外，它能创建多样化的患者队列，通过检测和缓解人口偏见来增强模型公平性。

Conclusion: 生成式基础模型在构建更准确、数据高效和公平的医疗AI系统方面具有变革性作用。

Abstract: The scarcity of well-annotated diverse medical images is a major hurdle for
developing reliable AI models in healthcare. Substantial technical advances
have been made in generative foundation models for natural images. Here we
develop `ChexGen', a generative vision-language foundation model that
introduces a unified framework for text-, mask-, and bounding box-guided
synthesis of chest radiographs. Built upon the latent diffusion transformer
architecture, ChexGen was pretrained on the largest curated chest X-ray dataset
to date, consisting of 960,000 radiograph-report pairs. ChexGen achieves
accurate synthesis of radiographs through expert evaluations and quantitative
metrics. We demonstrate the utility of ChexGen for training data augmentation
and supervised pretraining, which led to performance improvements across
disease classification, detection, and segmentation tasks using a small
fraction of training data. Further, our model enables the creation of diverse
patient cohorts that enhance model fairness by detecting and mitigating
demographic biases. Our study supports the transformative role of generative
foundation models in building more accurate, data-efficient, and equitable
medical AI systems.

</details>


### [65] [LMVC: An End-to-End Learned Multiview Video Coding Framework](https://arxiv.org/abs/2509.03922)
*Xihua Sheng,Yingwen Zhang,Long Xu,Shiqi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种端到端学习的多视角视频编码（LMVC）框架，通过有效利用独立视角的运动和内容信息来增强依赖视角的压缩效率，显著优于传统MV-HEVC标准。


<details>
  <summary>Details</summary>
Motivation: 多视角视频是沉浸式3D场景重建的关键数据源，但其庞大的数据量给存储和传输带来了巨大挑战。尽管基于深度学习的端到端视频编码已取得成功，但多数集中于单视角或立体视频，通用多视角场景尚未充分探索。

Method: 本文提出了一种端到端学习的多视角视频编码（LMVC）框架，确保随机访问和向后兼容性，并提高压缩效率。主要创新在于：1) 利用独立视角运动信息，提出基于特征的视角间运动矢量预测方法，并结合视角间运动熵模型学习先验；2) 利用独立视角内容信息，提出无视差的视角间上下文预测模块，并结合视角间上下文熵模型捕捉先验。

Result: 实验结果表明，所提出的LMVC框架在性能上大幅超越了传统MV-HEVC标准的参考软件。

Conclusion: 所提出的LMVC框架为该领域的未来研究建立了一个强大的基线。

Abstract: Multiview video is a key data source for volumetric video, enabling immersive
3D scene reconstruction but posing significant challenges in storage and
transmission due to its massive data volume. Recently, deep learning-based
end-to-end video coding has achieved great success, yet most focus on
single-view or stereo videos, leaving general multiview scenarios
underexplored. This paper proposes an end-to-end learned multiview video coding
(LMVC) framework that ensures random access and backward compatibility while
enhancing compression efficiency. Our key innovation lies in effectively
leveraging independent-view motion and content information to enhance
dependent-view compression. Specifically, to exploit the inter-view motion
correlation, we propose a feature-based inter-view motion vector prediction
method that conditions dependent-view motion encoding on decoded
independent-view motion features, along with an inter-view motion entropy model
that learns inter-view motion priors. To exploit the inter-view content
correlation, we propose a disparity-free inter-view context prediction module
that predicts inter-view contexts from decoded independent-view content
features, combined with an inter-view contextual entropy model that captures
inter-view context priors. Experimental results show that our proposed LMVC
framework outperforms the reference software of the traditional MV-HEVC
standard by a large margin, establishing a strong baseline for future research
in this field.

</details>


### [66] [TopoSculpt: Betti-Steered Topological Sculpting of 3D Fine-grained Tubular Shapes](https://arxiv.org/abs/2509.03938)
*Minghui Zhang,Yaoyu Liu,Junyang Wu,Xin You,Hanxiao Zhang,Junjun He,Yun Gu*

Main category: cs.CV

TL;DR: 本文提出了一种名为TopoSculpt的新框架，用于对医学三维细粒度管状结构进行拓扑精修，显著提高了几何和拓扑的准确性，解决了现有方法在全局拓扑正确性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 医学管状结构（如气道和脑动脉）的准确几何和拓扑重建对于导航和连接性评估至关重要。现有方法常依赖体素重叠度量，无法捕捉拓扑正确性和完整性，且拓扑感知损失和持久同调约束通常局部应用，不能保证全局拓扑保持或在推理时纠正几何错误。

Method: TopoSculpt框架采用以下策略：(i) 整体区域建模策略以捕捉完整空间上下文；(ii) 首次引入拓扑完整性Betti (TIB) 约束，共同强制执行Betti数先验和全局完整性；(iii) 采用带有持久同调的课程精修方案，从粗到细逐步纠正错误。

Result: 在肺气道和Willis环数据集上的实验表明，TopoSculpt在几何和拓扑方面都有显著改进。例如，气道数据集上的$\beta_0$错误从69.00降至3.40，Willis环数据集上从1.65降至0.30，同时树长检测率和分支检测率提高了近10%。

Conclusion: TopoSculpt框架在纠正关键拓扑错误和推进复杂三维管状解剖结构的高保真建模方面非常有效，解决了现有方法在全局拓扑正确性方面的局限性。

Abstract: Medical tubular anatomical structures are inherently three-dimensional
conduits with lumens, enclosing walls, and complex branching topologies.
Accurate reconstruction of their geometry and topology is crucial for
applications such as bronchoscopic navigation and cerebral arterial
connectivity assessment. Existing methods often rely on voxel-wise overlap
measures, which fail to capture topological correctness and completeness.
Although topology-aware losses and persistent homology constraints have shown
promise, they are usually applied patch-wise and cannot guarantee global
preservation or correct geometric errors at inference. To address these
limitations, we propose a novel TopoSculpt, a framework for topological
refinement of 3D fine-grained tubular structures. TopoSculpt (i) adopts a
holistic whole-region modeling strategy to capture full spatial context, (ii)
first introduces a Topological Integrity Betti (TIB) constraint that jointly
enforces Betti number priors and global integrity, and (iii) employs a
curriculum refinement scheme with persistent homology to progressively correct
errors from coarse to fine scales. Extensive experiments on challenging
pulmonary airway and Circle of Willis datasets demonstrate substantial
improvements in both geometry and topology. For instance, $\beta_{0}$ errors
are reduced from 69.00 to 3.40 on the airway dataset and from 1.65 to 0.30 on
the CoW dataset, with Tree length detected and branch detected rates improving
by nearly 10\%. These results highlight the effectiveness of TopoSculpt in
correcting critical topological errors and advancing the high-fidelity modeling
of complex 3D tubular anatomy. The project homepage is available at:
https://github.com/Puzzled-Hui/TopoSculpt.

</details>


### [67] [Chest X-ray Pneumothorax Segmentation Using EfficientNet-B4 Transfer Learning in a U-Net Architecture](https://arxiv.org/abs/2509.03950)
*Alvaro Aranibar Roque,Helga Sebastian*

Main category: cs.CV

TL;DR: 该研究提出了一种基于U-Net和EfficientNet-B4编码器的自动化深度学习模型，用于准确分割胸部X光片中的气胸区域，并在独立数据集上取得了高精度，可辅助放射科医生诊断。


<details>
  <summary>Details</summary>
Motivation: 气胸若未被发现可能危及生命，而胸部X光片作为首选诊断工具，对于细微的小气胸案例可能难以识别。

Method: 研究提出了一种自动化深度学习流程，采用U-Net架构并结合EfficientNet-B4作为编码器，用于分割气胸区域。模型在SIIM-ACR数据集上进行训练，并使用了数据增强技术以及二元交叉熵与Dice损失函数的组合。

Result: 在独立的PTX-498数据集上，该模型的气胸分割性能达到0.7008的IoU（交并比）和0.8241的Dice分数。

Conclusion: 研究结果表明，所提出的模型能够准确地定位气胸，并能有效辅助放射科医生进行诊断。

Abstract: Pneumothorax, the abnormal accumulation of air in the pleural space, can be
life-threatening if undetected. Chest X-rays are the first-line diagnostic
tool, but small cases may be subtle. We propose an automated deep-learning
pipeline using a U-Net with an EfficientNet-B4 encoder to segment pneumothorax
regions. Trained on the SIIM-ACR dataset with data augmentation and a combined
binary cross-entropy plus Dice loss, the model achieved an IoU of 0.7008 and
Dice score of 0.8241 on the independent PTX-498 dataset. These results
demonstrate that the model can accurately localize pneumothoraces and support
radiologists.

</details>


### [68] [ANTS: Shaping the Adaptive Negative Textual Space by MLLM for OOD Detection](https://arxiv.org/abs/2509.03951)
*Zhu Wenjie,Zhang Yabin,Xin Jin,Wenjun Zeng,Lei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为自适应负文本空间（ANTS）的方法，利用多模态大语言模型（MLLMs）的理解和推理能力，为分布外（OOD）检测构建准确的负空间，有效提升了远OOD和近OOD的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有OOD检测方法在构建负空间时缺乏对OOD图像的理解，导致负空间不准确。此外，假负标签的存在显著降低了近OOD场景下的性能。

Method: 本文通过以下方式构建ANTS：1. 对于远OOD，识别潜在的OOD图像，并提示MLLM生成描述这些图像的富有表达力的负面句子。2. 对于近OOD，首先识别与负图像视觉相似的ID类别子集，然后利用MLLM的推理能力为该子集生成量身定制的视觉相似负标签，以减少假负例。3. 设计了一个自适应加权分数来平衡这两种负文本空间，使其无需特定任务先验知识即可处理不同OOD任务设置。

Result: 在ImageNet基准测试中，ANTS显著降低了FPR95 4.2%，达到了新的SOTA。此外，该方法是免训练和零样本的，具有高度的可扩展性。

Conclusion: 通过利用MLLMs的理解和推理能力，ANTS能够构建一个自适应的负文本空间，有效解决了现有OOD检测方法中负空间不准确和假负标签的问题，显著提升了远OOD和近OOD的检测性能，并展现出高适应性和可扩展性。

Abstract: The introduction of negative labels (NLs) has proven effective in enhancing
Out-of-Distribution (OOD) detection. However, existing methods often lack an
understanding of OOD images, making it difficult to construct an accurate
negative space. In addition, the presence of false negative labels
significantly degrades their near-OOD performance. To address these issues, we
propose shaping an Adaptive Negative Textual Space (ANTS) by leveraging the
understanding and reasoning capabilities of multimodal large language models
(MLLMs). Specifically, we identify images likely to be OOD samples as negative
images and prompt the MLLM to describe these images, generating expressive
negative sentences that precisely characterize the OOD distribution and enhance
far-OOD detection. For the near-OOD setting, where OOD samples resemble the
in-distribution (ID) subset, we first identify the subset of ID classes that
are visually similar to negative images and then leverage the reasoning
capability of MLLMs to generate visually similar negative labels tailored to
this subset, effectively reducing false negatives and improving near-OOD
detection. To balance these two types of negative textual spaces, we design an
adaptive weighted score that enables the method to handle different OOD task
settings (near-OOD and far-OOD) without relying on task-specific prior
knowledge, making it highly adaptable in open environments. On the ImageNet
benchmark, our ANTS significantly reduces the FPR95 by 4.2\%, establishing a
new state-of-the-art. Furthermore, our method is training-free and zero-shot,
enabling high scalability.

</details>


### [69] [Multimodal Feature Fusion Network with Text Difference Enhancement for Remote Sensing Change Detection](https://arxiv.org/abs/2509.03961)
*Yijun Zhou,Yikui Zhai,Zilu Ying,Tingfeng Xian,Wenlve Zhou,Zhiheng Zhou,Xiaolin Tian,Xudong Jia,Hongsheng Zhang,C. L. Philip Chen*

Main category: cs.CV

TL;DR: MMChange是一种多模态遥感变化检测方法，它结合图像和文本模态，通过图像特征细化、文本差异增强和图像文本特征融合模块，提高了在光照和噪声干扰下的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习遥感变化检测方法大多仅依赖图像模态，这限制了特征表示、变化模式建模和泛化能力，尤其是在光照和噪声干扰下表现不佳。

Method: MMChange方法结合了图像和文本模态。它引入了图像特征细化（IFR）模块以突出关键区域并抑制环境噪声；利用视觉语言模型（VLM）生成双时相图像的语义描述；设计了文本差异增强（TDE）模块来捕捉细粒度的语义变化；并构建了图像文本特征融合（ITFF）模块以实现跨模态的深度整合，弥合模态间的异构性。

Result: 在LEVIRCD、WHUCD和SYSUCD等数据集上进行的广泛实验表明，MMChange在多项指标上持续超越了最先进的方法。

Conclusion: MMChange方法有效提升了多模态遥感变化检测的准确性和鲁棒性，验证了其在复杂环境下的有效性。

Abstract: Although deep learning has advanced remote sensing change detection (RSCD),
most methods rely solely on image modality, limiting feature representation,
change pattern modeling, and generalization especially under illumination and
noise disturbances. To address this, we propose MMChange, a multimodal RSCD
method that combines image and text modalities to enhance accuracy and
robustness. An Image Feature Refinement (IFR) module is introduced to highlight
key regions and suppress environmental noise. To overcome the semantic
limitations of image features, we employ a vision language model (VLM) to
generate semantic descriptions of bitemporal images. A Textual Difference
Enhancement (TDE) module then captures fine grained semantic shifts, guiding
the model toward meaningful changes. To bridge the heterogeneity between
modalities, we design an Image Text Feature Fusion (ITFF) module that enables
deep cross modal integration. Extensive experiments on LEVIRCD, WHUCD, and
SYSUCD demonstrate that MMChange consistently surpasses state of the art
methods across multiple metrics, validating its effectiveness for multimodal
RSCD. Code is available at: https://github.com/yikuizhai/MMChange.

</details>


### [70] [SAC-MIL: Spatial-Aware Correlated Multiple Instance Learning for Histopathology Whole Slide Image Classification](https://arxiv.org/abs/2509.03973)
*Yu Bai,Zitong Yu,Haowen Tian,Xijing Wang,Shuo Yan,Lin Wang,Honglin Li,Xitong Ling,Bo Zhang,Zheng Zhang,Wufan Wang,Hui Gao,Xiangyang Gong,Wendong Wang*

Main category: cs.CV

TL;DR: 提出了一种名为SAC-MIL的WSI分类方法，它结合了空间感知的定位编码模块和基于MLP的全实例关联SAC块，实现了SOTA性能且易于部署。


<details>
  <summary>Details</summary>
Motivation: 在全玻片图像（WSI）分类中，需要有效利用实例间的空间关系和相关性，同时解决序列长度变化以及Transformer类方法部署复杂（需要自定义CUDA内核）的问题。

Method: SAC-MIL包含两个主要组件：1. 定位编码模块：利用WSI中实例的坐标而非索引来编码空间关系，并能处理训练和测试序列长度不一致的问题。2. SAC块：一个基于MLP的方法，以线性时间复杂度实现全实例关联，结构简单，易于部署，无需自定义CUDA内核。

Result: SAC-MIL在CAMELYON-16、TCGA-LUNG和TCGA-BRAC数据集上取得了最先进（state-of-the-art）的性能。

Conclusion: SAC-MIL通过其空间感知定位编码和高效的MLP-based全实例关联SAC块，为WSI分类提供了一种高性能且易于部署的解决方案，并在多个基准数据集上超越了现有方法。

Abstract: We propose Spatial-Aware Correlated Multiple Instance Learning (SAC-MIL) for
performing WSI classification. SAC-MIL consists of a positional encoding module
to encode position information and a SAC block to perform full instance
correlations. The positional encoding module utilizes the instance coordinates
within the slide to encode the spatial relationships instead of the instance
index in the input WSI sequence. The positional encoding module can also handle
the length extrapolation issue where the training and testing sequences have
different lengths. The SAC block is an MLP-based method that performs full
instance correlation in linear time complexity with respect to the sequence
length. Due to the simple structure of MLP, it is easy to deploy since it does
not require custom CUDA kernels, compared to Transformer-based methods for WSI
classification. SAC-MIL has achieved state-of-the-art performance on the
CAMELYON-16, TCGA-LUNG, and TCGA-BRAC datasets. The code will be released upon
acceptance.

</details>


### [71] [Improving Vessel Segmentation with Multi-Task Learning and Auxiliary Data Available Only During Model Training](https://arxiv.org/abs/2509.03975)
*Daniel Sobotka,Alexander Herold,Matthias Perkonigg,Lucian Beer,Nina Bastati,Alina Sablatnig,Ahmed Ba-Ssalamah,Georg Langs*

Main category: cs.CV

TL;DR: 该研究提出一种多任务学习框架，利用训练期间可用的辅助对比增强MRI数据，在非对比增强肝脏MRI中进行血管分割，以减少对大量标注数据的需求，并在有限标注下显著提高分割精度。


<details>
  <summary>Details</summary>
Motivation: 肝脏血管分割对于弥漫性肝脏疾病的计算分析至关重要。现有方法依赖于对比增强MRI，但这类序列并非总是可用。非对比增强MRI数据更常见，但血管分割难度大且需要大量标注。因此，如何在非对比增强MRI中高效准确地进行血管分割是一个挑战。

Method: 研究提出一个多任务学习框架，用于在非对比增强肝脏MRI中分割血管。该框架在训练阶段利用辅助的对比增强MRI数据（推理时不可用），以减少对标注训练样本的需求。模型训练使用配对的原始和对比增强数据，其中部分数据包含血管标注，部分不包含。此外，该方法还通过脑肿瘤分割任务进行了跨领域验证。

Result: 结果表明，即使辅助数据在推理时不可用，它们也能提高血管分割的准确性。当训练时只有少量标注数据可用时，这种优势最为显著，因为共享任务结构有助于特征表示。将该方法应用于脑肿瘤分割模型也证实了其在不同领域的益处。

Conclusion: 研究得出结论，辅助信息成像模态可以增强专家标注的效果，即使该模态仅在训练期间可用。这为在数据标注受限的情况下进行医学图像分割提供了一种有效策略。

Abstract: Liver vessel segmentation in magnetic resonance imaging data is important for
the computational analysis of vascular remodelling, associated with a wide
spectrum of diffuse liver diseases. Existing approaches rely on contrast
enhanced imaging data, but the necessary dedicated imaging sequences are not
uniformly acquired. Images without contrast enhancement are acquired more
frequently, but vessel segmentation is challenging, and requires large-scale
annotated data. We propose a multi-task learning framework to segment vessels
in liver MRI without contrast. It exploits auxiliary contrast enhanced MRI data
available only during training to reduce the need for annotated training
examples. Our approach draws on paired native and contrast enhanced data with
and without vessel annotations for model training. Results show that auxiliary
data improves the accuracy of vessel segmentation, even if they are not
available during inference. The advantage is most pronounced if only few
annotations are available for training, since the feature representation
benefits from the shared task structure. A validation of this approach to
augment a model for brain tumor segmentation confirms its benefits across
different domains. An auxiliary informative imaging modality can augment expert
annotations even if it is only available during training.

</details>


### [72] [Promptception: How Sensitive Are Large Multimodal Models to Prompts?](https://arxiv.org/abs/2509.03986)
*Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan*

Main category: cs.CV

TL;DR: 本研究揭示了多模态大模型（LMMs）在多项选择问答（MCQA）中对提示词设计的敏感性，提出了Promptception框架来系统评估，发现专有模型更敏感，并据此提出了提示词原则以实现更公平的评估。


<details>
  <summary>Details</summary>
Motivation: LMMs在MCQA中的提示词设计尚不明确，即使是微小的提示词变化也可能导致高达15%的准确率偏差。这种变异性使得LMMs的透明和公平评估面临挑战，因为模型通常报告其精心选择提示词下的最佳性能。

Method: 引入了Promptception，一个系统评估LMMs提示词敏感性的框架。该框架包含61种提示词类型，跨越15个类别和6个超级类别，旨在针对提示词制定的特定方面进行评估。研究使用该框架评估了10个LMMs（从轻量级开源模型到GPT-4o和Gemini 1.5 Pro），并在MMStar、MMMU-Pro、MVBench这3个MCQA基准上进行测试。

Result: 研究发现，专有模型对提示词措辞表现出更高的敏感性，反映出它们与指令语义更紧密的对齐。相比之下，开源模型虽然更稳定，但在处理细致和复杂的措辞时表现不佳。

Conclusion: 基于分析结果，本研究提出了针对专有和开源LMMs的“提示词原则”（Prompting Principles），以期实现更稳健和公平的模型评估。

Abstract: Despite the success of Large Multimodal Models (LMMs) in recent years, prompt
design for LMMs in Multiple-Choice Question Answering (MCQA) remains poorly
understood. We show that even minor variations in prompt phrasing and structure
can lead to accuracy deviations of up to 15% for certain prompts and models.
This variability poses a challenge for transparent and fair LMM evaluation, as
models often report their best-case performance using carefully selected
prompts. To address this, we introduce Promptception, a systematic framework
for evaluating prompt sensitivity in LMMs. It consists of 61 prompt types,
spanning 15 categories and 6 supercategories, each targeting specific aspects
of prompt formulation, and is used to evaluate 10 LMMs ranging from lightweight
open-source models to GPT-4o and Gemini 1.5 Pro, across 3 MCQA benchmarks:
MMStar, MMMU-Pro, MVBench. Our findings reveal that proprietary models exhibit
greater sensitivity to prompt phrasing, reflecting tighter alignment with
instruction semantics, while open-source models are steadier but struggle with
nuanced and complex phrasing. Based on this analysis, we propose Prompting
Principles tailored to proprietary and open-source LMMs, enabling more robust
and fair model evaluation.

</details>


### [73] [SliceSemOcc: Vertical Slice Based Multimodal 3D Semantic Occupancy Representation](https://arxiv.org/abs/2509.03999)
*Han Huang,Han Sun,Ningzhong Liu,Huiyu Zhou,Jiaquan Shen*

Main category: cs.CV

TL;DR: 针对3D语义占用预测中忽略高度轴信息和通道注意力分配不均的问题，本文提出了SliceSemOcc框架，通过垂直切片、全局局部融合以及动态高度感知通道注意力（SEAttention3D）显著提升了3D感知性能，尤其在小物体类别上表现突出。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶对精确3D感知有很高需求，3D语义占用预测是关键技术。现有方法在处理体素特征时，忽略了高度轴信息，且传统的SENet式通道注意力对所有高度层分配统一权重，限制了其强调不同高度特征的能力。

Method: 本文提出了SliceSemOcc，一个基于垂直切片的多模态3D语义占用表示框架。具体而言，它使用全局和局部垂直切片沿高度轴提取体素特征；然后，通过全局局部融合模块自适应地协调精细空间细节与整体上下文信息；此外，还提出了SEAttention3D模块，该模块通过平均池化保留高度分辨率，并为每个高度层分配动态通道注意力权重。

Result: 在nuScenes-SurroundOcc和nuScenes-OpenOccupancy数据集上进行了广泛实验，验证了所提方法显著提升了平均IoU，尤其在大多数小物体类别上取得了显著增益。详细的消融研究进一步证实了SliceSemOcc框架的有效性。

Conclusion: SliceSemOcc框架通过有效利用高度轴信息和动态通道注意力，成功解决了现有3D语义占用预测方法的局限性，显著增强了3D感知能力，尤其对小物体识别有显著提升。

Abstract: Driven by autonomous driving's demands for precise 3D perception, 3D semantic
occupancy prediction has become a pivotal research topic. Unlike
bird's-eye-view (BEV) methods, which restrict scene representation to a 2D
plane, occupancy prediction leverages a complete 3D voxel grid to model spatial
structures in all dimensions, thereby capturing semantic variations along the
vertical axis. However, most existing approaches overlook height-axis
information when processing voxel features. And conventional SENet-style
channel attention assigns uniform weight across all height layers, limiting
their ability to emphasize features at different heights. To address these
limitations, we propose SliceSemOcc, a novel vertical slice based multimodal
framework for 3D semantic occupancy representation. Specifically, we extract
voxel features along the height-axis using both global and local vertical
slices. Then, a global local fusion module adaptively reconciles fine-grained
spatial details with holistic contextual information. Furthermore, we propose
the SEAttention3D module, which preserves height-wise resolution through
average pooling and assigns dynamic channel attention weights to each height
layer. Extensive experiments on nuScenes-SurroundOcc and nuScenes-OpenOccupancy
datasets verify that our method significantly enhances mean IoU, achieving
especially pronounced gains on most small-object categories. Detailed ablation
studies further validate the effectiveness of the proposed SliceSemOcc
framework.

</details>


### [74] [Detecting Regional Spurious Correlations in Vision Transformers via Token Discarding](https://arxiv.org/abs/2509.04009)
*Solha Kang,Esla Timothy Anzaku,Wesley De Neve,Arnout Van Messem,Joris Vankerschaver,Francois Rameau,Utku Ozbulak*

Main category: cs.CV

TL;DR: 本文提出了一种检测视觉Transformer中虚假关联的新方法，通过大规模实验证明其有效性，并发现训练方法对模型依赖虚假关联有显著影响，同时识别出ImageNet数据集中存在虚假信号的特定类别。


<details>
  <summary>Details</summary>
Motivation: 神经网络，尤其是计算机视觉模型，能够检测并利用数据中意想不到的模式（即虚假关联），从而基于不正确或非预期的统计相关信号做出预测。这导致模型不可信、不可靠且泛化能力差，因此检测和缓解虚假关联对于构建值得信赖的模型至关重要。

Method: 本文提出了一种新颖的方法来检测视觉Transformer中的虚假关联。该方法在ImageNet数据集上对监督和自监督训练的模型进行了大规模实验。此外，还进行了一项关于侵入性乳腺肿块分类中虚假信号的案例研究。

Result: 所提出的方法能够成功识别视觉Transformer中的虚假关联。研究发现，即使使用相同的架构，训练方法也会显著影响模型对虚假关联的依赖。ImageNet数据集中某些类别包含容易被模型检测到的虚假信号，并且本文讨论了这些信号的潜在原因。作者还提供了一份包含上述图像的详尽列表。

Conclusion: 虚假关联是影响模型可靠性的重要问题。本文提出的方法能有效检测视觉Transformer中的虚假关联，且模型的训练方式对其依赖程度有显著影响。研究人员在使用ImageNet数据集中特定图像时应保持谨慎。研究工作还通过乳腺肿块分类案例研究与现实世界应用相结合。

Abstract: Due to their powerful feature association capabilities, neural network-based
computer vision models have the ability to detect and exploit unintended
patterns within the data, potentially leading to correct predictions based on
incorrect or unintended but statistically relevant signals. These clues may
vary from simple color aberrations to small texts within the image. In
situations where these unintended signals align with the predictive task,
models can mistakenly link these features with the task and rely on them for
making predictions. This phenomenon is referred to as spurious correlations,
where patterns appear to be associated with the task but are actually
coincidental. As a result, detection and mitigation of spurious correlations
have become crucial tasks for building trustworthy, reliable, and generalizable
machine learning models. In this work, we present a novel method to detect
spurious correlations in vision transformers, a type of neural network
architecture that gained significant popularity in recent years. Using both
supervised and self-supervised trained models, we present large-scale
experiments on the ImageNet dataset demonstrating the ability of the proposed
method to identify spurious correlations. We also find that, even if the same
architecture is used, the training methodology has a significant impact on the
model's reliance on spurious correlations. Furthermore, we show that certain
classes in the ImageNet dataset contain spurious signals that are easily
detected by the models and discuss the underlying reasons for those spurious
signals. In light of our findings, we provide an exhaustive list of the
aforementioned images and call for caution in their use in future research
efforts. Lastly, we present a case study investigating spurious signals in
invasive breast mass classification, grounding our work in real-world
scenarios.

</details>


### [75] [Learning from Majority Label: A Novel Problem in Multi-class Multiple-Instance Learning](https://arxiv.org/abs/2509.04023)
*Shiku Kaito,Shinnosuke Matsuo,Daiki Suehiro,Ryoma Bise*

Main category: cs.CV

TL;DR: 本文提出了一种名为“从多数标签学习”（LML）的多类别多示例学习（MIL）新问题，其目标是根据包内多数实例的类别标签来训练实例级分类模型。为解决LML问题，作者提出了一个计数网络（Counting Network）和一个多数比例增强模块（MPEM），并在实验中证明了其优于传统MIL方法的性能。


<details>
  <summary>Details</summary>
Motivation: LML问题在病理图像分割、政治投票预测、客户情感分析和环境监测等多种应用中具有重要价值，因此需要有效的方法来解决这一问题。

Method: 本文提出了一种计数网络（Counting Network），通过估计每个类别中实例的数量来生成包级的多数标签。此外，基于“高多数比例的包有利于学习”的发现，开发了一个多数比例增强模块（MPEM），通过移除包内的少数类别实例来增加多数类别的比例。

Result: 实验结果表明，所提出的方法在四个数据集上优于传统的MIL方法。消融研究证实了每个模块的有效性。分析实验还揭示了高多数比例的包能够促进学习。

Conclusion: LML是一个有价值的多类别多示例学习问题。本文提出的结合计数网络和多数比例增强模块的方法能够有效解决LML问题，并在实践中展现出卓越的性能。

Abstract: The paper proposes a novel multi-class Multiple-Instance Learning (MIL)
problem called Learning from Majority Label (LML). In LML, the majority class
of instances in a bag is assigned as the bag-level label. The goal of LML is to
train a classification model that estimates the class of each instance using
the majority label. This problem is valuable in a variety of applications,
including pathology image segmentation, political voting prediction, customer
sentiment analysis, and environmental monitoring. To solve LML, we propose a
Counting Network trained to produce bag-level majority labels, estimated by
counting the number of instances in each class. Furthermore, analysis
experiments on the characteristics of LML revealed that bags with a high
proportion of the majority class facilitate learning. Based on this result, we
developed a Majority Proportion Enhancement Module (MPEM) that increases the
proportion of the majority class by removing minority class instances within
the bags. Experiments demonstrate the superiority of the proposed method on
four datasets compared to conventional MIL methods. Moreover, ablation studies
confirmed the effectiveness of each module. The code is available at
\href{https://github.com/Shiku-Kaito/Learning-from-Majority-Label-A-Novel-Problem-in-Multi-class-Multiple-Instance-Learning}{here}.

</details>


### [76] [Millisecond-Response Tracking and Gazing System for UAVs: A Domestic Solution Based on "Phytium + Cambricon"](https://arxiv.org/abs/2509.04043)
*Yuchen Zhu,Longxiang Yin,Kai Zhao*

Main category: cs.CV

TL;DR: 本研究提出了一种基于飞腾处理器和寒武纪加速卡的异构计算架构，用于无人机跟踪与凝视系统，实现了毫秒级响应能力，并在低延迟和高精度方面取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统视频监控系统在动态场景中存在超过200毫秒的响应延迟，原因在于自动识别算法的深度特征提取能力不足和计算架构的效率瓶颈，无法满足复杂场景的实时性要求。

Method: 该研究在硬件层面采用了飞腾FT-2000/4处理器和MLU220加速卡协同计算架构，并通过多卡并行增强计算能力；在软件层面，创新性地将轻量级YOLOv5s检测网络与DeepSORT级联跟踪算法集成，形成了“检测-跟踪-反馈”的闭环控制链。

Result: 实验结果表明，该系统在1920*1080分辨率视频流处理中实现了50-100毫秒的稳定单帧综合处理延迟，多尺度目标识别精度超过98.5%，兼具低延迟和高精度。

Conclusion: 本研究为无人机监测和国产芯片的应用提供了一种创新性解决方案。

Abstract: In the frontier research and application of current video surveillance
technology, traditional camera systems exhibit significant limitations of
response delay exceeding 200 ms in dynamic scenarios due to the insufficient
deep feature extraction capability of automatic recognition algorithms and the
efficiency bottleneck of computing architectures, failing to meet the real-time
requirements in complex scenes. To address this issue, this study proposes a
heterogeneous computing architecture based on Phytium processors and Cambricon
accelerator cards, constructing a UAV tracking and gazing system with
millisecond-level response capability. At the hardware level, the system adopts
a collaborative computing architecture of Phytium FT-2000/4 processors and
MLU220 accelerator cards, enhancing computing power through multi-card
parallelism. At the software level, it innovatively integrates a lightweight
YOLOv5s detection network with a DeepSORT cascaded tracking algorithm, forming
a closed-loop control chain of "detection-tracking-feedback". Experimental
results demonstrate that the system achieves a stable single-frame
comprehensive processing delay of 50-100 ms in 1920*1080 resolution video
stream processing, with a multi-scale target recognition accuracy of over
98.5%, featuring both low latency and high precision. This study provides an
innovative solution for UAV monitoring and the application of domestic chips.

</details>


### [77] [A Re-ranking Method using K-nearest Weighted Fusion for Person Re-identification](https://arxiv.org/abs/2509.04050)
*Quang-Huy Che,Le-Chuong Nguyen,Gia-Nghia Tran,Dinh-Duy Phan,Vinh-Tiep Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种高效的、基于K-近邻加权融合（KWF）的重排序方法，通过无监督地聚合邻居特征来生成多视角特征，以减少视角偏差，显著提升行人重识别的准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 行人重识别中，单视角特征易受视角偏差、姿态变化、视角改变和遮挡等问题影响。使用多视角特征可以有效减少这些偏差，从而提升重排序的整体准确性。

Method: 该研究提出了一种高效的重排序方法，通过K-近邻加权融合（KWF）方法聚合邻居特征来生成多视角特征。核心假设是相同身份的特征高度相似，因此以无监督方式选择K个邻居特征进行聚合。此外，研究还探索了特征聚合过程中的权重选择策略。该方法无需模型微调或额外标注。

Result: 在Market1501、MSMT17和Occluded-DukeMTMC数据集上的评估显示，该方法在对初始排名前M位候选进行重排序时，显著提升了Rank@1和mAP。特别是在挑战性数据集MSMT17和Occluded-DukeMTMC上，Rank@1分别提升了9.8%和22.0%。与现有重排序方法相比，该方法在计算效率上也有显著提升。

Conclusion: 所提出的无监督KWF重排序方法通过生成多视角特征，有效解决了单视角特征的局限性，显著提高了行人重识别的准确性（Rank@1和mAP）和计算效率，尤其在复杂数据集上表现出色，且无需额外标注或模型微调，具有很高的实用价值。

Abstract: In person re-identification, re-ranking is a crucial step to enhance the
overall accuracy by refining the initial ranking of retrieved results. Previous
studies have mainly focused on features from single-view images, which can
cause view bias and issues like pose variation, viewpoint changes, and
occlusions. Using multi-view features to present a person can help reduce view
bias. In this work, we present an efficient re-ranking method that generates
multi-view features by aggregating neighbors' features using K-nearest Weighted
Fusion (KWF) method. Specifically, we hypothesize that features extracted from
re-identification models are highly similar when representing the same
identity. Thus, we select K neighboring features in an unsupervised manner to
generate multi-view features. Additionally, this study explores the weight
selection strategies during feature aggregation, allowing us to identify an
effective strategy. Our re-ranking approach does not require model fine-tuning
or extra annotations, making it applicable to large-scale datasets. We evaluate
our method on the person re-identification datasets Market1501, MSMT17, and
Occluded-DukeMTMC. The results show that our method significantly improves
Rank@1 and mAP when re-ranking the top M candidates from the initial ranking
results. Specifically, compared to the initial results, our re-ranking method
achieves improvements of 9.8%/22.0% in Rank@1 on the challenging datasets:
MSMT17 and Occluded-DukeMTMC, respectively. Furthermore, our approach
demonstrates substantial enhancements in computational efficiency compared to
other re-ranking methods.

</details>


### [78] [TEn-CATS: Text-Enriched Audio-Visual Video Parsing with Multi-Scale Category-Aware Temporal Graph](https://arxiv.org/abs/2509.04086)
*Yaru Chen,Faegheh Sardari,Peiliang Zhang,Ruohao Guo,Yang Xiang,Zhenbo Li,Wenwu Wang*

Main category: cs.CV

TL;DR: 本文提出一种结合双向文本融合（BiT）和类别感知时间图（CATS）模块的方法，用于弱监督音视频解析（AVVP），以解决现有方法中伪标签噪声和注意力扩散导致的错误放大问题，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有AVVP方法在处理弱监督标签时存在问题：(i) 基于注意力机制的架构将噪声分段级伪标签视为可靠监督；(ii) 生成丰富伪标签的方法让无差别的注意力将错误扩散到所有帧，导致训练过程中初始错误被反复放大。

Method: 提出结合双向文本融合（BiT）模块和类别感知时间图（CATS）模块。具体而言，BiT模块对音视频模态特征进行语义注入和动态校准，以定位和提纯更清晰、更丰富的语义线索。随后，CATS模块用于语义传播和连接，以实现精确的语义信息跨时间传播。

Result: 在LLP和UnAV-100两个基准数据集上，本文提出的方法在多个关键指标上取得了最先进（SOTA）的性能。

Conclusion: 通过结合语义提纯（BiT）和精确时间传播（CATS），本文方法有效解决了弱监督AVVP中错误放大的问题，显著提升了事件类别识别和时间定位的准确性，达到了SOTA水平。

Abstract: Audio-Visual Video Parsing (AVVP) task aims to identify event categories and
their occurrence times in a given video with weakly supervised labels. Existing
methods typically fall into two categories: (i) designing enhanced
architectures based on attention mechanism for better temporal modeling, and
(ii) generating richer pseudo-labels to compensate for the absence of
frame-level annotations. However, the first type methods treat noisy
segment-level pseudo labels as reliable supervision and the second type methods
let indiscriminate attention spread them across all frames, the initial errors
are repeatedly amplified during training. To address this issue, we propose a
method that combines the Bi-Directional Text Fusion (BiT) module and
Category-Aware Temporal Graph (CATS) module. Specifically, we integrate the
strengths and complementarity of the two previous research directions. We first
perform semantic injection and dynamic calibration on audio and visual modality
features through the BiT module, to locate and purify cleaner and richer
semantic cues. Then, we leverage the CATS module for semantic propagation and
connection to enable precise semantic information dissemination across time.
Experimental results demonstrate that our proposed method achieves
state-of-the-art (SOTA) performance in multiple key indicators on two benchmark
datasets, LLP and UnAV-100.

</details>


### [79] [TriLiteNet: Lightweight Model for Multi-Task Visual Perception](https://arxiv.org/abs/2509.04092)
*Quang-Huy Che,Duc-Khai Lam*

Main category: cs.CV

TL;DR: 本文提出TriLiteNet模型，这是一个轻量级多任务感知模型，专为ADAS设计，能在低计算成本下同时处理车辆检测、可行驶区域分割和车道线分割任务，并在嵌入式设备上表现出低延迟和合理功耗。


<details>
  <summary>Details</summary>
Motivation: 高级驾驶辅助系统（ADAS）需要高效的感知模型，以实现快速处理和响应，确保在真实世界环境中的安全性和有效性，从而满足实时执行的需求。

Method: 研究引入了TriLiteNet模型，该模型旨在同时管理全景驾驶感知相关的多项任务，并优化性能同时保持低计算成本。模型提供了不同配置，包括一个参数极少的微型版本。通过在BDD100k数据集上进行实验评估，并测试其在嵌入式设备上的延迟和功耗。

Result: TriLiteNet_base模型在BDD100k数据集上实现了车辆检测召回率85.6%、可行驶区域分割mIoU 92.4%和车道线分割准确率82.3%，仅需2.35M参数和7.72 GFLOPs。此外，模型还提供了一个仅有0.14M参数的微型配置。两种配置的TriLiteNet模型在嵌入式设备上均表现出低延迟和合理的推理功耗。

Conclusion: TriLiteNet通过平衡性能、计算效率和可扩展性，为真实世界的自动驾驶应用提供了一个实用且可部署的解决方案。

Abstract: Efficient perception models are essential for Advanced Driver Assistance
Systems (ADAS), as these applications require rapid processing and response to
ensure safety and effectiveness in real-world environments. To address the
real-time execution needs of such perception models, this study introduces the
TriLiteNet model. This model can simultaneously manage multiple tasks related
to panoramic driving perception. TriLiteNet is designed to optimize performance
while maintaining low computational costs. Experimental results on the BDD100k
dataset demonstrate that the model achieves competitive performance across
three key tasks: vehicle detection, drivable area segmentation, and lane line
segmentation. Specifically, the TriLiteNet_{base} demonstrated a recall of
85.6% for vehicle detection, a mean Intersection over Union (mIoU) of 92.4% for
drivable area segmentation, and an Acc of 82.3% for lane line segmentation with
only 2.35M parameters and a computational cost of 7.72 GFLOPs. Our proposed
model includes a tiny configuration with just 0.14M parameters, which provides
a multi-task solution with minimal computational demand. Evaluated for latency
and power consumption on embedded devices, TriLiteNet in both configurations
shows low latency and reasonable power during inference. By balancing
performance, computational efficiency, and scalability, TriLiteNet offers a
practical and deployable solution for real-world autonomous driving
applications. Code is available at https://github.com/chequanghuy/TriLiteNet.

</details>


### [80] [DVS-PedX: Synthetic-and-Real Event-Based Pedestrian Dataset](https://arxiv.org/abs/2509.04117)
*Mustafa Sakhai,Kaung Sithu,Min Khant Soe Oke,Maciej Wielgosz*

Main category: cs.CV

TL;DR: DVS-PedX是一个新颖的神经形态数据集，专为事件相机在正常和恶劣天气下进行行人检测和过街意图分析而设计，包含合成和真实世界事件流，并提供了基线SNN结果。


<details>
  <summary>Details</summary>
Motivation: 事件相机（如DVS）具有低延迟、高动态范围和运动鲁棒性等优势，但缺乏专门的神经形态数据集来研究行人安全和意图预测，尤其是在应对恶劣天气和模拟到真实场景差距方面。

Method: 该研究构建了DVS-PedX数据集，包含两个互补来源：1) 在CARLA模拟器中生成的合成事件流，用于受控的“接近-穿越”场景，涵盖不同天气和光照条件；2) 将真实的JAAD行车记录仪视频通过v2e工具转换为事件流，保留自然行为和背景。数据集提供配对的RGB帧、DVS“事件帧”（33毫秒累积）、帧级标签（过街与否）、原始AEDAT文件和元数据。使用SpikingJelly的基线脉冲神经网络（SNNs）来演示数据集的可用性。

Result: 基线SNNs验证了数据集的可用性，并揭示了明显的模拟到真实场景（sim-to-real）差距，这激励了领域适应和多模态融合的研究。

Conclusion: DVS-PedX数据集旨在加速基于事件的行人安全、意图预测和神经形态感知领域的研究，并为解决模拟到真实场景的差距和多模态融合提供了研究方向。

Abstract: Event cameras like Dynamic Vision Sensors (DVS) report micro-timed brightness
changes instead of full frames, offering low latency, high dynamic range, and
motion robustness. DVS-PedX (Dynamic Vision Sensor Pedestrian eXploration) is a
neuromorphic dataset designed for pedestrian detection and crossing-intention
analysis in normal and adverse weather conditions across two complementary
sources: (1) synthetic event streams generated in the CARLA simulator for
controlled "approach-cross" scenes under varied weather and lighting; and (2)
real-world JAAD dash-cam videos converted to event streams using the v2e tool,
preserving natural behaviors and backgrounds. Each sequence includes paired RGB
frames, per-frame DVS "event frames" (33 ms accumulations), and frame-level
labels (crossing vs. not crossing). We also provide raw AEDAT 2.0/AEDAT 4.0
event files and AVI DVS video files and metadata for flexible re-processing.
Baseline spiking neural networks (SNNs) using SpikingJelly illustrate dataset
usability and reveal a sim-to-real gap, motivating domain adaptation and
multimodal fusion. DVS-PedX aims to accelerate research in event-based
pedestrian safety, intention prediction, and neuromorphic perception.

</details>


### [81] [TaleDiffusion: Multi-Character Story Generation with Dialogue Rendering](https://arxiv.org/abs/2509.04123)
*Ayan Banerjee,Josep Lladós,Umapada Pal,Anjan Dutta*

Main category: cs.CV

TL;DR: TaleDiffusion是一个新颖的框架，通过迭代过程、身份一致性自注意力机制和准确的对话分配，解决了多角色文本到故事可视化中角色一致性和对话渲染的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多角色文本到故事可视化中难以保持角色一致性，导致图像伪影、对话渲染不准确和故事叙述脱节。

Method: TaleDiffusion框架采用迭代过程：首先使用预训练LLM通过上下文学习生成每帧描述、角色细节和对话；接着，利用基于边界注意力机制的逐框掩码技术控制角色互动并减少伪影；然后，应用身份一致性自注意力机制确保跨帧角色一致性，并结合区域感知交叉注意力进行精确物体放置；最后，通过CLIPSeg将对话渲染为气泡并分配给相应角色。

Result: 实验结果表明，TaleDiffusion在一致性、噪声消除和对话渲染方面均优于现有方法。

Conclusion: TaleDiffusion成功地解决了多角色故事可视化中的关键挑战，实现了跨帧的角色一致性、减少了伪影并准确渲染了对话，从而生成了更连贯的故事视觉内容。

Abstract: Text-to-story visualization is challenging due to the need for consistent
interaction among multiple characters across frames. Existing methods struggle
with character consistency, leading to artifact generation and inaccurate
dialogue rendering, which results in disjointed storytelling. In response, we
introduce TaleDiffusion, a novel framework for generating multi-character
stories with an iterative process, maintaining character consistency, and
accurate dialogue assignment via postprocessing. Given a story, we use a
pre-trained LLM to generate per-frame descriptions, character details, and
dialogues via in-context learning, followed by a bounded attention-based
per-box mask technique to control character interactions and minimize
artifacts. We then apply an identity-consistent self-attention mechanism to
ensure character consistency across frames and region-aware cross-attention for
precise object placement. Dialogues are also rendered as bubbles and assigned
to characters via CLIPSeg. Experimental results demonstrate that TaleDiffusion
outperforms existing methods in consistency, noise reduction, and dialogue
rendering.

</details>


### [82] [MEPG:Multi-Expert Planning and Generation for Compositionally-Rich Image Generation](https://arxiv.org/abs/2509.04126)
*Yuan Zhao,Liu Lin*

Main category: cs.CV

TL;DR: 本文提出了一种名为MEPG的多专家规划与生成框架，通过结合位置和风格感知的LLM与空间语义专家模块，显著提升了文本到图像扩散模型处理复杂多元素提示的能力以及风格多样性。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在处理复杂、多元素的提示时表现不佳，并且风格多样性有限。

Method: 该框架包含两个核心组件：1) 位置-风格感知（PSA）模块，利用经过监督微调的LLM将输入提示分解为精确的空间坐标和风格编码的语义指令；2) 多专家扩散（MED）模块，通过跨局部区域和全局区域的动态专家路由实现跨区域生成。在生成过程中，特定区域的专业模型（如写实专家、风格化专家）通过基于注意力的门控机制被选择性激活。此外，该架构支持专家模型的轻量级集成和替换，并提供一个交互式界面以进行实时空间布局编辑和按区域风格选择。

Result: 实验表明，MEPG在图像质量和风格多样性方面均显著优于使用相同骨干网络的基线模型。

Conclusion: MEPG框架通过其独特的多专家规划与生成机制，有效解决了现有文本到图像模型在处理复杂提示和实现风格多样性方面的局限性，并展现出强大的可扩展性和交互性。

Abstract: Text-to-image diffusion models have achieved remarkable image quality, but
they still struggle with complex, multiele ment prompts, and limited stylistic
diversity. To address these limitations, we propose a Multi-Expert Planning and
Gen eration Framework (MEPG) that synergistically integrates position- and
style-aware large language models (LLMs) with spatial-semantic expert modules.
The framework comprises two core components: (1) a Position-Style-Aware (PSA)
module that utilizes a supervised fine-tuned LLM to decom pose input prompts
into precise spatial coordinates and style encoded semantic instructions; and
(2) a Multi-Expert Dif fusion (MED) module that implements cross-region genera
tion through dynamic expert routing across both local regions and global areas.
During the generation process for each lo cal region, specialized models (e.g.,
realism experts, styliza tion specialists) are selectively activated for each
spatial par tition via attention-based gating mechanisms. The architec ture
supports lightweight integration and replacement of ex pert models, providing
strong extensibility. Additionally, an interactive interface enables real-time
spatial layout editing and per-region style selection from a portfolio of
experts. Ex periments show that MEPG significantly outperforms base line models
with the same backbone in both image quality
  and style diversity.

</details>


### [83] [VisioFirm: Cross-Platform AI-assisted Annotation Tool for Computer Vision](https://arxiv.org/abs/2509.04180)
*Safouane El Ghazouali,Umberto Michelucci*

Main category: cs.CV

TL;DR: VisioFirm是一个开源的AI辅助图像标注Web应用，它结合了前沿的基础模型和交互式工具，旨在大幅减少人工标注工作量，提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: AI模型依赖于大量的标注数据进行学习和预测，但传统标注工具需要大量手动输入，导致标注过程劳动密集且难以扩展到大型数据集。

Method: VisioFirm采用混合AI辅助方法：集成CLIP、Ultralytics预训练检测器和Grounding DINO等零样本模型生成初始标注（采用低置信度阈值以最大化召回率）。它提供交互式工具（如边界框、定向边界框、多边形）供用户精修。此外，它利用WebGPU加速的Segment Anything实现浏览器端实时分割，并通过基于CLIP的组件聚类和IoU图抑制冗余检测来保持准确性。该工具支持YOLO、COCO、Pascal VOC、CSV等多种导出格式，并可在模型缓存后离线运行。

Result: 在COCO类型类别上，初始预测被证明大部分是正确的。VisioFirm在不同数据集的基准测试中，将人工工作量减少了高达90%，同时通过智能过滤和冗余抑制保持了高标注准确性。

Conclusion: VisioFirm通过AI辅助自动化显著简化了图像标注过程，大幅减少了所需的人工工作量，并能保持高标注准确性，为AI数据标注提供了一个可扩展且高效的解决方案。

Abstract: AI models rely on annotated data to learn pattern and perform prediction.
Annotation is usually a labor-intensive step that require associating labels
ranging from a simple classification label to more complex tasks such as object
detection, oriented bounding box estimation, and instance segmentation.
Traditional tools often require extensive manual input, limiting scalability
for large datasets. To address this, we introduce VisioFirm, an open-source web
application designed to streamline image labeling through AI-assisted
automation. VisioFirm integrates state-of-the-art foundation models into an
interface with a filtering pipeline to reduce human-in-the-loop efforts. This
hybrid approach employs CLIP combined with pre-trained detectors like
Ultralytics models for common classes and zero-shot models such as Grounding
DINO for custom labels, generating initial annotations with low-confidence
thresholding to maximize recall. Through this framework, when tested on
COCO-type of classes, initial prediction have been proven to be mostly correct
though the users can refine these via interactive tools supporting bounding
boxes, oriented bounding boxes, and polygons. Additionally, VisioFirm has
on-the-fly segmentation powered by Segment Anything accelerated through WebGPU
for browser-side efficiency. The tool supports multiple export formats (YOLO,
COCO, Pascal VOC, CSV) and operates offline after model caching, enhancing
accessibility. VisioFirm demonstrates up to 90\% reduction in manual effort
through benchmarks on diverse datasets, while maintaining high annotation
accuracy via clustering of connected CLIP-based disambiguate components and
IoU-graph for redundant detection suppression. VisioFirm can be accessed from
\href{https://github.com/OschAI/VisioFirm}{https://github.com/OschAI/VisioFirm}.

</details>


### [84] [Revisiting Simple Baselines for In-The-Wild Deepfake Detection](https://arxiv.org/abs/2509.04150)
*Orlando Castaneda,Kevin So-Tang,Kshitij Gurung*

Main category: cs.CV

TL;DR: 研究表明，通过优化超参数，一个简单的开源深度伪造检测器在“in-the-wild”基准测试Deepfake-Eval-2024上的准确率可达81%，与领先的商业检测器相当，显著超越了其先前的报告性能。


<details>
  <summary>Details</summary>
Motivation: 合成媒体的广泛应用需要易于获取的深度伪造检测器和真实的基准测试。现有研究多在高度受控数据集上评估，而新发布的“in-the-wild”基准Deepfake-Eval-2024显示，开源模型表现远低于商业检测器（61%-69% vs 82%）。

Method: 重新审视了Ojha等人提出的基线方法，该方法通过调整标准预训练视觉骨干网络来生成可泛化的深度伪造检测器。核心改进在于通过更好地调整超参数来优化性能。

Result: 经过优化超参数后，该简单方法在Deepfake-Eval-2024上达到了81%的准确率，比之前报告的基线方法性能提高了18%，并与商业深度伪造检测器（82%）具有竞争力。论文还讨论了准确性、计算成本和可解释性方面的权衡。

Conclusion: 一个简单的、基于预训练视觉骨干网络的开源方法，通过精细的超参数调优，可以在实际部署场景中提供高度实用且有效的深度伪造检测能力，其性能足以与商业解决方案竞争。

Abstract: The widespread adoption of synthetic media demands accessible deepfake
detectors and realistic benchmarks. While most existing research evaluates
deepfake detectors on highly controlled datasets, we focus on the recently
released "in-the-wild" benchmark, Deepfake-Eval-2024. Initial reporting on
Deepfake-Eval-2024 showed that three finetuned open-source models achieve
accuracies between 61% and 69%, significantly lagging behind the leading
commercial deepfake detector with 82% accuracy. Our work revisits one of these
baseline approaches, originally introduced by Ojha et al., which adapts
standard pretrained vision backbones to produce generalizable deepfake
detectors. We demonstrate that with better-tuned hyperparameters, this simple
approach actually yields much higher performance -- 81% accuracy on
Deepfake-Eval-2024 -- surpassing the previously reported accuracy of this
baseline approach by 18% and competing with commercial deepfake detectors. We
discuss tradeoffs in accuracy, computational costs, and interpretability,
focusing on how practical these deepfake detectors might be when deployed in
real-world settings. Our code can be found at
https://github.com/Deepfake-Detection-KKO/deepfake-detection.

</details>


### [85] [DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval](https://arxiv.org/abs/2509.04193)
*Ruohong Yang,Peng Hu,Yunfan Li,Xi Peng*

Main category: cs.CV

TL;DR: DUDE是一种无监督跨域图像检索（UCIR）方法，通过利用文本到图像生成模型解耦对象特征与领域特定风格，并渐进式对齐域内和跨域的互近邻，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的UCIR方法在对齐整个图像的跨域特征时，对象特征常与领域特定风格纠缠，导致难以克服领域差距。

Method: DUDE方法基于特征解耦。它利用文本到图像生成模型将对象特征从领域特定风格中解耦出来，以促进语义图像检索。为进一步实现解耦对象特征的可靠对齐，DUDE以渐进方式对齐域内到跨域的互近邻。

Result: DUDE在三个基准数据集（涵盖13个领域）上取得了最先进的性能。

Conclusion: DUDE通过特征解耦和渐进式互近邻对齐，有效解决了无监督跨域图像检索中的领域差距问题，并取得了显著的性能提升。

Abstract: Unsupervised cross-domain image retrieval (UCIR) aims to retrieve images of
the same category across diverse domains without relying on annotations.
Existing UCIR methods, which align cross-domain features for the entire image,
often struggle with the domain gap, as the object features critical for
retrieval are frequently entangled with domain-specific styles. To address this
challenge, we propose DUDE, a novel UCIR method building upon feature
disentanglement. In brief, DUDE leverages a text-to-image generative model to
disentangle object features from domain-specific styles, thus facilitating
semantical image retrieval. To further achieve reliable alignment of the
disentangled object features, DUDE aligns mutual neighbors from within domains
to across domains in a progressive manner. Extensive experiments demonstrate
that DUDE achieves state-of-the-art performance across three benchmark datasets
over 13 domains. The code will be released.

</details>


### [86] [Learning Active Perception via Self-Evolving Preference Optimization for GUI Grounding](https://arxiv.org/abs/2509.04243)
*Wanfu Wang,Qipeng Huang,Guangquan Xue,Xiaobo Liang,Juntao Li*

Main category: cs.CV

TL;DR: 本文提出了LASER，一个自演进框架，通过结合蒙特卡洛质量估计和IoU评估，赋予视觉语言模型（VLMs）多步感知能力，以实现精确的坐标预测，从而改进GUI接地任务中的区域推理，并在基准测试中达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管最新的VLM（如OpenAI o3模型）引入了“放大搜索”策略以提升感知能力，但在高分辨率输入和复杂多元素视觉交互下，VLM在GUI接地任务中仍难以有效地对适当图像区域进行推理，精确的区域感知仍然是一个核心挑战。

Method: 本文提出了LASER框架，一个自演进的多步感知框架，旨在实现精确的坐标预测。具体而言，该方法将蒙特卡洛质量估计与基于IoU的区域质量评估相结合，共同鼓励在构建高质量偏好数据时兼顾准确性和多样性。这种组合明确指导模型关注指令相关的关键区域，并根据任务复杂性自适应地分配推理步骤。

Result: 在ScreenSpot Pro和ScreenSpot-v2基准测试上进行的综合实验表明，该方法取得了持续的性能提升，验证了其有效性。此外，当在GTA1-7B上进行微调时，LASER在ScreenSpot-Pro基准测试中取得了55.7分，在7B规模模型中建立了新的最先进（SoTA）水平。

Conclusion: LASER框架通过其自演进的多步感知能力，显著提升了VLMs在GUI接地任务中对复杂高分辨率输入的区域推理和坐标预测精度，并在现有基准测试中取得了领先的性能，证明了其在增强VLM主动感知方面的有效性。

Abstract: Vision Language Models (VLMs) have recently achieved significant progress in
bridging visual perception and linguistic reasoning. Recently, OpenAI o3 model
introduced a zoom-in search strategy that effectively elicits active perception
capabilities in VLMs, improving downstream task performance. However, enabling
VLMs to reason effectively over appropriate image regions remains a core
challenge in GUI grounding, particularly under high-resolution inputs and
complex multi-element visual interactions. In this work, we propose LASER, a
self-evolving framework that progressively endows VLMs with multi-step
perception capabilities, enabling precise coordinate prediction. Specifically,
our approach integrate Monte Carlo quality estimation with
Intersection-over-Union (IoU)-based region quality evaluation to jointly
encourage both accuracy and diversity in constructing high-quality preference
data. This combination explicitly guides the model to focus on
instruction-relevant key regions while adaptively allocating reasoning steps
based on task complexity. Comprehensive experiments on the ScreenSpot Pro and
ScreenSpot-v2 benchmarks demonstrate consistent performance gains, validating
the effectiveness of our method. Furthermore, when fine-tuned on GTA1-7B, LASER
achieves a score of 55.7 on the ScreenSpot-Pro benchmark, establishing a new
state-of-the-art (SoTA) among 7B-scale models.

</details>


### [87] [Differential Morphological Profile Neural Networks for Semantic Segmentation](https://arxiv.org/abs/2509.04268)
*David Huangal,J. Alex Hurt*

Main category: cs.CV

TL;DR: 本文探索将差分形态学剖面（DMP）整合到现代语义分割网络中，以解决遥感图像的特殊挑战，并发现混合DMP架构能有效提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的分割网络主要针对地面视角照片开发，难以直接应对遥感图像中的极端尺度变化、前景-背景不平衡及大图像尺寸等挑战。DMP已被证明能为深度神经网络提供关键形状信息，从而提高航空图像的检测和分类性能。

Method: 将差分形态学剖面（DMP）特征整合到三种先进的卷积和Transformer语义分割架构中。采用两种整合方式：1) 直接输入，即调整特征提取架构的输入，使其接受DMP通道；2) 混合架构，采用双流设计融合RGB和DMP编码器。使用iSAID基准数据集，评估了不同DMP差分和结构元素形状的效果。

Result: 非DMP模型通常优于直接输入DMP的变体。然而，混合DMP架构持续优于直接输入DMP，并且在mIoU、F1和Recall指标上能够超越非DMP模型。

Conclusion: 将DMP特征集成到语义分割网络中，特别是通过混合双流架构，可以有效提升遥感图像的分割性能，克服了为地面视角图像设计的网络所面临的挑战。

Abstract: Semantic segmentation of overhead remote sensing imagery enables applications
in mapping, urban planning, and disaster response. State-of-the-art
segmentation networks are typically developed and tuned on ground-perspective
photographs and do not directly address remote sensing challenges such as
extreme scale variation, foreground-background imbalance, and large image
sizes. We explore the incorporation of the differential morphological profile
(DMP), a multi-scale shape extraction method based on grayscale morphology,
into modern segmentation networks. Prior studies have shown that the DMP can
provide critical shape information to Deep Neural Networks to enable superior
detection and classification performance in overhead imagery. In this work, we
extend prior DMPNet work beyond classification and object detection by
integrating DMP features into three state-of-the-art convolutional and
transformer semantic segmentation architectures. We utilize both direct input,
which adapts the input stem of feature extraction architectures to accept DMP
channels, and hybrid architectures, a dual-stream design that fuses RGB and DMP
encoders. Using the iSAID benchmark dataset, we evaluate a variety of DMP
differentials and structuring element shapes to more effectively provide shape
information to the model. Our results show that while non-DMP models generally
outperform the direct-input variants, hybrid DMP consistently outperforms
direct-input and is capable of surpassing a non-DMP model on mIoU, F1, and
Recall.

</details>


### [88] [TauGenNet: Plasma-Driven Tau PET Image Synthesis via Text-Guided 3D Diffusion Models](https://arxiv.org/abs/2509.04269)
*Yuxin Gong,Se-in Jang,Wei Shao,Yi Su,Kuang Gong*

Main category: cs.CV

TL;DR: 本文提出了一种文本引导的3D扩散模型，利用结构MRI和血浆p-tau217测量（作为文本提示）来合成3D tau PET图像，以应对tau PET成本高昂和可用性有限的问题。


<details>
  <summary>Details</summary>
Motivation: Tau PET扫描在诊断和监测阿尔茨海默病(AD)方面至关重要，但其高成本和有限的可用性限制了广泛应用。相比之下，结构MRI和血浆生物标志物是非侵入性且广泛可用的，可以提供脑解剖和疾病进展信息。

Method: 研究者提出了一种文本引导的3D扩散模型，用于合成3D tau PET图像。该模型利用多模态条件：结构MRI提供解剖结构约束，血浆p-tau217测量（AD进展的关键指标）作为文本提示。该框架使用ADNI数据库中的临床AV1451 tau PET数据进行训练和评估。

Result: 实验结果表明，该方法能够生成逼真且具有临床意义的3D tau PET图像，涵盖了不同疾病阶段。

Conclusion: 所提出的框架可以帮助在不同设置下进行tau PET数据增强，提供一种非侵入性、经济高效的替代方案来可视化tau病理，并支持在不同血浆生物标志物水平和认知条件下模拟疾病进展。

Abstract: Accurate quantification of tau pathology via tau positron emission tomography
(PET) scan is crucial for diagnosing and monitoring Alzheimer's disease (AD).
However, the high cost and limited availability of tau PET restrict its
widespread use. In contrast, structural magnetic resonance imaging (MRI) and
plasma-based biomarkers provide non-invasive and widely available complementary
information related to brain anatomy and disease progression. In this work, we
propose a text-guided 3D diffusion model for 3D tau PET image synthesis,
leveraging multimodal conditions from both structural MRI and plasma
measurement. Specifically, the textual prompt is from the plasma p-tau217
measurement, which is a key indicator of AD progression, while MRI provides
anatomical structure constraints. The proposed framework is trained and
evaluated using clinical AV1451 tau PET data from the Alzheimer's Disease
Neuroimaging Initiative (ADNI) database. Experimental results demonstrate that
our approach can generate realistic, clinically meaningful 3D tau PET across a
range of disease stages. The proposed framework can help perform tau PET data
augmentation under different settings, provide a non-invasive, cost-effective
alternative for visualizing tau pathology, and support the simulation of
disease progression under varying plasma biomarker levels and cognitive
conditions.

</details>


### [89] [From Editor to Dense Geometry Estimator](https://arxiv.org/abs/2509.04338)
*JiYuan Wang,Chunyu Lin,Lei Sun,Rongying Liu,Lang Nie,Mingxing Li,Kang Liao,Xiangxiang Chu,Yao Zhao*

Main category: cs.CV

TL;DR: 该研究提出FE2E框架，开创性地将基于Diffusion Transformer (DiT) 架构的图像编辑模型应用于密集几何估计，通过改进的训练目标和精度处理，显著超越了基于文生图模型的方法，并在零样本深度和法线估计任务中取得了卓越性能。


<details>
  <summary>Details</summary>
Motivation: 当前密集预测任务常利用预训练的文生图（T2I）生成模型，但密集预测本质上是图生图任务。研究者认为图像编辑模型可能比文生图模型更适合作为微调的基础，因为它们可能具有固有的结构先验。

Method: 1. 系统性分析了编辑模型和生成模型在密集几何估计任务中的微调行为。2. 引入FE2E框架，首次将先进的基于Diffusion Transformer (DiT) 架构的编辑模型用于密集几何预测。3. 将编辑模型原始的流匹配损失重新表述为“一致速度”训练目标。4. 使用对数量化来解决编辑模型原生BFloat16格式与任务所需高精度之间的冲突。5. 利用DiT的全局注意力机制，实现深度和法线在单次前向传播中的无成本联合估计，使监督信号相互增强。

Result: 1. 研究发现编辑模型具有固有的结构先验，使其能够更稳定地收敛，并通过“提炼”其内在特征，最终比生成模型实现更高的性能。2. FE2E在不增加训练数据的情况下，在多个数据集上的零样本单目深度和法线估计中取得了显著的性能提升。3. 在ETH3D数据集上实现了超过35%的性能提升。4. 性能超越了训练数据量是其100倍的DepthAnything系列模型。

Conclusion: 图像编辑模型，尤其是通过FE2E框架进行适应性改造后，比文生图生成模型更适合密集几何估计任务，因为它们具有固有的结构先验。FE2E通过创新的损失函数、精度处理和联合估计策略，在零样本密集几何预测中取得了SOTA性能，证明了编辑模型在图生图任务中的巨大潜力。

Abstract: Leveraging visual priors from pre-trained text-to-image (T2I) generative
models has shown success in dense prediction. However, dense prediction is
inherently an image-to-image task, suggesting that image editing models, rather
than T2I generative models, may be a more suitable foundation for fine-tuning.
  Motivated by this, we conduct a systematic analysis of the fine-tuning
behaviors of both editors and generators for dense geometry estimation. Our
findings show that editing models possess inherent structural priors, which
enable them to converge more stably by ``refining" their innate features, and
ultimately achieve higher performance than their generative counterparts.
  Based on these findings, we introduce \textbf{FE2E}, a framework that
pioneeringly adapts an advanced editing model based on Diffusion Transformer
(DiT) architecture for dense geometry prediction. Specifically, to tailor the
editor for this deterministic task, we reformulate the editor's original flow
matching loss into the ``consistent velocity" training objective. And we use
logarithmic quantization to resolve the precision conflict between the editor's
native BFloat16 format and the high precision demand of our tasks.
Additionally, we leverage the DiT's global attention for a cost-free joint
estimation of depth and normals in a single forward pass, enabling their
supervisory signals to mutually enhance each other.
  Without scaling up the training data, FE2E achieves impressive performance
improvements in zero-shot monocular depth and normal estimation across multiple
datasets. Notably, it achieves over 35\% performance gains on the ETH3D dataset
and outperforms the DepthAnything series, which is trained on 100$\times$ data.
The project page can be accessed \href{https://amap-ml.github.io/FE2E/}{here}.

</details>


### [90] [Dual-Scale Volume Priors with Wasserstein-Based Consistency for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2509.04273)
*Junying Meng,Gangxuan Zhou,Jun Liu,Weihong Guo*

Main category: cs.CV

TL;DR: 本文提出了一种半监督医学图像分割框架，通过有效整合变分模型中的空间正则化方法和体素先验信息，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督医学图像分割网络在特征提取的方法指导和利用数据集中的重要先验信息方面存在不足。

Method: 该方法将强显式图像尺度体素先验和阈值动力学空间正则化（均源于变分模型）整合到骨干分割网络中。通过回归网络估计未标记图像的目标区域体素，并使用图像尺度Wasserstein距离约束进行正则化。此外，还设计了一个基于弱隐式体素先验的数据集尺度Wasserstein距离损失函数，以确保未标记数据集的体素分布与已标记数据集相似。

Result: 在2017 ACDC数据集、PROMISE12数据集和股部肌肉MR图像数据集上的实验结果表明，所提出的方法具有优越性。

Conclusion: 该研究开发了一个有效的半监督医学图像分割框架，成功整合了空间正则化方法和体素先验信息，显著提升了分割性能。

Abstract: Despite signi cant progress in semi-supervised medical image segmentation,
most existing segmentation networks overlook e ective methodological guidance
for feature extraction and important prior information from
  datasets. In this paper, we develop a semi-supervised medical image
segmentation framework that e ectively integrates spatial regularization
methods and volume priors. Speci cally, our approach integrates a strong
explicit volume prior at the image scale and Threshold Dynamics spatial
regularization, both derived from variational models, into the backbone
segmentation network. The target region volumes for each unlabeled image are
estimated by a regression network, which e ectively regularizes the backbone
segmentation network through an image-scale Wasserstein distance constraint,
ensuring that the class ratios in the segmentation results for each unlabeled
image match those predicted by the regression network. Additionally, we design
a dataset-scale Wasserstein distance loss function based on a weak implicit
volume prior, which enforces that the volume distribution predicted for the
unlabeled dataset is similar to that of labeled dataset. Experimental results
on the 2017 ACDC dataset, PROMISE12 dataset, and thigh muscle MR image dataset
show the superiority of the proposed method.

</details>


### [91] [SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer](https://arxiv.org/abs/2509.04379)
*Jimin Xu,Bosheng Qin,Tao Jin,Zhou Zhao,Zhenhui Ye,Jun Yu,Fei Wu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的3D风格迁移方法，通过整合预训练的2D扩散模型先验知识，解决了现有方法在高级风格语义提取和结构清晰度方面的不足，实现了更具结构化、视觉连贯性和艺术性的3D场景风格化。


<details>
  <summary>Details</summary>
Motivation: 现有的3D风格迁移方法（如基于神经辐射场和3D高斯泼溅）难以有效提取和迁移参考风格图像中的高级风格语义，并且风格化结果缺乏结构清晰度和实例分离性，难以区分3D场景中的不同对象。

Method: 该方法包含两个主要阶段：首先，利用扩散先验生成关键视角的风格化渲染图；然后，将这些风格化的关键视图迁移到3D表示上。其中包含两项创新设计：1) 跨视图风格对齐，在UNet的最后一个上采样块中引入跨视图注意力，确保生成风格保真和实例级别一致的关键视图；2) 实例级别风格迁移，利用风格化关键视图间的实例级别一致性，将其迁移到3D表示上。

Result: 广泛的定性和定量实验表明，该3D风格迁移管线在各种场景（从前向视图到具有挑战性的360度环境）中显著优于现有最先进的方法，产生了更具结构化、视觉连贯和艺术丰富性的风格化效果。

Conclusion: 本文提出的3D风格迁移管线通过有效整合2D扩散模型的先验知识，成功解决了现有方法在高级风格语义提取和结构清晰度方面的局限性，实现了卓越的3D场景风格化，提供了更结构化、视觉连贯且艺术性强的风格化结果。

Abstract: Recent advancements in neural representations, such as Neural Radiance Fields
and 3D Gaussian Splatting, have increased interest in applying style transfer
to 3D scenes. While existing methods can transfer style patterns onto
3D-consistent neural representations, they struggle to effectively extract and
transfer high-level style semantics from the reference style image.
Additionally, the stylized results often lack structural clarity and
separation, making it difficult to distinguish between different instances or
objects within the 3D scene. To address these limitations, we propose a novel
3D style transfer pipeline that effectively integrates prior knowledge from
pretrained 2D diffusion models. Our pipeline consists of two key stages: First,
we leverage diffusion priors to generate stylized renderings of key viewpoints.
Then, we transfer the stylized key views onto the 3D representation. This
process incorporates two innovative designs. The first is cross-view style
alignment, which inserts cross-view attention into the last upsampling block of
the UNet, allowing feature interactions across multiple key views. This ensures
that the diffusion model generates stylized key views that maintain both style
fidelity and instance-level consistency. The second is instance-level style
transfer, which effectively leverages instance-level consistency across
stylized key views and transfers it onto the 3D representation. This results in
a more structured, visually coherent, and artistically enriched stylization.
Extensive qualitative and quantitative experiments demonstrate that our 3D
style transfer pipeline significantly outperforms state-of-the-art methods
across a wide range of scenes, from forward-facing to challenging 360-degree
environments. Visit our project page https://jm-xu.github.io/SSGaussian for
immersive visualization.

</details>


### [92] [PAOLI: Pose-free Articulated Object Learning from Sparse-view Images](https://arxiv.org/abs/2509.04276)
*Jianning Deng,Kartic Subr,Hakan Bilen*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的自监督框架，用于从稀疏、未摆姿态的图像中学习可变形物体的表示，显著降低了输入要求。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要密集的视角观测和地面真实相机姿态，而本研究旨在仅使用少量（例如四个）视角且无需相机监督的情况下，学习可变形物体表示。

Method: 该方法首先利用稀疏视角3D重建技术独立重建每个姿态，然后学习一个变形场以建立跨姿态的密集对应关系。接着，采用渐进式解耦策略分离静态和运动部分（相机与物体运动），最后通过自监督损失（强制跨视角和跨姿态一致性）联合优化几何、外观和运动学。

Result: 实验表明，该方法在标准基准和真实世界示例上，能在比现有方法弱得多的输入假设下，生成准确且详细的可变形物体表示。

Conclusion: 该框架成功地在极少输入（稀疏、未摆姿态图像）的情况下，学习了精确的可变形物体表示，克服了现有方法的局限性。

Abstract: We present a novel self-supervised framework for learning articulated object
representations from sparse-view, unposed images. Unlike prior methods that
require dense multi-view observations and ground-truth camera poses, our
approach operates with as few as four views per articulation and no camera
supervision. To address the inherent challenges, we first reconstruct each
articulation independently using recent advances in sparse-view 3D
reconstruction, then learn a deformation field that establishes dense
correspondences across poses. A progressive disentanglement strategy further
separates static from moving parts, enabling robust separation of camera and
object motion. Finally, we jointly optimize geometry, appearance, and
kinematics with a self-supervised loss that enforces cross-view and cross-pose
consistency. Experiments on the standard benchmark and real-world examples
demonstrate that our method produces accurate and detailed articulated object
representations under significantly weaker input assumptions than existing
approaches.

</details>


### [93] [Noisy Label Refinement with Semantically Reliable Synthetic Images](https://arxiv.org/abs/2509.04298)
*Yingxuan Li,Jiafeng Mao,Yusuke Matsui*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的方法，利用文本到图像模型生成的合成图像作为可靠参考点，来识别和纠正真实数据集中语义噪声导致的错误标签，显著提高了图像分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 图像分类数据集中存在的语义噪声（即视觉上相似但标签错误的类别）对传统的监督学习构成了严峻挑战。虽然文本到图像模型生成的合成图像带有可靠标签，但由于领域差距和多样性限制，其直接用于训练的效果有限。

Method: 本文提出一种不同于传统方法的方案，利用合成图像作为可靠的参考点，以识别和纠正噪声数据集中被错误标记的样本。该方法与现有的抗噪声学习技术正交，可以结合使用。

Result: 在多种基准数据集和噪声条件下，尤其是语义标签噪声场景下，该方法显著提高了分类准确率。与最先进的抗噪声训练方法结合后，在70%语义噪声下，CIFAR-10上准确率提高了30%，CIFAR-100上提高了11%；在真实世界噪声条件下，ImageNet-100上准确率提高了24%。

Conclusion: 利用合成图像作为可靠参考点可以有效解决图像分类数据集中语义噪声问题，显著提升分类性能，并且可以与现有抗噪声学习技术结合实现更优异的表现。

Abstract: Semantic noise in image classification datasets, where visually similar
categories are frequently mislabeled, poses a significant challenge to
conventional supervised learning approaches. In this paper, we explore the
potential of using synthetic images generated by advanced text-to-image models
to address this issue. Although these high-quality synthetic images come with
reliable labels, their direct application in training is limited by domain gaps
and diversity constraints. Unlike conventional approaches, we propose a novel
method that leverages synthetic images as reliable reference points to identify
and correct mislabeled samples in noisy datasets. Extensive experiments across
multiple benchmark datasets show that our approach significantly improves
classification accuracy under various noise conditions, especially in
challenging scenarios with semantic label noise. Additionally, since our method
is orthogonal to existing noise-robust learning techniques, when combined with
state-of-the-art noise-robust training methods, it achieves superior
performance, improving accuracy by 30% on CIFAR-10 and by 11% on CIFAR-100
under 70% semantic noise, and by 24% on ImageNet-100 under real-world noise
conditions.

</details>


### [94] [Efficient Odd-One-Out Anomaly Detection](https://arxiv.org/abs/2509.04326)
*Silvio Chito,Paolo Rabino,Tatiana Tommasi*

Main category: cs.CV

TL;DR: 本文提出了一种基于DINO的高效模型，用于解决“格格不入”异常检测任务，该模型在保持竞争性能的同时，显著减少了参数量和训练时间。此外，还引入了多模态大语言模型作为基线，揭示了其在结构化视觉推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: “格格不入”异常检测任务对现代深度学习模型提出了多项挑战，包括需要跨多个视图进行空间推理、理解上下文的关系推理，以及在不同物体类别和布局之间进行泛化。研究动机在于解决这些挑战时，必须兼顾效率。

Method: 研究人员提出了一种基于DINO的模型，旨在通过减少参数量来提高效率。与当前最先进的模型相比，该模型将参数量减少了三分之一，训练时间缩短了三倍。此外，实验评估还引入了一个多模态大语言模型（Multimodal Large Language Model）作为基线。

Result: 所提出的DINO模型在保持竞争性能的同时，成功将参数量减少了三分之一，训练时间缩短了三倍，优于当前最先进的模型。对多模态大语言模型的评估也揭示了其在结构化视觉推理任务中的当前局限性。

Conclusion: 研究表明，通过基于DINO的方法，可以高效地解决“格格不入”异常检测任务，显著提升效率而性能不减。同时，多模态大语言模型在处理此类需要复杂结构化视觉推理的任务时仍存在不足，提示了未来研究的方向。

Abstract: The recently introduced odd-one-out anomaly detection task involves
identifying the odd-looking instances within a multi-object scene. This problem
presents several challenges for modern deep learning models, demanding spatial
reasoning across multiple views and relational reasoning to understand context
and generalize across varying object categories and layouts. We argue that
these challenges must be addressed with efficiency in mind. To this end, we
propose a DINO-based model that reduces the number of parameters by one third
and shortens training time by a factor of three compared to the current
state-of-the-art, while maintaining competitive performance. Our experimental
evaluation also introduces a Multimodal Large Language Model baseline,
providing insights into its current limitations in structured visual reasoning
tasks. The project page can be found at
https://silviochito.github.io/EfficientOddOneOut/

</details>


### [95] [Self-adaptive Dataset Construction for Real-World Multimodal Safety Scenarios](https://arxiv.org/abs/2509.04403)
*Jingen Qu,Lijun Li,Bo Zhang,Yichen Yan,Jing Shao*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的图像导向自适应方法，用于构建真实世界多模态安全（RMS）数据集，并引入了统一的评估指标，以解决现有方法在覆盖复杂场景和评估效果方面的不足。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）的安全挑战日益复杂，但当前风险导向的数据集构建方法无法覆盖日益增长的真实世界多模态安全场景（RMS）。此外，缺乏统一的评估指标导致其整体有效性未经证实。

Method: 1. 提出了一种新颖的图像导向自适应数据集构建方法，该方法从图像开始，最终构建配对的文本和指导响应。2. 使用此方法自动生成了一个包含3.5万图像-文本对及指导响应的RMS数据集。3. 引入了一个标准化的安全数据集评估指标：微调一个安全判断模型，并在其他安全数据集上评估其能力。

Result: 1. 成功生成了一个包含3.5万图像-文本对及指导响应的RMS数据集。2. 在各种任务上的广泛实验证明了所提出的图像导向管道的有效性。3. 结果证实了图像导向方法的扩展性和有效性。

Conclusion: 该研究为真实世界多模态安全数据集的构建提供了一个新视角，证明了图像导向方法的有效性和可扩展性，并引入了统一的评估标准。

Abstract: Multimodal large language models (MLLMs) are rapidly evolving, presenting
increasingly complex safety challenges. However, current dataset construction
methods, which are risk-oriented, fail to cover the growing complexity of
real-world multimodal safety scenarios (RMS). And due to the lack of a unified
evaluation metric, their overall effectiveness remains unproven. This paper
introduces a novel image-oriented self-adaptive dataset construction method for
RMS, which starts with images and end constructing paired text and guidance
responses. Using the image-oriented method, we automatically generate an RMS
dataset comprising 35k image-text pairs with guidance responses. Additionally,
we introduce a standardized safety dataset evaluation metric: fine-tuning a
safety judge model and evaluating its capabilities on other safety
datasets.Extensive experiments on various tasks demonstrate the effectiveness
of the proposed image-oriented pipeline. The results confirm the scalability
and effectiveness of the image-oriented approach, offering a new perspective
for the construction of real-world multimodal safety datasets.

</details>


### [96] [GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization](https://arxiv.org/abs/2509.04334)
*Pengyue Jia,Yingyi Zhang,Xiangyu Zhao,Yixuan Li*

Main category: cs.CV

TL;DR: 本文提出了GeoArena，一个开放平台，用于解决图像地理定位任务中现有评估方法的数据泄露和指标局限性问题，通过人类判断对大型视觉-语言模型（LVLMs）进行真实世界的基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前图像地理定位评估存在两大局限：一是数据泄露，即用于预测的LVLMs常在测试数据集上预训练，影响评估准确性；二是现有指标主要依赖精确地理坐标，忽略推理过程并引发隐私担忧。

Method: GeoArena是一个开放平台，用于评估全球图像地理定位任务中的LVLMs。它允许用户上传真实世界图像以丰富评估语料库，并利用成对的人类判断来评估模型输出与人类期望的匹配程度。

Result: GeoArena平台已在线部署两个月，收集了数千条投票记录。基于这些数据，作者进行了详细分析，并建立了不同LVLMs在图像地理定位任务上的排行榜。

Conclusion: GeoArena提供了一个新颖的、以人为中心的、真实世界图像地理定位LVLM评估平台，有效解决了现有评估方法的局限性，并能更准确地衡量模型的实际能力。

Abstract: Image geolocalization aims to predict the geographic location of images
captured anywhere on Earth, but its global nature presents significant
challenges. Current evaluation methodologies suffer from two major limitations.
First, data leakage: advanced approaches often rely on large vision-language
models (LVLMs) to predict image locations, yet these models are frequently
pretrained on the test datasets, compromising the accuracy of evaluating a
model's actual geolocalization capability. Second, existing metrics primarily
rely on exact geographic coordinates to assess predictions, which not only
neglects the reasoning process but also raises privacy concerns when user-level
location data is required. To address these issues, we propose GeoArena, a
first open platform for evaluating LVLMs on worldwide image geolocalization
tasks, offering true in-the-wild and human-centered benchmarking. GeoArena
enables users to upload in-the-wild images for a more diverse evaluation
corpus, and it leverages pairwise human judgments to determine which model
output better aligns with human expectations. Our platform has been deployed
online for two months, during which we collected over thousands voting records.
Based on this data, we conduct a detailed analysis and establish a leaderboard
of different LVLMs on the image geolocalization task.

</details>


### [97] [The Telephone Game: Evaluating Semantic Drift in Unified Models](https://arxiv.org/abs/2509.04438)
*Sabbir Mollah,Rohit Gupta,Sirnam Swetha,Qingyang Liu,Ahnaf Munir,Mubarak Shah*

Main category: cs.CV

TL;DR: 本文提出了一种名为UCF-UM的循环评估框架，用于衡量统一视觉语言模型在图像到文本(I2T)和文本到图像(T2I)任务之间语义漂移。通过多代交替评估和新指标（MCD、SDR、MGG）及新基准（ND400），研究发现不同模型的跨模态稳定性差异显著，揭示了循环一致性作为标准评估的必要补充。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法（如FID、GenEval用于T2I；MME、MMBench用于I2T）孤立地衡量统一模型的理解和生成能力。它们无法揭示模型是否能同时理解和生成同一概念，也无法评估在图像和文本模态之间循环时语义是否保持一致。然而，理解与生成之间的一致性对于下游应用至关重要。

Method: 研究引入了“统一模型统一一致性框架”（UCF-UM），这是一种循环评估协议，通过多次交替进行I2T和T2I任务来量化语义漂移。UCF-UM提出了三个指标：(i) 平均累积漂移 (MCD)，基于嵌入的整体语义损失度量；(ii) 语义漂移率 (SDR)，总结语义衰减率；(iii) 多代GenEval (MGG)，一个扩展GenEval的对象级依从性得分。此外，为评估模型在COCO之外的泛化能力，创建了新的基准ND400，并对七个近期模型进行了评估。

Result: UCF-UM揭示了跨模态稳定性在不同模型之间存在显著差异。例如，BAGEL等模型在多次交替后仍能保持语义，而Vila-u等模型尽管单次通过得分很高，但漂移速度很快。

Conclusion: 循环一致性是标准I2T和T2I评估的必要补充。UCF-UM提供了实用的指标，可以一致地评估统一模型的跨模态稳定性和其共享表示的强度。

Abstract: Employing a single, unified model (UM) for both visual understanding
(image-to-text: I2T) and and visual generation (text-to-image: T2I) has opened
a new direction in Visual Language Model (VLM) research. While UMs can also
support broader unimodal tasks (e.g., text-to-text, image-to-image), we focus
on the core cross-modal pair T2I and I2T, as consistency between understanding
and generation is critical for downstream use. Existing evaluations consider
these capabilities in isolation: FID and GenEval for T2I, and benchmarks such
as MME, MMBench for I2T. These single-pass metrics do not reveal whether a
model that understands a concept can also render it, nor whether meaning is
preserved when cycling between image and text modalities. To address this, we
introduce the Unified Consistency Framework for Unified Models (UCF-UM), a
cyclic evaluation protocol that alternates I2T and T2I over multiple
generations to quantify semantic drift. UCF formulates 3 metrics: (i) Mean
Cumulative Drift (MCD), an embedding-based measure of overall semantic loss;
(ii) Semantic Drift Rate (SDR), that summarizes semantic decay rate; and (iii)
Multi-Generation GenEval (MGG), an object-level compliance score extending
GenEval. To assess generalization beyond COCO, which is widely used in
training; we create a new benchmark ND400, sampled from NoCaps and DOCCI and
evaluate on seven recent models. UCF-UM reveals substantial variation in
cross-modal stability: some models like BAGEL maintain semantics over many
alternations, whereas others like Vila-u drift quickly despite strong
single-pass scores. Our results highlight cyclic consistency as a necessary
complement to standard I2T and T2I evaluations, and provide practical metrics
to consistently assess unified model's cross-modal stability and strength of
their shared representations. Code:
https://github.com/mollahsabbir/Semantic-Drift-in-Unified-Models

</details>


### [98] [MICACL: Multi-Instance Category-Aware Contrastive Learning for Long-Tailed Dynamic Facial Expression Recognition](https://arxiv.org/abs/2509.04344)
*Feng-Qi Cui,Zhen Lin,Xinlong Rao,Anyang Tong,Shiyao Li,Fei Wang,Changlin Chen,Bin Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为MICACL的多实例学习框架，用于动态面部表情识别（DFER），通过整合时空依赖建模和长尾对比学习优化，解决了长尾分布和时空特征建模的挑战，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 动态面部表情识别（DFER）面临长尾类别分布和复杂的时空特征建模带来的显著挑战。现有的深度学习方法往往未能有效解决这些问题，导致模型存在严重的归纳偏差。

Method: 本文提出了一种新颖的多实例学习框架MICACL，它集成了时空依赖建模和长尾对比学习优化。具体方法包括：
1.  **图增强实例交互模块（GEIIM）**：通过自适应邻接矩阵和多尺度卷积，捕获相邻实例之间复杂的时空关系。
2.  **加权实例聚合网络（WIAN）**：根据实例重要性动态分配权重，增强实例级别的特征聚合。
3.  **多尺度类别感知对比学习（MCCL）策略**：平衡主要类别和次要类别之间的训练。

Result: 在野外数据集（即DFEW和FERV39k）上的大量实验表明，MICACL实现了最先进的性能，并展现出卓越的鲁棒性和泛化能力。

Conclusion: MICACL框架通过有效解决长尾类别分布和复杂时空特征建模问题，显著提升了动态面部表情识别的性能，达到了最先进水平。

Abstract: Dynamic facial expression recognition (DFER) faces significant challenges due
to long-tailed category distributions and complexity of spatio-temporal feature
modeling. While existing deep learning-based methods have improved DFER
performance, they often fail to address these issues, resulting in severe model
induction bias. To overcome these limitations, we propose a novel
multi-instance learning framework called MICACL, which integrates
spatio-temporal dependency modeling and long-tailed contrastive learning
optimization. Specifically, we design the Graph-Enhanced Instance Interaction
Module (GEIIM) to capture intricate spatio-temporal between adjacent instances
relationships through adaptive adjacency matrices and multiscale convolutions.
To enhance instance-level feature aggregation, we develop the Weighted Instance
Aggregation Network (WIAN), which dynamically assigns weights based on instance
importance. Furthermore, we introduce a Multiscale Category-aware Contrastive
Learning (MCCL) strategy to balance training between major and minor
categories. Extensive experiments on in-the-wild datasets (i.e., DFEW and
FERV39k) demonstrate that MICACL achieves state-of-the-art performance with
superior robustness and generalization.

</details>


### [99] [Stitching the Story: Creating Panoramic Incident Summaries from Body-Worn Footage](https://arxiv.org/abs/2509.04370)
*Dor Cohen,Inga Efrosman,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CV

TL;DR: 该研究提出一种计算机视觉流程，将执法记录仪视频转换为全景图像，以提供事件现场的简洁视觉摘要，从而提高态势感知能力。


<details>
  <summary>Details</summary>
Motivation: 急救人员广泛使用执法记录仪，但在时间紧迫的情况下，审查冗长的视频不切实际。有效态势感知需要能够快速解读的简洁视觉摘要。

Method: 该方法利用单目同步定位与建图（SLAM）估计相机轨迹并重建环境空间布局。通过聚类相机姿态识别关键视角，并从每个聚类中选择代表性帧。这些帧使用多帧拼接技术融合成空间连贯的全景图像。

Result: 该流程将执法记录仪视频转换为信息丰富的全景图像，概括了事件现场。生成的摘要能实现对复杂环境的快速理解。

Conclusion: 所产生的摘要通过快速理解复杂环境，促进了高效的决策制定和事件回顾。

Abstract: First responders widely adopt body-worn cameras to document incident scenes
and support post-event analysis. However, reviewing lengthy video footage is
impractical in time-critical situations. Effective situational awareness
demands a concise visual summary that can be quickly interpreted. This work
presents a computer vision pipeline that transforms body-camera footage into
informative panoramic images summarizing the incident scene. Our method
leverages monocular Simultaneous Localization and Mapping (SLAM) to estimate
camera trajectories and reconstruct the spatial layout of the environment. Key
viewpoints are identified by clustering camera poses along the trajectory, and
representative frames from each cluster are selected. These frames are fused
into spatially coherent panoramic images using multi-frame stitching
techniques. The resulting summaries enable rapid understanding of complex
environments and facilitate efficient decision-making and incident review.

</details>


### [100] [AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval for Text-Based Person Anomaly Search](https://arxiv.org/abs/2509.04376)
*Hao Ju,Hu Zhang,Zhedong Zheng*

Main category: cs.CV

TL;DR: AnomalyLMM是首个利用大型多模态模型（LMMs）进行基于文本的人员异常行为搜索的框架，通过粗到细的管道和免训练的适应策略，有效解决了细粒度跨模态对齐和稀疏样本下的异常识别挑战。


<details>
  <summary>Details</summary>
Motivation: 公共安全需求日益增长，催生了基于文本的人员异常搜索任务。该任务面临两大挑战：细粒度跨模态对齐（文本异常与视觉行为）和稀疏样本下的异常识别。尽管大型多模态模型（LMMs）在多模态理解方面表现出色，但其在细粒度异常检索中的潜力尚未充分挖掘，主要受限于生成性知识与判别性检索之间的领域差距，以及缺乏高效的部署适应策略。

Method: 本文提出了AnomalyLMM框架，首次将LMMs应用于基于文本的人员异常搜索。其核心方法包括：1) 一个新颖的粗到细管道，将LMM的生成性世界知识与以检索为中心的异常检测相结合；2) 一个免训练的适应策略“食谱”，包含掩码跨模态提示、行为显著性预测和知识感知重排序，实现了对细微异常线索的零样本聚焦。

Result: 在唯一的公开基准PAB数据集上进行了严格评估，结果表明AnomalyLMM的有效性，其Recall@1准确率超越了竞争基线0.96%。值得注意的是，该方法还通过定性分析揭示了文本异常与视觉行为之间可解释的对齐关系。

Conclusion: AnomalyLMM成功地利用LMMs解决了基于文本的人员异常搜索任务中的关键挑战，实现了对异常行为的有效检索，并提供了可解释的跨模态对齐。该研究为LMMs在该领域的应用开辟了新方向，并提供了可供未来研究使用的代码和模型。

Abstract: With growing public safety demands, text-based person anomaly search has
emerged as a critical task, aiming to retrieve individuals with abnormal
behaviors via natural language descriptions. Unlike conventional person search,
this task presents two unique challenges: (1) fine-grained cross-modal
alignment between textual anomalies and visual behaviors, and (2) anomaly
recognition under sparse real-world samples. While Large Multi-modal Models
(LMMs) excel in multi-modal understanding, their potential for fine-grained
anomaly retrieval remains underexplored, hindered by: (1) a domain gap between
generative knowledge and discriminative retrieval, and (2) the absence of
efficient adaptation strategies for deployment. In this work, we propose
AnomalyLMM, the first framework that harnesses LMMs for text-based person
anomaly search. Our key contributions are: (1) A novel coarse-to-fine pipeline
integrating LMMs to bridge generative world knowledge with retrieval-centric
anomaly detection; (2) A training-free adaptation cookbook featuring masked
cross-modal prompting, behavioral saliency prediction, and knowledge-aware
re-ranking, enabling zero-shot focus on subtle anomaly cues. As the first study
to explore LMMs for this task, we conduct a rigorous evaluation on the PAB
dataset, the only publicly available benchmark for text-based person anomaly
search, with its curated real-world anomalies covering diverse scenarios (e.g.,
falling, collision, and being hit). Experiments show the effectiveness of the
proposed method, surpassing the competitive baseline by +0.96% Recall@1
accuracy. Notably, our method reveals interpretable alignment between textual
anomalies and visual behaviors, validated via qualitative analysis. Our code
and models will be released for future research.

</details>


### [101] [Aesthetic Image Captioning with Saliency Enhanced MLLMs](https://arxiv.org/abs/2509.04378)
*Yilin Tao,Jiashui Huang,Huaze Xu,Ling Shao*

Main category: cs.CV

TL;DR: 本文提出了ASE-MLLM，一个端到端框架，首次将图像美学显著性明确整合到多模态大语言模型（MLLMs）中，专门用于美学图像描述（AIC）任务，并在主流基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图像美学研究主要关注美学评分预测，在美学图像描述（AIC）中的应用有限。尽管预训练多模态大语言模型（MLLMs）发展迅速，但现有利用MLLMs的AIC工作主要依赖微调，未能专门使MLLMs关注目标美学内容。

Method: 本文提出了美学显著性增强多模态大语言模型（ASE-MLLM），这是一个端到端框架，明确将美学显著性融入MLLMs。该框架引入了图像美学显著性模块（IASM）来高效提取美学显著性特征。此外，设计了IAS-ViT作为MLLMs的图像编码器，通过交叉注意力机制将美学显著性特征与原始图像特征融合。

Result: 广泛的实验表明，ASE-MLLM在当前主流AIC基准测试中显著优于传统方法和通用MLLMs，达到了最先进（SOTA）的性能。

Conclusion: ASE-MLLM成功地将图像美学显著性整合到多模态大语言模型中，解决了现有AIC方法的局限性，并在美学图像描述任务上取得了显著的性能提升，实现了最先进的成果。

Abstract: Aesthetic Image Captioning (AIC) aims to generate textual descriptions of
image aesthetics, becoming a key research direction in the field of
computational aesthetics. In recent years, pretrained Multimodal Large Language
Models (MLLMs) have advanced rapidly, leading to a significant increase in
image aesthetics research that integrates both visual and textual modalities.
However, most existing studies on image aesthetics primarily focus on
predicting aesthetic ratings and have shown limited application in AIC.
Existing AIC works leveraging MLLMs predominantly rely on fine-tuning methods
without specifically adapting MLLMs to focus on target aesthetic content. To
address this limitation, we propose the Aesthetic Saliency Enhanced Multimodal
Large Language Model (ASE-MLLM), an end-to-end framework that explicitly
incorporates aesthetic saliency into MLLMs. Within this framework, we introduce
the Image Aesthetic Saliency Module (IASM), which efficiently and effectively
extracts aesthetic saliency features from images. Additionally, we design
IAS-ViT as the image encoder for MLLMs, this module fuses aesthetic saliency
features with original image features via a cross-attention mechanism. To the
best of our knowledge, ASE-MLLM is the first framework to integrate image
aesthetic saliency into MLLMs specifically for AIC tasks. Extensive experiments
demonstrated that our approach significantly outperformed traditional methods
and generic MLLMs on current mainstream AIC benchmarks, achieving
state-of-the-art (SOTA) performance.

</details>


### [102] [Learning neural representations for X-ray ptychography reconstruction with unknown probes](https://arxiv.org/abs/2509.04402)
*Tingyou Li,Zixin Xu,Zirui Gao,Hanfei Yan,Xiaojing Huang,Jizhou Li*

Main category: cs.CV

TL;DR: 本文提出PtyINR，一个自监督隐式神经表示框架，用于在X射线叠层成像中同时重建未知探针和物体，在低信号条件下表现出卓越的重建质量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: X射线叠层成像在纳米尺度分辨率方面表现出色，但当照明探针未知时，准确图像重建面临关键挑战。传统迭代方法和深度学习方法在低剂量和高速实验固有的低信号条件下表现不佳，这限制了重建保真度并阻碍了该技术的广泛应用。

Method: 本文引入了叠层成像隐式神经表示（PtyINR），这是一个自监督框架，通过将物体和探针都参数化为连续的神经表示来解决物体和探针的恢复问题。PtyINR直接从原始衍射图样进行端到端重建，无需预先表征探针。

Result: 广泛评估表明，PtyINR在模拟和实验数据上均实现了卓越的重建质量，并在挑战性的低信号条件下表现出显著的鲁棒性。

Conclusion: PtyINR提供了一个可泛化的、物理信息驱动的框架，用于解决依赖于探针的逆问题，使其适用于各种计算显微镜问题。

Abstract: X-ray ptychography provides exceptional nanoscale resolution and is widely
applied in materials science, biology, and nanotechnology. However, its full
potential is constrained by the critical challenge of accurately reconstructing
images when the illuminating probe is unknown. Conventional iterative methods
and deep learning approaches are often suboptimal, particularly under the
low-signal conditions inherent to low-dose and high-speed experiments. These
limitations compromise reconstruction fidelity and restrict the broader
adoption of the technique. In this work, we introduce the Ptychographic
Implicit Neural Representation (PtyINR), a self-supervised framework that
simultaneously addresses the object and probe recovery problem. By
parameterizing both as continuous neural representations, PtyINR performs
end-to-end reconstruction directly from raw diffraction patterns without
requiring any pre-characterization of the probe. Extensive evaluations
demonstrate that PtyINR achieves superior reconstruction quality on both
simulated and experimental data, with remarkable robustness under challenging
low-signal conditions. Furthermore, PtyINR offers a generalizable,
physics-informed framework for addressing probe-dependent inverse problems,
making it applicable to a wide range of computational microscopy problems.

</details>


### [103] [Few-step Flow for 3D Generation via Marginal-Data Transport Distillation](https://arxiv.org/abs/2509.04406)
*Zanwei Zhou,Taoran Yi,Jiemin Fang,Chen Yang,Lingxi Xie,Xinggang Wang,Wei Shen,Qi Tian*

Main category: cs.CV

TL;DR: 本文提出MDT-dist框架，通过引入速度匹配（VM）和速度蒸馏（VD）优化目标，显著加速了基于流的3D生成模型（如TRELLIS）的推理过程，同时保持了高视觉和几何保真度。


<details>
  <summary>Details</summary>
Motivation: 基于流的3D生成模型通常需要数十个采样步骤进行推理，导致速度较慢。尽管一致性模型（CMs）等少数步骤蒸馏方法在加速2D扩散模型方面取得了显著进展，但它们在更复杂的3D生成任务中仍未得到充分探索。

Method: 本文提出了MDT-dist框架，其主要目标是蒸馏预训练模型以学习边际数据传输（Marginal-Data Transport）。由于直接学习该目标需要对速度场进行积分，而这在计算上是不可行的。因此，本文提出了两个可优化的目标：速度匹配（Velocity Matching, VM）和速度蒸馏（Velocity Distillation, VD）。VM旨在稳定地匹配学生模型和教师模型之间的速度场，但可能提供有偏的梯度估计。VD通过利用学习到的速度场进行概率密度蒸馏，进一步增强了优化过程。

Result: 在先驱3D生成框架TRELLIS上进行评估，MDT-dist将每个流转换器的采样步骤从25步减少到1或2步。在A800上实现了0.68秒（1步x2）和0.94秒（2步x2）的延迟，分别带来了9.0倍和6.5倍的加速，同时保持了高视觉和几何保真度。实验表明，该方法显著优于现有的一致性模型蒸馏方法，并使TRELLIS在少步3D生成中表现出卓越的性能。

Conclusion: MDT-dist框架通过新颖的VM和VD优化目标，成功实现了基于流的3D生成模型的少步蒸馏，显著提高了推理速度，同时保持了生成质量，并在3D生成任务中超越了现有的一致性模型蒸馏方法。

Abstract: Flow-based 3D generation models typically require dozens of sampling steps
during inference. Though few-step distillation methods, particularly
Consistency Models (CMs), have achieved substantial advancements in
accelerating 2D diffusion models, they remain under-explored for more complex
3D generation tasks. In this study, we propose a novel framework, MDT-dist, for
few-step 3D flow distillation. Our approach is built upon a primary objective:
distilling the pretrained model to learn the Marginal-Data Transport. Directly
learning this objective needs to integrate the velocity fields, while this
integral is intractable to be implemented. Therefore, we propose two
optimizable objectives, Velocity Matching (VM) and Velocity Distillation (VD),
to equivalently convert the optimization target from the transport level to the
velocity and the distribution level respectively. Velocity Matching (VM) learns
to stably match the velocity fields between the student and the teacher, but
inevitably provides biased gradient estimates. Velocity Distillation (VD)
further enhances the optimization process by leveraging the learned velocity
fields to perform probability density distillation. When evaluated on the
pioneer 3D generation framework TRELLIS, our method reduces sampling steps of
each flow transformer from 25 to 1 or 2, achieving 0.68s (1 step x 2) and 0.94s
(2 steps x 2) latency with 9.0x and 6.5x speedup on A800, while preserving high
visual and geometric fidelity. Extensive experiments demonstrate that our
method significantly outperforms existing CM distillation methods, and enables
TRELLIS to achieve superior performance in few-step 3D generation.

</details>


### [104] [Durian: Dual Reference-guided Portrait Animation with Attribute Transfer](https://arxiv.org/abs/2509.04434)
*Hyunsoo Cha,Byungjun Kim,Hanbyul Joo*

Main category: cs.CV

TL;DR: Durian是首个零样本人像动画生成方法，通过双参考网络实现面部属性从参考图像到目标人像的高保真和空间一致性迁移。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在零样本设置下，实现高保真且空间一致的人像动画生成及面部属性迁移。研究旨在解决这一挑战。

Method: Durian引入了双参考网络，将人像和属性图像的空间特征注入扩散模型的去噪过程。模型采用自重建训练，通过从同一视频采样两帧（一帧作属性参考，一帧作目标人像）并重建其余帧。为支持不同空间范围的属性迁移，提出了基于关键点条件图像生成的掩码扩展策略。此外，通过空间和外观级变换增强属性和人像图像，以提高对位置不对齐的鲁棒性。

Result: Durian在带属性迁移的人像动画生成方面达到了最先进的性能。其双参考设计使得在单次生成中无需额外训练即可实现多属性组合。

Conclusion: Durian有效解决了零样本人像动画属性迁移问题，展现出强大的泛化能力和鲁棒性，并在多属性组合方面表现出色，为该领域树立了新标准。

Abstract: We present Durian, the first method for generating portrait animation videos
with facial attribute transfer from a given reference image to a target
portrait in a zero-shot manner. To enable high-fidelity and spatially
consistent attribute transfer across frames, we introduce dual reference
networks that inject spatial features from both the portrait and attribute
images into the denoising process of a diffusion model. We train the model
using a self-reconstruction formulation, where two frames are sampled from the
same portrait video: one is treated as the attribute reference and the other as
the target portrait, and the remaining frames are reconstructed conditioned on
these inputs and their corresponding masks. To support the transfer of
attributes with varying spatial extent, we propose a mask expansion strategy
using keypoint-conditioned image generation for training. In addition, we
further augment the attribute and portrait images with spatial and
appearance-level transformations to improve robustness to positional
misalignment between them. These strategies allow the model to effectively
generalize across diverse attributes and in-the-wild reference combinations,
despite being trained without explicit triplet supervision. Durian achieves
state-of-the-art performance on portrait animation with attribute transfer, and
notably, its dual reference design enables multi-attribute composition in a
single generation pass without additional training.

</details>


### [105] [From Lines to Shapes: Geometric-Constrained Segmentation of X-Ray Collimators via Hough Transform](https://arxiv.org/abs/2509.04437)
*Benjamin El-Zein,Dominik Eckert,Andreas Fieselmann,Christopher Syben,Ludwig Ritschl,Steffen Kappler,Sebastian Stober*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的、几何约束的分割方法，用于在X射线图像中检测准直器阴影，即使在散射X射线导致边缘模糊的情况下也能实现鲁棒的重建。


<details>
  <summary>Details</summary>
Motivation: X射线成像中的准直器阴影检测是限制曝光区域和最小化患者辐射剂量的关键预处理步骤。然而，散射X射线会导致边缘模糊，使检测变得困难。鉴于准直器阴影通常呈多边形，研究旨在利用这一先验知识来克服检测挑战。

Method: 该方法引入了一种深度学习分割模型，其几何形状受到内在约束。它集成了一个可微分的霍夫变换网络来检测准直器边界，并增强了提取ROI中心信息的能力。在推理阶段，结合这两个任务的信息来生成精细的、受线条约束的分割掩模。

Result: 该方法在多样化的真实X射线图像测试集上，实现了准直区域的鲁棒重建，中位数豪斯多夫距离为4.3-5.0毫米。尽管该应用涉及最多四个阴影边界，但该方法不限于特定数量的边缘。

Conclusion: 研究成功开发了一种鲁棒的、几何约束的深度学习方法，用于检测X射线图像中的准直器阴影，能够生成精细的、受线条约束的分割掩模，并在实际图像上表现出良好的准确性。

Abstract: Collimation in X-ray imaging restricts exposure to the region-of-interest
(ROI) and minimizes the radiation dose applied to the patient. The detection of
collimator shadows is an essential image-based preprocessing step in digital
radiography posing a challenge when edges get obscured by scattered X-ray
radiation. Regardless, the prior knowledge that collimation forms
polygonal-shaped shadows is evident. For this reason, we introduce a deep
learning-based segmentation that is inherently constrained to its geometry. We
achieve this by incorporating a differentiable Hough transform-based network to
detect the collimation borders and enhance its capability to extract the
information about the ROI center. During inference, we combine the information
of both tasks to enable the generation of refined, line-constrained
segmentation masks. We demonstrate robust reconstruction of collimated regions
achieving median Hausdorff distances of 4.3-5.0mm on diverse test sets of real
Xray images. While this application involves at most four shadow borders, our
method is not fundamentally limited by a specific number of edges.

</details>


### [106] [One Flight Over the Gap: A Survey from Perspective to Panoramic Vision](https://arxiv.org/abs/2509.04444)
*Xin Lin,Xian Ge,Dizhe Zhang,Zhaoliang Wan,Xianshun Wang,Xiangtai Li,Wenjie Jiang,Bo Du,Dacheng Tao,Ming-Hsuan Yang,Lu Qi*

Main category: cs.CV

TL;DR: 本综述全面回顾了全景图像（ODIs）领域，重点关注从透视图像到全景图像的适应性问题。它总结了主要挑战、分析了20多个代表性任务及其解决方法，并将全景视觉分为四大类，并展望了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着虚拟现实、自动驾驶和具身机器人等应用对空间智能和整体场景感知的需求增长，全景图像（提供完整360度视野）日益受到关注。然而，全景图像在几何投影、空间分布和边界连续性方面与透视图像存在显著差异，使得直接应用透视方法面临挑战，因此需要专门的适应性研究。

Method: 本研究通过以下方法进行：1) 回顾全景成像流程和投影方法，以理解结构差异。2) 总结透视到全景领域适应的三个主要挑战：极点附近的几何畸变、等距柱状投影（ERP）中的非均匀采样和周期性边界连续性。3) 从300多篇论文中选取20多个代表性任务，进行跨方法分析以探讨解决挑战的策略。4) 进行跨任务比较，将全景视觉分为四大类：视觉质量增强与评估、视觉理解、多模态理解和视觉生成。5) 讨论数据、模型和应用方面的开放挑战和未来方向。

Result: 本研究的结果包括：1) 明确了全景视觉领域适应的三个核心挑战：严重的极点几何畸变、等距柱状投影（ERP）中的非均匀采样以及周期性边界连续性。2) 总结了应对这些挑战的代表性策略。3) 将全景视觉任务划分为四大主要类别：视觉质量增强与评估、视觉理解、多模态理解和视觉生成。4) 提供了跨方法和跨任务的深入分析。

Conclusion: 本综述为全景视觉领域提供了新的见解和前瞻性视角，旨在推动全景视觉技术的发展。它不仅系统地梳理了现有技术和挑战，还指出了数据、模型和应用方面的开放挑战和未来研究方向，为研究人员提供了宝贵的参考。

Abstract: Driven by the demand for spatial intelligence and holistic scene perception,
omnidirectional images (ODIs), which provide a complete 360\textdegree{} field
of view, are receiving growing attention across diverse applications such as
virtual reality, autonomous driving, and embodied robotics. Despite their
unique characteristics, ODIs exhibit remarkable differences from perspective
images in geometric projection, spatial distribution, and boundary continuity,
making it challenging for direct domain adaption from perspective methods. This
survey reviews recent panoramic vision techniques with a particular emphasis on
the perspective-to-panorama adaptation. We first revisit the panoramic imaging
pipeline and projection methods to build the prior knowledge required for
analyzing the structural disparities. Then, we summarize three challenges of
domain adaptation: severe geometric distortions near the poles, non-uniform
sampling in Equirectangular Projection (ERP), and periodic boundary continuity.
Building on this, we cover 20+ representative tasks drawn from more than 300
research papers in two dimensions. On one hand, we present a cross-method
analysis of representative strategies for addressing panoramic specific
challenges across different tasks. On the other hand, we conduct a cross-task
comparison and classify panoramic vision into four major categories: visual
quality enhancement and assessment, visual understanding, multimodal
understanding, and visual generation. In addition, we discuss open challenges
and future directions in data, models, and applications that will drive the
advancement of panoramic vision research. We hope that our work can provide new
insight and forward looking perspectives to advance the development of
panoramic vision technologies. Our project page is
https://insta360-research-team.github.io/Survey-of-Panorama

</details>


### [107] [Plot'n Polish: Zero-shot Story Visualization and Disentangled Editing with Text-to-Image Diffusion Models](https://arxiv.org/abs/2509.04446)
*Kiymet Akdemir,Jing Shi,Kushal Kafle,Brian Price,Pinar Yanardag*

Main category: cs.CV

TL;DR: 本文提出Plot'n Polish，一个零样本框架，用于实现文本到图像故事生成的一致性，并提供对故事视觉化细粒度控制。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在故事视觉化方面潜力巨大，但现有方法在生成后图像的控制、精修和一致性修改方面存在不足，尤其是在多帧视觉和叙事一致性上缺乏灵活性，阻碍了创作者的无缝故事创作和精修。

Method: 引入了一个名为“Plot'n Polish”的零样本框架。

Result: 该框架能够实现一致的故事生成，并提供对故事视觉化在不同细节层级的细粒度控制。

Conclusion: Plot'n Polish框架有效解决了文本到图像故事生成中对一致性和细粒度控制的挑战。

Abstract: Text-to-image diffusion models have demonstrated significant capabilities to
generate diverse and detailed visuals in various domains, and story
visualization is emerging as a particularly promising application. However, as
their use in real-world creative domains increases, the need for providing
enhanced control, refinement, and the ability to modify images post-generation
in a consistent manner becomes an important challenge. Existing methods often
lack the flexibility to apply fine or coarse edits while maintaining visual and
narrative consistency across multiple frames, preventing creators from
seamlessly crafting and refining their visual stories. To address these
challenges, we introduce Plot'n Polish, a zero-shot framework that enables
consistent story generation and provides fine-grained control over story
visualizations at various levels of detail.

</details>


### [108] [TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection](https://arxiv.org/abs/2509.04448)
*Zehong Yan,Peng Qi,Wynne Hsu,Mong Li Lee*

Main category: cs.CV

TL;DR: 本文提出了TRUST-VL，一个统一且可解释的视觉-语言模型，用于通用的多模态错误信息检测，并通过一个大规模指令数据集TRUST-Instruct进行训练，实现了最先进的性能和强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多模态错误信息（包括文本、视觉和跨模态失真）日益增长，并被生成式AI放大，对社会构成威胁。现有方法通常只关注单一类型的失真，难以泛化到未见场景。

Method: 作者观察到不同失真类型共享共同的推理能力，同时也需要特定任务的技能。他们假设跨失真类型的联合训练有助于知识共享并增强模型的泛化能力。为此，他们引入了TRUST-VL，一个统一且可解释的视觉-语言模型，用于通用多模态错误信息检测。TRUST-VL包含一个新颖的“问题感知视觉放大器”模块，用于提取特定任务的视觉特征。此外，他们构建了TRUST-Instruct，一个包含19.8万个样本的大规模指令数据集，其结构化推理链与人类事实核查工作流程对齐。

Result: 在域内和零样本基准测试中，TRUST-VL都取得了最先进的性能，同时展现出强大的泛化能力和可解释性。

Conclusion: TRUST-VL作为一个统一且可解释的视觉-语言模型，结合其新颖的模块设计和大规模指令数据集，有效解决了多模态错误信息检测中的泛化和解释性挑战，取得了显著的性能提升。

Abstract: Multimodal misinformation, encompassing textual, visual, and cross-modal
distortions, poses an increasing societal threat that is amplified by
generative AI. Existing methods typically focus on a single type of distortion
and struggle to generalize to unseen scenarios. In this work, we observe that
different distortion types share common reasoning capabilities while also
requiring task-specific skills. We hypothesize that joint training across
distortion types facilitates knowledge sharing and enhances the model's ability
to generalize. To this end, we introduce TRUST-VL, a unified and explainable
vision-language model for general multimodal misinformation detection. TRUST-VL
incorporates a novel Question-Aware Visual Amplifier module, designed to
extract task-specific visual features. To support training, we also construct
TRUST-Instruct, a large-scale instruction dataset containing 198K samples
featuring structured reasoning chains aligned with human fact-checking
workflows. Extensive experiments on both in-domain and zero-shot benchmarks
demonstrate that TRUST-VL achieves state-of-the-art performance, while also
offering strong generalization and interpretability.

</details>


### [109] [Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image -- Technical Preview](https://arxiv.org/abs/2509.04450)
*Jun-Kun Chen,Aayush Bansal,Minh Phuoc Vo,Yu-Xiong Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为VFR（虚拟试衣间）的新型视频生成模型，能够自动回归、分段生成任意长度的虚拟试穿视频，解决了长视频生成中的局部平滑性和全局时间一致性问题。


<details>
  <summary>Details</summary>
Motivation: 生成任意长度的虚拟试穿视频面临资源密集型计算和缺乏灵活性的挑战。核心问题在于如何确保相邻视频片段间的局部平滑性以及不同片段间的全局时间一致性。

Method: VFR模型采用自回归、分段生成的方式处理长视频任务。为确保局部平滑性，引入了前缀视频条件；为维持全局时间一致性，使用了一个全面捕捉人体全身外观的360度锚点视频。

Result: VFR模型能够生成分钟级别的虚拟试穿视频，并在多种动作下同时实现局部平滑性和全局时间一致性。

Conclusion: VFR是长虚拟试穿视频生成领域的开创性工作，成功解决了该任务的关键挑战。

Abstract: We introduce the Virtual Fitting Room (VFR), a novel video generative model
that produces arbitrarily long virtual try-on videos. Our VFR models long video
generation tasks as an auto-regressive, segment-by-segment generation process,
eliminating the need for resource-intensive generation and lengthy video data,
while providing the flexibility to generate videos of arbitrary length. The key
challenges of this task are twofold: ensuring local smoothness between adjacent
segments and maintaining global temporal consistency across different segments.
To address these challenges, we propose our VFR framework, which ensures
smoothness through a prefix video condition and enforces consistency with the
anchor video -- a 360-degree video that comprehensively captures the human's
wholebody appearance. Our VFR generates minute-scale virtual try-on videos with
both local smoothness and global temporal consistency under various motions,
making it a pioneering work in long virtual try-on video generation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [110] [Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies](https://arxiv.org/abs/2509.03525)
*Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sepehr Karimi,Sina Rashidi,Ali Zolnour,Maryam Dadkhah,Yasaman Haghbin,Hossein AzadMaleki,Maryam Zolnoori*

Main category: cs.CL

TL;DR: 该研究比较了大型语言模型（LLMs）在痴呆症语音检测中的多种适应策略，发现模型适应方法对性能至关重要，且经过适当适应的开源模型可媲美甚至超越商业系统。


<details>
  <summary>Details</summary>
Motivation: 美国超过一半的阿尔茨海默病及相关痴呆症患者未被诊断，语音筛查提供了一种可扩展的检测方法。

Method: 研究评估了九种纯文本模型和三种多模态（音频-文本）模型，使用了DementiaBank语音语料库的录音。适应策略包括：不同演示选择策略的上下文学习、推理增强提示、参数高效微调（PEFT）以及多模态整合。

Result: 结果显示，类质心演示在上下文学习中表现最佳；推理改善了较小的模型；令牌级微调通常产生最佳分数。添加分类头显著改善了表现不佳的模型。在多模态模型中，微调的音频-文本系统表现良好，但未能超越顶级的纯文本模型。

Conclusion: 研究强调了模型适应策略（包括演示选择、推理设计和微调方法）对基于语音的痴呆症检测至关重要，并且经过适当适应的开源模型可以达到或超越商业系统的性能。

Abstract: Over half of US adults with Alzheimer disease and related dementias remain
undiagnosed, and speech-based screening offers a scalable detection approach.
We compared large language model adaptation strategies for dementia detection
using the DementiaBank speech corpus, evaluating nine text-only models and
three multimodal audio-text models on recordings from DementiaBank speech
corpus. Adaptations included in-context learning with different demonstration
selection policies, reasoning-augmented prompting, parameter-efficient
fine-tuning, and multimodal integration. Results showed that class-centroid
demonstrations achieved the highest in-context learning performance, reasoning
improved smaller models, and token-level fine-tuning generally produced the
best scores. Adding a classification head substantially improved
underperforming models. Among multimodal models, fine-tuned audio-text systems
performed well but did not surpass the top text-only models. These findings
highlight that model adaptation strategies, including demonstration selection,
reasoning design, and tuning method, critically influence speech-based dementia
detection, and that properly adapted open-weight models can match or exceed
commercial systems.

</details>


### [111] [Enhancing Speech Large Language Models through Reinforced Behavior Alignment](https://arxiv.org/abs/2509.03526)
*Yansong Liu,Jiateng Li,Yuan Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为强化行为对齐（RBA）的框架，通过自合成高质量对齐数据和基于强化学习的方法，显著提升了语音大模型（SpeechLMs）的指令遵循能力，并使其在语音问答和语音到文本翻译等任务上达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 尽管语音大模型（SpeechLMs）能够处理语音和文本请求，但由于模态间差异，它们在指令遵循方面与纯文本大模型（LLMs）相比仍存在显著性能差距，尤其是在面对动态多变的语音输入时。

Method: RBA框架不依赖于人工标注的监督微调。它采用自合成方法，利用一个强大的教师大模型生成大量高保真对齐数据。随后，通过基于强化学习的方法，将SpeechLMs的行为与教师大模型的行为进行对齐。

Result: 实验结果表明，RBA有效增强了SpeechLMs的指令遵循能力，优于传统的蒸馏基线方法。此外，RBA可以无缝扩展到语音问答和语音到文本翻译等任务，仅使用自生成数据就在开放基准测试中取得了最先进的性能。

Conclusion: RBA框架通过结合自合成数据生成和强化学习的行为对齐，成功弥合了SpeechLMs与纯文本LLMs在指令遵循上的性能差距，并展示了其在多模态任务上的泛化能力和卓越表现。

Abstract: The recent advancements of Large Language Models (LLMs) have spurred
considerable research interest in extending their linguistic capabilities
beyond text to other modalities, which leads to emergence of speech-based LLMs
(SpeechLMs) with capability of processing user request in either speech or
textual formats. However, owing to inter-modal discrepancies, these SpeechLMs
still exhibit a significant performance gap compared to their text-based LLM
counterparts in instruction-following, particularly when confronted with the
dynamic and variable nature of user speech. To address this challenge, this
paper introduces a framework termed Reinforced Behavior Alignment (RBA),
designed to bolster the language generation proficiency of SpeechLMs. Instead
of relying on supervised fine-tuning from human annotations, RBA employs a
self-synthesis methodology to generate extensive, high-fidelity alignment data
by a powerful teacher LLM. Then SpeechLMs is aligned its behavior with that of
a teacher using a reinforcement learning-based approach. Experimental results
demonstrate that this method effectively enhances the instruction-following
capabilities of SpeechLMs that outperform conventional distillation baselines.
Crucially, we demonstrate that RBA can be seamlessly extended to tasks such
including spoken question answering and speech-to-text translation, attaining
state-of-the-art performance on open benchmarks with only self-generated data.

</details>


### [112] [Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model](https://arxiv.org/abs/2509.03527)
*Bohdan M. Pavlyshenko*

Main category: cs.CL

TL;DR: 本文提出了一种使用经过微调的Mistral 7B大型语言模型（LLM）结合检索增强生成（RAG）技术，对加密货币新闻进行多层次、多任务分析的方法，通过生成图谱和文本摘要，并进行分层堆叠，以提供全面的洞察。


<details>
  <summary>Details</summary>
Motivation: 研究旨在对加密货币新闻进行信息丰富的定性及定量分析，并提供重要见解。同时，通过将新闻表示为知识图谱，旨在消除大型语言模型幻觉的问题。

Method: 研究采用经过4位量化并使用PEFT/LoRA方法微调的Mistral 7B LLM，结合RAG技术。在第一层分析中，模型生成带有情感评分的图谱和文本摘要，以及摘要的JSON表示。更高层次进行分层堆叠，将图谱和文本摘要以及摘要的摘要整合为全面的报告。将加密货币新闻表示为知识图谱。

Result: 结果表明，使用经过微调的Mistral 7B LLM进行多层次加密货币新闻分析，能够进行信息丰富的定性及定量分析，并提供重要的洞察。

Conclusion: 该研究证实，结合微调的Mistral 7B LLM和RAG技术进行多层次加密货币新闻分析是有效的，能够提供有价值的见解，并且通过知识图谱表示可以有效解决LLM幻觉问题。

Abstract: In the paper, we consider multilevel multitask analysis of cryptocurrency
news using a fine-tuned Mistral 7B large language model with
retrieval-augmented generation (RAG).
  On the first level of analytics, the fine-tuned model generates graph and
text summaries with sentiment scores as well as JSON representations of
summaries. Higher levels perform hierarchical stacking that consolidates sets
of graph-based and text-based summaries as well as summaries of summaries into
comprehensive reports. The combination of graph and text summaries provides
complementary views of cryptocurrency news. The model is fine-tuned with 4-bit
quantization using the PEFT/LoRA approach. The representation of cryptocurrency
news as knowledge graph can essentially eliminate problems with large language
model hallucinations.
  The obtained results demonstrate that the use of fine-tuned Mistral 7B LLM
models for multilevel cryptocurrency news analysis can conduct informative
qualitative and quantitative analytics, providing important insights.

</details>


### [113] [The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking Process](https://arxiv.org/abs/2509.03528)
*Matilde Contestabile,Chiara Ferrara,Alberto Giovannetti,Giovanni Parrillo,Andrea Vandin*

Main category: cs.CL

TL;DR: 本文介绍了ProLiFIC，一个利用大型语言模型（LLMs）从非结构化数据构建的意大利立法过程事件日志，旨在解决法律领域流程挖掘（PM）中数据集可访问性和质量的限制，并作为该领域的基准。


<details>
  <summary>Details</summary>
Motivation: 流程挖掘（PM）在法律领域的应用受到数据集可访问性和质量的限制，这阻碍了其在该领域的有效性。

Method: 研究者引入了ProLiFIC（意大利议会立法流程），这是一个包含1987年至2022年意大利立法过程的综合事件日志。该日志通过大型语言模型（LLMs）将来自Normattiva门户的非结构化数据进行结构化处理，实现了流程挖掘与LLMs的整合。

Result: 成功创建了ProLiFIC事件日志，并展示了初步分析结果。ProLiFIC被提议作为法律流程挖掘的基准。

Conclusion: ProLiFIC通过提供高质量、结构化的法律流程数据集，解决了法律领域流程挖掘的数据瓶颈，并有望通过作为基准来促进该领域的新发展。

Abstract: Process Mining (PM), initially developed for industrial and business
contexts, has recently been applied to social systems, including legal ones.
However, PM's efficacy in the legal domain is limited by the accessibility and
quality of datasets. We introduce ProLiFIC (Procedural Lawmaking Flow in
Italian Chambers), a comprehensive event log of the Italian lawmaking process
from 1987 to 2022. Created from unstructured data from the Normattiva portal
and structured using large language models (LLMs), ProLiFIC aligns with recent
efforts in integrating PM with LLMs. We exemplify preliminary analyses and
propose ProLiFIC as a benchmark for legal PM, fostering new developments.

</details>


### [114] [Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages](https://arxiv.org/abs/2509.03529)
*Alejandro Álvarez Castro,Joaquín Ordieres-Meré*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的多模态框架，通过将财报电话会议编码为分层话语树，并使用两阶段Transformer架构生成语义丰富、结构感知的嵌入，以克服现有扁平化模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的金融情感分析系统虽然整合了文本和语音等多模态信号，但大多依赖于扁平的文档级或句子级模型，未能捕捉财报电话会议中分层的话语结构，而财报电话会议本身是金融沟通中独特且半结构化的丰富来源。

Method: 该框架将财报电话会议编码为分层话语树。每个节点（独白或问答对）都通过文本、音频和视频中的情感信号以及连贯性得分、主题标签和回答覆盖率评估等结构化元数据进行丰富。采用两阶段Transformer架构：第一阶段使用对比学习编码节点级别的多模态内容和话语元数据；第二阶段综合生成整个会议的全局嵌入。

Result: 实验结果表明，生成的嵌入形成了稳定、语义有意义的表示，能够反映情感基调、结构逻辑和主题一致性。此外，该系统可推广到远程医疗、教育和政治话语等其他高风险非脚本式沟通领域。

Conclusion: 该方法为多模态话语表示提供了一种鲁棒且可解释的方法，对金融预测和话语评估等下游任务具有实际效用，并可推广应用于其他涉及高风险沟通的领域。

Abstract: Earnings calls represent a uniquely rich and semi-structured source of
financial communication, blending scripted managerial commentary with
unscripted analyst dialogue. Although recent advances in financial sentiment
analysis have integrated multi-modal signals, such as textual content and vocal
tone, most systems rely on flat document-level or sentence-level models,
failing to capture the layered discourse structure of these interactions. This
paper introduces a novel multi-modal framework designed to generate
semantically rich and structurally aware embeddings of earnings calls, by
encoding them as hierarchical discourse trees. Each node, comprising either a
monologue or a question-answer pair, is enriched with emotional signals derived
from text, audio, and video, as well as structured metadata including coherence
scores, topic labels, and answer coverage assessments. A two-stage transformer
architecture is proposed: the first encodes multi-modal content and discourse
metadata at the node level using contrastive learning, while the second
synthesizes a global embedding for the entire conference. Experimental results
reveal that the resulting embeddings form stable, semantically meaningful
representations that reflect affective tone, structural logic, and thematic
alignment. Beyond financial reporting, the proposed system generalizes to other
high-stakes unscripted communicative domains such as tele-medicine, education,
and political discourse, offering a robust and explainable approach to
multi-modal discourse representation. This approach offers practical utility
for downstream tasks such as financial forecasting and discourse evaluation,
while also providing a generalizable method applicable to other domains
involving high-stakes communication.

</details>


### [115] [Reading Between the Signs: Predicting Future Suicidal Ideation from Adolescent Social Media Texts](https://arxiv.org/abs/2509.03530)
*Paul Blum,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的任务和基于Transformer的模型Early-SIB，用于在青少年在线论坛上，在其明确表达自杀意念之前，预测其未来的自杀意念和行为（SIB）。


<details>
  <summary>Details</summary>
Motivation: 自杀是青少年死亡的主要原因，但预测自杀仍面临巨大挑战，许多案例因缺乏心理健康服务接触而未被发现。社交媒体为早期干预提供了独特机会，因为青少年常在线上实时分享想法和困扰。

Method: 提出了一种新颖的预测框架，即在用户尚未明确表达自杀意念时进行预测。引入了Early-SIB模型，这是一个基于Transformer的模型，它顺序处理用户撰写和参与的帖子，以预测他们是否会发布SIB帖子。

Result: Early-SIB模型在荷兰青少年论坛上预测未来SIB的平衡准确率达到0.73，表明此类工具可以有效补充传统预测方法。

Conclusion: 该研究证明，通过分析青少年在线论坛上的帖子，可以在他们明确表达自杀意念之前，有效地预测其未来的自杀意念和行为，为早期干预提供了有意义的工具。

Abstract: Suicide is a leading cause of death among adolescents (12-18), yet predicting
it remains a significant challenge. Many cases go undetected due to a lack of
contact with mental health services. Social media, however, offers a unique
opportunity, as young people often share their thoughts and struggles online in
real time. In this work, we propose a novel task and method to approach it:
predicting suicidal ideation and behavior (SIB) from forum posts before an
adolescent explicitly expresses suicidal ideation on an online forum. This
predictive framing, where no self-disclosure is used as input at any stage,
remains largely unexplored in the suicide prediction literature. To this end,
we introduce Early-SIB, a transformer-based model that sequentially processes
the posts a user writes and engages with to predict whether they will write a
SIB post. Our model achieves a balanced accuracy of 0.73 for predicting future
SIB on a Dutch youth forum, demonstrating that such tools can offer a
meaningful addition to traditional methods.

</details>


### [116] [Real-Time Detection of Hallucinated Entities in Long-Form Generation](https://arxiv.org/abs/2509.03531)
*Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda*

Main category: cs.CL

TL;DR: 本文提出了一种经济、可扩展的方法，用于实时识别大型语言模型长文本生成中的实体级幻觉（如虚构的名称、日期、引用），并将其成功应用于70B参数模型，性能优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗咨询、法律建议等高风险应用中被广泛使用，但其产生的幻觉可能导致严重危害。现有的幻觉检测方法要么局限于简短的事实查询，要么需要昂贵的外部验证，不适用于实际应用。

Method: 该方法针对实体级幻觉（如虚构的名称、日期、引用），将其映射到token级别的标签，从而实现流式检测。研究人员开发了一种利用网络搜索进行标注的方法，创建了一个带有接地标签的数据集，用于训练高效的幻觉分类器（例如线性探针）。

Result: 在四种模型家族上的评估显示，该分类器在长文本回复上始终优于基线方法（包括语义熵），并且在短文本问答设置中也有所改进（例如，Llama-3.3-70B的AUC从0.71提高到0.90）。尽管仅使用实体级标签进行训练，这些探针也能有效检测数学推理任务中的错误答案，表明其泛化能力。此外，一个模型标注的响应数据可用于训练其他模型的有效分类器。

Conclusion: 这项工作为可扩展、实际应用的幻觉检测提供了一种有前景的新方法。研究人员还公开了数据集以促进重用。

Abstract: Large language models are now routinely used in high-stakes applications
where hallucinations can cause serious harm, such as medical consultations or
legal advice. Existing hallucination detection methods, however, are
impractical for real-world use, as they are either limited to short factual
queries or require costly external verification. We present a cheap, scalable
method for real-time identification of hallucinated tokens in long-form
generations, and scale it effectively to 70B parameter models. Our approach
targets \emph{entity-level hallucinations} -- e.g., fabricated names, dates,
citations -- rather than claim-level, thereby naturally mapping to token-level
labels and enabling streaming detection. We develop an annotation methodology
that leverages web search to annotate model responses with grounded labels
indicating which tokens correspond to fabricated entities. This dataset enables
us to train effective hallucination classifiers with simple and efficient
methods such as linear probes. Evaluating across four model families, our
classifiers consistently outperform baselines on long-form responses, including
more expensive methods such as semantic entropy (e.g., AUC 0.90 vs 0.71 for
Llama-3.3-70B), and are also an improvement in short-form question-answering
settings. Moreover, despite being trained only with entity-level labels, our
probes effectively detect incorrect answers in mathematical reasoning tasks,
indicating generalization beyond entities. While our annotation methodology is
expensive, we find that annotated responses from one model can be used to train
effective classifiers on other models; accordingly, we publicly release our
datasets to facilitate reuse. Overall, our work suggests a promising new
approach for scalable, real-world hallucination detection.

</details>


### [117] [Topic Identification in LLM Input-Output Pairs through the Lens of Information Bottleneck](https://arxiv.org/abs/2509.03533)
*Igor Halperin*

Main category: cs.CL

TL;DR: 本文提出了一种名为UDIB的新型主题识别方法，它基于确定性信息瓶颈（DIB）并解决了现有语义差异度量（SDM）在检测大型语言模型（LLM）幻觉时主题识别的局限性，从而提供了一个更敏感的幻觉检测工具。


<details>
  <summary>Details</summary>
Motivation: 检测LLM的内在忠实性幻觉（即胡言乱语）的现有框架（如SDM）依赖于通过对句子嵌入进行几何聚类来识别提示和响应之间的潜在主题。然而，这些主题是为空间接近度优化的，而非为下游的信息理论分析优化，这导致了方法上的脱节。

Method: 本文通过将确定性信息瓶颈（DIB）方法转换为高维数据的实用算法，弥合了这一差距。具体来说，他们用一个计算效率高的上限替换了DIB中难以处理的KL散度项，从而得到了UDIB方法。UDIB可以被解释为K-means的一种熵正则化和鲁棒化版本，它本质上偏爱数量适中但信息量丰富的聚类。

Result: 通过将UDIB应用于LLM提示和响应嵌入的联合聚类，该方法生成了一个共享的主题表示，该表示不仅在空间上连贯，而且在根本上被构建为关于提示-响应关系的最大信息量。这为SDM框架提供了一个卓越的基础。

Conclusion: UDIB提供了一种新颖、更敏感的工具，用于检测LLM中的胡言乱语（幻觉），因为它能够生成最大化信息量的提示-响应关系主题表示。

Abstract: Large Language Models (LLMs) are prone to critical failure modes, including
\textit{intrinsic faithfulness hallucinations} (also known as confabulations),
where a response deviates semantically from the provided context. Frameworks
designed to detect this, such as Semantic Divergence Metrics (SDM), rely on
identifying latent topics shared between prompts and responses, typically by
applying geometric clustering to their sentence embeddings. This creates a
disconnect, as the topics are optimized for spatial proximity, not for the
downstream information-theoretic analysis. In this paper, we bridge this gap by
developing a principled topic identification method grounded in the
Deterministic Information Bottleneck (DIB) for geometric clustering. Our key
contribution is to transform the DIB method into a practical algorithm for
high-dimensional data by substituting its intractable KL divergence term with a
computationally efficient upper bound. The resulting method, which we dub UDIB,
can be interpreted as an entropy-regularized and robustified version of K-means
that inherently favors a parsimonious number of informative clusters. By
applying UDIB to the joint clustering of LLM prompt and response embeddings, we
generate a shared topic representation that is not merely spatially coherent
but is fundamentally structured to be maximally informative about the
prompt-response relationship. This provides a superior foundation for the SDM
framework and offers a novel, more sensitive tool for detecting confabulations.

</details>


### [118] [QuesGenie: Intelligent Multimodal Question Generation](https://arxiv.org/abs/2509.03535)
*Ahmed Mubarak,Amna Ahmed,Amira Nasser,Aya Mohamed,Fares El-Sadek,Mohammed Ahmed,Ahmed Salah,Youssef Sobhy*

Main category: cs.CL

TL;DR: 该项目开发了一个多模态问题生成系统，能够从各种内容格式中自动生成多样化的问题，以弥补学习资源与配套练习材料之间的差距。


<details>
  <summary>Details</summary>
Motivation: 在信息丰富的时代，学习者拥有大量教育资源，但缺乏与这些资源相匹配的实践材料是一个重大挑战。

Method: 该系统包含四个主要组件：多模态输入处理、问题生成、基于人类反馈的强化学习（RLHF）以及一个端到端交互式界面。

Result: 该项目为自动化、可扩展和智能的问题生成奠定了基础，并兼顾了资源效率、鲁棒功能和流畅的用户体验。

Conclusion: 该系统能够实现自动化、可扩展和智能的问题生成，有效解决教育资源与练习材料不匹配的问题，并提供良好的用户体验。

Abstract: In today's information-rich era, learners have access to abundant educational
resources, but the lack of practice materials tailored to these resources
presents a significant challenge. This project addresses that gap by developing
a multi-modal question generation system that can automatically generate
diverse question types from various content formats. The system features four
major components: multi-modal input handling, question generation,
reinforcement learning from human feedback (RLHF), and an end-to-end
interactive interface. This project lays the foundation for automated,
scalable, and intelligent question generation, carefully balancing resource
efficiency, robust functionality and a smooth user experience.

</details>


### [119] [AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models](https://arxiv.org/abs/2509.03537)
*Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang*

Main category: cs.CL

TL;DR: 本研究提出AR$^2$（Adversarial Reinforcement Learning for Abstract Reasoning）框架，通过对抗性强化学习显式训练大型语言模型（LLMs）的抽象推理能力，以解决其在代码生成中对抽象能力缺乏训练的问题，从而提高其在复杂编程任务上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 抽象能力是计算机科学的基础技能，对人类和LLMs都至关重要。尽管LLMs在代码生成方面取得了进展，但现有方法主要关注表面模式识别，忽视了对抽象能力的显式训练。

Method: AR$^2$框架包含一个教师模型和一个学生编码模型。教师模型将核心问题转换为叙述丰富但逻辑不变的复杂描述。学生编码模型则通过提取这些复杂叙述问题背后的计算核心来解决它们，从而在对抗性强化学习中提升抽象能力。

Result: 实验结果表明，AR$^2$显著提高了学生模型在以前未见的、具有挑战性的编程任务上的准确性。

Conclusion: 抽象能力是增强LLM泛化能力的关键技能。

Abstract: Abstraction--the ability to recognize and distill essential computational
patterns from complex problem statements--is a foundational skill in computer
science, critical both for human problem-solvers and coding-oriented large
language models (LLMs). Despite recent advances in training LLMs for code
generation using reinforcement learning (RL), most existing approaches focus
primarily on superficial pattern recognition, overlooking explicit training for
abstraction. In this study, we propose AR$^2$ (Adversarial Reinforcement
Learning for Abstract Reasoning), a novel framework explicitly designed to
enhance the abstraction abilities of LLMs. AR$^2$ employs a teacher model to
transform kernel problems into narrative-rich, challenging descriptions without
changing their fundamental logic. Simultaneously, a student coding model is
trained to solve these complex narrative problems by extracting their
underlying computational kernels. Experimental results demonstrate that AR$^2$
substantially improves the student model's accuracy on previously unseen,
challenging programming tasks, underscoring abstraction as a key skill for
enhancing LLM generalization.

</details>


### [120] [Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction](https://arxiv.org/abs/2509.03540)
*Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的框架，通过在推理时动态构建和扩展知识图谱（KG），整合LLM的内部知识和外部检索信息，以提高大型语言模型的事实准确性、答案精确性和可解释性，克服了现有RAG方法将知识视为非结构化文本的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）由于参数记忆的限制，常难以生成事实一致的答案。现有的检索增强生成（RAG）方法虽然引入外部知识，但通常将知识视为非结构化文本，这限制了它们支持组合推理和识别事实不一致的能力。

Method: 该方法在推理时动态构建和扩展知识图谱（KG），整合LLM内部知识和外部检索信息。具体步骤包括：首先通过提示从问题中提取一个种子KG，然后利用LLM的潜在知识进行迭代扩展，最后通过外部检索选择性地完善图谱，以增强事实覆盖并纠正不准确之处。

Result: 在三个不同的事实问答基准测试中，该方法在事实准确性、答案精确性和可解释性方面，均比基线提示和静态KG增强方法有显著改进。

Conclusion: 推理时构建知识图谱是增强LLM事实性一个有前景的方向，它能够以结构化、可解释和可扩展的方式实现这一目标。

Abstract: Large Language Models (LLMs) often struggle with producing factually
consistent answers due to limitations in their parametric memory.
Retrieval-Augmented Generation (RAG) methods address this issue by
incorporating external knowledge from trusted sources at inference time.
However, such methods typically treat knowledge as unstructured text, which
limits their ability to support compositional reasoning and identify factual
inconsistencies. To overcome these limitations, we propose a novel framework
that dynamically constructs and expands knowledge graphs (KGs) during
inference, integrating both internal knowledge extracted from LLMs and external
information retrieved from external sources. Our method begins by extracting a
seed KG from the question via prompting, followed by iterative expansion using
the LLM's latent knowledge. The graph is then selectively refined through
external retrieval, enhancing factual coverage and correcting inaccuracies. We
evaluate our approach on three diverse factual QA benchmarks, demonstrating
consistent improvements in factual accuracy, answer precision, and
interpretability over baseline prompting and static KG-augmented methods. Our
findings suggest that inference-time KG construction is a promising direction
for enhancing LLM factuality in a structured, interpretable, and scalable
manner.

</details>


### [121] [ResearchPulse: Building Method-Experiment Chains through Multi-Document Scientific Inference](https://arxiv.org/abs/2509.03565)
*Qi Chen,Jingxuan Wei,Zhuoya Yao,Haiguang Wang,Gaowei Wu,Bihui Yu,Siyuan Li,Cheng Tan*

Main category: cs.CL

TL;DR: 本文提出了一种名为“多文档科学推理”的新任务，旨在通过提取和对齐相关论文中的动机、方法和结果来重建研究发展链。为此，作者开发了ResearchPulse，一个基于代理的框架，并创建了ResearchPulse-Bench基准。实验表明，ResearchPulse在语义对齐、结构一致性和视觉保真度方面优于GPT-4o等强大基线。


<details>
  <summary>Details</summary>
Motivation: 理解科学思想的演变需要对主题相关的研究进行结构化、跨文档的推理，而不仅仅是总结单篇论文。现有方法难以实现跨论文的动机、方法和实验结果的提取与对齐，特别是松散结构化方法的时序对齐和异构实验表格的标准化。

Method: 本文将“多文档科学推理”形式化为一个新任务。提出ResearchPulse，一个基于代理的框架，整合了指令规划、科学内容提取和结构化可视化。它包含三个协调代理：Plan Agent（任务分解）、Mmap-Agent（构建动机-方法思维导图）和Lchart-Agent（合成实验折线图）。为支持此任务，还引入了ResearchPulse-Bench，一个包含标注论文集群的引用感知基准。

Result: 实验结果表明，ResearchPulse系统（尽管使用7B规模的代理）在语义对齐、结构一致性和视觉保真度方面，持续优于GPT-4o等强大的基线模型。

Conclusion: ResearchPulse框架及其基于代理的方法有效地解决了多文档科学推理任务中的关键挑战，能够重建科学研究的发展链条，并且在性能上超越了大型语言模型，证明了其在理解科学思想演变方面的优越性。

Abstract: Understanding how scientific ideas evolve requires more than summarizing
individual papers-it demands structured, cross-document reasoning over
thematically related research. In this work, we formalize multi-document
scientific inference, a new task that extracts and aligns motivation,
methodology, and experimental results across related papers to reconstruct
research development chains. This task introduces key challenges, including
temporally aligning loosely structured methods and standardizing heterogeneous
experimental tables. We present ResearchPulse, an agent-based framework that
integrates instruction planning, scientific content extraction, and structured
visualization. It consists of three coordinated agents: a Plan Agent for task
decomposition, a Mmap-Agent that constructs motivation-method mind maps, and a
Lchart-Agent that synthesizes experimental line charts. To support this task,
we introduce ResearchPulse-Bench, a citation-aware benchmark of annotated paper
clusters. Experiments show that our system, despite using 7B-scale agents,
consistently outperforms strong baselines like GPT-4o in semantic alignment,
structural consistency, and visual fidelity. The dataset are available in
https://huggingface.co/datasets/ResearchPulse/ResearchPulse-Bench.

</details>


### [122] [NoteBar: An AI-Assisted Note-Taking System for Personal Knowledge Management](https://arxiv.org/abs/2509.03610)
*Josh Wisoff,Yao Tang,Zhengyu Fang,Jordan Guzman,YuTang Wang,Alex Yu*

Main category: cs.CL

TL;DR: 本文介绍了NoteBar，一个利用人格信息和高效语言模型自动分类笔记的AI辅助笔记工具，并发布了一个包含3,173条笔记和8,494个概念的MBTI人格条件数据集，旨在提升AI辅助个人知识管理的效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 笔记记录在学术和专业环境中至关重要，但现有AI辅助工具在效率方面存在不足，无法有效支持用户工作流程。

Method: 开发了NoteBar，一个AI辅助笔记工具，它利用人格信息和高效语言模型自动将笔记组织到多个类别中。同时，引入了一个包含3,173条笔记和8,494个概念的、基于16种MBTI人格的新型数据集。此外，NoteBar的设计注重实用性和成本效益，无需重型基础设施即可部署。

Result: NoteBar能够高效地自动组织笔记，更好地支持用户工作流程。所创建的人格条件数据集为下游任务提供了多样性和语义丰富性。NoteBar的部署方式实用且经济高效，能够实现交互式使用。

Conclusion: NoteBar及其配套数据集为推进AI辅助个人知识管理提供了一个可扩展和可扩展的基础。

Abstract: Note-taking is a critical practice for capturing, organizing, and reflecting
on information in both academic and professional settings. The recent success
of large language models has accelerated the development of AI-assisted tools,
yet existing solutions often struggle with efficiency. We present NoteBar, an
AI-assisted note-taking tool that leverages persona information and efficient
language models to automatically organize notes into multiple categories and
better support user workflows. To support research and evaluation in this
space, we further introduce a novel persona-conditioned dataset of 3,173 notes
and 8,494 annotated concepts across 16 MBTI personas, offering both diversity
and semantic richness for downstream tasks. Finally, we demonstrate that
NoteBar can be deployed in a practical and cost-effective manner, enabling
interactive use without reliance on heavy infrastructure. Together, NoteBar and
its accompanying dataset provide a scalable and extensible foundation for
advancing AI-assisted personal knowledge management.

</details>


### [123] [E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition](https://arxiv.org/abs/2509.03615)
*Aryan Gupta,Anupam Purwar*

Main category: cs.CL

TL;DR: 本文介绍了一种名为Sprinklr-Edge-OCR的边缘优化传统OCR系统，并将其与五种先进的大型视觉-语言模型（LVLMs）和另一种传统OCR系统在一个多语言数据集上进行了大规模比较评估。研究发现，尽管LVLMs在某些指标上表现出色，但传统OCR系统在边缘部署场景下，尤其是在效率和成本方面，表现更为优越。


<details>
  <summary>Details</summary>
Motivation: 多语言、嘈杂和多样化的真实世界图像中的光学字符识别（OCR）仍然是一个重大挑战。随着大型视觉-语言模型（LVLMs）的兴起，人们对其超越固定OCR管道的泛化和推理能力越来越感兴趣。然而，在资源受限的边缘环境中部署这些模型的适用性尚未明确。

Method: 本文引入了Sprinklr-Edge-OCR，一个专为资源受限边缘部署优化的新型OCR系统。研究在一个专有的、经过双重人工标注的54种语言的多语言图像数据集上，对五种最先进的LVLMs（InternVL, Qwen, GOT OCR, LLaMA, MiniCPM）和两种传统OCR系统（Sprinklr-Edge-OCR, SuryaOCR）进行了大规模比较评估。评估涵盖了准确性、语义一致性、语言覆盖率、计算效率（延迟、内存、GPU使用）和部署成本等一系列指标。此外，还进行了仅限CPU环境下的边缘部署分析。

Result: 在评估结果中，Qwen取得了最高的精度（0.54），而Sprinklr-Edge-OCR则获得了最佳的整体F1分数（0.46）。与LVLM相比，Sprinklr-Edge-OCR在效率上表现更佳，处理图像速度快35倍（平均每张图像0.17秒），成本也低了不到0.01倍（每1000张图像0.006美元）。

Conclusion: 研究结果表明，即使在大型语言模型时代，由于传统OCR系统具有低计算需求、低延迟和极高的经济性，它们仍然是边缘部署最理想的OCR系统。

Abstract: Optical Character Recognition (OCR) in multilingual, noisy, and diverse
real-world images remains a significant challenge for optical character
recognition systems. With the rise of Large Vision-Language Models (LVLMs),
there is growing interest in their ability to generalize and reason beyond
fixed OCR pipelines. In this work, we introduce Sprinklr-Edge-OCR, a novel OCR
system built specifically optimized for edge deployment in resource-constrained
environments. We present a large-scale comparative evaluation of five
state-of-the-art LVLMs (InternVL, Qwen, GOT OCR, LLaMA, MiniCPM) and two
traditional OCR systems (Sprinklr-Edge-OCR, SuryaOCR) on a proprietary, doubly
hand annotated dataset of multilingual (54 languages) images. Our benchmark
covers a broad range of metrics including accuracy, semantic consistency,
language coverage, computational efficiency (latency, memory, GPU usage), and
deployment cost. To better reflect real-world applicability, we also conducted
edge case deployment analysis, evaluating model performance on CPU only
environments. Among the results, Qwen achieved the highest precision (0.54),
while Sprinklr-Edge-OCR delivered the best overall F1 score (0.46) and
outperformed others in efficiency, processing images 35 faster (0.17 seconds
per image on average) and at less than 0.01 of the cost (0.006 USD per 1,000
images) compared to LVLM. Our findings demonstrate that the most optimal OCR
systems for edge deployment are the traditional ones even in the era of LLMs
due to their low compute requirements, low latency, and very high
affordability.

</details>


### [124] [Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators](https://arxiv.org/abs/2509.03647)
*Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Jou Barzdukas,Simon Fu,Narmeen Oozeer*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）作为评估器存在“自我偏好偏差”，本研究发现轻量级转向向量可以在推理时显著减少高达97%的“无理由自我偏好偏差”，但对“合理自我偏好”和“无偏见一致性”不稳定，表明该偏差复杂且需要更强大的干预措施。


<details>
  <summary>Details</summary>
Motivation: LLMs作为自动评估器越来越普遍，但其“自我偏好偏差”——倾向于偏爱自己的输出——损害了评估流程的公平性和可靠性，尤其是在偏好调整和模型路由等任务中。

Method: 研究人员调查了在推理时使用轻量级转向向量（无需重新训练）来缓解偏差。他们构建了一个专门的数据集，将自我偏好偏差分为“合理自我偏好”和“无理由自我偏好”。转向向量通过两种方法构建：对比激活添加（CAA）和一种基于优化的方法。

Result: 结果显示，转向向量可以将“无理由自我偏好偏差”减少高达97%，显著优于提示工程和直接偏好优化基线。然而，转向向量在处理“合理自我偏好”和“无偏见一致性”时表现不稳定。

Conclusion: 转向向量作为LLM评估器的保护措施，既有潜力也有局限性，这表明自我偏好偏差涉及多重或非线性方向。这促使需要更强大的干预措施来解决这一问题。

Abstract: Large language models (LLMs) increasingly serve as automated evaluators, yet
they suffer from "self-preference bias": a tendency to favor their own outputs
over those of other models. This bias undermines fairness and reliability in
evaluation pipelines, particularly for tasks like preference tuning and model
routing. We investigate whether lightweight steering vectors can mitigate this
problem at inference time without retraining. We introduce a curated dataset
that distinguishes self-preference bias into justified examples of
self-preference and unjustified examples of self-preference, and we construct
steering vectors using two methods: Contrastive Activation Addition (CAA) and
an optimization-based approach. Our results show that steering vectors can
reduce unjustified self-preference bias by up to 97\%, substantially
outperforming prompting and direct preference optimization baselines. Yet
steering vectors are unstable on legitimate self-preference and unbiased
agreement, implying self-preference spans multiple or nonlinear directions.
This underscores both their promise and limits as safeguards for LLM-as-judges
and motivates more robust interventions.

</details>


### [125] [Semantic Analysis of SNOMED CT Concept Co-occurrences in Clinical Documentation using MIMIC-IV](https://arxiv.org/abs/2509.03662)
*Ali Noori,Somya Mohanty,Prashanti Manda*

Main category: cs.CL

TL;DR: 本研究利用MIMIC-IV数据库，探索SNOMED CT概念的共现模式与基于嵌入的语义相似性之间的关系，发现两者虽弱相关，但嵌入能捕捉临床上有意义的关联，并可用于补充临床注释、揭示潜在关系和支持决策。


<details>
  <summary>Details</summary>
Motivation: 临床笔记包含丰富的叙述但格式非结构化，难以大规模分析。标准化术语如SNOMED CT虽能提高互操作性，但概念间的共现和语义相似性关系尚未被充分探索。

Method: 研究利用MIMIC-IV数据库，结合SNOMED CT概念。采用归一化点互信息（NPMI）分析共现模式，并使用预训练嵌入（如ClinicalBERT、BioBERT）计算语义相似性。分析内容包括共现与语义相似性的相关性、嵌入对缺失概念的建议能力、以及这些关系随时间和专业的变化。

Result: 分析显示，共现和语义相似性之间存在弱相关性，但嵌入能捕捉到临床上有意义的关联，这些关联不总是体现在文档频率中。基于嵌入的建议经常与后来记录的概念相符。概念嵌入的聚类产生了连贯的临床主题（症状、实验室检查、诊断、心血管疾病），这些主题与患者表型和护理模式相对应。此外，与死亡率和再入院等结果相关的共现模式也证明了该方法的实用性。

Conclusion: 研究结果强调了共现统计和语义嵌入在提高文档完整性、揭示潜在临床关系以及为决策支持和表型分析应用提供信息方面的互补价值。

Abstract: Clinical notes contain rich clinical narratives but their unstructured format
poses challenges for large-scale analysis. Standardized terminologies such as
SNOMED CT improve interoperability, yet understanding how concepts relate
through co-occurrence and semantic similarity remains underexplored. In this
study, we leverage the MIMIC-IV database to investigate the relationship
between SNOMED CT concept co-occurrence patterns and embedding-based semantic
similarity. Using Normalized Pointwise Mutual Information (NPMI) and pretrained
embeddings (e.g., ClinicalBERT, BioBERT), we examine whether frequently
co-occurring concepts are also semantically close, whether embeddings can
suggest missing concepts, and how these relationships evolve temporally and
across specialties. Our analyses reveal that while co-occurrence and semantic
similarity are weakly correlated, embeddings capture clinically meaningful
associations not always reflected in documentation frequency. Embedding-based
suggestions frequently matched concepts later documented, supporting their
utility for augmenting clinical annotations. Clustering of concept embeddings
yielded coherent clinical themes (symptoms, labs, diagnoses, cardiovascular
conditions) that map to patient phenotypes and care patterns. Finally,
co-occurrence patterns linked to outcomes such as mortality and readmission
demonstrate the practical utility of this approach. Collectively, our findings
highlight the complementary value of co-occurrence statistics and semantic
embeddings in improving documentation completeness, uncovering latent clinical
relationships, and informing decision support and phenotyping applications.

</details>


### [126] [MLSD: A Novel Few-Shot Learning Approach to Enhance Cross-Target and Cross-Domain Stance Detection](https://arxiv.org/abs/2509.03725)
*Parush Gera,Tempestt Neal*

Main category: cs.CL

TL;DR: 本文提出MLSD（Metric Learning-Based Few-Shot Learning for Cross-Target and Cross-Domain Stance Detection），一种基于度量学习的少样本方法，用于跨领域和跨目标立场检测，显著提升了现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决跨领域和跨目标立场检测的挑战，提升其在不同目标和领域间的泛化能力和检测性能。

Method: MLSD方法利用度量学习（Metric Learning）结合三重态损失（Triplet Loss）来捕获立场目标之间的语义相似性和差异。通过构建一个判别性嵌入空间，MLSD使跨目标或跨领域立场检测模型能够从新的目标领域获取有用的样本，从而增强领域适应性。

Result: 在两个数据集的多个跨目标和跨领域场景中对MLSD进行了评估。结果表明，MLSD在六种广泛使用的立场检测模型上均实现了统计学上显著的性能提升。

Conclusion: MLSD是一种新颖且有效的跨目标和跨领域立场检测方法，能够通过度量学习显著提升现有立场检测模型的性能。

Abstract: We present the novel approach for stance detection across domains and
targets, Metric Learning-Based Few-Shot Learning for Cross-Target and
Cross-Domain Stance Detection (MLSD). MLSD utilizes metric learning with
triplet loss to capture semantic similarities and differences between stance
targets, enhancing domain adaptation. By constructing a discriminative
embedding space, MLSD allows a cross-target or cross-domain stance detection
model to acquire useful examples from new target domains. We evaluate MLSD in
multiple cross-target and cross-domain scenarios across two datasets, showing
statistically significant improvement in stance detection performance across
six widely used stance detection models.

</details>


### [127] [SiLVERScore: Semantically-Aware Embeddings for Sign Language Generation Evaluation](https://arxiv.org/abs/2509.03791)
*Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani*

Main category: cs.CL

TL;DR: 本文提出了一种名为SiLVERScore的新型语义感知嵌入式评估指标，用于手语生成，解决了传统回译方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有手语生成评估方法（回译）存在歧义：它无法捕捉手语的多模态特性（如面部表情、空间语法、韵律），也难以区分评估错误是来自生成模型还是翻译系统。

Method: 本文提出SiLVERScore，这是一种新颖的、基于语义感知的嵌入式评估指标，用于在联合嵌入空间中评估手语生成。研究包括识别现有指标的局限性，引入SiLVERScore，证明其对语义和韵律变化的鲁棒性，并探索其在不同数据集上的泛化挑战。

Result: 在PHOENIX-14T和CSL-Daily数据集上，SiLVERScore在正确和随机配对之间实现了近乎完美的区分（ROC AUC = 0.99，重叠 < 7%），显著优于传统指标。

Conclusion: SiLVERScore为手语生成提供了一种更鲁棒、语义感知更强的评估方法，有效克服了传统回译评估的不足，并在区分生成手语方面表现出卓越性能。

Abstract: Evaluating sign language generation is often done through back-translation,
where generated signs are first recognized back to text and then compared to a
reference using text-based metrics. However, this two-step evaluation pipeline
introduces ambiguity: it not only fails to capture the multimodal nature of
sign language-such as facial expressions, spatial grammar, and prosody-but also
makes it hard to pinpoint whether evaluation errors come from sign generation
model or the translation system used to assess it. In this work, we propose
SiLVERScore, a novel semantically-aware embedding-based evaluation metric that
assesses sign language generation in a joint embedding space. Our contributions
include: (1) identifying limitations of existing metrics, (2) introducing
SiLVERScore for semantically-aware evaluation, (3) demonstrating its robustness
to semantic and prosodic variations, and (4) exploring generalization
challenges across datasets. On PHOENIX-14T and CSL-Daily datasets, SiLVERScore
achieves near-perfect discrimination between correct and random pairs (ROC AUC
= 0.99, overlap < 7%), substantially outperforming traditional metrics.

</details>


### [128] [Measuring How (Not Just Whether) VLMs Build Common Ground](https://arxiv.org/abs/2509.03805)
*Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani*

Main category: cs.CL

TL;DR: 本研究引入了一个四度量标准套件，用于评估大型视觉语言模型（VLMs）在交互式接地（grounding）上下文中的表现，发现现有模型与人类模式存在显著差异，且任务成功与接地质量并非直接关联。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试主要在单轮或问答设置中评估VLMs的推理能力，但接地是一个互动过程，涉及通过持续沟通逐步建立共享理解。现有评估方法未能充分捕捉VLM在交互式接地中的表现。

Method: 研究引入了一个包含四个度量标准（接地效率、内容对齐、词汇适应和类人性）的套件。该套件被应用于三个专有VLM之间的150次交互式指称游戏自玩会话，并与人类配对进行比较。

Result: 所有三个模型在至少三个度量标准上都与人类模式存在差异，其中GPT4o-mini总体上最接近人类。研究发现，任务成功分数并不能表明成功的接地，并且高的图像-话语对齐也并不一定预示着任务成功。

Conclusion: 本研究提出的度量标准套件和发现为未来VLM接地能力的研究提供了一个框架，并强调了在交互式语境中评估VLM时需要更细致的视角。

Abstract: Large vision language models (VLMs) increasingly claim reasoning skills, yet
current benchmarks evaluate them in single-turn or question answering settings.
However, grounding is an interactive process in which people gradually develop
shared understanding through ongoing communication. We introduce a four-metric
suite (grounding efficiency, content alignment, lexical adaptation, and
human-likeness) to systematically evaluate VLM performance in interactive
grounding contexts. We deploy the suite on 150 self-play sessions of
interactive referential games between three proprietary VLMs and compare them
with human dyads. All three models diverge from human patterns on at least
three metrics, while GPT4o-mini is the closest overall. We find that (i) task
success scores do not indicate successful grounding and (ii) high
image-utterance alignment does not necessarily predict task success. Our metric
suite and findings offer a framework for future research on VLM grounding.

</details>


### [129] [Align-then-Slide: A complete evaluation framework for Ultra-Long Document-Level Machine Translation](https://arxiv.org/abs/2509.03809)
*Jiaxin Guo,Daimeng Wei,Yuanchang Luo,Xiaoyu Chen,Zhanglin Wu,Huan Yang,Hengchao Shang,Zongyao Li,Zhiqiang Rao,Jinlong Yang,Hao Yang*

Main category: cs.CL

TL;DR: 本文提出了一种名为“先对齐后滑动”（Align-then-Slide）的文档级机器翻译（doc-mt）评估框架，旨在解决大型语言模型（LLMs）生成整文档输出时现有评估方法面临的对齐挑战，并经验证其准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在文档级机器翻译（doc-mt）方面开创了新纪元，但其整文档输出使得依赖逐句对齐的现有评估方法面临挑战，尤其是在处理句子遗漏、多对一或一对多映射时。

Method: 本文提出了“先对齐后滑动”（Align-then-Slide）评估框架：
1.  **对齐阶段（Align stage）**：自动推断句子级别的源-目标对应关系，并重建目标文本以匹配源文本的句子数量，从而解决遗漏以及多对一/一对多映射问题。
2.  **N块滑动评估阶段（n-Chunk Sliding Evaluate stage）**：在1、2、3和4块粒度下计算平均度量分数，以实现多粒度评估。

Result: 1.  在WMT基准测试上，该方法与专家MQM排名之间的皮尔逊相关系数高达0.929。
2.  在一个新策展的真实世界测试集上，该方法的结果也与人类判断高度一致。
3.  “先对齐后滑动”生成的偏好数据能够有效支持CPO训练，并可直接用作GRPO的奖励模型，两者生成的译文均优于香草SFT基线。

Conclusion: 研究结果验证了“先对齐后滑动”框架是文档级机器翻译系统一个准确、鲁棒且可操作的评估工具。

Abstract: Large language models (LLMs) have ushered in a new era for document-level
machine translation (\textit{doc}-mt), yet their whole-document outputs
challenge existing evaluation methods that assume sentence-by-sentence
alignment. We introduce \textit{\textbf{Align-then-Slide}}, a complete
evaluation framework for ultra-long doc-mt. In the Align stage, we
automatically infer sentence-level source-target correspondences and rebuild
the target to match the source sentence number, resolving omissions and
many-to-one/one-to-many mappings. In the n-Chunk Sliding Evaluate stage, we
calculate averaged metric scores under 1-, 2-, 3- and 4-chunk for
multi-granularity assessment. Experiments on the WMT benchmark show a Pearson
correlation of 0.929 between our method with expert MQM rankings. On a newly
curated real-world test set, our method again aligns closely with human
judgments. Furthermore, preference data produced by Align-then-Slide enables
effective CPO training and its direct use as a reward model for GRPO, both
yielding translations preferred over a vanilla SFT baseline. The results
validate our framework as an accurate, robust, and actionable evaluation tool
for doc-mt systems.

</details>


### [130] [NE-PADD: Leveraging Named Entity Knowledge for Robust Partial Audio Deepfake Detection via Attention Aggregation](https://arxiv.org/abs/2509.03829)
*Huhong Xian,Rui Liu,Berrak Sisman,Haizhou Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为NE-PADD的新方法，用于局部音频深度伪造检测（PADD），通过结合命名实体知识和两种注意力聚合机制，实现了对伪造语音的帧级定位，并超越了现有基线。


<details>
  <summary>Details</summary>
Motivation: 传统的音频深度伪造检测（ADD）是句子级别的，而局部音频深度伪造检测（PADD）需要帧级定位伪造语音。在PADD领域，利用音频中的语义信息，特别是命名实体，仍然是一个未被充分探索的方面。

Method: NE-PADD方法通过两个并行分支（语音命名实体识别SpeechNER和PADD）来利用命名实体知识。它结合了两种注意力聚合机制：注意力融合（AF）用于组合注意力权重，以及注意力转移（AT）通过辅助损失利用命名实体语义指导PADD。该方法在PartialSpoof-NER数据集上进行构建和评估。

Result: 实验结果表明，NE-PADD方法优于现有基线，证明了将命名实体知识整合到PADD中的有效性。

Conclusion: 将命名实体知识有效地整合到局部音频深度伪造检测（PADD）中，可以显著提升检测性能，实现伪造语音的精确帧级定位。

Abstract: Different from traditional sentence-level audio deepfake detection (ADD),
partial audio deepfake detection (PADD) requires frame-level positioning of the
location of fake speech. While some progress has been made in this area,
leveraging semantic information from audio, especially named entities, remains
an underexplored aspect. To this end, we propose NE-PADD, a novel method for
Partial Audio Deepfake Detection (PADD) that leverages named entity knowledge
through two parallel branches: Speech Name Entity Recognition (SpeechNER) and
PADD. The approach incorporates two attention aggregation mechanisms: Attention
Fusion (AF) for combining attention weights and Attention Transfer (AT) for
guiding PADD with named entity semantics using an auxiliary loss. Built on the
PartialSpoof-NER dataset, experiments show our method outperforms existing
baselines, proving the effectiveness of integrating named entity knowledge in
PADD. The code is available at https://github.com/AI-S2-Lab/NE-PADD.

</details>


### [131] [Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth](https://arxiv.org/abs/2509.03867)
*Yang Wang,Chenghao Xiao,Chia-Yi Hsiao,Zi Yan Chang,Chi-Li Chen,Tyler Loakman,Chenghua Lin*

Main category: cs.CL

TL;DR: 本文引入了“Drivelology”这一语言现象，即“有深度的胡言乱语”，并发现大型语言模型（LLMs）无法理解其深层语义。研究构建了一个多语言基准数据集，评估了LLMs在分类、生成和推理任务上的表现，结果表明LLMs在语用理解上存在明显局限。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在许多NLP任务中表现出色，但它们未能理解“Drivelology”这种表面上无意义但却包含隐式含义的语言现象。研究旨在探究LLMs在处理这种需要上下文推断、道德推理或情感解释的复杂语义时的局限性。

Method: 研究构建了一个包含1200多个精心策划的多语言（英、普、西、法、日、韩）Drivelology示例的基准数据集。数据集的标注经过专家多轮审查和裁定。随后，研究评估了一系列LLMs在Drivelology的分类、生成和推理任务上的表现。

Result: 评估结果揭示了LLMs的明显局限性：模型经常将Drivelology与浅层无意义内容混淆，给出不连贯的解释，或完全未能理解其隐含的修辞功能。

Conclusion: 这些发现表明LLMs在语用理解方面存在深层的表征差距，并挑战了“统计流畅性等同于认知理解”的假设。研究发布了数据集和代码，以促进对超越表面连贯性的语言深度建模的进一步研究。

Abstract: We introduce Drivelology, a unique linguistic phenomenon characterised as
"nonsense with depth", utterances that are syntactically coherent yet
pragmatically paradoxical, emotionally loaded, or rhetorically subversive.
While such expressions may resemble surface-level nonsense, they encode
implicit meaning requiring contextual inference, moral reasoning, or emotional
interpretation. We find that current large language models (LLMs), despite
excelling at many natural language processing (NLP) tasks, consistently fail to
grasp the layered semantics of Drivelological text. To investigate this, we
construct a small but diverse benchmark dataset of over 1,200 meticulously
curated examples, with select instances in English, Mandarin, Spanish, French,
Japanese, and Korean. Annotation was especially challenging: each of the
examples required careful expert review to verify that it truly reflected
Drivelological characteristics. The process involved multiple rounds of
discussion and adjudication to address disagreements, highlighting the subtle
and subjective nature of the Drivelology. We evaluate a range of LLMs on
classification, generation, and reasoning tasks. Our results reveal clear
limitations of LLMs: models often confuse Drivelology with shallow nonsense,
produce incoherent justifications, or miss the implied rhetorical function
altogether. These findings highlight a deeper representational gap in LLMs'
pragmatic understanding and challenge the assumption that statistical fluency
implies cognitive comprehension. We release our dataset and code to facilitate
further research in modelling linguistic depth beyond surface-level coherence.

</details>


### [132] [A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models](https://arxiv.org/abs/2509.03871)
*Yanbo Wang,Yongcan Yu,Jian Liang,Ran He*

Main category: cs.CL

TL;DR: 本文综述了CoT（思维链）推理对大型语言模型（LLM）可信度的影响，重点关注真实性、安全性、鲁棒性、公平性和隐私性。


<details>
  <summary>Details</summary>
Motivation: 尽管CoT推理显著提升了LLM在多项任务上的性能和可解释性，但其对模型可信度的影响仍缺乏全面理解。

Method: 本文通过对近期关于推理模型和CoT技术的研究进行综述，从真实性、安全性、鲁棒性、公平性和隐私性五个核心维度进行分析。研究按时间顺序概述了相关工作，并详细分析了其方法、发现和局限性。

Result: CoT推理技术有望通过缓解幻觉、检测有害内容和提高鲁棒性来增强模型可信度。然而，尖端推理模型本身在安全性、鲁棒性和隐私性方面往往存在相似甚至更大的漏洞。

Conclusion: 推理技术在增强LLM可信度方面具有潜力，但当前的推理模型在安全性、鲁棒性和隐私性方面也面临显著挑战。本研究旨在为AI安全社区提供一个及时且有价值的资源，以了解推理可信度领域的最新进展。

Abstract: The development of Long-CoT reasoning has advanced LLM performance across
various tasks, including language understanding, complex problem solving, and
code generation. This paradigm enables models to generate intermediate
reasoning steps, thereby improving both accuracy and interpretability. However,
despite these advancements, a comprehensive understanding of how CoT-based
reasoning affects the trustworthiness of language models remains
underdeveloped. In this paper, we survey recent work on reasoning models and
CoT techniques, focusing on five core dimensions of trustworthy reasoning:
truthfulness, safety, robustness, fairness, and privacy. For each aspect, we
provide a clear and structured overview of recent studies in chronological
order, along with detailed analyses of their methodologies, findings, and
limitations. Future research directions are also appended at the end for
reference and discussion. Overall, while reasoning techniques hold promise for
enhancing model trustworthiness through hallucination mitigation, harmful
content detection, and robustness improvement, cutting-edge reasoning models
themselves often suffer from comparable or even greater vulnerabilities in
safety, robustness, and privacy. By synthesizing these insights, we hope this
work serves as a valuable and timely resource for the AI safety community to
stay informed on the latest progress in reasoning trustworthiness. A full list
of related papers can be found at
\href{https://github.com/ybwang119/Awesome-reasoning-safety}{https://github.com/ybwang119/Awesome-reasoning-safety}.

</details>


### [133] [False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize](https://arxiv.org/abs/2509.03888)
*Cheng Wang,Zeming Wei,Qin Liu,Muhao Chen*

Main category: cs.CL

TL;DR: 研究发现，现有基于探测的LLM安全检测方法可能学习到表面模式而非真正的语义有害性，导致虚假安全感，需要重新设计模型和评估协议。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）能力强大，但它们能够遵循有害指令，引发严重安全担忧。现有研究利用基于探测的方法来研究恶意和良性输入在LLM内部表示中的可分离性，并提出用这些方法进行安全检测。然而，这些方法在域外（OOD）性能不佳，促使作者假设探测器学习的是表面模式而非语义有害性。

Method: 本研究系统性地重新审视了基于探测的范式。通过一系列受控实验，包括将简单n-gram方法的性能与探测器进行比较、在语义清理的数据集上进行实验以及详细分析模式依赖性，来确认探测器学习的特定模式（指令模式和触发词）并验证其假设。

Result: 实验证实了探测器学习的是表面的指令模式和触发词，而非语义有害性。简单n-gram方法能达到与探测器相当的性能。这些结果揭示了当前基于探测的方法所带来的虚假安全感。

Conclusion: 当前基于探测的LLM安全检测方法存在根本性缺陷，未能学习到语义上的有害性。因此，迫切需要重新设计LLM模型和评估协议，以实现更负责任和有效的安全研究。

Abstract: Large Language Models (LLMs) can comply with harmful instructions, raising
serious safety concerns despite their impressive capabilities. Recent work has
leveraged probing-based approaches to study the separability of malicious and
benign inputs in LLMs' internal representations, and researchers have proposed
using such probing methods for safety detection. We systematically re-examine
this paradigm. Motivated by poor out-of-distribution performance, we
hypothesize that probes learn superficial patterns rather than semantic
harmfulness. Through controlled experiments, we confirm this hypothesis and
identify the specific patterns learned: instructional patterns and trigger
words. Our investigation follows a systematic approach, progressing from
demonstrating comparable performance of simple n-gram methods, to controlled
experiments with semantically cleaned datasets, to detailed analysis of pattern
dependencies. These results reveal a false sense of security around current
probing-based approaches and highlight the need to redesign both models and
evaluation protocols, for which we provide further discussions in the hope of
suggesting responsible further research in this direction. We have open-sourced
the project at https://github.com/WangCheng0116/Why-Probe-Fails.

</details>


### [134] [MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation](https://arxiv.org/abs/2509.03891)
*Gowen Loo,Chang Liu,Qinghong Yin,Xiang Chen,Jiawei Chen,Jingyuan Zhang,Yu Tian*

Main category: cs.CL

TL;DR: 本文提出了MobileRAG，一个基于检索增强生成（RAG）的移动智能体框架，旨在解决现有LLM驱动移动智能体在理解、环境交互和记忆方面的不足，并在复杂真实世界任务上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型（LLM）的移动智能体存在以下问题：1) 过度依赖LLM的理解能力，易导致操作错误或遗漏步骤；2) 缺乏与外部环境的交互，当应用无法满足需求时任务终止；3) 缺乏记忆能力，每次指令都需要重建界面且无法从错误中学习和纠正。

Method: 本文提出MobileRAG，一个通过检索增强生成（RAG）强化的移动智能体框架，包含InterRAG、LocalRAG和MemRAG。它利用RAG更快速准确地识别用户查询并完成复杂长序列移动任务。此外，还引入了MobileRAG-Eval，一个包含大量复杂真实世界任务且需要外部知识辅助的更具挑战性的基准来评估MobileRAG的性能。

Result: 在MobileRAG-Eval上的广泛实验结果表明，MobileRAG能够轻松处理真实世界移动任务，相比最先进的方法实现了10.3%的性能提升，并且操作步骤更少。

Conclusion: MobileRAG通过引入RAG有效缓解了现有LLM驱动移动智能体在理解、环境交互和记忆方面的不足，使其能够更高效、准确地完成复杂真实的移动任务。

Abstract: Smartphones have become indispensable in people's daily lives, permeating
nearly every aspect of modern society. With the continuous advancement of large
language models (LLMs), numerous LLM-based mobile agents have emerged. These
agents are capable of accurately parsing diverse user queries and automatically
assisting users in completing complex or repetitive operations. However,
current agents 1) heavily rely on the comprehension ability of LLMs, which can
lead to errors caused by misoperations or omitted steps during tasks, 2) lack
interaction with the external environment, often terminating tasks when an app
cannot fulfill user queries, and 3) lack memory capabilities, requiring each
instruction to reconstruct the interface and being unable to learn from and
correct previous mistakes. To alleviate the above issues, we propose MobileRAG,
a mobile agents framework enhanced by Retrieval-Augmented Generation (RAG),
which includes InterRAG, LocalRAG, and MemRAG. It leverages RAG to more quickly
and accurately identify user queries and accomplish complex and long-sequence
mobile tasks. Additionally, to more comprehensively assess the performance of
MobileRAG, we introduce MobileRAG-Eval, a more challenging benchmark
characterized by numerous complex, real-world mobile tasks that require
external knowledge assistance. Extensive experimental results on MobileRAG-Eval
demonstrate that MobileRAG can easily handle real-world mobile tasks, achieving
10.3\% improvement over state-of-the-art methods with fewer operational steps.
Our code is publicly available at:
https://github.com/liuxiaojieOutOfWorld/MobileRAG_arxiv

</details>


### [135] [MTQA:Matrix of Thought for Enhanced Reasoning in Complex Question Answering](https://arxiv.org/abs/2509.03918)
*Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao*

Main category: cs.CL

TL;DR: 本文提出了Matrix of Thought (MoT) 和事实纠正机制，构建了一个高效准确的问答框架MTQA，显著提升了大型语言模型在复杂问答任务中的推理能力和效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂抽象问答任务中因推理能力不足而表现不佳。现有的CoT和ToT方法存在冗余或路径单一的问题，而RAG方法难以有效利用大量涉及多实体和多跳的信息。

Method: 本文提出了Matrix of Thought (MoT)，这是一种新颖的LLM思维结构，通过“列-单元格通信”机制在水平和垂直维度上探索问题，实现多策略、深层次思考，减少冗余并增强推理能力。此外，还开发了一个事实纠正机制，通过从知识图谱三元组和原始文本构建知识单元来增强初始知识并纠正错误答案，最终形成高效准确的MTQA框架。

Result: 实验结果表明，MTQA框架在四个广泛使用的数据集上，F1和EM分数均优于最先进的方法。同时，其推理时间仅为基线方法的14.4%。

Conclusion: MTQA框架通过结合Matrix of Thought和事实纠正机制，显著提高了大型语言模型在复杂问答任务中的准确性和推理效率，证明了其优越性。

Abstract: Complex Question Answering (QA) is a fundamental and challenging task in NLP.
While large language models (LLMs) exhibit impressive performance in QA, they
suffer from significant performance degradation when facing complex and
abstract QA tasks due to insufficient reasoning capabilities. Works such as
Chain-of-Thought (CoT) and Tree-of-Thought (ToT) aim to enhance LLMs' reasoning
abilities, but they face issues such as in-layer redundancy in tree structures
and single paths in chain structures. Although some studies utilize
Retrieval-Augmented Generation (RAG) methods to assist LLMs in reasoning, the
challenge of effectively utilizing large amounts of information involving
multiple entities and hops remains critical. To address this, we propose the
Matrix of Thought (MoT), a novel and efficient LLM thought structure. MoT
explores the problem in both horizontal and vertical dimensions through the
"column-cell communication" mechanism, enabling LLMs to actively engage in
multi-strategy and deep-level thinking, reducing redundancy within the column
cells and enhancing reasoning capabilities. Furthermore, we develop a
fact-correction mechanism by constructing knowledge units from retrieved
knowledge graph triples and raw text to enhance the initial knowledge for LLM
reasoning and correct erroneous answers. This leads to the development of an
efficient and accurate QA framework (MTQA). Experimental results show that our
framework outperforms state-of-the-art methods on four widely-used datasets in
terms of F1 and EM scores, with reasoning time only 14.4\% of the baseline
methods, demonstrating both its efficiency and accuracy. The code for this
framework is available at https://github.com/lyfiter/mtqa.

</details>


### [136] [Decoding the Poetic Language of Emotion in Korean Modern Poetry: Insights from a Human-Labeled Dataset and AI Modeling](https://arxiv.org/abs/2509.03932)
*Iro Lim,Haein Ji,Byungjun Kim*

Main category: cs.CL

TL;DR: 本研究引入了KPoEM（韩国诗歌情感映射）数据集，用于现代韩国诗歌的计算情感分析。该数据集包含7,662个带有44种细粒度情感标签的条目。在一个最先进的韩国语言模型上对KPoEM进行微调后，其性能显著优于现有模型，F1-micro得分从0.34提高到0.60。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在文本情感分类方面取得了显著进展，但诗歌（尤其是韩国诗歌）由于其比喻性语言和文化特异性，在情感分析领域仍未得到充分探索。

Method: 研究构建了一个多标签情感数据集KPoEM，包含7,662个条目（7,007个行级和615个作品级），由五位有影响力的韩国诗人的作品中提取，并用44种细粒度情感类别进行标注。随后，通过顺序微调（先在通用语料库上，再在KPoEM数据集上）训练了一个最先进的韩国语言模型。

Result: 在KPoEM数据集上微调后的韩国语言模型显著优于在通用语料库上训练的模型，F1-micro得分从0.34提高到0.60。KPoEM模型不仅增强了识别时间和文化特定情感表达的能力，还展现出保留现代韩国诗歌核心情感的强大能力。

Conclusion: 本研究通过构建结构化数据，有效连接了计算方法与文学分析，为定量探索诗歌情感提供了新的可能性，并忠实地保留了韩国文学的情感和文化细微之处。

Abstract: This study introduces KPoEM (Korean Poetry Emotion Mapping) , a novel dataset
for computational emotion analysis in modern Korean poetry. Despite remarkable
progress in text-based emotion classification using large language models,
poetry-particularly Korean poetry-remains underexplored due to its figurative
language and cultural specificity. We built a multi-label emotion dataset of
7,662 entries, including 7,007 line-level entries from 483 poems and 615
work-level entries, annotated with 44 fine-grained emotion categories from five
influential Korean poets. A state-of-the-art Korean language model fine-tuned
on this dataset significantly outperformed previous models, achieving 0.60
F1-micro compared to 0.34 from models trained on general corpora. The KPoEM
model, trained through sequential fine-tuning-first on general corpora and then
on the KPoEM dataset-demonstrates not only an enhanced ability to identify
temporally and culturally specific emotional expressions, but also a strong
capacity to preserve the core sentiments of modern Korean poetry. This study
bridges computational methods and literary analysis, presenting new
possibilities for the quantitative exploration of poetic emotions through
structured data that faithfully retains the emotional and cultural nuances of
Korean literature.

</details>


### [137] [SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented Generation via Distribution Self-Alignment](https://arxiv.org/abs/2509.03934)
*Yuqing Huang,Rongyang Zhang,Qimeng Wang,Chengqiang Lu,Yan Gao,Yi Wu,Yao Hu,Xuyang Zhi,Guiquan Liu,Xin Li,Hao Wang,Enhong Chen*

Main category: cs.CL

TL;DR: 本文提出SelfAug方法，通过自分布对齐输入序列logits，以减轻大型语言模型在RAG场景下微调时出现的灾难性遗忘问题，同时提高下游任务性能并保持通用能力。


<details>
  <summary>Details</summary>
Motivation: 尽管监督微调（尤其是在RAG场景中）能有效提升任务特异性性能，但它常导致灾难性遗忘，使模型丧失原有知识和通用能力。现有解决方案要么依赖通用指令数据，要么在保持模型原始分布方面存在局限性。

Method: 本文提出SelfAug，一种自分布对齐方法。该方法通过对齐输入序列的logits来保留模型的语义分布，从而减轻灾难性遗忘并提高下游性能。

Result: 实验证明，SelfAug在下游学习和通用能力保留之间取得了更好的平衡。综合实证分析揭示了分布偏移与RAG场景中灾难性遗忘严重程度之间的直接关联，并指出通用指令微调中RAG能力的缺失导致了微调过程中的显著分布偏移。

Conclusion: SelfAug不仅加深了对RAG背景下灾难性遗忘的理解，还提供了一种适用于多种微调场景的实用解决方案。

Abstract: Recent advancements in large language models (LLMs) have revolutionized
natural language processing through their remarkable capabilities in
understanding and executing diverse tasks. While supervised fine-tuning,
particularly in Retrieval-Augmented Generation (RAG) scenarios, effectively
enhances task-specific performance, it often leads to catastrophic forgetting,
where models lose their previously acquired knowledge and general capabilities.
Existing solutions either require access to general instruction data or face
limitations in preserving the model's original distribution. To overcome these
limitations, we propose SelfAug, a self-distribution alignment method that
aligns input sequence logits to preserve the model's semantic distribution,
thereby mitigating catastrophic forgetting and improving downstream
performance. Extensive experiments demonstrate that SelfAug achieves a superior
balance between downstream learning and general capability retention. Our
comprehensive empirical analysis reveals a direct correlation between
distribution shifts and the severity of catastrophic forgetting in RAG
scenarios, highlighting how the absence of RAG capabilities in general
instruction tuning leads to significant distribution shifts during fine-tuning.
Our findings not only advance the understanding of catastrophic forgetting in
RAG contexts but also provide a practical solution applicable across diverse
fine-tuning scenarios. Our code is publicly available at
https://github.com/USTC-StarTeam/SelfAug.

</details>


### [138] [SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by Self-Play Fine-Tuning](https://arxiv.org/abs/2509.03937)
*Yuhao Zhang,Shaoming Duan,Jinhang Su,Chuanyi Liu,Peiyi Han*

Main category: cs.CL

TL;DR: 本文提出了一种名为SPFT-SQL的新型自博弈微调方法，专为Text-to-SQL任务设计，通过引入基于验证的迭代微调和错误驱动的损失函数，有效提升了大型语言模型生成准确SQL查询的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管自博弈微调（SPIN）在将弱LLM转化为强LLM方面取得了显著进展，但在Text-to-SQL任务中仍面临挑战。具体而言，SPIN不生成新信息，且对手模型生成的大量正确SQL查询反而降低了主模型生成准确SQL查询的能力。

Method: SPFT-SQL方法包含两个主要阶段：1. 自博弈前，引入基于验证的迭代微调方法，根据数据库schema和验证反馈迭代合成高质量微调数据，以增强模型性能并构建具有不同能力的基础模型。2. 在自博弈微调阶段，提出一种错误驱动的损失方法，激励对手模型产生不正确的输出，从而使主模型能够区分正确和错误的SQL，提高其生成正确SQL的能力。

Result: 在六个开源LLM和五个广泛使用的基准测试上进行的广泛实验和深入分析表明，SPFT-SQL方法优于现有的最先进（SOTA）方法。

Conclusion: SPFT-SQL通过创新的预微调和自博弈阶段策略，成功解决了现有SPIN在Text-to-SQL任务中的局限性，显著提升了LLM在该任务上的性能，实现了超越SOTA的成果。

Abstract: Despite the significant advancements of self-play fine-tuning (SPIN), which
can transform a weak large language model (LLM) into a strong one through
competitive interactions between models of varying capabilities, it still faces
challenges in the Text-to-SQL task. SPIN does not generate new information, and
the large number of correct SQL queries produced by the opponent model during
self-play reduces the main model's ability to generate accurate SQL queries. To
address this challenge, we propose a new self-play fine-tuning method tailored
for the Text-to-SQL task, called SPFT-SQL. Prior to self-play, we introduce a
verification-based iterative fine-tuning approach, which synthesizes
high-quality fine-tuning data iteratively based on the database schema and
validation feedback to enhance model performance, while building a model base
with varying capabilities. During the self-play fine-tuning phase, we propose
an error-driven loss method that incentivizes incorrect outputs from the
opponent model, enabling the main model to distinguish between correct SQL and
erroneous SQL generated by the opponent model, thereby improving its ability to
generate correct SQL. Extensive experiments and in-depth analyses on six
open-source LLMs and five widely used benchmarks demonstrate that our approach
outperforms existing state-of-the-art (SOTA) methods.

</details>


### [139] [VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based Role-Playing Agents](https://arxiv.org/abs/2509.03940)
*Weihao Wu,Liang Cao,Xinyu Wu,Zhiwei Lin,Rui Niu,Jingbei Li,Zhiyong Wu*

Main category: cs.CL

TL;DR: 本文介绍了VoxRole，首个专门用于评估基于语音的角色扮演对话代理（RPCA）的综合基准数据集，旨在解决现有研究中对副语言特征的忽视以及标准化评估基准的缺失。


<details>
  <summary>Details</summary>
Motivation: 现有RPCA研究主要关注文本模态，忽略了语音中对表达情感和塑造身份至关重要的副语言特征（如语调、韵律和节奏）。此外，基于语音的角色扮演领域缺乏标准化评估基准，现有口语对话数据集无法有效量化模型在长期角色一致性等核心能力上的表现。

Method: 本文引入了VoxRole基准，包含13335个多轮对话，总计65.6小时的语音，来自261部电影中的1228个独特角色。为构建该资源，作者提出了一种新颖的两阶段自动化流程：首先将电影音频与剧本对齐，然后利用大型语言模型（LLM）系统地为每个角色构建多维档案。

Result: VoxRole是首个全面的基于语音RPCA评估基准。利用VoxRole，作者对当代口语对话模型进行了多维评估，揭示了它们在维持角色一致性方面的优势和局限性。

Conclusion: VoxRole基准填补了基于语音RPCA评估领域的一个关键空白，为未来研究提供了标准化工具，以更有效地量化模型在处理副语言特征和保持角色一致性方面的性能。

Abstract: Recent significant advancements in Large Language Models (LLMs) have greatly
propelled the development of Role-Playing Conversational Agents (RPCAs). These
systems aim to create immersive user experiences through consistent persona
adoption. However, current RPCA research faces dual limitations. First,
existing work predominantly focuses on the textual modality, entirely
overlooking critical paralinguistic features including intonation, prosody, and
rhythm in speech, which are essential for conveying character emotions and
shaping vivid identities. Second, the speech-based role-playing domain suffers
from a long-standing lack of standardized evaluation benchmarks. Most current
spoken dialogue datasets target only fundamental capability assessments,
featuring thinly sketched or ill-defined character profiles. Consequently, they
fail to effectively quantify model performance on core competencies like
long-term persona consistency. To address this critical gap, we introduce
VoxRole, the first comprehensive benchmark specifically designed for the
evaluation of speech-based RPCAs. The benchmark comprises 13335 multi-turn
dialogues, totaling 65.6 hours of speech from 1228 unique characters across 261
movies. To construct this resource, we propose a novel two-stage automated
pipeline that first aligns movie audio with scripts and subsequently employs an
LLM to systematically build multi-dimensional profiles for each character.
Leveraging VoxRole, we conduct a multi-dimensional evaluation of contemporary
spoken dialogue models, revealing crucial insights into their respective
strengths and limitations in maintaining persona consistency.

</details>


### [140] [CANDY: Benchmarking LLMs' Limitations and Assistive Potential in Chinese Misinformation Fact-Checking](https://arxiv.org/abs/2509.03957)
*Ruiling Guo,Xinwei Yang,Chen Huang,Tong Zhang,Yong Hu*

Main category: cs.CL

TL;DR: 该研究提出了CANDY基准来评估大型语言模型（LLMs）在中文虚假信息事实核查方面的能力和局限性。结果显示LLMs在生成准确结论方面存在局限，但作为辅助工具可显著增强人类表现。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在日益普及，但它们在事实核查虚假信息方面的有效性仍不确定。

Method: 研究构建了一个名为CANDY的基准，用于系统评估LLMs在中文虚假信息事实核查中的能力和局限性。该基准包含一个精心标注的约2万条实例的数据集。为了理解LLMs的局限性，研究开发了一个分类法来归类LLM生成结论中存在的缺陷解释。

Result: 分析表明，即使通过思维链推理和少量样本提示增强，当前LLMs在生成准确事实核查结论方面仍存在局限性。研究识别出“事实编造”是LLM生成解释中最常见的失败模式。尽管LLMs单独进行事实核查不可靠，但它们作为辅助工具在特定场景下具有显著增强人类表现的潜力。

Conclusion: 大型语言模型（LLMs）在独立进行事实核查时并不可靠，但在作为辅助工具部署时，它们在增强人类表现方面具有巨大的潜力。

Abstract: The effectiveness of large language models (LLMs) to fact-check
misinformation remains uncertain, despite their growing use. To this end, we
present CANDY, a benchmark designed to systematically evaluate the capabilities
and limitations of LLMs in fact-checking Chinese misinformation. Specifically,
we curate a carefully annotated dataset of ~20k instances. Our analysis shows
that current LLMs exhibit limitations in generating accurate fact-checking
conclusions, even when enhanced with chain-of-thought reasoning and few-shot
prompting. To understand these limitations, we develop a taxonomy to categorize
flawed LLM-generated explanations for their conclusions and identify factual
fabrication as the most common failure mode. Although LLMs alone are unreliable
for fact-checking, our findings indicate their considerable potential to
augment human performance when deployed as assistive tools in scenarios. Our
dataset and code can be accessed at https://github.com/SCUNLP/CANDY

</details>


### [141] [Exploring NLP Benchmarks in an Extremely Low-Resource Setting](https://arxiv.org/abs/2509.03962)
*Ulin Nuha,Adam Jatowt*

Main category: cs.CL

TL;DR: 本文通过利用少量平行语料并翻译意大利语数据，为濒危语言拉登语（Ladin）创建了合成情感分析和多项选择问答数据集，并显著提升了机器翻译性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在极低资源语言（如土著语言）上的效果不佳，主要原因是缺乏标注数据。尽管兴趣日益增长，但这些语言的高质量自然语言处理（NLP）数据集仍然有限，阻碍了强大语言技术的发展。

Method: 该研究针对濒危罗曼语拉登语（特别是Val Badia方言），利用少量拉登语-意大利语平行句对，通过翻译单语意大利语数据创建了情感分析和多项选择问答（MCQA）的合成数据集。为确保语言质量和可靠性，采用了严格的过滤和回译程序。此外，将这些合成数据集整合到机器翻译训练中。

Result: 将合成数据集整合到机器翻译训练中，显著提升了现有意大利语-拉登语翻译基线的性能。本文还贡献了首批公开可用的拉登语情感分析和MCQA数据集。

Conclusion: 本研究为拉登语建立了基础资源，可支持该代表性不足语言的更广泛NLP研究和下游应用。

Abstract: The effectiveness of Large Language Models (LLMs) diminishes for extremely
low-resource languages, such as indigenous languages, primarily due to the lack
of labeled data. Despite growing interest, the availability of high-quality
natural language processing (NLP) datasets for these languages remains limited,
making it difficult to develop robust language technologies. This paper
addresses such gap by focusing on Ladin, an endangered Romance language,
specifically targeting the Val Badia variant. Leveraging a small set of
parallel Ladin-Italian sentence pairs, we create synthetic datasets for
sentiment analysis and multiple-choice question answering (MCQA) by translating
monolingual Italian data. To ensure linguistic quality and reliability, we
apply rigorous filtering and back-translation procedures in our method. We
further demonstrate that incorporating these synthetic datasets into machine
translation training leads to substantial improvements over existing
Italian-Ladin translation baselines. Our contributions include the first
publicly available sentiment analysis and MCQA datasets for Ladin, establishing
foundational resources that can support broader NLP research and downstream
applications for this underrepresented language.

</details>


### [142] [Expanding Foundational Language Capabilities in Open-Source LLMs through a Korean Case Study](https://arxiv.org/abs/2509.03972)
*Junghwan Lim,Gangwon Jo,Sungmin Lee,Jiyoung Park,Dongseok Kim,Jihwan Kim,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Kibong Choi,Jaeyeon Huh,Beomgyu Kim,Jangwoong Kim,Taehyun Kim,Haesol Lee,Jeesoo Lee,Dongpin Oh,Changseok Song,Daewon Suh*

Main category: cs.CL

TL;DR: Llama-3-Motif是一个1020亿参数的语言模型，基于Llama 3架构，通过LlamaPro和Masked Structure Growth等技术，增强了韩语能力并保持了强大的英语性能，在韩语基准测试中表现出色，可与GPT-4媲美。


<details>
  <summary>Details</summary>
Motivation: 旨在提升语言模型在韩语方面的能力，同时不牺牲其在英语上的优秀表现。

Method: 模型基于Llama 3架构，拥有1020亿参数。采用LlamaPro和Masked Structure Growth等先进训练技术进行扩展，不改变核心Transformer架构。利用MoAI平台在超大规模GPU集群上进行高效训练，并使用精心策划的、韩语和英语数据比例平衡的数据集进行优化。

Result: Llama-3-Motif在韩语特定基准测试中表现良好，超越了现有模型，并取得了与GPT-4相当的成果。

Conclusion: Llama-3-Motif成功地在增强韩语能力的同时保持了强大的英语性能，并在相关基准测试中展现出卓越表现。

Abstract: We introduce Llama-3-Motif, a language model consisting of 102 billion
parameters, specifically designed to enhance Korean capabilities while
retaining strong performance in English. Developed on the Llama 3 architecture,
Llama-3-Motif employs advanced training techniques, including LlamaPro and
Masked Structure Growth, to effectively scale the model without altering its
core Transformer architecture. Using the MoAI platform for efficient training
across hyperscale GPU clusters, we optimized Llama-3-Motif using a carefully
curated dataset that maintains a balanced ratio of Korean and English data.
Llama-3-Motif shows decent performance on Korean-specific benchmarks,
outperforming existing models and achieving results comparable to GPT-4.

</details>


### [143] [RTQA : Recursive Thinking for Complex Temporal Knowledge Graph Question Answering with Large Language Models](https://arxiv.org/abs/2509.03995)
*Zhaoyan Gong,Juan Li,Zhiqiang Liu,Lei Liang,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: RTQA是一个无需训练的新框架，通过递归分解、LLM和多路径聚合来增强时间知识图谱问答（TKGQA）中的推理能力，有效处理复杂时间查询并提高容错性。


<details>
  <summary>Details</summary>
Motivation: 现有TKGQA方法主要关注隐式时间约束，缺乏处理复杂时间查询的能力，并且在分解框架中存在推理能力有限和错误传播问题。

Method: RTQA框架遵循递归思维，将问题递归分解为子问题，利用大型语言模型（LLM）和TKG知识自下而上地解决，并通过多路径答案聚合提高容错性。它包含三个核心组件：时间问题分解器、递归求解器和答案聚合器。

Result: 在MultiTQ和TimelineKGQA基准测试上，RTQA在“多重”和“复杂”类别中实现了显著的Hits@1改进，优于现有最先进的方法。

Conclusion: RTQA通过增强推理和提高容错性，有效解决了TKGQA中处理复杂时间查询的挑战，且无需额外训练。

Abstract: Current temporal knowledge graph question answering (TKGQA) methods primarily
focus on implicit temporal constraints, lacking the capability of handling more
complex temporal queries, and struggle with limited reasoning abilities and
error propagation in decomposition frameworks. We propose RTQA, a novel
framework to address these challenges by enhancing reasoning over TKGs without
requiring training. Following recursive thinking, RTQA recursively decomposes
questions into sub-problems, solves them bottom-up using LLMs and TKG
knowledge, and employs multi-path answer aggregation to improve fault
tolerance. RTQA consists of three core components: the Temporal Question
Decomposer, the Recursive Solver, and the Answer Aggregator. Experiments on
MultiTQ and TimelineKGQA benchmarks demonstrate significant Hits@1 improvements
in "Multiple" and "Complex" categories, outperforming state-of-the-art methods.
Our code and data are available at https://github.com/zjukg/RTQA.

</details>


### [144] [On Robustness and Reliability of Benchmark-Based Evaluation of LLMs](https://arxiv.org/abs/2509.04013)
*Riccardo Lunardi,Vincenzo Della Mea,Stefano Mizzaro,Kevin Roitero*

Main category: cs.CL

TL;DR: 本研究发现大型语言模型（LLMs）在处理改写后的基准问题时，虽然排名相对稳定，但绝对性能显著下降，表明其在语言变异性方面存在不足，并对当前基准评估的可靠性提出了质疑。


<details>
  <summary>Details</summary>
Motivation: LLMs通常通过固定格式的基准进行评估，但实际应用中存在广泛的语言变异性。研究旨在系统评估LLMs对改写问题的鲁棒性，并探讨基于基准的评估是否能可靠衡量模型能力。

Method: 研究系统性地生成了六个常用基准中所有问题的各种改写版本，并测量了34个不同规模和性能的先进LLMs在这些改写输入上的有效性变化。

Result: 研究发现，LLM的排名在改写输入下保持相对稳定，但其绝对有效性分数显著下降。这表明LLMs在处理语言变异性方面存在困难，引发了对其泛化能力和评估方法的担忧。此外，观察到的性能下降挑战了基于基准评估的可靠性，暗示高基准分数可能无法完全捕捉模型对真实世界输入变化的鲁棒性。

Conclusion: 研究强调了LLM评估方法需要改进，需要开发更注重鲁棒性的基准，以更好地反映实际部署场景的需求。

Abstract: Large Language Models (LLMs) effectiveness is usually evaluated by means of
benchmarks such as MMLU, ARC-C, or HellaSwag, where questions are presented in
their original wording, thus in a fixed, standardized format. However,
real-world applications involve linguistic variability, requiring models to
maintain their effectiveness across diverse rewordings of the same question or
query. In this study, we systematically assess the robustness of LLMs to
paraphrased benchmark questions and investigate whether benchmark-based
evaluations provide a reliable measure of model capabilities. We systematically
generate various paraphrases of all the questions across six different common
benchmarks, and measure the resulting variations in effectiveness of 34
state-of-the-art LLMs, of different size and effectiveness. Our findings reveal
that while LLM rankings remain relatively stable across paraphrased inputs,
absolute effectiveness scores change, and decline significantly. This suggests
that LLMs struggle with linguistic variability, raising concerns about their
generalization abilities and evaluation methodologies. Furthermore, the
observed performance drop challenges the reliability of benchmark-based
evaluations, indicating that high benchmark scores may not fully capture a
model's robustness to real-world input variations. We discuss the implications
of these findings for LLM evaluation methodologies, emphasizing the need for
robustness-aware benchmarks that better reflect practical deployment scenarios.

</details>


### [145] [What if I ask in \textit{alia lingua}? Measuring Functional Similarity Across Languages](https://arxiv.org/abs/2509.04032)
*Debangan Mishra,Arihant Rastogi,Agyeya Negi,Shashwat Goel,Ponnurangam Kumaraguru*

Main category: cs.CL

TL;DR: 研究发现，随着大语言模型规模和能力的增长，其跨语言输出的一致性也随之提高，且模型内部的跨语言一致性高于与其他模型的共识。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探究大语言模型在不同语言间输出的相似程度。

Method: 本研究采用新提出的模型相似性度量指标 $\kappa_p$，在包含20种语言和47个科目的GlobalMMLU数据集上进行分析。

Result: 分析结果表明，模型的输出一致性随其规模和能力的增长而在不同语言间逐渐提高。此外，模型内部的跨语言一致性高于其在相同语言下与其他模型的一致性。

Conclusion: 研究不仅突显了 $\kappa_p$ 作为评估多语言可靠性的实用工具的价值，也揭示了其指导开发更一致的多语言系统的潜力。

Abstract: How similar are model outputs across languages? In this work, we study this
question using a recently proposed model similarity metric $\kappa_p$ applied
to 20 languages and 47 subjects in GlobalMMLU. Our analysis reveals that a
model's responses become increasingly consistent across languages as its size
and capability grow. Interestingly, models exhibit greater cross-lingual
consistency within themselves than agreement with other models prompted in the
same language. These results highlight not only the value of $\kappa_p$ as a
practical tool for evaluating multilingual reliability, but also its potential
to guide the development of more consistent multilingual systems.

</details>


### [146] [A RoBERTa-Based Functional Syntax Annotation Model for Chinese Texts](https://arxiv.org/abs/2509.04046)
*Han Xiaohui,Zhang Yunlong,Guo Yuxi*

Main category: cs.CL

TL;DR: 本研究基于RoBERTa开发了一个中文功能句法自动标注模型，在测试集上F1分数达到0.852，显著优于其他模型，为中文功能句法分析提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 尽管系统功能语法及其分支卡迪夫语法在语篇分析等领域应用广泛，但中文文本的自动标注系统尚未开发，这严重限制了相关理论的应用与推广。

Method: 研究引入了基于RoBERTa的中文功能句法标注模型。首先，从《人民日报》2014年语料库中随机选取4100个句子并进行功能句法标注以构建训练数据集。然后，基于该数据集对RoBERTa-Chinese wwm-ext模型进行微调，以实现命名实体识别任务。

Result: 该模型在测试集上取得了0.852的F1分数，显著优于其他对比模型。模型在识别主语(S)、主要动词(M)和补语(C)等核心句法元素方面表现出色。然而，对于标签样本不平衡的实体识别仍有改进空间。

Conclusion: 本研究首次将功能句法与基于注意力的NLP模型相结合，为中文功能句法自动化分析提供了一种新方法，并为后续研究奠定了坚实基础。

Abstract: Systemic Functional Grammar and its branch, Cardiff Grammar, have been widely
applied to discourse analysis, semantic function research, and other tasks
across various languages and texts. However, an automatic annotation system
based on this theory for Chinese texts has not yet been developed, which
significantly constrains the application and promotion of relevant theories. To
fill this gap, this research introduces a functional syntax annotation model
for Chinese based on RoBERTa (Robustly Optimized BERT Pretraining Approach).
The study randomly selected 4,100 sentences from the People's Daily 2014 corpus
and annotated them according to functional syntax theory to establish a dataset
for training. The study then fine-tuned the RoBERTa-Chinese wwm-ext model based
on the dataset to implement the named entity recognition task, achieving an F1
score of 0.852 on the test set that significantly outperforms other comparative
models. The model demonstrated excellent performance in identifying core
syntactic elements such as Subject (S), Main Verb (M), and Complement (C).
Nevertheless, there remains room for improvement in recognizing entities with
imbalanced label samples. As the first integration of functional syntax with
attention-based NLP models, this research provides a new method for automated
Chinese functional syntax analysis and lays a solid foundation for subsequent
studies.

</details>


### [147] [Synthesizing Sheet Music Problems for Evaluation and Reinforcement Learning](https://arxiv.org/abs/2509.04059)
*Zhilin Wang,Zhe Yang,Yun Luo,Yafu Li,Haoran Zhang,Runzhe Zhan,Derek F. Wong,Jizhe Zhou,Yu Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种基于乐理规则合成乐谱问题的方法，创建了SSMR-Bench基准和训练数据，并通过可验证奖励强化学习（RLVR）显著提升了大型语言模型（LLMs）和多模态大型语言模型（MLLMs）的乐谱理解能力，甚至促进了音乐创作。


<details>
  <summary>Details</summary>
Motivation: 当前研究在乐谱推理方面缺乏评估基准和训练数据，而提升LLMs和MLLMs解释乐谱的能力对于构建AI音乐家至关重要。

Method: 研究人员提出并实现了一个数据合成框架，该框架基于乐理规则生成文本和视觉模态的可验证乐谱问题。这形成了合成乐谱推理基准（SSMR-Bench）及其配套训练集。他们利用这些合成数据进行可验证奖励强化学习（RLVR），以训练和改进现有模型，并评估了多种LLMs/MLLMs（如Gemini 2.5-Pro, Qwen3-8B-Base, Qwen2.5-VL-Instruct, GPT-4）的表现。

Result: SSMR-Bench的评估结果表明了模型推理能力在乐谱解释中的重要性。Gemini 2.5-Pro表现不佳，凸显了MLLMs在视觉乐谱解释方面的挑战。通过RLVR使用合成数据，Qwen3-8B-Base和Qwen2.5-VL-Instruct在SSMR-Bench上取得了显著进步。经过训练的Qwen3-8B-Base在MusicTheoryBench上的整体性能超越了GPT-4，并在角色扮演和思维链策略下达到了与GPT-4相当的推理水平。此外，其在数学问题上的性能也得到提升，增强的推理能力还能促进音乐创作。

Conclusion: 该研究首次提出了基于乐理规则合成乐谱问题的方法，并证明了其在提升模型乐谱理解推理能力方面的有效性，同时也为AI辅助音乐创作开辟了新的可能性。

Abstract: Enhancing the ability of Large Language Models (LLMs) and Multimodal Large
Language Models (MLLMs) to interpret sheet music is a crucial step toward
building AI musicians. However, current research lacks both evaluation
benchmarks and training data for sheet music reasoning. To address this, we
propose the idea of synthesizing sheet music problems grounded in music theory,
which can serve both as evaluation benchmarks and as training data for
reinforcement learning with verifiable rewards (RLVR). We introduce a data
synthesis framework that generates verifiable sheet music questions in both
textual and visual modalities, leading to the Synthetic Sheet Music Reasoning
Benchmark (SSMR-Bench) and a complementary training set. Evaluation results on
SSMR-Bench show the importance of models' reasoning abilities in interpreting
sheet music. At the same time, the poor performance of Gemini 2.5-Pro
highlights the challenges that MLLMs still face in interpreting sheet music in
a visual format. By leveraging synthetic data for RLVR, Qwen3-8B-Base and
Qwen2.5-VL-Instruct achieve improvements on the SSMR-Bench. Besides, the
trained Qwen3-8B-Base surpasses GPT-4 in overall performance on
MusicTheoryBench and achieves reasoning performance comparable to GPT-4 with
the strategies of Role play and Chain-of-Thought. Notably, its performance on
math problems also improves relative to the original Qwen3-8B-Base.
Furthermore, our results show that the enhanced reasoning ability can also
facilitate music composition. In conclusion, we are the first to propose the
idea of synthesizing sheet music problems based on music theory rules, and
demonstrate its effectiveness not only in advancing model reasoning for sheet
music understanding but also in unlocking new possibilities for AI-assisted
music creation.

</details>


### [148] [Arabic Chatbot Technologies in Education: An Overview](https://arxiv.org/abs/2509.04066)
*Hicham Bourhil,Yacine El Younoussi*

Main category: cs.CL

TL;DR: 本文对教育领域现有的阿拉伯语聊天机器人进行了调查，发现它们普遍缺乏使用现代AI技术，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 人工智能和自然语言处理的进步，特别是聊天机器人在教育等领域的广泛应用，以及COVID-19疫情推动的远程学习需求，促使人们对教育领域数字技术，尤其是聊天机器人的兴趣日益增长。大型语言模型的出现进一步普及了聊天机器人。

Method: 本研究通过进行一项调查（survey），分析了现有教育领域阿拉伯语聊天机器人的不同特征，包括其采用的方法、语言种类以及用于衡量性能的指标。

Result: 研究发现了一些研究空白：尽管聊天机器人在英语等其他语言中取得了成功，但很少有教育领域的阿拉伯语聊天机器人使用了现代技术。

Conclusion: 文章讨论了该领域未来的研究方向。

Abstract: The recent advancements in Artificial Intelligence (AI) in general, and in
Natural Language Processing (NLP) in particular, and some of its applications
such as chatbots, have led to their implementation in different domains like
education, healthcare, tourism, and customer service. Since the COVID-19
pandemic, there has been an increasing interest in these digital technologies
to allow and enhance remote access. In education, e-learning systems have been
massively adopted worldwide. The emergence of Large Language Models (LLM) such
as BERT (Bidirectional Encoder Representations from Transformers) and GPT
(Generative Pre-trained Transformers) made chatbots even more popular. In this
study, we present a survey on existing Arabic chatbots in education and their
different characteristics such as the adopted approaches, language variety, and
metrics used to measure their performance. We were able to identified some
research gaps when we discovered that, despite the success of chatbots in other
languages such as English, only a few educational Arabic chatbots used modern
techniques. Finally, we discuss future directions of research in this field.

</details>


### [149] [Improving Narrative Classification and Explanation via Fine Tuned Language Models](https://arxiv.org/abs/2509.04077)
*Rishit Tyagi,Rahul Bouri,Mohit Gupta*

Main category: cs.CL

TL;DR: 本研究通过微调BERT模型和GPT-4o管道进行多标签叙事分类，并提出ReACT框架结合辅助知识库生成证据性解释，以有效检测和解释新闻文章中的隐性叙事，提高了分类准确性和解释可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统的自然语言处理方法难以检测细微的措辞和隐藏的意图，因此需要开发新的方法来理解隐性叙事和隐含信息，以分析偏见和情感，并生成简洁、基于证据的解释。

Method: 本研究采用多标签分类方法识别新闻文章中的叙事和子叙事。具体方法包括：1) 微调一个面向召回率的BERT模型进行叙事检测；2) 使用GPT-4o管道精炼BERT的预测以确保一致性；3) 提出一个ReACT（推理+行动）框架，结合基于语义检索的少样本提示，用于生成叙事解释；4) 引入结构化分类表作为辅助知识库，以提高事实准确性并减少幻觉。

Result: 研究结果表明，在提示中整合辅助知识显著提高了分类准确性和解释的可靠性。

Conclusion: 所提出的方法在检测和解释隐性叙事方面表现出色，并在媒体分析、教育和情报收集等领域具有潜在应用价值。

Abstract: Understanding covert narratives and implicit messaging is essential for
analyzing bias and sentiment. Traditional NLP methods struggle with detecting
subtle phrasing and hidden agendas. This study tackles two key challenges: (1)
multi-label classification of narratives and sub-narratives in news articles,
and (2) generating concise, evidence-based explanations for dominant
narratives. We fine-tune a BERT model with a recall-oriented approach for
comprehensive narrative detection, refining predictions using a GPT-4o pipeline
for consistency. For narrative explanation, we propose a ReACT (Reasoning +
Acting) framework with semantic retrieval-based few-shot prompting, ensuring
grounded and relevant justifications. To enhance factual accuracy and reduce
hallucinations, we incorporate a structured taxonomy table as an auxiliary
knowledge base. Our results show that integrating auxiliary knowledge in
prompts improves classification accuracy and justification reliability, with
applications in media analysis, education, and intelligence gathering.

</details>


### [150] [Towards Stable and Personalised Profiles for Lexical Alignment in Spoken Human-Agent Dialogue](https://arxiv.org/abs/2509.04104)
*Keara Schaaij,Roel Boumans,Tibor Bosse,Iris Hendrickx*

Main category: cs.CL

TL;DR: 本研究旨在为会话代理构建稳定、个性化的词汇配置文件，以实现词汇对齐。通过调整数据量和词性项目数量，找到了在性能和数据效率之间取得最佳平衡的紧凑配置文件。


<details>
  <summary>Details</summary>
Motivation: 词汇对齐有助于成功的沟通，但在会话代理中（尤其是在大型语言模型背景下）其实现仍未得到充分探索。本研究旨在迈出实现人机对话中词汇对齐的第一步。

Method: 研究借鉴了会话代理个性化策略，通过改变用于构建配置文件的数据量（转录语音数据）以及每个词性类别中包含的项目数量，来构建稳定、个性化的词汇配置文件。使用召回率、覆盖率和余弦相似度指标随时间评估配置文件的性能。

Result: 结果表明，由10分钟转录语音数据创建的更小、更紧凑的配置文件（形容词和连词各5项，副词、名词、代词和动词各10项），在性能和数据效率方面提供了最佳平衡。

Conclusion: 本研究为构建稳定、个性化的词汇配置文件提供了实用见解，考虑了最小数据需求，是会话代理中实现词汇对齐策略的基础性一步。

Abstract: Lexical alignment, where speakers start to use similar words across
conversation, is known to contribute to successful communication. However, its
implementation in conversational agents remains underexplored, particularly
considering the recent advancements in large language models (LLMs). As a first
step towards enabling lexical alignment in human-agent dialogue, this study
draws on strategies for personalising conversational agents and investigates
the construction of stable, personalised lexical profiles as a basis for
lexical alignment. Specifically, we varied the amounts of transcribed spoken
data used for construction as well as the number of items included in the
profiles per part-of-speech (POS) category and evaluated profile performance
across time using recall, coverage, and cosine similarity metrics. It was shown
that smaller and more compact profiles, created after 10 min of transcribed
speech containing 5 items for adjectives, 5 items for conjunctions, and 10
items for adverbs, nouns, pronouns, and verbs each, offered the best balance in
both performance and data efficiency. In conclusion, this study offers
practical insights into constructing stable, personalised lexical profiles,
taking into account minimal data requirements, serving as a foundational step
toward lexical alignment strategies in conversational agents.

</details>


### [151] [MultiWikiQA: A Reading Comprehension Benchmark in 300+ Languages](https://arxiv.org/abs/2509.04111)
*Dan Saattrup Smart*

Main category: cs.CL

TL;DR: 本文介绍了一个名为MultiWikiQA的全新阅读理解数据集，涵盖306种语言，其问题由LLM生成，答案直接取自维基百科文章。数据集经过人工评估，证实问题质量良好且具有挑战性，同时揭示了不同语言模型在不同语言上的性能差异。


<details>
  <summary>Details</summary>
Motivation: 需要一个覆盖大量语言的阅读理解数据集，以促进多语言LLM的开发和评估，并深入了解这些模型在不同语言上的表现。

Method: 通过以下步骤构建和评估数据集：1) 从维基百科文章中提取上下文。2) 使用大型语言模型（LLM）生成问题，确保答案在维基百科文章中逐字出现。3) 对30种语言的问题进行众包人工流畅性评估，以验证问题质量。4) 使用6种不同类型和规模的语言模型（包括解码器和编码器模型）进行基准测试，以评估数据集的难度和模型的性能。

Result: 研究结果表明：1) 众包人工评估证实生成的问题质量良好。2) 该基准测试对现有语言模型来说具有足够的难度。3) 在不同语言上，语言模型的性能存在显著差异。

Conclusion: MultiWikiQA是一个高质量、具有挑战性且覆盖广泛语言的阅读理解数据集，可用于评估和推动多语言大型语言模型的发展，并揭示了模型在跨语言理解方面的表现差异。

Abstract: We introduce a new reading comprehension dataset, dubbed MultiWikiQA, which
covers 306 languages. The context data comes from Wikipedia articles, with
questions generated by an LLM and the answers appearing verbatim in the
Wikipedia articles. We conduct a crowdsourced human evaluation of the fluency
of the generated questions across 30 of the languages, providing evidence that
the questions are of good quality. We evaluate 6 different language models,
both decoder and encoder models of varying sizes, showing that the benchmark is
sufficiently difficult and that there is a large performance discrepancy
amongst the languages. The dataset and survey evaluations are freely available.

</details>


### [152] [MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions](https://arxiv.org/abs/2509.04183)
*Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文提出MAGneT，一个多智能体框架，用于生成高质量的合成心理咨询会话数据，以解决现有数据稀缺问题，并显著提升了大型语言模型在心理咨询方面的性能。


<details>
  <summary>Details</summary>
Motivation: 可扩展心理咨询的需求日益增长，需要高质量、符合隐私规范的数据来微调开源大型语言模型（LLMs）。然而，此类数据非常稀缺，且现有单智能体方法未能充分捕捉真实咨询的复杂性。此外，现有评估协议存在不一致性。

Method: 本文引入了MAGneT，一个新颖的多智能体框架，用于生成合成心理咨询会话。它将咨询师响应生成分解为由专业LLM智能体处理的协调子任务，每个智能体模拟一种关键心理技术。与以往的单智能体方法不同，MAGneT能更好地捕捉真实咨询的结构和细微差别。此外，作者提出了一个统一的评估框架，整合了多样化的自动和专家指标，并将专家评估从之前的四个方面扩展到九个方面，以实现更全面、稳健的数据质量评估。

Result: 实验结果表明，MAGneT在生成咨询会话的质量、多样性和治疗一致性方面显著优于现有方法，平均将通用咨询技能提高3.2%，CBT特异性技能提高4.3%（基于认知疗法评级量表CTRS）。专家在77.2%的情况下更倾向于MAGneT生成的会话。更重要的是，使用MAGneT生成的会话微调开源模型，其性能比使用基线方法生成的会话微调的模型平均提升了6.3%的通用咨询技能和7.3%的CBT特异性技能（基于CTRS）。代码和数据已公开。

Conclusion: MAGneT通过其多智能体框架成功生成了高质量、治疗对齐的合成心理咨询会话数据，有效解决了数据稀缺问题。这些数据能显著提高开源大型语言模型在心理咨询领域的性能，为可扩展心理咨询提供了有价值的资源。

Abstract: The growing demand for scalable psychological counseling highlights the need
for fine-tuning open-source Large Language Models (LLMs) with high-quality,
privacy-compliant data, yet such data remains scarce. Here we introduce MAGneT,
a novel multi-agent framework for synthetic psychological counseling session
generation that decomposes counselor response generation into coordinated
sub-tasks handled by specialized LLM agents, each modeling a key psychological
technique. Unlike prior single-agent approaches, MAGneT better captures the
structure and nuance of real counseling. In addition, we address
inconsistencies in prior evaluation protocols by proposing a unified evaluation
framework integrating diverse automatic and expert metrics. Furthermore, we
expand the expert evaluations from four aspects of counseling in previous works
to nine aspects, enabling a more thorough and robust assessment of data
quality. Empirical results show that MAGneT significantly outperforms existing
methods in quality, diversity, and therapeutic alignment of the generated
counseling sessions, improving general counseling skills by 3.2% and
CBT-specific skills by 4.3% on average on cognitive therapy rating scale
(CTRS). Crucially, experts prefer MAGneT-generated sessions in 77.2% of cases
on average across all aspects. Moreover, fine-tuning an open-source model on
MAGneT-generated sessions shows better performance, with improvements of 6.3%
on general counseling skills and 7.3% on CBT-specific skills on average on CTRS
over those fine-tuned with sessions generated by baseline methods. We also make
our code and data public.

</details>


### [153] [Joint Modeling of Entities and Discourse Relations for Coherence Assessment](https://arxiv.org/abs/2509.04182)
*Wei Liu,Michael Strube*

Main category: cs.CL

TL;DR: 本研究探索了联合建模实体特征和语篇关系特征以评估连贯性的方法，实验证明结合这两种特征能显著提升连贯性模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的连贯性建模工作大多只关注实体特征或语篇关系特征，很少有研究尝试将两者结合起来进行建模。

Method: 研究探索了两种联合建模实体和语篇关系的方法，用于连贯性评估。

Result: 在三个基准数据集上的实验表明，整合这两种类型的特征显著提高了连贯性模型的性能。

Conclusion: 同时建模实体和语篇关系对于连贯性评估具有显著优势。

Abstract: In linguistics, coherence can be achieved by different means, such as by
maintaining reference to the same set of entities across sentences and by
establishing discourse relations between them. However, most existing work on
coherence modeling focuses exclusively on either entity features or discourse
relation features, with little attention given to combining the two. In this
study, we explore two methods for jointly modeling entities and discourse
relations for coherence assessment. Experiments on three benchmark datasets
show that integrating both types of features significantly enhances the
performance of coherence models, highlighting the benefits of modeling both
simultaneously for coherence evaluation.

</details>


### [154] [Explicit and Implicit Data Augmentation for Social Event Detection](https://arxiv.org/abs/2509.04202)
*Congbo Ma,Yuxia Wang,Jia Wu,Jian Yang,Jing Du,Zitai Qiu,Qing Li,Hu Wang,Preslav Nakov*

Main category: cs.CL

TL;DR: 本文提出了一种名为SED-Aug的即插即用双重数据增强框架，用于解决社交事件检测中标注数据稀缺的问题。该框架结合了显式文本增强和隐式特征空间增强，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 社交事件检测依赖于标注数据，但数据标注成本高昂且耗时费力，限制了该领域的发展。

Method: SED-Aug框架包含两部分：1) 显式增强：利用大型语言模型通过五种不同的生成策略增强文本信息；2) 隐式增强：设计了五种新颖的扰动技术，在结构融合嵌入的特征空间中操作，旨在保持嵌入的语义和关系特性同时增加多样性。

Result: 在Twitter2012数据集上，SED-Aug的平均F1分数比最佳基线模型提高了约17.67%；在Twitter2018数据集上，提高了约15.57%。

Conclusion: SED-Aug通过结合显式文本和隐式特征空间增强，有效提升了数据多样性和模型鲁棒性，从而显著改善了社交事件检测的性能。

Abstract: Social event detection involves identifying and categorizing important events
from social media, which relies on labeled data, but annotation is costly and
labor-intensive. To address this problem, we propose Augmentation framework for
Social Event Detection (SED-Aug), a plug-and-play dual augmentation framework,
which combines explicit text-based and implicit feature-space augmentation to
enhance data diversity and model robustness. The explicit augmentation utilizes
large language models to enhance textual information through five diverse
generation strategies. For implicit augmentation, we design five novel
perturbation techniques that operate in the feature space on structural fused
embeddings. These perturbations are crafted to keep the semantic and relational
properties of the embeddings and make them more diverse. Specifically, SED-Aug
outperforms the best baseline model by approximately 17.67% on the Twitter2012
dataset and by about 15.57% on the Twitter2018 dataset in terms of the average
F1 score. The code is available at GitHub: https://github.com/congboma/SED-Aug.

</details>


### [155] [Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge in Large Language Models](https://arxiv.org/abs/2509.04304)
*Juraj Vladika,Mahdi Dhaini,Florian Matthes*

Main category: cs.CL

TL;DR: LLMs在医疗领域的应用面临过时知识的风险。本研究通过构建新数据集评估LLMs，发现它们普遍依赖过时知识，并分析其原因，提出缓解方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在医疗保健领域具有巨大潜力，但它们依赖静态训练数据，这在医学建议不断演变的情况下构成重大风险。当LLMs记忆过时的医学知识时，可能提供有害建议或在临床推理任务中失败，因此有必要调查此问题。

Method: 研究引入了两个新的问答（QA）数据集，均来源于系统性综述：MedRevQA（包含16,501个通用生物医学知识QA对）和MedChangeQA（包含512个医学共识随时间变化的QA对）。研究者使用这些数据集评估了八个主流LLMs，并额外分析了过时预训练数据和训练策略的影响。

Result: 对八个主流LLMs在所构建数据集上的评估显示，所有模型都普遍依赖过时知识。

Conclusion: LLMs在医疗领域普遍存在依赖过时知识的问题。通过分析过时预训练数据和训练策略的影响，本研究为开发更实时、可靠的医疗AI系统奠定了基础，并提出了未来的缓解方向。

Abstract: The growing capabilities of Large Language Models (LLMs) show significant
potential to enhance healthcare by assisting medical researchers and
physicians. However, their reliance on static training data is a major risk
when medical recommendations evolve with new research and developments. When
LLMs memorize outdated medical knowledge, they can provide harmful advice or
fail at clinical reasoning tasks. To investigate this problem, we introduce two
novel question-answering (QA) datasets derived from systematic reviews:
MedRevQA (16,501 QA pairs covering general biomedical knowledge) and
MedChangeQA (a subset of 512 QA pairs where medical consensus has changed over
time). Our evaluation of eight prominent LLMs on the datasets reveals
consistent reliance on outdated knowledge across all models. We additionally
analyze the influence of obsolete pre-training data and training strategies to
explain this phenomenon and propose future directions for mitigation, laying
the groundwork for developing more current and reliable medical AI systems.

</details>


### [156] [Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?](https://arxiv.org/abs/2509.04292)
*Qinyan Zhang,Xinping Lei,Ruijie Miao,Yu Fu,Haojie Fan,Le Chang,Jiafan Hou,Dingling Zhang,Zhongfei Hou,Ziqiang Yang,Changxin Pu,Fei Hu,Jingkai Liu,Mengyun Liu,Yang Liu,Xiang Gao,Jiaheng Liu,Tong Yang,Zaiyuan Wang,Ge Zhang,Wenhao Huang*

Main category: cs.CL

TL;DR: 本文提出了Inverse IFEval基准测试，用于评估大型语言模型（LLMs）在面对与训练模式冲突的指令时，克服“认知惯性”并遵循“反直觉”指令的能力，发现现有LLMs在此方面表现不足，并强调未来对齐工作应关注非常规情境下的适应性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在遵循与其监督微调（SFT）中学到的标准化模式相冲突的指令时，常表现出“认知惯性”并难以执行。为了评估LLMs的这一局限性，研究者提出了Inverse IFEval。

Method: 研究者提出了Inverse IFEval基准测试，包含八种挑战类型，如问题修正、有意文本缺陷等。他们通过人机协作流程，构建了一个包含1012个高质量中英文问题的多领域数据集（涵盖23个领域），并采用优化的LLM-as-a-Judge框架进行评估。

Result: 对现有领先LLMs的实验表明，所提出的Inverse IFEval基准测试是必要的。研究结果强调，未来的对齐工作不仅应追求流畅性和事实准确性，还应考虑在非常规上下文中的适应性。

Conclusion: Inverse IFEval可作为诊断工具和开发方法的基石，以缓解LLMs的认知惯性，减少对狭隘模式的过拟合，并最终提高LLMs在多样化和不可预测的现实场景中遵循指令的可靠性。

Abstract: Large Language Models (LLMs) achieve strong performance on diverse tasks but
often exhibit cognitive inertia, struggling to follow instructions that
conflict with the standardized patterns learned during supervised fine-tuning
(SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that
measures models Counter-intuitive Abilitytheir capacity to override
training-induced biases and comply with adversarial instructions. Inverse
IFEval introduces eight types of such challenges, including Question
Correction, Intentional Textual Flaws, Code without Comments, and
Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a
dataset of 1012 high-quality Chinese and English questions across 23 domains,
evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing
leading LLMs demonstrate the necessity of our proposed Inverse IFEval
benchmark. Our findings emphasize that future alignment efforts should not only
pursue fluency and factual correctness but also account for adaptability under
unconventional contexts. We hope that Inverse IFEval serves as both a
diagnostic tool and a foundation for developing methods that mitigate cognitive
inertia, reduce overfitting to narrow patterns, and ultimately enhance the
instruction-following reliability of LLMs in diverse and unpredictable
real-world scenarios.

</details>


### [157] [PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity Disambiguation](https://arxiv.org/abs/2509.04357)
*Jiajun He,Naoki Sawada,Koichi Miyazaki,Tomoki Toda*

Main category: cs.CL

TL;DR: PARCO通过音素感知编码、对比实体消歧和分层过滤，显著提升了上下文ASR系统对领域特定命名实体（尤其是同音词）的识别能力，并表现出强大的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）系统在处理领域特定的命名实体时（特别是同音词）表现不佳。现有的上下文ASR虽然有所改进，但由于实体多样性有限，难以捕捉细微的音素差异。此外，先前方法将实体视为独立标记，导致多标记偏置不完整。

Method: 本文提出了Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation (PARCO)。该方法集成了音素感知编码、对比实体消歧、实体级监督和分层实体过滤。这些组件旨在增强语音辨别能力，确保完整的实体检索，并减少不确定性下的误报。

Result: 在包含1,000个干扰词的情况下，PARCO在中文AISHELL-1数据集上实现了4.22%的字符错误率（CER），在英文DATA2数据集上实现了11.14%的词错误率（WER），显著优于基线系统。PARCO还在域外数据集（如THCHS-30和LibriSpeech）上展现了稳健的性能提升。

Conclusion: PARCO通过其创新的组件，有效解决了ASR系统在识别领域特定命名实体和同音词方面的挑战，显著提升了识别性能，并在不同数据集上表现出强大的鲁棒性。

Abstract: Automatic speech recognition (ASR) systems struggle with domain-specific
named entities, especially homophones. Contextual ASR improves recognition but
often fails to capture fine-grained phoneme variations due to limited entity
diversity. Moreover, prior methods treat entities as independent tokens,
leading to incomplete multi-token biasing. To address these issues, we propose
Phoneme-Augmented Robust Contextual ASR via COntrastive entity disambiguation
(PARCO), which integrates phoneme-aware encoding, contrastive entity
disambiguation, entity-level supervision, and hierarchical entity filtering.
These components enhance phonetic discrimination, ensure complete entity
retrieval, and reduce false positives under uncertainty. Experiments show that
PARCO achieves CER of 4.22% on Chinese AISHELL-1 and WER of 11.14% on English
DATA2 under 1,000 distractors, significantly outperforming baselines. PARCO
also demonstrates robust gains on out-of-domain datasets like THCHS-30 and
LibriSpeech.

</details>


### [158] [Measuring Bias or Measuring the Task: Understanding the Brittle Nature of LLM Gender Biases](https://arxiv.org/abs/2509.04373)
*Bufan Gao,Elisa Kreiss*

Main category: cs.CL

TL;DR: 本文研究了提示语中是否明确指出评估目的如何影响大型语言模型（LLMs）中测量的性别偏见，发现微小的提示语变化会显著改变偏见结果，并质疑现有评估方法的生态有效性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在社会影响领域应用日益广泛，人们对性别偏见的担忧促使了对其测量和缓解的努力。然而，这些评估任务通常依赖于精心构造的提示语，与自然语言分布不同，可能无意中发出性别偏见相关内容的信号。因此，研究提示语中评估目的的信号如何影响LLMs中测量的性别偏见成为必要。

Method: 研究者在以下两种提示语条件下测试了模型：1) 使测试上下文显著；2) 使性别相关内容显著。然后，他们通过四种任务格式，使用词元概率和离散选择两种指标评估了提示语的敏感性。

Result: 研究发现，即使是微小的提示语变化也能显著改变偏见结果，有时甚至完全逆转偏见方向。此外，相对于概率度量，离散选择度量往往会放大偏见。

Conclusion: 这些发现不仅突出了LLM性别偏见评估的脆弱性，也为NLP基准测试和开发社区提出了新问题：精心控制的测试设计能在多大程度上触发LLM的“测试模式”表现，以及这对未来基准测试的生态有效性意味着什么。

Abstract: As LLMs are increasingly applied in socially impactful settings, concerns
about gender bias have prompted growing efforts both to measure and mitigate
such bias. These efforts often rely on evaluation tasks that differ from
natural language distributions, as they typically involve carefully constructed
task prompts that overtly or covertly signal the presence of gender
bias-related content. In this paper, we examine how signaling the evaluative
purpose of a task impacts measured gender bias in LLMs. Concretely, we test
models under prompt conditions that (1) make the testing context salient, and
(2) make gender-focused content salient. We then assess prompt sensitivity
across four task formats with both token-probability and discrete-choice
metrics. We find that even minor prompt changes can substantially alter bias
outcomes, sometimes reversing their direction entirely. Discrete-choice metrics
further tend to amplify bias relative to probabilistic measures. These findings
do not only highlight the brittleness of LLM gender bias evaluations but open a
new puzzle for the NLP benchmarking and development community: To what extent
can well-controlled testing designs trigger LLM ``testing mode'' performance,
and what does this mean for the ecological validity of future benchmarks.

</details>


### [159] [Can Language Models Handle a Non-Gregorian Calendar?](https://arxiv.org/abs/2509.04432)
*Mutsumi Sasaki,Go Kamoda,Ryosuke Takahashi,Kosuke Sato,Kentaro Inui,Keisuke Sakaguchi,Benjamin Heinzerling*

Main category: cs.CL

TL;DR: 本文系统评估了开源语言模型在处理非公历（特别是日本日历）方面的能力，发现即使是日文模型也难以进行算术运算和保持跨日历一致性。


<details>
  <summary>Details</summary>
Motivation: 语言模型的时间推理能力大多集中在公历上，但许多非公历系统（如日本、伊斯兰、希伯来日历）仍在广泛使用，反映了文化背景下的时间概念。目前尚未评估现有语言模型处理这些非公历系统的能力。

Method: 研究人员对开源语言模型处理日本日历的能力进行了系统评估。为此，他们创建了四个需要时间知识和时间推理的数据集，并评估了一系列以英语为中心和以日语为中心的语言模型。

Result: 评估结果显示，一些模型能够执行日历转换，但即使是以日语为中心的模型在处理日本日历的算术运算以及保持跨日历一致性方面也表现不佳。

Conclusion: 研究结果强调了开发更适合文化特定日历理解的语言模型的重要性。

Abstract: Temporal reasoning and knowledge are essential capabilities for language
models (LMs). While much prior work has analyzed and improved temporal
reasoning in LMs, most studies have focused solely on the Gregorian calendar.
However, many non-Gregorian systems, such as the Japanese, Hijri, and Hebrew
calendars, are in active use and reflect culturally grounded conceptions of
time. If and how well current LMs can accurately handle such non-Gregorian
calendars has not been evaluated so far. Here, we present a systematic
evaluation of how well open-source LMs handle one such non-Gregorian system:
the Japanese calendar. For our evaluation, we create datasets for four tasks
that require both temporal knowledge and temporal reasoning. Evaluating a range
of English-centric and Japanese-centric LMs, we find that some models can
perform calendar conversions, but even Japanese-centric models struggle with
Japanese-calendar arithmetic and with maintaining consistency across calendars.
Our results highlight the importance of developing LMs that are better equipped
for culture-specific calendar understanding.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [160] [Self-Organizing Aerial Swarm Robotics for Resilient Load Transportation : A Table-Mechanics-Inspired Approach](https://arxiv.org/abs/2509.03563)
*Quan Quan,Jiwen Xu,Runxiao Liu,Yi Ding,Jiaxing Che,Kai-Yuan Cai*

Main category: cs.RO

TL;DR: 本文提出了一种受物理学启发的无人机蜂群协同运输方法，该方法模仿桌腿的耗散力学，实现了去中心化、无通信的编队稳定和自适应载荷分配，并在仿真和实际实验中展现出卓越的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有协同运输方法在可扩展性、通信依赖性和动态故障鲁棒性方面存在局限性，而机器人蜂群的协同空中运输在物流和灾难响应中具有变革性潜力。

Method: 该研究开发了一种受物理学启发的去中心化耗散力模型，模仿桌腿载荷分配的耗散力学。每个机器人根据局部邻居和悬挂载荷动态调整位置，无需明确通信即可实现自主编队稳定和自适应载荷分配。该控制系统的稳定性得到了严格证明。

Result: 仿真结果表明，在能力变化、电缆不确定性、有限视野和载荷变化情况下，所提出方法的跟踪误差分别比现有方法低20%、68%、55.5%和21.9%。在六个飞行机器人的实际实验中，该系统在单机器人故障、断开事件、25%载荷变化和40%电缆长度不确定性下实现了94%的成功率，并在高达蒲福氏风级4级的室外风中表现出强大的鲁棒性。

Conclusion: 这种受物理学启发的协同运输方法将蜂群智能与机械稳定性原理相结合，为异构空中系统在通信受限环境中集体处理复杂运输任务提供了一个可扩展的框架。

Abstract: In comparison with existing approaches, which struggle with scalability,
communication dependency, and robustness against dynamic failures, cooperative
aerial transportation via robot swarms holds transformative potential for
logistics and disaster response. Here, we present a physics-inspired
cooperative transportation approach for flying robot swarms that imitates the
dissipative mechanics of table-leg load distribution. By developing a
decentralized dissipative force model, our approach enables autonomous
formation stabilization and adaptive load allocation without the requirement of
explicit communication. Based on local neighbor robots and the suspended
payload, each robot dynamically adjusts its position. This is similar to
energy-dissipating table leg reactions. The stability of the resultant control
system is rigorously proved. Simulations demonstrate that the tracking errors
of the proposed approach are 20%, 68%, 55.5%, and 21.9% of existing approaches
under the cases of capability variation, cable uncertainty, limited vision, and
payload variation, respectively. In real-world experiments with six flying
robots, the cooperative aerial transportation system achieved a 94% success
rate under single-robot failure, disconnection events, 25% payload variation,
and 40% cable length uncertainty, demonstrating strong robustness under outdoor
winds up to Beaufort scale 4. Overall, this physics-inspired approach bridges
swarm intelligence and mechanical stability principles, offering a scalable
framework for heterogeneous aerial systems to collectively handle complex
transportation tasks in communication-constrained environments.

</details>


### [161] [Cooperative Grasping for Collective Object Transport in Constrained Environments](https://arxiv.org/abs/2509.03638)
*David Alvear,George Turkiyyah,Shinkyu Park*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的框架，用于在受限环境中进行双机器人协作抓取和物体运输。该框架核心是一个条件嵌入（CE）模型，能够识别可行的抓取配置。


<details>
  <summary>Details</summary>
Motivation: 在受限环境中，双机器人协作抓取和物体运输的决策是一个挑战。需要一种通用的方法来识别可行的抓取配置，以确保机器人能够协同运输物体，并适用于各种环境和物体几何形状。

Method: 该方法的核心是一个条件嵌入（CE）模型，由两个神经网络组成。这些网络将抓取配置信息映射到一个嵌入空间中。通过监督学习和负采样，在包含多种环境地图和物体形状的数据集上训练这些网络，以有效区分可行和不可行的抓取配置。

Result: 在广泛的模拟环境和物体中进行的评估表明，该模型能够可靠地识别可行的抓取配置。通过在物理机器人平台上的实验进一步验证了该框架的实际适用性。

Conclusion: 所提出的基于条件嵌入模型的框架，能够有效地识别双机器人在受限环境中进行协作抓取的可行配置，并在模拟和物理实验中均表现出可靠性和实用性。

Abstract: We propose a novel framework for decision-making in cooperative grasping for
two-robot object transport in constrained environments. The core of the
framework is a Conditional Embedding (CE) model consisting of two neural
networks that map grasp configuration information into an embedding space. The
resulting embedding vectors are then used to identify feasible grasp
configurations that allow two robots to collaboratively transport an object. To
ensure generalizability across diverse environments and object geometries, the
neural networks are trained on a dataset comprising a range of environment maps
and object shapes. We employ a supervised learning approach with negative
sampling to ensure that the learned embeddings effectively distinguish between
feasible and infeasible grasp configurations. Evaluation results across a wide
range of environments and objects in simulations demonstrate the model's
ability to reliably identify feasible grasp configurations. We further validate
the framework through experiments on a physical robotic platform, confirming
its practical applicability.

</details>


### [162] [Efficient Virtuoso: A Latent Diffusion Transformer Model for Goal-Conditioned Trajectory Planning](https://arxiv.org/abs/2509.03658)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: 本文提出了Efficient Virtuoso，一个用于目标条件轨迹规划的条件潜在扩散模型，通过新颖的两阶段归一化和高效去噪，在Waymo数据集上实现了最先进的性能，并强调了多步稀疏路径对于高保真战术执行的重要性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶规划系统需要生成多样且合理的未来轨迹。尽管现有生成模型有前景，但在实现高保真度、计算效率和精确控制方面仍面临挑战。

Method: 本文提出了Efficient Virtuoso，一个用于目标条件轨迹规划的条件潜在扩散模型。其核心方法包括：1) 新颖的两阶段归一化流程，首先缩放轨迹以保留几何纵横比，然后归一化PCA潜在空间以确保稳定的训练目标。2) 去噪过程在一个低维潜在空间中通过一个简单的MLP去噪器高效完成，该去噪器以Transformer-based StateEncoder融合的丰富场景上下文为条件。3) 对目标表示进行了严格的消融研究。

Result: 该方法在Waymo Open Motion Dataset上实现了最先进的性能，minADE达到0.25。通过对目标表示的消融研究发现：单一终点目标可以解决战略模糊性，但更丰富的多步稀疏路径对于实现模仿人类驾驶行为的精确、高保真战术执行至关重要。

Conclusion: Efficient Virtuoso通过其创新的归一化和高效的潜在空间去噪，为自动驾驶轨迹规划提供了一个高性能解决方案。研究还揭示了使用多步稀疏路径作为目标表示对于实现精细、高保真战术执行的关键作用，这对于模拟人类驾驶行为至关重要。

Abstract: The ability to generate a diverse and plausible distribution of future
trajectories is a critical capability for autonomous vehicle planning systems.
While recent generative models have shown promise, achieving high fidelity,
computational efficiency, and precise control remains a significant challenge.
In this paper, we present the \textbf{Efficient Virtuoso}, a conditional latent
diffusion model for goal-conditioned trajectory planning. Our approach
introduces a novel two-stage normalization pipeline that first scales
trajectories to preserve their geometric aspect ratio and then normalizes the
resulting PCA latent space to ensure a stable training target. The denoising
process is performed efficiently in this low-dimensional latent space by a
simple MLP denoiser, which is conditioned on a rich scene context fused by a
powerful Transformer-based StateEncoder. We demonstrate that our method
achieves state-of-the-art performance on the Waymo Open Motion Dataset,
reaching a \textbf{minADE of 0.25}. Furthermore, through a rigorous ablation
study on goal representation, we provide a key insight: while a single endpoint
goal can resolve strategic ambiguity, a richer, multi-step sparse route is
essential for enabling the precise, high-fidelity tactical execution that
mirrors nuanced human driving behavior.

</details>


### [163] [Low-Cost Open-Source Ambidextrous Robotic Hand with 23 Direct-Drive servos for American Sign Language Alphabet](https://arxiv.org/abs/2509.03690)
*Kelvin Daniel Gonzalez Amador*

Main category: cs.RO

TL;DR: VulcanV3是一种低成本、开源、3D打印的灵巧型机器人手，能够以高识别准确率再现完整的美国手语（ASL）字母表。


<details>
  <summary>Details</summary>
Motivation: 手语对聋哑社区的交流至关重要，但现有的机器人解决方案往往成本高昂且功能有限，阻碍了无障碍沟通的普及。

Method: 本研究提出了VulcanV3，一种低成本、开源、3D打印的灵巧型机器人手。它采用23个直驱伺服执行器进行精确的手指和手腕运动，由Arduino Mega和双PCA9685模块控制。该系统具有可逆设计，能够重现完整的美国手语字母表（左右手共52个手势）。所有CAD文件和代码均以开放源代码许可发布。

Result: 经验测试证实VulcanV3能够准确再现所有52种ASL手形。一项参与者研究（n=33）显示，其识别准确率达到96.97%，在视频演示后提高到98.78%。

Conclusion: VulcanV3通过在一个开放共享的平台上结合了经济性、完整的ASL覆盖和灵巧性，推动了辅助机器人技术的发展，为无障碍通信技术和包容性创新做出了贡献。

Abstract: Accessible communication through sign language is vital for deaf communities,
1 yet robotic solutions are often costly and limited. This study presents
VulcanV3, a low- 2 cost, open-source, 3D-printed ambidextrous robotic hand
capable of reproducing the full 3 American Sign Language (ASL) alphabet (52
signs for right- and left-hand configurations). 4 The system employs 23
direct-drive servo actuators for precise finger and wrist movements, 5
controlled by an Arduino Mega with dual PCA9685 modules. Unlike most humanoid
upper- 6 limb systems, which rarely employ direct-drive actuation, VulcanV3
achieves complete ASL 7 coverage with a reversible design. All CAD files and
code are released under permissive 8 open-source licenses to enable
replication. Empirical tests confirmed accurate reproduction 9 of all 52 ASL
handshapes, while a participant study (n = 33) achieved 96.97% recognition 10
accuracy, improving to 98.78% after video demonstration. VulcanV3 advances
assistive 11 robotics by combining affordability, full ASL coverage, and
ambidexterity in an openly 12 shared platform, contributing to accessible
communication technologies and inclusive 13 innovation.

</details>


### [164] [Real-Time Buoyancy Estimation for AUV Simulations Using Convex Hull-Based Submerged Volume Calculation](https://arxiv.org/abs/2509.03804)
*Ad-Deen Mahbub,Md Ragib Shaharear*

Main category: cs.RO

TL;DR: 本文提出了一种基于凸包的新方法，用于在NVIDIA Isaac Sim中实时、准确地计算AUV的浮力，解决了平台缺乏原生浮力系统的问题。


<details>
  <summary>Details</summary>
Motivation: 高精度AUV仿真需要准确的实时浮力建模，但NVIDIA Isaac Sim缺乏原生的浮力系统，需要外部解决方案来实现精确的水下物理模拟。

Method: 该方法通过从仿真环境中提取网格几何体，并沿Z轴计算与水面相交的凸包部分，动态计算AUV的浸没体积。此外，通过横截面积扩展技术降低了计算开销，实现了高效的浮力更新，能适应姿态、深度和正弦波波动。

Result: 该方法在为SAUVC 2025设计的定制AUV上进行了测试，实现了实时性能和可扩展性，提高了水下机器人研究的仿真保真度，且无需预计算流体动力学模型。

Conclusion: 所提出的基于凸包的浮力计算方法为Isaac Sim中的AUV仿真提供了准确、实时的浮力模型，显著提升了仿真精度和效率，且能够适应复杂的环境变化。

Abstract: Accurate real-time buoyancy modeling is essential for high-fidelity
Autonomous Underwater Vehicle (AUV) simulations, yet NVIDIA Isaac Sim lacks a
native buoyancy system, requiring external solutions for precise underwater
physics. This paper presents a novel convex hull-based approach to dynamically
compute the submerged volume of an AUV in real time. By extracting mesh
geometry from the simulation environment and calculating the hull portion
intersecting the water level along the z-axis, our method enhances accuracy
over traditional geometric approximations. A cross-sectional area extension
reduces computational overhead, enabling efficient buoyant force updates that
adapt to orientation, depth, and sinusoidal wave fluctuations (+-0.3 m). Tested
on a custom AUV design for SAUVC 2025, this approach delivers real-time
performance and scalability, improving simulation fidelity for underwater
robotics research without precomputed hydrodynamic models.

</details>


### [165] [INGRID: Intelligent Generative Robotic Design Using Large Language Models](https://arxiv.org/abs/2509.03842)
*Guanglu Jia,Ceng Zhang,Gregory S. Chirikjian*

Main category: cs.RO

TL;DR: INGRID是一个将大语言模型（LLMs）与倒数螺旋理论和运动学综合方法深度结合的框架，旨在实现并联机器人机构的自动化设计，从而突破现有硬件对机器人智能的限制。


<details>
  <summary>Details</summary>
Motivation: 将LLMs集成到机器人系统中加速了具身人工智能的进展，但现有方法受限于串联机构等硬件，这种硬件依赖性从根本上限制了机器人智能的范围。研究的动机是解耦机器人智能的进步与硬件约束。

Method: 本研究提出了INGRID（智能生成机器人设计）框架，通过与倒数螺旋理论和运动学综合方法的深度集成，实现并联机器人机构的自动化设计。设计挑战被分解为四个渐进任务：约束分析、运动关节生成、链构造和完整机构设计。

Result: INGRID展示了生成具有固定和可变移动性的新型并联机构的能力，并发现了文献中未曾记载的运动学配置。通过三个案例研究验证了该方法，展示了INGRID如何根据所需的移动性要求协助用户设计特定任务的并联机器人。它使得没有专业机器人学培训的研究人员也能创建定制的并联机构。

Conclusion: INGRID通过弥合机构理论和机器学习之间的鸿沟，使机器人智能的进步不再受硬件限制。这项工作为“机构智能”奠定了基础，即AI系统主动设计机器人硬件，这可能彻底改变具身AI系统的发展。

Abstract: The integration of large language models (LLMs) into robotic systems has
accelerated progress in embodied artificial intelligence, yet current
approaches remain constrained by existing robotic architectures, particularly
serial mechanisms. This hardware dependency fundamentally limits the scope of
robotic intelligence. Here, we present INGRID (Intelligent Generative Robotic
Design), a framework that enables the automated design of parallel robotic
mechanisms through deep integration with reciprocal screw theory and kinematic
synthesis methods. We decompose the design challenge into four progressive
tasks: constraint analysis, kinematic joint generation, chain construction, and
complete mechanism design. INGRID demonstrates the ability to generate novel
parallel mechanisms with both fixed and variable mobility, discovering
kinematic configurations not previously documented in the literature. We
validate our approach through three case studies demonstrating how INGRID
assists users in designing task-specific parallel robots based on desired
mobility requirements. By bridging the gap between mechanism theory and machine
learning, INGRID enables researchers without specialized robotics training to
create custom parallel mechanisms, thereby decoupling advances in robotic
intelligence from hardware constraints. This work establishes a foundation for
mechanism intelligence, where AI systems actively design robotic hardware,
potentially transforming the development of embodied AI systems.

</details>


### [166] [Learning Multi-Stage Pick-and-Place with a Legged Mobile Manipulator](https://arxiv.org/abs/2509.03859)
*Haichao Zhang,Haonan Yu,Le Zhao,Andrew Choi,Qinxun Bai,Yiqing Yang,Wei Xu*

Main category: cs.RO

TL;DR: 本文提出了一种在模拟环境中训练视觉-运动策略的方法，用于四足机器人移动操作的抓取-放置任务，并在真实世界中实现了近80%的成功率，展示了高效的仿真到现实迁移。


<details>
  <summary>Details</summary>
Motivation: 四足机器人移动操作面临技能多样性、任务周期长和部分可观察性等重大挑战，需要一种能够有效应对这些复杂性的方法。

Method: 研究者提出了一种完全在模拟环境中训练视觉-运动策略的方法，用于多阶段的抓取-放置任务。该策略能够高效执行搜索、接近、抓取、运输和放置等动作，并涌现出重新抓取和任务链等行为。通过广泛的真实世界实验和消融研究来验证关键技术。

Result: 所提出的策略在真实世界中实现了近80%的成功率。实验证明了高效训练和有效的仿真到现实迁移的关键技术。此外，该方法在多种室内外环境中均表现出良好的部署能力。

Conclusion: 通过在模拟环境中训练的视觉-运动策略，四足机器人能够成功执行复杂的移动操作任务，并在真实世界中实现高成功率和鲁棒的仿真到现实迁移，同时展现出复杂的自主行为。

Abstract: Quadruped-based mobile manipulation presents significant challenges in
robotics due to the diversity of required skills, the extended task horizon,
and partial observability. After presenting a multi-stage pick-and-place task
as a succinct yet sufficiently rich setup that captures key desiderata for
quadruped-based mobile manipulation, we propose an approach that can train a
visuo-motor policy entirely in simulation, and achieve nearly 80\% success in
the real world. The policy efficiently performs search, approach, grasp,
transport, and drop into actions, with emerged behaviors such as re-grasping
and task chaining. We conduct an extensive set of real-world experiments with
ablation studies highlighting key techniques for efficient training and
effective sim-to-real transfer. Additional experiments demonstrate deployment
across a variety of indoor and outdoor environments. Demo videos and additional
resources are available on the project page:
https://horizonrobotics.github.io/gail/SLIM.

</details>


### [167] [Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance](https://arxiv.org/abs/2509.03889)
*Neha Sunil,Megha Tippur,Arnau Saumell,Edward Adelson,Alberto Rodriguez*

Main category: cs.RO

TL;DR: 本文提出一个双臂视觉触觉框架，结合置信度感知的密集视觉对应和触觉监督的抓取能力，直接操作褶皱和悬挂衣物，并能处理高度遮挡情况，实现鲁棒的服装操作。


<details>
  <summary>Details</summary>
Motivation: 服装操作因复杂构型、多变材料动力学和频繁自遮挡而充满挑战。现有系统通常要求展平衣物或假设关键特征可见，限制了其在实际场景中的应用。

Method: 该框架包含两个核心组件：1) 置信度感知的密集视觉对应模型，通过在自定义高保真模拟数据集上训练，利用分布损失捕获布料对称性并生成置信度估计，这些估计指导一个响应式状态机调整折叠策略。2) 触觉监督的抓取能力网络，通过高分辨率触觉反馈进行自监督，确定物理上可抓取的区域，并在执行期间使用同一触觉分类器进行实时抓取验证。系统通过在低置信度状态下推迟行动，以处理高度遮挡的桌面和空中配置。

Result: 该系统能够直接操作褶皱和悬挂的衣物，并有效处理高度遮挡的桌面和空中配置。研究者在折叠和悬挂任务中展示了其任务无关的抓取选择模块。此外，提出的密集描述符提供了一种可重用的中间表示。

Conclusion: 该框架通过结合视觉对应和触觉监督的抓取能力，克服了服装操作中的多项挑战。其密集描述符作为可重用的中间表示，有望应用于其他规划模式（如从人类视频演示中提取抓取目标），为更通用和可扩展的服装操作铺平了道路。

Abstract: Manipulating clothing is challenging due to complex configurations, variable
material dynamics, and frequent self-occlusion. Prior systems often flatten
garments or assume visibility of key features. We present a dual-arm
visuotactile framework that combines confidence-aware dense visual
correspondence and tactile-supervised grasp affordance to operate directly on
crumpled and suspended garments. The correspondence model is trained on a
custom, high-fidelity simulated dataset using a distributional loss that
captures cloth symmetries and generates correspondence confidence estimates.
These estimates guide a reactive state machine that adapts folding strategies
based on perceptual uncertainty. In parallel, a visuotactile grasp affordance
network, self-supervised using high-resolution tactile feedback, determines
which regions are physically graspable. The same tactile classifier is used
during execution for real-time grasp validation. By deferring action in
low-confidence states, the system handles highly occluded table-top and in-air
configurations. We demonstrate our task-agnostic grasp selection module in
folding and hanging tasks. Moreover, our dense descriptors provide a reusable
intermediate representation for other planning modalities, such as extracting
grasp targets from human video demonstrations, paving the way for more
generalizable and scalable garment manipulation.

</details>


### [168] [Odometry Calibration and Pose Estimation of a 4WIS4WID Mobile Wall Climbing Robot](https://arxiv.org/abs/2509.04016)
*Branimir Ćaran,Vladimir Milić,Marko Švaco,Bojan Jerbić*

Main category: cs.RO

TL;DR: 本文提出了一种基于多模态传感器融合（轮式里程计、视觉里程计、IMU）的四轮独立转向四轮独立驱动 (4WIS4WID) 爬墙移动机器人位姿估计器设计，并使用扩展卡尔曼滤波 (EKF) 和无迹卡尔曼滤波 (UKF) 进行融合，同时对系统参数和运动学参数进行了校准和实验验证。


<details>
  <summary>Details</summary>
Motivation: 爬墙机器人需要在建筑立面上携带精密测量设备和维护工具，因此精确的位姿信息至关重要。传统定位传感器（激光、超声波、雷达）因建筑立面复杂几何和材料特性而不可行；GPS 因钢筋混凝土和电磁干扰导致信号衰减而不可靠；机器人里程计虽是主要速度和位置来源，但易受系统性和非系统性误差影响而产生漂移。

Method: 位姿估计器设计：融合轮式里程计、视觉里程计和惯性测量单元 (IMU) 数据。融合算法：扩展卡尔曼滤波 (EKF) 和无迹卡尔曼滤波 (UKF)。系统参数校准：采用非线性优化、Levenberg-Marquardt 方法（牛顿-高斯和基于梯度的模型拟合）。运动学参数校准：采用遗传算法和粒子群算法（基于随机的方法）。性能验证：在实验性爬墙移动机器人上进行了详细的实验验证。

Result: 校准方法和位姿估计器的性能和结果均通过在实验性爬墙移动机器人上的实验得到了详细验证。

Conclusion: 本文成功设计并验证了一种针对4WIS4WID爬墙移动机器人的多模态融合位姿估计器，并开发了相应的系统和运动学参数校准方法，有效解决了复杂作业环境下的定位挑战。

Abstract: This paper presents the design of a pose estimator for a four wheel
independent steer four wheel independent drive (4WIS4WID) wall climbing mobile
robot, based on the fusion of multimodal measurements, including wheel
odometry, visual odometry, and an inertial measurement unit (IMU) data using
Extended Kalman Filter (EKF) and Unscented Kalman Filter (UKF). The pose
estimator is a critical component of wall climbing mobile robots, as their
operational environment involves carrying precise measurement equipment and
maintenance tools in construction, requiring information about pose on the
building at the time of measurement. Due to the complex geometry and material
properties of building facades, the use of traditional localization sensors
such as laser, ultrasonic, or radar is often infeasible for wall-climbing
robots. Moreover, GPS-based localization is generally unreliable in these
environments because of signal degradation caused by reinforced concrete and
electromagnetic interference. Consequently, robot odometry remains the primary
source of velocity and position information, despite being susceptible to drift
caused by both systematic and non-systematic errors. The calibrations of the
robot's systematic parameters were conducted using nonlinear optimization and
Levenberg-Marquardt methods as Newton-Gauss and gradient-based model fitting
methods, while Genetic algorithm and Particle swarm were used as
stochastic-based methods for kinematic parameter calibration. Performance and
results of the calibration methods and pose estimators were validated in detail
with experiments on the experimental mobile wall climbing robot.

</details>


### [169] [FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction](https://arxiv.org/abs/2509.04018)
*Yifan Yang,Zhixiang Duan,Tianshi Xie,Fuyu Cao,Pinxi Shen,Peili Song,Piaopiao Jin,Guokang Sun,Shaoqing Xu,Yangwei You,Jingtai Liu*

Main category: cs.RO

TL;DR: FPC-VLA 是一种双模型框架，将视觉-语言-动作 (VLA) 模型与一个用于故障预测和纠正的监督器集成，在机器人操作任务中显著提高了成功率，且对执行时间影响极小。


<details>
  <summary>Details</summary>
Motivation: 传统的感知-规划流程在开放式任务中缺乏灵活性，而单一的端到端 VLA 架构虽然有前景，但缺乏预测和从故障中恢复的关键机制。

Method: FPC-VLA 框架包含一个 VLA 模型和一个监督器。监督器通过视觉-语言查询评估动作可行性，并在风险出现时生成纠正策略，且无需手动标记即可高效训练。一个相似性引导的融合模块通过利用过去的预测来进一步优化动作。监督器仅在关键帧激活。

Result: FPC-VLA 在多个模拟平台（SIMPLER 和 LIBERO）和机器人（WidowX、Google Robot、Franka）上的零样本和微调设置中均优于最先进的模型。它显著提高了任务成功率，同时对执行时间影响最小。在各种长期真实世界任务中的成功部署也证实了其强大的泛化能力和实用性。

Conclusion: FPC-VLA 展现出强大的泛化能力和实用性，为构建更可靠的自主系统提供了有效途径。

Abstract: Robotic manipulation is a fundamental component of automation. However,
traditional perception-planning pipelines often fall short in open-ended tasks
due to limited flexibility, while the architecture of a single end-to-end
Vision-Language-Action (VLA) offers promising capabilities but lacks crucial
mechanisms for anticipating and recovering from failure. To address these
challenges, we propose FPC-VLA, a dual-model framework that integrates VLA with
a supervisor for failure prediction and correction. The supervisor evaluates
action viability through vision-language queries and generates corrective
strategies when risks arise, trained efficiently without manual labeling. A
similarity-guided fusion module further refines actions by leveraging past
predictions. Evaluation results on multiple simulation platforms (SIMPLER and
LIBERO) and robot embodiments (WidowX, Google Robot, Franka) show that FPC-VLA
outperforms state-of-the-art models in both zero-shot and fine-tuned settings.
By activating the supervisor only at keyframes, our approach significantly
increases task success rates with minimal impact on execution time. Successful
real-world deployments on diverse, long-horizon tasks confirm FPC-VLA's strong
generalization and practical utility for building more reliable autonomous
systems.

</details>


### [170] [Integrated Wheel Sensor Communication using ESP32 -- A Contribution towards a Digital Twin of the Road System](https://arxiv.org/abs/2509.04061)
*Ventseslav Yordanov,Simon Schäfer,Alexander Mann,Stefan Kowalewski,Bassam Alrifaee,Lutz Eckstein*

Main category: cs.RO

TL;DR: 本文提出了一种基于ESP32微控制器和发布-订阅系统的新型通信概念，用于高效传输集成轮毂传感器数据。在滚筒轮胎试验台上进行测试，结果表明该系统在数据传输量上优于现有方案，并实现了极低的数据丢失率。


<details>
  <summary>Details</summary>
Motivation: 当前的车载状态估计方法无法深入了解轮胎与路面之间的相互作用，因此需要一种新的方法来高效获取轮毂传感器数据。

Method: 研究了一种利用ESP32微控制器和发布-订阅系统的高效集成轮毂传感器数据传输通信概念。该方法在滚筒轮胎试验台上使用原型传感器系统进行了测试，采样频率范围在1 Hz到32000 Hz之间。

Result: 所提出的方法在数据传输量方面超越了现有文献中的可比解决方案。实现的通信系统数据丢失率极低，约为采样数据的0.1%。

Conclusion: 该研究验证了所开发通信系统的可靠性和有效性，并为推进实时数据采集以及优化集成轮毂传感器通信提供了有价值的见解。

Abstract: While current onboard state estimation methods are adequate for most driving
and safety-related applications, they do not provide insights into the
interaction between tires and road surfaces. This paper explores a novel
communication concept for efficiently transmitting integrated wheel sensor data
from an ESP32 microcontroller. Our proposed approach utilizes a
publish-subscribe system, surpassing comparable solutions in the literature
regarding data transmission volume. We tested this approach on a drum tire test
rig with our prototype sensors system utilizing a diverse selection of sample
frequencies between 1 Hz and 32 000 Hz to demonstrate the efficacy of our
communication concept. The implemented prototype sensor showcases minimal data
loss, approximately 0.1 % of the sampled data, validating the reliability of
our developed communication system. This work contributes to advancing
real-time data acquisition, providing insights into optimizing integrated wheel
sensor communication.

</details>


### [171] [Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models](https://arxiv.org/abs/2509.04063)
*Hongyin Zhang,Shiyuan Zhang,Junxi Jin,Qixin Zeng,Yifan Qiao,Hongchao Lu,Donglin Wang*

Main category: cs.RO

TL;DR: 针对基于流匹配的VLA模型在复杂任务上动作精度不足的问题，本文提出了ARFM算法，通过引入自适应调整的离线强化学习后训练目标，有效提升了模型的泛化、鲁棒性、少样本和持续学习性能。


<details>
  <summary>Details</summary>
Motivation: 基于流匹配的视觉-语言-动作（VLA）模型在通用机器人操作任务中表现出色，但在复杂下游任务上的动作精度不尽如人意。主要原因是这些模型仅依赖模仿学习的后训练范式，难以深入理解数据质量的分布特性，而这正是强化学习（RL）的优势所在。

Method: 本文理论上提出了VLA流模型的离线RL后训练目标，并由此推导出一个高效可行的离线RL微调算法——自适应强化流匹配（ARFM）。通过在VLA流模型损失中引入一个自适应调整的缩放因子，构建了一个有原则的偏差-方差权衡目标函数，以优化控制RL信号对流损失的影响。ARFM自适应地平衡了RL优势保留和流损失梯度方差控制。

Result: 大量的模拟和真实世界实验结果表明，ARFM展现出卓越的泛化能力、鲁棒性、少样本学习和持续学习性能。

Conclusion: ARFM通过引入自适应调整的离线强化学习信号，为VLA流模型提供了一种更稳定和高效的微调过程，显著提升了模型在复杂任务上的动作精度和整体性能。

Abstract: Vision-Language-Action (VLA) models based on flow matching have shown
excellent performance in general-purpose robotic manipulation tasks. However,
the action accuracy of these models on complex downstream tasks is
unsatisfactory. One important reason is that these models rely solely on the
post-training paradigm of imitation learning, which makes it difficult to have
a deeper understanding of the distribution properties of data quality, which is
exactly what Reinforcement Learning (RL) excels at. In this paper, we
theoretically propose an offline RL post-training objective for VLA flow models
and induce an efficient and feasible offline RL fine-tuning algorithm --
Adaptive Reinforced Flow Matching (ARFM). By introducing an adaptively adjusted
scaling factor in the VLA flow model loss, we construct a principled
bias-variance trade-off objective function to optimally control the impact of
RL signal on flow loss. ARFM adaptively balances RL advantage preservation and
flow loss gradient variance control, resulting in a more stable and efficient
fine-tuning process. Extensive simulation and real-world experimental results
show that ARFM exhibits excellent generalization, robustness, few-shot
learning, and continuous learning performance.

</details>


### [172] [Solving Robotics Tasks with Prior Demonstration via Exploration-Efficient Deep Reinforcement Learning](https://arxiv.org/abs/2509.04069)
*Chengyandan Shen,Christoffer Sloth*

Main category: cs.RO

TL;DR: 本文提出了DRLR框架，一种探索高效的深度强化学习方法，结合演示用于机器人任务。它通过改进IBRL的动作选择模块（提供校准Q值）和使用SAC，有效缓解了引导误差并防止收敛到次优策略。该方法在模拟和真实世界机器人任务中均得到验证，展现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在机器人学习任务中，现有的深度强化学习方法常面临探索效率低下（由引导误差引起）和策略可能收敛到次优解的问题。因此，需要一个能够有效利用演示数据并克服这些挑战的框架。

Method: DRLR（Deep Reinforcement Learning with Reference policy）框架基于IBRL算法开发。主要改进包括：1. 修改了动作选择模块，提供校准的Q值以缓解引导误差。2. 使用SAC（Soft Actor-Critic）作为RL策略而非TD3，以防止策略收敛到次优解。该框架整合了演示数据。通过在铲斗装载和抽屉开启等机器人任务中进行模拟和真实世界部署（sim2real），对方法进行了经验验证。

Result: DRLR框架成功缓解了引导误差并有效防止了过拟合（即收敛到次优策略）。在需要大量环境交互的机器人任务中（如铲斗装载和抽屉开启），其有效性得到了经验验证。仿真结果表明，DRLR框架在低维和高维状态-动作空间以及不同演示质量的任务中均展现出鲁棒性。此外，铲斗装载任务在真实轮式装载机上的sim2real部署也取得了成功。

Conclusion: DRLR框架是一个探索高效且鲁棒的深度强化学习方法，能够有效利用演示数据来学习机器人任务。它通过改进动作选择和策略选择，成功缓解了引导误差并防止了次优策略，并在模拟和真实世界的工业机器人任务中得到了成功验证。

Abstract: This paper proposes an exploration-efficient Deep Reinforcement Learning with
Reference policy (DRLR) framework for learning robotics tasks that incorporates
demonstrations. The DRLR framework is developed based on an algorithm called
Imitation Bootstrapped Reinforcement Learning (IBRL). We propose to improve
IBRL by modifying the action selection module. The proposed action selection
module provides a calibrated Q-value, which mitigates the bootstrapping error
that otherwise leads to inefficient exploration. Furthermore, to prevent the RL
policy from converging to a sub-optimal policy, SAC is used as the RL policy
instead of TD3. The effectiveness of our method in mitigating bootstrapping
error and preventing overfitting is empirically validated by learning two
robotics tasks: bucket loading and open drawer, which require extensive
interactions with the environment. Simulation results also demonstrate the
robustness of the DRLR framework across tasks with both low and high
state-action dimensions, and varying demonstration qualities. To evaluate the
developed framework on a real-world industrial robotics task, the bucket
loading task is deployed on a real wheel loader. The sim2real results validate
the successful deployment of the DRLR framework.

</details>


### [173] [Keypoint-based Diffusion for Robotic Motion Planning on the NICOL Robot](https://arxiv.org/abs/2509.04076)
*Lennart Clasmeier,Jan-Gerrit Habekost,Connor Gäde,Philipp Allgeuer,Stefan Wermter*

Main category: cs.RO

TL;DR: 该研究提出了一种基于扩散的深度学习模型用于机器人运动规划，通过学习传统规划器生成的数据集，显著缩短了运行时间，并取得了较高的无碰撞解决方案成功率。


<details>
  <summary>Details</summary>
Motivation: 传统的数值运动规划方法虽然能解决通用运动规划问题，但运行时间要求高，效率低下。

Method: 提出了一种新颖的基于扩散的机器人动作模型。该模型利用深度学习，从传统规划器生成的数据集中学习。最初模型尝试使用点云嵌入作为输入来预测基于关键点的关节序列，但在消融研究中发现点云嵌入的条件化存在挑战。通过识别并修正数据集中的偏差，提高了模型性能。最终模型在不使用点云编码的情况下也表现出色。

Result: 即使不使用点云编码，该模型在运行时间上比数值模型快一个数量级。在测试集上，实现了高达90%的无碰撞解决方案成功率。

Conclusion: 所提出的基于扩散的深度学习模型能够显著提高机器人运动规划的运行效率，同时保持高成功率，超越了传统的数值规划方法。

Abstract: We propose a novel diffusion-based action model for robotic motion planning.
Commonly, established numerical planning approaches are used to solve general
motion planning problems, but have significant runtime requirements. By
leveraging the power of deep learning, we are able to achieve good results in a
much smaller runtime by learning from a dataset generated by these planners.
While our initial model uses point cloud embeddings in the input to predict
keypoint-based joint sequences in its output, we observed in our ablation study
that it remained challenging to condition the network on the point cloud
embeddings. We identified some biases in our dataset and refined it, which
improved the model's performance. Our model, even without the use of the point
cloud encodings, outperforms numerical models by an order of magnitude
regarding the runtime, while reaching a success rate of up to 90% of collision
free solutions on the test set.

</details>


### [174] [Object-Reconstruction-Aware Whole-body Control of Mobile Manipulators](https://arxiv.org/abs/2509.04094)
*Fatih Dursun,Bruno Vilhena Adorno,Simon Watson,Wei Pan*

Main category: cs.RO

TL;DR: 本文提出了一种计算高效的机器人视角路径规划方法，通过计算并维持一个“焦点”在相机视野中，无需额外的路径规划器，实现了与采样基线方法相似的物体覆盖率和信息熵，但速度快了约九倍。


<details>
  <summary>Details</summary>
Motivation: 在机器人物体重建和检查任务中，识别能够揭示物体最多未知区域的路径至关重要，这被称为视角路径规划问题。现有方法常使用基于采样的路径规划技术，评估路径上的潜在视图以提高重建性能，但这些方法计算成本高昂，因为需要评估大量候选视图。

Method: 我们提出了一种计算高效的解决方案：计算物体最信息丰富（未知）区域的“焦点”，并让机器人在沿路径移动时将此焦点保持在相机视野中。我们将此策略整合到移动机械臂的全身控制中，采用可见性约束，无需额外的路径规划器。通过对114个多样化物体进行综合模拟，并与基于采样的规划策略进行贝叶斯数据分析比较。此外，还使用8自由度移动机械臂进行了真实世界实验。

Result: 研究结果表明，与基于采样的基线方法相比，我们提出的方法在物体覆盖率和信息熵方面没有显著差异。然而，在机器人两次视图之间花费的平均时间方面，我们的方法比基线方法快了大约九倍。

Conclusion: 我们提出的基于焦点的方法为视角路径规划提供了一个计算高效的解决方案，在不牺牲重建质量（覆盖率和信息熵）的前提下，显著提高了效率，尤其在机器人两次视图之间的时间消耗上表现出巨大优势。

Abstract: Object reconstruction and inspection tasks play a crucial role in various
robotics applications. Identifying paths that reveal the most unknown areas of
the object becomes paramount in this context, as it directly affects
efficiency, and this problem is known as the view path planning problem.
Current methods often use sampling-based path planning techniques, evaluating
potential views along the path to enhance reconstruction performance. However,
these methods are computationally expensive as they require evaluating several
candidate views on the path. To this end, we propose a computationally
efficient solution that relies on calculating a focus point in the most
informative (unknown) region and having the robot maintain this point in the
camera field of view along the path. We incorporated this strategy into the
whole-body control of a mobile manipulator employing a visibility constraint
without the need for an additional path planner. We conducted comprehensive and
realistic simulations using a large dataset of 114 diverse objects of varying
sizes from 57 categories to compare our method with a sampling-based planning
strategy using Bayesian data analysis. Furthermore, we performed real-world
experiments with an 8-DoF mobile manipulator to demonstrate the proposed
method's performance in practice. Our results suggest that there is no
significant difference in object coverage and entropy. In contrast, our method
is approximately nine times faster than the baseline sampling-based method in
terms of the average time the robot spends between views.

</details>


### [175] [Cloud-Assisted Remote Control for Aerial Robots: From Theory to Proof-of-Concept Implementation](https://arxiv.org/abs/2509.04095)
*Achilleas Santi Seisa,Viswa Narayanan Sankaranarayanan,Gerasimos Damigos,Sumeet Gajanan Satpute,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 本文提出一个可扩展且直观的框架，用于测试云和边缘机器人系统，该框架利用容器化技术构建云集群和机器人仿真环境，并通过UDP隧道和Linux流量控制模拟真实的双向网络条件。


<details>
  <summary>Details</summary>
Motivation: 云机器人技术因其卸载计算密集型任务、促进数据共享和增强机器人协调的优势而前景广阔。然而，由于网络延迟、安全问题和高效资源管理的需求，将云计算与机器人技术集成仍然是一个复杂的挑战。

Method: 该框架包含两个主要的容器化组件：(a) 容器化云集群和 (b) 容器化机器人仿真环境。系统通过用户数据报协议（UDP）隧道实现云集群容器与机器人仿真环境之间的双向通信，并利用基于Linux的流量控制引入人工延迟和抖动，以模拟实际云机器人部署中遇到的可变网络条件。具体应用案例是云辅助的空中机器人远程控制。

Result: 本文成功构建了一个可扩展且直观的框架，能够通过容器化技术和UDP隧道实现云和边缘机器人系统的集成测试，并能有效模拟实际网络条件，为云辅助远程控制等应用提供测试环境。

Conclusion: 该框架提供了一个可扩展且直观的解决方案，用于在模拟真实网络条件的情况下测试云和边缘机器人系统，从而应对云计算与机器人技术集成所面临的复杂挑战。

Abstract: Cloud robotics has emerged as a promising technology for robotics
applications due to its advantages of offloading computationally intensive
tasks, facilitating data sharing, and enhancing robot coordination. However,
integrating cloud computing with robotics remains a complex challenge due to
network latency, security concerns, and the need for efficient resource
management. In this work, we present a scalable and intuitive framework for
testing cloud and edge robotic systems. The framework consists of two main
components enabled by containerized technology: (a) a containerized cloud
cluster and (b) the containerized robot simulation environment. The system
incorporates two endpoints of a User Datagram Protocol (UDP) tunnel, enabling
bidirectional communication between the cloud cluster container and the robot
simulation environment, while simulating realistic network conditions. To
achieve this, we consider the use case of cloud-assisted remote control for
aerial robots, while utilizing Linux-based traffic control to introduce
artificial delay and jitter, replicating variable network conditions
encountered in practical cloud-robot deployments.

</details>


### [176] [Lightweight Kinematic and Static Modeling of Cable-Driven Continuum Robots via Actuation-Space Energy Formulation](https://arxiv.org/abs/2509.04119)
*Ke Wu,Yuhao Wang,Kevin Henry,Cesare Stefanini,Gang Zheng*

Main category: cs.RO

TL;DR: 本文提出了一种名为LASEM的轻量级驱动空间能量建模框架，用于索驱动连续体机器人。该框架通过在驱动空间中直接构建驱动势能，提供了一个精确且计算高效的分析正向模型，并能处理逆运动学和实际离散化问题。


<details>
  <summary>Details</summary>
Motivation: 连续体机器人因其灵巧性和固有的柔顺性，非常适合非结构化和受限环境。然而，其连续可变形的形态给运动规划和控制带来了挑战，需要精确但轻量级的模型。

Method: LASEM框架直接在驱动空间中构建驱动势能。它利用几何非线性梁和杆理论，通过哈密顿原理推导出一个分析正向模型，避免了显式建模缆索与骨架的接触。该模型接受力和位移输入，统一了运动学和静力学公式。在忽略摩擦的情况下，该框架可推广到非均匀几何形状、任意缆索布线、分布式载荷和轴向可伸缩性。为逆运动学开发了一种半分析迭代方案。对于实际机器人的离散化问题，LASEM将泛函最小化重新表述为数值优化问题。

Result: LASEM框架提供了一个精确且计算高效的分析正向模型，适用于实时使用。数值模拟验证了其准确性。该框架能够推广到多种复杂情况，并为逆运动学提供了有效的解决方案。通过数值优化，它还能自然地处理实际机器人的离散化问题。

Conclusion: LASEM框架成功解决了索驱动连续体机器人的建模挑战，提供了一个准确、轻量级且多功能的模型，适用于实时运动规划和控制，并能有效处理复杂的几何形状和实际应用中的离散化问题。

Abstract: Continuum robots, inspired by octopus arms and elephant trunks, combine
dexterity with intrinsic compliance, making them well suited for unstructured
and confined environments. Yet their continuously deformable morphology poses
challenges for motion planning and control, calling for accurate but
lightweight models. We propose the Lightweight Actuation Space Energy Modeling
(LASEM) framework for cable driven continuum robots, which formulates actuation
potential energy directly in actuation space. LASEM yields an analytical
forward model derived from geometrically nonlinear beam and rod theories via
Hamilton's principle, while avoiding explicit modeling of cable backbone
contact. It accepts both force and displacement inputs, thereby unifying
kinematic and static formulations. Assuming the friction is neglected, the
framework generalizes to nonuniform geometries, arbitrary cable routings,
distributed loading and axial extensibility, while remaining computationally
efficient for real-time use. Numerical simulations validate its accuracy, and a
semi-analytical iterative scheme is developed for inverse kinematics. To
address discretization in practical robots, LASEM further reformulates the
functional minimization as a numerical optimization, which also naturally
incorporates cable potential energy without explicit contact modeling.

</details>


### [177] [OVGrasp: Open-Vocabulary Grasping Assistance via Multimodal Intent Detection](https://arxiv.org/abs/2509.04324)
*Chen Hu,Shan Luo,Letizia Gionfrida*

Main category: cs.RO

TL;DR: OVGrasp是一个分层控制框架，通过集成RGB-D视觉、开放词汇提示和语音命令，为软骨骼外衣提供抓握辅助，实现在非结构化环境中对未知物体的零样本检测和高抓握能力，并优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 恢复运动障碍个体在非结构化环境中的自主性至关重要，尤其是在物体类别和用户意图多样且不可预测的情况下。

Method: OVGrasp是一个分层控制框架，用于基于软骨骼外衣的抓握辅助。它集成了RGB-D视觉、开放词汇提示和语音命令，以实现鲁棒的多模态交互。该框架采用视觉-语言基础模型和开放词汇机制，实现对未见物体的零样本检测。多模态决策器融合空间和语言线索，在多物体场景中推断用户意图。整个框架部署在定制的以自我为中心的穿戴式外骨骼上，并对15个物体和三种抓握类型进行了系统评估。

Result: OVGrasp在十名参与者的实验中，抓握能力得分（GAS）达到87.00%，优于现有基线，并实现了与自然手部运动更佳的运动学对齐。

Conclusion: OVGrasp提供了一种强大且可泛化的抓握辅助解决方案，能够帮助运动障碍个体在复杂多变的开放环境中实现自主性，并展现出优异的性能和自然度。

Abstract: Grasping assistance is essential for restoring autonomy in individuals with
motor impairments, particularly in unstructured environments where object
categories and user intentions are diverse and unpredictable. We present
OVGrasp, a hierarchical control framework for soft exoskeleton-based grasp
assistance that integrates RGB-D vision, open-vocabulary prompts, and voice
commands to enable robust multimodal interaction. To enhance generalization in
open environments, OVGrasp incorporates a vision-language foundation model with
an open-vocabulary mechanism, allowing zero-shot detection of previously unseen
objects without retraining. A multimodal decision-maker further fuses spatial
and linguistic cues to infer user intent, such as grasp or release, in
multi-object scenarios. We deploy the complete framework on a custom
egocentric-view wearable exoskeleton and conduct systematic evaluations on 15
objects across three grasp types. Experimental results with ten participants
demonstrate that OVGrasp achieves a grasping ability score (GAS) of 87.00%,
outperforming state-of-the-art baselines and achieving improved kinematic
alignment with natural hand motion.

</details>


### [178] [DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation](https://arxiv.org/abs/2509.04441)
*Hao-Shu Fang,Branden Romero,Yichen Xie,Arthur Hu,Bo-Ruei Huang,Juan Alvarez,Matthew Kim,Gabriel Margolis,Kavya Anbarasu,Masayoshi Tomizuka,Edward Adelson,Pulkit Agrawal*

Main category: cs.RO

TL;DR: 本文提出了一种名为“围手术期操作”（perioperation）的机器人数据采集范式，并实现于被动式手部外骨骼DEXOP中。DEXOP通过连接人手与机器人手指，提供直接接触反馈和姿态镜像，以最大化数据可迁移性，实现高效、高质量的灵巧操作数据采集。


<details>
  <summary>Details</summary>
Motivation: 现有机器人数据采集方法（如远程操控）在灵巧操作任务中不够自然，限制了人类采集丰富感官数据的能力，导致数据质量和效率不高。研究旨在开发一种能最大化数据可迁移性，并使人类能自然、高效地采集高质量灵巧操作数据的方法。

Method: 引入“围手术期操作”（perioperation）范式。设计并实现了DEXOP，一个被动式手部外骨骼。DEXOP机械连接人手与机器人手指，为用户提供直接接触反馈（通过本体感受），并将人手姿态镜像到被动机器人手上，以最大化演示技能向机器人的迁移。

Result: DEXOP能大规模收集高质量的灵巧、接触密集型任务演示数据。与远程操控相比，使用DEXOP数据学习的策略显著提高了单位数据采集时间的任务性能，并增加了演示的速度和准确性。

Conclusion: DEXOP是一种强大的工具，通过提供更自然、高效且高质量的数据采集方式，显著推动了机器人灵巧性的发展。

Abstract: We introduce perioperation, a paradigm for robotic data collection that
sensorizes and records human manipulation while maximizing the transferability
of the data to real robots. We implement this paradigm in DEXOP, a passive hand
exoskeleton designed to maximize human ability to collect rich sensory (vision
+ tactile) data for diverse dexterous manipulation tasks in natural
environments. DEXOP mechanically connects human fingers to robot fingers,
providing users with direct contact feedback (via proprioception) and mirrors
the human hand pose to the passive robot hand to maximize the transfer of
demonstrated skills to the robot. The force feedback and pose mirroring make
task demonstrations more natural for humans compared to teleoperation,
increasing both speed and accuracy. We evaluate DEXOP across a range of
dexterous, contact-rich tasks, demonstrating its ability to collect
high-quality demonstration data at scale. Policies learned with DEXOP data
significantly improve task performance per unit time of data collection
compared to teleoperation, making DEXOP a powerful tool for advancing robot
dexterity. Our project page is at https://dex-op.github.io.

</details>


### [179] [EMMA: Scaling Mobile Manipulation via Egocentric Human Data](https://arxiv.org/abs/2509.04443)
*Lawrence Y. Zhu,Pranav Kuppili,Ryan Punamiya,Patcharapong Aphiwetsa,Dhruv Patel,Simar Kareer,Sehoon Ha,Danfei Xu*

Main category: cs.RO

TL;DR: EMMA是一个端到端框架，通过联合训练人类全身运动数据和静态机器人数据，实现了可扩展的移动操纵模仿学习，避免了昂贵的移动机器人遥操作。


<details>
  <summary>Details</summary>
Motivation: 移动操纵模仿学习受限于移动机器人遥操作成本高昂这一瓶颈。

Method: 提出了Egocentric Mobile MAnipulation (EMMA)框架。它通过协同训练人类全身运动数据和静态机器人数据，来训练移动操纵策略，从而避免了移动遥操作。

Result: 在三个真实世界任务中，EMMA表现出与基于遥操作移动机器人数据训练的基线（如Mobile ALOHA）相当的性能，在完整任务成功率上达到更高或同等水平。EMMA能够泛化到新的空间配置和场景，并且随着人类数据量的增加，性能呈现正向扩展。

Conclusion: EMMA为真实世界环境中的可扩展机器人学习开辟了新途径，通过利用人类数据有效解决了移动操纵模仿学习中遥操作成本高昂的问题。

Abstract: Scaling mobile manipulation imitation learning is bottlenecked by expensive
mobile robot teleoperation. We present Egocentric Mobile MAnipulation (EMMA),
an end-to-end framework training mobile manipulation policies from human mobile
manipulation data with static robot data, sidestepping mobile teleoperation. To
accomplish this, we co-train human full-body motion data with static robot
data. In our experiments across three real-world tasks, EMMA demonstrates
comparable performance to baselines trained on teleoperated mobile robot data
(Mobile ALOHA), achieving higher or equivalent task performance in full task
success. We find that EMMA is able to generalize to new spatial configurations
and scenes, and we observe positive performance scaling as we increase the
hours of human data, opening new avenues for scalable robotic learning in
real-world environments. Details of this project can be found at
https://ego-moma.github.io/.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [180] [Data-Driven Smart Maintenance of Historic Buildings](https://arxiv.org/abs/2509.03685)
*Zhongjun Ni*

Main category: eess.SY

TL;DR: 论文提出了一种针对历史建筑的综合性数据驱动智能维护解决方案，整合物联网、云计算、边缘计算、本体建模、机器学习和数字孪生，以优化室内气候管理、能源效率和保护实践，从而实现预防性维护并推进遗产保护策略。


<details>
  <summary>Details</summary>
Motivation: 建筑环境的数字化转型为通过数据驱动方法改进建筑维护提供了新机遇。在历史建筑的保护中，预防性维护对于确保长期可持续性及保护遗产价值至关重要。

Method: 整合物联网（IoT）、云计算、边缘计算、基于本体的数据建模和机器学习；结合智能监测、数字孪生和人工智能。

Result: 该方案改善了室内气候管理、能源效率和保护实践；实现了预防性维护；为下一代遗产保护策略奠定了基础。

Conclusion: 本论文提出了一种针对历史建筑的综合性数据驱动智能维护解决方案，通过结合智能监测、数字孪生和人工智能，推动了历史建筑的数据驱动保护和预防性维护策略。

Abstract: Digital transformation in the built environment offers new opportunities to
improve building maintenance through data-driven approaches. Smart monitoring,
predictive modeling, and artificial intelligence can enhance decision-making
and enable proactive strategies. The preservation of historic buildings is an
important scenario where preventive maintenance is essential to ensure
long-term sustainability while protecting heritage values. This thesis presents
a comprehensive solution for data-driven smart maintenance of historic
buildings, integrating Internet of Things (IoT), cloud computing, edge
computing, ontology-based data modeling, and machine learning to improve indoor
climate management, energy efficiency, and conservation practices.
  This thesis advances data-driven conservation of historic buildings by
combining smart monitoring, digital twins, and artificial intelligence. The
proposed methods enable preventive maintenance and pave the way for the next
generation of heritage conservation strategies.

</details>


### [181] [Parameter Tuning Under Uncertain Road Perception in Driver Assistance Systems](https://arxiv.org/abs/2509.03694)
*Leon Greiser,Christian Rathgeber,Vladislav Nenchev,Sören Hohmann*

Main category: eess.SY

TL;DR: 本文提出了一种自动参数调整方法，用于在考虑噪声的车道估计下，基于记录数据优化车道保持场景中的横向规划参数，并通过仿真验证了其在未知数据上的性能提升。


<details>
  <summary>Details</summary>
Motivation: 高级驾驶辅助系统面临传感器限制导致的噪声车道估计挑战，这影响了控制架构的性能。此外，横向轨迹规划的参数通常需要耗时的人工手动调整。

Method: 本研究提出了一种自动参数调整方法，用于车道保持场景中的横向规划。该方法基于记录数据，并考虑了道路估计中的噪声。通过沿参考曲线模拟车辆的横向行为，该方法能够有效地优化规划器参数。

Result: 该方法能够高效地优化自动驾驶规划器参数，并在以前未见的测试数据上展示了改进的性能。

Conclusion: 所提出的自动参数调整方法有效解决了噪声道路估计和手动参数调整的问题，提高了自动驾驶横向规划的效率和在实际场景中的性能。

Abstract: Advanced driver assistance systems have improved comfort, safety, and
efficiency of modern vehicles. However, sensor limitations lead to noisy lane
estimates that pose a significant challenge in developing performant control
architectures. Lateral trajectory planning often employs an optimal control
formulation to maintain lane position and minimize steering effort. The
parameters are often tuned manually, which is a time-intensive procedure. This
paper presents an automatic parameter tuning method for lateral planning in
lane-keeping scenarios based on recorded data, while taking into account noisy
road estimates. By simulating the lateral vehicle behavior along a reference
curve, our approach efficiently optimizes planner parameters for automated
driving and demonstrates improved performance on previously unseen test data.

</details>


### [182] [Avoidance of an unexpected obstacle without reinforcement learning: Why not using advanced control-theoretic tools?](https://arxiv.org/abs/2509.03721)
*Cédric Join,Michel Fliess*

Main category: eess.SY

TL;DR: 本文提出了一种基于平坦度控制和无模型预测控制的方法，用于Dubins汽车的意外障碍物避碰，以替代强化学习，展示了良好的鲁棒性和低计算负担。


<details>
  <summary>Details</summary>
Motivation: 由于强化学习（RL）在学习新任务时需要“荒谬的大量试验”（Yann LeCun），本研究旨在寻找一种更高效的避碰控制方法。

Method: 研究使用了经典的Dubins汽车模型，并采用了两种方法：1) 基于平坦度控制结合HEOL反馈设置；2) 最新的无模型预测控制方法。

Result: 两种方法都在计算机实验中取得了令人信服的结果。基于模型的方法（平坦度控制）结果略优。两种方法对随机生成的不匹配/干扰都表现出令人满意的鲁棒性，其中无模型方法表现出色。此外，这两种方法所需的计算负担较低。

Conclusion: 基于平坦度控制和无模型预测控制的方法为意外障碍物避碰提供了一种有效的替代方案，相较于强化学习，其具有更高的鲁棒性和更低的计算成本，这些特性在当前的流行AI机器学习技术中可能难以实现。

Abstract: This communication on collision avoidance with unexpected obstacles is
motivated by some critical appraisals on reinforcement learning (RL) which
"requires ridiculously large numbers of trials to learn any new task" (Yann
LeCun). We use the classic Dubins' car in order to replace RL with
flatness-based control, combined with the HEOL feedback setting, and the latest
model-free predictive control approach. The two approaches lead to convincing
computer experiments where the results with the model-based one are only
slightly better. They exhibit a satisfactory robustness with respect to
randomly generated mismatches/disturbances, which become excellent in the
model-free case. Those properties would have been perhaps difficult to obtain
with today's popular machine learning techniques in AI. Finally, we should
emphasize that our two methods require a low computational burden.

</details>


### [183] [Decentralized Safety-Critical Control of Resilient DC Microgrids with Large-Signal Stability Guarantees](https://arxiv.org/abs/2509.03789)
*Muratkhan Abdirash,Xiaofan Cui*

Main category: eess.SY

TL;DR: 本文提出了一种分布式安全关键控制器（DSCC），它通过结合控制障碍函数和端口-哈密顿系统理论，为直流微电网实现了可扩展、安全且实用的稳定控制，以应对日益增长的分布式能源渗透和网络威胁。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源和电力电子接口在直流微电网中的普及以及网络威胁的增加，需要具有可证明的安全性、网络弹性和实用性的初级控制器。传统的下垂控制方法虽然简单但缺乏严格保证，设计经验性且保守；而先进策略常牺牲可扩展性、鲁棒性或形式安全性。

Method: 本文提出了一种分布式安全关键控制器（DSCC），该控制器以完全去中心化的方式系统地集成了全局稳定性和形式安全保证。它利用控制障碍函数（CBF）和端口-哈密顿系统理论（PHS），实现了可扩展的安全稳定控制。

Result: DSCC实现了可扩展的安全稳定控制，同时保留了实时可实现性。高保真开关电路仿真验证了该控制器在各种突发情况下的优势。

Conclusion: 该框架为下一代直流微电网中弹性、安全关键和可扩展的控制铺平了道路。

Abstract: The increasing penetration of distributed energy resources and
power-electronics interfaces in DC microgrids, coupled with rising cyber
threats, necessitates primary controllers that are provably safe,
cyber-resilient, and practical. The increasing penetration of distributed
energy resources and power-electronics interfaces in DC microgrids, coupled
with rising cyber threats, necessitates primary controllers that are provably
safe, cyber-resilient, and practical. Conventional droop-based methods remain
prevalent due to their simplicity, yet their design is largely empirical and
conservative, lacking rigorous guarantees. Advanced strategies improve certain
aspects, but often sacrifice scalability, robustness, or formal safety. In this
work, we propose a Distributed Safety-Critical Controller (DSCC) that
systematically integrates global stabilization with formal safety guarantees in
a fully decentralized manner. Leveraging control barrier functions and the
port-Hamiltonian system theory, the DSCC achieves scalable safe stabilization
while preserving real-time implementability. High-fidelity switched-circuit
simulations validate the controller's advantages under various contingencies.
This framework paves the way for resilient, safety-critical, and scalable
control in next-generation DC microgrids.

</details>


### [184] [On the Performance Analysis of Pinching-Antenna-Enabled SWIPT Systems](https://arxiv.org/abs/2509.03836)
*Bingxin Zhang,Han Zhang,Kun Yang,Yizhe Zhao,Kezhi Wang*

Main category: eess.SY

TL;DR: 本文研究了一种基于柔性收缩天线的同步无线信息与功率传输（SWIPT）系统性能，通过提出天线部署方案和混合协议来优化能量-速率性能。


<details>
  <summary>Details</summary>
Motivation: 为了支持灵活部署并优化能量收集和信息传输的性能，研究人员旨在开发一种能够动态调整能量收集和信息解码的SWIPT系统。

Method: 研究提出了三种实用的收缩天线部署方案（边缘部署、中心部署和对角部署），并引入了混合时分切换（TS）和功率分割（PS）协议。在此基础上，推导了随机用户设备的平均收集能量和平均可达速率的闭式表达式，并通过数值模拟验证了理论分析的准确性。

Result: 研究成功推导了在不同部署策略和传输协议下，随机用户设备的平均收集能量和平均可达速率的闭式表达式。数值模拟结果证实了理论分析的准确性，并揭示了不同方案下速率和能量收集之间的权衡关系。

Conclusion: 该研究通过引入柔性收缩天线、优化部署方案和混合TS/PS协议，为SWIPT系统提供了一种有效提升能量-速率性能的方法，并量化了其在不同配置下的性能权衡。

Abstract: In this paper, we studies the performance of a novel simultaneous wireless
information and power transfer (SWIPT) system enabled by a flexible
pinching-antenna. To support flexible deployment and optimize energy-rate
performance, we propose three practical pinching antenna placement-schemes: the
edge deployment scheme (EDS), the center deployment scheme (CDS), and the
diagonal deployment scheme (DDS). Moreover, a hybrid time-switching (TS) and
power-splitting (PS) protocol is introduced, allowing dynamic adjustment
between energy harvesting and information decoding. Under each deployment
strategy and the transmission protocol, closed-form expressions for the average
harvested energy and average achievable rate of a randomly located user
equipment (UE) are derived based on the optimal positioning of the
pinching-antenna. Numerical simulations confirm the accuracy of the theoretical
analysis and illustrate the trade-off between rate and energy harvesting under
different schemes.

</details>


### [185] [Reservoir Predictive Path Integral Control for Unknown Nonlinear Dynamics](https://arxiv.org/abs/2509.03839)
*Daisuke Inoue,Tadayoshi Matsumori,Gouhei Tanaka,Yuji Ito*

Main category: eess.SY

TL;DR: 本文提出了一种结合回声状态网络（ESN）和模型预测路径积分（MPPI）的新型控制框架RPPI（及其不确定性感知版本URPPI），旨在实现非线性动力系统的快速在线学习和控制，并显著提高了控制性能。


<details>
  <summary>Details</summary>
Motivation: 非线性动力系统的快速在线识别和控制是当前面临的核心挑战。

Method: 该研究将回声状态网络（ESN）与模型预测路径积分（MPPI）控制相结合，提出了储层预测路径积分（RPPI）框架。ESN用于快速学习非线性动力学，MPPI则直接利用学习到的非线性特性进行并行化控制计算，无需线性化近似。此外，该框架进一步扩展为不确定性感知RPPI（URPPI），利用ESN的不确定性来平衡探索和利用，在早期学习阶段侧重探索，模型置信度提高后侧重利用。

Result: 在控制Duffing振子和四罐系统的实验中，URPPI显著提升了控制性能，与传统的基于二次规划的模型预测控制方法相比，控制成本降低了高达60%。

Conclusion: RPPI和URPPI框架有效解决了非线性系统的快速在线学习和控制问题，并通过不确定性感知机制优化了探索与利用的平衡，从而显著提高了控制性能。

Abstract: Neural networks capable of approximating complex nonlinearities have found
extensive application in data-driven control of nonlinear dynamical systems.
However, fast online identification and control of unknown dynamics remain
central challenges. This paper integrates echo-state networks (ESNs) --
reservoir computing models implemented with recurrent neural networks -- and
model predictive path integral (MPPI) control -- sampling-based variants of
model predictive control -- to meet these challenges. The proposed reservoir
predictive path integral (RPPI) enables fast learning of nonlinear dynamics
with ESN and exploits the learned nonlinearities directly in parallelized MPPI
control computation without linearization approximations. The framework is
further extended to uncertainty-aware RPPI (URPPI), which leverages ESN
uncertainty to balance exploration and exploitation: exploratory inputs
dominate during early learning, while exploitative inputs prevail as model
confidence grows. Experiments on controlling the Duffing oscillator and
four-tank systems demonstrate that URPPI improves control performance, reducing
control costs by up to 60% compared to traditional quadratic programming-based
model predictive control methods.

</details>


### [186] [Sample Efficient Certification of Discrete-Time Control Barrier Functions](https://arxiv.org/abs/2509.03899)
*Sampath Kumar Mulagaleti,Andrea Del Prete*

Main category: eess.SY

TL;DR: 本文提出了一种基于Lipschitz论证的控制障碍函数（CBF）验证方法，旨在提高样本效率，以认证动态系统的安全性。


<details>
  <summary>Details</summary>
Motivation: 控制不变（CI）集对系统安全认证至关重要，而CBF是计算CI集的有效工具。然而，计算CBF通常涉及复杂且难以处理的鲁棒优化问题。情景方法虽能简化计算，但仍需验证CBF是否真正满足鲁棒约束。

Method: 本文提出了一种利用Lipschitz论证进行CBF验证的方法，并以此为基础设计了一个样本高效的认证算法。

Result: 通过数值示例验证了所提出验证程序的效率。

Conclusion: 该方法提供了一种高效验证CBF的手段，可作为样本高效认证算法的基础，有助于动态系统的安全认证。

Abstract: Control Invariant (CI) sets are instrumental in certifying the safety of
dynamical systems. Control Barrier Functions (CBFs) are effective tools to
compute such sets, since the zero sublevel sets of CBFs are CI sets. However,
computing CBFs generally involves addressing a complex robust optimization
problem, which can be intractable. Scenario-based methods have been proposed to
simplify this computation. Then, one needs to verify if the CBF actually
satisfies the robust constraints. We present an approach to perform this
verification that relies on Lipschitz arguments, and forms the basis of a
certification algorithm designed for sample efficiency. Through a numerical
example, we validated the efficiency of the proposed procedure.

</details>


### [187] [Physics-Informed Detection of Friction Anomalies in Satellite Reaction Wheels](https://arxiv.org/abs/2509.04060)
*Alejandro Penacho Riveiros,Nicola Bastianello,Karl H. Johansson,Matthieu Barreau*

Main category: eess.SY

TL;DR: 该研究提出了一种自动化算法，用于分析卫星反作用轮组件（RWA）的摩擦数据，并确定其运行状态，区分正常和多种异常情况，以减少人工工作量并实现预防性维护。


<details>
  <summary>Details</summary>
Motivation: 近年来在轨卫星数量呈指数级增长，需要自动化方法来确保其功能正常并减少人工工作量。

Method: 该算法首先利用基于混合系统理论的模型提取相关信息。提取过程结合了变点检测、动态规划和最大似然技术。然后，一个分类器使用提取的信息来确定RWA的状态，该分类器已使用高保真模拟器生成（主要由正常数据组成）的标记数据集进行训练。最终算法结合了基于模型和基于数据的方法。

Result: 该算法能够区分RWA的正常运行状态和几种需要采取预防措施的可能异常情况。最终算法取得了令人满意的结果，准确率约为95%。

Conclusion: 该研究成功开发了一种结合模型驱动和数据驱动方法的自动化算法，能够高效准确地监测卫星RWA的运行状态，为预防性维护提供了有效手段。

Abstract: As the number of satellites in orbit has increased exponentially in recent
years, ensuring their correct functionality has started to require automated
methods to decrease human workload. In this work, we present an algorithm that
analyzes the on-board data related to friction from the Reaction Wheel
Assemblies (RWA) of a satellite and determines their operating status,
distinguishing between nominal status and several possible anomalies that
require preventive measures to be taken. The algorithm first uses a model based
on hybrid systems theory to extract the information relevant to the problem.
The extraction process combines techniques in changepoint detection, dynamic
programming, and maximum likelihood in a structured way. A classifier then uses
the extracted information to determine the status of the RWA. This last
classifier has been previously trained with a labelled dataset produced by a
high-fidelity simulator, comprised for the most part of nominal data. The final
algorithm combines model-based and data-based approaches to obtain satisfactory
results with an accuracy around 95%.

</details>


### [188] [Low-Power Impact Detection and Localization on Forklifts Using Wireless IMU Sensors](https://arxiv.org/abs/2509.04096)
*Lyssa Ramaut,Chesney Buyle,Jona Cappelle,Liesbet Van der Perre*

Main category: eess.SY

TL;DR: 本文提出了一种基于多无线传感器节点的低成本、低功耗冲击检测系统，用于叉车碰撞的检测与定位，并能区分高强度冲击与正常使用，实现多年传感器自主运行。


<details>
  <summary>Details</summary>
Motivation: 叉车在工业环境中面临磨损、崎岖地形、狭窄空间和复杂操作，导致意外碰撞（与货物、基础设施或其他机械）的风险增加。此外，故意滥用也会损害安全和设备完整性。

Method: 该研究开发了一个基于多个无线传感器节点的低成本、低功耗冲击检测系统，测量3D加速度。这些节点部署在真实操作场景中进行测量活动。基于收集到的数据，开发了一种算法来区分高强度冲击事件和正常使用，并定位叉车上检测到的碰撞。

Result: 该解决方案成功地检测并定位了冲击，同时保持了低功耗，实现了可靠的叉车监控和多年的传感器自主运行。

Conclusion: 所提出的系统能有效检测和定位叉车冲击，同时具有低功耗和长续航能力，为叉车的安全和设备完整性提供了可靠的监控解决方案。

Abstract: Forklifts are essential for transporting goods in industrial environments.
These machines face wear and tear during field operations, along with rough
terrain, tight spaces and complex handling scenarios. This increases the
likelihood of unintended impacts, such as collisions with goods,
infrastructure, or other machinery. In addition, deliberate misuse has been
stated, compromising safety and equipment integrity. This paper presents a
low-cost and low-power impact detection system based on multiple wireless
sensor nodes measuring 3D accelerations. These were deployed in a measurement
campaign covering realworld operational scenarios. An algorithm was developed,
based on this collected data, to differentiate high-impact events from normal
usage and to localize detected collisions on the forklift. The solution
successfully detects and localizes impacts, while maintaining low power
consumption, enabling reliable forklift monitoring with multi-year sensor
autonomy.

</details>


### [189] [Remote Estimation for Markov Jump Linear Systems: A Distributionally Robust Approach](https://arxiv.org/abs/2509.04116)
*Ioannis Tzortzis,Themistoklis Charalambous,Charalambos D. Charalambous*

Main category: eess.SY

TL;DR: 本文提出了一种在后验模式概率存在不确定性时，针对马尔可夫跳跃线性系统进行远程状态估计的分布鲁棒方法。


<details>
  <summary>Details</summary>
Motivation: 当估计器通过不可靠的通信网络接收到有噪声或不完整的测量数据时，后验模式概率可能会出现不确定性，这促使研究人员寻求一种能够在这种不确定性下进行鲁健壮估计的方法。

Method: 研究将估计问题建模在一个分布鲁棒框架内，假设真实的后验分布位于以名义后验为中心的总变差距离球内。由此产生的极小极大公式扩展了经典的MMSE解决方案，并增加了考虑模式不确定性的项。通过一阶广义伪贝叶斯算法的分布鲁棒变体，开发了一种可行的实现。

Result: 该方法产生了一个扩展了经典MMSE解决方案的估计器，其中包含用于处理模式不确定性的附加项。通过数值示例证明了该方法的适用性和有效性。

Conclusion: 所提出的分布鲁棒方法能有效处理马尔可夫跳跃线性系统在后验模式概率存在不确定性时的远程状态估计问题，并提供了一个可行的实现方案。

Abstract: This paper considers the problem of remote state estimation for Markov jump
linear systems in the presence of uncertainty in the posterior mode
probabilities. Such uncertainty may arise when the estimator receives noisy or
incomplete measurements over an unreliable communication network. To address
this challenge, the estimation problem is formulated within a distributionally
robust framework, where the true posterior is assumed to lie within a total
variation distance ball centered at the nominal posterior. The resulting
minimax formulation yields an estimator that extends the classical MMSE
solution with additional terms that account for mode uncertainty. A tractable
implementation is developed using a distributionally robust variant of the
first-order generalized pseudo-Bayesian algorithm. A numerical example is
provided to illustrate the applicability and effectiveness of the approach.

</details>


### [190] [Laplacian Flows in Complex-valued Directed Networks: Analysis, Design, and Consensus](https://arxiv.org/abs/2509.04196)
*Aditi Saxena,Twinkle Tripathy,Rajasekhar Anguluri*

Main category: eess.SY

TL;DR: 本研究探讨了复值网络中达成共识的必要和充分条件，引入了“实数主导”约束，并提出了改进的流方法以确保共识。


<details>
  <summary>Details</summary>
Motivation: 复值网络能够通过捕获交互的幅度和相位来提供更细致的关系表示，并在配电网等领域有重要应用。这种更丰富的框架促使作者研究其共识机制。

Method: 研究了强连接和弱连接有向图中的共识条件；利用复Perron-Frobenius性质研究拉普拉斯算子的谱特性及其与图条件的关系；提出了即使原始网络不收敛也能保证共识的改进流；探讨了复值网络中的扩散作为共识的对偶过程；在合成和真实网络上进行了模拟。

Result: 复值拉普拉斯流在满足“实数主导”（依赖于边权重的相角）的额外约束下收敛到共识。提出的改进流即使在原始网络不收敛的情况下也能保证共识。扩散作为共识的对偶过程得到了探索和模拟验证。

Conclusion: 本研究确立了复值网络中达成共识的必要和充分条件，特别是引入了“实数主导”这一关键约束。同时，提出了有效的方法来确保共识的实现，并探索了扩散作为共识的对偶过程。

Abstract: In the interdisciplinary field of network science, a complex-valued network,
with edges assigned complex weights, provides a more nuanced representation of
relationships by capturing both the magnitude and phase of interactions.
Additionally, an important application of this setting arises in distribution
power grids. Motivated by the richer framework, we study the necessary and
sufficient conditions for achieving consensus in both strongly and weakly
connected digraphs. The paper establishes that complex-valued Laplacian flows
converge to consensus subject to an additional constraint termed as real
dominance which relies on the phase angles of the edge weights. Our approach
builds on the complex Perron-Frobenius properties to study the spectral
properties of the Laplacian and its relation to graphical conditions. Finally,
we propose modified flows that guarantee consensus even if the original network
does not converge to consensus. Additionally, we explore diffusion in
complex-valued networks as a dual process of consensus and simulate our results
on synthetic and real-world networks.

</details>


### [191] [On the Effect of Sampling-Time Jitter](https://arxiv.org/abs/2509.04199)
*Dieter Schwarzmann,Simon Käser*

Main category: eess.SY

TL;DR: 本文分析了采样时间抖动对线性时不变系统的影响，提出通过无抖动模拟系统重新解释抖动系统，发现抖动会导致系统矩阵的仿射缩放和频率缩放。


<details>
  <summary>Details</summary>
Motivation: 研究旨在为实践者分析采样时间抖动（由执行时间不准确产生的误差）对线性时不变（LTI）系统的影响。

Method: 提出通过等效的无抖动模拟系统重新解释受抖动影响的线性时不变系统。通过构建一个将时序扰动吸收到其动态中的“感知系统”来实现。研究涵盖了测量和实现两种场景。

Result: 主要结果包括发现抖动的仿射缩放。证明了抖动会有效地缩放系统矩阵。此外，在拉普拉斯域中，抖动可以被解释为频率缩放。

Conclusion: 论文得出结论，采样时间抖动对线性时不变系统的影响可以通过将其重新解释为无抖动模拟系统进行系统分析，从而揭示抖动的仿射缩放、系统矩阵的缩放以及拉普拉斯域中的频率缩放。

Abstract: This brief, aimed at practitioners, offers an analysis of the effect of
sampling-time jitter, i. e., the error produced by execution-time inaccuracies.
We propose reinterpreting jitter-afflicted linear time-invariant systems
through equivalent jitter-free analogs. By constructing a perceived system that
absorbs the effects of timing perturbations into its dynamics, we find an
affine scaling of jitter. We examine both measurement and implementation
scenarios, demonstrating that the presence of jitter effectively scales the
system matrices. Moreover, we observe that, in the Laplace domain, jitter can
be interpreted as a frequency scaling.

</details>


### [192] [Sailing Towards Zero-Shot State Estimation using Foundation Models Combined with a UKF](https://arxiv.org/abs/2509.04213)
*Tobin Holtmann,David Stenger,Andres Posada-Moreno,Friedrich Solowjow,Sebastian Trimpe*

Main category: eess.SY

TL;DR: 本文提出了一种名为FM-UKF的零样本状态估计方法，它结合了基于Transformer的系统动力学模型和卡尔曼滤波（UKF）的分析传感器模型，实现了在不重新训练的情况下对不同传感器配置的泛化能力，并在集装箱船模型上表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 传统的控制和系统工程中的状态估计需要大量的系统识别或数据收集工作。虽然基于Transformer的预训练基础模型在其他领域减少了数据需求，但现有的基于Transformer的端到端方法在零样本性能上仍受限于训练期间见过的传感器模型。因此，需要开发一种能够泛化到新传感器配置的零样本基础模型。

Method: 本文引入了基础模型无迹卡尔曼滤波（FM-UKF）。该方法通过UKF将基于Transformer的系统动力学模型与分析已知的传感器模型相结合，从而在不为新的传感器配置重新训练的情况下，实现对不同动力学的泛化。

Result: FM-UKF能够在不重新训练新传感器配置的情况下，实现对不同动力学的泛化。在新的复杂动力学集装箱船模型基准测试中，FM-UKF与具有近似系统知识的经典方法和端到端方法相比，在精度、工作量和鲁棒性之间取得了有竞争力的权衡。此外，该基准测试和数据集已开源以支持未来的研究。

Conclusion: FM-UKF通过结合Transformer模型和UKF，有效解决了零样本状态估计中传感器模型泛化的问题，提供了一种在复杂系统（如集装箱船）中实现高效、鲁棒状态估计的新范式，并为该领域的研究提供了宝贵的开源资源。

Abstract: State estimation in control and systems engineering traditionally requires
extensive manual system identification or data-collection effort. However,
transformer-based foundation models in other domains have reduced data
requirements by leveraging pre-trained generalist models. Ultimately,
developing zero-shot foundation models of system dynamics could drastically
reduce manual deployment effort. While recent work shows that transformer-based
end-to-end approaches can achieve zero-shot performance on unseen systems, they
are limited to sensor models seen during training. We introduce the foundation
model unscented Kalman filter (FM-UKF), which combines a transformer-based
model of system dynamics with analytically known sensor models via an UKF,
enabling generalization across varying dynamics without retraining for new
sensor configurations. We evaluate FM-UKF on a new benchmark of container ship
models with complex dynamics, demonstrating a competitive accuracy, effort, and
robustness trade-off compared to classical methods with approximate system
knowledge and to an end-to-end approach. The benchmark and dataset are open
sourced to further support future research in zero-shot state estimation via
foundation models.

</details>


### [193] [Compatibility of Multiple Control Barrier Functions for Constrained Nonlinear Systems](https://arxiv.org/abs/2509.04220)
*Max H. Cohen,Eugene Lavretsky,Aaron D. Ames*

Main category: eess.SY

TL;DR: 本文提出了一种利用多个控制障碍函数（CBFs）来处理非线性系统向量值输出上的箱式约束的框架，实现了可证明安全的控制器，并在特定条件下具有闭式解。


<details>
  <summary>Details</summary>
Motivation: 现有文献中，控制障碍函数（CBFs）主要关注单个约束，难以综合处理多个状态约束以实现可证明安全的控制器。

Method: 本文提出了一个框架，使用多个CBFs来处理非线性系统向量值输出上的箱式约束。当输出具有向量相对度时，编码这些箱式约束的CBF约束是兼容的，由此产生的基于优化的控制器是局部Lipschitz连续的，并具有闭式表达式。此外，还分析了在安全约束存在下，标称跟踪目标的性能下降情况。

Result: 研究结果表明，当输出具有向量相对度时，CBF约束是兼容的，并且所得到的基于优化的控制器是局部Lipschitz连续的，并具有闭式表达式。通过对平面四旋翼飞行器的仿真，验证了所提出框架的有效性，能够处理多个输出箱式约束下的安全控制问题。

Conclusion: 该框架为具有多个箱式输出约束的非线性系统提供了一种有效的、可证明安全的控制方法，解决了现有CBF方法在处理多约束方面的挑战，并提供了具有良好理论性质的控制器。

Abstract: Control barrier functions (CBFs) are a powerful tool for the constrained
control of nonlinear systems; however, the majority of results in the
literature focus on systems subject to a single CBF constraint, making it
challenging to synthesize provably safe controllers that handle multiple state
constraints. This paper presents a framework for constrained control of
nonlinear systems subject to box constraints on the systems' vector-valued
outputs using multiple CBFs. Our results illustrate that when the output has a
vector relative degree, the CBF constraints encoding these box constraints are
compatible, and the resulting optimization-based controller is locally
Lipschitz continuous and admits a closed-form expression. Additional results
are presented to characterize the degradation of nominal tracking objectives in
the presence of safety constraints. Simulations of a planar quadrotor are
presented to demonstrate the efficacy of the proposed framework.

</details>


### [194] [Reinforcement Learning for Robust Ageing-Aware Control of Li-ion Battery Systems with Data-Driven Formal Verification](https://arxiv.org/abs/2509.04288)
*Rudi Coppola,Hovsep Touloujian,Pierfrancesco Ombrini,Manuel Mazo Jr*

Main category: eess.SY

TL;DR: 本文提出了一种数据驱动的混合控制策略，结合强化学习和形式化方法，用于优化锂离子电池的充电和安全协议，以平衡充电速度和电池老化，并提供性能的概率保证。


<details>
  <summary>Details</summary>
Motivation: 锂离子电池在现代技术中无处不在，但电池管理系统（BMS）面临一个核心挑战：如何在充电速度和电池容量损失（老化）之间取得平衡。现有协议需要改进以优化这一权衡。

Method: 研究采用高保真物理电池模型，并提出一种数据驱动的充电和安全协议设计方法。该方法遵循反例引导归纳合成（CEGIS）方案，将强化学习（RL）用于合成独立的控制器，并利用数据驱动的形式化方法进行抽象。抽象根据电池的初始输出测量结果，将控制器划分成一个切换结构，从而实现一个混合控制系统（RL控制器离散选择与电池连续动态结合）。

Result: 该方法产生了一种混合控制策略，其中RL用于合成控制器，而数据驱动的抽象指导了控制器的切换。当设计满足预期标准时，该抽象能够为电池的闭环性能提供概率性保证。

Conclusion: 通过结合强化学习和数据驱动的形式化方法，可以设计出一种混合控制策略，有效解决锂离子电池充电速度与老化之间的权衡问题，并为电池的性能提供可靠的概率保证。

Abstract: Rechargeable lithium-ion (Li-ion) batteries are a ubiquitous element of
modern technology. In the last decades, the production and design of such
batteries and their adjacent embedded charging and safety protocols, denoted by
Battery Management Systems (BMS), has taken central stage. A fundamental
challenge to be addressed is the trade-off between the speed of charging and
the ageing behavior, resulting in the loss of capacity in the battery cell. We
rely on a high-fidelity physics-based battery model and propose an approach to
data-driven charging and safety protocol design. Following a
Counterexample-Guided Inductive Synthesis scheme, we combine Reinforcement
Learning (RL) with recent developments in data-driven formal methods to obtain
a hybrid control strategy: RL is used to synthesise the individual controllers,
and a data-driven abstraction guides their partitioning into a switched
structure, depending on the initial output measurements of the battery. The
resulting discrete selection among RL-based controllers, coupled with the
continuous battery dynamics, realises a hybrid system. When a design meets the
desired criteria, the abstraction provides probabilistic guarantees on the
closed-loop performance of the cell.

</details>


### [195] [Learning Optimal Crew Dispatch for Grid Restoration Following an Earthquake](https://arxiv.org/abs/2509.04308)
*Farshad Amani,Faezeh Ardali,Amin Kargarian*

Main category: eess.SY

TL;DR: 该研究提出了一种结合Transformer和深度强化学习（DRL）的新型学习框架，用于灾后人员调度，旨在提供近实时决策支持，同时保持解决方案质量，以加速恢复并增强系统弹性。


<details>
  <summary>Details</summary>
Motivation: 传统的混合整数线性规划方法在计算灾后人员调度方案时耗时过长（数分钟至数小时），导致决策延迟，影响动态恢复环境中的及时响应。

Method: 将人员调度建模为不确定性下的序列决策问题。框架整合了Transformer架构（捕捉高维系统状态和时间依赖性）和DRL（实现自适应和可扩展决策）。首先依据地震标准表征地震引起的配电网络损坏，然后通过情景生成和缩减流程聚合结果为地理空间影响图。基于此图，离线训练（模拟和历史事件）并在线部署该框架，以生成二级调度策略。

Result: 该方法实现了近实时的决策支持，显著缩短了运行时间，同时保持了高质量的解决方案。通过实现更快、更有效的恢复，增强了系统弹性。在2869总线欧洲燃气和电力网络的案例研究中，证明了该方法能大幅加速恢复并保持高解决方案质量。

Conclusion: 所提出的方法能够显著加速灾后恢复过程，同时保持高解决方案质量，这凸显了其在大规模灾害响应中实际部署的巨大潜力。

Abstract: Post-disaster crew dispatch is a critical but computationally intensive task.
Traditional mixed-integer linear programming methods often require minutes to
several hours to compute solutions, leading to delays that hinder timely
decision-making in highly dynamic restoration environments. To address this
challenge, we propose a novel learning-based framework that integrates
transformer architectures with deep reinforcement learning (DRL) to deliver
near real-time decision support without compromising solution quality. Crew
dispatch is formulated as a sequential decision-making problem under
uncertainty, where transformers capture high-dimensional system states and
temporal dependencies, while DRL enables adaptive and scalable decision-making.
Earthquake-induced distribution network damage is first characterized using
established seismic standards, followed by a scenario generation and reduction
pipeline that aggregates probable outcomes into a single geospatial impact map.
Conditioned on this map, the proposed framework generates second-level dispatch
strategies, trained offline on simulated and historical events and deployed
online for rapid response. In addition to substantial runtime improvements, the
proposed method enhances system resilience by enabling faster and more
effective recovery and restoration. Case studies, particularly on the 2869-bus
European gas and power network, demonstrate that the method substantially
accelerates restoration while maintaining high-quality solutions, underscoring
its potential for practical deployment in large-scale disaster response.

</details>


### [196] [Impact on transient stability of self-synchronisation control strategies in grid-forming VSC-based generators](https://arxiv.org/abs/2509.04388)
*Regulo E. Avila-Martinez,Xavier Guillaud,Javier Renedo,Luis Rouco,Aurelio Garcia-Cerrada,Lukas Sigrist*

Main category: eess.SY

TL;DR: 本文分析并比较了四种GFM-VSC自同步策略（VSM变体）的暂态稳定性，并提出/分析了两种提高暂态稳定性的方法（VAPC和FLC）。


<details>
  <summary>Details</summary>
Motivation: 并网型电压源变换器（GFM-VSCs）是可再生能源并网的关键解决方案，需要自同步策略。尽管虚拟同步机（VSM）控制是流行的自同步策略，但目前缺乏对其不同变体对暂态稳定性影响的系统性研究。

Method: 本文分析并比较了四种GFM-VSC自同步策略的暂态稳定性：无锁相环（PLL）的VSM、带PLL的VSM、使用冲刷滤波器（wash-out filter）的无PLL VSM，以及积分-比例（IP）控制器。此外，本文还分析了两种可用于提高暂态稳定性的方法：虚拟不饱和有功功率控制器（VAPC）和本文提出的GFM-VSC限频算法（FLC）。

Result: 本文分析并比较了四种GFM-VSC自同步策略（VSM无PLL、VSM带PLL、VSM无PLL带冲刷滤波器、IP控制器）的暂态稳定性。同时，分析了VAPC概念和新提出的GFM-VSC限频算法（FLC）对提高暂态稳定性的效果。

Conclusion: 通过对不同GFM-VSC自同步策略及其改进方法的分析和比较，本文旨在深入理解和提升GFM-VSC在可再生能源并网中的暂态稳定性。

Abstract: Grid-forming voltage source converters (GFM-VSCs) are emerging as a solution
for integrating renewable energy resources (RERs) into power systems. GFM-VSCs
need a self-synchronisation strategy to ensure that all converters and
generators in the power system are in synchronism and they reach the same
frequency in steady state. The self-synchronisation strategy in GFM-VSCs that
has received most attention in previous research is virtual synchronous machine
(VSM) control. However, no systematic study of the effects on transient
stability of different variants of this strategy has been carried out in
previous work. This paper analyses and compares transient stability of four
self-synchronisation strategies for GFM-VSCs: VSM without phase-locked loop
(PLL), VSM with PLL, VSM without PLL using wash-out filter and
integral-proportional (IP) controller. The paper also analyses two different
methods that can \color{black} be applied to GFM-VSC self-synchronisation
strategies to improve transient stability: the concept of virtual unsaturated
active-power controller (VAPC), proposed in previous work, and an algorithm for
frequency limitation in the GFM-VSC (FLC), which is proposed in this paper.

</details>


### [197] [Leveraging Equivariances and Symmetries in the Control Barrier Function Synthesis](https://arxiv.org/abs/2509.04399)
*Adrian Wiltz,Dimos V. Dimarogonas*

Main category: eess.SY

TL;DR: 本文探讨了如何利用系统动力学中的等变性（一种对称形式）来简化控制障碍函数（CBF）的合成和计算，从而显著节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 控制障碍函数（CBF）的合成通常计算量大或需要精心构建。研究人员希望利用系统动力学和约束的结构特性（如对称性/等变性）来缓解这些挑战。

Method: 本文研究了动力学中的等变性如何应用于CBF合成。具体方法包括：1) 证明动力学中的等变性以及约束中的对称性如何通过可达性分析诱导CBF的对称性；2) 展示如何利用部分已知的CBF和等变性来为各种新约束（包括非对称约束）构建CBF；3) 通过理论示例和数值研究来验证计算增益。

Result: 研究发现，动力学中的等变性以及约束中的对称性可以诱导CBF的对称性。这一洞察使得研究者可以从CBF在子集上的值推断其在整个域上的值，从而实现显著的计算节省。此外，即使对于非对称约束，等变性也可以与部分已知的CBF结合使用，以构建新的CBF。数值研究也证实了利用等变性进行CBF合成的计算收益。

Conclusion: 利用系统动力学中的等变性可以有效简化控制障碍函数（CBF）的合成过程，减少计算量，并且能够将CBF应用于更广泛的约束条件（包括非对称约束）。

Abstract: The synthesis of Control Barrier Functions (CBFs) often involves demanding
computations or a meticulous construction. However, structural properties of
the system dynamics and constraints have the potential to mitigate these
challenges. In this paper, we explore how equivariances in the dynamics,
loosely speaking a form of symmetry, can be leveraged in the CBF synthesis.
Although CBFs are generally not inherently symmetric, we show how equivariances
in the dynamics and symmetries in the constraints induce symmetries in CBFs
derived through reachability analysis. This insight allows us to infer their
CBF values across the entire domain from their values on a subset, leading to
significant computational savings. Interestingly, equivariances can be even
leveraged to the CBF synthesis for non-symmetric constraints. Specifically, we
show how a partially known CBF can be leveraged together with equivariances to
construct a CBF for various new constraints. Throughout the paper, we provide
examples illustrating the theoretical findings. Furthermore, a numerical study
investigates the computational gains from invoking equivariances into the CBF
synthesis.

</details>


### [198] [SAFE--MA--RRT: Multi-Agent Motion Planning with Data-Driven Safety Certificates](https://arxiv.org/abs/2509.04413)
*Babak Esmaeili,Hamidreza Modares*

Main category: eess.SY

TL;DR: 本文提出了一种完全数据驱动的多智能体运动规划框架，适用于无显式系统模型的同构线性多智能体系统。该框架通过凸半定规划从实验数据中学习局部不变椭球和状态反馈增益，利用这些椭球在基于网格的路径点之间规划动态可行且可证明安全的轨迹。通过采样式规划器和时空预留表，确保了智能体间的连续安全性和无碰撞协调。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为在共享、充满障碍的工作空间中运行的同构线性多智能体系统提供运动规划解决方案，尤其是在缺乏明确系统模型的情况下。目标是生成既动态可行又对环境和智能体间碰撞都可证明安全的轨迹。

Method: 每个智能体独立地从实验数据中学习其闭环行为，通过求解凸半定规划生成局部不变椭球和相应的状态反馈增益。这些椭球以网格路径点为中心，验证短程转换的动态可行性并定义安全操作区域。一个基于采样的规划器构建路径点树，仅当相邻椭球重叠时才允许转换，确保不变到不变的转换和连续安全性。所有智能体同时扩展其树，并通过时空预留表进行协调，以防止同时占用和正面碰撞，从而保证智能体间安全。树中的每个成功边都配备了自己的局部控制器，无需在运行时重新解决优化问题。

Result: 该方法能够为多个智能体合成同步、安全的轨迹。生成的轨迹不仅动态可行，而且对环境约束和智能体间碰撞都可证明安全。仿真结果表明，该方法在使用纯数据和凸优化工具的情况下，在共享动态和约束条件下，能够有效地实现多智能体的同步安全轨迹。

Conclusion: 该研究成功地提出了一种完全数据驱动的多智能体运动规划框架，在没有显式系统模型的情况下，通过学习不变椭球和采用协调规划策略，实现了在障碍环境中动态可行且对环境和智能体间碰撞都可证明安全的轨迹。该方法通过预先计算的局部控制器，实现了高效的运行时执行。

Abstract: This paper proposes a fully data-driven motion-planning framework for
homogeneous linear multi-agent systems that operate in shared, obstacle-filled
workspaces without access to explicit system models. Each agent independently
learns its closed-loop behavior from experimental data by solving convex
semidefinite programs that generate locally invariant ellipsoids and
corresponding state-feedback gains. These ellipsoids, centered along grid-based
waypoints, certify the dynamic feasibility of short-range transitions and
define safe regions of operation. A sampling-based planner constructs a tree of
such waypoints, where transitions are allowed only when adjacent ellipsoids
overlap, ensuring invariant-to-invariant transitions and continuous safety. All
agents expand their trees simultaneously and are coordinated through a
space-time reservation table that guarantees inter-agent safety by preventing
simultaneous occupancy and head-on collisions. Each successful edge in the tree
is equipped with its own local controller, enabling execution without
re-solving optimization problems at runtime. The resulting trajectories are not
only dynamically feasible but also provably safe with respect to both
environmental constraints and inter-agent collisions. Simulation results
demonstrate the effectiveness of the approach in synthesizing synchronized,
safe trajectories for multiple agents under shared dynamics and constraints,
using only data and convex optimization tools.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [199] [Latent Space Single-Pixel Imaging Under Low-Sampling Conditions](https://arxiv.org/abs/2509.03543)
*Chenyu Yuan*

Main category: eess.IV

TL;DR: 本文提出LSSPI框架，将单像素成像从像素空间迁移到潜在空间，显著提升了低采样率下的成像能力、重建质量和计算效率，并支持盲去噪和高频信息恢复。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习单像素成像网络在像素空间操作，可能限制其性能，尤其是在低采样率条件下。

Method: 创新性地将单像素成像迁移到潜在空间，并命名为LSSPI（潜在空间单像素成像）框架。在该潜在空间中，深入探索了单像素成像的重建和生成任务。

Result: LSSPI显著增强了低采样率下的成像能力。与传统深度学习网络相比，LSSPI在同等采样率下能重建出更高信噪比和更丰富细节的图像，并实现了盲去噪和高频信息有效恢复。此外，LSSPI在模型参数效率和重建速度方面也具有显著优势，计算效率极高。

Conclusion: LSSPI作为一种理想的低采样单像素成像解决方案，其卓越的计算效率和性能优势，有效推动了单像素成像技术的实际应用。

Abstract: In recent years, the introduction of deep learning into the field of
single-pixel imaging has garnered significant attention. However, traditional
networks often operate within the pixel space. To address this, we innovatively
migrate single-pixel imaging to the latent space, naming this framework LSSPI
(Latent Space Single-Pixel Imaging). Within the latent space, we conduct
in-depth explorations into both reconstruction and generation tasks for
single-pixel imaging. Notably, this approach significantly enhances imaging
capabilities even under low sampling rate conditions. Compared to conventional
deep learning networks, LSSPI not only reconstructs images with higher
signal-to-noise ratios (SNR) and richer details under equivalent sampling rates
but also enables blind denoising and effective recovery of high-frequency
information. Furthermore, by migrating single-pixel imaging to the latent
space, LSSPI achieves superior advantages in terms of model parameter
efficiency and reconstruction speed. Its excellent computational efficiency
further positions it as an ideal solution for low-sampling single-pixel imaging
applications, effectively driving the practical implementation of single-pixel
imaging technology.

</details>


### [200] [Neural Video Compression with In-Loop Contextual Filtering and Out-of-Loop Reconstruction Enhancement](https://arxiv.org/abs/2509.04051)
*Yaojun Wu,Chaoyi Lin,Yiming Wang,Semih Esenlik,Zhaobin Zhang,Kai Zhang,Li Zhang*

Main category: eess.IV

TL;DR: 本文系统性地研究了增强滤波技术在神经视频压缩中的应用，将其分为环内上下文滤波和环外重建增强，并提出自适应编码决策策略，实现了比特率的显著降低。


<details>
  <summary>Details</summary>
Motivation: 在逐帧编码过程中，误差传播会影响时间上下文的细化，且自适应应用滤波具有挑战性；同时，需要简单有效的方法来提升重建帧的质量和编码效率。

Method: 作者将增强滤波技术分为环内上下文滤波（用于减轻误差传播）和环外重建增强（用于提升重建质量）。针对环内滤波的挑战，引入了一种自适应编码决策策略来动态决定滤波的应用。这是首次在基于条件的神经视频压缩背景下对增强滤波进行系统研究。

Result: 实验结果表明，与现有最先进的神经视频编解码器相比，所提出的方法实现了7.71%的比特率降低。

Conclusion: 增强滤波技术在神经视频压缩中是有效的，特别是通过结合环内上下文滤波和环外重建增强，并辅以自适应编码决策策略，能够显著提升编码效率和重建质量。

Abstract: This paper explores the application of enhancement filtering techniques in
neural video compression. Specifically, we categorize these techniques into
in-loop contextual filtering and out-of-loop reconstruction enhancement based
on whether the enhanced representation affects the subsequent coding loop.
In-loop contextual filtering refines the temporal context by mitigating error
propagation during frame-by-frame encoding. However, its influence on both the
current and subsequent frames poses challenges in adaptively applying filtering
throughout the sequence. To address this, we introduce an adaptive coding
decision strategy that dynamically determines filtering application during
encoding. Additionally, out-of-loop reconstruction enhancement is employed to
refine the quality of reconstructed frames, providing a simple yet effective
improvement in coding efficiency. To the best of our knowledge, this work
presents the first systematic study of enhancement filtering in the context of
conditional-based neural video compression. Extensive experiments demonstrate a
7.71% reduction in bit rate compared to state-of-the-art neural video codecs,
validating the effectiveness of the proposed approach.

</details>


### [201] [EHVC: Efficient Hierarchical Reference and Quality Structure for Neural Video Coding](https://arxiv.org/abs/2509.04118)
*Junqi Liao,Yaojun Wu,Chaoyi Lin,Zhipin Deng,Li Li,Dong Liu,Xiaoyan Sun*

Main category: eess.IV

TL;DR: 本文提出了一种高效分层神经视频编码器（EHVC），通过引入分层多参考方案、前瞻策略和分层质量尺度与随机质量训练，解决了现有神经视频编码器中参考与质量结构不匹配以及质量结构优化不足的问题，显著提升了编码性能。


<details>
  <summary>Details</summary>
Motivation: 尽管神经视频编码器（NVCs）在编码效率上表现出色，但现有研究对NVC中的参考结构设计关注较少，导致其与分层质量结构不匹配。此外，分层质量结构本身仍有很大的优化空间。

Method: 本文提出了EHVC，包含三项关键创新：1) 分层多参考方案，借鉴传统视频编码器设计，使参考结构与质量结构对齐，解决参考-质量不匹配问题；2) 前瞻策略，利用未来帧的编码器侧上下文信息增强质量结构；3) 分层质量尺度与随机质量训练策略，以在推理时稳定质量结构。

Result: EHVC在性能上显著优于现有最先进的神经视频编码器。

Conclusion: EHVC通过其创新的分层多参考、前瞻策略和分层质量尺度设计，有效解决了神经视频编码器中的参考-质量不匹配和质量结构优化不足问题，实现了卓越的编码性能。

Abstract: Neural video codecs (NVCs), leveraging the power of end-to-end learning, have
demonstrated remarkable coding efficiency improvements over traditional video
codecs. Recent research has begun to pay attention to the quality structures in
NVCs, optimizing them by introducing explicit hierarchical designs. However,
less attention has been paid to the reference structure design, which
fundamentally should be aligned with the hierarchical quality structure. In
addition, there is still significant room for further optimization of the
hierarchical quality structure. To address these challenges in NVCs, we propose
EHVC, an efficient hierarchical neural video codec featuring three key
innovations: (1) a hierarchical multi-reference scheme that draws on
traditional video codec design to align reference and quality structures,
thereby addressing the reference-quality mismatch; (2) a lookahead strategy to
utilize an encoder-side context from future frames to enhance the quality
structure; (3) a layer-wise quality scale with random quality training strategy
to stabilize quality structures during inference. With these improvements, EHVC
achieves significantly superior performance to the state-of-the-art NVCs. Code
will be released in: https://github.com/bytedance/NEVC.

</details>
