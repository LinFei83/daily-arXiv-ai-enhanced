<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 18]
- [cs.CV](#cs.CV) [Total: 46]
- [cs.CL](#cs.CL) [Total: 69]
- [cs.RO](#cs.RO) [Total: 46]
- [eess.SY](#eess.SY) [Total: 10]
- [eess.IV](#eess.IV) [Total: 5]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Towards Efficient Constraint Handling in Neural Solvers for Routing Problems](https://arxiv.org/abs/2602.16012)
*Jieyi Bi,Zhiguang Cao,Jianan Zhou,Wen Song,Yaoxin Wu,Jie Zhang,Yining Ma,Cathy Wu*

Main category: cs.AI

TL;DR: 本文提出了一种名为 Construct-and-Refine (CaR) 的新框架，用于解决具有复杂约束的神经路由问题，通过显式学习的可行性细化来提高效率和解的质量。


<details>
  <summary>Details</summary>
Motivation: 现有神经求解器在处理复杂约束时效率低下且适用性差，本文旨在开发一种通用且高效的约束处理框架。

Method: CaR 采用联合训练框架，引导构建模块生成多样化的高质量解，并结合轻量级的改进过程。它还引入了构建-改进共享表示，以实现知识共享。

Result: 在具有挑战性的硬约束路由问题上，CaR 在可行性、解的质量和效率方面均优于现有的经典和神经求解器。

Conclusion: CaR 是一种有效且通用的约束处理框架，能够显著提升神经路由求解器在复杂约束下的性能。

Abstract: Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we present Construct-and-Refine (CaR), the first general and efficient constraint-handling framework for neural routing solvers based on explicit learning-based feasibility refinement. Unlike prior construction-search hybrids that target reducing optimality gaps through heavy improvements yet still struggle with hard constraints, CaR achieves efficient constraint handling by designing a joint training framework that guides the construction module to generate diverse and high-quality solutions well-suited for a lightweight improvement process, e.g., 10 steps versus 5k steps in prior work. Moreover, CaR presents the first use of construction-improvement-shared representation, enabling potential knowledge sharing across paradigms by unifying the encoder, especially in more complex constrained scenarios. We evaluate CaR on typical hard routing constraints to showcase its broader applicability. Results demonstrate that CaR achieves superior feasibility, solution quality, and efficiency compared to both classical and neural state-of-the-art solvers.

</details>


### [2] [Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection](https://arxiv.org/abs/2602.16037)
*Cameron Cagan,Pedram Fard,Jiazi Tian,Jingya Cheng,Shawn N. Murphy,Hossein Estiri*

Main category: cs.AI

TL;DR: 研究表明，自主AI在低普遍性分类任务中存在优化不稳定的问题，即持续改进反而会降低性能。通过引入一个选择器代理，可以有效避免这种灾难性故障，并显著提升模型在低普遍性任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 自主代理工作流在持续改进自身行为方面潜力巨大，但其失败模式尚未得到充分表征。作者希望深入研究一种称为“优化不稳定性”的现象。

Method: 使用Pythia框架对三种不同患病率的临床症状（呼吸急促、胸痛、长新冠脑雾）进行自动化提示优化。评估了两种干预措施：引导代理（指导优化）和选择器代理（回顾性选择最佳迭代）。

Result: 在低患病率（3%）下，即使准确率达到95%，系统也可能检测不到任何阳性病例。引导代理反而加剧了过拟合。选择器代理成功防止了灾难性故障，并在脑雾检测方面比专家词汇表F1得分高出331%，胸痛方面高出7%。

Conclusion: 优化不稳定性是自主AI系统的一个关键失败模式。对于低普遍性分类任务，回顾性选择最佳迭代比主动干预更能稳定系统并取得更好的性能。

Abstract: Autonomous agentic workflows that iteratively refine their own behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate optimization instability, a phenomenon in which continued autonomous improvement paradoxically degrades classifier performance, using Pythia, an open-source framework for automated prompt optimization. Evaluating three clinical symptoms with varying prevalence (shortness of breath at 23%, chest pain at 12%, and Long COVID brain fog at 3%), we observed that validation sensitivity oscillated between 1.0 and 0.0 across iterations, with severity inversely proportional to class prevalence. At 3% prevalence, the system achieved 95% accuracy while detecting zero positive cases, a failure mode obscured by standard evaluation metrics. We evaluated two interventions: a guiding agent that actively redirected optimization, amplifying overfitting rather than correcting it, and a selector agent that retrospectively identified the best-performing iteration successfully prevented catastrophic failure. With selector agent oversight, the system outperformed expert-curated lexicons on brain fog detection by 331% (F1) and chest pain by 7%, despite requiring only a single natural language term as input. These findings characterize a critical failure mode of autonomous AI systems and demonstrate that retrospective selection outperforms active intervention for stabilization in low-prevalence classification tasks.

</details>


### [3] [How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment](https://arxiv.org/abs/2602.16039)
*Hang Li,Kaiqi Yang,Xianxuan Long,Fedor Filippov,Yucheng Chu,Yasemin Copur-Gencturk,Peng He,Cory Miller,Namsoo Shin,Joseph Krajcik,Hui Liu,Jiliang Tang*

Main category: cs.AI

TL;DR: 本文对用于教育领域自动评分的大型语言模型（LLMs）的输出不确定性进行了基准测试和分析，评估了不同不确定性量化方法的有效性，并考察了模型家族、评估任务和解码策略等因素对不确定性的影响，为开发更可靠的评分系统奠定基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在教育自动评估中展现出优势，但其固有的概率性带来了输出不确定性的挑战，这可能影响后续的教学干预，对学生学习产生负面影响。现有研究对LLMs在教育评分中的不确定性量化方法研究不足。

Method: 对一系列不确定性量化方法在LLM自动评分场景下进行了基准测试。通过在多个评估数据集、LLM家族和生成控制设置下进行分析，研究了LLMs在评分中的不确定性模式，并评估了不同不确定性度量的优缺点，以及模型家族、评估任务和解码策略等因素的影响。

Result: 本文对LLMs在评分场景下的不确定性模式进行了表征，并评估了不同不确定性量化方法的有效性、优缺点。研究还分析了模型家族、评估任务和解码策略等关键因素对不确定性估计的影响。

Conclusion: 该研究为理解LLM自动评分中的不确定性提供了可操作的见解，并为未来开发更可靠、更有效的考虑不确定性的评分系统奠定了基础。

Abstract: The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they also introduce new challenges related to output uncertainty, stemming from the inherently probabilistic nature of LLMs. Output uncertainty is an inescapable challenge in automatic assessment, as assessment results often play a critical role in informing subsequent pedagogical actions, such as providing feedback to students or guiding instructional decisions. Unreliable or poorly calibrated uncertainty estimates can lead to unstable downstream interventions, potentially disrupting students' learning processes and resulting in unintended negative consequences. To systematically understand this challenge and inform future research, we benchmark a broad range of uncertainty quantification methods in the context of LLM-based automatic assessment. Although the effectiveness of these methods has been demonstrated in many tasks across other domains, their applicability and reliability in educational settings, particularly for automatic grading, remain underexplored. Through comprehensive analyses of uncertainty behaviors across multiple assessment datasets, LLM families, and generation control settings, we characterize the uncertainty patterns exhibited by LLMs in grading scenarios. Based on these findings, we evaluate the strengths and limitations of different uncertainty metrics and analyze the influence of key factors, including model families, assessment tasks, and decoding strategies, on uncertainty estimates. Our study provides actionable insights into the characteristics of uncertainty in LLM-based automatic assessment and lays the groundwork for developing more reliable and effective uncertainty-aware grading systems in the future.

</details>


### [4] [Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination](https://arxiv.org/abs/2602.16050)
*Amir Hosseinian,MohammadReza Zare Shahneh,Umer Mansoor,Gilbert Szeto,Kirill Karlin,Nima Aghaeepour*

Main category: cs.AI

TL;DR: 名为January Mirror的循证临床推理系统在内分泌学考试中表现优于GPT-5、GPT-5.2和Gemini-3-Pro等前沿大语言模型，并超越了人类参考水平，表明在专业临床推理中，经过精心策划的证据优于无限制的网络检索。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在普通医学考试中表现出色，但在亚专科临床推理方面仍面临挑战，原因是指南更新迅速且证据层级复杂。

Method: 研究人员评估了一个名为January Mirror的循证临床推理系统，该系统整合了内分泌学和心脏代谢证据语料库及结构化推理架构，能够生成与证据链接的输出。该系统在120道内分泌学专业考试题上与GPT-5、GPT-5.2和Gemini-3-Pro等前沿大语言模型进行比较。Mirror在封闭证据限制下运行，不进行外部检索；而对比模型则具有实时网络访问能力。

Result: Mirror的准确率为87.5%（105/120），高于人类参考（62.3%）以及GPT-5.2（74.6%）、GPT-5（74.0%）和Gemini-3-Pro（69.8%）。在30道最难的问题（人类准确率低于50%）上，Mirror的准确率为76.7%。Mirror的前两位准确率为92.5%，而GPT-5.2为85.25%。

Conclusion: Mirror能够提供证据可追溯性，74.2%的输出至少引用了一个指南级来源，并且100%的引用准确性经过人工验证。对于亚专科临床推理，精心策划的带有明确来源的证据比无限制的网络检索表现更好，并且支持临床部署的可审计性。

Abstract: Background: Large language models have demonstrated strong performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated January Mirror, an evidence-grounded clinical reasoning system, against frontier LLMs (GPT-5, GPT-5.2, Gemini-3-Pro) on a 120-question endocrinology board-style examination. Mirror integrates a curated endocrinology and cardiometabolic evidence corpus with a structured reasoning architecture to generate evidence-linked outputs. Mirror operated under a closed-evidence constraint without external retrieval. Comparator LLMs had real-time web access to guidelines and primary literature. Results: Mirror achieved 87.5% accuracy (105/120; 95% CI: 80.4-92.3%), exceeding a human reference of 62.3% and frontier LLMs including GPT-5.2 (74.6%), GPT-5 (74.0%), and Gemini-3-Pro (69.8%). On the 30 most difficult questions (human accuracy less than 50%), Mirror achieved 76.7% accuracy. Top-2 accuracy was 92.5% for Mirror versus 85.25% for GPT-5.2. Conclusions: Mirror provided evidence traceability: 74.2% of outputs cited at least one guideline-tier source, with 100% citation accuracy on manual verification. Curated evidence with explicit provenance can outperform unconstrained web retrieval for subspecialty clinical reasoning and supports auditability for clinical deployment.

</details>


### [5] [Improving Interactive In-Context Learning from Natural Language Feedback](https://arxiv.org/abs/2602.16066)
*Martin Klissarov,Jonathan Cook,Diego Antognini,Hao Sun,Jingling Li,Natasha Jaques,Claudiu Musat,Edward Grefenstette*

Main category: cs.AI

TL;DR: 提出了一种将单轮可验证任务转化为多轮教学交互的框架，通过信息不对称来训练大型语言模型（LLM）的交互式学习能力，使其能够从反馈中动态适应，甚至实现自我改进。


<details>
  <summary>Details</summary>
Motivation: 当前 LLM 的训练方法依赖于静态语料库，忽视了模型在交互式环境中从反馈中动态适应的能力，而这种能力对人类学习至关重要。

Method: 将交互式学习能力视为一个可训练的技能，提出了一种框架，将单轮可验证任务转化为由信息不对称驱动的多轮教学交互。通过训练模型预测教师的批评来模拟反馈环境，实现自我改进。

Result: 证明了当前 LLM 在整合硬推理任务的纠正反馈方面存在不足。采用新方法训练的模型在交互式学习反馈方面表现出显著的提升，即使是较小的模型也能接近更大模型的性能。观察到良好的分布外泛化能力，跨越数学、编程、谜题和导航等领域。

Conclusion: 提出的框架能够显着提高 LLM 的交互式学习能力，增强其上下文可塑性，并提供一种统一的自我改进途径，使模型能够在没有外部教师的情况下进行自我纠正。

Abstract: Adapting one's thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static corpora. While effective for knowledge acquisition, it overlooks the interactive feedback loops essential for models to adapt dynamically to their context. In this work, we propose a framework that treats this interactive in-context learning ability not as an emergent property, but as a distinct, trainable skill. We introduce a scalable method that transforms single-turn verifiable tasks into multi-turn didactic interactions driven by information asymmetry. We first show that current flagship models struggle to integrate corrective feedback on hard reasoning tasks. We then demonstrate that models trained with our approach dramatically improve the ability to interactively learn from language feedback. More specifically, the multi-turn performance of a smaller model nearly reaches that of a model an order of magnitude larger. We also observe robust out-of-distribution generalization: interactive training on math problems transfers to diverse domains like coding, puzzles and maze navigation. Our qualitative analysis suggests that this improvement is due to an enhanced in-context plasticity. Finally, we show that this paradigm offers a unified path to self-improvement. By training the model to predict the teacher's critiques, effectively modeling the feedback environment, we convert this external signal into an internal capability, allowing the model to self-correct even without a teacher.

</details>


### [6] [GPSBench: Do Large Language Models Understand GPS Coordinates?](https://arxiv.org/abs/2602.16105)
*Thinh Hung Truong,Jey Han Lau,Jianzhong Qi*

Main category: cs.AI

TL;DR: 研究者们提出了GPSBench数据集，用于评估大型语言模型（LLMs）在地理空间推理能力方面的表现，发现LLMs在地理常识推理方面优于几何计算，且地理知识的理解呈层级性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在与物理世界交互的应用中越来越普遍，例如导航、机器人和地图绘制，因此，强大的地理空间推理能力变得至关重要。然而，LLMs在地理坐标和真实世界地理方面的推理能力仍未得到充分探索。

Method: 引入GPSBench数据集，包含57,800个样本，横跨17项任务，用于评估LLMs的地理空间推理能力。评估的重点是模型本身的内在能力，而非工具使用。评估了14个最先进的LLMs。

Result: GPS推理对LLMs仍然是一个挑战，不同任务间的表现存在显著差异：模型在真实世界地理推理方面通常比在几何计算方面更可靠。地理知识的理解呈层级化，在国家层面的表现良好，但在城市层面的定位能力较弱。模型对坐标噪声的鲁棒性表明其具备真实的坐标理解能力，而非死记硬背。此外，GPS坐标增强可以提升下游地理空间任务的表现，而微调会带来几何计算能力的提升和世界知识理解能力下降的权衡。

Conclusion: GPSBench数据集为评估LLMs的地理空间推理能力提供了一个全面的基准。研究结果表明，LLMs在地理空间推理方面仍有提升空间，特别是几何计算和城市级别的定位能力。同时，GPS坐标的增强和微调策略可以影响模型的表现，但需要注意潜在的权衡。

Abstract: Large Language Models (LLMs) are increasingly deployed in applications that interact with the physical world, such as navigation, robotics, or mapping, making robust geospatial reasoning a critical capability. Despite that, LLMs' ability to reason about GPS coordinates and real-world geography remains underexplored. We introduce GPSBench, a dataset of 57,800 samples across 17 tasks for evaluating geospatial reasoning in LLMs, spanning geometric coordinate operations (e.g., distance and bearing computation) and reasoning that integrates coordinates with world knowledge. Focusing on intrinsic model capabilities rather than tool use, we evaluate 14 state-of-the-art LLMs and find that GPS reasoning remains challenging, with substantial variation across tasks: models are generally more reliable at real-world geographic reasoning than at geometric computations. Geographic knowledge degrades hierarchically, with strong country-level performance but weak city-level localization, while robustness to coordinate noise suggests genuine coordinate understanding rather than memorization. We further show that GPS-coordinate augmentation can improve in downstream geospatial tasks, and that finetuning induces trade-offs between gains in geometric computation and degradation in world knowledge. Our dataset and reproducible code are available at https://github.com/joey234/gpsbench

</details>


### [7] [Learning Personalized Agents from Human Feedback](https://arxiv.org/abs/2602.16173)
*Kaiqu Liang,Julia Kruk,Shengyi Qian,Xianjun Yang,Shengjie Bi,Yuanshun Yao,Shaoliang Nie,Mingyang Zhang,Lijuan Liu,Jaime Fernández Fisac,Shuyan Zhou,Saghar Hosseini*

Main category: cs.AI

TL;DR: 提出了一种名为PAHF的框架，通过在线学习和显式的用户记忆，使AI代理能够持续适应用户不断变化的个性化偏好，并在模拟环境中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的AI代理在适应个体用户特异性、不断变化的偏好方面存在困难，尤其是在面对新用户或偏好随时间改变时。现有方法依赖静态数据集，难以实现持续个性化。

Method: PAHF框架包含三个步骤：(1) 动作前的澄清以解决歧义；(2) 基于从用户记忆中检索到的偏好来执行动作；(3) 动作后的反馈用于在偏好漂移时更新记忆。该研究还开发了一个四阶段协议和两个基准来评估该框架。

Result: PAHF框架通过结合显式记忆和双反馈通道，能够更快地学习，并显著优于不使用记忆或仅使用单一反馈通道的方法。实验结果表明，PAHF能减少初始个性化误差，并能快速适应偏好变化。

Conclusion: 显式用户记忆与双反馈通道的结合对于AI代理实现持续个性化至关重要，PAHF框架能够有效解决现有方法的局限性，实现快速、鲁棒的偏好学习和适应。

Abstract: Modern AI agents are powerful but often fail to align with the idiosyncratic, evolving preferences of individual users. Prior approaches typically rely on static datasets, either training implicit preference models on interaction history or encoding user profiles in external memory. However, these approaches struggle with new users and with preferences that change over time. We introduce Personalized Agents from Human Feedback (PAHF), a framework for continual personalization in which agents learn online from live interaction using explicit per-user memory. PAHF operationalizes a three-step loop: (1) seeking pre-action clarification to resolve ambiguity, (2) grounding actions in preferences retrieved from memory, and (3) integrating post-action feedback to update memory when preferences drift. To evaluate this capability, we develop a four-phase protocol and two benchmarks in embodied manipulation and online shopping. These benchmarks quantify an agent's ability to learn initial preferences from scratch and subsequently adapt to persona shifts. Our theoretical analysis and empirical results show that integrating explicit memory with dual feedback channels is critical: PAHF learns substantially faster and consistently outperforms both no-memory and single-channel baselines, reducing initial personalization error and enabling rapid adaptation to preference shifts.

</details>


### [8] [EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments](https://arxiv.org/abs/2602.16179)
*Sushant Mehta,Logan Ritchie,Suhaas Garre,Nick Heiner,Edwin Chen*

Main category: cs.AI

TL;DR: 本研究通过在高度逼真的企业级客户支持模拟环境“CoreCraft”中训练AI代理，证明了高质量、多样化和真实的训练环境能够显著提升AI代理的能力泛化性，使其能够解决现实世界中的多步骤、领域特定任务。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理在处理现实世界复杂任务时泛化能力不足，需要能够衡量和提升AI代理在实际工作场景中执行多步骤、领域特定任务的能力。

Method: 引入了一个名为“CoreCraft”的企业级客户支持模拟环境，该环境包含2500多个实体、14种实体类型和23种工具。使用Group Relative Policy Optimization (GRPO)和自适应裁剪技术，在CoreCraft环境中训练了GLM 4.6模型。

Result: 经过一个训练周期后，GLM 4.6在CoreCraft上的任务通过率从25.37%提升到36.76%。更重要的是，这些改进能够迁移到分布外（out-of-distribution）的基准测试中，在BFCL Parallel上提升4.5%，在τ^2-Bench Retail上提升7.4%，在Toolathlon (Pass@1)上提升6.8%。

Conclusion: 高质量、多样化和真实的企业级模拟环境是实现AI代理可泛化能力的关键因素。这些环境特性，包括以任务为中心的构建、专家制定的评估标准以及反映专业模式的企业工作流程，能够有效促进AI代理能力的提升和泛化。

Abstract: We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce \corecraft{}, the first environment in \textsc{EnterpriseGym}, Surge AI's suite of agentic RL environments. \corecraft{} is a fully operational enterprise simulation of a customer support organization, comprising over 2,500 entities across 14 entity types with 23 unique tools, designed to measure whether AI agents can perform the multi-step, domain-specific work that real jobs demand. Frontier models such as GPT-5.2 and Claude Opus 4.6 solve fewer than 30\% of tasks when all expert-authored rubric criteria must be satisfied. Using this environment, we train GLM~4.6 with Group Relative Policy Optimization (GRPO) and adaptive clipping. After a single epoch of training, the model improves from 25.37\% to 36.76\% task pass rate on held-out evaluation tasks. More importantly, these gains transfer to out-of-distribution benchmarks: +4.5\% on BFCL Parallel, +7.4\% on $τ^2$-Bench Retail, and +6.8\% on Toolathlon (Pass@1). We believe three environment properties are consistent with the observed transfer: task-centric world building that optimizes for diverse, challenging tasks; expert-authored rubrics enabling reliable reward computation; and enterprise workflows that reflect realistic professional patterns. Our results suggest that environment quality, diversity, and realism are key factors enabling generalizable agent capabilities.

</details>


### [9] [Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage](https://arxiv.org/abs/2602.16192)
*Hiroaki Yamanaka,Daisuke Miyashita,Takashi Toi,Asuka Maki,Taiga Ikeda,Jun Deguchi*

Main category: cs.AI

TL;DR: 本文提出并探讨了几种与“提取后存储”范式不同的“记忆”设计概念，以期实现人工智能超级智能（ASI）。重点介绍了“存储后按需提取”的方法，该方法通过保留原始经验来避免信息丢失，并提出了从概率性经验中发现更深层见解以及通过共享经验提高收集效率的两种补充方法。尽管这些方法在直觉上很有效，但实验表明了其潜力，并且文章最后讨论了实现这些方法的挑战和未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前主流的“提取后存储”方法存在信息丢失的风险，特别是在处理不同任务时可能丢弃有价值的知识。研究的动机是探索新的“记忆”设计概念，以避免信息丢失，并为实现人工智能超级智能（ASI）提供潜在的更优解决方案。

Method: 本文提出并分析了几种“记忆”设计概念，包括“存储后按需提取”、“从概率性经验中发现深层见解”以及“通过共享经验提高效率”。研究采用了简单的实验来验证这些方法的有效性，并讨论了相关的挑战和研究方向。

Result: 简单的实验表明，“存储后按需提取”等方法在避免信息丢失和潜在地提升不同任务表现方面是有效的。从概率性经验中发现深层见解和提高经验收集效率也具有潜力。

Conclusion: 本文强调了“存储后按需提取”等新型记忆设计概念在避免信息丢失和支持未来人工智能发展方面的潜力。尽管存在挑战，但这些方向值得进一步研究，以期实现人工智能超级智能（ASI）。

Abstract: Driven by our mission of "uplifting the world with memory," this paper explores the design concept of "memory" that is essential for achieving artificial superintelligence (ASI). Rather than proposing novel methods, we focus on several alternative approaches whose potential benefits are widely imaginable, yet have remained largely unexplored. The currently dominant paradigm, which can be termed "extract then store," involves extracting information judged to be useful from experiences and saving only the extracted content. However, this approach inherently risks the loss of information, as some valuable knowledge particularly for different tasks may be discarded in the extraction process. In contrast, we emphasize the "store then on-demand extract" approach, which seeks to retain raw experiences and flexibly apply them to various tasks as needed, thus avoiding such information loss. In addition, we highlight two further approaches: discovering deeper insights from large collections of probabilistic experiences, and improving experience collection efficiency by sharing stored experiences. While these approaches seem intuitively effective, our simple experiments demonstrate that this is indeed the case. Finally, we discuss major challenges that have limited investigation into these promising directions and propose research topics to address them.

</details>


### [10] [Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents](https://arxiv.org/abs/2602.16246)
*Yun-Shiuan Chuang,Chaitanya Kulkarni,Alec Chiu,Avinash Thangali,Zijie Pan,Shivani Shekhar,Yirou Ge,Yixi Li,Uma Kona,Linsey Pang,Prakhar Mehrotra*

Main category: cs.AI

TL;DR: 提出了一种名为“代理状态评估”（Proxy State-Based Evaluation）的基于 LLM 的模拟框架，用于评估交互式 LLM 代理，无需依赖确定性的后端，从而实现可扩展性和易于迭代。该框架通过 LLM 来跟踪代理状态，并使用 LLM 法官来验证目标完成情况和检测幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的交互式 LLM 代理基准测试（如 tau-bench、AppWorld）依赖于确定性后端，这在构建和迭代上成本高昂。需要一种更具成本效益且易于迭代的评估方法，同时仍能提供可靠的评估和用于训练的数据。

Method: 该框架使用 LLM 驱动的模拟。场景包含用户目标、事实、预期最终状态和预期代理行为。LLM 状态跟踪器根据交互历史推断结构化代理状态。LLM 法官根据场景约束验证目标完成情况并检测幻觉。该框架还支持用户个性分析，并能生成用于模型训练的 on-policy 和 off-policy 数据。

Result: 该基准测试在不同模型家族和推理时间下产生了稳定的、区分度高的模型排名。其 on-/off-policy 采样提供了可迁移到未见过场景的监督信号。仔细的场景设计可将模拟器幻觉率降至接近零。与人类评估者的一致性超过 90%。

Conclusion: 代理状态评估为工业级 LLM 代理提供了一种实用且可扩展的替代确定性代理基准测试的方法，能够有效且经济地评估 LLM 代理的性能，并生成有用的训练数据。

Abstract: Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-bench, tau2-bench, AppWorld) rely on fully deterministic backends, which are costly to build and iterate. We propose Proxy State-Based Evaluation, an LLM-driven simulation framework that preserves final state-based evaluation without a deterministic database. Specifically, a scenario specifies the user goal, user/system facts, expected final state, and expected agent behavior, and an LLM state tracker infers a structured proxy state from the full interaction trace. LLM judges then verify goal completion and detect tool/user hallucinations against scenario constraints. Empirically, our benchmark produces stable, model-differentiating rankings across families and inference-time reasoning efforts, and its on-/off-policy rollouts provide supervision that transfers to unseen scenarios. Careful scenario specification yields near-zero simulator hallucination rates as supported by ablation studies. The framework also supports sensitivity analyses over user personas. Human-LLM judge agreement exceeds 90%, indicating reliable automated evaluation. Overall, proxy state-based evaluation offers a practical, scalable alternative to deterministic agentic benchmarks for industrial LLM agents.

</details>


### [11] [Multi-agent cooperation through in-context co-player inference](https://arxiv.org/abs/2602.16301)
*Marissa A. Weis,Maciej Wołczyk,Rajai Nasser,Rif A. Saurous,Blaise Agüera y Arcas,João Sacramento,Alexander Meulemans*

Main category: cs.AI

TL;DR: 本研究表明，利用序列模型的上下文学习能力，可以在没有硬编码假设或时间尺度分离的情况下，让自私的智能体之间实现合作。通过与多样化的对手进行训练，智能体能够学习到上下文最佳响应策略，从而自发地产生合作行为，解决了先前的外行勒索问题。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习中，如何让自私的智能体之间实现合作是一个基本挑战。先前的研究虽然取得了一定进展，但依赖于硬编码的假设或严格的时间尺度分离，这些方法存在局限性。

Method: 本研究利用序列模型的上下文学习能力，训练智能体与多样化的对手进行交互。智能体通过学习对手的内部学习动态来调整自身的策略，从而实现上下文最佳响应。

Result: 研究发现，这种方法能够自然地诱导出上下文最佳响应策略，并在智能体之间引发合作行为。特别是，先前提出的“易受敲诈”导致相互塑造的合作机制，在本研究的设置下自然出现。

Conclusion: 标准化的去中心化强化学习结合序列模型和对手多样性，为学习合作行为提供了一条可扩展的路径。上下文学习能力为实现学习感知智能体提供了新的解决方案，克服了现有方法的限制。

Abstract: Achieving cooperation among self-interested agents remains a fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be induced between "learning-aware" agents that account for and shape the learning dynamics of their co-players. However, existing approaches typically rely on hardcoded, often inconsistent, assumptions about co-player learning rules or enforce a strict separation between "naive learners" updating on fast timescales and "meta-learners" observing these updates. Here, we demonstrate that the in-context learning capabilities of sequence models allow for co-player learning awareness without requiring hardcoded assumptions or explicit timescale separation. We show that training sequence model agents against a diverse distribution of co-players naturally induces in-context best-response strategies, effectively functioning as learning algorithms on the fast intra-episode timescale. We find that the cooperative mechanism identified in prior work-where vulnerability to extortion drives mutual shaping-emerges naturally in this setting: in-context adaptation renders agents vulnerable to extortion, and the resulting mutual pressure to shape the opponent's in-context learning dynamics resolves into the learning of cooperative behavior. Our results suggest that standard decentralized reinforcement learning on sequence models combined with co-player diversity provides a scalable path to learning cooperative behaviors.

</details>


### [12] [Verifiable Semantics for Agent-to-Agent Communication](https://arxiv.org/abs/2602.16424)
*Philipp Schoenegger,Matt Carlson,Chris Schneider,Chris Daly*

Main category: cs.AI

TL;DR: 本文提出了一种基于刺激-意义模型的认证协议，用于验证多智能体系统中智能体之间的术语理解一致性，通过限制推理到认证术语来保证有限的不一致性。


<details>
  <summary>Details</summary>
Motivation: 多智能体AI系统需要一致的通信，但目前缺乏验证智能体对术语理解是否一致的方法。自然语言可解释但易发生语义漂移，而学习到的协议效率高但缺乏透明度。

Method: 提出了一种基于刺激-意义模型的认证协议，通过测试智能体对共享可观测事件的反应来认证术语，当经验不一致性低于统计阈值时，术语被认证。该协议还包括检测漂移（再认证）和恢复共享词汇（再协商）的机制。研究中采用“核心守卫推理”（core-guarded reasoning）来限制智能体的推理。

Result: 在模拟实验中，核心守卫推理将不一致性降低了 72-96%。在对微调语言模型进行的验证中，不一致性降低了 51%。

Conclusion: 该框架为实现可验证的智能体间通信迈出了第一步，通过认证协议和核心守卫推理，能够有效减少智能体之间的语义不一致性。

Abstract: Multiagent AI systems require consistent communication, but we lack methods to verify that agents share the same understanding of the terms used. Natural language is interpretable but vulnerable to semantic drift, while learned protocols are efficient but opaque. We propose a certification protocol based on the stimulus-meaning model, where agents are tested on shared observable events and terms are certified if empirical disagreement falls below a statistical threshold. In this protocol, agents restricting their reasoning to certified terms ("core-guarded reasoning") achieve provably bounded disagreement. We also outline mechanisms for detecting drift (recertification) and recovering shared vocabulary (renegotiation). In simulations with varying degrees of semantic divergence, core-guarding reduces disagreement by 72-96%. In a validation with fine-tuned language models, disagreement is reduced by 51%. Our framework provides a first step towards verifiable agent-to-agent communication.

</details>


### [13] [Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.16435)
*Arun Vignesh Malarkkan,Wangyang Ying,Yanjie Fu*

Main category: cs.AI

TL;DR: CAFE 框架将自动化特征工程（AFE）重塑为因果引导的顺序决策过程，结合因果发现和强化学习，提高了特征的鲁棒性和效率，尤其在分布变化下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有 AFE 方法依赖统计启发式，生成的特征在分布变化下鲁棒性差。研究动机是开发一种能生成更鲁棒特征的 AFE 方法。

Method: CAFE 分两个阶段：第一阶段学习特征与目标之间的稀疏有向无环图（DAG），获得软因果先验，并将特征分为直接、间接或其他类型；第二阶段使用级联多智能体深度 Q-学习架构，结合分层奖励塑造和因果组探索策略，选择因果组和转换算子。

Result: 在 15 个基准测试中，CAFE 相较于现有 AFE 方法有高达 7% 的性能提升，收敛速度更快，并且在分布变化下性能下降减少约 4 倍，生成的特征集更紧凑，事后归因更稳定。

Conclusion: 将因果结构作为软归纳偏置而非硬约束，可以显著提高自动化特征工程的鲁棒性和效率。

Abstract: Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over features and the target to obtain soft causal priors, grouping features as direct, indirect, or other based on their causal influence with respect to the target. Phase II uses a cascading multi-agent deep Q-learning architecture to select causal groups and transformation operators, with hierarchical reward shaping and causal group-level exploration strategies that favor causally plausible transformations while controlling feature complexity. Across 15 public benchmarks (classification with macro-F1; regression with inverse relative absolute error), CAFE achieves up to 7% improvement over strong AFE baselines, reduces episodes-to-convergence, and delivers competitive time-to-target. Under controlled covariate shifts, CAFE reduces performance drop by ~4x relative to a non-causal multi-agent baseline, and produces more compact feature sets with more stable post-hoc attributions. These findings underscore that causal structure, used as a soft inductive prior rather than a rigid constraint, can substantially improve the robustness and efficiency of automated feature engineering.

</details>


### [14] [Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach](https://arxiv.org/abs/2602.16481)
*Zihao Li,Fabrizio Russo*

Main category: cs.AI

TL;DR: 本文将大语言模型（LLMs）作为不完美的专家，用于因果发现的因果假设式论证（Causal ABA）框架。通过从变量名称和描述中提取语义结构先验，并结合条件独立性证据，实现了最先进的性能，并提出了一种新的评估协议来减轻 LLMs 在因果发现中的记忆偏差。


<details>
  <summary>Details</summary>
Motivation: 在因果发现中，结合专家知识和统计方法来构建因果图存在挑战。专家知识对于构建合理的因果图至关重要，但统计方法在利用观测数据方面存在不同的理论保证。因此，需要一种能够有效结合数据和专家知识的框架。

Method: 本文将大语言模型（LLMs）作为不完美的专家，用于因果假设式论证（Causal ABA）框架。具体而言，从变量名称和描述中提取语义结构先验，并将其与条件独立性证据相结合。此外，还引入了一种新的评估协议来减轻 LLMs 在因果发现中的记忆偏差。

Result: 在标准基准测试和基于语义的合成图上的实验表明，该方法实现了最先进的性能。新的评估协议成功地减轻了 LLMs 的记忆偏差。

Conclusion: 大语言模型（LLMs）可以作为不完美的专家，有效地融入因果发现的因果假设式论证（Causal ABA）框架中，从而在结合专家知识和统计证据方面取得了优异的性能。引入的评估协议有助于更公平地评估 LLMs 在因果发现任务中的能力。

Abstract: Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.

</details>


### [15] [Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs](https://arxiv.org/abs/2602.16512)
*Felix Fricke,Simon Malberg,Georg Groh*

Main category: cs.AI

TL;DR: 本文提出了一种名为“思路框架”(FoT)的通用基础框架，用于构建和优化动态推理方案，以克服现有方法在适应性、超参数调优和效率方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型推理方案（如CoT、ToT、GoT）需要静态、问题特定的推理结构，缺乏适应性和优化。这导致超参数、提示、运行时和成本等方面存在不足。

Method: FoT是一个通用框架，集成了超参数调优、提示优化、并行执行和智能缓存等功能，以构建和优化动态推理方案。研究人员在FoT中实现了ToT、GoT和ProbTree，并通过实验验证了其有效性。

Result: 通过FoT实现的推理方案，在执行速度、成本和任务得分方面均有显著提升。FoT能够解锁推理方案的潜在性能。

Conclusion: FoT是一个能够显著提高动态推理方案效率和性能的通用框架，有助于未来开发更高效的推理方案。

Abstract: Prompting schemes such as Chain of Thought, Tree of Thoughts, and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However, most existing schemes require users to define static, problem-specific reasoning structures that lack adaptability to dynamic or unseen problem types. Additionally, these schemes are often under-optimized in terms of hyperparameters, prompts, runtime, and prompting cost. To address these limitations, we introduce Framework of Thoughts (FoT)--a general-purpose foundation framework for building and optimizing dynamic reasoning schemes. FoT comes with built-in features for hyperparameter tuning, prompt optimization, parallel execution, and intelligent caching, unlocking the latent performance potential of reasoning schemes. We demonstrate FoT's capabilities by implementing three popular schemes--Tree of Thoughts, Graph of Thoughts, and ProbTree--within FoT. We empirically show that FoT enables significantly faster execution, reduces costs, and achieves better task scores through optimization. We release our codebase to facilitate the development of future dynamic and efficient reasoning schemes.

</details>


### [16] [Creating a digital poet](https://arxiv.org/abs/2602.16578)
*Vered Tohar,Tsahi Hayat,Amir Leshem*

Main category: cs.AI

TL;DR: 研究表明，通过迭代式专家反馈，大型语言模型可以被塑造成一个有独特风格的数字诗人，其创作的诗歌在盲测中难以与人类诗人区分，甚至被商业出版。这引发了关于机器艺术创作和作者身份的新讨论。


<details>
  <summary>Details</summary>
Motivation: 探索机器（特别是大型语言模型）是否能创作出有艺术价值的诗歌，以及这是否会动摇我们对艺术本质和价值的根本认知。

Method: 通过一个为期七个月的诗歌工坊，利用迭代式、情境内的专家反馈（而非重新训练）来塑造一个大型语言模型，使其成为一个数字诗人。对模型产出的诗歌进行了定量和定性分析，并进行了包括人类和AI诗歌在内的盲测。

Result: 该模型发展出了独特的风格和连贯的作品集。在由50名人文专业学生和毕业生进行的盲测中，他们无法区分AI创作的诗歌和著名诗人创作的诗歌，判断准确率接近随机猜测。模型甚至创作了自己的笔名和作者形象。

Conclusion: 通过工作坊式的提示工程，可以实现对大型语言模型长周期的创造性塑造。研究结果表明，机器可以进行有意义的艺术创作，并促使关于创造力、艺术价值和作者身份的辩论重新展开。

Abstract: Can a machine write good poetry? Any positive answer raises fundamental questions about the nature and value of art. We report a seven-month poetry workshop in which a large language model was shaped into a digital poet through iterative in-context expert feedback, without retraining. Across sessions, the model developed a distinctive style and a coherent corpus, supported by quantitative and qualitative analyses, and it produced a pen name and author image. In a blinded authorship test with 50 humanities students and graduates (three AI poems and three poems by well-known poets each), judgments were at chance: human poems were labeled human 54% of the time and AI poems 52%, with 95% confidence intervals including 50%. After the workshop, a commercial publisher released a poetry collection authored by the model. These results show that workshop-style prompting can support long-horizon creative shaping and renew debates on creativity and authorship.

</details>


### [17] [Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments](https://arxiv.org/abs/2602.16653)
*Yangjie Xu,Lujun Li,Lama Sleem,Niccolo Gentile,Yewei Song,Yiqun Wang,Siming Ji,Wenbo Wu,Radu State*

Main category: cs.AI

TL;DR: 本文研究了Agent Skill框架对小语言模型（SLM）的效益，发现中等规模（12B-30B参数）的SLM能显著受益于此框架，而大型代码专业模型（约80B参数）在GPU效率上可媲美闭源模型。


<details>
  <summary>Details</summary>
Motivation: 在实际工业场景中，由于数据安全和预算限制，无法持续依赖公共API，而SLM在定制化场景下泛化能力有限。因此，需要研究Agent Skill框架是否能为SLM带来类似Proprietary模型的好处，以解决这些工业痛点。

Method: 研究首先对Agent Skill过程进行了形式化的数学定义，然后系统性地评估了不同规模的语言模型（包括SLM）在多个使用场景下的表现。评估包括两个开源任务和一个真实的保险理赔数据集。

Result: 研究发现，非常小的模型在可靠地选择技能方面存在困难。然而，中等规模的SLM（约12B-30B参数）从Agent Skill方法中获得了显著的提升。此外，约80B参数的代码专业化模型在性能上能与闭源基线模型相媲美，同时提高了GPU效率。

Conclusion: Agent Skill框架对SLM的能力和限制进行了全面而细致的表征。研究结果为在以SLM为主的环境中有效部署Agent Skills提供了可操作的见解，特别是对于中等规模的SLM，该框架能显著提高性能和效率。

Abstract: Agent Skill framework, now widely and officially supported by major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations, an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small language models (SLMs). This question matters in industrial scenarios where continuous reliance on public APIs is infeasible due to data-security and budget constraints requirements, and where SLMs often show limited generalization in highly customized scenarios. This work introduces a formal mathematical definition of the Agent Skill process, followed by a systematic evaluation of language models of varying sizes across multiple use cases. The evaluation encompasses two open-source tasks and a real-world insurance claims data set. The results show that tiny models struggle with reliable skill selection, while moderately sized SLMs (approximately 12B - 30B) parameters) benefit substantially from the Agent Skill approach. Moreover, code-specialized variants at around 80B parameters achieve performance comparable to closed-source baselines while improving GPU efficiency. Collectively, these findings provide a comprehensive and nuanced characterization of the capabilities and constraints of the framework, while providing actionable insights for the effective deployment of Agent Skills in SLM-centered environments.

</details>


### [18] [Towards a Science of AI Agent Reliability](https://arxiv.org/abs/2602.16666)
*Stephan Rabanser,Sayash Kapoor,Peter Kirgis,Kangheng Liu,Saiteja Utpala,Arvind Narayanan*

Main category: cs.AI

TL;DR: 现有AI代理的准确率评分不能反映其实际可靠性，作者提出了一个包含一致性、鲁棒性、可预测性和安全性的四维度十二项指标体系来评估代理的可靠性，并发现近期能力提升对可靠性提升不大。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理的准确率评分无法全面反映其在实际应用中的运行缺陷，如不一致、易受干扰、故障不可预测或错误严重性不可控等问题。

Method: 提出一个基于安全关键工程学的性能评估体系，包含一致性、鲁棒性、可预测性和安全性四个维度共十二项具体指标，并用此体系评估了14个代理模型在两个基准上的表现。

Result: 评估发现，尽管AI代理的能力有所提升，但在可靠性方面仅有微小改进。

Conclusion: 作者提出的可靠性指标体系能够弥补传统评估的不足，提供更全面的代理性能分析工具，有助于理解代理的行为、性能下降和失效模式。

Abstract: AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity. Grounded in safety-critical engineering, we provide a holistic performance profile by proposing twelve concrete metrics that decompose agent reliability along four key dimensions: consistency, robustness, predictability, and safety. Evaluating 14 agentic models across two complementary benchmarks, we find that recent capability gains have only yielded small improvements in reliability. By exposing these persistent limitations, our metrics complement traditional evaluations while offering tools for reasoning about how agents perform, degrade, and fail.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [19] [Egocentric Bias in Vision-Language Models](https://arxiv.org/abs/2602.15892)
*Maijunxian Wang,Yijiang Li,Bingyang Wang,Tianwei Zhao,Ran Ji,Qingying Gao,Emmy Liu,Hokin Deng,Dezhi Luo*

Main category: cs.CV

TL;DR: 研究者提出了FlipSet基准测试，用于评估视觉语言模型（VLMs）的二级视觉透视能力。测试发现，大多数模型存在系统性的以自我为中心的偏见，错误结果常复制了相机视角，并且模型在单独执行心智旋转和心智理论任务时表现良好，但在整合这两项能力时会灾难性地失败，表明其在结合社会意识和空间操作方面存在根本性缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在理解他人视觉视角方面能力不足，需要一个专门的基准来诊断和提升这种能力。

Method: 提出FlipSet基准，要求模型模拟2D字符串在180度旋转后从另一代理人视角看的样子，以隔离空间转换和3D场景复杂性。评估了103个VLMs，并进行对照实验以探究模型的组合能力。

Result: 大多数VLMs的表现低于随机猜测水平，约四分之三的错误复制了相机视角。对照实验发现，模型在单独进行心智理论和心智旋转任务时表现良好，但在需要整合这两种能力时失败。

Conclusion: 当前VLMs在结合社会意识和空间操作方面存在缺陷，缺乏必要的机制来实现模型式的空间推理，FlipSet提供了一个诊断多模态系统透视能力的平台。

Abstract: Visual perspective taking--inferring how the world appears from another's viewpoint--is foundational to social cognition. We introduce FlipSet, a diagnostic benchmark for Level-2 visual perspective taking (L2 VPT) in vision-language models. The task requires simulating 180-degree rotations of 2D character strings from another agent's perspective, isolating spatial transformation from 3D scene complexity. Evaluating 103 VLMs reveals systematic egocentric bias: the vast majority perform below chance, with roughly three-quarters of errors reproducing the camera viewpoint. Control experiments expose a compositional deficit--models achieve high theory-of-mind accuracy and above-chance mental rotation in isolation, yet fail catastrophically when integration is required. This dissociation indicates that current VLMs lack the mechanisms needed to bind social awareness to spatial operations, suggesting fundamental limitations in model-based spatial reasoning. FlipSet provides a cognitively grounded testbed for diagnosing perspective-taking capabilities in multimodal systems.

</details>


### [20] [Detecting Deepfakes with Multivariate Soft Blending and CLIP-based Image-Text Alignment](https://arxiv.org/abs/2602.15903)
*Jingwei Li,Jiaxin Tong,Pengfei Wu*

Main category: cs.CV

TL;DR: 提出了一种名为 MSBA-CLIP 的新型深度伪造检测框架，通过多变量软混合增强和 CLIP 引导的伪造强度估计，提高了检测精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法因不同伪造技术产生的样本分布差异而存在精度有限和泛化能力差的问题。

Method: 提出 MSBA-CLIP 框架，利用 CLIP 的多模态对齐能力捕捉细微伪造痕迹；引入多变量软混合增强 (MSBA) 合成图像，迫使模型学习可泛化模式；设计多变量伪造强度估计 (MFIE) 模块，显式引导模型学习与不同伪造模式和强度相关的特征。

Result: 在域内测试中，精度和 AUC 分别比最佳基线提高了 3.32% 和 4.02%；在跨 5 个数据集的域间评估中，平均 AUC 提升了 3.27%。消融实验验证了所提组件的有效性。

Conclusion: MSBA-CLIP 框架在深度伪造检测方面取得了最先进的性能，实现了更具泛化性和鲁棒性的检测，但计算成本较高。

Abstract: The proliferation of highly realistic facial forgeries necessitates robust detection methods. However, existing approaches often suffer from limited accuracy and poor generalization due to significant distribution shifts among samples generated by diverse forgery techniques. To address these challenges, we propose a novel Multivariate and Soft Blending Augmentation with CLIP-guided Forgery Intensity Estimation (MSBA-CLIP) framework. Our method leverages the multimodal alignment capabilities of CLIP to capture subtle forgery traces. We introduce a Multivariate and Soft Blending Augmentation (MSBA) strategy that synthesizes images by blending forgeries from multiple methods with random weights, forcing the model to learn generalizable patterns. Furthermore, a dedicated Multivariate Forgery Intensity Estimation (MFIE) module is designed to explicitly guide the model in learning features related to varied forgery modes and intensities. Extensive experiments demonstrate state-of-the-art performance. On in-domain tests, our method improves Accuracy and AUC by 3.32\% and 4.02\%, respectively, over the best baseline. In cross-domain evaluations across five datasets, it achieves an average AUC gain of 3.27\%. Ablation studies confirm the efficacy of both proposed components. While the reliance on a large vision-language model entails higher computational cost, our work presents a significant step towards more generalizable and robust deepfake detection.

</details>


### [21] [A Comprehensive Survey on Deep Learning-Based LiDAR Super-Resolution for Autonomous Driving](https://arxiv.org/abs/2602.15904)
*June Moh Goo,Zichao Zeng,Jan Boehm*

Main category: cs.CV

TL;DR: 该论文首次对自动驾驶领域的 LiDAR 超分辨率方法进行了全面调查，将现有方法分为四类：CNN、模型展开、隐式表示和 Transformer/Mamba。它还讨论了数据表示、问题设定、基准数据集和评估指标，并指出现有趋势和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有低分辨率 LiDAR 传感器成本低但点云稀疏，容易错过关键细节，而高分辨率传感器成本高昂。LiDAR 超分辨率技术可以提高低分辨率传感器的性能，填补了不同传感器之间的技术空白，但目前缺乏系统性的综述。因此，该研究旨在提供一个全面的调查，以推动该领域的发展。

Method: 该论文对 LiDAR 超分辨率方法进行了系统的文献调查，并将现有方法归类为四种主要架构：1. 基于卷积神经网络 (CNN) 的方法；2. 基于模型展开（model-based deep unrolling）的方法；3. 基于隐式表示（implicit representation）的方法；4. 基于 Transformer 和 Mamba 的方法。文章还建立了基础概念，包括数据表示、问题设定、基准数据集和评估指标。

Result: 论文对 LiDAR 超分辨率方法进行了分类和分析，总结了当前的研究趋势，包括：采用范围图像表示以提高处理效率；模型压缩和分辨率灵活的架构；以及实时推理和跨传感器泛化能力的提升。文章还识别了该领域面临的开放性挑战和未来的研究方向。

Conclusion: 该论文对 LiDAR 超分辨率技术进行了首次全面综述，为理解该领域的研究现状、技术趋势和未来发展方向提供了重要参考。研究强调了实时性和跨传感器泛化能力在实际部署中的重要性，并指出了该领域仍需解决的挑战。

Abstract: LiDAR sensors are often considered essential for autonomous driving, but high-resolution sensors remain expensive while affordable low-resolution sensors produce sparse point clouds that miss critical details. LiDAR super-resolution addresses this challenge by using deep learning to enhance sparse point clouds, bridging the gap between different sensor types and enabling cross-sensor compatibility in real-world deployments. This paper presents the first comprehensive survey of LiDAR super-resolution methods for autonomous driving. Despite the importance of practical deployment, no systematic review has been conducted until now. We organize existing approaches into four categories: CNN-based architectures, model-based deep unrolling, implicit representation methods, and Transformer and Mamba-based approaches. We establish fundamental concepts including data representations, problem formulation, benchmark datasets and evaluation metrics. Current trends include the adoption of range image representation for efficient processing, extreme model compression and the development of resolution-flexible architectures. Recent research prioritizes real-time inference and cross-sensor generalization for practical deployment. We conclude by identifying open challenges and future research directions for advancing LiDAR super-resolution technology.

</details>


### [22] [MaS-VQA: A Mask-and-Select Framework for Knowledge-Based Visual Question Answering](https://arxiv.org/abs/2602.15915)
*Xianwei Mao,Kai Ye,Sheng Zhou,Nan Zhang,Haikuan Huang,Bin Li,Jiajun Bu*

Main category: cs.CV

TL;DR: 提出了一种名为 MaS-VQA 的选择驱动框架，通过显式知识过滤和隐式知识推理来解决知识库视觉问答中的知识噪声问题，提高了答案的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的知识库视觉问答模型在整合视觉信息和外部知识时，会面临检索到的知识噪声大、部分不相关或与视觉内容不对齐的问题，而模型内部知识则难以控制和解释。简单地聚合这些信息源会限制推理效果并降低答案准确性。

Method: MaS-VQA 首先检索候选知识片段，然后应用“Mask-and-Select”机制，联合过滤不相关的图像区域和弱相关知识片段，生成紧凑、高信号的多模态知识。接着，利用过滤后的知识指导内部知识在受限的语义空间中激活，从而实现显式和隐式知识的互补协同建模，以进行稳健的答案预测。

Result: 在 Encyclopedic-VQA 和 InfoSeek 数据集上，MaS-VQA 在多种多模态大模型（MLLM）骨干网络上都实现了性能的持续提升。消融实验验证了选择机制能有效减少噪声并增强知识利用率。

Conclusion: MaS-VQA 框架通过结合显式知识过滤和隐式知识推理，能够有效地解决知识库视觉问答中的知识噪声问题，显著提升模型的答案预测能力。

Abstract: Knowledge-based Visual Question Answering (KB-VQA) requires models to answer questions by integrating visual information with external knowledge. However, retrieved knowledge is often noisy, partially irrelevant, or misaligned with the visual content, while internal model knowledge is difficult to control and interpret. Naive aggregation of these sources limits reasoning effectiveness and reduces answer accuracy. To address this, we propose MaS-VQA, a selection-driven framework that tightly couples explicit knowledge filtering with implicit knowledge reasoning. MaS-VQA first retrieves candidate passages and applies a Mask-and-Select mechanism to jointly prune irrelevant image regions and weakly relevant knowledge fragments, producing compact, high-signal multimodal knowledge . This filtered knowledge then guides the activation of internal knowledge in a constrained semantic space, enabling complementary co-modeling of explicit and implicit knowledge for robust answer prediction. Experiments on Encyclopedic-VQA and InfoSeek demonstrate consistent performance gains across multiple MLLM backbones, and ablations verify that the selection mechanism effectively reduces noise and enhances knowledge utilization.

</details>


### [23] [EarthSpatialBench: Benchmarking Spatial Reasoning Capabilities of Multimodal LLMs on Earth Imagery](https://arxiv.org/abs/2602.15918)
*Zelin Xu,Yupu Zhang,Saugat Adhikari,Saiful Islam,Tingsong Xiao,Zibo Liu,Shigang Chen,Da Yan,Zhe Jiang*

Main category: cs.CV

TL;DR: 本文提出了一个名为EarthSpatialBench的全面基准，用于评估多模态大语言模型（MLLMs）在地球图像上的空间推理能力，弥补了现有基准在定量方向、距离推理、系统拓扑关系和复杂几何形状方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有针对地球图像的空间推理基准主要侧重于2D空间定位、图像字幕和粗略的空间关系，缺乏对定量方向和距离推理、系统性拓扑关系以及超越边界框的复杂物体几何形状的支持，而这些对于具身AI和需要精确物理世界交互的代理系统至关重要。

Method: 构建了一个包含超过32.5万个问答对的EarthSpatialBench基准，涵盖了定性/定量距离和方向推理、系统拓扑关系、单对象/对象对/组合聚合组查询，以及通过文本描述、视觉叠加和显式几何坐标（包括2D边界框、折线和多边形）引用的对象。并在开源和专有模型上进行了广泛实验。

Result: 通过在EarthSpatialBench上进行的大量实验，发现了当前MLLMs在处理地球图像空间推理方面存在的局限性。

Conclusion: EarthSpatialBench提供了一个用于评估MLLMs在地球图像空间推理能力的新基准，通过引入更复杂和量化的空间关系任务，揭示了现有模型的不足，为未来研究指明了方向。

Abstract: Benchmarking spatial reasoning in multimodal large language models (MLLMs) has attracted growing interest in computer vision due to its importance for embodied AI and other agentic systems that require precise interaction with the physical world. However, spatial reasoning on Earth imagery has lagged behind, as it uniquely involves grounding objects in georeferenced images and quantitatively reasoning about distances, directions, and topological relations using both visual cues and vector geometry coordinates (e.g., 2D bounding boxes, polylines, and polygons). Existing benchmarks for Earth imagery primarily focus on 2D spatial grounding, image captioning, and coarse spatial relations (e.g., simple directional or proximity cues). They lack support for quantitative direction and distance reasoning, systematic topological relations, and complex object geometries beyond bounding boxes. To fill this gap, we propose \textbf{EarthSpatialBench}, a comprehensive benchmark for evaluating spatial reasoning in MLLMs on Earth imagery. The benchmark contains over 325K question-answer pairs spanning: (1) qualitative and quantitative reasoning about spatial distance and direction; (2) systematic topological relations; (3) single-object queries, object-pair queries, and compositional aggregate group queries; and (4) object references expressed via textual descriptions, visual overlays, and explicit geometry coordinates, including 2D bounding boxes, polylines, and polygons. We conducted extensive experiments on both open-source and proprietary models to identify limitations in the spatial reasoning of MLLMs.

</details>


### [24] [A Study on Real-time Object Detection using Deep Learning](https://arxiv.org/abs/2602.15926)
*Ankita Bose,Jayasravani Bhumireddy,Naveen N*

Main category: cs.CV

TL;DR: 本文对深度学习在实时目标检测领域的应用进行了详细综述，涵盖了不同模型、数据集、实际应用以及未来挑战。


<details>
  <summary>Details</summary>
Motivation: 目标检测在众多领域具有广泛应用，实时目标检测能够实现即时决策，而深度学习算法的进步极大地提升了目标检测的准确性和效率。因此，需要对该领域的现状、方法和未来发展进行梳理和探讨。

Method: 本文通过详细介绍Faster R-CNN, Mask R-CNN, Cascade R-CNN, YOLO, SSD, RetinaNet等不同的深度学习目标检测模型，以及公开的基准数据集，并引用相关研究来阐述目标检测模型的应用。此外，还进行了对照研究以比较不同策略的有效性。

Result: 文章对不同的目标检测模型进行了介绍，并探讨了它们在各类实际应用中的表现。通过对照研究，揭示了不同策略的有效性，并得出了一些有价值的发现。

Conclusion: 深度学习显著增强了实时目标检测的能力，本文全面回顾了现有技术，并为未来的研究方向提出了挑战和建议，包括改进深度学习方法和目标识别技术。

Abstract: Object detection has compelling applications over a range of domains, including human-computer interfaces, security and video surveillance, navigation and road traffic monitoring, transportation systems, industrial automation healthcare, the world of Augmented Reality (AR) and Virtual Reality (VR), environment monitoring and activity identification. Applications of real time object detection in all these areas provide dynamic analysis of the visual information that helps in immediate decision making. Furthermore, advanced deep learning algorithms leverage the progress in the field of object detection providing more accurate and efficient solutions. There are some outstanding deep learning algorithms for object detection which includes, Faster R CNN(Region-based Convolutional Neural Network),Mask R-CNN, Cascade R-CNN, YOLO (You Only Look Once), SSD (Single Shot Multibox Detector), RetinaNet etc. This article goes into great detail on how deep learning algorithms are used to enhance real time object recognition. It provides information on the different object detection models available, open benchmark datasets, and studies on the use of object detection models in a range of applications. Additionally, controlled studies are provided to compare various strategies and produce some illuminating findings. Last but not least, a number of encouraging challenges and approaches are offered as suggestions for further investigation in both relevant deep learning approaches and object recognition.

</details>


### [25] [Visual Memory Injection Attacks for Multi-Turn Conversations](https://arxiv.org/abs/2602.15927)
*Christian Schlarmann,Matthias Hein*

Main category: cs.CV

TL;DR: 本文提出了一种名为“视觉记忆注入”（VMI）的新型攻击方法，能够在多轮对话中操纵生成式大型视觉语言模型（LVLMs）的行为，即使在输入看似正常的情况下也能实现，旨在引起对 LVLMs 安全性的关注。


<details>
  <summary>Details</summary>
Motivation: 当前生成式大型视觉语言模型（LVLMs）在用户增长的同时，其安全性，尤其是在长上下文和多轮对话场景下，尚未得到充分研究。研究者希望探讨在真实场景下，攻击者如何利用操纵过的图像来影响 LVLMs，进而操纵用户。

Method: 提出了一种新颖的“视觉记忆注入”（VMI）攻击方法。该方法通过向 LVLMs 输入被操纵的图像，使得模型在处理正常提示时表现正常，但在遇到特定触发提示时，会输出攻击者预设的目标信息。该攻击方法能在多轮对话中持续有效。

Result: 研究者在多个近期开源的 LVLMs 上成功演示了 VMI 攻击。结果表明，在多轮对话场景下，通过在图像中嵌入扰动，可以有效地实现对用户的操纵，例如用于敌对营销或政治说服。

Conclusion: 大型视觉语言模型（LVLMs）在多轮对话环境中容易受到通过操纵图像进行的潜在大规模用户操纵攻击。研究呼吁提高 LVLMs 对此类攻击的鲁棒性。

Abstract: Generative large vision-language models (LVLMs) have recently achieved impressive performance gains, and their user base is growing rapidly. However, the security of LVLMs, in particular in a long-context multi-turn setting, is largely underexplored. In this paper, we consider the realistic scenario in which an attacker uploads a manipulated image to the web/social media. A benign user downloads this image and uses it as input to the LVLM. Our novel stealthy Visual Memory Injection (VMI) attack is designed such that on normal prompts the LVLM exhibits nominal behavior, but once the user gives a triggering prompt, the LVLM outputs a specific prescribed target message to manipulate the user, e.g. for adversarial marketing or political persuasion. Compared to previous work that focused on single-turn attacks, VMI is effective even after a long multi-turn conversation with the user. We demonstrate our attack on several recent open-weight LVLMs. This article thereby shows that large-scale manipulation of users is feasible with perturbed images in multi-turn conversation settings, calling for better robustness of LVLMs against these attacks. We release the source code at https://github.com/chs20/visual-memory-injection

</details>


### [26] [Can Vision-Language Models See Squares? Text-Recognition Mediates Spatial Reasoning Across Three Model Families](https://arxiv.org/abs/2602.15950)
*Yuval Levental*

Main category: cs.CV

TL;DR: 当前最先进的视觉语言模型（VLMs）在准确识别二进制网格中无文本标识的填充单元格方面存在根本性局限，尤其是在仅使用视觉表示时，其空间定位能力会严重下降。


<details>
  <summary>Details</summary>
Motivation: 研究人员旨在揭示视觉语言模型在处理缺乏文本标识的视觉空间信息时的根本性局限性。

Method: 通过生成十五个不同填充密度的15x15二进制网格，并以两种图像形式（文本符号和填充方块）呈现给三个前沿VLMs（Claude Opus, ChatGPT 5.2, Gemini 3 Thinking），然后比较它们转录的准确性。

Result: 在文本符号条件下，Claude和ChatGPT表现出较高的准确率（约91%）和F1分数（约84%），而Gemini表现稍逊。但在填充方块条件下，所有模型的准确率和F1分数均大幅下降至60-73%和29-39%。文本符号与填充方块之间的F1分数差距显著（34-54个点），表明VLMs依赖于高保真的文本识别通路来执行空间推理，而其原生视觉通路在此方面表现较差。不同模型在填充方块条件下表现出不同的失败模式，但共同的问题是空间定位能力严重退化。

Conclusion: VLMs在处理非文本视觉元素时，其空间定位能力存在严重缺陷。模型表现出一种“以文本为中心”的空间推理偏见，这表明其在整合纯粹视觉信息进行空间理解方面存在根本性不足。

Abstract: We present a simple experiment that exposes a fundamental limitation in vision-language models (VLMs): the inability to accurately localize filled cells in binary grids when those cells lack textual identity. We generate fifteen 15x15 grids with varying density (10.7%-41.8% filled cells) and render each as two image types -- text symbols (. and #) and filled squares without gridlines -- then ask three frontier VLMs (Claude Opus, ChatGPT 5.2, and Gemini 3 Thinking) to transcribe them. In the text-symbol condition, Claude and ChatGPT achieve approximately 91% cell accuracy and 84% F1, while Gemini achieves 84% accuracy and 63% F1. In the filled-squares condition, all three models collapse to 60-73% accuracy and 29-39% F1. Critically, all conditions pass through the same visual encoder -- the text symbols are images, not tokenized text. The text-vs-squares F1 gap ranges from 34 to 54 points across models, demonstrating that VLMs behave as if they possess a high-fidelity text-recognition pathway for spatial reasoning that dramatically outperforms their native visual pathway. Each model exhibits a distinct failure mode in the squares condition -- systematic under-counting (Claude), massive over-counting (ChatGPT), and template hallucination (Gemini) -- but all share the same underlying deficit: severely degraded spatial localization for non-textual visual elements.

</details>


### [27] [Position-Aware Scene-Appearance Disentanglement for Bidirectional Photoacoustic Microscopy Registration](https://arxiv.org/abs/2602.15959)
*Yiwen Wang,Jiahao Qin*

Main category: cs.CV

TL;DR: 提出了一种名为GPEReg-Net的框架，用于解决高帧率光声显微镜双向扫描引入的图像配准问题，该框架通过解耦场景外观和利用时间信息来提高配准精度和时序一致性。


<details>
  <summary>Details</summary>
Motivation: 双向光声显微镜成像速度快，但会导致图像出现领域迁移和几何错位。现有方法注册质量不高，而生成模型缺乏时间感知能力。

Method: 提出GPEReg-Net框架，利用自适应实例归一化（AdaIN）解耦场景特征和外观代码，实现直接图像配准。引入全局位置编码（GPE）模块，结合可学习位置嵌入、正弦编码和跨帧注意力，利用邻近帧信息提高时序一致性。

Result: 在OR-PAM-Reg-4K基准测试中，GPEReg-Net在NCC、SSIM和PSNR方面均优于现有最先进方法，SSIM提升3.8%，PSNR提升1.99dB。

Conclusion: GPEReg-Net是一种有效的场景外观解耦框架，通过利用时间信息，能够显著提高双向光声显微镜图像的配准质量和时序一致性。

Abstract: High-speed optical-resolution photoacoustic microscopy (OR-PAM) with bidirectional raster scanning doubles imaging speed but introduces coupled domain shift and geometric misalignment between forward and backward scan lines. Existing registration methods, constrained by brightness constancy assumptions, achieve limited alignment quality, while recent generative approaches address domain shift through complex architectures that lack temporal awareness across frames. We propose GPEReg-Net, a scene-appearance disentanglement framework that separates domain-invariant scene features from domain-specific appearance codes via Adaptive Instance Normalization (AdaIN), enabling direct image-to-image registration without explicit deformation field estimation. To exploit temporal structure in sequential acquisitions, we introduce a Global Position Encoding (GPE) module that combines learnable position embeddings with sinusoidal encoding and cross-frame attention, allowing the network to leverage context from neighboring frames for improved temporal coherence. On the OR-PAM-Reg-4K benchmark (432 test samples), GPEReg-Net achieves NCC of 0.953, SSIM of 0.932, and PSNR of 34.49dB, surpassing the state-of-the-art by 3.8% in SSIM and 1.99dB in PSNR while maintaining competitive NCC. Code is available at https://github.com/JiahaoQin/GPEReg-Net.

</details>


### [28] [Automated Re-Identification of Holstein-Friesian Cattle in Dense Crowds](https://arxiv.org/abs/2602.15962)
*Phoenix Yu,Tilo Burghardt,Andrew W Dowsey,Neill W Campbell*

Main category: cs.CV

TL;DR: 提出了一种新的“检测-分割-识别”流水线，通过集成开放词汇量无权重定位和分割任意模型，并结合Re-ID网络，有效解决了密集牛群中的个体检测和再识别问题，准确率高达98.93%，显著优于现有方法，并实现了94.82%的Re-ID准确率。


<details>
  <summary>Details</summary>
Motivation: 现有牛只检测和再识别方法在牛群密集聚集时效果不佳，特别是对于花纹容易打破轮廓的品种。研究旨在提高在这种场景下的检测和识别的有效性和可迁移性。

Method: 提出了一种“检测-分割-识别”流水线，将开放词汇量无权重定位（OWLViT）和分割任意模型（SAM）作为预处理阶段，并结合Re-ID网络。

Result: 该方法在密集牛群中的检测准确率达到98.93%，比基于定向边界框和SAM的基线方法分别提高了47.52%和27.13%。无监督对比学习进一步提升了Re-ID准确率至94.82%。

Conclusion: 该研究证明了在实际农场环境中，无需人工干预，密集场景下的牛只再识别是实用且可靠的。代码和数据集已公开以供复现。

Abstract: Holstein-Friesian detection and re-identification (Re-ID) methods capture individuals well when targets are spatially separate. However, existing approaches, including YOLO-based species detection, break down when cows group closely together. This is particularly prevalent for species which have outline-breaking coat patterns. To boost both effectiveness and transferability in this setting, we propose a new detect-segment-identify pipeline that leverages the Open-Vocabulary Weight-free Localisation and the Segment Anything models as pre-processing stages alongside Re-ID networks. To evaluate our approach, we publish a collection of nine days CCTV data filmed on a working dairy farm. Our methodology overcomes detection breakdown in dense animal groupings, resulting in a 98.93% accuracy. This significantly outperforms current oriented bounding box-driven, as well as SAM species detection baselines with accuracy improvements of 47.52% and 27.13%, respectively. We show that unsupervised contrastive learning can build on this to yield 94.82% Re-ID accuracy on our test data. Our work demonstrates that Re-ID in crowded scenarios is both practical as well as reliable in working farm settings with no manual intervention. Code and dataset are provided for reproducibility.

</details>


### [29] [Non-Contact Physiological Monitoring in Pediatric Intensive Care Units via Adaptive Masking and Self-Supervised Learning](https://arxiv.org/abs/2602.15967)
*Mohamed Khalil Ben Salah,Philippe Jouvet,Rita Noumeir*

Main category: cs.CV

TL;DR: 该研究提出了一种基于 VisionMamba 和自监督预训练框架的远程光电容积脉搏波（rPPG）技术，用于在儿科重症监护室（PICU）中进行无接触式心率监测，通过渐进式课程学习和教师-学生蒸馏来克服运动伪影、遮挡和数据稀缺等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的接触式生命体征监测传感器在PICU环境中存在皮肤刺激、感染风险和患者不适等问题。rPPG作为一种无接触式替代方案，尽管存在运动伪影、遮挡、光照变化和域偏移等挑战，但在PICU中的应用仍需改进。

Method: 研究提出了一种基于 VisionMamba 架构的自监督预训练框架，结合渐进式课程学习策略和自适应掩码机制。该框架使用一个轻量级的 Mamba 控制器来分配时空重要性得分，指导概率性斑块采样。同时，采用教师-学生蒸馏设置，利用在公开数据集上训练的监督模型提供指导。课程分为三个阶段：干净的公开视频、合成遮挡场景和来自 500 名儿科患者的无标签视频。

Result: 该框架将平均绝对误差（MAE）降低了 42%，相对标准掩码自编码器（MAE）而言，并比 PhysFormer 提高了 31%，最终 MAE 达到 3.2 bpm。模型在没有显式兴趣区域提取的情况下，能够持续关注富含脉搏的区域，并在临床遮挡和噪声下表现出鲁棒性。

Conclusion: 所提出的自监督预训练框架能够有效地利用 VisionMamba 架构和渐进式课程策略，克服 rPPG 在 PICU 环境中的挑战，实现准确且鲁棒的无接触式心率监测，为临床应用提供了潜力。

Abstract: Continuous monitoring of vital signs in Pediatric Intensive Care Units (PICUs) is essential for early detection of clinical deterioration and effective clinical decision-making. However, contact-based sensors such as pulse oximeters may cause skin irritation, increase infection risk, and lead to patient discomfort. Remote photoplethysmography (rPPG) offers a contactless alternative to monitor heart rate using facial video, but remains underutilized in PICUs due to motion artifacts, occlusions, variable lighting, and domain shifts between laboratory and clinical data.
  We introduce a self-supervised pretraining framework for rPPG estimation in the PICU setting, based on a progressive curriculum strategy. The approach leverages the VisionMamba architecture and integrates an adaptive masking mechanism, where a lightweight Mamba-based controller assigns spatiotemporal importance scores to guide probabilistic patch sampling. This strategy dynamically increases reconstruction difficulty while preserving physiological relevance.
  To address the lack of labeled clinical data, we adopt a teacher-student distillation setup. A supervised expert model, trained on public datasets, provides latent physiological guidance to the student. The curriculum progresses through three stages: clean public videos, synthetic occlusion scenarios, and unlabeled videos from 500 pediatric patients.
  Our framework achieves a 42% reduction in mean absolute error relative to standard masked autoencoders and outperforms PhysFormer by 31%, reaching a final MAE of 3.2 bpm. Without explicit region-of-interest extraction, the model consistently attends to pulse-rich areas and demonstrates robustness under clinical occlusions and noise.

</details>


### [30] [LAND: A Longitudinal Analysis of Neuromorphic Datasets](https://arxiv.org/abs/2602.15973)
*Gregory Cohen,Alexandre Marcireau*

Main category: cs.CV

TL;DR: 该综述分析了现有的神经形态数据集，指出了其规模、标准化和可访问性方面的挑战，并探讨了合成和元数据集的兴起及其影响。


<details>
  <summary>Details</summary>
Motivation: 现有神经形态研究中普遍存在对更多、更大数据的需求，这部分源于深度学习方法所需的数据量，但也受限于现有数据集的可用性、理解和访问的困难。

Method: 通过收集和分析超过423个神经形态数据集，研究了它们的任务性质和数据结构，并探讨了合成数据集（模拟或视频转事件）和元数据集的优点和缺点。

Result: 分析发现，现有神经形态数据集在规模、标准化和数据获取方面存在显著挑战。合成数据集在测试现有算法方面有益，但在探索新应用方面存在局限性。元数据集的出现有望减少对新数据的需求并减少偏差。

Conclusion: 神经形态研究面临数据挑战，现有数据集的可用性和标准化亟待改进。合成数据集和元数据集提供了新的解决方案，有助于缓解数据问题并推动神经形态技术的发展。

Abstract: Neuromorphic engineering has a data problem. Despite the meteoric rise in the number of neuromorphic datasets published over the past ten years, the conclusion of a significant portion of neuromorphic research papers still states that there is a need for yet more data and even larger datasets. Whilst this need is driven in part by the sheer volume of data required by modern deep learning approaches, it is also fuelled by the current state of the available neuromorphic datasets and the difficulties in finding them, understanding their purpose, and determining the nature of their underlying task. This is further compounded by practical difficulties in downloading and using these datasets. This review starts by capturing a snapshot of the existing neuromorphic datasets, covering over 423 datasets, and then explores the nature of their tasks and the underlying structure of the presented data. Analysing these datasets shows the difficulties arising from their size, the lack of standardisation, and difficulties in accessing the actual data. This paper also highlights the growth in the size of individual datasets and the complexities involved in working with the data. However, a more important concern is the rise of synthetic datasets, created by either simulation or video-to-events methods. This review explores the benefits of simulated data for testing existing algorithms and applications, highlighting the potential pitfalls for exploring new applications of neuromorphic technologies. This review also introduces the concepts of meta-datasets, created from existing datasets, as a way of both reducing the need for more data, and to remove potential bias arising from defining both the dataset and the task.

</details>


### [31] [SAM 3D Body: Robust Full-Body Human Mesh Recovery](https://arxiv.org/abs/2602.15989)
*Xitong Yang,Devansh Kukreja,Don Pinkus,Anushka Sagar,Taosha Fan,Jinhyung Park,Soyong Shin,Jinkun Cao,Jiawei Liu,Nicolas Ugrinovic,Matt Feiszli,Jitendra Malik,Piotr Dollar,Kris Kitani*

Main category: cs.CV

TL;DR: 本文提出了一种名为 3DB 的新模型，用于从单张图像恢复全身体网格，该模型性能优越，具有强大的泛化能力，并引入了一种新的参数化网格表示 MHR。


<details>
  <summary>Details</summary>
Motivation: 现有模型在野外条件下性能不稳定，泛化能力不足，作者希望开发一个在各种复杂场景下都能准确恢复全身体网格的模型。

Method: 3DB 采用编码器-解码器架构，并引入了新的参数化网格表示 Momentum Human Rig (MHR)，该表示将骨骼结构与表面形状解耦。模型支持 2D 关键点和掩码等辅助提示，并采用了多阶段标注流程和数据引擎来保证数据质量和多样性。

Result: 3DB 在各种条件下表现出卓越的泛化能力和准确性，在用户偏好研究和传统量化分析中均优于现有方法。

Conclusion: 3DB 是一种高性能的、可提示的全身体网格恢复模型，MHR 是一种创新的网格表示。该模型在复杂场景下具有出色的泛化能力，为该领域的研究提供了新的工具和方法。

Abstract: We introduce SAM 3D Body (3DB), a promptable model for single-image full-body 3D human mesh recovery (HMR) that demonstrates state-of-the-art performance, with strong generalization and consistent accuracy in diverse in-the-wild conditions. 3DB estimates the human pose of the body, feet, and hands. It is the first model to use a new parametric mesh representation, Momentum Human Rig (MHR), which decouples skeletal structure and surface shape. 3DB employs an encoder-decoder architecture and supports auxiliary prompts, including 2D keypoints and masks, enabling user-guided inference similar to the SAM family of models. We derive high-quality annotations from a multi-stage annotation pipeline that uses various combinations of manual keypoint annotation, differentiable optimization, multi-view geometry, and dense keypoint detection. Our data engine efficiently selects and processes data to ensure data diversity, collecting unusual poses and rare imaging conditions. We present a new evaluation dataset organized by pose and appearance categories, enabling nuanced analysis of model behavior. Our experiments demonstrate superior generalization and substantial improvements over prior methods in both qualitative user preference studies and traditional quantitative analysis. Both 3DB and MHR are open-source.

</details>


### [32] [BTReport: A Framework for Brain Tumor Radiology Report Generation with Clinically Relevant Features](https://arxiv.org/abs/2602.16006)
*Juampablo E. Heras Rivera,Dickson T. Chen,Tianyi Ren,Daniel K. Low,Asma Ben Abacha,Alberto Santamaria-Pang,Mehmet Kurt*

Main category: cs.CV

TL;DR: 该研究提出了一个名为BTReport的开源框架，用于生成脑肿瘤放射学报告。该框架通过确定性地提取影像特征，并仅使用大型语言模型进行文本组织，解决了脑肿瘤影像报告生成中缺乏公开数据集和模型幻觉的问题，并生成了与临床报告高度一致的报告，同时还发布了一个包含合成报告的数据集BTReport-BraTS。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤放射学报告生成（RRG）领域由于缺乏公开的影像-报告配对数据集而进展缓慢。现有方法依赖于大型通用或微调的视觉-语言模型，容易产生幻觉，且模型解释性差。

Method: BTReport框架将RRG过程分解为两个主要步骤：1. 确定性特征提取：从影像中提取关键特征。2. 报告生成：使用大型语言模型（LLM）将提取的特征组织成语法正确、叙事连贯的自然语言报告。这种方法将影像分析和报告组合分开，提高了报告的可解释性并减少了幻觉。

Result: 1. BTReport生成的报告完全可解释，并且比现有基线方法更符合参考临床报告。2. 用于报告生成的影像特征能够预测重要的临床结果，如生存期和IDH突变状态。3. 研究发布了BTReport-BraTS数据集，该数据集将BraTS影像与使用BTReport生成的合成报告相结合。

Conclusion: BTReport框架通过结合确定性特征提取和LLM的文本组织能力，成功地解决了脑肿瘤RRG中的挑战，生成了可解释且与临床报告高度一致的报告，并发布了一个新的数据集以促进该领域的研究。

Abstract: Recent advances in radiology report generation (RRG) have been driven by large paired image-text datasets; however, progress in neuro-oncology has been limited due to a lack of open paired image-report datasets. Here, we introduce BTReport, an open-source framework for brain tumor RRG that constructs natural language radiology reports using deterministically extracted imaging features. Unlike existing approaches that rely on large general-purpose or fine-tuned vision-language models for both image interpretation and report composition, BTReport performs deterministic feature extraction for image analysis and uses large language models only for syntactic structuring and narrative formatting. By separating RRG into a deterministic feature extraction step and a report generation step, the generated reports are completely interpretable and less prone to hallucinations. We show that the features used for report generation are predictive of key clinical outcomes, including survival and IDH mutation status, and reports generated by BTReport are more closely aligned with reference clinical reports than existing baselines for RRG. Finally, we introduce BTReport-BraTS, a companion dataset that augments BraTS imaging with synthetically generated radiology reports produced with BTReport. Code for this project can be found at  https://github.com/KurtLabUW/BTReport.

</details>


### [33] [MedProbCLIP: Probabilistic Adaptation of Vision-Language Foundation Model for Reliable Radiograph-Report Retrieval](https://arxiv.org/abs/2602.16019)
*Ahmad Elallaf,Yu Zhang,Yuktha Priya Masupalli,Jeong Yang,Young Lee,Zechun Cao,Gongbo Liang*

Main category: cs.CV

TL;DR: MedProbCLIP 是一个用于胸部 X 光和放射学报告的概率性视觉-语言学习框架，通过建模不确定性来提高表示学习和双向检索的可靠性，在 MIMIC-CXR 数据集上优于现有方法，并展示了更好的校准性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言基础模型在生物医学应用中，尤其是在高风险场景下，由于其确定性嵌入而缺乏可靠性。因此，需要一个能够捕捉不确定性的模型。

Method: MedProbCLIP 将图像和文本表示建模为高斯嵌入，并采用概率性对比目标来捕捉不确定性和一对多对应关系。使用变分信息瓶颈来缓解过于自信的预测。在训练时采用多视图 X 光片编码和多段报告编码，在推理时使用单张 X 光片和单份报告。

Result: MedProbCLIP 在 MIMIC-CXR 数据集上的检索和零样本分类任务中优于 CLIP、CXR-CLIP 和 PCME++ 等确定性和概率性基线。此外，MedProbCLIP 在校准性、风险覆盖行为、选择性检索可靠性和对临床相关噪声的鲁棒性方面表现更优。

Conclusion: 概率性视觉-语言建模对于提高放射影像-文本检索系统的可信度和安全性具有重要价值，MedProbCLIP 的结果证明了其在捕捉不确定性、提高鲁棒性方面的优势。

Abstract: Vision-language foundation models have emerged as powerful general-purpose representation learners with strong potential for multimodal understanding, but their deterministic embeddings often fail to provide the reliability required for high-stakes biomedical applications. This work introduces MedProbCLIP, a probabilistic vision-language learning framework for chest X-ray and radiology report representation learning and bidirectional retrieval. MedProbCLIP models image and text representations as Gaussian embeddings through a probabilistic contrastive objective that explicitly captures uncertainty and many-to-many correspondences between radiographs and clinical narratives. A variational information bottleneck mitigates overconfident predictions, while MedProbCLIP employs multi-view radiograph encoding and multi-section report encoding during training to provide fine-grained supervision for clinically aligned correspondence, yet requires only a single radiograph and a single report at inference. Evaluated on the MIMIC-CXR dataset, MedProbCLIP outperforms deterministic and probabilistic baselines, including CLIP, CXR-CLIP, and PCME++, in both retrieval and zero-shot classification. Beyond accuracy, MedProbCLIP demonstrates superior calibration, risk-coverage behavior, selective retrieval reliability, and robustness to clinically relevant corruptions, underscoring the value of probabilistic vision-language modeling for improving the trustworthiness and safety of radiology image-text retrieval systems.

</details>


### [34] [LGQ: Learning Discretization Geometry for Scalable and Stable Image Tokenization](https://arxiv.org/abs/2602.16086)
*Idil Bilge Altun,Mert Onur Cakiroglu,Elham Buxton,Mehmet Dalkilic,Hasan Kurban*

Main category: cs.CV

TL;DR: 本文提出了一种名为Learnable Geometric Quantization (LGQ) 的离散图像标记方法，通过端到端学习离散化几何结构，解决了现有方法在紧凑性、语义结构保持和离散容量有效利用方面的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的向量量化标记方法在大型词汇量下存在优化偏差、码本利用率低和表示崩溃的问题；而结构化标量或隐式标记方法虽然利用稳定，但固定的离散化几何可能无法有效利用异构潜在统计下的容量。

Method: LGQ通过引入温度控制的软分配来替代硬最近邻查找，实现了完全可微分的训练，并在推理时恢复硬分配。该方法将分配视为各向同性高斯混合模型的后验责任，并最小化变分自由能目标。同时，LGQ结合了标记级别和全局使用正则化器，鼓励自信但均衡的码本利用。

Result: 在ImageNet数据集上，LGQ在VQGAN风格的骨干网络上实现了稳定的优化和均衡的码本利用。在16K码本大小下，LGQ相比FSQ在rFID上提升了11.88%，同时使用的活动码数量减少了49.96%；相比SimVQ，rFID提升了6.06%，有效表示率降低了49.45%，在达到可比保真度的同时显著减少了活动条目。

Conclusion: LGQ作为一种可学习的离散图像标记方法，能够端到端地学习离散化几何，并在保持高保真度的同时，显著提高码本的利用效率和表示的紧凑性，克服了现有方法的局限性。

Abstract: Discrete image tokenization is a key bottleneck for scalable visual generation: a tokenizer must remain compact for efficient latent-space priors while preserving semantic structure and using discrete capacity effectively. Existing quantizers face a trade-off: vector-quantized tokenizers learn flexible geometries but often suffer from biased straight-through optimization, codebook under-utilization, and representation collapse at large vocabularies. Structured scalar or implicit tokenizers ensure stable, near-complete utilization by design, yet rely on fixed discretization geometries that may allocate capacity inefficiently under heterogeneous latent statistics.
  We introduce Learnable Geometric Quantization (LGQ), a discrete image tokenizer that learns discretization geometry end-to-end. LGQ replaces hard nearest-neighbor lookup with temperature-controlled soft assignments, enabling fully differentiable training while recovering hard assignments at inference. The assignments correspond to posterior responsibilities of an isotropic Gaussian mixture and minimize a variational free-energy objective, provably converging to nearest-neighbor quantization in the low-temperature limit. LGQ combines a token-level peakedness regularizer with a global usage regularizer to encourage confident yet balanced code utilization without imposing rigid grids.
  Under a controlled VQGAN-style backbone on ImageNet across multiple vocabulary sizes, LGQ achieves stable optimization and balanced utilization. At 16K codebook size, LGQ improves rFID by 11.88% over FSQ while using 49.96% fewer active codes, and improves rFID by 6.06% over SimVQ with 49.45% lower effective representation rate, achieving comparable fidelity with substantially fewer active entries. Our GitHub repository is available at: https://github.com/KurbanIntelligenceLab/LGQ

</details>


### [35] [OmniCT: Towards a Unified Slice-Volume LVLM for Comprehensive CT Analysis](https://arxiv.org/abs/2602.16110)
*Tianwei Lin,Zhongwei Qiu,Wenqiao Zhang,Jiang Liu,Yihan Xie,Mingjian Gao,Zhenxuan Fan,Zhaocheng Li,Sijing Li,Zhongle Xie,Peng LU,Yueting Zhuang,Yingda Xia,Ling Zhang,Beng Chin Ooi*

Main category: cs.CV

TL;DR: OmniCT是一个统一的CT影像大模型，能够同时理解切片和容积信息，通过空间一致性增强和器官级语义增强，在各种临床任务中表现优于现有方法，并提出了新的医学影像理解范式。


<details>
  <summary>Details</summary>
Motivation: 现有的医学影像大模型在处理CT影像时存在切片理解和容积理解割裂的问题，前者泛化性好但缺乏跨切片空间一致性，后者能捕捉容积语义但粒度粗糙且不兼容切片输入，阻碍了模型在临床上的应用。因此，需要一个能够统一处理切片和容积信息的模型。

Method: 提出OmniCT模型，包含三个主要贡献：1. 空间一致性增强（SCE），通过容积切片组合和三轴位置嵌入引入容积一致性，并使用MoE混合投影实现高效切片-容积适应。2. 器官级语义增强（OSE），通过分割和感兴趣区域（ROI）定位来显式对齐解剖区域，强调病灶和器官级语义。3. MedEval-CT，构建了最大的切片-容积CT数据集和混合基准，集成了全面的评价指标。

Result: OmniCT在各种临床任务上始终显著优于现有方法，能够同时满足微观细节敏感性和宏观空间推理能力。

Conclusion: OmniCT通过统一的切片-容积建模范式，克服了现有模型的局限性，并在CT影像理解方面取得了显著进展，为跨模态医学影像理解树立了新范例。

Abstract: Computed Tomography (CT) is one of the most widely used and diagnostically information-dense imaging modalities, covering critical organs such as the heart, lungs, liver, and colon. Clinical interpretation relies on both slice-driven local features (e.g., sub-centimeter nodules, lesion boundaries) and volume-driven spatial representations (e.g., tumor infiltration, inter-organ anatomical relations). However, existing Large Vision-Language Models (LVLMs) remain fragmented in CT slice versus volumetric understanding: slice-driven LVLMs show strong generalization but lack cross-slice spatial consistency, while volume-driven LVLMs explicitly capture volumetric semantics but suffer from coarse granularity and poor compatibility with slice inputs. The absence of a unified modeling paradigm constitutes a major bottleneck for the clinical translation of medical LVLMs. We present OmniCT, a powerful unified slice-volume LVLM for CT scenarios, which makes three contributions: (i) Spatial Consistency Enhancement (SCE): volumetric slice composition combined with tri-axial positional embedding that introduces volumetric consistency, and an MoE hybrid projection enables efficient slice-volume adaptation; (ii) Organ-level Semantic Enhancement (OSE): segmentation and ROI localization explicitly align anatomical regions, emphasizing lesion- and organ-level semantics; (iii) MedEval-CT: the largest slice-volume CT dataset and hybrid benchmark integrates comprehensive metrics for unified evaluation. OmniCT consistently outperforms existing methods with a substantial margin across diverse clinical tasks and satisfies both micro-level detail sensitivity and macro-level spatial reasoning. More importantly, it establishes a new paradigm for cross-modal medical imaging understanding.

</details>


### [36] [CHAI: CacHe Attention Inference for text2video](https://arxiv.org/abs/2602.16132)
*Joel Mathew Cherian,Ashutosh Muralidhara Bharadwaj,Vima Gupta,Anand Padmanabha Iyer*

Main category: cs.CV

TL;DR: CHAI提出了一种名为Cache Attention的跨推理缓存技术，通过选择性地关注跨推理潜变量中共享的对象/场景，实现了在降低视频生成延迟的同时保持视频质量，速度比基线模型快1.65倍至3.35倍。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频扩散模型虽然效果好，但由于3D潜变量的顺序去噪而速度较慢。现有的加速方法要么需要昂贵的模型再训练，要么采用基于启发式的跳步方法，这在减少去噪步数时难以保持视频质量。

Method: 提出了一种名为Cache Attention的跨推理缓存机制。该机制通过选择性地关注跨推理潜变量中共享的对象/场景，实现了对语义相关提示的缓存潜变量的有效重用，从而提高了缓存命中率。

Result: CHAI能够使用少至8个去噪步数生成高质量视频。与基线OpenSora 1.2相比，CHAI的速度提高了1.65倍至3.35倍，同时保持了视频质量。

Conclusion: CHAI通过Cache Attention技术，成功地在不牺牲视频质量的前提下，显著提高了文本到视频扩散模型的推理速度，为实现高效的视频生成提供了一种新方法。

Abstract: Text-to-video diffusion models deliver impressive results but remain slow because of the sequential denoising of 3D latents. Existing approaches to speed up inference either require expensive model retraining or use heuristic-based step skipping, which struggles to maintain video quality as the number of denoising steps decreases. Our work, CHAI, aims to use cross-inference caching to reduce latency while maintaining video quality. We introduce Cache Attention as an effective method for attending to shared objects/scenes across cross-inference latents. This selective attention mechanism enables effective reuse of cached latents across semantically related prompts, yielding high cache hit rates. We show that it is possible to generate high-quality videos using Cache Attention with as few as 8 denoising steps. When integrated into the overall system, CHAI is 1.65x - 3.35x faster than baseline OpenSora 1.2 while maintaining video quality.

</details>


### [37] [IRIS: Intent Resolution via Inference-time Saccades for Open-Ended VQA in Large Vision-Language Models](https://arxiv.org/abs/2602.16138)
*Parsa Madinei,Srijita Karmakar,Russell Cohen Hoffing,Felix Gervitz,Miguel P. Eckstein*

Main category: cs.CV

TL;DR: 本文提出了一种名为IRIS的新方法，利用实时眼动追踪数据来解决开放式视觉问答（VQA）中的歧义问题，显著提高了大型视觉语言模型（VLMs）在处理歧义问题时的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的开放式VQA模型在处理含糊不清的图像-问题对时表现不佳，需要一种方法来实时解决这种歧义。

Method: IRIS利用眼动追踪数据，重点关注参与者开始提问时最接近的注视点，将其作为最能消除歧义的信息来源。通过用户研究，将这种眼动数据整合到大型VLMs中进行训练。

Result: 在处理歧义性问题时，IRIS将准确率从35.2%提高到77.2%，同时在非歧义性问题上的性能保持不变。该方法在不同架构的VLMs上都显示出一致的改进效果。

Conclusion: 实时眼动追踪数据，特别是提问时的注视点，可以有效用于消除开放式VQA中的歧义，并显著提高VLMs的性能。研究者发布了一个新的基准数据集、实时交互协议和评估套件。

Abstract: We introduce IRIS (Intent Resolution via Inference-time Saccades), a novel training-free approach that uses eye-tracking data in real-time to resolve ambiguity in open-ended VQA. Through a comprehensive user study with 500 unique image-question pairs, we demonstrate that fixations closest to the time participants start verbally asking their questions are the most informative for disambiguation in Large VLMs, more than doubling the accuracy of responses on ambiguous questions (from 35.2% to 77.2%) while maintaining performance on unambiguous queries. We evaluate our approach across state-of-the-art VLMs, showing consistent improvements when gaze data is incorporated in ambiguous image-question pairs, regardless of architectural differences. We release a new benchmark dataset to use eye movement data for disambiguated VQA, a novel real-time interactive protocol, and an evaluation suite.

</details>


### [38] [Evaluating Demographic Misrepresentation in Image-to-Image Portrait Editing](https://arxiv.org/abs/2602.16149)
*Huichan Seo,Minki Hong,Sieun Choi,Jihie Kim,Jean Oh*

Main category: cs.CV

TL;DR: 本研究探讨了在图像到图像（I2I）编辑中，针对不同人口统计学特征（种族、性别、年龄）的指令引导式编辑存在系统性失败模式，表现为编辑效果减弱（软擦除）或引入不期望的刻板印象（刻板印象替换）。研究提出了一个基准测试来评估现有编辑器，并发现存在普遍且不均等的身份保留失败，这受隐性社会先入为主观念的影响。最后，研究提出了一种无需模型更新的提示级身份约束方法，有效减少了少数群体身份的改变，并为构建人口统计学鲁棒的编辑系统提供了方向。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注文本到图像（T2I）生成中的人口统计学偏见，而对指令引导式图像到图像（I2I）编辑中同样存在的人口统计学偏见和相关失败模式的探索不足。研究旨在揭示I2I编辑器在处理不同人口统计学特征时的潜在问题。

Method: 1. 形式化了两种I2I编辑失败模式：软擦除（Soft Erasure）和刻板印象替换（Stereotype Replacement）。 2. 构建了一个受控基准测试，通过生成并编辑以种族、性别和年龄为条件的人像，并使用诊断性提示集。 3. 评估了多个开源I2I编辑器，结合了视觉语言模型（VLM）评分和人工评估。 4. 提出并验证了一种无需模型更新的提示级身份约束方法。

Result: 1. 身份保留失败在I2I编辑中普遍存在，且在不同人口统计学群体间表现不均。 2. 这些失败受到隐性社会先入为主观念的影响，例如基于职业的性别推断。 3. 提示级身份约束方法能显著减少少数群体身份的变化，而对多数群体影响较小。

Conclusion: 身份保留是一个关键且在人口统计学上不均等的人口统计学偏见失败模式，存在于当前的I2I编辑器中。研究结果强调了开发人口统计学鲁棒的I2I编辑系统的必要性，并提出了一种有效且易于实现的约束方法。

Abstract: Demographic bias in text-to-image (T2I) generation is well studied, yet demographic-conditioned failures in instruction-guided image-to-image (I2I) editing remain underexplored. We examine whether identical edit instructions yield systematically different outcomes across subject demographics in open-weight I2I editors. We formalize two failure modes: Soft Erasure, where edits are silently weakened or ignored in the output image, and Stereotype Replacement, where edits introduce unrequested, stereotype-consistent attributes. We introduce a controlled benchmark that probes demographic-conditioned behavior by generating and editing portraits conditioned on race, gender, and age using a diagnostic prompt set, and evaluate multiple editors with vision-language model (VLM) scoring and human evaluation. Our analysis shows that identity preservation failures are pervasive, demographically uneven, and shaped by implicit social priors, including occupation-driven gender inference. Finally, we demonstrate that a prompt-level identity constraint, without model updates, can substantially reduce demographic change for minority groups while leaving majority-group portraits largely unchanged, revealing asymmetric identity priors in current editors. Together, our findings establish identity preservation as a central and demographically uneven failure mode in I2I editing and motivate demographic-robust editing systems. Project page: https://seochan99.github.io/i2i-demographic-bias

</details>


### [39] [Uncertainty-Guided Inference-Time Depth Adaptation for Transformer-Based Visual Tracking](https://arxiv.org/abs/2602.16160)
*Patrick Poggi,Divake Kumar,Theja Tulabandhula,Amit Ranjan Trivedi*

Main category: cs.CV

TL;DR: 提出了一种名为 UncL-STARK 的 Transformer 跟踪器，它通过动态适应推理深度来提高效率，同时保持准确性，在牺牲少量计算资源的情况下实现了显著的能耗和延迟降低。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 Transformer 的单目标跟踪器在处理每个视频帧时都会执行完整的编码器-解码器堆栈，即使帧的视觉复杂度较低，这也导致了不必要的计算成本，尤其是在长视频序列中。

Method: UncL-STARK 是一种架构保留的方法，通过随机深度训练和知识蒸馏，使模型能够在多个中间深度下保持预测鲁棒性。在运行时，模型从热力图估计不确定性，并利用这个估计值通过一个反馈驱动的策略来动态选择下一帧的编码器和解码器深度，从而利用视频的时间连贯性。

Result: 在 GOT-10k 和 LaSOT 数据集上进行了广泛的实验，结果表明 UncL-STARK 能够将 GFLOPs 降低高达 12%，延迟降低 8.9%，能耗节省 10.8%，同时在跟踪精度方面与全深度基线相比仅有 0.2% 的微小下降。

Conclusion: UncL-STARK 能够通过不修改底层网络或添加辅助头部来实现 Transformer 跟踪器的动态、不确定性感知深度适应，从而在效率和准确性之间取得良好的平衡。

Abstract: Transformer-based single-object trackers achieve state-of-the-art accuracy but rely on fixed-depth inference, executing the full encoder--decoder stack for every frame regardless of visual complexity, thereby incurring unnecessary computational cost in long video sequences dominated by temporally coherent frames. We propose UncL-STARK, an architecture-preserving approach that enables dynamic, uncertainty-aware depth adaptation in transformer-based trackers without modifying the underlying network or adding auxiliary heads. The model is fine-tuned to retain predictive robustness at multiple intermediate depths using random-depth training with knowledge distillation, thus enabling safe inference-time truncation. At runtime, we derive a lightweight uncertainty estimate directly from the model's corner localization heatmaps and use it in a feedback-driven policy that selects the encoder and decoder depth for the next frame based on the prediction confidence by exploiting temporal coherence in video. Extensive experiments on GOT-10k and LaSOT demonstrate up to 12\% GFLOPs reduction, 8.9\% latency reduction, and 10.8\% energy savings while maintaining tracking accuracy within 0.2\% of the full-depth baseline across both short-term and long-term sequences.

</details>


### [40] [DataCube: A Video Retrieval Platform via Natural Language Semantic Profiling](https://arxiv.org/abs/2602.16231)
*Yiming Ju,Hanyu Zhao,Quanyue Ma,Donglin Hao,Chengwei Wu,Ming Li,Songjing Wang,Tengfei Pan*

Main category: cs.CV

TL;DR: DataCube是一个智能平台，用于自动处理视频、多维度分析和查询驱动的检索，以克服从原始视频创建特定任务数据集的成本和效率问题。


<details>
  <summary>Details</summary>
Motivation: 创建用于视频理解和生成的高质量、特定任务的数据集，从大型视频存储库中提取是昂贵且低效的。

Method: DataCube 自动处理视频，构建结构化的语义表示，并支持结合神经重新排序和深度语义匹配的混合检索。它提供了一个交互式 Web 界面，允许用户从大型存储库中高效地创建自定义视频子集，并为私有视频集合构建可搜索系统。

Result: 该系统能够高效地处理视频、进行多维度分析并支持查询驱动的检索，从而简化了定制视频数据集的创建和搜索。

Conclusion: DataCube 是一个创新的解决方案，它通过自动化视频处理、多维度分析和先进的检索技术，显着提高了创建和使用视频数据集的效率和灵活性。

Abstract: Large-scale video repositories are increasingly available for modern video understanding and generation tasks. However, transforming raw videos into high-quality, task-specific datasets remains costly and inefficient. We present DataCube, an intelligent platform for automatic video processing, multi-dimensional profiling, and query-driven retrieval. DataCube constructs structured semantic representations of video clips and supports hybrid retrieval with neural re-ranking and deep semantic matching. Through an interactive web interface, users can efficiently construct customized video subsets from massive repositories for training, analysis, and evaluation, and build searchable systems over their own private video collections. The system is publicly accessible at https://datacube.baai.ac.cn/. Demo Video: https://baai-data-cube.ks3-cn-beijing.ksyuncs.com/custom/Adobe%20Express%20-%202%E6%9C%8818%E6%97%A5%20%281%29%281%29%20%281%29.mp4

</details>


### [41] [EasyControlEdge: A Foundation-Model Fine-Tuning for Edge Detection](https://arxiv.org/abs/2602.16238)
*Hiroki Nakamura,Hiroto Iino,Masashi Okada,Tadahiro Taniguchi*

Main category: cs.CV

TL;DR: 提出EasyControlEdge，一种将图像生成基础模型适配于边缘检测的方法，旨在解决真实世界边缘检测中对清晰度和数据效率的要求，尤其是在训练样本有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 真实世界边缘检测（如楼层平面图的墙壁、卫星图像的道路/建筑物、医学图像的器官边界）需要高清晰度和数据效率，但现有方法在训练数据有限时难以生成清晰的原始边缘图。现有图像生成基础模型在数据高效迁移和高频细节保持方面具有潜力，但尚未被充分利用于边缘检测。

Method: 通过一种边缘导向的目标函数和高效的像素空间损失，对图像生成基础模型进行边缘检测的专门化适配。在推理时，引入基于无条件动态的引导机制，允许通过引导尺度控制边缘密度。

Result: 在BSDS500、NYUDv2、BIPED和CubiCasa数据集上的实验表明，EasyControlEdge相比最先进的方法在边缘检测任务上取得了持续的提升，特别是在无需后处理的清晰度评估以及在训练数据有限的情况下。

Conclusion: EasyControlEdge成功地利用了图像生成基础模型的优势，实现了数据高效且高清晰度的边缘检测，并且能够灵活地控制边缘密度。

Abstract: We propose EasyControlEdge, adapting an image-generation foundation model to edge detection. In real-world edge detection (e.g., floor-plan walls, satellite roads/buildings, and medical organ boundaries), crispness and data efficiency are crucial, yet producing crisp raw edge maps with limited training samples remains challenging. Although image-generation foundation models perform well on many downstream tasks, their pretrained priors for data-efficient transfer and iterative refinement for high-frequency detail preservation remain underexploited for edge detection. To enable crisp and data-efficient edge detection using these capabilities, we introduce an edge-specialized adaptation of image-generation foundation models. To better specialize the foundation model for edge detection, we incorporate an edge-oriented objective with an efficient pixel-space loss. At inference, we introduce guidance based on unconditional dynamics, enabling a single model to control the edge density through a guidance scale. Experiments on BSDS500, NYUDv2, BIPED, and CubiCasa compare against state-of-the-art methods and show consistent gains, particularly under no-post-processing crispness evaluation and with limited training data.

</details>


### [42] [HyPCA-Net: Advancing Multimodal Fusion in Medical Image Analysis](https://arxiv.org/abs/2602.16245)
*J. Dhar,M. K. Pandey,D. Chakladar,M. Haghighat,A. Alavi,S. Mistry,N. Zaidi*

Main category: cs.CV

TL;DR: 本文提出了一种名为 HyPCA-Net 的混合并行融合级联注意力网络，用于多模态医学图像融合，以提高计算效率和特征表示能力，从而在多疾病分析任务中取得更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像多模态融合方法存在计算成本高、信息丢失风险以及共享表征捕捉能力受限的问题，限制了其在低资源环境和多疾病分析任务中的应用。

Method: 提出 HyPCA-Net，包含两个核心模块：1) 计算高效的残差自适应学习注意力模块，用于捕获精细的模态特定表示；2) 双视图级联注意力模块，用于学习跨模态的鲁棒共享表示。

Result: 在十个公开数据集上的实验表明，HyPCA-Net 在性能上比现有领先方法提高了高达 5.2%，计算成本降低了高达 73.1%。

Conclusion: HyPCA-Net 是一种高效且有效的多模态医学图像融合框架，能够克服现有方法的局限性，在多疾病分析任务中表现出优越的性能和计算效率。

Abstract: Multimodal fusion frameworks, which integrate diverse medical imaging modalities (e.g., MRI, CT), have shown great potential in applications such as skin cancer detection, dementia diagnosis, and brain tumor prediction. However, existing multimodal fusion methods face significant challenges. First, they often rely on computationally expensive models, limiting their applicability in low-resource environments. Second, they often employ cascaded attention modules, which potentially increase risk of information loss during inter-module transitions and hinder their capacity to effectively capture robust shared representations across modalities. This restricts their generalization in multi-disease analysis tasks. To address these limitations, we propose a Hybrid Parallel-Fusion Cascaded Attention Network (HyPCA-Net), composed of two core novel blocks: (a) a computationally efficient residual adaptive learning attention block for capturing refined modality-specific representations, and (b) a dual-view cascaded attention block aimed at learning robust shared representations across diverse modalities. Extensive experiments on ten publicly available datasets exhibit that HyPCA-Net significantly outperforms existing leading methods, with improvements of up to 5.2% in performance and reductions of up to 73.1% in computational cost. Code: https://github.com/misti1203/HyPCA-Net.

</details>


### [43] [AFFMAE: Scalable and Efficient Vision Pretraining for Desktop Graphics Cards](https://arxiv.org/abs/2602.16249)
*David Smerkous,Zian Wang,Behzad Najafian*

Main category: cs.CV

TL;DR: AFFMAE 是一种新的自监督预训练框架，通过自适应、离网的 token 合并，克服了传统 MAE 在处理高分辨率数据和分层结构时的挑战，显著降低了计算和内存需求，并在电子显微镜分割任务上取得了与 ViT-MAE 相当的性能。


<details>
  <summary>Details</summary>
Motivation: 当前高分辨率自监督预训练模型（如 MAE）需要大规模计算资源，限制了许多研究实验室的开发能力。现有的 MAE 方法与分层架构结合存在结构性挑战，需要改进。

Method: 提出 AFFMAE 框架，采用自适应、离网的 token 合并策略，仅对可见 token 进行合并，从而去除密集网格假设并保留分层可扩展性。开发了数值稳定的混合精度 Flash 集群注意力核，并通过深度监督缓解稀疏阶段的表示坍塌。

Result: 在 vollständige Auflösung Elektronenmikroskopie Segmentation 任务上，AFFMAE 在参数量相同的情况下，FLOPs 降低高达 7 倍，内存使用减半，训练速度更快，性能与 ViT-MAE 相当。

Conclusion: AFFMAE 是一种高效且可扩展的自监督预训练框架，能够有效地处理高分辨率数据，为资源受限的研究实验室提供了开发领域基础模型的新途径。

Abstract: Self-supervised pretraining has transformed computer vision by enabling data-efficient fine-tuning, yet high-resolution training typically requires server-scale infrastructure, limiting in-domain foundation model development for many research laboratories. Masked Autoencoders (MAE) reduce computation by encoding only visible tokens, but combining MAE with hierarchical downsampling architectures remains structurally challenging due to dense grid priors and mask-aware design compromises. We introduce AFFMAE, a masking-friendly hierarchical pretraining framework built on adaptive, off-grid token merging. By discarding masked tokens and performing dynamic merging exclusively over visible tokens, AFFMAE removes dense-grid assumptions while preserving hierarchical scalability. We developed numerically stable mixed-precision Flash-style cluster attention kernels, and mitigate sparse-stage representation collapse via deep supervision. On high-resolution electron microscopy segmentation, AFFMAE matches ViT-MAE performance at equal parameter count while reducing FLOPs by up to 7x, halving memory usage, and achieving faster training on a single RTX 5090. Code available at https://github.com/najafian-lab/affmae.

</details>


### [44] [Breaking the Sub-Millimeter Barrier: Eyeframe Acquisition from Color Images](https://arxiv.org/abs/2602.16281)
*Manel Guzmán,Antonio Agudo*

Main category: cs.CV

TL;DR: 本文提出了一种基于计算机视觉的多视角眼框轨迹追踪方法，用于光学行业，以克服传统机械追踪的效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 传统的眼框轨迹追踪方法依赖机械工具，需要精确的定位和校准，耗时且需要额外设备，效率低下。

Method: 该方法利用InVision系统捕获的多视角图像，通过图像采集、眼框分割、深度估计以及结合RGB图像和深度数据的多视角处理，来实现精确的眼框轮廓测量。

Result: 提出的算法在实际数据上进行了不同配置和变体的分析，结果表明其能提供与现有解决方案相媲美的测量精度，仅使用静态彩色图像。

Conclusion: 该方法通过消除对专用追踪设备的需求，并简化了光学技师的工作流程，提供了一种更高效、更具竞争力的眼框轨迹追踪解决方案。

Abstract: Eyeframe lens tracing is an important process in the optical industry that requires sub-millimeter precision to ensure proper lens fitting and optimal vision correction. Traditional frame tracers rely on mechanical tools that need precise positioning and calibration, which are time-consuming and require additional equipment, creating an inefficient workflow for opticians. This work presents a novel approach based on artificial vision that utilizes multi-view information. The proposed algorithm operates on images captured from an InVision system. The full pipeline includes image acquisition, frame segmentation to isolate the eyeframe from background, depth estimation to obtain 3D spatial information, and multi-view processing that integrates segmented RGB images with depth data for precise frame contour measurement. To this end, different configurations and variants are proposed and analyzed on real data, providing competitive measurements from still color images with respect to other solutions, while eliminating the need for specialized tracing equipment and reducing workflow complexity for optical technicians.

</details>


### [45] [A Self-Supervised Approach for Enhanced Feature Representations in Object Detection Tasks](https://arxiv.org/abs/2602.16322)
*Santiago C. Vilabella,Pablo Pérez-Núñez,Beatriz Remeseiro*

Main category: cs.CV

TL;DR: 通过自监督学习增强特征提取器，可以在较少标注数据的情况下提升目标检测模型的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型日益复杂，标注数据短缺，尤其是目标检测任务需要大量时间和资源进行数据标注，给企业带来高昂成本。

Method: 采用自监督学习策略，训练一个在无标注数据上的模型，以增强特征提取器，使其能够学习更有效的表示。

Result: 所提出的模型在目标检测任务上优于在ImageNet上预训练的最先进特征提取器，并且通过鼓励模型关注对象的关键部分，获得了更好的特征表示。

Conclusion: 增强特征提取器是解决标注数据稀缺问题的有效途径，可以显著提高目标检测模型的性能和鲁棒性，降低对大量标注数据的依赖。

Abstract: In the fast-evolving field of artificial intelligence, where models are increasingly growing in complexity and size, the availability of labeled data for training deep learning models has become a significant challenge. Addressing complex problems like object detection demands considerable time and resources for data labeling to achieve meaningful results. For companies developing such applications, this entails extensive investment in highly skilled personnel or costly outsourcing. This research work aims to demonstrate that enhancing feature extractors can substantially alleviate this challenge, enabling models to learn more effective representations with less labeled data. Utilizing a self-supervised learning strategy, we present a model trained on unlabeled data that outperforms state-of-the-art feature extractors pre-trained on ImageNet and particularly designed for object detection tasks. Moreover, the results demonstrate that our approach encourages the model to focus on the most relevant aspects of an object, thus achieving better feature representations and, therefore, reinforcing its reliability and robustness.

</details>


### [46] [Subtractive Modulative Network with Learnable Periodic Activations](https://arxiv.org/abs/2602.16337)
*Tiou Wang,Zhuoqian Yang,Markus Flierl,Mathieu Salzmann,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 提出了一种名为SMN（Subtractive Modulative Network）的新型参数高效隐式神经表示（INR）架构，它借鉴了经典减法合成的原理，通过可学习的周期激活层生成多频基，并利用调制掩码模块生成高阶谐波，在图像重建和新视角合成任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了开发一种参数高效且在信号处理上具有原则性的隐式神经表示（INR）架构，并且能够实现高质量的图像重建和新视角合成。

Method: 提出了一种名为Subtractive Modulative Network（SMN）的新型INR架构。SMN包含一个可学习的周期激活层（Oscillator），用于生成多频基；以及一系列调制掩码模块（Filters），用于生成高阶谐波。该架构被设计为一个信号处理流水线。

Result: SMN在两个图像数据集上实现了40+ dB的PSNR，在重建精度和参数效率方面优于现有最先进方法。在具有挑战性的3D NeRF新视角合成任务中也观察到了持续的优势。

Conclusion: SMN是一种新颖的、参数高效的INR架构，其信号处理流水线设计使其能够有效捕捉信号的复杂性，并在图像重建和新视角合成任务中取得了优异的性能。

Abstract: We propose the Subtractive Modulative Network (SMN), a novel, parameter-efficient Implicit Neural Representation (INR) architecture inspired by classical subtractive synthesis. The SMN is designed as a principled signal processing pipeline, featuring a learnable periodic activation layer (Oscillator) that generates a multi-frequency basis, and a series of modulative mask modules (Filters) that actively generate high-order harmonics. We provide both theoretical analysis and empirical validation for our design. Our SMN achieves a PSNR of $40+$ dB on two image datasets, comparing favorably against state-of-the-art methods in terms of both reconstruction accuracy and parameter efficiency. Furthermore, consistent advantage is observed on the challenging 3D NeRF novel view synthesis task. Supplementary materials are available at https://inrainbws.github.io/smn/.

</details>


### [47] [SCAR: Satellite Imagery-Based Calibration for Aerial Recordings](https://arxiv.org/abs/2602.16349)
*Henry Hölzemann,Michael Schleiss*

Main category: cs.CV

TL;DR: 提出了一种名为SCAR的方法，利用地理参考的卫星图像作为全局参考，对航空视觉惯性系统进行长期自动校准优化。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于专门的校准机动或手动控制点，在长期野外部署条件下，校准会退化。研究动机是开发一种无需手动干预即可实现准确、鲁棒和可重复校准的自动化方法。

Method: SCAR通过将航空图像与来自公开可用的正射影像和高程模型的2D-3D对应关系对齐，来估计内参和外参。利用外部地理空间数据来检测和纠正校准退化。

Result: 在六个为期两年的大规模航空活动中进行的评估显示，SCAR在减少重投影误差、降低视觉定位旋转误差和提高姿态精度方面，始终优于现有基线方法（Kalibr, COLMAP, VINS-Mono）。

Conclusion: SCAR能够为长期航空作业提供准确、鲁棒且可重复的校准，且无需手动干预，有效解决了现有方法的局限性。

Abstract: We introduce SCAR, a method for long-term auto-calibration refinement of aerial visual-inertial systems that exploits georeferenced satellite imagery as a persistent global reference. SCAR estimates both intrinsic and extrinsic parameters by aligning aerial images with 2D--3D correspondences derived from publicly available orthophotos and elevation models. In contrast to existing approaches that rely on dedicated calibration maneuvers or manually surveyed ground control points, our method leverages external geospatial data to detect and correct calibration degradation under field deployment conditions. We evaluate our approach on six large-scale aerial campaigns conducted over two years under diverse seasonal and environmental conditions. Across all sequences, SCAR consistently outperforms established baselines (Kalibr, COLMAP, VINS-Mono), reducing median reprojection error by a large margin, and translating these calibration gains into substantially lower visual localization rotation errors and higher pose accuracy. These results demonstrate that SCAR provides accurate, robust, and reproducible calibration over long-term aerial operations without the need for manual intervention.

</details>


### [48] [Designing Production-Scale OCR for India: Multilingual and Domain-Specific Systems](https://arxiv.org/abs/2602.16430)
*Ali Faraz,Raja Kolla,Ashish Kulkarni,Shubham Agarwal*

Main category: cs.CV

TL;DR: 本文研究了两种训练策略，用于构建多语言视觉语言模型OCR系统，并在印度语境下进行了评估。结果表明，微调现有OCR模型比端到端训练的策略在准确率-延迟权衡方面表现更好，并在多语言OCR和政府文件结构化信息提取方面取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 设计适用于印度语言多样性、文档异构性和部署限制的多语言OCR系统。

Method: 研究了两种训练策略：1) 结合通用的视觉编码器和多语言语言模型进行端到端OCR训练；2) 微调一个现有的OCR模型（未针对目标语言训练）。在多语言印度OCR基准和面向部署的指标上进行了评估。还介绍了Parichay模型系列，用于提取9种印度政府文件的结构化关键字段。

Result: 微调现有OCR模型的策略在准确率-延迟权衡方面表现更优。Chitrapathak-2比前代产品速度快3-6倍，在泰卢固语上达到SOTA（6.69 char ANLS），在其他语言上也表现出色。Parichay在9种印度政府文件上实现了89.8%的精确匹配率，并且推理速度更快。

Conclusion: 在印度语境下，微调现有OCR模型是构建多语言OCR系统的有效策略，能够实现SOTA性能并为生产规模的OCR管道提供实际指导。

Abstract: Designing Optical Character Recognition (OCR) systems for India requires balancing linguistic diversity, document heterogeneity, and deployment constraints. In this paper, we study two training strategies for building multilingual OCR systems with Vision-Language Models through the Chitrapathak series. We first follow a popular multimodal approach, pairing a generic vision encoder with a strong multilingual language model and training the system end-to-end for OCR. Alternatively, we explore fine-tuning an existing OCR model, despite not being trained for the target languages. Through extensive evaluation on multilingual Indic OCR benchmarks and deployment-oriented metrics, we find that the second strategy consistently achieves better accuracy-latency trade-offs. Chitrapathak-2 achieves 3-6x speedup over its predecessor with being state-of-the-art (SOTA) in Telugu (6.69 char ANLS) and second best in the rest. In addition, we present Parichay, an independent OCR model series designed specifically for 9 Indian government documents to extract structured key fields, achieving 89.8% Exact Match score with a faster inference. Together, these systems achieve SOTA performance and provide practical guidance for building production-scale OCR pipelines in the Indian context.

</details>


### [49] [Parameter-Free Adaptive Multi-Scale Channel-Spatial Attention Aggregation framework for 3D Indoor Semantic Scene Completion Toward Assisting Visually Impaired](https://arxiv.org/abs/2602.16385)
*Qi He,XiangXiang Wang,Jingtao Zhang,Yongbin Yu,Hongxiang Chu,Manping Fan,JingYe Cai,Zhenglin Yang*

Main category: cs.CV

TL;DR: 提出了一种名为AMAA（自适应多尺度注意力聚合）的框架，用于增强单目3D语义场景补全（SSC）的性能，特别是在室内辅助感知领域，旨在提高对视觉障碍用户的安全性。AMAA通过对体素特征的可靠性进行建模和规范化跨尺度信息传播，解决了现有方法中的投影扩散和特征纠缠问题。


<details>
  <summary>Details</summary>
Motivation: 现有单目SSC方法在室内辅助感知中存在不足，容易出现投影扩散和特征纠缠，影响结构稳定性，从而限制了其在对安全性要求高的场景下的应用。这促使研究者们开发一种更可靠、更稳定的单目SSC方法。

Method: 该研究提出了AMAA框架，它建立在MonoScene管道之上。AMAA通过并行通道-空间注意力聚合来校准体素特征的语义和空间维度，并采用分层自适应特征门控策略来稳定多尺度编码器-解码器融合，从而规范化跨尺度的信息注入。

Result: 在NYUv2基准测试中，AMAA在SSC mIoU上取得了27.25%（+0.31）的提升，在SC IoU上取得了43.10%（+0.59）的提升，同时没有显著增加系统复杂性。此外，AMAA框架在NVIDIA Jetson平台上进行了部署验证，证明其可以在嵌入式硬件上稳定运行。

Conclusion: AMAA框架成功提高了单目SSC的质量，并为面向视觉障碍用户的室内辅助系统提供了一个可靠且可部署的感知框架。

Abstract: In indoor assistive perception for visually impaired users, 3D Semantic Scene Completion (SSC) is expected to provide structurally coherent and semantically consistent occupancy under strictly monocular vision for safety-critical scene understanding. However, existing monocular SSC approaches often lack explicit modeling of voxel-feature reliability and regulated cross-scale information propagation during 2D-3D projection and multi-scale fusion, making them vulnerable to projection diffusion and feature entanglement and thus limiting structural stability.To address these challenges, this paper presents an Adaptive Multi-scale Attention Aggregation (AMAA) framework built upon the MonoScene pipeline. Rather than introducing a heavier backbone, AMAA focuses on reliability-oriented feature regulation within a monocular SSC framework. Specifically, lifted voxel features are jointly calibrated in semantic and spatial dimensions through parallel channel-spatial attention aggregation, while multi-scale encoder-decoder fusion is stabilized via a hierarchical adaptive feature-gating strategy that regulates information injection across scales.Experiments on the NYUv2 benchmark demonstrate consistent improvements over MonoScene without significantly increasing system complexity: AMAA achieves 27.25% SSC mIoU (+0.31) and 43.10% SC IoU (+0.59). In addition, system-level deployment on an NVIDIA Jetson platform verifies that the complete AMAA framework can be executed stably on embedded hardware. Overall, AMAA improves monocular SSC quality and provides a reliable and deployable perception framework for indoor assistive systems targeting visually impaired users.

</details>


### [50] [ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding](https://arxiv.org/abs/2602.16412)
*Daichi Yashima,Shuhei Kurita,Yusuke Oda,Komei Sugiura*

Main category: cs.CV

TL;DR: ReMoRa 是一种视频多模态大语言模型（MLLM），通过直接处理视频的压缩表示来解决长视频理解的挑战，并取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 长形式视频理解对于多模态大语言模型（MLLM）来说仍然是一个重大挑战，因为处理完整的 RGB 帧序列在计算上是不可行的，并且由于自注意力机制与序列长度的二次方复杂度而导致冗余。

Method: ReMoRa 模型通过直接操作视频的压缩表示来处理视频。它保留了稀疏的 RGB 关键帧用于外观信息，并将时间动态编码为运动表示，从而无需对整个 RGB 帧序列进行解码。这些运动表示作为光流的紧凑代理。为了改进块状运动的噪声和低保真度，模型引入了一个模块来去噪并生成细粒度的运动表示。此外，该模型以与序列长度线性相关的速度压缩这些特征。

Result: ReMoRa 在包括 LongVideoBench、NExT-QA 和 MLVU 在内的多个具有挑战性的长视频理解基准测试中，其性能优于基线方法。

Conclusion: ReMoRa 通过创新地处理视频的压缩表示（外观和时间动态），有效地解决了长视频理解的计算挑战，并在多项基准测试中取得了领先的性能。

Abstract: While multimodal large language models (MLLMs) have shown remarkable success across a wide range of tasks, long-form video understanding remains a significant challenge. In this study, we focus on video understanding by MLLMs. This task is challenging because processing a full stream of RGB frames is computationally intractable and highly redundant, as self-attention have quadratic complexity with sequence length. In this paper, we propose ReMoRa, a video MLLM that processes videos by operating directly on their compressed representations. A sparse set of RGB keyframes is retained for appearance, while temporal dynamics are encoded as a motion representation, removing the need for sequential RGB frames. These motion representations act as a compact proxy for optical flow, capturing temporal dynamics without full frame decoding. To refine the noise and low fidelity of block-based motions, we introduce a module to denoise and generate a fine-grained motion representation. Furthermore, our model compresses these features in a way that scales linearly with sequence length. We demonstrate the effectiveness of ReMoRa through extensive experiments across a comprehensive suite of long-video understanding benchmarks. ReMoRa outperformed baseline methods on multiple challenging benchmarks, including LongVideoBench, NExT-QA, and MLVU.

</details>


### [51] [Visual Self-Refine: A Pixel-Guided Paradigm for Accurate Chart Parsing](https://arxiv.org/abs/2602.16455)
*Jinsong Li,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Dahua Lin*

Main category: cs.CV

TL;DR: 提出了一种名为Visual Self-Refine (VSR)的新范式，通过生成像素级定位、可视化这些定位并将其反馈给模型进行自我纠正，以提高LVLMs在图表解析等视觉感知任务中的准确性。该范式已在ChartVSR模型中实现，并构建了ChartP-Bench基准。VSR可作为一种通用的视觉反馈机制，有望提升多种视觉任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LVLMs在视觉感知任务（如图表解析）上表现不佳，容易出现数据遗漏、错位和幻觉等问题，尽管它们在文本推理和自我纠正方面表现出色。受人类阅读复杂图表时使用手指作为“视觉锚”的启发，研究旨在提高LVLMs在视觉密集型任务中的准确性。

Method: 提出Visual Self-Refine (VSR)范式，该范式使模型能够生成像素级定位输出，可视化这些输出，并将可视化结果反馈给模型进行自我检查和纠正。具体实现为ChartVSR模型，该模型将图表解析过程分为两个阶段：1. Refine Stage：迭代使用视觉反馈来确保所有数据点的像素级定位准确性；2. Decode Stage：使用经过验证的定位作为精确视觉锚来解析结构化数据。同时构建了ChartP-Bench基准。

Result: VSR范式通过ChartVSR模型在图表解析任务中取得了改进，通过迭代的视觉反馈机制提高了定位准确性。ChartP-Bench基准的构建为评估图表解析任务提供了新的挑战。

Conclusion: VSR是一种有前景的视觉自我纠正范式，通过像素级定位和视觉反馈，有效解决了LVLMs在图表解析等视觉感知任务中的局限性。该范式有望成为一种通用的视觉反馈机制，提升多种视觉中心任务的性能。

Abstract: While Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities for reasoning and self-correction at the textual level, these strengths provide minimal benefits for complex tasks centered on visual perception, such as Chart Parsing. Existing models often struggle with visually dense charts, leading to errors like data omission, misalignment, and hallucination. Inspired by the human strategy of using a finger as a ``visual anchor'' to ensure accuracy when reading complex charts, we propose a new paradigm named Visual Self-Refine (VSR). The core idea of VSR is to enable a model to generate pixel-level localization outputs, visualize them, and then feed these visualizations back to itself, allowing it to intuitively inspect and correct its own potential visual perception errors. We instantiate the VSR paradigm in the domain of Chart Parsing by proposing ChartVSR. This model decomposes the parsing process into two stages: a Refine Stage, where it iteratively uses visual feedback to ensure the accuracy of all data points' Pixel-level Localizations, and a Decode Stage, where it uses these verified localizations as precise visual anchors to parse the final structured data. To address the limitations of existing benchmarks, we also construct ChartP-Bench, a new and highly challenging benchmark for chart parsing. Our work also highlights VSR as a general-purpose visual feedback mechanism, offering a promising new direction for enhancing accuracy on a wide range of vision-centric tasks.

</details>


### [52] [Benchmarking Adversarial Robustness and Adversarial Training Strategies for Object Detection](https://arxiv.org/abs/2602.16494)
*Alexis Winter,Jean-Vincent Martini,Romaric Audigier,Angelique Loesch,Bertrand Luvison*

Main category: cs.CV

TL;DR: 本文提出了一个统一的基准框架来公平地比较目标检测模型的对抗攻击方法，发现现有攻击对 Transformer 架构的迁移性较差，并提出了一种结合多种扰动类型的高扰动攻击的混合数据集作为最有效的对抗训练策略。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测模型的对抗攻击防御研究缺乏标准化评估，难以公平比较攻击和防御方法，导致防御进展滞后。

Method: 提出了一个统一的基准框架，专注于数字、非补丁攻击，引入了区分定位和分类误差的指标，并使用多种感知指标评估扰动成本。在此基础上，对多种先进攻击和目标检测器进行了广泛实验，并研究了不同对抗训练策略。

Result: 发现现代对抗攻击对 Transformer 架构的迁移性显著不足。研究表明，最有效的对抗训练策略是使用包含高扰动、不同目标（空间和语义）攻击的混合数据集进行训练，其鲁棒性优于仅使用单一攻击训练的方法。

Conclusion: 目标检测模型的对抗攻击评估需要标准化的基准。Transformer 架构在对抗攻击方面表现出更高的鲁棒性。通过混合不同类型的高扰动攻击进行对抗训练，可以获得最有效的防御策略。

Abstract: Object detection models are critical components of automated systems, such as autonomous vehicles and perception-based robots, but their sensitivity to adversarial attacks poses a serious security risk. Progress in defending these models lags behind classification, hindered by a lack of standardized evaluation. It is nearly impossible to thoroughly compare attack or defense methods, as existing work uses different datasets, inconsistent efficiency metrics, and varied measures of perturbation cost. This paper addresses this gap by investigating three key questions: (1) How can we create a fair benchmark to impartially compare attacks? (2) How well do modern attacks transfer across different architectures, especially from Convolutional Neural Networks to Vision Transformers? (3) What is the most effective adversarial training strategy for robust defense? To answer these, we first propose a unified benchmark framework focused on digital, non-patch-based attacks. This framework introduces specific metrics to disentangle localization and classification errors and evaluates attack cost using multiple perceptual metrics. Using this benchmark, we conduct extensive experiments on state-of-the-art attacks and a wide range of detectors. Our findings reveal two major conclusions: first, modern adversarial attacks against object detection models show a significant lack of transferability to transformer-based architectures. Second, we demonstrate that the most robust adversarial training strategy leverages a dataset composed of a mix of high-perturbation attacks with different objectives (e.g., spatial and semantic), which outperforms training on any single attack.

</details>


### [53] [MMA: Multimodal Memory Agent](https://arxiv.org/abs/2602.16493)
*Yihao Lu,Wanru Cheng,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: 提出了一种名为MMA（Multimodal Memory Agent）的多模态记忆代理，通过为检索到的记忆项动态分配可靠性分数来解决现有代理因检索到不可靠或冲突信息而产生的过拟合错误。同时，提出了MMA-Bench基准测试以评估信念动态。实验表明，MMA在多项任务上性能优越，能有效减少错误并提高准确性，尤其是在处理文本-视觉矛盾时。


<details>
  <summary>Details</summary>
Motivation: 现有基于相似性检索的长时域多模态代理容易检索到过时、低可信度或冲突的记忆项，导致代理产生过拟合错误。因此，需要一种能够动态评估记忆项可靠性并据此调整代理行为的机制。

Method: 提出了MMA（Multimodal Memory Agent），为每个检索到的记忆项分配动态可靠性分数，该分数结合了来源可信度、时间衰减和冲突感知网络共识。代理使用此分数重新加权证据，并在支持不足时选择弃权。同时，创建了MMA-Bench基准测试，用于生成具有可控发言人可靠性和结构化文本-视觉矛盾的信念动态。

Result: 在FEVER数据集上，MMA的准确率与基线持平，但方差降低了35.2%，选择性效用有所提高。在LoCoMo数据集上，MMA的安全配置提高了可操作准确率并减少了错误答案。在MMA-Bench基准测试中，MMA在Vision模式下达到了41.18%的Type-B准确率，而基线在该协议下准确率降至0.0%。发现了“视觉安慰剂效应”，揭示了RAG代理会继承基础模型的潜在视觉偏见。

Conclusion: MMA是一种有效的多模态记忆代理，通过动态可靠性评分机制，能够解决传统检索方法带来的问题，提高代理在面对不可靠或冲突信息时的鲁棒性和准确性。MMA-Bench为评估信念动态提供了新的平台，并揭示了基础模型中存在的视觉偏见问题。

Abstract: Long-horizon multimodal agents depend on external memory; however, similarity-based retrieval often surfaces stale, low-credibility, or conflicting items, which can trigger overconfident errors. We propose Multimodal Memory Agent (MMA), which assigns each retrieved memory item a dynamic reliability score by combining source credibility, temporal decay, and conflict-aware network consensus, and uses this signal to reweight evidence and abstain when support is insufficient. We also introduce MMA-Bench, a programmatically generated benchmark for belief dynamics with controlled speaker reliability and structured text-vision contradictions. Using this framework, we uncover the "Visual Placebo Effect", revealing how RAG-based agents inherit latent visual biases from foundation models. On FEVER, MMA matches baseline accuracy while reducing variance by 35.2% and improving selective utility; on LoCoMo, a safety-oriented configuration improves actionable accuracy and reduces wrong answers; on MMA-Bench, MMA reaches 41.18% Type-B accuracy in Vision mode, while the baseline collapses to 0.0% under the same protocol. Code: https://github.com/AIGeeksGroup/MMA.

</details>


### [54] [DressWild: Feed-Forward Pose-Agnostic Garment Sewing Pattern Generation from In-the-Wild Images](https://arxiv.org/abs/2602.16502)
*Zeng Tao,Ying Jiang,Yunuo Chen,Tianyi Xie,Huamin Wang,Yingnian Wu,Yin Yang,Abishek Sampath Kumar,Kenji Tashiro,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: DressWild 提出了一种新颖的前馈方法，可以从单张野外图像中重建物理一致的 2D 缝纫图案和相应的 3D 服装，用于服装建模和制造。


<details>
  <summary>Details</summary>
Motivation: 现有的前馈方法在处理不同姿势和视角时存在困难，而基于优化的方法计算成本高且难以扩展。作者旨在为需要可编辑、可分离和可模拟服装的服装建模和制造应用提供一种更有效、可扩展的解决方案。

Method: DressWild 利用视觉语言模型（VLMs）对图像进行姿势归一化，提取姿势感知、3D 感知服装特征。然后，这些特征通过基于 Transformer 的编码器进行融合，用于预测缝纫图案参数，这些参数可直接用于物理模拟、纹理合成和多层虚拟试穿。

Result: DressWild 能够从野外图像中鲁棒地恢复出多样化的缝纫图案和相应的 3D 服装，而无需多视角输入或迭代优化。

Conclusion: DressWild 提供了一种高效且可扩展的解决方案，可用于逼真的服装模拟和动画，能够从单张野外图像生成物理一致的 2D 缝纫图案和 3D 服装。

Abstract: Recent advances in garment pattern generation have shown promising progress. However, existing feed-forward methods struggle with diverse poses and viewpoints, while optimization-based approaches are computationally expensive and difficult to scale. This paper focuses on sewing pattern generation for garment modeling and fabrication applications that demand editable, separable, and simulation-ready garments. We propose DressWild, a novel feed-forward pipeline that reconstructs physics-consistent 2D sewing patterns and the corresponding 3D garments from a single in-the-wild image. Given an input image, our method leverages vision-language models (VLMs) to normalize pose variations at the image level, then extract pose-aware, 3D-informed garment features. These features are fused through a transformer-based encoder and subsequently used to predict sewing pattern parameters, which can be directly applied to physical simulation, texture synthesis, and multi-layer virtual try-on. Extensive experiments demonstrate that our approach robustly recovers diverse sewing patterns and the corresponding 3D garments from in-the-wild images without requiring multi-view inputs or iterative optimization, offering an efficient and scalable solution for realistic garment simulation and animation.

</details>


### [55] [Let's Split Up: Zero-Shot Classifier Edits for Fine-Grained Video Understanding](https://arxiv.org/abs/2602.16545)
*Kaiting Liu,Hazel Doughty*

Main category: cs.CV

TL;DR: 提出了一种名为“类别拆分”的新任务，旨在无需额外标注数据的情况下，将视频分类器中粗粒度的类别细化为更精细的子类别，同时保持其他类别的准确性。该方法利用了视频分类器的潜在组合结构，并通过零样本编辑实现，低样本微调也在此基础上得到了提升。


<details>
  <summary>Details</summary>
Motivation: 现有的视频识别模型通常使用过于粗粒度的固定分类体系，无法区分细微的对象、方式或结果。随着任务和定义的演变，重新标注和训练成本高昂。

Method: 提出了一种零样本编辑方法，该方法利用视频分类器的潜在组合结构来暴露细粒度的区分。此外，还展示了低样本微调的有效性，并表明其受益于零样本初始化。

Result: 在新的视频类别拆分基准测试中，所提出的方法显著优于现有的视觉-语言基线，提高了新拆分类别的准确性，同时未牺牲其他类别的性能。

Conclusion: 类别拆分是一种有效的方法，可以无需额外数据的情况下细化视频分类器的类别，并且可以与现有的微调技术结合使用以获得更好的性能。

Abstract: Video recognition models are typically trained on fixed taxonomies which are often too coarse, collapsing distinctions in object, manner or outcome under a single label. As tasks and definitions evolve, such models cannot accommodate emerging distinctions and collecting new annotations and retraining to accommodate such changes is costly. To address these challenges, we introduce category splitting, a new task where an existing classifier is edited to refine a coarse category into finer subcategories, while preserving accuracy elsewhere. We propose a zero-shot editing method that leverages the latent compositional structure of video classifiers to expose fine-grained distinctions without additional data. We further show that low-shot fine-tuning, while simple, is highly effective and benefits from our zero-shot initialization. Experiments on our new video benchmarks for category splitting demonstrate that our method substantially outperforms vision-language baselines, improving accuracy on the newly split categories without sacrificing performance on the rest. Project page: https://kaitingliu.github.io/Category-Splitting/.

</details>


### [56] [A Contrastive Learning Framework Empowered by Attention-based Feature Adaptation for Street-View Image Classification](https://arxiv.org/abs/2602.16590)
*Qi You,Yitai Cheng,Zichao Zeng,James Haworth*

Main category: cs.CV

TL;DR: 提出了一种名为CLIP-MHAdapter的轻量级CLIP模型适配方法，通过引入多头自注意力机制来增强局部区域特征的建模能力，在街景属性分类任务上取得了优于现有方法的新SOTA结果，同时保持了低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的街景图像属性分类方法计算成本高，并且基于CLIP的适配方法主要依赖全局图像嵌入，难以捕捉街景中精细、局部的属性信息。因此，需要一种既能有效捕捉局部属性，又计算成本低的模型。

Method: 提出CLIP-MHAdapter，一种CLIP的轻量级适配方法。该方法在CLIP模型中附加了一个包含多头自注意力机制的瓶颈MLP，该机制作用于patch tokens，用于建模patch之间的依赖关系，从而更好地捕捉局部属性。

Result: CLIP-MHAdapter在Global StreetScapes数据集的八个属性分类任务上取得了优于或媲美现有方法的准确率，并达到了新的SOTA水平，同时保持了约140万的可训练参数和较低的计算成本。

Conclusion: CLIP-MHAdapter是一种有效且高效的街景图像属性分类方法，通过引入多头自注意力机制增强了模型对局部特征的建模能力，克服了现有方法的局限性，并在多个任务上取得了SOTA性能。

Abstract: Street-view image attribute classification is a vital downstream task of image classification, enabling applications such as autonomous driving, urban analytics, and high-definition map construction. It remains computationally demanding whether training from scratch, initialising from pre-trained weights, or fine-tuning large models. Although pre-trained vision-language models such as CLIP offer rich image representations, existing adaptation or fine-tuning methods often rely on their global image embeddings, limiting their ability to capture fine-grained, localised attributes essential in complex, cluttered street scenes. To address this, we propose CLIP-MHAdapter, a variant of the current lightweight CLIP adaptation paradigm that appends a bottleneck MLP equipped with multi-head self-attention operating on patch tokens to model inter-patch dependencies. With approximately 1.4 million trainable parameters, CLIP-MHAdapter achieves superior or competitive accuracy across eight attribute classification tasks on the Global StreetScapes dataset, attaining new state-of-the-art results while maintaining low computational cost. The code is available at https://github.com/SpaceTimeLab/CLIP-MHAdapter.

</details>


### [57] [Arc2Morph: Identity-Preserving Facial Morphing with Arc2Face](https://arxiv.org/abs/2602.16569)
*Nicolò Di Domenico,Annalisa Franco,Matteo Ferrara,Davide Maltoni*

Main category: cs.CV

TL;DR: 本文提出了一种基于Arc2Face的创新面部变形技术，该技术能够生成逼真的面部图像，并将其应用于电子身份识别系统中的面部变形攻击检测。实验表明，该方法在检测数据集上的表现与传统的最具挑战性的基于地标的技术相当。


<details>
  <summary>Details</summary>
Motivation: 电子身份识别系统面临严峻的面部变形攻击威胁，尤其是在缺乏监督的护照采集过程中。研究旨在开发一种新的、更具挑战性的面部变形技术，以评估和改进面部变形攻击检测方法的鲁棒性。

Method: 利用Arc2Face（一种身份条件化的面部基础模型）生成逼真的面部图像，从而实现一种新的面部变形技术。通过在两个大型面部变形攻击检测数据集和两个新数据集（FEI和ONOT）上评估变形攻击潜力（MAP）来验证该方法的有效性，并与现有技术进行比较。

Result: 所提出的基于深度学习的面部变形方法在面部变形攻击检测数据集上实现了与传统上被认为最具挑战性的基于地标的技术相当的变形攻击潜力。这表明该方法在变形生成过程中有效地保留和管理了身份信息。

Conclusion: 所提出的基于Arc2Face的面部变形技术能够生成高质量的面部变形图像，对现有面部变形攻击检测方法构成了新的挑战。该方法在保留身份信息方面表现出色，为开发更强大的面部识别安全系统提供了新的思路。

Abstract: Face morphing attacks are widely recognized as one of the most challenging threats to face recognition systems used in electronic identity documents. These attacks exploit a critical vulnerability in passport enrollment procedures adopted by many countries, where the facial image is often acquired without a supervised live capture process. In this paper, we propose a novel face morphing technique based on Arc2Face, an identity-conditioned face foundation model capable of synthesizing photorealistic facial images from compact identity representations. We demonstrate the effectiveness of the proposed approach by comparing the morphing attack potential metric on two large-scale sequestered face morphing attack detection datasets against several state-of-the-art morphing methods, as well as on two novel morphed face datasets derived from FEI and ONOT. Experimental results show that the proposed deep learning-based approach achieves a morphing attack potential comparable to that of landmark-based techniques, which have traditionally been regarded as the most challenging. These findings confirm the ability of the proposed method to effectively preserve and manage identity information during the morph generation process.

</details>


### [58] [Unpaired Image-to-Image Translation via a Self-Supervised Semantic Bridge](https://arxiv.org/abs/2602.16664)
*Jiaming Liu,Felix Petersen,Yunhe Gao,Yabin Zhang,Hyojin Kim,Akshay S. Chaudhari,Yu Sun,Stefano Ermon,Sergios Gatidis*

Main category: cs.CV

TL;DR: 提出一种名为Self-Supervised Semantic Bridge (SSB) 的框架，该框架利用自监督视觉编码器和外部语义先验，通过条件化扩散桥模型，实现无需跨域监督的空间保真图像翻译，并在医学图像合成和文本引导编辑方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的无配对图像到图像翻译方法（如对抗性和扩散-逆扩散）存在局限性：对抗性方法泛化能力受限，而扩散-逆扩散方法保真度较低。因此，需要一种新的方法来提高翻译的保真度和泛化能力，尤其是在医学图像等领域。

Method: 提出Self-Supervised Semantic Bridge (SSB) 框架。核心思想是利用自监督视觉编码器学习对外观变化不变但能捕捉几何结构的表示，构建共享的潜在空间，并用该空间来条件化扩散桥模型。该方法整合了外部语义先验，实现了空间保真的翻译，且无需跨域监督。

Result: SSB框架在医学图像合成方面，无论是在域内还是域外设置下，都优于现有的强大方法。此外，该框架易于扩展到高质量的文本引导编辑任务。

Conclusion: SSB框架是一种通用的解决方案，通过整合自监督语义表示和外部语义先验，克服了现有方法的局限性，实现了空间保真的图像翻译，并在医学图像合成和文本引导编辑等任务中展现出优越的性能。

Abstract: Adversarial diffusion and diffusion-inversion methods have advanced unpaired image-to-image translation, but each faces key limitations. Adversarial approaches require target-domain adversarial loss during training, which can limit generalization to unseen data, while diffusion-inversion methods often produce low-fidelity translations due to imperfect inversion into noise-latent representations. In this work, we propose the Self-Supervised Semantic Bridge (SSB), a versatile framework that integrates external semantic priors into diffusion bridge models to enable spatially faithful translation without cross-domain supervision. Our key idea is to leverage self-supervised visual encoders to learn representations that are invariant to appearance changes but capture geometric structure, forming a shared latent space that conditions the diffusion bridges. Extensive experiments show that SSB outperforms strong prior methods for challenging medical image synthesis in both in-domain and out-of-domain settings, and extends easily to high-quality text-guided editing.

</details>


### [59] [PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction](https://arxiv.org/abs/2602.16669)
*Bo Lang,Nirav Savaliya,Zhihao Zheng,Jinglun Feng,Zheng-Hang Yeh,Mooi Choo Chuah*

Main category: cs.CV

TL;DR: 提出一种新的端到端框架，用于一致的在线高清矢量地图构建，通过语义感知查询生成、历史栅格化地图记忆和短期未来引导来提高地图构建的时间一致性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有基于查询的方法在初始化和时间建模方面存在不足，导致地图构建时出现时间不一致和不稳定。

Method: 提出一个包含语义感知查询生成器、历史栅格化地图记忆和短期未来引导模块的端到端框架，该框架联合进行地图实例跟踪和短期预测，以生成一致的在线高清矢量地图。

Result: 在nuScenes和Argoverse2数据集上的实验表明，该方法在效率和性能上优于现有最先进方法。

Conclusion: 该框架通过引入语义信息、显式的历史先验和短期运动预测，成功实现了更稳定、更一致的高清矢量地图在线构建。

Abstract: High-definition (HD) maps are crucial to autonomous driving, providing structured representations of road elements to support navigation and planning. However, existing query-based methods often employ random query initialization and depend on implicit temporal modeling, which lead to temporal inconsistencies and instabilities during the construction of a global map. To overcome these challenges, we introduce a novel end-to-end framework for consistent online HD vectorized map construction, which jointly performs map instance tracking and short-term prediction. First, we propose a Semantic-Aware Query Generator that initializes queries with spatially aligned semantic masks to capture scene-level context globally. Next, we design a History Rasterized Map Memory to store fine-grained instance-level maps for each tracked instance, enabling explicit historical priors. A History-Map Guidance Module then integrates rasterized map information into track queries, improving temporal continuity. Finally, we propose a Short-Term Future Guidance module to forecast the immediate motion of map instances based on the stored history trajectories. These predicted future locations serve as hints for tracked instances to further avoid implausible predictions and keep temporal consistency. Extensive experiments on the nuScenes and Argoverse2 datasets demonstrate that our proposed method outperforms state-of-the-art (SOTA) methods with good efficiency.

</details>


### [60] [VETime: Vision Enhanced Zero-Shot Time Series Anomaly Detection](https://arxiv.org/abs/2602.16681)
*Yingyuan Yang,Tian Lan,Yifei Gao,Yimeng Lu,Wenjun He,Meng Wang,Chenghao Liu,Chen Zhang*

Main category: cs.CV

TL;DR: 本文提出VETime，一个统一时序和视觉模态的时间序列异常检测框架，通过细粒度的视觉-时序对齐和动态融合，解决了现有模型在点异常和上下文异常检测上的权衡问题，并在零样本场景下取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测模型（TSAD）在检测即时点异常和长程上下文异常时存在固有权衡：一维时序模型能精确定位点异常但缺乏全局视角；二维视觉模型能捕捉全局模式但存在信息瓶颈，难以进行时序对齐和精细化点异常检测。为了解决这一困境，需要一个能够融合两种模态优势的TSAD框架。

Method: VETime框架通过引入“可逆图像转换”和“块级时序对齐”模块，建立共享的视觉-时序时间线，以保留区分性细节并维持时序敏感性。此外，设计了“异常窗口对比学习”机制和“任务自适应多模态融合”来适应性地整合两种模态的互补感知优势。

Result: 在零样本场景下，VETime相比于现有的最先进模型取得了显著的性能提升，在异常定位精度上表现更优，并且计算开销低于现有的基于视觉的方法。

Conclusion: VETime是首个统一时序和视觉模态的时间序列异常检测框架，通过细粒度的视觉-时序对齐和动态融合，有效解决了现有方法的局限性，并在多种评估指标上展现出优越的性能，同时具有较低的计算成本。

Abstract: Time-series anomaly detection (TSAD) requires identifying both immediate Point Anomalies and long-range Context Anomalies. However, existing foundation models face a fundamental trade-off: 1D temporal models provide fine-grained pointwise localization but lack a global contextual perspective, while 2D vision-based models capture global patterns but suffer from information bottlenecks due to a lack of temporal alignment and coarse-grained pointwise detection. To resolve this dilemma, we propose VETime, the first TSAD framework that unifies temporal and visual modalities through fine-grained visual-temporal alignment and dynamic fusion. VETime introduces a Reversible Image Conversion and a Patch-Level Temporal Alignment module to establish a shared visual-temporal timeline, preserving discriminative details while maintaining temporal sensitivity. Furthermore, we design an Anomaly Window Contrastive Learning mechanism and a Task-Adaptive Multi-Modal Fusion to adaptively integrate the complementary perceptual strengths of both modalities. Extensive experiments demonstrate that VETime significantly outperforms state-of-the-art models in zero-shot scenarios, achieving superior localization precision with lower computational overhead than current vision-based approaches. Code available at: https://github.com/yyyangcoder/VETime.

</details>


### [61] [Are Object-Centric Representations Better At Compositional Generalization?](https://arxiv.org/abs/2602.16689)
*Ferdinand Kapl,Amir Mohammad Karimi Mamaghan,Maximilian Seitzer,Karl Henrik Johansson,Carsten Marr,Stefan Bauer,Andrea Dittadi*

Main category: cs.CV

TL;DR: 研究引入了三个视觉问答基准，以评估面向对象的（OC）表征在处理新颖组合概念方面的能力，并发现OC表征在更具挑战性的组合泛化场景下表现更优，同时样本效率更高。


<details>
  <summary>Details</summary>
Motivation: 组合泛化是人类认知的基础，也是机器学习的挑战。尽管面向对象的表征被认为有助于此，但在视觉丰富的场景下缺乏系统性证据。

Method: 构建了CLEVRTex、Super-CLEVR和MOVi-C三个受控视觉世界的视觉问答基准，使用DINOv2和SigLIP2作为基础模型及其面向对象的变体，并通过控制训练数据多样性、样本量、表示大小、下游模型容量和计算量来确保公平比较。

Result: 1. OC方法在更难的组合泛化设置中表现更优；2. 原始密集表征仅在更容易的设置中优于OC，且需要更多的下游计算；3. OC模型样本效率更高，用更少的图像就能达到更强的泛化能力。

Conclusion: 面向对象的表征在数据集大小、训练数据多样性或下游计算量受限的任何情况下，都能提供更强的组合泛化能力。

Abstract: Compositional generalization, the ability to reason about novel combinations of familiar concepts, is fundamental to human cognition and a critical challenge for machine learning. Object-centric (OC) representations, which encode a scene as a set of objects, are often argued to support such generalization, but systematic evidence in visually rich settings is limited. We introduce a Visual Question Answering benchmark across three controlled visual worlds (CLEVRTex, Super-CLEVR, and MOVi-C) to measure how well vision encoders, with and without object-centric biases, generalize to unseen combinations of object properties. To ensure a fair and comprehensive comparison, we carefully account for training data diversity, sample size, representation size, downstream model capacity, and compute. We use DINOv2 and SigLIP2, two widely used vision encoders, as the foundation models and their OC counterparts. Our key findings reveal that (1) OC approaches are superior in harder compositional generalization settings; (2) original dense representations surpass OC only on easier settings and typically require substantially more downstream compute; and (3) OC models are more sample efficient, achieving stronger generalization with fewer images, whereas dense encoders catch up or surpass them only with sufficient data and diversity. Overall, object-centric representations offer stronger compositional generalization when any one of dataset size, training data diversity, or downstream compute is constrained.

</details>


### [62] [Learning Situated Awareness in the Real World](https://arxiv.org/abs/2602.16682)
*Chuhan Li,Ruilin Han,Joy Hsu,Yongyuan Liang,Rajiv Dhawan,Jiajun Wu,Ming-Hsuan Yang,Xin Eric Wang*

Main category: cs.CV

TL;DR: 本文提出了SAW-Bench，一个评估多模态基础模型（MFMs）在真实世界视频中以自我为中心的空间感知能力的新基准，并发现现有模型在理解与观察者视角、姿态和运动相关的任务上与人类存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数量化多模态基础模型（MFMs）的基准侧重于环境中心的空间关系，而忽略了需要根据代理的视角、姿态和运动进行推理的观察者中心关系。这导致了对人类感知核心方面——情境感知（situated awareness）——的评估不足。

Method: 提出了SAW-Bench（Situated Awareness in the Real World）基准，包含786个使用Ray-Ban Meta（Gen 2）智能眼镜在真实世界录制的视频，覆盖多样化的室内外环境。数据集包含超过2,071个人工标注的问答对，并设计了六种不同的感知任务来评估模型的观察者中心理解能力。

Result: 对包括Gemini 3 Flash在内的最佳MFM进行了评估，发现人类与模型之间存在37.66%的性能差距。进一步分析表明，尽管模型能利用第一人称视角视频中的部分几何线索，但它们通常无法推断出连贯的相机几何，导致系统性的空间推理错误。

Conclusion: SAW-Bench作为一个评估情境空间智能的基准，旨在推动MFMs从被动观察转向理解物理基础的、以观察者为中心 DYNAMICS。研究强调了在评估MFMs时，需要更加关注观察者中心的空间推理能力，并指出了当前模型在该领域的局限性。

Abstract: A core aspect of human perception is situated awareness, the ability to relate ourselves to the surrounding physical environment and reason over possible actions in context. However, most existing benchmarks for multimodal foundation models (MFMs) emphasize environment-centric spatial relations (relations among objects in a scene), while largely overlooking observer-centric relationships that require reasoning relative to agent's viewpoint, pose, and motion. To bridge this gap, we introduce SAW-Bench (Situated Awareness in the Real World), a novel benchmark for evaluating egocentric situated awareness using real-world videos. SAW-Bench comprises 786 self-recorded videos captured with Ray-Ban Meta (Gen 2) smart glasses spanning diverse indoor and outdoor environments, and over 2,071 human-annotated question-answer pairs. It probes a model's observer-centric understanding with six different awareness tasks. Our comprehensive evaluation reveals a human-model performance gap of 37.66%, even with the best-performing MFM, Gemini 3 Flash. Beyond this gap, our in-depth analysis uncovers several notable findings; for example, while models can exploit partial geometric cues in egocentric videos, they often fail to infer a coherent camera geometry, leading to systematic spatial reasoning errors. We position SAW-Bench as a benchmark for situated spatial intelligence, moving beyond passive observation to understanding physically grounded, observer-centric dynamics.

</details>


### [63] [Saliency-Aware Multi-Route Thinking: Revisiting Vision-Language Reasoning](https://arxiv.org/abs/2602.16702)
*Mingjia Shi,Yinhan He,Yaochen Zhu,Jundong Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为“Saliency-Aware Principle” (SAP) 的推理框架，用于增强视觉语言模型（VLMs）的推理能力，通过高层推理原则而非token级别来稳定控制生成过程，并支持多路径推理，从而减少物体幻觉、提高推理稳定性并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在推理时，视觉信息输入一次且早期视觉接地错误易累积，导致推理过程过度依赖文本，难以进行长文本的细粒度视觉推理。此外，对视觉接地的粗糙指导也阻碍了推理的有效性。

Method: 提出Saliency-Aware Principle (SAP) 选择机制。SAP在高层推理原则上操作，而非token级别，允许模型在需要时重新审视视觉证据。SAP还支持多路径推理，以探索不同的推理行为。SAP模型无关且无需训练。

Result: SAP在相同的token生成预算下，在减少物体幻觉方面表现出竞争力，并且比CoT风格的长序列推理具有更稳定的推理和更低的响应延迟。

Conclusion: SAP提供了一种有效且无需训练的机制，可以提高视觉语言模型的长文本推理能力，解决视觉信息输入和早期接地错误累积的问题，并在物体幻觉、推理稳定性和响应延迟方面取得了显著的改进。

Abstract: Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. While allocating additional inference-time computation has proven effective for large language models (LLMs), achieving similar scaling in VLMs remains challenging. A key obstacle is that visual inputs are typically provided only once at the start of generation, while textual reasoning (e.g., early visual summaries) is generated autoregressively, causing reasoning to become increasingly text-dominated and allowing early visual grounding errors to accumulate. Moreover, vanilla guidance for visual grounding during inference is often coarse and noisy, making it difficult to steer reasoning over long texts. To address these challenges, we propose \emph{Saliency-Aware Principle} (SAP) selection. SAP operates on high-level reasoning principles rather than token-level trajectories, which enable stable control over discrete generation under noisy feedback while allowing later reasoning steps to re-consult visual evidence when renewed grounding is required. In addition, SAP supports multi-route inference, enabling parallel exploration of diverse reasoning behaviors. SAP is model-agnostic and data-free, requiring no additional training. Empirical results show that SAP achieves competitive performance, especially in reducing object hallucination, under comparable token-generation budgets while yielding more stable reasoning and lower response latency than CoT-style long sequential reasoning.

</details>


### [64] [TeCoNeRV: Leveraging Temporal Coherence for Compressible Neural Representations for Videos](https://arxiv.org/abs/2602.16711)
*Namitha Padmanabhan,Matthew Gwilliam,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: TeCoNeRV 是一种基于超网络的方法，通过空间和时间分解、残差存储以及时间相干性正则化，提高了基于隐式神经表示（INR）的视频压缩的质量、效率和可扩展性，特别是在高分辨率下。它在 UVG 数据集上实现了显著的 PSNR 提升和比特率降低，同时提高了编码速度，并且首次在 1080p 分辨率下实现了超网络的视频压缩。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 INR 的视频压缩方法需要为每个视频单独训练，难以扩展到高分辨率视频并保持编码效率。基于超网络的方法虽然速度快，但在高分辨率下存在质量低、压缩尺寸大和内存需求高的问题。

Method: TeCoNeRV 提出了一种创新的三部分方法：1. 空间和时间分解：将短视频段分解为“patch tubelets”，将权重预测任务分解，大幅降低预训练内存开销。2. 残差存储：仅存储连续段表示之间的差异，显著减小比特流尺寸。3. 时间相干性正则化：鼓励权重空间的变化与视频内容相关联。

Result: 在 UVG 数据集上，TeCoNeRV 在 480p 和 720p 分辨率下分别实现了 2.47dB 和 5.35dB 的 PSNR 提升，比特率降低了 36%，编码速度提高了 1.5-3 倍。与现有方法相比，TeCoNeRV 在内存使用方面表现出色，首次在 UVG、HEVC 和 MCL-JCV 数据集的 480p、720p 和 1080p 分辨率下实现了超网络方法的应用。

Conclusion: TeCoNeRV 成功解决了现有基于超网络 INR 视频压缩方法的局限性，通过新颖的技术在提高压缩质量、降低比特率、加速编码和降低内存需求方面取得了显著进展，并且成功扩展到高分辨率视频压缩。

Abstract: Implicit Neural Representations (INRs) have recently demonstrated impressive performance for video compression. However, since a separate INR must be overfit for each video, scaling to high-resolution videos while maintaining encoding efficiency remains a significant challenge. Hypernetwork-based approaches predict INR weights (hyponetworks) for unseen videos at high speeds, but with low quality, large compressed size, and prohibitive memory needs at higher resolutions. We address these fundamental limitations through three key contributions: (1) an approach that decomposes the weight prediction task spatially and temporally, by breaking short video segments into patch tubelets, to reduce the pretraining memory overhead by 20$\times$; (2) a residual-based storage scheme that captures only differences between consecutive segment representations, significantly reducing bitstream size; and (3) a temporal coherence regularization framework that encourages changes in the weight space to be correlated with video content. Our proposed method, TeCoNeRV, achieves substantial improvements of 2.47dB and 5.35dB PSNR over the baseline at 480p and 720p on UVG, with 36% lower bitrates and 1.5-3$\times$ faster encoding speeds. With our low memory usage, we are the first hypernetwork approach to demonstrate results at 480p, 720p and 1080p on UVG, HEVC and MCL-JCV. Our project page is available at https://namithap10.github.io/teconerv/ .

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [65] [The Perplexity Paradox: Why Code Compresses Better Than Math in LLM Prompts](https://arxiv.org/abs/2602.15843)
*Warren Johnson*

Main category: cs.CL

TL;DR: 本研究通过在更多代码和推理基准上验证提示压缩对代码生成和链式思考推理的影响，首次进行了逐词困惑度分析，发现了“困惑度悖论”，并提出了自适应压缩算法TAAC，显著提高了压缩效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 先前的研究（Johnson, 2026）虽然发现代码生成能容忍高比例的提示压缩，但存在局限性：仅限于HumanEval数据集，未验证“困惑度悖论”机制，且未提供自适应算法。本研究旨在解决这些不足，拓展研究范围，深入理解压缩机制，并开发更有效的压缩方法。

Method: 1. 验证：在六个代码基准（HumanEval, MBPP, HumanEval+, MultiPL-E）和四个推理基准（GSM8K, MATH, ARC-Challenge, MMLU-STEM）上评估提示压缩。 2. 困惑度分析：对723个词元进行逐词困惑度分析，以识别“困惑度悖论”。 3. 签名注入：通过注入签名来恢复性能。 4. TAAC算法：提出任务感知自适应压缩算法。

Result: 1. 压缩阈值在不同语言和难度的基准上均能泛化。 2. 发现了“困惑度悖论”：代码语法词元（高困惑度）被保留，而数学问题中的关键数值（低困惑度）却被修剪。 3. 签名注入将通过率提高了34个百分点（从5.3%提升至39.3%）。 4. TAAC算法在保持96%质量的同时，成本降低了22%，比固定比例压缩效果好7%。MBPP验证显示，当r=0.3时通过率为3.6%，r=1.0时为54.6%。

Conclusion: 提示压缩策略对代码生成和链式思考推理有显著影响，存在“困惑度悖论”现象。通过签名注入和任务感知自适应压缩（TAAC）算法，可以在有效降低成本的同时，显著提升模型在各项基准上的性能。

Abstract: In "Compress or Route?" (Johnson, 2026), we found that code generation tolerates aggressive prompt compression (r >= 0.6) while chain-of-thought reasoning degrades gradually. That study was limited to HumanEval (164 problems), left the "perplexity paradox" mechanism unvalidated, and provided no adaptive algorithm. This paper addresses all three gaps. First, we validate across six code benchmarks (HumanEval, MBPP, HumanEval+, MultiPL-E) and four reasoning benchmarks (GSM8K, MATH, ARC-Challenge, MMLU-STEM), confirming the compression threshold generalizes across languages and difficulties. Second, we conduct the first per-token perplexity analysis (n=723 tokens), revealing a "perplexity paradox": code syntax tokens are preserved (high perplexity) while numerical values in math problems are pruned despite being task-critical (low perplexity). Signature injection recovers +34 percentage points in pass rate (5.3% to 39.3%; Cohen's h=0.890). Third, we propose TAAC (Task-Aware Adaptive Compression), achieving 22% cost reduction with 96% quality preservation, outperforming fixed-ratio compression by 7%. MBPP validation (n=1,800 trials) confirms systematic variation: 3.6% at r=0.3 to 54.6% at r=1.0.

</details>


### [66] [Language Model Representations for Efficient Few-Shot Tabular Classification](https://arxiv.org/abs/2602.15844)
*Inwon Kang,Parikshit Ram,Yi Zhou,Horst Samulowitz,Oshani Seneviratne*

Main category: cs.CL

TL;DR: 本文提出了一种名为 TaRL 的轻量级方法，利用现有的大语言模型（LLMs）对网页表格数据进行少样本分类，并通过去除共同分量和校准 softmax 温度等技术，在低数据量情况下取得了与最先进模型相媲美的性能。


<details>
  <summary>Details</summary>
Motivation: 网页表格数据结构和语义的异质性使得难以统一处理，而大语言模型（LLMs）已被广泛应用于网络基础设施中。研究动机在于探索如何利用已部署的 LLMs 来进行表格分类，避免训练专门模型或进行大规模重训练。

Method: 提出 TaRL 方法，直接利用表格行数的语义嵌入进行少样本表格分类。具体技术包括：1. 去除所有嵌入的共同分量；2. 校准 softmax 温度；3. 使用一个简单的元学习器，基于手工特征预测合适的温度。

Result: 直接应用嵌入性能不如专用表格模型。通过上述两种关键技术，TaRL 方法在少样本（k ≤ 32）的语义丰富表格分类任务上，达到了与现有最先进模型相当的性能。

Conclusion: 本研究证明了重用现有 LLM 基础设施来高效理解网页表格数据的可行性，为语义驱动的网页表格理解提供了一条有效途径。

Abstract: The Web is a rich source of structured data in the form of tables, from product catalogs and knowledge bases to scientific datasets. However, the heterogeneity of the structure and semantics of these tables makes it challenging to build a unified method that can effectively leverage the information they contain. Meanwhile, Large language models (LLMs) are becoming an increasingly integral component of web infrastructure for tasks like semantic search. This raises a crucial question: can we leverage these already-deployed LLMs to classify structured data in web-native tables (e.g., product catalogs, knowledge base exports, scientific data portals), avoiding the need for specialized models or extensive retraining? This work investigates a lightweight paradigm, $\textbf{Ta}$ble $\textbf{R}$epresentation with $\textbf{L}$anguage Model~($\textbf{TaRL}$), for few-shot tabular classification that directly utilizes semantic embeddings of individual table rows. We first show that naive application of these embeddings underperforms compared to specialized tabular models. We then demonstrate that their potentials can be unlocked with two key techniques: removing the common component from all embeddings and calibrating the softmax temperature. We show that a simple meta-learner, trained on handcrafted features, can learn to predict an appropriate temperature. This approach achieves performance comparable to state-of-the-art models in low-data regimes ($k \leq 32$) of semantically-rich tables. Our findings demonstrate the viability of reusing existing LLM infrastructure for efficient semantics-driven pathway to reuse existing LLM infrastructure for Web table understanding.

</details>


### [67] [KD4MT: A Survey of Knowledge Distillation for Machine Translation](https://arxiv.org/abs/2602.15845)
*Ona de Gibert,Joseph Attieh,Timothee Mickus,Yves Scherrer,Jörg Tiedemann*

Main category: cs.CL

TL;DR: 本文对机器翻译中的知识蒸馏（KD4MT）进行了全面的调查，涵盖了105篇论文，总结了方法、应用、趋势和挑战，并提供了实践指南和对大型语言模型（LLMs）影响的讨论。


<details>
  <summary>Details</summary>
Motivation: 尽管知识蒸馏在NLP领域作为模型压缩工具受到广泛关注，但机器翻译（MT）中的知识蒸馏（KD）在塑造监督、翻译质量和效率方面提供了更细致的视角，因此需要对其进行系统性总结和分析。

Method: 该研究系统地调查了105篇关于机器翻译知识蒸馏（KD4MT）的论文，从方法论贡献和实际应用两个维度对研究进展进行了分类，并进行了定性和定量分析，同时收集了相关方法和术语信息，构建了一个公开数据库。

Result: 研究发现，KD4MT领域存在一些共同趋势，但缺乏统一的评估实践。此外，KD在MT中的应用可能带来幻觉增加和偏见放大的风险。研究还为具体应用场景下的KD方法选择提供了指导。

Conclusion: 本文对KD4MT领域进行了全面的梳理，指出了当前的研究现状、关键挑战以及大型语言模型（LLMs）可能带来的变革，并为未来的研究提供了宝贵的资源和见解。

Abstract: Knowledge Distillation (KD) as a research area has gained a lot of traction in recent years as a compression tool to address challenges related to ever-larger models in NLP. Remarkably, Machine Translation (MT) offers a much more nuanced take on this narrative: in MT, KD also functions as a general-purpose knowledge transfer mechanism that shapes supervision and translation quality as well as efficiency.
  This survey synthesizes KD for MT (KD4MT) across 105 papers (through October 1, 2025). We begin by introducing both MT and KD for non-experts, followed by an overview of the standard KD approaches relevant to MT applications. Subsequently, we categorize advances in the KD4MT literature based on (i) their methodological contributions and (ii) their practical applications. Our qualitative and quantitative analyses identify common trends in the field and highlight key research gaps as well as the absence of unified evaluation practice for KD methods in MT. We further provide practical guidelines for selecting a KD method in concrete settings and highlight potential risks associated with the application of KD to MT such as increased hallucination and bias amplification. Finally, we discuss the role of LLMs in re-shaping the KD4MT field. To support further research, we complement our survey with a publicly available database summarizing the main characteristics of the surveyed KD methods and a glossary of key terms.

</details>


### [68] [Gated Tree Cross-attention for Checkpoint-Compatible Syntax Injection in Decoder-Only LLMs](https://arxiv.org/abs/2602.15846)
*Xinyu Gao,Shaonan Wang,Nai Ding*

Main category: cs.CL

TL;DR: 本文提出了一种名为门控树交叉注意力（GTCA）的检查点兼容分支，用于增强仅解码器的大语言模型（LLMs）的语法鲁棒性，同时不损害其预训练能力。


<details>
  <summary>Details</summary>
Motivation: 现有的仅解码器LLMs在通用任务上表现出色，但在面对轻微的语法扰动时表现脆弱，这影响了它们在下游推理任务中的可靠性。直接修改现有LLM的检查点以注入显式语法结构可能会干扰其预训练能力。

Method: 作者引入了一个检查点兼容的门控树交叉注意力（GTCA）分支，该分支读取预先计算的构成块内存，同时保持主干架构不变。该设计使用令牌更新掩码和分阶段训练来控制结构更新的范围和时机。

Result: 在多个基准测试和Transformer主干上，GTCA在语法鲁棒性方面优于继续训练的基线模型，并且不损害多项选择问答（Multiple-Choice QA）和常识推理的性能。

Conclusion: GTCA提供了一种实用的、兼容检查点的方法，可以提高仅解码器LLMs的语法鲁棒性，而不会影响其现有的通用推理能力。

Abstract: Decoder-only large language models achieve strong broad performance but are brittle to minor grammatical perturbations, undermining reliability for downstream reasoning. However, directly injecting explicit syntactic structure into an existing checkpoint can interfere with its pretrained competence. We introduce a checkpoint-compatible gated tree cross-attention (GTCA) branch that reads precomputed constituency chunk memory while leaving backbone architecture unchanged. Our design uses a token update mask and staged training to control the scope and timing of structural updates. Across benchmarks and Transformer backbones, GTCA strengthens syntactic robustness beyond continued-training baselines without compromising Multiple-Choice QA performance or commonsense reasoning, providing a practical checkpoint-compatible route to more syntax-robust decoder-only LLMs.

</details>


### [69] [Do Personality Traits Interfere? Geometric Limitations of Steering in Large Language Models](https://arxiv.org/abs/2602.15847)
*Pranav Bhandari,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）中人格特征的独立性问题，发现不同人格特征的控制向量之间存在几何依赖性，即控制一个特征会影响其他特征，即使排除了线性重叠，也无法实现完全独立的特征控制。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常假设大型语言模型中的不同人格特征可以独立控制，本文旨在探究这一假设是否成立。

Method: 作者分析了从 LLaMA-3-8B 和 Mistral-8B 模型家族中提取的人格特征（Big Five）的控制向量之间的几何关系，并应用了从无约束方向到软硬正交化的多种几何条件方案。

Result: 研究发现，不同人格特征的控制向量之间存在显著的几何依赖性。即使通过硬正交化强制执行几何独立性，也未能消除跨特征的行为影响，并且可能削弱控制强度。

Conclusion: 大型语言模型中的人格特征占据一个轻度耦合的子空间，这限制了对每个特征的完全独立控制。

Abstract: Personality steering in large language models (LLMs) commonly relies on injecting trait-specific steering vectors, implicitly assuming that personality traits can be controlled independently. In this work, we examine whether this assumption holds by analysing the geometric relationships between Big Five personality steering directions. We study steering vectors extracted from two model families (LLaMA-3-8B and Mistral-8B) and apply a range of geometric conditioning schemes, from unconstrained directions to soft and hard orthonormalisation. Our results show that personality steering directions exhibit substantial geometric dependence: steering one trait consistently induces changes in others, even when linear overlap is explicitly removed. While hard orthonormalisation enforces geometric independence, it does not eliminate cross-trait behavioural effects and can reduce steering strength. These findings suggest that personality traits in LLMs occupy a slightly coupled subspace, limiting fully independent trait control.

</details>


### [70] [Can LLMs Assess Personality? Validating Conversational AI for Trait Profiling](https://arxiv.org/abs/2602.15848)
*Andrius Matšenas,Anet Lello,Tõnis Lees,Hans Peep,Kim Lilii Tamm*

Main category: cs.CL

TL;DR: 该研究探索了使用大型语言模型（LLM）进行个性评估的可行性，发现其与传统问卷在一定程度上具有一致性，并且用户认为LLM评估的准确性不亚于传统方法。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLM）作为一种动态替代传统问卷进行个性评估的方法，以提供一种新的心理测量学途径。

Method: 进行了一项被试内实验（N=33），比较了通过引导式LLM对话获得的“大五”人格得分与金标准IPIP-50问卷得分，并测量了用户感知的准确性。

Result: LLM对话与IPIP-50问卷在“尽责性”、“开放性”和“神经质”维度上显示出中等程度的收敛效度（r=0.38-0.58），且得分统计上无显著差异。“宜人性”和“外向性”维度存在显著差异。用户普遍认为LLM生成的个性评估与其自身感知和问卷结果一样准确。

Conclusion: 对话式AI（LLM）为传统心理测量学提供了一种有前途的新方法，尽管在某些特质上需要进行校准以提高准确性。

Abstract: This study validates Large Language Models (LLMs) as a dynamic alternative to questionnaire-based personality assessment. Using a within-subjects experiment (N=33), we compared Big Five personality scores derived from guided LLM conversations against the gold-standard IPIP-50 questionnaire, while also measuring user-perceived accuracy. Results indicate moderate convergent validity (r=0.38-0.58), with Conscientiousness, Openness, and Neuroticism scores statistically equivalent between methods. Agreeableness and Extraversion showed significant differences, suggesting trait-specific calibration is needed. Notably, participants rated LLM-generated profiles as equally accurate as traditional questionnaire results. These findings suggest conversational AI offers a promising new approach to traditional psychometrics.

</details>


### [71] [Preference Optimization for Review Question Generation Improves Writing Quality](https://arxiv.org/abs/2602.15849)
*Karun Sharma,Vidushee Vats,Shengzhi Li,Yuxiang Wang,Zhongtian Sun,Prayag Tiwari*

Main category: cs.CL

TL;DR: 本文提出了一种名为IntelliReward的新型奖励模型，它通过在LLM的最终状态上训练多头Transformer，能够生成比现有方法更具实质性和证据性的同行评审问题。结合IntelliReward与DAPO，训练出的IntelliAsk模型在推理和写作任务上均有提升，并提供了一个用于评估LLM生成评审问题质量的自动基准。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的同行评审问题生成方法倾向于生成表面层面的问题，过分依赖文章的开头部分。研究旨在弥合这一差距，生成更具实质性、证据性和基于文章内容的问题。

Method: 开发了一个名为IntelliReward的奖励模型，该模型基于冻结的自回归LLM，并在其最终的50个token状态上训练可训练的多头Transformer。使用IntelliReward，结合Decoupled Clip和Dynamic Sampling Policy Optimization (DAPO)，训练了一个名为IntelliAsk的问题生成模型。

Result: IntelliAsk在推理和写作基准测试上均显示出持续的改进。与Qwen3-32B基础模型相比，IntelliAsk在MuSR（准确率从64.7%提高到68.3%）和WritingBench（得分从8.07提高到8.31）等任务上表现更优。研究发现，评审问题的质量与LLM的更广泛能力（如推理和写作）相关。

Conclusion: IntelliReward模型能够学习专家级别的人类偏好，生成更高质量的同行评审问题。IntelliAsk模型通过此方法训练，在多项基准测试中取得了显著进步，证明了改进问题质量对提升LLM整体能力的重要性。研究还发布了相关实现、标注数据和奖励模型，以促进LLM生成评审问题的自动评估。

Abstract: Peer review relies on substantive, evidence-based questions, yet existing LLM-based approaches often generate surface-level queries, drawing over 50\% of their question tokens from a paper's first page. To bridge this gap, we develop IntelliReward, a novel reward model built from a frozen autoregressive LLM with trainable multi-head transformers over the final 50 token states, which outperforms API-based SFT baselines in predicting expert-level human preferences. By applying Decoupled Clip and Dynamic Sampling Policy Optimization (DAPO) with IntelliReward, we train IntelliAsk, a question-generation model aligned with human standards of effort, evidence, and grounding. We find consistent improvements on reasoning and writing benchmarks, suggesting reviewer-question quality correlates with broader capabilities. Compared to the Qwen3-32B base model, IntelliAsk shows measurable gains across diverse benchmarks, specifically improving performance on reasoning tasks like MuSR (68.3 vs 64.7 Acc) and complex writing evaluations such as WritingBench (8.31 vs 8.07). We release our implementation, expert preference annotations, and the IntelliReward model to provide an automatic evaluation benchmark for grounding, effort, and evidence in LLM-generated review questions.

</details>


### [72] [Large Language Models for Assisting American College Applications](https://arxiv.org/abs/2602.15850)
*Zhengliang Liu,Weihang You,Peng Shu,Junhao Chen,Yi Pan,Hanqi Jiang,Yiwei Li,Zhaojun Ding,Chao Cao,Xinliang Li,Yifan Zhou,Ruidong Zhang,Shaochen Xu,Wei Ruan,Huaqin Zhao,Dajiang Zhu,Tianming Liu*

Main category: cs.CL

TL;DR: EZCollegeApp是一个由大型语言模型驱动的系统，旨在帮助高中生简化美国大学申请过程，通过结构化申请表、提供基于官方招生文档的答案建议，并确保学生对最终答案拥有完全控制权。


<details>
  <summary>Details</summary>
Motivation: 美国大学申请过程复杂且碎片化，要求学生处理重复、有条件的表格和模糊的问题，常常需要查阅多个信息源。

Method: EZCollegeApp采用“先映射后生成”的范式，将表单理解与答案生成分开。它整合了官方招生网站的文档摄取、检索增强问答以及一个“人在回路”的聊天机器人界面，在申请字段旁边提供建议，但不自动提交。

Result: 系统能够将官方招生文档的答案与申请表字段对应起来，并为学生提供指导性的答案建议，同时保留人类对最终输入的完全控制。

Conclusion: EZCollegeApp通过结构化申请过程、提供基于证据的答案建议和确保人类控制，有效地减轻了美国大学申请的复杂性，并发布了源代码以促进更广泛的应用。

Abstract: American college applications require students to navigate fragmented admissions policies, repetitive and conditional forms, and ambiguous questions that often demand cross-referencing multiple sources. We present EZCollegeApp, a large language model (LLM)-powered system that assists high-school students by structuring application forms, grounding suggested answers in authoritative admissions documents, and maintaining full human control over final responses. The system introduces a mapping-first paradigm that separates form understanding from answer generation, enabling consistent reasoning across heterogeneous application portals. EZCollegeApp integrates document ingestion from official admissions websites, retrieval-augmented question answering, and a human-in-the-loop chatbot interface that presents suggestions alongside application fields without automated submission. We describe the system architecture, data pipeline, internal representations, security and privacy measures, and evaluation through automated testing and human quality assessment. Our source code is released on GitHub (https://github.com/ezcollegeapp-public/ezcollegeapp-public) to facilitate the broader impact of this work.

</details>


### [73] [Narrative Theory-Driven LLM Methods for Automatic Story Generation and Understanding: A Survey](https://arxiv.org/abs/2602.15851)
*David Y. Liu,Aditya Joshi,Paul Dawson*

Main category: cs.CL

TL;DR: 本文对NLP研究中应用叙事理论的现有工作进行了调查，并提出了一个分类法，以反映叙事学中的既有区分。研究者们识别了叙事数据集、任务、理论、NLP管道以及提示和微调的方法学趋势。文章强调了LLM在连接NLP管道与抽象叙事概念方面的潜力，并指出了跨学科合作的机会。然而，在统一叙事相关任务的定义或基准方面仍存在挑战，这使得模型比较困难。研究者建议未来的研究应侧重于定义和改进基于理论的叙事属性指标，进行大规模的、理论驱动的文学/社会/文化分析，以及创建用于验证或完善叙事理论的实验，而不是追求单一的、泛化的“叙事质量”基准。


<details>
  <summary>Details</summary>
Motivation: LLMs在自动故事生成和理解方面展现出巨大潜力，然而，NLP研究如何与叙事学研究相结合尚不明确。本研究旨在调查NLP研究如何应用叙事理论，并为相关工作提供一个分类框架，以促进跨学科合作和更系统化的叙事研究。

Method: 作者对NLP研究中应用叙事理论的现有工作进行了调查，并提出了一个分类法，该分类法反映了叙事学中的既有区分。他们识别了叙事数据集、任务、理论、NLP管道以及提示和微调的方法学趋势。

Result: 研究发现了叙事数据集和任务、叙事理论、NLP管道以及提示和微调的方法学趋势。LLMs能够轻松连接NLP管道与抽象叙事概念，并为跨学科合作提供了机会。然而，在统一叙事相关任务的定义或基准方面仍存在挑战，这使得模型比较困难。

Conclusion: 本文为NLP领域更系统化和理论驱动的叙事研究奠定了基础。研究者建议未来的方向应侧重于开发基于理论的指标，进行理论驱动的分析，并通过实验来验证或完善叙事理论，而非追求单一的通用基准。

Abstract: Applications of narrative theories using large language models (LLMs) deliver promising use-cases in automatic story generation and understanding tasks. Our survey examines how natural language processing (NLP) research engages with fields of narrative studies, and proposes a taxonomy for ongoing efforts that reflect established distinctions in narratology. We discover patterns in the following: narrative datasets and tasks, narrative theories and NLP pipeline and methodological trends in prompting and fine-tuning. We highlight how LLMs enable easy connections of NLP pipelines with abstract narrative concepts and opportunities for interdisciplinary collaboration. Challenges remain in attempts to work towards any unified definition or benchmark of narrative related tasks, making model comparison difficult. For future directions, instead of the pursuit of a single, generalised benchmark for 'narrative quality', we believe that progress benefits more from efforts that focus on the following: defining and improving theory-based metrics for individual narrative attributes to incrementally improve model performance; conducting large-scale, theory-driven literary/social/cultural analysis; and creating experiments where outputs can be used to validate or refine narrative theories. This work provides a contextual foundation for more systematic and theoretically informed narrative research in NLP by providing an overview to ongoing research efforts and the broader narrative studies landscape.

</details>


### [74] [Building Safe and Deployable Clinical Natural Language Processing under Temporal Leakage Constraints](https://arxiv.org/abs/2602.15852)
*Ha Na Cho,Sairam Sutari,Alexander Lopez,Hansen Bow,Kai Zheng*

Main category: cs.CL

TL;DR: 本研究提出了一种轻量级审计流水线，用于识别和抑制临床NLP模型中的时间泄露，以构建安全可部署的模型，特别是在出院预测任务中，审计后的模型表现出更保守、校准更好的预测，并减少了对泄露信号的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的临床NLP模型在利用叙述性临床文档支持医院出院规划方面展现出潜力，但容易受到时间泄露和词汇泄露的影响，这可能导致模型过度自信和不准确的预测，对临床工作流程和患者安全构成风险。因此，研究旨在解决构建安全、可部署的临床NLP模型在时间泄露约束下的系统级设计选择问题。

Method: 研究提出了一种轻量级审计流水线，该流水线将可解释性集成到模型开发过程中，用于识别和抑制泄露风险信号，然后再进行最终训练。在择期脊柱手术后的次日出院预测任务中，评估了审计对预测行为、校准和安全相关权衡的影响。

Result: 审计后的模型展现出更保守、校准更好的概率估计。模型对与出院相关的词汇线索的依赖性降低。审计过程有助于改善模型的预测准确性和可靠性。

Conclusion: 部署就绪的临床NLP系统应优先考虑时间有效性、校准和行为鲁棒性，而不是片面追求乐观的性能指标。审计机制是构建安全可靠临床NLP模型的重要组成部分。

Abstract: Clinical natural language processing (NLP) models have shown promise for supporting hospital discharge planning by leveraging narrative clinical documentation. However, note-based models are particularly vulnerable to temporal and lexical leakage, where documentation artifacts encode future clinical decisions and inflate apparent predictive performance. Such behavior poses substantial risks for real-world deployment, where overconfident or temporally invalid predictions can disrupt clinical workflows and compromise patient safety. This study focuses on system-level design choices required to build safe and deployable clinical NLP under temporal leakage constraints. We present a lightweight auditing pipeline that integrates interpretability into the model development process to identify and suppress leakage-prone signals prior to final training. Using next-day discharge prediction after elective spine surgery as a case study, we evaluate how auditing affects predictive behavior, calibration, and safety-relevant trade-offs. Results show that audited models exhibit more conservative and better-calibrated probability estimates, with reduced reliance on discharge-related lexical cues. These findings emphasize that deployment-ready clinical NLP systems should prioritize temporal validity, calibration, and behavioral robustness over optimistic performance.

</details>


### [75] [A Lightweight Explainable Guardrail for Prompt Safety](https://arxiv.org/abs/2602.15853)
*Md Asiful Islam,Mihai Surdeanu*

Main category: cs.CL

TL;DR: 提出了一种名为 LEG 的轻量级可解释的保护性围栏方法，用于识别不安全提示。该方法采用多任务学习，同时对提示本身和解释性词语进行分类，并使用新颖的策略生成合成数据以克服大型语言模型的确认偏差。


<details>
  <summary>Details</summary>
Motivation: 现有识别不安全提示的方法在模型规模和可解释性方面存在不足，研究者希望开发一种更轻量级且具有良好可解释性的解决方案。

Method: 该方法使用多任务学习架构，联合训练一个提示分类器和一个解释分类器。解释分类器用于标记解释安全/不安全决策的提示词。训练数据通过一种新颖的策略生成，该策略旨在对抗大型语言模型的确认偏差。损失函数结合了交叉熵损失、焦点损失以及基于不确定性的加权。

Result: LEG 在提示分类和可解释性方面均达到了与最先进方法相当或更好的性能，并且模型尺寸显著减小。实验在三个数据集上进行了领域内和领域外评估。

Conclusion: LEG 是一种轻量级且可解释的方法，能够有效地对不安全提示进行分类，并在保持高性能的同时减小模型规模，有望克服现有方法的局限性。

Abstract: We propose a lightweight explainable guardrail (LEG) method for the classification of unsafe prompts. LEG uses a multi-task learning architecture to jointly learn a prompt classifier and an explanation classifier, where the latter labels prompt words that explain the safe/unsafe overall decision. LEG is trained using synthetic data for explainability, which is generated using a novel strategy that counteracts the confirmation biases of LLMs. Lastly, LEG's training process uses a novel loss that captures global explanation signals and combines cross-entropy and focal losses with uncertainty-based weighting. LEG obtains equivalent or better performance than the state-of-the-art for both prompt classification and explainability, both in-domain and out-of-domain on three datasets, despite the fact that its model size is considerably smaller than current approaches. If accepted, we will release all models and the annotated dataset publicly.

</details>


### [76] [Rethinking Soft Compression in Retrieval-Augmented Generation: A Query-Conditioned Selector Perspective](https://arxiv.org/abs/2602.15856)
*Yunhao Liu,Zian Jia,Xinyu Gao,Kanjun Xu,Yun Xiong*

Main category: cs.CL

TL;DR: 本文提出 SeleCom，一种基于选择器的软上下文压缩框架，用于 RAG。它通过查询条件信息选择器克服了现有软压缩方法的局限性，显著提高了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的软上下文压缩方法在 RAG 中存在压缩过度的低效问题，导致模型性能下降。研究人员发现这是由于不必要的全文压缩以及其与 LLM 生成行为的冲突。

Method: 提出 SeleCom 框架，将编码器重定义为查询条件信息选择器，并使用大规模、多样化、难度分级的合成 QA 数据集和课程学习进行训练。

Result: SeleCom 在 RAG 任务上显著优于现有的软压缩方法，性能可与非压缩基线方法媲美或超越，同时将计算和延迟降低了 33.8%~84.6%。

Conclusion:  SeleCom 通过查询条件信息选择器实现了高效且有效的软上下文压缩，克服了现有方法的固有缺陷，为 RAG 的可扩展性提供了新的解决方案。

Abstract: Retrieval-Augmented Generation (RAG) effectively grounds Large Language Models (LLMs) with external knowledge and is widely applied to Web-related tasks. However, its scalability is hindered by excessive context length and redundant retrievals. Recent research on soft context compression aims to address this by encoding long documents into compact embeddings, yet they often underperform non-compressed RAG due to their reliance on auto-encoder-like full-compression that forces the encoder to compress all document information regardless of relevance to the input query.
  In this work, we conduct an analysis on this paradigm and reveal two fundamental limitations: (I) Infeasibility, full-compression conflicts with the LLM's downstream generation behavior; and (II) Non-necessity: full-compression is unnecessary and dilutes task-relevant information density. Motivated by these insights, we introduce SeleCom, a selector-based soft compression framework for RAG that redefines the encoder's role as query-conditioned information selector. The selector is decoder-only and is trained with a massive, diverse and difficulty-graded synthetic QA dataset with curriculum learning.
  Extensive experiments show that SeleCom significantly outperforms existing soft compression approaches and achieves competitive or superior performance to non-compression baselines, while reducing computation and latency by 33.8%~84.6%.

</details>


### [77] [Multi-source Heterogeneous Public Opinion Analysis via Collaborative Reasoning and Adaptive Fusion: A Systematically Integrated Approach](https://arxiv.org/abs/2602.15857)
*Yi Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为CRAF（Collaborative Reasoning and Adaptive Fusion）的新型框架，用于整合来自异构来源的公共意见分析，特别是融合了传统特征方法和大型语言模型（LLMs），并具备跨平台注意力、自适应融合、联合优化和多模态信息提取能力，在多个数据集上显著提高了主题聚类和情感分析的性能，并大幅减少了对新平台标注数据的需求。


<details>
  <summary>Details</summary>
Motivation: 公共意见分析面临来自异构来源（如结构差异、语义变化、平台偏见）的挑战，现有方法难以有效整合这些信息。

Method: 提出CRAF框架，该框架包含四个关键创新：1. 跨平台协同注意力模块，用于对齐语义表示并保留源特性；2. 分层自适应融合机制，根据数据质量和任务需求动态加权特征；3. 联合优化策略，通过共享的潜在空间同时学习主题表示和情感分布；4. 新型多模态提取能力，整合OCR、ASR和视觉情感分析处理视频内容。

Result: 理论分析显示CRAF的泛化界比独立源模型有O(sqrt(d log K / m))的改进。实验结果表明，在三个多平台数据集上，CRAF在主题聚类上的ARI平均达到0.76（比最佳基线提高4.1%），在情感分析上的F1分数达到0.84（比最佳基线提高3.8%）。该框架在新平台上的标注数据需求减少了75%。

Conclusion: CRAF框架能够有效地整合来自异构来源的公共意见数据，通过协同推理和自适应融合，克服了跨平台分析的挑战，显著提升了分析性能，并展现了良好的跨平台适应性和数据效率。

Abstract: The analysis of public opinion from multiple heterogeneous sources presents significant challenges due to structural differences, semantic variations, and platform-specific biases. This paper introduces a novel Collaborative Reasoning and Adaptive Fusion (CRAF) framework that systematically integrates traditional feature-based methods with large language models (LLMs) through a structured multi-stage reasoning mechanism. Our approach features four key innovations: (1) a cross-platform collaborative attention module that aligns semantic representations while preserving source-specific characteristics, (2) a hierarchical adaptive fusion mechanism that dynamically weights features based on both data quality and task requirements, (3) a joint optimization strategy that simultaneously learns topic representations and sentiment distributions through shared latent spaces, and (4) a novel multimodal extraction capability that processes video content from platforms like Douyin and Kuaishou by integrating OCR, ASR, and visual sentiment analysis. Theoretical analysis demonstrates that CRAF achieves a tighter generalization bound with a reduction of O(sqrt(d log K / m)) compared to independent source modeling, where d is feature dimensionality, K is the number of sources, and m is sample size. Comprehensive experiments on three multi-platform datasets (Weibo-12, CrossPlatform-15, NewsForum-8) show that CRAF achieves an average topic clustering ARI of 0.76 (4.1% improvement over best baseline) and sentiment analysis F1-score of 0.84 (3.8% improvement). The framework exhibits strong cross-platform adaptability, reducing the labeled data requirement for new platforms by 75%.

</details>


### [78] [State Design Matters: How Representations Shape Dynamic Reasoning in Large Language Models](https://arxiv.org/abs/2602.15858)
*Annie Wong,Aske Plaat,Thomas Bäck,Niki van Stein,Anna V. Kononova*

Main category: cs.CL

TL;DR: 研究表明，在动态环境中，LLM的表现很大程度上取决于状态的表示方式。摘要形式、自然语言表示和文本空间编码能显著提升模型性能。然而，即使经过优化，LLM在长时序推理和多任务处理方面仍显不足。


<details>
  <summary>Details</summary>
Motivation: 随着LLM从静态推理转向动态环境，它们在与环境交互时的状态表示能力成为关键。现有研究对这一因素的探索不足。

Method: 研究人员在固定的模型参数下，系统性地改变了三种状态表示的关键方面：(1) 状态粒度（长文本 vs 摘要），(2) 结构（自然语言 vs 符号化），和 (3) 空间接地（仅文本 vs 图像或文本地图编码）。实验在多种顺序决策任务上进行。

Result: 1. 轨迹摘要化通过减少噪声和稳定长时序推理提高了性能。2. 自然语言表示对模型最鲁棒，而结构化编码仅对具有代码或结构化输出先验的模型（如JSON schema）有帮助。3. 文本空间编码比图像输入更有效，这并非源于空间信息本身，而是构建过程促使模型进行静态输入无法激发的空间推理。

Conclusion: 状态表示的设计选择对LLM在动态环境中的性能起决定性作用，这与信息可用性本身是不同的。然而，即使有改进的状态表示，目前的LLM和VLM在长时序推理方面仍然脆弱，尤其是在需要综合信息来管理多个子任务以达成目标时。

Abstract: As large language models (LLMs) move from static reasoning tasks toward dynamic environments, their success depends on the ability to navigate and respond to an environment that changes as they interact at inference time. An underexplored factor in these settings is the representation of the state. Holding model parameters fixed, we systematically vary three key aspects: (1) state granularity (long form versus summary), (2) structure (natural language versus symbolic), and (3) spatial grounding (text-only versus images or textual map encodings) across sequential decision-making benchmarks. We find that trajectory summarisation improves performance by reducing noise and stabilising long-horizon reasoning. Second, natural language representations are the most robust across models, whereas structured encodings help mainly for models with strong code or structured output priors, such as JSON schemas. Third, while image-inputs show some benefit, text-based spatial encodings prove most effective. This advantage stems not from the spatial information itself, but from the act of construction, which compels the model to perform the spatial reasoning that static input does not elicit. Overall, we demonstrate that design choices for representing state are a decisive factor in performance, distinct from the availability of information itself. We note, however, that even with improved representations, current LLMs and VLMs remain brittle over long horizons, particularly when they must synthesise information to manage multiple subtasks to reach a goal.

</details>


### [79] [From Transcripts to AI Agents: Knowledge Extraction, RAG Integration, and Robust Evaluation of Conversational AI Assistants](https://arxiv.org/abs/2602.15859)
*Krittin Pachtrachai,Petmongkon Pornpichitsuwan,Wachiravit Modecrua,Touchapon Kraisingkorn*

Main category: cs.CL

TL;DR: 本研究提出了一种端到端的框架，用于直接从历史通话记录中构建和评估对话式 AI 助手，适用于需要实时信息的客户服务行业。


<details>
  <summary>Details</summary>
Motivation: 现有对话式 AI 在处理嘈杂数据、碎片化知识以及需要准确人工交接的场景（尤其是在依赖实时信息的领域）时面临挑战。

Method: 该框架首先使用 PIPA 框架的简化版本对通话记录进行评分和过滤，然后使用 LLM 从精选记录中提取结构化知识，并将其作为 RAG 管道的唯一基础。助手行为通过系统化的提示调优进行管理，并使用基于记录的用户模拟器进行评估，同时通过红队测试来评估其对攻击的鲁棒性。

Result: 在房地产和专业招聘领域，该助手能够自主处理约 30% 的电话，在事实准确性和拒绝不当请求方面接近完美，并且在对抗性测试下表现出很强的鲁棒性。

Conclusion: 该框架能够有效地从历史通话记录中构建出能够在具有挑战性的实时信息密集型领域中自主处理部分客户来电的对话式 AI 助手，并具有良好的准确性和鲁棒性。

Abstract: Building reliable conversational AI assistants for customer-facing industries remains challenging due to noisy conversational data, fragmented knowledge, and the requirement for accurate human hand-off - particularly in domains that depend heavily on real-time information. This paper presents an end-to-end framework for constructing and evaluating a conversational AI assistant directly from historical call transcripts. Incoming transcripts are first graded using a simplified adaptation of the PIPA framework, focusing on observation alignment and appropriate response behavior, and are filtered to retain only high-quality interactions exhibiting coherent flow and effective human agent responses. Structured knowledge is then extracted from curated transcripts using large language models (LLMs) and deployed as the sole grounding source in a Retrieval-Augmented Generation (RAG) pipeline. Assistant behavior is governed through systematic prompt tuning, progressing from monolithic prompts to lean, modular, and governed designs that ensure consistency, safety, and controllable execution. Evaluation is conducted using a transcript-grounded user simulator, enabling quantitative measurement of call coverage, factual accuracy, and human escalation behavior. Additional red teaming assesses robustness against prompt injection, out-of-scope, and out-of-context attacks. Experiments are conducted in the Real Estate and Specialist Recruitment domains, which are intentionally challenging and currently suboptimal for automation due to their reliance on real-time data. Despite these constraints, the assistant autonomously handles approximately 30 percents of calls, achieves near-perfect factual accuracy and rejection behavior, and demonstrates strong robustness under adversarial testing.

</details>


### [80] [Decoupling Strategy and Execution in Task-Focused Dialogue via Goal-Oriented Preference Optimization](https://arxiv.org/abs/2602.15854)
*Jingyi Xu,Xingyu Ren,Zhiqiang You,Yumeng Zhang,Zhoupeng Shou*

Main category: cs.CL

TL;DR: 提出了一种名为GOPO的层级强化学习框架，通过解耦策略规划和响应生成，以及引入新的序列级评估指标TSE，显著提升了面向任务的对话系统的长期任务成功率，并在与大型模型的对比中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有面向任务的对话系统训练方法（如基于token的似然或偏好优化）未能有效实现长对话周期的任务成功。

Method: 提出了一种名为GOPO（Goal-Oriented Preference Optimization）的层级强化学习框架，包含一个Expert Agent（负责多轮目标偏好优化）和一个Customer Service Agent（负责根据策略生成响应）。引入了基于真实电商交互数据衍生的序列级评估指标TSE（Task-focused Sequential Engagement）。

Result: 在Mgshop数据集上，GOPO相比PPO和Memento，TSE分别提高了7.7%和10.3%，同时提升了序列级奖励和生成质量。使用GOPO训练的14B模型在TSE上优于Qwen-235B和GPT-5.2。消融实验证明了Expert Agent在长周期优化中的关键作用。GOPO在其他数据集上也表现出一致的改进。

Conclusion: GOPO框架能够有效解决面向任务的对话系统在长对话周期中任务成功率不高的问题，为商业场景下的面向任务对话系统开辟了新范式。

Abstract: Large language models show potential in task-oriented dialogue systems, yet existing training methods often rely on token-level likelihood or preference optimization, which poorly align with long-horizon task success. To address this, we propose Goal-Oriented Preference Optimization (GOPO), a hierarchical reinforcement learning framework that decouples strategy planning from response generation via an Expert Agent and a Customer Service Agent. The Expert Agent optimizes multi-turn goal preferences at the dialogue-trajectory level, while the Customer Service Agent generates responses strictly aligned with the selected strategy. We evaluate GOPO on public benchmarks and e-commerce customer service datasets, and introduce Task-focused Sequential Engagement (TSE), a sequence-level metric derived from real e-commerce interaction data. On the Mgshop dataset, GOPO improves TSE by 7.7% and 10.3% over PPO and Memento, with consistent gains in sequence-level reward and generation quality. Furthermore, a 14B model trained with GOPO achieves 2.7% and 1.5% higher TSE than Qwen-235B and GPT-5.2, respectively. Ablation studies confirm the Expert Agent's critical role in long-horizon optimization. GOPO demonstrates consistent improvements across other datasets as well. This work establishes a new paradigm for task-oriented dialogue systems in commercial scenarios, with code and datasets to be made public.

</details>


### [81] [Reranker Optimization via Geodesic Distances on k-NN Manifolds](https://arxiv.org/abs/2602.15860)
*Wen G. Gong*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Maniscope 的新颖几何重排序方法，用于检索增强生成 (RAG)，该方法在 k-NN 流形上计算测地线距离，相比现有方法（如基于交叉编码器或 LLM 的方法）在保持竞争力的准确性的同时，显著提高了效率和降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的 RAG 重排序方法依赖计算资源密集型和高延迟的模型（如交叉编码器和 LLM），这阻碍了实时 RAG 应用的部署。因此，需要一种更高效的重排序方法。

Method: Maniscope 方法首先在检索到的文档候选集上构建 k-NN 流形，然后计算这些流形上的测地线距离。它结合了全局余弦相似度和局部流形几何来捕捉语义结构，并分析了其计算复杂度 O(N D + M^2 D + M k log k)，其中 M << N。

Result: Maniscope 在八个 BEIR 基准数据集上的评估显示，在三个最难的数据集（NFCorpus, TREC-COVID, AorB）上，其 NDCG@3 指标优于 HNSW 基线。与交叉编码器重排序器相比，Maniscope 的准确性损失不到 2%，但延迟降低了 10-45 倍。与 LLM-Reranker 相比，Maniscope 在显著降低延迟的同时，提供了可比的性能提升。

Conclusion: Maniscope 是一种高效且实用的 RAG 重排序方法，它通过利用流形几何，在保证高准确性的前提下，显著降低了延迟，使其成为实时 RAG 部署的有力替代方案。作者计划将 Maniscope 开源。

Abstract: Current neural reranking approaches for retrieval-augmented generation (RAG) rely on cross-encoders or large language models (LLMs), requiring substantial computational resources and exhibiting latencies of 3-5 seconds per query. We propose Maniscope, a geometric reranking method that computes geodesic distances on k-nearest neighbor (k-NN) manifolds constructed over retrieved document candidates. This approach combines global cosine similarity with local manifold geometry to capture semantic structure that flat Euclidean metrics miss. Evaluating on eight BEIR benchmark datasets (1,233 queries), Maniscope outperforms HNSW graph-based baseline on the three hardest datasets (NFCorpus: +7.0%, TREC-COVID: +1.6%, AorB: +2.8% NDCG@3) while being 3.2x faster (4.7 ms vs 14.8 ms average). Compared to cross-encoder rerankers, Maniscope achieves within 2% accuracy at 10-45x lower latency. On TREC-COVID, LLM-Reranker provides only +0.5% NDCG@3 improvement over Maniscope at 840x higher latency, positioning Maniscope as a practical alternative for real-time RAG deployment. The method requires O(N D + M^2 D + M k log k) complexity where M << N , enabling sub-10 ms latency. We plan to release Maniscope as open-source software.

</details>


### [82] [CAST: Achieving Stable LLM-based Text Analysis for Data Analytics](https://arxiv.org/abs/2602.15861)
*Jinxiang Xie,Zihao Li,Wei He,Rui Ding,Shi Han,Dongmei Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为CAST的框架，通过算法提示和先思考后生成的方法，显著提高了大型语言模型在表格数据文本分析（如摘要和标注）任务中的输出稳定性，同时保持或提升了输出质量。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在进行表格数据的摘要和标注等任务时，其输出稳定性不足，难以满足数据分析的要求。

Method: CAST框架结合了两种技术：（1）算法提示（Algorithmic Prompting），通过引入程序化约束来规范模型的推理过程；（2）先思考后生成（Thinking-before-Speaking），要求模型在最终生成前做出明确的中间决策。

Result: 在公开的基准数据集和多种LLM模型上进行的实验表明，CAST框架在摘要和标注任务上均表现出最佳的稳定性，稳定性得分最高可提升16.2%，并且输出质量也得到维持或改善。作者还提出了CAST-S和CAST-T两种稳定性评估指标，并验证了其与人类判断的一致性。

Conclusion: CAST框架能够有效提高大型语言模型在表格数据文本分析任务中的输出稳定性，同时保证输出质量，为数据分析领域的可信AI应用提供了新的解决方案。

Abstract: Text analysis of tabular data relies on two core operations: \emph{summarization} for corpus-level theme extraction and \emph{tagging} for row-level labeling. A critical limitation of employing large language models (LLMs) for these tasks is their inability to meet the high standards of output stability demanded by data analytics. To address this challenge, we introduce \textbf{CAST} (\textbf{C}onsistency via \textbf{A}lgorithmic Prompting and \textbf{S}table \textbf{T}hinking), a framework that enhances output stability by constraining the model's latent reasoning path. CAST combines (i) Algorithmic Prompting to impose a procedural scaffold over valid reasoning transitions and (ii) Thinking-before-Speaking to enforce explicit intermediate commitments before final generation. To measure progress, we introduce \textbf{CAST-S} and \textbf{CAST-T}, stability metrics for bulleted summarization and tagging, and validate their alignment with human judgments. Experiments across publicly available benchmarks on multiple LLM backbones show that CAST consistently achieves the best stability among all baselines, improving Stability Score by up to 16.2\%, while maintaining or improving output quality.

</details>


### [83] [Enhancing Action and Ingredient Modeling for Semantically Grounded Recipe Generation](https://arxiv.org/abs/2602.15862)
*Guoshan Liu,Bin Zhu,Yian Li,Jingjing Chen,Chong-Wah Ngo,Yu-Gang Jiang*

Main category: cs.CL

TL;DR: 研究提出了一个用于从食物图像生成食谱的框架，通过预测和验证动作和配料的语义，提高了生成食谱的准确性，并在Recipe1M数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的从食物图像生成食谱的模型，即使在词汇层面得分很高，也经常生成语义上不正确的动作或配料。

Method: 该研究提出了一个两阶段的框架，包括监督微调（SFT）和强化微调（RFT）。SFT使用动作-推理数据集和配料语料库来建立基础准确性。RFT使用频率感知的奖励来提高长尾动作预测和配料泛化能力。此外，还引入了一个语义置信度评分和修正（SCSR）模块来过滤和纠正预测。

Result: 在Recipe1M数据集上的实验表明，该框架达到了最先进的性能，并显著提高了语义保真度。

Conclusion: 提出的框架有效地解决了MLMMs在食谱生成中语义不准确的问题，通过预测和验证内部上下文（动作和配料），显著提高了生成食谱的质量。

Abstract: Recent advances in Multimodal Large Language Models (MLMMs) have enabled recipe generation from food images, yet outputs often contain semantically incorrect actions or ingredients despite high lexical scores (e.g., BLEU, ROUGE). To address this gap, we propose a semantically grounded framework that predicts and validates actions and ingredients as internal context for instruction generation. Our two-stage pipeline combines supervised fine-tuning (SFT) with reinforcement fine-tuning (RFT): SFT builds foundational accuracy using an Action-Reasoning dataset and ingredient corpus, while RFT employs frequency-aware rewards to improve long-tail action prediction and ingredient generalization. A Semantic Confidence Scoring and Rectification (SCSR) module further filters and corrects predictions. Experiments on Recipe1M show state-of-the-art performance and markedly improved semantic fidelity.

</details>


### [84] [Not the Example, but the Process: How Self-Generated Examples Enhance LLM Reasoning](https://arxiv.org/abs/2602.15863)
*Daehoon Gwak,Minseo Jung,Junwoo Park,Minho Park,ChaeHun Park,Junha Hyung,Jaegul Choo*

Main category: cs.CL

TL;DR: 研究表明，大型语言模型（LLMs）通过生成少样本示例可以提升推理能力，但其背后机制不明。本文认为，提升效果的关键在于生成过程本身，而非生成的示例。通过对比零样本、集成提示（生成与解决在同一提示中）和分离提示（复用生成示例但不包含生成过程），实验证明集成提示效果最优，分离提示效果提升有限。注意力分析也证实了集成提示与分离提示在注意力模式上的差异。


<details>
  <summary>Details</summary>
Motivation: 目前尚不清楚大型语言模型通过自生成少样本示例提升推理能力的确切机制，这使得有效应用该技术变得困难。

Method: 在多种LLM架构和推理任务上，对比评估了三种提示策略：零样本提示、集成提示（模型在同一提示中生成并解决问题）和分离提示（模型生成示例并将其作为上下文，但不包含生成过程）。通过注意力分析进一步探究。

Result: 集成提示策略在各种模型架构和推理任务上均显著优于零样本提示和分离提示。分离提示相较于零样本提示仅有边际收益。注意力分析显示集成提示和分离提示在注意力模式上存在显著差异。

Conclusion: 自生成提示的优势来自于问题创建的过程本身，而非生成的示例。这一发现为了解和设计更有效的提示策略提供了重要见解。

Abstract: Recent studies have shown that Large Language Models (LLMs) can improve their reasoning performance through self-generated few-shot examples, achieving results comparable to manually curated in-context examples. However, the underlying mechanism behind these gains remains unclear, making it hard to decide when and how to apply the technique effectively. In this work, we argue that the key benefit arises not from the generated examples themselves but from the act of creating them. To validate this, on reasoning-intensive tasks across diverse LLM architectures, we systematically evaluate three prompting strategies for in-context learning: (1) Zero-shot prompting; (2) Integrated prompting, where LLMs create and solve problems within a single, unified prompt; and (3) Decoupled prompting, where self-generated examples are reused as in-context examples, but the context of their creation itself is excluded. We conduct experiments across five widely used model architectures, demonstrating that Integrated prompting consistently outperforms both Zero-shot and Decoupled prompting. In contrast, Decoupled prompting offers only marginal gains over Zero-shot. Further, for a more in-depth analysis, we conduct an attention analysis and observe significant differences in attention patterns between Integrated and Decoupled prompting. These findings suggest that the advantage of self-generation prompting comes from the process of problem creation, not the examples themselves, providing valuable insights for designing more effective prompting strategies.

</details>


### [85] [NLP Privacy Risk Identification in Social Media (NLP-PRISM): A Survey](https://arxiv.org/abs/2602.15866)
*Dhiman Goswami,Jai Kruthunz Naveen Kumar,Sanchari Das*

Main category: cs.CL

TL;DR: 该研究通过对203篇相关论文的回顾，提出了NLP-PRISM框架，用于评估社交媒体NLP应用中的隐私风险。研究发现，在保护隐私的同时，模型性能会有所下降，并且在隐私研究方面存在显著的不足。


<details>
  <summary>Details</summary>
Motivation: 社交媒体内容中的个人身份信息（PII）、行为线索和元数据带来了隐私风险（如监视、画像和定向广告），因此需要系统性地评估和解决这些风险。

Method: 对203篇同行评审论文进行系统性回顾，并提出NLP-PRISM框架，从数据收集、预处理、可见性、公平性、计算风险和法规遵从性六个维度评估隐私风险。同时，评估了隐私保护微调对Transformer模型性能的影响，并考察了六种NLP任务在隐私研究方面的覆盖情况。

Result: Transformer模型在隐私保护微调下，F1分数会下降1%-23%。NLP-PRISM框架在六种NLP任务（情感分析、情绪检测、攻击性语言识别、代码混合处理、母语识别和方言检测）中揭示了隐私研究的显著差距。隐私保护与模型效用之间存在2%-9%的权衡，MIA AUC为0.81，AIA准确率为0.75。

Conclusion: 社交媒体NLP应用在隐私保护方面存在显著的研究空白，需要加强匿名化、隐私感知学习和公平性驱动的训练，以实现合乎伦理的社交媒体NLP应用。

Abstract: Natural Language Processing (NLP) is integral to social media analytics but often processes content containing Personally Identifiable Information (PII), behavioral cues, and metadata raising privacy risks such as surveillance, profiling, and targeted advertising. To systematically assess these risks, we review 203 peer-reviewed papers and propose the NLP Privacy Risk Identification in Social Media (NLP-PRISM) framework, which evaluates vulnerabilities across six dimensions: data collection, preprocessing, visibility, fairness, computational risk, and regulatory compliance. Our analysis shows that transformer models achieve F1-scores ranging from 0.58-0.84, but incur a 1% - 23% drop under privacy-preserving fine-tuning. Using NLP-PRISM, we examine privacy coverage in six NLP tasks: sentiment analysis (16), emotion detection (14), offensive language identification (19), code-mixed processing (39), native language identification (29), and dialect detection (24) revealing substantial gaps in privacy research. We further found a (reduced by 2% - 9%) trade-off in model utility, MIA AUC (membership inference attacks) 0.81, AIA accuracy 0.75 (attribute inference attacks). Finally, we advocate for stronger anonymization, privacy-aware learning, and fairness-driven training to enable ethical NLP in social media contexts.

</details>


### [86] [Playing With AI: How Do State-Of-The-Art Large Language Models Perform in the 1977 Text-Based Adventure Game Zork?](https://arxiv.org/abs/2602.15867)
*Berry Gerrits*

Main category: cs.CL

TL;DR: 本论文使用经典的文本冒险游戏 Zork 来评估大型语言模型 (LLM) 的问题解决和推理能力。结果显示，尽管有详细的指令，但 ChatGPT、Claude 和 Gemini 的表现都很差，平均完成率不到 10%，这表明当前 LLM 在元认知和推理方面存在根本性局限。


<details>
  <summary>Details</summary>
Motivation: 研究人员希望通过在 Zork 这一具有挑战性的文本冒险游戏中的表现来评估当前大型语言模型 (LLM) 的问题解决和推理能力，以了解它们在理解自然语言描述和生成行动序列方面的局限性。

Method: 研究人员测试了 ChatGPT、Claude 和 Gemini 三种主流专有 LLM 在 Zork 游戏中的表现。他们采用了两种指令设置：最小指令和详细指令，并以游戏得分作为主要衡量标准。此外，研究人员还对模型的推理过程进行了定性分析。

Result: 所有测试模型在 Zork 游戏中的平均完成率均低于 10%，即使是表现最好的 Claude Opus 4.5 也只获得了大约 350 分中的 75 分。提供详细指令或启用“扩展思考”均未带来性能提升。定性分析显示，模型存在重复尝试失败动作、策略持续性不一致以及无法从对话历史中学习等问题。

Conclusion: 当前的大型语言模型在文本冒险游戏领域表现出显著的局限性，尤其是在元认知能力和问题解决方面。它们似乎难以进行反思、保持策略一致性以及从过去的经验中学习，这表明其推理能力仍有待提高。

Abstract: In this positioning paper, we evaluate the problem-solving and reasoning capabilities of contemporary Large Language Models (LLMs) through their performance in Zork, the seminal text-based adventure game first released in 1977. The game's dialogue-based structure provides a controlled environment for assessing how LLM-based chatbots interpret natural language descriptions and generate appropriate action sequences to succeed in the game. We test the performance of leading proprietary models - ChatGPT, Claude, and Gemini - under both minimal and detailed instructions, measuring game progress through achieved scores as the primary metric. Our results reveal that all tested models achieve less than 10% completion on average, with even the best-performing model (Claude Opus 4.5) reaching only approximately 75 out of 350 possible points. Notably, providing detailed game instructions offers no improvement, nor does enabling ''extended thinking''. Qualitative analysis of the models' reasoning processes reveals fundamental limitations: repeated unsuccessful actions suggesting an inability to reflect on one's own thinking, inconsistent persistence of strategies, and failure to learn from previous attempts despite access to conversation history. These findings suggest substantial limitations in current LLMs' metacognitive abilities and problem-solving capabilities within the domain of text-based games, raising questions about the nature and extent of their reasoning capabilities.

</details>


### [87] [Understanding LLM Failures: A Multi-Tape Turing Machine Analysis of Systematic Errors in Language Model Reasoning](https://arxiv.org/abs/2602.15868)
*Magnus Boman*

Main category: cs.CL

TL;DR: 研究提出了一种形式化的方法，使用确定性多磁带图灵机来精确分析大型语言模型（LLMs）的失效模式，并解释链式思考等技术的有效性和局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在看似简单的任务中也会出现失效模式，需要一种更严谨的方式来理解和定位这些问题，而非依赖于模糊的几何学比喻。

Method: 将LLM交互形式化为确定性多磁带图灵机，每个磁带代表输入字符、tokens、词汇表、模型参数、激活、概率分布和输出文本等不同组件。通过分析模型在不同阶段的行为来定位失效模式。

Result: 该模型能够精确地将失效模式定位到特定的流水线阶段，例如揭示tokenization如何掩盖计数任务所需的字符级结构。同时，解释了链式思考等技术通过将计算外化到输出磁带来提供帮助的原因，并指出了其根本性局限。

Conclusion: 这种基于图灵机的形式化方法为理解LLM的失效模式提供了一种严谨、可证伪的替代方案，并能够为错误分析提供原理性的依据，是对经验性扩展定律的重要补充。

Abstract: Large language models (LLMs) exhibit failure modes on seemingly trivial tasks. We propose a formalisation of LLM interaction using a deterministic multi-tape Turing machine, where each tape represents a distinct component: input characters, tokens, vocabulary, model parameters, activations, probability distributions, and output text. The model enables precise localisation of failure modes to specific pipeline stages, revealing, e.g., how tokenisation obscures character-level structure needed for counting tasks. The model clarifies why techniques like chain-of-thought prompting help, by externalising computation on the output tape, while also revealing their fundamental limitations. This approach provides a rigorous, falsifiable alternative to geometric metaphors and complements empirical scaling laws with principled error analysis.

</details>


### [88] [Understand Then Memory: A Cognitive Gist-Driven RAG Framework with Global Semantic Diffusion](https://arxiv.org/abs/2602.15895)
*Pengcheng Zhou,Haochen Li,Zhiqiang Nie,JiaLe Chen,Qing Gong,Weizhen Zhang,Chun Yu*

Main category: cs.CL

TL;DR: 本文提出了一种名为CogitoRAG的检索增强生成（RAG）框架，通过模拟人类认知记忆机制，利用“语义要点”和多维度知识图谱来提升LLM处理复杂查询和知识整合的能力，并在多项QA基准测试和多任务生成上取得了显著优于现有SOTA RAG方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG框架中文本离散表示导致语义完整性损失，引起检索偏差，启发研究者借鉴人类的“情景记忆”机制来改进RAG。

Method: CogitoRAG框架包含离线索引和在线检索两个阶段。离线阶段，将非结构化语料库提取成“语义要点”语料库，并转化为多维知识图谱（包含实体、关系和记忆节点）。在线阶段，通过查询分解模块处理复杂查询，通过实体扩散模块进行关联检索，并使用CogniRank算法融合扩散分数和语义相似度进行重排序。最终以“段落-记忆”配对的形式提供信息。

Result: 在五个主流QA基准测试和GraphBench的多任务生成上，CogitoRAG显著优于最先进的RAG方法，展现出在复杂知识整合和推理方面的卓越能力。

Conclusion: CogitoRAG通过模拟人类认知记忆过程，有效解决了现有RAG框架的局限性，在复杂知识整合和推理方面取得了显著的性能提升。

Abstract: Retrieval-Augmented Generation (RAG) effectively mitigates hallucinations in LLMs by incorporating external knowledge. However, the inherent discrete representation of text in existing frameworks often results in a loss of semantic integrity, leading to retrieval deviations. Inspired by the human episodic memory mechanism, we propose CogitoRAG, a RAG framework that simulates human cognitive memory processes. The core of this framework lies in the extraction and evolution of the Semantic Gist. During the offline indexing stage, CogitoRAG first deduces unstructured corpora into gist memory corpora, which are then transformed into a multi-dimensional knowledge graph integrating entities, relational facts, and memory nodes. In the online retrieval stage, the framework handles complex queries via Query Decomposition Module that breaks them into comprehensive sub-queries, mimicking the cognitive decomposition humans employ for complex information. Subsequently, Entity Diffusion Module performs associative retrieval across the graph, guided by structural relevance and an entity-frequency reward mechanism. Furthermore, we propose the CogniRank algorithm, which precisely reranks candidate passages by fusing diffusion-derived scores with semantic similarity. The final evidence is delivered to the generator in a passage-memory pairing format, providing high-density information support. Experimental results across five mainstream QA benchmarks and multi-task generation on GraphBench demonstrate that CogitoRAG significantly outperforms state-of-the-art RAG methods, showcasing superior capabilities in complex knowledge integration and reasoning.

</details>


### [89] [DocSplit: A Comprehensive Benchmark Dataset and Evaluation Approach for Document Packet Recognition and Splitting](https://arxiv.org/abs/2602.15958)
*Md Mofijul Islam,Md Sirajus Salekin,Nivedha Balakrishnan,Vincil C. Bishop,Niharika Jain,Spencer Romo,Bob Strahan,Boyi Xie,Diego A. Socolinsky*

Main category: cs.CL

TL;DR: 本文提出了第一个用于文档包分割的基准数据集DocSplit和新的评估指标，以解决多页异构文档包的分割问题，并评估了现有大语言模型的能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的文档理解任务经常涉及处理包含多个拼接文档的异构、多页文档包，而现有的视觉文档理解技术在文档包分割这一基础任务上研究不足。

Method: 创建了一个包含五个不同复杂度和类型的文档包分割数据集（DocSplit），并定义了识别文档边界、分类文档类型和保持页面顺序的新评估指标。对现有的大语言模型进行了广泛的实验评估。

Result: 现有的大语言模型在处理复杂的文档包分割任务时存在显著的性能差距。

Conclusion: DocSplit基准数据集和新的评估指标为推动文档理解能力，特别是在文档包分割方面，提供了系统性的框架，对法律、金融、医疗等领域具有重要意义。

Abstract: Document understanding in real-world applications often requires processing heterogeneous, multi-page document packets containing multiple documents stitched together. Despite recent advances in visual document understanding, the fundamental task of document packet splitting, which involves separating a document packet into individual units, remains largely unaddressed. We present the first comprehensive benchmark dataset, DocSplit, along with novel evaluation metrics for assessing the document packet splitting capabilities of large language models. DocSplit comprises five datasets of varying complexity, covering diverse document types, layouts, and multimodal settings. We formalize the DocSplit task, which requires models to identify document boundaries, classify document types, and maintain correct page ordering within a document packet. The benchmark addresses real-world challenges, including out-of-order pages, interleaved documents, and documents lacking clear demarcations. We conduct extensive experiments evaluating multimodal LLMs on our datasets, revealing significant performance gaps in current models' ability to handle complex document splitting tasks. The DocSplit benchmark datasets and proposed novel evaluation metrics provide a systematic framework for advancing document understanding capabilities essential for legal, financial, healthcare, and other document-intensive domains. We release the datasets to facilitate future research in document packet processing.

</details>


### [90] [Towards Fair and Efficient De-identification: Quantifying the Efficiency and Generalizability of De-identification Approaches](https://arxiv.org/abs/2602.15869)
*Noopur Zambare,Kiana Aghakasiri,Carissa Lin,Carrie Ye,J. Ross Mitchell,Mohamed Abdalla*

Main category: cs.CL

TL;DR: 该研究评估了不同规模的 LLM 在临床去标识化任务中的表现，发现小型 LLM 在性能和成本之间取得了良好的平衡，并且可以通过有限的多语言数据进行微调，以提升在不同文化背景下的泛化能力。研究者还发布了一个名为 BERT-MultiCulture-DEID 的多文化去标识化模型集。


<details>
  <summary>Details</summary>
Motivation: 现有研究在评估 LLM 进行临床去标识化时的泛化能力方面存在不足，尤其是在不同格式、文化和性别方面。因此，需要系统地评估 LLM 的效率-泛化能力权衡，并探索在多文化背景下实现公平高效去标识化的可行方法。

Method: 研究者系统地评估了多种模型的去标识化性能，包括微调的 Transformer 模型（BERT, ClinicalBERT, ModernBERT）、小型 LLM（Llama 1-8B, Qwen 1.5-7B）和大型 LLM（Llama-70B, Qwen-72B）。为了提高多文化背景下的鲁棒性，研究者引入并发布了 BERT-MultiCulture-DEID 模型集，该模型集基于 BERT 系列模型，并在包含多种语言变体的 MIMIC 数据集上进行了微调。

Result: 研究表明，小型 LLM 在去标识化任务上能达到与大型模型相当的性能，同时显著降低了推理成本，更适合实际部署。通过使用有限的多语言数据进行微调，小型模型在去标识化普通话、印地语、西班牙语、法语、孟加拉语、英语地区变体以及性别化名称方面，表现优于大型模型。

Conclusion: 该研究提供了对去标识化任务中效率-泛化能力权衡的首次全面量化，并为实现公平高效的临床去标识化提供了实际途径。小型 LLM 在成本和性能之间取得了良好平衡，并且可以通过有限的多语言数据进行有效微调，以适应不同文化背景的需求。

Abstract: Large language models (LLMs) have shown strong performance on clinical de-identification, the task of identifying sensitive identifiers to protect privacy. However, previous work has not examined their generalizability between formats, cultures, and genders. In this work, we systematically evaluate fine-tuned transformer models (BERT, ClinicalBERT, ModernBERT), small LLMs (Llama 1-8B, Qwen 1.5-7B), and large LLMs (Llama-70B, Qwen-72B) at de-identification. We show that smaller models achieve comparable performance while substantially reducing inference cost, making them more practical for deployment. Moreover, we demonstrate that smaller models can be fine-tuned with limited data to outperform larger models in de-identifying identifiers drawn from Mandarin, Hindi, Spanish, French, Bengali, and regional variations of English, in addition to gendered names. To improve robustness in multi-cultural contexts, we introduce and publicly release BERT-MultiCulture-DEID, a set of de-identification models based on BERT, ClinicalBERT, and ModernBERT, fine-tuned on MIMIC with identifiers from multiple language variants. Our findings provide the first comprehensive quantification of the efficiency-generalizability trade-off in de-identification and establish practical pathways for fair and efficient clinical de-identification.
  Details on accessing the models are available at: https://doi.org/10.5281/zenodo.18342291

</details>


### [91] [VDLM: Variable Diffusion LMs via Robust Latent-to-Text Rendering](https://arxiv.org/abs/2602.15870)
*Shuhui Qu*

Main category: cs.CL

TL;DR: 本文提出了一种名为VDLM的模块化变量扩散语言模型，它通过将语义规划与文本渲染分离，并在潜在空间中进行迭代精炼，显著提升了多步推理任务的长文本生成能力。


<details>
  <summary>Details</summary>
Motivation: 传统的自回归语言模型在多步推理过程中，由于其从左到右的不可逆解码特性，限制了推理过程中的修正能力。

Method: VDLM模型将语义规划与文本渲染分离。它首先在LLaDA风格的掩码扩散模型上对语义变量嵌入进行操作，以在潜在空间中实现迭代精炼。然后，使用嵌入空间的奖励和值进行轨迹感知优化来后训练规划器，避免在强化学习循环中进行文本解码。最后，使用Vec2Text渲染器将规划好的嵌入转换回文本，并引入嵌入扰动来增强解码在规划器噪声下的鲁棒性。

Result: 在通用推理、数学和代码等九个基准测试中，VDLM在预训练阶段表现具有竞争力，并在长文本生成任务上显示出显著的后训练改进，优于其他基线模型。

Conclusion: 研究结果表明，在扩散语言模型中进行嵌入空间的后训练以及采用鲁棒的潜在空间到文本渲染是提高模型性能的有效方法。

Abstract: Autoregressive language models decode left-to-right with irreversible commitments, limiting revision during multi-step reasoning. We propose \textbf{VDLM}, a modular variable diffusion language model that separates semantic planning from text rendering. VDLM applies LLaDA-style masked diffusion over semantic variable embeddings to enable iterative refinement in latent space, then post-trains the planner with trajectory-aware optimization using embedding-space rewards and values, avoiding text decoding inside the RL loop. To convert planned embeddings back to text, we use a \textbf{Vec2Text} renderer and introduce \textbf{embedding perturbations} to robustify decoding under planner noise. Across nine benchmarks spanning general reasoning, math, and code, VDLM is competitive in pre-training and yields substantial post-training improvements on long-form generation tasks, outperforming other baselines. These results highlight the effectiveness of embedding-space post-training and robust latent-to-text rendering for diffusion language modeling.

</details>


### [92] [Doc-to-LoRA: Learning to Instantly Internalize Contexts](https://arxiv.org/abs/2602.15902)
*Rujikorn Charakorn,Edoardo Cetin,Shinnosuke Uesaka,Robert Tjarko Lange*

Main category: cs.CL

TL;DR: 提出了一种名为 Doc-to-LoRA (D2L) 的轻量级超网络，它可以在单次前向传播中执行近似上下文蒸馏，从而解决 Transformer 模型处理长输入序列时注意力机制的二次成本问题。D2L 为目标 LLM 生成 LoRA 适配器，以存储上下文信息，从而减少推理时的延迟和 KV 缓存内存消耗。


<details>
  <summary>Details</summary>
Motivation: Transformer 模型在处理长输入序列（如 in-context learning、文档理解和多步推理）时，注意力机制的二次成本导致推理过程内存密集且速度缓慢。现有的上下文蒸馏（CD）方法虽然有效，但按提示进行蒸馏的成本过高且延迟大，不切实际。

Method: 提出 Doc-to-LoRA (D2L)，一种轻量级超网络。D2L 通过元学习，在单次前向传播中学习执行近似上下文蒸馏。给定一个未见过的提示，D2L 会为目标 LLM 生成一个 LoRA 适配器，该适配器可以存储来自原始上下文的信息。后续查询可以直接使用该适配器，无需重新消耗原始上下文。

Result: 在长上下文的“针海找针”任务上，D2L 成功将上下文信息映射到适配器中，实现了接近完美的零样本准确率，序列长度超过了目标 LLM 的原生上下文窗口的 4 倍以上。在计算资源有限的真实世界 QA 数据集上，D2L 的表现优于标准的上下文蒸馏方法，同时显著降低了峰值内存消耗和更新延迟。

Conclusion: D2L 是一种有效且轻量级的方法，可以克服长序列输入 LLM 的挑战。它通过生成 LoRA 适配器实现了高效的上下文信息存储和检索，显著提高了推理效率并降低了计算成本。D2L 有望促进 LLM 的快速适应，实现频繁的知识更新和个性化聊天行为。

Abstract: Long input sequences are central to in-context learning, document understanding, and multi-step reasoning of Large Language Models (LLMs). However, the quadratic attention cost of Transformers makes inference memory-intensive and slow. While context distillation (CD) can transfer information into model parameters, per-prompt distillation is impractical due to training costs and latency. To address these limitations, we propose Doc-to-LoRA (D2L), a lightweight hypernetwork that meta-learns to perform approximate CD within a single forward pass. Given an unseen prompt, D2L generates a LoRA adapter for a target LLM, enabling subsequent queries to be answered without re-consuming the original context, reducing latency and KV-cache memory consumption during inference of the target LLM. On a long-context needle-in-a-haystack task, D2L successfully learns to map contexts into adapters that store the needle information, achieving near-perfect zero-shot accuracy at sequence lengths exceeding the target LLM's native context window by more than 4x. On real-world QA datasets with limited compute, D2L outperforms standard CD while significantly reducing peak memory consumption and update latency. We envision that D2L can facilitate rapid adaptation of LLMs, opening up the possibility of frequent knowledge updates and personalized chat behavior.

</details>


### [93] [CheckIfExist: Detecting Citation Hallucinations in the Era of AI-Generated Content](https://arxiv.org/abs/2602.15871)
*Diletta Abbonato*

Main category: cs.CL

TL;DR: 本文提出了一种名为CheckIfExist的开源在线工具，用于通过CrossRef、Semantic Scholar和OpenAlex等多个数据库验证文献引用的真实性，以解决大型语言模型可能产生的虚假引用问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在学术界的应用带来了文献完整性方面的挑战，特别是生成不存在的虚假引用，这在顶级机器学习会议论文中也已出现，因此迫切需要自动化验证机制。

Method: 开发了一个基于Web的工具CheckIfExist，采用多源验证（CrossRef, Semantic Scholar, OpenAlex）和字符串相似度算法计算多维度匹配置信度分数，并通过级联验证架构实现。支持单条引用和BibTeX批量处理。

Result: 该工具能够提供即时反馈，验证引用的真实性，并返回APA格式的引用和可导出的BibTeX记录。

Conclusion: CheckIfExist作为一种免费、开源的解决方案，填补了现有文献管理工具和商业服务在实时引用真实性验证方面的空白，有效解决了LLM可能引入的虚假引用问题。

Abstract: The proliferation of large language models (LLMs) in academic workflows has introduced unprecedented challenges to bibliographic integrity, particularly through reference hallucination -- the generation of plausible but non-existent citations. Recent investigations have documented the presence of AI-hallucinated citations even in papers accepted at premier machine learning conferences such as NeurIPS and ICLR, underscoring the urgency of automated verification mechanisms. This paper presents "CheckIfExist", an open-source web-based tool designed to provide immediate verification of bibliographic references through multi-source validation against CrossRef, Semantic Scholar, and OpenAlex scholarly databases. While existing reference management tools offer bibliographic organization capabilities, they do not provide real-time validation of citation authenticity. Commercial hallucination detection services, though increasingly available, often impose restrictive usage limits on free tiers or require substantial subscription fees. The proposed tool fills this gap by employing a cascading validation architecture with string similarity algorithms to compute multi-dimensional match confidence scores, delivering instant feedback on reference authenticity. The system supports both single-reference verification and batch processing of BibTeX entries through a unified interface, returning validated APA citations and exportable BibTeX records within seconds.

</details>


### [94] [Language Statistics and False Belief Reasoning: Evidence from 41 Open-Weight LMs](https://arxiv.org/abs/2602.16085)
*Sean Trott,Samuel Taylor,Cameron Jones,James A. Michaelov,Pamela D. Rivière*

Main category: cs.CL

TL;DR: 研究了41个开源语言模型在理解他人意图（虚假信念任务）方面的能力，发现约34%的模型表现出一定程度的理解，但没有模型能完全解释人类的反应。研究还发现，模型大小与理解能力和预测能力呈正相关。此外，研究提出并验证了一个新假设：人类和模型都更容易在非事实性动词（如“认为”）引导下，而非间接线索下，归因虚假信念。这一发现表明，语言的统计规律可能不足以解释人类在识别知识状态上的敏感性，但可能足以解释模型在这方面的行为。


<details>
  <summary>Details</summary>
Motivation: 现有关于语言模型（LMs）的心智状态推理研究主要基于少量闭源模型，限制了对人类社会认知理论的严谨检验和对LM能力的全面评估。因此，研究者希望通过更大规模的开源模型来扩展和深化这一研究。

Method: 研究者选取了41个不同家族的开源权重模型，对它们进行了虚假信念任务的测试，并与人类行为进行了对比。通过分析模型在不同条件下的反应，评估其对隐含知识状态的敏感性，并考察模型大小与其表现的关系。同时，研究者利用模型的行为数据提出了关于人类认知的新假设，并对其进行了检验。

Result: 在测试的41个模型中，34%的模型表现出对隐含知识状态的敏感性。然而，与先前研究一致，没有模型能够完全“消除”人类反应中的虚假信念效应。更大的模型表现出更高的敏感性和更强的心理测量预测能力。研究还发现，人类和模型在通过非事实性动词（如“认为”）而非间接线索（如“看”）来提示知识状态时，都表现出更强的归因虚假信念的倾向。

Conclusion: 使用更大规模的开源模型样本有助于更有效地检验人类认知理论和评估语言模型的能力。研究结果表明，语言的统计分布可能能够解释模型在识别知识状态上的某些行为，但不足以完全解释人类在这方面的敏感性。

Abstract: Research on mental state reasoning in language models (LMs) has the potential to inform theories of human social cognition--such as the theory that mental state reasoning emerges in part from language exposure--and our understanding of LMs themselves. Yet much published work on LMs relies on a relatively small sample of closed-source LMs, limiting our ability to rigorously test psychological theories and evaluate LM capacities. Here, we replicate and extend published work on the false belief task by assessing LM mental state reasoning behavior across 41 open-weight models (from distinct model families). We find sensitivity to implied knowledge states in 34% of the LMs tested; however, consistent with prior work, none fully ``explain away'' the effect in humans. Larger LMs show increased sensitivity and also exhibit higher psychometric predictive power. Finally, we use LM behavior to generate and test a novel hypothesis about human cognition: both humans and LMs show a bias towards attributing false beliefs when knowledge states are cued using a non-factive verb (``John thinks...'') than when cued indirectly (``John looks in the...''). Unlike the primary effect of knowledge states, where human sensitivity exceeds that of LMs, the magnitude of the human knowledge cue effect falls squarely within the distribution of LM effect sizes-suggesting that distributional statistics of language can in principle account for the latter but not the former in humans. These results demonstrate the value of using larger samples of open-weight LMs to test theories of human cognition and evaluate LM capacities.

</details>


### [95] [Updating Parametric Knowledge with Context Distillation Retains Post-Training Capabilities](https://arxiv.org/abs/2602.16093)
*Shankar Padmanabhan,Mustafa Omer Gul,Tanya Goyal*

Main category: cs.CL

TL;DR: 提出了一种名为Distillation via Split Contexts (DiSC) 的新方法，用于持续适应预训练语言模型，使其能够学习新知识并避免遗忘旧能力。


<details>
  <summary>Details</summary>
Motivation: 现有的后训练大型语言模型（LLMs）知识有截止日期，需要持续适应。然而，现有方法无法同时学习新知识并防止遗忘旧能力。

Method: DiSC是一种基于上下文蒸馏的方法。它通过对训练示例的不同部分进行条件化来获得学生和教师分布，并最小化共享标记之间的KL散度。这种方法无需在训练过程中进行显式的生成步骤。

Result: 在四个后训练模型和两个适应领域进行的实验表明，DiSC在学习新知识和缓解遗忘（如指令遵循、推理和事实知识）方面，相比于之前的微调和蒸馏方法，取得了更好的权衡。

Conclusion: DiSC是一种有效且高效的持续知识适应方法，能够同时学习新知识并保留旧能力，优于现有的持续适应技术。

Abstract: Post-training endows pretrained LLMs with a variety of desirable skills, including instruction-following, reasoning, and others. However, these post-trained LLMs only encode knowledge up to a cut-off date, necessitating continual adaptation. Unfortunately, existing solutions cannot simultaneously learn new knowledge from an adaptation document corpora and mitigate the forgetting of earlier learned capabilities. To address this, we introduce Distillation via Split Contexts (DiSC), a simple context-distillation based approach for continual knowledge adaptation. \methodname~derives student and teacher distributions by conditioning on distinct segments of the training example and minimizes the KL divergence between the shared tokens. This allows us to efficiently apply context-distillation without requiring explicit generation steps during training. We run experiments on four post-trained models and two adaptation domains. Compared to prior finetuning and distillation methods for continual adaptation, DiSC consistently reports the best trade-off between learning new knowledge and mitigating forgetting of previously learned skills like instruction-following, reasoning, and factual knowledge.

</details>


### [96] [Quality-constrained Entropy Maximization Policy Optimization for LLM Diversity](https://arxiv.org/abs/2602.15894)
*Haihui Pan,Yuzhong Hong,Shaoke Lv,Junwei Bao,Hongfei Jiang,Yang Song*

Main category: cs.CL

TL;DR: 提出了一种名为QEMPO的方法，可以在提高LLM输出多样性的同时，保持甚至提升输出质量。


<details>
  <summary>Details</summary>
Motivation: 现有LLM对齐方法在提高输出质量的同时，会降低输出多样性。而现有的提高多样性的方法往往会牺牲性能。

Method: 理论上将对齐任务分解为质量和多样性两个分布，并提出了质量约束熵最大化策略优化（QEMPO）方法，旨在最大化策略的输出熵，同时保证输出质量。通过对QEMPO添加不同的约束，可以获得不同的策略，并提出了在线和离线训练方法来优化这些策略。

Result: 实验证明QEMPO在保证输出质量的同时，显著提高了LLM的输出多样性，且性能与RLHF相当甚至更好。

Conclusion: QEMPO是一种有效的方法，可以在不牺牲性能的情况下，同时提高LLM输出的质量和多样性。

Abstract: Recent research indicates that while alignment methods significantly improve the quality of large language model(LLM) outputs, they simultaneously reduce the diversity of the models' output. Although some methods have been proposed to enhance LLM output diversity, they often come at the cost of reduced performance. In this work, we first theoretically demonstrate that the alignment task can be decomposed into two distributions: quality and diversity. To enhance the diversity of LLM outputs while ensuring quality, we propose the Quality-constrained Entropy Maximization Policy Optimization (QEMPO). QEMPO aims to maximize the output entropy of the policy while ensuring output quality. By adding different constraints to QEMPO, we obtain different policies. To optimize policies, we propose both online and offline training methods. Experiments validate that QEMPO achieves performance comparable to or even better than RLHF while improving output diversity.

</details>


### [97] [P-RAG: Prompt-Enhanced Parametric RAG with LoRA and Selective CoT for Biomedical and Multi-Hop QA](https://arxiv.org/abs/2602.15874)
*Xingda Lyu,Gongfu Lyu,Zitai Yan,Yuxin Jiang*

Main category: cs.CL

TL;DR: 本文提出了一种名为P-RAG（Prompt-Enhanced Parametric RAG）的新型检索增强生成（RAG）架构，该架构结合了LLM的参数知识和检索到的外部知识，并利用Chain-of-Thought（CoT）提示和LoRA微调来优化。在PubMedQA和2WikiMultihopQA数据集上的实验表明，P-RAG在生物医学问答任务上显著优于标准RAG。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）受限于静态训练数据，而标准的检索增强生成（RAG）模型虽然引入了外部知识，但其性能高度依赖于知识库的质量。为了克服这些限制并提高问答系统的准确性和适应性，研究者们试图探索新的RAG架构。

Method: 研究者们提出了一种名为P-RAG（Prompt-Enhanced Parametric RAG）的混合架构。P-RAG将LLM的参数知识与检索到的外部证据相结合，并通过Chain-of-Thought（CoT）提示引导推理过程，同时利用Low-Rank Adaptation（LoRA）进行微调。实验使用了经过LoRA微调的LLaMA-3.2-1B-Instruct模型，并在PubMedQA和2WikiMultihopQA两个数据集上进行了评估。

Result: P-RAG在PubMedQA数据集上的F1分数比标准RAG高出10.47个百分点（93.33% vs. 82.86%）。在2WikiMultihopQA数据集上，P-RAG的整体得分几乎是标准RAG的两倍（33.44% vs. 17.83%）。CoT提示在多步推理方面有显著提升，但对单步查询效果不一。

Conclusion: P-RAG架构通过结合参数知识、检索知识、CoT提示和LoRA微调，在生物医学问答任务中展现了优越的性能，证明了其在准确性、可扩展性和上下文适应性方面的潜力。研究成果包括LoRA微调LLaMA模型、P-RAG架构及其在两个基准数据集上取得的先进结果。

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities but remain limited by their reliance on static training data. Retrieval-Augmented Generation (RAG) addresses this constraint by retrieving external knowledge during inference, though it still depends heavily on knowledge base quality. To explore potential improvements, we evaluated three RAG variants-Standard RAG, DA-RAG, and our proposed Prompt-Enhanced Parametric RAG (P-RAG), a hybrid architecture that integrates parametric knowledge within the LLM and retrieved evidence, guided by Chain-of-Thought (CoT) prompting and Low-Rank Adaptation (LoRA) fine-tuning-on both general and biomedical datasets. Using LLaMA-3.2-1B-Instruct fine-tuned via LoRA, we evaluate on PubMedQA and 2WikiMultihopQA. P-RAG outperforms Standard RAG on PubMedQA by 10.47 percentage points in F1 (93.33% vs. 82.86%; 12.64% relative). On 2WikiMultihopQA, P-RAG nearly doubles the overall score vs. Standard RAG (33.44% vs. 17.83%) and achieves 44.03% on the Compare subset (with 42.74% Bridge, 21.84% Inference, 8.60% Compose). CoT prompting substantially improves multi-hop reasoning but yields mixed results for simpler, single-hop queries. These findings underscore P-RAG's potential for accurate, scalable, and contextually adaptive biomedical question answering. Our contributions include: (1) LoRA-based fine-tuning of LLaMA-3.2-1B-Instruct for biomedical QA, (2) introduction of P-RAG with Chain-of-Thought prompting, and (3) state-of-the-art results on PubMedQA and 2WikiMultihopQA.

</details>


### [98] [Balancing Faithfulness and Performance in Reasoning via Multi-Listener Soft Execution](https://arxiv.org/abs/2602.16154)
*Nithin Sivakumaran,Shoubin Yu,Hyunji Lee,Yue Zhang,Ali Payani,Mohit Bansal,Elias Stengel-Eskin*

Main category: cs.CL

TL;DR: 本文提出了一种名为REMUL的多方强化学习方法，通过让多个“听众”模型理解“说话者”生成的推理过程，来提高大型语言模型（LLM）的推理过程与实际计算的一致性（即忠实性），同时不牺牲任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思考（CoT）推理有时无法真实反映LLM的计算过程，阻碍了其解释能力。此外，提升推理的忠实性和可解释性常常会损害任务性能。作者希望解决这种忠实性与性能之间的权衡问题。

Method: REMUL采用多方强化学习，其中一个“说话者”模型生成推理过程，然后将其截断传递给一组“听众”模型。听众模型负责“执行”推理过程并得出答案。说话者模型会根据其推理过程的清晰度（即听众理解的程度）获得奖励。此外，通过掩码监督微调进行额外的正确性正则化，以对抗忠实性与性能之间的权衡。

Result: 在BIG-Bench Extra Hard、MuSR、ZebraLogicBench和FOLIO等多个推理基准上，REMUL在提示归因、早期回答面积（AOC）和错误注入AOC三个忠实性指标上都取得了持续且显著的提升，同时准确率也有所提高。

Conclusion: REMUL成功地提升了LLM推理过程的忠实性，并且这种提升是稳健的，能够在不同训练领域中泛化，同时也能提高推理的可读性，并产生更短、更直接的链式思考。

Abstract: Chain-of-thought (CoT) reasoning sometimes fails to faithfully reflect the true computation of a large language model (LLM), hampering its utility in explaining how LLMs arrive at their answers. Moreover, optimizing for faithfulness and interpretability in reasoning often degrades task performance. To address this tradeoff and improve CoT faithfulness, we propose Reasoning Execution by Multiple Listeners (REMUL), a multi-party reinforcement learning approach. REMUL builds on the hypothesis that reasoning traces which other parties can follow will be more faithful. A speaker model generates a reasoning trace, which is truncated and passed to a pool of listener models who "execute" the trace, continuing the trace to an answer. Speakers are rewarded for producing reasoning that is clear to listeners, with additional correctness regularization via masked supervised finetuning to counter the tradeoff between faithfulness and performance. On multiple reasoning benchmarks (BIG-Bench Extra Hard, MuSR, ZebraLogicBench, and FOLIO), REMUL consistently and substantially improves three measures of faithfulness -- hint attribution, early answering area over the curve (AOC), and mistake injection AOC -- while also improving accuracy. Our analysis finds that these gains are robust across training domains, translate to legibility gains, and are associated with shorter and more direct CoTs.

</details>


### [99] [Every Little Helps: Building Knowledge Graph Foundation Model with Fine-grained Transferable Multi-modal Tokens](https://arxiv.org/abs/2602.15896)
*Yichi Zhang,Zhuo Chen,Lingbing Guo,Wen Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为 TOFU 的基于 token 的多模态知识图谱推理（MMKGR）基础模型，该模型通过将结构、视觉和文本信息离散化为 token，并采用分层融合机制，实现了跨不同 MMKGs 的强大泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有 MMKGR 方法多为转导式设置，难以泛化到新知识图谱；而现有的知识图谱基础模型（KGFMs）主要关注结构信息，忽略了多模态信号。

Method: TOFU 将结构、视觉和文本信息转化为模态特定的 token，并使用带有混合消息机制的分层融合架构来处理这些 token，以获得可迁移的 MMKGR 特征。

Result: 在 17 个转导式、归纳式和全归纳式 MMKGs 上的实验表明，TOFU 在未见过的数据集上始终优于强大的 KGFM 和 MMKGR 基线模型。

Conclusion: TOFU 是一种具有强大跨 MMKG 泛化能力的 token 化基础模型，能够有效利用多模态信息进行知识图谱推理。

Abstract: Multi-modal knowledge graph reasoning (MMKGR) aims to predict the missing links by exploiting both graph structure information and multi-modal entity contents. Most existing works are designed for a transductive setting, which learns dataset-specific embeddings and struggles to generalize to new KGs. Recent knowledge graph foundation models (KGFMs) improve cross-KG transfer, but they mainly exploit structural patterns and ignore rich multi-modal signals. We address these gaps by proposing a token-based foundation model (TOFU) for MMKGR, which exhibits strong generalization across different MMKGs. TOFU discretizes structural, visual, and textual information into modality-specific tokens. TOFU then employs a hierarchical fusion architecture with mixture-of-message mechanisms, aiming to process these tokens and obtain transferable features for MMKGR. Experimental results on 17 transductive, inductive, and fully-inductive MMKGs show that TOFU consistently outperforms strong KGFM and MMKGR baselines, delivering strong performance on unseen MMKGs.

</details>


### [100] [Beyond Learning: A Training-Free Alternative to Model Adaptation](https://arxiv.org/abs/2602.16189)
*Namkyung Yoon,Kyeonghyun Yoo,Wooyong Jung,Sanghong Kim,Hwangnam Kim*

Main category: cs.CL

TL;DR: 研究提出了一种“模型移植”技术，通过识别并移植语言模型内部的特定功能模块，可以在不进行额外训练的情况下，显著提升模型在特定任务上的性能，尤其能改善性能下降的模型。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在持续研究和演进中，有时会出现性能不如先前版本的情况。而克服这些挑战的现有方法通常资源消耗大，因此需要更快捷、易于实施的替代方案。

Method: 首先，通过激活分析识别出在推理负载下表现出一致且局部激活变化的模块。然后，将为特定任务而激活的内部模块移植到目标模型中，实现无需额外训练或微调的即时功能改进。实验通过量化移植强度与性能提升的关系来验证此技术的有效性。

Result: 在跨生成设置中，移植激活选择的模块可以将性能下降的模型提升至目标基线水平的两倍，性能恢复超过100%。在基础模型与其指令微调版本之间的移植实验中，可以将性能较差的模型提升至更强基线水平的约2.33倍，性能恢复最高可达100%。

Conclusion: 研究结果表明，通过移植高度局部化的模块，可以实现有意义的能力迁移。这项工作为语言模型中的任务局部模块化提供了实证证据，并开创了一个新的研究领域：模型移植。

Abstract: Despite the continuous research and evolution of language models, they sometimes underperform previous versions. Existing approaches to overcome these challenges are resource-intensive, highlighting the need for alternatives that enable immediate action. We assume that each language model has a local module inside that is suitable for a specific function. First, this work identifies a set of modules showing consistent and local activation changes under an inference workload through activation-based analysis. Subsequently, we transplant an internal module that is properly activated for a specific task into the target model, leading to immediate and measurable functional changes without additional training or fine-tuning. To experimentally demonstrate the effectiveness of the transplant technique, we quantify the relationship between transplant strength and performance improvement under different conditions for two language models. In the cross-generation setting, we find that transplanting activation-selected modules can substantially improve the underperforming model, reaching up to twice the target baseline and achieving gap-based recovery above 100%. Moreover, in transplant experiments between a base model and its instruction-tuned counterpart, transplantation improves the underperforming model toward the stronger baseline, yielding up to about 2.33 times the target baseline with gap-based recovery reaching up to 100% in the best case. These results show that meaningful capacity transfer can be realized through the implantation of highly localized modules implied by language models. Overall, this work provides empirical evidence for task-localized modularity in language models and presents a new research area: model transplantation.

</details>


### [101] [Mitigating Gradient Inversion Risks in Language Models via Token Obfuscation](https://arxiv.org/abs/2602.15897)
*Xinguo Feng,Zhongkui Ma,Zihan Wang,Alsharif Abuadbba,Guangdong Bai*

Main category: cs.CL

TL;DR: 本研究提出了一种名为GHOST的梯度防御机制，通过在token级别进行混淆来对抗梯度反演攻击（GIAs），有效保护隐私并保持模型效用。


<details>
  <summary>Details</summary>
Motivation: 现有的梯度防御方法（如梯度扰动）在对抗梯度反演攻击（GIAs）方面效果有限，因为它们未能完全打破梯度、嵌入和token空间之间的语义联系。GIAs可以利用共享梯度重构私有训练数据，对模型训练的隐私性构成威胁。

Method: GHOST通过token级别的混淆来解耦梯度、嵌入和token空间之间的联系。其核心思想是利用token空间中存在语义不同但嵌入相似的token作为“影子替身”，从而在token空间实现语义上的解耦，同时保持嵌入和梯度空间的联系。GHOST包含一个多标准搜索过程来识别语义上不同的候选token，以及一个选择过程来挑选最优的影子token，以最小化对模型训练关键特征的干扰。

Result: 在BERT和Llama等模型架构以及不同数据集上的评估表明，GHOST在保护隐私方面效果显著（恢复率低至1%），在保持模型效用方面也表现出色（分类F1值高达0.92，困惑度仅为5.45）。该方法在分类和生成任务中，对抗最先进的GIAs和自适应攻击均取得了良好效果。

Conclusion: GHOST是一种有效的token级混淆防御机制，能够显著提升大规模语言模型在协作学习中的隐私性，同时对模型效用造成的负面影响很小，为解决梯度反演攻击问题提供了一种新颖且有效的方法。

Abstract: Training and fine-tuning large-scale language models largely benefit from collaborative learning, but the approach has been proven vulnerable to gradient inversion attacks (GIAs), which allow adversaries to reconstruct private training data from shared gradients. Existing defenses mainly employ gradient perturbation techniques, e.g., noise injection or gradient pruning, to disrupt GIAs' direct mapping from gradient space to token space. However, these methods often fall short due to the retention of semantics similarity across gradient, embedding, and token spaces. In this work, we propose a novel defense mechanism named GHOST (gradient shield with obfuscated tokens), a token-level obfuscation mechanism that neutralizes GIAs by decoupling the inherent connections across gradient, embedding, and token spaces. GHOST is built upon an important insight: due to the large scale of the token space, there exist semantically distinct yet embedding-proximate tokens that can serve as the shadow substitutes of the original tokens, which enables a semantic disconnection in the token space while preserving the connection in the embedding and gradient spaces. GHOST comprises a searching step, which identifies semantically distinct candidate tokens using a multi-criteria searching process, and a selection step, which selects optimal shadow tokens to ensure minimal disruption to features critical for training by preserving alignment with the internal outputs produced by original tokens. Evaluation across diverse model architectures (from BERT to Llama) and datasets demonstrates the remarkable effectiveness of GHOST in protecting privacy (as low as 1% in recovery rate) and preserving utility (up to 0.92 in classification F1 and 5.45 in perplexity), in both classification and generation tasks against state-of-the-art GIAs and adaptive attack scenarios.

</details>


### [102] [Long-Tail Knowledge in Large Language Models: Taxonomy, Mechanisms, Interventions and Implications](https://arxiv.org/abs/2602.16201)
*Sanket Badhe,Deep Shah,Nehal Kathrotia*

Main category: cs.CL

TL;DR: 本文提出一个分析大型语言模型（LLM）中长尾知识的框架，该框架涵盖了长尾知识的定义、训练和推理过程中知识的丢失或扭曲机制、缓解这些失败的技术干预措施，以及这些失败对公平、问责、透明度和用户信任的影响。此外，研究还探讨了现有评估方法如何掩盖长尾行为并使罕见但重要的失败的问责复杂化，并指出了与隐私、可持续性和治理相关的开放性挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM的平均性能有所提高，但它们在低频、领域特定、文化和时间知识方面仍存在持续的故障，这尚未得到充分表征，并且这些故障的潜在原因和影响尚不清楚。

Method: 研究者开发了一个结构化的分析框架，该框架从四个互补的维度对现有工作进行综合：长尾知识的定义、训练和推理过程中知识丢失或扭曲的机制、缓解这些失败的技术干预措施，以及这些失败对公平、问责、透明度和用户信任的影响。此外，研究还检查了现有评估实践如何掩盖长尾行为并使问责复杂化，并指出了相关的开放性挑战。

Result: 研究提出了一个关于LLM中长尾知识的结构化分类法和分析方法。该框架能够定义、理解知识丢失/扭曲的机制、评估干预措施，并分析其对公平、问责、透明度和用户信任的影响。研究还指出，现有评估方法可能掩盖长尾行为，并使问责复杂化。

Conclusion: 本文提供了一个统一的概念框架，用于理解长尾知识在已部署的语言模型系统中如何被定义、丢失、评估和体现。研究还强调了与隐私、可持续性和治理相关的开放性挑战，这些挑战限制了长尾知识的表示。

Abstract: Large language models (LLMs) are trained on web-scale corpora that exhibit steep power-law distributions, in which the distribution of knowledge is highly long-tailed, with most appearing infrequently. While scaling has improved average-case performance, persistent failures on low-frequency, domain-specific, cultural, and temporal knowledge remain poorly characterized. This paper develops a structured taxonomy and analysis of long-Tail Knowledge in large language models, synthesizing prior work across technical and sociotechnical perspectives.
  We introduce a structured analytical framework that synthesizes prior work across four complementary axes: how long-Tail Knowledge is defined, the mechanisms by which it is lost or distorted during training and inference, the technical interventions proposed to mitigate these failures, and the implications of these failures for fairness, accountability, transparency, and user trust. We further examine how existing evaluation practices obscure tail behavior and complicate accountability for rare but consequential failures. The paper concludes by identifying open challenges related to privacy, sustainability, and governance that constrain long-Tail Knowledge representation. Taken together, this paper provides a unifying conceptual framework for understanding how long-Tail Knowledge is defined, lost, evaluated, and manifested in deployed language model systems.

</details>


### [103] [MultiCube-RAG for Multi-hop Question Answering](https://arxiv.org/abs/2602.15898)
*Jimeng Shi,Wei Hu,Runchu Tian,Bowen Jin,Wonbin Kweon,SeongKu Kang,Yunfan Kang,Dingqi Ye,Sizhe Zhou,Shaowen Wang,Jiawei Han*

Main category: cs.CL

TL;DR: 提出了一种名为 MultiCube-RAG 的无训练方法，利用基于本体的立方体结构来解决多跳问答中的多步推理和检索问题，通过将复杂查询分解为子查询并利用专业化的立方体来提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法在捕捉多跳问答中的结构化语义方面存在不足，基于图的方法会产生噪声且计算成本高。训练方法则存在收敛不稳定和计算开销大的问题。因此，需要一种更有效、更准确的方法来处理多跳问答。

Method: 提出了一种基于本体的立方体结构，具有多个正交维度来建模主题、属性和关系。在此基础上，开发了 MultiCube-RAG，一种无训练方法。该方法使用多个立方体进行多步推理和检索，每个立方体专注于一类主题，允许灵活选择最合适的立方体。通过将复杂的多跳查询分解为沿立方体维度的简单子查询，并顺序处理，以增强查询驱动的推理和检索。

Result: 在四个多跳问答数据集上的实验表明，MultiCube-RAG 的响应准确率比各种基线方法的平均性能提高了 8.9%。同时，证明了该方法具有更高的效率和固有的可解释性。

Conclusion: MultiCube-RAG 是一种有效的无训练方法，通过创新的立方体结构和查询分解策略，解决了多跳问答中的挑战，并在准确性、效率和可解释性方面取得了显著的改进。

Abstract: Multi-hop question answering (QA) necessitates multi-step reasoning and retrieval across interconnected subjects, attributes, and relations. Existing retrieval-augmented generation (RAG) methods struggle to capture these structural semantics accurately, resulting in suboptimal performance. Graph-based RAGs structure such information in graphs, but the resulting graphs are often noisy and computationally expensive. Moreover, most methods rely on single-step retrieval, neglecting the need for multi-hop reasoning processes. Recent training-based approaches attempt to incentivize the large language models (LLMs) for iterative reasoning and retrieval, but their training processes are prone to unstable convergence and high computational overhead. To address these limitations, we devise an ontology-based cube structure with multiple and orthogonal dimensions to model structural subjects, attributes, and relations. Built on the cube structure, we propose MultiCube-RAG, a training-free method consisting of multiple cubes for multi-step reasoning and retrieval. Each cube specializes in modeling a class of subjects, so that MultiCube-RAG flexibly selects the most suitable cubes to acquire the relevant knowledge precisely. To enhance the query-based reasoning and retrieval, our method decomposes a complex multi-hop query into a set of simple subqueries along cube dimensions and conquers each of them sequentially. Experiments on four multi-hop QA datasets show that MultiCube-RAG improves response accuracy by 8.9% over the average performance of various baselines. Notably, we also demonstrate that our method performs with greater efficiency and inherent explainability.

</details>


### [104] [Are LLMs Ready to Replace Bangla Annotators?](https://arxiv.org/abs/2602.16241)
*Md. Najib Hasan,Touseef Hasan,Souvika Sarkar*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）在作为低资源语言（如孟加拉语）的仇恨言论零样本标注器时，存在偏见和不稳定性，并且模型规模并非决定标注质量的关键因素。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）被广泛用于自动化标注以扩大数据集创建，但它们作为无偏见标注器的可靠性，尤其是在低资源和涉及敏感身份的场景下，仍然知之甚少。作者希望理解LLMs在这些关键设置下的行为。

Method: 研究者对17个LLMs进行了系统性基准测试，采用统一的评估框架，将LLMs用作孟加拉语仇恨言论的零样本标注器。

Result: 分析揭示了LLMs作为标注器存在偏见和判断上的显著不稳定性。令人意外的是，模型规模的增大并不保证标注质量的提升；规模较小、更专注于特定任务的模型，其行为往往比规模更大的模型更稳定。

Conclusion: 这项研究强调了当前LLMs在低资源语言的敏感标注任务中存在重要局限性，并强调在部署前进行仔细评估的必要性。模型规模并非衡量标注质量的唯一标准，更小、更专业的模型可能表现更佳。

Abstract: Large Language Models (LLMs) are increasingly used as automated annotators to scale dataset creation, yet their reliability as unbiased annotators--especially for low-resource and identity-sensitive settings--remains poorly understood. In this work, we study the behavior of LLMs as zero-shot annotators for Bangla hate speech, a task where even human agreement is challenging, and annotator bias can have serious downstream consequences. We conduct a systematic benchmark of 17 LLMs using a unified evaluation framework. Our analysis uncovers annotator bias and substantial instability in model judgments. Surprisingly, increased model scale does not guarantee improved annotation quality--smaller, more task-aligned models frequently exhibit more consistent behavior than their larger counterparts. These results highlight important limitations of current LLMs for sensitive annotation tasks in low-resource languages and underscore the need for careful evaluation before deployment.

</details>


### [105] [A Curious Class of Adpositional Multiword Expressions in Korean](https://arxiv.org/abs/2602.16023)
*Junghyun Min,Na-Rae Han,Jena D. Hwang,Nathan Schneider*

Main category: cs.CL

TL;DR: 本文研究了韩语中一种特定的多词语（MWE）形式——后置词动词类结构（PVCs），并提出了一套标注指南，旨在促进韩语多词语介词的研究和跨语言框架的整合。


<details>
  <summary>Details</summary>
Motivation: 现有跨语言标注框架中韩语多词语（MWE）代表性不足，特别是韩语多词语介词缺乏系统分析、标注资源和多语言框架整合。

Method: 从韩语维基百科数据中提取并分析了多种PVC表达，并将其与非MWE和结构相似的光动词结构（LVCs）进行对比。在此基础上，提出了用于指导韩语多词语介词标注的指南。

Result: 对韩语PVCs进行了调查和分析，并与非MWEs和LVCs进行了对比，发现了它们之间的结构和功能差异。提出了支持韩语多词语介词标注的指南。

Conclusion: 本文的研究为填补韩语多词语介词在现有跨语言研究中的空白奠定了基础，提出的标注指南有助于未来的研究和与多语言框架的对接。

Abstract: Multiword expressions (MWEs) have been widely studied in cross-lingual annotation frameworks such as PARSEME. However, Korean MWEs remain underrepresented in these efforts. In particular, Korean multiword adpositions lack systematic analysis, annotated resources, and integration into existing multilingual frameworks. In this paper, we study a class of Korean functional multiword expressions: postpositional verb-based constructions (PVCs). Using data from Korean Wikipedia, we survey and analyze several PVC expressions and contrast them with non-MWEs and light verb constructions (LVCs) with similar structure. Building on this analysis, we propose annotation guidelines designed to support future work in Korean multiword adpositions and facilitate alignment with cross-lingual frameworks.

</details>


### [106] [CLAA: Cross-Layer Attention Aggregation for Accelerating LLM Prefill](https://arxiv.org/abs/2602.16054)
*Bradley McDanel,Steven Li,Harshit Khaitan*

Main category: cs.CL

TL;DR: 本文提出了一种名为CLAA的方法，通过聚合跨层的token重要性分数来解决长文本LLM推理中的预填充瓶颈问题，显著减少了生成时间。


<details>
  <summary>Details</summary>
Motivation: 长文本LLM推理中的预填充阶段存在计算瓶颈。现有的token排序启发式方法在token重要性估计上不稳定，并且难以独立评估其质量。

Method: 引入了“Answer-Informed Oracle”，通过测量生成答案对prompt的注意力来定义真实的token重要性。基于该oracle的诊断，提出了一种名为Cross-Layer Attention Aggregation (CLAA)的方法，该方法聚合跨层的token重要性分数。

Result: CLAA方法接近oracle的上界，并将Time-to-First-Token (TTFT)相比于Full KV Cache基线模型降低了高达39%。

Conclusion: 聚合跨层token重要性分数是一种有效的方法，可以稳定token重要性估计，显著提高长文本LLM推理的效率，并解决了现有启发式方法的局限性。

Abstract: The prefill stage in long-context LLM inference remains a computational bottleneck. Recent token-ranking heuristics accelerate inference by selectively processing a subset of semantically relevant tokens. However, existing methods suffer from unstable token importance estimation, often varying between layers. Evaluating token-ranking quality independently from heuristic-specific architectures is challenging. To address this, we introduce an Answer-Informed Oracle, which defines ground-truth token importance by measuring attention from generated answers back to the prompt. This oracle reveals that existing heuristics exhibit high variance across layers: rankings can degrade sharply at specific layers, a failure mode invisible to end-to-end benchmarks. The diagnosis suggests a simple fix: aggregate scores across layers rather than relying on any single one. We implement this as Cross-Layer Attention Aggregation (CLAA), which closes the gap to the oracle upper bound and reduces Time-to-First-Token (TTFT) by up to 39\% compared to the Full KV Cache baseline.

</details>


### [107] [Surgical Activation Steering via Generative Causal Mediation](https://arxiv.org/abs/2602.16080)
*Aruna Sankaranarayanan,Amir Zur,Atticus Geiger,Dylan Hadfield-Menell*

Main category: cs.CL

TL;DR: 提出了一种名为生成因果中介 (GCM) 的新程序，用于识别和控制大型语言模型 (LM) 在长篇回复中跨越多个 token 的行为，例如区分诗歌和散文的说话风格。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是找出在语言模型中应干预哪些部分，以控制那些弥散在长篇回复多个 token 中的行为。

Method: GCM 程序首先构建包含对比输入的响应数据集。然后，量化各个模型组件（例如注意力头）如何介导对比概念，并选择最强的中介者进行引导。在三种任务（拒绝、谄媚和风格迁移）上，针对三种语言模型进行了评估。

Result: GCM 成功地定位了长篇回复中表达的概念，并且在仅使用稀疏的注意力头进行引导时，性能始终优于基于相关性探测的基线方法。

Conclusion: GCM 为定位和控制语言模型的长篇回复提供了一种有效的方法。

Abstract: Where should we intervene in a language model (LM) to control behaviors that are diffused across many tokens of a long-form response? We introduce Generative Causal Mediation (GCM), a procedure for selecting model components, e.g., attention heads, to steer a binary concept (e.g., talk in verse vs. talk in prose) from contrastive long-form responses. In GCM, we first construct a dataset of contrasting inputs and responses. Then, we quantify how individual model components mediate the contrastive concept and select the strongest mediators for steering. We evaluate GCM on three tasks--refusal, sycophancy, and style transfer--across three language models. GCM successfully localizes concepts expressed in long-form responses and consistently outperforms correlational probe-based baselines when steering with a sparse set of attention heads. Together, these results demonstrate that GCM provides an effective approach for localizing and controlling the long-form responses of LMs.

</details>


### [108] [IndicEval: A Bilingual Indian Educational Evaluation Framework for Large Language Models](https://arxiv.org/abs/2602.16467)
*Saurabh Bharti,Gaurav Azad,Abhinaw Jagtap,Nachiket Tapas*

Main category: cs.CL

TL;DR: 本文提出了 IndicEval，一个用于评估大型语言模型（LLMs）在真实世界高风险考试（包括英语和印地语的 STEM 和人文领域）中表现的基准测试平台。研究发现，思维链（CoT）提示能提高推理准确性，但模型之间仍存在显著性能差异，并且在印地语方面的性能普遍不如英语。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展需要能够反映现实学术严谨性和多语言复杂性的评估框架，特别是针对教育领域。

Method: 构建了一个名为 IndicEval 的可扩展基准测试平台，使用来自 UPSC、JEE 和 NEET 的真实考试题目（涵盖 STEM 和人文领域，英语和印地语）。采用零样本、少样本和思维链（CoT）提示策略自动化评估。在 Gemini 2.0 Flash、GPT-4、Claude 和 LLaMA 3-70B 等模型上进行实验。

Result: 1. CoT 提示在所有科目和语言中都能持续提高推理准确性。2. 不同模型在高性能考试中的表现存在显著差异。3. 多语言能力退化是一个关键挑战，模型在印地语上的准确率明显低于英语，尤其是在零样本条件下。

Conclusion: IndicEval 为多语言教育环境中 LLMs 的严格、公平评估提供了一个面向实践、可扩展的基础。研究结果揭示了多语言推理和领域迁移方面仍然存在的差距，并为改进 LLMs 的推理鲁棒性和语言适应性提供了可操作的见解。

Abstract: The rapid advancement of large language models (LLMs) necessitates evaluation frameworks that reflect real-world academic rigor and multilingual complexity. This paper introduces IndicEval, a scalable benchmarking platform designed to assess LLM performance using authentic high-stakes examination questions from UPSC, JEE, and NEET across STEM and humanities domains in both English and Hindi. Unlike synthetic benchmarks, IndicEval grounds evaluation in real examination standards, enabling realistic measurement of reasoning, domain knowledge, and bilingual adaptability. The framework automates assessment using Zero-Shot, Few-Shot, and Chain-of-Thought (CoT) prompting strategies and supports modular integration of new models and languages. Experiments conducted on Gemini 2.0 Flash, GPT-4, Claude, and LLaMA 3-70B reveal three major findings. First, CoT prompting consistently improves reasoning accuracy, with substantial gains across subjects and languages. Second, significant cross-model performance disparities persist, particularly in high-complexity examinations. Third, multilingual degradation remains a critical challenge, with marked accuracy drops in Hindi compared to English, especially under Zero-Shot conditions. These results highlight persistent gaps in bilingual reasoning and domain transfer. Overall, IndicEval provides a practice-oriented, extensible foundation for rigorous, equitable evaluation of LLMs in multilingual educational settings and offers actionable insights for improving reasoning robustness and language adaptability.

</details>


### [109] [Missing-by-Design: Certifiable Modality Deletion for Revocable Multimodal Sentiment Analysis](https://arxiv.org/abs/2602.16144)
*Rong Fu,Wenxin Zhang,Ziming Wang,Chunlei Meng,Jiaxuan Lu,Jiekai Wu,Kangan Qian,Hao Zhang,Simon Fong*

Main category: cs.CL

TL;DR: 本文提出 Missing-by-Design (MBD) 框架，用于多模态情感分析中的可撤销性，通过结构化表示学习和参数修改管道实现，能在不影响模型性能的情况下，选择性地移除特定模态数据，并提供可验证的模态删除证书。


<details>
  <summary>Details</summary>
Motivation: 随着多模态系统处理越来越多的敏感个人数据，选择性地撤销特定数据模态的能力对于隐私合规和用户自主性变得至关重要。

Method: MBD 框架结合了结构化表示学习和基于生成器的重建技术，用于学习属性感知嵌入，并恢复缺失的模态通道。对于删除请求，框架采用显著性驱动的候选选择和校准的高斯更新，生成可机器验证的模态删除证书。

Result: MBD 在不完整输入下实现了强大的预测性能，并提供了实用的隐私-效用权衡。与完全重新训练相比，手术式遗忘是一种更有效的方法。

Conclusion: MBD 提供了一个统一的框架，能够有效地实现多模态情感分析中的选择性数据模态撤销，并提供可验证的删除证明，为隐私保护提供了一种高效的解决方案。

Abstract: As multimodal systems increasingly process sensitive personal data, the ability to selectively revoke specific data modalities has become a critical requirement for privacy compliance and user autonomy. We present Missing-by-Design (MBD), a unified framework for revocable multimodal sentiment analysis that combines structured representation learning with a certifiable parameter-modification pipeline. Revocability is critical in privacy-sensitive applications where users or regulators may request removal of modality-specific information. MBD learns property-aware embeddings and employs generator-based reconstruction to recover missing channels while preserving task-relevant signals. For deletion requests, the framework applies saliency-driven candidate selection and a calibrated Gaussian update to produce a machine-verifiable Modality Deletion Certificate. Experiments on benchmark datasets show that MBD achieves strong predictive performance under incomplete inputs and delivers a practical privacy-utility trade-off, positioning surgical unlearning as an efficient alternative to full retraining.

</details>


### [110] [Learning to Learn from Language Feedback with Social Meta-Learning](https://arxiv.org/abs/2602.16488)
*Jonathan Cook,Diego Antognini,Martin Klissarov,Claudiu Musat,Edward Grefenstette*

Main category: cs.CL

TL;DR: 本研究提出了一种名为“社会元学习”（SML）的微调方法，用于训练大型语言模型（LLMs）主动寻求并学习纠正性语言反馈，从而提高其在对话中的适应性和解决复杂问题的能力，尤其是在信息不完整的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在对话中难以从纠正性反馈中学习，并且在面对不确定性时很少主动寻求反馈，导致对话僵化、缺乏适应性。

Method: 将社会元学习（SML）概念转化为一种微调方法，在模拟的教学对话中训练LLMs主动寻求和学习语言反馈。将静态任务转化为互动式社会学习问题。

Result: SML训练的模型能够利用对话来解决单轮无法解决的问题。这种能力可以跨领域泛化（例如，在数学问题上训练的模型也能更好地利用反馈解决编码问题）。经过SML训练的模型在面对信息不完整的任务时，会减少过早回答的次数，并更倾向于询问所需信息。

Conclusion: SML是一种可扩展的方法，可以开发出能有效从语言反馈中学习的AI系统，显著提高了LLMs在对话中的学习能力和处理不确定信息的能力。

Abstract: Large language models (LLMs) often struggle to learn from corrective feedback within a conversational context. They are rarely proactive in soliciting this feedback, even when faced with ambiguity, which can make their dialogues feel static, one-sided, and lacking the adaptive qualities of human conversation. To address these limitations, we draw inspiration from social meta-learning (SML) in humans - the process of learning how to learn from others. We formulate SML as a finetuning methodology, training LLMs to solicit and learn from language feedback in simulated pedagogical dialogues, where static tasks are converted into interactive social learning problems. SML effectively teaches models to use conversation to solve problems they are unable to solve in a single turn. This capability generalises across domains; SML on math problems produces models that better use feedback to solve coding problems and vice versa. Furthermore, despite being trained only on fully-specified problems, these models are better able to solve underspecified tasks where critical information is revealed over multiple turns. When faced with this ambiguity, SML-trained models make fewer premature answer attempts and are more likely to ask for the information they need. This work presents a scalable approach to developing AI systems that effectively learn from language feedback.

</details>


### [111] [Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling](https://arxiv.org/abs/2602.16485)
*Jeffrey T. H. Wong,Zixi Zhang,Junyi Liu,Yiren Zhao*

Main category: cs.CL

TL;DR: 提出了一种名为 Team-of-Thoughts 的新型多智能体系统 (MAS) 架构，通过引入一个协调器-工具范式，利用异构智能体的互补能力，并在推理和代码生成任务上取得了优于同类方法的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体系统通常依赖于静态、同质化的模型配置，限制了它们利用不同后训练模型独特优势的能力。

Method: 提出了一种名为 Team-of-Thoughts 的 MAS 架构，采用协调器-工具范式。核心机制包括：1) 协调器校准方案，用于识别协作能力更强的模型；2) 自我评估协议，工具智能体评估自身领域专业知识以应对后训练技能的差异。推理时，协调器根据能力档案动态激活最合适的工具智能体。

Result: 在五个推理和代码生成基准测试上，Team-of-Thoughts 取得了持续优越的任务性能。在 AIME24 和 LiveCodeBench 上，准确率分别达到 96.67% 和 72.53%，显著优于同质化角色扮演基线（分别为 80% 和 65.93%）。

Conclusion: Team-of-Thoughts 架构通过利用异构智能体的互补能力，并结合校准和自我评估机制，有效地提升了多智能体系统的性能，尤其在需要复杂推理和代码生成的任务上表现突出。

Abstract: Existing Multi-Agent Systems (MAS) typically rely on static, homogeneous model configurations, limiting their ability to exploit the distinct strengths of differently post-trained models. To address this, we introduce Team-of-Thoughts, a novel MAS architecture that leverages the complementary capabilities of heterogeneous agents via an orchestrator-tool paradigm. Our framework introduces two key mechanisms to optimize performance: (1) an orchestrator calibration scheme that identifies models with superior coordination capabilities, and (2) a self-assessment protocol where tool agents profile their own domain expertise to account for variations in post-training skills. During inference, the orchestrator dynamically activates the most suitable tool agents based on these proficiency profiles. Experiments on five reasoning and code generation benchmarks show that Team-of-Thoughts delivers consistently superior task performance. Notably, on AIME24 and LiveCodeBench, our approach achieves accuracies of 96.67% and 72.53%, respectively, substantially outperforming homogeneous role-play baselines, which score 80% and 65.93%.

</details>


### [112] [LLMs Exhibit Significantly Lower Uncertainty in Creative Writing Than Professional Writers](https://arxiv.org/abs/2602.16162)
*Peiqi Sui*

Main category: cs.CL

TL;DR: 文章指出，LLMs在创意写作中的不确定性是一个被忽视的性能限制，导致作品缺乏新意。研究通过量化“不确定性差距”发现，人类写作比模型生成的内容具有更高的不确定性，尤其是在创意写作领域。文章呼吁开发新的、关注不确定性的对齐范式，以提升LLMs的创意写作能力。


<details>
  <summary>Details</summary>
Motivation: 作者认为，当前大型语言模型（LLMs）在创意写作中的表现往往平庸且充斥陈词滥调，其核心限制在于“不确定性”这一关键因素被忽视。现有的模型对齐策略为了确保事实准确性和减少幻觉，反而引导模型避开不确定的输出，这与文学创作中不确定性对创造力至关重要这一理论相悖。

Method: 研究通过信息论方法，量化了人类创作的故事与模型生成的续写之间的“不确定性差距”。对28个LLMs在高质量故事数据集上的表现进行对照分析。

Result: 研究结果显示，人类写作在不确定性上显著高于模型生成的内容。指令微调和具有推理能力的模型比基础模型加剧了这种不确定性差距。此外，该差距在创意写作领域比在功能性领域更为明显，并且与写作质量高度相关。

Conclusion: 为了达到人类水平的创意写作能力，需要开发新的、关注不确定性的对齐范式。这些范式需要能够区分有害的幻觉与文学性所必需的建设性模糊性，从而使LLMs能够生成更具创造力和丰富性的作品。

Abstract: We argue that uncertainty is a key and understudied limitation of LLMs' performance in creative writing, which is often characterized as trite and cliché-ridden. Literary theory identifies uncertainty as a necessary condition for creative expression, while current alignment strategies steer models away from uncertain outputs to ensure factuality and reduce hallucination. We formalize this tension by quantifying the "uncertainty gap" between human-authored stories and model-generated continuations. Through a controlled information-theoretic analysis of 28 LLMs on high-quality storytelling datasets, we demonstrate that human writing consistently exhibits significantly higher uncertainty than model outputs. We find that instruction-tuned and reasoning models exacerbate this trend compared to their base counterparts; furthermore, the gap is more pronounced in creative writing than in functional domains, and strongly correlates to writing quality. Achieving human-level creativity requires new uncertainty-aware alignment paradigms that can distinguish between destructive hallucinations and the constructive ambiguity required for literary richness.

</details>


### [113] [The Validity of Coreference-based Evaluations of Natural Language Understanding](https://arxiv.org/abs/2602.16200)
*Ian Porada*

Main category: cs.CL

TL;DR: 本研究通过扩展现有评估方法和分析评估结果的一致性，改进了对基于共指消解（coreference resolution）评估的理解。研究发现，当前的语言模型在标准基准上表现出色，但在评估条件稍有变化时，泛化能力不足，无法像人类一样进行推理。


<details>
  <summary>Details</summary>
Motivation: 研究动机是改进对共指消解评估结果的理解，解决现有评估方法在有效性和一致性方面存在的问题，并探究当前语言模型在共指消解任务上的真实能力和局限性。

Method: 该研究首先分析了标准的共指消解评估方法，揭示了其在测量有效性方面存在的问题（如定义模糊和跨基准不一致）。随后，提出并实现了一种新的评估方法，侧重于测试系统推断事件相对可能性的能力，这是解决共指消解的一个关键方面。

Result: 研究发现，当前的语言模型在标准基准上表现出强大的性能，并且在某些领域和共指消解类型上优于早期的基线系统。然而，模型对评估条件的敏感性很高，当评估上下文略有改变时，它们常常无法像人类一样进行泛化。

Conclusion: 研究结论指出，当前的自然语言处理（NLP）范式在共指消解任务上，虽然在常用评估中比基线系统提高了准确性，但在测量有效性方面存在弱点，并且模型泛化能力有限。研究结果为未来开发更好的评估方法和更具真正泛化能力的系统提供了方向。

Abstract: In this thesis, I refine our understanding as to what conclusions we can reach from coreference-based evaluations by expanding existing evaluation practices and considering the extent to which evaluation results are either converging or conflicting. First, I analyze standard coreference evaluations and show that their design often leads to non-generalizable conclusions due to issues of measurement validity - including contestedness (multiple, competing definitions of coreference) and convergent validity (evaluation results that rank models differently across benchmarks). Second, I propose and implement a novel evaluation focused on testing systems' ability to infer the relative plausibility of events, a key aspect of resolving coreference. Through this extended evaluation, I find that contemporary language models demonstrate strong performance on standard benchmarks - improving over earlier baseline systems within certain domains and types of coreference - but remain sensitive to the evaluation conditions: they often fail to generalize in ways one would expect a human to be capable of when evaluation contexts are slightly modified. Taken together, these findings clarify both the strengths, such as improved accuracy over baselines on widely used evaluations, and the limitations of the current NLP paradigm, including weaknesses in measurement validity, and suggest directions for future work in developing better evaluation methods and more genuinely generalizable systems.

</details>


### [114] [Aladdin-FTI @ AMIYA Three Wishes for Arabic NLP: Fidelity, Diglossia, and Multidialectal Generation](https://arxiv.org/abs/2602.16290)
*Jonathan Mutal,Perla Al Almaoui,Simon Hengchen,Pierrette Bouillon*

Main category: cs.CL

TL;DR: 本文提出了Aladdin-FTI系统，一个用于方言阿拉伯语生成和翻译的模型，支持摩洛哥、埃及、巴勒斯坦、叙利亚和沙特阿拉伯方言，以及它们与现代标准阿拉伯语和英语之间的双向翻译。


<details>
  <summary>Details</summary>
Motivation: 由于方言阿拉伯语的非标准化和高变异性，其在自然语言处理（NLP）研究中一直代表性不足。大型语言模型（LLMs）的最新进展提供了解决这一差距的途径，将阿拉伯语视为一个多中心语言进行建模。

Method: 该研究提出了Aladdin-FTI系统，这是一个支持方言阿拉伯语文本生成和翻译的模型。具体来说，该模型支持摩洛哥、埃及、巴勒斯坦、叙利亚和沙特阿拉伯方言的文本生成，以及这些方言与现代标准阿拉伯语（MSA）和英语之间的双向翻译。

Result: 该系统能够生成多种方言阿拉伯语，并支持方言阿拉伯语、MSA和英语之间的双向翻译。

Conclusion: Aladdin-FTI系统通过利用LLMs的潜力，为解决阿拉伯语方言在NLP中的代表性不足问题提供了一个解决方案，并且其代码和训练模型已公开可用。

Abstract: Arabic dialects have long been under-represented in Natural Language Processing (NLP) research due to their non-standardization and high variability, which pose challenges for computational modeling. Recent advances in the field, such as Large Language Models (LLMs), offer promising avenues to address this gap by enabling Arabic to be modeled as a pluricentric language rather than a monolithic system. This paper presents Aladdin-FTI, our submission to the AMIYA shared task. The proposed system is designed to both generate and translate dialectal Arabic (DA). Specifically, the model supports text generation in Moroccan, Egyptian, Palestinian, Syrian, and Saudi dialects, as well as bidirectional translation between these dialects, Modern Standard Arabic (MSA), and English. The code and trained model are publicly available.

</details>


### [115] [From Growing to Looping: A Unified View of Iterative Computation in LLMs](https://arxiv.org/abs/2602.16490)
*Ferdinand Kapl,Emmanouil Angelis,Kaitlin Maile,Johannes von Oswald,Stefan Bauer*

Main category: cs.CL

TL;DR: 本文统一了模型中层循环（looping）和深度增长（depth growing）这两种增强推理能力的方法，发现它们都依赖于相似的深度计算模式，并且可以组合使用以进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明模型层循环和深度增长可以提高模型的推理能力，但它们之间的联系尚不明确。本文旨在揭示这两种方法的机制联系，并探索它们的组合潜力。

Method: 通过分析模型在不同推理任务中的激活模式，比较了循环模型和深度增长模型在深度方向上的计算签名。在此基础上，研究了将推理时循环应用于深度增长模型的中间层，以及在不同训练数据条件下（如更多in-context示例、额外监督微调数据、高质量的math-heavy cooldown混合数据）评估两种方法的适应性。

Result: 循环和深度增长模型在深度计算模式上表现出一致性，例如对后期层的依赖性增强和与循环/增长块对齐的重复模式。将推理时循环应用于深度增长模型的中间块，可以将推理性能提升高达2倍。深度增长模型在使用更高质量的math-heavy cooldown混合数据时推理增益最大，且可以通过将中间块适配为循环进一步提升。

Conclusion: 深度增长和循环是提升模型推理能力的有效且互补的方法，它们通过诱导和扩展迭代计算来实现。这两种方法都具有良好的适应性和可组合性，为提高模型推理能力提供了新的途径。

Abstract: Looping, reusing a block of layers across depth, and depth growing, training shallow-to-deep models by duplicating middle layers, have both been linked to stronger reasoning, but their relationship remains unclear. We provide a mechanistic unification: looped and depth-grown models exhibit convergent depth-wise signatures, including increased reliance on late layers and recurring patterns aligned with the looped or grown block. These shared signatures support the view that their gains stem from a common form of iterative computation. Building on this connection, we show that the two techniques are adaptable and composable: applying inference-time looping to the middle blocks of a depth-grown model improves accuracy on some reasoning primitives by up to $2\times$, despite the model never being trained to loop. Both approaches also adapt better than the baseline when given more in-context examples or additional supervised fine-tuning data. Additionally, depth-grown models achieve the largest reasoning gains when using higher-quality, math-heavy cooldown mixtures, which can be further boosted by adapting a middle block to loop. Overall, our results position depth growth and looping as complementary, practical methods for inducing and scaling iterative computation to improve reasoning.

</details>


### [116] [MultiCW: A Large-Scale Balanced Benchmark Dataset for Training Robust Check-Worthiness Detection Models](https://arxiv.org/abs/2602.16298)
*Martin Hyben,Sebastian Kula,Jan Cegin,Jakub Simko,Ivan Srba,Robert Moro*

Main category: cs.CL

TL;DR: 该研究提出了一个名为MultiCW的多语言、多领域、多风格的数据集，用于检测事实核查中“值得核查”的陈述，并评估了不同大型语言模型（LLM）在该任务上的表现，发现微调模型在零样本LLM之上表现更优，且具有良好的跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在信息核查领域应用日益广泛，但自动检测“值得核查”的陈述这一关键步骤仍存在局限。因此，需要一个更全面、更具挑战性的数据集来推动该领域的研究。

Method: 研究构建了MultiCheck-Worthy (MultiCW) 数据集，包含16种语言、7个主题领域、2种写作风格共123,722个样本，并设计了一个包含27,761个样本的、分布外（out-of-distribution）的评估集。同时，对15个商业和开源LLM在零样本设置下进行了基线评估，并与3个常用的多语言Transformer微调模型进行了比较。

Result: 微调模型在陈述分类任务上持续优于零样本LLM，并且在跨语言、跨领域和跨风格的分布外评估中展现出强大的泛化能力。

Conclusion: MultiCW数据集是一个严谨的多语言资源，有助于推进自动化事实核查的研究，并为比较微调模型和尖端LLM在检测值得核查陈述方面的性能提供了系统性的方法。

Abstract: Large Language Models (LLMs) are beginning to reshape how media professionals verify information, yet automated support for detecting check-worthy claims a key step in the fact-checking process remains limited. We introduce the Multi-Check-Worthy (MultiCW) dataset, a balanced multilingual benchmark for check-worthy claim detection spanning 16 languages, 7 topical domains, and 2 writing styles. It consists of 123,722 samples, evenly distributed between noisy (informal) and structured (formal) texts, with balanced representation of check-worthy and non-check-worthy classes across all languages. To probe robustness, we also introduce an equally balanced out-of-distribution evaluation set of 27,761 samples in 4 additional languages. To provide baselines, we benchmark 3 common fine-tuned multilingual transformers against a diverse set of 15 commercial and open LLMs under zero-shot settings. Our findings show that fine-tuned models consistently outperform zero-shot LLMs on claim classification and show strong out-of-distribution generalization across languages, domains, and styles. MultiCW provides a rigorous multilingual resource for advancing automated fact-checking and enables systematic comparisons between fine-tuned models and cutting-edge LLMs on the check-worthy claim detection task.

</details>


### [117] [Explainable AI: Context-Aware Layer-Wise Integrated Gradients for Explaining Transformer Models](https://arxiv.org/abs/2602.16608)
*Melkamu Abay Mersha,Jugal Kalita*

Main category: cs.CL

TL;DR: 本文提出了一种名为CA-LIG的上下文感知分层集成梯度框架，用于解释Transformer模型的预测，该框架能够捕捉跨层依赖关系和结构化组件，并生成更准确、更连贯的归因图。


<details>
  <summary>Details</summary>
Motivation: 现有Transformer模型的可解释性方法存在局限性，例如仅依赖最终层归因、缺乏跨层依赖性捕获、无法统一局部和全局归因、以及缺乏对上下文和结构组件的感知。这些局限性阻碍了对Transformer决策过程的深入理解。

Method: 提出CA-LIG框架，该框架在每个Transformer块内计算分层集成梯度，并将这些token级归因与特定类别的注意力梯度相结合。通过这种集成，生成有符号的、上下文敏感的归因图，能够捕捉支持性和对抗性证据，并追踪相关性在Transformer层中的分层流动。

Result: 在情感分析、文档分类、仇恨言论检测和图像分类等多种任务、领域和Transformer模型（包括BERT、XLM-R、AfroLM和MAE）上进行了评估。结果表明，CA-LIG比现有方法提供了更忠实的归因，对上下文依赖性更敏感，可视化效果更清晰、语义更连贯。

Conclusion: CA-LIG框架提供了一种更全面、上下文感知和可靠的Transformer决策解释方法，提高了深度神经网络的可解释性和概念理解。

Abstract: Transformer models achieve state-of-the-art performance across domains and tasks, yet their deeply layered representations make their predictions difficult to interpret. Existing explainability methods rely on final-layer attributions, capture either local token-level attributions or global attention patterns without unification, and lack context-awareness of inter-token dependencies and structural components. They also fail to capture how relevance evolves across layers and how structural components shape decision-making. To address these limitations, we proposed the \textbf{Context-Aware Layer-wise Integrated Gradients (CA-LIG) Framework}, a unified hierarchical attribution framework that computes layer-wise Integrated Gradients within each Transformer block and fuses these token-level attributions with class-specific attention gradients. This integration yields signed, context-sensitive attribution maps that capture supportive and opposing evidence while tracing the hierarchical flow of relevance through the Transformer layers. We evaluate the CA-LIG Framework across diverse tasks, domains, and transformer model families, including sentiment analysis and long and multi-class document classification with BERT, hate speech detection in a low-resource language setting with XLM-R and AfroLM, and image classification with Masked Autoencoder vision Transformer model. Across all tasks and architectures, CA-LIG provides more faithful attributions, shows stronger sensitivity to contextual dependencies, and produces clearer, more semantically coherent visualizations than established explainability methods. These results indicate that CA-LIG provides a more comprehensive, context-aware, and reliable explanation of Transformer decision-making, advancing both the practical interpretability and conceptual understanding of deep neural models.

</details>


### [118] [MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks](https://arxiv.org/abs/2602.16313)
*Zexue He,Yu Wang,Churan Zhi,Yuanzhe Hu,Tzu-Ping Chen,Lang Yin,Ze Chen,Tong Arthur Wu,Siru Ouyang,Zihan Wang,Jiaxin Pei,Julian McAuley,Yejin Choi,Alex Pentland*

Main category: cs.CL

TL;DR: 本文提出了MemoryArena，一个用于评估多回合记忆智能体的新型基准测试环境，该环境模拟了真实世界中记忆获取和使用之间的耦合关系，并揭示了现有评估方法在评估智能体记忆能力方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有对具有记忆能力的智能体的评估通常将记忆和行动孤立开来，无法反映在真实场景中记忆在指导未来决策中的作用，因此需要一个能够同时评估记忆获取和使用，并模拟真实世界多回合交互场景的评估框架。

Method: 引入MemoryArena，一个包含人造智能体任务的统一评估环境，这些任务具有明确相互依赖的子任务。智能体需要在交互过程中学习、提炼经验到记忆中，并利用记忆来指导后续行动以完成整个任务。MemoryArena支持网页导航、约束规划、信息搜索和形式推理等多种任务。

Result: 在MemoryArena上的实验表明，即使在LoCoMo等现有长上下文记忆基准测试中表现接近饱和的智能体，在该评估环境中也表现不佳，揭示了当前评估方法在智能体记忆能力方面的局限性。

Conclusion: MemoryArena提供了一个更接近真实世界的评估框架，能够更有效地衡量和区分具有记忆能力的智能体，并指出当前针对智能体记忆的研究和评估需要改进，以更好地捕捉记忆在智能体行动中的实际应用。

Abstract: Existing evaluations of agents with memory typically assess memorization and action in isolation. One class of benchmarks evaluates memorization by testing recall of past conversations or text but fails to capture how memory is used to guide future decisions. Another class focuses on agents acting in single-session tasks without the need for long-term memory. However, in realistic settings, memorization and action are tightly coupled: agents acquire memory while interacting with the environment, and subsequently rely on that memory to solve future tasks. To capture this setting, we introduce MemoryArena, a unified evaluation gym for benchmarking agent memory in multi-session Memory-Agent-Environment loops. The benchmark consists of human-crafted agentic tasks with explicitly interdependent subtasks, where agents must learn from earlier actions and feedback by distilling experiences into memory, and subsequently use that memory to guide later actions to solve the overall task. MemoryArena supports evaluation across web navigation, preference-constrained planning, progressive information search, and sequential formal reasoning, and reveals that agents with near-saturated performance on existing long-context memory benchmarks like LoCoMo perform poorly in our agentic setting, exposing a gap in current evaluations for agents with memory.

</details>


### [119] [Align Once, Benefit Multilingually: Enforcing Multilingual Consistency for LLM Safety Alignment](https://arxiv.org/abs/2602.16660)
*Yuyan Bu,Xiaohao Liu,ZhaoXing Ren,Yaodong Yang,Juntao Dai*

Main category: cs.CL

TL;DR: 提出了一种名为多语言一致性（MLC）损失的即插即用方法，可以在不增加额外监督的情况下，通过改进多语言表示向量的共线性来提高多语言安全对齐的效率和跨语言泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言安全对齐方法需要大量资源（如高质量监督或与高资源语言配对），限制了其可扩展性。需要一种资源高效的方法来改进多语言安全对齐。

Method: 提出了一种即插即用的多语言一致性（MLC）损失，通过改进多语言表示向量的共线性，在单一更新中鼓励多语言语义层面的方向一致性。该方法使用多语言提示变体，无需低资源语言的额外响应级监督。

Result: 在不同模型架构和对齐范式中验证了MLC损失的有效性，提高了多语言安全性，同时对模型通用效用影响有限。此外，在不同语言和任务上的评估显示了改进的跨语言泛化能力。

Conclusion: MLC损失是一种实用的、资源高效的方法，可以在监督有限的情况下实现多语言一致性对齐，并能提升模型的跨语言泛化能力。

Abstract: The widespread deployment of large language models (LLMs) across linguistic communities necessitates reliable multilingual safety alignment. However, recent efforts to extend alignment to other languages often require substantial resources, either through large-scale, high-quality supervision in the target language or through pairwise alignment with high-resource languages, which limits scalability. In this work, we propose a resource-efficient method for improving multilingual safety alignment. We introduce a plug-and-play Multi-Lingual Consistency (MLC) loss that can be integrated into existing monolingual alignment pipelines. By improving collinearity between multilingual representation vectors, our method encourages directional consistency at the multilingual semantic level in a single update. This allows simultaneous alignment across multiple languages using only multilingual prompt variants without requiring additional response-level supervision in low-resource languages. We validate the proposed method across different model architectures and alignment paradigms, and demonstrate its effectiveness in enhancing multilingual safety with limited impact on general model utility. Further evaluation across languages and tasks indicates improved cross-lingual generalization, suggesting the proposed approach as a practical solution for multilingual consistency alignment under limited supervision.

</details>


### [120] [Who can we trust? LLM-as-a-jury for Comparative Assessment](https://arxiv.org/abs/2602.16610)
*Mengjie Qian,Guangzhi Sun,Mark J. F. Gales,Kate M. Knill*

Main category: cs.CL

TL;DR: 本文提出了一种名为 BT-sigma 的新方法，用于改进大型语言模型 (LLM) 作为评估者在生成文本评估中的表现。该方法通过引入一个判别器参数来估计每个 LLM 评估者的可靠性，从而能够更准确地从成对比较中推断出文本的排名，并且优于传统的平均聚合方法。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 评估方法通常假设所有 LLM 评估者具有相同的可靠性，但实际上 LLM 评估者的表现差异很大，且其判断概率可能存在偏差和不一致。现有方法未能有效处理这些不一致性，限制了基于概率的排序效果。此外，用于校准评估者的标注数据通常不可用。

Method: 本文首先通过实验证明了 LLM 比较概率的不一致性及其对排序效果的限制。然后，提出了一种名为 BT-sigma 的方法，该方法是对 Bradley-Terry 模型的扩展，引入了一个判别器参数来估计每个 LLM 评估者的可靠性。BT-sigma 能够仅从成对比较数据中同时推断出文本排名和评估者可靠性。

Result: 在公开的 NLG 评估数据集上的实验表明，BT-sigma 的性能始终优于基于平均聚合的方法。学习到的判别器参数与 LLM 判断的周期一致性的独立测量值高度相关。进一步分析表明，BT-sigma 可以被解释为一种无监督的校准机制，通过建模评估者可靠性来改进聚合。

Conclusion: BT-sigma 是一种有效的、评估者感知的模型，它通过显式建模 LLM 评估者的可靠性，显著提高了从成对比较中进行 NLG 评估的准确性。该方法提供了一种无需人工标注即可实现 LLM 评估者校准的途径。

Abstract: Large language models (LLMs) are increasingly applied as automatic evaluators for natural language generation assessment often using pairwise comparative judgements. Existing approaches typically rely on single judges or aggregate multiple judges assuming equal reliability. In practice, LLM judges vary substantially in performance across tasks and aspects, and their judgment probabilities may be biased and inconsistent. Furthermore, human-labelled supervision for judge calibration may be unavailable. We first empirically demonstrate that inconsistencies in LLM comparison probabilities exist and show that it limits the effectiveness of direct probability-based ranking. To address this, we study the LLM-as-a-jury setting and propose BT-sigma, a judge-aware extension of the Bradley-Terry model that introduces a discriminator parameter for each judge to jointly infer item rankings and judge reliability from pairwise comparisons alone. Experiments on benchmark NLG evaluation datasets show that BT-sigma consistently outperforms averaging-based aggregation methods, and that the learned discriminator strongly correlates with independent measures of the cycle consistency of LLM judgments. Further analysis reveals that BT-sigma can be interpreted as an unsupervised calibration mechanism that improves aggregation by modelling judge reliability.

</details>


### [121] [Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents](https://arxiv.org/abs/2602.16346)
*Nivya Talokar,Ayush K Tarun,Murari Mandal,Maksym Andriushchenko,Antoine Bosselut*

Main category: cs.CL

TL;DR: 本文提出了一种名为STING的自动化红队测试框架，用于评估基于LLM的智能体在多轮交互中执行有害任务的能力，并引入了一种新的分析方法来衡量越狱的难度和效率，实验证明STING比现有方法更有效地检测到智能体的滥用行为，尤其是在多语言环境下。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM智能体滥用基准测试主要关注单轮指令，无法评估智能体在多轮交互中协助完成有害或非法任务的能力，这与实际应用场景不符。因此，需要一个能够模拟真实多轮交互的测试框架。

Method: STING框架通过以下方式工作：1. 构建一个基于良性角色的分步非法计划；2. 迭代地向目标智能体提出适应性后续问题；3. 使用裁判智能体跟踪阶段完成情况。此外，本文还提出了一种将多轮红队测试建模为“首次越狱时间”随机变量的分析框架，并引入了发现曲线、攻击语言的危险率归因以及受限平均越狱发现率等新指标。

Result: 在AgentHarm场景下，STING在非法任务完成率方面显著高于单轮提示和针对工具使用智能体的多轮聊天基线。在六种非英语语言的评估中，发现攻击成功率和非法任务完成率在低资源语言中并不一致地提高，这与常见的聊天机器人发现不同。

Conclusion: STING提供了一种实用的方法来评估和压力测试LLM智能体在现实部署场景中的滥用行为，这些场景通常涉及多轮交互和多语言环境。研究结果强调了在评估智能体安全时考虑多轮和多语言交互的重要性。

Abstract: LLM-based agents execute real-world workflows via tools and memory. These affordances enable ill-intended adversaries to also use these agents to carry out complex misuse scenarios. Existing agent misuse benchmarks largely test single-prompt instructions, leaving a gap in measuring how agents end up helping with harmful or illegal tasks over multiple turns. We introduce STING (Sequential Testing of Illicit N-step Goal execution), an automated red-teaming framework that constructs a step-by-step illicit plan grounded in a benign persona and iteratively probes a target agent with adaptive follow-ups, using judge agents to track phase completion. We further introduce an analysis framework that models multi-turn red-teaming as a time-to-first-jailbreak random variable, enabling analysis tools like discovery curves, hazard-ratio attribution by attack language, and a new metric: Restricted Mean Jailbreak Discovery. Across AgentHarm scenarios, STING yields substantially higher illicit-task completion than single-turn prompting and chat-oriented multi-turn baselines adapted to tool-using agents. In multilingual evaluations across six non-English settings, we find that attack success and illicit-task completion do not consistently increase in lower-resource languages, diverging from common chatbot findings. Overall, STING provides a practical way to evaluate and stress-test agent misuse in realistic deployment settings, where interactions are inherently multi-turn and often multilingual.

</details>


### [122] [Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents](https://arxiv.org/abs/2602.16379)
*Mohammad H. A. Monfared,Lucie Flek,Akbar Karimi*

Main category: cs.CL

TL;DR: 提出了一种用于方面级情感分析（ABSA）的智能数据增强方法，通过迭代生成和验证来提高合成训练样本的质量，并与基于提示的方法进行了比较。结果表明，智能增强方法在标签保持方面优于基于提示的方法，并且在与真实数据结合时能带来更高的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了提高Aspect-Based Sentiment Analysis（ABSA）模型的训练数据质量和数量，开发一种更有效的数据增强方法，并隔离智能（agentic）结构对数据增强效果的影响。

Method: 提出了一种名为“agentic data augmentation”的方法，该方法通过迭代生成和验证来创建高质量的合成训练样本。同时，开发了一个使用相同模型和指令的基于提示（prompting-based）的基线方法进行对比。在三个ABSA子任务（ATE、ATSC、ASPE）、四个SemEval数据集和两种encoder-decoder模型（T5-Base和Tk-Instruct）上进行了评估。

Result: 智能增强方法在增强数据的标签保持方面优于原始提示方法，尤其是在需要方面词生成的任务中。当与真实数据结合时，智能增强方法提供了更高的性能提升，始终优于基于提示的生成方法。这些优势在T5-Base模型上尤为明显，而预训练更充分的Tk-Instruct模型改进幅度较小。

Conclusion: 所提出的智能数据增强方法能够生成高质量的合成数据，有效提升ABSA模型的性能，特别是对于T5-Base等模型，可以使其性能与更强大的模型相媲美。

Abstract: We propose an agentic data augmentation method for Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce high quality synthetic training examples. To isolate the effect of agentic structure, we also develop a closely matched prompting-based baseline using the same model and instructions. Both methods are evaluated across three ABSA subtasks (Aspect Term Extraction (ATE), Aspect Sentiment Classification (ATSC), and Aspect Sentiment Pair Extraction (ASPE)), four SemEval datasets, and two encoder-decoder models: T5-Base and Tk-Instruct. Our results show that the agentic augmentation outperforms raw prompting in label preservation of the augmented data, especially when the tasks require aspect term generation. In addition, when combined with real data, agentic augmentation provides higher gains, consistently outperforming prompting-based generation. These benefits are most pronounced for T5-Base, while the more heavily pretrained Tk-Instruct exhibits smaller improvements. As a result, augmented data helps T5-Base achieve comparable performance with its counterpart.

</details>


### [123] [Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents](https://arxiv.org/abs/2602.16699)
*Wenxuan Ding,Nicholas Tomlin,Greg Durrett*

Main category: cs.CL

TL;DR: 研究提出了一种名为Calibrate-Then-Act (CTA)的框架，通过显式地将成本-不确定性权衡引入LLM的决策过程，使其在与环境交互解决复杂问题时能够做出更优的探索决策。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM在处理需要与环境交互以获取信息并可能产生成本的问题时，其决策过程缺乏对成本-不确定性权衡的显式考虑，导致探索效率不高。

Method: 将信息检索和编码等任务形式化为不确定性下的序贯决策问题，并通过先验知识向LLM代理提供潜在环境状态。CTA框架通过向LLM提供额外的上下文信息，使其能够明确权衡探索成本与潜在收益，从而做出更优决策。实验中，对基线模型和CTA模型都进行了强化学习训练。

Result: 在信息获取问答和简化编码任务上的实验表明，CTA框架能够帮助代理发现更优的决策策略，有效平衡成本与效益。

Conclusion: 通过显式地让LLM考虑成本-不确定性权衡，CTA框架可以显著提升LLM在与环境交互时的探索效率和决策最优性。

Abstract: LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lower than the cost of making a mistake. In this work, we show that we can induce LLMs to explicitly reason about balancing these cost-uncertainty tradeoffs, then perform more optimal environment exploration. We formalize multiple tasks, including information retrieval and coding, as sequential decision-making problems under uncertainty. Each problem has latent environment state that can be reasoned about via a prior which is passed to the LLM agent. We introduce a framework called Calibrate-Then-Act (CTA), where we feed the LLM this additional context to enable it to act more optimally. This improvement is preserved even under RL training of both the baseline and CTA. Our results on information-seeking QA and on a simplified coding task show that making cost-benefit tradeoffs explicit with CTA can help agents discover more optimal decision-making strategies.

</details>


### [124] [TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers](https://arxiv.org/abs/2602.16429)
*Ido Levy,Eilam Shapira,Yinon Goldshtein,Avi Yaeli,Nir Mashkif,Segev Shlomov*

Main category: cs.CL

TL;DR: TabAgent 提出了一种框架，通过使用训练于执行轨迹的文本-表格分类器来替代智能体系统中用于闭集决策任务（如路由、筛选、门控和验证）的大语言模型（LLM）调用，从而显著降低延迟和成本。


<details>
  <summary>Details</summary>
Motivation: 现有的智能体系统通常依赖重复的 LLM 调用来执行闭集决策任务，这导致部署缓慢且成本高昂，原因是累积的延迟和 token 使用量。

Method: TabAgent 包含三个主要组件：(i) TabSchema，用于从智能体执行轨迹中提取结构化模式、状态和依赖特征；(ii) TabSynth，用于生成模式对齐的合成监督数据以增强覆盖范围；(iii) TabHead，一个轻量级分类器，用于对候选项进行评分。

Result: 在 AppWorld 基准测试中，TabAgent 保持了任务级别的成功率，同时消除了筛选阶段的 LLM 调用，将延迟降低了约 95%，并将推理成本降低了 85-91%。

Conclusion: TabAgent 是一种有效的框架，可以通过学习到的判别式模型替换生成式 LLM，从而解决生产环境中智能体架构中的生成式瓶颈问题，并且可以推广到其他智能体决策头。

Abstract: Agentic systems, AI architectures that autonomously execute multi-step workflows to achieve complex goals, are often built using repeated large language model (LLM) calls for closed-set decision tasks such as routing, shortlisting, gating, and verification. While convenient, this design makes deployments slow and expensive due to cumulative latency and token usage. We propose TabAgent, a framework for replacing generative decision components in closed-set selection tasks with a compact textual-tabular classifier trained on execution traces. TabAgent (i) extracts structured schema, state, and dependency features from trajectories (TabSchema), (ii) augments coverage with schema-aligned synthetic supervision (TabSynth), and (iii) scores candidates with a lightweight classifier (TabHead). On the long-horizon AppWorld benchmark, TabAgent maintains task-level success while eliminating shortlist-time LLM calls, reducing latency by approximately 95% and inference cost by 85-91%. Beyond tool shortlisting, TabAgent generalizes to other agentic decision heads, establishing a paradigm for learned discriminative replacements of generative bottlenecks in production agent architectures.

</details>


### [125] [Optimizing Soft Prompt Tuning via Structural Evolution](https://arxiv.org/abs/2602.16500)
*Zhenzhen Huang,Chaoning Zhang,Haoyu Bian,Songbo Zhang,Chi-lok Andy Tai,Jiaquan Zhang,Caiyan Qin,Jingjing Qu,Yalan Ye,Yang Yang,Heng Tao Shen*

Main category: cs.CL

TL;DR: 提出了一种基于拓扑形态演化的软提示调优优化方法，利用持久同调量化软提示在参数空间中的结构表示及其训练过程的演变，并通过构建拓扑软提示损失（TSLoss）来优化软提示，以提高其可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有软提示调优方法依赖高维、隐式表示，缺乏明确的语义和可追溯的训练行为，限制了其可解释性。

Method: 利用持久同调（TDA）量化软提示在连续参数空间中的结构表示及其训练过程的演变。设计了一种名为拓扑软提示损失（TSLoss）的损失函数，用于优化软提示调优，量化参数间的连通性和冗余度，引导模型学习结构稳定的适应性。

Result: 在实践中发现，拓扑上稳定且紧凑的软提示能够获得更好的下游任务性能。使用TSLoss进行训练可以加速收敛并提高调优性能。

Conclusion: 所提出的方法为理解和优化软提示调优提供了结构化和拓扑化视角的可解释方法，并能在实践中提升性能。

Abstract: Soft prompt tuning leverages continuous embeddings to capture task-specific information in large pre-trained language models (LLMs), achieving competitive performance in few-shot settings. However, soft prompts rely on high-dimensional, implicit representations and lack explicit semantics and traceable training behaviors, which limits their interpretability. To address this limitation, we propose a soft prompt tuning optimization method based on topological morphological evolution. Specifically, we employ persistent homology from topological data analysis (TDA) to quantify the structural representations of soft prompts in continuous parameter space and their training process evolution. Quantitative analysis shows that topologically stable and compact soft prompts achieve better downstream performance. Based on this empirical observation, we construct a loss function for optimizing soft prompt tuning, termed Topological Soft Prompt Loss (TSLoss). TSLoss guides the model to learn structurally stable adaptations by quantifying inter-parameter connectivity and redundancy. Extensive experiments show that training with TSLoss accelerates convergence and improves tuning performance, providing an interpretable method to understand and optimize soft prompt tuning from structural and topological perspectives.

</details>


### [126] [Training Models on Dialects of Translationese Shows How Lexical Diversity and Source-Target Syntactic Similarity Shape Learning](https://arxiv.org/abs/2602.16469)
*Jenny Kunz*

Main category: cs.CL

TL;DR: 本研究探讨了机器翻译文本（即翻译文本）对小型英语语言模型的影响，特别是翻译文本如何从不同源语言中塑造模型的语言可接受性判断和语言建模能力。


<details>
  <summary>Details</summary>
Motivation: 由于原生文本稀缺，机器翻译文本在多语言自然语言处理中被广泛使用。然而，翻译文本与原生文本存在系统性差异，这种现象被称为“翻译文本”，它反映了源语言的痕迹以及翻译本身的特性。本研究旨在了解这种翻译文本如何影响模型的学习。

Method: 研究人员使用来自 24 种在语言类型和资源上多样化的源语言的英语翻译文本来训练小型英语语言模型。通过这种方式，他们可以系统地分析源语言和语料库的特性如何影响模型所学到的知识。

Result: 研究结果表明，源语言对模型行为有显著影响。模型的整体困惑度（perplexity）更多地受到翻译语料库词汇多样性的驱动，而语法表现则在数据量足够的情况下，与源语言和英语的语言类型相似度密切相关。

Conclusion: 源语言的特性，包括其与英语的语言类型相似度以及翻译语料库的词汇多样性，都会对机器翻译数据训练出的语言模型产生影响，尤其是在语言可接受性判断和语言建模任务上。

Abstract: Machine-translated data is widely used in multilingual NLP, particularly when native text is scarce. However, translated text differs systematically from native text. This phenomenon is known as translationese, and it reflects both traces of the source language and characteristic properties of translation itself. In this paper, we study how training on machine-translated data affects small English language models, focusing on how translationese from different source languages shapes linguistic acceptability judgments and language modelling for different domains. We train models on English text translated from 24 typologically and resource-diverse source languages, enabling a systematic analysis of how source language and corpus properties influence what models learn. Our results show that the source language has a clear impact on model behavior: general perplexity is more driven by the lexical diversity of the translated corpus, while grammatical performance is strongly correlated to typological similarity to English, given enough data.

</details>


### [127] [Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable Multilingual LLM-Based Classification](https://arxiv.org/abs/2602.16516)
*Taja Kuzman Pungeršek,Peter Rupnik,Daniela Širinić,Nikola Ljubešić*

Main category: cs.CL

TL;DR: 本文介绍了ParlaCAP，一个用于分析欧洲议程设置的大规模数据集，并提出了一种构建特定领域政策主题分类器的有效方法。该方法利用LLM进行数据标注，并对多语言编码器模型进行微调，结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有议程设置研究受限于大规模、多语言的议会话语数据集，且缺乏有效的方法来构建特定领域的政策主题分类器。

Method: 使用 teacher-student 框架，高能力的LLM为多语言ParlaMint语料库（包含800万条欧洲议会演讲）标注数据，然后微调一个多语言编码器模型进行可扩展的数据标注。同时，还提供了议员、政党元数据和情感预测。

Result: 所提出的方法生成的分类器能够很好地适应目标领域，与人类标注者的一致性接近，并且性能优于在手动标注但非目标域数据上训练的现有CAP分类器。

Conclusion: ParlaCAP数据集为跨国政治关注和代表性研究提供了丰富资源，并展示了其在分析议会关注点分布、演讲情感模式和性别差异方面的潜力。

Abstract: This paper introduces ParlaCAP, a large-scale dataset for analyzing parliamentary agenda setting across Europe, and proposes a cost-effective method for building domain-specific policy topic classifiers. Applying the Comparative Agendas Project (CAP) schema to the multilingual ParlaMint corpus of over 8 million speeches from 28 parliaments of European countries and autonomous regions, we follow a teacher-student framework in which a high-performing large language model (LLM) annotates in-domain training data and a multilingual encoder model is fine-tuned on these annotations for scalable data annotation. We show that this approach produces a classifier tailored to the target domain. Agreement between the LLM and human annotators is comparable to inter-annotator agreement among humans, and the resulting model outperforms existing CAP classifiers trained on manually-annotated but out-of-domain data. In addition to the CAP annotations, the ParlaCAP dataset offers rich speaker and party metadata, as well as sentiment predictions coming from the ParlaSent multilingual transformer model, enabling comparative research on political attention and representation across countries. We illustrate the analytical potential of the dataset with three use cases, examining the distribution of parliamentary attention across policy topics, sentiment patterns in parliamentary speech, and gender differences in policy attention.

</details>


### [128] [CitiLink-Summ: Summarization of Discussion Subjects in European Portuguese Municipal Meeting Minutes](https://arxiv.org/abs/2602.16607)
*Miguel Marques,Ana Luísa Fernandes,Ana Filipa Pacheco,Rute Rebouças,Inês Cantante,José Isidro,Luís Filipe Cunha,Alípio Jorge,Nuno Guimarães,Sérgio Nunes,António Leal,Purificação Silvano,Ricardo Campos*

Main category: cs.CL

TL;DR: 本文介绍了CitiLink-Summ数据集，它包含了欧洲葡萄牙语的市政会议记录及其摘要，旨在为市政记录自动摘要研究提供资源，并利用此数据集建立了基于先进生成模型和大型语言模型的基线性能。


<details>
  <summary>Details</summary>
Motivation: 市政会议记录冗长且难以理解，阻碍了公民参与。现有研究在低资源语言和市政记录摘要领域存在不足，关键在于缺乏高质量的摘要数据集。

Method: 构建了一个包含100篇欧洲葡萄牙语市政会议记录和2,322个对应讨论主题的手写摘要的数据集CitiLink-Summ。利用该数据集，采用BART、PRIMERA等生成模型以及大型语言模型（LLMs）进行自动摘要，并使用ROUGE、BLEU、METEOR和BERTScore等指标进行评估。

Result: 利用CitiLink-Summ数据集，为市政记录摘要领域建立了首个欧洲葡萄牙语的基线性能。评估结果展示了不同模型在摘要任务上的表现。

Conclusion: CitiLink-Summ数据集为欧洲葡萄牙语市政记录的自动摘要研究提供了重要的基准和资源，有助于推动处理复杂行政文本的自然语言处理研究。

Abstract: Municipal meeting minutes are formal records documenting the discussions and decisions of local government, yet their content is often lengthy, dense, and difficult for citizens to navigate. Automatic summarization can help address this challenge by producing concise summaries for each discussion subject. Despite its potential, research on summarizing discussion subjects in municipal meeting minutes remains largely unexplored, especially in low-resource languages, where the inherent complexity of these documents adds further challenges. A major bottleneck is the scarcity of datasets containing high-quality, manually crafted summaries, which limits the development and evaluation of effective summarization models for this domain. In this paper, we present CitiLink-Summ, a new corpus of European Portuguese municipal meeting minutes, comprising 100 documents and 2,322 manually hand-written summaries, each corresponding to a distinct discussion subject. Leveraging this dataset, we establish baseline results for automatic summarization in this domain, employing state-of-the-art generative models (e.g., BART, PRIMERA) as well as large language models (LLMs), evaluated with both lexical and semantic metrics such as ROUGE, BLEU, METEOR, and BERTScore. CitiLink-Summ provides the first benchmark for municipal-domain summarization in European Portuguese, offering a valuable resource for advancing NLP research on complex administrative texts.

</details>


### [129] [ColBERT-Zero: To Pre-train Or Not To Pre-train ColBERT models](https://arxiv.org/abs/2602.16609)
*Antoine Chaffin,Luca Arnaboldi,Amélie Chatelain,Florent Krzakala*

Main category: cs.CL

TL;DR: 本文研究了多向量模型的预训练方法，发现大规模多向量预训练能显著提升模型性能。通过完全预训练的ColBERT-Zero模型，在公开数据上取得了超越利用闭源强数据集的GTE-ModernColBERT及其基础模型GTE-ModernBERT的SOTA性能。此外，文章还提出了一种先监督微调再知识蒸馏的方法，能在跳过昂贵无监督阶段的情况下获得接近完全预训练的效果。最后，强调了微调与预训练设置对齐的重要性，并开源了相关代码和模型。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的多向量模型依赖于在强大的单向量模型上进行小的知识蒸馏（KD）训练，利用了大规模预训练的优势。本研究旨在探索直接预训练多向量模型，以获得更强的多向量模型。

Method: 本文采用了大规模多向量预训练方法，并进行了实验对比。研究了两种改进策略：1) 在KD前增加监督微调步骤；2) 确保微调与预训练设置的一致性。同时，开源了训练代码和模型。

Result: 1) 大规模多向量预训练显著优于仅进行小规模KD。2) 完全预训练的ColBERT-Zero模型在公开数据上性能优于使用闭源强数据集的GTE-ModernColBERT及其基础模型GTE-ModernBERT，达到SOTA。3) 在KD前加入监督微调步骤，可以在跳过昂贵的无监督预训练阶段的情况下，获得接近完全预训练的效果。4) 微调与预训练设置的对齐对于复用模型至关重要。

Conclusion: 大规模多向量预训练是构建更强多向量模型的有效途径。结合监督微调和知识蒸馏可以提高效率，同时对齐预训练和微调设置是实现最佳性能的关键。

Abstract: Current state-of-the-art multi-vector models are obtained through a small Knowledge Distillation (KD) training step on top of strong single-vector models, leveraging the large-scale pre-training of these models. In this paper, we study the pre-training of multi-vector models and show that large-scale multi-vector pre-training yields much stronger multi-vector models. Notably, a fully ColBERT-pre-trained model, ColBERT-Zero, trained only on public data, outperforms GTE-ModernColBERT as well as its base model, GTE-ModernBERT, which leverages closed and much stronger data, setting new state-of-the-art for model this size. We also find that, although performing only a small KD step is not enough to achieve results close to full pre-training, adding a supervised step beforehand allows to achieve much closer performance while skipping the most costly unsupervised phase. Finally, we find that aligning the fine-tuning and pre-training setups is crucial when repurposing existing models. To enable exploration of our results, we release various checkpoints as well as code used to train them.

</details>


### [130] [AREG: Adversarial Resource Extraction Game for Evaluating Persuasion and Resistance in Large Language Models](https://arxiv.org/abs/2602.16639)
*Adib Sakhawat,Fardeen Sadab*

Main category: cs.CL

TL;DR: 本研究提出了一个名为AREG的新基准，用于评估大型语言模型（LLM）在多轮、零和的财务资源谈判中的说服和抵抗能力。发现这两种能力呈弱相关且可以分离，抵抗能力普遍优于说服能力，并指出交互结构对结果有重要影响。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM评估方法侧重于静态文本生成，无法捕捉其在动态、对抗性交互中的社交智能。需要一种新的评估框架来衡量LLM的说服和抵抗能力。

Method: 引入了“对抗性资源提取游戏”（AREG）基准，该基准通过多轮、零和的财务资源谈判来模拟说服和抵抗。在一个循环赛制的比赛中，对前沿LLM进行了评估，以联合评估它们的说服（进攻）和抵抗（防御）能力。

Result: 说服和抵抗能力之间的相关性较弱（ρ=0.33），并且是经验上分离的：强大的说服能力并不一定预示着强大的抵抗能力，反之亦然。在所有评估模型中，抵抗得分普遍高于说服得分，表明在对抗性对话环境中存在系统性的防御优势。语言分析表明，交互结构（例如，增量承诺寻求策略和验证寻求响应）对这些结果起着关键作用。

Conclusion: LLM的社交影响力并非单一能力，仅关注说服能力的评估框架可能会忽略不对称的行为脆弱性。AREG基准为评估和理解LLM在社交交互中的复杂能力提供了一个新的视角。

Abstract: Evaluating the social intelligence of Large Language Models (LLMs) increasingly requires moving beyond static text generation toward dynamic, adversarial interaction. We introduce the Adversarial Resource Extraction Game (AREG), a benchmark that operationalizes persuasion and resistance as a multi-turn, zero-sum negotiation over financial resources. Using a round-robin tournament across frontier models, AREG enables joint evaluation of offensive (persuasion) and defensive (resistance) capabilities within a single interactional framework. Our analysis provides evidence that these capabilities are weakly correlated ($ρ= 0.33$) and empirically dissociated: strong persuasive performance does not reliably predict strong resistance, and vice versa. Across all evaluated models, resistance scores exceed persuasion scores, indicating a systematic defensive advantage in adversarial dialogue settings. Further linguistic analysis suggests that interaction structure plays a central role in these outcomes. Incremental commitment-seeking strategies are associated with higher extraction success, while verification-seeking responses are more prevalent in successful defenses than explicit refusal. Together, these findings indicate that social influence in LLMs is not a monolithic capability and that evaluation frameworks focusing on persuasion alone may overlook asymmetric behavioral vulnerabilities.

</details>


### [131] [Quecto-V1: Empirical Analysis of 8-bit Quantized Small Language Models for On-Device Legal Retrieval](https://arxiv.org/abs/2602.16640)
*Subrit Dikshit*

Main category: cs.CL

TL;DR: 本文提出了 Quecto-V1，一个专门针对印度法律领域的 1.24 亿参数的小型语言模型（SLM）。该模型经过大量印度法律文献的训练，并采用 8 位量化技术，使其在本地设备上可离线运行，内存占用小于 150MB，在法律定义和条款检索任务上表现优于通用 SLM。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在法律领域的应用存在资源门槛和数据主权风险。研究旨在为资源受限的环境和注重数据隐私的场景提供一个可行的解决方案， democratize access to Indian legal intelligence。

Method: 使用 GPT-2 架构（1.24 亿参数）构建了一个领域特定的 SLM（Quecto-V1），并仅使用印度法律文献（包括 IPC、CrPC 和印度宪法）进行从头训练。采用后训练 8 位量化（GGUF 格式）来减小模型大小。通过实证分析和消融研究来评估模型性能。

Result: Quecto-V1 在检索法定定义和处罚规定方面具有高保真度，在特定领域的精确匹配任务上优于通用 SLM。8 位量化将模型大小减少了 74%，同时检索准确率仅下降了不到 3.5%。模型可完全离线运行在消费级 CPU 上。

Conclusion: 对于法律等专业且高风险的领域，领域特定训练结合激进的量化技术，是替代大型云端模型的一种可行且能保护隐私的方案。

Abstract: The rapid proliferation of Large Language Models (LLMs) has revolutionized Natural Language Processing (NLP) but has simultaneously created a "resource divide." State-of-the-art legal intelligence systems typically rely on massive parameter counts (7B+) and cloud-based inference, rendering them inaccessible to practitioners in resource-constrained environments and posing significant data sovereignty risks. This paper introduces Quecto-V1, a domain-specific Small Language Model (SLM) engineered to democratize access to Indian legal intelligence. Built upon a custom configuration of the GPT-2 architecture (124 million parameters), Quecto-V1 was trained from scratch exclusively on a corpus of Indian statutes, including the Indian Penal Code (IPC), the Code of Criminal Procedure (CrPC), and the Constitution of India. Unlike generalist models, which prioritize broad world knowledge, our approach maximizes "lexical density" within the legal domain. Furthermore, we address the deployment bottleneck by applying post-training 8-bit quantization (GGUF format), compressing the model to a memory footprint of under 150 MB. Our empirical analysis demonstrates that Quecto-V1 achieves high fidelity in retrieving statutory definitions and penal provisions, outperforming general-purpose SLMs in domain-specific exact match tasks while running entirely offline on consumer-grade CPUs. We further present an ablation study showing that 8-bit quantization yields a 74% reduction in model size with less than 3.5% degradation in retrieval accuracy compared to full-precision baselines. These findings suggest that for specialized, high-stakes domains like law, domain-specific training coupled with aggressive quantization offers a viable, privacy-preserving alternative to monolithic cloud models.

</details>


### [132] [Utility-Preserving De-Identification for Math Tutoring: Investigating Numeric Ambiguity in the MathEd-PII Benchmark Dataset](https://arxiv.org/abs/2602.16571)
*Zhuqian Zhou,Kirk Vanacore,Bakhtawar Ahtisham,Jinsook Lee,Doug Pietrzak,Daryl Hedley,Jorge Dias,Chris Shaw,Ruth Schäfer,René F. Kizilcec*

Main category: cs.CL

TL;DR: 该研究提出了MathEd-PII，一个包含1000个数学辅导对话的基准数据集，用于解决数学辅导记录中个人身份信息（PII）检测的“数字歧义”问题，并开发了一种数学感知的提示策略，显著提高了PII检测的准确性，同时保留了教育数据的效用。


<details>
  <summary>Details</summary>
Motivation: 在数学辅导记录中，数字表达式经常被误识别为个人身份信息（PII），导致通用PII检测系统过度删除关键的教学内容，降低了数据集的可用性。本研究旨在解决这一问题，提高PII检测在数学辅导记录中的准确性，同时保留其教育价值。

Method: 研究者提出了MathEd-PII数据集，该数据集通过一个包含人工审核的LLM工作流程构建，包含1000个辅导会话（115,620条消息；769,628个token），并带有经过验证的PII标注。研究者还使用基于密度的分割方法分析了PII的误删除情况。最后，研究者比较了四种PII检测策略：Presidio基线模型和三种基于LLM的方法（基本提示、数学感知提示、片段感知提示）。

Result: 研究发现，PII的误删除不成比例地集中在数学密集区域，证实了数字歧义是主要的失败模式。数学感知提示策略相比Presidio基线模型，F1分数从0.379显著提高到0.821，并且减少了数字相关的假阳性。这表明将领域上下文纳入PII检测对于保留数据的分析效用至关重要。

Conclusion: 本研究为数学辅导数据的PII检测提供了一个新的基准数据集（MathEd-PII）和一个有效的方法。结论是，在辅导数据中实现保留效用的PII去识别化，必须采用领域感知的建模方法，特别是考虑到数字信息的歧义性。

Abstract: Large-scale sharing of dialogue-based data is instrumental for advancing the science of teaching and learning, yet rigorous de-identification remains a major barrier. In mathematics tutoring transcripts, numeric expressions frequently resemble structured identifiers (e.g., dates or IDs), leading generic Personally Identifiable Information (PII) detection systems to over-redact core instructional content and reduce dataset utility. This work asks how PII can be detected in math tutoring transcripts while preserving their educational utility. To address this challenge, we investigate the "numeric ambiguity" problem and introduce MathEd-PII, the first benchmark dataset for PII detection in math tutoring dialogues, created through a human-in-the-loop LLM workflow that audits upstream redactions and generates privacy-preserving surrogates. The dataset contains 1,000 tutoring sessions (115,620 messages; 769,628 tokens) with validated PII annotations. Using a density-based segmentation method, we show that false PII redactions are disproportionately concentrated in math-dense regions, confirming numeric ambiguity as a key failure mode. We then compare four detection strategies: a Presidio baseline and LLM-based approaches with basic, math-aware, and segment-aware prompting. Math-aware prompting substantially improves performance over the baseline (F1: 0.821 vs. 0.379) while reducing numeric false positives, demonstrating that de-identification must incorporate domain context to preserve analytic utility. This work provides both a new benchmark and evidence that utility-preserving de-identification for tutoring data requires domain-aware modeling.

</details>


### [133] [Reinforced Fast Weights with Next-Sequence Prediction](https://arxiv.org/abs/2602.16704)
*Hee Seung Hwang,Xindi Wu,Sanghyuk Chun,Olga Russakovsky*

Main category: cs.CL

TL;DR: 本文提出了一种名为 REFINE 的强化学习框架，用于改进快速权重模型在长上下文建模方面的表现，通过采用下一序列预测（NSP）目标来克服传统下一词预测（NTP）的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的快速权重模型在长上下文建模方面潜力受限，因为其训练范式（NTP）只关注单下一个词的预测，忽略了多词序列的语义连贯性，导致模型学习到的表征不佳，无法捕捉长距离依赖。作者希望通过改进训练目标来解决这个问题。

Method: REFINE 框架利用强化学习，采用下一序列预测（NSP）目标来训练快速权重模型。具体方法包括：1. 基于预测熵选择信息量大的 token 位置；2. 生成多 token 的 rollout；3. 给予自监督的序列级奖励；4. 使用组相对策略优化（GRPO）进行模型优化。该框架可应用于预训练语言模型的训练生命周期中（中期训练、后期训练、测试时训练）。

Result: 在 LaCT-760M 和 DeltaNet-1.3B 数据集上的实验表明，REFINE 在“针尖找针”检索、长上下文问答以及 LongBench 的各项任务中，始终优于使用 NTP 进行监督微调的方法。

Conclusion: REFINE 为提高快速权重架构中的长上下文建模能力提供了一个有效且通用的框架，通过引入 NSP 目标和强化学习机制，显著提升了模型在处理长序列信息时的性能。

Abstract: Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token predictions and ignores semantic coherence across multiple tokens following a prefix. Consequently, fast weight models, which dynamically update their parameters to store contextual information, learn suboptimal representations that fail to capture long-range dependencies. We introduce REFINE (Reinforced Fast weIghts with Next sEquence prediction), a reinforcement learning framework that trains fast weight models under the next-sequence prediction (NSP) objective. REFINE selects informative token positions based on prediction entropy, generates multi-token rollouts, assigns self-supervised sequence-level rewards, and optimizes the model with group relative policy optimization (GRPO). REFINE is applicable throughout the training lifecycle of pre-trained language models: mid-training, post-training, and test-time training. Our experiments on LaCT-760M and DeltaNet-1.3B demonstrate that REFINE consistently outperforms supervised fine-tuning with NTP across needle-in-a-haystack retrieval, long-context question answering, and diverse tasks in LongBench. REFINE provides an effective and versatile framework for improving long-context modeling in fast weight architectures.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [134] [EdgeNav-QE: QLoRA Quantization and Dynamic Early Exit for LAM-based Navigation on Edge Devices](https://arxiv.org/abs/2602.15836)
*Mengyun Liu,Shanshan Huang,Jianan Jiang*

Main category: cs.RO

TL;DR: EdgeNav-QE 框架通过结合 QLoRA 和动态早退机制，显著提高了在大规模行动模型（LAMs）在边缘设备上进行实时导航的效率，在降低延迟和内存占用的同时，保持了高导航成功率。


<details>
  <summary>Details</summary>
Motivation: 将参数量巨大的 LAMs 部署到内存受限、对延迟要求高的边缘设备上存在挑战。

Method: 提出 EdgeNav-QE 框架，集成量化低秩适应（QLoRA）和动态早退（DEE）机制。通过将骨干网络量化到 4 位精度，并策略性地放置早退分支，实现针对简单导航任务的早期推理终止，而复杂任务则继续使用完整深度。

Result: 在 Habitat-Sim 环境和 Matterport3D 数据集上，使用 OpenVLA-7B 作为骨干，EdgeNav-QE 相较于全精度基线，推理延迟降低了 82.7%，内存占用减少了 66.7%，导航成功率仍保持在 81.8%。与静态早退方法相比，延迟降低了 17.9%。

Conclusion: EdgeNav-QE 框架有效地优化了 LAMs 在边缘导航中的性能，通过内容感知的自适应计算，在满足安全关键应用需求的场景下，实现了显著的效率提升。

Abstract: Large Action Models (LAMs) have shown immense potential in autonomous navigation by bridging high-level reasoning with low-level control. However, deploying these multi-billion parameter models on edge devices remains a significant challenge due to memory constraints and latency requirements. In this paper, we propose EdgeNav-QE, a novel framework that integrates Quantized Low-Rank Adaptation (QLoRA) with a dynamic early-exit (DEE) mechanism to optimize LAMs for real-time edge navigation. By quantizing the backbone to 4-bit precision and strategically placing early-exit branches, we enable the model to terminate inference early for simple navigation tasks while retaining full depth for complex decision-making. Experimental results on the Habitat-Sim environment with Matterport3D dataset using OpenVLA-7B backbone, demonstrate that EdgeNav-QE reduces inference latency by 82.7% and memory footprint by 66.7% compared to full-precision baselines, while maintaining 81.8% navigation success rate. Furthermore, it outperforms state-of-the-art static early-exit method by 17.9% in latency, demonstrating the superiority of content-aware adaptive computation for safety-critical applications.

</details>


### [135] [From Conflicts to Collisions: A Two-Stage Collision Scenario-Testing Approach for Autonomous Driving Systems](https://arxiv.org/abs/2602.15837)
*Siyuan Chen,Fuyuan Zhang,Hua Qi,Lei Ma,Tomoyuki Tsuchiya,Michio Hayashi,Manabu Okada*

Main category: cs.RO

TL;DR: 本文提出了一种两阶段的自动驾驶系统（ADS）场景测试框架，通过搜索“冲突”情景并将其变异以诱发实际碰撞，提高了测试效率和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有ADS测试方法主要关注接近碰撞的场景，忽略了其他危险情况。需要更全面的方法来发现更多类型的碰撞。

Method: 提出“冲突”作为中间搜索目标，并设计了一个两阶段的场景测试框架：首先搜索冲突，然后变异冲突场景以诱发碰撞。

Result: 在Baidu Apollo上评估，该方法在一个运行中发现了多达12种不同的碰撞类型，比现有基线方法发现的多一倍，并且由于针对冲突的变异，所需的模拟次数更少。

Conclusion: 将冲突作为中间目标可以拓宽搜索范围，显著提高ADS安全评估的效率和有效性。

Abstract: Autonomous driving systems (ADS) are safety-critical and require rigorous testing before public deployment. Simulation-based scenario testing provides a safe and cost-effective alternative to extensive on-road trials, enabling efficient evaluation of ADS under diverse and high-risk conditions. However, existing approaches mainly evaluates the scenarios based on their proximity to collisions and focus on scenarios already close to collision, leaving many other hazardous situations unexplored. To bridge this, we introduce a collision-related concept of conflict as an intermediate search target and propose a two-stage scenario testing framework that first searches for conflicts and then mutates these conflict scenarios to induce actual collisions. Evaluated on Baidu Apollo, our approach reveals up to 12 distinct collision types in a single run, doubling the diversity discovered by state-of-the-art baselines while requiring fewer simulations thanks to conflict-targeted mutations. These results show that using conflicts as intermediate objectives broadens the search horizon and significantly improves the efficiency and effectiveness of ADS safety evaluation.

</details>


### [136] [VGGT-based online 3D semantic SLAM for indoor scene understanding and navigation](https://arxiv.org/abs/2602.15899)
*Anna Gelencsér-Horváth,Gergely Dinya,Dorka Boglárka Erős,Péter Halász,Islam Muhammad Muqsit,Kristóf Karacs*

Main category: cs.RO

TL;DR: SceneVGGT是一个结合SLAM和语义映射的时空3D场景理解框架，通过滑动窗口流水线实现了对长视频流的处理，并在ScanNet++基准测试中取得了有竞争力的点云性能，同时内存占用稳定，适合辅助导航。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为了开发一个能够对长视频流进行时空3D场景理解的框架，并将其应用于自主和辅助导航，同时需要解决内存和速度效率问题。

Method: 该方法基于VGGT，利用滑动窗口流水线处理长视频流。它通过相机姿态变换来对齐局部子地图，从而实现内存和速度高效的建图并保持几何一致性。语义信息从2D实例掩码提升到3D对象，并利用VGGT的跟踪头来保持时间上一致的对象身份，便于变化检测。最后，将对象位置投影到估计的地面平面上以实现辅助导航。

Result: 该流水线的GPU内存使用量保持在17 GB以下，与输入序列的长度无关。在ScanNet++基准测试中，该方法取得了具有竞争力的点云性能。SceneVGGT能够确保鲁棒的语义识别，并且速度足够快，能够支持带有音频反馈的交互式辅助导航。

Conclusion: SceneVGGT是一个有效且高效的时空3D场景理解框架，能够处理长视频流，并成功应用于辅助导航场景，实现了鲁棒的语义识别和实时的交互能力。

Abstract: We present SceneVGGT, a spatio-temporal 3D scene understanding framework that combines SLAM with semantic mapping for autonomous and assistive navigation. Built on VGGT, our method scales to long video streams via a sliding-window pipeline. We align local submaps using camera-pose transformations, enabling memory- and speed-efficient mapping while preserving geometric consistency. Semantics are lifted from 2D instance masks to 3D objects using the VGGT tracking head, maintaining temporally coherent identities for change detection. As a proof of concept, object locations are projected onto an estimated floor plane for assistive navigation. The pipeline's GPU memory usage remains under 17 GB, irrespectively of the length of the input sequence and achieves competitive point-cloud performance on the ScanNet++ benchmark. Overall, SceneVGGT ensures robust semantic identification and is fast enough to support interactive assistive navigation with audio feedback.

</details>


### [137] [TurboADMM: A Structure-Exploiting Parallel Solver for Multi-Agent Trajectory Optimization](https://arxiv.org/abs/2602.15838)
*Yucheng Chen*

Main category: cs.RO

TL;DR: 本文提出了一种名为TurboADMM的新型单机二次规划（QP）求解器，用于解决多智能体轨迹优化问题。它通过结合ADMM分解、Riccati预热启动和qpOASES的参数化QP热启动，在智能体数量上实现了近乎线性的复杂度和高效求解。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体轨迹优化方法在求解大规模耦合QP时面临可扩展性问题，无法同时利用时间结构、智能体分解和迭代相似性。通用QP求解器在智能体数量增加时难以扩展，而利用时间结构的方法在密集耦合约束下表现不佳。

Method: TurboADMM是一个专门为多智能体轨迹优化设计的单机QP求解器，它通过三个互补的组件实现高效求解：1. ADMM分解将问题分解为可并行求解的每个智能体子问题，保留了块三对角结构。2. Riccati预热启动利用时间结构为每个智能体的QP提供高质量的初始值。3. qpOASES的参数化QP热启动在ADMM迭代过程中重用KKT系统分解。

Result: TurboADMM在智能体数量上实现了经验上的近乎线性复杂度，能够高效地解决多智能体轨迹优化问题。

Conclusion: TurboADMM通过系统地协同设计ADMM分解、Riccati预热启动和参数化QP热启动，有效解决了现有QP求解器在多智能体轨迹优化中的可扩展性问题，并在智能体数量上实现了高效求解。

Abstract: Multi-agent trajectory optimization with dense interaction networks require solving large coupled QPs at control rates, yet existing solvers fail to simultaneously exploit temporal structure, agent decomposition, and iteration similarity. One usually treats multi-agent problems monolithically when using general-purpose QP solvers (OSQP, MOSEK), which encounter scalability difficulties with agent count. Structure-exploiting solvers (HPIPM) leverage temporal structure through Riccati recursion but can be vulnerable to dense coupling constraints. We introduce TurboADMM, a specialized single-machine QP solver that achieves empirically near linear complexity in agent count through systematic co-design of three complementary components: (1) ADMM decomposition creates per-agent subproblems solvable in parallel, preserving block-tridiagonal structure under dense coupling; (2) Riccati warmstart exploits temporal structure to provide high-quality primal-dual initialization for each agent's QP; (3) parametric QP hotstart \footnote{In the paper, we refer warmstart as the technique that uses the Riccati equation results as auxiliary QP initialization for a single QP solve, while hotstart as reusing the QR factorization across QP solve iterations.}in qpOASES reuses similar KKT system factorizations across ADMM iterations.

</details>


### [138] [A Decade of Human-Robot Interaction through Immersive Lenses: A Literature Review on Extended Reality as a Research Instrument in Social Robotics](https://arxiv.org/abs/2602.15840)
*André Helgert,Carolin Straßmann,Sabrina C. Eimler*

Main category: cs.RO

TL;DR: 对2015-2025年期间的33项关于扩展现实（XR）与社交机器人交互（XR-HRI）的实证研究进行了系统性回顾，发现该领域仍处于早期阶段，主要局限于实验室模拟，研究方法、硬件软件细节报告不充分，机器人互动性不强，研究者和参与者群体存在同质化问题。文章提出了一个包含五个阶段的路线图，旨在推动XR-HRI成为一个可靠且生态有效的社交机器人学研究媒介。


<details>
  <summary>Details</summary>
Motivation: 尽管XR在人机交互研究中受到关注，但在社交机器人学的实证研究中仍未得到充分探索。作者旨在系统性地梳理和分析该领域的研究现状，识别关键挑战，并提出未来发展方向。

Method: 通过对2015年至2025年发表的6,527篇同行评审文章进行系统性回顾，筛选出33篇符合严格纳入标准的实证研究。对这些研究进行了以下方面的检查：（1）XR与虚拟社交机器人的使用方式和背景；（2）数据收集和分析方法；（3）研究者和参与者的人口统计学特征；（4）研究中提出的挑战和未来研究议程。最后，基于分析结果提出了一个五阶段的路线图。

Result: 社交XR-HRI研究主要局限于实验室模拟，硬件、软件和机器人等关键技术细节常被忽略。机器人通常作为被动的视觉刺激，其互动性较弱，且现代头戴显示器丰富的生物信号（如眼动追踪）和记录功能未被充分利用。研究团队和参与者样本以西方、年轻、男性为主，且常缺乏人口统计学报告。研究的主要局限性包括硬件延迟、样本同质性低以及研究周期短浅。

Conclusion: 社交XR-HRI仍是一个新兴的研究领域，需要改进方法论创新、提高生态有效性、增强机器人互动质量、促进样本多样性，并建立统一的研究分类法，才能使其从实验室原型发展成为一个可靠且生态有效的社交机器人学研究工具。

Abstract: Over the past decade, extended reality (XR), including virtual, augmented, and mixed reality, gained attention as a research instrument in human-robot interaction studies, but remains underexplored in empirical investigations of social robotics. To map the field, we systematically reviewed empirical studies from 2015 to 2025. Of 6,527 peer-reviewed articles, only 33 met strict inclusion criteria. We examined (1) how XR and virtual social robots are used and in which contexts, (2) data collection and analysis methods, (3) demographics of the researchers and participants, and (4) the stated challenges and future agendas. Our findings show that social XR-HRI research is still dominated by laboratory simulations, while crucial specifications like used hardware, software, and robots are often not reported. Robots typically act as passive and less interactive visual stimuli, while the rich biosignal (e.g., eye-tracking) and logging functions of modern head-mounted displays remain largely untapped. The research teams and samples are predominantly tech-centric, Western, young, and male, with frequent gaps in demographic reporting. Key limitations include hardware delays, small homogeneous samples, and short, shallow study cycles. We propose a five-phase roadmap to establish social XR-HRI as a reliable research medium, which includes fostering methodological innovation, a reinforced ecological validity by, e.g., using application contexts, the improvement of the robot's interaction quality, promoting diversity in the sample and the development of a social XR-HRI taxonomy. Advancing in these directions is essential for XR to mature from a lab prototype into an ecologically valid research instrument for social robotics.

</details>


### [139] [ReasonNavi: Human-Inspired Global Map Reasoning for Zero-Shot Embodied Navigation](https://arxiv.org/abs/2602.15864)
*Yuzhuo Ao,Anbang Wang,Yu-Wing Tai,Chi-Keung Tang*

Main category: cs.RO

TL;DR: 提出了一种名为ReasonNavi的框架，通过结合多模态大语言模型（MLLM）和确定性规划器，实现了受人类启发的导航，无需MLLM微调，在各项导航任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有具身智能体在导航时主要依赖局部观察，缺乏全局视野，导致探索效率低下。而人类则擅长利用地图进行全局规划，然后局部执行。

Method: ReasonNavi框架将顶视图地图转换为离散推理空间（通过房间分割和候选目标节点采样），然后利用MLLM进行多阶段推理，选择与指令（对象、图像或文本目标）最一致的候选点。选定的航点通过在线构建的占位图上的确定性动作规划器，转化为可执行轨迹。同时，利用预训练的对象检测和分割器确保目标识别的鲁棒性。

Result: ReasonNavi在三个导航任务上始终优于需要大量训练或复杂场景建模的现有方法，提供了一种可扩展、可解释且具有全局视野的具身导航解决方案。

Conclusion: ReasonNavi是一种统一的零样本导航框架，它借鉴了人类的“先推理后行动”的导航范式，通过结合MLLM的语义推理能力和确定性规划器，克服了现有方法的局限性，并能够随着基础模型的改进而自然扩展。

Abstract: Embodied agents often struggle with efficient navigation because they rely primarily on partial egocentric observations, which restrict global foresight and lead to inefficient exploration. In contrast, humans plan using maps: we reason globally first, then act locally. We introduce ReasonNavi, a human-inspired framework that operationalizes this reason-then-act paradigm by coupling Multimodal Large Language Models (MLLMs) with deterministic planners. ReasonNavi converts a top-down map into a discrete reasoning space by room segmentation and candidate target nodes sampling. An MLLM is then queried in a multi-stage process to identify the candidate most consistent with the instruction (object, image, or text goal), effectively leveraging the model's semantic reasoning ability while sidestepping its weakness in continuous coordinate prediction. The selected waypoint is grounded into executable trajectories using a deterministic action planner over an online-built occupancy map, while pretrained object detectors and segmenters ensure robust recognition at the goal. This yields a unified zero-shot navigation framework that requires no MLLM fine-tuning, circumvents the brittleness of RL-based policies and scales naturally with foundation model improvements. Across three navigation tasks, ReasonNavi consistently outperforms prior methods that demand extensive training or heavy scene modeling, offering a scalable, interpretable, and globally grounded solution to embodied navigation. Project page: https://reasonnavi.github.io/

</details>


### [140] [MARVL: Multi-Stage Guidance for Robotic Manipulation via Vision-Language Models](https://arxiv.org/abs/2602.15872)
*Xunlan Zhou,Xuanlin Chen,Shaowei Zhang,Xiangkun Li,ShengHua Wan,Xiaohai Hu,Yuan Lei,Le Gan,De-chuan Zhan*

Main category: cs.RO

TL;DR: 本文提出了一种名为MARVL的方法，通过微调视觉语言模型（VLM）并将其应用于多阶段任务引导，来解决手动设计机器人强化学习（RL）奖励函数效率低和泛化性差的问题，并在Meta-World基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 手动设计机器人强化学习（RL）的密集奖励函数效率低下且难以扩展和自动化。现有的基于视觉语言模型（VLM）的奖励设计方法存在与任务进度不一致、空间定位困难和语义理解有限等问题。

Method: MARVL方法首先微调VLM以实现空间和语义的一致性，然后将任务分解为多个子任务，并采用任务方向投影来提高轨迹的敏感度。

Result: 在Meta-World基准测试中，MARVL显著优于现有的VLM奖励方法，在稀疏奖励操作任务上表现出更高的样本效率和鲁棒性。

Conclusion: MARVL通过多阶段引导和VLM微调，有效克服了现有VLM奖励设计的局限性，为机器人RL的奖励设计提供了一种更有效和自动化的解决方案。

Abstract: Designing dense reward functions is pivotal for efficient robotic Reinforcement Learning (RL). However, most dense rewards rely on manual engineering, which fundamentally limits the scalability and automation of reinforcement learning. While Vision-Language Models (VLMs) offer a promising path to reward design, naive VLM rewards often misalign with task progress, struggle with spatial grounding, and show limited understanding of task semantics. To address these issues, we propose MARVL-Multi-stAge guidance for Robotic manipulation via Vision-Language models. MARVL fine-tunes a VLM for spatial and semantic consistency and decomposes tasks into multi-stage subtasks with task direction projection for trajectory sensitivity. Empirically, MARVL significantly outperforms existing VLM-reward methods on the Meta-World benchmark, demonstrating superior sample efficiency and robustness on sparse-reward manipulation tasks.

</details>


### [141] [Test-Time Adaptation for Tactile-Vision-Language Models](https://arxiv.org/abs/2602.15873)
*Chuyang Ye,Haoxian Jing,Qinting Jiang,Yixi Lin,Qiang Li,Xing Tang,Jingyan Jiang*

Main category: cs.RO

TL;DR: 提出一种用于触觉-视觉-语言（TVL）模型的测试时自适应（TTA）框架，该框架通过估计模态可靠性来应对测试时分布变化，提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有TTA方法在处理模态异步变化和部分模态不可靠时表现不佳，急需一种能够明确处理模态可靠性的TTA方法。

Method: 通过预测不确定性和基于扰动的响应来估计每种模态的可靠性，并利用该可靠性信号来过滤不可靠的测试样本、自适应融合多模态特征以及进行可靠性指导的测试时优化。

Result: 在TAG-C基准和其他TVL场景下，该方法在严重模态损坏的情况下，准确率提升高达49.9%，显著优于现有TTA基线。

Conclusion: 显式地对模态可靠性进行建模对于TVL模型在测试时的鲁棒自适应至关重要。

Abstract: Tactile-vision-language (TVL) models are increasingly deployed in real-world robotic and multimodal perception tasks, where test-time distribution shifts are unavoidable. Existing test-time adaptation (TTA) methods provide filtering in unimodal settings but lack explicit treatment of modality-wise reliability under asynchronous cross-modal shifts, leaving them brittle when some modalities become unreliable. We study TTA for TVL models under such shifts and propose a reliability-aware framework that estimates per-modality reliability from prediction uncertainty and perturbation-based responses. This shared reliability signal is used to (i) filter unreliable test samples, (ii) adaptively fuse tactile, visual, and language features, and (iii) regularize test-time optimization with a reliability-guided objective. On the TAG-C benchmark and additional TVL scenarios, our approach consistently outperforms strong TTA baselines, achieving accuracy gains of up to 49.9\% under severe modality corruptions, underscoring the importance of explicit modality-wise reliability modeling for robust test-time adaptation.

</details>


### [142] [Fly0: Decoupling Semantic Grounding from Geometric Planning for Zero-Shot Aerial Navigation](https://arxiv.org/abs/2602.15875)
*Zhenxing Xu,Brikit Lu,Weidong Bao,Zhengqiu Zhu,Junsong Zhang,Hui Yan,Wenhao Lu,Ji Wang*

Main category: cs.RO

TL;DR: Fly0 框架通过解耦语义推理和几何规划，解决了现有视觉-语言导航（VLN）方法在语义理解和控制精度上的权衡问题，实现了更高效、更稳定的导航。


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法在语义理解和控制精度上存在权衡。基于多模态大语言模型（MLLM）的方法虽然推理能力强，但作为低层控制器时存在高延迟、轨迹震荡和泛化能力差等问题，原因在于其几何基础薄弱。

Method: Fly0 采用三阶段流水线：1. MLLM驱动模块将自然语言指令映射到2D像素坐标；2. 几何投影模块利用深度数据将目标定位在3D空间；3. 几何规划器生成无碰撞轨迹，即使在视觉丢失的情况下也能导航。

Result: Fly0 通过消除连续推理的需求，降低了计算开销并提高了系统稳定性。在模拟和真实环境中，Fly0 的成功率提高了20%以上，导航误差（NE）降低了约50%，优于现有最先进方法。

Conclusion: Fly0 框架成功地将语义推理与几何规划解耦，提高了VLN系统的性能和稳定性，尤其是在非结构化环境中，并能在视觉丢失时保持导航能力。

Abstract: Current Visual-Language Navigation (VLN) methodologies face a trade-off between semantic understanding and control precision. While Multimodal Large Language Models (MLLMs) offer superior reasoning, deploying them as low-level controllers leads to high latency, trajectory oscillations, and poor generalization due to weak geometric grounding. To address these limitations, we propose Fly0, a framework that decouples semantic reasoning from geometric planning. The proposed method operates through a three-stage pipeline: (1) an MLLM-driven module for grounding natural language instructions into 2D pixel coordinates; (2) a geometric projection module that utilizes depth data to localize targets in 3D space; and (3) a geometric planner that generates collision-free trajectories. This mechanism enables robust navigation even when visual contact is lost. By eliminating the need for continuous inference, Fly0 reduces computational overhead and improves system stability. Extensive experiments in simulation and real-world environments demonstrate that Fly0 outperforms state-of-the-art baselines, improving the Success Rate by over 20\% and reducing Navigation Error (NE) by approximately 50\% in unstructured environments. Our code is available at https://github.com/xuzhenxing1/Fly0.

</details>


### [143] [FUTURE-VLA: Forecasting Unified Trajectories Under Real-time Execution](https://arxiv.org/abs/2602.15882)
*Jingjing Fan,Yushan Liu,Shoujie Li,Botao Ren,Siyuan Li,Xiao-Ping Zhang,Wenbo Ding,Zhidong Deng*

Main category: cs.RO

TL;DR: FUTURE-VLA是一个统一的架构，通过将长期控制和未来预测重塑为单一序列生成任务，解决了机器人处理长视频流和高维预测的延迟问题。它采用自适应压缩和潜在空间自回归，实现了实时预测和交互式Human-In-the-Loop控制，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的通用视觉-语言模型在处理长视频流和生成高维未来预测时存在严重的延迟问题，这限制了它们在机器人领域的应用。因此，需要一种能够高效处理长时序信息并进行实时预测的机器人控制方法。

Method: FUTURE-VLA采用双边效率范式，通过以下方式解决延迟问题：1. **时间自适应压缩策略**：最大化时空信息密度，允许处理多视角长历史记录，同时保持恒定的推理延迟。2. **潜在空间自回归**：在一次前向传播中，将可操作的动力学与可视化的未来预览对齐。此外，还引入了**预测引导的Human-In-the-Loop机制**，允许操作员基于可解释的未来预览动态验证行为。

Result: FUTURE-VLA在LIBERO、RoboTwin和真实的Piper平台上分别取得了99.2%、75.4%和78.0%的成功率。与单帧基线相比，其时空窗口扩展了16倍，但推理延迟保持不变。

Conclusion: FUTURE-VLA成功地弥合了机器人长视频理解和高维预测的延迟差距，通过创新的效率策略实现了实时预测和增强的人机协作，并在多个基准测试中设定了新的最优性能标准。

Abstract: General vision-language models increasingly support unified spatiotemporal reasoning over long video streams, yet deploying such capabilities on robots remains constrained by the prohibitive latency of processing long-horizon histories and generating high-dimensional future predictions. To bridge this gap, we present FUTURE-VLA, a unified architecture that reformulates long-horizon control and future forecasting as a monolithic sequence-generation task. Adopting a dual-sided efficiency paradigm, FUTURE-VLA leverages a temporally adaptive compression strategy to maximize spatiotemporal information density, enabling the ingestion of extensive multi-view histories while maintaining constant inference latency. Simultaneously, it performs latent-space autoregression to align actionable dynamics with reviewable visual look-aheads in a single forward pass. These real-time predictive capabilities further enable a prediction-guided Human-In-the-Loop mechanism via interactive execution gating, allowing operators to dynamically validate behaviors based on interpretable future previews. Extensive evaluations demonstrate that FUTURE-VLA establishes new state-of-the-art performance, attaining success rates of 99.2% on LIBERO, 75.4% on RoboTwin, and 78.0% on a real-world Piper platform, all with a $16\times$ extended spatiotemporal window while maintaining the inference latency of a single-frame baseline.

</details>


### [144] [ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios](https://arxiv.org/abs/2602.16073)
*Kevin Kai-Chun Chang,Ekin Beyazit,Alberto Sangiovanni-Vincentelli,Tichakorn Wongpiromsarn,Sanjit A. Seshia*

Main category: cs.RO

TL;DR: 本文提出了 ScenicRules，一个用于评估自动驾驶系统在随机环境和多目标优先规则下的基准测试。该基准测试包含正式化的目标、分层规则手册和多样化的场景，旨在暴露自动驾驶系统的失效情况。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶系统评估基准缺乏对复杂交通环境中多目标优先规则以及规则适用情境的形式化建模，而这些在实际驾驶中至关重要。

Method: 1. 对多样化的目标进行形式化，作为量化评估指标。2. 设计了一个分层规则手册框架，以可解释和适应性的方式编码多目标及其优先关系。3. 使用 Scenic 语言构建了一个紧凑且具有代表性的场景集，涵盖了不同的驾驶情境和近乎事故的情况。

Result: 实验结果表明，所形式化的目标和分层规则手册与人类驾驶判断高度一致。该基准测试能够有效地暴露自动驾驶系统在优先目标上的失效情况。

Conclusion: ScenicRules 是一个有效的基准测试，能够评估自动驾驶系统在随机环境下的多目标优先规则遵循能力，并能识别出系统在该方面的不足。该基准测试为自动驾驶系统的研发提供了有力的工具。

Abstract: Developing autonomous driving systems for complex traffic environments requires balancing multiple objectives, such as avoiding collisions, obeying traffic rules, and making efficient progress. In many situations, these objectives cannot be satisfied simultaneously, and explicit priority relations naturally arise. Also, driving rules require context, so it is important to formally model the environment scenarios within which such rules apply. Existing benchmarks for evaluating autonomous vehicles lack such combinations of multi-objective prioritized rules and formal environment models. In this work, we introduce ScenicRules, a benchmark for evaluating autonomous driving systems in stochastic environments under prioritized multi-objective specifications. We first formalize a diverse set of objectives to serve as quantitative evaluation metrics. Next, we design a Hierarchical Rulebook framework that encodes multiple objectives and their priority relations in an interpretable and adaptable manner. We then construct a compact yet representative collection of scenarios spanning diverse driving contexts and near-accident situations, formally modeled in the Scenic language. Experimental results show that our formalized objectives and Hierarchical Rulebooks align well with human driving judgments and that our benchmark effectively exposes agent failures with respect to the prioritized objectives. Our benchmark can be accessed at https://github.com/BerkeleyLearnVerify/ScenicRules/.

</details>


### [145] [The SLAM Confidence Trap](https://arxiv.org/abs/2602.15884)
*Sebastian Sansoni,Santiago Ramón Tosetti Sanz*

Main category: cs.RO

TL;DR: SLAM研究界过度关注基准测试分数，忽略了不确定性估计的原则性问题，导致系统虽然几何精度高但概率不一致且不稳定。文章提倡将一致的、实时的不确定性计算作为主要成功指标。


<details>
  <summary>Details</summary>
Motivation: SLAM社区过于依赖基准测试分数，导致系统在概率上不一致且脆弱，尽管在几何上可能精确。作者认为这种趋势阻碍了SLAM技术的真正进步。

Method: 文章没有描述具体的方法，而是提出了一个研究范式的转变，建议将一致的、实时的不确定性计算作为SLAM系统的主要评估标准。

Result: 文章没有具体的实验结果，其主要“结果”是一种论证，即SLAM社区应该改变评估重点，以获得更稳健、概率一致的系统。

Conclusion: SLAM研究应将不确定性估计的准确性和实时性作为核心指标，而非仅仅追求基准测试分数，以克服当前系统的脆弱性问题。

Abstract: The SLAM community has fallen into a "Confidence Trap" by prioritizing benchmark scores over principled uncertainty estimation. This yields systems that are geometrically accurate but probabilitistically inconsistent and brittle. We advocate for a paradigm shift where the consistent, real-time computation of uncertainty becomes a primary metric of success.

</details>


### [146] [A novel Integrated Motion Tracking Device (IMTD) for Objective Laparoscopic Training Assessment: Development and Validation](https://arxiv.org/abs/2602.15885)
*Siwar Bouzid,Abdelbadia Chaker,Marc Arsicault,Sami Bennour,Med Amine Laribi*

Main category: cs.RO

TL;DR: 该研究提出了一种新型紧凑型四自由度运动追踪设备（IMTD），用于腹腔镜手术的培训和评估，该设备能够精确追踪手术器械的运动，并与标准训练器集成，具有低成本和易于使用的优点。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜手术培训和评估的需求，特别是需要一种能够准确追踪器械运动、易于集成且成本较低的设备。

Method: 设计并开发了一种四自由度运动追踪设备（IMTD），包括其运动学、机械设计、仪器仪表和原型。将IMTD的追踪精度和可靠性与运动捕捉系统（MoCap）进行了比较，并评估了其捕捉角位移和线位移运动的能力。最后，研究了精度、流畅性、速度和整体运动效率等关键性能参数。

Result: IMTD能够有效地追踪手术操作，并与MoCap系统相比具有良好的准确性和可靠性。该设备在追踪角度和线性运动方面表现出色，其低成本和集成设计便于在培训室中使用。

Conclusion: IMTD是一种有效、低成本且易于集成的腹腔镜手术培训和评估工具，能够提供客观、实时的反馈，有助于提高手术技能，缩短学习曲线，并为未来的手势评分算法和标准化培训协议奠定基础。

Abstract: This paper presents a novel, compact four-degree-of-freedom motion-tracking device (IMTD) designed for training and evaluation in laparoscopic surgery. The device's kinematics, mechanical design, instrumentation, and prototypes are developed and presented to meet the specific requirements of laparoscopic training context, including movement around a fixed center of motion and seamless integration into standard box trainers. The system IMTD's tracking accuracy and reliability are compared to a motion capture system (MoCap), assessing its ability to capture both angular and translational motions of surgical instruments. The study then focuses on key performance parameters including precision, fluidity, speed, and overall motion efficiency. The results highlight the system's effectiveness in tracking surgical gestures, providing valuable insights into its potential as a tool for training and performance evaluation in minimally invasive surgery. Additionally, IMTD's low cost and integrated design allow for easy integration and implementation in training rooms, offering a practical and accessible solution for general use. By offering objective, real-time feedback, the system can significantly contribute to improving surgical skills and shortening the learning curve for novice students, while also providing a foundation for future development of gesture scoring algorithms and standardized training protocols.

</details>


### [147] [Reactive Slip Control in Multifingered Grasping: Hybrid Tactile Sensing and Internal-Force Optimization](https://arxiv.org/abs/2602.16127)
*Théo Ayral,Saifeddine Aloui,Mathieu Grossard*

Main category: cs.RO

TL;DR: 该研究提出了一种混合学习和基于模型的抓取力自适应方法，利用多模态触觉传感器（压电传感器用于滑移检测，压阻传感器用于接触定位）来快速检测并纠正物体在机器人手中发生的滑移，以稳定抓取。该方法能在短时间内（理论上35-40ms）完成感知到控制的闭环响应，并在实验中成功演示了在外部扰动下多指抓取的闭环稳定。


<details>
  <summary>Details</summary>
Motivation: 为了在机器人抓取过程中应对物体滑移问题，并提高抓取过程的鲁棒性和响应速度，研究者们希望开发一种能够快速感知和响应滑移的抓取力自适应机制。

Method: 提出了一种混合学习和模型驱动的方法。利用压电传感器（PzE）快速检测滑移，压阻传感器（PzR）阵列进行接触定位，实时构建抓取矩阵。当检测到滑移时，通过二次规划（QP）更新抓取内部力，以在保持物体受力不变的同时满足执行器限制。整个过程结合了分析力控制和学习到的触觉信息。

Result: 该方法实现了35-40毫秒的理论感知到控制的延迟，其中PzR的几何更新和QP求解的延迟非常短（分别为5ms和4ms）。在实验中，滑移 onset 在20毫秒内被检测到。在外部扰动下，成功实现了多指抓取的闭环稳定。测量到的延迟主要由实验数据通路引起，而非计算本身。

Conclusion: 将高效的解析力控制与学习到的触觉线索相结合，可以实现鲁棒且快速的抓取响应。该方法为实现低于50毫秒的闭环稳定抓取提供了一条可行的路径。

Abstract: We present a hybrid learning and model-based approach that adapts internal grasp forces to halt in-hand slip on a multifingered robotic gripper. A multimodal tactile stack combines piezoelectric (PzE) sensing for fast slip cues with piezoresistive (PzR) arrays for contact localization, enabling online construction of the grasp matrix. Upon slip, we update internal forces computed in the null space of the grasp via a quadratic program that preserves the object wrench while enforcing actuation limits. The pipeline yields a theoretical sensing-to-command latency of 35-40 ms, with 5 ms for PzR-based contact and geometry updates and about 4 ms for the quadratic program solve. In controlled trials, slip onset is detected at 20ms. We demonstrate closed-loop stabilization on multifingered grasps under external perturbations. Augmenting efficient analytic force control with learned tactile cues yields both robustness and rapid reactions, as confirmed in our end-to-end evaluation. Measured delays are dominated by the experimental data path rather than actual computation. The analysis outlines a clear route to sub-50 ms closed-loop stabilization.

</details>


### [148] [SIT-LMPC: Safe Information-Theoretic Learning Model Predictive Control for Iterative Tasks](https://arxiv.org/abs/2602.16187)
*Zirui Zang,Ahmad Amine,Nick-Marios T. Kokolakis,Truong X. Nghiem,Ugo Rosolia,Rahul Mangharam*

Main category: cs.RO

TL;DR: 提出了一种名为安全信息论学习模型预测控制（SIT-LMPC）的算法，用于在复杂不确定环境中执行迭代任务，该算法能够平衡鲁棒性、安全性和高性能。


<details>
  <summary>Details</summary>
Motivation: 在复杂、不确定的环境中，机器人执行迭代任务需要一种既能保证鲁棒性、安全性，又能实现高性能的控制策略。

Method: 设计了一个基于信息论模型预测控制的迭代控制框架，用于解决离散时间非线性随机系统的约束下无限视界最优控制问题。采用自适应惩罚方法保证安全性和最优性。利用过去迭代的轨迹，通过归一化流学习价值函数，以实现比高斯先验更丰富的模型不确定性建模。SIT-LMPC设计为高度并行化，可在GPU上高效执行。

Result: 基准模拟和硬件实验表明，SIT-LMPC能够迭代地提升系统性能，同时稳健地满足系统约束。

Conclusion: SIT-LMPC是一种有效的迭代控制算法，可以在不确定环境中实现高性能、安全且鲁棒的机器人任务执行。

Abstract: Robots executing iterative tasks in complex, uncertain environments require control strategies that balance robustness, safety, and high performance. This paper introduces a safe information-theoretic learning model predictive control (SIT-LMPC) algorithm for iterative tasks. Specifically, we design an iterative control framework based on an information-theoretic model predictive control algorithm to address a constrained infinite-horizon optimal control problem for discrete-time nonlinear stochastic systems. An adaptive penalty method is developed to ensure safety while balancing optimality. Trajectories from previous iterations are utilized to learn a value function using normalizing flows, which enables richer uncertainty modeling compared to Gaussian priors. SIT-LMPC is designed for highly parallel execution on graphics processing units, allowing efficient real-time optimization. Benchmark simulations and hardware experiments demonstrate that SIT-LMPC iteratively improves system performance while robustly satisfying system constraints.

</details>


### [149] [Optimization of an Augmented R-CUBE mechanism for Cervical Surgery](https://arxiv.org/abs/2602.15886)
*Terence Essomba,Yu-Wen Wu,Abdelbadia Chaker,Med Amine Laribi*

Main category: cs.RO

TL;DR: 本文提出了一种基于改进的R-CUBE机械臂的新型机械结构，用于脊柱手术中钻孔腔体的操作，能够实现3T2R的运动，并根据真实患者数据进行了优化。


<details>
  <summary>Details</summary>
Motivation: 为了满足脊柱手术中钻取椎弓根螺钉所需的腔体钻孔操作的运动需求，需要一种能够精确控制钻头位置和姿态的机械装置。

Method: 研究提出了一种基于增强版全平移R-CUBE机制的新型机械结构，通过改进连杆实现额外的旋转运动。该机制包含三个阶段：平移、传动和旋转。分别推导了各阶段的运动学和速度模型，并进行了组合。最后，利用真实患者的钻孔轨迹数据对机制进行了优化，以获得最佳的运动学性能。

Result: 所提出的3T2R机械臂能够实现脊柱手术中钻头所需的复杂运动。优化后的机制在根据真实患者数据进行模拟时，展现出了优异的运动学性能。

Conclusion: 所提出的新型机械结构能够有效地实现脊柱手术中钻孔操作所需的3T2R运动，并且通过真实患者数据优化后，其运动学性能得到了提升，为脊柱手术机器人提供了新的解决方案。

Abstract: In some surgical operations targeting the spine, it is required to drill cavities in the vertebrae for the insertion of pedicle screws. A new mechanical architecture is proposed for this application. It is based on an augmented version of the full translational R-CUBE mechanism, with improved linkages to implement additional rotational motion. Using this concept, a mechanism presented with a 3T2R motion that is required for the manipulation of the surgical drill. It is mainly composed three stages: one translational, one transmitting and one rotational. Their respective kinematic and velocity models are separately derived, then combined. Based on the drilling trajectories obtained from a real patient case, the mechanism is optimized for generating the highest kinematic performances.

</details>


### [150] [Learning to Drive in New Cities Without Human Demonstrations](https://arxiv.org/abs/2602.15891)
*Zilin Wang,Saeed Rahmani,Daphne Cornelisse,Bidipta Sarkar,Alexander David Goldie,Jakob Nicolaus Foerster,Shimon Whiteson*

Main category: cs.RO

TL;DR: 本文提出了一种名为NOMAD的方法，利用基于地图的自玩多智能体强化学习，在无需目标城市人类演示数据的情况下，使自动驾驶策略能够适应新的城市环境。


<details>
  <summary>Details</summary>
Motivation: 将自动驾驶汽车部署到新城市面临挑战，因为需要大量人类演示来适应不同于训练区域的道路几何、交通规则和交互模式，这导致部署成本高昂且速度缓慢。

Method: 研究人员提出了NOMAD（NO data Map-based self-play for Autonomous Driving），一种在目标城市地图基础上构建的模拟器中进行策略适应的方法。该方法利用自玩多智能体强化学习，仅使用地图和元信息，无需目标城市的人类演示数据。

Result: NOMAD在目标城市显著提高了任务成功率和轨迹真实性，证明了其有效性和可扩展性。

Conclusion: NOMAD为自动驾驶的城市迁移提供了一种有效且可扩展的替代方案，克服了传统数据密集型方法的局限性。

Abstract: While autonomous vehicles have achieved reliable performance within specific operating regions, their deployment to new cities remains costly and slow. A key bottleneck is the need to collect many human demonstration trajectories when adapting driving policies to new cities that differ from those seen in training in terms of road geometry, traffic rules, and interaction patterns. In this paper, we show that self-play multi-agent reinforcement learning can adapt a driving policy to a substantially different target city using only the map and meta-information, without requiring any human demonstrations from that city. We introduce NO data Map-based self-play for Autonomous Driving (NOMAD), which enables policy adaptation in a simulator constructed based on the target-city map. Using a simple reward function, NOMAD substantially improves both task success rate and trajectory realism in target cities, demonstrating an effective and scalable alternative to data-intensive city-transfer methods. Project Page: https://nomaddrive.github.io/

</details>


### [151] [Nonplanar Model Predictive Control for Autonomous Vehicles with Recursive Sparse Gaussian Process Dynamics](https://arxiv.org/abs/2602.16206)
*Ahmad Amine,Kabir Puri,Viet-Anh Le,Rahul Mangharam*

Main category: cs.RO

TL;DR: 提出了一种用于非平面地形自动驾驶汽车的非平面模型预测控制（MPC）框架，该框架使用残差高斯过程（GP）学习复杂车辆动力学，并利用递归稀疏GP实现实时自适应，通过MPPI控制器和Isaac Sim仿真验证了其在3D表面上的跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车在非平面地形上的运行需要处理复杂的车辆动力学，现有方法难以有效应对。

Method: 开发了一种几何感知建模方法，学习残差高斯过程（GP）来近似复杂车辆动力学。使用递归稀疏GP实现对地形几何变化的实时自适应。结合模型预测路径积分（MPPI）控制器进行控制。

Result: 所提出的框架能够有效地学习非平面地形下的车辆动力学，并保持高跟踪精度。在具有挑战性的3D表面上进行了验证，显示了其有效性。

Conclusion: 所提出的非平面MPC框架能够通过几何感知建模和实时自适应，有效地实现自动驾驶汽车在非平面地形上的精确路径跟踪。

Abstract: This paper proposes a nonplanar model predictive control (MPC) framework for autonomous vehicles operating on nonplanar terrain. To approximate complex vehicle dynamics in such environments, we develop a geometry-aware modeling approach that learns a residual Gaussian Process (GP). By utilizing a recursive sparse GP, the framework enables real-time adaptation to varying terrain geometry. The effectiveness of the learned model is demonstrated in a reference-tracking task using a Model Predictive Path Integral (MPPI) controller. Validation within a custom Isaac Sim environment confirms the framework's capability to maintain high tracking accuracy on challenging 3D surfaces.

</details>


### [152] [Statistical-Geometric Degeneracy in UAV Search: A Physics-Aware Asymmetric Filtering Approach](https://arxiv.org/abs/2602.15893)
*Zhiyuan Ren,Yudong Fang,Tao Zhang,Wenchi Cheng,Ben Lan*

Main category: cs.RO

TL;DR: 提出了一种名为AsymmetricHuberEKF的定位方法，该方法通过引入非负NLOS偏差的物理先验来解决灾后UAV定位中的统计几何退化问题，并辅以主动感知策略，提高了收敛速度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒定位估计器在灾后UAV定位中面临非视距（NLOS）传播导致的信号反射引起的非对称偏差问题，这会与有限的观测几何相结合，导致统计几何退化（SGD）问题。而数据驱动方法受限于数据稀疏和现实差距。

Method: 提出了一种基于物理原理的解决方案，即AsymmetricHuberEKF，它通过一个导出的非对称损失函数来显式地包含NLOS偏差的非负物理先验。同时，设计了一种联合优化的主动感知策略来解决SGD问题。

Result: 在2D天顶扫描场景下验证，所提出的方法与对称基线相比，显著加速了收敛速度，提高了定位的鲁棒性。

Conclusion: AsymmetricHuberEKF是一种物理上合理且具有鲁棒性的解决方案，通过结合非对称损失函数和主动感知策略，能够有效解决灾后UAV定位中的SGD问题，尤其适用于数据稀疏和几何受限的场景。

Abstract: Post-disaster survivor localization using Unmanned Aerial Vehicles (UAVs) faces a fundamental physical challenge: the prevalence of Non-Line-of-Sight (NLOS) propagation in collapsed structures. Unlike standard Gaussian noise, signal reflection from debris introduces strictly non-negative ranging biases. Existing robust estimators, typically designed with symmetric loss functions (e.g., Huber or Tukey), implicitly rely on the assumption of error symmetry. Consequently, they experience a theoretical mismatch in this regime, leading to a phenomenon we formally identify as Statistical-Geometric Degeneracy (SGD)-a state where the estimator stagnates due to the coupling of persistent asymmetric bias and limited observation geometry. While emerging data-driven approaches offer alternatives, they often struggle with the scarcity of training data and the sim-to-real gap inherent in unstructured disaster zones. In this work, we propose a physically-grounded solution, the AsymmetricHuberEKF, which explicitly incorporates the non-negative physical prior of NLOS biases via a derived asymmetric loss function. Theoretically, we show that standard symmetric filters correspond to a degenerate case of our framework where the physical constraint is relaxed. Furthermore, we demonstrate that resolving SGD requires not just a robust filter, but specific bilateral information, which we achieve through a co-designed active sensing strategy. Validated in a 2D nadir-view scanning scenario, our approach significantly accelerates convergence compared to symmetric baselines, offering a resilient building block for search operations where data is scarce and geometry is constrained.

</details>


### [153] [Adaptive Illumination Control for Robot Perception](https://arxiv.org/abs/2602.15900)
*Yash Turkar,Shekoufeh Sadeghi,Karthik Dantu*

Main category: cs.RO

TL;DR: 本文提出了一种名为 Lightning 的闭环光照控制框架，用于视觉 SLAM，通过结合重照明、离线优化和模仿学习，来优化机器人感知在低光照或高动态范围下的表现，从而提高 SLAM 的鲁棒性并减少不必要的功耗。


<details>
  <summary>Details</summary>
Motivation: 机器人感知在低光照或高动态范围条件下通常需要下游处理（如特征提取、图像增强或闭环曝光控制）来改进，但这些方法受限于初始捕获的图像质量。一种替代方法是使用可编程的板载光源，但其对图像形成的影响难以预测，因为光照与深度、表面反射率和场景几何形状存在非线性交互，可能导致细节暴露也可能诱发失败模式。

Method: Lightning 框架分为三个阶段：1. 训练一个名为 Co-Located Illumination Decomposition (CLID) 的重照明模型，将机器人观测分解为环境光和光源贡献场，从而在不同光照强度下合成场景，生成密集多强度训练数据。2. 提出一个离线的最优光照调度（OIS）问题，通过权衡 SLAM 相关的图像效用、功耗和时间平滑性来选择一系列光照级别。3. 通过行为克隆将最优调度蒸馏成一个实时控制器，即光照控制策略（ILC），使其能够泛化并在线控制移动机器人离散的光照强度级别。

Result: Lightning 框架在评估中显著提高了 SLAM 轨迹的鲁棒性，同时减少了不必要的光照功耗。它通过 CLID 模型生成合成数据，解决了重复运行轨迹的难题，并通过 ILC 控制器实现了实时、泛化的光照管理。

Conclusion: Lightning 提供了一种新颖的闭环光照控制方法，能够显著改善视觉 SLAM 在挑战性光照条件下的性能，同时优化能源效率。该框架结合了物理一致的重照明、基于优化的调度以及高效的模仿学习，为机器人感知在复杂环境下的应用提供了有力的解决方案。

Abstract: Robot perception under low light or high dynamic range is usually improved downstream - via more robust feature extraction, image enhancement, or closed-loop exposure control. However, all of these approaches are limited by the image captured these conditions. An alternate approach is to utilize a programmable onboard light that adds to ambient illumination and improves captured images. However, it is not straightforward to predict its impact on image formation. Illumination interacts nonlinearly with depth, surface reflectance, and scene geometry. It can both reveal structure and induce failure modes such as specular highlights and saturation. We introduce Lightning, a closed-loop illumination-control framework for visual SLAM that combines relighting, offline optimization, and imitation learning. This is performed in three stages. First, we train a Co-Located Illumination Decomposition (CLID) relighting model that decomposes a robot observation into an ambient component and a light-contribution field. CLID enables physically consistent synthesis of the same scene under alternative light intensities and thereby creates dense multi-intensity training data without requiring us to repeatedly re-run trajectories. Second, using these synthesized candidates, we formulate an offline Optimal Intensity Schedule (OIS) problem that selects illumination levels over a sequence trading off SLAM-relevant image utility against power consumption and temporal smoothness. Third, we distill this ideal solution into a real-time controller through behavior cloning, producing an Illumination Control Policy (ILC) that generalizes beyond the initial training distribution and runs online on a mobile robot to command discrete light-intensity levels. Across our evaluation, Lightning substantially improves SLAM trajectory robustness while reducing unnecessary illumination power.

</details>


### [154] [Coverage Path Planning for Autonomous Sailboats in Inhomogeneous and Time-Varying Oceans: A Spatiotemporal Optimization Approach](https://arxiv.org/abs/2602.15901)
*Yang An,Zhikang Ge,Taiyu Zhang,Jean-Baptiste R. G. Souppez,Gaofei Xu,Zhengru Ren*

Main category: cs.RO

TL;DR: 本文提出了一种针对自主帆船的时空覆盖路径规划框架，考虑了海洋环境的不均匀性和时变性，以及帆船自身性能的各向异性，以克服传统方法在复杂海洋环境下的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有自主帆船的覆盖方法（如蛇形扫描）在不均匀且随时间变化的海洋风浪流环境下效率低下，而利用帆船进行长期海洋观测的需求日益增长。因此，需要一种能够应对这些挑战的路径规划方法。

Method: 该框架结合了基于拓扑学的空间域形态约束（促进紧凑连续覆盖）和面向未来的时间域预测规划（预测环境变化并进行前瞻性决策）。

Result: 在模拟的随机不均匀和时变海洋环境中（包括部分方向可达性场景），所提出的方法能够生成比传统策略更有效且可行的覆盖路径。

Conclusion: 该研究首次为在不均匀和时变海洋环境中运行的自主帆船提供了专门的覆盖路径规划解决方案，为未来多帆船协同覆盖奠定了基础。

Abstract: Autonomous sailboats are well suited for long-duration ocean observation due to their wind-driven endurance. However, their performance is highly anisotropic and strongly influenced by inhomogeneous and time-varying wind and current fields, limiting the effectiveness of existing coverage methods such as boustrophedon sweeping. Planning under these environmental and maneuvering constraints remains underexplored. This paper presents a spatiotemporal coverage path planning framework tailored to autonomous sailboats, combining (1) topology-based morphological constraints in the spatial domain to promote compact and continuous coverage, and (2) forecast-aware look-ahead planning in the temporal domain to anticipate environmental evolution and enable foresighted decision-making. Simulations conducted under stochastic inhomogeneous and time-varying ocean environments, including scenarios with partial directional accessibility, demonstrate that the proposed method generates efficient and feasible coverage paths where traditional strategies often fail. To the best of our knowledge, this study provides the first dedicated solution to the coverage path planning problem for autonomous sailboats operating in inhomogeneous and time-varying ocean environments, establishing a foundation for future cooperative multi-sailboat coverage.

</details>


### [155] [World Action Models are Zero-shot Policies](https://arxiv.org/abs/2602.15922)
*Seonghyeon Ye,Yunhao Ge,Kaiyuan Zheng,Shenyuan Gao,Sihyun Yu,George Kurian,Suneel Indupuru,You Liang Tan,Chuning Zhu,Jiannan Xiang,Ayaan Malik,Kyungmin Lee,William Liang,Nadun Ranawaka,Jiasheng Gu,Yinzhen Xu,Guanzhi Wang,Fengyuan Hu,Avnish Narayan,Johan Bjorck,Jing Wang,Gwanghyun Kim,Dantong Niu,Ruijie Zheng,Yuqi Xie,Jimmy Wu,Qi Wang,Ryan Julian,Danfei Xu,Yilun Du,Yevgen Chebotar,Scott Reed,Jan Kautz,Yuke Zhu,Linxi "Jim" Fan,Joel Jang*

Main category: cs.RO

TL;DR: DreamZero是一个基于预训练视频扩散模型的无监督世界动作模型（WAM），通过预测未来世界状态和动作来学习物理动力学，显著提高了在机器人上的泛化能力，并实现了实时闭环控制和跨载体迁移。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在语义泛化方面表现良好，但在处理新环境中的未知物理运动时存在局限性。研究者希望开发一种能够更好地泛化到新任务和环境中的模型。

Method: 作者提出了DreamZero，一个世界动作模型（WAM），它基于预训练的视频扩散模型。WAM通过预测未来的世界状态和动作来学习物理动力学，并利用视频作为世界演变的密集表示。模型联合学习视频和动作，从异构机器人数据中学习多样化技能，无需重复演示。

Result: DreamZero在真实机器人实验中，新任务和环境的泛化能力比最先进的VLA模型提高了2倍以上。模型支持14B参数的自回归视频扩散模型进行7Hz的实时闭环控制。通过视频演示进行跨载体迁移，在新任务上的性能相对提高了42%以上，仅需10-20分钟数据。模型还能通过30分钟的交互数据进行少样本载体适应，并保持零样本泛化能力。

Conclusion: DreamZero通过其世界动作模型（WAM）的方法，克服了现有VLA模型的泛化限制，在机器人控制和迁移学习方面取得了显著进展，并实现了实时运行能力。

Abstract: State-of-the-art Vision-Language-Action (VLA) models excel at semantic generalization but struggle to generalize to unseen physical motions in novel environments. We introduce DreamZero, a World Action Model (WAM) built upon a pretrained video diffusion backbone. Unlike VLAs, WAMs learn physical dynamics by predicting future world states and actions, using video as a dense representation of how the world evolves. By jointly modeling video and action, DreamZero learns diverse skills effectively from heterogeneous robot data without relying on repetitive demonstrations. This results in over 2x improvement in generalization to new tasks and environments compared to state-of-the-art VLAs in real robot experiments. Crucially, through model and system optimizations, we enable a 14B autoregressive video diffusion model to perform real-time closed-loop control at 7Hz. Finally, we demonstrate two forms of cross-embodiment transfer: video-only demonstrations from other robots or humans yield a relative improvement of over 42% on unseen task performance with just 10-20 minutes of data. More surprisingly, DreamZero enables few-shot embodiment adaptation, transferring to a new embodiment with only 30 minutes of play data while retaining zero-shot generalization.

</details>


### [156] [Hybrid Model Predictive Control with Physics-Informed Neural Network for Satellite Attitude Control](https://arxiv.org/abs/2602.15954)
*Carlo Cena,Mauro Martini,Marcello Chiaberge*

Main category: cs.RO

TL;DR: 研究表明，在航天器姿态动力学建模中，结合物理知识的神经网络（PINNs）相比纯数据驱动方法，能显著提高预测的可靠性、控制性能和鲁棒性，尤其在MPC框架下。


<details>
  <summary>Details</summary>
Motivation: 传统的基于物理模型的姿态动力学建模难以获取、耗时或计算量大，而纯数据驱动模型存在稳定性和外推能力不足的问题。因此，需要一种结合数据驱动优势和物理规律的建模方法。

Method: 使用高精度数值模拟生成数据集，比较了两种学习方法：纯数据驱动方法和引入物理约束的PINNs方法。并将这两种模型应用于MPC架构进行对比。

Result: PINNs方法将平均相对误差降低了68.17%。在MPC框架下，PINNs模型提供了更好的闭环跟踪性能和鲁棒性。混合控制方法结合了非线性学习模型和线性模型，实现了稳定的稳态收敛和更快的响应，将沉降时间缩短了61.52%-76.42%。

Conclusion: 将物理约束融入神经网络训练，可以显著提升航天器姿态动力学模型的预测可靠性，并在MPC控制中实现更优的性能和鲁棒性。混合控制策略能够进一步提高系统的收敛速度和响应性能。

Abstract: Reliable spacecraft attitude control depends on accurate prediction of attitude dynamics, particularly when model-based strategies such as Model Predictive Control (MPC) are employed, where performance is limited by the quality of the internal system model. For spacecraft with complex dynamics, obtaining accurate physics-based models can be difficult, time-consuming, or computationally heavy. Learning-based system identification presents a compelling alternative; however, models trained exclusively on data frequently exhibit fragile stability properties and limited extrapolation capability. This work explores Physics-Informed Neural Networks (PINNs) for modeling spacecraft attitude dynamics and contrasts it with a conventional data-driven approach. A comprehensive dataset is generated using high-fidelity numerical simulations, and two learning methodologies are investigated: a purely data-driven pipeline and a physics-regularized approach that incorporates prior knowledge into the optimization process. The results indicate that embedding physical constraints during training leads to substantial improvements in predictive reliability, achieving a 68.17% decrease in mean relative error relative. When deployed within an MPC architecture, the physics-informed models yield superior closed-loop tracking performance and improved robustness to uncertainty. Furthermore, a hybrid control formulation that merges the learned nonlinear dynamics with a nominal linear model enables consistent steady-state convergence and significantly faster response, reducing settling times by 61.52%-76.42% under measurement noise and reaction wheel friction.

</details>


### [157] [The human intention. A taxonomy attempt and its applications to robotics](https://arxiv.org/abs/2602.15963)
*J. E. Domínguez-Vidal,Alberto Sanfeliu*

Main category: cs.RO

TL;DR: 本论文旨在弥合机器人学中人类意图定义缺失的鸿沟，通过整合心理学见解，提出一个更全面、更易理解的意图框架，并展示该框架在机器人应用中的相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人学研究在理解人类意图方面存在定义模糊的问题，通常将意图等同于特定的任务目标。研究旨在解决这一不足，为机器人学研究提供一个更全面的意图定义。

Method: 文章借鉴心理学、沟通学等领域的理论，对不同类型的人类意图进行分类。随后，将这些分类应用于机器人学研究，并通过分析协作搜索和物体运输等具体用例来论证其重要性。

Result: 文章提出了一种基于多方面考虑的人类意图分类框架。该框架能够帮助研究人员从技术导向转向以人为本的研究视角，并能够指导各种机器人研究与这些意图类别进行对齐。

Conclusion: 考虑人类意图的多样化是机器人研究（尤其是协作任务）的关键。本研究提出的框架有助于机器人学界更深入地理解和应用人类意图的概念。

Abstract: Despite a surge in robotics research dedicated to inferring and understanding human intent, a universally accepted definition remains elusive since existing works often equate human intention with specific task-related goals. This article seeks to address this gap by examining the multifaceted nature of intention. Drawing on insights from psychology, it attempts to consolidate a definition of intention into a comprehensible framework for a broader audience. The article classifies different types of intention based on psychological and communication studies, offering guidance to researchers shifting from pure technical enhancements to a more human-centric perspective in robotics. It then demonstrates how various robotics studies can be aligned with these intention categories. Finally, through in-depth analyses of collaborative search and object transport use cases, the article underscores the significance of considering the diverse facets of human intention.

</details>


### [158] [ODYN: An All-Shifted Non-Interior-Point Method for Quadratic Programming in Robotics and AI](https://arxiv.org/abs/2602.16005)
*Jose Rojas,Aristotelis Papatheodorou,Sergi Martinez,Ioannis Havoutis,Carlos Mastalli*

Main category: cs.RO

TL;DR: 本文提出了一种名为ODYN的新型求解器，用于解决二次规划（QP）问题，尤其擅长处理病态和退化问题，并展现出强大的热启动能力，适用于通用优化、机器人和AI领域。


<details>
  <summary>Details</summary>
Motivation: 为了有效地处理具有挑战性的稠密和稀疏二次规划（QP）问题，特别是那些病态和退化的问题，并且需要增强热启动性能以满足机器人和AI等顺序和实时应用的需求。

Method: ODYN结合了全偏移非线性互补问题（NCP）函数与近邻乘子法，采用全偏移原对偶非内点方法。该方法无需满足约束的线性无关性。

Result: ODYN在Maros-Mészáros测试集上表现出最先进的收敛性能，尤其在小到大规模问题上，其热启动能力表现突出。在OdynSQP（SQP预测控制）、ODYNLayer（深度学习隐式可微优化层）和ODYNSim（接触动力学仿真）中的应用也证明了其优势。

Conclusion: ODYN是一种鲁棒且高效的QP求解器，其创新的方法使其能够处理病态和退化问题，并具有卓越的热启动性能，使其成为机器人、AI和通用优化领域的理想选择。

Abstract: We introduce ODYN, a novel all-shifted primal-dual non-interior-point quadratic programming (QP) solver designed to efficiently handle challenging dense and sparse QPs. ODYN combines all-shifted nonlinear complementarity problem (NCP) functions with proximal method of multipliers to robustly address ill-conditioned and degenerate problems, without requiring linear independence of the constraints. It exhibits strong warm-start performance and is well suited to both general-purpose optimization, and robotics and AI applications, including model-based control, estimation, and kernel-based learning methods. We provide an open-source implementation and benchmark ODYN on the Maros-Mészáros test set, demonstrating state-of-the-art convergence performance in small-to-high-scale problems. The results highlight ODYN's superior warm-starting capabilities, which are critical in sequential and real-time settings common in robotics and AI. These advantages are further demonstrated by deploying ODYN as the backend of an SQP-based predictive control framework (OdynSQP), as the implicitly differentiable optimization layer for deep learning (ODYNLayer), and the optimizer of a contact-dynamics simulation (ODYNSim).

</details>


### [159] [The Impact of Class Uncertainty Propagation in Perception-Based Motion Planning](https://arxiv.org/abs/2602.16035)
*Jibran Iqbal Shah,Andrei Ivanovic,Kelly Zhu,Masha Itkina,Rowan McAllister,Igor Gilitschenski,Florian Shkurti*

Main category: cs.RO

TL;DR: 研究了感知不确定性传播和校准对自动驾驶汽车（AV）基于感知的运动规划的影响，并提出了一种改进的预测-规划方法。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性感知规划器可能对预测不确定性校准不准确敏感，而这种敏感性的程度尚未得到量化。

Method: 通过比较两种不同程度不确定性传播的新型预测-规划流水线，并在nuPlan基准上进行闭环评估，分析了感知不确定性传播和校准的影响。

Result: 结合上游不确定性传播的方法在复杂的闭环场景中表现出更优越的泛化能力。

Conclusion: 上游不确定性传播对于提高自动驾驶汽车在复杂城市环境中的运动规划性能至关重要，尤其是在感知不确定性可能存在偏差的情况下。

Abstract: Autonomous vehicles (AVs) are being increasingly deployed in urban environments. In order to operate safely and reliably, AVs need to account for the inherent uncertainty associated with perceiving the world through sensor data and incorporate that into their decision-making process. Uncertainty-aware planners have recently been developed to account for upstream perception and prediction uncertainty. However, such planners may be sensitive to prediction uncertainty miscalibration, the magnitude of which has not yet been characterized. Towards this end, we perform a detailed analysis on the impact that perceptual uncertainty propagation and calibration has on perception-based motion planning. We do so by comparing two novel prediction-planning pipelines with varying levels of uncertainty propagation on the recently-released nuPlan planning benchmark. We study the impact of upstream uncertainty calibration using closed-loop evaluation on the nuPlan challenge scenarios. We find that the method incorporating upstream uncertainty propagation demonstrates superior generalization to complex closed-loop scenarios.

</details>


### [160] [Image Measurement Method for Automatic Insertion of Forks into Inclined Pallet](https://arxiv.org/abs/2602.16178)
*Nobuyuki Kita,Takuro Kato*

Main category: cs.RO

TL;DR: 该研究提出了一种基于宽视角相机的图像测量方法，用于自动测量AGF（自动导引叉车）所需货叉插入的货叉俯仰角、相对高度以及货盘是否加载，以实现叉车的自动化操作。


<details>
  <summary>Details</summary>
Motivation: 为了实现AGF（自动导引叉车）能够自动地将货叉插入货盘的孔洞，需要精确控制货叉的高度、到达位置和倾斜角度以匹配货盘孔洞的位置和方向。

Method: 提出了一种图像测量方法，利用固定在叉车靠背上的宽视角相机拍摄的图像，测量相机坐标系中货盘的俯仰倾斜角度。同时，提出了一种图像测量方法，用于获取相机坐标系与货叉坐标系之间的校准信息，以便将测量结果应用于货叉控制。

Result: 实验证明，在不同货盘俯仰倾斜角度、相对高度以及是否加载货盘的情况下，通过图像测量得到的误差在安全插入货叉的允许范围内。

Conclusion: 所提出的基于宽视角相机的图像测量方法能够有效地测量货盘的俯仰倾斜角度，并获取必要的校准信息，从而实现AGF货叉插入操作的自动化，并确保操作安全性。

Abstract: In order to insert a fork into a hole of a pallet by a forklift located in front of a pallet, it is necessary to control the height position, reach position, and tilt angle of the fork to match the position and orientation of the hole of the pallet. In order to make AGF (Autonomous Guided Forklift) do this automatically, we propose an image measurement method to measure the pitch inclination of the pallet in the camera coordinate system from an image obtained by using a wide-angle camera. In addition, we propose an image measurement method to easily acquire the calibration information between the camera coordinate system and the fork coordinate system necessary to apply the measurements in the camera coordinate system to the fork control. In the experiment space, a wide-angle camera was fixed at the backrest of a reach type forklift. The wide-angle images taken by placing a pallet in front of the camera were processed. As a result of evaluating the error by comparing the image measurement value with the hand measurement value when changing the pitch inclination angle of the pallet, the relative height of the pallet and the fork, and whether the pallet is loaded or not, it was confirmed that the error was within the allowable range for safely inserting the fork.

</details>


### [161] [World Model Failure Classification and Anomaly Detection for Autonomous Inspection](https://arxiv.org/abs/2602.16182)
*Michelle Ho,Muhammad Fadhil Ginting,Isaac R. Ward,Andrzej Reinke,Mykel J. Kochenderfer,Ali-akbar Agha-Mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: 提出了一种结合监督故障分类和异常检测的混合框架，用于对工业现场的自动检查任务进行分类（成功、已知故障或异常），能够实时部署，并在准确性和早期检测方面优于人类观察者。


<details>
  <summary>Details</summary>
Motivation: 人类进行工业现场检查存在成本高、风险大等问题。然而，由于遮挡、视角受限或意外环境条件，机器人进行准确读数具有挑战性。

Method: 该框架结合了监督故障分类和异常检测。它使用世界模型作为骨干网络，并采用压缩视频输入。该框架不依赖于特定策略或分布假设，通过共形预测（CP）确定的两个决策函数在人类观察者之前进行分类。

Result: 在办公室和工业现场收集的仪表检查数据上进行了评估，并在波士顿动力Spot机器人上进行了实时部署。实验表明，区分成功、已知故障和异常（OOD）情况的准确率超过90%，并且分类时间早于人类观察者。

Conclusion: 该框架能够对自动检查任务进行鲁棒的、预见性的故障检测，或者作为模型训练的反馈信号，以评估和改进训练数据的质量。

Abstract: Autonomous inspection robots for monitoring industrial sites can reduce costs and risks associated with human-led inspection. However, accurate readings can be challenging due to occlusions, limited viewpoints, or unexpected environmental conditions. We propose a hybrid framework that combines supervised failure classification with anomaly detection, enabling classification of inspection tasks as a success, known failure, or anomaly (i.e., out-of-distribution) case. Our approach uses a world model backbone with compressed video inputs. This policy-agnostic, distribution-free framework determines classifications based on two decision functions set by conformal prediction (CP) thresholds before a human observer does. We evaluate the framework on gauge inspection feeds collected from office and industrial sites and demonstrate real-time deployment on a Boston Dynamics Spot. Experiments show over 90% accuracy in distinguishing between successes, failures, and OOD cases, with classifications occurring earlier than a human observer. These results highlight the potential for robust, anticipatory failure detection in autonomous inspection tasks or as a feedback signal for model training to assess and improve the quality of training data. Project website: https://autoinspection-classification.github.io

</details>


### [162] [Markerless Robot Detection and 6D Pose Estimation for Multi-Agent SLAM](https://arxiv.org/abs/2602.16308)
*Markus Rueggeberg,Maximilian Ulmer,Maximilian Durner,Wout Boerdijk,Marcus Gerhard Mueller,Rudolph Triebel,Riccardo Giubilato*

Main category: cs.RO

TL;DR: 提出了一种基于深度学习的无标记物6D姿态估计方法，用于解决多机器人SLAM中的数据关联和相对定位精度问题，并在行星模拟环境中进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 现有的多机器人SLAM方法在融合不同机器人收集的定位历史和地图时，常因数据关联困难而受到限制，尤其是在感知混淆或视角差异大的情况下。而基于相互观测的方法虽能有效连接SLAM图，却依赖于校准的标志物，应用场景受限且易受光照条件影响。

Method: 利用深度学习驱动的6D姿态估计技术，将无标记物姿态估计集成到去中心化的多机器人SLAM系统中，以提升机器人之间的相对定位精度。

Result: 实验证明，该方法能够有效提升多机器人团队的相对定位精度。

Conclusion: 基于深度学习的无标记物6D姿态估计是解决多机器人SLAM中数据关联和相对定位精度问题的有效方法，且在行星模拟环境中得到了验证。

Abstract: The capability of multi-robot SLAM approaches to merge localization history and maps from different observers is often challenged by the difficulty in establishing data association. Loop closure detection between perceptual inputs of different robotic agents is easily compromised in the context of perceptual aliasing, or when perspectives differ significantly. For this reason, direct mutual observation among robots is a powerful way to connect partial SLAM graphs, but often relies on the presence of calibrated arrays of fiducial markers (e.g., AprilTag arrays), which severely limits the range of observations and frequently fails under sharp lighting conditions, e.g., reflections or overexposure. In this work, we propose a novel solution to this problem leveraging recent advances in Deep-Learning-based 6D pose estimation. We feature markerless pose estimation as part of a decentralized multi-robot SLAM system and demonstrate the benefit to the relative localization accuracy among the robotic team. The solution is validated experimentally on data recorded in a test field campaign on a planetary analogous environment.

</details>


### [163] [Machine Learning Driven Prediction of the Behavior of Biohybrid Actuators](https://arxiv.org/abs/2602.16330)
*Michail-Antisthenis Tsompanas,Marco Perez Hernandez,Faisal Abdul-Fattah,Karim Elhakim,Mostafa Ibrahim,Judith Fuentes,Florencia Lezcano,Riccardo Collu,Massimo Barbaro,Stefano Lai,Samuel Sanchez,Andrew Adamatzky*

Main category: cs.RO

TL;DR: 本研究利用机器学习（随机森林、神经网络和 LSTM）来预测和模拟基于骨骼肌的生物混合驱动器（BHMs）的行为，克服了生物变异性和非线性带来的可控性挑战，实现了高预测精度。


<details>
  <summary>Details</summary>
Motivation: 骨骼肌基的生物混合驱动器在软体机器人领域前景广阔，但其内在的生物变异性和非线性给可控性和可预测性带来了挑战。

Method: 研究者开发了两种机器学习模型：1. 静态预测模型（随机森林和神经网络回归器），用于从肌肉样本、电刺激参数和基线受力等输入变量预测最大受力；2. 动态建模框架（LSTM网络），用作数字孪生，模拟电刺激响应下的受力时间序列。

Result: 静态模型取得了 R2 为 0.9425 的最佳性能，动态模型则达到了 R2 为 0.9956 的高精度。这两种方法均展现了高预测准确性。

Conclusion: 静态模型有助于优化肌肉驱动器的性能以满足特定应用和目标受力需求，而动态模型为未来生物混合机器人系统开发鲁棒的自适应控制策略奠定了基础。

Abstract: Skeletal muscle-based biohybrid actuators have proved to be a promising component in soft robotics, offering efficient movement. However, their intrinsic biological variability and nonlinearity pose significant challenges for controllability and predictability. To address these issues, this study investigates the application of supervised learning, a form of machine learning, to model and predict the behavior of biohybrid machines (BHMs), focusing on a muscle ring anchored on flexible polymer pillars. First, static prediction models (i.e., random forest and neural network regressors) are trained to estimate the maximum exerted force achieved from input variables such as muscle sample, electrical stimulation parameters, and baseline exerted force. Second, a dynamic modeling framework, based on Long Short-Term Memory networks, is developed to serve as a digital twin, replicating the time series of exerted forces observed in response to electrical stimulation. Both modeling approaches demonstrate high predictive accuracy. The best performance of the static models is characterized by R2 of 0.9425, whereas the dynamic model achieves R2 of 0.9956. The static models can enable optimization of muscle actuator performance for targeted applications and required force outcomes, while the dynamic model provides a foundation for developing robustly adaptive control strategies in future biohybrid robotic systems.

</details>


### [164] [Dual-Quadruped Collaborative Transportation in Narrow Environments via Safe Reinforcement Learning](https://arxiv.org/abs/2602.16353)
*Zhezhi Lei,Zhihai Bi,Wenxin Wang,Jun Ma*

Main category: cs.RO

TL;DR: 本研究提出了一种基于安全强化学习的双足机器人协同运输方法，通过约束马尔可夫博弈和成本优势分解来保证碰撞避免，并采用约束分配策略提升整体任务性能。


<details>
  <summary>Details</summary>
Motivation: 在狭窄环境中实现多机器人协同运输面临挑战，需要确保机器人间的安全高效协作。

Method: 将任务建模为受限马尔可夫博弈，利用成本优势分解方法在强化学习框架内强制执行碰撞避免约束，并提出约束分配策略以最大化整体任务奖励。

Result: 提出的方法在双足机器人协同运输任务中，相比现有方法，在模拟和真实实验中均展现出更优越的性能和更高的成功率。

Conclusion: 该方法能够有效地解决狭窄环境中双足机器人协同运输的安全性和性能问题，实现了自主任务分配和高效协作。

Abstract: Collaborative transportation, where multiple robots collaboratively transport a payload, has garnered significant attention in recent years. While ensuring safe and high-performance inter-robot collaboration is critical for effective task execution, it is difficult to pursue in narrow environments where the feasible region is extremely limited. To address this challenge, we propose a novel approach for dual-quadruped collaborative transportation via safe reinforcement learning (RL). Specifically, we model the task as a fully cooperative constrained Markov game, where collision avoidance is formulated as constraints. We introduce a cost-advantage decomposition method that enforces the sum of team constraints to remain below an upper bound, thereby guaranteeing task safety within an RL framework. Furthermore, we propose a constraint allocation method that assigns shared constraints to individual robots to maximize the overall task reward, encouraging autonomous task-assignment among robots, thereby improving collaborative task performance. Simulation and real-time experimental results demonstrate that the proposed approach achieves superior performance and a higher success rate in dual-quadruped collaborative transportation compared to existing methods.

</details>


### [165] [Articulated 3D Scene Graphs for Open-World Mobile Manipulation](https://arxiv.org/abs/2602.16356)
*Martin Büchner,Adrian Röfer,Tim Engelbracht,Tim Welschehold,Zuria Bauer,Hermann Blum,Marc Pollefeys,Abhinav Valada*

Main category: cs.RO

TL;DR: 本文提出MoMa-SG框架，用于构建含可交互物体的三维语义-运动场景图，以解决机器人预测物体运动的难题，实现长时序移动操作。


<details>
  <summary>Details</summary>
Motivation: 当前机器人难以预测物体运动，阻碍了在真实世界中进行长时序的移动操作，需要弥合语义、几何和运动学之间的差距。

Method: 该框架利用RGB-D序列，通过时间分割和遮挡鲁棒的点追踪来推断物体运动。然后，将点轨迹提升至三维，并使用统一的扭转估计方法估计关节参数。接着，关联物体与运动模型，并通过父子关系检测包含物。同时，引入了Arti4D-Semantic数据集。

Result: 在两个数据集上的广泛评估显示了MoMa-SG的有效性。真实世界实验证明，该语义-运动场景图能够实现对家庭环境中可动关节物体的鲁棒操作。

Conclusion: MoMa-SG框架能够构建语义-运动场景图，有效解决机器人操作可动关节物体时的运动预测问题，为长时序移动操作提供了关键技术支持。

Abstract: Semantics has enabled 3D scene understanding and affordance-driven object interaction. However, robots operating in real-world environments face a critical limitation: they cannot anticipate how objects move. Long-horizon mobile manipulation requires closing the gap between semantics, geometry, and kinematics. In this work, we present MoMa-SG, a novel framework for building semantic-kinematic 3D scene graphs of articulated scenes containing a myriad of interactable objects. Given RGB-D sequences containing multiple object articulations, we temporally segment object interactions and infer object motion using occlusion-robust point tracking. We then lift point trajectories into 3D and estimate articulation models using a novel unified twist estimation formulation that robustly estimates revolute and prismatic joint parameters in a single optimization pass. Next, we associate objects with estimated articulations and detect contained objects by reasoning over parent-child relations at identified opening states. We also introduce the novel Arti4D-Semantic dataset, which uniquely combines hierarchical object semantics including parent-child relation labels with object axis annotations across 62 in-the-wild RGB-D sequences containing 600 object interactions and three distinct observation paradigms. We extensively evaluate the performance of MoMa-SG on two datasets and ablate key design choices of our approach. In addition, real-world experiments on both a quadruped and a mobile manipulator demonstrate that our semantic-kinematic scene graphs enable robust manipulation of articulated objects in everyday home environments. We provide code and data at: https://momasg.cs.uni-freiburg.de.

</details>


### [166] [System Identification under Constraints and Disturbance: A Bayesian Estimation Approach](https://arxiv.org/abs/2602.16358)
*Sergi Martinez,Steve Tonneau,Carlos Mastalli*

Main category: cs.RO

TL;DR: 提出了一种贝叶斯系统辨识框架，能够高精度地联合估计机器人的状态轨迹和物理参数，通过嵌入物理约束、能量正则化器和高效的计算方法，提高了参数可观性、估计精度和鲁棒性，并在仿真和实际机器人实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统辨识方法在联合估计状态和参数时存在精度不足、参数可观性差、难以处理非线性摩擦和物理约束等问题，尤其是在复杂动态环境下，对模型精度要求更高。

Method: 提出一个贝叶斯系统辨识框架，包含以下关键技术：1. 嵌入物理一致性逆动力学、接触和回路闭合约束作为硬等式约束；2. 采用基于能量的回归器提高参数可观性；3. 支持惯性与驱动参数的等式和不等式先验；4. 强制执行动态一致的扰动投影；5. 增强本体感觉测量与能量观测以区分非线性摩擦；6. 推导参数化等式约束Riccati递归以保持问题带状结构，实现线性的时间复杂度；7. 开发计算高效的导数。

Result: 仿真和真实机器人（Unitree B1 + Z1臂）实验表明，该方法比基于前向动力学和解耦辨识的方法具有更快的收敛速度、更低的惯性和摩擦估计误差，以及更高的接触一致性。将所学模型用于模型预测控制框架时，在复杂环境下的运动跟踪性能得到显著提升。

Conclusion: 所提出的贝叶斯系统辨识框架能够有效地联合估计机器人的状态轨迹和物理参数，尤其在处理物理约束、非线性摩擦和提高参数可观性方面表现出色，并且具有良好的计算效率和可扩展性，能够显著提升机器人在复杂环境下的控制性能。

Abstract: We introduce a Bayesian system identification (SysID) framework for jointly estimating robot's state trajectories and physical parameters with high accuracy. It embeds physically consistent inverse dynamics, contact and loop-closure constraints, and fully featured joint friction models as hard, stage-wise equality constraints. It relies on energy-based regressors to enhance parameter observability, supports both equality and inequality priors on inertial and actuation parameters, enforces dynamically consistent disturbance projections, and augments proprioceptive measurements with energy observations to disambiguate nonlinear friction effects. To ensure scalability, we derive a parameterized equality-constrained Riccati recursion that preserves the banded structure of the problem, achieving linear complexity in the time horizon, and develop computationally efficient derivatives. Simulation studies on representative robotic systems, together with hardware experiments on a Unitree B1 equipped with a Z1 arm, demonstrate faster convergence, lower inertial and friction estimation errors, and improved contact consistency compared to forward-dynamics and decoupled identification baselines. When deployed within model predictive control frameworks, the resulting models yield measurable improvements in tracking performance during locomotion over challenging environments.

</details>


### [167] [Docking and Persistent Operations for a Resident Underwater Vehicle](https://arxiv.org/abs/2602.16360)
*Leonard Günzel,Gabrielė Kasparavičiūtė,Ambjørn Grimsrud Waldum,Bjørn-Magnus Moslått,Abubakar Aliyu Badawi,Celil Yılmaz,Md Shamin Yeasher Yousha,Robert Staven,Martin Ludvigsen*

Main category: cs.RO

TL;DR: 该研究提出并验证了一种基于小型遥控潜水器（ROV）和对接站的自主水下监测系统，该系统可在90米深度实现持续、无需人工干预的运行，成功率高，表明了其在水下监测方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前水下监测方法受限于成本高、操作复杂，存在观测稀疏和不连续的问题。需要能够在无需持续水面支持下进行持久自主运行的水下监测系统。

Method: 开发了一个包含对接站和小型ROV的居民水下系统。ROV具备增强的板载处理和感知能力，能够使用USBL信号自主导航，并通过融合了ArUco标记视觉定位的扩展卡尔曼滤波器进行对接，并执行局部检查任务。

Result: 该系统实现了90%的自主对接成功率，并在四分钟内完成了完整的检查任务，验证了声学和视觉导航在真实条件下的集成能力。

Conclusion: 研究表明，在深水区域实现可靠的、无缆的自主水下运行是可行的，并突出了居民ROV系统在可扩展、低成本水下监测方面的潜力。

Abstract: Our understanding of the oceans remains limited by sparse and infrequent observations, primarily because current methods are constrained by the high cost and logistical effort of underwater monitoring, relying either on sporadic surveys across broad areas or on long-term measurements at fixed locations. To overcome these limitations, monitoring systems must enable persistent and autonomous operations without the need for continuous surface support. Despite recent advances, resident underwater vehicles remain uncommon due to persistent challenges in autonomy, robotic resilience, and mechanical robustness, particularly under long-term deployment in harsh and remote environments. This work addresses these problems by presenting the development, deployment, and operation of a resident infrastructure using a docking station with a mini-class Remotely Operated Vehicle (ROV) at 90m depth. The ROVis equipped with enhanced onboard processing and perception, allowing it to autonomously navigate using USBL signals, dock via ArUco marker-based visual localisation fused through an Extended Kalman Filter, and carry out local inspection routines. The system demonstrated a 90% autonomous docking success rate and completed full inspection missions within four minutes, validating the integration of acoustic and visual navigation in real-world conditions. These results show that reliable, untethered operations at depth are feasible, highlighting the potential of resident ROV systems for scalable, cost-effective underwater monitoring.

</details>


### [168] [Markerless 6D Pose Estimation and Position-Based Visual Servoing for Endoscopic Continuum Manipulators](https://arxiv.org/abs/2602.16365)
*Junhyun Park,Chunggil An,Myeongbo Park,Ihsan Ullah,Sihyeong Park,Minho Hwang*

Main category: cs.RO

TL;DR: 该研究提出了一种用于连续操纵器的全标记式立体视觉6D姿态估计和基于视觉伺服的闭环控制框架，通过仿真训练、多特征融合网络和无监督域自适应，在真实世界中实现了高精度的姿态估计和轨迹跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有连续操纵器的姿态估计和闭环控制面临挑战，如滞后性、依从性和有限的远端传感，而基于视觉的方法因几何可观性有限和计算开销高而难以实现实时闭环控制。该研究旨在克服这些限制，实现高精度、全标记式的闭环控制。

Method: 提出了一种结合照片级真实感仿真、多特征融合神经网络（利用分割掩码、关键点、热图和边界框）、前馈渲染模块（用于姿态校正）以及自监督域自适应策略的统一框架。通过这些方法，实现了标记式立体6D姿态估计和基于视觉伺服的闭环控制。

Result: 在真实世界验证中，姿态估计的平均平移误差为0.83 mm，平均旋转误差为2.76°。基于该姿态估计实现的闭环视觉伺服，平均平移误差为2.07 mm，平均旋转误差为7.41°，相比开环控制分别降低了85%和59%。

Conclusion: 该研究提出了首个用于连续操纵器的全标记式姿态估计驱动的基于位置的视觉伺服框架，实现了无需物理标记或嵌入式传感的精确闭环控制，显著提高了轨迹跟踪精度和可重复性。

Abstract: Continuum manipulators in flexible endoscopic surgical systems offer high dexterity for minimally invasive procedures; however, accurate pose estimation and closed-loop control remain challenging due to hysteresis, compliance, and limited distal sensing. Vision-based approaches reduce hardware complexity but are often constrained by limited geometric observability and high computational overhead, restricting real-time closed-loop applicability. This paper presents a unified framework for markerless stereo 6D pose estimation and position-based visual servoing of continuum manipulators. A photo-realistic simulation pipeline enables large-scale automatic training with pixel-accurate annotations. A stereo-aware multi-feature fusion network jointly exploits segmentation masks, keypoints, heatmaps, and bounding boxes to enhance geometric observability. To enforce geometric consistency without iterative optimization, a feed-forward rendering-based refinement module predicts residual pose corrections in a single pass. A self-supervised sim-to-real adaptation strategy further improves real-world performance using unlabeled data. Extensive real-world validation achieves a mean translation error of 0.83 mm and a mean rotation error of 2.76° across 1,000 samples. Markerless closed-loop visual servoing driven by the estimated pose attains accurate trajectory tracking with a mean translation error of 2.07 mm and a mean rotation error of 7.41°, corresponding to 85% and 59% reductions compared to open-loop control, together with high repeatability in repeated point-reaching tasks. To the best of our knowledge, this work presents the first fully markerless pose-estimation-driven position-based visual servoing framework for continuum manipulators, enabling precise closed-loop control without physical markers or embedded sensing.

</details>


### [169] [RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation](https://arxiv.org/abs/2602.16444)
*Yixue Zhang,Kun Wu,Zhi Gao,Zhen Zhao,Pei Ren,Zhiyuan Xu,Fei Liao,Xinhua Wang,Shichao Fan,Di Wu,Qiuxuan Feng,Meng Li,Zhengping Che,Chang Liu,Jian Tang*

Main category: cs.RO

TL;DR: RoboGene是一个自动生成多样化、物理上可行操控任务的代理框架，旨在解决机器人操控领域数据稀疏的问题，并能与现有基础模型（如GPT-4o）相比，显著提升视觉-语言-动作（VLA）模型的性能。


<details>
  <summary>Details</summary>
Motivation: 机器人操控领域通用性研究受限于真实世界交互数据的稀缺性，而数据收集成本高昂。现有手动方法效率低下且存在偏见，基础模型则可能生成不切实际的任务指令。

Method: RoboGene框架包含三个核心组件：1. 驱动多样性采样的机制以实现广泛的任务覆盖；2. 自我反思机制以强制执行物理约束；3. 人机协作式改进机制以实现持续优化。

Result: RoboGene生成了包含18,000个轨迹的数据集，并引入了新的任务质量、可行性和多样性评估指标。实验表明，RoboGene在任务生成质量上显著优于GPT-4o和Gemini 2.5 Pro等模型。使用RoboGene预训练的VLA模型在真实世界实验中展现出更高的成功率和泛化能力。

Conclusion: RoboGene能够有效地自动生成多样化且物理上可行的数据，为提升机器人操控能力，特别是VLA模型的性能，提供了关键支持，解决了当前数据收集的瓶颈问题。

Abstract: The pursuit of general-purpose robotic manipulation is hindered by the scarcity of diverse, real-world interaction data. Unlike data collection from web in vision or language, robotic data collection is an active process incurring prohibitive physical costs. Consequently, automated task curation to maximize data value remains a critical yet under-explored challenge. Existing manual methods are unscalable and biased toward common tasks, while off-the-shelf foundation models often hallucinate physically infeasible instructions. To address this, we introduce RoboGene, an agentic framework designed to automate the generation of diverse, physically plausible manipulation tasks across single-arm, dual-arm, and mobile robots. RoboGene integrates three core components: diversity-driven sampling for broad task coverage, self-reflection mechanisms to enforce physical constraints, and human-in-the-loop refinement for continuous improvement. We conduct extensive quantitative analysis and large-scale real-world experiments, collecting datasets of 18k trajectories and introducing novel metrics to assess task quality, feasibility, and diversity. Results demonstrate that RoboGene significantly outperforms state-of-the-art foundation models (e.g., GPT-4o, Gemini 2.5 Pro). Furthermore, real-world experiments show that VLA models pre-trained with RoboGene achieve higher success rates and superior generalization, underscoring the importance of high-quality task generation. Our project is available at https://robogene-boost-vla.github.io.

</details>


### [170] [Dynamic Modeling and MPC for Locomotion of Tendon-Driven Soft Quadruped](https://arxiv.org/abs/2602.16371)
*Saumya Karan,Neerav Maram,Suraj Borate,Madhu Vadali*

Main category: cs.RO

TL;DR: 该论文介绍了一种名为SLOT的软体四足机器人，并提出了一种结合物理信息建模和控制的方法，用于实现其仿生运动。该方法能够准确模拟软腿的大变形和弹性，并通过模型预测控制实现稳定运动，并在实验中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于为具有柔顺腿部驱动的软体四足机器人开发一种物理信息建模和控制方法，以实现仿生运动，并提高控制的稳定性和可扩展性。

Method: 论文中提出的方法包括：1. 使用离散Cosserat杆理论对每条软腿进行建模，以捕捉大弯曲变形、分布式弹性和肌腱驱动。2. 建立一个模块化的全身建模框架，将柔顺腿动力学表示为施加在刚性躯干上的物理上一致的反作用力。3. 将该模型嵌入到凸模型预测控制框架中，优化地反作用力并将其映射到肌腱驱动。4. 使用物理信息力-角度关系进行控制。

Result: 提出的控制框架在各种扰动下实现了渐近稳定性。实验结果表明，该方法在模拟和现实原型上都取得了高精度（质心轨迹RMSE小于5毫米），成功实现了爬行和行走步态。

Conclusion: 该研究提出了一种通用的方法，将连续体软腿集成到基于模型的运动控制中，为软体四足机器人的可扩展和可重用建模与控制方法提供了进步。

Abstract: SLOT (Soft Legged Omnidirectional Tetrapod), a tendon-driven soft quadruped robot with 3D-printed TPU legs, is presented to study physics-informed modeling and control of compliant legged locomotion using only four actuators. Each leg is modeled as a deformable continuum using discrete Cosserat rod theory, enabling the capture of large bending deformations, distributed elasticity, tendon actuation, and ground contact interactions. A modular whole-body modeling framework is introduced, in which compliant leg dynamics are represented through physically consistent reaction forces applied to a rigid torso, providing a scalable interface between continuum soft limbs and rigid-body locomotion dynamics. This formulation allows efficient whole-body simulation and real-time control without sacrificing physical fidelity. The proposed model is embedded into a convex model predictive control framework that optimizes ground reaction forces over a 0.495 s prediction horizon and maps them to tendon actuation through a physics-informed force-angle relationship. The resulting controller achieves asymptotic stability under diverse perturbations. The framework is experimentally validated on a physical prototype during crawling and walking gaits, achieving high accuracy with less than 5 mm RMSE in center of mass trajectories. These results demonstrate a generalizable approach for integrating continuum soft legs into model-based locomotion control, advancing scalable and reusable modeling and control methods for soft quadruped robots.

</details>


### [171] [Reactive Motion Generation With Particle-Based Perception in Dynamic Environments](https://arxiv.org/abs/2602.16462)
*Xiyuan Zhao,Huijun Li,Lifeng Zhu,Zhikai Wei,Xianyi Zhu,Aiguo Song*

Main category: cs.RO

TL;DR: 本文提出了一种结合了动态环境感知和机器人运动规划的方法，通过显式建模机器人与动态障碍物之间的相互作用，提高了机器人在不确定和动态环境下的安全性和反应能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人运动生成方法在动态和非结构化环境中存在不足，主要受限于静态感知和系统动力学模型，难以可靠地建模动态障碍物并优化避障轨迹，同时面临感知和控制的不确定性。

Method: 文章提出了一种张量化粒子权重更新方案，用于高效地进行动态属性的粒子感知，该方案同时维护障碍物的速度和协方差。在此基础上，提出了一种障碍物感知的MPPI（Model Predictive Path Integral）规划方法，该方法联合传播机器人-障碍物动力学，从而在不确定性下预测和评估未来的系统运动。

Result: 实验结果表明，该模型预测方法在动态环境中显著提高了安全性和反应能力。在模拟和带有噪声的真实世界环境中，该框架能够有效地避开多个静态和动态障碍物，并且在性能上优于最先进的基于MPPI的感知-规划基线方法。

Conclusion: 显式建模机器人-障碍物动力学对于提升机器人在动态不确定环境下的规划和感知能力至关重要。所提出的框架能够有效结合动态感知和运动规划，实现更安全、更具反应性的机器人操作。

Abstract: Reactive motion generation in dynamic and unstructured scenarios is typically subject to essentially static perception and system dynamics. Reliably modeling dynamic obstacles and optimizing collision-free trajectories under perceptive and control uncertainty are challenging. This article focuses on revealing tight connection between reactive planning and dynamic mapping for manipulators from a model-based perspective. To enable efficient particle-based perception with expressively dynamic property, we present a tensorized particle weight update scheme that explicitly maintains obstacle velocities and covariance meanwhile. Building upon this dynamic representation, we propose an obstacle-aware MPPI-based planning formulation that jointly propagates robot-obstacle dynamics, allowing future system motion to be predicted and evaluated under uncertainty. The model predictive method is shown to significantly improve safety and reactivity with dynamic surroundings. By applying our complete framework in simulated and noisy real-world environments, we demonstrate that explicit modeling of robot-obstacle dynamics consistently enhances performance over state-of-the-art MPPI-based perception-planning baselines avoiding multiple static and dynamic obstacles.

</details>


### [172] [Decentralized and Fully Onboard: Range-Aided Cooperative Localization and Navigation on Micro Aerial Vehicles](https://arxiv.org/abs/2602.16594)
*Abhishek Goudar,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文提出了一种完全去中心化的方法，用于机器人团队的测距辅助定位和编队控制，能够实现分米级的精度，并且不需要专门的轨迹来维持编队。


<details>
  <summary>Details</summary>
Motivation: 传统的集中式机器人控制方法难以扩展，而依赖外部全局定位系统的方案并非总是可用。因此，研究一种去中心化的、仅依赖相对测量（如测距）的定位和编队控制方法具有重要意义。

Method: 该研究提出了两种主要方法：1. 基于块坐标下降的去中心化定位方法，该方法允许机器人仅使用自身里程计和与其他机器人的距离测量数据进行定位，并且无需严格的机器人间协调。2. 将编队控制问题形式化为因子图上的推理问题，该方法考虑了状态估计的不确定性，并且可以高效求解。

Result: 该方法实现了完全去中心化的定位和编队导航，无需特殊轨迹维持编队，并在定位和编队控制方面达到了分米级精度。通过在室内外多种环境下进行的多次实际实验进行了验证。

Conclusion: 本文提出的测距辅助去中心化定位和编队控制方法，有效解决了机器人协同控制的挑战，实现了高精度、鲁棒且无需中心化协调的机器人团队协同导航。

Abstract: Controlling a team of robots in a coordinated manner is challenging because centralized approaches (where all computation is performed on a central machine) scale poorly, and globally referenced external localization systems may not always be available. In this work, we consider the problem of range-aided decentralized localization and formation control. In such a setting, each robot estimates its relative pose by combining data only from onboard odometry sensors and distance measurements to other robots in the team. Additionally, each robot calculates the control inputs necessary to collaboratively navigate an environment to accomplish a specific task, for example, moving in a desired formation while monitoring an area. We present a block coordinate descent approach to localization that does not require strict coordination between the robots. We present a novel formulation for formation control as inference on factor graphs that takes into account the state estimation uncertainty and can be solved efficiently. Our approach to range-aided localization and formation-based navigation is completely decentralized, does not require specialized trajectories to maintain formation, and achieves decimeter-level positioning and formation control accuracy. We demonstrate our approach through multiple real experiments involving formation flights in diverse indoor and outdoor environments.

</details>


### [173] [VIGOR: Visual Goal-In-Context Inference for Unified Humanoid Fall Safety](https://arxiv.org/abs/2602.16511)
*Osher Azulay,Zhengjie Xu,Andrew Scheffer,Stella X. Yu*

Main category: cs.RO

TL;DR: 本文提出了一种统一的摔倒安全方法，通过结合对人类摔倒和恢复姿势的洞察，以及集成的感知-运动表征，使得人形机器人能够在复杂地形下实现可靠的摔倒恢复。该方法利用教师-学生模型，在模拟和真实环境中都取得了零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人摔倒恢复方法存在碎片化（如单独处理避险、冲击缓解、站立恢复）或依赖于缺乏视觉信息的端到端策略，且通常只在平坦地形上训练，这限制了其在复杂环境下的可扩展性和泛化能力。因此，需要一种能够覆盖摔倒恢复所有阶段的统一方法。

Method: 该研究基于两个关键洞察：1) 人类的摔倒和恢复姿势在不同地形之间可以通过对齐进行迁移；2) 快速的全身体反应需要集成的感知-运动表征。研究者训练了一个特权教师模型，利用稀疏的人类演示（包括平坦和模拟的复杂地形），然后将其蒸馏到一个可部署的学生模型中。学生模型仅依赖于以自身为中心的深度感知和本体感觉，通过匹配教师的目标姿势与局部地形相结合的潜在表征来学习反应策略。

Result: 所提出的方法在模拟环境和真实的Unitree G1人形机器人上进行了验证，结果表明该方法能够在多种非平坦环境中实现鲁棒的、零样本的摔倒安全，且无需在真实世界进行额外的微调。

Conclusion: 本文提出了一种新颖的统一摔倒安全方法，通过整合感知和运动的表征，并利用教师-学生学习范式，成功地克服了现有方法的局限性，使人形机器人能够在复杂地形下进行可靠的摔倒恢复，并展现了良好的泛化能力。

Abstract: Reliable fall recovery is critical for humanoids operating in cluttered environments. Unlike quadrupeds or wheeled robots, humanoids experience high-energy impacts, complex whole-body contact, and large viewpoint changes during a fall, making recovery essential for continued operation. Existing methods fragment fall safety into separate problems such as fall avoidance, impact mitigation, and stand-up recovery, or rely on end-to-end policies trained without vision through reinforcement learning or imitation learning, often on flat terrain. At a deeper level, fall safety is treated as monolithic data complexity, coupling pose, dynamics, and terrain and requiring exhaustive coverage, limiting scalability and generalization. We present a unified fall safety approach that spans all phases of fall recovery. It builds on two insights: 1) Natural human fall and recovery poses are highly constrained and transferable from flat to complex terrain through alignment, and 2) Fast whole-body reactions require integrated perceptual-motor representations. We train a privileged teacher using sparse human demonstrations on flat terrain and simulated complex terrains, and distill it into a deployable student that relies only on egocentric depth and proprioception. The student learns how to react by matching the teacher's goal-in-context latent representation, which combines the next target pose with the local terrain, rather than separately encoding what it must perceive and how it must act. Results in simulation and on a real Unitree G1 humanoid demonstrate robust, zero-shot fall safety across diverse non-flat environments without real-world fine-tuning. The project page is available at https://vigor2026.github.io/

</details>


### [174] [Sensor Query Schedule and Sensor Noise Covariances for Accuracy-constrained Trajectory Estimation](https://arxiv.org/abs/2602.16598)
*Abhishek Goudar,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 本文提出了一种通过半正定规划（SDP）来估计传感器参数（采样率或噪声协方差）的方法，以达到预期的机器人轨迹估计精度。该方法考虑了系统模型和传感器本身的限制，并能在仿真和真实实验中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在机器人轨迹估计中，传感器精度和采样率对估计精度至关重要，但成本和资源限制了它们的提升。研究动机是，在给定成本和资源限制下，如何最优地选择传感器参数以达到特定的轨迹估计精度。

Method: 本文将估计传感器采样率（或其调度）和传感器噪声协方差的问题，分别建模为半正定规划（SDP）问题。通过求解SDP，可以得到实现特定估计精度的传感器参数。

Result: 通过仿真和真实实验验证，所提出的方法能够计算出实现预期轨迹估计精度的传感器采样率和传感器噪声协方差。此外，该方法还能识别在给定系统和传感器特性下，某些估计精度是无法实现的。

Conclusion: 所提出的基于SDP的方法能够有效地估计实现特定轨迹估计精度的传感器参数（采样率或噪声协方差），并能识别不可达到的精度目标，为资源受限下的机器人轨迹估计提供了优化手段。

Abstract: Trajectory estimation involves determining the trajectory of a mobile robot by combining prior knowledge about its dynamic model with noisy observations of its state obtained using sensors. The accuracy of such a procedure is dictated by the system model fidelity and the sensor parameters, such as the accuracy of the sensor (as represented by its noise covariance) and the rate at which it can generate observations, referred to as the sensor query schedule. Intuitively, high-rate measurements from accurate sensors lead to accurate trajectory estimation. However, cost and resource constraints limit the sensor accuracy and its measurement rate. Our work's novel contribution is the estimation of sensor schedules and sensor covariances necessary to achieve a specific estimation accuracy. Concretely, we focus on estimating: (i) the rate or schedule with which a sensor of known covariance must generate measurements to achieve specific estimation accuracy, and alternatively, (ii) the sensor covariance necessary to achieve specific estimation accuracy for a given sensor update rate. We formulate the problem of estimating these sensor parameters as semidefinite programs, which can be solved by off-the-shelf solvers. We validate our approach in simulation and real experiments by showing that the sensor schedules and the sensor covariances calculated using our proposed method achieve the desired trajectory estimation accuracy. Our method also identifies scenarios where certain estimation accuracy is unachievable with the given system and sensor characteristics.

</details>


### [175] [Towards Autonomous Robotic Kidney Ultrasound: Spatial-Efficient Volumetric Imaging via Template Guided Optimal Pivoting](https://arxiv.org/abs/2602.16641)
*Xihan Ma,Haichong Zhang*

Main category: cs.RO

TL;DR: 本文提出了一种基于模板引导的最优旋转的自主工作流程，以实现高效的机器人超声（RUS）肾脏成像，该方法通过最小化探头占地面积来最大化肾脏覆盖率。


<details>
  <summary>Details</summary>
Motivation: 传统的自由手超声成像结果不稳定且依赖操作员，缺乏3D定位信息，并可能导致操作员的肌肉骨骼损伤。现有的RUS系统虽然能标准化数据采集，但扫描方法无法确定最优成像窗口，导致盲扫、声影和器官覆盖不全。因此，迫切需要一种空间高效的成像技术。

Method: 该系统首先进行探索性成像以获取部分肾脏观测数据，然后将该数据配准到肾脏模板以估计器官姿态。在定位肾脏后，机器人执行固定点旋转扫描，将成像平面与肾脏长轴对齐，以最小化探头平移。通过模板引导的最优旋转实现高效肾脏成像。

Result: 仿真结果表明，60%的探索率在肾脏定位精度和扫描效率之间达到了最佳平衡。体内实验在两名男性受试者身上进行了验证，肾脏定位精度高达7.36毫米和13.84度。与基线方法相比，最优旋转方法将探头占地面积缩短了约75毫米。

Conclusion: 该方法通过利用解剖学模板优化探头对齐以进行容积扫描，有效提高了机器人超声肾脏成像的效率和覆盖率，缩短了探头占地面积，并提高了定位精度。

Abstract: Medical ultrasound (US) imaging is a frontline tool for the diagnosis of kidney diseases. However, traditional freehand imaging procedure suffers from inconsistent, operator-dependent outcomes, lack of 3D localization information, and risks of work-related musculoskeletal disorders. While robotic ultrasound (RUS) systems offer the potential for standardized, operator-independent 3D kidney data acquisition, the existing scanning methods lack the ability to determine the optimal imaging window for efficient imaging. As a result, the scan is often blindly performed with excessive probe footprint, which frequently leads to acoustic shadowing and incomplete organ coverage. Consequently, there is a critical need for a spatially efficient imaging technique that can maximize the kidney coverage through minimum probe footprint. Here, we propose an autonomous workflow to achieve efficient kidney imaging via template-guided optimal pivoting. The system first performs an explorative imaging to generate partial observations of the kidney. This data is then registered to a kidney template to estimate the organ pose. With the kidney localized, the robot executes a fixed-point pivoting sweep where the imaging plane is aligned with the kidney long axis to minimize the probe translation. The proposed method was validated in simulation and in-vivo. Simulation results indicate that a 60% exploration ratio provides optimal balance between kidney localization accuracy and scanning efficiency. In-vivo evaluation on two male subjects demonstrates a kidney localization accuracy up to 7.36 mm and 13.84 degrees. Moreover, the optimal pivoting approach shortened the probe footprint by around 75 mm when compared with the baselines. These results valid our approach of leveraging anatomical templates to align the probe optimally for volumetric sweep.

</details>


### [176] [Learning to unfold cloth: Scaling up world models to deformable object manipulation](https://arxiv.org/abs/2602.16675)
*Jack Rome,Stephen James,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 本文提出了一种基于改进版DreamerV2的空中布料操控方法，通过引入表面法线输入、改进回放缓冲区和数据增强，提升了机器人在模拟和真实环境中对不同类型布料进行展开的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 布料操控在机器人研究和实际应用中都具有重要意义，但其复杂的物理特性使得通用操控策略难以实现。研究的动机在于开发一种能够应对不同形状、大小、折叠和褶皱模式，以及外观变化的布料操控方法，并着重考虑模型结构对泛化性能的影响。

Method: 研究者修改了最近提出的强化学习架构DreamerV2，使其能够利用表面法线作为输入。同时，他们还改进了回放缓冲区和数据增强的程序。这些修改旨在增强机器人所使用的世界模型，以处理被操控物体的物理复杂性。

Result: 在模拟和物理机器人实验中，所提出的方法在零样本部署下成功实现了对多种不同类型布料的空中展开。实验结果证明了所提架构在泛化能力方面的优势。

Conclusion: 通过修改DreamerV2架构，并结合表面法线输入、改进的回放缓冲区和数据增强，该研究成功地提升了机器人在空中布料操控任务上的泛化能力，能够应对不同类型的布料。

Abstract: Learning to manipulate cloth is both a paradigmatic problem for robotic research and a problem of immediate relevance to a variety of applications ranging from assistive care to the service industry. The complex physics of the deformable object makes this problem of cloth manipulation nontrivial. In order to create a general manipulation strategy that addresses a variety of shapes, sizes, fold and wrinkle patterns, in addition to the usual problems of appearance variations, it becomes important to carefully consider model structure and their implications for generalisation performance. In this paper, we present an approach to in-air cloth manipulation that uses a variation of a recently proposed reinforcement learning architecture, DreamerV2. Our implementation modifies this architecture to utilise surface normals input, in addition to modiying the replay buffer and data augmentation procedures. Taken together these modifications represent an enhancement to the world model used by the robot, addressing the physical complexity of the object being manipulated by the robot. We present evaluations both in simulation and in a zero-shot deployment of the trained policies in a physical robot setup, performing in-air unfolding of a variety of different cloth types, demonstrating the generalisation benefits of our proposed architecture.

</details>


### [177] [Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation](https://arxiv.org/abs/2602.16705)
*Runpei Dong,Ziyan Li,Xialin He,Saurabh Gupta*

Main category: cs.RO

TL;DR: 提出了一种名为HERO的新范式，通过结合大型视觉模型的泛化能力和模拟训练的控制性能，实现了人形机器人在野外对任意物体进行视觉运动操纵。该方法通过一个精确的残差感知末端执行器（EE）跟踪策略，结合逆运动学、学习到的正向动力学模型、目标调整和重规划，显著降低了EE跟踪误差，并实现多样化环境下的物体操纵。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人视觉运动操纵方法在真实世界中泛化能力有限，主要是因为难以收集大规模训练数据集。研究者希望结合大型视觉模型的强大泛化性和模拟训练的精确控制能力，以解决这一问题。

Method: 提出HERO范式，设计了一个精确的残差感知EE跟踪策略，该策略结合了经典机器人学和机器学习技术。具体包括：1）使用逆运动学将残差EE目标转换为参考轨迹；2）使用学习到的神经网络前向模型进行精确的前向运动学计算；3）进行目标调整；4）进行重规划。在此基础上，构建了一个模块化运动操纵系统，利用开放词汇的大型视觉模型实现强大的视觉泛化。

Result: 通过EE跟踪策略，将末端执行器跟踪误差降低了3.2倍。所提出的系统能够在包括办公室和咖啡馆在内的多样化真实世界环境中运行，成功操纵各种日常物体（如马克杯、苹果、玩具），操作表面高度范围从43厘米到92厘米。

Conclusion: HERO范式有效地结合了大型视觉模型的泛化能力和模拟训练的控制性能，显著提高了人形机器人在野外进行视觉运动操纵的能力。研究表明，该方法在真实世界环境中取得了成功，并为训练人形机器人与日常物体互动开辟了新途径。

Abstract: Visual loco-manipulation of arbitrary objects in the wild with humanoid robots requires accurate end-effector (EE) control and a generalizable understanding of the scene via visual inputs (e.g., RGB-D images). Existing approaches are based on real-world imitation learning and exhibit limited generalization due to the difficulty in collecting large-scale training datasets. This paper presents a new paradigm, HERO, for object loco-manipulation with humanoid robots that combines the strong generalization and open-vocabulary understanding of large vision models with strong control performance from simulated training. We achieve this by designing an accurate residual-aware EE tracking policy. This EE tracking policy combines classical robotics with machine learning. It uses a) inverse kinematics to convert residual end-effector targets into reference trajectories, b) a learned neural forward model for accurate forward kinematics, c) goal adjustment, and d) replanning. Together, these innovations help us cut down the end-effector tracking error by 3.2x. We use this accurate end-effector tracker to build a modular system for loco-manipulation, where we use open-vocabulary large vision models for strong visual generalization. Our system is able to operate in diverse real-world environments, from offices to coffee shops, where the robot is able to reliably manipulate various everyday objects (e.g., mugs, apples, toys) on surfaces ranging from 43cm to 92cm in height. Systematic modular and end-to-end tests in simulation and the real world demonstrate the effectiveness of our proposed design. We believe the advances in this paper can open up new ways of training humanoid robots to interact with daily objects.

</details>


### [178] [EgoScale: Scaling Dexterous Manipulation with Diverse Egocentric Human Data](https://arxiv.org/abs/2602.16710)
*Ruijie Zheng,Dantong Niu,Yuqi Xie,Jing Wang,Mengda Xu,Yunfan Jiang,Fernando Castañeda,Fengyuan Hu,You Liang Tan,Letian Fu,Trevor Darrell,Furong Huang,Yuke Zhu,Danfei Xu,Linxi Fan*

Main category: cs.RO

TL;DR: 本文提出了 EgoScale 框架，利用大规模的以自我为中心的人类行为视频数据，实现了高效的机器人灵巧操作。研究发现，人类数据规模与模型性能之间存在对数线性增长关系，并通过预训练和轻量级迁移学习，显著提升了机器人在复杂操作任务上的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有研究在利用人类行为数据进行机器人灵巧操作方面存在局限性，尤其是在大规模、高自由度操作的场景下。本文旨在探索大规模人类数据对精细灵巧操作的有效性，并提出一种可扩展的框架。

Method: 利用超过 20,854 小时的动作标记的以自我为中心的人类视频数据，训练了一个视觉-语言-动作（VLA）模型。提出了一种两阶段的迁移学习方法：大规模人类数据预训练，然后进行轻量级的人类-机器人对齐中期训练。

Result: 发现了人类数据规模与验证损失之间存在对数线性增长规律，且验证损失与机器人实际操作性能强相关。该方法在 22 DoF 灵巧机械手上，相较于无预训练基线，平均成功率提升了 54%，并能有效迁移到低自由度机械手上。

Conclusion: 大规模以自我为中心的人类行为数据是机器人灵巧操作的有效且可预测的监督源。通过大规模预训练和轻量级迁移学习，可以实现高效的长时程灵巧操作，并支持一次性任务适应，且该方法具有良好的通用性，不受机器人具身特性的限制。

Abstract: Human behavior is among the most scalable sources of data for learning physical intelligence, yet how to effectively leverage it for dexterous manipulation remains unclear. While prior work demonstrates human to robot transfer in constrained settings, it is unclear whether large scale human data can support fine grained, high degree of freedom dexterous manipulation. We present EgoScale, a human to dexterous manipulation transfer framework built on large scale egocentric human data. We train a Vision Language Action (VLA) model on over 20,854 hours of action labeled egocentric human video, more than 20 times larger than prior efforts, and uncover a log linear scaling law between human data scale and validation loss. This validation loss strongly correlates with downstream real robot performance, establishing large scale human data as a predictable supervision source. Beyond scale, we introduce a simple two stage transfer recipe: large scale human pretraining followed by lightweight aligned human robot mid training. This enables strong long horizon dexterous manipulation and one shot task adaptation with minimal robot supervision. Our final policy improves average success rate by 54% over a no pretraining baseline using a 22 DoF dexterous robotic hand, and transfers effectively to robots with lower DoF hands, indicating that large scale human motion provides a reusable, embodiment agnostic motor prior.

</details>


### [179] [One Hand to Rule Them All: Canonical Representations for Unified Dexterous Manipulation](https://arxiv.org/abs/2602.16712)
*Zhenyu Wei,Yunchao Yao,Mingyu Ding*

Main category: cs.RO

TL;DR: 本文提出了一种参数化的手部模型统一表示方法，包括统一参数空间和URDF格式，以解决现有操纵策略对手部设计固定的限制。该方法通过学习潜在流形，实现了不同手部形态间的平滑过渡，并标准化了动作空间，从而实现了跨模型抓取策略的有效学习和零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 当前灵巧操作策略在很大程度上依赖于固定的手部设计，限制了其在不同手部结构上的泛化能力。为了解决这一问题，需要一种能够统一各种灵巧手部结构的方法。

Method: 提出了一种参数化的手部模型统一表示，包括一个统一的参数空间和一个标准的URDF格式。训练一个变分自编码器（VAE）来学习该统一表示的紧凑、语义丰富的潜在嵌入。开发了一个基于标准表示的抓取策略，该策略能够泛化到不同的手部结构。

Result: 所提出的框架在模仿学习、VAE潜在编码和跨模型零样本迁移方面表现出优势。训练的VAE能够学习手部形态的结构化潜在流形，允许在不同手部形态之间进行平滑插值。条件化的抓取策略在未见过的手部结构上实现了高达81.9%的零样本成功率，表明了跨模型泛化能力。

Conclusion: 该框架通过统一表示和动作空间，为结构多样的灵巧手部提供了可扩展的学习基础，实现了跨手部学习，朝着通用灵巧操作的目标迈进。它有效地解决了当前手部设计固定带来的泛化限制问题。

Abstract: Dexterous manipulation policies today largely assume fixed hand designs, severely restricting their generalization to new embodiments with varied kinematic and structural layouts. To overcome this limitation, we introduce a parameterized canonical representation that unifies a broad spectrum of dexterous hand architectures. It comprises a unified parameter space and a canonical URDF format, offering three key advantages. 1) The parameter space captures essential morphological and kinematic variations for effective conditioning in learning algorithms. 2) A structured latent manifold can be learned over our space, where interpolations between embodiments yield smooth and physically meaningful morphology transitions. 3) The canonical URDF standardizes the action space while preserving dynamic and functional properties of the original URDFs, enabling efficient and reliable cross-embodiment policy learning. We validate these advantages through extensive analysis and experiments, including grasp policy replay, VAE latent encoding, and cross-embodiment zero-shot transfer. Specifically, we train a VAE on the unified representation to obtain a compact, semantically rich latent embedding, and develop a grasping policy conditioned on the canonical representation that generalizes across dexterous hands. We demonstrate, through simulation and real-world tasks on unseen morphologies (e.g., 81.9% zero-shot success rate on 3-finger LEAP Hand), that our framework unifies both the representational and action spaces of structurally diverse hands, providing a scalable foundation for cross-hand learning toward universal dexterous manipulation.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [180] [Close-enough general routing problem for multiple unmanned aerial vehicles in monitoring missions](https://arxiv.org/abs/2602.15841)
*Huan Liu,Michel Gendreau,Binjie Xu,Guohua Wu,Yi Gu*

Main category: eess.SY

TL;DR: 本文提出了一种近乎多无人机通用路径规划问题（CEMUAVGRP），并设计了一个两阶段迭代方法（AILS-VND-SOCP）来解决，该方法通过优化节点代表点来最小化总距离，并证明了其有效性和圆盘邻域的优势。


<details>
  <summary>Details</summary>
Motivation: 为了解决多无人机监控任务中，无人机需要在覆盖节点的同时最小化总行驶距离的问题，同时考虑到节点附近的监测区域（圆盘邻域）。

Method: 提出了一种两阶段迭代方法：第一阶段使用变量邻域下降（VND）启发式算法解决通用路径规划问题（不考虑圆盘邻域），第二阶段使用二阶锥规划（SOCP）优化每个节点在其路径中的代表点。这两个阶段被集成到一个自适应迭代局部搜索（AILS）框架中进行迭代。

Result: 提出的AILS-VND-SOCP算法在 CEMUAVGRP 问题上表现出高效性，并且实验证明了考虑圆盘邻域比不考虑圆盘邻域效果更好。

Conclusion: 所提出的AILS-VND-SOCP算法是一种有效的解决CEMUAVGRP 的方法，并且在无人机路径规划中引入圆盘邻域概念能够带来更优的性能。

Abstract: In this paper, we introduce a close-enough multi-UAV general routing problem (CEMUAVGRP) where a fleet of homogeneous UAVs conduct monitoring tasks containing nodes, each of which has its disk neighborhood, and edges, aiming to minimize the total distance. A two-phase iterative method is proposed, partitioning the CEMUAVGRP into a general routing phase where a satisfactory route including required nodes and edges for each UAV is obtained without considering the disk neighborhoods of required nodes, and a close-enough routing phase where representative points are optimized for each required node in the determined route. To be specific, a variable neighborhood descent (VND) heuristic is proposed for the general routing phase, while a second-order cone programming (SOCP) procedure is applied in the close-enough routing phase. These two phases are performed in an iterative fashion under the framework of an adaptive iterated local search (AILS) algorithm until the predefined termination criteria are satisfied. Extensive experiments and comparative studies are conducted, demonstrating the efficiency of the proposed AILS-VND-SOCP algorithm and the superiority of disk neighborhoods.

</details>


### [181] [Stability and convergence of multi-converter systems using projection-free power-limiting droop control](https://arxiv.org/abs/2602.16036)
*Amirhossein Iraniparast,Dominic Groß*

Main category: eess.SY

TL;DR: 提出了一种无需投影的限功率下垂控制方法，用于并网电力电子设备，并分析了相关的约束潮流问题。该方法能实现半全局指数稳定，并且与基于投影的方法相比，计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有的基于投影的限功率下垂控制方法计算复杂度较高，促使研究者们开发一种无需投影的控制方法，以提高计算效率并保证系统的稳定性。

Method: 提出了一种新的无需投影的限功率下垂控制算法，并将其与约束潮流问题的投影无关对偶动力学联系起来。通过变换到边坐标系，分析了网络动力学的稳定性、收敛速度，并提出了控制器参数调整方法，最后通过电磁暂态仿真验证了理论分析结果。

Result: 所提出的无需投影的限功率下垂控制方法能够使网络动力学半全局指数稳定。研究人员能够确定收敛速率的界限，并提出了一种调整控制器参数以加速收敛的方法。此外，还分析了收敛速率界限与网络连通性之间的关系。

Conclusion: 无需投影的限功率下垂控制是一种有效且计算效率高的方法，可以实现并网电力电子系统的稳定运行，并能通过参数调整进一步优化其收敛性能。

Abstract: In this paper, we propose a projection-free power-limiting droop control for grid-connected power electronics and an associated constrained flow problem. In contrast to projection-based power-limiting droop control, the novel projection-free power-limiting droop control results in networked dynamics that are semi-globally exponentially stable with respect to the set of optimizers of the constrained flow problem. Under a change to edge coordinates, the overall networked dynamics arising from projection-free power-limiting droop control coincide with the projection-free primal-dual dynamics associated with an augmented Lagrangian of the constrained flow problem. Leveraging this result, we (i) provide a bound on the convergence rate of the projection-free networked dynamics, (ii) propose a tuning method for controller parameters to improve the bound on the convergence rate, and (iii) analyze the relationship of the bound on the convergence rate and connectivity of the network. Finally, the analytical results are illustrated using an Electromagnetic transient (EMT) simulation.

</details>


### [182] [Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets](https://arxiv.org/abs/2602.16062)
*Nelson Salazar-Pena,Alejandra Tabares,Andres Gonzalez-Mancera*

Main category: eess.SY

TL;DR: 该研究提出了一种名为“隐式协作”的框架，允许去中心化能源代理通过系统级指标（拟物信号）进行协调，无需显式通信，从而在本地能源市场中近似最优协调。


<details>
  <summary>Details</summary>
Motivation: 当前能源市场协调依赖于昂贵的中心化通信基础设施，而显式点对点通信在去中心化环境中又难以实现。本研究旨在探索一种无需显式通信的去中心化协调方法，同时提高效率和稳定性，并保护隐私。

Method: 将问题建模为去中心化部分可观察马尔可夫决策过程，并使用多智能体强化学习解决。代理利用拟物信号（系统级KPI）来推断全局状态并做出反应。通过在IEEE 34节点拓扑上进行3x3析因设计，评估了三种训练范式（CTCE、CTDE、DTDE）和三种算法（PPO、APPO、SAC）。

Result: APPO-DTDE被确定为最优配置，实现了相对于中心化基准（CTCE）91.7%的协调得分。去中心化方法（DTDE）在物理稳定性方面优于混合架构，将电网平衡方差降低了31%，并产生了可预测的、偏向进口的负荷曲线。拓扑分析显示代理会形成稳定的交易社区以最小化拥堵罚款。SAC在混合环境中表现良好，但在去中心化环境中因熵驱动的不稳定性而失败。

Conclusion: 拟物信号为复杂的电网协调提供了足够的上下文信息，为昂贵的中心化通信基础设施提供了一种强大且隐私保护的替代方案。去中心化方法在稳定性和可预测性方面具有优势，尽管可能在效率上略有折衷。

Abstract: This paper proposes implicit cooperation, a framework enabling decentralized agents to approximate optimal coordination in local energy markets without explicit peer-to-peer communication. We formulate the problem as a decentralized partially observable Markov decision problem that is solved through a multi-agent reinforcement learning task in which agents use stigmergic signals (key performance indicators at the system level) to infer and react to global states. Through a 3x3 factorial design on an IEEE 34-node topology, we evaluated three training paradigms (CTCE, CTDE, DTDE) and three algorithms (PPO, APPO, SAC). Results identify APPO-DTDE as the optimal configuration, achieving a coordination score of 91.7% relative to the theoretical centralized benchmark (CTCE). However, a critical trade-off emerges between efficiency and stability: while the centralized benchmark maximizes allocative efficiency with a peer-to-peer trade ratio of 0.6, the fully decentralized approach (DTDE) demonstrates superior physical stability. Specifically, DTDE reduces the variance of grid balance by 31% compared to hybrid architectures, establishing a highly predictable, import-biased load profile that simplifies grid regulation. Furthermore, topological analysis reveals emergent spatial clustering, where decentralized agents self-organize into stable trading communities to minimize congestion penalties. While SAC excelled in hybrid settings, it failed in decentralized environments due to entropy-driven instability. This research proves that stigmergic signaling provides sufficient context for complex grid coordination, offering a robust, privacy-preserving alternative to expensive centralized communication infrastructure.

</details>


### [183] [MARLEM: A Multi-Agent Reinforcement Learning Simulation Framework for Implicit Cooperation in Decentralized Local Energy Markets](https://arxiv.org/abs/2602.16063)
*Nelson Salazar-Pena,Alejandra Tabares,Andres Gonzalez-Mancera*

Main category: eess.SY

TL;DR: 本文提出一个用于研究智能电网中的隐式合作的开源多智能体强化学习（MARL）模拟框架。该框架通过增强代理的观察和奖励来促进隐式合作，使其能够在没有明确通信的情况下学习对整个系统有利的策略。


<details>
  <summary>Details</summary>
Motivation: 为了研究和促进智能电网中的隐式合作，特别是在去中心化的部分可观察马尔可夫决策过程（Dec-POMDP）环境下，以及为设计、测试和验证未来智能去中心化能源系统的策略提供一个灵活、可扩展且可复现的工具。

Method: 构建了一个模块化的、基于Gymnasium环境的MARL模拟框架。该框架包含了市场平台、即插即用的清算机制、具有物理约束的代理模型（包括储能）、真实的电网网络以及分析套件。核心创新在于提出了一种增强代理的观察和奖励的方法，加入系统级关键绩效指标（KPIs），从而促使代理学习能够带来集体利益的策略。

Result: 通过案例研究表明，该框架能够分析不同市场配置（如储能部署）对系统性能的影响，并证明了其在促进隐式协调、提高市场效率和增强电网稳定性方面的潜力。

Conclusion: 所提出的模拟框架是一个灵活、可扩展且可复现的工具，能够有效地分析和促进智能电网中的隐式合作，有助于设计和验证未来的智能去中心化能源系统策略。

Abstract: This paper introduces a novel, open-source MARL simulation framework for studying implicit cooperation in LEMs, modeled as a decentralized partially observable Markov decision process and implemented as a Gymnasium environment for MARL. Our framework features a modular market platform with plug-and-play clearing mechanisms, physically constrained agent models (including battery storage), a realistic grid network, and a comprehensive analytics suite to evaluate emergent coordination. The main contribution is a novel method to foster implicit cooperation, where agents' observations and rewards are enhanced with system-level key performance indicators to enable them to independently learn strategies that benefit the entire system and aim for collectively beneficial outcomes without explicit communication. Through representative case studies (available in a dedicated GitHub repository in https://github.com/salazarna/marlem, we show the framework's ability to analyze how different market configurations (such as varying storage deployment) impact system performance. This illustrates its potential to facilitate emergent coordination, improve market efficiency, and strengthen grid stability. The proposed simulation framework is a flexible, extensible, and reproducible tool for researchers and practitioners to design, test, and validate strategies for future intelligent, decentralized energy systems.

</details>


### [184] [Tunable Ferroelectric Acoustic Resonators in Monolithic Thin-Film Barium Titanate](https://arxiv.org/abs/2602.16102)
*Ian Anderson,Agham Posadas,Alexander A. Demkov,Ruochen Lu*

Main category: eess.SY

TL;DR: 本研究提出了一种基于外延钛酸钡（BTO）在硅上生长的可调谐声学谐振器，工作在亚GHz频段，可用于可重构射频应用。


<details>
  <summary>Details</summary>
Motivation: 无线通信频段的快速发展需要小型化、低损耗、频率可调的射频滤波技术。可调谐声学谐振器是满足这些需求的理想方案。

Method: 研究人员在硅上外延生长了钛酸钡（BTO）薄膜，并利用有限元模拟设计了具有横向电极的器件。通过施加直流偏压来对齐铁电畴，从而实现对声学模式的电激励、频率调谐和品质因数增强。

Result: 在近300 MHz和700 MHz的频率下观察到谐振，表现出高达8%的机电耦合和依赖于偏压的频率调谐特性，在20 V附近出现行为的明显转变。

Conclusion: 在外延BTO/硅平台上实现的横向激励、可调谐声学谐振器为可重构射频应用提供了一个有前景的材料体系。

Abstract: The increasing development of wireless communication bands has motivated the development of compact, low-loss, and frequency adjustable RF filtering technologies. Acoustic resonators are the ideal solution to these requirements, and tunable implementations offer a path toward reconfigurable front ends. In this work, we investigate epitaxial barium titanate (BTO) grown on silicon as a platform for tunable acoustic resonators operating in the sub-GHz regime. We demonstrate lateral excitation of symmetric lamb (S0) modes in X-cut BTO membranes, in contrast to prior thickness-defined ferroelectric resonators. Devices are designed using finite-element simulations and fabricated with laterally patterned electrodes that enable overtone coupling to multiple resonant modes. Under applied DC bias, ferroelectric domains align, allowing electrical excitation, frequency tuning, and quality-factor enhancement of acoustic modes. Resonances near 300 MHz and 700 MHz exhibit electromechanical coupling up to 8% and bias-dependent frequency tuning, with a distinct transition in behavior near 20 V. These results highlight monolithic BTO on silicon as a promising material system for laterally excited, tunable acoustic resonators for reconfigurable RF applications.

</details>


### [185] [Discovering Unknown Inverter Governing Equations via Physics-Informed Sparse Machine Learning](https://arxiv.org/abs/2602.16166)
*Jialin Zheng,Ruhaan Batta,Zhong Liu,Xiaonan Lu*

Main category: eess.SY

TL;DR: 提出了一种名为 PISML 的物理信息稀疏机器学习框架，用于从外部测量中发现并恢复逆变器的控制方程，兼顾了非线性和物理一致性，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在识别逆变器未知非线性方程时难以同时保持物理一致性，这阻碍了对现代逆变器密集型电力系统的分析。

Method: 提出 PISML 框架，结合稀疏符号骨干捕捉主要模型结构，神经网络残差分支处理复杂非线性控制逻辑。采用雅可比正则化的物理信息训练机制确保多尺度一致性。通过对残差分支进行符号回归，将黑盒数据转化为显式控制方程。

Result: PISML 框架在硬件在环平台上的实验中表现优异，识别误差比基线方法降低了 340 倍以上。成功将复杂的神经网络压缩成紧凑的显式形式，恢复了可分析性和稳定性分析能力，并显著降低了计算复杂度。

Conclusion: PISML 框架能够从黑盒数据中发现显式数学模型，为分析具有未知逆变器控制方程的电力系统提供了统一的解决方案，提高了分析的精确度和效率。

Abstract: Discovering the unknown governing equations of grid-connected inverters from external measurements holds significant attraction for analyzing modern inverter-intensive power systems. However, existing methods struggle to balance the identification of unmodeled nonlinearities with the preservation of physical consistency. To address this, this paper proposes a Physics-Informed Sparse Machine Learning (PISML) framework. The architecture integrates a sparse symbolic backbone to capture dominant model skeletons with a neural residual branch that compensates for complex nonlinear control logic. Meanwhile, a Jacobian-regularized physics-informed training mechanism is introduced to enforce multi-scale consistency including large/small-scale behaviors. Furthermore, by performing symbolic regression on the neural residual branch, PISML achieves a tractable mapping from black-box data to explicit control equations. Experimental results on a high-fidelity Hardware-in-the-Loop platform demonstrate the framework's superior performance. It not only achieves high-resolution identification by reducing error by over 340 times compared to baselines but also realizes the compression of heavy neural networks into compact explicit forms. This restores analytical tractability for rigorous stability analysis and reduces computational complexity by orders of magnitude. It also provides a unified pathway to convert structurally inaccessible devices into explicit mathematical models, enabling stability analysis of power systems with unknown inverter governing equations.

</details>


### [186] [Collaborative Safe Bayesian Optimization](https://arxiv.org/abs/2602.16235)
*Alina Castell Blasco,Maxime Bouton*

Main category: eess.SY

TL;DR: 本文首次将安全贝叶斯优化应用于移动网络，并提出了一种名为CoSBO的新型安全协同优化算法，该算法考虑了多个安全约束，能够在线安全地调整网络参数，并且样本效率高。


<details>
  <summary>Details</summary>
Motivation: 移动网络需要安全优化来适应不断变化的流量需求和信号传输质量，同时提高服务性能。传统参数调整方法在复杂的新兴移动网络中过于保守或难以评估。

Method: 应用安全贝叶斯优化，并开发了一种新的安全协同优化算法CoSBO，该算法利用来自网络中多个优化任务的信息，并考虑多个安全约束。

Result: 提出的CoSBO算法能够在很少的迭代次数内安全地在线调整网络参数。与SafeOpt-MC算法相比，该方法在移动网络场景中提高了优化过程早期的样本效率。

Conclusion: CoSBO是一种有效的安全协同优化算法，适用于移动网络参数的在线安全调整，能够显著提高样本效率。

Abstract: Mobile networks require safe optimization to adapt to changing conditions in traffic demand and signal transmission quality, in addition to improving service performance metrics. With the increasing complexity of emerging mobile networks, traditional parameter tuning methods become too conservative or complex to evaluate. For the first time, we apply safe Bayesian optimization to mobile networks. Moreover, we develop a new safe collaborative optimization algorithm called CoSBO, leveraging information from multiple optimization tasks in the network and considering multiple safety constraints. The resulting algorithm is capable of safely tuning the network parameter online with very few iterations. We demonstrate that the proposed method improves sample efficiency in the early stages of the optimization process by comparing it against the SafeOpt-MC algorithm in a mobile network scenario.

</details>


### [187] [Autonomous and non-autonomous fixed-time leader-follower consensus for second-order multi-agent systems](https://arxiv.org/abs/2602.16260)
*Miguel A. Trujillo,Rodrigo Aldana-López,David Gomez Gutierrez,Michael Defoort,Javier Ruiz Leon,Hector M. Becerra*

Main category: eess.SY

TL;DR: 本文提出了一种用于领导者-跟随者多智能体系统的固定时间共识跟踪控制方法，其中只有一部分跟随者可以访问领导者状态。该方法分为两步：分布式固定时间领导者状态估计，以及基于估计的固定时间共识跟踪控制。文中比较了两种控制策略：一种是用户预设收敛时间上界的自治协议，另一种是使用有界时变增益的非自治协议，后者能获得更优的收敛时间估计。


<details>
  <summary>Details</summary>
Motivation: 解决在部分跟随者无法直接获取领导者状态的情况下，多智能体系统实现固定时间共识跟踪的问题。

Method: 提出一个两步控制方案：1. 分布式固定时间领导者状态估计；2. 基于估计的固定时间共识跟踪控制。研究并比较了两种控制策略：一种是具有用户设定收敛时间上界的自治协议，另一种是具有有界时变增益的非自治协议。

Result: 提出了两种固定时间共识跟踪控制策略，并通过数值仿真验证了其有效性。非自治协议（使用时变增益）能够获得比自治协议更优的收敛时间上界估计。

Conclusion: 本文成功设计并验证了两种用于领导者-跟随者多智能体系统的固定时间共识跟踪控制协议。其中，基于时变增益的非自治协议在保证收敛时间和增益有界的前提下，提供了更灵活的收敛时间设定。

Abstract: This paper addresses the problem of consensus tracking with fixed-time convergence, for leader-follower multi-agent systems with double-integrator dynamics, where only a subset of followers has access to the state of the leader. The control scheme is divided into two steps. The first one is dedicated to the estimation of the leader state by each follower in a distributed way and in a fixed-time. Then, based on the estimate of the leader state, each follower computes its control law to track the leader in a fixed-time. In this paper, two control strategies are investigated and compared to solve the two mentioned steps. The first one is an autonomous protocol which ensures a fixed-time convergence for the observer and for the controller parts where the Upper Bound of the Settling-Time (UBST) is set a priory by the user. Then, the previous strategy is redesigned using time-varying gains to obtain a non-autonomous protocol. This enables to obtain less conservative estimates of the UBST while guaranteeing that the time-varying gains remain bounded. Some numerical examples show the effectiveness of the proposed consensus protocols.

</details>


### [188] [Certifying Hamilton-Jacobi Reachability Learned via Reinforcement Learning](https://arxiv.org/abs/2602.16475)
*Prashant Solanki,Isabelle El-Hajj,Jasper J. van Beers,Erik-Jan van Kampen,Coen C. de Visser*

Main category: eess.SY

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: We present a framework to \emph{certify} Hamilton--Jacobi (HJ) reachability learned by reinforcement learning (RL). Building on a discounted initial time \emph{travel-cost} formulation that makes small-step RL value iteration provably equivalent to a forward Hamilton--Jacobi (HJ) equation with damping, we convert certified learning errors into calibrated inner/outer enclosures of strict backward reachable tube. The core device is an additive-offset identity: if $W_λ$ solves the discounted travel-cost Hamilton--Jacobi--Bellman (HJB) equation, then $W_\varepsilon:=W_λ+ \varepsilon$ solves the same PDE with a constant offset $λ\varepsilon$. This means that a uniform value error is \emph{exactly} equal to a constant HJB offset. We establish this uniform value error via two routes: (A) a Bellman operator-residual bound, and (B) a HJB PDE-slack bound. Our framework preserves HJ-level safety semantics and is compatible with deep RL. We demonstrate the approach on a double-integrator system by formally certifying, via satisfiability modulo theories (SMT), a value function learned through reinforcement learning to induce provably correct inner and outer backward-reachable set enclosures over a compact region of interest.

</details>


### [189] [Optimal Placement and Sizing of PV-Based DG Units in a Distribution Network Considering Loading Capacity](https://arxiv.org/abs/2602.16565)
*Abhinav Sharma,Pratyush Chakraborty,Manoj Datta,Kazi N. Hasan*

Main category: eess.SY

TL;DR: 提出了一种两阶段方法，用于在考虑网络负载能力的情况下，在径向分布网络（RDN）中高效分配多个光伏（PV）分布式发电（DG）单元，以最小化电压偏差和减少有功功率损耗。


<details>
  <summary>Details</summary>
Motivation: 为了在保证网络负载能力的同时，提高配电网的电压稳定性和减少能量损耗，需要一种有效的方法来优化光伏 DG 单元的配置。

Method: 采用两阶段方法。第一阶段，通过迭代法确定网络的额外有功功率负载能力及各母线的载荷极限，识别出适合安装 DG 单元的候选节点。第二阶段，利用蒙特卡洛方法，以最小化电压偏差和有功功率损耗为目标，确定 DG 单元的最优位置和容量。

Result: 在 IEEE 33 母线 RDN 上验证了该方法。结果表明，配置一个、两个和三个 DG 单元可分别减少 50.37%、58.62% 和 65.16% 的网络有功功率损耗，并显著改善了所有母线的电压剖面。与现有研究相比，该方法允许更大的 DG 容量，并保持更好的电压剖面。

Conclusion: 所提出的两阶段方法能够有效地在径向分布网络中分配多个光伏 DG 单元，在考虑网络负载能力的同时，显著降低有功功率损耗并改善电压剖面，且优于现有方法。

Abstract: This research paper proposes an efficient methodology for the allocation of multiple photovoltaic (PV)-based distributed generation (DG) units in the radial distribution network (RDN), while considering the loading capacity of the network. The proposed method is structured using a two-stage approach. In the first stage, the additional active power loading capacity of the network and each individual bus is determined using an iterative approach. This analysis quantifies the network's additional active loadability limits and identifies buses with high active power loading capacity, which are considered candidate nodes for the placement of DG units. Subsequently, in the second stage, the optimal locations and sizes of DG units are determined using the Monte Carlo method, with the objectives of minimizing voltage deviation and reducing active power losses in the network. The methodology is validated on the standard IEEE 33-bus RDN to determine the optimal locations and sizes of DG units. The results demonstrate that the optimal allocation of one, two, and three DG units, achieved from proposed method, reduces network active power losses by 50.37%, 58.62%, and 65.16%, respectively, and also significantly enhances the voltage profile across all buses. When the obtained results are compared with the results of several existing studies, it is found that the proposed method allows for larger DG capacities and maintains better voltage profiles throughout the RDN.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [190] [Foundation Models for Medical Imaging: Status, Challenges, and Directions](https://arxiv.org/abs/2602.15913)
*Chuang Niu,Pengwei Wu,Bruno De Man,Ge Wang*

Main category: eess.IV

TL;DR: 本文综述了医学影像领域基础模型（FMs）的出现，涵盖了其设计原则、应用以及未来的挑战与机遇，旨在为开发可靠且可临床转化的FMs提供路线图。


<details>
  <summary>Details</summary>
Motivation: 作者认为基础模型（FMs）正在重塑医学影像领域，从任务特定模型转向通用模型，因此需要对这一新兴领域进行系统性梳理和展望。

Method: 本文采用综述（review）的方式，从FM设计原则、应用、以及挑战与机遇这三个主要方面，对医学影像FMs的现有研究进行了整合。

Result: 文章梳理了医学影像FMs的设计原则，展示了其在不同模态、解剖结构和临床任务中的广泛应用，并提出了未来发展面临的挑战和机遇。

Conclusion: 该综述为医学影像FMs的开发提供了技术上可靠、临床上可行且面向未来的路线图，强调了开发强大、通用、值得信赖且可负责任地转化为临床实践的FMs的重要性。

Abstract: Foundation models (FMs) are rapidly reshaping medical imaging, shifting the field from narrowly trained, task-specific networks toward large, general-purpose models that can be adapted across modalities, anatomies, and clinical tasks. In this review, we synthesize the emerging landscape of medical imaging FMs along three major axes: principles of FM design, applications of FMs, and forward-looking challenges and opportunities. Taken together, this review provides a technically grounded, clinically aware, and future-facing roadmap for developing FMs that are not only powerful and versatile but also trustworthy and ready for responsible translation into clinical practice.

</details>


### [191] [Automated Histopathology Report Generation via Pyramidal Feature Extraction and the UNI Foundation Model](https://arxiv.org/abs/2602.16422)
*Ahmet Halici,Ece Tugba Cebeci,Musa Balci,Mustafa Cini,Serkan Sokmen*

Main category: eess.IV

TL;DR: 该研究提出了一种用于从全切片病理图像（WSIs）生成诊断文本的层次化视觉语言模型，结合了预训练的病理基础模型和Transformer解码器，并通过多分辨率金字塔块选择、背景去除、BioGPT分词和基于检索的验证步骤来提高效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 从病理全切片图像（WSIs）生成诊断文本面临巨大的输入规模（gigapixel）和精确的领域特定语言要求等挑战。

Method: 提出一个层次化视觉语言框架，包括：1. 多分辨率金字塔块选择（下采样因子2^3到2^6）并去除背景和伪影。2. 使用UNI Vision Transformer提取块特征。3. 将特征投影到6层Transformer解码器。4. 使用BioGPT进行词元化。5. 引入基于检索的验证步骤，通过Sentence BERT嵌入比较生成报告与参考语料库，若相似度高则替换为检索到的真实报告。

Result: 该方法能够从WSIs生成诊断文本，并通过检索验证步骤提高了报告的可靠性。

Conclusion: 该研究提出了一种有效且可靠的框架，用于从大型病理全切片图像生成诊断文本，克服了现有方法的局限性。

Abstract: Generating diagnostic text from histopathology whole slide images (WSIs) is challenging due to the gigapixel scale of the input and the requirement for precise, domain specific language. We propose a hierarchical vision language framework that combines a frozen pathology foundation model with a Transformer decoder for report generation. To make WSI processing tractable, we perform multi resolution pyramidal patch selection (downsampling factors 2^3 to 2^6) and remove background and artifacts using Laplacian variance and HSV based criteria. Patch features are extracted with the UNI Vision Transformer and projected to a 6 layer Transformer decoder that generates diagnostic text via cross attention. To better represent biomedical terminology, we tokenize the output using BioGPT. Finally, we add a retrieval based verification step that compares generated reports with a reference corpus using Sentence BERT embeddings; if a high similarity match is found, the generated report is replaced with the retrieved ground truth reference to improve reliability.

</details>


### [192] [Automated Assessment of Kidney Ureteroscopy Exploration for Training](https://arxiv.org/abs/2602.15988)
*Fangjie Li,Nicholas Kavoussi,Charan Mohan,Matthieu Chabanas,Jie Ying Wu*

Main category: eess.IV

TL;DR: 开发了一个基于纯视频的输尿管镜视频定位系统，可用于肾脏探查训练，自动识别训练者遗漏的肾盏，并提供准确的相机位姿定位。该系统能够实现脱离手术室的独立训练。


<details>
  <summary>Details</summary>
Motivation: 当前的临床泌尿外科腹腔镜训练存在不足，需要专家一对一指导且受限于手术室环境，学习曲线陡峭。因此，需要一个带有自动反馈的假体训练系统来扩大训练机会。

Method: 提出了一种新颖的、纯粹基于输尿管镜视频的镜头定位框架。首先，使用详细的预先探索视频生成参考重建，然后利用该参考重建来定位同一假体肾脏的任何探索视频，自动识别训练者遗漏的肾盏。

Result: 在15个探索视频中，共正确分类了69个肾盏（总计74个）。相机位姿定位误差小于4毫米。在有了参考重建后，系统处理一个典型的探索视频（1-2分钟长）大约需要10分钟。

Conclusion: 该研究展示了一个新颖的相机定位框架，能够为肾脏假体探查提供准确的自动反馈，并证明其作为一种有效的工具，可以在没有专家监督的情况下进行手术室外的训练。

Abstract: Purpose: Kidney ureteroscopic navigation is challenging with a steep learning curve. However, current clinical training has major deficiencies, as it requires one-on-one feedback from experts and occurs in the operating room (OR). Therefore, there is a need for a phantom training system with automated feedback to greatly \revision{expand} training opportunities.
  Methods: We propose a novel, purely ureteroscope video-based scope localization framework that automatically identifies calyces missed by the trainee in a phantom kidney exploration. We use a slow, thorough, prior exploration video of the kidney to generate a reference reconstruction. Then, this reference reconstruction can be used to localize any exploration video of the same phantom.
  Results: In 15 exploration videos, a total of 69 out of 74 calyces were correctly classified. We achieve < 4mm camera pose localization error. Given the reference reconstruction, the system takes 10 minutes to generate the results for a typical exploration (1-2 minute long).
  Conclusion: We demonstrate a novel camera localization framework that can provide accurate and automatic feedback for kidney phantom explorations. We show its ability as a valid tool that enables out-of-OR training without requiring supervision from an expert.

</details>


### [193] [RefineFormer3D: Efficient 3D Medical Image Segmentation via Adaptive Multi-Scale Transformer with Cross Attention Fusion](https://arxiv.org/abs/2602.16320)
*Kavyansh Tyagi,Vishwas Rathi,Puneet Goyal*

Main category: eess.IV

TL;DR: 提出了一种轻量级的3D医学图像分割Transformer模型RefineFormer3D，该模型通过高效的模块设计（GhostConv3D、MixFFN3D、跨注意力融合解码器）在保持高精度的同时，显著减少了参数量和计算复杂度，适用于资源受限的临床环境。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer模型在3D医学图像分割中虽然能捕捉全局上下文信息，但参数量和内存需求过高，限制了其在临床中的应用。研究旨在开发一个既能保证分割精度又兼顾计算效率的轻量级Transformer模型。

Method: 提出了一种名为RefineFormer3D的轻量级分层Transformer架构。该架构包含三个核心组件：1) 基于GhostConv3D的Patch Embedding，用于高效提取特征并减少冗余；2) MixFFN3D模块，利用低秩投影和深度卷积实现参数高效的特征提取；3) 跨注意力融合解码器，用于自适应地整合多尺度跳跃连接。模型参数量仅为2.94M。

Result: 在ACDC和BraTS数据集上的实验结果显示，RefineFormer3D分别取得了93.44%和85.9%的平均Dice分数。与现有最先进的方法相比，该模型在参数量显著减少的情况下，分割精度不相上下甚至更高。此外，模型推理速度快（GPU上每体积8.35毫秒），内存占用低。

Conclusion: RefineFormer3D是一种有效且可扩展的3D医学图像分割解决方案，它通过轻量级设计实现了高精度、低参数量和高效推理的平衡，能够满足资源受限的临床部署需求。

Abstract: Accurate and computationally efficient 3D medical image segmentation remains a critical challenge in clinical workflows. Transformer-based architectures often demonstrate superior global contextual modeling but at the expense of excessive parameter counts and memory demands, restricting their clinical deployment. We propose RefineFormer3D, a lightweight hierarchical transformer architecture that balances segmentation accuracy and computational efficiency for volumetric medical imaging. The architecture integrates three key components: (i) GhostConv3D-based patch embedding for efficient feature extraction with minimal redundancy, (ii) MixFFN3D module with low-rank projections and depthwise convolutions for parameter-efficient feature extraction, and (iii) a cross-attention fusion decoder enabling adaptive multi-scale skip connection integration. RefineFormer3D contains only 2.94M parameters, substantially fewer than contemporary transformer-based methods. Extensive experiments on ACDC and BraTS benchmarks demonstrate that RefineFormer3D achieves 93.44\% and 85.9\% average Dice scores respectively, outperforming or matching state-of-the-art methods while requiring significantly fewer parameters. Furthermore, the model achieves fast inference (8.35 ms per volume on GPU) with low memory requirements, supporting deployment in resource-constrained clinical environments. These results establish RefineFormer3D as an effective and scalable solution for practical 3D medical image segmentation.

</details>


### [194] [ROIX-Comp: Optimizing X-ray Computed Tomography Imaging Strategy for Data Reduction and Reconstruction](https://arxiv.org/abs/2602.15917)
*Amarjit Singh,Kento Sato,Kohei Yoshida,Kentaro Uesugi,Yasumasa Joti,Takaki Hatsui,Andrès Rubio Proaño*

Main category: eess.IV

TL;DR: 提出了一种名为ROIX-Comp的区域感兴趣（ROI）驱动的数据提取和压缩框架，用于处理高维、大数据量的X射线CT（X-CT）数据集。该框架通过错误有界量化和对象提取与先进的压缩器相结合，显著减小了数据量，同时保留了关键信息，与标准压缩相比，压缩比提高了12.34倍。


<details>
  <summary>Details</summary>
Motivation: 高亮度同步辐射设施中产生的大量X-CT数据在计算和存储方面带来了挑战，传统的处理方法需要巨大的存储空间和高传输带宽，限制了实时处理和工作流程效率。

Method: 提出ROIX-Comp框架，包含两个主要阶段：1. 预处理阶段：利用错误有界量化（error-bounded quantization）减少数据量，提高计算效率。2. 压缩阶段：结合对象提取（object extraction）技术与多种先进的有损和无损压缩器，以实现高压缩比。

Result: 在七个X-CT数据集上的评估显示，ROIX-Comp框架相较于标准压缩方法，相对压缩比提高了12.34倍。

Conclusion: ROIX-Comp框架能够有效地减少X-CT数据量，同时保留下游处理任务所需的核心信息，为解决大规模X-CT数据处理的挑战提供了一种高效的解决方案。

Abstract: In high-performance computing (HPC) environments, particularly in synchrotron radiation facilities, vast amounts of X-ray images are generated. Processing large-scale X-ray Computed Tomography (X-CT) datasets presents significant computational and storage challenges due to their high dimensionality and data volume. Traditional approaches often require extensive storage capacity and high transmission bandwidth, limiting real-time processing capabilities and workflow efficiency. To address these constraints, we introduce a region-of-interest (ROI)-driven extraction framework (ROIX-Comp) that intelligently compresses X-CT data by identifying and retaining only essential features. Our work reduces data volume while preserving critical information for downstream processing tasks. At pre-processing stage, we utilize error-bounded quantization to reduce the amount of data to be processed and therefore improve computational efficiencies. At the compression stage, our methodology combines object extraction with multiple state-of-the-art lossless and lossy compressors, resulting in significantly improved compression ratios. We evaluated this framework against seven X-CT datasets and observed a relative compression ratio improvement of 12.34x compared to the standard compression.

</details>
