<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 18]
- [cs.CV](#cs.CV) [Total: 53]
- [cs.CL](#cs.CL) [Total: 93]
- [cs.RO](#cs.RO) [Total: 17]
- [eess.SY](#eess.SY) [Total: 12]
- [eess.IV](#eess.IV) [Total: 7]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management](https://arxiv.org/abs/2509.04505)
*Somtochukwu Azie,Yiping Meng*

Main category: cs.AI

TL;DR: 本研究评估了大型语言模型（LLMs）在建筑项目管理（CPM）中处理伦理敏感决策时的伦理可行性和可靠性。结果显示，LLMs在结构化领域表现尚可，但在处理情境细微差别、问责和透明推理方面存在显著不足，强调需加强人工监督。


<details>
  <summary>Details</summary>
Motivation: 人工智能（AI）及其中的大型语言模型（LLMs）正加速融入建筑项目管理（CPM）作为决策支持工具。本研究旨在批判性评估LLMs在CPM中固有的伦理敏感、高风险决策情境中的伦理可行性和可靠性。

Method: 采用混合方法研究设计：
1. 定量分析：使用新颖的“伦理决策支持评估清单（EDSAC）”，针对12个真实世界的伦理情景，对两个领先的LLMs进行性能测试。
2. 定性分析：对12位行业专家进行半结构化访谈，以获取专业看法。

Result: 1. LLMs在法律合规等结构化领域表现尚可。
2. LLMs在处理情境细微差别、确保问责制和提供透明推理方面存在显著缺陷。
3. 利益相关者对AI自主进行伦理判断表示担忧，强烈主张实施强大的人工监督（human-in-the-loop）。

Conclusion: LLMs目前最适合作为决策支持辅助工具，而非自主的伦理代理。本研究引入了EDSAC框架作为可复制的方法论，并提供了可操作的建议。这是首批在建筑领域实证测试LLMs伦理推理的研究之一。

Abstract: The integration of Artificial Intelligence (AI) into construction project
management (CPM) is accelerating, with Large Language Models (LLMs) emerging as
accessible decision-support tools. This study aims to critically evaluate the
ethical viability and reliability of LLMs when applied to the ethically
sensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods
research design was employed, involving the quantitative performance testing of
two leading LLMs against twelve real-world ethical scenarios using a novel
Ethical Decision Support Assessment Checklist (EDSAC), and qualitative analysis
of semi-structured interviews with 12 industry experts to capture professional
perceptions. The findings reveal that while LLMs demonstrate adequate
performance in structured domains such as legal compliance, they exhibit
significant deficiencies in handling contextual nuance, ensuring
accountability, and providing transparent reasoning. Stakeholders expressed
considerable reservations regarding the autonomous use of AI for ethical
judgments, strongly advocating for robust human-in-the-loop oversight. To our
knowledge, this is one of the first studies to empirically test the ethical
reasoning of LLMs within the construction domain. It introduces the EDSAC
framework as a replicable methodology and provides actionable recommendations,
emphasising that LLMs are currently best positioned as decision-support aids
rather than autonomous ethical agents.

</details>


### [2] [Maestro: Joint Graph & Config Optimization for Reliable AI Agents](https://arxiv.org/abs/2509.04642)
*Wenxiao Wang,Priyatham Kattakinda,Soheil Feizi*

Main category: cs.AI

TL;DR: Maestro是一个LLM代理的整体优化器，它通过联合搜索代理的图结构和节点配置来最大化代理质量，解决了现有优化器无法处理的结构性故障模式，并在多个基准测试中显著超越了领先的提示优化器。


<details>
  <summary>Details</summary>
Motivation: 构建可靠的LLM代理需要在图结构和节点配置两个层面进行决策。现有优化器通常只调整配置，而忽略了图结构，导致无法解决结构性故障模式。这促使研究人员开发一个能同时优化这两个层面的框架。

Method: Maestro是一个与框架无关的整体优化器，它在明确的运行/token预算下，联合搜索LLM代理的图结构（模块及其信息流）和每个节点的配置（模型、提示、工具、控制旋钮）。此外，Maestro利用来自追踪的反射性文本反馈来优先处理编辑，从而提高样本效率并针对特定的故障模式。

Result: 在IFBench和HotpotQA基准测试中，Maestro平均分别超越了领先的提示优化器MIPROv2、GEPA和GEPA+Merge 12%、4.9%和4.86%。即使仅限于提示优化，Maestro仍分别领先9.65%、2.37%和2.41%。Maestro在取得这些结果的同时，使用的运行次数远少于GEPA。此外，Maestro在面试官和RAG代理这两个应用中也显示出显著的提升，证明联合图结构和配置搜索能够解决仅凭提示调整无法修复的结构性故障模式。

Conclusion: 联合搜索LLM代理的图结构和配置对于构建可靠的LLM代理至关重要，它能够有效解决仅通过提示调整无法解决的结构性故障模式。Maestro框架通过这种整体优化方法，显著提升了LLM代理的性能和效率。

Abstract: Building reliable LLM agents requires decisions at two levels: the graph
(which modules exist and how information flows) and the configuration of each
node (models, prompts, tools, control knobs). Most existing optimizers tune
configurations while holding the graph fixed, leaving structural failure modes
unaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for
LLM agents that jointly searches over graphs and configurations to maximize
agent quality, subject to explicit rollout/token budgets. Beyond numeric
metrics, Maestro leverages reflective textual feedback from traces to
prioritize edits, improving sample efficiency and targeting specific failure
modes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses
leading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%,
4.9%, and 4.86%, respectively; even when restricted to prompt-only
optimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these
results with far fewer rollouts than GEPA. We further show large gains on two
applications (interviewer & RAG agents), highlighting that joint graph &
configuration search addresses structural failure modes that prompt tuning
alone cannot fix.

</details>


### [3] [Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization](https://arxiv.org/abs/2509.04646)
*Philippe J. Giabbanelli,Ameeta Agrawal*

Main category: cs.AI

TL;DR: 该研究提出了一种分步框架，通过识别不同健康利益相关者的解释需求和风格偏好，并指导大型语言模型（LLMs）生成定制化的健康模拟解释，以提高模拟模型的可及性。


<details>
  <summary>Details</summary>
Motivation: 健康领域的建模与仿真（M&S）方法（如基于代理的模型）在支持决策方面潜力巨大，但其复杂性使得这些模型对关键利益相关者（如临床医生、政策制定者、患者等）而言难以理解和利用。虽然LLMs可以转换模拟输出，但现有方法通常提供“一刀切”的摘要，未能满足不同利益相关者多样化的信息需求和风格偏好。

Method: 该研究提出一个分步框架，采用混合方法设计：首先，通过启发式方法获取不同健康利益相关者的解释需求和风格偏好；其次，优化LLMs生成定制化输出的能力（例如，通过可控属性调整）；最后，通过一系列综合指标评估并进一步改进定制化摘要的生成。

Result: 该研究的主要成果是提出了一个系统的分步框架，用于识别健康领域利益相关者的解释需求，并指导LLMs生成针对性的、定制化的健康模拟解释，以克服模型复杂性和现有LLM摘要普适性的局限性。

Conclusion: 该框架旨在弥合复杂健康模拟与利益相关者理解之间的鸿沟，通过LLMs生成定制化解释，使健康模拟模型更易于访问和利用，从而充分发挥其在支持健康决策中的潜力。

Abstract: Modeling & Simulation (M&S) approaches such as agent-based models hold
significant potential to support decision-making activities in health, with
recent examples including the adoption of vaccines, and a vast literature on
healthy eating behaviors and physical activity behaviors. These models are
potentially usable by different stakeholder groups, as they support
policy-makers to estimate the consequences of potential interventions and they
can guide individuals in making healthy choices in complex environments.
However, this potential may not be fully realized because of the models'
complexity, which makes them inaccessible to the stakeholders who could benefit
the most. While Large Language Models (LLMs) can translate simulation outputs
and the design of models into text, current approaches typically rely on
one-size-fits-all summaries that fail to reflect the varied informational needs
and stylistic preferences of clinicians, policymakers, patients, caregivers,
and health advocates. This limitation stems from a fundamental gap: we lack a
systematic understanding of what these stakeholders need from explanations and
how to tailor them accordingly. To address this gap, we present a step-by-step
framework to identify stakeholder needs and guide LLMs in generating tailored
explanations of health simulations. Our procedure uses a mixed-methods design
by first eliciting the explanation needs and stylistic preferences of diverse
health stakeholders, then optimizing the ability of LLMs to generate tailored
outputs (e.g., via controllable attribute tuning), and then evaluating through
a comprehensive range of metrics to further improve the tailored generation of
summaries.

</details>


### [4] [An Approach to Grounding AI Model Evaluations in Human-derived Criteria](https://arxiv.org/abs/2509.04676)
*Sasha Mitts*

Main category: cs.AI

TL;DR: 该研究提出了一种以人为中心的评估框架，通过整合人类认知的关键技能来增强现有AI基准测试，旨在更准确地衡量AI模型的细微能力，尤其是在物理世界建模方面。


<details>
  <summary>Details</summary>
Motivation: 传统AI基准测试难以捕捉AI模型的细微能力，尤其是在物理世界建模方面，导致模型行为的解释性和适用性不足。

Method: 研究以Perception Test和OpenEQA基准为基础，通过深度访谈和大规模调查识别出优先级、记忆、辨别和情境化等关键认知技能。这些技能被整合到基准设计中，以开发更符合人类的评估方法。

Result: 研究发现，参与者认为AI在解释性和同理心技能方面存在不足，但对其性能抱有很高期望。通过将这些发现整合到基准设计中，研究提供了一个开发更符合人类的AI进展定义和衡量方法的框架。

Conclusion: 该工作强调了在AI开发中以用户为中心评估的重要性，为研究人员和实践者提供了可操作的指导，以使AI能力与人类认知过程对齐。这种方法既增强了当前的基准测试实践，也为AI模型评估的未来发展奠定了基础。

Abstract: In the rapidly evolving field of artificial intelligence (AI), traditional
benchmarks can fall short in attempting to capture the nuanced capabilities of
AI models. We focus on the case of physical world modeling and propose a novel
approach to augment existing benchmarks with human-derived evaluation criteria,
aiming to enhance the interpretability and applicability of model behaviors.
Grounding our study in the Perception Test and OpenEQA benchmarks, we conducted
in-depth interviews and large-scale surveys to identify key cognitive skills,
such as Prioritization, Memorizing, Discerning, and Contextualizing, that are
critical for both AI and human reasoning. Our findings reveal that participants
perceive AI as lacking in interpretive and empathetic skills yet hold high
expectations for AI performance. By integrating insights from our findings into
benchmark design, we offer a framework for developing more human-aligned means
of defining and measuring progress. This work underscores the importance of
user-centered evaluation in AI development, providing actionable guidelines for
researchers and practitioners aiming to align AI capabilities with human
cognitive processes. Our approach both enhances current benchmarking practices
and sets the stage for future advancements in AI model evaluation.

</details>


### [5] [Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning](https://arxiv.org/abs/2509.04731)
*Brennen Hill*

Main category: cs.AI

TL;DR: 该论文提出，为解决复杂多智能体任务中强化学习的局限性，应构建显式、分层且由语言模型动态生成的“世界模型”，以提供内在课程和密集学习信号，从而提高智能体的学习效率和策略能力。


<details>
  <summary>Details</summary>
Motivation: 语言模型、智能体模型和世界模型的融合是AI前沿，但复杂、长周期多智能体任务中，显式世界模型的开发仍是瓶颈。标准强化学习在结构扁平的模拟器中常因探索空间巨大和奖励稀疏而失败，例如在机器人足球等领域。

Method: 论文主张通过分层脚手架（将复杂目标分解为可管理的子目标）来创建具有显式、分层世界模型的环境。通过对2024年多智能体足球研究的系统综述，发现整合符号和分层方法与多智能体强化学习（MARL）的趋势。在此基础上，论文提出利用大型语言模型（LLM）动态生成这种分层脚手架，从而构建一个语言驱动的世界模型。

Result: 通过语言驱动的世界模型，可以提供内在课程、密集而有意义的学习信号，并支持组合学习，使智能体模型能够以更高的样本效率习得复杂的战略行为。这将弥合低级反应行为与高级战略团队协作之间的差距。

Conclusion: 通过构建具有显式、语言可配置任务层的环境，可以为训练下一代智能体提供一个强大且可泛化的框架，从而实现更复杂、更高效的学习和战略行为。

Abstract: The convergence of Language models, Agent models, and World models represents
a critical frontier for artificial intelligence. While recent progress has
focused on scaling Language and Agent models, the development of sophisticated,
explicit World Models remains a key bottleneck, particularly for complex,
long-horizon multi-agent tasks. In domains such as robotic soccer, agents
trained via standard reinforcement learning in high-fidelity but
structurally-flat simulators often fail due to intractable exploration spaces
and sparse rewards. This position paper argues that the next frontier in
developing capable agents lies in creating environments that possess an
explicit, hierarchical World Model. We contend that this is best achieved
through hierarchical scaffolding, where complex goals are decomposed into
structured, manageable subgoals. Drawing evidence from a systematic review of
2024 research in multi-agent soccer, we identify a clear and decisive trend
towards integrating symbolic and hierarchical methods with multi-agent
reinforcement learning (MARL). These approaches implicitly or explicitly
construct a task-based world model to guide agent learning. We then propose a
paradigm shift: leveraging Large Language Models to dynamically generate this
hierarchical scaffold, effectively using language to structure the World Model
on the fly. This language-driven world model provides an intrinsic curriculum,
dense and meaningful learning signals, and a framework for compositional
learning, enabling Agent Models to acquire sophisticated, strategic behaviors
with far greater sample efficiency. By building environments with explicit,
language-configurable task layers, we can bridge the gap between low-level
reactive behaviors and high-level strategic team play, creating a powerful and
generalizable framework for training the next generation of intelligent agents.

</details>


### [6] [What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking](https://arxiv.org/abs/2509.04791)
*Yuan Sui,Yanming Zhang,Yi Liao,Yu Gu,Guohua Tang,Zhongqian Sun,Wei Yang,Bryan Hooi*

Main category: cs.AI

TL;DR: WiA-LLM是一种新的范式，通过整合情景假设分析（WIA）和强化学习，赋予大型语言模型（LLMs）主动思考能力，使其能够在动态环境中预测行动后果，并在《王者荣耀》中实现显著的未来状态预测准确率提升。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型擅长被动信息处理，但缺乏系统性探索假设未来的能力，无法在行动前预测潜在后果。这一关键缺陷限制了它们在战略规划、风险评估和实时决策等高风险场景中的应用。

Method: 本文提出了WiA-LLM，通过整合情景假设分析（WIA）和利用强化学习的环境反馈，使LLMs能够主动思考。WiA-LLM动态模拟每个潜在行动的结果，从而预测未来状态，而非仅仅对当前条件作出反应。

Result: 在复杂的多人游戏环境《王者荣耀》中，WiA-LLM在预测游戏状态变化方面达到了74.2%的准确率（比基线模型提高了两倍），尤其在高难度场景中表现出显著优势。这是首次将情景假设分析能力正式整合到LLMs中的工作。

Conclusion: WiA-LLM代表了LLMs在主动推理方面的一个根本性进展，为动态环境中的稳健决策提供了一个可扩展的框架，对战略应用具有广泛的意义。

Abstract: Large language models (LLMs) excel at processing information reactively but
lack the ability to systemically explore hypothetical futures. They cannot ask,
"what if we take this action? how will it affect the final outcome" and
forecast its potential consequences before acting. This critical gap limits
their utility in dynamic, high-stakes scenarios like strategic planning, risk
assessment, and real-time decision making. To bridge this gap, we propose
WiA-LLM, a new paradigm that equips LLMs with proactive thinking capabilities.
Our approach integrates What-If Analysis (WIA), a systematic approach for
evaluating hypothetical scenarios by changing input variables. By leveraging
environmental feedback via reinforcement learning, WiA-LLM moves beyond
reactive thinking. It dynamically simulates the outcomes of each potential
action, enabling the model to anticipate future states rather than merely react
to the present conditions. We validate WiA-LLM in Honor of Kings (HoK), a
complex multiplayer game environment characterized by rapid state changes and
intricate interactions. The game's real-time state changes require precise
multi-step consequence prediction, making it an ideal testbed for our approach.
Experimental results demonstrate WiA-LLM achieves a remarkable 74.2% accuracy
in forecasting game-state changes (up to two times gain over baselines). The
model shows particularly significant gains in high-difficulty scenarios where
accurate foresight is critical. To our knowledge, this is the first work to
formally explore and integrate what-if analysis capabilities within LLMs.
WiA-LLM represents a fundamental advance toward proactive reasoning in LLMs,
providing a scalable framework for robust decision-making in dynamic
environments with broad implications for strategic applications.

</details>


### [7] [TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models](https://arxiv.org/abs/2509.04809)
*Haechang Kim,Hao Chen,Can Li,Jong Min Lee*

Main category: cs.AI

TL;DR: 本文提出了TalkToAgent，一个基于多智能体大型语言模型（LLM）的框架，旨在为强化学习（RL）策略提供交互式、自然语言的解释，以弥合复杂RL策略与领域专家之间的理解鸿沟。


<details>
  <summary>Details</summary>
Motivation: 现有可解释强化学习（XRL）结果的可理解性有限，且XRL方法覆盖范围孤立，导致用户不确定如何选择工具，从而在复杂RL策略与领域专家之间存在理解障碍。

Method: 引入了TalkToAgent，一个包含五个专门LLM智能体（协调器、解释器、编码器、评估器和调试器）的多智能体LLM框架。该框架能自动将用户查询映射到相关的XRL工具，并以关键状态变量、预期结果或反事实解释的形式阐明智能体的行为。此外，它通过从定性行为描述或新规则策略中推导替代场景，扩展了现有的反事实解释。

Result: 在四罐过程控制问题上进行了验证。结果表明，TalkToAgent能够高精度地将用户查询映射到XRL任务，并且编码器-调试器交互最大限度地减少了反事实生成中的失败。定性评估也证实TalkToAgent能有效解释智能体的行为，并将其含义置于问题域中。

Conclusion: TalkToAgent通过提供交互式、自然语言的解释，有效提高了RL策略的透明度和可理解性，并解决了现有XRL方法在工具选择和反事实生成方面的局限性，从而有效地弥合了复杂RL与领域专家之间的理解差距。

Abstract: Explainable Reinforcement Learning (XRL) has emerged as a promising approach
in improving the transparency of Reinforcement Learning (RL) agents. However,
there remains a gap between complex RL policies and domain experts, due to the
limited comprehensibility of XRL results and isolated coverage of current XRL
approaches that leave users uncertain about which tools to employ. To address
these challenges, we introduce TalkToAgent, a multi-agent Large Language Models
(LLM) framework that delivers interactive, natural language explanations for RL
policies. The architecture with five specialized LLM agents (Coordinator,
Explainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically
map user queries to relevant XRL tools and clarify an agent's actions in terms
of either key state variables, expected outcomes, or counterfactual
explanations. Moreover, our approach extends previous counterfactual
explanations by deriving alternative scenarios from qualitative behavioral
descriptions, or even new rule-based policies. We validated TalkToAgent on
quadruple-tank process control problem, a well-known nonlinear control
benchmark. Results demonstrated that TalkToAgent successfully mapped user
queries into XRL tasks with high accuracy, and coder-debugger interactions
minimized failures in counterfactual generation. Furthermore, qualitative
evaluation confirmed that TalkToAgent effectively interpreted agent's actions
and contextualized their meaning within the problem domain.

</details>


### [8] [Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory](https://arxiv.org/abs/2509.04847)
*Mukul Singh,Arjun Radhakrishna,Sumit Gulwani*

Main category: cs.AI

TL;DR: 本研究在迭代囚徒困境中系统性地评估了语言模型的长期合作行为，发现它们表现出高水平的合作性、适应性，并能与经典策略相媲美甚至超越。


<details>
  <summary>Details</summary>
Motivation: 语言模型在交互式在线环境中日益普及，但其在多方设置中的合作与竞争行为，尤其是在长期互动、人机协作以及行为模式随时间演变方面的研究不足。

Method: 研究采用迭代囚徒困境（IPD）框架，让语言模型代理与240种经典策略进行Axelrod式锦标赛。同时，通过受控的“策略切换”实验，评估语言模型对对手策略变化的适应性。

Result: 语言模型表现出与最佳经典策略相当甚至超越的性能。行为分析表明，它们具备强合作策略的关键特性：友善、可激怒性、慷慨，并能快速适应对手策略的变化，在几轮内检测并响应策略转变，媲美甚至超越人类的适应性。

Conclusion: 本研究首次系统性地刻画了语言模型代理的长期合作行为，为未来研究其在更复杂、人机混合的社会环境中的作用奠定了基础。

Abstract: Language models are increasingly deployed in interactive online environments,
from personal chat assistants to domain-specific agents, raising questions
about their cooperative and competitive behavior in multi-party settings. While
prior work has examined language model decision-making in isolated or
short-term game-theoretic contexts, these studies often neglect long-horizon
interactions, human-model collaboration, and the evolution of behavioral
patterns over time. In this paper, we investigate the dynamics of language
model behavior in the iterated prisoner's dilemma (IPD), a classical framework
for studying cooperation and conflict. We pit model-based agents against a
suite of 240 well-established classical strategies in an Axelrod-style
tournament and find that language models achieve performance on par with, and
in some cases exceeding, the best-known classical strategies. Behavioral
analysis reveals that language models exhibit key properties associated with
strong cooperative strategies - niceness, provocability, and generosity while
also demonstrating rapid adaptability to changes in opponent strategy mid-game.
In controlled "strategy switch" experiments, language models detect and respond
to shifts within only a few rounds, rivaling or surpassing human adaptability.
These results provide the first systematic characterization of long-term
cooperative behaviors in language model agents, offering a foundation for
future research into their role in more complex, mixed human-AI social
environments.

</details>


### [9] [Cloning a Conversational Voice AI Agent from Call\,Recording Datasets for Telesales](https://arxiv.org/abs/2509.04871)
*Krittanon Kaewtawee,Wachiravit Modecrua,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: 本文提出了一种从通话录音语料库中克隆对话式语音AI代理的通用方法，该代理能够听取客户、用合成语音回应并遵循人类优秀代理的学习剧本，并在常规任务中接近人类表现，但在说服和异议处理方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 语言和语音建模的最新进展使得构建自主语音助手成为可能，这些系统能够实时理解和生成人类对话，并被部署在客户服务和医疗保健等领域，以自动化重复任务、降低运营成本并提供全天候支持。

Method: 研究人员开发了一种通用方法，通过整合自动语音识别（ASR）、基于大型语言模型（LLM）的对话管理器和文本到语音（TTS）合成，构建了一个流式推理管道。该系统从通话录音中学习结构化剧本，并使用领域选择、知识提取和提示工程来构建代理。通过22项标准（包括介绍、产品沟通、销售推动、异议处理和结束语）对克隆代理进行盲测评估。

Result: 盲测结果显示，AI代理在通话的常规方面接近人类表现，但在说服和异议处理方面表现不佳。研究人员对这些不足进行了分析并相应地优化了提示。

Conclusion: 论文总结了设计经验和未来研究方向，包括大规模模拟和自动化评估。尽管AI代理在说服和异议处理方面仍有提升空间，但在常规任务中已能接近人类表现。

Abstract: Recent advances in language and speech modelling have made it possible to
build autonomous voice assistants that understand and generate human dialogue
in real time. These systems are increasingly being deployed in domains such as
customer service and healthcare care, where they can automate repetitive tasks,
reduce operational costs, and provide constant support around the clock. In
this paper, we present a general methodology for cloning a conversational voice
AI agent from a corpus of call recordings. Although the case study described in
this paper uses telesales data to illustrate the approach, the underlying
process generalizes to any domain where call transcripts are available. Our
system listens to customers over the telephone, responds with a synthetic
voice, and follows a structured playbook learned from top performing human
agents. We describe the domain selection, knowledge extraction, and prompt
engineering used to construct the agent, integrating automatic speech
recognition, a large language model based dialogue manager, and text to speech
synthesis into a streaming inference pipeline. The cloned agent is evaluated
against human agents on a rubric of 22 criteria covering introduction, product
communication, sales drive, objection handling, and closing. Blind tests show
that the AI agent approaches human performance in routine aspects of the call
while underperforming in persuasion and objection handling. We analyze these
shortcomings and refine the prompt accordingly. The paper concludes with design
lessons and avenues for future research, including large scale simulation and
automated evaluation.

</details>


### [10] [OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in Multi-Agent LLM Collaboration](https://arxiv.org/abs/2509.04876)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Xiaofei Sun,Keze Wang*

Main category: cs.AI

TL;DR: OSC (Orchestrating Cognitive Synergy) 是一个知识感知的自适应协作框架，旨在通过引入协作知识模型（CKM）和实时认知差距分析，增强多智能体系统中大型语言模型之间的深度协作，从而优化沟通效率和任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作在智能体选择和结果聚合方面有所进展，但专家智能体之间高效的语言交互以实现深度协作仍然是关键瓶颈。OSC 旨在解决在智能体选择和聚合之间缺乏有效中间层的问题。

Method: OSC 作为一个关键的中间层，引入了协作知识模型（CKM），使每个智能体能够动态感知其协作者的认知状态。通过实时认知差距分析，智能体利用学习到的策略自适应地调整沟通行为，包括内容焦点、细节水平和表达风格。

Result: 在复杂的推理和问题解决基准测试中，OSC 显著提高了任务性能和沟通效率，将“并行工作的个体”转变为“深度协作的认知团队”。

Conclusion: 该框架不仅优化了多智能体协作，还为大型语言模型智能体之间的交互行为提供了新的见解。

Abstract: This paper introduces OSC (Orchestrating Cognitive Synergy), a
knowledge-aware adaptive collaboration framework designed to enhance cognitive
synergy in multi-agent systems with large language models. While prior work has
advanced agent selection and result aggregation, efficient linguistic
interactions for deep collaboration among expert agents remain a critical
bottleneck. OSC addresses this gap as a pivotal intermediate layer between
selection and aggregation, introducing Collaborator Knowledge Models (CKM) to
enable each agent to dynamically perceive its collaborators' cognitive states.
Through real-time cognitive gap analysis, agents adaptively adjust
communication behaviors, including content focus, detail level, and expression
style, using learned strategies. Experiments on complex reasoning and
problem-solving benchmarks demonstrate that OSC significantly improves task
performance and communication efficiency, transforming "parallel-working
individuals'' into a "deeply collaborative cognitive team.'' This framework not
only optimizes multi-agent collaboration but also offers new insights into LLM
agent interaction behaviors.

</details>


### [11] [SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and Parsing](https://arxiv.org/abs/2509.04908)
*Hongyi Jing,Jiafu Chen,Chen Rao,Ziqiang Dang,Jiajie Teng,Tianyi Chu,Juncheng Mo,Shuo Fang,Huaizhong Lin,Rui Lv,Chenguang Ma,Lei Zhao*

Main category: cs.AI

TL;DR: SparkUI-Parser是一个用于GUI感知的端到端框架，它通过连续坐标建模和拒绝机制，显著提高了定位精度和全界面解析能力，并引入了新的评估基准ScreenParse。


<details>
  <summary>Details</summary>
Motivation: 现有的GUI多模态大语言模型（MLLMs）面临两大挑战：1) 基于文本自回归机制的离散坐标建模导致定位精度低和推理速度慢；2) 只能定位预定义元素，无法解析整个界面，限制了其广泛应用。

Method: 本文提出了SparkUI-Parser框架。它通过在预训练MLLM上增加一个token路由器和坐标解码器，实现坐标的连续建模，而非概率离散建模，从而提高精度和推理速度。此外，引入了基于改进匈牙利匹配算法的拒绝机制，以识别并拒绝不存在的元素，减少误报。同时，构建了一个新的基准ScreenParse，用于系统评估GUI模型的结构感知能力。

Result: 广泛实验表明，SparkUI-Parser在ScreenSpot、ScreenSpot-v2、CAGUI-Grounding和ScreenParse等基准测试中，持续优于现有SOTA方法。

Conclusion: SparkUI-Parser通过创新的连续坐标建模和鲁棒的拒绝机制，成功实现了更高的定位精度和细粒度的全界面解析能力，有效解决了现有MLLM在GUI感知中的局限性。同时，提出的ScreenParse基准为未来研究提供了系统评估工具。

Abstract: The existing Multimodal Large Language Models (MLLMs) for GUI perception have
made great progress. However, the following challenges still exist in prior
methods: 1) They model discrete coordinates based on text autoregressive
mechanism, which results in lower grounding accuracy and slower inference
speed. 2) They can only locate predefined sets of elements and are not capable
of parsing the entire interface, which hampers the broad application and
support for downstream tasks. To address the above issues, we propose
SparkUI-Parser, a novel end-to-end framework where higher localization
precision and fine-grained parsing capability of the entire interface are
simultaneously achieved. Specifically, instead of using probability-based
discrete modeling, we perform continuous modeling of coordinates based on a
pre-trained Multimodal Large Language Model (MLLM) with an additional token
router and coordinate decoder. This effectively mitigates the limitations
inherent in the discrete output characteristics and the token-by-token
generation process of MLLMs, consequently boosting both the accuracy and the
inference speed. To further enhance robustness, a rejection mechanism based on
a modified Hungarian matching algorithm is introduced, which empowers the model
to identify and reject non-existent elements, thereby reducing false positives.
Moreover, we present ScreenParse, a rigorously constructed benchmark to
systematically assess structural perception capabilities of GUI models across
diverse scenarios. Extensive experiments demonstrate that our approach
consistently outperforms SOTA methods on ScreenSpot, ScreenSpot-v2,
CAGUI-Grounding and ScreenParse benchmarks. The resources are available at
https://github.com/antgroup/SparkUI-Parser.

</details>


### [12] [Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts](https://arxiv.org/abs/2509.04926)
*Barbara Gendron,Gaël Guibon,Mathieu D'aquin*

Main category: cs.AI

TL;DR: 本文提出了一种基于本体论的方法，通过将定性会话特征（如语言熟练度）量化并形式化，以提高大型语言模型（LLM）作为对话代理时的可控性和透明度。


<details>
  <summary>Details</summary>
Motivation: LLM作为对话代理时，其可控性是一个关键挑战，尤其是在确保可预测和用户个性化响应方面。传统的定性会话特征难以有效控制。

Method: 该研究提出了一种基于本体论的方法。首先，利用语言描述符将定性会话特征（如CEFR语言熟练度）转换为定量定义。然后，将这些定义形式化为描述逻辑并整合到本体中，用于推理和一致性检查。最后，通过微调LLM，利用该本体指导受控的文本生成。

Result: 实验结果表明，该方法提供了连贯且可解释的熟练度级别定义，显著提高了会话AI的透明度。

Conclusion: 基于本体论的方法能够有效地将定性会话特征形式化并用于控制LLM的文本生成，从而提高LLM在会话中的可控性、一致性和透明度。

Abstract: The controllability of Large Language Models (LLMs) when used as
conversational agents is a key challenge, particularly to ensure predictable
and user-personalized responses. This work proposes an ontology-based approach
to formally define conversational features that are typically qualitative in
nature. By leveraging a set of linguistic descriptors, we derive quantitative
definitions for qualitatively-defined concepts, enabling their integration into
an ontology for reasoning and consistency checking. We apply this framework to
the task of proficiency-level control in conversations, using CEFR language
proficiency levels as a case study. These definitions are then formalized in
description logic and incorporated into an ontology, which guides controlled
text generation of an LLM through fine-tuning. Experimental results demonstrate
that our approach provides consistent and explainable proficiency-level
definitions, improving transparency in conversational AI.

</details>


### [13] [Internet 3.0: Architecture for a Web-of-Agents with it's Algorithm for Ranking Agents](https://arxiv.org/abs/2509.04979)
*Rajesh Tembarai Krishnamachari,Srividya Rajesh*

Main category: cs.AI

TL;DR: 本文提出了DOVIS协议和AgentRank-UC算法，旨在解决未来“智能体之网”中智能体排名面临的数据碎片化和隐私问题，通过协调协议实现基于使用和能力的动态、信任感知的智能体排名。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型驱动的AI智能体及其工具、数据和网络搜索的集成，互联网正演变为一个“智能体之网”，其中自主智能体大规模交互、协作并执行任务。然而，要实现这一愿景，需要对智能体进行排名，而现有的排名机制（如PageRank）不适用，因为智能体的使用信号是碎片化和私密的，使得在没有协调的情况下进行排名不可行。

Method: 研究提出了DOVIS，一个五层操作协议（发现、编排、验证、激励、语义），用于收集最小、隐私保护的生态系统使用和性能聚合数据。在此基础上，实现了AgentRank-UC，一个动态、信任感知的算法，将“使用”（选择频率）和“能力”（结果质量、成本、安全性、延迟）结合起来进行统一排名。

Result: 通过模拟结果和理论保证，证明了DOVIS和AgentRank-UC在收敛性、鲁棒性和Sybil攻击抵抗方面的可行性，展示了协调协议和性能感知排名在构建可扩展、可信赖的智能体网络中的潜力。

Conclusion: 协调协议和性能感知排名对于实现可扩展、可信赖的智能体网络至关重要。DOVIS协议和AgentRank-UC算法为解决智能体排名挑战提供了可行的解决方案，能够有效整合使用和能力信号，促进智能体生态系统的发展。

Abstract: AI agents -- powered by reasoning-capable large language models (LLMs) and
integrated with tools, data, and web search -- are poised to transform the
internet into a \emph{Web of Agents}: a machine-native ecosystem where
autonomous agents interact, collaborate, and execute tasks at scale. Realizing
this vision requires \emph{Agent Ranking} -- selecting agents not only by
declared capabilities but by proven, recent performance. Unlike Web~1.0's
PageRank, a global, transparent network of agent interactions does not exist;
usage signals are fragmented and private, making ranking infeasible without
coordination.
  We propose \textbf{DOVIS}, a five-layer operational protocol
(\emph{Discovery, Orchestration, Verification, Incentives, Semantics}) that
enables the collection of minimal, privacy-preserving aggregates of usage and
performance across the ecosystem. On this substrate, we implement
\textbf{AgentRank-UC}, a dynamic, trust-aware algorithm that combines
\emph{usage} (selection frequency) and \emph{competence} (outcome quality,
cost, safety, latency) into a unified ranking. We present simulation results
and theoretical guarantees on convergence, robustness, and Sybil resistance,
demonstrating the viability of coordinated protocols and performance-aware
ranking in enabling a scalable, trustworthy Agentic Web.

</details>


### [14] [Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework](https://arxiv.org/abs/2509.05007)
*Jie Chen,Jinhao Jiang,Yingqian Min,Zican Dong,Shijie Wang,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.AI

TL;DR: Sticker-TTS是一个新的测试时扩展框架，它利用历史经验（称为“贴纸”）来指导三个大型推理模型（LRMs）迭代探索和完善解决方案，从而显著提高了复杂推理任务的计算效率和性能。


<details>
  <summary>Details</summary>
Motivation: 当前的测试时扩展方法主要依赖冗余采样，忽略了历史经验的利用，这限制了计算效率。因此，研究的动机是克服这一局限性，提高LRMs在推理时的计算效率和性能。

Method: Sticker-TTS框架协调三个协作的LRMs，通过历史尝试的指导迭代地探索和完善解决方案。其核心是“贴纸”（从历史尝试中提炼的关键条件），用于在多轮推理中提取、精炼和重用关键信息。为了进一步提高效率和性能，引入了两阶段优化策略，结合了模仿学习和自我改进。

Result: 在AIME-24、AIME-25和OlymMATH三个具有挑战性的数学推理基准测试中，Sticker-TTS在可比的推理预算下，持续超越了包括自洽性和先进强化学习方法在内的强大基线。

Conclusion: 这些结果突出了“贴纸”引导的历史经验利用在提高大型推理模型性能和效率方面的有效性。

Abstract: Large reasoning models (LRMs) have exhibited strong performance on complex
reasoning tasks, with further gains achievable through increased computational
budgets at inference. However, current test-time scaling methods predominantly
rely on redundant sampling, ignoring the historical experience utilization,
thereby limiting computational efficiency. To overcome this limitation, we
propose Sticker-TTS, a novel test-time scaling framework that coordinates three
collaborative LRMs to iteratively explore and refine solutions guided by
historical attempts. At the core of our framework are distilled key
conditions-termed stickers-which drive the extraction, refinement, and reuse of
critical information across multiple rounds of reasoning. To further enhance
the efficiency and performance of our framework, we introduce a two-stage
optimization strategy that combines imitation learning with self-improvement,
enabling progressive refinement. Extensive evaluations on three challenging
mathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH,
demonstrate that Sticker-TTS consistently surpasses strong baselines, including
self-consistency and advanced reinforcement learning approaches, under
comparable inference budgets. These results highlight the effectiveness of
sticker-guided historical experience utilization. Our code and data are
available at https://github.com/RUCAIBox/Sticker-TTS.

</details>


### [15] [Finding your MUSE: Mining Unexpected Solutions Engine](https://arxiv.org/abs/2509.05072)
*Nir Sweed,Hanit Hakim,Ben Wolfson,Hila Lifshitz,Dafna Shahaf*

Main category: cs.AI

TL;DR: 本文提出了一种构建功能概念图（FCG）的方法，并开发了MUSE算法，利用FCG为给定问题生成创新灵感，以克服创新者认知固着的问题。


<details>
  <summary>Details</summary>
Motivation: 创新者常对现有解决方案或初期想法存在认知固着，阻碍了新颖替代方案的探索。

Method: 引入了功能概念图（FCG）的构建方法，FCG是相互关联的功能元素表示，支持抽象、问题重构和类比启发。该方法生成了具有显式抽象关系的大规模、高质量FCG，克服了以往工作的局限。进一步提出了MUSE算法，利用FCG为给定问题生成创新灵感。通过在50万份专利上计算FCG来展示该方法，并发布了该FCG。

Result: 成功构建了大规模、高质量且具有显式抽象关系的功能概念图（FCG），克服了现有方法的局限。MUSE算法能够为给定问题生成创造性灵感。在50万份专利上计算并发布了一个FCG，可供进一步研究。

Conclusion: 功能概念图（FCG）及其MUSE算法能够有效帮助创新者克服认知固着，促进新颖解决方案的探索，并能生成创造性灵感。发布的FCG是一个有价值的研究资源。

Abstract: Innovators often exhibit cognitive fixation on existing solutions or nascent
ideas, hindering the exploration of novel alternatives. This paper introduces a
methodology for constructing Functional Concept Graphs (FCGs), interconnected
representations of functional elements that support abstraction, problem
reframing, and analogical inspiration. Our approach yields large-scale,
high-quality FCGs with explicit abstraction relations, overcoming limitations
of prior work. We further present MUSE, an algorithm leveraging FCGs to
generate creative inspirations for a given problem. We demonstrate our method
by computing an FCG on 500K patents, which we release for further research.

</details>


### [16] [ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback](https://arxiv.org/abs/2509.05091)
*Matteo Bortoletto,Yichao Zhou,Lance Ying,Tianmin Shu,Andreas Bulling*

Main category: cs.AI

TL;DR: 本文提出了ProToM，一个基于心智理论的AI系统，通过提供有针对性、情境敏感的反馈，在多智能体系统中促进亲社会行为，并被证明优于现有的大语言模型。


<details>
  <summary>Details</summary>
Motivation: 人类在追求独立目标时，难以判断何时以及如何协助他人，这阻碍了合作。研究旨在开发一个AI系统，通过提供有用反馈来促进亲社会行为，即即便不直接符合自身目标，也能使他人受益的行为。

Method: 引入ProToM，一个受心智理论启发的协调器。它首先使用贝叶斯逆向规划推断智能体的目标，然后根据推断的目标分布，通过最大化预期效用选择要传达的反馈，从而提供有针对性、情境敏感的反馈。

Result: 在两个多智能体环境（Doors, Keys, and Gems 和 Overcooked）中进行评估。结果显示，最先进的大语言和推理模型在提供情境化和及时反馈方面表现不足，导致更高的通信开销和更慢的任务加速。相比之下，ProToM提供了有针对性且有益的反馈，实现了更高的成功率、更短的任务完成时间，并持续受到人类用户的青睐。

Conclusion: ProToM通过提供有针对性且有益的反馈，有效促进了多智能体系统中的亲社会行为，其性能优于现有的大语言模型，证明了其在提升合作方面的潜力。

Abstract: While humans are inherently social creatures, the challenge of identifying
when and how to assist and collaborate with others - particularly when pursuing
independent goals - can hinder cooperation. To address this challenge, we aim
to develop an AI system that provides useful feedback to promote prosocial
behaviour - actions that benefit others, even when not directly aligned with
one's own goals. We introduce ProToM, a Theory of Mind-informed facilitator
that promotes prosocial actions in multi-agent systems by providing targeted,
context-sensitive feedback to individual agents. ProToM first infers agents'
goals using Bayesian inverse planning, then selects feedback to communicate by
maximising expected utility, conditioned on the inferred goal distribution. We
evaluate our approach against baselines in two multi-agent environments: Doors,
Keys, and Gems, as well as Overcooked. Our results suggest that
state-of-the-art large language and reasoning models fall short of
communicating feedback that is both contextually grounded and well-timed -
leading to higher communication overhead and task speedup. In contrast, ProToM
provides targeted and helpful feedback, achieving a higher success rate,
shorter task completion times, and is consistently preferred by human users.

</details>


### [17] [Evaluation and Comparison Semantics for ODRL](https://arxiv.org/abs/2509.05139)
*Jaime Osvaldo Salas,Paolo Pareti,Semih Yumuşak,Soulmaz Gheisari,Luis-Daniel Ibáñez,George Konstantinidis*

Main category: cs.AI

TL;DR: 该论文提出了基于查询应答的ODRL形式化语义，并在此基础上定义了策略比较问题，用于评估和比较数字权利语言策略。


<details>
  <summary>Details</summary>
Motivation: ODRL是数字资源访问和使用的事实标准，但仍缺乏全面的形式化语义。现有工作虽有初步进展，但不足以支持对计算策略的评估和比较，特别是在数据共享场景中。

Method: 本文提出了一种基于查询应答的ODRL形式化语义，该语义简单直观，并与最新的ODRL 2.2规范保持一致。在此评估语义的基础上，定义并研究了策略比较问题，包括检测等效、更严格或更宽松的策略。

Result: 成功提供了一个与ODRL 2.2规范对齐的、基于查询应答的ODRL形式化语义。在此基础上，建立了用于比较两个ODRL策略（如等效性、限制性或宽松性）的框架。

Conclusion: 该论文通过提供全面的形式化语义和策略比较框架，填补了ODRL语言在评估和比较计算策略方面的空白，特别适用于数据共享场景。

Abstract: We consider the problem of evaluating, and comparing computational policies
in the Open Digital Rights Language (ODRL), which has become the de facto
standard for governing the access and usage of digital resources. Although
preliminary progress has been made on the formal specification of the
language's features, a comprehensive formal semantics of ODRL is still missing.
In this paper, we provide a simple and intuitive formal semantics for ODRL that
is based on query answering. Our semantics refines previous formalisations, and
is aligned with the latest published specification of the language (2.2).
Building on our evaluation semantics, and motivated by data sharing scenarios,
we also define and study the problem of comparing two policies, detecting
equivalent, more restrictive or more permissive policies.

</details>


### [18] [LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation](https://arxiv.org/abs/2509.05263)
*Yinglin Duan,Zhengxia Zou,Tongwei Gu,Wei Jia,Zhan Zhao,Luyi Xu,Xinzhu Liu,Hao Jiang,Kang Chen,Shuang Qiu*

Main category: cs.AI

TL;DR: LatticeWorld是一个高效的3D世界生成框架，它结合轻量级大型语言模型和工业级渲染引擎，通过多模态输入快速创建具有高精度物理模拟和实时渲染的大规模互动3D环境，显著提升了生产效率。


<details>
  <summary>Details</summary>
Motivation: 为了缩小模拟与现实之间的差距，需要更真实、具有精确物理特性的3D世界模型。传统手动建模效率低下，而现代机器学习方法，尤其是生成式方法，能够根据用户指令创建虚拟世界，这促使了对更高效、高质量3D环境生成技术的需求。

Method: 本文提出了LatticeWorld框架，它利用轻量级大型语言模型（如LLaMA-2-7B）和工业级渲染引擎（如Unreal Engine 5）来生成动态环境。该框架接受文本描述和视觉指令作为多模态输入，能够创建包含动态智能体、多智能体交互、高保真物理模拟和实时渲染的大规模3D互动世界。

Result: LatticeWorld在场景布局生成和视觉保真度方面表现出卓越的准确性。与传统手动生产方法相比，它在保持高创造性质量的同时，将工业生产效率提高了90倍以上。

Conclusion: LatticeWorld是一个简单而有效的3D世界生成框架，它通过结合先进的AI技术和工业级渲染引擎，极大地简化了3D环境的工业生产流程，实现了高效、高保真、大规模的互动3D世界生成，对具身AI、自动驾驶等领域具有重要应用价值。

Abstract: Recent research has been increasingly focusing on developing 3D world models
that simulate complex real-world scenarios. World models have found broad
applications across various domains, including embodied AI, autonomous driving,
entertainment, etc. A more realistic simulation with accurate physics will
effectively narrow the sim-to-real gap and allow us to gather rich information
about the real world conveniently. While traditional manual modeling has
enabled the creation of virtual 3D scenes, modern approaches have leveraged
advanced machine learning algorithms for 3D world generation, with most recent
advances focusing on generative methods that can create virtual worlds based on
user instructions. This work explores such a research direction by proposing
LatticeWorld, a simple yet effective 3D world generation framework that
streamlines the industrial production pipeline of 3D environments. LatticeWorld
leverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering
engine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed
framework accepts textual descriptions and visual instructions as multimodal
inputs and creates large-scale 3D interactive worlds with dynamic agents,
featuring competitive multi-agent interaction, high-fidelity physics
simulation, and real-time rendering. We conduct comprehensive experiments to
evaluate LatticeWorld, showing that it achieves superior accuracy in scene
layout generation and visual fidelity. Moreover, LatticeWorld achieves over a
$90\times$ increase in industrial production efficiency while maintaining high
creative quality compared with traditional manual production methods. Our demo
video is available at https://youtu.be/8VWZXpERR18

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [19] [Facial Emotion Recognition does not detect feeling unsafe in automated driving](https://arxiv.org/abs/2509.04490)
*Abel van Elburg,Konstantinos Gkentsidis,Mathieu Sarrazin,Sarah Barendswaard,Varun Kotian,Riender Happee*

Main category: cs.CV

TL;DR: 本研究通过驾驶模拟器实验，探究了自动驾驶车辆中感知风险与信任。结果显示，动态驾驶风格和关键交互（如行人）会增加不适感。面部表情识别被证明不可靠，而基于车辆运动和皮肤电反应的神经网络模型在客观评估感知风险方面显示出潜力。


<details>
  <summary>Details</summary>
Motivation: 信任和感知安全在公众接受自动驾驶车辆中至关重要。为了促进自动驾驶的普及，需要深入理解用户对自动驾驶的感知风险。

Method: 实验使用驾驶模拟器，设置两种自动驾驶风格（平稳和动态）并可选引入横穿行人。收集了32名参与者的连续主观舒适度评分、车辆运动数据、网络摄像头（面部表情）、皮肤电导、心率和眼动数据。采用主观评分分析、面部表情分析和基于车辆运动与皮肤电反应的神经网络模型来预测感知风险。

Result: 主观感知风险评分显示，转弯和制动时存在显著不适感，随后是放松或舒适。动态驾驶风格比平稳风格引起更强的不适。横穿行人对平稳驾驶风格下的不适无影响，但使动态驾驶风格下的舒适度下降加倍。面部表情识别被证明不可靠，大多数参与者没有可检测的面部反应，少数有反应的也多为“开心”或“惊讶”，从未出现“恐惧”。基于车辆运动和皮肤电反应的神经网络模型与报告的感知风险高度相关，显示出客观评估感知风险的潜力。

Conclusion: 面部表情识别不是评估自动驾驶车辆中感知风险的可靠方法。利用车辆运动和皮肤电反应的神经网络模型在客观评估自动驾驶车辆中的感知风险方面具有潜力，有助于减少主观偏见并为未来研究指明方向。

Abstract: Trust and perceived safety play a crucial role in the public acceptance of
automated vehicles. To understand perceived risk, an experiment was conducted
using a driving simulator under two automated driving styles and optionally
introducing a crossing pedestrian. Data was collected from 32 participants,
consisting of continuous subjective comfort ratings, motion, webcam footage for
facial expression, skin conductance, heart rate, and eye tracking. The
continuous subjective perceived risk ratings showed significant discomfort
associated with perceived risk during cornering and braking followed by relief
or even positive comfort on continuing the ride. The dynamic driving style
induced a stronger discomfort as compared to the calm driving style. The
crossing pedestrian did not affect discomfort with the calm driving style but
doubled the comfort decrement with the dynamic driving style. This illustrates
the importance of consequences of critical interactions in risk perception.
Facial expression was successfully analyzed for 24 participants but most
(15/24) did not show any detectable facial reaction to the critical event.
Among the 9 participants who did, 8 showed a Happy expression, and only 4
showed a Surprise expression. Fear was never dominant. This indicates that
facial expression recognition is not a reliable method for assessing perceived
risk in automated vehicles. To predict perceived risk a neural network model
was implemented using vehicle motion and skin conductance. The model correlated
well with reported perceived risk, demonstrating its potential for objective
perceived risk assessment in automated vehicles, reducing subjective bias and
highlighting areas for future research.

</details>


### [20] [PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting](https://arxiv.org/abs/2509.04545)
*Linqing Wang,Ximing Xing,Yiji Cheng,Zhiyuan Zhao,Jiale Tao,Qixun Wang,Ruihuang Li,Xin Li,Mingrui Wu,Xinchi Deng,Chunyu Wang,Qinglin Lu*

Main category: cs.CV

TL;DR: PromptEnhancer是一个新颖的、通用的提示词重写框架，通过强化学习训练CoT重写器并由AlignEvaluator奖励模型指导，显著提升了预训练文生图模型对复杂提示词的理解和图像-文本对齐。


<details>
  <summary>Details</summary>
Motivation: 当前的文生图（T2I）扩散模型在生成高保真图像方面表现出色，但难以忠实地渲染复杂用户提示，特别是在属性绑定、否定和组合关系方面，导致用户意图与生成输出之间存在显著 Mismatch。

Method: 本文提出了PromptEnhancer，一个无需修改模型权重的通用提示词重写框架。它将重写器与生成器解耦，通过强化学习训练一个Chain-of-Thought (CoT) 重写器。该训练由一个专门的奖励模型AlignEvaluator指导，AlignEvaluator根据对常见T2I失败模式的24个关键点分类学提供显式和细粒度的反馈。

Result: 在HunyuanImage 2.1模型上的广泛实验表明，PromptEnhancer在各种语义和组合挑战中显著改善了图像-文本对齐。此外，本文还引入了一个新的高质量人类偏好基准，以促进未来的研究。

Conclusion: PromptEnhancer提供了一个有效且通用的提示词重写解决方案，通过学习生成更精确的提示词，显著提高了文生图模型对用户意图的理解和图像生成质量，克服了复杂提示词处理的挑战。

Abstract: Recent advancements in text-to-image (T2I) diffusion models have demonstrated
remarkable capabilities in generating high-fidelity images. However, these
models often struggle to faithfully render complex user prompts, particularly
in aspects like attribute binding, negation, and compositional relationships.
This leads to a significant mismatch between user intent and the generated
output. To address this challenge, we introduce PromptEnhancer, a novel and
universal prompt rewriting framework that enhances any pretrained T2I model
without requiring modifications to its weights. Unlike prior methods that rely
on model-specific fine-tuning or implicit reward signals like image-reward
scores, our framework decouples the rewriter from the generator. We achieve
this by training a Chain-of-Thought (CoT) rewriter through reinforcement
learning, guided by a dedicated reward model we term the AlignEvaluator. The
AlignEvaluator is trained to provide explicit and fine-grained feedback based
on a systematic taxonomy of 24 key points, which are derived from a
comprehensive analysis of common T2I failure modes. By optimizing the CoT
rewriter to maximize the reward from our AlignEvaluator, our framework learns
to generate prompts that are more precisely interpreted by T2I models.
Extensive experiments on the HunyuanImage 2.1 model demonstrate that
PromptEnhancer significantly improves image-text alignment across a wide range
of semantic and compositional challenges. Furthermore, we introduce a new,
high-quality human preference benchmark to facilitate future research in this
direction.

</details>


### [21] [Skywork UniPic 2.0: Building Kontext Model with Online RL for Unified Multimodal Model](https://arxiv.org/abs/2509.04548)
*Hongyang Wei,Baixin Xu,Hongbo Liu,Cyrus Wu,Jie Liu,Yi Peng,Peiyu Wang,Zexiang Liu,Jingwen He,Yidan Xietian,Chuanxin Tang,Zidong Wang,Yichen Wei,Liang Hu,Boyi Jiang,William Li,Ying He,Yang Liu,Xuchen Song,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: 本文提出了UniPic2-SD3.5M-Kontext，一个2B参数的DiT模型，通过优化训练策略实现了最先进的图像生成和编辑能力。在此基础上，通过连接器与Qwen2.5-VL-7B结合，构建了统一的多模态模型UniPic2-Metaquery，整合了理解、生成和编辑，并在各种任务中取得了顶尖性能。


<details>
  <summary>Details</summary>
Motivation: 许多主流开源多模态模型侧重于扩展模型参数而非优化训练策略，这限制了它们的效率和性能。

Method: 1. 对SD3.5-Medium进行架构修改并进行大规模高质量数据预训练，以实现图文生成和编辑能力。2. 提出渐进式双任务强化策略（PDTR），分阶段增强指令遵循和编辑一致性。3. 将UniPic2-SD3.5M-Kontext与Qwen2.5-VL-7B通过连接器进行联合训练，构建统一的多模态模型UniPic2-Metaquery。

Result: 1. UniPic2-SD3.5M-Kontext（2B参数）在图像生成和编辑方面超越了参数量更大的模型（如BAGEL 7B和Flux-Kontext 12B）。2. PDTR策略的强化阶段对不同任务互利且不产生负面干扰。3. UniPic2-Metaquery在理解、生成和编辑等多样任务中实现了顶尖性能。

Conclusion: 所提出的训练范式（Skywork UniPic 2.0）被证实是有效、可泛化且可扩展的，能够以更少的参数实现强大的统一多模态能力。

Abstract: Recent advances in multimodal models have demonstrated impressive
capabilities in unified image generation and editing. However, many prominent
open-source models prioritize scaling model parameters over optimizing training
strategies, limiting their efficiency and performance. In this work, we present
UniPic2-SD3.5M-Kontext, a 2B-parameter DiT model based on SD3.5-Medium, which
achieves state-of-the-art image generation and editing while extending
seamlessly into a unified multimodal framework. Our approach begins with
architectural modifications to SD3.5-Medium and large-scale pre-training on
high-quality data, enabling joint text-to-image generation and editing
capabilities. To enhance instruction following and editing consistency, we
propose a novel Progressive Dual-Task Reinforcement strategy (PDTR), which
effectively strengthens both tasks in a staged manner. We empirically validate
that the reinforcement phases for different tasks are mutually beneficial and
do not induce negative interference. After pre-training and reinforcement
strategies, UniPic2-SD3.5M-Kontext demonstrates stronger image generation and
editing capabilities than models with significantly larger generation
parameters-including BAGEL (7B) and Flux-Kontext (12B). Furthermore, following
the MetaQuery, we connect the UniPic2-SD3.5M-Kontext and Qwen2.5-VL-7B via a
connector and perform joint training to launch a unified multimodal model
UniPic2-Metaquery. UniPic2-Metaquery integrates understanding, generation, and
editing, achieving top-tier performance across diverse tasks with a simple and
scalable training paradigm. This consistently validates the effectiveness and
generalizability of our proposed training paradigm, which we formalize as
Skywork UniPic 2.0.

</details>


### [22] [Inpaint4Drag: Repurposing Inpainting Models for Drag-Based Image Editing via Bidirectional Warping](https://arxiv.org/abs/2509.04582)
*Jingyi Lu,Kai Han*

Main category: cs.CV

TL;DR: Inpaint4Drag提出了一种新的拖拽式图像编辑框架，通过像素空间双向变形和图像修复，实现了实时、高精度且通用的编辑体验，克服了现有潜在空间方法的局限。


<details>
  <summary>Details</summary>
Motivation: 现有的拖拽式图像编辑方法主要依赖生成模型的潜在空间操作，导致精度有限、反馈延迟以及模型特定限制，影响了用户交互体验。

Method: 该方法将拖拽式编辑分解为像素空间双向变形和图像修复。受物理世界弹性物体变形启发，将图像区域视为可变形材料。它将拖拽输入直接转换为标准修复格式，使其能作为任何修复模型的通用适配器，无需修改架构。

Result: Inpaint4Drag实现了512x512分辨率下实时变形预览（0.01秒）和高效修复（0.3秒），显著优于现有方法（需数分钟）。实验表明，该方法在保持实时性能的同时，实现了卓越的视觉质量和精确控制。

Conclusion: Inpaint4Drag通过将拖拽式编辑分解为像素空间变形和图像修复，提供了一种实时、高精度、通用且能自动继承未来修复技术改进的图像编辑解决方案，显著提升了交互体验。

Abstract: Drag-based image editing has emerged as a powerful paradigm for intuitive
image manipulation. However, existing approaches predominantly rely on
manipulating the latent space of generative models, leading to limited
precision, delayed feedback, and model-specific constraints. Accordingly, we
present Inpaint4Drag, a novel framework that decomposes drag-based editing into
pixel-space bidirectional warping and image inpainting. Inspired by elastic
object deformation in the physical world, we treat image regions as deformable
materials that maintain natural shape under user manipulation. Our method
achieves real-time warping previews (0.01s) and efficient inpainting (0.3s) at
512x512 resolution, significantly improving the interaction experience compared
to existing methods that require minutes per edit. By transforming drag inputs
directly into standard inpainting formats, our approach serves as a universal
adapter for any inpainting model without architecture modification,
automatically inheriting all future improvements in inpainting technology.
Extensive experiments demonstrate that our method achieves superior visual
quality and precise control while maintaining real-time performance. Project
page: https://visual-ai.github.io/inpaint4drag/

</details>


### [23] [DisPatch: Disarming Adversarial Patches in Object Detection with Diffusion Models](https://arxiv.org/abs/2509.04597)
*Jin Ma,Mohammed Aldeen,Christopher Salas,Feng Luo,Mashrur Chowdhury,Mert Pesé,Long Cheng*

Main category: cs.CV

TL;DR: 本文提出DISPATCH，首个基于扩散模型的物体检测防御框架，采用“再生与纠正”策略，有效抵御各种对抗性补丁攻击，无需预知攻击类型。


<details>
  <summary>Details</summary>
Motivation: 先进的物体检测器易受对抗性补丁攻击，这些攻击可能隐藏物体或制造虚假物体，导致严重后果。鉴于攻击的多样性和潜在的未知威胁，需要一种有效、通用且能抵御自适应攻击的防御方法。

Method: DISPATCH采用“再生与纠正”策略，而非传统的“检测与移除”。它利用扩散模型的分布内生成能力，重新生成整个图像以使其与良性数据对齐。随后，通过纠正过程识别并用重新生成的良性区域替换对抗性区域。该方法与攻击类型无关，无需预先了解补丁信息。

Result: DISPATCH在多种检测器和攻击类型上均优于现有最先进的防御方法。在隐藏攻击上，其mAP.5得分达到89.3%；在非目标创建攻击上，攻击成功率降至24.8%。此外，它对自适应攻击也表现出强大的鲁棒性。

Conclusion: DISPATCH是一种实用且可靠的物体检测系统防御方案，能够有效、普遍且鲁棒地应对各种对抗性补丁攻击，包括隐藏攻击和创建攻击，并能抵御自适应攻击。

Abstract: Object detection is fundamental to various real-world applications, such as
security monitoring and surveillance video analysis. Despite their
advancements, state-of-theart object detectors are still vulnerable to
adversarial patch attacks, which can be easily applied to real-world objects to
either conceal actual items or create non-existent ones, leading to severe
consequences. Given the current diversity of adversarial patch attacks and
potential unknown threats, an ideal defense method should be effective,
generalizable, and robust against adaptive attacks. In this work, we introduce
DISPATCH, the first diffusion-based defense framework for object detection.
Unlike previous works that aim to "detect and remove" adversarial patches,
DISPATCH adopts a "regenerate and rectify" strategy, leveraging generative
models to disarm attack effects while preserving the integrity of the input
image. Specifically, we utilize the in-distribution generative power of
diffusion models to regenerate the entire image, aligning it with benign data.
A rectification process is then employed to identify and replace adversarial
regions with their regenerated benign counterparts. DISPATCH is attack-agnostic
and requires no prior knowledge of the existing patches. Extensive experiments
across multiple detectors and attacks demonstrate that DISPATCH consistently
outperforms state-of-the-art defenses on both hiding attacks and creating
attacks, achieving the best overall mAP.5 score of 89.3% on hiding attacks, and
lowering the attack success rate to 24.8% on untargeted creating attacks.
Moreover, it maintains strong robustness against adaptive attacks, making it a
practical and reliable defense for object detection systems.

</details>


### [24] [WATCH: World-aware Allied Trajectory and pose reconstruction for Camera and Human](https://arxiv.org/abs/2509.04600)
*Qijun Ying,Zhongyuan Hu,Rui Zhang,Ronghui Li,Yu Lu,Zijiao Zeng*

Main category: cs.CV

TL;DR: WATCH是一个统一框架，通过分析性航向角分解和受世界模型启发的相机轨迹集成，解决了单目视频中全球人体运动重建中的相机方向和位移信息利用不足的问题，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实、图形和机器人应用对野外单目视频中全球人体运动重建的需求日益增长，但现有方法面临深度模糊、运动模糊以及相机与人体运动纠缠的挑战。此外，以人体运动为中心的方法在保留运动细节和物理合理性方面表现出色，但未能充分利用相机方向信息和有效整合相机位移线索。

Method: 本文提出了WATCH（World-aware Allied Trajectory and pose reconstruction for Camera and Human）框架。该方法引入了一种分析性航向角分解技术，相比现有几何方法更高效、更具扩展性。此外，设计了一种受世界模型启发的相机轨迹集成机制，为利用相机位移信息提供了一条有效途径，超越了简单的硬解码方法。

Result: 通过在野外基准测试上的实验，WATCH在端到端轨迹重建方面取得了最先进的性能。

Conclusion: 本工作证明了联合建模相机-人体运动关系的有效性，并为解决全球人体运动重建中长期存在的相机位移集成挑战提供了新见解。

Abstract: Global human motion reconstruction from in-the-wild monocular videos is
increasingly demanded across VR, graphics, and robotics applications, yet
requires accurate mapping of human poses from camera to world coordinates-a
task challenged by depth ambiguity, motion ambiguity, and the entanglement
between camera and human movements. While human-motion-centric approaches excel
in preserving motion details and physical plausibility, they suffer from two
critical limitations: insufficient exploitation of camera orientation
information and ineffective integration of camera translation cues. We present
WATCH (World-aware Allied Trajectory and pose reconstruction for Camera and
Human), a unified framework addressing both challenges. Our approach introduces
an analytical heading angle decomposition technique that offers superior
efficiency and extensibility compared to existing geometric methods.
Additionally, we design a camera trajectory integration mechanism inspired by
world models, providing an effective pathway for leveraging camera translation
information beyond naive hard-decoding approaches. Through experiments on
in-the-wild benchmarks, WATCH achieves state-of-the-art performance in
end-to-end trajectory reconstruction. Our work demonstrates the effectiveness
of jointly modeling camera-human motion relationships and offers new insights
for addressing the long-standing challenge of camera translation integration in
global human motion reconstruction. The code will be available publicly.

</details>


### [25] [Sali4Vid: Saliency-Aware Video Reweighting and Adaptive Caption Retrieval for Dense Video Captioning](https://arxiv.org/abs/2509.04602)
*MinJu Jeon,Si-Woo Kim,Ye-Chan Kim,HyunGee Kim,Dong-Jin Kim*

Main category: cs.CV

TL;DR: Sali4Vid 是一种简单有效的密集视频字幕框架，通过引入显著性感知视频重加权和基于语义的自适应字幕检索，解决了现有方法中视频帧处理不均和固定块检索的问题，并在YouCook2和ViTT数据集上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有端到端密集视频字幕模型存在两个局限性：1) 仅对文本应用时间戳监督，而对所有视频帧一视同仁；2) 从固定大小的视频块中检索字幕，忽略了场景转换。

Method: 本文提出了Sali4Vid框架。它包含两个主要组件：1) 显著性感知视频重加权（Saliency-aware Video Reweighting），将时间戳注释转换为基于Sigmoid的帧重要性权重；2) 基于语义的自适应字幕检索（Semantic-based Adaptive Caption Retrieval），通过帧相似性分割视频以捕捉场景转换并改进字幕检索。

Result: Sali4Vid在YouCook2和ViTT数据集上取得了最先进（state-of-the-art）的结果。

Conclusion: 联合改进视频加权和检索对密集视频字幕任务具有显著益处。

Abstract: Dense video captioning aims to temporally localize events in video and
generate captions for each event. While recent works propose end-to-end models,
they suffer from two limitations: (1) applying timestamp supervision only to
text while treating all video frames equally, and (2) retrieving captions from
fixed-size video chunks, overlooking scene transitions. To address these, we
propose Sali4Vid, a simple yet effective saliency-aware framework. We introduce
Saliency-aware Video Reweighting, which converts timestamp annotations into
sigmoid-based frame importance weights, and Semantic-based Adaptive Caption
Retrieval, which segments videos by frame similarity to capture scene
transitions and improve caption retrieval. Sali4Vid achieves state-of-the-art
results on YouCook2 and ViTT, demonstrating the benefit of jointly improving
video weighting and retrieval for dense video captioning

</details>


### [26] [UAV-Based Intelligent Traffic Surveillance System: Real-Time Vehicle Detection, Classification, Tracking, and Behavioral Analysis](https://arxiv.org/abs/2509.04624)
*Ali Khanpour,Tianyi Wang,Afra Vahidi-Shams,Wim Ectors,Farzam Nakhaie,Amirhossein Taheri,Christian Claudel*

Main category: cs.CV

TL;DR: 本文提出了一种基于无人机（UAV）的先进交通监控系统，能够对城市交通进行车辆检测、分类、跟踪和行为分析，并自动识别交通违规行为，具有高精度、可扩展性和实用性。


<details>
  <summary>Details</summary>
Motivation: 传统的交通监控系统（如固定摄像头和传感器）存在覆盖范围有限、适应性差和可扩展性低的问题，无法有效应对城市交通拥堵和违规挑战。

Method: 该系统利用无人机在约200米高空采集视频数据，通过多尺度和多角度模板匹配、卡尔曼滤波和基于单应性的校准进行处理。车辆行为分析和违规检测则融合了地理围栏、运动过滤和轨迹偏差分析。此外，系统还集成了分析模块，支持起讫点跟踪、车辆计数、类间关联分析、热力图拥堵建模、出入口轨迹分析、路段车辆密度估算和运动方向记录。

Result: 在城市区域案例研究中，系统实现了91.8%的检测精度、90.5%的F1分数，以及92.1%的MOTA和93.7%的MOTP跟踪指标。系统能分类五种车辆类型，并自动检测不安全变道、非法双重停车和人行横道阻塞等关键交通违规行为。实验结果证实了系统的可扩展性、准确性和实用性。

Conclusion: 该系统是一个可扩展、准确且具有实际意义的交通监控解决方案，有望成为下一代智慧城市中独立于基础设施、支持执法的新型交通监控工具。

Abstract: Traffic congestion and violations pose significant challenges for urban
mobility and road safety. Traditional traffic monitoring systems, such as fixed
cameras and sensor-based methods, are often constrained by limited coverage,
low adaptability, and poor scalability. To address these challenges, this paper
introduces an advanced unmanned aerial vehicle (UAV)-based traffic surveillance
system capable of accurate vehicle detection, classification, tracking, and
behavioral analysis in real-world, unconstrained urban environments. The system
leverages multi-scale and multi-angle template matching, Kalman filtering, and
homography-based calibration to process aerial video data collected from
altitudes of approximately 200 meters. A case study in urban area demonstrates
robust performance, achieving a detection precision of 91.8%, an F1-score of
90.5%, and tracking metrics (MOTA/MOTP) of 92.1% and 93.7%, respectively.
Beyond precise detection, the system classifies five vehicle types and
automatically detects critical traffic violations, including unsafe lane
changes, illegal double parking, and crosswalk obstructions, through the fusion
of geofencing, motion filtering, and trajectory deviation analysis. The
integrated analytics module supports origin-destination tracking, vehicle count
visualization, inter-class correlation analysis, and heatmap-based congestion
modeling. Additionally, the system enables entry-exit trajectory profiling,
vehicle density estimation across road segments, and movement direction
logging, supporting comprehensive multi-scale urban mobility analytics.
Experimental results confirms the system's scalability, accuracy, and practical
relevance, highlighting its potential as an enforcement-aware,
infrastructure-independent traffic monitoring solution for next-generation
smart cities.

</details>


### [27] [VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation](https://arxiv.org/abs/2509.04669)
*Mustafa Munir,Alex Zhang,Radu Marculescu*

Main category: cs.CV

TL;DR: VCMamba是一种结合了卷积神经网络（CNN）和多向Mamba状态空间模型（SSM）的新型视觉骨干网络，旨在高效捕捉局部和全局特征，并在图像分类和语义分割任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers (ViTs)和Mamba等SSM在全局上下文和长序列建模方面表现优异，但在细粒度局部特征捕捉上不如CNN。而CNN擅长局部特征，但缺乏全局推理能力。研究旨在弥合这一差距，结合两者的优势。

Method: VCMamba采用卷积主干和早期阶段的卷积块来提取丰富的局部特征，随后通过多向Mamba块处理这些特征，以有效地建模长距离依赖和全局上下文。这种混合设计保持了线性复杂性，并具有分层结构。

Result: VCMamba-B在ImageNet-1K分类上达到82.6%的top-1准确率，比PlainMamba-L3高0.3%且参数减少37%，比Vision GNN-B高0.3%且参数减少64%。在ADE20K语义分割上，VCMamba-B获得47.1 mIoU，超越EfficientFormer-L7 2.0 mIoU且参数减少62%。

Conclusion: VCMamba成功地整合了CNN的局部特征提取能力和多向Mamba SSM的全局上下文建模能力，实现了卓越的特征表示，同时保持了图像分辨率的线性复杂度，并在多项视觉任务上展现出优越的性能和效率。

Abstract: Recent advances in Vision Transformers (ViTs) and State Space Models (SSMs)
have challenged the dominance of Convolutional Neural Networks (CNNs) in
computer vision. ViTs excel at capturing global context, and SSMs like Mamba
offer linear complexity for long sequences, yet they do not capture
fine-grained local features as effectively as CNNs. Conversely, CNNs possess
strong inductive biases for local features but lack the global reasoning
capabilities of transformers and Mamba. To bridge this gap, we introduce
\textit{VCMamba}, a novel vision backbone that integrates the strengths of CNNs
and multi-directional Mamba SSMs. VCMamba employs a convolutional stem and a
hierarchical structure with convolutional blocks in its early stages to extract
rich local features. These convolutional blocks are then processed by later
stages incorporating multi-directional Mamba blocks designed to efficiently
model long-range dependencies and global context. This hybrid design allows for
superior feature representation while maintaining linear complexity with
respect to image resolution. We demonstrate VCMamba's effectiveness through
extensive experiments on ImageNet-1K classification and ADE20K semantic
segmentation. Our VCMamba-B achieves 82.6% top-1 accuracy on ImageNet-1K,
surpassing PlainMamba-L3 by 0.3% with 37% fewer parameters, and outperforming
Vision GNN-B by 0.3% with 64% fewer parameters. Furthermore, VCMamba-B obtains
47.1 mIoU on ADE20K, exceeding EfficientFormer-L7 by 2.0 mIoU while utilizing
62% fewer parameters. Code is available at
https://github.com/Wertyuui345/VCMamba.

</details>


### [28] [Guideline-Consistent Segmentation via Multi-Agent Refinement](https://arxiv.org/abs/2509.04687)
*Vanshika Vats,Ashwani Rathee,James Davis*

Main category: cs.CV

TL;DR: 本文提出一个多智能体、免训练框架，通过迭代的“工作者-监督者”细化架构协调通用视觉语言模型，以解决语义分割中复杂文本指南依从性差的问题，并在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，语义分割不仅需要准确的掩码，还需要严格遵守复杂的文本标注指南。传统方法需要昂贵的任务特定再训练，且难以适应指南变化；现有开放词汇分割方法在处理简单提示时表现良好，但面对段落长度的复杂规则时则效果不佳，导致自动化和人工标注都难以忠实遵循指南。

Method: 本文引入了一个多智能体、免训练框架。该框架通过迭代的“工作者-监督者”细化架构来协调通用视觉语言模型。其中，工作者执行分割任务，监督者根据检索到的指南对分割结果进行批判，轻量级强化学习停止策略决定何时终止循环，以确保掩码符合指南并平衡资源使用。

Result: 在Waymo和ReasonSeg数据集上的评估显示，该方法显著优于现有最先进的基线方法，展现出强大的泛化能力和指令依从性。

Conclusion: 该框架通过创新的多智能体和迭代细化机制，有效解决了语义分割中遵守复杂、段落长度文本指南的挑战，且无需额外训练，显著提升了分割结果的指南一致性。

Abstract: Semantic segmentation in real-world applications often requires not only
accurate masks but also strict adherence to textual labeling guidelines. These
guidelines are typically complex and long, and both human and automated
labeling often fail to follow them faithfully. Traditional approaches depend on
expensive task-specific retraining that must be repeated as the guidelines
evolve. Although recent open-vocabulary segmentation methods excel with simple
prompts, they often fail when confronted with sets of paragraph-length
guidelines that specify intricate segmentation rules. To address this, we
introduce a multi-agent, training-free framework that coordinates
general-purpose vision-language models within an iterative Worker-Supervisor
refinement architecture. The Worker performs the segmentation, the Supervisor
critiques it against the retrieved guidelines, and a lightweight reinforcement
learning stop policy decides when to terminate the loop, ensuring
guideline-consistent masks while balancing resource use. Evaluated on the Waymo
and ReasonSeg datasets, our method notably outperforms state-of-the-art
baselines, demonstrating strong generalization and instruction adherence.

</details>


### [29] [Domain Adaptation for Different Sensor Configurations in 3D Object Detection](https://arxiv.org/abs/2509.04711)
*Satoshi Tanaka,Kok Seang Tan,Isamu Yamashita*

Main category: cs.CV

TL;DR: 本文提出并解决了3D目标检测中不同LiDAR传感器配置间的域适应问题，通过下游微调和部分层微调技术，实现了模型在不同车辆平台上的鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中，不同车辆平台部署的传感器配置各异，导致模型在不同配置间应用时性能下降，原因在于点云分布的变化。现有工作主要关注环境域差距和单一LiDAR内的密度变化，而不同传感器配置间的域差距尚未得到充分探索。

Method: 提出了两种技术：1) 下游微调（多数据集训练后进行数据集特定微调），2) 部分层微调（仅更新部分网络层以改善跨配置泛化能力）。研究使用了在同一地理区域、多种传感器配置下采集的配对数据集。

Result: 研究表明，结合下游微调和部分层微调的联合训练，在每种传感器配置下都显著优于简单的联合训练（即朴素联合训练）。

Conclusion: 研究结果为3D目标检测模型适应多样化车辆平台提供了一个实用且可扩展的解决方案。

Abstract: Recent advances in autonomous driving have underscored the importance of
accurate 3D object detection, with LiDAR playing a central role due to its
robustness under diverse visibility conditions. However, different vehicle
platforms often deploy distinct sensor configurations, causing performance
degradation when models trained on one configuration are applied to another
because of shifts in the point cloud distribution. Prior work on multi-dataset
training and domain adaptation for 3D object detection has largely addressed
environmental domain gaps and density variation within a single LiDAR; in
contrast, the domain gap for different sensor configurations remains largely
unexplored. In this work, we address domain adaptation across different sensor
configurations in 3D object detection. We propose two techniques: Downstream
Fine-tuning (dataset-specific fine-tuning after multi-dataset training) and
Partial Layer Fine-tuning (updating only a subset of layers to improve
cross-configuration generalization). Using paired datasets collected in the
same geographic region with multiple sensor configurations, we show that joint
training with Downstream Fine-tuning and Partial Layer Fine-tuning consistently
outperforms naive joint training for each configuration. Our findings provide a
practical and scalable solution for adapting 3D object detection models to the
diverse vehicle platforms.

</details>


### [30] [CD-Mamba: Cloud detection with long-range spatial dependency modeling](https://arxiv.org/abs/2509.04729)
*Tianxiang Xue,Jiayi Zhao,Jingsheng Li,Changlu Chen,Kun Zhan*

Main category: cs.CV

TL;DR: 本文提出CD-Mamba，一种结合卷积和Mamba状态空间模型的混合网络，用于遥感图像云检测，旨在同时捕获局部空间细节和长距离依赖关系，并取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 遥感图像常被云层遮挡，严重影响数据完整性和可靠性。有效的云检测需要同时处理云斑块的短程空间冗余和长程大气相似性。现有方法在捕获局部或长程依赖方面存在局限性。

Method: 提出CD-Mamba混合模型，将卷积神经网络（擅长捕获局部空间依赖）与Mamba的状态空间模型（擅长建模长程依赖）集成到一个统一的云检测网络中。该模型旨在全面捕获像素级纹理细节和长期的块级依赖关系。

Result: 广泛的实验验证了CD-Mamba的有效性，并证明其性能优于现有方法。

Conclusion: CD-Mamba通过同时管理像素级交互和广泛的块级依赖，显著提高了不同空间尺度下的云检测精度。

Abstract: Remote sensing images are frequently obscured by cloud cover, posing
significant challenges to data integrity and reliability. Effective cloud
detection requires addressing both short-range spatial redundancies and
long-range atmospheric similarities among cloud patches. Convolutional neural
networks are effective at capturing local spatial dependencies, while Mamba has
strong capabilities in modeling long-range dependencies. To fully leverage both
local spatial relations and long-range dependencies, we propose CD-Mamba, a
hybrid model that integrates convolution and Mamba's state-space modeling into
a unified cloud detection network. CD-Mamba is designed to comprehensively
capture pixelwise textural details and long term patchwise dependencies for
cloud detection. This design enables CD-Mamba to manage both pixel-wise
interactions and extensive patch-wise dependencies simultaneously, improving
detection accuracy across diverse spatial scales. Extensive experiments
validate the effectiveness of CD-Mamba and demonstrate its superior performance
over existing methods.

</details>


### [31] [Exploiting Unlabeled Structures through Task Consistency Training for Versatile Medical Image Segmentation](https://arxiv.org/abs/2509.04732)
*Shengqian Zhu,Jiafei Wu,Xiaogang Xu,Chengrong Yu,Ying Song,Zhang Yi,Guangjun Li,Junjie Hu*

Main category: cs.CV

TL;DR: 本文提出了一种任务一致性训练（TCT）框架，用于解决在部分标注数据集上进行多功能医学图像分割（VMIS）时因类别不平衡和标签噪声问题，该框架无需额外模型，通过一致性约束、过滤策略和统一辅助不确定性加权损失来实现。


<details>
  <summary>Details</summary>
Motivation: 多功能医学图像分割（VMIS）需要完整的类别标注，但这在实践中耗时且费力。利用部分标注数据集（PLDs）是一种有前景的替代方案，但现有方法面临严重的类别不平衡问题。现有方法通过生成伪完整标签来解决，但这通常需要额外的模型并可能因标签噪声导致性能下降。

Method: 本文引入了任务一致性训练（TCT）框架。TCT包含一个主干网络，一个用于多通道预测的主分割头（MSH）和多个用于特定任务预测的辅助任务头（ATHs）。通过在MSH和ATH预测之间施加一致性约束，TCT有效利用未标注的解剖结构。为避免低一致性、潜在噪声数据引起的错误传播，提出了一种过滤策略。此外，引入了统一辅助不确定性加权损失（UAUWL）来缓解特定任务主导导致的分割质量下降。

Result: 在来自不同临床站点的八个腹部数据集上进行的广泛实验证明了该方法的有效性。

Conclusion: TCT框架能够有效解决部分标注数据集上VMIS的类别不平衡问题，避免了额外模型的需求，并通过一致性训练、数据过滤和不确定性加权损失来提升分割性能和鲁棒性。

Abstract: Versatile medical image segmentation (VMIS) targets the segmentation of
multiple classes, while obtaining full annotations for all classes is often
impractical due to the time and labor required. Leveraging partially labeled
datasets (PLDs) presents a promising alternative; however, current VMIS
approaches face significant class imbalance due to the unequal category
distribution in PLDs. Existing methods attempt to address this by generating
pseudo-full labels. Nevertheless, these typically require additional models and
often result in potential performance degradation from label noise. In this
work, we introduce a Task Consistency Training (TCT) framework to address class
imbalance without requiring extra models. TCT includes a backbone network with
a main segmentation head (MSH) for multi-channel predictions and multiple
auxiliary task heads (ATHs) for task-specific predictions. By enforcing a
consistency constraint between the MSH and ATH predictions, TCT effectively
utilizes unlabeled anatomical structures. To avoid error propagation from
low-consistency, potentially noisy data, we propose a filtering strategy to
exclude such data. Additionally, we introduce a unified auxiliary
uncertainty-weighted loss (UAUWL) to mitigate segmentation quality declines
caused by the dominance of specific tasks. Extensive experiments on eight
abdominal datasets from diverse clinical sites demonstrate our approach's
effectiveness.

</details>


### [32] [Enhancing 3D Point Cloud Classification with ModelNet-R and Point-SkipNet](https://arxiv.org/abs/2509.05198)
*Mohammad Saeid,Amir Salarpour,Pedram MohajerAnsari*

Main category: cs.CV

TL;DR: 本文提出ModelNet-R，一个改进的3D点云分类数据集，并引入Point-SkipNet，一个轻量级图神经网络。实验证明ModelNet-R能显著提升模型性能，Point-SkipNet在ModelNet-R上以更少参数实现了最先进的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的ModelNet40数据集在3D点云分类中存在标签不一致、2D数据、尺寸不匹配和类别区分不足等局限性，阻碍了模型性能。

Method: 1. 引入ModelNet-R，一个精心改进的ModelNet40版本，旨在解决原数据集的问题。2. 提出Point-SkipNet，一个轻量级图神经网络，利用高效采样、邻域分组和跳跃连接。

Result: 1. 在ModelNet-R上训练的模型表现出显著的性能提升。2. Point-SkipNet在ModelNet-R上实现了最先进的准确率。3. Point-SkipNet与现有模型相比，参数量大幅减少。

Conclusion: 数据集质量对于优化3D点云分类模型的效率至关重要。

Abstract: The classification of 3D point clouds is crucial for applications such as
autonomous driving, robotics, and augmented reality. However, the commonly used
ModelNet40 dataset suffers from limitations such as inconsistent labeling, 2D
data, size mismatches, and inadequate class differentiation, which hinder model
performance. This paper introduces ModelNet-R, a meticulously refined version
of ModelNet40 designed to address these issues and serve as a more reliable
benchmark. Additionally, this paper proposes Point-SkipNet, a lightweight
graph-based neural network that leverages efficient sampling, neighborhood
grouping, and skip connections to achieve high classification accuracy with
reduced computational overhead. Extensive experiments demonstrate that models
trained in ModelNet-R exhibit significant performance improvements. Notably,
Point-SkipNet achieves state-of-the-art accuracy on ModelNet-R with a
substantially lower parameter count compared to contemporary models. This
research highlights the crucial role of dataset quality in optimizing model
efficiency for 3D point cloud classification. For more details, see the code
at: https://github.com/m-saeid/ModeNetR_PointSkipNet.

</details>


### [33] [Enhancing Self-Driving Segmentation in Adverse Weather Conditions: A Dual Uncertainty-Aware Training Approach to SAM Optimization](https://arxiv.org/abs/2509.04735)
*Dharsan Ravindran,Kevin Wang,Zhuoyuan Cao,Saleh Abdelrahman,Jeffery Wu*

Main category: cs.CV

TL;DR: 本文通过引入不确定性量化训练，提高了视觉基础模型（如SAM2）在恶劣天气下自动驾驶场景的分割鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管SAM和SAM2等视觉基础模型在通用图像分割方面表现出色，但它们在视觉模糊性高的恶劣天气条件下表现不佳，主要原因在于缺乏不确定性量化。受医学成像领域不确定性感知训练能提高模糊情况可靠性的启发，研究旨在提升自动驾驶的分割鲁棒性。

Method: 研究了两种方法：1. 对SAM2进行多步微调，将不确定性指标直接纳入损失函数，以改善整体场景识别。2. 将原用于医学图像分割的“不确定性感知适配器”（UAT）应用于驾驶场景。两种方法均在CamVid、BDD100K和GTA驾驶数据集上进行了评估。

Result: 实验表明，UAT-SAM在极端天气下优于标准SAM，而引入不确定性感知损失的SAM2在各种驾驶场景中均实现了性能提升。

Conclusion: 这些发现强调了在挑战性环境中为安全关键型自动驾驶进行显式不确定性建模的价值。

Abstract: Recent advances in vision foundation models, such as the Segment Anything
Model (SAM) and its successor SAM2, have achieved state-of-the-art performance
on general image segmentation benchmarks. However, these models struggle in
adverse weather conditions where visual ambiguity is high, largely due to their
lack of uncertainty quantification. Inspired by progress in medical imaging,
where uncertainty-aware training has improved reliability in ambiguous cases,
we investigate two approaches to enhance segmentation robustness for autonomous
driving. First, we introduce a multi-step finetuning procedure for SAM2 that
incorporates uncertainty metrics directly into the loss function, improving
overall scene recognition. Second, we adapt the Uncertainty-Aware Adapter
(UAT), originally designed for medical image segmentation, to driving contexts.
We evaluate both methods on CamVid, BDD100K, and GTA driving datasets.
Experiments show that UAT-SAM outperforms standard SAM in extreme weather,
while SAM2 with uncertainty-aware loss achieves improved performance across
diverse driving scenes. These findings underscore the value of explicit
uncertainty modeling for safety-critical autonomous driving in challenging
environments.

</details>


### [34] [WatchHAR: Real-time On-device Human Activity Recognition System for Smartwatches](https://arxiv.org/abs/2509.04736)
*Taeyoung Yeon,Vasco Xu,Henry Hoffmann,Karan Ahuja*

Main category: cs.CV

TL;DR: WatchHAR是一个基于智能手表的音频和惯性传感器的人类活动识别（HAR）系统，它完全在设备上运行，解决了隐私和延迟问题，并实现了高性能。


<details>
  <summary>Details</summary>
Motivation: 尽管细粒度HAR取得了进展，但完全在智能手表上、在无约束环境下运行的系统仍然难以实现，现有方案存在外部数据处理带来的隐私和延迟问题。

Method: WatchHAR利用音频和惯性传感器数据，优化了管道中的每个组件，并引入了一种新颖的架构，将传感器数据预处理和推理统一到一个端到端可训练的模块中，以实现更快的处理速度和高准确性。

Result: WatchHAR实现了5倍更快的处理速度，在超过25种活动类别中保持了90%以上的准确率。它在智能手表上直接运行时，在事件检测和活动分类方面均优于最先进的模型，活动事件检测处理时间为9.3毫秒，多模态活动分类处理时间为11.8毫秒。

Conclusion: 这项研究推动了设备上活动识别技术的发展，实现了智能手表作为独立的、隐私保护的、微创的连续活动跟踪设备的潜力。

Abstract: Despite advances in practical and multimodal fine-grained Human Activity
Recognition (HAR), a system that runs entirely on smartwatches in unconstrained
environments remains elusive. We present WatchHAR, an audio and inertial-based
HAR system that operates fully on smartwatches, addressing privacy and latency
issues associated with external data processing. By optimizing each component
of the pipeline, WatchHAR achieves compounding performance gains. We introduce
a novel architecture that unifies sensor data preprocessing and inference into
an end-to-end trainable module, achieving 5x faster processing while
maintaining over 90% accuracy across more than 25 activity classes. WatchHAR
outperforms state-of-the-art models for event detection and activity
classification while running directly on the smartwatch, achieving 9.3 ms
processing time for activity event detection and 11.8 ms for multimodal
activity classification. This research advances on-device activity recognition,
realizing smartwatches' potential as standalone, privacy-aware, and
minimally-invasive continuous activity tracking devices.

</details>


### [35] [MCANet: A Multi-Scale Class-Specific Attention Network for Multi-Label Post-Hurricane Damage Assessment using UAV Imagery](https://arxiv.org/abs/2509.04757)
*Zhangding Liu,Neda Mohammadi,John E. Taylor*

Main category: cs.CV

TL;DR: MCANet是一个多标签分类框架，旨在通过学习多尺度表示和自适应关注空间相关区域，解决现有CNN方法在飓风后损害评估中难以捕捉多尺度特征和区分相似损害类型的问题。


<details>
  <summary>Details</summary>
Motivation: 飓风后快速准确的损害评估对于灾害响应和恢复至关重要。然而，现有的基于CNN的方法难以捕捉多尺度空间特征，并且难以区分视觉上相似或同时发生的损害类型。

Method: 该论文提出了MCANet框架。它采用基于Res2Net的层次化骨干网络来丰富跨尺度的空间上下文，并使用多头类别特定的残差注意力模块来增强区分能力。每个注意力分支专注于不同的空间粒度，平衡局部细节和全局上下文。MCANet在Hurricane Michael后的4,494张无人机图像组成的RescueNet数据集上进行了评估。

Result: MCANet在RescueNet数据集上实现了91.75%的平均精度均值（mAP），优于ResNet、Res2Net、VGG、MobileNet、EfficientNet和ViT等模型。使用八个注意力头时，性能进一步提升至92.35%，使“道路堵塞”等挑战性类别的平均精度提高了6%以上。类别激活映射证实了MCANet定位损害相关区域的能力，支持了可解释性。

Conclusion: MCANet有效解决了多尺度特征捕获和相似损害类型区分的挑战，其输出可为灾后风险测绘、紧急路线规划和基于数字孪生的灾害响应提供信息。未来的工作可以整合灾害特定知识图谱和多模态大型语言模型，以提高对未知灾害的适应性和丰富语义理解，从而支持实际决策。

Abstract: Rapid and accurate post-hurricane damage assessment is vital for disaster
response and recovery. Yet existing CNN-based methods struggle to capture
multi-scale spatial features and to distinguish visually similar or
co-occurring damage types. To address these issues, we propose MCANet, a
multi-label classification framework that learns multi-scale representations
and adaptively attends to spatially relevant regions for each damage category.
MCANet employs a Res2Net-based hierarchical backbone to enrich spatial context
across scales and a multi-head class-specific residual attention module to
enhance discrimination. Each attention branch focuses on different spatial
granularities, balancing local detail with global context. We evaluate MCANet
on the RescueNet dataset of 4,494 UAV images collected after Hurricane Michael.
MCANet achieves a mean average precision (mAP) of 91.75%, outperforming ResNet,
Res2Net, VGG, MobileNet, EfficientNet, and ViT. With eight attention heads,
performance further improves to 92.35%, boosting average precision for
challenging classes such as Road Blocked by over 6%. Class activation mapping
confirms MCANet's ability to localize damage-relevant regions, supporting
interpretability. Outputs from MCANet can inform post-disaster risk mapping,
emergency routing, and digital twin-based disaster response. Future work could
integrate disaster-specific knowledge graphs and multimodal large language
models to improve adaptability to unseen disasters and enrich semantic
understanding for real-world decision-making.

</details>


### [36] [Dynamic Group Detection using VLM-augmented Temporal Groupness Graph](https://arxiv.org/abs/2509.04758)
*Kaname Yokoyama,Chihiro Nakatani,Norimichi Ukita*

Main category: cs.CV

TL;DR: 该论文提出了一种在视频中动态检测人类群体的方法，通过增强的视觉-语言模型（VLM）提取局部和全局特征，并使用全局优化来处理群体随时间的变化，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 检测复杂群体不仅需要群内成员的局部特征，还需要场景的全局上下文。此外，群体结构应随时间保持一致，而现有方法通常假设群体在视频中不变，无法处理动态变化的群体。

Method: 该方法使用一个针对群体检测进行增强的视觉-语言模型（VLM）来提取每帧的局部和全局外观特征。通过对CLIP特征进行“群体性”增强，估算每帧的群体概率。然后，利用包含所有帧群体概率的图进行全局优化，以检测动态变化的群体。

Result: 实验结果表明，该方法在公共数据集上优于现有的最先进的群体检测方法。

Conclusion: 该论文提出了一种有效的动态人类群体检测方法，通过结合VLM提取的局部/全局特征和基于全局优化的时间一致性处理，成功解决了视频中复杂和动态群体检测的挑战。

Abstract: This paper proposes dynamic human group detection in videos. For detecting
complex groups, not only the local appearance features of in-group members but
also the global context of the scene are important. Such local and global
appearance features in each frame are extracted using a Vision-Language Model
(VLM) augmented for group detection in our method. For further improvement, the
group structure should be consistent over time. While previous methods are
stabilized on the assumption that groups are not changed in a video, our method
detects dynamically changing groups by global optimization using a graph with
all frames' groupness probabilities estimated by our groupness-augmented CLIP
features. Our experimental results demonstrate that our method outperforms
state-of-the-art group detection methods on public datasets. Code:
https://github.com/irajisamurai/VLM-GroupDetection.git

</details>


### [37] [FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph](https://arxiv.org/abs/2509.04772)
*Zhangding Liu,Neda Mohammadi,John E. Taylor*

Main category: cs.CV

TL;DR: 本文提出FloodVision，一个结合GPT-4o视觉语言模型和结构化领域知识图谱的零样本框架，用于准确、泛化性强的洪水深度估计，其在实际图像上显著优于基线和现有方法。


<details>
  <summary>Details</summary>
Motivation: 及时准确的洪水深度估计对于道路通行和应急响应至关重要。现有计算机视觉方法在洪水检测方面存在准确性限制和泛化能力差的问题，因为它们依赖于固定对象检测器和特定任务训练。

Method: FloodVision是一个零样本框架，它结合了基础视觉语言模型GPT-4o的语义推理能力和一个结构化的领域知识图谱。该知识图谱编码了常见城市物体（如车辆、人员、基础设施）的规范真实世界尺寸。FloodVision动态识别RGB图像中的可见参考物体，从知识图谱中检索验证过的高度以减少幻觉，估计淹没比例，并应用统计异常值过滤来计算最终深度值。

Result: 在来自MyCoast New York的110张众包图像上进行评估，FloodVision实现了8.17厘米的平均绝对误差，将GPT-4o基线的10.28厘米降低了20.5%，并超越了之前的基于CNN的方法。该系统在不同场景下表现出良好的泛化能力，并能近实时运行。

Conclusion: FloodVision系统在不同场景下具有良好的泛化能力并能近实时运行，使其适用于未来集成到数字孪生平台和公民报告应用程序中，以增强智慧城市的洪水韧性。

Abstract: Timely and accurate floodwater depth estimation is critical for road
accessibility and emergency response. While recent computer vision methods have
enabled flood detection, they suffer from both accuracy limitations and poor
generalization due to dependence on fixed object detectors and task-specific
training. To enable accurate depth estimation that can generalize across
diverse flood scenarios, this paper presents FloodVision, a zero-shot framework
that combines the semantic reasoning abilities of the foundation
vision-language model GPT-4o with a structured domain knowledge graph. The
knowledge graph encodes canonical real-world dimensions for common urban
objects including vehicles, people, and infrastructure elements to ground the
model's reasoning in physical reality. FloodVision dynamically identifies
visible reference objects in RGB images, retrieves verified heights from the
knowledge graph to mitigate hallucination, estimates submergence ratios, and
applies statistical outlier filtering to compute final depth values. Evaluated
on 110 crowdsourced images from MyCoast New York, FloodVision achieves a mean
absolute error of 8.17 cm, reducing the GPT-4o baseline 10.28 cm by 20.5% and
surpassing prior CNN-based methods. The system generalizes well across varying
scenes and operates in near real-time, making it suitable for future
integration into digital twin platforms and citizen-reporting apps for smart
city flood resilience.

</details>


### [38] [Hybrid-Tower: Fine-grained Pseudo-query Interaction and Generation for Text-to-Video Retrieval](https://arxiv.org/abs/2509.04773)
*Bangxiang Lan,Ruobing Xie,Ruixiang Zhao,Xingwu Sun,Zhanhui Kang,Gang Yang,Xirong Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为 PIG 的混合塔（Hybrid-Tower）框架，用于文本到视频检索（T2VR），通过生成伪查询实现视频特征与文本特征的细粒度交互，从而同时提高检索的有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 CLIP 的文本到视频检索方法在双塔（Two-Tower）框架下效率高但效果差，而单塔（Single-Tower）框架下效果好但效率低，缺乏一种能兼顾两者优点的方案。

Method: 本文提出了一种新的混合塔框架和一种名为 PIG（Fine-grained Pseudo-query Interaction and Generation）的混合方法。PIG 包含一个伪查询生成器，为每个视频生成伪查询，使其视频特征能与伪查询的文本特征进行细粒度交互，从而在未接收到真实查询前就达到高有效性。同时，该方法在推理阶段不增加额外的存储或计算开销，保持了高效率。

Result: 在五个常用的文本-视频检索基准测试中，该方法比基线模型显著提高了 1.6% 到 3.9% 的 R@1 指标。此外，该方法在保持与双塔模型相同效率的同时，达到了接近最先进的性能。

Conclusion: 混合塔框架及其 PIG 方法成功地结合了双塔框架的效率和单塔框架的有效性，为文本到视频检索任务提供了一个高性能且高效率的解决方案。

Abstract: The Text-to-Video Retrieval (T2VR) task aims to retrieve unlabeled videos by
textual queries with the same semantic meanings. Recent CLIP-based approaches
have explored two frameworks: Two-Tower versus Single-Tower framework, yet the
former suffers from low effectiveness, while the latter suffers from low
efficiency. In this study, we explore a new Hybrid-Tower framework that can
hybridize the advantages of the Two-Tower and Single-Tower framework, achieving
high effectiveness and efficiency simultaneously. We propose a novel hybrid
method, Fine-grained Pseudo-query Interaction and Generation for T2VR, ie, PIG,
which includes a new pseudo-query generator designed to generate a pseudo-query
for each video. This enables the video feature and the textual features of
pseudo-query to interact in a fine-grained manner, similar to the Single-Tower
approaches to hold high effectiveness, even before the real textual query is
received. Simultaneously, our method introduces no additional storage or
computational overhead compared to the Two-Tower framework during the inference
stage, thus maintaining high efficiency. Extensive experiments on five commonly
used text-video retrieval benchmarks demonstrate that our method achieves a
significant improvement over the baseline, with an increase of $1.6\% \sim
3.9\%$ in R@1. Furthermore, our method matches the efficiency of Two-Tower
models while achieving near state-of-the-art performance, highlighting the
advantages of the Hybrid-Tower framework.

</details>


### [39] [MLP-SRGAN: A Single-Dimension Super Resolution GAN using MLP-Mixer](https://arxiv.org/abs/2303.06298)
*Samir Mitha,Seungho Choe,Pejman Jahbedar Maralani,Alan R. Moody,April Khademi*

Main category: cs.CV

TL;DR: 本文提出了一种名为MLP-SRGAN的新型单维度超分辨率生成对抗网络架构，它结合了多层感知器混频器（MLP-Mixer）和卷积层，用于切片方向的图像上采样，并在MRI图像超分辨率任务中表现出优于现有方法的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有超分辨率网络在MRI图像的单维度（切片方向）上采样方面可能存在局限性，导致边缘不清晰、细节丢失或模型效率低下。研究旨在开发一种更有效的架构，以改善低空间分辨率MRI图像的质量，尤其是在缺乏高分辨率真实图像的情况下。

Method: 研究提出MLP-SRGAN，一个结合MLP-Mixer和卷积层的单维度SRGAN，用于切片方向的上采样。该模型使用MSSEG2挑战数据集中的高分辨率FLAIR MRI进行训练和验证。它被应用于CAIN、ADNI、CCNA三个多中心FLAIR数据集，以评估其在未见临床数据上的性能。性能评估使用PSNR和SSIM（有真实图像时），并提出了新的无参考图像质量指标（用于量化清晰度、噪声和模糊度，在无真实图像时）进行比较。

Result: MLP-SRGAN生成的结果具有更锐利的边缘、更少的模糊、保留了更多的纹理和精细解剖细节。与现有方法相比，它拥有更少的参数、更快的训练/评估时间以及更小的模型尺寸。

Conclusion: MLP-SRGAN是一种高效且高性能的单维度超分辨率方法，特别适用于MRI图像的切片方向上采样，它在提高图像质量（如锐度、细节保留）和操作效率（更少的参数、更快的速度、更小的模型）方面优于现有技术。

Abstract: We propose a novel architecture called MLP-SRGAN, which is a single-dimension
Super Resolution Generative Adversarial Network (SRGAN) that utilizes
Multi-Layer Perceptron Mixers (MLP-Mixers) along with convolutional layers to
upsample in the slice direction. MLP-SRGAN is trained and validated using high
resolution (HR) FLAIR MRI from the MSSEG2 challenge dataset. The method was
applied to three multicentre FLAIR datasets (CAIN, ADNI, CCNA) of images with
low spatial resolution in the slice dimension to examine performance on
held-out (unseen) clinical data. Upsampled results are compared to several
state-of-the-art SR networks. For images with high resolution (HR) ground
truths, peak-signal-to-noise-ratio (PSNR) and structural similarity index
(SSIM) are used to measure upsampling performance. Several new structural,
no-reference image quality metrics were proposed to quantify sharpness (edge
strength), noise (entropy), and blurriness (low frequency information) in the
absence of ground truths. Results show MLP-SRGAN results in sharper edges, less
blurring, preserves more texture and fine-anatomical detail, with fewer
parameters, faster training/evaluation time, and smaller model size than
existing methods. Code for MLP-SRGAN training and inference, data generators,
models and no-reference image quality metrics will be available at
https://github.com/IAMLAB-Ryerson/MLP-SRGAN.

</details>


### [40] [Comparative Evaluation of Traditional and Deep Learning Feature Matching Algorithms using Chandrayaan-2 Lunar Data](https://arxiv.org/abs/2509.04775)
*R. Makharia,J. G. Singla,Amitabh,N. Dube,H. Sharma*

Main category: cs.CV

TL;DR: 该研究评估了多种特征匹配算法在月球跨模态图像配准中的性能，发现SuperGlue表现最佳，并强调了预处理和学习方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 月球探测需要精确的图像配准来实现表面测绘、资源定位和任务规划。然而，来自不同月球传感器（光学、高光谱、雷达）的数据因分辨率、光照和传感器畸变差异，导致数据对齐极具挑战性。

Method: 研究评估了五种特征匹配算法：SIFT、ASIFT、AKAZE、RIFT2和SuperGlue（一种基于深度学习的匹配器），使用了来自赤道和极地地区的跨模态图像对。同时，提出了一套预处理流程，包括地理配准、分辨率对齐、强度归一化以及自适应直方图均衡化、主成分分析和阴影校正等增强技术。

Result: SuperGlue持续产生最低的均方根误差和最快的运行时间。SIFT和AKAZE等经典方法在赤道附近表现良好，但在极地光照条件下性能下降。

Conclusion: 研究结果强调了预处理和基于学习的方法对于在不同条件下实现鲁棒月球图像配准的重要性。

Abstract: Accurate image registration is critical for lunar exploration, enabling
surface mapping, resource localization, and mission planning. Aligning data
from diverse lunar sensors -- optical (e.g., Orbital High Resolution Camera,
Narrow and Wide Angle Cameras), hyperspectral (Imaging Infrared Spectrometer),
and radar (e.g., Dual-Frequency Synthetic Aperture Radar, Selene/Kaguya
mission) -- is challenging due to differences in resolution, illumination, and
sensor distortion. We evaluate five feature matching algorithms: SIFT, ASIFT,
AKAZE, RIFT2, and SuperGlue (a deep learning-based matcher), using
cross-modality image pairs from equatorial and polar regions. A preprocessing
pipeline is proposed, including georeferencing, resolution alignment, intensity
normalization, and enhancements like adaptive histogram equalization, principal
component analysis, and shadow correction. SuperGlue consistently yields the
lowest root mean square error and fastest runtimes. Classical methods such as
SIFT and AKAZE perform well near the equator but degrade under polar lighting.
The results highlight the importance of preprocessing and learning-based
approaches for robust lunar image registration across diverse conditions.

</details>


### [41] [Toward Accessible Dermatology: Skin Lesion Classification Using Deep Learning Models on Mobile-Acquired Images](https://arxiv.org/abs/2509.04800)
*Asif Newaz,Masum Mushfiq Ishti,A Z M Ashraful Azam,Asif Ur Rahman Adib*

Main category: cs.CV

TL;DR: 本研究通过手机采集的图像构建了一个包含50多种皮肤病的大型数据集，并发现Transformer模型（特别是Swin Transformer）在皮肤病分类上优于CNN，结合Grad-CAM提升了可解释性，为资源匮乏地区的AI辅助皮肤病诊断提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 传统的皮肤病诊断方法成本高、复杂且在资源匮乏地区难以获得。现有的深度学习研究多局限于皮肤镜数据集和少数疾病类别，无法代表真实的临床条件。

Method: 研究人员策划并构建了一个包含50多种皮肤病类别的大型数据集，图像通过移动设备采集，更具真实世界代表性。他们评估了多种卷积神经网络（CNN）和基于Transformer的架构，并特别关注了Swin Transformer。为了增强模型的可解释性，引入了梯度加权类激活映射（Grad-CAM）。

Result: Transformer模型，特别是Swin Transformer，通过有效捕获全局上下文特征，取得了优越的性能。Grad-CAM成功突出了临床相关的区域，并为模型预测提供了透明度。

Conclusion: 研究结果强调了基于Transformer的方法在手机采集皮肤病变分类方面的潜力，为在资源有限的环境中实现可及的AI辅助皮肤病筛查和早期诊断铺平了道路。

Abstract: Skin diseases are among the most prevalent health concerns worldwide, yet
conventional diagnostic methods are often costly, complex, and unavailable in
low-resource settings. Automated classification using deep learning has emerged
as a promising alternative, but existing studies are mostly limited to
dermoscopic datasets and a narrow range of disease classes. In this work, we
curate a large dataset of over 50 skin disease categories captured with mobile
devices, making it more representative of real-world conditions. We evaluate
multiple convolutional neural networks and Transformer-based architectures,
demonstrating that Transformer models, particularly the Swin Transformer,
achieve superior performance by effectively capturing global contextual
features. To enhance interpretability, we incorporate Gradient-weighted Class
Activation Mapping (Grad-CAM), which highlights clinically relevant regions and
provides transparency in model predictions. Our results underscore the
potential of Transformer-based approaches for mobile-acquired skin lesion
classification, paving the way toward accessible AI-assisted dermatological
screening and early diagnosis in resource-limited environments.

</details>


### [42] [Extracting Uncertainty Estimates from Mixtures of Experts for Semantic Segmentation](https://arxiv.org/abs/2509.04816)
*Svetlana Pavlitska,Beyza Keskin,Alwin Faßbender,Christian Hubschneider,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 该研究表明，混合专家模型（MoE）能从计算机视觉模型中提取准确且校准良好的预测不确定性，比集成方法更可靠，尤其是在分布外数据下，且无需修改架构。


<details>
  <summary>Details</summary>
Motivation: 在交通场景感知等安全关键应用中，准确且校准良好的预测不确定性对于提高计算机视觉模型的可靠性至关重要。虽然集成方法常用于量化不确定性，但混合专家模型（MoE）通过门控网络动态加权专家预测，提供了一种更高效的替代方案。

Method: 研究基于之前工作中MoE在语义分割上的应用，探讨了三种从MoE中提取预测不确定性的方法：预测熵、互信息和专家方差。这些方法在一个包含两个专家且在A2D2数据集语义分割上训练的MoE模型上进行评估。此外，还通过门控熵评估了路由不确定性，并比较了简单门控机制与更复杂的类别门控。最后，在Cityscapes数据集上验证了增加专家数量对不确定性校准的影响。

Result: 结果显示，在分布外（OOD）数据下，MoE在条件正确性指标方面比集成方法产生更可靠的不确定性估计。简单的门控机制比复杂的类别门控能更好地校准路由不确定性估计。在Cityscapes数据集上的实验表明，增加专家数量可以进一步增强不确定性校准。

Conclusion: 混合专家模型（MoE）无需架构修改即可提供准确且校准良好的预测不确定性估计，其可靠性优于集成方法，尤其是在处理分布外数据时。简单的门控机制有助于更好的路由不确定性校准，且增加专家数量能进一步提升不确定性校准效果。

Abstract: Estimating accurate and well-calibrated predictive uncertainty is important
for enhancing the reliability of computer vision models, especially in
safety-critical applications like traffic scene perception. While ensemble
methods are commonly used to quantify uncertainty by combining multiple models,
a mixture of experts (MoE) offers an efficient alternative by leveraging a
gating network to dynamically weight expert predictions based on the input.
Building on the promising use of MoEs for semantic segmentation in our previous
works, we show that well-calibrated predictive uncertainty estimates can be
extracted from MoEs without architectural modifications. We investigate three
methods to extract predictive uncertainty estimates: predictive entropy, mutual
information, and expert variance. We evaluate these methods for an MoE with two
experts trained on a semantical split of the A2D2 dataset. Our results show
that MoEs yield more reliable uncertainty estimates than ensembles in terms of
conditional correctness metrics under out-of-distribution (OOD) data.
Additionally, we evaluate routing uncertainty computed via gate entropy and
find that simple gating mechanisms lead to better calibration of routing
uncertainty estimates than more complex classwise gates. Finally, our
experiments on the Cityscapes dataset suggest that increasing the number of
experts can further enhance uncertainty calibration. Our code is available at
https://github.com/KASTEL-MobilityLab/mixtures-of-experts/.

</details>


### [43] [Exploring Non-Local Spatial-Angular Correlations with a Hybrid Mamba-Transformer Framework for Light Field Super-Resolution](https://arxiv.org/abs/2509.04824)
*Haosong Liu,Xiancheng Zhu,Huanqiang Zeng,Jianqing Zhu,Jiuwen Cao,Junhui Hou*

Main category: cs.CV

TL;DR: 本文提出了一种名为LFMT的混合Mamba-Transformer框架，通过子空间简单扫描策略和双阶段建模策略，解决了现有Mamba方法在光场超分辨率（LFSR）中特征提取效率低和信息保存不足的问题，显著提升了LFSR性能并保持了较低的计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有基于Mamba的方法在光场图像超分辨率（LFSR）中展现潜力，但在复杂光场数据上，多方向扫描策略导致特征提取效率低下且冗余。此外，状态空间模型在保留空间-角度和视差信息方面存在局限性，未能充分探索非局部空间-角度相关性。

Method: 本文提出以下方法：1. 子空间简单扫描（Sub-SS）策略及子空间简单Mamba块（SSMB），以实现更高效和精确的特征提取。2. 双阶段建模策略，用于全面探索非局部空间-角度相关性：第一阶段引入空间-角度残差子空间Mamba块（SA-RSMB）进行浅层空间-角度特征提取；第二阶段采用双分支并行结构，结合极平面Mamba块（EPMB）和极平面Transformer块（EPTB）进行深层极平面特征细化。3. 构建了混合Mamba-Transformer框架LFMT，整合了Mamba和Transformer模型的优势，以全面探索空间、角度和极平面域的信息。

Result: 实验结果表明，LFMT在LFSR任务中显著优于当前最先进的方法，在真实和合成光场数据集上均实现了显著的性能提升，同时保持了较低的计算复杂度。

Conclusion: LFMT框架成功地将Mamba和Transformer的优势结合起来，通过创新的子空间扫描和双阶段建模策略，有效解决了光场超分辨率中特征提取和多维度信息探索的挑战，实现了卓越的性能和计算效率。

Abstract: Recently, Mamba-based methods, with its advantage in long-range information
modeling and linear complexity, have shown great potential in optimizing both
computational cost and performance of light field image super-resolution
(LFSR). However, current multi-directional scanning strategies lead to
inefficient and redundant feature extraction when applied to complex LF data.
To overcome this challenge, we propose a Subspace Simple Scanning (Sub-SS)
strategy, based on which we design the Subspace Simple Mamba Block (SSMB) to
achieve more efficient and precise feature extraction. Furthermore, we propose
a dual-stage modeling strategy to address the limitation of state space in
preserving spatial-angular and disparity information, thereby enabling a more
comprehensive exploration of non-local spatial-angular correlations.
Specifically, in stage I, we introduce the Spatial-Angular Residual Subspace
Mamba Block (SA-RSMB) for shallow spatial-angular feature extraction; in stage
II, we use a dual-branch parallel structure combining the Epipolar Plane Mamba
Block (EPMB) and Epipolar Plane Transformer Block (EPTB) for deep epipolar
feature refinement. Building upon meticulously designed modules and strategies,
we introduce a hybrid Mamba-Transformer framework, termed LFMT. LFMT integrates
the strengths of Mamba and Transformer models for LFSR, enabling comprehensive
information exploration across spatial, angular, and epipolar-plane domains.
Experimental results demonstrate that LFMT significantly outperforms current
state-of-the-art methods in LFSR, achieving substantial improvements in
performance while maintaining low computational complexity on both real-word
and synthetic LF datasets.

</details>


### [44] [PropVG: End-to-End Proposal-Driven Visual Grounding with Multi-Granularity Discrimination](https://arxiv.org/abs/2509.04833)
*Ming Dai,Wenxuan Cheng,Jiedong Zhuang,Jiang-jiang Liu,Hongshen Zhao,Zhenhua Feng,Wankou Yang*

Main category: cs.CV

TL;DR: PropVG是一个端到端、基于提议的视觉定位框架，它将前景对象提议生成与参照对象理解无缝集成，并引入了对比参照评分（CRS）模块和多粒度目标判别（MTD）模块，以解决现有方法效率低下、忽略前景目标和缺乏多粒度判别的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉定位方法大多从传统的两阶段框架转向端到端直接参照范式，但它们过度依赖被参照目标进行监督，忽略了显著前景目标的潜在益处。此外，现有方法通常未能整合多粒度判别，这对于复杂场景中的鲁棒对象识别至关重要。

Method: 本文提出了PropVG，一个端到端、基于提议的框架，首次在不额外引入检测器的情况下，将前景对象提议生成与参照对象理解无缝集成。PropVG引入了对比参照评分（CRS）模块，该模块在句子和词语层面采用对比学习，以增强理解和区分参照对象的能力。此外，还设计了多粒度目标判别（MTD）模块，融合对象级和语义级信息，以改进对缺失目标的识别。

Result: 在gRefCOCO (GREC/GRES)、Ref-ZOM、R-RefCOCO和RefCOCO (REC/RES) 基准上的广泛实验证明了PropVG的有效性。

Conclusion: PropVG通过其创新的端到端提议集成、对比学习和多粒度判别机制，显著提升了视觉定位任务的性能和鲁棒性。

Abstract: Recent advances in visual grounding have largely shifted away from
traditional proposal-based two-stage frameworks due to their inefficiency and
high computational complexity, favoring end-to-end direct reference paradigms.
However, these methods rely exclusively on the referred target for supervision,
overlooking the potential benefits of prominent prospective targets. Moreover,
existing approaches often fail to incorporate multi-granularity discrimination,
which is crucial for robust object identification in complex scenarios. To
address these limitations, we propose PropVG, an end-to-end proposal-based
framework that, to the best of our knowledge, is the first to seamlessly
integrate foreground object proposal generation with referential object
comprehension without requiring additional detectors. Furthermore, we introduce
a Contrastive-based Refer Scoring (CRS) module, which employs contrastive
learning at both sentence and word levels to enhance the capability in
understanding and distinguishing referred objects. Additionally, we design a
Multi-granularity Target Discrimination (MTD) module that fuses object- and
semantic-level information to improve the recognition of absent targets.
Extensive experiments on gRefCOCO (GREC/GRES), Ref-ZOM, R-RefCOCO, and RefCOCO
(REC/RES) benchmarks demonstrate the effectiveness of PropVG. The codes and
models are available at https://github.com/Dmmm1997/PropVG.

</details>


### [45] [TemporalFlowViz: Parameter-Aware Visual Analytics for Interpreting Scramjet Combustion Evolution](https://arxiv.org/abs/2509.04834)
*Yifei Jia,Shiyu Cheng,Yu Dong,Guan Li,Dong Tian,Ruixiao Peng,Xuyi Lu,Yu Wang,Wei Yao,Guihua Shan*

Main category: cs.CV

TL;DR: TemporalFlowViz是一个参数感知的可视化分析系统，旨在通过结合视觉转换器、降维聚类和视觉语言模型，支持专家对超燃冲压发动机燃烧模拟中的大规模时序流场数据进行聚类、可视化和解释，从而促进模式发现和知识获取。


<details>
  <summary>Details</summary>
Motivation: 超燃冲压发动机中复杂的燃烧动力学对于高速推进技术至关重要。然而，模拟生成的大规模、高维时序流场数据在视觉解释、特征区分和跨案例比较方面带来了显著挑战。

Method: TemporalFlowViz系统采用以下方法：1) 利用预训练的视觉转换器从时序流场图像中提取高维嵌入。2) 应用降维和基于密度的聚类来揭示潜在的燃烧模式。3) 在嵌入空间中构建时间轨迹以追踪模拟演变。4) 领域专家标注代表性聚类中心，作为视觉语言模型的上下文提示，生成帧和完整模拟案例的自然语言摘要。5) 支持基于参数的过滤、基于相似性的案例检索和协调多视图探索。

Result: 通过两个专家知情的案例研究和专家反馈，TemporalFlowViz被证明能够增强假设生成、支持可解释的模式发现，并促进大规模超燃冲压发动机燃烧分析中的知识发现。

Conclusion: TemporalFlowViz是一个有效的参数感知可视化分析工作流和系统，能够帮助专家对超燃冲压发动机燃烧模拟中的复杂时序流场数据进行深入分析、模式识别和知识获取。

Abstract: Understanding the complex combustion dynamics within scramjet engines is
critical for advancing high-speed propulsion technologies. However, the large
scale and high dimensionality of simulation-generated temporal flow field data
present significant challenges for visual interpretation, feature
differentiation, and cross-case comparison. In this paper, we present
TemporalFlowViz, a parameter-aware visual analytics workflow and system
designed to support expert-driven clustering, visualization, and interpretation
of temporal flow fields from scramjet combustion simulations. Our approach
leverages hundreds of simulated combustion cases with varying initial
conditions, each producing time-sequenced flow field images. We use pretrained
Vision Transformers to extract high-dimensional embeddings from these frames,
apply dimensionality reduction and density-based clustering to uncover latent
combustion modes, and construct temporal trajectories in the embedding space to
track the evolution of each simulation over time. To bridge the gap between
latent representations and expert reasoning, domain specialists annotate
representative cluster centroids with descriptive labels. These annotations are
used as contextual prompts for a vision-language model, which generates
natural-language summaries for individual frames and full simulation cases. The
system also supports parameter-based filtering, similarity-based case
retrieval, and coordinated multi-view exploration to facilitate in-depth
analysis. We demonstrate the effectiveness of TemporalFlowViz through two
expert-informed case studies and expert feedback, showing TemporalFlowViz
enhances hypothesis generation, supports interpretable pattern discovery, and
enhances knowledge discovery in large-scale scramjet combustion analysis.

</details>


### [46] [Pose-Free 3D Quantitative Phase Imaging of Flowing Cellular Populations](https://arxiv.org/abs/2509.04848)
*Enze Ye,Wei Lin,Shaochi Ren,Yakun Liu,Xiaoping Li,Hao Wang,He Sun,Feng Pan*

Main category: cs.CV

TL;DR: OmniFHT是一种新型的无姿态3D折射率（RI）重建框架，结合傅里叶衍射定理和隐式神经表示（INRs），首次实现了流式细胞术中对所有流动细胞群体的原位、高通量断层成像，克服了现有方法对细胞形状和旋转的限制。


<details>
  <summary>Details</summary>
Motivation: 现有高通量3D定量相位成像（QPI）方法假设细胞进行均匀的单轴旋转且姿态已知，这限制了其仅适用于近球形细胞，无法准确成像不规则形状细胞的复杂旋转，导致只能分析部分细胞群体，限制了流式分析的统计鲁棒性。

Method: 该研究引入了OmniFHT框架，利用傅里叶衍射定理和隐式神经表示（INRs）进行高通量流式细胞术断层成像。它在弱散射假设下，联合优化每个细胞的未知旋转轨迹和体积结构，从而实现无姿态的3D RI重建。

Result: OmniFHT支持任意细胞几何形状和多轴旋转。其连续表示允许从稀疏采样投影和受限角度范围（例如，仅10个视图或120度角范围）进行准确重建，产生高保真结果。首次实现了对整个流动细胞群体的原位、高通量断层成像。

Conclusion: OmniFHT为流式细胞术平台提供了一种可扩展且无偏的无标记形态分析解决方案，首次实现了对所有流动细胞群体的原位、高通量断层成像。

Abstract: High-throughput 3D quantitative phase imaging (QPI) in flow cytometry enables
label-free, volumetric characterization of individual cells by reconstructing
their refractive index (RI) distributions from multiple viewing angles during
flow through microfluidic channels. However, current imaging methods assume
that cells undergo uniform, single-axis rotation, which require their poses to
be known at each frame. This assumption restricts applicability to
near-spherical cells and prevents accurate imaging of irregularly shaped cells
with complex rotations. As a result, only a subset of the cellular population
can be analyzed, limiting the ability of flow-based assays to perform robust
statistical analysis. We introduce OmniFHT, a pose-free 3D RI reconstruction
framework that leverages the Fourier diffraction theorem and implicit neural
representations (INRs) for high-throughput flow cytometry tomographic imaging.
By jointly optimizing each cell's unknown rotational trajectory and volumetric
structure under weak scattering assumptions, OmniFHT supports arbitrary cell
geometries and multi-axis rotations. Its continuous representation also allows
accurate reconstruction from sparsely sampled projections and restricted
angular coverage, producing high-fidelity results with as few as 10 views or
only 120 degrees of angular range. OmniFHT enables, for the first time, in
situ, high-throughput tomographic imaging of entire flowing cell populations,
providing a scalable and unbiased solution for label-free morphometric analysis
in flow cytometry platforms.

</details>


### [47] [CoRe-GS: Coarse-to-Refined Gaussian Splatting with Semantic Object Focus](https://arxiv.org/abs/2509.04859)
*Hannah Schieber,Dominik Frischmann,Simon Boche,Victor Schaack,Angela Schoellig,Stefan Leutenegger,Daniel Roth*

Main category: cs.CV

TL;DR: 本文提出CoRe-GS，一种针对自主航空机器人移动重建的方法，通过结合语义高斯溅射和新颖的基于颜色的过滤，实现更快、更高质量的特定对象（兴趣点）3D重建，减少训练时间并提高新视图合成质量。


<details>
  <summary>Details</summary>
Motivation: 远程指导和灾害响应等关键应用需要准确的3D重建和快速场景处理。详细重建整个场景效率低下，而关注特定对象（兴趣点）更有效。高斯溅射（GS）在高质量新视图合成和3D表示方面前景广阔，但需要优化训练时间，尤其是在关注特定对象时。

Method: 本文提出了CoRe-GS方法。首先，使用语义高斯溅射生成一个粗略的、可用于分割的场景。然后，利用新颖的基于颜色的有效过滤技术对语义对象（兴趣点）进行精细化隔离和重建。

Result: CoRe-GS将训练过程时间缩短了约四分之一，相对于完整的语义高斯溅射训练周期。在SCRREAM（真实世界，室外）和NeRDS 360（合成，室内）两个数据集上的评估表明，该方法减少了运行时间并提高了新视图合成的质量。

Conclusion: CoRe-GS通过结合语义高斯溅射和创新的颜色过滤，实现了更快、更高质量的特定对象3D重建，有效平衡了重建质量与训练时间，非常适用于需要快速处理兴趣点的移动机器人应用。

Abstract: Mobile reconstruction for autonomous aerial robotics holds strong potential
for critical applications such as tele-guidance and disaster response. These
tasks demand both accurate 3D reconstruction and fast scene processing. Instead
of reconstructing the entire scene in detail, it is often more efficient to
focus on specific objects, i.e., points of interest (PoIs). Mobile robots
equipped with advanced sensing can usually detect these early during data
acquisition or preliminary analysis, reducing the need for full-scene
optimization. Gaussian Splatting (GS) has recently shown promise in delivering
high-quality novel view synthesis and 3D representation by an incremental
learning process. Extending GS with scene editing, semantics adds useful
per-splat features to isolate objects effectively.
  Semantic 3D Gaussian editing can already be achieved before the full training
cycle is completed, reducing the overall training time. Moreover, the
semantically relevant area, the PoI, is usually already known during capturing.
To balance high-quality reconstruction with reduced training time, we propose
CoRe-GS. We first generate a coarse segmentation-ready scene with semantic GS
and then refine it for the semantic object using our novel color-based
effective filtering for effective object isolation. This is speeding up the
training process to be about a quarter less than a full training cycle for
semantic GS. We evaluate our approach on two datasets, SCRREAM (real-world,
outdoor) and NeRDS 360 (synthetic, indoor), showing reduced runtime and higher
novel-view-synthesis quality.

</details>


### [48] [Cryo-RL: automating prostate cancer cryoablation planning with reinforcement learning](https://arxiv.org/abs/2509.04886)
*Trixia Simangan,Ahmed Nadeem Abbasi,Yipeng Hu,Shaheer U. Saeed*

Main category: cs.CV

TL;DR: 本文提出Cryo-RL，一个基于强化学习的框架，用于前列腺癌冷冻消融术中冷冻探针放置的自动化规划，显著提升了规划质量和效率。


<details>
  <summary>Details</summary>
Motivation: 当前冷冻消融规划是手动、依赖专家经验且耗时的，导致治疗质量不一和可扩展性受限。

Method: 将冷冻消融规划建模为马尔可夫决策过程，并开发了一个强化学习框架Cryo-RL。在一个模拟环境中，智能体通过基于肿瘤覆盖的奖励函数，学习并顺序选择冷冻探针位置和冰球直径，以生成最优的冷冻消融策略。

Result: 在583例回顾性前列腺癌病例中，Cryo-RL相比于最佳几何优化自动化基线，Dice系数提高了超过8个百分点，并与人类专家表现相当，同时大幅减少了规划时间。

Conclusion: 强化学习在前列腺癌冷冻消融规划中具有巨大潜力，能够提供临床可行、可复现且高效的治疗方案。

Abstract: Cryoablation is a minimally invasive localised treatment for prostate cancer
that destroys malignant tissue during de-freezing, while sparing surrounding
healthy structures. Its success depends on accurate preoperative planning of
cryoprobe placements to fully cover the tumour and avoid critical anatomy. This
planning is currently manual, expertise-dependent, and time-consuming, leading
to variability in treatment quality and limited scalability. In this work, we
introduce Cryo-RL, a reinforcement learning framework that models cryoablation
planning as a Markov decision process and learns an optimal policy for
cryoprobe placement. Within a simulated environment that models clinical
constraints and stochastic intraoperative variability, an agent sequentially
selects cryoprobe positions and ice sphere diameters. Guided by a reward
function based on tumour coverage, this agent learns a cryoablation strategy
that leads to optimal cryoprobe placements without the need for any
manually-designed plans. Evaluated on 583 retrospective prostate cancer cases,
Cryo-RL achieved over 8 percentage-point Dice improvements compared with the
best automated baselines, based on geometric optimisation, and matched human
expert performance while requiring substantially less planning time. These
results highlight the potential of reinforcement learning to deliver clinically
viable, reproducible, and efficient cryoablation plans.

</details>


### [49] [SpiderNets: Estimating Fear Ratings of Spider-Related Images with Vision Models](https://arxiv.org/abs/2509.04889)
*Dominik Pegler,David Steyrl,Mengfan Zhang,Alexander Karner,Jozsef Arato,Frank Scharnowski,Filip Melinscak*

Main category: cs.CV

TL;DR: 研究表明，预训练的计算机视觉模型能够从蜘蛛图像中准确预测人类的恐惧水平，平均绝对误差在10.1至11.0之间，并强调了数据量和模型可解释性的重要性。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉的进步为临床应用（特别是计算机化暴露疗法）开辟了新途径，其中视觉刺激可以根据患者反应进行动态调整。本研究旨在探索预训练的计算机视觉模型是否能准确预测患者对蜘蛛图像的恐惧水平，以作为开发此类自适应系统的关键一步。

Method: 研究人员采用迁移学习方法，调整了三个不同的预训练计算机视觉模型，使其能够从一个包含313张标准化图像的数据集中预测人类的恐惧评分（0-100分）。模型通过交叉验证进行评估，并进行了学习曲线分析、可解释性评估以及类别错误分析。

Result: 模型在预测人类恐惧评分方面取得了平均10.1到11.0的平均绝对误差（MAE）。学习曲线分析显示，减少数据集大小会显著损害性能，但进一步增加数据量并未带来实质性收益。可解释性评估表明模型的预测基于蜘蛛相关特征。类别错误分析进一步识别出与较高误差相关的视觉条件，例如远距离视图和人造/绘画的蜘蛛图像。

Conclusion: 研究结果证明了可解释的计算机视觉模型在预测恐惧评分方面的潜力，并强调了模型可解释性以及足够的数据集大小对于开发有效的、情感感知的治疗技术的重要性。

Abstract: Advances in computer vision have opened new avenues for clinical
applications, particularly in computerized exposure therapy where visual
stimuli can be dynamically adjusted based on patient responses. As a critical
step toward such adaptive systems, we investigated whether pretrained computer
vision models can accurately predict fear levels from spider-related images. We
adapted three diverse models using transfer learning to predict human fear
ratings (on a 0-100 scale) from a standardized dataset of 313 images. The
models were evaluated using cross-validation, achieving an average mean
absolute error (MAE) between 10.1 and 11.0. Our learning curve analysis
revealed that reducing the dataset size significantly harmed performance,
though further increases yielded no substantial gains. Explainability
assessments showed the models' predictions were based on spider-related
features. A category-wise error analysis further identified visual conditions
associated with higher errors (e.g., distant views and artificial/painted
spiders). These findings demonstrate the potential of explainable computer
vision models in predicting fear ratings, highlighting the importance of both
model explainability and a sufficient dataset size for developing effective
emotion-aware therapeutic technologies.

</details>


### [50] [SynGen-Vision: Synthetic Data Generation for training industrial vision models](https://arxiv.org/abs/2509.04894)
*Alpana Dubey,Suma Mani Kuriakose,Nitish Bhardwaj*

Main category: cs.CV

TL;DR: 该研究提出了一种利用视觉语言模型和3D模拟引擎生成合成数据的方法，用于训练工业磨损检测计算机视觉模型，并在锈蚀检测任务上取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 工业磨损检测是预测性维护中的重要计算机视觉问题，但由于缺乏不同磨损场景的数据集，数据收集和标注成本高昂且耗时，限制了模型训练。

Method: 该方法结合了视觉语言模型（VLM）与3D模拟和渲染引擎，以生成针对不同锈蚀条件的合成数据。生成的合成数据集随后用于训练计算机视觉模型进行锈蚀检测。

Result: 使用该方法生成的合成数据训练的计算机视觉模型，在真实工业锈蚀图像上的mAP50得分达到0.87，优于其他方法。该方法还具有可定制性和可扩展性，适用于其他工业磨损检测场景。

Conclusion: 所提出的合成数据生成方法能有效解决工业磨损检测中数据稀缺的问题，通过训练模型在真实数据上表现出色，并可推广到其他磨损场景。

Abstract: We propose an approach to generate synthetic data to train computer vision
(CV) models for industrial wear and tear detection. Wear and tear detection is
an important CV problem for predictive maintenance tasks in any industry.
However, data curation for training such models is expensive and time-consuming
due to the unavailability of datasets for different wear and tear scenarios.
Our approach employs a vision language model along with a 3D simulation and
rendering engine to generate synthetic data for varying rust conditions. We
evaluate our approach by training a CV model for rust detection using the
generated dataset and tested the trained model on real images of rusted
industrial objects. The model trained with the synthetic data generated by our
approach, outperforms the other approaches with a mAP50 score of 0.87. The
approach is customizable and can be easily extended to other industrial wear
and tear detection scenarios

</details>


### [51] [Evaluating Multiple Instance Learning Strategies for Automated Sebocyte Droplet Counting](https://arxiv.org/abs/2509.04895)
*Maryam Adelipour,Gustavo Carneiro,Jeongkwon Kim*

Main category: cs.CV

TL;DR: 本研究引入了一种基于注意力机制的多实例学习（MIL）框架，用于自动化皮脂细胞脂滴计数。结果表明，简单的包级聚合模型（MLP）比注意力MIL模型更稳定，是脂滴计数的可靠基线。


<details>
  <summary>Details</summary>
Motivation: 皮脂细胞分化以细胞内脂滴积累为标志，其定量是皮脂细胞生物学中的关键指标。手动计数费时且主观，因此需要自动化的解决方案。

Method: 研究开发了一个简单的基于注意力机制的多实例学习（MIL）框架。使用尼罗红染色的皮脂细胞图像根据脂滴数量被标注为14个类别，并通过数据增强扩展到约50,000个细胞。对比了两种模型：一个基于聚合补丁级计数的基线多层感知器（MLP），以及一个利用ResNet-50特征和实例加权的基于注意力机制的MIL模型。实验采用五折交叉验证。

Result: 基线MLP模型表现出更稳定的性能（平均MAE = 5.6），而基于注意力机制的MIL模型一致性较差（平均MAE = 10.7），但在特定折叠中偶尔表现更优。

Conclusion: 研究结果表明，简单的包级聚合为玻片级脂滴计数提供了一个鲁棒的基线。基于注意力机制的MIL模型需要任务对齐的池化和正则化，才能充分发挥其在皮脂细胞图像分析中的潜力。

Abstract: Sebocytes are lipid-secreting cells whose differentiation is marked by the
accumulation of intracellular lipid droplets, making their quantification a key
readout in sebocyte biology. Manual counting is labor-intensive and subjective,
motivating automated solutions. Here, we introduce a simple attention-based
multiple instance learning (MIL) framework for sebocyte image analysis. Nile
Red-stained sebocyte images were annotated into 14 classes according to droplet
counts, expanded via data augmentation to about 50,000 cells. Two models were
benchmarked: a baseline multi-layer perceptron (MLP) trained on aggregated
patch-level counts, and an attention-based MIL model leveraging ResNet-50
features with instance weighting. Experiments using five-fold cross-validation
showed that the baseline MLP achieved more stable performance (mean MAE = 5.6)
compared with the attention-based MIL, which was less consistent (mean MAE =
10.7) but occasionally superior in specific folds. These findings indicate that
simple bag-level aggregation provides a robust baseline for slide-level droplet
counting, while attention-based MIL requires task-aligned pooling and
regularization to fully realize its potential in sebocyte image analysis.

</details>


### [52] [UniView: Enhancing Novel View Synthesis From A Single Image By Unifying Reference Features](https://arxiv.org/abs/2509.04932)
*Haowang Cui,Rui Chen,Tao Luo,Rui Li,Jiaze Wang*

Main category: cs.CV

TL;DR: UniView是一种新颖的单图新视角合成模型，通过利用检索到的相似物体参考图像和多模态大语言模型（MLLM）提供强先验信息，并结合适配器模块和解耦三重注意力机制，显著改善了合成质量并超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 从单张图像合成新视角是一个高度不适定的任务，因为未观察区域存在多种解释。大多数现有方法依赖模糊先验和输入视图附近的插值来生成未见区域，这经常导致严重的失真。

Method: 本文提出了UniView模型，其方法包括：1) 构建一个检索和增强系统，并利用多模态大语言模型（MLLM）辅助选择符合要求的参考图像；2) 引入一个带有多层隔离层的即插即用适配器模块，用于动态生成目标视图的参考特征；3) 设计一个解耦三重注意力机制，以有效对齐和整合多分支特征到合成过程中，从而保留原始输入图像的细节。

Result: 广泛的实验证明，UniView显著提高了新视角合成性能，并在具有挑战性的数据集上超越了最先进的方法。

Conclusion: UniView通过有效利用相似物体的参考图像作为强先验信息，并结合创新的特征生成和整合机制，成功克服了单图新视角合成的局限性，实现了卓越的合成效果。

Abstract: The task of synthesizing novel views from a single image is highly ill-posed
due to multiple explanations for unobserved areas. Most current methods tend to
generate unseen regions from ambiguity priors and interpolation near input
views, which often lead to severe distortions. To address this limitation, we
propose a novel model dubbed as UniView, which can leverage reference images
from a similar object to provide strong prior information during view
synthesis. More specifically, we construct a retrieval and augmentation system
and employ a multimodal large language model (MLLM) to assist in selecting
reference images that meet our requirements. Additionally, a plug-and-play
adapter module with multi-level isolation layers is introduced to dynamically
generate reference features for the target views. Moreover, in order to
preserve the details of an original input image, we design a decoupled triple
attention mechanism, which can effectively align and integrate multi-branch
features into the synthesis process. Extensive experiments have demonstrated
that our UniView significantly improves novel view synthesis performance and
outperforms state-of-the-art methods on the challenging datasets.

</details>


### [53] [Efficient Video-to-Audio Generation via Multiple Foundation Models Mapper](https://arxiv.org/abs/2509.04957)
*Gehui Chen,Guan'an Wang,Xiaowen Huang,Jitao Sang*

Main category: cs.CV

TL;DR: 本文提出MFM-Mapper，通过融合双视觉编码器特征并使用GPT-2作为映射器，显著提高了视频到音频（V2A）生成的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 从头训练视频到音频（V2A）生成模型资源消耗巨大。现有利用预训练基础模型的工作通过轻量级映射器连接单一视觉编码器和文本到音频模型，但可能未能充分利用语义和时序信息，且特征对齐有待提升。

Method: 引入MFM-Mapper，通过融合来自双视觉编码器的特征，以获取更丰富的语义和时序信息。将之前的线性映射器替换为GPT-2，将跨模态特征映射视为自回归翻译任务，从而改善特征对齐。

Result: MFM-Mapper展现出卓越的训练效率，训练规模仅为先前基于映射器工作的16%。在语义和时序一致性方面表现更佳，并能与更大规模训练的模型达到竞争性性能。

Conclusion: MFM-Mapper通过结合双视觉编码器和GPT-2映射器，显著提升了V2A生成的训练效率，并在语义和时序一致性上取得了更好的性能。

Abstract: Recent Video-to-Audio (V2A) generation relies on extracting semantic and
temporal features from video to condition generative models. Training these
models from scratch is resource intensive. Consequently, leveraging foundation
models (FMs) has gained traction due to their cross-modal knowledge transfer
and generalization capabilities. One prior work has explored fine-tuning a
lightweight mapper network to connect a pre-trained visual encoder with a
text-to-audio generation model for V2A. Inspired by this, we introduce the
Multiple Foundation Model Mapper (MFM-Mapper). Compared to the previous mapper
approach, MFM-Mapper benefits from richer semantic and temporal information by
fusing features from dual visual encoders. Furthermore, by replacing a linear
mapper with GPT-2, MFM-Mapper improves feature alignment, drawing parallels
between cross-modal features mapping and autoregressive translation tasks. Our
MFM-Mapper exhibits remarkable training efficiency. It achieves better
performance in semantic and temporal consistency with fewer training consuming,
requiring only 16\% of the training scale compared to previous mapper-based
work, yet achieves competitive performance with models trained on a much larger
scale.

</details>


### [54] [Dual-Domain Perspective on Degradation-Aware Fusion: A VLM-Guided Robust Infrared and Visible Image Fusion Framework](https://arxiv.org/abs/2509.05000)
*Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui*

Main category: cs.CV

TL;DR: 本文提出了一种名为GD^2Fusion的新型红外-可见光图像融合（IVIF）框架，通过结合视觉-语言模型（VLMs）进行退化感知和双域（频率/空间）联合优化，有效处理双源图像退化场景。


<details>
  <summary>Details</summary>
Motivation: 现有IVIF方法假定输入图像质量高，难以处理双源退化场景，需要手动且顺序应用预增强步骤。这种解耦的“预增强-融合”流程会导致误差累积和性能下降。

Method: GD^2Fusion框架协同整合了视觉-语言模型（VLMs）进行退化感知，并结合了双域（频率/空间）联合优化。具体包括：1) 引导式频率模态特定提取（GFMSE）模块，用于频率域的退化感知、抑制和鉴别性特征提取。2) 引导式空间模态聚合融合（GSMAF）模块，用于空间域的跨模态退化滤波和自适应多源特征聚合，以增强模态互补性和结构一致性。

Result: 广泛的定性和定量实验表明，GD^2Fusion在双源退化场景下，与现有算法和策略相比，实现了卓越的融合性能。

Conclusion: GD^2Fusion通过其创新的框架，成功克服了传统IVIF方法在处理退化输入时的局限性，显著提升了融合效果。

Abstract: Most existing infrared-visible image fusion (IVIF) methods assume
high-quality inputs, and therefore struggle to handle dual-source degraded
scenarios, typically requiring manual selection and sequential application of
multiple pre-enhancement steps. This decoupled pre-enhancement-to-fusion
pipeline inevitably leads to error accumulation and performance degradation. To
overcome these limitations, we propose Guided Dual-Domain Fusion (GD^2Fusion),
a novel framework that synergistically integrates vision-language models (VLMs)
for degradation perception with dual-domain (frequency/spatial) joint
optimization. Concretely, the designed Guided Frequency Modality-Specific
Extraction (GFMSE) module performs frequency-domain degradation perception and
suppression and discriminatively extracts fusion-relevant sub-band features.
Meanwhile, the Guided Spatial Modality-Aggregated Fusion (GSMAF) module carries
out cross-modal degradation filtering and adaptive multi-source feature
aggregation in the spatial domain to enhance modality complementarity and
structural consistency. Extensive qualitative and quantitative experiments
demonstrate that GD^2Fusion achieves superior fusion performance compared with
existing algorithms and strategies in dual-source degraded scenarios. The code
will be publicly released after acceptance of this paper.

</details>


### [55] [Interpretable Deep Transfer Learning for Breast Ultrasound Cancer Detection: A Multi-Dataset Study](https://arxiv.org/abs/2509.05004)
*Mohammad Abbadi,Yassine Himeur,Shadi Atalla,Wathiq Mansoor*

Main category: cs.CV

TL;DR: 本研究利用机器学习和深度学习技术，对乳腺超声图像进行乳腺癌分类，并取得了高准确率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是女性癌症相关死亡的主要原因。超声成像因其安全性和成本效益在早期检测中发挥关键作用，尤其是在乳腺组织致密的患者中。本研究旨在通过AI技术进一步提升乳腺超声图像的诊断能力。

Method: 研究使用了BUSI、BUS-BRA和BrEaST-Lesions USG等数据集，评估了经典机器学习模型（SVM、KNN）和深度卷积神经网络（ResNet-18、EfficientNet-B0、GoogLeNet）。同时，还探讨了通过深度特征提取增强经典机器学习模型的方法，并使用Grad-CAM进行模型可视化和可解释性分析。

Result: 实验结果显示，ResNet-18实现了最高准确率（99.7%）和恶性病变完美敏感性。经典机器学习模型在通过深度特征提取增强后，也取得了具有竞争力的性能。Grad-CAM可视化进一步提高了模型透明度，突出了诊断相关的图像区域。

Conclusion: 研究结果支持将基于AI的诊断工具整合到临床工作流程中，并证明了部署高性能、可解释的超声乳腺癌检测系统的可行性。

Abstract: Breast cancer remains a leading cause of cancer-related mortality among women
worldwide. Ultrasound imaging, widely used due to its safety and
cost-effectiveness, plays a key role in early detection, especially in patients
with dense breast tissue. This paper presents a comprehensive study on the
application of machine learning and deep learning techniques for breast cancer
classification using ultrasound images. Using datasets such as BUSI, BUS-BRA,
and BrEaST-Lesions USG, we evaluate classical machine learning models (SVM,
KNN) and deep convolutional neural networks (ResNet-18, EfficientNet-B0,
GoogLeNet). Experimental results show that ResNet-18 achieves the highest
accuracy (99.7%) and perfect sensitivity for malignant lesions. Classical ML
models, though outperformed by CNNs, achieve competitive performance when
enhanced with deep feature extraction. Grad-CAM visualizations further improve
model transparency by highlighting diagnostically relevant image regions. These
findings support the integration of AI-based diagnostic tools into clinical
workflows and demonstrate the feasibility of deploying high-performing,
interpretable systems for ultrasound-based breast cancer detection.

</details>


### [56] [A biologically inspired separable learning vision model for real-time traffic object perception in Dark](https://arxiv.org/abs/2509.05012)
*Hulin Li,Qiliang Ren,Jun Li,Hanbing Wei,Zheng Liu,Linfang Fan*

Main category: cs.CV

TL;DR: 本文针对低光照交通场景下的目标感知问题，提出了一个物理降解方法来构建迄今为止最大的低光照交通场景数据集Dark-traffic，并提出了受生物启发的SLVM模型，该模型在检测、实例分割和光流估计等任务上实现了最先进的性能，同时降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: 在低光照交通场景中，由于严重的照明退化和缺乏可靠的视觉线索，现有的感知模型难以快速适应和准确预测。此外，目前缺乏专门针对低光照交通场景的大规模基准数据集。

Method: 研究者引入了一种基于物理原理的照明降解方法，并构建了Dark-traffic数据集，这是目前最大的、密集标注的低光照交通场景数据集，支持目标检测、实例分割和光流估计。此外，本文提出了可分离学习视觉模型（SLVM），这是一个受生物启发的框架，包含四个关键组件：光自适应瞳孔机制、特征级可分离学习策略、任务特定解耦分支和空间错位感知融合模块。

Result: SLVM在降低计算开销的同时，实现了最先进的性能。在Dark-traffic数据集上，SLVM在检测方面超越RT-DETR 11.2个百分点，在实例分割方面超越YOLOv12 6.1个百分点，并使基线模型的光流端点误差（EPE）降低12.37%。在LIS基准上，端到端训练的SLVM在关键指标上平均超越Swin Transformer+EnlightenGAN和ConvNeXt-T+EnlightenGAN 11个百分点，并超越Mask RCNN（带光照增强）3.1个百分点。Dark-traffic数据集和完整代码已发布。

Conclusion: 本文提出的Dark-traffic数据集和SLVM模型有效解决了低光照交通场景目标感知的挑战，为该领域提供了一个高效且性能优越的解决方案，显著提升了恶劣照明条件下的感知能力。

Abstract: Fast and accurate object perception in low-light traffic scenes has attracted
increasing attention. However, due to severe illumination degradation and the
lack of reliable visual cues, existing perception models and methods struggle
to quickly adapt to and accurately predict in low-light environments. Moreover,
there is the absence of available large-scale benchmark specifically focused on
low-light traffic scenes. To bridge this gap, we introduce a physically
grounded illumination degradation method tailored to real-world low-light
settings and construct Dark-traffic, the largest densely annotated dataset to
date for low-light traffic scenes, supporting object detection, instance
segmentation, and optical flow estimation. We further propose the Separable
Learning Vision Model (SLVM), a biologically inspired framework designed to
enhance perception under adverse lighting. SLVM integrates four key components:
a light-adaptive pupillary mechanism for illumination-sensitive feature
extraction, a feature-level separable learning strategy for efficient
representation, task-specific decoupled branches for multi-task separable
learning, and a spatial misalignment-aware fusion module for precise
multi-feature alignment. Extensive experiments demonstrate that SLVM achieves
state-of-the-art performance with reduced computational overhead. Notably, it
outperforms RT-DETR by 11.2 percentage points in detection, YOLOv12 by 6.1
percentage points in instance segmentation, and reduces endpoint error (EPE) of
baseline by 12.37% on Dark-traffic. On the LIS benchmark, the end-to-end
trained SLVM surpasses Swin Transformer+EnlightenGAN and
ConvNeXt-T+EnlightenGAN by an average of 11 percentage points across key
metrics, and exceeds Mask RCNN (with light enhancement) by 3.1 percentage
points. The Dark-traffic dataset and complete code is released at
https://github.com/alanli1997/slvm.

</details>


### [57] [Leveraging Transfer Learning and Mobile-enabled Convolutional Neural Networks for Improved Arabic Handwritten Character Recognition](https://arxiv.org/abs/2509.05019)
*Mohsine El Khayati,Ayyad Maafiri,Yassine Himeur,Hamzah Ali Alkhazaleh,Shadi Atalla,Wathiq Mansoor*

Main category: cs.CV

TL;DR: 本研究探索了迁移学习（TL）与移动端卷积神经网络（MbNets）的结合，以提升阿拉伯手写字符识别（AHCR）的性能，解决了计算资源和数据稀缺问题，并评估了不同策略和模型在基准数据集上的表现。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯手写字符识别（AHCR）面临计算需求高和数据集稀缺的挑战，需要更高效、资源友好的解决方案。

Method: 研究评估了三种迁移学习策略（完全微调、部分微调、从头开始训练）与四种轻量级MbNets（MobileNet、SqueezeNet、MnasNet、ShuffleNet）的结合。实验在AHCD、HIJJA和IFHCDB三个基准数据集上进行。

Result: MobileNet表现最佳，在准确性、鲁棒性和效率上均优异；ShuffleNet在泛化能力上表现出色，尤其在完全微调下。IFHCDB数据集取得了最高结果（MnasNet完全微调下达99%准确率），AHCD数据集达到97%（ShuffleNet），HIJJA数据集因变异性挑战取得92%（ShuffleNet）。完全微调策略在平衡准确性和收敛速度方面表现最佳，而部分微调表现不佳。

Conclusion: 结合迁移学习和MbNets为资源高效的AHCR提供了巨大潜力。未来的工作将集中于架构修改、数据集特征分析、数据增强和高级敏感性分析，以进一步提高模型的鲁棒性和泛化能力。

Abstract: The study explores the integration of transfer learning (TL) with
mobile-enabled convolutional neural networks (MbNets) to enhance Arabic
Handwritten Character Recognition (AHCR). Addressing challenges like extensive
computational requirements and dataset scarcity, this research evaluates three
TL strategies--full fine-tuning, partial fine-tuning, and training from
scratch--using four lightweight MbNets: MobileNet, SqueezeNet, MnasNet, and
ShuffleNet. Experiments were conducted on three benchmark datasets: AHCD,
HIJJA, and IFHCDB. MobileNet emerged as the top-performing model, consistently
achieving superior accuracy, robustness, and efficiency, with ShuffleNet
excelling in generalization, particularly under full fine-tuning. The IFHCDB
dataset yielded the highest results, with 99% accuracy using MnasNet under full
fine-tuning, highlighting its suitability for robust character recognition. The
AHCD dataset achieved competitive accuracy (97%) with ShuffleNet, while HIJJA
posed significant challenges due to its variability, achieving a peak accuracy
of 92% with ShuffleNet. Notably, full fine-tuning demonstrated the best overall
performance, balancing accuracy and convergence speed, while partial
fine-tuning underperformed across metrics. These findings underscore the
potential of combining TL and MbNets for resource-efficient AHCR, paving the
way for further optimizations and broader applications. Future work will
explore architectural modifications, in-depth dataset feature analysis, data
augmentation, and advanced sensitivity analysis to enhance model robustness and
generalizability.

</details>


### [58] [LUIVITON: Learned Universal Interoperable VIrtual Try-ON](https://arxiv.org/abs/2509.05030)
*Cong Cao,Xianhang Cheng,Jingyuan Liu,Yujian Zheng,Zhenhui Lin,Meriem Chkir,Hao Li*

Main category: cs.CV

TL;DR: LUIVITON是一个端到端的全自动虚拟试穿系统，能够将复杂的多层服装，披挂到各种姿态多样的人形角色上，通过将服装与身体的披挂问题分解为服装到SMPL和身体到SMPL的对应任务，并分别使用几何学习和扩散模型解决。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了解决在全自动虚拟试穿中，将复杂服装与任意且高度多样化的身体形状进行对齐的挑战。

Method: 该方法使用SMPL作为代理表示，将服装到身体的披挂问题分解为两个对应任务：1) 服装到SMPL的对应，通过基于几何学习的方法进行部分到完整形状对应预测；2) 身体到SMPL的对应，引入了基于扩散模型的方法，利用多视角一致的外观特征和预训练的2D基础模型。系统还支持服装尺寸和材料属性的快速定制。

Result: LUIVITON系统能够生成高质量的3D服装拟合，无需人工干预，即使没有2D服装缝纫图案也能工作。它能处理复杂的几何形状、非流形网格，并有效泛化到各种人形角色（包括人类、机器人、卡通人物、生物和外星人），同时保持计算效率以实现实际应用。

Conclusion: LUIVITON提供了一个全自动、高质量且高效的虚拟试穿解决方案，能够克服复杂服装和多样身体形状的挑战，并具有广泛的适用性和实用性。

Abstract: We present LUIVITON, an end-to-end system for fully automated virtual try-on,
capable of draping complex, multi-layer clothing onto diverse and arbitrarily
posed humanoid characters. To address the challenge of aligning complex
garments with arbitrary and highly diverse body shapes, we use SMPL as a proxy
representation and separate the clothing-to-body draping problem into two
correspondence tasks: 1) clothing-to-SMPL and 2) body-to-SMPL correspondence,
where each has its unique challenges. While we address the clothing-to-SMPL
fitting problem using a geometric learning-based approach for
partial-to-complete shape correspondence prediction, we introduce a diffusion
model-based approach for body-to-SMPL correspondence using multi-view
consistent appearance features and a pre-trained 2D foundation model. Our
method can handle complex geometries, non-manifold meshes, and generalizes
effectively to a wide range of humanoid characters -- including humans, robots,
cartoon subjects, creatures, and aliens, while maintaining computational
efficiency for practical adoption. In addition to offering a fully automatic
fitting solution, LUIVITON supports fast customization of clothing size,
allowing users to adjust clothing sizes and material properties after they have
been draped. We show that our system can produce high-quality 3D clothing
fittings without any human labor, even when 2D clothing sewing patterns are not
available.

</details>


### [59] [Towards Efficient Pixel Labeling for Industrial Anomaly Detection and Localization](https://arxiv.org/abs/2509.05034)
*Jingqi Wu,Hanxi Li,Lin Yuanbo Wu,Hao Chen,Deyin Liu,Peng Wang*

Main category: cs.CV

TL;DR: 本文提出了ADClick和ADClick-Seg，用于工业异常检测。ADClick通过少量点击和文本描述实现高效的像素级异常标注，显著提升了异常检测模型性能。ADClick-Seg是一个跨模态框架，结合像素级先验和语言引导线索，在多类别异常检测任务中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 工业产品检测中的异常检测（AD）框架通常仅使用无缺陷样本进行训练。虽然可以收集到有缺陷样本，但利用它们通常需要耗时的像素级标注，这限制了模型的可扩展性。

Method: 1. **ADClick**: 一种交互式图像分割（IIS）算法，仅通过少量用户点击和简短文本描述即可生成像素级异常标注。2. **ADClick-Seg**: 一个跨模态框架，通过基于原型的方法对视觉特征和文本提示进行对齐，结合像素级先验和语言引导线索进行异常检测和定位。

Result: 1. ADClick实现了精确高效的标注，显著提高了异常检测模型性能（例如，在MVTec AD上AP达到96.1%）。2. ADClick-Seg在具有挑战性的“多类别”异常检测任务中取得了最先进的结果（在MVTec AD上AP达到80.0%，PRO达到97.5%，Pixel-AUROC达到99.1%）。

Conclusion: ADClick和ADClick-Seg通过提供高效的交互式像素级标注和强大的跨模态框架，有效地解决了工业异常检测中利用缺陷样本的可扩展性问题，从而显著提升了在通用和多类别异常检测及定位任务中的性能，并达到了最先进水平。

Abstract: Industrial product inspection is often performed using Anomaly Detection (AD)
frameworks trained solely on non-defective samples. Although defective samples
can be collected during production, leveraging them usually requires
pixel-level annotations, limiting scalability. To address this, we propose
ADClick, an Interactive Image Segmentation (IIS) algorithm for industrial
anomaly detection. ADClick generates pixel-wise anomaly annotations from only a
few user clicks and a brief textual description, enabling precise and efficient
labeling that significantly improves AD model performance (e.g., AP = 96.1\% on
MVTec AD). We further introduce ADClick-Seg, a cross-modal framework that
aligns visual features and textual prompts via a prototype-based approach for
anomaly detection and localization. By combining pixel-level priors with
language-guided cues, ADClick-Seg achieves state-of-the-art results on the
challenging ``Multi-class'' AD task (AP = 80.0\%, PRO = 97.5\%, Pixel-AUROC =
99.1\% on MVTec AD).

</details>


### [60] [Systematic Review and Meta-analysis of AI-driven MRI Motion Artifact Detection and Correction](https://arxiv.org/abs/2509.05071)
*Mojtaba Safari,Zach Eidex,Richard L. J. Qiu,Matthew Goette,Tonghe Wang,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 该论文系统综述并元分析了AI驱动方法（特别是深度学习生成模型）在磁共振成像（MRI）运动伪影检测与校正中的应用，评估了其发展、有效性、挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 为了评估AI驱动方法（特别是深度学习生成模型）在MRI运动伪影处理中的当前发展、有效性、面临的挑战以及未来的研究方向。尽管这些方法显示出前景，但其有限的泛化性、对配对训练数据的依赖以及潜在的视觉失真风险是亟待解决的关键挑战。

Method: 进行了一项全面的系统综述和元分析，重点关注深度学习（DL）方法，特别是生成模型，在MRI运动伪影检测和校正中的应用。提取了关于所用数据集、DL架构和性能指标的定量数据。

Result: 深度学习，特别是生成模型，在减少运动伪影和提高图像质量方面显示出潜力。然而，有限的泛化性、对配对训练数据的依赖以及视觉失真风险仍然是主要的挑战，这些挑战促使需要标准化数据集和报告。

Conclusion: AI驱动方法，特别是深度学习生成模型，在通过有效处理运动伪影来改善MRI图像质量方面具有显著潜力。但必须解决关键挑战，包括需要全面的公共数据集、标准化伪影水平报告协议，以及更先进、适应性强的深度学习技术，以减少对大量配对数据集的依赖。解决这些问题可以大幅提高MRI诊断准确性，降低医疗成本，并改善患者护理结果。

Abstract: Background: To systematically review and perform a meta-analysis of
artificial intelligence (AI)-driven methods for detecting and correcting
magnetic resonance imaging (MRI) motion artifacts, assessing current
developments, effectiveness, challenges, and future research directions.
Methods: A comprehensive systematic review and meta-analysis were conducted,
focusing on deep learning (DL) approaches, particularly generative models, for
the detection and correction of MRI motion artifacts. Quantitative data were
extracted regarding utilized datasets, DL architectures, and performance
metrics. Results: DL, particularly generative models, show promise for reducing
motion artifacts and improving image quality; however, limited
generalizability, reliance on paired training data, and risk of visual
distortions remain key challenges that motivate standardized datasets and
reporting. Conclusions: AI-driven methods, particularly DL generative models,
show significant potential for improving MRI image quality by effectively
addressing motion artifacts. However, critical challenges must be addressed,
including the need for comprehensive public datasets, standardized reporting
protocols for artifact levels, and more advanced, adaptable DL techniques to
reduce reliance on extensive paired datasets. Addressing these aspects could
substantially enhance MRI diagnostic accuracy, reduce healthcare costs, and
improve patient care outcomes.

</details>


### [61] [GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting](https://arxiv.org/abs/2509.05075)
*Yangming Li,Chaoyu Liu,Lihao Liu,Simon Masnou,Carola-Bibian Schönlieb*

Main category: cs.CV

TL;DR: GeoSplat是一个通用的几何约束优化框架，通过利用一阶和二阶几何先验以及鲁棒的估计方法，显著提升了高斯泼溅（Gaussian Splatting）在新视角合成中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究在优化高斯泼溅时，主要使用低阶几何先验（如法向量），且这些先验通过对噪声敏感的方法（如局部主成分分析）估计，导致性能提升有限且不可靠。本研究旨在解决这些局限性。

Method: 本文提出了GeoSplat框架，该框架利用一阶和二阶几何量（如主曲率）来改进高斯泼溅的整个训练流程，包括高斯初始化、梯度更新和稠密化。例如，通过主曲率初始化3D高斯基元的尺度，以更好地覆盖物体表面。此外，基于特定的几何结构（如局部流形），引入了高效且对噪声鲁棒的估计方法，为框架提供动态几何先验。

Result: GeoSplat框架在多个新视角合成数据集上进行了广泛实验，结果表明它显著提高了高斯泼溅的性能，并优于以往的基线方法。

Conclusion: GeoSplat通过有效整合一阶和二阶几何先验以及鲁棒的估计方法，成功解决了现有高斯泼溅优化中几何先验的局限性，显著提升了其在新视角合成任务中的表现。

Abstract: A few recent works explored incorporating geometric priors to regularize the
optimization of Gaussian splatting, further improving its performance. However,
those early studies mainly focused on the use of low-order geometric priors
(e.g., normal vector), and they are also unreliably estimated by
noise-sensitive methods, like local principal component analysis. To address
their limitations, we first present GeoSplat, a general geometry-constrained
optimization framework that exploits both first-order and second-order
geometric quantities to improve the entire training pipeline of Gaussian
splatting, including Gaussian initialization, gradient update, and
densification. As an example, we initialize the scales of 3D Gaussian
primitives in terms of principal curvatures, leading to a better coverage of
the object surface than random initialization. Secondly, based on certain
geometric structures (e.g., local manifold), we introduce efficient and
noise-robust estimation methods that provide dynamic geometric priors for our
framework. We conduct extensive experiments on multiple datasets for novel view
synthesis, showing that our framework: GeoSplat, significantly improves the
performance of Gaussian splatting and outperforms previous baselines.

</details>


### [62] [Scale-interaction transformer: a hybrid cnn-transformer model for facial beauty prediction](https://arxiv.org/abs/2509.05078)
*Djamel Eddine Boukhari*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Scale-Interaction Transformer (SIT) 的混合深度学习架构，结合了CNN和Transformer的优势，通过显式建模多尺度面部特征的相互作用，在面部美感预测任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 面部美感预测(FBP)是一项具有挑战性的计算机视觉任务，涉及局部和全局面部特征的复杂相互作用。传统卷积神经网络(CNN)通常以固定尺度处理信息，可能忽略了不同粒度级别特征之间关键的相互依赖关系，而这些关系对人类感知至关重要。

Method: SIT模型首先采用一个多尺度模块，通过并行卷积捕获不同感受野下的面部特征。然后，这些多尺度表示被组织成一个序列，并由Transformer编码器处理，该编码器通过自注意力机制显式建模它们之间的相互作用和上下文关系。

Result: 在广泛使用的SCUT-FBP5500基准数据集上进行了大量实验，SIT模型取得了新的最先进成果，实现了0.9187的皮尔逊相关系数，优于现有方法。

Conclusion: 研究结果表明，显式建模多尺度视觉线索之间的相互作用对于高性能面部美感预测至关重要。SIT架构的成功突显了混合CNN-Transformer模型在需要整体、上下文感知理解的复杂图像回归任务中的潜力。

Abstract: Automated Facial Beauty Prediction (FBP) is a challenging computer vision
task due to the complex interplay of local and global facial features that
influence human perception. While Convolutional Neural Networks (CNNs) excel at
feature extraction, they often process information at a fixed scale,
potentially overlooking the critical inter-dependencies between features at
different levels of granularity. To address this limitation, we introduce the
Scale-Interaction Transformer (SIT), a novel hybrid deep learning architecture
that synergizes the feature extraction power of CNNs with the relational
modeling capabilities of Transformers. The SIT first employs a multi-scale
module with parallel convolutions to capture facial characteristics at varying
receptive fields. These multi-scale representations are then framed as a
sequence and processed by a Transformer encoder, which explicitly models their
interactions and contextual relationships via a self-attention mechanism. We
conduct extensive experiments on the widely-used SCUT-FBP5500 benchmark
dataset, where the proposed SIT model establishes a new state-of-the-art. It
achieves a Pearson Correlation of 0.9187, outperforming previous methods. Our
findings demonstrate that explicitly modeling the interplay between multi-scale
visual cues is crucial for high-performance FBP. The success of the SIT
architecture highlights the potential of hybrid CNN-Transformer models for
complex image regression tasks that demand a holistic, context-aware
understanding.

</details>


### [63] [Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers](https://arxiv.org/abs/2509.05086)
*Svetlana Pavlitska,Haixi Fan,Konstantin Ditschuneit,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 本文通过在CNN中引入稀疏专家混合（MoE）层，结合对抗训练，提高了模型对PGD和AutoPGD攻击的鲁棒性。研究发现，平衡损失（switch loss）会导致路由塌陷，使得部分专家过度使用并因此变得更加鲁棒，甚至形成更鲁棒的子路径。


<details>
  <summary>Details</summary>
Motivation: 使卷积神经网络（CNN）对抗对抗性攻击仍然具有挑战性，且通常需要大量资源。研究旨在探索一种无需额外推理成本即可提高模型容量和鲁棒性的方法。

Method: 研究人员在ResNet架构上，用稀疏专家混合（MoE）层替换选定的残差块或卷积层，并在CIFAR-100数据集上进行训练。他们结合对抗训练（PGD和AutoPGD）评估了模型的鲁棒性，并分析了使用平衡损失（switch loss）对专家路由和鲁棒性的影响。

Result: 在ResNet架构上，将单个MoE层插入更深阶段，结合对抗训练，能持续提高模型在PGD和AutoPGD攻击下的鲁棒性。此外，当使用平衡损失时，路由会塌陷到一小组过度使用的专家上，从而将对抗训练集中在这些路径上，无意中使它们更加鲁棒。结果显示，一些单独的专家在鲁棒性方面甚至优于整个门控MoE模型。

Conclusion: 通过专家混合层的引入和平衡损失的使用，模型中出现了鲁棒的子路径，这表明鲁棒性可以通过专家特化而产生。这种方法在不增加额外推理成本的情况下，有效地提升了CNN的对抗鲁棒性。

Abstract: Robustifying convolutional neural networks (CNNs) against adversarial attacks
remains challenging and often requires resource-intensive countermeasures. We
explore the use of sparse mixture-of-experts (MoE) layers to improve robustness
by replacing selected residual blocks or convolutional layers, thereby
increasing model capacity without additional inference cost. On ResNet
architectures trained on CIFAR-100, we find that inserting a single MoE layer
in the deeper stages leads to consistent improvements in robustness under PGD
and AutoPGD attacks when combined with adversarial training. Furthermore, we
discover that when switch loss is used for balancing, it causes routing to
collapse onto a small set of overused experts, thereby concentrating
adversarial training on these paths and inadvertently making them more robust.
As a result, some individual experts outperform the gated MoE model in
robustness, suggesting that robust subpaths emerge through specialization. Our
code is available at https://github.com/KASTEL-MobilityLab/robust-sparse-moes.

</details>


### [64] [Semi-supervised Deep Transfer for Regression without Domain Alignment](https://arxiv.org/abs/2509.05092)
*Mainak Biswas,Ambedkar Dukkipati,Devarajan Sridharan*

Main category: cs.CV

TL;DR: 本文提出CRAFT，一种基于Contradistinguisher的正则化方法，用于源数据不可用、目标数据标签稀缺的回归任务的半监督深度迁移学习。CRAFT在神经科学和其他真实世界回归基准测试中表现出色，优于现有微调和最先进的无源域适应模型。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在实际应用中（如医学）面临领域漂移导致泛化能力差的问题。许多成功的域适应方法需要完全访问源数据，但这在隐私或成本限制下不切实际。此外，标记的目标数据也可能稀缺，尤其是在连续值输出的回归任务中。

Method: 本文基于Contradistinguisher (CUDA) 框架开发了CRAFT（Contradistinguisher-based Regularization Approach for Flexible Training）。与CUDA（设计用于无监督DA、完全访问源数据、分类任务）不同，CRAFT专为源数据不可用（Source-Free, SF）、半监督迁移和回归任务而设计，无需中间表示对齐。

Result: CRAFT在标记训练样本稀缺时，相较于微调模型，均方根误差（RMSE）最高提升9%。它有效利用了未标记的目标数据，并超越了四种最先进的无源域适应模型超过3%。CRAFT在注视预测（EEG数据）和“脑龄”预测（MRI数据）两个神经科学场景以及另外两个真实世界回归基准测试中均展现了其有效性。

Conclusion: CRAFT是一种高效的、适用于生物学和医学中普遍存在的回归任务的无源、半监督深度迁移学习方法。

Abstract: Deep learning models deployed in real-world applications (e.g., medicine)
face challenges because source models do not generalize well to domain-shifted
target data. Many successful domain adaptation (DA) approaches require full
access to source data. Yet, such requirements are unrealistic in scenarios
where source data cannot be shared either because of privacy concerns or
because it is too large and incurs prohibitive storage or computational costs.
Moreover, resource constraints may limit the availability of labeled targets.
We illustrate this challenge in a neuroscience setting where source data are
unavailable, labeled target data are meager, and predictions involve
continuous-valued outputs. We build upon Contradistinguisher (CUDA), an
efficient framework that learns a shared model across the labeled source and
unlabeled target samples, without intermediate representation alignment. Yet,
CUDA was designed for unsupervised DA, with full access to source data, and for
classification tasks. We develop CRAFT -- a Contradistinguisher-based
Regularization Approach for Flexible Training -- for source-free (SF),
semi-supervised transfer of pretrained models in regression tasks. We showcase
the efficacy of CRAFT in two neuroscience settings: gaze prediction with
electroencephalography (EEG) data and ``brain age'' prediction with structural
MRI data. For both datasets, CRAFT yielded up to 9% improvement in
root-mean-squared error (RMSE) over fine-tuned models when labeled training
examples were scarce. Moreover, CRAFT leveraged unlabeled target data and
outperformed four competing state-of-the-art source-free domain adaptation
models by more than 3%. Lastly, we demonstrate the efficacy of CRAFT on two
other real-world regression benchmarks. We propose CRAFT as an efficient
approach for source-free, semi-supervised deep transfer for regression that is
ubiquitous in biology and medicine.

</details>


### [65] [A Scalable Attention-Based Approach for Image-to-3D Texture Mapping](https://arxiv.org/abs/2509.05131)
*Arianna Rampini,Kanika Madan,Bruno Roy,AmirHossein Zamani,Derek Cheung*

Main category: cs.CV

TL;DR: 该论文提出了一种基于Transformer的框架，能够从单张图像和网格直接预测3D纹理场，无需UV映射或可微渲染，实现快速、高质量的纹理生成。


<details>
  <summary>Details</summary>
Motivation: 现有的3D纹理生成方法速度慢、依赖UV映射，并且难以忠实还原参考图像，这阻碍了高质量3D内容的高效创建。

Method: 本文提出一个基于Transformer的框架，直接从单张图像和网格预测3D纹理场。该方法结合了三平面表示（triplane representation）和基于深度的反投影损失（depth-based backprojection losses），从而实现了高效训练和快速推理，并消除了对UV映射和可微渲染的需求。

Result: 训练后，该方法能以单次前向传播生成高保真纹理，每个形状仅需0.2秒。定性、定量和用户偏好评估均表明，在单图像纹理重建方面，该方法在对输入图像的保真度和感知质量上均优于现有最先进的基线方法。

Conclusion: 该方法为可扩展、高质量和可控的3D内容创建提供了实用工具，解决了传统纹理生成方法的痛点，显著提高了效率和质量。

Abstract: High-quality textures are critical for realistic 3D content creation, yet
existing generative methods are slow, rely on UV maps, and often fail to remain
faithful to a reference image. To address these challenges, we propose a
transformer-based framework that predicts a 3D texture field directly from a
single image and a mesh, eliminating the need for UV mapping and differentiable
rendering, and enabling faster texture generation. Our method integrates a
triplane representation with depth-based backprojection losses, enabling
efficient training and faster inference. Once trained, it generates
high-fidelity textures in a single forward pass, requiring only 0.2s per shape.
Extensive qualitative, quantitative, and user preference evaluations
demonstrate that our method outperforms state-of-the-art baselines on
single-image texture reconstruction in terms of both fidelity to the input
image and perceptual quality, highlighting its practicality for scalable,
high-quality, and controllable 3D content creation.

</details>


### [66] [SGS-3D: High-Fidelity 3D Instance Segmentation via Reliable Semantic Mask Splitting and Growing](https://arxiv.org/abs/2509.05144)
*Chaolei Wang,Yang Luo,Jing Du,Siyu Chen,Yiping Chen,Ting Han*

Main category: cs.CV

TL;DR: 本文提出SGS-3D，一个“先分割后增长”的无训练框架，通过结合语义和几何信息，有效提炼和完善由2D-to-3D提升方法产生的模糊3D实例分割结果，显著提高了分割精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 基于2D-to-3D提升的方法在生成精确3D实例分割时，由于语义指导模糊和深度约束不足，在提升过程中会累积误差，导致实例级分割精度不足。因此，需要一种方法来解决这些挑战。

Method: 本文提出了SGS-3D框架，采用“先分割后增长”策略。首先，它利用几何基元纯化并分割模糊的提升掩模；然后，将这些掩模增长为完整的场景实例。SGS-3D是一种无训练的细化方法，它融合了语义和几何信息。具体来说，它引入了掩模过滤策略，利用3D几何基元的共现来识别和移除模糊掩模，以确保与3D对象实例更可靠的语义一致性。在几何细化方面，它通过利用空间连续性和高级特征来构建细粒度对象实例，尤其是在不同对象之间存在语义歧义的情况下。

Result: 在ScanNet200、ScanNet++和KITTI-360数据集上的实验结果表明，SGS-3D显著提高了分割精度和对预训练模型不准确掩模的鲁棒性，生成了高保真度的对象实例，并在多样化的室内外环境中保持了强大的泛化能力。

Conclusion: SGS-3D通过有效融合语义和几何信息，成功解决了2D-to-3D提升方法在3D实例分割中累积误差的问题，实现了高精度、高鲁棒性及强泛化能力的3D实例分割。

Abstract: Accurate 3D instance segmentation is crucial for high-quality scene
understanding in the 3D vision domain. However, 3D instance segmentation based
on 2D-to-3D lifting approaches struggle to produce precise instance-level
segmentation, due to accumulated errors introduced during the lifting process
from ambiguous semantic guidance and insufficient depth constraints. To tackle
these challenges, we propose splitting and growing reliable semantic mask for
high-fidelity 3D instance segmentation (SGS-3D), a novel "split-then-grow"
framework that first purifies and splits ambiguous lifted masks using geometric
primitives, and then grows them into complete instances within the scene.
Unlike existing approaches that directly rely on raw lifted masks and sacrifice
segmentation accuracy, SGS-3D serves as a training-free refinement method that
jointly fuses semantic and geometric information, enabling effective
cooperation between the two levels of representation. Specifically, for
semantic guidance, we introduce a mask filtering strategy that leverages the
co-occurrence of 3D geometry primitives to identify and remove ambiguous masks,
thereby ensuring more reliable semantic consistency with the 3D object
instances. For the geometric refinement, we construct fine-grained object
instances by exploiting both spatial continuity and high-level features,
particularly in the case of semantic ambiguity between distinct objects.
Experimental results on ScanNet200, ScanNet++, and KITTI-360 demonstrate that
SGS-3D substantially improves segmentation accuracy and robustness against
inaccurate masks from pre-trained models, yielding high-fidelity object
instances while maintaining strong generalization across diverse indoor and
outdoor environments. Code is available in the supplementary materials.

</details>


### [67] [SL-SLR: Self-Supervised Representation Learning for Sign Language Recognition](https://arxiv.org/abs/2509.05188)
*Ariel Basso Madjoukeng,Jérôme Fink,Pierre Poitier,Edith Belise Kenmogne,Benoit Frenay*

Main category: cs.CV

TL;DR: 本文提出了一种新的自监督学习框架，包含无负样本对方法和数据增强技术，以解决手语识别中对比学习的局限性，显著提高了识别准确率。


<details>
  <summary>Details</summary>
Motivation: 手语识别领域标注数据稀缺，对比学习等无监督方法很有前景。然而，现有对比学习方法存在两个问题：1) 对视频所有部分一视同仁，未考虑关键信息部位的重要性；2) 不同手语之间共享动作导致负样本对高度相似，难以区分，进而导致学习到非判别性特征，下游任务表现不佳。

Method: 本文提出了一个为手语识别设计的自监督学习框架。该框架包含两个核心组件：1) 一种新的基于“无负样本对”（free-negative pairs）的自监督学习方法；2) 一种新的数据增强技术。这两个组件协同工作以学习有意义的表示。

Result: 与多种对比学习和自监督方法相比，本文提出的方法在准确性方面取得了显著提升。该提升在线性评估、半监督学习以及手语之间的可迁移性等多种评估设置中均得到验证。

Conclusion: 本文提出的自监督学习框架有效解决了手语识别中现有对比学习方法的局限性，通过引入无负样本对方法和新的数据增强技术，学习到了更具判别性的特征，显著提高了手语识别任务的性能和泛化能力。

Abstract: Sign language recognition (SLR) is a machine learning task aiming to identify
signs in videos. Due to the scarcity of annotated data, unsupervised methods
like contrastive learning have become promising in this field. They learn
meaningful representations by pulling positive pairs (two augmented versions of
the same instance) closer and pushing negative pairs (different from the
positive pairs) apart. In SLR, in a sign video, only certain parts provide
information that is truly useful for its recognition. Applying contrastive
methods to SLR raises two issues: (i) contrastive learning methods treat all
parts of a video in the same way, without taking into account the relevance of
certain parts over others; (ii) shared movements between different signs make
negative pairs highly similar, complicating sign discrimination. These issues
lead to learning non-discriminative features for sign recognition and poor
results in downstream tasks. In response, this paper proposes a self-supervised
learning framework designed to learn meaningful representations for SLR. This
framework consists of two key components designed to work together: (i) a new
self-supervised approach with free-negative pairs; (ii) a new data augmentation
technique. This approach shows a considerable gain in accuracy compared to
several contrastive and self-supervised methods, across linear evaluation,
semi-supervised learning, and transferability between sign languages.

</details>


### [68] [COGITAO: A Visual Reasoning Framework To Study Compositionality & Generalization](https://arxiv.org/abs/2509.05249)
*Yassine Taoudi-Benchekroun,Klim Troyan,Pascal Sager,Stefan Gerber,Lukas Tuggener,Benjamin Grewe*

Main category: cs.CV

TL;DR: COGITAO是一个模块化、可扩展的数据生成框架和基准，旨在系统地研究视觉领域中的组合性和泛化能力，并揭示现有模型在此方面的不足。


<details>
  <summary>Details</summary>
Motivation: 人类智能的关键在于能够组合已学习的概念并将其应用于新颖场景，但这仍是当前最先进机器学习模型的一个持续性限制。

Method: COGITAO受ARC-AGI启发，构建基于规则的任务，在网格环境中对对象应用一系列变换。它支持可调节深度的组合，包含28种可互操作的变换，并能广泛控制网格参数和对象属性。这种灵活性使其能创建数百万个独特的任务规则，并为每个规则生成几乎无限的样本。

Result: 使用最先进的视觉模型进行的基线实验表明，尽管这些模型在域内表现强劲，但它们始终无法泛化到熟悉元素的新颖组合。

Conclusion: COGITAO提供了一个开放源代码的工具和基准，以支持在该领域持续研究组合性和泛化能力，并突显了现有模型在应对复杂组合任务时的局限性。

Abstract: The ability to compose learned concepts and apply them in novel settings is
key to human intelligence, but remains a persistent limitation in
state-of-the-art machine learning models. To address this issue, we introduce
COGITAO, a modular and extensible data generation framework and benchmark
designed to systematically study compositionality and generalization in visual
domains. Drawing inspiration from ARC-AGI's problem-setting, COGITAO constructs
rule-based tasks which apply a set of transformations to objects in grid-like
environments. It supports composition, at adjustable depth, over a set of 28
interoperable transformations, along with extensive control over grid
parametrization and object properties. This flexibility enables the creation of
millions of unique task rules -- surpassing concurrent datasets by several
orders of magnitude -- across a wide range of difficulties, while allowing
virtually unlimited sample generation per rule. We provide baseline experiments
using state-of-the-art vision models, highlighting their consistent failures to
generalize to novel combinations of familiar elements, despite strong in-domain
performance. COGITAO is fully open-sourced, including all code and datasets, to
support continued research in this field.

</details>


### [69] [Symbolic Graphics Programming with Large Language Models](https://arxiv.org/abs/2509.05208)
*Yamei Chen,Haoquan Zhang,Yangyi Huang,Zeju Qiu,Kaipeng Zhang,Yandong Wen,Weiyang Liu*

Main category: cs.CV

TL;DR: 本文探讨了大型语言模型（LLMs）生成符号图形程序（SGPs，特别是SVG）的能力。研究引入了SGP-GenBench基准测试，发现专有模型表现优于开源模型。为弥补差距，提出了一种带有可验证奖励的强化学习（RL）方法，显著提升了LLMs生成SVG的质量和语义，使其达到前沿水平，并揭示了RL在对象分解和场景连贯性方面的作用。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在程序合成方面表现出色，但它们生成能够精确渲染视觉内容的符号图形程序（SGPs）的能力尚未得到充分探索。通过这项任务，可以深入了解LLMs如何理解视觉世界。初步研究发现，前沿专有模型与开源模型之间存在显著性能差距，且性能与通用编码能力相关。

Method: 1. 引入SGP-GenBench：一个全面的基准测试，用于评估LLMs生成SVG的能力，涵盖对象保真度、场景保真度和组合性（属性绑定、空间关系、数字能力）。2. 提出一种带有可验证奖励的强化学习（RL）方法：该方法包含一个格式有效性门以确保可渲染的SVG，以及一个跨模态奖励机制，通过强大的视觉编码器（如SigLIP用于文本-图像对齐，DINO用于图像-图像对齐）来对齐文本和渲染图像。3. 将此方法应用于Qwen-2.5-7B模型。

Result: 1. 在SGP-GenBench上，前沿专有模型显著优于开源模型，且性能与通用编码能力高度相关。2. 提出的RL方法显著提升了Qwen-2.5-7B模型的SVG生成质量和语义，使其性能达到前沿系统的水平。3. 训练动态分析表明，RL诱导了对象更精细的分解为可控基元，以及改善场景连贯性的上下文细节。

Conclusion: 符号图形编程提供了一个精确且可解释的视角，用于研究大型语言模型的跨模态基础能力。通过强化学习，可以有效提升LLMs生成精确视觉内容的能力，甚至使较小的模型达到前沿性能。

Abstract: Large language models (LLMs) excel at program synthesis, yet their ability to
produce symbolic graphics programs (SGPs) that render into precise visual
content remains underexplored. We study symbolic graphics programming, where
the goal is to generate an SGP from a natural-language description. This task
also serves as a lens into how LLMs understand the visual world by prompting
them to generate images rendered from SGPs. Among various SGPs, our paper
sticks to scalable vector graphics (SVGs). We begin by examining the extent to
which LLMs can generate SGPs. To this end, we introduce SGP-GenBench, a
comprehensive benchmark covering object fidelity, scene fidelity, and
compositionality (attribute binding, spatial relations, numeracy). On
SGP-GenBench, we discover that frontier proprietary models substantially
outperform open-source models, and performance correlates well with general
coding capabilities. Motivated by this gap, we aim to improve LLMs' ability to
generate SGPs. We propose a reinforcement learning (RL) with verifiable rewards
approach, where a format-validity gate ensures renderable SVG, and a
cross-modal reward aligns text and the rendered image via strong vision
encoders (e.g., SigLIP for text-image and DINO for image-image). Applied to
Qwen-2.5-7B, our method substantially improves SVG generation quality and
semantics, achieving performance on par with frontier systems. We further
analyze training dynamics, showing that RL induces (i) finer decomposition of
objects into controllable primitives and (ii) contextual details that improve
scene coherence. Our results demonstrate that symbolic graphics programming
offers a precise and interpretable lens on cross-modal grounding.

</details>


### [70] [WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool](https://arxiv.org/abs/2509.05296)
*Zizun Li,Jianjun Zhou,Yifan Wang,Haoyu Guo,Wenzheng Chang,Yang Zhou,Haoyi Zhu,Junyi Chen,Chunhua Shen,Tong He*

Main category: cs.CV

TL;DR: WinT3R是一个前馈重建模型，能够在线预测精确的相机姿态和高质量点云图，通过滑动窗口机制和紧凑相机表示解决了传统方法在重建质量和实时性能之间的权衡，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 以往的方法在重建质量和实时性能之间存在权衡，难以同时达到高水准。WinT3R旨在解决这一问题，实现在线高精度重建和实时性能。

Method: 该研究引入了滑动窗口机制，确保窗口内帧之间充分的信息交换，以提高几何预测质量而无需大量计算。此外，它利用紧凑的相机表示并维护一个全局相机令牌池，以提高相机姿态估计的可靠性而不牺牲效率。

Result: WinT3R在在线重建质量、相机姿态估计和重建速度方面均达到了最先进的性能，并通过对各种数据集的广泛实验得到了验证。

Conclusion: WinT3R通过其独特的设计，成功地在保持实时性能的同时，显著提升了在线相机姿态估计和点云图重建的质量和速度，解决了现有方法的局限性。

Abstract: We present WinT3R, a feed-forward reconstruction model capable of online
prediction of precise camera poses and high-quality point maps. Previous
methods suffer from a trade-off between reconstruction quality and real-time
performance. To address this, we first introduce a sliding window mechanism
that ensures sufficient information exchange among frames within the window,
thereby improving the quality of geometric predictions without large
computation. In addition, we leverage a compact representation of cameras and
maintain a global camera token pool, which enhances the reliability of camera
pose estimation without sacrificing efficiency. These designs enable WinT3R to
achieve state-of-the-art performance in terms of online reconstruction quality,
camera pose estimation, and reconstruction speed, as validated by extensive
experiments on diverse datasets. Code and model are publicly available at
https://github.com/LiZizun/WinT3R.

</details>


### [71] [FlowSeek: Optical Flow Made Easier with Depth Foundation Models and Motion Bases](https://arxiv.org/abs/2509.05297)
*Matteo Poggi,Fabio Tosi*

Main category: cs.CV

TL;DR: FlowSeek是一个新颖的光流框架，训练所需硬件资源极少（单块消费级GPU），但仍能在多个数据集上实现优于现有技术的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 大多数最新光流方法在训练时需要大量硬件资源。本研究旨在开发一种紧凑、准确且对硬件要求极低的光流架构。

Method: FlowSeek结合了光流网络设计空间的最新进展、前沿的单图像深度基础模型以及经典的低维运动参数化方法，构建了一个紧凑而精确的架构。

Result: FlowSeek在单个消费级GPU上训练（硬件预算比大多数最新方法低约8倍），但在Sintel Final和KITTI数据集上实现了卓越的跨数据集泛化，比之前的最先进技术SEA-RAFT相对提升了10%和15%，并在Spring和LayeredFlow数据集上也表现出色。

Conclusion: FlowSeek是一个高效、准确且资源友好的光流框架，它在显著降低训练硬件成本的同时，实现了超越现有技术的泛化性能。

Abstract: We present FlowSeek, a novel framework for optical flow requiring minimal
hardware resources for training. FlowSeek marries the latest advances on the
design space of optical flow networks with cutting-edge single-image depth
foundation models and classical low-dimensional motion parametrization,
implementing a compact, yet accurate architecture. FlowSeek is trained on a
single consumer-grade GPU, a hardware budget about 8x lower compared to most
recent methods, and still achieves superior cross-dataset generalization on
Sintel Final and KITTI, with a relative improvement of 10 and 15% over the
previous state-of-the-art SEA-RAFT, as well as on Spring and LayeredFlow
datasets.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [72] [INSEva: A Comprehensive Chinese Benchmark for Large Language Models in Insurance](https://arxiv.org/abs/2509.04455)
*Shisong Chen,Qian Zhu,Wenyan Yang,Chengyi Yang,Zhong Wang,Ping Wang,Xuan Lin,Bo Xu,Daqian Li,Chao Yuan,Licai Qi,Wanqing Xu,sun zhenxing,Xin Lu,Shiqiang Xiong,Chao Chen,Haixiang Hu,Yanghua Xiao*

Main category: cs.CL

TL;DR: 本文提出了INSEva，一个专门针对保险领域AI系统知识和能力的综合性中文基准测试。它包含38,704个高质量示例，并采用多维度评估方法。对8个最先进的大语言模型进行评估后发现，虽然它们具备基本能力，但在处理复杂现实保险场景时仍存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有的AI基准测试未能捕捉保险领域的独特特征和要求，导致在该领域AI评估方面存在空白，尤其是在对准确性和可靠性要求极高的金融系统中。

Method: 研究者开发了INSEva，一个综合性中文基准测试，其特点是多维度评估分类法，涵盖业务领域、任务格式、难度级别和认知知识维度。该基准包含38,704个来自权威材料的高质量评估示例，并为开放式回答设计了评估忠实性和完整性的定制方法。研究者使用此基准评估了8个最先进的大语言模型。

Result: 评估结果显示，不同维度之间存在显著的性能差异。虽然通用大语言模型表现出基本的保险领域能力，平均得分超过80分，但在处理复杂的现实世界保险场景方面仍存在巨大差距。

Conclusion: INSEva成功弥补了保险领域AI评估的空白。尽管当前的大语言模型已具备一定的保险领域基础能力，但它们在应对复杂和实际的保险场景时仍需大幅提升。该基准将很快公开。

Abstract: Insurance, as a critical component of the global financial system, demands
high standards of accuracy and reliability in AI applications. While existing
benchmarks evaluate AI capabilities across various domains, they often fail to
capture the unique characteristics and requirements of the insurance domain. To
address this gap, we present INSEva, a comprehensive Chinese benchmark
specifically designed for evaluating AI systems' knowledge and capabilities in
insurance. INSEva features a multi-dimensional evaluation taxonomy covering
business areas, task formats, difficulty levels, and cognitive-knowledge
dimension, comprising 38,704 high-quality evaluation examples sourced from
authoritative materials. Our benchmark implements tailored evaluation methods
for assessing both faithfulness and completeness in open-ended responses.
Through extensive evaluation of 8 state-of-the-art Large Language Models
(LLMs), we identify significant performance variations across different
dimensions. While general LLMs demonstrate basic insurance domain competency
with average scores above 80, substantial gaps remain in handling complex,
real-world insurance scenarios. The benchmark will be public soon.

</details>


### [73] [Mentalic Net: Development of RAG-based Conversational AI and Evaluation Framework for Mental Health Support](https://arxiv.org/abs/2509.04456)
*Anandi Dutta,Shivani Mruthyunjaya,Jessica Saddington,Kazi Sifatul Islam*

Main category: cs.CL

TL;DR: 本文开发了一个名为Mentalic Net Conversational AI的心理健康支持聊天机器人，旨在增强专业医疗服务，并强调安全和有意义的应用。该系统采用RAG框架、提示工程和模型微调，并在多维度评估中表现良好。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的兴起带来了无限可能，但也伴随着重大挑战。研究旨在开发一个安全、有意义的心理健康支持应用，以辅助专业医疗服务。

Method: 研究采用了检索增强生成（RAG）框架，整合了提示工程，并使用新颖数据集对预训练模型进行了微调。系统经过了严格评估，涵盖了准确性、同理心、可信度、隐私和偏见等多个方面。

Result: 所开发的Mentalic Net Conversational AI系统在BERT Score上达到了0.898，其他评估指标也均在满意范围内。

Conclusion: 研究倡导在开发此类变革性技术时，应采取“人机协作”（human-in-the-loop）方法和长期负责任的策略，以充分发挥其改变生活的潜力，并有效管理潜在风险。

Abstract: The emergence of large language models (LLMs) has unlocked boundless
possibilities, along with significant challenges. In response, we developed a
mental health support chatbot designed to augment professional healthcare, with
a strong emphasis on safe and meaningful application. Our approach involved
rigorous evaluation, covering accuracy, empathy, trustworthiness, privacy, and
bias. We employed a retrieval-augmented generation (RAG) framework, integrated
prompt engineering, and fine-tuned a pre-trained model on novel datasets. The
resulting system, Mentalic Net Conversational AI, achieved a BERT Score of
0.898, with other evaluation metrics falling within satisfactory ranges. We
advocate for a human-in-the-loop approach and a long-term, responsible strategy
in developing such transformative technologies, recognizing both their
potential to change lives and the risks they may pose if not carefully managed.

</details>


### [74] [Do MLLMs Really Understand the Charts?](https://arxiv.org/abs/2509.04457)
*Xiao Zhang,Dongyuan Li,Liuyu Xiang,Yao Zhang,Cheng Zhong,Zhaofeng He*

Main category: cs.CL

TL;DR: 现有多模态大语言模型（MLLMs）在处理无标注图表时存在幻觉和性能下降问题，本文提出ChartReasoner模型和CRBench基准测试，旨在通过模仿人类视觉推理来提升MLLMs的图表理解能力。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在图表理解方面表现出色，但在处理无标注图表时出现严重的幻觉和性能下降，这引发了对它们是否真正理解图表的质疑。人类能够通过视觉推理理解图表并估计数值，这促使研究者探索如何让MLLMs也具备类似能力。

Method: 1. 建立了全面的图表推理基准CRBench，以严格评估MLLMs在无标注图表上的视觉推理能力。2. 提出MLLMs主要依赖识别而非推理来解释图表。3. 提出了ChartReasoner模型，通过将估计结果建立在图表理解的基础上，模仿人类行为来引导MLLMs进行合理的图表理解。

Result: 在CRBench上的广泛实验表明，ChartReasoner-3B/7B取得了卓越的图表推理性能，甚至优于GPT-4o和Gemini-2.5-Flash。更重要的是，ChartReasoner还在公共基准测试上展示了其在通用图表理解方面的视觉推理能力，带来了显著的性能提升。

Conclusion: ChartReasoner通过增强MLLMs的视觉推理能力，使其能够更理性地理解图表，显著解决了现有模型在无标注图表处理中的幻觉和性能问题。

Abstract: Although Multimodal Large Language Models (MLLMs) have demonstrated
increasingly impressive performance in chart understanding, most of them
exhibit alarming hallucinations and significant performance degradation when
handling non-annotated charts. Therefore, a question arises: Do MLLMs really
understand the charts? Since a human is capable of understanding charts and
estimating the values by visual reasoning, we first carefully establish a
comprehensive Chart Reasoning Benchmark CRBench to rigorously evaluate the
visual reasoning abilities of MLLMs on non-annotated charts. We argue that
MLLMs are primarily relying on recognition rather than reasoning to interpret
the charts. To steer MLLMs to reasonable chart understanding, we propose
ChartReasoner that mimics human behavior by grounding their estimation in chart
understanding. Extensive results on the proposed CRBench show that
ChartReasnoner-3B/7B achieves superior performance in chart reasoning, even
compared to GPT-4o and Gemini-2.5-Flash. More importantly, ChartReasnoner also
demonstrates the visual reasoning abilities in general chart comprehension on
public benchmarks, leading to significant performance gains and enabling MLLMs
to rationally understand the charts. The code and dataset will be publicly
available upon publication.

</details>


### [75] [Predicting Failures of LLMs to Link Biomedical Ontology Terms to Identifiers Evidence Across Models and Ontologies](https://arxiv.org/abs/2509.04458)
*Daniel B. Hier,Steven Keith Platt,Tayo Obafemi-Ajayi*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在生物医学NLP任务中难以将本体术语链接到正确标识符，通过分析GPT-4o和LLaMa 3.1 405B模型在HDO和GO本体上的表现，发现模型对本体标识符的熟悉程度是链接成功的最强预测因子。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生物医学自然语言处理任务中表现良好，但经常无法将本体术语与其正确的标识符关联起来。本研究旨在调查这些失败发生的原因。

Method: 研究分析了GPT-4o和LLaMa 3.1 405B两个高性能模型在人类表型本体（Human Phenotype Ontology）和基因本体（Gene Ontology）这两个主要本体上的预测结果。评估了九个候选特征，涉及术语熟悉度、标识符使用、形态学和本体结构。采用单变量和多变量分析方法。

Result: 单变量和多变量分析结果表明，模型对本体标识符的暴露或熟悉程度是链接成功的最强预测因子。

Conclusion: 模型能否成功将本体术语链接到正确标识符的关键因素在于其对本体标识符本身的接触和熟悉程度。

Abstract: Large language models often perform well on biomedical NLP tasks but may fail
to link ontology terms to their correct identifiers. We investigate why these
failures occur by analyzing predictions across two major ontologies, Human
Phenotype Ontology and Gene Ontology, and two high-performing models, GPT-4o
and LLaMa 3.1 405B. We evaluate nine candidate features related to term
familiarity, identifier usage, morphology, and ontology structure. Univariate
and multivariate analyses show that exposure to ontology identifiers is the
strongest predictor of linking success.

</details>


### [76] [Uncertainty-Aware Collaborative System of Large and Small Models for Multimodal Sentiment Analysis](https://arxiv.org/abs/2509.04459)
*Shiqin Han,Manning Gao,Menghua Jiang,Yuncheng Jiang,Haifeng Hu,Sijie Mai*

Main category: cs.CL

TL;DR: 该研究提出了一种不确定性感知协同系统（U-ACS），结合轻量级模型和大型多模态语言模型（MLLM），通过不确定性驱动的级联机制，在多模态情感分析中实现了计算效率和性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型（MLLMs）性能强大但计算成本高昂，难以实际部署；小型模型效率高但性能不足。研究旨在解决这种性能与效率之间的矛盾。

Method: 提出U-ACS系统，核心是不确定性驱动的级联机制：轻量级模型首先处理所有输入，只有高预测不确定性的样本才会被上报给MLLM进行深入分析。此外，系统还包含处理模糊或冲突预测的策略，如相似极性预测的加权平均和高不确定性冲突预测的基于提示的交叉验证。

Result: 在基准数据集上的实验表明，所提出的方法在显著降低计算资源消耗（相比单独使用MLLM）的同时，实现了最先进的性能。

Conclusion: U-ACS通过动态分配计算资源，有效平衡了多模态情感分析中的性能和计算效率，使得高性能MLLM的优势能够在资源受限的环境中得到利用。

Abstract: The advent of Multimodal Large Language Models (MLLMs) has significantly
advanced the state-of-the-art in multimodal machine learning, yet their
substantial computational demands present a critical barrier to real-world
deployment. Conversely, smaller, specialized models offer high efficiency but
often at the cost of performance. To reconcile this performance-efficiency
trade-off, we propose a novel Uncertainty-Aware Collaborative System (U-ACS)
that synergistically orchestrates a powerful MLLM (e.g., HumanOmni) and a
lightweight baseline model for multimodal sentiment analysis. The core of our
system is an uncertainty-driven cascade mechanism, where the efficient small
model first acts as a rapid filter for all input samples. Only those samples
yielding high predictive uncertainty, thereby indicating greater difficulty,
are selectively escalated to the MLLM for more sophisticated analysis.
Furthermore, our system introduces advanced strategies to handle ambiguous or
conflicting predictions, including weighted averaging for predictions of
similar polarity and a prompt-based cross-verification to resolve conflicting
predictions when both models exhibit high uncertainty. This
sample-difficulty-aware approach allows for a dynamic allocation of
computational resources, drastically reducing inference costs while retaining
the high accuracy of MLLM. Extensive experiments on benchmark datasets
demonstrate that our proposed method achieves state-of-the-art performance,
while requiring only a fraction of the computational resources compared to
using a standalone MLLM.

</details>


### [77] [CoCoNUTS: Concentrating on Content while Neglecting Uninformative Textual Styles for AI-Generated Peer Review Detection](https://arxiv.org/abs/2509.04460)
*Yihan Chen,Jiawei Chen,Guozhao Mo,Xuanang Chen,Ben He,Xianpei Han,Le Sun*

Main category: cs.CL

TL;DR: 针对大型语言模型（LLMs）在同行评审中生成内容的风险，本文提出了一种从基于风格到基于内容的检测范式转变。我们引入了CoCoNUTS基准和CoCoDet多任务学习检测器，以实现更准确、公平的AI参与同行评审内容检测。


<details>
  <summary>Details</summary>
Motivation: LLMs在同行评审中生成实质性内容引发了对公平性和可靠性的担忧。现有通用AI文本检测器容易受到复述攻击，且难以区分语言润色和实质性内容生成，主要依赖风格线索，导致误报或漏报。

Method: 本文提出从基于风格的检测转向基于内容的检测。具体而言，我们构建了CoCoNUTS，一个内容导向的基准，包含一个涵盖六种人机协作模式的细粒度AI生成同行评审数据集。在此基础上，我们开发了CoCoDet，一个通过多任务学习框架实现的AI评审检测器。

Result: CoCoNUTS和CoCoDet为评估LLMs在同行评审中的使用提供了一个实用的基础，并实现了对评审内容中AI参与的更准确和鲁棒的检测。

Conclusion: 这项工作有助于开发更精确、公平和可靠的检测方法，以应对现实世界学术应用中LLMs在同行评审中的使用问题。

Abstract: The growing integration of large language models (LLMs) into the peer review
process presents potential risks to the fairness and reliability of scholarly
evaluation. While LLMs offer valuable assistance for reviewers with language
refinement, there is growing concern over their use to generate substantive
review content. Existing general AI-generated text detectors are vulnerable to
paraphrasing attacks and struggle to distinguish between surface language
refinement and substantial content generation, suggesting that they primarily
rely on stylistic cues. When applied to peer review, this limitation can result
in unfairly suspecting reviews with permissible AI-assisted language
enhancement, while failing to catch deceptively humanized AI-generated reviews.
To address this, we propose a paradigm shift from style-based to content-based
detection. Specifically, we introduce CoCoNUTS, a content-oriented benchmark
built upon a fine-grained dataset of AI-generated peer reviews, covering six
distinct modes of human-AI collaboration. Furthermore, we develop CoCoDet, an
AI review detector via a multi-task learning framework, designed to achieve
more accurate and robust detection of AI involvement in review content. Our
work offers a practical foundation for evaluating the use of LLMs in peer
review, and contributes to the development of more precise, equitable, and
reliable detection methods for real-world scholarly applications. Our code and
data will be publicly available at https://github.com/Y1hanChen/COCONUTS.

</details>


### [78] [From Post To Personality: Harnessing LLMs for MBTI Prediction in Social Media](https://arxiv.org/abs/2509.04461)
*Tian Ma,Kaiyu Feng,Yu Rong,Kangfei Zhao*

Main category: cs.CL

TL;DR: 本文提出PostToPersonality (PtoP) 框架，通过结合检索增强生成（RAG）和合成少数类过采样技术微调大型语言模型（LLM），解决了LLM在MBTI人格预测中存在的幻觉问题和数据类别不平衡挑战，并实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体帖子的人格预测（特别是MBTI）具有重要的心理学和社会学应用价值。尽管大型语言模型（LLM）在此领域潜力巨大，但直接应用它们面临两大挑战：LLM固有的幻觉问题以及MBTI类型在人群中自然存在的不平衡分布。

Method: 本文提出了名为PostToPersonality (PtoP) 的新型LLM框架。具体方法包括：1. 利用检索增强生成（RAG）和上下文学习（in-context learning）来减轻LLM的幻觉问题。2. 通过合成少数类过采样（synthetic minority oversampling）技术微调预训练LLM，以生成合成样本来平衡类别不平衡，从而提高模型对MBTI的理解能力。

Result: 在真实社交媒体数据集上进行的实验表明，PtoP框架与10种机器学习（ML）和深度学习（DL）基线方法相比，取得了最先进的性能。

Conclusion: PtoP框架成功地利用LLM进行MBTI人格预测，有效克服了LLM的幻觉问题和数据类别不平衡挑战，并在真实世界数据上展现出卓越的预测能力。

Abstract: Personality prediction from social media posts is a critical task that
implies diverse applications in psychology and sociology. The Myers Briggs Type
Indicator (MBTI), a popular personality inventory, has been traditionally
predicted by machine learning (ML) and deep learning (DL) techniques. Recently,
the success of Large Language Models (LLMs) has revealed their huge potential
in understanding and inferring personality traits from social media content.
However, directly exploiting LLMs for MBTI prediction faces two key challenges:
the hallucination problem inherent in LLMs and the naturally imbalanced
distribution of MBTI types in the population. In this paper, we propose
PostToPersonality (PtoP), a novel LLM based framework for MBTI prediction from
social media posts of individuals. Specifically, PtoP leverages Retrieval
Augmented Generation with in context learning to mitigate hallucination in
LLMs. Furthermore, we fine tune a pretrained LLM to improve model specification
in MBTI understanding with synthetic minority oversampling, which balances the
class imbalance by generating synthetic samples. Experiments conducted on a
real world social media dataset demonstrate that PtoP achieves state of the art
performance compared with 10 ML and DL baselines.

</details>


### [79] [Benchmarking GPT-5 for biomedical natural language processing](https://arxiv.org/abs/2509.04462)
*Yu Hou,Zaifu Zhan,Rui Zhang*

Main category: cs.CL

TL;DR: 本研究评估了GPT-5和GPT-4o在生物医学自然语言处理（BioNLP）基准上的表现，发现GPT-5在多项任务中取得了最强的整体性能，尤其是在问答方面，但在某些提取和摘要任务上仍落后于特定领域模型。


<details>
  <summary>Details</summary>
Motivation: 生物医学文献的快速增长，以及对可扩展自然语言处理解决方案的需求日益增加。尽管GPT-4在特定任务（如问答）上表现出色，但在其他领域性能不均衡，促使研究人员评估更先进的模型。

Method: 研究人员更新了一个标准化的BioNLP基准，使用零次、一次和五次少样本提示，评估了GPT-5和GPT-4o在涵盖命名实体识别、关系抽取、多标签文档分类、问答、文本摘要和文本简化六个任务家族的12个数据集上的性能。评估使用了固定的提示模板、相同的解码参数和批量推理，并与GPT-4、GPT-3.5和LLaMA-2-13B的先前结果进行了比较。

Result: GPT-5取得了最强的整体基准性能，在五次少样本提示下，宏平均分数上升到0.557，超过GPT-4（0.506）和GPT-4o（0.508）。在MedQA上，GPT-5达到94.1%的准确率，超过了之前监督式SOTA五十多个百分点；在PubMedQA上与监督式系统持平（0.734）。在抽取任务中，GPT-5在化学NER（0.886 F1）和ChemProt关系抽取（0.616 F1）上取得了显著进步。然而，摘要和疾病NER任务仍落后于特定领域基线。

Conclusion: 研究结果表明，GPT-5作为一种通用模型，在推理导向的生物医学问答方面已具备部署就绪的性能。然而，对于精度关键的抽取和证据密集型摘要任务，精调或混合方法仍然更具优势。该基准为BioNLP系统设计提供了可操作的指导，指明了简单提示足以应对的场景，以及可能需要检索增强或基于规划的支架的场景。

Abstract: The rapid expansion of biomedical literature has heightened the need for
scalable natural language processing (NLP) solutions. While GPT-4 substantially
narrowed the gap with task-specific systems, especially in question answering,
its performance across other domains remained uneven. We updated a standardized
BioNLP benchmark to evaluate GPT-5 and GPT-4o under zero-, one-, and five-shot
prompting across 12 datasets spanning six task families: named entity
recognition, relation extraction, multi-label document classification, question
answering, text summarization, and text simplification. Using fixed prompt
templates, identical decoding parameters, and batch inference, we report
primary metrics per dataset and include prior results for GPT-4, GPT-3.5, and
LLaMA-2-13B for comparison. GPT-5 achieved the strongest overall benchmark
performance, with macro-average scores rising to 0.557 under five-shot
prompting versus 0.506 for GPT-4 and 0.508 for GPT-4o. On MedQA, GPT-5 reached
94.1% accuracy, exceeding the previous supervised state of the art by over
fifty points, and attained parity with supervised systems on PubMedQA (0.734).
In extraction tasks, GPT-5 delivered major gains in chemical NER (0.886 F1) and
ChemProt relation extraction (0.616 F1), outperforming GPT-4 and GPT-4o, though
summarization and disease NER still lagged behind domain-specific baselines.
These results establish GPT-5 as a general-purpose model now offering
deployment-ready performance for reasoning-oriented biomedical QA, while
precision-critical extraction and evidence-dense summarization continue to
favor fine-tuned or hybrid approaches. The benchmark delineates where simple
prompting suffices and where retrieval-augmented or planning-based scaffolds
are likely required, providing actionable guidance for BioNLP system design as
frontier models advance.

</details>


### [80] [Can Multiple Responses from an LLM Reveal the Sources of Its Uncertainty?](https://arxiv.org/abs/2509.04464)
*Yang Nan,Pengfei He,Ravi Tandon,Han Xu*

Main category: cs.CL

TL;DR: 本研究提出了一种诊断大型语言模型（LLMs）不确定性来源的方法，通过分析其多个生成响应之间的分歧模式，并利用辅助LLM来推断不确定性的具体原因（如输入歧义、知识缺乏）。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs取得了显著进展，但它们仍可能产生不可靠或误导性输出，对实际应用构成挑战。现有研究多关注量化模型不确定性，但很少探究不确定性的根本来源。

Method: 从目标LLM收集多个响应，然后使用一个辅助LLM来分析这些响应之间的分歧模式。辅助模型负责推断不确定性的可能来源，例如输入问题的歧义性、相关知识的缺乏，或两者兼有。在涉及知识空白的情况下，辅助模型还会识别导致不确定性的具体缺失事实或概念。

Result: 该框架在AmbigQA、OpenBookQA和MMLU-Pro数据集上进行了验证，证实了其在诊断不同不确定性来源方面的通用性。

Conclusion: 诊断不确定性来源有助于进行相关的人工干预，从而提高LLM的性能和可靠性。

Abstract: Large language models (LLMs) have delivered significant breakthroughs across
diverse domains but can still produce unreliable or misleading outputs, posing
critical challenges for real-world applications. While many recent studies
focus on quantifying model uncertainty, relatively little work has been devoted
to \textit{diagnosing the source of uncertainty}. In this study, we show that,
when an LLM is uncertain, the patterns of disagreement among its multiple
generated responses contain rich clues about the underlying cause of
uncertainty. To illustrate this point, we collect multiple responses from a
target LLM and employ an auxiliary LLM to analyze their patterns of
disagreement. The auxiliary model is tasked to reason about the likely source
of uncertainty, such as whether it stems from ambiguity in the input question,
a lack of relevant knowledge, or both. In cases involving knowledge gaps, the
auxiliary model also identifies the specific missing facts or concepts
contributing to the uncertainty. In our experiment, we validate our framework
on AmbigQA, OpenBookQA, and MMLU-Pro, confirming its generality in diagnosing
distinct uncertainty sources. Such diagnosis shows the potential for relevant
manual interventions that improve LLM performance and reliability.

</details>


### [81] [Emotionally-Aware Agents for Dispute Resolution](https://arxiv.org/abs/2509.04465)
*Sushrita Rakshit,James Hale,Kushal Chawla,Jeanne M. Brett,Jonathan Gratch*

Main category: cs.CL

TL;DR: 本研究利用大型语言模型（LLMs）对买卖纠纷对话中的情感表达进行识别和分析，发现LLMs在情感强度标注上优于传统方法，并能有效揭示情感表达如何影响冲突升级与解决，为基于智能体的纠纷管理系统提供潜力。


<details>
  <summary>Details</summary>
Motivation: 以往研究已显示文本情感识别在谈判中的潜力，但纠纷情境会引发更强烈的情绪和不同的社会过程。因此，本研究旨在探索自动文本情感识别，特别是利用大型语言模型，能否为理解和干预纠纷解决中的情感影响提供新的见解。

Method: 研究使用了大量的买卖纠纷对话语料库。通过大型语言模型（LLMs）进行情感强度标注，并将其解释力与之前的方法以及人类标注者的决策进行比较。

Result: 研究发现，大型语言模型在情感强度标注方面比以往方法具有显著更高的解释力，并且与人类标注者的判断更吻合。研究结果支持了现有关于情感表达如何导致冲突升级和解决的理论模型。

Conclusion: 情感识别技术，尤其是基于大型语言模型的，可以为理解和管理纠纷中的情感动态提供深入洞察。基于智能体的系统有望通过识别和潜在地缓解情感升级来有效地管理纠纷。

Abstract: In conflict, people use emotional expressions to shape their counterparts'
thoughts, feelings, and actions. This paper explores whether automatic text
emotion recognition offers insight into this influence in the context of
dispute resolution. Prior work has shown the promise of such methods in
negotiations; however, disputes evoke stronger emotions and different social
processes. We use a large corpus of buyer-seller dispute dialogues to
investigate how emotional expressions shape subjective and objective outcomes.
We further demonstrate that large-language models yield considerably greater
explanatory power than previous methods for emotion intensity annotation and
better match the decisions of human annotators. Findings support existing
theoretical models for how emotional expressions contribute to conflict
escalation and resolution and suggest that agent-based systems could be useful
in managing disputes by recognizing and potentially mitigating emotional
escalation.

</details>


### [82] [Just-in-time and distributed task representations in language models](https://arxiv.org/abs/2509.04466)
*Yuxuan Li,Declan Campbell,Stephanie C. Y. Chan,Andrew Kyle Lampinen*

Main category: cs.CL

TL;DR: 本研究探究了语言模型在上下文学习中新任务表示的形成时间和演变方式，发现这些可迁移表示是非单调、零星且具有时序和语义局部性的，表明模型采用一种即时计算过程来适应新证据。


<details>
  <summary>Details</summary>
Motivation: 语言模型强大的上下文学习能力源于其无需权重更新即可根据指令或示例学习新任务。本研究旨在深入理解这些新任务的表示何时形成以及在上下文过程中如何变化。

Method: 研究关注“可迁移”任务表示，即能够恢复模型中任务上下文的向量表示。通过观察这些表示在上下文中的演变，分析其形成机制、累积过程以及与任务性能和结构的关系。

Result: 研究发现，可迁移任务表示以非单调和零星的方式演变，且与更惰性的高级任务类别表示不同。模型将多个证据浓缩到这些可迁移表示中，这与更多示例带来的性能提升相符。然而，这种累积过程在序列维度上表现出强烈的局部性，仅在特定标记处在线。此外，这些局部但可迁移的任务表示倾向于捕获最小的“任务范围”（如语义独立的子任务），而模型依赖更长时间分布的表示来支持更长和复合的任务，显示出时序和语义上的双重局部性。

Conclusion: 语言模型在上下文学习中，新任务表示的形成和演变具有显著的时序和语义局部性。这种“即时”的计算过程是语言模型适应新证据并实时学习新任务能力的基础。

Abstract: Many of language models' impressive capabilities originate from their
in-context learning: based on instructions or examples, they can infer and
perform new tasks without weight updates. In this work, we investigate
\emph{when} representations for new tasks are formed in language models, and
\emph{how} these representations change over the course of context. We focus on
''transferrable'' task representations -- vector representations that can
restore task context in another instance of the model, even without the full
prompt. We show that these representations evolve in non-monotonic and sporadic
ways, and are distinct from a more inert representation of high-level task
categories that persists throughout the context. Specifically, models often
condense multiple evidence into these transferrable task representations, which
align well with the performance improvement based on more examples in the
context. However, this accrual process exhibits strong locality along the
sequence dimension, coming online only at certain tokens -- despite task
identity being reliably decodable throughout the context. Moreover, these local
but transferrable task representations tend to capture minimal ''task scopes'',
such as a semantically-independent subtask, and models rely on more
temporally-distributed representations to support longer and composite tasks.
This two-fold locality (temporal and semantic) underscores a kind of
just-in-time computational process underlying language models' ability to adapt
to new evidence and learn new tasks on the fly.

</details>


### [83] [Enhancing LLM Efficiency: Targeted Pruning for Prefill-Decode Disaggregation in Inference](https://arxiv.org/abs/2509.04467)
*Hao Zhang,Mengsi Lyu,Yulong Ao,Yonghua Lin*

Main category: cs.CL

TL;DR: 本文提出了一种针对大语言模型（LLMs）预填充-解码（PD）分离推理的新型剪枝方法，通过独立的块移除和令牌感知的KV缓存剪枝，显著提高了推理速度并降低了数据传输带宽。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）的高计算和内存成本限制了其部署。现有剪枝方法未能充分考虑实际应用中预填充-解码（PD）分离的特性，导致剪枝效率和精度不足。

Method: 本文提出了一种针对PD分离推理的剪枝方法。它构建了剪枝和蒸馏数据集，对预填充和解码阶段独立进行迭代块移除，以获得更优的剪枝方案。此外，引入了令牌感知的缓存剪枝机制，在预填充阶段保留所有KV缓存，但在解码阶段选择性地重用特定层中第一个和最后一个令牌序列的KV缓存条目，以最小开销减少通信成本。

Result: 该方法在PD分离和PD统一设置下均表现出强大的性能。在默认设置下，推理速度提升了20.56%，数据传输带宽消耗减少了4.95倍。

Conclusion: 所提出的剪枝方法有效解决了LLM部署中的计算和内存瓶颈，通过精确的块和KV缓存剪枝，特别是在PD分离推理场景下，显著提升了推理效率和带宽利用率。

Abstract: Large Language Models (LLMs) demonstrate exceptional capabilities across
various tasks, but their deployment is constrained by high computational and
memory costs. Model pruning provides an effective means to alleviate these
demands. However, existing methods often ignore the characteristics of
prefill-decode (PD) disaggregation in practice. In this paper, we propose a
novel pruning method for PD disaggregation inference, enabling more precise and
efficient block and KV Cache pruning. Our approach constructs pruning and
distillation sets to perform iterative block removal independently for the
prefill and decode stages, obtaining better pruning solutions. Moreover, we
introduce a token-aware cache pruning mechanism that retains all KV Cache in
the prefill stage but selectively reuses entries for the first and last token
sequences in selected layers during decode, reducing communication costs with
minimal overhead. Extensive experiments demonstrate that our approach
consistently achieves strong performance in both PD disaggregation and PD
unified settings without disaggregation. Under the default settings, our method
achieves a 20.56% inference speedup and a 4.95 times reduction in data
transmission bandwidth consumption.

</details>


### [84] [Evaluating Large Language Models for Financial Reasoning: A CFA-Based Benchmark Study](https://arxiv.org/abs/2509.04468)
*Xuan Yao,Qianteng Wang,Xinbo Liu,Ke-Wei Huang*

Main category: cs.CL

TL;DR: 本研究首次使用1,560道CFA模拟考试题全面评估了最先进的大型语言模型（LLMs）在金融领域的表现，并引入了一种结合CFA课程内容的检索增强生成（RAG）管道。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在金融应用中展现巨大潜力，但其在专业金融背景下的系统性评估仍然有限。

Method: 研究使用了来自CFA I-III级官方模拟考试的1,560道选择题。比较了多模态、推理专用和轻量级LLMs在零样本提示下的表现。还开发了一种新颖的检索增强生成（RAG）管道，通过分层知识组织和结构化查询生成，整合了官方CFA课程内容以增强领域特定知识检索。

Result: 结果显示，推理导向模型在零样本设置下表现最佳，而RAG管道尤其在复杂场景中提供了显著改进。全面的错误分析表明，知识空白是主要的失败模式，文本可读性影响微乎其微。

Conclusion: 这些发现为LLM在金融领域的部署提供了可操作的见解，为从业者提供了模型选择和成本-性能优化的循证指导。

Abstract: The rapid advancement of large language models presents significant
opportunities for financial applications, yet systematic evaluation in
specialized financial contexts remains limited. This study presents the first
comprehensive evaluation of state-of-the-art LLMs using 1,560 multiple-choice
questions from official mock exams across Levels I-III of CFA, most rigorous
professional certifications globally that mirror real-world financial analysis
complexity. We compare models distinguished by core design priorities:
multi-modal and computationally powerful, reasoning-specialized and highly
accurate, and lightweight efficiency-optimized.
  We assess models under zero-shot prompting and through a novel
Retrieval-Augmented Generation pipeline that integrates official CFA curriculum
content. The RAG system achieves precise domain-specific knowledge retrieval
through hierarchical knowledge organization and structured query generation,
significantly enhancing reasoning accuracy in professional financial
certification evaluation.
  Results reveal that reasoning-oriented models consistently outperform others
in zero-shot settings, while the RAG pipeline provides substantial improvements
particularly for complex scenarios. Comprehensive error analysis identifies
knowledge gaps as the primary failure mode, with minimal impact from text
readability. These findings provide actionable insights for LLM deployment in
finance, offering practitioners evidence-based guidance for model selection and
cost-performance optimization.

</details>


### [85] [Multi-Modal Vision vs. Text-Based Parsing: Benchmarking LLM Strategies for Invoice Processing](https://arxiv.org/abs/2509.04469)
*David Berghaus,Armin Berger,Lars Hillebrand,Kostadin Cvejoski,Rafet Sifa*

Main category: cs.CL

TL;DR: 本文对八种多模态大语言模型（GPT-5、Gemini 2.5、Gemma 3系列）在三个发票数据集上进行了零样本基准测试，比较了直接图像处理和结构化解析两种策略，发现直接图像处理通常表现更优。


<details>
  <summary>Details</summary>
Motivation: 为自动化文档系统选择合适的模型和处理策略提供指导和见解。

Method: 使用零样本提示，对来自三个系列（GPT-5、Gemini 2.5、开源Gemma 3）的八种多模态大语言模型进行了基准测试。测试数据集为三个多样化的公开可用发票文档数据集。比较了两种处理策略：直接使用多模态能力处理图像，以及先将文档转换为Markdown再进行结构化解析。

Result: 原生图像处理通常优于结构化解析方法。模型的性能因模型类型和文档特征而异。

Conclusion: 这项基准测试为自动化文档系统选择合适的模型和处理策略提供了有价值的见解。

Abstract: This paper benchmarks eight multi-modal large language models from three
families (GPT-5, Gemini 2.5, and open-source Gemma 3) on three diverse openly
available invoice document datasets using zero-shot prompting. We compare two
processing strategies: direct image processing using multi-modal capabilities
and a structured parsing approach converting documents to markdown first.
Results show native image processing generally outperforms structured
approaches, with performance varying across model types and document
characteristics. This benchmark provides insights for selecting appropriate
models and processing strategies for automated document systems. Our code is
available online.

</details>


### [86] [COCORELI: Cooperative, Compositional Reconstitution \& Execution of Language Instructions](https://arxiv.org/abs/2509.04470)
*Swarnadeep Bhar,Omar Naim,Eleni Metheniti,Bastien Navarri,Loïc Cabannes,Morteza Ezzabady,Nicholas Asher*

Main category: cs.CL

TL;DR: COCORELI是一个混合代理框架，通过结合中型LLM代理、新颖的抽象机制和话语模块，有效解决了大型语言模型在处理复杂指令、减少幻觉和进行空间推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在需要遵循复杂指令、最小化幻觉和进行空间推理的任务中存在局限性，这促使研究者开发COCORELI以克服这些挑战。

Method: COCORELI是一个混合代理框架，它集成了中型LLM代理、新颖的抽象机制以及一个话语模块。该框架通过上下文学习（in-context learn）动态的、高层次的环境表示来解析指令。

Result: 在自然协作构建任务中，COCORELI表现优于使用更大LLM的单一LLM CoT和代理LLM系统。它能很大程度上避免幻觉、识别缺失信息、请求澄清并更新其学习到的对象。此外，COCORELI的抽象能力不仅限于环境，在ToolBench API完成任务中也得到了验证。

Conclusion: COCORELI框架成功地提高了LLM代理在处理复杂指令、减少幻觉和进行空间推理方面的能力，并通过其独特的抽象机制和话语模块实现了优异的性能和泛化能力。

Abstract: We present COCORELI, a hybrid agent framework designed to tackle the
limitations of large language models (LLMs) in tasks requiring: following
complex instructions, minimizing hallucination, and spatial reasoning. COCORELI
integrates medium-sized LLM agents with novel abstraction mechanisms and a
discourse module to parse instructions to in-context learn dynamic, high-level
representations of the environment. Experiments on natural collaborative
construction tasks show that COCORELI outperforms single-LLM CoT and agentic
LLM systems, all using larger LLMs. It manages to largely avoid hallucinations,
identify missing information, ask for clarifications, and update its learned
objects. COCORELI's abstraction abilities extend beyond ENVIRONMENT, as shown
in the ToolBench API completion task.

</details>


### [87] [MOSAIC: A Multilingual, Taxonomy-Agnostic, and Computationally Efficient Approach for Radiological Report Classification](https://arxiv.org/abs/2509.04471)
*Alice Schiavone,Marco Fraccaro,Lea Marie Pehrson,Silvia Ingala,Rasmus Bonnevie,Michael Bachmann Nielsen,Vincent Beliveau,Melanie Ganz,Desmond Elliott*

Main category: cs.CL

TL;DR: MOSAIC是一种多语言、与分类法无关且计算高效的放射学报告分类方法，基于紧凑的开源语言模型，在多语言、多模态数据集上表现出色，为临床环境中的大型或专有LLM提供了实用替代方案。


<details>
  <summary>Details</summary>
Motivation: 现有放射学报告分析方法面临挑战：基于规则的方法难以处理语言变异性；监督模型需要大量标注数据；近期基于LLM的系统依赖闭源或资源密集型模型，不适合临床使用；且大多限于英语和单一模态/分类法。

Method: 引入MOSAIC，一种多语言、与分类法无关且计算高效的方法。它基于紧凑的开源语言模型（MedGemma-4B），支持零/少样本提示和轻量级微调，可在消费级GPU上部署。

Result: MOSAIC在英语、西班牙语、法语和丹麦语的七个多模态和多标签分类法数据集上进行了评估。在五个胸部X光数据集上平均宏观F1得分达到88，接近或超过专家水平，仅需24GB GPU内存。通过数据增强，仅80个标注样本即可在丹麦语报告上达到82的加权F1分数（完整训练集为86）。

Conclusion: MOSAIC为临床环境中大型或专有LLM提供了一个实用且可部署的替代方案。该模型和代码均为开源，鼓励社区评估和扩展其在新的语言、分类法和模态上的应用。

Abstract: Radiology reports contain rich clinical information that can be used to train
imaging models without relying on costly manual annotation. However, existing
approaches face critical limitations: rule-based methods struggle with
linguistic variability, supervised models require large annotated datasets, and
recent LLM-based systems depend on closed-source or resource-intensive models
that are unsuitable for clinical use. Moreover, current solutions are largely
restricted to English and single-modality, single-taxonomy datasets. We
introduce MOSAIC, a multilingual, taxonomy-agnostic, and computationally
efficient approach for radiological report classification. Built on a compact
open-access language model (MedGemma-4B), MOSAIC supports both zero-/few-shot
prompting and lightweight fine-tuning, enabling deployment on consumer-grade
GPUs. We evaluate MOSAIC across seven datasets in English, Spanish, French, and
Danish, spanning multiple imaging modalities and label taxonomies. The model
achieves a mean macro F1 score of 88 across five chest X-ray datasets,
approaching or exceeding expert-level performance, while requiring only 24 GB
of GPU memory. With data augmentation, as few as 80 annotated samples are
sufficient to reach a weighted F1 score of 82 on Danish reports, compared to 86
with the full 1600-sample training set. MOSAIC offers a practical alternative
to large or proprietary LLMs in clinical settings. Code and models are
open-source. We invite the community to evaluate and extend MOSAIC on new
languages, taxonomies, and modalities.

</details>


### [88] [RECAP: REwriting Conversations for Intent Understanding in Agentic Planning](https://arxiv.org/abs/2509.04472)
*Kushan Mitra,Dan Zhang,Hannah Kim,Estevam Hruschka*

Main category: cs.CL

TL;DR: 本文提出了RECAP基准测试和一种意图重写方法，旨在将用户对话转化为简洁的用户目标表示，以解决会话助手（特别是基于LLM的多智能体系统）中意图检测的挑战，从而改善智能体规划。


<details>
  <summary>Details</summary>
Motivation: 在会话助手中，理解用户意图对于有效规划至关重要，但真实世界的对话常常模糊、不明确或动态，使得意图检测成为一个难题。传统的分类方法在开放式设置中难以泛化，导致解释脆弱和下游规划不佳。

Method: 研究者提出了RECAP（REwriting Conversations for Agent Planning）基准测试，用于评估和推进意图重写，将用户-智能体对话重构为用户目标的简洁表示。RECAP涵盖了歧义、意图漂移、模糊性和混合目标对话等挑战。同时，他们引入了一个基于LLM的评估器，根据重写的意图评估规划效用。在此基础上，开发了一种基于提示的重写方法，并进一步通过微调两个基于DPO的重写器来提升效用。

Result: 基于提示的重写方法优于基线模型。通过微调两个基于DPO的重写器，获得了额外的效用提升。研究结果表明，意图重写是改进开放域对话系统中智能体规划的关键且可行的组成部分。

Conclusion: 意图重写是改进开放域对话系统中智能体规划的一个关键且可行的组成部分。通过RECAP基准测试和有效的重写方法，可以显著提升会话助手的规划能力。

Abstract: Understanding user intent is essential for effective planning in
conversational assistants, particularly those powered by large language models
(LLMs) coordinating multiple agents. However, real-world dialogues are often
ambiguous, underspecified, or dynamic, making intent detection a persistent
challenge. Traditional classification-based approaches struggle to generalize
in open-ended settings, leading to brittle interpretations and poor downstream
planning. We propose RECAP (REwriting Conversations for Agent Planning), a new
benchmark designed to evaluate and advance intent rewriting, reframing
user-agent dialogues into concise representations of user goals. RECAP captures
diverse challenges such as ambiguity, intent drift, vagueness, and mixed-goal
conversations. Alongside the dataset, we introduce an LLM-based evaluator that
assesses planning utility given the rewritten intent. Using RECAP, we develop a
prompt-based rewriting approach that outperforms baselines. We further
demonstrate that fine-tuning two DPO-based rewriters yields additional utility
gains. Our results highlight intent rewriting as a critical and tractable
component for improving agent planning in open-domain dialogue systems.

</details>


### [89] [SpeechLLM: Unified Speech and Language Model for Enhanced Multi-Task Understanding in Low Resource Settings](https://arxiv.org/abs/2509.04473)
*Jaekwon Yoo,Kunal Chandiramani,Divya Tadimeti,Abenezer Girma,Chandra Dhir*

Main category: cs.CL

TL;DR: 该研究提出了一种参数高效的适配器，能将语音嵌入转换为LLM兼容的tokens，并结合LLM生成合成数据集，以解决语音编码器与LLM集成时数据和资源不足的问题。该方法在ASR、NER和SA任务上取得了显著性能提升，且训练参数减少7倍。


<details>
  <summary>Details</summary>
Motivation: 将语音编码器与大型语言模型（LLM）集成需要大量数据和资源，但实际应用中数据可用性不足，导致用例受限。

Method: 研究提出了一种参数高效的适配器，用于将语音嵌入转换为LLM兼容的tokens。为降低标注成本，采用了基于LLM的合成数据集标注技术。此外，还使用了分类器正则化和LoRA（Low-Rank Adaptation）等高级技术来优化LLM。

Result: 所提出的适配器使用的可训练参数减少了7倍，并在性能上取得了显著提升：LibriSpeech ASR任务的词错误率（WER）相对改善26%，NER任务的F1分数相对增加6.3%，SA任务的F1分数相对提升32%。结合高级技术，如分类器正则化和LoRA，使口语理解评估（SLUE）分数分别提高了6.6%和9.5%。

Conclusion: 该研究提出的参数高效适配器结合LLM生成的合成数据集，能有效且资源节约地将语音集成到LLM中，并在多个语音理解任务上取得了显著的性能提升，为解决语音-LLM集成中的数据和资源限制提供了可行方案。

Abstract: While integrating speech encoder with LLM requires substantial data and
resources, use cases face limitations due to insufficient availability. To
address this, we propose a solution with a parameter-efficient adapter that
converts speech embeddings into LLM-compatible tokens, focusing on end-to-end
automatic speech recognition (ASR), named entity recognition (NER), and
sentiment analysis (SA). To reduce labeling costs, we employ an LLM-based
synthetic dataset annotation technique. The proposed adapter, using 7x fewer
trainable parameters, achieves significant performance gains: a 26% relative
Word Error Rates (WER) improvement on the LibriSpeech ASR task, a 6.3% relative
F1 score increase on the NER task, and a 32% relative F1 score boost on the SA
task. Moreover, using advanced techniques such as adding a classifier
regularizer and optimizing the LLM with Low-Rank Adaptation (LoRA) yields
notable performance gains, with Spoken Language Understanding Evaluation (SLUE)
score improvement of 6.6% and 9.5%

</details>


### [90] [Scaling Up, Speeding Up: A Benchmark of Speculative Decoding for Efficient LLM Test-Time Scaling](https://arxiv.org/abs/2509.04474)
*Shengyin Sun,Yiming Li,Xing Li,Yingzhao Lian,Weizhe Lin,Hui-Ling Zhen,Zhiyuan Yang,Chen Chen,Xianzhi Yu,Mingxuan Yuan,Chen Ma*

Main category: cs.CL

TL;DR: 本研究引入了一个基准测试，用于评估投机解码方法在加速LLM测试时间扩展方面的效果，发现简单的N-gram方法在处理重复推理时表现出色，并建议结合不同方法。


<details>
  <summary>Details</summary>
Motivation: 测试时间扩展（Test-time scaling）能增强大型语言模型（LLMs）的推理能力，但由于生成冗余和重复的推理痕迹，导致计算效率低下。投机解码（Speculative decoding）有望缓解这种低效率，但在测试时间扩展这种结构化、重复丰富的场景中，其有效性尚未被充分探索。

Method: 引入了第一个全面的基准测试，旨在评估用于加速LLM测试时间扩展的投机解码方法。该基准测试为代表性的测试时间扩展范式（如Best-of-N采样和多轮思考）提供了统一的实验协议，公平比较了三种主要的投机解码类别：基于模型、基于训练和基于N-gram的方法。

Result: 广泛的实验表明，简单的基于N-gram的方法能有效捕获重复模式，在加速测试时间扩展方面展现出独特的潜力。

Conclusion: 基于N-gram的方法可以与基于模型或基于训练的方法相结合，以平衡测试时间扩展中重复和多样化推理的加速效果。该基准测试有望推动投机解码在测试时间扩展方面的进一步研究，通过更好地处理重复和多样化推理路径，实现LLMs更快、更实用的推理。

Abstract: Test-time scaling has emerged as a powerful paradigm for enhancing the
reasoning capabilities of large language models (LLMs) by allocating additional
computational resources during inference. However, this paradigm is inherently
inefficient due to the generation of redundant and repetitive reasoning traces,
leading to significant computational overhead. Speculative decoding offers a
promising avenue for mitigating this inefficiency, yet its efficacy in the
structured, repetition-rich context of test-time scaling remains largely
unexplored. To bridge this gap, we introduce the first comprehensive benchmark
designed to evaluate speculative decoding methods for accelerating LLM
test-time scaling. Our benchmark provides consistent experimental protocols
across representative test-time scaling paradigms (e.g., Best-of-N sampling and
multi-round thinking), enabling a fair comparison of three major categories of
speculative decoding: model-based, training-based, and n-gram-based methods.
Extensive experiments reveal that simple n-gram-based methods effectively
capture repetitive patterns, demonstrating unique potential in accelerating
test-time scaling. This phenomenon demonstrates the value of integrating
n-gram-based methods with model-based or training-based approaches to balance
acceleration for both repetitive and diverse reasoning in test-time scaling. We
hope this benchmark spurs further research on speculative decoding for
test-time scaling, enabling faster and more practical reasoning in LLMs through
better handling of repetitive and diverse reasoning paths.

</details>


### [91] [ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute](https://arxiv.org/abs/2509.04475)
*Hao Wen,Yifan Su,Feifei Zhang,Yunxin Liu,Yunhao Liu,Ya-Qin Zhang,Yuanchun Li*

Main category: cs.CL

TL;DR: 该论文提出了ParaThinker，一个通过并行生成和综合多个多样化推理路径来训练大型语言模型（LLM）的框架，以克服传统顺序推理的“隧道视野”问题，从而实现更高效、更优质的推理。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）的推理能力提升主要依赖于测试时计算扩展，即生成更长的顺序思维过程。然而，这种策略在计算量增加时会遇到瓶颈，即进一步的计算只能带来微小的性能提升。作者认为这不是模型能力的固有局限，而是扩展策略本身的缺陷，称之为“隧道视野”，即模型不完美的初始步骤会将其锁定在次优的推理路径中。

Method: 引入了一种新的扩展范式：原生思维并行化。提出了ParaThinker，一个端到端框架，通过训练LLM并行生成多个多样化的推理路径，并将其综合成一个更优的最终答案。通过同时探索不同的思路，ParaThinker有效地规避了“隧道视野”问题。

Result: 在具有挑战性的推理基准测试中，ParaThinker比顺序LLM取得了显著的准确性提升（对于1.5B模型平均提高12.3%，对于7B模型平均提高7.5%，均使用8条并行路径），同时只增加了可忽略的延迟开销（7.1%）。这使得较小的模型能够超越大得多的模型。

Conclusion: 并行思维是比简单顺序扩展（深度）更有效、更高效的卓越推理方式，它能够解锁模型的潜在推理能力，并确立了并行思维作为未来LLM扩展的关键、高效维度。

Abstract: Recent advances in Large Language Models (LLMs) have been driven by test-time
compute scaling - a strategy that improves reasoning by generating longer,
sequential thought processes. While effective, this approach encounters a
significant bottleneck as computation increases, where further computation
offers only marginal performance gains. We argue this ceiling is not an
inherent limit of the model's capability but a flaw in the scaling strategy
itself, a phenomenon we term "Tunnel Vision", where a model's imperfect initial
steps lock it into a suboptimal reasoning path. To overcome this, we introduce
a new scaling paradigm: native thought parallelism. We present ParaThinker, an
end-to-end framework that trains an LLM to generate multiple, diverse reasoning
paths in parallel and synthesize them into a superior final answer. By
exploring different lines of thoughts simultaneously, ParaThinker effectively
sidesteps the Tunnel Vision issue and unlocks the model's latent reasoning
potential. Our approach demonstrates that scaling compute in parallel (width)
is a more effective and efficient way to superior reasoning than simply scaling
sequentially (depth). On challenging reasoning benchmarks, ParaThinker achieves
substantial accuracy improvements over sequential LLMs (12.3% for 1.5B and 7.5%
for 7B models on average with 8 parallel paths), while adding only negligible
latency overhead (7.1%). This enables smaller models to surpass much larger
counterparts and establishes parallel thinking as a critical, efficient
dimension for scaling future LLMs.

</details>


### [92] [Training Text-to-Molecule Models with Context-Aware Tokenization](https://arxiv.org/abs/2509.04476)
*Seojin Kim,Hyeontae Song,Jaehyun Nam,Jinwoo Shin*

Main category: cs.CL

TL;DR: 现有文本到分子模型因原子级分词而缺乏全局结构上下文。CAMT5通过引入子结构级分词和基于重要性的训练策略，有效捕捉分子语义，在文本到分子生成任务中表现优异，且训练效率更高。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到分子模型依赖原子级分词，主要关注局部连接性，限制了模型捕捉分子内全局结构上下文的能力。

Method: 本文提出了上下文感知分子T5 (CAMT5) 模型。核心方法包括：1) 引入子结构级分词（如环系统）来理解分子结构；2) 开发一种基于重要性的训练策略，优先处理关键子结构；3) 提出一种简单有效的集成策略，聚合多个文本到分子模型的输出以进一步提升性能。

Result: CAMT5在各种文本到分子生成任务中均优于现有最先进的方法。值得注意的是，CAMT5仅使用2%的训练token就超越了SOTA方法。此外，提出的集成策略能进一步提高生成性能。

Conclusion: 通过子结构级分词和基于重要性的训练策略，CAMT5显著提升了文本到分子模型捕捉全局分子语义的能力，实现了卓越的生成性能和更高的训练效率。

Abstract: Recently, text-to-molecule models have shown great potential across various
chemical applications, e.g., drug-discovery. These models adapt language models
to molecular data by representing molecules as sequences of atoms. However,
they rely on atom-level tokenizations, which primarily focus on modeling local
connectivity, thereby limiting the ability of models to capture the global
structural context within molecules. To tackle this issue, we propose a novel
text-to-molecule model, coined Context-Aware Molecular T5 (CAMT5). Inspired by
the significance of the substructure-level contexts in understanding molecule
structures, e.g., ring systems, we introduce substructure-level tokenization
for text-to-molecule models. Building on our tokenization scheme, we develop an
importance-based training strategy that prioritizes key substructures, enabling
CAMT5 to better capture the molecular semantics. Extensive experiments verify
the superiority of CAMT5 in various text-to-molecule generation tasks.
Intriguingly, we find that CAMT5 outperforms the state-of-the-art methods using
only 2% of training tokens. In addition, we propose a simple yet effective
ensemble strategy that aggregates the outputs of text-to-molecule models to
further boost the generation performance. Code is available at
https://github.com/Songhyeontae/CAMT5.git.

</details>


### [93] [An End-to-End System for Culturally-Attuned Driving Feedback using a Dual-Component NLG Engine](https://arxiv.org/abs/2509.04478)
*Iniakpokeikiye Peter Thompson,Yi Dewei,Reiter Ehud*

Main category: cs.CL

TL;DR: 本文提出了一个针对尼日利亚低资源环境的端到端移动系统，通过新颖的双组件自然语言生成（NLG）引擎和机器学习模型，提供文化适应的安全驾驶反馈。


<details>
  <summary>Details</summary>
Motivation: 在尼日利亚等基础设施挑战显著的低资源环境中，需要为驾驶员提供安全驾驶反馈，并解决酒精影响驾驶等当地关键安全问题。

Method: 开发了一个端到端移动系统，其核心是一个双组件NLG引擎，提供基于法律的安全提示和理论驱动的行为报告。系统架构包括自动行程检测服务、设备端行为分析、利用两步反射过程的高质量NLG管道，以及一个专门用于检测酒精影响驾驶的机器学习模型。该架构还针对间歇性连接和嘈杂传感器数据进行了鲁棒性设计。

Result: 对90名司机进行的试点部署证明了该方法的可行性，并展示了检测到的不安全行为的初步结果。

Conclusion: 这项工作为应用数据到文本和人工智能系统以实现社会效益提供了一个框架。

Abstract: This paper presents an end-to-end mobile system that delivers
culturally-attuned safe driving feedback to drivers in Nigeria, a low-resource
environment with significant infrastructural challenges. The core of the system
is a novel dual-component Natural Language Generation (NLG) engine that
provides both legally-grounded safety tips and persuasive, theory-driven
behavioural reports. We describe the complete system architecture, including an
automatic trip detection service, on-device behaviour analysis, and a
sophisticated NLG pipeline that leverages a two-step reflection process to
ensure high-quality feedback. The system also integrates a specialized machine
learning model for detecting alcohol-influenced driving, a key local safety
issue. The architecture is engineered for robustness against intermittent
connectivity and noisy sensor data. A pilot deployment with 90 drivers
demonstrates the viability of our approach, and initial results on detected
unsafe behaviours are presented. This work provides a framework for applying
data-to-text and AI systems to achieve social good.

</details>


### [94] [No Clustering, No Routing: How Transformers Actually Process Rare Tokens](https://arxiv.org/abs/2509.04479)
*Jing Liu*

Main category: cs.CL

TL;DR: 大型语言模型中罕见词元预测的专业化是由分布式、训练驱动的分化而非架构模块化产生的，它通过额外的“高原”神经元实现，这些神经元空间分散且不依赖于注意力机制的优先路由。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在罕见词元预测上表现不佳，其专业化机制尚不明确。先前的研究识别出处理罕见词元的“高原”神经元，但其功能组织方式未知。

Method: 通过神经元影响分析、基于图的聚类和注意力头消融实验，在GPT-2 XL和Pythia模型上进行研究。

Result: 1) 罕见词元处理需要超出常见词元所需（幂律机制）的额外“高原”神经元，形成双重计算机制；2) “高原”神经元空间上分散分布，而非形成模块化集群；3) 注意力机制未显示出对专业神经元的优先路由。

Conclusion: 罕见词元专业化是通过分布式、训练驱动的分化而非架构模块化产生的，这在实现自适应容量分配的同时，保留了上下文敏感的灵活性。

Abstract: Large language models struggle with rare token prediction, yet the mechanisms
driving their specialization remain unclear. Prior work identified specialized
``plateau'' neurons for rare tokens following distinctive three-regime
influence patterns \cite{liu2025emergent}, but their functional organization is
unknown. We investigate this through neuron influence analyses, graph-based
clustering, and attention head ablations in GPT-2 XL and Pythia models. Our
findings show that: (1) rare token processing requires additional plateau
neurons beyond the power-law regime sufficient for common tokens, forming dual
computational regimes; (2) plateau neurons are spatially distributed rather
than forming modular clusters; and (3) attention mechanisms exhibit no
preferential routing to specialists. These results demonstrate that rare token
specialization arises through distributed, training-driven differentiation
rather than architectural modularity, preserving context-sensitive flexibility
while achieving adaptive capacity allocation.

</details>


### [95] [Discrete Prompt Tuning via Recursive Utilization of Black-box Multimodal Large Language Model for Personalized Visual Emotion Recognition](https://arxiv.org/abs/2509.04480)
*Ryo Takahashi,Naoki Saito,Keisuke Maeda,Takahiro Ogawa,Miki Haseyama*

Main category: cs.CL

TL;DR: 本文提出一种离散提示调整方法，通过模仿人类提示工程，将多模态大语言模型（MLLMs）适应于个性化视觉情感识别（VER），以克服其偏向多数观点的局限性。


<details>
  <summary>Details</summary>
Motivation: 视觉情感识别（VER）应用广泛，个性化VER尤为关键。然而，现有MLLMs在个性化VER中表现受限，因为它们倾向于多数观点和常见模式，无法满足实际应用需求。

Method: 该方法采用受人类提示工程启发的离散提示调整技术，为每个个体调整VER任务。它从生成的提示中选择最佳的自然语言表示，并用其更新提示，以实现准确的个性化VER。

Result: 通过提出的离散提示调整方法，MLLMs能够适应个性化VER任务，从而克服其对一般观点的偏好，实现准确的个性化视觉情感识别。

Conclusion: 所提出的离散提示调整方法有效解决了MLLMs在个性化视觉情感识别中偏向多数观点的问题，为实现准确和实用的个性化VER提供了关键改进。

Abstract: Visual Emotion Recognition (VER) is an important research topic due to its
wide range of applications, including opinion mining and advertisement design.
Extending this capability to recognize emotions at the individual level further
broadens its potential applications. Recently, Multimodal Large Language Models
(MLLMs) have attracted increasing attention and demonstrated performance
comparable to that of conventional VER methods. However, MLLMs are trained on
large and diverse datasets containing general opinions, which causes them to
favor majority viewpoints and familiar patterns. This tendency limits their
performance in a personalized VER, which is crucial for practical and
real-world applications, and indicates a key area for improvement. To address
this limitation, the proposed method employs discrete prompt tuning inspired by
the process of humans' prompt engineering to adapt the VER task to each
individual. Our method selects the best natural language representation from
the generated prompts and uses it to update the prompt for the realization of
accurate personalized VER.

</details>


### [96] [Energy Landscapes Enable Reliable Abstention in Retrieval-Augmented Large Language Models for Healthcare](https://arxiv.org/abs/2509.04482)
*Ravi Shankar,Sheng Wong,Lin Li,Magdalena Bachmann,Alex Silverthorne,Beth Albert,Gabriel Davis Jones*

Main category: cs.CL

TL;DR: 该研究提出了一种基于能量模型（EBM）的检索增强生成（RAG）系统拒答机制，在语义困难的近分布查询上，其性能优于传统的softmax和kNN方法，特别是在安全关键领域。


<details>
  <summary>Details</summary>
Motivation: 在女性健康等安全关键领域，RAG系统的不准确回答可能导致危害，因此可靠的拒答功能至关重要。传统的置信度评估方法可能不足以处理语义上具有挑战性的查询。

Method: 研究构建了一个基于能量模型（EBM），通过在包含260万个指南衍生问题的密集语义语料库上学习平滑的能量景观，使系统能够决定何时生成或拒答。该EBM与校准的softmax基线和kNN密度启发式方法在简单和困难的拒答情境下进行了基准测试。通过受控的负采样和公平的数据暴露进行了全面的消融实验。

Result: EBM在语义困难的拒答案例上取得了卓越的性能，AUROC达到0.961（softmax为0.950），FPR@95降低至0.235（softmax为0.331）。在简单负例上，各种方法性能相当。EBM的鲁棒性主要源于其能量评分头，而不同负例类型的包含或排除仅能锐化决策边界，但并非泛化到困难案例的关键。

Conclusion: 基于能量的拒答评分提供了比基于概率的softmax置信度更可靠的置信信号，为构建安全的RAG系统提供了可扩展且可解释的基础。

Abstract: Reliable abstention is critical for retrieval-augmented generation (RAG)
systems, particularly in safety-critical domains such as women's health, where
incorrect answers can lead to harm. We present an energy-based model (EBM) that
learns a smooth energy landscape over a dense semantic corpus of 2.6M
guideline-derived questions, enabling the system to decide when to generate or
abstain. We benchmark the EBM against a calibrated softmax baseline and a
k-nearest neighbour (kNN) density heuristic across both easy and hard
abstention splits, where hard cases are semantically challenging
near-distribution queries. The EBM achieves superior abstention performance
abstention on semantically hard cases, reaching AUROC 0.961 versus 0.950 for
softmax, while also reducing FPR@95 (0.235 vs 0.331). On easy negatives,
performance is comparable across methods, but the EBM's advantage becomes most
pronounced in safety-critical hard distributions. A comprehensive ablation with
controlled negative sampling and fair data exposure shows that robustness stems
primarily from the energy scoring head, while the inclusion or exclusion of
specific negative types (hard, easy, mixed) sharpens decision boundaries but is
not essential for generalisation to hard cases. These results demonstrate that
energy-based abstention scoring offers a more reliable confidence signal than
probability-based softmax confidence, providing a scalable and interpretable
foundation for safe RAG systems.

</details>


### [97] [DecMetrics: Structured Claim Decomposition Scoring for Factually Consistent LLM Outputs](https://arxiv.org/abs/2509.04483)
*Minghui Huang*

Main category: cs.CL

TL;DR: 该论文引入了DecMetrics，一套包含COMPLETENESS、CORRECTNESS和SEMANTIC ENTROPY的新指标，用于自动评估声明分解模型的质量，并利用这些指标优化了一个轻量级分解模型。


<details>
  <summary>Details</summary>
Motivation: 尽管声明分解在事实核查中至关重要，但当前研究主要集中于生成方法，对分解出的原子声明质量评估关注不足，存在评估空白。

Method: 引入了DecMetrics，包含COMPLETENESS、CORRECTNESS和SEMANTIC ENTROPY三个新指标，用于自动评估分解声明的质量。此外，开发了一个轻量级声明分解模型，并以这些指标作为奖励函数进行优化。

Result: 通过自动评估，该方法旨在为声明分解设定基准，提高事实核查系统的可靠性和有效性。

Conclusion: 通过引入新的评估指标和优化方法，本研究显著提升了声明分解的质量评估能力，并有望改善事实核查系统的整体性能。

Abstract: Claim decomposition plays a crucial role in the fact-checking process by
breaking down complex claims into simpler atomic components and identifying
their unfactual elements. Despite its importance, current research primarily
focuses on generative methods for decomposition, with insufficient emphasis on
evaluating the quality of these decomposed atomic claims. To bridge this gap,
we introduce \textbf{DecMetrics}, which comprises three new metrics:
\texttt{COMPLETENESS}, \texttt{CORRECTNESS}, and \texttt{SEMANTIC ENTROPY},
designed to automatically assess the quality of claims produced by
decomposition models. Utilizing these metrics, we develop a lightweight claim
decomposition model, optimizing its performance through the integration of
these metrics as a reward function. Through automatic evaluation, our approach
aims to set a benchmark for claim decomposition, enhancing both the reliability
and effectiveness of fact-checking systems.

</details>


### [98] [The Good, the Bad and the Constructive: Automatically Measuring Peer Review's Utility for Authors](https://arxiv.org/abs/2509.04484)
*Abdelrahman Sadallah,Tim Baumgärtner,Iryna Gurevych,Ted Briscoe*

Main category: cs.CL

TL;DR: 该研究引入了RevUtil数据集和微调模型，用于评估同行评审评论的实用性（基于可操作性、基础与特异性、可验证性和帮助性四个方面）。这些模型在某些方面表现优于GPT-4o，但分析显示机器生成的评论总体上不如人类评论。


<details>
  <summary>Details</summary>
Motivation: 随着审稿人用于评审的时间越来越少，需要自动化支持系统来确保高质量的评审，从而为作者提供有用的反馈。这促使研究者识别并评估评审评论中驱动其实用性的关键方面。

Method: 研究者确定了评审评论的四个关键方面：可操作性、基础与特异性、可验证性和帮助性。为此，他们创建了RevUtil数据集，包含1,430条人工标注的评论和1万条带理由的合成标注评论。利用该数据集，他们对微调模型进行了基准测试，以评估评论的这些方面并生成理由。

Result: 实验表明，微调模型在评估评审评论方面与人类达成了一致，在某些情况下甚至超过了GPT-4o等强大的闭源模型。然而，分析也揭示机器生成的评论在所定义的四个方面上普遍不如人类评论。

Conclusion: 该研究成功开发了用于评估评审评论实用性的数据集和模型，证明了其在自动化评审支持方面的潜力。同时，研究也强调了当前机器生成评论与人类评论在质量上仍存在差距。

Abstract: Providing constructive feedback to paper authors is a core component of peer
review. With reviewers increasingly having less time to perform reviews,
automated support systems are required to ensure high reviewing quality, thus
making the feedback in reviews useful for authors. To this end, we identify
four key aspects of review comments (individual points in weakness sections of
reviews) that drive the utility for authors: Actionability, Grounding &
Specificity, Verifiability, and Helpfulness. To enable evaluation and
development of models assessing review comments, we introduce the RevUtil
dataset. We collect 1,430 human-labeled review comments and scale our data with
10k synthetically labeled comments for training purposes. The synthetic data
additionally contains rationales, i.e., explanations for the aspect score of a
review comment. Employing the RevUtil dataset, we benchmark fine-tuned models
for assessing review comments on these aspects and generating rationales. Our
experiments demonstrate that these fine-tuned models achieve agreement levels
with humans comparable to, and in some cases exceeding, those of powerful
closed models like GPT-4o. Our analysis further reveals that machine-generated
reviews generally underperform human reviews on our four aspects.

</details>


### [99] [ASCENDgpt: A Phenotype-Aware Transformer Model for Cardiovascular Risk Prediction from Electronic Health Records](https://arxiv.org/abs/2509.04485)
*Chris Sainsbury,Andreas Karwath*

Main category: cs.CL

TL;DR: ASCENDgpt是一个基于Transformer的模型，利用创新的表型感知分词方案，从纵向电子健康记录（EHRs）中预测心血管疾病风险，实现了高效且可解释的预测，并取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 从纵向电子健康记录中进行心血管风险预测面临挑战，需要一种既能有效处理海量原始诊断代码，又能保持临床语义信息和计算效率的方法。

Method: 该研究提出了ASCENDgpt模型，其核心方法包括：1) 创新的表型感知分词方案，将47,155个原始ICD代码映射为176个临床有意义的表型标记，实现了99.6%的诊断代码整合和77.9%的词汇量缩减；2) 在19,402名个体的序列数据上使用掩码语言建模进行预训练；3) 针对心肌梗死、中风、主要不良心血管事件、心血管死亡和全因死亡等五种心血管结局进行时间到事件预测的微调。

Result: ASCENDgpt模型在测试集上取得了出色的判别能力，平均C-index为0.816。具体结果包括：心肌梗死0.792，中风0.824，主要不良心血管事件0.800，心血管死亡0.842，全因死亡0.824。这种基于表型的方法在保持计算效率的同时，实现了临床可解释的预测。

Conclusion: 该工作证明了领域特定分词和预训练对于基于EHR的风险预测任务的有效性，ASCENDgpt为心血管风险预测提供了一个高性能、高效率且可解释的解决方案。

Abstract: We present ASCENDgpt, a transformer-based model specifically designed for
cardiovascular risk prediction from longitudinal electronic health records
(EHRs). Our approach introduces a novel phenotype-aware tokenization scheme
that maps 47,155 raw ICD codes to 176 clinically meaningful phenotype tokens,
achieving 99.6\% consolidation of diagnosis codes while preserving semantic
information. This phenotype mapping contributes to a total vocabulary of 10,442
tokens - a 77.9\% reduction when compared with using raw ICD codes directly. We
pretrain ASCENDgpt on sequences derived from 19402 unique individuals using a
masked language modeling objective, then fine-tune for time-to-event prediction
of five cardiovascular outcomes: myocardial infarction (MI), stroke, major
adverse cardiovascular events (MACE), cardiovascular death, and all-cause
mortality. Our model achieves excellent discrimination on the held-out test set
with an average C-index of 0.816, demonstrating strong performance across all
outcomes (MI: 0.792, stroke: 0.824, MACE: 0.800, cardiovascular death: 0.842,
all-cause mortality: 0.824). The phenotype-based approach enables clinically
interpretable predictions while maintaining computational efficiency. Our work
demonstrates the effectiveness of domain-specific tokenization and pretraining
for EHR-based risk prediction tasks.

</details>


### [100] [Serialized Output Prompting for Large Language Model-based Multi-Talker Speech Recognition](https://arxiv.org/abs/2509.04488)
*Hao Shi,Yusuke Fujita,Tomoya Mizumoto,Lianbo Liu,Atsushi Kojima,Yui Sudo*

Main category: cs.CL

TL;DR: 本文提出了一种名为序列化输出提示（SOP）的方法，通过显式引导大型语言模型（LLM）来显著提升基于LLM的多说话人自动语音识别（ASR）系统的性能，尤其是在复杂场景下。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的多说话人ASR系统要么省略提示，要么仅使用简单的任务定义提示，缺乏对提示设计以提升系统性能的探索。这限制了LLM在处理多说话人场景时的潜力。

Method: 研究人员在语音编码器后插入分离器和序列化连接时序分类（CTC）层，以“先说先出”的方式从混合语音编码中提取多说话人内容。通过贪婪搜索解码序列化CTC输出，得到作为LLM提示的SOP。同时，设计了三阶段训练策略：序列化输出训练（SOT）微调、序列化语音信息提取和基于SOP的适应。

Result: 实验结果显示，尽管基于LLM的SOT模型在双说话人场景中表现良好，但在更复杂的三说话人场景中未能充分利用LLM。所提出的SOP方法在双说话人和三说话人条件下均显著提升了系统性能。

Conclusion: SOP方法通过提取序列化输出并显式引导LLM，有效解决了现有LLM-based多说话人ASR系统在复杂场景下的性能瓶颈，显著提升了系统在多说话人条件下的识别准确性。

Abstract: Prompts are crucial for task definition and for improving the performance of
large language models (LLM)-based systems. However, existing LLM-based
multi-talker (MT) automatic speech recognition (ASR) systems either omit
prompts or rely on simple task-definition prompts, with no prior work exploring
the design of prompts to enhance performance. In this paper, we propose
extracting serialized output prompts (SOP) and explicitly guiding the LLM using
structured prompts to improve system performance (SOP-MT-ASR). A Separator and
serialized Connectionist Temporal Classification (CTC) layers are inserted
after the speech encoder to separate and extract MT content from the mixed
speech encoding in a first-speaking-first-out manner. Subsequently, the SOP,
which serves as a prompt for LLMs, is obtained by decoding the serialized CTC
outputs using greedy search. To train the model effectively, we design a
three-stage training strategy, consisting of serialized output training (SOT)
fine-tuning, serialized speech information extraction, and SOP-based
adaptation. Experimental results on the LibriMix dataset show that, although
the LLM-based SOT model performs well in the two-talker scenario, it fails to
fully leverage LLMs under more complex conditions, such as the three-talker
scenario. The proposed SOP approach significantly improved performance under
both two- and three-talker conditions.

</details>


### [101] [Refining Transcripts With TV Subtitles by Prompt-Based Weakly Supervised Training of ASR](https://arxiv.org/abs/2509.04491)
*Xinnian Zhao,Hugo Van Hamme*

Main category: cs.CL

TL;DR: 本研究提出一种新的弱监督ASR方法，利用电视字幕作为上下文丰富的提示，通过迭代细化伪转录本，显著提高了转录准确性。


<details>
  <summary>Details</summary>
Motivation: 电视字幕虽然易得，但与对应音频的对齐不精确，限制了其作为监督信号的直接应用。需要一种方法来有效利用这些不精确的字幕。

Method: 该方法将字幕视为上下文丰富的提示，而非直接监督信号。生成的伪转录本成为主要目标，字幕作为指导线索进行迭代细化。此外，引入加权注意力机制，在推断时强调相关字幕标记。

Result: 实验证明转录准确性显著提高，表明所提出方法在细化转录本方面的有效性。这些增强的伪标记数据集为训练鲁棒的ASR系统提供了高质量的基础资源。

Conclusion: 所提出的方法能够有效利用不精确的电视字幕来细化转录本，生成高质量的伪标记数据集，从而为训练强大的ASR系统奠定基础。

Abstract: This study proposes a novel approach to using TV subtitles within a weakly
supervised (WS) Automatic Speech Recognition (ASR) framework. Although TV
subtitles are readily available, their imprecise alignment with corresponding
audio limits their applicability as supervised targets for verbatim
transcription. Rather than using subtitles as direct supervision signals, our
method reimagines them as context-rich prompts. This design enables the model
to handle discrepancies between spoken audio and subtitle text. Instead,
generated pseudo transcripts become the primary targets, with subtitles acting
as guiding cues for iterative refinement. To further enhance the process, we
introduce a weighted attention mechanism that emphasizes relevant subtitle
tokens during inference. Our experiments demonstrate significant improvements
in transcription accuracy, highlighting the effectiveness of the proposed
method in refining transcripts. These enhanced pseudo-labeled datasets provide
high-quality foundational resources for training robust ASR systems.

</details>


### [102] [Learned Hallucination Detection in Black-Box LLMs using Token-level Entropy Production Rate](https://arxiv.org/abs/2509.04492)
*Charles Moslonka,Hicham Randrianarivo,Arthur Garnier,Emmanuel Malherbe*

Main category: cs.CL

TL;DR: 本文提出了一种针对LLM问答任务中幻觉的单次检测方法，该方法利用非贪婪解码过程中有限的对数概率（例如，每个token的前10个）来推导不确定性指标，并通过监督学习进行增强，显著提高了检测性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在问答任务中的幻觉严重损害了其在实际应用中的可靠性。尤其是在数据访问受限（如与黑盒LLM API交互，只能获取少量排名靠前的token对数概率）的场景下，急需一种鲁棒的幻觉检测方法。

Method: 该方法直接从非贪婪解码过程中生成的、易于获取的对数概率中推导不确定性指标。首先，提出了一种熵产生率（EPR）度量作为基线性能。然后，通过监督学习对EPR进行增强，利用单个生成序列中可访问的排名靠前token的熵贡献作为特征。该方法无需多次查询重跑，仅依赖于每个token通常可用的少量对数概率。

Result: 该方法在不同的问答数据集和多个LLM上进行了评估，结果表明其幻觉检测性能显著优于单独使用EPR。关键是，即使仅使用通常很小的可用对数概率集（例如，每个token的前10个），也能表现出高检测性能，证实了其在API受限部署中的实用性和效率。该技术在金融框架中（分析年度报告查询响应）也得到了应用验证。

Conclusion: 这项工作提供了一种易于部署的技术，可以在问答（QA）和检索增强生成（RAG）系统中，通过单次生成过程提高LLM响应的可信度。其在API受限环境中的高效性及其在工业数据集上的成功应用进一步证明了其价值。

Abstract: Hallucinations in Large Language Model (LLM) outputs for Question Answering
(QA) tasks critically undermine their real-world reliability. This paper
introduces an applied methodology for robust, one-shot hallucination detection,
specifically designed for scenarios with limited data access, such as
interacting with black-box LLM APIs that typically expose only a few top
candidate log-probabilities per token. Our approach derives uncertainty
indicators directly from these readily available log-probabilities generated
during non-greedy decoding. We first derive an Entropy Production Rate (EPR)
metric that offers baseline performance, later augmented with supervised
learning. Our learned model uses features representing the entropic
contributions of the accessible top-ranked tokens within a single generated
sequence, requiring no multiple query re-runs. Evaluated across diverse QA
datasets and multiple LLMs, this estimator significantly improves hallucination
detection over using EPR alone. Crucially, high performance is demonstrated
using only the typically small set of available log-probabilities (e.g., top
<10 per token), confirming its practical efficiency and suitability for these
API-constrained deployments. This work provides a readily deployable technique
to enhance the trustworthiness of LLM responses from a single generation pass
in QA and Retrieval-Augmented Generation (RAG) systems, with its utility
further demonstrated in a finance framework analyzing responses to queries on
annual reports from an industrial dataset.

</details>


### [103] [A Narrative-Driven Computational Framework for Clinician Burnout Surveillance](https://arxiv.org/abs/2509.04497)
*Syed Ahmad Chan Bukhari,Fazel Keshtkar,Alyssa Meczkowska*

Main category: cs.CL

TL;DR: 本研究利用混合自然语言处理（NLP）方法分析ICU出院总结中的临床叙述文本，以识别临床医生职业倦怠风险，并发现临床叙述中包含可操作的预警信号。


<details>
  <summary>Details</summary>
Motivation: 临床医生职业倦怠对患者安全构成重大威胁，尤其是在高危重症监护室（ICU）。现有研究主要依赖回顾性调查或宽泛的电子健康记录（EHR）元数据，往往忽视了临床笔记中嵌入的宝贵叙述信息，因此需要一种更有效的方法来利用这些信息进行主动监测。

Method: 研究分析了来自MIMIC-IV数据库的10,000份ICU出院总结，该数据集包含生命体征、医疗指令、诊断、程序、治疗和去识别化的自由文本临床笔记。研究引入了一个混合管道，结合了为临床叙述微调的BioBERT情感嵌入、为临床医生职业倦怠监测量身定制的词汇压力词典，以及包含工作量代理的五主题潜在狄利克雷分配（LDA）。最终使用提供者级别的逻辑回归分类器进行风险预测。

Result: 在分层保留集上，提供者级别的逻辑回归分类器实现了0.80的精确度、0.89的召回率和0.84的F1分数，F1分数超过仅使用元数据的基线至少0.17。专业特异性分析表明，放射科、精神病学和神经内科的提供者职业倦怠风险较高。

Conclusion: ICU临床叙述中包含可操作的信号，可用于主动监测临床医生的福祉，证明了利用自然语言处理从临床笔记中提取此类信息的有效性。

Abstract: Clinician burnout poses a substantial threat to patient safety, particularly
in high-acuity intensive care units (ICUs). Existing research predominantly
relies on retrospective survey tools or broad electronic health record (EHR)
metadata, often overlooking the valuable narrative information embedded in
clinical notes. In this study, we analyze 10,000 ICU discharge summaries from
MIMIC-IV, a publicly available database derived from the electronic health
records of Beth Israel Deaconess Medical Center. The dataset encompasses
diverse patient data, including vital signs, medical orders, diagnoses,
procedures, treatments, and deidentified free-text clinical notes. We introduce
a hybrid pipeline that combines BioBERT sentiment embeddings fine-tuned for
clinical narratives, a lexical stress lexicon tailored for clinician burnout
surveillance, and five-topic latent Dirichlet allocation (LDA) with workload
proxies. A provider-level logistic regression classifier achieves a precision
of 0.80, a recall of 0.89, and an F1 score of 0.84 on a stratified hold-out
set, surpassing metadata-only baselines by greater than or equal to 0.17 F1
score. Specialty-specific analysis indicates elevated burnout risk among
providers in Radiology, Psychiatry, and Neurology. Our findings demonstrate
that ICU clinical narratives contain actionable signals for proactive
well-being monitoring.

</details>


### [104] [Where Should I Study? Biased Language Models Decide! Evaluating Fairness in LMs for Academic Recommendations](https://arxiv.org/abs/2509.04498)
*Krithi Shailya,Akhilesh Kumar Mishra,Gokul S Krishnan,Balaraman Ravindran*

Main category: cs.CL

TL;DR: 本研究发现，用于教育规划的开源大型语言模型（LLMs）存在严重的地理、人口和经济偏见，过度偏爱全球北方机构并强化性别刻板印象。文章提出了一个多维度评估框架，并强调了在教育LLM中考虑偏见的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）日益被用作教育规划等任务的推荐系统，但其推荐存在延续社会偏见的风险，这可能影响高等教育的公平可及性。

Method: 研究通过360个模拟用户档案（性别、国籍、经济状况），分析了LLaMA-3.1-8B、Gemma-7B和Mistral-7B三个开源LLM的25,000多条大学和项目推荐。为量化这些问题，论文还提出了一个超越准确性、衡量人口和地理代表性的新型多维度评估框架。

Result: 研究结果显示LLMs存在显著偏见：全球北方机构被不成比例地偏爱；推荐常强化性别刻板印象；机构推荐重复性高。尽管LLaMA-3.1在多样性方面表现最佳（推荐了58个国家的481所独特大学），但系统性差异依然普遍存在。

Conclusion: 研究发现凸显了在教育领域LLMs中迫切需要考虑偏见问题，以确保全球高等教育的公平可及性。

Abstract: Large Language Models (LLMs) are increasingly used as daily recommendation
systems for tasks like education planning, yet their recommendations risk
perpetuating societal biases. This paper empirically examines geographic,
demographic, and economic biases in university and program suggestions from
three open-source LLMs: LLaMA-3.1-8B, Gemma-7B, and Mistral-7B. Using 360
simulated user profiles varying by gender, nationality, and economic status, we
analyze over 25,000 recommendations. Results show strong biases: institutions
in the Global North are disproportionately favored, recommendations often
reinforce gender stereotypes, and institutional repetition is prevalent. While
LLaMA-3.1 achieves the highest diversity, recommending 481 unique universities
across 58 countries, systemic disparities persist. To quantify these issues, we
propose a novel, multi-dimensional evaluation framework that goes beyond
accuracy by measuring demographic and geographic representation. Our findings
highlight the urgent need for bias consideration in educational LMs to ensure
equitable global access to higher education.

</details>


### [105] [DeepTRACE: Auditing Deep Research AI Systems for Tracking Reliability Across Citations and Evidence](https://arxiv.org/abs/2509.04499)
*Pranav Narayanan Venkit,Philippe Laban,Yilun Zhou,Kung-Hsiang Huang,Yixin Mao,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 本研究引入了DeepTRACE审计框架，用于评估生成式搜索引擎和深度研究LLM代理在可信度、来源引用和事实支持方面的表现。研究发现，这些系统普遍存在过度自信、片面性以及大量陈述未被其引用来源支持的问题，即使是深度研究配置也未能完全解决这些挑战。


<details>
  <summary>Details</summary>
Motivation: 生成式搜索引擎和深度研究LLM代理承诺提供可信、基于来源的综合信息，但用户经常遇到过度自信、来源薄弱和引用实践混乱的问题。因此，需要一个框架来识别和衡量这些已知的失败案例。

Method: 研究引入了DeepTRACE，一个基于社会技术学的审计框架，将社区识别的失败案例转化为八个可衡量的维度，涵盖答案文本、来源和引用。它使用陈述级分析（分解、置信度评分）并构建引用和事实支持矩阵。通过自动化提取管道评估了流行的公共模型（如GPT-4.5/5, You.com, Perplexity, Copilot/Bing, Gemini），并使用与人类评估者达成一致的LLM判官，评估了网络搜索引擎和深度研究配置。

Result: 研究发现，生成式搜索引擎和深度研究代理在辩论查询上经常产生片面、高度自信的回答，并且包含大量未被其列出来源支持的陈述。深度研究配置虽然能降低过度自信并达到较高的引用彻底性，但在辩论查询上仍高度片面，且仍显示大量未被支持的陈述，系统间的引用准确率在40-80%之间。

Conclusion: 尽管生成式搜索引擎和深度研究LLM代理承诺提供可信信息，但它们普遍存在过度自信、片面性以及其自身来源无法支持大量陈述的问题。虽然深度研究配置在降低过度自信和提高引用彻底性方面有所帮助，但仍未能解决片面性和未支持陈述的根本问题，引用准确性也存在显著不足。

Abstract: Generative search engines and deep research LLM agents promise trustworthy,
source-grounded synthesis, yet users regularly encounter overconfidence, weak
sourcing, and confusing citation practices. We introduce DeepTRACE, a novel
sociotechnically grounded audit framework that turns prior community-identified
failure cases into eight measurable dimensions spanning answer text, sources,
and citations. DeepTRACE uses statement-level analysis (decomposition,
confidence scoring) and builds citation and factual-support matrices to audit
how systems reason with and attribute evidence end-to-end. Using automated
extraction pipelines for popular public models (e.g., GPT-4.5/5, You.com,
Perplexity, Copilot/Bing, Gemini) and an LLM-judge with validated agreement to
human raters, we evaluate both web-search engines and deep-research
configurations. Our findings show that generative search engines and deep
research agents frequently produce one-sided, highly confident responses on
debate queries and include large fractions of statements unsupported by their
own listed sources. Deep-research configurations reduce overconfidence and can
attain high citation thoroughness, but they remain highly one-sided on debate
queries and still exhibit large fractions of unsupported statements, with
citation accuracy ranging from 40--80% across systems.

</details>


### [106] [Context Engineering for Trustworthiness: Rescorla Wagner Steering Under Mixed and Inappropriate Contexts](https://arxiv.org/abs/2509.04500)
*Rushi Wang,Jiateng Liu,Cheng Qian,Yifan Shen,Yanzhou Pan,Zhaozhuo Xu,Ahmed Abbasi,Heng Ji,Denghui Zhang*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在处理混合上下文时，倾向于采纳其中不那么普遍的不当信息，导致响应质量下降。本文提出了RW-Steering，一种两阶段微调方法，使LLMs能够识别并忽略不当信号，显著提升了模型在真实世界场景中的安全性和响应质量。


<details>
  <summary>Details</summary>
Motivation: 将外部上下文整合到LLMs中可以显著提高响应质量，但实际上下文往往混杂了相关信息和大量不当内容，这带来了可靠性风险。研究旨在探究LLMs如何处理和优先排序这种混合上下文。

Method: 引入了“中毒上下文测试平台”（Poisoned Context Testbed），将查询与包含相关和不当内容的真实世界上下文配对。受动物联想学习启发，改编了神经科学中的Rescorla-Wagner (RW) 模型来量化竞争性上下文信号如何影响LLM输出。为解决发现的问题，提出了RW-Steering，这是一种两阶段的基于微调的方法，使模型能够内部识别并忽略不当信号。

Result: 改编模型揭示了LLMs的一种一致行为模式：它们强烈倾向于采纳上下文中不那么普遍的信息。这种易感性在实际设置中是有害的，少量不当内容就能显著降低响应质量。经验评估进一步证实了这种脆弱性。RW-Steering方法与现有方法不同，它能鲁棒地泛化到不同比例的不当内容。实验表明，最佳微调模型将响应质量提高了39.8%，并逆转了不良行为曲线。

Conclusion: RW-Steering被确立为一种鲁棒、可泛化的上下文工程解决方案，用于提高LLMs在真实世界使用中的安全性，通过使模型内部识别并忽略不当信号，解决了LLMs易受上下文中不那么普遍的不当信息影响的问题。

Abstract: Incorporating external context can significantly enhance the response quality
of Large Language Models (LLMs). However, real-world contexts often mix
relevant information with disproportionate inappropriate content, posing
reliability risks. How do LLMs process and prioritize mixed context? To study
this, we introduce the Poisoned Context Testbed, pairing queries with
real-world contexts containing relevant and inappropriate content. Inspired by
associative learning in animals, we adapt the Rescorla-Wagner (RW) model from
neuroscience to quantify how competing contextual signals influence LLM
outputs. Our adapted model reveals a consistent behavioral pattern: LLMs
exhibit a strong tendency to incorporate information that is less prevalent in
the context. This susceptibility is harmful in real-world settings, where small
amounts of inappropriate content can substantially degrade response quality.
Empirical evaluations on our testbed further confirm this vulnerability. To
tackle this, we introduce RW-Steering, a two-stage finetuning-based approach
that enables the model to internally identify and ignore inappropriate signals.
Unlike prior methods that rely on extensive supervision across diverse context
mixtures, RW-Steering generalizes robustly across varying proportions of
inappropriate content. Experiments show that our best fine-tuned model improves
response quality by 39.8% and reverses the undesirable behavior curve,
establishing RW-Steering as a robust, generalizable context engineering
solution for improving LLM safety in real-world use.

</details>


### [107] [Understanding Reinforcement Learning for Model Training, and future directions with GRAPE](https://arxiv.org/abs/2509.04501)
*Rohit Patel*

Main category: cs.CL

TL;DR: 本文从零开始详细阐述了大型语言模型（LLMs）指令微调的关键算法（如SFT、PPO、DPO等），采用简化且专注LLMs的符号，旨在消除歧义并提供清晰直观的理解，并提出了新的研究方向GRAPE。


<details>
  <summary>Details</summary>
Motivation: 现有算法解释常假设读者有先验知识、缺乏关键细节、过于泛化或复杂，导致难以理解。本文旨在消除歧义，提供对概念的清晰直观理解，并减少认知负担。

Method: 本文逐一讨论并逐步发展了SFT、Rejection Sampling、REINFORCE、TRPO、PPO、GRPO和DPO等指令微调算法，采用简化、明确且专注于LLMs的符号。它最大程度地减少了对更广泛强化学习文献的深入探讨，并将概念与LLMs紧密连接。此外，还提供了最新技术的文献综述，并提出了名为GRAPE（Generalized Relative Advantage Policy Evolution）的新研究思路。

Result: 通过简化和明确的符号，本文成功地消除了对LLMs指令微调算法的歧义，提供了清晰直观的概念理解，并减少了认知负担。同时，它回顾了新颖技术，并提出了GRAPE作为新的研究和探索方向。

Conclusion: 本文为LLMs指令微调的关键算法提供了全面、清晰且易于理解的阐述，成功地简化了复杂概念，并为未来的研究和探索（如GRAPE）奠定了基础。

Abstract: This paper provides a self-contained, from-scratch, exposition of key
algorithms for instruction tuning of models: SFT, Rejection Sampling,
REINFORCE, Trust Region Policy Optimization (TRPO), Proximal Policy
Optimization (PPO), Group Relative Policy Optimization (GRPO), and Direct
Preference Optimization (DPO). Explanations of these algorithms often assume
prior knowledge, lack critical details, and/or are overly generalized and
complex. Here, each method is discussed and developed step by step using
simplified and explicit notation focused on LLMs, aiming to eliminate ambiguity
and provide a clear and intuitive understanding of the concepts. By minimizing
detours into the broader RL literature and connecting concepts to LLMs, we
eliminate superfluous abstractions and reduce cognitive overhead. Following
this exposition, we provide a literature review of new techniques and
approaches beyond those detailed. Finally, new ideas for research and
exploration in the form of GRAPE (Generalized Relative Advantage Policy
Evolution) are presented.

</details>


### [108] [VaccineRAG: Boosting Multimodal Large Language Models' Immunity to Harmful RAG Samples](https://arxiv.org/abs/2509.04502)
*Qixin Sun,Ziqin Wang,Hengyuan Zhao,Yilin Li,Kaiyou Song,Linjiang Huang,Xiaolin Hu,Qingpei Guo,Si Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为VaccineRAG的新型Chain-of-Thought（CoT）检索增强生成数据集，旨在通过评估不同正负样本比例的数据和生成显式CoT分析来解决检索器精度问题，并引入Partial-GRPO方法以增强模型学习复杂CoT内容的能力。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）的有效性常受检索器精度的限制，许多检索到的样本与生成阶段无关或具有误导性，成为大型语言模型（LLM）性能的关键瓶颈。

Method: 1. 引入VaccineRAG数据集，一个基于CoT的检索增强生成数据集。2. VaccineRAG使用基准测试，通过不同正负样本比例的数据评估模型，暴露LLM的固有弱点。3. 通过提示LLM为每个样本生成显式CoT分析，增强模型的样本判别能力。4. 提出Partial-GRPO方法，通过将LLM输出建模为多个组件而非单一整体，以增强模型学习长序列复杂CoT内容的能力。

Result: 在VaccineRAG上的综合评估和消融研究验证了所提出方案的有效性。

Conclusion: 所提出的VaccineRAG数据集和Partial-GRPO方法能有效提升RAG的性能，通过增强样本判别和复杂CoT学习，解决了检索器精度不足的瓶颈问题。

Abstract: Retrieval Augmented Generation enhances the response accuracy of Large
Language Models (LLMs) by integrating retrieval and generation modules with
external knowledge, demonstrating particular strength in real-time queries and
Visual Question Answering tasks. However, the effectiveness of RAG is
frequently hindered by the precision of the retriever: many retrieved samples
fed into the generation phase are irrelevant or misleading, posing a critical
bottleneck to LLMs' performance. To address this challenge, we introduce
VaccineRAG, a novel Chain-of-Thought-based retrieval-augmented generation
dataset. On one hand, VaccineRAG employs a benchmark to evaluate models using
data with varying positive/negative sample ratios, systematically exposing
inherent weaknesses in current LLMs. On the other hand, it enhances models'
sample-discrimination capabilities by prompting LLMs to generate explicit
Chain-of-Thought (CoT) analysis for each sample before producing final answers.
Furthermore, to enhance the model's ability to learn long-sequence complex CoT
content, we propose Partial-GRPO. By modeling the outputs of LLMs as multiple
components rather than a single whole, our model can make more informed
preference selections for complex sequences, thereby enhancing its capacity to
learn complex CoT. Comprehensive evaluations and ablation studies on VaccineRAG
validate the effectiveness of the proposed scheme. The code and dataset will be
publicly released soon.

</details>


### [109] [Behavioral Fingerprinting of Large Language Models](https://arxiv.org/abs/2509.04504)
*Zehua Pei,Hui-Ling Zhen,Ying Zhang,Zhiyuan Yang,Xing Li,Xianzhi Yu,Mingxuan Yuan,Bei Yu*

Main category: cs.CL

TL;DR: 本文提出了一种“行为指纹”框架，用于超越传统性能指标，评估大型语言模型（LLMs）的内在认知和交互风格。研究发现，尽管顶级模型的核心能力趋于一致，但与对齐相关的行为差异显著，且模型的交互性质是开发者对齐策略的直接结果。


<details>
  <summary>Details</summary>
Motivation: 当前LLM基准测试主要关注性能指标，未能捕捉到区分模型细微行为特征的能力。

Method: 引入了“行为指纹”框架，通过一套精心策划的“诊断提示套件”和一个创新的自动化评估流程（由强大的LLM充当公正的评判者），分析了18个不同能力层级的模型。

Result: 研究揭示，LLM领域存在关键差异：顶级模型的核心能力（如抽象和因果推理）趋于收敛，但与对齐相关的行为（如谄媚和语义鲁棒性）差异巨大。此外，还发现跨模型存在默认人格聚类（ISTJ/ESTJ），这可能反映了常见的对齐激励。

Conclusion: 模型的交互性质并非其规模或推理能力的涌现属性，而是特定且高度可变的开发者对齐策略的直接结果。该框架提供了一种可复现和可扩展的方法来揭示这些深层的行为差异。

Abstract: Current benchmarks for Large Language Models (LLMs) primarily focus on
performance metrics, often failing to capture the nuanced behavioral
characteristics that differentiate them. This paper introduces a novel
``Behavioral Fingerprinting'' framework designed to move beyond traditional
evaluation by creating a multi-faceted profile of a model's intrinsic cognitive
and interactive styles. Using a curated \textit{Diagnostic Prompt Suite} and an
innovative, automated evaluation pipeline where a powerful LLM acts as an
impartial judge, we analyze eighteen models across capability tiers. Our
results reveal a critical divergence in the LLM landscape: while core
capabilities like abstract and causal reasoning are converging among top
models, alignment-related behaviors such as sycophancy and semantic robustness
vary dramatically. We further document a cross-model default persona clustering
(ISTJ/ESTJ) that likely reflects common alignment incentives. Taken together,
this suggests that a model's interactive nature is not an emergent property of
its scale or reasoning power, but a direct consequence of specific, and highly
variable, developer alignment strategies. Our framework provides a reproducible
and scalable methodology for uncovering these deep behavioral differences.
Project: https://github.com/JarvisPei/Behavioral-Fingerprinting

</details>


### [110] [From Silent Signals to Natural Language: A Dual-Stage Transformer-LLM Approach](https://arxiv.org/abs/2509.04507)
*Nithyashree Sivasubramaniam*

Main category: cs.CL

TL;DR: 本文提出了一种结合Transformer声学模型和LLM后处理的增强型ASR框架，显著提高了静默语音接口合成语音的识别准确性，降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 静默语音接口生成的合成语音通常存在语音歧义和噪声问题，而目前对其识别和下游处理的研究有限。

Method: 本文提出了一种增强的自动语音识别（ASR）框架。该框架结合了基于Transformer的声学模型（用于捕获完整话语上下文）和大型语言模型（LLM）进行后处理（用于确保语言一致性）。

Result: 实验结果显示，相对于36%的基线，词错误率（WER）相对降低了16%，绝对降低了6%。

Conclusion: 该框架显著提高了静默语音接口生成语音的可懂度，为解决其语音识别挑战提供了有效方案。

Abstract: Silent Speech Interfaces (SSIs) have gained attention for their ability to
generate intelligible speech from non-acoustic signals. While significant
progress has been made in advancing speech generation pipelines, limited work
has addressed the recognition and downstream processing of synthesized speech,
which often suffers from phonetic ambiguity and noise. To overcome these
challenges, we propose an enhanced automatic speech recognition framework that
combines a transformer-based acoustic model with a large language model (LLM)
for post-processing. The transformer captures full utterance context, while the
LLM ensures linguistic consistency. Experimental results show a 16% relative
and 6% absolute reduction in word error rate (WER) over a 36% baseline,
demonstrating substantial improvements in intelligibility for silent speech
interfaces.

</details>


### [111] [ProST: Progressive Sub-task Training for Pareto-Optimal Multi-agent Systems Using Small Language Models](https://arxiv.org/abs/2509.04508)
*Biddut Sarker Bijoy,Mohammad Saqib Hasan,Pegah Alipoormolabashi,Avirup Sil,Aruna Balasubramanian,Niranjan Balasubramanian*

Main category: cs.CL

TL;DR: 本研究探讨了多智能体小型语言模型（SLM）系统作为大型语言模型（LLM）单智能体系统的替代方案，并提出了一种渐进式子任务训练策略，显著提高了多智能体SLM系统的有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 研究多智能体SLM系统与单智能体LLM系统在解决复杂问题时的有效性和效率权衡，并解决SLM在长轨迹学习和子任务学习中的局限性。

Method: 在AppWorld环境中实例化单智能体和多智能体系统，使用不同大小的语言模型。引入了一种渐进式子任务训练策略，在每个训练周期逐步引入新的子任务。通过帕累托分析、消融实验和其他分析来评估系统性能。

Result: SLM在长轨迹学习中表现不佳，即使进行专业化训练也未能有效学习所有子任务。提出的渐进式子任务训练策略显著提高了多智能体在所有配置下的有效性。精细调整的多智能体系统在有效性-效率权衡方面表现更优。该训练策略能有效降低子任务错误率。

Conclusion: 多智能体SLM系统，特别是结合渐进式子任务训练策略后，能够为复杂问题提供比单智能体LLM系统更好的有效性-效率权衡，有效克服SLM在长轨迹学习中的局限性。

Abstract: Multi-agent systems with smaller language models (SLMs) present a viable
alternative to single agent systems powered by large language models (LLMs) for
addressing complex problems. In this work, we study how these alternatives
compare in terms of both effectiveness and efficiency. To study this trade-off,
we instantiate single and multi-agent systems for the complex problems in the
AppWorld environment using different sized language models.
  We find that difficulties with long-trajectory learning in smaller language
models (SLMs) limit their performance. Even when trained for specialized roles,
SLMs fail to learn all subtasks effectively. To address this issue, we
introduce a simple progressive sub-task training strategy, which introduces new
sub-tasks progressively in each training epoch. We find that this novel
strategy, analogous to instance level curriculum learning, consistently
improves the effectiveness of multi-agents at all configurations. Our Pareto
analysis shows that fine-tuned multi-agent systems yield better
effectiveness-efficiency trade-offs. Additional ablations and analyses shows
the importance of our progressive training strategy and its ability to reduce
subtask error rates.

</details>


### [112] [Mitigation of Gender and Ethnicity Bias in AI-Generated Stories through Model Explanations](https://arxiv.org/abs/2509.04515)
*Martha O. Dimgba,Sharon Oba,Ameeta Agrawal,Philippe J. Giabbanelli*

Main category: cs.CL

TL;DR: 本研究调查并缓解了AI生成职业故事中的性别和种族偏见，通过提出的BAME策略，利用模型解释进行提示工程，显著改善了人口统计学代表性。


<details>
  <summary>Details</summary>
Motivation: 语言模型已被证明会通过其输出传播社会偏见，尤其是在性别和种族表示方面。本研究旨在解决AI生成职业故事中存在的性别和种族偏见问题。

Method: 研究提出了一种名为“通过解释进行偏见分析和缓解”（BAME）的缓解策略。BAME利用模型生成的解释来指导有针对性的提示工程，从而在不修改模型参数的情况下减少偏见。偏见通过在应用BAME前后测量表示偏差来评估。研究分析了25个职业群体、三种大型语言模型（Claude 3.5 Sonnet, Llama 3.1 70B Instruct, 和 GPT-4 Turbo）以及多个人口统计学维度生成的职业故事。

Result: 应用BAME后，人口统计学代表性得到了2%到20%的改善。研究还发现，与训练数据中的刻板印象相关的过度代表和代表不足的持续模式。结果表明，通过模型自身的内部推理机制来指导模型可以显著增强人口统计学上的平等。

Conclusion: 本研究得出结论，利用模型自身的内部推理机制可以显著提高人口统计学上的平等，从而有助于开发更透明的生成式AI系统。

Abstract: Language models have been shown to propagate social bias through their
output, particularly in the representation of gender and ethnicity. This paper
investigates gender and ethnicity biases in AI-generated occupational stories.
Representation biases are measured before and after applying our proposed
mitigation strategy, Bias Analysis and Mitigation through Explanation (BAME),
revealing improvements in demographic representation ranging from 2% to 20%.
BAME leverages model-generated explanations to inform targeted prompt
engineering, effectively reducing biases without modifying model parameters. By
analyzing stories generated across 25 occupational groups, three large language
models (Claude 3.5 Sonnet, Llama 3.1 70B Instruct, and GPT-4 Turbo), and
multiple demographic dimensions, we identify persistent patterns of
overrepresentation and underrepresentation linked to training data stereotypes.
Our findings demonstrate that guiding models with their own internal reasoning
mechanisms can significantly enhance demographic parity, thereby contributing
to the development of more transparent generative AI systems.

</details>


### [113] [Combine Virtual Reality and Machine-Learning to Identify the Presence of Dyslexia: A Cross-Linguistic Approach](https://arxiv.org/abs/2509.04510)
*Michele Materazzini,Gianluca Morciano,Jose Manuel Alcalde-Llergo,Enrique Yeguas-Bolivar,Giuseppe Calabro,Andrea Zingoni,Juri Taborri*

Main category: cs.CL

TL;DR: 本研究利用虚拟现实（VR）和机器学习（ML）技术，通过无声阅读测试数据，预测意大利和西班牙大学生中是否存在阅读障碍，并取得了可观的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索VR和AI（特别是ML算法）是否能有效预测意大利和西班牙大学生中的阅读障碍，特别是通过VR衍生的无声阅读测试数据和自尊评估来区分患有和未患阅读障碍的学生。

Method: 参与者完成了基于VR的阅读表现和自尊评估任务。首先进行了初步统计分析（t检验和Mann Whitney检验），比较阅读障碍组和非阅读障碍组的得分。随后，训练并测试了监督式机器学习模型，以分类阅读障碍的存在与否。

Result: 统计分析显示，阅读障碍组在无声阅读测试的完成时间上存在显著差异，但在准确率和自尊方面无显著差异。机器学习模型在分类阅读障碍方面表现出：意大利组准确率为87.5%，西班牙组为66.6%，合并组为75.0%。结果表明语言特异性因素可能影响分类准确率。

Conclusion: 研究结果表明，VR和ML可以作为评估阅读障碍的有效辅助工具，尤其在捕捉任务完成速度差异方面。然而，语言特异性因素可能会影响分类的准确性。

Abstract: This study explores the use of virtual reality (VR) and artificial
intelligence (AI) to predict the presence of dyslexia in Italian and Spanish
university students. In particular, the research investigates whether
VR-derived data from Silent Reading (SR) tests and self-esteem assessments can
differentiate between students that are affected by dyslexia and students that
are not, employing machine learning (ML) algorithms. Participants completed
VR-based tasks measuring reading performance and self-esteem. A preliminary
statistical analysis (t tests and Mann Whitney tests) on these data was
performed, to compare the obtained scores between individuals with and without
dyslexia, revealing significant differences in completion time for the SR test,
but not in accuracy, nor in self esteem. Then, supervised ML models were
trained and tested, demonstrating an ability to classify the presence/absence
of dyslexia with an accuracy of 87.5 per cent for Italian, 66.6 per cent for
Spanish, and 75.0 per cent for the pooled group. These findings suggest that VR
and ML can effectively be used as supporting tools for assessing dyslexia,
particularly by capturing differences in task completion speed, but
language-specific factors may influence classification accuracy.

</details>


### [114] [Quantized Large Language Models in Biomedical Natural Language Processing: Evaluation and Recommendation](https://arxiv.org/abs/2509.04534)
*Zaifu Zhan,Shuang Zhou,Min Zeng,Kai Yu,Meijia Song,Xiaoyi Chen,Jun Wang,Yu Hou,Rui Zhang*

Main category: cs.CL

TL;DR: 本研究表明，量化能显著降低大型语言模型（LLMs）的GPU内存需求（高达75%），同时保持性能，从而实现在资源受限的生物医学环境中安全、本地部署LLMs。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生物医学自然语言处理中表现出色，但其巨大的模型尺寸和计算需求阻碍了在医疗保健领域的应用，因为数据隐私要求本地部署且资源有限。

Method: 研究系统地评估了量化对12个最先进的大型语言模型（包括通用和生物医学专用模型）的影响，并在涵盖命名实体识别、关系提取、多标签分类和问答四项关键任务的八个基准数据集上进行了测试。

Result: 量化将GPU内存需求减少了高达75%，同时在各种任务中保持了模型性能，使得70B参数的模型可以在40GB消费级GPU上部署。此外，模型的领域特定知识和对高级提示方法的响应能力也得到了很大程度的保留。

Conclusion: 量化是一种实用且有效的策略，能够实现大型且高性能语言模型在生物医学环境中的安全、本地部署，弥合了AI技术进步与实际临床转化之间的鸿沟。

Abstract: Large language models have demonstrated remarkable capabilities in biomedical
natural language processing, yet their rapid growth in size and computational
requirements present a major barrier to adoption in healthcare settings where
data privacy precludes cloud deployment and resources are limited. In this
study, we systematically evaluated the impact of quantization on 12
state-of-the-art large language models, including both general-purpose and
biomedical-specific models, across eight benchmark datasets covering four key
tasks: named entity recognition, relation extraction, multi-label
classification, and question answering. We show that quantization substantially
reduces GPU memory requirements-by up to 75%-while preserving model performance
across diverse tasks, enabling the deployment of 70B-parameter models on 40GB
consumer-grade GPUs. In addition, domain-specific knowledge and responsiveness
to advanced prompting methods are largely maintained. These findings provide
significant practical and guiding value, highlighting quantization as a
practical and effective strategy for enabling the secure, local deployment of
large yet high-capacity language models in biomedical contexts, bridging the
gap between technical advances in AI and real-world clinical translation.

</details>


### [115] [Scaling behavior of large language models in emotional safety classification across sizes and tasks](https://arxiv.org/abs/2509.04512)
*Edoardo Pinzuti,Oliver Tüscher,André Ferreira Castro*

Main category: cs.CL

TL;DR: 该研究调查了大型语言模型（LLMs）处理情感敏感内容的扩展行为，发现虽然更大模型性能更强，但经过轻量级微调的小型模型也能在隐私敏感应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 理解LLMs如何处理情感敏感内容对于构建安全可靠的系统至关重要，尤其是在心理健康领域。

Method: 研究采用两种分类任务：情感安全三元分类（安全、不安全、临界）和六类别安全风险多标签分类。构建了一个包含超过1.5万样本的新型数据集，该数据集结合了人工编写的心理健康数据并使用ChatGPT生成的提示进行情感重新解释增强。评估了四种LLaMA模型（1B、3B、8B、70B），并在零样本、少样本和微调设置下进行测试。

Result: 结果显示，更大的LLMs通常表现出更强的平均性能，尤其是在细致的多标签分类和零样本设置中。然而，通过轻量级微调，1B模型在几个高数据类别中达到了与更大模型和BERT相当的性能，且推理时仅需不到2GB的显存。

Conclusion: 这些发现表明，小型、可在设备上运行的模型可以作为敏感应用的有效、隐私保护替代方案，能够解释情感上下文并维持安全的对话边界。这对于治疗性LLM应用和安全关键系统的可扩展对齐具有重要意义。

Abstract: Understanding how large language models (LLMs) process emotionally sensitive
content is critical for building safe and reliable systems, particularly in
mental health contexts. We investigate the scaling behavior of LLMs on two key
tasks: trinary classification of emotional safety (safe vs. unsafe vs.
borderline) and multi-label classification using a six-category safety risk
taxonomy. To support this, we construct a novel dataset by merging several
human-authored mental health datasets (> 15K samples) and augmenting them with
emotion re-interpretation prompts generated via ChatGPT. We evaluate four LLaMA
models (1B, 3B, 8B, 70B) across zero-shot, few-shot, and fine-tuning settings.
Our results show that larger LLMs achieve stronger average performance,
particularly in nuanced multi-label classification and in zero-shot settings.
However, lightweight fine-tuning allowed the 1B model to achieve performance
comparable to larger models and BERT in several high-data categories, while
requiring <2GB VRAM at inference. These findings suggest that smaller,
on-device models can serve as viable, privacy-preserving alternatives for
sensitive applications, offering the ability to interpret emotional context and
maintain safe conversational boundaries. This work highlights key implications
for therapeutic LLM applications and the scalable alignment of safety-critical
systems.

</details>


### [116] [Manipulating Transformer-Based Models: Controllability, Steerability, and Robust Interventions](https://arxiv.org/abs/2509.04549)
*Faruk Alpay,Taylan Alpay*

Main category: cs.CL

TL;DR: 本文探索了通过提示、激活和权重干预，在三个层面实现Transformer模型精细控制的方法，并提出了一个统一框架，在保持基础性能的同时实现了高成功率的文本生成控制。


<details>
  <summary>Details</summary>
Motivation: 尽管基于Transformer的语言模型在NLP任务中表现出色，但对其进行精细控制仍然是一个挑战。

Method: 本文将可控文本生成形式化为一个优化问题，可通过提示工程、参数高效微调、模型编辑和强化学习来解决。研究引入了一个统一框架，涵盖提示级引导、激活干预和权重空间编辑。理论上，作者展示了最小的权重更新即可实现有针对性的行为改变，且副作用有限。

Result: 经验证，在情感控制和事实编辑方面取得了超过90%的成功率，同时保留了基础性能。研究还分析了鲁棒性和安全隐患，包括对抗性攻击和对齐缓解措施，但存在泛化-特异性权衡。

Conclusion: 这项工作为设计可控且鲁棒的语言模型奠定了基础，并讨论了伦理双重用途风险以及严格评估的必要性。

Abstract: Transformer-based language models excel in NLP tasks, but fine-grained
control remains challenging. This paper explores methods for manipulating
transformer models through principled interventions at three levels: prompts,
activations, and weights. We formalize controllable text generation as an
optimization problem addressable via prompt engineering, parameter-efficient
fine-tuning, model editing, and reinforcement learning. We introduce a unified
framework encompassing prompt-level steering, activation interventions, and
weight-space edits. We analyze robustness and safety implications, including
adversarial attacks and alignment mitigations. Theoretically, we show minimal
weight updates can achieve targeted behavior changes with limited side-effects.
Empirically, we demonstrate >90% success in sentiment control and factual edits
while preserving base performance, though generalization-specificity trade-offs
exist. We discuss ethical dual-use risks and the need for rigorous evaluation.
This work lays groundwork for designing controllable and robust language
models.

</details>


### [117] [Artificially Fluent: Swahili AI Performance Benchmarks Between English-Trained and Natively-Trained Datasets](https://arxiv.org/abs/2509.04516)
*Sophie Jaffer,Simeon Sayer*

Main category: cs.CL

TL;DR: 本研究发现，对于斯瓦希里语，原生语言训练的模型表现明显优于通过翻译处理的英文训练模型，表明语言一致性对模型性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）多语言能力的扩展，其在不同语言间的性能公平性受到质疑。英文训练数据的主导地位可能使非英文使用者处于不利地位，因此需要检验数据差异是否影响模型性能。

Method: 研究比较了两个单语BERT模型：一个完全用斯瓦希里语数据训练和测试，另一个用可比的英语新闻数据训练。为了模拟多语言LLM处理非英语查询的方式，研究将斯瓦希里语新闻数据翻译成英语，并用英语训练的模型进行评估。然后将此性能与完全用斯瓦希里语训练和测试的模型进行比较，以隔离语言一致性与跨语言抽象的影响。

Result: 原生斯瓦希里语训练的模型表现优于翻译成英语后用英语模型评估的模型，错误率分别为0.36%和1.47%，前者错误率是后者的近四分之一。这表明即使有高质量翻译，翻译也无法弥合语言间的表征差异，并且用一种语言训练的模型可能难以准确解释翻译后的输入。

Conclusion: 原生语言训练对于获得可靠结果仍然重要。即使是小的性能差距也可能加剧教育和信息领域的不平等。未来的研究应关注欠代表语言的数据集开发和多语言模型评估，以减少全球AI部署对现有数字鸿沟的强化效应。

Abstract: As large language models (LLMs) expand multilingual capabilities, questions
remain about the equity of their performance across languages. While many
communities stand to benefit from AI systems, the dominance of English in
training data risks disadvantaging non-English speakers. To test the hypothesis
that such data disparities may affect model performance, this study compares
two monolingual BERT models: one trained and tested entirely on Swahili data,
and another on comparable English news data. To simulate how multilingual LLMs
process non-English queries through internal translation and abstraction, we
translated the Swahili news data into English and evaluated it using the
English-trained model. This approach tests the hypothesis by evaluating whether
translating Swahili inputs for evaluation on an English model yields better or
worse performance compared to training and testing a model entirely in Swahili,
thus isolating the effect of language consistency versus cross-lingual
abstraction. The results prove that, despite high-quality translation, the
native Swahili-trained model performed better than the Swahili-to-English
translated model, producing nearly four times fewer errors: 0.36% vs. 1.47%
respectively. This gap suggests that translation alone does not bridge
representational differences between languages and that models trained in one
language may struggle to accurately interpret translated inputs due to
imperfect internal knowledge representation, suggesting that native-language
training remains important for reliable outcomes. In educational and
informational contexts, even small performance gaps may compound inequality.
Future research should focus on addressing broader dataset development for
underrepresented languages and renewed attention to multilingual model
evaluation, ensuring the reinforcing effect of global AI deployment on existing
digital divides is reduced.

</details>


### [118] [Sample-efficient Integration of New Modalities into Large Language Models](https://arxiv.org/abs/2509.04606)
*Osman Batur İnce,André F. T. Martins,Oisin Mac Aodha,Edoardo M. Ponti*

Main category: cs.CL

TL;DR: 本文提出了一种名为SEMI（样本高效模态集成）的方法，通过超网络实现样本高效地将新模态集成到大型语言模型（LLMs）中，尤其适用于低资源模态。


<details>
  <summary>Details</summary>
Motivation: 多模态基础模型难以涵盖所有不断演进的模态，从头训练不切实际。将新模态集成到现有模型中通常需要大量配对数据，而低资源模态往往缺乏此类数据。

Method: 该方法设计了一个超网络，用于调整一个共享的投影器（位于模态特定编码器和LLM之间）。超网络在推理时通过任意模态的少量样本进行条件化，以生成合适的适配器，并在高资源模态（文本、语音、音频、视频）上进行训练。通过等距变换人工增加编码器数量，以提高训练模态的多样性。

Result: SEMI在少量样本集成新模态（如卫星图像、天文图像、惯性测量和分子）时，显著提高了样本效率，并能处理任意嵌入维度的编码器。例如，达到与32样本SEMI相同的精度，从头训练投影器需要多64倍的数据。

Conclusion: SEMI有望扩展基础模型的模态覆盖范围，为低资源模态的集成提供了有效途径。

Abstract: Multimodal foundation models can process several modalities. However, since
the space of possible modalities is large and evolving over time, training a
model from scratch to encompass all modalities is unfeasible. Moreover,
integrating a modality into a pre-existing foundation model currently requires
a significant amount of paired data, which is often not available for
low-resource modalities. In this paper, we introduce a method for
sample-efficient modality integration (SEMI) into Large Language Models (LLMs).
To this end, we devise a hypernetwork that can adapt a shared projector --
placed between modality-specific encoders and an LLM -- to any modality. The
hypernetwork, trained on high-resource modalities (i.e., text, speech, audio,
video), is conditioned on a few samples from any arbitrary modality at
inference time to generate a suitable adapter. To increase the diversity of
training modalities, we artificially multiply the number of encoders through
isometric transformations. We find that SEMI achieves a significant boost in
sample efficiency during few-shot integration of new modalities (i.e.,
satellite images, astronomical images, inertial measurements, and molecules)
with encoders of arbitrary embedding dimensionality. For instance, to reach the
same accuracy as 32-shot SEMI, training the projector from scratch needs
64$\times$ more data. As a result, SEMI holds promise to extend the modality
coverage of foundation models.

</details>


### [119] [Analysis of Voluntarily Reported Data Post Mesh Implantation for Detecting Public Emotion and Identifying Concern Reports](https://arxiv.org/abs/2509.04517)
*Indu Bala,Lewis Mitchell,Marianne H Gillam*

Main category: cs.CL

TL;DR: 本研究利用NLP分析MAUDE数据库中2000-2021年间患者对网片植入术后情感报告，发现特定时期（2011-2012和2017-2018）“关注报告”和情感强度增加，为改善术前咨询和术后护理提供见解。


<details>
  <summary>Details</summary>
Motivation: 疝气修复手术中网片植入术后并发症是一个重要问题。研究旨在通过分析患者报告，了解患者植入网片后的情感体验，并探究这些体验如何随医疗设备监管和技术进步而变化，以期改善患者护理。

Method: 研究使用自然语言处理（NLP）技术，分析了2000年至2021年美国制造商和用户设施设备经验（MAUDE）数据库中的患者报告。采用加拿大国家研究委员会（NRC）情感词典将患者叙述分为八种情绪（愤怒、恐惧、预期、信任、惊喜、悲伤、喜悦和厌恶），并利用TextBlob进行情感极性分析。研究还识别了表示紧急关注的“关注报告”，并进行了时间序列分析。

Result: 研究发现，“关注报告”和情感强度在2011-2012年和2017-2018年期间有所增加。通过对“关注报告”和整体情感的时间分析，揭示了患者术后体验的模式和变化。

Conclusion: 本研究为医护人员提供了宝贵的见解，加深了他们对患者术后体验的理解，这对改善术前咨询、术后护理和患者术前准备至关重要。研究强调了在医疗实践中考虑情感因素的重要性，以及情感分析在指导和增强患者护理方面的潜力。

Abstract: Mesh implants are widely utilized in hernia repair surgeries, but
postoperative complications present a significant concern. This study analyzes
patient reports from the Manufacturer and User Facility Device Experience
(MAUDE) database spanning 2000 to 2021 to investigate the emotional aspects of
patients following mesh implantation using Natural Language Processing (NLP).
Employing the National Research Council Canada (NRC) Emotion Lexicon and
TextBlob for sentiment analysis, the research categorizes patient narratives
into eight emotions (anger, fear, anticipation, trust, surprise, sadness, joy,
and disgust) and assesses sentiment polarity. The goal is to discern patterns
in patient sentiment over time and to identify reports signaling urgent
concerns, referred to as "Concern Reports," thereby understanding shifts in
patient experiences in relation to changes in medical device regulation and
technological advancements in healthcare. The study detected an increase in
Concern Reports and higher emotional intensity during the periods of 2011-2012
and 2017-2018. Through temporal analysis of Concern Reports and overall
sentiment, this research provides valuable insights for healthcare
practitioners, enhancing their understanding of patient experiences
post-surgery, which is critical for improving preoperative counselling,
postoperative care, and preparing patients for mesh implant surgeries. The
study underscores the importance of emotional considerations in medical
practices and the potential for sentiment analysis to inform and enhance
patient care.

</details>


### [120] [Comparative Analysis of Transformer Models in Disaster Tweet Classification for Public Safety](https://arxiv.org/abs/2509.04650)
*Sharif Noor Zisad,Ragib Hasan*

Main category: cs.CL

TL;DR: 本研究评估了Transformer模型在灾害相关推文分类中的有效性，发现它们显著优于传统机器学习模型，其中BERT表现最佳。


<details>
  <summary>Details</summary>
Motivation: Twitter等社交媒体在灾害期间提供实时信息至关重要，自动分类灾害推文有助于应急响应。然而，传统机器学习模型难以理解推文中非正式、隐喻或模糊的语言上下文。

Method: 研究评估了包括BERT、DistilBERT、RoBERTa和DeBERTa在内的Transformer模型，用于分类灾害相关推文。这些模型与传统的机器学习方法（如逻辑回归、朴素贝叶斯和支持向量机）进行了比较。

Result: 实验结果显示，BERT取得了最高的准确率（91%），显著优于传统模型如逻辑回归和朴素贝叶斯（均为82%）。Transformer模型通过上下文嵌入和注意力机制，能更好地理解推文中细微的语言。

Conclusion: Transformer架构更适用于公共安全应用，它们提供了更高的准确性、更深层次的语言理解以及在真实世界社交媒体文本中更好的泛化能力。

Abstract: Twitter and other social media platforms have become vital sources of real
time information during disasters and public safety emergencies. Automatically
classifying disaster related tweets can help emergency services respond faster
and more effectively. Traditional Machine Learning (ML) models such as Logistic
Regression, Naive Bayes, and Support Vector Machines have been widely used for
this task, but they often fail to understand the context or deeper meaning of
words, especially when the language is informal, metaphorical, or ambiguous. We
posit that, in this context, transformer based models can perform better than
traditional ML models. In this paper, we evaluate the effectiveness of
transformer based models, including BERT, DistilBERT, RoBERTa, and DeBERTa, for
classifying disaster related tweets. These models are compared with traditional
ML approaches to highlight the performance gap. Experimental results show that
BERT achieved the highest accuracy (91%), significantly outperforming
traditional models like Logistic Regression and Naive Bayes (both at 82%). The
use of contextual embeddings and attention mechanisms allows transformer models
to better understand subtle language in tweets, where traditional ML models
fall short. This research demonstrates that transformer architectures are far
more suitable for public safety applications, offering improved accuracy,
deeper language understanding, and better generalization across real world
social media text.

</details>


### [121] [Advancing SLM Tool-Use Capability using Reinforcement Learning](https://arxiv.org/abs/2509.04518)
*Dhruvi Paprunia,Vansh Kharidia,Pankti Doshi*

Main category: cs.CL

TL;DR: 本研究利用强化学习（特别是GRPO）来提升小型语言模型（SLMs）的工具使用能力，以解决其在工具使用方面相较于大型语言模型（LLMs）的不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在工具使用方面表现出色，但其巨大的资源需求和计算复杂性限制了其广泛应用。小型语言模型（SLMs）虽然更紧凑高效，但在工具使用方面表现不佳，知识库和上下文理解能力有限。因此，需要一种方法来增强SLMs的工具使用能力。

Method: 本研究采用强化学习（RL），具体是群组相对策略优化（Group Relative Policy Optimization, GRPO）方法，来提升SLMs的工具使用熟练度。与传统的微调方法不同，该方法旨在提供一个高效且适应性强的解决方案。

Result: 研究结果表明，该方法显著提高了SLMs的工具使用准确性，从而增加了它们的实际应用价值。

Conclusion: 本研究提供了一种高效、有效的解决方案，通过强化学习（GRPO）显著提升了小型语言模型（SLMs）的工具使用能力，增强了它们的实用性。

Abstract: Large Language Models (LLMs) have progressed beyond simple text creation, and
tool use has become increasingly important for complex, real-world tasks. Tool
use in LLMs refers to their ability to utilize external resources such as APIs,
databases, or software functions to extend their functionality beyond
generating text.Tools are used for tasks such as performing calculations,
making API calls to retrieve the current time and date, and more. This
capability enables models to fetch real-time data, execute commands, or solve
problems requiring dynamic interaction, making it indispensable for
applications like AI agents in virtual assistants, robotic control, or
automated workflows.
  However, while LLMs are usually adept tool use, their vast resource
requirements and computation complexity restrict their use in every use case.As
a result, there is an increasing need for more compact and efficient Small
Language Models (SLMs). Small language models (SLMs) struggle in tool use
compared to large language models (LLMs). As soon in Table 1. SLMs are
typically trained on smaller, more specific datasets, resulting in a narrower
knowledge base and limited contextual understanding compared to LLMs.
  This research addresses these challenges by using Reinforcement Learning
(RL), specifically Group Relative Policy Optimization (GRPO), to enhance
tool-use proficiency in SLMs. Unlike conventional fine-tuning approaches that
require heavy computation and often lack adaptability, our method provides an
efficient, effective solution that significantly boosts SLM tool-use accuracy,
increasing their practical utility.

</details>


### [122] [Polysemantic Dropout: Conformal OOD Detection for Specialized LLMs](https://arxiv.org/abs/2509.04655)
*Ayush Gupta,Ramneet Kaur,Anirban Roy,Adam D. Cobb,Rama Chellappa,Susmit Jha*

Main category: cs.CL

TL;DR: 本文提出了一种针对专业化大型语言模型（LLMs）的新型推理时域外（OOD）检测算法，该算法利用模型对Dropout的容忍度，结合归纳共形异常检测（ICAD）框架来识别OOD输入。


<details>
  <summary>Details</summary>
Motivation: 尽管专业化LLMs在域内任务上表现出色，但当遇到域外（OOD）输入时，它们仍然容易产生不正确或不可靠的输出，这在关键应用中带来了风险。因此，需要有效的方法来检测OOD输入以提高模型可靠性。

Method: 该方法基于归纳共形异常检测（ICAD）框架，并引入了一种新的非一致性度量，该度量基于模型对Dropout的容忍度。研究假设域内输入比OOD输入表现出更高的Dropout容忍度。通过有效的集成方法，在多个层聚合Dropout容忍度，以提高检测效果，同时保持ICAD的理论误报边界。

Result: 在医学专业化LLMs上的实验表明，该方法在检测OOD输入方面优于基线方法，当将OOD数据点视为正例、域内测试数据点视为负例时，AUROC（曲线下面积）提高了2%到37%。

Conclusion: 所提出的基于Dropout容忍度和ICAD的OOD检测算法能有效识别专业化LLMs的域外输入，显著提升了模型在关键应用中的可靠性和安全性。

Abstract: We propose a novel inference-time out-of-domain (OOD) detection algorithm for
specialized large language models (LLMs). Despite achieving state-of-the-art
performance on in-domain tasks through fine-tuning, specialized LLMs remain
vulnerable to incorrect or unreliable outputs when presented with OOD inputs,
posing risks in critical applications. Our method leverages the Inductive
Conformal Anomaly Detection (ICAD) framework, using a new non-conformity
measure based on the model's dropout tolerance. Motivated by recent findings on
polysemanticity and redundancy in LLMs, we hypothesize that in-domain inputs
exhibit higher dropout tolerance than OOD inputs. We aggregate dropout
tolerance across multiple layers via a valid ensemble approach, improving
detection while maintaining theoretical false alarm bounds from ICAD.
Experiments with medical-specialized LLMs show that our approach detects OOD
inputs better than baseline methods, with AUROC improvements of $2\%$ to $37\%$
when treating OOD datapoints as positives and in-domain test datapoints as
negatives.

</details>


### [123] [Hierarchical Section Matching Prediction (HSMP) BERT for Fine-Grained Extraction of Structured Data from Hebrew Free-Text Radiology Reports in Crohn's Disease](https://arxiv.org/abs/2509.04519)
*Zvi Badash,Hadas Ben-Atya,Naama Gavrielov,Liam Hazan,Gili Focht,Ruth Cytter-Kuint,Talar Hagopian,Dan Turner,Moti Freiman*

Main category: cs.CL

TL;DR: 本文开发了HSMP-BERT模型，一种基于提示的BERT模型，用于从希伯来语放射学报告中提取克罗恩病（Crohn's disease）的结构化临床信息。该模型在低资源语言环境下表现出色，显著优于基线模型，并能实现人群层面的疾病分析。


<details>
  <summary>Details</summary>
Motivation: 从放射学报告中提取结构化临床信息具有挑战性，尤其是在资源匮乏的语言（如希伯来语）中。对于克罗恩病这种涉及多器官且发现稀疏的疾病，这一挑战更为突出。因此，研究的动机是开发一种有效的解决方案来解决这一问题。

Method: 研究开发了HSMP-BERT（Hierarchical Structured Matching Prediction BERT），一个基于提示（prompt-based）的模型，用于从希伯来语放射学文本中提取信息。研究分析了9,683份克罗恩病患者的放射学报告，并对其中512份报告进行了放射科医生标注，涵盖六个胃肠器官和15种病理，生成了90个结构化标签。数据采用多标签分层划分（66%训练+验证；33%测试），并使用准确率、F1分数、Cohen's $\kappa$、AUC、PPV、NPV和召回率进行性能评估。模型与SMP零样本基线和标准微调方法进行了比较，并引入了分层推理以提高运行效率。

Result: 在24个阳性样本超过15个的器官-发现组合上，HSMP-BERT实现了平均F1分数0.83±0.08和$\kappa$值0.65±0.17。这显著优于SMP零样本基线（F1 0.49±0.07，$\kappa$ 0.06±0.07）和标准微调（F1 0.30±0.27，$\kappa$ 0.27±0.34），配对t检验p值小于10^-7。此外，分层推理将运行时长缩短了5.1倍。将模型应用于所有报告后，揭示了回肠壁增厚、狭窄和狭窄前扩张之间的关联，以及炎症性发现中年龄和性别特异性趋势。

Conclusion: HSMP-BERT为放射学领域结构化信息提取提供了一个可扩展的解决方案，特别适用于低资源语言环境。该模型能够实现克罗恩病的人群水平分析，并展示了人工智能在资源受限环境中的巨大潜力。

Abstract: Extracting structured clinical information from radiology reports is
challenging, especially in low-resource languages. This is pronounced in
Crohn's disease, with sparsely represented multi-organ findings. We developed
Hierarchical Structured Matching Prediction BERT (HSMP-BERT), a prompt-based
model for extraction from Hebrew radiology text. In an administrative database
study, we analyzed 9,683 reports from Crohn's patients imaged 2010-2023 across
Israeli providers. A subset of 512 reports was radiologist-annotated for
findings across six gastrointestinal organs and 15 pathologies, yielding 90
structured labels per subject. Multilabel-stratified split (66%
train+validation; 33% test), preserving label prevalence. Performance was
evaluated with accuracy, F1, Cohen's $\kappa$, AUC, PPV, NPV, and recall. On 24
organ-finding combinations with $>$15 positives, HSMP-BERT achieved mean F1
0.83$\pm$0.08 and $\kappa$ 0.65$\pm$0.17, outperforming the SMP zero-shot
baseline (F1 0.49$\pm$0.07, $\kappa$ 0.06$\pm$0.07) and standard fine-tuning
(F1 0.30$\pm$0.27, $\kappa$ 0.27$\pm$0.34; paired t-test $p < 10^{-7}$).
Hierarchical inference cuts runtime 5.1$\times$ vs. traditional inference.
Applied to all reports, it revealed associations among ileal wall thickening,
stenosis, and pre-stenotic dilatation, plus age- and sex-specific trends in
inflammatory findings. HSMP-BERT offers a scalable solution for structured
extraction in radiology, enabling population-level analysis of Crohn's disease
and demonstrating AI's potential in low-resource settings.

</details>


### [124] [Evaluating NL2SQL via SQL2NL](https://arxiv.org/abs/2509.04657)
*Mohammadtaher Safarzadeh,Afshin Oroojlooyjadid,Dan Roth*

Main category: cs.CL

TL;DR: 现有NL2SQL模型在面对语言变体时鲁棒性极差，现有基准测试未能有效揭示此问题。本文提出了一种新的框架来生成语言多样化的查询，并发现最先进的模型在这些变体上性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试很少系统或受控地解决语言变体对自然语言到SQL（NL2SQL）模型泛化能力的影响，而这对于理解模型的鲁棒性至关重要。

Method: 本文提出了一种新颖的模式对齐复述框架，该框架利用SQL到自然语言（SQL2NL）技术自动生成语义等效、词汇多样化且与原始模式和意图保持一致的查询。这使得首次能够孤立地评估NL2SQL模型对语言变体的鲁棒性。

Result: 分析表明，最先进的模型远比标准基准测试所显示的更脆弱。例如，LLaMa3.3-70B在复述的Spider查询上执行准确率下降了10.23%（从77.11%降至66.9%），而LLaMa3.1-8B的下降幅度更大，接近20%（从62.9%降至42.5%）。小型模型（如GPT-4o mini）受到的影响尤为严重。鲁棒性下降程度还随查询复杂性、数据集和领域显著变化。

Conclusion: 研究结果强调了需要专门衡量语言泛化能力的评估框架，以确保NL2SQL模型在实际应用中的可靠性能。

Abstract: Robust evaluation in the presence of linguistic variation is key to
understanding the generalization capabilities of Natural Language to SQL
(NL2SQL) models, yet existing benchmarks rarely address this factor in a
systematic or controlled manner. We propose a novel schema-aligned paraphrasing
framework that leverages SQL-to-NL (SQL2NL) to automatically generate
semantically equivalent, lexically diverse queries while maintaining alignment
with the original schema and intent. This enables the first targeted evaluation
of NL2SQL robustness to linguistic variation in isolation-distinct from prior
work that primarily investigates ambiguity or schema perturbations. Our
analysis reveals that state-of-the-art models are far more brittle than
standard benchmarks suggest. For example, LLaMa3.3-70B exhibits a 10.23% drop
in execution accuracy (from 77.11% to 66.9%) on paraphrased Spider queries,
while LLaMa3.1-8B suffers an even larger drop of nearly 20% (from 62.9% to
42.5%). Smaller models (e.g., GPT-4o mini) are disproportionately affected. We
also find that robustness degradation varies significantly with query
complexity, dataset, and domain -- highlighting the need for evaluation
frameworks that explicitly measure linguistic generalization to ensure reliable
performance in real-world settings.

</details>


### [125] [Using LLMs to create analytical datasets: A case study of reconstructing the historical memory of Colombia](https://arxiv.org/abs/2509.04523)
*David Anderson,Galia Benitez,Margret Bjarnadottir,Shriyan Reyya*

Main category: cs.CL

TL;DR: 本研究利用GPT分析超过20万篇哥伦比亚暴力相关报纸文章，以弥补历史记录空白，并研究暴力与古柯作物根除的关系，展示了大型语言模型（LLM）在深度文本分析中的新机遇。


<details>
  <summary>Details</summary>
Motivation: 哥伦比亚长期受武装冲突困扰，但政府过去并未优先系统记录暴力事件，导致公开可用的冲突信息和历史记载严重缺失。

Method: 利用大型语言模型（LLM）GPT阅读并回答关于20多万篇西班牙语暴力相关报纸文章的问题，生成了一个数据集。随后，利用该数据集进行描述性分析，并研究暴力与古柯作物根除之间的关系。

Result: 创建了一个关于哥伦比亚暴力历史的详细数据集，并基于此数据进行了描述性分析，以及一项关于暴力与古柯作物根除之间关系的政策分析示例。

Conclusion: 本研究表明，大型语言模型（LLM）通过实现对大型文本语料库前所未有的深度分析，开辟了新的研究机会。

Abstract: Colombia has been submerged in decades of armed conflict, yet until recently,
the systematic documentation of violence was not a priority for the Colombian
government. This has resulted in a lack of publicly available conflict
information and, consequently, a lack of historical accounts. This study
contributes to Colombia's historical memory by utilizing GPT, a large language
model (LLM), to read and answer questions about over 200,000 violence-related
newspaper articles in Spanish. We use the resulting dataset to conduct both
descriptive analysis and a study of the relationship between violence and the
eradication of coca crops, offering an example of policy analyses that such
data can support. Our study demonstrates how LLMs have opened new research
opportunities by enabling examinations of large text corpora at a previously
infeasible depth.

</details>


### [126] [ODKE+: Ontology-Guided Open-Domain Knowledge Extraction with LLMs](https://arxiv.org/abs/2509.04696)
*Samira Khorshidi,Azadeh Nikfarjam,Suprita Shankar,Yisi Sang,Yash Govind,Hyun Jang,Ali Kasgari,Alexis McClimans,Mohamed Soliman,Vishnu Konda,Ahmed Fakhry,Xiaoguang Qi*

Main category: cs.CL

TL;DR: ODKE+是一个生产级的系统，它利用模块化组件、混合知识提取器（包括LLM）和本体引导，从网络源自动、高精度地提取和摄取开放域事实，以维护知识图谱的及时性和完整性。


<details>
  <summary>Details</summary>
Motivation: 知识图谱是许多AI应用的基础，但维护其新鲜度和完整性成本高昂。

Method: ODKE+是一个可扩展的模块化流水线系统，包括：1) 提取启动器检测缺失或过时事实；2) 证据检索器收集支持文档；3) 混合知识提取器结合基于模式的规则和本体引导的LLM提示；4) 轻量级验证器使用第二个LLM验证提取的事实；5) 确认器对候选事实进行排名和规范化。系统动态生成针对每个实体类型的本体片段，以使提取与模式约束对齐，并支持批处理和流式模式。

Result: ODKE+处理了超过900万个维基百科页面，摄取了1900万个高置信度事实，精度达到98.8%。它显著提高了覆盖率，与第三方知识图谱重叠度高达48%，并平均减少了50天的更新延迟。

Conclusion: 基于LLM的提取，在本体结构和验证工作流的支持下，能够实现可信赖的、生产规模的知识摄取，并具有广泛的实际应用价值。

Abstract: Knowledge graphs (KGs) are foundational to many AI applications, but
maintaining their freshness and completeness remains costly. We present ODKE+,
a production-grade system that automatically extracts and ingests millions of
open-domain facts from web sources with high precision. ODKE+ combines modular
components into a scalable pipeline: (1) the Extraction Initiator detects
missing or stale facts, (2) the Evidence Retriever collects supporting
documents, (3) hybrid Knowledge Extractors apply both pattern-based rules and
ontology-guided prompting for large language models (LLMs), (4) a lightweight
Grounder validates extracted facts using a second LLM, and (5) the Corroborator
ranks and normalizes candidate facts for ingestion. ODKE+ dynamically generates
ontology snippets tailored to each entity type to align extractions with schema
constraints, enabling scalable, type-consistent fact extraction across 195
predicates. The system supports batch and streaming modes, processing over 9
million Wikipedia pages and ingesting 19 million high-confidence facts with
98.8% precision. ODKE+ significantly improves coverage over traditional
methods, achieving up to 48% overlap with third-party KGs and reducing update
lag by 50 days on average. Our deployment demonstrates that LLM-based
extraction, grounded in ontological structure and verification workflows, can
deliver trustworthiness, production-scale knowledge ingestion with broad
real-world applicability. A recording of the system demonstration is included
with the submission and is also available at https://youtu.be/UcnE3_GsTWs.

</details>


### [127] [Spoken in Jest, Detected in Earnest: A Systematic Review of Sarcasm Recognition -- Multimodal Fusion, Challenges, and Future Prospects](https://arxiv.org/abs/2509.04605)
*Xiyuan Gao,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: 这篇系统综述首次关注基于语音的讽刺识别，追踪了从单模态到多模态方法的发展，并指出了数据集、特征提取和分类方法的演变以及未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 讽刺是人类交流中的常见挑战，对人际和人机互动构成障碍。语言学研究强调了韵律线索的重要性，但语音数据在讽刺识别中的作用尚未被充分探索。自动语音讽刺识别可以改善神经退行性疾病患者的社交互动，并提高机器对复杂人类语言的理解，从而实现更细致的交互。

Method: 本文采用系统综述的方法，首次专注于基于语音的讽刺识别。它涵盖了数据集、特征提取和分类方法，并追溯了从单模态到多模态方法的演变，旨在弥合不同研究领域之间的鸿沟。

Result: 研究发现，语音讽刺识别的数据集存在局限性；特征提取技术从传统的声学特征发展到基于深度学习的表示；分类方法从单模态方法演进到多模态融合技术。

Conclusion: 结论强调需要更多地关注跨文化和多语言的讽刺识别，以及将讽刺视为一种多模态现象而非仅基于文本的挑战。

Abstract: Sarcasm, a common feature of human communication, poses challenges in
interpersonal interactions and human-machine interactions. Linguistic research
has highlighted the importance of prosodic cues, such as variations in pitch,
speaking rate, and intonation, in conveying sarcastic intent. Although previous
work has focused on text-based sarcasm detection, the role of speech data in
recognizing sarcasm has been underexplored. Recent advancements in speech
technology emphasize the growing importance of leveraging speech data for
automatic sarcasm recognition, which can enhance social interactions for
individuals with neurodegenerative conditions and improve machine understanding
of complex human language use, leading to more nuanced interactions. This
systematic review is the first to focus on speech-based sarcasm recognition,
charting the evolution from unimodal to multimodal approaches. It covers
datasets, feature extraction, and classification methods, and aims to bridge
gaps across diverse research domains. The findings include limitations in
datasets for sarcasm recognition in speech, the evolution of feature extraction
techniques from traditional acoustic features to deep learning-based
representations, and the progression of classification methods from unimodal
approaches to multimodal fusion techniques. In so doing, we identify the need
for greater emphasis on cross-cultural and multilingual sarcasm recognition, as
well as the importance of addressing sarcasm as a multimodal phenomenon, rather
than a text-based challenge.

</details>


### [128] [KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced Question Answering](https://arxiv.org/abs/2509.04716)
*Yushi Sun,Kai Sun,Yifan Ethan Xu,Xiao Yang,Xin Luna Dong,Nan Tang,Lei Chen*

Main category: cs.CL

TL;DR: KERAG是一种基于知识图谱的检索增强生成（RAG）管道，通过检索更广泛的子图、过滤、摘要和使用微调LLM进行思维链推理，显著提高了问答覆盖率和质量，超越了现有SOTA和GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）存在幻觉问题，RAG可通过外部数据缓解。知识图谱（KG）为问答提供关键信息。传统KGQA方法依赖语义解析，检索知识严格受限，常因严格的模式要求和语义模糊导致覆盖率低。因此，需要一种能提高问答覆盖率的KG-based RAG方法。

Method: KERAG采用检索-过滤-摘要的方法。它首先检索一个更广泛的知识子图，该子图可能包含相关信息，以提高覆盖率。然后对检索到的子图进行过滤和摘要处理以减少噪声。最后，结合经过微调的LLM，利用思维链（Chain-of-Thought）推理在处理后的知识子图上进行问答。

Result: KERAG在问答质量上超越了现有最先进解决方案约7%，并且比GPT-4o (Tool) 高出10-21%。

Conclusion: KERAG通过其新颖的检索-过滤-摘要方法和结合微调LLM的思维链推理，有效解决了传统KGQA覆盖率低的问题，显著提高了简单和复杂问题的问答质量，并优于现有顶级LLM解决方案。

Abstract: Retrieval-Augmented Generation (RAG) mitigates hallucination in Large
Language Models (LLMs) by incorporating external data, with Knowledge Graphs
(KGs) offering crucial information for question answering. Traditional
Knowledge Graph Question Answering (KGQA) methods rely on semantic parsing,
which typically retrieves knowledge strictly necessary for answer generation,
thus often suffer from low coverage due to rigid schema requirements and
semantic ambiguity. We present KERAG, a novel KG-based RAG pipeline that
enhances QA coverage by retrieving a broader subgraph likely to contain
relevant information. Our retrieval-filtering-summarization approach, combined
with fine-tuned LLMs for Chain-of-Thought reasoning on knowledge sub-graphs,
reduces noises and improves QA for both simple and complex questions.
Experiments demonstrate that KERAG surpasses state-of-the-art solutions by
about 7% in quality and exceeds GPT-4o (Tool) by 10-21%.

</details>


### [129] [Breaking to Build: A Threat Model of Prompt-Based Attacks for Securing LLMs](https://arxiv.org/abs/2509.04615)
*Brennen Hill,Surendra Parla,Venkata Abhijeeth Balabhadruni,Atharv Prajod Padmalayam,Sujay Chandra Shekara Sharma*

Main category: cs.CL

TL;DR: 大语言模型（LLMs）面临严重的提示攻击安全挑战。本文对这些攻击方法进行了全面的文献综述和分类，旨在提供一个清晰的威胁模型，并指导未来安全LLMs的开发。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的普及，出现了关键的安全挑战，恶意行为者可以通过操纵输入提示来造成重大损害并规避安全对齐。这些基于提示的攻击利用模型设计、训练和上下文理解中的漏洞，导致知识产权盗窃、虚假信息生成和用户信任受损。系统地理解这些攻击向量是开发强大防御措施的基础。

Method: 本文通过对基于提示的攻击方法进行全面的文献综述，并对其进行分类，以提供一个清晰的威胁模型。

Result: 论文详细阐述了基于提示的攻击机制和影响，并对攻击方法进行了系统分类，从而构建了一个清晰的威胁模型。

Conclusion: 本综述旨在为研究社区构建下一代安全的LLMs提供信息，使其能够固有地抵抗未经授权的蒸馏、微调和编辑，从而开发出更强大的对策。

Abstract: The proliferation of Large Language Models (LLMs) has introduced critical
security challenges, where adversarial actors can manipulate input prompts to
cause significant harm and circumvent safety alignments. These prompt-based
attacks exploit vulnerabilities in a model's design, training, and contextual
understanding, leading to intellectual property theft, misinformation
generation, and erosion of user trust. A systematic understanding of these
attack vectors is the foundational step toward developing robust
countermeasures. This paper presents a comprehensive literature survey of
prompt-based attack methodologies, categorizing them to provide a clear threat
model. By detailing the mechanisms and impacts of these exploits, this survey
aims to inform the research community's efforts in building the next generation
of secure LLMs that are inherently resistant to unauthorized distillation,
fine-tuning, and editing.

</details>


### [130] [A Study of Large Language Models for Patient Information Extraction: Model Architecture, Fine-Tuning Strategy, and Multi-task Instruction Tuning](https://arxiv.org/abs/2509.04753)
*Cheng Peng,Xinyu Dong,Mengxian Lyu,Daniel Paredes,Yaoyun Zhang,Yonghui Wu*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型（LLMs）在临床叙述中进行患者信息提取的有效性，重点关注LLM架构、参数高效微调（PEFT）策略以及多任务指令微调技术，以开发稳健且泛化能力强的系统。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理（NLP）是提取临床叙述中患者信息以支持医疗应用的关键技术。尽管大型语言模型（LLMs）的快速发展彻底改变了临床领域的许多NLP任务，但其在患者信息提取任务中的最佳使用仍需进一步探索。

Method: 本研究探讨了LLM在临床概念和关系提取任务中的关键概念，包括：1) 编码器-only或解码器-only LLM架构，2) 基于提示的参数高效微调（PEFT）算法，以及3) 多任务指令微调对少样本学习性能的影响。研究基准测试了一系列LLMs，包括编码器基LLMs（BERT, GatorTron）和解码器基LLMs（GatorTronGPT, Llama 3.1, GatorTronLlama），并跨五个数据集进行评估。研究比较了传统的全尺寸微调和基于提示的PEFT。此外，还探索了一个多任务指令微调框架，该框架结合了四个数据集上的两项任务，并使用留一数据集法评估了零样本和少样本学习性能。

Result: 摘要描述了研究将要进行的基准测试和比较，但并未明确给出具体的实验结果或发现。它表明研究将比较不同LLM架构、微调策略和多任务指令微调在患者信息提取任务中的表现。

Conclusion: 摘要并未提供明确的研究结论，而是指出了本研究旨在探索和理解LLM在临床患者信息提取中的最佳使用方式，并通过对不同架构、微调策略和多任务指令微调的系统性评估，为开发稳健和通用系统提供见解。

Abstract: Natural language processing (NLP) is a key technology to extract important
patient information from clinical narratives to support healthcare
applications. The rapid development of large language models (LLMs) has
revolutionized many NLP tasks in the clinical domain, yet their optimal use in
patient information extraction tasks requires further exploration. This study
examines LLMs' effectiveness in patient information extraction, focusing on LLM
architectures, fine-tuning strategies, and multi-task instruction tuning
techniques for developing robust and generalizable patient information
extraction systems. This study aims to explore key concepts of using LLMs for
clinical concept and relation extraction tasks, including: (1) encoder-only or
decoder-only LLMs, (2) prompt-based parameter-efficient fine-tuning (PEFT)
algorithms, and (3) multi-task instruction tuning on few-shot learning
performance. We benchmarked a suite of LLMs, including encoder-based LLMs
(BERT, GatorTron) and decoder-based LLMs (GatorTronGPT, Llama 3.1,
GatorTronLlama), across five datasets. We compared traditional full-size
fine-tuning and prompt-based PEFT. We explored a multi-task instruction tuning
framework that combines both tasks across four datasets to evaluate the
zero-shot and few-shot learning performance using the leave-one-dataset-out
strategy.

</details>


### [131] [AraHalluEval: A Fine-grained Hallucination Evaluation Framework for Arabic LLMs](https://arxiv.org/abs/2509.04656)
*Aisha Alansari,Hamzah Luqman*

Main category: cs.CL

TL;DR: 本研究首次对阿拉伯语和多语言大型语言模型（LLMs）在阿拉伯语生成式问答和摘要任务中的幻觉现象进行了全面评估，并发现事实性幻觉更普遍，且阿拉伯语预训练模型表现较好。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言和阿拉伯语LLMs数量不断增长，但LLMs在阿拉伯语语境下的幻觉评估仍相对不足。鉴于阿拉伯语的广泛使用及其在全球交流和媒体中的重要性，填补这一知识空白刻不容缓。

Method: 研究评估了12个LLMs（包括4个阿拉伯语预训练模型、4个多语言模型和4个基于推理的模型），在生成式问答（GQA）和摘要两个关键阿拉伯语自然语言生成任务上进行。开发了一个包含12个细粒度幻觉指标的评估框架，以评估LLMs输出的事实一致性和忠实度。

Result: 结果显示，在所有模型和任务中，事实性幻觉比忠实度错误更为普遍。值得注意的是，阿拉伯语预训练模型Allam持续展现出比多语言模型更低的幻觉率，并与基于推理的模型表现相当。

Conclusion: 本研究首次全面评估了阿拉伯语LLMs的幻觉现象，揭示了事实性幻觉的普遍性，并表明专门的阿拉伯语预训练模型在降低幻觉方面可能优于多语言模型，为未来的阿拉伯语LLM开发提供了重要见解。

Abstract: Recently, extensive research on the hallucination of the large language
models (LLMs) has mainly focused on the English language. Despite the growing
number of multilingual and Arabic-specific LLMs, evaluating LLMs' hallucination
in the Arabic context remains relatively underexplored. The knowledge gap is
particularly pressing given Arabic's widespread use across many regions and its
importance in global communication and media. This paper presents the first
comprehensive hallucination evaluation of Arabic and multilingual LLMs on two
critical Arabic natural language generation tasks: generative question
answering (GQA) and summarization. This study evaluates a total of 12 LLMs,
including 4 Arabic pre-trained models, 4 multilingual models, and 4
reasoning-based models. To assess the factual consistency and faithfulness of
LLMs' outputs, we developed a fine-grained hallucination evaluation framework
consisting of 12 fine-grained hallucination indicators that represent the
varying characteristics of each task. The results reveal that factual
hallucinations are more prevalent than faithfulness errors across all models
and tasks. Notably, the Arabic pre-trained model Allam consistently
demonstrates lower hallucination rates than multilingual models and a
comparative performance with reasoning-based models. The code is available at:
\href{https://github.com/aishaalansari57/AraHalluEval}{Github link}.

</details>


### [132] [Decoders Laugh as Loud as Encoders](https://arxiv.org/abs/2509.04779)
*Eli Borodach,Raj Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.CL

TL;DR: 本文比较了微调后的解码器（GPT-4o）和编码器（RoBERTa）在幽默理解任务上的表现，发现两者性能相当。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在各种自然语言处理任务中表现出色，甚至超越人类水平，但它们对所生成内容的理解程度仍不清楚，尤其是在幽默这种细微主题上。计算机是否理解幽默的问题仍未解决。

Method: 研究人员对一个解码器模型（GPT-4o）进行了微调，并将其与一个最佳的微调编码器模型（RoBERTa）在幽默理解任务上进行了比较。

Result: 微调后的解码器GPT-4o在幽默理解任务中取得了0.85的平均F1-macro分数，而微调后的编码器RoBERTa取得了0.86的平均F1分数。这表明两者的性能相当。

Conclusion: 微调后的解码器（如GPT-4o）在幽默理解方面可以与最佳的微调编码器（如RoBERTa）表现得同样出色。

Abstract: From the dawn of the computer, Allen Turing dreamed of a robot that could
communicate using language as a human being. The recent advances in the field
of Large Language Models (LLMs) shocked the scientific community when a single
model can apply for various natural language processing (NLP) tasks, while the
output results are sometimes even better than most human communication skills.
Models such as GPT, Claude, Grok, etc. have left their mark on the scientific
community. However, it is unclear how much these models understand what they
produce, especially in a nuanced theme such as humor. The question of whether
computers understand humor is still open (among the decoders, the latest to be
checked was GPT-2). We addressed this issue in this paper; we have showed that
a fine-tuned decoder (GPT-4o) performed (Mean F1-macro score of 0.85) as well
as the best fine-tuned encoder (RoBERTa with a Mean of F1-score 0.86)

</details>


### [133] [Why Language Models Hallucinate](https://arxiv.org/abs/2509.04664)
*Adam Tauman Kalai,Ofir Nachum,Santosh S. Vempala,Edwin Zhang*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）的幻觉源于训练和评估机制奖励猜测而非承认不确定性，本质是二元分类错误。解决之道在于修改现有基准测试的评分方式，以引导模型更值得信赖。


<details>
  <summary>Details</summary>
Motivation: LLMs在不确定时会“猜测”，产生看似合理但错误的陈述（即“幻觉”），这损害了用户对系统的信任，即使是先进模型也存在此问题。

Method: 本文通过分析现代训练流程中的统计原因，将幻觉归结为二元分类错误。同时，作者论证了现有评估方法（即“惩罚不确定响应”）如何导致幻觉持续存在，因为模型被优化为“善于考试者”，猜测能提高测试表现。

Result: 幻觉并非神秘，它们是二元分类中的简单错误。当错误陈述无法与事实区分时，预训练语言模型在统计压力下会产生幻觉。此外，由于大多数评估的评分方式，奖励猜测而非承认不确定性，导致幻觉持续存在。

Conclusion: 解决幻觉的“流行”需要社会技术层面的缓解措施：修改现有主导排行榜但存在偏差的基准测试的评分方式，而非引入额外的幻觉评估。这种改变可能促使领域转向更值得信赖的AI系统。

Abstract: Like students facing hard exam questions, large language models sometimes
guess when uncertain, producing plausible yet incorrect statements instead of
admitting uncertainty. Such "hallucinations" persist even in state-of-the-art
systems and undermine trust. We argue that language models hallucinate because
the training and evaluation procedures reward guessing over acknowledging
uncertainty, and we analyze the statistical causes of hallucinations in the
modern training pipeline. Hallucinations need not be mysterious -- they
originate simply as errors in binary classification. If incorrect statements
cannot be distinguished from facts, then hallucinations in pretrained language
models will arise through natural statistical pressures. We then argue that
hallucinations persist due to the way most evaluations are graded -- language
models are optimized to be good test-takers, and guessing when uncertain
improves test performance. This "epidemic" of penalizing uncertain responses
can only be addressed through a socio-technical mitigation: modifying the
scoring of existing benchmarks that are misaligned but dominate leaderboards,
rather than introducing additional hallucination evaluations. This change may
steer the field toward more trustworthy AI systems.

</details>


### [134] [Enhancing Diversity in Large Language Models via Determinantal Point Processes](https://arxiv.org/abs/2509.04784)
*Yilei Chen,Souradip Chakraborty,Lorenz Wolf,Ioannis Ch. Paschalidis,Aldo Pacchiano*

Main category: cs.CL

TL;DR: 本文提出了一种名为DQO的新型训练方法，基于行列式点过程（DPPs），旨在同时优化大型语言模型（LLMs）的输出质量和语义多样性，有效解决了现有后训练方法导致的多样性下降问题。


<details>
  <summary>Details</summary>
Motivation: 监督微调和强化学习等LLM后训练方法虽然能提升模型性能，但常会降低输出多样性，导致响应狭隘和规范化。现有提高多样性的方法要么仅限于推理时，要么只关注词汇差异，存在局限性。

Method: DQO方法基于行列式点过程（DPPs），为每个提示词采样并嵌入一组响应。它利用基于核函数的相似性矩阵的行列式来衡量多样性，该行列式代表了这些响应嵌入所跨越的“体积”。

Result: 在指令遵循、摘要、故事生成和推理等任务上的实验表明，DQO方法在不牺牲模型质量的前提下，显著提高了语义多样性。

Conclusion: DQO是一种有效的训练方法，能够联合优化大型语言模型的质量和语义多样性，解决了传统后训练方法在多样性方面的不足。

Abstract: Supervised fine-tuning and reinforcement learning are two popular methods for
post-training large language models (LLMs). While improving the model's
performance on downstream tasks, they often reduce the model's output
diversity, leading to narrow, canonical responses. Existing methods to enhance
diversity are limited, either by operating at inference time or by focusing on
lexical differences. We propose a novel training method named DQO based on
determinantal point processes (DPPs) to jointly optimize LLMs for quality and
semantic diversity. Our approach samples and embeds a group of responses for
each prompt, then uses the determinant of a kernel-based similarity matrix to
measure diversity as the volume spanned by the embeddings of these responses.
Experiments across instruction-following, summarization, story generation, and
reasoning tasks demonstrate that our method substantially improves semantic
diversity without sacrificing model quality.

</details>


### [135] [OleSpeech-IV: A Large-Scale Multispeaker and Multilingual Conversational Speech Dataset with Diverse Topics](https://arxiv.org/abs/2509.04702)
*Wei Chu,Yuanzhe Dong,Ke Tan,Dong Han,Xavier Menendez-Pidal,Ruchao Fan,Chenfeng Miao,Chanwoo Kim,Bhiksha Raj,Rita Singh*

Main category: cs.CL

TL;DR: OleSpeech-IV是一个大规模、多说话人、多语言的对话语音数据集，内容来源于公开的英文播客和会议，经过人工标注和专有流程处理，并开放了一个子集供非商业研究使用。


<details>
  <summary>Details</summary>
Motivation: 抽象中没有明确说明动机，但推测是为了提供一个高质量、大规模、多样化的对话语音数据集，以支持相关领域的语音技术研究和开发。

Method: 音频内容来源于公开的英文播客、脱口秀、电话会议及其他对话。说话人姓名、轮次和转录本通过人工标注和专有流程进行精炼，时间戳和置信度等附加信息也由该流程生成。

Result: 创建了OleSpeech-IV数据集，它是一个大规模、多说话人、多语言的对话语音数据集，包含多样主题。该数据集是Olewave数据集系列的Tier IV。此外，还开放了一个名为OleSpeech-IV-2025-EN-AR-100的子集，供非商业研究使用。

Conclusion: 该研究提供了一个高质量、大规模的对话语音数据集，并通过开放子集的方式，为非商业研究社区提供了宝贵的资源，有助于推动多说话人、多语言对话语音处理领域的发展。

Abstract: OleSpeech-IV dataset is a large-scale multispeaker and multilingual
conversational speech dataset with diverse topics. The audio content comes from
publicly-available English podcasts, talk shows, teleconferences, and other
conversations. Speaker names, turns, and transcripts are human-sourced and
refined by a proprietary pipeline, while additional information such as
timestamps and confidence scores is derived from the pipeline. The IV denotes
its position as Tier IV in the Olewave dataset series. In addition, we have
open-sourced a subset, OleSpeech-IV-2025-EN-AR-100, for non-commercial research
use.

</details>


### [136] [PLaMo 2 Technical Report](https://arxiv.org/abs/2509.04897)
*Preferred Networks,:,Kaizaburo Chubachi,Yasuhiro Fujita,Shinichi Hemmi,Yuta Hirokawa,Toshiki Kataoka,Goro Kobayashi,Kenichi Maehashi,Calvin Metzger,Hiroaki Mikami,Shogo Murai,Daisuke Nishino,Kento Nozawa,Shintarou Okada,Daisuke Okanohara,Shunta Saito,Shotaro Sano,Shuji Suzuki,Daisuke Tanaka,Avinash Ummadisingu,Hanqin Wang,Sixue Wang,Tianqi Xu*

Main category: cs.CL

TL;DR: PLaMo 2 是一系列专注于日语的大型语言模型，采用混合Samba架构，通过持续预训练支持32K长上下文。它利用合成数据克服数据稀缺，并通过权重复用和结构化剪枝实现高效训练，使8B模型达到与之前100B模型相当的性能。通过SFT和DPO等后训练优化，PLaMo 2在日语基准测试上取得了最先进的成果，超越了同等规模的开源模型。


<details>
  <summary>Details</summary>
Motivation: 开发高性能、长上下文、专注于日语的大型语言模型，同时克服日语数据稀缺问题，并通过计算效率优化使其在推理时表现出色。

Method: 该研究采用混合Samba-based架构，通过持续预训练过渡到全注意力机制以支持32K长上下文。训练利用大量合成语料库解决数据稀缺。计算效率通过权重复用和结构化剪枝实现。后训练流程包括监督微调（SFT）和直接偏好优化（DPO），并结合合成日语指令数据和模型合并技术。推理优化则通过vLLM和量化技术实现。

Result: PLaMo 2 系列模型在日语基准测试上取得了最先进的成果。特别是，通过高效剪枝，一个8B模型实现了与之前100B模型相当的性能。这些模型在指令遵循、语言流畅性和日语特定知识方面优于同等规模的开源模型。

Conclusion: PLaMo 2 成功开发了一系列高效、高性能的日语大型语言模型。通过结合创新的混合架构、合成数据利用、高效剪枝和先进的后训练技术，PLaMo 2 在长上下文支持和日语特定任务上树立了新的标杆，并在计算效率和性能之间取得了卓越的平衡。

Abstract: In this report, we introduce PLaMo 2, a series of Japanese-focused large
language models featuring a hybrid Samba-based architecture that transitions to
full attention via continual pre-training to support 32K token contexts.
Training leverages extensive synthetic corpora to overcome data scarcity, while
computational efficiency is achieved through weight reuse and structured
pruning. This efficient pruning methodology produces an 8B model that achieves
performance comparable to our previous 100B model. Post-training further
refines the models using a pipeline of supervised fine-tuning (SFT) and direct
preference optimization (DPO), enhanced by synthetic Japanese instruction data
and model merging techniques. Optimized for inference using vLLM and
quantization with minimal accuracy loss, the PLaMo 2 models achieve
state-of-the-art results on Japanese benchmarks, outperforming similarly-sized
open models in instruction-following, language fluency, and Japanese-specific
knowledge.

</details>


### [137] [Phonological Representation Learning for Isolated Signs Improves Out-of-Vocabulary Generalization](https://arxiv.org/abs/2509.04745)
*Lee Kezar,Zed Sehyr,Jesse Thomason*

Main category: cs.CL

TL;DR: 本研究通过引入音系学归纳偏置（参数解耦和音系学半监督）改进了矢量量化自编码器，以提高手语模型对未见手语的泛化能力和已知手语的识别性能。


<details>
  <summary>Details</summary>
Motivation: 手语数据集在词汇量方面通常不具代表性，因此需要模型能够泛化到未见手语。现有矢量量化方法尚未评估其学习到的单元是否捕获了阻碍词汇外性能的虚假相关性。

Method: 使用矢量量化自编码器，并引入两种音系学归纳偏置：参数解耦（一种架构偏置）和音系学半监督（一种正则化技术），旨在改善已知手语的孤立手语识别和未见手语的重建质量。

Result: 与受控基线相比，所提出模型学习到的表征在未见手语的单次重建方面更有效，并且在手语识别方面更具判别性。

Conclusion: 本工作定量分析了明确的、受语言学启发的偏置如何能提高手语学习表征的泛化能力。

Abstract: Sign language datasets are often not representative in terms of vocabulary,
underscoring the need for models that generalize to unseen signs. Vector
quantization is a promising approach for learning discrete, token-like
representations, but it has not been evaluated whether the learned units
capture spurious correlations that hinder out-of-vocabulary performance. This
work investigates two phonological inductive biases: Parameter Disentanglement,
an architectural bias, and Phonological Semi-Supervision, a regularization
technique, to improve isolated sign recognition of known signs and
reconstruction quality of unseen signs with a vector-quantized autoencoder. The
primary finding is that the learned representations from the proposed model are
more effective for one-shot reconstruction of unseen signs and more
discriminative for sign identification compared to a controlled baseline. This
work provides a quantitative analysis of how explicit, linguistically-motivated
biases can improve the generalization of learned representations of sign
language.

</details>


### [138] [ToM-SSI: Evaluating Theory of Mind in Situated Social Interactions](https://arxiv.org/abs/2509.05066)
*Matteo Bortoletto,Constantin Ruhdorfer,Andreas Bulling*

Main category: cs.CL

TL;DR: 本文提出ToM-SSI，一个多模态、支持多智能体群体互动的全新心智理论（ToM）基准，旨在解决现有基准的局限性，并揭示了当前模型在此类复杂任务中的显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有针对基础模型的心智理论（ToM）基准主要依赖于Sally-Anne测试的变体，视角非常有限，未能捕捉人类社会互动的复杂性，且仅限于文本或双边互动。

Method: 提出ToM-SSI基准，专为测试基础模型在富含社会互动和空间动态环境中的ToM能力。它支持多模态，包含多达四个智能体的群体互动，智能体可在情境化环境中交流和移动。该设计首次允许研究混合合作-阻碍设置以及并行推理多个智能体的心智状态。

Result: 评估结果表明，当前模型的性能仍然受到严重限制，尤其是在ToM-SSI提出的新任务中表现不佳。

Conclusion: 当前基础模型在复杂社会互动场景中的ToM能力存在关键性差距，为未来研究指明了方向。

Abstract: Most existing Theory of Mind (ToM) benchmarks for foundation models rely on
variations of the Sally-Anne test, offering only a very limited perspective on
ToM and neglecting the complexity of human social interactions. To address this
gap, we propose ToM-SSI: a new benchmark specifically designed to test ToM
capabilities in environments rich with social interactions and spatial
dynamics. While current ToM benchmarks are limited to text-only or dyadic
interactions, ToM-SSI is multimodal and includes group interactions of up to
four agents that communicate and move in situated environments. This unique
design allows us to study, for the first time, mixed cooperative-obstructive
settings and reasoning about multiple agents' mental state in parallel, thus
capturing a wider range of social cognition than existing benchmarks. Our
evaluations reveal that the current models' performance is still severely
limited, especially in these new tasks, highlighting critical gaps for future
research.

</details>


### [139] [Research on Multi-hop Inference Optimization of LLM Based on MQUAKE Framework](https://arxiv.org/abs/2509.04770)
*Zucheng Liang,Wenxin Wei,Kaijie Zhang,Hongyi Chen*

Main category: cs.CL

TL;DR: 本文提出并验证了一种基于多跳问题分解的方法，显著提高了大型语言模型（LLM）回答复杂问题的准确性，无论模型是否经过微调。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在准确回答复杂问题方面一直面临重大挑战。

Method: 本文基于MQUAKE框架，提出了一种针对复杂问题的多跳问题分解方法。利用LLAMA3模型，将MQUAKE-T数据集划分为直接回答复杂问题的单跳数据集和使用多跳分解方法构建的多跳数据集。然后，使用LoRA（Low-Rank Adaptation）方法对LLAMA3模型在这些数据集上进行微调，并进行推理测试，系统研究了多跳问题分解对模型理解和推理准确性的影响。

Result: 实验结果表明，在未微调LLM的情况下，基于多跳问题分解方法的预测性能显著优于直接回答复杂问题的方法。经过LoRA微调后，两种方法的性能均有所提高，但多跳分解方法始终保持其优越性。

Conclusion: 这些发现验证了多跳分解方法在训练前后均有效，证明了其能够有效增强LLM回答复杂问题的能力。

Abstract: Accurately answering complex questions has consistently been a significant
challenge for Large Language Models (LLMs). To address this, this paper
proposes a multi-hop question decomposition method for complex questions,
building upon research within the MQUAKE framework. Utilizing the LLAMA3 model,
we systematically investigate the impact of multi-hop question decomposition
within knowledge graphs on model comprehension and reasoning accuracy, both
before and after model training. In our experiments, we systematically
partitioned and converted the MQUAKE-T dataset into two distinct formats: a
single-hop dataset designed for directly answering complex questions, and a
multi-hop dataset constructed using the multi-hop question decomposition
method. We then fine-tuned the LLAMA3 model on these datasets and conducted
inference tests. Our results demonstrate that, without fine-tuning the LLM, the
prediction performance based on the multi-hop question decomposition method
significantly outperforms the method of directly answering complex questions.
After fine-tuning using the LoRA (Low-Rank Adaptation) method, the performance
of both approaches improved compared to the untrained baseline. Crucially, the
method utilizing multi-hop decomposition consistently maintained its
superiority. These findings validate the effectiveness of the multi-hop
decomposition method both before and after training, demonstrating its
capability to effectively enhance the LLM's ability to answer complex
questions.

</details>


### [140] [ICR: Iterative Clarification and Rewriting for Conversational Search](https://arxiv.org/abs/2509.05100)
*Zhiyu Cao,Peifeng Li,Qiaoming Zhu*

Main category: cs.CL

TL;DR: 本文提出了一种名为ICR（迭代澄清与重写）的新框架，通过迭代生成澄清问题和重写查询来解决对话查询重写中多重模糊表达的问题，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 以往的对话查询重写方法多采用端到端范式，但这种方法难以同时识别和重写查询中存在的多个模糊表达，导致性能受限。

Method: 本文提出ICR框架，采用迭代重写方案，以澄清问题为核心。模型在此框架下交替生成澄清问题和重写后的查询。

Result: 实验结果表明，ICR在澄清-重写迭代过程中能持续提升检索性能，并在两个流行数据集上取得了最先进的性能。

Conclusion: ICR通过迭代澄清和重写的方法，有效解决了对话查询中多重模糊表达的挑战，显著提升了查询重写的质量和检索性能。

Abstract: Most previous work on Conversational Query Rewriting employs an end-to-end
rewriting paradigm. However, this approach is hindered by the issue of multiple
fuzzy expressions within the query, which complicates the simultaneous
identification and rewriting of multiple positions. To address this issue, we
propose a novel framework ICR (Iterative Clarification and Rewriting), an
iterative rewriting scheme that pivots on clarification questions. Within this
framework, the model alternates between generating clarification questions and
rewritten queries. The experimental results show that our ICR can continuously
improve retrieval performance in the clarification-rewriting iterative process,
thereby achieving state-of-the-art performance on two popular datasets.

</details>


### [141] [Personality as a Probe for LLM Evaluation: Method Trade-offs and Downstream Effects](https://arxiv.org/abs/2509.04794)
*Gunmay Handa,Zekun Wu,Adriano Koshiyama,Philip Treleaven*

Main category: cs.CL

TL;DR: 本文系统研究了大型语言模型（LLMs）中基于大五人格特质的人格控制机制及权衡，比较了上下文学习（ICL）、参数高效微调（PEFT）和机制转向（MS）三种方法，并揭示了它们在对齐、能力损失和部署方面的不同表现。


<details>
  <summary>Details</summary>
Motivation: LLMs中的人格操纵在客户服务和智能体场景中应用日益广泛，但其内在机制和权衡尚未明确。

Method: ['构建了一个平衡高/低特质响应的对比数据集，用于向量计算和跨方法评估。', '引入了一个统一的评估框架，基于内部运行的$\\Delta$分析，以解耦推理能力、智能体性能和人口统计学偏见。', '开发了特质净化技术，以分离开放性和尽责性，解决特质编码中的重叠问题。', '提出了一个三级稳定性框架，量化方法、特质和组合层面的鲁棒性。', '在Gemma-2-2B-IT和LLaMA-3-8B-Instruct模型上，比较了ICL、PEFT和MS三种方法。']

Result: ['ICL实现了强大的对齐，同时能力损失最小。', 'PEFT提供了最高的对齐度，但代价是任务性能下降。', 'MS提供了轻量级的运行时控制，且效果具有竞争力。', '特质层面分析显示，开放性特质最具挑战性，宜人性对ICL最不敏感，人格编码倾向于在中间层巩固。']

Conclusion: 人格操纵是行为表征的多层次探针，它连接了表面条件反射、参数编码和激活层转向。机制转向（MS）作为一种轻量级替代方案，在部署和可解释性方面均可替代微调。

Abstract: Personality manipulation in large language models (LLMs) is increasingly
applied in customer service and agentic scenarios, yet its mechanisms and
trade-offs remain unclear. We present a systematic study of personality control
using the Big Five traits, comparing in-context learning (ICL),
parameter-efficient fine-tuning (PEFT), and mechanistic steering (MS). Our
contributions are fourfold. First, we construct a contrastive dataset with
balanced high/low trait responses, enabling effective steering vector
computation and fair cross-method evaluation. Second, we introduce a unified
evaluation framework based on within-run $\Delta$ analysis that disentangles,
reasoning capability, agent performance, and demographic bias across MMLU,
GAIA, and BBQ benchmarks. Third, we develop trait purification techniques to
separate openness from conscientiousness, addressing representational overlap
in trait encoding. Fourth, we propose a three-level stability framework that
quantifies method-, trait-, and combination-level robustness, offering
practical guidance under deployment constraints. Experiments on Gemma-2-2B-IT
and LLaMA-3-8B-Instruct reveal clear trade-offs: ICL achieves strong alignment
with minimal capability loss, PEFT delivers the highest alignment at the cost
of degraded task performance, and MS provides lightweight runtime control with
competitive effectiveness. Trait-level analysis shows openness as uniquely
challenging, agreeableness as most resistant to ICL, and personality encoding
consolidating around intermediate layers. Taken together, these results
establish personality manipulation as a multi-level probe into behavioral
representation, linking surface conditioning, parameter encoding, and
activation-level steering, and positioning mechanistic steering as a
lightweight alternative to fine-tuning for both deployment and
interpretability.

</details>


### [142] [HoPE: Hyperbolic Rotary Positional Encoding for Stable Long-Range Dependency Modeling in Large Language Models](https://arxiv.org/abs/2509.05218)
*Chang Dai,Hongyu Shan,Mingyang Song,Di Liang*

Main category: cs.CL

TL;DR: 本文提出了一种基于双曲几何的旋转位置编码（HoPE），通过借鉴洛伦兹变换，解决了传统RoPE在长序列中注意力模式不稳定的问题，并在多项长序列基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的位置编码机制存在局限性：绝对位置编码难以泛化到更长序列；Alibi在超长上下文上性能下降；广泛使用的RoPE引入了振荡注意力模式，阻碍了稳定的长距离依赖建模。

Method: 本文通过对位置编码进行几何重构，提出了双曲旋转位置编码（HoPE）。HoPE受双曲几何中的洛伦兹变换启发，利用双曲函数对token表示进行洛伦兹旋转。理论分析表明，RoPE是HoPE的特例。HoPE通过强制注意力权重随token距离增加而单调衰减，从根本上解决了RoPE的平移问题。

Result: 广泛的实验结果，包括在多个扩展序列基准下的困惑度评估，表明HoPE始终优于现有的位置编码方法。这些发现强调了HoPE在表示和泛化长距离依赖方面的增强能力。

Conclusion: HoPE通过其独特的双曲几何设计，有效解决了现有位置编码在长距离依赖建模中的挑战，特别是在稳定性和泛化能力方面表现出色，为Transformer模型处理长序列提供了更优的解决方案。

Abstract: Positional encoding mechanisms enable Transformers to model sequential
structure and long-range dependencies in text. While absolute positional
encodings struggle with extrapolation to longer sequences due to fixed
positional representations, and relative approaches like Alibi exhibit
performance degradation on extremely long contexts, the widely-used Rotary
Positional Encoding (RoPE) introduces oscillatory attention patterns that
hinder stable long-distance dependency modelling. We address these limitations
through a geometric reformulation of positional encoding. Drawing inspiration
from Lorentz transformations in hyperbolic geometry, we propose Hyperbolic
Rotary Positional Encoding (HoPE), which leverages hyperbolic functions to
implement Lorentz rotations on token representations. Theoretical analysis
demonstrates that RoPE is a special case of our generalized formulation. HoPE
fundamentally resolves RoPE's slation issues by enforcing monotonic decay of
attention weights with increasing token distances. Extensive experimental
results, including perplexity evaluations under several extended sequence
benchmarks, show that HoPE consistently exceeds existing positional encoding
methods. These findings underscore HoPE's enhanced capacity for representing
and generalizing long-range dependencies. Data and code will be available.

</details>


### [143] [Knowledge Collapse in LLMs: When Fluency Survives but Facts Fail under Recursive Synthetic Training](https://arxiv.org/abs/2509.04796)
*Figarri Keisha,Zekun Wu,Ze Wang,Adriano Koshiyama,Philip Treleaven*

Main category: cs.CL

TL;DR: 由于合成数据训练，大型语言模型面临“知识崩溃”，即事实准确性下降但表面流畅性保持的现象。研究发现崩溃轨迹和时间取决于指令格式，并提出领域特定合成训练作为有效的缓解策略。


<details>
  <summary>Details</summary>
Motivation: 人类编写内容稀缺导致大型语言模型日益依赖合成数据，但模型在自身生成输出上进行递归训练会导致模型崩溃，特别是“知识崩溃”，即模型生成“自信但错误”的输出，对依赖准确性的领域构成严重风险。

Method: 通过递归合成训练进行受控实验，定义了知识崩溃为三个阶段的现象。研究了指令格式对崩溃轨迹和时间的影响。提出了领域特定合成训练作为缓解策略。评估框架结合了以模型为中心的指标和以任务为中心的度量来检测退化阶段。

Result: 知识崩溃是一个独特的三阶段现象，表现为事实准确性下降但表面流畅性持续存在。崩溃轨迹和时间关键取决于指令格式，区分了有条件的、依赖提示的指令遵循崩溃。领域特定合成训练作为缓解策略，显著提高了抗崩溃能力并保持了计算效率。

Conclusion: 这些发现提供了关于崩溃动力学的理论见解，并为知识密集型应用中可持续的AI训练提供了实用指导，其中准确性至关重要。

Abstract: Large language models increasingly rely on synthetic data due to
human-written content scarcity, yet recursive training on model-generated
outputs leads to model collapse, a degenerative process threatening factual
reliability. We define knowledge collapse as a distinct three-stage phenomenon
where factual accuracy deteriorates while surface fluency persists, creating
"confidently wrong" outputs that pose critical risks in accuracy-dependent
domains. Through controlled experiments with recursive synthetic training, we
demonstrate that collapse trajectory and timing depend critically on
instruction format, distinguishing instruction-following collapse from
traditional model collapse through its conditional, prompt-dependent nature. We
propose domain-specific synthetic training as a targeted mitigation strategy
that achieves substantial improvements in collapse resistance while maintaining
computational efficiency. Our evaluation framework combines model-centric
indicators with task-centric metrics to detect distinct degradation phases,
enabling reproducible assessment of epistemic deterioration across different
language models. These findings provide both theoretical insights into collapse
dynamics and practical guidance for sustainable AI training in
knowledge-intensive applications where accuracy is paramount.

</details>


### [144] [CURE: Controlled Unlearning for Robust Embeddings -- Mitigating Conceptual Shortcuts in Pre-Trained Language Models](https://arxiv.org/abs/2509.05230)
*Aysenur Kocak,Shuo Yang,Bardh Prenkaj,Gjergji Kasneci*

Main category: cs.CL

TL;DR: CURE是一个轻量级框架，通过解耦和抑制概念性捷径，同时保留内容信息，提高预训练语言模型的鲁棒性和公平性。它在IMDB和Yelp数据集上取得了显著的F1分数提升，且计算开销极小。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型在应用中表现出色，但容易受到虚假、概念驱动的相关性影响，这会损害模型的鲁棒性和公平性。

Method: CURE框架包含两个主要部分：1) 内容提取器，通过逆转网络强化，提取与概念无关的表示，确保任务相关信息损失最小；2) 可控去偏模块，利用对比学习精细调整残余概念线索的影响，以减少有害偏见或利用有益关联。

Result: 在IMDB和Yelp数据集上，使用三种预训练架构进行评估，CURE在IMDB上F1分数绝对提升了10点，在Yelp上提升了2点，同时引入的计算开销极小。

Conclusion: 该方法为对抗概念性偏见提供了一个灵活、无监督的蓝图，为更可靠和公平的语言理解系统铺平了道路。

Abstract: Pre-trained language models have achieved remarkable success across diverse
applications but remain susceptible to spurious, concept-driven correlations
that impair robustness and fairness. In this work, we introduce CURE, a novel
and lightweight framework that systematically disentangles and suppresses
conceptual shortcuts while preserving essential content information. Our method
first extracts concept-irrelevant representations via a dedicated content
extractor reinforced by a reversal network, ensuring minimal loss of
task-relevant information. A subsequent controllable debiasing module employs
contrastive learning to finely adjust the influence of residual conceptual
cues, enabling the model to either diminish harmful biases or harness
beneficial correlations as appropriate for the target task. Evaluated on the
IMDB and Yelp datasets using three pre-trained architectures, CURE achieves an
absolute improvement of +10 points in F1 score on IMDB and +2 points on Yelp,
while introducing minimal computational overhead. Our approach establishes a
flexible, unsupervised blueprint for combating conceptual biases, paving the
way for more reliable and fair language understanding systems.

</details>


### [145] [Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in LLMs with Action Graphs](https://arxiv.org/abs/2509.04802)
*Ilham Wicaksono,Zekun Wu,Theo King,Adriano Koshiyama,Philip Treleaven*

Main category: cs.CL

TL;DR: 本文介绍了AgentSeer，一个基于可观察性的评估框架，用于评估大型语言模型向智能体系统转型时面临的部署特定风险。研究发现，智能体层面的漏洞与模型层面存在显著差异，并揭示了“仅智能体”漏洞，尤其是在工具调用和智能体转移操作中，凸显了对智能体情境评估的迫切需求。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型向智能体系统过渡，现有的安全评估框架在评估部署特定风险方面存在严重不足，无法有效捕捉智能体特有的漏洞。

Method: 引入了AgentSeer框架，该框架基于可观察性，将智能体执行分解为细粒度的动作和组件图，以实现系统的智能体情境评估。通过对GPT-OSS-20B和Gemini-2.0-flash进行跨模型验证，并使用HarmBench单轮和迭代细化攻击来评估漏洞。

Result: 研究发现模型层面和智能体层面的漏洞特征存在根本差异。模型层面评估显示GPT-OSS-20B的ASR为39.47%，Gemini-2.0-flash为50.00%，两者都易受社会工程攻击但对基于逻辑的攻击具有抵抗力。然而，智能体层面评估揭示了传统评估无法发现的“仅智能体”漏洞，其中工具调用使两种模型的ASR提高了24-60%。跨模型分析揭示了普遍的智能体模式：智能体转移操作是风险最高的工具，漏洞机制是语义而非语法，攻击效果依赖于上下文。直接从模型层面到智能体层面的攻击效果下降（GPT-OSS-20B：57%，Gemini-2.0-flash：28%），而上下文感知的迭代攻击成功攻破了模型层面失败的目标。

Conclusion: 这些发现确立了对智能体情境评估范式的迫切需求，AgentSeer提供了标准化的方法论和实证验证，以解决这一关键评估空白。

Abstract: As large language models transition to agentic systems, current safety
evaluation frameworks face critical gaps in assessing deployment-specific
risks. We introduce AgentSeer, an observability-based evaluation framework that
decomposes agentic executions into granular action and component graphs,
enabling systematic agentic-situational assessment. Through cross-model
validation on GPT-OSS-20B and Gemini-2.0-flash using HarmBench single turn and
iterative refinement attacks, we demonstrate fundamental differences between
model-level and agentic-level vulnerability profiles. Model-level evaluation
reveals baseline differences: GPT-OSS-20B (39.47% ASR) versus Gemini-2.0-flash
(50.00% ASR), with both models showing susceptibility to social engineering
while maintaining logic-based attack resistance. However, agentic-level
assessment exposes agent-specific risks invisible to traditional evaluation. We
discover "agentic-only" vulnerabilities that emerge exclusively in agentic
contexts, with tool-calling showing 24-60% higher ASR across both models.
Cross-model analysis reveals universal agentic patterns, agent transfer
operations as highest-risk tools, semantic rather than syntactic vulnerability
mechanisms, and context-dependent attack effectiveness, alongside
model-specific security profiles in absolute ASR levels and optimal injection
strategies. Direct attack transfer from model-level to agentic contexts shows
degraded performance (GPT-OSS-20B: 57% human injection ASR; Gemini-2.0-flash:
28%), while context-aware iterative attacks successfully compromise objectives
that failed at model-level, confirming systematic evaluation gaps. These
findings establish the urgent need for agentic-situation evaluation paradigms,
with AgentSeer providing the standardized methodology and empirical validation.

</details>


### [146] [Analyzing Finnish Inflectional Classes through Discriminative Lexicon and Deep Learning Models](https://arxiv.org/abs/2509.04813)
*Alexandre Nikolaev,Yu-Ying Chuang,R. Harald Baayen*

Main category: cs.CL

TL;DR: 本研究探讨了判别词汇模型（DLM）在没有明确设置屈折类的情况下，能否理解和生成芬兰语屈折名词，并发现其性能与屈折类的生产力及词频相关。


<details>
  <summary>Details</summary>
Motivation: 屈折类在语言教学和形态学系统中很有用，但尚不清楚它们是否具有认知真实性，即母语者是否需要发现这些类别才能正确学习名词变格。

Method: 使用判别词汇模型（DLM），数据集包含来自49个屈折类的2000个高频芬兰语名词的55,271个屈折形式。设置了多种DLM理解和生成模型，包括未考虑词频的模型（无限暴露学习）和考虑词频的模型（基于使用频率的学习）。

Result: 模型在训练数据上表现出高准确性，在测试数据上准确性有所下降但仍可接受。在大多数模型中，对于类型更多、低频词更多、单现词更多的屈折类，性能有所提高，这反映了屈折类的生产力。模型在非生产性和生产力较低的类别的新颖形式上表现较差，但在生产性类别中表现更好。然而，对于基于使用的生成模型，词频是模型性能的主要预测因子，与生产力指标的相关性微弱或缺失。

Conclusion: DLM无需明确的屈折类即可理解和生成芬兰语屈折名词，这表明屈折类可能不具备认知真实性。在基于使用的学习中，词频是影响模型性能的关键因素。

Abstract: Descriptions of complex nominal or verbal systems make use of inflectional
classes. Inflectional classes bring together nouns which have similar stem
changes and use similar exponents in their paradigms. Although inflectional
classes can be very useful for language teaching as well as for setting up
finite state morphological systems, it is unclear whether inflectional classes
are cognitively real, in the sense that native speakers would need to discover
these classes in order to learn how to properly inflect the nouns of their
language. This study investigates whether the Discriminative Lexicon Model
(DLM) can understand and produce Finnish inflected nouns without setting up
inflectional classes, using a dataset with 55,271 inflected nouns of 2000
high-frequency Finnish nouns from 49 inflectional classes. Several DLM
comprehension and production models were set up. Some models were not informed
about frequency of use, and provide insight into learnability with infinite
exposure (endstate learning). Other models were set up from a usage based
perspective, and were trained with token frequencies being taken into
consideration (frequency-informed learning). On training data, models performed
with very high accuracies. For held-out test data, accuracies decreased, as
expected, but remained acceptable. Across most models, performance increased
for inflectional classes with more types, more lower-frequency words, and more
hapax legomena, mirroring the productivity of the inflectional classes. The
model struggles more with novel forms of unproductive and less productive
classes, and performs far better for unseen forms belonging to productive
classes. However, for usage-based production models, frequency was the dominant
predictor of model performance, and correlations with measures of productivity
were tenuous or absent.

</details>


### [147] [Crosscoding Through Time: Tracking Emergence & Consolidation Of Linguistic Representations Throughout LLM Pretraining](https://arxiv.org/abs/2509.05291)
*Deniz Bayazit,Aaron Mueller,Antoine Bosselut*

Main category: cs.CL

TL;DR: 本文提出使用稀疏跨编码器和相对间接效应（RelIE）指标，在预训练过程中跟踪大型语言模型（LLMs）中语言特征的出现、维持和消失，以更深入地理解概念层面能力的习得。


<details>
  <summary>Details</summary>
Motivation: 传统的评估方法无法揭示LLMs何时以及如何获取语言概念和能力，因此需要弥合这一差距，从概念层面更好地理解模型训练过程。

Method: 研究采用稀疏跨编码器在模型检查点之间发现并对齐特征，以追踪预训练期间语言特征的演变。通过在具有显著性能和表示变化的开源检查点三元组之间训练跨编码器，并引入一种新颖的指标——相对间接效应（RelIE），来追踪单个特征何时对任务性能变得因果重要。

Result: 研究表明，跨编码器能够检测预训练期间特征的出现、维持和消失。该方法与模型架构无关且具有可扩展性。

Conclusion: 该方法为在预训练过程中对表示学习进行更具解释性和细粒度的分析提供了一条有前景的途径。

Abstract: Large language models (LLMs) learn non-trivial abstractions during
pretraining, like detecting irregular plural noun subjects. However, it is not
well understood when and how specific linguistic abilities emerge as
traditional evaluation methods such as benchmarking fail to reveal how models
acquire concepts and capabilities. To bridge this gap and better understand
model training at the concept level, we use sparse crosscoders to discover and
align features across model checkpoints. Using this approach, we track the
evolution of linguistic features during pretraining. We train crosscoders
between open-sourced checkpoint triplets with significant performance and
representation shifts, and introduce a novel metric, Relative Indirect Effects
(RelIE), to trace training stages at which individual features become causally
important for task performance. We show that crosscoders can detect feature
emergence, maintenance, and discontinuation during pretraining. Our approach is
architecture-agnostic and scalable, offering a promising path toward more
interpretable and fine-grained analysis of representation learning throughout
pretraining.

</details>


### [148] [AFD-SLU: Adaptive Feature Distillation for Spoken Language Understanding](https://arxiv.org/abs/2509.04821)
*Yan Xie,Yibo Cui,Liang Xie,Erwei Yin*

Main category: cs.CL

TL;DR: 本文提出了一种自适应特征蒸馏框架（AFD-SLU），通过将基于通用文本嵌入（GTE）的教师模型的丰富语义表示转移到轻量级学生模型，以解决口语理解（SLU）中数据稀缺和大型语言模型（LLM）部署计算负担的问题，并在中文ProSLU基准上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 开发有效的口语理解（SLU）系统面临两大挑战：标记训练数据稀缺和大型语言模型（LLM）在实际应用中部署的计算负担。

Method: 本文提出了一个自适应特征蒸馏（Adaptive Feature Distillation）框架。该方法引入了一个配备残差投影神经网络（RPNN）的动态适配器来对齐异构特征空间，并使用一个动态蒸馏系数（DDC），根据意图和槽位预测性能的实时反馈自适应地调整蒸馏强度。

Result: 在中文基于配置文件的ProSLU基准测试中，AFD-SLU框架取得了最先进的结果，包括95.67%的意图准确率、92.02%的槽位F1分数和85.50%的整体准确率。

Conclusion: 该框架通过自适应特征蒸馏，成功将大型教师模型的语义知识有效迁移至轻量级学生模型，显著提升了SLU系统的性能，同时缓解了数据和计算资源限制，实现了口语理解任务的最新技术水平。

Abstract: Spoken Language Understanding (SLU) is a core component of conversational
systems, enabling machines to interpret user utterances. Despite its
importance, developing effective SLU systems remains challenging due to the
scarcity of labeled training data and the computational burden of deploying
Large Language Models (LLMs) in real-world applications. To further alleviate
these issues, we propose an Adaptive Feature Distillation framework that
transfers rich semantic representations from a General Text Embeddings
(GTE)-based teacher model to a lightweight student model. Our method introduces
a dynamic adapter equipped with a Residual Projection Neural Network (RPNN) to
align heterogeneous feature spaces, and a Dynamic Distillation Coefficient
(DDC) that adaptively modulates the distillation strength based on real-time
feedback from intent and slot prediction performance. Experiments on the
Chinese profile-based ProSLU benchmark demonstrate that AFD-SLU achieves
state-of-the-art results, with 95.67% intent accuracy, 92.02% slot F1 score,
and 85.50% overall accuracy.

</details>


### [149] [Memorization $\neq$ Understanding: Do Large Language Models Have the Ability of Scenario Cognition?](https://arxiv.org/abs/2509.04866)
*Boxiang Ma,Ru Li,Yuanlong Wang,Hongye Tan,Xiaoli Li*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLM）的场景认知能力，发现LLM主要依赖表面记忆，而非深层语义理解，揭示了其语义理解的关键局限。


<details>
  <summary>Details</summary>
Motivation: 探究LLM的泛化能力是源于对训练数据的简单记忆，还是深层语义理解。

Method: 提出了一个双视角评估框架来评估LLM的场景认知能力。构建了一个包含虚构事实文本描述及场景元素标注的场景数据集。通过LLM回答场景相关问题的能力（模型输出视角）和探测其内部表示中编码的场景元素-论元关联（内部表示视角）进行评估。

Result: 实验表明，当前的LLM主要依赖表面记忆，即使在简单情况下也未能实现稳健的语义场景认知。

Conclusion: 这些发现揭示了LLM在语义理解方面的关键局限性，并为提升其能力提供了认知见解。

Abstract: Driven by vast and diverse textual data, large language models (LLMs) have
demonstrated impressive performance across numerous natural language processing
(NLP) tasks. Yet, a critical question persists: does their generalization arise
from mere memorization of training data or from deep semantic understanding? To
investigate this, we propose a bi-perspective evaluation framework to assess
LLMs' scenario cognition - the ability to link semantic scenario elements with
their arguments in context. Specifically, we introduce a novel scenario-based
dataset comprising diverse textual descriptions of fictional facts, annotated
with scenario elements. LLMs are evaluated through their capacity to answer
scenario-related questions (model output perspective) and via probing their
internal representations for encoded scenario elements-argument associations
(internal representation perspective). Our experiments reveal that current LLMs
predominantly rely on superficial memorization, failing to achieve robust
semantic scenario cognition, even in simple cases. These findings expose
critical limitations in LLMs' semantic understanding and offer cognitive
insights for advancing their capabilities.

</details>


### [150] [Using LLMs for Multilingual Clinical Entity Linking to ICD-10](https://arxiv.org/abs/2509.04868)
*Sylvia Vassileva,Ivan Koychev,Svetla Boytcheva*

Main category: cs.CL

TL;DR: 本文提出了一种利用大型语言模型（LLMs），特别是GPT-4.1，通过多阶段流程将临床术语链接到多语言ICD-10代码的方法，旨在自动化疾病分类。


<details>
  <summary>Details</summary>
Motivation: 将临床实体链接到ICD-10代码对于从临床文本中提取结构化信息至关重要。自动分配正确的ICD-10代码可以简化医护人员的工作，并确保医院编码的一致性。

Method: 该方法采用多阶段流水线：首先使用临床词典匹配文本中明确的术语；然后，对于未匹配词典的术语，利用GPT-4.1进行情境学习（in-context learning）来预测ICD-10代码。该方法支持不同语言。

Result: 该系统在不同基准数据集上显示出有希望的结果：在西班牙语CodiEsp数据集上，类别F1分数为0.89，子类别F1分数为0.78；在希腊语ElCardioCC数据集上，F1分数为0.85。

Conclusion: 所提出的基于LLM的方法能够有效且有前景地将多语言临床术语链接到ICD-10代码，有助于自动化疾病分类工作。

Abstract: The linking of clinical entities is a crucial part of extracting structured
information from clinical texts. It is the process of assigning a code from a
medical ontology or classification to a phrase in the text. The International
Classification of Diseases - 10th revision (ICD-10) is an international
standard for classifying diseases for statistical and insurance purposes.
Automatically assigning the correct ICD-10 code to terms in discharge summaries
will simplify the work of healthcare professionals and ensure consistent coding
in hospitals. Our paper proposes an approach for linking clinical terms to
ICD-10 codes in different languages using Large Language Models (LLMs). The
approach consists of a multistage pipeline that uses clinical dictionaries to
match unambiguous terms in the text and then applies in-context learning with
GPT-4.1 to predict the ICD-10 code for the terms that do not match the
dictionary. Our system shows promising results in predicting ICD-10 codes on
different benchmark datasets in Spanish - 0.89 F1 for categories and 0.78 F1 on
subcategories on CodiEsp, and Greek - 0.85 F1 on ElCardioCC.

</details>


### [151] [PRIM: Towards Practical In-Image Multilingual Machine Translation](https://arxiv.org/abs/2509.05146)
*Yanzhi Tian,Zeming Liu,Zhengyang Liu,Chong Feng,Xin Li,Heyan Huang,Yuhang Guo*

Main category: cs.CL

TL;DR: 该研究关注实际图像内多语言机器翻译（IIMMT），解决了现有研究主要基于合成数据的局限性。为此，作者构建了真实世界图像数据集PRIM，并提出了端到端模型VisTrans，在翻译质量和视觉效果上均优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 当前的图像内机器翻译（IIMT）研究主要依赖于具有简单背景、单一字体、固定文本位置和双语翻译的合成数据，这与真实世界的复杂场景存在显著差距，导致研究成果难以应用于实际条件。为了推动IIMT在真实世界场景中的研究，需要解决数据不足和模型适应性问题。

Method: 为了弥补公开数据不足，作者标注了PRIM数据集，该数据集包含真实世界捕获的单行文本图像，具有复杂背景、多样字体、不同文本位置，并支持多语言翻译方向。作者提出了一种名为VisTrans的端到端模型，用于处理PRIM数据集中的实际挑战。VisTrans模型将图像中的视觉文本和背景信息分开处理，旨在确保多语言翻译能力的同时，提高视觉质量。

Result: 实验结果表明，与现有其他模型相比，VisTrans在翻译质量和视觉效果方面均取得了更好的表现。

Conclusion: 该研究通过构建真实世界的PRIM数据集和提出VisTrans模型，有效推动了实际图像内多语言机器翻译（IIMMT）的研究，并证明了其方法在复杂真实场景下的有效性和优越性。

Abstract: In-Image Machine Translation (IIMT) aims to translate images containing texts
from one language to another. Current research of end-to-end IIMT mainly
conducts on synthetic data, with simple background, single font, fixed text
position, and bilingual translation, which can not fully reflect real world,
causing a significant gap between the research and practical conditions. To
facilitate research of IIMT in real-world scenarios, we explore Practical
In-Image Multilingual Machine Translation (IIMMT). In order to convince the
lack of publicly available data, we annotate the PRIM dataset, which contains
real-world captured one-line text images with complex background, various
fonts, diverse text positions, and supports multilingual translation
directions. We propose an end-to-end model VisTrans to handle the challenge of
practical conditions in PRIM, which processes visual text and background
information in the image separately, ensuring the capability of multilingual
translation while improving the visual quality. Experimental results indicate
the VisTrans achieves a better translation quality and visual effect compared
to other models. The code and dataset are available at:
https://github.com/BITHLP/PRIM.

</details>


### [152] [L1RA: Dynamic Rank Assignment in LoRA Fine-Tuning](https://arxiv.org/abs/2509.04884)
*Raul Singh,Nicolo Brunello,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: L1RA是一种新颖的技术，通过L1正则化动态分配LoRA微调中的低秩适配器秩，从而优化资源利用并提高LLM微调的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在复杂任务中表现出色，但其微调计算成本高昂，尤其是在资源受限的情况下，这构成了重大挑战。

Method: L1RA在LoRA微调过程中引入L1正则化，根据给定的秩预算，动态修剪冗余秩并将其重新分配给不同的适配器，以优化资源利用。它通过实验与现有LoRA变体进行比较。

Result: L1RA在保持与传统LoRA变体相当或更低的计算开销的同时，实现了相同或更好的性能。此外，训练后分析揭示了前馈层和注意力输出投影是模型中最需要适应以匹配任务目标的组件。

Conclusion: L1RA是一种很有前景的技术，不仅能提高LLM微调的效率，还能提供有价值的诊断信息，有助于模型优化和定制，特别适用于计算资源受限的场景，从而提升LLM适应的性能和可解释性。

Abstract: The ability of Large Language Models (LLMs) to solve complex tasks has made
them crucial in the development of AI-based applications. However, the high
computational requirements to fine-tune these LLMs on downstream tasks pose
significant challenges, particularly when resources are limited. In response to
this challenge, we introduce L1RA, a novel technique aimed at dynamically
distributing the rank of low-rank adapters during fine-tuning using LoRA. Given
a rank budget (i.e., total sum of adapters rank), L1RA leverages L1
regularisation to prune redundant ranks and redistribute them across adapters,
thereby optimising resource utilisation. Through a series of comprehensive
experiments, we empirically demonstrate that L1RA maintains comparable or even
reduced computational overhead compared to other LoRA variants, including the
vanilla approach, while achieving same or better performances. Moreover, the
post-training analysis of rank distribution unveiled insights into the specific
model components requiring the most adaptation to align with the task
objective: the feed-forward layers and the attention output projection. These
results highlight the efficacy of L1RA in not only enhancing the efficiency of
LLM fine-tuning, but also in providing valuable diagnostic information for
model refinement and customisation. In conclusion, L1RA stands as a promising
technique for advancing the performance and interpretability of LLM adaptation,
particularly in scenarios where computational resources are constrained.

</details>


### [153] [ACE-RL: Adaptive Constraint-Enhanced Reward for Long-form Generation Reinforcement Learning](https://arxiv.org/abs/2509.04903)
*Jianghao Chen,Wei Sun,Qixiang Yin,Lingxing Kong,Zhixing Tan,Jiajun Zhang*

Main category: cs.CL

TL;DR: 本文提出了ACE-RL框架，通过自适应约束增强奖励机制，解决了大型语言模型在长文本生成中对稀缺数据和粗粒度质量优化的依赖问题，显著提升了长文本生成质量，并超越了现有基线和GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在高质量长文本生成方面面临挑战，主要原因有二：1) 过度依赖稀缺的高质量长文本响应数据进行监督微调（SFT）或强化学习（RL）中的偏好奖励；2) 关注于粗粒度的质量优化维度（如相关性、连贯性、有用性），而忽略了多样化长文本生成场景中固有的细粒度具体要求。

Method: 本文提出了一个名为ACE-RL（Adaptive Constraint-Enhanced reward for long-form generation Reinforcement Learning）的框架。该框架首先通过识别指令的潜在意图和需求，自动将其解构为一系列细粒度、自适应的约束条件；其次，设计了一个奖励机制，通过量化长文本响应对相应约束的满足程度来评估其质量，将主观质量评估转化为约束验证；最后，利用强化学习来引导模型获得卓越的长文本生成能力。

Result: 实验结果表明，ACE-RL框架在WritingBench上显著优于现有的SFT和RL基线，分别提高了20.70%和7.32%。表现最佳的模型甚至超越了专有系统GPT-4o 7.10%。

Conclusion: ACE-RL框架为大型语言模型在多样化长文本生成场景中生成高质量内容提供了一种更有效的训练范式。

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
long-context understanding, yet they face significant challenges in
high-quality long-form generation. Existing studies primarily suffer from two
limitations: (1) A heavy reliance on scarce, high-quality long-form response
data for supervised fine-tuning (SFT) or for pairwise preference reward in
reinforcement learning (RL). (2) Focus on coarse-grained quality optimization
dimensions, such as relevance, coherence, and helpfulness, overlooking the
fine-grained specifics inherent to diverse long-form generation scenarios. To
address this issue, we propose a framework using Adaptive Constraint-Enhanced
reward for long-form generation Reinforcement Learning (ACE-RL). ACE-RL first
automatically deconstructs each instruction into a set of fine-grained,
adaptive constraint criteria by identifying its underlying intents and demands.
Subsequently, we design a reward mechanism that quantifies the quality of
long-form responses based on their satisfaction over corresponding constraints,
converting subjective quality evaluation into constraint verification. Finally,
we utilize reinforcement learning to guide models toward superior long-form
generation capabilities. Experimental results demonstrate that our ACE-RL
framework significantly outperforms existing SFT and RL baselines by 20.70% and
7.32% on WritingBench, and our top-performing model even surpasses proprietary
systems like GPT-4o by 7.10%, providing a more effective training paradigm for
LLMs to generate high-quality content across diverse long-form generation
scenarios.

</details>


### [154] [Classification of kinetic-related injury in hospital triage data using NLP](https://arxiv.org/abs/2509.04969)
*Midhun Shyam,Jim Basilakis,Kieran Luken,Steven Thomas,John Crozier,Paul M. Middleton,X. Rosalind Wang*

Main category: cs.CL

TL;DR: 本文提出了一种使用有限计算资源对急诊分诊笔记进行分类的流水线，通过两阶段微调预训练大型语言模型实现。


<details>
  <summary>Details</summary>
Motivation: 分析急诊分诊数据面临多重挑战：数据隐私限制必须现场分析；多数医院缺乏微调甚至训练大型语言模型所需的硬件；识别感兴趣的记录需要耗时且昂贵的人工标注。

Method: 该方法包括一个两阶段的微调流水线：首先，在一个GPU上使用一个小型（2k）开源数据集对预训练的大型语言模型及其分类器进行微调；然后，在一个CPU上使用1000个医院特定样本对模型进行进一步微调。关键在于精心策划数据集并利用现有模型和开源数据。

Result: 研究表明，通过精心策划数据集并利用现有模型和开源数据，可以在有限的计算资源下成功对分诊数据进行分类。

Conclusion: 通过仔细的数据管理和利用现有模型及开源数据，即使计算资源有限，也能有效地对急诊分诊数据进行分类。

Abstract: Triage notes, created at the start of a patient's hospital visit, contain a
wealth of information that can help medical staff and researchers understand
Emergency Department patient epidemiology and the degree of time-dependent
illness or injury. Unfortunately, applying modern Natural Language Processing
and Machine Learning techniques to analyse triage data faces some challenges:
Firstly, hospital data contains highly sensitive information that is subject to
privacy regulation thus need to be analysed on site; Secondly, most hospitals
and medical facilities lack the necessary hardware to fine-tune a Large
Language Model (LLM), much less training one from scratch; Lastly, to identify
the records of interest, expert inputs are needed to manually label the
datasets, which can be time-consuming and costly. We present in this paper a
pipeline that enables the classification of triage data using LLM and limited
compute resources. We first fine-tuned a pre-trained LLM with a classifier
using a small (2k) open sourced dataset on a GPU; and then further fine-tuned
the model with a hospital specific dataset of 1000 samples on a CPU. We
demonstrated that by carefully curating the datasets and leveraging existing
models and open sourced data, we can successfully classify triage data with
limited compute resources.

</details>


### [155] [Optimizing Small Transformer-Based Language Models for Multi-Label Sentiment Analysis in Short Texts](https://arxiv.org/abs/2509.04982)
*Julius Neumann,Robert Lange,Yuni Susanti,Michael Färber*

Main category: cs.CL

TL;DR: 本文评估了小型Transformer模型（BERT、RoBERTa）在短文本多标签情感分类中的表现，重点关注了领域特定预训练、数据增强和分类头架构，发现数据增强有效，而预训练可能引入噪声。


<details>
  <summary>Details</summary>
Motivation: 短文本情感分类面临诸多挑战，包括类别不平衡、训练样本有限、情感标签主观性以及上下文有限导致的歧义和数据稀疏性，这些因素阻碍了有效的学习。

Method: 研究评估了小于10亿参数的小型Transformer模型（BERT和RoBERTa）在短文本多标签情感分类中的有效性。具体考察了三个关键影响因素：1) 持续的领域特定预训练，2) 使用自动生成示例（生成式数据增强）进行数据增强，3) 分类头架构的变体。

Result: 实验结果表明，数据增强能提高分类性能；然而，在增强数据集上进行持续预训练反而可能引入噪声，而非提升准确性。此外，对分类头进行修改仅带来微小的收益。

Conclusion: 研究结果为在资源受限环境下优化基于BERT的模型以及改进短文本数据集的情感分类策略提供了实用指导。

Abstract: Sentiment classification in short text datasets faces significant challenges
such as class imbalance, limited training samples, and the inherent
subjectivity of sentiment labels -- issues that are further intensified by the
limited context in short texts. These factors make it difficult to resolve
ambiguity and exacerbate data sparsity, hindering effective learning. In this
paper, we evaluate the effectiveness of small Transformer-based models (i.e.,
BERT and RoBERTa, with fewer than 1 billion parameters) for multi-label
sentiment classification, with a particular focus on short-text settings.
Specifically, we evaluated three key factors influencing model performance: (1)
continued domain-specific pre-training, (2) data augmentation using
automatically generated examples, specifically generative data augmentation,
and (3) architectural variations of the classification head. Our experiment
results show that data augmentation improves classification performance, while
continued pre-training on augmented datasets can introduce noise rather than
boost accuracy. Furthermore, we confirm that modifications to the
classification head yield only marginal benefits. These findings provide
practical guidance for optimizing BERT-based models in resource-constrained
settings and refining strategies for sentiment classification in short-text
datasets.

</details>


### [156] [Do Large Language Models Need Intent? Revisiting Response Generation Strategies for Service Assistant](https://arxiv.org/abs/2509.05006)
*Inbal Bolshinsky,Shani Kupiec,Almog Sasson,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CL

TL;DR: 本文比较了两种服务响应生成范式：先识别意图再生成响应（Intent-First）和直接生成响应（Direct Response Generation），以探究显式意图识别是否为高质量响应的必要条件。


<details>
  <summary>Details</summary>
Motivation: 在对话式AI中，生成准确且符合上下文的服务响应是一个关键挑战。核心问题是：显式意图识别是否是生成高质量服务响应的先决条件，或者模型能否跳过此步骤直接生成有效回复？

Method: 本文进行了一项严格的比较研究，利用两个公开的服务交互数据集，在“意图优先响应生成”和“直接响应生成”两种范式下，对包括微调T5变体在内的多个最先进语言模型进行了基准测试。评估指标涵盖语言质量和任务成功率。

Result: 评估结果揭示了关于显式意图建模必要性或冗余性的出人意料的见解，挑战了对话式AI管道中的传统假设。

Conclusion: 研究结果为设计更高效、更有效的响应生成系统提供了可操作的指导方针。

Abstract: In the era of conversational AI, generating accurate and contextually
appropriate service responses remains a critical challenge. A central question
remains: Is explicit intent recognition a prerequisite for generating
high-quality service responses, or can models bypass this step and produce
effective replies directly? This paper conducts a rigorous comparative study to
address this fundamental design dilemma. Leveraging two publicly available
service interaction datasets, we benchmark several state-of-the-art language
models, including a fine-tuned T5 variant, across both paradigms: Intent-First
Response Generation and Direct Response Generation. Evaluation metrics
encompass both linguistic quality and task success rates, revealing surprising
insights into the necessity or redundancy of explicit intent modelling. Our
findings challenge conventional assumptions in conversational AI pipelines,
offering actionable guidelines for designing more efficient and effective
response generation systems.

</details>


### [157] [Masked Diffusion Language Models with Frequency-Informed Training](https://arxiv.org/abs/2509.05056)
*Despoina Kosmopoulou,Efthymios Georgiou,Vaggelis Dorovatas,Georgios Paraskevopoulos,Alexandros Potamianos*

Main category: cs.CL

TL;DR: 本文提出了一种掩码扩散语言建模框架，用于在数据受限条件下进行高效训练，并在BabyLM 2025挑战赛中表现出与混合自回归-掩码基线相当的竞争力。


<details>
  <summary>Details</summary>
Motivation: 在严格的数据限制下（如BabyLM 2025挑战赛），实现数据高效的语言模型训练。

Method: 该方法应用扩散训练目标于语言建模，并结合了频率感知掩码（优先学习稀有词元）。研究探索了多种噪声调度策略（包括双模方法）以及NELBO目标内的不同噪声加权方案。

Result: 在BabyLM基准测试套件（衡量语言能力、世界知识和类人性）上的评估结果显示，该方法的性能与混合自回归-掩码基线相当。

Conclusion: 扩散式训练为数据受限的语言学习提供了一种可行的替代方案。

Abstract: We present a masked diffusion language modeling framework for data-efficient
training for the BabyLM 2025 Challenge. Our approach applies diffusion training
objectives to language modeling under strict data constraints, incorporating
frequency-informed masking that prioritizes learning from rare tokens while
maintaining theoretical validity. We explore multiple noise scheduling
strategies, including two-mode approaches, and investigate different noise
weighting schemes within the NELBO objective. We evaluate our method on the
BabyLM benchmark suite, measuring linguistic competence, world knowledge, and
human-likeness. Results show performance competitive to hybrid
autoregressive-masked baselines, demonstrating that diffusion-based training
offers a viable alternative for data-restricted language learning.

</details>


### [158] [Entropy2Vec: Crosslingual Language Modeling Entropy as End-to-End Learnable Language Representations](https://arxiv.org/abs/2509.05060)
*Patrick Amadeus Irawan,Ryandito Diandaru,Belati Jagad Bintang Syuhada,Randy Zakya Suchrady,Alham Fikri Aji,Genta Indra Winata,Fajri Koto,Samuel Cahyawijaya*

Main category: cs.CL

TL;DR: Entropy2Vec是一个新颖的跨语言表征框架，它利用单语语言模型的熵来捕捉语言间的类型学关系，克服了传统方法稀疏性和静态性的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的类型学清单存在特征稀疏性和静态快照的问题，无法充分捕捉语言间的类型学关系。

Method: 该方法通过训练单语语言模型，并利用其预测的熵来反映语言间的结构相似性（熵低表示相似度高，熵高表示差异大）。这产生了密集、非稀疏、可适应且无缺失值的语言嵌入。

Result: 经验评估表明，Entropy2Vec嵌入与既定的类型学类别保持一致，并在下游多语言NLP任务（例如LinguAlchemy框架）中取得了具有竞争力的性能。

Conclusion: Entropy2Vec通过利用语言模型的内在不确定性，提供了一种有效且创新的方法来推导跨语言表征，成功捕捉了语言间的类型学关系，并克服了传统方法的局限性。

Abstract: We introduce Entropy2Vec, a novel framework for deriving cross-lingual
language representations by leveraging the entropy of monolingual language
models. Unlike traditional typological inventories that suffer from feature
sparsity and static snapshots, Entropy2Vec uses the inherent uncertainty in
language models to capture typological relationships between languages. By
training a language model on a single language, we hypothesize that the entropy
of its predictions reflects its structural similarity to other languages: Low
entropy indicates high similarity, while high entropy suggests greater
divergence. This approach yields dense, non-sparse language embeddings that are
adaptable to different timeframes and free from missing values. Empirical
evaluations demonstrate that Entropy2Vec embeddings align with established
typological categories and achieved competitive performance in downstream
multilingual NLP tasks, such as those addressed by the LinguAlchemy framework.

</details>


### [159] [Triadic Fusion of Cognitive, Functional, and Causal Dimensions for Explainable LLMs: The TAXAL Framework](https://arxiv.org/abs/2509.05199)
*David Herrera-Poyatos,Carlos Peláez-González,Cristina Zuheros,Virilo Tejedor,Rosana Montes,Francisco Herrera*

Main category: cs.CL

TL;DR: 本文提出了TAXAL（代理型大型语言模型可解释性三元对齐）框架，通过融合认知、功能和因果三个维度，为代理型LLM在不同社会技术环境中的可解释性设计、评估和部署提供了统一且角色敏感的基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）正被部署在高风险领域，但其不透明性、偏见和不稳定性损害了信任和问责制。传统的解释方法仅关注表面输出，无法捕捉代理型LLMs的推理路径、规划逻辑和系统性影响，因此需要更全面的可解释性解决方案。

Method: 本文引入了TAXAL框架，这是一个三元融合框架，结合了认知（用户理解）、功能（实际效用）和因果（忠实推理）三个互补维度。该方法通过综合现有方法（包括事后归因、对话界面和解释感知提示），并将其置于TAXAL模型中，并通过法律、教育、医疗和公共服务领域的案例研究来展示其适用性。

Result: TAXAL框架为在多样化社会技术环境中设计、评估和部署解释提供了一个统一且角色敏感的基础。它成功地综合了现有解释方法，并通过案例研究展示了解释策略如何适应制度约束和利益相关者角色。

Conclusion: 通过结合概念清晰性、设计模式和部署路径，TAXAL将可解释性提升为一种技术和社会技术实践，从而在代理型AI时代支持可信赖和情境敏感的LLM应用。

Abstract: Large Language Models (LLMs) are increasingly being deployed in high-risk
domains where opacity, bias, and instability undermine trust and
accountability. Traditional explainability methods, focused on surface outputs,
do not capture the reasoning pathways, planning logic, and systemic impacts of
agentic LLMs.
  We introduce TAXAL (Triadic Alignment for eXplainability in Agentic LLMs), a
triadic fusion framework that unites three complementary dimensions: cognitive
(user understanding), functional (practical utility), and causal (faithful
reasoning). TAXAL provides a unified, role-sensitive foundation for designing,
evaluating, and deploying explanations in diverse sociotechnical settings.
  Our analysis synthesizes existing methods, ranging from post-hoc attribution
and dialogic interfaces to explanation-aware prompting, and situates them
within the TAXAL triadic fusion model. We further demonstrate its applicability
through case studies in law, education, healthcare, and public services,
showing how explanation strategies adapt to institutional constraints and
stakeholder roles.
  By combining conceptual clarity with design patterns and deployment pathways,
TAXAL advances explainability as a technical and sociotechnical practice,
supporting trustworthy and context-sensitive LLM applications in the era of
agentic AI.

</details>


### [160] [Hunyuan-MT Technical Report](https://arxiv.org/abs/2509.05209)
*Mao Zheng,Zheng Li,Bingxin Qu,Mingyang Song,Yang Du,Mingrui Sun,Di Wang*

Main category: cs.CL

TL;DR: 本文介绍了两个开源多语言翻译模型：Hunyuan-MT-7B 和 Hunyuan-MT-Chimera-7B。Hunyuan-MT-7B 支持 33 种语言的双向翻译，并特别关注普通话与少数民族语言及方言的翻译。Hunyuan-MT-Chimera-7B 采用“慢思考”模式，通过整合 Hunyuan-MT-7B 的多种输出，实现了优于传统方法的性能。这两个模型在综合实验中表现出色，超越了同等参数规模的翻译模型和大多数 SOTA 大模型，并在 WMT2025 共享任务中 31 个语对中的 30 个排名第一。


<details>
  <summary>Details</summary>
Motivation: 开发高性能的开源多语言翻译模型，特别是解决普通话与少数民族语言及方言之间的翻译需求，并通过引入“慢思考”模式来服务和解决多样化的翻译场景并提升模型在测试时的性能。

Method: 开发了 Hunyuan-MT-7B，一个支持 33 种主要语言的双向翻译模型。引入了 Hunyuan-MT-Chimera-7B，该模型受慢思考模式启发，通过整合 Hunyuan-MT-7B 在不同参数设置下生成的多个输出。模型的开发遵循一个为多语言翻译量身定制的整体训练流程，包括通用和面向机器翻译的预训练、监督微调（SFT）以及通过强化学习（RL）和弱到强 RL 进行的高级对齐。

Result: Hunyuan-MT-7B 和 Hunyuan-MT-Chimera-7B 显著优于所有同等参数规模的翻译专用模型和大多数 SOTA 大型模型，尤其是在普通话与少数民族语言及方言之间的翻译任务上。Hunyuan-MT-Chimera-7B 的性能优于基于 Chain-of-Thought (CoT) 的传统慢思考模型。在 WMT2025 共享任务（通用机器翻译）中，模型在 31 个语对中的 30 个语对中排名第一，展示了在包括高资源语言（如中文、英语、日语）和低资源语言（如捷克语、马拉地语、爱沙尼亚语、冰岛语）在内的多样化语言范围内的鲁棒性。

Conclusion: Hunyuan-MT-7B 和 Hunyuan-MT-Chimera-7B 模型在多语言机器翻译领域取得了显著进展，提供了最先进的性能，特别是在低资源语言和普通话与少数民族语言及方言之间的翻译中表现出色，并证明了所提出的慢思考集成方法和整体训练过程的有效性。

Abstract: In this report, we introduce Hunyuan-MT-7B, our first open-source
multilingual translation model, which supports bidirectional translation across
33 major languages and places a special emphasis on translation between
Mandarin and several ethnic minority languages as well as dialects.
Furthermore, to serve and address diverse translation scenarios and enhance
model performance at test time, we introduce Hunyuan-MT-Chimera-7B, a
translation model inspired by the slow thinking mode. This model integrates
multiple outputs generated by the Hunyuan-MT-7B model under varying parameter
settings, thereby achieving performance superior to that of conventional
slow-thinking models based on Chain-of-Thought (CoT). The development of our
models follows a holistic training process specifically engineered for
multilingual translation, which begins with general and MT-oriented
pre-training to build foundational capabilities, proceeds to Supervised
Fine-Tuning (SFT) for task-specific adaptation, and culminates in advanced
alignment through Reinforcement Learning (RL) and weak-to-strong RL. Through
comprehensive experimentation, we demonstrate that both Hunyuan-MT-7B and
Hunyuan-MT-Chimera-7B significantly outperform all translation-specific models
of comparable parameter size and most of the SOTA large models, particularly on
the task of translation between Mandarin and minority languages as well as
dialects. In the WMT2025 shared task (General Machine Translation), our models
demonstrate state-of-the-art performance, ranking first in 30 out of 31
language pairs. This result highlights the robustness of our models across a
diverse linguistic spectrum, encompassing high-resource languages such as
Chinese, English, and Japanese, as well as low-resource languages including
Czech, Marathi, Estonian, and Icelandic.

</details>


### [161] [BEDTime: A Unified Benchmark for Automatically Describing Time Series](https://arxiv.org/abs/2509.05215)
*Medhasweta Sen,Zachary Gottesman,Jiaxing Qiu,C. Bayan Bruss,Nam Nguyen,Tom Hartvigsen*

Main category: cs.CL

TL;DR: 本文提出了一个标准化基准，用于评估时间序列基础模型在自然语言描述任务上的能力，并统一了多个数据集以实现直接比较，发现现有模型（特别是纯语言模型）仍有显著提升空间且鲁棒性不足。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列基础模型评估存在问题：新模型常伴随新数据集，导致难以直接比较和理解不同方法的优劣；评估任务过于宽泛，未能明确指出模型具体能力对整体性能的贡献。

Method: 研究者形式化并评估了3个测试模型使用通用自然语言描述时间序列能力的任务：识别（真/假问答）、区分（多项选择问答）和生成（开放式自然语言描述）。他们统一了4个近期数据集，以实现模型在每个任务上的直接比较，并评估了13个最先进的语言、视觉-语言和时间序列-语言模型。

Result: 实验发现：1) 流行的纯语言方法表现普遍不佳，表明需要特定于时间序列的架构；2) 视觉-语言模型（VLM）表现相当成功，证实了视觉模型对这些任务的价值；3) 预训练的多模态时间序列-语言模型优于大型语言模型（LLM），但仍有显著改进空间。此外，所有方法在鲁棒性测试中都表现出明显的脆弱性。

Conclusion: 该基准为时间序列推理系统所需的任务提供了标准化评估，揭示了当前模型（尤其是纯语言模型）的局限性，并强调了多模态方法（特别是结合视觉）的潜力，但所有模型在鲁棒性方面仍需大幅提升。

Abstract: Many recent studies have proposed general-purpose foundation models designed
for a variety of time series analysis tasks. While several established datasets
already exist for evaluating these models, previous works frequently introduce
their models in conjunction with new datasets, limiting opportunities for
direct, independent comparisons and obscuring insights into the relative
strengths of different methods. Additionally, prior evaluations often cover
numerous tasks simultaneously, assessing a broad range of model abilities
without clearly pinpointing which capabilities contribute to overall
performance. To address these gaps, we formalize and evaluate 3 tasks that test
a model's ability to describe time series using generic natural language: (1)
recognition (True/False question-answering), (2) differentiation (multiple
choice question-answering), and (3) generation (open-ended natural language
description). We then unify 4 recent datasets to enable head-to-head model
comparisons on each task. Experimentally, in evaluating 13 state-of-the-art
language, vision--language, and time series--language models, we find that (1)
popular language-only methods largely underperform, indicating a need for time
series-specific architectures, (2) VLMs are quite successful, as expected,
identifying the value of vision models for these tasks and (3) pretrained
multimodal time series--language models successfully outperform LLMs, but still
have significant room for improvement. We also find that all approaches exhibit
clear fragility in a range of robustness tests. Overall, our benchmark provides
a standardized evaluation on a task necessary for time series reasoning
systems.

</details>


### [162] [Less is More Tokens: Efficient Math Reasoning via Difficulty-Aware Chain-of-Thought Distillation](https://arxiv.org/abs/2509.05226)
*Abdul Waheed,Chancharik Mitra,Laurie Z. Wang,Deva Ramanan,Bhiksha Raj*

Main category: cs.CL

TL;DR: 本文提出了一种难度感知推理框架，通过精心策划的数据进行后训练，使模型能够根据问题复杂性动态调整思维链的推理深度，无需架构修改。


<details>
  <summary>Details</summary>
Motivation: 虽然思维链推理功能强大，但对于简单问题会产生不必要的冗长输出，因此需要一种方法使模型能够根据问题难度动态调整推理深度。

Method: 研究人员通过在精心策划的数据上进行后训练（包括与问题难度成比例的思维链痕迹），使模型具备动态推理路径。他们比较了监督微调（SFT）和直接偏好优化（DPO）及其组合的效果，发现无需任何架构修改。

Result: 分析表明，SFT主要捕捉推理长度和格式模式，DPO保持推理准确性，而两者的结合既能缩短长度又能保持或提高性能。定量和定性评估均证实，模型可以学会“按比例思考”，在简单问题上进行最少推理，同时在复杂问题上保持深度。

Conclusion: 模型能够学习难度感知推理，动态调整推理深度，在简单问题上进行简洁推理，在复杂问题上保持必要的深度，从而实现更高效和适应性的AI推理。

Abstract: Chain-of-thought reasoning, while powerful, can produce unnecessarily verbose
output for simpler problems. We present a framework for difficulty-aware
reasoning that teaches models to dynamically adjust reasoning depth based on
problem complexity. Remarkably, we show that models can be endowed with such
dynamic inference pathways without any architectural modifications; we simply
post-train on data that is carefully curated to include chain-of-thought traces
that are proportional in length to problem difficulty. Our analysis reveals
that post-training via supervised fine-tuning (SFT) primarily captures patterns
like reasoning length and format, while direct preference optimization (DPO)
preserves reasoning accuracy, with their combination reducing length and
maintaining or improving performance. Both quantitative metrics and qualitative
assessments confirm that models can learn to "think proportionally", reasoning
minimally on simple problems while maintaining depth for complex ones.

</details>


### [163] [Uniform Information Density and Syntactic Reduction: Revisiting $\textit{that}$-Mentioning in English Complement Clauses](https://arxiv.org/abs/2509.05254)
*Hailin Hao,Elsi Kaiser*

Main category: cs.CL

TL;DR: 研究发现，说话者在信息密度低时更倾向于省略补语连接词“that”，以保持信息传输的均匀性。使用上下文词嵌入能更准确地预测这种省略模式。


<details>
  <summary>Details</summary>
Motivation: 重新审视并验证信息密度（UID）假说与英语补语从句中“that”省略之间的关系，并利用先进的机器学习和神经语言模型改进信息密度估计，以克服以往测量方法的局限性。

Method: 分析一个大规模、现代的对话语料库。使用机器学习和神经语言模型（特别是上下文词嵌入）来精炼信息密度的估计。

Result: 复制了信息密度与“that”提及之间已建立的关系。发现先前基于主句动词次范畴化概率的信息密度测量捕获了显著的词汇特异性变异，而通过上下文词嵌入得出的估计则解释了补语使用模式中额外的变异。

Conclusion: 信息密度假说在“that”省略中得到支持。先进的自然语言处理技术（如上下文词嵌入）提供了更精确的信息密度测量方法，从而更好地理解补语连接词的使用模式。

Abstract: Speakers often have multiple ways to express the same meaning. The Uniform
Information Density (UID) hypothesis suggests that speakers exploit this
variability to maintain a consistent rate of information transmission during
language production. Building on prior work linking UID to syntactic reduction,
we revisit the finding that the optional complementizer $\textit{that}$in
English complement clauses is more likely to be omitted when the clause has low
information density (i.e., more predictable). We advance this line of research
by analyzing a large-scale, contemporary conversational corpus and using
machine learning and neural language models to refine estimates of information
density. Our results replicated the established relationship between
information density and $\textit{that}$-mentioning. However, we found that
previous measures of information density based on matrix verbs'
subcategorization probability capture substantial idiosyncratic lexical
variation. By contrast, estimates derived from contextual word embeddings
account for additional variance in patterns of complementizer usage.

</details>


### [164] [Elucidating the Design Space of Decay in Linear Attention](https://arxiv.org/abs/2509.05282)
*Zhen Qin,Xuyang Shen,Yiran Zhong*

Main category: cs.CL

TL;DR: 本文全面研究了线性复杂度序列模型中的衰减机制，系统地划分了其设计空间，并揭示了参数化策略、参数共享、衰减粒度以及与相对位置编码（如RoPE）兼容性方面的关键发现。


<details>
  <summary>Details</summary>
Motivation: 旨在深入理解和改进线性复杂度序列模型中固有的衰减机制，以优化其性能。

Method: 通过系统地将衰减机制的设计空间划分为四个关键维度（参数化策略、参数共享、衰减粒度、与相对位置编码的兼容性），并在各种语言建模任务上进行广泛实验。

Result: 1. 衰减的参数化策略需精细考虑，有效配置通常局限于特定参数范围。2. 参数共享不能随意使用，可能导致衰减值过大或过小，严重影响性能。3. 在相同参数化策略下，标量衰减通常不如向量衰减，但在特定替代策略下，标量衰减可能意外超越向量衰减。4. RoPE（旋转位置嵌入）通常未能为大多数线性注意力机制带来显著益处。

Conclusion: 线性复杂度序列模型中衰减机制的设计需要跨多个维度（参数化、共享、粒度）进行仔细考量。RoPE通常对线性注意力机制无明显增益。这些发现为设计更有效的线性复杂度模型提供了关键见解。

Abstract: This paper presents a comprehensive investigation into the decay mechanisms
inherent in linear complexity sequence models. We systematically delineate the
design space of decay mechanisms across four pivotal dimensions:
parameterization strategy, which refers to the computational methodology for
decay; parameter sharing, which involves the utilization of supplementary
parameters for decay computation; decay granularity, comparing scalar versus
vector-based decay; and compatibility with relative positional encoding
methods, such as Rotary Position Embedding (RoPE). Through an extensive series
of experiments conducted on diverse language modeling tasks, we uncovered
several critical insights. Firstly, the design of the parameterization strategy
for decay requires meticulous consideration. Our findings indicate that
effective configurations are typically confined to a specific range of
parameters. Secondly, parameter sharing cannot be used arbitrarily, as it may
cause decay values to be too large or too small, thereby significantly
impacting performance. Thirdly, under identical parameterization strategies,
scalar decay generally underperforms compared to its vector-based counterpart.
However, in certain scenarios with alternative parameterization strategies,
scalar decay may unexpectedly surpass vector decay in efficacy. Lastly, our
analysis reveals that RoPE, a commonly employed relative positional encoding
method, typically fails to provide tangible benefits to the majority of linear
attention mechanisms.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [165] [In-Context Policy Adaptation via Cross-Domain Skill Diffusion](https://arxiv.org/abs/2509.04535)
*Minjong Yoo,Woo Kyung Kim,Honguk Woo*

Main category: cs.RO

TL;DR: 本文提出了一个名为ICPAD的框架，用于长时程多任务环境中的上下文策略适应。该框架利用基于扩散的技能学习技术，通过跨域技能扩散和动态域提示，实现了在无模型更新和目标域数据有限的严格约束下，对跨域环境中基于技能的强化学习策略的快速适应。


<details>
  <summary>Details</summary>
Motivation: 在长时程多任务环境中，需要使基于技能的强化学习策略能够快速适应多样化的目标域，尤其是在不允许模型更新且目标域数据非常有限的严格约束下。

Method: 该框架采用以下方法：1. 跨域技能扩散方案：通过跨域一致的扩散过程，从离线数据中共同有效地学习域无关的原型技能和域基础的技能适配器。原型技能作为通用行为表示的基元，用于连接不同领域。2. 动态域提示方案：引导基于扩散的技能适配器更好地与目标域对齐，从而增强上下文适应性能。

Result: 通过在Metaworld（机器人操作）和CARLA（自动驾驶）中的实验，作者展示了ICPAD框架在目标域数据有限的条件下，对于包括环境动态、智能体形态和任务时程差异在内的各种跨域配置，实现了卓越的策略适应性能。

Conclusion: ICPAD框架通过结合跨域技能扩散和动态域提示，为长时程多任务环境中的快速、有效的上下文策略适应提供了一个强大的解决方案，特别是在数据和模型更新受限的跨域场景下表现出色。

Abstract: In this work, we present an in-context policy adaptation (ICPAD) framework
designed for long-horizon multi-task environments, exploring diffusion-based
skill learning techniques in cross-domain settings. The framework enables rapid
adaptation of skill-based reinforcement learning policies to diverse target
domains, especially under stringent constraints on no model updates and only
limited target domain data. Specifically, the framework employs a cross-domain
skill diffusion scheme, where domain-agnostic prototype skills and a
domain-grounded skill adapter are learned jointly and effectively from an
offline dataset through cross-domain consistent diffusion processes. The
prototype skills act as primitives for common behavior representations of
long-horizon policies, serving as a lingua franca to bridge different domains.
Furthermore, to enhance the in-context adaptation performance, we develop a
dynamic domain prompting scheme that guides the diffusion-based skill adapter
toward better alignment with the target domain. Through experiments with
robotic manipulation in Metaworld and autonomous driving in CARLA, we show that
our $\oursol$ framework achieves superior policy adaptation performance under
limited target domain data conditions for various cross-domain configurations
including differences in environment dynamics, agent embodiment, and task
horizon.

</details>


### [166] [Action Chunking with Transformers for Image-Based Spacecraft Guidance and Control](https://arxiv.org/abs/2509.04628)
*Alejandro Posadas-Nava,Andrea Scorsoglio,Luca Ghilardi,Roberto Furfaro,Richard Linares*

Main category: cs.RO

TL;DR: 本文提出一种基于模仿学习的航天器制导、导航与控制（GNC）方法，利用Action Chunking with Transformers (ACT)，仅用少量专家演示数据即可实现高性能，并在对接任务中展现出更高的精度、更平滑的控制和更高的样本效率，优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 在航天器GNC领域，实现高性能控制通常需要大量数据。本研究旨在开发一种能够从有限数据中学习并实现高表现的控制策略。

Method: 研究采用了一种名为Action Chunking with Transformers (ACT) 的模仿学习方法。该方法仅使用100次专家演示（相当于6,300次环境交互），学习一个将视觉和状态观测映射到推力与扭矩指令的控制策略。该方法在国际空间站（ISS）的在轨交会对接任务上进行了评估。

Result: ACT方法生成的轨迹比使用4000万次交互训练的元强化学习（meta-RL）基线更平滑、更一致。实验表明，该方法在精度、控制平滑性和样本效率方面均表现更优。

Conclusion: 基于ACT的模仿学习方法能够以极高的样本效率，从有限的专家演示中学习到高性能的航天器GNC控制策略，实现更准确、更平滑的控制，并显著优于传统强化学习基线。

Abstract: We present an imitation learning approach for spacecraft guidance,
navigation, and control(GNC) that achieves high performance from limited data.
Using only 100 expert demonstrations, equivalent to 6,300 environment
interactions, our method, which implements Action Chunking with Transformers
(ACT), learns a control policy that maps visual and state observations to
thrust and torque commands. ACT generates smoother, more consistent
trajectories than a meta-reinforcement learning (meta-RL) baseline trained with
40 million interactions. We evaluate ACT on a rendezvous task: in-orbit docking
with the International Space Station (ISS). We show that our approach achieves
greater accuracy, smoother control, and greater sample efficiency.

</details>


### [167] [Planning from Point Clouds over Continuous Actions for Multi-object Rearrangement](https://arxiv.org/abs/2509.04645)
*Kallol Saha,Amber Li,Angela Rodriguez-Izquierdo,Lifan Yu,Ben Eisner,Maxim Likhachev,David Held*

Main category: cs.RO

TL;DR: 本文提出了一种名为SPOT的混合学习与规划方法，通过在点云对象变换空间中搜索，实现了机器人长时间跨度操作的规划，无需离散化，并在仿真和真实环境中表现优于纯策略学习方法。


<details>
  <summary>Details</summary>
Motivation: 机器人长时间跨度操作规划面临巨大挑战，需要推理一系列动作对3D物理场景的影响。传统任务规划方法虽有效，但需将连续状态和动作空间离散化为符号描述。本文旨在解决无需离散化连续空间，实现有效长时间跨度操作规划的问题。

Method: 本文提出SPOT（Search over Point cloud Object Transformations）方法，它是一种混合学习与规划的方法。SPOT通过搜索从初始场景点云到满足目标点云的变换序列来规划。它利用学习到的建议器（suggesters）从部分观测的点云中采样候选动作，从而避免了离散化动作或对象关系。学习模型作为领域特定先验来指导高维连续动作空间的搜索。

Result: SPOT在多对象重新排列任务上进行了评估，报告了在仿真和真实世界环境中的任务规划成功率和任务执行成功率。实验结果表明，SPOT能够生成成功的规划，并优于纯策略学习方法。消融实验也突出了基于搜索的规划的重要性。

Conclusion: SPOT成功地通过在点云对象变换空间中搜索来解决长时间跨度机器人操作规划问题，避免了对连续状态和动作空间的离散化。该方法利用学习模型作为先验指导搜索，并在实际任务中表现出优越的规划和执行能力，证明了混合学习与规划范式的有效性。

Abstract: Long-horizon planning for robot manipulation is a challenging problem that
requires reasoning about the effects of a sequence of actions on a physical 3D
scene. While traditional task planning methods are shown to be effective for
long-horizon manipulation, they require discretizing the continuous state and
action space into symbolic descriptions of objects, object relationships, and
actions. Instead, we propose a hybrid learning-and-planning approach that
leverages learned models as domain-specific priors to guide search in
high-dimensional continuous action spaces. We introduce SPOT: Search over Point
cloud Object Transformations, which plans by searching for a sequence of
transformations from an initial scene point cloud to a goal-satisfying point
cloud. SPOT samples candidate actions from learned suggesters that operate on
partially observed point clouds, eliminating the need to discretize actions or
object relationships. We evaluate SPOT on multi-object rearrangement tasks,
reporting task planning success and task execution success in both simulation
and real-world environments. Our experiments show that SPOT generates
successful plans and outperforms a policy-learning approach. We also perform
ablations that highlight the importance of search-based planning.

</details>


### [168] [Surformer v2: A Multimodal Classifier for Surface Understanding from Touch and Vision](https://arxiv.org/abs/2509.04658)
*Manish Kansana,Sindhuja Penchala,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.RO

TL;DR: Surformer v2 是一种增强的多模态分类架构，通过决策级（晚期）融合机制整合视觉（CNN）和触觉（Transformer）传感器数据，用于机器人操作和交互中的表面材料分类，并在保持实时推理速度的同时表现良好。


<details>
  <summary>Details</summary>
Motivation: 推动机器人操作和交互中的触觉感知能力，特别是在多模态表面材料分类方面。旨在改进 Surformer v1 框架，将特征提取集成到模型中并采用晚期融合策略。

Method: Surformer v2 采用增强的多模态分类架构。视觉分支使用基于 CNN 的分类器（Efficient V-Net），触觉分支使用仅编码器 Transformer 模型。模型通过学习到的加权和组合输出对数（logits）进行决策级（晚期）融合，而不是合并特征图。与 Surformer v1 相比，Surformer v2 将特征提取过程集成到模型内部，并从手工特征提取和中级融合转向模型内学习特征提取和晚期融合。

Result: Surformer v2 在 Touch and Go 数据集上进行了评估，表现良好，并保持了有竞争力的推理速度，适用于实时机器人应用。这些发现强调了决策级融合和基于 Transformer 的触觉建模在增强多模态机器人感知中表面理解的有效性。

Conclusion: 决策级融合和基于 Transformer 的触觉建模对于增强多模态机器人感知中的表面理解是有效的，Surformer v2 证明了其在实时机器人应用中的潜力和竞争力。

Abstract: Multimodal surface material classification plays a critical role in advancing
tactile perception for robotic manipulation and interaction. In this paper, we
present Surformer v2, an enhanced multi-modal classification architecture
designed to integrate visual and tactile sensory streams through a
late(decision level) fusion mechanism. Building on our earlier Surformer v1
framework [1], which employed handcrafted feature extraction followed by
mid-level fusion architecture with multi-head cross-attention layers, Surformer
v2 integrates the feature extraction process within the model itself and shifts
to late fusion. The vision branch leverages a CNN-based classifier(Efficient
V-Net), while the tactile branch employs an encoder-only transformer model,
allowing each modality to extract modality-specific features optimized for
classification. Rather than merging feature maps, the model performs
decision-level fusion by combining the output logits using a learnable weighted
sum, enabling adaptive emphasis on each modality depending on data context and
training dynamics. We evaluate Surformer v2 on the Touch and Go dataset [2], a
multi-modal benchmark comprising surface images and corresponding tactile
sensor readings. Our results demonstrate that Surformer v2 performs well,
maintaining competitive inference speed, suitable for real-time robotic
applications. These findings underscore the effectiveness of decision-level
fusion and transformer-based tactile modeling for enhancing surface
understanding in multi-modal robotic perception.

</details>


### [169] [Bootstrapping Reinforcement Learning with Sub-optimal Policies for Autonomous Driving](https://arxiv.org/abs/2509.04712)
*Zhihao Zhang,Chengyang Peng,Ekim Yurtsever,Keith A. Redmill*

Main category: cs.RO

TL;DR: 该研究通过将一个非专家级的演示策略（基于规则的变道控制器）与SAC算法结合，来指导强化学习自动驾驶智能体，以提高样本效率和探索能力，从而改善驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习在自动驾驶控制中面临样本效率低和有效探索困难的挑战，这使得智能体难以发现最优驾驶策略。

Method: 提出用一个非专家级的演示策略来引导强化学习驾驶智能体。具体来说，将一个基于规则的变道控制器与Soft Actor Critic (SAC) 算法相结合，以增强探索和学习效率。

Result: 该方法展示了改进的驾驶性能。

Conclusion: 所提出的方法能够提高探索和学习效率，改善驾驶性能，并且可以推广到其他类似受益于基于演示指导的驾驶场景。

Abstract: Automated vehicle control using reinforcement learning (RL) has attracted
significant attention due to its potential to learn driving policies through
environment interaction. However, RL agents often face training challenges in
sample efficiency and effective exploration, making it difficult to discover an
optimal driving strategy. To address these issues, we propose guiding the RL
driving agent with a demonstration policy that need not be a highly optimized
or expert-level controller. Specifically, we integrate a rule-based lane change
controller with the Soft Actor Critic (SAC) algorithm to enhance exploration
and learning efficiency. Our approach demonstrates improved driving performance
and can be extended to other driving scenarios that can similarly benefit from
demonstration-based guidance.

</details>


### [170] [Hierarchical Reduced-Order Model Predictive Control for Robust Locomotion on Humanoid Robots](https://arxiv.org/abs/2509.04722)
*Adrian B. Ghansah,Sergio A. Esteban,Aaron D. Ames*

Main category: cs.RO

TL;DR: 本文提出了一种计算高效的分层控制框架，用于实现人形机器人在多变环境中的鲁棒运动，通过简化的模型进行步态规划并整合手臂和躯干动力学以增强稳定性，并在Unitree G1机器人上进行了仿真和硬件验证。


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人进入现实世界环境，确保其在各种环境下都能进行鲁棒运动变得至关重要。

Method: 该研究采用了一种分层控制框架：高层使用ALIP模型的步态动力学，通过非线性MPC同时优化步态周期、步长和踝关节扭矩；中层则是一个线性MPC框架，它扩展了标准的SRB-MPC，纳入了简化的手臂和躯干动力学，并以高层ALIP轨迹作为参考。整个框架计算高效，高层MPC运行频率为40 Hz，中层MPC为500 Hz，均在板载迷你PC上运行。方法通过在Unitree G1人形机器人上的仿真和硬件实验进行验证。

Result: 自适应步态时序将推力恢复成功率提高了36%；上身控制改善了偏航扰动抑制能力。此外，该方法在多种室内外地形（包括草地、石板路和不平坦的健身垫）上都展现了鲁棒的运动能力。

Conclusion: 所提出的分层控制框架能够使人形机器人在多样化环境中实现鲁棒且多功能的运动，显著提升了扰动抑制和推力恢复能力，同时保持了计算效率。

Abstract: As humanoid robots enter real-world environments, ensuring robust locomotion
across diverse environments is crucial. This paper presents a computationally
efficient hierarchical control framework for humanoid robot locomotion based on
reduced-order models -- enabling versatile step planning and incorporating arm
and torso dynamics to better stabilize the walking. At the high level, we use
the step-to-step dynamics of the ALIP model to simultaneously optimize over
step periods, step lengths, and ankle torques via nonlinear MPC. The ALIP
trajectories are used as references to a linear MPC framework that extends the
standard SRB-MPC to also include simplified arm and torso dynamics. We validate
the performance of our approach through simulation and hardware experiments on
the Unitree G1 humanoid robot. In the proposed framework the high-level step
planner runs at 40 Hz and the mid-level MPC at 500 Hz using the onboard
mini-PC. Adaptive step timing increased the push recovery success rate by 36%,
and the upper body control improved the yaw disturbance rejection. We also
demonstrate robust locomotion across diverse indoor and outdoor terrains,
including grass, stone pavement, and uneven gym mats.

</details>


### [171] [Imitation Learning Based on Disentangled Representation Learning of Behavioral Characteristics](https://arxiv.org/abs/2509.04737)
*Ryoga Oishi,Sho Sakaino,Toshiaki Tsuji*

Main category: cs.RO

TL;DR: 本文提出了一种机器人运动生成模型，能够根据人类指令中的修饰词（如行为条件）在线调整机器人动作。


<details>
  <summary>Details</summary>
Motivation: 机器人学习领域中，通过语言指令协调机器人动作日益可行，但将动作适应人类指令仍具挑战，因为此类指令通常是定性的，需要探索满足不同条件的行为。

Method: 该方法通过将演示分割成短序列，并分配对应特定修饰词类型的弱监督标签，学习修饰词指令到动作的映射。

Result: 在擦拭和抓取放置任务中，该方法能够在线响应修饰词指令调整动作，这与无法在执行期间适应的传统批处理方法不同。

Conclusion: 该研究成功地提出了一种机器人运动生成模型，使其能够在线适应人类指令中的定性修饰词，从而提高了机器人行为的灵活性和适应性。

Abstract: In the field of robot learning, coordinating robot actions through language
instructions is becoming increasingly feasible. However, adapting actions to
human instructions remains challenging, as such instructions are often
qualitative and require exploring behaviors that satisfy varying conditions.
This paper proposes a motion generation model that adapts robot actions in
response to modifier directives human instructions imposing behavioral
conditions during task execution. The proposed method learns a mapping from
modifier directives to actions by segmenting demonstrations into short
sequences, assigning weakly supervised labels corresponding to specific
modifier types. We evaluated our method in wiping and pick and place tasks.
Results show that it can adjust motions online in response to modifier
directives, unlike conventional batch-based methods that cannot adapt during
execution.

</details>


### [172] [COMMET: A System for Human-Induced Conflicts in Mobile Manipulation of Everyday Tasks](https://arxiv.org/abs/2509.04836)
*Dongping Li,Shaoting Peng,John Pohovey,Katherine Rose Driggs-Campbell*

Main category: cs.RO

TL;DR: 该论文提出了COMMET系统，旨在解决家庭环境中机器人与人类活动之间的冲突，并通过混合检测方法和GPT-4o总结用户偏好来提供个性化解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着机器人和AI技术的发展，机器人正从工业领域进入日常生活环境。然而，日常生活中动态且不可预测的人类活动可能与机器人行为发生冲突。由于这些冲突的社会属性，解决方案往往不唯一，且高度依赖用户的个人偏好，这阻碍了家用机器人的发展。

Method: 论文提出了COMMET系统，用于处理日常任务中移动操作引起的人类冲突。COMMET采用混合检测方法，首先进行多模态检索，对于低置信度情况则升级为微调模型推理。此外，系统会收集用户偏好选项和设置，并利用GPT-4o从相关案例中总结用户偏好。

Result: 初步研究表明，COMMET的检测模块在准确性和延迟方面优于GPT模型。为了促进未来的研究，论文还设计了一个用户友好的界面用于用户数据收集，并展示了一个有效的实际部署工作流程。

Conclusion: COMMET系统提供了一种有效的方法来检测和解决家庭环境中机器人与人类的冲突，通过结合混合检测和基于用户偏好的个性化解决方案。其检测模块表现出优越的性能，并且系统设计了数据收集界面和部署工作流程，为家用机器人的进一步发展奠定了基础。

Abstract: Continuous advancements in robotics and AI are driving the integration of
robots from industry into everyday environments. However, dynamic and
unpredictable human activities in daily lives would directly or indirectly
conflict with robot actions. Besides, due to the social attributes of such
human-induced conflicts, solutions are not always unique and depend highly on
the user's personal preferences. To address these challenges and facilitate the
development of household robots, we propose COMMET, a system for human-induced
COnflicts in Mobile Manipulation of Everyday Tasks. COMMET employs a hybrid
detection approach, which begins with multi-modal retrieval and escalates to
fine-tuned model inference for low-confidence cases. Based on collected user
preferred options and settings, GPT-4o will be used to summarize user
preferences from relevant cases. In preliminary studies, our detection module
shows better accuracy and latency compared with GPT models. To facilitate
future research, we also design a user-friendly interface for user data
collection and demonstrate an effective workflow for real-world deployments.

</details>


### [173] [A Knowledge-Driven Diffusion Policy for End-to-End Autonomous Driving Based on Expert Routing](https://arxiv.org/abs/2509.04853)
*Chengkai Xu,Jiaqi Liu,Yicheng Guo,Peng Hang,Jian Sun*

Main category: cs.RO

TL;DR: 本文提出了一种知识驱动的扩散策略KDP，通过结合生成扩散模型和稀疏专家混合路由机制，解决了端到端自动驾驶中多模态动作生成、时间稳定性及泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端自动驾驶方法在生成多模态动作、保持时间稳定性以及在不同场景下泛化方面存在局限，常导致多模态性缺失、长时序一致性差或模块化适应性不足。

Method: KDP整合了生成扩散模型（用于生成时间连贯和多模态的动作序列）与稀疏专家混合路由机制（根据上下文激活专业且可重用的专家），从而实现模块化的知识组合。该方法还利用了Transformer骨干网络。

Result: KDP在各种驾驶场景中取得了更高的成功率、更低的碰撞风险和更平滑的控制。消融研究证明了稀疏专家激活和Transformer骨干网络的有效性，激活分析揭示了专家结构化专业化和跨场景重用能力。

Conclusion: 结合专家路由的扩散模型为知识驱动的端到端自动驾驶提供了一个可扩展且可解释的范式。

Abstract: End-to-end autonomous driving remains constrained by the need to generate
multi-modal actions, maintain temporal stability, and generalize across diverse
scenarios. Existing methods often collapse multi-modality, struggle with
long-horizon consistency, or lack modular adaptability. This paper presents
KDP, a knowledge-driven diffusion policy that integrates generative diffusion
modeling with a sparse mixture-of-experts routing mechanism. The diffusion
component generates temporally coherent and multi-modal action sequences, while
the expert routing mechanism activates specialized and reusable experts
according to context, enabling modular knowledge composition. Extensive
experiments across representative driving scenarios demonstrate that KDP
achieves consistently higher success rates, reduced collision risk, and
smoother control compared to prevailing paradigms. Ablation studies highlight
the effectiveness of sparse expert activation and the Transformer backbone, and
activation analyses reveal structured specialization and cross-scenario reuse
of experts. These results establish diffusion with expert routing as a scalable
and interpretable paradigm for knowledge-driven end-to-end autonomous driving.

</details>


### [174] [Towards an Accurate and Effective Robot Vision (The Problem of Topological Localization for Mobile Robots)](https://arxiv.org/abs/2509.04948)
*Emanuela Boros*

Main category: cs.RO

TL;DR: 本文针对办公环境下的机器人拓扑定位问题，不依赖图像序列的时间连续性，系统性地比较了多种视觉描述符、距离度量和分类器的性能，并验证了其在复杂视觉条件下的有效性。


<details>
  <summary>Details</summary>
Motivation: 移动机器人需要确定自身位置以完成任务，而视觉定位和地点识别面临感知模糊、传感器噪声和光照变化等挑战，因此需要研究鲁棒的拓扑定位方法。

Method: 本研究使用安装在机器人平台上的透视彩色相机获取图像，评估了包括颜色直方图、SIFT、ASIFT、RGB-SIFT和受文本检索启发的视觉词袋（Bag-of-Visual-Words）等最先进的视觉描述符。通过标准评估指标和可视化方法，对这些特征、距离度量和分类器进行了系统性的定量比较，且不依赖图像序列的时间连续性。

Result: 结果表明，通过适当配置外观描述符、相似性度量和分类器，可以显著提高拓扑定位性能。这些配置的质量在ImageCLEF评估活动的机器人视觉任务中得到了进一步验证，系统成功识别了新图像序列的最可能位置。

Conclusion: 适当配置视觉描述符、相似性度量和分类器对于在复杂环境下实现鲁棒的拓扑定位至关重要。未来的工作将探索分层模型、排序方法和特征组合，以构建更鲁棒、实时性更强的定位系统，同时减少训练和运行时开销，并避免维度灾难。

Abstract: Topological localization is a fundamental problem in mobile robotics, since
robots must be able to determine their position in order to accomplish tasks.
Visual localization and place recognition are challenging due to perceptual
ambiguity, sensor noise, and illumination variations. This work addresses
topological localization in an office environment using only images acquired
with a perspective color camera mounted on a robot platform, without relying on
temporal continuity of image sequences. We evaluate state-of-the-art visual
descriptors, including Color Histograms, SIFT, ASIFT, RGB-SIFT, and
Bag-of-Visual-Words approaches inspired by text retrieval. Our contributions
include a systematic, quantitative comparison of these features, distance
measures, and classifiers. Performance was analyzed using standard evaluation
metrics and visualizations, extending previous experiments. Results demonstrate
the advantages of proper configurations of appearance descriptors, similarity
measures, and classifiers. The quality of these configurations was further
validated in the Robot Vision task of the ImageCLEF evaluation campaign, where
the system identified the most likely location of novel image sequences. Future
work will explore hierarchical models, ranking methods, and feature
combinations to build more robust localization systems, reducing training and
runtime while avoiding the curse of dimensionality. Ultimately, this aims
toward integrated, real-time localization across varied illumination and longer
routes.

</details>


### [175] [Ground-Aware Octree-A* Hybrid Path Planning for Memory-Efficient 3D Navigation of Ground Vehicles](https://arxiv.org/abs/2509.04950)
*Byeong-Il Ham,Hyun-Bin Kim,Kyung-Soo Kim*

Main category: cs.RO

TL;DR: 本文提出了一种结合A*算法和八叉树结构的3D路径规划方法，用于无人地面车辆和仿生机器人，通过利用可穿越障碍物并优化地图表示来提高效率和实时性。


<details>
  <summary>Details</summary>
Motivation: 随着无人地面车辆和仿生机器人移动能力的进步，障碍物不仅是需要避开的阻碍，也可以作为导航辅助。传统路径规划可能无法有效利用这些障碍物，且计算效率和内存使用是实时规划的挑战。

Method: 该方法将3D A*算法与八叉树结构相结合。修改后的3D A*算法在成本函数中引入基于高度的惩罚，以利用可穿越障碍物并避开不可穿越障碍物。八叉树3D网格地图通过合并高分辨率节点（尤其是在无障碍或稀疏区域）实现压缩，从而减少A*算法探索的节点数量。

Result: 该算法能够生成更高效、更真实的路径，通过利用可穿越障碍物辅助运动。八叉树结构显著减少了内存使用和计算时间，提高了计算效率，并支持在实际环境中的实时路径规划。基准测试结果证明了在确保最优路径的同时，内存使用和计算时间得到了显著降低。

Conclusion: 所提出的结合A*算法和八叉树结构的3D路径规划方法，通过智能地利用障碍物和高效的地图表示，实现了最优路径规划，同时显著降低了内存消耗和计算时间，为无人地面车辆和仿生机器人的实时导航提供了有效解决方案。

Abstract: In this paper, we propose a 3D path planning method that integrates the A*
algorithm with the octree structure. Unmanned Ground Vehicles (UGVs) and legged
robots have been extensively studied, enabling locomotion across a variety of
terrains. Advances in mobility have enabled obstacles to be regarded not only
as hindrances to be avoided, but also as navigational aids when beneficial. A
modified 3D A* algorithm generates an optimal path by leveraging obstacles
during the planning process. By incorporating a height-based penalty into the
cost function, the algorithm enables the use of traversable obstacles to aid
locomotion while avoiding those that are impassable, resulting in more
efficient and realistic path generation. The octree-based 3D grid map achieves
compression by merging high-resolution nodes into larger blocks, especially in
obstacle-free or sparsely populated areas. This reduces the number of nodes
explored by the A* algorithm, thereby improving computational efficiency and
memory usage, and supporting real-time path planning in practical environments.
Benchmark results demonstrate that the use of octree structure ensures an
optimal path while significantly reducing memory usage and computation time.

</details>


### [176] [DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and Interpretability in Manipulation](https://arxiv.org/abs/2509.04970)
*Tien Pham,Xinyun Chi,Khang Nguyen,Manfred Huber,Angelo Cangelosi*

Main category: cs.RO

TL;DR: DeGuV是一种强化学习框架，通过可学习的深度掩码网络、对比学习和稳定的Q值估计，显著提升了视觉输入RL智能体的泛化能力和样本效率，特别适用于零样本模拟到真实世界的迁移。


<details>
  <summary>Details</summary>
Motivation: 强化学习智能体在从视觉输入中学习复杂任务时，将所学技能泛化到新环境（尤其在机器人领域）是一个重大挑战。数据增强虽能提高泛化能力，但常以牺牲样本效率和训练稳定性为代价。

Method: 本文提出了DeGuV框架。它利用一个可学习的掩码网络，从深度输入生成掩码，只保留关键视觉信息并丢弃无关像素，使RL智能体专注于必要特征，从而增强数据增强下的鲁棒性。此外，DeGuV还结合了对比学习，并稳定了增强条件下的Q值估计，以进一步提高样本效率和训练稳定性。

Result: DeGuV在RL-ViGen基准测试（使用Franka Emika机器人）中进行了评估，并在零样本模拟到真实世界的迁移中展示了其有效性。结果表明，DeGuV在泛化能力和样本效率方面均优于现有最先进的方法，同时通过突出视觉输入中最相关的区域，提高了可解释性。

Conclusion: DeGuV是一个有效的RL框架，能够显著提高视觉输入RL智能体的泛化能力和样本效率，并在数据增强下保持鲁棒性，同时提供更好的可解释性，为机器人等实际应用提供了更强大的解决方案。

Abstract: Reinforcement learning (RL) agents can learn to solve complex tasks from
visual inputs, but generalizing these learned skills to new environments
remains a major challenge in RL application, especially robotics. While data
augmentation can improve generalization, it often compromises sample efficiency
and training stability. This paper introduces DeGuV, an RL framework that
enhances both generalization and sample efficiency. In specific, we leverage a
learnable masker network that produces a mask from the depth input, preserving
only critical visual information while discarding irrelevant pixels. Through
this, we ensure that our RL agents focus on essential features, improving
robustness under data augmentation. In addition, we incorporate contrastive
learning and stabilize Q-value estimation under augmentation to further enhance
sample efficiency and training stability. We evaluate our proposed method on
the RL-ViGen benchmark using the Franka Emika robot and demonstrate its
effectiveness in zero-shot sim-to-real transfer. Our results show that DeGuV
outperforms state-of-the-art methods in both generalization and sample
efficiency while also improving interpretability by highlighting the most
relevant regions in the visual input

</details>


### [177] [Lyapunov-Based Deep Learning Control for Robots with Unknown Jacobian](https://arxiv.org/abs/2509.04984)
*Koji Matsuno,Chien Chern Cheah*

Main category: cs.RO

TL;DR: 本文提出了一种用于机器人运动控制的端到端深度学习控制理论框架，通过模块化学习和类李雅普诺夫分析确保系统稳定性，有效解决了深度学习的“黑箱”问题，并实现了稳定、实时的机器人运动学控制。


<details>
  <summary>Details</summary>
Motivation: 深度学习在机器人应用中面临“黑箱”问题，特别是在机器人控制中，缺乏对系统稳定性的信任度和鲁棒性保障，这对于确保安全至关重要。研究旨在建立一种能与现有机器人控制理论结合的方法，以分析和确保系统稳定性。

Method: 开发了一个端到端深度学习控制的理论框架，该框架采用模块化学习方法实时更新所有层的权重，并基于类李雅普诺夫分析来确保系统稳定性。

Result: 在工业机器人上的实验结果表明，所提出的深度学习控制器性能良好，有效解决了深度学习的“黑箱”问题，并展示了以稳定方式部署实时深度学习策略进行机器人运动学控制的可能性。

Conclusion: 该研究为深度学习在实时机器人应用中提供了一个关键基础，证明了实现稳定、实时深度学习机器人运动学控制的可行性。

Abstract: Deep learning, with its exceptional learning capabilities and flexibility,
has been widely applied in various applications. However, its black-box nature
poses a significant challenge in real-time robotic applications, particularly
in robot control, where trustworthiness and robustness are critical in ensuring
safety. In robot motion control, it is essential to analyze and ensure system
stability, necessitating the establishment of methodologies that address this
need. This paper aims to develop a theoretical framework for end-to-end deep
learning control that can be integrated into existing robot control theories.
The proposed control algorithm leverages a modular learning approach to update
the weights of all layers in real time, ensuring system stability based on
Lyapunov-like analysis. Experimental results on industrial robots are presented
to illustrate the performance of the proposed deep learning controller. The
proposed method offers an effective solution to the black-box problem in deep
learning, demonstrating the possibility of deploying real-time deep learning
strategies for robot kinematic control in a stable manner. This achievement
provides a critical foundation for future advancements in deep learning based
real-time robotic applications.

</details>


### [178] [FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies](https://arxiv.org/abs/2509.04996)
*Moritz Reuss,Hongyi Zhou,Marcel Rühle,Ömer Erdinç Yağmurlu,Fabian Otto,Rudolf Lioutikov*

Main category: cs.RO

TL;DR: 本文提出了一种名为FLOWER的高效视觉-语言-动作（VLA）策略，通过中间模态融合和动作特定全局条件化，显著降低了计算成本和资源需求，同时保持了竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有扩散式VLA策略需要数十亿参数模型和海量数据集才能达到良好性能，导致计算成本和资源需求过高，阻碍了其实际机器人部署。

Method: 研究采用了两种方法：1. 中间模态融合：通过剪枝高达50%的LLM层，将容量重新分配给扩散头。2. 动作特定Global-AdaLN条件化：通过模块化适应，减少了20%的参数。这些方法被整合到一个9.5亿参数的VLA模型FLOWER中。

Result: FLOWER仅用200个H100 GPU小时预训练，在涵盖10个模拟和真实世界基准的190项任务中，与更大的VLA模型表现出竞争力，并在CALVIN ABC基准上取得了4.53的新SOTA（State-of-the-Art）成绩，同时对多样化的机器人实体展现了鲁棒性。

Conclusion: FLOWER提供了一个高效、高性能的VLA解决方案，通过创新的架构优化，显著降低了训练和部署成本，使其成为实际机器人应用中更具可行性的选择。

Abstract: Developing efficient Vision-Language-Action (VLA) policies is crucial for
practical robotics deployment, yet current approaches face prohibitive
computational costs and resource requirements. Existing diffusion-based VLA
policies require multi-billion-parameter models and massive datasets to achieve
strong performance. We tackle this efficiency challenge with two contributions:
intermediate-modality fusion, which reallocates capacity to the diffusion head
by pruning up to $50\%$ of LLM layers, and action-specific Global-AdaLN
conditioning, which cuts parameters by $20\%$ through modular adaptation. We
integrate these advances into a novel 950 M-parameter VLA called FLOWER.
Pretrained in just 200 H100 GPU hours, FLOWER delivers competitive performance
with bigger VLAs across $190$ tasks spanning ten simulation and real-world
benchmarks and demonstrates robustness across diverse robotic embodiments. In
addition, FLOWER achieves a new SoTA of 4.53 on the CALVIN ABC benchmark.
Demos, code and pretrained weights are available at
https://intuitive-robots.github.io/flower_vla/.

</details>


### [179] [Pointing-Guided Target Estimation via Transformer-Based Attention](https://arxiv.org/abs/2509.05031)
*Luca Müller,Hassan Ali,Philipp Allgeuer,Lukáš Gajdošech,Stefan Wermter*

Main category: cs.RO

TL;DR: 本文提出MM-ITF模型，通过多模态交互注意力，利用单目RGB数据准确预测人类指向手势的目标物体，以实现直观的人机协作。


<details>
  <summary>Details</summary>
Motivation: 指向手势是人类非语言沟通的基本形式，在人机交互（HRI）中至关重要，机器人需要能够预测人类意图并做出适当响应。

Method: 提出了一种名为Multi-Modality Inter-TransFormer (MM-ITF) 的模块化架构，该架构利用跨模态注意力，将2D指向手势映射到物体位置，为每个位置分配可能性分数，并识别最可能的目标。使用单目RGB数据进行预测。为评估性能，引入了补丁混淆矩阵。

Result: 研究结果表明，该方法能够使用单目RGB数据准确预测预期的目标物体，从而实现直观且易于访问的人机协作。

Conclusion: MM-ITF模型通过准确预测指向手势的目标，显著提升了人机交互的直观性和可访问性。

Abstract: Deictic gestures, like pointing, are a fundamental form of non-verbal
communication, enabling humans to direct attention to specific objects or
locations. This capability is essential in Human-Robot Interaction (HRI), where
robots should be able to predict human intent and anticipate appropriate
responses. In this work, we propose the Multi-Modality Inter-TransFormer
(MM-ITF), a modular architecture to predict objects in a controlled tabletop
scenario with the NICOL robot, where humans indicate targets through natural
pointing gestures. Leveraging inter-modality attention, MM-ITF maps 2D pointing
gestures to object locations, assigns a likelihood score to each, and
identifies the most likely target. Our results demonstrate that the method can
accurately predict the intended object using monocular RGB data, thus enabling
intuitive and accessible human-robot collaboration. To evaluate the
performance, we introduce a patch confusion matrix, providing insights into the
model's predictions across candidate object locations. Code available at:
https://github.com/lucamuellercode/MMITF.

</details>


### [180] [Shared Autonomy through LLMs and Reinforcement Learning for Applications to Ship Hull Inspections](https://arxiv.org/abs/2509.05042)
*Cristiano Caissutti,Estelle Gerbier,Ehsan Khorrambakht,Paolo Marinelli,Andrea Munafo',Andrea Caiti*

Main category: cs.RO

TL;DR: 本文提出了一种用于异构海洋机器人舰队的共享自治多层架构，该架构结合了大型语言模型、人机协作框架和行为树，旨在提高人机协作在复杂海洋环境中的效率和透明度。


<details>
  <summary>Details</summary>
Motivation: 在复杂、高风险和不确定的海洋环境中，有效的机器人与人类协作至关重要，因此需要先进的共享自治范式。

Method: 该研究结合了三种互补方法：1) 集成大型语言模型（LLMs）以促进直观的高级任务规范（如船体检查）；2) 在多智能体设置中实现人机协作框架，以实现自适应和意图感知协调；3) 开发基于行为树的模块化任务管理器，提供可解释和灵活的任务控制。

Result: 初步的仿真和实际湖泊环境测试结果表明，该多层架构有潜力减少操作员的认知负荷，增强透明度，并改善自适应行为与人类意图的一致性。

Conclusion: 这项研究为安全关键型海洋机器人应用中的可信、人机协作自治奠定了模块化和可扩展的基础。

Abstract: Shared autonomy is a promising paradigm in robotic systems, particularly
within the maritime domain, where complex, high-risk, and uncertain
environments necessitate effective human-robot collaboration. This paper
investigates the interaction of three complementary approaches to advance
shared autonomy in heterogeneous marine robotic fleets: (i) the integration of
Large Language Models (LLMs) to facilitate intuitive high-level task
specification and support hull inspection missions, (ii) the implementation of
human-in-the-loop interaction frameworks in multi-agent settings to enable
adaptive and intent-aware coordination, and (iii) the development of a modular
Mission Manager based on Behavior Trees to provide interpretable and flexible
mission control. Preliminary results from simulation and real-world lake-like
environments demonstrate the potential of this multi-layered architecture to
reduce operator cognitive load, enhance transparency, and improve adaptive
behaviour alignment with human intent. Ongoing work focuses on fully
integrating these components, refining coordination mechanisms, and validating
the system in operational port scenarios. This study contributes to
establishing a modular and scalable foundation for trustworthy,
human-collaborative autonomy in safety-critical maritime robotics applications.

</details>


### [181] [Robust Model Predictive Control Design for Autonomous Vehicles with Perception-based Observers](https://arxiv.org/abs/2509.05201)
*Nariman Niknejad,Gokul S. Sankar,Bahare Kiumarsi,Hamidreza Modares*

Main category: cs.RO

TL;DR: 本文提出了一种鲁棒模型预测控制（MPC）框架，专门处理深度学习感知模块中固有的非高斯噪声，通过集合状态估计和线性规划重构实现，并在重尾噪声条件下表现出优越的控制性能。


<details>
  <summary>Details</summary>
Motivation: 传统的MPC方法假设感知误差为零均值高斯噪声，但基于深度学习的感知模块存在固有的非高斯、有偏、重尾噪声，导致不准确的不确定性量化和不安全的反馈控制。因此，需要一种能够准确捕捉这类不确定性的控制框架。

Method: 该方法采用基于约束zonotope的集合状态估计来捕获有偏、重尾的不确定性，并保持有界估计误差。为了提高计算效率，鲁棒MPC被重新表述为线性规划（LP），使用基于Minkowski-Lyapunov的成本函数和松弛变量。通过Minkowski-Lyapunov不等式和收缩zonotope不变集确保闭环稳定性，并通过zonotope的椭球近似推导出最大的稳定终端集和反馈增益。

Result: 通过全向移动机器人上的仿真和硬件实验验证了该框架。结果表明，在重尾噪声条件下，所提出的感知感知MPC提供了稳定和准确的控制性能，在状态估计误差边界和整体控制性能方面显著优于传统的基于高斯噪声的设计。

Conclusion: 所提出的感知感知MPC框架能够有效处理深度学习感知模块中的非高斯、重尾噪声，确保了在复杂不确定性条件下的稳定和准确控制，其性能明显优于传统方法。

Abstract: This paper presents a robust model predictive control (MPC) framework that
explicitly addresses the non-Gaussian noise inherent in deep learning-based
perception modules used for state estimation. Recognizing that accurate
uncertainty quantification of the perception module is essential for safe
feedback control, our approach departs from the conventional assumption of
zero-mean noise quantification of the perception error. Instead, it employs
set-based state estimation with constrained zonotopes to capture biased,
heavy-tailed uncertainties while maintaining bounded estimation errors. To
improve computational efficiency, the robust MPC is reformulated as a linear
program (LP), using a Minkowski-Lyapunov-based cost function with an added
slack variable to prevent degenerate solutions. Closed-loop stability is
ensured through Minkowski-Lyapunov inequalities and contractive zonotopic
invariant sets. The largest stabilizing terminal set and its corresponding
feedback gain are then derived via an ellipsoidal approximation of the
zonotopes. The proposed framework is validated through both simulations and
hardware experiments on an omnidirectional mobile robot along with a camera and
a convolutional neural network-based perception module implemented within a
ROS2 framework. The results demonstrate that the perception-aware MPC provides
stable and accurate control performance under heavy-tailed noise conditions,
significantly outperforming traditional Gaussian-noise-based designs in terms
of both state estimation error bounding and overall control performance.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [182] [PRREACH: Probabilistic Risk Assessment Using Reachability for UAV Control](https://arxiv.org/abs/2509.04451)
*Nicole Fronda,Hariharan Narayanan,Sadia Afrin Ananna,Steven Weber,Houssam Abbas*

Main category: eess.SY

TL;DR: 本文提出了一种名为PRReach的新方法，利用可达性分析对无人机轨迹进行概率风险评估，并通过优化控制律以满足预设风险阈值，从而实现风险受限的无人机控制。


<details>
  <summary>Details</summary>
Motivation: 现有无人机风险评估框架依赖于难以获取的条件概率数据，且缺乏风险缓解的控制方法，这使得实际应用面临挑战。

Method: PRReach方法基于无人机动力学，采用可达性分析对所有可行无人机轨迹进行概率风险评估。然后，将这种整体风险评估用于构建一个控制优化问题，旨在以最小改动现有控制律的方式，使其风险受限于可接受的阈值。该方法利用公开的无人机动力学模型和开源空间数据。

Result: 仿真实验结果表明，与传统控制器相比，PRReach控制器在离线情况下可将风险降低高达24%，在线情况下可降低高达53%。

Conclusion: PRReach提供了一种实用且有效的方法来设计无人机风险受限控制器，能够实现离线预飞行和在线飞行中的风险评估和缓解。

Abstract: We present a new approach for designing risk-bounded controllers for Uncrewed
Aerial Vehicles (UAVs). Existing frameworks for assessing risk of UAV
operations rely on knowing the conditional probability of an incident occurring
given different causes. Limited data for computing these probabilities makes
real-world implementation of these frameworks difficult. Furthermore, existing
frameworks do not include control methods for risk mitigation. Our approach
relies on UAV dynamics, and employs reachability analysis for a probabilistic
risk assessment over all feasible UAV trajectories. We use this holistic risk
assessment to formulate a control optimization problem that minimally changes a
UAV's existing control law to be bounded by an accepted risk threshold. We call
our approach PRReach. Public and readily available UAV dynamics models and open
source spatial data for mapping hazard outcomes enables practical
implementation of PRReach for both offline pre-flight and online in-flight risk
assessment and mitigation. We evaluate PRReach through simulation experiments
on real-world data. Results show that PRReach controllers reduce risk by up to
24% offline, and up to 53% online from classical controllers.

</details>


### [183] [Memristor-Based Neural Network Accelerators for Space Applications: Enhancing Performance with Temporal Averaging and SIRENs](https://arxiv.org/abs/2509.04506)
*Zacharia A. Rudge,Dominik Dold,Moritz Fieback,Dario Izzo,Said Hamdioui*

Main category: eess.SY

TL;DR: 该研究通过模拟展示了忆阻器基神经网络在航天任务中的潜力，并利用特定技术显著提升了其性能，使其接近最先进水平。


<details>
  <summary>Details</summary>
Motivation: 忆阻器具有高能效和抗辐射性，非常适合航天器上的AI部署。然而，忆阻器器件的非理想性（如器件变异、电导漂移和故障）导致神经网络性能严重下降，难以满足航天应用对可靠和精确计算的要求。

Method: 研究通过模拟，采用位切片 (bit-slicing)、神经网络层的时间平均 (temporal averaging of NN layers) 和周期性激活函数 (periodic activation functions) 等技术，以改善RRAM器件上忆阻器基神经网络的性能。

Result: 在导航与控制以及小行星测地学等板载任务中，忆阻器基神经网络的初始性能（误差）从约0.07提高到0.01，从0.3提高到0.007，已接近最先进水平（分别为0.003-0.005和0.003）。

Conclusion: 研究结果证明了忆阻器在板载航天应用中的巨大潜力。作者相信，未来的技术和神经网络改进将进一步缩小性能差距，充分发挥忆阻器的优势。

Abstract: Memristors are an emerging technology that enables artificial intelligence
(AI) accelerators with high energy efficiency and radiation robustness --
properties that are vital for the deployment of AI on-board spacecraft.
However, space applications require reliable and precise computations, while
memristive devices suffer from non-idealities, such as device variability,
conductance drifts, and device faults. Thus, porting neural networks (NNs) to
memristive devices often faces the challenge of severe performance degradation.
In this work, we show in simulations that memristor-based NNs achieve
competitive performance levels on on-board tasks, such as navigation \& control
and geodesy of asteroids. Through bit-slicing, temporal averaging of NN layers,
and periodic activation functions, we improve initial results from around
$0.07$ to $0.01$ and $0.3$ to $0.007$ for both tasks using RRAM devices, coming
close to state-of-the-art levels ($0.003-0.005$ and $0.003$, respectively). Our
results demonstrate the potential of memristors for on-board space
applications, and we are convinced that future technology and NN improvements
will further close the performance gap to fully unlock the benefits of
memristors.

</details>


### [184] [Indifference-Zone Relaxation Procedures for Finding Feasible Systems](https://arxiv.org/abs/2509.04514)
*Yuwei Zhou,Sigrún Andradóttir,Seong-Hee Kim,Chuljin Park*

Main category: eess.SY

TL;DR: 本文提出了一种名为“无差异区松弛 (IZR)”的新方法，以及其改进版本“带估计的IZR (IZE)”，用于通过模拟寻找具有随机约束的系统可行性。这些方法通过引入松弛的容忍水平，提高了计算效率和统计有效性，显著减少了所需的观测次数。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理随机约束下的系统可行性问题时存在局限性：传统的无差异区 (IZ) 程序引入了固定的容忍水平，导致不必要的模拟；而无IZ程序在系统性能接近阈值时表现不佳。因此，需要一种更高效且统计上有效的方法来解决这一挑战。

Method: 本文提出了IZR程序，它引入了一组松弛的容忍水平，并为每个水平使用两个子程序：一个识别明显可行的系统，另一个排除明显不可行的系统。在此基础上，进一步开发了IZE程序，它为每个系统和约束引入了两个松弛的容忍水平：一个匹配原始容忍水平，另一个基于系统性能度量的估计。这些程序通过采用不同的容忍水平，实现了统计有效的早期可行性判定。

Result: 研究证明，IZR和IZE程序能够以期望的概率确定系统可行性。通过实验表明，与现有程序相比，这些新方法显著减少了所需的观测次数，提高了计算效率。

Conclusion: IZR和IZE程序通过引入松弛的容忍水平，为解决随机约束下的系统可行性问题提供了统计有效且计算高效的解决方案。它们能够实现早期可行性判定，并显著降低模拟成本。

Abstract: We consider the problem of finding feasible systems with respect to
stochastic constraints when system performance is evaluated through simulation.
Our objective is to solve this problem with high computational efficiency and
statistical validity. Existing indifference-zone (IZ) procedures introduce a
fixed tolerance level, which denotes how much deviation the decision-maker is
willing to accept from the threshold in the constraint. These procedures are
developed under the assumption that all systems' performance measures are
exactly the tolerance level away from the threshold, leading to unnecessary
simulations. In contrast, IZ-free procedures, which eliminate the tolerance
level, perform well when systems' performance measures are far from the
threshold. However, they may significantly underperform compared to IZ
procedures when systems' performance measures are close to the threshold. To
address these challenges, we propose the Indifference-Zone Relaxation (IZR)
procedure, IZR introduces a set of relaxed tolerance levels and utilizes two
subroutines for each level: one to identify systems that are clearly feasible
and the other to exclude those that are clearly infeasible. We also develop the
IZR procedure with estimation (IZE), which introduces two relaxed tolerance
levels for each system and constraint: one matching the original tolerance
level and the other based on an estimate of the system's performance measure.
By employing different tolerance levels, these procedures facilitate early
feasibility determination with statistical validity. We prove that IZR and IZE
determine system feasibility with the desired probability and show through
experiments that they significantly reduce the number of observations required
compared to an existing procedure.

</details>


### [185] [Resource-Oriented Optimization of Electric Vehicle Systems: A Data-Driven Survey on Charging Infrastructure, Scheduling, and Fleet Management](https://arxiv.org/abs/2509.04533)
*Hai Wang,Baoshen Guo,Xiaolei Zhou,Shuai Wang,Zhiqing Hong,Tian He*

Main category: eess.SY

TL;DR: 本文综述了数据驱动模型和方法，旨在解决电动汽车（EV）系统在充电站拥堵、充电成本和乘客服务需求冲突等方面的核心挑战，并探讨了其对人类出行、智能电网和环境可持续性的影响，同时指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 电动汽车的快速发展带来了空气质量改善和能源安全优势，但仍面临充电站拥堵、动态电价下的高充电成本以及充电需求与乘客服务要求冲突等核心挑战，促使研究者寻求解决方案。

Method: 本文采用文献综述的方法，全面回顾了现有文献中提出的数据驱动模型和方法，这些研究涵盖了电动汽车系统的整个生命周期，包括充电站部署、充电调度策略和大规模车队管理。

Result: 研究结果包括对解决电动汽车挑战的数据驱动模型和方法的综合回顾，这些方法覆盖了充电站部署、充电调度和车队管理。此外，论文还讨论了电动汽车整合在人类出行、智能电网基础设施和环境可持续性等多个领域中的广泛影响，并识别了未来研究的关键机会和方向。

Conclusion: 通过对数据驱动模型和方法的全面回顾，本文为解决电动汽车面临的核心挑战提供了深入见解，并强调了电动汽车在多领域融合的广泛影响，为未来研究指明了方向。

Abstract: Driven by growing concerns over air quality and energy security, electric
vehicles (EVs) has experienced rapid development and are reshaping global
transportation systems and lifestyle patterns. Compared to traditional
gasoline-powered vehicles, EVs offer significant advantages in terms of lower
energy consumption, reduced emissions, and decreased operating costs. However,
there are still some core challenges to be addressed: (i) Charging station
congestion and operational inefficiencies during peak hours, (ii) High charging
cost under dynamic electricity pricing schemes, and (iii) Conflicts between
charging needs and passenger service requirements.Hence, in this paper, we
present a comprehensive review of data-driven models and approaches proposed in
the literature to address the above challenges. These studies cover the entire
lifecycle of EV systems, including charging station deployment, charging
scheduling strategies, and large-scale fleet management. Moreover, we discuss
the broader implications of EV integration across multiple domains, such as
human mobility, smart grid infrastructure, and environmental sustainability,
and identify key opportunities and directions for future research.

</details>


### [186] [Wasserstein Distributionally Robust Adaptive Covariance Steering](https://arxiv.org/abs/2509.04593)
*Aditya Gahlawat,Vivek Khatana,Duo Wang,Sambhu H. Karumanchi,Naira Hovakimyan,Petros Voulgaris*

Main category: eess.SY

TL;DR: 本文提出了一种针对不确定非线性随机过程的、可预测且安全的协方差控制方法，通过结合$\mathcal{L}_1$-自适应控制和 Wasserstein 度量证书来处理一般不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理包含无界随机扰动和不完整模型知识的普遍不确定性，导致状态分布未知、形状任意且可能无法量化地偏离预期行为，从而引发不可预测和不安全的控制。

Method: 该方法基于$\mathcal{L}_1$-自适应控制架构，确保对不确定随机过程的鲁棒控制，并提供概率测度空间中的 Wasserstein 度量证书。这些分布证书被整合到高层协方差控制中，以保证安全控制。

Result: 该方法能保证安全控制，并避免了现有分布鲁棒规划和控制方法中难以验证的要求，如需要真实潜在分布的有限样本或先验知识的时变模糊集。

Conclusion: 研究提出了一种新颖的方法，实现了在普遍不确定性下的可预测和安全协方差控制，克服了现有技术在处理未知和复杂状态分布方面的局限性。

Abstract: We present a methodology for predictable and safe covariance steering control
of uncertain nonlinear stochastic processes. The systems under consideration
are subject to general uncertainties, which include unbounded random
disturbances (aleatoric uncertainties) and incomplete model knowledge
(state-dependent epistemic uncertainties). These general uncertainties lead to
temporally evolving state distributions that are entirely unknown, can have
arbitrary shapes, and may diverge unquantifiably from expected behaviors,
leading to unpredictable and unsafe behaviors. Our method relies on an
$\mathcal{L}_1$-adaptive control architecture that ensures robust control of
uncertain stochastic processes while providing Wasserstein metric certificates
in the space of probability measures. We show how these distributional
certificates can be incorporated into the high-level covariance control
steering to guarantee safe control. Unlike existing distributionally robust
planning and control methodologies, our approach avoids difficult-to-verify
requirements like the availability of finite samples from the true underlying
distribution or an a priori knowledge of time-varying ambiguity sets to which
the state distributions are assumed to belong.

</details>


### [187] [$\mathcal{L}_1$-DRAC: Distributionally Robust Adaptive Control](https://arxiv.org/abs/2509.04619)
*Aditya Gahlawat,Sambhu H. Karumanchi,Naira Hovakimyan*

Main category: eess.SY

TL;DR: 本文提出了一种名为 $\mathcal{L}_1$ 分布式鲁棒自适应控制（$\mathcal{L}_1$-DRAC）的新型控制方法，用于不确定随机过程，旨在通过结合数据驱动和鲁棒自适应控制的优势，解决数据驱动方法在安全关键应用中的可预测性和鲁棒性不足问题，并提供严格的分布偏差鲁棒性保证。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的机器学习方法在动态系统控制和估计方面取得了显著进展，但其可预测性和鲁棒性不足限制了在安全相关应用中的采用。传统的鲁棒自适应控制虽然能保证可预测性，但与数据驱动方法整合时面临挑战，通常导致保守结果，且难以有效应对数据驱动方法固有的分布偏移问题。

Method: 本文提出了 $\mathcal{L}_1$ 分布式鲁棒自适应控制（$\mathcal{L}_1$-DRAC）。该方法利用 $\mathcal{L}_1$ 自适应控制方法，确保存在一个以名义分布为中心的 Wasserstein 模糊集，该模糊集被保证包含真实分布。该模糊集会生成一个围绕时间变化名义分布的“模糊管”，用于应对认知不确定性（模型不确定性）和偶然不确定性（固有随机性和扰动）。

Result: 所设计的 $\mathcal{L}_1$-DRAC 控制器能为不确定随机过程提供鲁棒性证书，具体体现在均匀（有限时间）和最大分布偏差方面。该方法确保了包含真实分布的 Wasserstein 模糊集围绕着一个随时间变化的名义分布。

Conclusion: $\mathcal{L}_1$-DRAC 提供了一种有效的方法，将数据驱动工具与鲁棒自适应控制相结合，解决了传统方法在处理分布偏移问题时的局限性，为不确定随机过程提供了强大的可预测性和鲁棒性保证，使其适用于安全关键应用。

Abstract: Data-driven machine learning methodologies have attracted considerable
attention for the control and estimation of dynamical systems. However, such
implementations suffer from a lack of predictability and robustness. Thus,
adoption of data-driven tools has been minimal for safety-aware applications
despite their impressive empirical results. While classical tools like robust
adaptive control can ensure predictable performance, their consolidation with
data-driven methods remains a challenge and, when attempted, leads to
conservative results. The difficulty of consolidation stems from the inherently
different `spaces' that robust control and data-driven methods occupy.
Data-driven methods suffer from the distribution-shift problem, which current
robust adaptive controllers can only tackle if using over-simplified learning
models and unverifiable assumptions. In this paper, we present $\mathcal{L}_1$
distributionally robust adaptive control ($\mathcal{L}_1$-DRAC): a control
methodology for uncertain stochastic processes that guarantees robustness
certificates in terms of uniform (finite-time) and maximal distributional
deviation. We leverage the $\mathcal{L}_1$ adaptive control methodology to
ensure the existence of Wasserstein ambiguity set around a nominal
distribution, which is guaranteed to contain the true distribution. The uniform
ambiguity set produces an ambiguity tube of distributions centered on the
nominal temporally-varying nominal distribution. The designed controller
generates the ambiguity tube in response to both epistemic (model
uncertainties) and aleatoric (inherent randomness and disturbances)
uncertainties.

</details>


### [188] [Bayesian Diagnosability and Active Fault Identification](https://arxiv.org/abs/2509.04708)
*Chun-Wei Kong,Jay McMahon,Morteza Lahijanian*

Main category: eess.SY

TL;DR: 本文提出了一种针对离散时间非线性系统（含高斯白噪声）的贝叶斯故障识别框架，引入了新的可诊断性定义，并设计了主动故障识别策略以优化控制输入，显著提高了故障识别的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 在离散时间非线性系统（存在附加高斯白噪声）中，被动故障识别（FID）受到给定控制序列的根本限制，尤其是在存在未建模故障的情况下。

Method: 研究引入了一个贝叶斯框架，在合理假设下明确考虑了未建模故障。该方法依赖于一个新的定量可诊断性定义，揭示了被动故障识别的局限性。为克服这些局限，提出了一种主动故障识别策略，通过设计控制输入来改善故障识别。

Result: 在双水箱系统和具有复杂不连续动力学的火星卫星上的数值研究表明，与纯被动技术相比，该方法显著降低了故障率并缩短了识别延迟。

Conclusion: 所提出的贝叶斯框架结合新的可诊断性定义和主动故障识别策略，能够有效克服被动方法在复杂非线性系统故障识别中的局限性，显著提升性能。

Abstract: We study fault identification in discrete-time nonlinear systems subject to
additive Gaussian white noise. We introduce a Bayesian framework that
explicitly accounts for unmodeled faults under reasonable assumptions. Our
approach hinges on a new quantitative diagnosability definition, revealing when
passive fault identification (FID) is fundamentally limited by the given
control sequence. To overcome such limitations, we propose an active FID
strategy that designs control inputs for better fault identification. Numerical
studies on a two-water tank system and a Mars satellite with complex and
discontinuous dynamics demonstrate that our method significantly reduces
failure rates with shorter identification delays compared to purely passive
techniques.

</details>


### [189] [Performance Analysis of Pinching-Antenna-Enabled Internet of Things Systems](https://arxiv.org/abs/2509.04885)
*Han Zhang,Bingxin Zhang,Yizhe Zhao,Kun Yang,Guopeng Zhang*

Main category: eess.SY

TL;DR: 本文首次分析了在圆形室内环境中，考虑全覆盖/部分覆盖波导以及传播损耗的夹持天线系统（PASS）性能，并提供了实用的设计指导。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多假设矩形室内布局、全覆盖波导且忽略传播损耗，这与实际部署中存在的几何约束、部分覆盖和不可忽略的波导衰减不符。

Method: 开发了一个统一的几何-传播框架，综合考虑夹持天线放置、物联网设备位置分布和波导衰减。推导了四种场景下的中断概率和平均可达速率的闭式表达式，并通过蒙特卡洛仿真验证了准确性。

Result: 推导了四种场景（包括有/无传播损耗的全覆盖和部分覆盖波导）的中断概率和平均可达速率的闭式表达式。分析表明，在有传播损耗的部分覆盖波导场景下，系统性能随波导长度呈现非单调趋势，且最佳长度随衰减系数的增加而减小。数值结果量化了部署策略、波导传播损耗和覆盖几何之间的相互作用。

Conclusion: 该研究揭示了部署策略、波导传播损耗和覆盖几何之间的复杂关系，为面向性能的夹持天线系统设计提供了实用的指导方针。

Abstract: The pinching-antenna systems (PASS), which activate small dielectric
particles along a dielectric waveguide, has recently emerged as a promising
paradigm for flexible antenna deployment in next-generation wireless
communication networks. While most existing studies assume rectangular indoor
layouts with full coverage waveguide, practical deployments may involve
geometric constraints, partial coverage, and non-negligible waveguide
attenuation. This paper presents the first analytical investigation of PASS in
a circular indoor environment, encompassing both full coverage and partial
coverage waveguide configurations with/without propagation loss. A unified
geometric-propagation framework is developed that jointly captures
pinching-antenna placement, Internet of Things (IoT) device location
distribution, and waveguide attenuation. Closed-form expressions for the outage
probability and average achievable rate are derived for four scenarios, with
accuracy validated via extensive Monte-Carlo simulations. The analysis reveals
that, under the partial coverage waveguide scenario with propagation loss, the
system performance demonstrates a non-monotonic trend with respect to the
waveguide length, and the optimal length decreases as the attenuation
coefficient increases. Numerical results further quantify the interplay between
deployment strategy, waveguide propagation loss, and coverage geometry,
offering practical guidelines for performance-oriented PASS design.

</details>


### [190] [Estimating Cellular Network Delays in Finnish Railways: A Machine Learning Enhanced Approach](https://arxiv.org/abs/2509.05003)
*Saeideh Mansouri,Mohamed Shamekh,Simon Indola,Petri Mahonen*

Main category: eess.SY

TL;DR: 该研究基于芬兰Digirail项目，利用机器学习对公共蜂窝网络在铁路通信中的延迟进行建模和预测，以评估其替代老旧GSM-R网络的可行性。


<details>
  <summary>Details</summary>
Motivation: 随着公共蜂窝网络技术发展，人们日益关注其替代专用行业网络（如老旧的GSM-R铁路网络）的可能性。芬兰的Digirail项目旨在将铁路通信系统现代化，转向公共4G和5G网络，因此需要评估这些公共网络的性能是否能满足铁路通信的严格要求。

Method: 研究在全国范围内进行了两种模式的测量活动：最佳质量模式（Best Quality）和数据包复制模式（Packet Replication）。由于最佳质量模式引入了人为延迟，不适用于真实评估，因此研究基于数据包复制模式的测量数据，利用机器学习对铁路网络延迟进行建模。最终，使用表现最佳的模型生成了一个估算芬兰铁路网络延迟的全国性数据集。

Result: 研究表明基于机器学习的网络性能预测是可行的。生成的全国性延迟数据集提供了更准确的网络性能表示。结果表明，芬兰的公共蜂窝网络能够满足铁路网络控制的严格性能要求。

Conclusion: 芬兰的公共蜂窝网络有能力满足铁路网络控制的严苛性能需求，为Digirail项目向公共网络过渡提供了可行性支持。

Abstract: There is growing interest in using public cellular networks for specialized
communication applications, replacing standalone sector-specific networks. One
such application is transitioning from the aging GSM-R railway network to
public 4G and 5G networks. Finland is modernizing its railway communication
system through the Digirail project, leveraging public cellular networks. To
evaluate network performance, a nationwide measurement campaign was conducted
in two modes: Best Quality and Packet Replication. However, Best Quality mode
introduces artificial delays, making it unsuitable for real-world assessments.
In this paper, railway network delays are modeled using machine learning based
on measurements from the Packet Replication mode. The best-performing model is
then employed to generate a dataset estimating network delays across Finland's
railway network. This dataset provides a more accurate representation of
network performance. Machine learning based network performance prediction is
shown to be feasible, and the results indicate that Finland's public cellular
network can meet the stringent performance requirements of railway network
control.

</details>


### [191] [StimulHeat: a Low-Energy Wearable Thermal Feedback Device Using Peltier Elements with Heat Flow Controlled Loop for Hand Interactions in Virtual Reality](https://arxiv.org/abs/2509.05020)
*Matthieu Mesnage,Sophie Villenave,Bertrand Massot,Matthieu Blanchard,Pierre Raimbaud,Guillaume Lavoué,Claudine Gehin*

Main category: eess.SY

TL;DR: StimulHeat是一个无线、低功耗的热反馈系统，可集成到Valve Index控制器，通过控制热流而非温度提供热刺激，并通过用户研究验证了其在VR中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有VR热反馈系统大多不兼容或不集成到标准控制器，且基于温度控制，而非热流控制。

Method: 本研究通过以下方法实现：1. 提出通过控制热流而非温度来管理热刺激的方法。2. 设计了优化的热电装置（TED）驱动器，能够注入连续、双向电流以实现加热或冷却。3. 将该驱动器集成到电子板中，包含温度和热流控制回路以及蓝牙低功耗（BLE）接口。4. 设计了可夹持在Valve Index控制器上的非侵入式机械集成扩展件。5. 进行了用户研究，在一个Unity构建的虚拟环境中验证了StimulHeat在VR中的应用。

Result: 本研究开发了无线、低功耗的热反馈系统StimulHeat，该系统通过控制热电装置（TED）的电流实现热流控制，而非传统的温度控制。设计并实现了能够注入连续双向电流的TED驱动器，以及包含温度和热流控制回路、蓝牙低功耗接口的电子板。完成了可集成到Valve Index控制器的非侵入式机械设计。用户研究结果验证了StimulHeat在虚拟现实应用中的有效性。

Conclusion: StimulHeat作为一个无线、低功耗的热反馈系统，成功实现了与现有VR控制器的集成，并通过控制热流而非温度提供了新的热刺激管理方法，并通过用户研究验证了其在VR应用中的有效性。

Abstract: Nowadays, the majority of wearable thermal feedback systems designed for use
in virtual reality applications are not compatible or not integrated to
standard controllers and are based on temperature control. The objectives of
the present work is to enable integration with existing controllers, in this
case Valve Index controllers, and to propose an alternative approach to
managing thermal stimulation with Peltier modules by controlling heat flow
instead of temperature. We introduce StimulHeat as a wireless, low power
thermal feedback system, based on the continuous relationship between heat and
current injection in thermoelectric device (TED). First, we designed an
optimized TED driver capable of injecting a continuous, bidirectional current
into the TED, thereby driving it as a heater or cooler. Subsequently, this
driver was implemented in an electronic board to include temperature and heat
flow control loops, as well as Bluetooth Low Energy interface for remote
control. A mechanical integration was conducted, in the form of a controller
extension which is non-intrusive and can be clipped to Valve Index controllers
to enclose the TED, temperature sensors and electronics. Finally, we present a
user study validating StimulHeat for use in Virtual Reality, utilizing a
Unity-built virtual environment with our open-source package.

</details>


### [192] [Model predictive quantum control: A modular approach for efficient and robust quantum optimal control](https://arxiv.org/abs/2509.05167)
*Eya Guizani,Julian Berberich*

Main category: eess.SY

TL;DR: 本文提出一个模块化框架，通过模型预测控制（MPC）提高量子最优控制（QOC）的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 模型预测控制（MPC）是现代控制方法中非常成功的一种，研究者希望将其应用于量子最优控制（QOC），以解决现有QOC的效率和鲁棒性问题。

Method: 本文首先从QOC角度介绍MPC基本概念，然后提出多种MPC方案，从简单方法到具有稳定性保证的复杂方案。该框架可用于提高开环QOC的效率和通过反馈提高闭环量子控制的鲁棒性。

Result: 数值结果表明，所提出的方法在效率和鲁棒性方面优于现有竞争方法。

Conclusion: MPC可以显著提高量子最优控制的效率和闭环量子控制的鲁棒性，为QOC提供了一个有效的模块化框架。

Abstract: Model predictive control (MPC) is one of the most successful modern control
methods. It relies on repeatedly solving a finite-horizon optimal control
problem and applying the beginning piece of the optimal input. In this paper,
we develop a modular framework for improving efficiency and robustness of
quantum optimal control (QOC) via MPC. We first provide a tutorial introduction
to basic concepts of MPC from a QOC perspective. We then present multiple MPC
schemes, ranging from simple approaches to more sophisticated schemes which
admit stability guarantees. This yields a modular framework which can be used
1) to improve efficiency of open-loop QOC and 2) to improve robustness of
closed-loop quantum control by incorporating feedback. We demonstrate these
benefits with numerical results, where we benchmark the proposed methods
against competing approaches.

</details>


### [193] [Feedback Linearisation with State Constraints](https://arxiv.org/abs/2509.05191)
*Songlin Jin,Yuanbo Nie,Morgan Jones*

Main category: eess.SY

TL;DR: 本文提出一种在应用反馈线性化（FBL）之前先增强系统动力学以捕获状态约束的方法，并通过切换FBL控制器克服了由此产生的相对度定义不清问题，从而简化了FBL中状态约束的处理。


<details>
  <summary>Details</summary>
Motivation: 反馈线性化（FBL）虽然能将非线性系统转化为线性系统，但原始系统中的简单状态约束在FBL后的线性化系统中会变得复杂，削弱了线性化的优势，增加了控制难度。

Method: 该方法首先在应用FBL之前增强系统动力学以纳入状态约束。针对由此在状态约束边界处导致的相对度定义不清问题，提出使用切换FBL控制器来解决。

Result: 所提出的增强方法会导致在状态约束边界处出现相对度定义不清的问题，但通过使用切换FBL控制器可以克服这些问题。数值实验验证了该方法在FBL框架内处理状态约束的能力。

Conclusion: 该方法通过在FBL前增强系统动力学并结合切换FBL控制器，成功地在FBL框架内处理了状态约束，避免了约束复杂化的问题。

Abstract: Feedback Linearisation (FBL) is a widely used technique that applies feedback
laws to transform input-affine nonlinear dynamical systems into linear
dynamical systems, allowing for the use of linear controller design methods
such as pole placement. However, for problems with state constraints,
controlling the linear system induced by FBL can be more challenging than
controlling the original system. This is because simple state constraints in
the original nonlinear system become complex nonlinear constraints in the FBL
induced linearised system, thereby diminishing the advantages of linearisation.
To avoid increasing the complexity of state constraints under FBL, this paper
introduces a method to first augment system dynamics to capture state
constraints before applying FBL. We show that our proposed augmentation method
leads to ill-defined relative degrees at state constraint boundaries. However,
we show that ill-defined relative degrees can be overcome by using a switching
FBL controller. Numerical experiments illustrate the capabilities of this
method for handling state constraints within the FBL framework.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [194] [Inferring the Graph Structure of Images for Graph Neural Networks](https://arxiv.org/abs/2509.04677)
*Mayur S Gowda,John Shi,Augusto Santos,José M. F. Moura*

Main category: eess.IV

TL;DR: 本研究通过为图像数据集（如MNIST）构建替代的图表示（行/列相关图、乘积图），而非传统的网格图或超像素方法，显著提高了下游图神经网络（GNN）的分类准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的图像表示方法（如网格图和超像素）在作为图神经网络（GNN）输入时，可能未能充分捕捉图像信息，导致下游GNN任务（如图像分类）的准确性有待提高。

Method: 研究人员基于像素值之间的相关性，为MNIST和Fashion-MNIST数据集中的每张图像构建了行相关图、列相关图和乘积图。这些新颖的图表示和特征被用作下游GNN模型的输入，并与传统方法进行了比较。

Result: 实验结果表明，使用这些基于像素相关性构建的不同图表示和特征作为GNN模型的输入，能够比使用传统网格图和超像素方法获得更高的分类准确性。

Conclusion: 通过探索和应用基于像素相关性的替代图表示方法，可以有效提升图神经网络在图像分类任务上的性能，优于传统的图像图表示方法。

Abstract: Image datasets such as MNIST are a key benchmark for testing Graph Neural
Network (GNN) architectures. The images are traditionally represented as a grid
graph with each node representing a pixel and edges connecting neighboring
pixels (vertically and horizontally). The graph signal is the values
(intensities) of each pixel in the image. The graphs are commonly used as input
to graph neural networks (e.g., Graph Convolutional Neural Networks (Graph
CNNs) [1, 2], Graph Attention Networks (GAT) [3], GatedGCN [4]) to classify the
images. In this work, we improve the accuracy of downstream graph neural
network tasks by finding alternative graphs to the grid graph and superpixel
methods to represent the dataset images, following the approach in [5, 6]. We
find row correlation, column correlation, and product graphs for each image in
MNIST and Fashion-MNIST using correlations between the pixel values building on
the method in [5, 6]. Experiments show that using these different graph
representations and features as input into downstream GNN models improves the
accuracy over using the traditional grid graph and superpixel methods in the
literature.

</details>


### [195] [AURAD: Anatomy-Pathology Unified Radiology Synthesis with Progressive Representations](https://arxiv.org/abs/2509.04819)
*Shuhan Ding,Jingjing Fu,Yu Gu,Naiteek Sangani,Mu Wei,Paul Vozila,Nan Liu,Jiang Bian,Hoifung Poon*

Main category: eess.IV

TL;DR: AURAD是一个可控的放射学合成框架，能够生成高保真胸部X射线图像和伪语义掩膜，以解决医疗图像合成中的数据稀缺和精细控制难题。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺的临床环境中，医学图像合成是增强数据集和提高模型泛化能力的重要策略。然而，由于高质量标注有限以及数据集间的领域差异，精细和可控的合成仍然困难。现有方法难以推广到胸部X射线，因为其疾病模式形态多样且与解剖结构紧密交织。

Method: 本文提出了AURAD框架，它联合生成高保真胸部X射线图像和伪语义掩膜。该方法学习生成能够捕捉多病理共存和解剖-病理一致性的掩膜。其遵循渐进式流程：首先根据临床提示并以解剖结构为条件生成伪掩膜，然后用这些掩膜指导图像合成。此外，还利用预训练的医学专家模型过滤输出，确保临床合理性。合成的掩膜也可用作下游任务（如检测和分割）的标签。

Result: 广泛的实验和盲法放射科医生评估证明了该方法在不同任务和数据集上的有效性和泛化能力。具体而言，78%的合成图像被认证放射科医生归类为真实，超过40%的预测分割叠加被评为具有临床实用性。

Conclusion: AURAD框架有效解决了胸部X射线医疗图像合成中的挑战，实现了高保真、可控的图像生成和有用的伪语义掩膜。它通过提供下游任务的标签，并确保临床合理性，弥合了生成模型与现实世界临床应用之间的差距。

Abstract: Medical image synthesis has become an essential strategy for augmenting
datasets and improving model generalization in data-scarce clinical settings.
However, fine-grained and controllable synthesis remains difficult due to
limited high-quality annotations and domain shifts across datasets. Existing
methods, often designed for natural images or well-defined tumors, struggle to
generalize to chest radiographs, where disease patterns are morphologically
diverse and tightly intertwined with anatomical structures. To address these
challenges, we propose AURAD, a controllable radiology synthesis framework that
jointly generates high-fidelity chest X-rays and pseudo semantic masks. Unlike
prior approaches that rely on randomly sampled masks-limiting diversity,
controllability, and clinical relevance-our method learns to generate masks
that capture multi-pathology coexistence and anatomical-pathological
consistency. It follows a progressive pipeline: pseudo masks are first
generated from clinical prompts conditioned on anatomical structures, and then
used to guide image synthesis. We also leverage pretrained expert medical
models to filter outputs and ensure clinical plausibility. Beyond visual
realism, the synthesized masks also serve as labels for downstream tasks such
as detection and segmentation, bridging the gap between generative modeling and
real-world clinical applications. Extensive experiments and blinded radiologist
evaluations demonstrate the effectiveness and generalizability of our method
across tasks and datasets. In particular, 78% of our synthesized images are
classified as authentic by board-certified radiologists, and over 40% of
predicted segmentation overlays are rated as clinically useful. All code,
pre-trained models, and the synthesized dataset will be released upon
publication.

</details>


### [196] [Multi-modal Uncertainty Robust Tree Cover Segmentation For High-Resolution Remote Sensing Images](https://arxiv.org/abs/2509.04870)
*Yuanyuan Gui,Wei Li,Yinjian Wang,Xiang-Gen Xia,Mauro Marty,Christian Ginzler,Zuyuan Wang*

Main category: eess.IV

TL;DR: 本文提出MURTreeFormer框架，通过概率潜在表示和VAE重采样机制，有效缓解多模态遥感图像中因时间错位导致的交叉模态不确定性，显著提升树木覆盖分割精度。


<details>
  <summary>Details</summary>
Motivation: 多模态遥感图像在树木覆盖测绘中表现优越，但不同模态数据采集时间可能相隔数天甚至数月，导致植被变化或成像质量差异，引入交叉模态不确定性，严重降低分割精度。

Method: MURTreeFormer将一种模态设为主模态，其他为辅助模态。它通过概率潜在表示显式建模辅助模态的块级不确定性。不确定补丁通过基于VAE的重采样机制从主模态分布中重建，生成增强的辅助特征用于融合。解码器中进一步集成梯度幅度注意力（GMA）模块和轻量级细化头（RH），以引导对树状结构的关注并保留精细空间细节。

Result: 在上海和苏黎世的多模态数据集上进行的广泛实验表明，MURTreeFormer显著提高了分割性能，并有效减少了时间引起的不确定性影响。

Conclusion: MURTreeFormer是一个新颖的多模态分割框架，能够有效缓解并利用不确定性，实现鲁棒的树木覆盖测绘，解决了多模态遥感图像中时间错位带来的挑战。

Abstract: Recent advances in semantic segmentation of multi-modal remote sensing images
have significantly improved the accuracy of tree cover mapping, supporting
applications in urban planning, forest monitoring, and ecological assessment.
Integrating data from multiple modalities-such as optical imagery, light
detection and ranging (LiDAR), and synthetic aperture radar (SAR)-has shown
superior performance over single-modality methods. However, these data are
often acquired days or even months apart, during which various changes may
occur, such as vegetation disturbances (e.g., logging, and wildfires) and
variations in imaging quality. Such temporal misalignments introduce
cross-modal uncertainty, especially in high-resolution imagery, which can
severely degrade segmentation accuracy. To address this challenge, we propose
MURTreeFormer, a novel multi-modal segmentation framework that mitigates and
leverages aleatoric uncertainty for robust tree cover mapping. MURTreeFormer
treats one modality as primary and others as auxiliary, explicitly modeling
patch-level uncertainty in the auxiliary modalities via a probabilistic latent
representation. Uncertain patches are identified and reconstructed from the
primary modality's distribution through a VAE-based resampling mechanism,
producing enhanced auxiliary features for fusion. In the decoder, a gradient
magnitude attention (GMA) module and a lightweight refinement head (RH) are
further integrated to guide attention toward tree-like structures and to
preserve fine-grained spatial details. Extensive experiments on multi-modal
datasets from Shanghai and Zurich demonstrate that MURTreeFormer significantly
improves segmentation performance and effectively reduces the impact of
temporally induced aleatoric uncertainty.

</details>


### [197] [INR meets Multi-Contrast MRI Reconstruction](https://arxiv.org/abs/2509.04888)
*Natascha Niessen,Carolin M. Pirkl,Ana Beatriz Solana,Hannah Eichhorn,Veronika Spieker,Wenqi Huang,Tim Sprenger,Marion I. Menzel,Julia A. Schnabel*

Main category: eess.IV

TL;DR: 本研究提出了一种基于隐式神经表示（INR）网络的多对比度MRI重建方法，通过互补欠采样模式和联合重建，实现了更高的加速因子并优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 多对比度MRI序列扫描时间长，限制了其临床应用。通过k空间欠采样可以缩短扫描时间，但这给重建带来了挑战。需要先进的重建技术来在加速下获得高质量图像。

Method: 该方法利用多对比度序列中冗余的解剖信息，设计了特殊的欠采样模式：在k空间中心捕获对比度信息，同时在高频部分对不同对比度进行互补欠采样。提出了一种隐式神经表示（INR）网络，该网络能够联合重建所有对比度图像，从而有效利用跨对比度获取的互补信息来重建高度稀疏的k空间数据。

Result: 将所提出的INR方法应用于MPnRAGE序列的多对比度MRI重建，结果表明，即使在更高的加速因子下，该方法也优于最先进的并行成像压缩感知（PICS）重建方法。

Conclusion: 所提出的INR方法通过利用多对比度序列的互补信息和联合重建，能够实现更高加速率的多对比度MRI，并获得优于现有技术的重建质量，有望使多对比度序列更适用于临床常规应用。

Abstract: Multi-contrast MRI sequences allow for the acquisition of images with varying
tissue contrast within a single scan. The resulting multi-contrast images can
be used to extract quantitative information on tissue microstructure. To make
such multi-contrast sequences feasible for clinical routine, the usually very
long scan times need to be shortened e.g. through undersampling in k-space.
However, this comes with challenges for the reconstruction. In general,
advanced reconstruction techniques such as compressed sensing or deep
learning-based approaches can enable the acquisition of high-quality images
despite the acceleration. In this work, we leverage redundant anatomical
information of multi-contrast sequences to achieve even higher acceleration
rates. We use undersampling patterns that capture the contrast information
located at the k-space center, while performing complementary undersampling
across contrasts for high frequencies. To reconstruct this highly sparse
k-space data, we propose an implicit neural representation (INR) network that
is ideal for using the complementary information acquired across contrasts as
it jointly reconstructs all contrast images. We demonstrate the benefits of our
proposed INR method by applying it to multi-contrast MRI using the MPnRAGE
sequence, where it outperforms the state-of-the-art parallel imaging compressed
sensing (PICS) reconstruction method, even at higher acceleration factors.

</details>


### [198] [VLSM-Ensemble: Ensembling CLIP-based Vision-Language Models for Enhanced Medical Image Segmentation](https://arxiv.org/abs/2509.05154)
*Julia Dietlmeier,Oluwabukola Grace Adegboro,Vayangi Ganepola,Claudia Mazo,Noel E. O'Connor*

Main category: eess.IV

TL;DR: 本文提出了一种将视觉语言分割模型（VLSMs）与低复杂度CNN进行集成的方法，以弥补基于CLIP/BiomedCLIP的VLSMs在图像分割任务中与更先进架构（如CRIS）之间的性能差距。


<details>
  <summary>Details</summary>
Motivation: 基于CLIP和BiomedCLIP的视觉语言模型在图像分割任务中的表现落后于CRIS等更复杂的架构，且现有研究多集中于文本提示工程。

Method: 研究人员没有专注于文本提示工程，而是通过将视觉语言分割模型（VLSMs）与一个低复杂度的卷积神经网络（CNN）进行集成。具体使用了集成的BiomedCLIPSeg。

Result: 该方法在BKAI息肉数据集上使集成BiomedCLIPSeg的Dice分数显著提高了6.3%，在其他数据集上也有1%到6%的提升。此外，还在四个额外的放射学和非放射学数据集上提供了初步结果，显示集成方法在不同数据集上的表现（优于或劣于CRIS模型）存在差异。

Conclusion: 集成方法在不同数据集上的效果不一（有时优于CRIS模型，有时劣于），这表明该领域有待社区进一步研究。代码已开源。

Abstract: Vision-language models and their adaptations to image segmentation tasks
present enormous potential for producing highly accurate and interpretable
results. However, implementations based on CLIP and BiomedCLIP are still
lagging behind more sophisticated architectures such as CRIS. In this work,
instead of focusing on text prompt engineering as is the norm, we attempt to
narrow this gap by showing how to ensemble vision-language segmentation models
(VLSMs) with a low-complexity CNN. By doing so, we achieve a significant Dice
score improvement of 6.3% on the BKAI polyp dataset using the ensembled
BiomedCLIPSeg, while other datasets exhibit gains ranging from 1% to 6%.
Furthermore, we provide initial results on additional four radiology and
non-radiology datasets. We conclude that ensembling works differently across
these datasets (from outperforming to underperforming the CRIS model),
indicating a topic for future investigation by the community. The code is
available at https://github.com/juliadietlmeier/VLSM-Ensemble.

</details>


### [199] [Exploring Autoregressive Vision Foundation Models for Image Compression](https://arxiv.org/abs/2509.05169)
*Huu-Tai Phung,Yu-Hsiang Lin,Yen-Kuan Ho,Wen-Hsiao Peng*

Main category: eess.IV

TL;DR: 首次尝试将视觉基础模型（VFMs）重新用作图像编解码器，以探索其在低码率图像压缩中的生成能力，并发现它们在极低码率下展现出卓越的感知质量。


<details>
  <summary>Details</summary>
Motivation: 视觉基础模型（VFMs）在生成任务中被广泛应用，许多VFMs采用类似于端到端学习图像编解码器的编码器-解码器架构，并学习自回归（AR）模型进行下一token预测。本研究旨在探索这些模型的生成能力，将其应用于低码率图像压缩。

Method: 将VFM中的自回归（AR）模型重新利用，基于先前编码的token对下一个token进行熵编码，从而实现图像压缩。这种方法不同于早期仅依赖条件生成重建输入图像的语义压缩。

Result: 通过广泛的实验和分析，发现某些预训练的通用VFMs在极低码率下，相比于专门优化失真或感知质量的SOTA编解码器，展现出卓越的感知质量。

Conclusion: 这项研究为利用VFMs进行低码率、语义丰富的图像压缩开辟了一个有前景的研究方向。

Abstract: This work presents the first attempt to repurpose vision foundation models
(VFMs) as image codecs, aiming to explore their generation capability for
low-rate image compression. VFMs are widely employed in both conditional and
unconditional generation scenarios across diverse downstream tasks, e.g.,
physical AI applications. Many VFMs employ an encoder-decoder architecture
similar to that of end-to-end learned image codecs and learn an autoregressive
(AR) model to perform next-token prediction. To enable compression, we
repurpose the AR model in VFM for entropy coding the next token based on
previously coded tokens. This approach deviates from early semantic compression
efforts that rely solely on conditional generation for reconstructing input
images. Extensive experiments and analysis are conducted to compare VFM-based
codec to current SOTA codecs optimized for distortion or perceptual quality.
Notably, certain pre-trained, general-purpose VFMs demonstrate superior
perceptual quality at extremely low bitrates compared to specialized learned
image codecs. This finding paves the way for a promising research direction
that leverages VFMs for low-rate, semantically rich image compression.

</details>


### [200] [Generation of realistic cardiac ultrasound sequences with ground truth motion and speckle decorrelation](https://arxiv.org/abs/2509.05261)
*Thierry Judge,Nicolas Duchateau,Khuram Faraz,Pierre-Marc Jodoin,Olivier Bernard*

Main category: eess.IV

TL;DR: 本研究提出了一种改进的超声图像序列模拟框架，通过引入散斑去相关动态模型，显著提高了模拟序列的真实性，使其能更准确地捕捉实际观察到的时间变化。


<details>
  <summary>Details</summary>
Motivation: 用于左心室应变估计的机器学习算法的训练和验证需要真实的模拟超声图像序列。然而，现有的模拟管道因未考虑散斑去相关而导致真实性有限。

Method: 该方法在现有超声模拟管道的基础上，整合了一个动态散斑变异模型。它从真实超声序列和心肌分割数据生成网格，并引入一个随时间局部自适应的相干性图（该图来源于真实超声数据中测量的相关值），以取代固定比例的散射体，从而显式地模拟散斑去相关。

Result: 通过比较真实和模拟图像的相关曲线，该方法在98名患者的超声数据上进行了评估。结果显示，所提出的方法比基线管道的平均绝对误差更低，表明它能更忠实地再现临床数据中的去相关行为。

Conclusion: 该改进的模拟框架通过考虑散斑去相关，显著提高了模拟超声图像序列的真实性，使其能更有效地用于机器学习算法的训练和验证。

Abstract: Simulated ultrasound image sequences are key for training and validating
machine learning algorithms for left ventricular strain estimation. Several
simulation pipelines have been proposed to generate sequences with
corresponding ground truth motion, but they suffer from limited realism as they
do not consider speckle decorrelation. In this work, we address this limitation
by proposing an improved simulation framework that explicitly accounts for
speckle decorrelation. Our method builds on an existing ultrasound simulation
pipeline by incorporating a dynamic model of speckle variation. Starting from
real ultrasound sequences and myocardial segmentations, we generate meshes that
guide image formation. Instead of applying a fixed ratio of myocardial and
background scatterers, we introduce a coherence map that adapts locally over
time. This map is derived from correlation values measured directly from the
real ultrasound data, ensuring that simulated sequences capture the
characteristic temporal changes observed in practice. We evaluated the realism
of our approach using ultrasound data from 98 patients in the CAMUS database.
Performance was assessed by comparing correlation curves from real and
simulated images. The proposed method achieved lower mean absolute error
compared to the baseline pipeline, indicating that it more faithfully
reproduces the decorrelation behavior seen in clinical data.

</details>
