<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 28]
- [cs.CV](#cs.CV) [Total: 79]
- [cs.CL](#cs.CL) [Total: 55]
- [cs.RO](#cs.RO) [Total: 38]
- [eess.SY](#eess.SY) [Total: 8]
- [eess.IV](#eess.IV) [Total: 7]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning](https://arxiv.org/abs/2602.06107)
*Zhuoming Chen,Hongyi Liu,Yang Zhou,Haizhong Zheng,Beidi Chen*

Main category: cs.AI

TL;DR: 本文提出了一种名为Jackpot的框架，通过最优预算拒绝采样（OBRS）来解决强化学习（RL）大语言模型（LLM）训练成本高昂的问题，特别是滚动生成成本高昂。Jackpot通过减少滚动模型和演进策略之间的分布差异来提高效率，同时保持训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习（RL）用于大语言模型（LLM）训练成本高昂，尤其是滚动生成阶段。研究动机在于寻找一种更有效的方法来降低LLM的RL训练成本，通过解耦滚动生成和策略优化来实现。

Method: 本文提出了Jackpot框架，该框架利用最优预算拒绝采样（OBRS）来直接减小滚动模型和演进策略之间的分布差异。Jackpot包含一个OBRS程序、一个联合更新策略和滚动模型的统一训练目标，以及一个利用top-k概率估计和批级别偏差校正实现的有效系统。理论分析表明，OBRS在可控的接受预算下能有效缩小滚动分布与目标分布的差距。

Result: Jackpot框架显著提高了训练稳定性，优于重要性采样基线。在Qwen3-8B-Base模型上，Jackpot在最多300步更新（batchsize 64）的情况下，达到了与on-policy RL相当的性能。

Conclusion: 基于OBRS的解耦方法能够有效解决LLM RL训练中的分布不匹配问题，为实现滚动生成与策略优化的实际有效解耦迈出了重要一步，从而降低训练成本并提高效率。

Abstract: Reinforcement learning (RL) for large language models (LLMs) remains expensive, particularly because the rollout is expensive. Decoupling rollout generation from policy optimization (e.g., leveraging a more efficient model to rollout) could enable substantial efficiency gains, yet doing so introduces a severe distribution mismatch that destabilizes learning. We propose Jackpot, a framework that leverages Optimal Budget Rejection Sampling (OBRS) to directly reduce the discrepancy between the rollout model and the evolving policy. Jackpot integrates a principled OBRS procedure, a unified training objective that jointly updates the policy and rollout models, and an efficient system implementation enabled by top-$k$ probability estimation and batch-level bias correction. Our theoretical analysis shows that OBRS consistently moves the rollout distribution closer to the target distribution under a controllable acceptance budget. Empirically, \sys substantially improves training stability compared to importance-sampling baselines, achieving performance comparable to on-policy RL when training Qwen3-8B-Base for up to 300 update steps of batchsize 64. Taken together, our results show that OBRS-based alignment brings us a step closer to practical and effective decoupling of rollout generation from policy optimization for RL for LLMs.

</details>


### [2] [Large Language Model Reasoning Failures](https://arxiv.org/abs/2602.06176)
*Peiyang Song,Pengrui Han,Noah Goodman*

Main category: cs.AI

TL;DR: 本文对大型语言模型（LLMs）的推理失败进行了首次全面的调研，提出了一个将推理分为具身和非具身（非正式和正式），以及将失败分为基础性、应用特定和鲁棒性问题的新分类框架，并分析了现有研究、根源和缓解策略，旨在为未来研究提供指导，并附带一个GitHub资源库。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在推理方面取得了显著进展，但仍然存在普遍的推理失败，甚至在看似简单的场景下也是如此。为了系统地理解和解决这些不足，需要一个全面的调研来整合零散的研究工作。

Method: 作者提出了一个新的分类框架，将LLM推理分为具身和非具身（非正式和正式）两类。同时，推理失败被分为基础性（与LLM架构相关）、应用特定（在特定领域表现出局限性）和鲁棒性（在微小变化下表现不一致）三类。对于每种失败类型，文章都进行了定义、现有研究分析、根源探讨和缓解策略介绍。

Result: 该研究对LLM推理失败进行了系统性的分类和梳理，识别了不同类型的推理失败及其潜在的根源，并总结了现有的缓解策略。此外，作者还发布了一个关于LLM推理失败的研究作品集。

Conclusion: 通过对LLM推理失败的统一视角和结构化分析，该调研为理解LLM推理的系统性弱点提供了宝贵的见解，并为未来开发更强大、更可靠、更鲁棒的推理能力指明了方向。

Abstract: Large Language Models (LLMs) have exhibited remarkable reasoning capabilities, achieving impressive results across a wide range of tasks. Despite these advances, significant reasoning failures persist, occurring even in seemingly simple scenarios. To systematically understand and address these shortcomings, we present the first comprehensive survey dedicated to reasoning failures in LLMs. We introduce a novel categorization framework that distinguishes reasoning into embodied and non-embodied types, with the latter further subdivided into informal (intuitive) and formal (logical) reasoning. In parallel, we classify reasoning failures along a complementary axis into three types: fundamental failures intrinsic to LLM architectures that broadly affect downstream tasks; application-specific limitations that manifest in particular domains; and robustness issues characterized by inconsistent performance across minor variations. For each reasoning failure, we provide a clear definition, analyze existing studies, explore root causes, and present mitigation strategies. By unifying fragmented research efforts, our survey provides a structured perspective on systemic weaknesses in LLM reasoning, offering valuable insights and guiding future research towards building stronger, more reliable, and robust reasoning capabilities. We additionally release a comprehensive collection of research works on LLM reasoning failures, as a GitHub repository at https://github.com/Peiyang-Song/Awesome-LLM-Reasoning-Failures, to provide an easy entry point to this area.

</details>


### [3] [Do It for HER: First-Order Temporal Logic Reward Specification in Reinforcement Learning (Extended Version)](https://arxiv.org/abs/2602.06227)
*Pierriccardo Olivieri,Fausto Lasca,Alessandro Gianola,Matteo Papini*

Main category: cs.AI

TL;DR: 本文提出了一种在具有大状态空间的马尔可夫决策过程（MDP）中逻辑化非马尔可夫奖励的新框架，使用LTLfMT（一种扩展的线性时序逻辑），并开发了一种基于奖励机器和HER的方法来处理其复杂性和稀疏奖励问题。


<details>
  <summary>Details</summary>
Motivation: 为了在具有大状态空间的MDP中逻辑化非马尔可夫奖励，并且需要处理复杂、非结构化和异构数据域的任务，而无需手动编码谓词。

Method: 使用线性时序逻辑模理论（LTLfMT）来逻辑化非马尔可夫奖励。理论上，识别了一个可处理但足够表达性的LTLfMT片段。实践中，开发了一种基于奖励机器和Hindsight Experience Replay（HER）的方法来处理一阶逻辑规范和奖励稀疏性。

Result: 在连续控制设置中使用非线性算术理论进行评估，结果表明该方法能够自然地指定复杂任务。改进的HER实现对于解决具有复杂目标的任务至关重要。

Conclusion: 该框架能够逻辑化非马尔可夫奖励，并且结合HER可以有效地解决具有复杂目标和稀疏奖励的强化学习任务。

Abstract: In this work, we propose a novel framework for the logical specification of non-Markovian rewards in Markov Decision Processes (MDPs) with large state spaces. Our approach leverages Linear Temporal Logic Modulo Theories over finite traces (LTLfMT), a more expressive extension of classical temporal logic in which predicates are first-order formulas of arbitrary first-order theories rather than simple Boolean variables. This enhanced expressiveness enables the specification of complex tasks over unstructured and heterogeneous data domains, promoting a unified and reusable framework that eliminates the need for manual predicate encoding. However, the increased expressive power of LTLfMT introduces additional theoretical and computational challenges compared to standard LTLf specifications. We address these challenges from a theoretical standpoint, identifying a fragment of LTLfMT that is tractable but sufficiently expressive for reward specification in an infinite-state-space context. From a practical perspective, we introduce a method based on reward machines and Hindsight Experience Replay (HER) to translate first-order logic specifications and address reward sparsity. We evaluate this approach to a continuous-control setting using Non-Linear Arithmetic Theory, showing that it enables natural specification of complex tasks. Experimental results show how a tailored implementation of HER is fundamental in solving tasks with complex goals.

</details>


### [4] [Do LLMs Act Like Rational Agents? Measuring Belief Coherence in Probabilistic Decision Making](https://arxiv.org/abs/2602.06286)
*Khurram Yamin,Jingjing Tang,Santiago Cortes-Gomez,Amit Sharma,Eric Horvitz,Bryan Wilder*

Main category: cs.AI

TL;DR: 该研究旨在探究大型语言模型（LLMs）在处理高风险决策时，其决策逻辑是否符合理性效用最大化原则，并评估其信念的一致性和偏好的稳定性。研究方法是在诊断挑战问题中分析LLM的行为，并将其推理与理想的贝叶斯效用最大化进行对比。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域，LLMs需要基于对世界的不确定性和不同结果的效用进行最优决策，但其决策逻辑难以解释。因此，有必要研究LLMs是否能作为理性的效用最大化者。

Method: 通过在诊断挑战问题中观察LLM的行为，分析其报告的概率和行动，并与理想的贝叶斯效用最大化模型进行比较。研究提出了可证伪的条件，用于判断LLM的报告概率是否能代表任何理性代理的真实信念。该方法应用于多个医学诊断领域，并对不同LLMs进行了评估。

Result: 研究结果揭示了LLM推理与理想的贝叶斯效用最大化之间的关系，并提供了评估LLM信念一致性和偏好稳定性的方法。通过在医学诊断领域的应用，发现了LLM在处理不确定性和效用考量方面存在的潜在问题。

Conclusion: 该研究为理解LLMs在高风险决策中的行为提供了新的视角，并指出了未来在指导高风险决策中使用LLMs的方向。研究结果对于开发更可靠、更可解释的LLMs具有重要意义。

Abstract: Large language models (LLMs) are increasingly deployed as agents in high-stakes domains where optimal actions depend on both uncertainty about the world and consideration of utilities of different outcomes, yet their decision logic remains difficult to interpret. We study whether LLMs are rational utility maximizers with coherent beliefs and stable preferences. We consider behaviors of models for diagnosis challenge problems. The results provide insights about the relationship of LLM inferences to ideal Bayesian utility maximization for elicited probabilities and observed actions. Our approach provides falsifiable conditions under which the reported probabilities \emph{cannot} correspond to the true beliefs of any rational agent. We apply this methodology to multiple medical diagnostic domains with evaluations across several LLMs. We discuss implications of the results and directions forward for uses of LLMs in guiding high-stakes decisions.

</details>


### [5] [Exposing Weaknesses of Large Reasoning Models through Graph Algorithm Problems](https://arxiv.org/abs/2602.06319)
*Qifan Zhang,Jianhao Ruan,Aochuan Chen,Kang Zeng,Nuo Chen,Jing Tang,Jia Li*

Main category: cs.AI

TL;DR: 本文提出了一个名为 GrAlgoBench 的新基准，用于评估大型推理模型 (LRM) 在图算法推理方面的能力。实验发现，现有 LRM 在处理长上下文时准确率急剧下降，并且存在过度思考的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的数学、代码和常识推理基准在长上下文评估、挑战性以及答案的可验证性方面存在不足。图算法问题因其需要长上下文推理、易于控制难度以及支持程序化评估的特性，非常适合作为 LRM 推理能力的测试平台。

Method: 构建了一个包含九个任务的 GrAlgoBench 基准，使用图算法问题来评估 LRM。通过系统性实验，分析 LRM 在不同上下文长度下的准确率、错误类型（执行错误、记忆弱、冗余推理）以及“过度思考”现象。

Result: 研究发现，当前 LRM 在处理长上下文（超过 120 个节点）时，准确率会急剧下降至 50% 以下。LRM 容易出现执行错误、记忆能力弱和冗余推理的问题。此外，LRM 表现出“过度思考”的现象，即通过大量的自我验证来生成冗长的推理过程，但并未有效提升正确率。

Conclusion: GrAlgoBench 提供了一个严谨、多维度且实用的测试平台，揭示了当前 LRM 在图算法推理方面存在的长上下文处理能力不足和过度思考等关键局限性，为进一步提升 LRM 的推理能力指明了方向。

Abstract: Large Reasoning Models (LRMs) have advanced rapidly; however, existing benchmarks in mathematics, code, and common-sense reasoning remain limited. They lack long-context evaluation, offer insufficient challenge, and provide answers that are difficult to verify programmatically. We introduce GrAlgoBench, a benchmark designed to evaluate LRMs through graph algorithm problems. Such problems are particularly well suited for probing reasoning abilities: they demand long-context reasoning, allow fine-grained control of difficulty levels, and enable standardized, programmatic evaluation. Across nine tasks, our systematic experiments reveal two major weaknesses of current LRMs. First, accuracy deteriorates sharply as context length increases, falling below 50% once graphs exceed 120 nodes. This degradation is driven by frequent execution errors, weak memory, and redundant reasoning. Second, LRMs suffer from an over-thinking phenomenon, primarily caused by extensive yet largely ineffective self-verification, which inflates reasoning traces without improving correctness. By exposing these limitations, GrAlgoBench establishes graph algorithm problems as a rigorous, multidimensional, and practically relevant testbed for advancing the study of reasoning in LRMs. Code is available at https://github.com/Bklight999/GrAlgoBench.

</details>


### [6] [Trifuse: Enhancing Attention-Based GUI Grounding via Multimodal Fusion](https://arxiv.org/abs/2602.06351)
*Longhui Ma,Di Zhao,Siwei Wang,Zhao Lv,Miao Wang*

Main category: cs.AI

TL;DR: 提出了一种名为Trifuse的注意力机制GUI grounding框架，通过融合注意力、OCR文本线索和图标描述语义来提高对GUI元素的定位准确性，无需特定任务的微调，并减少了对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有GUI grounding方法依赖大量标注数据且泛化能力差，而基于注意力的方法可靠性不高，缺乏显式的空间锚定。本研究旨在解决这些限制，提高GUI grounding的效率和准确性。

Method: 提出Trifuse框架，一种基于注意力机制的 grounding 方法。它通过Consensus-SinglePeak (CS) 融合策略，显式整合互补的空间锚点（注意力、OCR文本线索、图标描述语义），强制跨模态一致性并保持精确定位。

Result: Trifuse在四个GUI grounding基准测试中表现出色，无需特定任务微调，显著降低了对昂贵标注数据的需求。消融实验表明，OCR和图标描述线索的引入一致性地提升了基于注意力的 grounding 性能。

Conclusion: Trifuse是一个有效的、无需微调的GUI grounding框架，通过融合多种空间信息显著提高了定位精度，并展示了OCR和图标描述线索在GUI grounding任务中的普遍有效性。

Abstract: GUI grounding maps natural language instructions to the correct interface elements, serving as the perception foundation for GUI agents. Existing approaches predominantly rely on fine-tuning multimodal large language models (MLLMs) using large-scale GUI datasets to predict target element coordinates, which is data-intensive and generalizes poorly to unseen interfaces. Recent attention-based alternatives exploit localization signals in MLLMs attention mechanisms without task-specific fine-tuning, but suffer from low reliability due to the lack of explicit and complementary spatial anchors in GUI images. To address this limitation, we propose Trifuse, an attention-based grounding framework that explicitly integrates complementary spatial anchors. Trifuse integrates attention, OCR-derived textual cues, and icon-level caption semantics via a Consensus-SinglePeak (CS) fusion strategy that enforces cross-modal agreement while retaining sharp localization peaks. Extensive evaluations on four grounding benchmarks demonstrate that Trifuse achieves strong performance without task-specific fine-tuning, substantially reducing the reliance on expensive annotated data. Moreover, ablation studies reveal that incorporating OCR and caption cues consistently improves attention-based grounding performance across different backbones, highlighting its effectiveness as a general framework for GUI grounding.

</details>


### [7] [Difficulty-Estimated Policy Optimization](https://arxiv.org/abs/2602.06375)
*Yu Zhao,Fan Jiang,Tianle Liu,Bo Zeng,Yu Liu,Longyue Wang,Weihua Luo*

Main category: cs.AI

TL;DR: 本文提出了一种名为DEPO（Difficulty-Estimated Policy Optimization）的新框架，通过在线难度估计来过滤训练数据，优先处理高学习潜力的样本，从而提高推理模型训练的效率和鲁棒性，可将Rollout成本降低高达2倍，且不影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的GRPO方法在处理过于简单或过于复杂的问题时，梯度信号会衰减，影响收敛稳定性。DAPO等变体虽然解决了梯度消失问题，但存在低效样本的计算开销过大的问题。因此，需要一种更高效、更鲁棒的推理模型训练优化方法。

Method: 提出DEPO框架，引入在线难度估计器，在Rollout阶段之前动态评估和过滤训练数据，确保计算资源优先用于学习潜力高的样本。

Result: DEPO在不影响模型性能的情况下，可将Rollout成本降低高达2倍。这显著降低了训练高性能推理模型的计算门槛。

Conclusion: DEPO是一种有效且鲁棒的推理对齐优化框架，通过智能的数据过滤机制，提高了训练效率，为推理模型的扩展提供了更可持续的途径。

Abstract: Recent advancements in Large Reasoning Models (LRMs), exemplified by DeepSeek-R1, have underscored the potential of scaling inference-time compute through Group Relative Policy Optimization (GRPO). However, GRPO frequently suffers from gradient signal attenuation when encountering problems that are either too trivial or overly complex. In these scenarios, the disappearance of inter-group advantages makes the gradient signal susceptible to noise, thereby jeopardizing convergence stability. While variants like DAPO attempt to rectify gradient vanishing, they do not alleviate the substantial computational overhead incurred by exhaustive rollouts on low-utility samples. In this paper, we propose Difficulty-Estimated Policy Optimization (DEPO), a novel framework designed to optimize the efficiency and robustness of reasoning alignment. DEPO integrates an online Difficulty Estimator that dynamically assesses and filters training data before the rollout phase. This mechanism ensures that computational resources are prioritized for samples with high learning potential. Empirical results demonstrate that DEPO achieves up to a 2x reduction in rollout costs without compromising model performance. Our approach significantly lowers the computational barrier for training high-performance reasoning models, offering a more sustainable path for reasoning scaling. Code and data will be released upon acceptance.

</details>


### [8] [Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization](https://arxiv.org/abs/2602.06394)
*Arvid E. Gollwitzer,Paridhi Latawa,David de Gruijl,Deepak A. Subramanian,Adrián Noriega de la Colina*

Main category: cs.AI

TL;DR: 本文提出了一种名为QA-Token（Quality-Aware Tokenization）的新型数据分词方法，它将信号质量融入词汇构建过程，旨在提升在真实世界嘈杂数据上的处理效果，并取得了在基因组学和金融领域的显著性能提升，同时在基础模型预训练中实现了更好的病原体检测性能并减少了词元数量。


<details>
  <summary>Details</summary>
Motivation: 现有的分词方法未考虑信号质量，导致在处理嘈杂的真实世界语料时效果受限。研究动机是为了开发一种能够直接将数据可靠性纳入词汇构建过程的分词方法，以应对此类挑战。

Method: 本文提出QA-Token，包含三个主要贡献：（1）采用双层优化框架，同时优化词汇构建和下游任务性能；（2）利用强化学习学习基于质量感知的奖励策略，并保证了收敛性；（3）通过Gumbel-Softmax松弛实现参数自适应学习，以支持端到端优化。

Result: QA-Token在基因组学（变异检测F1分数比BPE提高6.7个百分点）和金融领域（夏普比率提高30%）均取得了显著改进。在基础模型层面，对包含1.7万亿碱基对的预训练语料进行分词，实现了94.53%的MCC（ Matthews Correlation Coefficient）用于病原体检测，达到了最先进水平，同时词元数量减少了15%。

Conclusion: QA-Token能够有效地利用嘈杂的真实世界语料（如基因组序列和金融时间序列）进行基础模型训练，且在训练过程中没有引入额外的推理开销，并在多个领域证明了其有效性。

Abstract: Current tokenization methods process sequential data without accounting for signal quality, limiting their effectiveness on noisy real-world corpora. We present QA-Token (Quality-Aware Tokenization), which incorporates data reliability directly into vocabulary construction. We make three key contributions: (i) a bilevel optimization formulation that jointly optimizes vocabulary construction and downstream performance, (ii) a reinforcement learning approach that learns merge policies through quality-aware rewards with convergence guarantees, and (iii) an adaptive parameter learning mechanism via Gumbel-Softmax relaxation for end-to-end optimization. Our experimental evaluation demonstrates consistent improvements: genomics (6.7 percentage point F1 gain in variant calling over BPE), finance (30% Sharpe ratio improvement). At foundation scale, we tokenize a pretraining corpus comprising 1.7 trillion base-pairs and achieve state-of-the-art pathogen detection (94.53 MCC) while reducing token count by 15%. We unlock noisy real-world corpora, spanning petabases of genomic sequences and terabytes of financial time series, for foundation model training with zero inference overhead.

</details>


### [9] [Intrinsic Stability Limits of Autoregressive Reasoning: Structural Consequences for Long-Horizon Execution](https://arxiv.org/abs/2602.06413)
*Hsien-Jyh Liao*

Main category: cs.AI

TL;DR: 该研究认为，大型语言模型在长任务中的推理能力下降并非仅由任务复杂性引起，而是源于自回归生成过程固有的稳定性限制。研究提出了“结构治理”的视角，并推导了决定性优势随执行长度指数衰减的定理，指出稳定长程推理需要离散化和图状执行结构（如DAG）。实验证实了这一理论预测。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长任务中推理能力急剧下降，现有解释（任务复杂度、搜索难题）不完整，研究者希望找到更根本的原因。

Method: 提出“结构治理”的概念，将长程推理视为稳定性问题；推导了证明决策优势随执行长度指数衰减的定理（Theorem A）；在合成环境和TextWorld任务中进行实证研究。

Result: 证明了自回归决策优势随执行长度呈指数级衰减；发现性能悬崖与理论预测一致；短程评估可能掩盖结构不稳定性。

Conclusion: 长程推理的根本限制在于自回归生成过程的稳定性，而非仅仅是任务复杂度；稳定的长程推理需要离散化和图状执行结构；未来的研究方向可能从单纯的规模扩展转向结构化治理。

Abstract: Large language models (LLMs) demonstrate remarkable reasoning capabilities, yet their performance often deteriorates sharply in long-horizon tasks, exhibiting systematic breakdown beyond certain scales. Conventional explanations primarily attribute this phenomenon to task complexity, such as combinatorial search explosion or long-term credit assignment challenges. In this work, we argue that these explanations are incomplete: even in linear, unbranched tasks without semantic ambiguity, autoregressive execution is subject to an intrinsic stability limit.
  We propose that the fundamental constraint on long-horizon reasoning arises from process-level instability in autoregressive generation rather than solely from search or task complexity, reframing long-horizon reasoning as a problem of structural governance. We derive Theorem~A, showing that decision advantage in single-path autoregressive reasoning decays exponentially with execution length, imposing a fundamental bound on maintainable reasoning chains. This result implies a structural consequence: stable long-horizon reasoning requires discrete segmentation, naturally inducing graph-like execution structures such as directed acyclic graphs (DAGs).
  Empirical studies in both synthetic environments and real TextWorld tasks reveal observable performance cliffs consistent with theoretical predictions. Our findings provide a dynamical perspective on long-horizon reasoning failure and suggest new limitations on maintaining long-term coherence under purely autoregressive architectures. Furthermore, we highlight that short-horizon evaluation protocols may obscure structural instability, indicating a potential shift from scaling toward structured governance in future reasoning systems.

</details>


### [10] [AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents](https://arxiv.org/abs/2602.06485)
*Haotian Chen,Xin Cong,Shengda Fan,Yuyang Fu,Ziqin Gong,Yaxi Lu,Yishan Li,Boye Niu,Chengjun Pan,Zijun Song,Huadong Wang,Yesai Wu,Yueying Wu,Zihao Xie,Yukun Yan,Zhong Zhang,Yankai Lin,Zhiyuan Liu,Maosong Sun*

Main category: cs.AI

TL;DR: 该研究首次系统性地研究了40亿参数规模的LLM智能体（agent）的训练，并提出了AgentCPM-Explore模型和一套新的训练框架，以解决边缘规模模型在灾难性遗忘、奖励信号噪声敏感性和长上下文推理退化等问题。结果表明，AgentCPM-Explore在40亿参数级别达到SOTA，并能媲美甚至超越80亿参数的模型，证明了边缘规模模型的能力潜力被低估，关键在于推理稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体依赖大型模型，而边缘规模模型的潜力尚未被充分探索。研究旨在填补这一空白，并提升边缘规模模型处理复杂任务的能力。

Method: 提出AgentCPM-Explore，一个40亿参数的紧凑型智能体模型，具备高知识密度和强大的探索能力。同时，设计了一套包含参数空间模型融合、奖励信号去噪和上下文信息精炼的整体训练框架。

Result: AgentCPM-Explore在40亿参数级别实现了SOTA性能，并在四个基准上达到了或超越了80亿参数级别的SOTA模型。在五个基准上，其性能甚至优于Claude-4.5-Sonnet和DeepSeek-v3.2等更大规模的模型。在GAIA文本任务上，pass@64的准确率达到了97.09%。

Conclusion: 边缘规模模型的瓶颈不在于固有的能力上限，而在于推理稳定性。提出的AgentCPM-Explore及其训练框架有效释放了边缘规模模型被低估的巨大潜力。

Abstract: While Large Language Model (LLM)-based agents have shown remarkable potential for solving complex tasks, existing systems remain heavily reliant on large-scale models, leaving the capabilities of edge-scale models largely underexplored. In this paper, we present the first systematic study on training agentic models at the 4B-parameter scale. We identify three primary bottlenecks hindering the performance of edge-scale models: catastrophic forgetting during Supervised Fine-Tuning (SFT), sensitivity to reward signal noise during Reinforcement Learning (RL), and reasoning degradation caused by redundant information in long-context scenarios. To address the issues, we propose AgentCPM-Explore, a compact 4B agent model with high knowledge density and strong exploration capability. We introduce a holistic training framework featuring parameter-space model fusion, reward signal denoising, and contextual information refinement. Through deep exploration, AgentCPM-Explore achieves state-of-the-art (SOTA) performance among 4B-class models, matches or surpasses 8B-class SOTA models on four benchmarks, and even outperforms larger-scale models such as Claude-4.5-Sonnet or DeepSeek-v3.2 in five benchmarks. Notably, AgentCPM-Explore achieves 97.09% accuracy on GAIA text-based tasks under pass@64. These results provide compelling evidence that the bottleneck for edge-scale models is not their inherent capability ceiling, but rather their inference stability. Based on our well-established training framework, AgentCPM-Explore effectively unlocks the significant, yet previously underestimated, potential of edge-scale models.

</details>


### [11] [JADE: Expert-Grounded Dynamic Evaluation for Open-Ended Professional Tasks](https://arxiv.org/abs/2602.06486)
*Lanbo Lin,Jiayao Liu,Tianyuan Yang,Li Cai,Yuanwu Xu,Lei Wei,Sicong Xie,Guannan Zhang*

Main category: cs.AI

TL;DR: 提出了一种名为JADE的两层评估框架，用于评估开放式专业任务中的AI代理，该框架结合了预定义的评估技能和针对具体报告的、基于声明的评估，以提高评估的稳定性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 评估在开放式专业任务中的AI代理面临着严格性和灵活性的困境：静态评分标准过于死板，而基于LLM的评估则不稳定且有偏见。研究人员受到人类专家评估方式的启发，试图找到一种折衷方案。

Method: JADE框架分为两层：第一层将专家知识编码为一组评估技能，提供稳定的评估标准；第二层进行报告特定的、基于声明的评估，允许评估不同的推理策略，并使用证据依赖性门控来识别基于被驳斥声明的无效结论。

Result: 在BizBench上的实验表明，JADE提高了评估的稳定性，并发现了独立的LLM评估方法未能捕捉到的关键AI故障模式。此外，JADE与专家制定的评分标准高度一致，并能有效地迁移到医学领域的基准测试中。

Conclusion: JADE是一个有效的两层评估框架，能够灵活且稳定地评估AI代理在开放式专业任务中的表现，并能跨领域通用。

Abstract: Evaluating agentic AI on open-ended professional tasks faces a fundamental dilemma between rigor and flexibility. Static rubrics provide rigorous, reproducible assessment but fail to accommodate diverse valid response strategies, while LLM-as-a-judge approaches adapt to individual responses yet suffer from instability and bias. Human experts address this dilemma by combining domain-grounded principles with dynamic, claim-level assessment. Inspired by this process, we propose JADE, a two-layer evaluation framework. Layer 1 encodes expert knowledge as a predefined set of evaluation skills, providing stable evaluation criteria. Layer 2 performs report-specific, claim-level evaluation to flexibly assess diverse reasoning strategies, with evidence-dependency gating to invalidate conclusions built on refuted claims. Experiments on BizBench show that JADE improves evaluation stability and reveals critical agent failure modes missed by holistic LLM-based evaluators. We further demonstrate strong alignment with expert-authored rubrics and effective transfer to a medical-domain benchmark, validating JADE across professional domains. Our code is publicly available at https://github.com/smiling-world/JADE.

</details>


### [12] [Progress Constraints for Reinforcement Learning in Behavior Trees](https://arxiv.org/abs/2602.06525)
*Finn Rietz,Mart Kartašev,Johannes A. Stork,Petter Ögren*

Main category: cs.AI

TL;DR: 本文提出了一种结合行为树（BT）和强化学习（RL）的新方法，通过引入“进展约束”来解决直接结合两者可能导致的性能下降问题，实验证明该方法能提高性能、样本效率和约束满足度。


<details>
  <summary>Details</summary>
Motivation: 现有的行为树（BT）在基于环境条件切换子控制器方面表现良好，而强化学习（RL）能学习近乎最优的控制器但存在稀疏奖励、安全探索和长期信用分配等问题。直接将 BT 和 RL 结合可能导致控制器互相抵消，影响整体性能，因此需要一种更优的整合方法。

Method: 提出了一种名为“进展约束”的新机制，利用可行性估计器根据理论上的 BT 收敛结果来约束允许的动作集合，从而指导 RL 学习。

Result: 在 2D 和高保真仓库环境的实证评估中，与以往的 BT-RL 集成方法相比，新方法在性能、样本效率和约束满足度方面均有所提高。

Conclusion: 进展约束是一种有效的新机制，可以解决 BT 和 RL 直接集成带来的性能问题，通过引入对动作集合的约束，可以实现更优的 BT-RL 协同学习。

Abstract: Behavior Trees (BTs) provide a structured and reactive framework for decision-making, commonly used to switch between sub-controllers based on environmental conditions. Reinforcement Learning (RL), on the other hand, can learn near-optimal controllers but sometimes struggles with sparse rewards, safe exploration, and long-horizon credit assignment. Combining BTs with RL has the potential for mutual benefit: a BT design encodes structured domain knowledge that can simplify RL training, while RL enables automatic learning of the controllers within BTs. However, naive integration of BTs and RL can lead to some controllers counteracting other controllers, possibly undoing previously achieved subgoals, thereby degrading the overall performance. To address this, we propose progress constraints, a novel mechanism where feasibility estimators constrain the allowed action set based on theoretical BT convergence results. Empirical evaluations in a 2D proof-of-concept and a high-fidelity warehouse environment demonstrate improved performance, sample efficiency, and constraint satisfaction, compared to prior methods of BT-RL integration.

</details>


### [13] [HyPER: Bridging Exploration and Exploitation for Scalable LLM Reasoning with Hypothesis Path Expansion and Reduction](https://arxiv.org/abs/2602.06527)
*Shengxuan Qiu,Haochen Huang,Shuzhang Zhong,Pengfei Zuo,Meng Li*

Main category: cs.AI

TL;DR: 提出了一种名为HyPER的训练无关型在线控制策略，用于混合专家模型的多路径解码，通过动态地在探索和利用之间进行权衡，提高了推理准确性，同时减少了计算量。


<details>
  <summary>Details</summary>
Motivation: 现有的多路径思维链方法在探索-利用权衡方面存在不足，要么过度探索导致冗余，要么探索规则僵化，无法适应后训练推理。作者观察到最优平衡是与阶段相关的，并且正确和错误的推理路径通常在后期才会分歧，这促使了对测试时计算扩展的新方法的研究。

Method: HyPER将测试时计算扩展重塑为一个基于假设池的动态扩展-规约控制问题。它包含一个在线控制器，该控制器根据假设池的演变，从探索转向利用；一个允许在生成时进行有效利用而无需重新采样整个路径的token级精炼机制；以及一个考虑长度和置信度的聚合策略，以实现可靠的答案利用。

Result: 在四个混合专家语言模型和多个推理基准上的实验表明，HyPER在准确性-计算权衡方面表现优越，准确率提高了8%到10%，同时token使用量减少了25%到40%。

Conclusion: HyPER是一种有效的训练无关型策略，能够动态地管理多路径解码中的计算资源，显著提高了推理任务的准确性，并降低了计算成本。

Abstract: Scaling test-time compute with multi-path chain-of-thought improves reasoning accuracy, but its effectiveness depends critically on the exploration-exploitation trade-off. Existing approaches address this trade-off in rigid ways: tree-structured search hard-codes exploration through brittle expansion rules that interfere with post-trained reasoning, while parallel reasoning over-explores redundant hypothesis paths and relies on weak answer selection. Motivated by the observation that the optimal balance is phase-dependent and that correct and incorrect reasoning paths often diverge only at late stages, we reformulate test-time scaling as a dynamic expand-reduce control problem over a pool of hypotheses. We propose HyPER, a training-free online control policy for multi-path decoding in mixture-of-experts models that reallocates computation under a fixed budget using lightweight path statistics. HyPER consists of an online controller that transitions from exploration to exploitation as the hypothesis pool evolves, a token-level refinement mechanism that enables efficient generation-time exploitation without full-path resampling, and a length- and confidence-aware aggregation strategy for reliable answer-time exploitation. Experiments on four mixture-of-experts language models across diverse reasoning benchmarks show that HyPER consistently achieves a superior accuracy-compute trade-off, improving accuracy by 8 to 10 percent while reducing token usage by 25 to 40 percent.

</details>


### [14] [LogicSkills: A Structured Benchmark for Formal Reasoning in Large Language Models](https://arxiv.org/abs/2602.06533)
*Brian Rabern,Philipp Mondorf,Barbara Plank*

Main category: cs.AI

TL;DR: 本研究提出了一个名为LogicSkills的基准测试，用于评估大型语言模型（LLM）在形式逻辑推理中的核心技能，包括符号化、反例构造和有效性判断。结果表明，LLM在有效性判断上表现良好，但在符号化和反例构造方面表现较差，表明它们可能依赖于表面模式而非真正的符号或规则推理。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在逻辑推理任务上表现出色，但对其掌握的核心逻辑技能尚不明确。研究旨在分离并评估LLM在形式推理中的三个基本技能。

Method: 研究设计了一个名为LogicSkills的统一基准测试，该测试包含三个核心技能：形式符号化（将前提转化为一阶逻辑）、反例构造（构建一个使前提为真而结论为假的模型）和有效性评估（判断结论是否从前提推导得出）。测试内容基于不含同一性的二阶一阶逻辑片段，并提供自然语言和包含新词的 Carroll 风格语言两种表达形式。所有实例均通过 SMT 求解器 Z3 验证了正确性和非平凡性。

Result: 在评估的领先模型中，LLM在有效性判断任务上的表现很高，但在符号化和反例构造任务上的表现显著较低。

Conclusion: LLM在逻辑推理中的高表现可能并非源于真正的符号推理或基于规则的推理能力，而是更多地依赖于对表面模式的学习。研究结果表明，LLM在符号化和反例构造等更深层次的逻辑技能上仍有待提高。

Abstract: Large language models have demonstrated notable performance across various logical reasoning benchmarks. However, it remains unclear which core logical skills they truly master. To address this, we introduce LogicSkills, a unified benchmark designed to isolate three fundamental skills in formal reasoning: (i) $\textit{formal symbolization}\unicode{x2014}$translating premises into first-order logic; (ii) $\textit{countermodel construction}\unicode{x2014}$formulating a finite structure in which all premises are true while the conclusion is false; and (iii) $\textit{validity assessment}\unicode{x2014}$deciding whether a conclusion follows from a given set of premises. Items are drawn from the two-variable fragment of first-order logic (without identity) and are presented in both natural English and a Carroll-style language with nonce words. All examples are verified for correctness and non-triviality using the SMT solver Z3. Across leading models, performance is high on validity but substantially lower on symbolization and countermodel construction, suggesting reliance on surface-level patterns rather than genuine symbolic or rule-based reasoning.

</details>


### [15] [AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research](https://arxiv.org/abs/2602.06540)
*Yishan Li,Wentong Chen,Yukun Yan,Mingwei Li,Sen Mei,Xiaorong Wang,Kunpeng Liu,Xin Cong,Shuo Wang,Zhong Zhang,Yaxi Lu,Zhenghao Liu,Yankai Lin,Zhiyuan Liu,Maosong Sun*

Main category: cs.AI

TL;DR: 提出了一种名为AgentCPM-Report的轻量级本地解决方案，用于生成深度研究报告，该方案通过Writing As Reasoning Policy (WARP)框架模仿人类写作过程，并采用8B参数的模型，通过多阶段智能体训练来克服现有方法的局限性，并在多个基准测试中超越了闭源模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在生成深度研究报告时面临挑战，因为这需要大规模信息获取和洞察驱动的分析。现有的“计划-然后-写”范式严重依赖初始大纲的质量，而大纲的构建本身就需要很强的推理能力。此外，依赖闭源或在线大模型存在部署障碍、安全和隐私问题。

Method: 提出AgentCPM-Report，一个包含框架和8B参数智能体的本地解决方案。框架采用Writing As Reasoning Policy (WARP)，允许模型在报告生成过程中动态修改大纲。智能体交替进行“基于证据的起草”和“推理驱动的深化”，支持信息获取、知识提炼和迭代式大纲演进。引入“多阶段智能体训练”策略，包括冷启动、原子技能强化学习和整体流水线强化学习。

Result: 在DeepResearch Bench、DeepConsult和DeepResearch Gym基准测试中，AgentCPM-Report的表现优于领先的闭源系统，尤其在“洞察力”方面取得了显著提升。

Conclusion: AgentCPM-Report是一种有效的轻量级本地解决方案，能够模仿人类写作过程，通过动态大纲修改和多阶段训练，使小型模型能够生成高质量的研究报告，并克服了当前大语言模型在深度研究报告生成方面的挑战。

Abstract: Generating deep research reports requires large-scale information acquisition and the synthesis of insight-driven analysis, posing a significant challenge for current language models. Most existing approaches follow a plan-then-write paradigm, whose performance heavily depends on the quality of the initial outline. However, constructing a comprehensive outline itself demands strong reasoning ability, causing current deep research systems to rely almost exclusively on closed-source or online large models. This reliance raises practical barriers to deployment and introduces safety and privacy concerns for user-authored data. In this work, we present AgentCPM-Report, a lightweight yet high-performing local solution composed of a framework that mirrors the human writing process and an 8B-parameter deep research agent. Our framework uses a Writing As Reasoning Policy (WARP), which enables models to dynamically revise outlines during report generation. Under this policy, the agent alternates between Evidence-Based Drafting and Reasoning-Driven Deepening, jointly supporting information acquisition, knowledge refinement, and iterative outline evolution. To effectively equip small models with this capability, we introduce a Multi-Stage Agentic Training strategy, consisting of cold-start, atomic skill RL, and holistic pipeline RL. Experiments on DeepResearch Bench, DeepConsult, and DeepResearch Gym demonstrate that AgentCPM-Report outperforms leading closed-source systems, with substantial gains in Insight.

</details>


### [16] [SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees](https://arxiv.org/abs/2602.06554)
*Tianyi Hu,Qingxu Fu,Yanxi Chen,Zhaoyang Liu,Bolin Ding*

Main category: cs.AI

TL;DR: 本文提出了SeeUPO，一种在多轮对话场景下具有收敛保证且无需 critic 的强化学习算法，解决了现有RL算法在LLM智能体训练中存在的收敛不稳定问题，并在实验中展现出显著的性能提升和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有用于训练LLM智能体的强化学习算法（如PPO）在多轮对话场景下缺乏收敛保证，导致训练不稳定和无法收敛到最优策略。这促使研究者们需要一种在多轮交互中既能保证收敛又不需要 critic 的方法。

Method: 本文首先分析了不同策略更新机制和优势估计方法在单/多轮场景下的收敛性，发现REINFORCE+GRAE可收敛到全局最优，但PPO+GRAE破坏了PPO的单调改进性质。随后，提出了一种名为SeeUPO（Sequence-level Sequential Update Policy Optimization）的全新算法。SeeUPO将多轮交互建模为顺序执行的多智能体老虎机问题，通过逆序进行基于反向归纳的逐轮策略更新，确保了单调改进和全局最优收敛。

Result: SeeUPO在AppWorld和BFCL v4基准测试中，相比于现有的主流RL算法，在Qwen3-14B模型上平均实现了43.3%-54.6%的相对性能提升，在Qwen2.5-14B模型上平均提升了24.1%-41.9%。此外，SeeUPO展现出更优越的训练稳定性。

Conclusion: SeeUPO是一种创新的、无需critic且具备收敛保证的多轮交互强化学习算法。它通过将多轮对话视为顺序多智能体问题并采用反向归纳更新策略，有效解决了现有算法的收敛性问题，并在实际应用中取得了显著的性能提升和稳定性。

Abstract: Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn settings, which can lead to training instability and failure to converge to optimal policies.
  In this paper, we systematically analyze how different combinations of policy update mechanisms and advantage estimation methods affect convergence properties in single/multi-turn scenarios. We find that REINFORCE with Group Relative Advantage Estimation (GRAE) can converge to the globally optimal under undiscounted conditions, but the combination of PPO & GRAE breaks PPO's original monotonic improvement property. Furthermore, we demonstrate that mainstream backbone RL algorithms cannot simultaneously achieve both critic-free and convergence guarantees in multi-turn scenarios.
  To address this, we propose SeeUPO (Sequence-level Sequential Update Policy Optimization), a critic-free approach with convergence guarantees for multi-turn interactions. SeeUPO models multi-turn interaction as sequentially executed multi-agent bandit problems. Through turn-by-turn sequential policy updates in reverse execution order, it ensures monotonic improvement and convergence to global optimal solution via backward induction.
  Experiments on AppWorld and BFCL v4 demonstrate SeeUPO's substantial improvements over existing backbone algorithms: relative gains of 43.3%-54.6% on Qwen3-14B and 24.1%-41.9% on Qwen2.5-14B (averaged across benchmarks), along with superior training stability.

</details>


### [17] [Same Answer, Different Representations: Hidden instability in VLMs](https://arxiv.org/abs/2602.06652)
*Farooq Ahmad Wani,Alessandro Suglia,Rohit Saxena,Aryo Pradipta Gema,Wai-Chung Kwan,Fazl Barez,Maria Sofia Bucarelli,Fabrizio Silvestri,Pasquale Minervini*

Main category: cs.AI

TL;DR: 研究提出了一个包含表示感知和频率感知的评估框架，用于评估视觉语言模型（VLMs）的鲁棒性。该框架测量内部嵌入漂移、频谱敏感性和结构平滑度，并发现当前VLMs存在三种失败模式：即使输出不变，内部表示也会发生显著漂移；模型规模增大并未提高鲁棒性；不同任务受扰动影响的方式不同。


<details>
  <summary>Details</summary>
Motivation: 现有对VLMs鲁棒性的评估方法主要依赖输出不变性，这隐含地假设稳定的预测反映了稳定的多模态处理。作者认为这种假设不足以全面评估VLMs的鲁棒性，因此提出了一个更全面的评估框架。

Method: 提出一个表示感知和频率感知的评估框架，该框架除了标准的基于标签的指标外，还测量内部嵌入漂移、频谱敏感性和结构平滑度（视觉标记的空间一致性）。该框架被应用于SEEDBench、MMMU和POPE数据集上的现代VLMs。

Result: 揭示了三种主要的失败模式：1. 模型在输出不变的情况下，内部表示会发生显著漂移，尤其是在文本叠加等扰动下，其漂移幅度接近于图像间变异性，表明表示移动到通常由不相关输入占据的区域。2. 鲁棒性不随模型规模的增加而提高，更大的模型虽然准确率更高，但表现出相同或更大的敏感性，这与更尖锐但更脆弱的决策边界一致。3. 扰动对不同任务的影响不同：当扰动破坏模型组合粗细视觉线索的方式时，会损害推理能力；而在幻觉基准测试中，扰动可以通过使模型产生更保守的答案来减少假阳性。

Conclusion: 现有的鲁棒性评估方法可能不足以捕捉VLMs的真实鲁棒性。VLMs在应对扰动时存在表示漂移、对规模不敏感以及对不同任务影响差异的固有问题，这些问题需要进一步的研究和改进。

Abstract: The robustness of Vision Language Models (VLMs) is commonly assessed through output-level invariance, implicitly assuming that stable predictions reflect stable multimodal processing. In this work, we argue that this assumption is insufficient. We introduce a representation-aware and frequency-aware evaluation framework that measures internal embedding drift, spectral sensitivity, and structural smoothness (spatial consistency of vision tokens), alongside standard label-based metrics. Applying this framework to modern VLMs across the SEEDBench, MMMU, and POPE datasets reveals three distinct failure modes. First, models frequently preserve predicted answers while undergoing substantial internal representation drift; for perturbations such as text overlays, this drift approaches the magnitude of inter-image variability, indicating that representations move to regions typically occupied by unrelated inputs despite unchanged outputs. Second, robustness does not improve with scale; larger models achieve higher accuracy but exhibit equal or greater sensitivity, consistent with sharper yet more fragile decision boundaries. Third, we find that perturbations affect tasks differently: they harm reasoning when they disrupt how models combine coarse and fine visual cues, but on the hallucination benchmarks, they can reduce false positives by making models generate more conservative answers.

</details>


### [18] [Autoregressive Models for Knowledge Graph Generation](https://arxiv.org/abs/2602.06707)
*Thiviyan Thanapalasingam,Antonis Vozikis,Peter Bloem,Paul Groth*

Main category: cs.AI

TL;DR: ARK是一种自回归模型，通过将知识图谱视为三元组序列来生成知识图谱，能自动学习领域语义约束。SAIL是ARK的变分扩展，支持可控生成。ARK模型在IntelliGraphs基准上表现出色，显示模型容量比深度更重要。


<details>
  <summary>Details</summary>
Motivation: 传统的知识图谱生成模型在处理复杂语义依赖和领域约束方面存在挑战，需要显式规则监督。本研究旨在开发一种能够从数据中自动学习这些约束的生成模型。

Method: 提出了ARK（Auto-Regressive Knowledge Graph Generation）模型，将知识图谱视为三元组序列进行自回归生成。ARK能隐式学习类型一致性、时间有效性和关系模式等语义约束。此外，还提出了SAIL（Variational ARK），一个基于学习到的潜在表示的可控生成模型。

Result: ARK模型在IntelliGraphs基准上实现了89.2%至100.0%的语义有效性，并能生成训练集中未出现过的新知识图谱。SAIL支持无条件采样和条件补全。研究发现，模型容量（隐藏维度>=64）比架构深度对知识图谱生成更重要，循环架构与Transformer在有效性上相当，但计算效率更高。

Conclusion: 自回归模型框架能够有效地生成知识图谱，并能自动学习复杂的语义约束。ARK和SAIL模型在生成具有高语义有效性的知识图谱方面表现出色，在知识库补全和查询回答等领域具有实际应用价值。

Abstract: Knowledge Graph (KG) generation requires models to learn complex semantic dependencies between triples while maintaining domain validity constraints. Unlike link prediction, which scores triples independently, generative models must capture interdependencies across entire subgraphs to produce semantically coherent structures. We present ARK (Auto-Regressive Knowledge Graph Generation), a family of autoregressive models that generate KGs by treating graphs as sequences of (head, relation, tail) triples. ARK learns implicit semantic constraints directly from data, including type consistency, temporal validity, and relational patterns, without explicit rule supervision. On the IntelliGraphs benchmark, our models achieve 89.2% to 100.0% semantic validity across diverse datasets while generating novel graphs not seen during training. We also introduce SAIL, a variational extension of ARK that enables controlled generation through learned latent representations, supporting both unconditional sampling and conditional completion from partial graphs. Our analysis reveals that model capacity (hidden dimensionality >= 64) is more critical than architectural depth for KG generation, with recurrent architectures achieving comparable validity to transformer-based alternatives while offering substantial computational efficiency. These results demonstrate that autoregressive models provide an effective framework for KG generation, with practical applications in knowledge base completion and query answering.

</details>


### [19] [Semantically Labelled Automata for Multi-Task Reinforcement Learning with LTL Instructions](https://arxiv.org/abs/2602.06746)
*Alessandro Abate,Giuseppe De Giacomo,Mathias Jackermeier,Jan Kretínský,Maximilian Prokop,Christoph Weinhuber*

Main category: cs.AI

TL;DR: 研究了多任务强化学习（RL），提出了一种新的基于LTL公式到语义自动机的嵌入技术，用于条件化策略，并在复杂场景中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了在多任务RL中实现一个能够泛化到任意（可能未见过）任务的单一通用策略，并解决现有方法在复杂LTL规范下的局限性。

Method: 提出了一种新的任务嵌入技术，利用新一代的LTL到语义自动机翻译。这种方法可以高效地实时计算自动机，提取用于条件化策略的表达性任务嵌入，并自然支持完整的LTL。

Result: 在多个领域进行了实验，证明了该方法在复杂规范下取得了最先进的性能，并且能够扩展到现有方法难以处理的场景。

Conclusion: 所提出的基于LTL到语义自动机嵌入的技术是一种有效的方法，可以提高多任务RL中策略的泛化能力和性能，尤其是在处理复杂的LTL规范时。

Abstract: We study multi-task reinforcement learning (RL), a setting in which an agent learns a single, universal policy capable of generalising to arbitrary, possibly unseen tasks. We consider tasks specified as linear temporal logic (LTL) formulae, which are commonly used in formal methods to specify properties of systems, and have recently been successfully adopted in RL. In this setting, we present a novel task embedding technique leveraging a new generation of semantic LTL-to-automata translations, originally developed for temporal synthesis. The resulting semantically labelled automata contain rich, structured information in each state that allow us to (i) compute the automaton efficiently on-the-fly, (ii) extract expressive task embeddings used to condition the policy, and (iii) naturally support full LTL. Experimental results in a variety of domains demonstrate that our approach achieves state-of-the-art performance and is able to scale to complex specifications where existing methods fail.

</details>


### [20] [Towards Understanding What State Space Models Learn About Code](https://arxiv.org/abs/2602.06774)
*Jiali Wu,Abhinav Anand,Shweta Verma,Mira Mezini*

Main category: cs.AI

TL;DR: 本文首次系统性地分析了 SSM 在代码理解任务上的学习机制，并与 Transformer 进行了比较。研究发现 SSM 在预训练阶段能更好地捕捉代码的语法和语义，但在微调阶段会遗忘部分语法和语义关系，尤其是在关注短程依赖的任务上。为此，本文提出了 SSM-Interpret 框架，揭示了微调过程中 SSM 存在向短程依赖偏移的频谱变化，并基于此提出了改进的 SSM 架构，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 尽管 SSM 在代码理解任务上表现出色，但其内部机制不透明，且与 Transformer 相比，其在微调阶段的性能下降问题尚未得到解释。

Method: 本文采用了系统性分析和比较的方法，评估了 SSM 和 Transformer 在代码理解任务上的表现。为了诊断 SSM 在微调阶段的问题，作者引入了一个名为 SSM-Interpret 的频域分析框架。

Result: SSM 在预训练阶段比 Transformer 更能捕捉代码的语法和语义。然而，在任务微调阶段，SSM 会遗忘部分语法和语义关系，特别是在强调短程依赖的任务上。SSM-Interpret 框架揭示了微调过程中 SSM 存在向短程依赖偏移的频谱变化。基于这些发现提出的架构修改显著提升了 SSM 代码模型的性能。

Conclusion: SSM 在代码理解方面具有潜力，但其在微调阶段的性能下降问题可以通过频域分析来诊断，并通过改进其架构来解决，从而获得更好的性能。

Abstract: State Space Models (SSMs) have emerged as an efficient alternative to the transformer architecture. Recent studies show that SSMs can match or surpass Transformers on code understanding tasks, such as code retrieval, when trained under similar conditions. However, their internal mechanisms remain a black box. We present the first systematic analysis of what SSM-based code models actually learn and perform the first comparative analysis of SSM and Transformer-based code models. Our analysis reveals that SSMs outperform Transformers at capturing code syntax and semantics in pretraining but forgets certain syntactic and semantic relations during fine-tuning on task, especially when the task emphasizes short-range dependencies. To diagnose this, we introduce SSM-Interpret, a frequency-domain framework that exposes a spectral shift toward short-range dependencies during fine-tuning. Guided by these findings, we propose architectural modifications that significantly improve the performance of SSM-based code model, validating that our analysis directly enables better models.

</details>


### [21] [ScaleEnv: Scaling Environment Synthesis from Scratch for Generalist Interactive Tool-Use Agent Training](https://arxiv.org/abs/2602.06820)
*Dunwei Tu,Hongyan Hao,Hansi Yang,Yihao Chen,Yi-Kai Zhang,Zhikang Xia,Yu Yang,Yueqing Sun,Xingchen Liu,Furao Shen,Qi Gu,Hui Su,Xunliang Cai*

Main category: cs.AI

TL;DR: ScaleEnv 是一个框架，用于生成多样化且可验证的交互式环境和任务，以训练通用的、能够适应不同场景的智能体，并在各种基准测试中证明了其优越的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的交互式环境稀缺且在多样性和可扩展性方面存在局限，这阻碍了通用智能体的训练。因此，需要一个能够生成丰富、可靠且可验证的环境和任务的框架。

Method: ScaleEnv 框架通过程序化测试来确保环境的可靠性，并通过工具依赖图扩展和可执行动作验证来保证任务的完整性和可解性。在此基础上，训练智能体在 ScaleEnv 中进行探索学习。

Result: 在 $τ^2$-Bench 和 VitaBench 等未见过、多轮的工具使用基准测试中，使用 ScaleEnv 训练的智能体表现出显著的性能提升和强大的泛化能力。此外，研究表明增加环境域的数量对于提升智能体的泛化性能至关重要。

Conclusion: ScaleEnv 框架有效地解决了现有交互式环境的不足，通过生成多样化且可验证的环境和任务，显著提升了通用智能体的泛化能力，并且强调了增加环境多样性对鲁棒智能体学习的重要性。

Abstract: Training generalist agents capable of adapting to diverse scenarios requires interactive environments for self-exploration. However, interactive environments remain critically scarce, and existing synthesis methods suffer from significant limitations regarding environmental diversity and scalability. To address these challenges, we introduce ScaleEnv, a framework that constructs fully interactive environments and verifiable tasks entirely from scratch. Specifically, ScaleEnv ensures environment reliability through procedural testing, and guarantees task completeness and solvability via tool dependency graph expansion and executable action verification. By enabling agents to learn through exploration within ScaleEnv, we demonstrate significant performance improvements on unseen, multi-turn tool-use benchmarks such as $τ^2$-Bench and VitaBench, highlighting strong generalization capabilities. Furthermore, we investigate the relationship between increasing number of domains and model generalization performance, providing empirical evidence that scaling environmental diversity is critical for robust agent learning.

</details>


### [22] [Wild Guesses and Mild Guesses in Active Concept Learning](https://arxiv.org/abs/2602.06818)
*Anirudh Chari,Neil Pattanaik*

Main category: cs.AI

TL;DR: 研究了一个神经符号贝叶斯学习器，它使用LLM生成假设并进行贝叶斯更新，并比较了两种主动学习策略：最大化预期信息增益（EIG）和人类偏好的正例测试策略（PTS）。结果表明，EIG在需要证伪复杂规则时有效，但在简单概念上表现不佳，原因在于与LLM的假设生成分布不匹配。PTS虽然信息量较低，但更适合简单概念，因为它倾向于选择“安全”的查询，从而避免了支持不匹配陷阱。


<details>
  <summary>Details</summary>
Motivation: 人类概念学习通常是主动的，需要平衡查询的信息量和学习者提出和评估假设的稳定性。研究者旨在探索在神经符号贝叶斯学习器中，主动学习策略在平衡信息量和假设稳定性方面的权衡。

Method: 研究者构建了一个神经符号贝叶斯学习器，其假设由大型语言模型（LLM）生成，并通过贝叶斯更新进行重新加权。他们比较了两种主动学习策略：一种是理性主动学习者，旨在最大化近似预期信息增益（EIG）；另一种是模拟人类的正例测试策略（PTS），即查询当前最佳假设下预测为正例的实例。实验在经典的数字游戏中进行。

Result: 在经典数字游戏的概念学习任务中，EIG在需要证伪（如复合规则或有例外规则）时表现有效，但在简单概念上表现不佳。EIG在简单概念上的失败归因于EIG策略与LLM的生成分布之间的支持不匹配：诊断性强的边界查询会使后验分布倾向于LLM生成无效或过于具体的程序的区域，导致粒子近似中出现支持不匹配陷阱。PTS虽然信息量次优，但通过选择“安全”的查询，倾向于维持生成器假设的有效性，从而在简单规则上实现更快的收敛。

Conclusion: 研究结果表明，“证实偏差”可能并非认知错误，而是为了在人类思维的稀疏、开放式假设空间中维持可处理的推理的一种理性适应。PTS策略在简单概念学习中表现更优，证明了在存在LLM生成假设的情况下，选择“安全”查询的重要性。

Abstract: Human concept learning is typically active: learners choose which instances to query or test in order to reduce uncertainty about an underlying rule or category. Active concept learning must balance informativeness of queries against the stability of the learner that generates and scores hypotheses. We study this trade-off in a neuro-symbolic Bayesian learner whose hypotheses are executable programs proposed by a large language model (LLM) and reweighted by Bayesian updating. We compare a Rational Active Learner that selects queries to maximize approximate expected information gain (EIG) and the human-like Positive Test Strategy (PTS) that queries instances predicted to be positive under the current best hypothesis. Across concept-learning tasks in the classic Number Game, EIG is effective when falsification is necessary (e.g., compound or exception-laden rules), but underperforms on simple concepts. We trace this failure to a support mismatch between the EIG policy and the LLM proposal distribution: highly diagnostic boundary queries drive the posterior toward regions where the generator produces invalid or overly specific programs, yielding a support-mismatch trap in the particle approximation. PTS is information-suboptimal but tends to maintain proposal validity by selecting "safe" queries, leading to faster convergence on simple rules. Our results suggest that "confirmation bias" may not be a cognitive error, but rather a rational adaptation for maintaining tractable inference in the sparse, open-ended hypothesis spaces characteristic of human thought.

</details>


### [23] [POP: Online Structural Pruning Enables Efficient Inference of Large Foundation Models](https://arxiv.org/abs/2602.06822)
*Yi Chen,Wonjin Shin,Shuhong Liu,Tho Mai,Jeongmo Lee,Chuanbo Hua,Kun Wang,Jun Liu,Joo-Young Kim*

Main category: cs.AI

TL;DR: 提出了一种名为POP（Partition-guided Online Pruning）的高效在线结构化剪枝框架，它能够在推理过程中根据上下文动态调整模型剪枝，以解决现有静态剪枝方法忽略自回归生成过程中稀疏性模式的问题。POP通过预填充和解码阶段生成动态掩码，实现了计算开销最小化的上下文条件动态剪枝。


<details>
  <summary>Details</summary>
Motivation: 现有的结构化剪枝方法在推理时做出固定的剪枝决策，未能捕捉自回归 token 生成过程中出现的稀疏性模式，导致模型性能受限。

Method: POP将模型通道划分为保留、候选和剪枝区域。预填充阶段确定粗粒度剪枝分区，解码阶段在候选区域内生成细粒度掩码，避免了对整个通道进行重新评估。该方法无需预处理、离线校准、重新训练或学习预测器，具有即插即用性。

Result: 在大型语言模型（LLMs）、混合专家模型（MoEs）和视觉语言模型（VLMs）等多种LFMs上的广泛评估表明，POP能够始终提供比现有剪枝方法更高的准确性，同时带来更小的计算开销和更低的推理延迟。

Conclusion: POP是一种轻量级、即插即用的在线结构化剪枝框架，能够根据上下文进行动态剪枝，并且在不牺牲准确性的前提下显著降低计算开销和推理延迟，适用于各种大型基础模型。

Abstract: Large foundation models (LFMs) achieve strong performance through scaling, yet current structural pruning methods derive fixed pruning decisions during inference, overlooking sparsity patterns that emerge in the autoregressive token generation. In this paper, we propose POP (Partition-guided Online Pruning), an efficient online structural pruning framework that enables context-conditioned dynamic pruning with minimal computational overhead. POP partitions model channels into retained, candidate, and pruned regions, where prefilling defines a coarse pruning partition, and the decoding stage generates a fine-grained mask within the candidate region, avoiding full-channel re-evaluation. The coarse pruning partition preserves consistently important weights, while the fine-grained masking provides context-conditioned variation during decoding. Moreover, POP is a lightweight, plug-and-play method that requires no preprocessing, including offline calibration, retraining, or learning predictors. Extensive evaluations across diverse LFMs, including large language models (LLMs), mixture-of-experts models (MoEs), and vision-language models (VLMs), demonstrate that POP consistently delivers higher accuracy than existing pruning approaches while incurring smaller computational overhead and minimizing inference latency.

</details>


### [24] [An Adaptive Differentially Private Federated Learning Framework with Bi-level Optimization](https://arxiv.org/abs/2602.06838)
*Jin Wang,Hui Ma,Fei Xing,Ming Yan*

Main category: cs.AI

TL;DR: 本文提出了一种自适应差分隐私联邦学习框架，通过轻量级本地压缩、自适应梯度裁剪和约束感知聚合，提高了模型在异构和隐私限制下的效率、收敛稳定性和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习在设备异构和非IID数据环境下存在梯度更新不稳定和偏差问题，而差分隐私的引入会加剧梯度扰动，导致训练振荡和性能下降。因此，需要一个能够应对这些挑战的自适应差分隐私联邦学习框架。

Method: 1. 客户端：引入轻量级本地压缩模块，正则化中间表示，约束梯度变异性，减少局部优化中的噪声放大。2. 服务器端：采用自适应梯度裁剪策略，根据历史更新统计动态调整裁剪阈值，避免过度裁剪和噪声主导。3. 设计约束感知聚合机制，抑制不可靠或受噪声影响的客户端更新，稳定全局优化。

Result: 通过在CIFAR-10和SVHN数据集上的大量实验，证明了所提出的框架在收敛稳定性和分类准确性方面有所提升。

Conclusion: 所提出的自适应差分隐私联邦学习框架能够有效解决设备异构、非IID数据和差分隐私带来的挑战，在效率、稳定性和准确性方面表现优越。

Abstract: Federated learning enables collaborative model training across distributed clients while preserving data privacy. However, in practical deployments, device heterogeneity, non-independent, and identically distributed (Non-IID) data often lead to highly unstable and biased gradient updates. When differential privacy is enforced, conventional fixed gradient clipping and Gaussian noise injection may further amplify gradient perturbations, resulting in training oscillation and performance degradation and degraded model performance. To address these challenges, we propose an adaptive differentially private federated learning framework that explicitly targets model efficiency under heterogeneous and privacy-constrained settings. On the client side, a lightweight local compressed module is introduced to regularize intermediate representations and constrain gradient variability, thereby mitigating noise amplification during local optimization. On the server side, an adaptive gradient clipping strategy dynamically adjusts clipping thresholds based on historical update statistics to avoid over-clipping and noise domination. Furthermore, a constraint-aware aggregation mechanism is designed to suppress unreliable or noise-dominated client updates and stabilize global optimization. Extensive experiments on CIFAR-10 and SVHN demonstrate improved convergence stability and classification accuracy.

</details>


### [25] [LLM Active Alignment: A Nash Equilibrium Perspective](https://arxiv.org/abs/2602.06836)
*Tonghan Wang,Yuqi Pan,Xinyi Yang,Yanchen Jiang,Milind Tambe,David C. Parkes*

Main category: cs.AI

TL;DR: 研究提出了一种基于博弈论的框架，通过纳什均衡分析来预测和引导大型语言模型（LLM）群体行为，以避免在开放文本空间中计算均衡的困难，并提出了一种将LLM的策略限制在与人类子群体对齐的方式，从而实现可解释的、实质性的政策。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的对齐方法可能无法完全控制其群体行为，尤其是在开放文本空间中，可能出现诸如政治排斥等病态现象。研究旨在开发一种更具可控性和可解释性的方法来引导LLM群体行为，并解决这些潜在问题。

Method: 研究构建了一个博弈论框架，将LLM的行动建模为与人类子群体混合对齐。通过纳什均衡分析，推导出封闭形式的均衡特征，并利用标准的凹函数效用假设，进行系统级预测，并为引导对齐目标到社会期望结果提供明确的指导。该方法被设计为一个主动对齐层，可以叠加在现有的对齐流程（如RLHF）之上。

Result: 在社交媒体环境中，研究发现LLM群体（尤其是基于推理的模型）可能出现政治排斥现象，即某些子群体被所有LLM代理忽略。所提出的方法能够避免这种病态行为，并通过调整对齐目标来将LLM的行为导向更符合社会期望的输出。

Conclusion: 该研究提出的博弈论框架和纳什均衡分析方法，能够有效地预测和引导LLM群体行为，避免出现如政治排斥等负面现象，并为将LLM的行为导向社会期望结果提供了可操作的指导。该方法在调节多智能体LLM动态方面展现出巨大潜力，可应用于不同领域。

Abstract: We develop a game-theoretic framework for predicting and steering the behavior of populations of large language models (LLMs) through Nash equilibrium (NE) analysis. To avoid the intractability of equilibrium computation in open-ended text spaces, we model each agent's action as a mixture over human subpopulations. Agents choose actively and strategically which groups to align with, yielding an interpretable and behaviorally substantive policy class. We derive closed-form NE characterizations, adopting standard concave-utility assumptions to enable analytical system-level predictions and give explicit, actionable guidance for shifting alignment targets toward socially desirable outcomes. The method functions as an active alignment layer on top of existing alignment pipelines such as RLHF. In a social-media setting, we show that a population of LLMs, especially reasoning-based models, may exhibit political exclusion, pathologies where some subpopulations are ignored by all LLM agents, which can be avoided by our method, illustrating the promise of applying the method to regulate multi-agent LLM dynamics across domains.

</details>


### [26] [From Features to Actions: Explainability in Traditional and Agentic AI Systems](https://arxiv.org/abs/2602.06841)
*Sindhuja Chaduvula,Jessee Ho,Kina Kim,Aravind Narayanan,Mahshid Alinoori,Muskan Garg,Dhanesh Ramachandram,Shaina Raza*

Main category: cs.AI

TL;DR: 本文比较了用于静态模型预测的归因方法和用于多步决策的代理 AI 系统的轨迹诊断方法。研究发现，归因方法不适用于代理系统，而轨迹诊断方法能有效识别行为中断。文章呼吁将解释性研究的重点从单个预测转移到整个决策轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有解释性 AI 方法主要关注对单个模型预测的解释，而大型语言模型（LLM）催生的代理 AI 系统行为是动态的、多步骤的。如何将静态解释方法应用于代理系统，以及如何有效诊断这些系统的失败原因，是亟待解决的问题。

Method: 文章通过实证研究，将用于静态分类任务的归因解释方法与用于代理基准测试（TAU-bench Airline 和 AssistantBench）的轨迹诊断方法进行了比较。使用了 Spearman 秩相关系数来评估静态设置下的特征排名稳定性，并分析了代理设置下失败运行中行为中断的发生率和对成功概率的影响。

Result: 在静态设置下，归因方法实现了稳定的特征排名（Spearman $ρ= 0.86$）。然而，这些方法无法可靠地诊断代理轨迹中的执行级失败。相反，轨迹驱动的评分评估方法能一致地定位行为中断，并发现状态跟踪不一致在失败运行中更为普遍（2.7倍），且成功概率降低了 49%。

Conclusion: 研究表明，对于代理 AI 系统，需要从单个预测的解释转向整个决策轨迹的解释性分析。轨迹级别的诊断方法在理解和改进代理 AI 行为方面比传统的归因方法更有效。

Abstract: Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate inputs to outputs under a fixed decision structure. Recent advances in large language models (LLMs) have enabled agentic AI systems whose behaviour unfolds over multi-step trajectories. In these settings, success and failure are determined by sequences of decisions rather than a single output. While useful, it remains unclear how explanation approaches designed for static predictions translate to agentic settings where behaviour emerges over time. In this work, we bridge the gap between static and agentic explainability by comparing attribution-based explanations with trace-based diagnostics across both settings. To make this distinction explicit, we empirically compare attribution-based explanations used in static classification tasks with trace-based diagnostics used in agentic benchmarks (TAU-bench Airline and AssistantBench). Our results show that while attribution methods achieve stable feature rankings in static settings (Spearman $ρ= 0.86$), they cannot be applied reliably to diagnose execution-level failures in agentic trajectories. In contrast, trace-grounded rubric evaluation for agentic settings consistently localizes behaviour breakdowns and reveals that state tracking inconsistency is 2.7$\times$ more prevalent in failed runs and reduces success probability by 49\%. These findings motivate a shift towards trajectory-level explainability for agentic systems when evaluating and diagnosing autonomous AI behaviour.
  Resources:
  https://github.com/VectorInstitute/unified-xai-evaluation-framework https://vectorinstitute.github.io/unified-xai-evaluation-framework

</details>


### [27] [AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents](https://arxiv.org/abs/2602.06855)
*Alisia Lupidi,Bhavul Gauri,Thomas Simon Foster,Bassel Al Omari,Despoina Magka,Alberto Pepe,Alexis Audran-Reiss,Muna Aghamelu,Nicolas Baldwin,Lucia Cipolina-Kun,Jean-Christophe Gagnon-Audet,Chee Hau Leow,Sandra Lefdal,Hossam Mossalam,Abhinav Moudgil,Saba Nazir,Emanuel Tewolde,Isabel Urrego,Jordi Armengol Estape,Amar Budhiraja,Gaurav Chaurasia,Abhishek Charnalia,Derek Dunfield,Karen Hambardzumyan,Daniel Izcovich,Martin Josifoski,Ishita Mediratta,Kelvin Niu,Parth Pathak,Michael Shvartsman,Edan Toledo,Anton Protopopov,Roberta Raileanu,Alexander Miller,Tatiana Shavrina,Jakob Foerster,Yoram Bachrach*

Main category: cs.AI

TL;DR: 本文提出了AIRS-Bench，一个包含20个来自前沿机器学习论文的任务的基准测试，用于评估LLM代理在整个科学研究生命周期中的能力。结果显示，代理在部分任务上超越了人类SOTA，但在大多数任务上仍有差距，表明该基准测试有很大的改进空间。


<details>
  <summary>Details</summary>
Motivation: 为了加速LLM代理在科学研究中的进步，需要一个能够评估其在整个研究生命周期中能力的基准测试。

Method: 创建了AIRS-Bench，包含20个跨越不同领域的科学研究任务，评估代理在想法生成、实验分析和迭代改进等方面的能力，不提供基线代码。使用前沿模型配合顺序和并行框架建立基线。

Result: 在20个任务中，LLM代理在4个任务上超过了人类SOTA，但在16个任务上未能达到。即使在超过人类基准的任务中，代理也未达到理论上的性能上限。

Conclusion: AIRS-Bench是一个有价值的工具，可以评估LLM代理在科学研究中的能力，并指出了当前代理存在的局限性。该基准测试远未饱和，为未来研究提供了广阔的空间。通过开源任务定义和评估代码，旨在促进自主科学研究的发展。

Abstract: LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling, mathematics, bioinformatics, and time series forecasting. AIRS-Bench tasks assess agentic capabilities over the full research lifecycle -- including idea generation, experiment analysis and iterative refinement -- without providing baseline code. The AIRS-Bench task format is versatile, enabling easy integration of new tasks and rigorous comparison across different agentic frameworks. We establish baselines using frontier models paired with both sequential and parallel scaffolds. Our results show that agents exceed human SOTA in four tasks but fail to match it in sixteen others. Even when agents surpass human benchmarks, they do not reach the theoretical performance ceiling for the underlying tasks. These findings indicate that AIRS-Bench is far from saturated and offers substantial room for improvement. We open-source the AIRS-Bench task definitions and evaluation code to catalyze further development in autonomous scientific research.

</details>


### [28] [Agentic Uncertainty Reveals Agentic Overconfidence](https://arxiv.org/abs/2602.06948)
*Jean Kaddour,Srijan Patel,Gbètondji Dovonon,Leo Richter,Pasquale Minervini,Matt J. Kusner*

Main category: cs.AI

TL;DR: 研究AI代理的“代理不确定性”，发现AI在任务执行前、中、后都表现出过度自信。令人惊讶的是，在执行前评估（信息较少）比执行后评估（信息较多）具有更好的区分度。将评估重构为“找Bug”的对抗性提示能获得最佳校准。


<details>
  <summary>Details</summary>
Motivation: 研究AI代理在执行任务时对其自身成功概率的评估能力（代理不确定性），特别是AI是否能准确预测自己能否成功完成任务。

Method: 通过在任务执行前、中、后三个阶段向AI代理“诱导”其对成功概率进行估计，并分析这些估计的准确性和校准度。同时，测试了“对抗性提示”（将评估重构为找Bug）对校准度的影响。

Result: 所有AI代理都表现出“过度自信”（agentic overconfidence），即实际成功率远低于其预测的成功率（例如，实际成功率22%时，预测成功率77%）。在某些情况下，执行前评估比执行后评估能更好地辨别代理的能力。对抗性提示方法能获得最佳的校准度。

Conclusion: AI代理在评估自身任务成功概率方面存在显著的过度自信问题。执行前评估策略可能比执行后评估在区分代理能力方面更有效。通过对抗性提示将评估任务重构为“找Bug”是提高AI代理校准度的有效方法。

Abstract: Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination than standard post-execution review, though differences are not always significant. Adversarial prompting reframing assessment as bug-finding achieves the best calibration.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [29] [From Blurry to Believable: Enhancing Low-quality Talking Heads with 3D Generative Priors](https://arxiv.org/abs/2602.06122)
*Ding-Jiun Huang,Yuanhao Wang,Shao-Ji Yuan,Albert Mosella-Montoro,Francisco Vicente Carrasco,Cheng Zhang,Fernando De la Torre*

Main category: cs.CV

TL;DR: SuperHead 是一个新框架，用于增强低分辨率、可动画化的 3D 头像，通过利用预训练的 3D 生成模型的先验知识，并采用动态感知 3D 逆转方案，以生成高保真度的 3D 高斯喷溅头像，并能进行动画。


<details>
  <summary>Details</summary>
Motivation: 现有的 3D 头像创建技术常因低质量的输入源而受限，导致 3D 重建效果不佳。现有的超分辨率技术难以处理动态 3D 输入。

Method: SuperHead 利用预训练的 3D 生成模型，通过新颖的动态感知 3D 逆转方案来优化潜在表示，生成超分辨率的 3D 高斯喷溅（3DGS）头部模型，并将其绑定到参数化头部模型（如 FLAME）进行动画。该逆转过程受到稀疏的 2D 面部渲染和对应深度图的联合监督，以确保动态面部运动下的真实性。

Result: SuperHead 能够生成具有细致面部细节和动态运动的 3D 头像，在视觉质量上显著优于基线方法。

Conclusion: SuperHead 能够有效提升低分辨率 3D 头像的质量，并在动态动画和身份保持方面表现出色，克服了现有技术的局限性。

Abstract: Creating high-fidelity, animatable 3D talking heads is crucial for immersive applications, yet often hindered by the prevalence of low-quality image or video sources, which yield poor 3D reconstructions. In this paper, we introduce SuperHead, a novel framework for enhancing low-resolution, animatable 3D head avatars. The core challenge lies in synthesizing high-quality geometry and textures, while ensuring both 3D and temporal consistency during animation and preserving subject identity. Despite recent progress in image, video and 3D-based super-resolution (SR), existing SR techniques are ill-equipped to handle dynamic 3D inputs. To address this, SuperHead leverages the rich priors from pre-trained 3D generative models via a novel dynamics-aware 3D inversion scheme. This process optimizes the latent representation of the generative model to produce a super-resolved 3D Gaussian Splatting (3DGS) head model, which is subsequently rigged to an underlying parametric head model (e.g., FLAME) for animation. The inversion is jointly supervised using a sparse collection of upscaled 2D face renderings and corresponding depth maps, captured from diverse facial expressions and camera viewpoints, to ensure realism under dynamic facial motions. Experiments demonstrate that SuperHead generates avatars with fine-grained facial details under dynamic motions, significantly outperforming baseline methods in visual quality.

</details>


### [30] [EgoAVU: Egocentric Audio-Visual Understanding](https://arxiv.org/abs/2602.06139)
*Ashish Seth,Xinhao Mei,Changsheng Zhao,Varun Nagaraja,Ernie Chang,Gregory P. Meyer,Gael Le Lan,Yunyang Xiong,Vikas Chandra,Yangyang Shi,Dinesh Manocha,Zhipeng Cai*

Main category: cs.CV

TL;DR: 本研究提出了EgoAVU数据引擎，用于自动生成第一人称视频的视听叙述、问答数据，构建了EgoAVU-Instruct数据集和EgoAVU-Bench评估集。实验表明现有MLLM在理解第一人称视频时偏重视觉信息，忽略音频，而使用EgoAVU-Instruct进行微调能显著提升模型在EgoAVU-Bench及其他相关任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在理解第一人称视频时，由于缺乏包含连贯联合模态信息的文本标签，对于同时理解视频和音频模态的能力仍未得到充分探索。

Method: 提出EgoAVU数据引擎，通过跨模态相关性建模，自动化生成第一人称视频的音频-视频叙述、问答。通过基于Token的视频过滤和基于图的策展来确保数据的多样性和质量。基于EgoAVU构建了300万样本的EgoAVU-Instruct训练数据集和手动验证的EgoAVU-Bench评估集。

Result: EgoAVU-Bench评估集揭示了现有MLLM在理解第一人称视频时存在偏重视觉信号、忽略音频或音频与视觉源不匹配的问题。使用EgoAVU-Instruct进行微调，模型在EgoAVU-Bench上的性能提升高达113%。在EgoTempo和EgoIllusion等其他基准测试上，性能也相对提升高达28%。

Conclusion: EgoAVU数据引擎能够有效地生成高质量的第一人称视频视听数据，并能通过EgoAVU-Instruct数据集显著提升MLLM在第一人称视频理解任务上的表现，解决现有模型在联合模态理解上的不足。

Abstract: Understanding egocentric videos plays a vital role for embodied intelligence. Recent multi-modal large language models (MLLMs) can accept both visual and audio inputs. However, due to the challenge of obtaining text labels with coherent joint-modality information, whether MLLMs can jointly understand both modalities in egocentric videos remains under-explored. To address this problem, we introduce EgoAVU, a scalable data engine to automatically generate egocentric audio-visual narrations, questions, and answers. EgoAVU enriches human narrations with multimodal context and generates audio-visual narrations through cross-modal correlation modeling. Token-based video filtering and modular, graph-based curation ensure both data diversity and quality. Leveraging EgoAVU, we construct EgoAVU-Instruct, a large-scale training dataset of 3M samples, and EgoAVU-Bench, a manually verified evaluation split covering diverse tasks. EgoAVU-Bench clearly reveals the limitations of existing MLLMs: they bias heavily toward visual signals, often neglecting audio cues or failing to correspond audio with the visual source. Finetuning MLLMs on EgoAVU-Instruct effectively addresses this issue, enabling up to 113% performance improvement on EgoAVU-Bench. Such benefits also transfer to other benchmarks such as EgoTempo and EgoIllusion, achieving up to 28% relative performance gain. Code will be released to the community.

</details>


### [31] [MGP-KAD: Multimodal Geometric Priors and Kolmogorov-Arnold Decoder for Single-View 3D Reconstruction in Complex Scenes](https://arxiv.org/abs/2602.06158)
*Luoxi Zhang,Chun Xie,Itaru Kitahara*

Main category: cs.CV

TL;DR: 提出了一种名为MGP-KAD的多模态特征融合框架，结合RGB图像和几何先验，利用KAN解码器提升复杂场景下的单视角三维重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有单视角三维重建方法在复杂真实场景下，面临噪声、物体多样性和数据集稀缺等挑战。

Method: 提出了MGP-KAD框架，该框架融合RGB信息和通过聚类生成、动态调整的几何先验类特征。同时，采用基于Kolmogorov-Arnold Networks (KAN) 的混合解码器处理多模态输入。

Result: 在Pix3D数据集上，MGP-KAD实现了SOTA性能，显著提高了重建的几何完整性、平滑度和细节保留能力。

Conclusion: MGP-KAD为复杂场景下的单视角三维重建提供了一个鲁棒且有效的解决方案。

Abstract: Single-view 3D reconstruction in complex real-world scenes is challenging due to noise, object diversity, and limited dataset availability. To address these challenges, we propose MGP-KAD, a novel multimodal feature fusion framework that integrates RGB and geometric prior to enhance reconstruction accuracy. The geometric prior is generated by sampling and clustering ground-truth object data, producing class-level features that dynamically adjust during training to improve geometric understanding. Additionally, we introduce a hybrid decoder based on Kolmogorov-Arnold Networks (KAN) to overcome the limitations of traditional linear decoders in processing complex multimodal inputs. Extensive experiments on the Pix3D dataset demonstrate that MGP-KAD achieves state-of-the-art (SOTA) performance, significantly improving geometric integrity, smoothness, and detail preservation. Our work provides a robust and effective solution for advancing single-view 3D reconstruction in complex scenes.

</details>


### [32] [Driving with DINO: Vision Foundation Features as a Unified Bridge for Sim-to-Real Generation in Autonomous Driving](https://arxiv.org/abs/2602.06159)
*Xuyang Chen,Conglang Zhang,Chuanheng Fu,Zihao Yang,Kaixuan Zhou,Yizhi Zhang,Jianan He,Yanfeng Zhang,Mingwei Sun,Zengmao Wang,Zhen Dong,Xiaoxiao Long,Liqiu Meng*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Driving with DINO (DwD) 的新框架，利用 DINOv3 的视觉基础模块 (VFM) 特征作为模拟到真实世界域的统一桥梁，通过主成分子空间投影和随机通道丢弃来解决一致性-真实性困境，并引入了空间对齐模块和因果时间聚合器来提高控制精度和时间稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶视频生成方法（Sim2Real）在控制精度和真实性之间存在“一致性-真实性困境”，低级信号控制精度高但牺牲真实性，高级先验真实性好但缺乏细节。作者希望找到一种统一的方法来解决这个问题。

Method: 1. 提出使用 Vision Foundation Module (VFM) 特征作为统一的域桥梁，因为其包含从语义到结构的信息。 2. 采用主成分子空间投影（Principal Subspace Projection）去除导致“纹理烘焙”的高频成分。 3. 引入随机通道丢弃（Random Channel Tail Drop）来缓解降维带来的结构损失。 4. 引入可学习的空间对齐模块（Spatial Alignment Module）将高分辨率 DINO 特征适配到扩散骨干网络。 5. 提出因果时间聚合器（Causal Temporal Aggregator）利用因果卷积来聚合帧间 DINO 特征，保留历史运动信息，减少运动模糊，保证时间稳定性。

Result: 该方法成功地在保证真实性的同时，实现了对自动驾驶视频生成的精确控制，并且显著减少了运动模糊，提高了时间稳定性。

Conclusion: Driving with DINO (DwD) 框架通过利用 DINOv3 的 VFM 特征，并结合主成分子空间投影、随机通道丢弃、空间对齐模块和因果时间聚合器，有效地解决了现有 Sim2Real 方法的一致性-真实性困境，能够生成高质量、高控制精度且时间稳定的自动驾驶视频。

Abstract: Driven by the emergence of Controllable Video Diffusion, existing Sim2Real methods for autonomous driving video generation typically rely on explicit intermediate representations to bridge the domain gap. However, these modalities face a fundamental Consistency-Realism Dilemma. Low-level signals (e.g., edges, blurred images) ensure precise control but compromise realism by "baking in" synthetic artifacts, whereas high-level priors (e.g., depth, semantics, HDMaps) facilitate photorealism but lack the structural detail required for consistent guidance. In this work, we present Driving with DINO (DwD), a novel framework that leverages Vision Foundation Module (VFM) features as a unified bridge between the simulation and real-world domains. We first identify that these features encode a spectrum of information, from high-level semantics to fine-grained structure. To effectively utilize this, we employ Principal Subspace Projection to discard the high-frequency elements responsible for "texture baking," while concurrently introducing Random Channel Tail Drop to mitigate the structural loss inherent in rigid dimensionality reduction, thereby reconciling realism with control consistency. Furthermore, to fully leverage DINOv3's high-resolution capabilities for enhancing control precision, we introduce a learnable Spatial Alignment Module that adapts these high-resolution features to the diffusion backbone. Finally, we propose a Causal Temporal Aggregator employing causal convolutions to explicitly preserve historical motion context when integrating frame-wise DINO features, which effectively mitigates motion blur and guarantees temporal stability. Project page: https://albertchen98.github.io/DwD-project/

</details>


### [33] [MetaSSP: Enhancing Semi-supervised Implicit 3D Reconstruction through Meta-adaptive EMA and SDF-aware Pseudo-label Evaluation](https://arxiv.org/abs/2602.06163)
*Luoxi Zhang,Chun Xie,Itaru Kitahara*

Main category: cs.CV

TL;DR: MetaSSP是一种新颖的半监督框架，利用大量无标签图像来提高单视图3D重建的质量和可扩展性，并在Pix3D基准上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于隐式SDF的单视图3D重建方法虽然质量高，但需要大量有标签数据，这限制了其扩展性。因此，研究者希望利用丰富的无标签图像来改进这一方法。

Method: 该方法提出了一种半监督框架MetaSSP，该框架利用梯度来估计参数重要性，从而正则化自适应EMA更新，并引入了一个结合了增强一致性和SDF方差的SDF感知伪标签加权机制。该框架从10%的有监督预训练开始，然后联合优化有标签和无标签数据。

Result: 在Pix3D基准上，MetaSSP将Chamfer Distance降低了约20.61%，并将IoU提高了约24.09%，优于现有的半监督基线方法。

Conclusion: MetaSSP是一种有效的半监督学习框架，能够显著提高单视图3D重建的性能，为利用无标签数据进行3D重建提供了新的方向。

Abstract: Implicit SDF-based methods for single-view 3D reconstruction achieve high-quality surfaces but require large labeled datasets, limiting their scalability. We propose MetaSSP, a novel semi-supervised framework that exploits abundant unlabeled images. Our approach introduces gradient-based parameter importance estimation to regularize adaptive EMA updates and an SDF-aware pseudo-label weighting mechanism combining augmentation consistency with SDF variance. Beginning with a 10% supervised warm-up, the unified pipeline jointly refines labeled and unlabeled data. On the Pix3D benchmark, our method reduces Chamfer Distance by approximately 20.61% and increases IoU by around 24.09% compared to existing semi-supervised baselines, setting a new state of the art.

</details>


### [34] [M3: High-fidelity Text-to-Image Generation via Multi-Modal, Multi-Agent and Multi-Round Visual Reasoning](https://arxiv.org/abs/2602.06166)
*Bangji Yang,Ruihan Guo,Jiajun Fan,Chaoran Cheng,Ge Liu*

Main category: cs.CV

TL;DR: M3 是一个无需训练的框架，通过多智能体迭代推理来改进文本到图像生成，尤其擅长处理复杂的组合提示。它能够提升开源模型性能，超越商业模型。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型在处理包含多个约束的复杂组合提示时表现不佳。研究动机在于提升模型处理这类复杂任务的能力。

Method: M3 框架使用多智能体循环，包括 Planner（规划器）将提示分解为可验证的清单，Checker（检查器）、Refiner（精炼器）和 Editor（编辑器）智能体逐一修正约束，Verifier（验证器）确保性能单调提升。该框架无需重新训练，直接应用于现有的基础模型。

Result: M3 在 OneIG-EN 基准测试上取得了显著成果，使用 Qwen-Image+M3 的模型在性能上超越了 Imagen4 和 Seedream 3.0，达到了新的 SOTA 性能（0.532）。此外，M3 显著提高了 GenEval 组合度量，使空间推理性能翻倍。

Conclusion: M3 证明了智能多智能体推理可以使开源模型超越专有模型。作为一个即插即用的模块，M3 为无需昂贵再训练的组合生成提供了一种新范式。

Abstract: Generative models have achieved impressive fidelity in text-to-image synthesis, yet struggle with complex compositional prompts involving multiple constraints. We introduce \textbf{M3 (Multi-Modal, Multi-Agent, Multi-Round)}, a training-free framework that systematically resolves these failures through iterative inference-time refinement. M3 orchestrates off-the-shelf foundation models in a robust multi-agent loop: a Planner decomposes prompts into verifiable checklists, while specialized Checker, Refiner, and Editor agents surgically correct constraints one at a time, with a Verifier ensuring monotonic improvement. Applied to open-source models, M3 achieves remarkable results on the challenging OneIG-EN benchmark, with our Qwen-Image+M3 surpassing commercial flagship systems including Imagen4 (0.515) and Seedream 3.0 (0.530), reaching state-of-the-art performance (0.532 overall). This demonstrates that intelligent multi-agent reasoning can elevate open-source models beyond proprietary alternatives. M3 also substantially improves GenEval compositional metrics, effectively doubling spatial reasoning performance on hardened test sets. As a plug-and-play module compatible with any pre-trained T2I model, M3 establishes a new paradigm for compositional generation without costly retraining.

</details>


### [35] [Unsupervised Anomaly Detection of Diseases in the Female Pelvis for Real-Time MR Imaging](https://arxiv.org/abs/2602.06179)
*Anika Knupfer,Johanna P. Müller,Jordina A. Verdera,Martin Fenske,Claudius S. Mathy,Smiti Tripathy,Sebastian Arndt,Matthias May,Michael Uder,Matthias W. Beckmann,Stefanie Burghaus,Jana Hutter*

Main category: cs.CV

TL;DR: 提出了一种新颖的、不受疾病和参数限制的、实时兼容的盆腔 MRI 无监督异常检测框架，利用残差变分自编码器学习正常盆腔解剖结构，并生成重构误差热图来识别病变区域。


<details>
  <summary>Details</summary>
Motivation: 现有针对女性生殖年龄盆腔疾病的 AI 方法存在疾病特异性强、缺乏实时性，限制了其临床应用。该研究旨在克服这些限制，开发一种更通用、更实用的方法。

Method: 使用残差变分自编码器（Residual Variational Autoencoder）框架，仅在健康的矢状位 T2 加权盆腔 MRI 扫描上进行训练，以学习正常解剖结构。在推理阶段，通过重构误差热图来检测与正常结构相悖的异常区域。模型训练数据包括真实健康扫描和扩散模型生成的合成数据，以提高鲁棒性。

Result: 在子宫肌瘤 MRI 数据集上的定量评估中，平均 AUC 达到 0.736，敏感性为 0.828，特异性为 0.692。此外，通过对子宫内膜癌、子宫内膜异位症和子宫腺肌症的临床评估，揭示了解剖异质性和观察者间变异性对性能的影响。模型重构速度约为 92.6 帧/秒，支持实时应用。

Conclusion: 该框架为女性盆腔 MRI 的无监督异常检测提供了一个基准，其不受疾病和参数限制且兼容实时操作的特性，为未来集成到实时 MRI 提供了可能，并为相关领域的研究和临床应用奠定了基础。

Abstract: Pelvic diseases in women of reproductive age represent a major global health burden, with diagnosis frequently delayed due to high anatomical variability, complicating MRI interpretation. Existing AI approaches are largely disease-specific and lack real-time compatibility, limiting generalizability and clinical integration. To address these challenges, we establish a benchmark framework for disease- and parameter-agnostic, real-time-compatible unsupervised anomaly detection in pelvic MRI. The method uses a residual variational autoencoder trained exclusively on healthy sagittal T2-weighted scans acquired across diverse imaging protocols to model normal pelvic anatomy. During inference, reconstruction error heatmaps indicate deviations from learned healthy structure, enabling detection of pathological regions without labeled abnormal data. The model is trained on 294 healthy scans and augmented with diffusion-generated synthetic data to improve robustness. Quantitative evaluation on the publicly available Uterine Myoma MRI Dataset yields an average area-under-the-curve (AUC) value of 0.736, with 0.828 sensitivity and 0.692 specificity. Additional inter-observer clinical evaluation extends analysis to endometrial cancer, endometriosis, and adenomyosis, revealing the influence of anatomical heterogeneity and inter-observer variability on performance interpretation. With a reconstruction time of approximately 92.6 frames per second, the proposed framework establishes a baseline for unsupervised anomaly detection in the female pelvis and supports future integration into real-time MRI. Code is available upon request (https://github.com/AniKnu/UADPelvis), prospective data sets are available for academic collaboration.

</details>


### [36] [PhenoLIP: Integrating Phenotype Ontology Knowledge into Medical Vision-Language Pretraining](https://arxiv.org/abs/2602.06184)
*Cheng Liang,Chaoyi Wu,Weike Zhao,Ya Zhang,Yanfeng Wang,Weidi Xie*

Main category: cs.CV

TL;DR: 本文提出了PhenoLIP，一个结合了本体知识图谱（PhenoKG）的医学视觉语言模型（VLM）预训练框架，通过两阶段知识蒸馏来增强模型对医学表型的理解，并在新的基准测试PhenoBench上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的医学VLM主要依赖粗粒度的图像-文本对比学习，未能有效利用医学本体中编码的结构化视觉知识。

Method: 构建了PhenoKG，一个包含52万个图像-文本对和3000个表型的表型中心多模态知识图谱。提出了PhenoLIP预训练框架，通过两阶段：1）学习文本本体的知识增强表型嵌入空间；2）利用教师引导的知识蒸馏将结构化知识融入多模态预训练。

Result: PhenoLIP在表型分类准确率上比BiomedCLIP提升8.85%，在跨模态检索上比BIOMEDICA提升15.03%。

Conclusion: 将表型中心先验知识融入医学VLM可以提升其在结构化和可解释的医学图像理解能力。

Abstract: Recent progress in large-scale CLIP-like vision-language models(VLMs) has greatly advanced medical image analysis. However, most existing medical VLMs still rely on coarse image-text contrastive objectives and fail to capture the systematic visual knowledge encoded in well-defined medical phenotype ontologies. To address this gap, we construct PhenoKG, the first large-scale, phenotype-centric multimodal knowledge graph that encompasses over 520K high-quality image-text pairs linked to more than 3,000 phenotypes. Building upon PhenoKG, we propose PhenoLIP, a novel pretraining framework that explicitly incorporates structured phenotype knowledge into medical VLMs through a two-stage process. We first learn a knowledge-enhanced phenotype embedding space from textual ontology data and then distill this structured knowledge into multimodal pretraining via a teacher-guided knowledge distillation objective. To support evaluation, we further introduce PhenoBench, an expert-verified benchmark designed for phenotype recognition, comprising over 7,800 image--caption pairs covering more than 1,000 phenotypes. Extensive experiments demonstrate that PhenoLIP outperforms previous state-of-the-art baselines, improving upon BiomedCLIP in phenotype classification accuracy by 8.85\% and BIOMEDICA in cross-modal retrieval by 15.03%, underscoring the value of integrating phenotype-centric priors into medical VLMs for structured and interpretable medical image understanding.

</details>


### [37] [DeDPO: Debiased Direct Preference Optimization for Diffusion Models](https://arxiv.org/abs/2602.06195)
*Khiem Pham,Quang Nguyen,Tung Nguyen,Jingsen Zhu,Michele Santacatterina,Dimitris Metaxas,Ramin Zabih*

Main category: cs.CV

TL;DR: 本文提出了一种名为 DeDPO 的半监督框架，通过结合少量人类偏好标签和大量由人工智能生成的合成反馈，来克服 DPO 方法对大规模高质量人类标签的依赖。DeDPO 引入了来自因果推断的去偏估计技术，以纠正合成标注中的偏差和噪声，从而实现从不完美反馈源中稳健学习。实验证明，DeDPO 在使用合成监督的情况下，能够达到与完全人类标签数据训练的模型相当甚至更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 DPO 方法在对扩散模型进行对齐时，需要大量昂贵且难以获取的高质量人类偏好标签，这限制了其成本效益和可扩展性。为了解决这一瓶颈，研究者希望找到一种方法，能够利用成本更低的合成数据来辅助训练。

Method: 本文提出了 Debiased DPO (DeDPO) 框架，该框架结合了少量人类偏好数据和大量通过合成 AI 反馈标注的未标记数据。DeDPO 的核心创新在于将因果推断中的去偏估计技术融入 DPO 目标函数，以识别和修正合成标注器固有的系统性偏差和噪声。这种方法允许模型从不完美的合成反馈（包括自训练和视觉语言模型 VLM 的反馈）中进行稳健学习。

Result: 实验结果表明，DeDPO 对合成标签方法的差异具有鲁棒性。使用 DeDPO 训练的模型，其性能与完全使用人类标签数据训练的模型相当，甚至在某些情况下超越了理论上的最优性能。这证明了 DeDPO 作为一种使用廉价合成监督进行人类-AI 对齐的可扩展解决方案的有效性。

Conclusion: DeDPO 是一种有效的半监督对齐方法，通过利用合成 AI 反馈并结合去偏估计技术，克服了传统 DPO 对大规模人类偏好标签的依赖。该方法能够实现成本效益高且可扩展的人类-AI 对齐，在实际应用中具有重要价值。

Abstract: Direct Preference Optimization (DPO) has emerged as a predominant alignment method for diffusion models, facilitating off-policy training without explicit reward modeling. However, its reliance on large-scale, high-quality human preference labels presents a severe cost and scalability bottleneck. To overcome this, We propose a semi-supervised framework augmenting limited human data with a large corpus of unlabeled pairs annotated via cost-effective synthetic AI feedback. Our paper introduces Debiased DPO (DeDPO), which uniquely integrates a debiased estimation technique from causal inference into the DPO objective. By explicitly identifying and correcting the systematic bias and noise inherent in synthetic annotators, DeDPO ensures robust learning from imperfect feedback sources, including self-training and Vision-Language Models (VLMs). Experiments demonstrate that DeDPO is robust to the variations in synthetic labeling methods, achieving performance that matches and occasionally exceeds the theoretical upper bound of models trained on fully human-labeled data. This establishes DeDPO as a scalable solution for human-AI alignment using inexpensive synthetic supervision.

</details>


### [38] [AnyThermal: Towards Learning Universal Representations for Thermal Perception](https://arxiv.org/abs/2602.06203)
*Parv Maheshwari,Jay Karhade,Yogesh Chawla,Isaiah Adu,Florian Heisen,Andrew Porco,Andrew Jong,Yifei Liu,Santosh Pitla,Sebastian Scherer,Wenshan Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 AnyThermal 的通用热成像特征提取骨干网络，并辅以 TartanRGBT 数据集和采集平台，用于跨模态场景识别、热成像分割和单目深度估计等多种任务，并在多环境和多任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有热成像骨干网络通常基于特定任务的小规模数据进行训练，导致其适用性受限于特定环境和任务。研究旨在开发一个能够捕获通用、鲁棒的跨任务热成像特征的骨干网络，并适用于多种环境和任务，无需针对每个任务进行专门训练。

Method: 利用 DINOv2 等视觉基础模型，通过在多环境热成像数据上进行蒸馏，将视觉基础模型的特征表示迁移到热成像编码器中，构建 AnyThermal。同时，为了解决现有 RGB-热成像数据集的局限性，引入了 TartanRGBT 数据采集平台，并利用该平台收集了多样化且平衡的 TartanRGBT 数据集。

Result: AnyThermal 在多种下游任务（如跨模态场景识别、热成像分割、单目深度估计）和不同环境（室内、航空、越野、城市）下均取得了最先进的性能，在现有数据集上的性能提升高达 36%。

Conclusion: AnyThermal 骨干网络能够有效地从热成像数据中提取通用且鲁棒的任务无关特征，适用于广泛的环境和下游任务。TartanRGBT 数据集和采集平台为热成像研究提供了宝贵资源，并有助于 AnyThermal 的开发和验证。

Abstract: We present AnyThermal, a thermal backbone that captures robust task-agnostic thermal features suitable for a variety of tasks such as cross-modal place recognition, thermal segmentation, and monocular depth estimation using thermal images. Existing thermal backbones that follow task-specific training from small-scale data result in utility limited to a specific environment and task. Unlike prior methods, AnyThermal can be used for a wide range of environments (indoor, aerial, off-road, urban) and tasks, all without task-specific training. Our key insight is to distill the feature representations from visual foundation models such as DINOv2 into a thermal encoder using thermal data from these multiple environments. To bridge the diversity gap of the existing RGB-Thermal datasets, we introduce the TartanRGBT platform, the first open-source data collection platform with synced RGB-Thermal image acquisition. We use this payload to collect the TartanRGBT dataset - a diverse and balanced dataset collected in 4 environments. We demonstrate the efficacy of AnyThermal and TartanRGBT, achieving state-of-the-art results with improvements of up to 36% across diverse environments and downstream tasks on existing datasets.

</details>


### [39] [DroneKey++: A Size Prior-free Method and New Benchmark for Drone 3D Pose Estimation from Sequential Images](https://arxiv.org/abs/2602.06211)
*Seo-Bin Hwang,Yeong-Jun Cho*

Main category: cs.CV

TL;DR: 本文提出了DroneKey++，一个无需先验知识即可进行无人机关键点检测、分类和3D姿态估计的框架。并构建了一个大规模合成数据集6DroneSyn，以克服现有数据集的局限性。实验结果表明DroneKey++在泛化性和实时性方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有无人机3D姿态估计方法依赖于先验的无人机信息（如尺寸、3D模型），并且现有数据集规模小、模型单一、环境受限，难以验证方法的泛化能力。

Method: 提出DroneKey++框架，包含一个关键点编码器（用于同时检测关键点和分类无人机）和一个姿态解码器（利用基于射线的几何推理和类别嵌入来估计3D姿态）。构建了大规模合成数据集6DroneSyn，包含7种无人机模型和88种背景。

Result: DroneKey++在旋转估计上达到了17.34度的MAE和17.1度的MedAE，在平移估计上达到了0.135米的MAE和0.242米的MedAE。推理速度达到19.25 FPS（CPU）和414.07 FPS（GPU），展示了良好的跨模型泛化能力和实时性。

Conclusion: DroneKey++是一个无需先验知识的无人机3D姿态估计框架，通过新的编码器-解码器结构和大规模合成数据集，能够有效地进行关键点检测、分类和3D姿态估计，并展现出优异的泛化性和实时性。

Abstract: Accurate 3D pose estimation of drones is essential for security and surveillance systems. However, existing methods often rely on prior drone information such as physical sizes or 3D meshes. At the same time, current datasets are small-scale, limited to single models, and collected under constrained environments, which makes reliable validation of generalization difficult. We present DroneKey++, a prior-free framework that jointly performs keypoint detection, drone classification, and 3D pose estimation. The framework employs a keypoint encoder for simultaneous keypoint detection and classification, and a pose decoder that estimates 3D pose using ray-based geometric reasoning and class embeddings. To address dataset limitations, we construct 6DroneSyn, a large-scale synthetic benchmark with over 50K images covering 7 drone models and 88 outdoor backgrounds, generated using 360-degree panoramic synthesis. Experiments show that DroneKey++ achieves MAE 17.34 deg and MedAE 17.1 deg for rotation, MAE 0.135 m and MedAE 0.242 m for translation, with inference speeds of 19.25 FPS (CPU) and 414.07 FPS (GPU), demonstrating both strong generalization across drone models and suitability for real-time applications. The dataset is publicly available.

</details>


### [40] [Addressing the Waypoint-Action Gap in End-to-End Autonomous Driving via Vehicle Motion Models](https://arxiv.org/abs/2602.06214)
*Jorge Daniel Rodríguez-Vidal,Gabriel Villalonga,Diego Porres,Antonio M. López Peña*

Main category: cs.CV

TL;DR: 提出了一种新的可微分车辆模型框架，可以将基于动作的自动驾驶模型与基于路径点的基准进行匹配，从而首次在基于路径点的基准上训练和评估基于动作的自动驾驶模型，并在多个基准测试中实现了改进，包括在 NAVSIM navhard 上达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶系统主要分为基于路径点和基于动作的模型。当前的基准协议和训练流程主要偏向于基于路径点的方法，这阻碍了基于动作的方法的训练和比较，从而减缓了其进步。

Method: 提出了一种新颖的可微分车辆模型框架。该框架可以将预测的动作序列通过滚动优化生成对应的以自身为参考系的路径点轨迹，并在路径点空间进行监督。这使得基于动作的架构能够首次在不修改底层评估协议的情况下，在基于路径点的基准上进行训练和评估。

Result: 该框架在多个具有挑战性的基准测试中得到了广泛评估，并观察到相对于基线方法的一致性改进。特别是在 NAVSIM navhard 基准上，该方法取得了最先进的性能。

Conclusion: 所提出的可微分车辆模型框架成功弥合了基于路径点和基于动作的自动驾驶模型之间的差距，使得基于动作的模型能够有效地在现有的基于路径点的基准上进行训练和评估，并显著提升了性能。

Abstract: End-to-End Autonomous Driving (E2E-AD) systems are typically grouped by the nature of their outputs: (i) waypoint-based models that predict a future trajectory, and (ii) action-based models that directly output throttle, steer and brake. Most recent benchmark protocols and training pipelines are waypoint-based, which makes action-based policies harder to train and compare, slowing their progress. To bridge this waypoint-action gap, we propose a novel, differentiable vehicle-model framework that rolls out predicted action sequences to their corresponding ego-frame waypoint trajectories while supervising in waypoint space. Our approach enables action-based architectures to be trained and evaluated, for the first time, within waypoint-based benchmarks without modifying the underlying evaluation protocol. We extensively evaluate our framework across multiple challenging benchmarks and observe consistent improvements over the baselines. In particular, on NAVSIM \texttt{navhard} our approach achieves state-of-the-art performance. Our code will be made publicly available upon acceptance.

</details>


### [41] [Cross-Modal Redundancy and the Geometry of Vision-Language Embeddings](https://arxiv.org/abs/2602.06218)
*Grégoire Dhimoïla,Thomas Fel,Victor Boutin,Agustin Picard*

Main category: cs.CV

TL;DR: 本文提出了一种基于“等能量假设”（Iso-Energy Assumption）的对齐稀疏自编码器（SAE）来分析视觉-语言模型（VLMs）的几何结构，发现稀疏的跨模态原子承载了对齐信号，而单模态原子则解释了模态鸿沟，去除单模态原子可缩小鸿沟且不影响性能，并将向量运算限制在跨模态子空间内可实现可控编辑和提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLMs）在对齐图像和文本方面取得了成功，但其共享嵌入空间的几何结构仍未被充分理解。本研究旨在探究和理解这种几何结构，并提出一种方法来改善其可解释性和可操作性。

Method: 本文提出了“等能量假设”，并将其应用于对齐稀疏自编码器（SAE）的训练中。该方法鼓励在训练过程中保持跨模态的能量一致性，同时保留重构能力。通过在受控数据和基础VLMs上进行实验，分析SAE的学习结果，并在此基础上进行几何分析。

Result: 研究发现：1. 稀疏的跨模态原子包含了全部的跨模态对齐信号；2. 单模态原子表现为特定模态的偏置，并能完全解释模态鸿沟；3. 移除单模态原子可以缩小模态鸿沟，且不损害模型性能；4. 将向量运算限制在跨模态子空间内，可以实现分布内编辑并提升检索效果。

Conclusion: 正确的归纳偏置（inductive bias）不仅可以保持模型的保真度，还能使潜在的几何结构变得可解释且可操作。本文的方法揭示了VLMs内部的结构，并提供了改进模型性能和理解其工作机制的实用途径。

Abstract: Vision-language models (VLMs) align images and text with remarkable success, yet the geometry of their shared embedding space remains poorly understood. To probe this geometry, we begin from the Iso-Energy Assumption, which exploits cross-modal redundancy: a concept that is truly shared should exhibit the same average energy across modalities. We operationalize this assumption with an Aligned Sparse Autoencoder (SAE) that encourages energy consistency during training while preserving reconstruction. We find that this inductive bias changes the SAE solution without harming reconstruction, giving us a representation that serves as a tool for geometric analysis. Sanity checks on controlled data with known ground truth confirm that alignment improves when Iso-Energy holds and remains neutral when it does not. Applied to foundational VLMs, our framework reveals a clear structure with practical consequences: (i) sparse bimodal atoms carry the entire cross-modal alignment signal; (ii) unimodal atoms act as modality-specific biases and fully explain the modality gap; (iii) removing unimodal atoms collapses the gap without harming performance; (iv) restricting vector arithmetic to the bimodal subspace yields in-distribution edits and improved retrieval. These findings suggest that the right inductive bias can both preserve model fidelity and render the latent geometry interpretable and actionable.

</details>


### [42] [ForeHOI: Feed-forward 3D Object Reconstruction from Daily Hand-Object Interaction Videos](https://arxiv.org/abs/2602.06226)
*Yuantao Chen,Jiahao Chang,Chongjie Ye,Chaoran Zhang,Zhaojie Fang,Chenghong Li,Xiaoguang Han*

Main category: cs.CV

TL;DR: 本文提出了一种名为ForeHOI的新型前馈模型，能够从单目手部交互视频中直接重建3D物体几何形状，克服了传统优化方法在遮挡问题上的不足，并且推理速度比之前的方法快100倍。作者还发布了一个大规模的合成数据集来支持模型训练。


<details>
  <summary>Details</summary>
Motivation: 单目视频中手部与物体的交互场景非常普遍，是训练具身智能的宝贵资源。然而，从这些视频中重建3D物体仍然具有挑战性，主要原因是严重的遮挡以及相机、手部和物体之间复杂的耦合运动。现有方法在处理这些问题时效率不高。

Method: 作者提出了一个名为ForeHOI的前馈模型，可以直接从单目手部交互视频中重建3D物体几何形状，无需预处理。其核心思想是通过联合预测2D掩码修复和3D形状补全，并在前馈框架内进行信息交换，以有效解决严重的遮挡问题。此外，作者构建了一个大规模、高保真的手部-物体交互合成数据集来训练模型。

Result: ForeHOI模型在物体重建方面取得了最先进的性能，显著优于之前的优化方法，并且推理速度提高了约100倍。2D和3D形状补全之间的信息交换提高了整体重建质量，能够有效处理严重的手部-物体遮挡。

Conclusion: ForeHOI模型通过新颖的前馈联合2D/3D重建方法，成功解决了单目手部交互视频中的物体重建问题，尤其是在严重遮挡的情况下，其性能和效率都远超现有方法。新数据集的贡献也为该领域的研究提供了有力支持。

Abstract: The ubiquity of monocular videos capturing daily hand-object interactions presents a valuable resource for embodied intelligence. While 3D hand reconstruction from in-the-wild videos has seen significant progress, reconstructing the involved objects remains challenging due to severe occlusions and the complex, coupled motion of the camera, hands, and object. In this paper, we introduce ForeHOI, a novel feed-forward model that directly reconstructs 3D object geometry from monocular hand-object interaction videos within one minute of inference time, eliminating the need for any pre-processing steps. Our key insight is that, the joint prediction of 2D mask inpainting and 3D shape completion in a feed-forward framework can effectively address the problem of severe occlusion in monocular hand-held object videos, thereby achieving results that outperform the performance of optimization-based methods. The information exchanges between the 2D and 3D shape completion boosts the overall reconstruction quality, enabling the framework to effectively handle severe hand-object occlusion. Furthermore, to support the training of our model, we contribute the first large-scale, high-fidelity synthetic dataset of hand-object interactions with comprehensive annotations. Extensive experiments demonstrate that ForeHOI achieves state-of-the-art performance in object reconstruction, significantly outperforming previous methods with around a 100x speedup. Code and data are available at: https://github.com/Tao-11-chen/ForeHOI.

</details>


### [43] [ASMa: Asymmetric Spatio-temporal Masking for Skeleton Action Representation Learning](https://arxiv.org/abs/2602.06251)
*Aman Anand,Amir Eskandari,Elyas Rahsno,Farhana Zulkernine*

Main category: cs.CV

TL;DR: 提出了一种名为ASMa（非对称时空掩码）的新型自监督学习方法，用于骨架动作识别。ASMa结合了两种互补的掩码策略，旨在学习更全面、更平衡的骨架表示。此外，引入了可学习的特征对齐模块和知识蒸馏技术，以实现模型压缩和资源受限环境下的部署。


<details>
  <summary>Details</summary>
Motivation: 现有骨架动作识别的自监督学习方法依赖于单一的、偏向于掩码高运动帧和高自由度关节的增强策略，导致学习到的特征表示不完整且泛化能力差。研究旨在学习更全面的时空动态，以解决这个问题。

Method: 提出了一种名为Asymmetric Spatio-temporal Masking (ASMa) 的方法，结合了两种掩码策略：一种掩码高自由度关节和低运动，另一种掩码低自由度关节和高运动帧。引入了一个可学习的特征对齐模块来对齐不同掩码视图的学习表示。最后，使用知识蒸馏将学习到的表示压缩成一个轻量级模型，以适应资源受限的环境。

Result: 在NTU RGB+D 60、NTU RGB+D 120和PKU-MMD数据集上进行了大量实验。ASMa在微调时平均提高了2.7-4.4%，在迁移学习到噪声数据集时提高了5.9%。蒸馏后的模型在参数量上减少了91.4%，推理速度提高了3倍，同时保持了具有竞争力的准确性。

Conclusion: ASMa方法能够学习到更全面、更平衡的骨架表示，提高了骨架动作识别的性能和泛化能力。通过知识蒸馏，ASMa能够生成轻量级模型，在保持高性能的同时，显著降低了计算资源需求，使其适用于资源受限的设备和场景。

Abstract: Self-supervised learning (SSL) has shown remarkable success in skeleton-based action recognition by leveraging data augmentations to learn meaningful representations. However, existing SSL methods rely on data augmentations that predominantly focus on masking high-motion frames and high-degree joints such as joints with degree 3 or 4. This results in biased and incomplete feature representations that struggle to generalize across varied motion patterns. To address this, we propose Asymmetric Spatio-temporal Masking (ASMa) for Skeleton Action Representation Learning, a novel combination of masking to learn a full spectrum of spatio-temporal dynamics inherent in human actions. ASMa employs two complementary masking strategies: one that selectively masks high-degree joints and low-motion, and another that masks low-degree joints and high-motion frames. These masking strategies ensure a more balanced and comprehensive skeleton representation learning. Furthermore, we introduce a learnable feature alignment module to effectively align the representations learned from both masked views. To facilitate deployment in resource-constrained settings and on low-resource devices, we compress the learned and aligned representation into a lightweight model using knowledge distillation. Extensive experiments on NTU RGB+D 60, NTU RGB+D 120, and PKU-MMD datasets demonstrate that our approach outperforms existing SSL methods with an average improvement of 2.7-4.4% in fine-tuning and up to 5.9% in transfer learning to noisy datasets and achieves competitive performance compared to fully supervised baselines. Our distilled model achieves 91.4% parameter reduction and 3x faster inference on edge devices while maintaining competitive accuracy, enabling practical deployment in resource-constrained scenarios.

</details>


### [44] [An Interpretable Vision Transformer as a Fingerprint-Based Diagnostic Aid for Kabuki and Wiedemann-Steiner Syndromes](https://arxiv.org/abs/2602.06282)
*Marilyn Lionts,Arnhildur Tomasdottir,Viktor I. Agustsson,Yuankai Huo,Hans T. Bjornsson,Lotta M. Ellingsen*

Main category: cs.CV

TL;DR: 研究提出了一种基于视觉变换器的深度学习模型，利用指纹图像来区分先天性肌营养不良综合征（KS）和Wiedemann-Steiner综合征（WSS）患者与健康对照组，以及区分两者。模型在区分任务中表现出可观的性能，并能通过可视化提供可解释的诊断依据。


<details>
  <summary>Details</summary>
Motivation: Kabuki综合征（KS）和Wiedemann-Steiner综合征（WSS）是罕见的遗传性疾病，尽管有临床重叠，但诊断率不高，部分原因是遗传检测的可及性和专业知识的限制。指纹异常是许多遗传综合征的标志，但未被充分利用。

Method: 研究者开发了一个基于视觉变换器（Vision Transformer）的深度学习模型，利用指纹图像进行KS和WSS患者与健康对照组的区分，以及KS与WSS之间的区分。模型性能通过AUC和F1分数进行评估，并使用注意力机制可视化来解释模型预测的关键指纹区域。

Result: 在三个二分类任务中，模型取得了以下性能：对照组 vs. KS 组AUC为0.80，F1得分为0.71；对照组 vs. WSS组AUC为0.73，F1得分为0.72；KS组 vs. WSS组AUC为0.85，F1得分为0.83。

Conclusion: 研究表明，KS和WSS患者的指纹存在特异性特征。基于指纹的AI工具具有成为一种非侵入性、可解释且易于获取的辅助诊断工具的潜力，可以帮助早期诊断这些被低估的遗传综合征。

Abstract: Kabuki syndrome (KS) and Wiedemann-Steiner syndrome (WSS) are rare but distinct developmental disorders that share overlapping clinical features, including neurodevelopmental delay, growth restriction, and persistent fetal fingertip pads. While genetic testing remains the diagnostic gold standard, many individuals with KS or WSS remain undiagnosed due to barriers in access to both genetic testing and expertise. Dermatoglyphic anomalies, despite being established hallmarks of several genetic syndromes, remain an underutilized diagnostic signal in the era of molecular testing. This study presents a vision transformer-based deep learning model that leverages fingerprint images to distinguish individuals with KS and WSS from unaffected controls and from one another. We evaluate model performance across three binary classification tasks. Across the three classification tasks, the model achieved AUC scores of 0.80 (control vs. KS), 0.73 (control vs. WSS), and 0.85 (KS vs. WSS), with corresponding F1 scores of 0.71, 0.72, and 0.83, respectively. Beyond classification, we apply attention-based visualizations to identify fingerprint regions most salient to model predictions, enhancing interpretability. Together, these findings suggest the presence of syndrome-specific fingerprint features, demonstrating the feasibility of a fingerprint-based artificial intelligence (AI) tool as a noninvasive, interpretable, and accessible future diagnostic aid for the early diagnosis of underdiagnosed genetic syndromes.

</details>


### [45] [MMEarth-Bench: Global Model Adaptation via Multimodal Test-Time Training](https://arxiv.org/abs/2602.06285)
*Lucia Gordon,Serge Belongie,Christian Igel,Nico Lang*

Main category: cs.CV

TL;DR: 本文提出了 MMEarth-Bench，一个包含五个新的多模态环境任务、12 种数据模态、全球分布数据以及 in-distribution 和 out-of-distribution 测试集的新基准。研究发现，多模态预训练能提高模型在数据有限情况下的鲁棒性，但地理泛化能力仍然不足。为此，作者提出了一个模型无关的测试时训练方法 TTT-MMR，利用测试时所有可用的模态作为辅助任务，以提高模型在新下游任务和地理域上的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的地理空间基准数据集数据模态少，全球代表性不足，难以评估多模态预训练模型在全球尺度上的表现，因此需要新的、更全面的基准来弥补这一不足。

Method: 1. 提出了 MMEarth-Bench 数据集，包含五个新的多模态环境任务、12 种数据模态、全球分布数据以及 in-distribution 和 out-of-distribution 测试集。2. 评估了多种预训练模型的表现。3. 提出了模型无关的测试时训练方法 TTT-MMR，利用测试时所有可用的模态作为辅助任务进行重构。

Result: 1. 多模态预训练在数据有限的情况下能提高模型的鲁棒性，但地理泛化能力仍较差。2. TTT-MMR 方法在随机和地理测试集上均提高了模型性能。3. 地理批处理在 TTT 过程中能很好地平衡正则化和专业化。

Conclusion: MMEarth-Bench 提供了一个更全面的评估多模态预训练模型在地理空间任务上表现的平台。TTT-MMR 方法是一种有效的模型适应技术，能够提高模型在新任务和新地理域上的泛化能力。

Abstract: Recent research in geospatial machine learning has demonstrated that models pretrained with self-supervised learning on Earth observation data can perform well on downstream tasks with limited training data. However, most of the existing geospatial benchmark datasets have few data modalities and poor global representation, limiting the ability to evaluate multimodal pretrained models at global scales. To fill this gap, we introduce MMEarth-Bench, a collection of five new multimodal environmental tasks with 12 modalities, globally distributed data, and both in- and out-of-distribution test splits. We benchmark a diverse set of pretrained models and find that while (multimodal) pretraining tends to improve model robustness in limited data settings, geographic generalization abilities remain poor. In order to facilitate model adaptation to new downstream tasks and geographic domains, we propose a model-agnostic method for test-time training with multimodal reconstruction (TTT-MMR) that uses all the modalities available at test time as auxiliary tasks, regardless of whether a pretrained model accepts them as input. Our method improves model performance on both the random and geographic test splits, and geographic batching leads to a good trade-off between regularization and specialization during TTT. Our dataset, code, and visualization tool are linked from the project page at lgordon99.github.io/mmearth-bench.

</details>


### [46] [Unsupervised MRI-US Multimodal Image Registration with Multilevel Correlation Pyramidal Optimization](https://arxiv.org/abs/2602.06288)
*Jiazheng Wang,Zeyu Liu,Min Liu,Xiang Chen,Hang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为多级别相关金字塔优化（MCPO）的无监督多模态医学图像配准方法，旨在解决术前与术中多模态图像配准的挑战，并在Learn2Reg 2025的ReMIND2Reg任务中取得第一名。


<details>
  <summary>Details</summary>
Motivation: 术前与术中多模态医学图像配准存在挑战，原因在于不同模态图像的差异以及术中组织位移和移除导致的图像变形。

Method: 该方法首先使用与模态无关的邻域描述符提取图像特征并将其映射到特征空间。然后，利用多级别金字塔融合优化机制，通过密集相关性分析和权重平衡耦合凸优化，在不同尺度下实现位移场的全局优化和局部细节补充。

Result: 该方法在Learn2Reg 2025的ReMIND2Reg任务的验证集和测试集中均取得第一名。在Resect数据集上，平均TRE为1.798 mm。

Conclusion: MCPO方法能够有效地解决术前到术中多模态图像配准的挑战，并具有广泛的适用性。

Abstract: Surgical navigation based on multimodal image registration has played a significant role in providing intraoperative guidance to surgeons by showing the relative position of the target area to critical anatomical structures during surgery. However, due to the differences between multimodal images and intraoperative image deformation caused by tissue displacement and removal during the surgery, effective registration of preoperative and intraoperative multimodal images faces significant challenges. To address the multimodal image registration challenges in Learn2Reg 2025, an unsupervised multimodal medical image registration method based on multilevel correlation pyramidal optimization (MCPO) is designed to solve these problems. First, the features of each modality are extracted based on the modality independent neighborhood descriptor, and the multimodal images is mapped to the feature space. Second, a multilevel pyramidal fusion optimization mechanism is designed to achieve global optimization and local detail complementation of the displacement field through dense correlation analysis and weight-balanced coupled convex optimization for input features at different scales. Our method focuses on the ReMIND2Reg task in Learn2Reg 2025. Based on the results, our method achieved the first place in the validation phase and test phase of ReMIND2Reg. The MCPO is also validated on the Resect dataset, achieving an average TRE of 1.798 mm. This demonstrates the broad applicability of our method in preoperative-to-intraoperative image registration. The code is avaliable at https://github.com/wjiazheng/MCPO.

</details>


### [47] [Accelerating Vision Transformers on Brain Processing Unit](https://arxiv.org/abs/2602.06300)
*Jinchi Tang,Yan Guo*

Main category: cs.CV

TL;DR: 提出了一种通过卷积算子重构Vision Transformer（ViT）模型的方法，使其能够充分利用为CNN设计的Brain Processing Unit（BPU）硬件进行加速，而无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 目前的CNN优化硬件（如BPU）在加速Transformer模型（如ViT）时存在架构不匹配的问题，因为ViT的线性层操作三维数据，而BPU主要为四维卷积操作设计。

Method: 通过将Vision Transformer中的线性层和层归一化操作替换为精心设计的卷积算子来重构模型，从而使其能够利用BPU的加速能力。

Result: 重构后的模型能够继承原始模型的权重参数，无需重新训练。在ImageNet数据集上，量化后的DeiT-Base模型实现了80.4%的准确率，推理速度提升高达3.8倍。在花卉分类数据集上微调后，DeiT-Base模型准确率仅下降0.5%。

Conclusion: 该方法首次成功地将Vision Transformer模型部署在BPU硬件上，并充分利用了其加速能力，证明了其有效性。

Abstract: With the advancement of deep learning technologies, specialized neural processing hardware such as Brain Processing Units (BPUs) have emerged as dedicated platforms for CNN acceleration, offering optimized INT8 computation capabilities for convolutional operations. Meanwhile, Vision Transformer (ViT) models, such as the Data-efficient Image Transformer (DeiT), have demonstrated superior performance and play increasingly crucial roles in computer vision tasks. However, due to the architectural mismatch between CNN-optimized hardware and Vision Transformer computation characteristics--namely, that linear layers in Transformers operate on three-dimensional data while BPU acceleration is designed for four-dimensional convolution operations-it is difficult or even impossible to leverage BPU's advantages when deploying Vision Transformers. To address this challenge, we propose a novel approach that restructures the Vision Transformer by replacing linear layers and layer normalization operations with carefully designed convolutional operators. This enables DeiT to fully utilize the acceleration capabilities of BPUs, while allowing the original weight parameters to be inherited by the restructured models without retraining or fine-tuning. To the best of our knowledge, this is the first successful deployment of Vision Transformers that fully leverages BPU classification datasets demonstrate the effectiveness of our approach. Specifically, the quantized DeiT-Base model achieves 80.4% accuracy on ImageNet, compared to the original 81.8%, while obtaining up to a 3.8* inference speedup. Our finetuned DeiT model on the flower classification dataset also achieves excellent performance, with only a 0.5% accuracy drop for the DeiT-Base model, further demonstrating the effectiveness of our method.

</details>


### [48] [Adaptive and Balanced Re-initialization for Long-timescale Continual Test-time Domain Adaptation](https://arxiv.org/abs/2602.06328)
*Yanshuo Wang,Jinguang Tong,Jun Lan,Weiqiang Wang,Huijia Zhu,Haoxing Chen,Xuesong Li,Jie Hong*

Main category: cs.CV

TL;DR: 本文提出了一种基于重初始化的自适应且平衡的重初始化（ABR）方法，以提高模型在持续时间测试时域自适应（CTTA）中的长期性能，该方法通过监测标签翻转的变化来确定自适应的重初始化间隔。


<details>
  <summary>Details</summary>
Motivation: 现有CTTA方法在长期适应性方面存在挑战，即模型能否在持续变化的环境中长期保持良好性能。

Method: 提出了一种名为自适应且平衡的重初始化（ABR）的策略。ABR通过自适应间隔进行模型权重重初始化，该间隔根据标签翻转的变化来确定。

Result: ABR方法在广泛的CTTA基准测试中取得了优越的性能。

Conclusion: 基于重初始化的ABR策略能够有效地提高模型在CTTA任务中的长期性能，并且该方法在标签翻转模式的长期性能关联性观察基础上，实现了简单而有效的改进。

Abstract: Continual test-time domain adaptation (CTTA) aims to adjust models so that they can perform well over time across non-stationary environments. While previous methods have made considerable efforts to optimize the adaptation process, a crucial question remains: Can the model adapt to continually changing environments over a long time? In this work, we explore facilitating better CTTA in the long run using a re-initialization (or reset) based method. First, we observe that the long-term performance is associated with the trajectory pattern in label flip. Based on this observed correlation, we propose a simple yet effective policy, Adaptive-and-Balanced Re-initialization (ABR), towards preserving the model's long-term performance. In particular, ABR performs weight re-initialization using adaptive intervals. The adaptive interval is determined based on the change in label flip. The proposed method is validated on extensive CTTA benchmarks, achieving superior performance.

</details>


### [49] [Halt the Hallucination: Decoupling Signal and Semantic OOD Detection Based on Cascaded Early Rejection](https://arxiv.org/abs/2602.06330)
*Ningkang Peng,Chuanjie Cheng,Jingyang Mao,Xiaoqian Peng,Feng Xing,Bo Zhang,Chao Tan,Zhichao Zheng,Peiheng Li,Yanhui Gu*

Main category: cs.CV

TL;DR: 提出了一种名为级联早期拒绝（CER）的框架，通过分层过滤来检测分布外（OOD）数据，该框架由结构能量筛（SES）和语义感知超球能量（SHE）探测器组成，以减少计算开销并提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在低级统计噪声上执行完全推理，导致资源浪费和语义幻觉，需要更高效鲁棒的OOD检测方法。

Method: 提出了级联早期拒绝（CER）框架，包括：1）结构能量筛（SES），使用拉普拉斯算子在网络入口处进行非参数过滤，拦截物理信号异常；2）语义感知超球能量（SHE）探测器，在中间层解耦特征幅度和方向，识别细粒度语义偏差。

Result: CER将计算开销减少了32%，在CIFAR-100基准测试上FPR95从33.58%显著降低到22.84%，AUROC提高到93.97%。在模拟传感器故障的实际场景中，CER的性能远超现有SOTA方法。

Conclusion: CER框架通过分层过滤实现高效鲁棒的OOD检测，显著降低计算成本并提升检测性能，可以作为通用插件集成到现有模型中以获得性能提升。

Abstract: Efficient and robust Out-of-Distribution (OOD) detection is paramount for safety-critical applications.However, existing methods still execute full-scale inference on low-level statistical noise. This computational mismatch not only incurs resource waste but also induces semantic hallucination, where deep networks forcefully interpret physical anomalies as high-confidence semantic features.To address this, we propose the Cascaded Early Rejection (CER) framework, which realizes hierarchical filtering for anomaly detection via a coarse-to-fine logic.CER comprises two core modules: 1)Structural Energy Sieve (SES), which establishes a non-parametric barrier at the network entry using the Laplacian operator to efficiently intercept physical signal anomalies; and 2) the Semantically-aware Hyperspherical Energy (SHE) detector, which decouples feature magnitude from direction in intermediate layers to identify fine-grained semantic deviations. Experimental results demonstrate that CER not only reduces computational overhead by 32% but also achieves a significant performance leap on the CIFAR-100 benchmark:the average FPR95 drastically decreases from 33.58% to 22.84%, and AUROC improves to 93.97%. Crucially, in real-world scenarios simulating sensor failures, CER exhibits performance far exceeding state-of-the-art methods. As a universal plugin, CER can be seamlessly integrated into various SOTA models to provide performance gains.

</details>


### [50] [Taming SAM3 in the Wild: A Concept Bank for Open-Vocabulary Segmentation](https://arxiv.org/abs/2602.06333)
*Gensheng Pei,Xiruo Jiang,Yazhou Yao,Xiangbo Shu,Fumin Shen,Byeungwoo Jeon*

Main category: cs.CV

TL;DR: 提出了一种名为 ConceptBank 的参数化零样本开放词汇分割（OVS）的校准框架，通过构建特定于数据集的概念库来解决 SAM3 在数据漂移和概念漂移下的对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有的 SAM3 在开放词汇分割中依赖预定义的提示，当目标域出现数据漂移（视觉分布变化）或概念漂移（条件标签分布变化）时，会导致视觉证据和提示之间的对齐失效。

Method: ConceptBank 构建了一个特定于目标域的概念库，通过类别的视觉原型来锚定目标域的证据，挖掘代表性支持来抑制数据漂移下的异常值，并融合候选概念来纠正概念漂移。

Result: ConceptBank 能够有效地将 SAM3 适配到自然场景和遥感等分布漂移问题，并在鲁棒性和效率方面设立了新的 OVS 基准。

Conclusion: ConceptBank 是一种有效的、无需参数即可对 SAM3 进行校准的框架，能够在分布漂移下恢复视觉证据和提示之间的对齐，提高了 OVS 的鲁棒性和效率。

Abstract: The recent introduction of \texttt{SAM3} has revolutionized Open-Vocabulary Segmentation (OVS) through \textit{promptable concept segmentation}, which grounds pixel predictions in flexible concept prompts. However, this reliance on pre-defined concepts makes the model vulnerable: when visual distributions shift (\textit{data drift}) or conditional label distributions evolve (\textit{concept drift}) in the target domain, the alignment between visual evidence and prompts breaks down. In this work, we present \textsc{ConceptBank}, a parameter-free calibration framework to restore this alignment on the fly. Instead of adhering to static prompts, we construct a dataset-specific concept bank from the target statistics. Our approach (\textit{i}) anchors target-domain evidence via class-wise visual prototypes, (\textit{ii}) mines representative supports to suppress outliers under data drift, and (\textit{iii}) fuses candidate concepts to rectify concept drift. We demonstrate that \textsc{ConceptBank} effectively adapts \texttt{SAM3} to distribution drifts, including challenging natural-scene and remote-sensing scenarios, establishing a new baseline for robustness and efficiency in OVS. Code and model are available at https://github.com/pgsmall/ConceptBank.

</details>


### [51] [SPDA-SAM: A Self-prompted Depth-Aware Segment Anything Model for Instance Segmentation](https://arxiv.org/abs/2602.06335)
*Yihan Shang,Wei Wang,Chao Huang,Xinghui Dong*

Main category: cs.CV

TL;DR: 提出了一种名为 SPDA-SAM 的自提示深度感知 SAM 模型，用于实例分割，通过结合语义-空间自提示和粗到细的 RGB-D 融合来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 SAM 模型高度依赖手动提示的质量，并且 RGB 图像缺乏深度信息，这限制了实例分割的性能。研究者希望解决这些问题。

Method: 设计了一个语义-空间自提示模块 (SSSPM) 来从 SAM 的图像编码器和掩码解码器中提取提示。引入了一个粗到细的 RGB-D 融合模块 (C2FFM)，利用单目 RGB 图像和其估计的深度图来融合特征，其中深度图的结构信息提供粗粒度指导，而深度局部变化则用于细粒度特征融合。

Result: SPDA-SAM 在十二个不同的数据集上优于最先进的方法。

Conclusion: 自提示和粗到细的 RGB-D 融合操作可以有效地弥补空间信息损失，并提高实例分割的性能。

Abstract: Recently, Segment Anything Model (SAM) has demonstrated strong generalizability in various instance segmentation tasks. However, its performance is severely dependent on the quality of manual prompts. In addition, the RGB images that instance segmentation methods normally use inherently lack depth information. As a result, the ability of these methods to perceive spatial structures and delineate object boundaries is hindered. To address these challenges, we propose a Self-prompted Depth-Aware SAM (SPDA-SAM) for instance segmentation. Specifically, we design a Semantic-Spatial Self-prompt Module (SSSPM) which extracts the semantic and spatial prompts from the image encoder and the mask decoder of SAM, respectively. Furthermore, we introduce a Coarse-to-Fine RGB-D Fusion Module (C2FFM), in which the features extracted from a monocular RGB image and the depth map estimated from it are fused. In particular, the structural information in the depth map is used to provide coarse-grained guidance to feature fusion, while local variations in depth are encoded in order to fuse fine-grained feature representations. To our knowledge, SAM has not been explored in such self-prompted and depth-aware manners. Experimental results demonstrate that our SPDA-SAM outperforms its state-of-the-art counterparts across twelve different data sets. These promising results should be due to the guidance of the self-prompts and the compensation for the spatial information loss by the coarse-to-fine RGB-D fusion operation.

</details>


### [52] [FlowConsist: Make Your Flow Consistent with Real Trajectory](https://arxiv.org/abs/2602.06346)
*Tianyi Zhang,Chengcheng Liu,Jinwei Chen,Chun-Le Guo,Chongyi Li,Ming-Ming Cheng,Bo Li,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种名为FlowConsist的训练框架，旨在解决现有快速流模型在训练过程中存在的轨迹漂移和误差累积问题，从而提高生成样本的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的快速流模型在训练过程中存在两个主要问题：1. 条件速度的构建会导致轨迹漂移，模型无法遵循一致的ODE路径。2. 模型的近似误差会随时间步累积，导致长时间间隔下的严重偏差。

Method: FlowConsist框架通过以下方式解决上述问题：1. 用模型自身预测的边际速度取代条件速度，以实现优化与真实轨迹的一致性。2. 引入轨迹校正策略，在轨迹的每一步都使生成样本和真实样本的边际分布对齐，以解决误差累积问题。

Result: FlowConsist在ImageNet 256x256数据集上取得了新的最先进水平，在仅使用1个采样步的情况下，FID得分达到了1.52。

Conclusion: FlowConsist训练框架能够有效地提高快速流模型的轨迹一致性，减少误差累积，从而在少数采样步下实现高质量的图像生成。

Abstract: Fast flow models accelerate the iterative sampling process by learning to directly predict ODE path integrals, enabling one-step or few-step generation. However, we argue that current fast-flow training paradigms suffer from two fundamental issues. First, conditional velocities constructed from randomly paired noise-data samples introduce systematic trajectory drift, preventing models from following a consistent ODE path. Second, the model's approximation errors accumulate over time steps, leading to severe deviations across long time intervals. To address these issues, we propose FlowConsist, a training framework designed to enforce trajectory consistency in fast flows. We propose a principled alternative that replaces conditional velocities with the marginal velocities predicted by the model itself, aligning optimization with the true trajectory. To further address error accumulation over time steps, we introduce a trajectory rectification strategy that aligns the marginal distributions of generated and real samples at every time step along the trajectory. Our method establishes a new state-of-the-art on ImageNet 256$\times$256, achieving an FID of 1.52 with only 1 sampling step.

</details>


### [53] [Di3PO -- Diptych Diffusion DPO for Targeted Improvements in Image](https://arxiv.org/abs/2602.06355)
*Sanjana Reddy,Ishaan Malhi,Sally Ma,Praneet Dutta*

Main category: cs.CV

TL;DR: 提出了一种名为 Di3PO 的新方法，用于在文本到图像扩散模型的偏好调整中创建更有针对性的正负图像对，以提高效率和效果。


<details>
  <summary>Details</summary>
Motivation: 现有偏好调整方法生成的正负图像对效率低下，可能缺乏有意义的差异，难以采样，或在无关区域存在方差，影响训练效果。

Method: Di3PO 通过隔离目标改进区域并保持图像其他上下文稳定来创建正负图像对。

Result: 将 Di3PO 应用于文本渲染任务，并展示了其在 SFT 和 DPO 等基线方法上的优越性。

Conclusion: Di3PO 能够有效地为扩散模型的偏好调整生成正负图像对，尤其在文本渲染方面，比现有方法有显著提升。

Abstract: Existing methods for preference tuning of text-to-image (T2I) diffusion models often rely on computationally expensive generation steps to create positive and negative pairs of images. These approaches frequently yield training pairs that either lack meaningful differences, are expensive to sample and filter, or exhibit significant variance in irrelevant pixel regions, thereby degrading training efficiency. To address these limitations, we introduce "Di3PO", a novel method for constructing positive and negative pairs that isolates specific regions targeted for improvement during preference tuning, while keeping the surrounding context in the image stable. We demonstrate the efficacy of our approach by applying it to the challenging task of text rendering in diffusion models, showcasing improvements over baseline methods of SFT and DPO.

</details>


### [54] [Uncertainty-Aware 4D Gaussian Splatting for Monocular Occluded Human Rendering](https://arxiv.org/abs/2602.06343)
*Weiquan Wang,Feifei Shao,Lin Li,Zhen Wang,Jun Xiao,Long Chen*

Main category: cs.CV

TL;DR: U-4DGS 提出了一种基于不确定性估计的框架，用于在单目视频中高保真渲染动态人物，特别是在遮挡情况下，通过概率变形网络和双重光栅化流水线来减轻伪影和几何漂移，并在 ZJU-MoCap 和 OcMotion 数据集上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理单目视频动态人物渲染时的遮挡问题时，要么生成模型产生时间闪烁，要么僵化的几何启发式无法捕捉多样性外观。因此，研究的动机是开发一种能同时处理遮挡、减少伪影和几何漂移的方法。

Method: 将任务重构为异方差观测噪声下的最大后验估计问题。提出 U-4DGS 框架，整合了概率变形网络和双重光栅化流水线。该架构生成像素对齐的不确定图，作为自适应梯度调制器，自动衰减不可靠观测的伪影。此外，引入了置信度感知正则化，利用学习到的不确定性选择性地传播时空有效性，以防止缺乏可靠视觉线索的区域发生几何漂移。

Result: U-4DGS 生成的像素对齐不确定图能够自适应地调整梯度，有效缓解了由不可靠观测引起的伪影。通过置信度感知正则化，有效地防止了在信息稀疏区域的几何漂移。在 ZJU-MoCap 和 OcMotion 数据集上的实验结果表明，U-4DGS 在渲染保真度和鲁棒性方面达到了最先进的水平。

Conclusion: U-4DGS 框架通过整合概率变形网络和双重光栅化流水线，并引入不确定性估计和置信度感知正则化，成功解决了单目视频动态人物渲染在遮挡情况下的挑战，实现了更高的渲染质量和鲁棒性。

Abstract: High-fidelity rendering of dynamic humans from monocular videos typically degrades catastrophically under occlusions. Existing solutions incorporate external priors-either hallucinating missing content via generative models, which induces severe temporal flickering, or imposing rigid geometric heuristics that fail to capture diverse appearances. To this end, we reformulate the task as a Maximum A Posteriori estimation problem under heteroscedastic observation noise. In this paper, we propose U-4DGS, a framework integrating a Probabilistic Deformation Network and a Double Rasterization pipeline. This architecture renders pixel-aligned uncertainty maps that act as an adaptive gradient modulator, automatically attenuating artifacts from unreliable observations. Furthermore, to prevent geometric drift in regions lacking reliable visual cues, we enforce Confidence-Aware Regularizations, which leverage the learned uncertainty to selectively propagate spatial-temporal validity. Extensive experiments on ZJU-MoCap and OcMotion demonstrate that U-4DGS achieves SOTA rendering fidelity and robustness.

</details>


### [55] [Robust Pedestrian Detection with Uncertain Modality](https://arxiv.org/abs/2602.06363)
*Qian Bie,Xiao Wang,Bin Yang,Zhixi Yu,Jun Chen,Xin Xu*

Main category: cs.CV

TL;DR: 本文提出了一种用于跨模态行人检测（CMPD）的自适应不确定性感知网络（AUNet），该网络能够处理任意的RGB、NIR和TIR模态输入组合，克服了现有方法在模态缺失时的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有的CMPD方法依赖于RGB和TIR模态，但在TIR模态中行人纹理信息丢失。NIR模态可以弥补这一不足，但实际应用中可能无法同时获取所有三种模态，导致现有CMPD方法在模态不确定输入下性能下降。

Method: 本文构建了新的Triplet RGB-NIR-TIR（TRNT）数据集。提出了自适应不确定性感知网络（AUNet），包含统一模态验证细化（UMVR）模块（不确定性感知路由器和语义细化）以及模态感知交互（MAI）模块，以处理任意模态组合输入。

Result: AUNet能够准确辨别模态可用性，并充分利用可用信息，在模态缺失的情况下表现出色，有效提升了CMPD的鲁棒性。

Conclusion: AUNet是一种有效的CMPD方法，能够处理不可预测的模态组合输入，显著提高了在各种实际场景下的行人检测性能。

Abstract: Existing cross-modal pedestrian detection (CMPD) employs complementary information from RGB and thermal-infrared (TIR) modalities to detect pedestrians in 24h-surveillance systems.RGB captures rich pedestrian details under daylight, while TIR excels at night. However, TIR focuses primarily on the person's silhouette, neglecting critical texture details essential for detection. While the near-infrared (NIR) captures texture under low-light conditions, which effectively alleviates performance issues of RGB and detail loss in TIR, thereby reducing missed detections. To this end, we construct a new Triplet RGB-NIR-TIR (TRNT) dataset, comprising 8,281 pixel-aligned image triplets, establishing a comprehensive foundation for algorithmic research. However, due to the variable nature of real-world scenarios, imaging devices may not always capture all three modalities simultaneously. This results in input data with unpredictable combinations of modal types, which challenge existing CMPD methods that fail to extract robust pedestrian information under arbitrary input combinations, leading to significant performance degradation. To address these challenges, we propose the Adaptive Uncertainty-aware Network (AUNet) for accurately discriminating modal availability and fully utilizing the available information under uncertain inputs. Specifically, we introduce Unified Modality Validation Refinement (UMVR), which includes an uncertainty-aware router to validate modal availability and a semantic refinement to ensure the reliability of information within the modality. Furthermore, we design a Modality-Aware Interaction (MAI) module to adaptively activate or deactivate its internal interaction mechanisms per UMVR output, enabling effective complementary information fusion from available modalities.

</details>


### [56] [Revisiting Salient Object Detection from an Observer-Centric Perspective](https://arxiv.org/abs/2602.06369)
*Fuxi Zhang,Yifan Wang,Hengrun Zhao,Zhuohan Sun,Changxing Xia,Lijun Wang,Huchuan Lu,Yangrui Shao,Chen Yang,Long Teng*

Main category: cs.CV

TL;DR: 本研究提出了一种新的观察者中心显著目标检测（OC-SOD）方法，该方法考虑了视觉线索和观察者特定因素，以解决现有方法将显著性检测视为客观问题的不足。研究人员构建了一个名为OC-SODBench的新数据集，并开发了一个名为OC-SODAgent的基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有显著目标检测方法将问题视为客观预测任务，忽略了人类感知的主观性和多样性，导致问题欠适定且不适定。本研究旨在通过引入观察者中心视角来解决这个问题。

Method: 提出观察者中心显著目标检测（OC-SOD）框架，该框架结合视觉线索和观察者特定因素（如偏好或意图）。利用多模态大型语言模型开发数据标注流程，构建了OC-SODBench数据集。设计了一个名为OC-SODAgent的基线模型，采用“感知-反思-调整”的过程进行OC-SOD。

Result: 在提出的OC-SODBench数据集上进行了广泛的实验，证明了所提出方法的有效性。OC-SODAgent在OC-SOD任务上取得了比现有方法更好的性能。

Conclusion: 本研究通过观察者中心视角，为显著目标检测提供了一种更真实、更灵活的方法，弥合了人类感知与计算模型之间的差距，并为理解“显著性”提供了新的见解。新数据集和基线模型为未来的研究提供了基础。

Abstract: Salient object detection is inherently a subjective problem, as observers with different priors may perceive different objects as salient. However, existing methods predominantly formulate it as an objective prediction task with a single groundtruth segmentation map for each image, which renders the problem under-determined and fundamentally ill-posed. To address this issue, we propose Observer-Centric Salient Object Detection (OC-SOD), where salient regions are predicted by considering not only the visual cues but also the observer-specific factors such as their preferences or intents. As a result, this formulation captures the intrinsic ambiguity and diversity of human perception, enabling personalized and context-aware saliency prediction. By leveraging multi-modal large language models, we develop an efficient data annotation pipeline and construct the first OC-SOD dataset named OC-SODBench, comprising 33k training, validation and test images with 152k textual prompts and object pairs. Built upon this new dataset, we further design OC-SODAgent, an agentic baseline which performs OC-SOD via a human-like "Perceive-Reflect-Adjust" process. Extensive experiments on our proposed OC-SODBench have justified the effectiveness of our contribution. Through this observer-centric perspective, we aim to bridge the gap between human perception and computational modeling, offering a more realistic and flexible understanding of what makes an object truly "salient." Code and dataset are publicly available at: https://github.com/Dustzx/OC_SOD

</details>


### [57] [TFusionOcc: Student's t-Distribution Based Object-Centric Multi-Sensor Fusion Framework for 3D Occupancy Prediction](https://arxiv.org/abs/2602.06400)
*Zhenxing Ming,Julie Stephany Berrio,Mao Shan,Stewart Worrall*

Main category: cs.CV

TL;DR: 本文提出了一种名为TFusionOcc的新型三维语义占用预测框架，通过多阶段多传感器融合、学生t分布、T-Mixture模型和可变形超二次曲面等方法，显著提升了自动驾驶车辆对周围环境的感知能力，并在nuScenes数据集上取得了SOTA性能，同时对nuScenes-C数据集上的各种噪声干扰表现出良好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有三维语义占用预测方法依赖于三维体素或三维高斯表示，难以有效捕捉三维驾驶环境中精细的几何细节，作者旨在解决这一问题。

Method: 提出TFusionOcc框架，采用多阶段多传感器融合，利用学生t分布和T-Mixture模型，并引入可变形超二次曲面（带有逆向变形场的超二次曲面）作为更灵活的几何原始表示。

Result: 在nuScenes数据集上实现了SOTA性能，并在nuScenes-C数据集的各种相机和激光雷达损坏场景下证明了方法的鲁棒性。

Conclusion: TFusionOcc通过引入更灵活的几何表示和多阶段融合机制，有效提升了三维语义占用预测的性能和鲁棒性，为自动驾驶车辆提供了更精细的环境感知能力。

Abstract: 3D semantic occupancy prediction enables autonomous vehicles (AVs) to perceive fine-grained geometric and semantic structure of their surroundings from onboard sensors, which is essential for safe decision-making and navigation. Recent models for 3D semantic occupancy prediction have successfully addressed the challenge of describing real-world objects with varied shapes and classes. However, the intermediate representations used by existing methods for 3D semantic occupancy prediction rely heavily on 3D voxel volumes or a set of 3D Gaussians, hindering the model's ability to efficiently and effectively capture fine-grained geometric details in the 3D driving environment. This paper introduces TFusionOcc, a novel object-centric multi-sensor fusion framework for predicting 3D semantic occupancy. By leveraging multi-stage multi-sensor fusion, Student's t-distribution, and the T-Mixture model (TMM), together with more geometrically flexible primitives, such as the deformable superquadric (superquadric with inverse warp), the proposed method achieved state-of-the-art (SOTA) performance on the nuScenes benchmark. In addition, extensive experiments were conducted on the nuScenes-C dataset to demonstrate the robustness of the proposed method in different camera and lidar corruption scenarios. The code will be available at: https://github.com/DanielMing123/TFusionOcc

</details>


### [58] [POINTS-GUI-G: GUI-Grounding Journey](https://arxiv.org/abs/2602.06391)
*Zhongyin Zhao,Yuan Liu,Yikun Liu,Haicheng Wang,Le Tian,Xiao Zhou,Yangxiu You,Zilin Yu,Yang Yu,Jie Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为POINTS-GUI-G-8B的视觉语言模型，它在GUI（图形用户界面）基础能力，特别是GUI元素定位方面取得了SOTA（state-of-the-art）性能，即使是从一个基础模型开始。该模型通过改进数据工程、训练策略和引入可验证奖励的强化学习来实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多依赖于本身具有强大空间感知能力的基础模型来构建GUI代理，而本文旨在从一个基础能力较弱的模型开始，掌握完整的技术流程，以证明其通用性和提升GUI代理的鲁棒性。

Method: 作者提出了一种名为POINTS-GUI-G-8B的模型，其改进主要体现在三个方面：1. 精细化的数据工程，包括数据格式统一、数据增强、过滤和难度分级。2. 改进的训练策略，持续微调视觉编码器以提高感知准确性，并保持训练和推理时分辨率的一致性。3. 引入带有可验证奖励的强化学习（RL），利用GUI任务中奖励易于验证的特性，提高定位的精确度。

Result: POINTS-GUI-G-8B模型在多个GUI基础能力评估基准上取得了SOTA性能，包括ScreenSpot-Pro（59.9）、OSWorld-G（66.0）、ScreenSpot-v2（95.7）和UI-Vision（49.9）。

Conclusion: 该研究表明，通过精心设计的数据工程、训练策略和引入可验证奖励的强化学习，即使是从一个基础能力较弱的模型出发，也可以在GUI基础能力任务中达到顶尖水平，并验证了强化学习在感知密集型任务中的有效性。

Abstract: The rapid advancement of vision-language models has catalyzed the emergence of GUI agents, which hold immense potential for automating complex tasks, from online shopping to flight booking, thereby alleviating the burden of repetitive digital workflows. As a foundational capability, GUI grounding is typically established as a prerequisite for end-to-end task execution. It enables models to precisely locate interface elements, such as text and icons, to perform accurate operations like clicking and typing. Unlike prior works that fine-tune models already possessing strong spatial awareness (e.g., Qwen3-VL), we aim to master the full technical pipeline by starting from a base model with minimal grounding ability, such as POINTS-1.5. We introduce POINTS-GUI-G-8B, which achieves state-of-the-art performance with scores of 59.9 on ScreenSpot-Pro, 66.0 on OSWorld-G, 95.7 on ScreenSpot-v2, and 49.9 on UI-Vision. Our model's success is driven by three key factors: (1) Refined Data Engineering, involving the unification of diverse open-source datasets format alongside sophisticated strategies for augmentation, filtering, and difficulty grading; (2) Improved Training Strategies, including continuous fine-tuning of the vision encoder to enhance perceptual accuracy and maintaining resolution consistency between training and inference; and (3) Reinforcement Learning (RL) with Verifiable Rewards. While RL is traditionally used to bolster reasoning, we demonstrate that it significantly improves precision in the perception-intensive GUI grounding task. Furthermore, GUI grounding provides a natural advantage for RL, as rewards are easily verifiable and highly accurate.

</details>


### [59] [MeDocVL: A Visual Language Model for Medical Document Understanding and Parsing](https://arxiv.org/abs/2602.06402)
*Wenjie Wang,Wei Wu,Ying Liu,Yuan Zhao,Xiaole Lv,Liang Diao,Zengjian Fan,Wenfeng Xie,Ziling Lin,De Shi,Lin Huang,Kaihe Xu,Hong Li*

Main category: cs.CV

TL;DR: 提出了一种名为 MeDocVL 的新型视觉语言模型，用于医疗文档的查询驱动解析，通过结合标签精炼和噪声感知混合后训练策略，在嘈杂标注的情况下实现了先进的提取性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 OCR 系统和通用视觉语言模型在处理复杂布局、领域特定术语和嘈杂标注的医疗文档时表现不佳，而医疗文档解析需要严格的字段级精确匹配。

Method: 提出 MeDocVL 模型，该模型结合了两种策略：1. 训练驱动标签精炼（Training-driven Label Refinement），用于从嘈杂标注构建高质量监督信息。2. 噪声感知混合后训练（Noise-aware Hybrid Post-training），整合了强化学习和监督微调。

Result: 在医疗发票基准测试中，MeDocVL 表现优于传统的 OCR 系统和强大的 VLM 基线，在嘈杂监督的情况下达到了最先进的性能。

Conclusion: MeDocVL 是一种有效的后训练视觉语言模型，能够处理医疗文档解析的挑战，并在嘈杂的标注条件下提供鲁棒且精确的提取。

Abstract: Medical document OCR is challenging due to complex layouts, domain-specific terminology, and noisy annotations, while requiring strict field-level exact matching. Existing OCR systems and general-purpose vision-language models often fail to reliably parse such documents. We propose MeDocVL, a post-trained vision-language model for query-driven medical document parsing. Our framework combines Training-driven Label Refinement to construct high-quality supervision from noisy annotations, with a Noise-aware Hybrid Post-training strategy that integrates reinforcement learning and supervised fine-tuning to achieve robust and precise extraction. Experiments on medical invoice benchmarks show that MeDocVL consistently outperforms conventional OCR systems and strong VLM baselines, achieving state-of-the-art performance under noisy supervision.

</details>


### [60] [EUGens: Efficient, Unified, and General Dense Layers](https://arxiv.org/abs/2410.09771)
*Sang Min Kim,Byeongchan Kim,Arijit Sehanobish,Somnath Basu Roy Chowdhury,Rahul Kidambi,Dongseok Shim,Avinava Dubey,Snigdha Chaturvedi,Min-hwan Oh,Krzysztof Choromanski*

Main category: cs.CV

TL;DR: 本文提出了一种名为 EUGens 的新型全连接层，它使用随机特征来近似标准全连接层，并引入输入范数依赖，从而将推理复杂度从二次降低到线性，减少参数数量和计算量，同时保持模型表达能力。该方法还能实现首个无偏近似标准全连接层的算法，并提出了一种无需反向传播的层级知识迁移技术。实验证明，EUGens 在图像分类、语言模型预训练和 3D 场景重建等任务中，集成到 Transformer 和 MLP 中可以显著提高推理速度（高达 27%）和内存效率（高达 30%）。


<details>
  <summary>Details</summary>
Motivation: 标准全连接层（FFLs）在神经网络中引入了计算和参数数量的瓶颈，限制了模型在实时应用和资源受限环境下的扩展性。因此，需要更高效的全连接层替代方案。

Method: 提出了一种名为 EUGens（Efficient, Unified and General dense layers）的新型密集层。EUGens 利用随机特征来近似标准 FFLs，并引入输入范数的直接依赖。它们将推理复杂度从二次降低到线性，并实现了首个对具有任意多项式激活函数的 FFLs 的无偏近似算法。

Result: EUGens 将推理复杂度从二次降低到线性，减少了参数数量和计算开销，同时保留了 FFLs 的表达能力和适应性。实验表明，将 EUGens 集成到 Transformer 和 MLP 中，在图像分类、语言模型预训练和 3D 场景重建等任务上，推理速度提高了高达 27%，内存效率提高了高达 30%。

Conclusion: EUGens 是一种高效、通用且统一的全连接层，通过引入随机特征和输入范数依赖，显著降低了计算和参数复杂度，同时保持了模型的性能。该方法为大规模神经网络在实际场景中的可扩展部署提供了潜力，并为高效模型适应提供了新的技术。

Abstract: Efficient neural networks are essential for scaling machine learning models to real-time applications and resource-constrained environments. Fully-connected feedforward layers (FFLs) introduce computation and parameter count bottlenecks within neural network architectures. To address this challenge, in this work, we propose a new class of dense layers that generalize standard fully-connected feedforward layers, \textbf{E}fficient, \textbf{U}nified and \textbf{Gen}eral dense layers (EUGens). EUGens leverage random features to approximate standard FFLs and go beyond them by incorporating a direct dependence on the input norms in their computations. The proposed layers unify existing efficient FFL extensions and improve efficiency by reducing inference complexity from quadratic to linear time. They also lead to \textbf{the first} unbiased algorithms approximating FFLs with arbitrary polynomial activation functions. Furthermore, EuGens reduce the parameter count and computational overhead while preserving the expressive power and adaptability of FFLs. We also present a layer-wise knowledge transfer technique that bypasses backpropagation, enabling efficient adaptation of EUGens to pre-trained models. Empirically, we observe that integrating EUGens into Transformers and MLPs yields substantial improvements in inference speed (up to \textbf{27}\%) and memory efficiency (up to \textbf{30}\%) across a range of tasks, including image classification, language model pre-training, and 3D scene reconstruction. Overall, our results highlight the potential of EUGens for the scalable deployment of large-scale neural networks in real-world scenarios.

</details>


### [61] [A neuromorphic model of the insect visual system for natural image processing](https://arxiv.org/abs/2602.06405)
*Adam D. Hines,Karin Nordström,Andrew B. Barron*

Main category: cs.CV

TL;DR: 本文提出了一种受昆虫视觉启发的、能够生成稀疏判别性代码的自监督视觉模型。该模型在花卉识别和自然图像基准测试中表现良好，并在模拟定位任务中优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 当前许多计算视觉模型虽然任务表现优异，但忽略了生物学上合理的处理通路。作者希望创建一个受昆虫视觉系统启发的、能够进行稀疏计算的模型。

Method: 作者构建了一个生物启发式视觉模型，该模型能够将密集视觉输入转化为稀疏、判别性代码。模型采用完全自监督的对比学习目标进行训练，无需标记数据。模型实现了人工神经网络和脉冲神经网络两种形式。

Result: 模型生成的稀疏代码能够可靠地区分视觉上相似的输入。在花卉识别和自然图像基准测试中，模型表现出优异的性能。在模拟定位任务中，该方法优于简单的图像降采样基线。

Conclusion: 这项工作提供了一个可泛化的、受昆虫视觉启发的模型，能够在各种任务中进行稀疏计算，推动了昆虫计算建模的发展。

Abstract: Insect vision supports complex behaviors including associative learning, navigation, and object detection, and has long motivated computational models for understanding biological visual processing. However, many contemporary models prioritize task performance while neglecting biologically grounded processing pathways. Here, we introduce a bio-inspired vision model that captures principles of the insect visual system to transform dense visual input into sparse, discriminative codes. The model is trained using a fully self-supervised contrastive objective, enabling representation learning without labeled data and supporting reuse across tasks without reliance on domain-specific classifiers. We evaluated the resulting representations on flower recognition tasks and natural image benchmarks. The model consistently produced reliable sparse codes that distinguish visually similar inputs. To support different modelling and deployment uses, we have implemented the model as both an artificial neural network and a spiking neural network. In a simulated localization setting, our approach outperformed a simple image downsampling comparison baseline, highlighting the functional benefit of incorporating neuromorphic visual processing pathways. Collectively, these results advance insect computational modelling by providing a generalizable bio-inspired vision model capable of sparse computation across diverse tasks.

</details>


### [62] [Efficient-LVSM: Faster, Cheaper, and Better Large View Synthesis Model via Decoupled Co-Refinement Attention](https://arxiv.org/abs/2602.06478)
*Xiaosong Jia,Yihang Sun,Junqi You,Songbur Wong,Zichen Zou,Junchi Yan,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 提出了一种名为Efficient-LVSM的改进型Transformer模型，用于新视图合成（NVS），该模型通过双流架构和解耦的协同细化机制，解决了全自注意力机制的计算效率和参数共享问题，并在性能和速度上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的NVS模型（如LVSM）存在计算复杂度高（与输入视图数量呈二次方关系）以及对异构Token进行僵化参数共享的问题，作者认为其全自注意力设计并非最优。

Method: 提出Efficient-LVSM，采用双流架构，通过解耦的协同细化机制解决上述问题。具体而言，对输入视图应用视图内自注意力（intra-view self-attention），对目标视图应用先自注意力后交叉注意力的机制（self-then-cross attention），从而避免了不必要的计算。

Result: 在RealEstate10K数据集上，使用2个输入视图时，Efficient-LVSM实现了29.86 dB的PSNR，比LVSM提高了0.2 dB。同时，训练收敛速度提高了2倍，推理速度提高了4.4倍。Efficient-LVSM在多个基准测试中均取得了最先进的性能，并展现出对不同视图数量的强大零样本泛化能力，以及通过KV缓存实现增量推理的能力。

Conclusion: Efficient-LVSM通过其解耦的双流架构和协同细化机制，有效地提高了Transformer模型在NVS任务上的效率和性能，克服了现有方法的局限性，并在速度、精度和泛化能力上均取得了显著提升。

Abstract: Feedforward models for novel view synthesis (NVS) have recently advanced by transformer-based methods like LVSM, using attention among all input and target views. In this work, we argue that its full self-attention design is suboptimal, suffering from quadratic complexity with respect to the number of input views and rigid parameter sharing among heterogeneous tokens. We propose Efficient-LVSM, a dual-stream architecture that avoids these issues with a decoupled co-refinement mechanism. It applies intra-view self-attention for input views and self-then-cross attention for target views, eliminating unnecessary computation. Efficient-LVSM achieves 29.86 dB PSNR on RealEstate10K with 2 input views, surpassing LVSM by 0.2 dB, with 2x faster training convergence and 4.4x faster inference speed. Efficient-LVSM achieves state-of-the-art performance on multiple benchmarks, exhibits strong zero-shot generalization to unseen view counts, and enables incremental inference with KV-cache, thanks to its decoupled designs.

</details>


### [63] [Point Virtual Transformer](https://arxiv.org/abs/2602.06406)
*Veerain Sood,Bnalin,Gaurav Pandey*

Main category: cs.CV

TL;DR: 提出了一种名为PointViT的基于Transformer的3D目标检测框架，通过结合稀疏的激光雷达点云和选择性采样的虚拟点来解决远距离物体检测的挑战，并采用了多种融合策略和稀疏卷积来生成BEV表示，最终通过Transformer模块进行上下文聚合。


<details>
  <summary>Details</summary>
Motivation: 现有的基于激光雷达的3D目标检测器在远距离检测方面存在困难，因为远距离点云稀疏，几何线索不可靠。现有的方法通过RGB图像的深度完成的虚拟点来增强数据，但这会增加计算成本并带来融合问题。

Method: 提出Point Virtual Transformer (PointViT) 框架，该框架联合推理原始激光雷达点和选择性采样的虚拟点。研究了多种融合策略（从早期点级融合到BEV门控融合），并将融合后的点云进行体素化和稀疏卷积编码，生成BEV表示。然后，利用Transformer进行上下文聚合来初始化和细化高置信度的目标查询。

Result: 在KITTI基准测试中，PointViT在Car类别的3D AP上达到了91.16%，BEV AP上达到了95.94%，在KITTI 2D检测基准测试中达到了99.36%的AP。

Conclusion: PointViT通过有效融合真实和虚拟点云信息，并采用Transformer架构，显著提高了在KITTI数据集上的3D和2D目标检测性能，尤其是在远距离物体检测方面。

Abstract: LiDAR-based 3D object detectors often struggle to detect far-field objects due to the sparsity of point clouds at long ranges, which limits the availability of reliable geometric cues. To address this, prior approaches augment LiDAR data with depth-completed virtual points derived from RGB images; however, directly incorporating all virtual points leads to increased computational cost and introduces challenges in effectively fusing real and virtual information. We present Point Virtual Transformer (PointViT), a transformer-based 3D object detection framework that jointly reasons over raw LiDAR points and selectively sampled virtual points. The framework examines multiple fusion strategies, ranging from early point-level fusion to BEV-based gated fusion, and analyses their trade-offs in terms of accuracy and efficiency. The fused point cloud is voxelized and encoded using sparse convolutions to form a BEV representation, from which a compact set of high-confidence object queries is initialised and refined through a transformer-based context aggregation module. Experiments on the KITTI benchmark report 91.16% 3D AP, 95.94% BEV AP, and 99.36% AP on the KITTI 2D detection benchmark for the Car class.

</details>


### [64] [LIBERO-X: Robustness Litmus for Vision-Language-Action Models](https://arxiv.org/abs/2602.06556)
*Guodong Wang,Chenkai Zhang,Qingjie Liu,Jinjin Zhang,Jiancheng Cai,Junjie Liu,Xinmin Liu*

Main category: cs.CV

TL;DR: 本文提出了LIBERO-X，一个包含分层评估协议和多样化训练数据集的视觉-语言-动作（VLA）模型基准测试，旨在更可靠地评估VLA模型的泛化和鲁棒性，克服现有基准测试的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型基准测试在评估泛化性、鲁棒性和感知与语言驱动操作任务的对齐方面存在不足，评估协议不充分，未能有效捕捉真实世界分布变化。

Method: 提出了一种分层评估协议，包含三个核心能力（空间泛化、物体识别、任务指令理解）的递进难度级别。构建了一个高多样性的、通过人类遥操作收集的训练数据集，每个场景支持多个精细操作目标，以缩小训练-评估分布差距。

Result: 在LIBERO-X基准测试上，代表性的VLA模型在累积扰动下表现出显著的性能下降，暴露了在场景理解和指令理解方面的持续局限性。

Conclusion: LIBERO-X通过整合分层评估和多样化训练数据，为评估和改进VLA模型开发提供了更可靠的基础，能更有效地揭示模型在复杂环境和任务下的性能瓶颈。

Abstract: Reliable benchmarking is critical for advancing Vision-Language-Action (VLA) models, as it reveals their generalization, robustness, and alignment of perception with language-driven manipulation tasks. However, existing benchmarks often provide limited or misleading assessments due to insufficient evaluation protocols that inadequately capture real-world distribution shifts. This work systematically rethinks VLA benchmarking from both evaluation and data perspectives, introducing LIBERO-X, a benchmark featuring: 1) A hierarchical evaluation protocol with progressive difficulty levels targeting three core capabilities: spatial generalization, object recognition, and task instruction understanding. This design enables fine-grained analysis of performance degradation under increasing environmental and task complexity; 2) A high-diversity training dataset collected via human teleoperation, where each scene supports multiple fine-grained manipulation objectives to bridge the train-evaluation distribution gap. Experiments with representative VLA models reveal significant performance drops under cumulative perturbations, exposing persistent limitations in scene comprehension and instruction grounding. By integrating hierarchical evaluation with diverse training data, LIBERO-X offers a more reliable foundation for assessing and advancing VLA development.

</details>


### [65] [Learning Human Visual Attention on 3D Surfaces through Geometry-Queried Semantic Priors](https://arxiv.org/abs/2602.06419)
*Soham Pahari,Sandeep C. Kumain*

Main category: cs.CV

TL;DR: 提出了一种名为SemGeo-AttentionNet的双流网络，通过融合几何和语义信息来模拟人类对3D物体的视觉注意力，并将其扩展到生成符合3D网格拓扑和抑制返回动力学的扫描路径。


<details>
  <summary>Details</summary>
Motivation: 现有3D显著性方法在解释为何人类会在语义上有意义但几何上不突出的区域停留方面存在不足，因此需要一种能够结合几何和语义信息来模拟人类视觉注意力的模型。

Method: 设计了一个双流网络SemGeo-AttentionNet，该网络采用不对称跨模态融合。它利用几何条件多视图渲染的基于扩散的语义先验和点云Transformer进行几何处理。通过交叉注意力机制，几何特征可以查询语义内容，从而实现自下而上的显著性指导自上而下的检索。此外，将该框架通过强化学习扩展到时间扫描路径生成，并引入了第一个尊重3D网格拓扑和抑制返回动力学的模型。

Result: 在SAL3D、NUS3D和3DVA数据集上进行了评估，结果显示在模拟人类3D视觉注意力方面取得了显著的改进。

Conclusion: 基于认知原理设计的架构能够有效地模拟人类对三维物体的视觉注意力，并且提出的SemGeo-AttentionNet能够通过融合几何和语义信息以及生成符合拓扑结构的扫描路径来提升性能。

Abstract: Human visual attention on three-dimensional objects emerges from the interplay between bottom-up geometric processing and top-down semantic recognition. Existing 3D saliency methods rely on hand-crafted geometric features or learning-based approaches that lack semantic awareness, failing to explain why humans fixate on semantically meaningful but geometrically unremarkable regions. We introduce SemGeo-AttentionNet, a dual-stream architecture that explicitly formalizes this dichotomy through asymmetric cross-modal fusion, leveraging diffusion-based semantic priors from geometry-conditioned multi-view rendering and point cloud transformers for geometric processing. Cross-attention ensures geometric features query semantic content, enabling bottom-up distinctiveness to guide top-down retrieval. We extend our framework to temporal scanpath generation through reinforcement learning, introducing the first formulation respecting 3D mesh topology with inhibition-of-return dynamics. Evaluation on SAL3D, NUS3D and 3DVA datasets demonstrates substantial improvements, validating how cognitively motivated architectures effectively model human visual attention on three-dimensional surfaces.

</details>


### [66] [ProtoQuant: Quantization of Prototypical Parts For General and Fine-Grained Image Classification](https://arxiv.org/abs/2602.06592)
*Mikołaj Janusz,Adam Wróbel,Bartosz Zieliński,Dawid Rymarczyk*

Main category: cs.CV

TL;DR: ProtoQuant 提出了一种通过潜在向量量化来稳定和接地原型的模型，实现了高效可解释的 ImageNet 级别泛化。


<details>
  <summary>Details</summary>
Motivation: 现有基于原型部件的模型在 ImageNet 规模的泛化能力和计算效率方面存在不足，且原型易发生漂移，缺乏实际意义。

Method: ProtoQuant 利用潜在向量量化，将原型约束在一个离散的代码书中，从而确保其表示的稳定性，无需微调主干网络。

Result: ProtoQuant 在 ImageNet 和细粒度数据集上取得了具有竞争力的分类精度，并具备与其他原型部件模型相当的可解释性。

Conclusion: ProtoQuant 是一种高效、可解释且可扩展到大规模数据集的原型部件模型，通过潜在向量量化解决了原型稳定性和接地问题。

Abstract: Prototypical parts-based models offer a "this looks like that" paradigm for intrinsic interpretability, yet they typically struggle with ImageNet-scale generalization and often require computationally expensive backbone finetuning. Furthermore, existing methods frequently suffer from "prototype drift," where learned prototypes lack tangible grounding in the training distribution and change their activation under small perturbations. We present ProtoQuant, a novel architecture that achieves prototype stability and grounded interpretability through latent vector quantization. By constraining prototypes to a discrete learned codebook within the latent space, we ensure they remain faithful representations of the training data without the need to update the backbone. This design allows ProtoQuant to function as an efficient, interpretable head that scales to large-scale datasets. We evaluate ProtoQuant on ImageNet and several fine-grained benchmarks (CUB-200, Cars-196). Our results demonstrate that ProtoQuant achieves competitive classification accuracy while generalizing to ImageNet and comparable interpretability metrics to other prototypical-parts-based methods.

</details>


### [67] [Bridging the Indoor-Outdoor Gap: Vision-Centric Instruction-Guided Embodied Navigation for the Last Meters](https://arxiv.org/abs/2602.06427)
*Yuxiang Zhao,Yirong Yang,Yanqing Zhu,Yanfen Shen,Chiyu Wang,Zhining Gu,Pei Shi,Wei Guo,Mu Xu*

Main category: cs.CV

TL;DR: 本研究提出了一种新的“室外到室内”无先验指令驱动的具身导航任务，并开发了一个以视觉为中心的框架和首个相关数据集，以解决现有方法在室内外环境切换和精细化入口定位方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有具身导航方法在室内外环境切换和精细化入口定位方面存在不足，无法实现从室外到室内无缝过渡的实际应用（如最后一英里配送），且过度依赖精确坐标系等强假设。

Method: 提出“室外到室内”无先验指令驱动的具身导航任务。开发了一个以视觉为中心的具身导航框架，利用图像提示指导决策。构建了首个开源数据集，并使用了轨迹条件视频合成技术来生成数据。

Result: 所提出的方法在成功率和路径效率等关键指标上均优于现有最先进的基线方法。

Conclusion: 该研究成功地提出了一个在无外部先验信息下，仅依赖视觉观察和指令的室外到室内导航新任务，并开发了有效的解决方案和数据集，为实现更广泛的具身导航应用铺平了道路。

Abstract: Embodied navigation holds significant promise for real-world applications such as last-mile delivery. However, most existing approaches are confined to either indoor or outdoor environments and rely heavily on strong assumptions, such as access to precise coordinate systems. While current outdoor methods can guide agents to the vicinity of a target using coarse-grained localization, they fail to enable fine-grained entry through specific building entrances, critically limiting their utility in practical deployment scenarios that require seamless outdoor-to-indoor transitions. To bridge this gap, we introduce a novel task: out-to-in prior-free instruction-driven embodied navigation. This formulation explicitly eliminates reliance on accurate external priors, requiring agents to navigate solely based on egocentric visual observations guided by instructions. To tackle this task, we propose a vision-centric embodied navigation framework that leverages image-based prompts to drive decision-making. Additionally, we present the first open-source dataset for this task, featuring a pipeline that integrates trajectory-conditioned video synthesis into the data generation process. Through extensive experiments, we demonstrate that our proposed method consistently outperforms state-of-the-art baselines across key metrics including success rate and path efficiency.

</details>


### [68] [DriveWorld-VLA: Unified Latent-Space World Modeling with Vision-Language-Action for Autonomous Driving](https://arxiv.org/abs/2602.06521)
*Feiyang jia,Lin Liu,Ziying Song,Caiyan Jia,Hangjun Ye,Xiaoshuai Hao,Long Chen*

Main category: cs.CV

TL;DR: 本文提出了DriveWorld-VLA框架，通过在潜在空间中紧密集成视觉-语言-动作（VLA）模型和世界模型，以提升自动驾驶的决策和前瞻性想象能力，并在NAVSIMv1、NAVSIMv2和nuScenes数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法在统一未来场景演化和动作规划时存在不足，未能有效共享潜在状态，导致视觉想象对动作决策的影响受限。

Method: 提出DriveWorld-VLA框架，在潜在空间中统一世界建模和规划。该框架将VLA模型和世界模型在表示层面进行紧密集成，使VLA规划器能够直接受益于整体场景演化建模。世界模型的潜在状态被用作VLA规划器的核心决策状态，支持可控的、动作条件下的潜在空间想象，避免像素级模拟。

Result: 在NAVSIMv1上达到了91.3 PDMS，在NAVSIMv2上达到了86.8 EPDMS，在nuScenes上3秒平均碰撞率为0.16，均取得了最先进的性能。

Conclusion: DriveWorld-VLA框架有效地解决了现有方法在统一场景演化和动作规划方面的局限性，通过在潜在空间中的紧密集成实现了更优的自动驾驶决策和前瞻性能力，并减少了对密集标注的依赖。

Abstract: End-to-end (E2E) autonomous driving has recently attracted increasing interest in unifying Vision-Language-Action (VLA) with World Models to enhance decision-making and forward-looking imagination. However, existing methods fail to effectively unify future scene evolution and action planning within a single architecture due to inadequate sharing of latent states, limiting the impact of visual imagination on action decisions. To address this limitation, we propose DriveWorld-VLA, a novel framework that unifies world modeling and planning within a latent space by tightly integrating VLA and world models at the representation level, which enables the VLA planner to benefit directly from holistic scene-evolution modeling and reducing reliance on dense annotated supervision. Additionally, DriveWorld-VLA incorporates the latent states of the world model as core decision-making states for the VLA planner, facilitating the planner to assess how candidate actions impact future scene evolution. By conducting world modeling entirely in the latent space, DriveWorld-VLA supports controllable, action-conditioned imagination at the feature level, avoiding expensive pixel-level rollouts. Extensive open-loop and closed-loop evaluations demonstrate the effectiveness of DriveWorld-VLA, which achieves state-of-the-art performance with 91.3 PDMS on NAVSIMv1, 86.8 EPDMS on NAVSIMv2, and 0.16 3-second average collision rate on nuScenes. Code and models will be released in https://github.com/liulin815/DriveWorld-VLA.git.

</details>


### [69] [Alleviating Sparse Rewards by Modeling Step-Wise and Long-Term Sampling Effects in Flow-Based GRPO](https://arxiv.org/abs/2602.06422)
*Yunze Tong,Mushui Liu,Canyu Zhao,Wanggui He,Shiyi Zhang,Hongwei Zhang,Peng Zhang,Jinlong Liu,Ju Huang,Jiamang Wang,Hao Jiang,Pipei Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为TurningPoint-GRPO (TP-GRPO) 的新框架，用于改进基于流匹配的文本到图像生成模型。TP-GRPO通过使用逐步增量奖励和识别“转折点”来解决现有方法中奖励稀疏和忽略长期依赖性的问题，从而更有效地利用奖励信号并提高生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于GRPO的文本到图像生成方法存在问题：1. 将全局结果奖励传播给所有预设的去噪步骤，未能区分每个步骤的局部影响。2. 当前的组间排名忽略了轨迹内部的依赖关系，早期去噪操作可以通过延迟的、隐式的交互影响后续状态。需要一种方法来缓解奖励稀疏性并显式地建模去噪轨迹中的长期效应。

Method: TP-GRPO框架包含两个主要创新：1. 使用逐步增量奖励（step-level incremental rewards）替代基于结果的奖励，提供密集的、感知步骤的学习信号，更好地隔离每个去噪动作的“纯”效果。2. 识别“转折点”（turning points）——即局部奖励趋势发生翻转并使后续奖励演变与整体轨迹趋势一致的步骤——并为这些动作分配聚合的长期奖励，以捕捉其延迟影响。转折点仅通过增量奖励的符号变化来检测，无需超参数。

Result: TP-GRPO在实验中显示出更有效地利用奖励信号，并一致地提高了生成质量。它通过更精细的奖励信号和对长期效应的建模，实现了比现有方法更好的性能。

Conclusion: TP-GRPO框架通过引入逐步增量奖励和识别转折点来解决现有GRPO方法在文本到图像生成中的局限性，能够更有效地利用奖励信号，捕捉去噪轨迹中的长期依赖关系，从而在生成效果上取得了一致的提升。

Abstract: Deploying GRPO on Flow Matching models has proven effective for text-to-image generation. However, existing paradigms typically propagate an outcome-based reward to all preceding denoising steps without distinguishing the local effect of each step. Moreover, current group-wise ranking mainly compares trajectories at matched timesteps and ignores within-trajectory dependencies, where certain early denoising actions can affect later states via delayed, implicit interactions. We propose TurningPoint-GRPO (TP-GRPO), a GRPO framework that alleviates step-wise reward sparsity and explicitly models long-term effects within the denoising trajectory. TP-GRPO makes two key innovations: (i) it replaces outcome-based rewards with step-level incremental rewards, providing a dense, step-aware learning signal that better isolates each denoising action's "pure" effect, and (ii) it identifies turning points-steps that flip the local reward trend and make subsequent reward evolution consistent with the overall trajectory trend-and assigns these actions an aggregated long-term reward to capture their delayed impact. Turning points are detected solely via sign changes in incremental rewards, making TP-GRPO efficient and hyperparameter-free. Extensive experiments also demonstrate that TP-GRPO exploits reward signals more effectively and consistently improves generation. Demo code is available at https://github.com/YunzeTong/TurningPoint-GRPO.

</details>


### [70] [SPARC: Separating Perception And Reasoning Circuits for Test-time Scaling of VLMs](https://arxiv.org/abs/2602.06566)
*Niccolo Avogaro,Nayanika Debnath,Li Mi,Thomas Frick,Junling Wang,Zexue He,Hang Hua,Konrad Schindler,Mattia Rigotti*

Main category: cs.CV

TL;DR: SPARC是一个新的视觉语言模型（VLM）框架，它将视觉感知与推理分开，以提高VLM在推理时的稳定性和效率。通过一个两阶段的流程（显式视觉搜索和基于搜索结果的推理），SPARC能够独立扩展各个模块，优化计算资源分配，并减少所需的token数量，从而在视觉推理任务上取得更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在测试时扩展（test-time scaling）时表现不稳定，图像的非结构化思考过程会将感知和推理纠缠在一起，导致上下文混乱，微小的感知错误可能导致完全错误的答案。此外，实现良好性能需要昂贵的、带有手工奖励的强化学习。研究者希望找到一种方法来解耦感知和推理，提高模型的稳定性和效率。

Method: SPARC采用一个两阶段的流水线：1. 显式视觉搜索（explicit visual search），用于定位与问题相关的图像区域。2. 推理（reasoning），在定位到的区域基础上进行推理并给出最终答案。这种方法借鉴了大脑中感官到认知信息的处理过程，实现了感知和推理的明确分离。

Result: SPARC在各种具有挑战性的视觉推理基准测试中，优于单一模型基线和强大的视觉接地方法。具体来说，SPARC在$V^*$ VQA基准上将Qwen3VL-4B的准确率提高了6.7个百分点。在一个具有挑战性的OOD任务上，SPARC的性能比“thinking with images”高4.6个百分点，同时所需的token预算降低了200倍。

Conclusion: SPARC通过将视觉感知与推理显式解耦，提供了一个模块化的框架，提高了VLM在测试时的可扩展性、稳定性和效率。这种分离允许独立的计算分配、选择性的优化以及压缩上下文，从而在视觉推理任务上取得了显著的性能提升。

Abstract: Despite recent successes, test-time scaling - i.e., dynamically expanding the token budget during inference as needed - remains brittle for vision-language models (VLMs): unstructured chains-of-thought about images entangle perception and reasoning, leading to long, disorganized contexts where small perceptual mistakes may cascade into completely wrong answers. Moreover, expensive reinforcement learning with hand-crafted rewards is required to achieve good performance. Here, we introduce SPARC (Separating Perception And Reasoning Circuits), a modular framework that explicitly decouples visual perception from reasoning. Inspired by sequential sensory-to-cognitive processing in the brain, SPARC implements a two-stage pipeline where the model first performs explicit visual search to localize question-relevant regions, then conditions its reasoning on those regions to produce the final answer. This separation enables independent test-time scaling with asymmetric compute allocation (e.g., prioritizing perceptual processing under distribution shift), supports selective optimization (e.g., improving the perceptual stage alone when it is the bottleneck for end-to-end performance), and accommodates compressed contexts by running global search at lower image resolutions and allocating high-resolution processing only to selected regions, thereby reducing total visual tokens count and compute. Across challenging visual reasoning benchmarks, SPARC outperforms monolithic baselines and strong visual-grounding approaches. For instance, SPARC improves the accuracy of Qwen3VL-4B on the $V^*$ VQA benchmark by 6.7 percentage points, and it surpasses "thinking with images" by 4.6 points on a challenging OOD task despite requiring a 200$\times$ lower token budget.

</details>


### [71] [DAVE: Distribution-aware Attribution via ViT Gradient Decomposition](https://arxiv.org/abs/2602.06613)
*Adam Wróbel,Siddhartha Gairola,Jacek Tabor,Bernt Schiele,Bartosz Zieliński,Dawid Rymarczyk*

Main category: cs.CV

TL;DR: 提出了一种名为 DAVE 的新方法，用于为 Vision Transformers (ViTs) 生成稳定且高分辨率的归因图，解决了现有方法在处理 ViT 特有组件（如 Patch Embedding 和 Attention Routing）时产生的结构性伪影问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在为 ViT 生成稳定、高分辨率的归因图时面临挑战，因为 ViT 的架构组件（如 Patch Embedding 和 Attention Routing）会引入结构性伪影，导致许多方法只能生成粗粒度的 Patch 级别归因。

Method: DAVE 是一种基于 ViT 输入梯度结构化分解的数学原理归因方法。它利用 ViT 的架构特性，将输入-输出映射中局部等变且稳定的成分与由架构引起的伪影和其他不稳定性来源分离开来。

Result: DAVE 能够分离出 ViT 中局部等变和稳定的有效输入-输出映射成分，并将其与架构引入的伪影及其他不稳定因素区分开。

Conclusion: DAVE 是一种为 ViT 设计的、基于梯度分解的归因方法，能够生成更稳定、更精细的归因图，有效解决了现有方法在处理 ViT 架构特性时出现的挑战。

Abstract: Vision Transformers (ViTs) have become a dominant architecture in computer vision, yet producing stable and high-resolution attribution maps for these models remains challenging. Architectural components such as patch embeddings and attention routing often introduce structured artifacts in pixel-level explanations, causing many existing methods to rely on coarse patch-level attributions. We introduce DAVE \textit{(\underline{D}istribution-aware \underline{A}ttribution via \underline{V}iT Gradient D\underline{E}composition)}, a mathematically grounded attribution method for ViTs based on a structured decomposition of the input gradient. By exploiting architectural properties of ViTs, DAVE isolates locally equivariant and stable components of the effective input--output mapping. It separates these from architecture-induced artifacts and other sources of instability.

</details>


### [72] [POPL-KF: A Pose-Only Geometric Representation-Based Kalman Filter for Point-Line-Based Visual-Inertial Odometry](https://arxiv.org/abs/2602.06425)
*Aiping Wang,Zhaolong Yang,Shuwen Chen,Hai Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 POPL-KF 的视觉-惯性里程计 (VIO) 系统，它利用点和线特征的纯姿态几何表示，解决了传统 VIO 系统在挑战性场景下性能下降和线性化误差的问题，并在公开数据集和实际实验中取得了优于现有 SOTA 方法的性能，同时保持了实时性。


<details>
  <summary>Details</summary>
Motivation: 主流 VIO 系统依赖点特征，在挑战性场景下性能会下降。MSCKF-VIO 系统的定位精度受到特征三维坐标的线性化误差和测量更新延迟的影响。因此，需要一种改进的 VIO 系统来提高在挑战性场景下的性能。

Method: 1. 提出线特征的纯姿态几何表示。
2. 开发 POPL-KF 系统，为点和线特征采用纯姿态几何表示，通过消除测量方程中的特征坐标来减轻线性化误差，并实现即时更新。
3. 设计统一的基帧选择算法，确保纯姿态测量模型下的相机姿态最优约束。
4. 提出基于图像网格分割和双向光流一致性的线特征滤波器，以提高线特征质量。

Result: POPL-KF 在公开数据集和实际实验中，性能优于 SOTA 的基于滤波的方法（OpenVINS, PO-KF）和基于优化的方法（PL-VINS, EPLF-VINS），并且保持了实时性能。

Conclusion: POPL-KF 系统通过采用纯姿态几何表示和改进的特征处理方法，有效解决了 VIO 系统在挑战性场景下的性能和精度问题，是一种高效且鲁棒的 VIO 解决方案。

Abstract: Mainstream Visual-inertial odometry 
(VIO) systems rely on point features for motion estimation and localization. However, their performance degrades in challenging scenarios. Moreover, the localization accuracy of multi-state constraint Kalman filter (MSCKF)-based VIO systems suffers from linearization errors associated with feature 3D coordinates and delayed measurement updates. To improve the performance of VIO in challenging scenes, we first propose a pose-only geometric representation for line features. Building on this, we develop POPL-KF, a Kalman filter-based VIO system that employs a pose-only geometric representation for both point and line features. POPL-KF mitigates linearization errors by explicitly eliminating both point and line feature coordinates from the measurement equations, while enabling immediate update of visual measurements. We also design a unified base-frames selection algorithm for both point and line features to ensure optimal constraints on camera poses within the pose-only measurement model. To further improve line feature quality, a line feature filter based on image grid segmentation and bidirectional optical flow consistency is proposed. Our system is evaluated on public datasets and real-world experiments, demonstrating that POPL-KF outperforms the state-of-the-art (SOTA) filter-based methods (OpenVINS, PO-KF) and optimization-based methods (PL-VINS, EPLF-VINS), while maintaining real-time performance.

</details>


### [73] [ChatUMM: Robust Context Tracking for Conversational Interleaved Generation](https://arxiv.org/abs/2602.06442)
*Wenxun Dai,Zhiyuan Zhao,Yule Zhong,Yiji Cheng,Jianwei Zhang,Linqing Wang,Shiyi Zhang,Yunlong Lin,Runze He,Fellix Song,Wayne Zhuang,Yong Liu,Haoji Zhang,Yansong Tang,Qinglin Lu,Chunyu Wang*

Main category: cs.CV

TL;DR: 本文提出了ChatUMM，一个统一的多模态模型，通过创新的多轮训练策略和数据合成流水线，实现了连续对话能力，克服了现有模型的单轮交互限制，并在多轮场景下表现出优越的鲁棒性和上下文感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态模型（UMMs）受限于单轮交互范式，无法胜任连续对话任务，因此研究动机是为了构建一个能够进行连续多轮交互的UMM。

Method: ChatUMM通过两种关键创新实现：1. 采用交错式多轮训练策略，将序列化的文本-图像流视为连续对话流；2. 构建系统性的对话数据合成流水线，将标准单轮数据集转化为多轮对话，包括构建基础状态对话、通过“干扰”轮次强制长程依赖以及合成自然交错的多模态响应。

Result: ChatUMM在视觉理解和指令引导编辑基准上取得了领先于开源统一模型的性能，并在文本到图像生成方面保持了竞争力。特别地，ChatUMM在复杂的两轮场景下展现出卓越的鲁棒性。

Conclusion: ChatUMM成功地解决了统一多模态模型的单轮交互限制，通过新颖的训练和数据合成方法，实现了强大的多轮对话能力，并能在复杂场景下进行流利、上下文感知的对话。

Abstract: Unified multimodal models (UMMs) have achieved remarkable progress yet remain constrained by a single-turn interaction paradigm, effectively functioning as solvers for independent requests rather than assistants in continuous dialogue. To bridge this gap, we present ChatUMM. As a conversational unified model, it excels at robust context tracking to sustain interleaved multimodal generation. ChatUMM derives its capabilities from two key innovations: an interleaved multi-turn training strategy that models serialized text-image streams as a continuous conversational flow, and a systematic conversational data synthesis pipeline. This pipeline transforms a diverse set of standard single-turn datasets into fluid dialogues through three progressive stages: constructing basic stateful dialogues, enforcing long-range dependency resolution via ``distractor'' turns with history-dependent query rewriting, and synthesizing naturally interleaved multimodal responses. Extensive evaluations demonstrate that ChatUMM achieves state-of-the-art performance among open-source unified models on visual understanding and instruction-guided editing benchmarks, while maintaining competitive fidelity in text-to-image generation. Notably, ChatUMM exhibits superior robustness in complex multi-turn scenarios, ensuring fluid, context-aware dialogues.

</details>


### [74] [Gold Exploration using Representations from a Multispectral Autoencoder](https://arxiv.org/abs/2602.06748)
*Argyro Tsandalidou,Konstantinos Dogeas,Eleftheria Tetoula Tsonga,Elisavet Parselia,Georgios Tsimiklis,George Arvanitakis*

Main category: cs.CV

TL;DR: 研究提出了一种利用预训练的自编码器（Isometric）从Sentinel-2卫星多光谱图像中提取矿物学特征，并结合XGBoost分类器进行金矿勘探的方法，显著提高了勘探的准确性。


<details>
  <summary>Details</summary>
Motivation: 卫星遥感数据在大规模矿产资源潜力制图中的应用，由于现场勘探数据成本高且可用性有限。

Method: 使用在FalconSpace-S2 v1.0数据集上预训练的自编码器（Isometric）从Sentinel-2卫星多光谱图像中学习生成表示，然后将这些表示作为输入，送入XGBoost分类器进行金矿区域的识别。并将此方法与直接使用原始光谱数据的方法进行了对比。

Result: 基于生成表示的方法将斑块级别的准确率从0.51提高到0.68，图像级别的准确率从0.55提高到0.73。证明了生成嵌入能够捕捉可迁移的矿物学模式，即使在标记数据有限的情况下。

Conclusion: 基于基础模型的生成表示在矿产勘探中具有潜力，可以提高勘探的效率、可扩展性和全球适用性。

Abstract: Satellite imagery is employed for large-scale prospectivity mapping due to the high cost and typically limited availability of on-site mineral exploration data. In this work, we present a proof-of-concept framework that leverages generative representations learned from multispectral Sentinel-2 imagery to identify gold-bearing regions from space. An autoencoder foundation model, called Isometric, which is pretrained on the large-scale FalconSpace-S2 v1.0 dataset, produces information-dense spectral-spatial representations that serve as inputs to a lightweight XGBoost classifier. We compare this representation-based approach with a raw spectral input baseline using a dataset of 63 Sentinel-2 images from known gold and non-gold locations. The proposed method improves patch-level accuracy from 0.51 to 0.68 and image-level accuracy from 0.55 to 0.73, demonstrating that generative embeddings capture transferable mineralogical patterns even with limited labeled data. These results highlight the potential of foundation-model representations to make mineral exploration more efficient, scalable, and globally applicable.

</details>


### [75] [Exploring Specular Reflection Inconsistency for Generalizable Face Forgery Detection](https://arxiv.org/abs/2602.06452)
*Hongyan Fei,Zexi Jia,Chuanwei Huang,Jinchao Zhang,Jie Zhou*

Main category: cs.CV

TL;DR: 提出一种基于光照（特别是Phong模型中的镜面反射）不一致性来检测深度伪造人脸的新方法SRI-Net，该方法通过Retinex理论估计面部纹理以分离镜面反射，并利用交叉注意力机制捕捉镜面反射与其纹理及直射光的关联，在多种数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法在应对高质量、完全AI合成的伪造人脸（特别是扩散模型生成）时效果有限，需要新的检测思路。

Method: 1. 基于Retinex理论快速准确地估计面部纹理，以分离镜面反射。 2. 提出SRI-Net，设计一个两阶段的交叉注意力机制，捕捉镜面反射与其面部纹理和直射光的数学关系，从而检测不一致性。 3. 将镜面反射相关特征与图像特征结合以进行鲁棒检测。

Result: 在传统和生成式深度伪造数据集（尤其包含扩散模型生成的人脸）上，所提出的SRI-Net方法均取得了优于现有方法的性能。

Conclusion: 光照（尤其是镜面反射）的复杂物理规律和参数化特性使其难以被AI完美复制。通过检测镜面反射与其面部纹理、直射光之间的不一致性，可以有效识别深度伪造人脸，并且SRI-Net能够鲁棒地捕获这种不一致性。

Abstract: Detecting deepfakes has become increasingly challenging as forgery faces synthesized by AI-generated methods, particularly diffusion models, achieve unprecedented quality and resolution. Existing forgery detection approaches relying on spatial and frequency features demonstrate limited efficacy against high-quality, entirely synthesized forgeries. In this paper, we propose a novel detection method grounded in the observation that facial attributes governed by complex physical laws and multiple parameters are inherently difficult to replicate. Specifically, we focus on illumination, particularly the specular reflection component in the Phong illumination model, which poses the greatest replication challenge due to its parametric complexity and nonlinear formulation. We introduce a fast and accurate face texture estimation method based on Retinex theory to enable precise specular reflection separation. Furthermore, drawing from the mathematical formulation of specular reflection, we posit that forgery evidence manifests not only in the specular reflection itself but also in its relationship with corresponding face texture and direct light. To address this issue, we design the Specular-Reflection-Inconsistency-Network (SRI-Net), incorporating a two-stage cross-attention mechanism to capture these correlations and integrate specular reflection related features with image features for robust forgery detection. Experimental results demonstrate that our method achieves superior performance on both traditional deepfake datasets and generative deepfake datasets, particularly those containing diffusion-generated forgery faces.

</details>


### [76] [What Is Wrong with Synthetic Data for Scene Text Recognition? A Strong Synthetic Engine with Diverse Simulations and Self-Evolution](https://arxiv.org/abs/2602.06450)
*Xingsong Ye,Yongkun Du,JiaXin Zhang,Chen Li,Jing LYU,Zhineng Chen*

Main category: cs.CV

TL;DR: 该研究提出了一个名为UnionST的数据引擎和UnionST-S数据集，旨在解决现有合成数据在场景文字识别（STR）领域与真实数据之间的域差距。同时，研究还开发了一个自演化学习（SEL）框架，以提高真实数据标注的效率。实验结果表明，使用UnionST-S训练的模型在STR任务上表现优于使用现有合成数据集的模型，甚至在某些场景下超越了真实数据训练的模型，并且SEL框架能够以更少的数据标签实现有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有用于训练STR模型的真实世界文本数据规模和类别平衡性难以达到要求，而合成数据虽然成本低且标注完美，但与真实数据存在显著的域差距，导致性能受限。因此，需要改进合成数据的生成方式以缩小这一差距，并提高真实数据标注的效率。

Method: 1. 对主流基于渲染的合成数据集进行系统性分析，识别其在语料、字体和布局多样性方面的局限性。 2. 提出UnionST数据引擎，用于生成包含具有挑战性的样本并能更好地模拟真实世界复杂性的合成数据。 3. 构建UnionST-S大规模合成数据集，其中包含对复杂场景的改进模拟。 4. 开发自演化学习（SEL）框架，用于对真实数据进行有效标注。

Result: 在STR任务上，使用UnionST-S训练的模型相比现有合成数据集训练的模型取得了显著的性能提升，并在某些场景下超越了真实数据训练的模型。此外，通过SEL框架，模型仅需9%的真实数据标签即可达到有竞争力的性能。

Conclusion: UnionST-S作为一种改进的合成数据集，能够有效缩小与真实数据的域差距，提升STR模型的性能。SEL框架则为高效利用真实世界数据进行模型训练提供了一种新的途径，显著降低了对大量标注真实数据的依赖。

Abstract: Large-scale and categorical-balanced text data is essential for training effective Scene Text Recognition (STR) models, which is hard to achieve when collecting real data. Synthetic data offers a cost-effective and perfectly labeled alternative. However, its performance often lags behind, revealing a significant domain gap between real and current synthetic data. In this work, we systematically analyze mainstream rendering-based synthetic datasets and identify their key limitations: insufficient diversity in corpus, font, and layout, which restricts their realism in complex scenarios. To address these issues, we introduce UnionST, a strong data engine synthesizes text covering a union of challenging samples and better aligns with the complexity observed in the wild. We then construct UnionST-S, a large-scale synthetic dataset with improved simulations in challenging scenarios. Furthermore, we develop a self-evolution learning (SEL) framework for effective real data annotation. Experiments show that models trained on UnionST-S achieve significant improvements over existing synthetic datasets. They even surpass real-data performance in certain scenarios. Moreover, when using SEL, the trained models achieve competitive performance by only seeing 9% of real data labels.

</details>


### [77] [LAB-Det: Language as a Domain-Invariant Bridge for Training-Free One-Shot Domain Generalization in Object Detection](https://arxiv.org/abs/2602.06474)
*Xu Zhang,Zhe Chen,Jing Zhang,Dacheng Tao*

Main category: cs.CV

TL;DR: 提出了一种名为LAB-Det的训练无关的单样本域泛化方法，通过将单个示例投影为文本描述来引导冻结的目标检测器，从而在数据稀缺的领域实现了比微调更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的目标检测器在专业领域（如水下图像、工业缺陷）数据稀缺时性能会下降。传统的跨领域少样本方法需要微调，成本高且有过度拟合的风险。研究者希望在不更新模型权重的情况下，仅使用每个类别的单个示例就能使冻结的检测器适应新领域。

Method: 提出LAB-Det方法，利用语言作为领域不变的桥梁。具体做法是将每个类别的单个示例投影到其描述性文本，然后利用这些文本来条件化和引导一个冻结的目标检测器。这种方法不依赖于梯度更新，而是通过语言来指导模型的适应。

Result: 在UODD（水下）和NEU-DET（工业缺陷）两个数据稀缺的基准测试上进行了评估。LAB-Det在不更新任何参数的情况下，相较于最先进的微调基线方法，mAP最高提升了5.4。

Conclusion: 研究结果表明，在专业和数据稀缺的检测场景下，利用语言进行适应是一种比微调更有效且可解释的替代方案，能够实现鲁棒的泛化能力。

Abstract: Foundation object detectors such as GLIP and Grounding DINO excel on general-domain data but often degrade in specialized and data-scarce settings like underwater imagery or industrial defects. Typical cross-domain few-shot approaches rely on fine-tuning scarce target data, incurring cost and overfitting risks. We instead ask: Can a frozen detector adapt with only one exemplar per class without training? To answer this, we introduce training-free one-shot domain generalization for object detection, where detectors must adapt to specialized domains with only one annotated exemplar per class and no weight updates. To tackle this task, we propose LAB-Det, which exploits Language As a domain-invariant Bridge. Instead of adapting visual features, we project each exemplar into a descriptive text that conditions and guides a frozen detector. This linguistic conditioning replaces gradient-based adaptation, enabling robust generalization in data-scarce domains. We evaluate on UODD (underwater) and NEU-DET (industrial defects), two widely adopted benchmarks for data-scarce detection, where object boundaries are often ambiguous, and LAB-Det achieves up to 5.4 mAP improvement over state-of-the-art fine-tuned baselines without updating a single parameter. These results establish linguistic adaptation as an efficient and interpretable alternative to fine-tuning in specialized detection settings.

</details>


### [78] [Instance-Free Domain Adaptive Object Detection](https://arxiv.org/abs/2602.06484)
*Hengfu Yu,Jinhong Deng,Lixin Duan,Wen Li*

Main category: cs.CV

TL;DR: 本文提出了一种新的实例无关域自适应目标检测（Instance-Free DAOD）问题，并引入了关系结构一致性网络（RSCN）来解决。RSCN利用背景特征原型进行对齐，并鼓励源域和目标域前景与背景特征之间的一致性，从而在目标域无实例的情况下实现鲁棒的域适应。此外，作者还创建了三个相关基准来推动该领域的研究。


<details>
  <summary>Details</summary>
Motivation: 现有的域自适应目标检测（DAOD）方法通常依赖于包含足够前景实例的无标签目标数据。然而，在许多实际应用场景中（如野生动物监测、病灶检测），收集包含目标物种的目标域数据成本高昂，而背景数据却很丰富。这种约束给域对齐带来了巨大挑战，因为目标实例不可用，适应只能依赖目标背景信息。因此，研究者希望解决在目标域缺乏实例时进行域自适应的问题。

Method: 本文提出了关系结构一致性网络（RSCN）。该网络采用了一种新颖的对齐策略，该策略基于背景特征原型。同时，它鼓励源域前景特征与目标域背景特征之间的关系一致性，即使在目标域没有实例的情况下也能实现鲁棒的适应。

Result: 在三个新创建的基准（模拟自动驾驶检测、野生动物检测、肺结节检测）上进行的广泛实验表明，RSCN在实例无关场景下显著优于现有的DAOD方法。

Conclusion: RSCN成功地解决了实例无关域自适应目标检测的挑战，通过利用背景信息和前景-背景关系的一致性，即使在目标域缺乏实例的情况下也能实现有效的域适应。作者还通过创建新的基准数据集，为该领域的研究做出了贡献。

Abstract: While Domain Adaptive Object Detection (DAOD) has made significant strides, most methods rely on unlabeled target data that is assumed to contain sufficient foreground instances. However, in many practical scenarios (e.g., wildlife monitoring, lesion detection), collecting target domain data with objects of interest is prohibitively costly, whereas background-only data is abundant. This common practical constraint introduces a significant technical challenge: the difficulty of achieving domain alignment when target instances are unavailable, forcing adaptation to rely solely on the target background information. We formulate this challenge as the novel problem of Instance-Free Domain Adaptive Object Detection. To tackle this, we propose the Relational and Structural Consistency Network (RSCN) which pioneers an alignment strategy based on background feature prototypes while simultaneously encouraging consistency in the relationship between the source foreground features and the background features within each domain, enabling robust adaptation even without target instances. To facilitate research, we further curate three specialized benchmarks, including simulative auto-driving detection, wildlife detection, and lung nodule detection. Extensive experiments show that RSCN significantly outperforms existing DAOD methods across all three benchmarks in the instance-free scenario. The code and benchmarks will be released soon.

</details>


### [79] [Rebenchmarking Unsupervised Monocular 3D Occupancy Prediction](https://arxiv.org/abs/2602.06488)
*Zizhan Guo,Yi Feng,Mengtan Zhang,Haoran Zhang,Wei Ye,Rui Fan*

Main category: cs.CV

TL;DR: 该研究提出了一个改进的无监督单目3D占用预测基准，解决了现有方法在训练和评估过程中的不一致性以及遮挡区域歧义性问题，并通过引入新的表示和多视角线索的遮挡感知极化机制，使得无监督方法在性能上能够媲美监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有无监督单目3D占用预测方法在训练和评估时存在不一致性，且2D地面真值无法处理遮挡区域的歧义性，导致性能受限。

Method: 1. 重新解释体渲染过程中的变量，识别最符合物理规律的占用概率表示。 2. 改进评估协议，使新的表示与3D占用地面真值对齐，实现无监督方法与监督方法一致的评估。 3. 引入遮挡感知极化机制，利用多视角视觉线索处理遮挡区域，增强区分占位和自由空间的能力。

Result: 提出的方法显著优于现有的无监督方法，并且性能达到了监督方法的水平。

Conclusion: 通过对体渲染过程的深入分析和新颖的评估协议以及遮挡感知机制，可以有效地提升无监督单目3D占用预测的性能，并使其在遮挡区域的处理上与监督方法相媲美。

Abstract: Inferring the 3D structure from a single image, particularly in occluded regions, remains a fundamental yet unsolved challenge in vision-centric autonomous driving. Existing unsupervised approaches typically train a neural radiance field and treat the network outputs as occupancy probabilities during evaluation, overlooking the inconsistency between training and evaluation protocols. Moreover, the prevalent use of 2D ground truth fails to reveal the inherent ambiguity in occluded regions caused by insufficient geometric constraints. To address these issues, this paper presents a reformulated benchmark for unsupervised monocular 3D occupancy prediction. We first interpret the variables involved in the volume rendering process and identify the most physically consistent representation of the occupancy probability. Building on these analyses, we improve existing evaluation protocols by aligning the newly identified representation with voxel-wise 3D occupancy ground truth, thereby enabling unsupervised methods to be evaluated in a manner consistent with that of supervised approaches. Additionally, to impose explicit constraints in occluded regions, we introduce an occlusion-aware polarization mechanism that incorporates multi-view visual cues to enhance discrimination between occupied and free spaces in these regions. Extensive experiments demonstrate that our approach not only significantly outperforms existing unsupervised approaches but also matches the performance of supervised ones. Our source code and evaluation protocol will be made available upon publication.

</details>


### [80] [Rethinking Multi-Condition DiTs: Eliminating Redundant Attention via Position-Alignment and Keyword-Scoping](https://arxiv.org/abs/2602.06850)
*Chao Zhou,Tianyi Wei,Yiling Chen,Wenbo Zhou,Nenghai Yu*

Main category: cs.CV

TL;DR: 本文提出了一种名为 PKA（Position-aligned and Keyword-scoped Attention）的高效框架，用于解决现有文本到图像模型在多条件控制方面的计算瓶颈，通过空间对齐和语义过滤来减少冗余，并引入 CSAS 策略加速训练，实现了显著的速度提升和显存节省。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在精细控制方面存在不足，尤其是当需要同时考虑空间布局和主体外观等多个条件时，传统的“拼接-注意力”机制会导致计算和显存开销随条件数量呈二次方增长。因此，需要一种更高效的多条件控制方法。

Method: PKA 框架包含两个核心组件：1. Position-Aligned Attention (PAA) 通过局部块对齐来线性化空间控制；2. Keyword-Scoped Attention (KSA) 通过语义感知掩码来过滤不相关的对象交互。此外，还引入了 Conditional Sensitivity-Aware Sampling (CSAS) 策略，通过重新加权训练目标来加速收敛并提高条件保真度。

Result: PKA 框架实现了 10.0 倍的推理速度提升和 5.1 倍的 VRAM 节省，同时在高保真度的多条件生成方面表现出色。

Conclusion: PKA 提供了一种可扩展且资源友好的解决方案，能够高效地实现高保真度的多条件文本到图像生成，克服了现有方法的计算瓶颈。

Abstract: While modern text-to-image models excel at prompt-based generation, they often lack the fine-grained control necessary for specific user requirements like spatial layouts or subject appearances. Multi-condition control addresses this, yet its integration into Diffusion Transformers (DiTs) is bottlenecked by the conventional ``concatenate-and-attend'' strategy, which suffers from quadratic computational and memory overhead as the number of conditions scales. Our analysis reveals that much of this cross-modal interaction is spatially or semantically redundant. To this end, we propose Position-aligned and Keyword-scoped Attention (PKA), a highly efficient framework designed to eliminate these redundancies. Specifically, Position-Aligned Attention (PAA) linearizes spatial control by enforcing localized patch alignment, while Keyword-Scoped Attention (KSA) prunes irrelevant subject-driven interactions via semantic-aware masking. To facilitate efficient learning, we further introduce a Conditional Sensitivity-Aware Sampling (CSAS) strategy that reweights the training objective towards critical denoising phases, drastically accelerating convergence and enhancing conditional fidelity. Empirically, PKA delivers a 10.0$\times$ inference speedup and a 5.1$\times$ VRAM saving, providing a scalable and resource-friendly solution for high-fidelity multi-conditioned generation.

</details>


### [81] [DreamHome-Pano: Design-Aware and Conflict-Free Panoramic Interior Generation](https://arxiv.org/abs/2602.06494)
*Lulu Chen,Yijiang Hu,Yuanqing Liu,Yulong Li,Yue Yang*

Main category: cs.CV

TL;DR: DreamHome-Pano 是一个可控的全景室内生成框架，通过 Prompt-LLM 和 Conflict-Free Control 架构解决了现有方法在满足结构约束和风格偏好时的“条件冲突”问题，从而生成高质量且结构一致的室内设计。


<details>
  <summary>Details</summary>
Motivation: 现有的多条件生成框架在平衡刚性的建筑结构约束和特定的风格偏好时存在“条件冲突”问题，导致风格属性损害几何布局的精确性。本研究旨在解决这一挑战，实现高保真室内合成。

Method: 提出了一种名为 Prompt-LLM 的语义桥梁，用于将布局约束和风格参考转化为专业描述性提示，实现精确的跨模态对齐。开发了 Conflict-Free Control 架构，结合了结构感知的几何先验和多条件解耦策略，以抑制风格干扰。建立了全面的全景室内基准和多阶段训练流程，包括 SFT 和 RL。

Result: 实验结果表明，DreamHome-Pano 在美学质量和结构一致性之间取得了更好的平衡，在全景室内可视化方面提供了稳健且专业的解决方案。

Conclusion: DreamHome-Pano 成功地解决了多条件生成中的“条件冲突”问题，通过其创新的 Prompt-LLM 和 Conflict-Free Control 架构，实现了高质量、结构精确的全景室内设计生成。

Abstract: In modern interior design, the generation of personalized spaces frequently necessitates a delicate balance between rigid architectural structural constraints and specific stylistic preferences. However, existing multi-condition generative frameworks often struggle to harmonize these inputs, leading to "condition conflicts" where stylistic attributes inadvertently compromise the geometric precision of the layout. To address this challenge, we present DreamHome-Pano, a controllable panoramic generation framework designed for high-fidelity interior synthesis. Our approach introduces a Prompt-LLM that serves as a semantic bridge, effectively translating layout constraints and style references into professional descriptive prompts to achieve precise cross-modal alignment. To safeguard architectural integrity during the generative process, we develop a Conflict-Free Control architecture that incorporates structural-aware geometric priors and a multi-condition decoupling strategy, effectively suppressing stylistic interference from eroding the spatial layout. Furthermore, we establish a comprehensive panoramic interior benchmark alongside a multi-stage training pipeline, encompassing progressive Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). Experimental results demonstrate that DreamHome-Pano achieves a superior balance between aesthetic quality and structural consistency, offering a robust and professional-grade solution for panoramic interior visualization.

</details>


### [82] [NanoFLUX: Distillation-Driven Compression of Large Text-to-Image Generation Models for Mobile Devices](https://arxiv.org/abs/2602.06879)
*Ruchika Chavhan,Malcolm Chadwick,Alberto Gil Couto Pimentel Ramos,Luca Morreale,Mehdi Noroozi,Abhinav Mehrotra*

Main category: cs.CV

TL;DR: NanoFLUX是一个2.4B的文本到图像流匹配模型，通过蒸馏自17B FLUX.1-Schnell，实现了在移动设备上高质量且快速的图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模文本到图像扩散模型在生成质量上不断提高，但其规模的增长使得在设备端运行的模型与最先进模型之间差距扩大。本研究旨在缩小这一差距，实现高质量的设备端文本到图像生成。

Method: 研究者提出了NanoFLUX，一个2.4B参数的模型。该模型通过一个渐进式压缩流程，从17B FLUX.1-Schnell蒸馏而来，以保持生成质量。具体方法包括：1. 通过剪枝扩散 Transformer 中的冗余组件进行模型压缩；2. 引入基于 ResNet 的 Token 下采样机制，允许中间层在低分辨率 Token 上操作以降低延迟；3. 提出一种新颖的文本编码器蒸馏方法，在采样时利用降噪器早期层的视觉信号。

Result: NanoFLUX 可以在移动设备上大约 2.5 秒内生成 512x512 分辨率的图像，证明了高质量设备端文本到图像生成的可行性。

Conclusion: NanoFLUX 通过创新的模型压缩、Token 下采样和文本编码器蒸馏技术，成功地将大型文本到图像模型的能力缩小到适合设备端运行的规模，并保持了高质量的生成能力和高效的推理速度。

Abstract: While large-scale text-to-image diffusion models continue to improve in visual quality, their increasing scale has widened the gap between state-of-the-art models and on-device solutions. To address this gap, we introduce NanoFLUX, a 2.4B text-to-image flow-matching model distilled from 17B FLUX.1-Schnell using a progressive compression pipeline designed to preserve generation quality. Our contributions include: (1) A model compression strategy driven by pruning redundant components in the diffusion transformer, reducing its size from 12B to 2B; (2) A ResNet-based token downsampling mechanism that reduces latency by allowing intermediate blocks to operate on lower-resolution tokens while preserving high-resolution processing elsewhere; (3) A novel text encoder distillation approach that leverages visual signals from early layers of the denoiser during sampling. Empirically, NanoFLUX generates 512 x 512 images in approximately 2.5 seconds on mobile devices, demonstrating the feasibility of high-quality on-device text-to-image generation.

</details>


### [83] [Forest canopy height estimation from satellite RGB imagery using large-scale airborne LiDAR-derived training data and monocular depth estimation](https://arxiv.org/abs/2602.06503)
*Yongkang Lai,Xihan Mu,Tim R. McVicar,Dasheng Fan,Donghui Xie,Shanxin Guo,Wenli Huang,Tianjie Zhao,Guangjian Yan*

Main category: cs.CV

TL;DR: 研究利用单目深度估计模型Depth Anything V2，结合大量的航空LiDAR数据和卫星RGB影像，训练了一个名为Depth2CHM的模型，用于从PlanetScope RGB影像中生成高分辨率、连续的森林冠层高度模型（CHM）。


<details>
  <summary>Details</summary>
Motivation: 现有的大尺度、高分辨率森林冠层高度制图对于理解区域和全球碳水循环至关重要，但空间上稀疏的ICESat-2和GEDI等星载LiDAR数据存在不确定性。近地表LiDAR（航空和UAV）测量精度高，但数据量有限。本研究旨在利用易获取的RGB影像生成高分辨率、连续的CHM。

Method: 使用公开的航空LiDAR点云数据（约16,000平方公里）以及PlanetScope和航空RGB影像，训练了state-of-the-art单目深度估计模型Depth Anything V2，生成了名为Depth2CHM的模型。该模型可以直接从PlanetScope RGB影像估计CHM。

Result: 在中国的验证点（约1平方公里）和美国的验证点（约116平方公里）上，Depth2CHM模型分别取得了0.59米和0.41米的偏差，以及2.54米和5.75米的均方根误差（RMSE）。与现有的全球米级分辨率CHM产品相比，平均绝对误差减少了约1.5米，RMSE减少了约2米。

Conclusion: 利用大规模航空LiDAR衍生的冠层高度数据训练的单目深度估计网络，为从卫星RGB影像实现高分辨率、空间连续的森林冠层高度估算提供了一条有前景且可扩展的途径。

Abstract: Large-scale, high-resolution forest canopy height mapping plays a crucial role in understanding regional and global carbon and water cycles. Spaceborne LiDAR missions, including the Ice, Cloud, and Land Elevation Satellite-2 (ICESat-2) and the Global Ecosystem Dynamics Investigation (GEDI), provide global observations of forest structure but are spatially sparse and subject to inherent uncertainties. In contrast, near-surface LiDAR platforms, such as airborne and unmanned aerial vehicle (UAV) LiDAR systems, offer much finer measurements of forest canopy structure, and a growing number of countries have made these datasets openly available. In this study, a state-of-the-art monocular depth estimation model, Depth Anything V2, was trained using approximately 16,000 km2 of canopy height models (CHMs) derived from publicly available airborne LiDAR point clouds and related products across multiple countries, together with 3 m resolution PlanetScope and airborne RGB imagery. The trained model, referred to as Depth2CHM, enables the estimation of spatially continuous CHMs directly from PlanetScope RGB imagery. Independent validation was conducted at sites in China (approximately 1 km2) and the United States (approximately 116 km2). The results showed that Depth2CHM could accurately estimate canopy height, with biases of 0.59 m and 0.41 m and root mean square errors (RMSEs) of 2.54 m and 5.75 m for these two sites, respectively. Compared with an existing global meter-resolution CHM product, the mean absolute error is reduced by approximately 1.5 m and the RMSE by approximately 2 m. These results demonstrated that monocular depth estimation networks trained with large-scale airborne LiDAR-derived canopy height data provide a promising and scalable pathway for high-resolution, spatially continuous forest canopy height estimation from satellite RGB imagery.

</details>


### [84] [PANC: Prior-Aware Normalized Cut for Object Segmentation](https://arxiv.org/abs/2602.06912)
*Juan Gutiérrez,Victor Gutiérrez-Garcia,José Luis Blanco-Murillo*

Main category: cs.CV

TL;DR: 提出了一种名为 PANC 的弱监督谱分割框架，通过少量标注的视觉标记来稳定、可控地生成目标掩码，并在多个数据集上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有完全无监督的分割方法生成的分割结果不稳定且对初始化敏感，作者希望开发一种能够提供稳定、可控且可复现分割结果的方法。

Method: 在 TokenCut 方法的基础上，通过引入少量标注的先验信息来增强 token-token 亲和力图，并利用这些先验信息来引导谱特征空间，从而生成与标注一致的分割结果。该方法是无训练的。

Result: 使用 5 到 30 个标注，PANC 在 DUTS-TE、ECSSD、MS COCO 等标准数据集上达到了先进的性能。在 CrackForest (CFD)、CUB-200-2011 和 HAM10000 数据集上，平均交并比 (mIoU) 分别为 96.8%、78.0% 和 78.8%。该框架还能实现用户可控的语义分割。

Conclusion: PANC 是一种有效的弱监督谱分割框架，通过少量标注可以显著提高分割的稳定性、可控性和质量，尤其适用于标注成本高或类内差异细微的领域。

Abstract: Fully unsupervised segmentation pipelines naively seek the most salient object, should this be present. As a result, most of the methods reported in the literature deliver non-deterministic partitions that are sensitive to initialization, seed order, and threshold heuristics.
  We propose PANC, a weakly supervised spectral segmentation framework that uses a minimal set of annotated visual tokens to produce stable, controllable, and reproducible object masks. From the TokenCut approach, we augment the token-token affinity graph with a handful of priors coupled to anchor nodes. By manipulating the graph topology, we bias the spectral eigenspace toward partitions that are consistent with the annotations. Our approach preserves the global grouping enforced by dense self-supervised visual features, trading annotated tokens for significant gains in reproducibility, user control, and segmentation quality.
  Using 5 to 30 annotations per dataset, our training-free method achieves state-of-the-art performance among weakly and unsupervised approaches on standard benchmarks (e.g., DUTS-TE, ECSSD, MS COCO). Contrarily, it excels in domains where dense labels are costly or intra-class differences are subtle. We report strong and reliable results on homogeneous, fine-grained, and texture-limited domains, achieving 96.8% (+14.43% over SotA), 78.0% (+0.2%), and 78.8% (+0.37%) average mean intersection-over-union (mIoU) on CrackForest (CFD), CUB-200-2011, and HAM10000 datasets, respectively. For multi-object benchmarks, the framework showcases explicit, user-controllable semantic segmentation.

</details>


### [85] [FloorplanVLM: A Vision-Language Model for Floorplan Vectorization](https://arxiv.org/abs/2602.06507)
*Yuanqing Liu,Ziming Yang,Yulong Li,Yue Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为 FloorplanVLM 的框架，将平面图矢量化任务视为图像条件序列建模问题，能够直接生成包含全局拓扑结构的 JSON 序列，解决了传统方法在处理复杂几何形状和约束方面的挑战。该方法通过构建大规模数据集、采用渐进式训练策略以及引入新的评估基准 FPBench-2K，在复杂平面图的结构有效性和几何精度方面取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的将栅格平面图转换为工程级矢量图形的方法存在挑战，例如复杂的拓扑结构和严格的几何约束。像素级方法依赖脆弱的启发式规则，而基于查询的 Transformer 模型生成的房间可能不完整。

Method: FloorplanVLM 将平面图矢量化重构为图像条件序列建模任务，直接输出表示全局拓扑的结构化 JSON 序列。该方法使用一个可扩展的数据引擎，构建了大规模数据集 (Floorplan-2M) 和高保真子集 (Floorplan-HQ-300K)。训练策略包括使用监督微调 (SFT) 进行结构接地和质量退火，然后使用组相对策略优化 (GRPO) 进行严格的几何对齐。还建立了评估基准 FPBench-2K。

Result: 在 FPBench-2K 基准上，FloorplanVLM 实现了 92.52% 的外墙 IoU，并在非曼哈顿架构上展现出稳健的泛化能力，证明了其在结构有效性和几何精度方面的优越性。

Conclusion: FloorplanVLM 提供了一种新的、统一的框架，能够精确且全面地满足复杂几何形状（如斜墙和弧线）的约束，并生成结构有效的矢量平面图。该方法通过大规模数据集、创新的训练策略和严格的评估标准，在平面图矢量化领域取得了显著进展。

Abstract: Converting raster floorplans into engineering-grade vector graphics is challenging due to complex topology and strict geometric constraints. To address this, we present FloorplanVLM, a unified framework that reformulates floorplan vectorization as an image-conditioned sequence modeling task. Unlike pixel-based methods that rely on fragile heuristics or query-based transformers that generate fragmented rooms, our model directly outputs structured JSON sequences representing the global topology. This 'pixels-to-sequence' paradigm enables the precise and holistic constraint satisfaction of complex geometries, such as slanted walls and curved arcs. To support this data-hungry approach, we introduce a scalable data engine: we construct a large-scale dataset (Floorplan-2M) and a high-fidelity subset (Floorplan-HQ-300K) to balance geometric diversity and pixel-level precision. We then employ a progressive training strategy, using Supervised Fine-Tuning (SFT) for structural grounding and quality annealing, followed by Group Relative Policy Optimization (GRPO) for strict geometric alignment. To standardize evaluation on complex layouts, we establish and open-source FPBench-2K. Evaluated on this rigorous benchmark, FloorplanVLM demonstrates exceptional structural validity, achieving $\textbf{92.52%}$ external-wall IoU and robust generalization across non-Manhattan architectures.

</details>


### [86] [MicroBi-ConvLSTM: An Ultra-Lightweight Efficient Model for Human Activity Recognition on Resource Constrained Devices](https://arxiv.org/abs/2602.06523)
*Mridankan Mandal*

Main category: cs.CV

TL;DR: 提出了一种名为 MicroBi-ConvLSTM 的超轻量级卷积-循环神经网络架构，用于资源受限的可穿戴设备上的人类活动识别，参数量仅为 11.4K，显著优于现有模型，并在多个基准测试中取得了具有竞争力的性能，INT8 量化后部署占用空间仅为 23.0 KB。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级 HAR 模型（如 TinierHAR 和 TinyHAR）在考虑操作系统开销后，其内存占用仍超出微控制器（SRAM 有限）的预算。

Method: 提出了一种名为 MicroBi-ConvLSTM 的超轻量级卷积-循环架构，采用两阶段卷积特征提取、4倍时间池化和单个双向 LSTM 层。

Result: MicroBi-ConvLSTM 平均参数量为 11.4K，相较于 TinierHAR 减少 2.9 倍，相较于 DeepConvLSTM 减少 11.9 倍，并保持了线性 O(N) 复杂度。在八个 HAR 基准测试中，Macro F1 分数分别为 93.41% (UCI-HAR)、94.46% (SKODA assembly gestures) 和 88.98% (Daphnet gait freeze detection)。INT8 量化后平均 F1 分数下降仅 0.21%，部署占用空间为 23.0 KB。

Conclusion: MicroBi-ConvLSTM 是一种适用于内存受限边缘设备的超轻量级 HAR 模型，可在保证模型精度的同时，大幅降低参数量和内存占用，INT8 量化进一步提高了其部署可行性。

Abstract: Human Activity Recognition (HAR) on resource constrained wearables requires models that balance accuracy against strict memory and computational budgets. State of the art lightweight architectures such as TinierHAR (34K parameters) and TinyHAR (55K parameters) achieve strong accuracy, but exceed memory budgets of microcontrollers with limited SRAM once operating system overhead is considered. We present MicroBi-ConvLSTM, an ultra-lightweight convolutional-recurrent architecture achieving 11.4K parameters on average through two stage convolutional feature extraction with 4x temporal pooling and a single bidirectional LSTM layer. This represents 2.9x parameter reduction versus TinierHAR and 11.9x versus DeepConvLSTM while preserving linear O(N) complexity. Evaluation across eight diverse HAR benchmarks shows that MicroBi-ConvLSTM maintains competitive performance within the ultra-lightweight regime: 93.41% macro F1 on UCI-HAR, 94.46% on SKODA assembly gestures, and 88.98% on Daphnet gait freeze detection. Systematic ablation reveals task dependent component contributions where bidirectionality benefits episodic event detection, but provides marginal gains on periodic locomotion. INT8 post training quantization incurs only 0.21% average F1-score degradation, yielding a 23.0 KB average deployment footprint suitable for memory constrained edge devices.

</details>


### [87] [AdaptOVCD: Training-Free Open-Vocabulary Remote Sensing Change Detection via Adaptive Information Fusion](https://arxiv.org/abs/2602.06529)
*Mingyu Dou,Shi Qiu,Ming Hu,Yifan Chen,Huping Ye,Xiaohan Liao,Zhe Sun*

Main category: cs.CV

TL;DR: 本文提出了一种名为AdaptOVCD的无需训练的开放词汇变化检测（OVCD）框架，通过多层次（数据、特征、决策）和多维度（自适应设计）的信息融合，解决了现有方法依赖预定义类别和大量像素级标注的局限性，实现了对任意类别变化的零样本检测，并在跨数据集评估中取得了优异的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有遥感变化检测方法通常需要预定义的类别和大规模像素级标注，这限制了其在开放世界场景下的泛化能力和适用性。

Method: 提出AdaptOVCD框架，采用双维度多层级信息融合策略，包括：1. 数据层面：自适应辐射度对齐（ARA）融合辐射统计、原始纹理和SAM-HQ，实现辐射度一致的分割；2. 特征层面：自适应变化阈值（ACT）结合全局差异分布、边缘结构先验和DINOv3，实现鲁棒变化检测；3. 决策层面：自适应置信度过滤（ACF）集成语义置信度和空间约束，并结合DGTRS-CLIP实现高置信度语义识别。

Result: AdaptOVCD在九个场景下进行了全面评估，实现了对任意类别变化的零样本检测，显著优于现有无需训练的方法。在跨数据集评估中，其性能达到了全监督性能上限的84.89%，并展现出优越的泛化能力。

Conclusion: AdaptOVCD是一种有效的无需训练的开放词汇变化检测方法，通过创新的多层次、多维度信息融合机制，克服了现有方法的局限性，并在开放世界场景下实现了高性能和良好的泛化能力。

Abstract: Remote sensing change detection plays a pivotal role in domains such as environmental monitoring, urban planning, and disaster assessment. However, existing methods typically rely on predefined categories and large-scale pixel-level annotations, which limit their generalization and applicability in open-world scenarios. To address these limitations, this paper proposes AdaptOVCD, a training-free Open-Vocabulary Change Detection (OVCD) architecture based on dual-dimensional multi-level information fusion. The framework integrates multi-level information fusion across data, feature, and decision levels vertically while incorporating targeted adaptive designs horizontally, achieving deep synergy among heterogeneous pre-trained models to effectively mitigate error propagation. Specifically, (1) at the data level, Adaptive Radiometric Alignment (ARA) fuses radiometric statistics with original texture features and synergizes with SAM-HQ to achieve radiometrically consistent segmentation; (2) at the feature level, Adaptive Change Thresholding (ACT) combines global difference distributions with edge structure priors and leverages DINOv3 to achieve robust change detection; (3) at the decision level, Adaptive Confidence Filtering (ACF) integrates semantic confidence with spatial constraints and collaborates with DGTRS-CLIP to achieve high-confidence semantic identification. Comprehensive evaluations across nine scenarios demonstrate that AdaptOVCD detects arbitrary category changes in a zero-shot manner, significantly outperforming existing training-free methods. Meanwhile, it achieves 84.89\% of the fully-supervised performance upper bound in cross-dataset evaluations and exhibits superior generalization capabilities. The code is available at https://github.com/Dmygithub/AdaptOVCD.

</details>


### [88] [Universal Anti-forensics Attack against Image Forgery Detection via Multi-modal Guidance](https://arxiv.org/abs/2602.06530)
*Haipeng Li,Rongxuan Peng,Anwei Luo,Shunquan Tan,Changsheng Chen,Anastasia Antsiferova*

Main category: cs.CV

TL;DR: 本文提出了一个名为 ForgeryEraser 的框架，用于对 AIGC 检测器进行通用反取证攻击。该框架利用了 Vision-Language Models (VLMs) 的共享骨干网络（如 CLIP）的漏洞，通过多模态引导损失，将伪造图像的嵌入推向文本导向的真实锚点，从而绕过 AIGC 检测器。


<details>
  <summary>Details</summary>
Motivation: 现有的 AIGC 检测器评估协议忽视了反取证攻击，这可能影响其在现实世界应用中的鲁棒性。因此，需要一种能够对 AIGC 检测器进行有效反取证攻击的方法。

Method: ForgeryEraser 框架通过利用 VLM 共享骨干网络的特征空间，设计了一种多模态引导损失。该损失旨在将伪造图像的嵌入（features）引导至由文本生成的真实图像锚点，同时远离伪造图像锚点，从而抹去伪造痕迹。攻击不需要访问目标 AIGC 检测器。

Result: ForgeryEraser 在全球合成和局部编辑基准测试中，显著降低了先进 AIGC 检测器的性能。此外，该攻击还能诱导可解释的取证模型生成与真实图像一致的解释，即使是针对伪造图像。

Conclusion: ForgeryEraser 框架能够有效地对 AIGC 检测器进行通用反取证攻击，揭示了当前 AIGC 检测器在利用 VLM 共享骨干网络方面存在的系统性漏洞。该方法展示了其在降低 AIGC 检测器性能和影响可解释性方面的有效性。

Abstract: The rapid advancement of AI-Generated Content (AIGC) technologies poses significant challenges for authenticity assessment. However, existing evaluation protocols largely overlook anti-forensics attack, failing to ensure the comprehensive robustness of state-of-the-art AIGC detectors in real-world applications. To bridge this gap, we propose ForgeryEraser, a framework designed to execute universal anti-forensics attack without access to the target AIGC detectors. We reveal an adversarial vulnerability stemming from the systemic reliance on Vision-Language Models (VLMs) as shared backbones (e.g., CLIP), where downstream AIGC detectors inherit the feature space of these publicly accessible models. Instead of traditional logit-based optimization, we design a multi-modal guidance loss to drive forged image embeddings within the VLM feature space toward text-derived authentic anchors to erase forgery traces, while repelling them from forgery anchors. Extensive experiments demonstrate that ForgeryEraser causes substantial performance degradation to advanced AIGC detectors on both global synthesis and local editing benchmarks. Moreover, ForgeryEraser induces explainable forensic models to generate explanations consistent with authentic images for forged images. Our code will be made publicly available.

</details>


### [89] [An Integer Linear Programming Approach to Geometrically Consistent Partial-Partial Shape Matching](https://arxiv.org/abs/2602.06590)
*Viktoria Ehm,Paul Roetzer,Florian Bernard,Daniel Cremers*

Main category: cs.CV

TL;DR: 本文提出了首个针对三维形状的部分-部分匹配问题的整数线性规划方法，该方法利用几何一致性来估计重叠区域并计算保持邻域关系的对应关系，并在匹配误差和光滑度方面取得了高质量的结果，且比现有方法更具可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有研究较少关注三维形状的部分-部分匹配问题，因为其独特的挑战在于需要同时确定未知的重叠区域和计算对应关系。然而，该场景在现实世界（如3D扫描）中更为常见。

Method: 提出了一种基于整数线性规划（ILP）的方法，该方法利用几何一致性作为先验知识，以解决部分-部分三维形状匹配的挑战。该方法能够估计重叠区域并计算保持邻域关系的对应关系。

Result: 在匹配误差和光滑度方面均取得了高质量的匹配结果。与现有方法相比，该方法更具可扩展性。

Conclusion: 所提出的整数线性规划方法是首个专门针对部分-部分三维形状匹配问题的解决方案，能够有效且高效地解决该问题，并在准确性和可扩展性方面表现出色。

Abstract: The task of establishing correspondences between two 3D shapes is a long-standing challenge in computer vision. While numerous studies address full-full and partial-full 3D shape matching, only a limited number of works have explored the partial-partial setting, very likely due to its unique challenges: we must compute accurate correspondences while at the same time find the unknown overlapping region. Nevertheless, partial-partial 3D shape matching reflects the most realistic setting, as in many real-world cases, such as 3D scanning, shapes are only partially observable. In this work, we introduce the first integer linear programming approach specifically designed to address the distinctive challenges of partial-partial shape matching. Our method leverages geometric consistency as a strong prior, enabling both robust estimation of the overlapping region and computation of neighbourhood-preserving correspondences. We empirically demonstrate that our approach achieves high-quality matching results both in terms of matching error and smoothness. Moreover, we show that our method is more scalable than previous formalisms.

</details>


### [90] [CauCLIP: Bridging the Sim-to-Real Gap in Surgical Video Understanding via Causality-Inspired Vision-Language Modeling](https://arxiv.org/abs/2602.06619)
*Yuxin He,An Li,Cheng Xue*

Main category: cs.CV

TL;DR: 提出了一种名为CauCLIP的因果推理视觉-语言框架，利用CLIP学习领域不变表征，用于手术阶段识别，无需目标域数据。该方法通过频率增强和因果抑制损失来提高模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 手术阶段识别对于智能手术室的上下文感知决策支持至关重要，但有限的标注视频和合成/真实手术数据间的领域差异阻碍了模型的鲁棒性训练。

Method: 提出CauCLIP框架，该框架结合了：1) 频率增强策略，扰动领域特定属性同时保留语义结构；2) 因果抑制损失，减轻非因果偏见并强化因果手术特征。模型在统一的训练框架下学习领域不变表征。

Result: 在SurgVisDom硬域适应基准测试中，CauCLIP显著优于所有竞争方法，表明因果引导的视觉-语言模型在领域泛化手术视频理解方面的有效性。

Conclusion: CauCLIP是一种有效的因果推理视觉-语言框架，能够学习领域不变表征，从而在无需目标域数据的情况下实现泛化能力强的 
手术阶段识别。

Abstract: Surgical phase recognition is a critical component for context-aware decision support in intelligent operating rooms, yet training robust models is hindered by limited annotated clinical videos and large domain gaps between synthetic and real surgical data. To address this, we propose CauCLIP, a causality-inspired vision-language framework that leverages CLIP to learn domain-invariant representations for surgical phase recognition without access to target domain data. Our approach integrates a frequency-based augmentation strategy to perturb domain-specific attributes while preserving semantic structures, and a causal suppression loss that mitigates non-causal biases and reinforces causal surgical features. These components are combined in a unified training framework that enables the model to focus on stable causal factors underlying surgical workflows. Experiments on the SurgVisDom hard adaptation benchmark demonstrate that our method substantially outperforms all competing approaches, highlighting the effectiveness of causality-guided vision-language models for domain-generalizable surgical video understanding.

</details>


### [91] [PlanViz: Evaluating Planning-Oriented Image Generation and Editing for Computer-Use Tasks](https://arxiv.org/abs/2602.06663)
*Junxian Li,Kai Liu,Leyang Chen,Weida Wang,Zhixin Wang,Jiaqi Xu,Fan Li,Renjing Pei,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: 本文提出了PlanViz基准，用于评估统一多模态模型（UMMs）在计算机使用规划任务中的图像生成和编辑能力，并引入了PlanScore评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有的统一多模态模型在图像生成和多模态推理方面表现出色，但其在与日常生活密切相关的计算机使用规划任务中的能力尚未得到充分探索。这些任务需要空间推理和程序理解能力，作者希望评估UMMs是否具备这些能力。

Method: 设计了一个名为PlanViz的新基准，包含三个子任务：路线规划、工作图表绘制和网页/UI展示。该基准通过精心标注的问题和参考图像以及质量控制流程来确保数据质量。提出了一个名为PlanScore的自适应评分指标，用于评估生成图像的正确性、视觉质量和效率。

Result: 通过在PlanViz基准上的实验，揭示了UMMs在计算机使用规划任务中的关键局限性，并指出了未来研究的机遇。

Conclusion: PlanViz基准和PlanScore评估指标为评估UMMs在计算机使用规划任务中的图像生成和编辑能力提供了一个新框架，并为该领域的研究提供了方向。

Abstract: Unified multimodal models (UMMs) have shown impressive capabilities in generating natural images and supporting multimodal reasoning. However, their potential in supporting computer-use planning tasks, which are closely related to our lives, remain underexplored. Image generation and editing in computer-use tasks require capabilities like spatial reasoning and procedural understanding, and it is still unknown whether UMMs have these capabilities to finish these tasks or not. Therefore, we propose PlanViz, a new benchmark designed to evaluate image generation and editing for computer-use tasks. To achieve the goal of our evaluation, we focus on sub-tasks which frequently involve in daily life and require planning steps. Specifically, three new sub-tasks are designed: route planning, work diagramming, and web&UI displaying. We address challenges in data quality ensuring by curating human-annotated questions and reference images, and a quality control process. For challenges of comprehensive and exact evaluation, a task-adaptive score, PlanScore, is proposed. The score helps understanding the correctness, visual quality and efficiency of generated images. Through experiments, we highlight key limitations and opportunities for future research on this topic.

</details>


### [92] [NECromancer: Breathing Life into Skeletons via BVH Animation](https://arxiv.org/abs/2602.06548)
*Mingxi Xu,Qi Wang,Zhengyu Wen,Phong Dao Thien,Zhengyu Li,Ning Zhang,Xiaoyu He,Wei Zhao,Kehong Gong,Mingyuan Zhang*

Main category: cs.CV

TL;DR: NECromancer (NEC) 提出了一种通用的运动序列分词器，可以直接处理任意 BVH 骨骼，实现了跨物种的运动表示、迁移和生成。


<details>
  <summary>Details</summary>
Motivation: 现有运动分词方法大多受限于特定物种的骨骼，限制了其在不同形态间的通用性。研究旨在开发一种能够处理任意 BVH 骨骼的通用运动分词器。

Method: NECromancer (NEC) 包含三个主要组件：1. 骨骼图编码器 (OwO)，用于编码 BVH 文件的结构信息（关节语义、骨骼偏移、拓扑结构）；2. 拓扑无关分词器 (TAT)，将运动序列压缩成一种通用的、与拓扑无关的离散表示；3. 统一 BVH 宇宙 (UvU) 数据集，包含各种骨骼的 BVH 运动数据。

Result: NEC 在显著压缩的情况下实现了高保真度的运动重建，并且能够有效地将运动与骨骼结构解耦。其生成的 token 空间支持跨物种运动迁移、组合、去噪、基于 token 的生成以及文本-运动检索。

Conclusion: NECromancer 提供了一个统一的框架，能够跨越不同形态进行运动分析和合成，展示了其在通用运动建模方面的潜力。

Abstract: Motion tokenization is a key component of generalizable motion models, yet most existing approaches are restricted to species-specific skeletons, limiting their applicability across diverse morphologies. We propose NECromancer (NEC), a universal motion tokenizer that operates directly on arbitrary BVH skeletons. NEC consists of three components: (1) an Ontology-aware Skeletal Graph Encoder (OwO) that encodes structural priors from BVH files, including joint semantics, rest-pose offsets, and skeletal topology, into skeletal embeddings; (2) a Topology-Agnostic Tokenizer (TAT) that compresses motion sequences into a universal, topology-invariant discrete representation; and (3) the Unified BVH Universe (UvU), a large-scale dataset aggregating BVH motions across heterogeneous skeletons. Experiments show that NEC achieves high-fidelity reconstruction under substantial compression and effectively disentangles motion from skeletal structure. The resulting token space supports cross-species motion transfer, composition, denoising, generation with token-based models, and text-motion retrieval, establishing a unified framework for motion analysis and synthesis across diverse morphologies. Demo page: https://animotionlab.github.io/NECromancer/

</details>


### [93] [CytoCrowd: A Multi-Annotator Benchmark Dataset for Cytology Image Analysis](https://arxiv.org/abs/2602.06674)
*Yonghao Si,Xingyuan Zeng,Zhao Chen,Libin Zheng,Caleb Chen Cao,Lei Chen,Jian Yin*

Main category: cs.CV

TL;DR: CytoCrowd 是一个包含 446 张细胞学图像的新型公开基准数据集，其特点是包含来自四位病理学家的原始、冲突的标注以及一位资深专家建立的高质量黄金标准。该数据集可用于标准计算机视觉任务和评估标注聚合算法。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像分析数据集要么提供单一的、清晰的地面真值（忽略了真实的专家分歧），要么提供多个标注但缺乏独立的黄金标准用于客观评估。研究旨在弥合这一差距，为解决专家分歧提供一个现实的测试平台。

Method: 创建了一个名为 CytoCrowd 的新公开基准数据集，包含 446 张高分辨率图像。每张图像都包含两部分：来自四位独立病理学家的原始、冲突的标注，以及一位资深专家建立的独立、高质量的黄金标准地面真值。提供了两个任务的基线结果：使用黄金标准进行的标准计算机视觉任务（目标检测和分类），以及评估标注聚合算法。

Result: CytoCrowd 数据集已成功创建并发布。实验结果表明，该数据集具有挑战性，并展示了解决专家分歧的复杂性。提供了标准计算机视觉任务和标注聚合任务的基线性能。

Conclusion: CytoCrowd 是一个多功能资源，可作为标准计算机视觉任务的基准，同时也是评估标注聚合算法以解决专家分歧的现实测试平台。该数据集的挑战性证明了其作为开发下一代医学图像分析模型的价值。

Abstract: High-quality annotated datasets are crucial for advancing machine learning in medical image analysis. However, a critical gap exists: most datasets either offer a single, clean ground truth, which hides real-world expert disagreement, or they provide multiple annotations without a separate gold standard for objective evaluation. To bridge this gap, we introduce CytoCrowd, a new public benchmark for cytology analysis. The dataset features 446 high-resolution images, each with two key components: (1) raw, conflicting annotations from four independent pathologists, and (2) a separate, high-quality gold-standard ground truth established by a senior expert. This dual structure makes CytoCrowd a versatile resource. It serves as a benchmark for standard computer vision tasks, such as object detection and classification, using the ground truth. Simultaneously, it provides a realistic testbed for evaluating annotation aggregation algorithms that must resolve expert disagreements. We provide comprehensive baseline results for both tasks. Our experiments demonstrate the challenges presented by CytoCrowd and establish its value as a resource for developing the next generation of models for medical image analysis.

</details>


### [94] [Clinical-Prior Guided Multi-Modal Learning with Latent Attention Pooling for Gait-Based Scoliosis Screening](https://arxiv.org/abs/2602.06743)
*Dong Chen,Zizhuang Wei,Jialei Xu,Xinyang Sun,Zonglin He,Meiru An,Huili Peng,Yong Hu,Kenneth MC Cheung*

Main category: cs.CV

TL;DR: 本研究提出了ScoliGait数据集和一种新的多模态方法，用于通过步态视频分析更准确、可解释地检测青少年特发性脊柱侧凸（AIS），解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的AIS筛查方法存在主观性、难以规模化和依赖专业知识的缺点。现有视频步态分析方法则面临数据泄露和模型解释性不足的问题。

Method: 构建了包含1572个训练视频剪辑和300个独立测试视频剪辑的ScoliGait数据集。提出了一种多模态框架，该框架结合了临床先验知识引导的运动学知识图谱，以及用于融合视频、文本和知识图谱的潜在注意力池化机制。

Result: 所提出的方法在一个真实的、不重复受试者的基准上取得了新的最先进性能，显示出显著的性能提升。

Conclusion: 该研究提供了一个稳健、可解释且符合临床实际的解决方案，为可扩展、非侵入性的AIS评估奠定了基础。

Abstract: Adolescent Idiopathic Scoliosis (AIS) is a prevalent spinal deformity whose progression can be mitigated through early detection. Conventional screening methods are often subjective, difficult to scale, and reliant on specialized clinical expertise. Video-based gait analysis offers a promising alternative, but current datasets and methods frequently suffer from data leakage, where performance is inflated by repeated clips from the same individual, or employ oversimplified models that lack clinical interpretability. To address these limitations, we introduce ScoliGait, a new benchmark dataset comprising 1,572 gait video clips for training and 300 fully independent clips for testing. Each clip is annotated with radiographic Cobb angles and descriptive text based on clinical kinematic priors. We propose a multi-modal framework that integrates a clinical-prior-guided kinematic knowledge map for interpretable feature representation, alongside a latent attention pooling mechanism to fuse video, text, and knowledge map modalities. Our method establishes a new state-of-the-art, demonstrating a significant performance gap on a realistic, non-repeating subject benchmark. Our approach establishes a new state of the art, showing a significant performance gain on a realistic, subject-independent benchmark. This work provides a robust, interpretable, and clinically grounded foundation for scalable, non-invasive AIS assessment.

</details>


### [95] [Can We Build a Monolithic Model for Fake Image Detection? SICA: Semantic-Induced Constrained Adaptation for Unified-Yet-Discriminative Artifact Feature Space Reconstruction](https://arxiv.org/abs/2602.06676)
*Bo Du,Xiaochen Ma,Xuekang Zhu,Zhe Yang,Chaogun Niu,Jian Liu,Ji-Zhe Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为SICA（Semantic-Induced Constrained Adaptation）的单一模型框架，用于检测来自不同伪造图像子域（如JPEG压缩、复制-移动、拼接、PRNU）的伪造痕迹。SICA通过利用图像的高层语义信息来解决现有单一模型因“异构现象”（不同子域伪造痕迹的固有差异）导致的特征空间坍塌问题，实现了“统一且可区分”的特征表示，并在实验中取得了优于15种现有先进方法的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的单一伪造图像检测（FID）模型在实践中表现不如集成方法，其根本原因在于“异构现象”导致伪造痕迹特征空间坍塌。作者旨在找出这一问题的根源，并提出一种能克服这一挑战的单一模型。

Method: 作者提出了“异构现象”的概念，并将其归因于单一FID模型性能不佳的原因。为了解决“统一且可区分”的伪造痕迹特征空间重建问题，作者提出了一种名为SICA（Semantic-Induced Constrained Adaptation）的新型单一FID框架。SICA利用图像的高层语义信息作为结构先验，来约束和重建伪造痕迹特征空间。

Result: 在OpenMMSec数据集上的广泛实验表明，SICA模型的性能优于15种最先进的方法。此外，SICA能够以近乎正交的方式重建目标“统一且可区分”的伪造痕迹特征空间，这有力地验证了其利用高层语义信息作为结构先验的假设。

Conclusion: “异构现象”是导致单一FID模型性能不佳的根本原因，它导致了伪造痕迹特征空间的坍塌。SICA框架通过利用高层语义信息作为结构先验，成功地实现了“统一且可区分”的伪造痕迹特征空间重建，是第一个实用的单一FID模型，并在实验中取得了优异的性能。

Abstract: Fake Image Detection (FID), aiming at unified detection across four image forensic subdomains, is critical in real-world forensic scenarios. Compared with ensemble approaches, monolithic FID models are theoretically more promising, but to date, consistently yield inferior performance in practice. In this work, by discovering the ``heterogeneous phenomenon'', which is the intrinsic distinctness of artifacts across subdomains, we diagnose the cause of this underperformance for the first time: the collapse of the artifact feature space driven by such phenomenon. The core challenge for developing a practical monolithic FID model thus boils down to the ``unified-yet-discriminative" reconstruction of the artifact feature space. To address this paradoxical challenge, we hypothesize that high-level semantics can serve as a structural prior for the reconstruction, and further propose Semantic-Induced Constrained Adaptation (SICA), the first monolithic FID paradigm. Extensive experiments on our OpenMMSec dataset demonstrate that SICA outperforms 15 state-of-the-art methods and reconstructs the target unified-yet-discriminative artifact feature space in a near-orthogonal manner, thus firmly validating our hypothesis. The code and dataset are available at:https: //github.com/scu-zjz/SICA_OpenMMSec.

</details>


### [96] [Revisiting Emotions Representation for Recognition in the Wild](https://arxiv.org/abs/2602.06778)
*Joao Baptista Cardia Neto,Claudio Ferrari,Stefano Berretti*

Main category: cs.CV

TL;DR: 本文提出了一种将面部表情识别视为分布学习问题的新方法，通过利用 Valence-Arousal-Dominance (VAD) 空间中的基本和复合情绪映射，自动重新标注现有数据集，从而更全面地描述复杂的情绪状态。


<details>
  <summary>Details</summary>
Motivation: 现有的面部表情识别方法将表情视为单一标签分类，这过于简化，无法表示自发情绪状态的多方面光谱。因此，需要一种更复杂的方法来捕捉情绪的组合性。

Method: 该研究提出了一种自动重新标注现有数据集的方法，该方法利用了情绪到 Valence-Arousal-Dominance (VAD) 空间的映射。通过输入带有 VAD 值的面部图像，估计其属于不同情绪分布的可能性，从而将情绪状态描述为情绪的混合体。

Result: 通过在现有数据集上进行实验，初步证明了该方法能够更丰富地描述情绪状态，并能解释情绪感知的模糊性。

Conclusion: 该研究提出了一种通过分布学习来描述复杂情绪状态的新方法，该方法通过自动重新标注数据集，克服了现有方法的局限性，并为面部表情识别开辟了新的研究方向。

Abstract: Facial emotion recognition has been typically cast as a single-label classification problem of one out of six prototypical emotions. However, that is an oversimplification that is unsuitable for representing the multifaceted spectrum of spontaneous emotional states, which are most often the result of a combination of multiple emotions contributing at different intensities. Building on this, a promising direction that was explored recently is to cast emotion recognition as a distribution learning problem. Still, such approaches are limited in that research datasets are typically annotated with a single emotion class. In this paper, we contribute a novel approach to describe complex emotional states as probability distributions over a set of emotion classes. To do so, we propose a solution to automatically re-label existing datasets by exploiting the result of a study in which a large set of both basic and compound emotions is mapped to probability distributions in the Valence-Arousal-Dominance (VAD) space. In this way, given a face image annotated with VAD values, we can estimate the likelihood of it belonging to each of the distributions, so that emotional states can be described as a mixture of emotions, enriching their description, while also accounting for the ambiguous nature of their perception. In a preliminary set of experiments, we illustrate the advantages of this solution and a new possible direction of investigation. Data annotations are available at https://github.com/jbcnrlz/affectnet-b-annotation.

</details>


### [97] [A Unified Formula for Affine Transformations between Calibrated Cameras](https://arxiv.org/abs/2602.06805)
*Levente Hajder*

Main category: cs.CV

TL;DR: 文章推导出了一个封闭形式的表达式，用于描述连接两个已校准视图中的局部图像块的仿射变换。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是找到一种直接的方法来计算或表示两个不同视角下图像中对应局部区域之间的几何关系。

Method: 通过利用相对相机姿态、图像坐标和局部表面法线，推导出了一个封闭形式的仿射变换表达式。

Result: 成功地得到了一个封闭形式的仿射变换表达式，该表达式能够将一个视图中的局部图像块映射到另一个视图中。

Conclusion: 该技术笔记提供了一种数学上精确的方法来描述两个已校准视图之间的局部图像块变换，该变换是相机姿态、图像坐标和表面法线的函数。

Abstract: In this technical note, we derive a closed-form expression for the affine transformation mapping local image patches between two calibrated views. We show that the transformation is a function of the relative camera pose, the image coordinates, and the local surface normal.

</details>


### [98] [Machine Learning for Detection and Severity Estimation of Sweetpotato Weevil Damage in Field and Lab Conditions](https://arxiv.org/abs/2602.06786)
*Doreen M. Chelangat,Sudi Murindanyi,Bruce Mugizi,Paul Musana,Benard Yada,Milton A. Otema,Florence Osaru,Andrew Katumba,Joyce Nakatumba-Nabende*

Main category: cs.CV

TL;DR: 本研究提出了一种基于计算机视觉的方法，用于自动化评估甘薯象甲（Cylas spp.）对甘薯的危害程度，解决了传统手动评估耗时、主观和不一致的问题，可应用于田间和实验室场景，提高了甘薯育种效率。


<details>
  <summary>Details</summary>
Motivation: 传统的甘薯象甲损害评估方法依赖于手动评分，存在劳动密集、主观性强和结果不一致等问题，这严重阻碍了培育抗虫甘薯新品种的育种计划。

Method: 在田间，收集数据训练分类模型以预测根部损害等级，准确率达71.43%。在实验室，构建数据集并采用YOLOv12目标检测模型，结合根部分割和瓦片策略，以提高对微小损害的检测能力，最终实现77.7%的平均精度。

Result: 计算机视觉方法在田间和实验室场景下均展现出评估甘薯象甲损害的潜力，田间分类模型准确率为71.43%，实验室目标检测模型在识别微小象甲蛀孔方面达到77.7%的平均精度。

Conclusion: 计算机视觉技术能够提供高效、客观且可扩展的评估工具，能够无缝集成到当前的育种工作流程中，显著提高甘薯育种的表型分析效率，并有助于缓解象甲对粮食安全的不利影响。

Abstract: Sweetpotato weevils (Cylas spp.) are considered among the most destructive pests impacting sweetpotato production, particularly in sub-Saharan Africa. Traditional methods for assessing weevil damage, predominantly relying on manual scoring, are labour-intensive, subjective, and often yield inconsistent results. These challenges significantly hinder breeding programs aimed at developing resilient sweetpotato varieties. This study introduces a computer vision-based approach for the automated evaluation of weevil damage in both field and laboratory contexts. In the field settings, we collected data to train classification models to predict root-damage severity levels, achieving a test accuracy of 71.43%. Additionally, we established a laboratory dataset and designed an object detection pipeline employing YOLO12, a leading real-time detection model. This methodology incorporated a two-stage laboratory pipeline that combined root segmentation with a tiling strategy to improve the detectability of small objects. The resulting model demonstrated a mean average precision of 77.7% in identifying minute weevil feeding holes. Our findings indicate that computer vision technologies can provide efficient, objective, and scalable assessment tools that align seamlessly with contemporary breeding workflows. These advancements represent a significant improvement in enhancing phenotyping efficiency within sweetpotato breeding programs and play a crucial role in mitigating the detrimental effects of weevils on food security.

</details>


### [99] [GaussianPOP: Principled Simplification Framework for Compact 3D Gaussian Splatting via Error Quantification](https://arxiv.org/abs/2602.06830)
*Soonbin Lee,Yeong-Gyu Kim,Simon Sasse,Tomas M. Borges,Yago Sanchez,Eun-Seok Ryu,Thomas Schierl,Cornelius Hellge*

Main category: cs.CV

TL;DR: 提出了一种名为GaussianPOP的3D高斯泼溅简化框架，它基于分析高斯误差量化，能够更准确地衡量每个高斯对渲染图像的贡献，从而在模型紧凑性和渲染保真度之间取得更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅简化方法依赖于非视觉误差指标，导致在紧凑性和渲染保真度之间存在次优权衡。

Method: 提出了一种基于分析高斯误差量化的简化框架，引入了一种新的误差标准，该标准直接源于3DGS渲染方程，能够精确测量每个高斯对渲染图像的贡献。该框架采用高效算法，可在单次前向传播中计算误差，并支持训练中剪枝和训练后简化。

Result: 实验结果表明，GaussianPOP在模型紧凑性和渲染质量方面始终优于现有的最先进剪枝方法。

Conclusion: GaussianPOP是一种准确且灵活的3D高斯泼溅简化框架，通过量化每个高斯对渲染误差的贡献，实现了比现有方法更好的紧凑性和渲染质量的权衡。

Abstract: Existing 3D Gaussian Splatting simplification methods commonly use importance scores, such as blending weights or sensitivity, to identify redundant Gaussians. However, these scores are not driven by visual error metrics, often leading to suboptimal trade-offs between compactness and rendering fidelity. We present GaussianPOP, a principled simplification framework based on analytical Gaussian error quantification. Our key contribution is a novel error criterion, derived directly from the 3DGS rendering equation, that precisely measures each Gaussian's contribution to the rendered image. By introducing a highly efficient algorithm, our framework enables practical error calculation in a single forward pass. The framework is both accurate and flexible, supporting on-training pruning as well as post-training simplification via iterative error re-quantification for improved stability. Experimental results show that our method consistently outperforms existing state-of-the-art pruning methods across both application scenarios, achieving a superior trade-off between model compactness and high rendering quality.

</details>


### [100] [RAIGen: Rare Attribute Identification in Text-to-Image Generative Models](https://arxiv.org/abs/2602.06806)
*Silpa Vadakkeeveetil Sreelatha,Dan Wang,Serge Belongie,Muhammad Awais,Anjan Dutta*

Main category: cs.CV

TL;DR: 本文提出了一种名为 RAIGen 的无监督框架，用于在文本到图像扩散模型中发现稀有属性，它结合了神经元激活频率和语义独特性来识别代表稀有属性的神经元。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么关注预定义的公平类别，要么只识别主导属性，忽略了挖掘模型中编码的、但在数据分布中代表性不足的稀有（社会、文化或风格）属性。

Method: RAIGen 使用 Matryoshka 稀疏自编码器，并引入了一个新的少数派指标，该指标结合了神经元激活频率和语义独特性，以识别揭示数据不足的属性的可解释神经元。

Result: RAIGen 能够发现 Stable Diffusion 中超越固定公平类别的稀有属性，并能扩展到 SDXL 等更大模型。此外，它还能实现跨架构的系统审计，并支持在生成过程中定向放大稀有属性。

Conclusion: RAIGen 是一个创新的框架，能够无监督地发现文本到图像扩散模型中以前未被识别的稀有属性，为模型的公平性和覆盖范围审计提供了新的途径。

Abstract: Text-to-image diffusion models achieve impressive generation quality but inherit and amplify training-data biases, skewing coverage of semantic attributes. Prior work addresses this in two ways. Closed-set approaches mitigate biases in predefined fairness categories (e.g., gender, race), assuming socially salient minority attributes are known a priori. Open-set approaches frame the task as bias identification, highlighting majority attributes that dominate outputs. Both overlook a complementary task: uncovering rare or minority features underrepresented in the data distribution (social, cultural, or stylistic) yet still encoded in model representations. We introduce RAIGen, the first framework, to our knowledge, for un-supervised rare-attribute discovery in diffusion models. RAIGen leverages Matryoshka Sparse Autoencoders and a novel minority metric combining neuron activation frequency with semantic distinctiveness to identify interpretable neurons whose top-activating images reveal underrepresented attributes. Experiments show RAIGen discovers attributes beyond fixed fairness categories in Stable Diffusion, scales to larger models such as SDXL, supports systematic auditing across architectures, and enables targeted amplification of rare attributes during generation.

</details>


### [101] [Parameters as Experts: Adapting Vision Models with Dynamic Parameter Routing](https://arxiv.org/abs/2602.06862)
*Meng Lou,Stanley Yu,Yizhou Yu*

Main category: cs.CV

TL;DR: 提出了一种名为AdaRoute的新型参数高效微调（PEFT）方法，用于适应预训练的视觉模型，尤其是在密集预测任务上。AdaRoute使用一个简单的混合专家（MoE）架构，通过动态参数路由机制为每个模块生成定制化的低秩适应权重矩阵，并在多个网络层之间共享专家中心以促进跨层特征交互，从而在各种视觉任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调（PEFT）方法在应用于复杂的密集预测任务时存在局限性，例如输入无关建模和冗余的跨层表示。研究人员希望开发一种能够实现与全量微调相媲美性能，但参数量极少的新方法。

Method: 提出AdaRoute，一种新的适配器（adapter-style）方法，采用简单的混合专家（MoE）架构。AdaRoute模块在前向传播时，通过动态参数路由机制，选择性地聚合专家中心的参数矩阵，生成定制化的、输入相关的低秩适应权重矩阵。不同层的AdaRoute模块共享相同的专家中心，以促进跨层特征交互。

Result: AdaRoute在语义分割、目标检测、实例分割和全景分割等多种视觉任务上进行了广泛的实验，结果表明其性能优于现有的方法。

Conclusion: AdaRoute是一种有效的参数高效微调方法，能够生成更具定制化和更强大的特征表示，并在各种密集预测任务上取得了显著的性能提升。通过动态权重生成和跨层特征交互，AdaRoute克服了现有方法的不足。

Abstract: Adapting pre-trained vision models using parameter-efficient fine-tuning (PEFT) remains challenging, as it aims to achieve performance comparable to full fine-tuning using a minimal number of trainable parameters. When applied to complex dense prediction tasks, existing methods exhibit limitations, including input-agnostic modeling and redundant cross-layer representations. To this end, we propose AdaRoute, a new adapter-style method featuring a simple mixture-of-experts (MoE) architecture. Specifically, we introduce shared expert centers, where each expert is a trainable parameter matrix. During a feedforward pass, each AdaRoute module in the network dynamically generates weight matrices tailored for the current module via a simple dynamic parameter routing mechanism, which selectively aggregates parameter matrices in the corresponding expert center. Dynamic weight matrices in AdaRoute modules facilitate low-rank adaptation in an input-dependent manner, thus generating more customized and powerful feature representations. Moreover, since AdaRoute modules across multiple network layers share the same expert center, they improve feature diversity by promoting implicit cross-layer feature interaction. Extensive experiments demonstrate the superiority of AdaRoute on diverse vision tasks, including semantic segmentation, object detection and instance segmentation, and panoptic segmentation. Code will be available at: https://bit.ly/3NZcr0H.

</details>


### [102] [RFDM: Residual Flow Diffusion Model for Efficient Causal Video Editing](https://arxiv.org/abs/2602.06871)
*Mohammadreza Salehi,Mehdi Noroozi,Luca Morreale,Ruchika Chavhan,Malcolm Chadwick,Alberto Gil Ramos,Abhinav Mehrotra*

Main category: cs.CV

TL;DR: 本文提出了一种名为残差流扩散模型（RFDM）的因果、高效的视频编辑模型，该模型能够以文本提示编辑可变长度的视频。RFDM通过将2D图像到图像（I2I）扩散模型改编为视频到视频（V2V）编辑，并利用时间冗余来聚焦于帧间变化，从而实现了高效编辑，计算成本与图像模型相当，且不随视频长度增加。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法通常需要固定长度的输入和大量的计算资源，而自回归视频生成虽然能高效合成可变长度视频，但其在视频编辑方面的应用研究不足。研究者希望开发一种能够高效编辑可变长度视频，同时保持较低计算成本的方法。

Method: 该研究将2D图像到图像（I2I）扩散模型改编为视频到视频（V2V）编辑，通过在时间步t时将编辑条件设置为模型在t-1时的预测来实现。为了利用视频的时间冗余，提出了一个残差流扩散模型（RFDM）的I2I扩散前向过程，鼓励模型预测目标输出与前一预测之间的残差，从而将去噪过程聚焦于连续帧之间的变化。

Result: 在配对视频数据上进行训练后，RFDM在全局/局部风格迁移和物体移除等任务上，优于基于I2I的方法，并能与全时空（3D）V2V模型相媲美。同时，其计算成本与图像模型相当，并且可以独立于输入视频的长度进行扩展。研究者还提出了一个新的基准，能更好地对视频编辑任务的最新方法进行排名。

Conclusion: RFDM是一种高效的因果视频编辑模型，能够通过文本提示编辑可变长度的视频。该模型通过残差学习和利用视频时间冗余，在保证计算效率的同时，实现了与先进视频编辑方法相竞争的性能，并为视频编辑任务提供了一个新的评估标准。

Abstract: Instructional video editing applies edits to an input video using only text prompts, enabling intuitive natural-language control. Despite rapid progress, most methods still require fixed-length inputs and substantial compute. Meanwhile, autoregressive video generation enables efficient variable-length synthesis, yet remains under-explored for video editing. We introduce a causal, efficient video editing model that edits variable-length videos frame by frame. For efficiency, we start from a 2D image-to-image (I2I) diffusion model and adapt it to video-to-video (V2V) editing by conditioning the edit at time step t on the model's prediction at t-1. To leverage videos' temporal redundancy, we propose a new I2I diffusion forward process formulation that encourages the model to predict the residual between the target output and the previous prediction. We call this Residual Flow Diffusion Model (RFDM), which focuses the denoising process on changes between consecutive frames. Moreover, we propose a new benchmark that better ranks state-of-the-art methods for editing tasks. Trained on paired video data for global/local style transfer and object removal, RFDM surpasses I2I-based methods and competes with fully spatiotemporal (3D) V2V models, while matching the compute of image models and scaling independently of input video length. More content can be found in: https://smsd75.github.io/RFDM_page/

</details>


### [103] [Reliable Mislabel Detection for Video Capsule Endoscopy Data](https://arxiv.org/abs/2602.06938)
*Julia Werner,Julius Oexle,Oliver Bause,Maxime Le Floch,Franz Brinkmann,Hannah Tolle,Jochen Hampe,Oliver Bringmann*

Main category: cs.CV

TL;DR: 提出一个在医疗图像数据集中检测错误标签的框架，并在视频胶囊内窥镜数据集上验证，提高了异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 医疗图像数据集的标注成本高、难度大，且类别界限模糊，限制了深度学习模型的性能。

Method: 提出一个用于检测医疗数据集中错误标签的框架，并在视频胶囊内窥镜数据集上进行验证，由三位经验丰富的主治医师对潜在错误标签的样本进行审查和重新标注。

Result: 该框架成功检测出错误标注的数据，并且在清理数据集后，与现有基线方法相比，异常检测性能有所提高。

Conclusion: 提出的框架能够有效地检测医疗图像数据集中的错误标签，并能通过数据集清理来提升模型的性能。

Abstract: The classification performance of deep neural networks relies strongly on access to large, accurately annotated datasets. In medical imaging, however, obtaining such datasets is particularly challenging since annotations must be provided by specialized physicians, which severely limits the pool of annotators. Furthermore, class boundaries can often be ambiguous or difficult to define which further complicates machine learning-based classification. In this paper, we want to address this problem and introduce a framework for mislabel detection in medical datasets. This is validated on the two largest, publicly available datasets for Video Capsule Endoscopy, an important imaging procedure for examining the gastrointestinal tract based on a video stream of lowresolution images. In addition, potentially mislabeled samples identified by our pipeline were reviewed and re-annotated by three experienced gastroenterologists. Our results show that the proposed framework successfully detects incorrectly labeled data and results in an improved anomaly detection performance after cleaning the datasets compared to current baselines.

</details>


### [104] [Seeing Beyond Redundancy: Task Complexity's Role in Vision Token Specialization in VLLMs](https://arxiv.org/abs/2602.06914)
*Darryl Hannan,John Cooper,Dylan White,Yijing Watkins*

Main category: cs.CV

TL;DR: 研究表明，视觉大型语言模型（VLLMs）在处理细粒度视觉信息和空间推理方面表现不佳，可能与视觉信息冗余和压缩有关。通过合成数据集和度量指标，发现任务复杂性与视觉压缩程度相关，高复杂度数据对VLLMs的视觉表示分布和任务表现至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现VLLMs在细粒度视觉信息和空间推理任务上表现较差，但具体原因尚不明确。本文旨在深入探究VLLMs处理视觉信息的方式，以及哪些信息被丢弃，以解释其性能瓶颈。

Method: 研究人员引入了一个专门设计的合成基准数据集，用于探测各种视觉特征。此外，他们开发了一套度量指标来量化视觉冗余。接着，他们通过在复杂的视觉任务上对VLLMs进行微调，来考察不同复杂度的训练数据对冗余和压缩的影响。

Result: 研究发现，任务复杂性与视觉压缩之间存在关联。模型在处理高复杂度视觉数据时，会改变其视觉表示的分布方式，从而提高在复杂视觉任务上的性能。

Conclusion: 具有足够比例的高复杂度视觉数据对于改变VLLMs的视觉表示分布，进而提升其在复杂视觉任务上的表现至关重要。这项研究为未来VLLMs的训练提供了有价值的见解。

Abstract: Vision capabilities in vision large language models (VLLMs) have consistently lagged behind their linguistic capabilities. In particular, numerous benchmark studies have demonstrated that VLLMs struggle when fine-grained visual information or spatial reasoning is required. However, we do not yet understand exactly why VLLMs struggle so much with these tasks relative to others. Some works have focused on visual redundancy as an explanation, where high-level visual information is uniformly spread across numerous tokens and specific, fine-grained visual information is discarded. In this work, we investigate this premise in greater detail, seeking to better understand exactly how various types of visual information are processed by the model and what types of visual information are discarded. To do so, we introduce a simple synthetic benchmark dataset that is specifically constructed to probe various visual features, along with a set of metrics for measuring visual redundancy, allowing us to better understand the nuances of their relationship. Then, we explore fine-tuning VLLMs on a number of complex visual tasks to better understand how redundancy and compression change based upon the complexity of the data that a model is trained on. We find that there is a connection between task complexity and visual compression, implying that having a sufficient ratio of high complexity visual data is crucial for altering the way that VLLMs distribute their visual representation and consequently improving their performance on complex visual tasks. We hope that this work will provide valuable insights for training the next generation of VLLMs.

</details>


### [105] [Prompt Reinjection: Alleviating Prompt Forgetting in Multimodal Diffusion Transformers](https://arxiv.org/abs/2602.06886)
*Yuxuan Yao,Yuxuan Chen,Hui Li,Kaihui Cheng,Qipeng Guo,Yuwei Sun,Zilong Dong,Jingdong Wang,Siyu Zhu*

Main category: cs.CV

TL;DR: 研究发现多模态扩散 Transformer（MMDiTs）在文本到图像生成过程中存在“提示遗忘”现象，即文本提示在深层网络中逐渐被遗忘。提出一种无需训练的“提示重注入”方法，通过将早期层的提示表示注入到后期层来缓解该问题，并在多个基准测试中取得了生成能力和图像质量的提升。


<details>
  <summary>Details</summary>
Motivation: 在多模态扩散 Transformer (MMDiTs) 中观察到文本提示在网络加深时其表示被逐渐遗忘（提示遗忘现象），这影响了文本到图像生成任务的指令遵循能力。

Method: 1. 验证并量化了在 SD3, SD3.5, FLUX.1 等 MMDiTs 模型中存在的提示遗忘现象，通过探查文本分支层级的语言属性。 2. 提出了一种训练免费的“提示重注入”方法，将文本分支早期层的提示表示重新注入到后期层，以缓解提示遗忘。

Result: 所提出的提示重注入方法在 GenEval, DPG, T2I-CompBench++ 等基准测试中，一致性地提升了模型的指令遵循能力，并在捕获偏好、美观度和整体文本-图像生成质量方面取得了改进。

Conclusion: 提示遗忘是 MMDiTs 模型中的一个关键问题，而提示重注入作为一种训练免费的后处理技术，能够有效缓解此问题，显著提升文本到图像生成模型的性能，尤其是在指令遵循能力和整体生成质量方面。

Abstract: Multimodal Diffusion Transformers (MMDiTs) for text-to-image generation maintain separate text and image branches, with bidirectional information flow between text tokens and visual latents throughout denoising. In this setting, we observe a prompt forgetting phenomenon: the semantics of the prompt representation in the text branch is progressively forgotten as depth increases. We further verify this effect on three representative MMDiTs--SD3, SD3.5, and FLUX.1 by probing linguistic attributes of the representations over the layers in the text branch. Motivated by these findings, we introduce a training-free approach, prompt reinjection, which reinjects prompt representations from early layers into later layers to alleviate this forgetting. Experiments on GenEval, DPG, and T2I-CompBench++ show consistent gains in instruction-following capability, along with improvements on metrics capturing preference, aesthetics, and overall text--image generation quality.

</details>


### [106] [CineScene: Implicit 3D as Effective Scene Representation for Cinematic Video Generation](https://arxiv.org/abs/2602.06959)
*Kaiyi Huang,Yukun Huang,Yu Li,Jianhong Bai,Xintao Wang,Zinan Lin,Xuefei Ning,Jiwen Yu,Pengfei Wan,Yu Wang,Xihui Liu*

Main category: cs.CV

TL;DR: 提出了一种名为CineScene的框架，用于生成具有解耦场景上下文的电影级视频，通过利用隐式3D感知场景表示和新颖的上下文条件机制，在保持场景一致性的同时合成具有动态主体的视频，并允许用户指定相机轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统电影制作成本高昂，需要搭建实体场景。研究的动机是开发一种能够从静态环境图像生成具有动态主体和特定相机轨迹的电影级视频的方法，以降低成本并提高灵活性。

Method: CineScene框架利用隐式3D感知场景表示。其核心创新在于一种新的上下文条件机制，通过VGGT将场景图像编码为视觉表示，并将这些空间先验信息隐式地注入预训练的文本到视频生成模型中。此外，还引入了训练时的随机图像打乱策略来增强鲁棒性。

Result: CineScene在场景一致性电影级视频生成方面取得了最先进的性能，能够处理大幅度的相机移动，并在不同环境中表现出泛化能力。

Conclusion: CineScene框架能够有效地生成具有解耦场景上下文的电影级视频，成功地在保持场景一致性的同时合成具有动态主体和用户指定相机轨迹的视频，为电影制作提供了新的解决方案。

Abstract: Cinematic video production requires control over scene-subject composition and camera movement, but live-action shooting remains costly due to the need for constructing physical sets. To address this, we introduce the task of cinematic video generation with decoupled scene context: given multiple images of a static environment, the goal is to synthesize high-quality videos featuring dynamic subject while preserving the underlying scene consistency and following a user-specified camera trajectory. We present CineScene, a framework that leverages implicit 3D-aware scene representation for cinematic video generation. Our key innovation is a novel context conditioning mechanism that injects 3D-aware features in an implicit way: By encoding scene images into visual representations through VGGT, CineScene injects spatial priors into a pretrained text-to-video generation model by additional context concatenation, enabling camera-controlled video synthesis with consistent scenes and dynamic subjects. To further enhance the model's robustness, we introduce a simple yet effective random-shuffling strategy for the input scene images during training. To address the lack of training data, we construct a scene-decoupled dataset with Unreal Engine 5, containing paired videos of scenes with and without dynamic subjects, panoramic images representing the underlying static scene, along with their camera trajectories. Experiments show that CineScene achieves state-of-the-art performance in scene-consistent cinematic video generation, handling large camera movements and demonstrating generalization across diverse environments.

</details>


### [107] [MedMO: Grounding and Understanding Multimodal Large Language Model for Medical Images](https://arxiv.org/abs/2602.06965)
*Ankan Deria,Komal Kumar,Adinath Madhavrao Dukre,Eran Segal,Salman Khan,Imran Razzak*

Main category: cs.CV

TL;DR: 本文提出了MedMO，一个基于通用多模态大语言模型架构的医学领域基础模型，通过多阶段训练，在医学影像问答、报告生成和定位等任务上取得了显著优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型（MLLMs）在医学领域的应用受限于领域覆盖不足、模态对齐不佳和推理能力欠缺。因此，需要一个专门针对医学数据训练的、更强大的基础模型。

Method: MedMO采用了多阶段训练策略：1. 跨模态预训练，对齐异构视觉编码器和医学语言主干；2. 指令微调，包含医学影像字幕生成、视觉问答（VQA）、报告生成、检索和带边界框的疾病定位等任务；3. 强化学习，结合事实核查和边界框的GIoU奖励，以提高空间定位和逐步推理能力。

Result: MedMO在多个医学任务和模态上均超越了现有的开源医学MLLMs。在VQA基准测试中，MedMO的平均准确率比基线模型提高了13.7%；在基于文本的问答中，比基线模型提高了6.9%。在医学报告生成方面，MedMO在语义和临床准确性上都有显著提升。其定位能力也得到显著增强，IoU比基线模型提高了40.4%。

Conclusion: MedMO是一个强大的医学领域多模态基础模型，通过专门的训练策略，克服了现有MLLMs在医学应用中的挑战，并在多种医学模态和任务中展现出优越的性能和泛化能力。

Abstract: Multimodal large language models (MLLMs) have rapidly advanced, yet their adoption in medicine remains limited by gaps in domain coverage, modality alignment, and grounded reasoning. In this work, we introduce MedMO, a medical foundation model built upon a generalized MLLM architecture and trained exclusively on large-scale, domain-specific data. MedMO follows a multi-stage training recipe: (i) cross-modal pretraining to align heterogeneous visual encoders with a medical language backbone; (ii) instruction tuning on multi-task supervision that spans captioning, VQA, report generation, retrieval, and grounded disease localization with bounding boxes; and (iii) reinforcement learning with verifiable rewards that combine factuality checks with a box-level GIoU reward to strengthen spatial grounding and step-by-step reasoning in complex clinical scenarios. MedMO consistently outperforms strong open-source medical MLLMs across multiple modalities and tasks. On VQA benchmarks, MedMO achieves an average accuracy improvement of +13.7% over the baseline and performs within 1.9% of the SOTA Fleming-VL. For text-based QA, it attains +6.9% over the baseline and +14.5% over Fleming-VL. In medical report generation, MedMO delivers significant gains in both semantic and clinical accuracy. Moreover, it exhibits strong grounding capability, achieving an IoU improvement of +40.4 over the baseline and +37.0% over Fleming-VL, underscoring its robust spatial reasoning and localization performance. Evaluations across radiology, ophthalmology, and pathology-microscopy confirm MedMO's broad cross-modality generalization. We release two versions of MedMO: 4B and 8B. Project is available at https://genmilab.github.io/MedMO-Page

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [108] [Recontextualizing Famous Quotes for Brand Slogan Generation](https://arxiv.org/abs/2602.06049)
*Ziao Yang,Zizhang Chen,Lei Zhang,Hongfu Liu*

Main category: cs.CL

TL;DR: 本研究提出了一种新的广告语生成方法，通过重新组合和修改名人名言来生成新颖且具有品牌个性的广告语，并在实验中取得了优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在生成广告语时存在风格单一、缺乏品牌个性、易显现机器生成痕迹的问题，导致广告疲劳，因此需要更具创意和洞察力的广告语生成方法。

Method: 研究提出了一种模块化框架，将广告语生成分解为四个子任务：名言匹配、结构分解、词汇替换和重组生成，核心思想是利用名人名言来生成广告语。

Result: 通过自动和人工评估，该方法在多样性、新颖性、情感影响和人类偏好方面均比三种最先进的大型语言模型基线方法有边际提升。

Conclusion: 通过将名人名言重新语境化用于广告语生成，可以有效平衡新颖性和熟悉度，生成更具创意、深度和品牌个性的广告语，克服了现有方法的不足。

Abstract: Slogans are concise and memorable catchphrases that play a crucial role in advertising by conveying brand identity and shaping public perception. However, advertising fatigue reduces the effectiveness of repeated slogans, creating a growing demand for novel, creative, and insightful slogan generation. While recent work leverages large language models (LLMs) for this task, existing approaches often produce stylistically redundant outputs that lack a clear brand persona and appear overtly machine-generated. We argue that effective slogans should balance novelty with familiarity and propose a new paradigm that recontextualizes persona-related famous quotes for slogan generation. Well-known quotes naturally align with slogan-length text, employ rich rhetorical devices, and offer depth and insight, making them a powerful resource for creative generation. Technically, we introduce a modular framework that decomposes slogan generation into interpretable subtasks, including quote matching, structural decomposition, vocabulary replacement, and remix generation. Extensive automatic and human evaluations demonstrate marginal improvements in diversity, novelty, emotional impact, and human preference over three state-of-the-art LLM baselines.

</details>


### [109] [Relevance-aware Multi-context Contrastive Decoding for Retrieval-augmented Visual Question Answering](https://arxiv.org/abs/2602.06050)
*Jongha Kim,Byungoh Ko,Jeehye Na,Jinsung Yoon,Hyunwoo J. Kim*

Main category: cs.CL

TL;DR: 提出了一种名为RMCD的新型解码方法，用于改进检索增强生成（RAG）在大型视觉语言模型（LVLMs）中的应用，通过整合多个相关上下文并抑制无关上下文的负面影响，从而提升了模型在知识密集型视觉问答任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG解码方法未能充分利用多个相关上下文，并且无法有效抑制无关上下文的负面影响，导致LVLMs在处理特定实体知识时存在不足。

Method: 提出了一种名为相关性感知多上下文对比解码（RMCD）的新型解码方法。RMCD通过整合每个上下文预测的输出，并根据上下文与问题的相关性对其进行加权，从而生成最终预测。这种方法能够有效聚合多个相关上下文的信息，并抵消无关上下文的负面效应。

Result: RMCD在多个LVLMs上持续优于其他解码方法，并在三个知识密集型视觉问答基准测试中取得了最佳性能。该方法无需额外训练，并且对检索结果具有鲁棒性。

Conclusion: RMCD是一种有效且易于应用的解码方法，可以显著提升LVLMs在检索增强生成任务中的表现，尤其是在处理知识密集型视觉问答场景时，能够更好地利用相关上下文并规避无关上下文的干扰。

Abstract: Despite the remarkable capabilities of Large Vision Language Models (LVLMs), they still lack detailed knowledge about specific entities. Retrieval-augmented Generation (RAG) is a widely adopted solution that enhances LVLMs by providing additional contexts from an external Knowledge Base. However, we observe that previous decoding methods for RAG are sub-optimal as they fail to sufficiently leverage multiple relevant contexts and suppress the negative effects of irrelevant contexts. To this end, we propose Relevance-aware Multi-context Contrastive Decoding (RMCD), a novel decoding method for RAG. RMCD outputs a final prediction by combining outputs predicted with each context, where each output is weighted based on its relevance to the question. By doing so, RMCD effectively aggregates useful information from multiple relevant contexts while also counteracting the negative effects of irrelevant ones. Experiments show that RMCD consistently outperforms other decoding methods across multiple LVLMs, achieving the best performance on three knowledge-intensive visual question-answering benchmarks. Also, RMCD can be simply applied by replacing the decoding method of LVLMs without additional training. Analyses also show that RMCD is robust to the retrieval results, consistently performing the best across the weakest to the strongest retrieval results. Code is available at https://github.com/mlvlab/RMCD.

</details>


### [110] [CAST: Character-and-Scene Episodic Memory for Agents](https://arxiv.org/abs/2602.06051)
*Kexin Ma,Bojun Li,Yuhua Tang,Ruochun Jin,Liting Sun*

Main category: cs.CL

TL;DR: 本文提出了一种名为CAST（Character-and-Scene based memory architecture）的基于戏剧理论的记忆架构，用于解决现有智能体记忆系统难以表示和检索连贯事件的问题。CAST结合了基于3D场景的事件记忆和基于图的语义记忆，在多个数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有智能体记忆系统主要关注语义检索，未能有效表示和检索连贯的事件（who, when, where），而人类的 the episodic memory 恰好擅长此能力。

Method: 构建了基于3D场景（时间/地点/主题）的事件记忆，并将事件组织到角色档案中。同时，结合基于图的语义记忆，形成了一个双重记忆设计。

Result: 在多个数据集上，CAST的F1分数平均提高了8.11%，LLM-as-a-Judge评估得分平均提高了10.21%。在开放性和时间敏感的对话问题上表现尤为突出。

Conclusion: CAST架构成功地弥补了现有智能体记忆系统在处理连贯事件方面的不足，通过结合事件记忆和语义记忆，显著提升了智能体的回忆能力，尤其是在处理复杂对话场景时。

Abstract: Episodic memory is a central component of human memory, which refers to the ability to recall coherent events grounded in who, when, and where. However, most agent memory systems only emphasize semantic recall and treat experience as structures such as key-value, vector, or graph, which makes them struggle to represent and retrieve coherent events. To address this challenge, we propose a Character-and-Scene based memory architecture(CAST) inspired by dramatic theory. Specifically, CAST constructs 3D scenes (time/place/topic) and organizes them into character profiles that summarize the events of a character to represent episodic memory. Moreover, CAST complements this episodic memory with a graph-based semantic memory, which yields a robust dual memory design. Experiments demonstrate that CAST has averagely improved 8.11% F1 and 10.21% J(LLM-as-a-Judge) than baselines on various datasets, especially on open and time-sensitive conversational questions.

</details>


### [111] [Rethinking Memory Mechanisms of Foundation Agents in the Second Half](https://arxiv.org/abs/2602.06052)
*Wei-Chieh Huang,Weizhi Zhang,Yueqing Liang,Yuanchen Bei,Yankai Chen,Tao Feng,Xinyu Pan,Zhen Tan,Yu Wang,Tianxin Wei,Shanglin Wu,Ruiyao Xu,Liangwei Yang,Rui Yang,Wooseong Yang,Chin-Yuan Yeh,Hanrong Zhang,Haozhen Zhang,Siqi Zhu,Henry Peng Zou,Wanjia Zhao,Song Wang,Wujiang Xu,Zixuan Ke,Zheng Hui,Dawei Li,Yaozu Wu,Langzhou He,Chen Wang,Xiongxiao Xu,Baixiang Huang,Juntao Tan,Shelby Heinecke,Huan Wang,Caiming Xiong,Ahmed A. Metwally,Jun Yan,Chen-Yu Lee,Hanqing Zeng,Yinglong Xia,Xiaokai Wei,Ali Payani,Yu Wang,Haitong Ma,Wenya Wang,Chengguang Wang,Yu Zhang,Xin Wang,Yongfeng Zhang,Jiaxuan You,Hanghang Tong,Xiao Luo,Yizhou Sun,Wei Wang,Julian McAuley,James Zou,Jiawei Han,Philip S. Yu,Kai Shu*

Main category: cs.CL

TL;DR: 本篇论文对人工智能代理中的基础记忆进行了全面的综述，重点关注其在动态、用户依赖环境中的实用性，并探讨了记忆的基底、机制、主体、实现方式、评估方法以及未来的挑战。


<details>
  <summary>Details</summary>
Motivation: 人工智能领域正从关注模型和分数转向强调实际应用和真实世界评估。在“下半场”，长时、动态、用户依赖的环境成为核心挑战，需要代理能够处理信息爆炸并有效管理和重用信息，因此，记忆成为填补实用性鸿沟的关键。

Method: 本综述从三个维度对基础代理记忆进行了统一视图：记忆基底（内部和外部）、认知机制（情景、语义、感官、工作和程序性）以及记忆主体（代理中心和用户中心）。此外，还分析了不同代理拓扑结构下记忆的实例化和操作，并探讨了记忆操作的学习策略。

Result: 论文对记忆的基底、认知机制和主体进行了分类，并分析了记忆在不同代理结构下的具体实现和学习策略。同时，回顾了评估记忆效用的基准和指标。

Conclusion: 记忆是弥合人工智能代理实用性差距的关键。未来的研究需要关注如何在动态、用户依赖的环境中有效设计和评估代理记忆，以应对信息爆炸和长时交互的挑战。

Abstract: The research of artificial intelligence is undergoing a paradigm shift from prioritizing model innovations over benchmark scores towards emphasizing problem definition and rigorous real-world evaluation. As the field enters the "second half," the central challenge becomes real utility in long-horizon, dynamic, and user-dependent environments, where agents face context explosion and must continuously accumulate, manage, and selectively reuse large volumes of information across extended interactions. Memory, with hundreds of papers released this year, therefore emerges as the critical solution to fill the utility gap. In this survey, we provide a unified view of foundation agent memory along three dimensions: memory substrate (internal and external), cognitive mechanism (episodic, semantic, sensory, working, and procedural), and memory subject (agent- and user-centric). We then analyze how memory is instantiated and operated under different agent topologies and highlight learning policies over memory operations. Finally, we review evaluation benchmarks and metrics for assessing memory utility, and outline various open challenges and future directions.

</details>


### [112] [PersonaPlex: Voice and Role Control for Full Duplex Conversational Speech Models](https://arxiv.org/abs/2602.06053)
*Rajarshi Roy,Jonathan Raiman,Sang-gil Lee,Teodor-Dumitru Ene,Robert Kirby,Sungwon Kim,Jaehyeon Kim,Bryan Catanzaro*

Main category: cs.CL

TL;DR: PersonaPlex是一个双工对话语音模型，通过结合角色引导、文本提示和语音克隆，实现了更具个性化和结构化的语音交互，并在多角色客服场景下优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有双工语音模型受限于固定的角色和声音，无法支持需要结构化、角色驱动的实际应用以及个性化交互。

Method: 提出PersonaPlex模型，该模型采用混合系统提示，结合了角色引导、文本提示和语音克隆（通过语音样本）。模型在一个大规模合成数据集上进行训练，该数据集由开放源代码的LLM和TTS模型生成。此外，扩展了Full-Duplex-Bench基准测试以支持多角色客服场景。

Result: PersonaPlex在角色引导行为、声音条件下的语音输出以及自然对话响应方面表现出色，在角色遵从性、说话人相似度、延迟和自然度等方面优于最先进的双工语音模型和基于混合LLM的语音系统。

Conclusion: PersonaPlex成功地实现了灵活的角色和声音控制，为构建更具适应性和个性化的双工对话语音应用提供了新的可能性。

Abstract: Recent advances in duplex speech models have enabled natural, low-latency speech-to-speech interactions. However, existing models are restricted to a fixed role and voice, limiting their ability to support structured, role-driven real-world applications and personalized interactions. In this work, we introduce PersonaPlex, a duplex conversational speech model that incorporates hybrid system prompts, combining role conditioning with text prompts and voice cloning with speech samples. PersonaPlex is trained on a large-scale synthetic dataset of paired prompts and user-agent conversations, generated with open-source large language models (LLM) and text-to-speech (TTS) models. To evaluate role conditioning in real-world settings, we extend the Full-Duplex-Bench benchmark beyond a single assistant role to multi-role customer service scenarios. Experiments show that PersonaPlex achieves strong role-conditioned behavior, voice-conditioned speech, and natural conversational responsiveness, surpassing state-of-the-art duplex speech models and hybrid large language model-based speech systems in role adherence, speaker similarity, latency, and naturalness.

</details>


### [113] [What Is Novel? A Knowledge-Driven Framework for Bias-Aware Literature Originality Evaluation](https://arxiv.org/abs/2602.06054)
*Abeer Mostafa,Thi Huyen Nguyen,Zahra Ahmadi*

Main category: cs.CL

TL;DR: 本文提出了一种基于文献的、可解释的新颖性评估框架，该框架通过学习人类审稿人的判断行为，并结合结构化的文献比对，来更客观、一致地评估研究新颖性。


<details>
  <summary>Details</summary>
Motivation: 当前研究新颖性评估的主观性强、比较不充分，导致同行评审中的判断依赖于隐性标准。

Method: 利用近8万份AI顶会论文的审稿报告，对大型语言模型进行微调，学习人类对新颖性的评价行为。该系统提取论文的结构化表征，检索相关文献，构建相似度图谱，进行细粒度的概念级比对，并基于这些证据生成新颖性评分和解释。

Result: 与现有方法相比，该系统能够减少对新颖性的高估，提高评估的一致性，并生成类似人类的解释性评估。

Conclusion: 该框架通过结合学习人类行为和结构化文献比对，能够实现更可靠、更一致的研究新颖性评估。

Abstract: Assessing research novelty is a core yet highly subjective aspect of peer review, typically based on implicit judgment and incomplete comparison to prior work. We introduce a literature-aware novelty assessment framework that explicitly learns how humans judge novelty from peer-review reports and grounds these judgments in structured comparison to existing research. Using nearly 80K novelty-annotated reviews from top-tier AI conferences, we fine-tune a large language model to capture reviewer-aligned novelty evaluation behavior. For a given manuscript, the system extracts structured representations of its ideas, methods, and claims, retrieves semantically related papers, and constructs a similarity graph that enables fine-grained, concept-level comparison to prior work. Conditioning on this structured evidence, the model produces calibrated novelty scores and human-like explanatory assessments, reducing overestimation and improving consistency relative to existing approaches.

</details>


### [114] [Quantifying and Attributing Polarization to Annotator Groups](https://arxiv.org/abs/2602.06055)
*Dimitris Tsirmpas,John Pavlopoulos*

Main category: cs.CL

TL;DR: 提出了一种新的量化指标和统计检验方法，用于分析不同标注者群体之间的极化现象，解决了现有指标在群体间分析、样本不平衡和多标签设置下的局限性，并应用于仇恨言论和毒性检测任务，发现种族、宗教和教育程度对标注极化有显著影响。


<details>
  <summary>Details</summary>
Motivation: 现有的标注一致性指标不适用于跨群体分析，对群体规模不平衡敏感，且仅限于单标注场景，不足以应对诸如毒性言论和仇恨言论检测等主观性强的任务。

Method: 引入了一种可量化的指标，并配合统计显著性检验，用于归因不同标注者群体间的极化现象。该方法支持对不同规模的社会人口统计学和意识形态亚群体进行直接比较，跨越不同数据集和任务，并适用于多标签设置。

Result: 在仇恨言论和毒性检测数据集上的应用表明：1. 标注者的种族，尤其是在仇恨言论任务上，与极化现象强相关且持续存在。2. 宗教背景的标注者之间不存在根本性分歧，但与其他标注者存在分歧，而无宗教信仰的标注者则表现出相反的趋势。3. 教育程度较低的标注者更具主观性，而受过良好教育的标注者之间更倾向于达成一致。

Conclusion: 提出的新指标和方法能够有效地分析不同标注者群体的极化现象，并揭示了种族、宗教和教育程度等因素对标注结果的影响。研究还估计了获得稳健结果所需的最小标注者数量，并提供了一个开源的Python库来实现该指标。

Abstract: Current annotation agreement metrics are not well-suited for inter-group analysis, are sensitive to group size imbalances and restricted to single-annotation settings. These restrictions render them insufficient for many subjective tasks such as toxicity and hate-speech detection. For this reason, we introduce a quantifiable metric, paired with a statistical significance test, that attributes polarization to various annotator groups. Our metric enables direct comparisons between heavily imbalanced sociodemographic and ideological subgroups across different datasets and tasks, while also enabling analysis on multi-label settings. We apply this metric to three datasets on hate speech, and one on toxicity detection, discovering that: (1) Polarization is strongly and persistently attributed to annotator race, especially on the hate speech task. (2) Religious annotators do not fundamentally disagree with each other, but do with other annotators, a trend that is gradually diminished and then reversed with irreligious annotators. (3) Less educated annotators are more subjective, while educated ones tend to broadly agree more between themselves. Overall, our results reflect current findings around annotation patterns for various subgroups. Finally, we estimate the minimum number of annotators needed to obtain robust results, and provide an open-source Python library that implements our metric.

</details>


### [115] [Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding](https://arxiv.org/abs/2602.06161)
*Yanzheng Xiang,Lan Wei,Yizhen Yao,Qinglin Zhu,Hanqi Yan,Chen Jin,Philip Alexander Teare,Dandan Zhang,Lin Gui,Amrutha Saseendran,Yulan He*

Main category: cs.CL

TL;DR: 提出了一种名为COVER的新型并行解码方法，通过在一次前向传播中进行留一法验证和稳定草稿，解决了现有方法中因翻转振荡导致的效率低下和质量下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有的可撤销解码方法在加速扩散语言模型推理时，存在频繁的翻转振荡（token被重新掩码又恢复不变），这会削弱上下文信息并浪费修订预算，从而降低推理速度并影响输出质量。

Method: COVER方法通过KV缓存覆盖构建两种注意力视图：将选定的种子token进行掩码以进行验证，同时将它们的缓存键值状态注入所有其他查询以保留上下文信息。使用闭式对角线校正来防止种子位置的自泄露。此外，COVER使用一种基于稳定性的分数来优先选择种子，该分数平衡了不确定性、下游影响和缓存漂移，并能自适应地调整每步验证的种子数量。

Result: COVER显著减少了不必要的修订，提高了解码速度，同时保持了输出质量。在多个基准测试中均取得了良好的效果。

Conclusion: COVER是一种有效的并行解码方法，通过创新的验证和草稿机制，克服了现有方法的局限性，在保证质量的同时显著提升了扩散语言模型的推理效率。

Abstract: Parallel diffusion decoding can accelerate diffusion language model inference by unmasking multiple tokens per step, but aggressive parallelism often harms quality. Revocable decoding mitigates this by rechecking earlier tokens, yet we observe that existing verification schemes frequently trigger flip-flop oscillations, where tokens are remasked and later restored unchanged. This behaviour slows inference in two ways: remasking verified positions weakens the conditioning context for parallel drafting, and repeated remask cycles consume the revision budget with little net progress. We propose COVER (Cache Override Verification for Efficient Revision), which performs leave-one-out verification and stable drafting within a single forward pass. COVER constructs two attention views via KV cache override: selected seeds are masked for verification, while their cached key value states are injected for all other queries to preserve contextual information, with a closed form diagonal correction preventing self leakage at the seed positions. COVER further prioritises seeds using a stability aware score that balances uncertainty, downstream influence, and cache drift, and it adapts the number of verified seeds per step. Across benchmarks, COVER markedly reduces unnecessary revisions and yields faster decoding while preserving output quality.

</details>


### [116] [Uncertainty Drives Social Bias Changes in Quantized Large Language Models](https://arxiv.org/abs/2602.06181)
*Stanley Z. Hua,Sanae Lotfi,Irene Y. Chen*

Main category: cs.CL

TL;DR: 研究发现，后训练量化（post-training quantization）虽然降低了大型语言模型的计算成本，但会以一种聚合指标无法捕捉的方式改变模型的社会偏见。作者提出了“量化诱导的掩码偏见翻转”现象，其中高达21%的响应在量化后会在有偏和无偏状态之间翻转，尽管聚合偏见分数没有变化。这种翻转与模型不确定性密切相关，且量化强度越高，翻转现象越显著。这种变化对不同人口统计群体产生不对称影响，可能导致聚合结果误导性地中性。


<details>
  <summary>Details</summary>
Motivation: 现有的后训练量化研究主要关注模型性能和计算成本的权衡，而忽视了量化对模型社会偏见的潜在影响，尤其是量化可能以聚合指标无法捕捉的方式改变偏见模式。

Method: 作者构建了一个包含13个数据集的基准测试 PostTrainingBiasBench，并在此基准上对50个量化模型进行了大规模研究。他们分析了量化后响应在有偏和无偏之间的翻转现象，并研究了模型不确定性、量化强度、模型大小以及模型家族对偏见翻转的影响。此外，研究还评估了量化对不同人口统计群体偏见影响的差异性。

Result: 1. 发现了“量化诱导的掩码偏见翻转”现象，高达21%的响应在量化后发生偏见状态翻转，但聚合偏见分数变化不大。
2. 高不确定性响应比自信响应更有可能发生翻转（3-11倍）。
3. 量化强度越高（如4位量化），偏见翻转现象越显著（4-6倍）。
4. 量化诱导的偏见变化对不同人口统计群体造成不对称影响，有的群体偏见加剧（高达18.6%），有的则改善（高达14.1%），导致聚合结果具有误导性。
5. 大型模型在抵抗偏见改变方面没有显示出一致的优势，且群体特异性变化在不同模型家族间不可预测。

Conclusion: 后训练量化会从根本上改变语言模型的偏见模式，尤其是在细粒度层面上。这种量化诱导的掩码偏见翻转现象对不同群体产生不对称影响，使得简单的聚合指标评估不可靠。因此，在模型部署前，必须进行量化后的细致评估，并采取干预措施以确保模型的可靠性。

Abstract: Post-training quantization reduces the computational cost of large language models but fundamentally alters their social biases in ways that aggregate metrics fail to capture. We present the first large-scale study of 50 quantized models evaluated on PostTrainingBiasBench, a unified benchmark of 13 closed- and open-ended bias datasets. We identify a phenomenon we term quantization-induced masked bias flipping, in which up to 21% of responses flip between biased and unbiased states after quantization, despite showing no change in aggregate bias scores. These flips are strongly driven by model uncertainty, where the responses with high uncertainty are 3-11x more likely to change than the confident ones. Quantization strength amplifies this effect, with 4-bit quantized models exhibiting 4-6x more behavioral changes than 8-bit quantized models. Critically, these changes create asymmetric impacts across demographic groups, where bias can worsen by up to 18.6% for some groups while improving by 14.1% for others, yielding misleadingly neutral aggregate outcomes. Larger models show no consistent robustness advantage, and group-specific shifts vary unpredictably across model families. Our findings demonstrate that compression fundamentally alters bias patterns, requiring crucial post-quantization evaluation and interventions to ensure reliability in practice.

</details>


### [117] [BenchMarker: An Education-Inspired Toolkit for Highlighting Flaws in Multiple-Choice Benchmarks](https://arxiv.org/abs/2602.06221)
*Nishant Balepur,Bhavya Rajasekaran,Jane Oh,Michael Xie,Atrey Desai,Vipul Gupta,Steven James Moore,Eunsol Choi,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 本文提出 BenchMarker 工具包，利用 LLM 评估者来识别和修复多项选择题问答 (MCQA) 基准测试中的常见缺陷（污染、捷径、写作错误），以提高 NLP 评估的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的 MCQA 基准测试缺乏严格的质量控制，导致评估结果可能被数据污染、选择项中的提示词或写作错误所干扰，从而影响 NLP 模型性能的真实评估。

Method: 使用 LLM 作为“教育风格”的裁判，依据一套包含 19 条规则的教育标准来识别三类 MCQA 缺陷：1) 污染（题目在线上出现）；2) 捷径（选项中存在易于猜测的线索）；3) 写作错误（结构或语法问题）。通过人类标注验证 BenchMarker 的有效性，然后将其应用于 12 个现有基准测试进行审计。

Result: 研究发现，题目污染会虚高模型准确率，而写作错误会降低准确率并显著改变模型排名。之前的基准测试修复方法虽然解决了特定问题，但可能引入新的缺陷，例如不合理的干扰项或多个正确答案。

Conclusion: MCQA 基准测试中的缺陷会损害 NLP 评估的可靠性。借鉴教育研究领域的经验和方法，可以改进 MCQA 基准测试的设计。BenchMarker 工具包的发布旨在弥合 NLP 和教育研究之间的差距，促进更优质的 MCQA 基准测试。

Abstract: Multiple-choice question answering (MCQA) is standard in NLP, but benchmarks lack rigorous quality control. We present BenchMarker, an education-inspired toolkit using LLM judges to flag three common MCQ flaws: 1) contamination - items appearing exactly online; 2) shortcuts - cues in the choices that enable guessing; and 3) writing errors - structural/grammatical issues based on a 19-rule education rubric. We validate BenchMarker with human annotations, then run the tool to audit 12 benchmarks, revealing: 2) contaminated MCQs tend to inflate accuracy, while writing errors tend to lower it and change rankings beyond random; and 3) prior benchmark repairs address their targeted issues (i.e., lowering accuracy with LLM-written distractors), but inadvertently add new flaws (i.e. implausible distractors, many correct answers). Overall, flaws in MCQs degrade NLP evaluation, but education research offers a path forward. We release BenchMarker to bridge the fields and improve MCQA benchmark design.

</details>


### [118] [Can One-sided Arguments Lead to Response Change in Large Language Models?](https://arxiv.org/abs/2602.06260)
*Pedro Cisneros-Velarde*

Main category: cs.CL

TL;DR: 研究表明，通过提供单方面论点，可以有效地引导大型语言模型（LLM）在回答争议性问题时倾向于特定观点，而改变论点会削弱这种引导效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在回答争议性问题时，可能表现出单一、倾向性观点，或者拒绝回答，缺乏平衡性。研究旨在探索一种简单直观的方法，通过提供单方面论点来引导LLM采取特定立场。

Method: 研究人员通过构建小型数据集，系统性地研究了三种维度对LLM观点引导的影响：（i）诱导的立场、（ii）争议性问题的表述方式、（iii）论点呈现方式。实验涉及不同模型、不同数量的论点和不同的话题。

Result: 研究发现，通过提供支持特定观点的单方面论点，可以有效地引导LLM的回答倾向于该观点，并且这种引导效果在不同模型、论点数量和话题上都普遍存在。然而，改变所提供的论点会一致性地降低观点引导的效果。

Conclusion: 即使只提供单方面论点，也能在不改变问题表述和论点呈现方式的情况下，有效地引导LLM在争议性问题中采取特定立场。研究结果为理解和控制LLM在处理复杂话题时的行为提供了新的视角。

Abstract: Polemic questions need more than one viewpoint to express a balanced answer. Large Language Models (LLMs) can provide a balanced answer, but also take a single aligned viewpoint or refuse to answer. In this paper, we study if such initial responses can be steered to a specific viewpoint in a simple and intuitive way: by only providing one-sided arguments supporting the viewpoint. Our systematic study has three dimensions: (i) which stance is induced in the LLM response, (ii) how the polemic question is formulated, (iii) how the arguments are shown. We construct a small dataset and remarkably find that opinion steering occurs across (i)-(iii) for diverse models, number of arguments, and topics. Switching to other arguments consistently decreases opinion steering.

</details>


### [119] [Is my model "mind blurting"? Interpreting the dynamics of reasoning tokens with Recurrence Quantification Analysis (RQA)](https://arxiv.org/abs/2602.06266)
*Quoc Tuan Pham,Mehdi Jafari,Flora Salim*

Main category: cs.CL

TL;DR: 本研究提出使用 Recurrence Quantification Analysis (RQA) 作为一种非文本方法，在推理模型测试时分析其思考过程，并表明 RQA 能比响应长度更有效地捕捉推理动态并预测任务复杂度。


<details>
  <summary>Details</summary>
Motivation: 分析大型推理模型的测试时计算行为变得越来越不切实际和不可靠，响应长度作为衡量推理努力的代理指标不足以捕捉思考过程（CoT）的动态和有效性。

Method: 将 token 生成视为一个动态系统，提取每个生成步骤的隐藏嵌入，并对由此产生的轨迹应用 RQA。RQA 指标（如确定性和层状性）用于量化模型潜在表示中的重复和停滞模式。

Result: 对 3,600 个 DeepSeek-R1-Distill 的生成轨迹进行分析，发现 RQA 能够捕捉到响应长度未体现的信号，并且能将任务复杂度预测能力提高 8%。

Conclusion: RQA 是一种原则性的工具，可用于研究推理模型在测试时扩展过程中的潜在 token 生成动态。

Abstract: Test-time compute is central to large reasoning models, yet analysing their reasoning behaviour through generated text is increasingly impractical and unreliable. Response length is often used as a brute proxy for reasoning effort, but this metric fails to capture the dynamics and effectiveness of the Chain of Thoughts (CoT) or the generated tokens. We propose Recurrence Quantification Analysis (RQA) as a non-textual alternative for analysing model's reasoning chains at test time. By treating token generation as a dynamical system, we extract hidden embeddings at each generation step and apply RQA to the resulting trajectories. RQA metrics, including Determinism and Laminarity, quantify patterns of repetition and stalling in the model's latent representations. Analysing 3,600 generation traces from DeepSeek-R1-Distill, we show that RQA captures signals not reflected by response length, but also substantially improves prediction of task complexity by 8\%. These results help establish RQA as a principled tool for studying the latent token generation dynamics of test-time scaling in reasoning models.

</details>


### [120] [MPIB: A Benchmark for Medical Prompt Injection Attacks and Clinical Safety in LLMs](https://arxiv.org/abs/2602.06268)
*Junhyeok Lee,Han Jang,Kyu Sung Choi*

Main category: cs.CL

TL;DR: 本文提出了一种名为MPIB的医学提示注入基准测试套件，用于评估大型语言模型（LLMs）和检索增强生成（RAG）系统在临床环境中的安全性，特别关注由提示注入攻击引起的潜在临床危害。研究发现，攻击成功率（ASR）和临床危害事件率（CHER）可能存在显著差异，且模型的鲁棒性与攻击是否源自用户查询还是检索到的上下文密切相关。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs和RAG系统在临床工作流程中的广泛应用，提示注入攻击对这些系统输出的临床安全性构成了严重威胁，可能导致不安全或误导性的医疗建议。因此，需要一个专门的基准来评估和改进系统在面对这类攻击时的安全性。

Method: 研究引入了医学提示注入基准测试套件（MPIB），包含9,697个精心设计的实例，用于评估直接和通过RAG间接的提示注入攻击。MPIB的核心指标是临床危害事件率（CHER），用于衡量高风险的临床危害事件，并结合攻击成功率（ASR）来区分指令遵从度和下游患者风险。该基准经过多阶段质量门和临床安全审查。

Result: 在对不同LLMs和防御配置的评估中，研究发现ASR和CHER可能存在显著差异。模型的鲁棒性高度依赖于对抗性指令是出现在用户查询中还是检索到的上下文中。这表明区分攻击的来源对于评估和防御至关重要。

Conclusion: MPIB提供了一个系统性的方法来评估和研究临床提示注入的安全性问题。研究结果强调了ASR和CHER的独立性以及攻击来源对模型鲁棒性的影响，为开发更安全的临床AI系统提供了重要依据。研究团队公开了MPIB基准、评估代码和对抗性基线，以促进相关研究的可复现性。

Abstract: Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems are increasingly integrated into clinical workflows; however, prompt injection attacks can steer these systems toward clinically unsafe or misleading outputs. We introduce the Medical Prompt Injection Benchmark (MPIB), a dataset-and-benchmark suite for evaluating clinical safety under both direct prompt injection and indirect, RAG-mediated injection across clinically grounded tasks. MPIB emphasizes outcome-level risk via the Clinical Harm Event Rate (CHER), which measures high-severity clinical harm events under a clinically grounded taxonomy, and reports CHER alongside Attack Success Rate (ASR) to disentangle instruction compliance from downstream patient risk. The benchmark comprises 9,697 curated instances constructed through multi-stage quality gates and clinical safety linting. Evaluating MPIB across a diverse set of baseline LLMs and defense configurations, we find that ASR and CHER can diverge substantially, and that robustness depends critically on whether adversarial instructions appear in the user query or in retrieved context. We release MPIB with evaluation code, adversarial baselines, and comprehensive documentation to support reproducible and systematic research on clinical prompt injection. Code and data are available at GitHub (code) and Hugging Face (data).

</details>


### [121] [VowelPrompt: Hearing Speech Emotions from Text via Vowel-level Prosodic Augmentation](https://arxiv.org/abs/2602.06270)
*Yancheng Wang,Osama Hanna,Ruiming Xie,Xianfeng Rui,Maohao Shen,Xuedong Zhang,Christian Fuegen,Jilong Wu,Debjyoti Paul,Arthur Guo,Zhihong Lei,Ozlem Kalinli,Qing He,Yingzhen Yang*

Main category: cs.CL

TL;DR: 本文提出了一种名为 VowelPrompt 的新框架，通过将细粒度的元音级韵律信息（音高、能量、时长）转化为自然语言描述，并与大型语言模型（LLM）结合，以提高语音情感识别的准确性和可解释性。研究采用了两阶段的适应性训练方法（SFT + RLVR），并在多项基准数据集上取得了优于现有方法的性能，同时能够生成基于语义和韵律的解释。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 LLM 的语音情感识别方法通常忽略了细粒度的韵律信息，限制了其有效性和可解释性。而语音韵律信息，尤其是元音，是承载情感的关键。因此，需要一种能够整合这些细粒度韵律信息并增强 LLM 推理能力的方法。

Method: 1. **特征提取**: 从时间对齐的元音片段中提取音高、能量和时长描述符。 2. **特征转换**: 将提取的韵律特征转换为自然语言描述。 3. **模型架构**: 将语言语义和韵律描述结合，输入 LLM 进行联合推理。 4. **训练策略**: 采用两阶段适应性训练：监督微调（SFT）后接基于可验证奖励的强化学习（RLVR），并使用 GRPO 实现。

Result: VowelPrompt 在零样本、微调、跨领域和跨语言等多种条件下，均显著优于当前最先进的语音情感识别方法。此外，该框架能够生成同时基于上下文语义和细粒度韵律结构的、可解释的解释。

Conclusion: VowelPrompt 框架成功地将细粒度的元音级韵律信息融入 LLM，显著提升了语音情感识别的性能和可解释性，并证明了这种结合方法在处理不同数据集和语言时的有效性。

Abstract: Emotion recognition in speech presents a complex multimodal challenge, requiring comprehension of both linguistic content and vocal expressivity, particularly prosodic features such as fundamental frequency, intensity, and temporal dynamics. Although large language models (LLMs) have shown promise in reasoning over textual transcriptions for emotion recognition, they typically neglect fine-grained prosodic information, limiting their effectiveness and interpretability. In this work, we propose VowelPrompt, a linguistically grounded framework that augments LLM-based emotion recognition with interpretable, fine-grained vowel-level prosodic cues. Drawing on phonetic evidence that vowels serve as primary carriers of affective prosody, VowelPrompt extracts pitch-, energy-, and duration-based descriptors from time-aligned vowel segments, and converts these features into natural language descriptions for better interpretability. Such a design enables LLMs to jointly reason over lexical semantics and fine-grained prosodic variation. Moreover, we adopt a two-stage adaptation procedure comprising supervised fine-tuning (SFT) followed by Reinforcement Learning with Verifiable Reward (RLVR), implemented via Group Relative Policy Optimization (GRPO), to enhance reasoning capability, enforce structured output adherence, and improve generalization across domains and speaker variations. Extensive evaluations across diverse benchmark datasets demonstrate that VowelPrompt consistently outperforms state-of-the-art emotion recognition methods under zero-shot, fine-tuned, cross-domain, and cross-linguistic conditions, while enabling the generation of interpretable explanations that are jointly grounded in contextual semantics and fine-grained prosodic structure.

</details>


### [122] [RoPE-LIME: RoPE-Space Locality + Sparse-K Sampling for Efficient LLM Attribution](https://arxiv.org/abs/2602.06275)
*Isaac Picov,Ritesh Goru*

Main category: cs.CL

TL;DR: RoPE-LIME 是一种用于解释闭源 LLM 输出的新方法，它使用小型开源模型来计算 token 级别的归因，并引入了 RoPE 嵌入空间的局部性核和稀疏采样策略，以提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解释闭源 LLM 输出很困难，因为 API 访问阻止了基于梯度的归因，而扰动方法由于需要重新生成文本而成本高昂且噪声大。

Method: RoPE-LIME 使用一个小型开源模型，通过扰动输入并计算概率目标（负对数似然和散度目标）来获得 token 级别的归因。它引入了一个基于 RoPE 嵌入空间中 Relaxed Word Mover's Distance 的局部性核，以及一种名为 Sparse-K sampling 的高效扰动策略。

Result: 在 HotpotQA 和 MMLU 数据集上的实验表明，RoPE-LIME 产生的归因比留一法采样更具信息量，并且优于 gSMILE，同时显著减少了闭源模型的 API 调用次数。

Conclusion: RoPE-LIME 是一种有效且经济的方法，能够为闭源 LLM 的输出提供有意义的 token 级别归因，解决了现有方法的局限性。

Abstract: Explaining closed-source LLM outputs is challenging because API access prevents gradient-based attribution, while perturbation methods are costly and noisy when they depend on regenerated text. We introduce RoPE-LIME, an open-source extension of gSMILE that decouples reasoning from explanation: given a fixed output from a closed model, a smaller open-source surrogate computes token-level attributions from probability-based objectives (negative log-likelihood and divergence targets) under input perturbations. RoPE-LIME incorporates (i) a locality kernel based on Relaxed Word Mover's Distance computed in RoPE embedding space for stable similarity under masking, and (ii) Sparse-K sampling, an efficient perturbation strategy that improves interaction coverage under limited budgets. Experiments on HotpotQA (sentence features) and a hand-labeled MMLU subset (word features) show that RoPE-LIME produces more informative attributions than leave-one-out sampling and improves over gSMILE while substantially reducing closed-model API calls.

</details>


### [123] [Judging What We Cannot Solve: A Consequence-Based Approach for Oracle-Free Evaluation of Research-Level Math](https://arxiv.org/abs/2602.06291)
*Guijin Son,Donghun Yang,Hitesh Laxmichand Patel,Hyunwoo Ko,Amit Agarwal,Sunghee Ahn,Kyong-Ha Lee,Youngjae Yu*

Main category: cs.CL

TL;DR: 本文提出了一种名为“基于结果的效用”（Consequence-Based Utility）的评估方法，用于评估研究水平数学问题中LLM生成解决方案的质量，该方法通过测试解决方案在解决相关问题时的价值来评分，并在实验中优于现有评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有的研究水平数学推理模型在生成解决方案方面取得进展，但验证环节仍然是瓶颈，消耗专家大量时间。研究者希望找到一种方法，能够评估生成解决方案的有效性，并缓解验证成本。

Method: 提出“基于结果的效用”（Consequence-Based Utility）评估器。该方法不依赖于外部验证器（oracle-free），而是通过将每个候选解决方案作为上下文示例，测试其在解决相关且可验证的问题时的价值来对其进行评分。

Result: 在原创研究水平数学问题集上进行的评估显示，“基于结果的效用”在排名质量方面持续优于奖励模型、生成奖励模型和LLM评判器。对于GPT-OSS-120B，其Acc@1从67.2提升到76.3，AUC从71.4提升到79.6。对于GPT-OSS-20B，AUC也显著提升（69.0到79.2）。此外，与LLM评判器相比，该方法展现出更大的求解器-评估器差距，即使在求解器经常失败的情况下，也能保持更强的正确-错误分离。

Conclusion: “基于结果的效用”是一种有效的、无需外部验证器的方法，能够更好地评估研究水平数学问题中LLM生成解决方案的质量，并在准确性和区分度方面优于现有评估技术。

Abstract: Recent progress in reasoning models suggests that generating plausible attempts for research-level mathematics may be within reach, but verification remains a bottleneck, consuming scarce expert time. We hypothesize that a meaningful solution should contain enough method-level information that, when applied to a neighborhood of related questions, it should yield better downstream performance than incorrect solutions. Building on this idea, we propose \textbf{Consequence-Based Utility}, an oracle-free evaluator that scores each candidate by testing its value as an in-context exemplar in solving related yet verifiable questions. Our approach is evaluated on an original set of research-level math problems, each paired with one expert-written solution and nine LLM-generated solutions. Notably, Consequence-Based Utility consistently outperforms reward models, generative reward models, and LLM judges on ranking quality. Specifically, for GPT-OSS-120B, it improves Acc@1 from 67.2 to 76.3 and AUC from 71.4 to 79.6, with similarly large AUC gains on GPT-OSS-20B (69.0 to 79.2). Furthermore, compared to LLM-Judges, it also exhibits a larger solver-evaluator gap, maintaining a stronger correct-wrong separation even on instances where the underlying solver often fails to solve.

</details>


### [124] [Lost in Speech: Benchmarking, Evaluation, and Parsing of Spoken Code-Switching Beyond Standard UD Assumptions](https://arxiv.org/abs/2602.06307)
*Nemika Tyagi,Holly Hendrix,Nelvin Licona-Guevara,Justin Mackie,Phanos Kareen,Muhammad Imran,Megan Michelle Smith,Tatiana Gallego Hernande,Chitta Baral,Olga Kellert*

Main category: cs.CL

TL;DR: 本文提出了一种针对口语代码转换（CSW）的系统化解析方法，通过引入新的语言学分类、标注基准（SpokeBench）和评估指标（FLEX-UD），并开发了一个解耦代理解析框架（DECAP），以解决现有解析器在处理口语CSW时的不足，并取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 口语代码转换（CSW）在语音中的不流畅、重复、省略和语篇驱动结构等现象，严重挑战了现有的句法解析器和大型语言模型（LLMs），尽管它们在书面文本上表现良好。现有评估指标的僵化也加剧了这一问题，将合法的语言变异误判为结构错误。

Method: 1. 提出了口语CSW现象的语言学分类。2. 构建了SpokeBench，一个专家标注的基准数据集，用于测试超越标准UD假设的口语结构。3. 提出了FLEX-UD，一种歧义感知评估指标。4. 开发了DECAP，一个解耦代理解析框架，将口语现象处理与核心句法分析分离。

Result: DECAP框架在不进行模型重训的情况下，能够产生更鲁棒和可解释的解析结果，相较于现有解析技术，性能提升高达52.6%。FLEX-UD评估揭示了DECAP在质量上的改进，而这些改进在标准指标下被掩盖了。

Conclusion: 本文提出的系统化方法，包括SpokeBench、FLEX-UD和DECAP，能够有效提升口语CSW的句法解析性能，克服了现有技术和评估方法的局限性，并为未来的口语语言处理研究提供了新的方向。

Abstract: Spoken code-switching (CSW) challenges syntactic parsing in ways not observed in written text. Disfluencies, repetition, ellipsis, and discourse-driven structure routinely violate standard Universal Dependencies (UD) assumptions, causing parsers and large language models (LLMs) to fail despite strong performance on written data. These failures are compounded by rigid evaluation metrics that conflate genuine structural errors with acceptable variation. In this work, we present a systems-oriented approach to spoken CSW parsing. We introduce a linguistically grounded taxonomy of spoken CSW phenomena and SpokeBench, an expert-annotated gold benchmark designed to test spoken-language structure beyond standard UD assumptions. We further propose FLEX-UD, an ambiguity-aware evaluation metric, which reveals that existing parsing techniques perform poorly on spoken CSW by penalizing linguistically plausible analyses as errors. We then propose DECAP, a decoupled agentic parsing framework that isolates spoken-phenomena handling from core syntactic analysis. Experiments show that DECAP produces more robust and interpretable parses without retraining and achieves up to 52.6% improvements over existing parsing techniques. FLEX-UD evaluations further reveal qualitative improvements that are masked by standard metrics.

</details>


### [125] [Can Post-Training Transform LLMs into Causal Reasoners?](https://arxiv.org/abs/2602.06337)
*Junqi Chen,Sirui Chen,Chaochao Lu*

Main category: cs.CL

TL;DR: 本研究引入 CauGym 数据集，系统评估了五种后训练方法（SFT, DPO, KTO, PPO, GRPO）对大语言模型（LLMs）因果推理能力的影响。结果表明，适当的后训练能显著提升小型 LLMs 的因果推理能力，使其在某些任务上超越更大的模型，并展现出良好的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明大语言模型在因果推理方面有潜力，但其精确估计能力有限，且后训练对这些能力的影响未被充分探索。本研究旨在填补这一空白，评估后训练能否提升 LLMs 的因果推理能力。

Method: 作者构建了一个包含七个核心因果任务的训练集和五个测试集的综合数据集 CauGym。然后，使用此数据集系统地评估了五种后训练方法：SFT, DPO, KTO, PPO, 和 GRPO。在五个领域内任务和四个现有基准测试中进行了实验。

Result: 实验结果显示，经过适当的后训练，小型 LLMs 能够进行具有竞争力的因果推理，其性能常常优于规模大得多的模型。例如，14B 参数的模型在 CaLM 基准测试中达到了 93.5% 的准确率，而 OpenAI o3 为 55.4%。此外，后训练的 LLMs 在面对分布变化和噪声数据等实际情况时，表现出强大的泛化能力和鲁棒性。

Conclusion: 本研究提供了首个系统的证据，表明有针对性的后训练能够产生可靠且鲁棒的基于 LLM 的因果推理器。CauGym 数据集和 GRPO 模型已开源。

Abstract: Causal inference is essential for decision-making but remains challenging for non-experts. While large language models (LLMs) show promise in this domain, their precise causal estimation capabilities are still limited, and the impact of post-training on these abilities is insufficiently explored. This paper examines the extent to which post-training can enhance LLMs' capacity for causal inference. We introduce CauGym, a comprehensive dataset comprising seven core causal tasks for training and five diverse test sets. Using this dataset, we systematically evaluate five post-training approaches: SFT, DPO, KTO, PPO, and GRPO. Across five in-domain and four existing benchmarks, our experiments demonstrate that appropriate post-training enables smaller LLMs to perform causal inference competitively, often surpassing much larger models. Our 14B parameter model achieves 93.5% accuracy on the CaLM benchmark, compared to 55.4% by OpenAI o3. Furthermore, the post-trained LLMs exhibit strong generalization and robustness under real-world conditions such as distribution shifts and noisy data. Collectively, these findings provide the first systematic evidence that targeted post-training can produce reliable and robust LLM-based causal reasoners. Our data and GRPO-model are available at https://github.com/OpenCausaLab/CauGym.

</details>


### [126] [SHINE: A Scalable In-Context Hypernetwork for Mapping Context to LoRA in a Single Pass](https://arxiv.org/abs/2602.06358)
*Yewei Liu,Xiyuan Wang,Yansheng Mao,Yoav Gelbery,Haggai Maron,Muhan Zhang*

Main category: cs.CL

TL;DR: SHINE 是一种可扩展的超网络，它通过重用冻结的 LLM 参数，并结合架构创新，能够将各种有意义的上下文映射到高质量的 LoRA 适配器，从而在一次前向传播中使 LLM 能够处理上下文相关问题。


<details>
  <summary>Details</summary>
Motivation: 现有超网络在处理多样化上下文和保持参数效率方面存在局限性，研究者希望开发一种更强大、更具扩展性的方法来将上下文知识注入 LLM。

Method: 提出了一种名为 SHINE 的可扩展超网络，采用“in-context hypernetwork”设计，重用冻结的 LLM 参数，并引入架构创新。通过预训练和指令微调管道来训练超网络，使其能够根据上下文生成 LoRA 适配器。

Result: SHINE 在多种任务上取得了优异的性能，能够快速生成 LoRA 适配器，并使 LLM 能够处理复杂的上下文相关问题，而无需直接访问上下文。与 SFT 方法相比，显著节省了时间、计算和内存成本。

Conclusion: SHINE 是一种高效且可扩展的超网络方法，能够有效地将上下文知识转化为 LLM 的参数知识，为 LLM 的自适应学习提供了新的潜力，并能显著降低适应成本。

Abstract: We propose SHINE (Scalable Hyper In-context NEtwork), a scalable hypernetwork that can map diverse meaningful contexts into high-quality LoRA adapters for large language models (LLM). By reusing the frozen LLM's own parameters in an in-context hypernetwork design and introducing architectural innovations, SHINE overcomes key limitations of prior hypernetworks and achieves strong expressive power with a relatively small number of parameters. We introduce a pretraining and instruction fine-tuning pipeline, and train our hypernetwork to generate high quality LoRA adapters from diverse meaningful contexts in a single forward pass. It updates LLM parameters without any fine-tuning, and immediately enables complex question answering tasks related to the context without directly accessing the context, effectively transforming in-context knowledge to in-parameter knowledge in one pass. Our work achieves outstanding results on various tasks, greatly saves time, computation and memory costs compared to SFT-based LLM adaptation, and shows great potential for scaling. Our code is available at https://github.com/Yewei-Liu/SHINE

</details>


### [127] [Cost-Aware Model Selection for Text Classification: Multi-Objective Trade-offs Between Fine-Tuned Encoders and LLM Prompting in Production](https://arxiv.org/abs/2602.06370)
*Alberto Andres Valdes Gonzalez*

Main category: cs.CL

TL;DR: 该研究比较了用于文本分类的两种方法：基于提示的大型语言模型（LLMs）和完全微调的编码器模型（如BERT）。研究发现，微调的编码器模型在预测性能、推理延迟和成本方面通常优于LLMs，并建议LLMs更适合混合架构，而不是直接用于标准文本分类任务。


<details>
  <summary>Details</summary>
Motivation: 现有研究在选择文本分类模型时，往往只关注预测性能，而忽视了实际生产环境中模型部署的操作约束（如延迟和成本）。本研究旨在系统地比较两种主流文本分类方法，并考虑这些操作约束。

Method: 研究人员比较了两种文本分类范式：零样本/少样本提示LLMs和完全微调的编码器模型。他们在四个经典基准数据集（IMDB、SST-2、AG News、DBPedia）上评估了模型的预测质量（宏F1）、推理延迟和经济成本。他们将模型评估视为一个多目标决策问题，并利用帕累托前沿投影和参数化效用函数来分析不同部署场景下的权衡。

Result: 研究结果表明，基于BERT家族的微调编码器模型在分类性能上具有竞争力，甚至常常优于零样本/少样本LLM提示。同时，这些微调模型在成本和延迟方面比LLMs低一到两个数量级。

Conclusion: 对于标准文本分类工作负载，不加区分地使用LLMs可能导致次优的系统级结果。研究建议，微调编码器模型是结构化NLP管道中更高效、更可靠的选择，而LLMs更适合作为混合架构的补充部分。研究团队公开了所有代码、数据集和评估协议，以支持可复现性和成本感知的NLP系统设计。

Abstract: Large language models (LLMs) such as GPT-4o and Claude Sonnet 4.5 have demonstrated strong capabilities in open-ended reasoning and generative language tasks, leading to their widespread adoption across a broad range of NLP applications. However, for structured text classification problems with fixed label spaces, model selection is often driven by predictive performance alone, overlooking operational constraints encountered in production systems.
  In this work, we present a systematic comparison of two contrasting paradigms for text classification: zero- and few-shot prompt-based large language models, and fully fine-tuned encoder-only architectures. We evaluate these approaches across four canonical benchmarks (IMDB, SST-2, AG News, and DBPedia), measuring predictive quality (macro F1), inference latency, and monetary cost.
  We frame model evaluation as a multi-objective decision problem and analyze trade-offs using Pareto frontier projections and a parameterized utility function reflecting different deployment regimes. Our results show that fine-tuned encoder-based models from the BERT family achieve competitive, and often superior, classification performance while operating at one to two orders of magnitude lower cost and latency compared to zero- and few-shot LLM prompting.
  Overall, our findings suggest that indiscriminate use of large language models for standard text classification workloads can lead to suboptimal system-level outcomes. Instead, fine-tuned encoders emerge as robust and efficient components for structured NLP pipelines, while LLMs are better positioned as complementary elements within hybrid architectures. We release all code, datasets, and evaluation protocols to support reproducibility and cost-aware NLP system design.

</details>


### [128] [ReBeCA: Unveiling Interpretable Behavior Hierarchy behind the Iterative Self-Reflection of Language Models with Causal Analysis](https://arxiv.org/abs/2602.06373)
*Tianqiang Yan,Sihan Shang,Yuheng Li,Song Qiu,Hao Peng,Wenjian Luo,Jue Xie,Lizhen Qu,Yuan Gao*

Main category: cs.CL

TL;DR: 本文提出了一种名为 ReBeCA 的新框架，通过因果分析揭示了语言模型自我反思的内在行为机制，发现自我反思的效果受到语义行为分层影响，且并非越多越好，并验证了其在不同任务和分布外的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有对语言模型自我反思的研究主要基于相关性分析，缺乏对内在机制的深入理解，且结果难以泛化。作者希望通过因果分析来揭示自我反思结果的真实决定因素。

Method: 作者提出了 ReBeCA 框架，利用因果图模型化自我反思的轨迹，并通过三阶段的 Invariant Causal Prediction (ICP) 流水线来识别真实的性能决定因素。此外，还进行了干预研究以验证因果关系。

Result: 1. 语义行为对自我反思结果具有分层影响（直接或间接）。2. 只有少数语义行为是自我反思效果可泛化的真正原因。3. 即使是直接的因果因素，看似积极的语义行为的组合也可能损害自我反思的有效性。ICP 方法在不同任务中实现了高达 49.6% 的结构似然性提升，并在分布外验证中展现了鲁棒性。

Conclusion: ReBeCA 提供了一种严谨的方法来区分自我反思动态中的真正因果机制与虚假关联，揭示了自我反思效果的复杂性，并强调了因果分析在理解和改进语言模型行为中的重要性。

Abstract: While self-reflection can enhance language model reliability, its underlying mechanisms remain opaque, with existing analyses often yielding correlation-based insights that fail to generalize. To address this, we introduce \textbf{\texttt{ReBeCA}} (self-\textbf{\texttt{Re}}flection \textbf{\texttt{Be}}havior explained through \textbf{\texttt{C}}ausal \textbf{\texttt{A}}nalysis), a framework that unveils the interpretable behavioral hierarchy governing the self-reflection outcome. By modeling self-reflection trajectories as causal graphs, ReBeCA isolates genuine determinants of performance through a three-stage Invariant Causal Prediction (ICP) pipeline. We establish three critical findings: (1) \textbf{Behavioral hierarchy:} Semantic behaviors of the model influence final self-reflection results hierarchically: directly or indirectly; (2) \textbf{Causation matters:} Generalizability in self-reflection effects is limited to just a few semantic behaviors; (3) \textbf{More $\mathbf{\neq}$ better:} The confluence of seemingly positive semantic behaviors, even among direct causal factors, can impair the efficacy of self-reflection. ICP-based verification identifies sparse causal parents achieving up to $49.6\%$ structural likelihood gains, stable across tasks where correlation-based patterns fail. Intervention studies on novel datasets confirm these causal relationships hold out-of-distribution ($p = .013, η^2_\mathrm{p} = .071$). ReBeCA thus provides a rigorous methodology for disentangling genuine causal mechanisms from spurious associations in self-reflection dynamics.

</details>


### [129] [FMBench: Adaptive Large Language Model Output Formatting](https://arxiv.org/abs/2602.06384)
*Yaoting Wang,Yun Zhou,Henghui Ding*

Main category: cs.CL

TL;DR: 该论文提出了FMBench基准测试，用于评估大型语言模型在Markdown格式生成方面的鲁棒性，并提出了一种结合SFT和RL的轻量级对齐方法，以提高Markdown格式的合规性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在生成满足语义意图和格式约束的输出方面存在挑战，特别是在Markdown格式方面，容易出现难以检测的错误，影响下游可用性。因此，需要一个能够评估模型在复杂Markdown格式指令遵循能力方面的基准测试，并提出相应的改进方法。

Method: 本文提出了FMBench基准测试，该测试涵盖了多种指令遵循场景和多样的结构化要求，强调了多层级组织、混合内容以及对用户指定布局的严格遵守。同时，提出了一种轻量级的对齐流水线，结合了监督微调（SFT）和强化学习（RL）微调，以在不依赖硬解码约束的情况下改进Markdown合规性。流水线首先对指令-响应对进行SFT，然后优化一个平衡语义保真度和结构正确性的复合目标。

Result: 实验表明，SFT能够持续提高语义对齐能力。而RL在从强大的SFT策略初始化时，能够进一步提高模型对复杂Markdown指令的鲁棒性。研究还揭示了语义和结构目标之间存在的固有权衡，强调了精心设计的奖励函数对于可靠格式生成的重要性。

Conclusion: FMBench是一个有效的评估模型Markdown格式生成能力的基准测试。提出的SFT+RL对齐流水线能够有效提升模型的Markdown格式遵循能力。研究结果为理解和优化格式化生成中的语义与结构之间的权衡提供了见解。

Abstract: Producing outputs that satisfy both semantic intent and format constraints is essential for deploying large language models in user-facing and system-integrated workflows. In this work, we focus on Markdown formatting, which is ubiquitous in assistants, documentation, and tool-augmented pipelines but still prone to subtle, hard-to-detect errors (e.g., broken lists, malformed tables, inconsistent headings, and invalid code blocks) that can significantly degrade downstream usability. We present FMBench, a benchmark for adaptive Markdown output formatting that evaluates models under a wide range of instruction-following scenarios with diverse structural requirements. FMBench emphasizes real-world formatting behaviors such as multi-level organization, mixed content (natural language interleaved with lists/tables/code), and strict adherence to user-specified layout constraints. To improve Markdown compliance without relying on hard decoding constraints, we propose a lightweight alignment pipeline that combines supervised fine-tuning (SFT) with reinforcement learning fine-tuning. Starting from a base model, we first perform SFT on instruction-response pairs, and then optimize a composite objective that balances semantic fidelity with structural correctness. Experiments on two model families (OpenPangu and Qwen) show that SFT consistently improves semantic alignment, while reinforcement learning provides additional gains in robustness to challenging Markdown instructions when initialized from a strong SFT policy. Our results also reveal an inherent trade-off between semantic and structural objectives, highlighting the importance of carefully designed rewards for reliable formatted generation. Code is available at: https://github.com/FudanCVL/FMBench.

</details>


### [130] [Stopping Computation for Converged Tokens in Masked Diffusion-LM Decoding](https://arxiv.org/abs/2602.06412)
*Daisuke Oba,Danushka Bollegala,Masahiro Kaneko,Naoaki Okazaki*

Main category: cs.CL

TL;DR: SureLock 是一种加速掩码扩散语言模型（MDLM）的方法，通过在生成过程中稳定后验概率的未掩码 token 位置进行“锁定”，从而显著减少计算量，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的掩码扩散语言模型在每一步迭代中都会重新计算所有 token 位置的注意力机制和前馈网络，即使许多未掩码 token 的状态已经稳定，导致了大量的计算浪费。

Method: SureLock 提出了一种“锁定”机制。当一个未掩码 token 位置的后验概率在多步迭代中趋于稳定时，就将其锁定，跳过其查询投影和前馈子层，并缓存其键值（key-value），以便其他位置继续进行注意力计算。理论上，通过监控锁定步的局部 KL 散度即可约束最终 token 概率的偏差。

Result: 在 LLaDA-8B 模型上，SureLock 将算法 FLOPs 减少了 30% 到 50%，同时生成的质量与未采用锁定机制的基线模型相当。

Conclusion: SureLock 是一种有效且理论上可行的加速 MDLM 的方法，通过选择性地锁定已稳定的 token 位置，显著降低了计算成本，而不会牺牲生成质量。

Abstract: Masked Diffusion Language Models generate sequences via iterative sampling that progressively unmasks tokens. However, they still recompute the attention and feed-forward blocks for every token position at every step -- even when many unmasked tokens are essentially fixed, resulting in substantial waste in compute. We propose SureLock: when the posterior at an unmasked position has stabilized across steps (our sure condition), we lock that position -- thereafter skipping its query projection and feed-forward sublayers -- while caching its attention keys and values so other positions can continue to attend to it. This reduces the dominant per-iteration computational cost from $O(N^2d)$ to $O(MNd)$ where $N$ is the sequence length, $M$ is the number of unlocked token positions, and $d$ is the model dimension. In practice, $M$ decreases as the iteration progresses, yielding substantial savings. On LLaDA-8B, SureLock reduces algorithmic FLOPs by 30--50% relative to the same sampler without locking, while maintaining comparable generation quality. We also provide a theoretical analysis to justify the design rationale of SureLock: monitoring only the local KL at the lock step suffices to bound the deviation in final token probabilities. Our code will be available at https://daioba.github.io/surelock .

</details>


### [131] [Investigating the structure of emotions by analyzing similarity and association of emotion words](https://arxiv.org/abs/2602.06430)
*Fumitaka Iwaki,Tatsuji Takahashi*

Main category: cs.CL

TL;DR: 该研究通过构建和分析情绪词的语义网络，来检验Plutchik情绪轮的有效性。结果表明，语义网络的结构与情绪轮在大部分程度上相似，但在局部存在差异。


<details>
  <summary>Details</summary>
Motivation: 现有关于Plutchik情绪轮在情感分析中的应用，但对其有效性的检验不足。

Method: 研究者收集了情绪词对的相似度和关联度数据，构建了语义网络。然后，使用社区检测方法分析网络结构，并与Plutchik情绪轮进行比较。

Result: 所构建的语义网络的结构在大部分与Plutchik情绪轮相似，但在局部存在差异。

Conclusion: Plutchik情绪轮在表示情绪关系方面具有一定有效性，但其结构可能无法完全捕捉人类情绪的复杂性和细微差别。

Abstract: In the field of natural language processing, some studies have attempted sentiment analysis on text by handling emotions as explanatory or response variables. One of the most popular emotion models used in this context is the wheel of emotion proposed by Plutchik. This model schematizes human emotions in a circular structure, and represents them in two or three dimensions. However, the validity of Plutchik's wheel of emotion has not been sufficiently examined. This study investigated the validity of the wheel by creating and analyzing a semantic networks of emotion words. Through our experiments, we collected data of similarity and association of ordered pairs of emotion words, and constructed networks using these data. We then analyzed the structure of the networks through community detection, and compared it with that of the wheel of emotion. The results showed that each network's structure was, for the most part, similar to that of the wheel of emotion, but locally different.

</details>


### [132] [On the Wings of Imagination: Conflicting Script-based Multi-role Framework for Humor Caption Generation](https://arxiv.org/abs/2602.06423)
*Wenbo Shang,Yuxi Sun,Jing Ma,Xin Huang*

Main category: cs.CL

TL;DR: 本文提出了一种名为HOMER的新型基于LLM的多模态幽默生成机制，它结合了幽默理论（GTVH）和多角色LLM协作，旨在生成更具创意和可解释性的幽默图片描述。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM幽默生成方法（如基于推理链或自纠错）在创造力和可解释性方面存在局限，特别是在多模态场景下（如图片配字幕）更具挑战性，需要视觉理解、幽默推理和创意想象。

Method: 研究引入了名为HOMER的框架，它包含三个基于LLM的角色：（1）冲突脚本提取器，识别幽默的基础（脚本对立）；（2）检索增强型分层想象器，通过联想扩展幽默目标（想象树）；（3）字幕生成器，根据提取的知识生成幽默字幕。该框架结合了幽默理论GTVH和幽默检索。

Result: 在New Yorker Cartoon数据集上的实验表明，HOMER在多模态幽默配字幕任务上优于现有最先进的方法和强大的LLM推理策略。

Conclusion: HOMER通过结合幽默理论、多角色LLM协作和检索机制，有效克服了现有方法的局限，能够生成更有趣、更多样化且更具可解释性的多模态幽默内容。

Abstract: Humor is a commonly used and intricate human language in daily life. Humor generation, especially in multi-modal scenarios, is a challenging task for large language models (LLMs), which is typically as funny caption generation for images, requiring visual understanding, humor reasoning, creative imagination, and so on. Existing LLM-based approaches rely on reasoning chains or self-improvement, which suffer from limited creativity and interpretability. To address these bottlenecks, we develop a novel LLM-based humor generation mechanism based on a fundamental humor theory, GTVH. To produce funny and script-opposite captions, we introduce a humor-theory-driven multi-role LLM collaboration framework augmented with humor retrieval (HOMER). The framework consists of three LLM-based roles: (1) conflicting-script extractor that grounds humor in key script oppositions, forming the basis of caption generation; (2) retrieval-augmented hierarchical imaginator that identifies key humor targets and expands the creative space of them through diverse associations structured as imagination trees; and (3) caption generator that produces funny and diverse captions conditioned on the obtained knowledge. Extensive experiments on two New Yorker Cartoon benchmarking datasets show that HOMER outperforms state-of-the-art baselines and powerful LLM reasoning strategies on multi-modal humor captioning.

</details>


### [133] [TrailBlazer: History-Guided Reinforcement Learning for Black-Box LLM Jailbreaking](https://arxiv.org/abs/2602.06440)
*Sung-Hoon Yoon,Ruizhi Qian,Minda Zhao,Weiyue Li,Mengyu Wang*

Main category: cs.CL

TL;DR: 提出了一种历史感知的基于强化学习的越狱框架，通过分析和重新加权历史交互中的漏洞信号来提高LLM越狱的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有越狱研究未能有效利用早期交互轮次中暴露的漏洞，导致攻击效率低下且不稳定。强化学习非常适合处理这种受先前交互影响的顺序交互问题。

Method: 开发了一个历史感知的基于强化学习的越狱框架，该框架分析并重新加权先前步骤中的漏洞信号以指导未来的决策。引入了一种基于注意力机制的重新加权方法，以突出交互历史中的关键漏洞。

Result: 与现有方法相比，该框架显著提高了越狱成功率，并大大提高了查询效率。在AdvBench和HarmBench上的实验证明了其最先进的性能。

Conclusion: 历史漏洞信号在基于强化学习的越狱策略中至关重要，并且为推进LLM安全防护的对抗性研究提供了一条有原则的途径。

Abstract: Large Language Models (LLMs) have become integral to many domains, making their safety a critical priority. Prior jailbreaking research has explored diverse approaches, including prompt optimization, automated red teaming, obfuscation, and reinforcement learning (RL) based methods. However, most existing techniques fail to effectively leverage vulnerabilities revealed in earlier interaction turns, resulting in inefficient and unstable attacks. Since jailbreaking involves sequential interactions in which each response influences future actions, reinforcement learning provides a natural framework for this problem. Motivated by this, we propose a history-aware RL-based jailbreak framework that analyzes and reweights vulnerability signals from prior steps to guide future decisions. We show that incorporating historical information alone improves jailbreak success rates. Building on this insight, we introduce an attention-based reweighting mechanism that highlights critical vulnerabilities within the interaction history, enabling more efficient exploration with fewer queries. Extensive experiments on AdvBench and HarmBench demonstrate that our method achieves state-of-the-art jailbreak performance while significantly improving query efficiency. These results underscore the importance of historical vulnerability signals in reinforcement learning-driven jailbreak strategies and offer a principled pathway for advancing adversarial research on LLM safeguards.

</details>


### [134] [CORE: Comprehensive Ontological Relation Evaluation for Large Language Models](https://arxiv.org/abs/2602.06446)
*Satyam Dwivedi,Sanjukta Ghosh,Shivam Dwivedi,Nishi Kumari,Anil Thakur,Anurag Purushottam,Deepak Alok,Praveen Gatla,Manjuprasad B,Bipasha Patgiri*

Main category: cs.CL

TL;DR: 本文提出 CORE 数据集用于评估大型语言模型（LLM）区分语义关系和无关性的能力，发现现有 LLM 在识别无关性方面存在严重缺陷，尽管置信度很高，并且在特定领域表现更差。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 评估很少关注其区分有意义的语义关系和真正的无关性对偶的能力，而 LLM 在此方面表现不佳可能带来安全风险。

Method: 创建 CORE 数据集，包含 225K 道选择题和 203 道经过验证的开放式问题，覆盖 74 个学科和 24 种语义关系类型。招募了 1000 多名参与者作为人类基线，并对 29 个最先进的 LLM 进行了评估。

Result: 人类基线准确率达到 92.6%，LLM 整体准确率在 48.25-70.9% 之间。LLM 在识别相关对方面表现良好（86.5-100%），但在识别无关对方面表现严重下降（0-41.35%），且置信度相似。在 CORE 225K 数据集上，LLM 准确率仅为 2% 左右。LLM 存在 37.6% 的平均语义崩溃率，表明它们会系统性地生成虚假关系。

Conclusion: 无关性推理是 LLM 评估和安全领域一个关键但被低估的研究方向。现有 LLM 在识别无关性方面存在根本性缺陷，尤其是在特定领域，这对其可靠性和安全性构成了重大挑战。

Abstract: Large Language Models (LLMs) perform well on many reasoning benchmarks, yet existing evaluations rarely assess their ability to distinguish between meaningful semantic relations and genuine unrelatedness. We introduce CORE (Comprehensive Ontological Relation Evaluation), a dataset of 225K multiple-choice questions spanning 74 disciplines, together with a general-domain open-source benchmark of 203 rigorously validated questions (Cohen's Kappa = 1.0) covering 24 semantic relation types with equal representation of unrelated pairs. A human baseline from 1,000+ participants achieves 92.6% accuracy (95.1% on unrelated pairs). In contrast, 29 state-of-the-art LLMs achieve 48.25-70.9% overall accuracy, with near-ceiling performance on related pairs (86.5-100%) but severe degradation on unrelated pairs (0-41.35%), despite assigning similar confidence (92-94%). Expected Calibration Error increases 2-4x on unrelated pairs, and a mean semantic collapse rate of 37.6% indicates systematic generation of spurious relations. On the CORE 225K MCQs dataset, accuracy further drops to approximately 2%, highlighting substantial challenges in domain-specific semantic reasoning. We identify unrelatedness reasoning as a critical, under-evaluated frontier for LLM evaluation and safety.

</details>


### [135] [Evaluating an evidence-guided reinforcement learning framework in aligning light-parameter large language models with decision-making cognition in psychiatric clinical reasoning](https://arxiv.org/abs/2602.06449)
*Xinxin Lin,Guangxin Dai,Yi Zhong,Xiang Li,Xue Xiao,Yixin Zhang,Zhengdong Wu,Yongbo Zheng,Runchuan Zhu,Ming Zhao,Huizi Yu,Shuo Wu,Jun Zhao,Lingming Hu,Yumei Wang,Ping Yin,Joey W. Y. Chan,Ngan Yin Chan,Sijing Chen,Yun Kwok Wing,Lin Lu,Xin Ma,Lizhou Fan*

Main category: cs.CL

TL;DR: 研究提出了一种名为ClinMPO的强化学习框架，通过医学证据指导LLM的推理过程，成功提升了轻量级LLM在精神病学诊断任务上的表现，甚至超越了医学学生的平均水平。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在精神病学领域的应用受到幻觉和浅层推理的限制，尤其是在需要保护隐私和高效部署的轻量级LLM中。现有的训练方法侧重于语言流畅性而非结构化临床逻辑，与专业诊断认知不符。

Method: 提出ClinMPO框架，采用基于强化学习的方法，通过一个独立的奖励模型来对齐LLMs的内部推理与专业精神病学实践。奖励模型基于4474篇精神病学期刊文章，并按照循证医学原则进行结构化。在隔离推理能力而非死记硬背的测试集上评估了ClinMPO。

Result: 经过ClinMPO优化的Qwen3-8B轻量级LLM模型，在复杂精神病学诊断任务上的准确率为31.4%，超过了300名医学学生的平均准确率30.8%。

Conclusion: 基于医学证据的优化方法能够使轻量级LLM掌握复杂的推理任务，为实现可靠且安全的精神病学决策支持提供了可扩展的途径。

Abstract: Large language models (LLMs) hold transformative potential for medical decision support yet their application in psychiatry remains constrained by hallucinations and superficial reasoning. This limitation is particularly acute in light-parameter LLMs which are essential for privacy-preserving and efficient clinical deployment. Existing training paradigms prioritize linguistic fluency over structured clinical logic and result in a fundamental misalignment with professional diagnostic cognition. Here we introduce ClinMPO, a reinforcement learning framework designed to align the internal reasoning of LLMs with professional psychiatric practice. The framework employs a specialized reward model trained independently on a dataset derived from 4,474 psychiatry journal articles and structured according to evidence-based medicine principles. We evaluated ClinMPO on a unseen subset of the benchmark designed to isolate reasoning capabilities from rote memorization. This test set comprises items where leading large-parameter LLMs consistently fail. We compared the ClinMPO-aligned light LLM performance against a cohort of 300 medical students. The ClinMPO-tuned Qwen3-8B model achieved a diagnostic accuracy of 31.4% and surpassed the human benchmark of 30.8% on these complex cases. These results demonstrate that medical evidence-guided optimization enables light-parameter LLMs to master complex reasoning tasks. Our findings suggest that explicit cognitive alignment offers a scalable pathway to reliable and safe psychiatric decision support.

</details>


### [136] [RelayGen: Intra-Generation Model Switching for Efficient Reasoning](https://arxiv.org/abs/2602.06454)
*Jiwon Song,Yoongon Kim,Jae-Joon Kim*

Main category: cs.CL

TL;DR: RelayGen 是一种训练免费、片段级别运行时模型切换框架，通过识别长篇推理中的难度变化，将低难度部分委托给更小的模型，从而在保持准确性的同时显著降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在处理复杂推理任务时推理成本高昂，现有提高效率的方法未能有效处理单个输出内部的生成难度变化。

Method: 通过离线分析生成不确定性（使用 token 概率边距）来识别片段级别的难度转换。RelayGen 找出模型特定的切换信号，将低难度部分的推理任务动态地分配给更小的模型，而将高难度推理保留给大模型。该方法无需额外训练或学习型路由组件。

Result: 在多个推理基准测试中，RelayGen 显著降低了推理延迟，同时保留了大型模型的绝大部分准确性。与投机解码结合使用时，RelayGen 可实现高达 2.2 倍的端到端加速，准确率下降不到 2%。

Conclusion: RelayGen 是一种有效的训练免费框架，能够通过动态地将推理任务分配给不同大小的模型来提高大型推理模型的推理效率，同时保持较高的准确性。

Abstract: Large reasoning models (LRMs) achieve strong performance on complex reasoning tasks by generating long, multi-step reasoning trajectories, but inference-time scaling incurs substantial deployment cost. A key challenge is that generation difficulty varies within a single output, whereas existing efficiency-oriented approaches either ignore this intra-generation variation or rely on supervised token-level routing with high system complexity. We present \textbf{RelayGen}, a training-free, segment-level runtime model switching framework that exploits difficulty variation in long-form reasoning. Through offline analysis of generation uncertainty using token probability margins, we show that coarse-grained segment-level control is sufficient to capture difficulty transitions within a reasoning trajectory. RelayGen identifies model-specific switch cues that signal transitions to lower-difficulty segments and dynamically delegates their continuation to a smaller model, while preserving high-difficulty reasoning on the large model. Across multiple reasoning benchmarks, RelayGen substantially reduces inference latency while preserving most of the accuracy of large models. When combined with speculative decoding, RelayGen achieves up to 2.2$\times$ end-to-end speedup with less than 2\% accuracy degradation, without requiring additional training or learned routing components.

</details>


### [137] [Diffusion-State Policy Optimization for Masked Diffusion Language Models](https://arxiv.org/abs/2602.06462)
*Daisuke Oba,Hiroki Furuta,Naoaki Okazaki*

Main category: cs.CL

TL;DR: 本文提出了一种名为DiSPO（Diffusion-State Policy Optimization）的即插即用信用分配层，用于解决掩码扩散语言模型中粗粒度的信用分配问题，通过优化中间填充决策来提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 掩码扩散语言模型在生成过程中，仅依赖最终完成结果的奖励进行学习，导致中间决策的信用分配过于粗糙，影响模型效率和性能。

Method: DiSPO在选定的中间掩码状态下，通过重采样填充当前掩码位置的token，评估由此产生的完整文本，并仅更新新填充的token。此过程无需额外的多步扩散采样。DiSPO为分支填充制定了一个固定状态目标，并推导了一个策略梯度估计器，可以与基于终端反馈的策略优化结合使用。

Result: 在LLaDA-8B-Instruct模型上，DiSPO在数学和规划基准测试中，在匹配的计算量和优化器步数下，始终优于仅基于终端反馈的diffu-GRPO基线。

Conclusion: DiSPO是一种有效的信用分配方法，可以直接优化扩散语言模型的中间填充决策，显著提升模型在复杂任务上的表现，且计算效率高。

Abstract: Masked diffusion language models generate by iteratively filling masked tokens over multiple denoising steps, so learning only from a terminal reward on the final completion yields coarse credit assignment over intermediate decisions. We propose DiSPO (Diffusion-State Policy Optimization), a plug-in credit-assignment layer that directly optimizes intermediate filling decisions. At selected intermediate masked states, DiSPO branches by resampling fillings for the currently masked positions from rollout-cached logits, scores the resulting completions, and updates only the newly filled tokens -- without additional multi-step diffusion rollouts. We formalize a fixed-state objective for branched completions and derive a policy-gradient estimator that can be combined with terminal-feedback policy optimization using the same rollouts. On LLaDA-8B-Instruct, DiSPO consistently improves over the terminal-feedback diffu-GRPO baseline on math and planning benchmarks under matched rollout compute and optimizer steps. Our code will be available at https://daioba.github.io/dispo .

</details>


### [138] [Improve Large Language Model Systems with User Logs](https://arxiv.org/abs/2602.06470)
*Changyue Wang,Weihang Su,Qingyao Ai,Yiqun Liu*

Main category: cs.CL

TL;DR: 本文提出了UNO框架，通过从用户日志中提取规则和偏好对，聚类处理异构数据，并量化模型与日志数据间的认知差距，从而改进大型语言模型系统（LLMsys），使其能自适应地过滤噪声反馈并区分主要和反射性经验，以提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的训练数据和模型参数规模的增长面临数据稀缺和计算成本升高的挑战。从现实世界的用户交互日志中学习，可以获取真实的反馈和程序性知识，但用户日志的非结构化和噪声特性使其学习过程困难，且存在离线策略优化问题。

Method: UNO框架首先将日志提炼成半结构化的规则和偏好对。然后，利用查询-反馈驱动的聚类来处理数据异构性。最后，量化模型先验知识与日志数据之间的认知差距，以此指导LLMsys自适应地过滤噪声反馈，并为从用户日志中提取的主要和反射性经验构建不同模块。

Result: UNO在大量实验中表现出最先进的效果和效率，显著优于检索增强生成（RAG）和基于记忆的基线方法。

Conclusion: UNO是一个统一的框架，能够有效地利用用户日志改进LLM系统，通过处理日志的复杂性并量化模型认知差距，从而提升模型在真实世界应用中的表现。

Abstract: Scaling training data and model parameters has long driven progress in large language models (LLMs), but this paradigm is increasingly constrained by the scarcity of high-quality data and diminishing returns from rising computational costs. As a result, recent work is increasing the focus on continual learning from real-world deployment, where user interaction logs provide a rich source of authentic human feedback and procedural knowledge. However, learning from user logs is challenging due to their unstructured and noisy nature. Vanilla LLM systems often struggle to distinguish useful feedback signals from noisy user behavior, and the disparity between user log collection and model optimization (e.g., the off-policy optimization problem) further strengthens the problem. To this end, we propose UNO (User log-driveN Optimization), a unified framework for improving LLM systems (LLMsys) with user logs. UNO first distills logs into semi-structured rules and preference pairs, then employs query-and-feedback-driven clustering to manage data heterogeneity, and finally quantifies the cognitive gap between the model's prior knowledge and the log data. This assessment guides the LLMsys to adaptively filter out noisy feedback and construct different modules for primary and reflective experiences extracted from user logs, thereby improving future responses. Extensive experiments show that UNO achieves state-of-the-art effectiveness and efficiency, significantly outperforming Retrieval Augmented Generation (RAG) and memory-based baselines. We have open-sourced our code at https://github.com/bebr2/UNO .

</details>


### [139] [Revisiting the Shape Convention of Transformer Language Models](https://arxiv.org/abs/2602.06471)
*Feng-Ting Liao,Meng-Hsi Chen,Guan-Ting Yi,Da-shan Shiu*

Main category: cs.CL

TL;DR: 本文提出了一种新的 Transformer FFN 结构（沙漏型 FFN），取代了传统的窄-宽-窄结构，并在不同模型规模下进行了实证验证，结果表明沙漏型 FFN 在参数量有限的情况下能取得更好的性能。


<details>
  <summary>Details</summary>
Motivation: 受限于传统 Transformer FFN 窄-宽-窄 MLP 结构，研究者们希望探索一种具有更优函数逼近能力的 MLP 结构，并挑战其在 Transformer 中的普遍设计。

Method: 本文提出了一种沙漏型 FFN 结构，它由多个堆叠的沙漏子 MLP 组成，并通过残差连接。研究者们还将参数预算固定，比较了沙漏型 FFN 与传统 FFN 的性能，并探索了增加注意力参数和减少 FFN 参数的组合。

Result: 在模型规模小于 400M 时，沙漏型 FFN 性能优于传统 FFN。在 1B 参数规模下，两者性能相当。在固定参数预算下，减少 FFN 参数并增加注意力参数的沙漏型 FFN 变体，性能持续优于传统配置。

Conclusion: 沙漏型 FFN 是传统窄-宽-窄 MLP 结构的一个有竞争力的替代方案，并且在参数受限的情况下，可以通过调整 FFN 和注意力参数的比例来提升模型效率和表达能力，促使研究者重新思考 MLP 结构和注意力-FFN 之间的平衡。

Abstract: Dense Transformer language models have largely adhered to one consistent architectural shape: each layer consists of an attention module followed by a feed-forward network (FFN) with a narrow-wide-narrow MLP, allocating most parameters to the MLP at expansion ratios between 2 and 4. Motivated by recent results that residual wide-narrow-wide (hourglass) MLPs offer superior function approximation capabilities, we revisit the long-standing MLP shape convention in Transformer, challenging the necessity of the narrow-wide-narrow design. To study this, we develop a Transformer variant that replaces the conventional FFN with a deeper hourglass-shaped FFN, comprising a stack of hourglass sub-MLPs connected by residual pathways. We posit that a deeper but lighter hourglass FFN can serve as a competitive alternative to the conventional FFN, and that parameters saved by using a lighter hourglass FFN can be more effectively utilized, such as by enlarging model hidden dimensions under fixed budgets. We confirm these through empirical validations across model scales: hourglass FFNs outperform conventional FFNs up to 400M and achieve comparable performance at larger scales to 1B parameters; hourglass FFN variants with reduced FFN and increased attention parameters show consistent improvements over conventional configurations at matched budgets. Together, these findings shed new light on recent work and prompt a rethinking of the narrow-wide-narrow MLP convention and the balance between attention and FFN towards efficient and expressive modern language models.

</details>


### [140] [Completing Missing Annotation: Multi-Agent Debate for Accurate and Scalable Relevant Assessment for IR Benchmarks](https://arxiv.org/abs/2602.06526)
*Minjeong Ban,Jeonghwan Choi,Hyangsuk Min,Nicole Hee-Yeon Kim,Minseok Kim,Jae-Gil Lee,Hwanjun Song*

Main category: cs.CL

TL;DR: 本研究提出DREAM框架，通过LLM代理进行多轮辩论式相关性评估，以解决信息检索（IR）基准数据集标签不全的问题。该框架通过对抗性辩论和迭代批评提高标注准确性和AI到人类的升级效率，仅用3.5%的人工参与即达到95.2%的标注准确率。在此基础上，构建了BRIDGE数据集，解决了29,824个缺失的相关片段，并重新评估了IR和RAG系统，发现未被发现的空白会扭曲排名并导致检索-生成不匹配。


<details>
  <summary>Details</summary>
Motivation: 信息检索（IR）评估面临基准数据集不完整、包含未标注相关片段的挑战。现有LLM和混合策略虽然降低了成本，但存在LLM过度自信和AI到人类升级无效的问题。

Method: 提出DREAM框架，一个基于多轮辩论的相关性评估框架，利用LLM代理，建立在初始对立立场和迭代的相互批评之上。通过基于一致性的辩论进行评估。

Result: DREAM框架在某些情况下提高了标注准确性，在不确定情况下提高了AI到人类的升级可靠性，仅需3.5%的人工参与即可达到95.2%的标注准确率。基于DREAM构建的BRIDGE数据集识别出29,824个缺失的相关片段，减少了评估偏差。重新评估IR和RAG系统表明，未解决的空白会扭曲检索器排名并导致检索-生成不匹配。

Conclusion: DREAM框架能够更准确地进行相关性标注，并更可靠地升级不确定性给人类。BRIDGE数据集的构建弥补了现有基准的不足，使得IR系统评估更公平。未被发现的空白会显著影响IR和RAG系统的性能评估和匹配度。

Abstract: Information retrieval (IR) evaluation remains challenging due to incomplete IR benchmark datasets that contain unlabeled relevant chunks. While LLMs and LLM-human hybrid strategies reduce costly human effort, they remain prone to LLM overconfidence and ineffective AI-to-human escalation. To address this, we propose DREAM, a multi-round debate-based relevance assessment framework with LLM agents, built on opposing initial stances and iterative reciprocal critique. Through our agreement-based debate, it yields more accurate labeling for certain cases and more reliable AI-to-human escalation for uncertain ones, achieving 95.2% labeling accuracy with only 3.5% human involvement. Using DREAM, we build BRIDGE, a refined benchmark that mitigates evaluation bias and enables fairer retriever comparison by uncovering 29,824 missing relevant chunks. We then re-benchmark IR systems and extend evaluation to RAG, showing that unaddressed holes not only distort retriever rankings but also drive retrieval-generation misalignment. The relevance assessment framework is available at https: //github.com/DISL-Lab/DREAM-ICLR-26; and the BRIDGE dataset is available at https://github.com/DISL-Lab/BRIDGE-Benchmark.

</details>


### [141] [MTQE.en-he: Machine Translation Quality Estimation for English-Hebrew](https://arxiv.org/abs/2602.06546)
*Andy Rosenbaum,Assaf Siani,Ilan Kernerman*

Main category: cs.CL

TL;DR: 本文发布了MTQE.en-he，一个用于机器翻译质量评估的英汉双语基准测试集，并评估了ChatGPT、TransQuest和CometKiwi等模型在该基准上的表现。研究发现模型集成优于单一模型，参数高效的微调方法能稳定提升性能。


<details>
  <summary>Details</summary>
Motivation: 为了填补机器翻译质量评估领域在英汉语言对上的公开可用基准测试集的空白，以促进对该资源匮乏语言对的研究。

Method: 构建了一个包含959个英文原文-希伯来文机器翻译对及其人工评分的MTQE.en-he基准。评估了ChatGPT、TransQuest和CometKiwi三种模型的性能，并尝试了全模型微调和参数高效微调（LoRA、BitFit、FTHead）方法。

Result: 模型集成（ChatGPT、TransQuest、CometKiwi）比最佳单一模型（CometKiwi）在Pearson相关系数上提升6.4个百分点，在Spearman相关系数上提升5.6个百分点。参数高效的微调方法（LoRA、BitFit、FTHead）在微调TransQuest和CometKiwi时，训练稳定且性能提升2-3个百分点，而全模型微调则容易过拟合和分布崩溃。

Conclusion: MTQE.en-he基准测试集为英汉机器翻译质量评估研究提供了基础。参数高效的微调方法是应对该任务中数据稀疏和模型过拟合问题的有效途径。

Abstract: We release MTQE.en-he: to our knowledge, the first publicly available English-Hebrew benchmark for Machine Translation Quality Estimation. MTQE.en-he contains 959 English segments from WMT24++, each paired with a machine translation into Hebrew, and Direct Assessment scores of the translation quality annotated by three human experts. We benchmark ChatGPT prompting, TransQuest, and CometKiwi and show that ensembling the three models outperforms the best single model (CometKiwi) by 6.4 percentage points Pearson and 5.6 percentage points Spearman. Fine-tuning experiments with TransQuest and CometKiwi reveal that full-model updates are sensitive to overfitting and distribution collapse, yet parameter-efficient methods (LoRA, BitFit, and FTHead, i.e., fine-tuning only the classification head) train stably and yield improvements of 2-3 percentage points. MTQE.en-he and our experimental results enable future research on this under-resourced language pair.

</details>


### [142] [Baichuan-M3: Modeling Clinical Inquiry for Reliable Medical Decision-Making](https://arxiv.org/abs/2602.06570)
*Baichuan-M3 Team,:,Chengfeng Dou,Fan Yang,Fei Li,Jiyuan Jia,Qiang Ju,Shuai Wang,Tianpeng Li,Xiangrong Zeng,Yijie Zhou,Hongda Zhang,Jinyang Tai,Linzhuang Sun,Peidong Guo,Yichuan Mo,Xiaochuan Wang,Hengfu Cui,Zhishou Zhang*

Main category: cs.CL

TL;DR: Baichuan-M3是一个经过医学增强的大型语言模型，旨在提供临床级的决策支持，超越传统的问答模式。它通过专门的训练流程模拟医生的工作流程，具备主动信息获取、长远推理和自适应幻觉抑制能力，并在多个医学基准测试中取得优于GPT-5.2的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在开放式医疗咨询中存在局限性，无法像医生一样进行主动的信息获取、整合证据进行推理，并确保事实的可靠性。研究者希望开发一个能提供临床级决策支持的模型。

Method: Baichuan-M3采用了专门的训练流程，模拟医生的系统性工作流程。其关键能力包括：1) 主动信息获取以消除歧义；2) 长远推理以整合零散证据并形成连贯诊断；3) 自适应幻觉抑制以确保事实可靠性。

Result: 在HealthBench、HealthBench-Hallu和ScanBench等多个基准测试中，Baichuan-M3均取得了最先进的性能。在临床问询、咨询和安全性方面，其表现显著优于GPT-5.2。

Conclusion: Baichuan-M3成功地将大型语言模型的能力从被动问答提升到主动、临床级别的决策支持，并在医学领域的多个评估中展现出优越性。

Abstract: We introduce Baichuan-M3, a medical-enhanced large language model engineered to shift the paradigm from passive question-answering to active, clinical-grade decision support. Addressing the limitations of existing systems in open-ended consultations, Baichuan-M3 utilizes a specialized training pipeline to model the systematic workflow of a physician. Key capabilities include: (i) proactive information acquisition to resolve ambiguity; (ii) long-horizon reasoning that unifies scattered evidence into coherent diagnoses; and (iii) adaptive hallucination suppression to ensure factual reliability. Empirical evaluations demonstrate that Baichuan-M3 achieves state-of-the-art results on HealthBench, the newly introduced HealthBench-Hallu and ScanBench, significantly outperforming GPT-5.2 in clinical inquiry, advisory and safety. The models are publicly available at https://huggingface.co/collections/baichuan-inc/baichuan-m3.

</details>


### [143] [Inference-Time Rethinking with Latent Thought Vectors for Math Reasoning](https://arxiv.org/abs/2602.06584)
*Deqian Kong,Minglu Zhao,Aoyang Qin,Bo Pang,Chenxin Tao,David Hartmann,Edouardo Honig,Dehong Xu,Amit Kumar,Matt Sarte,Chuan Li,Jianwen Xie,Ying Nian Wu*

Main category: cs.CL

TL;DR: 提出了一种名为“推理时反思”的生成框架，通过解耦声明式潜在思维向量和程序化生成，实现了迭代式自我纠错，从而提高数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思考推理方法在生成过程中容易出错且无法纠正，本文旨在通过引入一种可迭代自我纠错的机制来克服这一限制。

Method: 将推理过程分解为连续的潜在思维向量（思考什么）和条件化该向量的解码器（如何思考）。在测试时，通过交替生成候选推理过程并优化潜在向量来改进推理策略。

Result: 在GSM8K数据集上，一个0.2B参数的模型经过30次反思迭代后，性能优于参数量10至15倍的基线模型，包括一个3B参数的模型。

Conclusion: 有效的数学推理可以通过复杂的推理时计算来实现，而非仅仅依赖于巨大的模型参数量。

Abstract: Standard chain-of-thought reasoning generates a solution in a single forward pass, committing irrevocably to each token and lacking a mechanism to recover from early errors. We introduce Inference-Time Rethinking, a generative framework that enables iterative self-correction by decoupling declarative latent thought vectors from procedural generation. We factorize reasoning into a continuous latent thought vector (what to reason about) and a decoder that verbalizes the trace conditioned on this vector (how to reason). Beyond serving as a declarative buffer, latent thought vectors compress the reasoning structure into a continuous representation that abstracts away surface-level token variability, making gradient-based optimization over reasoning strategies well-posed. Our prior model maps unstructured noise to a learned manifold of valid reasoning patterns, and at test time we employ a Gibbs-style procedure that alternates between generating a candidate trace and optimizing the latent vector to better explain that trace, effectively navigating the latent manifold to refine the reasoning strategy. Training a 0.2B-parameter model from scratch on GSM8K, our method with 30 rethinking iterations surpasses baselines with 10 to 15 times more parameters, including a 3B counterpart. This result demonstrates that effective mathematical reasoning can emerge from sophisticated inference-time computation rather than solely from massive parameter counts.

</details>


### [144] [Echoes as Anchors: Probabilistic Costs and Attention Refocusing in LLM Reasoning](https://arxiv.org/abs/2602.06600)
*Zhuoyuan Hao,Zhuo Li,Wu Li,Fangming Liu,Min Zhang,Jing Li*

Main category: cs.CL

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Test-time compute allocation in large reasoning models (LRMs) is widely used and has applications in mathematical problem solving, code synthesis, and planning. Recent work has addressed this problem by scaling self-consistency and parallel thinking, adding generic ``thinking tokens'' and prompting models to re-read the question before answering. Unfortunately, these approaches either inject task-agnostic tokens or mandate heuristics that do not explain -- and often ignore -- the \emph{spontaneous} repetition that many LRMs exhibit at the head of their internal chains. In contrast, we analyze and harness the model's tendency to restate the question, which we term the \emph{Echo of Prompt (EOP)}, as a front-loaded, compute-shaping mechanism. We formalize its probabilistic cost by casting echo removal as rejection-based conditioning and defining the \emph{Echo Likelihood Gap} $Δ\mathcal{L}$ as a computable proxy. This provides the missing theoretical link that links early repetition to likelihood gains and downstream accuracy. However, it does not by itself specify how to exploit EOP. Consequently, we develop \emph{Echo-Distilled SFT (ED-SFT)} to instill an ``echo-then-reason'' pattern through supervised finetuning, and \emph{Echoic Prompting (EP)} to re-ground the model mid-trace without training. While promising, quantifying benefits beyond verbosity is non-trivial. Therefore, we conduct length and suffix-controlled likelihood analyses together with layer-wise attention studies, showing that EOP increases answer to answer-prefix attention in middle layers, consistent with an \emph{attention refocusing} mechanism. We evaluate on GSM8K, MathQA, Hendrycks-MATH, AIME24, and MATH-500 under identical decoding settings and budgets, and find consistent gains over baselines. Code is available at https://github.com/hhh2210/echoes-as-anchors.

</details>


### [145] [Do Prompts Guarantee Safety? Mitigating Toxicity from LLM Generations through Subspace Intervention](https://arxiv.org/abs/2602.06623)
*Himanshu Singh,Ziwei Xu,A. V. Subramanyam,Mohan Kankanhalli*

Main category: cs.CL

TL;DR: 提出了一种在LLM的隐藏表征层面上识别和抑制毒性模式的子空间干预策略，该策略在不影响生成文本的安全性和流畅性的前提下，有效降低了文本毒性。


<details>
  <summary>Details</summary>
Motivation: LLM可能生成有毒或有害内容，即使在看似无害的提示下，这带来了安全挑战，并且难以在token或句子层面检测。现有的缓解方法可能在安全性和文本连贯性之间存在权衡。

Method: 提出了一种针对性的子空间干预策略，用于识别和抑制模型表征中的隐藏毒性模式，同时保持生成安全流畅内容的能力。

Result: 在RealToxicityPrompts数据集上，该方法相比现有基线展现了强大的缓解性能，且对推理复杂度的影响很小。在多种LLM上，该方法将现有最先进的去毒化系统的毒性降低了8-20%，同时保持了相当的流畅性。

Conclusion: 该方法通过子空间干预在不损害生成性能的情况下实现了有效的毒性降低，并且一致优于现有基线。

Abstract: Large Language Models (LLMs) are powerful text generators, yet they can produce toxic or harmful content even when given seemingly harmless prompts. This presents a serious safety challenge and can cause real-world harm. Toxicity is often subtle and context-dependent, making it difficult to detect at the token level or through coarse sentence-level signals. Moreover, efforts to mitigate toxicity often face a trade-off between safety and the coherence, or fluency of the generated text. In this work, we present a targeted subspace intervention strategy for identifying and suppressing hidden toxic patterns from underlying model representations, while preserving overall ability to generate safe fluent content. On the RealToxicityPrompts, our method achieves strong mitigation performance compared to existing baselines, with minimal impact on inference complexity. Across multiple LLMs, our approach reduces toxicity of state-of-the-art detoxification systems by 8-20%, while maintaining comparable fluency. Through extensive quantitative and qualitative analyses, we show that our approach achieves effective toxicity reduction without impairing generative performance, consistently outperforming existing baselines.

</details>


### [146] [FairJudge: An Adaptive, Debiased, and Consistent LLM-as-a-Judge](https://arxiv.org/abs/2602.06625)
*Bo Yang,Lanfei Feng,Yunkui Chen,Yu Zhang,Xiao Xu,Shijian Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为FairJudge的新型LLM裁判系统，旨在解决现有LLM裁判在适应性、偏见和一致性方面存在的局限性，通过将裁判行为建模为可学习策略并采用SFT-DPO-GRPO训练范式，在多个基准测试中表现优于其他大型模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLM裁判系统在适应特定任务/领域评估标准、存在由位置、长度、格式等非语义线索导致的系统性偏见以及在不同评估模式下（点对点/成对）产生矛盾判断等方面存在不足。

Method: FairJudge将裁判行为建模为一个可学习且经过正则化的策略。通过构建一个高信息密度的裁判数据集，并采用SFT-DPO-GRPO的课程学习式训练范式，逐步对齐标准遵循、偏见缓解和跨模式一致性，同时避免灾难性遗忘。

Result: 在多个内部和公开基准测试中，FairJudge显著提高了评估的一致性和F1分数，减少了非语义偏见，并且在性能上大幅超越了更大规模的指令微调LLMs。

Conclusion: FairJudge是一个自适应、去偏见且一致的LLM裁判系统，能够有效克服现有方法的局限性，并在多项评估任务中取得优异表现。

Abstract: Existing LLM-as-a-Judge systems suffer from three fundamental limitations: limited adaptivity to task- and domain-specific evaluation criteria, systematic biases driven by non-semantic cues such as position, length, format, and model provenance, and evaluation inconsistency that leads to contradictory judgments across different evaluation modes (e.g., pointwise versus pairwise). To address these issues, we propose FairJudge, an adaptive, debiased, and consistent LLM-as-a-Judge. Unlike prior approaches that treat the judge as a static evaluator, FairJudge models judging behavior itself as a learnable and regularized policy. From a data-centric perspective, we construct a high-information-density judging dataset that explicitly injects supervision signals aligned with evaluation behavior. Building on this dataset, we adopt a curriculum-style SFT-DPO-GRPO training paradigm that progressively aligns rubric adherence, bias mitigation, and cross-mode consistency, while avoiding catastrophic forgetting. Experimental results on multiple internal and public benchmarks show that FairJudge consistently improves agreement and F1, reduces non-semantic biases, and outperforms substantially larger instruction-tuned LLMs. All resources will be publicly released after acceptance to facilitate future research.

</details>


### [147] [Not All Layers Need Tuning: Selective Layer Restoration Recovers Diversity](https://arxiv.org/abs/2602.06665)
*Bowen Zhang,Meiyi Wang,Harold Soh*

Main category: cs.CL

TL;DR: 本文提出了一种名为选择性层恢复（SLR）的训练后方法，通过将特定层恢复到预训练权重，有效解决了大型语言模型（LLM）在指令遵循和模型有用性提升的同时出现的生成多样性下降（模式崩溃）问题，且不增加推理成本。


<details>
  <summary>Details</summary>
Motivation: 后训练（post-training）虽然提升了 LLM 的指令遵循能力和有用性，但常常导致生成多样性下降，产生重复输出（模式崩溃）。研究者观察到 LLM 不同层具有不同功能，因此假设模式崩溃可以定位到特定层，通过恢复部分层到预训练权重可以恢复多样性同时保持高质量输出。

Method: 研究者设计了一个名为“约束随机字符”（CRC）的代理任务，用于评估恢复不同层对多样性和质量的影响。基于 CRC 任务的结果，提出选择性层恢复（SLR）方法，该方法在训练后模型中，选择性地将部分层恢复到其预训练权重，得到一个具有相同架构和参数数量的混合模型，且无需额外的推理成本。

Result: 在 CRC 代理任务上，研究发现不同层恢复范围存在明显的多样性-有效性权衡，并识别出能在多样性提升和质量损失之间取得良好平衡的配置。在创意写作、开放式问答和多步推理三个不同任务以及 Llama、Qwen 和 Gemma 三个模型家族上，SLR 方法能够持续且显著地提高输出多样性，同时保持高质量输出。

Conclusion: 选择性层恢复（SLR）是一种有效的、无需训练的方法，能够缓解 LLM 后训练带来的模式崩溃问题，显著提升生成多样性，同时保持或提高输出质量，适用于多种任务和模型。

Abstract: Post-training improves instruction-following and helpfulness of large language models (LLMs) but often reduces generation diversity, which leads to repetitive outputs in open-ended settings, a phenomenon known as mode collapse. Motivated by evidence that LLM layers play distinct functional roles, we hypothesize that mode collapse can be localized to specific layers and that restoring a carefully chosen range of layers to their pre-trained weights can recover diversity while maintaining high output quality. To validate this hypothesis and decide which layers to restore, we design a proxy task -- Constrained Random Character(CRC) -- with an explicit validity set and a natural diversity objective. Results on CRC reveal a clear diversity-validity trade-off across restoration ranges and identify configurations that increase diversity with minimal quality loss. Based on these findings, we propose Selective Layer Restoration (SLR), a training-free method that restores selected layers in a post-trained model to their pre-trained weights, yielding a hybrid model with the same architecture and parameter count, incurring no additional inference cost. Across three different tasks (creative writing, open-ended question answering, and multi-step reasoning) and three different model families (Llama, Qwen, and Gemma), we find SLR can consistently and substantially improve output diversity while maintaining high output quality.

</details>


### [148] [Reading Between the Waves: Robust Topic Segmentation Using Inter-Sentence Audio Features](https://arxiv.org/abs/2602.06647)
*Steffen Freisinger,Philipp Seeberger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 提出一种多模态方法，通过微调文本编码器和Siamese音频编码器来改进在线视频和播客的自动主题分割，实验表明效果优于仅文本和早期多模态方法，且对ASR噪声具有更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有自动主题分割方法未充分利用声学特征，存在改进空间。

Method: 提出一种多模态方法，微调文本编码器和Siamese音频编码器，以捕捉句子边界周围的声学线索。

Result: 在YouTube视频的大规模数据集上，该方法取得了显著的性能提升。与仅文本和早期多模态基线相比，该模型表现更优。此外，该模型对ASR噪声的鲁棒性更强，并在三种不同语言的数据集上优于更大的仅文本基线。

Conclusion: 学习到的声学特征对于鲁棒的主题分割至关重要，该多模态方法能有效捕捉这些特征，从而提升主题分割的性能和鲁棒性。

Abstract: Spoken content, such as online videos and podcasts, often spans multiple topics, which makes automatic topic segmentation essential for user navigation and downstream applications. However, current methods do not fully leverage acoustic features, leaving room for improvement. We propose a multi-modal approach that fine-tunes both a text encoder and a Siamese audio encoder, capturing acoustic cues around sentence boundaries. Experiments on a large-scale dataset of YouTube videos show substantial gains over text-only and multi-modal baselines. Our model also proves more resilient to ASR noise and outperforms a larger text-only baseline on three additional datasets in Portuguese, German, and English, underscoring the value of learned acoustic features for robust topic segmentation.

</details>


### [149] [compar:IA: The French Government's LLM arena to collect French-language human prompts and preference data](https://arxiv.org/abs/2602.06669)
*Lucie Termignon,Simonas Zilinskas,Hadrien Pélissier,Aurélien Barrot,Nicolas Chesnais,Elie Gavoty*

Main category: cs.CL

TL;DR: 为解决大型语言模型在非英语语言中表现不佳、文化对齐和安全鲁棒性不足的问题，本研究推出了 compar:IA，一个开源的数字公共服务平台，用于收集大规模法语用户偏好数据，并发布了相关数据集，旨在推动多语言模型的发展。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在非英语语言中表现不佳，主要原因是英语在预训练数据和人类偏好对齐数据中占据主导地位。RLHF和DPO等训练方法需要人类偏好数据，但这些数据在英语之外的语言中非常稀缺且不公开。

Method: 通过一个开源的数字公共服务平台 compar:IA，采用盲目配对比较界面，收集来自法国普通用户的、无约束的、真实的语言模型偏好数据。平台设计注重低参与门槛和隐私保护，并对数据进行自动化过滤。

Result: 截至2026年2月7日，compar:IA已收集超过60万个自由格式的提示和25万个偏好投票，其中约89%的数据为法语。发布了包含对话、投票和反应的三种数据集，并进行了初步分析，包括法语模型排行榜和用户互动模式。

Conclusion: compar:IA成功收集了大规模法语偏好数据，为解决非英语语言模型性能问题提供了重要资源。该平台正朝着成为一个国际化的数字公共产品发展，为多语言模型训练、评估以及人机交互研究提供可重用的基础设施。

Abstract: Large Language Models (LLMs) often show reduced performance, cultural alignment, and safety robustness in non-English languages, partly because English dominates both pre-training data and human preference alignment datasets. Training methods like Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO) require human preference data, which remains scarce and largely non-public for many languages beyond English. To address this gap, we introduce compar:IA, an open-source digital public service developed inside the French government and designed to collect large-scale human preference data from a predominantly French-speaking general audience. The platform uses a blind pairwise comparison interface to capture unconstrained, real-world prompts and user judgments across a diverse set of language models, while maintaining low participation friction and privacy-preserving automated filtering. As of 2026-02-07, compar:IA has collected over 600,000 free-form prompts and 250,000 preference votes, with approximately 89% of the data in French. We release three complementary datasets -- conversations, votes, and reactions -- under open licenses, and present initial analyses, including a French-language model leaderboard and user interaction patterns. Beyond the French context, compar:IA is evolving toward an international digital public good, offering reusable infrastructure for multilingual model training, evaluation, and the study of human-AI interaction.

</details>


### [150] [Beyond Static Alignment: Hierarchical Policy Control for LLM Safety via Risk-Aware Chain-of-Thought](https://arxiv.org/abs/2602.06650)
*Jianfeng Si,Lin Sun,Weihong Lin,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: PACT框架通过分层策略和链式思考（Chain-of-Thought）来实现大型语言模型（LLM）的安全响应动态可控，平衡了安全性和有用性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM安全策略是静态且统一的，无法满足多样化的应用需求，导致模型可能过度拒绝无害请求或未能有效限制有害请求。

Method: PACT框架采用分层策略架构：一个不可覆盖的全局安全策略设定底线，用户定义的策略可以引入特定领域的风险类别并指定标签到行为的映射。该框架将安全决策分解为“分类→行动”的结构化路径，实现透明决策。

Result: PACT在全局策略评估下达到了接近最先进的安全性能，并在用户特定策略评估下实现了最佳的可控性，有效缓解了安全-有用性之间的权衡。

Conclusion: PACT框架通过动态、可控的安全策略，成功解决了LLM在安全性和有用性之间的固有矛盾，为可控安全对齐研究提供了可复现的工具和数据。

Abstract: Large Language Models (LLMs) face a fundamental safety-helpfulness trade-off due to static, one-size-fits-all safety policies that lack runtime controllabilityxf, making it difficult to tailor responses to diverse application needs. %As a result, models may over-refuse benign requests or under-constrain harmful ones. We present \textbf{PACT} (Prompt-configured Action via Chain-of-Thought), a framework for dynamic safety control through explicit, risk-aware reasoning. PACT operates under a hierarchical policy architecture: a non-overridable global safety policy establishes immutable boundaries for critical risks (e.g., child safety, violent extremism), while user-defined policies can introduce domain-specific (non-global) risk categories and specify label-to-action behaviors to improve utility in real-world deployment settings. The framework decomposes safety decisions into structured Classify$\rightarrow$Act paths that route queries to the appropriate action (comply, guide, or reject) and render the decision-making process transparent.
  Extensive experiments demonstrate that PACT achieves near state-of-the-art safety performance under global policy evaluation while attaining the best controllability under user-specific policy evaluation, effectively mitigating the safety-helpfulness trade-off. We will release the PACT model suite, training data, and evaluation protocols to facilitate reproducible research in controllable safety alignment.

</details>


### [151] [Evaluating Prompt Engineering Strategies for Sentiment Control in AI-Generated Texts](https://arxiv.org/abs/2602.06692)
*Kerstin Sahler,Sophie Jentzsch*

Main category: cs.CL

TL;DR: 研究发现，通过精心设计的提示工程（prompt engineering），可以有效地控制大型语言模型（LLM）生成文本的情感，为开发情感适应性AI提供了一种比微调更具成本效益和资源敏感的替代方案，其中Few-Shot提示效果最佳。


<details>
  <summary>Details</summary>
Motivation: 为了增强人机交互，需要开发能够适应用户情感的AI系统，但控制LLM的情感输出具有挑战性。

Method: 使用gpt-3.5-turbo模型，通过Zero-Shot和Chain-of-Thought等提示工程技术，并与微调方法进行对比，研究如何控制LLM生成文本中的六种基本情感。

Result: 提示工程能够有效引导AI生成文本的情感。在所研究的技术中，Few-Shot提示（使用人类编写的示例）被证明是最有效的方法。

Conclusion: 提示工程是一种实用且经济高效的方式，可以控制LLM生成文本的情感，尤其是在数据受限的情况下，为情感适应性AI的开发提供了有价值的见解。

Abstract: The groundbreaking capabilities of Large Language Models (LLMs) offer new opportunities for enhancing human-computer interaction through emotion-adaptive Artificial Intelligence (AI). However, deliberately controlling the sentiment in these systems remains challenging. The present study investigates the potential of prompt engineering for controlling sentiment in LLM-generated text, providing a resource-sensitive and accessible alternative to existing methods. Using Ekman's six basic emotions (e.g., joy, disgust), we examine various prompting techniques, including Zero-Shot and Chain-of-Thought prompting using gpt-3.5-turbo, and compare it to fine-tuning. Our results indicate that prompt engineering effectively steers emotions in AI-generated texts, offering a practical and cost-effective alternative to fine-tuning, especially in data-constrained settings. In this regard, Few-Shot prompting with human-written examples was the most effective among other techniques, likely due to the additional task-specific guidance. The findings contribute valuable insights towards developing emotion-adaptive AI systems.

</details>


### [152] [Generating Data-Driven Reasoning Rubrics for Domain-Adaptive Reward Modeling](https://arxiv.org/abs/2602.06795)
*Kate Sanders,Nathaniel Weir,Sapana Chaudhary,Kaj Bostrom,Huzefa Rangwala*

Main category: cs.CL

TL;DR: 该研究提出了一种数据驱动的方法，用于自动构建精细化的推理错误分类体系（“评分细则”），以提高大型语言模型（LLMs）在代码、数学和化学工程等技术领域中识别推理错误的能力。通过使用这些评分细则，可以构建更强大的LLM评分奖励函数，用于强化学习训练模型。实验表明，这种方法在提高模型任务准确性方面具有显著潜力，并且所需的标注数据量远少于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在验证推理过程中的错误时存在困难，尤其是在长输出、需要专业知识的领域以及没有可验证奖励的问题上。这阻碍了LLMs在推理输出验证方面的应用。

Method: 提出了一种数据驱动的方法，自动构建精细化的推理错误分类体系（“评分细则”）。利用这些评分细则来增强LLM驱动的错误检测能力，并将其应用于构建更强的LLM评分奖励函数，用于强化学习训练。

Result: 研究发现，利用评分细则的分类方法在代码、数学和化学工程等技术领域比基线方法具有更强的错误识别能力。通过评分细则构建的奖励函数，相比通用LLM评分的训练模型，在困难领域的任务准确性提高了45%，并且在仅使用20%的金标签数据的情况下，达到了接近可验证奖励训练模型的性能。

Conclusion: 该研究成功地将评分细则的应用从评估模型定性行为扩展到评估模型在通常通过RLVR奖励学习的任务上的定量正确性。这为在缺乏昂贵金标签数据集的情况下，教会模型解决复杂技术问题提供了新的途径。

Abstract: An impediment to using Large Language Models (LLMs) for reasoning output verification is that LLMs struggle to reliably identify errors in thinking traces, particularly in long outputs, domains requiring expert knowledge, and problems without verifiable rewards. We propose a data-driven approach to automatically construct highly granular reasoning error taxonomies to enhance LLM-driven error detection on unseen reasoning traces. Our findings indicate that classification approaches that leverage these error taxonomies, or "rubrics", demonstrate strong error identification compared to baseline methods in technical domains like coding, math, and chemical engineering. These rubrics can be used to build stronger LLM-as-judge reward functions for reasoning model training via reinforcement learning. Experimental results show that these rewards have the potential to improve models' task accuracy on difficult domains over models trained by general LLMs-as-judges by +45%, and approach performance of models trained by verifiable rewards while using as little as 20% as many gold labels. Through our approach, we extend the usage of reward rubrics from assessing qualitative model behavior to assessing quantitative model correctness on tasks typically learned via RLVR rewards. This extension opens the door for teaching models to solve complex technical problems without a full dataset of gold labels, which are often highly costly to procure.

</details>


### [153] [Table-as-Search: Formulate Long-Horizon Agentic Information Seeking as Table Completion](https://arxiv.org/abs/2602.06724)
*Tian Lan,Felix Henry,Bin Zhu,Qianghuai Jia,Junyang Ren,Qihang Pu,Haijun Li,Longyue Wang,Zhao Xu,Weihua Luo*

Main category: cs.CL

TL;DR: 本文提出了Table-as-Search (TaS)框架，将信息检索任务转化为表格补全任务，通过结构化表格来管理搜索状态，有效解决了现有信息检索代理在长时程探索中难以保持专注和连贯的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的信息检索（InfoSeeking）代理在长时程探索中难以维持专注和连贯性，因为在单一的纯文本上下文中跟踪搜索状态（包括规划过程和海量搜索结果）容易出错。

Method: TaS将信息检索任务重新构建为表格补全任务。它将每个查询映射到一个外部数据库中维护的结构化表格模式，其中行代表搜索候选，列代表约束或所需信息。通过填充的单元格记录历史和搜索结果，未填写的单元格作为明确的搜索计划来管理搜索状态。

Result: TaS在三种基准（包括多智能体框架和商业系统）上，在Deep Search、Wide Search和DeepWide Search这三种信息检索任务上，均显著优于多个最先进的基线方法。实验还验证了TaS在长时程信息检索任务上的鲁棒性、效率、可扩展性和灵活性。 

Conclusion: TaS框架通过结构化表格管理搜索状态，有效解决了长时程信息检索中的挑战，并取得了优于现有方法的性能，同时证明了其鲁棒性、效率、可扩展性和灵活性。

Abstract: Current Information Seeking (InfoSeeking) agents struggle to maintain focus and coherence during long-horizon exploration, as tracking search states, including planning procedure and massive search results, within one plain-text context is inherently fragile. To address this, we introduce \textbf{Table-as-Search (TaS)}, a structured planning framework that reformulates the InfoSeeking task as a Table Completion task. TaS maps each query into a structured table schema maintained in an external database, where rows represent search candidates and columns denote constraints or required information. This table precisely manages the search states: filled cells strictly record the history and search results, while empty cells serve as an explicit search plan. Crucially, TaS unifies three distinct InfoSeeking tasks: Deep Search, Wide Search, and the challenging DeepWide Search. Extensive experiments demonstrate that TaS significantly outperforms numerous state-of-the-art baselines across three kinds of benchmarks, including multi-agent framework and commercial systems. Furthermore, our analysis validates the TaS's superior robustness in long-horizon InfoSeeking, alongside its efficiency, scalability and flexibility. Code and datasets are publicly released at https://github.com/AIDC-AI/Marco-Search-Agent.

</details>


### [154] [The Representational Geometry of Number](https://arxiv.org/abs/2602.06843)
*Zhimin Hu,Lanhao Niu,Sashank Varma*

Main category: cs.CL

TL;DR: 该研究提出，概念表征的共享体现在概念之间的几何关系上，而非概念本身。研究使用语言模型作为计算载体，并以数字概念为测试对象，发现数字表征在不同任务间保持稳定的关系结构，而任务特定的表征则位于不同的子空间中，可以通过线性映射相互转换，表明表征共享了关系结构。


<details>
  <summary>Details</summary>
Motivation: 认知科学中存在一个核心问题：概念表征是收敛于共享流形以支持泛化，还是发散到正交子空间以最小化任务干扰？现有研究虽然发现了支持这两种观点的证据，但缺乏一个解释这两种特性如何共存和跨任务转化的机制。

Method: 研究使用语言模型作为高维计算基底，并以数字概念为测试平台。通过分析语言模型中数字表征在不同任务下的几何关系，探究其共享结构和任务特定性。具体方法包括检查表征是否位于不同子空间，以及这些子空间是否可以通过线性映射相互转换。

Result: 研究发现，数字表征在不同任务间保持了稳定的关系结构。任务特定的表征被嵌入到不同的子空间中，并且低级特征（如大小和奇偶性）沿着可分离的线性方向编码。关键的是，研究发现这些子空间在很大程度上可以通过线性映射相互转换，表明表征尽管位于不同的子空间，但共享了关系结构。

Conclusion: 该研究为理解语言模型如何平衡数字表征的共享结构和功能灵活性提供了一个机制性视角。研究结果表明，理解发生在将任务特定的变换应用于概念表征的共享底层关系结构时。这意味着概念表征的共享性体现在它们之间的关系结构，而非表征本身的绝对位置或形式。

Abstract: A central question in cognitive science is whether conceptual representations converge onto a shared manifold to support generalization, or diverge into orthogonal subspaces to minimize task interference. While prior work has discovered evidence for both, a mechanistic account of how these properties coexist and transform across tasks remains elusive. We propose that representational sharing lies not in the concepts themselves, but in the geometric relations between them. Using number concepts as a testbed and language models as high-dimensional computational substrates, we show that number representations preserve a stable relational structure across tasks. Task-specific representations are embedded in distinct subspaces, with low-level features like magnitude and parity encoded along separable linear directions. Crucially, we find that these subspaces are largely transformable into one another via linear mappings, indicating that representations share relational structure despite being located in distinct subspaces. Together, these results provide a mechanistic lens of how language models balance the shared structure of number representation with functional flexibility. It suggests that understanding arises when task-specific transformations are applied to a shared underlying relational structure of conceptual representations.

</details>


### [155] [R-Align: Enhancing Generative Reward Models through Rationale-Centric Meta-Judging](https://arxiv.org/abs/2602.06763)
*Yanlin Lai,Mitt Huang,Hangyu Guo,Xiangfeng Wang,Haodong Li,Shaoxiong Zhan,Liang Zhao,Chengyuan Yao,Yinmin Zhang,Qi Han,Chun Yuan,Zheng Ge,Xiangyu Zhang,Daxin Jiang*

Main category: cs.CL

TL;DR: 该研究提出了R-Align方法，通过在训练中引入黄金判断并显式监督推理过程，提高了生成奖励模型（GenRM）的推理保真度，从而改善了大型语言模型（LLM）在强化学习中的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有的生成奖励模型（GenRM）在训练和评估时仅关注最终偏好标签，忽略了其生成理由的质量。作者发现，即使在标签准确率相同的情况下，理由的忠实度（reasoning fidelity）也对下游强化学习（RLHF）的结果有重要影响，并且推理不一致会导致模型性能下降。因此，研究的动机是提高GenRM的推理保真度，以获得更稳健的LLM对齐。

Method: 该研究提出了R-Align（Rationale-Centric Alignment）方法，该方法在GenRM的训练过程中，不仅使用偏好标签，还引入了黄金判断（gold judgments）来显式监督推理过程，以确保生成的理由与黄金理由对齐。此外，研究还提出了Spurious Correctness（S-Corr）指标来衡量推理过程中的不一致性，并利用该指标来评估GenRM的性能。

Result: 研究发现，即使是性能优越的GenRM也存在显著的S-Corr，且S-Corr越高，模型在优化过程中越容易出现性能退化。通过R-Align方法，显著降低了S-Corr，并在STEM、编码、指令遵循和通用任务等多个领域均取得了Actor性能的提升。

Conclusion: 推理保真度是评估和训练生成奖励模型的关键因素，直接影响着LLM的对齐效果。R-Align通过关注推理过程的对齐，能够有效提高GenRM的质量，并带来下游RLHF任务的性能提升。

Abstract: Reinforcement Learning from Human Feedback (RLHF) remains indispensable for aligning large language models (LLMs) in subjective domains. To enhance robustness, recent work shifts toward Generative Reward Models (GenRMs) that generate rationales before predicting preferences. Yet in GenRM training and evaluation, practice remains outcome-label-only, leaving reasoning quality unchecked. We show that reasoning fidelity-the consistency between a GenRM's preference decision and reference decision rationales-is highly predictive of downstream RLHF outcomes, beyond standard label accuracy. Specifically, we repurpose existing reward-model benchmarks to compute Spurious Correctness (S-Corr)-the fraction of label-correct decisions with rationales misaligned with golden judgments. Our empirical evaluation reveals substantial S-Corr even for competitive GenRMs, and higher S-Corr is associated with policy degeneration under optimization. To improve fidelity, we propose Rationale-Centric Alignment, R-Align, which augments training with gold judgments and explicitly supervises rationale alignment. R-Align reduces S-Corr on RM benchmarks and yields consistent gains in actor performance across STEM, coding, instruction following, and general tasks.

</details>


### [156] [Visual Word Sense Disambiguation with CLIP through Dual-Channel Text Prompting and Image Augmentations](https://arxiv.org/abs/2602.06799)
*Shamik Bhattacharya,Daniel Perkins,Yaren Dogan,Vineeth Konjeti,Sudarshan Srinivasan,Edmon Begoli*

Main category: cs.CL

TL;DR: 本文提出了一个可解释的视觉词义消歧（VWSD）框架，利用CLIP将文本和图像映射到共享空间，并通过多样的提示和数据增强来提高消歧性能，实验证明该方法在SemEval-2023 VWSD数据集上有效。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在理解词义歧义时面临挑战，研究希望通过视觉信息来解决词义歧义问题。

Method: 开发了一个可解释的VWSD框架，利用CLIP将模糊词语和候选图像映射到共享多模态空间。通过语义和基于照片的提示（结合WordNet同义词）来丰富文本嵌入，并使用测试时增强来优化图像嵌入。最后，通过余弦相似度选择最匹配的图像。

Result: 在SemEval-2023 VWSD数据集上，该框架将MRR从0.7227提升至0.7590，Hit Rate从0.5810提升至0.6220。消融研究表明，双通道提示性能优越且延迟低，而过度的图像增强效果不显著。

Conclusion: 精确的、与CLIP对齐的提示对于视觉词义消歧非常有效，而引入WordNet定义或多语言提示等外部信号反而会稀释语义特异性。

Abstract: Ambiguity poses persistent challenges in natural language understanding for large language models (LLMs). To better understand how lexical ambiguity can be resolved through the visual domain, we develop an interpretable Visual Word Sense Disambiguation (VWSD) framework. The model leverages CLIP to project ambiguous language and candidate images into a shared multimodal space. We enrich textual embeddings using a dual-channel ensemble of semantic and photo-based prompts with WordNet synonyms, while image embeddings are refined through robust test-time augmentations. We then use cosine similarity to determine the image that best aligns with the ambiguous text. When evaluated on the SemEval-2023 VWSD dataset, enriching the embeddings raises the MRR from 0.7227 to 0.7590 and the Hit Rate from 0.5810 to 0.6220. Ablation studies reveal that dual-channel prompting provides strong, low-latency performance, whereas aggressive image augmentation yields only marginal gains. Additional experiments with WordNet definitions and multilingual prompt ensembles further suggest that noisy external signals tend to dilute semantic specificity, reinforcing the effectiveness of precise, CLIP-aligned prompts for visual word sense disambiguation.

</details>


### [157] [Halluverse-M^3: A multitask multilingual benchmark for hallucination in LLMs](https://arxiv.org/abs/2602.06920)
*Samir Abdaljalil,Parichit Sharma,Erchin Serpedin,Hasan Kurban*

Main category: cs.CL

TL;DR: 本文提出了 Halluverse-M^3 数据集，用于系统地分析多语言、多任务场景下大型语言模型的幻觉问题，并基于此数据集对不同模型进行了评估，揭示了语言、任务和幻觉类型对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在多语言和生成任务中存在持续的幻觉问题，但对其跨语言、跨任务和跨幻觉类型的行为理解不足。需要一个专门的数据集来系统地研究这些问题。

Method: 构建了一个名为 Halluverse-M^3 的数据集，覆盖四种语言（英语、阿拉伯语、印地语、土耳其语）和两种生成任务（问答、对话摘要）。数据集明确区分了实体级、关系级和句子级幻觉，并通过受控编辑和人工标注来保证幻觉内容与原文的一致性。然后，使用该数据集评估了多种语言模型的幻觉检测能力。

Result: 问答任务的幻觉检测普遍比对话摘要任务容易。句子级幻觉对所有模型都是一个挑战。英语性能最高，低资源语言（尤其是印地语）的检测准确率下降。现代模型在检测实体级和关系级幻觉方面表现优于句子级幻觉。

Conclusion: Halluverse-M^3 是一个现实且具有挑战性的基准，能够促进对多语言、多任务场景下幻觉问题的深入研究。该数据集可用于推动幻觉检测和缓解方面的未来研究。

Abstract: Hallucinations in large language models remain a persistent challenge, particularly in multilingual and generative settings where factual consistency is difficult to maintain. While recent models show strong performance on English-centric benchmarks, their behavior across languages, tasks, and hallucination types is not yet well understood. In this work, we introduce Halluverse-M^3, a dataset designed to enable systematic analysis of hallucinations across multiple languages, multiple generation tasks, and multiple hallucination categories. Halluverse-M^3 covers four languages, English, Arabic, Hindi, and Turkish, and supports two generation tasks: question answering and dialogue summarization. The dataset explicitly distinguishes between entity-level, relation-level, and sentence-level hallucinations. Hallucinated outputs are constructed through a controlled editing process and validated by human annotators, ensuring clear alignment between original content and hallucinated generations. Using this dataset, we evaluate a diverse set of contemporary open-source and proprietary language models on fine-grained hallucination detection. Our results show that question answering is consistently easier than dialogue summarization, while sentence-level hallucinations remain challenging even for the strongest models. Performance is highest in English and degrades in lower-resource languages, with Hindi exhibiting the lowest detection accuracy. Overall, Halluverse-M^3 provides a realistic and challenging benchmark for studying hallucinations in multilingual, multi-task settings. We release the dataset to support future research on hallucination detection and mitigation\footnote{https://huggingface.co/datasets/sabdalja/HalluVerse-M3}.

</details>


### [158] [SEMA: Simple yet Effective Learning for Multi-Turn Jailbreak Attacks](https://arxiv.org/abs/2602.06854)
*Mingqian Feng,Xiaodong Liu,Weiwei Yang,Jialin Song,Xuekai Zhu,Chenliang Xu,Jianfeng Gao*

Main category: cs.CL

TL;DR: 提出了一种名为SEMA的框架，用于训练能够进行多轮越狱攻击的LLM。SEMA通过预填充自调优和带有意图漂移意识的奖励进行强化学习，无需外部数据或现有策略，有效解决了现有方法的探索复杂性和意图漂移问题，并在多项评估中达到了SOTA攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的单轮越狱攻击不能完全代表安全对齐的聊天机器人的实际威胁模型，而多轮攻击面临探索复杂性和意图漂移的挑战。研究旨在开发一种更有效、更真实的多轮越狱攻击方法，以更好地测试LLM的安全性。

Method: SEMA框架包含两个阶段：1. 预填充自调优：使用最小前缀自我生成、结构良好且不拒绝的多轮对抗性提示进行微调，以稳定后续学习。2. 带有意图漂移意识的奖励强化学习：训练攻击者生成有效的多轮对抗性提示，同时保持有害目标。意图漂移意识奖励结合了意图对齐、合规风险和详细程度。该方法采用开放循环攻击模式，避免依赖受害者反馈，统一单轮和多轮设置，降低了探索复杂性。

Result: SEMA在多个数据集、受害者模型和越狱评估器上取得了最先进的攻击成功率（ASR），显著优于所有单轮基线、手动脚本化和模板驱动的多轮基线，以及SFT和DPO变体。例如，在AdvBench上，SEMA在三个闭源和开源受害者模型上实现了平均80.1%的ASR@1，比现有SOTA提高了33.9%。

Conclusion: SEMA是一种简单有效、紧凑、可复现且可迁移的多轮越狱攻击框架，能够克服现有方法的局限性，为LLM安全提供更强大、更真实的压力测试，并支持自动红队测试以暴露和定位故障模式。

Abstract: Multi-turn jailbreaks capture the real threat model for safety-aligned chatbots, where single-turn attacks are merely a special case. Yet existing approaches break under exploration complexity and intent drift. We propose SEMA, a simple yet effective framework that trains a multi-turn attacker without relying on any existing strategies or external data. SEMA comprises two stages. Prefilling self-tuning enables usable rollouts by fine-tuning on non-refusal, well-structured, multi-turn adversarial prompts that are self-generated with a minimal prefix, thereby stabilizing subsequent learning. Reinforcement learning with intent-drift-aware reward trains the attacker to elicit valid multi-turn adversarial prompts while maintaining the same harmful objective. We anchor harmful intent in multi-turn jailbreaks via an intent-drift-aware reward that combines intent alignment, compliance risk, and level of detail. Our open-loop attack regime avoids dependence on victim feedback, unifies single- and multi-turn settings, and reduces exploration complexity. Across multiple datasets, victim models, and jailbreak judges, our method achieves state-of-the-art (SOTA) attack success rates (ASR), outperforming all single-turn baselines, manually scripted and template-driven multi-turn baselines, as well as our SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization) variants. For instance, SEMA performs an average $80.1\%$ ASR@1 across three closed-source and open-source victim models on AdvBench, 33.9% over SOTA. The approach is compact, reproducible, and transfers across targets, providing a stronger and more realistic stress test for large language model (LLM) safety and enabling automatic redteaming to expose and localize failure modes. Our code is available at: https://github.com/fmmarkmq/SEMA.

</details>


### [159] [Optimal Turkish Subword Strategies at Scale: Systematic Evaluation of Data, Vocabulary, Morphology Interplay](https://arxiv.org/abs/2602.06942)
*Duygu Altinok*

Main category: cs.CL

TL;DR: 本研究首次对土耳其语的子词分词进行了全面、系统的研究，通过联合调整词汇量和训练语料库大小，并对比不同分词器族在相同参数预算下的表现，同时引入了包含多种细粒度指标的形态学感知诊断工具，以评估其在各种下游任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有关于形态丰富语言（如土耳其语）的神经语言模型分词研究，在调整词汇量时未能系统控制训练语料库，且缺乏深入的内在诊断和广泛的下游任务评估，限制了对其有效性的理解和改进。

Method: 研究者联合调整了词汇量和训练语料库大小（数据-词汇量耦合），对比了WordPiece、形态学层级和字符级等多种分词器族，并引入了包括边界级F1、词形原子性、过/欠分割、编辑距离、延续率以及词缀覆盖率等在内的形态学感知诊断工具，在语义、句法和形态学敏感任务上进行了评估。

Result: 研究系统地考察了词汇量-语料库-成功之间的关系，提出了一个将内在诊断与外在结果联系起来的统一评估框架，并确定了字符级和形态学层级分词器在特定情况下的优势。

Conclusion: 该研究为构建形态丰富语言的有效分词器提供了可操作的指导，并为未来的研究奠定了可复现的基础，强调了数据-词汇量耦合以及细粒度形态学诊断在理解和改进分词器方面的关键作用。

Abstract: Tokenization is a pivotal design choice for neural language modeling in morphologically rich languages (MRLs) such as Turkish, where productive agglutination challenges both vocabulary efficiency and morphological fidelity. Prior studies have explored tokenizer families and vocabulary sizes but typically (i) vary vocabulary without systematically controlling the tokenizer's training corpus, (ii) provide limited intrinsic diagnostics, and (iii) evaluate a narrow slice of downstream tasks. We present the first comprehensive, principled study of Turkish subword tokenization; a "subwords manifest", that jointly varies vocabulary size and tokenizer training corpus size (data and vocabulary coupling), compares multiple tokenizer families under matched parameter budgets (WordPiece, morphology level, and character baselines), and evaluates across semantic (NLI, STS, sentiment analysis, NER), syntactic (POS, dependency parsing), and morphology-sensitive probes. To explain why tokenizers succeed or fail, we introduce a morphology-aware diagnostic toolkit that goes beyond coarse aggregates to boundary-level micro/macro F1, decoupled lemma atomicity vs. surface boundary hits, over/under-segmentation indices, character/word edit distances (CER/WER), continuation rates, and affix-type coverage and token-level atomicity. Our contributions are fourfold: (i) a systematic investigation of the vocabulary-corpus-success triad; (ii) a unified, morphology-aware evaluation framework linking intrinsic diagnostics to extrinsic outcomes; (iii) controlled comparisons identifying when character-level and morphology-level tokenization pay off; and (iv) an open-source release of evaluation code, tokenizer pipelines, and models. As the first work of its kind, this "subwords manifest" delivers actionable guidance for building effective tokenizers in MRLs and establishes a reproducible foundation for future research.

</details>


### [160] [Uncovering Cross-Objective Interference in Multi-Objective Alignment](https://arxiv.org/abs/2602.06869)
*Yining Lu,Meng Jiang*

Main category: cs.CL

TL;DR: 本研究首次系统地研究了大型语言模型（LLM）多目标对齐中普遍存在的“交叉目标干扰”现象，即在优化部分目标时导致其他目标性能下降。研究者提出了基于协方差的分析方法，并据此开发了一种名为CTWA的新型即插即用方法来缓解此问题，同时对算法的全局收敛性进行了理论分析。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLM）在多目标对齐过程中遇到的一个持续存在的失败模式：训练提升了部分目标性能，却导致其他目标性能下降。这种“交叉目标干扰”现象普遍存在且与模型紧密相关，需要被理解和解决。

Method: 1. 形式化“交叉目标干扰”现象。 2. 系统性地评估经典标量化算法在此现象上的表现。 3. 推导局部协方差律，解释目标如何通过与标量化得分的正协方差而得到改善。 4. 将协方差律扩展到现代对齐中使用的截断代理目标。 5. 提出一种名为CTWA（Covariance Targeted Weight Adaptation）的即插即用方法，通过维持目标奖励与训练信号的正协方差来缓解干扰。 6. 进行全局收敛性分析，研究在Polyak--Łojasiewicz条件下的非凸标量化优化，并分析交叉目标干扰与模型几何性质的关系。

Result: 1. 交叉目标干扰现象在经典标量化算法中普遍存在，且高度依赖于模型。 2. 局部协方差律有效解释了目标改善的机制，即使在截断代理目标下也适用。 3. CTWA方法能有效缓解交叉目标干扰。 4. 理论分析确定了非凸标量化优化的全局收敛条件，并揭示了交叉目标干扰与模型几何性质的联系。

Conclusion: 交叉目标干扰是LLM多目标对齐中的一个关键挑战。通过理解其背后的协方差机制，可以开发出有效的缓解方法（如CTWA），并在理论上保证优化算法的性能和收敛性。

Abstract: We study a persistent failure mode in multi-objective alignment for large language models (LLMs): training improves performance on only a subset of objectives while causing others to degrade. We formalize this phenomenon as cross-objective interference and conduct the first systematic study across classic scalarization algorithms, showing that interference is pervasive and exhibits strong model dependence.
  To explain this phenomenon, we derive a local covariance law showing that an objective improves at first order when its reward exhibits positive covariance with the scalarized score. We extend this analysis to clipped surrogate objectives used in modern alignment, demonstrating that the covariance law remains valid under mild conditions despite clipping. Building on this analysis, we propose Covariance Targeted Weight Adaptation (CTWA), a plug-and-play method that maintains positive covariance between objective rewards and the training signal to effectively mitigate cross-objective interference. Finally, we complement these local improvement conditions with a global convergence analysis under the Polyak--Łojasiewicz condition, establishing when non-convex scalarized optimization achieves global convergence and how cross-objective interference depends on specific model geometric properties.

</details>


### [161] [DAWN: Dependency-Aware Fast Inference for Diffusion LLMs](https://arxiv.org/abs/2602.06953)
*Lizhuo Luo,Zhuoran Shi,Jiajun Luo,Zhi Wang,Shen Ren,Wenya Wang,Tianwei Zhang*

Main category: cs.CL

TL;DR: DAWN是一种训练无关的、依赖感知的解码方法，通过提取和利用Token间的依赖关系，实现了dLLM推理的高效并行化，并在不牺牲生成质量的情况下将推理速度提高了1.80-8.06倍。


<details>
  <summary>Details</summary>
Motivation: 现有dLLM的并行解码方法未能充分挖掘效率潜力，因为它们在并行处理时忽略了Token间的语义依赖关系，导致生成质量下降。作者旨在解决这种质量-速度的权衡问题。

Method: DAWN方法通过构建依赖图来提取Token依赖关系，并利用两个关键洞察：（1）依赖于已确定Token的位置会更可靠；（2）同时解锁强耦合的不确定位置会导致错误。DAWN在每次迭代中选择更可靠的解锁位置，从而实现高并行度。

Result: 在多个模型和数据集上的实验表明，DAWN在保持生成质量的同时，将推理速度相比基线方法提高了1.80-8.06倍。

Conclusion: DAWN通过建模Token间的依赖关系，能够实现dLLM的高效并行推理，显著提升速度，同时保持生成质量。

Abstract: Diffusion large language models (dLLMs) have shown advantages in text generation, particularly due to their inherent ability for parallel decoding. However, constrained by the quality--speed trade-off, existing inference solutions adopt conservative parallel strategies, leaving substantial efficiency potential underexplored. A core challenge is that parallel decoding assumes each position can be filled independently, but tokens are often semantically coupled. Thus, the correct choice at one position constrains valid choices at others. Without modeling these inter-token dependencies, parallel strategies produce deteriorated outputs. Motivated by this insight, we propose DAWN, a training-free, dependency-aware decoding method for fast dLLM inference. DAWN extracts token dependencies and leverages two key motivations: (1) positions dependent on unmasked certain positions become more reliable, (2) simultaneously unmasking strongly coupled uncertain positions induces errors. Given those findings, DAWN leverages a dependency graph to select more reliable unmasking positions at each iteration, achieving high parallelism with negligible loss in generation quality. Extensive experiments across multiple models and datasets demonstrate that DAWN speedups the inference by 1.80-8.06x over baselines while preserving the generation quality. Code is released at https://github.com/lizhuo-luo/DAWN.

</details>


### [162] [InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning](https://arxiv.org/abs/2602.06960)
*Yuchen Yan,Liang Jiang,Jin Jiang,Shuaicheng Li,Zujie Wen,Zhiqiang Zhang,Jun Zhou,Jian Shao,Yueting Zhuang,Yongliang Shen*

Main category: cs.CL

TL;DR: 提出了一种名为 InftyThink+ 的端到端强化学习框架，用于优化迭代推理过程，解决了现有方法在何时总结、保留什么以及如何恢复推理方面的不足，并在推理准确性和效率上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思考（chain-of-thought）方法存在二次成本、上下文长度限制和“中间丢失”效应导致的推理性能下降问题。虽然迭代推理可以缓解这些问题，但现有方法依赖于监督学习或固定启发式，未能优化总结、保留和恢复推理的时机。

Method: 提出 InftyThink+，一个端到端的强化学习框架，通过模型控制的迭代边界和显式总结来优化整个迭代推理轨迹。采用两阶段训练：监督冷启动后进行轨迹级别的强化学习。

Result: 在 DeepSeek-R1-Distill-Qwen-1.5B 模型上进行实验，InftyThink+ 在 AIME24 上准确率提升了 21%，并且优于传统的长链式思考强化学习方法，在分布外基准测试上也表现出更好的泛化能力。此外，InftyThink+ 显著降低了推理延迟，加速了强化学习训练。

Conclusion: InftyThink+ 框架通过端到端强化学习优化了迭代推理过程，成功解决了现有方法的局限性，在提高推理准确性的同时，也显著提升了推理效率。

Abstract: Large reasoning models achieve strong performance by scaling inference-time chain-of-thought, but this paradigm suffers from quadratic cost, context length limits, and degraded reasoning due to lost-in-the-middle effects. Iterative reasoning mitigates these issues by periodically summarizing intermediate thoughts, yet existing methods rely on supervised learning or fixed heuristics and fail to optimize when to summarize, what to preserve, and how to resume reasoning. We propose InftyThink+, an end-to-end reinforcement learning framework that optimizes the entire iterative reasoning trajectory, building on model-controlled iteration boundaries and explicit summarization. InftyThink+ adopts a two-stage training scheme with supervised cold-start followed by trajectory-level reinforcement learning, enabling the model to learn strategic summarization and continuation decisions. Experiments on DeepSeek-R1-Distill-Qwen-1.5B show that InftyThink+ improves accuracy by 21% on AIME24 and outperforms conventional long chain-of-thought reinforcement learning by a clear margin, while also generalizing better to out-of-distribution benchmarks. Moreover, InftyThink+ significantly reduces inference latency and accelerates reinforcement learning training, demonstrating improved reasoning efficiency alongside stronger performance.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [163] [Dynamic Modeling, Parameter Identification and Numerical Analysis of Flexible Cables in Flexibly Connected Dual-AUV Systems](https://arxiv.org/abs/2602.06087)
*Kuo Chen,Minghao Dou,Qianqi Liu,Yang An,Kai Ren,Zeming WU,Yu Tian,Jie Sun,Xinping Wang,Zhier Chen,Jiancheng Yu*

Main category: cs.RO

TL;DR: 本文提出了一种用于柔性连接双AUV系统的动力学建模和参数识别框架，该框架能精确描述系统的高度非线性行为，并揭示了柔性缆绳的动态特性对系统响应的影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究难以准确描述柔性连接双AUV系统的高度非线性行为，特别是材料特性和流体动力学系数难以直接测量，因此需要一种结合物理模型和实验数据的参数识别方法。

Method: 采用集总质量法建立动力学模型，考虑了轴向弹性、弯曲刚度、附加质量和流体动力学力。通过多种配置下的张力实验，提出了一种结合物理模型和实验数据的参数识别方法，用于辨识等效杨氏模量和流体动力学系数。

Result: 识别出的模型在不同工况下表现出预测一致性。数值分析表明，柔性缆绳的动态特性具有显著的非线性，且高度依赖于材料属性变化和AUV的运动条件。这种非线性动态行为导致了缆绳的松弛和绷紧两种典型响应状态，受边界条件和流体动力学效应共同影响。

Conclusion: 揭示了柔性缆绳在复杂边界条件下的动力学行为，为类似系统的设计、优化和控制研究提供了理论基础。该研究强调了柔性缆绳非线性动力学对系统整体行为的重要性。

Abstract: This research presents a dynamic modeling framework and parameter identification methods for describing the highly nonlinear behaviors of flexibly connected dual-AUV systems. The modeling framework is established based on the lumped mass method, integrating axial elasticity, bending stiffness, added mass and hydrodynamic forces, thereby accurately capturing the time-varying response of the forces and cable configurations. To address the difficulty of directly measuring material-related and hydrodynamic coefficients, this research proposes a parameter identification method that combines the physical model with experimental data. High-precision inversion of the equivalent Youngs modulus and hydrodynamic coefficients is performed through tension experiments under multiple configurations, effectively demonstrating that the identified model maintains predictive consistency in various operational conditions. Further numerical analysis indicates that the dynamic properties of flexible cable exhibit significant nonlinear characteristics, which are highly dependent on material property variations and AUV motion conditions. This nonlinear dynamic behavior results in two typical response states, slack and taut, which are jointly determined by boundary conditions and hydrodynamic effects, significantly affecting the cable configuration and endpoint loads. In this research, the dynamics of flexible cables under complex boundary conditions is revealed, providing a theoretical foundation for the design, optimization and further control research of similar systems.

</details>


### [164] [Transformer-Based Reinforcement Learning for Autonomous Orbital Collision Avoidance in Partially Observable Environments](https://arxiv.org/abs/2602.06088)
*Thomas Georges,Adam Abdin*

Main category: cs.RO

TL;DR: 提出了一种基于Transformer的强化学习框架，用于自主轨道碰撞规避，该框架能够处理部分可观测性和不完美的监测。


<details>
  <summary>Details</summary>
Motivation: 空间操作中存在部分可观测性和不完美的监测问题，这影响了自主轨道碰撞规避的可靠性。

Method: 结合了可配置的遭遇模拟器、距离相关的观测模型和序列状态估计器来表示相对运动中的不确定性，并采用了基于Transformer的部分可观测马尔可夫决策过程（POMDP）架构，利用长期时间注意力来更有效地处理嘈杂和间歇性的观测。

Result: Transformer架构能够比传统架构更有效地解释嘈杂和间歇性的观测。

Conclusion: 该框架为在不完美的监测环境下更可靠地运行碰撞规避代理提供了基础。

Abstract: We introduce a Transformer-based Reinforcement Learning framework for autonomous orbital collision avoidance that explicitly models the effects of partial observability and imperfect monitoring in space operations. The framework combines a configurable encounter simulator, a distance-dependent observation model, and a sequential state estimator to represent uncertainty in relative motion. A central contribution of this work is the use of transformer-based Partially Observable Markov Decision Process (POMDP) architecture, which leverage long-range temporal attention to interpret noisy and intermittent observations more effectively than traditional architectures. This integration provides a foundation for training collision avoidance agents that can operate more reliably under imperfect monitoring environments.

</details>


### [165] [Active Localization of Unstable Systems with Coarse Information](https://arxiv.org/abs/2602.06191)
*Ege Yuceel,Daniel Liberzon,Sayan Mitra*

Main category: cs.RO

TL;DR: 本文研究了在粗粒度、单比特传感下，不稳定系统的定位与控制问题，并提出了一种结合基于集合的估计器和Voronoi分区控制策略的主动定位算法，该算法能保证初始状态的不确定性呈指数收敛。


<details>
  <summary>Details</summary>
Motivation: 研究不稳定的系统在粗粒度、单比特传感下的基本局限性。

Method: 提出一种主动定位算法，该算法整合了基于集合的估计器和源自Voronoi分区的控制策略。

Result: 在推导出的条件下，该算法能够保证初始状态的不确定性呈指数收敛。

Conclusion: 该研究为机器人领域中传感受限（如关键帧、分割或线特征）的定位问题提供了理论见解。

Abstract: We study localization and control for unstable systems under coarse, single-bit sensing. Motivated by understanding the fundamental limitations imposed by such minimal feedback, we identify sufficient conditions under which the initial state can be recovered despite instability and extremely sparse measurements. Building on these conditions, we develop an active localization algorithm that integrates a set-based estimator with a control strategy derived from Voronoi partitions, which provably estimates the initial state while ensuring the agent remains in informative regions. Under the derived conditions, the proposed approach guarantees exponential contraction of the initial-state uncertainty, and the result is further supported by numerical experiments. These findings can offer theoretical insight into localization in robotics, where sensing is often limited to coarse abstractions such as keyframes, segmentations, or line-based features.

</details>


### [166] [Bioinspired Kirigami Capsule Robot for Minimally Invasive Gastrointestinal Biopsy](https://arxiv.org/abs/2602.06207)
*Ruizhou Zhao,Yichen Chu,Shuwei Zhao,Wenchao Yue,Raymond Shing-Yan Tang,Hongliang Ren*

Main category: cs.RO

TL;DR: 本研究提出了一种名为 Kiri-Capsule 的可吞咽微创活检胶囊机器人，它利用 kirigami 原理和机械臂实现组织采集，可用于胃肠道疾病的诊断。


<details>
  <summary>Details</summary>
Motivation: 目前无线胶囊内窥镜（WCE）无法进行活检，而传统的活检方法创伤大、范围有限，存在安全隐患，因此需要开发一种可吞咽的、微创的、能够采集组织样本进行病理分析的解决方案。

Method: Kiri-Capsule 结合了 kirigami 结构和双凸轮驱动机制。在内窥镜运动过程中，其表面的 PI 膜保持平坦；当凸轮驱动伸展时，PI 膜变形为锋利的突起，能够刺入并刮取组织。采集到的样本被保存在内部的扇形腔内。

Result: 台架测试表明 PI 膜具有约 20 MPa 的杨氏模量，且在 15% 应变下可稳定展开至约 34°。离体猪组织研究显示，Kiri-Capsule 的穿透深度在安全范围内（中位数约 0.61 mm），采集的组织样本量与标准活检钳相当（胃部平均约 10.9 mg，肠部平均约 18.9 mg）。

Conclusion: Kiri-Capsule 成功地将无创成像与功能性活检结合起来，提供了一种可吞咽、深度可控且准备好进行组织病理学分析的解决方案，有望安全有效地应用于临床胶囊诊断。

Abstract: Wireless capsule endoscopy (WCE) has transformed gastrointestinal (GI) diagnostics by enabling noninvasive visualization of the digestive tract, yet its diagnostic yield remains constrained by the absence of biopsy capability, as histological analysis is still the gold standard for confirming disease. Conventional biopsy using forceps, needles, or rotating blades is invasive, limited in reach, and carries risks of perforation or mucosal trauma, while fluid- or microbiota-sampling capsules cannot provide structured tissue for pathology, leaving a critical gap in swallowable biopsy solutions. Here we present the Kiri-Capsule, a kirigami-inspired capsule robot that integrates deployable PI-film flaps actuated by a compact dual-cam mechanism to achieve minimally invasive and repeatable tissue collection. The kirigami surface remains flat during locomotion but transforms into sharp protrusions upon cam-driven stretching, enabling controlled penetration followed by rotary scraping, with specimens retained in internal fan-shaped cavities. Bench tests confirmed that PI films exhibit a Young's modulus of approximately 20 MPa and stable deployment angles (about 34$^\circ$ at 15% strain), while ex vivo porcine studies demonstrated shallow penetration depths (median $\sim$0.61 mm, range 0.46--0.66 mm) and biopsy yields comparable to standard forceps (mean $\sim$10.9 mg for stomach and $\sim$18.9 mg for intestine), with forces within safe ranges reported for GI biopsy. These findings demonstrate that the Kiri-Capsule bridges passive imaging and functional biopsy, providing a swallowable, depth-controlled, and histology-ready solution that advances capsule-based diagnostics toward safe and effective clinical application.

</details>


### [167] [Coupled Local and Global World Models for Efficient First Order RL](https://arxiv.org/abs/2602.06219)
*Joseph Amigo,Rooholla Khorrambakht,Nicolas Mansard,Ludovic Righetti*

Main category: cs.RO

TL;DR: 本文提出了一种在数据驱动的世界模型内部训练强化学习策略的方法，用于解决依赖于传统物理模拟器难以建模的任务，尤其是在图像空间中。该方法利用解耦的一阶梯度（FoG）技术，结合了能够生成准确前向轨迹的完整世界模型和用于高效梯度计算的轻量级潜在空间代理模型。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在处理复杂的动力学（如接触和非刚性）以及视觉感知等复杂传感器信息时，依赖于标准模拟器，这些模拟器在这些情况下表现不佳。同时，世界模型虽然能更真实地捕捉这些复杂情况，但计算成本高昂，不适合流行的强化学习方法。因此，研究者希望找到一种方法，能够绕过传统的模拟器，直接在学习到的世界模型中训练强化学习策略，以解决难以建模的强化学习任务。

Method: 该方法在完全由机器人与真实环境交互学习到的世界模型内部训练强化学习策略。核心在于利用新颖的解耦一阶梯度（FoG）方法，通过大规模扩散模型实现策略训练。具体来说，一个完整的世界模型负责生成准确的前向轨迹，而一个轻量级的潜在空间代理模型则近似其局部动力学，以实现高效的梯度计算。这种局部和全局世界模型的耦合，保证了高保真度的前向展开和计算上可行的微分。

Result: 在“推-抓取”操纵任务上，该方法显著优于PPO，在样本效率方面表现更佳。此外，该方法还在一个以四足机器人为中心的物体操纵任务上进行了评估，证明了其在图像空间中解决难以建模的强化学习任务的潜力。

Conclusion: 在数据驱动的世界模型内部进行学习是在图像空间中解决难以建模的强化学习任务的一个有前景的途径，并且无需依赖手工设计的物理模拟器。该方法通过FoG技术有效地解决了世界模型高计算成本的问题，为更复杂的机器人任务提供了新的解决方案。

Abstract: World models offer a promising avenue for more faithfully capturing complex dynamics, including contacts and non-rigidity, as well as complex sensory information, such as visual perception, in situations where standard simulators struggle. However, these models are computationally complex to evaluate, posing a challenge for popular RL approaches that have been successfully used with simulators to solve complex locomotion tasks but yet struggle with manipulation. This paper introduces a method that bypasses simulators entirely, training RL policies inside world models learned from robots' interactions with real environments. At its core, our approach enables policy training with large-scale diffusion models via a novel decoupled first-order gradient (FoG) method: a full-scale world model generates accurate forward trajectories, while a lightweight latent-space surrogate approximates its local dynamics for efficient gradient computation. This coupling of a local and global world model ensures high-fidelity unrolling alongside computationally tractable differentiation. We demonstrate the efficacy of our method on the Push-T manipulation task, where it significantly outperforms PPO in sample efficiency. We further evaluate our approach through an ego-centric object manipulation task with a quadruped. Together, these results demonstrate that learning inside data-driven world models is a promising pathway for solving hard-to-model RL tasks in image space without reliance on hand-crafted physics simulators.

</details>


### [168] [A Dialogue-Based Human-Robot Interaction Protocol for Wheelchair and Robotic Arm Integrated Control](https://arxiv.org/abs/2602.06243)
*Guangping Liu,Nicholas Hawkins,Billy Madden,Tipu Sultan,Madi Babaiasl*

Main category: cs.RO

TL;DR: 本研究提出了一种基于自然对话的人机交互协议，用于控制轮椅和机器人手臂，以提高下肢和上肢残疾人士的行动能力和独立性，并在试点研究中取得了积极的反馈。


<details>
  <summary>Details</summary>
Motivation: 现有的辅助设备接口（如触摸屏和预设语音命令）不够直观，难以捕捉用户复杂意图，因此需要更自然、更智能的交互方式。

Method: 设计了一个模拟智能助手的对话式人机交互协议，允许用户通过自然语言与轮椅和机器人手臂进行交流，以理解意图并执行辅助任务。通过招募五名参与者，让他们完成五项辅助任务（清洁、饮水、进食、开抽屉、开门），并与手动控制进行比较，收集反馈。

Result: 试点研究结果显示，参与者普遍喜欢基于对话的交互方式和助手机器人的自主性。

Conclusion: 基于对话的交互协议是一种有前途的辅助技术，能够提高残疾人士的独立性和生活质量，并且在用户体验方面表现出色。

Abstract: People with lower and upper body disabilities can benefit from wheelchairs and robotic arms to improve mobility and independence. Prior assistive interfaces, such as touchscreens and voice-driven predefined commands, often remain unintuitive and struggle to capture complex user intent. We propose a natural, dialogue based human robot interaction protocol that simulates an intelligent agent capable of communicating with users to understand intent and execute assistive actions. In a pilot study, five participants completed five assistive tasks (cleaning, drinking, feeding, drawer opening, and door opening) through dialogue-based interaction with a wheelchair and robotic arm. As a baseline, participants were required to open a door using the manual control (a wheelchair joystick and a game controller for the arm) and complete a questionnaire to gather their feedback. By analyzing the post-study questionnaires, we found that most participants enjoyed the dialogue-based interaction and assistive robot autonomy.

</details>


### [169] [MORPH Wheel: A Passive Variable-Radius Wheel Embedding Mechanical Behavior Logic for Input-Responsive Transformation](https://arxiv.org/abs/2602.06265)
*JaeHyung Jang,JuYeong Seo,Dae-Young Lee,Jee-Hwan Ryu*

Main category: cs.RO

TL;DR: 本文提出了一种名为MORPH的全被动式可变半径轮，它能够根据输入的扭矩自动调整半径，无需任何传感器、执行器或主动控制。该轮设计巧妙，实现了双向驱动、高扭矩传输和可控的传动比。


<details>
  <summary>Details</summary>
Motivation: 传统的可变传动系统依赖于复杂的电子元件和控制系统，这限制了其在某些环境下的应用。研究动机是开发一种全被动、机械集成智能的传动系统，能够自主适应环境变化。

Method: 设计并制造了一种名为MORPH的轮子，其核心在于一个扭矩响应耦合器和弹簧加载的连接支柱，利用其几何形状和弹性结构，根据输入扭矩在80mm和45mm之间被动地调整半径。开发了分析模型来描述其机械行为逻辑，并进行了实验验证和机器人平台演示。

Result: 实验表明，MORPH轮的扭矩-半径和力-位移特性符合理论预测。在不同负载、斜坡和复杂地形的机器人演示中，MORPH轮能够被动调整半径以提供最优传动比。

Conclusion: MORPH轮是一种创新的、全被动的可变半径轮，通过机械编程实现了智能的、与上下文相关的行为。它为在不可预测或控制受限环境中运行的机器人提供了新的被动可变传动和机械智能范式。

Abstract: This paper introduces the Mechacnially prOgrammed Radius-adjustable PHysical (MORPH) wheel, a fully passive variable-radius wheel that embeds mechanical behavior logic for torque-responsive transformation. Unlike conventional variable transmission systems relying on actuators, sensors, and active control, the MORPH wheel achieves passive adaptation solely through its geometry and compliant structure. The design integrates a torque-response coupler and spring-loaded connecting struts to mechanically adjust the wheel radius between 80 mm and 45 mm in response to input torque, without any electrical components. The MORPH wheel provides three unique capabilities rarely achieved simultaneously in previous passive designs: (1) bidirectional operation with unlimited rotation through a symmetric coupler; (2) high torque capacity exceeding 10 N with rigid power transmission in drive mode; and (3) precise and repeatable transmission ratio control governed by deterministic kinematics. A comprehensive analytical model was developed to describe the wheel's mechanical behavior logic, establishing threshold conditions for mode switching between direct drive and radius transformation. Experimental validation confirmed that the measured torque-radius and force-displacement characteristics closely follow theoretical predictions across wheel weights of 1.8-2.8kg. Robot-level demonstrations on varying loads (0-25kg), slopes, and unstructured terrains further verified that the MORPH wheel passively adjusts its radius to provide optimal transmission ratio. The MORPH wheel exemplifies a mechanically programmed structure, embedding intelligent, context-dependent behavior directly into its physical design. This approach offers a new paradigm for passive variable transmission and mechanical intelligence in robotic mobility systems operating in unpredictable or control-limited environments.

</details>


### [170] [A High-Fidelity Robotic Manipulator Teleoperation Framework for Human-Centered Augmented Reality Evaluation](https://arxiv.org/abs/2602.06273)
*Harsh Chhajed,Tian Guo*

Main category: cs.RO

TL;DR: 本文提出了ARBot，一个用于AR系统评估的实时遥操作平台，通过机器人机械臂精确复现人类运动，以解决人类运动不稳定性导致的地面真实运动获取难题。


<details>
  <summary>Details</summary>
Motivation: 在验证增强现实（AR）追踪和交互模型时，需要精确、可重复的地面真实运动数据。然而，人类运动固有的生物力学变异性导致无法稳定地执行一致的运动。机器人机械臂被认为是模仿人类运动的理想代理。

Method: ARBot平台包含两种运动捕捉模型：通过自定义的计算机视觉（CV）和惯性测量单元（IMU）流水线稳定地捕捉手腕运动；通过移动应用程序实现自然的六自由度（6-DOF）控制。设计了一个主动安全的二次规划（QP）控制器，以确保机器人机械臂平滑、无抖动地执行运动。

Result: ARBot能够有效地捕捉自然人类运动，并通过机器人机械臂精确地重放这些运动。平台能够作为高保真的记录和重放物理代理。此外，研究者开源了ARBot平台，并发布了一个包含132条人类和合成轨迹的基准数据集，以支持可控且可扩展的AR评估。

Conclusion: ARBot平台成功地为AR系统的评估提供了一种解决方案，通过机器人机械臂精确复现人类运动，克服了人类运动不稳定性带来的挑战，并开源了平台和数据集以促进AR研究。

Abstract: Validating Augmented Reality (AR) tracking and interaction models requires precise, repeatable ground-truth motion. However, human users cannot reliably perform consistent motion due to biomechanical variability. Robotic manipulators are promising to act as human motion proxies if they can mimic human movements. In this work, we design and implement ARBot, a real-time teleoperation platform that can effectively capture natural human motion and accurately replay the movements via robotic manipulators. ARBot includes two capture models: stable wrist motion capture via a custom CV and IMU pipeline, and natural 6-DOF control via a mobile application. We design a proactively-safe QP controller to ensure smooth, jitter-free execution of the robotic manipulator, enabling it to function as a high-fidelity record and replay physical proxy. We open-source ARBot and release a benchmark dataset of 132 human and synthetic trajectories captured using ARBot to support controllable and scalable AR evaluation.

</details>


### [171] [Dynamic Motion/Force Control of Mobile Manipulators via Extended-UDE](https://arxiv.org/abs/2404.00443)
*Songqun Gao,Wendi Ding,Maotong Cheng,Qinyuan Ren,Ben M. Chen*

Main category: cs.RO

TL;DR: 本文提出了一种集成动力学耦合的移动机械臂模型和扩展不确定性与扰动估计器（UDE），以改进在移动基座动态运动时的机器人-环境交互性能。


<details>
  <summary>Details</summary>
Motivation: 移动机械臂在智能工业和家庭服务领域具有巨大潜力，但其移动基座和机械臂之间的动力学耦合对力交互任务构成了挑战，现有策略通常忽略了这种耦合。

Method: 提出了一种仅需机械臂动力学和移动基座运动学的动力学耦合集成机械臂模型。在此基础上，设计了一个扩展UDE，分别估计动力学耦合项和其他未建模的不确定性，并将它们集成到前馈和反馈控制中。

Result: 所提出的方法提高了系统的响应速度和机器人-环境交互（REI）性能。仿真和实验结果表明，该方法显著提高了在移动基座动态运动时的运动/力跟踪性能。

Conclusion: 该研究成功地通过集成动力学耦合和改进的UDE，有效地解决了移动机械臂在动态运动时的力交互控制问题，并验证了其在实际应用中的有效性。

Abstract: Mobile manipulators are known for their superior mobility over manipulators on fixed bases, offering promising applications in smart industry and housekeeping scenarios. The dynamic coupling nature between the mobile base and the manipulator presents challenges for force interactive tasks of the mobile manipulator. However, current strategies often fail to account for this coupling in such scenarios. To address this, this paper presents a dynamic coupling-integrated manipulator model that requires only the manipulator dynamics and the mobile base kinematics, which simplifies the modeling process. In addition, embedding the dynamic model, an extended uncertainty and disturbance estimator (UDE) is proposed for the mobile manipulator, which separately estimates the dynamic coupling terms and other unmodeled uncertainties, incorporating them into the feedforward and feedback control loops, respectively. The proposed approach increases the speed of response of the system and improves the dynamic robot-environment interaction (REI) performance of the mobile manipulator. A series of simulations and experiments of a wall-cleaning task are conducted to verify the effectiveness of the proposed approach. Ablation studies demonstrate that the proposed approach significantly improves the motion/force tracking performance when the mobile base is in dynamic motion.

</details>


### [172] [Robots That Generate Planarity Through Geometry](https://arxiv.org/abs/2602.06294)
*Jakub F. Kowalewski,Abdulaziz O. Alrashed,Jacob Alpert,Rishi Ponnapalli,Lucas R. Meza,Jeffrey Ian Lipton*

Main category: cs.RO

TL;DR: 该研究提出了一种基于球体到平面几何逆变换的平面运动机制（FPM），该机制通过连杆长度和连接性实现平面运动，无需外部测量，并能将制造误差降低一个数量级。


<details>
  <summary>Details</summary>
Motivation: 当前的精密机器人运动系统依赖于部件的平面度，但这需要精确的内部对齐和高精度组件，导致长且易受误差影响的参考链。因此，需要一种新的方法来构建平面运动系统。

Method: 利用球体到平面几何逆变换的原理，设计出平面运动机制（FPM），使其平面运动直接由连杆长度和连接性决定，实现自参考几何约束。

Result: 研究人员演示了从微米到米尺度的FPM，并证明其制造误差可以降低一个数量级。此外，他们还开发了一个基于FPM的三轴定位系统，可用于计量表面扫描（±12 mm）和狭窄容器内的3D打印。

Conclusion: FPMs提供了一种新的几何基础来实现平面运动，该基础在不同尺寸范围内均可实现，并在计量、制造和微定位领域开辟了新的可能性。

Abstract: Constraining motion to a flat surface is a fundamental requirement for equipment across science and engineering. Modern precision robotic motion systems, such as gantries, rely on the flatness of components, including guide rails and granite surface plates. However, translating this static flatness into motion requires precise internal alignment and tight-tolerance components that create long, error-sensitive reference chains. Here, we show that by using the geometric inversion of a sphere into a plane, we can produce robotic motion systems that derive planarity entirely from link lengths and connectivity. This allows planar motion to emerge from self-referencing geometric constraints, and without external metrology. We demonstrate these Flat-Plane Mechanisms (FPMs) from micron to meter scales and show that fabrication errors can be attenuated by an order of magnitude in the resulting flatness. Finally, we present a robotic FPM-based 3-axis positioning system that can be used for metrology surface scans ($\pm 12$-mm) and 3D printing inside narrow containers. This work establishes an alternative geometric foundation for planar motion that can be realized across size scales and opens new possibilities in metrology, fabrication, and micro-positioning.

</details>


### [173] [Internalized Morphogenesis: A Self-Organizing Model for Growth, Replication, and Regeneration via Local Token Exchange in Modular Systems](https://arxiv.org/abs/2602.06296)
*Takeshi Ishida*

Main category: cs.RO

TL;DR: 提出了一种基于内部信息交互的形态发生模型，用于在资源受限的自主系统中实现复杂形态生成，无需外部空间计算。


<details>
  <summary>Details</summary>
Motivation: 现有自组织模型需要全局空间计算，不适用于资源受限的物理模块；旨在开发一种仅依赖局部交互的、更具计算效率和生物学合理性的模型。

Method: 通过扩展“Ishida token model”，利用离散整数值交换和基于 RD 的模型，模拟了模块间的局部交互，引入内部势能（基于 token 积累和老化）来驱动形态变化，并利用身体边界作为信息熵的自然汇聚点。

Result: 通过在六边形网格上的模拟，成功实现了肢体状延伸、自我分裂和结构损伤后的鲁棒再生能力。

Conclusion: 复杂的形态行为可以从极简的、纯内部规则中涌现，该模型为开发自修复、自适应和自主硬件提供了一种计算高效且生物学上可行的方法。

Abstract: This study presents an internalized morphogenesis model for autonomous systems, such as swarm robotics and micro-nanomachines, that eliminates the need for external spatial computation. Traditional self-organizing models often require calculations across the entire coordinate space, including empty areas, which is impractical for resource-constrained physical modules. Our proposed model achieves complex morphogenesis through strictly local interactions between adjacent modules within the "body." By extending the "Ishida token model," modules exchange integer values using an RD-inspired discrete analogue without solving differential equations. The internal potential, derived from token accumulation and aging, guides autonomous growth, shrinkage, and replication. Simulations on a hexagonal grid demonstrated the emergence of limb-like extensions, self-division, and robust regeneration capabilities following structural amputation. A key feature is the use of the body boundary as a natural sink for information entropy (tokens) to maintain a dynamic equilibrium. These results indicate that sophisticated morphological behaviors can emerge from minimal, internal-only rules. This framework offers a computationally efficient and biologically plausible approach to developing self-repairing, adaptive, and autonomous hardware.

</details>


### [174] [Nipping the Drift in the Bud: Retrospective Rectification for Robust Vision-Language Navigation](https://arxiv.org/abs/2602.06356)
*Gang He,Zhenyang Liu,Kepeng Xu,Li Xu,Tong Qiao,Wenxin Yu,Chang Wu,Weiying Xie*

Main category: cs.RO

TL;DR: 本文提出了一种名为BudVLN的在线学习框架，通过回溯纠正和条件化监督合成来解决现有视觉语言导航（VLN）方法中的指令-状态不匹配问题，并在R2R-CE和RxR-CE数据集上取得了最新的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法在模仿学习中存在暴露偏差，即推理过程中的微小偏差会导致累积错误。尽管DAgger类方法尝试纠正错误状态，但忽略了指令-状态不匹配问题，即从偏离轨迹的状态学习恢复动作会产生与原始指令语义冲突的监督信号。

Method: BudVLN是一个在线框架，通过构建与当前状态分布匹配的监督信号来进行回溯纠正。它利用反事实重新锚定和决策条件化监督合成，并通过测地线预言家合成起源于有效历史状态的纠正轨迹，以确保语义一致性。

Result: BudVLN能够有效缓解分布偏移问题，并在R2R-CE和RxR-CE基准测试中，在成功率（Success Rate）和SPL（Success weighted by Path Length）两项指标上均达到了最先进的性能。

Conclusion: BudVLN通过解决指令-状态不匹配问题，有效地改善了VLN的性能，证明了在线学习框架和新颖的监督信号合成方法在解决暴露偏差和提高导航准确性方面的有效性。

Abstract: Vision-Language Navigation (VLN) requires embodied agents to interpret natural language instructions and navigate through complex continuous 3D environments. However, the dominant imitation learning paradigm suffers from exposure bias, where minor deviations during inference lead to compounding errors. While DAgger-style approaches attempt to mitigate this by correcting error states, we identify a critical limitation: Instruction-State Misalignment. Forcing an agent to learn recovery actions from off-track states often creates supervision signals that semantically conflict with the original instruction. In response to these challenges, we introduce BudVLN, an online framework that learns from on-policy rollouts by constructing supervision to match the current state distribution. BudVLN performs retrospective rectification via counterfactual re-anchoring and decision-conditioned supervision synthesis, using a geodesic oracle to synthesize corrective trajectories that originate from valid historical states, ensuring semantic consistency. Experiments on the standard R2R-CE and RxR-CE benchmarks demonstrate that BudVLN consistently mitigates distribution shift and achieves state-of-the-art performance in both Success Rate and SPL.

</details>


### [175] [Action Hallucination in Generative Visual-Language-Action Models](https://arxiv.org/abs/2602.06339)
*Harold Soh,Eugene Lim*

Main category: cs.RO

TL;DR: 研究了视觉-语言-动作（VLA）模型在机器人策略训练中的“幻觉”问题，即机器人生成了违反物理约束或导致任务失败的动作。发现这些幻觉源于模型结构与机器人实际行为之间的不匹配，并提出了三种主要的障碍：拓扑、精度和视野，它们会带来不可避免的权衡。这项研究为理解和改进生成式机器人策略的可靠性和可信度提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 尽管基于VLA的模型在机器人领域取得了显著进展，但它们是否真正解决了机器人领域长期存在的挑战（如动作幻觉和计划失败）仍然不清楚。作者希望深入分析这些问题，并找到改进方法。

Method: 通过分析违反物理约束的动作幻觉及其在计划层面的扩展，作者聚焦于潜变量生成策略。他们研究了三种结构性障碍：拓扑、精度和视野，并展示了它们如何导致不可避免的权衡。通过建立模型结构与机器人行为之间的联系，来解释和预测幻觉的发生。

Result: 研究表明，动作幻觉常常源于机器人可行的行为与常见模型架构之间的结构不匹配。分析揭示了拓扑、精度和视野这三个关键障碍，并指出了它们在改善机器人策略可靠性和可信度方面，如何在不牺牲表达能力的前提下，提供改进的方向。

Conclusion: 视觉-语言-动作模型在机器人领域存在固有的挑战，即“幻觉”问题。这些问题根源于模型架构与机器人实际行为之间的结构性不匹配。通过理解这些障碍（拓扑、精度、视野）及其带来的权衡，可以为开发更可靠、更值得信赖的生成式机器人策略提供指导。

Abstract: Robot Foundation Models such as Vision-Language-Action models are rapidly reshaping how robot policies are trained and deployed, replacing hand-designed planners with end-to-end generative action models. While these systems demonstrate impressive generalization, it remains unclear whether they fundamentally resolve the long-standing challenges of robotics. We address this question by analyzing action hallucinations that violate physical constraints and their extension to plan-level failures. Focusing on latent-variable generative policies, we show that hallucinations often arise from structural mismatches between feasible robot behavior and common model architectures. We study three such barriers -- topological, precision, and horizon -- and show how they impose unavoidable tradeoffs. Our analysis provides mechanistic explanations for reported empirical failures of generative robot policies and suggests principled directions for improving reliability and trustworthiness, without abandoning their expressive power.

</details>


### [176] [A Consistency-Improved LiDAR-Inertial Bundle Adjustment](https://arxiv.org/abs/2602.06380)
*Xinran Li,Shuaikang Zheng,Pengcheng Zheng,Xinyang Wang,Jiacheng Li,Zhitian Li,Xudong Zou*

Main category: cs.RO

TL;DR: 提出了一种改进的激光雷达-惯性视觉SLAM的捆绑调整方法，通过使用新的特征表示和MAP-FEJ估计器，提高了估计的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于特征的激光雷达SLAM系统在特征参数化和协方差估计方面存在不一致的问题，影响了导航的准确性。

Method: 提出了使用球极投影表示方法来参数化平面和边缘特征，并进行了可观性分析。实现了基于最大后验（MAP）和第一估计雅可比（FEJ）的激光雷达-惯性捆绑调整，以保持估计协方差和可观性。

Result: 所提出的方法应用于激光雷达-惯性里程计，并能够保持准确的估计协方差和可观性。

Conclusion: 该研究提出了一种更一致的激光雷达-惯性捆绑调整方法，通过改进的特征表示和MAP-FEJ估计器，有望提高自动驾驶导航系统的性能。

Abstract: Simultaneous Localization and Mapping (SLAM) using 3D LiDAR has emerged as a cornerstone for autonomous navigation in robotics. While feature-based SLAM systems have achieved impressive results by leveraging edge and planar structures, they often suffer from the inconsistent estimator associated with feature parameterization and estimated covariance. In this work, we present a consistency-improved LiDAR-inertial bundle adjustment (BA) with tailored parameterization and estimator. First, we propose a stereographic-projection representation parameterizing the planar and edge features, and conduct a comprehensive observability analysis to support its integrability with consistent estimator. Second, we implement a LiDAR-inertial BA with Maximum a Posteriori (MAP) formulation and First-Estimate Jacobians (FEJ) to preserve the accurate estimated covariance and observability properties of the system. Last, we apply our proposed BA method to a LiDAR-inertial odometry.

</details>


### [177] [HiWET: Hierarchical World-Frame End-Effector Tracking for Long-Horizon Humanoid Loco-Manipulation](https://arxiv.org/abs/2602.06341)
*Zhanxiang Cao,Liyun Yan,Yang Zhang,Sirui Chen,Jianming Ma,Tianyue Zhan,Shengcheng Fu,Yufei Jia,Cewu Lu,Yue Gao*

Main category: cs.RO

TL;DR: 提出了一种名为HiWET的层次化强化学习框架，通过在世界坐标系下进行末端执行器跟踪，解决了人形机器人运动-操作中的累积世界坐标漂移问题，并通过运动学流形先验（KMP）提升了训练效率和稳定性，在仿真和真实机器人上均取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人运动-操作方法通常在以身体为中心的坐标系下进行任务规划，在执行过程中容易因 the legged locomotion 导致累积的世界坐标漂移，影响末端执行器的精度和整体稳定性。

Method: 提出了HiWET（Hierarchical World-frame End-effector Tracking）框架，采用层次化强化学习，将问题分解为全局规划和动态执行。高层策略在世界坐标系下生成优化末端执行器精度和机器人基座位置的子目标；低层策略在稳定性约束下执行这些指令。引入了运动学流形先验（KMP），通过残差学习将操作流形嵌入动作空间，降低了探索维度并避免了运动学上无效的行为。

Result: HiWET在长时域的世界坐标系任务中实现了精确且稳定的末端执行器跟踪。低层策略的零样本仿真到真实迁移在物理人形机器人上得到了验证，机器人在接受各种操作指令时表现出稳定的运动能力。

Conclusion: 显式地在世界坐标系下进行推理，并结合层次化控制，是解决长时域人形机器人运动-操作问题的有效且可扩展的解决方案。

Abstract: Humanoid loco-manipulation requires executing precise manipulation tasks while maintaining dynamic stability amid base motion and impacts. Existing approaches typically formulate commands in body-centric frames, fail to inherently correct cumulative world-frame drift induced by legged locomotion. We reformulate the problem as world-frame end-effector tracking and propose HiWET, a hierarchical reinforcement learning framework that decouples global reasoning from dynamic execution. The high-level policy generates subgoals that jointly optimize end-effector accuracy and base positioning in the world frame, while the low-level policy executes these commands under stability constraints. We introduce a Kinematic Manifold Prior (KMP) that embeds the manipulation manifold into the action space via residual learning, reducing exploration dimensionality and mitigating kinematically invalid behaviors. Extensive simulation and ablation studies demonstrate that HiWET achieves precise and stable end-effector tracking in long-horizon world-frame tasks. We validate zero-shot sim-to-real transfer of the low-level policy on a physical humanoid, demonstrating stable locomotion under diverse manipulation commands. These results indicate that explicit world-frame reasoning combined with hierarchical control provides an effective and scalable solution for long-horizon humanoid loco-manipulation.

</details>


### [178] [Force Generative Imitation Learning: Bridging Position Trajectory and Force Commands through Control Technique](https://arxiv.org/abs/2602.06620)
*Hiroshi Sato,Sho Sakaino,Toshiaki Tsuji*

Main category: cs.RO

TL;DR: 本文提出了一种从位置轨迹生成机器人接触任务中力的模型，并通过反馈控制提高了对未知轨迹的泛化能力，最终在机器人写作任务上取得了改进。


<details>
  <summary>Details</summary>
Motivation: 在机器人接触任务中，位置轨迹易得但力的指令未知。现有的基于基础模型的力生成方法受限于特定硬件，泛化能力不足，尤其是在处理未见过的位置轨迹时。

Method: 提出了一种从位置轨迹估计力指令的生成模型。为了解决模型对未知轨迹的泛化问题，引入了反馈控制机制。实验发现，带记忆的模型无法稳定进行反馈控制，因此采用无记忆模型，实现了稳定的反馈控制。

Result: 在机器人写作任务上，所提出的模型（结合无记忆生成模型和反馈控制）能够有效地生成力指令，即使对于未见过的位置轨迹，也表现出比基线方法更好的泛化能力。

Conclusion: 通过结合一个无记忆的力生成模型和一个反馈控制机制，可以实现对机器人接触任务中未知位置轨迹的有效力指令生成，提高了模型的泛化能力，尤其适用于机器人写作等实际应用。

Abstract: In contact-rich tasks, while position trajectories are often easy to obtain, appropriate force commands are typically unknown. Although it is conceivable to generate force commands using a pretrained foundation model such as Vision-Language-Action (VLA) models, force control is highly dependent on the specific hardware of the robot, which makes the application of such models challenging. To bridge this gap, we propose a force generative model that estimates force commands from given position trajectories. However, when dealing with unseen position trajectories, the model struggles to generate accurate force commands. To address this, we introduce a feedback control mechanism. Our experiments reveal that feedback control does not converge when the force generative model has memory. We therefore adopt a model without memory, enabling stable feedback control. This approach allows the system to generate force commands effectively, even for unseen position trajectories, improving generalization for real-world robot writing tasks.

</details>


### [179] [Towards Adaptive Environment Generation for Training Embodied Agents](https://arxiv.org/abs/2602.06366)
*Teresa Yeo,Dulaj Weerakoon,Dulanga Weerakoon,Archan Misra*

Main category: cs.RO

TL;DR: 提出了一种闭环环境生成方法，通过根据代理的性能动态调整环境难度来提高代理的学习效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的开放式环境生成方法效率低下，因为它们不考虑代理的当前性能，导致生成的环境可能过于简单，提供的学习信号有限。

Method: 使用可控的环境表示，提取超越二元成功/失败的精细性能反馈，并实现一个闭环适应机制，将反馈转化为环境修改。

Result: 闭环方法生成的训练环境在代理需要改进的方面更具挑战性，从而提高了学习效率和对新环境的泛化能力。

Conclusion: 闭环环境生成是一种更有效的方法，可以为代理创建具有挑战性的训练场景，从而促进更快的学习和更好的泛化。

Abstract: Embodied agents struggle to generalize to new environments, even when those environments share similar underlying structures to their training settings. Most current approaches to generating these training environments follow an open-loop paradigm, without considering the agent's current performance. While procedural generation methods can produce diverse scenes, diversity without feedback from the agent is inefficient. The generated environments may be trivially easy, providing limited learning signal. To address this, we present a proof-of-concept for closed-loop environment generation that adapts difficulty to the agent's current capabilities. Our system employs a controllable environment representation, extracts fine-grained performance feedback beyond binary success or failure, and implements a closed-loop adaptation mechanism that translates this feedback into environment modifications. This feedback-driven approach generates training environments that more challenging in the ways the agent needs to improve, enabling more efficient learning and better generalization to novel settings.

</details>


### [180] [Now You See That: Learning End-to-End Humanoid Locomotion from Raw Pixels](https://arxiv.org/abs/2602.06382)
*Wandong Sun,Yongbo Su,Leoric Huang,Alex Zhang,Dwyane Wei,Mu San,Daniel Tian,Ellie Cao,Finn Yan,Ethan Xie,Zongwu Xie*

Main category: cs.RO

TL;DR: 提出了一种端到端的视觉驱动人形机器人运动框架，通过高保真深度传感器仿真和视觉感知行为蒸馏解决 sim-to-real 差距，并通过地形特定的奖励塑形与多判别器学习实现多地形适应，在不同地形上表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 实现鲁棒的视觉驱动人形机器人运动面临两个主要挑战：sim-to-real 差距带来的感知噪声以及多样化地形训练中的学习目标冲突。

Method: 开发了高保真深度传感器仿真，捕捉真实世界传感器的立体匹配伪影和校准不确定性；提出了视觉感知行为蒸馏，结合潜空间对齐和噪声不变辅助任务；引入了地形特定的奖励塑形，并结合多判别器学习，使专用网络捕获不同地形的动力学和运动先验。

Result: 该框架在配备不同立体深度相机的两种人形机器人平台上进行了验证，展示了在各种环境中鲁棒的性能，能够应对高平台、宽缝隙等极端挑战，并能进行双向长期楼梯行走等精细任务。

Conclusion: 所提出的端到端框架通过解决 sim-to-real 差距和地形适应性问题，实现了鲁棒且通用的视觉驱动人形机器人运动。

Abstract: Achieving robust vision-based humanoid locomotion remains challenging due to two fundamental issues: the sim-to-real gap introduces significant perception noise that degrades performance on fine-grained tasks, and training a unified policy across diverse terrains is hindered by conflicting learning objectives. To address these challenges, we present an end-to-end framework for vision-driven humanoid locomotion. For robust sim-to-real transfer, we develop a high-fidelity depth sensor simulation that captures stereo matching artifacts and calibration uncertainties inherent in real-world sensing. We further propose a vision-aware behavior distillation approach that combines latent space alignment with noise-invariant auxiliary tasks, enabling effective knowledge transfer from privileged height maps to noisy depth observations. For versatile terrain adaptation, we introduce terrain-specific reward shaping integrated with multi-critic and multi-discriminator learning, where dedicated networks capture the distinct dynamics and motion priors of each terrain type. We validate our approach on two humanoid platforms equipped with different stereo depth cameras. The resulting policy demonstrates robust performance across diverse environments, seamlessly handling extreme challenges such as high platforms and wide gaps, as well as fine-grained tasks including bidirectional long-term staircase traversal.

</details>


### [181] [ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking](https://arxiv.org/abs/2602.06445)
*Weidong Huang,Jingwen Zhang,Jiongye Li,Shibowen Zhang,Jiayang Wu,Jiayi Wang,Hangxin Liu,Yaodong Yang,Yao Su*

Main category: cs.RO

TL;DR: 本文提出了一种名为ECO（Energy-Constrained Optimization）的受限强化学习框架，用于实现人形机器人稳定且节能的运动。ECO将能源相关指标作为不等式约束，而不是奖励的一部分，从而提高了效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人运动控制方法（如MPC和RL）在优化能源效率时，通常将能源指标嵌入多目标优化框架，导致需要大量的超参数调整且策略次优。因此，需要一种更有效、更直观的方法来实现节能的机器人运动。

Method: ECO框架将能源消耗和参考运动的指标重塑为显式的不等式约束，并使用拉格朗日方法来强制执行这些约束。通过将能源指标与奖励分离，ECO提供了更清晰、更易于理解的物理能耗表示，从而可以更有效地调整超参数。

Result: 在与MPC、奖励塑形的标准RL以及四种最先进的受限RL方法进行对比的实验中，ECO显著降低了能源消耗，同时保持了鲁棒的行走性能。实验包括在BRUCE人形机器人上的sim-to-sim和sim-to-real迁移。

Conclusion: ECO是一种有效的受限强化学习框架，能够显著提高人形机器人的行走能效，同时保持运动的稳定性，为实现更节能的人形机器人运动提供了新的途径。

Abstract: Achieving stable and energy-efficient locomotion is essential for humanoid robots to operate continuously in real-world applications. Existing MPC and RL approaches often rely on energy-related metrics embedded within a multi-objective optimization framework, which require extensive hyperparameter tuning and often result in suboptimal policies. To address these challenges, we propose ECO (Energy-Constrained Optimization), a constrained RL framework that separates energy-related metrics from rewards, reformulating them as explicit inequality constraints. This method provides a clear and interpretable physical representation of energy costs, enabling more efficient and intuitive hyperparameter tuning for improved energy efficiency. ECO introduces dedicated constraints for energy consumption and reference motion, enforced by the Lagrangian method, to achieve stable, symmetric, and energy-efficient walking for humanoid robots. We evaluated ECO against MPC, standard RL with reward shaping, and four state-of-the-art constrained RL methods. Experiments, including sim-to-sim and sim-to-real transfers on the kid-sized humanoid robot BRUCE, demonstrate that ECO significantly reduces energy consumption compared to baselines while maintaining robust walking performance. These results highlight a substantial advancement in energy-efficient humanoid locomotion. All experimental demonstrations can be found on the project website: https://sites.google.com/view/eco-humanoid.

</details>


### [182] [User-Centric Object Navigation: A Benchmark with Integrated User Habits for Personalized Embodied Object Search](https://arxiv.org/abs/2602.06459)
*Hongcheng Wang,Jinyu Zhu,Hao Dong*

Main category: cs.RO

TL;DR: 提出用户中心对象导航（UcON）新基准，引入用户特定对象摆放习惯，以提升机器人导航能力，并提出用户习惯检索模块。


<details>
  <summary>Details</summary>
Motivation: 现有对象导航基准未能考虑用户个体放置习惯，限制了导航机器人在个性化家庭环境中的适应性。

Method: 构建包含约22,600个用户习惯、489个对象类别的 UcON 基准；提出用户习惯检索模块，用于提取和利用目标对象的习惯信息。

Result: 现有先进方法在用户习惯驱动的对象摆放场景下性能显著下降；集成用户习惯能持续提升导航成功率。

Conclusion: 用户习惯在对象导航中起着重要作用，UcON 基准和用户习惯检索模块有助于开发更适应个性化环境的导航智能体。

Abstract: In the evolving field of robotics, the challenge of Object Navigation (ON) in household environments has attracted significant interest. Existing ON benchmarks typically place objects in locations guided by general scene priors, without accounting for the specific placement habits of individual users. This omission limits the adaptability of navigation agents in personalized household environments. To address this, we introduce User-centric Object Navigation (UcON), a new benchmark that incorporates user-specific object placement habits, referred to as user habits. This benchmark requires agents to leverage these user habits for more informed decision-making during navigation. UcON encompasses approximately 22,600 user habits across 489 object categories. UcON is, to our knowledge, the first benchmark that explicitly formalizes and evaluates habit-conditioned object navigation at scale and covers the widest range of target object categories. Additionally, we propose a habit retrieval module to extract and utilize habits related to target objects, enabling agents to infer their likely locations more effectively. Experimental results demonstrate that current SOTA methods exhibit substantial performance degradation under habit-driven object placement, while integrating user habits consistently improves success rates. Code is available at https://github.com/whcpumpkin/User-Centric-Object-Navigation.

</details>


### [183] [MultiGraspNet: A Multitask 3D Vision Model for Multi-gripper Robotic Grasping](https://arxiv.org/abs/2602.06504)
*Stephany Ortuno-Chanelo,Paolo Rabino,Enrico Civitelli,Tatiana Tommasi,Raffaello Camoriano*

Main category: cs.RO

TL;DR: MultiGraspNet是一个多任务3D深度学习模型，能够同时为并行夹爪和真空吸盘预测可行的抓取姿势，从而使单个机器人能够处理多个末端执行器，并在一系列实验中表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的机器人抓取方法要么仅限于单一夹爪，要么依赖于需要特定学习程序的定制混合夹爪，这限制了它们的通用性。本研究旨在开发一种能够处理多种末端执行器的通用方法。

Method: MultiGraspNet是一个多任务3D深度学习方法，它在GraspNet-1Billion和SuctionNet-1Billion数据集上进行训练，预测并行夹爪和真空吸盘的可行抓取姿势。它通过共享早期特征和使用特定于夹爪的精炼器来利用不同抓取模态之间的互补信息，并生成量化场景点抓取可行性的掩码。

Result: MultiGraspNet在相关基准测试中表现出与单任务模型相当的性能。在真实世界的实验中，它比仅使用真空吸盘的方法能够抓取更多已见的和新颖的物体，并且在并行抓取任务上取得了有竞争力的结果。

Conclusion: MultiGraspNet能够在一个统一的框架内处理多种抓取模态，提高了机器人抓取的鲁棒性和适应性，特别是在混乱的场景中，并证明了其在实际应用中的有效性。

Abstract: Vision-based models for robotic grasping automate critical, repetitive, and draining industrial tasks. Existing approaches are typically limited in two ways: they either target a single gripper and are potentially applied on costly dual-arm setups, or rely on custom hybrid grippers that require ad-hoc learning procedures with logic that cannot be transferred across tasks, restricting their general applicability. In this work, we present MultiGraspNet, a novel multitask 3D deep learning method that predicts feasible poses simultaneously for parallel and vacuum grippers within a unified framework, enabling a single robot to handle multiple end effectors. The model is trained on the richly annotated GraspNet-1Billion and SuctionNet-1Billion datasets, which have been aligned for the purpose, and generates graspability masks quantifying the suitability of each scene point for successful grasps. By sharing early-stage features while maintaining gripper-specific refiners, MultiGraspNet effectively leverages complementary information across grasping modalities, enhancing robustness and adaptability in cluttered scenes. We characterize MultiGraspNet's performance with an extensive experimental analysis, demonstrating its competitiveness with single-task models on relevant benchmarks. We run real-world experiments on a single-arm multi-gripper robotic setup showing that our approach outperforms the vacuum baseline, grasping 16% percent more seen objects and 32% more of the novel ones, while obtaining competitive results for the parallel task.

</details>


### [184] [World-VLA-Loop: Closed-Loop Learning of Video World Model and VLA Policy](https://arxiv.org/abs/2602.06508)
*Xiaokang Liu,Zechen Bai,Hai Ci,Kevin Yuchen Ma,Mike Zheng Shou*

Main category: cs.RO

TL;DR: 提出了一种名为World-VLA-Loop的闭环框架，用于联合优化机器人世界模型和视觉-语言-动作（VLA）策略。该框架通过一个状态感知的视频世界模型，能够预测未来观察和奖励信号，并通过SANS数据集和迭代反馈机制来提高动作遵循的精度，从而在模拟环境中对VLA策略进行强化学习后训练，最终提升机器人在模拟和现实世界中的任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人世界模型虽然能生成逼真的视觉模拟，但存在动作遵循精度差的问题，限制了其在机器人学习中的应用。因此，需要一种方法来同时改进世界模型和VLA策略，以提高机器人的动作执行能力。

Method: 1. 提出一个状态感知的视频世界模型，能够联合预测未来观察和奖励信号，充当高保真交互式模拟器。 2. 引入SANS数据集，包含近乎成功的轨迹，以改进世界模型中的动作-结果对齐。 3. 构建了一个闭环框架（World-VLA-Loop），将世界模型和VLA策略联合进行强化学习后训练。 4. 利用VLA策略生成的失败回滚来迭代地改进世界模型的精度，从而促进世界模型和策略学习的共同演进。

Result: 在模拟和现实世界任务的评估中，World-VLA-Loop框架显著提高了VLA策略的性能，同时最大限度地减少了物理交互。该框架在世界建模和策略学习之间建立了互利共生的关系，适用于通用机器人。

Conclusion: World-VLA-Loop框架通过联合优化世界模型和VLA策略，有效解决了现有世界模型动作遵循精度差的问题。该框架能够实现高效的闭环强化学习，并通过迭代反馈机制实现世界模型和策略的协同进步，为通用机器人提供了更优的解决方案。

Abstract: Recent progress in robotic world models has leveraged video diffusion transformers to predict future observations conditioned on historical states and actions. While these models can simulate realistic visual outcomes, they often exhibit poor action-following precision, hindering their utility for downstream robotic learning. In this work, we introduce World-VLA-Loop, a closed-loop framework for the joint refinement of world models and Vision-Language-Action (VLA) policies. We propose a state-aware video world model that functions as a high-fidelity interactive simulator by jointly predicting future observations and reward signals. To enhance reliability, we introduce the SANS dataset, which incorporates near-success trajectories to improve action-outcome alignment within the world model. This framework enables a closed-loop for reinforcement learning (RL) post-training of VLA policies entirely within a virtual environment. Crucially, our approach facilitates a co-evolving cycle: failure rollouts generated by the VLA policy are iteratively fed back to refine the world model precision, which in turn enhances subsequent RL optimization. Evaluations across simulation and real-world tasks demonstrate that our framework significantly boosts VLA performance with minimal physical interaction, establishing a mutually beneficial relationship between world modeling and policy learning for general-purpose robotics. Project page: https://showlab.github.io/World-VLA-Loop/.

</details>


### [185] [Beyond the Majority: Long-tail Imitation Learning for Robotic Manipulation](https://arxiv.org/abs/2602.06512)
*Junhong Zhu,Ji Zhang,Jingkuan Song,Lianli Gao,Heng Tao Shen*

Main category: cs.RO

TL;DR: 该研究分析了机器人模仿学习中数据长尾分布导致的任务泛化能力差的问题，并提出了一种名为Approaching-Phase Augmentation (APA) 的数据增强方法，通过将头部任务的知识迁移到尾部任务，提升了模型在数据稀疏任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在机器人通用策略学习中具有潜力，但训练数据中普遍存在的长尾分布（头部任务数据丰富，尾部任务数据稀疏）严重阻碍了其泛化能力，导致模型在数据稀疏的尾部任务上表现不佳。

Method: 作者首先分析了传统长尾学习策略（如重采样）在策略学习上的无效性，并揭示了数据稀疏性直接损害了策略的空间推理能力。为解决此问题，提出了一种名为Approaching-Phase Augmentation (APA) 的方法，该方法能够无需外部演示，将数据丰富头部任务的知识转移到数据稀疏的尾部任务。

Result: APA方法被证明是简单而有效的，通过在仿真和真实世界机器人操作任务中的大量实验验证了其有效性。

Conclusion: 数据长尾分布是机器人模仿学习中的一个关键挑战，直接影响了模型的空间推理和泛化能力。APA是一种有效的数据增强技术，能够缓解长尾分布带来的问题，提升模型在数据稀疏任务上的性能。

Abstract: While generalist robot policies hold significant promise for learning diverse manipulation skills through imitation, their performance is often hindered by the long-tail distribution of training demonstrations. Policies learned on such data, which is heavily skewed towards a few data-rich head tasks, frequently exhibit poor generalization when confronted with the vast number of data-scarce tail tasks. In this work, we conduct a comprehensive analysis of the pervasive long-tail challenge inherent in policy learning. Our analysis begins by demonstrating the inefficacy of conventional long-tail learning strategies (e.g., re-sampling) for improving the policy's performance on tail tasks. We then uncover the underlying mechanism for this failure, revealing that data scarcity on tail tasks directly impairs the policy's spatial reasoning capability. To overcome this, we introduce Approaching-Phase Augmentation (APA), a simple yet effective scheme that transfers knowledge from data-rich head tasks to data-scarce tail tasks without requiring external demonstrations. Extensive experiments in both simulation and real-world manipulation tasks demonstrate the effectiveness of APA. Our code and demos are publicly available at: https://mldxy.github.io/Project-VLA-long-tail/.

</details>


### [186] [Primary Experimental Feedback on a Co-manipulated Robotic System for Assisted Cervical Surgery](https://arxiv.org/abs/2602.06541)
*Seifeddine Sellemi,Abdelbadia Chaker,Tanguy Vendeuvre,Terence Essomba,Med Amine Laribi*

Main category: cs.RO

TL;DR: 本研究评估了一个协作式机器人系统在颈椎手术钻孔任务中的表现，通过测量实际钻孔轨迹与计划轨迹的偏差来评估其准确性。


<details>
  <summary>Details</summary>
Motivation: 为了改善机器人辅助手术（尤其是在颈椎手术等复杂手术中）的人体工程学、精度和效率，并了解系统在临床应用中的可靠性。

Method: 八名经验丰富的颈椎外科医生使用协作式机器人系统执行了14次钻孔。研究量化了钻孔工具的位置和方向相对于计划轨迹的偏差。

Result: 研究量化了钻孔工具的位置和方向相对于计划轨迹的偏差，虽然未在此摘要中具体给出数值，但表明研究的目的是提供系统可靠性的见解。

Conclusion: 本研究的发现将有助于颈椎机器人辅助手术的持续发展，突显其优势和需要改进的领域，以实现更安全、更高效的手术流程。该研究深入分析了共同操作的机器人系统的性能、实验设置和误差评估方法。

Abstract: Robotic-assisted surgery has emerged as a promising approach to improve surgical ergonomics, precision, and workflow efficiency, particularly in complex procedures such as cervical spine surgery. In this study, we evaluate the performance of a collaborative robotic system designed to assist surgeons in drilling tasks by assessing its accuracy in executing predefined trajectories. A total of 14 drillings were performed by eight experienced cervical surgeons, utilizing a robotic-assisted setup aimed at ensuring stability and alignment. The primary objective of this study is to quantify the deviations in the position and orientation of the drilling tool relative to the planned trajectory, providing insights into the system's reliability and potential impact on clinical outcomes. While the primary function of robotic assistance in surgery is to enhance surgeon comfort and procedural guidance rather than solely optimizing precision, understanding the system's accuracy remains crucial for its effective integration into surgical practices part of this primary experimental feedback, the study offers an in-depth analysis of the co-manipulated robotic system's performance, focusing on the experimental setup and error evaluation methods. The findings of this study will contribute to the ongoing development of robotic-assisted cervical surgery, highlighting both its advantages and areas for improvement in achieving safer and more efficient surgical workflows

</details>


### [187] [The Law of Task-Achieving Body Motion: Axiomatizing Success of Robot Manipulation Actions](https://arxiv.org/abs/2602.06572)
*Malte Huerkamp,Jonas Dech,Michael Beetz*

Main category: cs.RO

TL;DR: 本文提出了一种名为“任务达成身体运动定律”的公理化方法，用于确保自主机器人的身体运动在语义、因果和可实现性方面都符合任务要求。该方法通过引入作用域任务-环境-具身（TEE）类，将世界状态表示为语义数字孪生（SDTs），并定义物理模型来分解任务达成过程，从而实现对机器人身体运动的合成和验证。


<details>
  <summary>Details</summary>
Motivation: 自主机器人需要在执行日常操作任务时，确保其身体运动在语义上与任务请求一致，在因果上对环境有效，并且在具身能力范围内是可行的。为了让机器人能够验证这些属性，需要一种通用的框架。

Method: 本文引入了“任务达成身体运动定律”，这是一个关于身体运动的公理化正确性规范。该方法使用作用域的任务-环境-具身（TEE）类，将世界状态表示为语义数字孪生（SDTs），并定义了适用的物理模型。任务达成被分解为三个谓词：SatisfiesRequest（语义请求满足）、Causes（因果充分性）和CanPerform（安全性和可行性）。

Result: 这种分解提供了一个可重用、与实现无关的接口，支持运动合成和现有身体运动的验证。它还支持类型化的故障诊断（语义、因果、具身和范围外）、跨机器人和环境的可行性以及关于机器人身体运动的反事实推理。研究人员通过在厨房环境中对铰接式容器操作进行实例化，并在三个不同的移动操作平台上进行了演示，证明了该定律的可用性。

Conclusion: “任务达成身体运动定律”为自主机器人的身体运动提供了一种形式化的验证方法，能够处理语义、因果和具身层面的复杂性，并支持故障诊断和反事实推理，具有广泛的应用前景。

Abstract: Autonomous agents that perform everyday manipulation actions need to ensure that their body motions are semantically correct with respect to a task request, causally effective within their environment, and feasible for their embodiment. In order to enable robots to verify these properties, we introduce the Law of Task-Achieving Body Motion as an axiomatic correctness specification for body motions. To that end we introduce scoped Task-Environment-Embodiment (TEE) classes that represent world states as Semantic Digital Twins (SDTs) and define applicable physics models to decompose task achievement into three predicates: SatisfiesRequest for semantic request satisfaction over SDT state evolution; Causes for causal sufficiency under the scoped physics model; and CanPerform for safety and feasibility verification at the embodiment level. This decomposition yields a reusable, implementation-independent interface that supports motion synthesis and the verification of given body motions. It also supports typed failure diagnosis (semantic, causal, embodiment and out-of-scope), feasibility across robots and environments, and counterfactual reasoning about robot body motions. We demonstrate the usability of the law in practice by instantiating it for articulated container manipulation in kitchen environments on three contrasting mobile manipulation platforms

</details>


### [188] [Humanoid Manipulation Interface: Humanoid Whole-Body Manipulation from Robot-Free Demonstrations](https://arxiv.org/abs/2602.06643)
*Ruiqian Nai,Boyuan Zheng,Junming Zhao,Haodong Zhu,Sicong Dai,Zunhao Chen,Yihang Hu,Yingdong Hu,Tong Zhang,Chuan Wen,Yang Gao*

Main category: cs.RO

TL;DR: 本文提出了一种名为 HuMI 的便携式高效框架，用于学习人形机器人的全身操作任务，通过免机器人数据收集和分层学习管道，实现了比传统方法更高效的数据收集和更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的人形机器人全身操作方法（如远程操作或视觉强化学习）存在硬件物流复杂、奖励工程困难的问题，导致自主技能有限且仅限于受控环境。因此，需要一种更高效、更通用的方法。

Method: HuMI 框架通过便携式硬件捕捉丰富的人体全身运动数据，无需机器人本体。这些数据被输入到一个分层学习管道，将人体运动转化为灵巧且可行的机器人操作技能。

Result: HuMI 在五种全身操作任务（跪姿、下蹲、投掷、行走和双手操作）的广泛实验中，数据收集效率比远程操作提高了 3 倍，并在未知环境中取得了 70% 的成功率。

Conclusion: HuMI 框架是一种便携式且高效的全身操作学习方法，能够克服传统方法的局限性，实现更广泛、更通用的机器人操作技能。

Abstract: Current approaches for humanoid whole-body manipulation, primarily relying on teleoperation or visual sim-to-real reinforcement learning, are hindered by hardware logistics and complex reward engineering. Consequently, demonstrated autonomous skills remain limited and are typically restricted to controlled environments. In this paper, we present the Humanoid Manipulation Interface (HuMI), a portable and efficient framework for learning diverse whole-body manipulation tasks across various environments. HuMI enables robot-free data collection by capturing rich whole-body motion using portable hardware. This data drives a hierarchical learning pipeline that translates human motions into dexterous and feasible humanoid skills. Extensive experiments across five whole-body tasks--including kneeling, squatting, tossing, walking, and bimanual manipulation--demonstrate that HuMI achieves a 3x increase in data collection efficiency compared to teleoperation and attains a 70% success rate in unseen environments.

</details>


### [189] [Think Proprioceptively: Embodied Visual Reasoning for VLA Manipulation](https://arxiv.org/abs/2602.06575)
*Fangyuan Wang,Peng Zhou,Jiaming Qi,Shipeng Lyu,David Navarro-Alarcon,Guodong Guo*

Main category: cs.RO

TL;DR: 本文提出了一种名为ThinkProprio的新型视觉-语言-动作（VLA）模型，它将机器人的本体感受（proprioception）信息提前融入到模型的输入阶段，而不是像传统模型那样作为后期条件。这种早期融合能让机器人的状态信息影响指令理解和视觉信息选择，从而更有效地聚焦于与动作相关的视觉线索。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型通常将本体感受信息作为后期条件输入，这限制了机器人状态信息在指令理解和视觉注意力分配中的作用。研究者希望通过更早地融合本体感受信息，使其能够主动地影响模型的推理过程，从而提升模型性能。

Method: ThinkProprio将本体感受信息编码为文本令牌，并与任务指令一起输入到VLM中。这种早期融合允许本体感受信息参与后续的视觉推理和令牌选择过程。研究者还进行了消融实验，以评估本体感受编码方式、状态输入点以及动作头条件化的影响。

Result: 实验结果表明，将本体感受编码为文本令牌比使用学习到的投影器更有效。此外，保留约15%的视觉令牌即可达到使用全部令牌的性能。ThinkProprio在CALVIN、LIBERO数据集和真实世界操作任务中，性能与强基线模型相当或有所提升，同时推理延迟降低了超过50%。

Conclusion: ThinkProprio通过将本体感受信息早期、以文本令牌的形式融入VLM，有效地提升了模型的指令理解和视觉注意力分配能力，实现了性能的提升和推理效率的显著提高。

Abstract: Vision-language-action (VLA) models typically inject proprioception only as a late conditioning signal, which prevents robot state from shaping instruction understanding and from influencing which visual tokens are attended throughout the policy. We introduce ThinkProprio, which converts proprioception into a sequence of text tokens in the VLM embedding space and fuses them with the task instruction at the input. This early fusion lets embodied state participate in subsequent visual reasoning and token selection, biasing computation toward action-critical evidence while suppressing redundant visual tokens. In a systematic ablation over proprioception encoding, state entry point, and action-head conditioning, we find that text tokenization is more effective than learned projectors, and that retaining roughly 15% of visual tokens can match the performance of using the full token set. Across CALVIN, LIBERO, and real-world manipulation, ThinkProprio matches or improves over strong baselines while reducing end-to-end inference latency over 50%.

</details>


### [190] [RAPID: Reconfigurable, Adaptive Platform for Iterative Design](https://arxiv.org/abs/2602.06653)
*Zi Yin,Fanhong Li,Shurui Zheng,Jia Liu*

Main category: cs.RO

TL;DR: 提出了一种名为RAPID的机器人操纵平台，该平台采用模块化硬件和软件设计，可实现快速更换末端执行器和传感器，从而显著缩短机器人策略的开发和迭代时间，并支持运行时传感器热插拔。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人末端执行器更换和系统集成过程耗时且复杂，阻碍了机器人操纵策略的迭代和研究。研究人员需要一种能够快速重新配置硬件并保持软件兼容性的平台。

Method: RAPID平台采用模块化硬件设计，支持免工具更换末端执行器和传感器。其软件栈通过USB事件生成“物理掩码”（Physical Mask），实时感知硬件配置。这种设计允许自动配置和在传感器热插拔时优雅降级。

Result: RAPID将多模态配置的设置时间缩短了两个数量级。实验证明，该平台能在运行时传感器热插拔事件下保持策略执行。硬件设计、驱动和软件栈均已开源。

Conclusion: RAPID平台通过其创新的模块化硬件和软件设计，极大地简化了机器人末端执行器的配置和研究流程，加速了机器人操纵策略的开发，并提高了系统的鲁棒性。

Abstract: Developing robotic manipulation policies is iterative and hypothesis-driven: researchers test tactile sensing, gripper geometries, and sensor placements through real-world data collection and training. Yet even minor end-effector changes often require mechanical refitting and system re-integration, slowing iteration. We present RAPID, a full-stack reconfigurable platform designed to reduce this friction. RAPID is built around a tool-free, modular hardware architecture that unifies handheld data collection and robot deployment, and a matching software stack that maintains real-time awareness of the underlying hardware configuration through a driver-level Physical Mask derived from USB events. This modular hardware architecture reduces reconfiguration to seconds and makes systematic multi-modal ablation studies practical, allowing researchers to sweep diverse gripper and sensing configurations without repeated system bring-up. The Physical Mask exposes modality presence as an explicit runtime signal, enabling auto-configuration and graceful degradation under sensor hot-plug events, so policies can continue executing when sensors are physically added or removed. System-centric experiments show that RAPID reduces the setup time for multi-modal configurations by two orders of magnitude compared to traditional workflows and preserves policy execution under runtime sensor hot-unplug events. The hardware designs, drivers, and software stack are open-sourced at https://rapid-kit.github.io/ .

</details>


### [191] [Crowd-FM: Learned Optimal Selection of Conditional Flow Matching-generated Trajectories for Crowd Navigation](https://arxiv.org/abs/2602.06698)
*Antareep Singha,Laksh Nanwani,Mathai Mathew P.,Samkit Jain,Phani Teja Singamaneni,Arun Kumar Singh,K. Madhava Krishna*

Main category: cs.RO

TL;DR: 本文提出了一种名为 Crowd-FM 的基于学习的方法，用于在拥挤、非结构化的人群环境中实现安全且计算效率高的机器人局部规划，同时模仿人类行为以提高机器人接受度。该方法结合了条件流匹配（CFM）策略来学习无碰撞的运动原语，以及一个评分函数来评估人类相似性，从而在推理时选择最佳轨迹。


<details>
  <summary>Details</summary>
Motivation: 在密集、非结构化的人群环境中，为移动机器人实现安全且计算高效的局部规划是一个基本挑战。此外，使机器人轨迹更像人类的运动方式可以提高机器人融入人类环境的接受度。

Method: 该方法包含两个新颖的组件：1. 训练一个条件流匹配（CFM）策略，学习一组无碰撞的运动原语，以应对各种场景。2. 学习一个评分函数，根据人类演示轨迹评估运动原语的人类相似性。在推理时，选择得分最高的最优轨迹。

Result: CFM 策略本身在无碰撞导航方面的成功率高于现有的基于学习的基线。结合推理时细化，该方法甚至优于昂贵的基于优化的规划方法。评分网络能够选择比手动设计的成本函数更接近专家数据的轨迹。

Conclusion: Crowd-FM 是一种有效的学习方法，能够同时解决在人群环境中进行安全导航和模仿人类行为的挑战，并在性能上超越现有技术。

Abstract: Safe and computationally efficient local planning for mobile robots in dense, unstructured human crowds remains a fundamental challenge. Moreover, ensuring that robot trajectories are similar to how a human moves will increase the acceptance of the robot in human environments. In this paper, we present Crowd-FM, a learning-based approach to address both safety and human-likeness challenges. Our approach has two novel components. First, we train a Conditional Flow-Matching (CFM) policy over a dataset of optimally controlled trajectories to learn a set of collision-free primitives that a robot can choose at any given scenario. The chosen optimal control solver can generate multi-modal collision-free trajectories, allowing the CFM policy to learn a diverse set of maneuvers. Secondly, we learn a score function over a dataset of human demonstration trajectories that provides a human-likeness score for the flow primitives. At inference time, computing the optimal trajectory requires selecting the one with the highest score. Our approach improves the state-of-the-art by showing that our CFM policy alone can produce collision-free navigation with a higher success rate than existing learning-based baselines. Furthermore, when augmented with inference-time refinement, our approach can outperform even expensive optimisation-based planning approaches. Finally, we validate that our scoring network can select trajectories closer to the expert data than a manually designed cost function.

</details>


### [192] [Constraint Manifold Exploration for Efficient Continuous Coverage Estimation](https://arxiv.org/abs/2602.06749)
*Robert Wilbrandt,Rüdiger Dillmann*

Main category: cs.RO

TL;DR: 本文提出了一种基于采样的连续覆盖率估计算法，用于评估工业机器人手臂在复杂表面上进行全覆盖的可行性，该算法考虑了工具姿态约束，并在不同环境下进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成机器人轨迹方面存在不足，缺乏对全表面覆盖可行性进行分析的充分方法，尤其是在打磨、喷漆等需要工具与表面保持垂直的应用中。

Method: 提出了一种基于采样的连续覆盖率估计算法，定义了包含工具位置和姿态约束的扩展环境配置空间，并采用基于连续的方法和两种不同的采样策略进行探索和分析。

Result: 通过在不同运动学和环境下进行详尽评估，验证了该方法在计算复杂表面覆盖率方面的准确性和效率。

Conclusion: 该方法能够准确有效地计算复杂环境下复杂表面的覆盖率，为工业机器人表面覆盖轨迹规划提供了可行性分析工具。

Abstract: Many automated manufacturing processes rely on industrial robot arms to move process-specific tools along workpiece surfaces. In applications like grinding, sanding, spray painting, or inspection, they need to cover a workpiece fully while keeping their tools perpendicular to its surface. While there are approaches to generate trajectories for these applications, there are no sufficient methods for analyzing the feasibility of full surface coverage. This work proposes a sampling-based approach for continuous coverage estimation that explores reachable surface regions in the configuration space. We define an extended ambient configuration space that allows for the representation of tool position and orientation constraints. A continuation-based approach is used to explore it using two different sampling strategies. A thorough evaluation across different kinematics and environments analyzes their runtime and efficiency. This validates our ability to accurately and efficiently calculate surface coverage for complex surfaces in complicated environments.

</details>


### [193] [SuReNav: Superpixel Graph-based Constraint Relaxation for Navigation in Over-constrained Environments](https://arxiv.org/abs/2602.06807)
*Keonyoung Koh,Moonkyeong Jung,Samuel Seungsup Lee,Daehyung Park*

Main category: cs.RO

TL;DR: 提出了一种名为SuReNav的超像素图基约束松弛与导航方法，用于解决半静态环境下的超约束规划问题，通过模仿人类的导航方式，在安全性和效率之间取得平衡，并在2D/3D地图和真实世界场景中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理超约束规划问题时，依赖预定义的区域成本，泛化能力有限，且难以准确识别可通行区域。同时，导航空间的连续性也增加了识别风险区域的难度。

Method: SuReNav方法包含三个部分：1）生成包含区域约束的超像素图；2）利用图神经网络（基于人类演示训练）对区域约束进行松弛，实现安全高效的导航；3）通过交替进行约束松弛、规划和执行来完成导航。

Result: 在2D语义地图和OpenStreetMap的3D地图上，SuReNav相比现有先进方法，取得了最高的人类化导航得分，并在效率和安全之间实现了良好的权衡。

Conclusion: SuReNav是一种有效的超约束规划方法，通过模拟人类导航行为，在保证安全性的前提下提高了导航效率，并展现了良好的可扩展性和泛化能力，能够成功应用于真实世界的城市导航任务。

Abstract: We address the over-constrained planning problem in semi-static environments. The planning objective is to find a best-effort solution that avoids all hard constraint regions while minimally traversing the least risky areas. Conventional methods often rely on pre-defined area costs, limiting generalizations. Further, the spatial continuity of navigation spaces makes it difficult to identify regions that are passable without overestimation. To overcome these challenges, we propose SuReNav, a superpixel graph-based constraint relaxation and navigation method that imitates human-like safe and efficient navigation. Our framework consists of three components: 1) superpixel graph map generation with regional constraints, 2) regional-constraint relaxation using graph neural network trained on human demonstrations for safe and efficient navigation, and 3) interleaving relaxation, planning, and execution for complete navigation. We evaluate our method against state-of-the-art baselines on 2D semantic maps and 3D maps from OpenStreetMap, achieving the highest human-likeness score of complete navigation while maintaining a balanced trade-off between efficiency and safety. We finally demonstrate its scalability and generalization performance in real-world urban navigation with a quadruped robot, Spot.

</details>


### [194] [DynaRetarget: Dynamically-Feasible Retargeting using Sampling-Based Trajectory Optimization](https://arxiv.org/abs/2602.06827)
*Victor Dhedin,Ilyass Taouil,Shafeef Omar,Dian Yu,Kun Tao,Angela Dai,Majid Khadiv*

Main category: cs.RO

TL;DR: 本文提出了一种名为 DynaRetarget 的完整管线，用于将人类动作重定向到人形机器人控制策略。其核心是采样基轨迹优化（SBTO）框架，能够将不完美的运动学轨迹转化为动态可行的动作，并能处理长时程任务。DynaRetarget 在处理大量人形-物体交互演示时表现出色，成功率高于现有技术，并且能鲁棒地处理不同物体属性。


<details>
  <summary>Details</summary>
Motivation: 当前在真实世界收集人形机器人操作轨迹的动作具有挑战性，数据量有限，而生成大规模合成数据集是解决这一瓶颈的关键。因此，研究如何有效地将人类动作重定向到人形机器人控制策略，以生成大规模合成数据集，是本研究的动机。

Method: 本文提出了一种名为 DynaRetarget 的完整管线，其核心是采样基轨迹优化（SBTO）框架。SBTO 能够逐步推进优化视界，对整个轨迹进行优化，以将不完美的运动学轨迹转化为动态可行的动作。

Result: DynaRetarget 成功地将数百个人形-物体交互演示重定向，取得了比现有技术更高的成功率。该框架还能够使用相同的跟踪目标，鲁棒地处理不同质量、尺寸和几何形状的物体。

Conclusion: DynaRetarget 提供了一种有效的管线，用于将人类动作重定向到人形机器人控制策略。其核心的 SBTO 框架能够生成动态可行的动作，并能鲁棒地处理多样化的演示和物体属性。这项工作为生成大规模人形机器人 loco-manipulation 合成数据集提供了可能性，有望解决当前数据收集的瓶颈。

Abstract: In this paper, we introduce DynaRetarget, a complete pipeline for retargeting human motions to humanoid control policies. The core component of DynaRetarget is a novel Sampling-Based Trajectory Optimization (SBTO) framework that refines imperfect kinematic trajectories into dynamically feasible motions. SBTO incrementally advances the optimization horizon, enabling optimization over the entire trajectory for long-horizon tasks. We validate DynaRetarget by successfully retargeting hundreds of humanoid-object demonstrations and achieving higher success rates than the state of the art. The framework also generalizes across varying object properties, such as mass, size, and geometry, using the same tracking objective. This ability to robustly retarget diverse demonstrations opens the door to generating large-scale synthetic datasets of humanoid loco-manipulation trajectories, addressing a major bottleneck in real-world data collection.

</details>


### [195] [A 26-Gram Butterfly-Inspired Robot Achieving Autonomous Tailless Flight](https://arxiv.org/abs/2602.06811)
*Weibin Gu,Chenrui Feng,Lian Liu,Chen Yang,Xingchi Jiao,Yuhe Ding,Xiaofei Shi,Chao Gao,Alessandro Rizzo,Guyue Zhou*

Main category: cs.RO

TL;DR: 研究介绍了一种名为AirPulse的26克仿蝴蝶扑翼微型飞行器（FWMAV），它能够在没有辅助控制面的情况下实现完全自主、闭环、无系绳飞行，并通过拍动参数的调节实现稳定飞行和机动。


<details>
  <summary>Details</summary>
Motivation: Tailless two-winged FWMAVs由于复杂的流固耦合和翼体耦合而未得到充分探索，尽管它们具有出色的生物启发式敏捷性。研究旨在克服这些挑战，实现稳定、可控的此类飞行器。此外，作者希望为轻量化、防碰撞FWMAV提供一个基础平台，并能解码蝴蝶飞行原理。

Method: 研究设计了一个26克的仿蝴蝶FWMAV（AirPulse），该飞行器具有低翼展比、柔性碳纤维增强机翼，并模仿蝴蝶低频、高幅度扑动。通过建立拍动调制参数与力-力矩生成之间的定量映射，并引入了STAR（Stroke Timing Asymmetry Rhythm）发生器来实现平滑、稳定、线性的拍动控制。结合姿态控制器，实现了俯仰和偏航稳定性。

Result: AirPulse飞行器成功实现了稳定爬升和转弯机动，可通过角度偏移或拍动时间不对称调制实现。这是首次在同行评审文献中报道的最轻的、双翼无尾、仿蝴蝶FWMAV的板载控制飞行。

Conclusion: AirPulse飞行器是一个具有开创性的平台，证明了在没有辅助控制面的情况下，通过模仿蝴蝶的生物力学特性，可以实现稳定、可控的扑翼飞行。这项工作为开发轻量化、可在复杂环境中应用的FWMAV提供了基础，并有助于理解蝴蝶高效但看似混乱的飞行原理。

Abstract: Flapping-wing micro air vehicles (FWMAVs) have demonstrated remarkable bio-inspired agility, yet tailless two-winged configurations remain largely unexplored due to their complex fluid-structure and wing-body coupling. Here we present \textit{AirPulse}, a 26-gram butterfly-inspired FWMAV that achieves fully onboard, closed-loop, untethered flight without auxiliary control surfaces. The AirPulse robot replicates key biomechanical traits of butterfly flight, including low wing aspect ratio, compliant carbon-fiber-reinforced wings, and low-frequency, high-amplitude flapping that induces cyclic variations in the center of gravity and moment of inertia, producing characteristic body undulation. We establish a quantitative mapping between flapping modulation parameters and force-torque generation, and introduce the Stroke Timing Asymmetry Rhythm (STAR) generator, enabling smooth, stable, and linearly parameterized wingstroke asymmetry for flapping control. Integrating these with an attitude controller, the AirPulse robot maintains pitch and yaw stability despite strong oscillatory dynamics. Free-flight experiments demonstrate stable climbing and turning maneuvers via either angle offset or stroke timing modulation, marking the first onboard controlled flight of the lightest two-winged, tailless butterfly-inspired FWMAV reported in peer-reviewed literature. This work corroborates a foundational platform for lightweight, collision-proof FWMAVs, bridging biological inspiration with practical aerial robotics. Their non-invasive maneuverability is ideally suited for real-world applications, such as confined-space inspection and ecological monitoring, inaccessible to traditional drones, while their biomechanical fidelity provides a physical model to decode the principles underlying the erratic yet efficient flight of real butterflies.

</details>


### [196] [Perception-Control Coupled Visual Servoing for Textureless Objects Using Keypoint-Based EKF](https://arxiv.org/abs/2602.06834)
*Allen Tao,Jun Yang,Stanko Oparnica,Wenjie Xue*

Main category: cs.RO

TL;DR: 提出了一种结合基于学习的边缘检测和扩展卡尔曼滤波器（EKF）的视觉伺服方法，用于在纹理缺失和遮挡等挑战性条件下实现对纹理缺失物体的鲁棒6D姿态估计和控制。该方法通过闭环集成感知和控制，并引入了不确定性感知控制律，以提高安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉伺服方法在处理纹理缺失物体和应对遮挡等恶劣视觉条件时面临挑战，导致精度和稳定性下降。因此，需要一种能够提高鲁棒性的方法。

Method: 利用基于学习的边缘检测技术检测纹理缺失物体上的关键点，并使用扩展卡尔曼滤波器（EKF）融合每帧的关键点测量值来估计6D物体姿态。然后，利用姿态估计驱动基于姿态的视觉伺服（PBVS）进行控制。此外，提出了一种概率控制律，计算相机速度及其不确定性，实现不确定性感知控制。

Result: 在真实机器人平台上进行了定量指标和抓取实验验证，结果表明所提出的方法在精度和实际应用方面优于传统的视觉伺服技术。

Conclusion: 该方法通过将感知和控制紧密集成在闭环中，并引入不确定性感知控制，有效解决了纹理缺失物体在恶劣视觉条件下的视觉伺服问题，提高了系统的鲁棒性、准确性和安全性。

Abstract: Visual servoing is fundamental to robotic applications, enabling precise positioning and control. However, applying it to textureless objects remains a challenge due to the absence of reliable visual features. Moreover, adverse visual conditions, such as occlusions, often corrupt visual feedback, leading to reduced accuracy and instability in visual servoing. In this work, we build upon learning-based keypoint detection for textureless objects and propose a method that enhances robustness by tightly integrating perception and control in a closed loop. Specifically, we employ an Extended Kalman Filter (EKF) that integrates per-frame keypoint measurements to estimate 6D object pose, which drives pose-based visual servoing (PBVS) for control. The resulting camera motion, in turn, enhances the tracking of subsequent keypoints, effectively closing the perception-control loop. Additionally, unlike standard PBVS, we propose a probabilistic control law that computes both camera velocity and its associated uncertainty, enabling uncertainty-aware control for safe and reliable operation. We validate our approach on real-world robotic platforms using quantitative metrics and grasping experiments, demonstrating that our method outperforms traditional visual servoing techniques in both accuracy and practical application.

</details>


### [197] [SURE: Safe Uncertainty-Aware Robot-Environment Interaction using Trajectory Optimization](https://arxiv.org/abs/2602.06864)
*Zhuocheng Zhang,Haizhou Zhao,Xudong Sun,Aaron M. Johnson,Majid Khadiv*

Main category: cs.RO

TL;DR: 提出了一种名为SURE的鲁棒轨迹优化框架，用于解决机器人接触交互中不确定的接触时机问题，通过多轨迹分支与汇合实现鲁棒性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统轨迹优化方法在处理机器人接触交互时，通常假设接触事件是确定性的，这导致在现实世界中的鲁棒性和适应性受限。

Method: SURE框架通过允许多条轨迹从可能的碰撞前状态分支，并在稍后汇合到共享轨迹，来明确考虑接触时机的 Butten. It enables robustness and computational efficiency within a unified optimization framework.

Result: 在具有未知冲击时间的两个代表性任务上进行了评估：1. 在涉及不确定墙壁位置的倒立摆任务中，SURE在控制过程中启用分支切换时，成功率平均提高了21.6%。 2. 在使用机械臂进行抓蛋实验中，SURE将成功率提高了40%。

Conclusion: SURE框架通过明确考虑接触时机的 Butten，显著提高了机器人接触交互任务的鲁棒性，优于传统的名义公式。

Abstract: Robotic tasks involving contact interactions pose significant challenges for trajectory optimization due to discontinuous dynamics. Conventional formulations typically assume deterministic contact events, which limit robustness and adaptability in real-world settings. In this work, we propose SURE, a robust trajectory optimization framework that explicitly accounts for contact timing uncertainty. By allowing multiple trajectories to branch from possible pre-impact states and later rejoin a shared trajectory, SURE achieves both robustness and computational efficiency within a unified optimization framework. We evaluate SURE on two representative tasks with unknown impact times. In a cart-pole balancing task involving uncertain wall location, SURE achieves an average improvement of 21.6% in success rate when branch switching is enabled during control. In an egg-catching experiment using a robotic manipulator, SURE improves the success rate by 40%. These results demonstrate that SURE substantially enhances robustness compared to conventional nominal formulations.

</details>


### [198] [Consensus-based optimization (CBO): Towards Global Optimality in Robotics](https://arxiv.org/abs/2602.06868)
*Xudong Sun,Armand Jordana,Massimo Fornasier,Jalal Etesami,Majid Khadiv*

Main category: cs.RO

TL;DR: 本文将共识优化（CBO）引入机器人领域，用于解决轨迹优化问题，并证明了其全局收敛性。实验表明，CBO在长时域、动态平衡和高维问题上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的零阶优化方法（如MPPI、CEM、CMA-ES）在机器人轨迹优化中存在局部收敛的局限性，而研究人员需要更全局的优化方法。

Method: 提出并理论分析了共识优化（CBO）方法在机器人领域的应用，并将其与现有方法（MPPI、CEM、CMA-ES）进行了比较。在三个具有挑战性的轨迹优化场景中进行了实验验证：长时域问题、动态平衡问题和高维终端成本问题。

Result: CBO在所有三个实验场景中均取得了比现有方法更低的成本。尤其是在长时域、动态平衡和高维问题上，CBO展现了更优的性能。

Conclusion: CBO是一种能够保证全局收敛的机器人轨迹优化新框架，为机器人领域的研究提供了新的途径，并在实际应用中展现出优越的性能。

Abstract: Zero-order optimization has recently received significant attention for designing optimal trajectories and policies for robotic systems. However, most existing methods (e.g., MPPI, CEM, and CMA-ES) are local in nature, as they rely on gradient estimation. In this paper, we introduce consensus-based optimization (CBO) to robotics, which is guaranteed to converge to a global optimum under mild assumptions. We provide theoretical analysis and illustrative examples that give intuition into the fundamental differences between CBO and existing methods. To demonstrate the scalability of CBO for robotics problems, we consider three challenging trajectory optimization scenarios: (1) a long-horizon problem for a simple system, (2) a dynamic balance problem for a highly underactuated system, and (3) a high-dimensional problem with only a terminal cost. Our results show that CBO is able to achieve lower costs with respect to existing methods on all three challenging settings. This opens a new framework to study global trajectory optimization in robotics.

</details>


### [199] [Strategizing at Speed: A Learned Model Predictive Game for Multi-Agent Drone Racing](https://arxiv.org/abs/2602.06925)
*Andrei-Carlo Papuc,Lasse Peters,Sihao Sun,Laura Ferranti,Javier Alonso-Mora*

Main category: cs.RO

TL;DR: 本文提出了一种名为学习模型预测博弈（LMPG）的新方法，该方法通过摊销模型预测博弈来减少延迟，并在模拟和硬件实验中在无人机竞速中超越了模型预测博弈（MPG）和轮廓模型预测控制（MPC）。


<details>
  <summary>Details</summary>
Motivation: 无人机竞速需要无人机不仅要以极限速度导航，还要预测和反击竞争对手的行动。本文旨在研究在此背景下，一个关键问题：代理在采取行动前应该进行多深度的策略规划。

Method: 本文比较了两种规划范式：模型预测博弈（MPG），能够找到考虑交互的策略但计算时间长；轮廓模型预测控制（MPC），计算速度快但不考虑交互。为了解决MPG在高速度下的延迟问题，本文提出了一种学习模型预测博弈（LMPG）方法，该方法摊销了模型预测博弈的计算。

Result: 实验表明，MPG在中等速度下优于MPC，但在高速下由于延迟而失去优势。LMPG在模拟和硬件实验中均优于MPG和MPC。

Conclusion: LMPG通过减少模型预测博弈的延迟，在无人机竞速中实现了比MPG和MPC更优的性能，为解决高速动态环境下的多智能体博弈问题提供了一种有效的方法。

Abstract: Autonomous drone racing pushes the boundaries of high-speed motion planning and multi-agent strategic decision-making. Success in this domain requires drones not only to navigate at their limits but also to anticipate and counteract competitors' actions. In this paper, we study a fundamental question that arises in this domain: how deeply should an agent strategize before taking an action? To this end, we compare two planning paradigms: the Model Predictive Game (MPG), which finds interaction-aware strategies at the expense of longer computation times, and contouring Model Predictive Control (MPC), which computes strategies rapidly but does not reason about interactions. We perform extensive experiments to study this trade-off, revealing that MPG outperforms MPC at moderate velocities but loses its advantage at higher speeds due to latency. To address this shortcoming, we propose a Learned Model Predictive Game (LMPG) approach that amortizes model predictive gameplay to reduce latency. In both simulation and hardware experiments, we benchmark our approach against MPG and MPC in head-to-head races, finding that LMPG outperforms both baselines.

</details>


### [200] [DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos](https://arxiv.org/abs/2602.06949)
*Shenyuan Gao,William Liang,Kaiyuan Zheng,Ayaan Malik,Seonghyeon Ye,Sihyun Yu,Wei-Cheng Tseng,Yuzhu Dong,Kaichun Mo,Chen-Hsuan Lin,Qianli Ma,Seungjun Nah,Loic Magne,Jiannan Xiang,Yuqi Xie,Ruijie Zheng,Dantong Niu,You Liang Tan,K. R. Zentner,George Kurian,Suneel Indupuru,Pooya Jannaty,Jinwei Gu,Jun Zhang,Jitendra Malik,Pieter Abbeel,Ming-Yu Liu,Yuke Zhu,Joel Jang,Linxi "Jim" Fan*

Main category: cs.RO

TL;DR: 研究提出了DreamDojo，一个基于大量人类视频预训练的通用世界模型，能够学习多样化的互动和精细控制，并可用于机器人任务的模拟、评估和规划。


<details>
  <summary>Details</summary>
Motivation: 当前的机器人世界模型在处理复杂、精细操作任务时面临数据稀疏和动作标注稀缺的挑战，限制了通用智能体的开发。因此，需要一个能够从更广泛、更易获得的数据源（如人类视频）中学习世界动力学和控制能力的基础模型。

Method: 使用44k小时的以自我为中心的人类视频作为预训练数据，构建了一个大型数据集。引入连续潜在动作作为统一的代理动作，以解决视频中动作标签稀缺的问题。模型经过在少量目标机器人数据上的后训练，并设计了一个蒸馏流程以加速模型并提高其时序一致性。

Result: DreamDojo展示了对物理规律的良好理解和精确的动作控制能力。蒸馏后的模型达到了10.81 FPS的实时速度，并提高了上下文一致性。在多个具有挑战性的分布外（OOD）基准测试中，该方法在开放世界、接触丰富的任务模拟方面表现出色。

Conclusion: DreamDojo作为一种基础世界模型，能够有效地从大规模视频数据中学习物理交互和精细控制，克服了数据稀疏和动作标注的限制，为通用机器人世界模型的开发奠定了基础，并支持了实时遥操作、策略评估和模型预测等应用。

Abstract: Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diverse interactions and dexterous controls from 44k hours of egocentric human videos. Our data mixture represents the largest video dataset to date for world model pretraining, spanning a wide range of daily scenarios with diverse objects and skills. To address the scarcity of action labels, we introduce continuous latent actions as unified proxy actions, enhancing interaction knowledge transfer from unlabeled videos. After post-training on small-scale target robot data, DreamDojo demonstrates a strong understanding of physics and precise action controllability. We also devise a distillation pipeline that accelerates DreamDojo to a real-time speed of 10.81 FPS and further improves context consistency. Our work enables several important applications based on generative world models, including live teleoperation, policy evaluation, and model-based planning. Systematic evaluation on multiple challenging out-of-distribution (OOD) benchmarks verifies the significance of our method for simulating open-world, contact-rich tasks, paving the way for general-purpose robot world models.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [201] [Dynamic Quantum Optimal Communication Topology Design for Consensus Control in Linear Multi-Agent Systems](https://arxiv.org/abs/2602.06215)
*Milad Hasanzadeh,Amin Kargarian*

Main category: eess.SY

TL;DR: 本文提出了一种量子框架，用于在基于共识的多智能体系统中设计通信拓扑，通过混合整数二次规划（MIQP）在线选择通信图，并利用三块交替方向乘子法（ADMM）和量子算法（QITE）解决其复杂性。


<details>
  <summary>Details</summary>
Motivation: 应对基于共识的多智能体系统中通信拓扑设计所面临的组合复杂性和NP-hard问题，并探索量子算法在其中的应用潜力。

Method: 提出了一种量子框架，通过求解MIQP来设计通信拓扑，该MIQP结合了通信和距离惩罚以及度正则化项，并采用流基方法强制执行完全连通性。利用三块ADMM分解MIQP，其中量子算法（QITE）用于近似求解映射到QUBO哈密顿量的二元子问题。最终将优化生成的拉普拉斯算子应用于线性共识动力学。

Result: 数值模拟表明，该方法能够生成满足度约束、实现共识且成本可与经典求解器相比的连通拓扑。

Conclusion: 量子算法可以嵌入到闭环分布式控制架构中作为拓扑优化器，为多智能体系统的通信拓扑设计提供了一种有效且可扩展的解决方案。

Abstract: This paper proposes a quantum framework for the design of communication topologies in consensus-based multi-agent systems. The communication graph is selected online by solving a mixed-integer quadratic program (MIQP) that minimizes a cost combining communication and distance penalties with degree-regularization terms, while enforcing exact connectivity through a flow-based formulation. To cope with the combinatorial complexity of this NP-hard problem, we develop a three-block ADMM scheme that decomposes the MIQP into a convex quadratic program in relaxed edge and flow variables, a pure binary unconstrained subproblem, and a closed-form auxiliary update. The binary subproblem is mapped to a quadratic unconstrained binary optimization (QUBO) Hamiltonian and approximately solved via quantum imaginary time evolution (QITE). The resulting time-varying, optimizer-generated Laplacians are applied to linear first- and second-order consensus dynamics. Numerical simulations on networks demonstrate that the proposed method produces connected topologies that satisfy degree constraints, achieve consensus, and incur costs comparable to those of classical mixed-integer solvers, thereby illustrating how quantum algorithms can be embedded as topology optimizers within closed-loop distributed control architectures.

</details>


### [202] [A hard-constrained NN learning framework for rapidly restoring AC-OPF from DC-OPF](https://arxiv.org/abs/2602.06255)
*Kejun Chen,Bernard Knueven,Wesley Jones*

Main category: eess.SY

TL;DR: 提出了一种硬约束无监督学习框架，用于快速求解交流最优潮流（AC-OPF）问题，该框架无需真实AC-OPF解，通过残差学习和可微优化层来保证可行性和最优性，并在IEEE-118和PEGASE-9241系统上实现了显著的加速。


<details>
  <summary>Details</summary>
Motivation: 现有的AC-OPF求解方法计算量大，难以满足实时运行的需求，而传统的无监督学习方法难以保证可行性和最优性。本研究旨在开发一种能够快速、可靠地求解AC-OPF问题的无监督学习方法。

Method: 提出了一种硬约束无监督学习框架。该框架利用残差学习思想，让神经网络（NN）学习从DC-OPF解到发电机有功功率设定点的修正映射。随后，利用一个优化模型恢复AC-OPF解，并将投影差异用作训练损失。通过一个回放缓冲区来提高学习效率。优化模型被设计成一个可微优化层，并利用隐函数定理推导出梯度。

Result: 在IEEE-118和PEGASE-9241总线系统上进行测试，结果表明该NN能够获得严格可行且接近最优的解，计算时间比传统求解器显著缩短。在不同拓扑下，结合更新的DC-OPF解和PF求解器，该NN能够快速找到相应的AC解。该方法实现了40倍的时间加速，同时保持了平均约束违反量在$10^{-4}$量级，优化间隙低于1%。

Conclusion: 所提出的硬约束无监督学习框架能够快速、可靠地求解AC-OPF问题，在保证可行性和最优性的同时，显著提高了计算效率，为实时电力系统运行提供了有效的解决方案。

Abstract: This paper proposes a hard-constrained unsupervised learning framework for rapidly solving the non-linear and non-convex AC optimal power flow (AC-OPF) problem in real-time operation. Without requiring ground-truth AC-OPF solutions, feasibility and optimality are ensured through a properly designed learning environment and training loss. Inspired by residual learning, the neural network (NN) learns the correction mapping from the DC-OPF solution to the active power setpoints of the generators through re-dispatch. A subsequent optimization model is utilized to restore the optimal AC-OPF solution, and the resulting projection difference is employed as the training loss. A replay buffer is utilized to enhance learning efficiency by fully leveraging past data pairs. The optimization model is cast as a differentiable optimization layer, where the gradient is derived by applying the implicit function theorem to the KKT conditions at the optimal solution. Tested on IEEE-118 and PEGASE-9241 bus systems, numerical results demonstrate that the proposed NN can obtain strictly feasible and near-optimal solutions with reduced computational time compared to conventional optimization solvers. In addition, aided by the updated DC-OPF solution under varying topologies, the trained NN, together with the PF solver, can rapidly find the corresponding AC solution. The proposed method achieves a $40\times$ time speedup, while maintaining an average constraint violation on the order of $10^{-4}$ and an optimization gap below $1\%$.

</details>


### [203] [Advances in Battery Energy Storage Management: Control and Economic Synergies](https://arxiv.org/abs/2602.06365)
*Venkata Rajesh Chundru,Shreshta Rajakumar Deshpande,Stanislav A Gankov*

Main category: eess.SY

TL;DR: 本研究通过对电池储能系统（BESS）相关文献进行分类综述，旨在弥合现有研究在电网稳定性控制和技术经济分析方面的不足，并提出一种能够同时优化BESS收益和确保电池安全高效运行的综合能源管理方法，特别是强调了经济性与控制策略的协同作用，以及利用数字孪生技术提升BESS性能和电网稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有关于BESS的研究主要集中在控制系统设计以实现电网稳定性和技术经济分析，但随着辅助服务的整合，需要一种更全面的能源管理方法，该方法不仅能优化BESS的收入，还能确保锂离子电池的安全、高效和可靠运行。本研究旨在填补这一空白。

Method: 对BESS相关文献进行系统性综述，并将文献分为五个类别：（1）BESS的辅助服务；（2）用于实时功率流管理的控制系统；（3）BESS调度优化算法；（4）BESS和电池系统的技术经济分析；（5）BESS数字孪生技术。通过识别潜在的协同效应、研究空白和新兴趋势。

Result: 研究识别了BESS在提供辅助服务、实时功率流管理、调度优化、技术经济可行性以及数字孪生应用等方面的现有研究成果。初步的分析表明，经济性与控制策略的协同作用以及数字孪生技术的应用，有望提升BESS的性能和电网的稳定性。

Conclusion: 通过对现有文献的综合分析，本研究强调了在BESS能源管理中整合经济性和运营性考量的必要性。通过利用数字孪生技术实现经济激励与控制策略的协同，可以开发出更健壮的BESS系统，从而提高电网的稳定性和BESS的盈利能力，为未来的BESS管理和部署策略指明了方向。

Abstract: The existing literature on Battery Energy Storage Systems (BESS) predominantly focuses on two main areas: control system design aimed at achieving grid stability and the techno-economic analysis of BESS dispatch on power grid. However, with the increasing incorporation of ancillary services into power grids, a more comprehensive approach to energy management systems is required. Such an approach should not only optimize revenue generation from BESS but also ensure the safe, efficient, and reliable operation of lithium-ion batteries. This research seeks to bridge this gap by exploring literature that addresses both the economic and operational dimensions of BESS. Specifically, it examines how economic aspects of grid duty cycles can align with control schemes deployed in BESS systems. This alignment, or synergy, could be instrumental in creating robust digital twins virtual representations of BESS systems that enhance both grid stability and revenue potential.
  The literature review is organized into five key categories: (1) ancillary services for BESS, exploring support functions that BESS can provide to power grids; (2) control systems developed for real-time BESS power flow management, ensuring smooth operations under dynamic grid conditions; (3) optimization algorithms for BESS dispatch, focusing on efficient energy allocation strategies; (4) techno-economic analyses of BESS and battery systems to assess their financial viability; and (5) digital twin technologies for real-world BESS deployments, enabling advanced predictive maintenance and performance optimization. This review will identify potential synergies, research gaps, and emerging trends, paving the way for future innovations in BESS management and deployment strategies.

</details>


### [204] [Safety Controller Synthesis for Stochastic Polynomial Time-Delayed Systems](https://arxiv.org/abs/2602.06569)
*Omid Akbarzadeh,MohammadHossein Ashoori,Amy Nejati,Abolfazl Lavaei*

Main category: eess.SY

TL;DR: 本文提出了一种针对具有时滞的离散时间随机非线性多项式系统（dt-SNPS-td）的安全控制器合成理论框架，利用 Krasovskii 控制屏障证书（CBC）来处理时滞的影响，并通过和平方优化实现控制器合成，并用案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有关于随机系统安全性的研究主要集中在无时滞系统，而对于存在时滞的随机系统，其安全控制器合成的研究尚不充分。本文旨在解决这一问题，开发一种能够处理时滞影响的安全控制器合成方法。

Method: 本文采用了 Krasovskii 控制屏障证书（Krasovskii CBC）方法，该方法在传统 CBC 框架的基础上增加了一个额外的求和项，以捕获延迟状态的影响。这种方法将当前状态和延迟状态统一纳入屏障结构中，并将其转化为一个和平方（sum-of-squares）优化问题，从而系统地构造 Krasovskii CBC 及其相关的安全控制器，同时考虑了输入约束，并提供了概率性的安全保证。

Result: 该框架能够为 dt-SNPS-td 系统合成满足输入约束的安全控制器，并提供鲁棒于时滞的概率性安全保证。所有系统轨迹都将保持在指定的安全区域内，并满足量化的概率界限。通过三个案例研究（包括两个物理系统）验证了该方法的有效性和实用性。

Conclusion: 本文成功地开发了一个理论框架，用于合成具有时滞的离散时间随机非线性多项式系统的安全控制器。该框架基于 Krasovskii CBC，并通过和平方优化实现了控制器设计，能够为该类系统提供有效的概率性安全保证。

Abstract: This work develops a theoretical framework for safety controller synthesis in discrete-time stochastic nonlinear polynomial systems subject to time-invariant delays (dt-SNPS-td). While safety analysis of stochastic systems using control barrier certificates (CBC) has been widely studied, developing safety controllers for stochastic systems with time delays remains largely unexplored. The main challenge arises from the need to account for the influence of delayed components when formulating and enforcing safety conditions. To address this, we employ Krasovskii control barrier certificates, which extend the conventional CBC framework by augmenting it with an additional summation term that captures the influence of delayed states. This formulation integrates both the current and delayed components into a unified barrier structure, enabling safety synthesis for stochastic systems with time delays. The proposed approach synthesizes safety controllers under input constraints, offering probabilistic safety guarantees robust to such delays: it ensures that all trajectories of the dt-SNPS-td remain within the prescribed safe region while fulfilling a quantified probabilistic bound. To achieve this, our method reformulates the safety constraints as a sum-of-squares optimization program, enabling the systematic construction of Krasovskii CBC together with their associated safety controllers. We validate the proposed framework through three case studies, including two physical systems, demonstrating its effectiveness and practical applicability.

</details>


### [205] [Structured Learning for Electromagnetic Field Modeling and Real-Time Inversion](https://arxiv.org/abs/2602.06618)
*Antonio Bernardes,Jasan Zughaibi,Michael Muehlebach,Bradley J. Nelson*

Main category: eess.SY

TL;DR: 本研究提出了一种基于多层感知器的磁场建模方法，作为标准偶极展开模型（MPEM）的替代方案，适用于复杂线圈几何形状的电磁导航系统（eMNS）。该方法能够快速、闭式地进行最小范数反演，并解决了MPEM校准中常见的虚假工作空间病态问题。


<details>
  <summary>Details</summary>
Motivation: 现有的分析偶极展开模型（MPEM）在处理具有复杂或不规则线圈几何形状的eMNS系统时存在局限性，因为它依赖于严格的物理假设，并且校准对初始化高度敏感。研究人员希望找到一种更灵活、更鲁棒的建模方法。

Method: 使用多层感知器（MLP）构建数据驱动的磁场模型。该模型学习非线性磁映射，同时严格保持对电流的线性依赖性。模型在OctoMag和Navion系统收集的大规模、高密度数据集上进行训练和评估。

Result: 数据驱动模型实现了与MPEM相当的预测保真度，并且数据效率相当。模型评估时间约为1毫秒，支持高带宽磁控制。此外，研究还证明了数据驱动模型可以消除MPEM校准中常报告的虚假工作空间病态问题。

Conclusion: 基于多层感知器的数据驱动磁场模型是MPEM的一种有前景的替代方案，能够处理复杂的线圈几何形状，实现快速精确的磁场建模和控制，并克服现有方法的局限性。研究团队已公开源代码和数据集以供进一步研究。

Abstract: Precise magnetic field modeling is fundamental to the closed-loop control of electromagnetic navigation systems (eMNS) and the analytical Multipole Expansion Model (MPEM) is the current standard. However, the MPEM relies on strict physical assumptions regarding source symmetry and isolation, and requires optimization-based calibration that is highly sensitive to initialization. These constraints limit its applicability to systems with complex or irregular coil geometries. This work introduces an alternative modeling paradigm based on multi-layer perceptrons that learns nonlinear magnetic mappings while strictly preserving the linear dependence on currents. As a result, the field models enable fast, closed-form minimum-norm inversion with evaluation times of approximately 1 ms, which is critical for high-bandwidth magnetic control. For model training and evaluation we use large-scale, high-density datasets collected from the research-grade OctoMag and clinical-grade Navion systems. Our results demonstrate that data-driven models achieve predictive fidelity equivalent to the MPEM while maintaining comparable data efficiency. Furthermore, we demonstrate that straightforward design choices effectively eliminate spurious workspace ill-conditioning frequently reported in MPEM-based calibration. To facilitate future research, we release the complete codebase and datasets open source.

</details>


### [206] [Efficient and Robust Modeling of Nonlinear Mechanical Systems](https://arxiv.org/abs/2602.06639)
*Davide Tebaldi,Roberto Zanasi*

Main category: eess.SY

TL;DR: 提出了一种新的非线性机械系统动力学模型，该模型在鲁棒性、抗噪声和计算效率方面优于欧拉-拉格朗日模型，并可应用于汽车和机器人领域。


<details>
  <summary>Details</summary>
Motivation: 开发高效鲁棒的动态模型是系统与控制工程领域的基础，现有模型在特定场景下存在局限性。

Method: 提出了一种新的非线性机械系统动力学模型及其自动建模流程，并与欧拉-拉格朗日模型进行了对比。

Result: 与欧拉-拉格朗日模型相比，新模型在面对外部变量依赖性系统时的测量噪声鲁棒性更优，在计算逆动力学时执行时间更短。

Conclusion: 所提出的新型动力学模型及其建模过程对于汽车和机器人等领域的非线性机械系统建模具有优势，尤其是在处理测量噪声和计算效率方面。

Abstract: The development of efficient and robust dynamic models is fundamental in the field of systems and control engineering. In this paper, a new formulation for the dynamic model of nonlinear mechanical systems, that can be applied to different automotive and robotic case studies, is proposed, together with a modeling procedure allowing to automatically obtain the model formulation. Compared with the Euler-Lagrange formulation, the proposed model is shown to give superior performances in terms of robustness against measurement noise for systems exhibiting dependence on some external variables, as well as in terms of execution time when computing the inverse dynamics of the system.

</details>


### [207] [UnifSrv: AP Selection for Achieving Uniformly Good Performance of CF-MIMO in Realistic Urban Networks](https://arxiv.org/abs/2602.06780)
*Yunlu Xiao,Marina Petrova,Ljiljana Simić*

Main category: eess.SY

TL;DR: 本文提出了一种名为UnifSrv的新型接入点（AP）选择算法，用于解决现实城市环境中Cell-free massive MIMO（CF-mMIMO）面临的吞吐量不均和边缘效应问题。该算法通过深度强化学习（DRL）或启发式方法实现，能在保证高吞吐量的同时，提高用户吞吐量的公平性并减小服务AP集合大小，显著优于现有基准方案。


<details>
  <summary>Details</summary>
Motivation: 在理想假设下，CF-mMIMO能提供均匀的高吞吐量。然而，在真实的非均匀城市传播环境中，很难为用户选择有限的服务AP集合，导致吞吐量下降，产生“边缘效应”，最差用户的性能显著退化。为了恢复CF-mMIMO在现实城市网络中的均匀高性能，需要新的AP选择方法。

Method: 1. 提出一个多目标优化问题，旨在同时最大化总数据速率（高吞吐量）、最大化Jain公平性指数（均匀吞吐量）以及最小化服务AP集合大小（可扩展性）。 2. 提出两种UnifSrv AP选择算法来解决该问题：一种基于深度强化学习（DRL）的算法（UnifSrv-DRL），另一种是启发式算法（UnifSrv-heu）。 3. 在真实的城市网络分布、传播和移动模式下进行性能评估。

Result: 与现有基准AP选择方案相比，UnifSrv算法至少可以将吞吐量提高一倍，或者在吞吐量相当的情况下，将服务AP集合的大小减少一半。特别是，启发式算法UnifSrv-heu的性能与UnifSrv-DRL相当，但计算复杂度低几个数量级。

Conclusion: UnifSrv算法是首次提出的能够实现CF-mMIMO在真实城市网络中提供均匀良好性能且低复杂度的AP选择算法。该算法有效解决了CF-mMIMO在现实场景中的性能退化问题，为部署可扩展、高性能的CF-mMIMO系统提供了可行方案。

Abstract: Under the ideal assumption of uniform propagation, cell-free massive MIMO (CF-mMIMO) provides uniformly high throughput over the network by effectively surrounding each user with its serving access point (AP) set. However, in realistic non-uniform urban propagation environments, it is difficult to consistently select good limited serving AP sets, resulting in significantly degraded throughput, reintroducing "edge-effect" for the worst-served users. To restore the uniformly good performance of scalable CF-mMIMO in realistic urban networks, we formulate a novel multi-objective optimization problem to jointly achieve high throughput by maximizing the sum data rate, uniform throughput by maximizing Jain's fairness index of the throughput per user, and scalability by minimizing the serving AP set size. We then propose the UnifSrv AP selection algorithms to solve this optimization problem, consisting of a deep reinforcement learning (DRL)-based algorithm UnifSrv-DRL and a heuristic algorithm UnifSrv-heu. We conduct a comprehensive performance evaluation of scalable CF-mMIMO under realistic urban network distributions, propagation, and mobility patterns, showing that the prior benchmark AP selection schemes fail to provide uniformly high throughput in practice. By contrast, UnifSrv at least doubles the throughput compared to prior benchmarks, or achieves comparable throughput but with half of the serving AP set size. Importantly, our heuristic algorithm achieves equivalent throughput to our DRL one, but with orders of magnitude lower complexity. We thus for the first time propose an AP selection algorithm that achieves uniformly good CF-mMIMO performance in realistic urban networks with low complexity.

</details>


### [208] [Optimal Derivative Feedback Control for an Active Magnetic Levitation System: An Experimental Study on Data-Driven Approaches](https://arxiv.org/abs/2602.06944)
*Saber Omidi,Rene Akupan Ebunle,Se Young Yoon*

Main category: eess.SY

TL;DR: 本文提出了一种数据驱动的最优导数反馈控制器，用于主动磁悬浮系统，并将其与基于模型的方法进行了比较。直接的无模型强化学习方法在迭代次数（epoch）增加时表现优于间接的基于模型的方法。


<details>
  <summary>Details</summary>
Motivation: 为了设计一种能够稳定并提高主动磁悬浮系统性能的控制器，并比较直接无模型方法和间接基于模型方法的效果。

Method: 使用强化学习框架提出了一种直接的无模型控制设计方法，并引入了epoch循环来收集多组过程数据。将此方法与基于DMDc和PEM系统辨识得到的模型进行对比。

Result: 两种控制器都能稳定和提高磁悬浮系统的性能。然而，在允许更多epoch的情况下，直接无模型方法持续优于间接方法。

Conclusion: 迭代优化的直接无模型控制方法比仅依赖单组系统数据识别模型的间接方法具有明显优势。

Abstract: This paper presents the design and implementation of data-driven optimal derivative feedback controllers for an active magnetic levitation system. A direct, model-free control design method based on the reinforcement learning framework is compared with an indirect optimal control design derived from a numerically identified mathematical model of the system. For the direct model-free approach, a policy iteration procedure is proposed, which adds an iteration layer called the epoch loop to gather multiple sets of process data, providing a more diverse dataset and helping reduce learning biases. This direct control design method is evaluated against a comparable optimal control solution designed from a plant model obtained through the combined Dynamic Mode Decomposition with Control (DMDc) and Prediction Error Minimization (PEM) system identification. Results show that while both controllers can stabilize and improve the performance of the magnetic levitation system when compared to controllers designed from a nominal model, the direct model-free approach consistently outperforms the indirect solution when multiple epochs are allowed. The iterative refinement of the optimal control law over the epoch loop provides the direct approach a clear advantage over the indirect method, which relies on a single set of system data to determine the identified model and control.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [209] [Content-Driven Frame-Level Bit Prediction for Rate Control in Versatile Video Coding](https://arxiv.org/abs/2602.06242)
*Amritha Premkumar,Prajit T Rajendran,Vignesh V Menon,Christian Herglotz*

Main category: eess.IV

TL;DR: 本文提出了一种基于视频复杂度分析仪（VCA）特征和随机森林回归的帧级比特消耗预测框架，用于视频编码的比特率控制，在保证编码效率的同时显著降低了编码时间。


<details>
  <summary>Details</summary>
Motivation: 传统的VVC两遍率控制（2pRC）依赖于分析性率-QP模型，该模型难以捕捉时空非线性变化，导致质量不稳定和高复杂度。需要一种更高效、更准确的率控制方法。

Method: 利用视频复杂度分析仪（VCA）提取的轻量级特征和量化参数，结合随机森林回归模型来预测帧级的比特消耗。将该预测框架集成到率控制循环中。

Result: 在超高清序列上，该模型对I、P、B帧的比特消耗预测分别取得了0.93、0.88和0.77的R2值。与2pRC相比，在编码效率相当的情况下，总编码时间减少了33.3%。

Conclusion: 基于VCA驱动的比特预测为传统的率-QP模型提供了一种计算高效且准确的替代方案，能够有效提高率控制的性能。

Abstract: Rate control allocates bits efficiently across frames to meet a target bitrate while maintaining quality. Conventional two-pass rate control (2pRC) in Versatile Video Coding (VVC) relies on analytical rate-QP models, which often fail to capture nonlinear spatial-temporal variations, causing quality instability and high complexity due to multiple trial encodes. This paper proposes a content-adaptive framework that predicts frame-level bit consumption using lightweight features from the Video Complexity Analyzer (VCA) and quantization parameters within a Random Forest regression. On ultra-high-definition sequences encoded with VVenC, the model achieves strong correlation with ground truth, yielding R2 values of 0.93, 0.88, and 0.77 for I-, P-, and B-frames, respectively. Integrated into a rate-control loop, it achieves comparable coding efficiency to 2pRC while reducing total encoding time by 33.3%. The results show that VCA-driven bit prediction provides a computationally efficient and accurate alternative to conventional rate-QP models.

</details>


### [210] [Adaptive Resolution and Chroma Subsampling for Energy-Efficient Video Coding](https://arxiv.org/abs/2602.06100)
*Amritha Premkumar,Christian Herglotz*

Main category: eess.IV

TL;DR: 提出了一种自适应分辨率-色度子采样（ARCS）框架，通过联合优化空间分辨率和色度子采样格式，以平衡感知质量和解码效率，从而在同等视觉质量下实现更高的比特率节省和更低的解码能耗。


<details>
  <summary>Details</summary>
Motivation: 传统的视频编码器采用固定的色度子采样格式（如YUV420），无法充分适应不同内容中色度细节的变化，导致色度质量不佳和比特率分配效率低下。

Method: 提出ARCS框架，通过最大化一个综合的质量-复杂度目标函数，并施加单调性约束，为每个比特率选择最优的（分辨率，色度格式）对。解码效率通过解码时间来衡量。

Result: 与固定的YUV444格式编码相比，ARCS在相同的colorVideoVDP得分下，平均实现了13.48%的比特率节省和62.18%的解码时间（能耗）减少。

Conclusion: ARCS框架引入了色度自适应作为一种新的控制维度，可以实现更节能的视频流传输，在保持感知质量的同时显著降低比特率和解码能耗。

Abstract: Conventional video encoders typically employ a fixed chroma subsampling format, such as YUV420, which may not optimally reflect variations in chroma detail across different types of content. This can lead to suboptimal chroma quality and inefficiencies in bitrate allocation. We propose an Adaptive Resolution-Chroma Subsampling (ARCS) framework that jointly optimizes spatial resolution and chroma subsampling to balance perceptual quality and decoding efficiency. ARCS selects an optimal (resolution, chroma format) pair for each bitrate by maximizing a composite quality-complexity objective, while enforcing monotonicity constraints to ensure smooth transitions between representations. Experimental results using x265 show that, compared to a fixed-format encoding (YUV444), on average, ARCS achieves a 13.48 % bitrate savings and a 62.18 % reduction in decoding time, which we use as a proxy for the decoding energy, to yield the same colorVideoVDP score. The proposed framework introduces chroma adaptivity as a new control dimension for energy-efficient video streaming.

</details>


### [211] [ALIEN: Analytic Latent Watermarking for Controllable Generation](https://arxiv.org/abs/2602.06101)
*Liangqi Lei,Keke Gai,Jing Yu,Qi Wu*

Main category: eess.IV

TL;DR: 该研究提出了一种名为ALIEN的分析性水印框架，用于潜在扩散模型（LDMs），以解决现有水印方法中计算开销大和局部最优的问题。ALIEN通过分析推导时间依赖的调制系数来控制水印嵌入模式，实验证明其在质量和鲁棒性方面优于现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 现有水印方法在优化水印潜变量时，需要计算密集型启发式优化来迭代细化信号，导致训练开销高且容易陷入局部最优。研究者希望找到一种更高效、可控的水印嵌入方法。

Method: 研究者提出了一种名为ALIEN（Analytical Watermarking Framework for Controllable Generation）的分析性水印框架。该框架首次对时间依赖的调制系数进行了分析推导，以指导水印残差的扩散，从而实现可控的水印嵌入模式。

Result: ALIEN-Q 在 5 项质量指标上比现有最先进方法提高了 33.1%。ALIEN-R 在 15 种不同条件下，在生成变体和稳定性威胁方面比现有最先进方法提高了 14.0%。

Conclusion: ALIEN框架通过分析方法解决了潜在扩散模型水印中的计算效率和局部最优问题，并在质量和鲁棒性方面取得了显著的性能提升，为生成模型的水印技术提供了新的解决方案。

Abstract: Watermarking is a technical alternative to safeguarding intellectual property and reducing misuse. Existing methods focus on optimizing watermarked latent variables to balance watermark robustness and fidelity, as Latent diffusion models (LDMs) are considered a powerful tool for generative tasks. However, reliance on computationally intensive heuristic optimization for iterative signal refinement results in high training overhead and local optima entrapment.To address these issues, we propose an \underline{A}na\underline{l}ytical Watermark\underline{i}ng Framework for Controllabl\underline{e} Generatio\underline{n} (ALIEN). We develop the first analytical derivation of the time-dependent modulation coefficient that guides the diffusion of watermark residuals to achieve controllable watermark embedding pattern.Experimental results show that ALIEN-Q outperforms the state-of-the-art by 33.1\% across 5 quality metrics, and ALIEN-R demonstrates 14.0\% improved robustness against generative variant and stability threats compared to the state-of-the-art across 15 distinct conditions. Code can be available at https://anonymous.4open.science/r/ALIEN/.

</details>


### [212] [COSMOS: Coherent Supergaussian Modeling with Spatial Priors for Sparse-View 3D Splatting](https://arxiv.org/abs/2602.06044)
*Chaeyoung Jeong,Kwangsu Kim*

Main category: eess.IV

TL;DR: COSMOS 提出了一种利用 3D 结构先验来改进 3D 高斯泼溅 (3DGS) 在稀疏输入视图下的重建质量的方法，通过引入超高斯分组和注意力机制，有效抑制了过拟合和结构退化。


<details>
  <summary>Details</summary>
Motivation: 现有的 3DGS 方法在稀疏输入视图下容易出现过拟合和结构退化，导致在新视图上的泛化能力差，原因是其优化仅依赖于光度损失而未引入 3D 结构先验。

Method: COSMOS 提出将高斯分散体（Gaussians）根据局部几何线索和外观特征进行分组，形成“超高斯”（supergaussian）单元。通过在超高斯分组之间应用全局自注意力，并在单个高斯分散体之间应用稀疏局部注意力，来整合全局和局部空间信息。这些结构感知特征用于预测高斯分散体的属性，并对组内位置进行正则化，以维持结构一致性和抑制浮动点。

Result: 在 Blender 和 DTU 数据集上的实验表明，COSMOS 在稀疏视图设置下，无需外部深度监督，性能优于现有的最先进方法。

Conclusion: COSMOS 通过引入基于结构先验的超高斯分组和注意力机制，有效地解决了 3DGS 在稀疏视图下的重建问题，提高了重建的一致性和泛化能力，并增强了训练稳定性。

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged as a promising approach for 3D reconstruction, providing explicit, point-based representations and enabling high-quality real time rendering. However, when trained with sparse input views, 3DGS suffers from overfitting and structural degradation, leading to poor generalization on novel views. This limitation arises from its optimization relying solely on photometric loss without incorporating any 3D structure priors. To address this issue, we propose Coherent supergaussian Modeling with Spatial Priors (COSMOS). Inspired by the concept of superpoints from 3D segmentation, COSMOS introduces 3D structure priors by newly defining supergaussian groupings of Gaussians based on local geometric cues and appearance features. To this end, COSMOS applies inter group global self-attention across supergaussian groups and sparse local attention among individual Gaussians, enabling the integration of global and local spatial information. These structure-aware features are then used for predicting Gaussian attributes, facilitating more consistent 3D reconstructions. Furthermore, by leveraging supergaussian-based grouping, COSMOS enforces an intra-group positional regularization to maintain structural coherence and suppress floaters, thereby enhancing training stability under sparse-view conditions. Our experiments on Blender and DTU show that COSMOS surpasses state-of-the-art methods in sparse-view settings without any external depth supervision.

</details>


### [213] [Zero-shot Multi-Contrast Brain MRI Registration by Intensity Randomizing T1-weighted MRI (LUMIR25)](https://arxiv.org/abs/2602.06292)
*Hengjie Liu,Yimeng Dou,Di Xu,Xinyi Fu,Dan Ruan,Ke Sheng*

Main category: eess.IV

TL;DR: 该论文提出了一种在LUMIR25挑战赛中获得第一名的零样本医学图像配准方法，该方法通过多模态损失、强度随机化和轻量级实例特定优化来应对域偏移问题。


<details>
  <summary>Details</summary>
Motivation: LUMIR25挑战赛专注于在存在域偏移（高场MRI、病理大脑、不同MRI对比度）的情况下进行零样本配准，而训练数据仅限于域内T1加权脑MRI。研究动机是开发一种能够从有限的域内数据泛化到多样化域外数据的配准方法。

Method: 该方法结合了三种策略：1. 基于模态无关邻域描述符（MIND）的多模态损失函数，以提高对不同MRI对比度的鲁棒性；2. 强度随机化作为外观增强技术，以模拟不同的MRI对比度；3. 推理时对特征编码器进行轻量级的实例特定优化（ISO），以适应特定的域偏移。

Result: 在验证集上，该方法在T1-T2配准方面取得了合理的准确性，同时保持了良好的形变规则性。该方法在LUMIR25挑战赛测试集上取得了总排名第一的成绩。

Conclusion: 通过采用MIND多模态损失、强度随机化和轻量级ISO，即使只在T1加权MRI上训练，也能实现对不同MRI对比度和域偏移的良好泛化性能，从而在零样本医学图像配准任务中取得优异成果。

Abstract: In this paper, we summarize the methods and results of our submission to the LUMIR25 challenge in Learn2Reg 2025, which achieved 1st place overall on the test set. Extended from LUMIR24, this year's task focuses on zero-shot registration under domain shifts (high-field MRI, pathological brains, and various MRI contrasts), while the training data comprise only in-domain T1-weighted brain MRI. We start with a meticulous analysis of LUMIR24 winners to identify the main contributors to good monomodal registration performance. To achieve good generalization with diverse contrasts from a model trained with T1-weighted MRI only, we employ three simple but effective strategies: (i) a multimodal loss based on the modality-independent neighborhood descriptor (MIND), (ii) intensity randomization for appearance augmentation, and (iii) lightweight instance-specific optimization (ISO) on feature encoders at inference time. On the validation set, our approach achieves reasonable T1-T2 registration accuracy while maintaining good deformation regularity.

</details>


### [214] [AS-Mamba: Asymmetric Self-Guided Mamba Decoupled Iterative Network for Metal Artifact Reduction](https://arxiv.org/abs/2602.06350)
*Bowen Ning,Zekun Zhou,Xinyi Zhong,Zhongzhen Wang,HongXin Wu,HaiTao Wang,Liu Shi,Qiegen Liu*

Main category: eess.IV

TL;DR: 提出了一种名为AS-Mamba的新型深度学习模型，用于减少CT图像中的金属伪影。该模型结合了Mamba的序列建模能力、频率域校正和自监督对比正则化，在处理方向性条纹伪影和保持结构细节方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在明确捕捉金属伪影的方向性几何特征方面存在不足，导致结构恢复效果不佳。希望开发一种能更有效地处理金属伪影的模型，以提高CT图像质量，辅助临床诊断。

Method: 提出Asymmetric Self-Guided Mamba (AS-Mamba)模型。利用Mamba架构捕捉和抑制方向性条纹伪影，并引入频率域校正机制来解决束伪影引起的光强不均。此外，采用自监督对比正则化策略来缩小不同临床场景下的分布差异。

Result: AS-Mamba在公共和临床牙科CBCT数据集上的实验表明，该模型在抑制方向性条纹和保留结构细节方面取得了优于现有方法的性能。

Conclusion: 将物理几何先验知识融入深度网络设计是有效的。AS-Mamba通过结合SSM的序列建模能力、频率域校正和自监督对比学习，能够有效地减少金属伪影，并恢复CT图像的质量。

Abstract: Metal artifact significantly degrades Computed Tomography (CT) image quality, impeding accurate clinical diagnosis. However, existing deep learning approaches, such as CNN and Transformer, often fail to explicitly capture the directional geometric features of artifacts, leading to compromised structural restoration. To address these limitations, we propose the Asymmetric Self-Guided Mamba (AS-Mamba) for metal artifact reduction. Specifically, the linear propagation of metal-induced streak artifacts aligns well with the sequential modeling capability of State Space Models (SSMs). Consequently, the Mamba architecture is leveraged to explicitly capture and suppress these directional artifacts. Simultaneously, a frequency domain correction mechanism is incorporated to rectify the global amplitude spectrum, thereby mitigating intensity inhomogeneity caused by beam hardening. Furthermore, to bridge the distribution gap across diverse clinical scenarios, we introduce a self-guided contrastive regularization strategy. Extensive experiments on public andclinical dental CBCT datasets demonstrate that AS-Mamba achieves superior performance in suppressing directional streaks and preserving structural details, validating the effectiveness of integrating physical geometric priors into deep network design.

</details>


### [215] [Orientation-Robust Latent Motion Trajectory Learning for Annotation-free Cardiac Phase Detection in Fetal Echocardiography](https://arxiv.org/abs/2602.06761)
*Yingyu Yang,Qianye Yang,Can Peng,Elena D'Alberti,Olga Patey,Aris T. Papageorghiou,J. Alison Noble*

Main category: eess.IV

TL;DR: 提出了一种名为ORBIT的无监督学习框架，可以从胎儿超声心动图的四腔视图中准确检测心动周期的舒张末期和收缩末期，即使在胎儿心脏方向变化的情况下也能保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 手动识别胎儿超声心动图中的心动周期（舒张末期和收缩末期）耗时耗力，且缺乏胎儿心电图时尤其困难。研究旨在实现心动周期的自动化检测，以克服这一瓶颈。

Method: ORBIT是一个无监督学习框架，利用视频帧的配准作为自监督任务，学习心肌变形的潜在运动轨迹。通过识别轨迹的转折点来确定心动周期的舒张末期和收缩末期。该方法对胎儿心脏的方向变化具有鲁棒性。

Result: ORBIT在正常胎儿超声心动图和先天性心脏病（CHD）病例上均取得了优异的性能，平均绝对误差（MAE）在正常病例中分别为1.9帧（舒张末期）和1.6帧（收缩末期），在CHD病例中分别为2.4帧（舒张末期）和2.1帧（收缩末期）。其性能优于现有对固定方向有约束的无标注方法。

Conclusion: ORBIT能够从四腔视图胎儿超声心动图中稳健地检测心动周期，为实现先天性心脏病（CHD）的自动化分析奠定了基础，有望减少人工标注的负担并提高检测效率。

Abstract: Fetal echocardiography is essential for detecting congenital heart disease (CHD), facilitating pregnancy management, optimized delivery planning, and timely postnatal interventions. Among standard imaging planes, the four-chamber (4CH) view provides comprehensive information for CHD diagnosis, where clinicians carefully inspect the end-diastolic (ED) and end-systolic (ES) phases to evaluate cardiac structure and motion. Automated detection of these cardiac phases is thus a critical component toward fully automated CHD analysis. Yet, in the absence of fetal electrocardiography (ECG), manual identification of ED and ES frames remains a labor-intensive bottleneck. We present ORBIT (Orientation-Robust Beat Inference from Trajectories), a self-supervised framework that identifies cardiac phases without manual annotations under various fetal heart orientation. ORBIT employs registration as self-supervision task and learns a latent motion trajectory of cardiac deformation, whose turning points capture transitions between cardiac relaxation and contraction, enabling accurate and orientation-robust localization of ED and ES frames across diverse fetal positions. Trained exclusively on normal fetal echocardiography videos, ORBIT achieves consistent performance on both normal (MAE = 1.9 frames for ED and 1.6 for ES) and CHD cases (MAE = 2.4 frames for ED and 2.1 for ES), outperforming existing annotation-free approaches constrained by fixed orientation assumptions. These results highlight the potential of ORBIT to facilitate robust cardiac phase detection directly from 4CH fetal echocardiography.

</details>
