<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 48]
- [cs.CV](#cs.CV) [Total: 123]
- [cs.CL](#cs.CL) [Total: 60]
- [cs.RO](#cs.RO) [Total: 55]
- [eess.SY](#eess.SY) [Total: 22]
- [eess.IV](#eess.IV) [Total: 7]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services](https://arxiv.org/abs/2509.18101)
*Guanzhong Pan,Haibo Wang*

Main category: cs.AI

TL;DR: 本文提出了一个成本效益分析框架，帮助组织确定何时本地部署开源大型语言模型（LLM）比订阅商业LLM服务更具经济可行性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的普及，组织面临选择商业LLM服务或本地部署的决策。商业服务易于访问和扩展，但存在数据隐私、供应商锁定和长期成本问题；本地部署开源模型则可解决这些问题，因此需要一个框架来评估其经济可行性。

Method: 本文提出了一个成本效益分析框架。该框架考虑了硬件要求、运营支出以及包括Qwen、Llama、Mistral等最新开源模型的性能基准。然后，将本地部署的总成本与主要云服务提供商的订阅费用进行比较。

Result: 研究结果提供了基于使用水平和性能需求的预估盈亏平衡点，即本地部署何时比商业订阅服务更经济。

Conclusion: 这些结果为组织规划其LLM战略提供了一个实用的框架，帮助它们做出明智的部署决策。

Abstract: Large language models (LLMs) are becoming increasingly widespread.
Organizations that want to use AI for productivity now face an important
decision. They can subscribe to commercial LLM services or deploy models on
their own infrastructure. Cloud services from providers such as OpenAI,
Anthropic, and Google are attractive because they provide easy access to
state-of-the-art models and are easy to scale. However, concerns about data
privacy, the difficulty of switching service providers, and long-term operating
costs have driven interest in local deployment of open-source models. This
paper presents a cost-benefit analysis framework to help organizations
determine when on-premise LLM deployment becomes economically viable compared
to commercial subscription services. We consider the hardware requirements,
operational expenses, and performance benchmarks of the latest open-source
models, including Qwen, Llama, Mistral, and etc. Then we compare the total cost
of deploying these models locally with the major cloud providers subscription
fee. Our findings provide an estimated breakeven point based on usage levels
and performance needs. These results give organizations a practical framework
for planning their LLM strategies.

</details>


### [2] [SPADE: A Large Language Model Framework for Soil Moisture Pattern Recognition and Anomaly Detection in Precision Agriculture](https://arxiv.org/abs/2509.18123)
*Yeonju Lee,Rui Qi Chen,Joseph Oboamah,Po Nien Su,Wei-zhen Liang,Yeyin Shi,Lu Gan,Yongsheng Chen,Xin Qiao,Jing Li*

Main category: cs.AI

TL;DR: 本研究引入了SPADE框架，利用大型语言模型（LLMs，如ChatGPT-4.1）对土壤湿度时间序列数据进行零样本分析，以联合检测灌溉模式和异常，并生成可解释的报告，在实际应用中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 准确解释土壤湿度模式对灌溉调度和作物管理至关重要。然而，现有的土壤湿度时间序列分析方法（如基于阈值的规则或数据密集型机器学习/深度学习模型）在适应性和可解释性方面存在局限。

Method: SPADE框架利用大型语言模型（具体为ChatGPT-4.1）的推理和指令遵循能力，进行零样本分析。它将时间序列数据转换为文本表示，并设计了领域知情的提示模板。通过这种方式，SPADE能够识别灌溉事件、估算净灌溉增益、检测和分类异常，并生成结构化、可解释的报告。

Result: SPADE在真实世界的土壤湿度传感器数据上进行了实验。结果表明，在异常检测方面，SPADE优于现有方法，实现了更高的召回率和F1分数，并能准确分类异常类型。此外，SPADE在检测灌溉事件方面也取得了高精度和高召回率。SPADE生成的报告提供了土壤湿度分析的可解释性和可用性。

Conclusion: 本研究强调了大型语言模型作为可扩展、适应性强的工具在精准农业中的潜力。它们能够整合定性知识和数据驱动的推理，为准确的土壤湿度监测和改进的灌溉调度提供可操作的见解。

Abstract: Accurate interpretation of soil moisture patterns is critical for irrigation
scheduling and crop management, yet existing approaches for soil moisture
time-series analysis either rely on threshold-based rules or data-hungry
machine learning or deep learning models that are limited in adaptability and
interpretability. In this study, we introduce SPADE (Soil moisture Pattern and
Anomaly DEtection), an integrated framework that leverages large language
models (LLMs) to jointly detect irrigation patterns and anomalies in soil
moisture time-series data. SPADE utilizes ChatGPT-4.1 for its advanced
reasoning and instruction-following capabilities, enabling zero-shot analysis
without requiring task-specific annotation or fine-tuning. By converting
time-series data into a textual representation and designing domain-informed
prompt templates, SPADE identifies irrigation events, estimates net irrigation
gains, detects, classifies anomalies, and produces structured, interpretable
reports. Experiments were conducted on real-world soil moisture sensor data
from commercial and experimental farms cultivating multiple crops across the
United States. Results demonstrate that SPADE outperforms the existing method
in anomaly detection, achieving higher recall and F1 scores and accurately
classifying anomaly types. Furthermore, SPADE achieved high precision and
recall in detecting irrigation events, indicating its strong capability to
capture irrigation patterns accurately. SPADE's reports provide
interpretability and usability of soil moisture analytics. This study
highlights the potential of LLMs as scalable, adaptable tools for precision
agriculture, which is capable of integrating qualitative knowledge and
data-driven reasoning to produce actionable insights for accurate soil moisture
monitoring and improved irrigation scheduling from soil moisture time-series
data.

</details>


### [3] [Position Paper: Integrating Explainability and Uncertainty Estimation in Medical AI](https://arxiv.org/abs/2509.18132)
*Xiuyi Fan*

Main category: cs.AI

TL;DR: 本文提出可解释不确定性估计（XUE），旨在将可解释性与不确定性量化相结合，以增强医疗AI的信任度和可用性，解决当前医疗AI在量化和传达不确定性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 医疗实践中不确定性普遍存在，但现有医疗AI系统未能明确量化或以符合临床推理的方式传达不确定性。现有可解释AI（XAI）侧重于预测解释而非置信度，而不确定性估计（UE）缺乏直观解释，两者脱节限制了AI在医学中的应用。

Method: 本文提出了可解释不确定性估计（XUE）的概念，系统地将医学不确定性映射到AI不确定性概念，识别了实现XUE的关键挑战。同时，概述了推进XUE的技术方向，包括多模态不确定性量化、模型无关可视化技术和不确定性感知决策支持系统，并提出了指导原则。

Result: 分析强调了AI系统不仅需要生成可靠预测，还需要以临床有意义的方式阐明置信水平。通过弥合可解释性与不确定性之间的鸿沟，为开发与真实世界临床复杂性相符的值得信赖的医疗AI系统铺平了道路。

Conclusion: 本研究通过整合可解释性与不确定性，为开发值得信赖的医疗AI做出了贡献，有助于构建与实际临床复杂性对齐的AI系统，从而提升医疗AI的信任度和可用性。

Abstract: Uncertainty is a fundamental challenge in medical practice, but current
medical AI systems fail to explicitly quantify or communicate uncertainty in a
way that aligns with clinical reasoning. Existing XAI works focus on
interpreting model predictions but do not capture the confidence or reliability
of these predictions. Conversely, uncertainty estimation (UE) techniques
provide confidence measures but lack intuitive explanations. The disconnect
between these two areas limits AI adoption in medicine. To address this gap, we
propose Explainable Uncertainty Estimation (XUE) that integrates explainability
with uncertainty quantification to enhance trust and usability in medical AI.
We systematically map medical uncertainty to AI uncertainty concepts and
identify key challenges in implementing XUE. We outline technical directions
for advancing XUE, including multimodal uncertainty quantification,
model-agnostic visualization techniques, and uncertainty-aware decision support
systems. Lastly, we propose guiding principles to ensure effective XUE
realisation. Our analysis highlights the need for AI systems that not only
generate reliable predictions but also articulate confidence levels in a
clinically meaningful way. This work contributes to the development of
trustworthy medical AI by bridging explainability and uncertainty, paving the
way for AI systems that are aligned with real-world clinical complexities.

</details>


### [4] [HSGM: Hierarchical Segment-Graph Memory for Scalable Long-Text Semantics](https://arxiv.org/abs/2509.18168)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: 本文提出分层段图记忆（HSGM）框架，通过将长文档分解为语义段并构建分层图记忆，有效解决了长文档语义解析中二次增长的复杂度和内存问题，实现了可扩展、准确的语义建模。


<details>
  <summary>Details</summary>
Motivation: 长文档的语义解析面临挑战，主要原因是成对组合和内存需求呈二次增长，导致计算成本过高。

Method: HSGM将长文档（长度N）分解为M个有意义的段，在每个段上构建“局部语义图”，并提取紧凑的“摘要节点”以形成“全局图记忆”。它支持增量更新和分层查询处理，通过摘要节点定位相关段，然后在局部图中进行细粒度推理。

Result: 理论上，HSGM将最坏情况下的复杂度从O(N^2)降低到O(N k + (N/k)^2)，并推导了节点摘要和稀疏化阈值引入的近似误差的Frobenius范数界限。经验上，在三个基准测试（长文档AMR解析、段级语义角色标注和法律事件提取）中，HSGM实现了2-4倍的推理速度提升，超过60%的峰值内存减少，以及不低于95%的基线准确率。

Conclusion: HSGM方法为超长文本的语义建模提供了可扩展、准确的解决方案，使其能够应用于实时和资源受限的自然语言处理场景。

Abstract: Semantic parsing of long documents remains challenging due to quadratic
growth in pairwise composition and memory requirements. We introduce
\textbf{Hierarchical Segment-Graph Memory (HSGM)}, a novel framework that
decomposes an input of length $N$ into $M$ meaningful segments, constructs
\emph{Local Semantic Graphs} on each segment, and extracts compact
\emph{summary nodes} to form a \emph{Global Graph Memory}. HSGM supports
\emph{incremental updates} -- only newly arrived segments incur local graph
construction and summary-node integration -- while \emph{Hierarchical Query
Processing} locates relevant segments via top-$K$ retrieval over summary nodes
and then performs fine-grained reasoning within their local graphs.
  Theoretically, HSGM reduces worst-case complexity from $O(N^2)$ to
$O\!\left(N\,k + (N/k)^2\right)$, with segment size $k \ll N$, and we derive
Frobenius-norm bounds on the approximation error introduced by node
summarization and sparsification thresholds. Empirically, on three benchmarks
-- long-document AMR parsing, segment-level semantic role labeling (OntoNotes),
and legal event extraction -- HSGM achieves \emph{2--4$\times$ inference
speedup}, \emph{$>60\%$ reduction} in peak memory, and \emph{$\ge 95\%$} of
baseline accuracy. Our approach unlocks scalable, accurate semantic modeling
for ultra-long texts, enabling real-time and resource-constrained NLP
applications.

</details>


### [5] [Foam-Agent: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM](https://arxiv.org/abs/2509.18178)
*Ling Yue,Nithin Somasekharan,Tingwen Zhang,Yadi Cao,Shaowu Pan*

Main category: cs.AI

TL;DR: Foam-Agent是一个多智能体框架，通过自然语言提示实现OpenFOAM计算流体动力学（CFD）模拟的端到端自动化，显著降低了使用门槛。


<details>
  <summary>Details</summary>
Motivation: 计算流体动力学（CFD）是工程领域重要的模拟工具，但其学习曲线陡峭且手动设置复杂，构成了显著的使用障碍。

Method: 引入了Foam-Agent，一个多智能体框架，其关键创新包括：1. 全面的端到端模拟自动化，涵盖高级预处理（网格生成、处理外部网格文件）、HPC提交脚本生成和后处理可视化。2. 可组合的服务架构，通过模型上下文协议（MCP）将核心功能暴露为可调用工具，便于集成。3. 高保真配置生成，利用分层多索引RAG进行精确上下文检索和依赖感知生成过程，确保配置一致性。

Result: 在110个模拟任务基准测试中，Foam-Agent与Claude 3.5 Sonnet结合实现了88.2%的成功率，显著优于现有框架（MetaOpenFOAM为55.5%）。

Conclusion: Foam-Agent极大地降低了CFD的专业知识门槛，展示了专业多智能体系统如何使复杂的科学计算大众化。

Abstract: Computational Fluid Dynamics (CFD) is an essential simulation tool in
engineering, yet its steep learning curve and complex manual setup create
significant barriers. To address these challenges, we introduce Foam-Agent, a
multi-agent framework that automates the entire end-to-end OpenFOAM workflow
from a single natural language prompt. Our key innovations address critical
gaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation:
Foam-Agent is the first system to manage the full simulation pipeline,
including advanced pre-processing with a versatile Meshing Agent capable of
handling external mesh files and generating new geometries via Gmsh, automatic
generation of HPC submission scripts, and post-simulation visualization via
ParaView. 2. Composable Service Architecture: Going beyond a monolithic agent,
the framework uses Model Context Protocol (MCP) to expose its core functions as
discrete, callable tools. This allows for flexible integration and use by other
agentic systems, such as Claude-code, for more exploratory workflows. 3.
High-Fidelity Configuration Generation: We achieve superior accuracy through a
Hierarchical Multi-Index RAG for precise context retrieval and a
dependency-aware generation process that ensures configuration consistency.
Evaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2%
success rate with Claude 3.5 Sonnet, significantly outperforming existing
frameworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the
expertise barrier for CFD, demonstrating how specialized multi-agent systems
can democratize complex scientific computing. The code is public at
https://github.com/csml-rpi/Foam-Agent.

</details>


### [6] [Large Language Models and Operations Research: A Structured Survey](https://arxiv.org/abs/2509.18180)
*Yang Wang,Kai Li*

Main category: cs.AI

TL;DR: 本文综述了大型语言模型（LLMs）在运筹学（OR）中的最新进展，将其整合方法分为自动建模、辅助优化和直接求解三类，并探讨了评估基准、应用、开放性问题及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统的运筹学方法在处理大规模、动态、多约束问题时，由于依赖专家建模和手动参数调整，面临诸多挑战。大型语言模型（LLMs）凭借其语义理解、结构化生成和推理能力，有望解决这些局限性。

Method: 本文通过文献综述的方式，将LLMs与OR的整合方法归纳为三个主要方向：自动建模、辅助优化和直接求解。同时，文章还回顾了评估基准和特定领域应用。

Result: LLMs能够将自然语言描述转化为数学模型或可执行代码，生成启发式算法，演化算法，并直接处理优化任务。然而，研究发现主要存在语义到结构映射不稳定、研究进展碎片化、泛化能力有限以及评估系统不足等关键开放性问题。

Conclusion: LLMs在运筹学中展现出巨大潜力，但仍面临诸多挑战。本综述总结了当前进展，指出了开放性问题，并为未来LLMs在运筹学领域的深入研究提供了方向。

Abstract: Operations research (OR) provides fundamental methodologies for complex
system decision-making, with established applications in transportation, supply
chain management, and production scheduling. Traditional approaches, which
depend on expert-based modeling and manual parameter adjustment, often face
challenges in handling large-scale, dynamic, and multi-constraint problems.
Recently, large language models (LLMs) have shown potential to address these
limitations through semantic understanding, structured generation, and
reasoning control. LLMs can translate natural language descriptions into
mathematical models or executable code, generate heuristics, evolve algorithms,
and directly tackle optimization tasks. This paper surveys recent progress on
the integration of LLMs into OR, organizing methods into three main directions:
automatic modeling, auxiliary optimization, and direct solving. It further
reviews evaluation benchmarks and domain-specific applications, and summarizes
key open issues such as unstable semantic-to-structure mapping, fragmented
research progress, limited generalization, and insufficient evaluation systems.
Finally, the survey outlines possible research avenues for advancing the role
of LLMs in OR.

</details>


### [7] [Synthesizing Attitudes, Predicting Actions (SAPA): Behavioral Theory-Guided LLMs for Ridesourcing Mode Choice Modeling](https://arxiv.org/abs/2509.18181)
*Mustafa Sameen,Xiaojian Zhang,Xilei Zhao*

Main category: cs.AI

TL;DR: 本文提出SAPA框架，利用大型语言模型（LLM）合成基于理论的潜在态度，以显著提高网约车出行模式选择的预测准确性，解决了现有模型在心理因素捕捉和类别不平衡方面的局限。


<details>
  <summary>Details</summary>
Motivation: 现有的网约车模式选择预测模型在捕捉关键心理因素方面存在局限，导致预测准确性不足；同时，由于网约车出行占日常出行的比例较小，模型还面临严重的类别不平衡挑战。

Method: 本文引入了“合成态度，预测行动”（SAPA）框架，这是一种分层方法：首先，LLM从原始出行调查数据中生成定性旅客画像；其次，基于人口统计学和行为特征（并结合画像）训练倾向得分模型，生成个体得分；接着，LLM为理论驱动的潜在变量（如时间敏感度、成本敏感度）分配定量分数；最后，一个分类器整合倾向得分、潜在变量得分（及其交互项）和可观测的出行属性，预测网约车模式选择。

Result: 在大规模、多年的出行调查数据上进行的实验表明，SAPA框架显著优于现有最先进的基线模型，在保留测试集上的PR-AUC指标方面，网约车选择预测的准确性提高了高达75.9%。

Conclusion: 本研究提供了一个强大的工具，能够准确预测网约车模式选择，并提出了一种易于推广到各种应用场景的方法论。

Abstract: Accurate modeling of ridesourcing mode choices is essential for designing and
implementing effective traffic management policies for reducing congestion,
improving mobility, and allocating resources more efficiently. Existing models
for predicting ridesourcing mode choices often suffer from limited predictive
accuracy due to their inability to capture key psychological factors, and are
further challenged by severe class imbalance, as ridesourcing trips comprise
only a small fraction of individuals' daily travel. To address these
limitations, this paper introduces the Synthesizing Attitudes, Predicting
Actions (SAPA) framework, a hierarchical approach that uses Large Language
Models (LLMs) to synthesize theory-grounded latent attitudes to predict
ridesourcing choices. SAPA first uses an LLM to generate qualitative traveler
personas from raw travel survey data and then trains a propensity-score model
on demographic and behavioral features, enriched by those personas, to produce
an individual-level score. Next, the LLM assigns quantitative scores to
theory-driven latent variables (e.g., time and cost sensitivity), and a final
classifier integrates the propensity score, latent-variable scores (with their
interaction terms), and observable trip attributes to predict ridesourcing mode
choice. Experiments on a large-scale, multi-year travel survey show that SAPA
significantly outperforms state-of-the-art baselines, improving ridesourcing
choice predictions by up to 75.9% in terms of PR-AUC on a held-out test set.
This study provides a powerful tool for accurately predicting ridesourcing mode
choices, and provides a methodology that is readily transferable to various
applications.

</details>


### [8] [An Outcome-Based Educational Recommender System](https://arxiv.org/abs/2509.18186)
*Nursultan Askarbekuly,Timur Fayzrakhmanov,Sladjan Babarogić,Ivan Luković*

Main category: cs.AI

TL;DR: 本文介绍了一种名为 OBER 的基于学习成果的教育推荐系统，它能直接评估算法对学习掌握程度的促进作用，并通过随机对照试验发现不同推荐方法在保留率和掌握度上的差异。


<details>
  <summary>Details</summary>
Motivation: 大多数教育推荐系统仅基于点击或评分进行调优和评估，其真正的教学效果（即对学习掌握程度的影响）尚不明确。

Method: 引入了 OBER 系统，它将学习成果和评估项直接嵌入数据模式，使得任何算法都能基于学习掌握度进行评估。OBER 采用极简实体关系模型、日志驱动的掌握度公式和插件式架构。在一个非正式领域的电子学习系统中，通过一项为期两周的随机分组测试进行了评估，涉及超过 5700 名学习者，比较了三种方法：固定专家路径、协同过滤（CF）和基于知识（KB）的过滤。

Result: 协同过滤（CF）最大化了学习者保留率，而固定专家路径实现了最高的学习掌握度。OBER 能够从相同的日志中得出业务、相关性和学习指标，使得实践者无需额外测试开销即可权衡相关性和参与度与学习成果的掌握度。

Conclusion: OBER 提供了一个方法无关且易于扩展的框架，允许教育推荐系统直接评估其教学影响和学习成果掌握度，为未来的自适应或情境感知推荐器奠定基础。

Abstract: Most educational recommender systems are tuned and judged on click- or
rating-based relevance, leaving their true pedagogical impact unclear. We
introduce OBER-an Outcome-Based Educational Recommender that embeds learning
outcomes and assessment items directly into the data schema, so any algorithm
can be evaluated on the mastery it fosters. OBER uses a minimalist
entity-relation model, a log-driven mastery formula, and a plug-in
architecture. Integrated into an e-learning system in non-formal domain, it was
evaluated trough a two-week randomized split test with over 5 700 learners
across three methods: fixed expert trajectory, collaborative filtering (CF),
and knowledge-based (KB) filtering. CF maximized retention, but the fixed path
achieved the highest mastery. Because OBER derives business, relevance, and
learning metrics from the same logs, it lets practitioners weigh relevance and
engagement against outcome mastery with no extra testing overhead. The
framework is method-agnostic and readily extensible to future adaptive or
context-aware recommenders.

</details>


### [9] [MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation](https://arxiv.org/abs/2509.18198)
*Rui Liu,Zikang Wang,Peng Gao,Yu Shen,Pratap Tokekar,Ming Lin*

Main category: cs.AI

TL;DR: 本文提出MMCD框架，用于在互联自动驾驶中实现多模态协同决策，通过跨模态知识蒸馏确保在部分数据模态缺失时仍能稳健运行，显著提升驾驶安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在事故多发环境下决策鲁棒性面临挑战，单车传感器范围有限且视线受阻。现有多车辆互联和多模态方法通常假设训练和测试时所有数据模态和互联车辆均可用，这在实际中因传感器故障或车辆缺失而不可行。

Method: 本文引入MMCD（多模态协同决策）框架，融合自我车辆和协作车辆的多模态（RGB图像和LiDAR点云）观测以增强决策。为确保在测试时某些数据模态不可用时的鲁棒性，提出一种基于跨模态知识蒸馏的方法，采用教师-学生模型结构：教师模型使用多种数据模态训练，学生模型则设计为在模态减少的情况下有效运行。

Result: 在“互联自动驾驶（地面车辆）”和“空地车辆协作”实验中，MMCD方法将驾驶安全性提高了高达20.7%，在检测潜在事故和做出安全驾驶决策方面超越了现有最佳基线。

Conclusion: MMCD框架为互联自动驾驶提供了一个新颖且鲁棒的解决方案，通过有效的多模态融合和知识蒸馏，即使在部分数据模态不可用的情况下也能显著提升驾驶安全性。

Abstract: Autonomous systems have advanced significantly, but challenges persist in
accident-prone environments where robust decision-making is crucial. A single
vehicle's limited sensor range and obstructed views increase the likelihood of
accidents. Multi-vehicle connected systems and multi-modal approaches,
leveraging RGB images and LiDAR point clouds, have emerged as promising
solutions. However, existing methods often assume the availability of all data
modalities and connected vehicles during both training and testing, which is
impractical due to potential sensor failures or missing connected vehicles. To
address these challenges, we introduce a novel framework MMCD (Multi-Modal
Collaborative Decision-making) for connected autonomy. Our framework fuses
multi-modal observations from ego and collaborative vehicles to enhance
decision-making under challenging conditions. To ensure robust performance when
certain data modalities are unavailable during testing, we propose an approach
based on cross-modal knowledge distillation with a teacher-student model
structure. The teacher model is trained with multiple data modalities, while
the student model is designed to operate effectively with reduced modalities.
In experiments on $\textit{connected autonomous driving with ground vehicles}$
and $\textit{aerial-ground vehicles collaboration}$, our method improves
driving safety by up to ${\it 20.7}\%$, surpassing the best-existing baseline
in detecting potential accidents and making safe driving decisions. More
information can be found on our website https://ruiiu.github.io/mmcd.

</details>


### [10] [Change in Quantitative Bipolar Argumentation: Sufficient, Necessary, and Counterfactual Explanations](https://arxiv.org/abs/2509.18215)
*Timotheus Kampik,Kristijonas Čyras,José Ruiz Alarcón*

Main category: cs.AI

TL;DR: 本文提出了一种形式化方法，用于解释量化双极论证框架（QBAFs）中推理变化的原因，通过追溯论证强度偏序的变化（强度不一致性）并将其归因于特定论证。


<details>
  <summary>Details</summary>
Motivation: 当QBAF被更新时，其推导出的结论可能会发生变化。理解这些推理变化（特别是论证强度偏序的变化）的原因对于解释QBAF的行为至关重要。

Method: 该研究通过定义“强度不一致性”来追踪QBAF更新后，特定“主题论证”的强度偏序的变化。它将这些不一致性的原因追溯到具体的论证，并识别出充分、必要和反事实的解释。此外，还提出了一种基于启发式的方法来寻找这些解释，并提供了实现。

Result: 研究表明，强度不一致性解释存在，当且仅当更新导致了强度不一致性。同时，提供了一种基于启发式的方法来促进强度不一致性解释的搜索，并提供了相应的实现。

Conclusion: 该论文为解释QBAFs中推理变化提供了一种形式化方法，通过识别和解释论证强度偏序的“强度不一致性”来追溯其原因，并提供了一种实用的启发式搜索方案。

Abstract: This paper presents a formal approach to explaining change of inference in
Quantitative Bipolar Argumentation Frameworks (QBAFs). When drawing conclusions
from a QBAF and updating the QBAF to then again draw conclusions (and so on),
our approach traces changes -- which we call strength inconsistencies -- in the
partial order over argument strengths that a semantics establishes on some
arguments of interest, called topic arguments. We trace the causes of strength
inconsistencies to specific arguments, which then serve as explanations. We
identify sufficient, necessary, and counterfactual explanations for strength
inconsistencies and show that strength inconsistency explanations exist if and
only if an update leads to strength inconsistency. We define a heuristic-based
approach to facilitate the search for strength inconsistency explanations, for
which we also provide an implementation.

</details>


### [11] [nDNA -- the Semantic Helix of Artificial Cognition](https://arxiv.org/abs/2509.18216)
*Amitava Das*

Main category: cs.AI

TL;DR: 本文提出“神经DNA”（nDNA）作为一种语义基因型表示，通过模型潜在几何的内在属性捕捉AI基础模型的内部认知身份，并开创“神经基因组学”领域，以研究AI模型的演化、继承和漂移。


<details>
  <summary>Details</summary>
Motivation: 随着AI基础模型能力的增强，研究者们希望深入理解其内部认知身份，而非仅仅是外在表现和输出。当前的基准测试只能衡量行为，而模型的“灵魂”存在于其潜在几何中。因此，需要一种方法来捕捉这种超越表面性能的内在身份。

Method: 本文提出神经DNA（nDNA），它是一种语义基因型表示，通过信念的内在几何结构捕捉模型的潜在身份。nDNA由三个核心潜在几何维度合成：谱曲率（揭示跨层的概念流曲率）、热力学长度（量化跨层表征转换所需的语义努力）和信念向量场（描绘引导模型信念方向的语义扭转场）。研究将AI基础模型视为语义流体动力学，nDNA是这种流动的物理级读数。

Result: nDNA提供了一个稳定、无坐标的神经DNA指纹，可以追溯模型在预训练、微调、对齐、剪枝、蒸馏和合并等过程中的谱系；测量检查点之间的继承性；检测新数据或目标下特征变化的漂移；并最终用于研究人工认知的演化，以比较模型、诊断风险并管理随时间的变化。

Conclusion: 通过引入神经DNA，本文开辟了一个新的领域——神经基因组学，将模型视为具有可追溯内部认知的数字语义有机体。这使得研究者能够深入理解模型的内部机制，进行模型比较、风险诊断和演化治理，从而超越行为测量，探索AI模型的内在“灵魂”。

Abstract: As AI foundation models grow in capability, a deeper question emerges: What
shapes their internal cognitive identity -- beyond fluency and output?
Benchmarks measure behavior, but the soul of a model resides in its latent
geometry. In this work, we propose Neural DNA (nDNA) as a semantic-genotypic
representation that captures this latent identity through the intrinsic
geometry of belief. At its core, nDNA is synthesized from three principled and
indispensable dimensions of latent geometry: spectral curvature, which reveals
the curvature of conceptual flow across layers; thermodynamic length, which
quantifies the semantic effort required to traverse representational
transitions through layers; and belief vector field, which delineates the
semantic torsion fields that guide a model's belief directional orientations.
Like biological DNA, it encodes ancestry, mutation, and semantic inheritance,
found in finetuning and alignment scars, cultural imprints, and architectural
drift. In naming it, we open a new field: Neural Genomics, where models are not
just tools, but digital semantic organisms with traceable inner cognition.
  Modeling statement. We read AI foundation models as semantic fluid--dynamics:
meaning is transported through layers like fluid in a shaped conduit; nDNA is
the physics-grade readout of that flow -- a geometry-first measure of how
meaning is bent, paid for, and pushed -- yielding a stable, coordinate-free
neural DNA fingerprint tied to on-input behavior; with this fingerprint we
cross into biology: tracing lineages across pretraining, fine-tuning,
alignment, pruning, distillation, and merges; measuring inheritance between
checkpoints; detecting drift as traits shift under new data or objectives; and,
ultimately, studying the evolution of artificial cognition to compare models,
diagnose risks, and govern change over time.

</details>


### [12] [Similarity Field Theory: A Mathematical Framework for Intelligence](https://arxiv.org/abs/2509.18218)
*Kei-Sing Ng*

Main category: cs.AI

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: We posit that persisting and transforming similarity relations form the
structural basis of any comprehensible dynamic system. This paper introduces
Similarity Field Theory, a mathematical framework that formalizes the
principles governing similarity values among entities and their evolution. We
define: (1) a similarity field $S: U \times U \to [0,1]$ over a universe of
entities $U$, satisfying reflexivity $S(E,E)=1$ and treated as a directed
relational field (asymmetry and non-transitivity are allowed); (2) the
evolution of a system through a sequence $Z_p = (X_p, S^{(p)})$ indexed by
$p=0,1,2,\ldots$; (3) concepts $K$ as entities that induce fibers
$F_{\alpha}(K) = { E \in U \mid S(E,K) \ge \alpha }$, i.e., superlevel sets of
the unary map $S_K(E) := S(E,K)$; and (4) a generative operator $G$ that
produces new entities. Within this framework, we formalize a generative
definition of intelligence: an operator $G$ is intelligent with respect to a
concept $K$ if, given a system containing entities belonging to the fiber of
$K$, it generates new entities that also belong to that fiber. Similarity Field
Theory thus offers a foundational language for characterizing, comparing, and
constructing intelligent systems. We prove two theorems: (i) asymmetry blocks
mutual inclusion; and (ii) stability requires either an anchor coordinate or
eventual confinement within a level set of $f$. These results ensure that the
evolution of similarity fields is both constrained and interpretable,
culminating in an exploration of how the framework allows us to interpret large
language models and use them as experimental probes into societal cognition.

</details>


### [13] [Multimodal Health Risk Prediction System for Chronic Diseases via Vision-Language Fusion and Large Language Models](https://arxiv.org/abs/2509.18221)
*Dingxin Lu,Shurui Wu,Xinyi Huang*

Main category: cs.AI

TL;DR: VL-RiskFormer是一个分层堆叠的视觉-语言多模态Transformer模型，通过整合多种临床数据，并结合LLM推理头，旨在主动预测个体健康风险。


<details>
  <summary>Details</summary>
Motivation: 慢性病负担日益加重，临床数据（医学影像、文本记录、可穿戴设备数据等）呈现多模态和异构性，迫切需要一个统一的多模态AI框架来主动预测个体健康风险。

Method: 本文提出了VL-RiskFormer，一个分层堆叠的视觉-语言多模态Transformer，其顶层嵌入了大型语言模型（LLM）推理头。该系统基于现有视觉-语言模型的双流架构，并引入了四项创新：(i) 使用动量更新编码器和去偏InfoNCE损失，对放射影像、眼底图和可穿戴设备照片与临床叙述进行跨模态比较和细粒度对齐预训练；(ii) 通过自适应时间间隔位置编码，将不规则就诊序列整合到因果Transformer解码器中的时间融合块；(iii) 一个疾病本体图适配器，将ICD-10编码注入视觉和文本通道，并借助图注意力机制推断共病模式。

Result: 在MIMIC-IV纵向队列数据上，VL-RiskFormer实现了平均0.90的AUROC，预期校准误差为2.7%。

Conclusion: VL-RiskFormer是一个有效且性能优异的多模态AI框架，能够利用多种异构临床数据对个体健康风险进行主动预测，并展示了良好的校准性能。

Abstract: With the rising global burden of chronic diseases and the multimodal and
heterogeneous clinical data (medical imaging, free-text recordings, wearable
sensor streams, etc.), there is an urgent need for a unified multimodal AI
framework that can proactively predict individual health risks. We propose
VL-RiskFormer, a hierarchical stacked visual-language multimodal Transformer
with a large language model (LLM) inference head embedded in its top layer. The
system builds on the dual-stream architecture of existing visual-linguistic
models (e.g., PaLM-E, LLaVA) with four key innovations: (i) pre-training with
cross-modal comparison and fine-grained alignment of radiological images,
fundus maps, and wearable device photos with corresponding clinical narratives
using momentum update encoders and debiased InfoNCE losses; (ii) a time fusion
block that integrates irregular visit sequences into the causal Transformer
decoder through adaptive time interval position coding; (iii) a disease
ontology map adapter that injects ICD-10 codes into visual and textual channels
in layers and infers comorbid patterns with the help of a graph attention
mechanism. On the MIMIC-IV longitudinal cohort, VL-RiskFormer achieved an
average AUROC of 0.90 with an expected calibration error of 2.7 percent.

</details>


### [14] [From "What to Eat?" to Perfect Recipe: ChefMind's Chain-of-Exploration for Ambiguous User Intent in Recipe Recommendation](https://arxiv.org/abs/2509.18226)
*Yu Fu,Linyue Cai,Ruoyu Wu,Yong Zhao*

Main category: cs.AI

TL;DR: ChefMind是一种结合CoE、KG、RAG和LLM的混合架构，旨在解决个性化食谱推荐中模糊用户意图、语义准确性和细节覆盖不足的问题，并在各项指标上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 个性化食谱推荐面临处理模糊用户意图、确保语义准确性以及提供足够细节覆盖的挑战。

Method: 本文提出了ChefMind，一个混合架构，结合了探索链（CoE）用于细化模糊查询，知识图谱（KG）提供语义推理和可解释性，检索增强生成（RAG）补充上下文烹饪细节，以及大型语言模型（LLM）整合输出。该方法在下厨房数据集和手动标注查询上进行了评估，并与仅LLM、仅KG和仅RAG的基线模型进行了比较。

Result: ChefMind在准确性、相关性、完整性和清晰度方面表现优异，平均得分8.7，而消融模型为6.4-6.7。此外，它将未处理的查询减少到1.6%，显示出处理模糊需求的鲁棒性。

Conclusion: ChefMind能够有效处理模糊用户需求，提供高质量的个性化食谱推荐，并在多项性能指标上超越现有基线模型。

Abstract: Personalized recipe recommendation faces challenges in handling fuzzy user
intent, ensuring semantic accuracy, and providing sufficient detail coverage.
We propose ChefMind, a hybrid architecture combining Chain of Exploration
(CoE), Knowledge Graph (KG), Retrieval-Augmented Generation (RAG), and a Large
Language Model (LLM). CoE refines ambiguous queries into structured conditions,
KG offers semantic reasoning and interpretability, RAG supplements contextual
culinary details, and LLM integrates outputs into coherent recommendations. We
evaluate ChefMind on the Xiachufang dataset and manually annotated queries,
comparing it with LLM-only, KG-only, and RAG-only baselines. Results show that
ChefMind achieves superior performance in accuracy, relevance, completeness,
and clarity, with an average score of 8.7 versus 6.4-6.7 for ablation models.
Moreover, it reduces unprocessed queries to 1.6%, demonstrating robustness in
handling fuzzy demands.

</details>


### [15] [An N-Plus-1 GPT Agency for Critical Solution of Mechanical Engineering Analysis Problems](https://arxiv.org/abs/2509.18229)
*Anthony Patera,Rohan Abeyaratne*

Main category: cs.AI

TL;DR: 本研究提出了一种“N-加-1”GPT代理机构，通过聚合多个GPT实例的解决方案来提高生成式AI在机械工程分析问题上的可靠性，以克服单个GPT实例的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI（尤其是GPT）在解决机械工程分析问题时，有时能给出卓越的解决方案，但有时也会出错（例如，成功率仅为85%）。这种不可靠性使得“开箱即用”的GPT不适合在教育或工程实践中部署。

Method: 引入了一个“N-加-1”GPT代理机构：首先启动N个“Agent Solve”实例以获得N个独立的解决方案；然后调用“Agent Compare”来总结和比较这N个解决方案，并提供一个推荐解决方案。该方法依据孔多塞陪审团定理，认为对于单次求解成功概率大于1/2的问题（且N足够大），多数（Agent Compare）提出的解决方案将以高概率是正确的。此外，Agent Compare还能整合次要解决方案的方面，特别是当它们代表不同的问题解释、数学模型或数学求解程序时。

Result: 通过“N-加-1”代理机构，对于单次求解成功概率大于1/2的问题，主要推荐的解决方案将以高概率是正确的。与商业多代理模型Grok Heavy相比，本机构在设计和性能上相似，但在透明度和教学价值方面有重要区别和侧重。

Conclusion: 所提出的“N-加-1”GPT代理机构能够显著提高GPT在机械工程分析问题上的可靠性，使其更适合在教育和工程实践中部署，并强调了透明度和教学价值。

Abstract: Generative AI, and specifically GPT, can produce a remarkable solution to a
mechanical engineering analysis problem - but also, on occasion, a flawed
solution. For example, an elementary mechanics problem is solved flawlessly in
one GPT instance and incorrectly in a subsequent GPT instance, with a success
probability of only 85%. This unreliability renders "out-of-the-box" GPT
unsuitable for deployment in education or engineering practice. We introduce an
"N-Plus-1" GPT Agency for Initial (Low-Cost) Analysis of mechanical engineering
Problem Statements. Agency first launches N instantiations of Agent Solve to
yield N independent Proposed Problem Solution Realizations; Agency then invokes
Agent Compare to summarize and compare the N Proposed Problem Solution
Realizations and to provide a Recommended Problem Solution. We argue from
Condorcet's Jury Theorem that, for a Problem Statement characterized by
per-Solve success probability greater than 1/2 (and N sufficiently large), the
Predominant (Agent Compare) Proposed Problem Solution will, with high
probability, correspond to a Correct Proposed Problem Solution. Furthermore,
Agent Compare can also incorporate aspects of Secondary (Agent Compare)
Proposed Problem Solutions, in particular when the latter represent alternative
Problem Statement interpretations - different Mathematical Models - or
alternative Mathematical Solution Procedures. Comparisons to Grok Heavy, a
commercial multi-agent model, show similarities in design and performance, but
also important differences in emphasis: our Agency focuses on transparency and
pedagogical value.

</details>


### [16] [Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces](https://arxiv.org/abs/2509.18230)
*Zihan Dong,Xinyu Fan,Zixiang Tang,Yunqing Li*

Main category: cs.AI

TL;DR: 本文提出了一种轻量级分层强化学习框架ComputerAgent，用于控制桌面应用程序。它通过分层策略、三重模态状态编码、元动作和紧凑模型设计，在保持高成功率的同时，大幅降低了模型规模和推理延迟，为桌面自动化提供了一个可扩展的替代方案。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大型语言模型（MLLMs）在控制桌面应用程序时面临高推理延迟、长序列稀疏奖励任务的样本效率低下以及难以在设备上部署等问题。

Method: ComputerAgent采用以下方法：1) 将操作系统控制建模为两级选项过程（管理器和子策略）的分层强化学习框架。2) 使用三重模态状态编码器（屏幕截图、任务ID、数字状态）来处理视觉和上下文多样性。3) 整合带有提前停止机制的元动作以减少无效交互。4) 采用紧凑的视觉骨干网络和小型策略网络（15M参数）实现设备上推理。

Result: 在135个真实桌面任务的测试中，ComputerAgent在简单任务（<8步）上达到92.1%的成功率，在困难任务（>=8步）上达到58.8%的成功率。在简单场景下，其性能与200B参数的MLLM基线相当或超越，同时将模型大小减少了四个数量级以上，并将推理时间减半。

Conclusion: 这些结果表明，分层强化学习为计算机控制中的整体式MLLM自动化提供了一个实用、可扩展的替代方案。

Abstract: Controlling desktop applications via software remains a fundamental yet
under-served problem. Existing multi-modal large language models (MLLMs) ingest
screenshots and task instructions to generate keystrokes and mouse events, but
they suffer from prohibitive inference latency, poor sample efficiency on
long-horizon sparse-reward tasks, and infeasible on-device deployment. We
introduce a lightweight hierarchical reinforcement learning framework,
ComputerAgent, that formulates OS control as a two-level option process
(manager and subpolicy), employs a triple-modal state encoder (screenshot, task
ID, numeric state) to handle visual and contextual diversity, integrates
meta-actions with an early-stop mechanism to reduce wasted interactions, and
uses a compact vision backbone plus small policy networks for on-device
inference (15M parameters). On a suite of 135 real-world desktop tasks,
ComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on
hard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on
simple scenarios while reducing model size by over four orders of magnitude and
halving inference time. These results demonstrate that hierarchical RL offers a
practical, scalable alternative to monolithic MLLM-based automation for
computer control.

</details>


### [17] [The Illusion of Readiness: Stress Testing Large Frontier Models on Multimodal Medical Benchmarks](https://arxiv.org/abs/2509.18234)
*Yu Gu,Jingjing Fu,Xiaodong Liu,Jeya Maria Jose Valanarasu,Noel Codella,Reuben Tan,Qianchu Liu,Ying Jin,Sheng Zhang,Jinyu Wang,Rui Wang,Lei Song,Guanghui Qin,Naoto Usuyama,Cliff Wong,Cheng Hao,Hohin Lee,Praneeth Sanapathi,Sarah Hilado,Bian Jiang,Javier Alvarez-Valle,Mu Wei,Jianfeng Gao,Eric Horvitz,Matt Lungren,Hoifung Poon,Paul Vozila*

Main category: cs.AI

TL;DR: 领先的医疗AI模型在基准测试中表现出色，但压力测试揭示其脆弱性、捷径学习和缺乏真实医学理解，表明现有基准分数未能反映实际应用能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大型模型在医疗基准测试中取得高分，但作者怀疑这些分数是否真正反映了医学理解和实际应用能力，认为现有基准可能奖励了“应试技巧”而非真正的医学知识。

Method: 对六个领先模型在六个常用医疗基准上进行压力测试，并采用临床医生指导的评估标准来分析基准测量的内容。

Result: 领先模型即使在关键输入缺失时也能猜对，在微小提示词变化下答案会翻转，并能编造有说服力但有缺陷的推理。高基准分数掩盖了模型的脆弱性和捷径学习。不同的基准测试衡量内容差异很大，但常被互换使用，掩盖了模型的失效模式。

Conclusion: 医疗基准测试分数不能直接反映AI在现实世界的就绪程度。为了让AI在医疗领域赢得信任，需要超越排行榜的胜利，并要求系统具备鲁棒性、可靠的推理能力以及与真实医疗需求的对齐。

Abstract: Large frontier models like GPT-5 now achieve top scores on medical
benchmarks. But our stress tests tell a different story. Leading systems often
guess correctly even when key inputs like images are removed, flip answers
under trivial prompt changes, and fabricate convincing yet flawed reasoning.
These aren't glitches; they expose how today's benchmarks reward test-taking
tricks over medical understanding. We evaluate six flagship models across six
widely used benchmarks and find that high leaderboard scores hide brittleness
and shortcut learning. Through clinician-guided rubric evaluation, we show that
benchmarks vary widely in what they truly measure yet are treated
interchangeably, masking failure modes. We caution that medical benchmark
scores do not directly reflect real-world readiness. If we want AI to earn
trust in healthcare, we must demand more than leaderboard wins and must hold
systems accountable for robustness, sound reasoning, and alignment with real
medical demands.

</details>


### [18] [Evaluating the Safety and Skill Reasoning of Large Reasoning Models Under Compute Constraints](https://arxiv.org/abs/2509.18382)
*Adarsha Balaji,Le Chen,Rajeev Thakur,Franck Cappello,Sandeep Madireddy*

Main category: cs.AI

TL;DR: 本文研究在计算资源受限下，通过限制推理长度和模型量化两种策略，优化语言模型链式思考(CoT)推理的计算效率，并分析其对模型安全性能的影响。


<details>
  <summary>Details</summary>
Motivation: 链式思考(CoT)虽然能提升推理语言模型的性能，但会导致显著的计算成本增加，因此需要探索降低计算需求的方法。

Method: 研究了两种计算约束策略：1) 推理长度约束；2) 模型量化。具体实施方法包括：1) 使用基于长度控制策略优化(LCPO)的强化学习方法微调推理模型，以满足用户定义的CoT推理长度；2) 应用量化在用户定义的计算约束内最大化CoT序列的生成。此外，还研究了计算效率与模型安全之间的权衡。

Result: 抽象中未明确给出具体结果，但指出研究了计算约束对推理模型安全性能的影响，并探索了计算效率与模型安全之间的权衡。

Conclusion: 抽象中未提供明确的结论，而是阐述了研究的范围和目标，即在计算受限下提升CoT模型的效率并评估其对安全性的影响。

Abstract: Test-time compute scaling has demonstrated the ability to improve the
performance of reasoning language models by generating longer chain-of-thought
(CoT) sequences. However, this increase in performance comes with a significant
increase in computational cost. In this work, we investigate two compute
constraint strategies: (1) reasoning length constraint and (2) model
quantization, as methods to reduce the compute demand of reasoning models and
study their impact on their safety performance. Specifically, we explore two
approaches to apply compute constraints to reasoning models: (1) fine-tuning
reasoning models using a length controlled policy optimization (LCPO) based
reinforcement learning method to satisfy a user-defined CoT reasoning length,
and (2) applying quantization to maximize the generation of CoT sequences
within a user-defined compute constraint. Furthermore, we study the trade-off
between the computational efficiency and the safety of the model.

</details>


### [19] [Gödel Test: Can Large Language Models Solve Easy Conjectures?](https://arxiv.org/abs/2509.18383)
*Moran Feldman,Amin Karbasi*

Main category: cs.AI

TL;DR: 本研究提出了“哥德尔测试”，以评估大型语言模型（如GPT-5）解决组合优化领域中新颖、简单数学猜想的能力，结果显示模型在常规推理方面取得进展，偶有独创性，但在需要跨论文综合时存在明显局限。


<details>
  <summary>Details</summary>
Motivation: 现有前沿AI模型在高中和本科数学竞赛中表现出色，但其是否能解决高级数学领域中全新、简单的猜想尚不明确。这促使研究者提出“哥德尔测试”来填补这一评估空白。

Method: 研究者提出了“哥德尔测试”，即评估模型能否为非常简单、先前未解决的猜想提供正确证明。他们将GPT-5应用于组合优化领域的五个猜想，为每个问题提供了一两篇来源论文，但未告知模型自己的猜想，并详细评估了模型的推理过程。

Result: 在三个较简单的问题上，GPT-5给出了几乎正确的解决方案。对于问题2，模型甚至推导出了一个不同的近似保证，该保证在验证后驳斥了研究者的猜想并提供了一个有效解。模型在需要结合两篇论文结果的问题4上失败。在更难且无已验证猜想的问题5上，GPT-5提出了与研究者相同的算法，但在分析中失败。

Conclusion: 尽管样本量小，结果表明GPT-5在常规推理方面取得了显著进展，偶尔展现出独创性，但在需要跨论文综合时存在明显局限性。GPT-5可能代表着前沿模型最终通过“哥德尔测试”的早期一步。

Abstract: Recent announcements from frontier AI model labs have highlighted strong
results on high-school and undergraduate math competitions. Yet it remains
unclear whether large language models can solve new, simple conjectures in more
advanced areas of mathematics. We propose the G\"odel Test: evaluating whether
a model can produce correct proofs for very simple, previously unsolved
conjectures. To this end, we study the performance of GPT-5 on five conjectures
in combinatorial optimization. For each problem, we provided one or two source
papers from which the conjecture arose, withheld our own conjecture, and then
assessed the model's reasoning in detail. On the three easier problems, GPT-5
produced nearly correct solutions; for Problem 2 it even derived a different
approximation guarantee that, upon checking, refuted our conjecture while
providing a valid solution. The model failed on Problem 4, which required
combining results from two papers. On Problem 5, a harder case without a
validated conjecture, GPT-5 proposed the same algorithm we had in mind but
failed in the analysis, suggesting the proof is more challenging than expected.
Although our sample is small, the results point to meaningful progress on
routine reasoning, occasional flashes of originality, and clear limitations
when cross-paper synthesis is required. GPT-5 may represent an early step
toward frontier models eventually passing the G\"odel Test.

</details>


### [20] [ATLAS: Benchmarking and Adapting LLMs for Global Trade via Harmonized Tariff Code Classification](https://arxiv.org/abs/2509.18400)
*Pritish Yuvraj,Siva Devarakonda*

Main category: cs.AI

TL;DR: 本文介绍了首个协调关税制度（HTS）编码分类基准，并提出了名为Atlas的微调模型（基于LLaMA-3.3-70B）。该模型在10位和6位分类上均显著优于现有领先LLM，且成本效益更高，同时解决了贸易中的关键瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: HTS产品分类的准确性是全球贸易中的关键瓶颈。错误分类可能导致货物完全停运，甚至邮政运营商暂停对美递送。然而，机器学习社区对这一问题关注甚少。

Method: 研究从美国海关裁决在线搜索系统（CROSS）中构建了首个HTS编码分类基准。评估了领先的大型语言模型（LLM），并开发并微调了Atlas模型（基于LLaMA-3.3-70B）。

Result: Atlas模型在10位分类中实现了40%的完全正确率，在6位分类中实现了57.5%的正确率，分别比GPT-5-Thinking提高了15个百分点，比Gemini-2.5-Pro-Thinking提高了27.5个百分点。此外，Atlas的成本比GPT-5-Thinking便宜约5倍，比Gemini-2.5-Pro-Thinking便宜约8倍，并支持自托管以保障数据隐私。

Conclusion: Atlas模型为HTS分类设定了一个强大的基线，但该基准任务仍然极具挑战性（10位准确率仅为40%）。通过发布数据集和模型，本文旨在将HTS分类定位为一个新的社区基准任务，并鼓励未来在检索、推理和对齐方面的研究。

Abstract: Accurate classification of products under the Harmonized Tariff Schedule
(HTS) is a critical bottleneck in global trade, yet it has received little
attention from the machine learning community. Misclassification can halt
shipments entirely, with major postal operators suspending deliveries to the
U.S. due to incomplete customs documentation. We introduce the first benchmark
for HTS code classification, derived from the U.S. Customs Rulings Online
Search System (CROSS). Evaluating leading LLMs, we find that our fine-tuned
Atlas model (LLaMA-3.3-70B) achieves 40 percent fully correct 10-digit
classifications and 57.5 percent correct 6-digit classifications, improvements
of 15 points over GPT-5-Thinking and 27.5 points over Gemini-2.5-Pro-Thinking.
Beyond accuracy, Atlas is roughly five times cheaper than GPT-5-Thinking and
eight times cheaper than Gemini-2.5-Pro-Thinking, and can be self-hosted to
guarantee data privacy in high-stakes trade and compliance workflows. While
Atlas sets a strong baseline, the benchmark remains highly challenging, with
only 40 percent 10-digit accuracy. By releasing both dataset and model, we aim
to position HTS classification as a new community benchmark task and invite
future work in retrieval, reasoning, and alignment.

</details>


### [21] [Instruction-Following Evaluation in Function Calling for Large Language Models](https://arxiv.org/abs/2509.18420)
*Nikolai Skripko*

Main category: cs.AI

TL;DR: IFEval-FC是一个评估大语言模型函数调用中精确指令遵循（特别是格式要求）的新基准，发现现有最先进模型在此方面表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有函数调用基准（如BFCL、tau^2-Bench、ACEBench）主要评估参数正确性，但未能测试模型对嵌入在参数描述中的格式指令（如双引号、ISO日期格式）的遵循情况，这在实际AI代理系统中是一个重要限制。

Method: 本文引入了IFEval-FC基准，灵感来源于IFEval。它将可验证的格式直接编码在JSON schema描述中（例如，指定值不能包含标点符号）。该基准包含750个测试用例，每个用例包括一个函数，其中一个输入参数嵌入了格式要求，以及一个相应的用户查询。评估过程完全是算法化的，确保客观性、可复现性和可扩展性。

Result: 评估结果表明，即使是包括GPT-5和Claude 4.1 Opus在内的最先进的专有模型，也经常未能遵循基本的格式规则。

Conclusion: 模型在函数调用中未能遵循基本格式规则，这突出了当前大语言模型在构建真实世界代理系统时的一个实际限制。

Abstract: Function calling is a core capability of large language models, essential for
AI agents. Existing benchmarks such as the Berkeley Function Calling
Leaderboard (BFCL), tau^2-Bench (arXiv:2506.07982), and ACEBench
(arXiv:2501.12851) evaluate argument correctness but do not test adherence to
format instructions embedded in parameter descriptions, such as enclosing
values in double quotes or using ISO date formats.
  We introduce IFEval-FC, a benchmark inspired by IFEval (arXiv:2311.07911)
that assesses precise instruction following in function calling. IFEval-FC
encodes verifiable formats directly within JSON schema descriptions, for
example specifying that a value must not contain punctuation. It includes 750
test cases, each consisting of a function with an embedded format for one of
its input parameters and a corresponding user query. Evaluation is fully
algorithmic, ensuring objectivity, reproducibility, and scalability.
  Our results show that even state-of-the-art proprietary models, including
GPT-5 and Claude 4.1 Opus, frequently fail to follow basic formatting rules,
highlighting a practical limitation for real-world agent systems. The complete
codebase and data are publicly available at
https://github.com/Skripkon/IFEval-FC.

</details>


### [22] [Memory-QA: Answering Recall Questions Based on Multimodal Memories](https://arxiv.org/abs/2509.18436)
*Hongda Jiang,Xinyuan Zhang,Siddhant Garg,Rishab Arora,Shiun-Zu Kuo,Jiayang Xu,Christopher Brossman,Yue Liu,Aaron Colak,Ahmed Aly,Anuj Kumar,Xin Luna Dong*

Main category: cs.AI

TL;DR: 本文提出了Memory-QA任务，旨在从多模态记忆中回答回忆性问题。为解决该任务的挑战，作者提出了Pensieve管道，并在新创建的基准测试中，相较于现有最佳方案，问答准确率提升高达14%。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能有效解决从存储的多模态记忆中回答回忆性问题。此任务面临独特挑战，包括创建任务导向记忆、有效利用记忆中的时空信息，以及整合多个记忆来回答回忆性问题。

Method: 提出了一个名为Pensieve的综合管道，该管道集成了记忆特异性增强、时间-位置感知的多信号检索，以及多记忆问答微调。同时，创建了一个多模态基准来展示任务中的各种实际挑战。

Result: Pensieve在所创建的多模态基准测试中，相比于现有最先进的解决方案，问答准确率提升高达14%。

Conclusion: Pensieve管道能有效应对Memory-QA任务中的独特挑战，并在从先前存储的多模态记忆中回答回忆性问题方面展现出优越的性能。

Abstract: We introduce Memory-QA, a novel real-world task that involves answering
recall questions about visual content from previously stored multimodal
memories. This task poses unique challenges, including the creation of
task-oriented memories, the effective utilization of temporal and location
information within memories, and the ability to draw upon multiple memories to
answer a recall question. To address these challenges, we propose a
comprehensive pipeline, Pensieve, integrating memory-specific augmentation,
time- and location-aware multi-signal retrieval, and multi-memory QA
fine-tuning. We created a multimodal benchmark to illustrate various real
challenges in this task, and show the superior performance of Pensieve over
state-of-the-art solutions (up to 14% on QA accuracy).

</details>


### [23] [FERA: Foil Fencing Referee Assistant Using Pose-Based Multi-Label Move Recognition and Rule Reasoning](https://arxiv.org/abs/2509.18527)
*Ziwen Chen,Zhong Wang*

Main category: cs.AI

TL;DR: FERA是一个原型AI裁判系统，用于花剑击剑，它结合了基于姿态的多标签动作识别和基于规则的推理，以解决裁判主观性、错误和可用性等挑战。


<details>
  <summary>Details</summary>
Motivation: 击剑运动（以及其他许多运动）在裁判方面面临挑战，包括主观判断、人为错误、偏见以及在训练环境中裁判可用性有限的问题。

Method: FERA从视频中提取2D关节位置并进行归一化，计算101维运动学特征集，然后使用Transformer进行多标签动作和剑位分类。为了确定优先权和得分，FERA应用了一个经过蒸馏的语言模型，其中编码了优先权规则，为每次交锋生成判决和解释。

Result: 在有限的手动标记数据下，通过5折交叉验证，FERA取得了0.549的平均宏观F1分数，优于包括时间卷积网络（TCN）、BiLSTM和普通Transformer在内的多个基线模型。系统能够生成判决和解释。

Conclusion: 虽然尚未准备好部署，但这些结果展示了在花剑击剑中实现自动化裁判辅助的 promising 途径，并为AI应用（如击剑领域的教练）提供了新机会。

Abstract: The sport of fencing, like many other sports, faces challenges in refereeing:
subjective calls, human errors, bias, and limited availability in practice
environments. We present FERA (Fencing Referee Assistant), a prototype AI
referee for foil fencing which integrates pose-based multi-label action
recognition and rule-based reasoning. FERA extracts 2D joint positions from
video, normalizes them, computes a 101-dimensional kinematic feature set, and
applies a Transformer for multi-label move and blade classification. To
determine priority and scoring, FERA applies a distilled language model with
encoded right-of-way rules, producing both a decision and an explanation for
each exchange. With limited hand-labeled data, a 5-fold cross-validation
achieves an average macro-F1 score of 0.549, outperforming multiple baselines,
including a Temporal Convolutional Network (TCN), BiLSTM, and a vanilla
Transformer. While not ready for deployment, these results demonstrate a
promising path towards automated referee assistance in foil fencing and new
opportunities for AI applications, such as coaching in the field of fencing.

</details>


### [24] [LLMZ+: Contextual Prompt Whitelist Principles for Agentic LLMs](https://arxiv.org/abs/2509.18557)
*Tom Pawelek,Raj Patel,Charlotte Crowell,Noorbakhsh Amiri,Sudip Mittal,Shahram Rahimi,Andy Perkins*

Main category: cs.AI

TL;DR: 本文提出LLMZ+，一种基于提示词白名单的新型安全方法，用于保护具有代理能力的LLM免受越狱攻击，确保只有安全且符合上下文的消息能与LLM交互，并实现了零误报和零漏报。


<details>
  <summary>Details</summary>
Motivation: 与传统模型相比，代理式AI因其对数据源和API工具的特权访问以及非确定性行为，成为极具价值的攻击目标，带来重大的运营和信息安全风险。现有防御机制主要依赖恶意意图检测，但不足以有效应对提示注入等越狱攻击。

Method: LLMZ+采用提示词白名单机制，而非传统的基于检测的方法。它只允许与上下文相关且安全的消息与代理式LLM交互，从而确保外部用户与LLM之间的所有交流都符合预定义的使用场景和操作边界。

Result: LLMZ+对最常见的越狱提示词表现出强大的抵御能力。同时，它不干扰合法的业务通信，并允许授权流量在用户和代理式LLM之间无缝流动。在实验设置中，误报率和漏报率均可降至0。

Conclusion: LLMZ+通过实施提示词白名单，简化了安全框架，增强了其长期弹性，并减少了维护LLM信息安全所需的资源。该方法有效提升了代理式LLM的安全性，同时不影响正常业务操作。

Abstract: Compared to traditional models, agentic AI represents a highly valuable
target for potential attackers as they possess privileged access to data
sources and API tools, which are traditionally not incorporated into classical
agents. Unlike a typical software application residing in a Demilitarized Zone
(DMZ), agentic LLMs consciously rely on nondeterministic behavior of the AI
(only defining a final goal, leaving the path selection to LLM). This
characteristic introduces substantial security risk to both operational
security and information security. Most common existing defense mechanism rely
on detection of malicious intent and preventing it from reaching the LLM agent,
thus protecting against jailbreak attacks such as prompt injection. In this
paper, we present an alternative approach, LLMZ+, which moves beyond
traditional detection-based approaches by implementing prompt whitelisting.
Through this method, only contextually appropriate and safe messages are
permitted to interact with the agentic LLM. By leveraging the specificity of
context, LLMZ+ guarantees that all exchanges between external users and the LLM
conform to predefined use cases and operational boundaries. Our approach
streamlines the security framework, enhances its long-term resilience, and
reduces the resources required for sustaining LLM information security. Our
empirical evaluation demonstrates that LLMZ+ provides strong resilience against
the most common jailbreak prompts. At the same time, legitimate business
communications are not disrupted, and authorized traffic flows seamlessly
between users and the agentic LLM. We measure the effectiveness of approach
using false positive and false negative rates, both of which can be reduced to
0 in our experimental setting.

</details>


### [25] [Solving Math Word Problems Using Estimation Verification and Equation Generation](https://arxiv.org/abs/2509.18565)
*Mitchell Piehl,Dillon Wilson,Ananya Kalita,Jugal Kalita*

Main category: cs.AI

TL;DR: 本研究提出了一种新颖的方法，结合大型语言模型（LLM）生成方程、外部符号求解器计算答案，并通过LLM估计和迭代纠正来验证答案，从而显著提升了LLM在数学应用题（MWP）上的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在解决问题和问答方面表现出色，但在数学应用题（MWP）上仍面临挑战，因为解决MWP需要一系列推理和数学能力。尽管最近的努力通过改进提示词有所帮助，但LLM在此方面仍显不足。

Method: 该方法首先提示LLM根据问题分解创建方程，然后使用外部符号方程求解器来得出答案。为了确保答案的准确性，LLM被指示进行第二次求解，但目标是估计正确答案而非精确求解。估计结果随后与生成的答案进行比较以进行验证。如果验证失败，则采用迭代纠正过程以确保最终找到正确答案。

Result: 该方法在先前研究使用的数值和代数MWP数据集上取得了新的最先进结果，平均比之前最佳结果提高了近2%。此外，它在三角函数MWP上取得了令人满意的结果，这是以前未曾尝试的任务。本研究还引入了两个新数据集：SVAMPClean和Trig300，以进一步推动LLM推理能力的测试。

Conclusion: 本研究提出的方法通过结合外部求解器和独特的两阶段验证与纠正过程，显著提高了LLM在数学应用题上的性能，并在数值、代数和三角函数MWP方面取得了最先进或令人满意的结果，同时引入了新的数据集以促进未来的研究。

Abstract: Large Language Models (LLMs) excel at various tasks, including
problem-solving and question-answering. However, LLMs often find Math Word
Problems (MWPs) challenging because solving them requires a range of reasoning
and mathematical abilities with which LLMs seem to struggle. Recent efforts
have helped LLMs solve more complex MWPs with improved prompts. This study
proposes a novel method that initially prompts an LLM to create equations from
a decomposition of the question, followed by using an external symbolic
equation solver to produce an answer. To ensure the accuracy of the obtained
answer, inspired by an established recommendation of math teachers, the LLM is
instructed to solve the MWP a second time, but this time with the objective of
estimating the correct answer instead of solving it exactly. The estimation is
then compared to the generated answer to verify. If verification fails, an
iterative rectification process is employed to ensure the correct answer is
eventually found. This approach achieves new state-of-the-art results on
datasets used by prior published research on numeric and algebraic MWPs,
improving the previous best results by nearly two percent on average. In
addition, the approach obtains satisfactory results on trigonometric MWPs, a
task not previously attempted to the authors' best knowledge. This study also
introduces two new datasets, SVAMPClean and Trig300, to further advance the
testing of LLMs' reasoning abilities.

</details>


### [26] [Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents](https://arxiv.org/abs/2509.18633)
*Yara Mohajerani*

Main category: cs.AI

TL;DR: 该论文提出了一种新颖的地理空间基于代理的模型，整合了气候灾害数据和经济代理的演化学习机制，以评估气候风险。研究表明，演化适应能使企业在气候压力后恢复生产，但供应链中断仍导致系统性风险和商品价格上涨。


<details>
  <summary>Details</summary>
Motivation: 气候风险评估需要模拟空间异质性灾害与适应性经济系统之间复杂的相互作用。

Method: 研究采用了一种新颖的地理空间基于代理的模型，将基于Mesa的空间建模与CLIMADA气候影响评估相结合。该模型引入了适应性学习行为，使企业通过基于适应度的选择和突变来演化预算分配、定价、工资和风险适应策略。模型使用RCP8.5情景下的河流洪水预测进行演示，模拟至2100年。

Result: 研究结果显示，演化适应使企业在经历数十年的气候压力中断后，能够与基线（无灾害）生产水平趋同。同时，即使未直接暴露于洪水风险的代理，也通过供应链中断面临影响，揭示了系统性风险。在RCP8.5情景下，到本世纪末，商品平均价格比基线高出5.6%。

Conclusion: 该开源框架为金融机构和公司提供了量化直接和级联气候风险的工具，并可用于评估具有成本效益的适应策略。

Abstract: Climate risk assessment requires modelling complex interactions between
spatially heterogeneous hazards and adaptive economic systems. We present a
novel geospatial agent-based model that integrates climate hazard data with
evolutionary learning for economic agents. Our framework combines Mesa-based
spatial modelling with CLIMADA climate impact assessment, introducing adaptive
learning behaviours that allow firms to evolve strategies for budget
allocation, pricing, wages, and risk adaptation through fitness-based selection
and mutation. We demonstrate the framework using riverine flood projections
under RCP8.5 until 2100, showing that evolutionary adaptation enables firms to
converge with baseline (no hazard) production levels after decades of
disruption due to climate stress. Our results reveal systemic risks where even
agents that are not directly exposed to floods face impacts through supply
chain disruptions, with the end-of-century average price of goods 5.6% higher
under RCP8.5 compared to the baseline. This open-source framework provides
financial institutions and companies with tools to quantify both direct and
cascading climate risks while evaluating cost-effective adaptation strategies.

</details>


### [27] [TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2509.18667)
*Qiao Xiao,Hong Ting Tsang,Jiaxin Bai*

Main category: cs.AI

TL;DR: TERAG是一个成本效益高的图基RAG框架，它在显著降低LLM令牌使用量的同时，保持了与现有方法相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的图基RAG系统在图构建过程中LLM令牌使用成本高昂，阻碍了其大规模应用。

Method: 提出了TERAG框架，该框架旨在以显著更低的成本构建信息图。受HippoRAG启发，TERAG在检索阶段融入了个性化PageRank（PPR）。

Result: TERAG在消耗仅3%-11%输出令牌的情况下，达到了广泛使用的图基RAG方法至少80%的准确率。

Conclusion: TERAG提供了一种简单而有效的方法，以显著降低的成本构建信息图，同时保持了高准确性，解决了现有图基RAG系统的成本问题。

Abstract: Graph-based Retrieval-augmented generation (RAG) has become a widely studied
approach for improving the reasoning, accuracy, and factuality of Large
Language Models. However, many existing graph-based RAG systems overlook the
high cost associated with LLM token usage during graph construction, hindering
large-scale adoption. To address this, we propose TERAG, a simple yet effective
framework designed to build informative graphs at a significantly lower cost.
Inspired by HippoRAG, we incorporate Personalized PageRank (PPR) during the
retrieval phase, and we achieve at least 80% of the accuracy of widely used
graph-based RAG methods while consuming only 3%-11% of the output tokens.

</details>


### [28] [Implementation of airborne ML models with semantics preservation](https://arxiv.org/abs/2509.18681)
*Nicolas Valot,Louis Fabre,Benjamin Lesage,Ammar Mechouche,Claire Pagetti*

Main category: cs.AI

TL;DR: 本文旨在明确机器学习模型与其明确描述（MLMD）之间的区别，并细化语义保存的概念，以确保模型在航空系统中的准确复制和安全合规性。


<details>
  <summary>Details</summary>
Motivation: 机器学习在航空系统中具有潜力，但必须确保其安全运行并符合相关指导（如EASA概念文件和ED-324）。现有方法提出了高层目标，但缺乏对ML模型及其准确复制的详细说明。

Method: 本文首先阐明了机器学习模型与机器学习模型描述（MLMD）之间的区别。其次，它细化了语义保存这一关键概念，以确保模型的准确复制。最后，将这些贡献应用于多个工业用例，以构建和比较不同的目标模型。

Result: 本文明确了机器学习模型与其明确描述（MLMD）之间的差异，并完善了语义保存的核心概念，以确保模型的精确复制。这些概念被应用于多个工业用例，用于构建和比较不同的目标模型。

Conclusion: 通过区分ML模型和MLMD，并细化语义保存的概念，本文为确保机器学习模型在航空系统中的准确复制和安全合规性提供了关键的基础，这对于满足航空安全标准至关重要。

Abstract: Machine Learning (ML) may offer new capabilities in airborne systems.
However, as any piece of airborne systems, ML-based systems will be required to
guarantee their safe operation. Thus, their development will have to be
demonstrated to be compliant with the adequate guidance. So far, the European
Union Aviation Safety Agency (EASA) has published a concept paper and an
EUROCAE/SAE group is preparing ED-324. Both approaches delineate high-level
objectives to confirm the ML model achieves its intended function and maintains
training performance in the target environment. The paper aims to clarify the
difference between an ML model and its corresponding unambiguous description,
referred to as the Machine Learning Model Description (MLMD). It then refines
the essential notion of semantics preservation to ensure the accurate
replication of the model. We apply our contributions to several industrial use
cases to build and compare several target models.

</details>


### [29] [Advances in Large Language Models for Medicine](https://arxiv.org/abs/2509.18690)
*Zhiyu Kan,Wensheng Gan,Zhenlian Qi,Philip S. Yu*

Main category: cs.AI

TL;DR: 本文系统回顾了大型语言模型（LLMs）在医疗领域的最新研究进展，深入分析其训练、应用、优缺点，并提出分类方法、解决方案及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 鉴于人工智能技术，特别是大型语言模型在医疗领域日益增长的影响力，本文旨在强调开发医疗LLMs的必要性，加深对其当前发展状况的理解，并为后续研究提供明确指导。

Method: 本文采用系统回顾的方法，对医疗领域中LLMs的最新研究进展进行深入分析。具体包括：分析大型医疗模型的训练技术、在医疗环境中的适应性、相关应用、优势与局限性；创新性地根据训练方法将医疗LLMs分为三类，并将评估方法分为两类；最后，针对现有挑战提出解决方案并规划未来研究方向。

Result: 研究结果包括对医疗LLMs训练技术、医疗场景适应性、应用、优势和局限性的深入分析；创新性地将医疗LLMs分为三种类型（基于训练方法）和两种评估方法；并基于已识别的问题提出了现有挑战的解决方案和未来的研究方向。

Conclusion: 通过系统回顾，本文强调了开发医疗LLMs的必要性，提供了对其当前发展状态的深刻理解，并为该领域的后续研究指明了清晰的方向。

Abstract: Artificial intelligence (AI) technology has advanced rapidly in recent years,
with large language models (LLMs) emerging as a significant breakthrough. LLMs
are increasingly making an impact across various industries, with the medical
field standing out as the most prominent application area. This paper
systematically reviews the up-to-date research progress of LLMs in the medical
field, providing an in-depth analysis of training techniques for large medical
models, their adaptation in healthcare settings, related applications, as well
as their strengths and limitations. Furthermore, it innovatively categorizes
medical LLMs into three distinct types based on their training methodologies
and classifies their evaluation approaches into two categories. Finally, the
study proposes solutions to existing challenges and outlines future research
directions based on identified issues in the field of medical LLMs. By
systematically reviewing previous and advanced research findings, we aim to
highlight the necessity of developing medical LLMs, provide a deeper
understanding of their current state of development, and offer clear guidance
for subsequent research.

</details>


### [30] [Autonomous Data Agents: A New Opportunity for Smart Data](https://arxiv.org/abs/2509.18710)
*Yanjie Fu,Dongjie Wang,Wangyang Ying,Xiangliang Zhang,Huan Liu,Jian Pei*

Main category: cs.AI

TL;DR: 本文提出数据代理（DataAgents），一种利用大型语言模型（LLM）推理和工具调用的自主系统，旨在将复杂数据转化为可操作的知识，实现数据到知识系统的范式转变。


<details>
  <summary>Details</summary>
Motivation: 数据处理、转换和分析过程劳动密集、重复且难以扩展，而数据中包含知识，AI从中学习知识，因此AI与数据的对齐至关重要。然而，数据结构通常不利于AI利用，且如何通过数据操作将更多知识打包到数据中是一个重要问题。

Method: 数据代理（DataAgents）整合了LLM推理、任务分解、行动推理与落地、以及工具调用。它们能自主解释数据任务描述、将任务分解为子任务、推断行动、将行动落地为Python代码或工具调用，并执行操作。与传统工具不同，DataAgents动态规划工作流、调用强大工具并适应大规模多样化数据任务。

Result: 数据代理能够处理数据的收集、集成、预处理、选择、转换、重新加权、增强、重编程、修复和检索等操作。通过这些能力，DataAgents将复杂和非结构化数据转化为连贯且可操作的知识，代表了迈向自主数据到知识系统的范式转变。

Conclusion: 文章呼吁集中精力推进行动工作流优化、建立开放数据集和基准生态系统、保障隐私、平衡效率与可扩展性，并开发可信赖的DataAgent防护措施以防止恶意行为。

Abstract: As data continues to grow in scale and complexity, preparing, transforming,
and analyzing it remains labor-intensive, repetitive, and difficult to scale.
Since data contains knowledge and AI learns knowledge from it, the alignment
between AI and data is essential. However, data is often not structured in ways
that are optimal for AI utilization. Moreover, an important question arises:
how much knowledge can we pack into data through intensive data operations?
Autonomous data agents (DataAgents), which integrate LLM reasoning with task
decomposition, action reasoning and grounding, and tool calling, can
autonomously interpret data task descriptions, decompose tasks into subtasks,
reason over actions, ground actions into python code or tool calling, and
execute operations. Unlike traditional data management and engineering tools,
DataAgents dynamically plan workflows, call powerful tools, and adapt to
diverse data tasks at scale. This report argues that DataAgents represent a
paradigm shift toward autonomous data-to-knowledge systems. DataAgents are
capable of handling collection, integration, preprocessing, selection,
transformation, reweighing, augmentation, reprogramming, repairs, and
retrieval. Through these capabilities, DataAgents transform complex and
unstructured data into coherent and actionable knowledge. We first examine why
the convergence of agentic AI and data-to-knowledge systems has emerged as a
critical trend. We then define the concept of DataAgents and discuss their
architectural design, training strategies, as well as the new skills and
capabilities they enable. Finally, we call for concerted efforts to advance
action workflow optimization, establish open datasets and benchmark ecosystems,
safeguard privacy, balance efficiency with scalability, and develop trustworthy
DataAgent guardrails to prevent malicious actions.

</details>


### [31] [Experience Scaling: Post-Deployment Evolution For Large Language Models](https://arxiv.org/abs/2509.18771)
*Xingkun Yin,Kaibin Huang,Dong In Kim,Hongyang Du*

Main category: cs.AI

TL;DR: 本文提出“经验扩展”框架，通过LLM与环境的自主交互和经验共享，实现部署后持续学习，以克服传统扩展方法（模型大小、数据、算力）的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的进步主要依赖于模型规模、训练数据和计算能力的扩展，但这些方法正因人类生成文本的枯竭而达到饱和，进一步的收益正在减少。

Method: 提出“经验扩展”框架，该框架通过LLM与环境的自主交互和积累经验的协作共享，实现部署后的持续演进。具体包括：捕获原始交互、将其提炼为紧凑可重用的知识，并定期优化存储内容以保持相关性和效率。在模拟真实世界场景中（如泛化到未见但相关的任务、重复查询和过饱和知识库）验证了该框架。

Result: 在所有测试设置中，“经验扩展”框架都提高了准确性，随着时间的推移保持了性能，并在应用于新情境时维持了收益。

Conclusion: 结构化的部署后学习能够将LLM的能力扩展到静态人类生成数据的限制之外，为持续的智能进步提供了一条可扩展的路径。

Abstract: Scaling model size, training data, and compute power have driven advances in
large language models (LLMs), but these approaches are reaching saturation as
human-generated text is exhausted and further gains diminish. We propose
experience scaling, a framework for continuous post-deployment evolution for
LLMs through autonomous interaction with the environment and collaborative
sharing of accumulated experience. The framework captures raw interactions,
distills them into compact, reusable knowledge, and periodically refines stored
content to preserve relevance and efficiency. We validate the framework in
simulated real-world scenarios involving generalization to previously unseen
but related tasks, repetitive queries, and over-saturated knowledge stores.
Across all settings, experience scaling improves accuracy, sustains performance
over time, and maintains gains when applied to novel situations. These results
demonstrate that structured post-deployment learning can extend LLM
capabilities beyond the limits of static human-generated data, offering a
scalable path for continued intelligence progress.

</details>


### [32] [The AGNTCY Agent Directory Service: Architecture and Implementation](https://arxiv.org/abs/2509.18787)
*Luca Muscariello,Vijoy Pandey,Ramiz Polic*

Main category: cs.AI

TL;DR: Agent Directory Service (ADS) 是一个分布式目录服务，用于发现AI智能体的能力、元数据和来源，通过内容寻址存储、分层分类和加密签名实现高效、可验证和多维度的发现。


<details>
  <summary>Details</summary>
Motivation: 动机是解决异构多智能体系统（MAS）中智能体能力、元数据和来源的发现挑战，需要一个能够实现高效、可验证和多维度发现的分布式目录服务。

Method: ADS基于Open Agentic Schema Framework (OASF) 构建，通过Kademlia分布式哈希表（DHT）实现两级映射，将能力索引与内容位置解耦。它利用内容寻址存储、分层分类和加密签名，并重用OCI / ORAS基础设施进行工件分发，集成Sigstore进行来源管理，并支持模式驱动的可扩展性，以适应新兴的智能体模式。

Result: ADS实现了跨异构多智能体系统的高效、可验证和多维度的智能体能力发现。它支持LLM提示智能体、MCP服务器和A2A启用组件等新兴智能体模式，并提供了形式化的架构模型、存储和发现层、安全性和性能属性。

Conclusion: ADS提供了一个全面的解决方案，用于在复杂多智能体环境中发现智能体能力，并通过其分布式架构、安全特性和对新兴智能体模式的支持，在智能体注册和互操作性领域具有重要地位。

Abstract: The Agent Directory Service (ADS) is a distributed directory for the
discovery of AI agent capabilities, metadata, and provenance. It leverages
content-addressed storage, hierarchical taxonomies, and cryptographic signing
to enable efficient, verifiable, and multi-dimensional discovery across
heterogeneous Multi-Agent Systems (MAS). Built on the Open Agentic Schema
Framework (OASF), ADS decouples capability indexing from content location
through a two-level mapping realized over a Kademlia-based Distributed Hash
Table (DHT). It reuses mature OCI / ORAS infrastructure for artifact
distribution, integrates Sigstore for provenance, and supports schema-driven
extensibility for emerging agent modalities (LLM prompt agents, MCP servers,
A2A-enabled components). This paper formalizes the architectural model,
describes storage and discovery layers, explains security and performance
properties, and positions ADS within the broader landscape of emerging agent
registry and interoperability initiatives.

</details>


### [33] [Bounded PCTL Model Checking of Large Language Model Outputs](https://arxiv.org/abs/2509.18836)
*Dennis Gross,Helge Spieker,Arnaud Gotlieb*

Main category: cs.AI

TL;DR: 本文提出了LLMCHECKER，一种基于模型检查的验证方法，用于验证大型语言模型（LLM）文本生成过程中概率计算树逻辑（PCTL）属性。通过引入$\alpha$-$k$有界文本生成，LLMCHECKER能形式化验证LLM的PCTL属性。


<details>
  <summary>Details</summary>
Motivation: 研究发现LLM文本生成过程中通常只选择有限数量的词元，且这些词元并非总是一致。这种概率性和选择的有限性促使研究者寻求一种形式化方法来验证LLM文本生成过程的属性。

Method: 该方法基于对LLM文本生成过程的观察，即每次生成只选择有限且不总是相同的词元。在此基础上，引入了“$\alpha$-$k$有界文本生成”概念，将关注点缩小到每一步文本生成中累积概率达到$\alpha$的最高$k$个词元。LLMCHECKER考虑初始字符串和随后的最高$k$个词元，并能适应各种文本量化方法（如评估文本质量和偏差）。阈值$\alpha$进一步减少了选定的词元，只选择累积概率超过或达到它的词元。最终，LLMCHECKER形式化验证$\alpha$-$k$有界LLM的PCTL属性。

Result: LLMCHECKER能够形式化验证$\alpha$-$k$有界LLM的PCTL属性。该方法已在Llama、Gemma、Mistral、Genstruct和BERT等多种LLM上验证了其适用性。据作者所知，这是首次将基于PCTL的模型检查用于检查LLM文本生成过程的一致性。

Conclusion: LLMCHECKER提供了一种新颖的、基于模型检查的验证方法，能够形式化验证LLM文本生成过程的PCTL属性。通过引入$\alpha$-$k$有界生成概念，该方法有效地处理了LLM生成过程的概率性，并已在多种主流LLM上展示了其广泛适用性，填补了PCTL模型检查在LLM文本生成一致性验证领域的空白。

Abstract: In this paper, we introduce LLMCHECKER, a model-checking-based verification
method to verify the probabilistic computation tree logic (PCTL) properties of
an LLM text generation process. We empirically show that only a limited number
of tokens are typically chosen during text generation, which are not always the
same. This insight drives the creation of $\alpha$-$k$-bounded text generation,
narrowing the focus to the $\alpha$ maximal cumulative probability on the
top-$k$ tokens at every step of the text generation process. Our verification
method considers an initial string and the subsequent top-$k$ tokens while
accommodating diverse text quantification methods, such as evaluating text
quality and biases. The threshold $\alpha$ further reduces the selected tokens,
only choosing those that exceed or meet it in cumulative probability.
LLMCHECKER then allows us to formally verify the PCTL properties of
$\alpha$-$k$-bounded LLMs. We demonstrate the applicability of our method in
several LLMs, including Llama, Gemma, Mistral, Genstruct, and BERT. To our
knowledge, this is the first time PCTL-based model checking has been used to
check the consistency of the LLM text generation process.

</details>


### [34] [Model selection meets clinical semantics: Optimizing ICD-10-CM prediction via LLM-as-Judge evaluation, redundancy-aware sampling, and section-aware fine-tuning](https://arxiv.org/abs/2509.18846)
*Hong-Jie Dai,Zheng-Hao Li,An-Tai Lu,Bo-Tsz Shain,Ming-Ta Li,Tatheer Hussain Mir,Kuang-Te Wang,Min-I Su,Pei-Kang Liu,Ming-Ju Tsai*

Main category: cs.AI

TL;DR: 本文提出一个模块化框架，通过原则性模型选择、冗余感知数据采样和结构化输入设计，解决大型语言模型在ICD-10-CM编码预测中的挑战，并使用开源LLM实现了可扩展的自动化医疗编码解决方案。


<details>
  <summary>Details</summary>
Motivation: 国际疾病分类（ICD）编码对临床文档、计费和医疗分析至关重要，但它耗时且易出错。尽管大型语言模型（LLMs）在自动化ICD编码方面显示出潜力，但其在基础模型选择、输入情境化和训练数据冗余方面的挑战限制了其有效性。

Method: 该框架包括：1) 结合LLM作为评估器和Plackett-Luce聚合的评估协议，以评估和排名开源LLM的内在理解能力。2) 引入基于嵌入的相似性度量和冗余感知采样策略来去除语义重复的出院摘要。3) 利用台湾医院的结构化出院摘要，通过通用和特定章节建模范式评估上下文效应和章节内容包含。4) 通过精细调整，选择基础模型进行预测。

Result: 在两个机构数据集上的实验表明，经过精细调整后选择的基础模型在内部和外部评估中始终优于基线LLM。纳入更多的临床章节一致地提高了预测性能。

Conclusion: 本研究使用开源LLM建立了一种实用且有原则的ICD-10-CM编码预测方法。所提出的框架通过结合知情的模型选择、高效的数据精炼和上下文感知的提示，为自动化医疗编码系统在实际部署中提供了一个可扩展、机构就绪的解决方案。

Abstract: Accurate International Classification of Diseases (ICD) coding is critical
for clinical documentation, billing, and healthcare analytics, yet it remains a
labour-intensive and error-prone task. Although large language models (LLMs)
show promise in automating ICD coding, their challenges in base model
selection, input contextualization, and training data redundancy limit their
effectiveness. We propose a modular framework for ICD-10 Clinical Modification
(ICD-10-CM) code prediction that addresses these challenges through principled
model selection, redundancy-aware data sampling, and structured input design.
The framework integrates an LLM-as-judge evaluation protocol with Plackett-Luce
aggregation to assess and rank open-source LLMs based on their intrinsic
comprehension of ICD-10-CM code definitions. We introduced embedding-based
similarity measures, a redundancy-aware sampling strategy to remove
semantically duplicated discharge summaries. We leverage structured discharge
summaries from Taiwanese hospitals to evaluate contextual effects and examine
section-wise content inclusion under universal and section-specific modelling
paradigms. Experiments across two institutional datasets demonstrate that the
selected base model after fine-tuning consistently outperforms baseline LLMs in
internal and external evaluations. Incorporating more clinical sections
consistently improves prediction performance. This study uses open-source LLMs
to establish a practical and principled approach to ICD-10-CM code prediction.
The proposed framework provides a scalable, institution-ready solution for
real-world deployment of automated medical coding systems by combining informed
model selection, efficient data refinement, and context-aware prompting.

</details>


### [35] [MAPO: Mixed Advantage Policy Optimization](https://arxiv.org/abs/2509.18849)
*Wenke Huang,Quan Zhang,Yiyang Fang,Jian Liang,Xuankun Rong,Huanjin Yao,Guancheng Wan,Ke Liang,Wenwen He,Mingjun Li,Leszek Rutkowski,Mang Ye,Bo Du,Dacheng Tao*

Main category: cs.AI

TL;DR: 本文提出了一种名为混合优势策略优化（MAPO）的GRPO策略，通过引入优势百分比偏差和动态重加权来解决现有优势函数在不同查询样本中分配不合理的问题，从而提升基础模型在推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的GRPO方法在基础模型推理任务中，其优势函数在轨迹重要性排序时存在“优势反转”和“优势镜像”问题，阻碍了优势在不同查询样本间的合理分配。

Method: 本文提出MAPO策略。首先，针对高确定性轨迹的样本，引入优势百分比偏差。其次，根据轨迹确定性的不同，动态重加权优势函数，以自适应地考虑样本特异性。

Result: 通过与现有最先进方法的比较以及对不同优势变体的消融研究，验证了MAPO方法的有效性。

Conclusion: MAPO是一种简单但有效的GRPO策略，它通过解决优势函数分配问题，显著提升了基础模型在推理任务上的表现。

Abstract: Recent advances in reinforcement learning for foundation models, such as
Group Relative Policy Optimization (GRPO), have significantly improved the
performance of foundation models on reasoning tasks. Notably, the advantage
function serves as a central mechanism in GRPO for ranking the trajectory
importance. However, existing explorations encounter both advantage reversion
and advantage mirror problems, which hinder the reasonable advantage allocation
across different query samples. In this work, we propose an easy but effective
GRPO strategy, Mixed Advantage Policy Optimization (MAPO). We reveal that the
trajectory appears with different certainty and propose the advantage percent
deviation for samples with high-certainty trajectories. Furthermore, we
dynamically reweight the advantage function for samples with varying trajectory
certainty, thereby adaptively configuring the advantage function to account for
sample-specific characteristics. Comparison with related state-of-the-art
methods, along with ablation studies on different advantage variants, validates
the effectiveness of our approach.

</details>


### [36] [Conf-Profile: A Confidence-Driven Reasoning Paradigm for Label-Free User Profiling](https://arxiv.org/abs/2509.18864)
*Yingxin Li,Jianbo Zhao,Xueyu Ren,Jie Tang,Wangjie You,Xu Chen,Kan Zhou,Chao Feng,Jiao Ran,Yuan Meng,Zhi Wang*

Main category: cs.AI

TL;DR: 本文提出ProfileBench，一个工业级用户画像基准，并引入Conf-Profile，一个置信度驱动的无标签用户画像推理框架。该框架通过两阶段训练，利用LLM合成高质量标签并进行置信度引导的无监督强化学习，显著提升了用户画像的F1分数。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在用户画像方面潜力巨大，但缺乏全面的基准测试，且难以收集大规模的真实标签。此外，异构且嘈杂的用户信息会影响LLMs的可靠性。

Method: 1. **ProfileBench基准**：构建了一个来自真实视频平台的工业级基准，包含异构用户数据和结构化画像分类体系。 2. **Conf-Profile框架**：采用两阶段范式实现无标签和可靠的用户画像推理。  a. **第一阶段（标签合成与聚合）**：利用高级LLM结合置信度提示合成高质量标签，并通过置信度加权投票提高准确性，置信度校准平衡分布。将多个画像结果、推理过程和置信度分数聚合并蒸馏到轻量级LLM中。  b. **第二阶段（置信度引导的无监督强化学习）**：利用置信度进行难度过滤、准真实标签投票和奖励加权，以增强推理能力。

Result: 实验结果表明，Conf-Profile通过两阶段训练取得了显著的性能提升，使Qwen3-8B模型的F1分数提高了13.97。

Conclusion: 本文通过引入ProfileBench基准和Conf-Profile框架，有效解决了LLM在用户画像领域面临的基准缺乏、真实标签稀缺以及数据异构嘈杂等挑战，实现了无标签且可靠的用户画像，并取得了显著的性能提升。

Abstract: User profiling, as a core technique for user understanding, aims to infer
structural attributes from user information. Large Language Models (LLMs)
provide a promising avenue for user profiling, yet the progress is hindered by
the lack of comprehensive benchmarks. To bridge this gap, we propose
ProfileBench, an industrial benchmark derived from a real-world video platform,
encompassing heterogeneous user data and a well-structured profiling taxonomy.
However, the profiling task remains challenging due to the difficulty of
collecting large-scale ground-truth labels, and the heterogeneous and noisy
user information can compromise the reliability of LLMs. To approach label-free
and reliable user profiling, we propose a Confidence-driven Profile reasoning
framework Conf-Profile, featuring a two-stage paradigm. We first synthesize
high-quality labels by leveraging advanced LLMs with confidence hints, followed
by confidence-weighted voting for accuracy improvement and confidence
calibration for a balanced distribution. The multiple profile results,
rationales, and confidence scores are aggregated and distilled into a
lightweight LLM. We further enhance the reasoning ability via confidence-guided
unsupervised reinforcement learning, which exploits confidence for difficulty
filtering, quasi-ground truth voting, and reward weighting. Experimental
results demonstrate that Conf-Profile delivers substantial performance through
the two-stage training, improving F1 by 13.97 on Qwen3-8B.

</details>


### [37] [Memory in Large Language Models: Mechanisms, Evaluation and Evolution](https://arxiv.org/abs/2509.18868)
*Dianxing Zhang,Wendong Li,Kani Song,Jiaye Lu,Gang Li,Liuchun Yang,Sheng Li*

Main category: cs.AI

TL;DR: 本文为大型语言模型（LLM）记忆提出了一套统一的操作定义、四部分分类法、记忆四元组、三设置评估协议以及分层评估方法。此外，还引入了DMM Gov框架用于记忆更新与遗忘管理，并提出了四个可测试的命题，旨在为LLM记忆研究与部署提供可复现、可比较和可治理的坐标系。


<details>
  <summary>Details</summary>
Motivation: 现有LLM记忆研究缺乏统一的操作定义和分类标准，导致不同设置下的比较困难。同时，需要一个全面的框架来连接记忆的机制、评估和治理（写入、读取、抑制/更新），并有效管理记忆的更新和遗忘，确保可审计性和一致性。

Method: 本文定义了LLM记忆的统一操作定义，并提出了四部分分类法（参数记忆、上下文记忆、外部记忆、程序/情景记忆）和记忆四元组（位置、持久性、写入/访问路径、可控性）。采用三设置协议（仅参数、离线检索、在线检索）以解耦能力与信息可用性。在此基础上构建了分层评估体系，涵盖了不同记忆类型的评估指标。为更新和遗忘，提出了DMM Gov框架，协调DAPT/TAPT、PEFT、模型编辑和RAG，形成可审计的循环。最后，提出了四个可测试的命题。

Result: 本文提供了一个统一的LLM记忆定义和分类系统。建立了一个能够避免异构设置下比较失真的三设置评估协议。开发了一个涵盖参数、上下文、外部和程序/情景记忆的全面分层评估框架。设计了一个集成了时间治理和泄露审计的系统，以及一个用于记忆更新和遗忘的DMM Gov可审计框架。提出了四个具体可测试的命题，旨在指导未来的研究方向。这些成果共同为LLM记忆的研究和部署提供了一个可复现、可比较和可治理的坐标系统。

Conclusion: 通过提供统一的定义、分类、评估协议和治理框架，本文为LLM记忆的研究和实际部署奠定了坚实的基础。该框架使研究人员能够对LLM记忆进行更准确、可比较的评估，并为记忆的更新、遗忘和审计提供了一个可控且可追溯的系统，从而促进了LLM领域的进步和负责任的部署。

Abstract: Under a unified operational definition, we define LLM memory as a persistent
state written during pretraining, finetuning, or inference that can later be
addressed and that stably influences outputs. We propose a four-part taxonomy
(parametric, contextual, external, procedural/episodic) and a memory quadruple
(location, persistence, write/access path, controllability). We link mechanism,
evaluation, and governance via the chain write -> read -> inhibit/update. To
avoid distorted comparisons across heterogeneous setups, we adopt a
three-setting protocol (parametric only, offline retrieval, online retrieval)
that decouples capability from information availability on the same data and
timeline. On this basis we build a layered evaluation: parametric (closed-book
recall, edit differential, memorization/privacy), contextual (position curves
and the mid-sequence drop), external (answer correctness vs snippet
attribution/faithfulness), and procedural/episodic (cross-session consistency
and timeline replay, E MARS+). The framework integrates temporal governance and
leakage auditing (freshness hits, outdated answers, refusal slices) and
uncertainty reporting via inter-rater agreement plus paired tests with
multiple-comparison correction. For updating and forgetting, we present DMM
Gov: coordinating DAPT/TAPT, PEFT, model editing (ROME, MEND, MEMIT, SERAC),
and RAG to form an auditable loop covering admission thresholds, rollout,
monitoring, rollback, and change audits, with specs for timeliness, conflict
handling, and long-horizon consistency. Finally, we give four testable
propositions: minimum identifiability; a minimal evaluation card; causally
constrained editing with verifiable forgetting; and when retrieval with
small-window replay outperforms ultra-long-context reading. This yields a
reproducible, comparable, and governable coordinate system for research and
deployment.

</details>


### [38] [LongCat-Flash-Thinking Technical Report](https://arxiv.org/abs/2509.18883)
*Meituan LongCat Team,Anchun Gui,Bei Li,Bingyang Tao,Bole Zhou,Borun Chen,Chao Zhang,Chao Zhang,Chengcheng Han,Chenhui Yang,Chi Zhang,Chong Peng,Chuyu Zhang,Cong Chen,Fengcun Li,Gang Xu,Guoyuan Lin,Hao Jiang,Hao Liang,Haomin Fu,Haoxiang Ma,Hong Liu,Hongyan Hao,Hongyin Tang,Hongyu Zang,Hongzhi Ni,Hui Su,Jiahao Liu,Jiahuan Li,Jialin Liu,Jianfei Zhang,Jianhao Xu,Jianing Wang,Jiaqi Sun,Jiaqi Zhang,Jiarong Shi,Jiawei Yang,Jingang Wang,Jinrui Ding,Jun Kuang,Jun Xu,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Li Wei,Liang Shi,Lin Qiu,Lingbin Kong,Lingchuan Liu,Linsen Guo,Longfei An,Mai Xia,Meng Zhou,Mengshen Zhu,Peng Pei,Pengcheng Jia,Qi Gu,Qi Guo,Qiong Huang,Quan Chen,Quanchi Weng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shanglin Lei,Shuai Du,Shuaikang Liu,Shuang Zhou,Shuhao Hu,Siyu Xu,Songshan Gong,Tao Liang,Tianhao Hu,Wei He,Wei Shi,Wei Wang,Wei Wu,Wei Zhuo,Weifeng Tang,Wenjie Shi,Wenlong Zhu,Xi Su,Xiangcheng Liu,Xiangyu Xi,Xiangzhou Huang,Xiao Liu,Xiaochen Jiang,Xiaowei Shi,Xiaowen Shi,Xiaoyu Li,Xin Chen,Xinyue Zhao,Xuan Huang,Xuemiao Zhang,Xuezhi Cao,Xunliang Cai,Yajie Zhang,Yang Chen,Yang Liu,Yang Liu,Yang Zheng,Yaoming Wang,Yaqi Huo,Yerui Sun,Yifan Lu,Yiyang Li,Youshao Xiao,Yuanzhe Lei,Yuchen Xie,Yueqing Sun,Yufei Zhang,Yuhuai Wei,Yulei Qian,Yunke Zhao,Yuqing Ding,Yuwei Jiang,Zhaohua Yang,Zhengyu Chen,Zhijian Liu,Zhikang Xia,Zhongda Su,Ziran Li,Ziwen Wang,Ziyuan Zhuang,Zongyu Wang,Zunyuan Yang*

Main category: cs.AI

TL;DR: LongCat-Flash-Thinking是一个560亿参数的开源MoE推理模型，通过CoT冷启动和大规模RL训练，实现了最先进的推理性能和卓越的智能体推理效率。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效、强大的开源推理模型，尤其是在复杂推理和智能体推理任务中表现出色，以推动推理系统和智能体AI研究的进展。

Method: 该模型采用560亿参数的专家混合（MoE）架构。训练过程包括：1) 使用长链式思考（CoT）数据进行冷启动训练，以增强推理潜力和在形式化和智能体推理方面的专业技能；2) 核心创新是域并行训练方案，将不同领域（如STEM、代码、智能体）的优化解耦，然后将生成的专家模型融合；3) 整个过程由DORA（Dynamic ORchestration for Asynchronous rollout）系统驱动，这是一个大规模RL框架，在数万个加速器上提供超过同步方法三倍的训练速度。

Result: LongCat-Flash-Thinking在复杂推理任务套件中，在开源模型中取得了最先进的性能。在智能体推理方面表现出卓越的效率，在AIME-25上将平均token消耗减少了64.5%（从19,653减少到6,965），且未降低任务准确性。

Conclusion: LongCat-Flash-Thinking是一个高效且性能卓越的开源MoE推理模型，特别擅长智能体推理。该模型的发布旨在促进推理系统和智能体AI研究的进一步发展。

Abstract: We present LongCat-Flash-Thinking, an efficient 560-billion-parameter
open-source Mixture-of-Experts (MoE) reasoning model. Its advanced capabilities
are cultivated through a meticulously crafted training process, beginning with
long Chain-of-Thought (CoT) data cold-start and culminating in large-scale
Reinforcement Learning (RL). We first employ a well-designed cold-start
training strategy, which significantly enhances the reasoning potential and
equips the model with specialized skills in both formal and agentic reasoning.
Then, a core innovation is our domain-parallel training scheme, which decouples
optimization across distinct domains (e.g., STEM, Code, Agentic) and
subsequently fuses the resulting expert models into a single, nearly
Pareto-optimal model. This entire process is powered by our Dynamic
ORchestration for Asynchronous rollout (DORA) system, a large-scale RL
framework that delivers a greater than threefold training speedup over
synchronous methods on tens of thousands of accelerators. As a result,
LongCat-Flash-Thinking achieves state-of-the-art performance among open-source
models on a suite of complex reasoning tasks. The model exhibits exceptional
efficiency in agentic reasoning, reducing average token consumption by 64.5%
(from 19, 653 to 6, 965) on AIME-25, without degrading task accuracy. We
release LongCat-Flash-Thinking to promote further advances in reasoning systems
and agentic AI research.

</details>


### [39] [How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective](https://arxiv.org/abs/2509.18905)
*Songsong Yu,Yuxin Chen,Hao Ju,Lianjie Jia,Fuxi Zhang,Shaofei Huang,Yuhan Wu,Rundi Cui,Binghao Ran,Zaibin Zhang,Zhedong Zheng,Zhipeng Zhang,Yifan Wang,Lin Song,Lijun Wang,Yanwei Li,Ying Shan,Huchuan Lu*

Main category: cs.AI

TL;DR: 本文系统性地调查了视觉空间推理（VSR）在视觉语言模型（VLMs）中的表现，回顾了现有方法，将空间智能分为三个能力等级，并构建了包含20个数据集的SIBench基准。实验揭示了当前VLMs在感知和推理之间存在显著差距，尤其在理解和规划任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 视觉空间推理（VSR）是人类的核心认知能力，也是推动具身智能和自主系统发展的关键。然而，由于三维空间表示和推理的复杂性，尽管视觉语言模型（VLMs）取得了进展，实现人类水平的VSR仍然极具挑战。

Method: 本文首先对VLMs中的VSR进行了系统性调查，涵盖了输入模态、模型架构、训练策略和推理机制等现有方法。其次，将空间智能划分为基本感知、空间理解和空间规划三个能力等级。最后，构建了SIBench空间智能基准，该基准包含近20个开源数据集和23种任务设置，并使用最先进的VLMs进行了实验。

Result: 实验结果表明，VLMs在基本感知任务上表现出能力，但在理解和规划任务中持续表现不佳，尤其是在数值估计、多视角推理、时间动态和空间想象方面。这揭示了模型在感知和推理之间存在显著差距。

Conclusion: 研究结果强调了在实现空间智能方面仍然存在巨大挑战。本文为该领域的未来研究提供了一个系统的路线图和全面的基准，以推动视觉空间推理技术的发展。

Abstract: Visual Spatial Reasoning (VSR) is a core human cognitive ability and a
critical requirement for advancing embodied intelligence and autonomous
systems. Despite recent progress in Vision-Language Models (VLMs), achieving
human-level VSR remains highly challenging due to the complexity of
representing and reasoning over three-dimensional space. In this paper, we
present a systematic investigation of VSR in VLMs, encompassing a review of
existing methodologies across input modalities, model architectures, training
strategies, and reasoning mechanisms. Furthermore, we categorize spatial
intelligence into three levels of capability, ie, basic perception, spatial
understanding, spatial planning, and curate SIBench, a spatial intelligence
benchmark encompassing nearly 20 open-source datasets across 23 task settings.
Experiments with state-of-the-art VLMs reveal a pronounced gap between
perception and reasoning, as models show competence in basic perceptual tasks
but consistently underperform in understanding and planning tasks, particularly
in numerical estimation, multi-view reasoning, temporal dynamics, and spatial
imagination. These findings underscore the substantial challenges that remain
in achieving spatial intelligence, while providing both a systematic roadmap
and a comprehensive benchmark to drive future research in the field. The
related resources of this study are accessible at
https://sibench.github.io/Awesome-Visual-Spatial-Reasoning/.

</details>


### [40] [Data Efficient Adaptation in Large Language Models via Continuous Low-Rank Fine-Tuning](https://arxiv.org/abs/2509.18942)
*Xiao Han,Zimo Zhao,Wanyu Wang,Maolin Wang,Zitao Liu,Yi Chang,Xiangyu Zhao*

Main category: cs.AI

TL;DR: 本文提出DEAL框架，结合LoRA和持续微调策略，通过知识保留和自适应参数更新模块，有效解决了传统LLM微调中灾难性遗忘和数据效率低下的问题，显著提升了任务准确性和资源效率。


<details>
  <summary>Details</summary>
Motivation: 传统LLM微调方法存在灾难性遗忘和数据效率低下等问题，限制了其在实际应用中的效果，尤其是在从头开始训练计算成本过高时，需要更有效的微调技术来适应特定任务。

Method: DEAL框架整合了低秩自适应（LoRA）与持续微调策略。它通过引入知识保留模块和自适应参数更新模块，来缓解现有微调方法的局限性，并保持隐私保护设置下的效率。

Result: 在15个不同数据集上的实验表明，DEAL始终优于基线方法，在任务准确性和资源效率方面取得了显著提升。

Conclusion: DEAL方法通过提高任务性能和资源效率，展示了其在LLM持续适应方面的巨大潜力，为LLM的持续适应提供了有效途径。

Abstract: Recent advancements in Large Language Models (LLMs) have emphasized the
critical role of fine-tuning (FT) techniques in adapting LLMs to specific
tasks, especially when retraining from scratch is computationally infeasible.
Fine-tuning enables LLMs to leverage task- or domain-specific data, producing
models that more effectively meet the requirements of targeted applications.
However, con- ventional FT approaches often suffer from catastrophic forgetting
and suboptimal data efficiency, limiting their real-world applicability. To
address these challenges, this paper proposes DEAL, a novel framework that
integrates Low-Rank Adapta- tion (LoRA) with a continuous fine-tuning strategy.
By incorporating knowledge retention and adaptive parameter update modules, the
framework mitigates the lim- itations of existing FT methods while maintaining
efficiency in privacy-preserving settings. Experiments on 15 diverse datasets
show that DEAL consistently outper- forms baseline methods, yielding
substantial gains in task accuracy and resource efficiency. These findings
demonstrate the potential of our approach to advance continual adaptation in
LLMs by enhancing task performance while improving resource efficiency.

</details>


### [41] [LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions](https://arxiv.org/abs/2509.18970)
*Xixun Lin,Yucheng Ning,Jingwen Zhang,Yan Dong,Yilong Liu,Yongxuan Wu,Xiaohua Qi,Nan Sun,Yanmin Shang,Pengfei Cao,Lixin Zou,Xu Chen,Chuan Zhou,Jia Wu,Shirui Pan,Bin Wang,Yanan Cao,Kai Chen,Songlin Hu,Li Guo*

Main category: cs.AI

TL;DR: 这篇论文首次全面综述了大型语言模型（LLM）驱动的智能体中出现的幻觉问题，提出了新的分类法、分析了触发原因，并总结了缓解和检测方法。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的智能体在各种实际应用中展现出巨大潜力，但其幻觉问题可能导致任务执行错误，并损害系统可靠性。因此，需要深入理解并系统性地整合LLM智能体幻觉的最新进展。

Method: 通过分析智能体的完整工作流程，提出了一种新的智能体幻觉分类法，识别了不同阶段的幻觉类型。深入研究了导致智能体幻觉出现的18个触发原因。详细回顾了大量现有研究，总结了幻觉缓解和检测方法。

Result: 该论文提供了一份关于LLM驱动智能体中幻觉问题的首次全面综述。提出了一个识别不同阶段幻觉的新分类法，并详细分析了18个触发幻觉的原因。同时，总结了现有的幻觉缓解和检测方法，并指出了未来的研究方向。

Conclusion: 这份综述旨在启发更多研究，以解决LLM驱动智能体中的幻觉问题，最终促进开发更鲁棒和可靠的智能体系统。

Abstract: Driven by the rapid advancements of Large Language Models (LLMs), LLM-based
agents have emerged as powerful intelligent systems capable of human-like
cognition, reasoning, and interaction. These agents are increasingly being
deployed across diverse real-world applications, including student education,
scientific research, and financial analysis. However, despite their remarkable
potential, LLM-based agents remain vulnerable to hallucination issues, which
can result in erroneous task execution and undermine the reliability of the
overall system design. Addressing this critical challenge requires a deep
understanding and a systematic consolidation of recent advances on LLM-based
agents. To this end, we present the first comprehensive survey of
hallucinations in LLM-based agents. By carefully analyzing the complete
workflow of agents, we propose a new taxonomy that identifies different types
of agent hallucinations occurring at different stages. Furthermore, we conduct
an in-depth examination of eighteen triggering causes underlying the emergence
of agent hallucinations. Through a detailed review of a large number of
existing studies, we summarize approaches for hallucination mitigation and
detection, and highlight promising directions for future research. We hope this
survey will inspire further efforts toward addressing hallucinations in
LLM-based agents, ultimately contributing to the development of more robust and
reliable agent systems.

</details>


### [42] [From latent factors to language: a user study on LLM-generated explanations for an inherently interpretable matrix-based recommender system](https://arxiv.org/abs/2509.18980)
*Maxime Manderlier,Fabian Lecron,Olivier Vu Thanh,Nicolas Gillis*

Main category: cs.AI

TL;DR: 本研究探讨大型语言模型（LLMs）如何为数学可解释的推荐模型生成有效的用户解释，并通过用户研究评估其质量。


<details>
  <summary>Details</summary>
Motivation: 可解释人工智能（XAI）领域中，许多工作依赖自动化评估指标，这些指标往往未能捕捉用户的实际需求和感知。因此，研究旨在采用以用户为中心的方法来评估解释的质量。

Method: 研究采用了一个基于约束矩阵分解的数学可解释推荐模型，其内部表示和预测分数直接可解释。通过精心设计的LLM提示，将模型结构转换为自然语言解释。进行了一项包含326名参与者的用户研究，评估了五关键维度（透明度、有效性、说服力、信任和满意度）的解释质量以及推荐本身。通过改变提供给LLM的输入信息，生成了多种解释类型以评估不同策略的感知效果。

Result: 分析显示，所有解释类型普遍受到好评，不同解释策略之间存在中等的统计学差异。用户评论进一步强调了参与者对每种解释类型的反应，提供了超越定量结果的补充见解。

Conclusion: LLMs能够为可解释的推荐模型生成有效的用户导向解释，并且这些解释在用户研究中普遍表现良好。用户中心评估对于理解解释的实际效果至关重要。

Abstract: We investigate whether large language models (LLMs) can generate effective,
user-facing explanations from a mathematically interpretable recommendation
model. The model is based on constrained matrix factorization, where user types
are explicitly represented and predicted item scores share the same scale as
observed ratings, making the model's internal representations and predicted
scores directly interpretable. This structure is translated into natural
language explanations using carefully designed LLM prompts. Many works in
explainable AI rely on automatic evaluation metrics, which often fail to
capture users' actual needs and perceptions. In contrast, we adopt a
user-centered approach: we conduct a study with 326 participants who assessed
the quality of the explanations across five key dimensions-transparency,
effectiveness, persuasion, trust, and satisfaction-as well as the
recommendations themselves.To evaluate how different explanation strategies are
perceived, we generate multiple explanation types from the same underlying
model, varying the input information provided to the LLM. Our analysis reveals
that all explanation types are generally well received, with moderate
statistical differences between strategies. User comments further underscore
how participants react to each type of explanation, offering complementary
insights beyond the quantitative results.

</details>


### [43] [Remaining Time Prediction in Outbound Warehouse Processes: A Case Study (Short Paper)](https://arxiv.org/abs/2509.18986)
*Erik Penther,Michael Grohs,Jana-Rebecca Rehse*

Main category: cs.AI

TL;DR: 本文比较了四种剩余时间预测方法在航空物流公司实际出库流程中的表现，发现深度学习模型精度最高，但浅层方法在精度具竞争力且计算资源需求显著更少。


<details>
  <summary>Details</summary>
Motivation: 预测性过程监控旨在预测正在进行的过程执行的未来，其中一个常见目标是预测剩余时间。研究者希望在真实场景中比较不同剩余时间预测方法的有效性。

Method: 研究人员比较了四种不同的剩余时间预测方法，并使用一家航空物流公司提供的包含169,523条轨迹的真实出库仓库流程事件日志进行评估。该事件日志已被公开。

Result: 研究发现深度学习模型实现了最高的预测精度，但传统的提升（boosting）技术等浅层方法也取得了具有竞争力的精度，并且需要显著更少的计算资源。

Conclusion: 对于剩余时间预测，深度学习模型虽然精度最高，但浅层方法在精度和计算资源需求之间提供了良好的平衡，可能是在资源受限环境下的实用选择。同时，研究公开了一个新的真实事件日志。

Abstract: Predictive process monitoring is a sub-domain of process mining which aims to
forecast the future of ongoing process executions. One common prediction target
is the remaining time, meaning the time that will elapse until a process
execution is completed. In this paper, we compare four different remaining time
prediction approaches in a real-life outbound warehouse process of a logistics
company in the aviation business. For this process, the company provided us
with a novel and original event log with 169,523 traces, which we can make
publicly available. Unsurprisingly, we find that deep learning models achieve
the highest accuracy, but shallow methods like conventional boosting techniques
achieve competitive accuracy and require significantly fewer computational
resources.

</details>


### [44] [Landmarks, Monuments, and Beacons: Understanding Generative Calls to Action](https://arxiv.org/abs/2509.19030)
*Victoire Hervé,Henrik Warpefelt,Christoph Salge*

Main category: cs.AI

TL;DR: 本文提出“地标(Landmarks)”、“纪念碑(Monuments)”和“灯塔(Beacons)”等嵌套概念，用于从玩家视角自动分解和评估程序生成内容（PCG），以解决当前评估指标与人类体验不符的问题。


<details>
  <summary>Details</summary>
Motivation: 当前程序生成内容（PCG）的算法评估，特别是对复合型作品的评估，缺乏与人类体验相符的指标。自动分解作为一种可能的解决方案，需要满足一系列属性的概念。

Method: 借鉴游戏研究和游戏AI研究，引入了“地标”、“纪念碑”和“灯塔”这三个嵌套概念。这些概念基于玩家视角下的可感知性、唤起性和行动召唤，并且通用性强，可跨游戏类型使用。提出这些实体可以通过现有研究和工业技术进行发现和评估。

Result: 这些概念为PCG的完全自动化分解和显著子组件的评估开辟了道路。尽管工作侧重于混合主动式PCG和组合式PCG，但其适用范围更广。这种方法旨在连接人文和技术游戏研究，实现更好的计算PCG评估。

Conclusion: 通过引入玩家中心、可分解的概念（地标、纪念碑、灯塔），本文旨在弥合人文与技术游戏研究之间的鸿沟，从而实现更有效、更符合人类体验的程序生成内容计算评估。

Abstract: Algorithmic evaluation of procedurally generated content struggles to find
metrics that align with human experience, particularly for composite artefacts.
Automatic decomposition as a possible solution requires concepts that meet a
range of properties. To this end, drawing on Games Studies and Game AI
research, we introduce the nested concepts of \textit{Landmarks},
\textit{Monuments}, and \textit{Beacons}. These concepts are based on the
artefact's perceivability, evocativeness, and Call to Action, all from a
player-centric perspective. These terms are generic to games and usable across
genres. We argue that these entities can be found and evaluated with techniques
currently used in both research and industry, opening a path towards a fully
automated decomposition of PCG, and evaluation of the salient sub-components.
Although the work presented here emphasises mixed-initiative PCG and
compositional PCG, we believe it applies beyond those domains. With this
approach, we intend to create a connection between humanities and technical
game research and allow for better computational PCG evaluation

</details>


### [45] [Towards Causal Representation Learning with Observable Sources as Auxiliaries](https://arxiv.org/abs/2509.19058)
*Kwonho Kim,Heejeong Nam,Inwoo Hwang,Sanghack Lee*

Main category: cs.AI

TL;DR: 本文提出了一种利用可观测源作为辅助变量的因果表征学习框架，通过体积保持编码器实现了潜在变量的识别，并扩展了现有方法的边界。


<details>
  <summary>Details</summary>
Motivation: 以往的因果表征学习框架通常需要关于潜在结构或关系的假设来实现可识别性，并限制辅助变量必须独立于混合函数。然而，在某些情况下，驱动系统的潜在因素本身是可观测或可从数据中提取的，这可能有助于识别。本文旨在利用这些“可观测源”作为有效的辅助条件变量。

Method: 本文引入了一个将可观测源作为辅助变量的框架，这些源充当有效的条件变量。主要方法包括使用体积保持编码器来识别潜在变量，并提出了一种变量选择方案，当存在多个已知辅助变量时，根据潜在因果图的知识选择能最大化潜在因子可恢复性的变量。

Result: 研究结果表明，该框架能够识别整个潜在变量，精度达到子空间变换和置换。此外，所提出的变量选择方案在已知潜在因果图的情况下，能有效选择最大化潜在因子可恢复性的辅助变量。通过在合成图和图像数据上的实验，验证了该框架的有效性。

Conclusion: 本文提出的框架通过利用可观测源作为辅助变量，有效地扩展了现有因果表征学习方法的边界，实现了潜在变量的识别，并在实验中展现了其有效性。

Abstract: Causal representation learning seeks to recover latent factors that generate
observational data through a mixing function. Needing assumptions on latent
structures or relationships to achieve identifiability in general, prior works
often build upon conditional independence given known auxiliary variables.
However, prior frameworks limit the scope of auxiliary variables to be external
to the mixing function. Yet, in some cases, system-driving latent factors can
be easily observed or extracted from data, possibly facilitating
identification. In this paper, we introduce a framework of observable sources
being auxiliaries, serving as effective conditioning variables. Our main
results show that one can identify entire latent variables up to subspace-wise
transformations and permutations using volume-preserving encoders. Moreover,
when multiple known auxiliary variables are available, we offer a
variable-selection scheme to choose those that maximize recoverability of the
latent factors given knowledge of the latent causal graph. Finally, we
demonstrate the effectiveness of our framework through experiments on synthetic
graph and image data, thereby extending the boundaries of current approaches.

</details>


### [46] [Code Driven Planning with Domain-Adaptive Critic](https://arxiv.org/abs/2509.19077)
*Zikang Tian,Shaohui Peng,Du Huang,Jiaming Guo,Ruizhi Chen,Rui Zhang,Xishan Zhang,Yuxuan Guo,Zidong Du,Qi Guo,Ling Li,Yewen Pu,Xing Hu,Yunji Chen*

Main category: cs.AI

TL;DR: CoPiC提出了一种结合LLM生成高层规划程序和领域自适应评论器的方法，以减少LLM作为规划器时的高查询成本并提升长期奖励对齐的规划能力，显著提高了成功率并降低了查询成本。


<details>
  <summary>Details</summary>
Motivation: LLM作为AI智能体的任务规划器因其通用知识而广泛应用，但其通用知识与环境特定需求之间的差距常导致不准确的计划。现有方法通过频繁查询LLM并基于短期环境反馈迭代优化计划，导致高昂的查询成本，且这种优化往往只关注短期反馈，未能有效对齐长期奖励。

Method: CoPiC不依赖频繁查询，而是利用LLM生成多样化的“高层规划程序”。这些程序迭代地生成并精炼候选计划。随后，一个经过训练的“领域自适应评论器”评估这些候选计划，并选择与长期奖励最一致的计划执行。通过将高层规划程序作为规划器，领域自适应评论器作为评估器，CoPiC旨在提高规划效率并显著降低查询成本。

Result: 在ALFWorld、NetHack和StarCraft II Unit Building等任务中，CoPiC的表现优于先进的基于LLM的基线方法（AdaPlanner和Reflexion）。它平均实现了23.33%的成功率提升和91.27%的查询成本降低。

Conclusion: CoPiC通过利用LLM生成高层规划程序并结合领域自适应评论器来评估长期奖励，有效解决了LLM作为规划器时查询成本高和短期反馈限制的问题。该方法在提高规划成功率的同时，显著降低了LLM的查询成本。

Abstract: Large Language Models (LLMs) have been widely adopted as task planners for AI
agents in sequential decision-making problems, leveraging their extensive world
knowledge. However, the gap between their general knowledge and
environment-specific requirements often leads to inaccurate plans. To address
this, existing approaches rely on frequent LLM queries to iteratively refine
plans based on immediate environmental feedback, which incurs substantial query
costs. However, this refinement is typically guided by short-term environmental
feedback, limiting LLMs from developing plans aligned with long-term rewards.
We propose Code Driven Planning with Domain-Adaptive Critic (CoPiC). Instead of
relying on frequent queries, CoPiC employs LLMs to generate a diverse set of
high-level planning programs, which iteratively produce and refine candidate
plans. A trained domain-adaptive critic then evaluates these candidates and
selects the one most aligned with long-term rewards for execution. Using
high-level planning programs as planner and domain-adaptive critic as
estimator, CoPiC improves planning while significantly reducing query costs.
Results in ALFWorld, NetHack, and StarCraft II Unit Building show that CoPiC
outperforms advanced LLM-based baselines, AdaPlanner and Reflexion, achieving
an average (1) 23.33% improvement in success rate and (2) 91.27% reduction in
query costs.

</details>


### [47] [AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and Expertise Orchestration for Effective and Efficient Collaboration](https://arxiv.org/abs/2509.19236)
*Chunhao Tian,Yutong Wang,Xuebo Liu,Zhexuan Wang,Liang Ding,Miao Zhang,Min Zhang*

Main category: cs.AI

TL;DR: AgentInit是一种新的多智能体系统（MAS）初始化方法，它通过优化智能体团队结构，考虑协作需求、采用多轮交互、自然语言到格式机制和帕累托平衡团队选择策略，显著提高了系统性能并降低了token消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体系统（MAS）初始化方法未能充分考虑后续阶段智能体之间的协作需求，这影响了系统的效率和有效性。

Method: AgentInit通过以下方法优化智能体团队结构：1. 在智能体生成过程中进行多轮交互和反思；2. 引入自然语言到格式（Natural Language to Format）机制以确保一致性和标准化；3. 采用基于帕累托原则的平衡团队选择策略，综合考虑智能体团队的多样性和任务相关性。

Result: 实验表明，AgentInit在各种框架和任务中持续优于现有最先进的初始化方法和预定义策略，性能分别提高了1.2倍和1.6倍，同时显著降低了token消耗。进一步分析证实了其强大的任务迁移能力，并验证了其关键组件的有效性。

Conclusion: AgentInit被证明是一种能力强、适应性好、可靠的多智能体系统初始化方法，能够有效提升系统性能和协作效率。

Abstract: Proper initialization is crucial for any system, particularly in multi-agent
systems (MAS), where it plays a pivotal role in determining both the system's
efficiency and effectiveness. However, existing MAS initialization methods do
not fully account for the collaborative needs of the generated agents in
subsequent stages. Inspired by the principles of effective team composition, we
propose AgentInit, which aims to optimize the structure of agent teams.
Specifically, in addition to multi-round interactions and reflections between
agents during agent generation, AgentInit incorporates a Natural Language to
Format mechanism to ensure consistency and standardization. Balanced team
selection strategies using Pareto principles are subsequently applied to
jointly consider agent team diversity and task relevance to promote effective
and efficient collaboration and enhance overall system performance. Experiments
show that AgentInit consistently outperforms state-of-the-art initialization
methods and pre-defined strategies across various frameworks and tasks,
achieving an overall performance improvement of up to 1.2 and 1.6,
respectively, while also significantly reducing token consumption. Further
analysis confirms its strong transferability to similar tasks and verifies the
effectiveness of its key components, demonstrating its capability and
adaptability as a reliable MAS initialization method. Source code and models
are available at https://github.com/1737423697/AgentInit.

</details>


### [48] [Cross-Cultural Transfer of Commonsense Reasoning in LLMs: Evidence from the Arab World](https://arxiv.org/abs/2509.19265)
*Saeed Almheiri,Rania Hossam,Mena Attia,Chenxi Wang,Preslav Nakov,Timothy Baldwin,Fajri Koto*

Main category: cs.AI

TL;DR: 本研究探索了大型语言模型在阿拉伯世界的跨文化常识推理能力，发现少量文化特定示例即可显著提升多语言模型在其他阿拉伯国家的表现，并证明了文化常识的跨文化可迁移性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）普遍存在西方中心偏见，限制了其在多元文化背景下的有效性。尽管已有文化对齐研究，但利用单一文化对齐来提升其他文化表现的“跨文化迁移”潜力尚未得到充分探索。

Method: 研究使用了一个涵盖13个阿拉伯国家的文化常识推理数据集。评估了轻量级对齐方法，如情境学习和基于演示的强化（DITTO），并与监督微调和直接偏好优化等基线方法进行了比较。

Result: 结果显示，仅需来自一个国家的12个文化特定示例，即可使多语言模型在其他国家的表现平均提升10%。此外，来自印度尼西亚和美国背景的非本文化演示，在多项选择题推理方面可以达到或超越本文化对齐的效果，突显了阿拉伯世界之外的文化常识可迁移性。

Conclusion: 这些发现表明，高效的跨文化对齐是可行的，为将大型语言模型适应到低资源文化环境提供了一种有前景的方法。

Abstract: Large language models (LLMs) often reflect Western-centric biases, limiting
their effectiveness in diverse cultural contexts. Although some work has
explored cultural alignment, the potential for cross-cultural transfer, using
alignment in one culture to improve performance in others, remains
underexplored. This paper investigates cross-cultural transfer of commonsense
reasoning in the Arab world, where linguistic and historical similarities
coexist with local cultural differences. Using a culturally grounded
commonsense reasoning dataset covering 13 Arab countries, we evaluate
lightweight alignment methods such as in-context learning and
demonstration-based reinforcement (DITTO), alongside baselines like supervised
fine-tuning and direct preference optimization. Our results show that merely 12
culture-specific examples from one country can improve performance in others by
10\% on average, within multilingual models. In addition, we demonstrate that
out-of-culture demonstrations from Indonesia and US contexts can match or
surpass in-culture alignment for MCQ reasoning, highlighting cultural
commonsense transferability beyond the Arab world. These findings demonstrate
that efficient cross-cultural alignment is possible and offer a promising
approach to adapt LLMs to low-resource cultural settings.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [49] [PolypSeg-GradCAM: Towards Explainable Computer-Aided Gastrointestinal Disease Detection Using U-Net Based Segmentation and Grad-CAM Visualization on the Kvasir Dataset](https://arxiv.org/abs/2509.18159)
*Akwasi Asare,Ulas Bagci*

Main category: cs.CV

TL;DR: 本研究提出PolypSeg-GradCAM，一个结合U-Net和Grad-CAM的可解释深度学习框架，用于结肠镜息肉分割，实现了高精度分割并提高了模型决策的透明度，有助于早期结直肠癌预防。


<details>
  <summary>Details</summary>
Motivation: 结直肠癌是全球癌症相关发病率和死亡率的主要原因，胃肠息肉是其关键前兆。结肠镜检查中早期准确分割息肉至关重要，但手动分割耗时且易受观察者差异影响。现有深度学习方法虽有潜力，但其可解释性不足是临床应用的主要障碍。

Method: 本研究提出了PolypSeg-GradCAM，一个可解释的深度学习框架，它将U-Net架构与梯度加权类激活映射（Grad-CAM）相结合，用于透明的息肉分割。模型在包含1000张带注释内窥镜图像的Kvasir-SEG数据集上进行训练和评估。

Result: 实验结果显示出强大的分割性能，在测试集上平均交并比（IoU）达到0.9257，并在训练和验证集上持续保持高Dice系数（F-score > 0.96）。Grad-CAM可视化进一步证实了模型的预测是由临床相关区域指导的，增强了模型决策的透明度和信任度。

Conclusion: PolypSeg-GradCAM通过将高分割精度与可解释性相结合，代表了迈向可靠、值得信赖的AI辅助结肠镜检查和改进早期结直肠癌预防的重要一步。

Abstract: Colorectal cancer (CRC) remains one of the leading causes of cancer-related
morbidity and mortality worldwide, with gastrointestinal (GI) polyps serving as
critical precursors according to the World Health Organization (WHO). Early and
accurate segmentation of polyps during colonoscopy is essential for reducing
CRC progression, yet manual delineation is labor-intensive and prone to
observer variability. Deep learning methods have demonstrated strong potential
for automated polyp analysis, but their limited interpretability remains a
barrier to clinical adoption. In this study, we present PolypSeg-GradCAM, an
explainable deep learning framework that integrates the U-Net architecture with
Gradient-weighted Class Activation Mapping (Grad-CAM) for transparent polyp
segmentation. The model was trained and evaluated on the Kvasir-SEG dataset of
1000 annotated endoscopic images. Experimental results demonstrate robust
segmentation performance, achieving a mean Intersection over Union (IoU) of
0.9257 on the test set and consistently high Dice coefficients (F-score > 0.96)
on training and validation sets. Grad-CAM visualizations further confirmed that
predictions were guided by clinically relevant regions, enhancing transparency
and trust in the model's decisions. By coupling high segmentation accuracy with
interpretability, PolypSeg-GradCAM represents a step toward reliable,
trustworthy AI-assisted colonoscopy and improved early colorectal cancer
prevention.

</details>


### [50] [PerceptronCARE: A Deep Learning-Based Intelligent Teleopthalmology Application for Diabetic Retinopathy Diagnosis](https://arxiv.org/abs/2509.18160)
*Akwasi Asare,Isaac Baffour Senkyire,Emmanuel Freeman,Simon Hilary Ayinedenaba Aluze-Ele,Kelvin Kwao*

Main category: cs.CV

TL;DR: PerceptronCARE是一款基于深度学习的远程眼科应用，利用视网膜图像自动检测糖尿病视网膜病变（DR），旨在提高欠发达地区的筛查可及性。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是成年人视力丧失的主要原因，尤其在医疗资源匮乏地区构成严峻的全球健康挑战，亟需可及的筛查解决方案。

Method: 本研究开发并评估了PerceptronCARE系统，使用了多种卷积神经网络（包括ResNet-18、EfficientNet-B0和SqueezeNet）进行模型优化，以在准确性和计算效率之间取得平衡。该应用集成了基于云计算的可扩展性、安全的患者数据管理和多用户框架。

Result: 最终模型在疾病严重程度分类上达到了85.4%的准确率，支持临床和远程医疗环境中的实时筛查。PerceptronCARE的集成功能有助于早期诊断、改善医患互动并降低医疗成本。

Conclusion: 本研究强调了人工智能驱动的远程医疗解决方案在扩大糖尿病视网膜病变筛查覆盖范围方面的潜力，尤其是在偏远和资源受限的环境中。

Abstract: Diabetic retinopathy is a leading cause of vision loss among adults and a
major global health challenge, particularly in underserved regions. This study
presents PerceptronCARE, a deep learning-based teleophthalmology application
designed for automated diabetic retinopathy detection using retinal images. The
system was developed and evaluated using multiple convolutional neural
networks, including ResNet-18, EfficientNet-B0, and SqueezeNet, to determine
the optimal balance between accuracy and computational efficiency. The final
model classifies disease severity with an accuracy of 85.4%, enabling real-time
screening in clinical and telemedicine settings. PerceptronCARE integrates
cloud-based scalability, secure patient data management, and a multi-user
framework, facilitating early diagnosis, improving doctor-patient interactions,
and reducing healthcare costs. This study highlights the potential of AI-driven
telemedicine solutions in expanding access to diabetic retinopathy screening,
particularly in remote and resource-constrained environments.

</details>


### [51] [Self Identity Mapping](https://arxiv.org/abs/2509.18165)
*Xiuding Cai,Yaoyao Zhu,Linjie Fu,Dong Miao,Yu Yao*

Main category: cs.CV

TL;DR: 本文提出了一种名为自身份映射（SIM）的数据内在正则化框架，通过逆映射机制增强表示学习和泛化能力。其高效实现ρSIM通过重建变换后的输出，减少信息损失并促进梯度平滑，在多种任务和领域中显示出显著改进，并能与现有正则化方法正交结合。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习正则化技术常依赖启发式方法，导致在不同设置下可靠性和有效性不足，因此需要更通用和可靠的正则化策略。

Method: 本文提出自身份映射（SIM）框架，利用逆映射机制从变换后的输出重建输入，以减少信息损失并促进平滑梯度流。为解决计算效率问题，SIM被实例化为ρSIM，通过引入补丁级特征采样和基于投影的方法来重建潜在特征，从而降低复杂度。SIM设计为模型和任务无关的即插即用模块。

Result: ρSIM在图像分类、少样本提示学习和领域泛化等任务中均超越基线方法，持续提升性能。实验证明ρSIM与现有正则化方法正交，能进一步增强其效果。此外，ρSIM能有效保留语义信息，并在语义分割、图像翻译等密集到密集任务以及音频分类和时间序列异常检测等非视觉领域中提升性能。

Conclusion: 自身份映射（SIM）及其高效实现ρSIM是一种简单而有效、数据内在的正则化框架，通过逆映射机制显著增强表示学习和泛化能力。它具有模型和任务无关性，可作为即插即用模块应用于广泛的任务和领域，并能与现有正则化方法协同工作，提供一致的性能提升。

Abstract: Regularization is essential in deep learning to enhance generalization and
mitigate overfitting. However, conventional techniques often rely on
heuristics, making them less reliable or effective across diverse settings. We
propose Self Identity Mapping (SIM), a simple yet effective, data-intrinsic
regularization framework that leverages an inverse mapping mechanism to enhance
representation learning. By reconstructing the input from its transformed
output, SIM reduces information loss during forward propagation and facilitates
smoother gradient flow. To address computational inefficiencies, We instantiate
SIM as $ \rho\text{SIM} $ by incorporating patch-level feature sampling and
projection-based method to reconstruct latent features, effectively lowering
complexity. As a model-agnostic, task-agnostic regularizer, SIM can be
seamlessly integrated as a plug-and-play module, making it applicable to
different network architectures and tasks.
  We extensively evaluate $\rho\text{SIM}$ across three tasks: image
classification, few-shot prompt learning, and domain generalization.
Experimental results show consistent improvements over baseline methods,
highlighting $\rho\text{SIM}$'s ability to enhance representation learning
across various tasks. We also demonstrate that $\rho\text{SIM}$ is orthogonal
to existing regularization methods, boosting their effectiveness. Moreover, our
results confirm that $\rho\text{SIM}$ effectively preserves semantic
information and enhances performance in dense-to-dense tasks, such as semantic
segmentation and image translation, as well as in non-visual domains including
audio classification and time series anomaly detection. The code is publicly
available at https://github.com/XiudingCai/SIM-pytorch.

</details>


### [52] [MAGIA: Sensing Per-Image Signals from Single-Round Averaged Gradients for Label-Inference-Free Gradient Inversion](https://arxiv.org/abs/2509.18170)
*Zhanting Zhou,Jinbo Wang,Zeqin Wu,Fengli Zhang*

Main category: cs.CV

TL;DR: MAGIA是一种基于动量的自适应梯度反演攻击修正方法，通过组合重缩放和动量混合，在单轮平均梯度（SAG）和大批量场景下，无需辅助信息即可实现高保真多图像重建，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在单轮平均梯度（SAG）机制中，每个样本的线索纠缠在一个批次平均梯度内，使得梯度反演攻击极具挑战性。现有方法在大批量场景下表现不佳或失效，研究旨在解决这一问题，实现高保真多图像重建。

Method: 引入了MAGIA（基于动量的自适应修正梯度反演攻击），这是一个新颖的无标签推理框架，通过探测随机数据子集来感知潜在的单图像信号。MAGIA的目标函数整合了两项核心创新：1. 闭式组合重缩放，创建了可证明更紧密的优化边界；2. 基于动量的全批次和子集损失混合，以确保重建的鲁棒性。

Result: MAGIA显著优于先进方法，在现有工作失败的大批量场景中实现了高保真多图像重建。其计算开销与标准求解器相当，且无需任何辅助信息。

Conclusion: MAGIA提供了一种在具有挑战性的单轮平均梯度（SAG）和大批量场景下进行梯度反演的有效解决方案，通过其创新的优化和混合策略，实现了鲁棒且高保真的图像重建，同时保持了计算效率和独立性。

Abstract: We study gradient inversion in the challenging single round averaged gradient
SAG regime where per sample cues are entangled within a single batch mean
gradient. We introduce MAGIA a momentum based adaptive correction on gradient
inversion attack a novel label inference free framework that senses latent per
image signals by probing random data subsets. MAGIA objective integrates two
core innovations 1 a closed form combinatorial rescaling that creates a
provably tighter optimization bound and 2 a momentum based mixing of whole
batch and subset losses to ensure reconstruction robustness. Extensive
experiments demonstrate that MAGIA significantly outperforms advanced methods
achieving high fidelity multi image reconstruction in large batch scenarios
where prior works fail. This is all accomplished with a computational footprint
comparable to standard solvers and without requiring any auxiliary information.

</details>


### [53] [Baseer: A Vision-Language Model for Arabic Document-to-Markdown OCR](https://arxiv.org/abs/2509.18174)
*Khalil Hennara,Muhammad Hreden,Mohamed Motasim Hamed,Ahmad Bastati,Zeina Aldallal,Sara Chrouf,Safwan AlModhayan*

Main category: cs.CV

TL;DR: 本文提出了Baseer，一个专门针对阿拉伯语文档OCR进行微调的视觉语言模型，通过结合合成和真实世界数据进行训练，并在新的Misraj-DocOCR基准上显著优于现有解决方案，达到了0.25的词错误率（WER），创造了新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语文档OCR由于其草书字体、多样字体、变音符号和从右到左的书写方向而极具挑战性。尽管现代多模态大型语言模型（MLLM）在处理高资源语言的文档理解方面取得了进展，但它们在阿拉伯语上的表现仍然有限。

Method: 本文引入了Baseer，一个专门为阿拉伯语文档OCR微调的视觉语言模型。通过结合合成和真实世界文档的大规模数据集，Baseer使用仅解码器微调策略进行训练，以适应预训练的MLLM，同时保留通用视觉特征。此外，本文还推出了Misraj-DocOCR，一个高质量、经过专家验证的基准，用于严格评估阿拉伯语OCR系统。

Result: 实验表明，Baseer显著优于现有的开源和商业解决方案，实现了0.25的词错误率（WER），并在阿拉伯语文档OCR领域建立了新的最先进水平。

Conclusion: 研究结果强调了对通用MLLM进行领域特定适应的优势，并为像阿拉伯语这样形态丰富的语言的高精度OCR建立了强大的基线。

Abstract: Arabic document OCR remains a challenging task due to the language's cursive
script, diverse fonts, diacritics, and right-to-left orientation. While modern
Multimodal Large Language Models (MLLMs) have advanced document understanding
for high-resource languages, their performance on Arabic remains limited. In
this work, we introduce Baseer, a vision-language model fine- tuned
specifically for Arabic document OCR. Leveraging a large-scale dataset
combining synthetic and real-world documents, Baseer is trained using a
decoder-only fine-tuning strategy to adapt a pre-trained MLLM while preserving
general visual features. We also present Misraj-DocOCR, a high-quality,
expert-verified benchmark designed for rigorous evaluation of Arabic OCR
systems. Our experiments show that Baseer significantly outperforms existing
open-source and commercial solutions, achieving a WER of 0.25 and establishing
a new state-of-the-art in the domain of Arabic document OCR. Our results
highlight the benefits of domain-specific adaptation of general-purpose MLLMs
and establish a strong baseline for high-accuracy OCR on morphologically rich
languages like Arabic.

</details>


### [54] [A Deep Learning Approach for Spatio-Temporal Forecasting of InSAR Ground Deformation in Eastern Ireland](https://arxiv.org/abs/2509.18176)
*Wendong Yao,Saeed Azadnejad,Binhua Huang,Shane Donohue,Soumyabrata Dev*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的深度学习框架（CNN-LSTM），能将稀疏InSAR数据转换为密集时空张量，首次实现计算机视觉架构直接应用于地面形变预测，并显著提高了预测的准确性和空间一致性。


<details>
  <summary>Details</summary>
Motivation: 监测地面位移对城市基础设施稳定和地质灾害防治至关重要。然而，从稀疏的合成孔径雷达干涉测量（InSAR）时间序列数据中预测未来形变是一个重大挑战。

Method: 该研究引入了一个深度学习框架，将稀疏点测量数据转换为密集的时空张量，从而可以直接应用先进的计算机视觉架构。设计并实现了一个混合卷积神经网络和长短期记忆网络（CNN-LSTM）模型，用于同时学习生成数据张量中的空间模式和时间依赖性。模型性能通过与Light Gradient Boosting Machine和LASSO回归等机器学习基线模型进行比较，使用了爱尔兰东部的Sentinel-1数据。

Result: 结果表明，所提出的架构提供了显著更准确和空间一致的预测，为该任务建立了新的性能基准。此外，可解释性分析揭示基线模型常默认简单的持久性模式，凸显了集成时空方法捕捉地面形变复杂动态的必要性。

Conclusion: 研究结果证实了时空深度学习在高分辨率形变预测中的有效性和潜力。

Abstract: Monitoring ground displacement is crucial for urban infrastructure stability
and mitigating geological hazards. However, forecasting future deformation from
sparse Interferometric Synthetic Aperture Radar (InSAR) time-series data
remains a significant challenge. This paper introduces a novel deep learning
framework that transforms these sparse point measurements into a dense
spatio-temporal tensor. This methodological shift allows, for the first time,
the direct application of advanced computer vision architectures to this
forecasting problem. We design and implement a hybrid Convolutional Neural
Network and Long-Short Term Memory (CNN-LSTM) model, specifically engineered to
simultaneously learn spatial patterns and temporal dependencies from the
generated data tensor. The model's performance is benchmarked against powerful
machine learning baselines, Light Gradient Boosting Machine and LASSO
regression, using Sentinel-1 data from eastern Ireland. Results demonstrate
that the proposed architecture provides significantly more accurate and
spatially coherent forecasts, establishing a new performance benchmark for this
task. Furthermore, an interpretability analysis reveals that baseline models
often default to simplistic persistence patterns, highlighting the necessity of
our integrated spatio-temporal approach to capture the complex dynamics of
ground deformation. Our findings confirm the efficacy and potential of
spatio-temporal deep learning for high-resolution deformation forecasting.

</details>


### [55] [A Framework for Generating Artificial Datasets to Validate Absolute and Relative Position Concepts](https://arxiv.org/abs/2509.18177)
*George Corrêa de Araújo,Helena de Almeida Maia,Helio Pedrini*

Main category: cs.CV

TL;DR: 论文提出了Scrapbook框架，一种生成大规模数据集的新方法，用于探究AI模型对基本概念的理解。研究发现，尽管模型在物体识别和计数方面表现出色，但在理解位置信息和处理带约束的查询时仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 在AI模型处理更复杂的任务之前，需要验证它们对物体识别、绝对和相对位置以及属性识别等基本概念的理解。

Method: 提出了Scrapbook框架，一种新颖的方法，通过生成包含大量关于独立概念和广泛语言变异问题的海量数据集，来探究AI模型的学习概念。

Result: 当代模型在物体识别和枚举方面表现熟练，但在理解位置信息和处理带额外约束的查询时遇到挑战。具体来说，MobileVLM-V2模型显示出显著的答案分歧和看似合理的错误答案，而其他模型则表现出肯定答案的偏向，并在涉及几何形状和位置信息的问题上表现不佳，表明在理解和一致性方面有待改进。

Conclusion: 所提出的Scrapbook框架提供了一个有价值的工具，可用于生成多样化和全面的数据集，从而系统地评估和提升AI模型的性能。

Abstract: In this paper, we present the Scrapbook framework, a novel methodology
designed to generate extensive datasets for probing the learned concepts of
artificial intelligence (AI) models. The framework focuses on fundamental
concepts such as object recognition, absolute and relative positions, and
attribute identification. By generating datasets with a large number of
questions about individual concepts and a wide linguistic variation, the
Scrapbook framework aims to validate the model's understanding of these basic
elements before tackling more complex tasks. Our experimental findings reveal
that, while contemporary models demonstrate proficiency in recognizing and
enumerating objects, they encounter challenges in comprehending positional
information and addressing inquiries with additional constraints. Specifically,
the MobileVLM-V2 model showed significant answer disagreements and plausible
wrong answers, while other models exhibited a bias toward affirmative answers
and struggled with questions involving geometric shapes and positional
information, indicating areas for improvement in understanding and consistency.
The proposed framework offers a valuable instrument for generating diverse and
comprehensive datasets, which can be utilized to systematically assess and
enhance the performance of AI models.

</details>


### [56] [The Describe-Then-Generate Bottleneck: How VLM Descriptions Alter Image Generation Outcomes](https://arxiv.org/abs/2509.18179)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.CV

TL;DR: 本文量化了多模态AI系统中“描述-生成”视觉-语言-视觉管道中的信息损失，发现通过文本中介后，视觉内容存在显著的感知和结构退化。


<details>
  <summary>Details</summary>
Motivation: 随着多模态AI系统在创意工作流中的集成度提高，理解视觉-语言-视觉管道中的信息损失对于评估系统局限性至关重要。然而，视觉内容通过文本中介时发生的退化尚未得到很好的量化。

Method: 研究通过“描述-生成”管道生成了150对图像，并应用现有指标（LPIPS、SSIM和颜色距离）来衡量感知、结构和色度维度上的信息保留情况。

Result: 评估显示，99.3%的样本表现出显著的感知退化，91.5%的样本表现出明显的结构信息损失。

Conclusion: “描述-生成”瓶颈代表了当代多模态系统中可衡量且一致的局限性，提供了实证证据证明了这一瓶颈的存在。

Abstract: With the increasing integration of multimodal AI systems in creative
workflows, understanding information loss in vision-language-vision pipelines
has become important for evaluating system limitations. However, the
degradation that occurs when visual content passes through textual
intermediation remains poorly quantified. In this work, we provide empirical
analysis of the describe-then-generate bottleneck, where natural language
serves as an intermediate representation for visual information. We generated
150 image pairs through the describe-then-generate pipeline and applied
existing metrics (LPIPS, SSIM, and color distance) to measure information
preservation across perceptual, structural, and chromatic dimensions. Our
evaluation reveals that 99.3% of samples exhibit substantial perceptual
degradation and 91.5% demonstrate significant structural information loss,
providing empirical evidence that the describe-then-generate bottleneck
represents a measurable and consistent limitation in contemporary multimodal
systems.

</details>


### [57] [AI-Derived Structural Building Intelligence for Urban Resilience: An Application in Saint Vincent and the Grenadines](https://arxiv.org/abs/2509.18182)
*Isabelle Tingzon,Yoji Toriumi,Caroline Gevaert*

Main category: cs.CV

TL;DR: 该研究提出了一种AI驱动的工作流程，利用高分辨率卫星图像自动推断屋顶属性，以解决小岛屿发展中国家（SIDS）在城市韧性规划和灾害风险管理中缺乏建筑结构信息的挑战。


<details>
  <summary>Details</summary>
Motivation: 气候脆弱地区（如加勒比海）的许多小岛屿发展中国家（SIDS）缺乏详细的建筑结构信息，而这些信息对于估算灾害（如气旋、洪水、山体滑坡）造成的潜在损害至关重要，是城市韧性规划和灾害风险减轻的关键。

Method: 该研究提出了一种AI驱动的工作流程，利用高分辨率卫星图像自动推断屋顶属性。方法包括比较地理空间基础模型结合浅层分类器与微调深度学习模型在屋顶分类中的效用，并评估纳入邻近SIDS的额外训练数据对模型性能的影响。案例研究地点为圣文森特和格林纳丁斯。

Result: 最佳模型在屋顶坡度分类上达到了0.88的F1分数，在屋顶材料分类上达到了0.83的F1分数。

Conclusion: 该工作旨在结合当地能力建设，为SIDS提供利用AI和地球观测（EO）数据的新能力，以实现更高效、基于证据的城市治理，特别是在灾害风险管理方面。

Abstract: Detailed structural building information is used to estimate potential damage
from hazard events like cyclones, floods, and landslides, making them critical
for urban resilience planning and disaster risk reduction. However, such
information is often unavailable in many small island developing states (SIDS)
in climate-vulnerable regions like the Caribbean. To address this data gap, we
present an AI-driven workflow to automatically infer rooftop attributes from
high-resolution satellite imagery, with Saint Vincent and the Grenadines as our
case study. Here, we compare the utility of geospatial foundation models
combined with shallow classifiers against fine-tuned deep learning models for
rooftop classification. Furthermore, we assess the impact of incorporating
additional training data from neighboring SIDS to improve model performance.
Our best models achieve F1 scores of 0.88 and 0.83 for roof pitch and roof
material classification, respectively. Combined with local capacity building,
our work aims to provide SIDS with novel capabilities to harness AI and Earth
Observation (EO) data to enable more efficient, evidence-based urban
governance.

</details>


### [58] [VLA-LPAF: Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation](https://arxiv.org/abs/2509.18183)
*Jinyue Bian,Zhaoxing Zhang,Zhengyu Liang,Shiwei Zheng,Shengtao Zhang,Rong Shen,Chen Yang,Anzhou Hou*

Main category: cs.CV

TL;DR: VLA模型在多视角视觉观察下泛化性受限。本文提出轻量级模块VLA-LPAF，通过2D数据和潜在空间融合，有效提升VLA模型的视角适应性，并在多个基准测试中显著提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作（VLA）模型通过大量演示数据训练，但其视觉观察（来自第三人称全局和腕部局部摄像头）在不同环境中数量和视角各异，导致视觉特征差异显著，从而限制了VLA模型的泛化能力。

Method: 提出VLA-LPAF，一个轻量级模块，仅使用2D数据提升VLA模型的视角适应性。该模块通过单一视角图像进行微调，并在潜在空间中融合其他多视角观察，有效弥合了视角不一致造成的差距。作者将VLA-LPAF与RoboFlamingo模型结合，构建了RoboFlamingo-LPAF。

Result: 实验表明，RoboFlamingo-LPAF在CALVIN上平均提升了约8%的任务成功率，在LIBERO上提升了15%，在一个定制模拟基准上提升了30%。此外，还在真实世界任务中展示了其开发的视角适应性特征。

Conclusion: VLA-LPAF模块能够有效且高效地弥合因视角不一致造成的差距，显著提高了VLA模型（如RoboFlamingo）在不同环境和摄像头设置下的泛化性和性能。

Abstract: The Visual-Language-Action (VLA) models can follow text instructions
according to visual observations of the surrounding environment. This ability
to map multimodal inputs to actions is derived from the training of the VLA
model on extensive standard demonstrations. These visual observations captured
by third-personal global and in-wrist local cameras are inevitably varied in
number and perspective across different environments, resulting in significant
differences in the visual features. This perspective heterogeneity constrains
the generality of VLA models. In light of this, we first propose the
lightweight module VLA-LPAF to foster the perspective adaptivity of VLA models
using only 2D data. VLA-LPAF is finetuned using images from a single view and
fuses other multiview observations in the latent space, which effectively and
efficiently bridge the gap caused by perspective inconsistency. We instantiate
our VLA-LPAF framework with the VLA model RoboFlamingo to construct
RoboFlamingo-LPAF. Experiments show that RoboFlamingo-LPAF averagely achieves
around 8% task success rate improvement on CALVIN, 15% on LIBERO, and 30% on a
customized simulation benchmark. We also demonstrate the developed viewadaptive
characteristics of the proposed RoboFlamingo-LPAF through real-world tasks.

</details>


### [59] [A Single Image Is All You Need: Zero-Shot Anomaly Localization Without Training Data](https://arxiv.org/abs/2509.18354)
*Mehrdad Moradi,Shengzhe Chen,Hao Yan,Kamran Paynabar*

Main category: cs.CV

TL;DR: 本文提出了一种名为SSDnet的单图像异常定位方法，该方法在零样本设置下，无需外部训练数据或参考，通过利用卷积神经网络的归纳偏置和图像自身的结构特性，实现了对图像中局部异常的有效检测。


<details>
  <summary>Details</summary>
Motivation: 传统的图像异常检测方法通常需要大量的训练数据或参考样本。然而，在许多实际场景中，这些数据可能无法获得，只能提供待检测的图像本身。为了解决这种零样本（zero-shot）设置下的挑战，本文提出了新的方法。

Method: SSDnet方法受Deep Image Prior (DIP)启发，利用卷积神经网络的归纳偏置。核心假设是自然图像通常表现出统一的纹理和模式，而异常表现为这些重复或随机模式的局部偏差。该方法设计了一个基于补丁的训练框架，直接将输入图像送入网络进行自重建，而非像DIP那样将随机噪声映射到图像。为避免模型学习恒等映射，引入了掩码、补丁混洗和高斯噪声。此外，使用基于内积相似度的感知损失来捕获超越像素保真度的结构信息。该方法不需要外部训练数据、标签或参考，并对噪声或缺失像素具有鲁棒性。

Result: SSDnet在MVTec-AD数据集上取得了0.99的AUROC和0.60的AUPRC，在fabric数据集上取得了0.98的AUROC和0.67的AUPRC，性能优于现有最先进的方法。

Conclusion: SSDnet是一种无需外部训练数据、标签或参考的单图像异常定位方法，它利用图像自身的结构特性和CNN的归纳偏置，通过自重建和特定的正则化技术，在零样本设置下表现出卓越的性能，并对噪声和缺失像素具有鲁棒性。

Abstract: Anomaly detection in images is typically addressed by learning from
collections of training data or relying on reference samples. In many
real-world scenarios, however, such training data may be unavailable, and only
the test image itself is provided. We address this zero-shot setting by
proposing a single-image anomaly localization method that leverages the
inductive bias of convolutional neural networks, inspired by Deep Image Prior
(DIP). Our method is named Single Shot Decomposition Network (SSDnet). Our key
assumption is that natural images often exhibit unified textures and patterns,
and that anomalies manifest as localized deviations from these repetitive or
stochastic patterns. To learn the deep image prior, we design a patch-based
training framework where the input image is fed directly into the network for
self-reconstruction, rather than mapping random noise to the image as done in
DIP. To avoid the model simply learning an identity mapping, we apply masking,
patch shuffling, and small Gaussian noise. In addition, we use a perceptual
loss based on inner-product similarity to capture structure beyond pixel
fidelity. Our approach needs no external training data, labels, or references,
and remains robust in the presence of noise or missing pixels. SSDnet achieves
0.99 AUROC and 0.60 AUPRC on MVTec-AD and 0.98 AUROC and 0.67 AUPRC on the
fabric dataset, outperforming state-of-the-art methods. The implementation code
will be released at https://github.com/mehrdadmoradi124/SSDnet

</details>


### [60] [URNet: Uncertainty-aware Refinement Network for Event-based Stereo Depth Estimation](https://arxiv.org/abs/2509.18184)
*Yifeng Cheng,Alois Knoll,Hu Cao*

Main category: cs.CV

TL;DR: 本文提出URNet，一个不确定性感知细化网络，用于基于事件相机的立体深度估计，通过局部-全局细化模块和KL散度不确定性建模，显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有高时间分辨率、高动态范围和低延迟的优势，但其在立体深度估计方面的潜力尚未完全开发。提升事件相机在深度估计中的可靠性和准确性是研究的动力。

Method: 本文引入了URNet（不确定性感知细化网络），其核心方法包括：1) 一个局部-全局细化模块，用于捕捉精细局部细节和长距离全局上下文；2) 一个基于Kullback-Leibler（KL）散度的不确定性建模方法，以提高预测的可靠性。

Result: 在DSEC数据集上进行的广泛实验表明，URNet在定性和定量评估中均持续优于现有的最先进（SOTA）方法。

Conclusion: URNet为事件相机的立体深度估计提供了一种先进且可靠的解决方案，通过其创新的细化模块和不确定性建模，显著提升了深度预测的性能。

Abstract: Event cameras provide high temporal resolution, high dynamic range, and low
latency, offering significant advantages over conventional frame-based cameras.
In this work, we introduce an uncertainty-aware refinement network called URNet
for event-based stereo depth estimation. Our approach features a local-global
refinement module that effectively captures fine-grained local details and
long-range global context. Additionally, we introduce a Kullback-Leibler (KL)
divergence-based uncertainty modeling method to enhance prediction reliability.
Extensive experiments on the DSEC dataset demonstrate that URNet consistently
outperforms state-of-the-art (SOTA) methods in both qualitative and
quantitative evaluations.

</details>


### [61] [Event-guided 3D Gaussian Splatting for Dynamic Human and Scene Reconstruction](https://arxiv.org/abs/2509.18566)
*Xiaoting Yin,Hao Shi,Kailun Yang,Jiajun Zhai,Shangwei Guo,Lin Wang,Kaiwei Wang*

Main category: cs.CV

TL;DR: 本文提出一个事件引导的人体-场景重建框架，利用单目事件相机和3D高斯溅射技术，共同建模动态人体和静态场景，并通过事件引导损失解决运动模糊问题，实现高质量重建。


<details>
  <summary>Details</summary>
Motivation: 从单目视频中重建动态人体和静态场景极具挑战，尤其是在快速运动导致RGB帧出现运动模糊时。事件相机具备微秒级时间分辨率，是处理动态人体重建的理想选择。

Method: 该方法提出一个新颖的事件引导人体-场景重建框架，通过3D高斯溅射技术，从单个单目事件相机共同建模人体和场景。统一的3D高斯集合携带可学习的语义属性：被分类为人体的部分进行变形以实现动画，而场景部分保持静态。为对抗模糊，提出一种事件引导损失，将连续渲染帧之间的模拟亮度变化与事件流匹配，以提高快速移动区域的局部保真度。该方法无需外部人体掩码，并简化了不同高斯集合的管理。

Result: 在ZJU-MoCap-Blur和MMHPSD-Blur两个基准数据集上，该方法实现了最先进的人体-场景重建性能，在PSNR/SSIM方面显著优于强基线，并降低了LPIPS，尤其对于高速运动目标表现更佳。

Conclusion: 该研究成功地利用事件相机和3D高斯溅射技术，通过事件引导损失，解决了从单目视频中重建动态人体和静态场景时遇到的运动模糊问题，尤其在快速运动场景下展现出卓越的重建能力和保真度。

Abstract: Reconstructing dynamic humans together with static scenes from monocular
videos remains difficult, especially under fast motion, where RGB frames suffer
from motion blur. Event cameras exhibit distinct advantages, e.g., microsecond
temporal resolution, making them a superior sensing choice for dynamic human
reconstruction. Accordingly, we present a novel event-guided human-scene
reconstruction framework that jointly models human and scene from a single
monocular event camera via 3D Gaussian Splatting. Specifically, a unified set
of 3D Gaussians carries a learnable semantic attribute; only Gaussians
classified as human undergo deformation for animation, while scene Gaussians
stay static. To combat blur, we propose an event-guided loss that matches
simulated brightness changes between consecutive renderings with the event
stream, improving local fidelity in fast-moving regions. Our approach removes
the need for external human masks and simplifies managing separate Gaussian
sets. On two benchmark datasets, ZJU-MoCap-Blur and MMHPSD-Blur, it delivers
state-of-the-art human-scene reconstruction, with notable gains over strong
baselines in PSNR/SSIM and reduced LPIPS, especially for high-speed subjects.

</details>


### [62] [Visionerves: Automatic and Reproducible Hybrid AI for Peripheral Nervous System Recognition Applied to Endometriosis Cases](https://arxiv.org/abs/2509.18185)
*Giammarco La Barbera,Enzo Bonnot,Thomas Isla,Juan Pablo de la Plata,Joy-Rose Dunoyer de Segonzac,Jennifer Attali,Cécile Lozach,Alexandre Bellucci,Louis Marcellin,Laure Fournier,Sabine Sarnacki,Pietro Gori,Isabelle Bloch*

Main category: cs.CV

TL;DR: Visionerves是一个混合AI框架，用于从多梯度DWI和形态MRI数据中识别周围神经系统。它通过模糊空间关系编码解剖知识，无需手动选择ROI，显著提高了对腰骶丛的神经识别准确性，为子宫内膜异位症相关神经病变诊断提供了新的非侵入性方法。


<details>
  <summary>Details</summary>
Motivation: 子宫内膜异位症常导致慢性盆腔疼痛并可能涉及神经，但周围神经的成像仍然是一个挑战。

Method: 本研究引入了Visionerves，一个混合AI框架，用于从多梯度DWI和形态MRI数据中识别周围神经系统。该框架通过模糊空间关系编码解剖知识，从而消除了手动选择ROI的需要。其流程包括两个阶段：(A) 使用深度学习模型自动分割解剖结构；(B) 通过符号空间推理进行纤维束描记和神经识别。

Result: 将Visionerves应用于10名患有（确诊或疑似）子宫内膜异位症女性的腰骶丛，结果显示其性能较标准纤维束描记法有显著提升：Dice分数提高了高达25%，空间误差减少到小于5毫米。

Conclusion: Visionerves提供了一种自动且可重复的详细神经分析方法，为子宫内膜异位症相关神经病变以及其他涉及神经的疾病的非侵入性诊断铺平了道路。

Abstract: Endometriosis often leads to chronic pelvic pain and possible nerve
involvement, yet imaging the peripheral nerves remains a challenge. We
introduce Visionerves, a novel hybrid AI framework for peripheral nervous
system recognition from multi-gradient DWI and morphological MRI data. Unlike
conventional tractography, Visionerves encodes anatomical knowledge through
fuzzy spatial relationships, removing the need for selection of manual ROIs.
The pipeline comprises two phases: (A) automatic segmentation of anatomical
structures using a deep learning model, and (B) tractography and nerve
recognition by symbolic spatial reasoning. Applied to the lumbosacral plexus in
10 women with (confirmed or suspected) endometriosis, Visionerves demonstrated
substantial improvements over standard tractography, with Dice score
improvements of up to 25% and spatial errors reduced to less than 5 mm. This
automatic and reproducible approach enables detailed nerve analysis and paves
the way for non-invasive diagnosis of endometriosis-related neuropathy, as well
as other conditions with nerve involvement.

</details>


### [63] [WaveletGaussian: Wavelet-domain Diffusion for Sparse-view 3D Gaussian Object Reconstruction](https://arxiv.org/abs/2509.19073)
*Hung Nguyen,Runfa Li,An Le,Truong Nguyen*

Main category: cs.CV

TL;DR: 针对稀疏视角下的3D高斯泼溅（3DGS）重建问题，本文提出WaveletGaussian框架，通过将扩散模型应用于小波域的低频部分并结合轻量级网络处理高频部分，以及采用高效的在线随机掩码策略，显著提高了训练效率，同时保持了竞争性的渲染质量。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）在稀疏视角设置下性能急剧下降。现有方法通过扩散模型修复损坏的渲染图作为伪真值进行优化，但扩散模型的微调和修复步骤计算成本高昂。

Method: WaveletGaussian框架的核心思想是将扩散过程转移到小波域：扩散仅应用于低分辨率的LL子带，而高频子带则通过轻量级网络进行细化。此外，提出了一种高效的在线随机掩码策略来生成扩散模型微调的训练对，取代了传统但效率低下的“留一法”策略。

Result: 在Mip-NeRF 360和OmniObject3D两个基准数据集上的实验表明，WaveletGaussian在实现具有竞争力的渲染质量的同时，大幅缩短了训练时间。

Conclusion: WaveletGaussian提供了一种更高效的稀疏视角3D高斯物体重建方法，它通过创新的小波域扩散和高效的掩码策略，显著降低了计算成本，同时保持了高质量的重建效果。

Abstract: 3D Gaussian Splatting (3DGS) has become a powerful representation for
image-based object reconstruction, yet its performance drops sharply in
sparse-view settings. Prior works address this limitation by employing
diffusion models to repair corrupted renders, subsequently using them as pseudo
ground truths for later optimization. While effective, such approaches incur
heavy computation from the diffusion fine-tuning and repair steps. We present
WaveletGaussian, a framework for more efficient sparse-view 3D Gaussian object
reconstruction. Our key idea is to shift diffusion into the wavelet domain:
diffusion is applied only to the low-resolution LL subband, while
high-frequency subbands are refined with a lightweight network. We further
propose an efficient online random masking strategy to curate training pairs
for diffusion fine-tuning, replacing the commonly used, but inefficient,
leave-one-out strategy. Experiments across two benchmark datasets, Mip-NeRF 360
and OmniObject3D, show WaveletGaussian achieves competitive rendering quality
while substantially reducing training time.

</details>


### [64] [V-SenseDrive: A Privacy-Preserving Road Video and In-Vehicle Sensor Fusion Framework for Road Safety & Driver Behaviour Modelling](https://arxiv.org/abs/2509.18187)
*Muhammad Naveed,Nazia Perwaiz,Sidra Sultana,Mohaira Ahmad,Muhammad Moazam Fraz*

Main category: cs.CV

TL;DR: V-SenseDrive是首个在巴基斯坦驾驶环境中收集的、保护隐私的多模态驾驶行为数据集，结合智能手机传感器数据和路向视频，旨在提升道路安全和支持智能交通系统。


<details>
  <summary>Details</summary>
Motivation: 道路交通事故是巴基斯坦等新兴经济体的重大公共卫生挑战，这些国家路况复杂、交通流量混合、驾驶纪律不一。现有数据集多来自发达国家，缺乏对新兴经济体驾驶行为多样性的代表性，且驾驶员面部记录存在隐私问题。因此，需要一个能代表这些环境并保护隐私的数据集。

Method: 研究团队开发了V-SenseDrive数据集。他们使用定制的Android应用程序，结合智能手机的惯性传感器（加速度计、陀螺仪）和GPS数据，以及同步的路向视频，在巴基斯坦的城市主干道、次级道路和高速公路等多种道路类型上，记录了三种目标驾驶行为（正常、激进和危险）。所有数据源均经过精确时间对齐，并结构化为原始、处理和语义层。

Result: 研究成果是V-SenseDrive，这是第一个完全在巴基斯坦驾驶环境中收集的、保护隐私的多模态驾驶行为数据集。它成功地结合了智能手机传感器数据和路向视频，记录了多样化的驾驶行为，并解决了现有数据集在代表性和隐私方面的不足。

Conclusion: V-SenseDrive数据集填补了全球驾驶行为数据集中在巴基斯坦等新兴经济体方面的关键空白。它为未来的驾驶行为分类、交通安全分析和高级驾驶辅助系统（ADAS）开发奠定了基础，并为情境感知智能交通解决方案提供了支持。

Abstract: Road traffic accidents remain a major public health challenge, particularly
in countries with heterogeneous road conditions, mixed traffic flow, and
variable driving discipline, such as Pakistan. Reliable detection of unsafe
driving behaviours is a prerequisite for improving road safety, enabling
advanced driver assistance systems (ADAS), and supporting data driven decisions
in insurance and fleet management. Most of existing datasets originate from the
developed countries with limited representation of the behavioural diversity
observed in emerging economies and the driver's face recording voilates the
privacy preservation. We present V-SenseDrive, the first privacy-preserving
multimodal driver behaviour dataset collected entirely within the Pakistani
driving environment. V-SenseDrive combines smartphone based inertial and GPS
sensor data with synchronized road facing video to record three target driving
behaviours (normal, aggressive, and risky) on multiple types of roads,
including urban arterials, secondary roads, and motorways. Data was gathered
using a custom Android application designed to capture high frequency
accelerometer, gyroscope, and GPS streams alongside continuous video, with all
sources precisely time aligned to enable multimodal analysis. The focus of this
work is on the data acquisition process, covering participant selection,
driving scenarios, environmental considerations, and sensor video
synchronization techniques. The dataset is structured into raw, processed, and
semantic layers, ensuring adaptability for future research in driver behaviour
classification, traffic safety analysis, and ADAS development. By representing
real world driving in Pakistan, V-SenseDrive fills a critical gap in the global
landscape of driver behaviour datasets and lays the groundwork for context
aware intelligent transportation solutions.

</details>


### [65] [Qianfan-VL: Domain-Enhanced Universal Vision-Language Models](https://arxiv.org/abs/2509.18189)
*Daxiang Dong,Mingming Zheng,Dong Xu,Bairong Zhuang,Wenyu Zhang,Chunhua Luo,Haoran Wang,Zijian Zhao,Jie Li,Yuxuan Li,Hanjun Zhong,Mengyue Liu,Jieting Chen,Shupeng Li,Lun Tian,Yaping Feng,Xin Li,Donggang Jiang,Yong Chen,Yehua Xu,Duohao Qin,Chen Feng,Dan Wang,Henghua Zhang,Jingjing Ha,Jinhui He,Yanfeng Zhai,Chengxin Zheng,Jiayi Mao,Jiacheng Chen,Ruchang Yao,Ziye Yuan,Jianmin Wu,Guangjun Xie,Dou Shen*

Main category: cs.CV

TL;DR: Qianfan-VL是一系列3B到70B参数的多模态大语言模型，通过创新的领域增强技术，在保持强大通用性能的同时，实现了SOTA级的领域特定能力，特别在OCR、文档理解、数学推理和逻辑推理方面表现出色，并验证了大规模AI基础设施的训练能力。


<details>
  <summary>Details</summary>
Motivation: 开发具有强大通用性能和卓越领域特定能力的多模态大语言模型，以满足多样化的企业部署场景需求，并探索创新的领域增强技术和高效的大规模训练方法。

Method: 采用多阶段渐进式训练和高精度数据合成流水线，通过领域增强策略提升模型在特定领域的性能。部分模型（8B和70B变体）融入了长链式思考能力。所有模型均在百度昆仑P800芯片上进行训练，并验证了大规模AI基础设施的高效扩展能力。

Result: Qianfan-VL在通用基准上与领先的开源模型结果相当，并在CCBench、SEEDBench IMG、ScienceQA和MMStar等基准上达到SOTA性能。在OCR和文档理解方面表现出显著优势（OCRBench 873%，DocVQA 94.75%）。8B和70B变体在数学推理（MathVista 78.6%）和逻辑推理任务上表现优异。模型在百度昆仑P800芯片上以超过90%的扩展效率（5000个芯片）成功训练，验证了其大规模AI基础设施的能力。

Conclusion: 这项工作为开发适用于各种企业部署场景的领域增强多模态模型建立了一种有效的方法论，并展示了大规模AI基础设施在训练SOTA级多模态模型方面的强大能力。

Abstract: We present Qianfan-VL, a series of multimodal large language models ranging
from 3B to 70B parameters, achieving state-of-the-art performance through
innovative domain enhancement techniques. Our approach employs multi-stage
progressive training and high-precision data synthesis pipelines, which prove
to be critical technologies for enhancing domain-specific capabilities while
maintaining strong general performance. Qianfan-VL achieves comparable results
to leading open-source models on general benchmarks, with state-of-the-art
performance on benchmarks such as CCBench, SEEDBench IMG, ScienceQA, and
MMStar. The domain enhancement strategy delivers significant advantages in OCR
and document understanding, validated on both public benchmarks (OCRBench 873,
DocVQA 94.75%) and in-house evaluations. Notably, Qianfan-VL-8B and 70B
variants incorporate long chain-of-thought capabilities, demonstrating superior
performance on mathematical reasoning (MathVista 78.6%) and logical inference
tasks. All models are trained entirely on Baidu's Kunlun P800 chips, validating
the capability of large-scale AI infrastructure to train SOTA-level multimodal
models with over 90% scaling efficiency on 5000 chips for a single task. This
work establishes an effective methodology for developing domain-enhanced
multimodal models suitable for diverse enterprise deployment scenarios.

</details>


### [66] [HazeFlow: Revisit Haze Physical Model as ODE and Non-Homogeneous Haze Generation for Real-World Dehazing](https://arxiv.org/abs/2509.18190)
*Junseong Shin,Seungwoo Chung,Yunjeong Yang,Tae Hyun Kim*

Main category: cs.CV

TL;DR: HazeFlow是一个基于ODE的去雾框架，将大气散射模型（ASM）重构为ODE，通过学习最优ODE轨迹将雾霾图像映射到清晰图像。它还引入了基于马尔可夫链布朗运动（MCBM）的非均匀雾霾生成方法，以解决真实世界配对数据稀缺问题，并在多个真实世界去雾基准测试中达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习去雾方法面临真实世界配对训练数据不足和领域鸿沟问题，导致泛化能力受限。同时，传统基于物理学的大气散射模型（ASM）难以处理真实世界的复杂性和多样化的雾霾模式。

Method: 本文提出了HazeFlow，一个新颖的基于ODE的框架，将大气散射模型（ASM）重新表述为常微分方程（ODE）。受Rectified Flow启发，HazeFlow学习一个最优的ODE轨迹，以单步推理将雾霾图像映射到清晰图像。此外，为了解决真实世界配对数据稀缺问题，引入了使用马尔可夫链布朗运动（MCBM）的非均匀雾霾生成方法，以模拟逼真的雾霾模式。

Result: 通过广泛的实验，HazeFlow在各种真实世界去雾基准数据集上均实现了最先进的性能。

Conclusion: HazeFlow通过将ASM重构为ODE并结合创新的数据生成方法，有效解决了真实世界去雾的挑战，显著提升了去雾效果和对多样化真实场景的适应性。

Abstract: Dehazing involves removing haze or fog from images to restore clarity and
improve visibility by estimating atmospheric scattering effects. While deep
learning methods show promise, the lack of paired real-world training data and
the resulting domain gap hinder generalization to real-world scenarios. In this
context, physics-grounded learning becomes crucial; however, traditional
methods based on the Atmospheric Scattering Model (ASM) often fall short in
handling real-world complexities and diverse haze patterns. To solve this
problem, we propose HazeFlow, a novel ODE-based framework that reformulates ASM
as an ordinary differential equation (ODE). Inspired by Rectified Flow (RF),
HazeFlow learns an optimal ODE trajectory to map hazy images to clean ones,
enhancing real-world dehazing performance with only a single inference step.
Additionally, we introduce a non-homogeneous haze generation method using
Markov Chain Brownian Motion (MCBM) to address the scarcity of paired
real-world data. By simulating realistic haze patterns through MCBM, we enhance
the adaptability of HazeFlow to diverse real-world scenarios. Through extensive
experiments, we demonstrate that HazeFlow achieves state-of-the-art performance
across various real-world dehazing benchmark datasets.

</details>


### [67] [TinyEcoWeedNet: Edge Efficient Real-Time Aerial Agricultural Weed Detection](https://arxiv.org/abs/2509.18193)
*Omar H. Khater,Abdul Jabbar Siddiqui,Aiman El-Maleh,M. Shamim Hossain*

Main category: cs.CV

TL;DR: 该研究通过结构化通道剪枝、量化感知训练和TensorRT加速，成功将EcoWeedNet模型压缩并部署到边缘设备上，显著减小了模型大小和计算量，同时提高了推理速度和精度，使其适用于精准农业。


<details>
  <summary>Details</summary>
Motivation: 在农业领域部署深度学习模型面临边缘设备资源有限的挑战。

Method: 采用结构化通道剪枝、量化感知训练（QAT）以及使用NVIDIA TensorRT在Jetson Orin Nano上进行加速。该方法解决了剪枝包含残差快捷连接、注意力机制、拼接和CSP块等复杂架构的挑战。

Result: 模型大小减小了高达68.5%，计算量减少了3.2 GFLOPs。推理速度在FP16下达到184 FPS，比基线快28.7%。在CottonWeedDet12数据集上，剪枝率为39.5%的EcoWeedNet表现优于YOLO11n和YOLO12n（仅20%剪枝），实现了83.7%的精确度、77.5%的召回率和85.9%的mAP50。

Conclusion: 经验证，该压缩版的EcoWeedNet模型在精准农业应用中既高效又有效。

Abstract: Deploying deep learning models in agriculture is difficult because edge
devices have limited resources, but this work presents a compressed version of
EcoWeedNet using structured channel pruning, quantization-aware training (QAT),
and acceleration with NVIDIA's TensorRT on the Jetson Orin Nano. Despite the
challenges of pruning complex architectures with residual shortcuts, attention
mechanisms, concatenations, and CSP blocks, the model size was reduced by up to
68.5% and computations by 3.2 GFLOPs, while inference speed reached 184 FPS at
FP16, 28.7% faster than the baseline. On the CottonWeedDet12 dataset, the
pruned EcoWeedNet with a 39.5% pruning ratio outperformed YOLO11n and YOLO12n
(with only 20% pruning), achieving 83.7% precision, 77.5% recall, and 85.9%
mAP50, proving it to be both efficient and effective for precision agriculture.

</details>


### [68] [Learning Contrastive Multimodal Fusion with Improved Modality Dropout for Disease Detection and Prediction](https://arxiv.org/abs/2509.18284)
*Yi Gu,Kuniaki Saito,Jiaxin Ma*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的多模态学习框架，通过增强的模态丢弃和对比学习，有效处理医学诊断中模态不平衡和缺失问题，实现了最先进的性能，特别是在仅有单一模态的挑战性场景下。


<details>
  <summary>Details</summary>
Motivation: 随着医学诊断越来越多地利用多模态数据，机器学习模型需要有效融合异构信息，同时对缺失模态保持鲁棒性，以应对现实世界中的模态不平衡和缺失等限制。

Method: 该方法引入了一个新颖的多模态学习框架，集成了增强的模态丢弃和对比学习。它引入了可学习的模态令牌，以改进对缺失模态的融合感知，并通过融合的多模态表示来增强传统的单模态对比目标。

Result: 该框架在大型临床数据集上（包括视觉和表格模态）进行了疾病检测和预测任务的验证。实验结果表明，该方法实现了最先进的性能，尤其是在仅有单一模态的挑战性实际场景中。此外，它还成功地与最近的CT基础模型集成，展示了其适应性。

Conclusion: 研究结果强调了该方法在多模态学习中的有效性、效率和泛化能力，提供了一个可扩展、低成本的解决方案，在实际临床应用中具有巨大潜力。

Abstract: As medical diagnoses increasingly leverage multimodal data, machine learning
models are expected to effectively fuse heterogeneous information while
remaining robust to missing modalities. In this work, we propose a novel
multimodal learning framework that integrates enhanced modalities dropout and
contrastive learning to address real-world limitations such as modality
imbalance and missingness. Our approach introduces learnable modality tokens
for improving missingness-aware fusion of modalities and augments conventional
unimodal contrastive objectives with fused multimodal representations. We
validate our framework on large-scale clinical datasets for disease detection
and prediction tasks, encompassing both visual and tabular modalities.
Experimental results demonstrate that our method achieves state-of-the-art
performance, particularly in challenging and practical scenarios where only a
single modality is available. Furthermore, we show its adaptability through
successful integration with a recent CT foundation model. Our findings
highlight the effectiveness, efficiency, and generalizability of our approach
for multimodal learning, offering a scalable, low-cost solution with
significant potential for real-world clinical applications. The code is
available at https://github.com/omron-sinicx/medical-modality-dropout.

</details>


### [69] [Rethinking Pulmonary Embolism Segmentation: A Study of Current Approaches and Challenges with an Open Weight Model](https://arxiv.org/abs/2509.18308)
*Yixin Zhang,Ryan Chamberlain,Lawrance Ngo,Kevin Kramer,Maciej A. Mazurowski*

Main category: cs.CV

TL;DR: 本研究在自建数据集上系统评估了9种分割架构对肺栓塞（PE）的性能，发现3D U-Net（ResNet编码器）表现出色，CNN优于ViT，且分类预训练可能不利于分割，远端栓塞仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在利用一个密集标注的自建数据集，系统评估多种广泛使用的分割架构（包括CNN和Vision Transformer）在肺栓塞（PE）分割任务中的性能，并进行统一的性能审计。

Method: 研究构建了一个包含490个CTPA扫描的密集标注内部数据集。在此数据集上，系统评估了9种广泛使用的分割架构（来自CNN和Vision Transformer家族），这些架构使用预训练或随机权重初始化，并在统一的测试框架下进行性能审计。

Result: 主要发现包括：(1) 带有ResNet编码器的3D U-Net仍然是PE分割的高效架构；(2) 鉴于栓塞的形态特征，3D模型特别适合此任务；(3) CNN模型在PE分割中通常优于ViT模型；(4) 基于分类的预训练（即使在大型PE数据集上）可能对分割性能产生负面影响，表明PE分类和分割可能依赖不同的判别特征；(5) 不同模型架构在相同数据上训练时显示出高度一致的分割性能模式；(6) 中心和大型栓塞可以达到满意的分割精度，但远端栓塞由于任务复杂性和高质量数据集稀缺而仍然具有挑战性。最佳模型在分割任务上实现了0.7131的平均Dice分数，并在60个内部测试扫描中检测到181个栓塞，有49个假阳性和28个假阴性，并在公共数据集上验证了其泛化能力。

Conclusion: 本研究得出结论，带有ResNet编码器的3D U-Net是PE分割的有效架构，3D模型适用于此任务，且CNN模型通常优于ViT模型。此外，分类预训练可能不适用于分割任务，远端栓塞的准确分割仍是未来研究的重点挑战。

Abstract: In this study, we curated a densely annotated in-house dataset comprising 490
CTPA scans. Using this dataset, we systematically evaluated nine widely used
segmentation architectures from both the CNN and Vision Transformer (ViT)
families, initialized with either pretrained or random weights, under a unified
testing framework as a performance audit. Our study leads to several important
observations: (1) 3D U-Net with a ResNet encoder remains a highly effective
architecture for PE segmentation; (2) 3D models are particularly well-suited to
this task given the morphological characteristics of emboli; (3) CNN-based
models generally yield superior performance compared to their ViT-based
counterparts in PE segmentation; (4) classification-based pretraining, even on
large PE datasets, can adversely impact segmentation performance compared to
training from scratch, suggesting that PE classification and segmentation may
rely on different sets of discriminative features; (5) different model
architectures show a highly consistent pattern of segmentation performance when
trained on the same data; and (6) while central and large emboli can be
segmented with satisfactory accuracy, distal emboli remain challenging due to
both task complexity and the scarcity of high-quality datasets. Besides these
findings, our best-performing model achieves a mean Dice score of 0.7131 for
segmentation. It detects 181 emboli with 49 false positives and 28 false
negatives from 60 in-house testing scans. Its generalizability is further
validated on public datasets.

</details>


### [70] [Improving Handshape Representations for Sign Language Processing: A Graph Neural Network Approach](https://arxiv.org/abs/2509.18309)
*Alessa Carbo,Eric Nalisnick*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的图神经网络，结合解剖学图结构和对比学习，显著提高了手语手形识别的准确性，并建立了首个结构化手形识别基准。


<details>
  <summary>Details</summary>
Motivation: 手形在手语中扮演着重要的语音学角色（如美国手语有约50种手形），但现有的计算方法很少明确地对手形进行建模，这限制了识别准确性和语言分析能力。研究旨在解决手形识别中微妙的类别间区分和时间变化等关键挑战。

Method: 研究引入了一种新颖的图神经网络，它将时间动态与静态手形配置分离。该方法结合了基于解剖学信息的图结构和对比学习，以应对手形识别中的挑战。

Result: 研究建立了首个手语序列中结构化手形识别的基准，在37个手形类别上实现了46%的准确率，远高于基线方法（25%）。

Conclusion: 该研究提出的图神经网络方法能够有效分离时间动态和静态手形，并通过结合解剖学信息和对比学习，显著提升了手语手形识别的准确性，并为该领域设立了一个新的性能基准。

Abstract: Handshapes serve a fundamental phonological role in signed languages, with
American Sign Language employing approximately 50 distinct shapes.
However,computational approaches rarely model handshapes explicitly, limiting
both recognition accuracy and linguistic analysis.We introduce a novel graph
neural network that separates temporal dynamics from static handshape
configurations. Our approach combines anatomically-informed graph structures
with contrastive learning to address key challenges in handshape recognition,
including subtle interclass distinctions and temporal variations. We establish
the first benchmark for structured handshape recognition in signing sequences,
achieving 46% accuracy across 37 handshape classes (with baseline methods
achieving 25%).

</details>


### [71] [Influence of Classification Task and Distribution Shift Type on OOD Detection in Fetal Ultrasound](https://arxiv.org/abs/2509.18326)
*Chun Kit Wong,Anders N. Christensen,Cosmin I. Bercea,Julia A. Schnabel,Martin G. Tolsgaard,Aasa Feragen*

Main category: cs.CV

TL;DR: 本研究发现，在胎儿超声图像中，模型分类任务的选择显著影响出分布（OOD）检测的性能，并且最佳任务取决于OOD样本的类型（图像特征或解剖特征偏移）。


<details>
  <summary>Details</summary>
Motivation: 在胎儿超声等医疗领域安全部署深度学习模型，可靠的出分布（OOD）检测至关重要，因为图像特征和临床环境存在异质性。现有研究主要关注不确定性量化方法，但本研究认为分类任务本身对OOD检测性能也有重要影响。

Method: 通过八种不确定性量化方法，在四种不同的分类任务上进行了实验，以评估OOD检测性能。研究了两种OOD样本类型：i) 图像特征偏移，ii) 解剖特征偏移。

Result: OOD检测性能随分类任务的不同而显著变化。最佳任务取决于ID-OOD的定义标准，即OOD样本是由图像特征偏移还是解剖特征偏移引起。此外，卓越的OOD检测性能并不能保证最佳的拒绝预测。

Conclusion: 在医学图像分析中，必须根据特定的下游应用来调整任务选择和不确定性策略，以实现有效的OOD检测和拒绝预测。

Abstract: Reliable out-of-distribution (OOD) detection is important for safe deployment
of deep learning models in fetal ultrasound amidst heterogeneous image
characteristics and clinical settings. OOD detection relies on estimating a
classification model's uncertainty, which should increase for OOD samples.
While existing research has largely focused on uncertainty quantification
methods, this work investigates the impact of the classification task itself.
Through experiments with eight uncertainty quantification methods across four
classification tasks, we demonstrate that OOD detection performance
significantly varies with the task, and that the best task depends on the
defined ID-OOD criteria; specifically, whether the OOD sample is due to: i) an
image characteristic shift or ii) an anatomical feature shift. Furthermore, we
reveal that superior OOD detection does not guarantee optimal abstained
prediction, underscoring the necessity to align task selection and uncertainty
strategies with the specific downstream application in medical image analysis.

</details>


### [72] [OrthoLoC: UAV 6-DoF Localization and Calibration Using Orthographic Geodata](https://arxiv.org/abs/2509.18350)
*Oussema Dhaouadi,Riccardo Marin,Johannes Meier,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: 该论文提出了OrthoLoC，一个用于从空中视角进行视觉定位的大规模数据集，该数据集利用轻量级的正射地理数据，并引入了一种名为AdHoP的匹配优化技术，显著提高了定位精度。


<details>
  <summary>Details</summary>
Motivation: 在资源受限（如无网络或GNSS/GPS）的情况下，需要高精度空中视觉定位，但现有的大型图像数据库或3D模型不切实际。同时，轻量级的正射地理数据作为替代方案，却未得到充分利用。

Method: 提出了OrthoLoC数据集，包含16,425张来自德国和美国的无人机图像，具有多种模态和配对结构，旨在解决无人机图像与地理空间数据之间的域偏移问题，并促进公平基准测试。通过综合评估，研究了域偏移、数据分辨率和共视性对定位精度的影响。最后，引入了一种名为AdHoP的精炼技术，可与任何特征匹配器集成。

Result: OrthoLoC数据集成功解决了无人机图像与地理空间数据之间的域偏移问题，并通过解耦图像检索和特征匹配，实现了对现有解决方案的公平基准测试。AdHoP精炼技术可将匹配性能提高高达95%，并将平移误差降低高达63%。

Conclusion: OrthoLoC数据集和AdHoP精炼技术为利用轻量级正射地理数据进行高精度空中视觉定位提供了一个新的范式，有效解决了资源受限环境下的定位挑战和域偏移问题，显著提升了定位精度。

Abstract: Accurate visual localization from aerial views is a fundamental problem with
applications in mapping, large-area inspection, and search-and-rescue
operations. In many scenarios, these systems require high-precision
localization while operating with limited resources (e.g., no internet
connection or GNSS/GPS support), making large image databases or heavy 3D
models impractical. Surprisingly, little attention has been given to leveraging
orthographic geodata as an alternative paradigm, which is lightweight and
increasingly available through free releases by governmental authorities (e.g.,
the European Union). To fill this gap, we propose OrthoLoC, the first
large-scale dataset comprising 16,425 UAV images from Germany and the United
States with multiple modalities. The dataset addresses domain shifts between
UAV imagery and geospatial data. Its paired structure enables fair benchmarking
of existing solutions by decoupling image retrieval from feature matching,
allowing isolated evaluation of localization and calibration performance.
Through comprehensive evaluation, we examine the impact of domain shifts, data
resolutions, and covisibility on localization accuracy. Finally, we introduce a
refinement technique called AdHoP, which can be integrated with any feature
matcher, improving matching by up to 95% and reducing translation error by up
to 63%. The dataset and code are available at:
https://deepscenario.github.io/OrthoLoC.

</details>


### [73] [Align Where the Words Look: Cross-Attention-Guided Patch Alignment with Contrastive and Transport Regularization for Bengali Captioning](https://arxiv.org/abs/2509.18369)
*Riad Ahmed Anonto,Sardar Md. Saffat Zabin,M. Saifur Rahman*

Main category: cs.CV

TL;DR: 该研究提出了一种计算感知的孟加拉语图像字幕生成管道，通过LaBSE验证数据和合成图像进行训练，并引入三元损失函数（PAL+InfoNCE+OT）来改善低资源语言视觉-语言模型的接地能力和减少错误匹配。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言中，视觉-语言模型（VLM）的接地（grounding）能力面临挑战，表现为模型常对错误物体生成流畅文本。这源于配对数据稀缺、翻译枢轴破坏对齐以及以英语为中心的预训练忽略目标语言语义等问题。

Method: 该方法构建了一个计算感知的孟加拉语字幕生成管道，使用LaBSE验证的英-孟配对数据和11万张双语提示合成图像进行训练。管道包括：一个冻结的MaxViT用于生成稳定的视觉补丁、一个孟加拉语原生的mBART-50解码器，以及一个轻量级桥接模块连接模态。核心创新是三元损失函数：补丁对齐损失（PAL）使用解码器交叉注意力对齐真实和合成补丁描述符；InfoNCE强制全局真实-合成分离；基于Sinkhorn的OT确保平衡的细粒度补丁对应。

Result: PAL+InfoNCE+OT的协同作用显著改善了接地能力，减少了虚假匹配。在Flickr30k-1k上，BLEU-4达到12.29，METEOR达到27.98，BERTScore-F1达到71.20；在MSCOCO-1k上，BLEU-4达到12.00，METEOR达到28.14，BERTScore-F1达到75.40。这些结果优于强大的CE基线，并将真实-合成质心差距缩小了41%。

Conclusion: 该研究通过引入创新的三元损失函数和优化的管道，有效解决了低资源语言中视觉-语言模型的接地挑战，显著提高了孟加拉语图像字幕生成的性能，并减少了模型中的错误关联。

Abstract: Grounding vision--language models in low-resource languages remains
challenging, as they often produce fluent text about the wrong objects. This
stems from scarce paired data, translation pivots that break alignment, and
English-centric pretraining that ignores target-language semantics. We address
this with a compute-aware Bengali captioning pipeline trained on LaBSE-verified
EN--BN pairs and 110k bilingual-prompted synthetic images. A frozen MaxViT
yields stable visual patches, a Bengali-native mBART-50 decodes, and a
lightweight bridge links the modalities. Our core novelty is a tri-loss
objective: Patch-Alignment Loss (PAL) aligns real and synthetic patch
descriptors using decoder cross-attention, InfoNCE enforces global
real--synthetic separation, and Sinkhorn-based OT ensures balanced fine-grained
patch correspondence. This PAL+InfoNCE+OT synergy improves grounding, reduces
spurious matches, and drives strong gains on Flickr30k-1k (BLEU-4 12.29, METEOR
27.98, BERTScore-F1 71.20) and MSCOCO-1k (BLEU-4 12.00, METEOR 28.14,
BERTScore-F1 75.40), outperforming strong CE baselines and narrowing the
real--synthetic centroid gap by 41%.

</details>


### [74] [TinyBEV: Cross Modal Knowledge Distillation for Efficient Multi Task Bird's Eye View Perception and Planning](https://arxiv.org/abs/2509.18372)
*Reeshad Khan,John Gauch*

Main category: cs.CV

TL;DR: TinyBEV是一个紧凑、实时、纯摄像头的鸟瞰图（BEV）框架，它将大型规划导向型教师模型（UniAD）的全栈自动驾驶能力蒸馏到一个参数量为28M的学生模型中，在nuScenes数据集上实现了高性能，同时运行速度快5倍。


<details>
  <summary>Details</summary>
Motivation: 现有的高效纯摄像头基线模型（如VAD、VADv2）不支持完整的自动驾驶堆栈。研究动机在于弥合大型多模态感知-规划模型与资源受限环境下可部署的实时自动驾驶系统之间的差距，证明在资源受限的环境中也能保留全栈驾驶智能。

Method: TinyBEV是一个统一的纯摄像头BEV框架，它将大型规划导向型教师模型（UniAD）的全栈能力（包括3D检测、高清地图分割、运动预测、占用率预测和目标导向规划）蒸馏到一个紧凑的实时学生模型中。该模型采用28M参数的主干网络，比UniAD减少了78%的参数。其模型无关的多阶段蒸馏策略结合了特征级、输出级和自适应区域感知监督，以有效地将高容量的多模态知识转移到轻量级的BEV表示中。

Result: 在nuScenes数据集上，TinyBEV在检测方面达到39.0 mAP，运动预测方面达到1.08 minADE，碰撞率为0.32。同时，它运行速度快5倍（11 FPS），并且仅需要摄像头输入。

Conclusion: 这项研究证明，在资源受限的环境中可以保留全栈驾驶智能，成功弥合了大型多模态感知-规划模型与可部署的实时自动驾驶系统之间的差距。

Abstract: We present TinyBEV, a unified, camera only Bird's Eye View (BEV) framework
that distills the full-stack capabilities of a large planning-oriented teacher
(UniAD [19]) into a compact, real-time student model. Unlike prior efficient
camera only baselines such as VAD[23] and VADv2[7], TinyBEV supports the
complete autonomy stack 3D detection, HD-map segmentation, motion forecasting,
occupancy prediction, and goal-directed planning within a streamlined
28M-parameter backbone, achieving a 78% reduction in parameters over UniAD
[19]. Our model-agnostic, multi-stage distillation strategy combines
feature-level, output-level, and adaptive region-aware supervision to
effectively transfer high-capacity multi-modal knowledge to a lightweight BEV
representation. On nuScenes[4], Tiny-BEV achieves 39.0 mAP for detection, 1.08
minADE for motion forecasting, and a 0.32 collision rate, while running 5x
faster (11 FPS) and requiring only camera input. These results demonstrate that
full-stack driving intelligence can be retained in resource-constrained
settings, bridging the gap between large-scale, multi-modal perception-planning
models and deployment-ready real-time autonomy.

</details>


### [75] [BlurBall: Joint Ball and Motion Blur Estimation for Table Tennis Ball Tracking](https://arxiv.org/abs/2509.18387)
*Thomas Gossard,Filip Radovic,Andreas Ziegler,Andrea Zell*

Main category: cs.CV

TL;DR: 本文提出一种新的标注策略，将快速运动模糊的球标注在模糊条纹中心并加入模糊属性，发布了新的乒乓球检测数据集，并引入了BlurBall模型，通过利用模糊信息显著提高了球的检测性能和轨迹预测可靠性。


<details>
  <summary>Details</summary>
Motivation: 运动模糊降低了快速移动物体的清晰度，对检测系统构成挑战，尤其是在球类运动中，球常表现为条纹而非清晰点。现有标注约定将球标记在模糊前沿，引入不对称性并忽略了与速度相关的有价值的运动线索。

Method: 引入新的标注策略，将球标记在模糊条纹的中心，并明确标注模糊属性。基于此约定，发布了一个新的乒乓球检测数据集。提出BlurBall模型，该模型联合估计球的位置和运动模糊属性，通过在多帧输入上结合Squeeze-and-Excitation等注意力机制。

Result: 新的标注方法持续提升了各种模型的检测性能。BlurBall模型在球检测方面达到了最先进的水平。利用模糊信息不仅提高了检测精度，还使轨迹预测更加可靠。

Conclusion: 通过引入新的模糊球标注策略和BlurBall模型，该研究有效解决了运动模糊对球检测的挑战，显著提升了检测准确性和轨迹预测的可靠性，对实时体育分析具有重要意义。

Abstract: Motion blur reduces the clarity of fast-moving objects, posing challenges for
detection systems, especially in racket sports, where balls often appear as
streaks rather than distinct points. Existing labeling conventions mark the
ball at the leading edge of the blur, introducing asymmetry and ignoring
valuable motion cues correlated with velocity. This paper introduces a new
labeling strategy that places the ball at the center of the blur streak and
explicitly annotates blur attributes. Using this convention, we release a new
table tennis ball detection dataset. We demonstrate that this labeling approach
consistently enhances detection performance across various models. Furthermore,
we introduce BlurBall, a model that jointly estimates ball position and motion
blur attributes. By incorporating attention mechanisms such as
Squeeze-and-Excitation over multi-frame inputs, we achieve state-of-the-art
results in ball detection. Leveraging blur not only improves detection accuracy
but also enables more reliable trajectory prediction, benefiting real-time
sports analytics.

</details>


### [76] [MVP: Motion Vector Propagation for Zero-Shot Video Object Detection](https://arxiv.org/abs/2509.18388)
*Binhua Huang,Ni Wang,Wendong Yao,Soumyabrata Dev*

Main category: cs.CV

TL;DR: 该论文提出了一种无需训练的视频开放词汇检测流水线（MVP），通过在关键帧上运行检测器（OWLv2）并利用压缩域运动向量将检测结果传播到中间帧，从而显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 在视频的每一帧上运行大型开放词汇检测器虽然准确，但计算成本高昂。

Method: 该方法（MVP）是一种无需训练的流水线，仅在固定间隔的关键帧上调用OWLv2检测器。它利用压缩域运动向量（MV）将检测结果传播到中间帧。具体方法包括：使用简单的3x3网格聚合运动向量以提供平移和均匀缩放更新，并辅以区域增长检查和可选的单类别切换。该方法无需标签、无需微调，并对所有开放词汇方法使用相同的提示列表。

Result: 在ILSVRC2015-VID（验证数据集）上，MVP达到了mAP@0.5=0.609和mAP@[0.5:0.95]=0.316。在宽松的交并比（IoU）阈值下，其性能接近逐帧OWLv2-Large（0.2/0.3 IoU时为0.747/0.721，而OWLv2为0.784/0.780）。在相同的关键帧调度下，MVP在mAP@0.5上优于基于跟踪器的传播方法（MOSSE、KCF、CSRT）。与需要标注训练的监督方法YOLOv12x（mAP@0.5为0.631）相比，MVP保持了无标签和开放词汇的优势。

Conclusion: 这些结果表明，压缩域传播是一种实用的方法，可以减少检测器调用次数，同时在视频中保持强大的零样本覆盖能力。

Abstract: Running a large open-vocabulary (Open-vocab) detector on every video frame is
accurate but expensive. We introduce a training-free pipeline that invokes
OWLv2 only on fixed-interval keyframes and propagates detections to
intermediate frames using compressed-domain motion vectors (MV). A simple 3x3
grid aggregation of motion vectors provides translation and uniform-scale
updates, augmented with an area-growth check and an optional single-class
switch. The method requires no labels, no fine-tuning, and uses the same prompt
list for all open-vocabulary methods. On ILSVRC2015-VID (validation dataset),
our approach (MVP) attains mAP@0.5=0.609 and mAP@[0.5:0.95]=0.316. At loose
intersection-over-union (IoU) thresholds it remains close to framewise
OWLv2-Large (0.747/0.721 at 0.2/0.3 versus 0.784/0.780), reflecting that coarse
localization is largely preserved. Under the same keyframe schedule, MVP
outperforms tracker-based propagation (MOSSE, KCF, CSRT) at mAP@0.5. A
supervised reference (YOLOv12x) reaches 0.631 at mAP@0.5 but requires labeled
training, whereas our method remains label-free and open-vocabulary. These
results indicate that compressed-domain propagation is a practical way to
reduce detector invocations while keeping strong zero-shot coverage in videos.
Our code and models are available at https://github.com/microa/MVP.

</details>


### [77] [Improving the color accuracy of lighting estimation models](https://arxiv.org/abs/2509.18390)
*Zitian Zhang,Joshua Urban Davis,Jeanne Phuong Anh Vu,Jiangtao Kuang,Jean-François Lalonde*

Main category: cs.CV

TL;DR: 本文研究了单幅图像高动态范围（HDR）光照估计方法在颜色鲁棒性方面的表现，发现通过预训练的白平衡网络对输入图像进行预处理，可以显著提高现有模型的颜色准确性，且无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 高动态范围（HDR）光照估计对于增强现实（AR）应用中的虚拟对象真实渲染至关重要。然而，现有方法在评估时常将颜色与其他光照属性（如强度、方向）混淆，导致颜色鲁棒性这一关键因素被忽视。作者旨在将颜色作为主要变量进行独立研究。

Method: 本文不引入新的光照估计算法，而是探索简单的自适应技术是否能提高现有模型的颜色准确性。为此，研究人员构建了一个包含多种光照颜色的新型HDR数据集，并系统评估了几种自适应策略，特别是使用预训练的白平衡网络对输入图像进行预处理的方法。

Result: 研究结果表明，使用预训练的白平衡网络对输入图像进行预处理，可以显著提高光照估计方法的颜色鲁棒性，在所有测试场景中均优于其他策略。值得注意的是，这种方法无需重新训练光照估计模型。此外，该技术已成功应用于三种最新的SOTA光照估计方法，验证了其普适性。

Conclusion: 简单的白平衡预处理是一种有效且普适的方法，可以显著提高现有单幅图像HDR光照估计模型的颜色准确性和鲁棒性，这对于实现AR应用的视觉真实感至关重要，且无需对原有模型进行重新训练。

Abstract: Advances in high dynamic range (HDR) lighting estimation from a single image
have opened new possibilities for augmented reality (AR) applications.
Predicting complex lighting environments from a single input image allows for
the realistic rendering and compositing of virtual objects. In this work, we
investigate the color robustness of such methods -- an often overlooked yet
critical factor for achieving visual realism. While most evaluations conflate
color with other lighting attributes (e.g., intensity, direction), we isolate
color as the primary variable of interest. Rather than introducing a new
lighting estimation algorithm, we explore whether simple adaptation techniques
can enhance the color accuracy of existing models. Using a novel HDR dataset
featuring diverse lighting colors, we systematically evaluate several
adaptation strategies. Our results show that preprocessing the input image with
a pre-trained white balance network improves color robustness, outperforming
other strategies across all tested scenarios. Notably, this approach requires
no retraining of the lighting estimation model. We further validate the
generality of this finding by applying the technique to three state-of-the-art
lighting estimation methods from recent literature.

</details>


### [78] [Check Field Detection Agent (CFD-Agent) using Multimodal Large Language and Vision Language Models](https://arxiv.org/abs/2509.18405)
*Sourav Halder,Jinjun Tong,Xinyu Wu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的、无需训练的支票字段检测框架，结合视觉语言模型（VLM）和多模态大语言模型（MLLM），实现零样本检测，并在小数据集上表现出强大的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 支票欺诈是一个持续存在的问题，需要强大的检测机制。核心在于准确识别和定位关键字段（如签名、MICR行、礼节性金额等）。传统方法依赖于大量标注数据，但由于专有性和隐私问题，此类数据稀缺，阻碍了部署。

Method: 该研究引入了一个无需训练的框架，利用视觉语言模型（VLM）和多模态大语言模型（MLLM）的能力。这种方法实现了支票组件的零样本检测，无需预先训练，解决了数据稀缺问题。

Result: 在包含110张支票的手动整理数据集（涵盖多种格式和布局）上进行定量评估，模型展示了强大的性能和泛化能力。此外，该框架还可作为生成高质量标注数据集的引导机制。

Conclusion: 所提出的无需训练的VLM/MLLM框架为支票字段检测提供了一种有效且易于部署的零样本解决方案，显著降低了实际金融环境中的部署门槛，并能辅助生成用于训练专业实时检测模型的数据集。

Abstract: Checks remain a foundational instrument in the financial ecosystem,
facilitating substantial transaction volumes across institutions. However,
their continued use also renders them a persistent target for fraud,
underscoring the importance of robust check fraud detection mechanisms. At the
core of such systems lies the accurate identification and localization of
critical fields, such as the signature, magnetic ink character recognition
(MICR) line, courtesy amount, legal amount, payee, and payer, which are
essential for subsequent verification against reference checks belonging to the
same customer. This field-level detection is traditionally dependent on object
detection models trained on large, diverse, and meticulously labeled datasets,
a resource that is scarce due to proprietary and privacy concerns. In this
paper, we introduce a novel, training-free framework for automated check field
detection, leveraging the power of a vision language model (VLM) in conjunction
with a multimodal large language model (MLLM). Our approach enables zero-shot
detection of check components, significantly lowering the barrier to deployment
in real-world financial settings. Quantitative evaluation of our model on a
hand-curated dataset of 110 checks spanning multiple formats and layouts
demonstrates strong performance and generalization capability. Furthermore,
this framework can serve as a bootstrap mechanism for generating high-quality
labeled datasets, enabling the development of specialized real-time object
detection models tailored to institutional needs.

</details>


### [79] [Losing the Plot: How VLM responses degrade on imperfect charts](https://arxiv.org/abs/2509.18425)
*Philip Wootaek Shin,Jack Sampson,Vijaykrishnan Narayanan,Andres Marquez,Mahantesh Halappanavar*

Main category: cs.CV

TL;DR: 该研究发现视觉语言模型（VLMs）在处理包含失真和遮挡的真实世界图表时性能显著下降，且易产生幻觉并过度自信。为此，论文引入了CHART NOISe数据集，用于评估模型在噪声环境下的图表理解能力，并提出了缓解策略。


<details>
  <summary>Details</summary>
Motivation: 现有图表理解基准通常假设图表清晰且查询基于事实，而现实世界的图表常包含失真和遮挡，需要更深层次的推理。VLMs在此类复杂情境下的表现及其潜在的幻觉问题尚未得到充分评估。

Method: 研究评估了ChatGPT 4o、Claude Sonnet 4和Gemini 2.5 Pro等主流VLM在图表失真或遮挡情况下的表现。随后，引入了CHART NOISe数据集，该数据集结合了图表损坏、遮挡以及受韩国高考英语部分启发的考试风格多项选择题，并创新性地加入了“提示反向不一致性”测试。此外，论文还提出了质量过滤和遮挡检测等基线缓解策略。

Result: 结果显示，在图表损坏或遮挡下，VLMs的性能急剧下降，幻觉（如数值捏造、趋势误解、实体混淆）变得更加频繁。模型在降级设置中仍然过度自信，生成看似合理但无依据的解释。研究还观察到模型在确认与否认同一陈述时存在提示反向不一致性。

Conclusion: 该研究通过对最先进VLMs的基准测试，揭示了它们在图表推理方面的系统性脆弱性；发布了CHART NOISe数据集，这是首个统一损坏、遮挡和反向不一致性的数据集；并提出了基线缓解策略。这些工作共同为提升图表理解的鲁棒性和可靠性建立了严格的测试平台。

Abstract: Vision language models (VLMs) show strong results on chart understanding, yet
existing benchmarks assume clean figures and fact based queries. Real world
charts often contain distortions and demand reasoning beyond simple matching.
We evaluate ChatGPT 4o, Claude Sonnet 4, and Gemini 2.5 Pro, finding sharp
performance drops under corruption or occlusion, with hallucinations such as
value fabrication, trend misinterpretation, and entity confusion becoming more
frequent. Models remain overconfident in degraded settings, generating
plausible but unsupported explanations.
  To address this gap, we introduce CHART NOISe(Chart Hallucinations, Answers,
and Reasoning Testing on Noisy and Occluded Input Selections), a dataset
combining chart corruptions, occlusions, and exam style multiple choice
questions inspired by Korea's CSAT English section. A key innovation is prompt
reverse inconsistency, where models contradict themselves when asked to confirm
versus deny the same statement. Our contributions are threefold: (1)
benchmarking state of the art VLMs, exposing systematic vulnerabilities in
chart reasoning; (2) releasing CHART NOISe, the first dataset unifying
corruption, occlusion, and reverse inconsistency; and (3) proposing baseline
mitigation strategies such as quality filtering and occlusion detection.
Together, these efforts establish a rigorous testbed for advancing robustness
and reliability in chart understanding.

</details>


### [80] [CPT-4DMR: Continuous sPatial-Temporal Representation for 4D-MRI Reconstruction](https://arxiv.org/abs/2509.18427)
*Xinyang Wu,Muheng Li,Xia Li,Orso Pusterla,Sairos Safai,Philippe C. Cattin,Antony J. Lomax,Ye Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于神经网络的四维MRI重建框架，通过将呼吸运动建模为由一维信号引导的连续变形，取代了传统的离散排序方法，显著提高了重建精度和效率，适用于放疗规划和实时自适应治疗。


<details>
  <summary>Details</summary>
Motivation: 传统的四维MRI重建方法（如相位分箱或独立模板扫描）难以捕捉时间变异性、使工作流程复杂化并产生巨大的计算负担。

Method: 引入了一个神经表示框架，将呼吸运动视为由一维替代信号引导的平滑、连续变形。该方法通过两个协同网络融合运动建模和图像重建：空间解剖网络（SAN）编码连续的三维解剖表示，而时间运动网络（TMN）在Transformer衍生的呼吸信号引导下生成时间一致的形变场。该方法无需模板和相位排序。

Result: 在19名志愿者的自由呼吸数据集上进行评估，结果表明该方法能准确捕捉规则和不规则呼吸模式，同时以高解剖保真度保持血管和支气管的连续性。处理效率显著提高，总处理时间从传统方法的约5小时缩短至仅15分钟的训练时间，每个3D体积的推理时间不到一秒。该框架能准确重建任何呼吸状态下的3D图像，并优于传统方法。

Conclusion: 该框架准确重建了3D图像，性能优于传统方法，在四维放射治疗规划和实时自适应治疗中展现出巨大的应用潜力。

Abstract: Four-dimensional MRI (4D-MRI) is an promising technique for capturing
respiratory-induced motion in radiation therapy planning and delivery.
Conventional 4D reconstruction methods, which typically rely on phase binning
or separate template scans, struggle to capture temporal variability,
complicate workflows, and impose heavy computational loads. We introduce a
neural representation framework that considers respiratory motion as a smooth,
continuous deformation steered by a 1D surrogate signal, completely replacing
the conventional discrete sorting approach. The new method fuses motion
modeling with image reconstruction through two synergistic networks: the
Spatial Anatomy Network (SAN) encodes a continuous 3D anatomical
representation, while a Temporal Motion Network (TMN), guided by
Transformer-derived respiratory signals, produces temporally consistent
deformation fields. Evaluation using a free-breathing dataset of 19 volunteers
demonstrates that our template- and phase-free method accurately captures both
regular and irregular respiratory patterns, while preserving vessel and
bronchial continuity with high anatomical fidelity. The proposed method
significantly improves efficiency, reducing the total processing time from
approximately five hours required by conventional discrete sorting methods to
just 15 minutes of training. Furthermore, it enables inference of each 3D
volume in under one second. The framework accurately reconstructs 3D images at
any respiratory state, achieves superior performance compared to conventional
methods, and demonstrates strong potential for application in 4D radiation
therapy planning and real-time adaptive treatment.

</details>


### [81] [An Analysis of Kalman Filter based Object Tracking Methods for Fast-Moving Tiny Objects](https://arxiv.org/abs/2509.18451)
*Prithvi Raj Singh,Raju Gottumukkala,Anthony Maida*

Main category: cs.CV

TL;DR: 本研究评估了五种基于卡尔曼滤波的先进跟踪方法在追踪快速移动微小物体（如壁球）时的性能。结果显示DeepOCSORT误差最低，ByteTrack速度最快，但所有方法都存在显著的跟踪漂移，表明现有技术对这类物体存在局限性，需要更专业的追踪方法。


<details>
  <summary>Details</summary>
Motivation: 由于运动模式不可预测且视觉标记小，精确追踪快速移动的微小物体（如壁球）是计算机视觉中的一个挑战。这对于体育机器人应用尤为重要，但基于卡尔曼滤波的通用跟踪方法在处理快速、不规则弹跳的物体时性能会显著下降。

Method: 研究评估了五种基于卡尔曼滤波的先进跟踪方法：OCSORT、DeepOCSORT、ByteTrack、BoTSORT和StrongSORT。使用了一个包含10,000帧带标注壁球图像（720p-1280p分辨率）的自定义数据集。分析重点关注推理速度和每图像更新频率，并在四种不同场景下进行了实验评估。

Result: DeepOCSORT实现了最低的跟踪误差（平均ADE为31.15像素），而ByteTrack处理速度最快（平均推理时间26.6毫秒）。然而，所有基于卡尔曼滤波的跟踪器都表现出显著的跟踪漂移，空间误差范围为3-11厘米（ADE值为31-114像素），错误率比标准目标跟踪基准高3-4倍。

Conclusion: 当前基于卡尔曼滤波的跟踪方法在处理快速移动、运动模式不可预测的微小物体时存在根本性局限。现有跟踪方法需要大幅改进，突出表明需要针对快速移动微小目标跟踪应用开发专门的方法。

Abstract: Unpredictable movement patterns and small visual mark make precise tracking
of fast-moving tiny objects like a racquetball one of the challenging problems
in computer vision. This challenge is particularly relevant for sport robotics
applications, where lightweight and accurate tracking systems can improve robot
perception and planning capabilities. While Kalman filter-based tracking
methods have shown success in general object tracking scenarios, their
performance degrades substantially when dealing with rapidly moving objects
that exhibit irregular bouncing behavior. In this study, we evaluate the
performance of five state-of-the-art Kalman filter-based tracking
methods-OCSORT, DeepOCSORT, ByteTrack, BoTSORT, and StrongSORT-using a custom
dataset containing 10,000 annotated racquetball frames captured at 720p-1280p
resolution. We focus our analysis on two critical performance factors:
inference speed and update frequency per image, examining how these parameters
affect tracking accuracy and reliability for fast-moving tiny objects. Our
experimental evaluation across four distinct scenarios reveals that DeepOCSORT
achieves the lowest tracking error with an average ADE of 31.15 pixels compared
to ByteTrack's 114.3 pixels, while ByteTrack demonstrates the fastest
processing at 26.6ms average inference time versus DeepOCSORT's 26.8ms.
However, our results show that all Kalman filter-based trackers exhibit
significant tracking drift with spatial errors ranging from 3-11cm (ADE values:
31-114 pixels), indicating fundamental limitations in handling the
unpredictable motion patterns of fast-moving tiny objects like racquetballs.
Our analysis demonstrates that current tracking approaches require substantial
improvements, with error rates 3-4x higher than standard object tracking
benchmarks, highlighting the need for specialized methodologies for fast-moving
tiny object tracking applications.

</details>


### [82] [MoCrop: Training Free Motion Guided Cropping for Efficient Video Action Recognition](https://arxiv.org/abs/2509.18473)
*Binhua Huang,Wendong Yao,Shaowu Chen,Guoxin Wang,Qingyuan Wang,Soumyabrata Dev*

Main category: cs.CV

TL;DR: MoCrop是一种运动感知的自适应裁剪模块，利用H.264运动向量在压缩域中高效进行视频动作识别，无需训练，可即插即用，显著提高准确性或降低计算量。


<details>
  <summary>Details</summary>
Motivation: 在压缩域中进行高效的视频动作识别，通过关注运动密集区域来减少计算开销并提高识别准确性。

Method: MoCrop利用H.264视频中可用的运动向量来定位运动密集区域，生成一个适用于推理时所有I帧的片段级裁剪。该模块无需训练，不增加参数，可插入到各种骨干网络中。其轻量级管道包括去噪与合并（DM）、蒙特卡洛采样（MCS）以及通过运动密度子矩阵搜索实现的自适应裁剪（AC）。

Result: 在UCF101数据集上，MoCrop使用ResNet-50时，在相同FLOPs下Top-1准确率提高3.5%，或在FLOPs减少26.5%的情况下Top-1准确率提高2.4%。应用于CoViAR数据集时，在原始成本下达到89.2%的Top-1准确率，或在计算量从11.6 GFLOPs减少到8.5 GFLOPs的情况下达到88.5%的Top-1准确率。在MobileNet-V3、EfficientNet-B1和Swin-B上均表现出一致的提升。

Conclusion: MoCrop是一个通用且高效的模块，适用于压缩域中的实时视频动作识别部署，能够在可忽略的开销下提高准确性或减少计算量，具有很强的实用性。

Abstract: We introduce MoCrop, a motion-aware adaptive cropping module for efficient
video action recognition in the compressed domain. MoCrop uses motion vectors
that are available in H.264 video to locate motion-dense regions and produces a
single clip-level crop that is applied to all I-frames at inference. The module
is training free, adds no parameters, and can be plugged into diverse
backbones. A lightweight pipeline that includes denoising & merge (DM), Monte
Carlo sampling (MCS), and adaptive cropping (AC) via a motion-density submatrix
search yields robust crops with negligible overhead. On UCF101, MoCrop improves
accuracy or reduces compute. With ResNet-50, it delivers +3.5% Top-1 accuracy
at equal FLOPs (attention setting), or +2.4% Top-1 accuracy with 26.5% fewer
FLOPs (efficiency setting). Applied to CoViAR, it reaches 89.2% Top-1 accuracy
at the original cost and 88.5% Top-1 accuracy while reducing compute from 11.6
to 8.5 GFLOPs. Consistent gains on MobileNet-V3, EfficientNet-B1, and Swin-B
indicate strong generality and make MoCrop practical for real-time deployment
in the compressed domain. Our code and models are available at
https://github.com/microa/MoCrop.

</details>


### [83] [Codebook-Based Adaptive Feature Compression With Semantic Enhancement for Edge-Cloud Systems](https://arxiv.org/abs/2509.18481)
*Xinyu Wang,Zikun Zhou,Yingjian Li,Xin An,Hongpeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为CAFC-SE的码本自适应特征压缩框架，用于在低比特率下为机器编码图像，同时保持强大的分析性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像编码方法（无论是在重建图像上分析还是压缩中间特征）在低比特率条件下表现不佳，因为它们保留了太多冗余细节或学习了过于集中的符号分布，这阻碍了有效的边缘-云系统。

Method: 本文提出了CAFC-SE（Codebook-based Adaptive Feature Compression framework with Semantic Enhancement）。它在边缘端通过矢量量化（VQ）将连续视觉特征映射到离散索引，并使用码本进行选择性传输到云端。VQ操作将特征向量投影到最近的视觉基元上，从而在低比特率条件下保留更多信息丰富的视觉模式。

Result: 广泛的实验证明，CAFC-SE在速率和准确性方面均优于现有方法。它在低比特率条件下受到的影响较小。

Conclusion: CAFC-SE通过码本和矢量量化机制，成功解决了低比特率下图像编码的挑战，为机器分析提供了更优的性能，使其在边缘-云系统中更具效率和鲁棒性。

Abstract: Coding images for machines with minimal bitrate and strong analysis
performance is key to effective edge-cloud systems. Several approaches deploy
an image codec and perform analysis on the reconstructed image. Other methods
compress intermediate features using entropy models and subsequently perform
analysis on the decoded features. Nevertheless, these methods both perform
poorly under low-bitrate conditions, as they retain many redundant details or
learn over-concentrated symbol distributions. In this paper, we propose a
Codebook-based Adaptive Feature Compression framework with Semantic
Enhancement, named CAFC-SE. It maps continuous visual features to discrete
indices with a codebook at the edge via Vector Quantization (VQ) and
selectively transmits them to the cloud. The VQ operation that projects feature
vectors onto the nearest visual primitives enables us to preserve more
informative visual patterns under low-bitrate conditions. Hence, CAFC-SE is
less vulnerable to low-bitrate conditions. Extensive experiments demonstrate
the superiority of our method in terms of rate and accuracy.

</details>


### [84] [MK-UNet: Multi-kernel Lightweight CNN for Medical Image Segmentation](https://arxiv.org/abs/2509.18493)
*Md Mostafijur Rahman,Radu Marculescu*

Main category: cs.CV

TL;DR: 本文提出了MK-UNet，一种超轻量级、多核U型卷积神经网络，专为医学图像分割设计，在显著降低计算资源的同时实现了更高的分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法可能计算成本高昂，难以在资源受限的环境（如即时医疗设备）中实时部署。因此，需要一种既轻量又高效的解决方案。

Method: MK-UNet的核心是多核深度可分离卷积块（MKDC），它通过多个核处理图像以捕获复杂的多分辨率空间关系。此外，MK-UNet还通过通道、空间和分组门控注意力机制来强调图像的显著特征。

Result: MK-UNet拥有0.316M参数和0.314G FLOPs的极低计算开销。在六个二元医学图像基准测试中，它在DICE分数上超越了包括TransUNet、UNeXt、MedT等在内的最先进方法，同时参数量和FLOPs分别减少了数百倍（例如，TransUNet的参数减少了约333倍，FLOPs减少了约123倍）。

Conclusion: MK-UNet以其卓越的性能和极低的计算成本，成为资源受限环境下（如即时医疗设备）实时、高保真医学诊断的无与伦比的解决方案。

Abstract: In this paper, we introduce MK-UNet, a paradigm shift towards
ultra-lightweight, multi-kernel U-shaped CNNs tailored for medical image
segmentation. Central to MK-UNet is the multi-kernel depth-wise convolution
block (MKDC) we design to adeptly process images through multiple kernels,
while capturing complex multi-resolution spatial relationships. MK-UNet also
emphasizes the images salient features through sophisticated attention
mechanisms, including channel, spatial, and grouped gated attention. Our
MK-UNet network, with a modest computational footprint of only 0.316M
parameters and 0.314G FLOPs, represents not only a remarkably lightweight, but
also significantly improved segmentation solution that provides higher accuracy
over state-of-the-art (SOTA) methods across six binary medical imaging
benchmarks. Specifically, MK-UNet outperforms TransUNet in DICE score with
nearly 333$\times$ and 123$\times$ fewer parameters and FLOPs, respectively.
Similarly, when compared against UNeXt, MK-UNet exhibits superior segmentation
performance, improving the DICE score up to 6.7% margins while operating with
4.7$\times$ fewer #Params. Our MK-UNet also outperforms other recent
lightweight networks, such as MedT, CMUNeXt, EGE-UNet, and Rolling-UNet, with
much lower computational resources. This leap in performance, coupled with
drastic computational gains, positions MK-UNet as an unparalleled solution for
real-time, high-fidelity medical diagnostics in resource-limited settings, such
as point-of-care devices. Our implementation is available at
https://github.com/SLDGroup/MK-UNet.

</details>


### [85] [BridgeSplat: Bidirectionally Coupled CT and Non-Rigid Gaussian Splatting for Deformable Intraoperative Surgical Navigation](https://arxiv.org/abs/2509.18501)
*Maximilian Fehrentz,Alexander Winkler,Thomas Heiliger,Nazim Haouchine,Christian Heiliger,Nassir Navab*

Main category: cs.CV

TL;DR: BridgeSplat是一种新颖的可变形手术导航方法，它将术中3D重建与术前CT数据结合，通过将3D高斯粒子绑定到CT网格并进行联合优化，实现从手术视频到体积患者数据的桥接，并能将变形传播回CT。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是弥合手术视频与体积患者数据之间的鸿沟，以实现可变形的手术导航。

Method: 该方法名为BridgeSplat，将3D高斯粒子绑定到CT网格上，通过光度监督联合优化高斯参数和网格变形。每个高斯粒子相对于其父网格三角形进行参数化，以确保高斯粒子与网格对齐，并使变形能够传播回CT以更新数据。

Result: BridgeSplat在内脏猪手术和模拟人体肝脏的合成数据上都展示了其有效性，表明它能在单目RGB数据上对术前CT产生合理的变形。

Conclusion: BridgeSplat成功地通过结合术中重建和术前CT数据，提供了一种有效的可变形手术导航解决方案，能够基于手术视频的变形更新术前CT数据。

Abstract: We introduce BridgeSplat, a novel approach for deformable surgical navigation
that couples intraoperative 3D reconstruction with preoperative CT data to
bridge the gap between surgical video and volumetric patient data. Our method
rigs 3D Gaussians to a CT mesh, enabling joint optimization of Gaussian
parameters and mesh deformation through photometric supervision. By
parametrizing each Gaussian relative to its parent mesh triangle, we enforce
alignment between Gaussians and mesh and obtain deformations that can be
propagated back to update the CT. We demonstrate BridgeSplat's effectiveness on
visceral pig surgeries and synthetic data of a human liver under simulation,
showing sensible deformations of the preoperative CT on monocular RGB data.
Code, data, and additional resources can be found at
https://maxfehrentz.github.io/ct-informed-splatting/ .

</details>


### [86] [Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment](https://arxiv.org/abs/2509.18502)
*Wenjie Liu,Hongmin Liu,Lixin Zhang,Bin Fan*

Main category: cs.CV

TL;DR: 本文提出了一种名为Diffusion-Guided Label Enrichment (DGLE)的新型框架，用于遥感图像语义分割的无源域自适应（SFDA）。该框架通过扩散模型将少量高质量的初始伪标签传播并丰富为完整的、高质量的伪标签集，从而解决了传统自训练方法中伪标签噪声大、难以直接优化完整集的问题。


<details>
  <summary>Details</summary>
Motivation: 遥感图像语义分割的无监督域自适应（UDA）研究已广泛进行，但在实际无源域数据可访问的SFDA场景中，研究仍有限。现有SFDA自训练方法通常需要优化包含大量噪声的完整伪标签集，这限制了优化效果和模型性能。

Method: 提出Diffusion-Guided Label Enrichment (DGLE)框架。首先，通过基于置信度过滤和超分辨率增强的伪标签融合方法，利用细节和上下文信息的交叉验证，获取少量高质量的初始伪标签（种子）。然后，利用扩散模型强大的去噪和复杂分布建模能力，将这些不完整、不规则分布的种子伪标签传播并生成完整且高质量的伪标签。

Result: 该方法有效避免了直接优化完整伪标签集的困难，显著提高了伪标签的质量，从而提升了模型在目标域的性能。

Conclusion: DGLE框架通过从少量高质量伪标签开始，并利用扩散模型进行传播和丰富，成功解决了SFDA中伪标签噪声大、难以优化的问题，显著提升了遥感图像语义分割在无源域自适应场景下的性能。

Abstract: Research on unsupervised domain adaptation (UDA) for semantic segmentation of
remote sensing images has been extensively conducted. However, research on how
to achieve domain adaptation in practical scenarios where source domain data is
inaccessible namely, source-free domain adaptation (SFDA) remains limited.
Self-training has been widely used in SFDA, which requires obtaining as many
high-quality pseudo-labels as possible to train models on target domain data.
Most existing methods optimize the entire pseudo-label set to obtain more
supervisory information. However, as pseudo-label sets often contain
substantial noise, simultaneously optimizing all labels is challenging. This
limitation undermines the effectiveness of optimization approaches and thus
restricts the performance of self-training. To address this, we propose a novel
pseudo-label optimization framework called Diffusion-Guided Label Enrichment
(DGLE), which starts from a few easily obtained high-quality pseudo-labels and
propagates them to a complete set of pseudo-labels while ensuring the quality
of newly generated labels. Firstly, a pseudo-label fusion method based on
confidence filtering and super-resolution enhancement is proposed, which
utilizes cross-validation of details and contextual information to obtain a
small number of high-quality pseudo-labels as initial seeds. Then, we leverage
the diffusion model to propagate incomplete seed pseudo-labels with irregular
distributions due to its strong denoising capability for randomly distributed
noise and powerful modeling capacity for complex distributions, thereby
generating complete and high-quality pseudo-labels. This method effectively
avoids the difficulty of directly optimizing the complete set of pseudo-labels,
significantly improves the quality of pseudo-labels, and thus enhances the
model's performance in the target domain.

</details>


### [87] [Hyperbolic Coarse-to-Fine Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2509.18504)
*Jiaxin Dai,Xiang Xiang*

Main category: cs.CV

TL;DR: 本研究提出在双曲空间中进行粗到细少样本类增量学习（C2FSCIL），通过引入庞加莱球模型、双曲对比损失、双曲全连接层及最大熵分布增强，有效提升粗细粒度分类准确性。


<details>
  <summary>Details</summary>
Motivation: 传统欧几里得空间在表示层次数据方面不如双曲空间。为了更好地解释“粗到细”范式，并利用双曲空间对层次数据的优越表示能力，本研究旨在将特征提取器嵌入双曲空间以解决C2FSCIL任务。

Method: 该方法遵循Knowe方法，对比学习粗类别标签，并标准化和冻结已学习细类别的分类器权重。具体地，它将特征提取器嵌入到庞加莱球模型中，使特征向量位于双曲空间。同时，引入双曲对比损失和双曲全连接层进行优化和分类。为应对少样本条件下的过拟合，还在双曲空间中实现了最大熵分布来估计细类别特征向量的概率分布，从而生成增强特征。

Result: 在C2FSCIL基准测试上的实验表明，该方法有效提高了粗类别和细类别的分类准确性。

Conclusion: 通过将特征提取器、损失函数和分类层置于双曲空间，并结合双曲空间中的数据增强策略，本研究提出的方法显著提升了C2FSCIL任务中粗粒度和细粒度分类的性能。

Abstract: In the field of machine learning, hyperbolic space demonstrates superior
representation capabilities for hierarchical data compared to conventional
Euclidean space. This work focuses on the Coarse-To-Fine Few-Shot
Class-Incremental Learning (C2FSCIL) task. Our study follows the Knowe
approach, which contrastively learns coarse class labels and subsequently
normalizes and freezes the classifier weights of learned fine classes in the
embedding space. To better interpret the "coarse-to-fine" paradigm, we propose
embedding the feature extractor into hyperbolic space. Specifically, we employ
the Poincar\'e ball model of hyperbolic space, enabling the feature extractor
to transform input images into feature vectors within the Poincar\'e ball
instead of Euclidean space. We further introduce hyperbolic contrastive loss
and hyperbolic fully-connected layers to facilitate model optimization and
classification in hyperbolic space. Additionally, to enhance performance under
few-shot conditions, we implement maximum entropy distribution in hyperbolic
space to estimate the probability distribution of fine-class feature vectors.
This allows generation of augmented features from the distribution to mitigate
overfitting during training with limited samples. Experiments on C2FSCIL
benchmarks show that our method effectively improves both coarse and fine class
accuracies.

</details>


### [88] [GeoRemover: Removing Objects and Their Causal Visual Artifacts](https://arxiv.org/abs/2509.18538)
*Zixin Zhu,Haoxiang Li,Xuelu Feng,He Wu,Chunming Qiao,Junsong Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种几何感知的两阶段框架，用于智能图像编辑中的物体移除，旨在同时消除目标物体及其因果视觉伪影（如阴影和反射），解决了现有方法无法有效处理未显式遮罩的伪影或过度擦除的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像外观的物体移除方法，要么严格遵循遮罩对齐训练，无法移除未显式遮罩的因果视觉伪影（如阴影和反射）；要么采用宽松的遮罩对齐策略，导致可控性不足，可能意外擦除其他物体。这些局限性源于忽略了物体几何存在与其视觉效果之间的因果关系。

Method: 本文提出了一个几何感知的两阶段框架：1. **几何移除**：使用严格的遮罩对齐监督，直接从几何（例如深度）中移除物体，实现具有强几何约束的结构感知编辑。引入了基于正负样本对的偏好驱动目标，鼓励模型移除物体及其因果视觉伪影，同时避免插入新的结构。2. **外观渲染**：基于更新后的几何渲染逼真的RGB图像，其中因果视觉效果被隐式地视为修改后3D几何的结果。

Result: 在两个流行基准测试中，我们的方法在移除物体及其相关伪影方面达到了最先进的性能。

Conclusion: 通过解耦物体移除为几何移除和外观渲染，并利用物体几何与视觉效果之间的因果关系，本文提出的几何感知两阶段框架有效解决了现有方法的局限性，实现了更智能、更彻底的物体移除，包括其伴随的因果视觉伪影。

Abstract: Towards intelligent image editing, object removal should eliminate both the
target object and its causal visual artifacts, such as shadows and reflections.
However, existing image appearance-based methods either follow strictly
mask-aligned training and fail to remove these causal effects which are not
explicitly masked, or adopt loosely mask-aligned strategies that lack
controllability and may unintentionally over-erase other objects. We identify
that these limitations stem from ignoring the causal relationship between an
object's geometry presence and its visual effects. To address this limitation,
we propose a geometry-aware two-stage framework that decouples object removal
into (1) geometry removal and (2) appearance rendering. In the first stage, we
remove the object directly from the geometry (e.g., depth) using strictly
mask-aligned supervision, enabling structure-aware editing with strong
geometric constraints. In the second stage, we render a photorealistic RGB
image conditioned on the updated geometry, where causal visual effects are
considered implicitly as a result of the modified 3D geometry. To guide
learning in the geometry removal stage, we introduce a preference-driven
objective based on positive and negative sample pairs, encouraging the model to
remove objects as well as their causal visual artifacts while avoiding new
structural insertions. Extensive experiments demonstrate that our method
achieves state-of-the-art performance in removing both objects and their
associated artifacts on two popular benchmarks. The code is available at
https://github.com/buxiangzhiren/GeoRemover.

</details>


### [89] [SEGA: A Transferable Signed Ensemble Gaussian Black-Box Attack against No-Reference Image Quality Assessment Models](https://arxiv.org/abs/2509.18546)
*Yujia Liu,Dingquan Li,Tiejun Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为SEGA的可迁移符号集成高斯黑盒攻击方法，首次解决了对NR-IQA模型进行黑盒攻击时迁移性差的问题，并在CLIVE数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有针对NR-IQA模型的对抗性攻击（尤其是在白盒设置下）在更现实的黑盒场景中对未知目标模型的迁移性较差。研究人员希望解决这一低迁移性挑战，以揭示模型漏洞并指导鲁棒系统设计。

Method: 该研究提出了一种可迁移的符号集成高斯黑盒攻击（SEGA）。其核心思想是通过对源模型应用高斯平滑并集成其平滑后的梯度来近似目标模型的梯度。为了确保对抗性扰动的不可感知性，SEGA还使用专门设计的扰动过滤掩码来去除不适当的扰动。

Result: 在CLIVE数据集上的实验结果表明，SEGA具有卓越的迁移性，验证了其在实现针对NR-IQA模型的成功基于迁移的黑盒攻击方面的有效性。

Conclusion: SEGA方法有效地解决了对NR-IQA模型进行黑盒攻击时低迁移性的挑战，为揭示模型漏洞和设计更鲁棒的系统提供了有价值的见解。

Abstract: No-Reference Image Quality Assessment (NR-IQA) models play an important role
in various real-world applications. Recently, adversarial attacks against
NR-IQA models have attracted increasing attention, as they provide valuable
insights for revealing model vulnerabilities and guiding robust system design.
Some effective attacks have been proposed against NR-IQA models in white-box
settings, where the attacker has full access to the target model. However,
these attacks often suffer from poor transferability to unknown target models
in more realistic black-box scenarios, where the target model is inaccessible.
This work makes the first attempt to address the challenge of low
transferability in attacking NR-IQA models by proposing a transferable Signed
Ensemble Gaussian black-box Attack (SEGA). The main idea is to approximate the
gradient of the target model by applying Gaussian smoothing to source models
and ensembling their smoothed gradients. To ensure the imperceptibility of
adversarial perturbations, SEGA further removes inappropriate perturbations
using a specially designed perturbation filter mask. Experimental results on
the CLIVE dataset demonstrate the superior transferability of SEGA, validating
its effectiveness in enabling successful transfer-based black-box attacks
against NR-IQA models.

</details>


### [90] [HadaSmileNet: Hadamard fusion of handcrafted and deep-learning features for enhancing facial emotion recognition of genuine smiles](https://arxiv.org/abs/2509.18550)
*Mohammad Junayed Hasan,Nabeel Mohammed,Shafin Rahman,Philipp Koehn*

Main category: cs.CV

TL;DR: HadaSmileNet通过Hadamard乘法融合Transformer特征和D-Markers，实现了高效且最先进的真假笑容情感识别，解决了现有方法计算效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 区分真假情感是模式识别的挑战，对社会科学、医疗保健和人机交互中的数据挖掘应用具有重要意义。尽管现有的多任务学习框架结合深度学习和D-Marker特征在笑容情感识别方面有前景，但它们因辅助任务监督和复杂的损失平衡而导致计算效率低下。

Method: 本文提出了HadaSmileNet，一个新颖的特征融合框架。它通过无参数的乘法交互（特别是Hadamard乘法融合）直接整合基于Transformer的表示和生理学基础的D-Marker特征。该研究系统评估了15种融合策略。

Result: Hadamard乘法融合实现了最佳性能，通过直接特征交互保持了计算效率。该方法在四个基准数据集上取得了深度学习方法的新SOTA结果：UvA-NEMO (88.7%, +0.8)、MMI (99.7%)、SPOS (98.5%, +0.7) 和 BBC (100%, +5.0)。与多任务替代方案相比，参数减少了26%，训练过程更简化。特征可视化显示通过直接领域知识整合增强了判别力。

Conclusion: HadaSmileNet框架的效率和有效性使其特别适用于需要实时情感计算能力的多媒体数据挖掘应用中的实际部署。

Abstract: The distinction between genuine and posed emotions represents a fundamental
pattern recognition challenge with significant implications for data mining
applications in social sciences, healthcare, and human-computer interaction.
While recent multi-task learning frameworks have shown promise in combining
deep learning architectures with handcrafted D-Marker features for smile facial
emotion recognition, these approaches exhibit computational inefficiencies due
to auxiliary task supervision and complex loss balancing requirements. This
paper introduces HadaSmileNet, a novel feature fusion framework that directly
integrates transformer-based representations with physiologically grounded
D-Markers through parameter-free multiplicative interactions. Through
systematic evaluation of 15 fusion strategies, we demonstrate that Hadamard
multiplicative fusion achieves optimal performance by enabling direct feature
interactions while maintaining computational efficiency. The proposed approach
establishes new state-of-the-art results for deep learning methods across four
benchmark datasets: UvA-NEMO (88.7 percent, +0.8), MMI (99.7 percent), SPOS
(98.5 percent, +0.7), and BBC (100 percent, +5.0). Comprehensive computational
analysis reveals 26 percent parameter reduction and simplified training
compared to multi-task alternatives, while feature visualization demonstrates
enhanced discriminative power through direct domain knowledge integration. The
framework's efficiency and effectiveness make it particularly suitable for
practical deployment in multimedia data mining applications that require
real-time affective computing capabilities.

</details>


### [91] [Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event Reasoning and Chain-of-Thought](https://arxiv.org/abs/2509.18571)
*Yuhan Wang,Cheng Liu,Zihan Zhao,Weichao Wu*

Main category: cs.CV

TL;DR: Live-E2T是一个新颖的框架，通过结构化语义表示、高效事件去重和基于CoT的LLM推理，实现了实时视频威胁监控的准确性、实时性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频威胁监控方法（无论是监督学习还是生成模型）难以同时满足实时性能和决策可解释性的高要求。

Method: Live-E2T框架通过三个协同机制实现目标：1) 将视频帧解构为结构化的“人-物-交互-地点”语义元组，创建紧凑且语义集中的表示。2) 提出高效的在线事件去重和更新机制，过滤时空冗余以确保实时响应。3) 使用思维链（Chain-of-Thought）策略微调大型语言模型（LLM），使其能够对事件序列进行透明且逻辑的推理，生成连贯的威胁评估报告。

Result: 在XD-Violence和UCF-Crime等基准数据集上的广泛实验表明，Live-E2T在威胁检测准确性、实时效率和关键的可解释性方面显著优于现有最先进的方法。

Conclusion: Live-E2T成功地统一了实时性能和决策可解释性这两个目标，为视频威胁监控提供了一个高效且透明的解决方案。

Abstract: Real-time threat monitoring identifies threatening behaviors in video streams
and provides reasoning and assessment of threat events through explanatory
text. However, prevailing methodologies, whether based on supervised learning
or generative models, struggle to concurrently satisfy the demanding
requirements of real-time performance and decision explainability. To bridge
this gap, we introduce Live-E2T, a novel framework that unifies these two
objectives through three synergistic mechanisms. First, we deconstruct video
frames into structured Human-Object-Interaction-Place semantic tuples. This
approach creates a compact, semantically focused representation, circumventing
the information degradation common in conventional feature compression. Second,
an efficient online event deduplication and updating mechanism is proposed to
filter spatio-temporal redundancies, ensuring the system's real time
responsiveness. Finally, we fine-tune a Large Language Model using a
Chain-of-Thought strategy, endow it with the capability for transparent and
logical reasoning over event sequences to produce coherent threat assessment
reports. Extensive experiments on benchmark datasets, including XD-Violence and
UCF-Crime, demonstrate that Live-E2T significantly outperforms state-of-the-art
methods in terms of threat detection accuracy, real-time efficiency, and the
crucial dimension of explainability.

</details>


### [92] [The Photographer Eye: Teaching Multimodal Large Language Models to See and Critique like Photographers](https://arxiv.org/abs/2509.18582)
*Daiqing Qi,Handong Zhao,Jing Shi,Simon Jenni,Yifei Fan,Franck Dernoncourt,Scott Cohen,Sheng Li*

Main category: cs.CV

TL;DR: 本文旨在通过引入一个专业数据集PhotoCritique、一个多视角融合模型PhotoEye和一个综合基准PhotoBench，显著提升多模态大语言模型（MLLMs）的视觉美学理解能力，以弥补其在区分图像事实元素与美学组件方面的不足。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在理解视觉美学方面存在显著挑战，它们常常将图像中的事实元素（如“天空”）与美学组件（如“蓝色”这一纯色块）混淆。现有工作仅限于一般和基本的审美常识，缺乏摄影技术、图像处理等专业知识，无法提供详细的审美分析，这促使研究者寻求根本性地增强MLLMs的美学理解能力。

Method: 研究者首先引入了一个名为PhotoCritique的新型数据集，该数据集来源于专业摄影师和爱好者的大量讨论，具有大规模、专业性和多样性。其次，为了更好地从PhotoCritique中学习视觉美学，提出了一种名为PhotoEye的新型模型，该模型具有语言引导的多视角视觉融合机制，以从多个角度理解图像美学。最后，提出了一个名为PhotoBench的综合性专业美学视觉理解基准。

Result: 在现有基准和新提出的PhotoBench上，本文提出的模型（PhotoEye）相较于现有模型展现出明显的优势。

Conclusion: 通过引入PhotoCritique数据集、PhotoEye模型和PhotoBench基准，本研究为多模态大语言模型在美学视觉理解方面提供了根本性的增强，使其能够更好地区分图像的事实元素与美学组件，并进行专业的审美分析。

Abstract: While editing directly from life, photographers have found it too difficult
to see simultaneously both the blue and the sky. Photographer and curator,
Szarkowski insightfully revealed one of the notable gaps between general and
aesthetic visual understanding: while the former focuses on identifying the
factual element in an image (sky), the latter transcends such object
identification, viewing it instead as an aesthetic component--a pure color
block (blue). Such fundamental distinctions between general (detection,
localization, etc.) and aesthetic (color, lighting, composition, etc.) visual
understanding present a significant challenge for Multimodal Large Language
Models (MLLMs). Although some recent works have made initial explorations, they
are often limited to general and basic aesthetic commonsense. As a result, they
frequently fall short in real-world scenarios (Fig. 1), which require extensive
expertise--including photographic techniques, photo pre/post-processing
knowledge, and more, to provide a detailed analysis and description. To
fundamentally enhance the aesthetics understanding of MLLMs, we first introduce
a novel dataset, PhotoCritique, derived from extensive discussions among
professional photographers and enthusiasts, and characterized by the large
scale, expertise, and diversity. Then, to better learn visual aesthetics from
PhotoCritique, we furthur propose a novel model, PhotoEye, featuring a
languageguided multi-view vision fusion mechanism to understand image
aesthetics from multiple perspectives. Finally, we present a novel benchmark,
PhotoBench, a comprehensive and professional benchmark for aesthetic visual
understanding. On existing benchmarks and PhotoBench, our model demonstrates
clear advantages over existing models.

</details>


### [93] [Enhancing Video Object Segmentation in TrackRAD Using XMem Memory Network](https://arxiv.org/abs/2509.18591)
*Pengchao Deng,Shengqi Chen*

Main category: cs.CV

TL;DR: 本文提出一个基于XMem模型的肿瘤分割框架，用于实时MRI引导的放射治疗，旨在解决TrackRAD2025挑战，并在初步印象中展现了合理的分割性能和实时性。


<details>
  <summary>Details</summary>
Motivation: MRI引导的放射治疗中，实时、精确的肿瘤跟踪对于提高癌症治疗的准确性和安全性至关重要。本研究旨在为TrackRAD2025挑战开发一个先进的肿瘤分割框架。

Method: 该方法利用了XMem模型，一种增强记忆的架构，通过有效整合记忆机制来分割长序列电影式MRI图像中的肿瘤，实现实时肿瘤运动跟踪。

Result: 尽管详细的实验记录已丢失，无法提供精确的定量结果，但根据开发过程中的初步印象，该基于XMem的框架展示了合理的肿瘤分割性能，并满足了临床实时性要求。

Conclusion: 本工作有助于提高MRI引导放射治疗中肿瘤跟踪的精度，这对提升癌症治疗的准确性和安全性至关重要。

Abstract: This paper presents an advanced tumor segmentation framework for real-time
MRI-guided radiotherapy, designed for the TrackRAD2025 challenge. Our method
leverages the XMem model, a memory-augmented architecture, to segment tumors
across long cine-MRI sequences. The proposed system efficiently integrates
memory mechanisms to track tumor motion in real-time, achieving high
segmentation accuracy even under challenging conditions with limited annotated
data. Unfortunately, the detailed experimental records have been lost,
preventing us from reporting precise quantitative results at this stage.
Nevertheless, From our preliminary impressions during development, the
XMem-based framework demonstrated reasonable segmentation performance and
satisfied the clinical real-time requirement. Our work contributes to improving
the precision of tumor tracking during MRI-guided radiotherapy, which is
crucial for enhancing the accuracy and safety of cancer treatments.

</details>


### [94] [SSCM: A Spatial-Semantic Consistent Model for Multi-Contrast MRI Super-Resolution](https://arxiv.org/abs/2509.18593)
*Xiaoman Wu,Lubin Gan,Siying Wu,Jing Zhang,Yunwei Ou,Xiaoyan Sun*

Main category: cs.CV

TL;DR: 本文提出了一种名为SSCM的多对比度磁共振成像超分辨率（MC-MRI SR）模型，通过动态空间配准、语义感知聚合和空频融合，在保持空间语义一致性的同时，实现了卓越的图像重建性能。


<details>
  <summary>Details</summary>
Motivation: MC-MRI SR旨在利用高分辨率（HR）参考图像增强低分辨率（LR）对比度，以缩短采集时间并提高成像效率。然而，主要挑战在于如何在目标和参考图像之间存在结构差异和运动的情况下，保持空间语义一致性，确保解剖结构良好对齐和连贯。传统方法在空间语义一致性建模和频率域信息利用方面不足，导致精细对齐不佳和高频细节恢复不足。

Method: 本文提出空间语义一致性模型（SSCM），该模型整合了三个关键模块：1) 动态空间形变模块（Dynamic Spatial Warping Module），用于实现对比度间的空间对齐；2) 语义感知令牌聚合模块（Semantic-Aware Token Aggregation Block），用于实现长距离语义一致性；3) 空频融合模块（Spatial-Frequency Fusion Block），用于恢复精细结构并利用频率域信息。

Result: 在公共和私有数据集上的实验表明，SSCM以更少的参数实现了最先进的性能，同时确保了空间和语义一致的重建效果。

Conclusion: SSCM通过有效整合动态空间对齐、长距离语义一致性和空频融合，成功解决了MC-MRI SR中保持空间语义一致性和恢复高频细节的挑战，达到了优越且一致的重建效果。

Abstract: Multi-contrast Magnetic Resonance Imaging super-resolution (MC-MRI SR) aims
to enhance low-resolution (LR) contrasts leveraging high-resolution (HR)
references, shortening acquisition time and improving imaging efficiency while
preserving anatomical details. The main challenge lies in maintaining
spatial-semantic consistency, ensuring anatomical structures remain
well-aligned and coherent despite structural discrepancies and motion between
the target and reference images. Conventional methods insufficiently model
spatial-semantic consistency and underuse frequency-domain information, which
leads to poor fine-grained alignment and inadequate recovery of high-frequency
details. In this paper, we propose the Spatial-Semantic Consistent Model
(SSCM), which integrates a Dynamic Spatial Warping Module for inter-contrast
spatial alignment, a Semantic-Aware Token Aggregation Block for long-range
semantic consistency, and a Spatial-Frequency Fusion Block for fine structure
restoration. Experiments on public and private datasets show that SSCM achieves
state-of-the-art performance with fewer parameters while ensuring spatially and
semantically consistent reconstructions.

</details>


### [95] [OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation](https://arxiv.org/abs/2509.18600)
*Zhuoxiao Chen,Hongyang Yu,Ying Xu,Yadan Luo,Long Duong,Yuan-Fang Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为OraPO（Oracle-educated GRPO）的新型放射学报告生成（RRG）框架，结合FactScore-based奖励（FactS），实现了在有限资源下高效训练，并在CheXpert Plus数据集上以更少的数据和计算资源达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的放射学报告生成方法通常遵循规模驱动范式，需要多阶段训练、大量的配对语料库和超大型骨干网络，导致其数据和计算密集度高，难以在资源受限的环境下应用。

Method: 本文提出了Oracle-educated GRPO (OraPO) 和基于FactScore的奖励 (FactS)。OraPO通过将GRPO在稀有或困难案例上的失败探索转化为直接偏好监督，实现了单阶段、仅RL的训练。FactS通过提取原子临床事实并对照真实标签检查蕴涵关系，提供密集、可解释的句子级奖励，将学习建立在诊断证据之上。

Result: OraPO和FactS的结合显著提高了临床挑战性病例的学习效率，在CheXpert Plus数据集上达到了新的SOTA性能（F1得分为0.341），且仅使用了小型VLM和适度硬件，训练数据量减少了2-3个数量级。

Conclusion: OraPO和FactS共同创建了一个紧凑而强大的框架，显著提高了放射学报告生成任务中临床挑战性病例的学习效率，以更少的训练数据和计算资源实现了卓越的性能，为资源受限环境下的RRG提供了有效解决方案。

Abstract: Radiology report generation (RRG) aims to automatically produce clinically
faithful reports from chest X-ray images. Prevailing work typically follows a
scale-driven paradigm, by multi-stage training over large paired corpora and
oversized backbones, making pipelines highly data- and compute-intensive. In
this paper, we propose Oracle-educated GRPO {OraPO) with a FactScore-based
reward (FactS) to tackle the RRG task under constrained budgets. OraPO enables
single-stage, RL-only training by converting failed GRPO explorations on rare
or difficult studies into direct preference supervision via a lightweight
oracle step. FactS grounds learning in diagnostic evidence by extracting atomic
clinical facts and checking entailment against ground-truth labels, yielding
dense, interpretable sentence-level rewards. Together, OraPO and FactS create a
compact and powerful framework that significantly improves learning efficiency
on clinically challenging cases, setting the new SOTA performance on the
CheXpert Plus dataset (0.341 in F1) with 2--3 orders of magnitude less training
data using a small base VLM on modest hardware.

</details>


### [96] [Training-Free Multi-Style Fusion Through Reference-Based Adaptive Modulation](https://arxiv.org/abs/2509.18602)
*Xu Liu,Yibo Lu,Xinxian Wang,Xinyu Wu*

Main category: cs.CV

TL;DR: AMSF是一个基于参考、免训练的框架，它使扩散模型能够可控地融合多种参考风格，解决了现有方法在多风格融合和风格平衡方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于参考的方法主要受限于：1) 只能接受一张风格图像，限制了混合美学和风格扩展性；2) 缺乏平衡多种风格影响的原理性机制。

Method: AMSF通过语义令牌分解模块编码所有风格图像和文本提示，并将其自适应地注入到冻结扩散模型的每个交叉注意力层。此外，一个相似性感知重加权模块在每个去噪步骤重新校准分配给每个风格组件的注意力，从而实现平衡且用户可控的风格融合，无需任何微调或外部适配器。

Result: 定性和定量评估均表明，AMSF生成的多风格融合结果始终优于现有最先进的方法。其融合设计可以无缝扩展到两种或更多风格。

Conclusion: AMSF的能力使其成为在扩散模型中实现富有表现力的多风格生成的一个实用进展。

Abstract: We propose Adaptive Multi-Style Fusion (AMSF), a reference-based
training-free framework that enables controllable fusion of multiple reference
styles in diffusion models. Most of the existing reference-based methods are
limited by (a) acceptance of only one style image, thus prohibiting hybrid
aesthetics and scalability to more styles, and (b) lack of a principled
mechanism to balance several stylistic influences. AMSF mitigates these
challenges by encoding all style images and textual hints with a semantic token
decomposition module that is adaptively injected into every cross-attention
layer of an frozen diffusion model. A similarity-aware re-weighting module then
recalibrates, at each denoising step, the attention allocated to every style
component, yielding balanced and user-controllable blends without any
fine-tuning or external adapters. Both qualitative and quantitative evaluations
show that AMSF produces multi-style fusion results that consistently outperform
the state-of-the-art approaches, while its fusion design scales seamlessly to
two or more styles. These capabilities position AMSF as a practical step toward
expressive multi-style generation in diffusion models.

</details>


### [97] [MLF-4DRCNet: Multi-Level Fusion with 4D Radar and Camera for 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2509.18613)
*Yuzhi Wu,Li Xiao,Jun Liu,Guangfeng Jiang,XiangGen Xia*

Main category: cs.CV

TL;DR: 本文提出MLF-4DRCNet，一个用于3D目标检测的新型两阶段框架，通过点级、场景级和提议级多层次融合4D毫米波雷达和摄像头图像，有效解决了4D雷达点云稀疏和噪声问题，实现了最先进的性能，甚至可与基于激光雷达的模型媲美。


<details>
  <summary>Details</summary>
Motivation: 4D毫米波雷达在自动驾驶中具有成本效益和鲁棒性，但其点云稀疏且噪声大，限制了其在3D目标检测中的独立应用。现有的4D雷达-相机融合方法大多采用为激光雷达-相机融合设计的范式，忽略了雷达点云固有的稀疏性和不完整几何结构，且融合仅限于粗略的场景级集成。

Method: 本文提出了MLF-4DRCNet，一个两阶段的3D目标检测框架，通过点级、场景级和提议级多层次融合4D雷达和摄像头图像。它包含三个关键组件：增强雷达点编码器（ERPE）模块在点级通过2D图像实例加密雷达点云，并使用三重注意力体素特征编码器将其编码为体素；分层场景融合池化（HSFP）模块使用可变形注意力动态整合多尺度体素特征和2D图像特征，并对融合特征进行池化；提议级融合增强（PLFE）模块通过融合图像特征细化区域提议，并进一步与HSFP的池化特征进行集成。

Result: 在View-of-Delft (VoD) 和 TJ4DRadSet 数据集上的实验结果表明，MLF-4DRCNet 实现了最先进的性能。值得注意的是，它在 VoD 数据集上取得了与基于激光雷达的模型相当的性能。

Conclusion: MLF-4DRCNet通过其独特的多层次融合策略，成功解决了4D雷达点云稀疏和噪声的挑战，显著提升了4D雷达-相机融合在3D目标检测中的感知能力，使其性能达到甚至超越现有先进水平，为自动驾驶中的鲁棒感知提供了有效解决方案。

Abstract: The emerging 4D millimeter-wave radar, measuring the range, azimuth,
elevation, and Doppler velocity of objects, is recognized for its
cost-effectiveness and robustness in autonomous driving. Nevertheless, its
point clouds exhibit significant sparsity and noise, restricting its standalone
application in 3D object detection. Recent 4D radar-camera fusion methods have
provided effective perception. Most existing approaches, however, adopt
explicit Bird's-Eye-View fusion paradigms originally designed for LiDAR-camera
fusion, neglecting radar's inherent drawbacks. Specifically, they overlook the
sparse and incomplete geometry of radar point clouds and restrict fusion to
coarse scene-level integration. To address these problems, we propose
MLF-4DRCNet, a novel two-stage framework for 3D object detection via
multi-level fusion of 4D radar and camera images. Our model incorporates the
point-, scene-, and proposal-level multi-modal information, enabling
comprehensive feature representation. It comprises three crucial components:
the Enhanced Radar Point Encoder (ERPE) module, the Hierarchical Scene Fusion
Pooling (HSFP) module, and the Proposal-Level Fusion Enhancement (PLFE) module.
Operating at the point-level, ERPE densities radar point clouds with 2D image
instances and encodes them into voxels via the proposed Triple-Attention Voxel
Feature Encoder. HSFP dynamically integrates multi-scale voxel features with 2D
image features using deformable attention to capture scene context and adopts
pooling to the fused features. PLFE refines region proposals by fusing image
features, and further integrates with the pooled features from HSFP.
Experimental results on the View-of-Delft (VoD) and TJ4DRadSet datasets
demonstrate that MLF-4DRCNet achieves the state-of-the-art performance.
Notably, it attains performance comparable to LiDAR-based models on the VoD
dataset.

</details>


### [98] [Prompt-Guided Dual Latent Steering for Inversion Problems](https://arxiv.org/abs/2509.18619)
*Yichen Wu,Xu Liu,Chenxuan Zhao,Xinyu Wu*

Main category: cs.CV

TL;DR: 新型PDLS框架利用整流流模型，通过结构和语义双路径引导，并采用LQR最优控制，解决了扩散模型潜在空间中损坏图像反演时结构保真度与语义准确性之间的矛盾，实现了高质量、无语义漂移的图像重建。


<details>
  <summary>Details</summary>
Motivation: 当前将损坏图像反演到扩散模型潜在空间的方法，通常将图像编码为单一潜在向量，难以平衡结构保真度和语义准确性，导致重建图像出现语义漂移（如细节模糊或属性错误）。

Method: 提出PDLS（Prompt-Guided Dual Latent Steering），一个基于整流流模型的新型无训练框架。PDLS将反演过程分解为结构路径（保留源图像完整性）和语义路径（由提示词引导）两个互补流。将这种双重引导表述为最优控制问题，并通过线性二次调节器（LQR）推导出闭式解，从而在每一步动态引导生成轨迹，防止语义漂移并保留细节，无需昂贵的逐图像优化。

Result: 在FFHQ-1K和ImageNet-1K数据集上，针对高斯去模糊、运动去模糊、超分辨率和自由形式修复等多种反演任务进行的广泛实验表明，PDLS生成的重建图像比单一潜在基线方法更忠实于原始图像，并且与语义信息更一致。

Conclusion: PDLS框架通过其独特的双潜在引导和LQR最优控制机制，成功解决了现有方法在图像反演中结构与语义平衡的挑战，实现了高保真度且语义准确的重建，显著优于传统单一潜在向量方法。

Abstract: Inverting corrupted images into the latent space of diffusion models is
challenging. Current methods, which encode an image into a single latent
vector, struggle to balance structural fidelity with semantic accuracy, leading
to reconstructions with semantic drift, such as blurred details or incorrect
attributes. To overcome this, we introduce Prompt-Guided Dual Latent Steering
(PDLS), a novel, training-free framework built upon Rectified Flow models for
their stable inversion paths. PDLS decomposes the inversion process into two
complementary streams: a structural path to preserve source integrity and a
semantic path guided by a prompt. We formulate this dual guidance as an optimal
control problem and derive a closed-form solution via a Linear Quadratic
Regulator (LQR). This controller dynamically steers the generative trajectory
at each step, preventing semantic drift while ensuring the preservation of fine
detail without costly, per-image optimization. Extensive experiments on FFHQ-1K
and ImageNet-1K under various inversion tasks, including Gaussian deblurring,
motion deblurring, super-resolution and freeform inpainting, demonstrate that
PDLS produces reconstructions that are both more faithful to the original image
and better aligned with the semantic information than single-latent baselines.

</details>


### [99] [Learning neuroimaging models from health system-scale data](https://arxiv.org/abs/2509.18638)
*Yiwei Lyu,Samir Harake,Asadur Chowdury,Soumyanil Banerjee,Rachel Gologorsky,Shixuan Liu,Anna-Katharina Meissner,Akshay Rao,Chenhui Zhao,Akhil Kondepudi,Cheng Jiang,Xinhai Hou,Rushikesh S. Joshi,Volker Neuschmelting,Ashok Srinivasan,Dawn Kleindorfer,Brian Athey,Vikas Gulani,Aditya Pandey,Honglak Lee,Todd Hollon*

Main category: cs.CV

TL;DR: Prima是一个基于视觉语言模型（VLM）的神经影像AI基础，在22万多份MRI研究上训练，并在3万份MRI研究中测试，在52种放射学诊断中实现了92.0的平均诊断AUC，超越了现有模型，并展示了算法公平性，有望缓解医疗系统压力和偏见。


<details>
  <summary>Details</summary>
Motivation: 全球对磁共振成像（MRI）研究的需求持续增长，给医疗系统带来巨大压力，导致周转时间延长和医生职业倦怠，尤其是在资源匮乏和农村地区，这些挑战促使研究开发更高效、公平的神经影像评估工具。

Method: 利用大型学术医疗系统作为数据引擎，开发了Prima，这是第一个服务于神经影像的视觉语言模型（VLM）。Prima采用分层视觉架构，在超过22万份MRI研究上进行训练，并在一个为期一年的、包含3万份MRI研究的医疗系统范围内研究中进行了测试。

Result: Prima在52种主要神经系统疾病的放射学诊断中，实现了92.0的平均诊断曲线下面积（AUC），优于其他最先进的通用和医学AI模型。它能提供可解释的鉴别诊断、放射科医生工作列表优先级和临床转诊建议，并在一系列患者人口统计和MRI系统上表现出算法公平性，有助于缓解医疗系统偏见，如低资源人群的周转时间过长问题。

Conclusion: 研究结果强调了医疗系统规模的视觉语言模型（VLM）的变革潜力，以及Prima在推动AI驱动的医疗保健和缓解医疗系统偏见方面的作用。

Abstract: Neuroimaging is a ubiquitous tool for evaluating patients with neurological
diseases. The global demand for magnetic resonance imaging (MRI) studies has
risen steadily, placing significant strain on health systems, prolonging
turnaround times, and intensifying physician burnout \cite{Chen2017-bt,
Rula2024-qp-1}. These challenges disproportionately impact patients in
low-resource and rural settings. Here, we utilized a large academic health
system as a data engine to develop Prima, the first vision language model (VLM)
serving as an AI foundation for neuroimaging that supports real-world, clinical
MRI studies as input. Trained on over 220,000 MRI studies, Prima uses a
hierarchical vision architecture that provides general and transferable MRI
features. Prima was tested in a 1-year health system-wide study that included
30K MRI studies. Across 52 radiologic diagnoses from the major neurologic
disorders, including neoplastic, inflammatory, infectious, and developmental
lesions, Prima achieved a mean diagnostic area under the ROC curve of 92.0,
outperforming other state-of-the-art general and medical AI models. Prima
offers explainable differential diagnoses, worklist priority for radiologists,
and clinical referral recommendations across diverse patient demographics and
MRI systems. Prima demonstrates algorithmic fairness across sensitive groups
and can help mitigate health system biases, such as prolonged turnaround times
for low-resource populations. These findings highlight the transformative
potential of health system-scale VLMs and Prima's role in advancing AI-driven
healthcare.

</details>


### [100] [Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation](https://arxiv.org/abs/2509.18639)
*Yuanhuiyi Lyu,Chi Kit Wong,Chenfei Liao,Lutao Jiang,Xu Zheng,Zexin Lu,Linfeng Zhang,Xuming Hu*

Main category: cs.CV

TL;DR: 本文提出了一种名为Understanding-in-Generation (UiG)的新型推理框架，通过将强大的理解能力融入到生成过程中，并通过图像编辑逐步增强生成图像，显著提升了统一模型在文本到图像生成方面的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成CoT推理方法将理解和生成过程分离，限制了它们在解决统一模型生成能力缺陷方面的指导作用。

Method: UiG框架的核心在于将统一模型的强大理解能力融入到生成推理过程中，以弥补生成能力的不足。具体通过引入“图像编辑”作为桥梁：首先验证生成的图像，将统一模型的理解融入到编辑指令中；然后逐步增强生成的图像，将理解逐渐注入到生成过程中。

Result: UiG框架在文本到图像生成方面展现出显著的性能提升，例如在TIIF基准的长提示设置上获得了3.92%的性能增益，优于现有方法。

Conclusion: UiG框架通过在生成过程中整合理解能力，有效利用了统一模型的优势，显著提高了其文本到图像的生成性能，克服了传统方法中理解与生成分离的局限性。

Abstract: Recent works have made notable advancements in enhancing unified models for
text-to-image generation through the Chain-of-Thought (CoT). However, these
reasoning methods separate the processes of understanding and generation, which
limits their ability to guide the reasoning of unified models in addressing the
deficiencies of their generative capabilities. To this end, we propose a novel
reasoning framework for unified models, Understanding-in-Generation (UiG),
which harnesses the robust understanding capabilities of unified models to
reinforce their performance in image generation. The core insight of our UiG is
to integrate generative guidance by the strong understanding capabilities
during the reasoning process, thereby mitigating the limitations of generative
abilities. To achieve this, we introduce "Image Editing" as a bridge to infuse
understanding into the generation process. Initially, we verify the generated
image and incorporate the understanding of unified models into the editing
instructions. Subsequently, we enhance the generated image step by step,
gradually infusing the understanding into the generation process. Our UiG
framework demonstrates a significant performance improvement in text-to-image
generation over existing text-to-image reasoning methods, e.g., a 3.92% gain on
the long prompt setting of the TIIF benchmark. The project code:
https://github.com/QC-LY/UiG

</details>


### [101] [Zero-shot Monocular Metric Depth for Endoscopic Images](https://arxiv.org/abs/2509.18642)
*Nicolas Toussaint,Emanuele Colleoni,Ricardo Sanchez-Matilla,Joshua Sutcliffe,Vanessa Thompson,Muhammad Asad,Imanol Luengo,Danail Stoyanov*

Main category: cs.CV

TL;DR: 本文提出了一项针对内窥镜图像深度估计的综合基准测试，并发布了一个名为EndoSynth的合成数据集，旨在弥补真实数据稀缺的不足，并证明使用该数据集微调模型能显著提高性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型（特别是基于Transformer的网络）在单目相对和度量深度估计方面取得了巨大进展，但内窥镜图像领域仍然缺乏鲁棒的基准测试和高质量数据集。

Method: 1. 对最先进的（度量和相对）深度估计模型进行了综合基准测试，并在真实的、未见的内窥镜图像上进行评估。2. 引入并发布了一个新颖的合成数据集（EndoSynth），其中包含内窥镜手术器械，并配有真实度量深度和分割掩模。3. 使用EndoSynth数据集对深度基础模型进行微调。

Result: 通过使用EndoSynth合成数据集对深度基础模型进行微调，在大多数未见的真实数据上显著提高了准确性。

Conclusion: 这项工作通过提供基准测试和合成数据集，推动了内窥镜图像深度估计领域的发展，并为未来的研究提供了重要资源。

Abstract: Monocular relative and metric depth estimation has seen a tremendous boost in
the last few years due to the sharp advancements in foundation models and in
particular transformer based networks. As we start to see applications to the
domain of endoscopic images, there is still a lack of robust benchmarks and
high-quality datasets in that area. This paper addresses these limitations by
presenting a comprehensive benchmark of state-of-the-art (metric and relative)
depth estimation models evaluated on real, unseen endoscopic images, providing
critical insights into their generalisation and performance in clinical
scenarios. Additionally, we introduce and publish a novel synthetic dataset
(EndoSynth) of endoscopic surgical instruments paired with ground truth metric
depth and segmentation masks, designed to bridge the gap between synthetic and
real-world data. We demonstrate that fine-tuning depth foundation models using
our synthetic dataset boosts accuracy on most unseen real data by a significant
margin. By providing both a benchmark and a synthetic dataset, this work
advances the field of depth estimation for endoscopic images and serves as an
important resource for future research. Project page, EndoSynth dataset and
trained weights are available at https://github.com/TouchSurgery/EndoSynth.

</details>


### [102] [LEAF-Mamba: Local Emphatic and Adaptive Fusion State Space Model for RGB-D Salient Object Detection](https://arxiv.org/abs/2509.18683)
*Lanhu Wu,Zilin Gao,Hao Fei,Mong-Li Lee,Wynne Hsu*

Main category: cs.CV

TL;DR: 针对RGB-D显著目标检测中现有方法性能与效率的矛盾，本文提出LEAF-Mamba模型，通过局部强调状态空间模块和基于SSM的自适应融合模块，有效解决了局部语义和跨模态融合问题，实现了卓越的性能和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的RGB-D显著目标检测（SOD）方法主要依赖CNN（受限于局部感受野）或Vision Transformers（计算复杂度高），难以平衡性能和效率。虽然Mamba等状态空间模型（SSM）在建模长距离依赖方面具有线性复杂度优势，但直接应用于RGB-D SOD可能导致局部语义不足和跨模态融合不充分。

Method: 本文提出了局部强调和自适应融合状态空间模型（LEAF-Mamba），包含两个核心组件：1) 局部强调状态空间模块（LE-SSM），用于捕获多尺度局部依赖；2) 基于SSM的自适应融合模块（AFM），用于实现互补的跨模态交互和可靠的跨模态集成。

Result: 实验结果表明，LEAF-Mamba在有效性和效率方面均持续优于16种最先进的RGB-D SOD方法。此外，该方法在RGB-T SOD任务上也表现出色，证明了其强大的泛化能力。

Conclusion: LEAF-Mamba通过创新的LE-SSM和AFM模块，成功将状态空间模型应用于RGB-D SOD任务，解决了传统方法的局限性，实现了性能与计算效率的良好平衡，并展现了出色的泛化能力。

Abstract: RGB-D salient object detection (SOD) aims to identify the most conspicuous
objects in a scene with the incorporation of depth cues. Existing methods
mainly rely on CNNs, limited by the local receptive fields, or Vision
Transformers that suffer from the cost of quadratic complexity, posing a
challenge in balancing performance and computational efficiency. Recently,
state space models (SSM), Mamba, have shown great potential for modeling
long-range dependency with linear complexity. However, directly applying SSM to
RGB-D SOD may lead to deficient local semantics as well as the inadequate
cross-modality fusion. To address these issues, we propose a Local Emphatic and
Adaptive Fusion state space model (LEAF-Mamba) that contains two novel
components: 1) a local emphatic state space module (LE-SSM) to capture
multi-scale local dependencies for both modalities. 2) an SSM-based adaptive
fusion module (AFM) for complementary cross-modality interaction and reliable
cross-modality integration. Extensive experiments demonstrate that the
LEAF-Mamba consistently outperforms 16 state-of-the-art RGB-D SOD methods in
both efficacy and efficiency. Moreover, our method can achieve excellent
performance on the RGB-T SOD task, proving a powerful generalization ability.

</details>


### [103] [Lightweight Vision Transformer with Window and Spatial Attention for Food Image Classification](https://arxiv.org/abs/2509.18692)
*Xinle Gao,Linghui Ye,Zhiyong Xiao*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级食物图像分类算法，结合了窗口多头注意力机制（WMHAM）和空间注意力机制（SAM），在保持高精度的同时显著降低了计算复杂度和参数量，适用于资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 随着社会和科技发展，食品工业对生产质量和效率要求提高，食物图像分类在自动化质检、食品安全监管和智能农业中至关重要。然而，现有的Vision Transformer模型参数多、计算复杂，难以满足实际应用需求。

Method: 提出了一种轻量级食物图像分类算法，集成了窗口多头注意力机制（WMHAM）和空间注意力机制（SAM）。WMHAM通过高效的窗口划分捕捉局部和全局上下文特征以降低计算成本；SAM自适应地强调关键空间区域以增强判别性特征表示。

Result: 在Food-101和Vireo Food-172数据集上，模型分别达到了95.24%和94.33%的准确率，与基线方法相比，显著减少了参数量和FLOPs。

Conclusion: 所提出的方法在计算效率和分类性能之间取得了有效平衡，非常适合部署在资源受限的环境中。

Abstract: With the rapid development of society and continuous advances in science and
technology, the food industry increasingly demands higher production quality
and efficiency. Food image classification plays a vital role in enabling
automated quality control on production lines, supporting food safety
supervision, and promoting intelligent agricultural production. However, this
task faces challenges due to the large number of parameters and high
computational complexity of Vision Transformer models. To address these issues,
we propose a lightweight food image classification algorithm that integrates a
Window Multi-Head Attention Mechanism (WMHAM) and a Spatial Attention Mechanism
(SAM). The WMHAM reduces computational cost by capturing local and global
contextual features through efficient window partitioning, while the SAM
adaptively emphasizes key spatial regions to improve discriminative feature
representation. Experiments conducted on the Food-101 and Vireo Food-172
datasets demonstrate that our model achieves accuracies of 95.24% and 94.33%,
respectively, while significantly reducing parameters and FLOPs compared with
baseline methods. These results confirm that the proposed approach achieves an
effective balance between computational efficiency and classification
performance, making it well-suited for deployment in resource-constrained
environments.

</details>


### [104] [RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images](https://arxiv.org/abs/2509.18711)
*Ke Li,Di Wang,Ting Wang,Fuyu Dong,Yiming Zhang,Luyao Zhang,Xiangyu Wang,Shaofeng Li,Quan Wang*

Main category: cs.CV

TL;DR: 本文提出了RSVG-ZeroOV，一个无需训练的框架，利用冻结的通用基础模型实现零样本开放词汇遥感视觉定位（RSVG），通过结合视觉-语言模型（VLM）和扩散模型（DM）的优势，生成纯净的分割掩码。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉定位方法受限于封闭词汇，难以应用于开放世界场景；而利用通用基础模型的方法则过度依赖昂贵的高质量数据集和耗时的微调。为了解决这些限制，研究者旨在探索冻结通用基础模型在零样本开放词汇RSVG中的潜力。

Method: 本文提出了RSVG-ZeroOV框架，无需训练，包含三个阶段：(i) 概述（Overview）：利用视觉-语言模型（VLM）获取捕获文本查询与视觉区域语义关联的交叉注意力图。(ii) 聚焦（Focus）：利用扩散模型（DM）的细粒度建模先验，补充VLM常忽略的物体结构和形状信息。(iii) 演化（Evolve）：引入一个简单有效的注意力演化模块，抑制不相关激活，生成纯净的指代对象分割掩码。

Result: 广泛的实验表明，所提出的RSVG-ZeroOV框架持续优于现有的弱监督和零样本方法。

Conclusion: RSVG-ZeroOV提供了一种高效且可扩展的解决方案，无需繁琐的任务特定训练，即可实现零样本开放词汇遥感视觉定位，充分利用了冻结通用基础模型的潜力。

Abstract: Remote sensing visual grounding (RSVG) aims to localize objects in remote
sensing images based on free-form natural language expressions. Existing
approaches are typically constrained to closed-set vocabularies, limiting their
applicability in open-world scenarios. While recent attempts to leverage
generic foundation models for open-vocabulary RSVG, they overly rely on
expensive high-quality datasets and time-consuming fine-tuning. To address
these limitations, we propose \textbf{RSVG-ZeroOV}, a training-free framework
that aims to explore the potential of frozen generic foundation models for
zero-shot open-vocabulary RSVG. Specifically, RSVG-ZeroOV comprises three key
stages: (i) Overview: We utilize a vision-language model (VLM) to obtain
cross-attention\footnote[1]{In this paper, although decoder-only VLMs use
self-attention over all tokens, we refer to the image-text interaction part as
cross-attention to distinguish it from pure visual self-attention.}maps that
capture semantic correlations between text queries and visual regions. (ii)
Focus: By leveraging the fine-grained modeling priors of a diffusion model
(DM), we fill in gaps in structural and shape information of objects, which are
often overlooked by VLM. (iii) Evolve: A simple yet effective attention
evolution module is introduced to suppress irrelevant activations, yielding
purified segmentation masks over the referred objects. Without cumbersome
task-specific training, RSVG-ZeroOV offers an efficient and scalable solution.
Extensive experiments demonstrate that the proposed framework consistently
outperforms existing weakly-supervised and zero-shot methods.

</details>


### [105] [OSDA: A Framework for Open-Set Discovery and Automatic Interpretation of Land-cover in Remote Sensing Imagery](https://arxiv.org/abs/2509.18693)
*Siyi Chen,Kai Wang,Weicong Pang,Ruiming Yang,Ziru Chen,Renjun Gao,Alexis Kai Hon Lau,Dasa Gu,Chenchen Zhang,Cheng Li*

Main category: cs.CV

TL;DR: 本研究提出OSDA框架，利用微调分割模型（SAM）和多模态大语言模型（MLLM）实现遥感影像中开放集地物发现、分割和描述，无需人工标注，结合像素级精度与高级语义理解。


<details>
  <summary>Details</summary>
Motivation: 遥感领域的开放集地物分析需要精细的空间定位和开放的语义分类能力，包括在无类别监督的情况下检测和分割新物体，并通过多模态推理赋予其可解释的语义标签。

Method: OSDA是一个三阶段的无标注开放集地物发现、分割和描述框架：1) 使用可提示的微调分割模型（SAM）进行精确发现和掩膜提取；2) 通过两阶段微调的多模态大语言模型（MLLM）进行语义归属和上下文描述；3) 利用LLM作为评估者并进行人工评分来评估MLLM。

Result: OSDA将像素级精度与高级语义理解相结合，解决了开放世界遥感解释中的关键挑战。该框架与架构无关、无需标签，支持在多样化卫星图像上进行鲁棒评估，无需人工标注。

Conclusion: 本工作为动态地物监测提供了一个可扩展且可解释的解决方案，在自动化制图更新和大规模地球观测分析方面显示出巨大潜力。

Abstract: Open-set land-cover analysis in remote sensing requires the ability to
achieve fine-grained spatial localization and semantically open categorization.
This involves not only detecting and segmenting novel objects without
categorical supervision but also assigning them interpretable semantic labels
through multimodal reasoning. In this study, we introduce OSDA, an integrated
three-stage framework for annotation-free open-set land-cover discovery,
segmentation, and description. The pipeline consists of: (1) precise discovery
and mask extraction with a promptable fine-tuned segmentation model (SAM), (2)
semantic attribution and contextual description via a two-phase fine-tuned
multimodal large language model (MLLM), and (3) LLM-as-judge and manual scoring
of the MLLMs evaluation. By combining pixel-level accuracy with high-level
semantic understanding, OSDA addresses key challenges in open-world remote
sensing interpretation. Designed to be architecture-agnostic and label-free,
the framework supports robust evaluation across diverse satellite imagery
without requiring manual annotation. Our work provides a scalable and
interpretable solution for dynamic land-cover monitoring, showing strong
potential for automated cartographic updating and large-scale earth observation
analysis.

</details>


### [106] [COLT: Enhancing Video Large Language Models with Continual Tool Usage](https://arxiv.org/abs/2509.18754)
*Yuyang Liu,Xinyuan Shi,Bang Yang,Peilin Zhou,Jiahua Dong,Long Chen,Ian Reid,Xiaondan Liang*

Main category: cs.CV

TL;DR: 本文提出COLT，一种增强开源视频LLM连续工具使用能力的方法，通过可学习的工具码本和动态选择机制，解决了在工具数据不断演进时“灾难性遗忘”的问题，并实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频LLM的工具使用方法（提示闭源LLM或指令微调）假设工具库是固定的，难以适应工具数据不断演进和流式更新的真实世界环境，且面临对过去学习工具的“灾难性遗忘”问题。

Method: 本文提出了COLT（COntinuaL Tool usage）框架，通过引入一个可学习的工具码本作为工具特定的记忆系统。该系统根据用户指令与码本中工具特征的相似性动态选择相关工具。此外，作者还收集了一个以视频为中心的工具使用指令微调数据集VideoToolBench。

Result: 在先前的视频LLM基准测试和VideoToolBench数据集上的大量实验表明，COLT取得了最先进的性能。

Conclusion: COLT成功地使开源视频LLM能够在不遗忘过去学习工具的情况下，连续地获取和使用新工具，从而显著提升了其在动态环境下的泛化能力和工具使用潜力。

Abstract: The success of Large Language Models (LLMs) has significantly propelled the
research of video understanding. To harvest the benefits of well-trained expert
models (i.e., tools), video LLMs prioritize the exploration of tool usage
capabilities. Existing methods either prompt closed-source LLMs or employ the
instruction tuning paradigm for tool-use fine-tuning. These methods, however,
assume an established repository of fixed tools and struggle to generalize to
real-world environments where tool data is perpetually evolving and streaming
in. To this end, we propose to enhance open-source video LLMs with COntinuaL
Tool usage (termed COLT), which automatically acquires tool-use ability in a
successive tool stream without suffering 'catastrophic forgetting' of the past
learned tools. Specifically, our COLT incorporates a learnable tool codebook as
a tool-specific memory system. Then relevant tools are dynamically selected
based on the similarity between user instruction and tool features within the
codebook. To unleash the tool usage potential of video LLMs, we collect a
video-centric tool-use instruction tuning dataset VideoToolBench. Extensive
experiments on both previous video LLM benchmarks and the tool-use-specific
VideoToolBench dataset demonstrate the state-of-the-art performance of our
proposed COLT.

</details>


### [107] [Overview of PlantCLEF 2021: cross-domain plant identification](https://arxiv.org/abs/2509.18697)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: 本文介绍了LifeCLEF 2021植物识别挑战，该挑战旨在通过利用植物标本馆数据，改善生物多样性丰富但数据匮乏地区（如热带国家）的自动化植物识别能力。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习植物识别技术主要依赖于北美和西欧等地区的数据，对热带国家等生物多样性丰富但缺乏野外照片数据的地区效果不佳。然而，这些地区拥有大量的数字化植物标本馆数据，可作为潜在的补充资源。

Method: LifeCLEF 2021挑战被设计为一个跨领域分类任务，目标是识别约1,000种圭亚那地盾的植物。训练集包含数十万份植物标本馆图像和数千张野外照片，以及元数据和5个形态功能性状。测试集仅包含野外照片。挑战旨在评估通过学习标本馆和野外照片之间的对应关系，来提升识别效果。

Result: 本文介绍了该评估的资源和评价方法，总结了参与研究团队所采用的方法和系统，并对主要结果进行了分析。

Conclusion: 该挑战旨在评估利用植物标本馆藏品，能在多大程度上改善数据匮乏地区植物群的自动化识别。本文将呈现此次评估的发现和主要成果。

Abstract: Automated plant identification has improved considerably thanks to recent
advances in deep learning and the availability of training data with more and
more field photos. However, this profusion of data concerns only a few tens of
thousands of species, mainly located in North America and Western Europe, much
less in the richest regions in terms of biodiversity such as tropical
countries. On the other hand, for several centuries, botanists have
systematically collected, catalogued and stored plant specimens in herbaria,
especially in tropical regions, and recent efforts by the biodiversity
informatics community have made it possible to put millions of digitised
records online. The LifeCLEF 2021 plant identification challenge (or "PlantCLEF
2021") was designed to assess the extent to which automated identification of
flora in data-poor regions can be improved by using herbarium collections. It
is based on a dataset of about 1,000 species mainly focused on the Guiana
Shield of South America, a region known to have one of the highest plant
diversities in the world. The challenge was evaluated as a cross-domain
classification task where the training set consisted of several hundred
thousand herbarium sheets and a few thousand photos to allow learning a
correspondence between the two domains. In addition to the usual metadata
(location, date, author, taxonomy), the training data also includes the values
of 5 morphological and functional traits for each species. The test set
consisted exclusively of photos taken in the field. This article presents the
resources and evaluations of the assessment carried out, summarises the
approaches and systems used by the participating research groups and provides
an analysis of the main results.

</details>


### [108] [DiSSECT: Structuring Transfer-Ready Medical Image Representations through Discrete Self-Supervision](https://arxiv.org/abs/2509.18765)
*Azad Singh,Deepak Mishra*

Main category: cs.CV

TL;DR: DiSSECT是一种新的自监督学习框架，通过多尺度向量量化引入离散表示瓶颈，解决了现有医疗图像SSL方法的复杂性、捷径学习和泛化性问题，实现了高效、可迁移的临床表征学习。


<details>
  <summary>Details</summary>
Motivation: 现有医疗图像自监督学习（SSL）方法存在以下问题：依赖复杂架构、解剖学先验或过度调优的数据增强，限制了可扩展性和泛化性；更关键的是，这些模型容易出现捷径学习，尤其是在解剖相似度高、病理特征微妙的胸部X光等模态中。

Method: 本文提出了DiSSECT框架，将多尺度向量量化集成到自监督学习流程中，以施加一个离散的表示瓶颈。这迫使模型学习可重复的、结构感知的特征，同时抑制视图特定或低效用的模式，从而改善跨任务和跨领域的表示迁移。

Result: DiSSECT在分类和分割任务上均取得了优异性能，仅需极少或无需微调，并在低标签状态下表现出特别高的标签效率。该方法在多个公开医疗影像数据集上得到验证，与现有最先进方法相比，展现出强大的鲁棒性和泛化性。

Conclusion: DiSSECT通过引入离散自监督学习，有效克服了现有医疗图像SSL方法的局限性，学习到可重复、结构感知的特征，从而提供了高效、可迁移的临床表征，在各种任务和数据集上均表现出强大的性能和泛化能力。

Abstract: Self-supervised learning (SSL) has emerged as a powerful paradigm for medical
image representation learning, particularly in settings with limited labeled
data. However, existing SSL methods often rely on complex architectures,
anatomy-specific priors, or heavily tuned augmentations, which limit their
scalability and generalizability. More critically, these models are prone to
shortcut learning, especially in modalities like chest X-rays, where anatomical
similarity is high and pathology is subtle. In this work, we introduce DiSSECT
-- Discrete Self-Supervision for Efficient Clinical Transferable
Representations, a framework that integrates multi-scale vector quantization
into the SSL pipeline to impose a discrete representational bottleneck. This
constrains the model to learn repeatable, structure-aware features while
suppressing view-specific or low-utility patterns, improving representation
transfer across tasks and domains. DiSSECT achieves strong performance on both
classification and segmentation tasks, requiring minimal or no fine-tuning, and
shows particularly high label efficiency in low-label regimes. We validate
DiSSECT across multiple public medical imaging datasets, demonstrating its
robustness and generalizability compared to existing state-of-the-art
approaches.

</details>


### [109] [AGSwap: Overcoming Category Boundaries in Object Fusion via Adaptive Group Swapping](https://arxiv.org/abs/2509.18699)
*Zedong Zhang,Ying Tai,Jianjun Qian,Jian Yang,Jun Li*

Main category: cs.CV

TL;DR: 针对文本到图像生成中跨类别对象融合的挑战，本文提出了AGSwap方法和COF数据集，有效解决了现有方法的局限性，实现了更连贯的图像合成。


<details>
  <summary>Details</summary>
Motivation: 文本到图像（T2I）生成中融合跨类别对象具有广泛应用前景，但现有方法常产生有偏差、视觉混乱或语义不一致的结果，主要由于重叠伪影和整合不佳。此外，该领域缺乏全面的基准数据集限制了进展。

Method: 本文提出AGSwap（自适应群组交换）方法，包含两个关键组件：1) 群组式嵌入交换，通过特征操作融合不同概念的语义属性；2) 自适应群组更新，一种由平衡评估分数指导的动态优化机制，确保连贯合成。此外，本文还引入了COF（跨类别对象融合）数据集，这是一个基于ImageNet-1K和WordNet构建的大规模、分层结构数据集，包含95个超类，每个超类有10个子类，支持451,250个独特的融合对。

Result: 广泛实验表明，AGSwap在简单和复杂提示下均优于现有最先进的组合式T2I方法（包括GPT-Image-1）。

Conclusion: AGSwap提供了一种简单高效的方法来解决跨类别对象融合中的挑战，而COF数据集则为该领域提供了急需的综合基准，共同推动了文本到图像生成中对象融合能力的发展。

Abstract: Fusing cross-category objects to a single coherent object has gained
increasing attention in text-to-image (T2I) generation due to its broad
applications in virtual reality, digital media, film, and gaming. However,
existing methods often produce biased, visually chaotic, or semantically
inconsistent results due to overlapping artifacts and poor integration.
Moreover, progress in this field has been limited by the absence of a
comprehensive benchmark dataset. To address these problems, we propose
\textbf{Adaptive Group Swapping (AGSwap)}, a simple yet highly effective
approach comprising two key components: (1) Group-wise Embedding Swapping,
which fuses semantic attributes from different concepts through feature
manipulation, and (2) Adaptive Group Updating, a dynamic optimization mechanism
guided by a balance evaluation score to ensure coherent synthesis.
Additionally, we introduce \textbf{Cross-category Object Fusion (COF)}, a
large-scale, hierarchically structured dataset built upon ImageNet-1K and
WordNet. COF includes 95 superclasses, each with 10 subclasses, enabling
451,250 unique fusion pairs. Extensive experiments demonstrate that AGSwap
outperforms state-of-the-art compositional T2I methods, including GPT-Image-1
using simple and complex prompts.

</details>


### [110] [A Kernel Space-based Multidimensional Sparse Model for Dynamic PET Image Denoising](https://arxiv.org/abs/2509.18801)
*Kuang Xiaodong,Li Bingxuan,Li Yuan,Rao Fan,Ma Gege,Xie Qingguo,Mok Greta S P,Liu Huafeng,Zhu Wentao*

Main category: cs.CV

TL;DR: 本文提出了一种基于模型的神经网络（Neural KMDS-Net），用于动态PET图像去噪，通过利用帧间空间相关性和帧内结构一致性，有效提升了短时帧的图像质量。


<details>
  <summary>Details</summary>
Motivation: 动态PET图像，特别是短时帧，由于统计量有限，图像质量差是一个挑战。深度学习在医学图像去噪任务中显示出巨大潜力。

Method: 研究人员提出了一种模型驱动的神经网络，首先利用动态PET中的帧间空间相关性和帧内结构一致性建立了基于核空间的多维稀疏（KMDS）模型。随后，用神经网络替换了参数估计的固有形式，实现了自适应参数优化，从而形成了端到端的Neural KMDS-Net。

Result: 在模拟数据和真实数据上的大量实验结果表明，Neural KMDS-Net在动态PET去噪方面表现出强大的性能，优于现有的基线方法。

Conclusion: 所提出的方法可以有效实现动态PET的高时间分辨率和空间分辨率。

Abstract: Achieving high image quality for temporal frames in dynamic positron emission
tomography (PET) is challenging due to the limited statistic especially for the
short frames. Recent studies have shown that deep learning (DL) is useful in a
wide range of medical image denoising tasks. In this paper, we propose a
model-based neural network for dynamic PET image denoising. The inter-frame
spatial correlation and intra-frame structural consistency in dynamic PET are
used to establish the kernel space-based multidimensional sparse (KMDS) model.
We then substitute the inherent forms of the parameter estimation with neural
networks to enable adaptive parameters optimization, forming the end-to-end
neural KMDS-Net. Extensive experimental results from simulated and real data
demonstrate that the neural KMDS-Net exhibits strong denoising performance for
dynamic PET, outperforming previous baseline methods. The proposed method may
be used to effectively achieve high temporal and spatial resolution for dynamic
PET. Our source code is available at
https://github.com/Kuangxd/Neural-KMDS-Net/tree/main.

</details>


### [111] [Overview of LifeCLEF Plant Identification task 2019: diving into data deficient tropical countries](https://arxiv.org/abs/2509.18705)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: LifeCLEF 2019植物识别挑战赛旨在评估深度学习在数据稀缺地区（如圭亚那地盾和亚马逊北部雨林）对10K物种的自动化识别能力，并与人类专家表现进行比较。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在植物识别方面取得了显著进展，但其成功主要局限于少数物种。全球有近36.9万种植物，但训练数据仅覆盖数万种。因此，需要解决数据稀缺区域和更多物种的自动化识别问题。

Method: 该挑战赛基于一个包含1万个物种的数据集，主要关注圭亚那地盾和亚马逊北部雨林地区的植物群。挑战赛评估了自动化识别系统的性能，并将其与热带植物专家进行比较。本文介绍了挑战赛的资源和评估方法，总结了参与研究团队采用的方法和系统，并分析了主要结果。

Result: 抽象本身并未提供具体的挑战赛结果（例如，哪个系统表现最好或AI与人类表现的差距）。它指出该论文将“总结参与研究团队采用的方法和系统，并分析主要结果”。

Conclusion: 该挑战赛为评估数据稀缺地区植物自动化识别提供了平台，并对自动化系统与人类专家的表现进行了比较。该论文将呈现挑战赛的资源、评估、参与方法和主要成果分析。

Abstract: Automated identification of plants has improved considerably thanks to the
recent progress in deep learning and the availability of training data.
However, this profusion of data only concerns a few tens of thousands of
species, while the planet has nearly 369K. The LifeCLEF 2019 Plant
Identification challenge (or "PlantCLEF 2019") was designed to evaluate
automated identification on the flora of data deficient regions. It is based on
a dataset of 10K species mainly focused on the Guiana shield and the Northern
Amazon rainforest, an area known to have one of the greatest diversity of
plants and animals in the world. As in the previous edition, a comparison of
the performance of the systems evaluated with the best tropical flora experts
was carried out. This paper presents the resources and assessments of the
challenge, summarizes the approaches and systems employed by the participating
research groups, and provides an analysis of the main outcomes.

</details>


### [112] [Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions](https://arxiv.org/abs/2509.18847)
*Junhao Su,Yuanliang Wan,Junwei Yang,Hengyu Shi,Tianyang Han,Junfeng Luo,Yurui Qiu*

Main category: cs.CV

TL;DR: 本文提出了一种名为“结构化反思”的方法，使工具增强型大型语言模型（LLMs）能够明确诊断错误并提出修复方案。通过结合DAPO和GSPO目标以及定制奖励机制进行训练，并在新的Tool-Reflection-Bench基准上评估，显著提升了多轮工具调用成功率和错误恢复能力。


<details>
  <summary>Details</summary>
Motivation: 目前的工具增强型LLMs在多轮交互中表现脆弱，常因启发式提示或单向推理的反思机制，在失败后重复犯错，难以从错误中学习。

Method: 研究人员提出了“结构化反思”机制，将从错误到修复的路径转化为明确、可控和可训练的动作。智能体通过证据诊断失败，并提出正确的、可执行的后续调用。训练结合了DAPO和GSPO目标，并设计了针对工具使用的奖励方案，优化“反思、调用、完成”的分步策略。评估引入了Tool-Reflection-Bench基准，以程序化方式检查结构有效性、可执行性、参数正确性和结果一致性。

Result: 在BFCL v3和Tool-Reflection-Bench上的实验显示，该方法在多轮工具调用成功率和错误恢复方面取得了显著提升，并减少了冗余调用。

Conclusion: 明确的反思和直接优化能显著提高工具交互的可靠性，并为智能体从失败中学习提供了可复现的路径。

Abstract: Tool-augmented large language models (LLMs) are usually trained with
supervised imitation or coarse-grained reinforcement learning that optimizes
single tool calls. Current self-reflection practices rely on heuristic prompts
or one-way reasoning: the model is urged to 'think more' instead of learning
error diagnosis and repair. This is fragile in multi-turn interactions; after a
failure the model often repeats the same mistake. We propose structured
reflection, which turns the path from error to repair into an explicit,
controllable, and trainable action. The agent produces a short yet precise
reflection: it diagnoses the failure using evidence from the previous step and
then proposes a correct, executable follow-up call. For training we combine
DAPO and GSPO objectives with a reward scheme tailored to tool use, optimizing
the stepwise strategy Reflect, then Call, then Final. To evaluate, we introduce
Tool-Reflection-Bench, a lightweight benchmark that programmatically checks
structural validity, executability, parameter correctness, and result
consistency. Tasks are built as mini trajectories of erroneous call,
reflection, and corrected call, with disjoint train and test splits.
Experiments on BFCL v3 and Tool-Reflection-Bench show large gains in multi-turn
tool-call success and error recovery, and a reduction of redundant calls. These
results indicate that making reflection explicit and optimizing it directly
improves the reliability of tool interaction and offers a reproducible path for
agents to learn from failure.

</details>


### [113] [What Makes You Unique? Attribute Prompt Composition for Object Re-Identification](https://arxiv.org/abs/2509.18715)
*Yingquan Wang,Pingping Zhang,Chong Sun,Dong Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: 本文提出了一种属性提示组合 (APC) 框架，利用文本语义和视觉语言模型 (VLM) 来共同增强目标重识别 (ReID) 的判别性和泛化性，解决了现有模型在单域或跨域场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有目标重识别模型存在局限性：单域模型容易过拟合特定领域特征，而跨域模型可能因归一化策略抑制身份判别性特征，限制了其在真实世界中的适用性。研究旨在解决这些问题，提升模型在判别性和泛化性方面的表现。

Method: 本文提出了一个属性提示组合 (APC) 框架，包含：1) 属性提示生成器 (APG)，由语义属性字典 (SAD) 和提示组合模块 (PCM) 组成，用于从丰富的语义描述中自适应地生成判别性属性感知特征。2) 快慢更新训练策略 (FSTS)，它结合了快速更新流 (FUS) 以学习 ReID 特定的判别知识，以及慢速更新流 (SUS) 以保留预训练 VLM 的通用知识，通过相互作用平衡判别性和泛化性，并减轻过拟合。

Result: 在传统和领域泛化 (DG) ReID 数据集上进行的广泛实验表明，所提出的框架超越了现有最先进的方法，在判别性和泛化性方面均表现出卓越的性能。

Conclusion: APC 框架通过有效利用文本语义和 VLM 的泛化能力，成功地解决了现有 ReID 模型的局限性，显著提升了目标重识别在判别性和泛化性方面的表现，为跨摄像头识别提供了更鲁棒的解决方案。

Abstract: Object Re-IDentification (ReID) aims to recognize individuals across
non-overlapping camera views. While recent advances have achieved remarkable
progress, most existing models are constrained to either single-domain or
cross-domain scenarios, limiting their real-world applicability. Single-domain
models tend to overfit to domain-specific features, whereas cross-domain models
often rely on diverse normalization strategies that may inadvertently suppress
identity-specific discriminative cues. To address these limitations, we propose
an Attribute Prompt Composition (APC) framework, which exploits textual
semantics to jointly enhance discrimination and generalization. Specifically,
we design an Attribute Prompt Generator (APG) consisting of a Semantic
Attribute Dictionary (SAD) and a Prompt Composition Module (PCM). SAD is an
over-complete attribute dictionary to provide rich semantic descriptions, while
PCM adaptively composes relevant attributes from SAD to generate discriminative
attribute-aware features. In addition, motivated by the strong generalization
ability of Vision-Language Models (VLM), we propose a Fast-Slow Training
Strategy (FSTS) to balance ReID-specific discrimination and generalizable
representation learning. Specifically, FSTS adopts a Fast Update Stream (FUS)
to rapidly acquire ReID-specific discriminative knowledge and a Slow Update
Stream (SUS) to retain the generalizable knowledge inherited from the
pre-trained VLM. Through a mutual interaction, the framework effectively
focuses on ReID-relevant features while mitigating overfitting. Extensive
experiments on both conventional and Domain Generalized (DG) ReID datasets
demonstrate that our framework surpasses state-of-the-art methods, exhibiting
superior performances in terms of both discrimination and generalization. The
source code is available at https://github.com/AWangYQ/APC.

</details>


### [114] [LiDAR Point Cloud Image-based Generation Using Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2509.18917)
*Amirhesam Aghanouri,Cristina Olaverri-Monreal*

Main category: cs.CV

TL;DR: 本文提出了一种改进的去噪扩散概率模型（DDPM），通过新颖的噪声调度和时间步嵌入技术，生成高质量的合成LiDAR数据，以增强自动驾驶汽车（AVs）的3D视觉感知能力，克服了真实世界LiDAR数据噪声和稀疏的挑战。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车的成功依赖于有效的3D视觉系统来感知环境和检测交通参与者。然而，收集真实的LiDAR数据耗时且易受恶劣天气或传感器限制导致噪声和稀疏。这促使研究人员寻求生成高质量合成数据的方法来克服这些限制。

Method: 研究人员应用了一种去噪扩散概率模型（DDPM），并对其进行了增强，引入了新颖的噪声调度和时间步嵌入技术。这些修改旨在改善去噪过程和模型的时间感知能力，从而根据投影生成更逼真的点云。

Result: 该方法在IAMCV和KITTI-360数据集上进行了广泛评估，并与现有最先进（SOTA）方法进行了四项性能指标的比较。结果表明，该模型在大多数现有基线中表现优越，并有效缓解了噪声和稀疏LiDAR数据的影响，生成了具有丰富空间关系和结构细节的多样化点云。

Conclusion: 所提出的方法通过生成高质量的合成LiDAR数据，显著提高了自动驾驶汽车的感知性能，有效应对了真实世界LiDAR数据噪声和稀疏的挑战，并且在多个基准测试中优于现有方法。

Abstract: Autonomous vehicles (AVs) are expected to revolutionize transportation by
improving efficiency and safety. Their success relies on 3D vision systems that
effectively sense the environment and detect traffic agents. Among sensors AVs
use to create a comprehensive view of surroundings, LiDAR provides
high-resolution depth data enabling accurate object detection, safe navigation,
and collision avoidance. However, collecting real-world LiDAR data is
time-consuming and often affected by noise and sparsity due to adverse weather
or sensor limitations. This work applies a denoising diffusion probabilistic
model (DDPM), enhanced with novel noise scheduling and time-step embedding
techniques to generate high-quality synthetic data for augmentation, thereby
improving performance across a range of computer vision tasks, particularly in
AV perception. These modifications impact the denoising process and the model's
temporal awareness, allowing it to produce more realistic point clouds based on
the projection. The proposed method was extensively evaluated under various
configurations using the IAMCV and KITTI-360 datasets, with four performance
metrics compared against state-of-the-art (SOTA) methods. The results
demonstrate the model's superior performance over most existing baselines and
its effectiveness in mitigating the effects of noisy and sparse LiDAR data,
producing diverse point clouds with rich spatial relationships and structural
detail.

</details>


### [115] [Pre-training CLIP against Data Poisoning with Optimal Transport-based Matching and Alignment](https://arxiv.org/abs/2509.18717)
*Tong Zhang,Kuofeng Gao,Jiawang Bai,Leo Yu Zhang,Xin Yin,Zonghui Wang,Shouling Ji,Wenzhi Chen*

Main category: cs.CV

TL;DR: 针对CLIP模型面临的数据投毒和后门攻击威胁，本文提出OTCCLIP框架。该框架利用最优传输（Optimal Transport）机制，通过细粒度视觉和文本特征对图像-标题对进行重建和对齐，有效降低了攻击成功率，并显著提升了CLIP模型在受污染数据集上的零样本和线性探测性能。


<details>
  <summary>Details</summary>
Motivation: CLIP模型因训练数据源自互联网，易受目标数据投毒和后门攻击。现有防御方法仅依赖图像和标题的全局表示来匹配新标题，忽略了细粒度特征，可能引入不正确的图像-标题对，从而损害CLIP预训练效果。

Method: 本文提出了一个基于最优传输的框架OTCCLIP来重建图像-标题对。具体方法包括：1) 提出一种新的基于最优传输的距离度量，用于评估细粒度视觉和文本特征集之间的匹配度。2) 基于该最优传输距离重新分配新的标题。3) 采用基于最优传输的目标函数，鼓励模态内和模态间的细粒度对齐，以进一步减少不匹配对的负面影响。

Result: 实验结果表明，OTCCLIP能够成功降低投毒攻击的成功率。与现有方法相比，OTCCLIP显著提升了CLIP模型在受污染数据集上进行训练后的零样本（zero-shot）和线性探测（linear probing）性能。

Conclusion: OTCCLIP通过引入基于最优传输的细粒度特征对齐和图像-标题对重建，有效应对了针对CLIP模型的投毒攻击，不仅增强了模型的鲁棒性，还改善了其在受污染数据上的学习性能。

Abstract: Recent studies have shown that Contrastive Language-Image Pre-training (CLIP)
models are threatened by targeted data poisoning and backdoor attacks due to
massive training image-caption pairs crawled from the Internet. Previous
defense methods correct poisoned image-caption pairs by matching a new caption
for each image. However, the matching process relies solely on the global
representations of images and captions, overlooking fine-grained features of
visual and textual features. It may introduce incorrect image-caption pairs and
harm the CLIP pre-training. To address their limitations, we propose an Optimal
Transport-based framework to reconstruct image-caption pairs, named OTCCLIP. We
propose a new optimal transport-based distance measure between fine-grained
visual and textual feature sets and re-assign new captions based on the
proposed optimal transport distance. Additionally, to further reduce the
negative impact of mismatched pairs, we encourage the inter- and intra-modality
fine-grained alignment by employing optimal transport-based objective
functions. Our experiments demonstrate that OTCCLIP can successfully decrease
the attack success rates of poisoning attacks. Also, compared to previous
methods, OTCCLIP significantly improves CLIP's zero-shot and linear probing
performance trained on poisoned datasets.

</details>


### [116] [No Labels Needed: Zero-Shot Image Classification with Collaborative Self-Learning](https://arxiv.org/abs/2509.18938)
*Matheus Vinícius Todescato,Joel Luís Carbonera*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的零样本图像分类框架，结合视觉语言模型（VLM）和预训练视觉模型，通过自学习循环和基于置信度的伪标签策略，在无需标注数据的情况下，直接在测试数据上训练轻量级分类器，实现动态适应和卓越性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型（如CNN和ViT）在分类方面表现出色，但其对大量标注数据的依赖在许多实际场景中构成重大障碍。视觉语言模型（VLM）和预训练视觉模型的迁移学习是解决此问题的有前景技术，但仍需探索更有效的零样本分类方法。

Method: 该方法提出了一个零样本图像分类框架，仅需类别名称，无需任何标注训练数据。它结合了VLM和预训练视觉模型，采用自学习循环。具体而言，VLM用于识别高置信度样本，预训练视觉模型增强这些样本的视觉表示。然后，这些增强的特征迭代地训练一个轻量级分类器，直接在测试数据上进行动态适应。该方法避免了VLM微调和大型语言模型的使用，通过依赖纯视觉模型来减少对语义表示的依赖。

Result: 在十个不同的数据集上的实验评估表明，所提出的方法优于基线零样本方法。

Conclusion: 该研究成功地提出了一种零样本图像分类框架，通过结合VLM和预训练视觉模型，并利用自学习伪标签策略，在无需标注数据和VLM微调的情况下，实现了对测试数据的动态适应，并显著提升了分类性能。

Abstract: While deep learning, including Convolutional Neural Networks (CNNs) and
Vision Transformers (ViTs), has significantly advanced classification
performance, its typical reliance on extensive annotated datasets presents a
major obstacle in many practical scenarios where such data is scarce.
Vision-language models (VLMs) and transfer learning with pre-trained visual
models appear as promising techniques to deal with this problem. This paper
proposes a novel zero-shot image classification framework that combines a VLM
and a pre-trained visual model within a self-learning cycle. Requiring only the
set of class names and no labeled training data, our method utilizes a
confidence-based pseudo-labeling strategy to train a lightweight classifier
directly on the test data, enabling dynamic adaptation. The VLM identifies
high-confidence samples, and the pre-trained visual model enhances their visual
representations. These enhanced features then iteratively train the classifier,
allowing the system to capture complementary semantic and visual cues without
supervision. Notably, our approach avoids VLM fine-tuning and the use of large
language models, relying on the visual-only model to reduce the dependence on
semantic representation. Experimental evaluations on ten diverse datasets
demonstrate that our approach outperforms the baseline zero-shot method.

</details>


### [117] [Knowledge Transfer from Interaction Learning](https://arxiv.org/abs/2509.18733)
*Yilin Gao,Kangyi Chen,Zhongxing Peng,Hengjie Lu,Shugong Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为“从交互中学习”（LFI）的框架，通过明确建模视觉理解为交互过程，解决了视觉基础模型（VFMs）在从视觉语言模型（VLMs）转移知识时存在的局限性，实现了更有效和忠实的知识迁移。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉基础模型（VFMs）在从视觉语言模型（VLMs）转移知识方面面临根本性限制。VLMs擅长通过统一表示空间建模跨模态交互，而现有VFMs主要采用以结果为导向的范式，忽略了底层的交互过程。这种表示差异阻碍了有效的知识转移，并限制了在不同视觉任务中的泛化能力。

Method: 本文提出了一种受认知启发的框架LFI，通过明确将视觉理解建模为一个交互过程来解决上述问题。其核心思想是捕获预训练VLM中编码的动态交互模式，以实现更忠实和高效的知识转移。该方法围绕两项技术创新：交互查询（Interaction Queries），用于在网络层之间维持持久的关系结构；以及基于交互的监督，该监督来源于VLMs的跨模态注意力机制。

Result: 全面的实验表明，LFI在多个基准测试中取得了持续改进：在TinyImageNet分类上实现了3.3mAP/2.4AP的绝对增益，在COCO检测/分割上实现了1.6mAP的绝对增益，且参数开销极小，收敛速度更快。该框架在跨领域设置中表现尤为出色，在PACS和VLCS上分别带来了2.4和9.3的零样本改进。人类评估进一步证实了其认知一致性，在语义一致性指标上比以结果为导向的方法高出2.7倍。

Conclusion: LFI框架通过明确建模视觉理解为交互过程，并利用交互查询和基于交互的监督，有效地解决了VFM从VLM转移知识的难题。它实现了显著的性能提升，尤其是在泛化能力和跨领域设置中，并展现出更高的认知一致性，为未来的视觉基础模型发展提供了新方向。

Abstract: Current visual foundation models (VFMs) face a fundamental limitation in
transferring knowledge from vision language models (VLMs), while VLMs excel at
modeling cross-modal interactions through unified representation spaces,
existing VFMs predominantly adopt result-oriented paradigms that neglect the
underlying interaction processes. This representational discrepancy hinders
effective knowledge transfer and limits generalization across diverse vision
tasks. We propose Learning from Interactions (LFI), a cognitive-inspired
framework that addresses this gap by explicitly modeling visual understanding
as an interactive process. Our key insight is that capturing the dynamic
interaction patterns encoded in pre-trained VLMs enables more faithful and
efficient knowledge transfer to VFMs. The approach centers on two technical
innovations, Interaction Queries, which maintain persistent relational
structures across network layers, and interaction-based supervision, derived
from the cross-modal attention mechanisms of VLMs. Comprehensive experiments
demonstrate consistent improvements across multiple benchmarks, achieving 3.3
and 1.6mAP/2.4AP absolute gains on TinyImageNet classification and COCO
detection/segmentation respectively, with minimal parameter overhead and faster
convergence. The framework particularly excels in cross-domain settings,
delivering 2.4 and 9.3 zero-shot improvements on PACS and VLCS. Human
evaluations further confirm its cognitive alignment, outperforming
result-oriented methods by 2.7 times in semantic consistency metrics.

</details>


### [118] [VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction](https://arxiv.org/abs/2509.19002)
*Hao Wang,Eiki Murata,Lingfang Zhang,Ayako Sato,So Fukuda,Ziqi Yin,Wentao Hu,Keisuke Nakao,Yusuke Nakamura,Sebastian Zwirner,Yi-Chia Chen,Hiroyuki Otomo,Hiroki Ouchi,Daisuke Kawahara*

Main category: cs.CV

TL;DR: 本文提出了VIR-Bench，一个包含200个旅行视频的新基准，旨在评估和提升多模态大语言模型（MLLMs）在长距离地理空间-时间轨迹理解方面的能力，并将其应用于行程重建任务。


<details>
  <summary>Details</summary>
Motivation: 当前的视频基准主要关注室内或短距离户外活动，忽略了长距离旅行带来的挑战。掌握扩展的地理空间-时间轨迹对于下一代MLLMs至关重要，是具身AI规划和导航等实际任务的基础。

Method: 研究者创建了VIR-Bench，一个包含200个旅行视频的新基准，并将行程重建作为一项挑战性任务来评估MLLMs的地理空间-时间智能。此外，他们还开发了一个原型旅行规划代理，利用VIR-Bench的发现来改进行程推荐。

Result: 实验结果显示，包括专有模型在内的最先进MLLMs在VIR-Bench上得分较低，突显了处理跨越扩展空间和时间尺度的视频的难度。原型旅行规划代理显著改进的行程推荐验证了评估协议的有效性，并能转化为面向用户应用的具体性能提升。

Conclusion: VIR-Bench不仅能有效评估MLLMs在长距离地理空间-时间理解方面的能力，而且其评估协议的洞察力能够转化为实际应用中（如旅行规划代理）的具体性能提升，推动了下一代MLLMs的发展。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly enhanced video understanding capabilities, opening new
possibilities for practical applications. Yet current video benchmarks focus
largely on indoor scenes or short-range outdoor activities, leaving the
challenges associated with long-distance travel largely unexplored. Mastering
extended geospatial-temporal trajectories is critical for next-generation
MLLMs, underpinning real-world tasks such as embodied-AI planning and
navigation. To bridge this gap, we present VIR-Bench, a novel benchmark
consisting of 200 travel videos that frames itinerary reconstruction as a
challenging task designed to evaluate and push forward MLLMs'
geospatial-temporal intelligence. Experimental results reveal that
state-of-the-art MLLMs, including proprietary ones, struggle to achieve high
scores, underscoring the difficulty of handling videos that span extended
spatial and temporal scales. Moreover, we conduct an in-depth case study in
which we develop a prototype travel-planning agent that leverages the insights
gained from VIR-Bench. The agent's markedly improved itinerary recommendations
verify that our evaluation protocol not only benchmarks models effectively but
also translates into concrete performance gains in user-facing applications.

</details>


### [119] [HyPSAM: Hybrid Prompt-driven Segment Anything Model for RGB-Thermal Salient Object Detection](https://arxiv.org/abs/2509.18738)
*Ruichao Hou,Xingyuan Li,Tongwei Ren,Dongming Zhou,Gangshan Wu,Jinde Cao*

Main category: cs.CV

TL;DR: 本文提出HyPSAM，一个混合提示驱动的SAM模型，通过动态融合网络生成视觉提示并利用即插即用细化网络结合多种提示引导SAM，以解决RGB-T显著目标检测中边界不精确和特征融合不足的问题。


<details>
  <summary>Details</summary>
Motivation: RGB-T显著目标检测（RGB-T SOD）在整合RGB和热成像模态信息以识别突出物体时，面临由于固有的特征融合不足和数据稀缺性导致的难以学习精确边界和完整物体的问题。

Method: 本文提出混合提示驱动的Segment Anything Model (HyPSAM)。首先，设计动态融合网络（DFNet）生成高质量的初始显著图作为视觉提示，DFNet采用动态卷积和多分支解码实现自适应跨模态交互。其次，提出即插即用细化网络（P2RNet）作为通用优化策略，通过混合提示（文本、掩码和边界框提示）引导SAM细化显著图。

Result: 在三个公共数据集上的大量实验表明，所提出的方法实现了最先进的性能。值得注意的是，HyPSAM具有显著的通用性，可以无缝集成到不同的RGB-T SOD方法中，实现显著的性能提升。

Conclusion: HyPSAM有效解决了RGB-T SOD的挑战，通过创新的混合提示工程和动态特征融合，实现了优越的性能和通用性，凸显了提示工程在该领域的巨大潜力。

Abstract: RGB-thermal salient object detection (RGB-T SOD) aims to identify prominent
objects by integrating complementary information from RGB and thermal
modalities. However, learning the precise boundaries and complete objects
remains challenging due to the intrinsic insufficient feature fusion and the
extrinsic limitations of data scarcity. In this paper, we propose a novel
hybrid prompt-driven segment anything model (HyPSAM), which leverages the
zero-shot generalization capabilities of the segment anything model (SAM) for
RGB-T SOD. Specifically, we first propose a dynamic fusion network (DFNet) that
generates high-quality initial saliency maps as visual prompts. DFNet employs
dynamic convolution and multi-branch decoding to facilitate adaptive
cross-modality interaction, overcoming the limitations of fixed-parameter
kernels and enhancing multi-modal feature representation. Moreover, we propose
a plug-and-play refinement network (P2RNet), which serves as a general
optimization strategy to guide SAM in refining saliency maps by using hybrid
prompts. The text prompt ensures reliable modality input, while the mask and
box prompts enable precise salient object localization. Extensive experiments
on three public datasets demonstrate that our method achieves state-of-the-art
performance. Notably, HyPSAM has remarkable versatility, seamlessly integrating
with different RGB-T SOD methods to achieve significant performance gains,
thereby highlighting the potential of prompt engineering in this field. The
code and results of our method are available at:
https://github.com/milotic233/HyPSAM.

</details>


### [120] [Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning](https://arxiv.org/abs/2509.19090)
*Guoxin Wang,Jun Zhao,Xinyi Liu,Yanbo Liu,Xuyang Cao,Chao Li,Zhuoyun Liu,Qintian Sun,Fangru Zhou,Haoqiang Xing,Zhenhong Yang*

Main category: cs.CV

TL;DR: Citrus-V是一个多模态医疗基础模型，结合图像分析与文本推理，在一个框架内实现病灶定位、报告生成和诊断推理，性能超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有医学影像模型过于狭窄，泛化能力差，且真实临床应用需要精确的视觉定位、多模态整合和链式推理能力。

Method: 引入Citrus-V，一个整合检测、分割和多模态链式推理的多模态医疗基础模型，能够进行像素级病灶定位、结构化报告生成和医生般的诊断推断。提出了一种新颖的多模态训练方法，并发布了涵盖推理、检测、分割和文档理解任务的开源数据集。

Result: Citrus-V在多个基准测试中超越了现有的开源医疗模型和专家级影像系统，提供了一个从视觉定位到临床推理的统一流程，支持精确病灶量化、自动化报告和可靠的第二意见。

Conclusion: Citrus-V成功地将视觉定位与临床推理相结合，提供了一个统一且高性能的医疗影像分析解决方案，有望在临床诊断中发挥重要作用。

Abstract: Medical imaging provides critical evidence for clinical diagnosis, treatment
planning, and surgical decisions, yet most existing imaging models are narrowly
focused and require multiple specialized networks, limiting their
generalization. Although large-scale language and multimodal models exhibit
strong reasoning and multi-task capabilities, real-world clinical applications
demand precise visual grounding, multimodal integration, and chain-of-thought
reasoning. We introduce Citrus-V, a multimodal medical foundation model that
combines image analysis with textual reasoning. The model integrates detection,
segmentation, and multimodal chain-of-thought reasoning, enabling pixel-level
lesion localization, structured report generation, and physician-like
diagnostic inference in a single framework. We propose a novel multimodal
training approach and release a curated open-source data suite covering
reasoning, detection, segmentation, and document understanding tasks.
Evaluations demonstrate that Citrus-V outperforms existing open-source medical
models and expert-level imaging systems across multiple benchmarks, delivering
a unified pipeline from visual grounding to clinical reasoning and supporting
precise lesion quantification, automated reporting, and reliable second
opinions.

</details>


### [121] [TriFusion-AE: Language-Guided Depth and LiDAR Fusion for Robust Point Cloud Processing](https://arxiv.org/abs/2509.18743)
*Susmit Neogi*

Main category: cs.CV

TL;DR: 本文提出TriFusion-AE，一种多模态交叉注意力自编码器，通过整合文本先验、单目深度图和LiDAR点云，显著提升LiDAR点云在强噪声和对抗性攻击下的重建鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LiDAR点云易受噪声、遮挡和对抗性攻击影响，而现有自编码器在复杂真实世界条件下性能下降，需要更鲁棒的感知框架。

Method: 提出TriFusion-AE，一个多模态交叉注意力自编码器。它整合了文本的语义线索、图像的几何（深度）特征和LiDAR的空间结构。通过对齐这些多模态信息，模型学习对随机噪声和对抗性扰动具有弹性的表示。该框架是模型无关的，可与任何基于CNN的点云自编码器集成。

Result: 在轻微扰动下，模型性能提升有限；但在强对抗性攻击和重度噪声下，其重建鲁棒性显著优于传统基于CNN的自编码器（后者会崩溃）。在nuScenes-mini数据集上进行了评估。

Conclusion: TriFusion-AE通过有效融合文本、图像深度和LiDAR数据，显著增强了LiDAR点云在恶劣条件（如强噪声和对抗性攻击）下的重建鲁棒性，为自动驾驶和机器人技术提供了更可靠的感知基础。

Abstract: LiDAR-based perception is central to autonomous driving and robotics, yet raw
point clouds remain highly vulnerable to noise, occlusion, and adversarial
corruptions. Autoencoders offer a natural framework for denoising and
reconstruction, but their performance degrades under challenging real-world
conditions. In this work, we propose TriFusion-AE, a multimodal cross-attention
autoencoder that integrates textual priors, monocular depth maps from
multi-view images, and LiDAR point clouds to improve robustness. By aligning
semantic cues from text, geometric (depth) features from images, and spatial
structure from LiDAR, TriFusion-AE learns representations that are resilient to
stochastic noise and adversarial perturbations. Interestingly, while showing
limited gains under mild perturbations, our model achieves significantly more
robust reconstruction under strong adversarial attacks and heavy noise, where
CNN-based autoencoders collapse. We evaluate on the nuScenes-mini dataset to
reflect realistic low-data deployment scenarios. Our multimodal fusion
framework is designed to be model-agnostic, enabling seamless integration with
any CNN-based point cloud autoencoder for joint representation learning.

</details>


### [122] [ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?](https://arxiv.org/abs/2509.19070)
*Zijian Ling,Han Zhang,Yazhuo Zhou,Jiahao Cui*

Main category: cs.CV

TL;DR: 本文提出了ColorBlindnessEval，一个受石原色盲测试启发的视觉对抗场景基准，旨在评估视觉语言模型（VLMs）的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估VLMs在视觉对抗场景中的鲁棒性，特别是其识别复杂视觉模式中嵌入的数字信息的能力。现有模型可能在这些复杂环境中表现出局限性。

Method: 研究方法包括：1) 创建ColorBlindnessEval数据集，包含500张类石原图片，嵌入0-99的数字，采用不同颜色组合；2) 使用是/否和开放式提示评估9个VLM；3) 将模型性能与人类参与者进行比较。

Result: 实验结果表明，模型在对抗性环境中解释数字的能力存在局限性，并普遍存在幻觉问题。这突显了模型在复杂视觉环境中的不足。

Conclusion: 研究结论强调了提高VLM在复杂视觉环境中鲁棒性的必要性。ColorBlindnessEval是一个有价值的工具，可用于基准测试和提高VLM在准确性至关重要的实际应用中的可靠性。

Abstract: This paper presents ColorBlindnessEval, a novel benchmark designed to
evaluate the robustness of Vision-Language Models (VLMs) in visually
adversarial scenarios inspired by the Ishihara color blindness test. Our
dataset comprises 500 Ishihara-like images featuring numbers from 0 to 99 with
varying color combinations, challenging VLMs to accurately recognize numerical
information embedded in complex visual patterns. We assess 9 VLMs using Yes/No
and open-ended prompts and compare their performance with human participants.
Our experiments reveal limitations in the models' ability to interpret numbers
in adversarial contexts, highlighting prevalent hallucination issues. These
findings underscore the need to improve the robustness of VLMs in complex
visual environments. ColorBlindnessEval serves as a valuable tool for
benchmarking and improving the reliability of VLMs in real-world applications
where accuracy is critical.

</details>


### [123] [RoSe: Robust Self-supervised Stereo Matching under Adverse Weather Conditions](https://arxiv.org/abs/2509.19165)
*Yun Wang,Junjie Hu,Junhui Hou,Chenghao Zhang,Renwei Yang,Dapeng Oliver Wu*

Main category: cs.CV

TL;DR: 该论文提出了一种在恶劣天气下进行鲁棒自监督立体匹配的方法，通过引入视觉基础模型先验和场景对应先验，并设计了一个新的训练范式，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督立体匹配方法在恶劣天气（如夜晚、雨、雾）下性能显著下降。主要原因有两点：一是恶劣天气引入的噪声和能见度降低使CNN特征提取器难以处理反光和无纹理区域；二是这些退化区域会破坏准确的像素对应，导致基于光度一致性假设的监督信号失效。

Method: 本文提出以下方法：1) 将来自视觉基础模型的鲁棒先验注入到CNN特征提取器中，以改善恶劣天气下的特征表示。2) 引入场景对应先验来构建鲁棒的监督信号，而非仅仅依赖光度一致性假设。3) 创建了合成立体数据集，包含具有真实天气退化的清晰和恶劣图像对，这些图像对保持相同的语义上下文和视差，从而保留了场景对应属性。4) 提出了一种鲁棒的自监督训练范式，包括两个关键步骤：鲁棒自监督场景对应学习和恶劣天气蒸馏。这两个步骤都旨在对齐来自清晰和恶劣图像对的底层场景结果。

Result: 广泛的实验证明了所提出解决方案的有效性和通用性，其性能优于现有最先进的自监督方法。

Conclusion: 通过结合视觉基础模型的鲁棒先验和场景对应先验，并设计了一个新的自监督训练范式，本文提出的解决方案能够显著提高立体匹配模型在恶劣天气条件下的视差估计精度和鲁棒性。

Abstract: Recent self-supervised stereo matching methods have made significant
progress, but their performance significantly degrades under adverse weather
conditions such as night, rain, and fog. We identify two primary weaknesses
contributing to this performance degradation. First, adverse weather introduces
noise and reduces visibility, making CNN-based feature extractors struggle with
degraded regions like reflective and textureless areas. Second, these degraded
regions can disrupt accurate pixel correspondences, leading to ineffective
supervision based on the photometric consistency assumption. To address these
challenges, we propose injecting robust priors derived from the visual
foundation model into the CNN-based feature extractor to improve feature
representation under adverse weather conditions. We then introduce scene
correspondence priors to construct robust supervisory signals rather than
relying solely on the photometric consistency assumption. Specifically, we
create synthetic stereo datasets with realistic weather degradations. These
datasets feature clear and adverse image pairs that maintain the same semantic
context and disparity, preserving the scene correspondence property. With this
knowledge, we propose a robust self-supervised training paradigm, consisting of
two key steps: robust self-supervised scene correspondence learning and adverse
weather distillation. Both steps aim to align underlying scene results from
clean and adverse image pairs, thus improving model disparity estimation under
adverse weather effects. Extensive experiments demonstrate the effectiveness
and versatility of our proposed solution, which outperforms existing
state-of-the-art self-supervised methods. Codes are available at
\textcolor{blue}{https://github.com/cocowy1/RoSe-Robust-Self-supervised-Stereo-Matching-under-Adverse-Weather-Conditions}.

</details>


### [124] [FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score Distillation](https://arxiv.org/abs/2509.18759)
*Zhaorui Wang,Yi Gu,Deming Zhou,Renjing Xu*

Main category: cs.CV

TL;DR: 针对稀疏视角下3D Gaussian Splatting (3DGS) 重建存在的伪影和多视角不一致性问题，本文提出FixingGS，一种免训练方法。它通过蒸馏现有扩散模型获取更准确和跨视角一致的先验，并结合自适应渐进增强方案，有效去除伪影并提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 3DGS在稀疏视角下的3D场景重建仍具挑战性，因视觉信息不足导致伪影。现有利用生成先验的方法虽能去除伪影和补全内容，但难以保证多视角一致性，造成结构模糊和细节不真实。

Method: 本文提出FixingGS，一种免训练方法，充分利用现有扩散模型的能力来增强稀疏视角3DGS重建。核心方法是蒸馏，它能提供更准确且跨视角一致的扩散先验，从而有效去除伪影和进行内容修复。此外，还引入了自适应渐进增强方案，进一步优化约束不足区域的重建。

Result: 广泛的实验证明，FixingGS在视觉质量和重建性能上均超越了现有的最先进方法。

Conclusion: FixingGS通过其独特的蒸馏方法和自适应渐进增强方案，成功解决了稀疏视角3DGS重建中的伪影和不一致性问题，显著提升了重建的视觉质量和性能。

Abstract: Recently, 3D Gaussian Splatting (3DGS) has demonstrated remarkable success in
3D reconstruction and novel view synthesis. However, reconstructing 3D scenes
from sparse viewpoints remains highly challenging due to insufficient visual
information, which results in noticeable artifacts persisting across the 3D
representation. To address this limitation, recent methods have resorted to
generative priors to remove artifacts and complete missing content in
under-constrained areas. Despite their effectiveness, these approaches struggle
to ensure multi-view consistency, resulting in blurred structures and
implausible details. In this work, we propose FixingGS, a training-free method
that fully exploits the capabilities of the existing diffusion model for
sparse-view 3DGS reconstruction enhancement. At the core of FixingGS is our
distillation approach, which delivers more accurate and cross-view coherent
diffusion priors, thereby enabling effective artifact removal and inpainting.
In addition, we propose an adaptive progressive enhancement scheme that further
refines reconstructions in under-constrained regions. Extensive experiments
demonstrate that FixingGS surpasses existing state-of-the-art methods with
superior visual quality and reconstruction performance. Our code will be
released publicly.

</details>


### [125] [HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid Plexus in Pediatric Hydrocephalus](https://arxiv.org/abs/2509.19218)
*Yunzhi Xu,Yushuang Ding,Hu Sun,Hongxi Zhang,Li Zhao*

Main category: cs.CV

TL;DR: 该研究提出了HyKid数据集，这是一个包含48名儿童脑积水患者的开放获取、专家标注的3D MRI数据集，特别包含脉络丛分割，并发现脉络丛体积与脑脊液总体积之间存在强相关性，可作为脑积水评估的潜在生物标志物。


<details>
  <summary>Details</summary>
Motivation: 儿童脑积水评估具有挑战性，且相关研究受限于缺乏公开可用的、专家标注的数据集，特别是缺少包含脉络丛分割的数据集。

Method: 研究构建了HyKid数据集，包含48名儿童脑积水患者的3D MRI图像，这些图像通过切片到体积算法从低分辨率图像重建得到1mm各向同性分辨率。经验丰富的神经科医生提供了包括白质、灰质、侧脑室、外部脑脊液和脉络丛在内的脑组织手动校正分割。此外，利用检索增强生成框架从临床放射学报告中提取了结构化数据。

Result: 脉络丛体积与脑脊液总体积之间存在显著相关性，这为脑积水评估提供了一个潜在的生物标志物。基于此的预测模型表现出色（AUC = 0.87）。所提出的HyKid数据集为神经影像算法的开发提供了高质量的基准，并揭示了脉络丛相关特征在脑积水评估中的价值。

Conclusion: HyKid数据集为脑积水评估和神经影像算法开发提供了宝贵的资源，并强调了脉络丛相关特征在脑积水评估中的重要性，有望成为新的生物标志物。

Abstract: Evaluation of hydrocephalus in children is challenging, and the related
research is limited by a lack of publicly available, expert-annotated datasets,
particularly those with segmentation of the choroid plexus. To address this, we
present HyKid, an open-source dataset from 48 pediatric patients with
hydrocephalus. 3D MRIs were provided with 1mm isotropic resolution, which was
reconstructed from routine low-resolution images using a slice-to-volume
algorithm. Manually corrected segmentations of brain tissues, including white
matter, grey matter, lateral ventricle, external CSF, and the choroid plexus,
were provided by an experienced neurologist. Additionally, structured data was
extracted from clinical radiology reports using a Retrieval-Augmented
Generation framework. The strong correlation between choroid plexus volume and
total CSF volume provided a potential biomarker for hydrocephalus evaluation,
achieving excellent performance in a predictive model (AUC = 0.87). The
proposed HyKid dataset provided a high-quality benchmark for neuroimaging
algorithms development, and it revealed the choroid plexus-related features in
hydrocephalus assessments. Our datasets are publicly available at
https://www.synapse.org/Synapse:syn68544889.

</details>


### [126] [Bi-VLM: Pushing Ultra-Low Precision Post-Training Quantization Boundaries in Vision-Language Models](https://arxiv.org/abs/2509.18763)
*Xijun Wang,Junyun Huang,Rayyan Abdalla,Chengyuan Zhang,Ruiqi Xian,Dinesh Manocha*

Main category: cs.CV

TL;DR: 该研究提出Bi-VLM，通过基于高斯分位数的非均匀权重分离和显著性感知混合量化算法，实现视觉-语言模型（VLM）的超低比特量化，显著提升效率和性能，并发现量化模型中图像token存在冗余。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型（VLM）的巨大计算成本和内存需求限制了其在硬件受限环境中的应用，因此需要寻找能大幅提高效率的超低比特权重精度（比特宽度≤2比特）方法。

Method: 研究提出了Bi-VLM，其核心方法包括：1) 基于高斯分位数非均匀地分离模型权重，将其分为异常值（显著）和多个正常值（非显著）子集，确保每个子集包含与其分布分位数相对应的权重比例。2) 提出一种显著性感知混合量化算法，根据显著性指标和压缩目标，对标量和二值矩阵施加不同约束来量化权重。3) 对量化后的模型进行token剪枝，以进一步提高效率。

Result: 实验结果表明：1) 在VLM的语言模型部分，Bi-VLM在视觉问答任务上，相对于现有最先进技术（SOTA），在四种不同基准和三种不同模型上性能提升了3%-47%。2) 对于整体VLM，Bi-VLM的性能优于SOTA 4%-45%。3) 在量化模型上进行token剪枝后，发现图像token存在90%-99%的冗余，这有助于进一步剪枝视觉token以提高效率。

Conclusion: Bi-VLM成功弥补了VLM计算需求与超低比特权重精度之间的差距，通过其独特的非均匀权重分离和显著性感知混合量化算法，显著提升了VLM在硬件受限环境中的效率和性能。此外，研究还揭示了量化模型中图像token的显著冗余，为未来的效率优化提供了方向。

Abstract: We address the critical gap between the computational demands of
vision-language models and the possible ultra-low-bit weight precision
(bitwidth $\leq2$ bits) we can use for higher efficiency. Our work is motivated
by the substantial computational cost and memory requirements of VLMs, which
restrict their applicability in hardware-constrained environments. We propose
Bi-VLM, which separates model weights non-uniformly based on the Gaussian
quantiles. Our formulation groups the model weights into outlier (salient) and
multiple inlier (unsalient) subsets, ensuring that each subset contains a
proportion of weights corresponding to its quantile in the distribution. We
propose a saliency-aware hybrid quantization algorithm and use it to quantize
weights by imposing different constraints on the scaler and binary matrices
based on the saliency metric and compression objective. We have evaluated our
approach on different VLMs. For the language model part of the VLM, our Bi-VLM
outperforms the SOTA by 3%-47% on the visual question answering task in terms
of four different benchmarks and three different models. For the overall VLM,
our Bi-VLM outperforms the SOTA by 4%-45%. We also perform token pruning on the
quantized models and observe that there is redundancy of image tokens 90% - 99%
in the quantized models. This helps us to further prune the visual tokens to
improve efficiency.

</details>


### [127] [MsFIN: Multi-scale Feature Interaction Network for Traffic Accident Anticipation](https://arxiv.org/abs/2509.19227)
*Tongshuai Wu,Chao Lu,Ze Song,Yunlong Lin,Sizhe Fan,Xuemei Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种名为多尺度特征交互网络（MsFIN）的模型，用于从行车记录仪视频中进行早期事故预测，旨在解决交通参与者特征交互和多时间尺度行为线索捕捉的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前的事故预测模型面临两大挑战：一是难以建模交通参与者（在行车记录仪视角下常被遮挡）之间的特征级交互；二是难以捕捉事故发生前复杂、异步的多时间尺度行为线索。

Method: 论文提出MsFIN网络，包含多尺度特征聚合、时序特征处理和多尺度特征后融合三个层。多尺度特征聚合层设计了一个多尺度模块，用于提取短、中、长期时间尺度的场景表示，并利用Transformer架构促进全面的特征交互。时序特征处理层捕获场景和物体特征在因果约束下的序列演变。多尺度特征后融合层则融合多时间尺度的场景和物体特征，以生成全面的风险表示。

Result: 在DAD和DADA数据集上的实验结果表明，MsFIN在预测正确性和提前性方面显著优于现有采用单尺度特征提取的先进模型。消融研究也验证了MsFIN中每个模块的有效性。

Conclusion: MsFIN通过多尺度特征融合和上下文交互建模，实现了卓越的性能，成功解决了行车记录仪视频中早期事故预测的关键挑战。

Abstract: With the widespread deployment of dashcams and advancements in computer
vision, developing accident prediction models from the dashcam perspective has
become critical for proactive safety interventions. However, two key challenges
persist: modeling feature-level interactions among traffic participants (often
occluded in dashcam views) and capturing complex, asynchronous multi-temporal
behavioral cues preceding accidents. To deal with these two challenges, a
Multi-scale Feature Interaction Network (MsFIN) is proposed for early-stage
accident anticipation from dashcam videos. MsFIN has three layers for
multi-scale feature aggregation, temporal feature processing and multi-scale
feature post fusion, respectively. For multi-scale feature aggregation, a
Multi-scale Module is designed to extract scene representations at short-term,
mid-term and long-term temporal scales. Meanwhile, the Transformer architecture
is leveraged to facilitate comprehensive feature interactions. Temporal feature
processing captures the sequential evolution of scene and object features under
causal constraints. In the multi-scale feature post fusion stage, the network
fuses scene and object features across multiple temporal scales to generate a
comprehensive risk representation. Experiments on DAD and DADA datasets show
that MsFIN significantly outperforms state-of-the-art models with single-scale
feature extraction in both prediction correctness and earliness. Ablation
studies validate the effectiveness of each module in MsFIN, highlighting how
the network achieves superior performance through multi-scale feature fusion
and contextual interaction modeling.

</details>


### [128] [Real-time Deer Detection and Warning in Connected Vehicles via Thermal Sensing and Deep Learning](https://arxiv.org/abs/2509.18779)
*Hemanth Puppala,Wayne Sarasua,Srinivas Biyaguda,Farhad Farzinpour,Mashrur Chowdhury*

Main category: cs.CV

TL;DR: 本文提出了一种结合热成像、深度学习和车联网通信的实时鹿检测及驾驶员预警系统，旨在有效减少鹿车碰撞事故。


<details>
  <summary>Details</summary>
Motivation: 美国每年发生约210万起鹿车碰撞事故，导致440人死亡、5.9万人受伤、100亿美元经济损失，并对鹿群数量造成显著影响，因此急需解决方案来缓解这一严峻的安全挑战。

Method: 该系统整合了热成像技术、深度学习算法和车联网（V2X）通信。它在一个包含超过12,000张热成像鹿图像的定制数据集上进行了训练和验证。系统通过蜂窝车联网（CV2X）设备将传感器数据共享消息广播给周围车辆和路边单元，并在检测到高概率碰撞风险时向驾驶员发出警报。

Result: 系统表现出色，平均精度达到98.84%，精确度95.44%，召回率95.96%。在实地测试中，它能提供预警，并在恶劣天气条件下保持88%至92%的检测准确率，远优于可见光摄像头（低于60%）。从检测到驾驶员警报的端到端延迟持续低于100毫秒。

Conclusion: 该研究通过热成像和互联车辆，为减少鹿车碰撞事故提供了一条可行的技术途径。

Abstract: Deer-vehicle collisions represent a critical safety challenge in the United
States, causing nearly 2.1 million incidents annually and resulting in
approximately 440 fatalities, 59,000 injuries, and 10 billion USD in economic
damages. These collisions also contribute significantly to declining deer
populations. This paper presents a real-time detection and driver warning
system that integrates thermal imaging, deep learning, and
vehicle-to-everything communication to help mitigate deer-vehicle collisions.
Our system was trained and validated on a custom dataset of over 12,000 thermal
deer images collected in Mars Hill, North Carolina. Experimental evaluation
demonstrates exceptional performance with 98.84 percent mean average precision,
95.44 percent precision, and 95.96 percent recall. The system was field tested
during a follow-up visit to Mars Hill and readily sensed deer providing the
driver with advanced warning. Field testing validates robust operation across
diverse weather conditions, with thermal imaging maintaining between 88 and 92
percent detection accuracy in challenging scenarios where conventional visible
light based cameras achieve less than 60 percent effectiveness. When a high
probability threshold is reached sensor data sharing messages are broadcast to
surrounding vehicles and roadside units via cellular vehicle to everything
(CV2X) communication devices. Overall, our system achieves end to end latency
consistently under 100 milliseconds from detection to driver alert. This
research establishes a viable technological pathway for reducing deer-vehicle
collisions through thermal imaging and connected vehicles.

</details>


### [129] [Adversarially-Refined VQ-GAN with Dense Motion Tokenization for Spatio-Temporal Heatmaps](https://arxiv.org/abs/2509.19252)
*Gabriel Maldonado,Narges Rashvand,Armin Danesh Pazho,Ghazal Alinezhad Noghre,Vinit Katariya,Hamed Tabkhi*

Main category: cs.CV

TL;DR: 本文提出了一种对抗性优化的VQ-GAN框架，结合密集运动标记化，用于压缩时空人体运动热图，显著提高了重建质量和时间稳定性，并揭示了2D和3D运动的最佳词汇量大小。


<details>
  <summary>Details</summary>
Motivation: 连续人体运动理解在计算机视觉中因其高维度和固有冗余性而面临核心挑战。高效的压缩和表示对于分析复杂运动动力学至关重要。

Method: 引入了一个对抗性优化的VQ-GAN框架，并结合密集运动标记化，用于压缩时空热图。该方法通过对抗性优化消除了重建伪影，如运动模糊和时间错位。

Result: 在CMU Panoptic数据集上的实验表明，该方法优于dVAE基线，SSIM提高了9.31%，时间不稳定性降低了37.1%。密集标记化策略还揭示，2D运动可由128个标记的词汇表最佳表示，而3D运动的复杂性需要1024个标记的更大码本进行忠实重建。

Conclusion: 该方法在人体运动理解和表示方面表现出卓越性能，具有实际部署的可行性，并为不同运动分析应用提供了新的见解，特别是关于2D和3D运动的最佳表示复杂性。

Abstract: Continuous human motion understanding remains a core challenge in computer
vision due to its high dimensionality and inherent redundancy. Efficient
compression and representation are crucial for analyzing complex motion
dynamics. In this work, we introduce an adversarially-refined VQ-GAN framework
with dense motion tokenization for compressing spatio-temporal heatmaps while
preserving the fine-grained traces of human motion. Our approach combines dense
motion tokenization with adversarial refinement, which eliminates
reconstruction artifacts like motion smearing and temporal misalignment
observed in non-adversarial baselines. Our experiments on the CMU Panoptic
dataset provide conclusive evidence of our method's superiority, outperforming
the dVAE baseline by 9.31% SSIM and reducing temporal instability by 37.1%.
Furthermore, our dense tokenization strategy enables a novel analysis of motion
complexity, revealing that 2D motion can be optimally represented with a
compact 128-token vocabulary, while 3D motion's complexity demands a much
larger 1024-token codebook for faithful reconstruction. These results establish
practical deployment feasibility across diverse motion analysis applications.
The code base for this work is available at
https://github.com/TeCSAR-UNCC/Pose-Quantization.

</details>


### [130] [Towards Application Aligned Synthetic Surgical Image Synthesis](https://arxiv.org/abs/2509.18796)
*Danush Kumar Venkatesh,Stefanie Speidel*

Main category: cs.CV

TL;DR: SAADi是一种新的扩散模型框架，通过将合成图像与下游模型偏好对齐，有效缓解了外科手术数据稀缺问题，显著提升了分类和分割任务的性能，尤其对于代表性不足的类别。


<details>
  <summary>Details</summary>
Motivation: 带注释的外科手术数据稀缺是开发深度学习系统的主要挑战。现有扩散模型虽然能生成逼真图像，但常出现数据记忆问题，导致生成样本不一致或缺乏多样性，可能无法改善甚至损害下游模型的性能。

Method: 该研究引入了“外科应用对齐扩散”（SAADi）框架。它通过构建“偏好”和“非偏好”合成图像对，并对扩散模型进行轻量级微调，使图像生成过程与下游目标明确对齐。此外，还采用了合成样本的迭代细化。

Result: 在三个外科手术数据集上，分类任务实现了7-9%的持续增益，分割任务实现了2-10%的持续增益，尤其在代表性不足的类别上观察到显著改进。合成样本的迭代细化进一步将性能提升了4-10%。与基线方法不同，SAADi克服了样本退化问题。

Conclusion: SAADi通过建立任务感知对齐作为关键原则，有效缓解了数据稀缺问题，并推动了外科视觉应用的发展，成功解决了现有方法中样本退化的问题。

Abstract: The scarcity of annotated surgical data poses a significant challenge for
developing deep learning systems in computer-assisted interventions. While
diffusion models can synthesize realistic images, they often suffer from data
memorization, resulting in inconsistent or non-diverse samples that may fail to
improve, or even harm, downstream performance. We introduce \emph{Surgical
Application-Aligned Diffusion} (SAADi), a new framework that aligns diffusion
models with samples preferred by downstream models. Our method constructs pairs
of \emph{preferred} and \emph{non-preferred} synthetic images and employs
lightweight fine-tuning of diffusion models to align the image generation
process with downstream objectives explicitly. Experiments on three surgical
datasets demonstrate consistent gains of $7$--$9\%$ in classification and
$2$--$10\%$ in segmentation tasks, with the considerable improvements observed
for underrepresented classes. Iterative refinement of synthetic samples further
boosts performance by $4$--$10\%$. Unlike baseline approaches, our method
overcomes sample degradation and establishes task-aware alignment as a key
principle for mitigating data scarcity and advancing surgical vision
applications.

</details>


### [131] [Surgical Video Understanding with Label Interpolation](https://arxiv.org/abs/2509.18802)
*Garam Kim,Tae Kyeong Jeong,Juyoun Park*

Main category: cs.CV

TL;DR: 为解决机器人辅助手术中视觉数据理解的挑战，本文提出了一种结合光流分割标签插值与多任务学习的新框架，以应对标注稀疏和时空不平衡问题，从而提高手术场景理解的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助手术（RAS）需要精确理解手术过程中的视觉数据。现有研究多关注单一任务，但真实手术场景复杂且动态。多任务学习（MTL）需要大量的像素级分割数据，但标注成本高昂且专业性强。特别是，长时程标注（如阶段、步骤）适用于所有帧，而短时程标注（如器械分割、动作检测）仅限于关键帧，导致显著的时空不平衡。

Method: 本文提出一个新颖的框架，将基于光流的分割标签插值与多任务学习相结合。利用从已标注关键帧估计的光流，将标签传播到相邻的未标注帧，以此丰富稀疏的空间监督，并平衡训练所需的时空信息。

Result: 这种集成方法提高了手术场景理解的准确性和效率。

Conclusion: 通过改善手术场景理解，该方法增强了机器人辅助手术的实用性。

Abstract: Robot-assisted surgery (RAS) has become a critical paradigm in modern
surgery, promoting patient recovery and reducing the burden on surgeons through
minimally invasive approaches. To fully realize its potential, however, a
precise understanding of the visual data generated during surgical procedures
is essential. Previous studies have predominantly focused on single-task
approaches, but real surgical scenes involve complex temporal dynamics and
diverse instrument interactions that limit comprehensive understanding.
Moreover, the effective application of multi-task learning (MTL) requires
sufficient pixel-level segmentation data, which are difficult to obtain due to
the high cost and expertise required for annotation. In particular, long-term
annotations such as phases and steps are available for every frame, whereas
short-term annotations such as surgical instrument segmentation and action
detection are provided only for key frames, resulting in a significant
temporal-spatial imbalance. To address these challenges, we propose a novel
framework that combines optical flow-based segmentation label interpolation
with multi-task learning. optical flow estimated from annotated key frames is
used to propagate labels to adjacent unlabeled frames, thereby enriching sparse
spatial supervision and balancing temporal and spatial information for
training. This integration improves both the accuracy and efficiency of
surgical scene understanding and, in turn, enhances the utility of RAS.

</details>


### [132] [Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation](https://arxiv.org/abs/2509.18824)
*Yanzuo Lu,Xin Xia,Manlin Zhang,Huafeng Kuang,Jianbin Zheng,Yuxi Ren,Xuefeng Xiao*

Main category: cs.CV

TL;DR: Hyper-Bagel是一个统一加速框架，通过推测解码和多阶段蒸馏，显著加速了多模态理解和生成任务，同时保持了输出质量。


<details>
  <summary>Details</summary>
Motivation: 统一多模态模型在理解和生成多样内容方面表现出色，但扩散去噪和自回归解码的迭代过程在处理大量交错多模态token时会产生显著的计算开销。

Method: 该方法采用分治策略，使用推测解码进行下一token预测，并采用多阶段蒸馏过程进行扩散去噪。此外，还结合了先进的对抗性蒸馏和人类反馈学习，以开发高效的1-NFE模型。

Result: Hyper-Bagel在多模态理解方面实现了超过2倍的加速。在生成任务中，无损6-NFE模型在文本到图像生成中实现了16.67倍加速，在图像编辑中实现了22倍加速，同时保持了原始模型的高质量输出。高效的1-NFE模型实现了近乎实时的交互式编辑和生成，具备极高的成本效益和响应速度。

Conclusion: Hyper-Bagel框架成功解决了多模态模型中的计算开销问题，通过显著加速理解和生成任务，同时保持高输出质量，实现了无缝且即时的复杂多模态交互。

Abstract: Unified multimodal models have recently attracted considerable attention for
their remarkable abilities in jointly understanding and generating diverse
content. However, as contexts integrate increasingly numerous interleaved
multimodal tokens, the iterative processes of diffusion denoising and
autoregressive decoding impose significant computational overhead. To address
this, we propose Hyper-Bagel, a unified acceleration framework designed to
simultaneously speed up both multimodal understanding and generation tasks. Our
approach uses a divide-and-conquer strategy, employing speculative decoding for
next-token prediction and a multi-stage distillation process for diffusion
denoising. The framework delivers substantial performance gains, achieving over
a 2x speedup in multimodal understanding. For generative tasks, our resulting
lossless 6-NFE model yields a 16.67x speedup in text-to-image generation and a
22x speedup in image editing, all while preserving the high-quality output of
the original model. We further develop a highly efficient 1-NFE model that
enables near real-time interactive editing and generation. By combining
advanced adversarial distillation with human feedback learning, this model
achieves ultimate cost-effectiveness and responsiveness, making complex
multimodal interactions seamless and instantaneous.

</details>


### [133] [Benchmarking Vision-Language and Multimodal Large Language Models in Zero-shot and Few-shot Scenarios: A study on Christian Iconography](https://arxiv.org/abs/2509.18839)
*Gianmarco Spinaci,Lukas Klic,Giovanni Colavizza*

Main category: cs.CV

TL;DR: 本研究评估了多模态大语言模型（MLLMs）和视觉语言模型（VLMs）在基督教圣像单标签分类任务中的能力，发现GPT-4o和Gemini-2.5 Pro表现优于ResNet50基线模型，表明它们在视觉复杂文化遗产领域具有分类潜力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在评估通用型VLMs（如CLIP和SigLIP）和LLMs（如GPT-4o和Gemini 2.5）是否能够解释通常由监督分类器处理的基督教圣像学，并评估它们的性能。

Method: 研究进行了一项基准测试，使用了三个原生支持Iconclass的数据集（ArtDL、ICONCLASS和Wikidata），并筛选出前10个最常见的类别。模型在三种条件下进行测试：(1) 使用类别标签分类，(2) 使用Iconclass描述分类，(3) 使用五个范例进行少样本学习。结果与在相同数据集上微调的ResNet50基线进行了比较。研究回答了两个问题：多模态LLMs在基督教圣像图像分类上的表现如何？以及当输入富含上下文信息或少样本示例时，性能如何变化？

Result: Gemini-2.5 Pro和GPT-4o的表现优于ResNet50基线。在Wikidata数据集上准确率显著下降，SigLIP在该数据集上达到最高准确率，表明模型对图像大小和元数据对齐的敏感性。用类别描述丰富提示通常能提高零样本性能，而少样本学习则产生了较低的结果，仅偶尔有微小准确率提升。

Conclusion: 通用型多模态LLMs能够对视觉复杂的文化遗产领域进行分类。这些结果支持将LLMs作为数字人文工作流程中的元数据整理工具，并建议未来研究进行提示优化以及将研究扩展到其他分类策略和模型。

Abstract: This study evaluates the capabilities of Multimodal Large Language Models
(LLMs) and Vision Language Models (VLMs) in the task of single-label
classification of Christian Iconography. The goal was to assess whether
general-purpose VLMs (CLIP and SigLIP) and LLMs, such as GPT-4o and Gemini 2.5,
can interpret the Iconography, typically addressed by supervised classifiers,
and evaluate their performance. Two research questions guided the analysis:
(RQ1) How do multimodal LLMs perform on image classification of Christian
saints? And (RQ2), how does performance vary when enriching input with
contextual information or few-shot exemplars? We conducted a benchmarking study
using three datasets supporting Iconclass natively: ArtDL, ICONCLASS, and
Wikidata, filtered to include the top 10 most frequent classes. Models were
tested under three conditions: (1) classification using class labels, (2)
classification with Iconclass descriptions, and (3) few-shot learning with five
exemplars. Results were compared against ResNet50 baselines fine-tuned on the
same datasets. The findings show that Gemini-2.5 Pro and GPT-4o outperformed
the ResNet50 baselines. Accuracy dropped significantly on the Wikidata dataset,
where Siglip reached the highest accuracy score, suggesting model sensitivity
to image size and metadata alignment. Enriching prompts with class descriptions
generally improved zero-shot performance, while few-shot learning produced
lower results, with only occasional and minimal increments in accuracy. We
conclude that general-purpose multimodal LLMs are capable of classification in
visually complex cultural heritage domains. These results support the
application of LLMs as metadata curation tools in digital humanities workflows,
suggesting future research on prompt optimization and the expansion of the
study to other classification strategies and models.

</details>


### [134] [ViG-LRGC: Vision Graph Neural Networks with Learnable Reparameterized Graph Construction](https://arxiv.org/abs/2509.18840)
*Ismael Elsharkawi,Hossam Sharara,Ahmed Rafea*

Main category: cs.CV

TL;DR: 本文提出了一种名为可学习重参数化图构建（LRGC）的新方法，用于视觉图神经网络（ViG）中的图像表示学习。LRGC通过键-查询注意力机制和可微分的软阈值重参数化实现可学习、无需超参数的图构建，解决了现有ViG模型图构建方法的局限性，并在ImageNet-1k数据集上超越了现有先进的ViG模型。


<details>
  <summary>Details</summary>
Motivation: 图像表示学习是计算机视觉中的一个重要问题。虽然ViG将图像视为节点图提供了一种更直观的表示，但现有的ViG模型在图构建方面存在挑战。它们依赖于非参数化、不可学习的统计方法（如k-NN、超图构建等），这些方法可能无法选择最佳的节点邻域，缺乏提供可学习、无超参数图构建的能力，并且需要超参数搜索。

Method: 本文提出了可学习重参数化图构建（LRGC）方法。LRGC在每对节点之间应用键-查询注意力机制，然后利用软阈值重参数化进行边选择，这使得训练能够使用可微分的数学模型。通过可学习参数来选择邻域，消除了传统聚类或阈值方法引入的偏差。此外，LRGC允许在每个层中根据训练数据调整阈值，因为阈值是通过训练学习的，而不是作为超参数提供给模型。

Result: 所提出的ViG-LRGC方法在ImageNet-1k基准数据集上，性能优于同等规模的现有最先进的ViG模型。

Conclusion: LRGC成功解决了ViG中图构建的挑战，提供了一种可学习、无超参数的图构建方法。它通过键-查询注意力机制和软阈值重参数化实现了可微分的训练，并允许每层自适应地学习阈值，从而提高了图像表示学习的性能。

Abstract: Image Representation Learning is an important problem in Computer Vision.
Traditionally, images were processed as grids, using Convolutional Neural
Networks or as a sequence of visual tokens, using Vision Transformers.
Recently, Vision Graph Neural Networks (ViG) have proposed the treatment of
images as a graph of nodes; which provides a more intuitive image
representation. The challenge is to construct a graph of nodes in each layer
that best represents the relations between nodes and does not need a
hyper-parameter search. ViG models in the literature depend on
non-parameterized and non-learnable statistical methods that operate on the
latent features of nodes to create a graph. This might not select the best
neighborhood for each node. Starting from k-NN graph construction to HyperGraph
Construction and Similarity-Thresholded graph construction, these methods lack
the ability to provide a learnable hyper-parameter-free graph construction
method. To overcome those challenges, we present the Learnable Reparameterized
Graph Construction (LRGC) for Vision Graph Neural Networks. LRGC applies
key-query attention between every pair of nodes; then uses soft-threshold
reparameterization for edge selection, which allows the use of a differentiable
mathematical model for training. Using learnable parameters to select the
neighborhood removes the bias that is induced by any clustering or thresholding
methods previously introduced in the literature. In addition, LRGC allows
tuning the threshold in each layer to the training data since the thresholds
are learnable through training and are not provided as hyper-parameters to the
model. We demonstrate that the proposed ViG-LRGC approach outperforms
state-of-the-art ViG models of similar sizes on the ImageNet-1k benchmark
dataset.

</details>


### [135] [Attack for Defense: Adversarial Agents for Point Prompt Optimization Empowering Segment Anything Model](https://arxiv.org/abs/2509.18891)
*Xueyu Liu,Xiaoyi Zhang,Guangze Shi,Meilin Liu,Yexin Lai,Yongfei Wu,Mingqiang Wei*

Main category: cs.CV

TL;DR: 本文提出Point Prompt Defender，一个对抗性强化学习框架，通过攻击-防御范式自动优化点提示，以提升Segment Anything Model (SAM)的分割性能、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: SAM的性能严重依赖提示质量，但现有方法多依赖启发式或手动制作的提示，限制了其可扩展性和泛化性。

Method: 构建了一个任务无关的点提示环境，将图像块表示为双空间图中的节点。攻击者智能体学习激活最大程度降低SAM分割性能的提示子集，而防御者智能体学习抑制这些破坏性提示并恢复准确性。两个智能体都使用Deep Q-Networks进行训练，奖励信号基于分割质量的变化。推理时只部署防御者来优化粗略提示集。

Result: Point Prompt Defender有效提高了SAM的鲁棒性和泛化能力，在不重新训练的情况下增强了SAM在各种任务中的分割性能。

Conclusion: 该框架为基于提示的分割提供了一个灵活、可解释且即插即用的解决方案。

Abstract: Prompt quality plays a critical role in the performance of the Segment
Anything Model (SAM), yet existing approaches often rely on heuristic or
manually crafted prompts, limiting scalability and generalization. In this
paper, we propose Point Prompt Defender, an adversarial reinforcement learning
framework that adopts an attack-for-defense paradigm to automatically optimize
point prompts. We construct a task-agnostic point prompt environment by
representing image patches as nodes in a dual-space graph, where edges encode
both physical and semantic distances. Within this environment, an attacker
agent learns to activate a subset of prompts that maximally degrade SAM's
segmentation performance, while a defender agent learns to suppress these
disruptive prompts and restore accuracy. Both agents are trained using Deep
Q-Networks with a reward signal based on segmentation quality variation. During
inference, only the defender is deployed to refine arbitrary coarse prompt
sets, enabling enhanced SAM segmentation performance across diverse tasks
without retraining. Extensive experiments show that Point Prompt Defender
effectively improves SAM's robustness and generalization, establishing a
flexible, interpretable, and plug-and-play framework for prompt-based
segmentation.

</details>


### [136] [SmartWilds: Multimodal Wildlife Monitoring Dataset](https://arxiv.org/abs/2509.18894)
*Jenna Kline,Anirudh Potlapally,Bharath Pillai,Tanishka Wani,Rugved Katole,Vedant Patil,Penelope Covey,Hari Subramoni,Tanya Berger-Wolf,Christopher Stewart*

Main category: cs.CV

TL;DR: SmartWilds是首个多模态野生动物监测数据集，同步整合了无人机图像、相机陷阱照片/视频和生物声学记录，旨在支持全面的环境监测和保护AI研究。


<details>
  <summary>Details</summary>
Motivation: 现有研究在濒危物种、生态保护和栖息地管理方面存在关键需求，需要更全面的环境监测方法，而多模态AI研究可以提供支持。

Method: 数据集于2025年夏季在俄亥俄州The Wilds野生动物园收集，进行为期四天的同步监测。它在220英亩的牧场上，通过无人机影像、相机陷阱（照片和视频）以及生物声学记录三种模态，捕捉了多种动物的数据。

Result: 研究展示了不同传感器模态在土地利用模式、物种检测、行为分析和栖息地监测方面的互补优势。同时，建立了可复现的多模态野生动物监测协议，并贡献了开放数据集。

Conclusion: SmartWilds数据集及其协议为推进保护计算机视觉研究做出了贡献。未来的版本将进一步扩展，包括GPS追踪数据、公民科学数据和更长的监测时间跨度。

Abstract: We present the first release of SmartWilds, a multimodal wildlife monitoring
dataset. SmartWilds is a synchronized collection of drone imagery, camera trap
photographs and videos, and bioacoustic recordings collected during summer 2025
at The Wilds safari park in Ohio. This dataset supports multimodal AI research
for comprehensive environmental monitoring, addressing critical needs in
endangered species research, conservation ecology, and habitat management. Our
pilot deployment captured four days of synchronized monitoring across three
modalities in a 220-acre pasture containing Pere David's deer, Sichuan takin,
Przewalski's horses, as well as species native to Ohio, including bald eagles,
white-tailed deer, and coyotes. We provide a comparative analysis of sensor
modality performance, demonstrating complementary strengths for landuse
patterns, species detection, behavioral analysis, and habitat monitoring. This
work establishes reproducible protocols for multimodal wildlife monitoring
while contributing open datasets to advance conservation computer vision
research. Future releases will include synchronized GPS tracking data from
tagged individuals, citizen science data, and expanded temporal coverage across
multiple seasons.

</details>


### [137] [RS3DBench: A Comprehensive Benchmark for 3D Spatial Perception in Remote Sensing](https://arxiv.org/abs/2509.18897)
*Jiayu Wang,Ruizhi Wang,Jie Song,Haofei Zhang,Mingli Song,Zunlei Feng,Li Sun*

Main category: cs.CV

TL;DR: 本文提出了一个名为RS3DBench的新型遥感图像3D理解基准数据集，包含大量对齐的遥感图像和深度图，并引入了一个基于稳定扩散的遥感深度估计模型，在该数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感数据集普遍缺乏全面的深度信息，或者深度数据与遥感图像的对齐精度不足，阻碍了通用、大规模遥感3D视觉模型的发展。

Method: 研究者构建了RS3DBench数据集，包含54,951对像素级对齐的遥感图像和深度图，并附带文本描述。此外，他们还提出了一个利用稳定扩散多模态融合能力的遥感深度估计模型。

Result: RS3DBench数据集为遥感图像空间理解任务中的3D视觉感知模型训练和评估提供了工具。所提出的基于稳定扩散的深度估计模型在该数据集上实现了最先进的性能。

Conclusion: 这项工作旨在为遥感领域3D视觉感知模型的发展和地理人工智能的进步做出重要贡献，并提供了数据集、模型和代码供访问。

Abstract: In this paper, we introduce a novel benchmark designed to propel the
advancement of general-purpose, large-scale 3D vision models for remote sensing
imagery. While several datasets have been proposed within the realm of remote
sensing, many existing collections either lack comprehensive depth information
or fail to establish precise alignment between depth data and remote sensing
images. To address this deficiency, we present a visual Benchmark for 3D
understanding of Remotely Sensed images, dubbed RS3DBench. This dataset
encompasses 54,951 pairs of remote sensing images and pixel-level aligned depth
maps, accompanied by corresponding textual descriptions, spanning a broad array
of geographical contexts. It serves as a tool for training and assessing 3D
visual perception models within remote sensing image spatial understanding
tasks. Furthermore, we introduce a remotely sensed depth estimation model
derived from stable diffusion, harnessing its multimodal fusion capabilities,
thereby delivering state-of-the-art performance on our dataset. Our endeavor
seeks to make a profound contribution to the evolution of 3D visual perception
models and the advancement of geographic artificial intelligence within the
remote sensing domain. The dataset, models and code will be accessed on the
https://rs3dbench.github.io.

</details>


### [138] [DeblurSplat: SfM-free 3D Gaussian Splatting with Event Camera for Robust Deblurring](https://arxiv.org/abs/2509.18898)
*Pengteng Li,Yunfan Lu,Pinhao Song,Weiyu Guo,Huizai Yao,F. Richard Yu,Hui Xiong*

Main category: cs.CV

TL;DR: 本文提出首个无SfM的事件相机去模糊3D高斯泼溅方法DeblurSplat，通过直接生成点云和利用事件流提供精细监督，实现高质量新视图生成和高渲染效率。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯泼溅中的运动去模糊问题，特别是避免传统SfM方法中因不准确相机姿态导致的累积误差传递到初始点云。

Method: 1. 利用预训练的密集立体模块DUSt3R直接从模糊图像获取准确初始点云，跳过相机姿态计算。2. 引入事件相机流，利用其对动态变化的敏感性。3. 从事件流和模糊图像中解码潜在清晰图像，为场景重建优化提供精细监督信号。

Result: DeblurSplat在各种场景下都能生成高保真度的新颖视图，并且与当前最先进的去模糊3D-GS方法相比，显著提高了渲染效率。

Conclusion: DeblurSplat是一种有效且高效的、无需SfM的事件相机去模糊3D高斯泼溅方法，在生成质量和渲染效率方面均表现出色。

Abstract: In this paper, we propose the first Structure-from-Motion (SfM)-free
deblurring 3D Gaussian Splatting method via event camera, dubbed DeblurSplat.
We address the motion-deblurring problem in two ways. First, we leverage the
pretrained capability of the dense stereo module (DUSt3R) to directly obtain
accurate initial point clouds from blurred images. Without calculating camera
poses as an intermediate result, we avoid the cumulative errors transfer from
inaccurate camera poses to the initial point clouds' positions. Second, we
introduce the event stream into the deblur pipeline for its high sensitivity to
dynamic change. By decoding the latent sharp images from the event stream and
blurred images, we can provide a fine-grained supervision signal for scene
reconstruction optimization. Extensive experiments across a range of scenes
demonstrate that DeblurSplat not only excels in generating high-fidelity novel
views but also achieves significant rendering efficiency compared to the SOTAs
in deblur 3D-GS.

</details>


### [139] [MoiréNet: A Compact Dual-Domain Network for Image Demoiréing](https://arxiv.org/abs/2509.18910)
*Shuwei Guo,Simin Luan,Yan Ke,Zeyd Boukhers,John See,Cong Yang*

Main category: cs.CV

TL;DR: MoiréNet是一个基于U-Net的卷积神经网络框架，它结合了频率和空间域特征，通过引入定向频率-空间编码器（DFSE）和频率-空间自适应选择器（FSAS），实现了对莫尔条纹的有效去除，同时保持了高参数效率和最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 莫尔条纹是显示器像素点阵和相机传感器网格之间频谱混叠产生的各向异性、多尺度伪影，对数字图像去莫尔条纹提出了重大挑战。

Method: 该研究提出了MoiréNet，一个基于U-Net的卷积神经网络框架，它协同整合了频率和空间域特征。MoiréNet引入了两个关键组件：1) 定向频率-空间编码器（DFSE），通过定向差分卷积识别莫尔条纹方向；2) 频率-空间自适应选择器（FSAS），实现精确的、特征自适应的抑制。

Result: MoiréNet在公共和活跃使用的数据集上取得了最先进的性能，并且具有很高的参数效率。它仅有5.513M参数，比ESDNet-L减少了48%，在提供卓越修复质量的同时，也实现了参数效率。

Conclusion: MoiréNet结合了卓越的修复质量和参数效率，非常适合资源受限的应用，包括智能手机摄影、工业成像和增强现实等。

Abstract: Moir\'e patterns arise from spectral aliasing between display pixel lattices
and camera sensor grids, manifesting as anisotropic, multi-scale artifacts that
pose significant challenges for digital image demoir\'eing. We propose
Moir\'eNet, a convolutional neural U-Net-based framework that synergistically
integrates frequency and spatial domain features for effective artifact
removal. Moir\'eNet introduces two key components: a Directional
Frequency-Spatial Encoder (DFSE) that discerns moir\'e orientation via
directional difference convolution, and a Frequency-Spatial Adaptive Selector
(FSAS) that enables precise, feature-adaptive suppression. Extensive
experiments demonstrate that Moir\'eNet achieves state-of-the-art performance
on public and actively used datasets while being highly parameter-efficient.
With only 5.513M parameters, representing a 48% reduction compared to ESDNet-L,
Moir\'eNet combines superior restoration quality with parameter efficiency,
making it well-suited for resource-constrained applications including
smartphone photography, industrial imaging, and augmented reality.

</details>


### [140] [Frequency-Domain Decomposition and Recomposition for Robust Audio-Visual Segmentation](https://arxiv.org/abs/2509.18912)
*Yunzhe Shen,Kai Peng,Leiye Liu,Wei Ji,Jingjing Li,Miao Zhang,Yongri Piao,Huchuan Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为FAVS的频率感知音视频分割框架，通过将AVS任务重新定义为频域分解和重组问题，解决了音视频模态间固有的频域矛盾，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有音视频分割（AVS）方法忽视了音视频模态在频域上的固有矛盾，即音频高频信号中普遍存在的干扰噪声与视觉高频信号中丰富的结构细节之间的差异。忽略这些差异可能导致次优的性能。

Method: 本文将AVS任务重新定义为频域分解和重组问题，并提出了频率感知音视频分割（FAVS）框架。该框架包含两个核心模块：
1.  **频域增强分解器（FDED）模块**：采用基于残差的迭代频率分解来区分模态特定的语义和结构特征。
2.  **协同跨模态一致性（SCMC）模块**：利用混合专家架构，通过动态专家路由来增强语义一致性并保留模态特定特征。

Result: FAVS框架在三个基准数据集上取得了最先进的性能。大量的定性可视化结果进一步验证了所提出的FDED和SCMC模块的有效性。

Conclusion: 本文提出的FAVS框架通过解决音视频模态固有的频域矛盾，显著提升了音视频分割任务的性能，并为多模态学习中的频率处理提供了新的视角。

Abstract: Audio-visual segmentation (AVS) plays a critical role in multimodal machine
learning by effectively integrating audio and visual cues to precisely segment
objects or regions within visual scenes. Recent AVS methods have demonstrated
significant improvements. However, they overlook the inherent frequency-domain
contradictions between audio and visual modalities--the pervasively interfering
noise in audio high-frequency signals vs. the structurally rich details in
visual high-frequency signals. Ignoring these differences can result in
suboptimal performance. In this paper, we rethink the AVS task from a deeper
perspective by reformulating AVS task as a frequency-domain decomposition and
recomposition problem. To this end, we introduce a novel Frequency-Aware
Audio-Visual Segmentation (FAVS) framework consisting of two key modules:
Frequency-Domain Enhanced Decomposer (FDED) module and Synergistic Cross-Modal
Consistency (SCMC) module. FDED module employs a residual-based iterative
frequency decomposition to discriminate modality-specific semantics and
structural features, and SCMC module leverages a mixture-of-experts
architecture to reinforce semantic consistency and modality-specific feature
preservation through dynamic expert routing. Extensive experiments demonstrate
that our FAVS framework achieves state-of-the-art performance on three
benchmark datasets, and abundant qualitative visualizations further verify the
effectiveness of the proposed FDED and SCMC modules. The code will be released
as open source upon acceptance of the paper.

</details>


### [141] [xAI-CV: An Overview of Explainable Artificial Intelligence in Computer Vision](https://arxiv.org/abs/2509.18913)
*Nguyen Van Tu,Pham Nguyen Hai Long,Vo Hoai Viet*

Main category: cs.CV

TL;DR: 本文综述了四种在视觉感知任务中常用的可解释人工智能（xAI）方法，分析了它们的机制、优缺点和评估指标，旨在指导未来研究和应用。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在图像分析中表现出色，但其“黑箱”特性使得决策过程难以理解，在关键应用中引发可靠性担忧。xAI的出现旨在解决这一挑战，帮助人类理解AI模型的工作方式。

Method: 本文通过调查和分析四种代表性的xAI方法（显著性图、概念瓶颈模型、基于原型的方法和混合方法）在视觉感知任务中的应用，来完成研究。

Result: 本文分析了这些xAI方法的基本机制、优势、局限性以及评估指标，提供了一个全面的概览。

Conclusion: 该综述为未来xAI在视觉感知任务中的研究和应用提供了指导。

Abstract: Deep learning has become the de facto standard and dominant paradigm in image
analysis tasks, achieving state-of-the-art performance. However, this approach
often results in "black-box" models, whose decision-making processes are
difficult to interpret, raising concerns about reliability in critical
applications. To address this challenge and provide human a method to
understand how AI model process and make decision, the field of xAI has
emerged. This paper surveys four representative approaches in xAI for visual
perception tasks: (i) Saliency Maps, (ii) Concept Bottleneck Models (CBM),
(iii) Prototype-based methods, and (iv) Hybrid approaches. We analyze their
underlying mechanisms, strengths and limitations, as well as evaluation
metrics, thereby providing a comprehensive overview to guide future research
and applications.

</details>


### [142] [Advancing Metallic Surface Defect Detection via Anomaly-Guided Pretraining on a Large Industrial Dataset](https://arxiv.org/abs/2509.18919)
*Chuni Liu,Hongjie Li,Jiaqi Du,Yangyang Hou,Qian Sun,Lei Jin,Ke Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为异常引导自监督预训练 (AGSSP) 的新范式，通过异常先验显式指导表示学习，解决了金属表面缺陷检测中预训练面临的领域差距和细微缺陷难以识别的问题，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 金属表面缺陷检测中，预训练-微调范式因数据稀缺而重要。然而，在ImageNet等自然图像数据集上预训练存在显著领域差距；而在领域内工业数据上进行朴素自监督预训练则效果不佳，现有学习目标难以区分细微缺陷模式与复杂背景噪声和纹理。

Method: 本文提出了异常引导自监督预训练 (AGSSP)，该方法包含两个阶段：1) 通过从异常图中蒸馏知识来预训练模型骨干网络，促使网络捕获缺陷显著特征；2) 使用从异常图导出的伪缺陷框预训练检测器，使其与定位任务对齐。为此，开发了一种知识增强方法来生成高质量异常图，并收集了一个包含120,000张图像的大规模工业数据集，同时提供了两个小规模、像素级标注的金属表面缺陷数据集用于验证。

Result: 广泛的实验表明，AGSSP在各种设置下持续提升性能，与基于ImageNet的模型相比，mAP@0.5提升高达10%，mAP@0.5:0.95提升高达11.4%。

Conclusion: AGSSP通过异常先验显式指导表示学习，成功解决了金属表面缺陷检测中预训练的困境，显著提高了检测性能。所有代码、预训练模型和数据集均已公开。

Abstract: The pretraining-finetuning paradigm is a crucial strategy in metallic surface
defect detection for mitigating the challenges posed by data scarcity. However,
its implementation presents a critical dilemma. Pretraining on natural image
datasets such as ImageNet, faces a significant domain gap. Meanwhile, naive
self-supervised pretraining on in-domain industrial data is often ineffective
due to the inability of existing learning objectives to distinguish subtle
defect patterns from complex background noise and textures. To resolve this, we
introduce Anomaly-Guided Self-Supervised Pretraining (AGSSP), a novel paradigm
that explicitly guides representation learning through anomaly priors. AGSSP
employs a two-stage framework: (1) it first pretrains the model's backbone by
distilling knowledge from anomaly maps, encouraging the network to capture
defect-salient features; (2) it then pretrains the detector using pseudo-defect
boxes derived from these maps, aligning it with localization tasks. To enable
this, we develop a knowledge-enhanced method to generate high-quality anomaly
maps and collect a large-scale industrial dataset of 120,000 images.
Additionally, we present two small-scale, pixel-level labeled metallic surface
defect datasets for validation. Extensive experiments demonstrate that AGSSP
consistently enhances performance across various settings, achieving up to a
10\% improvement in mAP@0.5 and 11.4\% in mAP@0.5:0.95 compared to
ImageNet-based models. All code, pretrained models, and datasets are publicly
available at https://clovermini.github.io/AGSSP-Dev/.

</details>


### [143] [Audio-Driven Universal Gaussian Head Avatars](https://arxiv.org/abs/2509.18924)
*Kartik Teotia,Helge Rhodin,Mohit Mendiratta,Hyeongwoo Kim,Marc Habermann,Christian Theobalt*

Main category: cs.CV

TL;DR: 该研究提出了一种首个音频驱动的通用逼真头像合成方法，结合了与人无关的语音模型和新型通用头部头像先验（UHAP），能够同时捕捉几何和外观变化，生成高度逼真的头像。


<details>
  <summary>Details</summary>
Motivation: 以往的方法主要将音频特征映射到几何变形，却忽略了与音频相关的外观变化。因此，需要一种能够考虑详细外观建模和渲染的、可泛化的音频驱动头像模型。

Method: 该方法引入了通用头部头像先验（UHAP），其在跨身份多视角视频上进行训练，并利用中性扫描数据进行监督，以高保真度捕获身份特定细节。一个通用的语音模型将原始音频输入直接映射到UHAP的潜在表情空间，该空间固有地编码了几何和外观变化。为了高效地对新主体进行个性化，采用单目编码器回归动态表情变化，使后续模型微调专注于捕捉主体的全局外观和几何。通过UHAP解码这些音频驱动的表情代码来生成头像。

Result: 该方法生成了高度逼真的头像，具有精确的唇部同步和细致的表情细节，如眉毛运动、凝视转移以及逼真的口腔内部外观和运动。它是首个能够进行详细外观建模和渲染的可泛化音频驱动头像模型，并且在唇部同步准确性、定量图像质量和感知真实感方面，优于现有的（仅几何）竞争方法。

Conclusion: 该研究成功地提出了一种通用、音频驱动的逼真头像合成方法，该方法能够处理详细的外观建模和渲染，并在唇部同步准确性、图像质量和感知真实感方面超越了现有方法。

Abstract: We introduce the first method for audio-driven universal photorealistic
avatar synthesis, combining a person-agnostic speech model with our novel
Universal Head Avatar Prior (UHAP). UHAP is trained on cross-identity
multi-view videos. In particular, our UHAP is supervised with neutral scan
data, enabling it to capture the identity-specific details at high fidelity. In
contrast to previous approaches, which predominantly map audio features to
geometric deformations only while ignoring audio-dependent appearance
variations, our universal speech model directly maps raw audio inputs into the
UHAP latent expression space. This expression space inherently encodes, both,
geometric and appearance variations. For efficient personalization to new
subjects, we employ a monocular encoder, which enables lightweight regression
of dynamic expression variations across video frames. By accounting for these
expression-dependent changes, it enables the subsequent model fine-tuning stage
to focus exclusively on capturing the subject's global appearance and geometry.
Decoding these audio-driven expression codes via UHAP generates highly
realistic avatars with precise lip synchronization and nuanced expressive
details, such as eyebrow movement, gaze shifts, and realistic mouth interior
appearance as well as motion. Extensive evaluations demonstrate that our method
is not only the first generalizable audio-driven avatar model that can account
for detailed appearance modeling and rendering, but it also outperforms
competing (geometry-only) methods across metrics measuring lip-sync accuracy,
quantitative image quality, and perceptual realism.

</details>


### [144] [SynapFlow: A Modular Framework Towards Large-Scale Analysis of Dendritic Spines](https://arxiv.org/abs/2509.18926)
*Pamela Osuna-Vargas,Altug Kamacioglu,Dominik F. Aschauer,Petros E. Vlachos,Sercan Alipek,Jochen Triesch,Simon Rumpel,Matthias Kaschube*

Main category: cs.CV

TL;DR: 该论文提出了一个模块化的机器学习流程，用于自动化检测、时间追踪和提取3D+时间显微镜数据中的树突棘特征，以实现对学习和记忆神经基础的大规模分析。


<details>
  <summary>Details</summary>
Motivation: 树突棘是兴奋性突触的关键结构，其大小反映突触效能。检测和追踪树突棘对于研究学习和记忆的神经基础至关重要。然而，对3D+时间显微镜数据中树突棘结构动力学的大规模分析仍然具有挑战性且劳动密集。

Method: 本文提出一个模块化的机器学习流程，包含：基于Transformer的检测模块、整合空间特征的深度追踪组件、利用空间一致性关联3D树突棘的时间追踪模块，以及量化生物学相关棘特性的特征提取单元。该方法在开源标记数据和两个新发布的互补注释数据集（一个用于检测和深度追踪，一个用于时间追踪）上进行了验证。

Result: 该方法在开源标记树突棘数据以及两个新发布的注释数据集上得到了验证，其中包括首次发布的时间追踪数据集。研究团队还发布了数据、代码和预训练权重，为树突棘动力学的可扩展、端到端分析建立了基线。

Conclusion: 该研究提供了一个可扩展、端到端的树突棘动力学分析基线，通过自动化检测、追踪和特征提取过程，解决了大规模分析的挑战，并鼓励未来的相关研究。

Abstract: Dendritic spines are key structural components of excitatory synapses in the
brain. Given the size of dendritic spines provides a proxy for synaptic
efficacy, their detection and tracking across time is important for studies of
the neural basis of learning and memory. Despite their relevance, large-scale
analyses of the structural dynamics of dendritic spines in 3D+time microscopy
data remain challenging and labor-intense. Here, we present a modular machine
learning-based pipeline designed to automate the detection, time-tracking, and
feature extraction of dendritic spines in volumes chronically recorded with
two-photon microscopy. Our approach tackles the challenges posed by biological
data by combining a transformer-based detection module, a depth-tracking
component that integrates spatial features, a time-tracking module to associate
3D spines across time by leveraging spatial consistency, and a feature
extraction unit that quantifies biologically relevant spine properties. We
validate our method on open-source labeled spine data, and on two complementary
annotated datasets that we publish alongside this work: one for detection and
depth-tracking, and one for time-tracking, which, to the best of our knowledge,
is the first data of this kind. To encourage future research, we release our
data, code, and pre-trained weights at
https://github.com/pamelaosuna/SynapFlow, establishing a baseline for scalable,
end-to-end analysis of dendritic spine dynamics.

</details>


### [145] [Seeing Through Reflections: Advancing 3D Scene Reconstruction in Mirror-Containing Environments with Gaussian Splatting](https://arxiv.org/abs/2509.18956)
*Zijing Guo,Yunyang Zhao,Lin Wang*

Main category: cs.CV

TL;DR: 该研究提出了MirrorScene3D数据集和ReflectiveGS方法，用于解决镜面环境中3D重建和新视角合成的挑战，通过将镜面反射视为互补视角来增强重建质量。


<details>
  <summary>Details</summary>
Motivation: NeRF和3DGS等先进方法在镜面环境中性能下降，因为反射表面引入了视角依赖的失真和不一致。现有解决方案主要通过对称映射处理镜面，但忽视了镜面反射所携带的丰富信息（即互补视角），这些信息可以填补缺失细节并显著提高重建质量。

Method: 1. 构建了MirrorScene3D数据集：包含多样化的室内场景、1256张高质量图像和标注的镜面掩码，作为评估反射环境中重建方法的基准。2. 提出了ReflectiveGS：作为3D Gaussian Splatting的扩展，它将镜面反射用作互补视角，而非简单的对称伪影，以增强场景几何并恢复缺失细节。

Result: 在MirrorScene3D数据集上的实验表明，ReflectiveGS在SSIM、PSNR、LPIPS和训练速度方面均优于现有方法。

Conclusion: ReflectiveGS在富含镜面的环境中为3D重建设定了新的基准，通过有效利用镜面反射作为互补视角，显著提升了重建质量和效率。

Abstract: Mirror-containing environments pose unique challenges for 3D reconstruction
and novel view synthesis (NVS), as reflective surfaces introduce view-dependent
distortions and inconsistencies. While cutting-edge methods such as Neural
Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) excel in typical
scenes, their performance deteriorates in the presence of mirrors. Existing
solutions mainly focus on handling mirror surfaces through symmetry mapping but
often overlook the rich information carried by mirror reflections. These
reflections offer complementary perspectives that can fill in absent details
and significantly enhance reconstruction quality. To advance 3D reconstruction
in mirror-rich environments, we present MirrorScene3D, a comprehensive dataset
featuring diverse indoor scenes, 1256 high-quality images, and annotated mirror
masks, providing a benchmark for evaluating reconstruction methods in
reflective settings. Building on this, we propose ReflectiveGS, an extension of
3D Gaussian Splatting that utilizes mirror reflections as complementary
viewpoints rather than simple symmetry artifacts, enhancing scene geometry and
recovering absent details. Experiments on MirrorScene3D show that
ReflectiveGaussian outperforms existing methods in SSIM, PSNR, LPIPS, and
training speed, setting a new benchmark for 3D reconstruction in mirror-rich
environments.

</details>


### [146] [Generative data augmentation for biliary tract detection on intraoperative images](https://arxiv.org/abs/2509.18958)
*Cristina Iacono,Mariarosaria Meola,Federica Conte,Laura Mecozzi,Umberto Bracale,Pietro Falco,Fanny Ficuciello*

Main category: cs.CV

TL;DR: 该研究利用深度学习（Yolo算法）结合真实与GAN生成的合成数据，旨在从腹腔镜手术的白光图像中定位胆道，以提高术中胆道可视化并降低胆管损伤风险。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜胆囊切除术是常见手术，但存在胆管损伤的较高风险，这严重影响患者生活质量和生存。提高术中胆道可视化是避免损伤的关键。

Method: 该研究构建并标注了一个图像数据库，用于训练Yolo检测算法。除了传统的图像数据增强技术外，还提出使用生成对抗网络（GAN）生成部分合成训练数据集。

Result: 摘要中提到已讨论了实验结果和伦理考量，但未具体说明实验结果的量化表现或具体发现。

Conclusion: 该研究致力于通过深度学习方法改善腹腔镜胆囊切除术中胆道的术中可视化，以期降低胆管损伤的风险，并讨论了相关实验结果和伦理问题。

Abstract: Cholecystectomy is one of the most frequently performed procedures in
gastrointestinal surgery, and the laparoscopic approach is the gold standard
for symptomatic cholecystolithiasis and acute cholecystitis. In addition to the
advantages of a significantly faster recovery and better cosmetic results, the
laparoscopic approach bears a higher risk of bile duct injury, which has a
significant impact on quality of life and survival. To avoid bile duct injury,
it is essential to improve the intraoperative visualization of the bile duct.
This work aims to address this problem by leveraging a deep-learning approach
for the localization of the biliary tract from white-light images acquired
during the surgical procedures. To this end, the construction and annotation of
an image database to train the Yolo detection algorithm has been employed.
Besides classical data augmentation techniques, the paper proposes Generative
Adversarial Network (GAN) for the generation of a synthetic portion of the
training dataset. Experimental results have been discussed along with ethical
considerations.

</details>


### [147] [Prompt-DAS: Annotation-Efficient Prompt Learning for Domain Adaptive Semantic Segmentation of Electron Microscopy Images](https://arxiv.org/abs/2509.18973)
*Jiabao Chen,Shan Xiong,Jialin Peng*

Main category: cs.CV

TL;DR: 本文提出Prompt-DAS，一个受SAM启发的、可提示的多任务框架，用于电子显微镜图像中的细胞器域自适应分割。它在训练和测试阶段对点提示的数量具有灵活性，支持无监督、弱监督域自适应以及交互式分割，并通过辅助中心点检测任务和提示引导对比学习，在各种基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大规模电子显微镜图像中大量细胞器实例的域自适应分割是实现注释高效学习的有前景方法。受SAM启发，但SAM需要为每个单独对象实例提供提示，这在实际应用中可能效率不高，因此需要一个更灵活且注释高效的框架。

Method: 本文提出了Prompt-DAS，一个可提示的多任务框架，它：1) 借鉴SAM但更灵活，在自适应训练和测试阶段可使用任意数量的点提示；2) 可进行无监督域自适应（UDA）、弱监督域自适应（WDA）以及测试时的交互式分割；3) 通过引入辅助中心点检测任务，可使用所有实例上的完整点、部分实例上的稀疏点，甚至不使用任何点进行训练；4) 提出了一种新颖的提示引导对比学习方法，以增强判别性特征学习。

Result: 在具有挑战性的基准测试上进行的综合实验表明，所提出的Prompt-DAS方法在性能上优于现有的UDA、WDA以及基于SAM的方法。

Conclusion: Prompt-DAS提供了一种有效且灵活的域自适应分割方法，特别适用于电子显微镜图像中的细胞器分割，通过其独特的提示机制和辅助任务，实现了注释高效的学习和卓越的性能。

Abstract: Domain adaptive segmentation (DAS) of numerous organelle instances from
large-scale electron microscopy (EM) is a promising way to enable
annotation-efficient learning. Inspired by SAM, we propose a promptable
multitask framework, namely Prompt-DAS, which is flexible enough to utilize any
number of point prompts during the adaptation training stage and testing stage.
Thus, with varying prompt configurations, Prompt-DAS can perform unsupervised
domain adaptation (UDA) and weakly supervised domain adaptation (WDA), as well
as interactive segmentation during testing. Unlike the foundation model SAM,
which necessitates a prompt for each individual object instance, Prompt-DAS is
only trained on a small dataset and can utilize full points on all instances,
sparse points on partial instances, or even no points at all, facilitated by
the incorporation of an auxiliary center-point detection task. Moreover, a
novel prompt-guided contrastive learning is proposed to enhance discriminative
feature learning. Comprehensive experiments conducted on challenging benchmarks
demonstrate the effectiveness of the proposed approach over existing UDA, WDA,
and SAM-based approaches.

</details>


### [148] [Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards](https://arxiv.org/abs/2509.19003)
*Honghao Chen,Xingzhou Lou,Xiaokun Feng,Kaiqi Huang,Xinlong Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为“分步链式推理”（Chain of Step, CoS）的新方法，用于视觉-语言模型，通过在更细粒度评估推理步骤质量，实现了有效的强化学习和推理时间扩展，并在挑战性基准测试中取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 链式思考（Chain of Thought）在大型语言模型中表现出色，但其在视觉-语言推理中的应用仍面临挑战，缺乏明确的最佳实践。现有方法通常采用粗粒度推理链，难以进行细粒度结构化推理，更重要的是，难以评估中间推理的奖励和质量。

Method: 本文深入研究了视觉-语言模型的分步链式推理，旨在准确评估推理步骤质量，从而实现有效的强化学习和基于细粒度奖励的推理时间扩展。具体方法包括：构建步级推理数据、开发过程奖励模型（PRM）以及进行强化学习训练，形成了一个简单、有效且完全透明的框架。

Result: 所提出的模型在挑战性的视觉-语言基准测试中建立了强大的基线，并持续取得了改进。更重要的是，通过彻底的实证分析和消融研究，揭示了每个组件的影响以及推理时间扩展的几个有趣特性。

Conclusion: 本文为视觉-语言模型提供了一个强大的基线，并为更复杂的跨模态推理提供了深刻见解。研究中生成的数据集、PRM和代码将对外公开。

Abstract: Chain of thought reasoning has demonstrated remarkable success in large
language models, yet its adaptation to vision-language reasoning remains an
open challenge with unclear best practices. Existing attempts typically employ
reasoning chains at a coarse-grained level, which struggles to perform
fine-grained structured reasoning and, more importantly, are difficult to
evaluate the reward and quality of intermediate reasoning. In this work, we
delve into chain of step reasoning for vision-language models, enabling
assessing reasoning step quality accurately and leading to effective
reinforcement learning and inference-time scaling with fine-grained rewards. We
present a simple, effective, and fully transparent framework, including the
step-level reasoning data, process reward model (PRM), and reinforcement
learning training. With the proposed approaches, our models set strong
baselines with consistent improvements on challenging vision-language
benchmarks. More importantly, we conduct a thorough empirical analysis and
ablation study, unveiling the impact of each component and several intriguing
properties of inference-time scaling. We believe this paper serves as a
baseline for vision-language models and offers insights into more complex
multimodal reasoning. Our dataset, PRM, and code will be available at
https://github.com/baaivision/CoS.

</details>


### [149] [Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model](https://arxiv.org/abs/2509.19028)
*Ioannis Sarafis,Alexandros Papadopoulos,Anastasios Delopoulos*

Main category: cs.CV

TL;DR: 本文提出一种弱监督食物图像语义分割方法，结合SAM的零样本能力与ViT的注意力机制，利用ViT的类别激活图生成SAM提示，实现无需像素级标注的食物分割。


<details>
  <summary>Details</summary>
Motivation: 传统语义分割需要大量的像素级标注，成本高昂。本文旨在通过弱监督学习，利用图像级标注来消除对像素级标注的需求，并加速食物图像标注任务或集成到食物营养追踪应用中。

Method: 该方法使用Swin Transformer（一种ViT模型）进行训练，仅需图像级标注。ViT生成的类别激活图（CAMs）被用作Segment Anything Model (SAM) 的提示。为提高SAM生成掩码的质量，研究了图像预处理技术以及单掩码和多掩码SAM生成策略。

Result: 该方法在FoodSeg103数据集上进行了评估，平均每张图像生成2.4个掩码（不包括背景），在多掩码场景下实现了0.54的mIoU。

Conclusion: 所提出的方法可以作为加速食物图像标注任务的工具，或作为食物和营养追踪应用中的集成组件，有效利用弱监督和零样本能力进行食物图像分割。

Abstract: In this paper, we propose a weakly supervised semantic segmentation approach
for food images which takes advantage of the zero-shot capabilities and
promptability of the Segment Anything Model (SAM) along with the attention
mechanisms of Vision Transformers (ViTs). Specifically, we use class activation
maps (CAMs) from ViTs to generate prompts for SAM, resulting in masks suitable
for food image segmentation. The ViT model, a Swin Transformer, is trained
exclusively using image-level annotations, eliminating the need for pixel-level
annotations during training. Additionally, to enhance the quality of the
SAM-generated masks, we examine the use of image preprocessing techniques in
combination with single-mask and multi-mask SAM generation strategies. The
methodology is evaluated on the FoodSeg103 dataset, generating an average of
2.4 masks per image (excluding background), and achieving an mIoU of 0.54 for
the multi-mask scenario. We envision the proposed approach as a tool to
accelerate food image annotation tasks or as an integrated component in food
and nutrition tracking applications.

</details>


### [150] [A DyL-Unet framework based on dynamic learning for Temporally Consistent Echocardiographic Segmentation](https://arxiv.org/abs/2509.19052)
*Jierui Qu,Jianchun Zhao*

Main category: cs.CV

TL;DR: DyL-UNet是一种基于动态学习的时间一致性U-Net分割架构，旨在实现超声心动图分割的时间稳定性和精确性，通过构建Echo-Dynamics Graph和引入Cardiac Phase-Dynamics Attention来解决帧间抖动问题。


<details>
  <summary>Details</summary>
Motivation: 超声心动图分割对心血管诊断和治疗至关重要，但易受形变和散斑噪声影响，导致帧间分割抖动。即使单帧分割精度高，时间不稳定性也会削弱功能评估并损害临床可解释性。

Method: 本文提出了DyL-UNet框架。它通过动态学习构建Echo-Dynamics Graph (EDG) 以提取视频中的动态信息。DyL-UNet包含多个基于Swin-Transformer的编码器-解码器分支来处理单帧图像。此外，在跳跃连接处引入了Cardiac Phase-Dynamics Attention (CPDA)，利用EDG编码的动态特征和心动周期线索来强制执行分割过程中的时间一致性。

Result: 在CAMUS和EchoNet-Dynamic数据集上的大量实验表明，DyL-UNet在保持与现有方法相当的分割精度的同时，实现了卓越的时间一致性。

Conclusion: DyL-UNet为自动化临床超声心动图提供了一个可靠的解决方案，能够实现稳定且精确的分割。

Abstract: Accurate segmentation of cardiac anatomy in echocardiography is essential for
cardiovascular diagnosis and treatment. Yet echocardiography is prone to
deformation and speckle noise, causing frame-to-frame segmentation jitter. Even
with high accuracy in single-frame segmentation, temporal instability can
weaken functional estimates and impair clinical interpretability. To address
these issues, we propose DyL-UNet, a dynamic learning-based temporal
consistency U-Net segmentation architecture designed to achieve temporally
stable and precise echocardiographic segmentation. The framework constructs an
Echo-Dynamics Graph (EDG) through dynamic learning to extract dynamic
information from videos. DyL-UNet incorporates multiple Swin-Transformer-based
encoder-decoder branches for processing single-frame images. It further
introduces Cardiac Phase-Dynamics Attention (CPDA) at the skip connections,
which uses EDG-encoded dynamic features and cardiac-phase cues to enforce
temporal consistency during segmentation. Extensive experiments on the CAMUS
and EchoNet-Dynamic datasets demonstrate that DyL-UNet maintains segmentation
accuracy comparable to existing methods while achieving superior temporal
consistency, providing a reliable solution for automated clinical
echocardiography.

</details>


### [151] [3rd Place Report of LSVOS 2025 MeViS Track: Sa2VA-i: Improving Sa2VA Results with Consistent Training and Inference](https://arxiv.org/abs/2509.19082)
*Alexey Nekrasov,Ali Athar,Daan de Geus,Alexander Hermans,Bastian Leibe*

Main category: cs.CV

TL;DR: Sa2VA模型在指代视频目标分割任务中存在训练与推理不一致的问题，本文提出改进版Sa2VA-i，通过修正这些不一致性显著提升了模型性能，并在多个视频基准测试中刷新了SOTA，证明了实现细节的重要性。


<details>
  <summary>Details</summary>
Motivation: Sa2VA作为一种语言引导的密集接地模型，在图像和视频分割基准测试中取得了最先进的成果并广受欢迎。然而，研究发现Sa2VA在指代视频目标分割任务中未能发挥其全部潜力。主要原因是训练和推理过程中的不一致性。

Method: 通过识别并纠正Sa2VA模型训练和推理过程中的不一致性，提出了一个改进版本Sa2VA-i。

Result: Sa2VA-i在多个视频基准测试中取得了新的最先进结果，使用相同的Sa2VA检查点，在MeViS上性能提升高达+11.6 J&F，在Ref-YT-VOS上提升+1.4，在Ref-DAVIS上提升+3.3，在ReVOS上提升+4.1。值得注意的是，Sa2VA-i-1B模型在MeViS基准测试上的表现甚至与原始Sa2VA-26B模型相当。

Conclusion: 这项工作强调了看似微不足道的实现细节的重要性，并为指代视频分割领域提供了有价值的见解。作者提供了代码和更新后的模型。

Abstract: Sa2VA is a recent model for language-guided dense grounding in images and
video that achieves state-of-the-art results on multiple segmentation
benchmarks and that has become widely popular. However, we found that Sa2VA
does not perform according to its full potential for referring video object
segmentation tasks. We identify inconsistencies between training and inference
procedures as the key factor holding it back. To mitigate this issue, we
propose an improved version of Sa2VA, Sa2VA-i, that rectifies these issues and
improves the results. In fact, Sa2VA-i sets a new state of the art for multiple
video benchmarks and achieves improvements of up to +11.6 J&F on MeViS, +1.4 on
Ref-YT-VOS, +3.3 on Ref-DAVIS and +4.1 on ReVOS using the same Sa2VA
checkpoints. With our fixes, the Sa2VA-i-1B model even performs on par with the
original Sa2VA-26B model on the MeViS benchmark. We hope that this work will
show the importance of seemingly trivial implementation details and that it
will provide valuable insights for the referring video segmentation field. We
provide the code and updated models at https://github.com/kumuji/sa2va-i

</details>


### [152] [Zero-Shot Multi-Spectral Learning: Reimagining a Generalist Multimodal Gemini 2.5 Model for Remote Sensing Applications](https://arxiv.org/abs/2509.19087)
*Ganesh Mallya,Yotam Gigi,Dahun Kim,Maxim Neumann,Genady Beryozkin,Tomer Shekel,Anelia Angelova*

Main category: cs.CV

TL;DR: 本文提出了一种免训练方法，使仅用RGB图像训练的通用多模态模型（如Gemini 2.5）能够以零样本（Zero-Shot）模式处理多光谱遥感数据，并在土地覆盖分类任务上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 多光谱图像在遥感应用中至关重要，但现有机器学习模型训练成本高昂，且强大的通用多模态模型无法直接理解和处理多光谱信号，限制了其在遥感领域的应用。

Method: 该研究提出了一种免训练方法，将多光谱数据作为通用多模态模型（仅用RGB输入训练）的零样本输入。其核心思想是利用模型对视觉空间的理解，将多光谱输入适配到该空间，并通过指令注入领域特定信息。研究以Gemini 2.5模型为例进行了验证。

Result: 该方法在流行的遥感土地覆盖和土地利用分类基准上取得了显著的零样本性能提升，并证明了Gemini 2.5模型对新输入的易适应性。

Conclusion: 研究结果表明，地理空间专业人员可以轻松利用如Gemini 2.5等强大的多模态模型处理非标准专业输入，从而受益于其丰富的推理和上下文能力，加速工作效率。

Abstract: Multi-spectral imagery plays a crucial role in diverse Remote Sensing
applications including land-use classification, environmental monitoring and
urban planning. These images are widely adopted because their additional
spectral bands correlate strongly with physical materials on the ground, such
as ice, water, and vegetation. This allows for more accurate identification,
and their public availability from missions, such as Sentinel-2 and Landsat,
only adds to their value. Currently, the automatic analysis of such data is
predominantly managed through machine learning models specifically trained for
multi-spectral input, which are costly to train and support. Furthermore,
although providing a lot of utility for Remote Sensing, such additional inputs
cannot be used with powerful generalist large multimodal models, which are
capable of solving many visual problems, but are not able to understand
specialized multi-spectral signals.
  To address this, we propose a training-free approach which introduces new
multi-spectral data in a Zero-Shot-only mode, as inputs to generalist
multimodal models, trained on RGB-only inputs. Our approach leverages the
multimodal models' understanding of the visual space, and proposes to adapt to
inputs to that space, and to inject domain-specific information as instructions
into the model. We exemplify this idea with the Gemini2.5 model and observe
strong Zero-Shot performance gains of the approach on popular Remote Sensing
benchmarks for land cover and land use classification and demonstrate the easy
adaptability of Gemini2.5 to new inputs. These results highlight the potential
for geospatial professionals, working with non-standard specialized inputs, to
easily leverage powerful multimodal models, such as Gemini2.5, to accelerate
their work, benefiting from their rich reasoning and contextual capabilities,
grounded in the specialized sensor data.

</details>


### [153] [Investigating Traffic Accident Detection Using Multimodal Large Language Models](https://arxiv.org/abs/2509.19096)
*Ilhan Skender,Kailin Tong,Selim Solmaz,Daniel Watzenig*

Main category: cs.CV

TL;DR: 本研究探讨了多模态大型语言模型（MLLMs）在零样本交通事故检测中的应用，通过集成先进视觉分析技术（如YOLO、Deep SORT、SAM）来增强其在基础设施摄像头图像上的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 交通安全是一个全球性问题，及时准确的事故检测对于减少危害和快速响应至关重要。基础设施视觉传感器提供实时监控方案，但依赖大量标注数据集的传统方法存在局限性。本研究旨在利用MLLMs的零样本能力，减少对标注数据的依赖，并解决多样化、真实基础设施事故数据稀缺的问题。

Method: 研究方法包括：1) 使用CARLA模拟的DeepAccident数据集评估MLLMs，以解决实际事故数据稀缺问题；2) 对比Gemini 1.5、2.0、Gemma 3和Pixtral模型在未微调情况下的事故识别和描述能力；3) 将YOLO（目标检测）、Deep SORT（多目标跟踪）和Segment Anything (SAM)（实例分割）等先进视觉分析技术集成到提示词中，以提高模型的准确性和可解释性。

Result: 主要结果显示：Pixtral模型表现最佳，F1-score达到0.71，召回率为83%。Gemini模型在增强提示词后精度显著提高（例如Gemini 1.5提高到90%），但F1-score和召回率有所下降。Gemma 3模型表现最为均衡，各项指标波动最小。

Conclusion: 研究结果表明，将多模态大型语言模型与先进视觉分析技术相结合具有巨大潜力，能有效提升其在现实世界自动化交通监控系统中的应用能力。

Abstract: Traffic safety remains a critical global concern, with timely and accurate
accident detection essential for hazard reduction and rapid emergency response.
Infrastructure-based vision sensors offer scalable and efficient solutions for
continuous real-time monitoring, facilitating automated detection of acci-
dents directly from captured images. This research investigates the zero-shot
capabilities of multimodal large language models (MLLMs) for detecting and
describing traffic accidents using images from infrastructure cameras, thus
minimizing reliance on extensive labeled datasets. Main contributions include:
(1) Evaluation of MLLMs using the simulated DeepAccident dataset from CARLA,
explicitly addressing the scarcity of diverse, realistic, infrastructure-based
accident data through controlled simulations; (2) Comparative performance
analysis between Gemini 1.5 and 2.0, Gemma 3 and Pixtral models in acci- dent
identification and descriptive capabilities without prior fine-tuning; and (3)
Integration of advanced visual analytics, specifically YOLO for object
detection, Deep SORT for multi- object tracking, and Segment Anything (SAM) for
instance segmentation, into enhanced prompts to improve model accuracy and
explainability. Key numerical results show Pixtral as the top performer with an
F1-score of 0.71 and 83% recall, while Gemini models gained precision with
enhanced prompts (e.g., Gemini 1.5 rose to 90%) but suffered notable F1 and
recall losses. Gemma 3 offered the most balanced performance with minimal
metric fluctuation. These findings demonstrate the substantial potential of
integrating MLLMs with advanced visual analytics techniques, enhancing their
applicability in real-world automated traffic monitoring systems.

</details>


### [154] [Track-On2: Enhancing Online Point Tracking with Memory](https://arxiv.org/abs/2509.19115)
*Görkay Aydemir,Weidi Xie,Fatma Güney*

Main category: cs.CV

TL;DR: 本文提出Track-On2，一个基于Transformer的简单高效模型，用于在线长期点跟踪。它通过因果处理和内存机制处理视频帧，在合成数据上训练，并在多个基准测试中达到了最先进的性能，超越了现有在线和部分离线方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决长期点跟踪问题，即在视频帧中持续识别点，即使面临显著的外观变化、运动和遮挡。特别关注在线设置，以适应实时和流媒体应用的需求。

Method: 该研究将之前的Track-On模型扩展为Track-On2，这是一个基于Transformer的在线长期跟踪模型。Track-On2通过架构改进、更有效的内存使用和改进的合成训练策略来提高性能和效率。它以因果方式处理帧，并通过内存机制保持时间一致性，以处理漂移和遮挡，而无需未来帧。推理时，先进行粗略的块级分类，然后进行细化。此外，还系统研究了合成训练设置及其对内存行为的影响。

Result: Track-On2在五个合成和真实世界基准测试中取得了最先进的成果，超越了之前的在线跟踪器，甚至优于利用双向上下文的强大离线方法。

Conclusion: 研究结论是，纯粹通过合成数据训练的因果、基于内存的架构是解决实际点跟踪问题的有效且可扩展的解决方案。

Abstract: In this paper, we consider the problem of long-term point tracking, which
requires consistent identification of points across video frames under
significant appearance changes, motion, and occlusion. We target the online
setting, i.e. tracking points frame-by-frame, making it suitable for real-time
and streaming applications. We extend our prior model Track-On into Track-On2,
a simple and efficient transformer-based model for online long-term tracking.
Track-On2 improves both performance and efficiency through architectural
refinements, more effective use of memory, and improved synthetic training
strategies. Unlike prior approaches that rely on full-sequence access or
iterative updates, our model processes frames causally and maintains temporal
coherence via a memory mechanism, which is key to handling drift and occlusions
without requiring future frames. At inference, we perform coarse patch-level
classification followed by refinement. Beyond architecture, we systematically
study synthetic training setups and their impact on memory behavior, showing
how they shape temporal robustness over long sequences. Through comprehensive
experiments, Track-On2 achieves state-of-the-art results across five synthetic
and real-world benchmarks, surpassing prior online trackers and even strong
offline methods that exploit bidirectional context. These results highlight the
effectiveness of causal, memory-based architectures trained purely on synthetic
data as scalable solutions for real-world point tracking. Project page:
https://kuis-ai.github.io/track_on2

</details>


### [155] [KAMERA: Enhancing Aerial Surveys of Ice-associated Seals in Arctic Environments](https://arxiv.org/abs/2509.19129)
*Adam Romlein,Benjamin X. Hou,Yuval Boss,Cynthia L. Christman,Stacie Koslovsky,Erin E. Moreland,Jason Parham,Anthony Hoogs*

Main category: cs.CV

TL;DR: KAMERA是一个用于多相机、多光谱同步和实时检测海豹与北极熊的综合系统，可将数据集处理时间减少80%，并已在空中调查中应用。


<details>
  <summary>Details</summary>
Motivation: 在白令海、楚科奇海和波弗特海的冰区海豹空中调查中，需要一个更高效、更准确的系统来同步多光谱数据、实时检测动物，并显著减少数据处理时间。

Method: 引入KAMERA系统，该系统采用多相机、多光谱同步技术，进行实时目标检测。通过严格的校准和硬件同步，实现多光谱数据用于目标检测。所有收集的数据都附带元数据，便于后续引用。所有图像和动物检测结果都被映射到世界平面上，以准确估算调查区域和快速评估调查结果。

Result: KAMERA系统将数据集处理时间比传统方法减少了80%。它使得多光谱数据能够用于目标检测，并能准确估算调查区域和快速评估调查结果。

Conclusion: KAMERA是一个全面、高效且准确的多相机、多光谱同步系统，用于实时检测海豹和北极熊，显著提高了空中调查的效率。该系统及其所有软件、模型和原理图都已开源，有望启发科学界其他测绘和检测工作。

Abstract: We introduce KAMERA: a comprehensive system for multi-camera, multi-spectral
synchronization and real-time detection of seals and polar bears. Utilized in
aerial surveys for ice-associated seals in the Bering, Chukchi, and Beaufort
seas around Alaska, KAMERA provides up to an 80% reduction in dataset
processing time over previous methods. Our rigorous calibration and hardware
synchronization enable using multiple spectra for object detection. All
collected data are annotated with metadata so they can be easily referenced
later. All imagery and animal detections from a survey are mapped onto a world
plane for accurate surveyed area estimates and quick assessment of survey
results. We hope KAMERA will inspire other mapping and detection efforts in the
scientific community, with all software, models, and schematics fully
open-sourced.

</details>


### [156] [NeuCODEX: Edge-Cloud Co-Inference with Spike-Driven Compression and Dynamic Early-Exit](https://arxiv.org/abs/2509.19156)
*Maurf Hassan,Steven Davy,Muhammad Zawish,Owais Bin Zuber,Nouman Ashraf*

Main category: cs.CV

TL;DR: NeuCODEX是一种神经形态协同推理架构，通过结合尖峰驱动压缩和动态提前退出机制，显著降低了边缘SNN部署的数据传输、能耗和端到端延迟，同时保持了高精度。


<details>
  <summary>Details</summary>
Motivation: SNN在边缘计算中具有节能潜力，但其固定的高时间步开销导致高延迟和能耗。边缘-云协同推理虽有前景，却受限于高延迟和特征传输成本，阻碍了其部署。

Method: 本文提出了NeuCODEX，一个神经形态协同推理架构，它联合优化了空间和时间冗余。该架构包含一个学习型尖峰驱动压缩模块以减少数据传输，并采用动态提前退出机制根据输出置信度自适应地终止推理。

Result: NeuCODEX在静态图像（CIFAR10、Caltech）和神经形态事件流（CIFAR10-DVS、N-Caltech）上进行了评估，并基于ResNet-18和VGG-16骨干网络在真实的边缘到云测试平台中进行了原型验证。结果显示，与纯边缘推理相比，数据传输减少高达2048倍，边缘能耗降低超过90%，端到端延迟降低高达3倍，而精度损失可忽略不计（低于2%）。

Conclusion: NeuCODEX使得在资源受限环境中实现实用、高性能的SNN部署成为可能，有效解决了SNN边缘-云协同推理的挑战。

Abstract: Spiking Neural Networks (SNNs) offer significant potential for enabling
energy-efficient intelligence at the edge. However, performing full SNN
inference at the edge can be challenging due to the latency and energy
constraints arising from fixed and high timestep overheads. Edge-cloud
co-inference systems present a promising solution, but their deployment is
often hindered by high latency and feature transmission costs. To address these
issues, we introduce NeuCODEX, a neuromorphic co-inference architecture that
jointly optimizes both spatial and temporal redundancy. NeuCODEX incorporates a
learned spike-driven compression module to reduce data transmission and employs
a dynamic early-exit mechanism to adaptively terminate inference based on
output confidence. We evaluated NeuCODEX on both static images (CIFAR10 and
Caltech) and neuromorphic event streams (CIFAR10-DVS and N-Caltech). To
demonstrate practicality, we prototyped NeuCODEX on ResNet-18 and VGG-16
backbones in a real edge-to-cloud testbed. Our proposed system reduces data
transfer by up to 2048x and edge energy consumption by over 90%, while reducing
end-to-end latency by up to 3x compared to edge-only inference, all with a
negligible accuracy drop of less than 2%. In doing so, NeuCODEX enables
practical, high-performance SNN deployment in resource-constrained
environments.

</details>


### [157] [YOLO-LAN: Precise Polyp Detection via Optimized Loss, Augmentations and Negatives](https://arxiv.org/abs/2509.19166)
*Siddharth Gupta,Jitin Singla*

Main category: cs.CV

TL;DR: 本文提出了一种基于YOLO的息肉检测流水线YOLO-LAN，通过M2IoU损失、数据增强和负样本训练，在Kvasir-seg和BKAI-IGH NeoPolyp数据集上超越了现有方法，实现了更精确和鲁棒的息肉检测。


<details>
  <summary>Details</summary>
Motivation: 结直肠癌（CRC）是一种致命疾病，源于结肠息肉。结肠镜检查是检测息肉的标准方法，但人工检测存在不一致和遗漏的风险。因此，基于深度学习的目标检测为结肠镜检查期间提供更准确、实时的诊断提供了更好的解决方案。

Method: 研究提出了一种名为YOLO-LAN的基于YOLO的息肉检测流水线。该流水线使用M2IoU损失、多功能数据增强和负样本数据进行训练，以模拟真实的临床情况。实验中使用了YOLOv12和YOLOv8作为基础模型。

Result: YOLO-LAN在Kvasir-seg和BKAI-IGH NeoPolyp数据集上均优于现有方法。在Kvasir-seg数据集上，使用YOLOv12时，mAP$_{50}$达到0.9619，mAP$_{50:95}$达到0.8599；使用YOLOv8时，mAP$_{50}$达到0.9540，mAP$_{50:95}$达到0.8487。尤其在mAP$_{50:95}$分数上实现了显著提升，表明了息肉检测的精确性。研究还展示了该方法在息肉大小和精确位置检测方面的鲁棒性。

Conclusion: YOLO-LAN在息肉检测方面表现出卓越的性能，特别是在提高检测精度和鲁棒性方面。这使其在AI辅助的结直肠筛查中具有重要的临床相关性。

Abstract: Colorectal cancer (CRC), a lethal disease, begins with the growth of abnormal
mucosal cell proliferation called polyps in the inner wall of the colon. When
left undetected, polyps can become malignant tumors. Colonoscopy is the
standard procedure for detecting polyps, as it enables direct visualization and
removal of suspicious lesions. Manual detection by colonoscopy can be
inconsistent and is subject to oversight. Therefore, object detection based on
deep learning offers a better solution for a more accurate and real-time
diagnosis during colonoscopy. In this work, we propose YOLO-LAN, a YOLO-based
polyp detection pipeline, trained using M2IoU loss, versatile data
augmentations and negative data to replicate real clinical situations. Our
pipeline outperformed existing methods for the Kvasir-seg and BKAI-IGH NeoPolyp
datasets, achieving mAP$_{50}$ of 0.9619, mAP$_{50:95}$ of 0.8599 with YOLOv12
and mAP$_{50}$ of 0.9540, mAP$_{50:95}$ of 0.8487 with YOLOv8 on the Kvasir-seg
dataset. The significant increase is achieved in mAP$_{50:95}$ score, showing
the precision of polyp detection. We show robustness based on polyp size and
precise location detection, making it clinically relevant in AI-assisted
colorectal screening.

</details>


### [158] [The 1st Solution for MOSEv2 Challenge 2025: Long-term and Concept-aware Video Segmentation via SeC](https://arxiv.org/abs/2509.19183)
*Mingqi Gao,Jingkun Chen,Yunqi Miao,Gengshen Wu,Zhijin Qin,Jungong Han*

Main category: cs.CV

TL;DR: 本报告分析并改进了增强型SAM-2框架SeC，以解决LSVOS挑战中MOSEv2赛道的复杂半监督视频对象分割任务，并凭借其长时记忆和概念感知记忆的优势，最终在该赛道中排名第一。


<details>
  <summary>Details</summary>
Motivation: 解决LSVOS挑战中MOSEv2赛道的复杂半监督视频对象分割任务所面临的核心挑战，包括处理遮挡、重现以及抑制干扰物等问题。

Method: 通过分析和改进增强型SAM-2框架SeC，并深入研究其长时记忆和概念感知记忆。长时记忆用于在遮挡和重现情况下保持时间连续性，而概念感知记忆则提供语义先验以抑制干扰物。

Result: 研究表明，长时记忆能有效保持遮挡和重现下的时间连续性，概念感知记忆能提供抑制干扰物的语义先验。该解决方案在测试集上取得了39.89%的JF分数，并在LSVOS挑战的MOSEv2赛道中排名第一。

Conclusion: SeC框架中长时记忆和概念感知记忆的结合，能够有效应对MOSEv2赛道的多个核心挑战，显著提升了复杂半监督视频对象分割的性能，并取得了领先的竞争成绩。

Abstract: This technical report explores the MOSEv2 track of the LSVOS Challenge, which
targets complex semi-supervised video object segmentation. By analysing and
adapting SeC, an enhanced SAM-2 framework, we conduct a detailed study of its
long-term memory and concept-aware memory, showing that long-term memory
preserves temporal continuity under occlusion and reappearance, while
concept-aware memory supplies semantic priors that suppress distractors;
together, these traits directly benefit several MOSEv2's core challenges. Our
solution achieves a JF score of 39.89% on the test set, ranking 1st in the
MOSEv2 track of the LSVOS Challenge.

</details>


### [159] [Reading Images Like Texts: Sequential Image Understanding in Vision-Language Models](https://arxiv.org/abs/2509.19191)
*Yueyan Li,Chenggong Zhao,Zeyuan Zang,Caixia Yuan,Xiaojie Wang*

Main category: cs.CV

TL;DR: 本文受人类视觉双流假说启发，解构了视觉语言模型（VLMs）的视觉处理过程，并提出了提高解码效率和空间推理能力的改进方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs通常以串行方式处理视觉信息，与人类视觉的并行特性大相径庭。此外，其不透明的内部机制阻碍了深入理解和架构创新。

Method: 研究将VLM的视觉处理解构为物体识别（“是什么”）和空间感知（“在哪里”）。对于物体识别，将图像转换为文本token图，分析其从浅层到深层的两阶段感知过程。对于空间感知，理论推导并实证验证了VLM中位置表示的几何结构。基于这些发现，提出了基于即插即用视觉解码器的指令无关token压缩算法以提高解码效率，以及RoPE缩放技术以增强空间推理能力。

Result: 研究验证了对VLM内部机制的分析，揭示了物体识别从属性识别到语义消歧的两阶段过程，并推导验证了空间表示的几何结构。在此基础上，提出的token压缩算法有效提高了解码效率，RoPE缩放技术增强了模型的空间推理能力。

Conclusion: 本研究加深了对VLM内部机制的理解，并为设计更强大的未来VLM架构提供了清晰的原则和指导。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable performance across
a variety of real-world tasks. However, existing VLMs typically process visual
information by serializing images, a method that diverges significantly from
the parallel nature of human vision. Moreover, their opaque internal mechanisms
hinder both deeper understanding and architectural innovation. Inspired by the
dual-stream hypothesis of human vision, which distinguishes the "what" and
"where" pathways, we deconstruct the visual processing in VLMs into object
recognition and spatial perception for separate study. For object recognition,
we convert images into text token maps and find that the model's perception of
image content unfolds as a two-stage process from shallow to deep layers,
beginning with attribute recognition and culminating in semantic
disambiguation. For spatial perception, we theoretically derive and empirically
verify the geometric structure underlying the positional representation in
VLMs. Based on these findings, we introduce an instruction-agnostic token
compression algorithm based on a plug-and-play visual decoder to improve
decoding efficiency, and a RoPE scaling technique to enhance spatial reasoning.
Through rigorous experiments, our work validates these analyses, offering a
deeper understanding of VLM internals and providing clear principles for
designing more capable future architectures.

</details>


### [160] [Vision-Free Retrieval: Rethinking Multimodal Search with Textual Scene Descriptions](https://arxiv.org/abs/2509.19203)
*Ioanna Ntinou,Alexandros Xenos,Yassine Ouali,Adrian Bulat,Georgios Tzimiropoulos*

Main category: cs.CV

TL;DR: 该研究挑战了视觉编码器在检索任务中的必要性，提出了一种无视觉、单编码器的文本到文本检索方案，通过VLLM生成的图像描述取代原始图像，实现了卓越的性能、更小的模态差距和更好的隐私性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（如CLIP）存在语言理解浅薄（表现为词袋行为）、双编码器设计导致的模态差距、训练成本高昂以及隐私问题等局限性。这些问题促使研究者探索更高效、更深入且更私密友好的检索方法。

Method: 该研究引入了一种无视觉、单编码器的检索流程，将传统的文本到图像检索范式转变为文本到文本范式。具体做法是，利用大型视觉-语言模型（VLLM）生成结构化的图像描述，用这些描述替代原始图像进行检索。同时，发布了两个新的组合性基准测试（subFlickr和subCOCO）来评估泛化能力。

Result: 这种范式转变显著减小了模态差距，提高了组合性，并在短句和长句查询上表现出更好的性能，且仅需少量GPU校准时间。用文本描述替代原始图像还提供了一种更隐私友好的检索方案。该无视觉检索器匹配并经常超越传统多模态模型，在多个检索和组合性基准测试中实现了最先进的零样本性能，甚至使用参数量小至0.3B的模型也能达到。

Conclusion: 研究表明，对于检索任务而言，视觉编码器并非必需。通过VLLM生成的结构化图像描述实现的文本到文本检索范式，不仅能够克服现有视觉-语言模型的局限性，提供卓越的性能和组合性理解，还能显著提升计算效率和数据隐私性，为未来的检索系统开辟了新的方向。

Abstract: Contrastively-trained Vision-Language Models (VLMs), such as CLIP, have
become the standard approach for learning discriminative vision-language
representations. However, these models often exhibit shallow language
understanding, manifesting bag-of-words behaviour. These limitations are
reinforced by their dual-encoder design, which induces a modality gap.
Additionally, the reliance on vast web-collected data corpora for training
makes the process computationally expensive and introduces significant privacy
concerns. To address these limitations, in this work, we challenge the
necessity of vision encoders for retrieval tasks by introducing a vision-free,
single-encoder retrieval pipeline. Departing from the traditional text-to-image
retrieval paradigm, we migrate to a text-to-text paradigm with the assistance
of VLLM-generated structured image descriptions. We demonstrate that this
paradigm shift has significant advantages, including a substantial reduction of
the modality gap, improved compositionality, and better performance on short
and long caption queries, all attainable with only a few hours of calibration
on two GPUs. Additionally, substituting raw images with textual descriptions
introduces a more privacy-friendly alternative for retrieval. To further assess
generalisation and address some of the shortcomings of prior compositionality
benchmarks, we release two benchmarks derived from Flickr30k and COCO,
containing diverse compositional queries made of short captions, which we coin
subFlickr and subCOCO. Our vision-free retriever matches and often surpasses
traditional multimodal models. Importantly, our approach achieves
state-of-the-art zero-shot performance on multiple retrieval and
compositionality benchmarks, with models as small as 0.3B parameters. Code is
available at: https://github.com/IoannaNti/LexiCLIP

</details>


### [161] [Long Story Short: Disentangling Compositionality and Long-Caption Understanding in VLMs](https://arxiv.org/abs/2509.19207)
*Israfel Salazar,Desmond Elliott,Yova Kementchedjhieva*

Main category: cs.CV

TL;DR: 本文研究了对比视觉-语言模型（VLMs）中组合性与长文本理解之间的关系。研究发现两者之间存在双向促进作用，但效果受数据质量和模型设计的显著影响。高质量、密集的描述性数据有助于同时提升这两种能力。


<details>
  <summary>Details</summary>
Motivation: 对比VLMs在绑定视觉和文本信息方面取得了显著进展，但在理解长而密集的图像描述方面仍面临挑战。作者假设组合性（即理解物体属性绑定和物体间关系的能力）是理解长文本的关键。

Method: 研究人员训练并评估了一系列针对组合性和长文本理解能力的模型。他们调查了训练其中一种能力是否能增强另一种能力，并探究了数据质量（例如，结构不良的描述）和模型设计（例如，冻结位置嵌入）对泛化能力的影响。

Result: 结果显示，组合性训练能提升长文本检索的性能，而长文本训练也能促进组合性，两者之间存在双向关系。然而，这些提升对数据质量和模型设计很敏感：使用结构不良的描述或有限的参数更新无法支持泛化；保留通用对齐的策略（如冻结位置嵌入）也无法改善组合性理解。最终，通过高质量、密集的、有基础的描述进行训练的模型，在这两项任务中均能取得优异表现。

Conclusion: 组合性理解和长文本理解是相互交织的能力，可以通过在密集、有基础的描述上进行训练来共同学习。尽管存在挑战，但通过高质量的长文本数据训练模型，可以显著提升VLM的泛化能力，为未来的模型改进提供了实用指导。

Abstract: Contrastive vision-language models (VLMs) have made significant progress in
binding visual and textual information, but understanding long, dense captions
remains an open challenge. We hypothesize that compositionality, the capacity
to reason about object-attribute bindings and inter-object relationships, is
key to understanding longer captions. In this paper, we investigate the
interaction between compositionality and long-caption understanding, asking
whether training for one property enhances the other. We train and evaluate a
range of models that target each of these capabilities. Our results reveal a
bidirectional relationship: compositional training improves performance on
long-caption retrieval, and training on long captions promotes
compositionality. However, these gains are sensitive to data quality and model
design. We find that training on poorly structured captions, or with limited
parameter updates, fails to support generalization. Likewise, strategies that
aim at retaining general alignment, such as freezing positional embeddings, do
not improve compositional understanding. Overall, we find that compositional
understanding and long-caption understanding are intertwined capabilities that
can be jointly learned through training on dense, grounded descriptions.
Despite these challenges, we show that models trained on high-quality,
long-caption data can achieve strong performance in both tasks, offering
practical guidance for improving VLM generalization.

</details>


### [162] [Enabling Plant Phenotyping in Weedy Environments using Multi-Modal Imagery via Synthetic and Generated Training Data](https://arxiv.org/abs/2509.19208)
*Earl Ranario,Ismael Mayanja,Heesup Yun,Brian N. Bailey,J. Mason Earles*

Main category: cs.CV

TL;DR: 该研究提出一个框架，结合合成RGB图像、少量真实标注和基于GAN的跨模态对齐，显著提升了热成像中植物分割的性能，尤其在杂草和植物类别上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 在户外环境中，热成像中准确的植物分割对于高通量田间表型分析是一个重大挑战，因为植物和杂草之间对比度低且频繁遮挡会阻碍性能。

Method: 该研究提出一个框架，利用合成RGB图像、少量真实标注和基于GAN的跨模态对齐来增强热图像中的语义分割。模型在1,128张包含作物和杂草混合物的合成图像上进行训练。同时，评估了整合少量（低至5张）真实手动分割图像的益处。通过CycleGAN-turbo将RGB图像转换为热图像，实现跨模态对齐，无需校准即可进行鲁棒的模板匹配。

Result: 与仅使用真实数据的基线相比，结合所有合成图像和少量带标注的真实图像，杂草类别的性能最大相对提升了22%，植物类别提升了17%。

Conclusion: 结果表明，将合成数据与有限的手动标注以及通过生成模型进行的跨域转换相结合，可以显著提高复杂田间环境中多模态图像的分割性能。

Abstract: Accurate plant segmentation in thermal imagery remains a significant
challenge for high throughput field phenotyping, particularly in outdoor
environments where low contrast between plants and weeds and frequent
occlusions hinder performance. To address this, we present a framework that
leverages synthetic RGB imagery, a limited set of real annotations, and
GAN-based cross-modality alignment to enhance semantic segmentation in thermal
images. We trained models on 1,128 synthetic images containing complex mixtures
of crop and weed plants in order to generate image segmentation masks for crop
and weed plants. We additionally evaluated the benefit of integrating as few as
five real, manually segmented field images within the training process using
various sampling strategies. When combining all the synthetic images with a few
labeled real images, we observed a maximum relative improvement of 22% for the
weed class and 17% for the plant class compared to the full real-data baseline.
Cross-modal alignment was enabled by translating RGB to thermal using
CycleGAN-turbo, allowing robust template matching without calibration. Results
demonstrated that combining synthetic data with limited manual annotations and
cross-domain translation via generative models can significantly boost
segmentation performance in complex field environments for multi-model imagery.

</details>


### [163] [DevFD: Developmental Face Forgery Detection by Learning Shared and Orthogonal LoRA Subspaces](https://arxiv.org/abs/2509.19230)
*Tianshuo Zhang,Li Gao,Siran Peng,Xiangyu Zhu,Zhen Lei*

Main category: cs.CV

TL;DR: 本文提出一种基于持续学习和专家混合（MoE）架构的方法，通过使用LoRA模型作为专家，实现人脸伪造检测模型对不断演进的新伪造类型快速适应，同时避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 逼真数字人脸生成和操纵技术的快速演进，使得现有检测模型难以跟上，且新伪造类型层出不穷。模型需要能在有限计算和数据下快速适应新领域，同时不忘记已学伪造类型，以应对持续变化的伪造威胁。

Method: 将人脸伪造检测视为一个持续学习问题。采用发展型专家混合（Developmental MoE）架构，其中LoRA模型作为独立专家。专家分为两组：一个Real-LoRA学习真实人脸知识，多个Fake-LoRA捕获不同伪造类型的增量信息。为防止灾难性遗忘，确保Fake-LoRA的学习方向与已建立的子空间正交，并集成正交梯度到Fake-LoRA的正交损失中，以防止训练过程中的梯度干扰。

Result: 在数据集和操纵类型增量协议下的实验结果表明，该方法有效。

Conclusion: 所提出的方法能有效应对人脸伪造检测中伪造技术不断演进的挑战，通过持续学习和特定的MoE架构，实现了对新伪造类型的快速适应和对旧知识的保留。

Abstract: The rise of realistic digital face generation and manipulation poses
significant social risks. The primary challenge lies in the rapid and diverse
evolution of generation techniques, which often outstrip the detection
capabilities of existing models. To defend against the ever-evolving new types
of forgery, we need to enable our model to quickly adapt to new domains with
limited computation and data while avoiding forgetting previously learned
forgery types. In this work, we posit that genuine facial samples are abundant
and relatively stable in acquisition methods, while forgery faces continuously
evolve with the iteration of manipulation techniques. Given the practical
infeasibility of exhaustively collecting all forgery variants, we frame face
forgery detection as a continual learning problem and allow the model to
develop as new forgery types emerge. Specifically, we employ a Developmental
Mixture of Experts (MoE) architecture that uses LoRA models as its individual
experts. These experts are organized into two groups: a Real-LoRA to learn and
refine knowledge of real faces, and multiple Fake-LoRAs to capture incremental
information from different forgery types. To prevent catastrophic forgetting,
we ensure that the learning direction of Fake-LoRAs is orthogonal to the
established subspace. Moreover, we integrate orthogonal gradients into the
orthogonal loss of Fake-LoRAs, preventing gradient interference throughout the
training process of each task. Experimental results under both the datasets and
manipulation types incremental protocols demonstrate the effectiveness of our
method.

</details>


### [164] [Lavida-O: Elastic Masked Diffusion Models for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2509.19244)
*Shufan Li,Jiuxiang Gu,Kangning Liu,Zhe Lin,Zijun Wei,Aditya Grover,Jason Kuen*

Main category: cs.CV

TL;DR: Lavida-O 是一种统一的多模态掩码扩散模型（MDM），能够处理图像理解和生成任务，支持高分辨率图像合成、对象定位和图像编辑，并通过规划和自我反思提升效果，实现了最先进的性能和推理速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态扩散语言模型（如 MMaDa 和 Muddit）仅支持简单的图像级理解任务和低分辨率图像生成，缺乏更高级的能力如对象定位和高分辨率合成。

Method: Lavida-O 是一个统一的 MDM，利用其理解能力通过规划和迭代自我反思来改进图像生成和编辑结果。它引入了多种新技术，包括弹性 Transformer 混合架构（Elastic Mixture-of-Transformer）、通用文本条件（universal text conditioning）和分层采样（stratified sampling），以实现有效高效的训练和采样。

Result: Lavida-O 在 RefCOCO 对象定位、GenEval 文本到图像生成和 ImgEdit 图像编辑等广泛基准测试中取得了最先进的性能，优于现有的自回归和连续扩散模型（如 Qwen2.5-VL 和 FluxKontext-dev），同时显著提高了推理速度。它还展示了对象定位、图像编辑和高分辨率（1024px）图像合成等新能力。

Conclusion: Lavida-O 是首个统一的多模态掩码扩散模型，通过其创新的架构和训练/采样技术，在图像理解和生成任务中取得了显著进展，实现了多项新能力、最先进的性能和更高的推理效率。

Abstract: We proposed Lavida-O, a unified multi-modal Masked Diffusion Model (MDM)
capable of image understanding and generation tasks. Unlike existing multimodal
diffsion language models such as MMaDa and Muddit which only support simple
image-level understanding tasks and low-resolution image generation, Lavida-O
exhibits many new capabilities such as object grounding, image-editing, and
high-resolution (1024px) image synthesis. It is also the first unified MDM that
uses its understanding capabilities to improve image generation and editing
results through planning and iterative self-reflection. To allow effective and
efficient training and sampling, Lavida-O ntroduces many novel techniques such
as Elastic Mixture-of-Transformer architecture, universal text conditioning,
and stratified sampling. \ours~achieves state-of-the-art performance on a wide
range of benchmarks such as RefCOCO object grounding, GenEval text-to-image
generation, and ImgEdit image editing, outperforming existing autoregressive
and continuous diffusion models such as Qwen2.5-VL and FluxKontext-dev, while
offering considerable speedup at inference.

</details>


### [165] [ConViS-Bench: Estimating Video Similarity Through Semantic Concepts](https://arxiv.org/abs/2509.19245)
*Benedetta Liberatori,Alessandro Conti,Lorenzo Vaquero,Yiming Wang,Elisa Ricci,Paolo Rota*

Main category: cs.CV

TL;DR: 该研究引入了一种名为ConViS的新任务和基准，旨在通过预定义的语义概念集来计算可解释的视频相似度分数，从而实现更接近人类的视频比较，并评估了现有模型在该任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有视频相似度模型通常依赖宽泛的全局相似度分数，而人类在比较视频时会考虑不同方面（如动作、地点）。这种能力尚未被充分研究，且对模型构成挑战。具有视频理解能力的大型多模态模型（LMMs）为利用自然语言进行视频比较提供了新机遇。

Method: 研究引入了“基于概念的视频相似度估计”（ConViS）任务，通过计算预定义关键语义概念上的可解释相似度分数来比较视频对。为支持此任务，研究还引入了ConViS-Bench基准，包含经过精心标注的视频对，每对都附有概念级相似度分数以及差异和相似性的文本描述。此外，研究还在ConViS上对多个最先进模型进行了基准测试。

Result: 基准测试结果显示，模型在ConViS任务上存在显著的性能差异，表明某些概念在估计视频相似度方面提出了更大的挑战。这揭示了模型与人类判断之间的一致性水平。

Conclusion: ConViS-Bench将成为推动语言驱动视频理解研究的宝贵资源。该任务和基准有助于实现更细致、更具解释性的视频相似度评估，并可能催生概念条件视频检索等新应用。

Abstract: What does it mean for two videos to be similar? Videos may appear similar
when judged by the actions they depict, yet entirely different if evaluated
based on the locations where they were filmed. While humans naturally compare
videos by taking different aspects into account, this ability has not been
thoroughly studied and presents a challenge for models that often depend on
broad global similarity scores. Large Multimodal Models (LMMs) with video
understanding capabilities open new opportunities for leveraging natural
language in comparative video tasks. We introduce Concept-based Video
Similarity estimation (ConViS), a novel task that compares pairs of videos by
computing interpretable similarity scores across a predefined set of key
semantic concepts. ConViS allows for human-like reasoning about video
similarity and enables new applications such as concept-conditioned video
retrieval. To support this task, we also introduce ConViS-Bench, a new
benchmark comprising carefully annotated video pairs spanning multiple domains.
Each pair comes with concept-level similarity scores and textual descriptions
of both differences and similarities. Additionally, we benchmark several
state-of-the-art models on ConViS, providing insights into their alignment with
human judgments. Our results reveal significant performance differences on
ConViS, indicating that some concepts present greater challenges for estimating
video similarity. We believe that ConViS-Bench will serve as a valuable
resource for advancing research in language-driven video understanding.

</details>


### [166] [Graph-Radiomic Learning (GrRAiL) Descriptor to Characterize Imaging Heterogeneity in Confounding Tumor Pathologies](https://arxiv.org/abs/2509.19258)
*Dheerendranath Battalapalli,Apoorva Safai,Maria Jaramillo,Hyemin Um,Gustavo Adalfo Pineda Ortiz,Ulas Bagci,Manmeet Singh Ahluwalia,Marwa Ismail,Pallavi Tiwari*

Main category: cs.CV

TL;DR: 本文提出了一种新的图-放射组学学习（GrRAiL）描述符，通过量化病灶内异质性，在多种肿瘤鉴别诊断任务中（如肿瘤复发与放射效应区分、肿瘤风险分层）显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 在实体瘤影像学中，可靠地区分混淆性病理与恶性肿瘤是一个重大挑战。现有的放射组学方法通常聚合感兴趣区域（ROI）内的特征，从而忽略了不同强度成分之间复杂的空间关系。

Method: GrRAiL方法首先使用每个体素的放射组学测量来识别子区域簇，然后计算图论指标以量化这些簇之间的空间关联。由此产生的加权图编码了ROI内更高阶的空间关系，旨在可靠地捕捉病灶内异质性（ILH）并区分混淆性病理与恶性肿瘤。

Result: GrRAiL在n=947名受试者的三个临床应用中进行了评估：区分胶质母细胞瘤（GBM）的肿瘤复发与放射效应（n=106）、区分脑转移瘤的复发与放射性坏死（n=233），以及将胰腺导管内乳头状黏液性肿瘤（IPMNs）分为无/低风险与高风险（n=608）。在多机构环境中，GrRAiL始终优于图神经网络（GNNs）、纹理放射组学和强度图分析等最新基线方法。在GBM中，复发与假性进展的交叉验证和测试准确率分别为89%和78%，比对照组高出10%以上的测试准确率。在脑转移瘤中，复发与放射性坏死的准确率分别为84%和74%（提高13%以上）。对于IPMN风险分层，准确率分别为84%和75%（提高10%以上）。

Conclusion: GrRAiL能够可靠地捕捉病灶内异质性，并在临床MRI扫描中有效区分混淆性病理与恶性肿瘤，展示了其在多种肿瘤鉴别诊断任务中的优越性能和临床可行性。

Abstract: A significant challenge in solid tumors is reliably distinguishing
confounding pathologies from malignant neoplasms on routine imaging. While
radiomics methods seek surrogate markers of lesion heterogeneity on CT/MRI,
many aggregate features across the region of interest (ROI) and miss complex
spatial relationships among varying intensity compositions. We present a new
Graph-Radiomic Learning (GrRAiL) descriptor for characterizing intralesional
heterogeneity (ILH) on clinical MRI scans. GrRAiL (1) identifies clusters of
sub-regions using per-voxel radiomic measurements, then (2) computes
graph-theoretic metrics to quantify spatial associations among clusters. The
resulting weighted graphs encode higher-order spatial relationships within the
ROI, aiming to reliably capture ILH and disambiguate confounding pathologies
from malignancy. To assess efficacy and clinical feasibility, GrRAiL was
evaluated in n=947 subjects spanning three use cases: differentiating tumor
recurrence from radiation effects in glioblastoma (GBM; n=106) and brain
metastasis (n=233), and stratifying pancreatic intraductal papillary mucinous
neoplasms (IPMNs) into no+low vs high risk (n=608). In a multi-institutional
setting, GrRAiL consistently outperformed state-of-the-art baselines - Graph
Neural Networks (GNNs), textural radiomics, and intensity-graph analysis. In
GBM, cross-validation (CV) and test accuracies for recurrence vs
pseudo-progression were 89% and 78% with >10% test-accuracy gains over
comparators. In brain metastasis, CV and test accuracies for recurrence vs
radiation necrosis were 84% and 74% (>13% improvement). For IPMN risk
stratification, CV and test accuracies were 84% and 75%, showing >10%
improvement.

</details>


### [167] [Moving by Looking: Towards Vision-Driven Avatar Motion Generation](https://arxiv.org/abs/2509.19259)
*Markos Diomataris,Berat Mert Albaba,Giorgio Becherini,Partha Ghosh,Omid Taheri,Michael J. Black*

Main category: cs.CV

TL;DR: 该研究提出CLOPS，首个仅使用自我中心视觉感知周围环境并导航的人形虚拟形象，通过解耦低级运动技能和高级视觉控制，实现了类人运动特性。


<details>
  <summary>Details</summary>
Motivation: 当前人体运动生成方法忽略了感知与运动的相互依赖性，并使用与人类感知差异很大的任务特定“感知”。研究认为，生成类人虚拟形象行为需要类人感知。

Method: 开发了CLOPS，一个仅使用自我中心视觉感知和导航的虚拟形象。为解决训练挑战，将低级运动技能学习与将视觉输入映射到运动的高级控制学习解耦。首先，在大规模动作捕捉数据集上训练运动先验模型；然后，使用Q学习训练策略，将自我中心视觉输入映射到运动先验的高级控制指令。

Result: 实验证明，自我中心视觉能使虚拟形象产生类人运动特性，例如，虚拟形象会避开视野中的障碍物。

Conclusion: 研究结果表明，为虚拟形象配备类人传感器，特别是自我中心视觉，有望训练出行为更像人类的虚拟形象。

Abstract: The way we perceive the world fundamentally shapes how we move, whether it is
how we navigate in a room or how we interact with other humans. Current human
motion generation methods, neglect this interdependency and use task-specific
``perception'' that differs radically from that of humans. We argue that the
generation of human-like avatar behavior requires human-like perception.
Consequently, in this work we present CLOPS, the first human avatar that solely
uses egocentric vision to perceive its surroundings and navigate. Using vision
as the primary driver of motion however, gives rise to a significant challenge
for training avatars: existing datasets have either isolated human motion,
without the context of a scene, or lack scale. We overcome this challenge by
decoupling the learning of low-level motion skills from learning of high-level
control that maps visual input to motion. First, we train a motion prior model
on a large motion capture dataset. Then, a policy is trained using Q-learning
to map egocentric visual inputs to high-level control commands for the motion
prior. Our experiments empirically demonstrate that egocentric vision can give
rise to human-like motion characteristics in our avatars. For example, the
avatars walk such that they avoid obstacles present in their visual field.
These findings suggest that equipping avatars with human-like sensors,
particularly egocentric vision, holds promise for training avatars that behave
like humans.

</details>


### [168] [OverLayBench: A Benchmark for Layout-to-Image Generation with Dense Overlaps](https://arxiv.org/abs/2509.19282)
*Bingnan Li,Chen-Yu Wang,Haiyang Xu,Xiang Zhang,Ethan Armand,Divyansh Srivastava,Xiaojun Shan,Zeyuan Chen,Jianwen Xie,Zhuowen Tu*

Main category: cs.CV

TL;DR: 该研究解决了布局到图像生成中边界框重叠严重的问题，提出了量化重叠复杂度的指标OverLayScore和新基准OverLayBench，并提出了初步改进模型CreatiLayout-AM，以促进更鲁棒的生成。


<details>
  <summary>Details</summary>
Motivation: 当前的布局到图像生成方法在处理边界框之间存在显著重叠的布局时表现不佳，主要挑战在于大面积重叠区域和语义区分度低的重叠实例，这导致生成质量下降。

Method: 1. 识别并分析了重叠边界框对生成质量的影响。2. 引入了OverLayScore，一个量化重叠边界框复杂度的指标。3. 创建了OverLayBench，一个具有高质量标注和不同OverLayScore值平衡分布的新基准。4. 提出了CreatiLayout-AM，一个在精选无模态掩码数据集上微调的模型，作为解决复杂重叠的初步方案。

Result: 1. 定性和定量分析表明重叠区域和语义区分度低会降低生成质量。2. 发现现有基准偏向于较低OverLayScore值的简单情况，限制了它们在挑战性条件下的评估有效性。3. OverLayBench提供了一个更具挑战性和平衡性的评估平台。4. CreatiLayout-AM作为初步尝试，展示了在复杂重叠场景下改进性能的潜力。

Conclusion: 该研究通过引入OverLayScore和OverLayBench，为在真实和挑战性场景下评估和开发更鲁棒的布局到图像生成方法奠定了基础，并提出了CreatiLayout-AM作为改进复杂重叠处理的初步步骤。

Abstract: Despite steady progress in layout-to-image generation, current methods still
struggle with layouts containing significant overlap between bounding boxes. We
identify two primary challenges: (1) large overlapping regions and (2)
overlapping instances with minimal semantic distinction. Through both
qualitative examples and quantitative analysis, we demonstrate how these
factors degrade generation quality. To systematically assess this issue, we
introduce OverLayScore, a novel metric that quantifies the complexity of
overlapping bounding boxes. Our analysis reveals that existing benchmarks are
biased toward simpler cases with low OverLayScore values, limiting their
effectiveness in evaluating model performance under more challenging
conditions. To bridge this gap, we present OverLayBench, a new benchmark
featuring high-quality annotations and a balanced distribution across different
levels of OverLayScore. As an initial step toward improving performance on
complex overlaps, we also propose CreatiLayout-AM, a model fine-tuned on a
curated amodal mask dataset. Together, our contributions lay the groundwork for
more robust layout-to-image generation under realistic and challenging
scenarios. Project link: https://mlpc-ucsd.github.io/OverLayBench.

</details>


### [169] [Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation](https://arxiv.org/abs/2509.19296)
*Sherwin Bahmani,Tianchang Shen,Jiawei Ren,Jiahui Huang,Yifeng Jiang,Haithem Turki,Andrea Tagliasacchi,David B. Lindell,Zan Gojcic,Sanja Fidler,Huan Ling,Jun Gao,Xuanchi Ren*

Main category: cs.CV

TL;DR: 本文提出一种自蒸馏框架，将视频扩散模型中的隐式3D知识蒸馏到显式3D高斯泼溅（3DGS）表示中，无需多视角训练数据，实现从文本、单图或单目视频实时生成静态和动态3D场景。


<details>
  <summary>Details</summary>
Motivation: 生成虚拟环境对游戏、机器人、自动驾驶等领域至关重要。现有基于学习的3D重建方法依赖于难以获取的真实世界多视角数据。视频扩散模型虽有强大想象力但仅限于2D，限制了其在需要与环境交互的3D模拟中的应用。

Method: 提出一个自蒸馏框架。在典型的RGB解码器基础上增加一个3DGS解码器，该3DGS解码器由RGB解码器的输出进行监督。通过这种方式，3DGS解码器可以完全使用视频扩散模型生成的合成数据进行训练。在推理时，模型可以从文本提示或单张图像合成3D场景，并支持实时渲染。框架还扩展到从单目输入视频生成动态3D场景。

Result: 在静态和动态3D场景生成方面，该框架取得了最先进的性能。模型能够在推理时从文本提示、单张图像或单目视频合成3D场景，并支持实时渲染。

Conclusion: 该框架通过自蒸馏方式，成功将2D视频扩散模型的隐式3D知识转化为显式3DGS表示，解决了多视角训练数据需求的问题，并实现了从多种2D输入实时生成高质量的静态和动态3D场景，达到了最先进水平。

Abstract: The ability to generate virtual environments is crucial for applications
ranging from gaming to physical AI domains such as robotics, autonomous
driving, and industrial AI. Current learning-based 3D reconstruction methods
rely on the availability of captured real-world multi-view data, which is not
always readily available. Recent advancements in video diffusion models have
shown remarkable imagination capabilities, yet their 2D nature limits the
applications to simulation where a robot needs to navigate and interact with
the environment. In this paper, we propose a self-distillation framework that
aims to distill the implicit 3D knowledge in the video diffusion models into an
explicit 3D Gaussian Splatting (3DGS) representation, eliminating the need for
multi-view training data. Specifically, we augment the typical RGB decoder with
a 3DGS decoder, which is supervised by the output of the RGB decoder. In this
approach, the 3DGS decoder can be purely trained with synthetic data generated
by video diffusion models. At inference time, our model can synthesize 3D
scenes from either a text prompt or a single image for real-time rendering. Our
framework further extends to dynamic 3D scene generation from a monocular input
video. Experimental results show that our framework achieves state-of-the-art
performance in static and dynamic 3D scene generation.

</details>


### [170] [VolSplat: Rethinking Feed-Forward 3D Gaussian Splatting with Voxel-Aligned Prediction](https://arxiv.org/abs/2509.19297)
*Weijie Wang,Yeqing Chen,Zeyu Zhang,Hengyu Liu,Haoxiao Wang,Zhiyuan Feng,Wenkang Qin,Zheng Zhu,Donny Y. Chen,Bohan Zhuang*

Main category: cs.CV

TL;DR: VolSplat提出了一种新的多视角前馈3D高斯溅射范式，用体素对齐的高斯取代像素对齐的高斯，以解决现有方法的局限性，实现了最先进的新视角合成性能和更鲁棒的3D重建。


<details>
  <summary>Details</summary>
Motivation: 现有的前馈3D高斯溅射方法主要依赖于像素对齐的高斯预测，导致重建的3D模型过度依赖输入视图数量、产生视角偏置的密度分布，并在遮挡或低纹理区域引入对齐误差。

Method: VolSplat引入了一种新的多视角前馈范式，用体素对齐的高斯取代像素对齐。它直接从预测的3D体素网格中预测高斯，避免了易出错的2D特征匹配，确保了鲁棒的多视角一致性。此外，它能根据3D场景复杂性自适应控制高斯密度。

Result: 在RealEstate10K和ScanNet等基准测试中，VolSplat达到了最先进的性能，生成了更合理、视角更一致的高斯重建。它还建立了一个更具可扩展性的前馈3D重建框架，具有更密集、更鲁棒的表示。

Conclusion: VolSplat通过提出体素对齐的高斯范式，克服了现有像素对齐方法的局限性，实现了卓越的新视角渲染质量和更可靠的3D几何一致性，为未来更广泛的3D重建研究铺平了道路。

Abstract: Feed-forward 3D Gaussian Splatting (3DGS) has emerged as a highly effective
solution for novel view synthesis. Existing methods predominantly rely on a
pixel-aligned Gaussian prediction paradigm, where each 2D pixel is mapped to a
3D Gaussian. We rethink this widely adopted formulation and identify several
inherent limitations: it renders the reconstructed 3D models heavily dependent
on the number of input views, leads to view-biased density distributions, and
introduces alignment errors, particularly when source views contain occlusions
or low texture. To address these challenges, we introduce VolSplat, a new
multi-view feed-forward paradigm that replaces pixel alignment with
voxel-aligned Gaussians. By directly predicting Gaussians from a predicted 3D
voxel grid, it overcomes pixel alignment's reliance on error-prone 2D feature
matching, ensuring robust multi-view consistency. Furthermore, it enables
adaptive control over Gaussian density based on 3D scene complexity, yielding
more faithful Gaussian point clouds, improved geometric consistency, and
enhanced novel-view rendering quality. Experiments on widely used benchmarks
including RealEstate10K and ScanNet demonstrate that VolSplat achieves
state-of-the-art performance while producing more plausible and view-consistent
Gaussian reconstructions. In addition to superior results, our approach
establishes a more scalable framework for feed-forward 3D reconstruction with
denser and more robust representations, paving the way for further research in
wider communities. The video results, code and trained models are available on
our project page: https://lhmd.top/volsplat.

</details>


### [171] [CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching](https://arxiv.org/abs/2509.19300)
*Chen Chen,Pengsheng Guo,Liangchen Song,Jiasen Lu,Rui Qian,Xinze Wang,Tsu-Jui Fu,Wei Liu,Yinfei Yang,Alex Schwing*

Main category: cs.CV

TL;DR: 该论文提出了CAR-Flow，一种用于流匹配的条件感知重参数化方法，通过学习轻量级偏移来调整源或目标分布，从而简化模型学习任务，实现更快训练和更优性能，且参数开销极小。


<details>
  <summary>Details</summary>
Motivation: 现有的条件生成模型（如扩散模型和流模型）需要学习质量传输和条件注入两项任务，这对模型要求较高。研究旨在减轻模型的学习负担。

Method: 提出条件感知重参数化（CAR-Flow），它是一个轻量级的、学习到的偏移，用于调整源分布、目标分布或两者。通过重新定位这些分布，CAR-Flow缩短了模型需要学习的概率路径。

Result: 在低维合成数据上，CAR-Flow的效果得到了可视化和量化。在ImageNet-256图像数据上，将CAR-Flow集成到SiT-XL/2中，FID从2.07降低到1.68，同时只增加了不到0.6%的额外参数，并且在实践中实现了更快的训练。

Conclusion: CAR-Flow通过条件感知重参数化有效简化了条件生成模型的学习任务，显著提升了模型性能（降低FID）并加速了训练，同时保持了极低的额外参数开销。

Abstract: Conditional generative modeling aims to learn a conditional data distribution
from samples containing data-condition pairs. For this, diffusion and
flow-based methods have attained compelling results. These methods use a
learned (flow) model to transport an initial standard Gaussian noise that
ignores the condition to the conditional data distribution. The model is hence
required to learn both mass transport and conditional injection. To ease the
demand on the model, we propose Condition-Aware Reparameterization for Flow
Matching (CAR-Flow) -- a lightweight, learned shift that conditions the source,
the target, or both distributions. By relocating these distributions, CAR-Flow
shortens the probability path the model must learn, leading to faster training
in practice. On low-dimensional synthetic data, we visualize and quantify the
effects of CAR. On higher-dimensional natural image data (ImageNet-256),
equipping SiT-XL/2 with CAR-Flow reduces FID from 2.07 to 1.68, while
introducing less than 0.6% additional parameters.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [172] [Dynamic Prompt Fusion for Multi-Task and Cross-Domain Adaptation in LLMs](https://arxiv.org/abs/2509.18113)
*Xin Hu,Yue Kang,Guanzi Yao,Tianze Kang,Mengjie Wang,Heyao Liu*

Main category: cs.CL

TL;DR: 本研究提出了一种动态提示调度机制，用于统一的多任务学习框架，以解决大型语言模型在多任务和跨领域设置中的泛化限制，显著提升了模型性能和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多任务和跨领域设置中存在泛化能力限制，且现有方法（如SPoT）依赖固定的提示模板，无法有效捕捉任务间的语义差异。

Method: 该研究引入了一个统一的多任务学习框架，包含动态提示调度机制。具体方法包括：构建一个提示池和任务感知调度策略，动态组合和对齐不同任务的提示；在提示融合阶段，利用任务嵌入和门控机制精细控制提示信号，确保提示内容与任务需求对齐，并构建灵活的任务间共享路径；优化目标侧重于联合多任务学习，并整合了调度权重自动学习策略，以减轻任务干扰和负迁移。

Result: 通过一系列敏感性实验（考察提示温度参数和任务数量变化），结果证实了所提出机制在保持模型稳定性、增强可迁移性方面的优势。实验发现，提示调度方法显著提高了模型在多项语言理解和知识推理任务上的性能。

Conclusion: 该动态提示调度方法在统一多任务建模和跨领域适应性方面表现出良好的适用性和有效性，充分证明了其在解决大型语言模型泛化问题上的潜力。

Abstract: This study addresses the generalization limitations commonly observed in
large language models under multi-task and cross-domain settings. Unlike prior
methods such as SPoT, which depends on fixed prompt templates, our study
introduces a unified multi-task learning framework with dynamic prompt
scheduling mechanism. By introducing a prompt pool and a task-aware scheduling
strategy, the method dynamically combines and aligns prompts for different
tasks. This enhances the model's ability to capture semantic differences across
tasks. During prompt fusion, the model uses task embeddings and a gating
mechanism to finely control the prompt signals. This ensures alignment between
prompt content and task-specific demands. At the same time, it builds flexible
sharing pathways across tasks. In addition, the proposed optimization objective
centers on joint multi-task learning. It incorporates an automatic learning
strategy for scheduling weights, which effectively mitigates task interference
and negative transfer. To evaluate the effectiveness of the method, a series of
sensitivity experiments were conducted. These experiments examined the impact
of prompt temperature parameters and task number variation. The results confirm
the advantages of the proposed mechanism in maintaining model stability and
enhancing transferability. Experimental findings show that the prompt
scheduling method significantly improves performance on a range of language
understanding and knowledge reasoning tasks. These results fully demonstrate
its applicability and effectiveness in unified multi-task modeling and
cross-domain adaptation.

</details>


### [173] [GAUSS: Benchmarking Structured Mathematical Skills for Large Language Models](https://arxiv.org/abs/2509.18122)
*Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma*

Main category: cs.CL

TL;DR: GAUSS是一个评估大型语言模型（LLM）数学能力的基准，通过12个核心技能维度提供全面、细粒度且可解释的模型数学智能剖析。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法未能提供LLM底层数学能力的细致、可解释的剖析，无法真实反映其数学智能。

Method: 引入GAUSS基准，将数学能力分为知识与理解、问题解决与沟通、元技能与创造力三个领域共十二个核心技能维度。通过根据认知技能对问题进行分类，并设计隔离特定能力的任务来构建评估体系。

Result: GAUSS能够构建全面、细粒度且可解释的模型数学能力剖析，忠实地代表其底层数学智能。以GPT-5-thinking为例，揭示了其优缺点以及与o4-mini-high的差异，突显了多维度、基于技能评估的价值。

Conclusion: GAUSS基准通过多维度、基于技能的评估方法，能够更深入、真实地评估和理解LLM的数学能力及潜在智能。

Abstract: We introduce \textbf{GAUSS} (\textbf{G}eneral \textbf{A}ssessment of
\textbf{U}nderlying \textbf{S}tructured \textbf{S}kills in Mathematics), a
benchmark that evaluates LLMs' mathematical abilities across twelve core skill
dimensions, grouped into three domains: knowledge and understanding, problem
solving and communication, and meta-skills and creativity. By categorizing
problems according to cognitive skills and designing tasks that isolate
specific abilities, GAUSS constructs comprehensive, fine-grained, and
interpretable profiles of models' mathematical abilities. These profiles
faithfully represent their underlying mathematical intelligence. To exemplify
how to use the \textsc{GAUSS} benchmark, we have derived the skill profile of
\textsc{GPT-5-thinking}, revealing its strengths and weaknesses as well as its
differences relative to \textsc{o4-mini-high}, thereby underscoring the value
of multidimensional, skill-based evaluation.

</details>


### [174] [Event Causality Identification with Synthetic Control](https://arxiv.org/abs/2509.18156)
*Haoyu Wang,Fengze Liu,Jiayao Zhang,Dan Roth,Kyle Richardson*

Main category: cs.CL

TL;DR: 本文提出一种基于Rubin因果模型和合成控制方法的新型事件因果识别（ECI）框架，通过生成“合成双胞胎”来模拟反事实情景，从而更鲁棒地识别因果关系，优于传统方法和GPT-4。


<details>
  <summary>Details</summary>
Motivation: 传统的事件因果识别方法主要依赖语言模式和多跳关系推理，存在因非正式语言使用和虚假图推理导致错误识别因果关系的风险。区分因果和相关性至关重要。

Method: 该研究采用Rubin因果模型，将两个按时间顺序排列的事件中的第一个视为“处理”，第二个视为“观察结果”。为确定因果关系，需概念性地操纵“处理”并估计结果事件发生可能性的变化。由于在文本领域无法实际操纵，作者提出通过合成控制方法，利用文本嵌入合成和反演技术，从相关历史数据中生成一个“合成双胞胎”，该“双胞胎”在“处理”前具有与主角相同的经历，但经历了不同的干预。

Result: 该方法能够比包括GPT-4在内的现有方法更鲁棒地识别因果关系，并在因果关系基准测试COPES-hard上得到了验证。

Conclusion: 通过结合Rubin因果模型和合成控制方法，该研究提供了一种新颖且更鲁棒的事件因果识别范式，有效克服了传统方法和大型语言模型在区分因果与相关性方面的局限性。

Abstract: Event causality identification (ECI), a process that extracts causal
relations between events from text, is crucial for distinguishing causation
from correlation. Traditional approaches to ECI have primarily utilized
linguistic patterns and multi-hop relational inference, risking false causality
identification due to informal usage of causality and specious graphical
inference. In this paper, we adopt the Rubin Causal Model to identify event
causality: given two temporally ordered events, we see the first event as the
treatment and the second one as the observed outcome. Determining their
causality involves manipulating the treatment and estimating the resultant
change in the likelihood of the outcome. Given that it is only possible to
implement manipulation conceptually in the text domain, as a work-around, we
try to find a twin for the protagonist from existing corpora. This twin should
have identical life experiences with the protagonist before the treatment but
undergoes an intervention of treatment. However, the practical difficulty of
locating such a match limits its feasibility. Addressing this issue, we use the
synthetic control method to generate such a twin' from relevant historical
data, leveraging text embedding synthesis and inversion techniques. This
approach allows us to identify causal relations more robustly than previous
methods, including GPT-4, which is demonstrated on a causality benchmark,
COPES-hard.

</details>


### [175] [ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization](https://arxiv.org/abs/2509.18158)
*Seungyoun Yi,Minsoo Khang,Sungrae Park*

Main category: cs.CL

TL;DR: ZERA是一个新颖的框架，通过联合优化系统和用户提示词，并使用结构化反馈和最少示例，显著改进了大型语言模型（LLM）的自动提示词优化（APO）性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自动提示词优化（APO）方法通常只关注用户提示词，依赖非结构化反馈，需要大量样本和漫长的迭代周期，导致成本高昂且脆弱。

Method: ZERA（Zero-init Instruction Evolving Refinement Agent）框架通过以下方式进行提示词优化：1) 联合优化系统和用户提示词；2) 使用八个可泛化标准对提示词进行评分，并自动推断权重；3) 基于结构化批判修订提示词。这使得它能够以最少的示例和短迭代周期快速收敛到高质量的提示词。

Result: 在五种LLM和九个涵盖推理、摘要和代码生成的不同数据集上，ZERA始终优于强大的基线。进一步的消融研究也强调了每个组件对更有效提示词构建的贡献。

Conclusion: ZERA是一种有效且低开销的联合提示词优化框架，通过解决现有APO方法的局限性，显著提高了LLM的性能。

Abstract: Automatic Prompt Optimization (APO) improves large language model (LLM)
performance by refining prompts for specific tasks. However, prior APO methods
typically focus only on user prompts, rely on unstructured feedback, and
require large sample sizes and long iteration cycles-making them costly and
brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a
novel framework that jointly optimizes both system and user prompts through
principled, low-overhead refinement. ZERA scores prompts using eight
generalizable criteria with automatically inferred weights, and revises prompts
based on these structured critiques. This enables fast convergence to
high-quality prompts using minimal examples and short iteration cycles. We
evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning,
summarization, and code generation tasks. Experimental results demonstrate
consistent improvements over strong baselines. Further ablation studies
highlight the contribution of each component to more effective prompt
construction. Our implementation including all prompts is publicly available at
https://github.com/younatics/zera-agent.

</details>


### [176] [Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning](https://arxiv.org/abs/2509.18163)
*Haodong Zhao,Chenyan Zhao,Yansi Li,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: 研究发现，大语言模型（LLMs）的逐步推理能力在面对辅助信息时是把双刃剑：有益信息能提高准确性，但误导信息会导致灾难性的性能下降，且这种下降会被其“思考”过程放大。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂领域中的推理能力至关重要，且通常会结合外部信息。然而，这些外部信息可能有用、无关甚至具有误导性。本研究旨在探讨这些辅助信息对具有明确逐步思考能力的大语言模型推理过程的因果影响。

Method: 通过引入一个名为SciAux的新数据集（源自ScienceQA），系统地测试模型对不同类型辅助信息（有益、无关、误导）的鲁棒性，并调查其对大语言模型逐步思考过程的影响。

Result: 研究发现，模型的“思考模式”是一把双刃剑。有益的上下文信息能提高准确性，但误导性信息会导致性能灾难性下降，并且这种下降会被思考过程放大。思考非但没有增强鲁棒性，反而会在接收到错误信息时加剧错误程度。

Conclusion: 挑战并非仅仅在于让模型“思考”，更在于赋予它们评估其推理所依据信息的能力。模型需要具备批判性思维，以甄别和评估辅助信息的质量。

Abstract: The capacity of Large Language Models (LLMs) to reason is fundamental to
their application in complex, knowledge-intensive domains. In real-world
scenarios, LLMs are often augmented with external information that can be
helpful, irrelevant, or even misleading. This paper investigates the causal
impact of such auxiliary information on the reasoning process of LLMs with
explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset
derived from ScienceQA, to systematically test the robustness of the model
against these types of information. Our findings reveal a critical
vulnerability: the model's deliberative "thinking mode" is a double-edged
sword. While helpful context improves accuracy, misleading information causes a
catastrophic drop in performance, which is amplified by the thinking process.
Instead of conferring robustness, thinking reinforces the degree of error when
provided with misinformation. This highlights that the challenge is not merely
to make models "think", but to endow them with the critical faculty to evaluate
the information upon which their reasoning is based. The SciAux dataset is
available at https://huggingface.co/datasets/billhdzhao/SciAux.

</details>


### [177] [SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework](https://arxiv.org/abs/2509.18167)
*Junlin Wang,Zehao Wu,Shaowei Lu,Yanlan Li,Xinghao Huang*

Main category: cs.CL

TL;DR: 本文提出了一种过程监督的多智能体框架，通过引入决策者和知识选择器，并使用LLM作为评判者提供细粒度奖励，以优化检索增强生成（RAG）中检索器和生成器之间的协调，从而提高问答准确性。


<details>
  <summary>Details</summary>
Motivation: RAG的效果受限于检索器和生成器之间次优的协调。检索器可能返回不相关或冗余的文档，而生成器可能未能充分利用检索到的证据，因为这两个组件是独立开发的。

Method: 提出了一个过程监督的多智能体框架，包含两个轻量级智能体：一个决策者（决定何时继续检索或停止生成答案）和一个知识选择器（过滤检索到的文档以保留最有用证据）。通过将LLM用作评判者，为每个中间动作提供过程级奖励，以实现更准确的归因。采用树状展开策略探索不同的推理路径，并使用近端策略优化（PPO）端到端训练两个智能体。该框架是模块化和即插即用的，无需修改检索器或生成器。

Result: 在单跳和多跳问答基准测试中，该方法实现了更高的准确性、更稳定的收敛，并产生了比标准RAG基线更可解释的推理轨迹。该框架的模块化和即插即用特性使其适用于实际的RAG应用。

Conclusion: 该框架通过引入智能体和过程级监督，成功弥合了检索器和生成器之间的鸿沟，显著提升了RAG的性能和可解释性，且无需修改现有组件，具有很高的实用价值。

Abstract: Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to
access external knowledge sources, but the effectiveness of RAG relies on the
coordination between the retriever and the generator. Since these components
are developed independently, their interaction is often suboptimal: the
retriever may return irrelevant or redundant documents, while the generator may
fail to fully leverage retrieved evidence. In this work, we propose a
process-supervised multi-agent framework to bridge the gap between retriever
and generator. The framework introduces two lightweight agents: a Decision
Maker, which determines when to continue retrieval or stop for answer
generation, and a Knowledge Selector, which filters retrieved documents to
retain only the most useful evidence. To provide fine-grained supervision, we
employ an LLM-as-a-Judge that evaluates each intermediate action with
process-level rewards, ensuring more accurate credit assignment than relying
solely on final answer correctness. We further adopt a tree-structured rollout
strategy to explore diverse reasoning paths, and train both agents with
Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on
single-hop and multi-hop question answering benchmarks show that our approach
achieves higher accuracy, more stable convergence, and produces more
interpretable reasoning trajectories compared with standard RAG baselines.
Importantly, the proposed framework is modular and plug-and-play, requiring no
modification to the retriever or generator, making it practical for real-world
RAG applications.

</details>


### [178] [ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers](https://arxiv.org/abs/2509.18175)
*Aditi Debsharma,Bhushan Jagyasi,Surajit Sen,Priyanka Pandey,Devicharith Dovari,Yuvaraj V. C,Rosalin Parida,Gopali Contractor*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的对话情感识别与预测（ERFC）架构，通过考虑多模态、情感属性、上下文和语料依赖性，预测对话中未来话语的情感，以提升客户服务体验。


<details>
  <summary>Details</summary>
Motivation: 对话中的情感识别在多个行业有广泛应用，尤其在呼叫中心场景中，客服人员需要通过管理客户情绪来提供良好的客户体验。预测未来话语的情感可以帮助客服人员更及时地提供正确的解决方案，从而将不满意的客户转变为满意的客户。

Method: 提出了一种名为“对话情感识别与预测”（Emotion Recognition and Forecasting in Conversation, ERFC）的新型架构。该架构考虑了多模态信息、情感的不同属性、对话上下文以及对话中说话者话语之间的相互依赖性。

Result: 在IEMOCAP数据集上进行的密集实验表明，所提出的ERFC架构是可行的。

Conclusion: 该ERFC方法可以为呼叫中心等客户满意度至关重要的应用带来巨大的商业价值。

Abstract: Emotion Recognition in Conversation has been seen to be widely applicable in
call center analytics, opinion mining, finance, retail, healthcare, and other
industries. In a call center scenario, the role of the call center agent is not
just confined to receiving calls but to also provide good customer experience
by pacifying the frustration or anger of the customers. This can be achieved by
maintaining neutral and positive emotion from the agent. As in any
conversation, the emotion of one speaker is usually dependent on the emotion of
other speaker. Hence the positive emotion of an agent, accompanied with the
right resolution will help in enhancing customer experience. This can change an
unhappy customer to a happy one. Imparting the right resolution at right time
becomes easier if the agent has the insight of the emotion of future
utterances. To predict the emotions of the future utterances we propose a novel
architecture, Emotion Recognition and Forecasting in Conversation. Our proposed
ERFC architecture considers multi modalities, different attributes of emotion,
context and the interdependencies of the utterances of the speakers in the
conversation. Our intensive experiments on the IEMOCAP dataset have shown the
feasibility of the proposed ERFC. This approach can provide a tremendous
business value for the applications like call center, where the happiness of
customer is utmost important.

</details>


### [179] [Evaluating Large Language Models for Detecting Antisemitism](https://arxiv.org/abs/2509.18293)
*Jay Patel,Hrudayangam Mehta,Jeremy Blackburn*

Main category: cs.CL

TL;DR: 该研究评估了八个开源大型语言模型（LLM）检测反犹太内容的能力，引入了Guided-CoT提示技术，发现其能显著提升模型性能，并指出Llama 3.1 70B表现优于微调的GPT-3.5。同时，研究还分析了LLM的错误和语义分歧。


<details>
  <summary>Details</summary>
Motivation: 检测仇恨内容是一个具有挑战性且重要的问题，自动化工具（如机器学习模型）需要持续训练以适应不断变化的社交媒体环境，尤其是在检测反犹太内容方面。

Method: 研究评估了八个开源LLM检测反犹太内容的能力，将上下文定义作为政策指南。探索了多种提示技术，并设计了一种新的类CoT（Chain-of-Thought）提示——Guided-CoT。此外，还检查了LLM的错误，并引入了量化模型生成理由中语义分歧的指标。

Result: Guided-CoT提示能够很好地处理上下文策略，提高所有评估模型的性能，无论解码配置、模型大小或推理能力如何。值得注意的是，Llama 3.1 70B的表现优于微调的GPT-3.5。对LLM错误的检查揭示了模型生成理由中显著的语义分歧和矛盾行为。

Conclusion: 实验结果突出了LLM在实用性、可解释性和可靠性方面存在的差异。Guided-CoT提示技术有效提升了LLM在仇恨内容检测任务上的表现，特别是Llama 3.1 70B展现出强大的潜力。

Abstract: Detecting hateful content is a challenging and important problem. Automated
tools, like machine-learning models, can help, but they require continuous
training to adapt to the ever-changing landscape of social media. In this work,
we evaluate eight open-source LLMs' capability to detect antisemitic content,
specifically leveraging in-context definition as a policy guideline. We explore
various prompting techniques and design a new CoT-like prompt, Guided-CoT.
Guided-CoT handles the in-context policy well, increasing performance across
all evaluated models, regardless of decoding configuration, model sizes, or
reasoning capability. Notably, Llama 3.1 70B outperforms fine-tuned GPT-3.5.
Additionally, we examine LLM errors and introduce metrics to quantify semantic
divergence in model-generated rationales, revealing notable differences and
paradoxical behaviors among LLMs. Our experiments highlight the differences
observed across LLMs' utility, explainability, and reliability.

</details>


### [180] [Exploiting Tree Structure for Credit Assignment in RL Training of LLMs](https://arxiv.org/abs/2509.18314)
*Hieu Tran,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Reinforcement learning improves LLM reasoning, yet sparse delayed reward over
long sequences makes token-level credit assignment the key bottleneck. We study
the verifiable-reward setting, where the final answer is checkable and multiple
responses can be drawn per prompt. Reasoning tasks in math and medical QA align
with this setup, where only a few decision tokens significantly impact the
outcome. PPO offers token-level advantages with a learned value model, but it
is complex to train both the actor and critic models simultaneously, and it is
not easily generalizable, as the token-level values from the critic model can
make training prone to overfitting. GRPO is critic-free and supports verifiable
rewards, but spreads a single sequence-level return across tokens and ignores
branching. We introduce \textbf{Prefix-to-Tree (P2T)}, a simple procedure that
converts a group of responses into a prefix tree and computes
\emph{nonparametric} prefix values \(V(s)\) by aggregating descendant outcomes.
Built on P2T, we propose \textbf{TEMPO} (\emph{\textbf{T}ree-\textbf{E}stimated
\textbf{M}ean Prefix Value for \textbf{P}olicy \textbf{O}ptimization}), a
critic-free algorithm that augments the group-relative outcome signal of GRPO
with \emph{branch-gated} temporal-difference corrections derived from the tree.
At non-branch tokens, the temporal-difference (TD) term is zero, so TEMPO
reduces to GRPO; at branching tokens, it supplies precise token-level credit
without a learned value network or extra judges/teachers. On Qwen3-1.7B/4B,
TEMPO outperforms PPO and GRPO on in-distribution (MATH, MedQA) and
out-of-distribution (GSM-HARD, AMC23, MedMCQA, MMLU-Medical) benchmarks, and
reaches higher validation accuracy with roughly the same wall-clock time.

</details>


### [181] [Brittleness and Promise: Knowledge Graph Based Reward Modeling for Diagnostic Reasoning](https://arxiv.org/abs/2509.18316)
*Saksham Khatwani,He Cheng,Majid Afshar,Dmitriy Dligach,Yanjun Gao*

Main category: cs.CL

TL;DR: 该研究探索了一种新的范式，将大型语言模型（LLM）作为知识图谱（KG）推理路径的奖励模型，以提高诊断推理的可靠性。尽管在路径判断上表现出色，但其到下游诊断任务的泛化能力较弱。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在诊断推理方面有潜力，但缺乏可靠的、基于知识的推理能力。知识图谱（如UMLS）提供了结构化的生物医学知识，可以支持可信赖的推理。现有的KG整合方法（如检索增强生成或微调）主要将KG内容插入提示中，而非实现结构化推理。本文受奖励训练和计算理论（验证解决方案通常比从头生成更容易）的启发，提出了一种将LLM作为KG推理路径奖励模型的替代范式。

Method: 该方法将LLM视为KG推理路径的奖励模型，让模型判断候选路径是否能导致正确的诊断。具体包括：1. 系统评估了五种知识路径判断任务的表述方式。2. 系统评估了八种训练范式。3. 测试了路径判断能力是否能泛化到下游诊断任务，包括诊断摘要和医学问答。实验使用了三个开源的指令微调LLM。

Result: 特定的奖励优化和蒸馏方法能够带来强大的路径判断性能。然而，其向诊断摘要和医学问答等下游任务的泛化能力仍然较弱。

Conclusion: 该研究首次系统评估了在临床知识图谱上采用“奖励模型式”推理的方法，为结构化、基于奖励的监督如何影响医疗领域生成式AI系统的诊断推理提供了见解。

Abstract: Large language models (LLMs) show promise for diagnostic reasoning but often
lack reliable, knowledge grounded inference. Knowledge graphs (KGs), such as
the Unified Medical Language System (UMLS), offer structured biomedical
knowledge that can support trustworthy reasoning. Prior approaches typically
integrate KGs via retrieval augmented generation or fine tuning, inserting KG
content into prompts rather than enabling structured reasoning. We explore an
alternative paradigm: treating the LLM as a reward model of KG reasoning paths,
where the model learns to judge whether a candidate path leads to correct
diagnosis for a given patient input. This approach is inspired by recent work
that leverages reward training to enhance model reasoning abilities, and
grounded in computational theory, which suggests that verifying a solution is
often easier than generating one from scratch. It also parallels physicians'
diagnostic assessment, where they judge which sequences of findings and
intermediate conditions most plausibly support a diagnosis. We first
systematically evaluate five task formulation for knowledge path judging and
eight training paradigm. Second, we test whether the path judging abilities
generalize to downstream diagnostic tasks, including diagnosis summarization
and medical question answering. Experiments with three open source
instruct-tuned LLMs reveal both promise and brittleness: while specific reward
optimization and distillation lead to strong path-judging performance, the
transferability to downstream tasks remain weak. Our finding provides the first
systematic assessment of "reward model style" reasoning over clinical KGs,
offering insights into how structured, reward-based supervision influences
diagnostic reasoning in GenAI systems for healthcare.

</details>


### [182] [Speculate Deep and Accurate: Lossless and Training-Free Acceleration for Offloaded LLMs via Substitute Speculative Decoding](https://arxiv.org/abs/2509.18344)
*Pei-Shuo Wang,Jian-Jia Chen,Chun-Che Yang,Chi-Chih Chang,Ning-Chi Huang,Mohamed S. Abdelfattah,Kai-Chiang Wu*

Main category: cs.CL

TL;DR: SubSpec是一种无损、免训练的即插即用方法，通过从卸载的目标LLM部分生成低比特量化替代层来构建高度对齐的草稿模型，并共享GPU驻留层和KV-Cache，显著加速了参数卸载场景下的LLM推理，解决了内存限制消费级GPU上的部署挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的巨大尺寸使得在内存受限的消费级GPU上部署面临挑战。现有策略如模型压缩会降低质量，参数卸载虽然保持质量但推理速度慢。推测解码可以加速参数卸载，但现有方法通常依赖预训练权重或需要额外训练来对齐，且训练草稿模型的方法因对齐不足导致加速效果不明显。

Method: 本文提出了SubSpec，一种无损、免训练的即插即用方法来加速参数卸载。SubSpec通过从卸载的目标LLM部分生成低比特量化替代层来构建高度对齐的草稿模型。此外，该方法还共享剩余的GPU驻留层和KV-Cache，进一步减少内存开销并增强对齐。

Result: SubSpec实现了较高的平均接受长度，在MT-Bench上为Qwen2.5 7B（8GB显存限制）提供了9.1倍的加速，在流行的生成基准测试中为Qwen2.5 32B（24GB显存限制）平均提供了12.5倍的加速。

Conclusion: SubSpec通过构建高度对齐的量化替代层草稿模型并共享资源，成功地在不损失质量和无需训练的情况下，显著加速了内存受限GPU上LLM的参数卸载推理，解决了现有方法的局限性。

Abstract: The immense model sizes of large language models (LLMs) challenge deployment
on memory-limited consumer GPUs. Although model compression and parameter
offloading are common strategies to address memory limitations, compression can
degrade quality, and offloading maintains quality but suffers from slow
inference. Speculative decoding presents a promising avenue to accelerate
parameter offloading, utilizing a fast draft model to propose multiple draft
tokens, which are then verified by the target LLM in parallel with a single
forward pass. This method reduces the time-consuming data transfers in forward
passes that involve offloaded weight transfers. Existing methods often rely on
pretrained weights of the same family, but require additional training to align
with custom-trained models. Moreover, approaches that involve draft model
training usually yield only modest speedups. This limitation arises from
insufficient alignment with the target model, preventing higher token
acceptance lengths. To address these challenges and achieve greater speedups,
we propose SubSpec, a plug-and-play method to accelerate parameter offloading
that is lossless and training-free. SubSpec constructs a highly aligned draft
model by generating low-bit quantized substitute layers from offloaded target
LLM portions. Additionally, our method shares the remaining GPU-resident layers
and the KV-Cache, further reducing memory overhead and enhance alignment.
SubSpec achieves a high average acceptance length, delivering 9.1x speedup for
Qwen2.5 7B on MT-Bench (8GB VRAM limit) and an average of 12.5x speedup for
Qwen2.5 32B on popular generation benchmarks (24GB VRAM limit).

</details>


### [183] [Speech Vecalign: an Embedding-based Method for Aligning Parallel Speech Documents](https://arxiv.org/abs/2509.18360)
*Chutong Meng,Philipp Koehn*

Main category: cs.CL

TL;DR: 本文提出Speech Vecalign，一种不依赖文本转录的并行语音文档对齐方法。它能生成更长、更鲁棒的对齐结果，并在语音到语音翻译任务中显著优于现有基线方法，甚至在数据量更少的情况下能与先进模型媲美或超越。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种不依赖文本转录、能生成高质量、鲁棒且更长语音到语音对齐的并行语音文档对齐方法，以改进语音到语音翻译模型的性能。

Method: 本文提出Speech Vecalign方法，该方法通过单调对齐语音片段嵌入来实现并行语音文档对齐，且不依赖于文本转录。

Result: 1. Speech Vecalign比基线方法Global Mining能产生更长的语音到语音对齐。2. 它比Local Mining更具鲁棒性，产生的噪声更少。3. 应用于3000小时的未标注英德并行语音数据，生成了约1000小时的高质量对齐。4. 基于这些对齐数据训练的英德语音到语音翻译模型，在En-to-De和De-to-En任务上的ASR-BLEU分数分别比Global Mining提高了0.37和0.18。5. 尽管使用了少8倍的原始语音文档，其模型性能与SpeechMatrix模型相当或更优。

Conclusion: Speech Vecalign是一种高效且鲁棒的并行语音文档对齐方法，无需文本转录即可生成高质量的对齐数据。这些对齐数据能显著提升语音到语音翻译模型的性能，甚至在数据量较少的情况下也能超越现有先进模型。

Abstract: We present Speech Vecalign, a parallel speech document alignment method that
monotonically aligns speech segment embeddings and does not depend on text
transcriptions. Compared to the baseline method Global Mining, a variant of
speech mining, Speech Vecalign produces longer speech-to-speech alignments. It
also demonstrates greater robustness than Local Mining, another speech mining
variant, as it produces less noise. We applied Speech Vecalign to 3,000 hours
of unlabeled parallel English-German (En-De) speech documents from VoxPopuli,
yielding about 1,000 hours of high-quality alignments. We then trained En-De
speech-to-speech translation models on the aligned data. Speech Vecalign
improves the En-to-De and De-to-En performance over Global Mining by 0.37 and
0.18 ASR-BLEU, respectively. Moreover, our models match or outperform
SpeechMatrix model performance, despite using 8 times fewer raw speech
documents.

</details>


### [184] [Interactive Real-Time Speaker Diarization Correction with Human Feedback](https://arxiv.org/abs/2509.18377)
*Xinlu He,Yiwen Guan,Badrivishal Paurana,Zilin Dai,Jacob Whitehill*

Main category: cs.CL

TL;DR: 本文提出一个由LLM辅助的实时说话人日志纠正系统，允许用户通过简短的口头反馈修正说话人归属错误，并通过SWM技术和在线说话人注册进一步提高准确性。


<details>
  <summary>Details</summary>
Motivation: 大多数自动语音处理系统以“开环”模式运行，缺乏用户反馈，而人机协作的工作流程有可能实现更高的准确性。

Method: 该系统采用流式ASR和说话人日志，使用LLM向用户提供简洁的摘要，并接受即时整合的简短口头反馈。此外，它还开发了两种技术：1) 分割合并（SWM）技术，用于检测并分割被ASR错误归因于单个说话人的多说话人片段；2) 基于用户纠正收集在线说话人注册，以预防未来的说话人日志错误。

Result: 在AMI测试集上，LLM驱动的模拟显示，该系统将DER大幅降低了9.92%，说话人混淆错误降低了44.23%。研究还分析了不同设置下的纠正效果，包括摘要与完整转录显示、在线注册数量限制和纠正频率。

Conclusion: 该LLM辅助的说话人日志纠正系统通过实时用户反馈、SWM技术和在线注册，显著提高了说话人日志的准确性，有效减少了DER和说话人混淆错误。

Abstract: Most automatic speech processing systems operate in "open loop" mode without
user feedback about who said what; yet, human-in-the-loop workflows can
potentially enable higher accuracy. We propose an LLM-assisted speaker
diarization correction system that lets users fix speaker attribution errors in
real time. The pipeline performs streaming ASR and diarization, uses an LLM to
deliver concise summaries to the users, and accepts brief verbal feedback that
is immediately incorporated without disrupting interactions. Moreover, we
develop techniques to make the workflow more effective: First, a
split-when-merged (SWM) technique detects and splits multi-speaker segments
that the ASR erroneously attributes to just a single speaker. Second, online
speaker enrollments are collected based on users' diarization corrections, thus
helping to prevent speaker diarization errors from occurring in the future.
LLM-driven simulations on the AMI test set indicate that our system
substantially reduces DER by 9.92% and speaker confusion error by 44.23%. We
further analyze correction efficacy under different settings, including summary
vs full transcript display, the number of online enrollments limitation, and
correction frequency.

</details>


### [185] [NormGenesis: Multicultural Dialogue Generation via Exemplar-Guided Social Norm Modeling and Violation Recovery](https://arxiv.org/abs/2509.18395)
*Minki Hong,Jangho Choi,Jihie Kim*

Main category: cs.CL

TL;DR: NormGenesis是一个多文化框架，用于生成和标注跨英语、中文和韩语的社会化对话。它引入了V2R对话类型来建模规范违反后的修复过程，并通过早期迭代细化提高了语用一致性。该框架构建了一个大型数据集，并证明了其在对话质量和模型语用能力方面的显著提升。


<details>
  <summary>Details</summary>
Motivation: 对话系统需要生成不仅连贯而且符合社会规范的回复，尤其是在多文化背景下。现有方法难以捕捉社会互动的动态性（超越静态规范分类），并且在资源稀缺语言中存在语用一致性问题。

Method: 该研究提出了NormGenesis框架，用于生成和标注英语、中文和韩语的社会化对话。它引入了“违规到解决”（V2R）这一新颖对话类型，以建模规范违反后的识别和修复过程。为提高语用一致性，在对话合成早期采用基于范例的迭代细化方法，以确保语言、情感和社会文化期望的一致性。基于此框架，构建了包含10,800个多轮对话的数据集，并对每轮对话进行了规范依从性、说话者意图和情感反应的标注。

Result: 人类和LLM评估表明，NormGenesis在细化质量、对话自然度和泛化性能方面显著优于现有数据集。在V2R增强数据上训练的模型在伦理敏感语境中表现出改进的语用能力。

Conclusion: 这项工作为文化适应性对话建模建立了新的基准，并为跨语言和文化多样性的规范感知生成提供了一种可扩展的方法。

Abstract: Social norms govern culturally appropriate behavior in communication,
enabling dialogue systems to produce responses that are not only coherent but
also socially acceptable. We present NormGenesis, a multicultural framework for
generating and annotating socially grounded dialogues across English, Chinese,
and Korean. To model the dynamics of social interaction beyond static norm
classification, we propose a novel dialogue type, Violation-to-Resolution
(V2R), which models the progression of conversations following norm violations
through recognition and socially appropriate repair. To improve pragmatic
consistency in underrepresented languages, we implement an exemplar-based
iterative refinement early in the dialogue synthesis process. This design
introduces alignment with linguistic, emotional, and sociocultural expectations
before full dialogue generation begins. Using this framework, we construct a
dataset of 10,800 multi-turn dialogues annotated at the turn level for norm
adherence, speaker intent, and emotional response. Human and LLM-based
evaluations demonstrate that NormGenesis significantly outperforms existing
datasets in refinement quality, dialogue naturalness, and generalization
performance. We show that models trained on our V2R-augmented data exhibit
improved pragmatic competence in ethically sensitive contexts. Our work
establishes a new benchmark for culturally adaptive dialogue modeling and
provides a scalable methodology for norm-aware generation across linguistically
and culturally diverse languages.

</details>


### [186] [Evaluating the Creativity of LLMs in Persian Literary Text Generation](https://arxiv.org/abs/2509.18401)
*Armin Tourajmehr,Mohammad Reza Modarres,Yadollah Yaghoobzadeh*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）生成波斯语文学文本的能力，通过构建新数据集、采用适应性的创造力评估维度和使用LLM作为自动评分员，揭示了LLMs在此领域的优缺点。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs在英语文学文本生成中的创造力，对非英语文学传统（特别是波斯语）的探索有限，且缺乏标准化的创造力评估方法。

Method: 研究构建了一个包含20个主题的用户生成波斯语文学文本数据集；通过改编托兰斯创造性思维测验，从原创性、流畅性、灵活性和精细化四个维度评估模型输出；采用LLM作为自动评分员以降低评估成本，并使用组内相关系数验证其与人类判断的一致性；此外，还分析了模型理解和运用四种核心文学修辞（明喻、暗喻、夸张、对偶）的能力。

Result: 研究结果突出了LLMs在波斯语文学文本生成方面的优势和局限性。

Conclusion: LLMs在波斯语文学文本生成方面仍需进一步改进和完善。

Abstract: Large language models (LLMs) have demonstrated notable creative abilities in
generating literary texts, including poetry and short stories. However, prior
research has primarily centered on English, with limited exploration of
non-English literary traditions and without standardized methods for assessing
creativity. In this paper, we evaluate the capacity of LLMs to generate Persian
literary text enriched with culturally relevant expressions. We build a dataset
of user-generated Persian literary spanning 20 diverse topics and assess model
outputs along four creativity dimensions-originality, fluency, flexibility, and
elaboration-by adapting the Torrance Tests of Creative Thinking. To reduce
evaluation costs, we adopt an LLM as a judge for automated scoring and validate
its reliability against human judgments using intraclass correlation
coefficients, observing strong agreement. In addition, we analyze the models'
ability to understand and employ four core literary devices: simile, metaphor,
hyperbole, and antithesis. Our results highlight both the strengths and
limitations of LLMs in Persian literary text generation, underscoring the need
for further refinement.

</details>


### [187] [Developing an AI framework to automatically detect shared decision-making in patient-doctor conversations](https://arxiv.org/abs/2509.18439)
*Oscar J. Ponce-Ponte,David Toro-Tobon,Luis F. Figueroa,Michael Gionfriddo,Megan Branda,Victor M. Montori,Saturnino Luz,Juan P. Brito*

Main category: cs.CL

TL;DR: 本研究开发了一种自动、可扩展的方法，利用语言模型和对话对齐（CA）分数来衡量医患对话中的共享决策（SDM），并发现CA分数与SDM结果相关。


<details>
  <summary>Details</summary>
Motivation: 共享决策（SDM）对于实现以患者为中心的护理至关重要，但目前缺乏一种能够大规模自动衡量SDM的方法。

Method: 研究使用了157个视频录制的医患对话（共42,559句话），通过上下文-响应对和负采样训练了深度学习（DL）模型和微调的BERT模型，以执行下一句预测（NSP）任务。然后，使用表现最佳的模型计算四种类型的对话对齐（CA）分数。通过调整年龄、性别、种族和试验组的随机效应分析，评估CA分数与SDM结果（决策冲突量表DCS和观察患者参与决策量表OPTION12）之间的关联，并使用Benjamini-Hochberg方法校正p值。

Result: 在157名患者中，临床医生平均比患者说更多的话。微调的BERTbase（110M）模型在recall@1上表现最佳（0.640），优于深度学习模型（0.227）。深度学习模型生成的AbsMax和Max CA分数与OPTION12评分相关联。微调的BERTbase（110M）模型生成的Max CA分数与DCS评分相关联。BERT模型的大小对CA分数与SDM之间的关联没有影响。

Conclusion: 本研究引入了一种自动化、可扩展且可解释的方法，通过对话对齐分数来衡量医患对话中的共享决策，这为大规模评估SDM策略提供了潜力。

Abstract: Shared decision-making (SDM) is necessary to achieve patient-centred care.
Currently no methodology exists to automatically measure SDM at scale. This
study aimed to develop an automated approach to measure SDM by using language
modelling and the conversational alignment (CA) score. A total of 157
video-recorded patient-doctor conversations from a randomized multi-centre
trial evaluating SDM decision aids for anticoagulation in atrial fibrillations
were transcribed and segmented into 42,559 sentences. Context-response pairs
and negative sampling were employed to train deep learning (DL) models and
fine-tuned BERT models via the next sentence prediction (NSP) task. Each
top-performing model was used to calculate four types of CA scores. A
random-effects analysis by clinician, adjusting for age, sex, race, and trial
arm, assessed the association between CA scores and SDM outcomes: the
Decisional Conflict Scale (DCS) and the Observing Patient Involvement in
Decision-Making 12 (OPTION12) scores. p-values were corrected for multiple
comparisons with the Benjamini-Hochberg method. Among 157 patients (34% female,
mean age 70 SD 10.8), clinicians on average spoke more words than patients
(1911 vs 773). The DL model without the stylebook strategy achieved a recall@1
of 0.227, while the fine-tuned BERTbase (110M) achieved the highest recall@1
with 0.640. The AbsMax (18.36 SE7.74 p=0.025) and Max CA (21.02 SE7.63 p=0.012)
scores generated with the DL without stylebook were associated with OPTION12.
The Max CA score generated with the fine-tuned BERTbase (110M) was associated
with the DCS score (-27.61 SE12.63 p=0.037). BERT model sizes did not have an
impact the association between CA scores and SDM. This study introduces an
automated, scalable methodology to measure SDM in patient-doctor conversations
through explainable CA scores, with potential to evaluate SDM strategies at
scale.

</details>


### [188] [CogniLoad: A Synthetic Natural Language Reasoning Benchmark With Tunable Length, Intrinsic Difficulty, and Distractor Density](https://arxiv.org/abs/2509.18458)
*Daniel Kaiser,Arnoldo Frigessi,Ali Ramezani-Kebrya,Benjamin Ricaud*

Main category: cs.CL

TL;DR: 本文介绍了CogniLoad，一个基于认知负荷理论（CLT）的新型合成基准，用于精确分析大型语言模型（LLMs）在长上下文推理中的失败原因，通过独立调节任务复杂性、干扰和任务长度等参数。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM长上下文推理基准往往混淆了内在任务复杂性、干扰物干扰和任务长度等关键因素，导致无法进行精确的失败分析。

Method: 研究者引入了CogniLoad，这是一个基于认知负荷理论（CLT）的新型合成基准。它生成自然语言逻辑谜题，并独立调整反映CLT核心维度的参数：内在难度（d）控制内在负荷；干扰物与信号比（ρ）调节无关负荷；任务长度（N）作为需要相关负荷的条件的操作代理。该方法对22个最先进的推理LLM进行了评估。

Result: CogniLoad揭示了LLM在长上下文推理中表现出的明显性能敏感性。研究发现任务长度是一个主要的限制因素，并揭示了LLM对内在复杂性的不同容忍度以及对干扰物比例的U形响应。

Conclusion: CogniLoad通过对认知负荷维度的系统性和因子控制，提供了一个可复现、可扩展且诊断丰富的工具，用于剖析LLM的推理局限性并指导未来的模型开发。

Abstract: Current benchmarks for long-context reasoning in Large Language Models (LLMs)
often blur critical factors like intrinsic task complexity, distractor
interference, and task length. To enable more precise failure analysis, we
introduce CogniLoad, a novel synthetic benchmark grounded in Cognitive Load
Theory (CLT). CogniLoad generates natural-language logic puzzles with
independently tunable parameters that reflect CLT's core dimensions: intrinsic
difficulty ($d$) controls intrinsic load; distractor-to-signal ratio ($\rho$)
regulates extraneous load; and task length ($N$) serves as an operational proxy
for conditions demanding germane load. Evaluating 22 SotA reasoning LLMs,
CogniLoad reveals distinct performance sensitivities, identifying task length
as a dominant constraint and uncovering varied tolerances to intrinsic
complexity and U-shaped responses to distractor ratios. By offering systematic,
factorial control over these cognitive load dimensions, CogniLoad provides a
reproducible, scalable, and diagnostically rich tool for dissecting LLM
reasoning limitations and guiding future model development.

</details>


### [189] [LAWCAT: Efficient Distillation from Quadratic to Linear Attention with Convolution across Tokens for Long Context Modeling](https://arxiv.org/abs/2509.18467)
*Zeyu Liu,Souvik Kundu,Lianghao Jiang,Anni Li,Srikanth Ronanki,Sravan Bodapati,Gourav Datta,Peter A. Beerel*

Main category: cs.CL

TL;DR: LAWCAT是一种新颖的线性化框架，旨在高效地将预训练Transformer的能力迁移到高性能线性注意力架构，以解决Transformer的二次复杂度瓶颈，并实现长上下文、低资源消耗和边缘部署。


<details>
  <summary>Details</summary>
Motivation: Transformer架构的计算复杂度随序列长度呈二次方增长，这限制了其在延迟敏感的长上下文应用中的使用。尽管存在线性复杂度的替代方案，但从头开始训练它们需要大量资源。

Method: LAWCAT（Linear Attention with Convolution Across Time）框架：它通过集成因果Conv1D层来增强局部依赖建模，并采用归一化门控线性注意力来提高在不同上下文长度下的泛化能力。其核心思想是将预训练Transformer的能力蒸馏到线性注意力架构中。

Result: 使用1K长度序列蒸馏Mistral-7B，在22K token上实现了超过90%的passkey检索准确率，显著扩展了其有效上下文窗口。Llama3.2-1B LAWCAT变体在S-NIAH 1&2&3 (1K-8K上下文) 和BABILong (QA2&QA3, 0K-16K上下文) 任务上表现出竞争力，且所需预训练token不到预训练模型的0.1%。此外，LAWCAT对超过8K token的序列表现出比FlashAttention-2更快的预填充速度。

Conclusion: LAWCAT提供了一种高效途径，可以构建适用于边缘部署的高性能、长上下文线性模型，从而减少对大量长序列训练数据和计算资源的依赖。

Abstract: Although transformer architectures have achieved state-of-the-art performance
across diverse domains, their quadratic computational complexity with respect
to sequence length remains a significant bottleneck, particularly for
latency-sensitive long-context applications. While recent linear-complexity
alternatives are increasingly powerful, effectively training them from scratch
is still resource-intensive. To overcome these limitations, we propose LAWCAT
(Linear Attention with Convolution Across Time), a novel linearization
framework designed to efficiently transfer the capabilities of pre-trained
transformers into a performant linear attention architecture. LAWCAT integrates
causal Conv1D layers to enhance local dependency modeling and employs
normalized gated linear attention to improve generalization across varying
context lengths. Our comprehensive evaluations demonstrate that, distilling
Mistral-7B with only 1K-length sequences yields over 90\% passkey retrieval
accuracy up to 22K tokens, significantly extending its effective context
window. Similarly, Llama3.2-1B LAWCAT variant achieves competitive performance
on S-NIAH 1\&2\&3 tasks (1K-8K context length) and BABILong benchmark
(QA2\&QA3, 0K-16K context length), requiring less than 0.1\% pre-training
tokens compared with pre-training models. Furthermore, LAWCAT exhibits faster
prefill speeds than FlashAttention-2 for sequences exceeding 8K tokens. LAWCAT
thus provides an efficient pathway to high-performance, long-context linear
models suitable for edge deployment, reducing reliance on extensive
long-sequence training data and computational resources.

</details>


### [190] [Actions Speak Louder than Prompts: A Large-Scale Study of LLMs for Graph Inference](https://arxiv.org/abs/2509.18487)
*Ben Finkelshtein,Silviu Cucerzan,Sujay Kumar Jauhar,Ryen White*

Main category: cs.CL

TL;DR: 本文系统评估了大型语言模型（LLMs）在文本丰富图机器学习任务中与图数据交互的能力，发现代码生成模式表现最佳，尤其在长文本或高连接度图上；同时，所有交互策略在异配图上依然有效，且代码生成能灵活调整对结构、特征或标签的依赖。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在文本丰富的图机器学习任务（如欺诈检测、推荐系统中的节点分类）中应用日益广泛，但目前对LLMs与图数据交互能力的原理性理解尚不足。

Method: 研究进行了一项大规模、受控的评估，涵盖了多个关键变量：LLM-图交互模式（提示、工具使用、代码生成）、数据集领域（引用、网页链接、电商、社交网络）、结构类型（同配图、异配图）、特征特性（短文本、长文本节点属性）以及LLM模型配置（不同大小和推理能力）。此外，通过截断特征、删除边和移除标签来量化LLM对输入类型的依赖性。

Result: 1. LLM作为代码生成器在图数据上取得了最强的整体性能，尤其在长文本或高连接度图上，显著优于提示模式。2. 所有交互策略在异配图上均保持有效，挑战了LLM方法在低同配性下失效的假设。3. 代码生成模式能够灵活调整其对结构、特征或标签的依赖，从而利用最具信息量的输入类型。

Conclusion: 这些发现全面揭示了当前LLM-图交互模式的优势和局限性，并为未来方法的设计提供了关键指导原则和实用的操作性建议。

Abstract: Large language models (LLMs) are increasingly used for text-rich graph
machine learning tasks such as node classification in high-impact domains like
fraud detection and recommendation systems. Yet, despite a surge of interest,
the field lacks a principled understanding of the capabilities of LLMs in their
interaction with graph data. In this work, we conduct a large-scale, controlled
evaluation across several key axes of variability to systematically assess the
strengths and weaknesses of LLM-based graph reasoning methods in text-based
applications. The axes include the LLM-graph interaction mode, comparing
prompting, tool-use, and code generation; dataset domains, spanning citation,
web-link, e-commerce, and social networks; structural regimes contrasting
homophilic and heterophilic graphs; feature characteristics involving both
short- and long-text node attributes; and model configurations with varying LLM
sizes and reasoning capabilities. We further analyze dependencies by
methodically truncating features, deleting edges, and removing labels to
quantify reliance on input types. Our findings provide practical and actionable
guidance. (1) LLMs as code generators achieve the strongest overall performance
on graph data, with especially large gains on long-text or high-degree graphs
where prompting quickly exceeds the token budget. (2) All interaction
strategies remain effective on heterophilic graphs, challenging the assumption
that LLM-based methods collapse under low homophily. (3) Code generation is
able to flexibly adapt its reliance between structure, features, or labels to
leverage the most informative input type. Together, these findings provide a
comprehensive view of the strengths and limitations of current LLM-graph
interaction modes and highlight key design principles for future approaches.

</details>


### [191] [A Rhythm-Aware Phrase Insertion for Classical Arabic Poetry Composition](https://arxiv.org/abs/2509.18514)
*Mohamad Elzohbi,Richard Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种使用ByT5模型向阿拉伯诗歌中插入短语以符合特定韵律的方法，该方法结合了基于规则的韵律提取和条件去噪微调，并在韵律对齐和语义连贯性方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 研究动机是协助古典阿拉伯诗歌的创作过程，特别是实现短语插入时与特定韵律的匹配。

Method: 方法包括：1) 针对完全注音的阿拉伯语脚本，采用基于规则的字素到节拍转换来提取韵律。2) 使用ByT5（一个字节级多语言Transformer模型），通过条件去噪目标进行微调，使模型重建被遮蔽的词语以匹配目标韵律。3) 采用课程学习策略，先在通用阿拉伯语数据集上预训练，再在诗歌数据集上微调。4) 探索了从英语到阿拉伯语的跨语言迁移。

Result: 实验结果表明，所提出的模型在保持语义连贯性的同时，实现了高水平的韵律对齐。

Conclusion: 该模型具有在古典阿拉伯诗歌创作过程中应用于协同创意应用的潜力。

Abstract: This paper presents a methodology for inserting phrases in Arabic poems to
conform to a specific rhythm using ByT5, a byte-level multilingual
transformer-based model. Our work discusses a rule-based grapheme-to-beat
transformation tailored for extracting the rhythm from fully diacritized Arabic
script. Our approach employs a conditional denoising objective to fine-tune
ByT5, where the model reconstructs masked words to match a target rhythm. We
adopt a curriculum learning strategy, pre-training on a general Arabic dataset
before fine-tuning on poetic dataset, and explore cross-lingual transfer from
English to Arabic. Experimental results demonstrate that our models achieve
high rhythmic alignment while maintaining semantic coherence. The proposed
model has the potential to be used in co-creative applications in the process
of composing classical Arabic poems.

</details>


### [192] [Trace Is In Sentences: Unbiased Lightweight ChatGPT-Generated Text Detector](https://arxiv.org/abs/2509.18535)
*Mo Mu,Dianqiao Lei,Chang Li*

Main category: cs.CL

TL;DR: 本文提出一个轻量级框架，通过分析文本的内部结构来检测原始及经复述修改的AI生成文本，以解决现有检测器对复述的脆弱性和偏见问题。


<details>
  <summary>Details</summary>
Motivation: ChatGPT的广泛应用引发了对其滥用的担忧，急需鲁棒的AI生成文本检测方法。现有词级检测器易受复述和简单提示（PSP）攻击，存在ChatGPT词级模式（CWP）和训练数据内容导致的偏见，对修改文本性能下降，且常需大型模型或在线LLM交互。

Method: 引入了一个检测原始及PSP修改的AI生成文本的新任务。提出了一个轻量级框架，通过文本内部结构进行分类，该结构在词级变化下保持不变。方法包括：从预训练语言模型编码句子嵌入，通过注意力机制建模它们的关系；采用对比学习减轻自回归生成引起的嵌入偏见；结合因果图和反事实方法，将结构特征与主题相关偏见分离。

Result: 在两个精选数据集（包括摘要比较和修订后的生活常见问题解答）上的实验验证了该方法的有效性。

Conclusion: 所提出的轻量级框架通过关注文本的内部结构并缓解偏见，能有效检测包括复述修改在内的AI生成文本，解决了现有检测器的诸多局限性。

Abstract: The widespread adoption of ChatGPT has raised concerns about its misuse,
highlighting the need for robust detection of AI-generated text. Current
word-level detectors are vulnerable to paraphrasing or simple prompts (PSP),
suffer from biases induced by ChatGPT's word-level patterns (CWP) and training
data content, degrade on modified text, and often require large models or
online LLM interaction. To tackle these issues, we introduce a novel task to
detect both original and PSP-modified AI-generated texts, and propose a
lightweight framework that classifies texts based on their internal structure,
which remains invariant under word-level changes. Our approach encodes sentence
embeddings from pre-trained language models and models their relationships via
attention. We employ contrastive learning to mitigate embedding biases from
autoregressive generation and incorporate a causal graph with counterfactual
methods to isolate structural features from topic-related biases. Experiments
on two curated datasets, including abstract comparisons and revised life FAQs,
validate the effectiveness of our method.

</details>


### [193] [CCQA: Generating Question from Solution Can Improve Inference-Time Reasoning in SLMs](https://arxiv.org/abs/2509.18536)
*Jin Young Kim,Ji Won Yoon*

Main category: cs.CL

TL;DR: 本文提出了一种名为CCQA的新型推理方法，通过循环一致性原理，利用问题生成和相似度评估，显著提升了小型语言模型（SLMs）在数学和常识推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 推理策略能提升大型语言模型（LLMs）的准确性，但其在小型模型（SLMs）上的有效性尚不明确，且传统方法在此背景下往往无法改善性能。

Method: CCQA方法受循环一致性启发，从每个推理路径和答案生成一个问题，通过评估生成问题与原始问题的相似度来选择最佳候选解决方案。为克服SLMs自身生成准确问题的困难，CCQA采用了一个轻量级的Flan-T5模型专门用于高效的问题生成。

Result: 实验结果表明，CCQA在数学和常识推理基准测试中，始终优于现有最先进（SOTA）方法，并在八个不同模型上得到了验证。此外，该方法为SLMs的有效推理建立了一个新的实用基线。

Conclusion: CCQA是一种对小型语言模型有效的推理方法，它通过引入循环一致性原则和辅助问题生成模型，显著提升了SLMs在推理任务上的性能，并为SLMs的推理提供了一个新的实用基线。

Abstract: Recently, inference-time reasoning strategies have further improved the
accuracy of large language models (LLMs), but their effectiveness on smaller
models remains unclear. Based on the observation that conventional approaches
often fail to improve performance in this context, we propose
\textbf{C}ycle-\textbf{C}onsistency in \textbf{Q}uestion \textbf{A}nswering
(CCQA), a novel reasoning method that can be effectively applied to SLMs.
Inspired by cycle consistency, CCQA generates a question from each reasoning
path and answer, evaluates each by its similarity to the original question, and
then selects the candidate solution with the highest similarity score as the
final response. Since conventional SLMs struggle to generate accurate questions
from their own reasoning paths and answers, we employ a lightweight Flan-T5
model specialized for question generation to support this process efficiently.
From the experimental results, it is verified that CCQA consistently
outperforms existing state-of-the-art (SOTA) methods across eight models on
mathematical and commonsense reasoning benchmarks. Furthermore, our method
establishes a new practical baseline for efficient reasoning in SLMs. Source
code can be found at https://github.com/scai-research/ccqa_official.

</details>


### [194] [Prior-based Noisy Text Data Filtering: Fast and Strong Alternative For Perplexity](https://arxiv.org/abs/2509.18577)
*Yeongbin Seo,Gayoung Kim,Jaehyung Kim,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 本文提出了一种基于词元先验的LLM数据过滤方法，该方法利用语料库级别的词频统计来估计词元先验，作为PPL的快速替代。它在性能上优于PPL，且时间成本降低了1000倍以上。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的预训练数据选择至关重要，但基于困惑度（PPL）的过滤方法存在时间成本高昂和处理噪声或分布外样本时不可靠的缺点。

Method: 受语言学中词语角色和词汇密度启发的见解，研究者提出了一种基于先验的数据过滤方法。该方法使用语料库级别的词频统计来估计词元先验，并根据词元先验的均值和标准差来过滤文档。它无需模型推理，可作为PPL的快速替代。

Result: 该基于先验的过滤器在20个下游基准测试中取得了最高的平均性能，同时与基于PPL的过滤方法相比，时间成本降低了1000倍以上。此外，它还适用于代码和数学等符号语言，并能动态适应多语言语料库而无需监督。

Conclusion: 基于词元先验的数据过滤方法是一种简单而强大的替代方案，它能有效且高效地选择LLM预训练数据，解决了PPL方法的局限性，并具有广泛的适用性。

Abstract: As large language models (LLMs) are pretrained on massive web corpora,
careful selection of data becomes essential to ensure effective and efficient
learning. While perplexity (PPL)-based filtering has shown strong performance,
it suffers from drawbacks: substantial time costs and inherent unreliability of
the model when handling noisy or out-of-distribution samples. In this work, we
propose a simple yet powerful alternative: a prior-based data filtering method
that estimates token priors using corpus-level term frequency statistics,
inspired by linguistic insights on word roles and lexical density. Our approach
filters documents based on the mean and standard deviation of token priors,
serving as a fast proxy to PPL while requiring no model inference. Despite its
simplicity, the prior-based filter achieves the highest average performance
across 20 downstream benchmarks, while reducing time cost by over 1000x
compared to PPL-based filtering. We further demonstrate its applicability to
symbolic languages such as code and math, and its dynamic adaptability to
multilingual corpora without supervision

</details>


### [195] [TsqLoRA: Towards Sensitivity and Quality Low-Rank Adaptation for Efficient Fine-Tuning](https://arxiv.org/abs/2509.18585)
*Yu Chen,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: TsqLoRA是一种新颖的参数高效微调方法，它结合了数据质量驱动的采样和敏感度感知的低秩适应，以提高微调效率并保持或提升性能。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的环境中，对大型预训练模型进行完全微调计算成本高且内存密集。现有的参数高效微微调方法虽然减少了可训练参数，但通常忽略了模型不同层的敏感性差异以及训练数据的重要性。

Method: 本文提出了TsqLoRA，包含两个主要组件：一个质量感知的采样机制，用于选择信息最丰富的训练数据；一个动态秩分配模块，根据每层对参数更新的敏感性调整其秩。

Result: 实验结果表明，TsqLoRA在提高微调效率的同时，在各种NLP任务上保持甚至提升了性能。

Conclusion: TsqLoRA通过结合数据质量驱动的采样和敏感度感知的动态秩分配，有效解决了现有参数高效微调方法的局限性，实现了更高效且高性能的模型微调。

Abstract: Fine-tuning large pre-trained models for downstream tasks has become a
fundamental approach in natural language processing. Fully fine-tuning all
model parameters is computationally expensive and memory-intensive, especially
in resource-constrained environments. Existing parameter-efficient fine-tuning
methods reduce the number of trainable parameters but typically overlook the
varying sensitivity of different model layers and the importance of training
data. In this work, we propose TsqLoRA, a novel method that integrates
data-quality-driven selection with sensitivity-aware low-rank adaptation,
consisted of two main components: a quality-aware sampling mechanism for
selecting the most informative training data, and a dynamic rank allocation
module that adjusts the rank of each layer based on its sensitivity to
parameter updates. The experimental results demonstrate that TsqLoRA improves
fine-tuning efficiency while maintaining or even improving performance on a
variety of NLP tasks. Our code will be available at
https://github.com/Benjamin-Ricky/TsqLoRA.

</details>


### [196] [UniECG: Understanding and Generating ECG in One Unified Model](https://arxiv.org/abs/2509.18588)
*Jiarui Jin,Haoyu Wang,Xiang Lan,Jun Li,Gaofeng Cheng,Hongyan Li,Shenda Hong*

Main category: cs.CL

TL;DR: UniECG是首个统一的ECG模型，能够同时进行基于证据的ECG解读和文本条件的ECG生成。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型（如GPT-5）在ECG信号理解、准确医疗诊断和ECG生成方面表现不佳。

Method: 提出UniECG模型，采用解耦的两阶段训练方法：首先学习基于证据的解读技能（ECG-到-文本），然后通过潜在空间对齐注入ECG生成能力（文本-到-ECG）。

Result: UniECG能根据用户输入自主选择解读或生成ECG，显著扩展了当前ECG模型的能力边界。

Conclusion: UniECG是首个能够同时进行ECG解读和生成的统一模型，解决了现有模型在ECG任务上的局限性。

Abstract: Recent unified models such as GPT-5 have achieved encouraging progress on
vision-language tasks. However, these unified models typically fail to
correctly understand ECG signals and provide accurate medical diagnoses, nor
can they correctly generate ECG signals. To address these limitations, we
propose UniECG, the first unified model for ECG capable of concurrently
performing evidence-based ECG interpretation and text-conditioned ECG
generation tasks. Through a decoupled two-stage training approach, the model
first learns evidence-based interpretation skills (ECG-to-Text), and then
injects ECG generation capabilities (Text-to-ECG) via latent space alignment.
UniECG can autonomously choose to interpret or generate an ECG based on user
input, significantly extending the capability boundaries of current ECG models.
Our code and checkpoints will be made publicly available at
https://github.com/PKUDigitalHealth/UniECG upon acceptance.

</details>


### [197] [A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users](https://arxiv.org/abs/2509.18632)
*Nishant Balepur,Matthew Shu,Yoo Yeon Sung,Seraphina Goldfarb-Tarrant,Shi Feng,Fumeng Yang,Rachel Rudinger,Jordan Lee Boyd-Graber*

Main category: cs.CL

TL;DR: 研究发现，大语言模型（LLM）计划的用户偏好和模型偏好并不能准确预测计划的实际帮助程度，常见的对齐反馈可能导致与实际帮助性不符。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM对齐方法（如RLHF和ChatbotArena）主要基于用户偏好进行训练或评估，但研究者质疑这种偏好是否真正反映了计划的实际帮助程度。

Method: 研究开发了一个名为Planorama的界面，让126名用户回答300个多步骤问题，并使用LLM生成的计划。共收集了4388次计划执行和5584次比较，以衡量计划的帮助性（QA成功率）和用户偏好。同时，研究人员在代理和奖励模型中重现了该设置，以观察它们是否模拟或偏好对用户有帮助的计划。

Result: 1) 用户/模型偏好和代理成功率并不能准确预测哪些计划对用户有帮助，这表明常见的对齐反馈可能与实际帮助性不符；2) 这种差异并非源于用户特有的偏好，因为用户在使用他们偏好或不偏好的计划时，成功率相似；3) 表面线索（如简洁性、问题相似性）与偏好密切相关，但这些偏见未能预测计划的帮助性。

Conclusion: 为了对齐真正有帮助的LLM，需要来自真实用户交互的反馈，而不仅仅是那些看起来有帮助的偏好。研究者讨论了自然语言处理（NLP）研究人员可以采取的解决方案来解决这个问题。

Abstract: To assist users in complex tasks, LLMs generate plans: step-by-step
instructions towards a goal. While alignment methods aim to ensure LLM plans
are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer,
assuming this reflects what helps them. We test this with Planorama: an
interface where 126 users answer 300 multi-step questions with LLM plans. We
get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA
success) and user preferences on plans, and recreate the setup in agents and
reward models to see if they simulate or prefer what helps users. We expose: 1)
user/model preferences and agent success do not accurately predict which plans
help users, so common alignment feedback can misalign with helpfulness; 2) this
gap is not due to user-specific preferences, as users are similarly successful
when using plans they prefer/disprefer; 3) surface-level cues like brevity and
question similarity strongly link to preferences, but such biases fail to
predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from
real user interactions, not just preferences of what looks helpful, so we
discuss the plan NLP researchers can execute to solve this problem.

</details>


### [198] [Consistency-Aware Parameter-Preserving Knowledge Editing Framework for Multi-Hop Question Answering](https://arxiv.org/abs/2509.18655)
*Lingwen Deng,Yifei Han,Long Zhang,Yue Du,Bin Li*

Main category: cs.CL

TL;DR: 现有基于知识图谱的参数不变知识编辑（PPKE）在多跳问答（MHQA）中存在一致性问题。本文提出了CAPE-KG框架，通过确保知识图谱的构建、更新和检索与MHQA任务一致，显著提高了PPKE的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的PPKE方法在扩展到多跳问答时，往往缺乏一致性，导致知识污染、更新不稳定以及检索行为无法反映预期编辑，从而损害了PPKE在多跳推理中的可靠性。

Method: 本文提出了CAPE-KG（Consistency-Aware Parameter-Preserving Editing with Knowledge Graphs），一个新颖的、一致性感知的PPKE框架。CAPE-KG确保知识图谱的构建、更新和检索始终与多跳问答任务的要求保持一致，从而在未经编辑和已编辑的知识上保持连贯的推理。

Result: 在MQuAKE基准测试上进行的广泛实验表明，CAPE-KG显著提高了多跳问答中PPKE的性能准确性。

Conclusion: 解决PPKE中的一致性问题对于提高多跳问答任务的性能是有效的，CAPE-KG框架证明了这一点。

Abstract: Parameter-Preserving Knowledge Editing (PPKE) enables updating models with
new or corrected information without retraining or parameter adjustment. Recent
PPKE approaches based on knowledge graphs (KG) to extend knowledge editing (KE)
capabilities to multi-hop question answering (MHQA). However, these methods
often lack consistency, leading to knowledge contamination, unstable updates,
and retrieval behaviors that fail to reflect the intended edits. Such
inconsistencies undermine the reliability of PPKE in multi- hop reasoning. We
present CAPE-KG, Consistency-Aware Parameter-Preserving Editing with Knowledge
Graphs, a novel consistency-aware framework for PPKE on MHQA. CAPE-KG ensures
KG construction, update, and retrieval are always aligned with the requirements
of the MHQA task, maintaining coherent reasoning over both unedited and edited
knowledge. Extensive experiments on the MQuAKE benchmark show accuracy
improvements in PPKE performance for MHQA, demonstrating the effectiveness of
addressing consistency in PPKE.

</details>


### [199] [Analyzing Uncertainty of LLM-as-a-Judge: Interval Evaluations with Conformal Prediction](https://arxiv.org/abs/2509.18658)
*Huanxin Sheng,Xinyi Liu,Hangfeng He,Jieyu Zhao,Jian Kang*

Main category: cs.CL

TL;DR: 本文提出首个利用共形预测为LLM作为评判者的评分提供预测区间，以量化评估的不确定性，并引入离散评分的序数边界调整和低偏差的中点分数。


<details>
  <summary>Details</summary>
Motivation: LLM作为评判者在自然语言生成评估中前景广阔，但其评估的不确定性尚未得到充分探索，这种可靠性不足限制了其在许多应用中的部署。

Method: 本文提出了一个利用共形预测分析LLM评分不确定性的框架，为LLM的评分提供预测区间。具体方法包括为离散评分任务设计序数边界调整，并建议使用区间中点作为原始模型分数和加权平均的低偏差替代方案。

Result: 实验和分析表明，共形预测可以提供具有覆盖率保证的有效预测区间。研究还探索了区间中点和评判者重新提示（reprompting）对获得更好判断的有用性。

Conclusion: 该研究首次通过共形预测为LLM作为评判者的评估提供了具有覆盖率保证的有效预测区间，从而量化并解决了其不确定性问题，并提出了改进评分准确性的新方法。

Abstract: LLM-as-a-judge has become a promising paradigm for using large language
models (LLMs) to evaluate natural language generation (NLG), but the
uncertainty of its evaluation remains underexplored. This lack of reliability
may limit its deployment in many applications. This work presents the first
framework to analyze the uncertainty by offering a prediction interval of
LLM-based scoring via conformal prediction. Conformal prediction constructs
continuous prediction intervals from a single evaluation run, and we design an
ordinal boundary adjustment for discrete rating tasks. We also suggest a
midpoint-based score within the interval as a low-bias alternative to raw model
score and weighted average. We perform extensive experiments and analysis,
which show that conformal prediction can provide valid prediction interval with
coverage guarantees. We also explore the usefulness of interval midpoint and
judge reprompting for better judgment.

</details>


### [200] [MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service](https://arxiv.org/abs/2509.18713)
*Yizhe Huang,Yang Liu,Ruiyu Zhao,Xiaolong Zhong,Xingming Yue,Ling Jiang*

Main category: cs.CL

TL;DR: 为解决客户服务中LLM代理的遗忘和重复错误问题，本文提出了MemOrb，一个轻量级的口头强化记忆层，通过结构化策略反思来显著提高任务成功率和稳定性，无需微调。


<details>
  <summary>Details</summary>
Motivation: LLM代理在客户服务中常出现跨会话遗忘、重复错误和缺乏持续自我改进能力，导致在动态环境中不可靠，而这些环境对稳定性和一致性要求很高。

Method: 本文提出了MemOrb，一个轻量级、即插即用的口头强化记忆层。它将多轮交互提炼成紧凑的策略反思，存储在一个共享记忆库中，并在决策时检索以提供指导，无需任何微调。评估指标包括任务成功率（衡量整体有效性）和一致性指标（如Pass$^k$，衡量多次试验的可靠性）。

Result: 实验表明，MemOrb显著提高了任务成功率和稳定性，在多轮成功率方面取得了高达63个百分点的提升，并在重复试验中展现出更一致的性能。

Conclusion: 结构化反思是增强客户服务场景中冻结LLM代理长期可靠性的强大机制。

Abstract: Large Language Model-based agents(LLM-based agents) are increasingly deployed
in customer service, yet they often forget across sessions, repeat errors, and
lack mechanisms for continual self-improvement. This makes them unreliable in
dynamic settings where stability and consistency are critical. To better
evaluate these properties, we emphasize two indicators: task success rate as a
measure of overall effectiveness, and consistency metrics such as Pass$^k$ to
capture reliability across multiple trials. To address the limitations of
existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal
reinforcement memory layer that distills multi-turn interactions into compact
strategy reflections. These reflections are stored in a shared memory bank and
retrieved to guide decision-making, without requiring any fine-tuning.
Experiments show that MemOrb significantly improves both success rate and
stability, achieving up to a 63 percentage-point gain in multi-turn success
rate and delivering more consistent performance across repeated trials. Our
results demonstrate that structured reflection is a powerful mechanism for
enhancing long-term reliability of frozen LLM agents in customer service
scenarios.

</details>


### [201] [LOTUSDIS: A Thai far-field meeting corpus for robust conversational ASR](https://arxiv.org/abs/2509.18722)
*Pattara Tipaksorn,Sumonmas Thatphithakkul,Vataya Chunwijitra,Kwanchiva Thangthai*

Main category: cs.CL

TL;DR: 该论文发布了一个名为LOTUSDIS的泰语会议语料库，包含114小时远场对话录音，用于提升远场会话式ASR。实验表明，使用LOTUSDIS进行微调可显著提高Whisper模型对远场语音的鲁棒性，尤其是在远距离麦克风上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有ASR模型在远场泰语语音识别中表现不佳，且缺乏合适的远场、距离多样化的泰语训练数据，导致预训练数据与远场泰语语音之间存在不匹配。

Method: 构建了LOTUSDIS语料库，包含114小时自发、非脚本对话，由三名参与者在15-20分钟的会话中录制，包含频繁的重叠语音。录音使用九个独立的单通道设备（六种麦克风类型），距离从0.12米到10米不等，保留了混响、噪声和设备音染。提供了标准的训练、开发、测试集划分，并发布了一个可复现的基线系统。在零样本和微调条件下，对多个Whisper变体进行了基准测试。

Result: 现成的模型在识别远距离语音时性能显著下降。在LOTUSDIS上进行微调后，鲁棒性得到极大提升：泰语Whisper基线模型的整体WER从64.3%降至38.3%，远场WER从81.6%降至49.5%，在最远距离麦克风上的提升尤为显著。

Conclusion: 研究结果强调了距离多样化训练数据对于构建鲁棒ASR系统的重要性。LOTUSDIS语料库及其训练和评估脚本已公开发布，以促进该领域的可复现研究。

Abstract: We present LOTUSDIS, a publicly available Thai meeting corpus designed to
advance far-field conversational ASR. The dataset comprises 114 hours of
spontaneous, unscripted dialogue collected in 15-20 minute sessions with three
participants, where overlapping speech is frequent and natural. Speech was
recorded simultaneously by nine independent single-channel devices spanning six
microphone types at distances from 0.12 m to 10 m, preserving the authentic
effects of reverberation, noise, and device coloration without relying on
microphone arrays. We provide standard train, dev, test splits and release a
reproducible baseline system. We benchmarked several Whisper variants under
zero-shot and fine-tuned conditions. Off-the-shelf models showed strong
degradation with distance, confirming a mismatch between pre-training data and
Thai far-field speech. Fine-tuning on LOTUSDIS dramatically improved
robustness: a Thai Whisper baseline reduced overall WER from 64.3 to 38.3 and
far-field WER from 81.6 to 49.5, with especially large gains on the most
distant microphones. These results underscore the importance of
distance-diverse training data for robust ASR. The corpus is available under
CC-BY-SA 4.0. We also release training and evaluation scripts as a baseline
system to promote reproducible research in this field.

</details>


### [202] [Global-Recent Semantic Reasoning on Dynamic Text-Attributed Graphs with Large Language Models](https://arxiv.org/abs/2509.18742)
*Yunan Wang,Jianxin Li,Ziwei Zhang*

Main category: cs.CL

TL;DR: 本文提出DyGRASP，一种结合大语言模型（LLMs）和时序图神经网络（temporal GNNs）的新方法，能高效有效地处理动态文本属性图（DyTAGs），捕捉近期和全局时间语义。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如GNNs和LLMs）主要关注静态文本属性图（TAGs），难以处理DyTAGs中时间演变的图交互和文本属性。它们忽略了近期-全局时间语义（交互文本的近期语义依赖和节点随时间的全局语义演变），且LLMs在处理DyTAGs中大量演变文本时面临效率问题。

Method: DyGRASP方法包括：1) 采用以节点为中心的隐式推理和滑动窗口机制，高效捕获近期时间语义。2) 利用定制提示和类RNN链式结构的显式推理，推断节点的全局语义动态。3) 通过更新和合并层，精妙地整合近期和全局时间语义以及动态图结构信息。

Result: 在DyTAG基准测试中，DyGRASP表现出卓越性能，在目标节点检索任务中，Hit@10指标最高提升34%。此外，DyGRASP在不同的时序GNNs和LLMs之间展现出强大的泛化能力。

Conclusion: DyGRASP是一种新颖的方法，能高效且有效地在动态文本属性图上进行推理，通过独特地捕捉近期和全局时间语义，显著优于现有方法并具有良好的泛化性。

Abstract: Dynamic Text-Attribute Graphs (DyTAGs), characterized by time-evolving graph
interactions and associated text attributes, are prevalent in real-world
applications. Existing methods, such as Graph Neural Networks (GNNs) and Large
Language Models (LLMs), mostly focus on static TAGs. Extending these existing
methods to DyTAGs is challenging as they largely neglect the recent-global
temporal semantics: the recent semantic dependencies among interaction texts
and the global semantic evolution of nodes over time. Furthermore, applying
LLMs to the abundant and evolving text in DyTAGs faces efficiency issues. To
tackle these challenges, we propose Dynamic Global-Recent Adaptive Semantic
Processing (DyGRASP), a novel method that leverages LLMs and temporal GNNs to
efficiently and effectively reason on DyTAGs. Specifically, we first design a
node-centric implicit reasoning method together with a sliding window mechanism
to efficiently capture recent temporal semantics. In addition, to capture
global semantic dynamics of nodes, we leverage explicit reasoning with tailored
prompts and an RNN-like chain structure to infer long-term semantics. Lastly,
we intricately integrate the recent and global temporal semantics as well as
the dynamic graph structural information using updating and merging layers.
Extensive experiments on DyTAG benchmarks demonstrate DyGRASP's superiority,
achieving up to 34% improvement in Hit@10 for destination node retrieval task.
Besides, DyGRASP exhibits strong generalization across different temporal GNNs
and LLMs.

</details>


### [203] [False Friends Are Not Foes: Investigating Vocabulary Overlap in Multilingual Language Models](https://arxiv.org/abs/2509.18750)
*Julie Kallini,Dan Jurafsky,Christopher Potts,Martijn Bartelds*

Main category: cs.CL

TL;DR: 本研究通过受控实验发现，多语言分词器中的词元重叠有助于跨语言迁移，且重叠程度越高，迁移性能越好，尤其当共享词元具有语义相似性时。


<details>
  <summary>Details</summary>
Motivation: 以往关于词元重叠对跨语言迁移影响的研究结果不一，部分原因在于实验设置和混杂因素（如词元频率、子词切分粒度）的差异。本研究旨在明确词元重叠是促进还是阻碍跨语言迁移，并探索共享词元的语义相似性在其中扮演的角色。

Method: 设计受控实验，在不同词汇重叠设置下，训练双语自回归模型。系统性地改变词汇重叠程度，并引入共享词元语义相似性作为新的分析维度。分析模型的隐层表示，并在XNLI和XQuAD数据集上评估模型性能。

Result: 任何形式的词元重叠都能创建捕获跨语言语义关系的嵌入空间，这种效果在词汇不重叠的模型中弱得多。在XNLI和XQuAD任务上，具有重叠词汇的模型优于词汇不重叠的模型，且迁移性能通常随重叠程度的增加而提高。

Conclusion: 词元重叠在多语言模型中具有优势，大量共享词汇仍然是多语言分词器的一种有益设计选择。

Abstract: Subword tokenizers trained on multilingual corpora naturally produce
overlapping tokens across languages. Does token overlap facilitate
cross-lingual transfer or instead introduce interference between languages?
Prior work offers mixed evidence, partly due to varied setups and confounders,
such as token frequency or subword segmentation granularity. To address this
question, we devise a controlled experiment where we train bilingual
autoregressive models on multiple language pairs under systematically varied
vocabulary overlap settings. Crucially, we explore a new dimension to
understanding how overlap affects transfer: the semantic similarity of tokens
shared across languages. We first analyze our models' hidden representations
and find that overlap of any kind creates embedding spaces that capture
cross-lingual semantic relationships, while this effect is much weaker in
models with disjoint vocabularies. On XNLI and XQuAD, we find that models with
overlap outperform models with disjoint vocabularies, and that transfer
performance generally improves as overlap increases. Overall, our findings
highlight the advantages of token overlap in multilingual models and show that
substantial shared vocabulary remains a beneficial design choice for
multilingual tokenizers.

</details>


### [204] [When Long Helps Short: How Context Length in Supervised Fine-tuning Affects Behavior of Large Language Models](https://arxiv.org/abs/2509.18762)
*Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen*

Main category: cs.CL

TL;DR: 研究发现，长上下文SFT（监督微调）能反直觉地提升LLM在短上下文任务上的性能，这与长上下文预训练的效果相反。这种提升源于MHA和FFN的独立受益，但纯粹的长上下文SFT会产生知识偏好。混合训练能缓解此偏好，提供优化的微调指导。


<details>
  <summary>Details</summary>
Motivation: 随着实际应用对LLM长上下文窗口的需求增加，在长上下文数据上进行持续预训练和SFT已成为常见做法。尽管持续预训练中数据长度的影响已被广泛研究，但SFT数据长度对LLM行为，尤其是在短上下文任务上的影响仍不明确。

Method: 本研究系统性地调查了SFT数据长度如何影响LLM在短上下文任务上的表现。首先，解耦并分析了多头注意力（MHA）和前馈网络（FFN）这两个关键组件。其次，研究了它们之间的交互作用，并揭示了知识偏好偏差。最后，通过混合训练来验证其对偏差的缓解作用。

Result: 研究发现，长上下文SFT反直觉地提升了LLM在短上下文任务上的性能，这与长上下文预训练中常见的性能下降现象相反。MHA和FFN均独立受益于长上下文SFT。长上下文SFT促进语境知识，而短上下文SFT偏爱参数知识，导致仅依赖长上下文SFT并非最优。混合训练能有效缓解这种知识偏好偏差。

Conclusion: 长上下文SFT能有效提升LLM在短上下文任务上的性能，通过增强MHA和FFN实现。然而，为避免语境知识与参数知识之间的偏好偏差，建议采用混合训练策略来优化LLM的微调过程，以获得更全面的知识利用能力。

Abstract: Large language models (LLMs) have achieved impressive performance across
natural language processing (NLP) tasks. As real-world applications
increasingly demand longer context windows, continued pretraining and
supervised fine-tuning (SFT) on long-context data has become a common approach.
While the effects of data length in continued pretraining have been extensively
studied, their implications for SFT remain unclear. In this work, we
systematically investigate how SFT data length influences LLM behavior on
short-context tasks. Counterintuitively, we find that long-context SFT improves
short-context performance, contrary to the commonly observed degradation from
long-context pretraining. To uncover the underlying mechanisms of this
phenomenon, we first decouple and analyze two key components, Multi-Head
Attention (MHA) and Feed-Forward Network (FFN), and show that both
independently benefit from long-context SFT. We further study their interaction
and reveal a knowledge preference bias: long-context SFT promotes contextual
knowledge, while short-context SFT favors parametric knowledge, making
exclusive reliance on long-context SFT suboptimal. Finally, we demonstrate that
hybrid training mitigates this bias, offering explainable guidance for
fine-tuning LLMs.

</details>


### [205] [Financial Risk Relation Identification through Dual-view Adaptation](https://arxiv.org/abs/2509.18775)
*Wei-Ning Chiu,Yu-Hsiang Wang,Andy Hsiao,Yu-Shiang Huang,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 该论文提出了一种利用10-K文件和无监督NLP方法，系统地提取企业间风险关系并量化风险关联分数的新方法，优于传统基线。


<details>
  <summary>Details</summary>
Motivation: 识别企业间风险关系对投资管理至关重要，但传统方法（如专家判断和人工分析）主观、劳动密集且难以规模化，因此需要一种系统性解决方案。

Method: 该方法以10-K文件为数据源，利用自然语言处理技术，通过基于时间顺序和词汇模式的无监督微调，捕捉隐性和抽象的风险联系。这开发了一个领域特定的金融编码器，并引入了量化的风险关系分数以提高透明度和可解释性。

Result: 广泛的实验表明，该方法在多种评估设置下均优于强大的基线模型。

Conclusion: 该研究提供了一种系统、定量且可解释的方法来提取企业间风险关系，克服了传统评估的局限性，并为投资策略等应用提供了更深入的洞察。

Abstract: A multitude of interconnected risk events -- ranging from regulatory changes
to geopolitical tensions -- can trigger ripple effects across firms.
Identifying inter-firm risk relations is thus crucial for applications like
portfolio management and investment strategy. Traditionally, such assessments
rely on expert judgment and manual analysis, which are, however, subjective,
labor-intensive, and difficult to scale. To address this, we propose a
systematic method for extracting inter-firm risk relations using Form 10-K
filings -- authoritative, standardized financial documents -- as our data
source. Leveraging recent advances in natural language processing, our approach
captures implicit and abstract risk connections through unsupervised
fine-tuning based on chronological and lexical patterns in the filings. This
enables the development of a domain-specific financial encoder with a deeper
contextual understanding and introduces a quantitative risk relation score for
transparency, interpretable analysis. Extensive experiments demonstrate that
our method outperforms strong baselines across multiple evaluation settings.

</details>


### [206] [AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field](https://arxiv.org/abs/2509.18776)
*Chen Liang,Zhaoqi Huang,Haofen Wang,Fu Chai,Chunying Yu,Huanhuan Wei,Zhengjie Liu,Yanpeng Li,Hongjun Wang,Ruifeng Luo,Xianzhong Zhao*

Main category: cs.CL

TL;DR: 本研究建立了AECBench基准测试平台，用于评估大型语言模型（LLMs）在建筑、工程和施工（AEC）领域的性能，发现LLMs在复杂推理、计算和专业文档生成方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: LLMs在AEC领域应用日益广泛，但其在该专业且安全关键领域中的鲁棒性和可靠性尚未得到充分评估。

Method: 本研究建立了AECBench，一个全面的基准测试平台，包含23项代表性任务，涵盖知识记忆、理解、推理、计算和应用五个认知层面。构建了一个包含4800个问题的多格式数据集，并采用“LLM作为评判者”的方法，结合专家制定的评分标准来评估复杂、长篇的回答。

Result: 通过评估九个LLM，发现模型的性能随着认知水平的提高而显著下降。LLMs在知识记忆和理解等基础任务上表现良好，但在解释建筑规范中的表格知识、执行复杂推理和计算，以及生成领域特定文档方面表现出明显的性能缺陷。

Conclusion: 本研究为未来旨在将LLMs稳健可靠地集成到安全关键工程实践中的研究和开发奠定了基础。

Abstract: Large language models (LLMs), as a novel information technology, are seeing
increasing adoption in the Architecture, Engineering, and Construction (AEC)
field. They have shown their potential to streamline processes throughout the
building lifecycle. However, the robustness and reliability of LLMs in such a
specialized and safety-critical domain remain to be evaluated. To address this
challenge, this paper establishes AECBench, a comprehensive benchmark designed
to quantify the strengths and limitations of current LLMs in the AEC domain.
The benchmark defines 23 representative tasks within a five-level
cognition-oriented evaluation framework encompassing Knowledge Memorization,
Understanding, Reasoning, Calculation, and Application. These tasks were
derived from authentic AEC practice, with scope ranging from codes retrieval to
specialized documents generation. Subsequently, a 4,800-question dataset
encompassing diverse formats, including open-ended questions, was crafted
primarily by engineers and validated through a two-round expert review.
Furthermore, an LLM-as-a-Judge approach was introduced to provide a scalable
and consistent methodology for evaluating complex, long-form responses
leveraging expert-derived rubrics. Through the evaluation of nine LLMs, a clear
performance decline across five cognitive levels was revealed. Despite
demonstrating proficiency in foundational tasks at the Knowledge Memorization
and Understanding levels, the models showed significant performance deficits,
particularly in interpreting knowledge from tables in building codes, executing
complex reasoning and calculation, and generating domain-specific documents.
Consequently, this study lays the groundwork for future research and
development aimed at the robust and reliable integration of LLMs into
safety-critical engineering practices.

</details>


### [207] [Beyond the Leaderboard: Understanding Performance Disparities in Large Language Models via Model Diffing](https://arxiv.org/abs/2509.18792)
*Sabri Boughorbel,Fahim Dalvi,Nadir Durrani,Majd Hawasly*

Main category: cs.CL

TL;DR: 本文使用模型差异分析（一种机械可解释性方法）来揭示大型语言模型微调过程中发生的具体能力变化，并量化了SimPO微调对Gemma-2-9b-it模型的影响。


<details>
  <summary>Details</summary>
Motivation: 随着微调成为改进大型语言模型（LLMs）的主导范式，理解此过程中发生的变化变得越来越重要。传统的基准测试通常无法解释为何一个模型优于另一个。

Method: 研究采用模型差异分析（一种机械可解释性方法），并利用跨编码器（crosscoders）识别和分类区分两个模型的潜在表征。具体分析了Gemma-2-9b-it及其SimPO增强变体。

Result: SimPO主要增强了模型的安全机制（+32.8%）、多语言能力（+43.8%）和指令遵循能力（+151.7%）。同时，它也减少了模型对自我参照的强调（-44.1%）和幻觉管理（-68.5%）。

Conclusion: 模型差异分析能够提供超越排行榜指标的细粒度洞察，将性能差距归因于具体的机械能力，为比较LLMs提供了一个透明且有针对性的框架。

Abstract: As fine-tuning becomes the dominant paradigm for improving large language
models (LLMs), understanding what changes during this process is increasingly
important. Traditional benchmarking often fails to explain why one model
outperforms another. In this work, we use model diffing, a mechanistic
interpretability approach, to analyze the specific capability differences
between Gemma-2-9b-it and a SimPO-enhanced variant. Using crosscoders, we
identify and categorize latent representations that differentiate the two
models. We find that SimPO acquired latent concepts predominantly enhance
safety mechanisms (+32.8%), multilingual capabilities (+43.8%), and
instruction-following (+151.7%), while its additional training also reduces
emphasis on model self-reference (-44.1%) and hallucination management
(-68.5%). Our analysis shows that model diffing can yield fine-grained insights
beyond leaderboard metrics, attributing performance gaps to concrete
mechanistic capabilities. This approach offers a transparent and targeted
framework for comparing LLMs.

</details>


### [208] [MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction](https://arxiv.org/abs/2509.18813)
*Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li*

Main category: cs.CL

TL;DR: MAPEX是首个将多智能体协作引入关键词提取的框架，通过动态适应文档长度的策略，显著优于现有无监督方法和LLM基线，展现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型（LLM）的无监督提示式关键词提取方法通常采用单阶段、统一的推理流程，不区分文档长度或LLM模型，这限制了LLM在处理多样化关键词提取场景时的推理和生成能力。

Method: 本文提出了MAPEX框架，引入多智能体协作进行关键词提取。MAPEX通过专家招募、候选提取、主题引导、知识增强和后处理等模块协调基于LLM的智能体。它采用双路径策略：对短文本进行知识驱动提取，对长文本进行主题引导提取，以动态适应文档长度。

Result: 在六个基准数据集和三个不同LLM上的广泛实验表明，MAPEX的平均F1@5指标优于最先进的无监督方法2.44%，优于标准LLM基线4.01%，展现出强大的泛化性和普适性。

Conclusion: MAPEX通过引入多智能体协作和动态适应文档长度的双路径策略，有效解决了现有无监督关键词提取方法的局限性，显著提升了性能，并证明了其在不同场景下的强大泛化能力和普适性。

Abstract: Keyphrase extraction is a fundamental task in natural language processing.
However, existing unsupervised prompt-based methods for Large Language Models
(LLMs) often rely on single-stage inference pipelines with uniform prompting,
regardless of document length or LLM backbone. Such one-size-fits-all designs
hinder the full exploitation of LLMs' reasoning and generation capabilities,
especially given the complexity of keyphrase extraction across diverse
scenarios. To address these challenges, we propose MAPEX, the first framework
that introduces multi-agent collaboration into keyphrase extraction. MAPEX
coordinates LLM-based agents through modules for expert recruitment, candidate
extraction, topic guidance, knowledge augmentation, and post-processing. A
dual-path strategy dynamically adapts to document length: knowledge-driven
extraction for short texts and topic-guided extraction for long texts.
Extensive experiments on six benchmark datasets across three different LLMs
demonstrate its strong generalization and universality, outperforming the
state-of-the-art unsupervised method by 2.44\% and standard LLM baselines by
4.01\% in F1@5 on average. Code is available at
https://github.com/NKU-LITI/MAPEX.

</details>


### [209] [Are Smaller Open-Weight LLMs Closing the Gap to Proprietary Models for Biomedical Question Answering?](https://arxiv.org/abs/2509.18843)
*Damian Stachura,Joanna Konieczna,Artur Nowak*

Main category: cs.CL

TL;DR: 本研究在生物医学问答领域比较了开源大型语言模型（LLMs）与专有LLMs的性能，结果显示开源模型表现相当，甚至在采用集成策略时超越了专有模型。


<details>
  <summary>Details</summary>
Motivation: 随着DeepSeek-V3等开源LLMs的快速发展，其性能已可与专有LLMs媲美。这引发了一个问题：小型开源LLMs是否能在生物医学问答等特定领域有效替代大型闭源模型。

Method: 研究团队参与了BioASQ挑战的Task 13B Phase B。他们将多个开源模型与GPT-4o、GPT-4.1、Claude 3.5 Sonnet和Claude 3.7 Sonnet等顶尖专有系统进行了比较。为提升问答能力，采用了多种技术，包括基于嵌入距离检索最相关片段、情境学习和结构化输出。对于某些提交，还利用集成方法来整合不同模型对精确答案问题的输出。

Result: 研究结果表明，开源LLMs与专有LLMs表现相当。在某些情况下，尤其是在应用集成策略时，开源LLMs甚至超越了闭源模型。

Conclusion: 开源LLMs在生物医学问答领域能够有效与专有模型竞争，并且在结合先进技术（如集成策略）时，有时甚至能超越它们。

Abstract: Open-weight versions of large language models (LLMs) are rapidly advancing,
with state-of-the-art models like DeepSeek-V3 now performing comparably to
proprietary LLMs. This progression raises the question of whether small
open-weight LLMs are capable of effectively replacing larger closed-source
models. We are particularly interested in the context of biomedical
question-answering, a domain we explored by participating in Task 13B Phase B
of the BioASQ challenge. In this work, we compare several open-weight models
against top-performing systems such as GPT-4o, GPT-4.1, Claude 3.5 Sonnet, and
Claude 3.7 Sonnet. To enhance question answering capabilities, we use various
techniques including retrieving the most relevant snippets based on embedding
distance, in-context learning, and structured outputs. For certain submissions,
we utilize ensemble approaches to leverage the diverse outputs generated by
different models for exact-answer questions. Our results demonstrate that
open-weight LLMs are comparable to proprietary ones. In some instances,
open-weight LLMs even surpassed their closed counterparts, particularly when
ensembling strategies were applied. All code is publicly available at
https://github.com/evidenceprime/BioASQ-13b.

</details>


### [210] [Multi-Hierarchical Feature Detection for Large Language Model Generated Text](https://arxiv.org/abs/2509.18862)
*Luyan Zhang,Xinyu Xie*

Main category: cs.CL

TL;DR: 本研究系统性地考察了多层次特征集成在AI文本检测中的效果，发现尽管有理论预期，但多特征集成带来的性能提升微乎其微（0.4-0.5%），而计算成本显著增加（4.2倍），表明单一神经模型可能已高效捕获了大部分相关检测信号。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型技术快速发展，人们对多特征方法是否能显著提升AI文本检测能力产生了兴趣，超越单一神经模型的表现。然而，对于结合语义、句法和统计特征是否能提供互补信号这一假设，尚未对现代LLM生成的文本进行严格测试。

Method: 研究实现了MHFD（多层次特征检测）方法，通过自适应融合集成了基于DeBERTa的语义分析、句法分析和统计概率特征。

Result: 研究揭示了重要的负面结果：尽管有理论预期，多特征集成带来的性能提升微乎其微（0.4-0.5%），却带来了巨大的计算开销（4.2倍）。MHFD方法在域内检测中实现了89.7%的准确率，在跨域检测中保持了84.2%的稳定性能，比现有方法取得了0.4-2.6%的适度改进。

Conclusion: 多特征集成在AI文本检测中的计算开销并未被其微小的性能提升所证明，这表明现代神经语言模型可能已经有效地捕获了大部分相关的检测信号。

Abstract: With the rapid advancement of large language model technology, there is
growing interest in whether multi-feature approaches can significantly improve
AI text detection beyond what single neural models achieve. While intuition
suggests that combining semantic, syntactic, and statistical features should
provide complementary signals, this assumption has not been rigorously tested
with modern LLM-generated text. This paper provides a systematic empirical
investigation of multi-hierarchical feature integration for AI text detection,
specifically testing whether the computational overhead of combining multiple
feature types is justified by performance gains. We implement MHFD
(Multi-Hierarchical Feature Detection), integrating DeBERTa-based semantic
analysis, syntactic parsing, and statistical probability features through
adaptive fusion. Our investigation reveals important negative results: despite
theoretical expectations, multi-feature integration provides minimal benefits
(0.4-0.5% improvement) while incurring substantial computational costs (4.2x
overhead), suggesting that modern neural language models may already capture
most relevant detection signals efficiently. Experimental results on multiple
benchmark datasets demonstrate that the MHFD method achieves 89.7% accuracy in
in-domain detection and maintains 84.2% stable performance in cross-domain
detection, showing modest improvements of 0.4-2.6% over existing methods.

</details>


### [211] [Diversity Boosts AI-Generated Text Detection](https://arxiv.org/abs/2509.18880)
*Advik Raj Basani,Pin-Yu Chen*

Main category: cs.CL

TL;DR: 本文提出DivEye，一个新颖的AI生成文本检测框架，它利用文本中不可预测性的波动（基于Surprisal特征）来区分人类和LLM生成的内容，并提供可解释的检测结果。


<details>
  <summary>Details</summary>
Motivation: 检测AI生成文本对于打击LLM在教育、商业、新闻和社交媒体中的滥用至关重要，因为合成文本的流畅性可能掩盖虚假信息或欺骗。现有的检测器（如基于token似然或黑盒分类器）在面对高质量生成文本时表现不佳，且缺乏可解释性。

Method: DivEye框架通过使用基于Surprisal的特征来捕捉文本中不可预测性如何波动。其灵感来源于人类创作的文本在词汇和结构不可预测性方面比LLM输出展现出更丰富的变异性。DivEye通过一组可解释的统计特征来捕捉这一信号。

Result: DivEye的性能优于现有零样本检测器高达33.2%，并在多个基准测试中与微调基线方法表现相当。它对释义和对抗性攻击具有鲁棒性，在不同领域和模型之间泛化良好，并且在作为辅助信号时，能将现有检测器的性能提高高达18.7%。

Conclusion: DivEye不仅能有效检测AI生成文本，还提供了可解释的洞察，揭示了“节奏性不可预测性”是LLM检测中一个强大且未被充分探索的信号。

Abstract: Detecting AI-generated text is an increasing necessity to combat misuse of
LLMs in education, business compliance, journalism, and social media, where
synthetic fluency can mask misinformation or deception. While prior detectors
often rely on token-level likelihoods or opaque black-box classifiers, these
approaches struggle against high-quality generations and offer little
interpretability. In this work, we propose DivEye, a novel detection framework
that captures how unpredictability fluctuates across a text using
surprisal-based features. Motivated by the observation that human-authored text
exhibits richer variability in lexical and structural unpredictability than LLM
outputs, DivEye captures this signal through a set of interpretable statistical
features. Our method outperforms existing zero-shot detectors by up to 33.2%
and achieves competitive performance with fine-tuned baselines across multiple
benchmarks. DivEye is robust to paraphrasing and adversarial attacks,
generalizes well across domains and models, and improves the performance of
existing detectors by up to 18.7% when used as an auxiliary signal. Beyond
detection, DivEye provides interpretable insights into why a text is flagged,
pointing to rhythmic unpredictability as a powerful and underexplored signal
for LLM detection.

</details>


### [212] [Extractive Fact Decomposition for Interpretable Natural Language Inference in one Forward Pass](https://arxiv.org/abs/2509.18901)
*Nicholas Popovič,Michael Färber*

Main category: cs.CL

TL;DR: JEDI是一种仅编码器架构，用于自然语言推理（NLI），它联合执行抽取式原子事实分解和可解释推理，无需生成模型。通过合成理由进行训练，JEDI在分布内精度具有竞争力，并显著提高了分布外和对抗性设置下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前自然语言推理（NLI）和事实核查中使用的原子事实分解方法依赖于资源密集型生成式大型语言模型（LLMs），这增加了推理成本和复杂性。研究旨在寻找一种更高效、仅编码器的替代方案，同时保持可解释性和鲁棒性。

Method: 本文提出了JEDI，一个仅编码器架构，它在推理过程中不依赖生成模型，联合执行抽取式原子事实分解和可解释推理。为便于训练，作者生成了一个包含多个NLI基准的大规模合成理由语料库。

Result: 实验结果表明，JEDI在分布内实现了具有竞争力的准确性，并且在分布外和对抗性设置下，相对于仅基于抽取式理由监督的模型，显著提高了鲁棒性。

Conclusion: 研究发现，NLI中的可解释性和鲁棒泛化可以通过仅编码器架构和合成理由来实现。

Abstract: Recent works in Natural Language Inference (NLI) and related tasks, such as
automated fact-checking, employ atomic fact decomposition to enhance
interpretability and robustness. For this, existing methods rely on
resource-intensive generative large language models (LLMs) to perform
decomposition. We propose JEDI, an encoder-only architecture that jointly
performs extractive atomic fact decomposition and interpretable inference
without requiring generative models during inference. To facilitate training,
we produce a large corpus of synthetic rationales covering multiple NLI
benchmarks. Experimental results demonstrate that JEDI achieves competitive
accuracy in distribution and significantly improves robustness out of
distribution and in adversarial settings over models based solely on extractive
rationale supervision. Our findings show that interpretability and robust
generalization in NLI can be realized using encoder-only architectures and
synthetic rationales. Code and data available at https://jedi.nicpopovic.com

</details>


### [213] [DTW-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment](https://arxiv.org/abs/2509.18987)
*Abderrahmane Issam,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文提出了一种基于动态时间规整（DTW）的方法，用于在端到端语音翻译（E2E-ST）训练期间对齐语音和文本嵌入，以弥合模态差距，实现更准确、更快速的对齐，并在低资源环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 端到端语音翻译（E2E-ST）面临语音和文本模态间的表示差异，即“模态鸿沟”。现有方法（如词或token级别对齐）需要并非所有语言都可用的对齐工具，而最近邻相似性搜索虽无需工具但对齐精度不足。

Method: 本文在训练过程中，采用动态时间规整（DTW）来对齐语音和文本的嵌入表示。

Result: 该方法有效弥合了E2E-ST中的模态鸿沟。与现有工作相比，它能生成更准确的对齐，实现可比的E2E-ST结果，同时显著提高速度。此外，在6个语言方向中的5个低资源设置下，该方法优于现有工作。

Conclusion: 所提出的DTW方法能有效、准确且快速地对齐语音和文本嵌入，成功弥合了E2E-ST中的模态差距，尤其在低资源环境下表现出色。

Abstract: End-to-End Speech Translation (E2E-ST) is the task of translating source
speech directly into target text bypassing the intermediate transcription step.
The representation discrepancy between the speech and text modalities has
motivated research on what is known as bridging the modality gap.
State-of-the-art methods addressed this by aligning speech and text
representations on the word or token level. Unfortunately, this requires an
alignment tool that is not available for all languages. Although this issue has
been addressed by aligning speech and text embeddings using nearest-neighbor
similarity search, it does not lead to accurate alignments. In this work, we
adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during
training. Our experiments demonstrate the effectiveness of our method in
bridging the modality gap in E2E-ST. Compared to previous work, our method
produces more accurate alignments and achieves comparable E2E-ST results while
being significantly faster. Furthermore, our method outperforms previous work
in low resource settings on 5 out of 6 language directions.

</details>


### [214] [Investigating Test-Time Scaling with Reranking for Machine Translation](https://arxiv.org/abs/2509.19020)
*Shaomu Tan,Ryosuke Mitani,Ritvik Choudhary,Toshiyuki Sekiya*

Main category: cs.CL

TL;DR: 本文首次系统研究了机器翻译（MT）中的测试时扩展（TTS）策略，发现其在高质量语言对中能有效提升翻译质量，并探讨了不同模型大小和计算预算下的性能与效率权衡。


<details>
  <summary>Details</summary>
Motivation: 扩展模型参数虽然能提升NLP系统性能，但计算成本高昂。测试时扩展（TTS）提供了一种替代方案，即在推理时分配更多计算资源（生成多个候选并选择最佳），但在机器翻译领域尚未得到系统探索。

Method: 研究采用了一个简单实用的“N选一”框架，在WMT24基准上对MT中的TTS进行了首次系统研究。实验涵盖了六个高资源语言对和一个低资源语言对，五种模型大小（3B-72B），以及高达1024的不同TTS计算预算（N值）。

Result: a) 对于高资源语言，TTS通常能根据多个神经MT评估指标提升翻译质量，并通过人工评估证实了这些提升；b) 使用大N值增强的小模型可以在付出更多计算成本的情况下，达到或超越N=1时的大模型性能；c) 在固定计算预算下，大模型通常更高效，但在低资源情况下，由于评估指标的盲点，TTS可能会降低质量。

Conclusion: TTS是提升机器翻译质量的有效策略，特别是在高资源语言对中。虽然较小的模型可以通过增加推理计算量来弥补其与大模型之间的差距，但在固定计算预算下，大模型通常更具效率。此外，在低资源场景下，TTS的效果可能受限于评估指标的准确性。

Abstract: Scaling model parameters has become the de facto strategy for improving NLP
systems, but it comes with substantial computational costs. Test-Time Scaling
(TTS) offers an alternative by allocating more computation at inference:
generating multiple candidates and selecting the best. While effective in tasks
such as mathematical reasoning, TTS has not been systematically explored for
machine translation (MT). In this paper, we present the first systematic study
of TTS for MT, investigating a simple but practical best-of-N framework on
WMT24 benchmarks. Our experiments cover six high-resource and one low-resource
language pairs, five model sizes (3B-72B), and various TTS compute budget (N up
to 1024). Our results show that a) For high-resource languages, TTS generally
improves translation quality according to multiple neural MT evaluation
metrics, and our human evaluation confirms these gains; b) Augmenting smaller
models with large $N$ can match or surpass larger models at $N{=}1$ with more
compute cost; c) Under fixed compute budgets, larger models are typically more
efficient, and TTS can degrade quality due to metric blind spots in
low-resource cases.

</details>


### [215] [Charting a Decade of Computational Linguistics in Italy: The CLiC-it Corpus](https://arxiv.org/abs/2509.19033)
*Chiara Alzetta,Serena Auriemma,Alessandro Bondielli,Luca Dini,Chiara Fazzone,Alessio Miaschi,Martina Miliani,Marta Sartor*

Main category: cs.CL

TL;DR: 本研究通过分析意大利领先的计算语言学与自然语言处理会议CLiC-it在过去十年的会议论文，追踪了意大利该领域的研究趋势，旨在为研究社区提供有价值的洞察。


<details>
  <summary>Details</summary>
Motivation: 计算语言学（CL）和自然语言处理（NLP）领域，特别是随着基于Transformer的大型语言模型（LLMs）的出现，在过去十年中迅速发展，改变了研究目标和优先事项。因此，有必要了解这些变化在特定研究社区（如意大利）中的体现。

Method: 研究人员收集了CLiC-it会议前十届（2014-2024年）的论文集，构建了CLiC-it语料库。他们对语料库的元数据（包括作者来源、性别、单位等）和论文内容（涉及的各种主题）进行了全面分析。

Result: 本研究提供了对意大利计算语言学和自然语言处理社区在过去十年中新兴趋势和关键发展的有价值的洞察，但抽象中并未列出具体发现。

Conclusion: 通过提供这些洞察，本研究旨在支持意大利和国际研究社区做出明智的决策，并指导该领域未来的发展方向。

Abstract: Over the past decade, Computational Linguistics (CL) and Natural Language
Processing (NLP) have evolved rapidly, especially with the advent of
Transformer-based Large Language Models (LLMs). This shift has transformed
research goals and priorities, from Lexical and Semantic Resources to Language
Modelling and Multimodality. In this study, we track the research trends of the
Italian CL and NLP community through an analysis of the contributions to
CLiC-it, arguably the leading Italian conference in the field. We compile the
proceedings from the first 10 editions of the CLiC-it conference (from 2014 to
2024) into the CLiC-it Corpus, providing a comprehensive analysis of both its
metadata, including author provenance, gender, affiliations, and more, as well
as the content of the papers themselves, which address various topics. Our goal
is to provide the Italian and international research communities with valuable
insights into emerging trends and key developments over time, supporting
informed decisions and future directions in the field.

</details>


### [216] [Pathways of Thoughts: Multi-Directional Thinking for Long-form Personalized Question Answering](https://arxiv.org/abs/2509.19094)
*Alireza Salemi,Cheng Li,Mingyang Zhang,Qiaozhu Mei,Zhuowan Li,Spurthi Amba Hombaiah,Weize Kong,Tao Chen,Hamed Zamani,Michael Bendersky*

Main category: cs.CL

TL;DR: 本文提出了一种名为“思维路径”（PoT）的推理阶段方法，旨在提升大型语言模型（LLM）在个性化问答（QA）中的表现。PoT通过迭代决策过程探索多条推理路径并根据用户偏好聚合候选答案，无需微调即可显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 个性化问答对于根据用户特定信息需求调整问答系统至关重要，但由于从冗长、嘈杂和隐式上下文中推断偏好以及生成既正确又符合用户期望和背景知识的响应等挑战，该领域仍未得到充分探索。

Method: PoT是一种推理阶段方法，适用于任何大型语言模型，无需进行特定任务的微调。它将LLM的推理建模为一个迭代决策过程，模型动态选择推理、修订、个性化和澄清等认知操作。这使得模型能够探索多种推理轨迹，生成捕捉不同视角的多元候选响应。随后，PoT根据推断出的用户偏好聚合并重新加权这些候选答案，从而产生最终的个性化响应。

Result: 在个性化问答基准LaMP-QA上的实验表明，PoT始终优于竞争性基线模型，相对改进高达13.1%。人工评估也证实了这些结果，标注者在66%的情况下更倾向于PoT的输出，仅在15%的情况下报告平局。

Conclusion: PoT通过建模迭代决策过程以探索多样化的推理路径，并根据用户偏好聚合响应，有效解决了个性化问答中的挑战。该方法在无需微调的情况下显著提升了LLM的个性化问答能力，提高了准确性和用户满意度。

Abstract: Personalization is essential for adapting question answering (QA) systems to
user-specific information needs, thereby improving both accuracy and user
satisfaction. However, personalized QA remains relatively underexplored due to
challenges such as inferring preferences from long, noisy, and implicit
contexts, and generating responses that are simultaneously correct,
contextually appropriate, and aligned with user expectations and background
knowledge. To address these challenges, we propose Pathways of Thoughts (PoT),
an inference-stage method that applies to any large language model (LLM)
without requiring task-specific fine-tuning. The approach models the reasoning
of an LLM as an iterative decision process, where the model dynamically selects
among cognitive operations such as reasoning, revision, personalization, and
clarification. This enables exploration of multiple reasoning trajectories,
producing diverse candidate responses that capture different perspectives. PoT
then aggregates and reweights these candidates according to inferred user
preferences, yielding a final personalized response that benefits from the
complementary strengths of diverse reasoning paths. Experiments on the LaMP-QA
benchmark for personalized QA show that PoT consistently outperforms
competitive baselines, achieving up to a 13.1% relative improvement. Human
evaluation corroborates these results, with annotators preferring outputs from
PoT in 66% of cases and reporting ties in only 15% of cases.

</details>


### [217] [Are most sentences unique? An empirical examination of Chomskyan claims](https://arxiv.org/abs/2509.19108)
*Hiram Ring*

Main category: cs.CL

TL;DR: 本文通过语料库分析，实证检验了语言学中“大多数语句都是独一无二的”这一说法，发现虽然独特句通常占多数，但这受语体类型高度制约，且重复句在任何语料库中都并非微不足道。


<details>
  <summary>Details</summary>
Motivation: 语言学中有一个反复出现的观点，即绝大多数语言表达都是独一无二的（例如，Pinker总结Chomsky的观点），但随着大型语料库的普及，这一主张现在可以进行实证检验。

Method: 使用NLTK Python库解析不同语体类型的语料库，并统计每个语料库中完全匹配的字符串（即重复句）的数量。

Result: 结果显示，虽然完全独特的句子通常在语料库中占多数，但这受到语体类型的高度制约。同时，重复句在任何单个语料库中都并非微不足道的一部分。

Conclusion: 关于语言表达近乎完全独特的说法需要修正，语体类型在句子的独特性方面扮演着重要角色，且重复句比传统观念认为的更为常见。

Abstract: A repeated claim in linguistics is that the majority of linguistic utterances
are unique. For example, Pinker (1994: 10), summarizing an argument by Noam
Chomsky, states that "virtually every sentence that a person utters or
understands is a brand-new combination of words, appearing for the first time
in the history of the universe." With the increased availability of large
corpora, this is a claim that can be empirically investigated. The current
paper addresses the question by using the NLTK Python library to parse corpora
of different genres, providing counts of exact string matches in each. Results
show that while completely unique sentences are often the majority of corpora,
this is highly constrained by genre, and that duplicate sentences are not an
insignificant part of any individual corpus.

</details>


### [218] [Human-Annotated NER Dataset for the Kyrgyz Language](https://arxiv.org/abs/2509.19109)
*Timur Turatali,Anton Alekseev,Gulira Jumalieva,Gulnara Kabaeva,Sergey Nikolenko*

Main category: cs.CL

TL;DR: 本文介绍了KyrgyzNER，首个针对吉尔吉斯语的手动标注命名实体识别数据集，包含1,499篇新闻文章、10,900个句子和39,075个实体提及。同时评估了传统CRF和多语言Transformer模型，发现多语言RoBERTa表现最佳，凸显了多语言预训练模型在低资源语言处理中的潜力。


<details>
  <summary>Details</summary>
Motivation: 吉尔吉斯语缺乏命名实体识别（NER）数据集，限制了该语言的自然语言处理发展。研究旨在填补这一空白，并探索现有模型在该低资源语言上的表现。

Method: 研究方法包括：1. 构建KyrgyzNER数据集，手动标注来自24.KG新闻门户的1,499篇新闻文章，共包含27类命名实体。2. 详细描述标注方案和遇到的挑战，并提供描述性统计数据。3. 评估多种NER模型，包括基于条件随机场（CRF）的传统序列标注方法和在数据集上微调的最新多语言Transformer模型（如多语言RoBERTa）。

Result: KyrgyzNER数据集包含10,900个句子和39,075个实体提及。所有评估模型在稀有实体类别上均表现出困难。多语言RoBERTa变体在准确率和召回率之间取得了有希望的平衡，表现最佳，但其他多语言模型也取得了可比结果。这表明多语言预训练模型在处理资源有限的语言方面既有挑战也有机遇。

Conclusion: 多语言预训练模型对低资源语言处理显示出巨大潜力，尤其是多语言RoBERTa模型。未来的工作可以探索更细粒度的标注方案，为吉尔吉斯语处理流程的评估提供更深入的见解。

Abstract: We introduce KyrgyzNER, the first manually annotated named entity recognition
dataset for the Kyrgyz language. Comprising 1,499 news articles from the 24.KG
news portal, the dataset contains 10,900 sentences and 39,075 entity mentions
across 27 named entity classes. We show our annotation scheme, discuss the
challenges encountered in the annotation process, and present the descriptive
statistics. We also evaluate several named entity recognition models, including
traditional sequence labeling approaches based on conditional random fields and
state-of-the-art multilingual transformer-based models fine-tuned on our
dataset. While all models show difficulties with rare entity categories, models
such as the multilingual RoBERTa variant pretrained on a large corpus across
many languages achieve a promising balance between precision and recall. These
findings emphasize both the challenges and opportunities of using multilingual
pretrained models for processing languages with limited resources. Although the
multilingual RoBERTa model performed best, other multilingual models yielded
comparable results. This suggests that future work exploring more granular
annotation schemes may offer deeper insights for Kyrgyz language processing
pipelines evaluation.

</details>


### [219] [Context-Aware Hierarchical Taxonomy Generation for Scientific Papers via LLM-Guided Multi-Aspect Clustering](https://arxiv.org/abs/2509.19125)
*Kun Zhu,Lizi Liao,Yuxuan Gu,Lei Huang,Xiaocheng Feng,Bing Qin*

Main category: cs.CL

TL;DR: 提出了一种新颖的上下文感知分层分类法生成框架，结合LLM引导的多方面编码和动态聚类，解决了现有方法在科学文献组织中缺乏连贯性和粒度的问题，并取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长要求高效的方法来组织和整合研究成果。现有分类法构建方法（如无监督聚类或直接LLM提示）往往缺乏连贯性和粒度。

Method: 该方法整合了LLM引导的多方面编码和动态聚类。具体而言，LLM识别每篇论文的关键方面（如方法、数据集、评估），生成特定方面的摘要，然后对这些摘要进行编码并沿每个方面进行聚类，以形成连贯的层次结构。此外，还引入了一个包含156个专家制作分类法和11.6k篇论文的新评估基准。

Result: 实验结果表明，该方法显著优于现有方法，在分类法的连贯性、粒度和可解释性方面达到了最先进的性能。

Conclusion: 所提出的上下文感知分层分类法生成框架，通过结合LLM的多方面编码和动态聚类，有效解决了科学文献组织中的挑战，并在多个关键评估指标上实现了卓越表现。

Abstract: The rapid growth of scientific literature demands efficient methods to
organize and synthesize research findings. Existing taxonomy construction
methods, leveraging unsupervised clustering or direct prompting of large
language models (LLMs), often lack coherence and granularity. We propose a
novel context-aware hierarchical taxonomy generation framework that integrates
LLM-guided multi-aspect encoding with dynamic clustering. Our method leverages
LLMs to identify key aspects of each paper (e.g., methodology, dataset,
evaluation) and generates aspect-specific paper summaries, which are then
encoded and clustered along each aspect to form a coherent hierarchy. In
addition, we introduce a new evaluation benchmark of 156 expert-crafted
taxonomies encompassing 11.6k papers, providing the first naturally annotated
dataset for this task. Experimental results demonstrate that our method
significantly outperforms prior approaches, achieving state-of-the-art
performance in taxonomy coherence, granularity, and interpretability.

</details>


### [220] [Anecdoctoring: Automated Red-Teaming Across Language and Place](https://arxiv.org/abs/2509.19143)
*Alejandro Cuevas,Saloni Dash,Bharat Kumar Nayak,Dan Vann,Madeleine I. G. Daepp*

Main category: cs.CL

TL;DR: 该研究提出了一种名为“anecdoctoring”的新型红队评估方法，通过自动生成跨语言和文化的对抗性提示，以应对生成式AI在虚假信息传播方面的风险，并克服现有评估数据集以美国和英语为中心的局限性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的滥用是虚假信息传播的主要风险之一。尽管需要跨语言和文化的鲁棒红队评估，但现有红队数据集普遍以美国和英语为中心，无法满足全球化需求。

Method: 研究提出“anecdoctoring”方法。首先，从事实核查网站收集三种语言（英语、西班牙语、印地语）和两个地理区域（美国、印度）的虚假信息声明。然后，将这些声明聚类成更广泛的叙事，并用知识图谱来表征这些聚类。最后，利用这些知识图谱增强一个攻击者大型语言模型（LLM），以自动生成对抗性提示。

Result: 该方法相比于少样本提示，产生了更高的攻击成功率，并提供了更好的可解释性优势。

Conclusion: 研究结果强调了开发全球规模且基于真实世界对抗性滥用情景的虚假信息缓解措施的必要性。

Abstract: Disinformation is among the top risks of generative artificial intelligence
(AI) misuse. Global adoption of generative AI necessitates red-teaming
evaluations (i.e., systematic adversarial probing) that are robust across
diverse languages and cultures, but red-teaming datasets are commonly US- and
English-centric. To address this gap, we propose "anecdoctoring", a novel
red-teaming approach that automatically generates adversarial prompts across
languages and cultures. We collect misinformation claims from fact-checking
websites in three languages (English, Spanish, and Hindi) and two geographies
(US and India). We then cluster individual claims into broader narratives and
characterize the resulting clusters with knowledge graphs, with which we
augment an attacker LLM. Our method produces higher attack success rates and
offers interpretability benefits relative to few-shot prompting. Results
underscore the need for disinformation mitigations that scale globally and are
grounded in real-world adversarial misuse.

</details>


### [221] [Measuring AI "Slop" in Text](https://arxiv.org/abs/2509.19163)
*Chantal Shaib,Tuhin Chakrabarty,Diego Garcia-Olano,Byron C. Wallace*

Main category: cs.CL

TL;DR: 本文旨在定义并量化“AI糟粕”（AI slop），通过专家访谈构建分类法，并提出可解释的评估维度，发现“糟粕”判断虽有主观性但与连贯性和相关性相关，并提供评估AI文本的框架。


<details>
  <summary>Details</summary>
Motivation: “AI糟粕”是一个日益流行的术语，用于描述低质量的AI生成文本，但目前尚无公认的定义或衡量其出现的方法。

Method: 通过对自然语言处理、写作和哲学专家的访谈，开发了“糟粕”的分类法；提出了评估文本中“糟粕”的一组可解释维度；进行了跨度级别的标注来分析二元“糟粕”判断的主观性及其与潜在维度（如连贯性和相关性）的关联。

Result: 研究发现，二元“糟粕”判断在一定程度上是主观的，但这些判断与连贯性和相关性等潜在维度存在关联。本文提出的框架可用于检测和二元偏好任务中评估AI生成文本。

Conclusion: 所提出的框架能为AI生成文本的质量判断提供新的见解，特别是关于语言和风格因素如何影响质量评估。这将有助于更好地理解和评估AI生成内容的质量。

Abstract: AI "slop" is an increasingly popular term used to describe low-quality
AI-generated text, but there is currently no agreed upon definition of this
term nor a means to measure its occurrence. In this work, we develop a taxonomy
of "slop" through interviews with experts in NLP, writing, and philosophy, and
propose a set of interpretable dimensions for its assessment in text. Through
span-level annotation, we find that binary "slop" judgments are (somewhat)
subjective, but such determinations nonetheless correlate with latent
dimensions such as coherence and relevance. Our framework can be used to
evaluate AI-generated text in both detection and binary preference tasks,
potentially offering new insights into the linguistic and stylistic factors
that contribute to quality judgments.

</details>


### [222] [Soft Tokens, Hard Truths](https://arxiv.org/abs/2509.19170)
*Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier*

Main category: cs.CL

TL;DR: 本文提出了一种可扩展的强化学习方法，用于训练大语言模型（LLMs）的连续思维链（CoT），解决了现有方法在训练难度和计算成本上的限制。该方法在数学推理任务上表现出色，提升了CoT多样性，并能更好地保持基础模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 连续令牌在理论上已被证明比离散令牌具有更强的表达能力，能更有效地解决问题，并能模拟多种推理路径的叠加。然而，现有方法在实际应用中面临严重的训练困难，如只能在推理时使用、需要从离散CoT中蒸馏且计算成本高昂，限制了连续CoT的长度。

Method: 本文首次提出一种可扩展的强化学习（RL）方法来学习连续CoT，而无需从参考离散CoT中蒸馏。该方法使用“软”令牌（令牌混合物加上输入嵌入的噪声）来促进RL探索。计算开销极小，能够学习包含数百个令牌的连续CoT。

Result: 在Llama和Qwen（高达8B参数）的数学推理基准测试中，使用连续CoT训练的模型在pass@1上与离散令牌CoT相当，在pass@32上则超越离散CoT，显示出更强的CoT多样性。最佳方案是使用连续CoT令牌进行训练，然后使用离散令牌进行推理，实现标准部署。此外，连续CoT的RL训练能更好地保留基础模型在域外任务上的预测能力。

Conclusion: 本文提出的基于强化学习的连续CoT训练方法是可扩展的，克服了以往训练连续CoT的难题。它显著提升了CoT的多样性，特别是在高通过率下，并能以标准方式部署。同时，该方法在不损害基础模型在域外任务表现的前提下，为模型训练提供了更“温和”的调整方式。

Abstract: The use of continuous instead of discrete tokens during the Chain-of-Thought
(CoT) phase of reasoning LLMs has garnered attention recently, based on the
intuition that a continuous mixture of discrete tokens could simulate a
superposition of several reasoning paths simultaneously. Theoretical results
have formally proven that continuous tokens have much greater expressivity and
can solve specific problems more efficiently. However, practical use of
continuous tokens has been limited by strong training difficulties: previous
works either just use continuous tokens at inference time on a pre-trained
discrete-token model, or must distill the continuous CoT from ground-truth
discrete CoTs and face computational costs that limit the CoT to very few
tokens.
  This is the first work introducing a scalable method to learn continuous CoTs
via reinforcement learning (RL), without distilling from reference discrete
CoTs. We use "soft" tokens: mixtures of tokens together with noise on the input
embedding to provide RL exploration. Computational overhead is minimal,
enabling us to learn continuous CoTs with hundreds of tokens. On math reasoning
benchmarks with Llama and Qwen models up to 8B, training with continuous CoTs
match discrete-token CoTs for pass@1 and surpass them for pass@32, showing
greater CoT diversity. In systematic comparisons, the best-performing scenario
is to train with continuous CoT tokens then use discrete tokens for inference,
meaning the "soft" models can be deployed in a standard way. Finally, we show
continuous CoT RL training better preserves the predictions of the base model
on out-of-domain tasks, thus providing a softer touch to the base model.

</details>


### [223] [Online Process Reward Leanring for Agentic Reinforcement Learning](https://arxiv.org/abs/2509.19199)
*Xiaoqian Liu,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li,Junge Zhang,Jianbin Jiao*

Main category: cs.CL

TL;DR: 本文提出了一种名为在线过程奖励学习（OPRL）的新型信用分配策略，用于提升基于强化学习的大型语言模型（LLM）代理的性能，通过将轨迹偏好转化为隐式步骤奖励，解决了稀疏奖励和信用分配的挑战。


<details>
  <summary>Details</summary>
Motivation: 将LLM训练为自主代理时，面临稀疏且有时难以验证的奖励导致的信用分配难题。现有集成过程监督的方法存在标注偏差、奖励劫持、信号过细导致的高方差或状态重叠罕见时的失败等问题。

Method: OPRL与标准在线策略算法无缝集成，无需额外回放或显式步骤标签。它通过基于轨迹的DPO目标，交替优化隐式过程奖励模型（PRM）和代理策略，将轨迹偏好转换为隐式步骤奖励。这些步骤奖励与回合级结果奖励结合，用于策略更新，形成一个自我强化的循环。理论上，学习到的步骤奖励与轨迹偏好一致，并作为基于势能的塑造奖励，提供有界梯度以稳定训练。

Result: OPRL在WebShop、VisualSokoban以及SOTOPIA等三个不同的代理基准测试中，表现优于前沿LLM和强大的RL基线。它实现了最先进的性能，具有更高的样本效率和更低的训练方差。进一步分析表明，OPRL使用更少的动作进行高效探索。

Conclusion: OPRL是一种通用且有效的代理RL信用分配策略，能够显著提升LLM代理在交互环境中的性能，具有更高的样本效率和更稳定的训练过程，在现实世界场景中的代理学习方面展现出巨大潜力。

Abstract: Large language models (LLMs) are increasingly trained with reinforcement
learning (RL) as autonomous agents that reason and act over long horizons in
interactive environments.
  However, sparse and sometimes unverifiable rewards make temporal credit
assignment extremely challenging.
  Recent work attempts to integrate process supervision into agent learning but
suffers from biased annotation, reward hacking, high-variance from overly
fine-grained signals or failtures when state overlap is rare.
  We therefore introduce Online Process Reward Learning (OPRL), a general
credit-assignment strategy for agentic RL that integrates seamlessly with
standard on-policy algorithms without relying on additional rollouts or
explicit step labels.
  In OPRL, we optimize an implicit process reward model (PRM) alternately with
the agent's policy to transform trajectory preferences into implicit step
rewards through a trajectory-based DPO objective.
  These step rewards are then used to compute step-level advantages, which are
combined with episode-level advantages from outcome rewards for policy update,
creating a self-reinforcing loop.
  Theoretical findings guarantee that the learned step rewards are consistent
with trajectory preferences and act as potential-based shaping rewards,
providing bounded gradients to stabilize training.
  Empirically, we evaluate OPRL on three distinct agent benmarks, including
WebShop and VisualSokoban, as well as open-ended social interactions with
unverfiable rewards in SOTOPIA.
  Crucially, OPRL shows superior performance over frontier LLMs and strong RL
baselines across domains, achieving state-of-the-art results with higher
sample-efficiency and lower variance during training.
  Further analysis also demonstrates the efficient exploration by OPRL using
fewer actions, underscoring its potential for agentic learning in real-world
scenarios.

</details>


### [224] [Steering Multimodal Large Language Models Decoding for Context-Aware Safety](https://arxiv.org/abs/2509.19212)
*Zheyuan Liu,Zhangchen Xu,Guangyao Dou,Xiangchi Yuan,Zhaoxuan Tan,Radha Poovendran,Meng Jiang*

Main category: cs.CL

TL;DR: 本文提出SafeCoDe，一个轻量级、模型无关的解码框架，通过对比解码和全局感知令牌调制，动态调整多模态大语言模型（MLLMs）的令牌生成，以提高上下文感知的安全决策，平衡过敏性和低敏性，同时保持模型有用性。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在实际应用中部署日益增多，但其进行上下文感知安全决策的能力有限。现有方法难以平衡过敏性（不合理地拒绝良性查询）和低敏性（未能检测到视觉相关的风险），导致安全对齐存在持续差距。

Method: 本文引入Safety-aware Contrastive Decoding (SafeCoDe)，一个轻量级且与模型无关的解码框架，分两阶段动态调整令牌生成：1) 对比解码机制，通过对比真实图像和高斯噪声图像来突出对视觉上下文敏感的令牌；2) 全局感知令牌调制策略，将场景级推理与令牌级调整相结合，根据预测的安全判断来调整拒绝行为。

Result: 在多种MLLM架构和安全基准（涵盖低敏性、过敏性和一般安全评估）上进行的广泛实验表明，SafeCoDe持续改进了上下文敏感的拒绝行为，同时保持了模型的有用性。

Conclusion: SafeCoDe通过动态调整令牌生成，有效提高了多模态大语言模型（MLLMs）的上下文感知安全决策能力，成功平衡了过敏性和低敏性，同时不牺牲模型的实用性。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly deployed in
real-world applications, yet their ability to make context-aware safety
decisions remains limited. Existing methods often fail to balance
oversensitivity (unjustified refusals of benign queries) and undersensitivity
(missed detection of visually grounded risks), leaving a persistent gap in
safety alignment. To address this issue, we introduce Safety-aware Contrastive
Decoding (SafeCoDe), a lightweight and model-agnostic decoding framework that
dynamically adjusts token generation based on multimodal context. SafeCoDe
operates in two stages: (1) a contrastive decoding mechanism that highlights
tokens sensitive to visual context by contrasting real and Gaussian-noised
images, and (2) a global-aware token modulation strategy that integrates
scene-level reasoning with token-level adjustment to adapt refusals according
to the predicted safety verdict. Extensive experiments across diverse MLLM
architectures and safety benchmarks, covering undersensitivity,
oversensitivity, and general safety evaluations, show that SafeCoDe
consistently improves context-sensitive refusal behaviors while preserving
model helpfulness.

</details>


### [225] [Systematic Comparative Analysis of Large Pretrained Language Models on Contextualized Medication Event Extraction](https://arxiv.org/abs/2509.19224)
*Tariq Abdul-Quddoos,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 本文对多种预训练注意力模型（如Bert Base, BioBert, RoBerta等）在电子健康记录（EHR）信息抽取任务上进行了比较分析，特别是针对药物事件的检测和上下文分类，发现临床数据预训练的模型在检测方面更有效，而通用领域预训练的Bert Base在上下文分类方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 注意力模型已成为医学语言处理（NLP）领域的主流方法，并在临床笔记中表现出色。研究旨在通过比较分析不同的预训练注意力模型，为电子健康记录（EHR）中的药物事件信息抽取任务开发有效的数据驱动解决方案，以应对哈佛医学院2022年国家临床NLP挑战（n2c2）的Track 1任务。

Method: 研究选取了Bert Base、BioBert、两种Bio+Clinical Bert变体、RoBerta和Clinical Longformer等预训练注意力模型进行比较。这些模型在n2c2挑战提供的上下文药物事件数据集（CMED）上进行微调，以执行药物提取、医学事件检测和多维药物事件上下文分类任务。同时，详细说明了EHR数据处理方法以适应模型。性能评估使用基于CMED评估部分的脚本，通过召回率、精确率和F1-分数等指标构建医学术语进行分析。

Result: 结果表明，在临床数据上预训练的模型在检测药物和药物事件方面更为有效。然而，在通用领域数据上预训练的Bert Base模型在分类与药物相关的事件上下文方面表现出最佳效果。

Conclusion: 研究得出结论，模型预训练的数据领域对其在医学NLP不同子任务中的表现有显著影响：临床数据预训练的模型更擅长检测任务，而通用数据预训练的模型（如Bert Base）在上下文分类任务上可能更具优势。

Abstract: Attention-based models have become the leading approach in modeling medical
language for Natural Language Processing (NLP) in clinical notes. These models
outperform traditional techniques by effectively capturing contextual rep-
resentations of language. In this research a comparative analysis is done
amongst pre- trained attention based models namely Bert Base, BioBert, two
variations of Bio+Clinical Bert, RoBerta, and Clinical Long- former on task
related to Electronic Health Record (EHR) information extraction. The tasks
from Track 1 of Harvard Medical School's 2022 National Clinical NLP Challenges
(n2c2) are considered for this comparison, with the Contextualized Medication
Event Dataset (CMED) given for these task. CMED is a dataset of unstructured
EHRs and annotated notes that contain task relevant information about the EHRs.
The goal of the challenge is to develop effective solutions for extracting
contextual information related to patient medication events from EHRs using
data driven methods. Each pre-trained model is fine-tuned and applied on CMED
to perform medication extraction, medical event detection, and
multi-dimensional medication event context classification. Pro- cessing methods
are also detailed for breaking down EHRs for compatibility with the applied
models. Performance analysis has been carried out using a script based on
constructing medical terms from the evaluation portion of CMED with metrics
including recall, precision, and F1-Score. The results demonstrate that models
pre-trained on clinical data are more effective in detecting medication and
medication events, but Bert Base, pre- trained on general domain data showed to
be the most effective for classifying the context of events related to
medications.

</details>


### [226] [CompLLM: Compression for Long Context Q&A](https://arxiv.org/abs/2509.19228)
*Gabriele Berton,Jayakrishnan Unnikrishnan,Son Tran,Mubarak Shah*

Main category: cs.CL

TL;DR: CompLLM是一种软上下文压缩技术，通过将长上下文分割并独立压缩，解决了LLM处理长上下文的二次复杂度问题，实现了线性扩展、可重用性和与非压缩上下文相当的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在处理长上下文时面临计算挑战，因为自注意力机制的复杂度呈二次方增长。现有的软上下文压缩方法通常将整个上下文作为单一单元压缩，导致压缩复杂度仍为二次方，且无法在重叠上下文的查询中重用计算，限制了实际应用。

Method: CompLLM引入了一种软压缩技术，将长上下文分割成多个段落，并独立压缩每个段落。这种设计实现了三个关键特性：效率（压缩步骤与上下文长度呈线性关系）、可扩展性（短序列训练模型可泛化到长上下文）和可重用性（压缩段可缓存并跨查询重用）。

Result: 实验表明，在2倍压缩率下，CompLLM在长上下文长度上将首个Token生成时间（TTFT）加速高达4倍，并将KV缓存大小减少50%。此外，CompLLM的性能与未压缩上下文相当，甚至在极长序列上超越了未压缩上下文的性能。

Conclusion: CompLLM通过其分段独立压缩的方法，有效解决了LLM处理长上下文的计算挑战，在保持甚至超越性能的同时，显著提高了效率、可扩展性和计算重用性，展现了其卓越的有效性和实用价值。

Abstract: Large Language Models (LLMs) face significant computational challenges when
processing long contexts due to the quadratic complexity of self-attention.
While soft context compression methods, which map input text to smaller latent
representations, have shown promise, their real-world adoption is limited.
Existing techniques typically compress the context as a single unit, which
leads to quadratic compression complexity and an inability to reuse
computations across queries with overlapping contexts. In this work, we
introduce CompLLM, a soft compression technique designed for practical
deployment. Instead of processing the context holistically, CompLLM divides it
into segments and compresses each one independently. This simple design choice
yields three critical properties: efficiency, as the compression step scales
linearly with the context length; scalability, enabling models trained on short
sequences (e.g., 1k tokens) to generalize to contexts of 100k tokens; and
reusability, allowing compressed segments to be cached and reused across
different queries. Our experiments show that with a 2x compression rate, at
high context lengths CompLLM speeds up Time To First Token (TTFT) by up to 4x
and reduces the KV cache size by 50%. Furthermore, CompLLM achieves performance
comparable to that obtained with the uncompressed context, and even surpasses
it on very long sequences, demonstrating its effectiveness and practical
utility.

</details>


### [227] [Reinforcement Learning on Pre-Training Data](https://arxiv.org/abs/2509.19249)
*Siheng Li,Kejiao Li,Zenan Xu,Guanhua Huang,Evander Yang,Kun Li,Haoyuan Wu,Jiajia Wu,Zihao Zheng,Chenchen Zhang,Kun Shi,Kyrierl Deng,Qi Yi,Ruibin Xiong,Tingqiang Xu,Yuhao Jiang,Jianfeng Yan,Yuyuan Zeng,Guanghui Xu,Jinbao Xue,Zhijiang Xu,Zheng Fang,Shuai Li,Qibin Liu,Xiaoxue Li,Zhuoyu Li,Yangyu Tao,Fei Gao,Cheng Jiang,Bo Chao Wang,Kai Liu,Jianchen Zhu,Wai Lam,Wayyt Wang,Bo Zhou,Di Wang*

Main category: cs.CL

TL;DR: RLPT是一种新的LLM训练范式，通过在预训练数据上应用强化学习，解决了高质量文本数据增长有限的问题，并在无需人工标注的情况下显著提升了模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 计算资源呈指数级增长，但高质量文本数据的增长有限，这限制了大型语言模型（LLMs）传统的扩展方法。

Method: 引入了预训练数据上的强化学习（RLPT）。与以往主要通过监督学习扩展训练的方法不同，RLPT使策略能够自主探索有意义的轨迹，从预训练数据中学习并通过强化学习提高能力。RLPT通过直接从预训练数据中获取奖励信号，避免了对人工标注的依赖（与RLHF和RLVR不同）。具体而言，它采用“下一段推理”目标，奖励策略准确预测后续文本段落的能力。

Result: 在通用领域和数学推理基准测试中，RLPT被证明是有效的。例如，应用于Qwen3-4B-Base时，RLPT在MMLU、MMLU-Pro、GPQA-Diamond、KOR-Bench、AIME24和AIME25上分别获得了3.0、5.1、8.1、6.0、6.6和5.3的绝对提升。结果还表明其具有良好的扩展行为，预示着随着计算资源的增加，仍有持续提升的潜力。此外，RLPT为扩展LLM的推理边界和增强RLVR性能提供了坚实基础。

Conclusion: RLPT是一种有效且可扩展的LLM训练范式，它通过利用预训练数据进行强化学习，解决了数据稀缺问题，提升了模型的泛化推理能力，并为LLM的进一步发展奠定了基础。

Abstract: The growing disparity between the exponential scaling of computational
resources and the finite growth of high-quality text data now constrains
conventional scaling approaches for large language models (LLMs). To address
this challenge, we introduce Reinforcement Learning on Pre-Training data
(RLPT), a new training-time scaling paradigm for optimizing LLMs. In contrast
to prior approaches that scale training primarily through supervised learning,
RLPT enables the policy to autonomously explore meaningful trajectories to
learn from pre-training data and improve its capability through reinforcement
learning (RL). While existing RL strategies such as reinforcement learning from
human feedback (RLHF) and reinforcement learning with verifiable rewards (RLVR)
rely on human annotation for reward construction, RLPT eliminates this
dependency by deriving reward signals directly from pre-training data.
Specifically, it adopts a next-segment reasoning objective, rewarding the
policy for accurately predicting subsequent text segments conditioned on the
preceding context. This formulation allows RL to be scaled on pre-training
data, encouraging the exploration of richer trajectories across broader
contexts and thereby fostering more generalizable reasoning skills. Extensive
experiments on both general-domain and mathematical reasoning benchmarks across
multiple models validate the effectiveness of RLPT. For example, when applied
to Qwen3-4B-Base, RLPT yields absolute improvements of $3.0$, $5.1$, $8.1$,
$6.0$, $6.6$, and $5.3$ on MMLU, MMLU-Pro, GPQA-Diamond, KOR-Bench, AIME24, and
AIME25, respectively. The results further demonstrate favorable scaling
behavior, suggesting strong potential for continued gains with more compute. In
addition, RLPT provides a solid foundation, extending the reasoning boundaries
of LLMs and enhancing RLVR performance.

</details>


### [228] [Extracting Conceptual Spaces from LLMs Using Prototype Embeddings](https://arxiv.org/abs/2509.19269)
*Nitesh Kumar,Usashi Chatterjee,Steven Schockaert*

Main category: cs.CL

TL;DR: 本文提出了一种从大型语言模型（LLMs）中提取概念空间的新策略，通过嵌入原型描述来编码特征，并通过微调LLM来对齐原型嵌入与概念维度，实验证明该方法非常有效。


<details>
  <summary>Details</summary>
Motivation: 概念空间在认知科学中广泛应用，并有望成为可解释人工智能（XAI）的基石。然而，它们很难学习。尽管最近的LLMs似乎在很大程度上捕捉到了所需的感知特征，但目前仍然缺乏提取相应概念空间的实用方法。

Method: 该研究提出了一种策略，通过嵌入相应原型（例如，“非常甜的食物”来表示“甜度”）的描述来编码特征。为了改进这一策略，研究人员对LLM进行了微调，以使原型嵌入与相应的概念空间维度对齐。

Result: 实证分析发现，所提出的方法高度有效。

Conclusion: 通过嵌入原型描述和微调LLM对齐原型嵌入与概念维度，可以有效地从LLMs中提取概念空间。

Abstract: Conceptual spaces represent entities and concepts using cognitively
meaningful dimensions, typically referring to perceptual features. Such
representations are widely used in cognitive science and have the potential to
serve as a cornerstone for explainable AI. Unfortunately, they have proven
notoriously difficult to learn, although recent LLMs appear to capture the
required perceptual features to a remarkable extent. Nonetheless, practical
methods for extracting the corresponding conceptual spaces are currently still
lacking. While various methods exist for extracting embeddings from LLMs,
extracting conceptual spaces also requires us to encode the underlying
features. In this paper, we propose a strategy in which features (e.g.
sweetness) are encoded by embedding the description of a corresponding
prototype (e.g. a very sweet food). To improve this strategy, we fine-tune the
LLM to align the prototype embeddings with the corresponding conceptual space
dimensions. Our empirical analysis finds this approach to be highly effective.

</details>


### [229] [SloPalSpeech: A 2,8000-Hour Slovak Speech Corpus from Parliamentary Data](https://arxiv.org/abs/2509.19270)
*Erik Božík,Marek Šuppa*

Main category: cs.CL

TL;DR: 该研究引入了一个新的大规模斯洛伐克语ASR数据集SloPalSpeech（2,806小时），并使用它微调了OpenAI Whisper模型，显著降低了标准基准上的词错误率，并公开了数据集和模型。


<details>
  <summary>Details</summary>
Motivation: 斯洛伐克语等低资源语言的自动语音识别（ASR）因训练数据稀缺而受阻。

Method: 研究团队开发了一个鲁棒的处理流程，将议会记录中的长篇录音对齐并分割成干净的30秒音频-文本对。然后，他们使用这个名为SloPalSpeech的新数据集微调了多种OpenAI Whisper模型（small, medium, large-v3, large-v3-turbo）。

Result: 微调后的Whisper模型在Common Voice和FLEURS等标准斯洛伐克语基准测试上实现了显著的词错误率（WER）降低。例如，微调后的Whisper-small模型的WER降低了高达70%，接近更大的Whisper-large-v3模型的基线性能。

Conclusion: 该研究通过公开完整的SloPalSpeech数据集、分割后的文本（6000万词）以及所有微调模型，旨在促进低资源语音识别领域的未来研究。

Abstract: Automatic Speech Recognition (ASR) for low-resource languages like Slovak is
hindered by the scarcity of training data. To address this, we introduce
SloPalSpeech, a new, large-scale Slovak ASR dataset containing 2,806 hours of
speech from parliamentary proceedings. We developed a robust processing
pipeline to align and segment long-form recordings into clean, 30-second
audio-transcript pairs suitable for model training. We use this dataset to
fine-tune several OpenAI Whisper models (small, medium, large-v3, and
large-v3-turbo), achieving significant Word Error Rate (WER) reductions on
standard Slovak benchmarks like Common Voice and FLEURS. For instance, the
fine-tuned Whisper-small model's WER dropped by up to 70\%, approaching the
baseline performance of the much larger Whisper-large-v3 model. To foster
future research in low-resource speech recognition, we publicly release the
complete SloPalSpeech dataset, the fully segmented transcripts (60 million
words), and all our fine-tuned models.

</details>


### [230] [WolBanking77: Wolof Banking Speech Intent Classification Dataset](https://arxiv.org/abs/2509.19271)
*Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione*

Main category: cs.CL

TL;DR: 该论文发布了一个新的沃洛夫语（Wolof）意图分类数据集WolBanking77，包含文本和语音数据，旨在解决低资源语言和高文盲率地区意图分类的挑战。


<details>
  <summary>Details</summary>
Motivation: 以往的意图分类模型主要关注高资源语言数据集，导致低资源语言以及文盲率高、语言以口语为主的地区存在空白。沃洛夫语在西非地区有超过1000万人使用，而塞内加尔的文盲率高达42%，因此急需针对此类语言的数据集。

Method: 研究者发布了Wolof意图分类数据集（WolBanking77），该数据集包含9,791个银行领域的文本句子和超过4小时的口语句子。在此数据集上，他们对文本和语音领域的各种最先进基线模型进行了实验，并提供了详细的数据内容分析。

Result: 在WolBanking77数据集上，各种基线模型的实验结果“非常有前景”。论文报告了NLP模型的F1分数和ASR模型的词错误率（WER）指标，并进行了模型间的比较。

Conclusion: 该论文通过发布WolBanking77数据集，为低资源语言的意图分类研究填补了空白，并展示了在沃洛夫语上进行意图分类的可行性。未来计划进行数据集维护、更新并发布开源代码。

Abstract: Intent classification models have made a lot of progress in recent years.
However, previous studies primarily focus on high-resource languages datasets,
which results in a gap for low-resource languages and for regions with a high
rate of illiterate people where languages are more spoken than read or written.
This is the case in Senegal, for example, where Wolof is spoken by around 90\%
of the population, with an illiteracy rate of 42\% for the country. Wolof is
actually spoken by more than 10 million people in West African region. To
tackle such limitations, we release a Wolof Intent Classification Dataset
(WolBanking77), for academic research in intent classification. WolBanking77
currently contains 9,791 text sentences in the banking domain and more than 4
hours of spoken sentences. Experiments on various baselines are conducted in
this work, including text and voice state-of-the-art models. The results are
very promising on this current dataset. This paper also provides detailed
analyses of the contents of the data. We report baseline f1-score and word
error rate metrics respectively on NLP and ASR models trained on WolBanking77
dataset and also comparisons between models. We plan to share and conduct
dataset maintenance, updates and to release open-source code.

</details>


### [231] [DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture](https://arxiv.org/abs/2509.19274)
*Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Nemil Shah,Abhilekh Borah,Vanshika Shah,Nishant Mishra,Sriparna Saha*

Main category: cs.CL

TL;DR: DRISHTIKON是一个专注于印度文化的多模态、多语言基准测试，旨在评估生成式AI系统的文化理解能力，并揭示了当前模型在处理文化背景输入方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试范围通用或全球化，缺乏对印度等多元文化的深入、细致覆盖，无法有效评估生成式AI系统对特定文化的理解能力。

Method: 引入了DRISHTIKON，一个包含15种语言、覆盖印度所有邦和联邦属地、超过64,000个对齐文本-图像对的多模态、多语言基准数据集。该数据集涵盖节日、服饰、美食、艺术形式和历史遗产等丰富的文化主题。作者评估了广泛的视觉-语言模型（VLM），包括开源大小模型、专有系统、推理专业VLM和专注于印度语言的模型，采用零样本和思维链设置。

Result: 评估结果揭示了当前模型在处理基于文化的多模态输入进行推理时存在关键局限性，尤其是在低资源语言和较少记录的传统方面表现不佳。

Conclusion: DRISHTIKON填补了包容性AI研究中的一个重要空白，提供了一个强大的测试平台，以推动文化感知、多模态能力强的语言技术发展。

Abstract: We introduce DRISHTIKON, a first-of-its-kind multimodal and multilingual
benchmark centered exclusively on Indian culture, designed to evaluate the
cultural understanding of generative AI systems. Unlike existing benchmarks
with a generic or global scope, DRISHTIKON offers deep, fine-grained coverage
across India's diverse regions, spanning 15 languages, covering all states and
union territories, and incorporating over 64,000 aligned text-image pairs. The
dataset captures rich cultural themes including festivals, attire, cuisines,
art forms, and historical heritage amongst many more. We evaluate a wide range
of vision-language models (VLMs), including open-source small and large models,
proprietary systems, reasoning-specialized VLMs, and Indic-focused models,
across zero-shot and chain-of-thought settings. Our results expose key
limitations in current models' ability to reason over culturally grounded,
multimodal inputs, particularly for low-resource languages and less-documented
traditions. DRISHTIKON fills a vital gap in inclusive AI research, offering a
robust testbed to advance culturally aware, multimodally competent language
technologies.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [232] [PEEK: Guiding and Minimal Image Representations for Zero-Shot Generalization of Robot Manipulation Policies](https://arxiv.org/abs/2509.18282)
*Jesse Zhang,Marius Memmel,Kevin Kim,Dieter Fox,Jesse Thomason,Fabio Ramos,Erdem Bıyık,Abhishek Gupta,Anqi Li*

Main category: cs.RO

TL;DR: PEEK通过微调视觉-语言模型（VLMs）来预测统一的基于点的中间表示（末端执行器路径和任务相关掩码），将机器人操纵策略中的高层推理（在哪里、做什么）卸载给VLMs，从而使策略专注于如何行动，显著提高了零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人操纵策略在泛化方面常常失败，因为它们必须同时学习关注哪里、采取什么行动以及如何执行这些行动，这导致学习任务过于复杂。

Method: 本文提出了PEEK（Policy-agnostic Extraction of Essential Keypoints），它微调视觉-语言模型（VLMs）来预测统一的基于点的中间表示：1) 指定采取什么行动的末端执行器路径，以及2) 指示关注哪里的任务相关掩码。这些注释直接叠加到机器人观测数据上，使表示与策略无关并可在不同架构间转移。为实现可扩展训练，引入了一个自动化标注流程，生成了跨20多个机器人数据集和9种实体的数据。

Result: 在实际世界评估中，PEEK持续提升了零样本泛化能力，包括使仅在仿真中训练的3D策略在实际世界中实现了41.4倍的改进，并使大型视觉-语言-动作模型（VLAs）和小型操纵策略都获得了2-3.5倍的增益。

Conclusion: 通过让VLMs吸收语义和视觉复杂性，PEEK为操纵策略提供了它们所需的最少线索（在哪里、做什么、如何做），从而显著增强了它们的泛化能力。

Abstract: Robotic manipulation policies often fail to generalize because they must
simultaneously learn where to attend, what actions to take, and how to execute
them. We argue that high-level reasoning about where and what can be offloaded
to vision-language models (VLMs), leaving policies to specialize in how to act.
We present PEEK (Policy-agnostic Extraction of Essential Keypoints), which
fine-tunes VLMs to predict a unified point-based intermediate representation:
1. end-effector paths specifying what actions to take, and 2. task-relevant
masks indicating where to focus. These annotations are directly overlaid onto
robot observations, making the representation policy-agnostic and transferable
across architectures. To enable scalable training, we introduce an automatic
annotation pipeline, generating labeled data across 20+ robot datasets spanning
9 embodiments. In real-world evaluations, PEEK consistently boosts zero-shot
generalization, including a 41.4x real-world improvement for a 3D policy
trained only in simulation, and 2-3.5x gains for both large VLAs and small
manipulation policies. By letting VLMs absorb semantic and visual complexity,
PEEK equips manipulation policies with the minimal cues they need--where, what,
and how. Website at https://peek-robot.github.io/.

</details>


### [233] [Fine-Tuning Robot Policies While Maintaining User Privacy](https://arxiv.org/abs/2509.18311)
*Benjamin A. Christie,Sagar Parekh,Dylan P. Losey*

Main category: cs.RO

TL;DR: 本文提出PRoP框架，通过为每个用户配备独特的密钥来数学转换机器人网络权重，实现个性化且私密的机器人策略，同时防止用户偏好数据泄露给外部代理。


<details>
  <summary>Details</summary>
Motivation: 通用机器人策略虽然强大，但用户在个性化微调过程中会泄露个人偏好、习惯等敏感数据。核心挑战在于如何在个性化机器人行为的同时，保护学习过程中的用户隐私不被外部代理获取。

Method: PRoP（个性化和私密机器人策略）是一个模型无关的框架。其核心思想是为每个用户配备一个唯一的密钥，该密钥用于数学转换机器人网络的权重。使用正确的密钥，机器人策略将匹配用户的偏好；使用不正确的密钥，机器人将恢复到其基线行为。

Result: PRoP方法在模仿学习、强化学习和分类任务等多种模型类型中显示出普遍适用性。它保留了原始策略的架构和行为，并在实验中优于现有的基于编码器的方法。

Conclusion: PRoP框架通过独特的密钥转换机制，成功解决了机器人个性化与隐私保护之间的矛盾，实现了私密学习的个性化机器人策略，并展现出实际优势和卓越性能。

Abstract: Recent works introduce general-purpose robot policies. These policies provide
a strong prior over how robots should behave -- e.g., how a robot arm should
manipulate food items. But in order for robots to match an individual person's
needs, users typically fine-tune these generalized policies -- e.g., showing
the robot arm how to make their own preferred dinners. Importantly, during the
process of personalizing robots, end-users leak data about their preferences,
habits, and styles (e.g., the foods they prefer to eat). Other agents can
simply roll-out the fine-tuned policy and see these personally-trained
behaviors. This leads to a fundamental challenge: how can we develop robots
that personalize actions while keeping learning private from external agents?
We here explore this emerging topic in human-robot interaction and develop
PRoP, a model-agnostic framework for personalized and private robot policies.
Our core idea is to equip each user with a unique key; this key is then used to
mathematically transform the weights of the robot's network. With the correct
key, the robot's policy switches to match that user's preferences -- but with
incorrect keys, the robot reverts to its baseline behaviors. We show the
general applicability of our method across multiple model types in imitation
learning, reinforcement learning, and classification tasks. PRoP is practically
advantageous because it retains the architecture and behaviors of the original
policy, and experimentally outperforms existing encoder-based approaches. See
videos and code here: https://prop-icra26.github.io.

</details>


### [234] [Haptic Communication in Human-Human and Human-Robot Co-Manipulation](https://arxiv.org/abs/2509.18327)
*Katherine H. Allen,Chris Rogers,Elaine S. Short*

Main category: cs.RO

TL;DR: 本研究比较了人-人与人-机器人在共享物体操作中的协作，发现人-人协作更流畅，并通过IMU和问卷数据证实了客观和主观差异，从而启发了改进机器人触觉通信的研究。


<details>
  <summary>Details</summary>
Motivation: 了解人类在共同操作物体时如何通过物体运动进行“触觉沟通”，并将其与人-机器人互动进行比较，以期改进机器人协作助手。

Method: 捕捉人类双人组共同操作物体（一人主导，一人不知情）的运动；然后捕捉相同的参与者与机器人协作操作同一物体的运动。使用低成本IMU跟踪共享物体的运动，并使用研究内和研究后问卷收集参与者反馈。最后，直接比较人-人与人-机器人协作的IMU数据和问卷结果。

Result: 问卷调查显示人-人协作显著更流畅。IMU数据捕获了不同条件（人-人 vs. 人-机器人）下运动曲线的客观差异。人-人与人-机器人试验在准确性和流畅性方面的客观和主观测量存在差异。

Conclusion: 人-人与人-机器人试验之间客观和主观测量结果的差异，促使未来研究通过使机器人能够发送和接收拟人化的触觉信号，来改进用于物理任务的机器人助手。

Abstract: When a human dyad jointly manipulates an object, they must communicate about
their intended motion plans. Some of that collaboration is achieved through the
motion of the manipulated object itself, which we call "haptic communication."
In this work, we captured the motion of human-human dyads moving an object
together with one participant leading a motion plan about which the follower is
uninformed. We then captured the same human participants manipulating the same
object with a robot collaborator. By tracking the motion of the shared object
using a low-cost IMU, we can directly compare human-human shared manipulation
to the motion of those same participants interacting with the robot.
Intra-study and post-study questionnaires provided participant feedback on the
collaborations, indicating that the human-human collaborations are
significantly more fluent, and analysis of the IMU data indicates that it
captures objective differences in the motion profiles of the conditions. The
differences in objective and subjective measures of accuracy and fluency
between the human-human and human-robot trials motivate future research into
improving robot assistants for physical tasks by enabling them to send and
receive anthropomorphic haptic signals.

</details>


### [235] [The Landform Contextual Mesh: Automatically Fusing Surface and Orbital Terrain for Mars 2020](https://arxiv.org/abs/2509.18330)
*Marsette Vona*

Main category: cs.RO

TL;DR: 该研究将火星2020探测器图像与火星勘测轨道器数据融合，自动生成交互式3D地形可视化（地貌情境网格），供任务规划和公众探索使用。


<details>
  <summary>Details</summary>
Motivation: 为火星2020任务科学家提供综合的3D地形可视化工具，以便进行战术和战略规划，并向公众开放部分数据。

Method: 将来自数千张火星2020探测器图像的2D和3D数据，以及来自火星勘测轨道器的轨道高程和彩色地图融合。在任务地面数据系统处理过程中自动构建“地貌情境网格”。

Result: 为每个漫游车位置创建了交互式3D地形可视化（情境网格）。这些网格可供任务科学家在ASTTRO工具中进行规划，其中一部分也部署到“与毅力号一起探索”的公众网站。

Conclusion: 地貌情境网格成功地将多种火星数据源整合为可用的3D可视化，有效支持了科学任务规划和公众参与。

Abstract: The Landform contextual mesh fuses 2D and 3D data from up to thousands of
Mars 2020 rover images, along with orbital elevation and color maps from Mars
Reconnaissance Orbiter, into an interactive 3D terrain visualization.
Contextual meshes are built automatically for each rover location during
mission ground data system processing, and are made available to mission
scientists for tactical and strategic planning in the Advanced Science
Targeting Tool for Robotic Operations (ASTTRO). A subset of them are also
deployed to the "Explore with Perseverance" public access website.

</details>


### [236] [Semantic-Aware Particle Filter for Reliable Vineyard Robot Localisation](https://arxiv.org/abs/2509.18342)
*Rajitha de Silva,Jonathan Cox,James R. Heselden,Marija Popovic,Cesar Cadena,Riccardo Polvara*

Main category: cs.RO

TL;DR: 本文提出了一种语义粒子滤波器，通过融合稳定的物体级检测（如藤蔓树干和支撑杆）以及“语义墙”作为结构约束，解决了移动机器人在葡萄园中因LiDAR感知混叠导致的定位失败问题，并在语义稀疏的区域引入噪声GPS先验以保持全局一致性。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在结构化的户外环境中（如葡萄园）需要精确的定位，但LiDAR方法常因重复的行几何结构和感知混叠而失效。

Method: 采用语义粒子滤波器，将藤蔓树干和支撑杆等稳定的物体级检测融入似然估计。检测到的地标被投影到鸟瞰图并与LiDAR扫描融合以生成语义观测。关键创新是使用“语义墙”将相邻地标连接成伪结构约束，以缓解行混叠。为在语义稀疏的田头区域保持全局一致性，引入了自适应支持滤波器的带噪声GPS先验。

Result: 在真实葡萄园的实验表明，该方法能够将定位保持在正确的行内，在AMCL失效的情况下能够从偏差中恢复，并且优于RTAB-Map等基于视觉的SLAM方法。

Conclusion: 所提出的语义粒子滤波器通过结合物体级语义信息和自适应GPS先验，有效解决了葡萄园等重复结构环境中机器人定位的挑战，并展现出优于现有方法的性能。

Abstract: Accurate localisation is critical for mobile robots in structured outdoor
environments, yet LiDAR-based methods often fail in vineyards due to repetitive
row geometry and perceptual aliasing. We propose a semantic particle filter
that incorporates stable object-level detections, specifically vine trunks and
support poles into the likelihood estimation process. Detected landmarks are
projected into a birds eye view and fused with LiDAR scans to generate semantic
observations. A key innovation is the use of semantic walls, which connect
adjacent landmarks into pseudo-structural constraints that mitigate row
aliasing. To maintain global consistency in headland regions where semantics
are sparse, we introduce a noisy GPS prior that adaptively supports the filter.
Experiments in a real vineyard demonstrate that our approach maintains
localisation within the correct row, recovers from deviations where AMCL fails,
and outperforms vision-based SLAM methods such as RTAB-Map.

</details>


### [237] [AD-VF: LLM-Automatic Differentiation Enables Fine-Tuning-Free Robot Planning from Formal Methods Feedback](https://arxiv.org/abs/2509.18384)
*Yunhao Yang,Junyuan Hong,Gabriel Jacob Perin,Zhiwen Fan,Li Yin,Zhangyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: LAD-VF是一个无需微调的框架，它利用形式化验证反馈自动进行提示工程，以提高大型语言模型在机器人等领域规划时对安全和规范的依从性，将成功率从60%提升至90%以上。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在将自然语言指令转换为可执行行动计划方面表现出色，但在物理世界部署时，常因幻觉或弱对齐而违反安全和监管约束。传统的对齐方法（如DPO）需要昂贵的人工标注，而现有形式化反馈方法则依赖于资源密集型微调。

Method: 本文提出了LAD-VF框架，它无需微调。该方法利用形式化验证反馈进行自动化提示工程。通过将形式化验证信息文本损失与LLM-AutoDiff结合，LAD-VF迭代地优化提示而非模型参数。

Result: 在机器人导航和操作任务中的实验表明，LAD-VF显著增强了规范依从性，将成功率从60%提高到90%以上。该方法实现了可扩展的适应性、与模块化LLM架构的兼容性以及通过可审计提示进行的可解释优化。

Conclusion: LAD-VF为构建值得信赖、经过形式化验证的LLM驱动控制系统提供了一条可扩展且可解释的途径。

Abstract: Large language models (LLMs) can translate natural language instructions into
executable action plans for robotics, autonomous driving, and other domains.
Yet, deploying LLM-driven planning in the physical world demands strict
adherence to safety and regulatory constraints, which current models often
violate due to hallucination or weak alignment. Traditional data-driven
alignment methods, such as Direct Preference Optimization (DPO), require costly
human labeling, while recent formal-feedback approaches still depend on
resource-intensive fine-tuning. In this paper, we propose LAD-VF, a
fine-tuning-free framework that leverages formal verification feedback for
automated prompt engineering. By introducing a formal-verification-informed
text loss integrated with LLM-AutoDiff, LAD-VF iteratively refines prompts
rather than model parameters. This yields three key benefits: (i) scalable
adaptation without fine-tuning; (ii) compatibility with modular LLM
architectures; and (iii) interpretable refinement via auditable prompts.
Experiments in robot navigation and manipulation tasks demonstrate that LAD-VF
substantially enhances specification compliance, improving success rates from
60% to over 90%. Our method thus presents a scalable and interpretable pathway
toward trustworthy, formally-verified LLM-driven control systems.

</details>


### [238] [Assistive Decision-Making for Right of Way Navigation at Uncontrolled Intersections](https://arxiv.org/abs/2509.18407)
*Navya Tiwari,Joseph Vazhaeparampil,Victoria Preston*

Main category: cs.RO

TL;DR: 该研究提出了一个基于POMDP的驾驶辅助框架，用于在非受控交叉口进行路权推理，通过模拟评估发现概率规划器（如POMCP和DESPOT）在部分可观察性下显著优于确定性规则，实现了更高的无碰撞导航率。


<details>
  <summary>Details</summary>
Motivation: 非受控交叉口因路权规则模糊、视线遮挡和驾驶员行为不可预测而导致大量交通事故。尽管自动驾驶汽车研究已探索了不确定性感知决策，但现有为人类驾驶车辆提供辅助导航支持的系统较少。

Method: 将非受控交叉口的路权推理问题建模为部分可观察马尔可夫决策过程（POMDP）。使用自定义模拟测试平台，该平台包含随机交通代理、行人、遮挡和对抗性场景。评估了四种决策方法：确定性有限状态机（FSM）以及三种概率规划器：QMDP、POMCP和DESPOT。

Result: 结果表明，概率规划器优于基于规则的基线方法，在部分可观察性下实现了高达97.5%的无碰撞导航。其中，POMCP优先考虑安全性，而DESPOT在效率和运行时可行性之间取得了平衡。

Conclusion: 研究结果强调了不确定性感知规划对于驾驶辅助的重要性，并激励未来将传感器融合和环境感知模块集成，以实现在真实交通环境中的实时部署。

Abstract: Uncontrolled intersections account for a significant fraction of roadway
crashes due to ambiguous right-of-way rules, occlusions, and unpredictable
driver behavior. While autonomous vehicle research has explored
uncertainty-aware decision making, few systems exist to retrofit human-operated
vehicles with assistive navigation support. We present a driver-assist
framework for right-of-way reasoning at uncontrolled intersections, formulated
as a Partially Observable Markov Decision Process (POMDP). Using a custom
simulation testbed with stochastic traffic agents, pedestrians, occlusions, and
adversarial scenarios, we evaluate four decision-making approaches: a
deterministic finite state machine (FSM), and three probabilistic planners:
QMDP, POMCP, and DESPOT. Results show that probabilistic planners outperform
the rule-based baseline, achieving up to 97.5 percent collision-free navigation
under partial observability, with POMCP prioritizing safety and DESPOT
balancing efficiency and runtime feasibility. Our findings highlight the
importance of uncertainty-aware planning for driver assistance and motivate
future integration of sensor fusion and environment perception modules for
real-time deployment in realistic traffic environments.

</details>


### [239] [Latent Action Pretraining Through World Modeling](https://arxiv.org/abs/2509.18428)
*Bahey Tharwat,Yara Nasser,Ali Abouzeid,Ian Reid*

Main category: cs.RO

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Vision-Language-Action (VLA) models have gained popularity for learning
robotic manipulation tasks that follow language instructions. State-of-the-art
VLAs, such as OpenVLA and $\pi_{0}$, were trained on large-scale, manually
labeled action datasets collected through teleoperation. More recent
approaches, including LAPA and villa-X, introduce latent action representations
that enable unsupervised pretraining on unlabeled datasets by modeling abstract
visual changes between frames. Although these methods have shown strong
results, their large model sizes make deployment in real-world settings
challenging. In this work, we propose LAWM, a model-agnostic framework to
pretrain imitation learning models in a self-supervised way, by learning latent
action representations from unlabeled video data through world modeling. These
videos can be sourced from robot recordings or videos of humans performing
actions with everyday objects. Our framework is designed to be effective for
transferring across tasks, environments, and embodiments. It outperforms models
trained with ground-truth robotics actions and similar pretraining methods on
the LIBERO benchmark and real-world setup, while being significantly more
efficient and practical for real-world settings.

</details>


### [240] [PrioriTouch: Adapting to User Contact Preferences for Whole-Arm Physical Human-Robot Interaction](https://arxiv.org/abs/2509.18447)
*Rishabh Madan,Jiawei Lin,Mahika Goel,Angchen Xie,Xiaoyu Liang,Marcus Lee,Justin Guo,Pranav N. Thakkar,Rohan Banerjee,Jose Barreiros,Kate Tsui,Tom Silver,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: 本文提出了PrioriTouch，一个用于多接触物理人机交互(pHRI)的框架，它能对多个接触点上的控制目标进行排序和执行，以适应用户的个性化接触偏好，尤其适用于护理任务。


<details>
  <summary>Details</summary>
Motivation: 在物理人机交互中，特别是涉及机器人全身与人体的多点同时接触时，识别和满足个体接触偏好非常困难，因为不同身体部位可能产生不兼容的力学要求。在护理等频繁且多样化的接触任务中，这种冲突不可避免，需要进行权衡和优先级排序。

Method: PrioriTouch框架结合了一种新颖的“学习排序”方法与分层操作空间控制。它利用“仿真循环”的推出进行数据高效和安全的探索。此外，通过用户研究获取个性化的舒适阈值并将其整合到框架中。

Result: PrioriTouch在广泛的仿真和真实世界实验中，展示了其适应用户接触偏好、保持任务性能以及提高安全性和舒适度的能力。

Conclusion: PrioriTouch框架有效解决了多接触pHRI中的挑战，通过优先级排序控制目标来适应个性化偏好，从而提高了机器人在护理等场景中的适应性、性能、安全性和舒适度。

Abstract: Physical human-robot interaction (pHRI) requires robots to adapt to
individual contact preferences, such as where and how much force is applied.
Identifying preferences is difficult for a single contact; with whole-arm
interaction involving multiple simultaneous contacts between the robot and
human, the challenge is greater because different body parts can impose
incompatible force requirements. In caregiving tasks, where contact is frequent
and varied, such conflicts are unavoidable. With multiple preferences across
multiple contacts, no single solution can satisfy all objectives--trade-offs
are inherent, making prioritization essential. We present PrioriTouch, a
framework for ranking and executing control objectives across multiple
contacts. PrioriTouch can prioritize from a general collection of controllers,
making it applicable not only to caregiving scenarios such as bed bathing and
dressing but also to broader multi-contact settings. Our method combines a
novel learning-to-rank approach with hierarchical operational space control,
leveraging simulation-in-the-loop rollouts for data-efficient and safe
exploration. We conduct a user study on physical assistance preferences, derive
personalized comfort thresholds, and incorporate them into PrioriTouch. We
evaluate PrioriTouch through extensive simulation and real-world experiments,
demonstrating its ability to adapt to user contact preferences, maintain task
performance, and enhance safety and comfort. Website:
https://emprise.cs.cornell.edu/prioritouch.

</details>


### [241] [Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands](https://arxiv.org/abs/2509.18455)
*Yunshuang Li,Yiyang Ling,Gaurav S. Sukhatme,Daniel Seita*

Main category: cs.RO

TL;DR: 本文提出了Geometry-aware Dexterous Pushing and Pulling (GD2P) 方法，利用灵巧机械手进行非抓取式推拉操作。通过学习基于物体几何形状的预接触手部姿态，实现对多样物体的有效操作，并在真实世界实验中验证了其可扩展性和通用性。


<details>
  <summary>Details</summary>
Motivation: 非抓取式操作（如推拉）能处理难以抓取的物体。现有方法多依赖于平行夹爪或简单工具。灵巧多指机械手提供更丰富的接触模式和多功能性，能为物体提供稳定支撑，弥补非抓取操作动力学建模的难度，因此研究如何利用灵巧手进行非抓取操作具有重要意义。

Method: 该方法将推拉问题框架为合成和学习导致有效操作的预接触灵巧手姿态。具体步骤包括：通过接触引导采样生成多样手部姿态；使用物理模拟过滤这些姿态；训练一个以物体几何形状为条件的扩散模型来预测可行的姿态。在测试时，采样手部姿态并使用标准运动规划器选择和执行推拉动作。

Result: 通过对Allegro手进行了840次真实世界实验，结果表明GD2P为训练灵巧非抓取操作策略提供了一条可扩展的途径。该方法还在LEAP手型上进行了演示，突出了其对不同手部形态的适用性。作者将开源预训练模型和包含2.3k物体、130万手部姿态的数据集。

Conclusion: GD2P提供了一种可扩展且通用的方法，用于通过灵巧机械手进行几何感知的非抓取式推拉操作。该方法通过学习有效的预接触手部姿态，克服了传统方法的局限性，并在多种手型和真实世界场景中展现出优越的性能和广阔的应用前景。

Abstract: Nonprehensile manipulation, such as pushing and pulling, enables robots to
move, align, or reposition objects that may be difficult to grasp due to their
geometry, size, or relationship to the robot or the environment. Much of the
existing work in nonprehensile manipulation relies on parallel-jaw grippers or
tools such as rods and spatulas. In contrast, multi-fingered dexterous hands
offer richer contact modes and versatility for handling diverse objects to
provide stable support over the objects, which compensates for the difficulty
of modeling the dynamics of nonprehensile manipulation. Therefore, we propose
Geometry-aware Dexterous Pushing and Pulling (GD2P) for nonprehensile
manipulation with dexterous robotic hands. We study pushing and pulling by
framing the problem as synthesizing and learning pre-contact dexterous hand
poses that lead to effective manipulation. We generate diverse hand poses via
contact-guided sampling, filter them using physics simulation, and train a
diffusion model conditioned on object geometry to predict viable poses. At test
time, we sample hand poses and use standard motion planners to select and
execute pushing and pulling actions. We perform 840 real-world experiments with
an Allegro Hand, comparing our method to baselines. The results indicate that
GD2P offers a scalable route for training dexterous nonprehensile manipulation
policies. We further demonstrate GD2P on a LEAP Hand, highlighting its
applicability to different hand morphologies. Our pre-trained models and
dataset, including 1.3 million hand poses across 2.3k objects, will be
open-source to facilitate further research. Our project website is available
at: geodex2p.github.io.

</details>


### [242] [A Counterfactual Reasoning Framework for Fault Diagnosis in Robot Perception Systems](https://arxiv.org/abs/2509.18460)
*Haeyoon Han,Mahdi Taheri,Soon-Jo Chung,Fred Y. Hadaegh*

Main category: cs.RO

TL;DR: 该论文提出了一种基于反事实推理的感知系统故障检测与隔离（FDI）框架，利用分析冗余而非物理冗余，并通过主动FDI方法（结合因果多臂老虎机和MCTS）来优化控制输入以提高故障隔离效率。


<details>
  <summary>Details</summary>
Motivation: 感知系统为自主系统提供环境理解，其故障会影响所有下游模块的决策。感知系统故障具有挑战性，常与环境感知上下文相关，且多阶段管道中的错误会传播，因此准确检测和隔离感知故障至关重要。

Method: 该研究采用反事实推理方法构建感知系统FDI框架。它利用分析冗余而非物理冗余，将感知可靠性测试构建为受系统状态和故障情景影响的因果结果。反事实推理生成假设故障下的可靠性测试结果以更新对故障假设的信念。论文推导了被动和主动FDI方法：被动FDI通过信念更新实现；主动FDI被定义为因果多臂老虎机问题，利用蒙特卡洛树搜索（MCTS）结合上置信界（UCB）来寻找最大化“有效信息”（EI）的控制输入，EI量化了控制输入对FDI的信息量。

Result: 该方法在一个机器人探索场景中进行了演示。在该场景中，一个执行基于视觉导航的空间机器人主动调整其姿态以增加EI，并正确隔离了由传感器损坏、动态场景和感知退化引起的故障。

Conclusion: 该论文提出了一种新颖的基于反事实推理的感知系统故障检测与隔离框架，通过结合分析冗余和主动FDI（利用因果多臂老虎机和MCTS优化信息量），能够有效地检测和隔离自主系统中的感知故障，并在实际机器人探索场景中得到了验证。

Abstract: Perception systems provide a rich understanding of the environment for
autonomous systems, shaping decisions in all downstream modules. Hence,
accurate detection and isolation of faults in perception systems is important.
Faults in perception systems pose particular challenges: faults are often tied
to the perceptual context of the environment, and errors in their multi-stage
pipelines can propagate across modules. To address this, we adopt a
counterfactual reasoning approach to propose a framework for fault detection
and isolation (FDI) in perception systems. As opposed to relying on physical
redundancy (i.e., having extra sensors), our approach utilizes analytical
redundancy with counterfactual reasoning to construct perception reliability
tests as causal outcomes influenced by system states and fault scenarios.
Counterfactual reasoning generates reliability test results under hypothesized
faults to update the belief over fault hypotheses. We derive both passive and
active FDI methods. While the passive FDI can be achieved by belief updates,
the active FDI approach is defined as a causal bandit problem, where we utilize
Monte Carlo Tree Search (MCTS) with upper confidence bound (UCB) to find
control inputs that maximize a detection and isolation metric, designated as
Effective Information (EI). The mentioned metric quantifies the informativeness
of control inputs for FDI. We demonstrate the approach in a robot exploration
scenario, where a space robot performing vision-based navigation actively
adjusts its attitude to increase EI and correctly isolate faults caused by
sensor damage, dynamic scenes, and perceptual degradation.

</details>


### [243] [Robotic Skill Diversification via Active Mutation of Reward Functions in Reinforcement Learning During a Liquid Pouring Task](https://arxiv.org/abs/2509.18463)
*Jannick van Buuren,Roberto Giglio,Loris Roveda,Luka Peternel*

Main category: cs.RO

TL;DR: 该研究通过对强化学习中的奖励函数进行故意变异，成功在机器人操作任务中（以倒水为例）生成了多样化的技能变体。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过变异强化学习中的奖励函数，使机器人系统在操作任务中产生多样化的技能，从而超越单一的预期行为。

Method: 开发了一个新的奖励函数变异框架，该框架通过对奖励函数中“准确性”、“时间”和“努力”等关键项的权重施加高斯噪声来实现。奖励函数的设计灵感来源于人类运动控制的成本效益权衡模型。实验在NVIDIA Isaac Sim仿真环境中，使用Franka Emika Panda机械臂和Proximal Policy Optimization (PPO)算法进行，系统地探索了不同变异权重配置对学习策略的影响。

Result: 变异后的奖励函数使机器人学习到的策略展现出广泛的行为范围，不仅包括原始倒水任务执行方式的变化，还衍生出诸如容器边缘清洁、液体混合和浇水等意想不到的新颖技能。

Conclusion: 这种方法为机器人系统在特定任务中进行多样化学习提供了有前景的方向，并有可能为未来的任务衍生出有意义的技能，拓展了机器人的应用潜力。

Abstract: This paper explores how deliberate mutations of reward function in
reinforcement learning can produce diversified skill variations in robotic
manipulation tasks, examined with a liquid pouring use case. To this end, we
developed a new reward function mutation framework that is based on applying
Gaussian noise to the weights of the different terms in the reward function.
Inspired by the cost-benefit tradeoff model from human motor control, we
designed the reward function with the following key terms: accuracy, time, and
effort. The study was performed in a simulation environment created in NVIDIA
Isaac Sim, and the setup included Franka Emika Panda robotic arm holding a
glass with a liquid that needed to be poured into a container. The
reinforcement learning algorithm was based on Proximal Policy Optimization. We
systematically explored how different configurations of mutated weights in the
rewards function would affect the learned policy. The resulting policies
exhibit a wide range of behaviours: from variations in execution of the
originally intended pouring task to novel skills useful for unexpected tasks,
such as container rim cleaning, liquid mixing, and watering. This approach
offers promising directions for robotic systems to perform diversified learning
of specific tasks, while also potentially deriving meaningful skills for future
tasks.

</details>


### [244] [RL-augmented Adaptive Model Predictive Control for Bipedal Locomotion over Challenging Terrain](https://arxiv.org/abs/2509.18466)
*Junnosuke Kamohara,Feiyang Wu,Chinmayee Wamorkar,Seth Hutchinson,Ye Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种RL增强的MPC框架，专为双足机器人在崎岖和湿滑地形上的运动设计，通过RL参数化MPC的关键组件，实现了比传统MPC和RL更强的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 模型预测控制（MPC）在双足运动中有效，但在崎岖和湿滑地形中，由于难以建模地形交互而受限。强化学习（RL）在多变地形上训练鲁棒策略方面表现出色，但缺乏约束满足保证且需要大量奖励塑形。现有的MPC与RL结合的方法主要限于平坦地形或四足机器人，缺乏针对双足机器人在复杂地形上的解决方案。

Method: 本文提出了一种RL增强的MPC框架，专门针对双足机器人在崎岖和湿滑地形上的运动。该方法利用RL对基于单刚体动力学的MPC的三个关键组件进行参数化：系统动力学、摆动腿控制器和步态频率。通过在NVIDIA IsaacLab中对双足机器人进行模拟验证，测试了包括楼梯、垫脚石和低摩擦表面在内的各种地形。

Result: 实验结果表明，与基线MPC和RL相比，本文提出的RL增强MPC框架能够产生显著更具适应性和鲁棒性的行为。

Conclusion: 所提出的RL增强MPC框架有效解决了双足机器人在崎岖和湿滑地形上运动的挑战，通过结合MPC的优点和RL的鲁棒性，显著提高了机器人的适应性和性能。

Abstract: Model predictive control (MPC) has demonstrated effectiveness for humanoid
bipedal locomotion; however, its applicability in challenging environments,
such as rough and slippery terrain, is limited by the difficulty of modeling
terrain interactions. In contrast, reinforcement learning (RL) has achieved
notable success in training robust locomotion policies over diverse terrain,
yet it lacks guarantees of constraint satisfaction and often requires
substantial reward shaping. Recent efforts in combining MPC and RL have shown
promise of taking the best of both worlds, but they are primarily restricted to
flat terrain or quadrupedal robots. In this work, we propose an RL-augmented
MPC framework tailored for bipedal locomotion over rough and slippery terrain.
Our method parametrizes three key components of
single-rigid-body-dynamics-based MPC: system dynamics, swing leg controller,
and gait frequency. We validate our approach through bipedal robot simulations
in NVIDIA IsaacLab across various terrains, including stairs, stepping stones,
and low-friction surfaces. Experimental results demonstrate that our
RL-augmented MPC framework produces significantly more adaptive and robust
behaviors compared to baseline MPC and RL.

</details>


### [245] [Spatial Envelope MPC: High Performance Driving without a Reference](https://arxiv.org/abs/2509.18506)
*Siyuan Yu,Congkai Shen,Yufei Xi,James Dallas,Michael Thompson,John Subosits,Hiroshi Yasuda,Tulga Ersal*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的基于包络线的模型预测控制（MPC）框架，使自动驾驶车辆能够在没有预定义参考的情况下，在各种高难度场景中实现高性能驾驶。


<details>
  <summary>Details</summary>
Motivation: 在高性自动驾驶中，车辆在动态极限下安全运行需要实时规划和控制框架，该框架能够考虑关键车辆动力学和环境约束，因为预定义参考轨迹在这种情况下是次优甚至不可行的。然而，现有的规划和控制框架大多是基于参考的，这限制了它们在这种情况下的性能。

Method: 该研究首先引入了一种计算高效的车辆动力学模型，专为基于优化的控制设计，并提出了一种连续可微的数学公式，精确捕捉整个可行驶包络线。这些创新模型和公式允许将动态可行性和安全约束直接集成到一个统一的规划和控制框架中，从而消除了对预定义参考的需求。通过结合强化学习和优化技术来解决包络线规划（即最大程度地逼近安全可行驶区域）的挑战。

Result: 该框架通过仿真和真实世界实验进行了验证，在赛车、紧急避撞和越野导航等各种任务中表现出高性能。这些结果突显了该框架的可扩展性和在不同场景中的广泛适用性。

Conclusion: 该框架能够让自动驾驶车辆在各种场景下实现高性能驾驶，而无需预设参考，展现出卓越的性能、可扩展性和广泛的适用性。

Abstract: This paper presents a novel envelope based model predictive control (MPC)
framework designed to enable autonomous vehicles to handle high performance
driving across a wide range of scenarios without a predefined reference. In
high performance autonomous driving, safe operation at the vehicle's dynamic
limits requires a real time planning and control framework capable of
accounting for key vehicle dynamics and environmental constraints when
following a predefined reference trajectory is suboptimal or even infeasible.
State of the art planning and control frameworks, however, are predominantly
reference based, which limits their performance in such situations. To address
this gap, this work first introduces a computationally efficient vehicle
dynamics model tailored for optimization based control and a continuously
differentiable mathematical formulation that accurately captures the entire
drivable envelope. This novel model and formulation allow for the direct
integration of dynamic feasibility and safety constraints into a unified
planning and control framework, thereby removing the necessity for predefined
references. The challenge of envelope planning, which refers to maximally
approximating the safe drivable area, is tackled by combining reinforcement
learning with optimization techniques. The framework is validated through both
simulations and real world experiments, demonstrating its high performance
across a variety of tasks, including racing, emergency collision avoidance and
off road navigation. These results highlight the framework's scalability and
broad applicability across a diverse set of scenarios.

</details>


### [246] [LCMF: Lightweight Cross-Modality Mambaformer for Embodied Robotics VQA](https://arxiv.org/abs/2509.18576)
*Zeyi Kang,Liang He,Yanxin Zhang,Zuheng Ming,Kaixing Zhao*

Main category: cs.RO

TL;DR: 本研究提出了一种轻量级LCMF级联注意力框架，通过在Mamba模块中引入多级跨模态参数共享机制，有效融合异构数据并提高计算效率，在资源受限的人机交互场景中表现出强大的多模态决策泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多模态语义学习在具身智能中至关重要，但面临异构数据有效融合和资源受限环境中计算效率的技术挑战。

Method: 本研究提出了轻量级LCMF级联注意力框架。该框架将多级跨模态参数共享机制引入Mamba模块，并结合了交叉注意力（Cross-Attention）和选择性参数共享状态空间模型（SSMs）的优势，以实现异构模态的高效融合和语义互补对齐。

Result: 实验结果显示，LCMF在VQA任务中超越现有基线，准确率达到74.29%；在EQA视频任务中，其性能在大型语言模型代理（LLM Agents）的分布集群中达到有竞争力的中等水平。其轻量化设计使FLOPs比可比较基线平均降低了4.35倍，参数量仅为166.51M（图像-文本）和219M（视频-文本）。

Conclusion: LCMF框架为资源受限场景下的人机交互（HRI）应用提供了一个高效的解决方案，具有强大的多模态决策泛化能力。

Abstract: Multimodal semantic learning plays a critical role in embodied intelligence,
especially when robots perceive their surroundings, understand human
instructions, and make intelligent decisions. However, the field faces
technical challenges such as effective fusion of heterogeneous data and
computational efficiency in resource-constrained environments. To address these
challenges, this study proposes the lightweight LCMF cascaded attention
framework, introducing a multi-level cross-modal parameter sharing mechanism
into the Mamba module. By integrating the advantages of Cross-Attention and
Selective parameter-sharing State Space Models (SSMs), the framework achieves
efficient fusion of heterogeneous modalities and semantic complementary
alignment. Experimental results show that LCMF surpasses existing multimodal
baselines with an accuracy of 74.29% in VQA tasks and achieves competitive
mid-tier performance within the distribution cluster of Large Language Model
Agents (LLM Agents) in EQA video tasks. Its lightweight design achieves a
4.35-fold reduction in FLOPs relative to the average of comparable baselines
while using only 166.51M parameters (image-text) and 219M parameters
(video-text), providing an efficient solution for Human-Robot Interaction (HRI)
applications in resource-constrained scenarios with strong multimodal decision
generalization capabilities.

</details>


### [247] [VLN-Zero: Rapid Exploration and Cache-Enabled Neurosymbolic Vision-Language Planning for Zero-Shot Transfer in Robot Navigation](https://arxiv.org/abs/2509.18592)
*Neel P. Bhatt,Yunhao Yang,Rohan Siva,Pranay Samineni,Daniel Milan,Zhangyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: VLN-Zero是一种两阶段的视觉-语言导航框架，它利用视觉-语言模型（VLM）构建符号场景图，并通过神经符号规划和缓存执行模块实现零样本导航，显著提升了在未知环境中的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖详尽探索或僵化导航策略，在未知环境中难以实现快速适应和泛化，这对于可扩展的真实世界自主性至关重要。

Method: VLN-Zero分为两阶段：1) 探索阶段：利用结构化提示引导VLM进行搜索，构建紧凑的符号场景图。2) 部署阶段：神经符号规划器基于场景图和环境观测生成可执行计划，同时缓存执行模块通过重用先前计算的任务-位置轨迹来加速适应。

Result: VLN-Zero在成功率上比最先进的零样本模型高出2倍，超越了大多数微调基线，并且在多样化环境中以一半的时间和平均少55%的VLM调用次数到达目标位置。

Conclusion: 该框架结合了快速探索、符号推理和缓存执行，克服了现有视觉-语言导航方法的计算效率低下和泛化能力差的问题，实现了在未知环境中鲁棒且可扩展的决策制定。

Abstract: Rapid adaptation in unseen environments is essential for scalable real-world
autonomy, yet existing approaches rely on exhaustive exploration or rigid
navigation policies that fail to generalize. We present VLN-Zero, a two-phase
vision-language navigation framework that leverages vision-language models to
efficiently construct symbolic scene graphs and enable zero-shot neurosymbolic
navigation. In the exploration phase, structured prompts guide VLM-based search
toward informative and diverse trajectories, yielding compact scene graph
representations. In the deployment phase, a neurosymbolic planner reasons over
the scene graph and environmental observations to generate executable plans,
while a cache-enabled execution module accelerates adaptation by reusing
previously computed task-location trajectories. By combining rapid exploration,
symbolic reasoning, and cache-enabled execution, the proposed framework
overcomes the computational inefficiency and poor generalization of prior
vision-language navigation methods, enabling robust and scalable
decision-making in unseen environments. VLN-Zero achieves 2x higher success
rate compared to state-of-the-art zero-shot models, outperforms most fine-tuned
baselines, and reaches goal locations in half the time with 55% fewer VLM calls
on average compared to state-of-the-art models across diverse environments.
Codebase, datasets, and videos for VLN-Zero are available at:
https://vln-zero.github.io/.

</details>


### [248] [Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills](https://arxiv.org/abs/2509.18597)
*Yuan Meng,Zhenguo Sun,Max Fest,Xukun Li,Zhenshan Bing,Alois Knoll*

Main category: cs.RO

TL;DR: 本文提出一个“人在环路”框架，通过将纠正编码为可重用技能，并结合外部记忆和带有提示机制的检索增强生成（RAG），解决了LLM在机器人操作代码生成中存在的噪声、固定原语、有限上下文窗口、长时序任务和泛化性差等问题，显著提高了任务成功率和纠正效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型（LLM）的机器人操作代码生成方法存在诸多问题：输出噪声大、受限于固定原语、上下文窗口有限，难以处理长时序任务。虽然探索了闭环反馈，但纠正知识存储格式不当，限制了泛化并导致灾难性遗忘，凸显了学习可重用技能的需求。此外，纯粹依赖LLM指导的方法在极长时序场景中常常失败，因为LLM在机器人领域推理能力有限，而这些问题对人类来说通常很容易识别。

Method: 为解决这些挑战，本文提出一个“人在环路”（human-in-the-loop）框架。该框架将纠正编码为可重用技能，并由外部记忆和带有提示机制的检索增强生成（RAG）提供支持，以实现技能的动态重用。

Result: 在Ravens、Franka Kitchen、MetaWorld以及真实世界环境中的实验表明，该框架实现了0.93的成功率（比基线高出27%），并将纠正轮次的效率提高了42%。它能稳健地解决“建造房屋”等极长时序任务，这些任务需要规划超过20个基本原语。

Conclusion: 本文提出的“人在环路”框架通过将纠正转化为可重用技能，并辅以外部记忆和RAG机制，有效克服了LLM在机器人操作代码生成中面临的噪声、泛化性差和长时序任务挑战，显著提升了任务成功率、纠正效率和对复杂任务的鲁棒性。

Abstract: Large language models (LLMs)-based code generation for robotic manipulation
has recently shown promise by directly translating human instructions into
executable code, but existing methods remain noisy, constrained by fixed
primitives and limited context windows, and struggle with long-horizon tasks.
While closed-loop feedback has been explored, corrected knowledge is often
stored in improper formats, restricting generalization and causing catastrophic
forgetting, which highlights the need for learning reusable skills. Moreover,
approaches that rely solely on LLM guidance frequently fail in extremely
long-horizon scenarios due to LLMs' limited reasoning capability in the robotic
domain, where such issues are often straightforward for humans to identify. To
address these challenges, we propose a human-in-the-loop framework that encodes
corrections into reusable skills, supported by external memory and
Retrieval-Augmented Generation with a hint mechanism for dynamic reuse.
Experiments on Ravens, Franka Kitchen, and MetaWorld, as well as real-world
settings, show that our framework achieves a 0.93 success rate (up to 27%
higher than baselines) and a 42% efficiency improvement in correction rounds.
It can robustly solve extremely long-horizon tasks such as "build a house",
which requires planning over 20 primitives.

</details>


### [249] [End-to-End Crop Row Navigation via LiDAR-Based Deep Reinforcement Learning](https://arxiv.org/abs/2509.18608)
*Ana Luiza Mineiro,Francisco Affonso,Marcelo Becker*

Main category: cs.RO

TL;DR: 本文提出一个端到端的基于深度强化学习的导航系统，该系统将原始3D LiDAR数据直接映射到控制命令，并在模拟环境中进行训练，以解决冠层下农业环境中的导航挑战。


<details>
  <summary>Details</summary>
Motivation: 冠层下农业环境中的可靠导航面临挑战，主要原因包括GNSS不可靠、行道杂乱以及光照多变。

Method: 该方法采用一个端到端的基于学习的导航系统，直接将原始3D LiDAR数据映射到控制命令。它使用在模拟中完全训练的深度强化学习策略，并包含一个基于体素的下采样策略，将LiDAR输入大小减少95.83%，从而实现高效的策略学习，且不依赖于标注数据集或手动设计的控制接口。

Result: 该策略在模拟中得到验证，在直行种植园中实现了100%的成功率。随着行道曲率的增加（通过不同的正弦频率和振幅测试），性能逐渐下降。

Conclusion: 该研究展示了一个基于模拟训练的端到端深度强化学习系统在冠层下农业导航中的潜力，尤其在直行环境中表现出色，但在处理复杂曲率时性能有待提升。

Abstract: Reliable navigation in under-canopy agricultural environments remains a
challenge due to GNSS unreliability, cluttered rows, and variable lighting. To
address these limitations, we present an end-to-end learning-based navigation
system that maps raw 3D LiDAR data directly to control commands using a deep
reinforcement learning policy trained entirely in simulation. Our method
includes a voxel-based downsampling strategy that reduces LiDAR input size by
95.83%, enabling efficient policy learning without relying on labeled datasets
or manually designed control interfaces. The policy was validated in
simulation, achieving a 100% success rate in straight-row plantations and
showing a gradual decline in performance as row curvature increased, tested
across varying sinusoidal frequencies and amplitudes.

</details>


### [250] [PIE: Perception and Interaction Enhanced End-to-End Motion Planning for Autonomous Driving](https://arxiv.org/abs/2509.18609)
*Chengran Yuan,Zijian Lu,Zhanqi Zhang,Yimin Zhao,Zefan Huang,Shuo Sun,Jiawei Sun,Jiahui Li,Christina Dao Wen Lee,Dongen Li,Marcelo H. Ang Jr*

Main category: cs.RO

TL;DR: PIE是一个端到端运动规划框架，通过集成先进的感知、推理和意图建模，利用双向Mamba融合和推理增强解码器，动态捕捉自车与周围智能体之间的交互，生成高质量的自车轨迹，并在NAVSIM基准上超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 端到端运动规划有望简化复杂的自动驾驶流程，但场景理解和有效的预测决策仍然是其大规模部署的重大障碍。

Method: PIE框架集成了先进的感知、推理和意图建模，以动态捕捉自车与周围智能体之间的交互。它采用了双向Mamba融合来解决相机和激光雷达多模态融合中的数据压缩损失，并引入了一种新颖的推理增强解码器（结合Mamba和Mixture-of-Experts）来促进符合场景的锚点选择和优化自适应轨迹推理。此外，PIE还采用了一个动作-运动交互模块来利用周围智能体的状态预测以完善自车规划。

Result: PIE在NAVSIM基准上进行了全面验证，在未使用任何集成和数据增强技术的情况下，取得了88.9的PDM分数和85.6的EPDM分数，超越了此前最先进方法的性能。定量和定性分析均表明PIE能够可靠地生成可行且高质量的自车轨迹。

Conclusion: PIE框架通过创新的感知、推理和意图建模方法，有效解决了端到端运动规划中的挑战，能够可靠地生成高质量的自车轨迹，并在关键指标上达到了新的SOTA水平。

Abstract: End-to-end motion planning is promising for simplifying complex autonomous
driving pipelines. However, challenges such as scene understanding and
effective prediction for decision-making continue to present substantial
obstacles to its large-scale deployment. In this paper, we present PIE, a
pioneering framework that integrates advanced perception, reasoning, and
intention modeling to dynamically capture interactions between the ego vehicle
and surrounding agents. It incorporates a bidirectional Mamba fusion that
addresses data compression losses in multimodal fusion of camera and LiDAR
inputs, alongside a novel reasoning-enhanced decoder integrating Mamba and
Mixture-of-Experts to facilitate scene-compliant anchor selection and optimize
adaptive trajectory inference. PIE adopts an action-motion interaction module
to effectively utilize state predictions of surrounding agents to refine ego
planning. The proposed framework is thoroughly validated on the NAVSIM
benchmark. PIE, without using any ensemble and data augmentation techniques,
achieves an 88.9 PDM score and 85.6 EPDM score, surpassing the performance of
prior state-of-the-art methods. Comprehensive quantitative and qualitative
analyses demonstrate that PIE is capable of reliably generating feasible and
high-quality ego trajectories.

</details>


### [251] [Distributionally Robust Safe Motion Planning with Contextual Information](https://arxiv.org/abs/2509.18666)
*Kaizer Rahaman,Simran Kumari,Ashish R. Hota*

Main category: cs.RO

TL;DR: 本文提出了一种结合上下文信息的分布鲁棒碰撞避免方法，通过条件核均值嵌入在RKHS中建模不确定性，并在运动规划中实现鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有碰撞避免方法可能未充分利用上下文信息或缺乏对未来轨迹分布不确定性的鲁棒性，导致在复杂场景下效果不佳。

Method: 该方法将障碍物未来轨迹的条件分布（以自我智能体运动为条件）通过条件核均值嵌入算子嵌入到再生核希尔伯特空间（RKHS）中。然后，定义一个模糊集，包含所有其RKHS嵌入与从历史数据学习到的经验条件均值嵌入在一定距离内的分布。最后，将此分布鲁棒碰撞避免约束纳入到自我智能体的滚动时域运动规划公式中。

Result: 仿真结果表明，在多个具有挑战性的场景中，与未包含上下文信息和/或分布鲁棒性的方法相比，所提出的方法在避免碰撞方面更成功。

Conclusion: 通过结合上下文信息和分布鲁棒性，利用条件核均值嵌入在RKHS中建模不确定性，本方法显著提高了碰撞避免的成功率，尤其适用于复杂环境。

Abstract: We present a distributionally robust approach for collision avoidance by
incorporating contextual information. Specifically, we embed the conditional
distribution of future trajectory of the obstacle conditioned on the motion of
the ego agent in a reproducing kernel Hilbert space (RKHS) via the conditional
kernel mean embedding operator. Then, we define an ambiguity set containing all
distributions whose embedding in the RKHS is within a certain distance from the
empirical estimate of conditional mean embedding learnt from past data.
Consequently, a distributionally robust collision avoidance constraint is
formulated, and included in the receding horizon based motion planning
formulation of the ego agent. Simulation results show that the proposed
approach is more successful in avoiding collision compared to approaches that
do not include contextual information and/or distributional robustness in their
formulation in several challenging scenarios.

</details>


### [252] [SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones](https://arxiv.org/abs/2509.18610)
*Maximilian Adang,JunEn Low,Ola Shorinwa,Mac Schwager*

Main category: cs.RO

TL;DR: SINGER是一种基于机载感知和计算的语言引导自主无人机导航系统，通过高斯泼溅模拟器、RRT启发式专家生成数据，并训练轻量级视觉运动策略，实现了卓越的零样本模拟到真实迁移性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉-语言模型在开放词汇机器人策略方面取得了显著进展，但开放词汇自主无人机导航仍是一个未解决的挑战，原因在于缺乏大规模演示数据、无人机稳定所需的实时控制需求以及缺乏可靠的外部姿态估计模块。

Method: SINGER利用三个核心组件来训练鲁棒的开放词汇导航策略：(i) 一个基于高斯泼溅的逼真语言嵌入飞行模拟器，具有最小的模拟到真实差距，用于高效数据生成；(ii) 一个RRT启发式的多轨迹生成专家，用于提供无碰撞导航演示；(iii) 一个轻量级的端到端视觉运动策略，用于实时闭环控制，该策略通过上述演示数据进行训练。所有操作仅使用机载传感器和计算。

Result: 通过广泛的硬件飞行实验，SINGER展示了其策略在未见环境和未见语言条件目标对象上的卓越零样本模拟到真实迁移能力。在约70万至100万个语言条件视觉运动观测-动作对上进行训练并在硬件上部署时，SINGER在平均到达查询目标方面比基于速度控制的语义引导基线高出23.33%，平均保持查询目标在视野中多16.67%，并且碰撞减少10%。

Conclusion: SINGER成功解决了开放世界中语言引导自主无人机导航的挑战，通过创新的模拟器和训练方法，实现了卓越的零样本模拟到真实迁移，并在真实硬件上表现出优于基线的导航性能，减少了碰撞并提高了目标达成率和视野保持率。

Abstract: Large vision-language models have driven remarkable progress in
open-vocabulary robot policies, e.g., generalist robot manipulation policies,
that enable robots to complete complex tasks specified in natural language.
Despite these successes, open-vocabulary autonomous drone navigation remains an
unsolved challenge due to the scarcity of large-scale demonstrations, real-time
control demands of drones for stabilization, and lack of reliable external pose
estimation modules. In this work, we present SINGER for language-guided
autonomous drone navigation in the open world using only onboard sensing and
compute. To train robust, open-vocabulary navigation policies, SINGER leverages
three central components: (i) a photorealistic language-embedded flight
simulator with minimal sim-to-real gap using Gaussian Splatting for efficient
data generation, (ii) an RRT-inspired multi-trajectory generation expert for
collision-free navigation demonstrations, and these are used to train (iii) a
lightweight end-to-end visuomotor policy for real-time closed-loop control.
Through extensive hardware flight experiments, we demonstrate superior
zero-shot sim-to-real transfer of our policy to unseen environments and unseen
language-conditioned goal objects. When trained on ~700k-1M observation action
pairs of language conditioned visuomotor data and deployed on hardware, SINGER
outperforms a velocity-controlled semantic guidance baseline by reaching the
query 23.33% more on average, and maintains the query in the field of view
16.67% more on average, with 10% fewer collisions.

</details>


### [253] [3D Flow Diffusion Policy: Visuomotor Policy Learning via Generating Flow in 3D Space](https://arxiv.org/abs/2509.18676)
*Sangjun Noh,Dongwoo Nam,Kangmin Kim,Geonhyup Lee,Yeonguk Yu,Raeyoung Kang,Kyoobin Lee*

Main category: cs.RO

TL;DR: 本文提出了3D流扩散策略（3D FDP），利用场景级3D流作为中间表示来捕获精细的局部运动线索，从而学习鲁棒且可泛化的视觉运动策略，在模拟和真实机器人任务中均表现出色。


<details>
  <summary>Details</summary>
Motivation: 机器人操作中学习鲁棒且能泛化到多样物体和交互动态的视觉运动策略是一个核心挑战。现有方法常忽视精确和接触密集型操作所需的局部运动线索。

Method: 本文提出了3D流扩散策略（3D FDP），该框架利用场景级3D流作为结构化的中间表示来捕获精细的局部运动线索。它预测采样查询点的时间轨迹，并在统一的扩散架构中根据这些交互感知流生成动作，从而将操作基于局部动态，并能推理更广泛的场景级动作后果。

Result: 在MetaWorld基准测试中，3D FDP在50项任务中取得了最先进的性能，尤其在中等和困难设置下表现突出。在八项真实机器人任务中，它持续优于现有基线，特别是在接触密集和非抓取场景中。

Conclusion: 研究结果表明，3D流是学习可泛化视觉运动策略的强大结构先验，支持开发更鲁棒和多功能的机器人操作能力。

Abstract: Learning robust visuomotor policies that generalize across diverse objects
and interaction dynamics remains a central challenge in robotic manipulation.
Most existing approaches rely on direct observation-to-action mappings or
compress perceptual inputs into global or object-centric features, which often
overlook localized motion cues critical for precise and contact-rich
manipulation. We present 3D Flow Diffusion Policy (3D FDP), a novel framework
that leverages scene-level 3D flow as a structured intermediate representation
to capture fine-grained local motion cues. Our approach predicts the temporal
trajectories of sampled query points and conditions action generation on these
interaction-aware flows, implemented jointly within a unified diffusion
architecture. This design grounds manipulation in localized dynamics while
enabling the policy to reason about broader scene-level consequences of
actions. Extensive experiments on the MetaWorld benchmark show that 3D FDP
achieves state-of-the-art performance across 50 tasks, particularly excelling
on medium and hard settings. Beyond simulation, we validate our method on eight
real-robot tasks, where it consistently outperforms prior baselines in
contact-rich and non-prehensile scenarios. These results highlight 3D flow as a
powerful structural prior for learning generalizable visuomotor policies,
supporting the development of more robust and versatile robotic manipulation.
Robot demonstrations, additional results, and code can be found at
https://sites.google.com/view/3dfdp/home.

</details>


### [254] [The Case for Negative Data: From Crash Reports to Counterfactuals for Reasonable Driving](https://arxiv.org/abs/2509.18626)
*Jay Patrikar,Apoorva Sharma,Sushant Veer,Boyi Li,Sebastian Scherer,Marco Pavone*

Main category: cs.RO

TL;DR: 本文提出一种方法，通过将真实事故报告转换为统一的场景-动作表示，并结合反事实推理，来增强自动驾驶系统在安全边界附近的决策能力和校准性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统主要基于无事故数据训练，在安全性能边界附近缺乏指导。真实的碰撞报告包含了必要的对比证据，但其非结构化、第三人称且与传感器视图关联性差的叙述，使其难以直接利用。

Method: 研究方法包括将碰撞叙述规范化为以自我为中心的语言，并将日志和碰撞数据转换为统一的场景-动作表示，以进行检索。在决策时，系统通过从统一索引中检索相关先例来裁决提议的动作；一个代理反事实扩展会提出合理的替代方案，为每个方案检索先例，并在做出决定前推理不同结果。

Result: 在nuScenes基准测试中，先例检索显著提高了校准性，上下文偏好动作的召回率从24%提高到53%。反事实变体在保持这些增益的同时，在风险临近时能使决策更加清晰。

Conclusion: 通过将碰撞报告整合到统一的场景-动作表示中进行先例检索，并结合反事实推理，可以显著改善自动驾驶系统在安全边界附近的决策能力和校准性，尤其是在高风险情境下。

Abstract: Learning-based autonomous driving systems are trained mostly on incident-free
data, offering little guidance near safety-performance boundaries. Real crash
reports contain precisely the contrastive evidence needed, but they are hard to
use: narratives are unstructured, third-person, and poorly grounded to sensor
views. We address these challenges by normalizing crash narratives to
ego-centric language and converting both logs and crashes into a unified
scene-action representation suitable for retrieval. At decision time, our
system adjudicates proposed actions by retrieving relevant precedents from this
unified index; an agentic counterfactual extension proposes plausible
alternatives, retrieves for each, and reasons across outcomes before deciding.
On a nuScenes benchmark, precedent retrieval substantially improves
calibration, with recall on contextually preferred actions rising from 24% to
53%. The counterfactual variant preserves these gains while sharpening
decisions near risk.

</details>


### [255] [Proactive-reactive detection and mitigation of intermittent faults in robot swarms](https://arxiv.org/abs/2509.19246)
*Sinan Oğuz,Emanuele Garone,Marco Dorigo,Mary Katherine Heinrich*

Main category: cs.RO

TL;DR: 本文提出了一种针对具有持久网络的机器人群间歇性故障的主动-被动策略，利用自组织备份层和多路网络中的分布式共识进行检测和缓解，有效防止故障中断队形控制。


<details>
  <summary>Details</summary>
Motivation: 现有机器人群容错研究主要关注永久性故障而非间歇性故障，因为在自组织临时网络中检测间歇性故障极其困难。自组织神经系统（SoNS）方法允许机器人群自组织持久网络结构，从而简化了间歇性故障的检测问题。

Method: 该方法是一种主动-被动策略，基于自组织备份层和多路网络中的分布式共识：
1. **主动**：在故障发生前，机器人自组织动态备份路径，以适应主网络拓扑和机器人相对位置的变化。
2. **被动**：机器人利用一次性似然比检验比较多路网络中沿不同路径接收到的信息，实现早期故障检测。
3. **缓解**：检测到故障后，通信会以自组织方式暂时重新路由，直到检测到的故障解决。

Result: 该方法在队形控制中出现故障定位数据的代表性场景中得到验证，结果表明：
- 间歇性故障被有效阻止，未中断收敛到期望队形。
- 故障检测准确率高。
- 误报率低。

Conclusion: 所提出的主动-被动策略能够有效检测和缓解具有持久网络的机器人群中的间歇性故障，确保了在故障情况下的鲁棒性收敛和高准确性检测。

Abstract: Intermittent faults are transient errors that sporadically appear and
disappear. Although intermittent faults pose substantial challenges to
reliability and coordination, existing studies of fault tolerance in robot
swarms focus instead on permanent faults. One reason for this is that
intermittent faults are prohibitively difficult to detect in the fully
self-organized ad-hoc networks typical of robot swarms, as their network
topologies are transient and often unpredictable. However, in the recently
introduced self-organizing nervous systems (SoNS) approach, robot swarms are
able to self-organize persistent network structures for the first time, easing
the problem of detecting intermittent faults. To address intermittent faults in
robot swarms that have persistent networks, we propose a novel
proactive-reactive strategy to detection and mitigation, based on
self-organized backup layers and distributed consensus in a multiplex network.
Proactively, the robots self-organize dynamic backup paths before faults occur,
adapting to changes in the primary network topology and the robots' relative
positions. Reactively, robots use one-shot likelihood ratio tests to compare
information received along different paths in the multiplex network, enabling
early fault detection. Upon detection, communication is temporarily rerouted in
a self-organized way, until the detected fault resolves. We validate the
approach in representative scenarios of faulty positional data occurring during
formation control, demonstrating that intermittent faults are prevented from
disrupting convergence to desired formations, with high fault detection
accuracy and low rates of false positives.

</details>


### [256] [Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training](https://arxiv.org/abs/2509.18631)
*Shuo Cheng,Liqian Ma,Zhenyang Chen,Ajay Mandlekar,Caelan Garrett,Danfei Xu*

Main category: cs.RO

TL;DR: 本文提出一个统一的模拟-现实协同训练框架，通过学习领域不变特征和使用最优传输（OT）损失对齐观察-动作联合分布，以少量真实世界演示提升机器人操作策略的现实成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人操作的行为克隆需要大量真实世界演示，但其获取成本高昂。虽然模拟数据提供了可扩展的替代方案，但模拟与现实之间的领域差异阻碍了策略的有效迁移。

Method: 提出一个统一的模拟-现实协同训练框架，主要利用模拟数据，仅需少量真实世界演示。核心在于学习一个领域不变、任务相关的特征空间。通过对齐跨领域的观察和对应动作的联合分布，而非仅对齐观察（边缘分布），来获取更丰富的信号。为此，在协同训练框架中嵌入了受最优传输（OT）启发的损失，并将其扩展到非平衡OT框架以处理模拟数据和真实世界数据之间的不平衡。

Result: 在具有挑战性的操作任务上验证了该方法，结果显示它能有效利用丰富的模拟数据，将真实世界的成功率提高高达30%，甚至能泛化到仅在模拟中出现过的场景。

Conclusion: 所提出的模拟-现实协同训练框架，结合领域不变特征学习和基于最优传输的联合分布对齐，能够以少量真实世界演示有效利用模拟数据，显著提升机器人操作策略在现实世界中的成功率和泛化能力，有效弥合了模拟与现实之间的领域鸿沟。

Abstract: Behavior cloning has shown promise for robot manipulation, but real-world
demonstrations are costly to acquire at scale. While simulated data offers a
scalable alternative, particularly with advances in automated demonstration
generation, transferring policies to the real world is hampered by various
simulation and real domain gaps. In this work, we propose a unified
sim-and-real co-training framework for learning generalizable manipulation
policies that primarily leverages simulation and only requires a few real-world
demonstrations. Central to our approach is learning a domain-invariant,
task-relevant feature space. Our key insight is that aligning the joint
distributions of observations and their corresponding actions across domains
provides a richer signal than aligning observations (marginals) alone. We
achieve this by embedding an Optimal Transport (OT)-inspired loss within the
co-training framework, and extend this to an Unbalanced OT framework to handle
the imbalance between abundant simulation data and limited real-world examples.
We validate our method on challenging manipulation tasks, showing it can
leverage abundant simulation data to achieve up to a 30% improvement in the
real-world success rate and even generalize to scenarios seen only in
simulation.

</details>


### [257] [Number Adaptive Formation Flight Planning via Affine Deformable Guidance in Narrow Environments](https://arxiv.org/abs/2509.18636)
*Yuan Zhou,Jialiang Hou,Guangtong Xu,Fei Gao*

Main category: cs.RO

TL;DR: 本文提出了一种基于可变形虚拟结构（DVS）的无人机编队规划方法，通过连续时空变换，解决了在狭窄环境中无人机数量变化时编队难以收敛的问题，实现了快速编队恢复和环境适应性。


<details>
  <summary>Details</summary>
Motivation: 在狭窄环境中，无人机数量变化时的编队维护会阻碍规划收敛到期望的配置，这是一个亟待解决的挑战。

Method: 1. **DVS与PAAS集成：** 采用可变形虚拟结构（DVS），并通过Lloyd算法进行均匀分区（PA）和匈牙利算法进行分配（AS），即PAAS，以满足群集安全距离并保持不规则编队形状的完整性。 2. **DVS时空轨迹规划：** 利用基于基元的路径搜索和非线性轨迹优化，规划涉及DVS的时空轨迹。该DVS轨迹通过仿射变换实现对无人机数量变化的自适应过渡，并确保对狭窄环境的适应性。 3. **分布式智能体规划：** 每个智能体在DVS内期望的时空位置引导下，进行分布式轨迹规划，同时考虑避碰和动态可行性要求。

Result: 该方法在模拟中能够处理多达15%的无人机加入或离开拥挤环境，并能快速恢复期望的编队形状。与现有先进的编队规划方法相比，本文方法展示了更快的编队恢复能力和环境适应性。实际实验验证了该编队规划方法的有效性和鲁棒性。

Conclusion: 本文提出的基于可变形虚拟结构和PAAS的编队规划方法，通过连续时空变换，能够有效解决无人机数量变化和狭窄环境下的编队维护问题，实现快速编队恢复和优异的环境适应性。

Abstract: Formation maintenance with varying number of drones in narrow environments
hinders the convergence of planning to the desired configurations. To address
this challenge, this paper proposes a formation planning method guided by
Deformable Virtual Structures (DVS) with continuous spatiotemporal
transformation. Firstly, to satisfy swarm safety distance and preserve
formation shape filling integrity for irregular formation geometries, we employ
Lloyd algorithm for uniform $\underline{PA}$rtitioning and Hungarian algorithm
for $\underline{AS}$signment (PAAS) in DVS. Subsequently, a spatiotemporal
trajectory involving DVS is planned using primitive-based path search and
nonlinear trajectory optimization. The DVS trajectory achieves adaptive
transitions with respect to a varying number of drones while ensuring
adaptability to narrow environments through affine transformation. Finally,
each agent conducts distributed trajectory planning guided by desired
spatiotemporal positions within the DVS, while incorporating collision
avoidance and dynamic feasibility requirements. Our method enables up to 15\%
of swarm numbers to join or leave in cluttered environments while rapidly
restoring the desired formation shape in simulation. Compared to cutting-edge
formation planning method, we demonstrate rapid formation recovery capacity and
environmental adaptability. Real-world experiments validate the effectiveness
and resilience of our formation planning method.

</details>


### [258] [Do You Need Proprioceptive States in Visuomotor Policies?](https://arxiv.org/abs/2509.18644)
*Juntu Zhao,Wenbo Lu,Di Zhang,Yufeng Liu,Yushen Liang,Tianluo Zhang,Yifeng Cao,Junyuan Xie,Yingdong Hu,Shengjie Wang,Junliang Guo,Dequan Wang,Yang Gao*

Main category: cs.RO

TL;DR: 本研究提出了一种“无状态策略”，仅依赖视觉观测来预测机器人动作，解决了传统仿人学习策略过度依赖本体感受状态导致空间泛化能力差的问题，并在多项实际任务中显著提高了泛化成功率。


<details>
  <summary>Details</summary>
Motivation: 研究发现，在基于模仿学习的机器人视觉运动策略中，同时使用视觉观测和本体感受状态会导致策略过度依赖本体感受状态输入，进而造成对训练轨迹的过拟合，并导致空间泛化能力差。

Method: 提出“无状态策略”，移除本体感受状态输入，仅根据视觉观测预测动作。该策略在相对末端执行器动作空间中构建，并利用双广角腕部摄像头提供完整的任务相关视觉观测。

Result: 经验结果表明，“无状态策略”比基于状态的策略具有显著更强的空间泛化能力：在抓取放置、叠衬衫和全身操纵等实际任务中，跨多种机器人实体，高度泛化成功率从0%提高到85%，水平泛化成功率从6%提高到64%。此外，该策略还在数据效率和跨实体适应性方面表现出优势。

Conclusion: “无状态策略”通过仅依赖视觉观测，显著提升了机器人操纵任务的空间泛化能力、数据效率和跨实体适应性，使其更具实际部署价值。

Abstract: Imitation-learning-based visuomotor policies have been widely used in robot
manipulation, where both visual observations and proprioceptive states are
typically adopted together for precise control. However, in this study, we find
that this common practice makes the policy overly reliant on the proprioceptive
state input, which causes overfitting to the training trajectories and results
in poor spatial generalization. On the contrary, we propose the State-free
Policy, removing the proprioceptive state input and predicting actions only
conditioned on visual observations. The State-free Policy is built in the
relative end-effector action space, and should ensure the full task-relevant
visual observations, here provided by dual wide-angle wrist cameras. Empirical
results demonstrate that the State-free policy achieves significantly stronger
spatial generalization than the state-based policy: in real-world tasks such as
pick-and-place, challenging shirt-folding, and complex whole-body manipulation,
spanning multiple robot embodiments, the average success rate improves from 0\%
to 85\% in height generalization and from 6\% to 64\% in horizontal
generalization. Furthermore, they also show advantages in data efficiency and
cross-embodiment adaptation, enhancing their practicality for real-world
deployment.

</details>


### [259] [SPiDR: A Simple Approach for Zero-Shot Safety in Sim-to-Real Transfer](https://arxiv.org/abs/2509.18648)
*Yarden As,Chengrui Qu,Benjamin Unger,Dongho Kang,Max van der Hart,Laixi Shi,Stelian Coros,Adam Wierman,Andreas Krause*

Main category: cs.RO

TL;DR: SPiDR提出了一种悲观领域随机化方法，实现了安全且可扩展的仿真到现实迁移，并提供了可证明的安全保证。


<details>
  <summary>Details</summary>
Motivation: 强化学习在实际应用中部署时，安全性是一个主要问题。模拟器训练虽然安全可扩展，但仿真到现实的差距会导致策略在真实世界中无法满足安全约束。现有的鲁棒安全强化学习技术通常与可扩展的训练流程不兼容，而常用的领域随机化方法在实践中又常导致不安全行为。

Method: 本文提出了SPiDR（Sim-to-real via Pessimistic Domain Randomization）算法。它利用领域随机化将仿真到现实差距带来的不确定性融入到安全约束中，使其能够兼容现有的训练流程。

Result: 通过在仿真基准和两个不同的真实世界机器人平台上进行大量实验，SPiDR证明了其在存在仿真到现实差距的情况下，能有效确保安全性，同时保持强大的性能。

Conclusion: SPiDR是一种可扩展的算法，为安全的仿真到现实迁移提供了可证明的保证，并且与现有训练流程高度兼容。

Abstract: Safety remains a major concern for deploying reinforcement learning (RL) in
real-world applications. Simulators provide safe, scalable training
environments, but the inevitable sim-to-real gap introduces additional safety
concerns, as policies must satisfy constraints in real-world conditions that
differ from simulation. To address this challenge, robust safe RL techniques
offer principled methods, but are often incompatible with standard scalable
training pipelines. In contrast, domain randomization, a simple and popular
sim-to-real technique, stands out as a promising alternative, although it often
results in unsafe behaviors in practice. We present SPiDR, short for
Sim-to-real via Pessimistic Domain Randomization -- a scalable algorithm with
provable guarantees for safe sim-to-real transfer. SPiDR uses domain
randomization to incorporate the uncertainty about the sim-to-real gap into the
safety constraints, making it versatile and highly compatible with existing
training pipelines. Through extensive experiments on sim-to-sim benchmarks and
two distinct real-world robotic platforms, we demonstrate that SPiDR
effectively ensures safety despite the sim-to-real gap while maintaining strong
performance.

</details>


### [260] [N2M: Bridging Navigation and Manipulation by Learning Pose Preference from Rollout](https://arxiv.org/abs/2509.18671)
*Kaixin Chai,Hyunjun Lee,Joseph J. Lim*

Main category: cs.RO

TL;DR: N2M是一个过渡模块，它在机器人到达任务区域后，引导其进入对后续操作更优的初始姿态，从而显著提高移动操作任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 在移动操作中，操作策略对初始姿态有强烈偏好，而导航模块仅关注到达任务区域，未考虑下游操作所需的最佳初始姿态，导致导航和操作之间存在错位。

Method: N2M是一个过渡模块，在机器人到达任务区域后，基于自我中心观察引导机器人到更优的初始姿态。其主要特点包括：仅依赖自我中心观察，无需全局或历史信息；实时适应环境变化；具有高视角鲁棒性的可靠预测；广泛适用于不同任务、操作策略和机器人硬件；以及出色的数据效率和泛化能力。

Result: 在PnPCounterToCab任务中，N2M将平均成功率从可达性基线的3%提高到54%。在Toybox Handover任务中，N2M仅用15个数据样本就能在未见过的环境中提供可靠预测，展现了卓越的数据效率和泛化能力。

Conclusion: N2M通过在导航和操作之间引入一个过渡模块，有效解决了初始姿态未对齐的问题，显著提高了移动操作任务的成功率，并表现出高可靠性、广泛适用性、数据效率和泛化能力。

Abstract: In mobile manipulation, the manipulation policy has strong preferences for
initial poses where it is executed. However, the navigation module focuses
solely on reaching the task area, without considering which initial pose is
preferable for downstream manipulation. To address this misalignment, we
introduce N2M, a transition module that guides the robot to a preferable
initial pose after reaching the task area, thereby substantially improving task
success rates. N2M features five key advantages: (1) reliance solely on
ego-centric observation without requiring global or historical information; (2)
real-time adaptation to environmental changes; (3) reliable prediction with
high viewpoint robustness; (4) broad applicability across diverse tasks,
manipulation policies, and robot hardware; and (5) remarkable data efficiency
and generalizability. We demonstrate the effectiveness of N2M through extensive
simulation and real-world experiments. In the PnPCounterToCab task, N2M
improves the averaged success rate from 3% with the reachability-based baseline
to 54%. Furthermore, in the Toybox Handover task, N2M provides reliable
predictions even in unseen environments with only 15 data samples, showing
remarkable data efficiency and generalizability.

</details>


### [261] [Query-Centric Diffusion Policy for Generalizable Robotic Assembly](https://arxiv.org/abs/2509.18686)
*Ziyi Xu,Haohong Lin,Shiqi Liu,Ding Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种名为查询中心扩散策略（QDP）的层次化框架，通过利用包含对象、接触点和技能信息的查询来弥合高层规划和低层控制之间的鸿沟，从而提高了机器人装配任务的精度和成功率。


<details>
  <summary>Details</summary>
Motivation: 机器人装配任务由于部件交互的复杂性和对接触密集环境中噪声扰动的敏感性，对构建通用机器人提出了关键挑战。传统的层次化策略在实践中因高层技能查询与低层执行之间的不匹配而难以实现。

Method: 本文提出了查询中心扩散策略（QDP），这是一个层次化框架。它利用包含对象、接触点和技能信息的查询来连接高层规划和低层控制。QDP引入了一种查询中心机制，用于识别任务相关组件并指导低层策略，同时利用点云观测来提高策略的鲁棒性。

Result: 在FurnitureBench上的模拟和真实世界实验表明，QDP在技能精度和长周期成功率方面均有显著提升。在具有挑战性的插入和拧螺丝任务中，与没有结构化查询的基线相比，QDP的技能成功率提高了50%以上。

Conclusion: QDP通过其查询中心机制有效解决了机器人装配中高层规划与低层控制之间的不匹配问题，显著提高了装配任务的鲁棒性和成功率。

Abstract: The robotic assembly task poses a key challenge in building generalist robots
due to the intrinsic complexity of part interactions and the sensitivity to
noise perturbations in contact-rich settings. The assembly agent is typically
designed in a hierarchical manner: high-level multi-part reasoning and
low-level precise control. However, implementing such a hierarchical policy is
challenging in practice due to the mismatch between high-level skill queries
and low-level execution. To address this, we propose the Query-centric
Diffusion Policy (QDP), a hierarchical framework that bridges high-level
planning and low-level control by utilizing queries comprising objects, contact
points, and skill information. QDP introduces a query-centric mechanism that
identifies task-relevant components and uses them to guide low-level policies,
leveraging point cloud observations to improve the policy's robustness. We
conduct comprehensive experiments on the FurnitureBench in both simulation and
real-world settings, demonstrating improved performance in skill precision and
long-horizon success rate. In the challenging insertion and screwing tasks, QDP
improves the skill-wise success rate by over 50% compared to baselines without
structured queries.

</details>


### [262] [Learning Obstacle Avoidance using Double DQN for Quadcopter Navigation](https://arxiv.org/abs/2509.18734)
*Nishant Doshi,Amey Sutvani,Sanket Gujar*

Main category: cs.RO

TL;DR: 本文提出使用强化学习训练配备深度摄像头的虚拟四旋翼无人机，以在模拟城市环境中进行导航和避障。


<details>
  <summary>Details</summary>
Motivation: 自主飞行器在城市环境中导航面临挑战，包括GPS精度降低、狭窄空间和动态障碍物，使路径规划复杂化。因此，需要开发一种利用机载深度传感器信息进行避障的能力。

Method: 提出一种基于强化学习的方法，训练一个配备深度摄像头的虚拟四旋翼机器人代理，使其在模拟城市环境中导航。

Result: 本文提出了一种方法，但抽象中尚未提供具体的实验结果。

Conclusion: 本文旨在通过强化学习使虚拟四旋翼无人机在模拟城市环境中，利用深度摄像头信息实现可靠的导航和有效的避障。

Abstract: One of the challenges faced by Autonomous Aerial Vehicles is reliable
navigation through urban environments. Factors like reduction in precision of
Global Positioning System (GPS), narrow spaces and dynamically moving obstacles
make the path planning of an aerial robot a complicated task. One of the skills
required for the agent to effectively navigate through such an environment is
to develop an ability to avoid collisions using information from onboard depth
sensors. In this paper, we propose Reinforcement Learning of a virtual
quadcopter robot agent equipped with a Depth Camera to navigate through a
simulated urban environment.

</details>


### [263] [MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning](https://arxiv.org/abs/2509.18757)
*Omar Rayyan,John Abanes,Mahmoud Hafez,Anthony Tzes,Fares Abu-Dakka*

Main category: cs.RO

TL;DR: MV-UMI框架通过结合第三人称视角与第一人称视角，克服了手持式抓手在数据采集中场景上下文不足的限制，显著提升了模仿学习在机器人操作任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 模仿学习依赖高质量多样化数据集，但其收集成本高昂且通常受限于特定机器人形态。手持式抓手作为一种直观且可扩展的数据收集方式，其第一人称视角腕部摄像头常限制了对足够场景上下文的捕获，影响了人机演示与机器人部署之间的领域迁移。

Method: 本文提出了MV-UMI（Multi-View Universal Manipulation Interface）框架。该框架将第三人称视角与手持抓手的自我中心（第一人称）摄像头视角相结合，以捕获更丰富的场景上下文。

Result: 实验结果（包括消融研究）表明，MV-UMI框架在需要广泛场景理解的子任务中，跨3个任务的性能平均提高了约47%。这证实了该方法在扩展手持抓手系统可学习操作任务范围方面的有效性。

Conclusion: MV-UMI框架通过多视角集成，成功克服了手持抓手数据收集的场景上下文限制，有效扩展了可学习操作任务的范围，同时保持了此类系统固有的跨形态优势。

Abstract: Recent advances in imitation learning have shown great promise for developing
robust robot manipulation policies from demonstrations. However, this promise
is contingent on the availability of diverse, high-quality datasets, which are
not only challenging and costly to collect but are often constrained to a
specific robot embodiment. Portable handheld grippers have recently emerged as
intuitive and scalable alternatives to traditional robotic teleoperation
methods for data collection. However, their reliance solely on first-person
view wrist-mounted cameras often creates limitations in capturing sufficient
scene contexts. In this paper, we present MV-UMI (Multi-View Universal
Manipulation Interface), a framework that integrates a third-person perspective
with the egocentric camera to overcome this limitation. This integration
mitigates domain shifts between human demonstration and robot deployment,
preserving the cross-embodiment advantages of handheld data-collection devices.
Our experimental results, including an ablation study, demonstrate that our
MV-UMI framework improves performance in sub-tasks requiring broad scene
understanding by approximately 47% across 3 tasks, confirming the effectiveness
of our approach in expanding the range of feasible manipulation tasks that can
be learned using handheld gripper systems, without compromising the
cross-embodiment advantages inherent to such systems.

</details>


### [264] [VGGT-DP: Generalizable Robot Control via Vision Foundation Models](https://arxiv.org/abs/2509.18778)
*Shijia Ge,Yinxin Zhang,Shuzhao Xie,Weixiang Zhang,Mingcai Zhou,Zhi Wang*

Main category: cs.RO

TL;DR: 本文提出VGGT-DP，一个将预训练3D感知模型的几何先验与本体感觉反馈相结合的视觉运动策略框架，通过优化视觉编码器和引入高效机制，显著提升了机器人模仿学习的精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉模仿学习方法主要侧重于策略设计，但往往忽略了视觉编码器的结构和容量，这限制了机器人的空间理解能力和泛化性。

Method: 本文提出了VGGT-DP框架，它：1) 采用视觉几何基础Transformer (VGGT) 作为视觉编码器；2) 整合了来自预训练3D感知模型的几何先验与本体感觉反馈；3) 引入了本体感觉引导的视觉学习策略，以对齐感知与机器人内部状态；4) 设计了帧级token重用机制以减少推理延迟；5) 应用了随机token剪枝以增强策略鲁棒性并减少过拟合。

Result: 在具有挑战性的MetaWorld任务上的实验表明，VGGT-DP显著优于DP和DP3等强基线模型，尤其在对精度要求高和长时程的场景中表现突出。

Conclusion: VGGT-DP通过整合几何先验和本体感觉反馈，并优化视觉编码器和推理效率，有效提升了机器人在模仿学习任务中的空间理解、闭环控制、鲁棒性和泛化能力，尤其适用于高精度和长时程操作。

Abstract: Visual imitation learning frameworks allow robots to learn manipulation
skills from expert demonstrations. While existing approaches mainly focus on
policy design, they often neglect the structure and capacity of visual
encoders, limiting spatial understanding and generalization. Inspired by
biological vision systems, which rely on both visual and proprioceptive cues
for robust control, we propose VGGT-DP, a visuomotor policy framework that
integrates geometric priors from a pretrained 3D perception model with
proprioceptive feedback. We adopt the Visual Geometry Grounded Transformer
(VGGT) as the visual encoder and introduce a proprioception-guided visual
learning strategy to align perception with internal robot states, improving
spatial grounding and closed-loop control. To reduce inference latency, we
design a frame-wise token reuse mechanism that compacts multi-view tokens into
an efficient spatial representation. We further apply random token pruning to
enhance policy robustness and reduce overfitting. Experiments on challenging
MetaWorld tasks show that VGGT-DP significantly outperforms strong baselines
such as DP and DP3, particularly in precision-critical and long-horizon
scenarios.

</details>


### [265] [Human-Interpretable Uncertainty Explanations for Point Cloud Registration](https://arxiv.org/abs/2509.18786)
*Johannes A. Gaus,Loris Schneider,Yitian Shi,Jongseok Lee,Rania Rayyes,Rudolph Triebel*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的高斯过程概念归因（GP-CA）方法，用于解决点云配准中由于传感器噪声、姿态估计误差和部分重叠引起的固有不确定性。GP-CA不仅量化并解释了不确定性来源，还利用主动学习发现新的不确定性。该方法在多个数据集和实际机器人实验中表现出优于现有技术的运行时间、样本效率和准确性，显著提高了机器人感知的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在点云配准问题中，诸如ICP等知名方法在面临传感器噪声、姿态估计误差和因遮挡导致的部分重叠等不确定性时表现不佳。这促使研究人员开发一种能够有效处理和解释这些不确定性的新方法。

Method: 本文开发了一种名为高斯过程概念归因（GP-CA）的新方法。该方法不仅量化了配准不确定性，还通过将其归因于配准问题中已知的误差来源来解释不确定性。此外，GP-CA利用主动学习通过查询信息实例来发现野外中新的不确定性来源。

Result: GP-CA在三个公开数据集和实际机器人实验中得到了验证。广泛的消融实验证实了其设计选择。该方法在运行时间、主动学习的高样本效率和高精度方面均优于其他最先进的方法。实际世界的实验清楚地证明了其适用性，并且GP-CA能够实现有效的故障恢复行为，从而产生更鲁棒的机器人感知。

Conclusion: GP-CA是一种有效且鲁棒的点云配准方法，它通过量化和解释不确定性，并利用主动学习发现新的不确定性来源，显著提高了配准的准确性和效率。其在实际机器人应用中的成功展示了其在增强机器人感知鲁棒性方面的巨大潜力，特别是在故障恢复方面。

Abstract: In this paper, we address the point cloud registration problem, where
well-known methods like ICP fail under uncertainty arising from sensor noise,
pose-estimation errors, and partial overlap due to occlusion. We develop a
novel approach, Gaussian Process Concept Attribution (GP-CA), which not only
quantifies registration uncertainty but also explains it by attributing
uncertainty to well-known sources of errors in registration problems. Our
approach leverages active learning to discover new uncertainty sources in the
wild by querying informative instances. We validate GP-CA on three publicly
available datasets and in our real-world robot experiment. Extensive ablations
substantiate our design choices. Our approach outperforms other
state-of-the-art methods in terms of runtime, high sample-efficiency with
active learning, and high accuracy. Our real-world experiment clearly
demonstrates its applicability. Our video also demonstrates that GP-CA enables
effective failure-recovery behaviors, yielding more robust robotic perception.

</details>


### [266] [Application Management in C-ITS: Orchestrating Demand-Driven Deployments and Reconfigurations](https://arxiv.org/abs/2509.18793)
*Lukas Zanger,Bastian Lampe,Lennart Reiher,Lutz Eckstein*

Main category: cs.RO

TL;DR: 本文提出了一种基于Kubernetes和ROS 2的需求驱动应用管理方法，用于解决协作式智能交通系统（C-ITS）中微服务编排的挑战，实现自动化部署、配置和扩展，以提高资源效率。


<details>
  <summary>Details</summary>
Motivation: 随着车辆自动化和互联程度的提高，C-ITS中云原生技术（如微服务和容器编排）的重要性日益增加。然而，在大规模C-ITS中编排应用面临独特挑战，主要源于环境的动态性和对高效资源利用的需求。

Method: 本文提出了一种需求驱动的应用管理方法，利用云原生技术，特别是Kubernetes，并结合机器人操作系统（ROS 2）。该方法根据C-ITS中不同实体的需求，自动化微服务的部署、重新配置、更新、升级和扩展等过程。它通过一个基于Kubernetes和ROS 2构建的应用管理框架，动态协调不断变化和新的需求。

Result: 该方法能够按需执行应用管理过程，从而减少计算资源消耗和网络流量。它能够动态处理不断变化和新的需求。研究人员在C-ITS的集体环境感知用例中展示了该框架的运行效果，并公开了原型框架的源代码。

Conclusion: 本文成功地提出了一个基于Kubernetes和ROS 2的需求驱动应用管理框架，有效应对了C-ITS中动态环境下的应用编排挑战，实现了微服务的自动化管理和高效资源利用。

Abstract: Vehicles are becoming increasingly automated and interconnected, enabling the
formation of cooperative intelligent transport systems (C-ITS) and the use of
offboard services. As a result, cloud-native techniques, such as microservices
and container orchestration, play an increasingly important role in their
operation. However, orchestrating applications in a large-scale C-ITS poses
unique challenges due to the dynamic nature of the environment and the need for
efficient resource utilization. In this paper, we present a demand-driven
application management approach that leverages cloud-native techniques -
specifically Kubernetes - to address these challenges. Taking into account the
demands originating from different entities within the C-ITS, the approach
enables the automation of processes, such as deployment, reconfiguration,
update, upgrade, and scaling of microservices. Executing these processes on
demand can, for example, reduce computing resource consumption and network
traffic. A demand may include a request for provisioning an external supporting
service, such as a collective environment model. The approach handles changing
and new demands by dynamically reconciling them through our proposed
application management framework built on Kubernetes and the Robot Operating
System (ROS 2). We demonstrate the operation of our framework in the C-ITS use
case of collective environment perception and make the source code of the
prototypical framework publicly available at
https://github.com/ika-rwth-aachen/application_manager .

</details>


### [267] [DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation](https://arxiv.org/abs/2509.18830)
*Suzannah Wistreich,Baiyu Shi,Stephen Tian,Samuel Clarke,Michael Nath,Chengyi Xu,Zhenan Bao,Jiajun Wu*

Main category: cs.RO

TL;DR: 本文提出DexSkin，一种柔软、可形变的电容式电子皮肤，能实现灵敏、局部化、可校准的触觉传感，并适用于各种几何形状，显著提升机器人学习复杂操作任务的能力。


<details>
  <summary>Details</summary>
Motivation: 为灵巧的机器人操作系统复制人类皮肤丰富的触觉感知能力，以定位大面积和异形区域的接触事件，是一个长期存在的挑战。

Method: 引入DexSkin，一种柔软、可形变的电容式电子皮肤，可定制以适应不同几何形状。通过在平行爪夹持器手指上安装DexSkin，覆盖几乎整个手指表面，实现触觉感知。在学习演示框架下，评估DexSkin在学习需要手指整个表面感知覆盖的复杂操作任务（如手内物体重新定向、将橡皮筋缠绕在盒子上）中的能力。展示DexSkin的可校准性，以实现传感器实例间的模型迁移，并证明其适用于真实机器人的在线强化学习。

Result: DexSkin实现了灵敏、局部化、可校准的触觉感知。它能有效学习需要手指整个表面感知覆盖的复杂操作任务。DexSkin可以校准以实现传感器实例间的模型迁移，并适用于真实机器人的在线强化学习。

Conclusion: DexSkin非常适合并实用，能够支持机器人学习现实世界中接触丰富的操作任务。

Abstract: Human skin provides a rich tactile sensing stream, localizing intentional and
unintentional contact events over a large and contoured region. Replicating
these tactile sensing capabilities for dexterous robotic manipulation systems
remains a longstanding challenge. In this work, we take a step towards this
goal by introducing DexSkin. DexSkin is a soft, conformable capacitive
electronic skin that enables sensitive, localized, and calibratable tactile
sensing, and can be tailored to varying geometries. We demonstrate its efficacy
for learning downstream robotic manipulation by sensorizing a pair of parallel
jaw gripper fingers, providing tactile coverage across almost the entire finger
surfaces. We empirically evaluate DexSkin's capabilities in learning
challenging manipulation tasks that require sensing coverage across the entire
surface of the fingers, such as reorienting objects in hand and wrapping
elastic bands around boxes, in a learning-from-demonstration framework. We then
show that, critically for data-driven approaches, DexSkin can be calibrated to
enable model transfer across sensor instances, and demonstrate its
applicability to online reinforcement learning on real robots. Our results
highlight DexSkin's suitability and practicality for learning real-world,
contact-rich manipulation. Please see our project webpage for videos and
visualizations: https://dex-skin.github.io/.

</details>


### [268] [Bi-VLA: Bilateral Control-Based Imitation Learning via Vision-Language Fusion for Action Generation](https://arxiv.org/abs/2509.18865)
*Masato Kobayashi,Thanpimon Buamanee*

Main category: cs.RO

TL;DR: 本文提出Bi-VLA框架，通过视觉-语言融合将双边控制的模仿学习扩展到单模型处理多任务，解决了传统方法的任务特异性限制。


<details>
  <summary>Details</summary>
Motivation: 传统的双边控制方法虽然能实现精确操作，但需要针对特定任务构建模型，通用性受限，无法在一个模型中处理多个任务。

Method: Bi-VLA利用领导者-跟随者双边控制中的机器人关节角度、速度和扭矩数据，并结合SigLIP提取的视觉特征以及通过FiLM融合的自然语言指令，实现视觉-语言融合。

Result: Bi-VLA成功解释了视觉-语言组合，并在需要语言提示和仅通过视觉可区分的两类任务上进行了验证。与传统双边控制模仿学习相比，Bi-VLA显著提高了任务成功率。

Conclusion: Bi-VLA解决了现有双边方法单任务的局限性，并提供了经验证据，表明结合视觉和语言能显著增强多任务处理的通用性和有效性。

Abstract: We propose Bilateral Control-Based Imitation Learning via Vision-Language
Fusion for Action Generation (Bi-VLA), a novel framework that extends bilateral
control-based imitation learning to handle more than one task within a single
model. Conventional bilateral control methods exploit joint angle, velocity,
torque, and vision for precise manipulation but require task-specific models,
limiting their generality. Bi-VLA overcomes this limitation by utilizing robot
joint angle, velocity, and torque data from leader-follower bilateral control
with visual features and natural language instructions through SigLIP and
FiLM-based fusion. We validated Bi-VLA on two task types: one requiring
supplementary language cues and another distinguishable solely by vision.
Real-robot experiments showed that Bi-VLA successfully interprets
vision-language combinations and improves task success rates compared to
conventional bilateral control-based imitation learning. Our Bi-VLA addresses
the single-task limitation of prior bilateral approaches and provides empirical
evidence that combining vision and language significantly enhances versatility.
Experimental results validate the effectiveness of Bi-VLA in real-world tasks.
For additional material, please visit the website:
https://mertcookimg.github.io/bi-vla/

</details>


### [269] [Lang2Morph: Language-Driven Morphological Design of Robotic Hands](https://arxiv.org/abs/2509.18937)
*Yanyuan Qiao,Kieran Gilday,Yutong Xie,Josie Hughes*

Main category: cs.RO

TL;DR: Lang2Morph是一个由语言驱动的机器人手部设计流程，它利用大型语言模型（LLMs）将自然语言任务描述转换为可3D打印的、任务特定的手部形态参数。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人手部形态设计方法依赖专家启发式、手动调整或计算密集型优化，且很少针对灵巧型手部。大型语言模型（LLMs）在人类-物体交互和生成能力方面的广泛知识为零样本设计推理提供了一种有前景的替代方案。

Method: Lang2Morph流程包括两部分：(i) 形态设计：LLMs将任务映射到语义标签、结构语法和OPH兼容参数；(ii) 选择与优化：评估设计候选方案的语义对齐和尺寸兼容性，并根据需要应用LLM引导的优化。

Result: Lang2Morph在各种任务中进行了评估，结果表明该方法能够生成多样化且与任务相关的形态。

Conclusion: 这是首次尝试开发一个基于LLM的框架，用于任务条件下的机器人手部设计。

Abstract: Designing robotic hand morphologies for diverse manipulation tasks requires
balancing dexterity, manufacturability, and task-specific functionality. While
open-source frameworks and parametric tools support reproducible design, they
still rely on expert heuristics and manual tuning. Automated methods using
optimization are often compute-intensive, simulation-dependent, and rarely
target dexterous hands. Large language models (LLMs), with their broad
knowledge of human-object interactions and strong generative capabilities,
offer a promising alternative for zero-shot design reasoning. In this paper, we
present Lang2Morph, a language-driven pipeline for robotic hand design. It uses
LLMs to translate natural-language task descriptions into symbolic structures
and OPH-compatible parameters, enabling 3D-printable task-specific
morphologies. The pipeline consists of: (i) Morphology Design, which maps tasks
into semantic tags, structural grammars, and OPH-compatible parameters; and
(ii) Selection and Refinement, which evaluates design candidates based on
semantic alignment and size compatibility, and optionally applies LLM-guided
refinement when needed. We evaluate Lang2Morph across varied tasks, and results
show that our approach can generate diverse, task-relevant morphologies. To our
knowledge, this is the first attempt to develop an LLM-based framework for
task-conditioned robotic hand design.

</details>


### [270] [Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations](https://arxiv.org/abs/2509.18953)
*Hanqing Liu,Jiahuan Long,Junqi Wu,Jiacheng Hou,Huili Tang,Tingsong Jiang,Weien Zhou,Wen Yao*

Main category: cs.RO

TL;DR: 该论文提出了Eva-VLA框架，首次系统性地评估了视觉-语言-动作（VLA）模型在真实物理变化下的鲁棒性，发现现有模型在各种变化下均表现出高失败率，揭示了从实验室到实际部署的关键差距。


<details>
  <summary>Details</summary>
Motivation: VLA模型在机器人操作方面前景广阔，但其对真实世界物理变化的鲁棒性尚未得到充分探索。现有研究缺乏系统性评估方法，且难以在不产生高昂数据收集成本的情况下发现最坏情况。

Method: 该研究提出了Eva-VLA统一框架，将离散的物理变化转化为连续优化问题。为系统表征变化，将其分解为物体3D变换、光照变化和对抗性补丁。为高效发现最坏情况，引入了连续黑盒优化框架，将离散物理变化转化为参数优化。

Result: 对最先进的OpenVLA模型进行广泛实验发现，所有类型的变化都导致超过60%的故障率。其中，物体变换在长周期任务中导致高达97.8%的故障率，揭示了VLA模型在受控实验室成功与不可预测部署就绪之间存在严重差距。

Conclusion: 研究结果暴露了VLA模型在真实世界部署中的关键漏洞。Eva-VLA框架为增强基于VLA的机器人操作模型以应对实际部署挑战提供了一条实用途径。

Abstract: Vision-Language-Action (VLA) models have emerged as promising solutions for
robotic manipulation, yet their robustness to real-world physical variations
remains critically underexplored. To bridge this gap, we propose Eva-VLA, the
first unified framework that systematically evaluates the robustness of VLA
models by transforming discrete physical variations into continuous
optimization problems. However, comprehensively assessing VLA robustness
presents two key challenges: (1) how to systematically characterize diverse
physical variations encountered in real-world deployments while maintaining
evaluation reproducibility, and (2) how to discover worst-case scenarios
without prohibitive real-world data collection costs efficiently. To address
the first challenge, we decompose real-world variations into three critical
domains: object 3D transformations that affect spatial reasoning, illumination
variations that challenge visual perception, and adversarial patches that
disrupt scene understanding. For the second challenge, we introduce a
continuous black-box optimization framework that transforms discrete physical
variations into parameter optimization, enabling systematic exploration of
worst-case scenarios. Extensive experiments on state-of-the-art OpenVLA models
across multiple benchmarks reveal alarming vulnerabilities: all variation types
trigger failure rates exceeding 60%, with object transformations causing up to
97.8% failure in long-horizon tasks. Our findings expose critical gaps between
controlled laboratory success and unpredictable deployment readiness, while the
Eva-VLA framework provides a practical pathway for hardening VLA-based robotic
manipulation models against real-world deployment challenges.

</details>


### [271] [Towards Robust LiDAR Localization: Deep Learning-based Uncertainty Estimation](https://arxiv.org/abs/2509.18954)
*Minoo Dolatabadi,Fardin Ayar,Ehsan Javanmardi,Manabu Tsukada,Mahdi Javanmardi*

Main category: cs.RO

TL;DR: 本文提出了一种数据驱动的深度学习框架，用于在匹配前和没有参考地图的情况下，估计激光雷达里程计（ICP）的配准误差协方差，从而提高定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的ICP算法在无特征或动态场景中容易出错，导致姿态估计不准确。现有的不确定性预测方法依赖于手工模型、简化假设或预建地图，且通常只提供二元分类，无法准确建模不确定性。因此，需要一种更鲁棒、更准确的方法来预测ICP的误差不确定性。

Method: 本文提出了一种数据驱动的深度学习框架，该框架能够在ICP匹配之前，甚至在没有参考地图的情况下，估计每次激光雷达扫描的可靠6自由度误差协方差。这种方法使得ICP能够无缝集成到卡尔曼滤波中，以增强定位精度和鲁棒性。

Result: 在KITTI数据集上进行的广泛实验表明，该方法能够准确预测协方差。当应用于使用预建地图的定位或SLAM时，它能有效减少定位误差并提高系统鲁棒性。

Conclusion: 所提出的数据驱动框架通过在匹配前准确估计ICP的误差协方差，显著提升了激光雷达定位和SLAM的精度与鲁棒性，克服了传统方法和现有深度学习方法的局限性。

Abstract: LiDAR-based localization and SLAM often rely on iterative matching
algorithms, particularly the Iterative Closest Point (ICP) algorithm, to align
sensor data with pre-existing maps or previous scans. However, ICP is prone to
errors in featureless environments and dynamic scenes, leading to inaccurate
pose estimation. Accurately predicting the uncertainty associated with ICP is
crucial for robust state estimation but remains challenging, as existing
approaches often rely on handcrafted models or simplified assumptions.
Moreover, a few deep learning-based methods for localizability estimation
either depend on a pre-built map, which may not always be available, or provide
a binary classification of localizable versus non-localizable, which fails to
properly model uncertainty. In this work, we propose a data-driven framework
that leverages deep learning to estimate the registration error covariance of
ICP before matching, even in the absence of a reference map. By associating
each LiDAR scan with a reliable 6-DoF error covariance estimate, our method
enables seamless integration of ICP within Kalman filtering, enhancing
localization accuracy and robustness. Extensive experiments on the KITTI
dataset demonstrate the effectiveness of our approach, showing that it
accurately predicts covariance and, when applied to localization using a
pre-built map or SLAM, reduces localization errors and improves robustness.

</details>


### [272] [Category-Level Object Shape and Pose Estimation in Less Than a Millisecond](https://arxiv.org/abs/2509.18979)
*Lorenzo Shaikewitz,Tim Nguyen,Luca Carlone*

Main category: cs.RO

TL;DR: 本文提出了一种快速的局部求解器，用于基于RGB-D图像和类别级先验知识进行物体形状和姿态估计。该方法利用语义关键点、线性主动形状模型和最大后验优化，通过自洽场迭代高效求解，并提供全局最优性证书。


<details>
  <summary>Details</summary>
Motivation: 物体形状和姿态估计是机器人领域的基础问题，支持操作、场景理解和导航等任务。因此，需要一个快速、高效且能利用类别级先验信息来解决此问题的方案。

Method: 该方法首先使用学习到的前端从RGB-D图像中检测目标物体上的稀疏、类别级语义关键点。物体未知形状通过线性主动形状模型表示。然后，构建一个最大后验（MAP）优化问题，以同时求解物体的位置、方向（使用单位四元数）和形状。其主要贡献在于使用自洽场迭代高效求解此问题，每次迭代只需计算一个4x4矩阵并找到其最小特征值-向量对。通过求解相应的拉格朗日乘子线性系统，可获得简单的全局最优性证书。

Result: 该求解器的一次迭代耗时约100微秒，支持快速离群点剔除。该方法在合成数据、两个公共数据集和无人机跟踪场景等多种真实世界环境中进行了测试，并取得了良好效果。相关代码已开源。

Conclusion: 本文提出了一种快速、高效且具备全局最优性证书的物体形状和姿态估计方法。该方法利用类别级先验信息和RGB-D数据，通过创新的自洽场迭代优化，为机器人领域的关键任务提供了强大的支持。

Abstract: Object shape and pose estimation is a foundational robotics problem,
supporting tasks from manipulation to scene understanding and navigation. We
present a fast local solver for shape and pose estimation which requires only
category-level object priors and admits an efficient certificate of global
optimality. Given an RGB-D image of an object, we use a learned front-end to
detect sparse, category-level semantic keypoints on the target object. We
represent the target object's unknown shape using a linear active shape model
and pose a maximum a posteriori optimization problem to solve for position,
orientation, and shape simultaneously. Expressed in unit quaternions, this
problem admits first-order optimality conditions in the form of an eigenvalue
problem with eigenvector nonlinearities. Our primary contribution is to solve
this problem efficiently with self-consistent field iteration, which only
requires computing a 4-by-4 matrix and finding its minimum eigenvalue-vector
pair at each iterate. Solving a linear system for the corresponding Lagrange
multipliers gives a simple global optimality certificate. One iteration of our
solver runs in about 100 microseconds, enabling fast outlier rejection. We test
our method on synthetic data and a variety of real-world settings, including
two public datasets and a drone tracking scenario. Code is released at
https://github.com/MIT-SPARK/Fast-ShapeAndPose.

</details>


### [273] [Pure Vision Language Action (VLA) Models: A Comprehensive Survey](https://arxiv.org/abs/2509.19012)
*Dapeng Zhang,Jin Sun,Chenghui Hu,Xiaoyan Wu,Zhenlong Yuan,Rui Zhou,Fei Shen,Qingguo Zhou*

Main category: cs.RO

TL;DR: 本综述全面回顾了视觉-语言-动作 (VLA) 模型，提供了清晰的分类法、方法分析、应用场景、基础资源，并提出了未来挑战和方向。


<details>
  <summary>Details</summary>
Motivation: VLA模型的出现标志着机器人控制从传统策略到通用机器人的范式转变，将VLM从被动序列生成器转变为主动智能体。因此，需要一个清晰的分类法和系统全面的综述来理解和推动这一快速发展的领域。

Method: 本研究通过对三百多项近期研究的综合分析，对VLA方法进行了分类（自回归、扩散、强化、混合和专业化范式），详细考察了它们的动机、核心策略和实现。此外，还分析了VLA在不同场景的应用，并介绍了基础数据集、基准和仿真平台。

Result: 本综述提供了VLA方法的清晰分类和系统全面的回顾，分析了其在不同场景中的应用，并详细阐述了各类方法的动机、核心策略和实现。同时，介绍了该领域的基础数据集、基准和仿真平台，并综合了大量最新研究的见解。

Conclusion: 本综述在总结当前VLA发展现状的基础上，提出了VLA模型和通用机器人领域面临的关键挑战和未来的研究方向，为可扩展、通用VLA方法的发展指明了道路。

Abstract: The emergence of Vision Language Action (VLA) models marks a paradigm shift
from traditional policy-based control to generalized robotics, reframing Vision
Language Models (VLMs) from passive sequence generators into active agents for
manipulation and decision-making in complex, dynamic environments. This survey
delves into advanced VLA methods, aiming to provide a clear taxonomy and a
systematic, comprehensive review of existing research. It presents a
comprehensive analysis of VLA applications across different scenarios and
classifies VLA approaches into several paradigms: autoregression-based,
diffusion-based, reinforcement-based, hybrid, and specialized methods; while
examining their motivations, core strategies, and implementations in detail. In
addition, foundational datasets, benchmarks, and simulation platforms are
introduced. Building on the current VLA landscape, the review further proposes
perspectives on key challenges and future directions to advance research in VLA
models and generalizable robotics. By synthesizing insights from over three
hundred recent studies, this survey maps the contours of this rapidly evolving
field and highlights the opportunities and challenges that will shape the
development of scalable, general-purpose VLA methods.

</details>


### [274] [Reduced-Order Model-Guided Reinforcement Learning for Demonstration-Free Humanoid Locomotion](https://arxiv.org/abs/2509.19023)
*Shuai Liu,Meng Cheng Lau*

Main category: cs.RO

TL;DR: 本文提出了ROM-GRL，一个两阶段强化学习框架，用于人形机器人行走。它无需动作捕捉数据或复杂奖励塑形，通过简化模型生成节能步态模板，并用其指导全身策略训练，实现了稳定、对称且低跟踪误差的步态。


<details>
  <summary>Details</summary>
Motivation: 现有的人形机器人行走强化学习方法通常依赖于动作捕捉数据或复杂的奖励塑形。研究的动机是开发一种无需人类演示，即可生成通用、自然的人形行为的方法。

Method: ROM-GRL是一个两阶段框架：
1. **第一阶段**：通过近端策略优化（PPO）训练一个紧凑的4自由度简化模型（ROM），以生成节能的步态模板。
2. **第二阶段**：利用这些动态一致的轨迹指导一个全身策略。该策略通过软执行者-评论家（SAC）训练，并辅以一个对抗性判别器，以确保学生策略的五维步态特征分布与ROM的演示相匹配。

Result: 实验结果表明，在1米/秒和4米/秒的速度下，ROM-GRL能够产生稳定、对称的步态，并且跟踪误差显著低于纯奖励基线方法。

Conclusion: ROM-GRL通过将轻量级ROM的指导提炼到高维策略中，弥合了纯奖励和基于模仿的运动方法之间的差距，从而实现了无需任何人类演示的通用、自然的人形行为。

Abstract: We introduce Reduced-Order Model-Guided Reinforcement Learning (ROM-GRL), a
two-stage reinforcement learning framework for humanoid walking that requires
no motion capture data or elaborate reward shaping. In the first stage, a
compact 4-DOF (four-degree-of-freedom) reduced-order model (ROM) is trained via
Proximal Policy Optimization. This generates energy-efficient gait templates.
In the second stage, those dynamically consistent trajectories guide a
full-body policy trained with Soft Actor--Critic augmented by an adversarial
discriminator, ensuring the student's five-dimensional gait feature
distribution matches the ROM's demonstrations. Experiments at 1
meter-per-second and 4 meter-per-second show that ROM-GRL produces stable,
symmetric gaits with substantially lower tracking error than a pure-reward
baseline. By distilling lightweight ROM guidance into high-dimensional
policies, ROM-GRL bridges the gap between reward-only and imitation-based
locomotion methods, enabling versatile, naturalistic humanoid behaviors without
any human demonstrations.

</details>


### [275] [TacEva: A Performance Evaluation Framework For Vision-Based Tactile Sensors](https://arxiv.org/abs/2509.19037)
*Qingzheng Cong,Steven Oh,Wen Fan,Shan Luo,Kaspar Althoefer,Dandan Zhang*

Main category: cs.RO

TL;DR: 由于缺乏标准化指标，视觉触觉传感器（VBTS）的性能评估和优化面临挑战。本文引入TacEva框架，通过定义性能指标和实验流程，实现VBTS的定量分析，辅助其选择和设计优化。


<details>
  <summary>Details</summary>
Motivation: 视觉触觉传感器（VBTS）因其传感机制、结构尺寸等参数的差异，导致性能表现不一。现有VBTS缺乏标准化的评估指标，使得针对特定任务进行选择和优化变得困难。

Method: 引入TacEva，一个全面的VBTS性能定量分析评估框架。该框架定义了一套捕获典型应用场景关键特征的性能指标，并为每个指标设计了结构化的实验流程，以确保一致和可重复的量化。

Result: 该框架已应用于多种具有不同传感机制的VBTS，结果表明其能够对每种设计进行彻底评估，并为每个性能维度提供定量指标。

Conclusion: TacEva框架使研究人员能够根据任务需求预选最合适的VBTS，并为VBTS的设计优化提供性能导向的见解。

Abstract: Vision-Based Tactile Sensors (VBTSs) are widely used in robotic tasks because
of the high spatial resolution they offer and their relatively low
manufacturing costs. However, variations in their sensing mechanisms,
structural dimension, and other parameters lead to significant performance
disparities between existing VBTSs. This makes it challenging to optimize them
for specific tasks, as both the initial choice and subsequent fine-tuning are
hindered by the lack of standardized metrics. To address this issue, TacEva is
introduced as a comprehensive evaluation framework for the quantitative
analysis of VBTS performance. The framework defines a set of performance
metrics that capture key characteristics in typical application scenarios. For
each metric, a structured experimental pipeline is designed to ensure
consistent and repeatable quantification. The framework is applied to multiple
VBTSs with distinct sensing mechanisms, and the results demonstrate its ability
to provide a thorough evaluation of each design and quantitative indicators for
each performance dimension. This enables researchers to pre-select the most
appropriate VBTS on a task by task basis, while also offering
performance-guided insights into the optimization of VBTS design. A list of
existing VBTS evaluation methods and additional evaluations can be found on our
website: https://stevenoh2003.github.io/TacEva/

</details>


### [276] [ManipForce: Force-Guided Policy Learning with Frequency-Aware Representation for Contact-Rich Manipulation](https://arxiv.org/abs/2509.19047)
*Geonhyup Lee,Yeongjin Lee,Kangmin Kim,Seongju Lee,Sangjun Noh,Seunghyeok Back,Kyoobin Lee*

Main category: cs.RO

TL;DR: 该研究提出了ManipForce系统用于采集高频力/扭矩和RGB数据，并基于此数据开发了频率感知多模态Transformer (FMT) 模型，以实现精确的接触式操作，显著优于仅视觉的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的模仿学习方法主要依赖于纯视觉演示，难以精确控制交互力，从而无法有效处理需要精确力控制的接触式操作任务。

Method: 研究方法包括：1) 开发ManipForce手持系统，用于在人类演示中捕获高频力/扭矩(F/T)和RGB数据；2) 引入频率感知多模态Transformer (FMT) 模型，该模型利用频率和模态感知的嵌入编码异步RGB和F/T信号，并通过双向交叉注意力在Transformer扩散策略中融合这些信号。

Result: 在六个真实的接触式操作任务（如齿轮组装、翻转盒子、电池插入）中，FMT模型在ManipForce演示数据上训练后，实现了83%的平均成功率，性能显著优于仅RGB的基线方法。消融实验和采样频率分析进一步证实，整合高频F/T数据和跨模态融合显著提升了策略性能，尤其是在需要高精度和稳定接触的任务中。

Conclusion: 该研究表明，通过结合高频力/扭矩数据和多模态学习（特别是使用FMT模型），可以显著提高模仿学习在接触式操作任务中的性能和鲁棒性，尤其对于高精度操作至关重要。

Abstract: Contact-rich manipulation tasks such as precision assembly require precise
control of interaction forces, yet existing imitation learning methods rely
mainly on vision-only demonstrations. We propose ManipForce, a handheld system
designed to capture high-frequency force-torque (F/T) and RGB data during
natural human demonstrations for contact-rich manipulation. Building on these
demonstrations, we introduce the Frequency-Aware Multimodal Transformer (FMT).
FMT encodes asynchronous RGB and F/T signals using frequency- and
modality-aware embeddings and fuses them via bi-directional cross-attention
within a transformer diffusion policy. Through extensive experiments on six
real-world contact-rich manipulation tasks - such as gear assembly, box
flipping, and battery insertion - FMT trained on ManipForce demonstrations
achieves robust performance with an average success rate of 83% across all
tasks, substantially outperforming RGB-only baselines. Ablation and
sampling-frequency analyses further confirm that incorporating high-frequency
F/T data and cross-modal integration improves policy performance, especially in
tasks demanding high precision and stable contact.

</details>


### [277] [SlicerROS2: A Research and Development Module for Image-Guided Robotic Interventions](https://arxiv.org/abs/2509.19076)
*Laura Connolly,Aravind S. Kumar,Kapi Ketan Mehta,Lidia Al-Zogbi,Peter Kazanzides,Parvin Mousavi,Gabor Fichtinger,Axel Krieger,Junichi Tokuda,Russell H. Taylor,Simon Leonard,Anton Deguet*

Main category: cs.RO

TL;DR: 本文介绍了SlicerROS2模块的重新设计版本，该模块旨在为图像引导机器人干预提供标准的集成方法，它结合了3D Slicer和ROS，并提供了增强的模块化、API访问和数据传输功能，并通过四个实际应用进行了演示。


<details>
  <summary>Details</summary>
Motivation: 医学机器人研究需要一种标准的集成方法，将医学成像（如3D Slicer）与机器人操作系统（如ROS）结合起来。SlicerROS2的初始版本虽然证明了可行性，但在模块化、低级功能访问、Python API支持和数据传输协议方面仍有改进空间。

Method: 研究人员重新编写并重新设计了SlicerROS2模块，旨在提供更高的模块化、对低级功能的访问、对3D Slicer Python API的访问以及更好的数据传输协议。新设计通过四个利用SlicerROS2核心功能的实际图像引导机器人场景应用进行演示。

Result: 本文介绍了SlicerROS2的新设计，该设计提供了更高的模块化、对低级功能的访问、对3D Slicer Python API的访问以及更好的数据传输协议。此外，通过四个实际的图像引导机器人应用，展示了SlicerROS2核心功能的应用。

Conclusion: 重新设计的SlicerROS2模块提供了一个更强大、更灵活的平台，用于整合3D Slicer和ROS，为医学机器人研究提供了一个标准化的集成方法，并通过实际应用验证了其在图像引导机器人干预中的实用性。

Abstract: Image-guided robotic interventions involve the use of medical imaging in
tandem with robotics. SlicerROS2 is a software module that combines 3D Slicer
and robot operating system (ROS) in pursuit of a standard integration approach
for medical robotics research. The first release of SlicerROS2 demonstrated the
feasibility of using the C++ API from 3D Slicer and ROS to load and visualize
robots in real time. Since this initial release, we've rewritten and redesigned
the module to offer greater modularity, access to low-level features, access to
3D Slicer's Python API, and better data transfer protocols. In this paper, we
introduce this new design as well as four applications that leverage the core
functionalities of SlicerROS2 in realistic image-guided robotics scenarios.

</details>


### [278] [World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation](https://arxiv.org/abs/2509.19080)
*Zhennan Jiang,Kai Liu,Yuxin Qin,Shuai Tian,Yupeng Zheng,Mingcai Zhou,Chao Yu,Haoran Li,Dongbin Zhao*

Main category: cs.RO

TL;DR: World4RL框架利用基于扩散模型的环境模型作为高保真模拟器，在纯想象环境中优化机器人操作策略，显著提升了策略性能。


<details>
  <summary>Details</summary>
Motivation: 机器人操作策略的初始化通常依赖模仿学习，但受限于专家数据的稀缺性和覆盖范围。强化学习可以改进策略，但真实机器人训练成本高昂且不安全，而模拟器训练则面临“模拟到现实”的鸿沟。鉴于生成模型（特别是扩散模型）在真实世界模拟方面的显著进步，研究者旨在探索如何将基于扩散模型的环境模型结合起来，以增强预训练的机器人操作策略。

Method: 提出了World4RL框架，该框架采用基于扩散模型的环境模型作为高保真模拟器，完全在想象环境中精炼预训练策略，实现端到端的策略优化。其设计基于两大原则：1) 预训练一个能在多任务数据集中捕捉多样化动态的扩散环境模型；2) 在冻结的环境模型中完全精炼策略，避免在线的真实世界交互。此外，还设计了一种专为机器人操作定制的two-hot动作编码方案，并采用扩散骨干网络以提高建模保真度。

Result: 广泛的模拟和真实世界实验表明，World4RL提供了高保真的环境建模，并实现了持续的策略精炼，与模仿学习和其他基线相比，成功率显著提高。

Conclusion: World4RL框架通过将基于扩散模型的环境模型作为高保真模拟器，在纯想象环境中有效精炼机器人操作策略，克服了传统方法的数据限制和“模拟到现实”的挑战，为机器人操作策略的优化提供了一条有效途径。

Abstract: Robotic manipulation policies are commonly initialized through imitation
learning, but their performance is limited by the scarcity and narrow coverage
of expert data. Reinforcement learning can refine polices to alleviate this
limitation, yet real-robot training is costly and unsafe, while training in
simulators suffers from the sim-to-real gap. Recent advances in generative
models have demonstrated remarkable capabilities in real-world simulation, with
diffusion models in particular excelling at generation. This raises the
question of how diffusion model-based world models can be combined to enhance
pre-trained policies in robotic manipulation. In this work, we propose
World4RL, a framework that employs diffusion-based world models as
high-fidelity simulators to refine pre-trained policies entirely in imagined
environments for robotic manipulation. Unlike prior works that primarily employ
world models for planning, our framework enables direct end-to-end policy
optimization. World4RL is designed around two principles: pre-training a
diffusion world model that captures diverse dynamics on multi-task datasets and
refining policies entirely within a frozen world model to avoid online
real-world interactions. We further design a two-hot action encoding scheme
tailored for robotic manipulation and adopt diffusion backbones to improve
modeling fidelity. Extensive simulation and real-world experiments demonstrate
that World4RL provides high-fidelity environment modeling and enables
consistent policy refinement, yielding significantly higher success rates
compared to imitation learning and other baselines. More visualization results
are available at https://world4rl.github.io/.

</details>


### [279] [FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation](https://arxiv.org/abs/2509.19102)
*Hongli Xu,Lei Zhang,Xiaoyue Hu,Boyang Zhong,Kaixin Bai,Zoltán-Csaba Márton,Zhenshan Bing,Zhaopeng Chen,Alois Christian Knoll,Jianwei Zhang*

Main category: cs.RO

TL;DR: FunCanon是一个机器人框架，它将长周期操作任务分解为动作块序列，并利用大型视觉语言模型进行功能对象规范化，以实现姿态感知和类别通用的策略。其核心FuncDiffuser扩散策略在对齐数据上训练，显著提高了泛化能力、行为复用和sim2real部署。


<details>
  <summary>Details</summary>
Motivation: 传统的端到端机器人演示通常导致任务特定的策略，这些策略难以泛化到训练分布之外，无法实现通用机器人技能。

Method: FunCanon框架将长周期操作任务转换为一系列动作块（由执行者、动词和对象定义）。通过使用大型视觉语言模型提供的可供性线索，进行功能对象规范化，将对象映射到共享的功能框架中，从而实现策略的姿态感知和类别通用性。在此对齐数据上训练了一个以对象和动作为中心的扩散策略FuncDiffuser。

Result: 实验证明，该方法实现了类别级别的泛化、跨任务行为复用以及鲁棒的sim2real部署。功能规范化为复杂操作领域的可扩展模仿学习提供了强大的归纳偏置。

Conclusion: FunCanon通过其动作块分解、功能对象规范化和FuncDiffuser扩散策略，成功解决了机器人技能泛化性差的问题，为复杂操作任务中的可扩展模仿学习提供了一种有效途径，显著提高了策略的泛化能力和行为复用性。

Abstract: General-purpose robotic skills from end-to-end demonstrations often leads to
task-specific policies that fail to generalize beyond the training
distribution. Therefore, we introduce FunCanon, a framework that converts
long-horizon manipulation tasks into sequences of action chunks, each defined
by an actor, verb, and object. These chunks focus policy learning on the
actions themselves, rather than isolated tasks, enabling compositionality and
reuse. To make policies pose-aware and category-general, we perform functional
object canonicalization for functional alignment and automatic manipulation
trajectory transfer, mapping objects into shared functional frames using
affordance cues from large vision language models. An object centric and action
centric diffusion policy FuncDiffuser trained on this aligned data naturally
respects object affordances and poses, simplifying learning and improving
generalization ability. Experiments on simulated and real-world benchmarks
demonstrate category-level generalization, cross-task behavior reuse, and
robust sim2real deployment, showing that functional canonicalization provides a
strong inductive bias for scalable imitation learning in complex manipulation
domains. Details of the demo and supplemental material are available on our
project website https://sites.google.com/view/funcanon.

</details>


### [280] [Spectral Signature Mapping from RGB Imagery for Terrain-Aware Navigation](https://arxiv.org/abs/2509.19105)
*Sarvesh Prajapati,Ananya Trivedi,Nathaniel Hanson,Bruce Maxwell,Taskin Padir*

Main category: cs.RO

TL;DR: 本文提出RS-Net，一个深度神经网络，能从RGB图像预测光谱特征，从而推断地形材料属性和摩擦系数。这使得机器人能利用易得的RGB传感器进行材料感知的户外导航。


<details>
  <summary>Details</summary>
Motivation: 户外导航需要准确预测机器人与地形的物理交互。现有方法（几何或语义标签）无法区分外观相似但材料属性不同的表面。光谱传感器能提供材料组成信息，但其部署受限于定制硬件、高成本和计算密集型处理。

Method: 本文提出了RS-Net（RGB图像到光谱特征神经网络），一个深度神经网络，用于从RGB图像块预测光谱特征。这些光谱特征被映射到地形标签和摩擦系数。地形分类结果被集成到轮式机器人的基于采样的运动规划器中，摩擦估计则被集成到四足机器人在湿滑表面导航的基于接触力的MPC中。该框架在训练阶段学习任务相关的物理属性，在测试阶段仅依赖RGB传感。

Result: RS-Net成功地从RGB图像预测了光谱特征，这些特征被用于地形分类和摩擦系数估计。这些信息被有效地集成到运动规划和MPC中，使得轮式和四足机器人在户外环境中能够进行材料感知的导航。

Conclusion: 本文引入了一个框架，它弥合了RGB传感器的可访问性与光谱数据丰富的材料信息之间的鸿沟。通过RS-Net，机器人能够在训练后仅依靠RGB传感在测试时推断出与任务相关的物理属性（如地形和摩擦力），从而实现更智能的户外导航。

Abstract: Successful navigation in outdoor environments requires accurate prediction of
the physical interactions between the robot and the terrain. To this end,
several methods rely on geometric or semantic labels to classify traversable
surfaces. However, such labels cannot distinguish visually similar surfaces
that differ in material properties. Spectral sensors enable inference of
material composition from surface reflectance measured across multiple
wavelength bands. Although spectral sensing is gaining traction in robotics,
widespread deployment remains constrained by the need for custom hardware
integration, high sensor costs, and compute-intensive processing pipelines. In
this paper, we present RGB Image to Spectral Signature Neural Network (RS-Net),
a deep neural network designed to bridge the gap between the accessibility of
RGB sensing and the rich material information provided by spectral data. RS-Net
predicts spectral signatures from RGB patches, which we map to terrain labels
and friction coefficients. The resulting terrain classifications are integrated
into a sampling-based motion planner for a wheeled robot operating in outdoor
environments. Likewise, the friction estimates are incorporated into a
contact-force-based MPC for a quadruped robot navigating slippery surfaces.
Thus, we introduce a framework that learns the task-relevant physical property
once during training and thereafter relies solely on RGB sensing at test time.
The code is available at https://github.com/prajapatisarvesh/RS-Net.

</details>


### [281] [BiGraspFormer: End-to-End Bimanual Grasp Transformer](https://arxiv.org/abs/2509.19142)
*Kangmin Kim,Seunghyeok Back,Geonhyup Lee,Sangbeom Lee,Sangjun Noh,Kyoobin Lee*

Main category: cs.RO

TL;DR: 本文提出BiGraspFormer，一个统一的端到端Transformer框架，利用“单臂引导双臂”（SGB）策略，直接从点云生成协调的双臂抓取，解决了现有方法的协调性问题。


<details>
  <summary>Details</summary>
Motivation: 现有双臂抓取方法存在局限性，要么只关注单臂抓取，要么将抓取生成与双臂评估分开，导致碰撞风险和力分布不均等协调问题。

Method: BiGraspFormer是一个统一的端到端Transformer框架，直接从物体点云生成协调的双臂抓取。其核心思想是“单臂引导双臂”（SGB）策略：首先使用Transformer解码器生成多样化的单臂抓取候选，然后通过专门的注意力机制利用这些学习到的特征，共同预测双臂姿态和质量得分。这种条件化策略降低了12自由度搜索空间的复杂性，并确保了双臂操作的协调性。

Result: 全面的仿真实验和真实世界验证表明，BiGraspFormer始终优于现有方法，并保持高效的推理速度（<0.05秒）。

Conclusion: BiGraspFormer是一个有效的框架，能够解决双臂抓取中的协调性问题，并展现出优异的性能和效率。

Abstract: Bimanual grasping is essential for robots to handle large and complex
objects. However, existing methods either focus solely on single-arm grasping
or employ separate grasp generation and bimanual evaluation stages, leading to
coordination problems including collision risks and unbalanced force
distribution. To address these limitations, we propose BiGraspFormer, a unified
end-to-end transformer framework that directly generates coordinated bimanual
grasps from object point clouds. Our key idea is the Single-Guided Bimanual
(SGB) strategy, which first generates diverse single grasp candidates using a
transformer decoder, then leverages their learned features through specialized
attention mechanisms to jointly predict bimanual poses and quality scores. This
conditioning strategy reduces the complexity of the 12-DoF search space while
ensuring coordinated bimanual manipulation. Comprehensive simulation
experiments and real-world validation demonstrate that BiGraspFormer
consistently outperforms existing methods while maintaining efficient inference
speed (<0.05s), confirming the effectiveness of our framework. Code and
supplementary materials are available at https://sites.google.com/bigraspformer

</details>


### [282] [A Multimodal Stochastic Planning Approach for Navigation and Multi-Robot Coordination](https://arxiv.org/abs/2509.19168)
*Mark Gonzales,Ethan Oh,Joseph Moore*

Main category: cs.RO

TL;DR: 本文提出了一种基于采样、滚动优化的规划器，通过交叉熵方法优化多模态策略分布，提高了鲁棒性、促进了探索，并自然扩展到多机器人无碰撞规划，经仿真和硬件验证有效。


<details>
  <summary>Details</summary>
Motivation: 克服局部最优、有效探索解空间，并实现多机器人无碰撞规划，使智能体能够共享多样化候选策略以避免死锁，同时在不增加集中式优化计算复杂性的情况下最小化全局目标。

Method: 采用滚动优化、基于采样的规划器。核心方法是使用交叉熵方法（CEM）在共同成本函数下优化多模态策略分布。该方法自然扩展到多机器人规划，通过智能体共享多样化的候选策略。

Result: 该方法提高了对抗局部最优的鲁棒性，促进了对解空间的有效探索。它自然地扩展到多机器人无碰撞规划，使智能体能够共享多样化候选策略以避免死锁，并允许团队在不产生集中式优化计算复杂性的情况下最小化全局目标。数值模拟表明，采用多模态显著提高了在陷阱环境和多机器人避碰中的成功率。硬件实验进一步验证了该方法的实时可行性和实际性能。

Conclusion: 所提出的基于交叉熵方法优化多模态策略分布的滚动优化规划器，显著提高了规划的鲁棒性和探索能力，特别是在复杂环境和多机器人协作中，并具有良好的实时性和实用性。

Abstract: In this paper, we present a receding-horizon, sampling-based planner capable
of reasoning over multimodal policy distributions. By using the cross-entropy
method to optimize a multimodal policy under a common cost function, our
approach increases robustness against local minima and promotes effective
exploration of the solution space. We show that our approach naturally extends
to multi-robot collision-free planning, enables agents to share diverse
candidate policies to avoid deadlocks, and allows teams to minimize a global
objective without incurring the computational complexity of centralized
optimization. Numerical simulations demonstrate that employing multiple modes
significantly improves success rates in trap environments and in multi-robot
collision avoidance. Hardware experiments further validate the approach's
real-time feasibility and practical performance.

</details>


### [283] [MagiClaw: A Dual-Use, Vision-Based Soft Gripper for Bridging the Human Demonstration to Robotic Deployment Gap](https://arxiv.org/abs/2509.19169)
*Tianyu Wu,Xudong Han,Haoran Sun,Zishang Zhang,Bangchao Huang,Chaoyang Song,Fang Wan*

Main category: cs.RO

TL;DR: MagiClaw是一种多功能两指末端执行器，旨在通过在数据收集（手持）和机器人执行（机器人末端）之间提供硬件一致性，并集成视觉和力觉传感器，来弥合人类示教到机器人操作的领域鸿沟。


<details>
  <summary>Details</summary>
Motivation: 将人类操作技能转移到机器人执行时，由于感知和形态上的“领域鸿沟”常常受到阻碍。

Method: 本文引入了MagiClaw，这是一种两指末端执行器，既可用作手持工具进行数据收集，也可用作机器人末端执行器进行策略部署，确保硬件一致性。每个手指都包含一个嵌入摄像头的软多面体网络（SPN），用于估计6自由度力和接触变形。这些本体感受数据与集成iPhone提供的外部环境感知（6D姿态、RGB视频、LiDAR深度图）融合。通过定制的iOS应用程序，MagiClaw流式传输同步的多模态数据，用于实时遥操作、离线策略学习和混合现实界面控制。

Result: 该统一系统架构降低了收集高保真、接触丰富数据集的门槛，并加速了可泛化操作策略的开发。

Conclusion: MagiClaw通过其创新的硬件设计和多模态传感融合，成功弥合了人类示教与机器人执行之间的领域鸿沟，从而简化了数据收集并加速了操作策略的开发。

Abstract: The transfer of manipulation skills from human demonstration to robotic
execution is often hindered by a "domain gap" in sensing and morphology. This
paper introduces MagiClaw, a versatile two-finger end-effector designed to
bridge this gap. MagiClaw functions interchangeably as both a handheld tool for
intuitive data collection and a robotic end-effector for policy deployment,
ensuring hardware consistency and reliability. Each finger incorporates a Soft
Polyhedral Network (SPN) with an embedded camera, enabling vision-based
estimation of 6-DoF forces and contact deformation. This proprioceptive data is
fused with exteroceptive environmental sensing from an integrated iPhone, which
provides 6D pose, RGB video, and LiDAR-based depth maps. Through a custom iOS
application, MagiClaw streams synchronized, multi-modal data for real-time
teleoperation, offline policy learning, and immersive control via mixed-reality
interfaces. We demonstrate how this unified system architecture lowers the
barrier to collecting high-fidelity, contact-rich datasets and accelerates the
development of generalizable manipulation policies. Please refer to the iOS app
at https://apps.apple.com/cn/app/magiclaw/id6661033548 for further details.

</details>


### [284] [Imitation-Guided Bimanual Planning for Stable Manipulation under Changing External Forces](https://arxiv.org/abs/2509.19261)
*Kuanqi Cai,Chunfeng Wang,Zeqi Li,Haowen Yao,Weinan Chen,Luis Figueredo,Aude Billard,Arash Ajoudani*

Main category: cs.RO

TL;DR: 本文提出了一种模仿学习引导的双臂规划框架，通过稳定的抓取流形交集采样策略和分层双阶段运动架构，解决了动态环境中机器人抓取类型平滑过渡和运动性能优化的问题，显著提高了抓取过渡效率和运动性能。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，机器人操作需要不同抓取类型之间的无缝过渡以保持稳定性和效率。然而，实现平滑和自适应的抓取过渡仍然是一个挑战，尤其是在处理外部力和复杂运动约束时。现有的抓取过渡策略通常未能考虑变化的外部力，也未能有效地优化运动性能。

Method: 本文提出了一种模仿学习引导的双臂规划框架。该框架整合了高效的抓取过渡策略和运动性能优化。具体方法包括：1) 引入了“抓取流形中稳定交集采样策略”（SSSIGM），用于单手和双手抓取之间的无缝过渡，旨在降低计算成本和重新抓取效率低下问题。2) 提出了一种“分层双阶段运动架构”，该架构结合了基于模仿学习的全局路径生成器和由二次规划驱动的局部规划器，以确保实时运动可行性、避障和卓越的可操作性。

Result: 所提出的方法通过一系列力密集型任务进行评估，结果表明在抓取过渡效率和运动性能方面取得了显著改进。

Conclusion: 该框架通过集成高效的抓取过渡策略和运动性能优化，有效地增强了机器人操作的稳定性和灵活性。

Abstract: Robotic manipulation in dynamic environments often requires seamless
transitions between different grasp types to maintain stability and efficiency.
However, achieving smooth and adaptive grasp transitions remains a challenge,
particularly when dealing with external forces and complex motion constraints.
Existing grasp transition strategies often fail to account for varying external
forces and do not optimize motion performance effectively. In this work, we
propose an Imitation-Guided Bimanual Planning Framework that integrates
efficient grasp transition strategies and motion performance optimization to
enhance stability and dexterity in robotic manipulation. Our approach
introduces Strategies for Sampling Stable Intersections in Grasp Manifolds for
seamless transitions between uni-manual and bi-manual grasps, reducing
computational costs and regrasping inefficiencies. Additionally, a Hierarchical
Dual-Stage Motion Architecture combines an Imitation Learning-based Global Path
Generator with a Quadratic Programming-driven Local Planner to ensure real-time
motion feasibility, obstacle avoidance, and superior manipulability. The
proposed method is evaluated through a series of force-intensive tasks,
demonstrating significant improvements in grasp transition efficiency and
motion performance. A video demonstrating our simulation results can be viewed
at
\href{https://youtu.be/3DhbUsv4eDo}{\textcolor{blue}{https://youtu.be/3DhbUsv4eDo}}.

</details>


### [285] [SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration](https://arxiv.org/abs/2509.19292)
*Yang Jin,Jun Lv,Han Xue,Wendi Chen,Chuan Wen,Cewu Lu*

Main category: cs.RO

TL;DR: 本文提出了一种名为SOE（Self-Improvement via On-Manifold Exploration）的框架，通过学习任务相关因素的紧凑潜在表示并将探索限制在有效动作流形上，显著提升了机器人策略的探索能力、安全性和样本效率。


<details>
  <summary>Details</summary>
Motivation: 智能体通过探索环境来改进其能力，但机器人策略常因动作模式崩溃而缺乏足够的探索能力。现有鼓励探索的方法通常依赖随机扰动，这既不安全又会导致不稳定和不稳定的行为，从而限制了它们的有效性。

Method: SOE框架通过学习任务相关因素的紧凑潜在表示，并将探索限制在有效动作的流形上，以确保安全性、多样性和有效性。它可作为即插即用模块与任意策略模型无缝集成，在不降低基础策略性能的情况下增强探索。此外，结构化的潜在空间还支持人机引导探索，进一步提高了效率和可控性。

Result: 在模拟和真实世界任务中的大量实验表明，SOE始终优于现有方法，实现了更高的任务成功率、更平稳和安全的探索以及卓越的样本效率。

Conclusion: 这些结果确立了基于流形的探索作为一种实现样本高效策略自我改进的原则性方法。

Abstract: Intelligent agents progress by continually refining their capabilities
through actively exploring environments. Yet robot policies often lack
sufficient exploration capability due to action mode collapse. Existing methods
that encourage exploration typically rely on random perturbations, which are
unsafe and induce unstable, erratic behaviors, thereby limiting their
effectiveness. We propose Self-Improvement via On-Manifold Exploration (SOE), a
framework that enhances policy exploration and improvement in robotic
manipulation. SOE learns a compact latent representation of task-relevant
factors and constrains exploration to the manifold of valid actions, ensuring
safety, diversity, and effectiveness. It can be seamlessly integrated with
arbitrary policy models as a plug-in module, augmenting exploration without
degrading the base policy performance. Moreover, the structured latent space
enables human-guided exploration, further improving efficiency and
controllability. Extensive experiments in both simulation and real-world tasks
demonstrate that SOE consistently outperforms prior methods, achieving higher
task success rates, smoother and safer exploration, and superior sample
efficiency. These results establish on-manifold exploration as a principled
approach to sample-efficient policy self-improvement. Project website:
https://ericjin2002.github.io/SOE

</details>


### [286] [Residual Off-Policy RL for Finetuning Behavior Cloning Policies](https://arxiv.org/abs/2509.19301)
*Lars Ankile,Zhenyu Jiang,Rocky Duan,Guanya Shi,Pieter Abbeel,Anusha Nagabandi*

Main category: cs.RO

TL;DR: 该研究提出了一种结合行为克隆（BC）和强化学习（RL）的残差学习框架，以克服各自的局限性，并首次在具有灵巧手的类人机器人上实现了成功的真实世界RL训练。


<details>
  <summary>Details</summary>
Motivation: 行为克隆（BC）受限于演示数据质量、收集成本和数据增益递减。强化学习（RL）在真实世界机器人上训练面临样本效率低下、安全问题、稀疏奖励学习困难以及高自由度（DoF）系统挑战。

Method: 该方法通过残差学习框架结合了BC和RL。它利用BC策略作为黑盒基础，并通过样本高效的离策略RL学习轻量级的每步残差校正。

Result: 该方法仅需稀疏的二元奖励信号，就能有效改进仿真和真实世界中高自由度系统的操作策略。它首次在具有灵巧手的类人机器人上实现了成功的真实世界RL训练，并在各种基于视觉的任务中展示了最先进的性能。

Conclusion: 该研究提供了一个在真实世界中部署RL的实用途径，显著提高了高自由度机器人（包括类人机器人）在复杂操作任务中的学习和控制能力。

Abstract: Recent advances in behavior cloning (BC) have enabled impressive visuomotor
control policies. However, these approaches are limited by the quality of human
demonstrations, the manual effort required for data collection, and the
diminishing returns from increasing offline data. In comparison, reinforcement
learning (RL) trains an agent through autonomous interaction with the
environment and has shown remarkable success in various domains. Still,
training RL policies directly on real-world robots remains challenging due to
sample inefficiency, safety concerns, and the difficulty of learning from
sparse rewards for long-horizon tasks, especially for high-degree-of-freedom
(DoF) systems. We present a recipe that combines the benefits of BC and RL
through a residual learning framework. Our approach leverages BC policies as
black-box bases and learns lightweight per-step residual corrections via
sample-efficient off-policy RL. We demonstrate that our method requires only
sparse binary reward signals and can effectively improve manipulation policies
on high-degree-of-freedom (DoF) systems in both simulation and the real world.
In particular, we demonstrate, to the best of our knowledge, the first
successful real-world RL training on a humanoid robot with dexterous hands. Our
results demonstrate state-of-the-art performance in various vision-based tasks,
pointing towards a practical pathway for deploying RL in the real world.
Project website: https://residual-offpolicy-rl.github.io

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [287] [Stochastic Economic Dispatch with Battery Energy Storage considering Wind and Load Uncertainty](https://arxiv.org/abs/2509.18100)
*Shishir Lamichhane,Anamika Dubey*

Main category: eess.SY

TL;DR: 本文提出了一个随机动态经济调度与储能（SDED-S）框架，用于评估电池储能系统（BESS）在管理不确定性方面的作用，并证明BESS能显著提高系统灵活性、减少弃风和运行成本，尤其是在高风电渗透率下。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源并网，电力系统在管理运行灵活性、可靠性及最小化运行成本方面面临日益严峻的挑战。电池储能系统（BESS）被认为是解决这些问题的有效方案。

Method: 本文提出了一个随机动态经济调度与储能（SDED-S）框架来评估BESS在管理不确定性方面的作用。该方法捕获了风电和负荷不确定性之间的时间相关性，并使用受分层和重要性采样启发的方法生成场景。该方法在一个修改后的IEEE 39节点系统上进行了演示，其中部分常规发电机被转换为风力发电厂。

Result: 案例研究表明，战略性部署BESS通过减少可再生能源弃用和调度成本，显著提高了系统灵活性。可再生能源弃用量随BESS规模的增加而减少，并可能趋近于零（取决于风电渗透水平）。风电渗透率越高，在没有储能的情况下弃用量越大，部署BESS时节省的成本也越大。

Conclusion: 随着可再生能源渗透率的增加，对灵活性的需求也随之增长。BESS是满足这种需求的有效解决方案，它能显著提升电力系统的灵活性，并通过减少弃风和运行成本来提高经济效益。

Abstract: With the integration of renewable energy resources in power systems, managing
operational flexibility and reliability while minimizing operational costs has
become increasingly challenging. Battery energy storage system (BESS) offers a
promising solution to address these issues. This paper presents a stochastic
dynamic economic dispatch with storage (SDED-S) framework to assess the impact
of BESS in managing uncertainty. The temporal correlation between wind and load
uncertainties is captured, with scenarios generated using a method inspired by
stratified and importance sampling. The proposed approach is demonstrated on a
modified IEEE 39-bus system, where selected conventional generators are
converted to wind power plants. Case studies show that strategic BESS
deployment significantly improves system flexibility by reducing renewable
curtailments and dispatch costs. Renewable energy curtailments decrease upon
increasing BESS size and approach zero depending on wind penetration level.
Higher wind penetrations result in greater curtailments without storage and
yield larger cost savings when BESS is deployed, highlighting the growing need
for flexibility as renewable energy penetrations increase.

</details>


### [288] [Reversible Kalman Filter for state estimation with Manifold](https://arxiv.org/abs/2509.18224)
*Svyatoslav Covanov,Cedric Pradalier*

Main category: eess.SY

TL;DR: 本文提出了一种新的卡尔曼滤波算法，用于流形上的状态估计，旨在以任意精度评估现有卡尔曼滤波变体的性能，并纠正其发散问题，同时扩展其应用场景。


<details>
  <summary>Details</summary>
Motivation: 现有卡尔曼滤波变体在合成数据上缺乏以任意精度评估其精度的有效方法，且存在发散问题和小速度假设的限制，这阻碍了其在高精度应用中的表现。

Method: 开发了一种新的卡尔曼滤波器，具有良好的数值特性。该滤波器假设传感器具有高精度，并引入了一个启发式检测步骤，使其能够应用于使用9轴IMU或里程计、加速度计和压力传感器组合的真实场景（例如水下环境）。

Result: 新滤波器纠正了先前卡尔曼滤波器变体中观察到的发散问题。其可实现精度不再受小速度假设的限制，仅由传感器噪声决定。该方法可扩展到使用9轴IMU或特定传感器组合（如用于水下环境的里程计、加速度计和压力传感器）的实际场景。

Conclusion: 本文提出了一种在流形上进行状态估计的新卡尔曼滤波算法，它解决了现有方法的精度评估限制和发散问题，消除了小速度假设，并通过启发式检测步骤扩展了其在多种真实场景（包括水下轨迹重建）中的应用潜力。

Abstract: This work introduces an algorithm for state estimation on manifolds within
the framework of the Kalman filter. Its primary objective is to provide a
methodology enabling the evaluation of the precision of existing Kalman filter
variants with arbitrary accuracy on synthetic data, something that, to the best
of our knowledge, has not been addressed in prior work. To this end, we develop
a new filter that exhibits favorable numerical properties, thereby correcting
the divergences observed in previous Kalman filter variants. In this
formulation, the achievable precision is no longer constrained by the
small-velocity assumption and is determined solely by sensor noise. In
addition, this new filter assumes high precision on the sensors, which, in real
scenarios require a detection step that we define heuristically, allowing one
to extend this approach to scenarios, using either a 9-axis IMU or a
combination of odometry, accelerometer, and pressure sensors. The latter
configuration is designed for the reconstruction of trajectories in underwater
environments.

</details>


### [289] [Fully Distributed State Estimation for Multi-agent Systems and its Application in Cooperative Localization](https://arxiv.org/abs/2509.18292)
*Shuaiting Huang,Haodong Jiang,Chengcheng Zhao,Peng Cheng,Junfeng Wu*

Main category: eess.SY

TL;DR: 本文提出了一种用于连续时间线性多智能体系统（MAS）的分布式状态观测器，使每个智能体能够估计整个系统的状态，并在强连通通信图下证明了其稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决由智能体自身监控的连续时间线性多智能体系统的分布式状态估计问题。

Method: 提出了一种分布式观测器。该方法的核心是让每个智能体i通过使用主从共识规则来跟踪智能体j的状态估计（由智能体j自身使用类Luenberger估计规则生成），从而恢复智能体j的状态。此外，讨论了在智能体仅知晓基本MAS配置信息（如同质性和最大允许智能体数量）情况下的全分布式设计，并将其应用于合作定位，开发了两种全分布式定位算法。

Result: 在节点级可观测性和拓扑排序一致性假设下，当且仅当通信图是强连通时，估计误差动力学是可镇定的。所提出的全分布式设计在智能体增减时也能正常工作。开发了两种全分布式定位算法，并仿真验证了理论结果的有效性。

Conclusion: 所提出的分布式观测器能有效解决多智能体系统的分布式状态估计问题，并在特定条件下保证了稳定性。其全分布式设计和在合作定位中的应用也展示了其鲁棒性和有效性。

Abstract: In this paper, we investigate the distributed state estimation problem for a
continuous-time linear multi-agent system (MAS) composed of $\mathit{m}$ agents
and monitored by the agents themselves. To address this problem, we propose a
distributed observer that enables each agent to reconstruct the state of the
MAS. The main idea is to let each agent $\mathit{i}$ recover the state of agent
$\mathit{j}$ by using leader-follower consensus rules to track agent
$\mathit{j}$'s state estimate, which is generated by agent $\mathit{j}$ itself
using a Luenberger-like estimation rule. Under the assumptions of node-level
observability and topological ordering consistency, we show that the estimation
error dynamics are stabilizable if and only if the communication graph is
strongly connected. Moreover, we discuss the fully distributed design of the
proposed observer, assuming that the agents only know basic MAS configuration
information, such as the homogeneity and the maximum number of allowable
agents. This design ensures that the proposed observer functions correctly when
agents are added or removed. Building on this, we consider cooperative
localization as a distributed estimation problem and develop two fully
distributed localization algorithms that allow agents to track their own and
other agents' positions (and velocities) within the MAS. Finally, we conduct
simulations to demonstrate the effectiveness of our proposed theoretical
results.

</details>


### [290] [On the Dynamics of Acceleration in First order Gradient Methods](https://arxiv.org/abs/2509.18346)
*M Parimi,Rachit Mehra,S. R. Wagh,Amol Yerudkar,Navdeep Singh*

Main category: eess.SY

TL;DR: 本文从动力系统视角，利用被动性与浸入方法及几何奇异摄动理论，正向推导并解释了Nesterov加速算法的内在原理和加速现象，而非传统地从离散算法逆向推导ODE。


<details>
  <summary>Details</summary>
Motivation: Nesterov加速算法的加速现象本质一直难以捉摸，传统上从离散算法逆向推导常微分方程（ODE）未能有效揭示其深层原理，导致对加速机制的理解不足。

Method: 本文不采用从离散算法逆向工程ODE的方法，而是利用控制范式中的“被动性与浸入方法”和“几何奇异摄动理论”等工具，正向构建了一个动力系统来解释和建模加速现象。

Result: 该方法成功揭示了Nesterov加速算法（针对平滑强凸和凸情况）中各项和步骤的内在原理。此外，该框架还能用于推导三重动量方法的加速机制，并解释了重球法不收敛到最优解的原因。

Conclusion: 通过从动力系统角度正向推导，本文成功地揭示了Nesterov加速算法背后的数学原理，提供了对加速现象更深层次的理解，并为其他加速方法提供了统一的解释框架。

Abstract: Ever since the original algorithm by Nesterov (1983), the true nature of the
acceleration phenomenon has remained elusive, with various interpretations of
why the method is actually faster. The diagnosis of the algorithm through the
lens of Ordinary Differential Equations (ODEs) and the corresponding dynamical
system formulation to explain the underlying dynamics has a rich history. In
the literature, the ODEs that explain algorithms are typically derived by
considering the limiting case of the algorithm maps themselves, that is, an ODE
formulation follows the development of an algorithm. This obfuscates the
underlying higher order principles and thus provides little evidence of the
working of the algorithm. Such has been the case with Nesterov algorithm and
the various analogies used to describe the acceleration phenomena, viz,
momentum associated with the rolling of a Heavy-Ball down a slope, Hessian
damping etc. The main focus of our work is to ideate the genesis of the
Nesterov algorithm from the viewpoint of dynamical systems leading to
demystifying the mathematical rigour behind the algorithm. Instead of reverse
engineering ODEs from discrete algorithms, this work explores tools from the
recently developed control paradigm titled Passivity and Immersion approach and
the Geometric Singular Perturbation theory which are applied to arrive at the
formulation of a dynamical system that explains and models the acceleration
phenomena. This perspective helps to gain insights into the various terms
present and the sequence of steps used in Nesterovs accelerated algorithm for
the smooth strongly convex and the convex case. The framework can also be
extended to derive the acceleration achieved using the triple momentum method
and provides justifications for the non-convergence to the optimal solution in
the Heavy-Ball method.

</details>


### [291] [Optimal Service Mode Assignment in a Simple Computation Offloading System: Extended Version](https://arxiv.org/abs/2509.18356)
*Darin Jeff,Eytan Modiano*

Main category: eess.SY

TL;DR: 本文研究了一种计算卸载模型，旨在通过设计作业分配策略（完全卸载或部分卸载）来最小化系统延迟，并提出了基于云服务器状态的最优策略。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了在计算卸载系统中，通过优化作业分配策略来最小化系统延迟。

Method: 研究方法是设计一种基于系统状态的作业分配策略，将作业分配给两种服务模式：完全云端处理或先本地处理后云端完成。通过理论分析推导出在不同云服务器状态下的最优策略结构，并使用仿真进行验证。

Result: 主要结果是：当云服务器空闲时，最优策略是将下一个作业分配给云端处理；当云服务器繁忙时，在温和假设下，最优策略是阈值类型，即如果系统队列超过某个阈值，则将下一个作业发送到本地服务器处理。

Conclusion: 结论是，最优的计算卸载策略结构取决于云服务器的状态：空闲时直接送云端，繁忙时则采用基于队列长度的阈值策略，该策略结构已通过仿真得到验证。

Abstract: We consider a simple computation offloading model where jobs can either be
fully processed in the cloud or be partially processed at a local server before
being sent to the cloud to complete processing. Our goal is to design a policy
for assigning jobs to service modes, i.e., full offloading or partial
offloading, based on the state of the system, in order to minimize delay in the
system. We show that when the cloud server is idle, the optimal policy is to
assign the next job in the system queue to the cloud for processing. However,
when the cloud server is busy, we show that, under mild assumptions, the
optimal policy is of a threshold type, that sends the next job in the system
queue to the local server if the queue exceeds a certain threshold. Finally, we
demonstrate this policy structure through simulations.

</details>


### [292] [Policy Gradient with Self-Attention for Model-Free Distributed Nonlinear Multi-Agent Games](https://arxiv.org/abs/2509.18371)
*Eduardo Sebastián,Maitrayee Keskar,Eeman Iqbal,Eduardo Montijano,Carlos Sagüés,Nikolay Atanasov*

Main category: eess.SY

TL;DR: 本文提出了一种模型无关的分布式策略梯度方法，用于动态非线性多智能体博弈。该方法利用自注意力层参数化非线性反馈增益策略，以应对时变通信拓扑，并在多种场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 动态非线性环境下的多智能体博弈面临挑战，原因在于智能体之间相互作用的时变性以及纳什均衡的非平稳性。特别是在模型未知（模型无关）的情况下，仅能观测到智能体状态转移和成本，这使得问题更具挑战性。

Method: 本文提出了一种策略梯度方法，用于学习多团队博弈中的分布式策略，这些策略遵循通信结构。该方法受到线性二次博弈中分布式策略（时变线性反馈增益形式）的启发。在非线性情况下，策略被建模为非线性反馈增益，并通过自注意力层进行参数化，以处理时变的多智能体通信拓扑。

Result: 研究表明，所提出的分布式策略梯度方法在多个设置中取得了强大的性能，包括分布式线性与非线性调节任务，以及模拟和真实的多机器人追捕-规避博弈。

Conclusion: 所提出的模型无关分布式策略梯度方法，通过自注意力层处理非线性动态和时变通信，能够有效学习复杂多智能体博弈中的分布式策略，并在各种实际场景中展现出优异的性能。

Abstract: Multi-agent games in dynamic nonlinear settings are challenging due to the
time-varying interactions among the agents and the non-stationarity of the
(potential) Nash equilibria. In this paper we consider model-free games, where
agent transitions and costs are observed without knowledge of the transition
and cost functions that generate them. We propose a policy gradient approach to
learn distributed policies that follow the communication structure in
multi-team games, with multiple agents per team. Our formulation is inspired by
the structure of distributed policies in linear quadratic games, which take the
form of time-varying linear feedback gains. In the nonlinear case, we model the
policies as nonlinear feedback gains, parameterized by self-attention layers to
account for the time-varying multi-agent communication topology. We demonstrate
that our distributed policy gradient approach achieves strong performance in
several settings, including distributed linear and nonlinear regulation, and
simulated and real multi-robot pursuit-and-evasion games.

</details>


### [293] [Compositional System Dynamics: The Higher Mathematics Underlying System Dynamics Diagrams & Practice](https://arxiv.org/abs/2509.18475)
*Xiaoyan Li,Evan Patterson,Patricia L. Mabry,Nathaniel D. Osgood*

Main category: eess.SY

TL;DR: 该工作利用范畴论为组合系统动力学建模建立了坚实的数学基础，以形式化和增强系统模型的表示、分析和组合。


<details>
  <summary>Details</summary>
Motivation: 现有系统动力学建模缺乏强大的数学结构，难以实现可伸缩、透明和系统的推理。研究旨在提供一个严谨的数学框架，以应对复杂系统建模的挑战，并支持模块化组合、分层和多样化的语义表示。

Method: 将系统动力学图（如存量-流量图、因果回路图）形式化为范畴构造，使用带属性的C-集将这些图编码为数据，并利用结构化余跨、推论、拉回和函子映射等高级范畴工具来实现模型的组合和分析。

Result: 该框架支持模块化组合、分层、语法与语义之间的无缝映射，有助于识别路径和反馈回路、检测复杂图中的简单模式、识别图之间的共同结构以及不同图类型之间的结构保持映射。它还支持除传统常微分方程之外的替代语义（如随机转移动力学），并在组合建模、模块化和团队协作中展示了实际优势。

Conclusion: 该工作揭示并形式化了系统动力学图中隐藏的数学结构，为从业者提供了清晰、可伸缩和严谨的工具，以应对复杂系统，并为未来的混合和基于代理建模以及时态推理提供了扩展方向。

Abstract: This work establishes a robust mathematical foundation for compositional
System Dynamics modeling, leveraging category theory to formalize and enhance
the representation, analysis, and composition of system models. Here, System
Dynamics diagrams, such as stock & flow diagrams, system structure diagrams,
and causal loop diagrams, are formulated as categorical constructs, enabling
scalable, transparent, and systematic reasoning. By encoding these diagrams as
data using attributed C-sets and utilizing advanced categorical tools like
structured cospans, pushouts, pullbacks, and functor mappings, the framework
supports modular composition, stratification, and seamless mapping between
syntax and semantics.
  The approach underwrites traditional practice with firm mathematical
structure, facilitates the identification of certain forms of pathways and
feedback loops, the detection of simple patterns within complex diagrams,
common structure between diagrams, and structure-preserving mappings between
diverse diagram types. Additionally, this framework supports alternative
semantics, such as stochastic transition dynamics, extending beyond traditional
ordinary differential equation (ODE) representations. Applications in
compositional modeling, modularity, and team-based collaboration demonstrate
the practical advantages of this advanced framework.
  Future directions include integrating dimensional annotations, supporting
hybrid and agent-based modeling paradigms, and expanding the framework's
applicability to global and local temporal reasoning through temporal sheaves.
By revealing and formalizing the hidden mathematical structure of System
Dynamics diagrams, this work empowers practitioners to tackle complex systems
with clarity, scalability, and rigor.

</details>


### [294] [Refined Barrier Conditions for Finite-Time Safety and Reach-Avoid Guarantees in Stochastic Systems](https://arxiv.org/abs/2509.18518)
*Bai Xue,Luke Ong,Dominik Wagner,Peixin Wang*

Main category: eess.SY

TL;DR: 本文提出了一种改进的类障碍条件，取消了辅助函数的有界性假设，从而能够为离散时间系统的有限时间安全概率和连续时间系统的有限时间到达-规避概率提供保证。


<details>
  <summary>Details</summary>
Motivation: 现有的障碍证书方法常依赖辅助函数的限制性有界性假设，这限制了它们在安全关键型随机系统中的应用范围。

Method: 通过建立新的类障碍条件，本文移除了辅助函数的有界性假设。具体来说，针对离散时间系统推导了有限时间安全概率的上限，针对连续时间系统推导了有限时间到达-规避概率的下限。

Result: 这一关键的放松显著扩展了可验证系统的类别，特别是对于无界状态空间系统，并促进了半定规划等先进优化技术的应用。方法有效性已通过数值例子验证。

Conclusion: 所提出的方法通过移除有界性假设，极大地扩展了障碍证书在随机系统安全性和到达-规避问题中的适用性，尤其是在处理无界状态空间时，并支持更先进的优化技术。

Abstract: Providing finite-time probabilistic safety and reach-avoid guarantees is
crucial for safety-critical stochastic systems. Existing barrier certificate
methods often rely on a restrictive boundedness assumption for auxiliary
functions, limiting their applicability. This paper presents refined
barrier-like conditions that remove this assumption. Specifically, we establish
conditions for deriving upper bounds on finite-time safety probabilities in
discrete-time systems and lower bounds on finite-time reach-avoid probabilities
in continuous-time systems. This key relaxation significantly expands the class
of verifiable systems, especially those with unbounded state spaces, and
facilitates the application of advanced optimization techniques, such as
semi-definite programming with polynomial functions. The efficacy of our
approach is validated through numerical examples.

</details>


### [295] [AI Agent Access (A\^3) Network: An Embodied, Communication-Aware Multi-Agent Framework for 6G Coverage](https://arxiv.org/abs/2509.18526)
*Han Zeng,Haibo Wang,Luhao Fan,Bingcheng Zhu,Xiaohu You,Zaichen Zhang*

Main category: eess.SY

TL;DR: 针对6G无基础设施环境的自主弹性网络需求，本文提出A^3网络，一个统一、去中心化、端到端的多智能体强化学习框架，将探索、用户接入和回传维护整合到单一学习过程，支持运行时智能体添加，并通过通信指标优化拓扑形成，实现了探索与通信效率的平衡以及系统级适应性。


<details>
  <summary>Details</summary>
Motivation: 6G通信要求在无固定基础设施的环境中实现自主和弹性的网络。然而，大多数多智能体强化学习（MARL）方法只关注孤立的阶段（如探索、中继形成或接入），且在静态部署和集中控制下运行，这限制了它们的适应性。

Method: 本文提出了AI Agent Access (A^3) 网络，这是一个统一的、具身智能驱动的框架，将多智能体网络转化为动态、去中心化和端到端的系统。它将探索、目标用户接入和回传维护整合到单一学习过程中，并支持在运行时按需添加智能体。A^3网络采用去中心化策略，使单个智能体能够在有限观测下独立运行，同时协调智能体实现可扩展、通信优化的覆盖。通过将链路级通信指标嵌入到Actor-Critic学习中，A^3网络将拓扑形成与鲁棒决策相结合。

Result: 数值模拟表明，A^3网络不仅能在探索和通信效率之间取得平衡，而且还提供了现有MARL框架所缺乏的系统级适应性。

Conclusion: A^3网络为6G多智能体网络提供了一个新的范式，通过其统一的、去中心化的和端到端的方法，解决了现有MARL方案的局限性。

Abstract: The vision of 6G communication demands autonomous and resilient networking in
environments without fixed infrastructure. Yet most multi-agent reinforcement
learning (MARL) approaches focus on isolated stages - exploration, relay
formation, or access - under static deployments and centralized control,
limiting adaptability. We propose the AI Agent Access (A\^3) Network, a
unified, embodied intelligence-driven framework that transforms multi-agent
networking into a dynamic, decentralized, and end-to-end system. Unlike prior
schemes, the A\^3 Network integrates exploration, target user access, and
backhaul maintenance within a single learning process, while supporting
on-demand agent addition during runtime. Its decentralized policies ensure that
even a single agent can operate independently with limited observations, while
coordinated agents achieve scalable, communication-optimized coverage. By
embedding link-level communication metrics into actor-critic learning, the A\^3
Network couples topology formation with robust decision-making. Numerical
simulations demonstrate that the A\^3 Network not only balances exploration and
communication efficiency but also delivers system-level adaptability absent in
existing MARL frameworks, offering a new paradigm for 6G multi-agent networks.

</details>


### [296] [Interaction-aware Lane-Changing Early Warning System in Congested Traffic](https://arxiv.org/abs/2509.18624)
*Yue Zhang,Xinzhi Zhong,Soyoung Ahn,Yajie Zou,Zhengbing He*

Main category: eess.SY

TL;DR: 本文提出了一种交互感知的变道预警（LCEW）系统，通过基于互信息（MI）的社交时空图卷积神经网络（STGCNN-MI）预测多车辆轨迹，识别潜在碰撞，从而提供可靠的早期预警信号，以提高交通安全和效率。


<details>
  <summary>Details</summary>
Motivation: 拥堵交通中的变道行为复杂，涉及多车辆交互，并带来严重的安全隐患。提供早期预警可以实现更主动的驾驶辅助系统，并支持驾驶员在变道时做出更明智的决策。

Method: 1. 调查变道的随机性，包括可变大小的多车辆交互以及由此产生的直接和间接风险。
2. 引入基于互信息（MI）的社交时空图卷积神经网络（STGCNN-MI）框架来预测多车辆轨迹，该框架利用MI基邻接矩阵增强预测精度并提供可解释的车辆交互表示。
3. 使用应用于预测轨迹的定向包围盒检测来识别变道车辆与相邻车辆之间的潜在碰撞（直接风险）或非相邻车辆之间的潜在碰撞（间接风险）。
4. 生成警告信号，通知变道驾驶员预测时间窗内潜在碰撞的位置。
5. 在SUMO交通模拟中进行实验验证。

Result: 所提出的交互感知LCEW系统在SUMO交通模拟中表现出显著效果，它同时提高了车辆级别的安全性和整体交通效率，并促进了更自然的驾驶行为适应。

Conclusion: 该交互感知变道早期预警系统通过准确的多车辆未来轨迹预测，能够提供可靠的早期预警信号，有效提升拥堵交通中变道的安全性，并改善整体交通效率和驾驶行为适应性。

Abstract: Lane changes (LCs) in congested traffic are complex, multi-vehicle
interactive events that pose significant safety concerns. Providing early
warnings can enable more proactive driver assistance system and support more
informed decision-making for drivers under LCs. This paper presents an
interaction-aware Lane-Changing Early Warning (LCEW) system designed to issue
reliable early warning signals based on future trajectory predictions. We first
investigate the stochastic nature of LCs, characterized by (i) variable-size
multi-vehicle interactions and (ii) the direct and indirect risks resulting
from these interactions. To model these stochastic interactions, a Social
Spatio-Temporal Graph Convolutional Neural Network framework informed by mutual
information (STGCNN-MI) is introduced to predict multi-vehicle trajectories. By
leveraging a MI-based adjacency matrix, the framework enhances trajectory
prediction accuracy while providing interpretable representations of vehicle
interactions. Then, potential collisions between the LC vehicle and adjacent
vehicles (direct risks) or among the non-adjacent vehicles (indirect risks) are
identified using oriented bounding box detection applied to the predicted
trajectories. Finally, a warning signal is generated to inform the LC driver of
location of potential collisions within the predicted time window. Traffic
simulation experiments conducted in SUMO demonstrate that the proposed
interaction-aware LCEW improves both vehicle-level safety and overall traffic
efficiency, while also promoting more natural behavioral adaptation.

</details>


### [297] [Dual Iterative Learning Control for Multiple-Input Multiple-Output Dynamics with Validation in Robotic Systems](https://arxiv.org/abs/2509.18723)
*Jan-Hendrik Ewering,Alessandro Papa,Simon F. G. Ehlers,Thomas Seel,Michael Meindl*

Main category: eess.SY

TL;DR: 本文提出了一种名为MIMO双迭代学习控制（DILC）的新型数据驱动迭代学习方案，用于重复性MIMO系统中的同步跟踪控制和模型学习，无需先验系统知识或手动参数调整，并在模拟和实际系统中展现出快速、自主的学习能力。


<details>
  <summary>Details</summary>
Motivation: 在智能真实世界系统中，自主准确地解决运动任务是核心能力。实现跨系统和任务的真正自主性，面临的关键挑战包括应对未知动态以及克服手动参数调优的需求，这在复杂的多输入多输出（MIMO）系统中尤为重要。

Method: 本文提出了MIMO双迭代学习控制（DILC），这是一种新颖的数据驱动迭代学习方案，用于同时进行跟踪控制和模型学习，无需任何先验系统知识或手动参数调优。该方法专为重复性MIMO系统设计，并能与现有迭代学习控制方法无缝集成。文中还提供了线性时不变系统中参考跟踪误差和模型误差的单调收敛条件。

Result: DILC方案在工业机器人高保真模拟和多个非线性真实世界MIMO系统中，无需模型知识或手动调整算法，即可快速自主地解决各种运动任务。实验表明，许多参考跟踪任务在10-20次试验内即可解决，即使是复杂的运动也能在不到100次迭代中学会。

Conclusion: 鉴于其快速和自主的学习能力，DILC有潜力成为智能真实世界系统中复杂学习框架内的一个高效构建模块。

Abstract: Solving motion tasks autonomously and accurately is a core ability for
intelligent real-world systems. To achieve genuine autonomy across multiple
systems and tasks, key challenges include coping with unknown dynamics and
overcoming the need for manual parameter tuning, which is especially crucial in
complex Multiple-Input Multiple-Output (MIMO) systems.
  This paper presents MIMO Dual Iterative Learning Control (DILC), a novel
data-driven iterative learning scheme for simultaneous tracking control and
model learning, without requiring any prior system knowledge or manual
parameter tuning. The method is designed for repetitive MIMO systems and
integrates seamlessly with established iterative learning control methods. We
provide monotonic convergence conditions for both reference tracking error and
model error in linear time-invariant systems.
  The DILC scheme -- rapidly and autonomously -- solves various motion tasks in
high-fidelity simulations of an industrial robot and in multiple nonlinear
real-world MIMO systems, without requiring model knowledge or manually tuning
the algorithm. In our experiments, many reference tracking tasks are solved
within 10-20 trials, and even complex motions are learned in less than 100
iterations. We believe that, because of its rapid and autonomous learning
capabilities, DILC has the potential to serve as an efficient building block
within complex learning frameworks for intelligent real-world systems.

</details>


### [298] [An Extended Kalman Filter for Systems with Infinite-Dimensional Measurements](https://arxiv.org/abs/2509.18749)
*Maxwell M. Varley,Timothy L. Molloy,Girish N. Nair*

Main category: eess.SY

TL;DR: 本文提出了一种针对具有无限维测量的离散时间非线性随机系统的扩展卡尔曼滤波器（EKF），并证明其测量雅可比矩阵对应于图像梯度，为基于视觉的状态估计中的图像梯度使用提供了理论依据，并在无人机定位任务中表现优于VINS-MONO。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于现实世界中基于视觉的定位和跟踪应用，这些应用通常涉及有限维状态和无限维测量（如图像），需要有效的状态估计方法。

Method: 研究开发了一种扩展卡尔曼滤波器（EKF），用于实时状态估计。其中，测量噪声被建模为无限维随机场。在基于视觉的状态估计中，EKF所需的测量雅可比矩阵被证明对应于图像梯度。

Result: 结果表明，该EKF为在基于视觉的状态估计中使用图像梯度作为特征提供了新颖的系统理论依据。在涉及无人机定位的公共真实世界数据集中，该EKF在某些情况下表现优于已有的视觉惯性里程计算法VINS-MONO，均方误差降低可达一个数量级。

Conclusion: 研究结论是，所开发的EKF在理论上为图像梯度在基于视觉的状态估计中的使用提供了坚实基础，并且在实际应用中，尤其是在无人机定位等任务中，展现出显著的性能提升和实用价值。

Abstract: This article examines state estimation in discrete-time nonlinear stochastic
systems with finite-dimensional states and infinite-dimensional measurements,
motivated by real-world applications such as vision-based localization and
tracking. We develop an extended Kalman filter (EKF) for real-time state
estimation, with the measurement noise modeled as an infinite-dimensional
random field. When applied to vision-based state estimation, the measurement
Jacobians required to implement the EKF are shown to correspond to image
gradients. This result provides a novel system-theoretic justification for the
use of image gradients as features for vision-based state estimation,
contrasting with their (often heuristic) introduction in many computer-vision
pipelines. We demonstrate the practical utility of the EKF on a public
real-world dataset involving the localization of an aerial drone using video
from a downward-facing monocular camera. The EKF is shown to outperform
VINS-MONO, an established visual-inertial odometry algorithm, in some cases
achieving mean squared error reductions of up to an order of magnitude.

</details>


### [299] [Integration of Concentrated Solar Power Plants in Renewable-Only VPP with Electrical and Thermal Demands: A Two-Stage Robust Bidding Approach](https://arxiv.org/abs/2509.18769)
*Hadi Nemati,Pedro Sánchez-Martín,Álvaro Ortega,Lukas Sigrist,Luis Rouco*

Main category: eess.SY

TL;DR: 本文提出将聚光太阳能热发电厂（CSP）整合到纯可再生能源虚拟电厂（RVPP）中，通过两阶段鲁棒优化方法应对多重不确定性，以参与日前和二次备用电力市场以及热能交易，结果显示这能增强RVPP的灵活性并提高盈利能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在应对纯可再生能源虚拟电厂在电力和热能市场中面临的多种不确定性（如电价、可再生能源产量、需求等），并探索整合聚光太阳能热发电厂（CSP）如何增强RVPP的灵活性和盈利能力。

Method: 采用重新表述的两阶段鲁棒优化方法，以处理多种不确定性。CSP的热储能通过可调节方法建模，根据RVPP的盈利能力分配能量用于向上和向下备用。通过多个案例研究进行模拟，以验证方法在不同操作决策和交易策略下的有效性和计算效率。

Result: 模拟结果表明，将CSP整合到RVPP中显著增强了RVPP在电力和热能交易方面的灵活性。此外，当考虑所有交易选项时，RVPP的盈利能力有所提高，且这种提升在RVPP运营商针对不确定参数采取不同保守程度时依然成立。

Conclusion: 将聚光太阳能热发电厂（CSP）整合到纯可再生能源虚拟电厂（RVPP）中，通过参与电力和热能市场，能够有效增强RVPP的灵活性并提高其盈利能力，尤其是在面对多重不确定性时。

Abstract: This paper proposes the integration of Concentrated Solar Power Plant (CSP)
in the Renewable-only virtual power plant (RVPP) for bidding in the electricity
day-ahead and secondary reserve markets, as well as trading thermal energy
through a heat purchase agreement. A reformulated two-stage robust optimization
approach is introduced to account for multiple uncertainties, including
electricity prices, non-dispatchable renewable energy sources electrical
production, CSP thermal production, and uncertainties in electrical and thermal
demand consumption. The provision of energy and reserve by the thermal storage
of CSP is modeled using an adjustable approach, which allocates a share of
energy for up and down reserves based on the profitability of the RVPP.
Simulations are conducted for several case studies to demonstrate the
effectiveness and computational efficiency of the proposed approach under
different RVPP operator decisions against uncertain parameters and various
trading strategies for electricity and thermal energy. The simulation results
show that integrating CSP into RVPP enhances RVPP flexibility for both
electrical and thermal trading. Furthermore, the results indicate that the
profitability of the RVPP increases when all trading options are considered,
across different levels of conservatism adopted by the RVPP operator in
response to uncertain parameters.

</details>


### [300] [Frequency-Varying Optimization: A Control Framework for New Dynamic Frequency Response Services](https://arxiv.org/abs/2509.18935)
*Yiqiao Xu,Quan Wan,Alessandra Parisio*

Main category: eess.SY

TL;DR: 为应对可再生能源发电的波动性，本文提出了一种针对聚合响应单元（ARU）的分布式控制框架，通过将频率变动优化（FVO）问题重构为最优轨迹跟踪（TOT）问题，实现在线优化协调大量资产，以满足电网频率响应需求。


<details>
  <summary>Details</summary>
Motivation: 可再生能源发电的波动性促使全球范围内推出更快、更有效的频率响应措施。在英国，国家能源系统运营商（NESO）引入了新的动态服务，其中资产聚合（ARU）扮演关键角色。ARU面临的挑战是，其所需的频率响应水平随电网频率变化，导致资产需要集体满足一个频率变化的等式约束。

Method: 研究将ARU的最佳协调问题构建为频率变动优化（FVO）问题，其中每个资产的最佳轨迹动态演变。为便于在线优化，FVO问题被重新表述为最优轨迹跟踪（TOT）问题，并针对两种场景提出了算法：一是资产动态可忽略不计，二是资产动态必须考虑在内。该框架被设计为易于分布式部署。

Result: 在合理条件下，ARU能在固定时间内收敛到最优轨迹，并满足NESO要求的最大响应交付时间。数值结果验证了所提出的控制框架的有效性和可扩展性。

Conclusion: 所提出的分布式控制框架能够有效且可扩展地协调大量聚合资产，以提供快速的频率响应，满足电网对可再生能源并网的需求，并在规定时间内达到最优性能。

Abstract: To address the variability of renewable generation, initiatives have been
launched globally to provide faster and more effective frequency responses. In
the UK, the National Energy System Operator (NESO) has introduced a suite of
three new dynamic services, where aggregation of assets is expected to play a
key role. For an Aggregated Response Unit (ARU), the required level of
frequency response varies with grid frequency, resulting in a frequency-varying
equality constraint that assets should meet collectively. We show that the
optimal coordination of an ARU constitutes a Frequency-Varying Optimization
(FVO) problem, in which the optimal trajectory for each asset evolves
dynamically. To facilitate online optimization, we reformulate the FVO problem
into Tracking of the Optimal Trajectory (TOT) problems, with algorithms
proposed for two scenarios: one where the asset dynamics are negligible, and
another where they must be accounted for. Under reasonable conditions, the ARU
converges to the optimal trajectory within a fixed time, and within the maximum
delivery time requested by NESO. The proposed framework can be readily
distributed to coordinate a large number of assets. Numerical results verify
the effectiveness and scalability of the proposed control framework.

</details>


### [301] [Adaptive Override Control under High-Relative-Degree Nonovershooting Constraints](https://arxiv.org/abs/2509.18988)
*Ziliang Lyu,Miroslav Krstic,Kaixin Lu,Yiguang Hong,Lihua Xie*

Main category: eess.SY

TL;DR: 本文提出一种模块化设计方法，用于在存在高相对度非超调约束和参数不确定性的情况下，自适应地覆盖标称控制器的不安全动作，实现安全违规的有界性和参数估计的收敛。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了解决在存在高相对度非超调约束和参数不确定性时，如何自适应地覆盖标称控制器可能产生的不安全动作，同时避免设计与参数估计误差的高阶导数耦合的问题。

Method: 采用模块化设计方法，将控制器和参数识别器分开设计。控制器模块确保在参数估计误差及其一阶导数有界或平方可积的条件下，由参数不确定性引起的安全违规保持有界。识别器模块则保证满足参数估计误差的这些要求。

Result: 理论分析和仿真结果表明，闭环安全违规由初始估计误差的可调函数所限制。此外，随着时间的增加，参数估计收敛到真实值，安全违规量也相应减少。

Conclusion: 该模块化设计方法能够有效处理具有高相对度约束和参数不确定性的自适应安全覆盖问题，确保了安全违规的有界性，且其上限可调并与初始估计误差相关，同时实现了参数估计的收敛和安全违规的减少。

Abstract: This paper considers the problem of adaptively overriding unsafe actions of a
nominal controller in the presence of high-relative-degree nonovershooting
constraints and parametric uncertainties. To prevent the design from being
coupled with high-order derivatives of the parameter estimation error, we adopt
a modular design approach in which the controller and the parameter identifier
are designed separately. The controller module ensures that any safety
violations caused by parametric uncertainties remain bounded, provided that the
parameter estimation error and its first-order derivative are either bounded or
square-integrable. The identifier module, in turn, guarantees that these
requirements on the parameter estimation error are satisfied. Both theoretical
analysis and simulation results demonstrate that the closed-loop safety
violation is bounded by a tunable function of the initial estimation error.
Moreover, as time increases, the parameter estimate converges to the true
value, and the amount of safety violation decreases accordingly.

</details>


### [302] [A Weighted Least Squares Error Hetero-functional Graph State Estimator of the American Multi-modal Energy System](https://arxiv.org/abs/2509.19045)
*Dakota Thompson,Amro M. Farid*

Main category: eess.SY

TL;DR: 为应对气候变化，本文分析了美国多模式能源系统（AMES）的行为和关键物质与能量流。通过将状态估计方法与异质功能图理论（HFGT）结合，首次提出了加权最小二乘误差异质功能图状态估计（WLSEHFGSE）优化程序，以资产级粒度估计AMES中的物质和能量流。


<details>
  <summary>Details</summary>
Motivation: 21世纪全球气候变化是紧迫挑战，需要对电力、天然气、石油和煤炭等关键能源基础设施进行变革。为了制定有效的政策，需要理解美国多模式能源系统（AMES）在结构和行为上的相互依赖性。

Method: 本文侧重于行为分析方法，以数据驱动和基于模型的系统工程方法，结合异质功能图理论（HFGT）。具体而言，建模了AMES的两个区域，并开发了一种加权最小二乘误差异质功能图状态估计（WLSEHFGSE）优化程序，以估计通过AMES的物质和能量的最佳流量。该方法将状态估计分析从单一的电网环境扩展到AMES的异质环境。

Result: 开发了WLSEHFGSE优化程序，用于估计通过AMES的最佳物质和能量流。这是首次将状态估计方法与HFGT集成。该方法能够以资产级粒度恢复AMES等系统中的物质和能量流。

Conclusion: 通过将状态估计方法与异质功能图理论（HFGT）相结合，本文提出的WLSEHFGSE方法能够有效地分析和恢复美国多模式能源系统（AMES）中具有资产级粒度的物质和能量流，这对于应对气候变化的政策制定至关重要。

Abstract: As one of the most pressing challenges of the 21st century, global climate
change demands a host of changes across at least four critical energy
infrastructures: the electric grid, the natural gas system, the oil system, and
the coal system. In the context of the United States, this paper refers to this
system-of-systems as ``The American Multi-Modal Energy System (AMES)". These
combined changes necessitate an understanding of the AMES interdependencies,
both structurally and behaviorally, to develop and enact effective policies.
This work focuses on behavioral analysis methods to provide examples of how to
analyze system behavior and the critical matter and energy flows through the
system. Building upon past works, two regions of the AMES are modeled, and
their behavior is analyzed using Hetero-functional Graph Theory (HFGT). More
specifically, the work presents a weighted least square error state estimation
model of the AMES. State estimation has played a major role in the operation
and development of the American Electric Power System. This work extends the
state estimation analysis beyond the single-operand electric grid environment
into the heterogeneous environment of the AMES. Employing a data-driven and
model-based systems engineering approach in combination with HFGT, a Weighted
Least Squares Error Hetero-functional Graph State Estimation (WLSEHFGSE)
optimization program is developed to estimate the optimal flows of mass and
energy through the AMES. This work is the first to integrate state estimation
methods with HFGT. Furthermore, it demonstrates how such a WLSEHFGSE recovers
the mass and energy flows in a system-of-systems like the AMES with asset-level
granularity.

</details>


### [303] [MAPPO for Edge Server Monitoring](https://arxiv.org/abs/2509.19079)
*Samuel Chamoun,Christian McDowell,Robin Buchanan,Kevin Chan,Eric Graves,Yin Sun*

Main category: eess.SY

TL;DR: 本文提出了一种基于MAPPO的分布式决策算法，用于边缘服务器监控中的查询调度与任务分派，通过结合主动查询和任务反馈，在动态工作负载下实现了吞吐量与通信开销的优异权衡。


<details>
  <summary>Details</summary>
Motivation: 在边缘服务器监控中，任务间歇性到达，需要分配给具有有限队列和时变可用性的共享服务器。准确的服务器状态知识对于维持高吞吐量至关重要，但在动态工作负载和部分可观测性下，获取准确状态具有挑战性。

Method: 每个调度器通过两种机制维护服务器知识：(i) 主动状态查询（有通信成本）和 (ii) 任务执行反馈（机会性揭示状态）。将此问题公式化为合作多智能体分布式决策问题，并提出了一种基于多智能体近端策略优化（MAPPO）的算法，该算法利用集中式训练和分散式执行（CTDE）来学习分布式查询和分派策略。

Result: 数值评估表明，MAPPO算法实现了卓越的吞吐量-成本权衡，显著优于基线策略，平均比最接近的基线提高了30%。

Conclusion: 所提出的MAPPO算法能有效解决边缘服务器监控中的查询调度与任务分派问题，在动态和部分可观测环境下，显著提升了系统性能，优化了吞吐量与通信开销之间的平衡。

Abstract: In this paper, we consider a goal-oriented communication problem for edge
server monitoring, where jobs arrive intermittently at multiple dispatchers and
must be assigned to shared edge servers with finite queues and time-varying
availability. Accurate knowledge of server status is critical for sustaining
high throughput, yet remains challenging under dynamic workloads and partial
observability. To address this challenge, each dispatcher maintains server
knowledge through two complementary mechanisms: (i) active status queries that
provide instantaneous updates at a communication cost, and (ii) job execution
feedback that reveals server conditions opportunistically. We formulate a
cooperative multi-agent distributed decision-making problem in which
dispatchers jointly optimize query scheduling to balance throughput against
communication overhead. To solve this problem, we propose a Multi-Agent
Proximal Policy Optimization (MAPPO)-based algorithm that leverages centralized
training with decentralized execution (CTDE) to learn distributed
query-and-dispatch policies under partial and stale observations. Numerical
evaluations show that MAPPO achieves superior throughput-cost tradeoffs and
significantly outperforms baseline strategies, achieving on average a 30%
improvement over the closest baseline.

</details>


### [304] [AI-Enabled Smart Hygiene System for Real-Time Glucose Detection](https://arxiv.org/abs/2509.19107)
*Khan Masood Parvez,Sk Md Abidar Rahaman,Ali Shiri Sichani,Hadi AliAkbarpour*

Main category: eess.SY

TL;DR: 本研究提出了一种基于共面波导槽环天线生物传感器的智能泌尿健康监测系统，通过测量尿液样本引起的谐振频率偏移来检测泌尿生物标志物，并讨论了结合CNN-LSTM框架以提高检测准确性，最终应用于智能马桶系统实现无感实时健康监测。


<details>
  <summary>Details</summary>
Motivation: 开发一种无需用户努力或行为改变，能够实时、准确监测泌尿健康的系统，并解决传统方法中频率响应重叠导致的检测局限性。

Method: 该研究采用了一种共面波导 (CPW) 馈电的槽环天线生物传感器，用于分析各种尿液样本。该天线通过检测尿液条件引起的谐振频率偏移（偏离基准1.42 GHz）来识别泌尿生物标志物。此外，研究还讨论了一个潜在的基于人工智能的卷积神经网络长短期记忆 (CNN-LSTM) 框架，旨在克服频率响应重叠的限制，从而提高健康状况检测的准确性。这些组件将整合到一个智能马桶系统中，在壁挂式小便器屏幕上显示实时健康信息。

Result: 该天线在暴露于五种特定尿液条件下时，表现出明显的谐振频率偏移，偏离其基线1.42 GHz的运行频率。这些可测量的频率变化使得天线能够作为一种有效的微波传感器，用于泌尿生物标志物的检测。

Conclusion: 这些组件的结合有助于开发一个智能马桶系统，该系统能够在不要求用户付出任何努力或改变行为的情况下，在壁挂式小便器屏幕上显示实时健康信息，从而实现高效、准确的泌尿健康监测，并有望通过AI框架进一步提升检测精度。

Abstract: This research presents a smart urinary health monitoring system incorporating
a coplanar waveguide (CPW)-fed slot-loop antenna biosensor designed to analyse
various urine samples. The antenna demonstrates distinct resonant frequency
shifts when exposed to five specific urine conditions, deviating from its
baseline 1.42 GHz operation. These measurable frequency variations enable the
antenna to function as an effective microwave sensor for urinary biomarker
detection. A potential artificial intelligence-based Convolutional Neural
Networks Long Short-Term Memory (CNN-LSTM) framework is also discussed to
overcome the limitations of overlapping frequency responses, aiming to improve
the accuracy of health condition detection. These components contribute to the
development of a smart toilet system that displays real-time health information
on a wall-mounted urinal screen, without requiring any user effort or
behavioural change.

</details>


### [305] [A Fast Initialization Method for Neural Network Controllers: A Case Study of Image-based Visual Servoing Control for the multicopter Interception](https://arxiv.org/abs/2509.19110)
*Chenxu Ke,Congling Tian,Kaichen Xu,Ye Li,Lingcong Bao*

Main category: eess.SY

TL;DR: 本文提出了一种基于系统模型构建符合稳定性条件数据集的神经网络快速初始化方法，用于稳定控制策略的初始训练，并通过多旋翼拦截案例进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习控制器设计方法需要大量数据、训练随机且收敛慢；基于Lyapunov的控制方法需要初始稳定的神经网络策略。一个稳定的初始神经网络控制器可以改善这两种方法的训练效率和性能。传统控制理论在处理复杂问题时需要丰富的专业知识。

Method: 本文提出了一种神经网络快速初始化方法。该方法通过根据系统模型构建符合稳定性条件的数据集，实现神经网络控制策略的初始训练。

Result: 通过对多旋翼拦截的图像视觉伺服控制进行仿真和实验，验证了所提出方法的有效性和实际性能。在实验中，训练后的控制策略实现了15米/秒的最终拦截速度。

Conclusion: 所提出的神经网络快速初始化方法能够有效生成稳定的初始控制策略，从而提高基于学习的控制方法的训练效率和性能，减少对专家知识的依赖。

Abstract: Reinforcement learning-based controller design methods often require
substantial data in the initial training phase. Moreover, the training process
tends to exhibit strong randomness and slow convergence. It often requires
considerable time or high computational resources. Another class of
learning-based method incorporates Lyapunov stability theory to obtain a
control policy with stability guarantees. However, these methods generally
require an initially stable neural network control policy at the beginning of
training. Evidently, a stable neural network controller can not only serve as
an initial policy for reinforcement learning, allowing the training to focus on
improving controller performance, but also act as an initial state for
learning-based Lyapunov control methods. Although stable controllers can be
designed using traditional control theory, designers still need to have a great
deal of control design knowledge to address increasingly complicated control
problems. The proposed neural network rapid initialization method in this paper
achieves the initial training of the neural network control policy by
constructing datasets that conform to the stability conditions based on the
system model. Furthermore, using the image-based visual servoing control for
multicopter interception as a case study, simulations and experiments were
conducted to validate the effectiveness and practical performance of the
proposed method. In the experiment, the trained control policy attains a final
interception velocity of 15 m/s.

</details>


### [306] [Robust Synchronous Reference Frame Phase-Looked Loop (PLL) with Feed-Forward Frequency Estimation](https://arxiv.org/abs/2509.19111)
*Michael Ruderman,Elia Brescia,Paolo Roberto Massenio,Giuseppe Leonardo Cascella,David Naso*

Main category: eess.SY

TL;DR: 本文提出了一种鲁棒的同步参考系锁相环（SRF-PLL）设计，结合了PI控制和无模型前馈频率估计器，以提高在噪声和时变谐波信号下的瞬态性能和频率跟踪能力。


<details>
  <summary>Details</summary>
Motivation: 同步参考系锁相环（SRF-PLL）广泛应用于电力系统和能源转换的接口和控制。然而，其频率和相位角的锁定性能受反馈环路和输入信号失真的影响。因此，需要一种鲁棒的设计来改善在噪声和时变谐波信号下的瞬态行为和频率斜坡跟踪。

Method: 该研究采用以下方法：1) 对传统的PI控制SRF-PLL进行了鲁棒设计，旨在最大化相位裕度。2) 使用归一化方案使环路对输入幅度变化不敏感。3) 引入了一个鲁棒的、无模型的前馈频率估计器，以改善瞬态行为和频率斜坡跟踪，该估计器适用于噪声和时变谐波信号。4) 在标准永磁同步电机（PMSM）驱动器（具有变化的角速度和负载）产生的3相谐波电流上对所提出的前馈-反馈SRF-PLL方案进行了实验评估。

Result: 实验结果表明，所提出的前馈-反馈SRF-PLL方案在跟踪角频率和锁定相位角方面均表现出显著的性能提升，尤其是在处理来自PMSM驱动器的有噪声和时变谐波电流时。

Conclusion: 通过结合鲁棒的PI控制和无模型前馈频率估计器，所提出的SRF-PLL方案在噪声和时变谐波信号下展现出更优异的瞬态响应和频率跟踪能力，为电力系统和能源转换应用提供了更可靠的同步解决方案。

Abstract: Synchronous reference frame phase-looked loop (SRF-PLL) techniques are widely
used for interfacing and control applications in the power systems and energy
conversion at large. Since a PLL system synchronizes its output with an
exogenous harmonic signal, often 3-phases voltage or current, the locking of
the frequency and phase angle depends on the performance of the feedback loop
with at least two integrator terms, and on the distortions of the measured
input quantities. For the conventional SRF-PLL with a proportional-integral
(PI) control in feedback, we are providing a robust design which maximizes the
phase margin and uses the normalization scheme for yielding the loop
insensitive to the input amplitude variations. The main improvement in the
transient behavior and also in tracking of frequency ramps is achieved by using
the robust feed-forward frequency estimator, which is model-free and suitable
for the noisy and time-varying harmonic signals. The proposed
feed-forward-feedback SRF-PLL scheme is experimentally evaluated on the
3-phases harmonic currents from standard PMSM drives with varying angular
speeds and loads. Both, the tracked angular frequency and locked phase angle
are assessed as performance metrics of the robust SRF-PLL scheme with
feedforwarding.

</details>


### [307] [Watts and Drops: Co-Scheduling Power and Water in Desalination Plants](https://arxiv.org/abs/2509.19243)
*Ahmed S. Alahmed,Audun Botterud,Saurabh Amin,Ali T. Al-Awami*

Main category: eess.SY

TL;DR: 本文提出一个数学框架，用于优化结合热能和膜技术的再生能源并置海水淡化厂的水电联合调度，以实现利润最大化。


<details>
  <summary>Details</summary>
Motivation: 旨在帮助利用可再生能源、整合热能和膜技术的脱盐厂实现利润最大化，通过优化其水和电力的生产与交易。

Method: 开发了一个数学框架来对价格接受型脱盐厂进行建模，该厂以给定价格向水务公司出售淡化水，并与电网进行双向电力交易，购买或出售电力。

Result: 最优调度策略依赖于工厂内部的可再生能源发电量，并遵循简单的阈值结构。在该最优策略下，基于热能的水产量随可再生能源产量单调递减，而基于膜技术的水产量则单调递增。

Conclusion: 最优调度策略呈现出简单的阈值结构，其特点是基于可再生能源输出，热能和膜技术产水之间存在反向的单调关系，这为利润最大化的水电联合调度提供了清晰的指导。

Abstract: We develop a mathematical framework to jointly schedule water and electricity
in a profit-maximizing renewable colocated water desalination plant that
integrates both thermal and membrane based technologies. The price-taking
desalination plant sells desalinated water to a water utility at a given price
and engages in bidirectional electricity transactions with the grid, purchasing
or selling power based on its net electricity demand. We show that the optimal
scheduling policy depends on the plant's internal renewable generation and
follows a simple threshold structure. Under the optimal policy, thermal based
water output decreases monotonically with renewable output, while membrane
based water output increases monotonically. We characterize the structure and
intuition behind the threshold policy and examine key special properties.

</details>


### [308] [Policy Gradient Bounds in Multitask LQR](https://arxiv.org/abs/2509.19266)
*Charis Stamouli,Leonardo F. Toso,Anastasios Tsiamis,George J. Pappas,James Anderson*

Main category: eess.SY

TL;DR: 本文分析了多任务线性二次调节（LQR）中策略梯度（policy gradient）的性能，并提出了基于双模拟（bisimulation）的任务异质性度量方法，以提供更精确的性能保证。


<details>
  <summary>Details</summary>
Motivation: 在多任务LQR中，目标是找到一个对所有任务都表现良好的控制器。现有的分析未能捕捉闭环任务的相似性，导致性能保证过于保守。因此，需要一种新的方法来量化并利用这些任务相似性。

Method: 作者提出了基于双模拟的任务异质性度量方法。这些度量利用新的双模拟函数来限制在通用稳定控制器下，一对任务之间闭环成本梯度距离。基于这些度量，作者推导了多任务最优控制器和渐进策略梯度控制器相对于每个任务的次优性界限，并给出了策略梯度迭代保持系统稳定的条件。

Result: 研究结果包括：为多任务最优控制器和渐进策略梯度控制器导出了次优性界限；提供了策略梯度迭代对每个系统保持稳定的条件。在多个随机任务集上，实验观察表明，所提出的基于双模拟的度量方法显著优于基线任务异质性度量方法。

Conclusion: 基于双模拟的度量方法能够有效捕捉多任务LQR中闭环任务的相似性，从而为策略梯度提供了更精确、更不保守的性能保证和稳定性分析。

Abstract: We analyze the performance of policy gradient in multitask linear quadratic
regulation (LQR), where the system and cost parameters differ across tasks. The
main goal of multitask LQR is to find a controller with satisfactory
performance on every task. Prior analyses on relevant contexts fail to capture
closed-loop task similarities, resulting in conservative performance
guarantees. To account for such similarities, we propose bisimulation-based
measures of task heterogeneity. Our measures employ new bisimulation functions
to bound the cost gradient distance between a pair of tasks in closed loop with
a common stabilizing controller. Employing these measures, we derive
suboptimality bounds for both the multitask optimal controller and the
asymptotic policy gradient controller with respect to each of the tasks. We
further provide conditions under which the policy gradient iterates remain
stabilizing for every system. For multiple random sets of certain tasks, we
observe that our bisimulation-based measures improve upon baseline measures of
task heterogeneity dramatically.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [309] [Measurement Score-Based MRI Reconstruction with Automatic Coil Sensitivity Estimation](https://arxiv.org/abs/2509.18402)
*Tingjun Liu,Chicago Y. Park,Yuyang Hu,Hongyu An,Ulugbek S. Kamilov*

Main category: eess.IV

TL;DR: 现有基于扩散模型的逆问题求解器（DIS）在并行MRI重建中表现出色，但依赖于预校准线圈灵敏度图（CSM）和真实图像，使其不切实际。本文提出C-MSM方法，通过联合自动CSM估计和自监督测量分数学习，消除了这些依赖，并在无需干净训练数据和预校准CSM的情况下，取得了与DIS相近的重建性能。


<details>
  <summary>Details</summary>
Motivation: 基于扩散模型的逆问题求解器（DIS）在压缩感知并行MRI重建中表现优异，但其依赖于预校准线圈灵敏度图（CSM）和真实图像。在严重欠采样下，CSM难以精确估计；真实图像通常也无法获取。这些限制使得现有方法在实际应用中不切实际。

Method: 本文提出了无校准测量分数扩散模型（C-MSM）。该方法通过以下方式消除了对预校准CSM和真实图像的依赖：1) 联合执行自动CSM估计；2) 直接从k空间数据进行测量分数的自监督学习。C-MSM通过对部分测量后验分数进行随机采样来近似完整后验分布，从而重建图像，并同时估计CSM。

Result: 在多线圈脑部fastMRI数据集上的实验表明，即使没有干净的训练数据和预校准CSM，C-MSM的重建性能也接近于使用干净扩散先验的DIS方法。

Conclusion: C-MSM成功解决了现有基于扩散模型的逆问题求解器在并行MRI重建中对预校准CSM和真实图像的依赖问题，显著提高了其实用性，同时保持了高水平的重建性能。

Abstract: Diffusion-based inverse problem solvers (DIS) have recently shown outstanding
performance in compressed-sensing parallel MRI reconstruction by combining
diffusion priors with physical measurement models. However, they typically rely
on pre-calibrated coil sensitivity maps (CSMs) and ground truth images, making
them often impractical: CSMs are difficult to estimate accurately under heavy
undersampling and ground-truth images are often unavailable. We propose
Calibration-free Measurement Score-based diffusion Model (C-MSM), a new method
that eliminates these dependencies by jointly performing automatic CSM
estimation and self-supervised learning of measurement scores directly from
k-space data. C-MSM reconstructs images by approximating the full posterior
distribution through stochastic sampling over partial measurement posterior
scores, while simultaneously estimating CSMs. Experiments on the multi-coil
brain fastMRI dataset show that C-MSM achieves reconstruction performance close
to DIS with clean diffusion priors -- even without access to clean training
data and pre-calibrated CSMs.

</details>


### [310] [Efficient Breast and Ovarian Cancer Classification via ViT-Based Preprocessing and Transfer Learning](https://arxiv.org/abs/2509.18553)
*Richa Rawat,Faisal Ahmed*

Main category: eess.IV

TL;DR: 本文提出了一种基于Vision Transformer (ViT) 的新方法，用于乳腺癌和卵巢癌的早期检测与分类，通过预训练模型微调和高效预处理，在二分类和多分类任务上均超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌和卵巢癌是女性面临的主要健康挑战。早期检测能显著提高生存率，但传统的手动影像学检查耗时、劳动密集且需要专业病理学家，效率低下。

Method: 研究引入了一种基于ViT的方法，使用预训练的ViT-Base-Patch16-224模型，并对其进行微调以执行二分类和多分类任务。该方法包含一个预处理流程，将原始组织病理学图像转换为标准化的PyTorch张量。模型在BreakHis数据集（二分类）和UBC-OCEAN数据集（五分类）上进行了评估，且未进行数据增强。

Result: 在二分类任务中，该模型超越了现有的CNN、ViT和基于拓扑数据分析的方法。在多分类任务中，它与最新的拓扑方法相比，也表现出卓越的性能。

Conclusion: 该研究强调了结合高效预处理的Vision Transformer迁移学习在肿瘤诊断中的有效性。

Abstract: Cancer is one of the leading health challenges for women, specifically breast
and ovarian cancer. Early detection can help improve the survival rate through
timely intervention and treatment. Traditional methods of detecting cancer
involve manually examining mammograms, CT scans, ultrasounds, and other imaging
types. However, this makes the process labor-intensive and requires the
expertise of trained pathologists. Hence, making it both time-consuming and
resource-intensive. In this paper, we introduce a novel vision transformer
(ViT)-based method for detecting and classifying breast and ovarian cancer. We
use a pre-trained ViT-Base-Patch16-224 model, which is fine-tuned for both
binary and multi-class classification tasks using publicly available
histopathological image datasets. Further, we use a preprocessing pipeline that
converts raw histophological images into standardized PyTorch tensors, which
are compatible with the ViT architecture and also help improve the model
performance. We evaluated the performance of our model on two benchmark
datasets: the BreakHis dataset for binary classification and the UBC-OCEAN
dataset for five-class classification without any data augmentation. Our model
surpasses existing CNN, ViT, and topological data analysis-based approaches in
binary classification. For multi-class classification, it is evaluated against
recent topological methods and demonstrates superior performance. Our study
highlights the effectiveness of Vision Transformer-based transfer learning
combined with efficient preprocessing in oncological diagnostics.

</details>


### [311] [HyperCool: Reducing Encoding Cost in Overfitted Codecs with Hypernetworks](https://arxiv.org/abs/2509.18748)
*Pep Borrell-Tatché,Till Aczel,Théo Ladune,Roger Wattenhofer*

Main category: eess.IV

TL;DR: HyperCool提出了一种超网络架构，通过为Cool-chic解码器生成内容自适应参数，显著加速了过拟合图像编码器的编码过程，在提升压缩性能的同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 过拟合图像编码器（如Cool-chic）能实现强大的压缩，但其编码过程缓慢且计算成本高昂。非过拟合（N-O）Cool-chic通过牺牲压缩性能来提高编码速度。本研究旨在缓解这种压缩性能与编码速度之间的权衡。

Method: HyperCool基于N-O Cool-chic框架，采用超网络架构。它通过一次前向传播为Cool-chic解码器生成内容自适应参数，从而根据输入图像调整解码器，而无需进行逐图像微调。此外，超网络的输出还能为进一步优化提供强大的初始化。

Result: HyperCool相较于N-O Cool-chic实现了4.9%的码率降低，且计算开销极小。超网络的输出为后续优化提供了强大的初始化，减少了达到完全过拟合模型性能所需的步骤。经过微调后，HyperCool在达到HEVC级别压缩性能的同时，仅需完全过拟合Cool-chic编码成本的60.4%。

Conclusion: 本研究提出了一种实用的方法来加速过拟合图像编码器的编码过程，提高了它们在计算预算紧张场景中的可行性。

Abstract: Overfitted image codecs like Cool-chic achieve strong compression by
tailoring lightweight models to individual images, but their encoding is slow
and computationally expensive. To accelerate encoding, Non-Overfitted (N-O)
Cool-chic replaces the per-image optimization with a learned inference model,
trading compression performance for encoding speed. We introduce HyperCool, a
hypernetwork architecture that mitigates this trade-off. Building upon the N-O
Cool-chic framework, HyperCool generates content-adaptive parameters for a
Cool-chic decoder in a single forward pass, tailoring the decoder to the input
image without requiring per-image fine-tuning. Our method achieves a 4.9% rate
reduction over N-O Cool-chic with minimal computational overhead. Furthermore,
the output of our hypernetwork provides a strong initialization for further
optimization, reducing the number of steps needed to approach fully overfitted
model performance. With fine-tuning, HEVC-level compression is achieved with
60.4% of the encoding cost of the fully overfitted Cool-chic. This work
proposes a practical method to accelerate encoding in overfitted image codecs,
improving their viability in scenarios with tight compute budgets.

</details>


### [312] [RFI Removal from SAR Imagery via Sparse Parametric Estimation of LFM Interferences](https://arxiv.org/abs/2509.18809)
*Dehui Yang,Feng Xi,Qihao Cao,Huizhang Yang*

Main category: eess.IV

TL;DR: 本文提出了一种新的信号模型，将合成孔径雷达（SAR）图像中的射频干扰（RFI）建模为多个线性调频（LFM）分量的混合，并通过稀疏参数估计方法有效去除RFI。


<details>
  <summary>Details</summary>
Motivation: 在星载合成孔径雷达（SAR）中，建模和减轻SAR图像中的射频干扰（RFI）伪影是一个重要挑战。

Method: 提出了一种新的信号模型，将聚焦后的SAR图像域中的RFI近似为多个LFM分量的混合。使用离散LFM字典的LFM干扰稀疏参数表示，有效估计每个LFM分量的方位和距离调频（FM）速率。该方法随后在现有RFI抑制框架内，通过2-D SPECAN算法（通过LFM聚焦和频谱域陷波滤波）进行测试。

Result: 在Sentinel-1单视复图像上的实验研究表明，所提出的LFM模型和稀疏参数估计方案优于现有的RFI去除方法。

Conclusion: 新的LFM模型和稀疏参数估计方案能有效建模和抑制SAR图像中的射频干扰，并表现出优于现有方法的性能。

Abstract: One of the challenges in spaceborne synthetic aperture radar (SAR) is
modeling and mitigating radio frequency interference (RFI) artifacts in SAR
imagery. Linear frequency modulated (LFM) signals have been commonly used for
characterizing the radar interferences in SAR. In this letter, we propose a new
signal model that approximates RFI as a mixture of multiple LFM components in
the focused SAR image domain. The azimuth and range frequency modulation (FM)
rates for each LFM component are estimated effectively using a sparse
parametric representation of LFM interferences with a discretized LFM
dictionary. This approach is then tested within the recently developed RFI
suppression framework using a 2-D SPECtral ANalysis (2-D SPECAN) algorithm
through LFM focusing and notch filtering in the spectral domain [1].
Experimental studies on Sentinel-1 single-look complex images demonstrate that
the proposed LFM model and sparse parametric estimation scheme outperforms
existing RFI removal methods.

</details>


### [313] [FlashGMM: Fast Gaussian Mixture Entropy Model for Learned Image Compression](https://arxiv.org/abs/2509.18815)
*Shimon Murai,Fangzheng Lin,Jiro Katto*

Main category: eess.IV

TL;DR: 本文提出了一种快速编码算法，通过动态二分搜索消除了高斯混合模型（GMM）在学习型图像压缩中由于CDF表引起的运行时瓶颈，将熵编码速度提升高达90倍，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 高性能学习型图像压缩编解码器需要灵活的概率模型来拟合潜在表示。高斯混合模型（GMM）能满足此需求，但其为rANS编码构建大型累积分布函数（CDF）表导致显著的运行时性能瓶颈。

Method: 该论文引入了一种快速编码算法，通过利用CDF的单调性，解码器执行动态二分搜索来查找正确的符号，从而无需昂贵的CDF表构建和查找。该方法还辅以SIMD优化和数值近似。

Result: 该方法将GMM熵编码过程加速了约90倍，且不影响码率-失真性能。

Conclusion: 该算法显著提高了基于GMM的编解码器的实用性。

Abstract: High-performance learned image compression codecs require flexible
probability models to fit latent representations. Gaussian Mixture Models
(GMMs) were proposed to satisfy this demand, but suffer from a significant
runtime performance bottleneck due to the large Cumulative Distribution
Function (CDF) tables that must be built for rANS coding. This paper introduces
a fast coding algorithm that entirely eliminates this bottleneck. By leveraging
the CDF's monotonic property, our decoder performs a dynamic binary search to
find the correct symbol, eliminating the need for costly table construction and
lookup. Aided by SIMD optimizations and numerical approximations, our approach
accelerates the GMM entropy coding process by up to approximately 90x without
compromising rate-distortion performance, significantly improving the
practicality of GMM-based codecs. The implementation will be made publicly
available at https://github.com/tokkiwa/FlashGMM.

</details>


### [314] [An on-chip Pixel Processing Approach with 2.4μs latency for Asynchronous Read-out of SPAD-based dToF Flash LiDARs](https://arxiv.org/abs/2509.19192)
*Yiyang Liu,Rongxuan Zhang,Istvan Gyongy,Alistair Gorman,Sarrah M. Patanwala,Filip Taneski,Robert K. Henderson*

Main category: eess.IV

TL;DR: 本文提出了一种用于SPAD直方图ToF闪光雷达的全异步峰值检测方法，实现了像素级的事件驱动深度采集，无需全局同步，从而降低延迟、减少运动模糊并提高有效帧率。


<details>
  <summary>Details</summary>
Motivation: 传统基于帧的LiDAR系统存在高延迟、运动模糊和较低的有效帧率等问题。研究旨在开发一种紧凑、低延迟、事件驱动的LiDAR架构，适用于机器人、自动驾驶和消费级应用。

Method: 该方法提出了一种全异步峰值检测方法，允许每个像素在达到足够的信噪比时独立报告深度信息。通过两种硬件实现进行验证：一个离线256x128 SPAD阵列（PC处理）和一个实时FPGA原型（2.4µs片上集成延迟）。此外，还推导了基于原始峰值查找的LiDAR系统检测概率的半封闭解。

Result: 实验结果表明，在静态和动态条件下，该方法都能实现鲁棒的深度估计、反射率重建和动态事件表示。异步操作减少了冗余背景数据和计算负载，且可通过简单超参数进行调节。FPGA原型实现了2.4µs的低延迟。

Conclusion: 研究结果为紧凑、低延迟、事件驱动的LiDAR架构奠定了基础，适用于机器人、自动驾驶和消费级应用。推导出的检测概率解决方案对传统和提出的异步LiDAR系统均有益处。

Abstract: We propose a fully asynchronous peak detection approach for SPAD-based direct
time-of-flight (dToF) flash LiDAR, enabling pixel-wise event-driven depth
acquisition without global synchronization. By allowing pixels to independently
report depth once a sufficient signal-to-noise ratio is achieved, the method
reduces latency, mitigates motion blur, and increases effective frame rate
compared to frame-based systems. The framework is validated under two hardware
implementations: an offline 256$\times$128 SPAD array with PC based processing
and a real-time FPGA proof-of-concept prototype with 2.4$\upmu$s latency for
on-chip integration. Experiments demonstrate robust depth estimation,
reflectivity reconstruction, and dynamic event-based representation under both
static and dynamic conditions. The results confirm that asynchronous operation
reduces redundant background data and computational load, while remaining
tunable via simple hyperparameters. These findings establish a foundation for
compact, low-latency, event-driven LiDAR architectures suited to robotics,
autonomous driving, and consumer applications. In addition, we have derived a
semi-closed-form solution for the detection probability of the raw-peak finding
based LiDAR systems that could benefit both conventional frame-based and
proposed asynchronous LiDAR systems.

</details>


### [315] [MOIS-SAM2: Exemplar-based Segment Anything Model 2 for multilesion interactive segmentation of neurobromas in whole-body MRI](https://arxiv.org/abs/2509.19277)
*Georgii Kolokolnikov,Marie-Lena Schmalhofer,Sophie Götz,Lennart Well,Said Farschtschi,Victor-Felix Mautner,Inka Ristow,Rene Werner*

Main category: eess.IV

TL;DR: 本研究提出了一种名为MOIS-SAM2的新型多对象交互式分割模型，用于全身MRI中神经纤维瘤(NF)的检测和分割。该模型在精度、可扩展性和泛化能力方面优于现有方法，有望集成到临床工作流程中。


<details>
  <summary>Details</summary>
Motivation: 神经纤维瘤病1型(NF1)患者全身MRI中存在大量神经纤维瘤，现有交互式分割方法在处理数百个病灶时，难以兼顾高病灶级精度和可扩展性，因此需要一种新的解决方案。

Method: 研究引入了MOIS-SAM2模型，它在先进的、基于Transformer的、可提示的Segment Anything Model 2 (SAM2)基础上，通过基于范例的语义传播进行了扩展。该模型在来自84名NF1患者的119次全身MRI扫描（T2加权脂肪抑制序列）上进行训练和评估，数据集按患者级别划分为训练集和四个测试集（一个域内测试集和三个反映不同域偏移场景的测试集，如MRI场强、低肿瘤负荷、临床站点和扫描仪供应商差异）。

Result: 在域内测试集上，MOIS-SAM2的扫描级DSC（Dice相似系数）为0.60，优于基线3D nnU-Net（DSC: 0.54）和SAM2（DSC: 0.35）。该模型在MRI场强变化（DSC: 0.53）和扫描仪供应商变化（DSC: 0.50）下仍保持性能，并在低肿瘤负荷情况下有所提升（DSC: 0.61）。病灶检测F1分数在0.62到0.78之间。初步的读者间变异性分析显示，模型与专家之间的一致性（DSC: 0.62-0.68）与专家之间的一致性（DSC: 0.57-0.69）相当。

Conclusion: 所提出的MOIS-SAM2模型能够以最少的用户输入实现全身MRI中神经纤维瘤的高效、可扩展的交互式分割，并具有强大的泛化能力，支持集成到临床工作流程中。

Abstract: Background and Objectives: Neurofibromatosis type 1 is a genetic disorder
characterized by the development of numerous neurofibromas (NFs) throughout the
body. Whole-body MRI (WB-MRI) is the clinical standard for detection and
longitudinal surveillance of NF tumor growth. Existing interactive segmentation
methods fail to combine high lesion-wise precision with scalability to hundreds
of lesions. This study proposes a novel interactive segmentation model tailored
to this challenge.
  Methods: We introduce MOIS-SAM2, a multi-object interactive segmentation
model that extends the state-of-the-art, transformer-based, promptable Segment
Anything Model 2 (SAM2) with exemplar-based semantic propagation. MOIS-SAM2 was
trained and evaluated on 119 WB-MRI scans from 84 NF1 patients acquired using
T2-weighted fat-suppressed sequences. The dataset was split at the patient
level into a training set and four test sets (one in-domain and three
reflecting different domain shift scenarios, e.g., MRI field strength
variation, low tumor burden, differences in clinical site and scanner vendor).
  Results: On the in-domain test set, MOIS-SAM2 achieved a scan-wise DSC of
0.60 against expert manual annotations, outperforming baseline 3D nnU-Net (DSC:
0.54) and SAM2 (DSC: 0.35). Performance of the proposed model was maintained
under MRI field strength shift (DSC: 0.53) and scanner vendor variation (DSC:
0.50), and improved in low tumor burden cases (DSC: 0.61). Lesion detection F1
scores ranged from 0.62 to 0.78 across test sets. Preliminary inter-reader
variability analysis showed model-to-expert agreement (DSC: 0.62-0.68),
comparable to inter-expert agreement (DSC: 0.57-0.69).
  Conclusions: The proposed MOIS-SAM2 enables efficient and scalable
interactive segmentation of NFs in WB-MRI with minimal user input and strong
generalization, supporting integration into clinical workflows.

</details>
