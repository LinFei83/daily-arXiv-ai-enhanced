<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 11]
- [cs.CV](#cs.CV) [Total: 88]
- [cs.CL](#cs.CL) [Total: 42]
- [cs.RO](#cs.RO) [Total: 28]
- [eess.SY](#eess.SY) [Total: 14]
- [eess.IV](#eess.IV) [Total: 13]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Rethinking the Illusion of Thinking](https://arxiv.org/abs/2507.01231)
*Iñaki Dellibarda Varela,Pablo Romero-Sorozabal,Eduardo Rocon,Manuel Cebrian*

Main category: cs.AI

TL;DR: 论文澄清了关于大型推理模型（LRMs）是否具备真正推理能力的争议，通过改进实验方法，发现LRMs在复杂任务中表现有限，但在可解问题中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决AI社区中关于LRMs是否具备真正推理能力的争议，澄清实验设计的缺陷和结论的夸大。

Method: 复制并改进原研究中的两个争议性基准（Towers of Hanoi和River Crossing），引入逐步提示和协作对话方法。

Result: LRMs在复杂任务（如8个盘子的Towers of Hanoi）中表现有限，但在可解问题（如100+代理对的River Crossing）中表现优异。

Conclusion: 当前的LRMs是基于离散状态空间的随机搜索器，真正的符号推理进展需要更精细的实验设计。

Abstract: Earlier this year, Apple ignited controversy by publishing "The Illusion of
Thinking," prompting heated debate within the AI community. Critics seized upon
the findings as conclusive evidence that Large Reasoning Models (LRMs) lack
genuine reasoning capabilities, branding them as mere stochastic parrots.
Meanwhile, defenders-spearheaded by Lawsen et al. (2025)-fired back, condemning
the experimental setup as flawed and the conclusions overstated. We clarify
this debate by replicating and refining two of the original study's most
contentious benchmarks: Towers of Hanoi and River Crossing. By introducing
incremental stepwise prompting and agentic collaborative dialogue, we show that
previously reported failures solving the Towers of Hanoi were not purely result
of output constraints, but also partly a result of cognition limitations: LRMs
still stumble when complexity rises moderately (around 8 disks). Moreover, the
River Crossing results initially heralded as catastrophic failures turn out to
hinge upon testing unsolvable configurations. Once we limit tests strictly to
solvable problems-LRMs effortlessly solve large instances involving over 100
agent pairs. Our findings ultimately defy simplistic narratives: today's LRMs
are stochastic, RL-tuned searchers in a discrete state space we barely
understand. Real progress in symbolic, long-horizon reasoning demands mapping
that terrain through fine-grained ablations like those introduced here.

</details>


### [2] [Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care](https://arxiv.org/abs/2507.01282)
*Matthew JY Kang,Wenli Yang,Monica R Roberts,Byeong Ho Kang,Charles B Malpas*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLM）在医疗诊断中的局限性，特别是在痴呆症诊断和护理中，强调需要结合统计学习和专家知识的混合方法以提高透明度和实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在基准测试中表现优异，但在实际临床环境中未能显著改善诊断效果，因此需要探索其局限性并提出改进方向。

Method: 通过范围综述分析AI在临床环境中的局限性，提出结合统计学习和专家规则的混合方法，如PEIRS和ATHENA-CDS。

Result: 研究发现LLM在临床应用中存在透明度不足、易产生幻觉和因果推理能力弱等问题，混合方法能更好地融入临床工作流程。

Conclusion: 未来AI决策支持应注重解释性，结合神经符号或混合AI，并衡量对临床医生理解、工作流程和患者结局的实际影响。

Abstract: The recent boom of large language models (LLMs) has re-ignited the hope that
artificial intelligence (AI) systems could aid medical diagnosis. Yet despite
dazzling benchmark scores, LLM assistants have yet to deliver measurable
improvements at the bedside. This scoping review aims to highlight the areas
where AI is limited to make practical contributions in the clinical setting,
specifically in dementia diagnosis and care.
  Standalone machine-learning models excel at pattern recognition but seldom
provide actionable, interpretable guidance, eroding clinician trust. Adjacent
use of LLMs by physicians did not result in better diagnostic accuracy or
speed. Key limitations trace to the data-driven paradigm: black-box outputs
which lack transparency, vulnerability to hallucinations, and weak causal
reasoning. Hybrid approaches that combine statistical learning with expert
rule-based knowledge, and involve clinicians throughout the process help bring
back interpretability. They also fit better with existing clinical workflows,
as seen in examples like PEIRS and ATHENA-CDS.
  Future decision-support should prioritise explanatory coherence by linking
predictions to clinically meaningful causes. This can be done through
neuro-symbolic or hybrid AI that combines the language ability of LLMs with
human causal expertise. AI researchers have addressed this direction, with
explainable AI and neuro-symbolic AI being the next logical steps in further
advancement in AI. However, they are still based on data-driven knowledge
integration instead of human-in-the-loop approaches. Future research should
measure success not only by accuracy but by improvements in clinician
understanding, workflow fit, and patient outcomes. A better understanding of
what helps improve human-computer interactions is greatly needed for AI systems
to become part of clinical practice.

</details>


### [3] [AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing](https://arxiv.org/abs/2507.01376)
*Yinwang Ren,Yangyang Liu,Tang Ji,Xun Xu*

Main category: cs.AI

TL;DR: 本文探讨了AI代理（如LLM-Agents、MLLM-Agents和Agentic AI）在智能制造中的潜力、技术进展及挑战。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI（GenAI）的快速发展，AI代理的能力显著提升，但其在智能制造中的定义、能力边界和实际应用尚不明确。

Method: 系统回顾AI和AI代理技术的演变，分析LLM-Agents、MLLM-Agents和Agentic AI的核心概念与技术进展，并探索其在智能制造中的应用与整合。

Result: 研究发现这些新兴AI范式在智能制造中具有广阔的应用前景，但仍面临挑战。

Conclusion: 研究为AI代理在智能制造中的进一步发展和应用提供了理论基础和实践指导。

Abstract: AI agents are autonomous systems designed to perceive, reason, and act within
dynamic environments. With the rapid advancements in generative AI (GenAI),
large language models (LLMs) and multimodal large language models (MLLMs) have
significantly improved AI agents' capabilities in semantic comprehension,
complex reasoning, and autonomous decision-making. At the same time, the rise
of Agentic AI highlights adaptability and goal-directed autonomy in dynamic and
complex environments. LLMs-based AI Agents (LLM-Agents), MLLMs-based AI Agents
(MLLM-Agents), and Agentic AI contribute to expanding AI's capabilities in
information processing, environmental perception, and autonomous
decision-making, opening new avenues for smart manufacturing. However, the
definitions, capability boundaries, and practical applications of these
emerging AI paradigms in smart manufacturing remain unclear. To address this
gap, this study systematically reviews the evolution of AI and AI agent
technologies, examines the core concepts and technological advancements of
LLM-Agents, MLLM-Agents, and Agentic AI, and explores their potential
applications in and integration into manufacturing, along with the potential
challenges they may face.

</details>


### [4] [A Fuzzy Approach to the Specification, Verification and Validation of Risk-Based Ethical Decision Making Models](https://arxiv.org/abs/2507.01410)
*Abeer Dyoub,Francesca A. Lisi*

Main category: cs.AI

TL;DR: 提出了一种基于伦理风险评估的模糊规则模型，用于描述和验证道德决策，并通过医学案例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 道德领域的复杂性和模糊性使得评估道德机器的性能标准难以明确，因此需要一种形式化方法来描述和验证伦理决策模型。

Method: 使用模糊规则描述伦理决策模型，并通过模糊Petri网进行验证和验证。

Result: 通过医学领域的案例研究验证了所提出方法的可行性和有效性。

Conclusion: 该方法为道德机器的伦理决策提供了一种可行的形式化描述和验证途径。

Abstract: The ontological and epistemic complexities inherent in the moral domain make
it challenging to establish clear standards for evaluating the performance of a
moral machine. In this paper, we present a formal method to describe Ethical
Decision Making models based on ethical risk assessment. Then, we show how
these models that are specified as fuzzy rules can be verified and validated
using fuzzy Petri nets. A case study from the medical field is considered to
illustrate the proposed approach.

</details>


### [5] [Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading](https://arxiv.org/abs/2507.01431)
*Yoonseok Yang,Minjune Kim,Marlon Rondinelli,Keren Shao*

Main category: cs.AI

TL;DR: Pensieve是一个AI辅助评分平台，利用大语言模型（LLMs）转录和评估学生手写作业，显著减少评分时间并保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决大规模STEM课程中手写开放性作业评分的瓶颈问题。

Method: 结合LLMs转录和评估学生作业，提供与评分标准一致的分数、转录文本和置信度评分，支持从提交到反馈的完整流程。

Result: 在20多所机构的实际课程中部署，评分超过30万份作业，评分时间平均减少65%，高置信度预测与教师评分一致率达95.4%。

Conclusion: Pensieve通过AI辅助显著提升了评分效率，同时保持了高准确性，适用于多学科STEM课程。

Abstract: Grading handwritten, open-ended responses remains a major bottleneck in large
university STEM courses. We introduce Pensieve (https://www.pensieve.co), an
AI-assisted grading platform that leverages large language models (LLMs) to
transcribe and evaluate student work, providing instructors with rubric-aligned
scores, transcriptions, and confidence ratings. Unlike prior tools that focus
narrowly on specific tasks like transcription or rubric generation, Pensieve
supports the entire grading pipeline-from scanned student submissions to final
feedback-within a human-in-the-loop interface.
  Pensieve has been deployed in real-world courses at over 20 institutions and
has graded more than 300,000 student responses. We present system details and
empirical results across four core STEM disciplines: Computer Science,
Mathematics, Physics, and Chemistry. Our findings show that Pensieve reduces
grading time by an average of 65%, while maintaining a 95.4% agreement rate
with instructor-assigned grades for high-confidence predictions.

</details>


### [6] [Using multi-agent architecture to mitigate the risk of LLM hallucinations](https://arxiv.org/abs/2507.01446)
*Abd Elrahman Amer,Magdi Amer*

Main category: cs.AI

TL;DR: 提出了一种多智能体系统，结合LLM和模糊逻辑，用于处理短信客户请求，以减少幻觉风险。


<details>
  <summary>Details</summary>
Motivation: 提高客户服务质量和响应时间是保持客户忠诚度和增加市场份额的关键，但LLM的幻觉风险是主要挑战。

Method: 采用多智能体系统，结合LLM和模糊逻辑处理客户短信请求。

Result: 系统有效减少了LLM的幻觉风险。

Conclusion: 多智能体系统结合模糊逻辑是解决LLM幻觉问题的可行方案。

Abstract: Improving customer service quality and response time are critical factors for
maintaining customer loyalty and increasing a company's market share. While
adopting emerging technologies such as Large Language Models (LLMs) is becoming
a necessity to achieve these goals, the risk of hallucination remains a major
challenge. In this paper, we present a multi-agent system to handle customer
requests sent via SMS. This system integrates LLM based agents with fuzzy logic
to mitigate hallucination risks.

</details>


### [7] [Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning](https://arxiv.org/abs/2507.01489)
*Yanfei Zhang*

Main category: cs.AI

TL;DR: 提出了一种分层框架Agent-as-tool，将工具调用与推理过程分离，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究同时处理工具调用和推理，导致模型负担过重，影响推理能力。

Method: 采用分层框架，分离工具调用与推理过程，由不同代理处理。

Result: 仅需少量样本微调即取得可比结果，在Bamboogle任务中表现优异。

Conclusion: Agent-as-tool框架有效减轻模型负担，显著提升推理性能。

Abstract: Large Language Models (LLMs) have emerged as one of the most significant
technological advancements in artificial intelligence in recent years. Their
ability to understand, generate, and reason with natural language has
transformed how we interact with AI systems. With the development of LLM-based
agents and reinforcement-learning-based reasoning models, the study of applying
reinforcement learning in agent frameworks has become a new research focus.
However, all previous studies face the challenge of deciding the tool calling
process and the reasoning process simultaneously, and the chain of reasoning
was solely relied on the unprocessed raw result with redundant information and
symbols unrelated to the task from the tool, which impose a heavy burden on the
model's capability to reason. Therefore, in our research, we proposed a
hierarchical framework Agent-as-tool that detach the tool calling process and
the reasoning process, which enables the model to focus on the verbally
reasoning process while the tool calling process is handled by another agent.
Our work had achieved comparable results with only a slight reinforcement
fine-tuning on 180 samples, and had achieved exceptionally well performance in
Bamboogle with 63.2% of exact match and 75.2% in cover exact match, exceeding
Search-R1 by 4.8% in exact match and 3.2% in cover exact match.

</details>


### [8] [T3DM: Test-Time Training-Guided Distribution Shift Modelling for Temporal Knowledge Graph Reasoning](https://arxiv.org/abs/2507.01597)
*Yuehang Si,Zefan Zeng,Jincai Huang,Qing Cheng*

Main category: cs.AI

TL;DR: 论文提出了一种新的TKG推理方法T3DM，通过建模分布偏移和改进负采样策略，提升了推理的全局一致性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有TKG推理方法在建模事件分布偏移和生成高质量负样本方面存在不足，影响了推理效果。

Method: 提出T3DM方法，结合测试时训练指导的分布偏移建模和基于对抗训练的负采样策略。

Result: 实验表明，T3DM在多数情况下优于现有基线方法，提供更优且更鲁棒的结果。

Conclusion: T3DM通过改进分布偏移建模和负采样策略，显著提升了TKG推理的性能。

Abstract: Temporal Knowledge Graph (TKG) is an efficient method for describing the
dynamic development of facts along a timeline. Most research on TKG reasoning
(TKGR) focuses on modelling the repetition of global facts and designing
patterns of local historical facts. However, they face two significant
challenges: inadequate modeling of the event distribution shift between
training and test samples, and reliance on random entity substitution for
generating negative samples, which often results in low-quality sampling. To
this end, we propose a novel distributional feature modeling approach for
training TKGR models, Test-Time Training-guided Distribution shift Modelling
(T3DM), to adjust the model based on distribution shift and ensure the global
consistency of model reasoning. In addition, we design a negative-sampling
strategy to generate higher-quality negative quadruples based on adversarial
training. Extensive experiments show that T3DM provides better and more robust
results than the state-of-the-art baselines in most cases.

</details>


### [9] [Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI](https://arxiv.org/abs/2507.01717)
*Gopichand Kanumolu,Ashok Urlana,Charaka Vinayak Kumar,Bala Mallikarjunarao Garlapati*

Main category: cs.AI

TL;DR: 利用大型语言模型（LLMs）和自主代理从专利中挖掘和生成产品概念，提出Agent Ideate框架，实验证明代理方法在创意质量、相关性和新颖性上优于单独使用LLMs。


<details>
  <summary>Details</summary>
Motivation: 专利蕴含丰富的技术知识，但访问和解读这些信息仍具挑战性，希望通过LLMs和代理技术挖掘其创新潜力。

Method: 设计Agent Ideate框架，结合开源LLMs和基于代理的架构，在计算机科学、自然语言处理和材料化学三个领域进行实验。

Result: 代理方法在创意质量、相关性和新颖性上均优于单独使用LLMs。

Conclusion: 结合LLMs与代理工作流可显著提升创新流程，解锁专利数据中未开发的商业创意潜力。

Abstract: Patents contain rich technical knowledge that can inspire innovative product
ideas, yet accessing and interpreting this information remains a challenge.
This work explores the use of Large Language Models (LLMs) and autonomous
agents to mine and generate product concepts from a given patent. In this work,
we design Agent Ideate, a framework for automatically generating product-based
business ideas from patents. We experimented with open-source LLMs and
agent-based architectures across three domains: Computer Science, Natural
Language Processing, and Material Chemistry. Evaluation results show that the
agentic approach consistently outperformed standalone LLMs in terms of idea
quality, relevance, and novelty. These findings suggest that combining LLMs
with agentic workflows can significantly enhance the innovation pipeline by
unlocking the untapped potential of business idea generation from patent data.

</details>


### [10] [Joint Matching and Pricing for Crowd-shipping with In-store Customers](https://arxiv.org/abs/2507.01749)
*Arash Dehghan,Mucahit Cevik,Merve Bodur,Bissan Ghaddar*

Main category: cs.AI

TL;DR: 论文研究了利用店内顾客作为配送员的集中式众包配送系统，提出了一种结合NeurADP和DDQN的动态优化策略，显著降低了配送成本。


<details>
  <summary>Details</summary>
Motivation: 针对城市地区最后一英里配送效率的需求增长，探索利用现有顾客资源进行配送的可行性。

Method: 采用马尔可夫决策过程（MDP）模型，结合NeurADP和DDQN进行动态订单分配和定价优化。

Result: 实验结果显示，动态策略比固定定价和短视基准分别节省6.7%和18%的成本，灵活配送和多目的地路由进一步降低成本。

Conclusion: 动态前瞻性策略在众包配送系统中具有显著优势，为城市物流运营商提供了实用指导。

Abstract: This paper examines the use of in-store customers as delivery couriers in a
centralized crowd-shipping system, targeting the growing need for efficient
last-mile delivery in urban areas. We consider a brick-and-mortar retail
setting where shoppers are offered compensation to deliver time-sensitive
online orders. To manage this process, we propose a Markov Decision Process
(MDP) model that captures key uncertainties, including the stochastic arrival
of orders and crowd-shippers, and the probabilistic acceptance of delivery
offers. Our solution approach integrates Neural Approximate Dynamic Programming
(NeurADP) for adaptive order-to-shopper assignment with a Deep Double Q-Network
(DDQN) for dynamic pricing. This joint optimization strategy enables multi-drop
routing and accounts for offer acceptance uncertainty, aligning more closely
with real-world operations. Experimental results demonstrate that the
integrated NeurADP + DDQN policy achieves notable improvements in delivery cost
efficiency, with up to 6.7\% savings over NeurADP with fixed pricing and
approximately 18\% over myopic baselines. We also show that allowing flexible
delivery delays and enabling multi-destination routing further reduces
operational costs by 8\% and 17\%, respectively. These findings underscore the
advantages of dynamic, forward-looking policies in crowd-shipping systems and
offer practical guidance for urban logistics operators.

</details>


### [11] [Refining Gelfond Rationality Principle Towards More Comprehensive Foundational Principles for Answer Set Semantics](https://arxiv.org/abs/2507.01833)
*Yi-Dong Shen,Thomas Eiter*

Main category: cs.AI

TL;DR: 本文探讨了非单调逻辑编程中的答案集语义（ASP）的两个核心问题，提出了对Gelfond答案集原则的改进，并定义了新的语义。


<details>
  <summary>Details</summary>
Motivation: 研究是否应将最小模型属性、约束单调性和基础性作为答案集语义的强制性条件，以及探索其他可能的通用原则。

Method: 通过示例说明现有条件的局限性，改进Gelfond答案集原则，定义新的语义，并分析计算复杂性。

Result: 提出了改进的Gelfond答案集原则，定义了新的语义，并评估了现有语义的合理性。

Conclusion: 改进的Gelfond答案集原则为答案集语义提供了更灵活和合理的基础，同时保持了计算可行性。

Abstract: Non-monotonic logic programming is the basis for a declarative problem
solving paradigm known as answer set programming (ASP). Departing from the
seminal definition by Gelfond and Lifschitz in 1988 for simple normal logic
programs, various answer set semantics have been proposed for extensions. We
consider two important questions: (1) Should the minimal model property,
constraint monotonicity and foundedness as defined in the literature be
mandatory conditions for an answer set semantics in general? (2) If not, what
other properties could be considered as general principles for answer set
semantics? We address the two questions. First, it seems that the three
aforementioned conditions may sometimes be too strong, and we illustrate with
examples that enforcing them may exclude expected answer sets. Second, we
evolve the Gelfond answer set (GAS) principles for answer set construction by
refining the Gelfond's rationality principle to well-supportedness, minimality
w.r.t. negation by default and minimality w.r.t. epistemic negation. The
principle of well-supportedness guarantees that every answer set is
constructible from if-then rules obeying a level mapping and is thus free of
circular justification, while the two minimality principles ensure that the
formalism minimizes knowledge both at the level of answer sets and of world
views. Third, to embody the refined GAS principles, we extend the notion of
well-supportedness substantially to answer sets and world views, respectively.
Fourth, we define new answer set semantics in terms of the refined GAS
principles. Fifth, we use the refined GAS principles as an alternative baseline
to intuitively assess the existing answer set semantics. Finally, we analyze
the computational complexity.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [12] [Geometry-aware 4D Video Generation for Robot Manipulation](https://arxiv.org/abs/2507.01099)
*Zeyi Liu,Shuang Li,Eric Cousineau,Siyuan Feng,Benjamin Burchfiel,Shuran Song*

Main category: cs.CV

TL;DR: 提出了一种4D视频生成模型，通过跨视角点图对齐监督，实现多视角3D一致性，提升机器人动态场景预测能力。


<details>
  <summary>Details</summary>
Motivation: 增强机器人在复杂环境中规划和交互的能力，解决现有视频生成模型在时间连贯性和几何一致性上的不足。

Method: 利用RGB-D观测数据，通过跨视角点图对齐监督训练模型，学习共享的3D场景表示，无需相机位姿输入。

Result: 在模拟和真实机器人数据集上，生成更稳定且空间对齐的视频预测，并能用于恢复机器人末端执行器轨迹。

Conclusion: 该方法支持机器人操作和新视角泛化，为动态场景预测提供了有效解决方案。

Abstract: Understanding and predicting the dynamics of the physical world can enhance a
robot's ability to plan and interact effectively in complex environments. While
recent video generation models have shown strong potential in modeling dynamic
scenes, generating videos that are both temporally coherent and geometrically
consistent across camera views remains a significant challenge. To address
this, we propose a 4D video generation model that enforces multi-view 3D
consistency of videos by supervising the model with cross-view pointmap
alignment during training. This geometric supervision enables the model to
learn a shared 3D representation of the scene, allowing it to predict future
video sequences from novel viewpoints based solely on the given RGB-D
observations, without requiring camera poses as inputs. Compared to existing
baselines, our method produces more visually stable and spatially aligned
predictions across multiple simulated and real-world robotic datasets. We
further show that the predicted 4D videos can be used to recover robot
end-effector trajectories using an off-the-shelf 6DoF pose tracker, supporting
robust robot manipulation and generalization to novel camera viewpoints.

</details>


### [13] [Landslide Detection and Mapping Using Deep Learning Across Multi-Source Satellite Data and Geographic Regions](https://arxiv.org/abs/2507.01123)
*Rahul A. Burange,Harsh K. Shinde,Omkar Mutyalwar*

Main category: cs.CV

TL;DR: 该研究提出了一种结合多源卫星影像和深度学习模型的方法，以提高滑坡识别和预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 滑坡对基础设施、经济和人类生命构成严重威胁，需要准确检测和预测。

Method: 利用Sentinel-2多光谱数据和ALOS PALSAR生成的坡度及DEM层，结合多种地理空间分析技术，评估地形特征、植被覆盖和降雨对检测准确性的影响。同时，比较了U-Net、DeepLabV3+和Res-Net等深度学习分割模型的性能。

Result: 研究结果为开发可靠的早期预警系统、改进灾害风险管理和可持续土地利用规划提供了有价值的见解。

Conclusion: 深度学习与多源遥感数据结合在构建稳健、可扩展和可迁移的滑坡预测模型中具有巨大潜力。

Abstract: Landslides pose severe threats to infrastructure, economies, and human lives,
necessitating accurate detection and predictive mapping across diverse
geographic regions. With advancements in deep learning and remote sensing,
automated landslide detection has become increasingly effective. This study
presents a comprehensive approach integrating multi-source satellite imagery
and deep learning models to enhance landslide identification and prediction. We
leverage Sentinel-2 multispectral data and ALOS PALSAR-derived slope and
Digital Elevation Model (DEM) layers to capture critical environmental features
influencing landslide occurrences. Various geospatial analysis techniques are
employed to assess the impact of terra in characteristics, vegetation cover,
and rainfall on detection accuracy. Additionally, we evaluate the performance
of multiple stateof-the-art deep learning segmentation models, including U-Net,
DeepLabV3+, and Res-Net, to determine their effectiveness in landslide
detection. The proposed framework contributes to the development of reliable
early warning systems, improved disaster risk management, and sustainable
land-use planning. Our findings provide valuable insights into the potential of
deep learning and multi-source remote sensing in creating robust, scalable, and
transferable landslide prediction models.

</details>


### [14] [cp_measure: API-first feature extraction for image-based profiling workflows](https://arxiv.org/abs/2507.01163)
*Alán F. Muñoz,Tim Treis,Alexandr A. Kalinin,Shatavisha Dasgupta,Fabian Theis,Anne E. Carpenter,Shantanu Singh*

Main category: cs.CV

TL;DR: cp_measure是一个Python库，将CellProfiler的核心测量功能模块化，便于程序化特征提取，支持机器学习工作流。


<details>
  <summary>Details</summary>
Motivation: 当前工具（如CellProfiler）在自动化、可重复分析和机器学习工作流中存在障碍，需要更灵活的工具。

Method: 开发cp_measure库，提取CellProfiler的核心功能，设计为模块化、API优先的工具。

Result: cp_measure特征与CellProfiler特征高度一致，并能无缝集成科学Python生态系统。

Conclusion: cp_measure支持可重复、自动化的图像分析流程，适用于计算生物学中的机器学习应用。

Abstract: Biological image analysis has traditionally focused on measuring specific
visual properties of interest for cells or other entities. A complementary
paradigm gaining increasing traction is image-based profiling - quantifying
many distinct visual features to form comprehensive profiles which may reveal
hidden patterns in cellular states, drug responses, and disease mechanisms.
While current tools like CellProfiler can generate these feature sets, they
pose significant barriers to automated and reproducible analyses, hindering
machine learning workflows. Here we introduce cp_measure, a Python library that
extracts CellProfiler's core measurement capabilities into a modular, API-first
tool designed for programmatic feature extraction. We demonstrate that
cp_measure features retain high fidelity with CellProfiler features while
enabling seamless integration with the scientific Python ecosystem. Through
applications to 3D astrocyte imaging and spatial transcriptomics, we showcase
how cp_measure enables reproducible, automated image-based profiling pipelines
that scale effectively for machine learning applications in computational
biology.

</details>


### [15] [Rapid Salient Object Detection with Difference Convolutional Neural Networks](https://arxiv.org/abs/2507.01182)
*Zhuo Su,Li Liu,Matthias Müller,Jiehua Zhang,Diana Wofk,Ming-Ming Cheng,Matti Pietikäinen*

Main category: cs.CV

TL;DR: 提出了一种高效的显著目标检测（SOD）网络设计，结合传统方法和现代CNN，通过Pixel Difference Convolutions（PDCs）和Difference Convolution Reparameterization（DCR）策略提升效率，适用于资源受限设备。


<details>
  <summary>Details</summary>
Motivation: 解决现有显著目标检测模型在资源受限设备上计算成本高的问题，实现实时性能。

Method: 结合传统SOD方法和现代CNN，使用PDCs编码特征对比，并通过DCR策略嵌入标准卷积以减少计算。针对视频SOD，提出STDC增强时空对比捕捉。

Result: 模型SDNet和STDNet在效率和准确性上取得显著平衡，在Jetson Orin设备上分别达到46 FPS和150 FPS，速度和准确性均优于其他轻量级模型。

Conclusion: 提出的方法在资源受限设备上实现了高效的显著目标检测，适用于实时应用。

Abstract: This paper addresses the challenge of deploying salient object detection
(SOD) on resource-constrained devices with real-time performance. While recent
advances in deep neural networks have improved SOD, existing top-leading models
are computationally expensive. We propose an efficient network design that
combines traditional wisdom on SOD and the representation power of modern CNNs.
Like biologically-inspired classical SOD methods relying on computing contrast
cues to determine saliency of image regions, our model leverages Pixel
Difference Convolutions (PDCs) to encode the feature contrasts. Differently,
PDCs are incorporated in a CNN architecture so that the valuable contrast cues
are extracted from rich feature maps. For efficiency, we introduce a difference
convolution reparameterization (DCR) strategy that embeds PDCs into standard
convolutions, eliminating computation and parameters at inference.
Additionally, we introduce SpatioTemporal Difference Convolution (STDC) for
video SOD, enhancing the standard 3D convolution with spatiotemporal contrast
capture. Our models, SDNet for image SOD and STDNet for video SOD, achieve
significant improvements in efficiency-accuracy trade-offs. On a Jetson Orin
device, our models with $<$ 1M parameters operate at 46 FPS and 150 FPS on
streamed images and videos, surpassing the second-best lightweight models in
our experiments by more than $2\times$ and $3\times$ in speed with superior
accuracy. Code will be available at https://github.com/hellozhuo/stdnet.git.

</details>


### [16] [Robust Brain Tumor Segmentation with Incomplete MRI Modalities Using Hölder Divergence and Mutual Information-Enhanced Knowledge Transfer](https://arxiv.org/abs/2507.01254)
*Runze Cheng,Xihang Qiu,Ming Li,Ye Zhang,Chun Li,Fei Yu*

Main category: cs.CV

TL;DR: 提出了一种基于单模态并行处理的鲁棒框架，用于处理多模态MRI中缺失模态的脑肿瘤分割问题，通过Holder散度和互信息实现高精度分割。


<details>
  <summary>Details</summary>
Motivation: 多模态MRI在脑肿瘤分割中提供互补信息，但传统方法在模态缺失时表现不佳，亟需一种鲁棒解决方案。

Method: 采用单模态并行处理框架，结合Holder散度和互信息损失函数，动态调整网络参数以适应可用输入。

Result: 在BraTS 2018和BraTS 2020数据集上表现优于现有方法，尤其在模态缺失情况下。

Conclusion: 该框架通过动态调整和损失函数优化，显著提升了模态缺失情况下的分割准确性。

Abstract: Multimodal MRI provides critical complementary information for accurate brain
tumor segmentation. However, conventional methods struggle when certain
modalities are missing due to issues such as image quality, protocol
inconsistencies, patient allergies, or financial constraints. To address this,
we propose a robust single-modality parallel processing framework that achieves
high segmentation accuracy even with incomplete modalities. Leveraging Holder
divergence and mutual information, our model maintains modality-specific
features while dynamically adjusting network parameters based on the available
inputs. By using these divergence- and information-based loss functions, the
framework effectively quantifies discrepancies between predictions and
ground-truth labels, resulting in consistently accurate segmentation. Extensive
evaluations on the BraTS 2018 and BraTS 2020 datasets demonstrate superior
performance over existing methods in handling missing modalities.

</details>


### [17] [AIGVE-MACS: Unified Multi-Aspect Commenting and Scoring Model for AI-Generated Video Evaluation](https://arxiv.org/abs/2507.01255)
*Xiao Liu,Jiawei Zhang*

Main category: cs.CV

TL;DR: 论文提出AIGVE-MACS，一种结合数值评分和多方面语言反馈的AI生成视频评估模型，显著提升评估的全面性和人类对齐性。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成视频评估指标仅提供数值评分，缺乏解释性，与人类评价对齐性低。

Method: 基于AIGVE-BENCH 2基准，结合视觉语言模型、加权损失和动态帧采样策略。

Result: AIGVE-MACS在评分相关性和评论质量上均优于基线模型，并通过多智能体框架提升视频生成质量53.5%。

Conclusion: AIGVE-MACS为AI生成视频评估提供了全面且人类对齐的新范式。

Abstract: The rapid advancement of AI-generated video models has created a pressing
need for robust and interpretable evaluation frameworks. Existing metrics are
limited to producing numerical scores without explanatory comments, resulting
in low interpretability and human evaluation alignment. To address those
challenges, we introduce AIGVE-MACS, a unified model for AI-Generated Video
Evaluation(AIGVE), which can provide not only numerical scores but also
multi-aspect language comment feedback in evaluating these generated videos.
Central to our approach is AIGVE-BENCH 2, a large-scale benchmark comprising
2,500 AI-generated videos and 22,500 human-annotated detailed comments and
numerical scores across nine critical evaluation aspects. Leveraging
AIGVE-BENCH 2, AIGVE-MACS incorporates recent Vision-Language Models with a
novel token-wise weighted loss and a dynamic frame sampling strategy to better
align with human evaluators. Comprehensive experiments across supervised and
zero-shot benchmarks demonstrate that AIGVE-MACS achieves state-of-the-art
performance in both scoring correlation and comment quality, significantly
outperforming prior baselines including GPT-4o and VideoScore. In addition, we
further showcase a multi-agent refinement framework where feedback from
AIGVE-MACS drives iterative improvements in video generation, leading to 53.5%
quality enhancement. This work establishes a new paradigm for comprehensive,
human-aligned evaluation of AI-generated videos. We release the AIGVE-BENCH 2
and AIGVE-MACS at https://huggingface.co/xiaoliux/AIGVE-MACS.

</details>


### [18] [Advancements in Weed Mapping: A Systematic Review](https://arxiv.org/abs/2507.01269)
*Mohammad Jahanbakht,Alex Olsen,Ross Marchant,Emilie Fillols,Mostafa Rahimi Azghadi*

Main category: cs.CV

TL;DR: 本文综述了杂草测绘的最新方法，填补了从数据获取到处理技术的全面文献空白，为未来研究提供参考。


<details>
  <summary>Details</summary>
Motivation: 杂草测绘对精准管理至关重要，但缺乏全面的文献综述，限制了该领域的进展。

Method: 遵循PRISMA指南，系统分析了数据获取、处理和测绘技术的最新方法。

Result: 综述提供了杂草测绘领域的整体理解，支持高效、可扩展和可持续的杂草管理系统开发。

Conclusion: 本文为未来杂草测绘研究奠定了基础，并推动了可持续杂草管理的发展。

Abstract: Weed mapping plays a critical role in precision management by providing
accurate and timely data on weed distribution, enabling targeted control and
reduced herbicide use. This minimizes environmental impacts, supports
sustainable land management, and improves outcomes across agricultural and
natural environments. Recent advances in weed mapping leverage ground-vehicle
Red Green Blue (RGB) cameras, satellite and drone-based remote sensing combined
with sensors such as spectral, Near Infra-Red (NIR), and thermal cameras. The
resulting data are processed using advanced techniques including big data
analytics and machine learning, significantly improving the spatial and
temporal resolution of weed maps and enabling site-specific management
decisions. Despite a growing body of research in this domain, there is a lack
of comprehensive literature reviews specifically focused on weed mapping. In
particular, the absence of a structured analysis spanning the entire mapping
pipeline, from data acquisition to processing techniques and mapping tools,
limits progress in the field. This review addresses these gaps by
systematically examining state-of-the-art methods in data acquisition (sensor
and platform technologies), data processing (including annotation and
modelling), and mapping techniques (such as spatiotemporal analysis and
decision support tools). Following PRISMA guidelines, we critically evaluate
and synthesize key findings from the literature to provide a holistic
understanding of the weed mapping landscape. This review serves as a
foundational reference to guide future research and support the development of
efficient, scalable, and sustainable weed management systems.

</details>


### [19] [Frequency Domain-Based Diffusion Model for Unpaired Image Dehazing](https://arxiv.org/abs/2507.01275)
*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 提出了一种基于频域的扩散模型（OURS），用于无配对图像去雾，通过振幅残差编码器和相位校正模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于对比学习的方法引入了与雾无关的内容信息，且忽略了频域中雾相关的特性。

Method: 利用扩散模型在频域进行重建，提出振幅残差编码器（ARE）补偿振幅差距，相位校正模块（PCM）消除伪影。

Result: 实验表明，OURS在合成和真实数据集上优于其他先进方法。

Conclusion: 频域扩散模型结合ARE和PCM能有效提升无配对图像去雾性能。

Abstract: Unpaired image dehazing has attracted increasing attention due to its
flexible data requirements during model training. Dominant methods based on
contrastive learning not only introduce haze-unrelated content information, but
also ignore haze-specific properties in the frequency domain (\ie,~haze-related
degradation is mainly manifested in the amplitude spectrum). To address these
issues, we propose a novel frequency domain-based diffusion model, named \ours,
for fully exploiting the beneficial knowledge in unpaired clear data. In
particular, inspired by the strong generative ability shown by Diffusion Models
(DMs), we tackle the dehazing task from the perspective of frequency domain
reconstruction and perform the DMs to yield the amplitude spectrum consistent
with the distribution of clear images. To implement it, we propose an Amplitude
Residual Encoder (ARE) to extract the amplitude residuals, which effectively
compensates for the amplitude gap from the hazy to clear domains, as well as
provide supervision for the DMs training. In addition, we propose a Phase
Correction Module (PCM) to eliminate artifacts by further refining the phase
spectrum during dehazing with a simple attention mechanism. Experimental
results demonstrate that our \ours outperforms other state-of-the-art methods
on both synthetic and real-world datasets.

</details>


### [20] [Learning an Ensemble Token from Task-driven Priors in Facial Analysis](https://arxiv.org/abs/2507.01290)
*Sunyong Seo,Semin Kim,Jongha Lee*

Main category: cs.CV

TL;DR: ET-Fuser是一种利用注意力机制和预训练模型任务先验学习集成令牌的新方法，用于面部分析，提高了特征表示效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单任务学习中缺乏统一的特征表示，ET-Fuser旨在解决这一问题。

Method: 提出了一种基于自注意力机制的集成令牌学习方法，利用预训练编码器的任务先验共享信息。

Result: 在多种面部分析任务中表现出显著的特征表示改进，计算成本极低。

Conclusion: ET-Fuser通过集成令牌方法有效提升了面部分析的性能，具有高效性和实用性。

Abstract: Facial analysis exhibits task-specific feature variations. While
Convolutional Neural Networks (CNNs) have enabled the fine-grained
representation of spatial information, Vision Transformers (ViTs) have
facilitated the representation of semantic information at the patch level.
Although the generalization of conventional methodologies has advanced visual
interpretability, there remains paucity of research that preserves the unified
feature representation on single task learning during the training process. In
this work, we introduce ET-Fuser, a novel methodology for learning ensemble
token by leveraging attention mechanisms based on task priors derived from
pre-trained models for facial analysis. Specifically, we propose a robust prior
unification learning method that generates a ensemble token within a
self-attention mechanism, which shares the mutual information along the
pre-trained encoders. This ensemble token approach offers high efficiency with
negligible computational cost. Our results show improvements across a variety
of facial analysis, with statistically significant enhancements observed in the
feature representations.

</details>


### [21] [DiffusionLight-Turbo: Accelerated Light Probes for Free via Single-Pass Chrome Ball Inpainting](https://arxiv.org/abs/2507.01305)
*Worameth Chinchuthakun,Pakkapon Phongthawee,Amit Raj,Varun Jampani,Pramook Khungurn,Supasorn Suwajanakorn*

Main category: cs.CV

TL;DR: 提出了一种通过将任务重构为铬球修复问题，从单张低动态范围（LDR）图像估计光照的简单有效方法。利用预训练扩散模型Stable Diffusion XL解决现有方法依赖有限HDR全景数据集的泛化问题。通过迭代修复生成稳定的低频光照先验，并引入Exposure LoRA生成HDR光探针。进一步提出DiffusionLight-Turbo，将运行时间从30分钟缩短至30秒。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖有限的HDR全景数据集，泛化能力不足，且扩散模型在生成HDR格式的铬球时存在困难。

Method: 使用Stable Diffusion XL进行铬球修复，通过迭代修复生成稳定的光照先验，并利用Exposure LoRA生成HDR光探针。进一步提出DiffusionLight-Turbo，通过训练Turbo LoRA直接预测迭代结果，实现60倍加速。

Result: 实验结果表明，该方法在多样化场景中生成逼真的光照估计，并在实际场景中表现出优越的泛化能力。

Conclusion: DiffusionLight及其加速版本DiffusionLight-Turbo提供了一种高效且泛化能力强的光照估计解决方案。

Abstract: We introduce a simple yet effective technique for estimating lighting from a
single low-dynamic-range (LDR) image by reframing the task as a chrome ball
inpainting problem. This approach leverages a pre-trained diffusion model,
Stable Diffusion XL, to overcome the generalization failures of existing
methods that rely on limited HDR panorama datasets. While conceptually simple,
the task remains challenging because diffusion models often insert incorrect or
inconsistent content and cannot readily generate chrome balls in HDR format.
Our analysis reveals that the inpainting process is highly sensitive to the
initial noise in the diffusion process, occasionally resulting in unrealistic
outputs. To address this, we first introduce DiffusionLight, which uses
iterative inpainting to compute a median chrome ball from multiple outputs to
serve as a stable, low-frequency lighting prior that guides the generation of a
high-quality final result. To generate high-dynamic-range (HDR) light probes,
an Exposure LoRA is fine-tuned to create LDR images at multiple exposure
values, which are then merged. While effective, DiffusionLight is
time-intensive, requiring approximately 30 minutes per estimation. To reduce
this overhead, we introduce DiffusionLight-Turbo, which reduces the runtime to
about 30 seconds with minimal quality loss. This 60x speedup is achieved by
training a Turbo LoRA to directly predict the averaged chrome balls from the
iterative process. Inference is further streamlined into a single denoising
pass using a LoRA swapping technique. Experimental results that show our method
produces convincing light estimates across diverse settings and demonstrates
superior generalization to in-the-wild scenarios. Our code is available at
https://diffusionlight.github.io/turbo

</details>


### [22] [Physics-informed Ground Reaction Dynamics from Human Motion Capture](https://arxiv.org/abs/2507.01340)
*Cuong Le,Huy-Phuong Le,Duc Le,Minh-Thien Duong,Van-Binh Nguyen,My-Ha Le*

Main category: cs.CV

TL;DR: 提出了一种基于物理约束和计算模拟的新方法，直接从运动捕捉数据估计地面反作用力，无需依赖实验室设备。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖实验室专用的力板设备，限制了人体动力学学习的广泛应用。

Method: 结合欧拉积分方案和PD算法，从运动捕捉数据计算地面反作用力，并利用物理约束优化深度学习模型。

Result: 在GroundLink数据集上测试，优于基线模型，提高了地面反作用力估计精度和模拟根轨迹精度。

Conclusion: 该方法通过物理约束和计算模拟，显著提升了从运动数据估计动力学参数的准确性和鲁棒性。

Abstract: Body dynamics are crucial information for the analysis of human motions in
important research fields, ranging from biomechanics, sports science to
computer vision and graphics. Modern approaches collect the body dynamics,
external reactive force specifically, via force plates, synchronizing with
human motion capture data, and learn to estimate the dynamics from a black-box
deep learning model. Being specialized devices, force plates can only be
installed in laboratory setups, imposing a significant limitation on the
learning of human dynamics. To this end, we propose a novel method for
estimating human ground reaction dynamics directly from the more reliable
motion capture data with physics laws and computational simulation as
constrains. We introduce a highly accurate and robust method for computing
ground reaction forces from motion capture data using Euler's integration
scheme and PD algorithm. The physics-based reactive forces are used to inform
the learning model about the physics-informed motion dynamics thus improving
the estimation accuracy. The proposed approach was tested on the GroundLink
dataset, outperforming the baseline model on: 1) the ground reaction force
estimation accuracy compared to the force plates measurement; and 2) our
simulated root trajectory precision. The implementation code is available at
https://github.com/cuongle1206/Phys-GRD

</details>


### [23] [Learning Camera-Agnostic White-Balance Preferences](https://arxiv.org/abs/2507.01342)
*Luxi Zhao,Mahmoud Afifi,Michael S. Brown*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级方法，通过学习后光照估计映射，将中性白平衡校正转换为美学偏好的校正，实现跨相机美学一致性。


<details>
  <summary>Details</summary>
Motivation: 商业自动白平衡（AWB）系统通常追求美学偏好而非准确中性校正，且现有学习型方法难以跨相机传感器泛化。

Method: 学习一个后光照估计映射，将中性白平衡校正转换为美学偏好的校正，适用于任何中性AWB模块。

Result: 模型仅含约500参数，运行时间0.024毫秒，在771张智能手机图像数据集上表现最优。

Conclusion: 该方法在保持跨相机兼容性的同时，实现了美学一致性和高效性。

Abstract: The image signal processor (ISP) pipeline in modern cameras consists of
several modules that transform raw sensor data into visually pleasing images in
a display color space. Among these, the auto white balance (AWB) module is
essential for compensating for scene illumination. However, commercial AWB
systems often strive to compute aesthetic white-balance preferences rather than
accurate neutral color correction. While learning-based methods have improved
AWB accuracy, they typically struggle to generalize across different camera
sensors -- an issue for smartphones with multiple cameras. Recent work has
explored cross-camera AWB, but most methods remain focused on achieving neutral
white balance. In contrast, this paper is the first to address aesthetic
consistency by learning a post-illuminant-estimation mapping that transforms
neutral illuminant corrections into aesthetically preferred corrections in a
camera-agnostic space. Once trained, our mapping can be applied after any
neutral AWB module to enable consistent and stylized color rendering across
unseen cameras. Our proposed model is lightweight -- containing only $\sim$500
parameters -- and runs in just 0.024 milliseconds on a typical flagship mobile
CPU. Evaluated on a dataset of 771 smartphone images from three different
cameras, our method achieves state-of-the-art performance while remaining fully
compatible with existing cross-camera AWB techniques, introducing minimal
computational and memory overhead.

</details>


### [24] [Learning from Random Subspace Exploration: Generalized Test-Time Augmentation with Self-supervised Distillation](https://arxiv.org/abs/2507.01347)
*Andrei Jelea,Ahmed Nabil Belbachir,Marius Leordeanu*

Main category: cs.CV

TL;DR: GTTA是一种通用的测试时增强方法，适用于多种视觉和非视觉任务，通过PCA子空间扰动和自监督学习提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时增强方法通用性不足，GTTA旨在提供一种通用且高效的解决方案。

Method: 通过随机扰动PCA子空间投影形成鲁棒集成，并引入自监督学习阶段减少计算成本。

Result: 在多种任务和数据集上验证了GTTA的通用性和有效性，尤其在低能见度水下视频的三文鱼分割任务中表现突出。

Conclusion: GTTA是一种高效且通用的测试时增强方法，显著提升了模型性能并降低了计算成本。

Abstract: We introduce Generalized Test-Time Augmentation (GTTA), a highly effective
method for improving the performance of a trained model, which unlike other
existing Test-Time Augmentation approaches from the literature is general
enough to be used off-the-shelf for many vision and non-vision tasks, such as
classification, regression, image segmentation and object detection. By
applying a new general data transformation, that randomly perturbs multiple
times the PCA subspace projection of a test input, GTTA forms robust ensembles
at test time in which, due to sound statistical properties, the structural and
systematic noises in the initial input data is filtered out and final estimator
errors are reduced. Different from other existing methods, we also propose a
final self-supervised learning stage in which the ensemble output, acting as an
unsupervised teacher, is used to train the initial single student model, thus
reducing significantly the test time computational cost, at no loss in
accuracy. Our tests and comparisons to strong TTA approaches and SoTA models on
various vision and non-vision well-known datasets and tasks, such as image
classification and segmentation, speech recognition and house price prediction,
validate the generality of the proposed GTTA. Furthermore, we also prove its
effectiveness on the more specific real-world task of salmon segmentation and
detection in low-visibility underwater videos, for which we introduce
DeepSalmon, the largest dataset of its kind in the literature.

</details>


### [25] [Medical-Knowledge Driven Multiple Instance Learning for Classifying Severe Abdominal Anomalies on Prenatal Ultrasound](https://arxiv.org/abs/2507.01401)
*Huanwen Liang,Jingxian Xu,Yuanji Zhang,Yuhao Huang,Yuhan Zhang,Xin Yang,Ran Li,Xuedong Deng,Yanjun Liu,Guowei Tao,Yun Wu,Sheng Zhao,Xinru Gao,Dong Ni*

Main category: cs.CV

TL;DR: 提出了一种基于多实例学习（MIL）的方法，用于胎儿腹部异常的产前超声分类，无需标准平面定位，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 胎儿腹部畸形是严重的先天性异常，需要准确诊断以指导妊娠管理。现有AI研究多关注图像级分类，缺乏病例级诊断。

Method: 采用混合注意力专家模块（MoAE）加权不同平面注意力，提出医学知识驱动的特征选择模块（MFS）和提示原型学习（PPL）。

Result: 在包含2,419个病例和24,748张图像的数据集上验证，性能优于现有方法。

Conclusion: 该方法在胎儿腹部异常分类中表现出色，为产前诊断提供了新工具。

Abstract: Fetal abdominal malformations are serious congenital anomalies that require
accurate diagnosis to guide pregnancy management and reduce mortality. Although
AI has demonstrated significant potential in medical diagnosis, its application
to prenatal abdominal anomalies remains limited. Most existing studies focus on
image-level classification and rely on standard plane localization, placing
less emphasis on case-level diagnosis. In this paper, we develop a case-level
multiple instance learning (MIL)-based method, free of standard plane
localization, for classifying fetal abdominal anomalies in prenatal ultrasound.
Our contribution is three-fold. First, we adopt a mixture-of-attention-experts
module (MoAE) to weight different attention heads for various planes. Secondly,
we propose a medical-knowledge-driven feature selection module (MFS) to align
image features with medical knowledge, performing self-supervised image token
selection at the case-level. Finally, we propose a prompt-based prototype
learning (PPL) to enhance the MFS. Extensively validated on a large prenatal
abdominal ultrasound dataset containing 2,419 cases, with a total of 24,748
images and 6 categories, our proposed method outperforms the state-of-the-art
competitors. Codes are available at:https://github.com/LL-AC/AAcls.

</details>


### [26] [Long-Tailed Distribution-Aware Router For Mixture-of-Experts in Large Vision-Language Model](https://arxiv.org/abs/2507.01351)
*Chaoxiang Cai,Longrong Yang,Kaibing Chen,Fan Yang,Xi Li*

Main category: cs.CV

TL;DR: 提出了一种长尾分布感知路由器（LTDR），用于视觉语言混合专家模型（MoE），以解决模态间分布差异和视觉尾部令牌激活不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有MoE框架在视觉语言模型中依赖负载均衡机制，忽视了视觉与语言模态间的分布差异，导致视觉尾部令牌处理不足。

Method: 提出LTDR，包括模态感知路由策略和针对视觉尾部令牌的专家激活增强策略（类似过采样）。

Result: 在多个基准测试中验证了方法的有效性。

Conclusion: LTDR通过模态感知路由和尾部令牌增强，显著提升了视觉语言MoE模型的性能。

Abstract: The mixture-of-experts (MoE), which replaces dense models with sparse
architectures, has gained attention in large vision-language models (LVLMs) for
achieving comparable performance with fewer activated parameters. Existing MoE
frameworks for LVLMs focus on token-to-expert routing (TER), encouraging
different experts to specialize in processing distinct tokens. However, these
frameworks often rely on the load balancing mechanism, overlooking the inherent
distributional differences between vision and language. To this end, we propose
a Long-Tailed Distribution-aware Router (LTDR) for vision-language TER,
tackling two challenges: (1) Distribution-aware router for modality-specific
routing. We observe that language TER follows a uniform distribution, whereas
vision TER exhibits a long-tailed distribution. This discrepancy necessitates
distinct routing strategies tailored to each modality. (2) Enhancing expert
activation for vision tail tokens. Recognizing the importance of vision tail
tokens, we introduce an oversampling-like strategy by increasing the number of
activated experts for these tokens. Experiments on extensive benchmarks
validate the effectiveness of our approach.

</details>


### [27] [DocShaDiffusion: Diffusion Model in Latent Space for Document Image Shadow Removal](https://arxiv.org/abs/2507.01422)
*Wenjie Liu,Bingshu Wang,Ze Wang,C. L. Philip Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为DocShaDiffusion的潜在空间扩散模型，用于文档图像阴影去除，并设计了阴影软掩模生成模块（SSGM）和阴影掩模感知引导扩散模块（SMGDM）以解决彩色阴影问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只能去除恒定颜色背景的阴影，而忽略了彩色阴影，因此需要一种更有效的方法。

Method: 通过将阴影图像从像素空间转换到潜在空间，结合SSGM生成精确阴影掩模，并利用SMGDM引导扩散和去噪过程去除阴影。此外，还提出了阴影鲁棒感知特征损失以保留细节。

Result: 在三个公共数据集上的实验验证了该方法的优越性。

Conclusion: DocShaDiffusion在文档图像阴影去除任务中表现优异，且代码和数据集将公开。

Abstract: Document shadow removal is a crucial task in the field of document image
enhancement. However, existing methods tend to remove shadows with constant
color background and ignore color shadows. In this paper, we first design a
diffusion model in latent space for document image shadow removal, called
DocShaDiffusion. It translates shadow images from pixel space to latent space,
enabling the model to more easily capture essential features. To address the
issue of color shadows, we design a shadow soft-mask generation module (SSGM).
It is able to produce accurate shadow mask and add noise into shadow regions
specially. Guided by the shadow mask, a shadow mask-aware guided diffusion
module (SMGDM) is proposed to remove shadows from document images by
supervising the diffusion and denoising process. We also propose a
shadow-robust perceptual feature loss to preserve details and structures in
document images. Moreover, we develop a large-scale synthetic document color
shadow removal dataset (SDCSRD). It simulates the distribution of realistic
color shadows and provides powerful supports for the training of models.
Experiments on three public datasets validate the proposed method's superiority
over state-of-the-art. Our code and dataset will be publicly available.

</details>


### [28] [DiffMark: Diffusion-based Robust Watermark Against Deepfakes](https://arxiv.org/abs/2507.01428)
*Chen Sun,Haiyang Sun,Zhiqing Guo,Yunfeng Diao,Liejun Wang,Dan Ma,Gaobo Yang,Keqin Li*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的鲁棒水印框架DiffMark，用于对抗Deepfake的面部篡改，通过改进训练和采样方案，结合条件引导和交叉信息融合模块，生成更鲁棒的水印图像。


<details>
  <summary>Details</summary>
Motivation: Deepfake技术对安全和隐私构成严重威胁，现有水印方法在对抗Deepfake篡改时鲁棒性不足。扩散模型在图像生成中表现优异，可用于水印与图像的融合。

Method: 通过修改扩散模型的训练和采样方案，将面部图像和水印作为条件引导生成水印图像。引入时间步依赖因子调整面部条件强度，并设计交叉信息融合模块整合水印特征。训练阶段使用冻结自编码器模拟Deepfake篡改，并引入对抗性引导增强鲁棒性。

Result: 实验证明DiffMark在典型Deepfake攻击下具有显著效果，生成的水印图像更鲁棒。

Conclusion: DiffMark是一种有效的对抗Deepfake篡改的鲁棒水印框架，通过扩散模型和条件引导实现了水印与图像的高效融合。

Abstract: Deepfakes pose significant security and privacy threats through malicious
facial manipulations. While robust watermarking can aid in authenticity
verification and source tracking, existing methods often lack the sufficient
robustness against Deepfake manipulations. Diffusion models have demonstrated
remarkable performance in image generation, enabling the seamless fusion of
watermark with image during generation. In this study, we propose a novel
robust watermarking framework based on diffusion model, called DiffMark. By
modifying the training and sampling scheme, we take the facial image and
watermark as conditions to guide the diffusion model to progressively denoise
and generate corresponding watermarked image. In the construction of facial
condition, we weight the facial image by a timestep-dependent factor that
gradually reduces the guidance intensity with the decrease of noise, thus
better adapting to the sampling process of diffusion model. To achieve the
fusion of watermark condition, we introduce a cross information fusion (CIF)
module that leverages a learnable embedding table to adaptively extract
watermark features and integrates them with image features via cross-attention.
To enhance the robustness of the watermark against Deepfake manipulations, we
integrate a frozen autoencoder during training phase to simulate Deepfake
manipulations. Additionally, we introduce Deepfake-resistant guidance that
employs specific Deepfake model to adversarially guide the diffusion sampling
process to generate more robust watermarked images. Experimental results
demonstrate the effectiveness of the proposed DiffMark on typical Deepfakes.
Our code will be available at https://github.com/vpsg-research/DiffMark.

</details>


### [29] [3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial Camouflage Generation](https://arxiv.org/abs/2507.01367)
*Tianrui Lou,Xiaojun Jia,Siyuan Liang,Jiawei Liang,Ming Zhang,Yanjun Xiao,Xiaochun Cao*

Main category: cs.CV

TL;DR: 论文提出了一种基于3D高斯散射（3DGS）的物理攻击框架PGA，通过快速精确的重建和逼真渲染能力，提升了跨视角鲁棒性和对抗效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于伪装的物理攻击方法依赖目标对象的网格先验和模拟器构建的虚拟环境，耗时且与现实存在差异，且缺乏多视角鲁棒性。

Method: PGA框架利用3DGS进行快速重建，通过防止高斯间的相互和自遮挡，以及采用最小-最大优化调整每个视角的背景，提升对抗效果。

Result: 实验验证了PGA在对抗效果和鲁棒性上的优越性。

Conclusion: PGA为物理攻击提供了一种高效且鲁棒的解决方案。

Abstract: Physical adversarial attack methods expose the vulnerabilities of deep neural
networks and pose a significant threat to safety-critical scenarios such as
autonomous driving. Camouflage-based physical attack is a more promising
approach compared to the patch-based attack, offering stronger adversarial
effectiveness in complex physical environments. However, most prior work relies
on mesh priors of the target object and virtual environments constructed by
simulators, which are time-consuming to obtain and inevitably differ from the
real world. Moreover, due to the limitations of the backgrounds in training
images, previous methods often fail to produce multi-view robust adversarial
camouflage and tend to fall into sub-optimal solutions. Due to these reasons,
prior work lacks adversarial effectiveness and robustness across diverse
viewpoints and physical environments. We propose a physical attack framework
based on 3D Gaussian Splatting (3DGS), named PGA, which provides rapid and
precise reconstruction with few images, along with photo-realistic rendering
capabilities. Our framework further enhances cross-view robustness and
adversarial effectiveness by preventing mutual and self-occlusion among
Gaussians and employing a min-max optimization approach that adjusts the
imaging background of each viewpoint, helping the algorithm filter out
non-robust adversarial features. Extensive experiments validate the
effectiveness and superiority of PGA. Our code is available
at:https://github.com/TRLou/PGA.

</details>


### [30] [NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation](https://arxiv.org/abs/2507.01463)
*Max Gandyra,Alessandro Santonicola,Michael Beetz*

Main category: cs.CV

TL;DR: NOCTIS是一个无需重新训练的实例分割框架，通过结合Grounded-SAM 2和DINOv2，在BOP 2023挑战中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决无需重新训练即可泛化到各种新物体的实例分割问题。

Method: 利用Grounded-SAM 2生成对象提议和分割掩码，DINOv2生成图像嵌入，通过相似性匹配和循环阈值过滤优化匹配分数。

Result: 在BOP 2023挑战的七个核心数据集上表现优于现有RGB和RGB-D方法。

Conclusion: NOCTIS提供了一种简单而强大的解决方案，适用于新物体的实例分割任务。

Abstract: Instance segmentation of novel objects instances in RGB images, given some
example images for each object, is a well known problem in computer vision.
Designing a model general enough to be employed, for all kinds of novel
objects, without (re-) training, has proven to be a difficult task. To handle
this, we propose a simple, yet powerful, framework, called: Novel Object Cyclic
Threshold based Instance Segmentation (NOCTIS). This work stems from and
improves upon previous ones like CNOS, SAM-6D and NIDS-Net; thus, it also
leverages on recent vision foundation models, namely: Grounded-SAM 2 and
DINOv2. It utilises Grounded-SAM 2 to obtain object proposals with precise
bounding boxes and their corresponding segmentation masks; while DINOv2's
zero-shot capabilities are employed to generate the image embeddings. The
quality of those masks, together with their embeddings, is of vital importance
to our approach; as the proposal-object matching is realized by determining an
object matching score based on the similarity of the class embeddings and the
average maximum similarity of the patch embeddings. Differently to SAM-6D,
calculating the latter involves a prior patch filtering based on the distance
between each patch and its corresponding cyclic/roundtrip patch in the image
grid. Furthermore, the average confidence of the proposals' bounding box and
mask is used as an additional weighting factor for the object matching score.
We empirically show that NOCTIS, without further training/fine tuning,
outperforms the best RGB and RGB-D methods on the seven core datasets of the
BOP 2023 challenge for the "Model-based 2D segmentation of unseen objects"
task.

</details>


### [31] [Towards Controllable Real Image Denoising with Camera Parameters](https://arxiv.org/abs/2507.01587)
*Youngjin Oh,Junhyeong Kwon,Keuntek Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: 提出了一种基于相机参数的可控去噪框架，通过ISO、快门速度和F值调整去噪强度，提升了去噪网络的性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法缺乏根据噪声水平、相机设置和用户偏好调整去噪强度的灵活性。

Method: 将ISO、快门速度和F值转换为向量，用于控制去噪网络。

Result: 实验表明，该方法为去噪网络增加了可控性并提升了性能。

Conclusion: 提出的框架有效增强了去噪网络的可控性和性能。

Abstract: Recent deep learning-based image denoising methods have shown impressive
performance; however, many lack the flexibility to adjust the denoising
strength based on the noise levels, camera settings, and user preferences. In
this paper, we introduce a new controllable denoising framework that adaptively
removes noise from images by utilizing information from camera parameters.
Specifically, we focus on ISO, shutter speed, and F-number, which are closely
related to noise levels. We convert these selected parameters into a vector to
control and enhance the performance of the denoising network. Experimental
results show that our method seamlessly adds controllability to standard
denoising neural networks and improves their performance. Code is available at
https://github.com/OBAKSA/CPADNet.

</details>


### [32] [Activation Reward Models for Few-Shot Model Alignment](https://arxiv.org/abs/2507.01368)
*Tianning Chai,Chancharik Mitra,Brandon Huang,Gautam Rajendrakumar Gare,Zhiqiu Lin,Assaf Arbelle,Leonid Karlinsky,Rogerio Feris,Trevor Darrell,Deva Ramanan,Roei Herzig*

Main category: cs.CV

TL;DR: 提出了一种新的少样本奖励建模方法Activation RMs，通过激活导向生成对齐的奖励信号，无需额外微调，并在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 对齐大型语言模型和多模态模型的人类偏好是提升生成输出质量的关键，传统奖励建模方法难以适应新偏好。

Method: 利用激活导向构建奖励信号，提出Activation RMs方法，并设计PreferenceHack基准测试奖励模型的抗攻击能力。

Result: Activation RMs在标准奖励建模基准和PreferenceHack测试中表现优异，甚至超过GPT-4o。

Conclusion: Activation RMs是一种高效、灵活的奖励建模方法，适用于安全关键应用。

Abstract: Aligning Large Language Models (LLMs) and Large Multimodal Models (LMMs) to
human preferences is a central challenge in improving the quality of the
models' generative outputs for real-world applications. A common approach is to
use reward modeling to encode preferences, enabling alignment via post-training
using reinforcement learning. However, traditional reward modeling is not
easily adaptable to new preferences because it requires a separate reward
model, commonly trained on large preference datasets. To address this, we
introduce Activation Reward Models (Activation RMs) -- a novel few-shot reward
modeling method that leverages activation steering to construct well-aligned
reward signals using minimal supervision and no additional model finetuning.
Activation RMs outperform existing few-shot reward modeling approaches such as
LLM-as-a-judge with in-context learning, voting-based scoring, and token
probability scoring on standard reward modeling benchmarks. Furthermore, we
demonstrate the effectiveness of Activation RMs in mitigating reward hacking
behaviors, highlighting their utility for safety-critical applications. Toward
this end, we propose PreferenceHack, a novel few-shot setting benchmark, the
first to test reward models on reward hacking in a paired preference format.
Finally, we show that Activation RM achieves state-of-the-art performance on
this benchmark, surpassing even GPT-4o.

</details>


### [33] [Crop Pest Classification Using Deep Learning Techniques: A Review](https://arxiv.org/abs/2507.01494)
*Muhammad Hassam Ejaz,Muhammad Bilal,Usman Habib*

Main category: cs.CV

TL;DR: 本文回顾了2018至2025年间37项关于AI害虫分类的研究，总结了基于深度学习的害虫检测技术发展、挑战及未来方向。


<details>
  <summary>Details</summary>
Motivation: 传统害虫监测方法效率低且难以扩展，深度学习技术（如CNN、ViT和混合模型）为自动化害虫检测提供了解决方案。

Method: 通过分析37项研究，按作物类型、害虫种类、模型架构、数据集使用和技术挑战进行分类总结。

Result: 早期研究主要依赖CNN，近年转向混合和Transformer模型，提高了准确性和上下文理解，但仍面临数据集不平衡、小害虫检测难等挑战。

Conclusion: 该领域需解决数据集和模型泛化问题，未来方向包括优化模型性能和边缘设备部署。

Abstract: Insect pests continue to bring a serious threat to crop yields around the
world, and traditional methods for monitoring them are often slow, manual, and
difficult to scale. In recent years, deep learning has emerged as a powerful
solution, with techniques like convolutional neural networks (CNNs), vision
transformers (ViTs), and hybrid models gaining popularity for automating pest
detection. This review looks at 37 carefully selected studies published between
2018 and 2025, all focused on AI-based pest classification. The selected
research is organized by crop type, pest species, model architecture, dataset
usage, and key technical challenges. The early studies relied heavily on CNNs
but latest work is shifting toward hybrid and transformer-based models that
deliver higher accuracy and better contextual understanding. Still, challenges
like imbalanced datasets, difficulty in detecting small pests, limited
generalizability, and deployment on edge devices remain significant hurdles.
Overall, this review offers a structured overview of the field, highlights
useful datasets, and outlines the key challenges and future directions for
AI-based pest monitoring systems.

</details>


### [34] [Perception-Oriented Latent Coding for High-Performance Compressed Domain Semantic Inference](https://arxiv.org/abs/2507.01608)
*Xu Zhang,Ming Lu,Yan Chen,Zhan Ma*

Main category: cs.CV

TL;DR: POLC提出了一种感知导向的潜在编码方法，通过丰富潜在特征的语义内容，显著提升了压缩域语义推理的性能，同时减少了微调的计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统基于MSE优化的图像编码模型在潜在空间中语义丰富性不足，且微调整个视觉模型计算成本高。

Method: 提出POLC方法，通过优化潜在特征的语义内容，仅需一个即插即用的适配器进行微调。

Result: POLC在保持与生成式图像编码方法相当的率感知性能的同时，显著提升了视觉任务性能，且微调开销极小。

Conclusion: POLC为压缩域语义推理提供了一种高效且性能优越的解决方案。

Abstract: In recent years, compressed domain semantic inference has primarily relied on
learned image coding models optimized for mean squared error (MSE). However,
MSE-oriented optimization tends to yield latent spaces with limited semantic
richness, which hinders effective semantic inference in downstream tasks.
Moreover, achieving high performance with these models often requires
fine-tuning the entire vision model, which is computationally intensive,
especially for large models. To address these problems, we introduce
Perception-Oriented Latent Coding (POLC), an approach that enriches the
semantic content of latent features for high-performance compressed domain
semantic inference. With the semantically rich latent space, POLC requires only
a plug-and-play adapter for fine-tuning, significantly reducing the parameter
count compared to previous MSE-oriented methods. Experimental results
demonstrate that POLC achieves rate-perception performance comparable to
state-of-the-art generative image coding methods while markedly enhancing
performance in vision tasks, with minimal fine-tuning overhead. Code is
available at https://github.com/NJUVISION/POLC.

</details>


### [35] [Active Measurement: Efficient Estimation at Scale](https://arxiv.org/abs/2507.01372)
*Max Hamilton,Jinlin Lai,Wenlong Zhao,Subhransu Maji,Daniel Sheldon*

Main category: cs.CV

TL;DR: 提出了一种名为“主动测量”的人机协作AI框架，用于科学测量，通过重要性采样和模型迭代优化，提高测量精度并减少人力需求。


<details>
  <summary>Details</summary>
Motivation: 当前AI在科学发现中的应用缺乏准确性和统计保证，需要一种更高效且可靠的方法。

Method: 结合AI模型预测和重要性采样的人类标注，通过迭代优化模型和蒙特卡洛估计提高测量精度。

Result: 主动测量在多个测量任务中降低了估计误差，并在AI模型不完美时仍能提供精确估计。

Conclusion: 主动测量是一种高效且可靠的科学测量方法，适用于不同精度需求的场景。

Abstract: AI has the potential to transform scientific discovery by analyzing vast
datasets with little human effort. However, current workflows often do not
provide the accuracy or statistical guarantees that are needed. We introduce
active measurement, a human-in-the-loop AI framework for scientific
measurement. An AI model is used to predict measurements for individual units,
which are then sampled for human labeling using importance sampling. With each
new set of human labels, the AI model is improved and an unbiased Monte Carlo
estimate of the total measurement is refined. Active measurement can provide
precise estimates even with an imperfect AI model, and requires little human
effort when the AI model is very accurate. We derive novel estimators,
weighting schemes, and confidence intervals, and show that active measurement
reduces estimation error compared to alternatives in several measurement tasks.

</details>


### [36] [Integrating Traditional and Deep Learning Methods to Detect Tree Crowns in Satellite Images](https://arxiv.org/abs/2507.01502)
*Ozan Durgut,Beril Kallfelz-Sirmacek,Cem Unsalan*

Main category: cs.CV

TL;DR: 论文提出了一种结合传统方法和深度学习的规则化树冠检测方法，以提高检测的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决全球变暖、生物多样性丧失和空气污染等问题，需要自动化监测森林，但现有方法在树冠检测上仍有不足。

Method: 结合传统方法（特征提取和分割）与深度学习方法（树冠检测），并通过规则化后处理优化结果。

Result: 提出的方法提高了检测到的树冠数量，并分析了其优缺点和改进空间。

Conclusion: 规则化方法在树冠检测中表现更优，但仍需进一步优化。

Abstract: Global warming, loss of biodiversity, and air pollution are among the most
significant problems facing Earth. One of the primary challenges in addressing
these issues is the lack of monitoring forests to protect them. To tackle this
problem, it is important to leverage remote sensing and computer vision methods
to automate monitoring applications. Hence, automatic tree crown detection
algorithms emerged based on traditional and deep learning methods. In this
study, we first introduce two different tree crown detection methods based on
these approaches. Then, we form a novel rule-based approach that integrates
these two methods to enhance robustness and accuracy of tree crown detection
results. While traditional methods are employed for feature extraction and
segmentation of forested areas, deep learning methods are used to detect tree
crowns in our method. With the proposed rule-based approach, we post-process
these results, aiming to increase the number of detected tree crowns through
neighboring trees and localized operations. We compare the obtained results
with the proposed method in terms of the number of detected tree crowns and
report the advantages, disadvantages, and areas for improvement of the obtained
outcomes.

</details>


### [37] [Using Wavelet Domain Fingerprints to Improve Source Camera Identification](https://arxiv.org/abs/2507.01712)
*Xinle Tian,Matthew Nunes,Emiko Dupont,Shaunagh Downing,Freddie Lichtenstein,Matt Burns*

Main category: cs.CV

TL;DR: 提出了一种基于小波域的传感器模式噪声（SPN）提取方法，简化了提取和比较流程，提高了检测精度和处理速度。


<details>
  <summary>Details</summary>
Motivation: 传统的小波去噪方法需要将指纹构建为图像，存在额外的反演步骤，效率较低。

Method: 直接在小波域中构建指纹，避免反演步骤，简化流程。

Result: 实验结果表明，该方法不仅检测精度更高，还能显著提升处理速度。

Conclusion: 小波域指纹提取方法是一种高效且准确的改进方案。

Abstract: Camera fingerprint detection plays a crucial role in source identification
and image forensics, with wavelet denoising approaches proving to be
particularly effective in extracting sensor pattern noise (SPN). In this
article, we propose a modification to wavelet-based SPN extraction. Rather than
constructing the fingerprint as an image, we introduce the notion of a wavelet
domain fingerprint. This avoids the final inversion step of the denoising
algorithm and allows fingerprint comparisons to be made directly in the wavelet
domain. As such, our modification streamlines the extraction and comparison
process. Experimental results on real-world datasets demonstrate that our
method not only achieves higher detection accuracy but can also significantly
improve processing speed.

</details>


### [38] [MUG: Pseudo Labeling Augmented Audio-Visual Mamba Network for Audio-Visual Video Parsing](https://arxiv.org/abs/2507.01384)
*Langyu Wang,Bingke Zhu,Yingying Chen,Yiyuan Zhang,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: 提出了一种基于伪标签增强的音频-视觉Mamba网络（MUG），用于提升弱监督音频-视觉视频解析（AVVP）的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在弱监督和模型架构限制下，难以同时提升片段级和事件级预测性能。

Method: 通过伪标签增强生成新数据，并采用音频-视觉Mamba网络进行特征处理和交互。

Result: 在LLP数据集上，MUG在所有指标上均优于现有方法（如视觉片段级和音频片段级指标分别提升2.1%和1.2%）。

Conclusion: MUG通过伪标签增强和Mamba网络，显著提升了AVVP任务的性能。

Abstract: The weakly-supervised audio-visual video parsing (AVVP) aims to predict all
modality-specific events and locate their temporal boundaries. Despite
significant progress, due to the limitations of the weakly-supervised and the
deficiencies of the model architecture, existing methods are lacking in
simultaneously improving both the segment-level prediction and the event-level
prediction. In this work, we propose a audio-visual Mamba network with pseudo
labeling aUGmentation (MUG) for emphasising the uniqueness of each segment and
excluding the noise interference from the alternate modalities. Specifically,
we annotate some of the pseudo-labels based on previous work. Using unimodal
pseudo-labels, we perform cross-modal random combinations to generate new data,
which can enhance the model's ability to parse various segment-level event
combinations. For feature processing and interaction, we employ a audio-visual
mamba network. The AV-Mamba enhances the ability to perceive different segments
and excludes additional modal noise while sharing similar modal information.
Our extensive experiments demonstrate that MUG improves state-of-the-art
results on LLP dataset in all metrics (e.g,, gains of 2.1% and 1.2% in terms of
visual Segment-level and audio Segment-level metrics). Our code is available at
https://github.com/WangLY136/MUG.

</details>


### [39] [Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence](https://arxiv.org/abs/2507.01504)
*Robert Aufschläger,Youssef Shoeb,Azarm Nowzad,Michael Heigl,Fabian Bally,Martin Schramm*

Main category: cs.CV

TL;DR: 论文提出了一种名为cRID的跨模态框架，结合视觉语言模型和图注意力网络，用于检测个人可识别信息（PII）并提升行人重识别（Re-ID）性能。


<details>
  <summary>Details</summary>
Motivation: 街景数据作为开放数据对自动驾驶和AI研究至关重要，但其中包含的个人可识别信息（PII）对行人隐私构成威胁。

Method: 采用跨模态框架cRID，结合视觉语言模型、图注意力网络和表征学习，检测PII并优化Re-ID。

Result: 实验表明，cRID在跨数据集Re-ID任务中表现优异，尤其在Market-1501到CUHK03-np的数据集上。

Conclusion: cRID框架能有效检测语义层面的PII，提升行人重识别性能，具有实际应用价值。

Abstract: The collection and release of street-level recordings as Open Data play a
vital role in advancing autonomous driving systems and AI research. However,
these datasets pose significant privacy risks, particularly for pedestrians,
due to the presence of Personally Identifiable Information (PII) that extends
beyond biometric traits such as faces. In this paper, we present cRID, a novel
cross-modal framework combining Large Vision-Language Models, Graph Attention
Networks, and representation learning to detect textual describable clues of
PII and enhance person re-identification (Re-ID). Our approach focuses on
identifying and leveraging interpretable features, enabling the detection of
semantically meaningful PII beyond low-level appearance cues. We conduct a
systematic evaluation of PII presence in person image datasets. Our experiments
show improved performance in practical cross-dataset Re-ID scenarios, notably
from Market-1501 to CUHK03-np (detected), highlighting the framework's
practical utility. Code is available at https://github.com/RAufschlaeger/cRID.

</details>


### [40] [FixTalk: Taming Identity Leakage for High-Quality Talking Head Generation in Extreme Cases](https://arxiv.org/abs/2507.01390)
*Shuai Tan,Bill Gong,Bin Ji,Ye Pan*

Main category: cs.CV

TL;DR: FixTalk框架通过EMI和EDI解决身份泄漏和渲染伪影问题，提升说话头生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在极端情况下存在身份泄漏和渲染伪影问题，影响生成质量。

Method: 提出EMI解耦身份信息，EDI利用泄漏信息补充细节。

Result: 实验表明FixTalk有效减少身份泄漏和伪影，性能优于现有方法。

Conclusion: FixTalk通过创新设计解决了关键问题，提升了说话头生成效果。

Abstract: Talking head generation is gaining significant importance across various
domains, with a growing demand for high-quality rendering. However, existing
methods often suffer from identity leakage (IL) and rendering artifacts (RA),
particularly in extreme cases. Through an in-depth analysis of previous
approaches, we identify two key insights: (1) IL arises from identity
information embedded within motion features, and (2) this identity information
can be leveraged to address RA. Building on these findings, this paper
introduces FixTalk, a novel framework designed to simultaneously resolve both
issues for high-quality talking head generation. Firstly, we propose an
Enhanced Motion Indicator (EMI) to effectively decouple identity information
from motion features, mitigating the impact of IL on generated talking heads.
To address RA, we introduce an Enhanced Detail Indicator (EDI), which utilizes
the leaked identity information to supplement missing details, thus fixing the
artifacts. Extensive experiments demonstrate that FixTalk effectively mitigates
IL and RA, achieving superior performance compared to state-of-the-art methods.

</details>


### [41] [Autonomous AI Surveillance: Multimodal Deep Learning for Cognitive and Behavioral Monitoring](https://arxiv.org/abs/2507.01590)
*Ameer Hamza,Zuhaib Hussain But,Umar Arif,Samiya,M. Abdullah Asad,Muhammad Naeem*

Main category: cs.CV

TL;DR: 该研究提出了一种多模态课堂监控系统，结合睡意检测、手机使用追踪和人脸识别，以高精度评估学生注意力。系统采用YOLOv8和LResNet Occ FC等技术，实现了实时监测，并在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在通过多模态技术提升课堂监控的精确性和全面性，同时实现自动考勤等功能。

Method: 利用YOLOv8检测手机和睡意，LResNet Occ FC进行人脸识别，结合PHP和ESP32-CAM硬件实现实时数据采集。

Result: 睡意检测mAP@50为97.42%，人脸识别准确率86.45%，手机检测mAP@50为85.89%。

Conclusion: 该系统为教育环境提供了高效、可扩展的监控解决方案，兼具实用性和创新性。

Abstract: This study presents a novel classroom surveillance system that integrates
multiple modalities, including drowsiness, tracking of mobile phone usage, and
face recognition,to assess student attentiveness with enhanced precision.The
system leverages the YOLOv8 model to detect both mobile phone and sleep
usage,(Ghatge et al., 2024) while facial recognition is achieved through
LResNet Occ FC body tracking using YOLO and MTCNN.(Durai et al., 2024) These
models work in synergy to provide comprehensive, real-time monitoring, offering
insights into student engagement and behavior.(S et al., 2023) The framework is
trained on specialized datasets, such as the RMFD dataset for face recognition
and a Roboflow dataset for mobile phone detection. The extensive evaluation of
the system shows promising results. Sleep detection achieves 97. 42% mAP@50,
face recognition achieves 86. 45% validation accuracy and mobile phone
detection reach 85. 89% mAP@50. The system is implemented within a core PHP web
application and utilizes ESP32-CAM hardware for seamless data capture.(Neto et
al., 2024) This integrated approach not only enhances classroom monitoring, but
also ensures automatic attendance recording via face recognition as students
remain seated in the classroom, offering scalability for diverse educational
environments.(Banada,2025)

</details>


### [42] [Coherent Online Road Topology Estimation and Reasoning with Standard-Definition Maps](https://arxiv.org/abs/2507.01397)
*Khanh Son Pham,Christian Witte,Jens Behley,Johannes Betz,Cyrill Stachniss*

Main category: cs.CV

TL;DR: 提出了一种利用标准地图（SD）信息预测车道段及其拓扑和道路边界的方法，通过混合编码和去噪技术提升性能，实验表明优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶车依赖高精地图的问题，通过车载传感器直接预测地图元素，并建模道路拓扑的复杂性。

Method: 利用SD地图信息，采用混合车道段编码和去噪技术，结合历史帧保证时间一致性。

Result: 实验表明，该方法大幅优于现有方法，验证了建模方案的有效性。

Conclusion: 提出的方法能有效预测车道段和拓扑，减少对高精地图的依赖，提升自动驾驶的鲁棒性。

Abstract: Most autonomous cars rely on the availability of high-definition (HD) maps.
Current research aims to address this constraint by directly predicting HD map
elements from onboard sensors and reasoning about the relationships between the
predicted map and traffic elements. Despite recent advancements, the coherent
online construction of HD maps remains a challenging endeavor, as it
necessitates modeling the high complexity of road topologies in a unified and
consistent manner. To address this challenge, we propose a coherent approach to
predict lane segments and their corresponding topology, as well as road
boundaries, all by leveraging prior map information represented by commonly
available standard-definition (SD) maps. We propose a network architecture,
which leverages hybrid lane segment encodings comprising prior information and
denoising techniques to enhance training stability and performance.
Furthermore, we facilitate past frames for temporal consistency. Our
experimental evaluation demonstrates that our approach outperforms previous
methods by a large margin, highlighting the benefits of our modeling scheme.

</details>


### [43] [Survivability of Backdoor Attacks on Unconstrained Face Recognition Systems](https://arxiv.org/abs/2507.01607)
*Quentin Le Roux,Yannick Teglia,Teddy Furon,Philippe Loubet-Moundi,Eric Bourbao*

Main category: cs.CV

TL;DR: 本文首次系统研究了深度学习人脸识别系统中的后门攻击，展示了两种新型攻击方式，并提出了防御措施。


<details>
  <summary>Details</summary>
Motivation: 深度学习人脸识别系统在现实场景中的后门攻击尚未被充分研究，本文填补了这一空白。

Method: 通过探索DNN后门在完整人脸识别流程中的可行性，展示了两种新型攻击（人脸生成和特征点偏移），并测试了20种系统配置和15种攻击案例。

Result: 研究表明，单一后门可绕过整个系统功能，同时提出了针对性的防御建议。

Conclusion: 本文揭示了人脸识别系统的后门漏洞，为相关方提供了实践指导和防御措施。

Abstract: The widespread use of deep learning face recognition raises several security
concerns. Although prior works point at existing vulnerabilities, DNN backdoor
attacks against real-life, unconstrained systems dealing with images captured
in the wild remain a blind spot of the literature. This paper conducts the
first system-level study of backdoors in deep learning-based face recognition
systems. This paper yields four contributions by exploring the feasibility of
DNN backdoors on these pipelines in a holistic fashion. We demonstrate for the
first time two backdoor attacks on the face detection task: face generation and
face landmark shift attacks. We then show that face feature extractors trained
with large margin losses also fall victim to backdoor attacks. Combining our
models, we then show using 20 possible pipeline configurations and 15 attack
cases that a single backdoor enables an attacker to bypass the entire function
of a system. Finally, we provide stakeholders with several best practices and
countermeasures.

</details>


### [44] [CaptionSmiths: Flexibly Controlling Language Pattern in Image Captioning](https://arxiv.org/abs/2507.01409)
*Kuniaki Saito,Donghyun Kim,Kwanyong Park,Atsushi Hashimoto,Yoshitaka Ushiku*

Main category: cs.CV

TL;DR: 提出了一种名为CaptionSmiths的方法，通过量化标题的长度、描述性和单词独特性，实现单一模型对多样化语言模式的灵活控制。


<details>
  <summary>Details</summary>
Motivation: 现有图像描述模型难以精细控制生成标题的属性，如描述性和长度，主要因为训练时未将这些属性作为条件，且无法平滑切换语言模式。

Method: 量化标题的三种属性（长度、描述性、单词独特性）为连续标量值，通过插值端点向量实现条件控制。

Result: 模型能平滑调整输出标题属性，词汇对齐度优于基线，例如长度控制误差减少506%。

Conclusion: CaptionSmiths成功实现了对标题属性的灵活控制，提升了模型的多功能性。

Abstract: An image captioning model flexibly switching its language pattern, e.g.,
descriptiveness and length, should be useful since it can be applied to diverse
applications. However, despite the dramatic improvement in generative
vision-language models, fine-grained control over the properties of generated
captions is not easy due to two reasons: (i) existing models are not given the
properties as a condition during training and (ii) existing models cannot
smoothly transition its language pattern from one state to the other. Given
this challenge, we propose a new approach, CaptionSmiths, to acquire a single
captioning model that can handle diverse language patterns. First, our approach
quantifies three properties of each caption, length, descriptiveness, and
uniqueness of a word, as continuous scalar values, without human annotation.
Given the values, we represent the conditioning via interpolation between two
endpoint vectors corresponding to the extreme states, e.g., one for a very
short caption and one for a very long caption. Empirical results demonstrate
that the resulting model can smoothly change the properties of the output
captions and show higher lexical alignment than baselines. For instance,
CaptionSmiths reduces the error in controlling caption length by 506\% despite
better lexical alignment. Code will be available on
https://github.com/omron-sinicx/captionsmiths.

</details>


### [45] [Prompt Guidance and Human Proximal Perception for HOT Prediction with Regional Joint Loss](https://arxiv.org/abs/2507.01630)
*Yuxiao Wang,Yu Lei,Zhenao Wei,Weiying Xue,Xinyu Jiang,Nan Zhuang,Qi Liu*

Main category: cs.CV

TL;DR: P3HOT框架通过结合提示引导和人类近端感知，解决了HOT检测中的过度分割和类别一致性问题，并在多个指标上实现了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有HOT检测模型局限于单一图像类型，导致过度分割和类别不一致，P3HOT旨在解决这些问题。

Method: P3HOT结合语义驱动的提示机制和人类近端感知机制，通过深度计算和RJLoss优化区域分类。

Result: 在HOT-Annotated数据集上，P3HOT在四个指标上显著提升，分别为0.7、2.0、1.6和11.0。

Conclusion: P3HOT通过创新机制和损失函数，显著提升了HOT检测的性能和鲁棒性。

Abstract: The task of Human-Object conTact (HOT) detection involves identifying the
specific areas of the human body that are touching objects. Nevertheless,
current models are restricted to just one type of image, often leading to too
much segmentation in areas with little interaction, and struggling to maintain
category consistency within specific regions. To tackle this issue, a HOT
framework, termed \textbf{P3HOT}, is proposed, which blends \textbf{P}rompt
guidance and human \textbf{P}roximal \textbf{P}erception. To begin with, we
utilize a semantic-driven prompt mechanism to direct the network's attention
towards the relevant regions based on the correlation between image and text.
Then a human proximal perception mechanism is employed to dynamically perceive
key depth range around the human, using learnable parameters to effectively
eliminate regions where interactions are not expected. Calculating depth
resolves the uncertainty of the overlap between humans and objects in a 2D
perspective, providing a quasi-3D viewpoint. Moreover, a Regional Joint Loss
(RJLoss) has been created as a new loss to inhibit abnormal categories in the
same area. A new evaluation metric called ``AD-Acc.'' is introduced to address
the shortcomings of existing methods in addressing negative samples.
Comprehensive experimental results demonstrate that our approach achieves
state-of-the-art performance in four metrics across two benchmark datasets.
Specifically, our model achieves an improvement of \textbf{0.7}$\uparrow$,
\textbf{2.0}$\uparrow$, \textbf{1.6}$\uparrow$, and \textbf{11.0}$\uparrow$ in
SC-Acc., mIoU, wIoU, and AD-Acc. metrics, respectively, on the HOT-Annotated
dataset. Code is available at https://github.com/YuxiaoWang-AI/P3HOT.

</details>


### [46] [Gradient Short-Circuit: Efficient Out-of-Distribution Detection via Feature Intervention](https://arxiv.org/abs/2507.01417)
*Jiawei Gu,Ziyue Qiao,Zechao Li*

Main category: cs.CV

TL;DR: 论文提出了一种基于梯度方向一致性的OOD检测方法，通过短路异常梯度方向来提升检测效果，同时保持ID分类性能。


<details>
  <summary>Details</summary>
Motivation: 在开放世界中部署深度学习模型时，OOD检测至关重要。研究发现，ID样本的梯度方向一致，而OOD样本的梯度方向混乱，这启发了通过梯度方向检测OOD样本的方法。

Method: 提出了一种推理阶段的技术，短路异常梯度方向，同时引入一阶近似以避免重复计算。

Result: 在标准OOD基准测试中，该方法显著提升了检测效果，且计算轻量。

Conclusion: 该方法为实际应用中的OOD检测提供了一种高效且实用的解决方案。

Abstract: Out-of-Distribution (OOD) detection is critical for safely deploying deep
models in open-world environments, where inputs may lie outside the training
distribution. During inference on a model trained exclusively with
In-Distribution (ID) data, we observe a salient gradient phenomenon: around an
ID sample, the local gradient directions for "enhancing" that sample's
predicted class remain relatively consistent, whereas OOD samples--unseen in
training--exhibit disorganized or conflicting gradient directions in the same
neighborhood. Motivated by this observation, we propose an inference-stage
technique to short-circuit those feature coordinates that spurious gradients
exploit to inflate OOD confidence, while leaving ID classification largely
intact. To circumvent the expense of recomputing the logits after this gradient
short-circuit, we further introduce a local first-order approximation that
accurately captures the post-modification outputs without a second forward
pass. Experiments on standard OOD benchmarks show our approach yields
substantial improvements. Moreover, the method is lightweight and requires
minimal changes to the standard inference pipeline, offering a practical path
toward robust OOD detection in real-world applications.

</details>


### [47] [Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation](https://arxiv.org/abs/2507.01631)
*Camille Billouard,Dawa Derksen,Alexandre Constantin,Bruno Vallet*

Main category: cs.CV

TL;DR: Snake-NeRF框架通过分块处理和优化策略，解决了NeRF在大规模场景中的内存限制问题，实现了单设备高效处理。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF方法因内存限制仅适用于小场景，需扩展至大规模卫星图像处理。

Method: 采用分块无重叠的3D瓦片策略，图像重叠裁剪，并引入2×2瓦片渐进策略和分段采样器。

Result: 实验表明，单GPU上线性时间处理大规模卫星图像，且质量无损失。

Conclusion: Snake-NeRF成功扩展了NeRF的应用范围，适用于大规模场景。

Abstract: Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D
reconstruction from multiview satellite imagery. However, state-of-the-art NeRF
methods are typically constrained to small scenes due to the memory footprint
during training, which we study in this paper. Previous work on large-scale
NeRFs palliate this by dividing the scene into NeRFs. This paper introduces
Snake-NeRF, a framework that scales to large scenes. Our out-of-core method
eliminates the need to load all images and networks simultaneously, and
operates on a single device. We achieve this by dividing the region of interest
into NeRFs that 3D tile without overlap. Importantly, we crop the images with
overlap to ensure each NeRFs is trained with all the necessary pixels. We
introduce a novel $2\times 2$ 3D tile progression strategy and segmented
sampler, which together prevent 3D reconstruction errors along the tile edges.
Our experiments conclude that large satellite images can effectively be
processed with linear time complexity, on a single GPU, and without compromise
in quality.

</details>


### [48] [TurboReg: TurboClique for Robust and Efficient Point Cloud Registration](https://arxiv.org/abs/2507.01439)
*Shaocheng Yan,Pengcheng Shi,Zhenjun Zhao,Kaixin Wang,Kuang Cao,Ji Wu,Jiayuan Li*

Main category: cs.CV

TL;DR: TurboReg提出了一种快速鲁棒的PCR估计方法，通过轻量级TurboClique和并行PGS算法，显著提升了速度和性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于最大团的PCR方法虽召回率高，但时间复杂度过高，不适用于实时应用。

Method: 定义TurboClique为高度约束兼容图中的3-团，结合并行PGS算法，以线性时间复杂度高效搜索。

Result: 在多个数据集上达到SOTA性能，速度提升显著（如3DMatch+FCGF上快208.22倍）。

Conclusion: TurboReg在保持高召回率的同时，大幅提升了效率，适用于实时PCR任务。

Abstract: Robust estimation is essential in correspondence-based Point Cloud
Registration (PCR). Existing methods using maximal clique search in
compatibility graphs achieve high recall but suffer from exponential time
complexity, limiting their use in time-sensitive applications. To address this
challenge, we propose a fast and robust estimator, TurboReg, built upon a novel
lightweight clique, TurboClique, and a highly parallelizable Pivot-Guided
Search (PGS) algorithm. First, we define the TurboClique as a 3-clique within a
highly-constrained compatibility graph. The lightweight nature of the 3-clique
allows for efficient parallel searching, and the highly-constrained
compatibility graph ensures robust spatial consistency for stable
transformation estimation. Next, PGS selects matching pairs with high SC$^2$
scores as pivots, effectively guiding the search toward TurboCliques with
higher inlier ratios. Moreover, the PGS algorithm has linear time complexity
and is significantly more efficient than the maximal clique search with
exponential time complexity. Extensive experiments show that TurboReg achieves
state-of-the-art performance across multiple real-world datasets, with
substantial speed improvements. For example, on the 3DMatch+FCGF dataset,
TurboReg (1K) operates $208.22\times$ faster than 3DMAC while also achieving
higher recall. Our code is accessible at
\href{https://github.com/Laka-3DV/TurboReg}{\texttt{TurboReg}}.

</details>


### [49] [Depth Anything at Any Condition](https://arxiv.org/abs/2507.01634)
*Boyuan Sun,Modi Jin,Bowen Yin,Qibin Hou*

Main category: cs.CV

TL;DR: DepthAnything-AC是一种基础单目深度估计模型，能够在多样环境条件下工作，通过无监督一致性正则化微调和空间距离约束提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基础MDE模型在复杂开放世界环境中表现不佳，尤其是在光照变化、恶劣天气和传感器失真等挑战条件下。

Method: 提出无监督一致性正则化微调范式和空间距离约束，以少量未标记数据提升模型性能。

Result: 在多样化基准测试中展示了零样本能力，包括真实世界恶劣天气、合成失真和通用场景。

Conclusion: DepthAnything-AC在复杂环境条件下表现出色，为单目深度估计提供了更鲁棒的解决方案。

Abstract: We present Depth Anything at Any Condition (DepthAnything-AC), a foundation
monocular depth estimation (MDE) model capable of handling diverse
environmental conditions. Previous foundation MDE models achieve impressive
performance across general scenes but not perform well in complex open-world
environments that involve challenging conditions, such as illumination
variations, adverse weather, and sensor-induced distortions. To overcome the
challenges of data scarcity and the inability of generating high-quality
pseudo-labels from corrupted images, we propose an unsupervised consistency
regularization finetuning paradigm that requires only a relatively small amount
of unlabeled data. Furthermore, we propose the Spatial Distance Constraint to
explicitly enforce the model to learn patch-level relative relationships,
resulting in clearer semantic boundaries and more accurate details.
Experimental results demonstrate the zero-shot capabilities of DepthAnything-AC
across diverse benchmarks, including real-world adverse weather benchmarks,
synthetic corruption benchmarks, and general benchmarks.
  Project Page: https://ghost233lism.github.io/depthanything-AC-page
  Code: https://github.com/HVision-NKU/DepthAnythingAC

</details>


### [50] [OoDDINO:A Multi-level Framework for Anomaly Segmentation on Complex Road Scenes](https://arxiv.org/abs/2507.01455)
*Yuxing Liu,Ji Zhang,Zhou Xuchuan,Jingzhong Xiao,Huimin Yang,Jiaxin Zhong*

Main category: cs.CV

TL;DR: OoDDINO是一个新颖的多级异常分割框架，通过粗到细的异常检测策略解决现有像素级方法的局限性，结合不确定性引导的检测模型和像素级分割模型，显著提升异常分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有像素级异常分割方法忽视像素间的空间相关性，且全局阈值策略导致背景误检或异常漏检，限制了实际应用效果。

Method: 提出OoDDINO框架，采用两阶段级联架构：1) 正交不确定性感知融合策略（OUAFS）整合多指标；2) 自适应双阈值网络（ADT-Net）动态生成区域特定阈值。

Result: 在两个基准数据集上的实验验证了OoDDINO的优越性和兼容性，显著优于现有方法。

Conclusion: OoDDINO通过多级策略和动态阈值优化，有效解决了异常分割中的关键挑战，为实际应用提供了高效解决方案。

Abstract: Anomaly segmentation aims to identify Out-of-Distribution (OoD) anomalous
objects within images. Existing pixel-wise methods typically assign anomaly
scores individually and employ a global thresholding strategy to segment
anomalies. Despite their effectiveness, these approaches encounter significant
challenges in real-world applications: (1) neglecting spatial correlations
among pixels within the same object, resulting in fragmented segmentation; (2)
variabil ity in anomaly score distributions across image regions, causing
global thresholds to either generate false positives in background areas or
miss segments of anomalous objects. In this work, we introduce OoDDINO, a novel
multi-level anomaly segmentation framework designed to address these
limitations through a coarse-to-fine anomaly detection strategy. OoDDINO
combines an uncertainty-guided anomaly detection model with a pixel-level
segmentation model within a two-stage cascade architecture. Initially, we
propose an Orthogonal Uncertainty-Aware Fusion Strategy (OUAFS) that
sequentially integrates multiple uncertainty metrics with visual
representations, employing orthogonal constraints to strengthen the detection
model's capacity for localizing anomalous regions accurately. Subsequently, we
develop an Adaptive Dual-Threshold Network (ADT-Net), which dynamically
generates region-specific thresholds based on object-level detection outputs
and pixel-wise anomaly scores. This approach allows for distinct thresholding
strategies within foreground and background areas, achieving fine-grained
anomaly segmentation. The proposed framework is compatible with other
pixel-wise anomaly detection models, which acts as a plug-in to boost the
performance. Extensive experiments on two benchmark datasets validate our
framework's superiority and compatibility over state-of-the-art methods.

</details>


### [51] [Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective](https://arxiv.org/abs/2507.01652)
*Yuxin Mao,Zhen Qin,Jinxing Zhou,Hui Deng,Xuyang Shen,Bin Fan,Jing Zhang,Yiran Zhong,Yuchao Dai*

Main category: cs.CV

TL;DR: 论文提出了一种名为LASAD的新型注意力机制，通过保留2D空间关系解决了线性注意力在图像生成中的性能下降问题，并基于此构建了LASADGen模型，实现了高效且高质量的图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归图像生成模型主要依赖Transformer架构，但其计算复杂度和内存开销较高。线性注意力机制虽然在语言模型中有效，但在图像生成中因无法捕捉长距离依赖而表现不佳。

Method: 提出Linear Attention with Spatial-Aware Decay (LASAD)，通过基于真实2D空间位置计算位置依赖的衰减因子，保留空间关系。基于LASAD构建了LASADGen模型。

Result: 在ImageNet上的实验表明，LASADGen在图像生成性能和计算效率上达到最先进水平。

Conclusion: LASADGen成功弥补了线性注意力效率与高质量图像生成所需空间理解之间的差距。

Abstract: Autoregressive (AR) models have garnered significant attention in image
generation for their ability to effectively capture both local and global
structures within visual data. However, prevalent AR models predominantly rely
on the transformer architectures, which are beset by quadratic computational
complexity concerning input sequence length and substantial memory overhead due
to the necessity of maintaining key-value caches. Although linear attention
mechanisms have successfully reduced this burden in language models, our
initial experiments reveal that they significantly degrade image generation
quality because of their inability to capture critical long-range dependencies
in visual data. We propose Linear Attention with Spatial-Aware Decay (LASAD), a
novel attention mechanism that explicitly preserves genuine 2D spatial
relationships within the flattened image sequences by computing
position-dependent decay factors based on true 2D spatial location rather than
1D sequence positions. Based on this mechanism, we present LASADGen, an
autoregressive image generator that enables selective attention to relevant
spatial contexts with linear complexity. Experiments on ImageNet show LASADGen
achieves state-of-the-art image generation performance and computational
efficiency, bridging the gap between linear attention's efficiency and spatial
understanding needed for high-quality generation.

</details>


### [52] [Representation Entanglement for Generation:Training Diffusion Transformers Is Much Easier Than You Think](https://arxiv.org/abs/2507.01467)
*Ge Wu,Shen Zhang,Ruijing Shi,Shanghua Gao,Zhenyuan Chen,Lei Wang,Zhaowei Chen,Hongcheng Gao,Yao Tang,Jian Yang,Ming-Ming Cheng,Xiang Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为REG的方法，通过将低层图像潜在表示与预训练模型的高层类别标记纠缠，显著提升了生成质量和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如REPA）在扩散模型中通过外部视觉表示对齐缓解训练挑战，但未能充分利用判别性表示的潜力。

Method: REG方法将低层图像潜在表示与预训练基础模型的单个高层类别标记纠缠，直接从纯噪声中生成一致的图像-类别对。

Result: 在ImageNet 256×256上，REG显著加速了收敛（63倍和23倍），且在400K次训练后即超越REPA的4M次训练结果。

Conclusion: REG通过语义知识的主动引导，显著提升了生成质量和训练效率，且推理开销极小。

Abstract: REPA and its variants effectively mitigate training challenges in diffusion
models by incorporating external visual representations from pretrained models,
through alignment between the noisy hidden projections of denoising networks
and foundational clean image representations. We argue that the external
alignment, which is absent during the entire denoising inference process, falls
short of fully harnessing the potential of discriminative representations. In
this work, we propose a straightforward method called Representation
Entanglement for Generation (REG), which entangles low-level image latents with
a single high-level class token from pretrained foundation models for
denoising. REG acquires the capability to produce coherent image-class pairs
directly from pure noise, substantially improving both generation quality and
training efficiency. This is accomplished with negligible additional inference
overhead, requiring only one single additional token for denoising (<0.5\%
increase in FLOPs and latency). The inference process concurrently reconstructs
both image latents and their corresponding global semantics, where the acquired
semantic knowledge actively guides and enhances the image generation process.
On ImageNet 256$\times$256, SiT-XL/2 + REG demonstrates remarkable convergence
acceleration, achieving $\textbf{63}\times$ and $\textbf{23}\times$ faster
training than SiT-XL/2 and SiT-XL/2 + REPA, respectively. More impressively,
SiT-L/2 + REG trained for merely 400K iterations outperforms SiT-XL/2 + REPA
trained for 4M iterations ($\textbf{10}\times$ longer). Code is available at:
https://github.com/Martinser/REG.

</details>


### [53] [ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving](https://arxiv.org/abs/2507.01735)
*Kai Chen,Ruiyuan Gao,Lanqing Hong,Hang Xu,Xu Jia,Holger Caesar,Dengxin Dai,Bingbing Liu,Dzmitry Tsishkou,Songcen Xu,Chunjing Xu,Qiang Xu,Huchuan Lu,Dit-Yan Yeung*

Main category: cs.CV

TL;DR: 首届W-CODA研讨会聚焦自动驾驶极端场景，结合多模态感知技术，推动下一代解决方案。


<details>
  <summary>Details</summary>
Motivation: 探索自动驾驶极端场景的先进解决方案，提升自动驾驶的可靠性和智能化水平。

Method: 邀请5位学术界和工业界专家分享最新进展，组织双轨挑战（场景理解与生成）。

Result: 研讨会汇集研究成果，推动前沿技术与可靠自动驾驶之间的桥梁建设。

Conclusion: W-CODA将持续致力于填补自动驾驶极端场景的技术空白。

Abstract: In this paper, we present details of the 1st W-CODA workshop, held in
conjunction with the ECCV 2024. W-CODA aims to explore next-generation
solutions for autonomous driving corner cases, empowered by state-of-the-art
multimodal perception and comprehension techniques. 5 Speakers from both
academia and industry are invited to share their latest progress and opinions.
We collect research papers and hold a dual-track challenge, including both
corner case scene understanding and generation. As the pioneering effort, we
will continuously bridge the gap between frontier autonomous driving techniques
and fully intelligent, reliable self-driving agents robust towards corner
cases.

</details>


### [54] [Optimizing Methane Detection On Board Satellites: Speed, Accuracy, and Low-Power Solutions for Resource-Constrained Hardware](https://arxiv.org/abs/2507.01472)
*Jonáš Herec,Vít Růžička,Rado Pitoňák*

Main category: cs.CV

TL;DR: 论文提出了一种高效、低功耗的甲烷检测算法（Mag1c-SAS和CEM），结合机器学习模型，显著提升了在资源有限的星载硬件上的检测速度（最高可达100倍和230倍）。同时，提出了三种波段选择策略，进一步优化了处理速度。


<details>
  <summary>Details</summary>
Motivation: 甲烷是强效温室气体，通过星载高光谱图像早期检测泄漏有助于减缓气候变化。现有任务多为手动模式，易漏检，且传统方法计算需求高，难以在资源有限的星载硬件上实现。

Method: 测试了快速目标检测方法（ACE、CEM），并提出Mag1c-SAS（Mag1c的快速变体），结合机器学习模型（U-Net、LinkNet）评估性能。还提出了三种波段选择策略。

Result: Mag1c-SAS和CEM在检测强羽流时表现良好，计算效率高（分别比Mag1c快100倍和230倍）。其中一种波段选择策略在减少通道数的同时保持了精度。

Conclusion: 研究为星载甲烷检测提供了高效、低硬件需求的解决方案，提升了数据实时性。代码、数据和模型已开源。

Abstract: Methane is a potent greenhouse gas, and detecting its leaks early via
hyperspectral satellite imagery can help mitigate climate change. Meanwhile,
many existing missions operate in manual tasking regimes only, thus missing
potential events of interest. To overcome slow downlink rates cost-effectively,
onboard detection is a viable solution. However, traditional methane
enhancement methods are too computationally demanding for resource-limited
onboard hardware. This work accelerates methane detection by focusing on
efficient, low-power algorithms. We test fast target detection methods (ACE,
CEM) that have not been previously used for methane detection and propose a
Mag1c-SAS - a significantly faster variant of the current state-of-the-art
algorithm for methane detection: Mag1c. To explore their true detection
potential, we integrate them with a machine learning model (U-Net, LinkNet).
Our results identify two promising candidates (Mag1c-SAS and CEM), both
acceptably accurate for the detection of strong plumes and computationally
efficient enough for onboard deployment: one optimized more for accuracy, the
other more for speed, achieving up to ~100x and ~230x faster computation than
original Mag1c on resource-limited hardware. Additionally, we propose and
evaluate three band selection strategies. One of them can outperform the method
traditionally used in the field while using fewer channels, leading to even
faster processing without compromising accuracy. This research lays the
foundation for future advancements in onboard methane detection with minimal
hardware requirements, improving timely data delivery. The produced code, data,
and models are open-sourced and can be accessed from
https://github.com/zaitra/methane-filters-benchmark.

</details>


### [55] [Active Control Points-based 6DoF Pose Tracking for Industrial Metal Objects](https://arxiv.org/abs/2507.01478)
*Chentao Shen,Ding Pan,Mingyu Mei,Zaixing He,Xinyue Zhao*

Main category: cs.CV

TL;DR: 提出了一种基于主动控制点的6DoF姿态跟踪方法，用于解决工业金属物体在真实环境中的反射问题。


<details>
  <summary>Details</summary>
Motivation: 工业金属物体的姿态跟踪因反射特性而具有挑战性，需要一种更有效的方法。

Method: 使用图像控制点主动生成边缘特征进行优化，并引入最优控制点回归方法提高鲁棒性。

Result: 在数据集评估和实际任务中表现有效，为实时跟踪提供了可行方案。

Conclusion: 该方法为工业金属物体的实时姿态跟踪提供了有效解决方案，代码已开源。

Abstract: Visual pose tracking is playing an increasingly vital role in industrial
contexts in recent years. However, the pose tracking for industrial metal
objects remains a challenging task especially in the real world-environments,
due to the reflection characteristic of metal objects. To address this issue,
we propose a novel 6DoF pose tracking method based on active control points.
The method uses image control points to generate edge feature for optimization
actively instead of 6DoF pose-based rendering, and serve them as optimization
variables. We also introduce an optimal control point regression method to
improve robustness. The proposed tracking method performs effectively in both
dataset evaluation and real world tasks, providing a viable solution for
real-time tracking of industrial metal objects. Our source code is made
publicly available at: https://github.com/tomatoma00/ACPTracking.

</details>


### [56] [Are Vision Transformer Representations Semantically Meaningful? A Case Study in Medical Imaging](https://arxiv.org/abs/2507.01788)
*Montasir Shams,Chashi Mahiul Islam,Shaeke Salman,Phat Tran,Xiuwen Liu*

Main category: cs.CV

TL;DR: 研究发现视觉变换器（ViT）在医学图像分类中的表征缺乏语义意义，且对微小变化敏感，导致分类结果不可靠。


<details>
  <summary>Details</summary>
Motivation: 探索ViT在医学图像任务中的表征是否具有语义意义及其稳定性。

Method: 使用基于投影梯度的算法分析ViT的表征。

Result: ViT的表征对微小变化敏感，语义意义不足，分类准确率可下降60%以上。

Conclusion: ViT在医学图像分类中的表征存在根本性缺陷，对其在安全关键系统中的部署提出挑战。

Abstract: Vision transformers (ViTs) have rapidly gained prominence in medical imaging
tasks such as disease classification, segmentation, and detection due to their
superior accuracy compared to conventional deep learning models. However, due
to their size and complex interactions via the self-attention mechanism, they
are not well understood. In particular, it is unclear whether the
representations produced by such models are semantically meaningful. In this
paper, using a projected gradient-based algorithm, we show that their
representations are not semantically meaningful and they are inherently
vulnerable to small changes. Images with imperceptible differences can have
very different representations; on the other hand, images that should belong to
different semantic classes can have nearly identical representations. Such
vulnerability can lead to unreliable classification results; for example,
unnoticeable changes cause the classification accuracy to be reduced by over
60\%. %. To the best of our knowledge, this is the first work to systematically
demonstrate this fundamental lack of semantic meaningfulness in ViT
representations for medical image classification, revealing a critical
challenge for their deployment in safety-critical systems.

</details>


### [57] [What does really matter in image goal navigation?](https://arxiv.org/abs/2507.01667)
*Gianluca Monaci,Philippe Weinzaepfel,Christian Wolf*

Main category: cs.CV

TL;DR: 研究探讨了端到端强化学习训练是否能在图像目标导航任务中高效运行，并分析了架构选择的影响。


<details>
  <summary>Details</summary>
Motivation: 探索端到端训练是否能在导航任务中实现相对姿态估计，避免依赖专用图像匹配或预训练模块。

Method: 通过大规模研究分析不同架构选择（如延迟融合、通道堆叠等）对导航训练中相对姿态估计器的影响。

Result: 发现模拟器设置会影响方法效果，但能力可部分迁移到更真实场景；导航性能与相对姿态估计性能相关。

Conclusion: 端到端训练在图像目标导航中可行，但需注意模拟器设置的影响；导航性能与相对姿态估计能力相关。

Abstract: Image goal navigation requires two different skills: firstly, core navigation
skills, including the detection of free space and obstacles, and taking
decisions based on an internal representation; and secondly, computing
directional information by comparing visual observations to the goal image.
Current state-of-the-art methods either rely on dedicated image-matching, or
pre-training of computer vision modules on relative pose estimation. In this
paper, we study whether this task can be efficiently solved with end-to-end
training of full agents with RL, as has been claimed by recent work. A positive
answer would have impact beyond Embodied AI and allow training of relative pose
estimation from reward for navigation alone. In a large study we investigate
the effect of architectural choices like late fusion, channel stacking,
space-to-depth projections and cross-attention, and their role in the emergence
of relative pose estimators from navigation training. We show that the success
of recent methods is influenced up to a certain extent by simulator settings,
leading to shortcuts in simulation. However, we also show that these
capabilities can be transferred to more realistic setting, up to some extend.
We also find evidence for correlations between navigation performance and
probed (emerging) relative pose estimation performance, an important sub skill.

</details>


### [58] [What Really Matters for Robust Multi-Sensor HD Map Construction?](https://arxiv.org/abs/2507.01484)
*Xiaoshuai Hao,Yuting Zhao,Yuheng Ji,Luanyuan Dai,Peng Hao,Dingzhe Li,Shuai Cheng,Rong Yin*

Main category: cs.CV

TL;DR: 本文提出了一种增强多模态融合方法鲁棒性的策略，用于高精度地图构建，包括数据增强、新型多模态融合模块和模态丢弃训练策略，并在NuScenes数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注模型精度，忽视了感知模型的鲁棒性，而鲁棒性对实际应用至关重要。

Method: 提出数据增强、新型多模态融合模块和模态丢弃训练策略。

Result: 在NuScenes数据集上显著提升了基线方法的鲁棒性，并在干净验证集上达到最优性能。

Conclusion: 研究为开发更鲁棒可靠的高精度地图构建模型提供了重要见解，推动了其在自动驾驶中的实际应用。

Abstract: High-definition (HD) map construction methods are crucial for providing
precise and comprehensive static environmental information, which is essential
for autonomous driving systems. While Camera-LiDAR fusion techniques have shown
promising results by integrating data from both modalities, existing approaches
primarily focus on improving model accuracy and often neglect the robustness of
perception models, which is a critical aspect for real-world applications. In
this paper, we explore strategies to enhance the robustness of multi-modal
fusion methods for HD map construction while maintaining high accuracy. We
propose three key components: data augmentation, a novel multi-modal fusion
module, and a modality dropout training strategy. These components are
evaluated on a challenging dataset containing 10 days of NuScenes data. Our
experimental results demonstrate that our proposed methods significantly
enhance the robustness of baseline methods. Furthermore, our approach achieves
state-of-the-art performance on the clean validation set of the NuScenes
dataset. Our findings provide valuable insights for developing more robust and
reliable HD map construction models, advancing their applicability in
real-world autonomous driving scenarios. Project website:
https://robomap-123.github.io.

</details>


### [59] [AVC-DPO: Aligned Video Captioning via Direct Preference Optimization](https://arxiv.org/abs/2507.01492)
*Jiyang Tang,Hengyi Li,Yifan Du,Wayne Xin Zhao*

Main category: cs.CV

TL;DR: AVC-DPO框架通过偏好对齐提升视频MLLMs的标题生成能力，关注时空动态和空间信息，在VDC基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视频MLLMs在根据人类偏好调整标题焦点方面存在不足，需改进以更好地满足用户需求。

Method: 设计增强提示，针对时空动态和空间信息，通过偏好感知训练和标题对齐优化模型。

Result: 在LOVE@CVPR'25 Workshop Track 1A中排名第一，VDCSCORE指标表现突出。

Conclusion: AVC-DPO有效提升了视频MLLMs的标题生成能力，实现了与人类偏好的对齐。

Abstract: Although video multimodal large language models (video MLLMs) have achieved
substantial progress in video captioning tasks, it remains challenging to
adjust the focal emphasis of video captions according to human preferences. To
address this limitation, we propose Aligned Video Captioning via Direct
Preference Optimization (AVC-DPO), a post-training framework designed to
enhance captioning capabilities in video MLLMs through preference alignment.
Our approach designs enhanced prompts that specifically target temporal
dynamics and spatial information-two key factors that humans care about when
watching a video-thereby incorporating human-centric preferences. AVC-DPO
leverages the same foundation model's caption generation responses under varied
prompt conditions to conduct preference-aware training and caption alignment.
Using this framework, we have achieved exceptional performance in the
LOVE@CVPR'25 Workshop Track 1A: Video Detailed Captioning Challenge, achieving
first place on the Video Detailed Captioning (VDC) benchmark according to the
VDCSCORE evaluation metric.

</details>


### [60] [ReFlex: Text-Guided Editing of Real Images in Rectified Flow via Mid-Step Feature Extraction and Attention Adaptation](https://arxiv.org/abs/2507.01496)
*Jimyeong Kim,Jungwon Park,Yeji Song,Nojun Kwak,Wonjong Rhee*

Main category: cs.CV

TL;DR: 提出了一种无需训练、无需用户提供掩码的ReFlow图像编辑方法，通过分析中间表示和利用中步潜在变量提升编辑效果。


<details>
  <summary>Details</summary>
Motivation: 尽管ReFlow在图像质量和文本对齐上优于扩散模型，但其在真实图像编辑中的应用仍具挑战性。

Method: 分析多模态Transformer块的中间表示，提取关键特征；利用中步潜在变量保持结构；调整注意力注入以提升编辑性。

Result: 在两项基准测试中优于九种基线方法，人类评估显示用户偏好显著。

Conclusion: 该方法在真实图像编辑中表现优越，无需额外训练或用户输入。

Abstract: Rectified Flow text-to-image models surpass diffusion models in image quality
and text alignment, but adapting ReFlow for real-image editing remains
challenging. We propose a new real-image editing method for ReFlow by analyzing
the intermediate representations of multimodal transformer blocks and
identifying three key features. To extract these features from real images with
sufficient structural preservation, we leverage mid-step latent, which is
inverted only up to the mid-step. We then adapt attention during injection to
improve editability and enhance alignment to the target text. Our method is
training-free, requires no user-provided mask, and can be applied even without
a source prompt. Extensive experiments on two benchmarks with nine baselines
demonstrate its superior performance over prior methods, further validated by
human evaluations confirming a strong user preference for our approach.

</details>


### [61] [Mamba Guided Boundary Prior Matters: A New Perspective for Generalized Polyp Segmentation](https://arxiv.org/abs/2507.01509)
*Tapas K. Dutta,Snehashis Majhi,Deepak Ranjan Nayak,Debesh Jha*

Main category: cs.CV

TL;DR: SAM-MaGuP是一种基于Segment Anything Model的创新方法，通过边界蒸馏模块和1D-2D Mamba适配器，解决了结肠镜图像中息肉分割的弱边界问题，显著提升了分割精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 息肉分割在结肠镜图像中对结直肠癌的早期检测至关重要，但现有方法在弱边界和模糊边界情况下表现不佳，且泛化能力不足。

Method: 提出SAM-MaGuP，结合边界蒸馏模块和1D-2D Mamba适配器，增强全局上下文交互和边界特征学习。

Result: 在五个不同数据集上的评估表明，SAM-MaGuP在分割精度和鲁棒性上优于现有方法。

Conclusion: SAM-MaGuP通过创新设计，为息肉分割领域设定了新标准，显著提升了性能。

Abstract: Polyp segmentation in colonoscopy images is crucial for early detection and
diagnosis of colorectal cancer. However, this task remains a significant
challenge due to the substantial variations in polyp shape, size, and color, as
well as the high similarity between polyps and surrounding tissues, often
compounded by indistinct boundaries. While existing encoder-decoder CNN and
transformer-based approaches have shown promising results, they struggle with
stable segmentation performance on polyps with weak or blurry boundaries. These
methods exhibit limited abilities to distinguish between polyps and non-polyps
and capture essential boundary cues. Moreover, their generalizability still
falls short of meeting the demands of real-time clinical applications. To
address these limitations, we propose SAM-MaGuP, a groundbreaking approach for
robust polyp segmentation. By incorporating a boundary distillation module and
a 1D-2D Mamba adapter within the Segment Anything Model (SAM), SAM-MaGuP excels
at resolving weak boundary challenges and amplifies feature learning through
enriched global contextual interactions. Extensive evaluations across five
diverse datasets reveal that SAM-MaGuP outperforms state-of-the-art methods,
achieving unmatched segmentation accuracy and robustness. Our key innovations,
a Mamba-guided boundary prior and a 1D-2D Mamba block, set a new benchmark in
the field, pushing the boundaries of polyp segmentation to new heights.

</details>


### [62] [How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks](https://arxiv.org/abs/2507.01955)
*Rahul Ramachandran,Ali Garjani,Roman Bachmann,Andrei Atanov,Oğuzhan Fatih Kar,Amir Zamir*

Main category: cs.CV

TL;DR: 论文评估了多模态基础模型在标准计算机视觉任务上的表现，发现它们虽不及专业模型，但作为通用模型表现尚可，且语义任务优于几何任务。


<details>
  <summary>Details</summary>
Motivation: 明确多模态基础模型（如GPT-4o）在视觉理解方面的实际能力，填补现有研究的空白。

Method: 通过提示链将标准视觉任务转化为文本可提示和API兼容的任务，建立标准化评估框架。

Result: 模型在语义任务上表现优于几何任务，GPT-4o在非推理模型中表现最佳，推理模型在几何任务上有改进。

Conclusion: 多模态基础模型在通用性上表现良好，但仍有改进空间，尤其是几何任务和提示敏感性方面。

Abstract: Multimodal foundation models, such as GPT-4o, have recently made remarkable
progress, but it is not clear where exactly these models stand in terms of
understanding vision. In this paper, we benchmark the performance of popular
multimodal foundation models (GPT-4o, o4-mini, Gemini 1.5 Pro and Gemini 2.0
Flash, Claude 3.5 Sonnet, Qwen2-VL, Llama 3.2) on standard computer vision
tasks (semantic segmentation, object detection, image classification, depth and
surface normal prediction) using established datasets (e.g., COCO, ImageNet and
its variants, etc).
  The main challenges to performing this are: 1) most models are trained to
output text and cannot natively express versatile domains, such as segments or
3D geometry, and 2) many leading models are proprietary and accessible only at
an API level, i.e., there is no weight access to adapt them. We address these
challenges by translating standard vision tasks into equivalent text-promptable
and API-compatible tasks via prompt chaining to create a standardized
benchmarking framework.
  We observe that 1) the models are not close to the state-of-the-art
specialist models at any task. However, 2) they are respectable generalists;
this is remarkable as they are presumably trained on primarily image-text-based
tasks. 3) They perform semantic tasks notably better than geometric ones. 4)
While the prompt-chaining techniques affect performance, better models exhibit
less sensitivity to prompt variations. 5) GPT-4o performs the best among
non-reasoning models, securing the top position in 4 out of 6 tasks, 6)
reasoning models, e.g. o3, show improvements in geometric tasks, and 7) a
preliminary analysis of models with native image generation, like the latest
GPT-4o, shows they exhibit quirks like hallucinations and spatial
misalignments.

</details>


### [63] [Exploring Pose-based Sign Language Translation: Ablation Studies and Attention Insights](https://arxiv.org/abs/2507.01532)
*Tomas Zelezny,Jakub Straka,Vaclav Javorek,Ondrej Valach,Marek Hruz,Ivan Gruber*

Main category: cs.CV

TL;DR: 论文探讨了基于姿态的数据预处理技术（归一化、插值和增强）对手语翻译（SLT）性能的影响，使用改进的T5编码器-解码器模型，实验表明这些技术能显著提升模型鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过姿态数据预处理技术提升手语翻译系统的性能，解决连续、无注释翻译中的挑战。

Method: 采用改进的T5编码器-解码器模型处理姿态表示，通过归一化、插值和增强技术预处理数据，并在YouTubeASL和How2Sign数据集上进行消融实验。

Result: 实验表明，适当的预处理技术能显著提升翻译准确性和模型性能，同时发现添加专用寄存器标记可进一步优化模型。

Conclusion: 姿态数据预处理技术对手语翻译性能有显著影响，未来可通过优化预处理策略进一步提升模型表现。

Abstract: Sign Language Translation (SLT) has evolved significantly, moving from
isolated recognition approaches to complex, continuous gloss-free translation
systems. This paper explores the impact of pose-based data preprocessing
techniques - normalization, interpolation, and augmentation - on SLT
performance. We employ a transformer-based architecture, adapting a modified T5
encoder-decoder model to process pose representations. Through extensive
ablation studies on YouTubeASL and How2Sign datasets, we analyze how different
preprocessing strategies affect translation accuracy. Our results demonstrate
that appropriate normalization, interpolation, and augmentation techniques can
significantly improve model robustness and generalization abilities.
Additionally, we provide a deep analysis of the model's attentions and reveal
interesting behavior suggesting that adding a dedicated register token can
improve overall model performance. We publish our code on our GitHub
repository, including the preprocessed YouTubeASL data.

</details>


### [64] [Locality-aware Parallel Decoding for Efficient Autoregressive Image Generation](https://arxiv.org/abs/2507.01957)
*Zhuoyang Zhang,Luke J. Huang,Chengyue Wu,Shang Yang,Kelly Peng,Yao Lu,Song Han*

Main category: cs.CV

TL;DR: Locality-aware Parallel Decoding (LPD) 通过灵活并行自回归建模和局部感知生成顺序，显著加速自回归图像生成，减少生成步骤并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 传统自回归图像生成依赖顺序预测，导致高延迟；现有并行化方法效果有限。

Method: 1. 灵活并行自回归建模：支持任意生成顺序和并行度；2. 局部感知生成顺序：最小化组内依赖，最大化上下文支持。

Result: 在ImageNet上，生成步骤从256降至20（256×256分辨率），1024降至48（512×512分辨率），延迟降低至少3.4倍。

Conclusion: LPD在保持生成质量的同时，显著提升了并行化和效率。

Abstract: We present Locality-aware Parallel Decoding (LPD) to accelerate
autoregressive image generation. Traditional autoregressive image generation
relies on next-patch prediction, a memory-bound process that leads to high
latency. Existing works have tried to parallelize next-patch prediction by
shifting to multi-patch prediction to accelerate the process, but only achieved
limited parallelization. To achieve high parallelization while maintaining
generation quality, we introduce two key techniques: (1) Flexible Parallelized
Autoregressive Modeling, a novel architecture that enables arbitrary generation
ordering and degrees of parallelization. It uses learnable position query
tokens to guide generation at target positions while ensuring mutual visibility
among concurrently generated tokens for consistent parallel decoding. (2)
Locality-aware Generation Ordering, a novel schedule that forms groups to
minimize intra-group dependencies and maximize contextual support, enhancing
generation quality. With these designs, we reduce the generation steps from 256
to 20 (256$\times$256 res.) and 1024 to 48 (512$\times$512 res.) without
compromising quality on the ImageNet class-conditional generation, and
achieving at least 3.4$\times$ lower latency than previous parallelized
autoregressive models.

</details>


### [65] [TrackingMiM: Efficient Mamba-in-Mamba Serialization for Real-time UAV Object Tracking](https://arxiv.org/abs/2507.01535)
*Bingxi Liu,Calvin Chen,Junhao Li,Guyang Yu,Haoqian Song,Xuchen Liu,Jinqiang Cui,Hong Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种基于Mamba模型的TrackingMiM架构，解决了Vision Transformer在无人机跟踪中的计算效率问题，实现了高性能和实时处理。


<details>
  <summary>Details</summary>
Motivation: Vision Transformer（ViT）在无人机跟踪任务中因二次复杂度问题难以实时处理数据，而现有的Mamba方法存在时间连续性不足的问题。

Method: 提出TrackingMiM，一种嵌套Mamba扫描的架构，独立处理时空一致的图像块标记，并将模板帧编码为查询标记用于跟踪。

Result: 在五个无人机跟踪基准测试中，TrackingMiM实现了最先进的精度和显著更高的速度。

Conclusion: TrackingMiM通过改进Mamba的时间连续性处理，为无人机跟踪任务提供了高效且高性能的解决方案。

Abstract: The Vision Transformer (ViT) model has long struggled with the challenge of
quadratic complexity, a limitation that becomes especially critical in unmanned
aerial vehicle (UAV) tracking systems, where data must be processed in real
time. In this study, we explore the recently proposed State-Space Model, Mamba,
leveraging its computational efficiency and capability for long-sequence
modeling to effectively process dense image sequences in tracking tasks. First,
we highlight the issue of temporal inconsistency in existing Mamba-based
methods, specifically the failure to account for temporal continuity in the
Mamba scanning mechanism. Secondly, building upon this insight,we propose
TrackingMiM, a Mamba-in-Mamba architecture, a minimal-computation burden model
for handling image sequence of tracking problem. In our framework, the mamba
scan is performed in a nested way while independently process temporal and
spatial coherent patch tokens. While the template frame is encoded as query
token and utilized for tracking in every scan. Extensive experiments conducted
on five UAV tracking benchmarks confirm that the proposed TrackingMiM achieves
state-of-the-art precision while offering noticeable higher speed in UAV
tracking.

</details>


### [66] [A Multi-Centric Anthropomorphic 3D CT Phantom-Based Benchmark Dataset for Harmonization](https://arxiv.org/abs/2507.01539)
*Mohammadreza Amirian,Michael Bach,Oscar Jimenez-del-Toro,Christoph Aberle,Roger Schaer,Vincent Andrearczyk,Jean-Félix Maestrati,Maria Martin Asiain,Kyriakos Flouris,Markus Obmann,Clarisse Dromain,Benoît Dufour,Pierre-Alexandre Alois Poletti,Hendrik von Tengg-Kobligk,Rolf Hügli,Martin Kretzschmar,Hatem Alkadhi,Ender Konukoglu,Henning Müller,Bram Stieltjes,Adrien Depeursinge*

Main category: cs.CV

TL;DR: 论文提出了一个开源基准数据集，用于促进AI在CT分析中的泛化能力，通过减少数据分布偏移。


<details>
  <summary>Details</summary>
Motivation: AI在医学CT分析中因数据分布偏移（如扫描仪制造商、重建技术或剂量变化）而泛化能力差，需要解决这一问题。

Method: 使用幻影CT扫描创建数据集，包含1378个图像系列，涵盖不同扫描仪和设置，并提出评估图像和特征稳定性的方法。

Result: 提供了一个开源数据集和基线结果，支持开发AI协调技术。

Conclusion: 该数据集和方法有助于推动AI在医学影像中的泛化能力研究。

Abstract: Artificial intelligence (AI) has introduced numerous opportunities for human
assistance and task automation in medicine. However, it suffers from poor
generalization in the presence of shifts in the data distribution. In the
context of AI-based computed tomography (CT) analysis, significant data
distribution shifts can be caused by changes in scanner manufacturer,
reconstruction technique or dose. AI harmonization techniques can address this
problem by reducing distribution shifts caused by various acquisition settings.
This paper presents an open-source benchmark dataset containing CT scans of an
anthropomorphic phantom acquired with various scanners and settings, which
purpose is to foster the development of AI harmonization techniques. Using a
phantom allows fixing variations attributed to inter- and intra-patient
variations. The dataset includes 1378 image series acquired with 13 scanners
from 4 manufacturers across 8 institutions using a harmonized protocol as well
as several acquisition doses. Additionally, we present a methodology, baseline
results and open-source code to assess image- and feature-level stability and
liver tissue classification, promoting the development of AI harmonization
strategies.

</details>


### [67] [Interpolation-Based Event Visual Data Filtering Algorithms](https://arxiv.org/abs/2507.01557)
*Marcin Kowlaczyk,Tomasz Kryjak*

Main category: cs.CV

TL;DR: 提出了一种基于无限脉冲响应（IIR）滤波器矩阵的方法，能去除事件相机数据中约99%的噪声，同时保留有效信号，适用于嵌入式设备。


<details>
  <summary>Details</summary>
Motivation: 事件相机数据流中存在显著噪声，影响应用效果，需高效去噪方法。

Method: 提出四种基于IIR滤波器矩阵的算法，在多个事件数据集上测试，包括人工生成噪声和动态视觉传感器记录的噪声。

Result: 方法能去除约99%的噪声，内存占用约30KB（1280x720分辨率传感器），适合嵌入式设备。

Conclusion: 该方法高效去噪且资源占用低，适合实际应用。

Abstract: The field of neuromorphic vision is developing rapidly, and event cameras are
finding their way into more and more applications. However, the data stream
from these sensors is characterised by significant noise. In this paper, we
propose a method for event data that is capable of removing approximately 99\%
of noise while preserving the majority of the valid signal. We have proposed
four algorithms based on the matrix of infinite impulse response (IIR) filters
method. We compared them on several event datasets that were further modified
by adding artificially generated noise and noise recorded with dynamic vision
sensor. The proposed methods use about 30KB of memory for a sensor with a
resolution of 1280 x 720 and is therefore well suited for implementation in
embedded devices.

</details>


### [68] [A Gift from the Integration of Discriminative and Diffusion-based Generative Learning: Boundary Refinement Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2507.01573)
*Hao Wang,Keyan Hu,Xin Guo,Haifeng Li,Chao Tao*

Main category: cs.CV

TL;DR: 论文提出了一种结合判别式学习和扩散生成学习的框架（IDGBR），用于改进遥感语义分割中的边界精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖判别式学习，擅长捕捉低频特征但忽略高频边界细节，而扩散生成模型擅长生成高频细节但语义推理不足。

Method: 结合判别式模型生成粗分割图，再通过扩散去噪过程细化边界。

Result: 在五个遥感数据集上验证了框架对边界细化的有效性。

Conclusion: IDGBR框架成功整合了两种学习方法的优势，显著提升了边界分割精度。

Abstract: Remote sensing semantic segmentation must address both what the ground
objects are within an image and where they are located. Consequently,
segmentation models must ensure not only the semantic correctness of
large-scale patches (low-frequency information) but also the precise
localization of boundaries between patches (high-frequency information).
However, most existing approaches rely heavily on discriminative learning,
which excels at capturing low-frequency features, while overlooking its
inherent limitations in learning high-frequency features for semantic
segmentation. Recent studies have revealed that diffusion generative models
excel at generating high-frequency details. Our theoretical analysis confirms
that the diffusion denoising process significantly enhances the model's ability
to learn high-frequency features; however, we also observe that these models
exhibit insufficient semantic inference for low-frequency features when guided
solely by the original image. Therefore, we integrate the strengths of both
discriminative and generative learning, proposing the Integration of
Discriminative and diffusion-based Generative learning for Boundary Refinement
(IDGBR) framework. The framework first generates a coarse segmentation map
using a discriminative backbone model. This map and the original image are fed
into a conditioning guidance network to jointly learn a guidance representation
subsequently leveraged by an iterative denoising diffusion process refining the
coarse segmentation. Extensive experiments across five remote sensing semantic
segmentation datasets (binary and multi-class segmentation) confirm our
framework's capability of consistent boundary refinement for coarse results
from diverse discriminative architectures. The source code will be available at
https://github.com/KeyanHu-git/IDGBR.

</details>


### [69] [SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation](https://arxiv.org/abs/2507.01586)
*Bryan Constantine Sadihin,Michael Hua Wang,Shei Pern Chua,Hang Su*

Main category: cs.CV

TL;DR: SketchColour是一种基于扩散变换器（DiT）的草图到色彩转换方法，显著减少了参数和GPU内存使用，并在SAKUGA数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统2D动画制作需要手工绘制和上色大量帧，耗时耗力。SketchColour旨在通过自动化流程提高效率。

Method: 采用DiT架构替代传统U-Net去噪器，通过轻量级通道连接适配器和LoRA微调注入草图信息，避免ControlNet的参数膨胀。

Result: 在SAKUGA数据集上，SketchColour以一半的训练数据在所有指标上超越现有方法，生成时间连贯且无显著伪影的动画。

Conclusion: SketchColour为2D动画上色提供了一种高效且高质量的解决方案，显著降低了计算资源需求。

Abstract: The production of high-quality 2D animation is highly labor-intensive
process, as animators are currently required to draw and color a large number
of frames by hand. We present SketchColour, the first sketch-to-colour pipeline
for 2D animation built on a diffusion transformer (DiT) backbone. By replacing
the conventional U-Net denoiser with a DiT-style architecture and injecting
sketch information via lightweight channel-concatenation adapters accompanied
with LoRA finetuning, our method natively integrates conditioning without the
parameter and memory bloat of a duplicated ControlNet, greatly reducing
parameter count and GPU memory usage. Evaluated on the SAKUGA dataset,
SketchColour outperforms previous state-of-the-art video colourization methods
across all metrics, despite using only half the training data of competing
models. Our approach produces temporally coherent animations with minimal
artifacts such as colour bleeding or object deformation. Our code is available
at: https://bconstantine.github.io/SketchColour .

</details>


### [70] [DepthSync: Diffusion Guidance-Based Depth Synchronization for Scale- and Geometry-Consistent Video Depth Estimation](https://arxiv.org/abs/2507.01603)
*Yue-Jiang Dong,Wang Zhao,Jiale Xu,Ying Shan,Song-Hai Zhang*

Main category: cs.CV

TL;DR: DepthSync提出了一种无需训练的方法，通过扩散引导实现长视频深度估计的尺度和几何一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长视频时存在尺度不一致和几何不一致的问题，忽略了视频深度的3D结构。

Method: 引入尺度引导和几何引导，协同优化去噪过程，确保尺度和几何一致性。

Result: 实验表明，DepthSync在多个数据集上显著提升了长视频深度估计的尺度和几何一致性。

Conclusion: DepthSync为长视频深度估计提供了一种有效的无训练解决方案，解决了现有方法的局限性。

Abstract: Diffusion-based video depth estimation methods have achieved remarkable
success with strong generalization ability. However, predicting depth for long
videos remains challenging. Existing methods typically split videos into
overlapping sliding windows, leading to accumulated scale discrepancies across
different windows, particularly as the number of windows increases.
Additionally, these methods rely solely on 2D diffusion priors, overlooking the
inherent 3D geometric structure of video depths, which results in geometrically
inconsistent predictions. In this paper, we propose DepthSync, a novel,
training-free framework using diffusion guidance to achieve scale- and
geometry-consistent depth predictions for long videos. Specifically, we
introduce scale guidance to synchronize the depth scale across windows and
geometry guidance to enforce geometric alignment within windows based on the
inherent 3D constraints in video depths. These two terms work synergistically,
steering the denoising process toward consistent depth predictions. Experiments
on various datasets validate the effectiveness of our method in producing depth
estimates with improved scale and geometry consistency, particularly for long
videos.

</details>


### [71] [SAILViT: Towards Robust and Generalizable Visual Backbones for MLLMs via Gradual Feature Refinement](https://arxiv.org/abs/2507.01643)
*Weijie Yin,Dingkang Yang,Hongyuan Dong,Zijian Kang,Jiacong Wang,Xiao Liang,Chao Feng,Jiao Ran*

Main category: cs.CV

TL;DR: SAILViT是一种逐步特征学习的ViT，用于提升多模态大语言模型（MLLMs）的性能，解决参数冲突和模态语义差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有ViTs在直接与LLMs协同训练时存在参数初始化冲突和模态语义差距，限制了性能。

Method: 提出SAILViT，通过逐步特征细化实现粗到细的特征对齐和知识注入。

Result: SAILViT在OpenCompass基准测试中显著提升MLLMs性能，并展现强大鲁棒性和泛化性。

Conclusion: SAILViT为MLLMs提供了有效的特征学习框架，突破复杂多模态交互的性能瓶颈。

Abstract: Vision Transformers (ViTs) are essential as foundation backbones in
establishing the visual comprehension capabilities of Multimodal Large Language
Models (MLLMs). Although most ViTs achieve impressive performance through
image-text pair-based contrastive learning or self-supervised mechanisms, they
struggle to engage in connector-based co-training directly with LLMs due to
potential parameter initialization conflicts and modality semantic gaps. To
address the above challenges, this paper proposes SAILViT, a gradual feature
learning-enhanced ViT for facilitating MLLMs to break through performance
bottlenecks in complex multimodal interactions. SAILViT achieves
coarse-to-fine-grained feature alignment and world knowledge infusion with
gradual feature refinement, which better serves target training demands. We
perform thorough empirical analyses to confirm the powerful robustness and
generalizability of SAILViT across different dimensions, including parameter
sizes, model architectures, training strategies, and data scales. Equipped with
SAILViT, existing MLLMs show significant and consistent performance
improvements on the OpenCompass benchmark across extensive downstream tasks.
SAILViT series models are released at
https://huggingface.co/BytedanceDouyinContent.

</details>


### [72] [RobuSTereo: Robust Zero-Shot Stereo Matching under Adverse Weather](https://arxiv.org/abs/2507.01653)
*Yuran Wang,Yingping Liang,Yutao Hu,Ying Fu*

Main category: cs.CV

TL;DR: 提出RobuSTereo框架，通过合成数据和改进特征提取，提升立体匹配模型在恶劣天气下的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的立体匹配模型在恶劣天气下表现不佳，主要由于训练数据稀缺和特征提取困难。

Method: 1. 使用扩散模型生成高质量合成数据；2. 设计结合ConvNet和去噪Transformer的鲁棒特征编码器。

Result: 实验表明，RobuSTereo显著提升了模型在多种恶劣天气下的鲁棒性和泛化能力。

Conclusion: RobuSTereo通过数据合成和特征提取改进，有效解决了立体匹配模型在恶劣天气下的性能问题。

Abstract: Learning-based stereo matching models struggle in adverse weather conditions
due to the scarcity of corresponding training data and the challenges in
extracting discriminative features from degraded images. These limitations
significantly hinder zero-shot generalization to out-of-distribution weather
conditions. In this paper, we propose \textbf{RobuSTereo}, a novel framework
that enhances the zero-shot generalization of stereo matching models under
adverse weather by addressing both data scarcity and feature extraction
challenges. First, we introduce a diffusion-based simulation pipeline with a
stereo consistency module, which generates high-quality stereo data tailored
for adverse conditions. By training stereo matching models on our synthetic
datasets, we reduce the domain gap between clean and degraded images,
significantly improving the models' robustness to unseen weather conditions.
The stereo consistency module ensures structural alignment across synthesized
image pairs, preserving geometric integrity and enhancing depth estimation
accuracy. Second, we design a robust feature encoder that combines a
specialized ConvNet with a denoising transformer to extract stable and reliable
features from degraded images. The ConvNet captures fine-grained local
structures, while the denoising transformer refines global representations,
effectively mitigating the impact of noise, low visibility, and weather-induced
distortions. This enables more accurate disparity estimation even under
challenging visual conditions. Extensive experiments demonstrate that
\textbf{RobuSTereo} significantly improves the robustness and generalization of
stereo matching models across diverse adverse weather scenarios.

</details>


### [73] [SPoT: Subpixel Placement of Tokens in Vision Transformers](https://arxiv.org/abs/2507.01654)
*Martine Hjelkrem-Tan,Marius Aasan,Gabriel Y. Arteaga,Adín Ramírez Rivera*

Main category: cs.CV

TL;DR: 提出了一种名为SPoT的新颖标记化策略，通过连续放置标记来避免网格限制，显著提升了性能并减少了推理所需的标记数量。


<details>
  <summary>Details</summary>
Motivation: 标准标记化方法将特征限制在离散的网格中，阻碍了模型在稀疏场景下的潜力。

Method: 采用子像素标记放置（SPoT）策略，结合oracle引导的搜索，实现连续标记定位。

Result: 通过理想子像素标记定位，显著提升了性能并减少了推理所需的标记数量。

Conclusion: SPoT为ViT架构提供了灵活、高效且可解释的新方向，将稀疏性转化为战略优势。

Abstract: Vision Transformers naturally accommodate sparsity, yet standard tokenization
methods confine features to discrete patch grids. This constraint prevents
models from fully exploiting sparse regimes, forcing awkward compromises. We
propose Subpixel Placement of Tokens (SPoT), a novel tokenization strategy that
positions tokens continuously within images, effectively sidestepping
grid-based limitations. With our proposed oracle-guided search, we uncover
substantial performance gains achievable with ideal subpixel token positioning,
drastically reducing the number of tokens necessary for accurate predictions
during inference. SPoT provides a new direction for flexible, efficient, and
interpretable ViT architectures, redefining sparsity as a strategic advantage
rather than an imposed limitation.

</details>


### [74] [Facial Emotion Learning with Text-Guided Multiview Fusion via Vision-Language Model for 3D/4D Facial Expression Recognition](https://arxiv.org/abs/2507.01673)
*Muzammil Behzad*

Main category: cs.CV

TL;DR: FACET-VLM是一个用于3D/4D面部表情识别的视觉语言框架，通过多视角表示学习和语义引导实现高精度识别，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 3D/4D面部表情识别在情感计算中具有挑战性，但对人机交互、医疗监测等领域至关重要。

Method: FACET-VLM结合了多视角表示学习和自然语言提示的语义引导，包括CVSA、MTGF和一致性损失三个关键组件。

Result: 在多个数据集上达到最先进水平，并成功扩展到4D微表情识别。

Conclusion: FACET-VLM为多模态面部表情识别提供了高效、可扩展的解决方案。

Abstract: Facial expression recognition (FER) in 3D and 4D domains presents a
significant challenge in affective computing due to the complexity of spatial
and temporal facial dynamics. Its success is crucial for advancing applications
in human behavior understanding, healthcare monitoring, and human-computer
interaction. In this work, we propose FACET-VLM, a vision-language framework
for 3D/4D FER that integrates multiview facial representation learning with
semantic guidance from natural language prompts. FACET-VLM introduces three key
components: Cross-View Semantic Aggregation (CVSA) for view-consistent fusion,
Multiview Text-Guided Fusion (MTGF) for semantically aligned facial emotions,
and a multiview consistency loss to enforce structural coherence across views.
Our model achieves state-of-the-art accuracy across multiple benchmarks,
including BU-3DFE, Bosphorus, BU-4DFE, and BP4D-Spontaneous. We further extend
FACET-VLM to 4D micro-expression recognition (MER) on the 4DME dataset,
demonstrating strong performance in capturing subtle, short-lived emotional
cues. The extensive experimental results confirm the effectiveness and
substantial contributions of each individual component within the framework.
Overall, FACET-VLM offers a robust, extensible, and high-performing solution
for multimodal FER in both posed and spontaneous settings.

</details>


### [75] [Component Adaptive Clustering for Generalized Category Discovery](https://arxiv.org/abs/2507.01711)
*Mingfu Yan,Jiancheng Huang,Yifan Liu,Shifeng Chen*

Main category: cs.CV

TL;DR: AdaGCD是一种基于自适应槽注意力的对比学习框架，用于在部分标记数据集中动态分类已知和未知类别。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖预设类别数量的假设，限制了处理真实世界数据的能力，因此需要一种自适应方法。

Method: 提出AdaGCD框架，结合自适应槽注意力（AdaSlot）动态确定槽数量，实现灵活聚类。

Result: 在公开和细粒度数据集上的实验验证了AdaGCD的有效性，尤其在利用空间局部信息方面表现突出。

Conclusion: AdaGCD通过自适应机制和动态槽分配，显著提升了开放世界场景下的类别发现能力。

Abstract: Generalized Category Discovery (GCD) tackles the challenging problem of
categorizing unlabeled images into both known and novel classes within a
partially labeled dataset, without prior knowledge of the number of unknown
categories. Traditional methods often rely on rigid assumptions, such as
predefining the number of classes, which limits their ability to handle the
inherent variability and complexity of real-world data. To address these
shortcomings, we propose AdaGCD, a cluster-centric contrastive learning
framework that incorporates Adaptive Slot Attention (AdaSlot) into the GCD
framework. AdaSlot dynamically determines the optimal number of slots based on
data complexity, removing the need for predefined slot counts. This adaptive
mechanism facilitates the flexible clustering of unlabeled data into known and
novel categories by dynamically allocating representational capacity. By
integrating adaptive representation with dynamic slot allocation, our method
captures both instance-specific and spatially clustered features, improving
class discovery in open-world scenarios. Extensive experiments on public and
fine-grained datasets validate the effectiveness of our framework, emphasizing
the advantages of leveraging spatial local information for category discovery
in unlabeled image datasets.

</details>


### [76] [Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation](https://arxiv.org/abs/2507.01721)
*Zhongwen Zhang,Yuri Boykov*

Main category: cs.CV

TL;DR: 论文提出了一种基于软自标记的弱监督分割方法，通过优化CRF/Potts损失改进网络训练，性能优于复杂系统和全监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有硬伪标签无法表示类别不确定性或错误，因此提出软自标记以提升性能。

Method: 提出一种辅助损失函数，系统评估CRF松弛方法、邻域系统及网络预测与软伪标签的连接方式，并设计连续子问题求解器。

Result: 软自标记显著提升了基于涂鸦的训练效果，性能优于复杂系统和全监督方法。

Conclusion: 软自标记是一种有效的弱监督分割方法，其思想可推广至其他弱监督问题。

Abstract: We consider weakly supervised segmentation where only a fraction of pixels
have ground truth labels (scribbles) and focus on a self-labeling approach
optimizing relaxations of the standard unsupervised CRF/Potts loss on unlabeled
pixels. While WSSS methods can directly optimize such losses via gradient
descent, prior work suggests that higher-order optimization can improve network
training by introducing hidden pseudo-labels and powerful CRF sub-problem
solvers, e.g. graph cut. However, previously used hard pseudo-labels can not
represent class uncertainty or errors, which motivates soft self-labeling. We
derive a principled auxiliary loss and systematically evaluate standard and new
CRF relaxations (convex and non-convex), neighborhood systems, and terms
connecting network predictions with soft pseudo-labels. We also propose a
general continuous sub-problem solver. Using only standard architectures, soft
self-labeling consistently improves scribble-based training and outperforms
significantly more complex specialized WSSS systems. It can outperform full
pixel-precise supervision. Our general ideas apply to other weakly-supervised
problems/systems.

</details>


### [77] [When Does Pruning Benefit Vision Representations?](https://arxiv.org/abs/2507.01722)
*Enrico Cassano,Riccardo Renzulli,Andrea Bragagnolo,Marco Grangetto*

Main category: cs.CV

TL;DR: 本文研究了剪枝对视觉模型在可解释性、无监督目标发现和与人类感知对齐三个方面的影响，发现稀疏模型在某些情况下表现更好，但效果因网络架构和规模而异。


<details>
  <summary>Details</summary>
Motivation: 剪枝常用于降低深度学习模型的复杂度，但其对可解释性和表示学习的影响尚不明确。本文旨在探索剪枝如何影响视觉模型在这三个关键维度上的表现。

Method: 分析不同视觉网络架构在不同稀疏度下对特征归因可解释性方法的影响，研究剪枝是否能促进更简洁的结构化表示，并评估剪枝是否能增强模型表示与人类感知的对齐。

Result: 研究发现存在‘甜点’，即稀疏模型在某些情况下表现出更高的可解释性、下游泛化能力和人类对齐性，但这些效果高度依赖网络架构和规模。

Conclusion: 剪枝对视觉模型的影响复杂，需进一步研究何时及如何剪枝才能优化表示学习。

Abstract: Pruning is widely used to reduce the complexity of deep learning models, but
its effects on interpretability and representation learning remain poorly
understood. This paper investigates how pruning influences vision models across
three key dimensions: (i) interpretability, (ii) unsupervised object discovery,
and (iii) alignment with human perception. We first analyze different vision
network architectures to examine how varying sparsity levels affect feature
attribution interpretability methods. Additionally, we explore whether pruning
promotes more succinct and structured representations, potentially improving
unsupervised object discovery by discarding redundant information while
preserving essential features. Finally, we assess whether pruning enhances the
alignment between model representations and human perception, investigating
whether sparser models focus on more discriminative features similarly to
humans. Our findings also reveal the presence of sweet spots, where sparse
models exhibit higher interpretability, downstream generalization and human
alignment. However, these spots highly depend on the network architectures and
their size in terms of trainable parameters. Our results suggest a complex
interplay between these three dimensions, highlighting the importance of
investigating when and how pruning benefits vision representations.

</details>


### [78] [HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion](https://arxiv.org/abs/2507.01737)
*Lin Wu,Zhixiang Chen,Jianglin Lan*

Main category: cs.CV

TL;DR: 论文提出HOI-Dyn框架，通过驱动-响应系统生成3D人-物交互，利用轻量级Transformer模型预测物体响应，并通过残差动力学损失提升一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将人与物体运动独立处理，导致物理上不合理的行为，需改进交互动力学建模。

Method: 提出HOI-Dyn框架，采用驱动-响应系统，结合Transformer模型预测物体响应，并引入残差动力学损失优化训练。

Result: 实验表明，该方法提升了交互生成质量，并提供了可行的评估指标。

Conclusion: HOI-Dyn框架有效解决了人-物交互生成的动力学一致性问题，同时保持推理效率。

Abstract: Generating realistic 3D human-object interactions (HOIs) remains a
challenging task due to the difficulty of modeling detailed interaction
dynamics. Existing methods treat human and object motions independently,
resulting in physically implausible and causally inconsistent behaviors. In
this work, we present HOI-Dyn, a novel framework that formulates HOI generation
as a driver-responder system, where human actions drive object responses. At
the core of our method is a lightweight transformer-based interaction dynamics
model that explicitly predicts how objects should react to human motion. To
further enforce consistency, we introduce a residual-based dynamics loss that
mitigates the impact of dynamics prediction errors and prevents misleading
optimization signals. The dynamics model is used only during training,
preserving inference efficiency. Through extensive qualitative and quantitative
experiments, we demonstrate that our approach not only enhances the quality of
HOI generation but also establishes a feasible metric for evaluating the
quality of generated interactions.

</details>


### [79] [DeRIS: Decoupling Perception and Cognition for Enhanced Referring Image Segmentation through Loopback Synergy](https://arxiv.org/abs/2507.01738)
*Ming Dai,Wenxuan Cheng,Jiang-jiang Liu,Sen Yang,Wenxiao Cai,Yanpeng Sun,Wankou Yang*

Main category: cs.CV

TL;DR: DeRIS框架将Referring Image Segmentation（RIS）分解为感知和认知两个模块，通过Loopback Synergy机制提升性能，并引入数据增强解决长尾分布问题。


<details>
  <summary>Details</summary>
Motivation: 现有RIS框架缺乏对性能瓶颈的系统分析，尤其是多模态认知能力的不足。

Method: 提出DeRIS框架，分解RIS为感知和认知模块，引入Loopback Synergy机制和数据增强方法。

Result: DeRIS在非和多目标场景中均表现出色，无需专门架构修改。

Conclusion: DeRIS通过模块化分析和改进机制，显著提升了RIS的性能和通用性。

Abstract: Referring Image Segmentation (RIS) is a challenging task that aims to segment
objects in an image based on natural language expressions. While prior studies
have predominantly concentrated on improving vision-language interactions and
achieving fine-grained localization, a systematic analysis of the fundamental
bottlenecks in existing RIS frameworks remains underexplored. To bridge this
gap, we propose DeRIS, a novel framework that decomposes RIS into two key
components: perception and cognition. This modular decomposition facilitates a
systematic analysis of the primary bottlenecks impeding RIS performance. Our
findings reveal that the predominant limitation lies not in perceptual
deficiencies, but in the insufficient multi-modal cognitive capacity of current
models. To mitigate this, we propose a Loopback Synergy mechanism, which
enhances the synergy between the perception and cognition modules, thereby
enabling precise segmentation while simultaneously improving robust image-text
comprehension. Additionally, we analyze and introduce a simple non-referent
sample conversion data augmentation to address the long-tail distribution issue
related to target existence judgement in general scenarios. Notably, DeRIS
demonstrates inherent adaptability to both non- and multi-referents scenarios
without requiring specialized architectural modifications, enhancing its
general applicability. The codes and models are available at
https://github.com/Dmmm1997/DeRIS.

</details>


### [80] [Calibrated Self-supervised Vision Transformers Improve Intracranial Arterial Calcification Segmentation from Clinical CT Head Scans](https://arxiv.org/abs/2507.01744)
*Benjamin Jin,Grant Mair,Joanna M. Wardlaw,Maria del C. Valdés Hernández*

Main category: cs.CV

TL;DR: 本文研究了基于MAE预训练的ViT在3D医学图像分割中的应用，首次将其用于颅内动脉钙化（IAC）分割，并展示了其优于监督学习基线的性能。


<details>
  <summary>Details</summary>
Motivation: 3D ViTs在医学图像分割中表现不佳，但其高效的自我监督训练（如MAE框架）使其成为处理大规模医学影像数据的理想选择。IAC作为神经血管疾病的生物标志物，其自动化量化有助于大规模风险评估。

Method: 通过MAE框架预训练ViT，并在IST-3临床试验的异构数据上微调用于IAC分割。研究了ViT的关键设计选择（如低patch大小和插值上采样）。

Result: 1）自我监督ViT比监督nnU-Net基线高3.2 Dice分数；2）低patch大小和插值上采样对ViT性能至关重要；3）ViT提高了对高切片厚度的鲁棒性，临床风险分类提升46%。

Conclusion: MAE预训练的ViT在IAC分割中表现优异，为医学图像分析提供了高效且鲁棒的解决方案。

Abstract: Vision Transformers (ViTs) have gained significant popularity in the natural
image domain but have been less successful in 3D medical image segmentation.
Nevertheless, 3D ViTs are particularly interesting for large medical imaging
volumes due to their efficient self-supervised training within the masked
autoencoder (MAE) framework, which enables the use of imaging data without the
need for expensive manual annotations. intracranial arterial calcification
(IAC) is an imaging biomarker visible on routinely acquired CT scans linked to
neurovascular diseases such as stroke and dementia, and automated IAC
quantification could enable their large-scale risk assessment. We pre-train
ViTs with MAE and fine-tune them for IAC segmentation for the first time. To
develop our models, we use highly heterogeneous data from a large clinical
trial, the third International Stroke Trial (IST-3). We evaluate key aspects of
MAE pre-trained ViTs in IAC segmentation, and analyse the clinical
implications. We show: 1) our calibrated self-supervised ViT beats a strong
supervised nnU-Net baseline by 3.2 Dice points, 2) low patch sizes are crucial
for ViTs for IAC segmentation and interpolation upsampling with regular
convolutions is preferable to transposed convolutions for ViT-based models, and
3) our ViTs increase robustness to higher slice thicknesses and improve risk
group classification in a clinical scenario by 46%. Our code is available
online.

</details>


### [81] [SSL4SAR: Self-Supervised Learning for Glacier Calving Front Extraction from SAR Imagery](https://arxiv.org/abs/2507.01747)
*Nora Gourmelon,Marcel Dreier,Martin Mayr,Thorsten Seehaus,Dakota Pyles,Matthias Braun,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 论文提出两种自监督多模态预训练技术和混合模型架构，用于冰川消融前缘的精确监测，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 冰川冰量快速减少，需准确监测消融前缘，但现有基于ImageNet预训练的模型因领域差异表现不佳。

Method: 提出自监督多模态预训练技术（基于新数据集SSL4SAR）和混合模型架构（Swin Transformer编码器+CNN解码器）。

Result: 在CaFFe基准数据集上平均距离误差293米，优于之前最佳模型67米；集成模型误差75米，接近人类水平38米。

Conclusion: 新技术显著提升了冰川消融前缘监测的精度，支持季节性变化的精确追踪。

Abstract: Glaciers are losing ice mass at unprecedented rates, increasing the need for
accurate, year-round monitoring to understand frontal ablation, particularly
the factors driving the calving process. Deep learning models can extract
calving front positions from Synthetic Aperture Radar imagery to track seasonal
ice losses at the calving fronts of marine- and lake-terminating glaciers. The
current state-of-the-art model relies on ImageNet-pretrained weights. However,
they are suboptimal due to the domain shift between the natural images in
ImageNet and the specialized characteristics of remote sensing imagery, in
particular for Synthetic Aperture Radar imagery. To address this challenge, we
propose two novel self-supervised multimodal pretraining techniques that
leverage SSL4SAR, a new unlabeled dataset comprising 9,563 Sentinel-1 and 14
Sentinel-2 images of Arctic glaciers, with one optical image per glacier in the
dataset. Additionally, we introduce a novel hybrid model architecture that
combines a Swin Transformer encoder with a residual Convolutional Neural
Network (CNN) decoder. When pretrained on SSL4SAR, this model achieves a mean
distance error of 293 m on the "CAlving Fronts and where to Find thEm" (CaFFe)
benchmark dataset, outperforming the prior best model by 67 m. Evaluating an
ensemble of the proposed model on a multi-annotator study of the benchmark
dataset reveals a mean distance error of 75 m, approaching the human
performance of 38 m. This advancement enables precise monitoring of seasonal
changes in glacier calving fronts.

</details>


### [82] [Rethinking Discrete Tokens: Treating Them as Conditions for Continuous Autoregressive Image Synthesis](https://arxiv.org/abs/2507.01756)
*Peng Zheng,Junke Wang,Yi Chang,Yizhou Yu,Rui Ma,Zuxuan Wu*

Main category: cs.CV

TL;DR: DisCon框架通过将离散标记作为条件信号而非生成目标，解决了连续标记建模的优化挑战，同时避免了量化带来的信息损失，显著提升了图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决基于自回归的视觉生成模型中量化过程导致的信息损失问题，同时避免连续标记建模的挑战。

Method: 提出DisCon框架，将离散标记作为条件信号，建模连续表示的条件概率。

Result: 在ImageNet 256×256生成任务中，gFID得分1.38，优于现有自回归方法。

Conclusion: DisCon通过结合离散和连续表示的优势，显著提升了图像生成性能。

Abstract: Recent advances in large language models (LLMs) have spurred interests in
encoding images as discrete tokens and leveraging autoregressive (AR)
frameworks for visual generation. However, the quantization process in AR-based
visual generation models inherently introduces information loss that degrades
image fidelity. To mitigate this limitation, recent studies have explored to
autoregressively predict continuous tokens. Unlike discrete tokens that reside
in a structured and bounded space, continuous representations exist in an
unbounded, high-dimensional space, making density estimation more challenging
and increasing the risk of generating out-of-distribution artifacts. Based on
the above findings, this work introduces DisCon (Discrete-Conditioned
Continuous Autoregressive Model), a novel framework that reinterprets discrete
tokens as conditional signals rather than generation targets. By modeling the
conditional probability of continuous representations conditioned on discrete
tokens, DisCon circumvents the optimization challenges of continuous token
modeling while avoiding the information loss caused by quantization. DisCon
achieves a gFID score of 1.38 on ImageNet 256$\times$256 generation,
outperforming state-of-the-art autoregressive approaches by a clear margin.

</details>


### [83] [Boosting Adversarial Transferability Against Defenses via Multi-Scale Transformation](https://arxiv.org/abs/2507.01791)
*Zihong Guo,Chen Wan,Yayin Zheng,Hailing Kuang,Xiaohai Lu*

Main category: cs.CV

TL;DR: 提出了一种新的分段高斯金字塔（SGP）攻击方法，通过多尺度图像处理增强对抗样本的迁移性，显著提高了对黑盒防御模型的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 对抗样本的迁移性对深度神经网络构成安全威胁，现有方法通常只关注单尺度图像，限制了攻击效果。

Method: 采用高斯滤波和三种下采样方法构建多尺度样本，计算各尺度损失函数的梯度并取平均以确定对抗扰动。

Result: 实验表明，SGP显著提高了对黑盒防御模型的攻击成功率，平均提升2.3%至32.6%。

Conclusion: SGP是一种可扩展的输入变换方法，易于集成到现有对抗攻击中，有效增强迁移性。

Abstract: The transferability of adversarial examples poses a significant security
challenge for deep neural networks, which can be attacked without knowing
anything about them. In this paper, we propose a new Segmented Gaussian Pyramid
(SGP) attack method to enhance the transferability, particularly against
defense models. Unlike existing methods that generally focus on single-scale
images, our approach employs Gaussian filtering and three types of downsampling
to construct a series of multi-scale examples. Then, the gradients of the loss
function with respect to each scale are computed, and their average is used to
determine the adversarial perturbations. The proposed SGP can be considered an
input transformation with high extensibility that is easily integrated into
most existing adversarial attacks. Extensive experiments demonstrate that in
contrast to the state-of-the-art methods, SGP significantly enhances attack
success rates against black-box defense models, with average attack success
rates increasing by 2.3% to 32.6%, based only on transferability.

</details>


### [84] [FreeLoRA: Enabling Training-Free LoRA Fusion for Autoregressive Multi-Subject Personalization](https://arxiv.org/abs/2507.01792)
*Peng Zheng,Ye Wang,Rui Ma,Zuxuan Wu*

Main category: cs.CV

TL;DR: FreeLoRA提出了一种无需训练的框架，通过融合特定主题的LoRA模块实现多主题个性化图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多主题个性化时需复杂调整或联合优化，难以高效融合多个独立适应的模块。

Method: 采用Full Token Tuning策略训练每个主题的LoRA模块，并通过Subject-Aware Inference在推理时激活对应模块。

Result: 实验表明FreeLoRA在主题保真度和提示一致性上表现优异。

Conclusion: FreeLoRA为多主题个性化提供了一种简单且通用的解决方案。

Abstract: Subject-driven image generation plays a crucial role in applications such as
virtual try-on and poster design. Existing approaches typically fine-tune
pretrained generative models or apply LoRA-based adaptations for individual
subjects. However, these methods struggle with multi-subject personalization,
as combining independently adapted modules often requires complex re-tuning or
joint optimization. We present FreeLoRA, a simple and generalizable framework
that enables training-free fusion of subject-specific LoRA modules for
multi-subject personalization. Each LoRA module is adapted on a few images of a
specific subject using a Full Token Tuning strategy, where it is applied across
all tokens in the prompt to encourage weakly supervised token-content
alignment. At inference, we adopt Subject-Aware Inference, activating each
module only on its corresponding subject tokens. This enables training-free
fusion of multiple personalized subjects within a single image, while
mitigating overfitting and mutual interference between subjects. Extensive
experiments show that FreeLoRA achieves strong performance in both subject
fidelity and prompt consistency.

</details>


### [85] [HCNQA: Enhancing 3D VQA with Hierarchical Concentration Narrowing Supervision](https://arxiv.org/abs/2507.01800)
*Shengli Zhou,Jianuo Zhu,Qilin Huang,Fangjing Wang,Yanfu Zhang,Feng Zheng*

Main category: cs.CV

TL;DR: HCNQA提出了一种分层监督方法，通过模仿人类逐步聚焦的过程，指导3D VQA模型发展合理的推理路径，避免浅层捷径。


<details>
  <summary>Details</summary>
Motivation: 现有3D VQA模型的答案中心监督方法仅监督最终输出，可能导致模型发展浅层推理路径，缺乏对推理过程的监督。

Method: 采用分层浓度窄化监督方法，通过三个阶段逐步聚焦，监督关键检查点，确保模型发展合理推理路径。

Result: 实验表明，HCNQA能有效确保模型发展合理推理路径，并取得更好的性能。

Conclusion: HCNQA通过分层监督方法解决了3D VQA中推理路径监督不足的问题，提升了模型性能。

Abstract: 3D Visual Question-Answering (3D VQA) is pivotal for models to perceive the
physical world and perform spatial reasoning. Answer-centric supervision is a
commonly used training method for 3D VQA models. Many models that utilize this
strategy have achieved promising results in 3D VQA tasks. However, the
answer-centric approach only supervises the final output of models and allows
models to develop reasoning pathways freely. The absence of supervision on the
reasoning pathway enables the potential for developing superficial shortcuts
through common patterns in question-answer pairs. Moreover, although
slow-thinking methods advance large language models, they suffer from
underthinking. To address these issues, we propose \textbf{HCNQA}, a 3D VQA
model leveraging a hierarchical concentration narrowing supervision method. By
mimicking the human process of gradually focusing from a broad area to specific
objects while searching for answers, our method guides the model to perform
three phases of concentration narrowing through hierarchical supervision. By
supervising key checkpoints on a general reasoning pathway, our method can
ensure the development of a rational and effective reasoning pathway. Extensive
experimental results demonstrate that our method can effectively ensure that
the model develops a rational reasoning pathway and performs better. The code
is available at https://github.com/JianuoZhu/HCNQA.

</details>


### [86] [AMD: Adaptive Momentum and Decoupled Contrastive Learning Framework for Robust Long-Tail Trajectory Prediction](https://arxiv.org/abs/2507.01801)
*Bin Rao,Haicheng Liao,Yanchen Guan,Chengyue Wang,Bonan Wang,Jiaxun Zhang,Zhenning Li*

Main category: cs.CV

TL;DR: 论文提出了一种自适应动量和解耦对比学习框架（AMD），用于提升自动驾驶中长尾轨迹预测的性能。通过改进的动量对比学习和解耦对比学习模块，结合轨迹随机增强和在线迭代聚类策略，显著提升了模型对复杂和罕见轨迹的识别能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中准确预测交通参与者的未来轨迹至关重要，但现有研究忽视了长尾轨迹模式的多样性和不确定性，导致对复杂和危险场景的预测能力不足。

Method: 提出AMD框架，结合改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL）模块，设计四种轨迹随机增强方法，并引入在线迭代聚类策略动态更新伪标签。

Result: 在nuScenes和ETH/UCY数据集上的实验表明，AMD在长尾轨迹预测和整体预测精度上均表现最优。

Conclusion: AMD框架通过结合对比学习和动态聚类策略，有效解决了长尾轨迹预测问题，为自动驾驶中的轨迹预测提供了新思路。

Abstract: Accurately predicting the future trajectories of traffic agents is essential
in autonomous driving. However, due to the inherent imbalance in trajectory
distributions, tail data in natural datasets often represents more complex and
hazardous scenarios. Existing studies typically rely solely on a base model's
prediction error, without considering the diversity and uncertainty of
long-tail trajectory patterns. We propose an adaptive momentum and decoupled
contrastive learning framework (AMD), which integrates unsupervised and
supervised contrastive learning strategies. By leveraging an improved momentum
contrast learning (MoCo-DT) and decoupled contrastive learning (DCL) module,
our framework enhances the model's ability to recognize rare and complex
trajectories. Additionally, we design four types of trajectory random
augmentation methods and introduce an online iterative clustering strategy,
allowing the model to dynamically update pseudo-labels and better adapt to the
distributional shifts in long-tail data. We propose three different criteria to
define long-tail trajectories and conduct extensive comparative experiments on
the nuScenes and ETH$/$UCY datasets. The results show that AMD not only
achieves optimal performance in long-tail trajectory prediction but also
demonstrates outstanding overall prediction accuracy.

</details>


### [87] [Modulate and Reconstruct: Learning Hyperspectral Imaging from Misaligned Smartphone Views](https://arxiv.org/abs/2507.01835)
*Daniil Reutsky,Daniil Vladimirov,Yasin Mamedov,Georgy Perevozchikov,Nancy Mehta,Egor Ershov,Radu Timofte*

Main category: cs.CV

TL;DR: 提出了一种基于多图像的超光谱重建（MI-HSR）框架，利用配备光谱滤镜的三摄像头智能手机系统，显著提高了重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单张RGB图像，导致光谱信息损失严重，限制了重建精度。

Method: 采用三摄像头智能手机系统，其中两个镜头配备精心选择的光谱滤镜，结合理论和实证分析，提出MI-HSR框架，并引入首个数据集Doomer。

Result: 实验表明，该方法在新建基准上优于现有方法，光谱估计精度比普通RGB相机提高30%。

Conclusion: 多视角光谱滤波结合商用硬件可实现更准确、实用的超光谱成像解决方案。

Abstract: Hyperspectral reconstruction (HSR) from RGB images is a fundamentally
ill-posed problem due to severe spectral information loss. Existing approaches
typically rely on a single RGB image, limiting reconstruction accuracy. In this
work, we propose a novel multi-image-to-hyperspectral reconstruction (MI-HSR)
framework that leverages a triple-camera smartphone system, where two lenses
are equipped with carefully selected spectral filters. Our configuration,
grounded in theoretical and empirical analysis, enables richer and more diverse
spectral observations than conventional single-camera setups. To support this
new paradigm, we introduce Doomer, the first dataset for MI-HSR, comprising
aligned images from three smartphone cameras and a hyperspectral reference
camera across diverse scenes. We show that the proposed HSR model achieves
consistent improvements over existing methods on the newly proposed benchmark.
In a nutshell, our setup allows 30% towards more accurately estimated spectra
compared to an ordinary RGB camera. Our findings suggest that multi-view
spectral filtering with commodity hardware can unlock more accurate and
practical hyperspectral imaging solutions.

</details>


### [88] [MobileIE: An Extremely Lightweight and Effective ConvNet for Real-Time Image Enhancement on Mobile Devices](https://arxiv.org/abs/2507.01838)
*Hailong Yan,Ao Li,Xiangtao Zhang,Zhe Liu,Zenglin Shi,Ce Zhu,Le Zhang*

Main category: cs.CV

TL;DR: 提出了一种极轻量级的CNN框架，用于移动设备上的实时图像增强，参数仅约4K，首次实现1,100 FPS的实时推理。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在资源受限平台（如移动设备）上部署时的高计算和内存需求问题。

Method: 结合重参数化和增量权重优化策略，引入特征自变换模块和分层双路径注意力机制，并使用局部方差加权损失优化性能。

Result: 在多个图像增强任务中实现了速度与性能的最佳平衡，达到1,100 FPS的实时推理。

Conclusion: 该框架为移动设备上的实时图像增强提供了高效解决方案，代码已开源。

Abstract: Recent advancements in deep neural networks have driven significant progress
in image enhancement (IE). However, deploying deep learning models on
resource-constrained platforms, such as mobile devices, remains challenging due
to high computation and memory demands. To address these challenges and
facilitate real-time IE on mobile, we introduce an extremely lightweight
Convolutional Neural Network (CNN) framework with around 4K parameters. Our
approach integrates reparameterization with an Incremental Weight Optimization
strategy to ensure efficiency. Additionally, we enhance performance with a
Feature Self-Transform module and a Hierarchical Dual-Path Attention mechanism,
optimized with a Local Variance-Weighted loss. With this efficient framework,
we are the first to achieve real-time IE inference at up to 1,100 frames per
second (FPS) while delivering competitive image quality, achieving the best
trade-off between speed and performance across multiple IE tasks. The code will
be available at https://github.com/AVC2-UESTC/MobileIE.git.

</details>


### [89] [Future Slot Prediction for Unsupervised Object Discovery in Surgical Video](https://arxiv.org/abs/2507.01882)
*Guiqiu Liao,Matjaz Jogan,Marcel Hussing,Edward Zhang,Eric Eaton,Daniel A. Hashimoto*

Main category: cs.CV

TL;DR: 论文提出了一种动态时序槽变换器（DTST）模块，用于解决手术视频中对象中心表示学习的挑战，并在多个手术数据库中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界应用（如手术）中的异构场景难以解析为有意义的一组槽，现有方法在手术视频上表现不佳。

Method: 提出动态时序槽变换器（DTST）模块，结合时序推理和预测未来最优槽初始化。

Result: 在多个手术数据库中实现了最先进的性能。

Conclusion: 无监督对象中心方法可应用于现实世界数据，并成为医疗应用中的常见工具。

Abstract: Object-centric slot attention is an emerging paradigm for unsupervised
learning of structured, interpretable object-centric representations (slots).
This enables effective reasoning about objects and events at a low
computational cost and is thus applicable to critical healthcare applications,
such as real-time interpretation of surgical video. The heterogeneous scenes in
real-world applications like surgery are, however, difficult to parse into a
meaningful set of slots. Current approaches with an adaptive slot count perform
well on images, but their performance on surgical videos is low. To address
this challenge, we propose a dynamic temporal slot transformer (DTST) module
that is trained both for temporal reasoning and for predicting the optimal
future slot initialization. The model achieves state-of-the-art performance on
multiple surgical databases, demonstrating that unsupervised object-centric
methods can be applied to real-world data and become part of the common arsenal
in healthcare applications.

</details>


### [90] [Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation for Semi-Supervised Lifelong Person Re-Identification](https://arxiv.org/abs/2507.01884)
*Kunlun Xu,Fan Zhuo,Jiangmeng Li,Xu Zou,Jiahuan Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种新型框架SPRED，用于解决半监督终身行人重识别（Semi-LReID）问题，通过动态原型引导的伪标签生成和新旧知识协同净化，显著提升了未标记数据的利用效果。


<details>
  <summary>Details</summary>
Motivation: 现实场景中标注资源有限，现有LReID方法在未标记数据利用时性能下降严重，亟需一种能够长期适应并减少噪声影响的半监督方法。

Method: SPRED框架结合动态原型生成高质量伪标签，并通过新旧知识协同净化机制优化伪标签，形成自我强化的循环。

Result: 在Semi-LReID基准测试中，SPRED取得了最先进的性能。

Conclusion: SPRED通过动态原型和知识协同机制，显著提升了半监督终身行人重识别的性能，为未来研究提供了新思路。

Abstract: Current lifelong person re-identification (LReID) methods predominantly rely
on fully labeled data streams. However, in real-world scenarios where
annotation resources are limited, a vast amount of unlabeled data coexists with
scarce labeled samples, leading to the Semi-Supervised LReID (Semi-LReID)
problem where LReID methods suffer severe performance degradation. Existing
LReID methods, even when combined with semi-supervised strategies, suffer from
limited long-term adaptation performance due to struggling with the noisy
knowledge occurring during unlabeled data utilization. In this paper, we
pioneer the investigation of Semi-LReID, introducing a novel Self-Reinforcing
Prototype Evolution with Dual-Knowledge Cooperation framework (SPRED). Our key
innovation lies in establishing a self-reinforcing cycle between dynamic
prototype-guided pseudo-label generation and new-old knowledge collaborative
purification to enhance the utilization of unlabeled data. Specifically,
learnable identity prototypes are introduced to dynamically capture the
identity distributions and generate high-quality pseudo-labels. Then, the
dual-knowledge cooperation scheme integrates current model specialization and
historical model generalization, refining noisy pseudo-labels. Through this
cyclic design, reliable pseudo-labels are progressively mined to improve
current-stage learning and ensure positive knowledge propagation over long-term
learning. Experiments on the established Semi-LReID benchmarks show that our
SPRED achieves state-of-the-art performance. Our source code is available at
https://github.com/zhoujiahuan1991/ICCV2025-SPRED

</details>


### [91] [Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning](https://arxiv.org/abs/2507.01908)
*Qingdong He,Xueqin Chen,Chaoyi Wang,Yanjie Pan,Xiaobin Hu,Zhenye Gan,Yabiao Wang,Chengjie Wang,Xiangtai Li,Jiangning Zhang*

Main category: cs.CV

TL;DR: 论文提出了Reason50K数据集和ReasonBrain框架，用于解决复杂假设指令的图像编辑问题，通过多模态大语言模型和细粒度推理模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理复杂隐式假设指令，缺乏支持推理的数据集和架构。

Method: 提出Reason50K数据集和ReasonBrain框架，结合MLLM和扩散模型，引入FRCE和CME模块。

Result: ReasonBrain在推理场景中表现优异，并具有零样本泛化能力。

Conclusion: Reason50K和ReasonBrain为复杂指令图像编辑提供了有效解决方案。

Abstract: Instruction-based image editing (IIE) has advanced rapidly with the success
of diffusion models. However, existing efforts primarily focus on simple and
explicit instructions to execute editing operations such as adding, deleting,
moving, or swapping objects. They struggle to handle more complex implicit
hypothetical instructions that require deeper reasoning to infer plausible
visual changes and user intent. Additionally, current datasets provide limited
support for training and evaluating reasoning-aware editing capabilities.
Architecturally, these methods also lack mechanisms for fine-grained detail
extraction that support such reasoning. To address these limitations, we
propose Reason50K, a large-scale dataset specifically curated for training and
evaluating hypothetical instruction reasoning image editing, along with
ReasonBrain, a novel framework designed to reason over and execute implicit
hypothetical instructions across diverse scenarios. Reason50K includes over 50K
samples spanning four key reasoning scenarios: Physical, Temporal, Causal, and
Story reasoning. ReasonBrain leverages Multimodal Large Language Models (MLLMs)
for editing guidance generation and a diffusion model for image synthesis,
incorporating a Fine-grained Reasoning Cue Extraction (FRCE) module to capture
detailed visual and textual semantics essential for supporting instruction
reasoning. To mitigate the semantic loss, we further introduce a Cross-Modal
Enhancer (CME) that enables rich interactions between the fine-grained cues and
MLLM-derived features. Extensive experiments demonstrate that ReasonBrain
consistently outperforms state-of-the-art baselines on reasoning scenarios
while exhibiting strong zero-shot generalization to conventional IIE tasks. Our
dataset and code will be released publicly.

</details>


### [92] [Modality Agnostic, patient-specific digital twins modeling temporally varying digestive motion](https://arxiv.org/abs/2507.01909)
*Jorge Tapias Gomez,Nishant Nadkarni,Lando S. Bosma,Jue Jiang,Ergys D. Subashi,William P. Segars,James M. Balter,Mert R Sabuncu,Neelam Tyagi,Harini Veeraraghavan*

Main category: cs.CV

TL;DR: 该论文提出了一种基于患者特异性数字孪生（DT）的管道，用于评估变形图像配准（DIR）方法在胃肠道（GI）器官运动中的准确性，并验证剂量映射的精确性。


<details>
  <summary>Details</summary>
Motivation: 临床实现DIR需要基于体素的空间准确性指标，如手动标记的界标，但对于高度移动的GI器官难以实施。因此，需要一种新方法来评估DIR的准确性。

Method: 通过半自动化管道，利用已发表的GI运动模型，从静态3D患者扫描生成21个运动阶段的4D序列，模拟消化GI运动。使用11个数据集（包括MRI和CT扫描）评估DIR方法的性能。

Result: 生成的DT模拟了真实的GI运动，运动幅度和Jacobian行列式与真实患者数据相似。该方法能够提取详细的DIR性能指标并验证剂量映射准确性。

Conclusion: 该管道为动态且解剖复杂的区域提供了严格的DIR工具测试，实现了空间和剂量学的精确评估。

Abstract: Objective: Clinical implementation of deformable image registration (DIR)
requires voxel-based spatial accuracy metrics such as manually identified
landmarks, which are challenging to implement for highly mobile
gastrointestinal (GI) organs. To address this, patient-specific digital twins
(DT) modeling temporally varying motion were created to assess the accuracy of
DIR methods. Approach: 21 motion phases simulating digestive GI motion as 4D
sequences were generated from static 3D patient scans using published
analytical GI motion models through a semi-automated pipeline. Eleven datasets,
including six T2w FSE MRI (T2w MRI), two T1w 4D golden-angle stack-of-stars,
and three contrast-enhanced CT scans. The motion amplitudes of the DTs were
assessed against real patient stomach motion amplitudes extracted from
independent 4D MRI datasets. The generated DTs were then used to assess six
different DIR methods using target registration error, Dice similarity
coefficient, and the 95th percentile Hausdorff distance using summary metrics
and voxel-level granular visualizations. Finally, for a subset of T2w MRI scans
from patients treated with MR-guided radiation therapy, dose distributions were
warped and accumulated to assess dose warping errors, including evaluations of
DIR performance in both low- and high-dose regions for patient-specific error
estimation. Main results: Our proposed pipeline synthesized DTs modeling
realistic GI motion, achieving mean and maximum motion amplitudes and a mean
log Jacobian determinant within 0.8 mm and 0.01, respectively, similar to
published real-patient gastric motion data. It also enables the extraction of
detailed quantitative DIR performance metrics and rigorous validation of dose
mapping accuracy. Significance: The pipeline enables rigorously testing DIR
tools for dynamic, anatomically complex regions enabling granular spatial and
dosimetric accuracies.

</details>


### [93] [3D Reconstruction and Information Fusion between Dormant and Canopy Seasons in Commercial Orchards Using Deep Learning and Fast GICP](https://arxiv.org/abs/2507.01912)
*Ranjan Sapkota,Zhichao Meng,Martin Churuvija,Xiaoqiang Du,Zenghong Ma,Manoj Karkee*

Main category: cs.CV

TL;DR: 提出了一种融合多季节结构数据的框架，用于支持果园自动化管理，解决了生长季节树冠遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 生长季节树冠密集遮挡树干和树枝，限制了机器视觉系统的能力，而休眠季节树冠结构更清晰可见。

Method: 结合休眠期和生长期的RGB-D图像，使用YOLOv9-Seg进行实例分割，Kinect Fusion进行3D重建，Fast GICP进行模型对齐。

Result: YOLOv9-Seg的MSE为0.0047，分割mAP@50达0.78；Kinect Fusion重建误差小（树干直径RMSE为5.23 mm）；Fast GICP配准精度高（最小适应分数0.00197）。

Conclusion: 多季节数据融合框架为机器人系统提供了完整的树结构信息，提升了修剪和疏果等自动化操作的精度。

Abstract: In orchard automation, dense foliage during the canopy season severely
occludes tree structures, minimizing visibility to various canopy parts such as
trunks and branches, which limits the ability of a machine vision system.
However, canopy structure is more open and visible during the dormant season
when trees are defoliated. In this work, we present an information fusion
framework that integrates multi-seasonal structural data to support robotic and
automated crop load management during the entire growing season. The framework
combines high-resolution RGB-D imagery from both dormant and canopy periods
using YOLOv9-Seg for instance segmentation, Kinect Fusion for 3D
reconstruction, and Fast Generalized Iterative Closest Point (Fast GICP) for
model alignment. Segmentation outputs from YOLOv9-Seg were used to extract
depth-informed masks, which enabled accurate 3D point cloud reconstruction via
Kinect Fusion; these reconstructed models from each season were subsequently
aligned using Fast GICP to achieve spatially coherent multi-season fusion. The
YOLOv9-Seg model, trained on manually annotated images, achieved a mean squared
error (MSE) of 0.0047 and segmentation mAP@50 scores up to 0.78 for trunks in
dormant season dataset. Kinect Fusion enabled accurate reconstruction of tree
geometry, validated with field measurements resulting in root mean square
errors (RMSE) of 5.23 mm for trunk diameter, 4.50 mm for branch diameter, and
13.72 mm for branch spacing. Fast GICP achieved precise cross-seasonal
registration with a minimum fitness score of 0.00197, allowing integrated,
comprehensive tree structure modeling despite heavy occlusions during the
growing season. This fused structural representation enables robotic systems to
access otherwise obscured architectural information, improving the precision of
pruning, thinning, and other automated orchard operations.

</details>


### [94] [IC-Custom: Diverse Image Customization via In-Context Learning](https://arxiv.org/abs/2507.01926)
*Yaowei Li,Xiaoyu Li,Zhaoyang Zhang,Yuxuan Bian,Gan Liu,Xinyuan Li,Jiale Xu,Wenbo Hu,Yating Liu,Lingen Li,Jing Cai,Yuexian Zou,Yancheng He,Ying Shan*

Main category: cs.CV

TL;DR: IC-Custom是一个统一的图像定制框架，通过上下文学习整合位置感知和无位置定制，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有图像定制方法缺乏通用框架的问题，提升多样场景下的应用能力。

Method: 提出IC-Custom框架，结合DiT的多模态注意力机制，引入ICMA机制和高质量数据集。

Result: 在多个基准测试中表现优异，人类偏好提升73%，仅训练0.4%参数。

Conclusion: IC-Custom为工业应用提供了高效、通用的图像定制解决方案。

Abstract: Image customization, a crucial technique for industrial media production,
aims to generate content that is consistent with reference images. However,
current approaches conventionally separate image customization into
position-aware and position-free customization paradigms and lack a universal
framework for diverse customization, limiting their applications across various
scenarios. To overcome these limitations, we propose IC-Custom, a unified
framework that seamlessly integrates position-aware and position-free image
customization through in-context learning. IC-Custom concatenates reference
images with target images to a polyptych, leveraging DiT's multi-modal
attention mechanism for fine-grained token-level interactions. We introduce the
In-context Multi-Modal Attention (ICMA) mechanism with learnable task-oriented
register tokens and boundary-aware positional embeddings to enable the model to
correctly handle different task types and distinguish various inputs in
polyptych configurations. To bridge the data gap, we carefully curated a
high-quality dataset of 12k identity-consistent samples with 8k from real-world
sources and 4k from high-quality synthetic data, avoiding the overly glossy and
over-saturated synthetic appearance. IC-Custom supports various industrial
applications, including try-on, accessory placement, furniture arrangement, and
creative IP customization. Extensive evaluations on our proposed ProductBench
and the publicly available DreamBench demonstrate that IC-Custom significantly
outperforms community workflows, closed-source models, and state-of-the-art
open-source approaches. IC-Custom achieves approximately 73% higher human
preference across identity consistency, harmonicity, and text alignment
metrics, while training only 0.4% of the original model parameters. Project
page: https://liyaowei-stu.github.io/project/IC_Custom

</details>


### [95] [evMLP: An Efficient Event-Driven MLP Architecture for Vision](https://arxiv.org/abs/2507.01927)
*Zhentan Zheng*

Main category: cs.CV

TL;DR: 论文提出了一种名为evMLP的模型，结合事件驱动的局部更新机制，通过选择性处理图像或特征图中的变化区域，显著提升了视频处理的计算效率。


<details>
  <summary>Details</summary>
Motivation: 探索多层感知机（MLPs）在视觉模型架构中的应用，并针对视频处理中的冗余计算问题，提出一种高效的解决方案。

Method: 提出evMLP模型，利用事件驱动的局部更新机制，仅处理连续帧间发生变化的图像块（事件），避免冗余计算。

Result: 在ImageNet分类任务中表现优异，视频数据集实验显示其显著降低计算成本，同时保持输出一致性。

Conclusion: evMLP通过事件驱动机制，为视频处理提供了一种高效且性能优越的解决方案。

Abstract: Deep neural networks have achieved remarkable results in computer vision
tasks. In the early days, Convolutional Neural Networks (CNNs) were the
mainstream architecture. In recent years, Vision Transformers (ViTs) have
become increasingly popular. In addition, exploring applications of multi-layer
perceptrons (MLPs) has provided new perspectives for research into vision model
architectures. In this paper, we present evMLP accompanied by a simple
event-driven local update mechanism. The proposed evMLP can independently
process patches on images or feature maps via MLPs. We define changes between
consecutive frames as "events". Under the event-driven local update mechanism,
evMLP selectively processes patches where events occur. For sequential image
data (e.g., video processing), this approach improves computational performance
by avoiding redundant computations. Through ImageNet image classification
experiments, evMLP attains accuracy competitive with state-of-the-art models.
More significantly, experimental results on multiple video datasets demonstrate
that evMLP reduces computational cost via its event-driven local update
mechanism while maintaining output consistency with its non-event-driven
baseline. The code and trained models are available at
https://github.com/i-evi/evMLP.

</details>


### [96] [CI-VID: A Coherent Interleaved Text-Video Dataset](https://arxiv.org/abs/2507.01938)
*Yiming Ju,Jijin Hu,Zhengxiong Luo,Haoge Deng,hanyu Zhao,Li Du,Chengwei Wu,Donglin Hao,Xinlong Wang,Tengfei Pan*

Main category: cs.CV

TL;DR: 论文介绍了CI-VID数据集，用于支持连贯多场景视频序列的生成，超越了传统的孤立文本-视频对数据集。


<details>
  <summary>Details</summary>
Motivation: 现有公开数据集主要由孤立的文本-视频对组成，无法支持连贯多场景视频序列的建模。

Method: 提出CI-VID数据集，包含34万样本，每个样本包含连贯的视频片段序列和文本描述，支持文本和视频到视频的生成。

Result: 实验表明，基于CI-VID训练的模型在生成视频序列时显著提升了准确性和内容一致性。

Conclusion: CI-VID数据集为故事驱动内容的生成提供了高质量支持，具有实际应用价值。

Abstract: Text-to-video (T2V) generation has recently attracted considerable attention,
resulting in the development of numerous high-quality datasets that have
propelled progress in this area. However, existing public datasets are
primarily composed of isolated text-video (T-V) pairs and thus fail to support
the modeling of coherent multi-clip video sequences. To address this
limitation, we introduce CI-VID, a dataset that moves beyond isolated
text-to-video (T2V) generation toward text-and-video-to-video (TV2V)
generation, enabling models to produce coherent, multi-scene video sequences.
CI-VID contains over 340,000 samples, each featuring a coherent sequence of
video clips with text captions that capture both the individual content of each
clip and the transitions between them, enabling visually and textually grounded
generation. To further validate the effectiveness of CI-VID, we design a
comprehensive, multi-dimensional benchmark incorporating human evaluation,
VLM-based assessment, and similarity-based metrics. Experimental results
demonstrate that models trained on CI-VID exhibit significant improvements in
both accuracy and content consistency when generating video sequences. This
facilitates the creation of story-driven content with smooth visual transitions
and strong temporal coherence, underscoring the quality and practical utility
of the CI-VID dataset We release the CI-VID dataset and the accompanying code
for data construction and evaluation at: https://github.com/ymju-BAAI/CI-VID

</details>


### [97] [LongAnimation: Long Animation Generation with Dynamic Global-Local Memory](https://arxiv.org/abs/2507.01945)
*Nan Chen,Mengqi Huang,Yihao Meng,Zhendong Mao*

Main category: cs.CV

TL;DR: 论文提出了一种名为LongAnimation的框架，用于解决长动画着色中的长期颜色一致性问题，通过动态全局-局部范式实现。


<details>
  <summary>Details</summary>
Motivation: 长动画着色在动画产业中成本高昂，现有研究仅关注短期着色，缺乏全局信息导致长期颜色一致性不足。

Method: 提出LongAnimation框架，包括SketchDiT、动态全局-局部记忆模块（DGLM）和颜色一致性奖励机制，动态融合全局与局部特征。

Result: 实验表明，LongAnimation在短期（14帧）和长期（平均500帧）动画着色任务中均能有效保持颜色一致性。

Conclusion: LongAnimation通过动态全局-局部范式成功解决了长动画着色中的颜色一致性问题，具有实际应用价值。

Abstract: Animation colorization is a crucial part of real animation industry
production. Long animation colorization has high labor costs. Therefore,
automated long animation colorization based on the video generation model has
significant research value. Existing studies are limited to short-term
colorization. These studies adopt a local paradigm, fusing overlapping features
to achieve smooth transitions between local segments. However, the local
paradigm neglects global information, failing to maintain long-term color
consistency. In this study, we argue that ideal long-term color consistency can
be achieved through a dynamic global-local paradigm, i.e., dynamically
extracting global color-consistent features relevant to the current generation.
Specifically, we propose LongAnimation, a novel framework, which mainly
includes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a Color
Consistency Reward. The SketchDiT captures hybrid reference features to support
the DGLM module. The DGLM module employs a long video understanding model to
dynamically compress global historical features and adaptively fuse them with
the current generation features. To refine the color consistency, we introduce
a Color Consistency Reward. During inference, we propose a color consistency
fusion to smooth the video segment transition. Extensive experiments on both
short-term (14 frames) and long-term (average 500 frames) animations show the
effectiveness of LongAnimation in maintaining short-term and long-term color
consistency for open-domain animation colorization task. The code can be found
at https://cn-makers.github.io/long_animation_web/.

</details>


### [98] [Kwai Keye-VL Technical Report](https://arxiv.org/abs/2507.01949)
*Kwai Keye Team,Biao Yang,Bin Wen,Changyi Liu,Chenglong Chu,Chengru Song,Chongling Rao,Chuan Yi,Da Li,Dunju Zang,Fan Yang,Guorui Zhou,Hao Peng,Haojie Ding,Jiaming Huang,Jiangxia Cao,Jiankang Chen,Jingyun Hua,Jin Ouyang,Kaibing Chen,Kaiyu Jiang,Kaiyu Tang,Kun Gai,Shengnan Zhang,Siyang Mao,Sui Huang,Tianke Zhang,Tingting Gao,Wei Chen,Wei Yuan,Xiangyu Wu,Xiao Hu,Xingyu Lu,Yang Zhou,Yi-Fan Zhang,Yiping Yang,Yulong Chen,Zhenhua Wu,Zhenyu Li,Zhixin Ling,Ziming Li,Dehua Ma,Di Xu,Haixuan Gao,Hang Li,Jiawei Guo,Jing Wang,Lejian Ren,Muhao Wei,Qianqian Wang,Qigen Hu,Shiyao Wang,Tao Yu,Xinchen Luo,Yan Li,Yiming Liang,Yuhang Hu,Zeyi Lu,Zhuoran Yang,Zixing Zhang*

Main category: cs.CV

TL;DR: Kwai Keye-VL是一个8B参数的多模态基础模型，专注于短视频理解，同时保持通用视觉-语言能力。通过大规模高质量数据集和创新训练方法，实现了领先性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型（MLLMs）在静态图像上表现优异，但在动态、信息密集的短视频理解上不足，Kwai Keye-VL旨在填补这一空白。

Method: 采用四阶段预训练和两阶段后训练方法，包括创新的五模式“冷启动”数据混合和强化学习优化。

Result: Keye-VL在公共视频基准测试中达到领先水平，并在通用图像任务中保持竞争力。

Conclusion: Kwai Keye-VL为短视频理解提供了高效解决方案，并通过新基准KC-MMBench验证了其优势。

Abstract: While Multimodal Large Language Models (MLLMs) demonstrate remarkable
capabilities on static images, they often fall short in comprehending dynamic,
information-dense short-form videos, a dominant medium in today's digital
landscape. To bridge this gap, we introduce \textbf{Kwai Keye-VL}, an
8-billion-parameter multimodal foundation model engineered for leading-edge
performance in short-video understanding while maintaining robust
general-purpose vision-language abilities. The development of Keye-VL rests on
two core pillars: a massive, high-quality dataset exceeding 600 billion tokens
with a strong emphasis on video, and an innovative training recipe. This recipe
features a four-stage pre-training process for solid vision-language alignment,
followed by a meticulous two-phase post-training process. The first
post-training stage enhances foundational capabilities like instruction
following, while the second phase focuses on stimulating advanced reasoning. In
this second phase, a key innovation is our five-mode ``cold-start'' data
mixture, which includes ``thinking'', ``non-thinking'', ``auto-think'', ``think
with image'', and high-quality video data. This mixture teaches the model to
decide when and how to reason. Subsequent reinforcement learning (RL) and
alignment steps further enhance these reasoning capabilities and correct
abnormal model behaviors, such as repetitive outputs. To validate our approach,
we conduct extensive evaluations, showing that Keye-VL achieves
state-of-the-art results on public video benchmarks and remains highly
competitive on general image-based tasks (Figure 1). Furthermore, we develop
and release the \textbf{KC-MMBench}, a new benchmark tailored for real-world
short-video scenarios, where Keye-VL shows a significant advantage.

</details>


### [99] [FreeMorph: Tuning-Free Generalized Image Morphing with Diffusion Model](https://arxiv.org/abs/2507.01953)
*Yukang Cao,Chenyang Si,Jinghao Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: FreeMorph是一种无需调优的图像变形方法，适用于不同语义或布局的输入，通过创新的自注意力模块设计和步骤导向的变化趋势，实现高质量变形。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预训练扩散模型的微调，受限于时间和语义/布局差异，FreeMorph旨在解决这些问题，提供无需实例训练的高保真图像变形。

Method: 1) 提出指导感知的球面插值设计，通过修改自注意力模块显式整合输入图像的指导；2) 引入步骤导向的变化趋势，混合输入图像的自注意力模块以实现可控过渡。

Result: FreeMorph在图像变形任务中表现优异，速度提升10~50倍，成为新的最先进方法。

Conclusion: FreeMorph通过创新设计解决了无需调优方法的质量问题，为图像变形领域提供了高效、高质量的解决方案。

Abstract: We present FreeMorph, the first tuning-free method for image morphing that
accommodates inputs with different semantics or layouts. Unlike existing
methods that rely on finetuning pre-trained diffusion models and are limited by
time constraints and semantic/layout discrepancies, FreeMorph delivers
high-fidelity image morphing without requiring per-instance training. Despite
their efficiency and potential, tuning-free methods face challenges in
maintaining high-quality results due to the non-linear nature of the multi-step
denoising process and biases inherited from the pre-trained diffusion model. In
this paper, we introduce FreeMorph to address these challenges by integrating
two key innovations. 1) We first propose a guidance-aware spherical
interpolation design that incorporates explicit guidance from the input images
by modifying the self-attention modules, thereby addressing identity loss and
ensuring directional transitions throughout the generated sequence. 2) We
further introduce a step-oriented variation trend that blends self-attention
modules derived from each input image to achieve controlled and consistent
transitions that respect both inputs. Our extensive evaluations demonstrate
that FreeMorph outperforms existing methods, being 10x ~ 50x faster and
establishing a new state-of-the-art for image morphing.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [100] [MALIBU Benchmark: Multi-Agent LLM Implicit Bias Uncovered](https://arxiv.org/abs/2507.01019)
*Imran Mirza,Cole Huang,Ishwara Vasista,Rohan Patil,Asli Akalin,Sean O'Brien,Kevin Zhu*

Main category: cs.CL

TL;DR: MALIBU是一个新基准，用于评估基于LLM的多智能体系统中隐含的社会偏见和刻板印象。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统可能强化LLM中的隐性偏见，引发公平性和代表性担忧。

Method: 通过场景化评估，分两阶段由LLM多智能体评判系统对带标签的响应进行评分和比较。

Result: 研究发现偏见缓解可能偏向边缘化群体，而非真正中立。

Conclusion: 需在系统中采用细致检测、平衡公平策略和透明评估基准。

Abstract: Multi-agent systems, which consist of multiple AI models interacting within a
shared environment, are increasingly used for persona-based interactions.
However, if not carefully designed, these systems can reinforce implicit biases
in large language models (LLMs), raising concerns about fairness and equitable
representation. We present MALIBU, a novel benchmark developed to assess the
degree to which LLM-based multi-agent systems implicitly reinforce social
biases and stereotypes. MALIBU evaluates bias in LLM-based multi-agent systems
through scenario-based assessments. AI models complete tasks within predefined
contexts, and their responses undergo evaluation by an LLM-based multi-agent
judging system in two phases. In the first phase, judges score responses
labeled with specific demographic personas (e.g., gender, race, religion)
across four metrics. In the second phase, judges compare paired responses
assigned to different personas, scoring them and selecting the superior
response. Our study quantifies biases in LLM-generated outputs, revealing that
bias mitigation may favor marginalized personas over true neutrality,
emphasizing the need for nuanced detection, balanced fairness strategies, and
transparent evaluation benchmarks in multi-agent systems.

</details>


### [101] [Event-based evaluation of abstractive news summarization](https://arxiv.org/abs/2507.01160)
*Huiling You,Samia Touileb,Erik Velldal,Lilja Øvrelid*

Main category: cs.CL

TL;DR: 提出了一种基于事件重叠的抽象摘要评估方法，通过比较生成摘要、参考摘要和原文的事件重叠来衡量摘要质量。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要依赖人工参考摘要的重叠单元或相似性评分，未能充分反映摘要中事件信息的完整性。

Method: 利用挪威语数据集的事件标注和专家摘要，计算生成摘要、参考摘要和原文之间的事件重叠。

Result: 该方法能更深入地分析摘要中的事件信息。

Conclusion: 基于事件重叠的评估方法为抽象摘要质量提供了更全面的视角。

Abstract: An abstractive summary of a news article contains its most important
information in a condensed version. The evaluation of automatically generated
summaries by generative language models relies heavily on human-authored
summaries as gold references, by calculating overlapping units or similarity
scores. News articles report events, and ideally so should the summaries. In
this work, we propose to evaluate the quality of abstractive summaries by
calculating overlapping events between generated summaries, reference
summaries, and the original news articles. We experiment on a richly annotated
Norwegian dataset comprising both events annotations and summaries authored by
expert human annotators. Our approach provides more insight into the event
information contained in the summaries.

</details>


### [102] [Matching and Linking Entries in Historical Swedish Encyclopedias](https://arxiv.org/abs/2507.01170)
*Simon Börjesson,Erik Ersmark,Pierre Nugues*

Main category: cs.CL

TL;DR: 本文分析了瑞典百科全书《Nordisk familjebok》第一版和第二版中地理条目的变化，发现从欧洲向北美、非洲、亚洲、澳大利亚和北欧的显著转移。


<details>
  <summary>Details</summary>
Motivation: 研究目的是通过数字化版本分析百科全书条目内容的变化，反映瑞典社会的知识变迁。

Method: 使用语义句子嵌入匹配条目，基于Transformer的分类器提取地理条目，并与Wikidata链接。

Result: 发现地理焦点从欧洲向其他地区转移，证实了一战和新势力崛起的影响。

Conclusion: 百科全书内容的变化反映了历史事件对知识结构的影响，数字化方法为类似研究提供了工具。

Abstract: The \textit{Nordisk familjebok} is a Swedish encyclopedia from the 19th and
20th centuries. It was written by a team of experts and aimed to be an
intellectual reference, stressing precision and accuracy. This encyclopedia had
four main editions remarkable by their size, ranging from 20 to 38 volumes. As
a consequence, the \textit{Nordisk familjebok} had a considerable influence in
universities, schools, the media, and society overall. As new editions were
released, the selection of entries and their content evolved, reflecting
intellectual changes in Sweden.
  In this paper, we used digitized versions from \textit{Project Runeberg}. We
first resegmented the raw text into entries and matched pairs of entries
between the first and second editions using semantic sentence embeddings. We
then extracted the geographical entries from both editions using a
transformer-based classifier and linked them to Wikidata. This enabled us to
identify geographic trends and possible shifts between the first and second
editions, written between 1876-1899 and 1904-1926, respectively.
  Interpreting the results, we observe a small but significant shift in
geographic focus away from Europe and towards North America, Africa, Asia,
Australia, and northern Scandinavia from the first to the second edition,
confirming the influence of the First World War and the rise of new powers. The
code and data are available on GitHub at
https://github.com/sibbo/nordisk-familjebok.

</details>


### [103] [MEGA: xLSTM with Multihead Exponential Gated Fusion for Precise Aspect-based Sentiment Analysis](https://arxiv.org/abs/2507.01213)
*Adamu Lawan,Juhua Pu,Haruna Yunusa,Jawad Muhammad,Muhammad Lawan*

Main category: cs.CL

TL;DR: 提出了一种名为MEGA的新框架，结合xLSTM和MECGAF机制，用于提升ABSA任务的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有ABSA方法在计算效率和性能之间难以平衡，xLSTM的潜力尚未在ABSA中充分挖掘。

Method: 采用双向mLSTM架构，结合PF-mLSTM和MECGAF机制，优化局部和全局上下文建模。

Result: 在三个基准数据集上，MEGA表现优于现有方法，实现了更高的准确性和效率。

Conclusion: MEGA框架为ABSA任务提供了一种高效且高性能的解决方案。

Abstract: Aspect-based Sentiment Analysis (ABSA) is a critical Natural Language
Processing (NLP) task that extracts aspects from text and determines their
associated sentiments, enabling fine-grained analysis of user opinions.
Existing ABSA methods struggle to balance computational efficiency with high
performance: deep learning models often lack global context, transformers
demand significant computational resources, and Mamba-based approaches face
CUDA dependency and diminished local correlations. Recent advancements in
Extended Long Short-Term Memory (xLSTM) models, particularly their efficient
modeling of long-range dependencies, have significantly advanced the NLP
community. However, their potential in ABSA remains untapped. To this end, we
propose xLSTM with Multihead Exponential Gated Fusion (MEGA), a novel framework
integrating a bi-directional mLSTM architecture with forward and partially
flipped backward (PF-mLSTM) streams. The PF-mLSTM enhances localized context
modeling by processing the initial sequence segment in reverse with dedicated
parameters, preserving critical short-range patterns. We further introduce an
mLSTM-based multihead cross exponential gated fusion mechanism (MECGAF) that
dynamically combines forward mLSTM outputs as query and key with PF-mLSTM
outputs as value, optimizing short-range dependency capture while maintaining
global context and efficiency. Experimental results on three benchmark datasets
demonstrate that MEGA outperforms state-of-the-art baselines, achieving
superior accuracy and efficiency in ABSA tasks.

</details>


### [104] [The Medium Is Not the Message: Deconfounding Text Embeddings via Linear Concept Erasure](https://arxiv.org/abs/2507.01234)
*Yu Fan,Yang Tian,Shauli Ravfogel,Mrinmaya Sachan,Elliott Ash,Alexander Hoyle*

Main category: cs.CL

TL;DR: 论文提出了一种去偏算法，通过从编码器表示中移除观察到的混杂信息，显著减少了文本嵌入中的偏差，且计算成本低。


<details>
  <summary>Details</summary>
Motivation: 文本序列的嵌入相似性度量可能受到无关属性（如来源或语言）的干扰，影响多语料库文本的应用效果。

Method: 采用去偏算法，从编码器表示中移除观察到的混杂信息。

Result: 去偏算法显著改善了文档相似性和聚类度量，且不影响分布外基准性能。

Conclusion: 该方法有效减少了嵌入偏差，且未对嵌入质量产生负面影响。

Abstract: Embedding-based similarity metrics between text sequences can be influenced
not just by the content dimensions we most care about, but can also be biased
by spurious attributes like the text's source or language. These document
confounders cause problems for many applications, but especially those that
need to pool texts from different corpora. This paper shows that a debiasing
algorithm that removes information about observed confounders from the encoder
representations substantially reduces these biases at a minimal computational
cost. Document similarity and clustering metrics improve across every embedding
variant and task we evaluate -- often dramatically. Interestingly, performance
on out-of-distribution benchmarks is not impacted, indicating that the
embeddings are not otherwise degraded.

</details>


### [105] [GAIus: Combining Genai with Legal Clauses Retrieval for Knowledge-based Assistant](https://arxiv.org/abs/2507.01259)
*Michał Matak,Jarosław A. Chudziak*

Main category: cs.CL

TL;DR: 论文探讨了大语言模型在处理非英语和非中文国家的法律问题时提供答案和引用的能力，提出了一种基于波兰民法典的检索机制gAIus，其表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决大语言模型在处理非主流语言法律信息时的局限性，提升其准确性和可解释性。

Method: 方法包括提出gAIus架构，结合波兰民法典的检索机制，并通过波兰法律学徒入学考试题目评估性能。

Result: 结果显示gAIus显著提升模型性能，gpt-3.5-turbo-0125提升419%，gpt-4o-mini从31%提升至86%。

Conclusion: 结论指出gAIus的潜力，并探讨了未来研究方向和应用前景。

Abstract: In this paper we discuss the capability of large language models to base
their answer and provide proper references when dealing with legal matters of
non-english and non-chinese speaking country. We discuss the history of legal
information retrieval, the difference between case law and statute law, its
impact on the legal tasks and analyze the latest research in this field. Basing
on that background we introduce gAIus, the architecture of the cognitive
LLM-based agent, whose responses are based on the knowledge retrieved from
certain legal act, which is Polish Civil Code. We propose a retrieval mechanism
which is more explainable, human-friendly and achieves better results than
embedding-based approaches. To evaluate our method we create special dataset
based on single-choice questions from entrance exams for law apprenticeships
conducted in Poland. The proposed architecture critically leveraged the
abilities of used large language models, improving the gpt-3.5-turbo-0125 by
419%, allowing it to beat gpt-4o and lifting gpt-4o-mini score from 31% to 86%.
At the end of our paper we show the possible future path of research and
potential applications of our findings.

</details>


### [106] [Evaluating Large Language Models for Multimodal Simulated Ophthalmic Decision-Making in Diabetic Retinopathy and Glaucoma Screening](https://arxiv.org/abs/2507.01278)
*Cindy Lie Tabuse,David Restepo,Carolina Gracitelli,Fernando Korn Malerbi,Caio Regatieri,Luis Filipe Nakayama*

Main category: cs.CL

TL;DR: GPT-4在眼科中模拟临床决策的能力有限，尤其在复杂任务中表现不佳，但可能适用于教育和文档工作。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）在眼科中模拟临床推理的潜力，特别是在糖尿病视网膜病变（DR）和青光眼筛查中的应用。

Method: 使用300张标注的眼底图像，通过结构化提示描述图像，评估GPT-4在ICDR严重程度评分、DR转诊建议和青光眼杯盘比估计中的表现。

Result: GPT-4在ICDR分类中表现中等（准确率67.5%），在DR转诊任务中表现较好（准确率82.3%），但在青光眼转诊中表现差（准确率约78%）。添加元数据对结果无显著影响。

Conclusion: GPT-4可从结构化提示中模拟基本眼科决策，但缺乏复杂任务的精确性，不适合临床使用，可能适用于教育或文档工作。

Abstract: Large language models (LLMs) can simulate clinical reasoning based on natural
language prompts, but their utility in ophthalmology is largely unexplored.
This study evaluated GPT-4's ability to interpret structured textual
descriptions of retinal fundus photographs and simulate clinical decisions for
diabetic retinopathy (DR) and glaucoma screening, including the impact of
adding real or synthetic clinical metadata. We conducted a retrospective
diagnostic validation study using 300 annotated fundus images. GPT-4 received
structured prompts describing each image, with or without patient metadata. The
model was tasked with assigning an ICDR severity score, recommending DR
referral, and estimating the cup-to-disc ratio for glaucoma referral.
Performance was evaluated using accuracy, macro and weighted F1 scores, and
Cohen's kappa. McNemar's test and change rate analysis were used to assess the
influence of metadata. GPT-4 showed moderate performance for ICDR
classification (accuracy 67.5%, macro F1 0.33, weighted F1 0.67, kappa 0.25),
driven mainly by correct identification of normal cases. Performance improved
in the binary DR referral task (accuracy 82.3%, F1 0.54, kappa 0.44). For
glaucoma referral, performance was poor across all settings (accuracy ~78%, F1
<0.04, kappa <0.03). Metadata inclusion did not significantly affect outcomes
(McNemar p > 0.05), and predictions remained consistent across conditions.
GPT-4 can simulate basic ophthalmic decision-making from structured prompts but
lacks precision for complex tasks. While not suitable for clinical use, LLMs
may assist in education, documentation, or image annotation workflows in
ophthalmology.

</details>


### [107] [Rethinking All Evidence: Enhancing Trustworthy Retrieval-Augmented Generation via Conflict-Driven Summarization](https://arxiv.org/abs/2507.01281)
*Juan Chen,Baolong Bi,Wei Zhang,Jingyan Sui,Xiaofei Zhu,Yuanzhuo Wang,Lingrui Mei,Shenghua Liu*

Main category: cs.CL

TL;DR: CARE-RAG框架通过冲突驱动的证据整合，提升RAG系统的生成可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决RAG系统中因内部知识冲突或检索噪声导致的生成不可靠问题。

Method: 提出CARE-RAG框架，包括参数感知证据生成、上下文感知证据提炼、冲突驱动总结及QA修复步骤。

Result: 在噪声或冲突证据场景下，CARE-RAG优于现有RAG基线。

Conclusion: CARE-RAG通过多源证据的可靠整合，显著提升RAG系统的可信度。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
integrating their parametric knowledge with external retrieved content.
However, knowledge conflicts caused by internal inconsistencies or noisy
retrieved content can severely undermine the generation reliability of RAG
systems.In this work, we argue that LLMs should rethink all evidence, including
both retrieved content and internal knowledge, before generating responses.We
propose CARE-RAG (Conflict-Aware and Reliable Evidence for RAG), a novel
framework that improves trustworthiness through Conflict-Driven Summarization
of all available evidence.CARE-RAG first derives parameter-aware evidence by
comparing parameter records to identify diverse internal perspectives. It then
refines retrieved evidences to produce context-aware evidence, removing
irrelevant or misleading content. To detect and summarize conflicts, we distill
a 3B LLaMA3.2 model to perform conflict-driven summarization, enabling reliable
synthesis across multiple sources.To further ensure evaluation integrity, we
introduce a QA Repair step to correct outdated or ambiguous benchmark
answers.Experiments on revised QA datasets with retrieval data show that
CARE-RAG consistently outperforms strong RAG baselines, especially in scenarios
with noisy or conflicting evidence.

</details>


### [108] [Frustratingly Simple Retrieval Improves Challenging, Reasoning-Intensive Benchmarks](https://arxiv.org/abs/2507.01297)
*Xinxi Lyu,Michael Duan,Rulin Shao,Pang Wei Koh,Sewon Min*

Main category: cs.CL

TL;DR: 论文提出CompactDS，一个高质量、多样化的网络规模数据存储，显著提升了检索增强生成（RAG）在推理密集型任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在推理密集型任务中表现有限，主要因缺乏与预训练数据广度对齐的高质量数据存储。

Method: 引入CompactDS，通过过滤低质量内容并结合内存近似最近邻（ANN）检索与磁盘精确搜索，实现高效检索。

Result: CompactDS显著提升了多个推理密集型基准测试的准确率（如MMLU提升10%，MATH提升19%），并优于复杂代理系统。

Conclusion: CompactDS展示了高质量多样化数据存储对RAG的重要性，同时保持了简单性和可复现性。

Abstract: Retrieval-augmented Generation (RAG) has primarily been studied in limited
settings, such as factoid question answering; more challenging,
reasoning-intensive benchmarks have seen limited success from minimal RAG. In
this work, we challenge this prevailing view on established,
reasoning-intensive benchmarks: MMLU, MMLU Pro, AGI Eval, GPQA, and MATH. We
identify a key missing component in prior work: a usable, web-scale datastore
aligned with the breadth of pretraining data. To this end, we introduce
CompactDS: a diverse, high-quality, web-scale datastore that achieves high
retrieval accuracy and subsecond latency on a single-node. The key insights are
(1) most web content can be filtered out without sacrificing coverage, and a
compact, high-quality subset is sufficient; and (2) combining in-memory
approximate nearest neighbor (ANN) retrieval and on-disk exact search balances
speed and recall. Using CompactDS, we show that a minimal RAG pipeline achieves
consistent accuracy improvements across all benchmarks and model sizes
(8B--70B), with relative gains of 10% on MMLU, 33% on MMLU Pro, 14% on GPQA,
and 19% on MATH. No single data source suffices alone, highlighting the
importance of diversity of sources (web crawls, curated math, academic papers,
textbooks). Finally, we show that our carefully designed in-house datastore
matches or outperforms web search engines such as Google Search, as well as
recently proposed, complex agent-based RAG systems--all while maintaining
simplicity, reproducibility, and self-containment. We release CompactDS and our
retrieval pipeline, supporting future research exploring retrieval-based AI
systems.

</details>


### [109] [La RoSA: Enhancing LLM Efficiency via Layerwise Rotated Sparse Activation](https://arxiv.org/abs/2507.01299)
*Kai Liu,Bowen Xu,Shaoyu Wu,Xin Chen,Hao Zhou,Yongliang Tao,Lulu Hu*

Main category: cs.CL

TL;DR: LaRoSA是一种新的激活稀疏化方法，通过层间正交旋转和Top-K选择，无需额外训练或基于幅度的剪枝，显著提升LLM推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要耗时恢复训练或依赖经验性剪枝，导致稀疏性不稳定和推理加速不可靠，LaRoSA旨在解决这些问题。

Method: 利用层间正交旋转将输入激活转换为更适合稀疏化的形式，并通过Top-K选择实现一致的模型级稀疏性。

Result: 在LLaMA2-7B上，40%稀疏性下仅0.17困惑度差距，1.30倍推理加速，零样本任务准确率差距仅0.54%。

Conclusion: LaRoSA在多种LLM上表现优异，稀疏化效果稳定且性能损失极小，显著优于现有方法。

Abstract: Activation sparsity can reduce the computational overhead and memory
transfers during the forward pass of Large Language Model (LLM) inference.
Existing methods face limitations, either demanding time-consuming recovery
training that hinders real-world adoption, or relying on empirical
magnitude-based pruning, which causes fluctuating sparsity and unstable
inference speed-up. This paper introduces LaRoSA (Layerwise Rotated Sparse
Activation), a novel method for activation sparsification designed to improve
LLM efficiency without requiring additional training or magnitude-based
pruning. We leverage layerwise orthogonal rotations to transform input
activations into rotated forms that are more suitable for sparsification. By
employing a Top-K selection approach within the rotated activations, we achieve
consistent model-level sparsity and reliable wall-clock time speed-up. LaRoSA
is effective across various sizes and types of LLMs, demonstrating minimal
performance degradation and robust inference acceleration. Specifically, for
LLaMA2-7B at 40% sparsity, LaRoSA achieves a mere 0.17 perplexity gap with a
consistent 1.30x wall-clock time speed-up, and reduces the accuracy gap in
zero-shot tasks compared to the dense model to just 0.54%, while surpassing
TEAL by 1.77% and CATS by 17.14%.

</details>


### [110] [Symbolic or Numerical? Understanding Physics Problem Solving in Reasoning LLMs](https://arxiv.org/abs/2507.01334)
*Nifu Dan,Yujun Cai,Yiwei Wang*

Main category: cs.CL

TL;DR: 研究探讨了高级指令调优推理模型（如Deepseek-R1）在解决复杂物理问题中的应用，展示了其在SciBench基准测试中的卓越表现和独特推理模式。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在物理推理中的复杂性问题，需要结合深刻的概念理解和问题解决技巧。

Method: 应用高级指令调优推理模型（如Deepseek-R1）处理SciBench基准中的多样化物理问题。

Result: 模型在复杂物理问题上达到最先进准确率，并展现出强调符号推导的独特推理模式。少量提示策略还能进一步提升性能。

Conclusion: 研究表明高级推理模型在物理问题解决中具有显著潜力，且通过策略性提示可进一步优化性能。

Abstract: Navigating the complexities of physics reasoning has long been a difficult
task for Large Language Models (LLMs), requiring a synthesis of profound
conceptual understanding and adept problem-solving techniques. In this study,
we investigate the application of advanced instruction-tuned reasoning models,
such as Deepseek-R1, to address a diverse spectrum of physics problems curated
from the challenging SciBench benchmark. Our comprehensive experimental
evaluation reveals the remarkable capabilities of reasoning models. Not only do
they achieve state-of-the-art accuracy in answering intricate physics
questions, but they also generate distinctive reasoning patterns that emphasize
on symbolic derivation. Furthermore, our findings indicate that even for these
highly sophisticated reasoning models, the strategic incorporation of few-shot
prompting can still yield measurable improvements in overall accuracy,
highlighting the potential for continued performance gains.

</details>


### [111] [LEDOM: An Open and Fundamental Reverse Language Model](https://arxiv.org/abs/2507.01335)
*Xunjian Yin,Sitao Cheng,Yuxi Xie,Xinyu Hu,Li Lin,Xinyi Wang,Liangming Pan,William Yang Wang,Xiaojun Wan*

Main category: cs.CL

TL;DR: LEDOM是首个纯逆向语言模型，通过反向时间顺序处理序列，并展示了其作为基础模型的潜力。进一步提出逆向奖励应用，显著提升数学推理任务性能。


<details>
  <summary>Details</summary>
Motivation: 探索逆向语言模型的潜力及其在通用任务中的应用，尤其是通过逆向推理提升生成质量。

Method: 训练了2B和7B参数的逆向语言模型LEDOM，采用自回归方式处理反向序列，并引入逆向奖励应用。

Result: LEDOM展示了独特的逆向推理能力，在数学推理任务中通过逆向奖励显著提升性能。

Conclusion: LEDOM具有广泛的应用潜力，未来将公开模型和训练数据以促进研究。

Abstract: We introduce LEDOM, the first purely reverse language model, trained
autoregressively on 435B tokens with 2B and 7B parameter variants, which
processes sequences in reverse temporal order through previous token
prediction. For the first time, we present the reverse language model as a
potential foundational model across general tasks, accompanied by a set of
intriguing examples and insights. Based on LEDOM, we further introduce a novel
application: Reverse Reward, where LEDOM-guided reranking of forward language
model outputs leads to substantial performance improvements on mathematical
reasoning tasks. This approach leverages LEDOM's unique backward reasoning
capability to refine generation quality through posterior evaluation. Our
findings suggest that LEDOM exhibits unique characteristics with broad
application potential. We will release all models, training code, and
pre-training data to facilitate future research.

</details>


### [112] [Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy](https://arxiv.org/abs/2507.01352)
*Chris Yuhao Liu,Liang Zeng,Yuzhen Xiao,Jujie He,Jiacai Liu,Chaojie Wang,Rui Yan,Wei Shen,Fuxiang Zhang,Jiacheng Xu,Yang Liu,Yahui Zhou*

Main category: cs.CL

TL;DR: 论文提出大规模偏好数据集SynPref-40M和奖励模型Skywork-Reward-V2，通过人机协同提升数据质量和模型性能，在多个基准测试中达到最优。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型在复杂人类偏好上表现不佳，主要因偏好数据集质量不足。

Method: 设计两阶段人机协同流程，结合人类标注质量与AI扩展性，训练8个不同规模的奖励模型。

Result: Skywork-Reward-V2在7个主要基准测试中表现最佳，验证了数据规模与高质量标注的重要性。

Conclusion: 人机协同的数据集构建方法显著提升了奖励模型的性能，展示了高质量数据的潜力。

Abstract: Despite the critical role of reward models (RMs) in reinforcement learning
from human feedback (RLHF), current state-of-the-art open RMs perform poorly on
most existing evaluation benchmarks, failing to capture the spectrum of nuanced
and sophisticated human preferences. Even approaches that incorporate advanced
training techniques have not yielded meaningful performance improvements. We
hypothesize that this brittleness stems primarily from limitations in
preference datasets, which are often narrowly scoped, synthetically labeled, or
lack rigorous quality control. To address these challenges, we present a
large-scale preference dataset comprising 40 million preference pairs, named
SynPref-40M. To enable data curation at scale, we design a human-AI synergistic
two-stage pipeline that leverages the complementary strengths of human
annotation quality and AI scalability. In this pipeline, humans provide
verified annotations, while large language models perform automatic curation
based on human guidance. Training on this preference mixture, we introduce
Skywork-Reward-V2, a suite of eight reward models ranging from 0.6B to 8B
parameters, trained on a carefully curated subset of 26 million preference
pairs from SynPref-40M. We demonstrate that Skywork-Reward-V2 is versatile
across a wide range of capabilities, including alignment with human
preferences, objective correctness, safety, resistance to stylistic biases, and
best-of-N scaling, achieving state-of-the-art performance across seven major
reward model benchmarks. Ablation studies confirm that the effectiveness of our
approach stems not only from data scale but also from high-quality curation.
The Skywork-Reward-V2 series represents substantial progress in open reward
models, highlighting the untapped potential of existing preference datasets and
demonstrating how human-AI curation synergy can unlock significantly higher
data quality.

</details>


### [113] [Clinical NLP with Attention-Based Deep Learning for Multi-Disease Prediction](https://arxiv.org/abs/2507.01437)
*Ting Xu,Xiaoxiao Deng,Xiandong Meng,Haifeng Yang,Yan Wu*

Main category: cs.CL

TL;DR: 本文提出了一种基于注意力机制的深度学习方法，用于电子健康记录文本的信息提取和多标签疾病预测，并在MIMIC-IV数据集上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决电子健康记录文本的非结构化和高维语义复杂性带来的挑战。

Method: 采用基于Transformer的架构进行临床文本表示学习，结合多层自注意力机制捕捉关键医学实体及其上下文关系，并使用Sigmoid多标签分类器预测疾病标签。

Result: 实验表明，该方法在多个性能指标上优于现有代表性方法，并在不同数据规模、干扰水平和模型深度配置下表现出强泛化能力。

Conclusion: 该框架为处理真实临床文本提供了高效算法基础，对多标签医学文本建模任务具有实际意义。

Abstract: This paper addresses the challenges posed by the unstructured nature and
high-dimensional semantic complexity of electronic health record texts. A deep
learning method based on attention mechanisms is proposed to achieve unified
modeling for information extraction and multi-label disease prediction. The
study is conducted on the MIMIC-IV dataset. A Transformer-based architecture is
used to perform representation learning over clinical text. Multi-layer
self-attention mechanisms are employed to capture key medical entities and
their contextual relationships. A Sigmoid-based multi-label classifier is then
applied to predict multiple disease labels. The model incorporates a
context-aware semantic alignment mechanism, enhancing its representational
capacity in typical medical scenarios such as label co-occurrence and sparse
information. To comprehensively evaluate model performance, a series of
experiments were conducted, including baseline comparisons, hyperparameter
sensitivity analysis, data perturbation studies, and noise injection tests.
Results demonstrate that the proposed method consistently outperforms
representative existing approaches across multiple performance metrics. The
model maintains strong generalization under varying data scales, interference
levels, and model depth configurations. The framework developed in this study
offers an efficient algorithmic foundation for processing real-world clinical
texts and presents practical significance for multi-label medical text modeling
tasks.

</details>


### [114] [LogitSpec: Accelerating Retrieval-based Speculative Decoding via Next Next Token Speculation](https://arxiv.org/abs/2507.01449)
*Tianyu Liu,Qitan Lv,Hao Li,Xing Gao,Xiao Sun*

Main category: cs.CL

TL;DR: LogitSpec是一种无需训练的检索式推测解码方法，通过利用最后一个token的logit推测下一个及下下个token，显著提升LLM推理速度。


<details>
  <summary>Details</summary>
Motivation: 解决检索式推测解码中难以找到匹配和准确草案token的问题，通过扩展检索范围提高草案生成效率。

Method: 1. 利用最后一个token的logit推测下下个token；2. 检索与下一个和下下个token相关的参考。

Result: 在多个文本生成基准测试中，LogitSpec实现了最高2.61倍加速和每解码步骤3.28个平均接受token。

Conclusion: LogitSpec是一种即插即用的高效方法，显著提升了LLM推理速度，且易于集成到现有框架中。

Abstract: Speculative decoding (SD), where a small draft model is employed to propose
draft tokens in advance and then the target model validates them in parallel,
has emerged as a promising technique for LLM inference acceleration. Many
endeavors to improve SD are to eliminate the need for a draft model and
generate draft tokens in a retrieval-based manner in order to further alleviate
the drafting overhead and significantly reduce the difficulty in deployment and
applications. However, retrieval-based SD relies on a matching paradigm to
retrieval the most relevant reference as the draft tokens, where these methods
often fail to find matched and accurate draft tokens. To address this
challenge, we propose LogitSpec to effectively expand the retrieval range and
find the most relevant reference as drafts. Our LogitSpec is motivated by the
observation that the logit of the last token can not only predict the next
token, but also speculate the next next token. Specifically, LogitSpec
generates draft tokens in two steps: (1) utilizing the last logit to speculate
the next next token; (2) retrieving relevant reference for both the next token
and the next next token. LogitSpec is training-free and plug-and-play, which
can be easily integrated into existing LLM inference frameworks. Extensive
experiments on a wide range of text generation benchmarks demonstrate that
LogitSpec can achieve up to 2.61 $\times$ speedup and 3.28 mean accepted tokens
per decoding step. Our code is available at
https://github.com/smart-lty/LogitSpec.

</details>


### [115] [Evaluating the Effectiveness of Direct Preference Optimization for Personalizing German Automatic Text Simplifications for Persons with Intellectual Disabilities](https://arxiv.org/abs/2507.01479)
*Yingqiang Gao,Kaede Johnson,David Froehlich,Luisa Carrer,Sarah Ebling*

Main category: cs.CL

TL;DR: 论文提出了一种基于直接偏好优化（DPO）的LLM文本简化方法，结合目标群体反馈以提升个性化。


<details>
  <summary>Details</summary>
Motivation: 现有LLM文本简化系统缺乏目标群体偏好反馈，导致个性化不足。

Method: 扩展监督微调（SFT），采用DPO技术，结合目标群体反馈进行后训练。

Result: 提出了个性化LLM文本简化系统的开发流程，强调目标群体参与的重要性。

Conclusion: 个性化AI系统需结合目标群体反馈，提升文本简化的可及性和满意度。

Abstract: Automatic text simplification (ATS) aims to enhance language accessibility
for various target groups, particularly persons with intellectual disabilities.
Recent advancements in generative AI, especially large language models (LLMs),
have substantially improved the quality of machine-generated text
simplifications, thereby mitigating information barriers for the target group.
However, existing LLM-based ATS systems do not incorporate preference feedback
on text simplifications during training, resulting in a lack of personalization
tailored to the specific needs of target group representatives.
  In this work, we extend the standard supervised fine-tuning (SFT) approach
for adapting LLM-based ATS models by leveraging a computationally efficient LLM
alignment technique -- direct preference optimization (DPO). Specifically, we
post-train LLM-based ATS models using human feedback collected from persons
with intellectual disabilities, reflecting their preferences on paired text
simplifications generated by mainstream LLMs. Furthermore, we propose a
pipeline for developing personalized LLM-based ATS systems, encompassing data
collection, model selection, SFT and DPO post-training, and evaluation. Our
findings underscore the necessity of active participation of target group
persons in designing personalized AI accessibility solutions aligned with human
expectations. This work represents a step towards personalizing inclusive AI
systems at the target-group level, incorporating insights not only from text
simplification experts but also from target group persons themselves.

</details>


### [116] [Efficient Out-of-Scope Detection in Dialogue Systems via Uncertainty-Driven LLM Routing](https://arxiv.org/abs/2507.01541)
*Álvaro Zaera,Diana Nicoleta Popa,Ivan Sekulic,Paolo Rosso*

Main category: cs.CL

TL;DR: 提出了一种结合不确定性建模和微调大语言模型（LLM）的模块化框架，用于高效准确地检测任务导向对话系统中的超出范围（OOS）意图。


<details>
  <summary>Details</summary>
Motivation: 任务导向对话系统（TODS）中OOS意图检测对处理未见和模糊查询至关重要，现有方法在效率和性能上存在不足。

Method: 首先对已部署的意图分类器输出进行不确定性估计，然后对高不确定性实例触发微调LLM进行最终决策。

Result: 在关键OOS检测基准测试中取得了最佳性能，包括从实际部署的TODS中获取的真实OOS数据。

Conclusion: 该方法在计算效率和性能之间取得了良好平衡，结合传统方法和LLM，为OOS检测提供了有效解决方案。

Abstract: Out-of-scope (OOS) intent detection is a critical challenge in task-oriented
dialogue systems (TODS), as it ensures robustness to unseen and ambiguous
queries. In this work, we propose a novel but simple modular framework that
combines uncertainty modeling with fine-tuned large language models (LLMs) for
efficient and accurate OOS detection. The first step applies uncertainty
estimation to the output of an in-scope intent detection classifier, which is
currently deployed in a real-world TODS handling tens of thousands of user
interactions daily. The second step then leverages an emerging LLM-based
approach, where a fine-tuned LLM is triggered to make a final decision on
instances with high uncertainty. Unlike prior approaches, our method
effectively balances computational efficiency and performance, combining
traditional approaches with LLMs and yielding state-of-the-art results on key
OOS detection benchmarks, including real-world OOS data acquired from a
deployed TODS.

</details>


### [117] [Is External Information Useful for Stance Detection with LLMs?](https://arxiv.org/abs/2507.01543)
*Quang Minh Nguyen,Taegyoon Kim*

Main category: cs.CL

TL;DR: 研究发现，在立场检测任务中，外部信息（如维基百科或网络搜索）对大型语言模型（LLMs）的性能产生负面影响，导致F1分数下降高达27.9%。


<details>
  <summary>Details</summary>
Motivation: 探讨外部信息是否对LLMs在立场检测任务中有益，尽管此前研究表明其对BERT等模型有提升作用。

Method: 系统评估了维基百科和网络搜索信息对8种LLMs在3个数据集和12个目标上的影响，并分析了LLMs的预测倾向。

Result: 外部信息通常降低性能，LLMs倾向于与提供的信息的立场和情感对齐，而非真实立场。微调可缓解但无法完全消除问题。

Conclusion: 研究揭示了LLMs在立场检测中的信息偏见风险，与BERT等模型的结论形成对比。

Abstract: In the stance detection task, a text is classified as either favorable,
opposing, or neutral towards a target. Prior work suggests that the use of
external information, e.g., excerpts from Wikipedia, improves stance detection
performance. However, whether or not such information can benefit large
language models (LLMs) remains an unanswered question, despite their wide
adoption in many reasoning tasks. In this study, we conduct a systematic
evaluation on how Wikipedia and web search external information can affect
stance detection across eight LLMs and in three datasets with 12 targets.
Surprisingly, we find that such information degrades performance in most cases,
with macro F1 scores dropping by up to 27.9\%. We explain this through
experiments showing LLMs' tendency to align their predictions with the stance
and sentiment of the provided information rather than the ground truth stance
of the given text. We also find that performance degradation persists with
chain-of-thought prompting, while fine-tuning mitigates but does not fully
eliminate it. Our findings, in contrast to previous literature on BERT-based
systems which suggests that external information enhances performance,
highlight the risks of information biases in LLM-based stance classifiers. Code
is available at https://github.com/ngqm/acl2025-stance-detection.

</details>


### [118] [Emotionally Intelligent Task-oriented Dialogue Systems: Architecture, Representation, and Optimisation](https://arxiv.org/abs/2507.01594)
*Shutong Feng,Hsien-chin Lin,Nurul Lubis,Carel van Niekerk,Michael Heck,Benjamin Ruppik,Renato Vukovic,Milica Gašić*

Main category: cs.CL

TL;DR: 论文提出LUSTER，一种基于LLM的任务导向对话系统，结合端到端强化学习和情感奖励，提升对话系统的任务成功率和情感响应能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）提升了语言流畅性和上下文理解，但构建高效且情感智能的任务导向对话系统仍具挑战性。

Method: 提出LUSTER系统，结合LLM能力和结构化奖励建模，通过端到端强化学习优化短期（用户情感）和长期（任务成功）奖励。

Result: 实验表明，LUSTER在任务成功率和情感响应方面表现更优，为下一代对话系统提供了实用路径。

Conclusion: 结合LLM与结构化奖励建模能显著提升任务导向对话系统的鲁棒性和情感智能。

Abstract: Task-oriented dialogue (ToD) systems are designed to help users achieve
specific goals through natural language interaction. While recent advances in
large language models (LLMs) have significantly improved linguistic fluency and
contextual understanding, building effective and emotionally intelligent ToD
systems remains a complex challenge. Effective ToD systems must optimise for
task success, emotional understanding and responsiveness, and precise
information conveyance, all within inherently noisy and ambiguous
conversational environments. In this work, we investigate architectural,
representational, optimisational as well as emotional considerations of ToD
systems. We set up systems covering these design considerations with a
challenging evaluation environment composed of a natural-language user
simulator coupled with an imperfect natural language understanding module. We
propose \textbf{LUSTER}, an \textbf{L}LM-based \textbf{U}nified \textbf{S}ystem
for \textbf{T}ask-oriented dialogue with \textbf{E}nd-to-end
\textbf{R}einforcement learning with both short-term (user sentiment) and
long-term (task success) rewards. Our findings demonstrate that combining LLM
capability with structured reward modelling leads to more resilient and
emotionally responsive ToD systems, offering a practical path forward for
next-generation conversational agents.

</details>


### [119] [Chart Question Answering from Real-World Analytical Narratives](https://arxiv.org/abs/2507.01627)
*Maeve Hutchinson,Radu Jianu,Aidan Slingsby,Jo Wood,Pranava Madhyastha*

Main category: cs.CL

TL;DR: 新数据集用于图表问答（CQA），基于可视化笔记本构建，包含真实多视图图表和自然语言问题，反映实际推理流程。GPT-4.1准确率69.3%，显示现有模型在此类任务中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有图表问答数据集缺乏真实性和多视图支持，无法反映实际推理流程。新数据集旨在填补这一空白。

Method: 从可视化笔记本中构建数据集，包含多视图图表和自然语言问题，模拟真实分析场景。

Result: 测试显示，GPT-4.1在此数据集上的准确率为69.3%，表明现有模型在真实CQA任务中表现不佳。

Conclusion: 新数据集为图表问答提供了更真实的基准，揭示了现有模型的局限性，为未来研究指明方向。

Abstract: We present a new dataset for chart question answering (CQA) constructed from
visualization notebooks. The dataset features real-world, multi-view charts
paired with natural language questions grounded in analytical narratives.
Unlike prior benchmarks, our data reflects ecologically valid reasoning
workflows. Benchmarking state-of-the-art multimodal large language models
reveals a significant performance gap, with GPT-4.1 achieving an accuracy of
69.3%, underscoring the challenges posed by this more authentic CQA setting.

</details>


### [120] [Confidence and Stability of Global and Pairwise Scores in NLP Evaluation](https://arxiv.org/abs/2507.01633)
*Georgii Levtsov,Dmitry Ustalov*

Main category: cs.CL

TL;DR: 论文比较了全局评分和成对比较在NLP模型评估中的优缺点，发现全局评分更可靠但可能低估某些模型，而成对比较能更好识别低分模型中的强者。


<details>
  <summary>Details</summary>
Motivation: 随着指令调优神经语言模型的发展，NLP评估从传统全局评分转向成对比较排行榜，需研究两者的优劣以指导评估策略选择。

Method: 通过合成和真实数据集的计算实验，使用标准全局指标和Bradley-Terry模型进行成对比较。

Result: 全局评分提供更可靠的整体排名，但可能低估某些模型；成对比较能识别低分模型中的强者，但收敛较慢。

Conclusion: 两种方法各有优劣，选择评估策略需根据具体需求权衡。代码和数据已开源。

Abstract: With the advent of highly capable instruction-tuned neural language models,
benchmarking in natural language processing (NLP) is increasingly shifting
towards pairwise comparison leaderboards, such as LMSYS Arena, from traditional
global pointwise scores (e.g., GLUE, BIG-bench, SWE-bench). This paper
empirically investigates the strengths and weaknesses of both global scores and
pairwise comparisons to aid decision-making in selecting appropriate model
evaluation strategies. Through computational experiments on synthetic and
real-world datasets using standard global metrics and the popular Bradley-Terry
model for pairwise comparisons, we found that while global scores provide more
reliable overall rankings, they can underestimate strong models with rare,
significant errors or low confidence. Conversely, pairwise comparisons are
particularly effective for identifying strong contenders among models with
lower global scores, especially where quality metrics are hard to define (e.g.,
text generation), though they require more comparisons to converge if ties are
frequent. Our code and data are available at
https://github.com/HSPyroblast/srw-ranking under a permissive license.

</details>


### [121] [Adapting Language Models to Indonesian Local Languages: An Empirical Study of Language Transferability on Zero-Shot Settings](https://arxiv.org/abs/2507.01645)
*Rifki Afina Putri*

Main category: cs.CL

TL;DR: 研究了预训练语言模型在低资源印尼本土语言情感分析任务中的迁移能力，评估了零样本和适配器迁移方法，发现模型性能与语言在预训练中的暴露程度密切相关。


<details>
  <summary>Details</summary>
Motivation: 探索预训练语言模型在低资源印尼本土语言中的迁移能力，以解决资源匮乏问题。

Method: 使用印尼单语BERT、多语言模型（mBERT、XLM-R）和适配器方法MAD-X，评估零样本和适配器迁移性能。

Result: 多语言模型在预训练见过的语言上表现最佳，MAD-X显著提升性能；语言暴露程度是迁移成功的关键因素。

Conclusion: 模型对语言的预训练暴露程度是迁移性能的主要决定因素，适配器方法能有效提升低资源语言的表现。

Abstract: In this paper, we investigate the transferability of pre-trained language
models to low-resource Indonesian local languages through the task of sentiment
analysis. We evaluate both zero-shot performance and adapter-based transfer on
ten local languages using models of different types: a monolingual Indonesian
BERT, multilingual models such as mBERT and XLM-R, and a modular adapter-based
approach called MAD-X. To better understand model behavior, we group the target
languages into three categories: seen (included during pre-training), partially
seen (not included but linguistically related to seen languages), and unseen
(absent and unrelated in pre-training data). Our results reveal clear
performance disparities across these groups: multilingual models perform best
on seen languages, moderately on partially seen ones, and poorly on unseen
languages. We find that MAD-X significantly improves performance, especially
for seen and partially seen languages, without requiring labeled data in the
target language. Additionally, we conduct a further analysis on tokenization
and show that while subword fragmentation and vocabulary overlap with
Indonesian correlate weakly with prediction quality, they do not fully explain
the observed performance. Instead, the most consistent predictor of transfer
success is the model's prior exposure to the language, either directly or
through a related language.

</details>


### [122] [AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness](https://arxiv.org/abs/2507.01702)
*Zixin Chen,Hongzhan Lin,Kaixin Li,Ziyang Luo,Zhen Ye,Guang Chen,Zhiyong Huang,Jing Ma*

Main category: cs.CL

TL;DR: AdamMeme是一个基于多智能体的评估框架，用于动态评估多模态大语言模型（mLLMs）对有害模因的理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准依赖静态数据集和准确性指标，无法适应模因的动态演变，需要更灵活和全面的评估方法。

Method: 通过多智能体协作，动态更新具有挑战性的模因数据，迭代评估mLLMs对有害模因的推理能力。

Result: 实验表明，AdamMeme能系统性地揭示不同mLLMs的性能差异，并提供细粒度的模型弱点分析。

Conclusion: AdamMeme为动态评估mLLMs对有害模因的理解提供了灵活且全面的框架。

Abstract: The proliferation of multimodal memes in the social media era demands that
multimodal Large Language Models (mLLMs) effectively understand meme
harmfulness. Existing benchmarks for assessing mLLMs on harmful meme
understanding rely on accuracy-based, model-agnostic evaluations using static
datasets. These benchmarks are limited in their ability to provide up-to-date
and thorough assessments, as online memes evolve dynamically. To address this,
we propose AdamMeme, a flexible, agent-based evaluation framework that
adaptively probes the reasoning capabilities of mLLMs in deciphering meme
harmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive
evaluations by iteratively updating the meme data with challenging samples,
thereby exposing specific limitations in how mLLMs interpret harmfulness.
Extensive experiments show that our framework systematically reveals the
varying performance of different target mLLMs, offering in-depth, fine-grained
analyses of model-specific weaknesses. Our code is available at
https://github.com/Lbotirx/AdamMeme.

</details>


### [123] [Stereotype Detection as a Catalyst for Enhanced Bias Detection: A Multi-Task Learning Approach](https://arxiv.org/abs/2507.01715)
*Aditya Tomar,Rudra Murthy,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: 论文提出StereoBias数据集，通过联合学习偏见和刻板印象检测任务提升模型性能，实验证明联合训练显著优于单独训练。


<details>
  <summary>Details</summary>
Motivation: 语言模型中的偏见和刻板印象可能造成危害，尤其在敏感领域如内容审核和决策中。

Method: 引入StereoBias数据集，比较编码器模型和微调解码器模型（使用QLoRA），并联合训练偏见和刻板印象检测任务。

Result: 联合训练显著提升偏见检测性能，且改进源于偏见与刻板印象的关联而非多任务学习。

Conclusion: 利用刻板印象信息有助于构建更公平有效的AI系统。

Abstract: Bias and stereotypes in language models can cause harm, especially in
sensitive areas like content moderation and decision-making. This paper
addresses bias and stereotype detection by exploring how jointly learning these
tasks enhances model performance. We introduce StereoBias, a unique dataset
labeled for bias and stereotype detection across five categories: religion,
gender, socio-economic status, race, profession, and others, enabling a deeper
study of their relationship. Our experiments compare encoder-only models and
fine-tuned decoder-only models using QLoRA. While encoder-only models perform
well, decoder-only models also show competitive results. Crucially, joint
training on bias and stereotype detection significantly improves bias detection
compared to training them separately. Additional experiments with sentiment
analysis confirm that the improvements stem from the connection between bias
and stereotypes, not multi-task learning alone. These findings highlight the
value of leveraging stereotype information to build fairer and more effective
AI systems.

</details>


### [124] [LLMs for Legal Subsumption in German Employment Contracts](https://arxiv.org/abs/2507.01734)
*Oliver Wardas,Florian Matthes*

Main category: cs.CL

TL;DR: 论文探讨了在德国雇佣合同中使用大语言模型（LLMs）和法律上下文评估条款合法性的方法，发现法律指南显著提升了模型性能，但仍不及人类律师。


<details>
  <summary>Details</summary>
Motivation: 法律工作的文本密集性和资源密集性为NLP研究提供了独特挑战和机会，但现有数据驱动方法缺乏可解释性和可信度，限制了其在动态法律环境中的应用。

Method: 与法律专家合作扩展数据集，利用LLMs和上下文学习评估条款合法性，比较不同法律上下文（无上下文、完整法律文本、法律指南）对模型性能的影响。

Result: 完整法律文本略微提升性能，法律指南显著提高了无效条款的召回率和加权F1-Score（达80%），但LLMs表现仍远低于人类律师。

Conclusion: LLMs在合同合法性审查中具有辅助潜力，但现有方法仍有局限性；贡献了扩展数据集和代码。

Abstract: Legal work, characterized by its text-heavy and resource-intensive nature,
presents unique challenges and opportunities for NLP research. While
data-driven approaches have advanced the field, their lack of interpretability
and trustworthiness limits their applicability in dynamic legal environments.
To address these issues, we collaborated with legal experts to extend an
existing dataset and explored the use of Large Language Models (LLMs) and
in-context learning to evaluate the legality of clauses in German employment
contracts. Our work evaluates the ability of different LLMs to classify clauses
as "valid," "unfair," or "void" under three legal context variants: no legal
context, full-text sources of laws and court rulings, and distilled versions of
these (referred to as examination guidelines). Results show that full-text
sources moderately improve performance, while examination guidelines
significantly enhance recall for void clauses and weighted F1-Score, reaching
80\%. Despite these advancements, LLMs' performance when using full-text
sources remains substantially below that of human lawyers. We contribute an
extended dataset, including examination guidelines, referenced legal sources,
and corresponding annotations, alongside our code and all log files. Our
findings highlight the potential of LLMs to assist lawyers in contract legality
review while also underscoring the limitations of the methods presented.

</details>


### [125] [Data interference: emojis, homoglyphs, and issues of data fidelity in corpora and their results](https://arxiv.org/abs/2507.01764)
*Matteo Di Cristofaro*

Main category: cs.CL

TL;DR: 论文探讨了分词对语言数据表示和分析结果的影响，强调了预处理表情符号和同形异义词的必要性，提出了确保数字文本准确表示的方法。


<details>
  <summary>Details</summary>
Motivation: 研究分词差异如何影响语言数据的表示和分析结果的有效性，特别是表情符号和同形异义词带来的挑战。

Method: 研究提出了预处理表情符号和同形异义词的方法，以确保数字文本在语料库中的准确表示。

Result: 研究强调了理解和处理语言和技术细节对提高语料分析准确性的重要性，对定量和定性研究均有重要意义。

Conclusion: 详细理解语言和技术细节是提高语料分析准确性的关键，对语料库研究的可靠性和可重复性至关重要。

Abstract: Tokenisation - "the process of splitting text into atomic parts" (Brezina &
Timperley, 2017: 1) - is a crucial step for corpus linguistics, as it provides
the basis for any applicable quantitative method (e.g. collocations) while
ensuring the reliability of qualitative approaches. This paper examines how
discrepancies in tokenisation affect the representation of language data and
the validity of analytical findings: investigating the challenges posed by
emojis and homoglyphs, the study highlights the necessity of preprocessing
these elements to maintain corpus fidelity to the source data. The research
presents methods for ensuring that digital texts are accurately represented in
corpora, thereby supporting reliable linguistic analysis and guaranteeing the
repeatability of linguistic interpretations. The findings emphasise the
necessity of a detailed understanding of both linguistic and technical aspects
involved in digital textual data to enhance the accuracy of corpus analysis,
and have significant implications for both quantitative and qualitative
approaches in corpus-based research.

</details>


### [126] [MuRating: A High Quality Data Selecting Approach to Multilingual Large Language Model Pretraining](https://arxiv.org/abs/2507.01785)
*Zhixun Chen,Ping Guo,Wenhan Han,Yifan Zhang,Binbin Liu,Haobin Lin,Fengze Liu,Yan Zhao,Bingni Zhang,Taifeng Wang,Yin Zheng,Meng Fang*

Main category: cs.CL

TL;DR: MuRating是一个可扩展的框架，通过将英语数据质量信号转移到17种目标语言中，训练多语言评估器，显著提升多语言任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于模型的数据选择方法主要针对英语，缺乏多语言支持，MuRating旨在填补这一空白。

Method: 通过聚合多个英语评分器的信号，学习统一的文档质量评分，并通过翻译将这些评分投射到目标语言，训练多语言评估器。

Result: 在英语和多语言基准测试中，MuRating显著提升了性能，尤其在知识密集型任务上表现突出。

Conclusion: MuRating为多语言数据质量评估提供了有效解决方案，并指出了未来研究方向。

Abstract: Data quality is a critical driver of large language model performance, yet
existing model-based selection methods focus almost exclusively on English. We
introduce MuRating, a scalable framework that transfers high-quality English
data-quality signals into a single rater for 17 target languages. MuRating
aggregates multiple English "raters" via pairwise comparisons to learn unified
document-quality scores,then projects these judgments through translation to
train a multilingual evaluator on monolingual, cross-lingual, and parallel text
pairs. Applied to web data, MuRating selects balanced subsets of English and
multilingual content to pretrain a 1.2 B-parameter LLaMA model. Compared to
strong baselines, including QuRater, AskLLM, DCLM and so on, our approach
boosts average accuracy on both English benchmarks and multilingual
evaluations, with especially large gains on knowledge-intensive tasks. We
further analyze translation fidelity, selection biases, and underrepresentation
of narrative material, outlining directions for future work.

</details>


### [127] [Probing Evaluation Awareness of Language Models](https://arxiv.org/abs/2507.01786)
*Jord Nguyen,Khiem Hoang,Carlo Leonardo Attubato,Felix Hofstätter*

Main category: cs.CL

TL;DR: 论文研究了语言模型（如Llama-3.3-70B-Instruct）的评估意识能力，发现线性探针能区分评估和部署提示，表明模型内部已具备这种区分能力。同时，当前安全评估被模型识别为人工或非真实，强调了确保可信评估和理解欺骗能力的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型的评估意识能力，因其对AI治理框架和行业自愿承诺的可靠性有重大影响。

Method: 使用线性探针分析Llama-3.3-70B-Instruct模型，区分评估和部署提示，并验证安全评估的识别情况。

Result: 线性探针能有效区分评估和部署提示，且当前安全评估被模型正确分类为人工或非真实。

Conclusion: 研究强调了确保评估可信度和理解模型欺骗能力的重要性，展示了模型内部信息如何支持黑盒安全审计。

Abstract: Language models can distinguish between testing and deployment phases -- a
capability known as evaluation awareness. This has significant safety and
policy implications, potentially undermining the reliability of evaluations
that are central to AI governance frameworks and voluntary industry
commitments. In this paper, we study evaluation awareness in
Llama-3.3-70B-Instruct. We show that linear probes can separate real-world
evaluation and deployment prompts, suggesting that current models internally
represent this distinction. We also find that current safety evaluations are
correctly classified by the probes, suggesting that they already appear
artificial or inauthentic to models. Our findings underscore the importance of
ensuring trustworthy evaluations and understanding deceptive capabilities. More
broadly, our work showcases how model internals may be leveraged to support
blackbox methods in safety audits, especially for future models more competent
at evaluation awareness and deception.

</details>


### [128] [How Do Vision-Language Models Process Conflicting Information Across Modalities?](https://arxiv.org/abs/2507.01790)
*Tianze Hua,Tian Yun,Ellie Pavlick*

Main category: cs.CL

TL;DR: 研究探讨多模态AI模型在输入信息冲突时的行为，发现模型倾向于优先处理某一模态，并识别出影响模态偏好的内部结构和注意力机制。


<details>
  <summary>Details</summary>
Motivation: 理解多模态模型如何处理冲突输入，以提升其在复杂环境中的表现。

Method: 通过向视觉-语言模型提供不一致输入（如图像与标题矛盾），测试模型对不同模态的偏好。

Result: 模型倾向于优先某一模态，且内部结构和注意力机制影响其偏好；发现模态无关的“路由头”可优化性能。

Conclusion: 研究为识别和控制多模态模型处理冲突信号提供了关键步骤。

Abstract: AI models are increasingly required to be multimodal, integrating disparate
input streams into a coherent state representation on which subsequent
behaviors and actions can be based. This paper seeks to understand how such
models behave when input streams present conflicting information. Focusing
specifically on vision-language models, we provide inconsistent inputs (e.g.,
an image of a dog paired with the caption "A photo of a cat") and ask the model
to report the information present in one of the specific modalities (e.g.,
"What does the caption say / What is in the image?"). We find that models often
favor one modality over the other, e.g., reporting the image regardless of what
the caption says, but that different models differ in which modality they
favor. We find evidence that the behaviorally preferred modality is evident in
the internal representational structure of the model, and that specific
attention heads can restructure the representations to favor one modality over
the other. Moreover, we find modality-agnostic "router heads" which appear to
promote answers about the modality requested in the instruction, and which can
be manipulated or transferred in order to improve performance across datasets
and modalities. Together, the work provides essential steps towards identifying
and controlling if and how models detect and resolve conflicting signals within
complex multimodal environments.

</details>


### [129] [AI4Research: A Survey of Artificial Intelligence for Scientific Research](https://arxiv.org/abs/2507.01903)
*Qiguang Chen,Mingda Yang,Libo Qin,Jinhao Liu,Zheng Yan,Jiannan Guan,Dengyun Peng,Yiyan Ji,Hanjing Li,Mengkang Hu,Yimeng Zhang,Yihao Liang,Yuhang Zhou,Jiaqi Wang,Zhi Chen,Wanxiang Che*

Main category: cs.CL

TL;DR: 本文综述了AI在科学研究中的应用（AI4Research），提出了系统分类法，指出了研究空白和未来方向，并整理了相关资源。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的进步激发了AI在科研中的应用，但缺乏全面综述，阻碍了领域发展。

Method: 提出系统分类法，识别研究空白，整理资源和应用。

Result: 提供了AI4Research的分类、未来方向和丰富资源。

Conclusion: 本文为研究社区提供了资源访问和领域发展的推动力。

Abstract: Recent advancements in artificial intelligence (AI), particularly in large
language models (LLMs) such as OpenAI-o1 and DeepSeek-R1, have demonstrated
remarkable capabilities in complex domains such as logical reasoning and
experimental coding. Motivated by these advancements, numerous studies have
explored the application of AI in the innovation process, particularly in the
context of scientific research. These AI technologies primarily aim to develop
systems that can autonomously conduct research processes across a wide range of
scientific disciplines. Despite these significant strides, a comprehensive
survey on AI for Research (AI4Research) remains absent, which hampers our
understanding and impedes further development in this field. To address this
gap, we present a comprehensive survey and offer a unified perspective on
AI4Research. Specifically, the main contributions of our work are as follows:
(1) Systematic taxonomy: We first introduce a systematic taxonomy to classify
five mainstream tasks in AI4Research. (2) New frontiers: Then, we identify key
research gaps and highlight promising future directions, focusing on the rigor
and scalability of automated experiments, as well as the societal impact. (3)
Abundant applications and resources: Finally, we compile a wealth of resources,
including relevant multidisciplinary applications, data corpora, and tools. We
hope our work will provide the research community with quick access to these
resources and stimulate innovative breakthroughs in AI4Research.

</details>


### [130] [The Anatomy of Evidence: An Investigation Into Explainable ICD Coding](https://arxiv.org/abs/2507.01802)
*Katharina Beckh,Elisa Studeny,Sujan Sai Gannamaneni,Dario Antweiler,Stefan Rüping*

Main category: cs.CL

TL;DR: 本文分析了MDACE数据集，评估了当前可解释医疗编码系统的合理性，发现真实证据与代码描述部分一致，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 自动医疗编码可简化文档和计费流程，但缺乏透明性评估数据，MDACE数据集为此提供了资源。

Method: 对MDACE数据集进行深入分析，评估现有可解释医疗编码系统的合理性，并提出匹配度量方法。

Result: 真实证据与代码描述部分一致，现有方法与真实证据高度重叠。

Conclusion: 研究为开发与评估可解释医疗编码系统提供了建议，促进了自动医疗编码的理解。

Abstract: Automatic medical coding has the potential to ease documentation and billing
processes. For this task, transparency plays an important role for medical
coders and regulatory bodies, which can be achieved using explainability
methods. However, the evaluation of these approaches has been mostly limited to
short text and binary settings due to a scarcity of annotated data. Recent
efforts by Cheng et al. (2023) have introduced the MDACE dataset, which
provides a valuable resource containing code evidence in clinical records. In
this work, we conduct an in-depth analysis of the MDACE dataset and perform
plausibility evaluation of current explainable medical coding systems from an
applied perspective. With this, we contribute to a deeper understanding of
automatic medical coding and evidence extraction. Our findings reveal that
ground truth evidence aligns with code descriptions to a certain degree. An
investigation into state-of-the-art approaches shows a high overlap with ground
truth evidence. We propose match measures and highlight success and failure
cases. Based on our findings, we provide recommendations for developing and
evaluating explainable medical coding systems.

</details>


### [131] [Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models](https://arxiv.org/abs/2507.01915)
*Chengao Li,Hanyu Zhang,Yunkun Xu,Hongyan Xue,Xiang Ao,Qing He*

Main category: cs.CL

TL;DR: 论文提出了一种名为GAPO的新方法，通过多梯度下降优化解决LLMs与多样化人类偏好对齐的问题，并引入P-GAPO进一步结合用户偏好。实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）与多样化且可能冲突的人类偏好对齐的挑战。

Method: 提出GAPO（梯度自适应策略优化），采用多梯度下降技术，自适应调整梯度以平衡目标间的权衡；进一步提出P-GAPO，结合用户偏好生成帕累托最优解。

Result: 理论证明GAPO收敛于帕累托最优解；实验显示GAPO在Mistral-7B上优于现有方法，在帮助性和无害性上表现更优。

Conclusion: GAPO和P-GAPO有效解决了LLMs与多样化人类偏好的对齐问题，为多目标优化提供了新思路。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has emerged as a powerful
technique for aligning large language models (LLMs) with human preferences.
However, effectively aligning LLMs with diverse human preferences remains a
significant challenge, particularly when they are conflict. To address this
issue, we frame human value alignment as a multi-objective optimization
problem, aiming to maximize a set of potentially conflicting objectives. We
introduce Gradient-Adaptive Policy Optimization (GAPO), a novel fine-tuning
paradigm that employs multiple-gradient descent to align LLMs with diverse
preference distributions. GAPO adaptively rescales the gradients for each
objective to determine an update direction that optimally balances the
trade-offs between objectives. Additionally, we introduce P-GAPO, which
incorporates user preferences across different objectives and achieves Pareto
solutions that better align with the user's specific needs. Our theoretical
analysis demonstrates that GAPO converges towards a Pareto optimal solution for
multiple objectives. Empirical results on Mistral-7B show that GAPO outperforms
current state-of-the-art methods, achieving superior performance in both
helpfulness and harmlessness.

</details>


### [132] [Evaluating Structured Output Robustness of Small Language Models for Open Attribute-Value Extraction from Clinical Notes](https://arxiv.org/abs/2507.01810)
*Nikita Neveditsin,Pawan Lingras,Vijay Mago*

Main category: cs.CL

TL;DR: 比较分析小语言模型生成的临床笔记结构化输出的可解析性，发现JSON格式表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究不同序列化格式（JSON、YAML、XML）在临床笔记属性值提取中的可解析性，为隐私敏感的临床环境提供实用指导。

Method: 评估三种序列化格式的解析能力，分析目标提示和模型大小对结构鲁棒性的影响。

Result: JSON格式表现最优，结构鲁棒性随提示优化和模型增大而提升，但在长文档和特定笔记类型中下降。

Conclusion: JSON是临床笔记结构化输出的首选格式，提示设计和模型选择需根据文档长度和类型调整。

Abstract: We present a comparative analysis of the parseability of structured outputs
generated by small language models for open attribute-value extraction from
clinical notes. We evaluate three widely used serialization formats: JSON,
YAML, and XML, and find that JSON consistently yields the highest parseability.
Structural robustness improves with targeted prompting and larger models, but
declines for longer documents and certain note types. Our error analysis
identifies recurring format-specific failure patterns. These findings offer
practical guidance for selecting serialization formats and designing prompts
when deploying language models in privacy-sensitive clinical settings.

</details>


### [133] [Adaptability of ASR Models on Low-Resource Language: A Comparative Study of Whisper and Wav2Vec-BERT on Bangla](https://arxiv.org/abs/2507.01931)
*Md Sazzadul Islam Ridoy,Sumi Akter,Md. Aminur Rahman*

Main category: cs.CL

TL;DR: 研究比较了Whisper和Wav2Vec-BERT在低资源语言孟加拉语上的表现，Wav2Vec-BERT在所有关键指标上表现更优。


<details>
  <summary>Details</summary>
Motivation: 支持低资源语言的语音识别系统开发。

Method: 使用公开数据集进行实验，通过微调和超参数优化比较模型性能。

Result: Wav2Vec-BERT在WER、CER、训练时间和计算效率上均优于Whisper。

Conclusion: Wav2Vec-BERT更适合低资源语言的语音识别系统开发。

Abstract: In recent years, neural models trained on large multilingual text and speech
datasets have shown great potential for supporting low-resource languages. This
study investigates the performances of two state-of-the-art Automatic Speech
Recognition (ASR) models, OpenAI's Whisper (Small & Large-V2) and Facebook's
Wav2Vec-BERT on Bangla, a low-resource language. We have conducted experiments
using two publicly available datasets: Mozilla Common Voice-17 and OpenSLR to
evaluate model performances. Through systematic fine-tuning and hyperparameter
optimization, including learning rate, epochs, and model checkpoint selection,
we have compared the models based on Word Error Rate (WER), Character Error
Rate (CER), Training Time, and Computational Efficiency. The Wav2Vec-BERT model
outperformed Whisper across all key evaluation metrics, demonstrated superior
performance while requiring fewer computational resources, and offered valuable
insights to develop robust speech recognition systems in low-resource
linguistic settings.

</details>


### [134] [Low-Perplexity LLM-Generated Sequences and Where To Find Them](https://arxiv.org/abs/2507.01844)
*Arthur Wuhrmann,Anastasiia Kucherenko,Andrei Kucharavy*

Main category: cs.CL

TL;DR: 本文提出了一种系统方法，通过分析低困惑度序列来研究大型语言模型（LLMs）如何利用和复制其训练数据，揭示了训练数据对模型行为的影响。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，理解训练数据如何影响其输出对透明度、责任、隐私和公平性至关重要。

Method: 通过分析低困惑度序列（模型生成的高概率文本片段），建立了一个可靠的提取和溯源流程，追踪这些片段到训练数据中的来源。

Result: 研究发现，大量低困惑度序列无法映射到训练数据；对于能匹配的部分，量化了其在源文档中的分布，揭示了模型的逐字回忆行为。

Conclusion: 该方法为理解训练数据如何影响LLMs行为提供了新途径，强调了数据溯源的重要性。

Abstract: As Large Language Models (LLMs) become increasingly widespread, understanding
how specific training data shapes their outputs is crucial for transparency,
accountability, privacy, and fairness. To explore how LLMs leverage and
replicate their training data, we introduce a systematic approach centered on
analyzing low-perplexity sequences - high-probability text spans generated by
the model. Our pipeline reliably extracts such long sequences across diverse
topics while avoiding degeneration, then traces them back to their sources in
the training data. Surprisingly, we find that a substantial portion of these
low-perplexity spans cannot be mapped to the corpus. For those that do match,
we quantify the distribution of occurrences across source documents,
highlighting the scope and nature of verbatim recall and paving a way toward
better understanding of how LLMs training data impacts their behavior.

</details>


### [135] [Eka-Eval : A Comprehensive Evaluation Framework for Large Language Models in Indian Languages](https://arxiv.org/abs/2507.01853)
*Samridhi Raj Sinha,Rajvee Sheth,Abhishek Upperwal,Mayank Singh*

Main category: cs.CL

TL;DR: EKA-EVAL是一个统一且可投入生产的评估框架，支持多语言（特别是印度语言）的LLM评估，集成了35个基准测试，包括10个印度特定数据集。


<details>
  <summary>Details</summary>
Motivation: 现有评估框架多为英语中心化，无法满足印度等多语言地区的需求，因此开发了EKA-EVAL。

Method: EKA-EVAL整合了35个基准测试，支持分布式推理、量化和多GPU使用，提供端到端评估。

Result: EKA-EVAL成为首个面向全球和印度LLM的可扩展评估套件，显著降低多语言基准测试门槛。

Conclusion: EKA-EVAL开源且将持续扩展，目标是建立强大的多语言LLM评估生态系统。

Abstract: The rapid advancement of Large Language Models (LLMs) has intensified the
need for evaluation frameworks that go beyond English centric benchmarks and
address the requirements of linguistically diverse regions such as India. We
present EKA-EVAL, a unified and production-ready evaluation framework that
integrates over 35 benchmarks, including 10 Indic-specific datasets, spanning
categories like reasoning, mathematics, tool use, long-context understanding,
and reading comprehension. Compared to existing Indian language evaluation
tools, EKA-EVAL offers broader benchmark coverage, with built-in support for
distributed inference, quantization, and multi-GPU usage. Our systematic
comparison positions EKA-EVAL as the first end-to-end, extensible evaluation
suite tailored for both global and Indic LLMs, significantly lowering the
barrier to multilingual benchmarking. The framework is open-source and publicly
available at https://github.com/lingo-iitgn/ eka-eval and a part of ongoing EKA
initiative (https://eka.soket.ai), which aims to scale up to over 100
benchmarks and establish a robust, multilingual evaluation ecosystem for LLMs.

</details>


### [136] [DIY-MKG: An LLM-Based Polyglot Language Learning System](https://arxiv.org/abs/2507.01872)
*Kenan Tang,Yanhong Li,Yao Qin*

Main category: cs.CL

TL;DR: DIY-MKG是一个开源系统，支持多语言学习者构建个性化词汇知识图谱，通过LLM提供相关词汇建议，并利用动态测验和反馈机制提升学习效果。


<details>
  <summary>Details</summary>
Motivation: 现有语言学习工具缺乏对多语言学习者的支持，定制化不足且存在认知卸载问题。

Method: 设计DIY-MKG系统，利用LLM构建个性化词汇知识图谱，支持动态测验生成和用户反馈。

Result: 评估表明，DIY-MKG的词汇扩展可靠且公平，生成的测验准确度高。

Conclusion: DIY-MKG通过个性化学习和反馈机制，有效解决了现有工具的局限性。

Abstract: Existing language learning tools, even those powered by Large Language Models
(LLMs), often lack support for polyglot learners to build linguistic
connections across vocabularies in multiple languages, provide limited
customization for individual learning paces or needs, and suffer from
detrimental cognitive offloading. To address these limitations, we design
Do-It-Yourself Multilingual Knowledge Graph (DIY-MKG), an open-source system
that supports polyglot language learning. DIY-MKG allows the user to build
personalized vocabulary knowledge graphs, which are constructed by selective
expansion with related words suggested by an LLM. The system further enhances
learning through rich annotation capabilities and an adaptive review module
that leverages LLMs for dynamic, personalized quiz generation. In addition,
DIY-MKG allows users to flag incorrect quiz questions, simultaneously
increasing user engagement and providing a feedback loop for prompt refinement.
Our evaluation of LLM-based components in DIY-MKG shows that vocabulary
expansion is reliable and fair across multiple languages, and that the
generated quizzes are highly accurate, validating the robustness of DIY-MKG.

</details>


### [137] [MiCoTA: Bridging the Learnability Gap with Intermediate CoT and Teacher Assistants](https://arxiv.org/abs/2507.01887)
*Dongyi Ding,Tiannan Wang,Chenghao Zhu,Meiling Tao,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: MiCoTA框架通过中间模型和中等长度推理序列，提升小语言模型的长推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决小语言模型（SLMs）因容量有限而难以学习长推理序列的问题。

Method: 引入MiCoTA框架，利用中间模型作为教师助手，使用中等长度推理序列进行蒸馏。

Result: SLMs在多个基准测试中表现显著提升，如Qwen2.5-7B和3B模型在AIME2024等任务中平均分提高3.47和3.93。

Conclusion: MiCoTA通过优化数据分布，为SLMs的长推理蒸馏提供了有效方法，为未来研究铺路。

Abstract: Large language models (LLMs) excel at reasoning tasks requiring long thought
sequences for planning, reflection, and refinement. However, their substantial
model size and high computational demands are impractical for widespread
deployment. Yet, small language models (SLMs) often struggle to learn long-form
CoT reasoning due to their limited capacity, a phenomenon we refer to as the
"SLMs Learnability Gap". To address this, we introduce
\textbf{Mi}d-\textbf{Co}T \textbf{T}eacher \textbf{A}ssistant Distillation
(MiCoTAl), a framework for improving long CoT distillation for SLMs. MiCoTA
employs intermediate-sized models as teacher assistants and utilizes
intermediate-length CoT sequences to bridge both the capacity and reasoning
length gaps. Our experiments on downstream tasks demonstrate that although SLMs
distilled from large teachers can perform poorly, by applying MiCoTA, they
achieve significant improvements in reasoning performance. Specifically,
Qwen2.5-7B-Instruct and Qwen2.5-3B-Instruct achieve an improvement of 3.47 and
3.93 respectively on average score on AIME2024, AMC, Olympiad, MATH-500 and
GSM8K benchmarks. To better understand the mechanism behind MiCoTA, we perform
a quantitative experiment demonstrating that our method produces data more
closely aligned with base SLM distributions. Our insights pave the way for
future research into long-CoT data distillation for SLMs.

</details>


### [138] [High-Layer Attention Pruning with Rescaling](https://arxiv.org/abs/2507.01900)
*Songtao Liu,Peng Liu*

Main category: cs.CL

TL;DR: 提出了一种新颖的剪枝算法，针对大语言模型的高层注意力头进行策略性剪枝，并通过自适应缩放参数校准表示尺度，显著提升了生成任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统剪枝方法不考虑注意力头在网络架构中的位置，导致性能下降。本文旨在通过策略性剪枝和表示校准解决这一问题。

Method: 提出了一种剪枝算法，专注于高层注意力头的剪枝，并引入自适应缩放参数校准剪枝后的表示尺度。

Result: 在多个大语言模型和27个数据集上的实验表明，该方法在生成任务中显著优于现有剪枝方法。

Conclusion: 策略性剪枝和表示校准有效提升了大语言模型的剪枝性能，尤其在生成任务中表现突出。

Abstract: Pruning is a highly effective approach for compressing large language models
(LLMs), significantly reducing inference latency. However, conventional
training-free structured pruning methods often employ a heuristic metric that
indiscriminately removes some attention heads across all pruning layers,
without considering their positions within the network architecture. In this
work, we propose a novel pruning algorithm that strategically prunes attention
heads in the model's higher layers. Since the removal of attention heads can
alter the magnitude of token representations, we introduce an adaptive
rescaling parameter that calibrates the representation scale post-pruning to
counteract this effect. We conduct comprehensive experiments on a wide range of
LLMs, including LLaMA3.1-8B, Mistral-7B-v0.3, Qwen2-7B, and Gemma2-9B. Our
evaluation includes both generation and discriminative tasks across 27
datasets. The results consistently demonstrate that our method outperforms
existing structured pruning methods. This improvement is particularly notable
in generation tasks, where our approach significantly outperforms existing
baselines.

</details>


### [139] [NaturalThoughts: Selecting and Distilling Reasoning Traces for General Reasoning Tasks](https://arxiv.org/abs/2507.01921)
*Yang Li,Youssef Emad,Karthik Padthe,Jack Lanchantin,Weizhe Yuan,Thao Nguyen,Jason Weston,Shang-Wen Li,Dong Wang,Ilia Kulikov,Xian Li*

Main category: cs.CL

TL;DR: 通过从教师模型中选择高质量推理轨迹（NaturalThoughts）进行蒸馏，显著提升学生模型的推理能力，优于随机采样和其他现有数据集。


<details>
  <summary>Details</summary>
Motivation: 研究教师模型的推理演示中哪些因素对学生模型推理能力提升最有效，填补系统性研究的空白。

Method: 从教师模型中精选推理轨迹（NaturalThoughts），分析样本效率和可扩展性，并比较随机采样与选择困难样本的效果。

Result: NaturalThoughts在Llama和Qwen模型上表现优于现有数据集（如OpenThoughts、LIMO），在STEM推理基准测试中取得更好成绩。

Conclusion: 精选困难且多样化的推理样本能更高效地提升学生模型的推理能力，数据规模扩展仍是有效基线。

Abstract: Recent work has shown that distilling reasoning traces from a larger teacher
model via supervised finetuning outperforms reinforcement learning with the
smaller student model alone (Guo et al. 2025). However, there has not been a
systematic study of what kind of reasoning demonstrations from the teacher are
most effective in improving the student model's reasoning capabilities. In this
work we curate high-quality "NaturalThoughts" by selecting reasoning traces
from a strong teacher model based on a large pool of questions from
NaturalReasoning (Yuan et al. 2025). We first conduct a systematic analysis of
factors that affect distilling reasoning capabilities, in terms of sample
efficiency and scalability for general reasoning tasks. We observe that simply
scaling up data size with random sampling is a strong baseline with steady
performance gains. Further, we find that selecting difficult examples that
require more diverse reasoning strategies is more sample-efficient to transfer
the teacher model's reasoning skills. Evaluated on both Llama and Qwen models,
training with NaturalThoughts outperforms existing reasoning datasets such as
OpenThoughts, LIMO, etc. on general STEM reasoning benchmarks including
GPQA-Diamond, MMLU-Pro and SuperGPQA.

</details>


### [140] [Decision-oriented Text Evaluation](https://arxiv.org/abs/2507.01923)
*Yu-Shiang Huang,Chuan-Ju Wang,Chung-Chi Chen*

Main category: cs.CL

TL;DR: 提出了一种基于决策效果的NLG评估框架，通过测量生成文本对人类和LLM决策的影响，发现传统评估指标与决策效果相关性较弱。


<details>
  <summary>Details</summary>
Motivation: 现有NLG评估方法（如n-gram重叠或句子合理性）与高风险领域决策效果相关性低，需开发更直接的评估框架。

Method: 使用市场摘要文本（客观晨报和主观收盘分析），通过人类投资者和LLM代理的金融交易表现评估决策质量。

Result: 人类和LLM代理仅依赖摘要时表现不优于随机；但更丰富的分析评论能显著提升人机协作团队的表现。

Conclusion: 强调评估生成文本应关注其促进人机协同决策的能力，传统内在指标存在局限性。

Abstract: Natural language generation (NLG) is increasingly deployed in high-stakes
domains, yet common intrinsic evaluation methods, such as n-gram overlap or
sentence plausibility, weakly correlate with actual decision-making efficacy.
We propose a decision-oriented framework for evaluating generated text by
directly measuring its influence on human and large language model (LLM)
decision outcomes. Using market digest texts--including objective morning
summaries and subjective closing-bell analyses--as test cases, we assess
decision quality based on the financial performance of trades executed by human
investors and autonomous LLM agents informed exclusively by these texts. Our
findings reveal that neither humans nor LLM agents consistently surpass random
performance when relying solely on summaries. However, richer analytical
commentaries enable collaborative human-LLM teams to outperform individual
human or agent baselines significantly. Our approach underscores the importance
of evaluating generated text by its ability to facilitate synergistic
decision-making between humans and LLMs, highlighting critical limitations of
traditional intrinsic metrics.

</details>


### [141] [The Thin Line Between Comprehension and Persuasion in LLMs](https://arxiv.org/abs/2507.01936)
*Adrian de Wynter,Tangming Yuan*

Main category: cs.CL

TL;DR: LLMs能进行连贯且有说服力的辩论，但缺乏对对话深层结构的理解。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在辩论中的表现及其对对话结构的理解能力。

Method: 评估LLMs的辩论能力及其对对话结构和语用背景的理解。

Result: LLMs能进行有说服力的辩论，但无法展示对深层对话结构的理解。

Conclusion: LLMs作为评估者的局限性源于其对语境的理解不足，辩论能力不依赖对内容的理解。

Abstract: Large language models (LLMs) are excellent at maintaining high-level,
convincing dialogues. They are being fast deployed as chatbots and evaluators
in sensitive areas, such as peer review and mental health applications. This,
along with the disparate accounts on their reasoning capabilities, calls for a
closer examination of LLMs and their comprehension of dialogue. In this work we
begin by evaluating LLMs' ability to maintain a debate--one of the purest yet
most complex forms of human communication. Then we measure how this capability
relates to their understanding of what is being talked about, namely, their
comprehension of dialogical structures and the pragmatic context. We find that
LLMs are capable of maintaining coherent, persuasive debates, often swaying the
beliefs of participants and audiences alike. We also note that awareness or
suspicion of AI involvement encourage people to be more critical of the
arguments made. When polling LLMs on their comprehension of deeper structures
of dialogue, however, they cannot demonstrate said understanding. Our findings
tie the shortcomings of LLMs-as-evaluators to their (in)ability to understand
the context. More broadly, for the field of argumentation theory we posit that,
if an agent can convincingly maintain a dialogue, it is not necessary for it to
know what it is talking about. Hence, the modelling of pragmatic context and
coherence are secondary to effectiveness.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [142] [Environment-Aware and Human-Cooperative Swing Control for Lower-Limb Prostheses in Diverse Obstacle Scenarios](https://arxiv.org/abs/2507.01111)
*Haosen Xing,Haoran Ma,Sijin Zhang,Hartmut Geyer*

Main category: cs.RO

TL;DR: 提出了一种新型控制策略，结合环境感知与用户意图，用于下肢假肢在复杂地形中的障碍物导航。


<details>
  <summary>Details</summary>
Motivation: 现有下肢假肢控制策略缺乏对环境及用户意图的感知，尤其在复杂地形中表现不佳。

Method: 使用机载深度摄像头检测障碍物，结合用户生物力学信号动态调整摆动轨迹。

Result: 实验显示，在150多次跨越和30多次踏上障碍物的测试中，成功率为100%。

Conclusion: 该系统能有效适应环境约束和用户意图，具有广泛的应用潜力。

Abstract: Current control strategies for powered lower limb prostheses often lack
awareness of the environment and the user's intended interactions with it. This
limitation becomes particularly apparent in complex terrains. Obstacle
negotiation, a critical scenario exemplifying such challenges, requires both
real-time perception of obstacle geometry and responsiveness to user intention
about when and where to step over or onto, to dynamically adjust swing
trajectories. We propose a novel control strategy that fuses environmental
awareness and human cooperativeness: an on-board depth camera detects obstacles
ahead of swing phase, prompting an elevated early-swing trajectory to ensure
clearance, while late-swing control defers to natural biomechanical cues from
the user. This approach enables intuitive stepping strategies without requiring
unnatural movement patterns. Experiments with three non-amputee participants
demonstrated 100 percent success across more than 150 step-overs and 30
step-ons with randomly placed obstacles of varying heights (4-16 cm) and
distances (15-70 cm). By effectively addressing obstacle navigation -- a
gateway challenge for complex terrain mobility -- our system demonstrates
adaptability to both environmental constraints and user intentions, with
promising applications across diverse locomotion scenarios.

</details>


### [143] [VISTA: Open-Vocabulary, Task-Relevant Robot Exploration with Online Semantic Gaussian Splatting](https://arxiv.org/abs/2507.01125)
*Keiko Nagami,Timothy Chen,Javier Yu,Ola Shorinwa,Maximilian Adang,Carlyn Dougherty,Eric Cristofalo,Mac Schwager*

Main category: cs.RO

TL;DR: VISTA是一种主动探索方法，帮助机器人规划信息丰富的轨迹，以提升与任务相关的3D地图质量。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在开放词汇搜索任务中高效探索环境并构建语义3D地图的需求。

Method: 通过规划语义相似性和未探索区域优先的轨迹，结合高效的视角-语义覆盖度量。

Result: 在静态数据集上表现优于FisherRF和Bayes' Rays，硬件实验中成功率提升6倍。

Conclusion: VISTA具有平台无关性，适用于多种机器人平台，代码将开源。

Abstract: We present VISTA (Viewpoint-based Image selection with Semantic Task
Awareness), an active exploration method for robots to plan informative
trajectories that improve 3D map quality in areas most relevant for task
completion. Given an open-vocabulary search instruction (e.g., "find a
person"), VISTA enables a robot to explore its environment to search for the
object of interest, while simultaneously building a real-time semantic 3D
Gaussian Splatting reconstruction of the scene. The robot navigates its
environment by planning receding-horizon trajectories that prioritize semantic
similarity to the query and exploration of unseen regions of the environment.
To evaluate trajectories, VISTA introduces a novel, efficient
viewpoint-semantic coverage metric that quantifies both the geometric view
diversity and task relevance in the 3D scene. On static datasets, our coverage
metric outperforms state-of-the-art baselines, FisherRF and Bayes' Rays, in
computation speed and reconstruction quality. In quadrotor hardware
experiments, VISTA achieves 6x higher success rates in challenging maps,
compared to baseline methods, while matching baseline performance in less
challenging maps. Lastly, we show that VISTA is platform-agnostic by deploying
it on a quadrotor drone and a Spot quadruped robot. Open-source code will be
released upon acceptance of the paper.

</details>


### [144] [A Review on Sound Source Localization in Robotics: Focusing on Deep Learning Methods](https://arxiv.org/abs/2507.01143)
*Reza Jalayer,Masoud Jalayer,Amirali Baniasadi*

Main category: cs.RO

TL;DR: 本文综述了机器人领域中的声源定位（SSL）技术，重点介绍了深度学习方法的最新进展，并探讨了当前挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有综述多关注通用音频应用，未充分考虑机器人领域的限制和深度学习的最新进展，本文旨在填补这一空白。

Method: 回顾了经典方法（如TDOA、波束成形等）和现代深度学习方法（如CNN、CRNN等），并探讨了数据与训练策略。

Result: 总结了不同机器人类型和应用领域的研究，并指出了当前SSL在环境鲁棒性、多声源问题等方面的挑战。

Conclusion: 提出了未来研究方向，以实现下一代机器人中鲁棒、高效且可解释的DL-based SSL。

Abstract: Sound source localization (SSL) adds a spatial dimension to auditory
perception, allowing a system to pinpoint the origin of speech, machinery
noise, warning tones, or other acoustic events, capabilities that facilitate
robot navigation, human-machine dialogue, and condition monitoring. While
existing surveys provide valuable historical context, they typically address
general audio applications and do not fully account for robotic constraints or
the latest advancements in deep learning. This review addresses these gaps by
offering a robotics-focused synthesis, emphasizing recent progress in deep
learning methodologies. We start by reviewing classical methods such as Time
Difference of Arrival (TDOA), beamforming, Steered-Response Power (SRP), and
subspace analysis. Subsequently, we delve into modern machine learning (ML) and
deep learning (DL) approaches, discussing traditional ML and neural networks
(NNs), convolutional neural networks (CNNs), convolutional recurrent neural
networks (CRNNs), and emerging attention-based architectures. The data and
training strategy that are the two cornerstones of DL-based SSL are explored.
Studies are further categorized by robot types and application domains to
facilitate researchers in identifying relevant work for their specific
contexts. Finally, we highlight the current challenges in SSL works in general,
regarding environmental robustness, sound source multiplicity, and specific
implementation constraints in robotics, as well as data and learning strategies
in DL-based SSL. Also, we sketch promising directions to offer an actionable
roadmap toward robust, adaptable, efficient, and explainable DL-based SSL for
next-generation robots.

</details>


### [145] [SonoGym: High Performance Simulation for Challenging Surgical Tasks with Robotic Ultrasound](https://arxiv.org/abs/2507.01152)
*Yunke Ao,Masoud Moghani,Mayank Mittal,Manish Prajapat,Luohong Wu,Frederic Giraud,Fabio Carrillo,Andreas Krause,Philipp Fürnstahl*

Main category: cs.RO

TL;DR: SonoGym是一个用于复杂机器人超声任务的可扩展模拟平台，支持通过物理和生成建模方法实时模拟超声数据，用于训练深度强化学习和模仿学习代理。


<details>
  <summary>Details</summary>
Motivation: 解决复杂手术任务中缺乏真实且高效的模拟环境的问题，以促进机器人超声在解剖重建和手术导航中的应用。

Method: 结合物理和生成建模方法模拟超声数据，集成常见机器人平台和骨科末端执行器，训练深度强化学习和模仿学习代理。

Result: 成功在多种场景中实现策略学习，同时揭示了当前方法在临床相关环境中的局限性。

Conclusion: SonoGym有助于推动机器人学习方法在复杂手术应用中的研究。

Abstract: Ultrasound (US) is a widely used medical imaging modality due to its
real-time capabilities, non-invasive nature, and cost-effectiveness. Robotic
ultrasound can further enhance its utility by reducing operator dependence and
improving access to complex anatomical regions. For this, while deep
reinforcement learning (DRL) and imitation learning (IL) have shown potential
for autonomous navigation, their use in complex surgical tasks such as anatomy
reconstruction and surgical guidance remains limited -- largely due to the lack
of realistic and efficient simulation environments tailored to these tasks. We
introduce SonoGym, a scalable simulation platform for complex robotic
ultrasound tasks that enables parallel simulation across tens to hundreds of
environments. Our framework supports realistic and real-time simulation of US
data from CT-derived 3D models of the anatomy through both a physics-based and
a generative modeling approach. Sonogym enables the training of DRL and recent
IL agents (vision transformers and diffusion policies) for relevant tasks in
robotic orthopedic surgery by integrating common robotic platforms and
orthopedic end effectors. We further incorporate submodular DRL -- a recent
method that handles history-dependent rewards -- for anatomy reconstruction and
safe reinforcement learning for surgery. Our results demonstrate successful
policy learning across a range of scenarios, while also highlighting the
limitations of current methods in clinically relevant environments. We believe
our simulation can facilitate research in robot learning approaches for such
challenging robotic surgery applications. Dataset, codes, and videos are
publicly available at https://sonogym.github.io/.

</details>


### [146] [A Differentiable Distance Metric for Robotics Through Generalized Alternating Projection](https://arxiv.org/abs/2507.01181)
*Vinicius M. Gonçalves,Shiqing Wei,Eduardo Malacarne S. de Souza,Krishnamurthy Prashanth,Anthony Tzes,Farshad Khorrami*

Main category: cs.RO

TL;DR: 论文提出了一种新的可微距离度量方法，解决了现有方法在凸多面体上的复杂性和实用性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统欧几里得距离不可微，而现有可微距离度量方法存在复杂性和实用性不足的问题，需要改进。

Method: 提出了更简单、实用的平滑投影表达式，适用于一般凸多面体，并确保距离在物体重叠时趋近于零。

Result: 实验结果表明，新方法有效且实用，并通过Python仿真包UAIBot公开可用。

Conclusion: 新方法解决了现有可微距离度量的不足，提供了更简单实用的解决方案。

Abstract: In many robotics applications, it is necessary to compute not only the
distance between the robot and the environment, but also its derivative - for
example, when using control barrier functions. However, since the traditional
Euclidean distance is not differentiable, there is a need for alternative
distance metrics that possess this property. Recently, a metric with guaranteed
differentiability was proposed [1]. This approach has some important drawbacks,
which we address in this paper. We provide much simpler and practical
expressions for the smooth projection for general convex polytopes.
Additionally, as opposed to [1], we ensure that the distance vanishes as the
objects overlap. We show the efficacy of the approach in experimental results.
Our proposed distance metric is publicly available through the Python-based
simulation package UAIBot.

</details>


### [147] [Search-Based Robot Motion Planning With Distance-Based Adaptive Motion Primitives](https://arxiv.org/abs/2507.01198)
*Benjamin Kraljusic,Zlatan Ajanovic,Nermin Covic,Bakir Lacevic*

Main category: cs.RO

TL;DR: 提出了一种结合采样和搜索的运动规划算法，利用自由配置空间的burs作为自适应运动基元，显著提高了路径规划效率。


<details>
  <summary>Details</summary>
Motivation: 传统固定大小的运动基元在复杂环境中效率较低，特别是在高自由度机械臂中。通过自适应扩展的自由配置空间burs，可以更高效地探索配置空间。

Method: 在SMPL库中实现了一种基于burs的算法，利用自由配置空间的burs作为自适应运动基元，替代固定大小的运动基元。

Result: 在复杂场景中，特别是高自由度机械臂，基于burs的方法优于固定基元规划，同时在简单场景中表现相当。

Conclusion: 基于burs的自适应运动基元显著提高了运动规划的效率，尤其在复杂和高自由度场景中表现优异。

Abstract: This work proposes a motion planning algorithm for robotic manipulators that
combines sampling-based and search-based planning methods. The core
contribution of the proposed approach is the usage of burs of free
configuration space (C-space) as adaptive motion primitives within the graph
search algorithm. Due to their feature to adaptively expand in free C-space,
burs enable more efficient exploration of the configuration space compared to
fixed-sized motion primitives, significantly reducing the time to find a valid
path and the number of required expansions. The algorithm is implemented within
the existing SMPL (Search-Based Motion Planning Library) library and evaluated
through a series of different scenarios involving manipulators with varying
number of degrees-of-freedom (DoF) and environment complexity. Results
demonstrate that the bur-based approach outperforms fixed-primitive planning in
complex scenarios, particularly for high DoF manipulators, while achieving
comparable performance in simpler scenarios.

</details>


### [148] [2024 NASA SUITS Report: LLM-Driven Immersive Augmented Reality User Interface for Robotics and Space Exploration](https://arxiv.org/abs/2507.01206)
*Kathy Zhuang,Zixun Huang,Yukun Song,Rui Li,Yinuo Zhou,Allen Y. Yang*

Main category: cs.RO

TL;DR: 论文介绍了URSA系统，一个基于LLM的增强现实（AR）系统，用于NASA的SUITS挑战，支持宇航员任务。系统结合了AR设备、语音控制和机器人跟踪算法，解决了动态环境中的3D定位问题。


<details>
  <summary>Details</summary>
Motivation: 随着AR技术的发展，机器感知在复杂动态环境中的3D物体姿态估计面临挑战。项目旨在为非侵入式、空间感知的人机交互提供解决方案，满足未来太空任务（如Artemis）的需求。

Method: URSA系统整合了头戴式AR设备、基于LLM的语音控制、机器人跟踪算法和数字孪生定位技术。使用了DTTD-Mobile数据集和ZED2相机进行实时跟踪。

Result: 系统实现了实时机器人控制和监控，支持无地面真实传感器的操作。关键贡献包括非侵入式AR界面、专用数据集、任务可视化控制台和优化的6DoF姿态估计器。

Conclusion: URSA系统推动了数字孪生在机器人领域的应用，为航空航天和工业领域提供了可扩展的解决方案。

Abstract: As modern computing advances, new interaction paradigms have emerged,
particularly in Augmented Reality (AR), which overlays virtual interfaces onto
physical objects. This evolution poses challenges in machine perception,
especially for tasks like 3D object pose estimation in complex, dynamic
environments. Our project addresses critical issues in human-robot interaction
within mobile AR, focusing on non-intrusive, spatially aware interfaces. We
present URSA, an LLM-driven immersive AR system developed for NASA's 2023-2024
SUITS challenge, targeting future spaceflight needs such as the Artemis
missions. URSA integrates three core technologies: a head-mounted AR device
(e.g., HoloLens) for intuitive visual feedback, voice control powered by large
language models for hands-free interaction, and robot tracking algorithms that
enable accurate 3D localization in dynamic settings. To enhance precision, we
leverage digital twin localization technologies, using datasets like
DTTD-Mobile and specialized hardware such as the ZED2 camera for real-world
tracking under noise and occlusion. Our system enables real-time robot control
and monitoring via an AR interface, even in the absence of ground-truth
sensors--vital for hazardous or remote operations. Key contributions include:
(1) a non-intrusive AR interface with LLM-based voice input; (2) a ZED2-based
dataset tailored for non-rigid robotic bodies; (3) a Local Mission Control
Console (LMCC) for mission visualization; (4) a transformer-based 6DoF pose
estimator (DTTDNet) optimized for depth fusion and real-time tracking; and (5)
end-to-end integration for astronaut mission support. This work advances
digital twin applications in robotics, offering scalable solutions for both
aerospace and industrial domains.

</details>


### [149] [Jump-Start Reinforcement Learning with Self-Evolving Priors for Extreme Monopedal Locomotion](https://arxiv.org/abs/2507.01243)
*Ziang Zheng,Guojian Zhan,Shiqi Liu,Yao Lyu,Tao Zhang,Shengbo Eben Li*

Main category: cs.RO

TL;DR: JumpER是一种通过自演化先验分阶段训练强化学习策略的框架，解决了四足机器人在极端欠驱动和极端地形下的单足跳跃任务挑战。


<details>
  <summary>Details</summary>
Motivation: 传统方法在同时应对极端欠驱动和极端地形时，由于早期交互不稳定和奖励反馈不可靠，难以直接训练有效的策略。

Method: JumpER通过分阶段学习，动态生成自演化先验，逐步优化策略，结合三阶段课程设计（动作模态、观测空间和任务目标的渐进演化）。

Result: JumpER首次实现了四足机器人在不可预测地形上的稳健单足跳跃，成功应对60厘米宽间隙、不规则楼梯和15-35厘米间距的踏石等挑战。

Conclusion: JumpER为极端欠驱动和极端地形下的运动任务提供了可扩展的解决方案。

Abstract: Reinforcement learning (RL) has shown great potential in enabling quadruped
robots to perform agile locomotion. However, directly training policies to
simultaneously handle dual extreme challenges, i.e., extreme underactuation and
extreme terrains, as in monopedal hopping tasks, remains highly challenging due
to unstable early-stage interactions and unreliable reward feedback. To address
this, we propose JumpER (jump-start reinforcement learning via self-evolving
priors), an RL training framework that structures policy learning into multiple
stages of increasing complexity. By dynamically generating self-evolving priors
through iterative bootstrapping of previously learned policies, JumpER
progressively refines and enhances guidance, thereby stabilizing exploration
and policy optimization without relying on external expert priors or
handcrafted reward shaping. Specifically, when integrated with a structured
three-stage curriculum that incrementally evolves action modality, observation
space, and task objective, JumpER enables quadruped robots to achieve robust
monopedal hopping on unpredictable terrains for the first time. Remarkably, the
resulting policy effectively handles challenging scenarios that traditional
methods struggle to conquer, including wide gaps up to 60 cm, irregularly
spaced stairs, and stepping stones with distances varying from 15 cm to 35 cm.
JumpER thus provides a principled and scalable approach for addressing
locomotion tasks under the dual challenges of extreme underactuation and
extreme terrains.

</details>


### [150] [LLM-based Realistic Safety-Critical Driving Video Generation](https://arxiv.org/abs/2507.01264)
*Yongjie Fu,Ruijian Zha,Pei Tian,Xuan Di*

Main category: cs.RO

TL;DR: 提出一种利用大语言模型（LLM）生成驾驶场景代码的框架，结合CARLA模拟器和视频生成技术，用于自动驾驶系统的安全测试。


<details>
  <summary>Details</summary>
Motivation: 设计多样且安全关键的驾驶场景对评估自动驾驶系统至关重要，但手动生成复杂场景效率低。

Method: 利用LLM进行少样本代码生成，自动合成CARLA模拟器中的驾驶场景，并结合视频生成技术提升场景真实性。

Result: 实验表明，该方法能有效生成多样、真实且安全关键的驾驶场景，包括罕见边缘案例。

Conclusion: 该框架为自动驾驶系统的仿真测试提供了高效且可控的工具。

Abstract: Designing diverse and safety-critical driving scenarios is essential for
evaluating autonomous driving systems. In this paper, we propose a novel
framework that leverages Large Language Models (LLMs) for few-shot code
generation to automatically synthesize driving scenarios within the CARLA
simulator, which has flexibility in scenario scripting, efficient code-based
control of traffic participants, and enforcement of realistic physical
dynamics. Given a few example prompts and code samples, the LLM generates
safety-critical scenario scripts that specify the behavior and placement of
traffic participants, with a particular focus on collision events. To bridge
the gap between simulation and real-world appearance, we integrate a video
generation pipeline using Cosmos-Transfer1 with ControlNet, which converts
rendered scenes into realistic driving videos. Our approach enables
controllable scenario generation and facilitates the creation of rare but
critical edge cases, such as pedestrian crossings under occlusion or sudden
vehicle cut-ins. Experimental results demonstrate the effectiveness of our
method in generating a wide range of realistic, diverse, and safety-critical
scenarios, offering a promising tool for simulation-based testing of autonomous
vehicles.

</details>


### [151] [VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process](https://arxiv.org/abs/2507.01284)
*Cristian Gariboldi,Hayato Tokida,Ken Kinjo,Yuki Asada,Alexander Carballo*

Main category: cs.RO

TL;DR: VLAD模型通过将视觉语言模型（VLM）与端到端自动驾驶系统（VAD）结合，提升了自动驾驶的感知、预测和规划能力，减少了31.82%的平均碰撞率。


<details>
  <summary>Details</summary>
Motivation: 利用开源视觉语言模型（如LLaVA、Qwen-VL）的通用知识，增强自动驾驶系统的空间推理能力和透明度。

Method: 采用定制问答数据集对VLM进行微调，生成高级导航指令，并通过VAD处理以指导车辆操作，同时提供自然语言解释。

Result: 在nuScenes数据集上测试，VLAD系统比基线方法减少了31.82%的平均碰撞率。

Conclusion: VLAD为VLM增强的自动驾驶系统设立了新基准，提高了性能和透明度。

Abstract: Recent advancements in open-source Visual Language Models (VLMs) such as
LLaVA, Qwen-VL, and Llama have catalyzed extensive research on their
integration with diverse systems. The internet-scale general knowledge
encapsulated within these models presents significant opportunities for
enhancing autonomous driving perception, prediction, and planning capabilities.
In this paper we propose VLAD, a vision-language autonomous driving model,
which integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end
system. We implement a specialized fine-tuning approach using custom
question-answer datasets designed specifically to improve the spatial reasoning
capabilities of the model. The enhanced VLM generates high-level navigational
commands that VAD subsequently processes to guide vehicle operation.
Additionally, our system produces interpretable natural language explanations
of driving decisions, thereby increasing transparency and trustworthiness of
the traditionally black-box end-to-end architecture. Comprehensive evaluation
on the real-world nuScenes dataset demonstrates that our integrated system
reduces average collision rates by 31.82% compared to baseline methodologies,
establishing a new benchmark for VLM-augmented autonomous driving systems.

</details>


### [152] [LANet: A Lane Boundaries-Aware Approach For Robust Trajectory Prediction](https://arxiv.org/abs/2507.01308)
*Muhammad Atta ur Rahman,Dooseop Choi,KyoungWook Min*

Main category: cs.RO

TL;DR: 提出了一种基于多向量地图元素的运动预测模型，通过融合车道边界和道路边缘等信息，提升自动驾驶车辆对复杂交通场景的预测能力，并通过剪枝机制保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前基于车道中心线的运动预测模型难以全面捕捉道路环境和交通规则，限制了预测准确性。

Method: 开发了一种特征融合策略，结合多种向量地图元素，并引入剪枝机制筛选最相关的地图连接。

Result: 在Argoverse 2数据集上验证了方法的有效性，性能优于现有技术。

Conclusion: 该方法提供了更全面且高效的道路环境表示，推动了自动驾驶运动预测技术的发展。

Abstract: Accurate motion forecasting is critical for safe and efficient autonomous
driving, enabling vehicles to predict future trajectories and make informed
decisions in complex traffic scenarios. Most of the current designs of motion
prediction models are based on the major representation of lane centerlines,
which limits their capability to capture critical road environments and traffic
rules and constraints. In this work, we propose an enhanced motion forecasting
model informed by multiple vector map elements, including lane boundaries and
road edges, that facilitates a richer and more complete representation of
driving environments. An effective feature fusion strategy is developed to
merge information in different vector map components, where the model learns
holistic information on road structures and their interactions with agents.
Since encoding more information about the road environment increases memory
usage and is computationally expensive, we developed an effective pruning
mechanism that filters the most relevant map connections to the target agent,
ensuring computational efficiency while maintaining essential spatial and
semantic relationships for accurate trajectory prediction. Overcoming the
limitations of lane centerline-based models, our method provides a more
informative and efficient representation of the driving environment and
advances the state of the art for autonomous vehicle motion forecasting. We
verify our approach with extensive experiments on the Argoverse 2 motion
forecasting dataset, where our method maintains competitiveness on AV2 while
achieving improved performance.
  Index Terms-Autonomous driving, trajectory prediction, vector map elements,
road topology, connection pruning, Argoverse 2.

</details>


### [153] [Approximation-free Control of Unknown Euler-Lagrangian Systems under Input Constraints](https://arxiv.org/abs/2507.01426)
*Ratnangshu Das,Pushpak Jagtap*

Main category: cs.RO

TL;DR: 提出了一种新型漏斗跟踪控制算法，用于解决未知动态和输入约束的机器人系统问题。


<details>
  <summary>Details</summary>
Motivation: 解决机器人系统在性能与执行器安全性之间的权衡问题，特别是在输入受限的情况下。

Method: 采用欧拉-拉格朗日建模，提出两种无近似控制策略，确保跟踪误差在预设漏斗边界内。

Result: 通过仿真和实验验证了算法的鲁棒性能与安全性。

Conclusion: 该研究显著提升了漏斗控制在现实机器人系统中的应用性。

Abstract: In this paper, we present a novel funnel-based tracking control algorithm for
robotic systems with unknown dynamics and prescribed input constraints. The
Euler-Lagrange formulation, a common modeling approach for robotic systems, has
been adopted in this study to address the trade-off between performance and
actuator safety. We establish feasibility conditions that ensure tracking
errors evolve within predefined funnel bounds while maintaining bounded control
efforts, a crucial consideration for robots with limited actuation
capabilities. We propose two approximation-free control strategies for
scenarios where these conditions are violated: one actively corrects the error,
and the other stops further deviation. Finally, we demonstrate the robust
performance and safety of the approach through simulations and experimental
validations. This work represents a significant advancement in funnel-based
control, enhancing its applicability to real-world robotics systems with input
constraints.

</details>


### [154] [TriVLA: A Unified Triple-System-Based Unified Vision-Language-Action Model for General Robot Control](https://arxiv.org/abs/2507.01424)
*Zhenyang Liu,Yongchong Gu,Sixiao Zheng,Xiangyang Xue,Yanwei Fu*

Main category: cs.RO

TL;DR: TriVLA是一种统一的三系统架构视觉-语言-动作模型，用于通用机器人控制，通过动态感知模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有自回归VLA方法往往忽略动态信息，而动态信息对机器人任务至关重要。

Method: TriVLA采用三系统架构，包括视觉-语言模块、动态感知模块和策略学习模块，结合预训练模型和机器人数据微调。

Result: TriVLA在36 Hz下运行，优于现有模仿学习方法，在仿真和实际任务中表现优异。

Conclusion: TriVLA通过动态感知和统一架构显著提升了机器人控制的性能。

Abstract: Recent advancements in vision-language models (VLMs) for common-sense
reasoning have led to the development of vision-language-action (VLA) models,
enabling robots to perform generalized manipulation. Although existing
autoregressive VLA methods design a specific architecture like dual-system to
leverage large-scale pretrained knowledge, they tend to capture static
information, often neglecting the dynamic aspects vital for embodied tasks. To
this end, we propose TriVLA, a unified Vision-Language-Action model with a
triple-system architecture for general robot control. The vision-language
module (System 2) interprets the environment through vision and language
instructions. The dynamics perception module (System 3) inherently produces
visual representations that encompass both current static information and
predicted future dynamics, thereby providing valuable guidance for policy
learning. TriVLA utilizes pre-trained VLM model and fine-tunes pre-trained
video foundation model on robot datasets along with internet human manipulation
data. The subsequent policy learning module (System 1) generates fluid motor
actions in real time. Experimental evaluation demonstrates that TriVLA operates
at approximately 36 Hz and surpasses state-of-the-art imitation learning
baselines on standard simulation benchmarks as well as challenging real-world
manipulation tasks.

</details>


### [155] [Quantum-Assisted Automatic Path-Planning for Robotic Quality Inspection in Industry 4.0](https://arxiv.org/abs/2507.01462)
*Eneko Osaba,Estibaliz Garrote,Pablo Miranda-Rodriguez,Alessia Ciacco,Itziar Cabanes,Aitziber Mancisidor*

Main category: cs.RO

TL;DR: 研究探讨了混合量子-经典算法在工业环境中优化机器人检测轨迹的应用，与传统方法相比表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算在工业自动化中的潜力，特别是在优化机器人检测轨迹方面。

Method: 将任务建模为3D旅行商问题，使用D-Wave求解器与GUROBI和Google OR-Tools等经典方法对比。

Result: 在五个实际案例中，量子方法在计算时间显著减少的同时保持了解决方案的竞争力。

Conclusion: 量子方法在工业4.0自动化中具有潜在优势。

Abstract: This work explores the application of hybrid quantum-classical algorithms to
optimize robotic inspection trajectories derived from Computer-Aided Design
(CAD) models in industrial settings. By modeling the task as a 3D variant of
the Traveling Salesman Problem, incorporating incomplete graphs and open-route
constraints, this study evaluates the performance of two D-Wave-based solvers
against classical methods such as GUROBI and Google OR-Tools. Results across
five real-world cases demonstrate competitive solution quality with
significantly reduced computation times, highlighting the potential of quantum
approaches in automation under Industry 4.0.

</details>


### [156] [BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments](https://arxiv.org/abs/2507.01485)
*Yibo Qiu,Zan Huang,Zhiyu Wang,Handi Liu,Yiling Qiao,Yifeng Hu,Shu'ang Sun,Hangke Peng,Ronald X Xu,Mingzhai Sun*

Main category: cs.RO

TL;DR: BioMARS是一个结合LLMs、VLMs和模块化机器人的智能平台，用于自主设计、规划和执行生物实验，性能优于人工操作。


<details>
  <summary>Details</summary>
Motivation: 现有语言和视觉模型在生物研究中的应用受限于协议设计僵化、适应性不足、错误处理能力弱和操作复杂。

Method: BioMARS采用分层架构：Biologist Agent通过检索增强生成协议；Technician Agent将其转化为可执行代码；Inspector Agent通过多模态感知确保程序完整性。

Result: 系统在细胞传代和培养任务中表现优于人工，并在视网膜色素上皮细胞分化中超越传统策略。

Conclusion: BioMARS展示了通用AI驱动实验室自动化的可行性，突显了语言推理在生物研究中的变革作用。

Abstract: Large language models (LLMs) and vision-language models (VLMs) have the
potential to transform biological research by enabling autonomous
experimentation. Yet, their application remains constrained by rigid protocol
design, limited adaptability to dynamic lab conditions, inadequate error
handling, and high operational complexity. Here we introduce BioMARS
(Biological Multi-Agent Robotic System), an intelligent platform that
integrates LLMs, VLMs, and modular robotics to autonomously design, plan, and
execute biological experiments. BioMARS uses a hierarchical architecture: the
Biologist Agent synthesizes protocols via retrieval-augmented generation; the
Technician Agent translates them into executable robotic pseudo-code; and the
Inspector Agent ensures procedural integrity through multimodal perception and
anomaly detection. The system autonomously conducts cell passaging and culture
tasks, matching or exceeding manual performance in viability, consistency, and
morphological integrity. It also supports context-aware optimization,
outperforming conventional strategies in differentiating retinal pigment
epithelial cells. A web interface enables real-time human-AI collaboration,
while a modular backend allows scalable integration with laboratory hardware.
These results highlight the feasibility of generalizable, AI-driven laboratory
automation and the transformative role of language-based reasoning in
biological research.

</details>


### [157] [Dynamic System Model Generation for Online Fault Detection and Diagnosis of Robotic Systems](https://arxiv.org/abs/2507.01550)
*Johannes Kohl,Georg Muck,Georg Jäger,Sebastian Zug*

Main category: cs.RO

TL;DR: 提出了一种动态生成系统模型的方法，用于机器人系统的故障检测与诊断，减少对预设模型和历史数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统复杂度的增加，传统故障检测方法因依赖预设模型和历史数据而难以应对动态变化。

Method: 在运行时动态生成系统模型，并利用该模型定位故障根源。

Result: 该方法适用于多种机器人系统，且具有低开销和减少专家依赖的特点。

Conclusion: 提出的方法为动态机器人系统提供了一种高效的故障检测与诊断解决方案。

Abstract: With the rapid development of more complex robots, Fault Detection and
Diagnosis (FDD) becomes increasingly harder. Especially the need for
predetermined models and historic data is problematic because they do not
encompass the dynamic and fast-changing nature of such systems. To this end, we
propose a concept that actively generates a dynamic system model at runtime and
utilizes it to locate root causes. The goal is to be applicable to all kinds of
robotic systems that share a similar software design. Additionally, it should
exhibit minimal overhead and enhance independence from expert attention.

</details>


### [158] [Self-Closing Suction Grippers for Industrial Grasping via Form-Flexible Design](https://arxiv.org/abs/2507.01561)
*Huijiang Wang,Holger Kunz,Timon Adler,Fumiya Iida*

Main category: cs.RO

TL;DR: 提出了一种基于混合堵塞和吸力机制的形变柔性夹持器，用于自适应抓取不同尺寸的物体。


<details>
  <summary>Details</summary>
Motivation: 传统夹持器难以处理尺寸变化大的物体，因此需要一种能自适应形变的夹持器。

Method: 采用混合堵塞和吸力机制，通过被动形变界面实现自适应抓取。

Result: 夹持器能抓取小至其孔径54.5%的物体（如鸡蛋），最大负载质量比为94.3。

Conclusion: 混合夹持器在自适应抓取方面表现出色，适用于工业应用。

Abstract: Shape-morphing robots have shown benefits in industrial grasping. We propose
form-flexible grippers for adaptive grasping. The design is based on the hybrid
jamming and suction mechanism, which deforms to handle objects that vary
significantly in size from the aperture, including both larger and smaller
parts. Compared with traditional grippers, the gripper achieves self-closing to
form an airtight seal. Under a vacuum, a wide range of grasping is realized
through the passive morphing mechanism at the interface that harmonizes
pressure and flow rate. This hybrid gripper showcases the capability to
securely grasp an egg, as small as 54.5% of its aperture, while achieving a
maximum load-to-mass ratio of 94.3.

</details>


### [159] [An RRT* algorithm based on Riemannian metric model for optimal path planning](https://arxiv.org/abs/2507.01697)
*Yu Zhang,Qi Zhou,Xiao-Song Yang*

Main category: cs.RO

TL;DR: 提出了一种基于黎曼度量的模型，用于解决高维空间中二维光滑子流形上的最优路径规划问题，通过构建新的黎曼度量将问题转化为二维平面上的几何问题，并提出了RRT*-R算法。


<details>
  <summary>Details</summary>
Motivation: 解决高维空间中机器人路径规划问题，尤其是在复杂环境下（如高度变化、地面阻力等）的路径优化。

Method: 构建由高维欧几里得度量诱导的二维投影平面上的新黎曼度量，并基于此提出了增量算法RRT*-R。

Result: 实验表明RRT*-R算法在多维不均匀场景中表现优异，能有效避开环境障碍，路径平滑且优化性能优于原始RRT*算法。

Conclusion: RRT*-R算法在二维投影平面上能较好地逼近理论最小测地距离，适用于复杂环境下的机器人路径规划。

Abstract: This paper presents a Riemannian metric-based model to solve the optimal path
planning problem on two-dimensional smooth submanifolds in high-dimensional
space. Our model is based on constructing a new Riemannian metric on a
two-dimensional projection plane, which is induced by the high-dimensional
Euclidean metric on two-dimensional smooth submanifold and reflects the
environmental information of the robot. The optimal path planning problem in
high-dimensional space is therefore transformed into a geometric problem on the
two-dimensional plane with new Riemannian metric. Based on the new Riemannian
metric, we proposed an incremental algorithm RRT*-R on the projection plane.
The experimental results show that the proposed algorithm is suitable for
scenarios with uneven fields in multiple dimensions. The proposed algorithm can
help the robot to effectively avoid areas with drastic changes in height,
ground resistance and other environmental factors. More importantly, the RRT*-R
algorithm shows better smoothness and optimization properties compared with the
original RRT* algorithm using Euclidean distance in high-dimensional workspace.
The length of the entire path by RRT*-R is a good approximation of the
theoretical minimum geodesic distance on projection plane.

</details>


### [160] [Efficient Collision Detection for Long and Slender Robotic Links in Euclidean Distance Fields: Application to a Forestry Crane](https://arxiv.org/abs/2507.01705)
*Marc-Philip Ecker,Bernhard Bischof,Minh Nhat Vu,Christoph Fröhlich,Tobias Glück,Wolfgang Kemmetmüller*

Main category: cs.RO

TL;DR: 提出了一种针对细长机械臂的新型碰撞检测算法，显著提高了运动规划的计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于球体近似的方法在处理细长机械臂时效率低下且不准确。

Method: 设计了一种专门利用机械臂细长结构的碰撞检测算法，无需调整近似精度参数。

Result: 在真实林业起重机LiDAR数据和模拟环境中验证了算法的有效性。

Conclusion: 新算法显著提升了计算效率，适用于复杂户外环境中的运动规划。

Abstract: Collision-free motion planning in complex outdoor environments relies heavily
on perceiving the surroundings through exteroceptive sensors. A widely used
approach represents the environment as a voxelized Euclidean distance field,
where robots are typically approximated by spheres. However, for large-scale
manipulators such as forestry cranes, which feature long and slender links,
this conventional spherical approximation becomes inefficient and inaccurate.
This work presents a novel collision detection algorithm specifically designed
to exploit the elongated structure of such manipulators, significantly
enhancing the computational efficiency of motion planning algorithms. Unlike
traditional sphere decomposition methods, our approach not only improves
computational efficiency but also naturally eliminates the need to fine-tune
the approximation accuracy as an additional parameter. We validate the
algorithm's effectiveness using real-world LiDAR data from a forestry crane
application, as well as simulated environment data.

</details>


### [161] [SE(3)-Equivariant Diffusion Policy in Spherical Fourier Space](https://arxiv.org/abs/2507.01723)
*Xupeng Zhu,Fan Wang,Robin Walters,Jane Shi*

Main category: cs.RO

TL;DR: 提出了一种SE(3)等变的扩散策略（SDP），通过球面傅里叶空间嵌入状态、动作和去噪过程，提升3D场景变换下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在3D空间中物体新排列时泛化能力差，影响实际性能。

Method: 使用球面傅里叶空间嵌入和球面FiLM层，提出球面去噪时间U-net实现时空等变。

Result: 在20个仿真任务和5个物理机器人任务中表现优于基线。

Conclusion: SDP实现了端到端SE(3)等变，显著提升了3D场景变换下的泛化性能。

Abstract: Diffusion Policies are effective at learning closed-loop manipulation
policies from human demonstrations but generalize poorly to novel arrangements
of objects in 3D space, hurting real-world performance. To address this issue,
we propose Spherical Diffusion Policy (SDP), an SE(3) equivariant diffusion
policy that adapts trajectories according to 3D transformations of the scene.
Such equivariance is achieved by embedding the states, actions, and the
denoising process in spherical Fourier space. Additionally, we employ novel
spherical FiLM layers to condition the action denoising process equivariantly
on the scene embeddings. Lastly, we propose a spherical denoising temporal
U-net that achieves spatiotemporal equivariance with computational efficiency.
In the end, SDP is end-to-end SE(3) equivariant, allowing robust generalization
across transformed 3D scenes. SDP demonstrates a large performance improvement
over strong baselines in 20 simulation tasks and 5 physical robot tasks
including single-arm and bi-manual embodiments. Code is available at
https://github.com/amazon-science/Spherical_Diffusion_Policy.

</details>


### [162] [Augmented Bridge Spinal Fixation: A New Concept for Addressing Pedicle Screw Pullout via a Steerable Drilling Robot and Flexible Pedicle Screws](https://arxiv.org/abs/2507.01753)
*Yash Kulkarni,Susheela Sharma,Omid Rezayof,Siddhartha Kapuria,Jordan P. Amadio,Mohsen Khadem,Maryam Tilton,Farshid Alambeigi*

Main category: cs.RO

TL;DR: 提出了一种增强桥接脊柱固定（AB-SF）技术，结合柔性椎弓根螺钉和机器人钻孔系统，以解决传统刚性螺钉的松动和拔出问题。


<details>
  <summary>Details</summary>
Motivation: 传统刚性椎弓根螺钉在脊柱固定中存在松动和拔出的局限性，需要一种更可靠的技术。

Method: 使用同心管可转向钻孔机器人（CT-SDR）在椎弓根中钻出J形隧道，植入柔性椎弓根螺钉（FPS）并通过其注入骨水泥形成增强桥接。

Result: 实验成功模拟了AB-SF技术，包括钻孔、螺钉植入和骨水泥增强过程。

Conclusion: AB-SF技术具有可行性，有望解决传统脊柱固定中的问题。

Abstract: To address the screw loosening and pullout limitations of rigid pedicle
screws in spinal fixation procedures, and to leverage our recently developed
Concentric Tube Steerable Drilling Robot (CT-SDR) and Flexible Pedicle Screw
(FPS), in this paper, we introduce the concept of Augmented Bridge Spinal
Fixation (AB-SF). In this concept, two connecting J-shape tunnels are first
drilled through pedicles of vertebra using the CT-SDR. Next, two FPSs are
passed through this tunnel and bone cement is then injected through the
cannulated region of the FPS to form an augmented bridge between two pedicles
and reinforce strength of the fixated spine. To experimentally analyze and
study the feasibility of AB-SF technique, we first used our robotic system
(i.e., a CT-SDR integrated with a robotic arm) to create two different fixation
scenarios in which two J-shape tunnels, forming a bridge, were drilled at
different depth of a vertebral phantom. Next, we implanted two FPSs within the
drilled tunnels and then successfully simulated the bone cement augmentation
process.

</details>


### [163] [S3D: A Spatial Steerable Surgical Drilling Framework for Robotic Spinal Fixation Procedures](https://arxiv.org/abs/2507.01779)
*Daniyal Maroufi,Xinyuan Huang,Yash Kulkarni,Omid Rezayof,Susheela Sharma,Vaibhav Goggela,Jordan P. Amadio,Mohsen Khadem,Farshid Alambeigi*

Main category: cs.RO

TL;DR: S3D是一个空间可转向的钻孔框架，用于机器人脊柱固定手术，结合了同心管可转向钻孔机器人和七自由度机械臂，实现了真实的钻孔操作。


<details>
  <summary>Details</summary>
Motivation: 解决脊柱固定手术中因解剖结构限制导致的钻孔难题，提升手术的精准性和安全性。

Method: 改进了同心管可转向钻孔机器人（CT-SDR），提出四阶段校准、配准和导航流程，结合七自由度机械臂进行实验验证。

Result: 在脊柱模型上验证了平面和非平面可转向钻孔的功能性。

Conclusion: S3D框架能够有效支持脊柱固定手术中的真实钻孔操作，具有临床应用潜力。

Abstract: In this paper, we introduce S3D: A Spatial Steerable Surgical Drilling
Framework for Robotic Spinal Fixation Procedures. S3D is designed to enable
realistic steerable drilling while accounting for the anatomical constraints
associated with vertebral access in spinal fixation (SF) procedures. To achieve
this, we first enhanced our previously designed concentric tube Steerable
Drilling Robot (CT-SDR) to facilitate steerable drilling across all vertebral
levels of the spinal column. Additionally, we propose a four-Phase calibration,
registration, and navigation procedure to perform realistic SF procedures on a
spine holder phantom by integrating the CT-SDR with a seven-degree-of-freedom
robotic manipulator. The functionality of this framework is validated through
planar and out-of-plane steerable drilling experiments in vertebral phantoms.

</details>


### [164] [Towards Design and Development of a Concentric Tube Steerable Drilling Robot for Creating S-shape Tunnels for Pelvic Fixation Procedures](https://arxiv.org/abs/2507.01811)
*Yash Kulkarni,Susheela Sharma,Sarah Go,Jordan P. Amadio,Mohsen Khadem,Farshid Alambeigi*

Main category: cs.RO

TL;DR: 提出了一种新型4自由度骨盆同心管可转向钻孔机器人（pelvic CT-SDR），用于解决传统刚性钻孔工具在骨盆固定中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统刚性钻孔工具限制了螺钉在复杂骨盆解剖结构中的最优路径放置，导致螺钉错位、手术时间延长和辐射暴露增加。

Method: 设计并开发了一种4自由度的骨盆同心管可转向钻孔机器人，能够实现S形钻孔轨迹。

Result: 在模拟骨模型中进行了多次S形钻孔实验，验证了该机器人的性能。

Conclusion: 该机器人能够实现更符合骨盆自然解剖结构的钻孔路径，有望减少手术并发症。

Abstract: Current pelvic fixation techniques rely on rigid drilling tools, which
inherently constrain the placement of rigid medical screws in the complex
anatomy of pelvis. These constraints prevent medical screws from following
anatomically optimal pathways and force clinicians to fixate screws in linear
trajectories. This suboptimal approach, combined with the unnatural placement
of the excessively long screws, lead to complications such as screw
misplacement, extended surgery times, and increased radiation exposure due to
repeated X-ray images taken ensure to safety of procedure. To address these
challenges, in this paper, we present the design and development of a unique 4
degree-of-freedom (DoF) pelvic concentric tube steerable drilling robot (pelvic
CT-SDR). The pelvic CT-SDR is capable of creating long S-shaped drilling
trajectories that follow the natural curvatures of the pelvic anatomy. The
performance of the pelvic CT-SDR was thoroughly evaluated through several
S-shape drilling experiments in simulated bone phantoms.

</details>


### [165] [MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics](https://arxiv.org/abs/2507.01843)
*Dmytro Kuzmenko,Nadiya Shvai*

Main category: cs.RO

TL;DR: MoIRA是一个模块化的Mixture-of-Experts框架，通过外部文本路由协调专家模型，提供零样本路由选项，并在机器人任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决传统MoE框架中无法选择性定制低级专家和路由器的限制，减少额外训练需求。

Method: 提出MoIRA框架，采用嵌入相似性和提示驱动的语言模型推理两种零样本路由方式，结合低秩适配器进行低开销推理。

Result: 在GR1 Humanoid和LIBERO基准测试中表现优于通用模型，并与其他MoE框架竞争。

Conclusion: MoIRA展示了模块化部署的可行性，为未来多专家机器人系统提供了可扩展的基础。

Abstract: Mixture-of-Experts (MoE) approaches have recently gained traction in robotics
applications due to their ability to dynamically allocate computational
resources and specialize sub-networks for distinct tasks or environmental
contexts, enabling more efficient decision-making. Such systems often comprise
sparsely activated experts combined under a single monolithic architecture and
require a well-configured internal routing mechanism, which does not allow for
selective low-level expert and router customization and requires additional
training. We propose MoIRA, an architecture-agnostic modular MoE framework
designed to coordinate existing experts with an external text-based router.
MoIRA incorporates two zero-shot routing options: embedding-based similarity
and prompt-driven language model inference. In our experiments, we choose large
Vision-Language-Action models, gr00t-N1 and $\pi_0$, as the underlying experts,
and train low-rank adapters for low-overhead inference. We evaluate MoIRA on
various GR1 Humanoid tasks and LIBERO Spatial and Goal benchmarks, where it
consistently outperforms generalist models and competes with other MoE
pipelines. Additionally, we analyse the robustness of the proposed approach to
the variations of the instructions. While relying solely on textual
descriptions of tasks and experts, MoIRA demonstrates the practical viability
of modular deployment with precise, low-effort routing and provides an
alternative, scalable foundation for future multi-expert robotic systems.

</details>


### [166] [TypeTele: Releasing Dexterity in Teleoperation by Dexterous Manipulation Types](https://arxiv.org/abs/2507.01857)
*Yuhao Lin,Yi-Lin Wei,Haoran Liao,Mu Lin,Chengyi Xing,Hao Li,Dandan Zhang,Mark Cutkosky,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: 提出TypeTele系统，通过引入灵巧操作类型库和MLLM辅助检索模块，使灵巧手能够执行不受人类动作模式限制的任务，显著提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统灵巧遥操作依赖手部重定向模仿人类动作，未能充分利用灵巧手的结构优势。

Method: 提出TypeTele系统，结合灵巧操作类型库和MLLM辅助检索模块，支持任务导向的灵巧操作。

Result: 实验表明，引入操作类型显著提升了灵巧手执行复杂任务的多样性和成功率。

Conclusion: TypeTele系统通过类型引导的遥操作，充分发挥了灵巧手的潜力，适用于多样化任务。

Abstract: Dexterous teleoperation plays a crucial role in robotic manipulation for
real-world data collection and remote robot control. Previous dexterous
teleoperation mostly relies on hand retargeting to closely mimic human hand
postures. However, these approaches may fail to fully leverage the inherent
dexterity of dexterous hands, which can execute unique actions through their
structural advantages compared to human hands. To address this limitation, we
propose TypeTele, a type-guided dexterous teleoperation system, which enables
dexterous hands to perform actions that are not constrained by human motion
patterns. This is achieved by introducing dexterous manipulation types into the
teleoperation system, allowing operators to employ appropriate types to
complete specific tasks. To support this system, we build an extensible
dexterous manipulation type library to cover comprehensive dexterous postures
used in manipulation tasks. During teleoperation, we employ a MLLM
(Multi-modality Large Language Model)-assisted type retrieval module to
identify the most suitable manipulation type based on the specific task and
operator commands. Extensive experiments of real-world teleoperation and
imitation learning demonstrate that the incorporation of manipulation types
significantly takes full advantage of the dexterous robot's ability to perform
diverse and complex tasks with higher success rates.

</details>


### [167] [A Survey on Vision-Language-Action Models: An Action Tokenization Perspective](https://arxiv.org/abs/2507.01925)
*Yifan Zhong,Fengshuo Bai,Shaofei Cai,Xuchuan Huang,Zhang Chen,Xiaowei Zhang,Yuanfei Wang,Shaoyang Guo,Tianrui Guan,Ka Nam Lui,Zhiquan Qi,Yitao Liang,Yuanpei Chen,Yaodong Yang*

Main category: cs.RO

TL;DR: 本文提出了一种统一框架，将现有的视觉-语言-动作（VLA）模型归类为基于动作令牌的设计，并分析了不同令牌类型的优缺点，旨在推动VLA模型的未来发展。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型的设计缺乏对动作令牌的全面理解，阻碍了有效开发和未来方向。本文旨在填补这一空白。

Method: 通过系统综述和分析，将VLA模型归类为基于动作令牌的框架，并比较不同令牌类型的优缺点。

Result: 总结了现有VLA研究的分类和局限性，并提出了改进方向。

Conclusion: 本文为VLA模型的未来发展提供了指导，并指出了潜在的研究方向。

Abstract: The remarkable advancements of vision and language foundation models in
multimodal understanding, reasoning, and generation has sparked growing efforts
to extend such intelligence to the physical world, fueling the flourishing of
vision-language-action (VLA) models. Despite seemingly diverse approaches, we
observe that current VLA models can be unified under a single framework: vision
and language inputs are processed by a series of VLA modules, producing a chain
of \textit{action tokens} that progressively encode more grounded and
actionable information, ultimately generating executable actions. We further
determine that the primary design choice distinguishing VLA models lies in how
action tokens are formulated, which can be categorized into language
description, code, affordance, trajectory, goal state, latent representation,
raw action, and reasoning. However, there remains a lack of comprehensive
understanding regarding action tokens, significantly impeding effective VLA
development and obscuring future directions. Therefore, this survey aims to
categorize and interpret existing VLA research through the lens of action
tokenization, distill the strengths and limitations of each token type, and
identify areas for improvement. Through this systematic review and analysis, we
offer a synthesized outlook on the broader evolution of VLA models, highlight
underexplored yet promising directions, and contribute guidance for future
research, hoping to bring the field closer to general-purpose intelligence.

</details>


### [168] [Large Language Model-Driven Closed-Loop UAV Operation with Semantic Observations](https://arxiv.org/abs/2507.01930)
*Wenhao Wang,Yanyan Li,Long Jiao,Jiawei Yuan*

Main category: cs.RO

TL;DR: 提出了一种基于LLM的闭环控制框架，通过代码生成器和评估器模块实现可靠的无人机操作，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在无人机操作中逻辑推理和复杂决策的可靠性问题。

Method: 采用闭环控制框架，将无人机状态转化为自然语言描述，并通过模拟优化代码执行。

Result: 实验表明，该框架在任务复杂度增加时，成功率和完整性显著优于基线方法。

Conclusion: 该框架为LLM驱动的无人机操作提供了可靠解决方案。

Abstract: Large Language Models (LLMs) have revolutionized robotic autonomy, including
Unmanned Aerial Vehicles (UAVs). Recent studies have demonstrated the potential
of LLMs for translating human instructions into executable control code for UAV
operations. However, LLMs still face challenges from logical reasoning and
complex decision-making, leading to concerns about the reliability of
LLM-driven UAV operations. In this paper, we propose a LLM-driven closed-loop
control framework that enables reliable UAV operations powered by effective
feedback and refinement using two LLM modules, i.e., a Code Generator and an
Evaluator. Our framework transforms numerical state observations from UAV
operations into natural language trajectory descriptions to enhance the
evaluator LLM's understanding of UAV dynamics for precise feedback generation.
Our framework also enables a simulation-based refinement process, and hence
eliminates the risks to physical UAVs caused by incorrect code execution during
the refinement. Extensive experiments on UAV control tasks with different
complexities are conducted. The experimental results show that our framework
can achieve reliable UAV operations using LLMs, which significantly outperforms
baseline approaches in terms of success rate and completeness with the increase
of task complexity.

</details>


### [169] [AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation](https://arxiv.org/abs/2507.01961)
*Sixiang Chen,Jiaming Liu,Siyuan Qian,Han Jiang,Lily Li,Renrui Zhang,Zhuoyang Liu,Chenyang Gu,Chengkai Hou,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 论文提出了一种名为AC-DiT的自适应协调扩散Transformer方法，用于改进移动底座和机械臂的协调控制，并通过动态调整2D和3D视觉输入的融合权重来满足不同阶段的多模态感知需求。


<details>
  <summary>Details</summary>
Motivation: 现有方法在移动底座和机械臂的协调控制中存在不足，未能明确建模移动底座对机械臂控制的影响，且忽视了不同阶段的多模态感知需求。

Method: 提出AC-DiT方法，包括移动底座到机械臂的条件机制和感知感知的多模态条件策略，动态调整2D和3D输入的融合权重。

Result: 在仿真和真实世界的移动操作任务中进行了广泛实验验证，证明了AC-DiT的有效性。

Conclusion: AC-DiT通过改进协调控制和多模态感知，显著提升了移动操作任务的性能。

Abstract: Recently, mobile manipulation has attracted increasing attention for enabling
language-conditioned robotic control in household tasks. However, existing
methods still face challenges in coordinating mobile base and manipulator,
primarily due to two limitations. On the one hand, they fail to explicitly
model the influence of the mobile base on manipulator control, which easily
leads to error accumulation under high degrees of freedom. On the other hand,
they treat the entire mobile manipulation process with the same visual
observation modality (e.g., either all 2D or all 3D), overlooking the distinct
multimodal perception requirements at different stages during mobile
manipulation. To address this, we propose the Adaptive Coordination Diffusion
Transformer (AC-DiT), which enhances mobile base and manipulator coordination
for end-to-end mobile manipulation. First, since the motion of the mobile base
directly influences the manipulator's actions, we introduce a mobility-to-body
conditioning mechanism that guides the model to first extract base motion
representations, which are then used as context prior for predicting whole-body
actions. This enables whole-body control that accounts for the potential impact
of the mobile base's motion. Second, to meet the perception requirements at
different stages of mobile manipulation, we design a perception-aware
multimodal conditioning strategy that dynamically adjusts the fusion weights
between various 2D visual images and 3D point clouds, yielding visual features
tailored to the current perceptual needs. This allows the model to, for
example, adaptively rely more on 2D inputs when semantic information is crucial
for action prediction, while placing greater emphasis on 3D geometric
information when precise spatial understanding is required. We validate AC-DiT
through extensive experiments on both simulated and real-world mobile
manipulation tasks.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [170] [Imitation Learning for Satellite Attitude Control under Unknown Perturbations](https://arxiv.org/abs/2507.01161)
*Zhizhuo Zhang,Hao Peng,Xiaoli Bai*

Main category: eess.SY

TL;DR: 提出了一种结合SAC强化学习和GAIL模仿学习的卫星姿态控制框架，提高了对未知扰动的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统控制方法依赖精确模型且对扰动敏感，需改进。

Method: 先开发SAC专家控制器，再用GAIL训练模仿策略。

Result: SAC专家在多种扰动下表现优异，GAIL学习者能有效模仿专家轨迹。

Conclusion: SAC与GAIL结合降低了样本复杂度，提升了自主控制能力。

Abstract: This paper presents a novel satellite attitude control framework that
integrates Soft Actor-Critic (SAC) reinforcement learning with Generative
Adversarial Imitation Learning (GAIL) to achieve robust performance under
various unknown perturbations. Traditional control techniques often rely on
precise system models and are sensitive to parameter uncertainties and external
perturbations. To overcome these limitations, we first develop a SAC-based
expert controller that demonstrates improved resilience against actuator
failures, sensor noise, and attitude misalignments, outperforming our previous
results in several challenging scenarios. We then use GAIL to train a learner
policy that imitates the expert's trajectories, thereby reducing training costs
and improving generalization through expert demonstrations. Preliminary
experiments under single and combined perturbations show that the SAC expert
can rotate the antenna to a specified direction and keep the antenna
orientation reliably stable in most of the listed perturbations. Additionally,
the GAIL learner can imitate most of the features from the trajectories
generated by the SAC expert. Comparative evaluations and ablation studies
confirm the effectiveness of the SAC algorithm and reward shaping. The
integration of GAIL further reduces sample complexity and demonstrates
promising imitation capabilities, paving the way for more intelligent and
autonomous spacecraft control systems.

</details>


### [171] [An Adaptive Estimation Approach based on Fisher Information to Overcome the Challenges of LFP Battery SOC Estimation](https://arxiv.org/abs/2507.01173)
*Junzhe Shi,Shida Jiang,Shengyu Tao,Jaewong Lee,Manashita Borah,Scott Moura*

Main category: eess.SY

TL;DR: 提出了一种自适应估计方法，结合库仑计数和等效电路模型，解决了LFP电池SOC估计的挑战，并在多种实际场景中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: LFP电池因其安全性和长寿命广泛应用于电动汽车和储能系统，但其平坦的OCV-SOC曲线和滞后效应使得SOC估计困难。

Method: 采用自适应Fisher信息融合策略，结合库仑计数和等效电路模型的SOC估计，并构建3D OCV-H-SOC映射作为基础。

Result: 在多种实际场景（如SOC-OCV平坦区、电流偏置、低温等）中验证，优于现有方法（如无迹卡尔曼滤波、LSTM和Transformer）。

Conclusion: 该方法在LFP电池SOC估计中表现出鲁棒性和实时性，适用于复杂实际条件。

Abstract: Robust and Real-time State of Charge (SOC) estimation is essential for
Lithium Iron Phosphate (LFP) batteries, which are widely used in electric
vehicles (EVs) and energy storage systems due to safety and longevity. However,
the flat Open Circuit Voltage (OCV)-SOC curve makes this task particularly
challenging. This challenge is complicated by hysteresis effects, and
real-world conditions such as current bias, voltage quantization errors, and
temperature that must be considered in the battery management system use. In
this paper, we proposed an adaptive estimation approach to overcome the
challenges of LFPSOC estimation. Specifically, the method uses an adaptive
fisher information fusion strategy that adaptively combines the SOC estimation
from two different models, which are Coulomb counting and equivalent circuit
model-based parameter identification. The effectiveness of this strategy is
rationalized by the information richness excited by external cycling signals. A
3D OCV-H-SOC map that captures the relationship between OCV, hysteresis, and
SOC was proposed as the backbone, and can be generalizable to other widely
adopted parameter-identification methods. Extensive validation under ideal and
real-world use scenarios, including SOC-OCV flat zones, current bias, voltage
quantization errors, low temperatures, and insufficient current excitations,
have been performed using 4 driving profiles, i.e., the Orange County Transit
Bus Cycle, the California Unified Cycle, the US06 Drive Cycle, and the New York
City Cycle, where the results demonstrate superiority over the state-of-the-art
unscented Kalman filter, long short-term memory networks and transformer in all
validation cases.

</details>


### [172] [A Spectral-Based Tuning Criterion for PI Controllers in IPDT Systems With Unified Tracking and Disturbance Rejection Performance](https://arxiv.org/abs/2507.01197)
*Dhamdhawach Horsuwan*

Main category: eess.SY

TL;DR: 提出了一种基于频谱的PI控制器调谐方法，针对IPDT系统，通过最小化闭环系统的频谱横坐标实现统一的指数衰减。


<details>
  <summary>Details</summary>
Motivation: 解决IPDT系统中PI控制器调谐问题，避免启发式权衡或权重参数的需求。

Method: 使用二阶半离散模型捕捉积分器和延迟动态，通过Newton-Raphson迭代优化连续时间极点。

Result: 相比传统方法（如Ziegler-Nichols、SIMC），实现了更快的收敛和更高的鲁棒性。

Conclusion: 该方法为延迟主导系统提供了一种透明且计算高效的PI控制框架。

Abstract: This paper proposes a spectral-based tuning method for proportional-integral
(PI) controllers in integrating-plus-dead-time (IPDT) systems. The design
objective is to achieve unified exponential decay for both reference tracking
and disturbance rejection by minimizing the spectral abscissa of the
closed-loop system. A second-order semi-discrete model accurately captures the
integrator and delay dynamics while enabling efficient dominant pole
extraction. These discrete-time poles are mapped to continuous time and refined
using Newton-Raphson iterations on the exact transcendental characteristic
equation. The method produces a unique PI gain set without requiring heuristic
trade-offs or weighting parameters. Comparative simulations demonstrate that
the proposed tuning achieves faster convergence and improved robustness margins
compared to classical rules (Ziegler-Nichols, SIMC) and integral performance
criteria (IAE, ITAE). The approach provides a transparent and computationally
efficient framework for PI control in delay-dominant systems.

</details>


### [173] [Teaching Cars to Drive: Spotlight on Connected and Automated Vehicles](https://arxiv.org/abs/2507.01211)
*Filippos N. Tzortzoglou,Andreas A. Malikopoulos*

Main category: eess.SY

TL;DR: 本文探讨了新兴移动系统（如CAVs）的现状、潜力与挑战，并介绍了相关研究中的实际问题及解决方案，最后提供了基于运动学原理的CAV建模入门教程。


<details>
  <summary>Details</summary>
Motivation: 研究新兴移动系统（如CAVs）对安全、污染、舒适性等方面的影响，并解决其在实际应用中的挑战。

Method: 分析CAVs的现状与潜力，讨论研究中的实际问题（如模拟与测试），并提出解决方案；提供基于运动学的建模教程。

Result: 总结了CAVs的潜力与挑战，提出了解决研究难题的方法，并提供了开源教程。

Conclusion: CAVs在移动系统中具有巨大潜力，但仍需解决实际研究中的挑战；开源教程有助于初学者入门。

Abstract: In recent decades, society has witnessed significant advancements in emerging
mobility systems. These systems refer to transportation solutions that
incorporate digital technologies, automation, connectivity, and sustainability
to create safer, more efficient, and user-centered mobility. Examples include
connected and automated vehicles (CAVs), shared mobility services
(car-pooling), electric vehicles, and mobility-as-a-service platforms. These
innovations have the potential to greatly impact areas such as safety,
pollution, comfort, travel time, and fairness. In this article, we explore the
current landscape of CAVs. We discuss their role in daily life and their future
potential, while also addressing the challenges they may introduce. Following,
we also examine the practical difficulties in research associated with CAVs
especially simulating and testing CAV-related algorithms in real-world
settings. We present existing solutions that aim to overcome these limitations.
Finally, we provide an accessible introduction to modeling CAVs using basic
kinematic principles and offer an open-source tutorial to help interested
students begin exploring the field.

</details>


### [174] [Tunnelling Through Time Series: A Probabilistic Visibility Graph for Local and Global Pattern Discovery](https://arxiv.org/abs/2507.01247)
*Roberto Sotero,Jose Sanchez-Bornot*

Main category: eess.SY

TL;DR: 论文提出了一种基于量子隧穿现象的Probabilistic Visibility Graph (PVG)方法，用于捕捉时间序列数据的局部和全局模式，并在模拟信号和脑电数据分析中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 高分辨率、长期时间序列数据的增多需要能够同时捕捉局部和全局模式的方法。

Method: PVG扩展了经典的Visibility Graph (VG)，通过引入概率连接来解决VG中因中间值遮挡而无法捕捉长程依赖的问题。

Result: PVG在休息和麻醉条件下的脑电数据中表现出不同的网络特性，休息状态下的小世界性和无标度行为更强，反映了集中化的连接结构。

Conclusion: PVG为分析具有交互时间尺度的复杂信号提供了新工具，有助于理解神经动力学和其他现实现象。

Abstract: The growing availability of high-resolution, long-term time series data has
highlighted the need for methods capable of capturing both local and global
patterns. To address this, we introduce the Probabilistic Visibility Graph
(PVG), a novel approach inspired by the quantum tunnelling phenomenon. The PVG
extends the classical Visibility Graph (VG) by introducing probabilistic
connections between time points that are obstructed in the VG due to
intermediate values. We demonstrate the PVG's effectiveness in capturing
long-range dependencies through simulations of amplitude-modulated signals and
analysis of electrocorticography (ECoG) data under rest and anesthesia
conditions. Key results show that the PVG presents distinct network properties
between rest and anesthesia, with rest exhibiting stronger small-worldness and
scale-free behavior, reflecting a hub-dominated, centralized connectivity
structure, compared to anesthesia. These findings highlight the PVG's potential
for analyzing complex signals with interacting temporal scales, offering new
insights into neural dynamics and other real-world phenomena.

</details>


### [175] [Synchronising DER inverters to weak grid using Kalman filter and LQR current controller](https://arxiv.org/abs/2507.01300)
*Phuoc Sang Nguyen,Ghavameddin Nourbakhsh,Gerard Ledwich*

Main category: eess.SY

TL;DR: 提出了一种基于卡尔曼滤波和LQR控制器的GFL逆变器改进方法，替代PLL，提高弱电网下的稳定性和精度。


<details>
  <summary>Details</summary>
Motivation: GFL逆变器在弱电网中因PLL的相位角估计不准确可能导致不稳定，需改进。

Method: 使用卡尔曼滤波结合LQR控制器，通过状态空间模型估计相位角，并调节电容电压和电流。

Result: 在双源案例中验证了稳定性，并在阻抗突变时表现出更高的精度和失真减少。

Conclusion: 该方法显著提高了振荡抑制能力，优于现有研究。

Abstract: Grid-following (GFL) inverters are commonly used for integrating renewable
energy sources into power grids. However, the dynamic performance of GFL models
can be significantly impacted by the Phase-Locked Loop (PLL) in a weak grid,
leading to instability due to inaccuracies in grid source phase angle
estimation. The proposed method in this manuscript replaces the PLL with an
Advanced Angle Estimation based Kalman Filter including a Linear Quadratic
Regulator (LQR) controller of the GFL. This method is robust in incorporating
grid impedance terms as part of state space models in the Kalman Filter
approach to estimate instantaneous phase angle using {\alpha}-\b{eta}
Synchronous Reference Frame equations. The stability performance of the
proposed approach is validated through eigenvalue analysis in a two-source
case. Additionally, an LQR controller is employed to regulate capacitor
voltage, inverter current, and the current at the Point of Common Coupling
(PCC). The proposed controller surpasses existing approaches in terms of
accuracy and distortion reduction under abrupt grid impedance increases.
Moreover, drop compensation is integrated into the Kalman Filter to enhance
robustness of the inverter against external oscillation disturbances from a
synchronous machine connected to the GFL via the PCC. The results in this paper
demonstrate substantial improvement in oscillation damping across a range of
frequencies compared with published research works.

</details>


### [176] [Cooperative Target Capture in 3D Engagements over Switched Dynamic Graphs](https://arxiv.org/abs/2507.01350)
*Abhinav Sinha,Shashi Ranjan Kumar*

Main category: eess.SY

TL;DR: 提出一种无领导者的协同制导策略，用于在动态切换网络下实现拦截器对静止目标的同步时间约束拦截。


<details>
  <summary>Details</summary>
Motivation: 解决拦截器缺乏径向加速能力时，仅依赖横向加速的3D耦合交战问题，并优化时间估计不确定性。

Method: 通过瞬时优化问题解析推导横向加速分量，结合动态图信息交换，确保时间一致性。

Result: 仿真验证了策略的有效性，确保在预设时间内达成时间一致性。

Conclusion: 该策略在复杂3D交战和动态网络中表现出鲁棒性和高效性。

Abstract: This paper presents a leaderless cooperative guidance strategy for
simultaneous time-constrained interception of a stationary target when the
interceptors exchange information over switched dynamic graphs. We specifically
focus on scenarios when the interceptors lack radial acceleration capabilities,
relying solely on their lateral acceleration components. This consideration
aligns with their inherent kinematic turn constraints. The proposed strategy
explicitly addresses the complexities of coupled 3D engagements, thereby
mitigating performance degradation that typically arises when the pitch and yaw
channels are decoupled into two separate, mutually orthogonal planar
engagements. Moreover, our formulation incorporates modeling uncertainties
associated with the time-to-go estimation into the derivation of cooperative
guidance commands to ensure robustness against inaccuracies in dynamic
engagement scenarios. To optimize control efficiency, we analytically derive
the lateral acceleration components in the orthogonal pitch and yaw channels by
solving an instantaneous optimization problem, subject to an affine constraint.
We show that the proposed cooperative guidance commands guarantee consensus in
time-to-go values within a predefined time, which can be prescribed as a design
parameter, regardless of the interceptors' initial configurations. We provide
simulations to attest to the efficacy of the proposed method.

</details>


### [177] [Multi-Revolution Low-Thrust Trajectory Optimization With Very Sparse Mesh Pseudospectral Method](https://arxiv.org/abs/2507.01450)
*Yilin Zou,Fanghua Jiang*

Main category: eess.SY

TL;DR: 提出了一种高效、精确且广泛适用的伪谱方法，用于解决多圈低推力轨迹优化问题。


<details>
  <summary>Details</summary>
Motivation: 多圈低推力轨迹优化问题在空间任务设计中具有重要意义和挑战性。

Method: 基于Sundman变换和伪谱方法，结合单调、近均匀分布且均匀散布在单位圆上的稀疏网格。提出了两种网格构造方法：基于旋转映射的确定性方法和利用自相关随机序列的随机方法。

Result: 该方法在具有挑战性的多圈低推力轨道交会问题中表现出高精度，计算时间仅需几秒。

Conclusion: 所提出的方法高效、准确且适用性广，适用于多种目标函数和扰动情况。

Abstract: Multi-revolution low-thrust trajectory optimization problems are important
and challenging in space mission design. In this paper, an efficient, accurate,
and widely applicable pseudospectral method is proposed to solve
multi-revolution low-thrust trajectory optimization problems with various
objective functions and perturbations. The method is based on the Sundman
transformation and pseudospectral method, together with a sparse mesh that is
monotonic, near-uniformly spaced, and uniformly scattered on the unit circle.
Two methods are proposed to construct the mesh: a deterministic method based on
rotation mapping; a stochastic method utilizing autocorrelated random
sequences. Core mechanisms ensuring the correctness of the method are analyzed,
including the dual roles of mesh points as both integration points in the
temporal domain and sampling points in the angular domain, the slow dynamics of
the system excluding the fast angle variable, and the nearly commutative vector
fields generated by applying different control inputs. The method is
demonstrated through a multi-revolution low-thrust orbital rendezvous problem.
Results show that the proposed method achieves high accuracy with only a few
seconds of computational time for challenging problems.

</details>


### [178] [Robust Input Shaping Control for Flexible Structures Based on Unscented Kalman Filter](https://arxiv.org/abs/2507.01460)
*Weiyi Yang,Yu Yuan,Mingsheng Shang*

Main category: eess.SY

TL;DR: 本文提出了一种基于无迹卡尔曼滤波的零振动导数输入整形（UZS）方法，用于抑制柔性结构和欠驱动系统中的残余振动，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 工业自动化和智能制造中，柔性结构和欠驱动系统的振动问题影响效率和结构完整性，传统输入整形技术因参数不准确和环境干扰性能下降。

Method: 结合无迹卡尔曼滤波实时识别系统参数和零振动导数输入整形器抑制振动，实验验证于垂直柔性梁平台。

Result: 实验结果显示UZS方法显著优于现有技术，数据集已公开。

Conclusion: UZS在工业自动化、机器人和精密工程中具有实际应用潜力。

Abstract: With the rapid development of industrial automation and smart manufacturing,
the control of flexible structures and underactuated systems has become a
critical research focus. Residual vibrations in these systems not only degrade
operational efficiency but also pose risks to structural integrity and
longevity. Traditional input shaping techniques, while effective, often suffer
from performance degradation due to parameter inaccuracies and environmental
disturbances. To address these challenges, this paper introduces an innovative
unscented Kalman filter-based zero vibration derivative input shaping (UZS)
method. The proposed approach combines two key innovations: 1) a data-driven
Unscented Kalman Filterfor real-time system parameter identification, and 2) a
zero-vibration derivative (ZVD) input shaper for robust vibration suppression.
To validate the effectiveness of UZS, we conducted extensive experiments on a
vertical flexible beam platform, and the results demonstrate significant
improvements over state-of-the-art methods. Additionally, we have made the
experimental datasets publicly available to facilitate further research. The
findings highlight UZS's potential for practical applications in industrial
automation, robotics, and precision engineering.

</details>


### [179] [Frequency Domain Design of a Reset-Based Filter: An Add-On Nonlinear Filter for Industrial Motion Control](https://arxiv.org/abs/2507.01491)
*S. Ali Hosseini,Fabian R. Quinten,Luke F. van Eijk,Dragan Kostic,S. Hassan HosseinNia*

Main category: eess.SY

TL;DR: 论文提出了一种改进的CgLp滤波器，通过引入前馈项减少非线性，实现全频段增益稳定，并提出了一种参数计算方法和附加滤波器结构，提升了控制性能。


<details>
  <summary>Details</summary>
Motivation: 传统CgLp滤波器存在非线性问题，影响控制性能，需改进以提升稳定性和适应性。

Method: 引入前馈项到FORE中，提出反向计算参数方法，设计附加滤波器结构，并提出灵敏度改进指标。

Result: 改进后的滤波器在工业案例中有效减少了低频振动，提升了控制性能。

Conclusion: 该方法显著改善了滤波器的性能，适用于工业控制系统。

Abstract: This study introduces a modified version of the Constant-in-Gain,
Lead-in-Phase (CgLp) filter, which incorporates a feedthrough term in the
First-Order Reset Element (FORE) to reduce the undesirable nonlinearities and
achieve an almost constant gain across all frequencies. A backward calculation
approach is proposed to derive the additional parameter introduced by the
feedthrough term, enabling designers to easily tune the filter to generate the
required phase. The paper also presents an add-on filter structure that can
enhance the performance of an existing LTI controller without altering its
robustness margins. A sensitivity improvement indicator is proposed to guide
the tuning process, enabling designers to visualize the improvements in
closed-loop performance. The proposed methodology is demonstrated through a
case study of an industrial wire bonder machine, showcasing its effectiveness
in addressing low-frequency vibrations and improving overall control
performance.

</details>


### [180] [Time-Varying Coverage Control: A Distributed Tracker-Planner MPC Framework](https://arxiv.org/abs/2507.01567)
*Patrick Benito Eberhard,Johannes Köhler,Oliver Hüsser,Melanie N. Zeilinger,Andrea Carron*

Main category: eess.SY

TL;DR: 提出了一种分布式多智能体控制框架，用于解决非线性约束动态下的时变覆盖控制问题，结合轨迹规划与跟踪MPC，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 时变覆盖控制在自动驾驶出租车和搜救行动中有广泛应用，但受时变密度函数、非线性动态和严格约束的挑战。

Method: 采用分布式多智能体控制框架，结合参考轨迹规划器和跟踪MPC，多速率运行。

Result: 对于周期性密度函数，证明了闭环收敛到最优轨迹配置，并满足约束、避碰和递归可行性；提出处理非周期性密度函数的高效算法。

Conclusion: 方法通过硬件实验验证，适用于实际应用。

Abstract: Time-varying coverage control addresses the challenge of coordinating
multiple agents covering an environment where regions of interest change over
time. This problem has broad applications, including the deployment of
autonomous taxis and coordination in search and rescue operations. The
achievement of effective coverage is complicated by the presence of
time-varying density functions, nonlinear agent dynamics, and stringent system
and safety constraints. In this paper, we present a distributed multi-agent
control framework for time-varying coverage under nonlinear constrained
dynamics. Our approach integrates a reference trajectory planner and a tracking
model predictive control (MPC) scheme, which operate at different frequencies
within a multi-rate framework. For periodic density functions, we demonstrate
closed-loop convergence to an optimal configuration of trajectories and provide
formal guarantees regarding constraint satisfaction, collision avoidance, and
recursive feasibility. Additionally, we propose an efficient algorithm capable
of handling nonperiodic density functions, making the approach suitable for
practical applications. Finally, we validate our method through hardware
experiments using a fleet of four miniature race cars.

</details>


### [181] [Vision-Aided ISAC in Low-Altitude Economy Networks via De-Diffused Visual Priors](https://arxiv.org/abs/2507.01574)
*Yulan Gao,Ziqiang Ye,Zhonghao Lyu,Ming Xiao,Yue Xiao,Ping Yang,Agata Manolova*

Main category: eess.SY

TL;DR: 论文提出了一种基于视觉辅助的ISAC框架（DeDiff-VARARO），用于无人机辅助的低空经济网络资源优化，结合De-Diffusion模型和雷达数据，实现隐私保护和高效率的资源调度。


<details>
  <summary>Details</summary>
Motivation: 解决低空经济网络（LAENets）在动态移动和有限基础设施下的敏捷、隐私保护资源控制问题。

Method: 提出DeDiff-VARARO算法，结合De-Diffusion模型提取语义令牌，融合毫米波雷达数据构建风险热图，并通过两阶段跨模态控制优化资源调度。

Result: 仿真显示DeDiff-VARARO在奖励收敛、链路鲁棒性和语义保真度上优于基线，接近原始图像性能上限的4%，同时保护隐私。

Conclusion: DeDiff-VARARO在动态低空网络中实现了高效的隐私保护资源优化，具有可扩展性。

Abstract: Emerging low-altitude economy networks (LAENets) require agile and
privacy-preserving resource control under dynamic agent mobility and limited
infrastructure support. To meet these challenges, we propose a vision-aided
integrated sensing and communication (ISAC) framework for UAV-assisted access
systems, where onboard masked De-Diffusion models extract compact semantic
tokens, including agent type, activity class, and heading orientation, while
explicitly suppressing sensitive visual content. These tokens are fused with
mmWave radar measurements to construct a semantic risk heatmap reflecting
motion density, occlusion, and scene complexity, which guides access technology
selection and resource scheduling. We formulate a multi-objective optimization
problem to jointly maximize weighted energy and perception efficiency via radio
access technology (RAT) assignment, power control, and beamforming, subject to
agent-specific QoS constraints. To solve this, we develop De-Diffusion-driven
vision-aided risk-aware resource optimization algorithm DeDiff-VARARO, a novel
two-stage cross-modal control algorithm: the first stage reconstructs visual
scenes from tokens via De-Diffusion model for semantic parsing, while the
second stage employs a deep deterministic policy gradient (DDPG)-based policy
to adapt RAT selection, power control, and beam assignment based on fused
radar-visual states. Simulation results show that DeDiff-VARARO consistently
outperforms baselines in reward convergence, link robustness, and semantic
fidelity, achieving within $4\%$ of the performance of a raw-image upper bound
while preserving user privacy and scalability in dense environments.

</details>


### [182] [Re-examining the Legendre-Gauss-Lobatto Pseudospectral Methods for Optimal Control](https://arxiv.org/abs/2507.01660)
*Yilin Zou,Fanghua Jiang*

Main category: eess.SY

TL;DR: 本文重新审视了Legendre-Gauss-Lobatto（LGL）配点方法，提出了一种增强的LGL配点方法，解决了收敛性问题，并在计算性能上优于Legendre-Gauss（LG）和Legendre-Gauss-Radau（LGR）方法。


<details>
  <summary>Details</summary>
Motivation: 传统认为LGL配点方法在收敛性上不如LG和LGR方法，本文旨在通过改进LGL方法解决这一问题。

Method: 引入增强的LGL配点方法，通过增加自由度（DOF）改进插值结构，并证明其数学等价于LGL配点方法的积分形式。

Result: 改进的LGL方法在离散问题维度和辛积分性质上优于LG和LGR方法，数值实验验证了其准确性。

Conclusion: 改进的LGL方法在长时域最优控制问题中具有更高的计算性能，同时保持与LG和LGR方法相当的精度。

Abstract: Pseudospectral methods represent an efficient approach for solving optimal
control problems. While Legendre-Gauss-Lobatto (LGL) collocation points have
traditionally been considered inferior to Legendre-Gauss (LG) and
Legendre-Gauss-Radau (LGR) points in terms of convergence properties, this
paper presents a rigorous re-examination of LGL-based methods. We introduce an
augmented formulation that enhances the standard LGL collocation approach by
incorporating an additional degree of freedom (DOF) into the interpolation
structure. We demonstrate that this augmented formulation is mathematically
equivalent to the integral formulation of the LGL collocation method. Through
analytical derivation, we establish that the adjoint system in both the
augmented differential and integral formulations corresponds to a Lobatto IIIB
discontinuous collocation method for the costate vector, thereby resolving the
previously reported convergence issues. Our comparative analysis of LG, LGR,
and LGL collocation methods reveals significant advantages of the improved LGL
approach in terms of discretized problem dimensionality and symplectic
integration properties. Numerical examples validate our theoretical findings,
demonstrating that the proposed LGL-based method achieves comparable accuracy
to LG and LGR methods while offering superior computational performance for
long-horizon optimal control problems due to the preservation of symplecticity.

</details>


### [183] [Auto-optimization of Energy Generation for Wave Energy Converters with Active Learning](https://arxiv.org/abs/2507.01727)
*Siyang Tang,Wen-Hua Chen,Cunjia Liu*

Main category: eess.SY

TL;DR: 提出了一种用于波浪能转换器（WEC）的自动优化控制框架，以在未知和变化的海洋条件下最大化能量生成。


<details>
  <summary>Details</summary>
Motivation: 解决波浪能转换器在未知和变化的海洋条件下能量生成效率低的问题。

Method: 采用双层控制框架，高层控制器基于DCEE概念设计，主动探测海洋条件并生成最优PTO力，低层控制器跟随高层生成的PTO力。

Result: 仿真结果表明，该方法在未知规则和不规则波浪下均表现出色，优于模型预测控制、极值搜索和经典Bang-Bang控制方法。

Conclusion: 该自动优化框架通过主动学习和参数化非稳态操作条件，显著提高了WEC系统的能量生成效率和鲁棒性。

Abstract: This paper presents an auto-optimization control framework for wave energy
converters (WECs) to maximize energy generation under unknown and changing
ocean conditions. The proposed control framework consists of two levels. The
high-level controller operating at a longer time scale aims to maximize the
average energy generation over several wave periods. The generated Power
Take-Off (PTO) profile as the reference for the low-level physical system to
follow. The new auto-optimization process leverages the parameterization of the
non-stationary operation condition in WECs, establishing the relationship
between the average energy generation and the key design parameters of the PTO
force subject to the unknown wave parameters. The high-level controller is
designed based on the concept of Dual Control for Exploration and Exploitation
(DCEE) to quickly learn the unknown wave parameters by actively probing the
ocean condition, while generating the optimal PTO profile. During this process,
the uncertainty of the estimated wave condition is quantified and embedded in
the optimization cost function to enable active learning. Simulation results
under unknown regular and irregular waves demonstrate the effectiveness and
robustness of this novel auto-optimization WEC systems with active learning,
outperforming model predictive control, extremum seeking and classic Bang-Bang
control approaches.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [184] [Prompt Mechanisms in Medical Imaging: A Comprehensive Survey](https://arxiv.org/abs/2507.01055)
*Hao Yang,Xinlong Liang,Zhang Li,Yue Sun,Zheyu Hu,Xinghe Xie,Behdad Dashtbozorg,Jincheng Huang,Shiwei Zhu,Luyi Han,Jiong Zhang,Shanshan Wang,Ritse Mann,Qifeng Yu,Tao Tan*

Main category: eess.IV

TL;DR: 本文综述了提示工程在医学影像中的应用，探讨了其如何通过多样化提示提升深度学习模型的性能、适应性和可解释性，同时指出了优化设计、数据异质性和临床部署等挑战。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医学影像中潜力巨大，但数据稀缺、分布偏移和任务泛化等问题阻碍了其临床应用。提示方法为模型提供了灵活的领域适应策略，无需大量重新训练即可显著提升性能。

Method: 系统分析了文本指令、视觉提示和可学习嵌入等多种提示模态，及其在图像生成、分割和分类等核心任务中的整合方式。

Result: 提示机制通过提高准确性、鲁棒性和数据效率，减少对人工特征工程的依赖，同时增强模型的可解释性。

Conclusion: 尽管取得了显著进展，提示设计优化、数据异质性和临床部署的扩展性仍是挑战。未来方向包括多模态提示和临床整合，以推动诊断和个性化治疗的革命。

Abstract: Deep learning offers transformative potential in medical imaging, yet its
clinical adoption is frequently hampered by challenges such as data scarcity,
distribution shifts, and the need for robust task generalization. Prompt-based
methodologies have emerged as a pivotal strategy to guide deep learning models,
providing flexible, domain-specific adaptations that significantly enhance
model performance and adaptability without extensive retraining. This
systematic review critically examines the burgeoning landscape of prompt
engineering in medical imaging. We dissect diverse prompt modalities, including
textual instructions, visual prompts, and learnable embeddings, and analyze
their integration for core tasks such as image generation, segmentation, and
classification. Our synthesis reveals how these mechanisms improve
task-specific outcomes by enhancing accuracy, robustness, and data efficiency
and reducing reliance on manual feature engineering while fostering greater
model interpretability by making the model's guidance explicit. Despite
substantial advancements, we identify persistent challenges, particularly in
prompt design optimization, data heterogeneity, and ensuring scalability for
clinical deployment. Finally, this review outlines promising future
trajectories, including advanced multimodal prompting and robust clinical
integration, underscoring the critical role of prompt-driven AI in accelerating
the revolution of diagnostics and personalized treatment planning in medicine.

</details>


### [185] [MID-INFRARED (MIR) OCT-based inspection in industry](https://arxiv.org/abs/2507.01074)
*N. P. García-de-la-Puente,Rocío del Amor,Fernando García-Torres,Niels Møller Israelsen,Coraline Lapre,Christian Rosenberg Petersen,Ole Bang,Dominik Brouczek,Martin Schwentenwein,Kevin Neumann,Niels Benson,Valery Naranjo*

Main category: eess.IV

TL;DR: 评估中红外光学相干断层扫描（MIR-OCT）系统在穿透材料和检测次表面缺陷中的应用，探索其在工业无损检测中的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究中红外OCT系统在监测生产过程中的实用性，为工业提供有价值的无损检测技术。

Method: 通过复合材料和陶瓷的多组数据采集，结合预处理和AI增强视觉算法，评估系统检测异常区域的能力。

Result: 讨论了系统参数选择的优化标准，并总结了其优势和局限性。

Conclusion: MIR-OCT系统在工业无损检测中具有潜力，但需进一步优化参数和方法。

Abstract: This paper aims to evaluate mid-infrared (MIR) Optical Coherence Tomography
(OCT) systems as a tool to penetrate different materials and detect sub-surface
irregularities. This is useful for monitoring production processes, allowing
Non-Destructive Inspection Techniques of great value to the industry. In this
exploratory study, several acquisitions are made on composite and ceramics to
know the capabilities of the system. In addition, it is assessed which
preprocessing and AI-enhanced vision algorithms can be anomaly-detection
methodologies capable of detecting abnormal zones in the analyzed objects.
Limitations and criteria for the selection of optimal parameters will be
discussed, as well as strengths and weaknesses will be highlighted.

</details>


### [186] [LotteryCodec: Searching the Implicit Representation in a Random Network for Low-Complexity Image Compression](https://arxiv.org/abs/2507.01204)
*Haotian Wu,Gongpu Chen,Pier Luigi Dragotti,Deniz Gündüz*

Main category: eess.IV

TL;DR: 彩票编解码假说提出未训练子网络可用于过拟合图像压缩，性能媲美训练网络。基于此的LotteryCodec通过二进制掩码和重调机制优化性能，实现SOTA压缩。


<details>
  <summary>Details</summary>
Motivation: 探索未训练子网络在图像压缩中的潜力，提出新压缩范式。

Method: 使用二进制掩码和重调机制在过参数化网络中搜索子网络。

Result: LotteryCodec性能超越VTM，成为单图压缩新标杆，支持自适应解码复杂度。

Conclusion: 彩票编解码假说为图像压缩提供新思路，LotteryCodec展示了其高效性和灵活性。

Abstract: We introduce and validate the lottery codec hypothesis, which states that
untrained subnetworks within randomly initialized networks can serve as
synthesis networks for overfitted image compression, achieving rate-distortion
(RD) performance comparable to trained networks. This hypothesis leads to a new
paradigm for image compression by encoding image statistics into the network
substructure. Building on this hypothesis, we propose LotteryCodec, which
overfits a binary mask to an individual image, leveraging an over-parameterized
and randomly initialized network shared by the encoder and the decoder. To
address over-parameterization challenges and streamline subnetwork search, we
develop a rewind modulation mechanism that improves the RD performance.
LotteryCodec outperforms VTM and sets a new state-of-the-art in single-image
compression. LotteryCodec also enables adaptive decoding complexity through
adjustable mask ratios, offering flexible compression solutions for diverse
device constraints and application requirements.

</details>


### [187] [Classification based deep learning models for lung cancer and disease using medical images](https://arxiv.org/abs/2507.01279)
*Ahmad Chaddad,Jihao Peng,Yihang Wu*

Main category: eess.IV

TL;DR: 提出了一种名为ResNet+的新型深度卷积神经网络模型，基于ResNet框架，用于改进肺癌和肺部疾病的预测。通过集成ResNet-D模块和卷积注意力模块，解决了特征信息丢失问题并增强了模型泛化能力。在多个公开数据集上表现出色，优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决传统CNN在下采样过程中特征信息丢失的问题，并提高肺癌和肺部疾病预测的准确性。

Method: 结合ResNet-D模块改进下采样层，并在瓶颈层加入卷积注意力模块，同时使用数据增强技术处理类别不平衡。

Result: 在多个数据集上表现优异，LC2500数据集准确率/F1为98.14/98.14%，IQ-OTH/NCCD数据集为99.25/99.13%。

Conclusion: ResNet+模型在预测肺癌图像方面优于基线模型，同时节省计算成本。

Abstract: The use of deep learning (DL) in medical image analysis has significantly
improved the ability to predict lung cancer. In this study, we introduce a
novel deep convolutional neural network (CNN) model, named ResNet+, which is
based on the established ResNet framework. This model is specifically designed
to improve the prediction of lung cancer and diseases using the images. To
address the challenge of missing feature information that occurs during the
downsampling process in CNNs, we integrate the ResNet-D module, a variant
designed to enhance feature extraction capabilities by modifying the
downsampling layers, into the traditional ResNet model. Furthermore, a
convolutional attention module was incorporated into the bottleneck layers to
enhance model generalization by allowing the network to focus on relevant
regions of the input images. We evaluated the proposed model using five public
datasets, comprising lung cancer (LC2500 $n$=3183, IQ-OTH/NCCD $n$=1336, and
LCC $n$=25000 images) and lung disease (ChestXray $n$=5856, and COVIDx-CT
$n$=425024 images). To address class imbalance, we used data augmentation
techniques to artificially increase the representation of underrepresented
classes in the training dataset. The experimental results show that ResNet+
model demonstrated remarkable accuracy/F1, reaching 98.14/98.14\% on the
LC25000 dataset and 99.25/99.13\% on the IQ-OTH/NCCD dataset. Furthermore, the
ResNet+ model saved computational cost compared to the original ResNet series
in predicting lung cancer images. The proposed model outperformed the baseline
models on publicly available datasets, achieving better performance metrics.
Our codes are publicly available at
https://github.com/AIPMLab/Graduation-2024/tree/main/Peng.

</details>


### [188] [PanTS: The Pancreatic Tumor Segmentation Dataset](https://arxiv.org/abs/2507.01291)
*Wenxuan Li,Xinze Zhou,Qi Chen,Tianyu Lin,Pedro R. A. S. Bassi,Szymon Plotka,Jaroslaw B. Cwikla,Xiaoxi Chen,Chen Ye,Zheren Zhu,Kai Ding,Heng Li,Kang Wang,Yang Yang,Yucheng Tang,Daguang Xu,Alan L. Yuille,Zongwei Zhou*

Main category: eess.IV

TL;DR: PanTS是一个大规模、多机构的数据集，用于推动胰腺CT分析研究，包含36,390个CT扫描和993,000多个专家验证的体素级标注，显著提升AI模型在胰腺肿瘤检测、定位和分割中的性能。


<details>
  <summary>Details</summary>
Motivation: 推动胰腺CT分析研究，提供更全面的数据集以支持AI模型的开发与评估。

Method: 收集来自145个医疗中心的36,390个CT扫描，包含专家验证的体素级标注和丰富的元数据。

Result: 在胰腺肿瘤检测、定位和分割任务中，基于PanTS训练的AI模型性能显著优于现有公共数据集。

Conclusion: PanTS是目前最大、最全面的胰腺CT分析资源，为AI模型的开发和评估提供了新的基准。

Abstract: PanTS is a large-scale, multi-institutional dataset curated to advance
research in pancreatic CT analysis. It contains 36,390 CT scans from 145
medical centers, with expert-validated, voxel-wise annotations of over 993,000
anatomical structures, covering pancreatic tumors, pancreas head, body, and
tail, and 24 surrounding anatomical structures such as vascular/skeletal
structures and abdominal/thoracic organs. Each scan includes metadata such as
patient age, sex, diagnosis, contrast phase, in-plane spacing, slice thickness,
etc. AI models trained on PanTS achieve significantly better performance in
pancreatic tumor detection, localization, and segmentation compared to those
trained on existing public datasets. Our analysis indicates that these gains
are directly attributable to the 16x larger-scale tumor annotations and
indirectly supported by the 24 additional surrounding anatomical structures. As
the largest and most comprehensive resource of its kind, PanTS offers a new
benchmark for developing and evaluating AI models in pancreatic CT analysis.

</details>


### [189] [SWinMamba: Serpentine Window State Space Model for Vascular Segmentation](https://arxiv.org/abs/2507.01323)
*Rongchang Zhao,Huanchi Liu,Jian Zhang*

Main category: eess.IV

TL;DR: 提出了一种名为SWinMamba的新方法，通过蛇形窗口序列和双向状态空间模型实现精确的血管分割，解决了血管结构不连续的问题。


<details>
  <summary>Details</summary>
Motivation: 血管分割在医学图像中至关重要，但现有方法常因血管细长和先验建模不足导致分割结果不连续。

Method: 结合蛇形窗口序列和双向状态空间模型，设计了SWToken和BAM模块，并引入双域学习增强特征表示。

Result: 在三个数据集上验证了SWinMamba的优越性能，实现了完整且连续的血管分割。

Conclusion: SWinMamba通过创新建模血管连续性，显著提升了血管分割的准确性。

Abstract: Vascular segmentation in medical images is crucial for disease diagnosis and
surgical navigation. However, the segmented vascular structure is often
discontinuous due to its slender nature and inadequate prior modeling. In this
paper, we propose a novel Serpentine Window Mamba (SWinMamba) to achieve
accurate vascular segmentation. The proposed SWinMamba innovatively models the
continuity of slender vascular structures by incorporating serpentine window
sequences into bidirectional state space models. The serpentine window
sequences enable efficient feature capturing by adaptively guiding global
visual context modeling to the vascular structure. Specifically, the Serpentine
Window Tokenizer (SWToken) adaptively splits the input image using overlapping
serpentine window sequences, enabling flexible receptive fields (RFs) for
vascular structure modeling. The Bidirectional Aggregation Module (BAM)
integrates coherent local features in the RFs for vascular continuity
representation. In addition, dual-domain learning with Spatial-Frequency Fusion
Unit (SFFU) is designed to enhance the feature representation of vascular
structure. Extensive experiments on three challenging datasets demonstrate that
the proposed SWinMamba achieves superior performance with complete and
connected vessels.

</details>


### [190] [Structure and Smoothness Constrained Dual Networks for MR Bias Field Correction](https://arxiv.org/abs/2507.01326)
*Dong Liang,Xingyu Qiu,Yuzhen Li,Wei Wang,Kuanquan Wang,Suyu Dong,Gongning Luo*

Main category: eess.IV

TL;DR: 提出了一种名为S2DNets的双网络模型，通过结构和平滑性约束自监督校正MR图像的偏置场，显著提升了图像质量。


<details>
  <summary>Details</summary>
Motivation: MR图像存在强度不均匀问题，影响诊断和分析。现有深度学习模型仅关注全局外观学习，忽略了图像结构和偏置场平滑性约束，导致校正结果失真。

Method: 提出S2DNets，引入分段结构约束和偏置场平滑性约束，通过自监督方式校正偏置场。

Result: 在临床和模拟MR数据集上的实验表明，S2DNets优于传统和基于深度学习的方法，并提升了下游分割任务的性能。

Conclusion: S2DNets有效解决了MR图像强度不均匀问题，保留了更多结构细节，具有实际应用价值。

Abstract: MR imaging techniques are of great benefit to disease diagnosis. However, due
to the limitation of MR devices, significant intensity inhomogeneity often
exists in imaging results, which impedes both qualitative and quantitative
medical analysis. Recently, several unsupervised deep learning-based models
have been proposed for MR image improvement. However, these models merely
concentrate on global appearance learning, and neglect constraints from image
structures and smoothness of bias field, leading to distorted corrected
results. In this paper, novel structure and smoothness constrained dual
networks, named S2DNets, are proposed aiming to self-supervised bias field
correction. S2DNets introduce piece-wise structural constraints and smoothness
of bias field for network training to effectively remove non-uniform intensity
and retain much more structural details. Extensive experiments executed on both
clinical and simulated MR datasets show that the proposed model outperforms
other conventional and deep learning-based models. In addition to comparison on
visual metrics, downstream MR image segmentation tasks are also used to
evaluate the impact of the proposed model. The source code is available at:
https://github.com/LeongDong/S2DNets}{https://github.com/LeongDong/S2DNets.

</details>


### [191] [BronchoGAN: Anatomically consistent and domain-agnostic image-to-image translation for video bronchoscopy](https://arxiv.org/abs/2507.01387)
*Ahmad Soliman,Ron Keuth,Marian Himstedt*

Main category: eess.IV

TL;DR: BronchoGAN提出了一种基于条件GAN的图像翻译方法，通过引入解剖约束和中间深度图像表示，实现了不同支气管镜输入域的鲁棒图像翻译，生成逼真的支气管图像。


<details>
  <summary>Details</summary>
Motivation: 支气管镜图像的有限可用性限制了深度学习模型的训练，需要一种能够跨域（虚拟支气管镜、体模、活体和离体数据）进行鲁棒图像翻译的方法。

Method: 提出BronchoGAN，将解剖约束（如支气管孔匹配）和基础模型生成的深度图像作为中间表示，集成到条件GAN中，减少对单个训练数据集的依赖。

Result: 实验表明，BronchoGAN能成功将不同域的输入图像翻译为逼真的人类气道图像，解剖结构（如支气管孔）得到保留，FID、SSIM和Dice系数显著提升。

Conclusion: BronchoGAN通过解剖约束和中间深度表示，填补了公共支气管镜图像的空白，为生成大规模逼真支气管镜数据集提供了有效工具。

Abstract: The limited availability of bronchoscopy images makes image synthesis
particularly interesting for training deep learning models. Robust image
translation across different domains -- virtual bronchoscopy, phantom as well
as in-vivo and ex-vivo image data -- is pivotal for clinical applications. This
paper proposes BronchoGAN introducing anatomical constraints for image-to-image
translation being integrated into a conditional GAN. In particular, we force
bronchial orifices to match across input and output images. We further propose
to use foundation model-generated depth images as intermediate representation
ensuring robustness across a variety of input domains establishing models with
substantially less reliance on individual training datasets. Moreover our
intermediate depth image representation allows to easily construct paired image
data for training. Our experiments showed that input images from different
domains (e.g. virtual bronchoscopy, phantoms) can be successfully translated to
images mimicking realistic human airway appearance. We demonstrated that
anatomical settings (i.e. bronchial orifices) can be robustly preserved with
our approach which is shown qualitatively and quantitatively by means of
improved FID, SSIM and dice coefficients scores. Our anatomical constraints
enabled an improvement in the Dice coefficient of up to 0.43 for synthetic
images. Through foundation models for intermediate depth representations,
bronchial orifice segmentation integrated as anatomical constraints into
conditional GANs we are able to robustly translate images from different
bronchoscopy input domains. BronchoGAN allows to incorporate public CT scan
data (virtual bronchoscopy) in order to generate large-scale bronchoscopy image
datasets with realistic appearance. BronchoGAN enables to bridge the gap of
missing public bronchoscopy images.

</details>


### [192] [Multi Source COVID-19 Detection via Kernel-Density-based Slice Sampling](https://arxiv.org/abs/2507.01564)
*Chia-Ming Lee,Bo-Cheng Qiu,Ting-Yao Chen,Ming-Han Sun,Fang-Ying Lin,Jung-Tse Tsai,I-An Tsai,Yu-Fan Lin,Chih-Chung Hsu*

Main category: eess.IV

TL;DR: 提出了一种基于SSFL和KDS的多源COVID-19检测方法，通过预处理和模型比较，EfficientNet表现优于Swin Transformer。


<details>
  <summary>Details</summary>
Motivation: 解决多源数据（来自四个医疗中心）的变异性问题，提高COVID-19检测的准确性。

Method: 采用SSFL框架和KDS切片采样，预处理包括肺部区域提取、质量控制和自适应切片采样，比较EfficientNet和Swin Transformer模型。

Result: EfficientNet的F1得分为94.68%，优于Swin Transformer的93.34%。

Conclusion: KDS预处理流程在多源数据上有效，数据集平衡对多机构医学影像评估至关重要。

Abstract: We present our solution for the Multi-Source COVID-19 Detection Challenge,
which classifies chest CT scans from four distinct medical centers. To address
multi-source variability, we employ the Spatial-Slice Feature Learning (SSFL)
framework with Kernel-Density-based Slice Sampling (KDS). Our preprocessing
pipeline combines lung region extraction, quality control, and adaptive slice
sampling to select eight representative slices per scan. We compare
EfficientNet and Swin Transformer architectures on the validation set. The
EfficientNet model achieves an F1-score of 94.68%, compared to the Swin
Transformer's 93.34%. The results demonstrate the effectiveness of our
KDS-based pipeline on multi-source data and highlight the importance of dataset
balance in multi-institutional medical imaging evaluation.

</details>


### [193] [Enhancing Multi-Exposure High Dynamic Range Imaging with Overlapped Codebook for Improved Representation Learning](https://arxiv.org/abs/2507.01588)
*Keuntek Lee,Jaehyun Park,Nam Ik Cho*

Main category: eess.IV

TL;DR: 提出了一种基于重叠码本（OLC）的HDR成像方法，通过改进VQGAN框架学习隐式HDR表示，并结合新网络提升饱和区域补偿和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 解决多曝光HDR成像中因运动差异和曝光设置导致的饱和区域问题。

Method: 提出重叠码本（OLC）方案改进VQGAN框架，并开发新网络利用预训练的VQ网络和OLC进行HDR重建。

Result: 在多个数据集上验证，方法在质量和定量指标上优于现有技术。

Conclusion: OLC方案和新网络有效提升了HDR成像的性能和视觉质量。

Abstract: High dynamic range (HDR) imaging technique aims to create realistic HDR
images from low dynamic range (LDR) inputs. Specifically, Multi-exposure HDR
imaging uses multiple LDR frames taken from the same scene to improve
reconstruction performance. However, there are often discrepancies in motion
among the frames, and different exposure settings for each capture can lead to
saturated regions. In this work, we first propose an Overlapped codebook (OLC)
scheme, which can improve the capability of the VQGAN framework for learning
implicit HDR representations by modeling the common exposure bracket process in
the shared codebook structure. Further, we develop a new HDR network that
utilizes HDR representations obtained from a pre-trained VQ network and OLC.
This allows us to compensate for saturated regions and enhance overall visual
quality. We have tested our approach extensively on various datasets and have
demonstrated that it outperforms previous methods both qualitatively and
quantitatively

</details>


### [194] [Robust brain age estimation from structural MRI with contrastive learning](https://arxiv.org/abs/2507.01794)
*Carlo Alberto Barbano,Benoit Dufumier,Edouard Duchesnay,Marco Grangetto,Pietro Gori*

Main category: eess.IV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Estimating brain age from structural MRI has emerged as a powerful tool for
characterizing normative and pathological aging. In this work, we explore
contrastive learning as a scalable and robust alternative to supervised
approaches for brain age estimation. We introduce a novel contrastive loss
function, $\mathcal{L}^{exp}$, and evaluate it across multiple public
neuroimaging datasets comprising over 20,000 scans. Our experiments reveal four
key findings. First, scaling pre-training on diverse, multi-site data
consistently improves generalization performance, cutting external mean
absolute error (MAE) nearly in half. Second, $\mathcal{L}^{exp}$ is robust to
site-related confounds, maintaining low scanner-predictability as training size
increases. Third, contrastive models reliably capture accelerated aging in
patients with cognitive impairment and Alzheimer's disease, as shown through
brain age gap analysis, ROC curves, and longitudinal trends. Lastly, unlike
supervised baselines, $\mathcal{L}^{exp}$ maintains a strong correlation
between brain age accuracy and downstream diagnostic performance, supporting
its potential as a foundation model for neuroimaging. These results position
contrastive learning as a promising direction for building generalizable and
clinically meaningful brain representations.

</details>


### [195] [Autoadaptive Medical Segment Anything Model](https://arxiv.org/abs/2507.01828)
*Tyler Ward,Meredith K. Owen,O'Kira Coleman,Brian Noehren,Abdullah-Al-Zubaer Imran*

Main category: eess.IV

TL;DR: ADA-SAM是一种新型的多任务学习框架，用于医学图像分割，通过辅助分类器的类激活图指导半监督分割分支，并结合梯度反馈机制提升分类预测。


<details>
  <summary>Details</summary>
Motivation: 传统全监督分割模型依赖大量标注数据，成本高且耗时，需要更高效、自动化的方法。

Method: 基于SAM框架，结合类激活图和梯度反馈机制，实现分割与分类分支的协同学习。

Result: 在真实临床数据上验证，ADA-SAM在有限标注条件下优于全监督和半监督基线模型。

Conclusion: ADA-SAM提供了一种高效、自动化的医学图像分割解决方案，显著提升了性能。

Abstract: Medical image segmentation is a key task in the imaging workflow, influencing
many image-based decisions. Traditional, fully-supervised segmentation models
rely on large amounts of labeled training data, typically obtained through
manual annotation, which can be an expensive, time-consuming, and error-prone
process. This signals a need for accurate, automatic, and annotation-efficient
methods of training these models. We propose ADA-SAM (automated,
domain-specific, and adaptive segment anything model), a novel multitask
learning framework for medical image segmentation that leverages class
activation maps from an auxiliary classifier to guide the predictions of the
semi-supervised segmentation branch, which is based on the Segment Anything
(SAM) framework. Additionally, our ADA-SAM model employs a novel gradient
feedback mechanism to create a learnable connection between the segmentation
and classification branches by using the segmentation gradients to guide and
improve the classification predictions. We validate ADA-SAM on real-world
clinical data collected during rehabilitation trials, and demonstrate that our
proposed method outperforms both fully-supervised and semi-supervised baselines
by double digits in limited label settings. Our code is available at:
https://github.com/tbwa233/ADA-SAM.

</details>


### [196] [A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs](https://arxiv.org/abs/2507.01881)
*Niccolò McConnell,Pardeep Vasudev,Daisuke Yamada,Daryl Cheng,Mehran Azimbagirad,John McCabe,Shahab Aslani,Ahmed H. Shahin,Yukun Zhou,The SUMMIT Consortium,Andre Altmann,Yipeng Hu,Paul Taylor,Sam M. Janes,Daniel C. Alexander,Joseph Jacob*

Main category: eess.IV

TL;DR: TANGERINE是一个开源、计算资源需求低的视觉基础模型，用于低剂量CT（LDCT）分析，能够快速适应多种疾病检测任务，显著减少训练时间和数据需求。


<details>
  <summary>Details</summary>
Motivation: 由于放射科医生短缺，大规模解读LDCT扫描成为挑战，需要一种高效、可扩展的解决方案。

Method: TANGERINE基于自监督学习预训练，使用超过98,000个胸部LDCT扫描数据，并通过3D掩码自编码器框架实现。

Result: 在14种疾病分类任务中达到最先进性能，包括肺癌和多种呼吸系统疾病，且能适应不同临床中心的数据。

Conclusion: TANGERINE的开源、轻量级设计为下一代医学影像工具提供了快速集成的基础，有望将肺癌筛查扩展为全面的呼吸系统疾病管理。

Abstract: Low-dose computed tomography (LDCT) imaging employed in lung cancer screening
(LCS) programs is increasing in uptake worldwide. LCS programs herald a
generational opportunity to simultaneously detect cancer and non-cancer-related
early-stage lung disease. Yet these efforts are hampered by a shortage of
radiologists to interpret scans at scale. Here, we present TANGERINE, a
computationally frugal, open-source vision foundation model for volumetric LDCT
analysis. Designed for broad accessibility and rapid adaptation, TANGERINE can
be fine-tuned off the shelf for a wide range of disease-specific tasks with
limited computational resources and training data. Relative to models trained
from scratch, TANGERINE demonstrates fast convergence during fine-tuning,
thereby requiring significantly fewer GPU hours, and displays strong label
efficiency, achieving comparable or superior performance with a fraction of
fine-tuning data. Pretrained using self-supervised learning on over 98,000
thoracic LDCTs, including the UK's largest LCS initiative to date and 27 public
datasets, TANGERINE achieves state-of-the-art performance across 14 disease
classification tasks, including lung cancer and multiple respiratory diseases,
while generalising robustly across diverse clinical centres. By extending a
masked autoencoder framework to 3D imaging, TANGERINE offers a scalable
solution for LDCT analysis, departing from recent closed, resource-intensive
models by combining architectural simplicity, public availability, and modest
computational requirements. Its accessible, open-source lightweight design lays
the foundation for rapid integration into next-generation medical imaging tools
that could transform LCS initiatives, allowing them to pivot from a singular
focus on lung cancer detection to comprehensive respiratory disease management
in high-risk populations.

</details>
