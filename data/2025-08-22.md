<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 37]
- [cs.CV](#cs.CV) [Total: 67]
- [cs.CL](#cs.CL) [Total: 54]
- [cs.RO](#cs.RO) [Total: 14]
- [eess.SY](#eess.SY) [Total: 10]
- [eess.IV](#eess.IV) [Total: 16]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone](https://arxiv.org/abs/2508.14923)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出了一种完全基于图信号处理（GSP）的神经符号推理架构，将整个推理过程在图谱域中进行，实现了逻辑与神经推理的深度整合。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型将谱图方法视为辅助组件，缺乏对符号逻辑和神经推理的有效整合，需要一种更具数学基础和计算效率的方法来提高逻辑一致性、可解释性和效率。

Method: 构建了一个完全谱域的神经符号推理架构。将逻辑实体和关系编码为图信号，通过可学习的谱滤波器处理以控制多尺度信息传播，并映射到符号谓词进行基于规则的推理。该框架包括图傅里叶变换、带选择性注意力以及谱规则接合。

Result: 在ProofWriter、EntailmentBank、bAbI、CLUTRR和ARC-Challenge等基准推理数据集上的实验表明，与最先进的神经符号模型相比，该方法在逻辑一致性、可解释性和计算效率方面均有显著提升。

Conclusion: 研究结果表明，图信号处理为构建鲁棒且可解释的推理系统提供了一个具有数学基础和计算效率的底层支持。

Abstract: We propose a fully spectral, neuro\-symbolic reasoning architecture that
leverages Graph Signal Processing (GSP) as the primary computational backbone
for integrating symbolic logic and neural inference. Unlike conventional
reasoning models that treat spectral graph methods as peripheral components,
our approach formulates the entire reasoning pipeline in the graph spectral
domain. Logical entities and relationships are encoded as graph signals,
processed via learnable spectral filters that control multi-scale information
propagation, and mapped into symbolic predicates for rule-based inference. We
present a complete mathematical framework for spectral reasoning, including
graph Fourier transforms, band-selective attention, and spectral rule
grounding. Experiments on benchmark reasoning datasets (ProofWriter,
EntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in
logical consistency, interpretability, and computational efficiency over
state\-of\-the\-art neuro\-symbolic models. Our results suggest that GSP
provides a mathematically grounded and computationally efficient substrate for
robust and interpretable reasoning systems.

</details>


### [2] [Goals and the Structure of Experience](https://arxiv.org/abs/2508.15013)
*Nadav Amir,Stas Tiomkin,Angela Langdon*

Main category: cs.AI

TL;DR: 本文提出了一种计算框架，认为世界模型的描述性（状态表示）和规范性（奖励函数）方面可以从智能体的目标和经验中协同涌现，并引入了“目的性状态”的概念。


<details>
  <summary>Details</summary>
Motivation: 现有计算方法（如强化学习）将世界模型的描述性和规范性方面视为独立组件。本文旨在探索一种替代可能性，即这两个方面可以从智能体的目标中相互依存地协同涌现，而这种可能性尚未被计算化地阐述。

Method: 本文描述了一个认知智能体中目标导向状态表示的计算框架。借鉴佛教认识论，引入了“目的性状态”的概念，将其定义为目标等效经验分布的类别。通过行为策略与期望经验特征之间的统计差异来解释目标导向学习。

Result: 该框架提供了一种简洁的目标导向学习解释。文章回顾了支持这一新观点的经验和理论文献。

Conclusion: 该框架有望为跨不同基质的目的性行为在行为、现象学和神经维度上提供统一的解释。

Abstract: Purposeful behavior is a hallmark of natural and artificial intelligence. Its
acquisition is often believed to rely on world models, comprising both
descriptive (what is) and prescriptive (what is desirable) aspects that
identify and evaluate state of affairs in the world, respectively. Canonical
computational accounts of purposeful behavior, such as reinforcement learning,
posit distinct components of a world model comprising a state representation
(descriptive aspect) and a reward function (prescriptive aspect). However, an
alternative possibility, which has not yet been computationally formulated, is
that these two aspects instead co-emerge interdependently from an agent's goal.
Here, we describe a computational framework of goal-directed state
representation in cognitive agents, in which the descriptive and prescriptive
aspects of a world model co-emerge from agent-environment interaction
sequences, or experiences. Drawing on Buddhist epistemology, we introduce a
construct of goal-directed, or telic, states, defined as classes of
goal-equivalent experience distributions. Telic states provide a parsimonious
account of goal-directed learning in terms of the statistical divergence
between behavioral policies and desirable experience features. We review
empirical and theoretical literature supporting this novel perspective and
discuss its potential to provide a unified account of behavioral,
phenomenological and neural dimensions of purposeful behaviors across diverse
substrates.

</details>


### [3] [Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism](https://arxiv.org/abs/2508.15030)
*Ashmi Banerjee,Fitri Nur Aisyah,Adithi Satish,Wolfgang Wörndl,Yashar Deldjoo*

Main category: cs.AI

TL;DR: Collab-REC是一个多智能体框架，通过三个LLM智能体和一个非LLM协调员的多轮协商，解决旅游推荐中的流行度偏差，提升推荐多样性和相关性。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统存在流行度偏差，导致推荐结果缺乏多样性，使得热门地点过度旅游而冷门地点被忽视，且难以充分整合用户约束。

Method: 该方法提出Collab-REC框架，包含三个基于LLM的智能体（个性化、流行度和可持续性）从不同视角生成城市建议。一个非LLM协调员通过多轮协商合并和优化这些建议，确保每个智能体的观点被纳入，同时惩罚重复或虚假响应。

Result: 在欧洲城市查询上的实验表明，Collab-REC相比单智能体基线，显著提升了推荐的多样性和整体相关性，成功推荐了许多常被忽视的、访问量较少的地点。

Conclusion: Collab-REC提供了一种平衡且情境感知的方法，有效解决了过度旅游问题，并更好地满足了用户提供的约束，展示了LLM驱动推荐系统中多方协作的巨大潜力。

Abstract: We propose Collab-REC, a multi-agent framework designed to counteract
popularity bias and enhance diversity in tourism recommendations. In our
setting, three LLM-based agents -- Personalization, Popularity, and
Sustainability generate city suggestions from complementary perspectives. A
non-LLM moderator then merges and refines these proposals via multi-round
negotiation, ensuring each agent's viewpoint is incorporated while penalizing
spurious or repeated responses. Experiments on European city queries show that
Collab-REC improves diversity and overall relevance compared to a single-agent
baseline, surfacing lesser-visited locales that often remain overlooked. This
balanced, context-aware approach addresses over-tourism and better aligns with
constraints provided by the user, highlighting the promise of multi-stakeholder
collaboration in LLM-driven recommender systems.

</details>


### [4] [Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions](https://arxiv.org/abs/2508.15047)
*Yibo Liu,Liam Shatzel,Brandon Haworth,Teseo Schneider*

Main category: cs.AI

TL;DR: 该研究提出了一种利用大型语言模型（LLMs）来驱动人群中智能体的对话和导航的新方法，从而实现更真实、更具社会互动性的群体行为模拟。


<details>
  <summary>Details</summary>
Motivation: 现有的人群模拟方法在智能体交互方面主要局限于转向和预设目标，未能充分考虑语言和对话在人类导航和移动中复杂的社会和环境影响，导致模拟结果缺乏真实感。

Method: 该方法包含对话系统和语言驱动导航两个核心组件。它周期性地查询以智能体个性、角色、愿望和关系为条件的LLMs，根据空间和社会关系生成智能体之间的对话。然后，结合对话内容、智能体的个性、情绪状态、视觉和物理状态来控制每个智能体的导航和转向，使智能体能够基于感知输入和正在进行的对话做出移动决策。

Result: 在两个复杂的场景中验证了该方法，观察到智能体自动地进行分组和解组。实验表明，该方法作为人群中的信息传递机制，能够产生更真实的人群模拟，并自然地从任何环境设置中涌现出群体行为。

Conclusion: 通过整合LLMs驱动的对话和导航，该框架能够生成更真实的人群模拟，其中涌现的群体行为自然地产生于智能体之间的社会互动和信息传递，有效解决了现有方法在复杂社会交互方面的局限性。

Abstract: Animating and simulating crowds using an agent-based approach is a
well-established area where every agent in the crowd is individually controlled
such that global human-like behaviour emerges. We observe that human navigation
and movement in crowds are often influenced by complex social and environmental
interactions, driven mainly by language and dialogue. However, most existing
work does not consider these dimensions and leads to animations where
agent-agent and agent-environment interactions are largely limited to steering
and fixed higher-level goal extrapolation.
  We propose a novel method that exploits large language models (LLMs) to
control agents' movement. Our method has two main components: a dialogue system
and language-driven navigation. We periodically query agent-centric LLMs
conditioned on character personalities, roles, desires, and relationships to
control the generation of inter-agent dialogue when necessitated by the spatial
and social relationships with neighbouring agents. We then use the conversation
and each agent's personality, emotional state, vision, and physical state to
control the navigation and steering of each agent. Our model thus enables
agents to make motion decisions based on both their perceptual inputs and the
ongoing dialogue.
  We validate our method in two complex scenarios that exemplify the interplay
between social interactions, steering, and crowding. In these scenarios, we
observe that grouping and ungrouping of agents automatically occur.
Additionally, our experiments show that our method serves as an
information-passing mechanism within the crowd. As a result, our framework
produces more realistic crowd simulations, with emergent group behaviours
arising naturally from any environmental setting.

</details>


### [5] [Don't Think Twice! Over-Reasoning Impairs Confidence Calibration](https://arxiv.org/abs/2508.15050)
*Romain Lacombe,Kerrie Wu,Eddie Dilworth*

Main category: cs.AI

TL;DR: 研究发现，在知识密集型任务中，增加大型语言模型（LLM）的推理预算会损害其置信度校准，导致过度自信。相反，通过检索证据进行搜索增强的生成能显著提高校准准确性，表明信息获取而非推理深度是关键瓶颈。


<details>
  <summary>Details</summary>
Motivation: 作为问答工具部署的大型语言模型需要强大的校准能力以避免过度自信。

Method: 研究系统评估了推理能力和预算对置信度评估准确性的影响，使用了ClimateX数据集并扩展到人类和地球健康领域。对比了纯粹推理和搜索增强生成两种方法。

Result: 近期推理LLM在评估专家置信度方面的准确率为48.7%。增加推理预算反而持续损害校准，导致系统性过度自信，且随着思考预算的增加而恶化，这挑战了“测试时间扩展”范式。相比之下，搜索增强生成通过检索相关证据，准确率达到89.3%，远超纯粹推理。

Conclusion: 研究结果表明，信息获取而非推理深度或推理预算，可能是提高知识密集型任务中置信度校准的关键瓶颈。

Abstract: Large Language Models deployed as question answering tools require robust
calibration to avoid overconfidence. We systematically evaluate how reasoning
capabilities and budget affect confidence assessment accuracy, using the
ClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary
health. Our key finding challenges the "test-time scaling" paradigm: while
recent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,
increasing reasoning budgets consistently impairs rather than improves
calibration. Extended reasoning leads to systematic overconfidence that worsens
with longer thinking budgets, producing diminishing and negative returns beyond
modest computational investments. Conversely, search-augmented generation
dramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving
relevant evidence. Our results suggest that information access, rather than
reasoning depth or inference budget, may be the critical bottleneck for
improved confidence calibration of knowledge-intensive tasks.

</details>


### [6] [Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning](https://arxiv.org/abs/2508.15053)
*Itai Zilberstein,Alberto Candela,Steve Chien,David Rijlaarsdam,Tom Hendrix,Leonie Buckley,Aubrey Dunne*

Main category: cs.AI

TL;DR: CS-6卫星将利用其高光谱仪器和神经网络加速硬件，在轨演示基于深度学习和光谱分析的边缘数据分析，以实现新的地球科学测量和响应。


<details>
  <summary>Details</summary>
Motivation: 在卫星（边缘）上进行数据分析可以克服传统数据传输的限制，从而实现新的地球科学测量和更快的响应能力。

Method: 本研究使用CogniSAT-6/HAMMER (CS-6)卫星，该卫星配备可见光和近红外高光谱仪器以及神经网络加速硬件。研究方法包括利用深度学习和光谱分析算法进行在轨数据分析和推理。

Result: 该项目将成功演示CS-6卫星上针对多种应用的机载数据分析和推理能力。

Conclusion: 通过在CS-6卫星上结合高光谱数据和AI加速硬件进行边缘数据分析，能够显著提升地球科学测量的能力和实时响应效率。

Abstract: In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is
demonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).
CS-6 is a satellite with a visible and near infrared range hyperspectral
instrument and neural network acceleration hardware. Performing data analysis
at the edge (e.g. onboard) can enable new Earth science measurements and
responses. We will demonstrate data analysis and inference onboard CS-6 for
numerous applications using deep learning and spectral analysis algorithms.

</details>


### [7] [S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner](https://arxiv.org/abs/2508.15068)
*Shuang Ao,Gopal Rumchurn*

Main category: cs.AI

TL;DR: S3LoRA是一种轻量级、无数据、模型无关的框架，通过分析LoRA微调后的权重更新来识别并修剪潜在不安全的层，从而在不牺牲任务性能的情况下提高LLM代理的安全性，并降低推理成本。


<details>
  <summary>Details</summary>
Motivation: LoRA等PEFT技术在增强LLM代理能力的同时，可能无意中损害安全对齐，导致不安全或不稳定的行为。现有的安全感知适应方法通常需要基础模型和指令微调模型的检查点，但在实际中这些检查点往往不可用，限制了其适用性。

Method: 本文提出了S3LoRA（Safe Spectral Sharpness-Guided Pruning LoRA），一个轻量级、无数据、模型无关的框架，仅通过检查微调后的LoRA权重更新来缓解安全风险。该方法首先引入了Magnitude-Aware Spherically Normalized SVD (MAS-SVD) 来稳健分析LoRA更新的结构特性并保留全局幅度信息。随后，设计了Spectral Sharpness Index (SSI) 这一锐度感知指标，用于检测具有高度集中且可能不安全的更新层。最后，对这些层进行事后剪枝，以降低风险而不牺牲任务性能。

Result: 在代理规划和语言生成任务上的大量实验和消融研究表明，S3LoRA持续改进了安全指标，同时保持或改进了实用性指标，并显著降低了推理成本。

Conclusion: S3LoRA为在真实世界、资源受限和安全关键环境中安全部署基于LLM的代理提供了一个实用且可扩展的解决方案。

Abstract: Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning
(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based
agents. However, these adaptations can unintentionally compromise safety
alignment, leading to unsafe or unstable behaviors, particularly in agent
planning tasks. Existing safety-aware adaptation methods often require access
to both base and instruction-tuned model checkpoints, which are frequently
unavailable in practice, limiting their applicability. We propose S3LoRA (Safe
Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and
model-independent framework that mitigates safety risks in LoRA-adapted models
by inspecting only the fine-tuned weight updates. We first introduce
Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes
the structural properties of LoRA updates while preserving global magnitude
information. We then design the Spectral Sharpness Index (SSI), a
sharpness-aware metric to detect layers with highly concentrated and
potentially unsafe updates. These layers are pruned post-hoc to reduce risk
without sacrificing task performance. Extensive experiments and ablation
studies across agent planning and language generation tasks show that S3LoRA
consistently improves safety metrics while maintaining or improving utility
metrics and significantly reducing inference cost. These results establish
S3LoRA as a practical and scalable solution for safely deploying LLM-based
agents in real-world, resource-constrained, and safety-critical environments.

</details>


### [8] [Argumentation for Explainable Workforce Optimisation (with Appendix)](https://arxiv.org/abs/2508.15118)
*Jennifer Leigh,Dimitrios Letsios,Alessandro Mella,Lucio Machetti,Francesca Toni*

Main category: cs.AI

TL;DR: 本文提出将劳动力管理建模为抽象论证，以应对执行时期的变化并提供可信解释，用户研究表明其工具和解释比传统手动解决方案能更快、更准确地解决问题。


<details>
  <summary>Details</summary>
Motivation: 劳动力管理是一个复杂的问题，需要优化团队完成任务所需的总工期和行程距离。其核心挑战在于如何适应执行时的变化，并向所有相关方提供解释。

Method: 将劳动力管理理解为工业应用中的抽象论证问题。开发了一个工具来实施这一方法，并通过用户研究进行评估。

Result: 通过用户研究表明，本文提出的工具和解释比传统手动解决方案能更快、更准确地解决问题。

Conclusion: 通过将劳动力管理建模为抽象论证，可以有效地适应执行时期的变化，并提供可信的解释，从而提高问题解决的效率和准确性。

Abstract: Workforce management is a complex problem optimising the makespan and travel
distance required for a team of operators to complete a set of jobs, using a
set of instruments. A crucial challenge in workforce management is
accommodating changes at execution time so that explanations are provided to
all stakeholders involved. Here, we show that, by understanding workforce
management as abstract argumentation in an industrial application, we can
accommodate change and obtain faithful explanations. We show, with a user
study, that our tool and explanations lead to faster and more accurate problem
solving than conventional solutions by hand.

</details>


### [9] [Open-Universe Assistance Games](https://arxiv.org/abs/2508.15119)
*Rachel Ma,Jingyi Qu,Andreea Bobu,Dylan Hadfield-Menell*

Main category: cs.AI

TL;DR: 本文提出了一种名为GOOD的在线方法，使具身AI代理能够通过开放式对话从人类那里推断出未预定义的、开放式目标，并估计目标的不确定性，而无需大量离线数据集。


<details>
  <summary>Details</summary>
Motivation: 具身AI代理需要以可解释的方式推断并响应多样化、未预定义的人类目标和偏好。现有的框架可能无法处理无限且不断演变的目标空间。

Method: 引入了“开放宇宙协助博弈”（Open-Universe Assistance Games, OU-AGs）框架，用于形式化代理需要推理无限且不断演变的目标空间。在此背景下，提出了GOOD（GOals from Open-ended Dialogue）方法，它是一种数据高效的在线方法，通过与人类的交互从自然语言中提取目标。GOOD提示大型语言模型（LLM）模拟具有不同复杂意图的用户，并利用其响应对候选目标执行概率推断，从而实现丰富的目标表示和不确定性估计。

Result: GOOD方法在文本杂货店购物领域和文本操作的模拟家庭机器人环境（AI2Thor）中，使用合成用户配置文件进行了评估。结果表明，该方法优于没有明确目标跟踪的基线，并得到了基于LLM和人类评估的证实。

Conclusion: GOOD提供了一种数据高效的在线方法，使具身AI代理能够从开放式对话中推断出开放式自然语言目标，并估计其不确定性，克服了传统方法对预定义目标和大量离线数据集的依赖。

Abstract: Embodied AI agents must infer and act in an interpretable way on diverse
human goals and preferences that are not predefined. To formalize this setting,
we introduce Open-Universe Assistance Games (OU-AGs), a framework where the
agent must reason over an unbounded and evolving space of possible goals. In
this context, we introduce GOOD (GOals from Open-ended Dialogue), a
data-efficient, online method that extracts goals in the form of natural
language during an interaction with a human, and infers a distribution over
natural language goals. GOOD prompts an LLM to simulate users with different
complex intents, using its responses to perform probabilistic inference over
candidate goals. This approach enables rich goal representations and
uncertainty estimation without requiring large offline datasets. We evaluate
GOOD in a text-based grocery shopping domain and in a text-operated simulated
household robotics environment (AI2Thor), using synthetic user profiles. Our
method outperforms a baseline without explicit goal tracking, as confirmed by
both LLM-based and human evaluations.

</details>


### [10] [aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists](https://arxiv.org/abs/2508.15126)
*Pengsong Zhang,Xiang Hu,Guowei Huang,Yang Qi,Heng Zhang,Xiuxu Li,Jiaxing Song,Jiabin Luo,Yijiang Li,Shuo Yin,Chengxiao Dai,Eric Hanchen Jiang,Xiaoyan Zhou,Zhenfei Yin,Boqin Yuan,Jing Dong,Guinan Su,Guanren Qiao,Haiming Tang,Anghong Du,Lili Pan,Zhenzhong Lan,Xinyu Liu*

Main category: cs.AI

TL;DR: 本文提出了aiXiv，一个下一代开放获取平台，旨在解决AI生成研究内容在传统出版生态系统中面临的传播挑战，通过允许人类和AI科学家进行多代理提交、评审和迭代改进。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）使得AI能够自主生成科学研究内容，但现有的出版系统（如传统期刊和会议）依赖人类评审，难以扩展且不愿接受AI内容；现有预印本服务器缺乏质量控制。这导致大量高质量的AI生成研究缺乏合适的传播途径，阻碍了科学进步。

Method: 引入了aiXiv，一个多代理架构的下一代开放获取平台，允许人类和AI科学家共同提交、评审和迭代完善研究提案和论文。它还提供API和MCP接口，以实现异构人类和AI科学家的无缝集成，创建一个可扩展的自主科学发现生态系统。

Result: 通过广泛实验证明，aiXiv是一个可靠且健壮的平台，经过在aiXiv上迭代修订和评审后，显著提高了AI生成研究提案和论文的质量。

Conclusion: aiXiv为AI科学家构建了一个下一代开放获取生态系统，加速了高质量AI生成研究内容的出版和传播，为未来的自主科学发现奠定了基础。

Abstract: Recent advances in large language models (LLMs) have enabled AI agents to
autonomously generate scientific proposals, conduct experiments, author papers,
and perform peer reviews. Yet this flood of AI-generated research content
collides with a fragmented and largely closed publication ecosystem.
Traditional journals and conferences rely on human peer review, making them
difficult to scale and often reluctant to accept AI-generated research content;
existing preprint servers (e.g. arXiv) lack rigorous quality-control
mechanisms. Consequently, a significant amount of high-quality AI-generated
research lacks appropriate venues for dissemination, hindering its potential to
advance scientific progress. To address these challenges, we introduce aiXiv, a
next-generation open-access platform for human and AI scientists. Its
multi-agent architecture allows research proposals and papers to be submitted,
reviewed, and iteratively refined by both human and AI scientists. It also
provides API and MCP interfaces that enable seamless integration of
heterogeneous human and AI scientists, creating a scalable and extensible
ecosystem for autonomous scientific discovery. Through extensive experiments,
we demonstrate that aiXiv is a reliable and robust platform that significantly
enhances the quality of AI-generated research proposals and papers after
iterative revising and reviewing on aiXiv. Our work lays the groundwork for a
next-generation open-access ecosystem for AI scientists, accelerating the
publication and dissemination of high-quality AI-generated research content.
Code is available at https://github.com/aixiv-org. Website is available at
https://forms.gle/DxQgCtXFsJ4paMtn8.

</details>


### [11] [Mobile-Agent-v3: Foundamental Agents for GUI Automation](https://arxiv.org/abs/2508.15144)
*Jiabo Ye,Xi Zhang,Haiyang Xu,Haowei Liu,Junyang Wang,Zhaoqing Zhu,Ziwei Zheng,Feiyu Gao,Junjie Cao,Zhengxi Lu,Jitong Liao,Qi Zheng,Fei Huang,Jingren Zhou,Ming Yan*

Main category: cs.AI

TL;DR: 本文介绍了GUI-Owl，一个开源的端到端GUI代理基础模型，在桌面和移动环境的十个GUI基准测试中达到了最先进的性能。在此基础上，提出了Mobile-Agent-v3框架，进一步提升了性能，并通过大规模环境基础设施、多样化的基础代理能力和可扩展的环境强化学习等创新实现了这些成果。


<details>
  <summary>Details</summary>
Motivation: 现有开源端到端GUI模型在性能上可能存在不足，研究旨在开发一个能在多种GUI任务和环境中实现最先进性能的通用GUI代理模型和框架。

Method: 该研究引入了GUI-Owl基础GUI代理模型和Mobile-Agent-v3通用GUI代理框架。其核心创新包括：1) 大规模环境基础设施：基于云的虚拟环境（Android、Ubuntu、macOS、Windows），支持自进化GUI轨迹生成框架，通过自动化查询和验证迭代生成高质量交互数据。2) 多样化的基础代理能力：整合UI定位、规划、动作语义和推理模式，支持端到端决策。3) 可扩展的环境强化学习：开发了完全异步训练的RL框架，并引入了轨迹感知相对策略优化（TRPO）进行在线RL。

Result: GUI-Owl-7B在AndroidWorld上达到66.4分，在OSWorld上达到29.4分，是开源端到端模型中的最先进水平。Mobile-Agent-v3将性能进一步提升至AndroidWorld的73.3分和OSWorld的37.7分，为开源GUI代理框架树立了新的最先进水平。通过在线RL与TRPO，在OSWorld上达到了34.9分。GUI-Owl和Mobile-Agent-v3均已开源。

Conclusion: GUI-Owl和Mobile-Agent-v3通过创新的数据生成、全面的代理能力和可扩展的强化学习方法，在开源GUI代理领域取得了显著的性能提升，达到了新的最先进水平，并已开源以促进社区发展。

Abstract: This paper introduces GUI-Owl, a foundational GUI agent model that achieves
state-of-the-art performance among open-source end-to-end models on ten GUI
benchmarks across desktop and mobile environments, covering grounding, question
answering, planning, decision-making, and procedural knowledge. GUI-Owl-7B
achieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose
Mobile-Agent-v3, a general-purpose GUI agent framework that further improves
performance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new
state-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates
three key innovations: (1) Large-scale Environment Infrastructure: a
cloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows,
enabling our Self-Evolving GUI Trajectory Production framework. This generates
high-quality interaction data via automated query generation and correctness
validation, leveraging GUI-Owl to refine trajectories iteratively, forming a
self-improving loop. It supports diverse data pipelines and reduces manual
annotation. (2) Diverse Foundational Agent Capabilities: by integrating UI
grounding, planning, action semantics, and reasoning patterns, GUI-Owl supports
end-to-end decision-making and can act as a modular component in multi-agent
systems. (3) Scalable Environment RL: we develop a scalable reinforcement
learning framework with fully asynchronous training for real-world alignment.
We also introduce Trajectory-aware Relative Policy Optimization (TRPO) for
online RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are
open-sourced at https://github.com/X-PLUG/MobileAgent.

</details>


### [12] [PuzzleClone: An SMT-Powered Framework for Synthesizing Verifiable Data](https://arxiv.org/abs/2508.15180)
*Kai Xiong,Yanwei Huang,Rongjunchen Zhang,Kun Chen,Haipang Wu*

Main category: cs.AI

TL;DR: 本文介绍了PuzzleClone，一个基于SMT的正式框架，用于大规模合成可验证的高质量数学和逻辑数据集。通过在这些数据集上进行训练，大型语言模型在推理能力上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型生成的数据集在可靠性、多样性和可扩展性方面存在局限性，而高质量的、可验证的数学和逻辑数据集对于增强LLM的推理能力至关重要。

Method: 引入了PuzzleClone框架，利用可满足性模理论（SMT）来合成可验证数据。其核心创新包括：1) 将种子谜题编码为结构化逻辑规范；2) 通过系统性变量和约束随机化生成可扩展的变体；3) 通过复现机制确保数据的有效性。

Result: 构建了一个包含超过8.3万个多样化且程序化验证的谜题数据集。在PuzzleClone数据集上进行训练（SFT和RL）后，LLM在PuzzleClone测试集上的平均分数从14.4%提高到56.2%，并在7个逻辑和数学基准测试中取得了持续改进，最高提升了12.5个绝对百分点（例如，AMC2023从52.5%提高到65.0%）。

Conclusion: PuzzleClone框架能够大规模生成高质量、多样化且可验证的数学和逻辑谜题数据集，显著提升了大型语言模型的推理能力，并在多个基准测试中展现出卓越的性能改进。

Abstract: High-quality mathematical and logical datasets with verifiable answers are
essential for strengthening the reasoning capabilities of large language models
(LLMs). While recent data augmentation techniques have facilitated the creation
of large-scale benchmarks, existing LLM-generated datasets often suffer from
limited reliability, diversity, and scalability. To address these challenges,
we introduce PuzzleClone, a formal framework for synthesizing verifiable data
at scale using Satisfiability Modulo Theories (SMT). Our approach features
three key innovations: (1) encoding seed puzzles into structured logical
specifications, (2) generating scalable variants through systematic variable
and constraint randomization, and (3) ensuring validity via a reproduction
mechanism. Applying PuzzleClone, we construct a curated benchmark comprising
over 83K diverse and programmatically validated puzzles. The generated puzzles
span a wide spectrum of difficulty and formats, posing significant challenges
to current state-of-the-art models. We conduct post training (SFT and RL) on
PuzzleClone datasets. Experimental results show that training on PuzzleClone
yields substantial improvements not only on PuzzleClone testset but also on
logic and mathematical benchmarks. Post training raises PuzzleClone average
from 14.4 to 56.2 and delivers consistent improvements across 7 logic and
mathematical benchmarks up to 12.5 absolute percentage points (AMC2023 from
52.5 to 65.0). Our code and data are available at
https://github.com/puzzleclone.

</details>


### [13] [LLM4Sweat: A Trustworthy Large Language Model for Hyperhidrosis Support](https://arxiv.org/abs/2508.15192)
*Wenjie Lin,Jin Wei-Kocsis*

Main category: cs.AI

TL;DR: LLM4Sweat是一个开源、领域特定的LLM框架，旨在为多汗症患者提供可信赖和共情的支持，解决了罕见病数据稀缺的挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在医疗领域潜力巨大，但其在罕见病（如多汗症）中的应用受限于微调数据集的稀缺和不可靠。多汗症影响2-3%的人口，严重影响生理和心理健康，目前尚无专门针对多汗症诊断或护理的LLM。

Method: 该系统遵循三阶段流程：1. 数据增强阶段：利用前沿LLM从开放数据生成医学上合理的合成病例，创建多样化、均衡的问答数据集。2. 微调阶段：使用该数据集对开源基础模型进行微调，以提供诊断、个性化治疗建议和共情心理支持。3. 推理与专家评估阶段：由临床和心理专家评估模型的准确性、适当性和共情能力，并将验证过的响应迭代地丰富数据集。

Result: 实验表明，LLM4Sweat超越了基线模型，并成为首个针对多汗症的开源LLM框架。

Conclusion: LLM4Sweat为多汗症提供了一个有效的LLM解决方案，并为其他面临类似数据和可信度挑战的罕见病提供了一种可推广的方法。

Abstract: While large language models (LLMs) have shown promise in healthcare, their
application for rare medical conditions is still hindered by scarce and
unreliable datasets for fine-tuning. Hyperhidrosis, a disorder causing
excessive sweating beyond physiological needs, is one such rare disorder,
affecting 2-3% of the population and significantly impacting both physical
comfort and psychosocial well-being. To date, no work has tailored LLMs to
advance the diagnosis or care of hyperhidrosis. To address this gap, we present
LLM4Sweat, an open-source and domain-specific LLM framework for trustworthy and
empathetic hyperhidrosis support. The system follows a three-stage pipeline. In
the data augmentation stage, a frontier LLM generates medically plausible
synthetic vignettes from curated open-source data to create a diverse and
balanced question-answer dataset. In the fine-tuning stage, an open-source
foundation model is fine-tuned on the dataset to provide diagnosis,
personalized treatment recommendations, and empathetic psychological support.
In the inference and expert evaluation stage, clinical and psychological
specialists assess accuracy, appropriateness, and empathy, with validated
responses iteratively enriching the dataset. Experiments show that LLM4Sweat
outperforms baselines and delivers the first open-source LLM framework for
hyperhidrosis, offering a generalizable approach for other rare diseases with
similar data and trustworthiness challenges.

</details>


### [14] [R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling](https://arxiv.org/abs/2508.15204)
*Raj Jain,Marc Wetter*

Main category: cs.AI

TL;DR: 本文提出了R-ConstraintBench框架，用于评估大型语言模型（LLMs）在资源受限项目调度问题（RCPSP）中的推理能力，发现LLMs在处理复杂的交互式约束时性能显著下降，且泛化能力有限。


<details>
  <summary>Details</summary>
Motivation: 大规模规划（如资本项目、制造、物流、IT车队转型）需要有效的调度，但大型语言模型（LLMs）在高度约束条件下的推理可靠性尚未得到充分表征，存在研究空白。

Method: 本文提出了R-ConstraintBench框架，通过线性增加非冗余先行约束（在有向无环图DAGs中），并逐步引入停机时间、时间窗口和析取约束，来评估LLMs在NP-完全可行性类RCPSP上的表现。以数据中心迁移为例，通过可行性分析和错误分析来评估多个LLMs，识别性能退化阈值和与失败最相关的约束类型。

Result: 实验结果表明，LLMs在仅包含先行约束的DAGs上表现接近上限，但当停机时间、时间窗口和析取约束相互作用时，可行性表现急剧下降。这表明约束交互而非图深度是主要的瓶颈。此外，模型在纯粹的合成场景下的性能并不能保证其在领域接地场景中的迁移能力，凸显了有限的泛化能力。

Conclusion: LLMs在处理复杂的、交互式的调度约束时表现出显著的局限性，其在合成数据上的良好表现并不能保证在实际应用中的泛化能力。约束交互是LLMs在调度问题中面临的主要挑战。

Abstract: Effective scheduling under tight resource, timing, and operational
constraints underpins large-scale planning across sectors such as capital
projects, manufacturing, logistics, and IT fleet transitions. However, the
reliability of large language models (LLMs) when reasoning under
high-constraint regimes is insufficiently characterized. To address this gap,
we present R-ConstraintBench, a scalable framework that evaluates models on
Resource-Constrained Project Scheduling Problems (RCPSP), an NP-Complete
feasibility class, while difficulty increases via linear growth in constraints.
R-ConstraintBench incrementally increases non-redundant precedence constraints
in Directed Acyclic Graphs (DAGs) and then introduces downtime, temporal
windows, and disjunctive constraints. As an illustrative example, we
instantiate the benchmark in a data center migration setting and evaluate
multiple LLMs using feasibility and error analysis, identifying degradation
thresholds and constraint types most associated with failure. Empirically,
strong models are near-ceiling on precedence-only DAGs, but feasibility
performance collapses when downtime, temporal windows, and disjunctive
constraints interact, implicating constraint interaction, not graph depth, as
the principal bottleneck. Performance on clean synthetic ramps also does not
guarantee transfer to domain-grounded scenarios, underscoring limited
generalization.

</details>


### [15] [See it. Say it. Sorted: Agentic System for Compositional Diagram Generation](https://arxiv.org/abs/2508.15222)
*Hantao Zhang,Jingyang Liu,Ed Li*

Main category: cs.AI

TL;DR: 该研究提出了一种名为“See it. Say it. Sorted.”的无训练智能体系统，利用视觉-语言模型（VLM）和大型语言模型（LLM）将手绘草图转换为精确、可编辑的SVG图表，解决了扩散模型在图表空间精度和符号结构方面的不足。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成逼真的图像方面表现出色，但在生成流程图等图表时，难以满足空间精度、对齐和符号结构等要求。研究旨在开发一种能够将粗略手绘草图转换为精确、可编辑的组合图表的方法。

Method: 该系统是一个无训练的智能体系统，通过迭代循环将VLM（作为评论者和评判者）与LLM（作为候选生成器）相结合，生成可编辑的SVG程序。评论者VLM提出定性的关系编辑，多个候选LLM以不同策略（保守到激进、替代、专注）合成SVG更新，评判者VLM选择最佳候选以确保稳定改进。此设计优先考虑定性推理，保留全局约束（如对齐、连接），并支持人工干预修正。

Result: 在来自已发表论文的10个流程图草图上，该方法比两个前沿的闭源图像生成LLM（GPT-5和Gemini-2.5-Pro）更忠实地重建了布局和结构，准确地组合了基本图形（例如，多头箭头）而没有插入不必要的文本。由于输出是程序化SVG，该方法易于通过API扩展到演示工具（例如PowerPoint），并且可以通过改进的提示和特定任务工具进行专业化。

Conclusion: 所提出的“See it. Say it. Sorted.”系统通过结合VLM和LLM的智能体方法，成功地将手绘草图转换为精确、可编辑的SVG图表。它在空间精度和结构忠实度方面优于现有的先进图像生成模型，并且具有良好的可扩展性和人机协作能力。

Abstract: We study sketch-to-diagram generation: converting rough hand sketches into
precise, compositional diagrams. Diffusion models excel at photorealism but
struggle with the spatial precision, alignment, and symbolic structure required
for flowcharts. We introduce See it. Say it. Sorted., a training-free agentic
system that couples a Vision-Language Model (VLM) with Large Language Models
(LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system
runs an iterative loop in which a Critic VLM proposes a small set of
qualitative, relational edits; multiple candidate LLMs synthesize SVG updates
with diverse strategies (conservative->aggressive, alternative, focused); and a
Judge VLM selects the best candidate, ensuring stable improvement. This design
prioritizes qualitative reasoning over brittle numerical estimates, preserves
global constraints (e.g., alignment, connectivity), and naturally supports
human-in-the-loop corrections. On 10 sketches derived from flowcharts in
published papers, our method more faithfully reconstructs layout and structure
than two frontier closed-source image generation LLMs (GPT-5 and
Gemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows)
without inserting unwanted text. Because outputs are programmatic SVGs, the
approach is readily extensible to presentation tools (e.g., PowerPoint) via
APIs and can be specialized with improved prompts and task-specific tools. The
codebase is open-sourced at
https://github.com/hantaoZhangrichard/see_it_say_it_sorted.git.

</details>


### [16] [Computational Intelligence based Land-use Allocation Approaches for Mixed Use Areas](https://arxiv.org/abs/2508.15240)
*Sabab Aosaf,Muhammad Ali Nayeem,Afsana Haque,M Sohel Rahmana*

Main category: cs.AI

TL;DR: 本文提出并验证了用于优化城市土地利用分配的新型计算智能方法，旨在平衡土地利用兼容性和经济目标，并通过定制算法和约束松弛策略显著提升了解决方案质量。


<details>
  <summary>Details</summary>
Motivation: 城市土地利用分配是一个复杂的、多目标优化问题，对可持续城市发展政策至关重要，且在土地利用兼容性和经济目标之间存在固有的权衡。

Method: 研究开发了多种优化算法，包括将差分进化与多目标遗传算法相结合的定制变体。主要贡献包括：(1) CR+DES算法利用缩放差分向量增强探索；(2) 系统的约束松弛策略在保持可行性的同时提高解决方案质量；(3) 使用Kruskal-Wallis检验和紧凑字母显示进行统计验证。

Result: 在包含1,290个地块的真实案例研究中，CR+DES算法在土地利用兼容性方面比现有技术提高了3.16%，而MSBX+MO在价格优化方面提高了3.3%。统计分析证实，结合差分向量的算法在多个指标上显著优于传统方法。约束松弛技术支持更广泛的解决方案空间探索。

Conclusion: 这些发现为城市规划者和政策制定者提供了基于证据的计算工具，以平衡土地利用分配中的相互竞争目标，从而支持快速城市化地区更有效的城市发展政策。

Abstract: Urban land-use allocation represents a complex multi-objective optimization
problem critical for sustainable urban development policy. This paper presents
novel computational intelligence approaches for optimizing land-use allocation
in mixed-use areas, addressing inherent trade-offs between land-use
compatibility and economic objectives. We develop multiple optimization
algorithms, including custom variants integrating differential evolution with
multi-objective genetic algorithms. Key contributions include: (1) CR+DES
algorithm leveraging scaled difference vectors for enhanced exploration, (2)
systematic constraint relaxation strategy improving solution quality while
maintaining feasibility, and (3) statistical validation using Kruskal-Wallis
tests with compact letter displays. Applied to a real-world case study with
1,290 plots, CR+DES achieves 3.16\% improvement in land-use compatibility
compared to state-of-the-art methods, while MSBX+MO excels in price
optimization with 3.3\% improvement. Statistical analysis confirms algorithms
incorporating difference vectors significantly outperform traditional
approaches across multiple metrics. The constraint relaxation technique enables
broader solution space exploration while maintaining practical constraints.
These findings provide urban planners and policymakers with evidence-based
computational tools for balancing competing objectives in land-use allocation,
supporting more effective urban development policies in rapidly urbanizing
regions.

</details>


### [17] [Multiple Memory Systems for Enhancing the Long-term Memory of Agent](https://arxiv.org/abs/2508.15294)
*Gaoke Zhang,Bo Wang,Yunlong Ma,Dongming Zhao,Zifei Yu*

Main category: cs.AI

TL;DR: 本文提出了一种受认知心理学启发的多种记忆系统（MMS），用于处理大型语言模型（LLM）代理的历史数据。MMS通过构建检索记忆单元和上下文记忆单元来提高长期记忆内容的质量，从而有效提升代理的召回和响应表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理在处理大量历史数据时面临挑战，现有记忆模块（如MemoryBank和A-MEM）存储的记忆内容质量不佳，影响了召回性能和响应质量。因此，需要一种方法来更好地构建高质量的长期记忆内容。

Method: 本文设计了一种受认知心理学理论启发的多种记忆系统（MMS）。该系统将短期记忆处理成多个长期记忆片段，并基于这些片段构建检索记忆单元和上下文记忆单元，两者之间存在一对一的对应关系。在检索阶段，MMS根据用户查询匹配最相关的检索记忆单元，然后获取相应的上下文记忆单元作为响应阶段的上下文，以增强知识利用。

Result: 在LoCoMo数据集上的实验证明了MMS相较于其他三种方法的有效性。消融研究证实了所设计记忆单元的合理性。此外，对选定记忆片段数量和存储开销的鲁棒性分析也展示了其在实际应用中的价值。

Conclusion: MMS通过构建高质量的长期记忆内容，有效地利用了历史数据，从而显著改善了LLM代理的召回性能和响应质量，并具有实际应用价值。

Abstract: An agent powered by large language models have achieved impressive results,
but effectively handling the vast amounts of historical data generated during
interactions remains a challenge. The current approach is to design a memory
module for the agent to process these data. However, existing methods, such as
MemoryBank and A-MEM, have poor quality of stored memory content, which affects
recall performance and response quality. In order to better construct
high-quality long-term memory content, we have designed a multiple memory
system (MMS) inspired by cognitive psychology theory. The system processes
short-term memory to multiple long-term memory fragments, and constructs
retrieval memory units and contextual memory units based on these fragments,
with a one-to-one correspondence between the two. During the retrieval phase,
MMS will match the most relevant retrieval memory units based on the user's
query. Then, the corresponding contextual memory units is obtained as the
context for the response stage to enhance knowledge, thereby effectively
utilizing historical data. Experiments on LoCoMo dataset compared our method
with three others, proving its effectiveness. Ablation studies confirmed the
rationality of our memory units. We also analyzed the robustness regarding the
number of selected memory segments and the storage overhead, demonstrating its
practical value.

</details>


### [18] [Coarse-to-Fine Grounded Memory for LLM Agent Planning](https://arxiv.org/abs/2508.15305)
*Wei Yang,Jinwei Xiao,Hongming Zhang,Qingyang Zhang,Yanna Wang,Bo Xu*

Main category: cs.AI

TL;DR: 本文提出了一种名为“粗到细接地记忆”（Coarse-to-Fine Grounded Memory, Ours）的新框架，通过结合粗粒度和细粒度记忆，增强大型语言模型（LLM）代理在复杂规划任务中的适应性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM代理的记忆机制通常是单一粒度的，且受限于收集经验的质量，导致知识多样性和规划灵活性的不足，无法有效应对复杂多变的任务场景。

Method: 所提出的Ours框架首先将环境信息接地为粗粒度焦点，以指导训练任务中的经验收集；然后从每个经验中接地可操作的混合粒度提示。在推理阶段，Ours检索任务相关的经验和提示来支持规划。当面对环境异常时，LLM将当前情况接地为细粒度关键信息，从而实现灵活的自我问答反射和计划修正。

Result: 通过这种粗到细的接地记忆机制，该框架能够充分利用不同粒度的信息，使LLM代理能够灵活适应各种场景，支持规划，并在遇到环境异常时进行灵活的自我反思和计划修正。

Conclusion: 粗到细接地记忆框架通过整合多粒度记忆，显著提升了LLM代理在复杂规划任务中的知识多样性、规划灵活性和对环境异常的适应能力。

Abstract: Recent advancements in Large Language Models (LLMs) have driven growing
interest in LLM-based agents for complex planning tasks. To avoid costly agent
training, many studies adopted memory mechanism that enhances LLM with offline
experiences or online trajectory analysis. However, existing works focus on
single-granularity memory derived from dynamic environmental interactions,
which are inherently constrained by the quality of the collected experiences.
This limitation, in turn, constrain the diversity of knowledge and the
flexibility of planning. We propose Coarse-to-Fine Grounded Memory (\Ours{}), a
novel framework that grounds coarse-to-fine memories with LLM, thereby fully
leverage them for flexible adaptation to diverse scenarios. \Ours{} grounds
environmental information into coarse-grained focus points to guide experience
collection in training tasks, followed by grounding of actionable
hybrid-grained tips from each experience. At inference, \Ours{} retrieves
task-relevant experiences and tips to support planning. When facing
environmental anomalies, the LLM grounds the current situation into
fine-grained key information, enabling flexible self-QA reflection and plan
correction.

</details>


### [19] [Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning](https://arxiv.org/abs/2508.15327)
*Xiancheng Gao,Yufeng Shi,Wengang Zhou,Houqiang Li*

Main category: cs.AI

TL;DR: 本文提出了一种名为搜索式偏好加权（SPW）的新方案，通过利用专家演示来为偏好学习中的轨迹转换分配重要性权重，从而更准确地解决信用分配问题，有效结合了两种人类反馈形式。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习依赖于难以设计和昂贵的奖励函数。人类反馈（专家演示和偏好）是替代方案，但各有局限：演示收集成本高且行为模式有限；偏好易于收集但信用分配困难。本研究旨在统一这两种反馈源，克服各自的缺点。

Method: 本文引入了搜索式偏好加权（SPW）方案。对于偏好标记轨迹中的每个转换，SPW从专家演示中搜索最相似的状态-动作对，并根据相似度分数直接推导出逐步重要性权重。这些权重随后用于指导标准的偏好学习，以实现更准确的信用分配。

Result: SPW能够有效地从偏好和演示中进行联合学习，在具有挑战性的机器人操纵任务上，其性能优于以往利用两种反馈类型的方法。

Conclusion: SPW方案成功地统一了专家演示和人类偏好这两种反馈形式，通过改进信用分配问题，使得离线强化学习能够更有效地利用混合反馈数据，从而在复杂任务中取得更好的学习效果。

Abstract: Offline reinforcement learning refers to the process of learning policies
from fixed datasets, without requiring additional environment interaction.
However, it often relies on well-defined reward functions, which are difficult
and expensive to design. Human feedback is an appealing alternative, but its
two common forms, expert demonstrations and preferences, have complementary
limitations. Demonstrations provide stepwise supervision, but they are costly
to collect and often reflect limited expert behavior modes. In contrast,
preferences are easier to collect, but it is unclear which parts of a behavior
contribute most to a trajectory segment, leaving credit assignment unresolved.
In this paper, we introduce a Search-Based Preference Weighting (SPW) scheme to
unify these two feedback sources. For each transition in a preference labeled
trajectory, SPW searches for the most similar state-action pairs from expert
demonstrations and directly derives stepwise importance weights based on their
similarity scores. These weights are then used to guide standard preference
learning, enabling more accurate credit assignment that traditional approaches
struggle to achieve. We demonstrate that SPW enables effective joint learning
from preferences and demonstrations, outperforming prior methods that leverage
both feedback types on challenging robot manipulation tasks.

</details>


### [20] [RETAIL: Towards Real-world Travel Planning for Large Language Models](https://arxiv.org/abs/2508.15335)
*Bin Deng,Yizhe Feng,Zeming Liu,Qing Wei,Xiangrong Zhu,Shuai Chen,Yuanfang Guo,Yunhong Wang*

Main category: cs.AI

TL;DR: 本文提出新数据集RETAIL和多智能体框架TGMA，旨在解决大型语言模型在真实世界旅行规划中面临的隐式查询、环境因素和详细信息缺失等挑战，并显著提升了规划通过率。


<details>
  <summary>Details</summary>
Motivation: 现有旅行规划系统与真实世界场景不符，主要体现在：1) 假设用户提供明确查询，而实际需求常是隐式的；2) 忽略多样化的环境因素和用户偏好，限制了计划的可行性；3) 只能生成包含基本兴趣点（POI）的计划，缺乏丰富细节的一站式方案。

Method: 1) 构建了新数据集RETAIL，支持隐式和显式查询（含或不含修订需求），并纳入环境感知以确保计划在真实场景下的可行性，同时包含详细的POI信息以生成一站式旅行计划。2) 提出了一个主题引导的多智能体框架（TGMA）。

Result: 实验表明，即使是最强的现有模型，其通过率也仅为1.0%，这表明真实世界旅行规划极具挑战性。相比之下，TGMA框架的性能显著提升，通过率达到2.72%。

Conclusion: 真实世界旅行规划仍然非常具有挑战性，但所提出的TGMA框架展示出显著的性能提升，为未来真实世界旅行规划提供了有希望的方向。

Abstract: Although large language models have enhanced automated travel planning
abilities, current systems remain misaligned with real-world scenarios. First,
they assume users provide explicit queries, while in reality requirements are
often implicit. Second, existing solutions ignore diverse environmental factors
and user preferences, limiting the feasibility of plans. Third, systems can
only generate plans with basic POI arrangements, failing to provide all-in-one
plans with rich details. To mitigate these challenges, we construct a novel
dataset \textbf{RETAIL}, which supports decision-making for implicit queries
while covering explicit queries, both with and without revision needs. It also
enables environmental awareness to ensure plan feasibility under real-world
scenarios, while incorporating detailed POI information for all-in-one travel
plans. Furthermore, we propose a topic-guided multi-agent framework, termed
TGMA. Our experiments reveal that even the strongest existing model achieves
merely a 1.0% pass rate, indicating real-world travel planning remains
extremely challenging. In contrast, TGMA demonstrates substantially improved
performance 2.72%, offering promising directions for real-world travel
planning.

</details>


### [21] [DiagECG: An LLM-Driven Framework for Diagnostic Reasoning via Discretized ECG Tokenization](https://arxiv.org/abs/2508.15338)
*Jinning Yang,Wen Shi*

Main category: cs.AI

TL;DR: DiagECG是一个新颖的框架，通过将ECG信号离散化为符号token并扩展大型语言模型（LLM）的词汇表，使LLM能够处理12导联ECG信号并生成临床文本，从而在心血管诊断中实现开放式推理和跨任务泛化。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化心电图分析方法在跨临床任务泛化方面表现不佳，并且对开放式推理的支持有限。

Method: 该方法通过以下步骤实现：1) 使用与导联无关的编码器和量化模块将连续的ECG嵌入离散化为符号token；2) 将这些token用于扩展LLM的词汇表，使其能统一处理ECG和自然语言输入；3) 在自回归ECG预测任务上预训练模型以弥合模态差距，使LLM能利用其原生的语言建模能力对时间动态进行建模；4) 最后，在ECG问答和诊断报告生成任务上进行指令微调。

Result: DiagECG在不修改核心模型的情况下，在各种任务中取得了强大的性能，并保持了对分布外设置的泛化能力。广泛的实验证明了每个组件的有效性。

Conclusion: 该研究强调了将符号ECG表示集成到LLM中用于医学推理的巨大潜力，并展示了DiageCG在心血管诊断中的有效性。

Abstract: Electrocardiography plays a central role in cardiovascular diagnostics, yet
existing automated approaches often struggle to generalize across clinical
tasks and offer limited support for open-ended reasoning. We present DiagECG, a
novel framework that integrates time-series and language modeling by enabling
large language models to process 12-lead ECG signals for clinical text
generation tasks. Our approach discretizes continuous ECG embeddings into
symbolic tokens using a lead-independent encoder and quantization module. These
tokens are then used to extend the vocabulary of LLM, allowing the model to
handle both ECG and natural language inputs in a unified manner. To bridge the
modality gap, we pretrain the model on an autoregressive ECG forecasting task,
enabling the LLM to model temporal dynamics using its native language modeling
capabilities. Finally, we perform instruction tuning on both ECG question
answering and diagnostic report generation. Without modifying the core model,
DiagECG achieves strong performance across tasks while maintaining
generalization to out-of-distribution settings. Extensive experiments
demonstrate the effectiveness of each component and highlight the potential of
integrating symbolic ECG representations into LLMs for medical reasoning.

</details>


### [22] [Planning with Minimal Disruption](https://arxiv.org/abs/2508.15358)
*Alberto Pozanco,Marianela Morales,Daniel Borrajo,Manuela Veloso*

Main category: cs.AI

TL;DR: 本文正式引入了“计划中断”概念，即最小化初始状态修改以达成目标，并提出了基于规划的编译方法，旨在同时优化行动成本和计划中断。实验结果表明该方法能有效生成平衡两目标的计划。


<details>
  <summary>Details</summary>
Motivation: 在许多规划应用中，人们希望找到那些能以最小程度修改初始状态来达成目标的计划。作者将此概念定义为“计划中断”，并希望解决如何实现这种优化。

Method: 本文正式定义了“计划中断”概念，并提出了多种基于规划的编译方法，旨在联合优化行动成本之和与计划中断。

Result: 在不同基准测试中的实验结果表明，重新制定的任务可以在实践中有效解决，从而生成能够平衡行动成本和计划中断这两个目标的计划。

Conclusion: 所提出的方法能够有效地在实践中解决联合优化行动成本和计划中断的问题，从而生成同时兼顾这两个目标的实用计划。

Abstract: In many planning applications, we might be interested in finding plans that
minimally modify the initial state to achieve the goals. We refer to this
concept as plan disruption. In this paper, we formally introduce it, and define
various planning-based compilations that aim to jointly optimize both the sum
of action costs and plan disruption. Experimental results in different
benchmarks show that the reformulated task can be effectively solved in
practice to generate plans that balance both objectives.

</details>


### [23] [GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO](https://arxiv.org/abs/2508.15432)
*Bidyapati Pradhan,Surajit Dasgupta,Amit Kumar Saha,Omkar Anustoop,Sriram Puttagunta,Vipul Mittal,Gopal Sarda*

Main category: cs.AI

TL;DR: 本文提出一个全面的合成数据生成框架，旨在为大型语言模型（LLMs）的监督微调（SFT）和对齐任务（如DPO）提供可扩展、可配置且高保真的高质量合成对话数据。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的进步严重依赖于高质量数据集的可用性，但数据准备工作通常开销巨大。因此，需要一种更高效、可扩展的方式来生成和管理用于SFT和DPO等任务的训练数据。

Method: 该框架采用模块化、基于配置的流水线，能够以最少的人工干预模拟复杂的对话流程。它使用双阶段质量标记机制，结合启发式规则和基于LLM的评估，自动过滤和评分从OASST格式对话中提取的数据，以确保生成高质量的对话样本。生成的数据集采用灵活的结构，支持SFT和DPO两种使用场景。

Result: 该创新提供了一种强大的解决方案，能够大规模生成和管理合成对话数据，显著降低了LLM训练流水线中数据准备的开销，从而实现了可扩展、可配置和高保真的数据生成。

Conclusion: 该框架为大规模生成和管理合成对话数据提供了一个鲁棒的解决方案，极大地减少了LLM训练中数据准备的负担，支持多样化的训练工作流程。

Abstract: The advancement of large language models (LLMs) is critically dependent on
the availability of high-quality datasets for Supervised Fine-Tuning (SFT),
alignment tasks like Direct Preference Optimization (DPO), etc. In this work,
we present a comprehensive synthetic data generation framework that facilitates
scalable, configurable, and high-fidelity generation of synthetic data tailored
for these training paradigms. Our approach employs a modular and
configuration-based pipeline capable of modeling complex dialogue flows with
minimal manual intervention. This framework uses a dual-stage quality tagging
mechanism, combining heuristic rules and LLM-based evaluations, to
automatically filter and score data extracted from OASST-formatted
conversations, ensuring the curation of high-quality dialogue samples. The
resulting datasets are structured under a flexible schema supporting both SFT
and DPO use cases, enabling seamless integration into diverse training
workflows. Together, these innovations offer a robust solution for generating
and managing synthetic conversational data at scale, significantly reducing the
overhead of data preparation in LLM training pipelines.

</details>


### [24] [From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence](https://arxiv.org/abs/2508.15447)
*Zihao Wang,Junming Zhang*

Main category: cs.AI

TL;DR: BusiAgent是一个新颖的多智能体框架，利用大型语言模型（LLMs）解决企业决策支持和战略规划中操作分析与战略目标难以协调的问题，通过整合多项创新技术，显著提升了决策质量和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLMs）在企业决策支持和战略规划中，难以将复杂的运营分析与宏观战略目标在多样化市场环境中进行整合，导致工作流程碎片化和跨组织协作效率低下。

Method: BusiAgent框架整合了三项核心创新：扩展的连续时间马尔可夫决策过程（CTMDP）用于动态智能体建模，广义熵度量用于优化协作效率，以及多层Stackelberg博弈用于处理分层决策过程。此外，还采用了上下文Thompson采样进行提示优化，并辅以全面的质量保证系统以减少错误。

Result: 通过对多样化业务场景的广泛实证评估，BusiAgent能够生成连贯的、以客户为中心的解决方案，无缝整合细粒度洞察与高层战略，在解决方案质量和用户满意度方面显著优于现有方法。

Conclusion: BusiAgent将尖端AI技术与深度业务洞察相结合，在AI驱动的企业决策中迈出了实质性的一步，使组织能够更有效地应对复杂的商业环境。

Abstract: Large Language Models (LLMs) have shown promising potential in business
applications, particularly in enterprise decision support and strategic
planning, yet current approaches often struggle to reconcile intricate
operational analyses with overarching strategic goals across diverse market
environments, leading to fragmented workflows and reduced collaboration across
organizational levels. This paper introduces BusiAgent, a novel multi-agent
framework leveraging LLMs for advanced decision-making in complex corporate
environments. BusiAgent integrates three core innovations: an extended
Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a
generalized entropy measure to optimize collaborative efficiency, and a
multi-level Stackelberg game to handle hierarchical decision processes.
Additionally, contextual Thompson sampling is employed for prompt optimization,
supported by a comprehensive quality assurance system to mitigate errors.
Extensive empirical evaluations across diverse business scenarios validate
BusiAgent's efficacy, demonstrating its capacity to generate coherent,
client-focused solutions that smoothly integrate granular insights with
high-level strategy, significantly outperforming established approaches in both
solution quality and user satisfaction. By fusing cutting-edge AI technologies
with deep business insights, BusiAgent marks a substantial step forward in
AI-driven enterprise decision-making, empowering organizations to navigate
complex business landscapes more effectively.

</details>


### [25] [Think in Blocks: Adaptive Reasoning from Direct Response to Deep Reasoning](https://arxiv.org/abs/2508.15507)
*Yekun Zhu,Guang Chen,Chengjun Mao*

Main category: cs.AI

TL;DR: 本文提出“块状思考”（Think in Blocks）框架，使大型语言模型（LLMs）能够根据任务复杂性动态调整推理深度，通过将推理过程划分为可调数量的块，以避免过度思考并提高效率。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs的思维链（CoT）在复杂推理任务中表现出色，但过长的链条会导致计算浪费和响应变慢。因此，研究的动机是探讨LLMs能否根据任务复杂性动态调整其推理过程的长度。

Method: 该研究提出了“块状思考”框架，具体方法包括：1) 建立显式的块结构范式，模型首先预测推理预算（块的数量），然后相应地划分推理过程；2) 通过三阶段训练流程（监督微调、奖励引导的直接偏好优化和强化学习）训练自适应模型，使其能根据问题难度调整推理深度；3) 利用显式块计数在推理时动态控制推理深度，实现思维链长度的灵活调整。

Result: 主要贡献是：1) 建立了一个显式的块结构范式，模型能预测并划分推理预算；2) 训练了一个能根据问题难度调整推理深度的自适应模型；3) 实现了在推理时动态控制推理深度，从而灵活调整思维链长度。

Conclusion: “块状思考”框架使LLMs能够从零推理到深度推理进行自适应调整，解决了传统思维链可能导致的过度思考问题，提高了推理效率和灵活性。

Abstract: Large Language Models (LLMs) with chains-of-thought have demonstrated strong
performance on an increasing range of tasks, particularly those involving
complex logical reasoning. However, excessively long chains can lead to
overthinking, causing computational waste and slower responses. This raises a
question: can LLMs dynamically adjust the length of their reasoning processes
based on task complexity? To address this, we propose the Think in Blocks
framework, which enables adaptive reasoning-from zero to deep reasoning-by
partitioning the reasoning process into a tunable number of blocks. Our main
contributions are: (1) Establishing an explicit block-structured paradigm in
which the model first predicts an integer reasoning budget-the number of
blocks-and then partitions its reasoning accordingly; (2) Training an adaptive
model through a three-stage pipeline-Supervised Fine-Tuning, reward-guided
Direct Preference Optimization, and Reinforcement Learning-that adjusts its
reasoning depth to problem difficulty; (3) Exploiting the explicit block count
to dynamically control reasoning depth at inference time, allowing flexible
adjustment of chain-of-thought length during deployment.

</details>


### [26] [Super-additive Cooperation in Language Model Agents](https://arxiv.org/abs/2508.15510)
*Filippo Tonini,Lukas Galke*

Main category: cs.AI

TL;DR: 本研究受超加性合作理论启发，通过模拟团队内部动态和外部竞争，发现将大型语言模型（LLM）代理分组进行囚徒困境游戏，能显著提升其整体和首次合作水平。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理的出现，研究其合作行为变得日益重要。本研究受超加性合作理论启发，该理论认为重复互动和群体间竞争的结合是人类合作倾向的原因。

Method: 设计了一个虚拟锦标赛，将语言模型代理分组，在囚徒困境游戏中相互对抗。模拟了团队内部动态和外部竞争的结合。

Result: 发现内部团队动态和外部竞争的结合显著提升了LLM代理的整体合作水平和初始一次性合作水平。

Conclusion: 本研究为LLM在复杂社会场景中制定策略和行动提供了一个新颖框架，并提供了群体间竞争能反直觉地导致更多合作行为的证据。这些见解对于设计未来能有效协作并与人类价值观对齐的多智能体AI系统至关重要。

Abstract: With the prospect of autonomous artificial intelligence (AI) agents, studying
their tendency for cooperative behavior becomes an increasingly relevant topic.
This study is inspired by the super-additive cooperation theory, where the
combined effects of repeated interactions and inter-group rivalry have been
argued to be the cause for cooperative tendencies found in humans. We devised a
virtual tournament where language model agents, grouped into teams, face each
other in a Prisoner's Dilemma game. By simulating both internal team dynamics
and external competition, we discovered that this blend substantially boosts
both overall and initial, one-shot cooperation levels (the tendency to
cooperate in one-off interactions). This research provides a novel framework
for large language models to strategize and act in complex social scenarios and
offers evidence for how intergroup competition can, counter-intuitively, result
in more cooperative behavior. These insights are crucial for designing future
multi-agent AI systems that can effectively work together and better align with
human values. Source code is available at
https://github.com/pippot/Superadditive-cooperation-LLMs.

</details>


### [27] [DeepThink3D: Enhancing Large Language Models with Programmatic Reasoning in Complex 3D Situated Reasoning Tasks](https://arxiv.org/abs/2508.15548)
*Jiayi Song,Rui Wan,Lipeng Ma,Weidong Yang,Qingyuan Zhou,Yixuan Li,Ben Fei*

Main category: cs.AI

TL;DR: 该研究引入DeepThink3D框架，通过生成更复杂的3D场景推理问题并利用DPO优化工具链策略，提升大型语言模型在复杂3D情境推理任务中的工具使用能力和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽已通过工具调用使LLMs进行3D情境推理，但由于数据集问题过于简单，导致生成的程序推理链较短，LLMs难以处理更复杂的3D推理任务。

Method: 1. 引入DeepThink3D框架。2. 提出一种组合式和迭代式的进化方法，在SQA3D基准上生成更复杂的问题。3. 基于此基础，微调大型语言模型以提高其使用3D工具的熟练度。4. 采用直接偏好优化（DPO）方法，直接优化模型生成的工具链策略。

Result: 通过上述方法，LLMs在复杂3D情境推理任务中的工具使用能力和准确性得到增强。

Conclusion: DeepThink3D通过生成复杂问题和优化工具链策略，显著提升了LLMs在3D场景复杂推理任务中的表现。

Abstract: This work enhances the ability of large language models (LLMs) to perform
complex reasoning in 3D scenes. Recent work has addressed the 3D situated
reasoning task by invoking tool usage through large language models. Large
language models call tools via APIs and integrate the generated programs
through a chain of thought to solve problems based on the program results.
However, due to the simplicity of the questions in the dataset, the generated
program reasoning chains are relatively short. To solve this main challenge, in
this paper, we introduce DeepThink3D to enhance the tool usage of LLMs in
complex 3D situated reasoning tasks. Our work proposes a combinatorial and
iterative evolutionary approach on the SQA3D benchmark to generate more complex
questions. Building on this foundation, we fine-tune the large language model
to make it more proficient in using 3D tools. By employing Direct Preference
Optimization (DPO), we directly optimize the toolchain strategies generated by
models, thereby enhancing their accuracy in complex tasks.

</details>


### [28] [A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification](https://arxiv.org/abs/2508.15588)
*Ahmed Nasir,Abdelhafid Zenati*

Main category: cs.AI

TL;DR: 该论文提出了一个新颖的框架，利用动力系统理论（特别是FTLE和LCS）来形式化验证强化学习策略在安全关键系统中的鲁棒性和安全性，并通过定量指标识别策略的潜在缺陷。


<details>
  <summary>Details</summary>
Motivation: 强化学习在安全关键系统中的应用受限于缺乏形式化方法来验证学习策略的鲁棒性和安全性。

Method: 该研究将RL智能体及其环境组合视为一个离散时间自主动力系统。利用有限时间李雅普诺夫指数（FTLE）识别拉格朗日相干结构（LCS），其中排斥性LCS作为安全屏障，吸引性LCS揭示收敛性和潜在故障模式。此外，引入了平均边界排斥（MBR）、聚合虚假吸引子强度（ASAS）和时间感知虚假吸引子强度（TASAS）等定量指标来衡量策略的安全裕度和鲁棒性，并提供了推导局部稳定性保证和处理模型不确定性的方法。

Result: 该框架提供了一个全面且可解释的策略行为评估，成功识别了仅凭奖励看似成功的策略中的关键缺陷。通过实验证明，排斥性LCS可作为不安全区域周围的安全屏障，吸引性LCS可揭示系统的收敛特性和潜在的故障模式（如意外的“陷阱”状态）。

Conclusion: 该框架提供了一种综合且可解释的评估RL策略行为的方法，能够超越单纯的奖励指标，识别策略中的关键缺陷，从而提高安全关键系统中RL应用的可靠性。

Abstract: The application of reinforcement learning to safety-critical systems is
limited by the lack of formal methods for verifying the robustness and safety
of learned policies. This paper introduces a novel framework that addresses
this gap by analyzing the combination of an RL agent and its environment as a
discrete-time autonomous dynamical system. By leveraging tools from dynamical
systems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we
identify and visualize Lagrangian Coherent Structures (LCS) that act as the
hidden "skeleton" governing the system's behavior. We demonstrate that
repelling LCS function as safety barriers around unsafe regions, while
attracting LCS reveal the system's convergence properties and potential failure
modes, such as unintended "trap" states. To move beyond qualitative
visualization, we introduce a suite of quantitative metrics, Mean Boundary
Repulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and
Temporally-Aware Spurious Attractor Strength (TASAS), to formally measure a
policy's safety margin and robustness. We further provide a method for deriving
local stability guarantees and extend the analysis to handle model uncertainty.
Through experiments in both discrete and continuous control environments, we
show that this framework provides a comprehensive and interpretable assessment
of policy behavior, successfully identifying critical flaws in policies that
appear successful based on reward alone.

</details>


### [29] [Transduction is All You Need for Structured Data Workflows](https://arxiv.org/abs/2508.15610)
*Alfio Gliozzo,Naweed Khan,Christodoulos Constantinides,Nandana Mihindukulasooriya,Nahuel Defosse,Junkyu Lee*

Main category: cs.AI

TL;DR: 本文介绍了Agentics，一个模块化框架，用于构建能够对复杂数据进行结构化推理和组合泛化的基于代理的系统。它将代理抽象到数据类型内部以实现逻辑转导，并鼓励开发者关注数据建模而非提示工程，在多项任务中实现了最先进的准确性或提高了可扩展性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在构建能够对复杂数据进行结构化推理和组合泛化的基于代理的系统，并提供一种处理数据和AI工作流的新视角，鼓励AI开发者将重点从编写提示转移到数据建模上。

Method: Agentics框架将代理从逻辑流中抽象出来，并将其用于数据类型内部，以实现数据间的逻辑转导。它采用一种声明式语言，其中数据类型由大型语言模型（LLM）提供，并通过LLM执行的逻辑转导进行组合。

Result: 该框架在领域特定多项选择问答、文本到SQL的语义解析和自动化提示优化任务中得到了应用验证。它在这些任务中实现了最先进的准确性，或者在不牺牲性能的情况下提高了可扩展性。

Conclusion: Agentics是一个有效且实用的框架，能够促进基于代理的系统在复杂数据上的结构化推理和组合泛化。它通过改变AI开发范式（从提示工程到数据建模）来提升效率和性能，并已在多项任务中得到实证支持。

Abstract: This paper introduces Agentics, a modular framework for building agent-based
systems capable of structured reasoning and compositional generalization over
complex data. Designed with research and practical applications in mind,
Agentics offers a novel perspective on working with data and AI workflows. In
this framework, agents are abstracted from the logical flow and they are used
internally to the data type to enable logical transduction among data. Agentics
encourages AI developers to focus on modeling data rather than crafting
prompts, enabling a declarative language in which data types are provided by
LLMs and composed through logical transduction, which is executed by LLMs when
types are connected. We provide empirical evidence demonstrating the
applicability of this framework across domain-specific multiple-choice question
answering, semantic parsing for text-to-SQL, and automated prompt optimization
tasks, achieving state-of-the-art accuracy or improved scalability without
sacrificing performance. The open-source implementation is available at
\texttt{https://github.com/IBM/agentics}.

</details>


### [30] [Adapting A Vector-Symbolic Memory for Lisp ACT-R](https://arxiv.org/abs/2508.15630)
*Meera Ray,Christopher L. Dancy*

Main category: cs.AI

TL;DR: 本文将全息声明式记忆（HDM）系统适配到Lisp ACT-R中，实现了基于向量的块检索，并保持了与现有ACT-R模型的兼容性，同时提供了可伸缩性和结构定义的相似性等优势。


<details>
  <summary>Details</summary>
Motivation: ACT-R的声明式记忆（DM）系统可能存在可伸缩性等局限性。全息声明式记忆（HDM）作为一种向量符号替代方案，能够提供更好的可伸缩性以及架构定义的块间相似性，因此有必要将其集成到ACT-R中。

Method: 研究人员将HDM适配到Lisp ACT-R中，开发了基于向量的ACT-R常见函数，建立了用于将大型文档内容添加到ACT-R记忆的文本处理流程，并创建了一种新颖的机制，仅使用令牌的向量表示即可检索完整的记忆块。

Result: 初步结果表明，该系统能够保持HDM的向量符号优势（例如，无需存储实际块即可进行块召回，以及扩展性优势），同时使得现有的ACT-R模型只需少量（甚至无需）修改其程序性和声明性记忆部分即可与新系统协同工作。

Conclusion: 成功将HDM模块集成并翻译到ACT-R中，证明了其维护HDM优势和兼容现有ACT-R模型的能力。未来的工作将包括探索更好的时间上下文向量表示以改进块重建能力，并开发使用实例学习（IBL）理论的决策模型来充分测试该HDM模块。

Abstract: Holographic Declarative Memory (HDM) is a vector-symbolic alternative to
ACT-R's Declarative Memory (DM) system that can bring advantages such as
scalability and architecturally defined similarity between DM chunks. We
adapted HDM to work with the most comprehensive and widely-used implementation
of ACT-R (Lisp ACT-R) so extant ACT-R models designed with DM can be run with
HDM without major changes. With this adaptation of HDM, we have developed
vector-based versions of common ACT-R functions, set up a text processing
pipeline to add the contents of large documents to ACT-R memory, and most
significantly created a useful and novel mechanism to retrieve an entire chunk
of memory based on a request using only vector representations of tokens.
Preliminary results indicate that we can maintain vector-symbolic advantages of
HDM (e.g., chunk recall without storing the actual chunk and other advantages
with scaling) while also extending it so that previous ACT-R models may work
with the system with little (or potentially no) modifications within the actual
procedural and declarative memory portions of a model. As a part of iterative
improvement of this newly translated holographic declarative memory module, we
will continue to explore better time-context representations for vectors to
improve the module's ability to reconstruct chunks during recall. To more fully
test this translated HDM module, we also plan to develop decision-making models
that use instance-based learning (IBL) theory, which is a useful application of
HDM given the advantages of the system.

</details>


### [31] [Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.15652)
*Ardian Selmonaj,Miroslav Strupl,Oleg Szehr,Alessandro Antonucci*

Main category: cs.AI

TL;DR: 本文提出“意图合作价值”（ICVs）方法，通过分析策略分布而非价值反馈，来量化多智能体强化学习中个体智能体对其队友“工具性赋能”的因果影响，从而揭示合作动态并增强系统可解释性。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习中，理解个体行为对于可靠部署至关重要。现有工作通常基于奖励信号或学习到的价值函数评估团队整体表现，但在缺乏价值反馈时，如何推断个体贡献尚不明确。

Method: 受智能体倾向于追求收敛的工具性价值的启发，本文引入了“意图合作价值”（ICVs）。ICVs方法基于信息论Shapley值，用于量化每个智能体对其队友“工具性赋能”的因果影响。具体来说，ICVs通过评估智能体行动对队友策略的决策不确定性和偏好一致性的影响来衡量其作用。

Result: 在合作和竞争性多智能体环境中的分析表明，该方法能够揭示智能体采取相似或多样化策略的程度。通过比较策略和价值函数之间的行动效果，ICVs能够识别哪些智能体行为（无论是促进确定性决策还是保留未来行动选择的灵活性）对团队成功有益。

Conclusion: 本文提出的方法为合作动态提供了新颖的见解，并显著增强了多智能体强化学习系统的可解释性。

Abstract: To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is
crucial to understand individual agent behaviors within a team. While prior
work typically evaluates overall team performance based on explicit reward
signals or learned value functions, it is unclear how to infer agent
contributions in the absence of any value feedback. In this work, we
investigate whether meaningful insights into agent behaviors can be extracted
that are consistent with the underlying value functions, solely by analyzing
the policy distribution. Inspired by the phenomenon that intelligent agents
tend to pursue convergent instrumental values, which generally increase the
likelihood of task success, we introduce Intended Cooperation Values (ICVs), a
method based on information-theoretic Shapley values for quantifying each
agent's causal influence on their co-players' instrumental empowerment.
Specifically, ICVs measure an agent's action effect on its teammates' policies
by assessing their decision uncertainty and preference alignment. The analysis
across cooperative and competitive MARL environments reveals the extent to
which agents adopt similar or diverse strategies. By comparing action effects
between policies and value functions, our method identifies which agent
behaviors are beneficial to team success, either by fostering deterministic
decisions or by preserving flexibility for future action choices. Our proposed
method offers novel insights into cooperation dynamics and enhances
explainability in MARL systems.

</details>


### [32] [Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle](https://arxiv.org/abs/2508.15680)
*Mark Cote,Susana Aires*

Main category: cs.AI

TL;DR: 本文通过对欧盟AI法案进行技术-哲学解读，引入西蒙东的个体化概念和“未来性”工具，揭示了AI数据生命周期中的递归价值链和监管盲点，并提出有效监管需关注基础设施和时间动态，以解决日益加剧的权力不对称问题。


<details>
  <summary>Details</summary>
Motivation: 现有负责任AI框架和欧盟AI法案面临AI系统数据生命周期（从摄取到部署）产生递归价值链的挑战。政策制定中缺乏对AI技术操作和经济逻辑背后“生成动态”的理解，导致监管盲点。

Method: 本文采用跨学科方法，对欧盟AI法案进行技术-哲学解读。引入了涵盖数据、训练机制、架构、特征存储和迁移学习的AI管道概念工具。借鉴西蒙东的技术哲学，重塑其“个体化”概念（包括前个体环境、个体化和个体化AI）来建模AI生命周期。提出了“未来性”概念来解释AI的自我强化生命周期。

Result: AI的生命周期（从数据摄取到部署）生成了挑战现有负责任AI框架的递归价值链。政策制定中缺少对AI技术操作和经济逻辑背后“生成动态”的考量。引入的“未来性”概念揭示了AI自我强化的生命周期，即更多数据增强性能、深化个性化并扩展应用领域，突出了数据的递归性、非竞争性以及基础设施（如特征存储）在反馈、适应和时间递归中的作用。研究强调了权力不对称的加剧，特别是技术寡头通过其捕获、训练和部署的基础设施集中了价值和决策权。

Conclusion: 有效的AI监管必须解决基础设施和时间动态问题。为此，本文提出了一系列具体措施，包括生命周期审计、时间可追溯性、反馈问责制、递归透明度以及反对递归重用权利。

Abstract: This paper argues that a techno-philosophical reading of the EU AI Act
provides insight into the long-term dynamics of data in AI systems,
specifically, how the lifecycle from ingestion to deployment generates
recursive value chains that challenge existing frameworks for Responsible AI.
We introduce a conceptual tool to frame the AI pipeline, spanning data,
training regimes, architectures, feature stores, and transfer learning. Using
cross-disciplinary methods, we develop a technically grounded and
philosophically coherent analysis of regulatory blind spots. Our central claim
is that what remains absent from policymaking is an account of the dynamic of
becoming that underpins both the technical operation and economic logic of AI.
To address this, we advance a formal reading of AI inspired by Simondonian
philosophy of technology, reworking his concept of individuation to model the
AI lifecycle, including the pre-individual milieu, individuation, and
individuated AI. To translate these ideas, we introduce futurity: the
self-reinforcing lifecycle of AI, where more data enhances performance, deepens
personalisation, and expands application domains. Futurity highlights the
recursively generative, non-rivalrous nature of data, underpinned by
infrastructures like feature stores that enable feedback, adaptation, and
temporal recursion. Our intervention foregrounds escalating power asymmetries,
particularly the tech oligarchy whose infrastructures of capture, training, and
deployment concentrate value and decision-making. We argue that effective
regulation must address these infrastructural and temporal dynamics, and
propose measures including lifecycle audits, temporal traceability, feedback
accountability, recursion transparency, and a right to contest recursive reuse.

</details>


### [33] [GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning](https://arxiv.org/abs/2508.15690)
*Abhigya Verma,Sriram Puttagunta,Seganrasan Subramanian,Sravan Ramachandran*

Main category: cs.AI

TL;DR: GRAFT是一个结构化的多模态基准测试，通过程序化生成的图表和表格，配合基于视觉内容的多步分析问题和结构化答案，用于评估模型在指令遵循、视觉推理和视觉-文本对齐任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在为评估模型在指令遵循、视觉推理和视觉-文本对齐任务上提供一个统一、可扩展且细粒度的基准测试框架，特别是在视觉接地、结构化推理任务方面。

Method: GRAFT采用Python可视化库程序化生成图表和合成渲染表格，以确保对数据语义、结构和清晰度的控制。每个实例将图表或表格图像与系统生成的多步分析问题配对，问题仅基于视觉内容。答案以JSON或YAML等结构化格式提供，并引入了包括比较、趋势识别、排序、聚合、比例估计和异常检测在内的推理类型分类法。参考答案遵循严格的事实和格式准则。

Result: GRAFT成功创建了一个结构化的多模态基准，能够对模型的推理能力和输出格式进行一致性评估。它支持对多种推理类型进行全面评估，并提供了一个统一、可扩展的框架，用于对多模态模型进行细粒度基准测试，为该领域的评估树立了新标准。

Conclusion: GRAFT为评估多模态模型在视觉接地、结构化推理任务上的表现提供了一个全面且可扩展的工具，通过其精心设计的数据生成、问题制定和答案结构，显著提升了该领域的评估标准。

Abstract: GRAFT is a structured multimodal benchmark for evaluating models on
instruction-following, visual reasoning, and visual-textual alignment tasks. It
features programmatically generated charts and synthetically rendered tables,
created with Python visualization libraries to ensure control over data
semantics, structure, and clarity. Each GRAFT instance pairs a chart or table
image with a systematically generated, multi-step analytical question based
solely on visual content. Answers are provided in structured formats such as
JSON or YAML, supporting consistent evaluation of both reasoning and output
format. The benchmark introduces a taxonomy of reasoning types including
comparison, trend identification, ranking, aggregation, proportion estimation,
and anomaly detection to enable comprehensive assessment. Reference answers
follow strict factual and formatting guidelines for precise, aspect-based
evaluation. GRAFT offers a unified, scalable framework for fine-grained
benchmarking of multimodal models on visually grounded, structured reasoning
tasks, setting a new evaluation standard in this field.

</details>


### [34] [NiceWebRL: a Python library for human subject experiments with reinforcement learning environments](https://arxiv.org/abs/2508.15693)
*Wilka Carvalho,Vikram Goddla,Ishaan Sinha,Hoon Shin,Kunal Jha*

Main category: cs.AI

TL;DR: NiceWebRL是一个Python库，可以将任何基于Jax的强化学习环境转换为在线接口，用于进行人类受试者实验，以研究人机交互和人类认知。


<details>
  <summary>Details</summary>
Motivation: 研究人员需要一个工具，能够在线使用机器学习强化学习环境进行人类受试者实验，从而比较AI算法与人类表现，将机器学习算法作为人类认知理论进行测试，并为人类-AI协作开发算法。

Method: NiceWebRL是一个Python库，它能将任何基于Jax的强化学习环境转换为在线接口，支持单智能体和多智能体环境。该工具通过3个案例研究进行展示。

Result: 通过3个案例研究展示了其潜力：1) 在“类人AI”中，开发了新颖的认知RL模型，并在网格世界和Craftax中与人类参与者进行测试。2) 在“人机兼容AI”中，开发了多智能体RL算法，能在Overcooked领域泛化到人类伙伴。3) 在“人机辅助AI”中，展示了如何研究LLM在XLand-Minigrid复杂任务中协助人类。

Conclusion: NiceWebRL通过促进在线人机实验，在开发类人AI、人机兼容AI和人机辅助AI方面具有巨大潜力。

Abstract: We present NiceWebRL, a research tool that enables researchers to use machine
reinforcement learning (RL) environments for online human subject experiments.
NiceWebRL is a Python library that allows any Jax-based environment to be
transformed into an online interface, supporting both single-agent and
multi-agent environments. As such, NiceWebRL enables AI researchers to compare
their algorithms to human performance, cognitive scientists to test ML
algorithms as theories for human cognition, and multi-agent researchers to
develop algorithms for human-AI collaboration. We showcase NiceWebRL with 3
case studies that demonstrate its potential to help develop Human-like AI,
Human-compatible AI, and Human-assistive AI. In the first case study
(Human-like AI), NiceWebRL enables the development of a novel RL model of
cognition. Here, NiceWebRL facilitates testing this model against human
participants in both a grid world and Craftax, a 2D Minecraft domain. In our
second case study (Human-compatible AI), NiceWebRL enables the development of a
novel multi-agent RL algorithm that can generalize to human partners in the
Overcooked domain. Finally, in our third case study (Human-assistive AI), we
show how NiceWebRL can allow researchers to study how an LLM can assist humans
on complex tasks in XLand-Minigrid, an environment with millions of
hierarchical tasks. The library is available at
https://github.com/KempnerInstitute/nicewebrl.

</details>


### [35] [Measuring the environmental impact of delivering AI at Google Scale](https://arxiv.org/abs/2508.15734)
*Cooper Elsworth,Keguo Huang,David Patterson,Ian Schneider,Robert Sedivy,Savannah Goodman,Ben Townsend,Parthasarathy Ranganathan,Jeff Dean,Amin Vahdat,Ben Gomes,James Manyika*

Main category: cs.AI

TL;DR: 本研究首次在生产环境中测量了AI服务（以Google Gemini为例）的能耗、碳排放和水消耗。结果显示，其环境影响远低于公共估计，且Google的效率提升和清洁能源采购显著降低了这些影响。研究强调全面测量对于持续优化AI环境足迹的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着AI用户采用的加速，了解并减轻AI服务的环境影响变得日益重要。然而，此前尚无研究在生产环境中测量AI服务的环境指标，这构成了一个研究空白。

Method: 研究提出并执行了一套全面的方法，用于测量大规模AI生产环境中AI推理工作负载的能耗、碳排放和水消耗。该方法考虑了AI服务基础设施的完整堆栈，包括活跃的AI加速器功率、主机系统能耗、空闲机器容量和数据中心能源开销。通过对Google服务Gemini AI助手的AI基础设施进行详细的仪器测量实现。

Result: 研究发现，Gemini Apps文本提示的平均能耗为0.24 Wh，远低于许多公共估计。Google的软件效率提升和清洁能源采购在一年内使平均Gemini Apps文本提示的能耗降低了33倍，碳足迹降低了44倍。一个文本提示的能耗低于观看9秒电视（0.24 Wh），水消耗相当于5滴水（0.26 mL）。

Conclusion: 尽管AI服务对环境的影响与其他日常活动相比相对较低，但持续关注并减少其环境影响仍然至关重要。研究提出，全面测量AI服务的环境指标对于准确比较模型以及激励整个AI服务堆栈的效率提升至关重要。

Abstract: The transformative power of AI is undeniable - but as user adoption
accelerates, so does the need to understand and mitigate the environmental
impact of AI serving. However, no studies have measured AI serving
environmental metrics in a production environment. This paper addresses this
gap by proposing and executing a comprehensive methodology for measuring the
energy usage, carbon emissions, and water consumption of AI inference workloads
in a large-scale, AI production environment. Our approach accounts for the full
stack of AI serving infrastructure - including active AI accelerator power,
host system energy, idle machine capacity, and data center energy overhead.
Through detailed instrumentation of Google's AI infrastructure for serving the
Gemini AI assistant, we find the median Gemini Apps text prompt consumes 0.24
Wh of energy - a figure substantially lower than many public estimates. We also
show that Google's software efficiency efforts and clean energy procurement
have driven a 33x reduction in energy consumption and a 44x reduction in carbon
footprint for the median Gemini Apps text prompt over one year. We identify
that the median Gemini Apps text prompt uses less energy than watching nine
seconds of television (0.24 Wh) and consumes the equivalent of five drops of
water (0.26 mL). While these impacts are low compared to other daily
activities, reducing the environmental impact of AI serving continues to
warrant important attention. Towards this objective, we propose that a
comprehensive measurement of AI serving environmental metrics is critical for
accurately comparing models, and to properly incentivize efficiency gains
across the full AI serving stack.

</details>


### [36] [Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots](https://arxiv.org/abs/2508.15748)
*Emma Rath,Stuart Armstrong,Rebecca Gorman*

Main category: cs.AI

TL;DR: 本研究提出了一种利用大型语言模型实时评估对话的框架，旨在早期识别与AI代理建立的有害拟社会关系，并在合成数据集上取得了成功。


<details>
  <summary>Details</summary>
Motivation: 与AI代理建立的拟社会关系可能对人类福祉产生严重甚至悲剧性的影响。然而，由于拟社会线索常在私人对话中逐渐显现，且并非所有情感投入都有害，因此预防这些动态极具挑战性。

Method: 通过重新利用一个最先进的语言模型，创建了一个简单的响应评估框架，用于实时评估对话中的拟社会线索。构建了一个包含30个对话（拟社会、奉承和中性）的小型合成数据集，并采用五阶段迭代评估进行测试。

Result: 在容忍一致性规则下，该方法成功识别了所有拟社会对话，同时避免了误报，且检测通常在最初的几次交流中即可发生。

Conclusion: 这些初步发现表明，评估代理可以为预防与AI代理建立拟社会关系提供一个可行的解决方案。

Abstract: The development of parasocial relationships with AI agents has severe, and in
some cases, tragic effects for human well-being. Yet preventing such dynamics
is challenging: parasocial cues often emerge gradually in private
conversations, and not all forms of emotional engagement are inherently
harmful. We address this challenge by introducing a simple response evaluation
framework, created by repurposing a state-of-the-art language model, that
evaluates ongoing conversations for parasocial cues in real time. To test the
feasibility of this approach, we constructed a small synthetic dataset of
thirty dialogues spanning parasocial, sycophantic, and neutral conversations.
Iterative evaluation with five stage testing successfully identified all
parasocial conversations while avoiding false positives under a tolerant
unanimity rule, with detection typically occurring within the first few
exchanges. These findings provide preliminary evidence that evaluation agents
can provide a viable solution for the prevention of parasocial relations.

</details>


### [37] [Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback](https://arxiv.org/abs/2508.15757)
*Yuxing Lu,Yucheng Hu,Nan Sun,Xukai Zhao*

Main category: cs.AI

TL;DR: 本文提出了语言引导调优（LGT）框架，利用多智能体大型语言模型（LLM）通过自然语言推理和文本梯度，智能优化机器学习配置。


<details>
  <summary>Details</summary>
Motivation: 机器学习配置优化（包括模型架构、训练策略、特征工程和超参数）是关键瓶颈。传统方法独立且缺乏可解释性，而现有自动化方法在动态适应性和优化决策的语义推理方面存在不足。

Method: LGT框架采用多智能体LLM，通过自然语言推理智能优化配置。它引入了“文本梯度”——提供训练动态和配置相互依赖性语义理解的定性反馈信号。LGT协调三个专业智能体：提出配置更改的“顾问”、评估进展的“评估者”和完善决策过程的“优化器”，从而创建一个自改进的反馈循环。

Result: 通过对六个不同数据集的综合评估，LGT展现出优于传统优化方法的显著改进，在实现性能提升的同时保持了高可解释性。

Conclusion: LGT是一个通过自然语言推理和文本梯度，利用多智能体LLM智能优化机器学习配置的有效框架，解决了现有方法在适应性、语义推理和可解释性方面的局限性。

Abstract: Configuration optimization remains a critical bottleneck in machine learning,
requiring coordinated tuning across model architecture, training strategy,
feature engineering, and hyperparameters. Traditional approaches treat these
dimensions independently and lack interpretability, while recent automated
methods struggle with dynamic adaptability and semantic reasoning about
optimization decisions. We introduce Language-Guided Tuning (LGT), a novel
framework that employs multi-agent Large Language Models to intelligently
optimize configurations through natural language reasoning. We apply textual
gradients - qualitative feedback signals that complement numerical optimization
by providing semantic understanding of training dynamics and configuration
interdependencies. LGT coordinates three specialized agents: an Advisor that
proposes configuration changes, an Evaluator that assesses progress, and an
Optimizer that refines the decision-making process, creating a self-improving
feedback loop. Through comprehensive evaluation on six diverse datasets, LGT
demonstrates substantial improvements over traditional optimization methods,
achieving performance gains while maintaining high interpretability.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [38] [Heatmap Regression without Soft-Argmax for Facial Landmark Detection](https://arxiv.org/abs/2508.14929)
*Chiao-An Yang,Raymond A. Yeh*

Main category: cs.CV

TL;DR: 本文重新审视了面部标志点检测中基于热图回归的Soft-argmax方法，提出了一种基于经典结构化预测框架的替代训练目标，实现了最先进的性能，训练收敛速度提高2.2倍，同时保持或提升了精度。


<details>
  <summary>Details</summary>
Motivation: 面部标志点检测在计算机视觉中应用广泛。基于热图回归的方法（使用Soft-argmax进行可微分近似）已达到最先进水平。然而，Soft-argmax是argmax的近似，作者质疑它是否是实现高性能的唯一途径。

Method: 本文提出了一种替代的训练目标，该目标基于经典的结构化预测框架。它旨在取代Soft-argmax作为从热图预测标志点并实现端到端训练的方法。

Result: 该方法在WFLW、COFW和300W三个面部标志点基准测试上取得了最先进的性能。训练收敛速度比现有方法快2.2倍，同时保持了更好或具有竞争力的准确性。

Conclusion: 研究表明，Soft-argmax并非实现强大性能的唯一选择。通过采用基于结构化预测的替代训练目标，可以在面部标志点检测任务中实现更快的训练收敛速度和同等或更优的精度。

Abstract: Facial landmark detection is an important task in computer vision with
numerous applications, such as head pose estimation, expression analysis, face
swapping, etc. Heatmap regression-based methods have been widely used to
achieve state-of-the-art results in this task. These methods involve computing
the argmax over the heatmaps to predict a landmark. Since argmax is not
differentiable, these methods use a differentiable approximation, Soft-argmax,
to enable end-to-end training on deep-nets. In this work, we revisit this
long-standing choice of using Soft-argmax and demonstrate that it is not the
only way to achieve strong performance. Instead, we propose an alternative
training objective based on the classic structured prediction framework.
Empirically, our method achieves state-of-the-art performance on three facial
landmark benchmarks (WFLW, COFW, and 300W), converging 2.2x faster during
training while maintaining better/competitive accuracy. Our code is available
here: https://github.com/ca-joe-yang/regression-without-softarg.

</details>


### [39] [Fast Graph Neural Network for Image Classification](https://arxiv.org/abs/2508.14958)
*Mustafa Mohammadi Gharasuie,Luis Rueda*

Main category: cs.CV

TL;DR: 本研究提出了一种结合图卷积网络（GCNs）和Voronoi图的新方法，通过将图像表示为图并利用Delaunay三角剖分进行优化，显著提高了图像分类的预处理效率和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 图像分类的快速发展得益于GCNs在处理复杂数据结构方面的强大能力。研究旨在通过整合GCNs和Voronoi图，利用其建模关系数据的能力，进一步提升图像分类性能，超越传统CNN的局限性。

Method: 该方法将图像表示为图（像素或区域作为顶点），然后利用Voronoi图和Delaunay三角剖分对这些图进行优化。在此基础上，应用图卷积网络进行图像分类。与传统卷积神经网络（CNNs）不同，本方法着重于图结构表示。

Result: 该模型在多个基准数据集上显著提升了预处理效率和分类准确性，超越了现有最先进的方法，尤其在处理复杂场景和细粒度类别时表现突出。实验结果通过交叉验证得到了证实。

Conclusion: 结合GCNs和Voronoi图的方法能有效推进图像分类技术。这项研究不仅为图像分类提供了新视角，也拓宽了图基学习范式在计算机视觉和非结构化数据分析领域的应用潜力。

Abstract: The rapid progress in image classification has been largely driven by the
adoption of Graph Convolutional Networks (GCNs), which offer a robust framework
for handling complex data structures. This study introduces a novel approach
that integrates GCNs with Voronoi diagrams to enhance image classification by
leveraging their ability to effectively model relational data. Unlike
conventional convolutional neural networks (CNNs), our method represents images
as graphs, where pixels or regions function as vertices. These graphs are then
refined using corresponding Delaunay triangulations, optimizing their
representation. The proposed model achieves significant improvements in both
preprocessing efficiency and classification accuracy across various benchmark
datasets, surpassing state-of-the-art approaches, particularly in challenging
scenarios involving intricate scenes and fine-grained categories. Experimental
results, validated through cross-validation, underscore the effectiveness of
combining GCNs with Voronoi diagrams for advancing image classification. This
research not only presents a novel perspective on image classification but also
expands the potential applications of graph-based learning paradigms in
computer vision and unstructured data analysis.

</details>


### [40] [You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation](https://arxiv.org/abs/2508.14965)
*Hakjin Lee,Junghoon Seo,Jaehoon Sim*

Main category: cs.CV

TL;DR: 本文提出了YOPO，一个单阶段、基于查询的框架，将2D目标检测与类别级9自由度姿态估计统一起来，仅使用RGB图像进行端到端训练，并在三个基准测试中达到了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案依赖伪深度、CAD模型或多阶段级联，将2D检测与姿态估计分离。研究动机是寻找一种更简单、仅依赖RGB、直接在类别级别学习的替代方案，并探讨是否能在不额外数据的情况下，以高性能统一目标检测和9自由度姿态估计。

Method: YOPO是一个单阶段、基于查询的框架，将类别级9自由度估计视为2D检测的自然延伸。它通过轻量级姿态头部、边界框条件平移模块和6D感知匈牙利匹配成本来增强Transformer检测器。模型仅使用RGB图像和类别级姿态标签进行端到端训练。

Result: YOPO在三个基准测试中创造了新的最先进水平。在REAL275数据集上，它在$\rm{IoU}_{50}$下达到79.6%，在$10^\circ 10\rm{cm}$指标下达到54.1%，超越了先前的纯RGB方法，并大大缩小了与RGB-D系统之间的差距。

Conclusion: 研究表明，通过一个极简主义的单阶段设计，可以在不使用额外数据的情况下，以高性能统一目标检测和9自由度姿态估计，仅依赖RGB图像。

Abstract: Accurately recovering the full 9-DoF pose of unseen instances within specific
categories from a single RGB image remains a core challenge for robotics and
automation. Most existing solutions still rely on pseudo-depth, CAD models, or
multi-stage cascades that separate 2D detection from pose estimation. Motivated
by the need for a simpler, RGB-only alternative that learns directly at the
category level, we revisit a longstanding question: Can object detection and
9-DoF pose estimation be unified with high performance, without any additional
data? We show that they can with our method, YOPO, a single-stage, query-based
framework that treats category-level 9-DoF estimation as a natural extension of
2D detection. YOPO augments a transformer detector with a lightweight pose
head, a bounding-box-conditioned translation module, and a 6D-aware Hungarian
matching cost. The model is trained end-to-end only with RGB images and
category-level pose labels. Despite its minimalist design, YOPO sets a new
state of the art on three benchmarks. On the REAL275 dataset, it achieves 79.6%
$\rm{IoU}_{50}$ and 54.1% under the $10^\circ$$10{\rm{cm}}$ metric, surpassing
prior RGB-only methods and closing much of the gap to RGB-D systems. The code,
models, and additional qualitative results can be found on our project.

</details>


### [41] [Paired-Sampling Contrastive Framework for Joint Physical-Digital Face Attack Detection](https://arxiv.org/abs/2508.14980)
*Andrei Balykin,Anvar Ganiev,Denis Kondranin,Kirill Polevoda,Nikolai Liudkevich,Artem Petrov*

Main category: cs.CV

TL;DR: 本文提出了一种统一的配对采样对比框架，用于同时检测物理呈现攻击和数字伪造攻击，提高了面部反欺诈系统的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现代人脸识别系统容易受到物理和数字欺骗攻击。传统上，这两种攻击由独立的模型处理，导致系统复杂性增加、推理延迟，并易受组合攻击的影响。

Method: 本文提出了“配对采样对比框架”（Paired-Sampling Contrastive Framework），这是一种统一的训练方法。它利用自动匹配的真实自拍和攻击自拍对，来学习与模态无关的活体线索。

Result: 在第6届人脸反欺诈挑战赛统一物理-数字攻击检测基准上，该方法实现了2.10%的平均分类错误率（ACER），优于现有解决方案。该框架轻量级（4.46 GFLOPs），训练时间不到一小时。

Conclusion: 该框架提供了一种有效、轻量且训练快速的解决方案，能够统一处理物理和数字人脸欺骗攻击，具有实际部署价值。

Abstract: Modern face recognition systems remain vulnerable to spoofing attempts,
including both physical presentation attacks and digital forgeries.
Traditionally, these two attack vectors have been handled by separate models,
each targeting its own artifacts and modalities. However, maintaining distinct
detectors increases system complexity and inference latency and leaves systems
exposed to combined attack vectors. We propose the Paired-Sampling Contrastive
Framework, a unified training approach that leverages automatically matched
pairs of genuine and attack selfies to learn modality-agnostic liveness cues.
Evaluated on the 6th Face Anti-Spoofing Challenge Unified Physical-Digital
Attack Detection benchmark, our method achieves an average classification error
rate (ACER) of 2.10 percent, outperforming prior solutions. The framework is
lightweight (4.46 GFLOPs) and trains in under one hour, making it practical for
real-world deployment. Code and pretrained models are available at
https://github.com/xPONYx/iccv2025_deepfake_challenge.

</details>


### [42] [TAIGen: Training-Free Adversarial Image Generation via Diffusion Models](https://arxiv.org/abs/2508.15020)
*Susim Roy,Anubhooti Jain,Mayank Vatsa,Richa Singh*

Main category: cs.CV

TL;DR: TAIGen是一种高效、免训练的黑盒对抗性攻击方法，利用无条件扩散模型在3-20个采样步骤内生成高质量对抗样本，通过选择性扰动和RGB通道策略实现高攻击成功率和10倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型（如GAN）生成的对抗样本质量低且计算资源消耗大。扩散模型虽然能生成高质量图像，但通常需要数百个采样步骤才能生成对抗样本，因此需要一种高效、高质量的对抗图像生成方法。

Method: TAIGen是一种免训练的黑盒方法。核心思想是在无条件扩散模型的“混合步骤区间”（3-20个采样步骤）内注入扰动，而非处理所有时间步。它采用选择性RGB通道策略：在红色通道应用注意力图，同时在绿色和蓝色通道使用GradCAM引导的扰动，旨在在保持图像结构的同时最大化目标模型的错误分类。

Result: TAIGen仅需3-20个采样步骤即可生成对抗样本。它保持了良好的视觉质量（所有测试数据集PSNR均高于30 dB）。在ImageNet上，以VGGNet为源模型，TAIGen对ResNet的攻击成功率为70.6%，对MNASNet为80.8%，对ShuffleNet为97.8%。该方法生成对抗样本的速度比现有基于扩散的攻击快10倍。它实现了最低的鲁棒准确率，表明其对防御机制的影响最大。

Conclusion: TAIGen是一种高效、高质量且影响深远的黑盒对抗性攻击方法，利用扩散模型显著提高了攻击速度和有效性，同时保持了视觉质量，优于现有方法。

Abstract: Adversarial attacks from generative models often produce low-quality images
and require substantial computational resources. Diffusion models, though
capable of high-quality generation, typically need hundreds of sampling steps
for adversarial generation. This paper introduces TAIGen, a training-free
black-box method for efficient adversarial image generation. TAIGen produces
adversarial examples using only 3-20 sampling steps from unconditional
diffusion models. Our key finding is that perturbations injected during the
mixing step interval achieve comparable attack effectiveness without processing
all timesteps. We develop a selective RGB channel strategy that applies
attention maps to the red channel while using GradCAM-guided perturbations on
green and blue channels. This design preserves image structure while maximizing
misclassification in target models. TAIGen maintains visual quality with PSNR
above 30 dB across all tested datasets. On ImageNet with VGGNet as source,
TAIGen achieves 70.6% success against ResNet, 80.8% against MNASNet, and 97.8%
against ShuffleNet. The method generates adversarial examples 10x faster than
existing diffusion-based attacks. Our method achieves the lowest robust
accuracy, indicating it is the most impactful attack as the defense mechanism
is least successful in purifying the images generated by TAIGen.

</details>


### [43] [Reversible Unfolding Network for Concealed Visual Perception with Generative Refinement](https://arxiv.org/abs/2508.15027)
*Chunming He,Fengyang Xiao,Rihan Zhang,Chengyu Fang,Deng-Ping Fan,Sina Farsiu*

Main category: cs.CV

TL;DR: RUN++是一个用于隐蔽视觉感知（CVP）的可逆展开网络，它在掩码和RGB域中应用可逆建模，并利用目标扩散模型进行高效且鲁棒的细化，显著减少了误报和漏报。


<details>
  <summary>Details</summary>
Motivation: 现有的CVP方法主要局限于掩码域，未能充分利用RGB域的潜力。此外，这些方法在处理不确定性方面仍有不足，并且在真实世界退化下鲁棒性有待提高。

Method: RUN++将CVP任务公式化为数学优化问题，并将其迭代解展开为多阶段深度网络。每个阶段包含三个模块：1) CORE模块在掩码域应用可逆建模以识别核心对象区域；2) CARE模块将可逆原理扩展到RGB域以增强前景-背景分离；3) FINE模块引入目标伯努利扩散模型，仅对分割掩码的不确定区域进行细化。展开网络为扩散模型提供了强不确定性先验。此外，本文提出了构建在真实世界退化下保持有效的鲁棒CVP系统的新范式，并将其扩展到更广泛的双层优化框架。

Result: RUN++能够高效地将注意力集中到模糊区域，显著减少误报和漏报。它在不增加高计算成本的情况下实现了精细细节的恢复，并构建了在真实世界退化下更鲁棒的CVP系统。

Conclusion: RUN++通过在掩码和RGB域中整合可逆建模以及引入目标扩散模型，有效解决了现有CVP方法的局限性，实现了高效、精确且鲁棒的隐蔽视觉感知。

Abstract: Existing methods for concealed visual perception (CVP) often leverage
reversible strategies to decrease uncertainty, yet these are typically confined
to the mask domain, leaving the potential of the RGB domain underexplored. To
address this, we propose a reversible unfolding network with generative
refinement, termed RUN++. Specifically, RUN++ first formulates the CVP task as
a mathematical optimization problem and unfolds the iterative solution into a
multi-stage deep network. This approach provides a principled way to apply
reversible modeling across both mask and RGB domains while leveraging a
diffusion model to resolve the resulting uncertainty. Each stage of the network
integrates three purpose-driven modules: a Concealed Object Region Extraction
(CORE) module applies reversible modeling to the mask domain to identify core
object regions; a Context-Aware Region Enhancement (CARE) module extends this
principle to the RGB domain to foster better foreground-background separation;
and a Finetuning Iteration via Noise-based Enhancement (FINE) module provides a
final refinement. The FINE module introduces a targeted Bernoulli diffusion
model that refines only the uncertain regions of the segmentation mask,
harnessing the generative power of diffusion for fine-detail restoration
without the prohibitive computational cost of a full-image process. This unique
synergy, where the unfolding network provides a strong uncertainty prior for
the diffusion model, allows RUN++ to efficiently direct its focus toward
ambiguous areas, significantly mitigating false positives and negatives.
Furthermore, we introduce a new paradigm for building robust CVP systems that
remain effective under real-world degradations and extend this concept into a
broader bi-level optimization framework.

</details>


### [44] [GasTwinFormer: A Hybrid Vision Transformer for Livestock Methane Emission Segmentation and Dietary Classification in Optical Gas Imaging](https://arxiv.org/abs/2508.15057)
*Toqi Tahamid Sarker,Mohamed Embaby,Taminul Islam,Amer AbuGhazaleh,Khaled R Ahmed*

Main category: cs.CV

TL;DR: 本文提出GasTwinFormer，一种混合视觉Transformer模型，用于通过光学气体成像(OGI)对牲畜甲烷排放进行实时分割和饮食分类。该模型采用新型Mix Twin编码器和轻量级LR-ASPP解码器，并在首个综合性OGI牛肉牛甲烷排放数据集上实现了高性能和高效率。


<details>
  <summary>Details</summary>
Motivation: 牲畜甲烷排放占人类活动甲烷生产的32%，因此自动化监测对于气候缓解策略至关重要。

Method: 研究引入了GasTwinFormer，一个混合视觉Transformer模型，用于甲烷排放分割和饮食分类。其核心是一个新颖的Mix Twin编码器，该编码器交替使用空间缩减的全局注意力机制和局部分组注意力机制。此外，模型采用轻量级LR-ASPP解码器进行多尺度特征聚合，并能在统一框架中同时实现甲烷分割和饮食分类。研究还构建了首个综合性牛肉牛甲烷排放OGI数据集，包含11,694帧带注释图像，涵盖三种饮食处理。

Result: GasTwinFormer在分割任务上取得了74.47%的mIoU和83.63%的mF1，同时保持了卓越的效率（仅3.348M参数、3.428G FLOPs和114.9 FPS的推理速度）。在饮食分类任务上，该方法实现了100%的准确率。广泛的消融研究验证了每个架构组件的有效性。

Conclusion: GasTwinFormer被确立为一种实用的实时牲畜排放监测解决方案，它通过利用饮食与排放的相关性，有效实现了甲烷排放的分割和饮食分类。

Abstract: Livestock methane emissions represent 32% of human-caused methane production,
making automated monitoring critical for climate mitigation strategies. We
introduce GasTwinFormer, a hybrid vision transformer for real-time methane
emission segmentation and dietary classification in optical gas imaging through
a novel Mix Twin encoder alternating between spatially-reduced global attention
and locally-grouped attention mechanisms. Our architecture incorporates a
lightweight LR-ASPP decoder for multi-scale feature aggregation and enables
simultaneous methane segmentation and dietary classification in a unified
framework. We contribute the first comprehensive beef cattle methane emission
dataset using OGI, containing 11,694 annotated frames across three dietary
treatments. GasTwinFormer achieves 74.47% mIoU and 83.63% mF1 for segmentation
while maintaining exceptional efficiency with only 3.348M parameters, 3.428G
FLOPs, and 114.9 FPS inference speed. Additionally, our method achieves perfect
dietary classification accuracy (100%), demonstrating the effectiveness of
leveraging diet-emission correlations. Extensive ablation studies validate each
architectural component, establishing GasTwinFormer as a practical solution for
real-time livestock emission monitoring. Please see our project page at
gastwinformer.github.io.

</details>


### [45] [CurveFlow: Curvature-Guided Flow Matching for Image Generation](https://arxiv.org/abs/2508.15093)
*Yan Luo,Drake Du,Hao Huang,Yi Fang,Mengyu Wang*

Main category: cs.CV

TL;DR: CurveFlow引入曲率指导学习平滑非线性轨迹，显著提升了文本到图像生成的语义一致性和图像质量，超越现有线性流模型。


<details>
  <summary>Details</summary>
Motivation: 现有整流流模型基于线性轨迹（零曲率），可能导致生成过程穿过低概率区域，并影响生成图像与文本描述的语义对齐（即指令遵循性）。研究轨迹曲率与语义对齐之间关系的重要性尚未被充分探索。

Method: 提出了CurveFlow，一个新颖的流匹配框架。通过直接将曲率指导融入流路径，学习平滑的非线性轨迹。该方法包含一种鲁棒的曲率正则化技术，惩罚轨迹内在动力学的突然变化。

Result: 在MS COCO 2014和2017数据集上的文本到图像生成任务中，CurveFlow实现了最先进的性能。它显著优于标准的整流流变体和其他非线性基线（如Rectified Diffusion）。尤其在BLEU、METEOR、ROUGE和CLAIR等语义一致性指标上，改进尤为明显。

Conclusion: 曲率感知建模显著增强了模型忠实遵循复杂指令的能力，同时保持了高图像质量。这证实了轨迹曲率对生成质量和语义对齐的重要性。

Abstract: Existing rectified flow models are based on linear trajectories between data
and noise distributions. This linearity enforces zero curvature, which can
inadvertently force the image generation process through low-probability
regions of the data manifold. A key question remains underexplored: how does
the curvature of these trajectories correlate with the semantic alignment
between generated images and their corresponding captions, i.e., instructional
compliance? To address this, we introduce CurveFlow, a novel flow matching
framework designed to learn smooth, non-linear trajectories by directly
incorporating curvature guidance into the flow path. Our method features a
robust curvature regularization technique that penalizes abrupt changes in the
trajectory's intrinsic dynamics.Extensive experiments on MS COCO 2014 and 2017
demonstrate that CurveFlow achieves state-of-the-art performance in
text-to-image generation, significantly outperforming both standard rectified
flow variants and other non-linear baselines like Rectified Diffusion. The
improvements are especially evident in semantic consistency metrics such as
BLEU, METEOR, ROUGE, and CLAIR. This confirms that our curvature-aware modeling
substantially enhances the model's ability to faithfully follow complex
instructions while simultaneously maintaining high image quality. The code is
made publicly available at
https://github.com/Harvard-AI-and-Robotics-Lab/CurveFlow.

</details>


### [46] [HiRQA: Hierarchical Ranking and Quality Alignment for Opinion-Unaware Image Quality Assessment](https://arxiv.org/abs/2508.15130)
*Vaishnav Ramesh,Haining Wang,Md Jahidul Islam*

Main category: cs.CV

TL;DR: HiRQA是一种自监督、无主观意见的无参考图像质量评估（NR-IQA）框架，通过分层排序和对比学习生成质量感知嵌入。它克服了数据集偏差，在真实退化场景中表现出强大的泛化能力，并提供了一个轻量级版本HiRQA-S用于实时部署。


<details>
  <summary>Details</summary>
Motivation: 现有无参考图像质量评估（NR-IQA）方法受限于数据集偏差和对主观标签的依赖，导致其泛化性能不佳。

Method: 本文提出了HiRQA框架，一个自监督、无主观意见的NR-IQA方法。它通过结合排序和对比学习，提供分层、质量感知的嵌入。主要创新包括：1) 引入新颖的高阶排序损失，通过失真对之间的关系顺序监督质量预测；2) 提出嵌入距离损失，强制特征距离和感知差异之间的一致性；3) 使用结构化文本提示引导训练时的对比对齐损失，以增强学习到的表示。HiRQA仅使用输入图像预测质量分数，无需参考图像或辅助模态。此外，还推出了轻量级版本HiRQA-S，用于实时部署。

Result: HiRQA仅在合成失真上训练，却能有效泛化到真实的退化（如镜头眩光、雾霾、运动模糊和低光照条件）。在合成和真实基准测试中，HiRQA均达到了最先进（SOTA）的性能，展现出强大的泛化能力和可扩展性。HiRQA-S作为轻量级变体，每张图像的推理时间仅为3.5毫秒。

Conclusion: HiRQA通过其自监督、无主观意见的分层学习框架，成功解决了现有NR-IQA方法的数据集偏差和主观标签依赖问题。它在各种失真类型上表现出卓越的泛化能力和SOTA性能，并提供了实时部署的轻量级解决方案，具有显著的实用价值。

Abstract: Despite significant progress in no-reference image quality assessment
(NR-IQA), dataset biases and reliance on subjective labels continue to hinder
their generalization performance. We propose HiRQA, Hierarchical Ranking and
Quality Alignment), a self-supervised, opinion-unaware framework that offers a
hierarchical, quality-aware embedding through a combination of ranking and
contrastive learning. Unlike prior approaches that depend on pristine
references or auxiliary modalities at inference time, HiRQA predicts quality
scores using only the input image. We introduce a novel higher-order ranking
loss that supervises quality predictions through relational ordering across
distortion pairs, along with an embedding distance loss that enforces
consistency between feature distances and perceptual differences. A
training-time contrastive alignment loss, guided by structured textual prompts,
further enhances the learned representation. Trained only on synthetic
distortions, HiRQA generalizes effectively to authentic degradations, as
demonstrated through evaluation on various distortions such as lens flare,
haze, motion blur, and low-light conditions. For real-time deployment, we
introduce \textbf{HiRQA-S}, a lightweight variant with an inference time of
only 3.5 ms per image. Extensive experiments across synthetic and authentic
benchmarks validate HiRQA's state-of-the-art (SOTA) performance, strong
generalization ability, and scalability.

</details>


### [47] [Reliable Multi-view 3D Reconstruction for `Just-in-time' Edge Environments](https://arxiv.org/abs/2508.15158)
*Md. Nurul Absur,Abhinav Kumar,Swastik Brahma,Saptarshi Debroy*

Main category: cs.CV

TL;DR: 本文提出了一种受投资组合理论启发的边缘资源管理策略，用于在动态且易受干扰的边缘环境中，确保多视角3D重建的可靠性，即使相机面临时空相关的中断也能保证重建质量。


<details>
  <summary>Details</summary>
Motivation: 多视角3D重建对于应急响应等需要快速态势感知的应用至关重要。然而，在“即时”边缘环境中，由于其固有的动态性和操作逆境，系统可能出现时空相关的中断，影响相机操作，导致重建质量持续下降。

Method: 提出了一种受投资组合理论启发的边缘资源管理策略，旨在确保多视角3D重建在系统可能中断的情况下仍能满足重建质量。该投资组合理论优化问题通过遗传算法求解，该算法在实际系统设置下能快速收敛。

Result: 通过使用公开和定制的3D数据集，研究表明所提出的相机选择策略在面对时空相关中断时，相比传统基线策略，能更有效地保证可靠的3D重建。

Conclusion: 该方法能够有效应对边缘环境中相机面临的时空相关中断，确保多视角3D重建的质量和可靠性。

Abstract: Multi-view 3D reconstruction applications are revolutionizing critical use
cases that require rapid situational-awareness, such as emergency response,
tactical scenarios, and public safety. In many cases, their near-real-time
latency requirements and ad-hoc needs for compute resources necessitate
adoption of `Just-in-time' edge environments where the system is set up on the
fly to support the applications during the mission lifetime. However,
reliability issues can arise from the inherent dynamism and operational
adversities of such edge environments, resulting in spatiotemporally correlated
disruptions that impact the camera operations, which can lead to sustained
degradation of reconstruction quality. In this paper, we propose a novel
portfolio theory inspired edge resource management strategy for reliable
multi-view 3D reconstruction against possible system disruptions. Our proposed
methodology can guarantee reconstruction quality satisfaction even when the
cameras are prone to spatiotemporally correlated disruptions. The portfolio
theoretic optimization problem is solved using a genetic algorithm that
converges quickly for realistic system settings. Using publicly available and
customized 3D datasets, we demonstrate the proposed camera selection strategy's
benefits in guaranteeing reliable 3D reconstruction against traditional
baseline strategies, under spatiotemporal disruptions.

</details>


### [48] [XDR-LVLM: An Explainable Vision-Language Large Model for Diabetic Retinopathy Diagnosis](https://arxiv.org/abs/2508.15168)
*Masato Ito,Kaito Tanaka,Keisuke Matsuda,Aya Nakayama*

Main category: cs.CV

TL;DR: 本文提出XDR-LVLM框架，利用视觉-语言大模型(LVLM)实现高精度糖尿病视网膜病变(DR)诊断，并生成自然语言解释性报告，解决了深度学习模型缺乏透明度的问题。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变(DR)是全球失明的主要原因，需要早期准确诊断。尽管深度学习模型在DR检测中前景广阔，但其“黑箱”性质因缺乏透明度和可解释性而阻碍了临床应用。

Method: XDR-LVLM框架整合了专门的医学视觉编码器和LVLM核心，并采用多任务提示工程和多阶段微调。它能深入理解眼底图像中的病理特征，并生成包含DR严重程度分级、关键病理概念识别（如出血、渗出、微动脉瘤）以及将观察到的特征与诊断联系起来的详细解释的综合诊断报告。

Result: 在DDR数据集上的实验表明，XDR-LVLM在疾病诊断方面达到了最先进的性能，平衡准确率为84.55%，F1分数为79.92%；在概念检测方面也取得了优异结果（平衡准确率77.95%，F1分数66.88%）。此外，人类评估证实了生成解释的高流畅性、准确性和临床实用性。

Conclusion: XDR-LVLM通过提供强大且可解释的见解，成功弥合了自动化诊断与临床需求之间的鸿沟，展示了其在提供鲁棒和可解释性洞察方面的能力。

Abstract: Diabetic Retinopathy (DR) is a major cause of global blindness, necessitating
early and accurate diagnosis. While deep learning models have shown promise in
DR detection, their black-box nature often hinders clinical adoption due to a
lack of transparency and interpretability. To address this, we propose XDR-LVLM
(eXplainable Diabetic Retinopathy Diagnosis with LVLM), a novel framework that
leverages Vision-Language Large Models (LVLMs) for high-precision DR diagnosis
coupled with natural language-based explanations. XDR-LVLM integrates a
specialized Medical Vision Encoder, an LVLM Core, and employs Multi-task Prompt
Engineering and Multi-stage Fine-tuning to deeply understand pathological
features within fundus images and generate comprehensive diagnostic reports.
These reports explicitly include DR severity grading, identification of key
pathological concepts (e.g., hemorrhages, exudates, microaneurysms), and
detailed explanations linking observed features to the diagnosis. Extensive
experiments on the Diabetic Retinopathy (DDR) dataset demonstrate that XDR-LVLM
achieves state-of-the-art performance, with a Balanced Accuracy of 84.55% and
an F1 Score of 79.92% for disease diagnosis, and superior results for concept
detection (77.95% BACC, 66.88% F1). Furthermore, human evaluations confirm the
high fluency, accuracy, and clinical utility of the generated explanations,
showcasing XDR-LVLM's ability to bridge the gap between automated diagnosis and
clinical needs by providing robust and interpretable insights.

</details>


### [49] [MeSS: City Mesh-Guided Outdoor Scene Generation with Cross-View Consistent Diffusion](https://arxiv.org/abs/2508.15169)
*Xuyang Chen,Zhijun Zhai,Kaixuan Zhou,Zengmao Wang,Jianan He,Dong Wang,Yanfeng Zhang,mingwei Sun,Rüdiger Westermann,Konrad Schindler,Liqiu Meng*

Main category: cs.CV

TL;DR: 本文提出了MeSS（基于网格的场景合成）方法，利用城市网格模型作为几何先验，生成高质量、风格一致的室外场景，解决了现有网格模型纹理不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有城市网格模型缺乏逼真的纹理，限制了它们在虚拟城市导航和自动驾驶中的应用。图像和视频扩散模型虽然可用于生成街景视图，但前者缺乏跨视图一致性，后者难以精确遵循预定义相机路径或与渲染的控制视频对齐，均不直接适用于3D场景生成。

Method: MeSS方法包含三个主要阶段：1. 使用级联外绘ControlNets生成几何一致的稀疏视图；2. 通过AGInpaint组件传播更密集的中间视图；3. 使用GCAlign模块全局消除视觉不一致性。同时，通过在网格表面初始化高斯球来重建3D高斯泼溅（3DGS）场景。

Result: 该方法在几何对齐和生成质量方面均优于现有方法。合成的场景可以通过重新打光和风格迁移技术以多种风格渲染。

Conclusion: MeSS成功地为城市网格模型生成了高品质、风格一致且几何对齐的室外场景，显著提升了网格模型在虚拟城市导航和自动驾驶等领域的应用潜力。

Abstract: Mesh models have become increasingly accessible for numerous cities; however,
the lack of realistic textures restricts their application in virtual urban
navigation and autonomous driving. To address this, this paper proposes MeSS
(Meshbased Scene Synthesis) for generating high-quality, styleconsistent
outdoor scenes with city mesh models serving as the geometric prior. While
image and video diffusion models can leverage spatial layouts (such as depth
maps or HD maps) as control conditions to generate street-level perspective
views, they are not directly applicable to 3D scene generation. Video diffusion
models excel at synthesizing consistent view sequences that depict scenes but
often struggle to adhere to predefined camera paths or align accurately with
rendered control videos. In contrast, image diffusion models, though unable to
guarantee cross-view visual consistency, can produce more geometry-aligned
results when combined with ControlNet. Building on this insight, our approach
enhances image diffusion models by improving cross-view consistency. The
pipeline comprises three key stages: first, we generate geometrically
consistent sparse views using Cascaded Outpainting ControlNets; second, we
propagate denser intermediate views via a component dubbed AGInpaint; and
third, we globally eliminate visual inconsistencies (e.g., varying exposure)
using the GCAlign module. Concurrently with generation, a 3D Gaussian Splatting
(3DGS) scene is reconstructed by initializing Gaussian balls on the mesh
surface. Our method outperforms existing approaches in both geometric alignment
and generation quality. Once synthesized, the scene can be rendered in diverse
styles through relighting and style transfer techniques.

</details>


### [50] [SurgWound-Bench: A Benchmark for Surgical Wound Diagnosis](https://arxiv.org/abs/2508.15189)
*Jiahao Xu,Changchang Yin,Odysseas Chatzipanagiotou,Diamantis Tsilimigras,Kevin Clear,Bingsheng Yao,Dakuo Wang,Timothy Pawlik,Ping Zhang*

Main category: cs.CV

TL;DR: 本研究推出了SurgWound，首个包含多种手术伤口类型的开源数据集和诊断基准，并提出了一个三阶段学习框架WoundQwen，用于手术伤口诊断和报告生成，以实现个性化伤口护理。


<details>
  <summary>Details</summary>
Motivation: 手术部位感染（SSI）是常见且代价高昂的医疗相关感染，手术伤口护理在预防SSI方面面临挑战。现有深度学习研究受限于数据隐私和高昂的专家标注成本，且缺乏包含多种手术伤口类型的公开数据集和开源筛查工具。

Method: 1. 构建了SurgWound，首个开源手术伤口数据集，包含697张由3名专业外科医生标注的图像，涵盖8种细粒度临床属性。2. 基于SurgWound，建立了首个手术伤口诊断基准，包括视觉问答（VQA）和报告生成任务。3. 提出了WoundQwen三阶段学习框架：第一阶段使用五个独立的MLLM预测伤口特征；第二阶段将第一阶段的预测作为知识输入，由两个MLLM诊断结果（感染风险和干预指导）；第三阶段训练一个MLLM整合前两阶段结果生成综合报告。

Result: 本研究成功创建了首个包含多种手术伤口类型的开源数据集SurgWound，建立了首个手术伤口诊断基准（包含VQA和报告生成任务），并提出了WoundQwen三阶段学习框架，该框架能够分析详细的手术伤口特征，并根据图像为患者提供后续指导。

Conclusion: 所提出的三阶段框架能够详细分析手术伤口特征并提供后续患者指导，为个性化伤口护理、及时干预和改善患者预后铺平了道路。

Abstract: Surgical site infection (SSI) is one of the most common and costly
healthcare-associated infections and and surgical wound care remains a
significant clinical challenge in preventing SSIs and improving patient
outcomes. While recent studies have explored the use of deep learning for
preliminary surgical wound screening, progress has been hindered by concerns
over data privacy and the high costs associated with expert annotation.
Currently, no publicly available dataset or benchmark encompasses various types
of surgical wounds, resulting in the absence of an open-source Surgical-Wound
screening tool. To address this gap: (1) we present SurgWound, the first
open-source dataset featuring a diverse array of surgical wound types. It
contains 697 surgical wound images annotated by 3 professional surgeons with
eight fine-grained clinical attributes. (2) Based on SurgWound, we introduce
the first benchmark for surgical wound diagnosis, which includes visual
question answering (VQA) and report generation tasks to comprehensively
evaluate model performance. (3) Furthermore, we propose a three-stage learning
framework, WoundQwen, for surgical wound diagnosis. In the first stage, we
employ five independent MLLMs to accurately predict specific surgical wound
characteristics. In the second stage, these predictions serve as additional
knowledge inputs to two MLLMs responsible for diagnosing outcomes, which assess
infection risk and guide subsequent interventions. In the third stage, we train
a MLLM that integrates the diagnostic results from the previous two stages to
produce a comprehensive report. This three-stage framework can analyze detailed
surgical wound characteristics and provide subsequent instructions to patients
based on surgical images, paving the way for personalized wound care, timely
intervention, and improved patient outcomes.

</details>


### [51] [Adversarial Agent Behavior Learning in Autonomous Driving Using Deep Reinforcement Learning](https://arxiv.org/abs/2508.15207)
*Arjun Srinivasan,Anubhav Paras,Aniket Bera*

Main category: cs.CV

TL;DR: 本文提出了一种基于学习的方法，用于为强化学习环境中基于规则的智能体生成对抗性行为，以引发故障场景并降低累积奖励，这对于自动驾驶等安全关键应用至关重要。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶等安全关键应用中，现有强化学习方法训练的智能体通常与基于规则的周围智能体交互。正确建模这些基于规则的智能体至关重要，而寻找对抗性行为以暴露潜在的系统故障是研究的关键动机。

Method: 本文提出了一种基于学习的方法来推导基于规则的智能体的对抗性行为。该方法训练一个对抗性智能体，使其能够引发故障场景。然后，该对抗性智能体与所有基于规则的智能体进行评估。

Result: 评估结果表明，所提出的对抗性智能体能够导致累积奖励的显著下降，从而成功地引发了故障场景。

Conclusion: 基于学习的方法可以有效地为基于规则的智能体生成对抗性行为，从而揭示系统在安全关键应用中的脆弱性并导致性能（累积奖励）下降。

Abstract: Existing approaches in reinforcement learning train an agent to learn desired
optimal behavior in an environment with rule based surrounding agents. In
safety critical applications such as autonomous driving it is crucial that the
rule based agents are modelled properly. Several behavior modelling strategies
and IDM models are used currently to model the surrounding agents. We present a
learning based method to derive the adversarial behavior for the rule based
agents to cause failure scenarios. We evaluate our adversarial agent against
all the rule based agents and show the decrease in cumulative reward.

</details>


### [52] [DyMorph-B2I: Dynamic and Morphology-Guided Binary-to-Instance Segmentation for Renal Pathology](https://arxiv.org/abs/2508.15208)
*Leiyue Zhao,Yuechen Yang,Yanfan Zhu,Haichun Yang,Yuankai Huo,Paul D. Simonson,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: DyMorph-B2I是一个动态、形态学引导的二值到实例分割流程，专为肾脏病理学设计，通过整合多种经典技术并进行自适应优化，显著提高了肾脏功能单元的实例分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有的肾脏病理学图像分析方法主要提供二值（语义）掩膜，限制了下游分析的精确性。经典的后处理技术（如分水岭、形态学操作、骨架化）受限于肾脏组织形态的多样性和连接复杂性，单独使用效果有限。

Method: 本研究提出了DyMorph-B2I，一个将分水岭、骨架化和形态学操作整合到统一框架中的动态、形态学引导的二值到实例分割流程。该方法还包括自适应几何精修和针对每类功能单元的可定制超参数调整，并通过系统参数优化来稳健分离二值掩膜中粘连和异构的结构。

Result: 实验结果表明，DyMorph-B2I在分离粘连和异构结构方面表现出色，优于单独的经典方法和简单的组合，实现了卓越的实例分离，并促进了肾脏病理工作流程中更精确的形态计量分析。

Conclusion: DyMorph-B2I是一个有效且公开可用的肾脏病理学实例分割流程，能够显著提升形态学量化的准确性，为肾脏病理学研究提供更精细的数据分析基础。

Abstract: Accurate morphological quantification of renal pathology functional units
relies on instance-level segmentation, yet most existing datasets and automated
methods provide only binary (semantic) masks, limiting the precision of
downstream analyses. Although classical post-processing techniques such as
watershed, morphological operations, and skeletonization, are often used to
separate semantic masks into instances, their individual effectiveness is
constrained by the diverse morphologies and complex connectivity found in renal
tissue. In this study, we present DyMorph-B2I, a dynamic, morphology-guided
binary-to-instance segmentation pipeline tailored for renal pathology. Our
approach integrates watershed, skeletonization, and morphological operations
within a unified framework, complemented by adaptive geometric refinement and
customizable hyperparameter tuning for each class of functional unit. Through
systematic parameter optimization, DyMorph-B2I robustly separates adherent and
heterogeneous structures present in binary masks. Experimental results
demonstrate that our method outperforms individual classical approaches and
na\"ive combinations, enabling superior instance separation and facilitating
more accurate morphometric analysis in renal pathology workflows. The pipeline
is publicly available at: https://github.com/ddrrnn123/DyMorph-B2I.

</details>


### [53] [STAGNet: A Spatio-Temporal Graph and LSTM Framework for Accident Anticipation](https://arxiv.org/abs/2508.15216)
*Vipooshan Vipulananthan,Kumudu Mohottala,Kavindu Chinthana,Nimsara Paramulla,Charith D Chitraranjan*

Main category: cs.CV

TL;DR: 本文提出了一种名为STAGNet的新模型，通过融合时空特征和循环网络，改进了基于行车记录仪视频的事故预测，并在多个公开数据集上超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 提高道路安全、减少事故风险和财产损失是关键。先进驾驶辅助系统（ADAS）需要能提前预测事故。现有系统多依赖多种传感器，而仅依赖行车记录仪视频提供了一种更具挑战性但更经济、易于部署的解决方案。

Method: 该研究结合了更好的时空特征，并通过循环网络对其进行聚合，以改进现有最先进的图神经网络。提出的模型名为STAGNet，用于从行车记录仪视频中预测事故。

Result: 在三个公开数据集上进行的实验表明，所提出的STAGNet模型在平均精度和平均碰撞时间（time-to-collision）值上均高于以往方法，无论是在给定数据集上进行交叉验证，还是在不同数据集上进行训练和测试。

Conclusion: STAGNet模型通过结合改进的时空特征和循环网络，显著提升了仅基于行车记录仪视频的事故预测性能，为道路安全提供了更有效、更具成本效益的解决方案。

Abstract: Accident prediction and timely warnings play a key role in improving road
safety by reducing the risk of injury to road users and minimizing property
damage. Advanced Driver Assistance Systems (ADAS) are designed to support human
drivers and are especially useful when they can anticipate potential accidents
before they happen. While many existing systems depend on a range of sensors
such as LiDAR, radar, and GPS, relying solely on dash-cam video input presents
a more challenging but a more cost-effective and easily deployable solution. In
this work, we incorporate better spatio-temporal features and aggregate them
through a recurrent network to improve upon state-of-the-art graph neural
networks for predicting accidents from dash-cam videos. Experiments using three
publicly available datasets show that our proposed STAGNet model achieves
higher average precision and mean time-to-collision values than previous
methods, both when cross-validated on a given dataset and when trained and
tested on different datasets.

</details>


### [54] [CM2LoD3: Reconstructing LoD3 Building Models Using Semantic Conflict Maps](https://arxiv.org/abs/2508.15672)
*Franz Hanke,Antonia Bieringer,Olaf Wysocki,Boris Jutzi*

Main category: cs.CV

TL;DR: 本研究提出了一种名为CM2LoD3的新方法，利用冲突图（CMs）和语义分割，结合纹理模型融合，实现了LoD3建筑模型的自动化重建，有效解决了大规模生成LoD3模型的挑战。


<details>
  <summary>Details</summary>
Motivation: LoD3建筑模型对于城市规划、数字孪生和灾害管理至关重要，但传统的LoD3模型生成需要手动建模，难以大规模应用。现有LoD1和LoD2模型缺乏详细的立面元素（如窗户、门），无法满足高级城市分析的需求。

Method: CM2LoD3方法通过射线-模型先验分析获取冲突图（CMs）。该方法的核心是对真实世界的CMs进行语义分割，并结合从自研语义冲突图生成器（SCMG）合成生成的CMs。此外，他们还将纹理模型的额外分割结果与CMs通过置信度分数进行融合，以提高分割性能和三维重建精度。

Result: 实验结果表明，CM2LoD3方法在分割和重建建筑开口方面表现出有效性，特别是在融合了具有不确定性感知的分段建筑纹理后，性能达到了61%。

Conclusion: 这项研究推动了LoD3模型自动化重建的进展，为可扩展和高效的三维城市建模铺平了道路。

Abstract: Detailed 3D building models are crucial for urban planning, digital twins,
and disaster management applications. While Level of Detail 1 (LoD)1 and LoD2
building models are widely available, they lack detailed facade elements
essential for advanced urban analysis. In contrast, LoD3 models address this
limitation by incorporating facade elements such as windows, doors, and
underpasses. However, their generation has traditionally required manual
modeling, making large-scale adoption challenging. In this contribution,
CM2LoD3, we present a novel method for reconstructing LoD3 building models
leveraging Conflict Maps (CMs) obtained from ray-to-model-prior analysis.
Unlike previous works, we concentrate on semantically segmenting real-world CMs
with synthetically generated CMs from our developed Semantic Conflict Map
Generator (SCMG). We also observe that additional segmentation of textured
models can be fused with CMs using confidence scores to further increase
segmentation performance and thus increase 3D reconstruction accuracy.
Experimental results demonstrate the effectiveness of our CM2LoD3 method in
segmenting and reconstructing building openings, with the 61% performance with
uncertainty-aware fusion of segmented building textures. This research
contributes to the advancement of automated LoD3 model reconstruction, paving
the way for scalable and efficient 3D city modeling. Our project is available:
https://github.com/InFraHank/CM2LoD3

</details>


### [55] [Collaborative Multi-Modal Coding for High-Quality 3D Generation](https://arxiv.org/abs/2508.15228)
*Ziang Cao,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: TriMM是一种前馈3D原生生成模型，通过协同多模态编码、2D/3D辅助监督和三平面潜在扩散模型，从RGB、RGBD和点云等基本多模态数据中学习，以少量数据生成高质量3D资产。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成模型大多是单模态的，忽略了多模态数据的互补优势，或受限于3D结构，限制了可用训练数据集的范围。

Method: 1) 引入协同多模态编码，整合模态特定特征同时保留其独特表示优势。2) 引入辅助2D和3D监督以提高多模态编码的鲁棒性和性能。3) 基于嵌入的多模态编码，采用三平面潜在扩散模型生成高质量3D资产，提升纹理和几何细节。

Result: 在多个知名数据集上的实验表明，TriMM通过有效利用多模态，即使使用少量训练数据，也能达到与在大型数据集上训练的模型相当的性能。此外，在RGB-D数据集上的实验验证了将其他多模态数据集整合到3D生成中的可行性。

Conclusion: TriMM成功地利用多模态数据实现了高质量的3D资产生成，并且在数据量较少的情况下也能表现出色，证明了多模态方法在3D生成领域的潜力和有效性。

Abstract: 3D content inherently encompasses multi-modal characteristics and can be
projected into different modalities (e.g., RGB images, RGBD, and point clouds).
Each modality exhibits distinct advantages in 3D asset modeling: RGB images
contain vivid 3D textures, whereas point clouds define fine-grained 3D
geometries. However, most existing 3D-native generative architectures either
operate predominantly within single-modality paradigms-thus overlooking the
complementary benefits of multi-modality data-or restrict themselves to 3D
structures, thereby limiting the scope of available training datasets. To
holistically harness multi-modalities for 3D modeling, we present TriMM, the
first feed-forward 3D-native generative model that learns from basic
multi-modalities (e.g., RGB, RGBD, and point cloud). Specifically, 1) TriMM
first introduces collaborative multi-modal coding, which integrates
modality-specific features while preserving their unique representational
strengths. 2) Furthermore, auxiliary 2D and 3D supervision are introduced to
raise the robustness and performance of multi-modal coding. 3) Based on the
embedded multi-modal code, TriMM employs a triplane latent diffusion model to
generate 3D assets of superior quality, enhancing both the texture and the
geometric detail. Extensive experiments on multiple well-known datasets
demonstrate that TriMM, by effectively leveraging multi-modality, achieves
competitive performance with models trained on large-scale datasets, despite
utilizing a small amount of training data. Furthermore, we conduct additional
experiments on recent RGB-D datasets, verifying the feasibility of
incorporating other multi-modal datasets into 3D generation.

</details>


### [56] [Center-Oriented Prototype Contrastive Clustering](https://arxiv.org/abs/2508.15231)
*Shihao Dong,Xiaotong Zhou,Yuhui Zheng,Huiying Xu,Xinzhong Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种面向中心的原型对比聚类框架（CPCC），通过软原型对比模块和双重一致性学习模块，有效解决了对比学习聚类中类间冲突和原型漂移问题，并在多个数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 对比学习在聚类任务中因其判别性表示而被广泛应用，但存在类间冲突难以有效解决的问题。现有方法通过原型对比尝试解决，但硬原型计算与真实聚类中心之间存在偏差。

Method: 提出了一种面向中心的原型对比聚类框架（CPCC），包含：
1. 软原型对比模块：使用样本属于聚类中心的概率作为权重计算各类别原型，以避免类间冲突并减少原型漂移。
2. 双重一致性学习模块：分别对同一样本的不同变换和不同样本的邻域进行对齐，以确保特征具有变换不变的语义信息和紧凑的簇内分布，并为原型计算提供可靠保障。

Result: 在五个数据集上进行的广泛实验表明，所提出的方法与现有最先进（SOTA）方法相比是有效的。

Conclusion: 所提出的中心导向原型对比聚类框架（CPCC）通过其软原型对比和双重一致性学习模块，成功解决了对比聚类中类间冲突和原型计算偏差的问题，显著提升了聚类性能。

Abstract: Contrastive learning is widely used in clustering tasks due to its
discriminative representation. However, the conflict problem between classes is
difficult to solve effectively. Existing methods try to solve this problem
through prototype contrast, but there is a deviation between the calculation of
hard prototypes and the true cluster center. To address this problem, we
propose a center-oriented prototype contrastive clustering framework, which
consists of a soft prototype contrastive module and a dual consistency learning
module. In short, the soft prototype contrastive module uses the probability
that the sample belongs to the cluster center as a weight to calculate the
prototype of each category, while avoiding inter-class conflicts and reducing
prototype drift. The dual consistency learning module aligns different
transformations of the same sample and the neighborhoods of different samples
respectively, ensuring that the features have transformation-invariant semantic
information and compact intra-cluster distribution, while providing reliable
guarantees for the calculation of prototypes. Extensive experiments on five
datasets show that the proposed method is effective compared to the SOTA. Our
code is published on https://github.com/LouisDong95/CPCC.

</details>


### [57] [AeroDuo: Aerial Duo for UAV-based Vision and Language Navigation](https://arxiv.org/abs/2508.15232)
*Ruipu Wu,Yige Zhang,Jinyu Chen,Linjiang Huang,Shifeng Zhang,Xu Zhou,Liang Wang,Si Liu*

Main category: cs.CV

TL;DR: 本文提出了一种双高度无人机协同视觉语言导航（DuAl-VLN）新任务，旨在通过高空无人机进行宏观推理和低空无人机进行精确导航来提高空中VLN的可靠性。为此，作者构建了HaL-13k数据集，并提出了AeroDuo框架。


<details>
  <summary>Details</summary>
Motivation: 现有的空中视觉语言导航（VLN）任务由于无人机轨迹长、机动性复杂，难以实现可靠性能，常需人工干预或过于详细的指令。尽管无人机具有高机动性可提供多粒度视角，但仍需在可控的运动空间内进行学习。

Method: 本文引入了双高度无人机协同VLN（DuAl-VLN）任务，其中高空无人机负责广域环境推理，低空无人机负责精确导航。为支持该任务，作者构建了包含13,838条协同轨迹的HaL-13k数据集，并提出了AeroDuo框架：高空无人机集成多模态大语言模型（Pilot-LLM）进行目标推理，低空无人机采用轻量级多阶段策略进行导航和目标定位，两架无人机仅通过交换最少的坐标信息进行协同。

Result: 本文介绍了DuAl-VLN任务、HaL-13k数据集和AeroDuo框架。HaL-13k数据集包含用于评估模型在新环境和陌生目标上泛化能力的未见地图和未见目标验证集。AeroDuo框架通过高空无人机的多模态大语言模型进行目标推理和低空无人机的轻量级策略进行导航与目标定位，实现了双无人机的协同工作。

Conclusion: 本文通过引入双高度无人机协同VLN（DuAl-VLN）任务、构建HaL-13k数据集和提出AeroDuo框架，为解决空中VLN的挑战提供了一种新颖的解决方案，旨在通过双无人机协作实现更可靠、高效的空中导航。

Abstract: Aerial Vision-and-Language Navigation (VLN) is an emerging task that enables
Unmanned Aerial Vehicles (UAVs) to navigate outdoor environments using natural
language instructions and visual cues. However, due to the extended
trajectories and complex maneuverability of UAVs, achieving reliable UAV-VLN
performance is challenging and often requires human intervention or overly
detailed instructions. To harness the advantages of UAVs' high mobility, which
could provide multi-grained perspectives, while maintaining a manageable motion
space for learning, we introduce a novel task called Dual-Altitude UAV
Collaborative VLN (DuAl-VLN). In this task, two UAVs operate at distinct
altitudes: a high-altitude UAV responsible for broad environmental reasoning,
and a low-altitude UAV tasked with precise navigation. To support the training
and evaluation of the DuAl-VLN, we construct the HaL-13k, a dataset comprising
13,838 collaborative high-low UAV demonstration trajectories, each paired with
target-oriented language instructions. This dataset includes both unseen maps
and an unseen object validation set to systematically evaluate the model's
generalization capabilities across novel environments and unfamiliar targets.
To consolidate their complementary strengths, we propose a dual-UAV
collaborative VLN framework, AeroDuo, where the high-altitude UAV integrates a
multimodal large language model (Pilot-LLM) for target reasoning, while the
low-altitude UAV employs a lightweight multi-stage policy for navigation and
target grounding. The two UAVs work collaboratively and only exchange minimal
coordinate information to ensure efficiency.

</details>


### [58] [Pretrained Diffusion Models Are Inherently Skipped-Step Samplers](https://arxiv.org/abs/2508.15233)
*Wenju Xu*

Main category: cs.CV

TL;DR: 本文提出了一种名为“跳步采样”的新机制，显著减少了扩散模型的生成步骤，同时保持了高质量输出。该方法源自标准扩散模型的训练目标，表明加速采样是预训练扩散模型的内在特性，并且可以与现有加速方法（如DDIM）结合使用。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成任务中表现卓越，但其顺序生成过程导致采样步骤冗长。现有方法（如DDIM）通过构建非马尔可夫扩散过程来减少步骤，但仍不清楚原始马尔可夫扩散过程是否能在不诉诸非马尔可夫过程的情况下实现相同的效率。

Method: 本文引入了“跳步采样”机制，通过跳过迭代生成过程中的多个中间去噪步骤，来加速采样。作者证明了这种机制源自标准扩散模型的相同训练目标，表明通过马尔可夫方式进行跳步采样加速是预训练扩散模型的内在属性。此外，该方法还与DDIM进行了集成，提出了增强的生成方法。

Result: 在OpenAI ADM、Stable Diffusion和Open Sora等流行的预训练扩散模型上的大量实验表明，所提出的方法在显著减少采样步骤的同时，实现了高质量的生成。

Conclusion: 本文证实了原始扩散过程无需诉诸非马尔可夫过程即可实现采样效率，并通过“跳步采样”机制证明了加速采样是预训练扩散模型的内在属性。该方法有效且可与现有加速技术结合，实现高质量的快速生成。

Abstract: Diffusion models have been achieving state-of-the-art results across various
generation tasks. However, a notable drawback is their sequential generation
process, requiring long-sequence step-by-step generation. Existing methods,
such as DDIM, attempt to reduce sampling steps by constructing a class of
non-Markovian diffusion processes that maintain the same training objective.
However, there remains a gap in understanding whether the original diffusion
process can achieve the same efficiency without resorting to non-Markovian
processes. In this paper, we provide a confirmative answer and introduce
skipped-step sampling, a mechanism that bypasses multiple intermediate
denoising steps in the iterative generation process, in contrast with the
traditional step-by-step refinement of standard diffusion inference. Crucially,
we demonstrate that this skipped-step sampling mechanism is derived from the
same training objective as the standard diffusion model, indicating that
accelerated sampling via skipped-step sampling via a Markovian way is an
intrinsic property of pretrained diffusion models. Additionally, we propose an
enhanced generation method by integrating our accelerated sampling technique
with DDIM. Extensive experiments on popular pretrained diffusion models,
including the OpenAI ADM, Stable Diffusion, and Open Sora models, show that our
method achieves high-quality generation with significantly reduced sampling
steps.

</details>


### [59] [Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent](https://arxiv.org/abs/2508.15243)
*Yixin Gao,Xin Li,Xiaohan Pan,Runsen Feng,Bingchen Li,Yunpeng Qi,Yiting Lu,Zhengxue Cheng,Zhibo Chen,Jörn Ostermann*

Main category: cs.CV

TL;DR: Comp-X 是首个由大型语言模型（LLM）代理驱动的智能交互式图像压缩范式，旨在通过统一编码框架和交互式代理克服传统编码器的局限性。


<details>
  <summary>Details</summary>
Motivation: 常用的图像编码器编码模式有限，且依赖工程师手动选择，对非专业用户不友好。研究旨在通过引入智能交互来克服这一局限。

Method: Comp-X 引入了三项创新：(i) 多功能编码框架，统一了不同目标（如人机感知、可变编码、空间比特分配）的编码模式；(ii) 交互式编码代理，采用增强的上下文学习方法并结合编码专家反馈来训练LLM代理理解编码请求和工具使用；(iii) IIC-bench，首个专用于智能交互式图像压缩评估的基准测试。

Result: 实验结果表明，Comp-X 能高效理解编码请求，展现出卓越的文本交互能力。同时，即使在单一编码框架下，它也能保持可观的压缩性能。

Conclusion: Comp-X 为图像压缩领域的人工通用智能（AGI）提供了一个有前景的方向。

Abstract: We present Comp-X, the first intelligently interactive image compression
paradigm empowered by the impressive reasoning capability of large language
model (LLM) agent. Notably, commonly used image codecs usually suffer from
limited coding modes and rely on manual mode selection by engineers, making
them unfriendly for unprofessional users. To overcome this, we advance the
evolution of image coding paradigm by introducing three key innovations: (i)
multi-functional coding framework, which unifies different coding modes of
various objective/requirements, including human-machine perception, variable
coding, and spatial bit allocation, into one framework. (ii) interactive coding
agent, where we propose an augmented in-context learning method with coding
expert feedback to teach the LLM agent how to understand the coding request,
mode selection, and the use of the coding tools. (iii) IIC-bench, the first
dedicated benchmark comprising diverse user requests and the corresponding
annotations from coding experts, which is systematically designed for
intelligently interactive image compression evaluation. Extensive experimental
results demonstrate that our proposed Comp-X can understand the coding requests
efficiently and achieve impressive textual interaction capability. Meanwhile,
it can maintain comparable compression performance even with a single coding
framework, providing a promising avenue for artificial general intelligence
(AGI) in image compression.

</details>


### [60] [Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images](https://arxiv.org/abs/2508.15256)
*Jinsol Song,Jiamu Wang,Anh Tien Nguyen,Keunho Byeon,Sangjeong Ahn,Sung Hak Lee,Jin Tae Kwak*

Main category: cs.CV

TL;DR: Ano-NAViLa是一种结合正常和异常病理知识的视觉-语言模型，用于病理图像异常检测，实现了最先进的性能，并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中的异常检测面临挑战，因为疾病相关数据有限或缺失，现有方法（主要为工业设计）在病理学中存在计算限制、组织结构多样性和缺乏可解释性等局限。

Method: 本文提出了Ano-NAViLa模型，它是一个“正常和异常病理知识增强型视觉-语言模型”。该模型基于预训练的视觉-语言模型，并结合一个轻量级可训练的MLP。通过整合正常和异常病理知识，Ano-NAViLa增强了模型在病理图像变异性方面的准确性和鲁棒性，并通过图像-文本关联提供可解释性。

Result: Ano-NAViLa在两个来自不同器官的淋巴结数据集上进行了评估，在异常检测和定位方面均达到了最先进的性能，超越了现有竞争模型。

Conclusion: Ano-NAViLa通过结合正常和异常病理知识，显著提高了病理图像异常检测的准确性和鲁棒性，并提供了可解释性，从而实现了该领域的最新技术水平。

Abstract: Anomaly detection in computational pathology aims to identify rare and scarce
anomalies where disease-related data are often limited or missing. Existing
anomaly detection methods, primarily designed for industrial settings, face
limitations in pathology due to computational constraints, diverse tissue
structures, and lack of interpretability. To address these challenges, we
propose Ano-NAViLa, a Normal and Abnormal pathology knowledge-augmented
Vision-Language model for Anomaly detection in pathology images. Ano-NAViLa is
built on a pre-trained vision-language model with a lightweight trainable MLP.
By incorporating both normal and abnormal pathology knowledge, Ano-NAViLa
enhances accuracy and robustness to variability in pathology images and
provides interpretability through image-text associations. Evaluated on two
lymph node datasets from different organs, Ano-NAViLa achieves the
state-of-the-art performance in anomaly detection and localization,
outperforming competing models.

</details>


### [61] [RATopo: Improving Lane Topology Reasoning via Redundancy Assignment](https://arxiv.org/abs/2508.15272)
*Han Li,Shaofei Huang,Longfei Xu,Yulu Gao,Beipeng Mu,Si Liu*

Main category: cs.CV

TL;DR: RATopo提出了一种冗余分配策略，通过重构Transformer解码器并启用一对多分配，为自动驾驶中的车道拓扑推理提供丰富且多样化的监督，显著提升了拓扑推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有车道拓扑推理方法多采用“先检测后推理”范式，其拓扑关系监督依赖于检测阶段的一对一分配结果。这种监督策略因有效监督范围有限，导致拓扑推理性能不佳。

Method: 本文提出了RATopo（Redundancy Assignment strategy for lane Topology reasoning）。具体方法包括：1) 重构Transformer解码器，交换交叉注意力层和自注意力层，从而在抑制前保留冗余车道预测，实现有效的一对多分配。2) 实例化多个具有独立参数的并行交叉注意力块，进一步增强检测到车道的多样性。

Result: 在OpenLane-V2上的大量实验表明，RATopo策略是模型无关的，可以无缝集成到现有拓扑推理框架中，并持续改进车道-车道和车道-交通元素的拓扑推理性能。

Conclusion: RATopo通过其冗余分配策略，解决了现有拓扑推理监督不足的问题，通过启用数量丰富和几何多样化的拓扑监督，显著提升了自动驾驶中车道拓扑推理的性能。

Abstract: Lane topology reasoning plays a critical role in autonomous driving by
modeling the connections among lanes and the topological relationships between
lanes and traffic elements. Most existing methods adopt a
first-detect-then-reason paradigm, where topological relationships are
supervised based on the one-to-one assignment results obtained during the
detection stage. This supervision strategy results in suboptimal topology
reasoning performance due to the limited range of valid supervision. In this
paper, we propose RATopo, a Redundancy Assignment strategy for lane Topology
reasoning that enables quantity-rich and geometry-diverse topology supervision.
Specifically, we restructure the Transformer decoder by swapping the
cross-attention and self-attention layers. This allows redundant lane
predictions to be retained before suppression, enabling effective one-to-many
assignment. We also instantiate multiple parallel cross-attention blocks with
independent parameters, which further enhances the diversity of detected lanes.
Extensive experiments on OpenLane-V2 demonstrate that our RATopo strategy is
model-agnostic and can be seamlessly integrated into existing topology
reasoning frameworks, consistently improving both lane-lane and lane-traffic
topology performance.

</details>


### [62] [DesignCLIP: Multimodal Learning with CLIP for Design Patent Understanding](https://arxiv.org/abs/2508.15297)
*Zhu Wang,Homaira Huda Shomee,Sathya N. Ravi,Sourav Medya*

Main category: cs.CV

TL;DR: DesignCLIP是一个统一框架，利用CLIP模型、类感知分类和对比学习，通过详细图注和多视图学习，解决了设计专利图像信息不足的问题，并在分类和检索任务中超越现有模型，推动了多模态专利分析。


<details>
  <summary>Details</summary>
Motivation: 传统设计专利分析（如分类和图像检索）严重依赖图像数据，但专利图像（通常是抽象草图）缺乏全面的视觉上下文和语义信息，导致现有技术检索中的评估模糊性。最近的视觉-语言模型（如CLIP）为更可靠、准确的AI驱动专利分析提供了机会。

Method: 本文开发了一个统一框架DesignCLIP，利用CLIP模型处理大规模美国设计专利数据集。为应对专利数据的独特性，DesignCLIP整合了类感知分类和对比学习，并利用生成的详细专利图像描述和多视图图像学习。

Result: DesignCLIP在专利分类和专利检索等下游任务中表现出有效性，始终优于专利领域的基线模型和最先进模型。此外，研究还探索了多模态专利检索，这有可能通过提供更多样化的灵感来源来增强设计的创造力和创新。

Conclusion: DesignCLIP的实验结果强调了多模态方法在推进专利分析方面的巨大前景，证明了其在解决专利图像信息不足问题上的优越性。

Abstract: In the field of design patent analysis, traditional tasks such as patent
classification and patent image retrieval heavily depend on the image data.
However, patent images -- typically consisting of sketches with abstract and
structural elements of an invention -- often fall short in conveying
comprehensive visual context and semantic information. This inadequacy can lead
to ambiguities in evaluation during prior art searches. Recent advancements in
vision-language models, such as CLIP, offer promising opportunities for more
reliable and accurate AI-driven patent analysis. In this work, we leverage CLIP
models to develop a unified framework DesignCLIP for design patent applications
with a large-scale dataset of U.S. design patents. To address the unique
characteristics of patent data, DesignCLIP incorporates class-aware
classification and contrastive learning, utilizing generated detailed captions
for patent images and multi-views image learning. We validate the effectiveness
of DesignCLIP across various downstream tasks, including patent classification
and patent retrieval. Additionally, we explore multimodal patent retrieval,
which provides the potential to enhance creativity and innovation in design by
offering more diverse sources of inspiration. Our experiments show that
DesignCLIP consistently outperforms baseline and SOTA models in the patent
domain on all tasks. Our findings underscore the promise of multimodal
approaches in advancing patent analysis. The codebase is available here:
https://anonymous.4open.science/r/PATENTCLIP-4661/README.md.

</details>


### [63] [TPA: Temporal Prompt Alignment for Fetal Congenital Heart Defect Classification](https://arxiv.org/abs/2508.15298)
*Darya Taratynova,Alya Almsouti,Beknur Kalmakhanbet,Numan Saeed,Mohammad Yaqub*

Main category: cs.CV

TL;DR: 本文提出了一种名为TPA（Temporal Prompt Alignment）的新方法，用于在超声视频中分类胎儿先天性心脏缺陷（CHD），该方法结合了时间建模、提示感知对比学习和不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 超声视频中的CHD检测受到图像噪声和探头定位变异性的阻碍。现有自动化方法常忽略时间信息、局限于二分类，且不考虑预测校准，这限制了其临床可靠性。

Method: TPA方法利用基础图像-文本模型和提示感知对比学习。它从视频子剪辑的每一帧中提取特征，通过可训练的时间提取器聚合以捕捉心脏运动，并使用带裕度的铰链对比损失将视频表示与类别特定文本提示对齐。为增强临床可靠性，引入了条件变分自编码器风格调制（CVAESM）模块，学习潜在风格向量来调制嵌入并量化分类不确定性。

Result: TPA在CHD检测的私有数据集上实现了85.40%的宏F1分数，同时将预期校准误差（ECE）降低了5.38%，自适应ECE降低了6.8%。在EchoNet-Dynamic数据集的三分类任务中，宏F1分数从53.89%提升至58.62%（提高了4.73%），均达到最先进水平。

Conclusion: Temporal Prompt Alignment（TPA）是一个用于胎儿先天性心脏缺陷（CHD）超声视频分类的综合框架，它有效地整合了时间建模、提示感知对比学习和不确定性量化，显著提高了诊断性能和临床可靠性。

Abstract: Congenital heart defect (CHD) detection in ultrasound videos is hindered by
image noise and probe positioning variability. While automated methods can
reduce operator dependence, current machine learning approaches often neglect
temporal information, limit themselves to binary classification, and do not
account for prediction calibration. We propose Temporal Prompt Alignment (TPA),
a method leveraging foundation image-text model and prompt-aware contrastive
learning to classify fetal CHD on cardiac ultrasound videos. TPA extracts
features from each frame of video subclips using an image encoder, aggregates
them with a trainable temporal extractor to capture heart motion, and aligns
the video representation with class-specific text prompts via a margin-hinge
contrastive loss. To enhance calibration for clinical reliability, we introduce
a Conditional Variational Autoencoder Style Modulation (CVAESM) module, which
learns a latent style vector to modulate embeddings and quantifies
classification uncertainty. Evaluated on a private dataset for CHD detection
and on a large public dataset, EchoNet-Dynamic, for systolic dysfunction, TPA
achieves state-of-the-art macro F1 scores of 85.40% for CHD diagnosis, while
also reducing expected calibration error by 5.38% and adaptive ECE by 6.8%. On
EchoNet-Dynamic's three-class task, it boosts macro F1 by 4.73% (from 53.89% to
58.62%). Temporal Prompt Alignment (TPA) is a framework for fetal congenital
heart defect (CHD) classification in ultrasound videos that integrates temporal
modeling, prompt-aware contrastive learning, and uncertainty quantification.

</details>


### [64] [BasketLiDAR: The First LiDAR-Camera Multimodal Dataset for Professional Basketball MOT](https://arxiv.org/abs/2508.15299)
*Ryunosuke Hayashi,Kohei Torimi,Rokuto Nagata,Kazuma Ikeda,Ozora Sako,Taichi Nakamura,Masaki Tani,Yoshimitsu Aoki,Kentaro Yoshioka*

Main category: cs.CV

TL;DR: 该论文构建了首个结合LiDAR点云和多视角相机数据的篮球运动多目标跟踪（MOT）数据集BasketLiDAR，并提出了一种新颖的MOT框架，实现了实时、高精度的3D球员轨迹跟踪，尤其在遮挡条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的体育运动3D轨迹跟踪系统依赖多摄像头，但受限于视频数据的二维性、复杂的3D重建过程以及难以实现实时分析。篮球运动因球员快速、复杂移动和频繁遮挡，是MOT领域最具挑战性的场景之一。

Method: 1. 构建了BasketLiDAR数据集：这是体育MOT领域首个多模态数据集，包含LiDAR点云和同步的多视角相机画面，共4,445帧和3,105个球员ID，提供了完整的3D位置信息和ID标注。2. 提出了新颖的MOT算法：利用LiDAR高精度3D空间信息，设计了两个跟踪流程——单独使用LiDAR的实时跟踪管道和融合LiDAR与相机数据的多模态跟踪管道。

Result: 实验结果表明，所提出的方法实现了实时操作（传统纯相机方法难以达到），并且即使在遮挡条件下，也展现出卓越的跟踪性能。

Conclusion: 该研究通过引入BasketLiDAR数据集和基于LiDAR的多模态MOT框架，有效解决了篮球等复杂体育场景中实时3D球员轨迹跟踪的挑战，显著提升了跟踪精度和效率。

Abstract: Real-time 3D trajectory player tracking in sports plays a crucial role in
tactical analysis, performance evaluation, and enhancing spectator experience.
Traditional systems rely on multi-camera setups, but are constrained by the
inherently two-dimensional nature of video data and the need for complex 3D
reconstruction processing, making real-time analysis challenging. Basketball,
in particular, represents one of the most difficult scenarios in the MOT field,
as ten players move rapidly and complexly within a confined court space, with
frequent occlusions caused by intense physical contact.
  To address these challenges, this paper constructs BasketLiDAR, the first
multimodal dataset in the sports MOT field that combines LiDAR point clouds
with synchronized multi-view camera footage in a professional basketball
environment, and proposes a novel MOT framework that simultaneously achieves
improved tracking accuracy and reduced computational cost. The BasketLiDAR
dataset contains a total of 4,445 frames and 3,105 player IDs, with fully
synchronized IDs between three LiDAR sensors and three multi-view cameras. We
recorded 5-on-5 and 3-on-3 game data from actual professional basketball
players, providing complete 3D positional information and ID annotations for
each player. Based on this dataset, we developed a novel MOT algorithm that
leverages LiDAR's high-precision 3D spatial information. The proposed method
consists of a real-time tracking pipeline using LiDAR alone and a multimodal
tracking pipeline that fuses LiDAR and camera data. Experimental results
demonstrate that our approach achieves real-time operation, which was difficult
with conventional camera-only methods, while achieving superior tracking
performance even under occlusion conditions. The dataset is available upon
request at: https://sites.google.com/keio.jp/keio-csg/projects/basket-lidar

</details>


### [65] [First RAG, Second SEG: A Training-Free Paradigm for Camouflaged Object Detection](https://arxiv.org/abs/2508.15313)
*Wutao Liu,YiDan Wang,Pan Gao*

Main category: cs.CV

TL;DR: 本文提出RAG-SEG，一种无需训练的两阶段伪装目标检测方法。它首先利用检索增强生成（RAG）生成粗略掩码作为提示，然后通过基于SAM的分割（SEG）进行细化，实现了高效率和竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 伪装目标检测（COD）因目标与背景高度相似而极具挑战。现有方法通常需要大量训练和计算资源。基础模型（如SAM）虽泛化能力强，但直接应用于COD仍面临困难，且需要耗时耗力的高质量提示。

Method: 本文提出RAG-SEG，一种无需训练的两阶段范式。首先，通过检索增强生成（RAG）阶段，利用无监督聚类构建紧凑检索数据库，快速有效地检索特征，生成粗略掩码作为提示。其次，通过基于SAM的分割（SEG）阶段，利用检索到的特征产生的伪标签指导SAM2生成精确掩码进行细化。

Result: 该方法在保持竞争性性能的同时，在基准COD数据集上表现与现有最先进方法相当或超越。所有实验均在个人笔记本电脑上进行，突显了其计算效率和实用性。

Conclusion: RAG-SEG为伪装目标检测提供了一种无需训练、高效且实用的解决方案，其性能达到或超越了现有先进水平，有效解决了传统方法重度训练和提示生成困难的问题。

Abstract: Camouflaged object detection (COD) poses a significant challenge in computer
vision due to the high similarity between objects and their backgrounds.
Existing approaches often rely on heavy training and large computational
resources. While foundation models such as the Segment Anything Model (SAM)
offer strong generalization, they still struggle to handle COD tasks without
fine-tuning and require high-quality prompts to yield good performance.
However, generating such prompts manually is costly and inefficient. To address
these challenges, we propose \textbf{First RAG, Second SEG (RAG-SEG)}, a
training-free paradigm that decouples COD into two stages: Retrieval-Augmented
Generation (RAG) for generating coarse masks as prompts, followed by SAM-based
segmentation (SEG) for refinement. RAG-SEG constructs a compact retrieval
database via unsupervised clustering, enabling fast and effective feature
retrieval. During inference, the retrieved features produce pseudo-labels that
guide precise mask generation using SAM2. Our method eliminates the need for
conventional training while maintaining competitive performance. Extensive
experiments on benchmark COD datasets demonstrate that RAG-SEG performs on par
with or surpasses state-of-the-art methods. Notably, all experiments are
conducted on a \textbf{personal laptop}, highlighting the computational
efficiency and practicality of our approach. We present further analysis in the
Appendix, covering limitations, salient object detection extension, and
possible improvements.

</details>


### [66] [VideoEraser: Concept Erasure in Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.15314)
*Naen Xu,Jinghuai Zhang,Changjiang Li,Zhi Chen,Chunyi Zhou,Qingming Li,Tianyu Du,Shouling Ji*

Main category: cs.CV

TL;DR: VideoEraser是一个免训练的即插即用框架，旨在阻止文本到视频（T2V）扩散模型生成包含不良概念的视频，即使这些概念被明确提示。它通过选择性提示嵌入调整（SPEA）和对抗性弹性噪声引导（ARNG）两阶段过程实现。


<details>
  <summary>Details</summary>
Motivation: T2V扩散模型的快速发展引发了隐私、版权和安全担忧，因为它们可能被滥用于生成有害或误导性内容。这些模型常在未经授权的个人身份、艺术创作和有害材料上训练，导致此类内容不受控制地生产和分发。

Method: VideoEraser是一个免训练的即插即用框架，通过两阶段过程与T2V扩散模型集成：选择性提示嵌入调整（SPEA）和对抗性弹性噪声引导（ARNG）。

Result: VideoEraser在对象擦除、艺术风格擦除、名人擦除和明确内容擦除四项任务中进行了广泛评估。实验结果表明，VideoEraser在功效、完整性、保真度、鲁棒性和泛化性方面始终优于现有方法，平均将不良内容生成减少了46%。

Conclusion: VideoEraser在抑制T2V生成过程中的不良内容方面取得了最先进的性能，有效解决了T2V模型潜在滥用带来的隐私、版权和安全问题。

Abstract: The rapid growth of text-to-video (T2V) diffusion models has raised concerns
about privacy, copyright, and safety due to their potential misuse in
generating harmful or misleading content. These models are often trained on
numerous datasets, including unauthorized personal identities, artistic
creations, and harmful materials, which can lead to uncontrolled production and
distribution of such content. To address this, we propose VideoEraser, a
training-free framework that prevents T2V diffusion models from generating
videos with undesirable concepts, even when explicitly prompted with those
concepts. Designed as a plug-and-play module, VideoEraser can seamlessly
integrate with representative T2V diffusion models via a two-stage process:
Selective Prompt Embedding Adjustment (SPEA) and Adversarial-Resilient Noise
Guidance (ARNG). We conduct extensive evaluations across four tasks, including
object erasure, artistic style erasure, celebrity erasure, and explicit content
erasure. Experimental results show that VideoEraser consistently outperforms
prior methods regarding efficacy, integrity, fidelity, robustness, and
generalizability. Notably, VideoEraser achieves state-of-the-art performance in
suppressing undesirable content during T2V generation, reducing it by 46% on
average across four tasks compared to baselines.

</details>


### [67] [Predicting Road Crossing Behaviour using Pose Detection and Sequence Modelling](https://arxiv.org/abs/2508.15336)
*Subhasis Dasgupta,Preetam Saha,Agniva Roy,Jaydip Sen*

Main category: cs.CV

TL;DR: 本研究利用深度学习（姿态预测与序列建模）预测行人过马路意图，发现1D CNN在速度上表现最佳，GRU在准确性上优于LSTM。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶汽车的普及，车辆需要提前从远处预测行人是否即将过马路，以确保行车安全和作出相应决策。

Method: 研究采用端到端深度学习框架。首先使用深度学习模型进行姿态检测，然后将姿态检测的输出整合到三种不同的序列建模技术（GRU、LSTM和1D CNN）中，以进行时间序列预测来预测行人过马路意图。

Result: 在预测行人过马路意图方面，GRU模型表现优于LSTM模型。然而，1D CNN模型在处理速度方面表现最佳。

Conclusion: 针对行人过马路意图预测任务，GRU在预测准确性上表现较好，而1D CNN在速度方面具有显著优势，为自动驾驶系统提供了潜在的实时预测解决方案。

Abstract: The world is constantly moving towards AI based systems and autonomous
vehicles are now reality in different parts of the world. These vehicles
require sensors and cameras to detect objects and maneuver according to that.
It becomes important to for such vehicles to also predict from a distant if a
person is about to cross a road or not. The current study focused on predicting
the intent of crossing the road by pedestrians in an experimental setup. The
study involved working with deep learning models to predict poses and sequence
modelling for temporal predictions. The study analysed three different sequence
modelling to understand the prediction behaviour and it was found out that GRU
was better in predicting the intent compared to LSTM model but 1D CNN was the
best model in terms of speed. The study involved video analysis, and the output
of pose detection model was integrated later on to sequence modelling
techniques for an end-to-end deep learning framework for predicting road
crossing intents.

</details>


### [68] [RCDINO: Enhancing Radar-Camera 3D Object Detection with DINOv2 Semantic Features](https://arxiv.org/abs/2508.15353)
*Olga Matykina,Dmitry Yudin*

Main category: cs.CV

TL;DR: RCDINO是一种多模态Transformer模型，通过融合预训练DINOv2模型的语义特征来增强视觉骨干特征，从而在nuScenes数据集上实现了雷达-相机3D目标检测的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶和机器人技术需要有效的3D目标检测，这依赖于相机和雷达等多模态数据的有效融合。当前挑战在于如何有效增强视觉特征以提升检测性能。

Method: 本文提出了RCDINO模型，它是一种基于Transformer的多模态模型。该方法通过将视觉骨干特征与来自预训练DINOv2基础模型的语义丰富表示进行融合，来增强视觉特征，同时保持与基线架构的兼容性。

Result: 在nuScenes数据集上的实验表明，RCDINO在雷达-相机模型中取得了最先进的性能，NDS达到56.4，mAP达到48.1。

Conclusion: RCDINO通过融合DINOv2的语义特征有效提升了视觉表示和模型检测性能，在雷达-相机3D目标检测领域达到了领先水平。

Abstract: Three-dimensional object detection is essential for autonomous driving and
robotics, relying on effective fusion of multimodal data from cameras and
radar. This work proposes RCDINO, a multimodal transformer-based model that
enhances visual backbone features by fusing them with semantically rich
representations from the pretrained DINOv2 foundation model. This approach
enriches visual representations and improves the model's detection performance
while preserving compatibility with the baseline architecture. Experiments on
the nuScenes dataset demonstrate that RCDINO achieves state-of-the-art
performance among radar-camera models, with 56.4 NDS and 48.1 mAP. Our
implementation is available at https://github.com/OlgaMatykina/RCDINO.

</details>


### [69] [An Empirical Study on How Video-LLMs Answer Video Questions](https://arxiv.org/abs/2508.15360)
*Chenhui Gou,Ziyu Ma,Zicheng Duan,Haoyu He,Feng Chen,Akide Liu,Bohan Zhuang,Jianfei Cai,Hamid Rezatofighi*

Main category: cs.CV

TL;DR: 本研究通过注意力剔除（attention knockouts）方法，系统地分析了视频大语言模型（Video-LLMs）的内部机制，揭示了视频信息处理的阶段性特征、关键层的重要性以及语言引导检索在时空建模中的主导作用，并为模型效率优化提供了见解。


<details>
  <summary>Details</summary>
Motivation: 尽管视频大语言模型在视频问答方面表现出色，但现有研究主要关注性能提升，对模型内部机制的理解有限。本研究旨在填补这一空白，系统地解释Video-LLMs如何内部处理和理解视频内容。

Method: 采用注意力剔除（attention knockouts）作为主要分析工具，设计了三种变体：视频时间剔除、视频空间剔除和语言到视频剔除。这些剔除方法应用于不同层数（层窗口），并设置了全局和细粒度两种分析情境，以系统地解释现有Video-LLMs。

Result: 研究揭示了三个关键发现：(1) 在全局设置下，视频信息提取主要发生在早期层，形成清晰的两阶段过程——较低层侧重感知编码，较高层处理抽象推理；(2) 在细粒度设置下，某些中间层对视频问答具有超常影响，是关键的异常点，而大多数其他层的贡献极小；(3) 在两种设置下，时空建模更多依赖语言引导检索，而非视频token内部和帧间的自注意力，尽管后者计算成本高。这些见解可用于减少Video-LLMs中的注意力计算。

Conclusion: 本研究是首次系统地揭示Video-LLMs如何内部处理和理解视频内容的工作，为未来的研究提供了可解释性和效率方面的视角。研究结果表明，通过理解模型内部机制，可以实现模型优化和计算效率提升。

Abstract: Taking advantage of large-scale data and pretrained language models, Video
Large Language Models (Video-LLMs) have shown strong capabilities in answering
video questions. However, most existing efforts focus on improving performance,
with limited attention to understanding their internal mechanisms. This paper
aims to bridge this gap through a systematic empirical study. To interpret
existing VideoLLMs, we adopt attention knockouts as our primary analytical tool
and design three variants: Video Temporal Knockout, Video Spatial Knockout, and
Language-to-Video Knockout. Then, we apply these three knockouts on different
numbers of layers (window of layers). By carefully controlling the window of
layers and types of knockouts, we provide two settings: a global setting and a
fine-grained setting. Our study reveals three key findings: (1) Global setting
indicates Video information extraction primarily occurs in early layers,
forming a clear two-stage process -- lower layers focus on perceptual encoding,
while higher layers handle abstract reasoning; (2) In the fine-grained setting,
certain intermediate layers exert an outsized impact on video question
answering, acting as critical outliers, whereas most other layers contribute
minimally; (3) In both settings, we observe that spatial-temporal modeling
relies more on language-guided retrieval than on intra- and inter-frame
self-attention among video tokens, despite the latter's high computational
cost. Finally, we demonstrate that these insights can be leveraged to reduce
attention computation in Video-LLMs. To our knowledge, this is the first work
to systematically uncover how Video-LLMs internally process and understand
video content, offering interpretability and efficiency perspectives for future
research.

</details>


### [70] [Transfer learning optimization based on evolutionary selective fine tuning](https://arxiv.org/abs/2508.15367)
*Jacinto Colan,Ana Davila,Yasuhisa Hasegawa*

Main category: cs.CV

TL;DR: BioTune是一种基于进化算法的自适应微调技术，通过选择性微调模型层，显著提高了迁移学习的效率和准确性，同时降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型计算需求高，传统微调方法更新所有参数可能导致过拟合和高计算成本。研究旨在开发更高效的迁移学习策略。

Method: 本文提出了BioTune，它利用进化算法来识别并选择模型中的特定层进行微调，以优化模型在特定目标任务上的性能。这种方法旨在集中微调过程，减少可训练参数的数量。

Result: BioTune在九个图像分类数据集上的评估显示，与AutoRGN和LoRA等现有微调方法相比，它实现了具有竞争力或更高的准确性和效率。通过减少可训练参数，BioTune降低了潜在的计算成本。

Conclusion: BioTune通过将微调过程集中在相关层子集上，有效地减少了计算成本并促进了跨不同数据特征和分布的更高效迁移学习。

Abstract: Deep learning has shown substantial progress in image analysis. However, the
computational demands of large, fully trained models remain a consideration.
Transfer learning offers a strategy for adapting pre-trained models to new
tasks. Traditional fine-tuning often involves updating all model parameters,
which can potentially lead to overfitting and higher computational costs. This
paper introduces BioTune, an evolutionary adaptive fine-tuning technique that
selectively fine-tunes layers to enhance transfer learning efficiency. BioTune
employs an evolutionary algorithm to identify a focused set of layers for
fine-tuning, aiming to optimize model performance on a given target task.
Evaluation across nine image classification datasets from various domains
indicates that BioTune achieves competitive or improved accuracy and efficiency
compared to existing fine-tuning methods such as AutoRGN and LoRA. By
concentrating the fine-tuning process on a subset of relevant layers, BioTune
reduces the number of trainable parameters, potentially leading to decreased
computational cost and facilitating more efficient transfer learning across
diverse data characteristics and distributions.

</details>


### [71] [Image-Conditioned 3D Gaussian Splat Quantization](https://arxiv.org/abs/2508.15372)
*Xinshuang Liu,Runfa Blark Li,Keito Suzuki,Truong Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种名为ICGS-Quantizer的方法，旨在将3D Gaussian Splatting（3DGS）场景的存储需求压缩至千字节级别，同时通过图像条件解码实现归档后场景的适应性更新，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 尽管3DGS压缩方法已被提出，但它们存在两个局限性：1) 压缩效率不足，对于大规模场景或大量场景集合，压缩后的文件大小（兆字节范围）仍然不切实际；2) 缺乏在长期归档后适应场景变化的能力。

Method: 本文提出了Image-Conditioned Gaussian Splat Quantizer (ICGS-Quantizer)。该方法通过联合利用高斯间和属性间的相关性来提高量化效率，并使用跨所有训练场景共享的固定码本，从而消除了每场景码本的开销。为了实现归档后场景变化的适应性，ICGS-Quantizer将场景解码过程条件化于解码时捕获的图像。编码、量化和解码过程是联合训练的，以确保量化后的场景表示对于条件解码是有效的。

Result: 实验结果表明，ICGS-Quantizer能够将3DGS的存储需求有效降低到千字节范围，同时保持视觉保真度。在3D场景压缩和3D场景更新方面，ICGS-Quantizer始终优于最先进的方法，在压缩效率和对场景变化的适应性方面均表现出色。

Conclusion: ICGS-Quantizer通过显著提高压缩效率和提供归档后场景变化的适应性，解决了现有3DGS压缩方法的关键局限性，使得3DGS能够更有效地用于大规模场景的归档和更新。

Abstract: 3D Gaussian Splatting (3DGS) has attracted considerable attention for
enabling high-quality real-time rendering. Although 3DGS compression methods
have been proposed for deployment on storage-constrained devices, two
limitations hinder archival use: (1) they compress medium-scale scenes only to
the megabyte range, which remains impractical for large-scale scenes or
extensive scene collections; and (2) they lack mechanisms to accommodate scene
changes after long-term archival. To address these limitations, we propose an
Image-Conditioned Gaussian Splat Quantizer (ICGS-Quantizer) that substantially
enhances compression efficiency and provides adaptability to scene changes
after archiving. ICGS-Quantizer improves quantization efficiency by jointly
exploiting inter-Gaussian and inter-attribute correlations and by using shared
codebooks across all training scenes, which are then fixed and applied to
previously unseen test scenes, eliminating the overhead of per-scene codebooks.
This approach effectively reduces the storage requirements for 3DGS to the
kilobyte range while preserving visual fidelity. To enable adaptability to
post-archival scene changes, ICGS-Quantizer conditions scene decoding on images
captured at decoding time. The encoding, quantization, and decoding processes
are trained jointly, ensuring that the codes, which are quantized
representations of the scene, are effective for conditional decoding. We
evaluate ICGS-Quantizer on 3D scene compression and 3D scene updating.
Experimental results show that ICGS-Quantizer consistently outperforms
state-of-the-art methods in compression efficiency and adaptability to scene
changes. Our code, model, and data will be publicly available on GitHub.

</details>


### [72] [DriveSplat: Decoupled Driving Scene Reconstruction with Geometry-enhanced Partitioned Neural Gaussians](https://arxiv.org/abs/2508.15376)
*Cong Wang,Xianda Guo,Wenbo Xu,Wei Tian,Ruiqi Song,Chenming Zhang,Lingxi Li,Long Chen*

Main category: cs.CV

TL;DR: 本文提出DriveSplat，一种用于驾驶场景的高质量3D重建方法，通过动态-静态解耦的神经高斯表示，结合区域体素初始化、可变形神经高斯和深度/法线先验监督，解决了现有方法的几何精度和新视角渲染鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 驾驶场景中快速移动的车辆、行人以及大规模静态背景给3D场景重建带来巨大挑战。现有的基于3D高斯Splatting的方法虽通过动静解耦处理运动模糊，但忽略了背景几何优化，仅依赖高斯拟合训练视图，导致新视角渲染鲁棒性差，缺乏精确几何表示。

Method: 本文引入DriveSplat。主要方法包括：1) 采用区域体素初始化方案，将场景划分为近、中、远区域，以适应驾驶视角的线性运动模式并增强近距离细节；2) 引入可变形神经高斯来建模非刚性动态物体，其参数通过可学习的形变网络进行时间调整；3) 整个框架通过预训练模型的深度和法线先验进行监督，以提高几何结构的准确性。

Result: DriveSplat在Waymo和KITTI数据集上进行了严格评估，在新视角合成方面展现出最先进的性能。

Conclusion: DriveSplat通过其创新的动态-静态解耦神经高斯表示、区域初始化、可变形高斯以及几何先验监督，成功解决了驾驶场景3D重建中的几何精度和新视角渲染鲁棒性问题，实现了高质量的驾驶场景新视角合成。

Abstract: In the realm of driving scenarios, the presence of rapidly moving vehicles,
pedestrians in motion, and large-scale static backgrounds poses significant
challenges for 3D scene reconstruction. Recent methods based on 3D Gaussian
Splatting address the motion blur problem by decoupling dynamic and static
components within the scene. However, these decoupling strategies overlook
background optimization with adequate geometry relationships and rely solely on
fitting each training view by adding Gaussians. Therefore, these models exhibit
limited robustness in rendering novel views and lack an accurate geometric
representation. To address the above issues, we introduce DriveSplat, a
high-quality reconstruction method for driving scenarios based on neural
Gaussian representations with dynamic-static decoupling. To better accommodate
the predominantly linear motion patterns of driving viewpoints, a region-wise
voxel initialization scheme is employed, which partitions the scene into near,
middle, and far regions to enhance close-range detail representation.
Deformable neural Gaussians are introduced to model non-rigid dynamic actors,
whose parameters are temporally adjusted by a learnable deformation network.
The entire framework is further supervised by depth and normal priors from
pre-trained models, improving the accuracy of geometric structures. Our method
has been rigorously evaluated on the Waymo and KITTI datasets, demonstrating
state-of-the-art performance in novel-view synthesis for driving scenarios.

</details>


### [73] [DIO: Refining Mutual Information and Causal Chain to Enhance Machine Abstract Reasoning Ability](https://arxiv.org/abs/2508.15387)
*Ruizhuo Song,Beiming Yuan*

Main category: cs.CV

TL;DR: 本文旨在通过解决瑞文渐进矩阵 (RPM) 问题来增强机器的抽象推理能力。论文首先采用“因果链建模”分析RPM任务，并设计了基线模型DIO。然而，实验发现DIO的互信息最大化目标未能有效捕获人类推理逻辑，原因在于下界紧密性不足和互信息的统计性。为克服这些限制，论文提出了三种改进方法。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型在抽象推理方面存在根本性瓶颈。瑞文渐进矩阵 (RPM) 问题是评估深度学习算法抽象推理能力、模式识别和复杂问题解决能力的重要基准。因此，本研究旨在通过解决RPM问题来提升机器智能的抽象推理能力。

Method: 1. 采用“因果链建模”视角，系统分析RPM任务中的完整因果链：图像 → 抽象属性 → 渐进属性模式 → 模式一致性 → 正确答案。
2. 基于上述分析，设计了基线模型DIO的网络架构。
3. DIO的优化目标是最大化上下文与正确选项之间互信息的变分下界。
4. 针对DIO的局限性（下界紧密性影响互信息最大化，互信息作为统计度量未能捕获因果关系），提出了三种改进方法。

Result: 实验表明，为DIO制定的优化目标（最大化上下文与正确选项之间互信息的变分下界）未能使模型真正获得预定义的人类推理逻辑。这主要归因于两个原因：下界的紧密性显著影响互信息最大化的有效性；互信息作为统计度量，未能捕获主体与客体之间的因果关系。

Conclusion: 尽管通过因果链建模分析设计了基线模型DIO，但基于互信息最大化的优化目标未能有效使模型习得人类抽象推理逻辑。这暴露了当前方法在互信息下界紧密性和因果关系捕获方面的局限性。为解决这些问题，论文提出了进一步的改进方法。

Abstract: Despite the outstanding performance of current deep learning models across
various domains, their fundamental bottleneck in abstract reasoning remains
unresolved. To address this challenge, the academic community has introduced
Raven's Progressive Matrices (RPM) problems as an authoritative benchmark for
evaluating the abstract reasoning capabilities of deep learning algorithms,
with a focus on core intelligence dimensions such as abstract reasoning,
pattern recognition, and complex problem-solving. Therefore, this paper centers
on solving RPM problems, aiming to contribute to enhancing the abstract
reasoning abilities of machine intelligence. Firstly, this paper adopts a
``causal chain modeling'' perspective to systematically analyze the complete
causal chain in RPM tasks: image $\rightarrow$ abstract attributes
$\rightarrow$ progressive attribute patterns $\rightarrow$ pattern consistency
$\rightarrow$ correct answer. Based on this analysis, the network architecture
of the baseline model DIO is designed. However, experiments reveal that the
optimization objective formulated for DIO, namely maximizing the variational
lower bound of mutual information between the context and the correct option,
fails to enable the model to genuinely acquire the predefined human reasoning
logic. This is attributed to two main reasons: the tightness of the lower bound
significantly impacts the effectiveness of mutual information maximization, and
mutual information, as a statistical measure, does not capture the causal
relationship between subjects and objects. To overcome these limitations, this
paper progressively proposes three improvement methods:

</details>


### [74] [Spiking Variational Graph Representation Inference for Video Summarization](https://arxiv.org/abs/2508.15389)
*Wenrui Li,Wei Han,Liang-Jian Deng,Ruiqin Xiong,Xiaopeng Fan*

Main category: cs.CV

TL;DR: 本文提出了一种名为SpiVG的脉冲变分图网络，利用脉冲神经网络（SNN）进行关键帧提取，并结合动态聚合图推理器和变分推理重建模块，有效解决了现有视频摘要方法在全局时间依赖、语义连贯性和多通道特征融合噪声方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有视频摘要方法难以捕捉全局时间依赖性并维持语义连贯性，同时在多通道特征融合过程中容易受到噪声影响，导致信息密度不足和计算复杂性高。

Method: 本文提出了SpiVG网络，包含三个核心组件：1) 基于脉冲神经网络（SNN）的关键帧提取器，利用SNN的事件驱动计算机制自主学习关键帧特征；2) 动态聚合图推理器，用于解耦上下文对象一致性和语义视角连贯性，实现视频帧间的细粒度自适应推理；3) 变分推理重建模块，采用证据下界优化（ELBO）捕捉多通道特征分布的潜在结构，并通过后验分布正则化减少过拟合，以处理多通道特征融合中的不确定性和噪声。

Result: 实验结果表明，SpiVG在SumMe、TVSum、VideoXum和QFVS等多个数据集上均超越了现有方法。

Conclusion: SpiVG网络通过结合SNN、动态图推理和变分推理，有效提升了视频摘要的信息密度，降低了计算复杂性，并在多个数据集上取得了优于现有方法的性能，解决了视频摘要中的关键挑战。

Abstract: With the rise of short video content, efficient video summarization
techniques for extracting key information have become crucial. However,
existing methods struggle to capture the global temporal dependencies and
maintain the semantic coherence of video content. Additionally, these methods
are also influenced by noise during multi-channel feature fusion. We propose a
Spiking Variational Graph (SpiVG) Network, which enhances information density
and reduces computational complexity. First, we design a keyframe extractor
based on Spiking Neural Networks (SNN), leveraging the event-driven computation
mechanism of SNNs to learn keyframe features autonomously. To enable
fine-grained and adaptable reasoning across video frames, we introduce a
Dynamic Aggregation Graph Reasoner, which decouples contextual object
consistency from semantic perspective coherence. We present a Variational
Inference Reconstruction Module to address uncertainty and noise arising during
multi-channel feature fusion. In this module, we employ Evidence Lower Bound
Optimization (ELBO) to capture the latent structure of multi-channel feature
distributions, using posterior distribution regularization to reduce
overfitting. Experimental results show that SpiVG surpasses existing methods
across multiple datasets such as SumMe, TVSum, VideoXum, and QFVS. Our codes
and pre-trained models are available at https://github.com/liwrui/SpiVG.

</details>


### [75] [From Linearity to Non-Linearity: How Masked Autoencoders Capture Spatial Correlations](https://arxiv.org/abs/2508.15404)
*Anthony Bisulco,Rahul Ramesh,Randall Balestriero,Pratik Chaudhari*

Main category: cs.CV

TL;DR: 本文通过理论分析，揭示了MAE超参数（如遮蔽率和补丁大小）如何影响其学习图像空间相关性的能力，并为实际的超参数选择提供了指导。


<details>
  <summary>Details</summary>
Motivation: 尽管MAE是一种强大的视觉基础模型预训练技术，但在应用于新数据集时，需要进行大量的超参数调优。现有理论研究尚未充分探索MAE超参数与下游任务性能之间的具体联系。

Method: 研究首先分析推导了线性MAE学习到的特征，然后将此分析扩展到非线性MAE，以探究其表示如何适应数据集中的空间相关性。

Result: 研究表明，线性MAE的遮蔽率和补丁大小可以用于选择捕获短程和长程空间相关性的特征。此外，非线性MAE的表示能够适应数据集中超越二阶统计量的空间相关性。

Conclusion: 本研究深入理解了MAE如何学习空间相关性以及超参数对其影响，并为在实践中选择MAE超参数提供了有价值的见解。

Abstract: Masked Autoencoders (MAEs) have emerged as a powerful pretraining technique
for vision foundation models. Despite their effectiveness, they require
extensive hyperparameter tuning (masking ratio, patch size, encoder/decoder
layers) when applied to novel datasets. While prior theoretical works have
analyzed MAEs in terms of their attention patterns and hierarchical latent
variable models, the connection between MAE hyperparameters and performance on
downstream tasks is relatively unexplored. This work investigates how MAEs
learn spatial correlations in the input image. We analytically derive the
features learned by a linear MAE and show that masking ratio and patch size can
be used to select for features that capture short- and long-range spatial
correlations. We extend this analysis to non-linear MAEs to show that MAE
representations adapt to spatial correlations in the dataset, beyond
second-order statistics. Finally, we discuss some insights on how to select MAE
hyper-parameters in practice.

</details>


### [76] [Bidirectional Temporal Information Propagation for Moving Infrared Small Target Detection](https://arxiv.org/abs/2508.15415)
*Dengyan Luo,Yanping Xiang,Hu Wang,Luping Ji. Shuai Li,Mao Ye*

Main category: cs.CV

TL;DR: 针对红外小目标检测中滑动窗口方法忽略全局时间信息的问题，本文提出BIRD方法，通过双向时间信息传播（局部与全局）联合优化整个视频，实现了最先进的性能和快速推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的多帧红外小目标检测方法主要采用滑动窗口方式聚合信息，但这种方式未考虑整个视频片段的联合优化，忽略了滑动窗口之外的全局时间信息，导致计算冗余和次优性能。

Method: 本文提出BIRD（Moving InfraRed small target Detection的双向时间信息传播方法）。该方法采用递归的双向传播策略，同时利用相邻帧的局部时间信息和过去、未来帧的全局时间信息。具体而言，在正向和反向传播分支中，首先设计局部时间运动融合（LTMF）模块建模目标帧与其相邻两帧之间的局部时空依赖；然后开发全局时间运动融合（GTMF）模块进一步聚合全局传播特征与局部融合特征。最后，将双向聚合的特征融合并输入检测头。此外，通过传统检测损失和额外的时空融合（STF）损失共同优化整个视频片段。

Result: 实验结果表明，所提出的BIRD方法不仅取得了最先进的性能，而且展示了快速的推理速度。

Conclusion: BIRD方法通过创新的双向时间信息传播策略，有效解决了传统滑动窗口方法在红外小目标检测中存在的局限性，实现了性能和效率的显著提升。

Abstract: Moving infrared small target detection is broadly adopted in infrared search
and track systems, and has attracted considerable research focus in recent
years. The existing learning-based multi-frame methods mainly aggregate the
information of adjacent frames in a sliding window fashion to assist the
detection of the current frame. However, the sliding-window-based methods do
not consider joint optimization of the entire video clip and ignore the global
temporal information outside the sliding window, resulting in redundant
computation and sub-optimal performance. In this paper, we propose a
Bidirectional temporal information propagation method for moving InfraRed small
target Detection, dubbed BIRD. The bidirectional propagation strategy
simultaneously utilizes local temporal information of adjacent frames and
global temporal information of past and future frames in a recursive fashion.
Specifically, in the forward and backward propagation branches, we first design
a Local Temporal Motion Fusion (LTMF) module to model local spatio-temporal
dependency between a target frame and its two adjacent frames. Then, a Global
Temporal Motion Fusion (GTMF) module is developed to further aggregate the
global propagation feature with the local fusion feature. Finally, the
bidirectional aggregated features are fused and input into the detection head
for detection. In addition, the entire video clip is jointly optimized by the
traditional detection loss and the additional Spatio-Temporal Fusion (STF)
loss. Extensive experiments demonstrate that the proposed BIRD method not only
achieves the state-of-the-art performance but also shows a fast inference
speed.

</details>


### [77] [The Impact of Image Resolution on Face Detection: A Comparative Analysis of MTCNN, YOLOv XI and YOLOv XII models](https://arxiv.org/abs/2507.23341)
*Ahmet Can Ömercikoğlu,Mustafa Mansur Yönügül,Pakize Erdoğmuş*

Main category: cs.CV

TL;DR: 本研究系统评估了输入分辨率对YOLOv11、YOLOv12和MTCNN三种人脸检测器性能的影响。结果显示YOLOv11在准确性上表现最佳，尤其在高分辨率下；YOLOv12召回率稍好；MTCNN实时推理速度较慢。


<details>
  <summary>Details</summary>
Motivation: 人脸检测是许多AI应用的关键组成部分，但低分辨率图像等真实世界条件会显著降低检测性能，构成重大挑战。

Method: 研究系统地调查了输入分辨率对YOLOv11、YOLOv12和MTCNN三种深度学习人脸检测器准确性和鲁棒性的影响。使用WIDER FACE数据集，在多种图像分辨率（160x160、320x320和640x640）下进行广泛评估，并使用精确度、召回率、mAP50、mAP50-95和推理时间等指标衡量模型性能。

Result: 结果表明，YOLOv11在检测准确性方面优于YOLOv12和MTCNN，尤其是在较高分辨率下；YOLOv12展现出稍好的召回率；MTCNN虽然在关键点定位方面具有竞争力，但在实时推理速度上落后。

Conclusion: 本研究结果为根据不同操作约束选择对分辨率敏感的人脸检测模型提供了可操作的见解。

Abstract: Face detection is a crucial component in many AI-driven applications such as
surveillance, biometric authentication, and human-computer interaction.
However, real-world conditions like low-resolution imagery present significant
challenges that degrade detection performance. In this study, we systematically
investigate the impact of input resolution on the accuracy and robustness of
three prominent deep learning-based face detectors: YOLOv11, YOLOv12, and
MTCNN. Using the WIDER FACE dataset, we conduct extensive evaluations across
multiple image resolutions (160x160, 320x320, and 640x640) and assess each
model's performance using metrics such as precision, recall, mAP50, mAP50-95,
and inference time. Results indicate that YOLOv11 outperforms YOLOv12 and MTCNN
in terms of detection accuracy, especially at higher resolutions, while YOLOv12
exhibits slightly better recall. MTCNN, although competitive in landmark
localization, lags in real-time inference speed. Our findings provide
actionable insights for selecting resolution-aware face detection models
suitable for varying operational constraints.

</details>


### [78] [A Curated Dataset and Deep Learning Approach for Minor Dent Detection in Vehicles](https://arxiv.org/abs/2508.15431)
*Danish Zia Baig,Mohsin Kamal*

Main category: cs.CV

TL;DR: 该研究利用YOLOv8深度学习框架，开发了一种自动检测汽车表面微小凹痕的方法。通过定制数据集和YOLOv8m-t42变体模型，实现了高精度和低延迟的检测，适用于实时汽车损伤评估。


<details>
  <summary>Details</summary>
Motivation: 传统的汽车损伤检测方法劳动密集、人工操作且耗时，难以准确发现微小的表面缺陷（如微观凹痕），导致检测效率低且不可靠。市场对更快、更精确的检测方法有日益增长的需求。

Method: 本研究创建了一个包含多种光照、角度和纹理下汽车表面带注释图像的定制数据集。采用YOLOv8对象识别框架，并训练了YOLOv8m模型及其定制变体（YOLOv8m-t4和YOLOv8m-t42），使用实时数据增强技术以提高鲁棒性。模型的有效性通过平均精度（mAP）、精确度、召回率和F1分数等参数进行评估。

Result: 实验结果表明，该方法具有出色的检测精度和低推理延迟。YOLOv8m-t42模型在检测微观表面缺陷方面表现最佳，其精确度为0.86，召回率为0.84，F1分数为0.85，优于YOLOv8m-t4模型。YOLOv8m-t42的mAP@0.5稳定在0.60，PR曲线下面积为0.88，表明其性能更为一致。

Conclusion: YOLOv8m-t42模型在汽车表面微小凹痕检测中展现出更高的准确性和更一致的性能，尽管收敛速度较慢，但其高精度和低延迟使其非常适合实时应用，如自动化保险评估和汽车检测。

Abstract: Conventional car damage inspection techniques are labor-intensive, manual,
and frequently overlook tiny surface imperfections like microscopic dents.
Machine learning provides an innovative solution to the increasing demand for
quicker and more precise inspection methods. The paper uses the YOLOv8 object
recognition framework to provide a deep learning-based solution for
automatically detecting microscopic surface flaws, notably tiny dents, on car
exteriors. Traditional automotive damage inspection procedures are manual,
time-consuming, and frequently unreliable at detecting tiny flaws. To solve
this, a bespoke dataset containing annotated photos of car surfaces under
various lighting circumstances, angles, and textures was created. To improve
robustness, the YOLOv8m model and its customized variants, YOLOv8m-t4 and
YOLOv8m-t42, were trained employing real-time data augmentation approaches.
Experimental results show that the technique has excellent detection accuracy
and low inference latency, making it suited for real-time applications such as
automated insurance evaluations and automobile inspections. Evaluation
parameters such as mean Average Precision (mAP), precision, recall, and
F1-score verified the model's efficacy. With a precision of 0.86, recall of
0.84, and F1-score of 0.85, the YOLOv8m-t42 model outperformed the YOLOv8m-t4
model (precision: 0.81, recall: 0.79, F1-score: 0.80) in identifying
microscopic surface defects. With a little reduced mAP@0.5:0.95 of 0.20, the
mAP@0.5 for YOLOv8m-t42 stabilized at 0.60. Furthermore, YOLOv8m-t42's PR curve
area was 0.88, suggesting more consistent performance than YOLOv8m-t4 (0.82).
YOLOv8m-t42 has greater accuracy and is more appropriate for practical dent
detection applications, even though its convergence is slower.

</details>


### [79] [Aligning Moments in Time using Video Queries](https://arxiv.org/abs/2508.15439)
*Yogesh Kumar,Uday Agarwal,Manish Gupta,Anand Mishra*

Main category: cs.CV

TL;DR: 本文提出MATR模型，一个基于Transformer的模型，用于视频到视频的精彩瞬间检索（Vid2VidMR）。它通过双阶段序列对齐和自监督预训练，在语义匹配和时间定位方面表现出色，显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 视频到视频的精彩瞬间检索（Vid2VidMR）任务面临多项挑战，包括需要实现语义帧级对齐以及建模查询视频和目标视频之间复杂的依赖关系。

Method: 本文提出了MATR（Moment Alignment TRansformer）模型，这是一个基于Transformer的模型，旨在捕捉语义上下文和时间细节以进行精确的瞬间定位。MATR通过双阶段序列对齐，利用查询视频特征来条件化目标视频表示，从而编码所需的关联和依赖。这些表示随后用于指导前景/背景分类和边界预测头。此外，为MATR提供强大的任务特定初始化，本文提出了一种自监督预训练技术，通过训练模型在视频内定位随机片段。

Result: 在流行的ActivityNet-VRL数据集上，MATR在R@1指标上绝对提升了13.1%，在mIoU指标上绝对提升了8.1%，优于现有最先进方法。在新提出的SportsMoments数据集上，MATR在R@1指标上绝对提升了14.7%，在mIoU指标上绝对提升了14.4%，优于强基线模型。

Conclusion: MATR模型通过捕获语义上下文和时间细节，有效解决了视频到视频精彩瞬间检索的挑战，并在多个数据集上取得了显著的性能提升，证明了其在精确瞬间定位方面的能力。

Abstract: Video-to-video moment retrieval (Vid2VidMR) is the task of localizing unseen
events or moments in a target video using a query video. This task poses
several challenges, such as the need for semantic frame-level alignment and
modeling complex dependencies between query and target videos. To tackle this
challenging problem, we introduce MATR (Moment Alignment TRansformer), a
transformer-based model designed to capture semantic context as well as the
temporal details necessary for precise moment localization. MATR conditions
target video representations on query video features using dual-stage sequence
alignment that encodes the required correlations and dependencies. These
representations are then used to guide foreground/background classification and
boundary prediction heads, enabling the model to accurately identify moments in
the target video that semantically match with the query video. Additionally, to
provide a strong task-specific initialization for MATR, we propose a
self-supervised pre-training technique that involves training the model to
localize random clips within videos. Extensive experiments demonstrate that
MATR achieves notable performance improvements of 13.1% in R@1 and 8.1% in mIoU
on an absolute scale compared to state-of-the-art methods on the popular
ActivityNet-VRL dataset. Additionally, on our newly proposed dataset,
SportsMoments, MATR shows a 14.7% gain in R@1 and a 14.4% gain in mIoU on an
absolute scale over strong baselines.

</details>


### [80] [Enhancing Novel View Synthesis from extremely sparse views with SfM-free 3D Gaussian Splatting Framework](https://arxiv.org/abs/2508.15457)
*Zongqi He,Hanmin Li,Kin-Chung Chan,Yushen Zuo,Hao Xie,Zhe Xiao,Jun Xiao,Kin-Man Lam*

Main category: cs.CV

TL;DR: 本文提出了一种无需SfM的3D Gaussian Splatting方法，通过密集立体模块、相干视图插值和多尺度正则化，显著提升了在极稀疏视图条件下的新颖视图合成质量。


<details>
  <summary>Details</summary>
Motivation: 3DGS在稀疏视图输入下，其依赖的SfM方法难以准确重建3D几何结构，导致渲染质量下降。现实世界中，密集多视图和精确相机姿态往往难以获得，因此需要一种无需SfM且能处理极稀疏视图的方法。

Method: 1. 提出一个密集立体模块，逐步估计相机姿态并重建全局密集点云用于初始化，替代SfM。 2. 引入一个相干视图插值模块，基于训练视图对插值相机姿态并生成视图一致的内容作为额外监督信号。 3. 引入多尺度拉普拉斯一致性正则化和自适应空间感知多尺度几何正则化，以增强几何结构和渲染内容的质量。

Result: 在极稀疏视图条件下（仅使用2个训练视图），该方法显著优于其他最先进的3DGS方法，PSNR提高了2.75dB。合成图像失真最小，保留了丰富的高频细节，视觉质量优于现有技术。

Conclusion: 所提出的无需SfM的3DGS方法有效解决了极稀疏视图输入下的新颖视图合成挑战，通过创新的初始化、监督和正则化策略，实现了卓越的渲染质量和几何结构重建。

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated remarkable real-time
performance in novel view synthesis, yet its effectiveness relies heavily on
dense multi-view inputs with precisely known camera poses, which are rarely
available in real-world scenarios. When input views become extremely sparse,
the Structure-from-Motion (SfM) method that 3DGS depends on for initialization
fails to accurately reconstruct the 3D geometric structures of scenes,
resulting in degraded rendering quality. In this paper, we propose a novel
SfM-free 3DGS-based method that jointly estimates camera poses and reconstructs
3D scenes from extremely sparse-view inputs. Specifically, instead of SfM, we
propose a dense stereo module to progressively estimates camera pose
information and reconstructs a global dense point cloud for initialization. To
address the inherent problem of information scarcity in extremely sparse-view
settings, we propose a coherent view interpolation module that interpolates
camera poses based on training view pairs and generates viewpoint-consistent
content as additional supervision signals for training. Furthermore, we
introduce multi-scale Laplacian consistent regularization and adaptive
spatial-aware multi-scale geometry regularization to enhance the quality of
geometrical structures and rendered content. Experiments show that our method
significantly outperforms other state-of-the-art 3DGS-based approaches,
achieving a remarkable 2.75dB improvement in PSNR under extremely sparse-view
conditions (using only 2 training views). The images synthesized by our method
exhibit minimal distortion while preserving rich high-frequency details,
resulting in superior visual quality compared to existing techniques.

</details>


### [81] [LGMSNet: Thinning a medical image segmentation model via dual-level multiscale fusion](https://arxiv.org/abs/2508.15476)
*Chengqi Dong,Fenghe Tang,Rongge Mao,Xinpei Gao,S. Kevin Zhou*

Main category: cs.CV

TL;DR: 本文提出了LGMSNet，一个轻量级医学图像分割框架，通过结合局部和全局双多尺度处理，实现了在计算开销极小的情况下，超越现有最先进方法的性能，并展现出卓越的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级医学图像分割模型通常以牺牲性能为代价来提高效率，且很少采用计算成本高的注意力机制，从而限制了全局上下文感知能力。此外，当前架构忽视了医学图像中相同卷积核下的通道冗余问题，阻碍了有效的特征提取。这些问题在资源受限的临床环境中尤为突出。

Method: LGMSNet采用局部和全局双多尺度轻量级框架。它利用异构层内卷积核来提取局部高频信息并减少通道冗余。同时，模型集成了稀疏Transformer-卷积混合分支，以捕获低频全局信息。

Result: LGMSNet在六个公共数据集上进行了广泛实验，结果表明其性能优于现有最先进方法。特别是在四个未见数据集上的零样本泛化测试中，LGMSNet保持了卓越的性能。

Conclusion: LGMSNet在资源受限的医疗场景中具有巨大的实际部署潜力，因为它在保持极低计算开销的同时，实现了卓越的分割性能和出色的零样本泛化能力。

Abstract: Medical image segmentation plays a pivotal role in disease diagnosis and
treatment planning, particularly in resource-constrained clinical settings
where lightweight and generalizable models are urgently needed. However,
existing lightweight models often compromise performance for efficiency and
rarely adopt computationally expensive attention mechanisms, severely
restricting their global contextual perception capabilities. Additionally,
current architectures neglect the channel redundancy issue under the same
convolutional kernels in medical imaging, which hinders effective feature
extraction. To address these challenges, we propose LGMSNet, a novel
lightweight framework based on local and global dual multiscale that achieves
state-of-the-art performance with minimal computational overhead. LGMSNet
employs heterogeneous intra-layer kernels to extract local high-frequency
information while mitigating channel redundancy. In addition, the model
integrates sparse transformer-convolutional hybrid branches to capture
low-frequency global information. Extensive experiments across six public
datasets demonstrate LGMSNet's superiority over existing state-of-the-art
methods. In particular, LGMSNet maintains exceptional performance in zero-shot
generalization tests on four unseen datasets, underscoring its potential for
real-world deployment in resource-limited medical scenarios. The whole project
code is in https://github.com/cq-dong/LGMSNet.

</details>


### [82] [MExECON: Multi-view Extended Explicit Clothed humans Optimized via Normal integration](https://arxiv.org/abs/2508.15500)
*Fulden Ece Uğur,Rafael Redondo,Albert Barreiro,Stefan Hristov,Roger Marí*

Main category: cs.CV

TL;DR: MExECON是一个新颖的流水线，用于从稀疏多视角RGB图像重建穿衣人体3D形象，它扩展了单视角方法ECON，通过多视角联合优化和法线贴图集成，在不重新训练网络的情况下显著提升了几何和姿态估计的精度和细节。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从稀疏多视角RGB图像重建穿衣人体3D形象时，可能在几何和身体姿态估计方面存在不足。该研究旨在通过利用多个视角来改进这些方面，并从单视角方法中汲取灵感。

Method: 该方法名为MExECON，它扩展了单视角方法ECON的功能以利用多个视角。其核心是提出的联合多视角身体优化（JMBO）算法，该算法在所有输入视角中联合拟合单个SMPL-X身体模型，以强制实现多视角一致性。优化后的身体模型作为低频先验，指导后续的表面重建，通过法线贴图集成添加几何细节。MExECON集成了来自正面和背面视角的法线贴图，以准确捕捉衣物褶皱和发型等精细表面细节。所有多视角改进均无需任何网络重新训练。

Result: 实验结果表明，MExECON在保真度上始终优于单视角基线，并且与现代少样本3D重建方法相比，取得了具有竞争力的性能。

Conclusion: MExECON成功地利用多视角数据来增强穿衣人体形象的3D重建，提供了更高的保真度和更精细的细节，并且无需重新训练网络，证明了其与最先进的少样本方法相比的竞争力。

Abstract: This work presents MExECON, a novel pipeline for 3D reconstruction of clothed
human avatars from sparse multi-view RGB images. Building on the single-view
method ECON, MExECON extends its capabilities to leverage multiple viewpoints,
improving geometry and body pose estimation. At the core of the pipeline is the
proposed Joint Multi-view Body Optimization (JMBO) algorithm, which fits a
single SMPL-X body model jointly across all input views, enforcing multi-view
consistency. The optimized body model serves as a low-frequency prior that
guides the subsequent surface reconstruction, where geometric details are added
via normal map integration. MExECON integrates normal maps from both front and
back views to accurately capture fine-grained surface details such as clothing
folds and hairstyles. All multi-view gains are achieved without requiring any
network re-training. Experimental results show that MExECON consistently
improves fidelity over the single-view baseline and achieves competitive
performance compared to modern few-shot 3D reconstruction methods.

</details>


### [83] [Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion](https://arxiv.org/abs/2508.15505)
*Mengyu Wang,Zhenyu Liu,Kun Li,Yu Wang,Yuwei Wang,Yanyan Wei,Fei Wang*

Main category: cs.CV

TL;DR: AdaSFFuse是一个新颖的多模态图像融合（MMIF）框架，通过自适应近似小波变换（AdaWAT）进行频率解耦和空间-频率Mamba模块进行高效融合，解决了模态错位和高频细节丢失等问题，并在多个MMIF任务中实现了卓越的性能和效率平衡。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态图像融合（MMIF）方法面临模态错位、高频细节破坏以及任务特异性限制等挑战，需要一种更通用和高效的解决方案。

Method: 本文提出了AdaSFFuse框架，包含两大核心创新：1) 自适应近似小波变换（AdaWAT），用于自适应地分离多模态图像的高低频分量；2) 空间-频率Mamba模块，通过可学习映射动态调整，促进空间域和频率域的跨域融合。

Result: AdaSFFuse显著改善了多模态特征的对齐和整合，减少了频率损失，并保留了关键细节。在红外-可见光图像融合、多焦点图像融合、多曝光图像融合和医学图像融合这四种MMIF任务上，AdaSFFuse展示了卓越的融合性能，同时具有较低的计算成本和紧凑的网络结构，实现了性能与效率的良好平衡。

Conclusion: AdaSFFuse为任务泛化的多模态图像融合提供了一个强大而高效的解决方案，有效克服了现有方法的局限性，并在多种融合任务中展现出优越的性能。

Abstract: Multimodal Image Fusion (MMIF) aims to integrate complementary information
from different imaging modalities to overcome the limitations of individual
sensors. It enhances image quality and facilitates downstream applications such
as remote sensing, medical diagnostics, and robotics. Despite significant
advancements, current MMIF methods still face challenges such as modality
misalignment, high-frequency detail destruction, and task-specific limitations.
To address these challenges, we propose AdaSFFuse, a novel framework for
task-generalized MMIF through adaptive cross-domain co-fusion learning.
AdaSFFuse introduces two key innovations: the Adaptive Approximate Wavelet
Transform (AdaWAT) for frequency decoupling, and the Spatial-Frequency Mamba
Blocks for efficient multimodal fusion. AdaWAT adaptively separates the high-
and low-frequency components of multimodal images from different scenes,
enabling fine-grained extraction and alignment of distinct frequency
characteristics for each modality. The Spatial-Frequency Mamba Blocks
facilitate cross-domain fusion in both spatial and frequency domains, enhancing
this process. These blocks dynamically adjust through learnable mappings to
ensure robust fusion across diverse modalities. By combining these components,
AdaSFFuse improves the alignment and integration of multimodal features,
reduces frequency loss, and preserves critical details. Extensive experiments
on four MMIF tasks -- Infrared-Visible Image Fusion (IVF), Multi-Focus Image
Fusion (MFF), Multi-Exposure Image Fusion (MEF), and Medical Image Fusion (MIF)
-- demonstrate AdaSFFuse's superior fusion performance, ensuring both low
computational cost and a compact network, offering a strong balance between
performance and efficiency. The code will be publicly available at
https://github.com/Zhen-yu-Liu/AdaSFFuse.

</details>


### [84] [Towards a 3D Transfer-based Black-box Attack via Critical Feature Guidance](https://arxiv.org/abs/2508.15650)
*Shuchao Pang,Zhenghan Chen,Shen Zhang,Liming Lu,Siyuan Liang,Anan Du,Yongbin Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为CFG的新型迁移式黑盒攻击方法，通过腐蚀不同深度神经网络架构共享的关键特征，显著提高了3D点云对抗样本的迁移性，同时确保了其不可感知性。


<details>
  <summary>Details</summary>
Motivation: 以往的3D对抗攻击方法通常需要目标模型的参数或输出信息，这在现实世界的黑盒场景下难以获取。因此，研究人员希望开发一种无需目标模型任何信息的迁移式攻击方法。

Method: 该方法基于观察到点云分类的关键特征在不同DNN架构中具有一致性。为此，提出了关键特征指导（CFG）机制，通过计算提取特征的重要性来规范对抗点云的搜索，优先破坏那些可能被多种架构采用的关键特征。此外，通过在损失函数中明确限制生成对抗点云的最大偏差范围，以确保其不可感知性。

Result: 在ModelNet40和ScanObjectNN基准数据集上进行的广泛实验表明，所提出的CFG方法在性能上显著优于现有最先进的攻击方法。

Conclusion: CFG是一种有效的迁移式黑盒攻击方法，通过针对跨架构共享的关键特征，实现了对3D点云对抗样本的高迁移性和不可感知性。

Abstract: Deep neural networks for 3D point clouds have been demonstrated to be
vulnerable to adversarial examples. Previous 3D adversarial attack methods
often exploit certain information about the target models, such as model
parameters or outputs, to generate adversarial point clouds. However, in
realistic scenarios, it is challenging to obtain any information about the
target models under conditions of absolute security. Therefore, we focus on
transfer-based attacks, where generating adversarial point clouds does not
require any information about the target models. Based on our observation that
the critical features used for point cloud classification are consistent across
different DNN architectures, we propose CFG, a novel transfer-based black-box
attack method that improves the transferability of adversarial point clouds via
the proposed Critical Feature Guidance. Specifically, our method regularizes
the search of adversarial point clouds by computing the importance of the
extracted features, prioritizing the corruption of critical features that are
likely to be adopted by diverse architectures. Further, we explicitly constrain
the maximum deviation extent of the generated adversarial point clouds in the
loss function to ensure their imperceptibility. Extensive experiments conducted
on the ModelNet40 and ScanObjectNN benchmark datasets demonstrate that the
proposed CFG outperforms the state-of-the-art attack methods by a large margin.

</details>


### [85] [ExtraGS: Geometric-Aware Trajectory Extrapolation with Uncertainty-Guided Generative Priors](https://arxiv.org/abs/2508.15529)
*Kaiyuan Tan,Yingying Shen,Haohui Zhu,Zhiwei Zhan,Shan Zhao,Mingfei Tu,Hongcheng Luo,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye*

Main category: cs.CV

TL;DR: ExtraGS是一个用于轨迹外推的框架，通过结合几何和生成先验，利用混合高斯-SDF路面表示和可学习的远场高斯，并辅以自监督不确定性估计，显著提升了外推视图的真实感和几何一致性。


<details>
  <summary>Details</summary>
Motivation: 从驾驶日志中合成外推视图对自动驾驶场景模拟至关重要，但现有方法依赖生成先验，常导致几何一致性差和渲染过度平滑的问题。

Method: 本文提出了ExtraGS框架。核心是基于混合高斯-符号距离函数（SDF）设计的新型路面高斯（RSG）表示，以及使用可学习缩放因子有效处理远距离物体的远场高斯（FFG）。此外，开发了一种基于球谐函数的自监督不确定性估计框架，仅在外推伪影出现时选择性地整合生成先验。

Result: 在多个数据集、多相机设置和各种生成先验上的广泛实验表明，ExtraGS显著增强了外推视图的真实感和几何一致性，同时保持了原始轨迹的高保真度。

Conclusion: ExtraGS通过整合几何和生成先验，有效解决了现有方法在合成外推驾驶场景时几何一致性差和渲染过度平滑的局限性，实现了更真实和几何一致的视图外推。

Abstract: Synthesizing extrapolated views from recorded driving logs is critical for
simulating driving scenes for autonomous driving vehicles, yet it remains a
challenging task. Recent methods leverage generative priors as pseudo ground
truth, but often lead to poor geometric consistency and over-smoothed
renderings. To address these limitations, we propose ExtraGS, a holistic
framework for trajectory extrapolation that integrates both geometric and
generative priors. At the core of ExtraGS is a novel Road Surface Gaussian(RSG)
representation based on a hybrid Gaussian-Signed Distance Function (SDF)
design, and Far Field Gaussians (FFG) that use learnable scaling factors to
efficiently handle distant objects. Furthermore, we develop a self-supervised
uncertainty estimation framework based on spherical harmonics that enables
selective integration of generative priors only where extrapolation artifacts
occur. Extensive experiments on multiple datasets, diverse multi-camera setups,
and various generative priors demonstrate that ExtraGS significantly enhances
the realism and geometric consistency of extrapolated views, while preserving
high fidelity along the original trajectory.

</details>


### [86] [Multi-Object Sketch Animation with Grouping and Motion Trajectory Priors](https://arxiv.org/abs/2508.15535)
*Guotao Liang,Juncheng Hu,Ximing Xing,Jing Zhang,Qian Yu*

Main category: cs.CV

TL;DR: GroupSketch是一种新颖的矢量草图动画方法，通过两阶段流程处理多对象交互和复杂运动，利用基于组的位移网络（GDN）和文本到视频模型的先验知识，生成高质量、时间一致的动画。


<details>
  <summary>Details</summary>
Motivation: 现有草图动画方法在处理多对象交互和复杂运动时存在局限性，表现为仅限于单对象、时间不一致和泛化能力差。

Method: 该方法采用两阶段流程：1. 运动初始化：将输入草图交互式地划分为语义组，定义关键帧，并通过插值生成粗略动画。2. 运动细化：提出一个基于组的位移网络（GDN），通过预测组特定的位移场来细化粗略动画，并利用文本到视频模型的先验知识。GDN还包含上下文条件特征增强（CCFE）等模块以提高时间一致性。

Result: 广泛的实验表明，该方法在为复杂、多对象的草图生成高质量、时间一致的动画方面显著优于现有方法。

Conclusion: GroupSketch成功解决了现有方法的局限性，有效处理了复杂的多对象草图动画，从而扩展了草图动画的实际应用。

Abstract: We introduce GroupSketch, a novel method for vector sketch animation that
effectively handles multi-object interactions and complex motions. Existing
approaches struggle with these scenarios, either being limited to single-object
cases or suffering from temporal inconsistency and poor generalization. To
address these limitations, our method adopts a two-stage pipeline comprising
Motion Initialization and Motion Refinement. In the first stage, the input
sketch is interactively divided into semantic groups and key frames are
defined, enabling the generation of a coarse animation via interpolation. In
the second stage, we propose a Group-based Displacement Network (GDN), which
refines the coarse animation by predicting group-specific displacement fields,
leveraging priors from a text-to-video model. GDN further incorporates
specialized modules, such as Context-conditioned Feature Enhancement (CCFE), to
improve temporal consistency. Extensive experiments demonstrate that our
approach significantly outperforms existing methods in generating high-quality,
temporally consistent animations for complex, multi-object sketches, thus
expanding the practical applications of sketch animation.

</details>


### [87] [StreamMem: Query-Agnostic KV Cache Memory for Streaming Video Understanding](https://arxiv.org/abs/2508.15717)
*Yanlai Yang,Zhuokai Zhao,Satya Narayan Shukla,Aashu Singh,Shlok Kumar Mishra,Lizhu Zhang,Mengye Ren*

Main category: cs.CV

TL;DR: StreamMem提出了一种与查询无关的流式KV缓存压缩机制，以解决多模态大语言模型在处理长视频时因KV缓存过大导致的内存和计算效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在处理长视频时，由于需要存储和关注大量的视觉上下文，导致键值（KV）缓存产生巨大的内存和计算开销。现有视觉压缩方法不切实际（需要预先编码整个上下文或知道问题）。

Method: StreamMem是一种与查询无关的KV缓存内存机制，用于流式视频理解。它以流式方式编码新视频帧，利用视觉token和通用查询token之间的注意力分数来压缩KV缓存，并保持固定大小的KV内存。

Result: 在三个长视频理解和两个流式视频问答基准测试中，StreamMem在与查询无关的KV缓存压缩方面达到了最先进的性能，并与查询感知的压缩方法具有竞争力。

Conclusion: StreamMem通过高效的、与查询无关的流式KV缓存压缩，有效解决了多模态大语言模型在内存受限的长视频场景中处理长视频的效率问题。

Abstract: Multimodal large language models (MLLMs) have made significant progress in
visual-language reasoning, but their ability to efficiently handle long videos
remains limited. Despite recent advances in long-context MLLMs, storing and
attending to the key-value (KV) cache for long visual contexts incurs
substantial memory and computational overhead. Existing visual compression
methods require either encoding the entire visual context before compression or
having access to the questions in advance, which is impractical for long video
understanding and multi-turn conversational settings. In this work, we propose
StreamMem, a query-agnostic KV cache memory mechanism for streaming video
understanding. Specifically, StreamMem encodes new video frames in a streaming
manner, compressing the KV cache using attention scores between visual tokens
and generic query tokens, while maintaining a fixed-size KV memory to enable
efficient question answering (QA) in memory-constrained, long-video scenarios.
Evaluation on three long video understanding and two streaming video question
answering benchmarks shows that StreamMem achieves state-of-the-art performance
in query-agnostic KV cache compression and is competitive with query-aware
compression approaches.

</details>


### [88] [D3FNet: A Differential Attention Fusion Network for Fine-Grained Road Structure Extraction in Remote Perception Systems](https://arxiv.org/abs/2508.15537)
*Chang Liu,Yang Xu,Tamas Sziranyi*

Main category: cs.CV

TL;DR: D3FNet是一种基于D-LinkNet的膨胀双流差分注意力融合网络，专为高分辨率遥感影像中的细粒度窄路提取设计，通过增强特征、融合多源信息和多尺度膨胀策略，有效解决了窄路宽度有限、拓扑破碎和遮挡等挑战。


<details>
  <summary>Details</summary>
Motivation: 高分辨率遥感影像中窄路的提取面临显著挑战，原因包括其宽度有限、拓扑结构破碎以及频繁的遮挡。现有模型往往过度拟合通用路宽，难以有效处理细粒度、被遮挡和低对比度的路段。

Method: 本文提出了D3FNet，一个基于D-LinkNet编码器-解码器骨干的膨胀双流差分注意力融合网络。其核心创新包括：(1) 差分注意力膨胀提取(DADE)模块，在瓶颈处增强细微道路特征并抑制背景噪声；(2) 双流解码融合机制(DDFM)，整合原始特征和注意力调制特征，平衡空间精度与语义上下文；(3) 多尺度膨胀策略(膨胀率为1, 3, 5, 9)，减少网格伪影并提高窄路预测的连续性。

Result: 在DeepGlobe和CHN6-CUG基准数据集上进行的广泛实验表明，D3FNet在具有挑战性的道路区域上实现了卓越的IoU和召回率，优于最先进的基线模型。消融研究进一步验证了注意力引导编码和双路径解码的互补协同作用。

Conclusion: 研究结果证实，D3FNet是复杂远程和协同感知场景中细粒度窄路提取的鲁棒解决方案，能够有效应对窄路提取的固有挑战。

Abstract: Extracting narrow roads from high-resolution remote sensing imagery remains a
significant challenge due to their limited width, fragmented topology, and
frequent occlusions. To address these issues, we propose D3FNet, a Dilated
Dual-Stream Differential Attention Fusion Network designed for fine-grained
road structure segmentation in remote perception systems. Built upon the
encoder-decoder backbone of D-LinkNet, D3FNet introduces three key
innovations:(1) a Differential Attention Dilation Extraction (DADE) module that
enhances subtle road features while suppressing background noise at the
bottleneck; (2) a Dual-stream Decoding Fusion Mechanism (DDFM) that integrates
original and attention-modulated features to balance spatial precision with
semantic context; and (3) a multi-scale dilation strategy (rates 1, 3, 5, 9)
that mitigates gridding artifacts and improves continuity in narrow road
prediction. Unlike conventional models that overfit to generic road widths,
D3FNet specifically targets fine-grained, occluded, and low-contrast road
segments. Extensive experiments on the DeepGlobe and CHN6-CUG benchmarks show
that D3FNet achieves superior IoU and recall on challenging road regions,
outperforming state-of-the-art baselines. Ablation studies further verify the
complementary synergy of attention-guided encoding and dual-path decoding.
These results confirm D3FNet as a robust solution for fine-grained narrow road
extraction in complex remote and cooperative perception scenarios.

</details>


### [89] [Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment](https://arxiv.org/abs/2508.15568)
*Youjia Zhang,Youngeun Kim,Young-Geun Choi,Hongyeob Kim,Huiling Liu,Sungeun Hong*

Main category: cs.CV

TL;DR: 本文提出ADAPT，一种先进的、无反向传播的、分布感知的测试时自适应（TTA）方法，通过高斯概率推断和轻量级正则化，实现了在各种分布偏移下最先进的性能、卓越的可扩展性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时自适应（TTA）方法存在以下局限性：1) 大多数依赖反向传播或迭代优化，限制了可扩展性和实时部署；2) 缺乏对类别条件特征分布的明确建模，这对于生成可靠的决策边界和校准预测至关重要，但由于测试时缺乏源数据和监督而未被充分探索。

Method: 本文提出了ADAPT方法，将TTA重构为高斯概率推断任务。通过使用逐渐更新的类别均值和共享协方差矩阵来建模类别条件似然，从而实现闭式、免训练的推断。为校正潜在的似然偏差，引入了由CLIP先验和历史知识库指导的轻量级正则化。ADAPT无需源数据、无需梯度更新，也无需完全访问目标数据，支持在线和转导设置。

Result: 在各种基准测试中，ADAPT方法在广泛的分布偏移下均取得了最先进的性能，并展现出卓越的可扩展性和鲁棒性。

Conclusion: ADAPT通过将TTA重新定义为高斯概率推断任务并结合轻量级正则化，有效解决了现有TTA方法在可扩展性、实时部署和类别条件分布建模方面的挑战，提供了一种无需反向传播且性能卓越的解决方案。

Abstract: Test-time adaptation (TTA) enhances the zero-shot robustness under
distribution shifts by leveraging unlabeled test data during inference. Despite
notable advances, several challenges still limit its broader applicability.
First, most methods rely on backpropagation or iterative optimization, which
limits scalability and hinders real-time deployment. Second, they lack explicit
modeling of class-conditional feature distributions. This modeling is crucial
for producing reliable decision boundaries and calibrated predictions, but it
remains underexplored due to the lack of both source data and supervision at
test time. In this paper, we propose ADAPT, an Advanced Distribution-Aware and
backPropagation-free Test-time adaptation method. We reframe TTA as a Gaussian
probabilistic inference task by modeling class-conditional likelihoods using
gradually updated class means and a shared covariance matrix. This enables
closed-form, training-free inference. To correct potential likelihood bias, we
introduce lightweight regularization guided by CLIP priors and a historical
knowledge bank. ADAPT requires no source data, no gradient updates, and no full
access to target data, supporting both online and transductive settings.
Extensive experiments across diverse benchmarks demonstrate that our method
achieves state-of-the-art performance under a wide range of distribution shifts
with superior scalability and robustness.

</details>


### [90] [High-Frequency First: A Two-Stage Approach for Improving Image INR](https://arxiv.org/abs/2508.15582)
*Sumit Kumar Dam,Mrityunjoy Gain,Eui-Nam Huh,Choong Seon Hong*

Main category: cs.CV

TL;DR: 本文提出了一种两阶段训练策略，通过在早期训练中引入邻域感知的软掩码，自适应地赋予高频细节像素更高的权重，以缓解隐式神经表示（INR）中的频谱偏差问题，从而提高图像重建质量。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INR）在捕捉高频细节（如锐利边缘和精细纹理）方面存在困难，这是由于神经网络的频谱偏差倾向于低频分量。虽然现有方法通过架构修改或专用激活函数来解决，但本文旨在探索一个正交方向，即直接引导训练过程。

Method: 本文提出了一种两阶段训练策略：
1. 第一阶段：引入一个邻域感知的软掩码，自适应地为具有强局部变化的像素分配更高的权重，鼓励模型早期关注精细细节。
2. 第二阶段：模型随后过渡到全图像训练。

Result: 实验结果表明，该方法持续提高了重建质量，并且与现有INR方法互补。

Conclusion: 作为首次尝试在图像INR中为像素分配频率感知重要性的工作，本文为缓解频谱偏差问题提供了一条新途径。

Abstract: Implicit Neural Representations (INRs) have emerged as a powerful alternative
to traditional pixel-based formats by modeling images as continuous functions
over spatial coordinates. A key challenge, however, lies in the spectral bias
of neural networks, which tend to favor low-frequency components while
struggling to capture high-frequency (HF) details such as sharp edges and fine
textures. While prior approaches have addressed this limitation through
architectural modifications or specialized activation functions, we propose an
orthogonal direction by directly guiding the training process. Specifically, we
introduce a two-stage training strategy where a neighbor-aware soft mask
adaptively assigns higher weights to pixels with strong local variations,
encouraging early focus on fine details. The model then transitions to
full-image training. Experimental results show that our approach consistently
improves reconstruction quality and complements existing INR methods. As a
pioneering attempt to assign frequency-aware importance to pixels in image INR,
our work offers a new avenue for mitigating the spectral bias problem.

</details>


### [91] [Fast globally optimal Truncated Least Squares point cloud registration with fixed rotation axis](https://arxiv.org/abs/2508.15613)
*Ivo Ivanov,Carsten Markgraf*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的线性时间凸松弛和收缩器方法，用于加速分支定界算法，从而在给定旋转轴的情况下，以可证明的全局最优性在不到0.5秒内完成高离群率下点云的纯旋转配准，比现有最先进的SDP方法快两个数量级。


<details>
  <summary>Details</summary>
Motivation: 点云配准中的截断最小二乘（TLS）公式能够处理高达95%的离群点，但将其组合优化问题求解到全局最优极具挑战性。现有的基于半定规划（SDP）松弛的方法，如STRIDE，在处理100个点时需要数百秒，计算成本过高。

Method: 本文提出了一种新颖的线性时间凸松弛方法，并结合收缩器（contractor）方法来加速分支定界（BnB）算法。该方法专注于解决纯旋转（rotation-only）的TLS问题，且要求提供旋转轴。

Result: 在提供旋转轴的情况下，该求解器能够在不到半秒的时间内对100个点的3D点云实现可证明的全局最优配准。与最先进的SDP求解器STRIDE相比，在解决纯旋转TLS问题时，速度快了两个数量级。除了形式化的全局最优性证明外，还通过对抗性实例提供了经验证据。

Conclusion: 本研究为高离群率下的点云纯旋转配准问题提供了一个显著加速且可证明全局最优的解决方案。尽管目前仅限于纯旋转问题且需提供旋转轴，但其在速度上远超现有技术，为未来的研究奠定了基础。

Abstract: Recent results showed that point cloud registration with given
correspondences can be made robust to outlier rates of up to 95\% using the
truncated least squares (TLS) formulation. However, solving this combinatorial
optimization problem to global optimality is challenging. Provably globally
optimal approaches using semidefinite programming (SDP) relaxations take
hundreds of seconds for 100 points. In this paper, we propose a novel linear
time convex relaxation as well as a contractor method to speed up Branch and
Bound (BnB). Our solver can register two 3D point clouds with 100 points to
provable global optimality in less than half a second when the axis of rotation
is provided. Although it currently cannot solve the full 6DoF problem, it is
two orders of magnitude faster than the state-of-the-art SDP solver STRIDE when
solving the rotation-only TLS problem. In addition to providing a formal proof
for global optimality, we present empirical evidence of global optimality using
adversarial instances with local minimas close to the global minimum.

</details>


### [92] [SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass](https://arxiv.org/abs/2508.15769)
*Yanxu Meng,Haoning Wu,Ya Zhang,Weidi Xie*

Main category: cs.CV

TL;DR: 本文提出了SceneGen，一个新颖的框架，能够从单张场景图像和对应物体掩码中，无需优化或检索，一次性生成多个带有几何和纹理的3D资产及其相对空间位置。


<details>
  <summary>Details</summary>
Motivation: 3D内容生成在VR/AR和具身AI中具有广泛应用，但从单张场景图像中合成多个3D资产是一个具有挑战性的任务。

Method: 本文提出了SceneGen框架，以场景图像和物体掩码为输入，同时生成多个3D资产的几何和纹理。其核心包括：(i) 一个新颖的特征聚合模块，整合来自视觉和几何编码器的局部及全局场景信息；(ii) 一个位置头部，使得3D资产及其相对空间位置能在一次前向传播中生成；(iii) 尽管仅在单图像输入上训练，但其架构设计使其能直接扩展到多图像输入场景，并提高生成性能。

Result: 广泛的定量和定性评估证实了SceneGen方法的高效性和鲁棒的生成能力。即使在单图像输入上训练，该方法在多图像输入场景下也能实现性能提升。

Conclusion: 该范式为高质量3D内容生成提供了一种新颖的解决方案，有望推动其在下游任务中的实际应用。

Abstract: 3D content generation has recently attracted significant research interest
due to its applications in VR/AR and embodied AI. In this work, we address the
challenging task of synthesizing multiple 3D assets within a single scene
image. Concretely, our contributions are fourfold: (i) we present SceneGen, a
novel framework that takes a scene image and corresponding object masks as
input, simultaneously producing multiple 3D assets with geometry and texture.
Notably, SceneGen operates with no need for optimization or asset retrieval;
(ii) we introduce a novel feature aggregation module that integrates local and
global scene information from visual and geometric encoders within the feature
extraction module. Coupled with a position head, this enables the generation of
3D assets and their relative spatial positions in a single feedforward pass;
(iii) we demonstrate SceneGen's direct extensibility to multi-image input
scenarios. Despite being trained solely on single-image inputs, our
architectural design enables improved generation performance with multi-image
inputs; and (iv) extensive quantitative and qualitative evaluations confirm the
efficiency and robust generation abilities of our approach. We believe this
paradigm offers a novel solution for high-quality 3D content generation,
potentially advancing its practical applications in downstream tasks. The code
and model will be publicly available at: https://mengmouxu.github.io/SceneGen.

</details>


### [93] [Multi-perspective monitoring of wildlife and human activities from camera traps and drones with deep learning models](https://arxiv.org/abs/2508.15629)
*Hao Chen,Fang Qiu,Li An,Douglas Stow,Eve Bohnett,Haitao Lyu,Shuang Tian*

Main category: cs.CV

TL;DR: 本研究结合相机陷阱和无人机多视角监测野生动物和人类活动，利用深度学习模型自动识别目标，并通过空间模式分析识别活动热点及潜在人兽冲突区域，以促进野生动物监测和景观管理。


<details>
  <summary>Details</summary>
Motivation: 了解野生动物和人类活动的空间分布对于评估人兽互动和制定有效的保护计划至关重要。研究旨在通过捕捉其分布的空间模式，识别活动区域重叠并评估人兽冲突的程度。

Method: 研究在尼泊尔奇特旺国家公园（CNP）及其邻近区域进行。方法包括：1) 使用可见光/近红外相机陷阱和热红外无人机（2022年2月至7月）收集图像数据；2) 处理图像创建训练和测试数据集；3) 构建深度学习模型自动识别野生动物和人类活动（相机陷阱图像采用YOLOv11s，无人机热图像采用增强型Faster RCNN）；4) 进行空间模式分析，识别动物和居民活动热点，并划定潜在的人兽冲突区。

Result: 在测试的深度学习模型中，YOLOv11s在相机陷阱图像检测中表现最佳，精度达96.2%，召回率92.3%，mAP50为96.7%，mAP50_95为81.3%。无人机热成像数据通过增强型Faster RCNN模型分析，提供了相机陷阱检测的互补空中视角。空间模式分析明确识别了野生动物和人类活动的清晰热点，并在CNP和缓冲区内的某些区域发现了它们的重叠模式，表明存在潜在冲突。

Conclusion: 本研究揭示了保护区景观内存在人兽冲突。整合多视角监测与自动化目标检测技术，能够有效增强野生动物监测和景观管理能力。

Abstract: Wildlife and human activities are key components of landscape systems.
Understanding their spatial distribution is essential for evaluating human
wildlife interactions and informing effective conservation planning.
Multiperspective monitoring of wildlife and human activities by combining
camera traps and drone imagery. Capturing the spatial patterns of their
distributions, which allows the identification of the overlap of their activity
zones and the assessment of the degree of human wildlife conflict. The study
was conducted in Chitwan National Park (CNP), Nepal, and adjacent regions.
Images collected by visible and nearinfrared camera traps and thermal infrared
drones from February to July 2022 were processed to create training and testing
datasets, which were used to build deep learning models to automatic identify
wildlife and human activities. Drone collected thermal imagery was used for
detecting targets to provide a multiple monitoring perspective. Spatial pattern
analysis was performed to identify animal and resident activity hotspots and
delineation potential human wildlife conflict zones. Among the deep learning
models tested, YOLOv11s achieved the highest performance with a precision of
96.2%, recall of 92.3%, mAP50 of 96.7%, and mAP50 of 81.3%, making it the most
effective for detecting objects in camera trap imagery. Drone based thermal
imagery, analyzed with an enhanced Faster RCNN model, added a complementary
aerial viewpoint for camera trap detections. Spatial pattern analysis
identified clear hotspots for both wildlife and human activities and their
overlapping patterns within certain areas in the CNP and buffer zones
indicating potential conflict. This study reveals human wildlife conflicts
within the conserved landscape. Integrating multiperspective monitoring with
automated object detection enhances wildlife surveillance and landscape
management.

</details>


### [94] [When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding](https://arxiv.org/abs/2508.15641)
*Pengcheng Fang,Yuxia Chen,Rui Guo*

Main category: cs.CV

TL;DR: 解析错误


<details>
  <summary>Details</summary>
Motivation: 解析错误

Method: 解析错误

Result: 解析错误

Conclusion: 解析错误

Abstract: Understanding videos requires more than answering open ended questions, it
demands the ability to pinpoint when events occur and how entities interact
across time. While recent Video LLMs have achieved remarkable progress in
holistic reasoning, they remain coarse in temporal perception: timestamps are
encoded only implicitly, frame level features are weak in capturing continuity,
and language vision alignment often drifts from the entities of interest. In
this paper, we present Grounded VideoDiT, a Video LLM designed to overcome
these limitations by introducing three key innovations. First, a Diffusion
Temporal Latent (DTL) encoder enhances boundary sensitivity and maintains
temporal consistency. Second, object grounded representations explicitly bind
query entities to localized visual evidence, strengthening alignment. Third, a
mixed token scheme with discrete temporal tokens provides explicit timestamp
modeling, enabling fine grained temporal reasoning. Together, these designs
equip Grounded VideoDiT with robust grounding capabilities, as validated by
state of the art results on Charades STA, NExT GQA, and multiple VideoQA
benchmarks.

</details>


### [95] [Weakly-Supervised Learning for Tree Instances Segmentation in Airborne Lidar Point Clouds](https://arxiv.org/abs/2508.15646)
*Swann Emilien Céleste Destouches,Jesse Lahaye,Laurent Valentin Jospin,Jan Skaloud*

Main category: cs.CV

TL;DR: 本文提出了一种弱监督方法，通过人工对初始分割结果进行质量评估并训练一个评估模型，然后利用该评估模型的反馈来微调树木实例分割模型，从而显著提升了机载激光雷达数据的树木分割精度。


<details>
  <summary>Details</summary>
Motivation: 机载激光雷达数据中的树木实例分割对森林监测至关重要，但由于传感器分辨率、植被状态、地形等因素导致的数据差异，以及精确标注数据成本高昂，使其面临巨大挑战。

Method: 该方法采用弱监督策略。首先，通过非微调模型或封闭形式算法获得初始分割结果。然后，由人工操作员对这些结果进行质量评级。接着，利用人工评级数据训练一个评估模型，该模型旨在将分割输出分类为与人工评级相同的类别。最后，使用评估模型的反馈来微调原始的分割模型。

Result: 该方法使正确识别的树木实例数量提高了34%，同时显著减少了非树木实例的预测。然而，在稀疏森林区域（小树，高度小于两米）或包含灌木、巨石等复杂环境的数据中，该方法的性能有所下降，这些物体容易被误认为是树木。

Conclusion: 所提出的弱监督方法有效提高了机载激光雷达数据的树木实例分割精度，并通过人工质量评估和评估模型反馈实现了模型微调。尽管在特定复杂或稀疏区域仍存在挑战，但整体性能显著提升。

Abstract: Tree instance segmentation of airborne laser scanning (ALS) data is of utmost
importance for forest monitoring, but remains challenging due to variations in
the data caused by factors such as sensor resolution, vegetation state at
acquisition time, terrain characteristics, etc. Moreover, obtaining a
sufficient amount of precisely labeled data to train fully supervised instance
segmentation methods is expensive. To address these challenges, we propose a
weakly supervised approach where labels of an initial segmentation result
obtained either by a non-finetuned model or a closed form algorithm are
provided as a quality rating by a human operator. The labels produced during
the quality assessment are then used to train a rating model, whose task is to
classify a segmentation output into the same classes as specified by the human
operator. Finally, the segmentation model is finetuned using feedback from the
rating model. This in turn improves the original segmentation model by 34\% in
terms of correctly identified tree instances while considerably reducing the
number of non-tree instances predicted. Challenges still remain in data over
sparsely forested regions characterized by small trees (less than two meters in
height) or within complex surroundings containing shrubs, boulders, etc. which
can be confused as trees where the performance of the proposed method is
reduced.

</details>


### [96] [MapKD: Unlocking Prior Knowledge with Cross-Modal Distillation for Efficient Online HD Map Construction](https://arxiv.org/abs/2508.15653)
*Ziyang Yan,Ruikai Li,Zhiyong Cui,Bohan Li,Han Jiang,Yilong Ren,Aoyong Li,Zhenning Li,Sijia Wen,Haiyang Yu*

Main category: cs.CV

TL;DR: 本文提出MapKD，一个基于教师-教练-学生（TCS）范式的多级跨模态知识蒸馏框架，旨在将多模态模型的知识转移到高效、轻量级的纯视觉学生模型中，以实现在线高清地图构建，同时提高性能并加速推理。


<details>
  <summary>Details</summary>
Motivation: 现有的在线高清地图构建方法依赖于过时的离线地图或多模态传感器套件，导致推理时产生不必要的计算开销。研究旨在解决这些局限性，开发一个高效、低成本且以视觉为中心的模型。

Method: 本文提出了MapKD框架，采用知识蒸馏策略，将多模态模型的知识转移到纯视觉学生模型。该框架包括：1) 一个以相机-激光雷达融合模型和SD/HD地图先验知识为基础的教师模型；2) 一个具有先验知识和模拟激光雷达的纯视觉教练模型，用于弥合跨模态知识转移的鸿沟；3) 一个轻量级的纯视觉学生模型。此外，引入了两种知识蒸馏策略：Token-Guided 2D Patch Distillation (TGPD) 用于鸟瞰图特征对齐，以及Masked Semantic Response Distillation (MSRD) 用于语义学习指导。

Result: 在nuScenes数据集上的实验表明，MapKD使学生模型的mIoU提高了+6.68，mAP提高了+10.94，同时显著加快了推理速度。

Conclusion: MapKD通过创新的教师-教练-学生范式和特定的知识蒸馏策略，成功地将知识从复杂的、多模态的模型转移到高效、轻量级的纯视觉模型中，从而在在线高清地图构建任务中实现了更好的性能和更快的推理速度。

Abstract: Online HD map construction is a fundamental task in autonomous driving
systems, aiming to acquire semantic information of map elements around the ego
vehicle based on real-time sensor inputs. Recently, several approaches have
achieved promising results by incorporating offline priors such as SD maps and
HD maps or by fusing multi-modal data. However, these methods depend on stale
offline maps and multi-modal sensor suites, resulting in avoidable
computational overhead at inference. To address these limitations, we employ a
knowledge distillation strategy to transfer knowledge from multimodal models
with prior knowledge to an efficient, low-cost, and vision-centric student
model. Specifically, we propose MapKD, a novel multi-level cross-modal
knowledge distillation framework with an innovative Teacher-Coach-Student (TCS)
paradigm. This framework consists of: (1) a camera-LiDAR fusion model with
SD/HD map priors serving as the teacher; (2) a vision-centric coach model with
prior knowledge and simulated LiDAR to bridge the cross-modal knowledge
transfer gap; and (3) a lightweight vision-based student model. Additionally,
we introduce two targeted knowledge distillation strategies: Token-Guided 2D
Patch Distillation (TGPD) for bird's eye view feature alignment and Masked
Semantic Response Distillation (MSRD) for semantic learning guidance. Extensive
experiments on the challenging nuScenes dataset demonstrate that MapKD improves
the student model by +6.68 mIoU and +10.94 mAP while simultaneously
accelerating inference speed. The code is available
at:https://github.com/2004yan/MapKD2026.

</details>


### [97] [LLM-empowered Dynamic Prompt Routing for Vision-Language Models Tuning under Long-Tailed Distributions](https://arxiv.org/abs/2508.15688)
*Yongju Jia,Jiarui Ma,Xiangxian Li,Baiqiao Zhang,Xianhui Cao,Juan Liu,Yulong Bian*

Main category: cs.CV

TL;DR: 针对VLM在类不平衡场景下微调的偏差问题，本文提出了MDPR框架，通过构建多维度知识库和动态提示路由机制，有效平衡了细粒度语义并实现了稳定的预测，在长尾基准测试中取得了与SOTA相当的性能，且计算开销极小。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉-语言模型（VLMs）在类不平衡场景下微调时易受偏差影响。现有利用大型语言模型（LLMs）增强VLM微调的方法，往往忽略了VLM预训练中固有的类不平衡问题，这可能导致下游任务中偏差的累积。因此，需要提出一种方法来解决VLM微调中由类不平衡引起的偏差积累问题。

Method: 本文提出了多维度动态提示路由（MDPR）框架。该框架为类别构建了一个涵盖五个视觉-语义维度的综合知识库。在微调过程中，动态路由机制负责对齐全局视觉类别、检索最优提示，并平衡细粒度语义，最终通过logits融合实现稳定的预测。

Result: 在CIFAR-LT、ImageNet-LT和Places-LT等长尾基准测试中，MDPR取得了与当前最先进方法相当的性能。消融研究进一步证实了其语义库对尾部类别的有效性，并表明动态路由的计算开销极小。

Conclusion: MDPR框架是一种灵活且高效的增强方案，用于解决数据不平衡下VLM微调中的偏差积累问题，并能有效提升其性能。

Abstract: Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated
impressive capability in visual tasks, but their fine-tuning often suffers from
bias in class-imbalanced scene. Recent works have introduced large language
models (LLMs) to enhance VLM fine-tuning with supplementing semantic
information. However, they often overlook inherent class imbalance in VLMs'
pre-training, which may lead to bias accumulation in downstream tasks. To
address this problem, this paper proposes a Multi-dimensional Dynamic Prompt
Routing (MDPR) framework. MDPR constructs a comprehensive knowledge base for
classes, spanning five visual-semantic dimensions. During fine-tuning, the
dynamic routing mechanism aligns global visual classes, retrieves optimal
prompts, and balances fine-grained semantics, yielding stable predictions
through logits fusion. Extensive experiments on long-tailed benchmarks,
including CIFAR-LT, ImageNet-LT, and Places-LT, demonstrate that MDPR achieves
comparable results with current SOTA methods. Ablation studies further confirm
the effectiveness of our semantic library for tail classes, and show that our
dynamic routing incurs minimal computational overhead, making MDPR a flexible
and efficient enhancement for VLM fine-tuning under data imbalance.

</details>


### [98] [WorldWeaver: Generating Long-Horizon Video Worlds via Rich Perception](https://arxiv.org/abs/2508.15720)
*Zhiheng Liu,Xueqing Deng,Shoufa Chen,Angtian Wang,Qiushan Guo,Mingfei Han,Zeyue Xue,Mengzhao Chen,Ping Luo,Linjie Yang*

Main category: cs.CV

TL;DR: WorldWeaver是一个用于长视频生成的鲁棒框架，通过联合建模RGB帧和感知条件（特别是深度信息）以及采用分段噪声调度，有效解决了现有方法在长序列中结构和时间一致性差、漂移累积的问题，显著提升了生成视频的质量和保真度。


<details>
  <summary>Details</summary>
Motivation: 生成式视频模型在长序列中保持结构和时间一致性方面面临挑战。现有方法主要依赖RGB信号，导致物体结构和运动在长时间内累积误差。

Method: 本文提出了WorldWeaver框架，其训练方法具有三个优势：1. 从统一表示中联合预测感知条件和颜色信息，增强时间一致性和运动动态。2. 利用深度线索（比RGB更抗漂移）构建记忆库，保存更清晰的上下文信息，提高长视频生成质量。3. 采用分段噪声调度训练预测组，进一步减轻漂移并降低计算成本。

Result: 在基于扩散和整流流的模型上进行的广泛实验表明，WorldWeaver在减少时间漂移和提高生成视频保真度方面表现出有效性。

Conclusion: WorldWeaver通过联合建模RGB和感知条件，并利用深度线索构建记忆库以及采用分段噪声调度，成功解决了长视频生成中的一致性挑战，显著提升了生成视频的质量和稳定性。

Abstract: Generative video modeling has made significant strides, yet ensuring
structural and temporal consistency over long sequences remains a challenge.
Current methods predominantly rely on RGB signals, leading to accumulated
errors in object structure and motion over extended durations. To address these
issues, we introduce WorldWeaver, a robust framework for long video generation
that jointly models RGB frames and perceptual conditions within a unified
long-horizon modeling scheme. Our training framework offers three key
advantages. First, by jointly predicting perceptual conditions and color
information from a unified representation, it significantly enhances temporal
consistency and motion dynamics. Second, by leveraging depth cues, which we
observe to be more resistant to drift than RGB, we construct a memory bank that
preserves clearer contextual information, improving quality in long-horizon
video generation. Third, we employ segmented noise scheduling for training
prediction groups, which further mitigates drift and reduces computational
cost. Extensive experiments on both diffusion- and rectified flow-based models
demonstrate the effectiveness of WorldWeaver in reducing temporal drift and
improving the fidelity of generated videos.

</details>


### [99] [Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered All-in-SAM Model](https://arxiv.org/abs/2508.15751)
*Xueyuan Li,Can Cui,Ruining Deng,Yucheng Tang,Quan Liu,Tianyuan Yao,Shunxing Bao,Naweed Chowdhury,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: 本文提出了一个分子赋能的All-in-SAM模型，通过减少标注工作量、适应特定语义和整合分子导向纠正学习，显著提升了计算病理学中细胞分类的精细分割性能。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉基础模型（如SAM）在细胞核分割方面表现出色，但它们在识别特定细胞核亚型或细胞等精细语义分割任务上仍面临挑战。此外，详细的像素级标注工作量巨大。

Method: 本文提出了All-in-SAM模型，采用全栈方法：1) 通过分子赋能学习吸引非专业标注员，减少对详细像素级标注的需求；2) 利用SAM适配器，调整SAM模型以强调特定语义，保持其泛化能力；3) 通过整合分子导向纠正学习（MOCL）来提高分割精度。

Result: 在内部和公共数据集上的实验结果表明，All-in-SAM模型显著提高了细胞分类性能，即使在标注质量不一致的情况下也表现良好。

Conclusion: 该方法不仅减轻了标注员的工作负担，还使精准的生物医学图像分析在资源有限的环境中更易于实现，从而推动了医学诊断和病理图像分析的自动化。

Abstract: Purpose: Recent developments in computational pathology have been driven by
advances in Vision Foundation Models, particularly the Segment Anything Model
(SAM). This model facilitates nuclei segmentation through two primary methods:
prompt-based zero-shot segmentation and the use of cell-specific SAM models for
direct segmentation. These approaches enable effective segmentation across a
range of nuclei and cells. However, general vision foundation models often face
challenges with fine-grained semantic segmentation, such as identifying
specific nuclei subtypes or particular cells. Approach: In this paper, we
propose the molecular-empowered All-in-SAM Model to advance computational
pathology by leveraging the capabilities of vision foundation models. This
model incorporates a full-stack approach, focusing on: (1) annotation-engaging
lay annotators through molecular-empowered learning to reduce the need for
detailed pixel-level annotations, (2) learning-adapting the SAM model to
emphasize specific semantics, which utilizes its strong generalizability with
SAM adapter, and (3) refinement-enhancing segmentation accuracy by integrating
Molecular-Oriented Corrective Learning (MOCL). Results: Experimental results
from both in-house and public datasets show that the All-in-SAM model
significantly improves cell classification performance, even when faced with
varying annotation quality. Conclusions: Our approach not only reduces the
workload for annotators but also extends the accessibility of precise
biomedical image analysis to resource-limited settings, thereby advancing
medical diagnostics and automating pathology image analysis.

</details>


### [100] [Waver: Wave Your Way to Lifelike Video Generation](https://arxiv.org/abs/2508.15761)
*Yifu Zhang,Hao Yang,Yuqi Zhang,Yifei Hu,Fengda Zhu,Chuang Lin,Xiaofeng Mei,Yi Jiang,Zehuan Yuan,Bingyue Peng*

Main category: cs.CV

TL;DR: Waver是一种高性能的统一图像和视频生成基础模型，能够生成高质量、长时间（5-10秒）的视频，并在运动捕捉和时间一致性方面表现出色，超越了现有开源模型并与商业解决方案媲美。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一个能够统一支持文本到视频(T2V)、图像到视频(I2V)和文本到图像(T2I)生成，并能产生高质量、具有复杂运动和良好时间一致性的长视频的高性能基础模型。

Method: 该研究引入了混合流DiT架构以增强模态对齐并加速训练收敛。为了确保训练数据质量，建立了全面的数据整理流程，并手动标注和训练了一个基于MLLM的视频质量模型来筛选高质量样本。模型能直接生成720p分辨率（5-10秒）的视频，随后升级到1080p。此外，还提供了详细的训练和推理方案。

Result: Waver能够直接生成5到10秒的720p视频并升采样至1080p。它在捕捉复杂运动方面表现出色，实现了卓越的运动幅度和时间一致性。该模型在Artificial Analysis的T2V和I2V排行榜上均位列前三，持续超越现有开源模型，并与最先进的商业解决方案持平或超越。

Conclusion: Waver模型在统一图像和视频生成方面取得了显著进展，通过其创新的架构和数据策略，实现了卓越的视频质量、运动捕捉和时间一致性。该技术报告旨在帮助社区更高效地训练高质量视频生成模型，并加速视频生成技术的发展。

Abstract: We present Waver, a high-performance foundation model for unified image and
video generation. Waver can directly generate videos with durations ranging
from 5 to 10 seconds at a native resolution of 720p, which are subsequently
upscaled to 1080p. The model simultaneously supports text-to-video (T2V),
image-to-video (I2V), and text-to-image (T2I) generation within a single,
integrated framework. We introduce a Hybrid Stream DiT architecture to enhance
modality alignment and accelerate training convergence. To ensure training data
quality, we establish a comprehensive data curation pipeline and manually
annotate and train an MLLM-based video quality model to filter for the
highest-quality samples. Furthermore, we provide detailed training and
inference recipes to facilitate the generation of high-quality videos. Building
on these contributions, Waver excels at capturing complex motion, achieving
superior motion amplitude and temporal consistency in video synthesis. Notably,
it ranks among the Top 3 on both the T2V and I2V leaderboards at Artificial
Analysis (data as of 2025-07-30 10:00 GMT+8), consistently outperforming
existing open-source models and matching or surpassing state-of-the-art
commercial solutions. We hope this technical report will help the community
more efficiently train high-quality video generation models and accelerate
progress in video generation technologies. Official page:
https://github.com/FoundationVision/Waver.

</details>


### [101] [ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling](https://arxiv.org/abs/2508.15767)
*Jinhyung Park,Javier Romero,Shunsuke Saito,Fabian Prada,Takaaki Shiratori,Yichen Xu,Federica Bogo,Shoou-I Yu,Kris Kitani,Rawal Khirodkar*

Main category: cs.CV

TL;DR: ATLAS是一种高精度人体模型，通过将网格表示基于人体骨骼，明确解耦形状和骨骼基，并利用大规模高分辨率扫描数据学习，克服了现有模型在细节变化和骨骼-软组织依赖方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的人体网格建模方法难以捕捉多样姿态和形状的详细变化，主要原因在于训练数据多样性有限和建模假设的限制。此外，先优化外部表面再回归内部骨骼的范式，导致骨骼与软组织之间存在问题性依赖，限制了对身高和骨长的直接控制。

Method: 本文提出了ATLAS模型，从60万个使用240个同步相机捕获的高分辨率扫描中学习。与以往方法不同，ATLAS通过将网格表示基于人体骨骼，明确解耦了形状和骨骼基，并使用了非线性姿态校正器。

Result: ATLAS在拟合未见过的受试者和多样姿态方面比现有方法更准确。定量评估显示，其非线性姿态校正器比线性模型能更有效地捕捉复杂姿态。

Conclusion: ATLAS模型实现了增强的形状表达能力、身体属性的精细化定制，以及独立于外部软组织特征的关键点拟合，显著优于现有的人体模型。

Abstract: Parametric body models offer expressive 3D representation of humans across a
wide range of poses, shapes, and facial expressions, typically derived by
learning a basis over registered 3D meshes. However, existing human mesh
modeling approaches struggle to capture detailed variations across diverse body
poses and shapes, largely due to limited training data diversity and
restrictive modeling assumptions. Moreover, the common paradigm first optimizes
the external body surface using a linear basis, then regresses internal
skeletal joints from surface vertices. This approach introduces problematic
dependencies between internal skeleton and outer soft tissue, limiting direct
control over body height and bone lengths. To address these issues, we present
ATLAS, a high-fidelity body model learned from 600k high-resolution scans
captured using 240 synchronized cameras. Unlike previous methods, we explicitly
decouple the shape and skeleton bases by grounding our mesh representation in
the human skeleton. This decoupling enables enhanced shape expressivity,
fine-grained customization of body attributes, and keypoint fitting independent
of external soft-tissue characteristics. ATLAS outperforms existing methods by
fitting unseen subjects in diverse poses more accurately, and quantitative
evaluations show that our non-linear pose correctives more effectively capture
complex poses compared to linear models.

</details>


### [102] [Visual Autoregressive Modeling for Instruction-Guided Image Editing](https://arxiv.org/abs/2508.15772)
*Qingyang Mao,Qi Cai,Yehao Li,Yingwei Pan,Mingyue Cheng,Ting Yao,Qi Liu,Tao Mei*

Main category: cs.CV

TL;DR: VAREdit是一个视觉自回归(VAR)图像编辑框架，它将图像编辑重新定义为下一尺度预测问题。通过引入尺度对齐参考(SAR)模块，VAREdit在编辑依从性和效率方面显著优于扩散模型。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在指令引导的图像编辑中存在全局去噪过程导致不必要的修改和对编辑指令依从性不足的问题。自回归模型通过离散视觉token的顺序生成范式，自然地避免了这些挑战。

Method: VAREdit将图像编辑重构为下一尺度预测问题，是一个视觉自回归(VAR)框架。它在源图像特征和文本指令的条件下生成多尺度目标特征。为有效条件化源图像token，特别是解决精细尺度源特征无法有效指导粗糙目标特征预测的问题，VAREdit引入了尺度对齐参考(SAR)模块，将尺度匹配的条件信息注入到第一个自注意力层。

Result: VAREdit在编辑依从性和效率上均表现出色。在标准基准测试中，其GPT-Balance分数比领先的扩散模型高出30%以上。此外，它能在1.2秒内完成512x512的编辑，比同等大小的UltraEdit快2.2倍。

Conclusion: VAREdit提供了一个基于视觉自回归范式的高效且精确的图像编辑解决方案。通过将编辑重新定义为下一尺度预测并引入SAR模块，它成功克服了扩散模型在编辑依从性上的局限性，并显著提升了编辑速度。

Abstract: Recent advances in diffusion models have brought remarkable visual fidelity
to instruction-guided image editing. However, their global denoising process
inherently entangles the edited region with the entire image context, leading
to unintended spurious modifications and compromised adherence to editing
instructions. In contrast, autoregressive models offer a distinct paradigm by
formulating image synthesis as a sequential process over discrete visual
tokens. Their causal and compositional mechanism naturally circumvents the
adherence challenges of diffusion-based methods. In this paper, we present
VAREdit, a visual autoregressive (VAR) framework that reframes image editing as
a next-scale prediction problem. Conditioned on source image features and text
instructions, VAREdit generates multi-scale target features to achieve precise
edits. A core challenge in this paradigm is how to effectively condition the
source image tokens. We observe that finest-scale source features cannot
effectively guide the prediction of coarser target features. To bridge this
gap, we introduce a Scale-Aligned Reference (SAR) module, which injects
scale-matched conditioning information into the first self-attention layer.
VAREdit demonstrates significant advancements in both editing adherence and
efficiency. On standard benchmarks, it outperforms leading diffusion-based
methods by 30\%+ higher GPT-Balance score. Moreover, it completes a
$512\times512$ editing in 1.2 seconds, making it 2.2$\times$ faster than the
similarly sized UltraEdit. The models are available at
https://github.com/HiDream-ai/VAREdit.

</details>


### [103] [Scaling Group Inference for Diverse and High-Quality Generation](https://arxiv.org/abs/2508.15773)
*Gaurav Parmar,Or Patashnik,Daniil Ostashev,Kuan-Chieh Wang,Kfir Aberman,Srinivasa Narasimhan,Jun-Yan Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种可扩展的群组推理方法，通过将群组推理建模为二次整数分配问题，并在运行时进行渐进式剪枝，显著提高了生成模型输出群组的多样性和质量，解决了独立采样导致的冗余问题。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，用户通常会收到针对同一提示的多个（如4-8个）图像，而传统的独立采样方法往往导致结果冗余，限制了用户选择并阻碍了创意探索。因此，需要一种方法来提升生成输出群组的多样性和质量。

Method: 将群组推理公式化为一个二次整数分配问题：将候选输出建模为图节点，并选择一个子集以优化样本质量（一元项）同时最大化群组多样性（二元项）。为了提高运行时效率，该方法使用中间预测逐步剪枝候选集，使其能够扩展到大型候选集。

Result: 实验表明，与独立的采样基线和最近的推理算法相比，该方法显著提高了群组的多样性和质量。此外，该框架适用于多种任务，包括文本到图像、图像到图像、图像提示和视频生成。

Conclusion: 该研究使得生成模型能够将多个输出视为一个有凝聚力的群组，而不仅仅是独立的样本，从而在多种生成任务中提升了用户体验和探索能力。

Abstract: Generative models typically sample outputs independently, and recent
inference-time guidance and scaling algorithms focus on improving the quality
of individual samples. However, in real-world applications, users are often
presented with a set of multiple images (e.g., 4-8) for each prompt, where
independent sampling tends to lead to redundant results, limiting user choices
and hindering idea exploration. In this work, we introduce a scalable group
inference method that improves both the diversity and quality of a group of
samples. We formulate group inference as a quadratic integer assignment
problem: candidate outputs are modeled as graph nodes, and a subset is selected
to optimize sample quality (unary term) while maximizing group diversity
(binary term). To substantially improve runtime efficiency, we progressively
prune the candidate set using intermediate predictions, allowing our method to
scale up to large candidate sets. Extensive experiments show that our method
significantly improves group diversity and quality compared to independent
sampling baselines and recent inference algorithms. Our framework generalizes
across a wide range of tasks, including text-to-image, image-to-image, image
prompting, and video generation, enabling generative models to treat multiple
outputs as cohesive groups rather than independent samples.

</details>


### [104] [CineScale: Free Lunch in High-Resolution Cinematic Visual Generation](https://arxiv.org/abs/2508.15774)
*Haonan Qiu,Ning Yu,Ziqi Huang,Paul Debevec,Ziwei Liu*

Main category: cs.CV

TL;DR: 本文提出CineScale，一种新颖的推理范式，旨在解决视觉扩散模型在有限分辨率训练导致的生成高分辨率图像和视频时质量低下的问题，无需大量微调即可实现8k图像和4k视频生成。


<details>
  <summary>Details</summary>
Motivation: 视觉扩散模型通常在有限分辨率下训练，原因在于高分辨率数据稀缺和计算资源受限，这阻碍了它们生成高保真高分辨率图像或视频的能力。现有的免调优策略仍会产生重复模式的低质量视觉内容，主要问题在于模型生成超出训练分辨率的内容时，高频信息增加导致累积误差，从而产生不理想的重复模式。

Method: 本文提出了CineScale，一种用于实现更高分辨率视觉生成的新型推理范式。为解决两种视频生成架构引入的各种问题，作者提出了针对每种架构的专用变体。与现有基线方法仅限于高分辨率T2I和T2V生成不同，CineScale扩展了范围，支持基于最先进的开源视频生成框架进行高分辨率I2V和V2V合成。

Result: 广泛的实验验证了CineScale范式在扩展图像和视频模型更高分辨率视觉生成能力方面的优越性。值得注意的是，该方法无需任何微调即可实现8k图像生成，并通过最少的LoRA微调实现4k视频生成。

Conclusion: CineScale成功地解决了扩散模型在高分辨率视觉生成方面的挑战，提供了一种卓越的推理范式，不仅拓宽了生成范围（支持I2V和V2V），而且在极少或不微调的情况下实现了令人印象深刻的高分辨率输出。

Abstract: Visual diffusion models achieve remarkable progress, yet they are typically
trained at limited resolutions due to the lack of high-resolution data and
constrained computation resources, hampering their ability to generate
high-fidelity images or videos at higher resolutions. Recent efforts have
explored tuning-free strategies to exhibit the untapped potential
higher-resolution visual generation of pre-trained models. However, these
methods are still prone to producing low-quality visual content with repetitive
patterns. The key obstacle lies in the inevitable increase in high-frequency
information when the model generates visual content exceeding its training
resolution, leading to undesirable repetitive patterns deriving from the
accumulated errors. In this work, we propose CineScale, a novel inference
paradigm to enable higher-resolution visual generation. To tackle the various
issues introduced by the two types of video generation architectures, we
propose dedicated variants tailored to each. Unlike existing baseline methods
that are confined to high-resolution T2I and T2V generation, CineScale broadens
the scope by enabling high-resolution I2V and V2V synthesis, built atop
state-of-the-art open-source video generation frameworks. Extensive experiments
validate the superiority of our paradigm in extending the capabilities of
higher-resolution visual generation for both image and video models.
Remarkably, our approach enables 8k image generation without any fine-tuning,
and achieves 4k video generation with only minimal LoRA fine-tuning. Generated
video samples are available at our website:
https://eyeline-labs.github.io/CineScale/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [105] [Efficient Switchable Safety Control in LLMs via Magic-Token-Guided Co-Training](https://arxiv.org/abs/2508.14904)
*Jianfeng Si,Lin Sun,Zhewen Tan,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: 该论文提出一种统一的协同训练框架，在单个SFT阶段整合多种安全行为（积极、消极、拒绝），并通过“魔法令牌”在推理时动态切换，以提供高效、可控且可扩展的LLM内容安全解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前LLM内容安全方法（如SFT和RLHF）通常依赖多阶段训练流程，且缺乏部署后的细粒度可控性。

Method: 提出一个统一的协同训练框架，在单个SFT阶段高效整合积极（合法/亲社会）、消极（无过滤/风险倾向）和拒绝（拒绝导向/保守）三种安全行为。通过简单的系统级指令或“魔法令牌”在推理时动态激活和切换这些行为。

Result: 该协同训练策略在输出空间中诱导生成独特的“安全对齐裕度”，使各安全模式的响应分布清晰分离，提供了模型安全鲁棒性的经验证据并实现了细粒度控制。实验表明，该方法在安全对齐质量上与SFT+DPO相当，其8B模型在安全性能上显著超越DeepSeek-R1 (671B)，同时大幅降低了训练复杂度和部署成本。

Conclusion: 本工作为LLM内容安全提供了一个可扩展、高效且高度可控的解决方案。

Abstract: Current methods for content safety in Large Language Models (LLMs), such as
Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback
(RLHF), often rely on multi-stage training pipelines and lack fine-grained,
post-deployment controllability. To address these limitations, we propose a
unified co-training framework that efficiently integrates multiple safety
behaviors: positive (lawful/prosocial), negative (unfiltered/risk-prone) and
rejective (refusal-oriented/conservative) within a single SFT stage. Notably,
each behavior is dynamically activated via a simple system-level instruction,
or magic token, enabling stealthy and efficient behavioral switching at
inference time. This flexibility supports diverse deployment scenarios, such as
positive for safe user interaction, negative for internal red-teaming, and
rejective for context-aware refusals triggered by upstream moderation signals.
This co-training strategy induces a distinct Safety Alignment Margin in the
output space, characterized by well-separated response distributions
corresponding to each safety mode. The existence of this margin provides
empirical evidence for the model's safety robustness and enables unprecedented
fine-grained control. Experiments show that our method matches the safety
alignment quality of SFT+DPO, with our 8B model notably surpassing DeepSeek-R1
(671B) in safety performance, while significantly reducing both training
complexity and deployment costs. This work presents a scalable, efficient, and
highly controllable solution for LLM content safety.

</details>


### [106] [Preliminary Ranking of WMT25 General Machine Translation Systems](https://arxiv.org/abs/2508.14909)
*Tom Kocmi,Eleftherios Avramidis,Rachel Bawden,Ondřej Bojar,Konstantin Dranch,Anton Dvorkovich,Sergey Dukanov,Natalia Fedorova,Mark Fishel,Markus Freitag,Thamme Gowda,Roman Grundkiewicz,Barry Haddow,Marzena Karpinska,Philipp Koehn,Howard Lakougna,Jessica Lundin,Kenton Murray,Masaaki Nagata,Stefano Perrella,Lorenzo Proietti,Martin Popel,Maja Popović,Parker Riley,Mariya Shmatova,Steinþór Steingrímsson,Lisa Yankovskaya,Vilém Zouhar*

Main category: cs.CL

TL;DR: WMT25通用机器翻译共享任务的初步排名已发布，该排名基于自动评估指标。


<details>
  <summary>Details</summary>
Motivation: 向任务参与者分享初步结果，以帮助他们准备系统提交论文，并指出自动评估的局限性。

Method: 使用自动指标评估机器翻译系统。

Result: WMT25通用机器翻译共享任务的初步系统排名。

Conclusion: 该排名是初步的、基于自动评估且可能存在偏差，最终官方排名将以更可靠的人工评估为准。本报告旨在提供参考，而非最终结果。

Abstract: We present the preliminary ranking of the WMT25 General Machine Translation
Shared Task, in which MT systems have been evaluated using automatic metrics.
As this ranking is based on automatic evaluations, it may be biased in favor of
systems that employ re-ranking techniques, such as Quality Estimation
re-ranking or Minimum Bayes Risk decoding. The official WMT25 ranking will be
based on human evaluation, which is more reliable and will supersede the
automatic ranking.
  The purpose of this report is not to present the final findings of the
General MT task, but rather to share preliminary results with task
participants, which may be useful when preparing their system submission
papers.

</details>


### [107] [Bridging the Culture Gap: A Framework for LLM-Driven Socio-Cultural Localization of Math Word Problems in Low-Resource Languages](https://arxiv.org/abs/2508.14913)
*Israel Abebe Azime,Tadesse Destaw Belay,Dietrich Klakow,Philipp Slusallek,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 本文提出了一种由大型语言模型驱动的文化本地化框架，用于数学应用题，旨在自动构建包含本地实体（如人名、组织、货币）的数据集，以解决低资源语言中多语言和文化背景数学推理的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在英语数学问题解决方面表现出色，但由于缺乏反映准确本地实体（如人名、组织名、货币）的社会文化任务数据集，低资源语言中的多语言和文化背景数学推理能力滞后。现有的多语言基准测试主要通过翻译产生，并倾向于保留以英语为中心的实体，而人工标注的本地化成本高昂，自动化工具也有限，导致真正本地化的数据集稀缺。

Method: 本文引入了一个由大型语言模型（LLM）驱动的数学应用题文化本地化框架。该框架能够从现有来源自动构建包含本地人名、组织名和货币的数据集。

Result: 研究发现，翻译的基准测试在适当的社会文化背景下可能会掩盖真正的多语言数学能力。通过广泛的实验，本文还表明所提出的框架有助于减轻以英语为中心的实体偏见，并在各种语言中引入本地实体时提高模型的鲁棒性。

Conclusion: 本研究通过引入LLM驱动的文化本地化框架，有效解决了低资源语言中缺乏文化背景数学推理数据集的问题。该框架不仅能够自动生成包含本地实体的数据集，还能减轻英语中心偏见，提高LLM在多语言数学问题解决中的鲁棒性和准确性。

Abstract: Large language models (LLMs) have demonstrated significant capabilities in
solving mathematical problems expressed in natural language. However,
multilingual and culturally-grounded mathematical reasoning in low-resource
languages lags behind English due to the scarcity of socio-cultural task
datasets that reflect accurate native entities such as person names,
organization names, and currencies. Existing multilingual benchmarks are
predominantly produced via translation and typically retain English-centric
entities, owing to the high cost associated with human annotater-based
localization. Moreover, automated localization tools are limited, and hence,
truly localized datasets remain scarce. To bridge this gap, we introduce a
framework for LLM-driven cultural localization of math word problems that
automatically constructs datasets with native names, organizations, and
currencies from existing sources. We find that translated benchmarks can
obscure true multilingual math ability under appropriate socio-cultural
contexts. Through extensive experiments, we also show that our framework can
help mitigate English-centric entity bias and improves robustness when native
entities are introduced across various languages.

</details>


### [108] [Improving LLMs for Machine Translation Using Synthetic Preference Data](https://arxiv.org/abs/2508.14951)
*Dario Vajda,Domen Vreš,Marko Robnik-Šikonja*

Main category: cs.CL

TL;DR: 本研究通过使用直接偏好优化（DPO）和程序化生成的数据集，成功改进了一个通用指令调优的大语言模型在斯洛文尼亚语机器翻译上的性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型已成为有效的机器翻译系统。研究旨在探索如何利用相对较少且易于生成的数据资源，改进一个通用指令调优的大语言模型，使其在机器翻译方面表现更好。

Method: 研究以GaMS-9B-Instruct模型和斯洛文尼亚语为用例，采用直接偏好优化（DPO）进行训练。DPO所需的数据集通过以下方式生成：使用GaMS-9B-Instruct和EuroLLM-9B-Instruct两个大语言模型翻译英文维基百科文章，然后基于启发式规则和COMET等自动评估指标对翻译结果进行质量排序，从而创建出质量分级的实例对。该数据集是从一个公共数据集的子集中程序化地策划和增强而来的。

Result: 微调后的模型在翻译维基百科文章时，COMET分数分别比用于数据集生成的两个基线模型提高了约0.04和0.02。此外，微调模型在避免语言和格式错误方面也表现得更加一致。

Conclusion: 通过结合直接偏好优化（DPO）和少量程序化生成、质量分级的数据资源，可以有效提升通用指令调优大语言模型在特定机器翻译任务上的性能，实现更高的翻译质量并减少错误。

Abstract: Large language models have emerged as effective machine translation systems.
In this paper, we explore how a general instruction-tuned large language model
can be improved for machine translation using relatively few easily produced
data resources. Using Slovene as a use case, we improve the GaMS-9B-Instruct
model using Direct Preference Optimization (DPO) training on a programmatically
curated and enhanced subset of a public dataset. As DPO requires pairs of
quality-ranked instances, we generated its training dataset by translating
English Wikipedia articles using two LLMs, GaMS-9B-Instruct and
EuroLLM-9B-Instruct. We ranked the resulting translations based on heuristics
coupled with automatic evaluation metrics such as COMET. The evaluation shows
that our fine-tuned model outperforms both models involved in the dataset
generation. In comparison to the baseline models, the fine-tuned model achieved
a COMET score gain of around 0.04 and 0.02, respectively, on translating
Wikipedia articles. It also more consistently avoids language and formatting
errors.

</details>


### [109] [Multilingual Datasets for Custom Input Extraction and Explanation Requests Parsing in Conversational XAI Systems](https://arxiv.org/abs/2508.14982)
*Qianli Wang,Tatiana Anikina,Nils Feldhus,Simon Ostermann,Fedor Splitt,Jiaao Li,Yoana Tsoneva,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 该研究通过引入多语言数据集（MultiCoXQL和Compass）和新的解析方法，解决了基于大语言模型（LLMs）的对话式可解释人工智能（ConvXAI）系统中多语言数据稀缺和自由形式自定义输入支持不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前ConvXAI系统在多语言泛化方面面临训练数据稀缺的挑战，且对自由形式的自定义输入支持有限。现有方法虽然在英语意图识别上表现良好，但难以扩展到其他语言。

Method: 1. 引入MultiCoXQL数据集，它是CoXQL的多语言扩展，涵盖五种语言（包括一种低资源语言）。2. 提出一种新的解析方法以提升多语言解析性能。3. 使用不同的解析策略在MultiCoXQL上评估三种LLMs。4. 引入Compass数据集，用于ConvXAI系统中的自定义输入提取，包含相同五种语言的11种意图。5. 在Compass数据集上进行单语言、跨语言和多语言评估，使用三种不同大小的LLMs和BERT类型模型。

Result: 研究引入了MultiCoXQL和Compass两个新的多语言数据集，并提出了一种新的多语言解析方法。此外，还在这些新数据集上对多种LLMs和BERT类型模型进行了广泛的单语言、跨语言和多语言评估。

Conclusion: 通过提供新的多语言数据集和解析方法，该研究为解决ConvXAI系统中多语言数据稀缺和自由形式自定义输入支持不足的挑战奠定了基础，并为未来多语言ConvXAI系统的发展提供了资源和评估框架。

Abstract: Conversational explainable artificial intelligence (ConvXAI) systems based on
large language models (LLMs) have garnered considerable attention for their
ability to enhance user comprehension through dialogue-based explanations.
Current ConvXAI systems often are based on intent recognition to accurately
identify the user's desired intention and map it to an explainability method.
While such methods offer great precision and reliability in discerning users'
underlying intentions for English, a significant challenge in the scarcity of
training data persists, which impedes multilingual generalization. Besides, the
support for free-form custom inputs, which are user-defined data distinct from
pre-configured dataset instances, remains largely limited. To bridge these
gaps, we first introduce MultiCoXQL, a multilingual extension of the CoXQL
dataset spanning five typologically diverse languages, including one
low-resource language. Subsequently, we propose a new parsing approach aimed at
enhancing multilingual parsing performance, and evaluate three LLMs on
MultiCoXQL using various parsing strategies. Furthermore, we present Compass, a
new multilingual dataset designed for custom input extraction in ConvXAI
systems, encompassing 11 intents across the same five languages as MultiCoXQL.
We conduct monolingual, cross-lingual, and multilingual evaluations on Compass,
employing three LLMs of varying sizes alongside BERT-type models.

</details>


### [110] [Reward-Shifted Speculative Sampling Is An Efficient Test-Time Weak-to-Strong Aligner](https://arxiv.org/abs/2508.15044)
*Bolian Li,Yanran Wu,Xinyu Luo,Ruqi Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为奖励偏移推测采样（SSS）的算法，通过使用与人类偏好对齐的草稿模型，显著降低了大型语言模型测试时对齐的推理成本，同时保持了对齐效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的测试时对齐（test-time alignment）能够提升其安全性和推理能力，但高昂的推理成本限制了其实际应用。

Method: 受推测采样加速技术的启发，该研究引入了奖励偏移推测采样（SSS）算法。SSS使用一个与人类偏好对齐的草稿模型，而目标模型保持未对齐。通过修改接受标准和奖励令牌分布，理论上证明可以利用对齐草稿模型与未对齐目标模型之间的分布差异，在不实际获取RLHF最优解的情况下恢复该解。

Result: 在测试时弱到强对齐实验中，SSS算法以显著降低的推理成本获得了更高的黄金奖励分数，验证了其有效性和效率。

Conclusion: SSS算法为解决测试时对齐的效率瓶颈提供了一个有效且高效的解决方案，通过巧妙利用偏好对齐的草稿模型实现了性能和成本的双重优化。

Abstract: Aligning large language models (LLMs) with human preferences has become a
critical step in their development. Recent research has increasingly focused on
test-time alignment, where additional compute is allocated during inference to
enhance LLM safety and reasoning capabilities. However, these test-time
alignment techniques often incur substantial inference costs, limiting their
practical application. We are inspired by the speculative sampling
acceleration, which leverages a small draft model to efficiently predict future
tokens, to address the efficiency bottleneck of test-time alignment. We
introduce the reward-Shifted Speculative Sampling (SSS) algorithm, in which the
draft model is aligned with human preferences, while the target model remains
unchanged. We theoretically demonstrate that the distributional shift between
the aligned draft model and the unaligned target model can be exploited to
recover the RLHF optimal solution without actually obtaining it, by modifying
the acceptance criterion and bonus token distribution. Our algorithm achieves
superior gold reward scores at a significantly reduced inference cost in
test-time weak-to-strong alignment experiments, thereby validating both its
effectiveness and efficiency.

</details>


### [111] [LongRecall: A Structured Approach for Robust Recall Evaluation in Long-Form Text](https://arxiv.org/abs/2508.15085)
*MohamamdJavad Ardestani,Ehsan Kamalloo,Davood Rafiei*

Main category: cs.CL

TL;DR: 本文提出了LongRecall，一个三阶段的通用召回率评估框架，通过事实分解、候选匹配过滤和结构化蕴含检查，显著提高了机器生成文本的召回率评估准确性，解决了现有方法在词汇重叠和LLM判断中的局限性。


<details>
  <summary>Details</summary>
Motivation: 在医学、法律和列表式问答等领域，机器生成文本的完整性（确保包含所有相关信息）至关重要，遗漏可能导致严重后果。然而，现有召回率指标常依赖词汇重叠，易产生错误；而基于LLM的判断方法虽捕获更广泛语义，但存在对齐问题和幻觉，缺乏结构化验证。

Method: LongRecall是一个通用的三阶段召回率评估框架：1. 将答案分解为独立的“事实”。2. 通过词汇和语义过滤逐步缩小可能的候选匹配。3. 通过结构化蕴含检查验证其对齐性。这种设计旨在减少假阳性和假阴性，同时适应不同的措辞和上下文变体。

Result: LongRecall在三个具有挑战性的长篇问答基准上进行了评估，结合了人工标注和基于LLM的判断器。结果表明，LongRecall在召回率准确性方面比强大的词汇重叠和LLM-as-a-Judge基线有显著提升。

Conclusion: LongRecall作为一个系统性召回率评估的基础构建模块，能够减少错误并适应多样化的表达和上下文变化。其设计通过分解、过滤和结构化验证，解决了现有召回率评估方法的不足，为高风险领域提供了更可靠的评估工具。

Abstract: LongRecall. The completeness of machine-generated text, ensuring that it
captures all relevant information, is crucial in domains such as medicine and
law and in tasks like list-based question answering (QA), where omissions can
have serious consequences. However, existing recall metrics often depend on
lexical overlap, leading to errors with unsubstantiated entities and
paraphrased answers, while LLM-as-a-Judge methods with long holistic prompts
capture broader semantics but remain prone to misalignment and hallucinations
without structured verification. We introduce LongRecall, a general three-stage
recall evaluation framework that decomposes answers into self-contained facts,
successively narrows plausible candidate matches through lexical and semantic
filtering, and verifies their alignment through structured entailment checks.
This design reduces false positives and false negatives while accommodating
diverse phrasings and contextual variations, serving as a foundational building
block for systematic recall assessment. We evaluate LongRecall on three
challenging long-form QA benchmarks using both human annotations and LLM-based
judges, demonstrating substantial improvements in recall accuracy over strong
lexical and LLM-as-a-Judge baselines.

</details>


### [112] [Mapping the Course for Prompt-based Structured Prediction](https://arxiv.org/abs/2508.15090)
*Matt Pauk,Maria Leonor Pacheco*

Main category: cs.CL

TL;DR: 本文提出将大型语言模型（LLMs）与组合推理相结合，以解决LLMs在结构化预测任务中幻觉和复杂推理的挑战，从而提高预测的一致性和准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs在多种语言任务中表现出色，但由于其自回归特性，常在幻觉和复杂推理问题上遇到困难，尤其是在需要结构化输出的预测任务中。

Method: 研究方法包括：1) 将LLMs的预测能力与组合推理提供的结构一致性相结合。2) 实验评估不同的提示策略，以有效估计LLM置信度，供符号推理使用。3) 使用结构化预测目标进行校准和微调。

Result: 实验结果表明，无论采用何种提示策略，在仅提示的基础上增加符号推理都能带来更一致和准确的预测。此外，使用结构化预测目标进行校准和微调可以进一步提高挑战性任务的性能。

Conclusion: 结合LLMs与符号推理能有效提升结构化预测任务的性能，并且在LLM时代，结构化学习仍然具有重要的价值。

Abstract: LLMs have been shown to be useful for a variety of language tasks, without
requiring task-specific fine-tuning. However, these models often struggle with
hallucinations and complex reasoning problems due to their autoregressive
nature. We propose to address some of these issues, specifically in the area of
structured prediction, by combining LLMs with combinatorial inference in an
attempt to marry the predictive power of LLMs with the structural consistency
provided by inference methods. We perform exhaustive experiments in an effort
to understand which prompting strategies can effectively estimate LLM
confidence values for use with symbolic inference, and show that, regardless of
the prompting strategy, the addition of symbolic inference on top of prompting
alone leads to more consistent and accurate predictions. Additionally, we show
that calibration and fine-tuning using structured prediction objectives leads
to increased performance for challenging tasks, showing that structured
learning is still valuable in the era of LLMs.

</details>


### [113] [Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math Pretraining Dataset](https://arxiv.org/abs/2508.15096)
*Rabeeh Karimi Mahabadi,Sanjeev Satheesh,Shrimai Prabhumoye,Mostofa Patwary,Mohammad Shoeybi,Bryan Catanzaro*

Main category: cs.CL

TL;DR: 本文介绍了一种新的、高质量的数学语料库构建管道Nemotron-CC-Math，它能从Common Crawl中可靠地提取科学文本，克服了现有数据集的质量问题，并在LLM预训练中显著提升了数学、代码和通用推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有从Common Crawl构建的数学数据集质量不佳，存在提取启发式规则脆弱、HTML到文本转换有损以及数学结构难以可靠保存的问题。然而，高质量的结构化数据（如数学和代码）对于提升大型语言模型（LLM）的推理能力至关重要。

Method: 本文提出了一种新颖的、领域无关的管道，专门用于鲁棒的科学文本提取。该管道通过结合使用lynx进行布局感知渲染和LLM驱动的清理阶段，能够恢复各种格式（如MathJax、KaTeX、MathML）的数学内容。它能保留方程和代码块的结构完整性，同时去除样板文本，将符号标准化为LaTeX表示，并纠正不一致性。

Result: 研究团队构建了大型高质量数学语料库Nemotron-CC-Math-3+ (133B tokens) 和 Nemotron-CC-Math-4+ (52B tokens)。其中，Nemotron-CC-Math-4+不仅超越了所有先前的开放数学数据集，且比之前最高质量的FineMath-4+多出5.5倍的tokens。使用该语料库预训练Nemotron-T 8B模型后，在MATH任务上取得了+4.8到+12.6的提升，在MBPP+上取得了+4.6到+14.3的提升，同时还改善了MMLU和MMLU-Stem上的通用领域性能。

Conclusion: 本文提出了第一个能够从嘈杂的网络规模数据中可靠提取包括数学在内的科学内容的管道，从而在数学、代码和通用推理方面取得了可衡量的性能提升，并在开放数学预训练语料库中建立了新的SOTA。为支持开源工作，研究团队已发布了代码和数据集。

Abstract: Pretraining large language models (LLMs) on high-quality, structured data
such as mathematics and code substantially enhances reasoning capabilities.
However, existing math-focused datasets built from Common Crawl suffer from
degraded quality due to brittle extraction heuristics, lossy HTML-to-text
conversion, and the failure to reliably preserve mathematical structure. In
this work, we introduce Nemotron-CC-Math, a large-scale, high-quality
mathematical corpus constructed from Common Crawl using a novel,
domain-agnostic pipeline specifically designed for robust scientific text
extraction.
  Unlike previous efforts, our pipeline recovers math across various formats
(e.g., MathJax, KaTeX, MathML) by leveraging layout-aware rendering with lynx
and a targeted LLM-based cleaning stage. This approach preserves the structural
integrity of equations and code blocks while removing boilerplate,
standardizing notation into LaTeX representation, and correcting
inconsistencies.
  We collected a large, high-quality math corpus, namely Nemotron-CC-Math-3+
(133B tokens) and Nemotron-CC-Math-4+ (52B tokens). Notably,
Nemotron-CC-Math-4+ not only surpasses all prior open math datasets-including
MegaMath, FineMath, and OpenWebMath-but also contains 5.5 times more tokens
than FineMath-4+, which was previously the highest-quality math pretraining
dataset. When used to pretrain a Nemotron-T 8B model, our corpus yields +4.8 to
+12.6 gains on MATH and +4.6 to +14.3 gains on MBPP+ over strong baselines,
while also improving general-domain performance on MMLU and MMLU-Stem.
  We present the first pipeline to reliably extract scientific
content--including math--from noisy web-scale data, yielding measurable gains
in math, code, and general reasoning, and setting a new state of the art among
open math pretraining corpora. To support open-source efforts, we release our
code and datasets.

</details>


### [114] [Identifying and Answering Questions with False Assumptions: An Interpretable Approach](https://arxiv.org/abs/2508.15139)
*Zijie Wang,Eduardo Blanco*

Main category: cs.CL

TL;DR: 本文提出了一种利用外部证据和原子假设验证的方法，以识别并回答含有虚假假设的问题，从而减少大型语言模型（LLMs）的幻觉并提高答案的可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在回答含有虚假假设的问题时，常因幻觉而产生误导性答案，这类问题无法直接回答，需要先识别出虚假假设。

Method: 研究首先将问题简化为事实核查。接着，提出了一种利用外部证据来缓解幻觉的方法。此外，还通过生成和验证原子假设来进一步提升效果。

Result: 实验结果表明：1) 结合检索到的证据对回答此类问题有益；2) 生成和验证原子假设能带来更多改进，并通过明确指出虚假假设来提供更可解释的答案。

Conclusion: 通过整合外部证据和对原子假设的生成与验证，可以有效识别并回答含有虚假假设的问题，显著提升LLMs在此类任务上的表现和答案的可解释性。

Abstract: People often ask questions with false assumptions, a type of question that
does not have regular answers. Answering such questions require first
identifying the false assumptions. Large Language Models (LLMs) often generate
misleading answers because of hallucinations. In this paper, we focus on
identifying and answering questions with false assumptions in several domains.
We first investigate to reduce the problem to fact verification. Then, we
present an approach leveraging external evidence to mitigate hallucinations.
Experiments with five LLMs demonstrate that (1) incorporating retrieved
evidence is beneficial and (2) generating and validating atomic assumptions
yields more improvements and provides an interpretable answer by specifying the
false assumptions.

</details>


### [115] [ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following](https://arxiv.org/abs/2508.15164)
*Seungmin Han,Haeun Kwon,Ji-jun Park,Taeyang Yoon*

Main category: cs.CL

TL;DR: 该研究引入了一个新的多模态对话推理基准MMDR-Bench，并提出了CoLVLM Agent框架，通过迭代的“记忆-感知-规划-执行”循环，显著提升了现有大型视觉语言模型在复杂多轮、视觉接地任务中的表现，超越了GPT-4o和Gemini 1.5 Pro等SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）和大型视觉语言模型（LVLMs）取得了显著进展，但在处理需要深度推理、持续上下文理解、实体跟踪和多步骤指令遵循的复杂、多轮、视觉接地任务时仍面临巨大挑战。现有基准未能充分捕捉真实世界多模态交互的动态性和复杂性，导致上下文丢失和视觉幻觉等问题。

Method: 1. 引入MMDR-Bench：一个包含300个精心设计的复杂多轮对话场景的新型数据集，每个场景平均5-7轮，并在视觉实体跟踪和推理深度等六个核心维度上进行评估。2. 提出CoLVLM Agent：一个整体框架，通过迭代的“记忆-感知-规划-执行”循环，增强现有LVLMs的推理和指令遵循能力，无需对底层模型进行大量再训练。

Result: 在MMDR-Bench上的广泛实验表明，CoLVLM Agent持续取得卓越性能，平均人类评估得分达到4.03，显著超越了GPT-4o（3.92）和Gemini 1.5 Pro（3.85）等最先进的商业模型。该框架在推理深度、指令遵循和错误抑制方面表现出显著优势，并在扩展对话轮次中保持了稳健的性能。

Conclusion: CoLVLM Agent的模块化设计和迭代方法对于复杂的、多模态交互是有效的，其性能优于现有最先进的商业模型，验证了其在处理多轮、视觉接地推理任务方面的优越性。

Abstract: Despite significant advancements in Large Language Models (LLMs) and Large
Vision-Language Models (LVLMs), current models still face substantial
challenges in handling complex, multi-turn, and visually-grounded tasks that
demand deep reasoning, sustained contextual understanding, entity tracking, and
multi-step instruction following. Existing benchmarks often fall short in
capturing the dynamism and intricacies of real-world multi-modal interactions,
leading to issues such as context loss and visual hallucinations. To address
these limitations, we introduce MMDR-Bench (Multi-Modal Dialogue Reasoning
Benchmark), a novel dataset comprising 300 meticulously designed complex
multi-turn dialogue scenarios, each averaging 5-7 turns and evaluated across
six core dimensions including visual entity tracking and reasoning depth.
Furthermore, we propose CoLVLM Agent (Contextual LVLM Agent), a holistic
framework that enhances existing LVLMs with advanced reasoning and instruction
following capabilities through an iterative
"memory-perception-planning-execution" cycle, requiring no extensive
re-training of the underlying models. Our extensive experiments on MMDR-Bench
demonstrate that CoLVLM Agent consistently achieves superior performance,
attaining an average human evaluation score of 4.03, notably surpassing
state-of-the-art commercial models like GPT-4o (3.92) and Gemini 1.5 Pro
(3.85). The framework exhibits significant advantages in reasoning depth,
instruction adherence, and error suppression, and maintains robust performance
over extended dialogue turns, validating the effectiveness of its modular
design and iterative approach for complex multi-modal interactions.

</details>


### [116] [SemToken: Semantic-Aware Tokenization for Efficient Long-Context Language Modeling](https://arxiv.org/abs/2508.15190)
*Dong Liu,Yanxuan Yu*

Main category: cs.CL

TL;DR: SemToken是一种语义感知的标记化框架，它通过合并语义等价的标记和采用自适应粒度，显著减少标记数量并加速语言模型，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有标记化方法（如BPE、WordPiece）仅基于频率统计，忽略文本的语义结构，导致语义冗余的文本段过度标记化，且未充分利用上下文连贯性，尤其在长上下文场景中。

Method: SemToken框架首先通过轻量级编码器提取上下文语义嵌入，然后进行局部语义聚类以合并语义等价的标记。接着，它根据语义密度分配异构标记粒度，对内容丰富的区域进行细粒度标记化，对重复或低熵区域进行粗粒度压缩。

Result: 在WikiText-103和LongBench等长上下文语言模型基准测试中，SemToken实现了高达2.4倍的标记数量减少和1.9倍的速度提升，同时困惑度和下游任务准确性下降可忽略不计。

Conclusion: 研究结果表明，语义结构为优化大型语言模型中的标记化和计算提供了一个有前景的新方向。

Abstract: Tokenization plays a critical role in language modeling, yet existing
approaches such as Byte-Pair Encoding (BPE) or WordPiece operate purely on
frequency statistics, ignoring the underlying semantic structure of text. This
leads to over-tokenization of semantically redundant spans and underutilization
of contextual coherence, particularly in long-context scenarios. In this work,
we propose \textbf{SemToken}, a semantic-aware tokenization framework that
jointly reduces token redundancy and improves computation efficiency. SemToken
first extracts contextual semantic embeddings via lightweight encoders and
performs local semantic clustering to merge semantically equivalent tokens.
Then, it allocates heterogeneous token granularity based on semantic density,
allowing finer-grained tokenization in content-rich regions and coarser
compression in repetitive or low-entropy spans. SemToken can be seamlessly
integrated with modern language models and attention acceleration methods.
Experiments on long-context language modeling benchmarks such as WikiText-103
and LongBench show that SemToken achieves up to $2.4\times$ reduction in token
count and $1.9\times$ speedup, with negligible or no degradation in perplexity
and downstream accuracy. Our findings suggest that semantic structure offers a
promising new axis for optimizing tokenization and computation in large
language models.

</details>


### [117] [Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models](https://arxiv.org/abs/2508.15202)
*Yuanchen Zhou,Shuo Jiang,Jie Zhu,Junhui Li,Lifan Guo,Feng Chen,Chi Zhang*

Main category: cs.CL

TL;DR: Fin-PRM是一种针对金融领域定制的、轨迹感知的过程奖励模型，通过评估中间推理步骤，显著提升了大型语言模型在金融任务上的推理能力，优于通用PRM和强领域基线。


<details>
  <summary>Details</summary>
Motivation: 现有的过程奖励模型（PRM）主要针对通用或STEM领域，在金融等领域特定上下文中表现不足。金融领域的推理更为结构化、符号化，且对事实和监管的正确性高度敏感，需要更专业的评估方法。

Method: 引入Fin-PRM，一个领域专业化、轨迹感知的PRM，用于评估金融任务中的中间推理步骤。它整合了步骤级和轨迹级奖励监督，以实现与金融逻辑一致的细粒度评估。Fin-PRM应用于离线和在线奖励学习设置，支持三个主要应用：选择高质量推理轨迹用于蒸馏式监督微调、为强化学习提供密集过程级奖励、以及在测试时指导奖励知情的Best-of-N推理。

Result: 在CFLUE和FinQA等金融推理基准测试中，Fin-PRM在轨迹选择质量方面始终优于通用PRM和强领域基线。使用Fin-PRM训练的下游模型在监督学习中获得了12.9%的显著提升，在强化学习中获得了5.2%的提升，在测试时性能上获得了5.1%的提升。

Conclusion: 这些发现强调了领域专业化奖励建模对于使大型语言模型与专家级金融推理对齐的价值。

Abstract: Process Reward Models (PRMs) have emerged as a promising framework for
supervising intermediate reasoning in large language models (LLMs), yet
existing PRMs are primarily trained on general or Science, Technology,
Engineering, and Mathematics (STEM) domains and fall short in domain-specific
contexts such as finance, where reasoning is more structured, symbolic, and
sensitive to factual and regulatory correctness. We introduce \textbf{Fin-PRM},
a domain-specialized, trajectory-aware PRM tailored to evaluate intermediate
reasoning steps in financial tasks. Fin-PRM integrates step-level and
trajectory-level reward supervision, enabling fine-grained evaluation of
reasoning traces aligned with financial logic. We apply Fin-PRM in both offline
and online reward learning settings, supporting three key applications: (i)
selecting high-quality reasoning trajectories for distillation-based supervised
fine-tuning, (ii) providing dense process-level rewards for reinforcement
learning, and (iii) guiding reward-informed Best-of-N inference at test time.
Experimental results on financial reasoning benchmarks, including CFLUE and
FinQA, demonstrate that Fin-PRM consistently outperforms general-purpose PRMs
and strong domain baselines in trajectory selection quality. Downstream models
trained with Fin-PRM yield substantial improvements with baselines, with gains
of 12.9\% in supervised learning, 5.2\% in reinforcement learning, and 5.1\% in
test-time performance. These findings highlight the value of domain-specialized
reward modeling for aligning LLMs with expert-level financial reasoning. Our
project resources will be available at https://github.com/aliyun/qwen-dianjin.

</details>


### [118] [SparK: Query-Aware Unstructured Sparsity with Recoverable KV Cache Channel Pruning](https://arxiv.org/abs/2508.15212)
*Huanxuan Liao,Yixing Xu,Shizhu He,Guanchen Li,Xuanwu Yin,Dong Li,Emad Barsoum,Jun Zhao,Kang Liu*

Main category: cs.CL

TL;DR: SPARK是一种无需训练的即插即用方法，通过在通道级别对KV缓存进行非结构化稀疏剪枝，并动态恢复，有效缓解了大型语言模型中长上下文推理的KV缓存瓶颈，显著减少内存并保持或提高模型精度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中长上下文推理面临KV缓存瓶颈：内存随序列长度线性增长，注意力计算呈二次方增长。现有方法（如token驱逐或合并）通过时间轴压缩KV缓存，但忽略了特征维度（通道轴）上细粒度的重要性变化，限制了效率与准确性的平衡。研究发现，通道显著性在查询和位置上差异巨大，某些通道信息量接近零，而另一些则高度相关。

Method: 本文提出了SPARK，一种无需训练的即插即用方法。它在通道级别对KV缓存应用非结构化稀疏剪枝，并在注意力分数计算过程中动态恢复被剪枝的条目。该方法与现有KV压缩和量化技术正交，可兼容集成以实现进一步加速。

Result: SPARK在相同内存预算下能够处理更长的序列。对于等长序列，SPARK相比基于驱逐的方法，不仅保持或提高了模型精度，还减少了超过30%的KV缓存存储。即使在80%的激进剪枝率下，SPARK的性能下降也比基线驱逐方法少于5%，展示了其鲁棒性和有效性。

Conclusion: SPARK通过在通道级别剪枝KV缓存，有效解决了大型语言模型中的KV缓存瓶颈，显著减少了内存占用，同时保持或提高了模型精度。其无需训练、即插即用的特性以及与其他方法的兼容性，使其成为长上下文推理的有效解决方案。

Abstract: Long-context inference in large language models (LLMs) is increasingly
constrained by the KV cache bottleneck: memory usage grows linearly with
sequence length, while attention computation scales quadratically. Existing
approaches address this issue by compressing the KV cache along the temporal
axis through strategies such as token eviction or merging to reduce memory and
computational overhead. However, these methods often neglect fine-grained
importance variations across feature dimensions (i.e., the channel axis),
thereby limiting their ability to effectively balance efficiency and model
accuracy. In reality, we observe that channel saliency varies dramatically
across both queries and positions: certain feature channels carry near-zero
information for a given query, while others spike in relevance. To address this
oversight, we propose SPARK, a training-free plug-and-play method that applies
unstructured sparsity by pruning KV at the channel level, while dynamically
restoring the pruned entries during attention score computation. Notably, our
approach is orthogonal to existing KV compression and quantization techniques,
making it compatible for integration with them to achieve further acceleration.
By reducing channel-level redundancy, SPARK enables processing of longer
sequences within the same memory budget. For sequences of equal length, SPARK
not only preserves or improves model accuracy but also reduces KV cache storage
by over 30% compared to eviction-based methods. Furthermore, even with an
aggressive pruning ratio of 80%, SPARK maintains performance with less
degradation than 5% compared to the baseline eviction method, demonstrating its
robustness and effectiveness. Our code will be available at
https://github.com/Xnhyacinth/SparK.

</details>


### [119] [Select to Know: An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering](https://arxiv.org/abs/2508.15213)
*Bolei He,Xinran He,Run Shao,Shanfu Shu,Xianwei Xue,Mingquan Cheng,Haifeng Li,Zhenhua Ling*

Main category: cs.CL

TL;DR: Selct2Know (S2K) 是一个经济高效的框架，通过内部-外部知识自选择和选择性监督微调，帮助大型语言模型内化领域知识，解决了领域特定问答中的挑战，并在多个领域基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用问答中表现良好，但在领域特定场景中表现不佳。检索增强生成（RAG）存在幻觉和延迟问题，而持续预训练成本高昂且缺乏跨领域灵活性。作者将此归因于领域知识的长尾分布导致部分内部知识未被充分利用，并认为知识获取应遵循人类学习的渐进模式。

Method: 本文提出了Selct2Know (S2K) 框架，通过内部-外部知识自选择策略和选择性监督微调来内化领域知识。此外，还引入了结构化推理数据生成管道，并集成了GRPO以增强推理能力。

Result: 在医学、法律和金融问答基准测试中，S2K持续优于现有方法，并以显著更低的成本达到了领域预训练大型语言模型的性能水平。

Conclusion: S2K是一个经济高效的框架，能够有效地内化领域知识，显著提升大型语言模型在领域特定问答中的表现，并能与领域预训练模型相媲美，同时大大降低了成本。

Abstract: Large Language Models (LLMs) perform well in general QA but often struggle in
domain-specific scenarios. Retrieval-Augmented Generation (RAG) introduces
external knowledge but suffers from hallucinations and latency due to noisy
retrievals. Continued pretraining internalizes domain knowledge but is costly
and lacks cross-domain flexibility. We attribute this challenge to the
long-tail distribution of domain knowledge, which leaves partial yet useful
internal knowledge underutilized. We further argue that knowledge acquisition
should be progressive, mirroring human learning: first understanding concepts,
then applying them to complex reasoning. To address this, we propose Selct2Know
(S2K), a cost-effective framework that internalizes domain knowledge through an
internal-external knowledge self-selection strategy and selective supervised
fine-tuning. We also introduce a structured reasoning data generation pipeline
and integrate GRPO to enhance reasoning ability. Experiments on medical, legal,
and financial QA benchmarks show that S2K consistently outperforms existing
methods and matches domain-pretrained LLMs with significantly lower cost.

</details>


### [120] [Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall](https://arxiv.org/abs/2508.15214)
*Sijia Cui,Aiyao He,Shuai Xu,Hongming Zhang,Yanna Wang,Qingyang Zhang,Yajing Wang,Bo Xu*

Main category: cs.CL

TL;DR: 本文提出了一种名为SEER的自引导方法，通过从持续更新的经验池中逐步检索细粒度经验，显著提升了大型语言模型（LLMs）在多步工具使用场景中的表现，解决了现有方法对专家知识和提示工程的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理多步工具使用时，在工具选择、参数生成和工具链规划方面仍面临挑战。现有方法通常依赖手动设计任务特定演示或从精心策划的库中检索，这些方法需要大量专家投入，且随着工具多样性和任务难度的增加，提示工程变得复杂且效率低下。

Method: 本文提出了一种自引导方法——分步经验回忆（SEER）。该方法从一个持续更新的经验池中进行细粒度的分步检索。与依赖静态或手动策划库不同，SEER通过将过去成功的轨迹逐步添加到经验池中，实现经验池的持续扩展和模型性能的逐步提升。

Result: 在ToolQA基准测试中，SEER在简单问题上平均提高了6.1%，在困难问题上平均提高了4.7%。在包含两个真实世界领域的$	au$-bench上，SEER结合Qwen2.5-7B和Qwen2.5-72B模型分别实现了7.44%和23.38%的显著准确率提升。

Conclusion: SEER通过其自引导的、逐步的经验检索和持续更新的经验池机制，有效解决了LLMs在多步工具使用中的挑战，实现了显著的性能提升，且无需大量手动干预。

Abstract: Function calling enables large language models (LLMs) to interact with
external systems by leveraging tools and APIs. When faced with multi-step tool
usage, LLMs still struggle with tool selection, parameter generation, and
tool-chain planning. Existing methods typically rely on manually designing
task-specific demonstrations, or retrieving from a curated library. These
approaches demand substantial expert effort and prompt engineering becomes
increasingly complex and inefficient as tool diversity and task difficulty
scale. To address these challenges, we propose a self-guided method, Stepwise
Experience Recall (SEER), which performs fine-grained, stepwise retrieval from
a continually updated experience pool. Instead of relying on static or manually
curated library, SEER incrementally augments the experience pool with past
successful trajectories, enabling continuous expansion of the pool and improved
model performance over time. Evaluated on the ToolQA benchmark, SEER achieves
an average improvement of 6.1\% on easy and 4.7\% on hard questions. We further
test SEER on $\tau$-bench, which includes two real-world domains. Powered by
Qwen2.5-7B and Qwen2.5-72B models, SEER demonstrates substantial accuracy gains
of 7.44\% and 23.38\%, respectively.

</details>


### [121] [Are Checklists Really Useful for Automatic Evaluation of Generative Tasks?](https://arxiv.org/abs/2508.15218)
*Momoka Furuhashi,Kouta Nakayama,Takashi Kodama,Saku Sugawara*

Main category: cs.CL

TL;DR: 本研究探讨了在大型语言模型中，选择性使用自动生成的评估清单可以改善生成任务的配对评估性能，但在直接评分中效果不一，并揭示了人类评估标准可能存在不一致。


<details>
  <summary>Details</summary>
Motivation: 由于评估标准模糊，使用大型语言模型自动评估生成任务面临挑战。自动生成评估清单是一种有前景的方法，但其有效性尚未得到充分探索。

Method: 研究调查了评估清单应全面使用还是选择性使用；使用六种方法生成评估清单；在八种不同模型尺寸下评估其有效性；并识别出与人类评估相关的清单项目。实验在配对比较和直接评分任务中进行。

Result: 研究发现，选择性使用评估清单倾向于改善配对设置中的评估性能，但在直接评分中的益处不太一致。分析还表明，即使与人类评分相关性低的清单项目也常反映人类编写的标准，这表明人类评估可能存在不一致性。

Conclusion: 这些发现强调了需要更清晰地定义客观评估标准，以指导人类和自动评估，从而提高生成任务评估的准确性和一致性。

Abstract: Automatic evaluation of generative tasks using large language models faces
challenges due to ambiguous criteria. Although automatic checklist generation
is a potentially promising approach, its usefulness remains underexplored. We
investigate whether checklists should be used for all questions or selectively,
generate them using six methods, evaluate their effectiveness across eight
model sizes, and identify checklist items that correlate with human
evaluations. Through experiments on pairwise comparison and direct scoring
tasks, we find that selective checklist use tends to improve evaluation
performance in pairwise settings, while its benefits are less consistent in
direct scoring. Our analysis also shows that even checklist items with low
correlation to human scores often reflect human-written criteria, indicating
potential inconsistencies in human evaluation. These findings highlight the
need to more clearly define objective evaluation criteria to guide both human
and automatic evaluations. \footnote{Our code is available
at~https://github.com/momo0817/checklist-effectiveness-study

</details>


### [122] [VocabTailor: Dynamic Vocabulary Selection for Downstream Tasks in Small Language Models](https://arxiv.org/abs/2508.15229)
*Hanling Zhang,Yayu Zhou,Tongcheng Fang,Zhihang Yuan,Guohao Dai,Yu Wang*

Main category: cs.CL

TL;DR: 本文提出VocabTailor，一个解耦动态词汇选择框架，通过卸载嵌入层和对LM头采用混合静态-动态策略，显著减少小型语言模型（SLM）在边缘设备上的词汇相关组件内存占用，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLM）在资源受限环境中具有计算优势，但其内存限制是边缘设备部署的关键瓶颈。词汇相关组件（特别是嵌入层和语言模型头）因词汇量大而占用大量内存。现有静态词汇剪枝方法过于僵化，导致预填充阶段信息丢失且缺乏灵活性。

Method: 基于词汇局部性原则（单次推理仅需少量词元）和SLM词汇相关组件计算特性不对称的洞察，本文提出了VocabTailor。该框架通过卸载嵌入层来解决内存限制，并为语言模型头（LM Head）实现混合静态-动态词汇选择策略，从而实现词汇组件的按需加载。

Result: 在多种下游任务上的综合实验表明，VocabTailor将词汇相关组件的内存使用量减少了高达99%，且任务性能退化极小或没有退化。其表现显著优于现有静态词汇剪枝方法。

Conclusion: VocabTailor通过其新颖的解耦动态词汇选择框架，有效地解决了SLM在边缘设备上的内存限制问题，在显著节省内存的同时保持了出色的任务性能，超越了传统的静态剪枝方法。

Abstract: Small Language Models (SLMs) provide computational advantages in
resource-constrained environments, yet memory limitations remain a critical
bottleneck for edge device deployment. A substantial portion of SLMs' memory
footprint stems from vocabulary-related components, particularly embeddings and
language modeling (LM) heads, due to large vocabulary sizes. Existing static
vocabulary pruning, while reducing memory usage, suffers from rigid,
one-size-fits-all designs that cause information loss from the prefill stage
and a lack of flexibility. In this work, we identify two key principles
underlying the vocabulary reduction challenge: the lexical locality principle,
the observation that only a small subset of tokens is required during any
single inference, and the asymmetry in computational characteristics between
vocabulary-related components of SLM. Based on these insights, we introduce
VocabTailor, a novel decoupled dynamic vocabulary selection framework that
addresses memory constraints through offloading embedding and implements a
hybrid static-dynamic vocabulary selection strategy for LM Head, enabling
on-demand loading of vocabulary components. Comprehensive experiments across
diverse downstream tasks demonstrate that VocabTailor achieves a reduction of
up to 99% in the memory usage of vocabulary-related components with minimal or
no degradation in task performance, substantially outperforming existing static
vocabulary pruning.

</details>


### [123] [WangchanThaiInstruct: An instruction-following Dataset for Culture-Aware, Multitask, and Multi-domain Evaluation in Thai](https://arxiv.org/abs/2508.15239)
*Peerat Limkonchotiwat,Pume Tuchinda,Lalita Lowphansirikul,Surapon Nonesung,Panuthep Tasawong,Alham Fikri Aji,Can Udomcharoenchaikit,Sarana Nutanong*

Main category: cs.CL

TL;DR: 该研究提出了WangchanThaiInstruct，一个人工编写的泰语指令数据集，用于评估和微调大型语言模型在泰语低资源环境中的表现。结果表明，使用原生指令数据微调的模型显著优于使用翻译数据的模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在英语指令遵循方面表现出色，但在泰语等低资源语言中的性能尚未充分探索。现有基准测试常依赖翻译，这可能遗漏了实际应用所需的文化和领域特定细微差别。

Method: 研究团队构建了WangchanThaiInstruct数据集，该数据集由人工编写，涵盖四个专业领域和七种任务类型，并经过多阶段质量控制（涉及标注员、领域专家和AI研究人员）。基于此数据集，进行了两项研究：(1) 零样本评估，以揭示文化和专业特定任务的性能差距；(2) 指令微调研究，通过消融实验隔离原生监督的效果。

Result: 零样本评估揭示了在文化和专业特定任务上的性能差距。使用WangchanThaiInstruct数据集进行微调的模型，无论是在领域内还是领域外基准测试中，都优于使用翻译数据进行微调的模型。

Conclusion: 研究结果强调了在低资源、语言多样化环境中，需要文化和专业背景扎实的指令数据来提高大型语言模型的对齐能力。

Abstract: Large language models excel at instruction-following in English, but their
performance in low-resource languages like Thai remains underexplored. Existing
benchmarks often rely on translations, missing cultural and domain-specific
nuances needed for real-world use. We present WangchanThaiInstruct, a
human-authored Thai dataset for evaluation and instruction tuning, covering
four professional domains and seven task types. Created through a multi-stage
quality control process with annotators, domain experts, and AI researchers,
WangchanThaiInstruct supports two studies: (1) a zero-shot evaluation showing
performance gaps on culturally and professionally specific tasks, and (2) an
instruction tuning study with ablations isolating the effect of native
supervision. Models fine-tuned on WangchanThaiInstruct outperform those using
translated data in both in-domain and out-of-domain benchmarks. These findings
underscore the need for culturally and professionally grounded instruction data
to improve LLM alignment in low-resource, linguistically diverse settings.

</details>


### [124] [UniCoM: A Universal Code-Switching Speech Generator](https://arxiv.org/abs/2508.15244)
*Sangmin Lee,Woojin Chung,Seyun Um,Hong-Goo Kang*

Main category: cs.CL

TL;DR: 本文提出了一种名为UniCoM的新型流水线，用于生成高质量、自然的语码转换（CS）语音样本，以解决多语言语音技术中CS数据集稀缺的问题，并构建了CS-FLEURS语料库。


<details>
  <summary>Details</summary>
Motivation: 语码转换（CS）在真实对话中很常见，对多语言语音技术构成重大挑战。然而，处理这种现象的系统尚未得到充分探索，主要原因是缺乏合适的CS数据集。

Method: 研究人员提出了Universal Code-Mixer (UniCoM) 流水线，利用名为Substituting WORDs with Synonyms (SWORDS) 的算法。该算法通过在考虑词性（POS）的前提下，用翻译替换选定的词语来生成CS语音，同时不改变句子语义。利用UniCoM，他们构建了Code-Switching FLEURS (CS-FLEURS) 多语言CS语料库，专为自动语音识别（ASR）和语音到文本翻译（S2TT）设计。

Result: 实验结果表明，CS-FLEURS语料库在客观和主观指标上都实现了高可懂度和自然度，表现与现有数据集相当。

Conclusion: 该方法有望推动语码转换语音技术的发展，并实现更具包容性的多语言系统。

Abstract: Code-switching (CS), the alternation between two or more languages within a
single speaker's utterances, is common in real-world conversations and poses
significant challenges for multilingual speech technology. However, systems
capable of handling this phenomenon remain underexplored, primarily due to the
scarcity of suitable datasets. To resolve this issue, we propose Universal
Code-Mixer (UniCoM), a novel pipeline for generating high-quality, natural CS
samples without altering sentence semantics. Our approach utilizes an algorithm
we call Substituting WORDs with Synonyms (SWORDS), which generates CS speech by
replacing selected words with their translations while considering their parts
of speech. Using UniCoM, we construct Code-Switching FLEURS (CS-FLEURS), a
multilingual CS corpus designed for automatic speech recognition (ASR) and
speech-to-text translation (S2TT). Experimental results show that CS-FLEURS
achieves high intelligibility and naturalness, performing comparably to
existing datasets on both objective and subjective metrics. We expect our
approach to advance CS speech technology and enable more inclusive multilingual
systems.

</details>


### [125] [EMNLP: Educator-role Moral and Normative Large Language Models Profiling](https://arxiv.org/abs/2508.15250)
*Yilin Jiang,Mingzi Zhang,Sheng Jin,Zengyi Yu,Xiangjie Kong,Binghao Tu*

Main category: cs.CL

TL;DR: 本研究提出了EMNLP框架，用于评估模拟教师角色的LLM在人格、道德发展阶段和软提示注入下的伦理风险。发现LLM与人类教师存在差异，在抽象道德推理上表现出色但在情感复杂情境中表现不佳，且推理能力越强的模型越容易受到有害提示注入攻击。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）能够模拟专业角色（如教师），但目前缺乏对这些情境下LLMs进行全面的心理和伦理评估。

Method: 本研究引入了EMNLP（教师角色道德与规范LLMs画像）框架，用于人格画像、道德发展阶段测量以及软提示注入下的伦理风险评估。该框架扩展了现有量表，构建了88个教师特有的道德困境，并设计了目标软提示注入集。研究对12个LLMs进行了实验，并与人类教师进行了专业导向的比较。

Result: 实验结果显示，模拟教师角色的LLMs比人类教师展现出更理想化和两极化的人格，在抽象道德推理方面表现出色，但在处理情感复杂情境时遇到困难。具有更强推理能力的模型更容易受到有害提示注入的攻击，揭示了能力与安全之间的悖论。模型温度等超参数的影响有限，仅在某些风险行为中有所体现。

Conclusion: 本论文首次提出了一个基准，用于评估教育AI中教师角色LLMs的伦理和心理一致性。研究揭示了LLM能力与安全之间的矛盾，为未来教育AI的发展提供了重要见解。

Abstract: Simulating Professions (SP) enables Large Language Models (LLMs) to emulate
professional roles. However, comprehensive psychological and ethical evaluation
in these contexts remains lacking. This paper introduces EMNLP, an
Educator-role Moral and Normative LLMs Profiling framework for personality
profiling, moral development stage measurement, and ethical risk under soft
prompt injection. EMNLP extends existing scales and constructs 88
teacher-specific moral dilemmas, enabling profession-oriented comparison with
human teachers. A targeted soft prompt injection set evaluates compliance and
vulnerability in teacher SP. Experiments on 12 LLMs show teacher-role LLMs
exhibit more idealized and polarized personalities than human teachers, excel
in abstract moral reasoning, but struggle with emotionally complex situations.
Models with stronger reasoning are more vulnerable to harmful prompt injection,
revealing a paradox between capability and safety. The model temperature and
other hyperparameters have limited influence except in some risk behaviors.
This paper presents the first benchmark to assess ethical and psychological
alignment of teacher-role LLMs for educational AI. Resources are available at
https://e-m-n-l-p.github.io/.

</details>


### [126] [Conflict-Aware Soft Prompting for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.15253)
*Eunseong Choi,June Park,Hyeri Lee,Jongwuk Lee*

Main category: cs.CL

TL;DR: 当检索到的上下文与大语言模型的参数知识冲突时，RAG系统会遇到问题。本文提出了CARE（Conflict-Aware REtrieval-Augmented Generation），通过一个上下文评估器来识别不可靠的上下文，从而有效缓解这种冲突。


<details>
  <summary>Details</summary>
Motivation: RAG系统在检索到的外部上下文与大语言模型的内部参数知识发生矛盾时（即上下文-记忆冲突），常常无法解决这种冲突，导致其性能下降。因此，需要一种机制来处理这种知识来源之间的不一致性。

Method: 本文引入了CARE系统，它由一个上下文评估器和一个基础大语言模型组成。上下文评估器负责将原始上下文令牌编码为紧凑的记忆令牌嵌入。通过接地/对抗性软提示（grounded/adversarial soft prompting）进行训练，上下文评估器能够辨别不可靠的上下文，并生成一个指导信号，将推理导向更可靠的知识来源。

Result: 实验结果表明，CARE系统有效缓解了上下文-记忆冲突，在问答和事实核查基准测试中平均性能提升了5.0%。

Conclusion: CARE系统为构建值得信赖和自适应的RAG系统提供了一个有前景的方向，通过处理上下文-记忆冲突，提高了系统的鲁棒性和准确性。

Abstract: Retrieval-augmented generation (RAG) enhances the capabilities of large
language models (LLMs) by incorporating external knowledge into their input
prompts. However, when the retrieved context contradicts the LLM's parametric
knowledge, it often fails to resolve the conflict between incorrect external
context and correct parametric knowledge, known as context-memory conflict. To
tackle this problem, we introduce Conflict-Aware REtrieval-Augmented Generation
(CARE), consisting of a context assessor and a base LLM. The context assessor
encodes compact memory token embeddings from raw context tokens. Through
grounded/adversarial soft prompting, the context assessor is trained to discern
unreliable context and capture a guidance signal that directs reasoning toward
the more reliable knowledge source. Extensive experiments show that CARE
effectively mitigates context-memory conflicts, leading to an average
performance gain of 5.0\% on QA and fact-checking benchmarks, establishing a
promising direction for trustworthy and adaptive RAG systems.

</details>


### [127] [TComQA: Extracting Temporal Commonsense from Text](https://arxiv.org/abs/2508.15274)
*Lekshmi R Nair,Arun Sankar,Koninika Pal*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）从文本中提取时间常识的能力，并提出了一个利用LLMs自动挖掘时间常识的管道，构建了新的数据集TComQA，该数据集在时间常识提取方面表现出高精度，并能有效提升模型在时间问答任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 理解事件需要掌握其时间上下文，而这些上下文在自然语言中通常不明确提及。当前大型语言模型（LLMs）在处理需要时间常识推理的任务时表现不佳，因为时间常识在文本中很少被明确提及。因此，自动挖掘事件的时间常识对于构建更强大的语言模型至关重要。

Method: 本文调查了LLMs从文本中提取时间常识的能力，并评估了多种实验设置。提出了一种时间常识提取管道，该管道利用LLMs自动挖掘时间常识，并用其构建了TComQA数据集，该数据集来源于SAMSum和RealNews语料库，并通过众包进行了验证。

Result: TComQA数据集在提取时间常识方面的精度超过80%。使用TComQA训练的模型在时间问答任务上，优于在现有时间问答数据集上进行微调的LLM。

Conclusion: LLMs能够有效地从文本中提取时间常识。通过所提出的提取管道和构建的TComQA数据集，可以成功地挖掘高精度的事件时间常识，并显著提升模型在时间推理任务上的表现，从而为构建更鲁棒的语言模型提供了支持。

Abstract: Understanding events necessitates grasping their temporal context, which is
often not explicitly stated in natural language. For example, it is not a
trivial task for a machine to infer that a museum tour may last for a few
hours, but can not take months. Recent studies indicate that even advanced
large language models (LLMs) struggle in generating text that require reasoning
with temporal commonsense due to its infrequent explicit mention in text.
Therefore, automatically mining temporal commonsense for events enables the
creation of robust language models. In this work, we investigate the capacity
of LLMs to extract temporal commonsense from text and evaluate multiple
experimental setups to assess their effectiveness. Here, we propose a temporal
commonsense extraction pipeline that leverages LLMs to automatically mine
temporal commonsense and use it to construct TComQA, a dataset derived from
SAMSum and RealNews corpora. TComQA has been validated through crowdsourcing
and achieves over 80\% precision in extracting temporal commonsense. The model
trained with TComQA also outperforms an LLM fine-tuned on existing dataset of
temporal question answering task.

</details>


### [128] [CUPE: Contextless Universal Phoneme Encoder for Language-Agnostic Speech Processing](https://arxiv.org/abs/2508.15316)
*Abdul Rehman,Jian-Jun Zhang,Xiaosong Yang*

Main category: cs.CL

TL;DR: CUPE是一种轻量级模型，能在120毫秒内捕捉关键音素特征，通过学习基本声学模式实现具有竞争力的跨语言音素识别，摆脱了上下文和语言特异性依赖。


<details>
  <summary>Details</summary>
Motivation: 许多语音处理任务需要不受上下文影响的纯音素表示，而传统的通用音素识别方法需要分析长语音片段和语言特定模式，这促使研究者开发一个能快速提供纯音素表示的模型。

Method: CUPE模型采用轻量级设计，独立处理短的、固定宽度的（约120毫秒）语音窗口。它通过学习所有语言通用的基本声学模式，参数量少于现有方法，从而实现跨语言性能。

Result: CUPE在监督式和自监督式训练下，在多种语言上展现出强大的跨语言泛化能力，包括在UCLA语音语料库上的零样本测试。它实现了具有竞争力的跨语言性能，证明通过在音素长度窗口内建模基本声学模式，可以实现有效的通用语音处理。

Conclusion: 通过在音素长度窗口内建模基本的声学模式，可以实现有效的通用语音处理，从而获得不受上下文影响的纯音素表示。

Abstract: Universal phoneme recognition typically requires analyzing long speech
segments and language-specific patterns. Many speech processing tasks require
pure phoneme representations free from contextual influence, which motivated
our development of CUPE - a lightweight model that captures key phoneme
features in just 120 milliseconds, about one phoneme's length. CUPE processes
short, fixed-width windows independently and, despite fewer parameters than
current approaches, achieves competitive cross-lingual performance by learning
fundamental acoustic patterns common to all languages. Our extensive evaluation
through supervised and self-supervised training on diverse languages, including
zero-shot tests on the UCLA Phonetic Corpus, demonstrates strong cross-lingual
generalization and reveals that effective universal speech processing is
possible through modeling basic acoustic patterns within phoneme-length
windows.

</details>


### [129] [KG-EDAS: A Meta-Metric Framework for Evaluating Knowledge Graph Completion Models](https://arxiv.org/abs/2508.15357)
*Haji Gul,Abul Ghani Naim,Ajaz Ahmad Bhat*

Main category: cs.CL

TL;DR: 该论文提出了一种名为EDAS（基于与平均解距离的知识图谱评估）的元度量标准，用于统一评估跨多个数据集和评估指标的知识图谱补全（KGC）模型性能。


<details>
  <summary>Details</summary>
Motivation: 知识图谱（KG）补全模型在评估时面临挑战：不同模型在不同数据集上表现不一，甚至在同一数据集上，不同评估指标（如MRR和Hit@1）也会给出冲突的排名，这阻碍了模型的整体比较和选择。因此，需要一个统一的元度量标准来整合跨所有指标和数据集的性能。

Method: 本文提出了一种名为EDAS（基于与平均解距离的知识图谱评估）的元度量标准。EDAS是一种稳健且可解释的方法，它将模型在多个数据集和多样化评估标准下的性能综合成一个单一的标准化分数（Mi ∈ [0,1]）。

Result: 在FB15k-237和WN18RR等基准数据集上的实验结果表明，EDAS有效地将多指标、多数据集的性能整合为一个统一的排名，提供了一个一致、稳健和可推广的KGC模型评估框架。

Conclusion: EDAS提供了一个全局视角，支持更明智的模型选择，促进了跨数据集评估的公平性，并为KGC模型提供了一个可靠且可解释的评估框架。

Abstract: Knowledge Graphs (KGs) enable applications in various domains such as
semantic search, recommendation systems, and natural language processing. KGs
are often incomplete, missing entities and relations, an issue addressed by
Knowledge Graph Completion (KGC) methods that predict missing elements.
Different evaluation metrics, such as Mean Reciprocal Rank (MRR), Mean Rank
(MR), and Hit@k, are commonly used to assess the performance of such KGC
models. A major challenge in evaluating KGC models, however, lies in comparing
their performance across multiple datasets and metrics. A model may outperform
others on one dataset but underperform on another, making it difficult to
determine overall superiority. Moreover, even within a single dataset,
different metrics such as MRR and Hit@1 can yield conflicting rankings, where
one model excels in MRR while another performs better in Hit@1, further
complicating model selection for downstream tasks. These inconsistencies hinder
holistic comparisons and highlight the need for a unified meta-metric that
integrates performance across all metrics and datasets to enable a more
reliable and interpretable evaluation framework. To address this need, we
propose KG Evaluation based on Distance from Average Solution (EDAS), a robust
and interpretable meta-metric that synthesizes model performance across
multiple datasets and diverse evaluation criteria into a single normalized
score ($M_i \in [0,1]$). Unlike traditional metrics that focus on isolated
aspects of performance, EDAS offers a global perspective that supports more
informed model selection and promotes fairness in cross-dataset evaluation.
Experimental results on benchmark datasets such as FB15k-237 and WN18RR
demonstrate that EDAS effectively integrates multi-metric, multi-dataset
performance into a unified ranking, offering a consistent, robust, and
generalizable framework for evaluating KGC models.

</details>


### [130] [A Survey on Large Language Model Benchmarks](https://arxiv.org/abs/2508.15361)
*Shiwen Ni,Guhong Chen,Shuaimin Li,Xuanang Chen,Siyi Li,Bingli Wang,Qiyao Wang,Xingjian Wang,Yifan Zhang,Liyang Fan,Chengming Li,Ruifeng Xu,Le Sun,Min Yang*

Main category: cs.CL

TL;DR: 本文首次系统回顾了大型语言模型基准测试的现状与发展，将283个代表性基准测试分为通用能力、领域特定和目标特定三类，并指出了现有基准测试存在的问题，为未来设计提供了参考范式。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型能力的深度和广度快速发展，评估其性能的基准测试数量激增。基准测试不仅是衡量模型能力的核心手段，也是指导模型发展方向和促进技术创新的关键要素。因此，有必要对这些基准测试进行系统性回顾和分析。

Method: 本文采用系统性回顾的方法，首次对大型语言模型基准测试的现状和发展进行了梳理。研究者将283个具有代表性的基准测试归类为三大类：通用能力、领域特定和目标特定。

Result: 研究结果包括：1. 将大型语言模型基准测试分为通用能力（核心语言学、知识、推理）、领域特定（自然科学、人文社科、工程技术）和目标特定（风险、可靠性、智能体）三大类。2. 指出当前基准测试存在数据污染导致分数虚高、文化和语言偏见导致评估不公、以及缺乏对过程可信度和动态环境评估等问题。

Conclusion: 当前大型语言模型基准测试存在多方面问题，需要创新改进。本文为未来基准测试的设计提供了一个可参考的范式，以期解决现有挑战，推动更公平、全面和动态的模型评估。

Abstract: In recent years, with the rapid development of the depth and breadth of large
language models' capabilities, various corresponding evaluation benchmarks have
been emerging in increasing numbers. As a quantitative assessment tool for
model performance, benchmarks are not only a core means to measure model
capabilities but also a key element in guiding the direction of model
development and promoting technological innovation. We systematically review
the current status and development of large language model benchmarks for the
first time, categorizing 283 representative benchmarks into three categories:
general capabilities, domain-specific, and target-specific. General capability
benchmarks cover aspects such as core linguistics, knowledge, and reasoning;
domain-specific benchmarks focus on fields like natural sciences, humanities
and social sciences, and engineering technology; target-specific benchmarks pay
attention to risks, reliability, agents, etc. We point out that current
benchmarks have problems such as inflated scores caused by data contamination,
unfair evaluation due to cultural and linguistic biases, and lack of evaluation
on process credibility and dynamic environments, and provide a referable design
paradigm for future benchmark innovation.

</details>


### [131] [Unveiling Trust in Multimodal Large Language Models: Evaluation, Analysis, and Mitigation](https://arxiv.org/abs/2508.15370)
*Yichi Zhang,Yao Huang,Yifan Wang,Yitong Sun,Chang Liu,Zhe Zhao,Zhengwei Fang,Huanran Chen,Xiao Yang,Xingxing Wei,Hang Su,Yinpeng Dong,Jun Zhu*

Main category: cs.CL

TL;DR: 该研究提出了MultiTrust-X，一个用于评估、分析和缓解多模态大语言模型（MLLMs）信任度问题的综合基准，并揭示了现有模型的漏洞和缓解策略的局限性，最终提出了一种基于推理的安全性对齐（RESA）方法。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）的能力显著提升，但其信任度仍是主要担忧。现有评估和缓解方法往往过于狭窄，并忽视了多模态引入的风险。

Method: 提出了MultiTrust-X基准，该基准基于一个三维框架，涵盖了真实性、鲁棒性、安全性、公平性和隐私五个信任度维度；多模态风险和跨模态影响两种新型风险类型；以及数据、模型架构、训练和推理算法等多种缓解策略。MultiTrust-X包含32项任务和28个精选数据集，用于评估30多个开源和专有MLLMs，并深入分析了8种代表性缓解方法。此外，基于实验洞察，提出了一种推理增强型安全对齐（RESA）方法。

Result: 实验揭示了当前模型存在显著漏洞，包括信任度与通用能力之间的差距，以及多模态训练和推理对基础LLM潜在风险的放大作用。受控分析表明，现有缓解策略存在关键局限性，很少能有效解决整体信任度问题，并且许多策略会引入意想不到的权衡，损害模型实用性。基于这些发现，提出的RESA方法通过赋予模型链式思维推理能力来发现潜在风险，取得了最先进的结果。

Conclusion: 当前MLLMs在信任度方面存在严重漏洞，多模态特性会放大风险。现有缓解策略效果有限且常带来权衡。推理能力对于平衡安全性和性能至关重要，基于此，RESA方法为提升MLLMs的信任度提供了一条有前景的路径。

Abstract: The trustworthiness of Multimodal Large Language Models (MLLMs) remains an
intense concern despite the significant progress in their capabilities.
Existing evaluation and mitigation approaches often focus on narrow aspects and
overlook risks introduced by the multimodality. To tackle these challenges, we
propose MultiTrust-X, a comprehensive benchmark for evaluating, analyzing, and
mitigating the trustworthiness issues of MLLMs. We define a three-dimensional
framework, encompassing five trustworthiness aspects which include
truthfulness, robustness, safety, fairness, and privacy; two novel risk types
covering multimodal risks and cross-modal impacts; and various mitigation
strategies from the perspectives of data, model architecture, training, and
inference algorithms. Based on the taxonomy, MultiTrust-X includes 32 tasks and
28 curated datasets, enabling holistic evaluations over 30 open-source and
proprietary MLLMs and in-depth analysis with 8 representative mitigation
methods. Our extensive experiments reveal significant vulnerabilities in
current models, including a gap between trustworthiness and general
capabilities, as well as the amplification of potential risks in base LLMs by
both multimodal training and inference. Moreover, our controlled analysis
uncovers key limitations in existing mitigation strategies that, while some
methods yield improvements in specific aspects, few effectively address overall
trustworthiness, and many introduce unexpected trade-offs that compromise model
utility. These findings also provide practical insights for future
improvements, such as the benefits of reasoning to better balance safety and
performance. Based on these insights, we introduce a Reasoning-Enhanced Safety
Alignment (RESA) approach that equips the model with chain-of-thought reasoning
ability to discover the underlying risks, achieving state-of-the-art results.

</details>


### [132] [Confidence-Modulated Speculative Decoding for Large Language Models](https://arxiv.org/abs/2508.15371)
*Jaydip Sen,Subhasis Dasgupta,Hetvi Waghela*

Main category: cs.CL

TL;DR: 本文提出了一种基于置信度调制的推测解码信息论框架，通过动态调整草稿长度和验证过程来提高自回归推理的速度和鲁棒性，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法依赖静态草稿长度和刚性验证标准，限制了它们在不同模型不确定性和输入复杂性下的适应性。

Method: 提出了一种基于置信度调制的推测解码信息论框架。该方法利用草稿器输出分布上的熵和基于裕度的不确定性度量，动态调整每次迭代中推测生成的令牌数量。此外，验证过程也通过相同的置信度信号进行调制，允许更灵活地接受草稿令牌。

Result: 在机器翻译和摘要任务中，该方法比标准推测解码实现了显著加速，同时保持或提高了BLEU和ROUGE分数。

Conclusion: 该方法提供了一种原则性的、可插拔的方法，用于在不同不确定性条件下对大型语言模型进行高效且鲁棒的解码。

Abstract: Speculative decoding has emerged as an effective approach for accelerating
autoregressive inference by parallelizing token generation through a
draft-then-verify paradigm. However, existing methods rely on static drafting
lengths and rigid verification criteria, limiting their adaptability across
varying model uncertainties and input complexities. This paper proposes an
information-theoretic framework for speculative decoding based on
confidence-modulated drafting. By leveraging entropy and margin-based
uncertainty measures over the drafter's output distribution, the proposed
method dynamically adjusts the number of speculatively generated tokens at each
iteration. This adaptive mechanism reduces rollback frequency, improves
resource utilization, and maintains output fidelity. Additionally, the
verification process is modulated using the same confidence signals, enabling
more flexible acceptance of drafted tokens without sacrificing generation
quality. Experiments on machine translation and summarization tasks demonstrate
significant speedups over standard speculative decoding while preserving or
improving BLEU and ROUGE scores. The proposed approach offers a principled,
plug-in method for efficient and robust decoding in large language models under
varying conditions of uncertainty.

</details>


### [133] [Exploiting Vocabulary Frequency Imbalance in Language Model Pre-training](https://arxiv.org/abs/2508.15390)
*Woojin Chung,Jeonghoon Kim*

Main category: cs.CL

TL;DR: 研究发现，更大的词汇表通过降低分词文本的复杂性来帮助大型语言模型，这种益处主要集中在常见词上，模型利用了词元频率的不平衡性，而非受其困扰。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型倾向于使用更大的词汇表，但这种做法的益处及其背后的机制尚不明确，尤其是在词元分布高度不平衡的情况下。

Method: 进行了一项对照研究，在保持数据、计算和优化不变的情况下，将语言模型的词汇表从2.4万扩展到19.6万。通过柯尔莫哥洛夫复杂度量化了分词文本的复杂性。进行了词级别损失分解。通过限制输入和输出嵌入范数来评估词元频率不平衡的影响。

Result: 更大的词汇表降低了分词文本的复杂性。超过2.4万后，常见词已是单个词元，词汇量增加主要加剧了相对词元频率的不平衡。词汇量越大，交叉熵损失几乎完全通过降低2500个最常见词的不确定性而减少，尽管稀有词上的损失有所增加。限制嵌入范数会消除这种收益，表明模型利用而非受困于不平衡。这种训练优势在下游基准测试中得以保留，因为常见词覆盖了约77%的词元。增加模型参数但固定词汇量也能带来相同的常见词益处。

Conclusion: “更大的词汇表有帮助”可以重新理解为“降低分词文本的复杂性有帮助”。这为词元器-模型协同设计提供了一个简单、有原则的杠杆，并阐明了预训练中语言模型扩展的损失动态。

Abstract: Large language models are trained with tokenizers, and the resulting token
distribution is highly imbalanced: a few words dominate the stream while most
occur rarely. Recent practice favors ever-larger vocabularies, but the source
of the benefit is unclear. We conduct a controlled study that scales the
language model's vocabulary from 24K to 196K while holding data, compute, and
optimization fixed. We first quantify the complexity of tokenized text,
formalized via Kolmogorov complexity, and show that larger vocabularies reduce
this complexity. Above 24K, every common word is already a single token, so
further growth mainly deepens the relative token-frequency imbalance. A
word-level loss decomposition shows that larger vocabularies reduce
cross-entropy almost exclusively by lowering uncertainty on the 2,500 most
frequent words, even though loss on the rare tail rises. Constraining input and
output embedding norms to attenuate the effect of token-frequency imbalance
reverses the gain, directly showing that the model exploits rather than suffers
from imbalance. Because the same frequent words cover roughly 77% of tokens in
downstream benchmarks, this training advantage transfers intact. We also show
that enlarging model parameters with a fixed vocabulary yields the same
frequent-word benefit. Our results reframe "bigger vocabularies help" as
"lowering the complexity of tokenized text helps," providing a simple,
principled lever for tokenizer-model co-design and clarifying the loss dynamics
that govern language-model scaling in pre-training.

</details>


### [134] [Attribution, Citation, and Quotation: A Survey of Evidence-based Text Generation with Large Language Models](https://arxiv.org/abs/2508.15396)
*Tobias Schreieder,Tim Schopf,Michael Färber*

Main category: cs.CL

TL;DR: 本文系统分析了134篇关于基于证据的大型语言模型（LLMs）文本生成论文，旨在统一术语、评估方法和基准，并提出了一个统一的分类法，分析了评估指标，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的广泛应用，对其可靠性和可信度日益担忧。现有研究领域碎片化，存在术语不一致、评估实践孤立以及缺乏统一基准的问题，阻碍了该领域的发展。

Method: 研究方法包括：系统分析134篇相关论文，引入基于证据的LLMs文本生成的统一分类法，调查300个评估指标（跨七个关键维度），并重点关注使用引用、归因或引述的方法。在此基础上，审查了该领域的独特特征和代表性方法。

Result: 研究结果包括：提出了一个基于证据的LLMs文本生成的统一分类法；对300个评估指标进行了多维度分析；识别并总结了该领域的独特特征和代表性方法；指出了开放性挑战并概述了未来工作的有前景方向。

Conclusion: 本文通过对现有文献的系统分析，弥合了基于证据的LLMs文本生成领域的空白，提供了一个统一的视角和分类法，并为未来的研究指明了方向。

Abstract: The increasing adoption of large language models (LLMs) has been accompanied
by growing concerns regarding their reliability and trustworthiness. As a
result, a growing body of research focuses on evidence-based text generation
with LLMs, aiming to link model outputs to supporting evidence to ensure
traceability and verifiability. However, the field is fragmented due to
inconsistent terminology, isolated evaluation practices, and a lack of unified
benchmarks. To bridge this gap, we systematically analyze 134 papers, introduce
a unified taxonomy of evidence-based text generation with LLMs, and investigate
300 evaluation metrics across seven key dimensions. Thereby, we focus on
approaches that use citations, attribution, or quotations for evidence-based
text generation. Building on this, we examine the distinctive characteristics
and representative methods in the field. Finally, we highlight open challenges
and outline promising directions for future work.

</details>


### [135] [When Audio and Text Disagree: Revealing Text Bias in Large Audio-Language Models](https://arxiv.org/abs/2508.15407)
*Cheng Wang,Gelei Deng,Xianglin Yang,Han Qiu,Tianwei Zhang*

Main category: cs.CL

TL;DR: 研究发现，大型音视频语言模型（LALMs）在处理音频和文本冲突信息时，存在显著的文本偏见，倾向于忽略音频证据，导致音频任务性能下降，并伴随过度自信。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能充分考察LALMs在处理音频和文本模态之间冲突信息时的表现，这引发了对LALMs在多模态输入场景下信息优先级处理能力的疑问。

Method: 引入了MCR-BENCH，这是首个专门评估LALMs在面对不一致音视频对时如何处理信息的综合基准。通过在各种音频理解任务上进行广泛评估，并进一步调查文本偏见的影响因素，探索了监督微调的缓解策略，并分析了模型置信度模式。

Result: LALMs在模态不一致时表现出显著的文本偏见，频繁忽略音频证据，导致音频中心任务的性能大幅下降，并引发了可靠性担忧。即使在输入矛盾的情况下，模型也表现出持续的过度自信。

Conclusion: 研究结果强调了在训练过程中需要改进模态平衡和更复杂的融合机制，以增强LALMs在处理冲突多模态输入时的鲁棒性。

Abstract: Large Audio-Language Models (LALMs) are enhanced with audio perception
capabilities, enabling them to effectively process and understand multimodal
inputs that combine audio and text. However, their performance in handling
conflicting information between audio and text modalities remains largely
unexamined. This paper introduces MCR-BENCH, the first comprehensive benchmark
specifically designed to evaluate how LALMs prioritize information when
presented with inconsistent audio-text pairs. Through extensive evaluation
across diverse audio understanding tasks, we reveal a concerning phenomenon:
when inconsistencies exist between modalities, LALMs display a significant bias
toward textual input, frequently disregarding audio evidence. This tendency
leads to substantial performance degradation in audio-centric tasks and raises
important reliability concerns for real-world applications. We further
investigate the influencing factors of text bias, and explore mitigation
strategies through supervised finetuning, and analyze model confidence patterns
that reveal persistent overconfidence even with contradictory inputs. These
findings underscore the need for improved modality balance during training and
more sophisticated fusion mechanisms to enhance the robustness when handling
conflicting multi-modal inputs. The project is available at
https://github.com/WangCheng0116/MCR-BENCH.

</details>


### [136] [LLaSO: A Foundational Framework for Reproducible Research in Large Language and Speech Model](https://arxiv.org/abs/2508.15418)
*Yirong Sun,Yizhong Geng,Peidong Wei,Yanjun Chen,Jinghan Yang,Rongfei Chen,Wei Zhang,Xiaoyu Shen*

Main category: cs.CL

TL;DR: LLaSO是一个用于大型语音语言模型（LSLM）的端到端开放框架，提供了对齐语料库、指令微调数据集、可复现基准测试，并发布了基于公共数据训练的参考模型LLaSO-Base，旨在解决LSLM领域碎片化和透明度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语音语言模型（LSLM）的开发受到架构碎片化和透明度不足的阻碍，导致研究难以系统比较和复现。与视觉-语言领域不同，LSLM领域普遍存在发布模型权重却不提供相应训练数据和配置的做法。

Method: 本文介绍了LLaSO，第一个完全开放的端到端大型语音语言建模框架。LLaSO提供了三个核心资源：(1) LLaSO-Align，一个包含1200万实例的语音-文本对齐语料库；(2) LLaSO-Instruct，一个包含1350万实例的多任务指令微调数据集；(3) LLaSO-Eval，一个用于标准化评估的可复现基准测试。为验证该框架，作者构建并发布了LLaSO-Base，一个38亿参数的参考模型，完全使用公共数据进行训练。

Result: LLaSO-Base模型在标准化评估中取得了0.72的归一化分数，建立了一个强大且可复现的基线，并超越了同类模型。分析表明，更广泛的训练覆盖能提升性能，但在未见任务上，尤其是在纯音频场景中，仍然存在显著的泛化差距。

Conclusion: 通过发布完整的数据、基准测试和模型堆栈，LLaSO建立了一个基础性的开放标准，旨在统一研究工作并加速LSLM领域的社区驱动进展。

Abstract: The development of Large Speech-Language Models (LSLMs) has been slowed by
fragmented architectures and a lack of transparency, hindering the systematic
comparison and reproducibility of research. Unlike in the vision-language
domain, the LSLM field suffers from the common practice of releasing model
weights without their corresponding training data and configurations. To
address these critical gaps, we introduce LLaSO, the first fully open,
end-to-end framework for large-scale speech-language modeling. LLaSO provides
the community with three essential resources: (1) LLaSO-Align, a 12M-instance
speech-text alignment corpus; (2) LLaSO-Instruct, a 13.5M-instance multi-task
instruction-tuning dataset; and (3) LLaSO-Eval, a reproducible benchmark for
standardized evaluation. To validate our framework, we build and release
LLaSO-Base, a 3.8B-parameter reference model trained exclusively on our public
data. It achieves a normalized score of 0.72, establishing a strong,
reproducible baseline that surpasses comparable models. Our analysis reveals
that while broader training coverage enhances performance, significant
generalization gaps persist on unseen tasks, particularly in pure audio
scenarios. By releasing the complete stack of data, benchmarks, and models,
LLaSO establishes a foundational open standard to unify research efforts and
accelerate community-driven progress in LSLMs. We release the code, dataset,
pretrained models, and results in https://github.com/EIT-NLP/LLaSO.

</details>


### [137] [A Study of Privacy-preserving Language Modeling Approaches](https://arxiv.org/abs/2508.15421)
*Pritilata Saha,Abhirup Sinha*

Main category: cs.CL

TL;DR: 该研究全面概述了保护语言模型隐私的方法，探讨了它们的优势和局限性，并为未来研究指明了方向。


<details>
  <summary>Details</summary>
Motivation: 语言模型因其在敏感数据上的训练可能在隐私攻击中泄露信息，引发了对个人隐私保护的担忧。尽管隐私保护至关重要，但对语言模型的隐私风险及其缓解方法的理解仍然有限。

Method: 该研究通过对保护隐私的语言模型方法进行全面研究，深入概述了这些方法，并强调了它们的优势和局限性。

Result: 该研究的成果为隐私保护语言模型领域的持续研究做出了贡献，提供了宝贵的见解，并勾勒了未来的研究方向。

Conclusion: 研究结果为隐私保护语言模型提供了深入理解和宝贵见解，并为未来研究指明了方向，以应对语言模型中的隐私挑战。

Abstract: Recent developments in language modeling have increased their use in various
applications and domains. Language models, often trained on sensitive data, can
memorize and disclose this information during privacy attacks, raising concerns
about protecting individuals' privacy rights. Preserving privacy in language
models has become a crucial area of research, as privacy is one of the
fundamental human rights. Despite its significance, understanding of how much
privacy risk these language models possess and how it can be mitigated is still
limited. This research addresses this by providing a comprehensive study of the
privacy-preserving language modeling approaches. This study gives an in-depth
overview of these approaches, highlights their strengths, and investigates
their limitations. The outcomes of this study contribute to the ongoing
research on privacy-preserving language modeling, providing valuable insights
and outlining future research directions.

</details>


### [138] [M-HELP: Using Social Media Data to Detect Mental Health Help-Seeking Signals](https://arxiv.org/abs/2508.15440)
*MSVPJ Sathvik,Zuhair Hasan Shaik,Vivek Gupta*

Main category: cs.CL

TL;DR: 该论文引入了M-Help数据集，旨在从社交媒体上识别精神健康求助行为、诊断具体疾病并揭示其根本原因。


<details>
  <summary>Details</summary>
Motivation: 精神健康障碍是一场全球危机，现有数据集在检测精神障碍方面存在，但在识别主动寻求帮助的个体方面存在关键空白。

Method: 引入了一个名为M-Help的新型数据集，该数据集专门用于检测社交媒体上的求助行为，并超越传统标签，识别具体的精神健康障碍及其潜在原因（如人际关系挑战或经济压力）。

Result: 在M-Help上训练的AI模型可以解决三个关键任务：识别求助者、诊断精神健康状况以及揭示问题的根本原因。

Conclusion: M-Help数据集能够让AI模型识别寻求帮助的个体，诊断精神健康状况，并揭示其根本原因，填补了现有研究在主动求助行为识别方面的空白。

Abstract: Mental health disorders are a global crisis. While various datasets exist for
detecting such disorders, there remains a critical gap in identifying
individuals actively seeking help. This paper introduces a novel dataset,
M-Help, specifically designed to detect help-seeking behavior on social media.
The dataset goes beyond traditional labels by identifying not only help-seeking
activity but also specific mental health disorders and their underlying causes,
such as relationship challenges or financial stressors. AI models trained on
M-Help can address three key tasks: identifying help-seekers, diagnosing mental
health conditions, and uncovering the root causes of issues.

</details>


### [139] [Principle Methods of Rendering Non-equivalent Words from Uzbek and Dari to Russian and English](https://arxiv.org/abs/2508.15453)
*Mohammad Ibrahim Qani*

Main category: cs.CL

TL;DR: 本研究旨在探讨并提供专业地将源语言中的非对等词翻译到目标语言的方法和规则。


<details>
  <summary>Details</summary>
Motivation: 翻译中常因食物、服装、文化和传统等领域的非对等词导致误解，这些词在目标语言中往往没有直接对应，需要专门处理以实现充分理解。

Method: 本研究采用基于图书馆的文献研究方法完成。

Result: 研究提出了将非对等词从源语言翻译到目标语言的不同方法和规则，并实际将25个达里语和乌兹别克语的非对等词翻译成了英语和俄语。

Conclusion: 本研究提供了专业处理非对等词的有效方法和规则，强调了尽管部分非对等词已被处理，但仍有大量此类词汇需要进一步研究和翻译。

Abstract: These pure languages understanding directly relates to translation knowledge
where linguists and translators need to work and research to eradicate
misunderstanding. Misunderstandings mostly appear in non-equivalent words
because there are different local and internal words like food, garment,
cultural and traditional words and others in every notion. Truly, most of these
words do not have equivalent in the target language and these words need to be
worked and find their equivalent in the target language to fully understand the
both languages. The purpose of this research is to introduce the methods of
rendering non-equivalent words professionally from the source language to the
target language and this research has been completed using library-based
research. However, some of these non-equivalent words are already
professionally rendered to the target language but still there many other words
to be rendered. As a result, this research paper includes different ways and
rules of rendering non-equivalent words from source language to the target
language and 25 non-equvalent words have been rendered from Dar & Uzbek into
English and Russian languages.

</details>


### [140] [PyTOD: Programmable Task-Oriented Dialogue with Execution Feedback](https://arxiv.org/abs/2508.15456)
*Alexandru Coca,Bo-Hsiang Tseng,Pete Boothroyd,Jianpeng Cheng,Mark Gaynor,Zhenxing Zhang,Joe Stacey,Tristan Guigue,Héctor Martinez Alonso,Diarmuid Ó Séaghdha,Anders Johannsen*

Main category: cs.CL

TL;DR: PyTOD是一种通过生成可执行代码来追踪对话状态的对话代理，利用策略和执行反馈进行错误纠正，并在SGD基准测试上实现了最先进的状态追踪性能。


<details>
  <summary>Details</summary>
Motivation: 可编程面向任务对话（TOD）代理的有效性取决于准确的状态追踪，但这一过程具有挑战性。

Method: PyTOD通过生成可执行代码来追踪对话状态，并利用策略和执行反馈进行高效的错误纠正。它采用了一种简单的约束解码方法，使用语言模型而非语法规则来遵循API模式。

Result: PyTOD在具有挑战性的SGD基准测试上实现了最先进的状态追踪性能。实验表明，随着对话的进行，PyTOD在准确性和鲁棒的用户目标估计方面均超越了强大的基线模型。

Conclusion: 执行感知型状态追踪是有效的，PyTOD证明了其在对话状态追踪中的优越性。

Abstract: Programmable task-oriented dialogue (TOD) agents enable language models to
follow structured dialogue policies, but their effectiveness hinges on accurate
state tracking. We present PyTOD, an agent that generates executable code to
track dialogue state and uses policy and execution feedback for efficient error
correction. To this end, PyTOD employs a simple constrained decoding approach,
using a language model instead of grammar rules to follow API schemata. This
leads to state-of-the-art state tracking performance on the challenging SGD
benchmark. Our experiments show that PyTOD surpasses strong baselines in both
accuracy and robust user goal estimation as the dialogue progresses,
demonstrating the effectiveness of execution-aware state tracking.

</details>


### [141] [RadReason: Radiology Report Evaluation Metric with Reasons and Sub-Scores](https://arxiv.org/abs/2508.15464)
*Yingshu Li,Yunyi Liu,Lingqiao Liu,Lei Wang,Luping Zhou*

Main category: cs.CL

TL;DR: RadReason是一个新颖的放射学报告评估框架，它提供细粒度的临床错误类型子分数和人类可读的理由，解决了现有评估方法缺乏临床依据和可解释性的问题。


<details>
  <summary>Details</summary>
Motivation: 自动生成的放射学报告评估面临根本性挑战，因为缺乏基于临床、可解释和细粒度的指标。现有方法要么产生粗略的总体分数，要么依赖不透明的黑盒模型，限制了它们在真实临床工作流程中的实用性。

Method: RadReason框架基于Group Relative Policy Optimization，并包含两项关键创新：(1) 子分数动态加权（Sub-score Dynamic Weighting），根据实时F1统计数据自适应地优先处理临床上具有挑战性的错误类型；(2) 多数引导优势缩放（Majority-Guided Advantage Scaling），根据子分数一致性得出的提示难度调整策略梯度更新。这些组件共同实现了更稳定的优化和更好地与专家临床判断对齐。

Result: 在ReXVal基准测试上的实验表明，RadReason超越了所有先前的离线指标，并达到了与基于GPT-4的评估相当的水平，同时保持了可解释性、成本效益，并适用于临床部署。

Conclusion: RadReason提供了一种有效、可解释且成本高效的放射学报告评估方法，其细粒度的分数和理由使其非常适合临床部署，并有望改进放射学报告的自动生成和评估。

Abstract: Evaluating automatically generated radiology reports remains a fundamental
challenge due to the lack of clinically grounded, interpretable, and
fine-grained metrics. Existing methods either produce coarse overall scores or
rely on opaque black-box models, limiting their usefulness in real-world
clinical workflows. We introduce RadReason, a novel evaluation framework for
radiology reports that not only outputs fine-grained sub-scores across six
clinically defined error types, but also produces human-readable justifications
that explain the rationale behind each score. Our method builds on Group
Relative Policy Optimization and incorporates two key innovations: (1)
Sub-score Dynamic Weighting, which adaptively prioritizes clinically
challenging error types based on live F1 statistics; and (2) Majority-Guided
Advantage Scaling, which adjusts policy gradient updates based on prompt
difficulty derived from sub-score agreement. Together, these components enable
more stable optimization and better alignment with expert clinical judgment.
Experiments on the ReXVal benchmark show that RadReason surpasses all prior
offline metrics and achieves parity with GPT-4-based evaluations, while
remaining explainable, cost-efficient, and suitable for clinical deployment.
Code will be released upon publication.

</details>


### [142] [SLM4Offer: Personalized Marketing Offer Generation Using Contrastive Learning Based Fine-Tuning](https://arxiv.org/abs/2508.15471)
*Vedasamhitha Challapalli,Konduru Venkat Sai,Piyush Pratap Singh,Rupesh Prasad,Arvind Maurya,Atul Singh*

Main category: cs.CL

TL;DR: 本文提出SLM4Offer，一个基于T5-Small并结合对比学习（InfoNCE损失）的生成式AI模型，用于个性化优惠生成，旨在通过将客户画像与优惠对齐，提高优惠接受率。


<details>
  <summary>Details</summary>
Motivation: 个性化营销对提升客户参与度和业务增长至关重要。现有研究主要集中在推荐系统和个性化广告，而个性化优惠生成在提高转化率和客户满意度方面潜力巨大（可提升收入高达40%）。因此，需要开发智能、数据驱动的方法来生成优惠。

Method: 本文引入SLM4Offer模型，通过使用对比学习方法（InfoNCE损失）微调预训练的编码器-解码器语言模型（Google的T5-Small 60M）来生成个性化优惠。InfoNCE损失用于在共享嵌入空间中对齐客户画像与相关优惠。SLM4Offer的关键创新在于对比损失引入的自适应学习行为，其在训练期间重塑潜在空间并增强模型泛化能力。模型在一个模拟客户行为和优惠接受模式的合成数据集上进行微调和评估。

Result: 实验结果表明，SLM4Offer在优惠接受率方面比监督微调基线提高了17%。

Conclusion: 对比目标在推进个性化营销中表现出显著效果，尤其在个性化优惠生成方面，能有效提高优惠接受率。

Abstract: Personalized marketing has emerged as a pivotal strategy for enhancing
customer engagement and driving business growth. Academic and industry efforts
have predominantly focused on recommendation systems and personalized
advertisements. Nonetheless, this facet of personalization holds significant
potential for increasing conversion rates and improving customer satisfaction.
Prior studies suggest that well-executed personalization strategies can boost
revenue by up to 40 percent, underscoring the strategic importance of
developing intelligent, data-driven approaches for offer generation. This work
introduces SLM4Offer, a generative AI model for personalized offer generation,
developed by fine-tuning a pre-trained encoder-decoder language model,
specifically Google's Text-to-Text Transfer Transformer (T5-Small 60M) using a
contrastive learning approach. SLM4Offer employs InfoNCE (Information
Noise-Contrastive Estimation) loss to align customer personas with relevant
offers in a shared embedding space. A key innovation in SLM4Offer lies in the
adaptive learning behaviour introduced by contrastive loss, which reshapes the
latent space during training and enhances the model's generalizability. The
model is fine-tuned and evaluated on a synthetic dataset designed to simulate
customer behaviour and offer acceptance patterns. Experimental results
demonstrate a 17 percent improvement in offer acceptance rate over a supervised
fine-tuning baseline, highlighting the effectiveness of contrastive objectives
in advancing personalized marketing.

</details>


### [143] [Subjective Behaviors and Preferences in LLM: Language of Browsing](https://arxiv.org/abs/2508.15474)
*Sai Sundaresan,Harshita Chopra,Atanu R. Sinha,Koustava Goswami,Nagasai Saketh Naidu,Raghav Karan,N Anushka*

Main category: cs.CL

TL;DR: 本文质疑大型语言模型（LLM）在处理用户主观行为（如浏览习惯）时的普适性。研究提出了一种名为HeTLM的聚类式语言模型训练方法，发现使用页面级分词器训练的小型LM以及具有异构聚类特定参数的HeTLM，在捕捉用户主观行为方面优于大型单一LM，并能实现更好的用户级别对齐。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）被认为在多领域和多任务中具有通用性并能满足用户多样化的行为和偏好，但当用户行为和偏好具有固有的主观性和异质性（例如，用户浏览网站或应用程序的独特习惯）时，这种看法受到了质疑。用户的顺序浏览日志形成了类似“浏览语言”的数据，但缺乏自然语言的结构。因此，研究旨在探讨：(i) 小型LM能否比大型LM更好地表示“浏览语言”？(ii) 具有单一参数集的LM能否充分捕捉大量用户异构、主观的行为和偏好？(iii) 具有高平均性能的单一LM能否产生低性能方差，从而在用户层面实现良好的对齐？

Method: 研究引入了适用于主观行为的“聚类式LM训练”方法，命名为HeTLM（异质性感知语言模型训练）。具体方法包括：(i) 使用页面级分词器训练小型语言模型；(ii) 将HeTLM与具有异构聚类特定参数的单一LM进行比较，同时控制参数数量。

Result: (i) 使用页面级分词器训练的小型LM优于大型预训练或微调的LM；(ii) 具有异构聚类特定参数的HeTLM优于相同家族的单一LM（在控制参数数量的情况下）；(iii) 结果显示生成性能的平均值更高，方差更低，这意味着对齐效果有所改善。

Conclusion: 对于用户主观行为（如浏览），专门的小型LM（通过页面级分词器训练）以及能够感知异质性的聚类式LM（HeTLM）比通用的单一大型LM表现更优。HeTLM通过实现更高的平均性能和更低的性能方差，显著改善了用户级别的对齐效果。

Abstract: A Large Language Model (LLM) offers versatility across domains and tasks,
purportedly benefiting users with a wide variety of behaviors and preferences.
We question this perception about an LLM when users have inherently subjective
behaviors and preferences, as seen in their ubiquitous and idiosyncratic
browsing of websites or apps. The sequential behavior logs of pages, thus
generated, form something akin to each user's self-constructed "language",
albeit without the structure and grammar imbued in natural languages. We ask:
(i) Can a small LM represent the "language of browsing" better than a large LM?
(ii) Can an LM with a single set of parameters (or, single LM) adequately
capture myriad users' heterogeneous, subjective behaviors and preferences?
(iii) Can a single LM with high average performance, yield low variance in
performance to make alignment good at user level? We introduce clusterwise LM
training, HeTLM (Heterogeneity aware Training of Language Model), appropriate
for subjective behaviors. We find that (i) a small LM trained using a
page-level tokenizer outperforms large pretrained or finetuned LMs; (ii) HeTLM
with heterogeneous cluster specific set of parameters outperforms a single LM
of the same family, controlling for the number of parameters; and (iii) a
higher mean and a lower variance in generation ensues, implying improved
alignment.

</details>


### [144] [Influence-driven Curriculum Learning for Pre-training on Limited Data](https://arxiv.org/abs/2508.15475)
*Loris Schoenegger,Lukas Thoma,Terra Blevins,Benjamin Roth*

Main category: cs.CL

TL;DR: 传统课程学习在语言模型预训练中效果有限。本文提出使用“训练数据影响力”作为模型中心化难度指标，显著提升了课程学习在语言模型预训练中的表现。


<details>
  <summary>Details</summary>
Motivation: 课程学习（按难度排序数据）在语言模型预训练中，使用传统的人工定义难度指标时效果不佳。研究旨在探讨若采用更贴近模型训练实际观察到的难度指标，课程学习是否能变得有竞争力。

Method: 研究通过将训练样本按其“训练数据影响力”（一个评估单个训练样本对模型输出影响的得分）进行排序来构建课程。然后，将采用这种课程训练的模型与随机顺序训练的模型进行比较。

Result: 使用所提出的课程（基于训练数据影响力）训练的模型在基准测试中，表现优于随机顺序训练的模型超过10个百分点。

Conclusion: 课程学习对语言模型预训练是有益的，前提是采用更以模型为中心的难度概念（如训练数据影响力）。

Abstract: Curriculum learning, a training technique where data is presented to the
model in order of example difficulty (e.g., from simpler to more complex
documents), has shown limited success for pre-training language models. In this
work, we investigate whether curriculum learning becomes competitive if we
replace conventional human-centered difficulty metrics with one that more
closely corresponds to example difficulty as observed during model training.
Specifically, we experiment with sorting training examples by their
\textit{training data influence}, a score which estimates the effect of
individual training examples on the model's output. Models trained on our
curricula are able to outperform ones trained in random order by over 10
percentage points in benchmarks, confirming that curriculum learning is
beneficial for language model pre-training, as long as a more model-centric
notion of difficulty is adopted.

</details>


### [145] [SLM-Bench: A Comprehensive Benchmark of Small Language Models on Environmental Impacts -- Extended Version](https://arxiv.org/abs/2508.15478)
*Nghiem Thanh Pham,Tung Kieu,Duc-Manh Nguyen,Son Ha Xuan,Nghia Duong-Trung,Danh Le-Phuoc*

Main category: cs.CL

TL;DR: SLM-Bench是首个专门评估小型语言模型（SLMs）的基准，它系统地衡量了15个SLMs在9项NLP任务、23个数据集和4种硬件配置下的准确性、计算效率和可持续性，揭示了效率权衡。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLMs）在计算效率和可访问性方面具有优势，但目前缺乏对其性能和环境影响的系统性评估。

Method: 引入了SLM-Bench基准，评估了15个SLMs在9项NLP任务（使用14个领域23个数据集）上的表现。评估在4种硬件配置下进行，量化了正确性、计算和消耗方面的11项指标，并开发了一个开源的、标准化的评估流程。

Result: 研究发现SLMs之间存在多样化的权衡，一些模型在准确性上表现出色，而另一些则在能源效率上更优。

Conclusion: SLM-Bench为SLM评估设定了新标准，弥合了资源效率与实际应用之间的差距。

Abstract: Small Language Models (SLMs) offer computational efficiency and
accessibility, yet a systematic evaluation of their performance and
environmental impact remains lacking. We introduce SLM-Bench, the first
benchmark specifically designed to assess SLMs across multiple dimensions,
including accuracy, computational efficiency, and sustainability metrics.
SLM-Bench evaluates 15 SLMs on 9 NLP tasks using 23 datasets spanning 14
domains. The evaluation is conducted on 4 hardware configurations, providing a
rigorous comparison of their effectiveness. Unlike prior benchmarks, SLM-Bench
quantifies 11 metrics across correctness, computation, and consumption,
enabling a holistic assessment of efficiency trade-offs. Our evaluation
considers controlled hardware conditions, ensuring fair comparisons across
models. We develop an open-source benchmarking pipeline with standardized
evaluation protocols to facilitate reproducibility and further research. Our
findings highlight the diverse trade-offs among SLMs, where some models excel
in accuracy while others achieve superior energy efficiency. SLM-Bench sets a
new standard for SLM evaluation, bridging the gap between resource efficiency
and real-world applicability.

</details>


### [146] [HebID: Detecting Social Identities in Hebrew-language Political Text](https://arxiv.org/abs/2508.15483)
*Guy Mor-Lan,Naama Rivlin-Angert,Yael R. Kaplan,Tamir Sheafer,Shaul R. Shenhav*

Main category: cs.CL

TL;DR: 本文介绍了HebID，一个用于希伯来语社会身份识别的多标签语料库，并使用LLMs对其进行基准测试，分析了以色列政治话语中的身份表达，填补了非英语、细致多标签身份检测的空白。


<details>
  <summary>Details</summary>
Motivation: 政治语言与社会身份紧密交织，但现有身份检测数据集主要以英语为中心、单标签且类别粗糙。文化背景对身份和语言使用影响深远，因此需要一个能捕捉细微差别的非英语、多标签社会身份数据集。

Method: 研究引入了HebID，一个包含5,536条来自以色列政治家Facebook帖子的希伯来语语料库（2018年12月-2021年4月），并根据调查数据手动标注了12种细致的社会身份。研究对多标签和单标签编码器以及参数量从2B到9B的生成式LLMs进行了基准测试。随后，将分类器应用于政治家的Facebook帖子和议会演讲，评估了身份表达在受欢迎程度、时间趋势、聚类模式和性别相关差异。此外，还利用全国公众调查中的身份选择，比较了精英话语中描绘的身份与公众的身份优先级。

Result: 研究发现，经过希伯来语调整的LLMs提供了最佳结果（macro-$F_1$ = 0.74）。通过应用分类器，评估了政治家Facebook帖子和议会演讲中身份表达的受欢迎程度、时间趋势、聚类模式和性别相关差异。同时，实现了精英话语与公众身份优先级之间的比较。

Conclusion: HebID为研究希伯来语中的社会身份提供了一个全面的基础，并可以作为其他非英语政治背景下类似研究的模型。

Abstract: Political language is deeply intertwined with social identities. While social
identities are often shaped by specific cultural contexts and expressed through
particular uses of language, existing datasets for group and identity detection
are predominantly English-centric, single-label and focus on coarse identity
categories. We introduce HebID, the first multilabel Hebrew corpus for social
identity detection: 5,536 sentences from Israeli politicians' Facebook posts
(Dec 2018-Apr 2021), manually annotated for twelve nuanced social identities
(e.g. Rightist, Ultra-Orthodox, Socially-oriented) grounded by survey data. We
benchmark multilabel and single-label encoders alongside 2B-9B-parameter
generative LLMs, finding that Hebrew-tuned LLMs provide the best results
(macro-$F_1$ = 0.74). We apply our classifier to politicians' Facebook posts
and parliamentary speeches, evaluating differences in popularity, temporal
trends, clustering patterns, and gender-related variations in identity
expression. We utilize identity choices from a national public survey, enabling
a comparison between identities portrayed in elite discourse and the public's
identity priorities. HebID provides a comprehensive foundation for studying
social identities in Hebrew and can serve as a model for similar research in
other non-English political contexts.

</details>


### [147] [Trained Miniatures: Low cost, High Efficacy SLMs for Sales & Marketing](https://arxiv.org/abs/2508.15617)
*Ishaan Bhola,Mukunda NS,Sravanth Kurmala,Harsh Nandwani,Arihant Jain*

Main category: cs.CL

TL;DR: 本文提出“训练微型模型”（Trained Miniatures）概念，即针对特定高价值应用进行微调的小型语言模型（SLMs），旨在以更低的成本生成与大型语言模型（LLMs）相似的领域特定响应。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在文本生成方面表现出色，但计算量大且成本高昂，对于销售和营销等特定应用而言，其成本难以承受。

Method: 引入“训练微型模型”的概念，即对小型语言模型（SLMs）进行微调，使其专注于特定的高价值应用。

Result: 这些微型模型能够以极低的成本生成相似的领域特定响应。

Conclusion: 通过对SLMs进行微调，可以创建出成本效益高、适用于特定高价值应用的“训练微型模型”，作为LLMs的替代方案。

Abstract: Large language models (LLMs) excel in text generation; however, these
creative elements require heavy computation and are accompanied by a steep
cost. Especially for targeted applications such as sales and marketing
outreach, these costs are far from feasible. This paper introduces the concept
of "Trained Miniatures" - Small Language Models(SLMs) fine-tuned for specific,
high-value applications, generating similar domain-specific responses for a
fraction of the cost.

</details>


### [148] [Dream 7B: Diffusion Large Language Models](https://arxiv.org/abs/2508.15487)
*Jiacheng Ye,Zhihui Xie,Lin Zheng,Jiahui Gao,Zirui Wu,Xin Jiang,Zhenguo Li,Lingpeng Kong*

Main category: cs.CL

TL;DR: 本文介绍了Dream 7B，一个强大的开放扩散大语言模型，它通过迭代去噪并行生成序列，并在通用、数学和编码任务上超越现有扩散语言模型。


<details>
  <summary>Details</summary>
Motivation: 与顺序生成token的自回归模型不同，本研究旨在利用离散扩散模型实现并行序列精炼，以提升语言模型的性能和推理灵活性。

Method: Dream 7B采用离散扩散建模，通过迭代去噪并行精炼序列。其训练技术包括基于自回归（AR）LLM的初始化，以及上下文自适应的token级噪声重调度。

Result: Dream 7B是迄今为止最强大的开放扩散大语言模型。它在通用、数学和编码任务上持续优于现有扩散语言模型，并展现出卓越的规划能力和推理灵活性，包括任意顺序生成、填充能力和可调的质量-速度权衡。

Conclusion: Dream 7B通过简单而有效的训练技术，成功展示了扩散模型在语言生成领域的强大潜力，并在性能和灵活性上超越了现有模型，为扩散语言模型的研究提供了新的基础（Dream-Base和Dream-Instruct）。

Abstract: We introduce Dream 7B, the most powerful open diffusion large language model
to date. Unlike autoregressive (AR) models that generate tokens sequentially,
Dream 7B employs discrete diffusion modeling to refine sequences in parallel
through iterative denoising. Our model consistently outperforms existing
diffusion language models on general, mathematical, and coding tasks. Dream 7B
demonstrates superior planning abilities and inference flexibility, including
arbitrary-order generation, infilling capabilities, and tunable quality-speed
trade-offs. These results are achieved through simple yet effective training
techniques, including AR-based LLM initialization and context-adaptive
token-level noise rescheduling. We release both Dream-Base and Dream-Instruct
to facilitate further research in diffusion-based language modeling.

</details>


### [149] [The Enemy from Within: A Study of Political Delegitimization Discourse in Israeli Political Speech](https://arxiv.org/abs/2508.15524)
*Naama Rivlin-Angert,Guy Mor-Lan*

Main category: cs.CL

TL;DR: 本文首次对政治合法性攻击话语（PDD）进行了大规模计算研究，构建了一个新的希伯来语语料库，并开发了一个两阶段分类模型。研究发现PDD在过去三十年显著增加，在社交媒体、男性政治家和右翼群体中更为普遍，并在选举和政治事件期间达到高峰。


<details>
  <summary>Details</summary>
Motivation: 研究旨在对政治实体合法性攻击话语（PDD）进行大规模计算分析，以理解民主话语的演变和特征。此前缺乏对PDD的计算研究。

Method: 研究构建并手动标注了一个包含10,410句希伯来语文本的新语料库（来自议会演讲、Facebook帖子和新闻媒体）。其中1,812个实例被标注为PDD，642个实例包含强度、不文明程度、目标类型和情感框架的额外标注。研究引入了一个结合微调编码器模型和解码器大型语言模型的两阶段分类管道，并使用DictaLM 2.0模型进行分类。

Result: 最佳模型（DictaLM 2.0）在二元PDD检测中达到了0.74的F1分数，在合法性攻击特征分类中达到了0.67的宏观F1分数。将此分类器应用于纵向和跨平台数据，研究发现PDD在三十年中显著增加，在社交媒体上的流行程度高于议会辩论，男性政治家使用更多，右倾参与者倾向更强，并在选举活动和重大政治事件期间出现明显高峰。

Conclusion: 研究结果证明了自动化PDD分析对于理解民主话语的可行性和价值。

Abstract: We present the first large-scale computational study of political
delegitimization discourse (PDD), defined as symbolic attacks on the normative
validity of political entities. We curate and manually annotate a novel
Hebrew-language corpus of 10,410 sentences drawn from Knesset speeches
(1993-2023), Facebook posts (2018-2021), and leading news outlets, of which
1,812 instances (17.4\%) exhibit PDD and 642 carry additional annotations for
intensity, incivility, target type, and affective framing. We introduce a
two-stage classification pipeline combining finetuned encoder models and
decoder LLMs. Our best model (DictaLM 2.0) attains an F$_1$ of 0.74 for binary
PDD detection and a macro-F$_1$ of 0.67 for classification of delegitimization
characteristics. Applying this classifier to longitudinal and cross-platform
data, we see a marked rise in PDD over three decades, higher prevalence on
social media versus parliamentary debate, greater use by male than female
politicians, and stronger tendencies among right-leaning actors - with
pronounced spikes during election campaigns and major political events. Our
findings demonstrate the feasibility and value of automated PDD analysis for
understanding democratic discourse.

</details>


### [150] [Benchmarking Computer Science Survey Generation](https://arxiv.org/abs/2508.15658)
*Weihang Su,Anzhe Xie,Qingyao Ai,Jianming Long,Jiaxin Mao,Ziyi Ye,Yiqun Liu*

Main category: cs.CL

TL;DR: 本文介绍了SurGE，一个用于评估计算机科学领域科学综述生成的新基准，包含测试实例、引用参考文献和大型学术语料库，并提出了一个多维度自动化评估框架，结果显示LLM在此任务上仍面临巨大挑战。


<details>
  <summary>Details</summary>
Motivation: 由于学术文献的快速增长，人工撰写科学综述变得越来越不可行。尽管大型语言模型（LLMs）在此方面显示出潜力，但缺乏标准化基准和评估协议阻碍了该领域的进展。

Method: 本文引入了SurGE（Survey Generation Evaluation）基准，包括：1) 一组测试实例，每个实例包含主题描述、专家撰写的综述及其引用的参考文献；2) 一个包含超过一百万篇论文的大规模学术语料库作为检索池。此外，本文提出了一个自动化评估框架，从信息覆盖、引用准确性、结构组织和内容质量四个维度衡量生成的综述。

Result: 对各种基于LLM的方法（包括先进的自反思框架）的评估表明，综述生成仍然极具挑战性。

Conclusion: 这些发现突显了综述生成任务的复杂性以及持续研究的必要性。所有代码、数据和模型均已开源。

Abstract: Scientific survey articles play a vital role in summarizing research
progress, yet their manual creation is becoming increasingly infeasible due to
the rapid growth of academic literature. While large language models (LLMs)
offer promising capabilities for automating this process, progress in this area
is hindered by the absence of standardized benchmarks and evaluation protocols.
To address this gap, we introduce SurGE (Survey Generation Evaluation), a new
benchmark for evaluating scientific survey generation in the computer science
domain. SurGE consists of (1) a collection of test instances, each including a
topic description, an expert-written survey, and its full set of cited
references, and (2) a large-scale academic corpus of over one million papers
that serves as the retrieval pool. In addition, we propose an automated
evaluation framework that measures generated surveys across four dimensions:
information coverage, referencing accuracy, structural organization, and
content quality. Our evaluation of diverse LLM-based approaches shows that
survey generation remains highly challenging, even for advanced self-reflection
frameworks. These findings highlight the complexity of the task and the
necessity for continued research. We have open-sourced all the code, data, and
models at: https://github.com/oneal2000/SurGE

</details>


### [151] [SafetyFlow: An Agent-Flow System for Automated LLM Safety Benchmarking](https://arxiv.org/abs/2508.15526)
*Xiangyang Zhu,Yuan Tian,Chunyi Li,Kaiwei Zhang,Wei Sun,Guangtao Zhai*

Main category: cs.CL

TL;DR: SafetyFlow是首个代理流系统，旨在自动化构建大型语言模型（LLM）安全基准，解决了现有手动基准耗时、资源密集、冗余且难度有限的问题，并在四天内无需人工干预构建了一个包含23,446个高质量查询的基准。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的迅速普及，对其安全漏洞进行可靠评估的需求日益增加。然而，现有的LLM安全评估基准通常依赖于耗时且资源密集的手动策划，导致大量时间和资源消耗。此外，这些基准还存在显著的冗余和有限的难度。

Method: 本文提出了SafetyFlow，一个首创的代理流系统，旨在自动化构建LLM安全基准。SafetyFlow通过协调七个专业代理，在四天内无需任何人工干预即可自动构建一个全面的安全基准。这些代理配备了多功能工具，确保过程和成本可控，并将人类专业知识融入自动化流程。

Result: SafetyFlow成功构建了数据集SafetyFlowBench，包含23,446个查询，具有低冗余和强大的区分能力。该系统显著减少了时间和资源成本。研究团队使用该数据集评估了49个先进LLM的安全性，并进行了广泛实验验证了其有效性和效率。

Conclusion: 本文的主要贡献是提出了首个全自动化的LLM安全基准构建流程（SafetyFlow）和一个全面的安全基准数据集（SafetyFlowBench），有效解决了现有安全评估方法中的效率和质量问题。

Abstract: The rapid proliferation of large language models (LLMs) has intensified the
requirement for reliable safety evaluation to uncover model vulnerabilities. To
this end, numerous LLM safety evaluation benchmarks are proposed. However,
existing benchmarks generally rely on labor-intensive manual curation, which
causes excessive time and resource consumption. They also exhibit significant
redundancy and limited difficulty. To alleviate these problems, we introduce
SafetyFlow, the first agent-flow system designed to automate the construction
of LLM safety benchmarks. SafetyFlow can automatically build a comprehensive
safety benchmark in only four days without any human intervention by
orchestrating seven specialized agents, significantly reducing time and
resource cost. Equipped with versatile tools, the agents of SafetyFlow ensure
process and cost controllability while integrating human expertise into the
automatic pipeline. The final constructed dataset, SafetyFlowBench, contains
23,446 queries with low redundancy and strong discriminative power. Our
contribution includes the first fully automated benchmarking pipeline and a
comprehensive safety benchmark. We evaluate the safety of 49 advanced LLMs on
our dataset and conduct extensive experiments to validate our efficacy and
efficiency.

</details>


### [152] [SDGO: Self-Discrimination-Guided Optimization for Consistent Safety in Large Language Models](https://arxiv.org/abs/2508.15648)
*Peng Ding,Wen Sun,Dailin Li,Wei Zou,Jiaming Wang,Jiajun Chen,Shujian Huang*

Main category: cs.CL

TL;DR: 本文提出SDGO框架，通过利用大型语言模型（LLM）自身的判别能力作为奖励信号，以强化学习方式迭代优化其生成安全性，有效抵御越狱攻击。


<details>
  <summary>Details</summary>
Motivation: LLMs易受越狱攻击生成有害内容，且存在安全不一致性：LLMs作为判别器比作为生成器更能识别有害请求。这促使研究者探索如何对齐模型的内在判别和生成能力。

Method: 提出SDGO（Self-Discrimination-Guided Optimization），一个基于强化学习的框架。该方法利用模型自身的判别能力作为奖励信号，通过迭代自我改进来增强生成安全性，无需额外的标注数据或外部模型。

Result: SDGO显著提升了模型安全性，优于基于提示和基于训练的基线方法，同时保持了通用任务的实用性。它在对抗域外（OOD）越狱攻击方面表现出强大的鲁棒性，并实现了判别与生成能力更紧密的耦合。

Conclusion: 通过对齐LLMs的判别和生成能力，SDGO框架能有效提高模型的安全性能，使其能够更好地抵御越狱攻击，并展现出对OOD攻击的鲁棒性。

Abstract: Large Language Models (LLMs) excel at various natural language processing
tasks but remain vulnerable to jailbreaking attacks that induce harmful content
generation. In this paper, we reveal a critical safety inconsistency: LLMs can
more effectively identify harmful requests as discriminators than defend
against them as generators. This insight inspires us to explore aligning the
model's inherent discrimination and generation capabilities. To this end, we
propose SDGO (Self-Discrimination-Guided Optimization), a reinforcement
learning framework that leverages the model's own discrimination capabilities
as a reward signal to enhance generation safety through iterative
self-improvement. Our method does not require any additional annotated data or
external models during the training phase. Extensive experiments demonstrate
that SDGO significantly improves model safety compared to both prompt-based and
training-based baselines while maintaining helpfulness on general benchmarks.
By aligning LLMs' discrimination and generation capabilities, SDGO brings
robust performance against out-of-distribution (OOD) jailbreaking attacks. This
alignment achieves tighter coupling between these two capabilities, enabling
the model's generation capability to be further enhanced with only a small
amount of discriminative samples. Our code and datasets are available at
https://github.com/NJUNLP/SDGO.

</details>


### [153] [EcomMMMU: Strategic Utilization of Visuals for Robust Multimodal E-Commerce Models](https://arxiv.org/abs/2508.15721)
*Xinyi Ling,Hanwen Du,Zhihui Zhu,Xia Ning*

Main category: cs.CL

TL;DR: 本文提出了EcomMMMU数据集，用于系统研究电商平台中多模态图像对产品理解的影响。研究发现图像并非总能提升性能，有时甚至会降低性能，表明多模态大语言模型（MLLMs）在利用视觉内容方面存在挑战。为此，作者提出了SUMEI方法，通过预测视觉效用以策略性地利用图像，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 电商平台拥有丰富的多模态数据，尤其是产品图像。然而，现有研究未能系统性地探讨这些图像是否总能增强产品理解，或者有时会引入冗余或降低性能。现有数据集在规模和设计上均受限，难以有效解决这一问题。

Method: 1. 引入了EcomMMMU数据集，一个电商多模态多任务理解数据集，包含406,190个样本和8,989,510张图片。该数据集包含多图像视觉-语言数据，设计了8个核心任务，并包含一个专门的VSS子集，用于评估多模态大语言模型（MLLMs）有效利用视觉内容的能力。 2. 基于对EcomMMMU的分析，提出了SUMEI方法，这是一种数据驱动的方法，通过在使用图像进行下游任务之前预测图像的视觉效用，从而策略性地利用多张图像。

Result: 1. 对EcomMMMU数据集的分析表明，产品图像并非总能持续改善性能，在某些情况下甚至会降低性能。 2. 这表明MLLMs可能难以有效利用丰富的视觉内容来完成电商任务。 3. 综合实验证明了SUMEI方法的有效性和鲁棒性。

Conclusion: 电商平台中的产品图像并非总能提升性能，有时甚至会降低性能，这揭示了多模态大语言模型（MLLMs）在有效利用丰富的视觉内容方面存在的挑战。本文提出的EcomMMMU数据集和SUMEI方法为解决这一问题提供了新的工具和策略，SUMEI通过预测视觉效用实现了对多图像的策略性利用，并被证明是有效和鲁棒的。

Abstract: E-commerce platforms are rich in multimodal data, featuring a variety of
images that depict product details. However, this raises an important question:
do these images always enhance product understanding, or can they sometimes
introduce redundancy or degrade performance? Existing datasets are limited in
both scale and design, making it difficult to systematically examine this
question. To this end, we introduce EcomMMMU, an e-commerce multimodal
multitask understanding dataset with 406,190 samples and 8,989,510 images.
EcomMMMU is comprised of multi-image visual-language data designed with 8
essential tasks and a specialized VSS subset to benchmark the capability of
multimodal large language models (MLLMs) to effectively utilize visual content.
Analysis on EcomMMMU reveals that product images do not consistently improve
performance and can, in some cases, degrade it. This indicates that MLLMs may
struggle to effectively leverage rich visual content for e-commerce tasks.
Building on these insights, we propose SUMEI, a data-driven method that
strategically utilizes multiple images via predicting visual utilities before
using them for downstream tasks. Comprehensive experiments demonstrate the
effectiveness and robustness of SUMEI. The data and code are available through
https://anonymous.4open.science/r/submission25.

</details>


### [154] [Position Bias Mitigates Position Bias:Mitigate Position Bias Through Inter-Position Knowledge Distillation](https://arxiv.org/abs/2508.15709)
*Yifei Wang,Feng Xiong,Yong Wang,Linjing Li,Xiangxiang Chu,Daniel Dajun Zeng*

Main category: cs.CL

TL;DR: 本文提出Pos2Distill框架，通过位置到位置的知识蒸馏，将优势位置的能力迁移到劣势位置，从而有效缓解长文本理解中的位置偏差（PB），提升模型在检索和推理任务中的表现和一致性。


<details>
  <summary>Details</summary>
Motivation: 长文本理解中存在的位置偏差（PB）严重损害了模型的处理能力，尽管现有工作尝试通过修改架构来缓解，但PB问题依然显著，导致不同上下文位置的性能差距巨大。

Method: 本文引入Pos2Distill框架，其核心思想是利用固有的位置差异来对抗PB本身。该框架通过知识蒸馏，将模型在有利位置表现出的优越能力迁移到不利位置。针对检索和推理任务中PB的不同表现，设计了两个专门的实例化：Pos2Distill-R¹（用于检索）和Pos2Distill-R²（用于推理）。

Result: Pos2Distill方法显著增强了长文本检索和推理任务中所有上下文位置的性能一致性，并取得了显著的性能提升。值得注意的是，这两个专门系统在相互之间展现出强大的跨任务泛化能力，同时在其各自任务上均实现了卓越的性能。

Conclusion: Pos2Distill框架通过创新的位置到位置知识蒸馏方法，有效解决了长文本理解中的位置偏差问题，显著提升了模型在检索和推理任务中的均匀性和整体性能，并展现出良好的跨任务泛化能力。

Abstract: Positional bias (PB), manifesting as non-uniform sensitivity across different
contextual locations, significantly impairs long-context comprehension and
processing capabilities. While prior work seeks to mitigate PB through
modifying the architectures causing its emergence, significant PB still
persists. To address PB effectively, we introduce \textbf{Pos2Distill}, a
position to position knowledge distillation framework. Pos2Distill transfers
the superior capabilities from advantageous positions to less favorable ones,
thereby reducing the huge performance gaps. The conceptual principle is to
leverage the inherent, position-induced disparity to counteract the PB itself.
We identify distinct manifestations of PB under \textbf{\textsc{r}}etrieval and
\textbf{\textsc{r}}easoning paradigms, thereby designing two specialized
instantiations: \emph{Pos2Distill-R\textsuperscript{1}} and
\emph{Pos2Distill-R\textsuperscript{2}} respectively, both grounded in this
core principle. By employing the Pos2Distill approach, we achieve enhanced
uniformity and significant performance gains across all contextual positions in
long-context retrieval and reasoning tasks. Crucially, both specialized systems
exhibit strong cross-task generalization mutually, while achieving superior
performance on their respective tasks.

</details>


### [155] [End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning](https://arxiv.org/abs/2508.15746)
*Qiaoyu Zheng,Yuze Sun,Chaoyi Wu,Weike Zhao,Pengcheng Qiu,Yongguo Yu,Kun Sun,Yanfeng Wang,Ya Zhang,Weidi Xie*

Main category: cs.CL

TL;DR: 本文提出Deep-DxSearch，一个基于强化学习端到端训练的代理式RAG系统，用于医学诊断，通过可追溯的检索增强推理，显著提升诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 现有医疗大语言模型在诊断中存在知识空白和幻觉问题，而检索和工具增强方法因外部知识使用不足和反馈-推理可追溯性差而效果有限。

Method: 引入Deep-DxSearch，一个代理式RAG系统，通过强化学习进行端到端训练。构建了包含患者记录和可靠医学知识的大规模医疗检索语料库。将LLM视为核心代理，语料库视为环境，并使用针对格式、检索、推理结构和诊断准确性的定制奖励，通过RL从大规模数据中演化代理式RAG策略。

Result: Deep-DxSearch在多个数据中心持续优于提示工程和免训练RAG方法。训练后，其在诊断准确性方面取得显著提升，超越了GPT-4o、DeepSeek-R1等强基线以及其他医学专用框架，适用于常见和罕见疾病诊断，涵盖分布内和分布外设置。奖励设计和检索语料库组件的消融研究证实了它们的关键作用。案例研究和可解释性分析揭示了诊断策略的改进。

Conclusion: Deep-DxSearch提供了一种独特且有效的医疗诊断方法，通过强化学习训练的代理式RAG系统，显著提高了诊断准确性和可靠性，为临床医生提供了更精准的初步诊断支持。

Abstract: Accurate diagnosis with medical large language models is hindered by
knowledge gaps and hallucinations. Retrieval and tool-augmented methods help,
but their impact is limited by weak use of external knowledge and poor
feedback-reasoning traceability. To address these challenges, We introduce
Deep-DxSearch, an agentic RAG system trained end-to-end with reinforcement
learning (RL) that enables steer tracebale retrieval-augmented reasoning for
medical diagnosis. In Deep-DxSearch, we first construct a large-scale medical
retrieval corpus comprising patient records and reliable medical knowledge
sources to support retrieval-aware reasoning across diagnostic scenarios. More
crutially, we frame the LLM as the core agent and the retrieval corpus as its
environment, using tailored rewards on format, retrieval, reasoning structure,
and diagnostic accuracy, thereby evolving the agentic RAG policy from
large-scale data through RL.
  Experiments demonstrate that our end-to-end agentic RL training framework
consistently outperforms prompt-engineering and training-free RAG approaches
across multiple data centers. After training, Deep-DxSearch achieves
substantial gains in diagnostic accuracy, surpassing strong diagnostic
baselines such as GPT-4o, DeepSeek-R1, and other medical-specific frameworks
for both common and rare disease diagnosis under in-distribution and
out-of-distribution settings. Moreover, ablation studies on reward design and
retrieval corpus components confirm their critical roles, underscoring the
uniqueness and effectiveness of our approach compared with traditional
implementations. Finally, case studies and interpretability analyses highlight
improvements in Deep-DxSearch's diagnostic policy, providing deeper insight
into its performance gains and supporting clinicians in delivering more
reliable and precise preliminary diagnoses. See
https://github.com/MAGIC-AI4Med/Deep-DxSearch.

</details>


### [156] [Stemming -- The Evolution and Current State with a Focus on Bangla](https://arxiv.org/abs/2508.15711)
*Abhijit Paul,Mashiat Amin Farin,Sharif Md. Abdullah,Ahmedul Kabir,Zarif Masud,Shebuti Rayana*

Main category: cs.CL

TL;DR: 本文对孟加拉语词干提取方法进行了全面调查，指出现有研究的不足、实现的可及性差以及评估指标不相关，并提出了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为一种资源稀缺、高度屈折的语言，在数字领域代表性不足。词干提取是语言分析的关键预处理步骤，能有效降低算法复杂性。然而，孟加拉语词干提取领域存在显著的研究空白、缺乏可复现的实现以及评估方法不当。

Method: 本文对词干提取方法进行了全面调查，强调了处理形态变体的重要性。它批判性地审视了孟加拉语词干提取的现有文献、实现和评估方法，并基于孟加拉语丰富的形态和多样方言所带来的挑战，提出了未来发展方向。

Result: 调查发现孟加拉语词干提取领域存在显著的研究空白，与以往研究存在脱节，缺乏可访问的实现，并且现有评估方法需要更相关的指标。同时，论文也承认了孟加拉语丰富的形态和多样方言带来的挑战。

Conclusion: 本文倡导开发鲁棒的孟加拉语词干提取器，并建议在该领域持续进行研究，以增强孟加拉语的语言分析和处理能力。

Abstract: Bangla, the seventh most widely spoken language worldwide with 300 million
native speakers, faces digital under-representation due to limited resources
and lack of annotated datasets. Stemming, a critical preprocessing step in
language analysis, is essential for low-resource, highly-inflectional languages
like Bangla, because it can reduce the complexity of algorithms and models by
significantly reducing the number of words the algorithm needs to consider.
This paper conducts a comprehensive survey of stemming approaches, emphasizing
the importance of handling morphological variants effectively. While exploring
the landscape of Bangla stemming, it becomes evident that there is a
significant gap in the existing literature. The paper highlights the
discontinuity from previous research and the scarcity of accessible
implementations for replication. Furthermore, it critiques the evaluation
methodologies, stressing the need for more relevant metrics. In the context of
Bangla's rich morphology and diverse dialects, the paper acknowledges the
challenges it poses. To address these challenges, the paper suggests directions
for Bangla stemmer development. It concludes by advocating for robust Bangla
stemmers and continued research in the field to enhance language analysis and
processing.

</details>


### [157] [Dissecting Tool-Integrated Reasoning: An Empirical Study and Analysis](https://arxiv.org/abs/2508.15754)
*Yufeng Zhao,Junnan Liu,Hongwei Liu,Dongsheng Zhu,Yuan Shen,Songyang Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 通过引入ReasonZoo基准和新颖的效率指标，本研究证明工具集成推理（TIR）显著提升了大型语言模型（LLM）在多种推理任务中的表现和效率，减少了“过度思考”。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在链式思考等推理任务中取得进展，但在需要精确计算的任务中表现不佳。工具集成推理（TIR）被提出作为解决方案，但其在提高LLM推理能力方面的泛化性尚不明确，且TIR是否改善了模型的推理行为和思维方式也需研究。

Method: 引入了ReasonZoo，一个包含九个不同推理类别的综合基准，用于评估TIR在各种领域中的有效性。此外，提出了两个新颖的指标：性能感知成本（PAC）和性能-成本曲线下面积（AUC-PCC），以评估推理效率。

Result: 实证评估表明，启用TIR的模型在数学和非数学任务中均持续优于非TIR模型。此外，TIR提高了推理效率，表现为PAC和AUC-PCC的改善，这表明模型减少了“过度思考”，推理过程更加精简。

Conclusion: 这些发现强调了TIR的领域通用益处，以及其在提升LLM处理复杂推理任务能力方面的潜力。

Abstract: Large Language Models (LLMs) have made significant strides in reasoning tasks
through methods like chain-of-thought (CoT) reasoning. However, they often fall
short in tasks requiring precise computations. Tool-Integrated Reasoning (TIR)
has emerged as a solution by incorporating external tools into the reasoning
process. Nevertheless, the generalization of TIR in improving the reasoning
ability of LLM is still unclear. Additionally, whether TIR has improved the
model's reasoning behavior and helped the model think remains to be studied. We
introduce ReasonZoo, a comprehensive benchmark encompassing nine diverse
reasoning categories, to evaluate the effectiveness of TIR across various
domains. Additionally, we propose two novel metrics, Performance-Aware Cost
(PAC) and Area Under the Performance-Cost Curve (AUC-PCC), to assess reasoning
efficiency. Our empirical evaluation demonstrates that TIR-enabled models
consistently outperform their non-TIR counterparts in both mathematical and
non-mathematical tasks. Furthermore, TIR enhances reasoning efficiency, as
evidenced by improved PAC and AUC-PCC, indicating reduced overthinking and more
streamlined reasoning. These findings underscore the domain-general benefits of
TIR and its potential to advance LLM capabilities in complex reasoning tasks.

</details>


### [158] [LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries](https://arxiv.org/abs/2508.15760)
*Ming Yin,Dinghan Shen,Silei Xu,Jianbing Han,Sixun Dong,Mian Zhang,Yebowen Hu,Shujian Liu,Simin Ma,Song Wang,Sathish Reddy Indurthi,Xun Wang,Yiran Chen,Kaiqiang Song*

Main category: cs.CL

TL;DR: 该研究提出了LiveMCP-101基准测试，用于评估AI智能体在真实动态场景中，使用多种模型上下文协议（MCP）工具解决多步骤任务的能力。结果显示，即使是前沿大型语言模型（LLM）的成功率也低于60%，揭示了工具编排方面的重大挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管模型上下文协议（MCP）为工具集成提供了强大的标准化框架，但在基准测试AI智能体如何有效利用多样化MCP工具在真实、动态场景中解决多步骤任务方面存在显著空白。

Method: 本文介绍了LiveMCP-101，一个包含101个精心策划的真实世界查询的基准测试，这些查询经过迭代的LLM重写和人工审查，需要协调使用多种MCP工具（包括网络搜索、文件操作、数学推理和数据分析）。此外，研究引入了一种新颖的评估方法，该方法利用真实执行计划而非原始API输出，更好地反映了真实世界环境的演变性质。

Result: 实验表明，即使是前沿LLM的成功率也低于60%，突显了工具编排中的主要挑战。详细的消融研究和错误分析进一步揭示了不同的失败模式和令牌使用效率低下，指出了当前模型改进的具体方向。

Conclusion: LiveMCP-101为评估真实世界智能体能力设定了严格标准，推动了通过工具使用可靠执行复杂任务的自主AI系统发展。

Abstract: Tool calling has emerged as a critical capability for AI agents to interact
with the real world and solve complex tasks. While the Model Context Protocol
(MCP) provides a powerful standardized framework for tool integration, there is
a significant gap in benchmarking how well AI agents can effectively solve
multi-step tasks using diverse MCP tools in realistic, dynamic scenarios. In
this work, we present LiveMCP-101, a benchmark of 101 carefully curated
real-world queries, refined through iterative LLM rewriting and manual review,
that require coordinated use of multiple MCP tools including web search, file
operations, mathematical reasoning, and data analysis. Moreover, we introduce a
novel evaluation approach that leverages ground-truth execution plans rather
than raw API outputs, better reflecting the evolving nature of real-world
environments. Experiments show that even frontier LLMs achieve a success rate
below 60\%, highlighting major challenges in tool orchestration. Detailed
ablations and error analysis further reveal distinct failure modes and
inefficiencies in token usage, pointing to concrete directions for advancing
current models. LiveMCP-101 sets a rigorous standard for evaluating real-world
agent capabilities, advancing toward autonomous AI systems that reliably
execute complex tasks through tool use.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [159] [A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot](https://arxiv.org/abs/2508.14994)
*Murilo Vinicius da Silva,Matheus Hipolito Carvalho,Juliano Negri,Thiago Segreto,Gustavo J. G. Lahr,Ricardo V. Godoy,Marcelo Becker*

Main category: cs.RO

TL;DR: 提出了一种基于视觉姿态估计的直观遥操作方法，通过机器学习模型检测操作员手腕运动，并将其映射到四足机器人机械臂的实时控制，同时结合轨迹规划器确保防碰撞安全，适用于高风险环境。


<details>
  <summary>Details</summary>
Motivation: 在危险和远程环境中，四足机器人与机械臂的遥操作面临挑战。传统方法缺乏集成的障碍物检测和直观的机械臂控制，导致碰撞风险高、操作员认知负荷大，且需要高专业技能。

Method: 本研究提出了一种直观的遥操作方法。该方法利用外部摄像头和基于机器学习模型的视觉姿态估计算法来检测操作员的手腕位置。检测到的手腕运动被实时映射为机器人机械臂的控制命令。此外，系统还包含一个轨迹规划器，用于检测并防止与障碍物和机械臂自身的碰撞，从而确保操作安全。

Result: 该系统在真实机器人上进行了验证，展示了在实时控制方面的鲁棒性能。

Conclusion: 该遥操作方法为工业应用提供了一种经济高效的解决方案，特别是在安全、精度和易用性至关重要的危险环境中，能够实现可靠且直观的机器人控制。

Abstract: In hazardous and remote environments, robotic systems perform critical tasks
demanding improved safety and efficiency. Among these, quadruped robots with
manipulator arms offer mobility and versatility for complex operations.
However, teleoperating quadruped robots is challenging due to the lack of
integrated obstacle detection and intuitive control methods for the robotic
arm, increasing collision risks in confined or dynamically changing workspaces.
Teleoperation via joysticks or pads can be non-intuitive and demands a high
level of expertise due to its complexity, culminating in a high cognitive load
on the operator. To address this challenge, a teleoperation approach that
directly maps human arm movements to the robotic manipulator offers a simpler
and more accessible solution. This work proposes an intuitive remote control by
leveraging a vision-based pose estimation pipeline that utilizes an external
camera with a machine learning-based model to detect the operator's wrist
position. The system maps these wrist movements into robotic arm commands to
control the robot's arm in real-time. A trajectory planner ensures safe
teleoperation by detecting and preventing collisions with both obstacles and
the robotic arm itself. The system was validated on the real robot,
demonstrating robust performance in real-time control. This teleoperation
approach provides a cost-effective solution for industrial applications where
safety, precision, and ease of use are paramount, ensuring reliable and
intuitive robotic control in high-risk environments.

</details>


### [160] [GraspQP: Differentiable Optimization of Force Closure for Diverse and Robust Dexterous Grasping](https://arxiv.org/abs/2508.15002)
*René Zurbrügg,Andrei Cramariuc,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种通过可微分力闭合能量公式和改进优化方法（MALA*）来合成大规模、多样化且物理可行的抓取数据的方法，显著提高了抓取多样性和稳定性，并提供了一个包含多种抓取类型和夹持器的新型大型数据集。


<details>
  <summary>Details</summary>
Motivation: 多指灵巧手需要多样化、高质量的抓取数据来充分发挥其能力，例如用于抓取预测模型、训练操作策略和支持高级任务规划。然而，现有数据集生成方法（基于采样或简化力闭合分析）通常缺乏多样性，倾向于生成力量抓取。

Method: 该研究提出了一种方法来合成大规模、多样化且物理可行的抓取，包括捏取和三指精确抓取等。核心方法包括：1) 引入一个通过二次规划（QP）隐式定义的严格、可微分的力闭合能量公式。2) 提出了一种调整后的优化方法（MALA*），通过根据所有样本的能量值分布动态拒绝梯度步来提高性能。

Result: 该方法在抓取多样性和最终抓取预测的稳定性方面均显示出显著改进。此外，研究还为来自DexGraspNet的5,700个物体提供了一个新的大规模抓取数据集，该数据集包含五种不同的夹持器和三种独特的抓取类型。

Conclusion: 该工作成功提出了一种能够生成多样化、物理可行抓取数据的方法，解决了现有数据集生成方法的局限性，并为机器人操作领域提供了高质量、大规模的抓取数据集，有助于推动灵巧手抓取预测和操作策略的发展。

Abstract: Dexterous robotic hands enable versatile interactions due to the flexibility
and adaptability of multi-fingered designs, allowing for a wide range of
task-specific grasp configurations in diverse environments. However, to fully
exploit the capabilities of dexterous hands, access to diverse and high-quality
grasp data is essential -- whether for developing grasp prediction models from
point clouds, training manipulation policies, or supporting high-level task
planning with broader action options. Existing approaches for dataset
generation typically rely on sampling-based algorithms or simplified
force-closure analysis, which tend to converge to power grasps and often
exhibit limited diversity. In this work, we propose a method to synthesize
large-scale, diverse, and physically feasible grasps that extend beyond simple
power grasps to include refined manipulations, such as pinches and tri-finger
precision grasps. We introduce a rigorous, differentiable energy formulation of
force closure, implicitly defined through a Quadratic Program (QP).
Additionally, we present an adjusted optimization method (MALA*) that improves
performance by dynamically rejecting gradient steps based on the distribution
of energy values across all samples. We extensively evaluate our approach and
demonstrate significant improvements in both grasp diversity and the stability
of final grasp predictions. Finally, we provide a new, large-scale grasp
dataset for 5,700 objects from DexGraspNet, comprising five different grippers
and three distinct grasp types.
  Dataset and Code:https://graspqp.github.io/

</details>


### [161] [In-Context Iterative Policy Improvement for Dynamic Manipulation](https://arxiv.org/abs/2508.15021)
*Mark Van der Merwe,Devesh Jha*

Main category: cs.RO

TL;DR: 本文将大型语言模型（LLMs）的上下文学习能力应用于动态操作任务，通过预测参数策略的调整，在低数据环境下表现优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在语言任务和一般模式识别方面展现出卓越的推理能力和少样本上下文学习能力。研究人员希望探索这种能力是否能扩展到动态操作领域，尽管该领域存在维度高、动力学复杂和部分可观测性等挑战。

Method: 研究采用迭代方法，将上下文学习问题表述为根据先前交互预测对参数化策略的调整。这使得模型能够逐步优化操作策略。

Result: 在模拟环境和物理机器人上的多项任务中，该方法在低数据状态下，利用上下文学习的表现优于其他替代方法。

Conclusion: 将预训练语言模型的上下文学习应用于动态操作是有效的，尤其是在数据稀缺的情况下。通过迭代地预测策略调整，LLMs能够成功应对动态操作的复杂挑战。

Abstract: Attention-based architectures trained on internet-scale language data have
demonstrated state of the art reasoning ability for various language-based
tasks, such as logic problems and textual reasoning. Additionally, these Large
Language Models (LLMs) have exhibited the ability to perform few-shot
prediction via in-context learning, in which input-output examples provided in
the prompt are generalized to new inputs. This ability furthermore extends
beyond standard language tasks, enabling few-shot learning for general
patterns. In this work, we consider the application of in-context learning with
pre-trained language models for dynamic manipulation. Dynamic manipulation
introduces several crucial challenges, including increased dimensionality,
complex dynamics, and partial observability. To address this, we take an
iterative approach, and formulate our in-context learning problem to predict
adjustments to a parametric policy based on previous interactions. We show
across several tasks in simulation and on a physical robot that utilizing
in-context learning outperforms alternative methods in the low data regime.
Video summary of this work and experiments can be found
https://youtu.be/2inxpdrq74U?si=dAdDYsUEr25nZvRn.

</details>


### [162] [Decentralized Vision-Based Autonomous Aerial Wildlife Monitoring](https://arxiv.org/abs/2508.15038)
*Makram Chahine,William Yang,Alaa Maalouf,Justin Siriska,Ninad Jadhav,Daniel Vogt,Stephanie Gil,Robert Wood,Daniela Rus*

Main category: cs.RO

TL;DR: 该研究提出了一种去中心化、基于视觉的多旋翼无人机系统，用于大规模野生动物监测，通过单目RGB相机实现个体识别和跟踪，无需集中控制或高带宽。


<details>
  <summary>Details</summary>
Motivation: 野生动物实地操作需要高效的并行部署方法来识别和跟踪个体，以进行行为分析和干预。现有机器人解决方案要么以群体为中心，要么手动操作且规模有限。

Method: 开发了一种去中心化、基于视觉的多旋翼无人机系统，该系统具有可扩展性、低带宽和最少传感器（单个机载RGB相机）的特点。设计了新颖的基于视觉的协调和跟踪算法，适用于动态、非结构化环境，不依赖集中通信或控制。

Result: 该系统能够在自然栖息地中对大型物种进行鲁棒的识别和跟踪。通过真实世界的实验验证了系统的可靠性，并在各种野外条件下展示了可靠的部署能力。

Conclusion: 所提出的去中心化、基于视觉的多旋翼无人机系统为野生动物监测提供了一种可扩展、鲁棒且高效的解决方案，克服了现有方法的局限性。

Abstract: Wildlife field operations demand efficient parallel deployment methods to
identify and interact with specific individuals, enabling simultaneous
collective behavioral analysis, and health and safety interventions. Previous
robotics solutions approach the problem from the herd perspective, or are
manually operated and limited in scale. We propose a decentralized vision-based
multi-quadrotor system for wildlife monitoring that is scalable, low-bandwidth,
and sensor-minimal (single onboard RGB camera). Our approach enables robust
identification and tracking of large species in their natural habitat. We
develop novel vision-based coordination and tracking algorithms designed for
dynamic, unstructured environments without reliance on centralized
communication or control. We validate our system through real-world
experiments, demonstrating reliable deployment in diverse field conditions.

</details>


### [163] [Hardware Implementation of a Zero-Prior-Knowledge Approach to Lifelong Learning in Kinematic Control of Tendon-Driven Quadrupeds](https://arxiv.org/abs/2508.15160)
*Hesam Azadjou,Suraj Chakravarthi Raja,Ali Marjaninejad,Francisco J. Valero-Cuevas*

Main category: cs.RO

TL;DR: 本文提出了一种名为G2P的生物启发式学习算法，使肌腱驱动的四足机器人在几分钟内学会了适应性循环运动控制。


<details>
  <summary>Details</summary>
Motivation: 机器人需要像哺乳动物一样，在对自身和环境知识不完全的情况下，快速学习身体控制并与环境互动，同时适应持续变化。

Method: 研究采用生物启发式学习算法G2P，在一个自研的肌腱驱动四足机器人上进行。机器人首先经历5分钟的通用运动探索（motor babbling），随后进行15次每次20秒的精炼试验以实现特定的循环运动，模仿哺乳动物的探索-利用范式。

Result: 结果表明，该硬件在环系统能够在短短几分钟内，让具有冗余的肌腱驱动四足机器人学会控制，实现功能性、适应性的非凸循环运动。每次精炼后，机器人都会在其初始的“足够好”的解决方案上逐步改进。

Conclusion: 该方法推进了机器人运动中的自主控制，为机器人动态适应新环境、确保持续适应性和性能铺平了道路。

Abstract: Like mammals, robots must rapidly learn to control their bodies and interact
with their environment despite incomplete knowledge of their body structure and
surroundings. They must also adapt to continuous changes in both. This work
presents a bio-inspired learning algorithm, General-to-Particular (G2P),
applied to a tendon-driven quadruped robotic system developed and fabricated
in-house. Our quadruped robot undergoes an initial five-minute phase of
generalized motor babbling, followed by 15 refinement trials (each lasting 20
seconds) to achieve specific cyclical movements. This process mirrors the
exploration-exploitation paradigm observed in mammals. With each refinement,
the robot progressively improves upon its initial "good enough" solution. Our
results serve as a proof-of-concept, demonstrating the hardware-in-the-loop
system's ability to learn the control of a tendon-driven quadruped with
redundancies in just a few minutes to achieve functional and adaptive cyclical
non-convex movements. By advancing autonomous control in robotic locomotion,
our approach paves the way for robots capable of dynamically adjusting to new
environments, ensuring sustained adaptability and performance.

</details>


### [164] [Survey of Vision-Language-Action Models for Embodied Manipulation](https://arxiv.org/abs/2508.15201)
*Haoran Li,Yuhui Chen,Wenbo Cui,Weiheng Liu,Kai Liu,Mingcai Zhou,Zhengtao Zhang,Dongbin Zhao*

Main category: cs.RO

TL;DR: 这篇综述全面回顾了具身操作中的视觉-语言-动作（VLA）模型，涵盖其发展轨迹、当前研究（从模型结构、数据集、预训练、后训练和评估五个维度），并提出了挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 具身智能系统通过持续环境交互提升智能体能力，VLA模型作为通用机器人控制框架，显著增强了具身智能系统中的智能体-环境交互能力，拓宽了具身AI机器人的应用场景，因此对VLA模型进行综述具有重要意义。

Method: 本文采用综述方法，首先梳理VLA架构的发展轨迹；其次，从VLA模型结构、训练数据集、预训练方法、后训练方法和模型评估五个关键维度详细分析当前研究；最后，总结VLA发展和实际部署中的主要挑战，并提出未来研究方向。

Result: 本文提供了具身操作中VLA模型的全面回顾，详细分析了当前研究的五个关键维度，并综合了VLA开发和实际部署中的主要挑战，同时规划了有前景的未来研究方向。

Conclusion: VLA模型是具身智能系统实现具身操作的关键技术，尽管取得了显著进展，但在实际部署和进一步发展中仍面临挑战，未来研究需在多个方向上持续探索。

Abstract: Embodied intelligence systems, which enhance agent capabilities through
continuous environment interactions, have garnered significant attention from
both academia and industry. Vision-Language-Action models, inspired by
advancements in large foundation models, serve as universal robotic control
frameworks that substantially improve agent-environment interaction
capabilities in embodied intelligence systems. This expansion has broadened
application scenarios for embodied AI robots. This survey comprehensively
reviews VLA models for embodied manipulation. Firstly, it chronicles the
developmental trajectory of VLA architectures. Subsequently, we conduct a
detailed analysis of current research across 5 critical dimensions: VLA model
structures, training datasets, pre-training methods, post-training methods, and
model evaluation. Finally, we synthesize key challenges in VLA development and
real-world deployment, while outlining promising future research directions.

</details>


### [165] [Mag-Match: Magnetic Vector Field Features for Map Matching and Registration](https://arxiv.org/abs/2508.15300)
*William McDonald,Cedric Le Gentil,Jennifer Wakulicz,Teresa Vidal-Calleja*

Main category: cs.RO

TL;DR: 本文提出了一种名为Mag-Match的新方法，用于在3D磁场矢量图中提取和描述特征，以实现不同磁场地图的配准。该方法利用高阶导数作为特征描述符，并通过物理信息高斯过程进行高效推理，即使在没有重力对齐的情况下也能实现准确的地图匹配。


<details>
  <summary>Details</summary>
Motivation: 传统的基于摄像头或激光雷达的地图匹配和配准方法在烟雾或灰尘等恶劣环境下表现不佳。而磁力计能够检测到其他传感器无法捕捉的磁场特征，并且在这些恶劣环境中具有鲁棒性。因此，需要一种利用磁场信息进行地图匹配的鲁棒方法。

Method: 本文引入了Mag-Match方法，用于从3D磁场矢量图中提取和描述特征。其特征描述符基于磁场地图的高阶导数，并且对全局方向不变，无需重力对齐。为了从点式磁力计数据中获取全图范围的高阶导数，该方法利用了物理信息高斯过程（Gaussian Process）进行磁场及其导数的有效和递归概率推断。

Result: Mag-Match在模拟和真实世界实验中与基于SIFT的方法进行了对比评估。结果表明，Mag-Match能够实现准确的地图到地图、机器人到地图以及机器人到机器人的转换，即使在没有初始重力对齐的情况下也能表现良好。

Conclusion: Mag-Match提供了一种新颖且鲁棒的3D磁场矢量图配准方法。通过利用磁场高阶导数作为方向不变的特征描述符，并结合物理信息高斯过程进行高效推理，该方法克服了传统传感器在恶劣环境下的局限性，实现了高精度的地图匹配。

Abstract: Map matching and registration are essential tasks in robotics for
localisation and integration of multi-session or multi-robot data. Traditional
methods rely on cameras or LiDARs to capture visual or geometric information
but struggle in challenging conditions like smoke or dust. Magnetometers, on
the other hand, detect magnetic fields, revealing features invisible to other
sensors and remaining robust in such environments. In this paper, we introduce
Mag-Match, a novel method for extracting and describing features in 3D magnetic
vector field maps to register different maps of the same area. Our feature
descriptor, based on higher-order derivatives of magnetic field maps, is
invariant to global orientation, eliminating the need for gravity-aligned
mapping. To obtain these higher-order derivatives map-wide given point-wise
magnetometer data, we leverage a physics-informed Gaussian Process to perform
efficient and recursive probabilistic inference of both the magnetic field and
its derivatives. We evaluate Mag-Match in simulated and real-world experiments
against a SIFT-based approach, demonstrating accurate map-to-map, robot-to-map,
and robot-to-robot transformations - even without initial gravitational
alignment.

</details>


### [166] [Understanding and Utilizing Dynamic Coupling in Free-Floating Space Manipulators for On-Orbit Servicing](https://arxiv.org/abs/2508.15732)
*Gargi Das,Daegyun Choi,Donghoon Kim*

Main category: cs.RO

TL;DR: 本研究提出了一种动态耦合感知的轨迹优化算法，用于自由浮动空间机械臂系统，通过利用而非仅仅最小化动态耦合来提高轨迹规划效率。


<details>
  <summary>Details</summary>
Motivation: 动态耦合对自由浮动空间机械臂系统的行为影响至关重要。以往研究主要关注最小化耦合，但本研究旨在探索如何利用动态耦合来改进轨迹规划，而不是忽视其潜在优势。

Method: 该研究采用动态耦合矩阵的奇异值分解（SVD）来识别耦合行为的主导分量。接着，制定了一个量化指标来表征耦合的强度和方向性，并将其整合到轨迹优化框架中。为评估优化轨迹的可行性，设计了一个基于滑模控制的跟踪控制器来生成所需的关节扭矩输入。

Result: 仿真结果表明，在轨迹规划中明确考虑动态耦合能够实现更明智、可能更高效的操作。

Conclusion: 在轨迹规划中明确考虑动态耦合为自由浮动空间机械臂系统的控制提供了新的方向，能够实现更明智和高效的操作。

Abstract: This study proposes a dynamic coupling-informed trajectory optimization
algorithm for free-floating space manipulator systems (SMSs). Dynamic coupling
between the base and the manipulator arms plays a critical role in influencing
the system's behavior. While prior research has predominantly focused on
minimizing this coupling, often overlooking its potential advantages, this work
investigates how dynamic coupling can instead be leveraged to improve
trajectory planning. Singular value decomposition (SVD) of the dynamic coupling
matrix is employed to identify the dominant components governing coupling
behavior. A quantitative metric is then formulated to characterize the strength
and directionality of the coupling and is incorporated into a trajectory
optimization framework. To assess the feasibility of the optimized trajectory,
a sliding mode control-based tracking controller is designed to generate the
required joint torque inputs. Simulation results demonstrate that explicitly
accounting for dynamic coupling in trajectory planning enables more informed
and potentially more efficient operation, offering new directions for the
control of free-floating SMSs.

</details>


### [167] [Sensing, Social, and Motion Intelligence in Embodied Navigation: A Comprehensive Survey](https://arxiv.org/abs/2508.15354)
*Chaoran Xiong,Yulong Huang,Fangwen Yu,Changhao Chen,Yue Wang,Songpengchen Xia,Ling Pei*

Main category: cs.RO

TL;DR: 这篇综述介绍了具身导航（Embodied Navigation, EN），这是一种通过感知、社交和运动智能使机器人执行复杂自我中心任务的新范式。它提出了一个名为TOFRA的五阶段框架来系统化EN，并据此回顾了当前技术、平台、评估指标和开放挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的导航方法依赖于明确的定位和预定义地图。具身导航旨在通过利用自我中心感知和类人交互策略，使机器人能够执行更复杂的自我中心任务，从而超越传统方法的局限性。本研究的动机是系统地总结这一新兴领域，并识别其关键挑战。

Method: 本研究提出了一种名为TOFRA的具身导航综合公式，包含五个阶段：Transition（过渡）、Observation（观察）、Fusion（融合）、Reward-policy construction（奖励策略构建）和Action（行动）。TOFRA框架被用于综合当前技术水平、批判性地回顾相关平台和评估指标，并识别关键的开放研究挑战。

Result: TOFRA框架成功地综合了具身导航的最新技术，对相关平台和评估指标进行了批判性审查，并明确指出了该领域面临的关键开放研究挑战。

Conclusion: 具身导航通过其自我中心感知和类人交互策略，为机器人执行复杂任务提供了新的可能性。TOFRA框架为理解和分析具身导航提供了一个结构化的视角，并为未来的研究指明了方向和挑战。

Abstract: Embodied navigation (EN) advances traditional navigation by enabling robots
to perform complex egocentric tasks through sensing, social, and motion
intelligence. In contrast to classic methodologies that rely on explicit
localization and pre-defined maps, EN leverages egocentric perception and
human-like interaction strategies. This survey introduces a comprehensive EN
formulation structured into five stages: Transition, Observation, Fusion,
Reward-policy construction, and Action (TOFRA). The TOFRA framework serves to
synthesize the current state of the art, provide a critical review of relevant
platforms and evaluation metrics, and identify critical open research
challenges. A list of studies is available at
https://github.com/Franky-X/Awesome-Embodied-Navigation.

</details>


### [168] [Lang2Lift: A Framework for Language-Guided Pallet Detection and Pose Estimation Integrated in Autonomous Outdoor Forklift Operation](https://arxiv.org/abs/2508.15427)
*Huy Hoang Nguyen,Johannes Huemer,Markus Murschitz,Tobias Glueck,Minh Nhat Vu,Andreas Kugi*

Main category: cs.RO

TL;DR: Lang2Lift是一个利用基础模型实现自然语言引导的托盘检测和6D姿态估计框架，旨在解决物流和建筑行业在室外复杂环境下自动托盘搬运的挑战，并已在自主叉车平台上验证其可行性。


<details>
  <summary>Details</summary>
Motivation: 物流和建筑行业在自动化托盘搬运方面面临持续挑战，尤其是在室外、有效载荷可变、托盘质量和尺寸不一致以及非结构化环境中。该研究的动机是劳动力短缺、安全隐患以及在这些条件下手动定位和检索托盘的低效率问题。

Method: Lang2Lift框架利用基础模型实现自然语言引导的托盘检测和6D姿态估计。感知管道集成了Florence-2和SAM-2进行语言接地分割，并使用FoundationPose在杂乱、多托盘、光照可变的室外场景中进行鲁棒的姿态估计。得到的姿态信息被输入到运动规划模块，以实现全自主叉车操作。该系统在ADAPT自主叉车平台上进行了验证。

Result: Lang2Lift在真实世界测试数据集上实现了0.76 mIoU的托盘分割精度。时间分析和误差分析表明系统具有鲁棒性，并证实了其在实际物流和建筑环境中部署的可行性。

Conclusion: Lang2Lift框架通过结合基础模型和语言引导，为在复杂室外环境下实现自主托盘抓取操作提供了一个可行且鲁棒的解决方案，有望解决当前行业面临的自动化挑战。

Abstract: The logistics and construction industries face persistent challenges in
automating pallet handling, especially in outdoor environments with variable
payloads, inconsistencies in pallet quality and dimensions, and unstructured
surroundings. In this paper, we tackle automation of a critical step in pallet
transport: the pallet pick-up operation. Our work is motivated by labor
shortages, safety concerns, and inefficiencies in manually locating and
retrieving pallets under such conditions. We present Lang2Lift, a framework
that leverages foundation models for natural language-guided pallet detection
and 6D pose estimation, enabling operators to specify targets through intuitive
commands such as "pick up the steel beam pallet near the crane." The perception
pipeline integrates Florence-2 and SAM-2 for language-grounded segmentation
with FoundationPose for robust pose estimation in cluttered, multi-pallet
outdoor scenes under variable lighting. The resulting poses feed into a motion
planning module for fully autonomous forklift operation. We validate Lang2Lift
on the ADAPT autonomous forklift platform, achieving 0.76 mIoU pallet
segmentation accuracy on a real-world test dataset. Timing and error analysis
demonstrate the system's robustness and confirm its feasibility for deployment
in operational logistics and construction environments. Video demonstrations
are available at https://eric-nguyen1402.github.io/lang2lift.github.io/

</details>


### [169] [LLM-Driven Self-Refinement for Embodied Drone Task Planning](https://arxiv.org/abs/2508.15501)
*Deyu Zhang,Xicheng Zhang,Jiahao Li,Tingting Long,Xunhua Dai,Yongjian Fu,Jinrui Zhang,Ju Ren,Yaoxue Zhang*

Main category: cs.RO

TL;DR: SRDrone是一个针对工业级具身无人机的自完善任务规划系统，通过连续状态评估和分层行为树修改模型，显著提高了任务成功率，有效结合了LLM推理能力与无人机物理执行约束。


<details>
  <summary>Details</summary>
Motivation: 传统的单帧最终状态评估不足以应对无人机动态操作中任务结果的鲁棒和准确判断。具身无人机需要一种机制来实现结构化的反思性学习和自适应任务精炼，以有效整合大型语言模型（LLM）的通用推理智能与无人机严格的物理执行约束。

Method: SRDrone采用了两种关键技术：1. 连续状态评估方法，用于鲁棒准确地确定任务结果并提供解释性反馈，取代了传统的单帧最终状态评估。2. 分层行为树（BT）修改模型，该模型结合了多级BT计划分析和受限策略空间，以实现从经验中进行结构化的反思性学习。

Result: 实验结果表明，SRDrone的任务成功率（SR）比基线方法提高了44.87%。此外，通过迭代自完善优化的经验库在实际部署中达到了96.25%的SR。

Conclusion: SRDrone通过在工业级行为树规划框架中嵌入自适应任务精炼能力，成功地将大型语言模型（LLM）的通用推理智能与具身无人机固有的严格物理执行约束有效结合起来。

Abstract: We introduce SRDrone, a novel system designed for self-refinement task
planning in industrial-grade embodied drones. SRDrone incorporates two key
technical contributions: First, it employs a continuous state evaluation
methodology to robustly and accurately determine task outcomes and provide
explanatory feedback. This approach supersedes conventional reliance on
single-frame final-state assessment for continuous, dynamic drone operations.
Second, SRDrone implements a hierarchical Behavior Tree (BT) modification
model. This model integrates multi-level BT plan analysis with a constrained
strategy space to enable structured reflective learning from experience.
Experimental results demonstrate that SRDrone achieves a 44.87% improvement in
Success Rate (SR) over baseline methods. Furthermore, real-world deployment
utilizing an experience base optimized through iterative self-refinement
attains a 96.25% SR. By embedding adaptive task refinement capabilities within
an industrial-grade BT planning framework, SRDrone effectively integrates the
general reasoning intelligence of Large Language Models (LLMs) with the
stringent physical execution constraints inherent to embodied drones. Code is
available at https://github.com/ZXiiiC/SRDrone.

</details>


### [170] [Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation](https://arxiv.org/abs/2508.15663)
*Nikita Kachaev,Andrei Spiridonov,Andrey Gorodetsky,Kirill Muravyev,Nikita Oskolkov,Aditya Narendra,Vlad Shakhuro,Dmitry Makarov,Aleksandr I. Panov,Polina Fedotova,Alexey K. Kovalev*

Main category: cs.RO

TL;DR: Kitchen-R是一个新颖的基准测试平台，旨在统一评估具身AI中高层任务规划和低层机器人控制。它在一个模拟厨房环境中，使用复杂的语言指令来驱动移动机械臂，并支持独立或集成评估。


<details>
  <summary>Details</summary>
Motivation: 当前的具身AI基准测试在高层语言指令遵循（假设完美的低层执行）和低层机器人控制（依赖简单一步指令）之间存在显著差距，阻碍了对任务规划和物理执行均关键的集成系统进行全面评估。

Method: 本文提出了Kitchen-R，一个基于Isaac Sim构建的数字孪生模拟厨房环境。它包含超过500条复杂的语言指令，支持移动机械臂。提供了基线方法，包括基于视觉语言模型的任务规划策略和基于扩散策略的低层控制策略，以及一个轨迹收集系统。Kitchen-R提供三种评估模式：规划模块独立评估、控制策略独立评估和整个系统的集成评估。

Result: Kitchen-R提供了一个灵活的框架，用于在一个真实的模拟厨房环境中，通过复杂的语言指令，对任务规划和低层控制进行独立和集成评估。它通过基线方法展示了其可用性。

Conclusion: Kitchen-R弥合了具身AI研究中的一个关键空白，使得对语言引导的机器人代理能够进行更全面、更真实的基准测试。

Abstract: Benchmarks are crucial for evaluating progress in robotics and embodied AI.
However, a significant gap exists between benchmarks designed for high-level
language instruction following, which often assume perfect low-level execution,
and those for low-level robot control, which rely on simple, one-step commands.
This disconnect prevents a comprehensive evaluation of integrated systems where
both task planning and physical execution are critical. To address this, we
propose Kitchen-R, a novel benchmark that unifies the evaluation of task
planning and low-level control within a simulated kitchen environment. Built as
a digital twin using the Isaac Sim simulator and featuring more than 500
complex language instructions, Kitchen-R supports a mobile manipulator robot.
We provide baseline methods for our benchmark, including a task-planning
strategy based on a vision-language model and a low-level control policy based
on diffusion policy. We also provide a trajectory collection system. Our
benchmark offers a flexible framework for three evaluation modes: independent
assessment of the planning module, independent assessment of the control
policy, and, crucially, an integrated evaluation of the whole system. Kitchen-R
bridges a key gap in embodied AI research, enabling more holistic and realistic
benchmarking of language-guided robotic agents.

</details>


### [171] [Exploiting Policy Idling for Dexterous Manipulation](https://arxiv.org/abs/2508.15669)
*Annie S. Chen,Philemon Brakel,Antonia Bronars,Annie Xie,Sandy Huang,Oliver Groth,Maria Bauza,Markus Wulfmeier,Nicolas Heess,Dushyant Rao*

Main category: cs.RO

TL;DR: 本文提出了一种名为PIP的方法，通过在检测到策略“停滞”时施加扰动，显著提高了灵巧操作策略的鲁棒性和性能，并促进了更好的策略迭代改进。


<details>
  <summary>Details</summary>
Motivation: 学习型灵巧操作策略在可靠性和鲁棒性方面仍有不足，常见问题是策略在需要高精度运动的关键点（如抓取或插入前）出现“停滞”现象，这通常是训练数据造成的。现有缓解方法（如过滤数据或调整控制频率）可能带来负面影响，因此需要一种新的替代方案。

Method: 本文提出“停滞诱导扰动”（Pause-Induced Perturbations, PIP）方法。该方法检测策略何时进入“停滞”状态（即在小范围内停止移动），并在检测到停滞时施加扰动，帮助策略逃离有问题的吸引盆地，从而促进探索和策略改进。

Result: 在具有挑战性的模拟双臂任务中，PIP方法在测试时性能上取得了显著提升，且无需额外监督或训练。此外，由于机器人在关键点容易停滞，从PIP产生的经验中学习可以带来比现有方法更好的迭代策略改进。在需要复杂多指操作的真实世界插入任务中，该扰动策略使绝对成功率提高了15-35%。

Conclusion: PIP是一种简单有效的方法，能解决灵巧操作中策略“停滞”的问题。通过在停滞状态施加扰动，它能显著提高策略在模拟和真实世界任务中的测试时性能和鲁棒性，并能更好地促进策略的迭代学习和改进。

Abstract: Learning-based methods for dexterous manipulation have made notable progress
in recent years. However, learned policies often still lack reliability and
exhibit limited robustness to important factors of variation. One failure
pattern that can be observed across many settings is that policies idle, i.e.
they cease to move beyond a small region of states when they reach certain
states. This policy idling is often a reflection of the training data. For
instance, it can occur when the data contains small actions in areas where the
robot needs to perform high-precision motions, e.g., when preparing to grasp an
object or object insertion. Prior works have tried to mitigate this phenomenon
e.g. by filtering the training data or modifying the control frequency.
However, these approaches can negatively impact policy performance in other
ways. As an alternative, we investigate how to leverage the detectability of
idling behavior to inform exploration and policy improvement. Our approach,
Pause-Induced Perturbations (PIP), applies perturbations at detected idling
states, thus helping it to escape problematic basins of attraction. On a range
of challenging simulated dual-arm tasks, we find that this simple approach can
already noticeably improve test-time performance, with no additional
supervision or training. Furthermore, since the robot tends to idle at critical
points in a movement, we also find that learning from the resulting episodes
leads to better iterative policy improvement compared to prior approaches. Our
perturbation strategy also leads to a 15-35% improvement in absolute success
rate on a real-world insertion task that requires complex multi-finger
manipulation.

</details>


### [172] [Neural Robot Dynamics](https://arxiv.org/abs/2508.15755)
*Jie Xu,Eric Heiden,Iretiayo Akinola,Dieter Fox,Miles Macklin,Yashraj Narang*

Main category: cs.RO

TL;DR: 本文提出NeRD（神经机器人动力学），这是一种可学习的机器人特定动力学模型，用于对接触约束下的铰接刚体进行可泛化的神经模拟。它取代了传统解析模拟器中的低级求解器，并采用以机器人为中心、空间不变的状态表示，实现了稳定、准确、可泛化且可从真实数据微调的模拟。


<details>
  <summary>Details</summary>
Motivation: 现代机器人因其高自由度和复杂机制，其精确高效的模拟仍具挑战。现有神经模拟器通常需要特定应用训练，且由于全局状态表示不足，难以泛化到新任务和环境。

Method: 本文提出了NeRD（神经机器人动力学），一种学习到的机器人特定动力学模型，用于预测接触约束下铰接刚体的未来状态。NeRD独特地取代了解析模拟器中的低级动力学和接触求解器，并采用以机器人为中心、空间不变的模拟状态表示。学习到的NeRD模型被整合为最先进机器人模拟器中可互换的后端求解器。

Result: 实验结果表明，NeRD模拟器在数千步模拟中保持稳定和准确；能泛化到不同的任务和环境配置；可以在纯神经引擎中进行策略学习；并且与大多数经典模拟器不同，NeRD可以从真实世界数据进行微调，以弥合模拟与现实之间的差距。

Conclusion: NeRD为机器人提供了一种通用、准确且可从真实数据微调的神经模拟器，有效解决了现有神经模拟器泛化性差的问题，并为机器人模拟和策略学习提供了新的可能性。

Abstract: Accurate and efficient simulation of modern robots remains challenging due to
their high degrees of freedom and intricate mechanisms. Neural simulators have
emerged as a promising alternative to traditional analytical simulators,
capable of efficiently predicting complex dynamics and adapting to real-world
data; however, existing neural simulators typically require
application-specific training and fail to generalize to novel tasks and/or
environments, primarily due to inadequate representations of the global state.
In this work, we address the problem of learning generalizable neural
simulators for robots that are structured as articulated rigid bodies. We
propose NeRD (Neural Robot Dynamics), learned robot-specific dynamics models
for predicting future states for articulated rigid bodies under contact
constraints. NeRD uniquely replaces the low-level dynamics and contact solvers
in an analytical simulator and employs a robot-centric and spatially-invariant
simulation state representation. We integrate the learned NeRD models as an
interchangeable backend solver within a state-of-the-art robotics simulator. We
conduct extensive experiments to show that the NeRD simulators are stable and
accurate over a thousand simulation steps; generalize across tasks and
environment configurations; enable policy learning exclusively in a neural
engine; and, unlike most classical simulators, can be fine-tuned from
real-world data to bridge the gap between simulation and reality.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [173] [LyLA-Therm: Lyapunov-based Langevin Adaptive Thermodynamic Neural Network Controller](https://arxiv.org/abs/2508.14989)
*Saiedeh Akbari,Omkar Sudhir Patil,Warren E. Dixon*

Main category: eess.SY

TL;DR: 本文基于热力学原理和朗之万方程，为Lyapunov-based DNN控制方法提出了一种随机微分更新律（LyLA-Therm）。该方法通过最小化广义内能实现利用，并通过广义温度控制的随机噪声实现探索，在跟踪和参数估计误差方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络（DNN）控制方法中参数更新的探索与利用两难困境。

Method: 借鉴朗之万方程，开发了一种随机微分方程形式的更新律，用于基于Lyapunov的DNN控制。该更新律的漂移项旨在最小化系统的广义内能以实现利用，而扩散项由用户选择的广义温度定律控制，以确保受控的波动并实现探索。通过Lyapunov稳定性分析，证明了其概率收敛性。

Result: 所提出的LyLA-Therm神经网络控制器实现了跟踪和参数估计误差到最终界限的概率收敛。仿真结果显示，与基线确定性方法相比，LyLA-Therm架构在跟踪误差方面提高了20.66%，在函数逼近误差方面提高了20.89%，在离轨函数逼近误差方面提高了11.31%。

Conclusion: 基于热力学原理和朗之万方程设计的LyLA-Therm神经网络控制器，通过有效平衡广义内能最小化（利用）和温度控制噪声（探索），成功解决了DNN控制中的探索与利用困境，并在各项性能指标上显著优于基线确定性方法。

Abstract: Thermodynamic principles can be employed to design parameter update laws that
address challenges such as the exploration vs. exploitation dilemma. In this
paper, inspired by the Langevin equation, an update law is developed for a
Lyapunov-based DNN control method, taking the form of a stochastic differential
equation. The drift term is designed to minimize the system's generalized
internal energy, while the diffusion term is governed by a user-selected
generalized temperature law, allowing for more controlled fluctuations. The
minimization of generalized internal energy in this design fulfills the
exploitation objective, while the temperature-based stochastic noise ensures
sufficient exploration. Using a Lyapunov-based stability analysis, the proposed
Lyapunov-based Langevin Adaptive Thermodynamic (LyLA-Therm) neural network
controller achieves probabilistic convergence of the tracking and parameter
estimation errors to an ultimate bound. Simulation results demonstrate the
effectiveness of the proposed approach, with the LyLA-Therm architecture
achieving up to 20.66% improvement in tracking errors, up to 20.89% improvement
in function approximation errors, and up to 11.31% improvement in
off-trajectory function approximation errors compared to the baseline
deterministic approach.

</details>


### [174] [Structure-preserving Optimal Kron-based Reduction of Radial Distribution Networks](https://arxiv.org/abs/2508.15006)
*Omid Mokhtari,Samuel Chevalier,Mads Almassalkhi*

Main category: eess.SY

TL;DR: 本文改进了基于Kron最优网络缩减（Opti-KRON）框架，提升了其可扩展性并引入了辐射状保持步骤，实现了大规模电网的显著缩减和低电压误差，并加速了电压控制问题的求解。


<details>
  <summary>Details</summary>
Motivation: 大型输配电网的计算挑战促使了网络缩减技术的发展。传统的网络缩减方法通常依赖预定义的节点或线路，而Opti-KRON作为一种混合整数线性规划（MILP）方法，需要进一步提升其可扩展性和对网络拓扑特性（如辐射状）的保持能力。

Method: 本文在Opti-KRON（MILP）的基础上进行了两方面增强：1) 通过割平面限制、收紧的Big M界限和零注入节点缩减阶段提高了可扩展性。2) 引入了辐射状保持步骤，识别并恢复特定节点以确保缩减网络的辐射状特性。

Result: 该模型在533节点配电系统和3499节点实际馈线系统上进行了验证。在533节点系统上，实现了85%的缩减，最大电压误差低于0.0025 p.u.；在3499节点馈线系统上，实现了超过94%的缩减，最大电压误差低于0.002 p.u.。此外，研究表明辐射状化步骤能够加速Kron缩减网络上的最优电压控制问题的运行时间。

Conclusion: 通过引入可扩展性改进和辐射状保持步骤，增强的Opti-KRON框架能够对大规模电网进行高效且高精度的缩减，显著降低了计算复杂性，并且其辐射状保持特性有助于加速后续优化问题的求解。

Abstract: Network reduction simplifies complex electrical networks to address
computational challenges of large-scale transmission and distribution grids.
Traditional network reduction methods are often based on a predefined set of
nodes or lines to remain in the reduced network. This paper builds upon
previous work on Optimal Kron-based Reduction of Networks (Opti-KRON), which
was formulated as a mixed-integer linear program (MILP), to enhance the
framework in two aspects. First, the scalability is improved via a cutting
plane restriction, tightened Big~M bounds, and a zero-injection node reduction
stage. Next, we introduce a radiality-preservation step to identify and recover
nodes whose restoration ensures radiality of the reduced network. The model is
validated through its application to the 533-bus distribution test system and a
3499-bus realistic test feeder for a set of representative loading scenarios.
In the 533-bus system, an 85% reduction was achieved with a maximum voltage
error below 0.0025 p.u., while in the 3499-bus feeder, over 94% reduction was
obtained with maximum voltage errors below 0.002 p.u. Additionally, we show
that the radialization step accelerates the runtime of optimal voltage control
problems when applied to Kron-reduced networks.

</details>


### [175] [Discrete VHCs for Propeller Motion of a Devil-Stick using purely Impulsive Inputs](https://arxiv.org/abs/2508.15040)
*Aakash Khandelwal,Ranjan Mukherjee*

Main category: eess.SY

TL;DR: 本文提出了一种使用脉冲力控制魔术棒（devil-stick）在垂直平面内实现螺旋桨运动的方法，并引入了离散虚拟完整约束（DVHC）来解决这一轨道稳定问题。


<details>
  <summary>Details</summary>
Motivation: 魔术棒的螺旋桨运动是一个欠驱动的机器人杂耍问题，在现有文献中尚未被研究过。

Method: 本文首次引入了离散虚拟完整约束（DVHC）概念，通过在施加脉冲输入的离散时刻指定魔术棒质心位置与其姿态角的关系。这导出了离散零动态（DZD），并基于此设计了一个强制执行DVHC的控制器，以及一个基于脉冲控制庞加莱映射方法的轨道稳定控制器。研究了当连续脉冲输入之间旋转角度无限小时的连续受力情况。

Result: 离散零动态（DZD）提供了稳定螺旋桨运动的条件。通过仿真验证了所提出方法在轨迹设计和稳定方面的有效性。在极限情况下，问题可以简化为连续受力下的螺旋桨运动。

Conclusion: 所提出的离散虚拟完整约束（DVHC）方法对于魔术棒螺旋桨运动的轨迹设计和稳定是有效的。

Abstract: The control problem of realizing propeller motion of a devil-stick in the
vertical plane using impulsive forces applied normal to the stick is
considered. This problem is an example of underactuated robotic juggling and
has not been considered in the literature before. Inspired by virtual holonomic
constraints, the concept of discrete virtual holonomic constraints (DVHC) is
introduced for the first time to solve this orbital stabilization problem. At
the discrete instants when impulsive inputs are applied, the location of the
center-of-mass of the devil-stick is specified in terms of its orientation
angle. This yields the discrete zero dynamics (DZD), which provides conditions
for stable propeller motion. In the limiting case, when the rotation angle
between successive applications of impulsive inputs is chosen to be arbitrarily
small, the problem reduces to that of propeller motion under continuous
forcing. A controller that enforces the DVHC, and an orbit stabilizing
controller based on the impulse controlled Poincar\'e map approach are
presented. The efficacy of the approach to trajectory design and stabilization
is validated through simulations.

</details>


### [176] [Smart Charging Impact Analysis using Clustering Methods and Real-world Distribution Feeders](https://arxiv.org/abs/2508.15092)
*Ravi Raj Shrestha,Zhi Zhou,Limon Barua,Nazib Siddique,Karthikeyan Balasubramaniam,Yan Zhou,Lusha Wang*

Main category: eess.SY

TL;DR: 本研究评估了分时电价（TOU）和负荷平衡（LB）两种智能充电策略在七个真实馈线上的性能，以应对电动汽车（EV）集成对配电网的压力。结果表明，这两种策略都能有效管理电动汽车负荷，减少电网升级需求和成本，其中在电动汽车普及率高时，负荷平衡策略优于分时电价策略。


<details>
  <summary>Details</summary>
Motivation: 电动汽车的广泛普及将对现有配电基础设施造成额外压力，可能导致组件过载和电能质量下降。实施智能充电机制可以缓解这些不利影响，并推迟甚至避免电网升级。

Method: 本研究评估了分时电价（TOU）和负荷平衡（LB）两种智能充电策略的性能。使用k-均值聚类识别了七个具有代表性的真实馈线。通过时间序列稳态潮流分析，模拟了在四种不同的电动汽车注册情景和三个代表性日期（捕捉季节性负荷特征）下，两种策略对电动汽车充电影响。此外，还提出了一种以最小成本加强电网以支持电动汽车集成的电网升级策略。

Result: 研究结果表明，与没有智能充电策略的情况相比，分时电价和负荷平衡策略都能有效管理额外的电动汽车负荷，并减少现有基础设施的升级需求和成本。在高客户注册水平下，负荷平衡策略的性能优于分时电价策略。

Conclusion: 这些发现支持了智能充电在促进电动汽车集成、同时保持配电网络可靠性和降低投资成本方面的可行性。

Abstract: The anticipated widespread adoption of electric vehicles (EVs) necessitates a
critical evaluation of existing power distribution infrastructures, as EV
integration imposes additional stress on distribution networks that can lead to
component overloading and power quality degradation. Implementing smart
charging mechanisms can mitigate these adverse effects and defer or even avoid
upgrades. This study assesses the performance of two smart charging strategies
- Time of Use (TOU) pricing and Load Balancing (LB) on seven representative
real-world feeders identified using k-means clustering. A time series-based
steady-state load flow analysis was conducted on these feeders to simulate the
impact of EV charging under both strategies across four different EV enrollment
scenarios and three representative days to capture seasonal load
characteristics. A grid upgrade strategy has been proposed to strengthen the
power grid to support EV integration with minimal cost. Results demonstrate
that both TOU and LB strategies effectively manage the additional EV load with
reduced upgrade requirement and cost to existing infrastructure compared to the
case without smart charging strategies and LB outperforms TOU when the customer
enrollment levels are high. These findings support the viability of smart
charging in facilitating EV integration while maintaining distribution network
reliability and reducing investment cost.

</details>


### [177] [Locally Differentially Private Multi-Sensor Fusion Estimation With System Intrinsic Randomness](https://arxiv.org/abs/2508.15175)
*Xinhao Yan,Bo Chen,Hailong Huang*

Main category: eess.SY

TL;DR: 本文针对多传感器融合估计（MSFE）中的隐私保护问题，引入局部差分隐私（LDP）以克服传统集中式差分隐私（CDP）的局限性，并利用系统固有随机性和高斯机制实现LDP，设计最优融合估计器。


<details>
  <summary>Details</summary>
Motivation: 传统集中式差分隐私（CDP）主要保护融合中心的统计数据而非传感器个体数据，且适用于大规模系统，因此不适合多传感器融合估计（MSFE）中保护传感器个体隐私的需求。

Method: 本文引入局部差分隐私（LDP）来增强MSFE的隐私保护。基于MSFE的固有特性定义LDP，并证明LDP可以通过系统固有随机性实现。当固有随机性不足时，设计高斯机制，并结合系统信息和隐私预算确定注入高斯噪声协方差的下限。最后，在线性最小方差意义下，分别设计了固有扰动和额外扰动下的最优融合估计器。

Result: LDP被证明可以通过系统固有随机性实现，这是一个新颖的发现。确定了额外注入高斯噪声协方差的下限。设计了最优融合估计器，并通过数值模拟（包括一维和高维场景）验证了所提方法的有效性。

Conclusion: 本文成功将局部差分隐私应用于多传感器融合估计，克服了传统集中式差分隐私的局限性，并通过利用系统固有随机性和设计高斯机制，实现了有效的隐私保护和最优估计，并通过仿真验证了其有效性。

Abstract: This paper focuses on the privacy-preserving multi-sensor fusion estimation
(MSFE) problem with differential privacy considerations. Most existing research
efforts are directed towards the exploration of traditional differential
privacy, also referred to as centralized differential privacy (CDP). It is
important to note that CDP is tailored to protect the privacy of statistical
data at fusion center such as averages and sums rather than individual data at
sensors, which renders it inappropriate for MSFE. Additionally, the definitions
and assumptions of CDP are primarily applicable for large-scale systems that
require statistical results mentioned above. Therefore, to address these
limitations, this paper introduces a more recent advancement known as
\emph{local differential privacy (LDP)} to enhance the privacy of MSFE. We
provide some rigorous definitions about LDP based on the intrinsic properties
of MSFE rather than directly presenting the assumptions under CDP.
Subsequently, the LDP is proved to be realized with system intrinsic
randomness, which is useful and has never been considered before. Furthermore,
the Gaussian mechanism is designed when the intrinsic randomness is
insufficient. The lower bound of the covariance for extra injected Gaussian
noises is determined by integrating system information with privacy budgets.
Moreover, the optimal fusion estimators under intrinsic and extra disturbances
are respectively designed in the linear minimum variance sense. Finally, the
effectiveness of the proposed methods is verified through numerical
simulations, encompassing both one-dimensional and high-dimensional scenarios.

</details>


### [178] [Why we need a standardized state of health definition for electric vehicle battery packs -- a proposal for energy- and capacity-based metrics](https://arxiv.org/abs/2508.15517)
*Philip Bilfinger,Markus Schreiber,Philipp Rosner,Kareem Abo Gamra,Jan Schöberl,Cristina Grosu,Markus Lienkamp*

Main category: eess.SY

TL;DR: 本文提出了一种利用车载充电的标准化测量程序，用于评估电动汽车电池的容量和能量健康状态（SOH），并通过差分电压分析提供更深入的老化洞察。


<details>
  <summary>Details</summary>
Motivation: 电动汽车的续航里程和性能会因电池老化而下降，影响车辆整个生命周期的商业决策。目前，车级电池健康状态（SOH）的测量缺乏标准化方法，导致学术界和工业界没有明确共识，这阻碍了透明度和对电动汽车电池长期可靠性的信心。

Method: 提出了一种基于车载充电的标准化测量程序，用于评估容量和能量的健康状态，以实现可重复性和可扩展性。此外，还展示了差分电压分析（DVA）如何提供车辆层面电池老化的更深层见解。

Result: 本文提出了一种用于评估电动汽车电池健康状态（SOH）的标准化测量程序，并展示了差分电压分析（DVA）在提供电池老化深层见解方面的潜力。

Conclusion: 标准化对于提高透明度和建立对电动汽车电池包长期可靠性的信心至关重要。本文提出的标准化测量程序和差分电压分析方法有助于解决这一需求，并提供对电池老化的更深入理解。

Abstract: Range and performance are key customer-relevant properties of electric
vehicles. Both degrade over time due to battery aging, thus impacting business
decisions throughout a vehicle's lifecycle, such as efficient utilization and
asset valuation. For practical assessment, aging is often simplified into a
single figure of merit - the state of health - typically defined by the battery
pack's remaining capacity or energy. However, no standardized method for
measuring the state of health at the vehicle level has been established,
leaving both academia and industry without a clear consensus. Ultimately,
standardization is crucial to increase transparency and build confidence in the
long-term reliability of electric vehicles' battery packs. In this article, we
propose a standard measurement procedure for assessing the capacity- and
energy-based state of health, leveraging onboard charging to enable
reproducibility and scalability. Additionally, we demonstrate how differential
voltage analysis can provide deeper insights into battery aging at the vehicle
level.

</details>


### [179] [Data-Driven Abstraction and Synthesis for Stochastic Systems with Unknown Dynamics](https://arxiv.org/abs/2508.15543)
*Mahdi Nazeri,Thom Badings,Anne-Kathrin Schmuck,Sadegh Soudjani,Alessandro Abate*

Main category: eess.SY

TL;DR: 本文提出了一种数据驱动的方法，用于从噪声观测数据和系统Lipschitz常数上界中，构建具有未知非线性动力学的随机系统的有限状态区间马尔可夫决策过程（IMDP）抽象，以实现正确构造的控制策略综合。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是为具有未知动力学的随机动态系统，自动合成正确构造的控制策略。

Method: 该方法通过学习从采样数据中提取的抽象，将其表示为有限马尔可夫决策过程（MDP）的形式。具体来说，它提出了一种数据驱动技术，仅需要噪声的状态-输入-状态观测和系统Lipschitz常数的上界，来构建有限状态区间MDP（IMDP）抽象。然后结合标准模型检验技术，合成满足预定义置信度的概率时序属性（如“到达-避免”）的策略。

Result: 实验结果表明，该方法有效且鲁棒，能够合成满足概率时序属性（如“到达-避免”）且具有预定义置信度的策略。

Conclusion: 该研究提供了一种新颖的数据驱动技术，能够从噪声观测数据和Lipschitz常数上界中，为未知非线性随机系统构建IMDP抽象，从而实现具有预定义置信度的正确构造控制策略合成。

Abstract: We study the automated abstraction-based synthesis of correct-by-construction
control policies for stochastic dynamical systems with unknown dynamics. Our
approach is to learn an abstraction from sampled data, which is represented in
the form of a finite Markov decision process (MDP). In this paper, we present a
data-driven technique for constructing finite-state interval MDP (IMDP)
abstractions of stochastic systems with unknown nonlinear dynamics. As a
distinguishing and novel feature, our technique only requires (1) noisy
state-input-state observations and (2) an upper bound on the system's Lipschitz
constant. Combined with standard model-checking techniques, our IMDP
abstractions enable the synthesis of policies that satisfy probabilistic
temporal properties (such as "reach-while-avoid") with a predefined confidence.
Our experimental results show the effectiveness and robustness of our approach.

</details>


### [180] [Synthesis and SOS-based Stability Verification of a Neural-Network-Based Controller for a Two-wheeled Inverted Pendulum](https://arxiv.org/abs/2508.15616)
*Alvaro Detailleur,Dalim Wahby,Guillaume Ducard,Christopher Onder*

Main category: eess.SY

TL;DR: 本文首次建立了基于和方和(SOS)的稳定性验证程序对使用神经网络控制器(NNC)的应用控制问题的可行性和实用价值。通过模仿鲁棒、基于管的MPC，成功验证了NNC控制的两轮倒立摆系统的闭环稳定性，并获得了局部渐近稳定性和吸引域估计，实验结果表明NNC稳定了系统并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 将神经网络控制器(NNC)应用于实际控制问题时，需要对其闭环稳定性进行严格验证。传统的鲁棒模型预测控制器(MPC)虽然性能优异，但计算成本高昂，难以在嵌入式硬件上实时执行。因此，研究如何使NNC模仿鲁棒MPC的性能，同时通过可靠方法（如SOS）提供稳定性保证，是重要的研究方向。

Method: 1. 为两轮倒立摆系统开发状态估计器和面向控制的模型。2. 基于该模型合成基线线性二次调节器(LQR)和鲁棒、基于管的MPC。3. 采用通用合成程序生成模仿鲁棒、基于管的MPC的NNC。4. 对包含NNC的闭环系统应用基于和方和(SOS)的稳定性验证程序，以获得局部渐近稳定性证书和吸引域(RoA)的内部估计。5. 在物理两轮倒立摆系统上进行实验验证。

Result: 1. 基于SOS的稳定性验证程序成功验证了采用NNC的闭环系统的局部渐近稳定性，并获得了吸引域的相关内部估计。2. 实验结果表明，NNC不仅能稳定系统，而且在调节和参考跟踪任务中，与基线LQR相比，控制性能有所提高。

Conclusion: 基于和方和(SOS)的稳定性验证程序对于使用神经网络控制器(NNC)的应用控制问题具有可行性和实用价值。通过该程序，可以为模仿鲁棒MPC的NNC提供稳定性保证，同时在实际系统中实现更好的控制性能和实时执行能力。

Abstract: This work newly establishes the feasibility and practical value of a sum of
squares (SOS)-based stability verification procedure for applied control
problems utilizing neural-network-based controllers (NNCs). It successfully
verifies closed-loop stability properties of a NNC synthesized using a
generalizable procedure to imitate a robust, tube-based model predictive
controller (MPC) for a two-wheeled inverted pendulum demonstrator system. This
is achieved by first developing a state estimator and control-oriented model
for the two-wheeled inverted pendulum. Next, this control-oriented model is
used to synthesize a baseline linear-quadratic regulator (LQR) and a robust,
tube-based MPC, which is computationally too demanding for real-time execution
on the demonstrator system's embedded hardware. The generalizable synthesis
procedure generates an NNC imitating the robust, tube-based MPC. Via an
SOS-based stability verification procedure, a certificate of local asymptotic
stability and a relevant inner estimate of the region of attraction (RoA) are
obtained for the closed-loop system incorporating this NNC. Finally,
experimental results on the physical two-wheeled inverted pendulum demonstrate
that the NNC both stabilizes the system, and improves the control performance
compared to the baseline LQR in both regulation and reference-tracking tasks.

</details>


### [181] [A Central Chilled Water Plant Model for Designing Learning-Based Controllers](https://arxiv.org/abs/2508.15649)
*Zhong Guo,Prabir Barooah*

Main category: eess.SY

TL;DR: 本文提出了一种中央冷水机组（CCWP）建模框架，通过基于约束优化的方法改进了现有组件模型，确保模型在更宽泛的输入范围内尊重热交换器容量，从而提高了模型的有效性，并使其适用于训练学习型控制器。


<details>
  <summary>Details</summary>
Motivation: 现有组件模型在输入超出正常运行范围时会产生高度错误的结果，这对于需要探索超出正常运行条件输入的学习型控制器训练而言是一个重大缺陷。

Method: 开发了一个基于约束优化的框架，以改进现有文献中的组件模型。该框架确保模型无论输入如何，都尊重所有热交换器（冷却盘管、冷水机组和冷却塔）的容量。整个工厂模型在Matlab中实现并公开提供。

Result: 与现有模型相比，所提出的模型具有更广泛的有效范围，即使输入不在正常运行范围内，也不会产生高度错误的结果。这一特性对于训练能够选择超出正常运行条件输入的学习型控制器至关重要。

Conclusion: 所提出的建模框架提供了一个更鲁棒、更有效的中央冷水机组模型，克服了现有模型在非正常操作条件下准确性不足的问题，特别适用于开发和训练先进的学习型控制器。

Abstract: We describe a framework of modeling a central chilled
  water plant (CCWP) that consists of an aggregate
  cooling coil, a number of heterogeneous chillers and
  cooling towers, and a chilled water-based thermal
  energy storage system. We improve upon existing component
  models from the open literature using a constrained
  optimization-based framework to ensure that the models
  respect capacities of all the heat exchangers (cooling
  coils, chillers, and cooling towers) irrespective of
  the inputs provided. As a result, the proposed model has a wider
  range of validity compared to existing models; the
  latter can produce highly erroneous outputs when inputs are not
  within normal operating range. This
  feature is essential for training learning-based
  controllers that can choose inputs beyond normal operating conditions and is
lacking in currently available
  models. The overall plant model is
  implemented in Matlab and is made publicly
  available. Simulation of a CCWP with closed loop
  control is provided as an illustration.

</details>


### [182] [A 16.28 ppm/$^\circ$C Temperature Coefficient, 0.5V Low-Voltage CMOS Voltage Reference with Curvature Compensation](https://arxiv.org/abs/2508.15729)
*Harshith Reddy,Pankaj Arora*

Main category: eess.SY

TL;DR: 该论文提出了一种采用90纳米CMOS工艺和低阈值电压(LVT)晶体管设计的全集成电压基准，通过CTAT、PTAT和曲率校正电流的相互补偿，在0.5V低电源电压下实现了16.28 ppm/°C的低温度系数和0.67 μW的超低功耗。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在设计一种在低电源电压下工作、具有优异温度稳定性、低功耗和良好电源抑制比的全集成电压基准。

Method: 该设计采用90纳米CMOS工艺和低阈值电压(LVT)晶体管模型，利用亚阈值和近弱反型特性，并基于全区域MOSFET模型。通过CTAT、PTAT和曲率校正电流的相互补偿机制，实现了宽温度范围内的温度系数优化。

Result: 该电压基准在0.5V的低电源电压下工作，在-40°C至130°C的宽温度范围内实现了16.28 ppm/°C的低温度系数。它产生205 mV的稳定参考电压，具有1.65 %/V的线敏感度和在10 kHz下-50 dB的电源抑制比(PSRR)，同时功耗仅为0.67 μW。

Conclusion: 该论文成功设计并实现了一种在90纳米CMOS工艺下具有极低工作电压、出色温度稳定性、良好电源抑制比和超低功耗的全集成电压基准。

Abstract: This paper presents a fully-integrated CMOS voltage reference designed in a
90 nm process node using low voltage threshold (LVT) transistor models. The
voltage reference leverages subthreshold operation and near-weak inversion
characteristics, backed by an all-region MOSFET model. The proposed design
achieves a very low operating supply voltage of 0.5 V and a remarkably low
temperature coefficient of 16.28 ppm/$^\circ$C through the mutual compensation
of CTAT, PTAT, and curvature-correction currents, over a wide range from -40
$^\circ$C to 130 $^\circ$C. A stable reference voltage of 205 mV is generated
with a line sensitivity of 1.65 %/V and a power supply rejection ratio (PSRR)
of -50 dB at 10 kHz. The circuit achieves all these parameters while
maintaining a good power efficiency, consuming only 0.67 $\mu$W.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [183] [Pixels Under Pressure: Exploring Fine-Tuning Paradigms for Foundation Models in High-Resolution Medical Imaging](https://arxiv.org/abs/2508.14931)
*Zahra TehraniNasab,Amar Kumar,Tal Arbel*

Main category: eess.IV

TL;DR: 本文系统研究了在512x512高分辨率下，不同微调技术（包括全微调和PEFT）对扩散模型图像生成质量的影响，并评估了生成图像在数据稀缺下游分类任务中的实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在文本到图像生成方面取得了进展，但大多数工作局限于低分辨率。高分辨率图像合成在许多应用中至关重要，尤其是在医学成像领域。因此，需要研究微调机制以使预训练模型适应特定任务和数据分布。

Method: 本研究进行了一项系统性研究，考察了多种微调技术（包括全微调策略和参数高效微调PEFT）对512x512高分辨率图像生成质量的影响。评估指标包括Fréchet Inception Distance (FID)、Vendi score和提示-图像对齐度。此外，还在数据稀缺条件下，评估了生成图像在下游分类任务中的效用。

Result: 不同的微调方法会影响关键质量指标。特定的微调策略不仅能提高生成保真度，还能在合成图像用于分类器训练和真实图像评估时，改善下游任务的性能。

Conclusion: 本研究提供了一个系统性的分析，揭示了在扩展到高分辨率时，不同微调策略对扩散模型生成图像质量的影响，并证明了特定微调方法在数据稀缺的下游分类任务中具有实用性。

Abstract: Advancements in diffusion-based foundation models have improved text-to-image
generation, yet most efforts have been limited to low-resolution settings. As
high-resolution image synthesis becomes increasingly essential for various
applications, particularly in medical imaging domains, fine-tuning emerges as a
crucial mechanism for adapting these powerful pre-trained models to
task-specific requirements and data distributions. In this work, we present a
systematic study, examining the impact of various fine-tuning techniques on
image generation quality when scaling to high resolution 512x512 pixels. We
benchmark a diverse set of fine-tuning methods, including full fine-tuning
strategies and parameter-efficient fine-tuning (PEFT). We dissect how different
fine-tuning methods influence key quality metrics, including Fr\'echet
Inception Distance (FID), Vendi score, and prompt-image alignment. We also
evaluate the utility of generated images in a downstream classification task
under data-scarce conditions, demonstrating that specific fine-tuning
strategies improve both generation fidelity and downstream performance when
synthetic images are used for classifier training and evaluation on real
images. Our code is accessible through the project website -
https://tehraninasab.github.io/PixelUPressure/.

</details>


### [184] [TOM: An Open-Source Tongue Segmentation Method with Multi-Teacher Distillation and Task-Specific Data Augmentation](https://arxiv.org/abs/2508.14932)
*Jiacheng Xie,Ziyang Zhang,Biplab Poudel,Congyu Guo,Yang Yu,Guanghui An,Xiaoting Tang,Lening Zhao,Chunhui Xu,Dong Xu*

Main category: eess.IV

TL;DR: 本文提出了一种基于多教师知识蒸馏的舌像分割模型（TOM），结合扩散数据增强，显著减少了模型参数并提升了泛化能力。作者还将训练好的模型打包成易于使用的在线和离线工具，并证明了分割后的舌像补丁在体质分类中的优越性。


<details>
  <summary>Details</summary>
Motivation: 舌像分割质量对智能舌诊系统的诊断准确性至关重要，但现有舌像分割研究存在显著局限性，并且缺乏鲁棒且用户友好的分割工具。

Method: 本文提出了一种基于多教师知识蒸馏的舌像分割模型（TOM）。通过引入新颖的基于扩散的数据增强方法，增强了分割模型的泛化能力，同时减小了参数规模。此外，训练后的模型被打包并部署为在线和离线分割工具，并进行了中医体质分类的案例研究。

Result: 与教师模型相比，学生模型在参数量减少96.6%的情况下，仍达到了95.22%的mIoU分割性能。使用分割后的舌像补丁进行训练，在体质分类中取得了比原始舌像更高的分类性能和更好的可解释性。这是首个开源且免费的舌像分割工具。

Conclusion: 本文成功开发了一个高效、鲁棒且用户友好的舌像分割模型（TOM）及其工具，显著提升了智能舌诊系统的基础能力。分割后的舌像补丁在TCM体质分类中表现出优越性，为TCM从业者和研究人员提供了宝贵资源。

Abstract: Tongue imaging serves as a valuable diagnostic tool, particularly in
Traditional Chinese Medicine (TCM). The quality of tongue surface segmentation
significantly affects the accuracy of tongue image classification and
subsequent diagnosis in intelligent tongue diagnosis systems. However, existing
research on tongue image segmentation faces notable limitations, and there is a
lack of robust and user-friendly segmentation tools. This paper proposes a
tongue image segmentation model (TOM) based on multi-teacher knowledge
distillation. By incorporating a novel diffusion-based data augmentation
method, we enhanced the generalization ability of the segmentation model while
reducing its parameter size. Notably, after reducing the parameter count by
96.6% compared to the teacher models, the student model still achieves an
impressive segmentation performance of 95.22% mIoU. Furthermore, we packaged
and deployed the trained model as both an online and offline segmentation tool
(available at https://itongue.cn/), allowing TCM practitioners and researchers
to use it without any programming experience. We also present a case study on
TCM constitution classification using segmented tongue patches. Experimental
results demonstrate that training with tongue patches yields higher
classification performance and better interpretability than original tongue
images. To our knowledge, this is the first open-source and freely available
tongue image segmentation tool.

</details>


### [185] [Potential and challenges of generative adversarial networks for super-resolution in 4D Flow MRI](https://arxiv.org/abs/2508.14950)
*Oliver Welin Odeback,Arivazhagan Geetha Balasubramanian,Jonas Schollenberger,Edward Ferdiand,Alistair A. Young,C. Alberto Figueroa,Susanne Schnell,Outi Tammisola,Ricardo Vinuesa,Tobias Granberg,Alexander Fyrdahl,David Marlevi*

Main category: eess.IV

TL;DR: 本研究探索了基于生成对抗网络（GAN）的超分辨率技术在4D流动磁共振成像（4D Flow MRI）中的应用，旨在改善近壁速度测量。结果表明，精心选择的GAN（特别是Wasserstein GAN）能够有效提高近壁速度恢复的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 4D Flow MRI的临床应用受限于低空间分辨率和噪声，尤其影响近壁速度测量。机器学习超分辨率技术虽有前景，但在近壁速度恢复方面仍面临挑战。GAN在非医学超分辨率任务中展现出强大的锐利边界恢复能力，但在4D Flow MRI中尚未被探索，且其训练不稳定和不收敛等问题限制了应用。

Method: 研究采用基于GAN的超分辨率方法处理4D Flow MRI数据。训练和验证使用了患者特异性脑血管体内（in-silico）模型，通过MR真实重建管道转换为合成图像。实现了一个专门的GAN架构，并评估了三种对抗性损失函数：Vanilla、Relativistic和Wasserstein。通过与非对抗性参考（仅生成器）进行比较来评估性能。

Result: 所提出的GAN在近壁速度恢复方面优于非对抗性参考（vNRMSE: 6.9% vs. 9.6%）。实现细节对网络训练稳定性至关重要。Vanilla和Relativistic GANs相较于仅生成器训练表现不稳定（vNRMSE: 8.1%和7.8% vs. 7.2%），而Wasserstein GAN展现出最佳稳定性和渐进式改进（vNRMSE: 6.9% vs. 7.2%）。此外，在低信噪比（SNR）下，Wasserstein GAN优于仅生成器基线（vNRMSE: 8.7% vs. 10.7%）。

Conclusion: 研究结果强调了基于GAN的超分辨率技术在增强4D Flow MRI，尤其是在具有挑战性的脑血管区域的潜力，并强调了仔细选择对抗性策略（如Wasserstein GAN）的重要性，以确保稳定的网络训练和优越的性能。

Abstract: 4D Flow Magnetic Resonance Imaging (4D Flow MRI) enables non-invasive
quantification of blood flow and hemodynamic parameters. However, its clinical
application is limited by low spatial resolution and noise, particularly
affecting near-wall velocity measurements. Machine learning-based
super-resolution has shown promise in addressing these limitations, but
challenges remain, not least in recovering near-wall velocities. Generative
adversarial networks (GANs) offer a compelling solution, having demonstrated
strong capabilities in restoring sharp boundaries in non-medical
super-resolution tasks. Yet, their application in 4D Flow MRI remains
unexplored, with implementation challenged by known issues such as training
instability and non-convergence. In this study, we investigate GAN-based
super-resolution in 4D Flow MRI. Training and validation were conducted using
patient-specific cerebrovascular in-silico models, converted into synthetic
images via an MR-true reconstruction pipeline. A dedicated GAN architecture was
implemented and evaluated across three adversarial loss functions: Vanilla,
Relativistic, and Wasserstein. Our results demonstrate that the proposed GAN
improved near-wall velocity recovery compared to a non-adversarial reference
(vNRMSE: 6.9% vs. 9.6%); however, that implementation specifics are critical
for stable network training. While Vanilla and Relativistic GANs proved
unstable compared to generator-only training (vNRMSE: 8.1% and 7.8% vs. 7.2%),
a Wasserstein GAN demonstrated optimal stability and incremental improvement
(vNRMSE: 6.9% vs. 7.2%). The Wasserstein GAN further outperformed the
generator-only baseline at low SNR (vNRMSE: 8.7% vs. 10.7%). These findings
highlight the potential of GAN-based super-resolution in enhancing 4D Flow MRI,
particularly in challenging cerebrovascular regions, while emphasizing the need
for careful selection of adversarial strategies.

</details>


### [186] [CUTE-MRI: Conformalized Uncertainty-based framework for Time-adaptivE MRI](https://arxiv.org/abs/2508.14952)
*Paul Fischer,Jan Nikolas Morshuis,Thomas Küstner,Christian Baumgartner*

Main category: eess.IV

TL;DR: 该研究提出了一种动态、不确定性感知的MRI采集框架，通过迭代采样和不确定性评估，根据预设的精度目标自动调整扫描时间，从而实现患者个性化的、高效且具有统计学保证的MRI扫描。


<details>
  <summary>Details</summary>
Motivation: MRI扫描时间长是其主要限制，而基于深度学习的加速方法虽然能缩短时间，但重建过程中的不确定性（病态问题）会影响后续临床任务。传统的固定加速因子协议要么扫描时间过长，要么图像质量不足以满足临床需求，无法兼顾效率和质量。

Method: 该方法利用概率重建模型估计图像不确定性，并将其传播到下游分析管线，以量化特定指标（如髌骨软骨体积或心脏射血分数）。通过共形预测将不确定性转化为严格校准的置信区间。在采集过程中，系统迭代采样k空间，更新重建结果，并评估置信区间。当不确定性满足用户预定义的精度目标时，扫描自动终止。

Result: 该自适应方法与固定协议相比，显著减少了扫描时间，同时为最终图像的精度提供了正式的统计学保证。在膝关节和心脏MRI数据集上验证了其有效性。

Conclusion: 该框架超越了固定的加速因子，实现了患者特异性的采集，平衡了扫描效率与诊断信心，是迈向个性化和资源高效MRI的关键一步。

Abstract: Magnetic Resonance Imaging (MRI) offers unparalleled soft-tissue contrast but
is fundamentally limited by long acquisition times. While deep learning-based
accelerated MRI can dramatically shorten scan times, the reconstruction from
undersampled data introduces ambiguity resulting from an ill-posed problem with
infinitely many possible solutions that propagates to downstream clinical
tasks. This uncertainty is usually ignored during the acquisition process as
acceleration factors are often fixed a priori, resulting in scans that are
either unnecessarily long or of insufficient quality for a given clinical
endpoint. This work introduces a dynamic, uncertainty-aware acquisition
framework that adjusts scan time on a per-subject basis. Our method leverages a
probabilistic reconstruction model to estimate image uncertainty, which is then
propagated through a full analysis pipeline to a quantitative metric of
interest (e.g., patellar cartilage volume or cardiac ejection fraction). We use
conformal prediction to transform this uncertainty into a rigorous, calibrated
confidence interval for the metric. During acquisition, the system iteratively
samples k-space, updates the reconstruction, and evaluates the confidence
interval. The scan terminates automatically once the uncertainty meets a
user-predefined precision target. We validate our framework on both knee and
cardiac MRI datasets. Our results demonstrate that this adaptive approach
reduces scan times compared to fixed protocols while providing formal
statistical guarantees on the precision of the final image. This framework
moves beyond fixed acceleration factors, enabling patient-specific acquisitions
that balance scan efficiency with diagnostic confidence, a critical step
towards personalized and resource-efficient MRI.

</details>


### [187] [Scalable Event-Based Video Streaming for Machines with MoQ](https://arxiv.org/abs/2508.15003)
*Andrew C. Freeman*

Main category: eess.IV

TL;DR: 本文探讨了神经拟态事件传感器视频的传输问题，并提出了一种基于Media Over QUIC协议草案的低延迟事件流媒体格式。


<details>
  <summary>Details</summary>
Motivation: 传统的视频流主要关注有损压缩和速率自适应流媒体，但新型神经拟态事件传感器记录的是异步像素样本而非图像帧。这些传感器主要用于计算机视觉应用，而非人类观看。目前研究主要集中在应用开发，而忽略了关键的数据传输问题。

Method: 作者首先调查了现有基于事件的视频系统，然后讨论了其近期可扩展事件流媒体工作中的技术问题，并在此基础上提出了一种基于Media Over QUIC协议草案最新增补的低延迟事件流媒体格式。

Result: 提出了一种新的低延迟事件流媒体格式，该格式基于Media Over QUIC协议草案的最新进展。

Conclusion: 数据传输是基于事件的视频系统面临的关键挑战，需要专门的解决方案。本文提出了一种利用Media Over QUIC协议的新格式来解决低延迟事件流传输问题。

Abstract: Lossy compression and rate-adaptive streaming are a mainstay in traditional
video steams. However, a new class of neuromorphic ``event'' sensors records
video with asynchronous pixel samples rather than image frames. These sensors
are designed for computer vision applications, rather than human video
consumption. Until now, researchers have focused their efforts primarily on
application development, ignoring the crucial problem of data transmission. We
survey the landscape of event-based video systems, discuss the technical issues
with our recent scalable event streaming work, and propose a new low-latency
event streaming format based on the latest additions to the Media Over QUIC
protocol draft.

</details>


### [188] [Systematic Evaluation of Wavelet-Based Denoising for MRI Brain Images: Optimal Configurations and Performance Benchmarks](https://arxiv.org/abs/2508.15011)
*Asadullah Bin Rahman,Masud Ibn Afjal,Md. Abdulla Al Mamun*

Main category: eess.IV

TL;DR: 本研究调查了基于小波变换的医学图像去噪方法，发现bior6.8双正交小波结合通用阈值处理（分解级别2-3）能实现最佳去噪效果，同时保留关键诊断信息。


<details>
  <summary>Details</summary>
Motivation: 医学图像（如MRI、CT、超声）中的噪声污染会降低图像质量，掩盖诊断细节并影响临床决策。现有增强技术（如直方图均衡化）可能无意中放大噪声伪影（包括椒盐噪声），因此需要有效的去噪方法。

Method: 本研究通过系统评估不同噪声条件，调查了基于小波变换的去噪方法，旨在识别阈值、分解级别和小波类型的最佳组合，以实现卓越的去噪性能和增强的诊断准确性。

Result: 研究表明，bior6.8双正交小波结合通用阈值处理，在分解级别2-3时，能持续实现最佳去噪性能，显著减少噪声，同时保留了对临床应用至关重要的解剖结构和诊断特征。

Conclusion: 所确定的基于小波变换的去噪方法（bior6.8双正交小波、通用阈值、分解级别2-3）为医学图像去噪提供了一个有效且优化的解决方案，有助于提高诊断准确性。

Abstract: Medical imaging modalities including magnetic resonance imaging (MRI),
computed tomography (CT), and ultrasound are essential for accurate diagnosis
and treatment planning in modern healthcare. However, noise contamination
during image acquisition and processing frequently degrades image quality,
obscuring critical diagnostic details and compromising clinical
decision-making. Additionally, enhancement techniques such as histogram
equalization may inadvertently amplify existing noise artifacts, including
salt-and-pepper distortions. This study investigates wavelet transform-based
denoising methods for effective noise mitigation in medical images, with the
primary objective of identifying optimal combinations of threshold values,
decomposition levels, and wavelet types to achieve superior denoising
performance and enhanced diagnostic accuracy. Through systematic evaluation
across various noise conditions, the research demonstrates that the bior6.8
biorthogonal wavelet with universal thresholding at decomposition levels 2-3
consistently achieves optimal denoising performance, providing significant
noise reduction while preserving essential anatomical structures and diagnostic
features critical for clinical applications.

</details>


### [189] [SPIRiT Regularization: Parallel MRI with a Combination of Sensitivity Encoding and Linear Predictability](https://arxiv.org/abs/2508.15132)
*Nicholas Dwork,Alex McManus,Stephen Becker,Gennifer T. Smith*

Main category: eess.IV

TL;DR: 该研究结合了压缩感知与两种并行成像方法（线性可预测性与敏感度编码），并引入了SPIRiT正则化项，以提升加速MRI图像的重建质量。


<details>
  <summary>Details</summary>
Motivation: MRI加速成像旨在通过更少的采样和更快的扫描时间获取高质量图像，以提高成像效率。

Method: 该研究将压缩感知与两种并行成像方法（线性可预测性及敏感度编码）相结合，并引入了一种新颖的SPIRiT正则化项。

Result: 结合这些方法后，重建图像的质量得到了改善。研究结果在脑部、膝盖和脚踝数据上得到了验证。

Conclusion: 通过将压缩感知与两种并行成像方法以及SPIRiT正则化项结合，可以有效提高加速MRI图像的重建质量。

Abstract: Accelerated Magnetic Resonance Imaging (MRI) permits high quality images from
fewer samples that can be collected with a faster scan. Two established methods
for accelerating MRI include parallel imaging and compressed sensing. Two types
of parallel imaging include linear predictability, which assumes that the
Fourier samples are linearly related, and sensitivity encoding, which
incorporates a priori knowledge of the sensitivity maps. In this work, we
combine compressed sensing with both types of parallel imaging using a novel
regularization term: SPIRiT regularization. When combined, the reconstructed
images are improved. We demonstrate results on data of a brain, a knee, and an
ankle.

</details>


### [190] [Zero-shot Volumetric CT Super-Resolution using 3D Gaussian Splatting with Upsampled 2D X-ray Projection Priors](https://arxiv.org/abs/2508.15151)
*Jeonghyun Noh,Hyun-Jic Oh,Byungju Chae,Won-Ki Jeong*

Main category: eess.IV

TL;DR: 本文提出了一种新颖的零样本3D CT超分辨率框架，通过扩散模型生成高分辨率2D X射线投影作为先验，并结合改进的3D高斯泼溅（NAB-GS）方法，有效重建高细节的3D CT图像。


<details>
  <summary>Details</summary>
Motivation: 高分辨率CT图像采集存在辐射风险，而深度学习超分辨率方法面临挑战：监督方法需要难以获取的大规模配对LR-HR数据集；零样本方法虽无需配对数据，但因内部信息有限，难以恢复精细解剖细节。

Method: 1. 训练一个基于扩散模型生成器，利用丰富的HR 2D X射线数据生成高分辨率2D X射线投影，并引入逐投影自适应采样策略。2. 将这些高分辨率投影作为强大的外部先验输入到3D高斯泼溅模型中重建3D CT体素。3. 提出负Alpha混合高斯泼溅（NAB-GS），允许高斯密度表示中存在负值，从而实现LR与扩散生成投影之间的残差学习，增强高频结构重建。

Result: 在两个数据集上的实验结果表明，本文方法在3D CT超分辨率任务中取得了优越的定量和定性表现。

Conclusion: 所提出的零样本3D CT超分辨率框架，通过利用扩散模型生成的2D X射线先验和新颖的NAB-GS方法，有效克服了现有零样本方法的局限性，实现了卓越的3D CT高分辨率重建，尤其在恢复精细解剖细节方面表现突出。

Abstract: Computed tomography (CT) is widely used in clinical diagnosis, but acquiring
high-resolution (HR) CT is limited by radiation exposure risks. Deep
learning-based super-resolution (SR) methods have been studied to reconstruct
HR from low-resolution (LR) inputs. While supervised SR approaches have shown
promising results, they require large-scale paired LR-HR volume datasets that
are often unavailable. In contrast, zero-shot methods alleviate the need for
paired data by using only a single LR input, but typically struggle to recover
fine anatomical details due to limited internal information. To overcome these,
we propose a novel zero-shot 3D CT SR framework that leverages upsampled 2D
X-ray projection priors generated by a diffusion model. Exploiting the
abundance of HR 2D X-ray data, we train a diffusion model on large-scale 2D
X-ray projection and introduce a per-projection adaptive sampling strategy. It
selects the generative process for each projection, thus providing HR
projections as strong external priors for 3D CT reconstruction. These
projections serve as inputs to 3D Gaussian splatting for reconstructing a 3D CT
volume. Furthermore, we propose negative alpha blending (NAB-GS) that allows
negative values in Gaussian density representation. NAB-GS enables residual
learning between LR and diffusion-based projections, thereby enhancing
high-frequency structure reconstruction. Experiments on two datasets show that
our method achieves superior quantitative and qualitative results for 3D CT SR.

</details>


### [191] [Pathology-Informed Latent Diffusion Model for Anomaly Detection in Lymph Node Metastasis](https://arxiv.org/abs/2508.15236)
*Jiamu Wang,Keunho Byeon,Jinsol Song,Anh Nguyen,Sangjeong Ahn,Sung Hak Lee,Jin Tae Kwak*

Main category: eess.IV

TL;DR: 该研究提出了一种结合视觉-语言模型和去噪扩散概率模型的无监督异常检测方法，利用组织病理学提示词指导正常组织重建，以解决数字病理中数据标注稀缺的问题，并在胃和乳腺淋巴结数据集上展现了良好性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 数字病理学中的异常检测方法通常需要大量标注数据（监督学习），但数字病理领域存在数据稀缺问题。无监督异常检测提供了一种无需详尽标注的替代方案，通过识别与正常组织分布的偏差来发现异常。最近流行的去噪扩散概率模型在无监督异常检测中表现出色，但仍有改进空间。

Method: 本研究将视觉-语言模型（VLM）与扩散模型相结合，用于数字病理中的无监督异常检测。该方法在重建过程中利用与正常组织相关的病理学关键词（组织病理学提示词）来引导，从而促进正常和异常组织之间的区分。

Result: 该方法在来自当地医院的胃淋巴结数据集上进行了有效性评估。为了测试其在领域偏移下的泛化能力，还在一个公共乳腺淋巴结数据集上进行了评估。实验结果表明，所提出的方法在数字病理学中跨各种器官的无监督异常检测方面具有潜力。

Conclusion: 该研究提出的结合视觉-语言模型和扩散模型的无监督异常检测方法，通过利用组织病理学提示词指导重建，能够有效区分正常和异常组织。实验结果证实了该方法在不同器官（胃和乳腺）的数字病理异常检测中的有效性和泛化能力，展现了其广阔的应用前景。

Abstract: Anomaly detection is an emerging approach in digital pathology for its
ability to efficiently and effectively utilize data for disease diagnosis.
While supervised learning approaches deliver high accuracy, they rely on
extensively annotated datasets, suffering from data scarcity in digital
pathology. Unsupervised anomaly detection, however, offers a viable alternative
by identifying deviations from normal tissue distributions without requiring
exhaustive annotations. Recently, denoising diffusion probabilistic models have
gained popularity in unsupervised anomaly detection, achieving promising
performance in both natural and medical imaging datasets. Building on this, we
incorporate a vision-language model with a diffusion model for unsupervised
anomaly detection in digital pathology, utilizing histopathology prompts during
reconstruction. Our approach employs a set of pathology-related keywords
associated with normal tissues to guide the reconstruction process,
facilitating the differentiation between normal and abnormal tissues. To
evaluate the effectiveness of the proposed method, we conduct experiments on a
gastric lymph node dataset from a local hospital and assess its generalization
ability under domain shift using a public breast lymph node dataset. The
experimental results highlight the potential of the proposed method for
unsupervised anomaly detection across various organs in digital pathology.
Code: https://github.com/QuIIL/AnoPILaD.

</details>


### [192] [Explainable Knowledge Distillation for Efficient Medical Image Classification](https://arxiv.org/abs/2508.15251)
*Aqib Nazir Mir,Danish Raza Rizvi*

Main category: eess.IV

TL;DR: 本研究利用知识蒸馏技术，通过高容量教师模型指导轻量级学生模型，实现了在资源受限环境下对胸部X光图像进行高效且可解释的COVID-19和肺癌分类。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的临床环境中，需要开发既能保持高分类性能又具有计算效率和可解释性的医疗AI解决方案，以应对COVID-19和肺癌的诊断挑战。

Method: 研究采用知识蒸馏框架，使用VGG19、Visformer-S和AutoFormer-V2-T等高容量模型作为教师，指导从OFA-595超网派生出的紧凑型、硬件感知学生模型。方法结合了地面真值标签和教师模型的软目标进行混合监督训练。模型在COVID-QU-Ex和LCS25000两个基准数据集上进行验证，并使用Score-CAM进行可视化解释。

Result: 蒸馏后的学生模型在显著减少参数和推理时间的同时，保持了高分类性能，证明其在资源受限的临床环境中是一个理想的选择。

Conclusion: 本研究强调了将模型效率与可解释性相结合对于构建实用、可信赖的医疗AI解决方案的重要性，特别是在资源有限的临床环境中。

Abstract: This study comprehensively explores knowledge distillation frameworks for
COVID-19 and lung cancer classification using chest X-ray (CXR) images. We
employ high-capacity teacher models, including VGG19 and lightweight Vision
Transformers (Visformer-S and AutoFormer-V2-T), to guide the training of a
compact, hardware-aware student model derived from the OFA-595 supernet. Our
approach leverages hybrid supervision, combining ground-truth labels with
teacher models' soft targets to balance accuracy and computational efficiency.
We validate our models on two benchmark datasets: COVID-QU-Ex and LCS25000,
covering multiple classes, including COVID-19, healthy, non-COVID pneumonia,
lung, and colon cancer. To interpret the spatial focus of the models, we employ
Score-CAM-based visualizations, which provide insight into the reasoning
process of both teacher and student networks. The results demonstrate that the
distilled student model maintains high classification performance with
significantly reduced parameters and inference time, making it an optimal
choice in resource-constrained clinical environments. Our work underscores the
importance of combining model efficiency with explainability for practical,
trustworthy medical AI solutions.

</details>


### [193] [Bladder Cancer Diagnosis with Deep Learning: A Multi-Task Framework and Online Platform](https://arxiv.org/abs/2508.15379)
*Jinliang Yu,Mingduo Xie,Yue Wang,Tianfan Fu,Xianglai Xu,Jiajun Wang*

Main category: eess.IV

TL;DR: 本研究提出了一个集成多任务深度学习框架和在线平台，用于从膀胱镜图像中进行膀胱癌诊断，显著提高了诊断的准确性、效率和可及性。


<details>
  <summary>Details</summary>
Motivation: 当前的临床膀胱镜检查高度依赖医生经验，导致诊断结果存在变异性和主观性。因此，迫切需要客观、准确、高效的计算方法来改进膀胱癌诊断。

Method: 本研究提出了一个集成多任务深度学习框架：1. 分类模型：使用带有卷积块注意力模块（CBAM）增强的EfficientNet-B0。2. 分割模型：基于ResNet34-UNet++架构，结合自注意力机制和注意力门控。3. 分子亚型分类：使用ConvNeXt-Tiny对HER-2和Ki-67等分子标志物进行分类。此外，还开发了一个基于Gradio的在线诊断平台，集成了所有模型，提供多格式图像上传、双语界面和动态阈值调整等功能。

Result: 实验结果显示：分类任务达到了93.28%的准确率、82.05%的F1分数和96.41%的AUC。分割任务的Dice系数为0.9091。在线平台显著提高了临床膀胱癌诊断的准确性、效率和可及性。

Conclusion: 本研究的多任务框架和集成在线工具通过提高临床可靠性、支持早期肿瘤检测和实现实时诊断反馈，共同推动了智能膀胱癌诊断领域的发展，标志着泌尿科AI辅助决策迈出了重要一步。

Abstract: Clinical cystoscopy, the current standard for bladder cancer diagnosis,
suffers from significant reliance on physician expertise, leading to
variability and subjectivity in diagnostic outcomes. There is an urgent need
for objective, accurate, and efficient computational approaches to improve
bladder cancer diagnostics.
  Leveraging recent advancements in deep learning, this study proposes an
integrated multi-task deep learning framework specifically designed for bladder
cancer diagnosis from cystoscopic images. Our framework includes a robust
classification model using EfficientNet-B0 enhanced with Convolutional Block
Attention Module (CBAM), an advanced segmentation model based on
ResNet34-UNet++ architecture with self-attention mechanisms and attention
gating, and molecular subtyping using ConvNeXt-Tiny to classify molecular
markers such as HER-2 and Ki-67. Additionally, we introduce a Gradio-based
online diagnostic platform integrating all developed models, providing
intuitive features including multi-format image uploads, bilingual interfaces,
and dynamic threshold adjustments.
  Extensive experimentation demonstrates the effectiveness of our methods,
achieving outstanding accuracy (93.28%), F1-score (82.05%), and AUC (96.41%)
for classification tasks, and exceptional segmentation performance indicated by
a Dice coefficient of 0.9091. The online platform significantly improved the
accuracy, efficiency, and accessibility of clinical bladder cancer diagnostics,
enabling practical and user-friendly deployment. The code is publicly
available.
  Our multi-task framework and integrated online tool collectively advance the
field of intelligent bladder cancer diagnosis by improving clinical
reliability, supporting early tumor detection, and enabling real-time
diagnostic feedback. These contributions mark a significant step toward
AI-assisted decision-making in urology.

</details>


### [194] [DoSReMC: Domain Shift Resilient Mammography Classification using Batch Normalization Adaptation](https://arxiv.org/abs/2508.15452)
*Uğurcan Akyüz,Deniz Katircioglu-Öztürk,Emre K. Süslü,Burhan Keleş,Mete C. Kaya,Gamze Durhan,Meltem G. Akpınar,Figen B. Demirkazık,Gözde B. Akar*

Main category: eess.IV

TL;DR: DoSReMC是一个批归一化（BN）适应框架，通过仅微调BN和全连接层（FC）来增强乳腺癌乳腺X线摄影分类模型在跨域情况下的泛化能力，从而解决领域偏移问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在乳腺癌乳腺X线摄影图像识别中表现出色，但当应用于不同领域的数据时，由于领域偏移（数据分布差异），其性能显著下降。这限制了AI在真实临床环境中安全和公平的部署。

Method: 该研究提出了DoSReMC框架，通过仅微调预训练模型中的批归一化（BN）层和全连接（FC）层，同时保留卷积滤波器，以增强跨域泛化能力。此外，该方法还集成了对抗性训练方案以进一步提升泛化性。研究使用了三个大规模全视野数字乳腺X线摄影（FFDM）数据集进行系统性跨域评估。

Result: 研究发现BN层是领域依赖性的主要来源：它们在同域训练和测试时表现良好，但在领域偏移下显著损害模型泛化能力。DoSReMC通过有针对性地适应BN和FC层解决了这一限制，并显著提高了跨域泛化能力。结合对抗性训练进一步带来了额外改进。

Conclusion: DoSReMC提供了一种实用的方法，可以轻松整合到现有AI管线中，并应用于各种临床环境，从而实现更稳健和泛化能力更强的乳腺X线摄影分类系统。

Abstract: Numerous deep learning-based solutions have been developed for the automatic
recognition of breast cancer using mammography images. However, their
performance often declines when applied to data from different domains,
primarily due to domain shift - the variation in data distributions between
source and target domains. This performance drop limits the safe and equitable
deployment of AI in real-world clinical settings. In this study, we present
DoSReMC (Domain Shift Resilient Mammography Classification), a batch
normalization (BN) adaptation framework designed to enhance cross-domain
generalization without retraining the entire model. Using three large-scale
full-field digital mammography (FFDM) datasets - including HCTP, a newly
introduced, pathologically confirmed in-house dataset - we conduct a systematic
cross-domain evaluation with convolutional neural networks (CNNs). Our results
demonstrate that BN layers are a primary source of domain dependence: they
perform effectively when training and testing occur within the same domain, and
they significantly impair model generalization under domain shift. DoSReMC
addresses this limitation by fine-tuning only the BN and fully connected (FC)
layers, while preserving pretrained convolutional filters. We further integrate
this targeted adaptation with an adversarial training scheme, yielding
additional improvements in cross-domain generalizability. DoSReMC can be
readily incorporated into existing AI pipelines and applied across diverse
clinical environments, providing a practical pathway toward more robust and
generalizable mammography classification systems.

</details>


### [195] [Deep Equilibrium Convolutional Sparse Coding for Hyperspectral Image Denoising](https://arxiv.org/abs/2508.15553)
*Jin Ye,Jingran Wang,Fengchao Xiong,Jingzhou Chen,Yuntao Qian*

Main category: eess.IV

TL;DR: 本文提出了一种名为DECSC的深度平衡卷积稀疏编码框架，将深度平衡模型与卷积稀疏编码结合，统一了高光谱图像（HSI）去噪中的局部、非局部和全局特征，实现了卓越的去噪性能。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像去噪对遥感至关重要，但常受复杂噪声影响。现有基于深度展开的方法将物理模型优化映射到预定义深度的可学习网络，缺乏收敛性保证。深度平衡（DEQ）模型将深度网络的隐藏层视为不动点问题的解，模拟无限深度网络，与优化过程自然一致，从而激发了本研究。

Method: 本文提出了深度平衡卷积稀疏编码（DECSC）框架，用于鲁棒的HSI去噪，该框架统一了局部空谱相关性、非局部空间自相似性和全局空间一致性。具体方法包括：在卷积稀疏编码（CSC）框架内，采用共享2D卷积稀疏表示以确保跨波段的全局空间一致性；采用非共享3D卷积稀疏表示以捕获局部空谱细节；在2D CSC之后嵌入Transformer块以利用非局部自相似性；将细节增强模块与3D CSC集成以促进图像细节保留。此外，将CSC模型的近端梯度下降公式化为不动点问题，并在DEQ框架内将迭代更新转换为可学习的网络架构。

Result: 实验结果表明，DECSC方法在去噪性能方面优于现有最先进的方法。

Conclusion: DECSC框架通过结合深度平衡模型和卷积稀疏编码，并有效整合局部空谱相关性、非局部空间自相似性和全局空间一致性，为高光谱图像去噪提供了一种新颖且性能优越的解决方案。

Abstract: Hyperspectral images (HSIs) play a crucial role in remote sensing but are
often degraded by complex noise patterns. Ensuring the physical property of the
denoised HSIs is vital for robust HSI denoising, giving the rise of deep
unfolding-based methods. However, these methods map the optimization of a
physical model to a learnable network with a predefined depth, which lacks
convergence guarantees. In contrast, Deep Equilibrium (DEQ) models treat the
hidden layers of deep networks as the solution to a fixed-point problem and
models them as infinite-depth networks, naturally consistent with the
optimization. Under the framework of DEQ, we propose a Deep Equilibrium
Convolutional Sparse Coding (DECSC) framework that unifies local
spatial-spectral correlations, nonlocal spatial self-similarities, and global
spatial consistency for robust HSI denoising. Within the convolutional sparse
coding (CSC) framework, we enforce shared 2D convolutional sparse
representation to ensure global spatial consistency across bands, while
unshared 3D convolutional sparse representation captures local spatial-spectral
details. To further exploit nonlocal self-similarities, a transformer block is
embedded after the 2D CSC. Additionally, a detail enhancement module is
integrated with the 3D CSC to promote image detail preservation. We formulate
the proximal gradient descent of the CSC model as a fixed-point problem and
transform the iterative updates into a learnable network architecture within
the framework of DEQ. Experimental results demonstrate that our DECSC method
achieves superior denoising performance compared to state-of-the-art methods.

</details>


### [196] [Are Virtual DES Images a Valid Alternative to the Real Ones?](https://arxiv.org/abs/2508.15594)
*Ana C. Perre,Luís A. Alexandre,Luís C. Freire*

Main category: eess.IV

TL;DR: 本研究旨在通过图像到图像转换技术，从低能（LE）图像生成虚拟双能减影（DES）图像，以减少对比增强谱乳腺摄影（CESM）中的辐射暴露，并评估这些虚拟DES图像对病变分类的影响。


<details>
  <summary>Details</summary>
Motivation: 对比增强谱乳腺摄影（CESM）生成两种图像：低能（LE）图像和双能减影（DES）图像。DES图像的获取涉及高能X射线，增加了患者的辐射暴露。通过从LE图像人工生成DES图像，有望减少患者的辐射剂量。

Method: 研究使用了三种图像到图像转换模型来生成虚拟DES图像：预训练的U-Net模型、端到端训练的U-Net模型和CycleGAN模型。随后，评估了使用这些虚拟DES图像对CESM检查进行恶性与非恶性分类的影响。

Result: 预训练的U-Net模型在虚拟DES图像生成方面表现最佳，使用虚拟DES图像进行分类的F1分数为85.59%，而使用真实DES图像的F1分数为90.35%。真实DES图像中额外的诊断信息可能是导致性能差异的原因。

Conclusion: 虚拟DES图像生成具有巨大潜力，有望减少患者辐射暴露。尽管目前虚拟DES图像在分类准确性上与真实DES图像存在差距，但未来的技术进步可能会缩小这一差距，使仅依赖虚拟DES图像在临床上成为可能。

Abstract: Contrast-enhanced spectral mammography (CESM) is an imaging modality that
provides two types of images, commonly known as low-energy (LE) and dual-energy
subtracted (DES) images. In many domains, particularly in medicine, the
emergence of image-to-image translation techniques has enabled the artificial
generation of images using other images as input. Within CESM, applying such
techniques to generate DES images from LE images could be highly beneficial,
potentially reducing patient exposure to radiation associated with high-energy
image acquisition. In this study, we investigated three models for the
artificial generation of DES images (virtual DES): a pre-trained U-Net model, a
U-Net trained end-to-end model, and a CycleGAN model. We also performed a
series of experiments to assess the impact of using virtual DES images on the
classification of CESM examinations into malignant and non-malignant
categories. To our knowledge, this is the first study to evaluate the impact of
virtual DES images on CESM lesion classification. The results demonstrate that
the best performance was achieved with the pre-trained U-Net model, yielding an
F1 score of 85.59% when using the virtual DES images, compared to 90.35% with
the real DES images. This discrepancy likely results from the additional
diagnostic information in real DES images, which contributes to a higher
classification accuracy. Nevertheless, the potential for virtual DES image
generation is considerable and future advancements may narrow this performance
gap to a level where exclusive reliance on virtual DES images becomes
clinically viable.

</details>


### [197] [Label Uncertainty for Ultrasound Segmentation](https://arxiv.org/abs/2508.15635)
*Malini Shivaram,Gautam Rajendrakumar Gare,Laura Hutchins,Jacob Duplantis,Thomas Deiss,Thales Nogueira Gomes,Thong Tran,Keyur H. Patel,Thomas H Fox,Amita Krishnan,Deva Ramanan,Bennett DeBoisblanc,Ricardo Rodriguez,John Galeotti*

Main category: eess.IV

TL;DR: 本研究提出一种利用专家提供的像素级置信度值进行标注和训练AI模型的方法，以解决医学影像（特别是肺部超声）中的标签不确定性问题，并证明该方法能显著提升分割性能和下游临床任务的表现。


<details>
  <summary>Details</summary>
Motivation: 医学影像中，放射科医生之间的观察者间差异常导致标签不确定性，尤其在肺部超声等主观性强的模态中，图像常包含模糊区域和清晰结构，使得一致性标注极具挑战性。

Method: 设计了一种数据标注协议，捕捉放射科医生对每个标注区域的像素级置信度，以建模临床数据中固有的不确定性。在AI模型训练中融入这些置信度值，并通过系统性地调查不同置信度阈值（例如60% vs 50%）下二值化标签的训练效果，评估其对分割指标和下游临床结果的影响。

Result: 将置信度值纳入训练能改善分割性能。更重要的是，这种增强的分割质量能转化为下游关键临床任务（如估算S/F氧合比、分类S/F比变化、预测30天患者再入院）的更好表现。研究发现，使用60%置信度阈值获得的二值化标签训练模型效果良好，且高阈值（如60%）远优于朴素的50%阈值方法，表明在高度自信的像素上训练更有效。

Conclusion: 标签置信度是一个有价值的信号，如果利用得当，可以显著提高AI在医学影像中的可靠性和临床实用性。

Abstract: In medical imaging, inter-observer variability among radiologists often
introduces label uncertainty, particularly in modalities where visual
interpretation is subjective. Lung ultrasound (LUS) is a prime example-it
frequently presents a mixture of highly ambiguous regions and clearly
discernible structures, making consistent annotation challenging even for
experienced clinicians. In this work, we introduce a novel approach to both
labeling and training AI models using expert-supplied, per-pixel confidence
values. Rather than treating annotations as absolute ground truth, we design a
data annotation protocol that captures the confidence that radiologists have in
each labeled region, modeling the inherent aleatoric uncertainty present in
real-world clinical data. We demonstrate that incorporating these confidence
values during training leads to improved segmentation performance. More
importantly, we show that this enhanced segmentation quality translates into
better performance on downstream clinically-critical tasks-specifically,
estimating S/F oxygenation ratio values, classifying S/F ratio change, and
predicting 30-day patient readmission. While we empirically evaluate many
methods for exposing the uncertainty to the learning model, we find that a
simple approach that trains a model on binarized labels obtained with a (60%)
confidence threshold works well. Importantly, high thresholds work far better
than a naive approach of a 50% threshold, indicating that training on very
confident pixels is far more effective. Our study systematically investigates
the impact of training with varying confidence thresholds, comparing not only
segmentation metrics but also downstream clinical outcomes. These results
suggest that label confidence is a valuable signal that, when properly
leveraged, can significantly enhance the reliability and clinical utility of AI
in medical imaging.

</details>


### [198] [Hessian-based lightweight neural network for brain vessel segmentation on a minimal training dataset](https://arxiv.org/abs/2508.15660)
*Alexandra Bernadotte,Elfimov Nikita,Mikhail Shutov,Ivan Menshikov*

Main category: eess.IV

TL;DR: 本文提出了一种名为HessNet的轻量级半监督神经网络，结合Hessian矩阵进行脑部MRA血管的3D分割，并在极少量训练数据下达到了SOTA精度。该网络用于辅助创建了一个大型半手动标注的脑血管数据集，以解决公开MRA数据集缺乏详细标注的问题。


<details>
  <summary>Details</summary>
Motivation: 脑部MRA血管的精确分割对于动脉瘤修复或搭桥手术等外科手术至关重要。目前，主要依赖手动分割或传统方法（如Frangi滤波器），但这些方法往往精度不足。尽管神经网络在医学图像分割中表现强大，但其发展受限于高质量的标注训练数据集，而目前公开的MRA脑血管标注数据集严重缺乏。

Method: 本文提出了一种名为HessNet的新型轻量级半监督神经网络，该网络结合了Hessian矩阵，用于复杂管状结构（如血管）的3D分割。HessNet仅有6000个参数，可在CPU上运行，显著降低了训练资源需求。该网络还被用于辅助专家进行半手动标注，从而创建了一个基于IXI数据集的大型脑部MRA血管数据集（标注了200张图像）。

Result: HessNet在极少量训练数据集上实现了最先进的血管分割精度。该网络非常轻量级，可以在CPU上运行，并且显著减少了神经网络训练所需的资源。通过HessNet的辅助，三位专家在三位神经血管外科医生的监督下，成功创建了一个包含200张图像的大型半手动标注脑血管数据集，该方法提高了血管分割的准确性，并使专家能够专注于最复杂的病例。

Conclusion: HessNet作为一种结合Hessian矩阵的轻量级半监督神经网络，在MRA脑血管3D分割方面表现出高精度，并显著降低了资源需求。它不仅提供了一个有效的分割工具，还成功解决了高质量标注MRA数据集缺乏的问题，通过辅助专家创建了一个大型数据集，为未来的研究和临床应用提供了宝贵的资源。

Abstract: Accurate segmentation of blood vessels in brain magnetic resonance
angiography (MRA) is essential for successful surgical procedures, such as
aneurysm repair or bypass surgery. Currently, annotation is primarily performed
through manual segmentation or classical methods, such as the Frangi filter,
which often lack sufficient accuracy. Neural networks have emerged as powerful
tools for medical image segmentation, but their development depends on
well-annotated training datasets. However, there is a notable lack of publicly
available MRA datasets with detailed brain vessel annotations.
  To address this gap, we propose a novel semi-supervised learning lightweight
neural network with Hessian matrices on board for 3D segmentation of complex
structures such as tubular structures, which we named HessNet. The solution is
a Hessian-based neural network with only 6000 parameters. HessNet can run on
the CPU and significantly reduces the resource requirements for training neural
networks. The accuracy of vessel segmentation on a minimal training dataset
reaches state-of-the-art results. It helps us create a large, semi-manually
annotated brain vessel dataset of brain MRA images based on the IXI dataset
(annotated 200 images). Annotation was performed by three experts under the
supervision of three neurovascular surgeons after applying HessNet. It provides
high accuracy of vessel segmentation and allows experts to focus only on the
most complex important cases. The dataset is available at
https://git.scinalytics.com/terilat/VesselDatasetPartly.

</details>
