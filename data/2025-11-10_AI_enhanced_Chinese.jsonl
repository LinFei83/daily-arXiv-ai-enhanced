{"id": "2511.04892", "categories": ["eess.IV", "cs.CV", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2511.04892", "abs": "https://arxiv.org/abs/2511.04892", "authors": ["Vasileios Magoulianitis", "Catherine A. Alexander", "Jiaxin Yang", "C. -C. Jay Kuo"], "title": "LG-NuSegHop: A Local-to-Global Self-Supervised Pipeline For Nuclei Instance Segmentation", "comment": "42 pages, 8 figures, 7 tables", "summary": "Nuclei segmentation is the cornerstone task in histology image reading,\nshedding light on the underlying molecular patterns and leading to disease or\ncancer diagnosis. Yet, it is a laborious task that requires expertise from\ntrained physicians. The large nuclei variability across different organ tissues\nand acquisition processes challenges the automation of this task. On the other\nhand, data annotations are expensive to obtain, and thus, Deep Learning (DL)\nmodels are challenged to generalize to unseen organs or different domains. This\nwork proposes Local-to-Global NuSegHop (LG-NuSegHop), a self-supervised\npipeline developed on prior knowledge of the problem and molecular biology.\nThere are three distinct modules: (1) a set of local processing operations to\ngenerate a pseudolabel, (2) NuSegHop a novel data-driven feature extraction\nmodel and (3) a set of global operations to post-process the predictions of\nNuSegHop. Notably, even though the proposed pipeline uses { no manually\nannotated training data} or domain adaptation, it maintains a good\ngeneralization performance on other datasets. Experiments in three publicly\navailable datasets show that our method outperforms other self-supervised and\nweakly supervised methods while having a competitive standing among fully\nsupervised methods. Remarkably, every module within LG-NuSegHop is transparent\nand explainable to physicians.", "AI": {"tldr": "LG-NuSegHop是一种自监督细胞核分割方法，无需手动标注数据或领域适应，在多个数据集中表现出良好的泛化能力和竞争力，且模块透明可解释。", "motivation": "细胞核分割是组织学图像分析的基础任务，对疾病诊断至关重要。然而，由于细胞核在不同组织和采集过程中的巨大变异性，以及数据标注成本高昂，导致自动化该任务极具挑战性，深度学习模型难以泛化到未见器官或不同领域。", "method": "本文提出了Local-to-Global NuSegHop (LG-NuSegHop)，一个基于问题先验知识和分子生物学的自监督流程。它包含三个模块：(1) 一组局部处理操作以生成伪标签；(2) NuSegHop，一个新颖的数据驱动特征提取模型；(3) 一组全局操作来后处理NuSegHop的预测。值得注意的是，该流程不使用任何手动标注的训练数据或领域适应。", "result": "在三个公开可用数据集上的实验表明，LG-NuSegHop优于其他自监督和弱监督方法，同时在完全监督方法中也具有竞争力。该方法保持了良好的泛化性能。此外，LG-NuSegHop的每个模块都对医生透明且可解释。", "conclusion": "LG-NuSegHop提供了一种有效、可泛化且对医生可解释的自监督细胞核分割解决方案，克服了传统方法对大量手动标注数据的依赖，并在不同数据集上展现出强大的性能。"}}
{"id": "2511.04827", "categories": ["cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04827", "abs": "https://arxiv.org/abs/2511.04827", "authors": ["Tobias Fischer", "Wolf Vollprecht", "Bas Zalmstra", "Ruben Arts", "Tim de Jager", "Alejandro Fontan", "Adam D Hines", "Michael Milford", "Silvio Traversaro", "Daniel Claes", "Scarlett Raine"], "title": "Pixi: Unified Software Development and Distribution for Robotics and AI", "comment": "20 pages, 3 figures, 11 code snippets", "summary": "The reproducibility crisis in scientific computing constrains robotics\nresearch. Existing studies reveal that up to 70% of robotics algorithms cannot\nbe reproduced by independent teams, while many others fail to reach deployment\nbecause creating shareable software environments remains prohibitively complex.\nThese challenges stem from fragmented, multi-language, and hardware-software\ntoolchains that lead to dependency hell. We present Pixi, a unified\npackage-management framework that addresses these issues by capturing exact\ndependency states in project-level lockfiles, ensuring bit-for-bit\nreproducibility across platforms. Its high-performance SAT solver achieves up\nto 10x faster dependency resolution than comparable tools, while integration of\nthe conda-forge and PyPI ecosystems removes the need for multiple managers.\nAdopted in over 5,300 projects since 2023, Pixi reduces setup times from hours\nto minutes and lowers technical barriers for researchers worldwide. By enabling\nscalable, reproducible, collaborative research infrastructure, Pixi accelerates\nprogress in robotics and AI.", "AI": {"tldr": "Pixi是一个统一的包管理框架，通过捕获精确的依赖状态，解决了机器人和AI研究中软件环境的不可复现性问题，显著提高了依赖解析速度并降低了技术门槛。", "motivation": "机器人研究面临着科学计算中的可复现性危机，多达70%的算法无法被独立团队复现，且许多算法因创建可共享软件环境过于复杂而未能部署。这些问题源于碎片化、多语言、软硬件混合的工具链导致的“依赖地狱”。", "method": "本文提出了Pixi，一个统一的包管理框架。它通过在项目级锁定文件中捕获精确的依赖状态，确保跨平台的位对位复现性。Pixi采用高性能SAT求解器，并集成了conda-forge和PyPI生态系统，从而无需使用多个管理器。", "result": "Pixi实现了位对位复现性，其高性能SAT求解器使依赖解析速度比同类工具快10倍。自2023年以来，Pixi已被超过5300个项目采用，将设置时间从数小时缩短至数分钟，并降低了全球研究人员的技术障碍。", "conclusion": "通过提供可扩展、可复现、协作式的研究基础设施，Pixi加速了机器人和AI领域的进展。"}}
{"id": "2511.04812", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04812", "abs": "https://arxiv.org/abs/2511.04812", "authors": ["Zixuan Huang", "Huaidian Hou", "Dmitry Berenson"], "title": "Unified Multimodal Diffusion Forcing for Forceful Manipulation", "comment": "Project website: https://unified-df.github.io", "summary": "Given a dataset of expert trajectories, standard imitation learning\napproaches typically learn a direct mapping from observations (e.g., RGB\nimages) to actions. However, such methods often overlook the rich interplay\nbetween different modalities, i.e., sensory inputs, actions, and rewards, which\nis crucial for modeling robot behavior and understanding task outcomes. In this\nwork, we propose Multimodal Diffusion Forcing, a unified framework for learning\nfrom multimodal robot trajectories that extends beyond action generation.\nRather than modeling a fixed distribution, MDF applies random partial masking\nand trains a diffusion model to reconstruct the trajectory. This training\nobjective encourages the model to learn temporal and cross-modal dependencies,\nsuch as predicting the effects of actions on force signals or inferring states\nfrom partial observations. We evaluate MDF on contact-rich, forceful\nmanipulation tasks in simulated and real-world environments. Our results show\nthat MDF not only delivers versatile functionalities, but also achieves strong\nperformance, and robustness under noisy observations. More visualizations can\nbe found on our website https://unified-df.github.io", "AI": {"tldr": "本文提出了一种名为多模态扩散强制 (MDF) 的统一框架，通过对机器人轨迹进行随机部分掩码并使用扩散模型进行重建，学习跨模态和时间依赖性，从而超越传统的模仿学习，实现多功能性、高性能和对噪声的鲁棒性。", "motivation": "标准的模仿学习方法通常只学习从观测到动作的直接映射，忽略了感觉输入、动作和奖励之间丰富的多模态交互，而这些交互对于建模机器人行为和理解任务结果至关重要。", "method": "本文提出了多模态扩散强制 (MDF) 框架。它不建模固定的分布，而是对多模态机器人轨迹应用随机部分掩码，并训练一个扩散模型来重建整个轨迹。这种训练目标鼓励模型学习时间依赖性和跨模态依赖性，例如预测动作对力信号的影响或从部分观测推断状态。", "result": "MDF 在模拟和真实世界的接触密集型、强力操纵任务中进行了评估。结果表明，MDF 不仅提供了多功能性，而且实现了强大的性能，并在噪声观测下表现出鲁棒性。", "conclusion": "MDF 是一个统一的框架，能够从多模态机器人轨迹中学习，通过重建掩码轨迹来捕捉复杂的跨模态和时间依赖性，从而在具有挑战性的机器人任务中实现多功能性、高性能和对噪声的鲁棒性。"}}
{"id": "2511.04917", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04917", "abs": "https://arxiv.org/abs/2511.04917", "authors": ["Shadrack T. Asiedu", "Tara Aryal", "Zongjie Wang", "Hossein Moradi Rekabdarkolaee", "Timothy M. Hansen"], "title": "Computationally Efficient Spline-Based Modeling of DER Dynamics for Voltage Stability in Active Distribution Networks", "comment": null, "summary": "The increasing integration of Distributed Energy Resources (DERs) into power\nsystems necessitates the accurate representation of their dynamic behavior at\nthe transmission level. Traditional electromagnetic transient models (EMT),\nwhile effective, face scalability challenges due to their reliance on detailed\nsystem information. Data-driven approaches, such as System Identification\n(SysID), offer a promising alternative by modeling system dynamics without\ndetailed system knowledge. However, SysID and similar methods are\ncomputationally intensive, requiring the computation of complex ordinary\ndifferential equations (ODEs) or transfer functions estimation. This makes them\nless effective for real-time operation. We therefore propose a novel\ndata-driven approach that simplifies the modeling of DERs dynamics by\nleveraging B-splines to transform discrete system data into continuous\ndifferentiable functions. This enables the estimation of lower order linear\nordinary differential equations with simple linear regression to represent the\nunderlying dynamics at a very low computational cost. Furthermore, the\nextracted dynamic equations are discretized by the backward Euler method for\npotential integration into discrete-time power dispatch models. Validation\nresults indicate a goodness-of-fit (GoF) of 98.74%, comparable to the 99.03%\nGoF of the SysID method, yet, 4.8 times faster. Our proposed model's execution\ntime of less than one minute makes it more suitable for real-time applications\nin power system operations.", "AI": {"tldr": "本文提出了一种基于B样条的低计算成本数据驱动方法，用于建模分布式能源（DER）的动态行为，通过将离散数据转换为连续可微函数，并利用线性回归估计低阶常微分方程，以实现接近传统系统辨识方法的精度，但速度快4.8倍，适用于电力系统实时应用。", "motivation": "随着分布式能源（DERs）日益整合到电力系统中，准确表示其在输电层面的动态行为变得至关重要。传统的电磁暂态模型（EMT）因对详细系统信息的依赖而面临可扩展性挑战。数据驱动方法（如系统辨识，SysID）虽然无需详细系统知识，但计算成本高昂，不适用于实时操作。", "method": "本文提出了一种新颖的数据驱动方法。该方法利用B样条将离散系统数据转换为连续可微函数，从而能够通过简单的线性回归估计低阶线性常微分方程来表示底层动态，大大降低了计算成本。此外，提取的动态方程通过后向欧拉法离散化，以便集成到离散时间电力调度模型中。", "result": "验证结果显示，所提模型的拟合优度（GoF）为98.74%，与系统辨识方法99.03%的GoF相当。然而，其运行速度比系统辨识方法快4.8倍。模型执行时间少于一分钟，这使其更适合电力系统运行中的实时应用。", "conclusion": "本文提出的基于B样条的数据驱动模型能够以极低的计算成本准确表示分布式能源的动态行为，其高精度和显著的计算速度优势使其非常适用于电力系统中的实时应用。"}}
{"id": "2511.04758", "categories": ["cs.RO", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04758", "abs": "https://arxiv.org/abs/2511.04758", "authors": ["Caelan Garrett", "Fabio Ramos"], "title": "ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling", "comment": "Project website: https://schedulestream.github.io", "summary": "Bimanual and humanoid robots are appealing because of their human-like\nability to leverage multiple arms to efficiently complete tasks. However,\ncontrolling multiple arms at once is computationally challenging due to the\ngrowth in the hybrid discrete-continuous action space. Task and Motion Planning\n(TAMP) algorithms can efficiently plan in hybrid spaces but generally produce\nplans, where only one arm is moving at a time, rather than schedules that allow\nfor parallel arm motion. In order to extend TAMP to produce schedules, we\npresent ScheduleStream, the first general-purpose framework for planning &\nscheduling with sampling operations. ScheduleStream models temporal dynamics\nusing hybrid durative actions, which can be started asynchronously and persist\nfor a duration that's a function of their parameters. We propose\ndomain-independent algorithms that solve ScheduleStream problems without any\napplication-specific mechanisms. We apply ScheduleStream to Task and Motion\nPlanning & Scheduling (TAMPAS), where we use GPU acceleration within samplers\nto expedite planning. We compare ScheduleStream algorithms to several ablations\nin simulation and find that they produce more efficient solutions. We\ndemonstrate ScheduleStream on several real-world bimanual robot tasks at\nhttps://schedulestream.github.io.", "AI": {"tldr": "ScheduleStream是一个通用的采样操作规划与调度框架，它解决了多臂机器人控制中并行运动的计算挑战，通过混合持续动作和GPU加速，生成更高效的并行任务计划。", "motivation": "双臂和人形机器人因其多臂协作能力而备受关注，但控制多个机械臂面临混合离散-连续动作空间增长带来的计算挑战。现有的任务与运动规划（TAMP）算法通常生成单臂顺序移动的计划，而非允许并行臂运动的调度。", "method": "本文提出了ScheduleStream，首个用于采样操作的通用规划与调度框架。它使用混合持续动作建模时间动态，这些动作可以异步启动并持续一段时间。该框架提出了领域无关的算法来解决ScheduleStream问题，并将其应用于任务与运动规划与调度（TAMPAS），其中利用GPU加速来加速规划过程中的采样器。", "result": "在模拟中，ScheduleStream算法与多个消融实验相比，能够生成更高效的解决方案。研究还在几个真实世界的双臂机器人任务中展示了ScheduleStream的有效性。", "conclusion": "ScheduleStream是一个通用的框架，能够为多臂机器人生成允许并行臂运动的规划与调度，有效解决了传统TAMP算法的局限性，并通过领域无关算法和GPU加速提高了效率。"}}
{"id": "2511.04727", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04727", "abs": "https://arxiv.org/abs/2511.04727", "authors": ["Ali Faraz", "Akash", "Shaharukh Khan", "Raja Kolla", "Akshat Patidar", "Suranjan Goswami", "Abhinav Ravi", "Chandra Khatri", "Shubham Agarwal"], "title": "IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs", "comment": null, "summary": "Vision-language models (VLMs) have demonstrated impressive generalization\nacross multimodal tasks, yet most evaluation benchmarks remain Western-centric,\nleaving open questions about their performance in culturally diverse and\nmultilingual settings. To address this gap, we introduce IndicVisionBench, the\nfirst large-scale benchmark centered on the Indian subcontinent. Covering\nEnglish and 10 Indian languages, our benchmark spans 3 multimodal tasks,\nincluding Optical Character Recognition (OCR), Multimodal Machine Translation\n(MMT), and Visual Question Answering (VQA), covering 6 kinds of question types.\nOur final benchmark consists of a total of ~5K images and 37K+ QA pairs across\n13 culturally grounded topics. In addition, we release a paired parallel corpus\nof annotations across 10 Indic languages, creating a unique resource for\nanalyzing cultural and linguistic biases in VLMs. We evaluate a broad spectrum\nof 8 models, from proprietary closed-source systems to open-weights medium and\nlarge-scale models. Our experiments reveal substantial performance gaps,\nunderscoring the limitations of current VLMs in culturally diverse contexts. By\ncentering cultural diversity and multilinguality, IndicVisionBench establishes\na reproducible evaluation framework that paves the way for more inclusive\nmultimodal research.", "AI": {"tldr": "本文介绍了IndicVisionBench，一个针对印度次大陆文化和语言多样性的新型大规模基准测试，旨在评估现有视觉语言模型（VLMs）在非西方多语言环境中的性能，并发现它们存在显著的性能差距。", "motivation": "尽管视觉语言模型（VLMs）在多模态任务中表现出色，但大多数评估基准仍然以西方为中心，导致其在文化多样和多语言环境（特别是印度次大陆）中的性能表现未知。", "method": "研究者引入了IndicVisionBench，这是一个涵盖英语和10种印度语言的大规模基准测试。该基准包含光学字符识别（OCR）、多模态机器翻译（MMT）和视觉问答（VQA）3种多模态任务（6种问题类型），共约5K张图像和37K+问答对，涉及13个文化主题。此外，还发布了10种印度语言的并行标注语料库。研究评估了8种不同类型的VLM模型。", "result": "实验结果揭示了当前VLM在文化多样性背景下存在显著的性能差距，凸显了它们的局限性。", "conclusion": "IndicVisionBench通过关注文化多样性和多语言性，建立了一个可复现的评估框架，为更具包容性的多模态研究铺平了道路，有助于未来开发在不同文化背景下表现更佳的VLM。"}}
{"id": "2511.04769", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04769", "abs": "https://arxiv.org/abs/2511.04769", "authors": ["Phat Nguyen", "Tsun-Hsuan Wang", "Zhang-Wei Hong", "Erfan Aasi", "Andrew Silva", "Guy Rosman", "Sertac Karaman", "Daniela Rus"], "title": "ReGen: Generative Robot Simulation via Inverse Design", "comment": null, "summary": "Simulation plays a key role in scaling robot learning and validating\npolicies, but constructing simulations remains a labor-intensive process. This\npaper introduces ReGen, a generative simulation framework that automates\nsimulation design via inverse design. Given a robot's behavior -- such as a\nmotion trajectory or an objective function -- and its textual description,\nReGen infers plausible scenarios and environments that could have caused the\nbehavior. ReGen leverages large language models to synthesize scenarios by\nexpanding a directed graph that encodes cause-and-effect relationships,\nrelevant entities, and their properties. This structured graph is then\ntranslated into a symbolic program, which configures and executes a robot\nsimulation environment. Our framework supports (i) augmenting simulations based\non ego-agent behaviors, (ii) controllable, counterfactual scenario generation,\n(iii) reasoning about agent cognition and mental states, and (iv) reasoning\nwith distinct sensing modalities, such as braking due to faulty GPS signals. We\ndemonstrate ReGen in autonomous driving and robot manipulation tasks,\ngenerating more diverse, complex simulated environments compared to existing\nsimulations with high success rates, and enabling controllable generation for\ncorner cases. This approach enhances the validation of robot policies and\nsupports data or simulation augmentation, advancing scalable robot learning for\nimproved generalization and robustness. We provide code and example videos at:\nhttps://regen-sim.github.io/", "AI": {"tldr": "本文介绍ReGen，一个通过逆向设计自动化模拟场景生成的框架。它利用大型语言模型（LLM）从机器人行为和文本描述中推断出合理的场景和环境，从而实现更高效、多样化的机器人学习模拟。", "motivation": "构建机器人模拟是一个劳动密集型过程，这限制了机器人学习的规模化和策略验证的效率。", "method": "ReGen是一个生成式模拟框架，通过逆向设计自动化模拟场景。给定机器人的行为（如运动轨迹或目标函数）及其文本描述，ReGen利用大型语言模型（LLM）通过扩展编码因果关系、相关实体及其属性的有向图来合成场景。这个结构化的图随后被转换为符号程序，用于配置和执行机器人模拟环境。该框架支持基于自我智能体行为的模拟增强、可控的反事实场景生成、智能体认知和心理状态推理，以及不同传感模态的推理。", "result": "ReGen在自动驾驶和机器人操作任务中得到了验证。与现有模拟相比，它能生成更多样化、更复杂的模拟环境，并具有高成功率，同时能够为极端情况实现可控生成。", "conclusion": "ReGen增强了机器人策略的验证，支持数据或模拟增强，并推动了可扩展机器人学习，以提高泛化能力和鲁棒性。"}}
{"id": "2511.04831", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04831", "abs": "https://arxiv.org/abs/2511.04831", "authors": ["NVIDIA", ":", "Mayank Mittal", "Pascal Roth", "James Tigue", "Antoine Richard", "Octi Zhang", "Peter Du", "Antonio Serrano-Muñoz", "Xinjie Yao", "René Zurbrügg", "Nikita Rudin", "Lukasz Wawrzyniak", "Milad Rakhsha", "Alain Denzler", "Eric Heiden", "Ales Borovicka", "Ossama Ahmed", "Iretiayo Akinola", "Abrar Anwar", "Mark T. Carlson", "Ji Yuan Feng", "Animesh Garg", "Renato Gasoto", "Lionel Gulich", "Yijie Guo", "M. Gussert", "Alex Hansen", "Mihir Kulkarni", "Chenran Li", "Wei Liu", "Viktor Makoviychuk", "Grzegorz Malczyk", "Hammad Mazhar", "Masoud Moghani", "Adithyavairavan Murali", "Michael Noseworthy", "Alexander Poddubny", "Nathan Ratliff", "Welf Rehberg", "Clemens Schwarke", "Ritvik Singh", "James Latham Smith", "Bingjie Tang", "Ruchik Thaker", "Matthew Trepte", "Karl Van Wyk", "Fangzhou Yu", "Alex Millane", "Vikram Ramasamy", "Remo Steiner", "Sangeeta Subramanian", "Clemens Volk", "CY Chen", "Neel Jawale", "Ashwin Varghese Kuruttukulam", "Michael A. Lin", "Ajay Mandlekar", "Karsten Patzwaldt", "John Welsh", "Huihua Zhao", "Fatima Anes", "Jean-Francois Lafleche", "Nicolas Moënne-Loccoz", "Soowan Park", "Rob Stepinski", "Dirk Van Gelder", "Chris Amevor", "Jan Carius", "Jumyung Chang", "Anka He Chen", "Pablo de Heras Ciechomski", "Gilles Daviet", "Mohammad Mohajerani", "Julia von Muralt", "Viktor Reutskyy", "Michael Sauter", "Simon Schirm", "Eric L. Shi", "Pierre Terdiman", "Kenny Vilella", "Tobias Widmer", "Gordon Yeoman", "Tiffany Chen", "Sergey Grizan", "Cathy Li", "Lotus Li", "Connor Smith", "Rafael Wiltz", "Kostas Alexis", "Yan Chang", "David Chu", "Linxi \"Jim\" Fan", "Farbod Farshidian", "Ankur Handa", "Spencer Huang", "Marco Hutter", "Yashraj Narang", "Soha Pouya", "Shiwei Sheng", "Yuke Zhu", "Miles Macklin", "Adam Moravanszky", "Philipp Reist", "Yunrong Guo", "David Hoeller", "Gavriel State"], "title": "Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning", "comment": "Code and documentation are available here:\n  https://github.com/isaac-sim/IsaacLab", "summary": "We present Isaac Lab, the natural successor to Isaac Gym, which extends the\nparadigm of GPU-native robotics simulation into the era of large-scale\nmulti-modal learning. Isaac Lab combines high-fidelity GPU parallel physics,\nphotorealistic rendering, and a modular, composable architecture for designing\nenvironments and training robot policies. Beyond physics and rendering, the\nframework integrates actuator models, multi-frequency sensor simulation, data\ncollection pipelines, and domain randomization tools, unifying best practices\nfor reinforcement and imitation learning at scale within a single extensible\nplatform. We highlight its application to a diverse set of challenges,\nincluding whole-body control, cross-embodiment mobility, contact-rich and\ndexterous manipulation, and the integration of human demonstrations for skill\nacquisition. Finally, we discuss upcoming integration with the differentiable,\nGPU-accelerated Newton physics engine, which promises new opportunities for\nscalable, data-efficient, and gradient-based approaches to robot learning. We\nbelieve Isaac Lab's combination of advanced simulation capabilities, rich\nsensing, and data-center scale execution will help unlock the next generation\nof breakthroughs in robotics research.", "AI": {"tldr": "Isaac Lab是Isaac Gym的继任者，一个GPU原生的机器人仿真平台，专为大规模多模态学习设计，整合了高保真物理、逼真渲染、多传感器模拟和数据工具，旨在推动机器人研究突破。", "motivation": "将GPU原生的机器人仿真范式扩展到大规模多模态学习时代，统一强化学习和模仿学习的最佳实践，并提供一个可扩展的平台来解决复杂的机器人挑战。", "method": "Isaac Lab结合了GPU并行物理模拟、逼真渲染、模块化可组合架构，并集成了执行器模型、多频传感器模拟、数据收集管道和域随机化工具。未来还将与可微分、GPU加速的Newton物理引擎集成。", "result": "该平台已应用于全身控制、跨形态移动、接触丰富和灵巧操作，以及整合人类演示进行技能学习等多种挑战。其先进的模拟能力、丰富的传感和数据中心规模的执行将为机器人学习带来新的机遇。", "conclusion": "Isaac Lab凭借其先进的模拟能力、丰富的传感和数据中心规模的执行，有望解锁机器人研究领域的下一代突破，特别是在可扩展、数据高效和基于梯度的机器人学习方法方面。"}}
{"id": "2511.04923", "categories": ["eess.SY", "cs.CY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.04923", "abs": "https://arxiv.org/abs/2511.04923", "authors": ["P. Vijaya Bharati", "J. S. V. Siva Kumar", "Sathish K Anumula", "P Vamshi Krishna", "Sangam Malla"], "title": "IoT and Predictive Maintenance in Industrial Engineering: A Data-Driven Approach", "comment": "9 Pages, 4 figures", "summary": "Fourth Industrial Revolution has brought in a new era of smart manufacturing,\nwherein, application of Internet of Things , and data-driven methodologies is\nrevolutionizing the conventional maintenance. With the help of real-time data\nfrom the IoT and machine learning algorithms, predictive maintenance allows\nindustrial systems to predict failures and optimize machines life. This paper\npresents the synergy between the Internet of Things and predictive maintenance\nin industrial engineering with an emphasis on the technologies, methodologies,\nas well as data analytics techniques, that constitute the integration. A\nsystematic collection, processing, and predictive modeling of data is\ndiscussed. The outcomes emphasize greater operational efficiency, decreased\ndowntime, and cost-saving, which makes a good argument as to why predictive\nmaintenance should be implemented in contemporary industries.", "AI": {"tldr": "本文探讨了工业物联网（IoT）与预测性维护在智能制造中的协同作用，强调了其技术、方法和数据分析，以提高运营效率并降低成本。", "motivation": "第四次工业革命带来了智能制造新时代，物联网和数据驱动方法正在彻底改变传统维护。通过预测故障和优化机器寿命，预测性维护成为工业系统提升效率的关键。", "method": "本文讨论了物联网与预测性维护的协同作用，包括利用物联网的实时数据和机器学习算法。具体方法涉及数据的系统收集、处理和预测建模，以及相关的数据分析技术。", "result": "研究结果表明，实施预测性维护能显著提高运营效率，减少停机时间，并实现成本节约。", "conclusion": "鉴于预测性维护在提高效率、降低成本和减少停机方面的显著优势，当代工业应积极采纳和实施预测性维护。"}}
{"id": "2511.04688", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04688", "abs": "https://arxiv.org/abs/2511.04688", "authors": ["Adrita Anika", "Md Messal Monem Miah"], "title": "Evaluating LLMs' Reasoning Over Ordered Procedural Steps", "comment": "Accepted to IJCNLP-AACL 2025 Findings", "summary": "Reasoning over procedural sequences, where the order of steps directly\nimpacts outcomes, is a critical capability for large language models (LLMs). In\nthis work, we study the task of reconstructing globally ordered sequences from\nshuffled procedural steps, using a curated dataset of food recipes, a domain\nwhere correct sequencing is essential for task success. We evaluate several\nLLMs under zero-shot and few-shot settings and present a comprehensive\nevaluation framework that adapts established metrics from ranking and sequence\nalignment. These include Kendall's Tau, Normalized Longest Common Subsequence\n(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects\nof ordering quality. Our analysis shows that model performance declines with\nincreasing sequence length, reflecting the added complexity of longer\nprocedures. We also find that greater step displacement in the input,\ncorresponding to more severe shuffling, leads to further degradation. These\nfindings highlight the limitations of current LLMs in procedural reasoning,\nespecially with longer and more disordered inputs.", "AI": {"tldr": "本研究评估了大型语言模型（LLMs）从打乱的步骤中重建程序序列（食谱）的能力。结果显示，LLMs在处理更长或更混乱的输入时表现不佳，揭示了其在程序推理方面的局限性。", "motivation": "程序序列推理对LLMs至关重要，因为步骤顺序直接影响结果。理解LLMs在此类任务中的能力和局限性是推动其发展的关键。", "method": "研究任务是从打乱的食谱步骤中重建全局有序序列。使用自建的食谱数据集，并在零样本和少样本设置下评估了多个LLMs。评估框架采用了排名和序列比对的成熟指标，包括Kendall's Tau、归一化最长公共子序列（NLCS）和归一化编辑距离（NED）。", "result": "模型性能随序列长度增加而下降，且输入步骤位移越大（即打乱程度越严重），性能下降越明显。这表明更长和更无序的程序对LLMs来说更具挑战性。", "conclusion": "当前LLMs在程序推理方面存在局限性，尤其是在处理更长和更混乱的输入时。这些发现为未来改进LLMs在复杂程序推理方面的能力提供了方向。"}}
{"id": "2511.04685", "categories": ["cs.AI", "math.OC", "90-04", "F.2.2"], "pdf": "https://arxiv.org/pdf/2511.04685", "abs": "https://arxiv.org/abs/2511.04685", "authors": ["Daniela Guericke", "Rolf van der Hulst", "Asal Karimpour", "Ieke Schrader", "Matthias Walter"], "title": "A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024", "comment": "23 pages, 2 figures, 10 tables", "summary": "We report about the algorithm, implementation and results submitted to the\nIntegrated Healthcare Timetabling Competition 2024 by Team Twente, which scored\nthird in the competition. Our approach combines mixed-integer programming,\nconstraint programming and simulated annealing in a 3-phase solution approach\nbased on decomposition into subproblems. Next to describing our approach and\ndescribing our design decisions, we share our insights and, for the first time,\nlower bounds on the optimal solution values for the benchmark instances. We\nfinally highlight open problems for which we think that addressing them could\nimprove our approach even further.", "AI": {"tldr": "本文介绍了Twente团队在2024年综合医疗排班竞赛中获得第三名的算法、实现和结果，该方法结合了混合整数规划、约束规划和模拟退火，并首次提供了基准实例的最优解下界。", "motivation": "参与2024年综合医疗排班竞赛并取得优异成绩，同时分享团队的见解，并为基准实例提供最优解的下界，以推动该领域的发展。", "method": "采用三阶段解决方案，基于子问题分解，结合了混合整数规划（MIP）、约束规划（CP）和模拟退火（SA）三种技术。", "result": "在竞赛中获得第三名，分享了设计决策和见解，并首次为基准实例提供了最优解的下界。", "conclusion": "所提出的结合MIP、CP和SA的三阶段分解方法是有效的，并且指出了未来可以进一步改进该方法的开放性问题。"}}
{"id": "2511.04835", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04835", "abs": "https://arxiv.org/abs/2511.04835", "authors": ["Shubham Natraj", "Bruno Sinopoli", "Yiannis Kantaros"], "title": "Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning", "comment": null, "summary": "Sampling-based motion planners (SBMPs) are widely used to compute dynamically\nfeasible robot paths. However, their reliance on uniform sampling often leads\nto poor efficiency and slow planning in complex environments. We introduce a\nnovel non-uniform sampling strategy that integrates into existing SBMPs by\nbiasing sampling toward `certified' regions. These regions are constructed by\n(i) generating an initial, possibly infeasible, path using any heuristic path\npredictor (e.g., A* or vision-language models) and (ii) applying conformal\nprediction to quantify the predictor's uncertainty. This process yields\nprediction sets around the initial-guess path that are guaranteed, with\nuser-specified probability, to contain the optimal solution. To our knowledge,\nthis is the first non-uniform sampling approach for SBMPs that provides such\nprobabilistically correct guarantees on the sampling regions. Extensive\nevaluations demonstrate that our method consistently finds feasible paths\nfaster and generalizes better to unseen environments than existing baselines.", "AI": {"tldr": "本文提出一种新颖的非均匀采样策略，通过共形预测生成“认证”区域，并偏向这些区域进行采样，以提高基于采样的运动规划器（SBMPs）的效率和泛化能力。", "motivation": "现有的基于采样的运动规划器（SBMPs）依赖均匀采样，导致在复杂环境中效率低下且规划速度慢。", "method": "该方法通过以下步骤集成到现有SBMPs中：(i) 使用启发式路径预测器（如A*或视觉-语言模型）生成初始路径（可能不可行）；(ii) 应用共形预测量化预测器的不确定性。这会生成围绕初始猜测路径的预测集，这些预测集以用户指定概率保证包含最优解。然后，SBMPs偏向这些“认证”区域进行采样。", "result": "广泛评估表明，该方法比现有基线能更快地找到可行路径，并对未知环境表现出更好的泛化能力。", "conclusion": "本研究首次为SBMPs提供了一种具有采样区域概率正确性保证的非均匀采样方法，显著提高了规划效率和泛化性能。"}}
{"id": "2511.05047", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.05047", "abs": "https://arxiv.org/abs/2511.05047", "authors": ["Muhammad Talha", "Qi Yang", "Zhu Li", "Anique Akhtar", "Geert Van Der Auwera"], "title": "J-SGFT: Joint Spatial and Graph Fourier Domain Learning for Point Cloud Attribute Deblocking", "comment": "Accepted to ICIP 2025 Workshop on Generative AI for World Simulations\n  and Communications & Celebrating 40 Years of Excellence in Education:\n  Honoring Professor Aggelos Katsaggelos, Sept. 2025, Alaska", "summary": "Point clouds (PC) are essential for AR/VR and autonomous driving but\nchallenge compression schemes with their size, irregular sampling, and\nsparsity. MPEG's Geometry-based Point Cloud Compression (GPCC) methods\nsuccessfully reduce bitrate; however, they introduce significant blocky\nartifacts in the reconstructed point cloud. We introduce a novel multi-scale\npostprocessing framework that fuses graph-Fourier latent attribute\nrepresentations with sparse convolutions and channel-wise attention to\nefficiently deblock reconstructed point clouds. Against the GPCC TMC13v14\nbaseline, our approach achieves BD-rate reduction of 18.81\\% in the Y channel\nand 18.14\\% in the joint YUV on the 8iVFBv2 dataset, delivering markedly\nimproved visual fidelity with minimal overhead.", "AI": {"tldr": "本文提出了一种多尺度后处理框架，结合图傅里叶潜在属性表示、稀疏卷积和通道注意力机制，有效去除几何点云压缩（GPCC）重建点云中的块状伪影，显著提升视觉质量并降低码率。", "motivation": "点云在AR/VR和自动驾驶中至关重要，但其大小、不规则采样和稀疏性对压缩方案构成挑战。MPEG的GPCC方法虽然能有效降低码率，但会在重建点云中引入明显的块状伪影。", "method": "研究人员引入了一种新颖的多尺度后处理框架。该框架将图傅里叶潜在属性表示与稀疏卷积和通道注意力机制相结合，旨在高效地对重建点云进行去块处理。", "result": "与GPCC TMC13v14基线相比，该方法在8iVFBv2数据集上实现了Y通道18.81%和YUV联合18.14%的BD-rate降低。同时，它显著改善了视觉保真度，且开销极小。", "conclusion": "所提出的多尺度后处理框架能有效去除GPCC压缩点云中的块状伪影，显著提升视觉质量，并在码率降低方面表现出色，具有最小的额外开销。"}}
{"id": "2511.04940", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.04940", "abs": "https://arxiv.org/abs/2511.04940", "authors": ["Jiachen Shen", "Jian Shi", "Lei Fan", "Chenye Wu", "Dan Wang", "Choong Seon Hong", "Zhu Han"], "title": "Strategic Decision-Making Under Uncertainty through Bi-Level Game Theory and Distributionally Robust Optimization", "comment": null, "summary": "In strategic scenarios where decision-makers operate at different\nhierarchical levels, traditional optimization methods are often inadequate for\nhandling uncertainties from incomplete information or unpredictable external\nfactors. To fill this gap, we introduce a mathematical framework that\nintegrates bi-level game theory with distributionally robust optimization\n(DRO), particularly suited for complex network systems. Our approach leverages\nthe hierarchical structure of bi-level games to model leader-follower\ninteractions while incorporating distributional robustness to guard against\nworst-case probability distributions. To ensure computational tractability, the\nKarush-Kuhn-Tucker (KKT) conditions are used to transform the bi-level\nchallenge into a more manageable single-level model, and the\ninfinite-dimensional DRO problem is reformulated into a finite equivalent. We\npropose a generalized algorithm to solve this integrated model. Simulation\nresults validate our framework's efficacy, demonstrating that under high\nuncertainty, the proposed model achieves up to a 22\\% cost reduction compared\nto traditional stochastic methods while maintaining a service level of over\n90\\%. This highlights its potential to significantly improve decision quality\nand robustness in networked systems such as transportation and communication\nnetworks.", "AI": {"tldr": "本文提出了一种结合双层博弈论和分布鲁棒优化（DRO）的数学框架，用于处理具有层级结构的复杂网络系统中的不确定性决策，并通过转化和算法求解，显著提升了决策质量和鲁棒性。", "motivation": "在具有不同层级决策者的战略场景中，传统优化方法难以有效处理因信息不完整或外部因素不可预测而产生的不确定性。", "method": "该研究引入了一个数学框架，整合了双层博弈论（用于建模领导者-追随者互动）与分布鲁棒优化（DRO，用于应对最坏情况下的概率分布）。为确保计算可行性，利用KKT条件将双层问题转换为单层模型，并将无限维DRO问题重新表述为有限维等效问题。最后，提出了一种通用算法来求解该集成模型。", "result": "仿真结果表明，在高度不确定性下，所提出的模型与传统随机方法相比，实现了高达22%的成本降低，同时保持了90%以上的服务水平。", "conclusion": "该框架在交通和通信网络等网络系统中具有显著提高决策质量和鲁棒性的潜力。"}}
{"id": "2511.05009", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05009", "abs": "https://arxiv.org/abs/2511.05009", "authors": ["S. Zhao", "W. Lu", "B. Wang", "T. Wang", "K. Zhang", "H. Zhao"], "title": "UHDRes: Ultra-High-Definition Image Restoration via Dual-Domain Decoupled Spectral Modulation", "comment": null, "summary": "Ultra-high-definition (UHD) images often suffer from severe degradations such\nas blur, haze, rain, or low-light conditions, which pose significant challenges\nfor image restoration due to their high resolution and computational demands.\nIn this paper, we propose UHDRes, a novel lightweight dual-domain decoupled\nspectral modulation framework for UHD image restoration. It explicitly models\nthe amplitude spectrum via lightweight spectrum-domain modulation, while\nrestoring phase implicitly through spatial-domain refinement. We introduce the\nspatio-spectral fusion mechanism, which first employs a multi-scale context\naggregator to extract local and global spatial features, and then performs\nspectral modulation in a decoupled manner. It explicitly enhances amplitude\nfeatures in the frequency domain while implicitly restoring phase information\nthrough spatial refinement. Additionally, a shared gated feed-forward network\nis designed to efficiently promote feature interaction through shared-parameter\nconvolutions and adaptive gating mechanisms. Extensive experimental comparisons\non five public UHD benchmarks demonstrate that our UHDRes achieves the\nstate-of-the-art restoration performance with only 400K parameters, while\nsignificantly reducing inference latency and memory usage. The codes and models\nare available at https://github.com/Zhao0100/UHDRes.", "AI": {"tldr": "本文提出UHDRes，一个轻量级双域解耦频谱调制框架，用于超高清图像恢复，在仅400K参数下实现最先进的性能，并显著降低推理延迟和内存使用。", "motivation": "超高清（UHD）图像常受到模糊、雾霾、雨水或低光等严重退化，其高分辨率和计算需求给图像恢复带来了巨大挑战。", "method": "本文提出UHDRes，一个轻量级双域解耦频谱调制框架。它通过轻量级频谱域调制显式建模振幅谱，同时通过空间域细化隐式恢复相位。引入了时空频谱融合机制，首先使用多尺度上下文聚合器提取局部和全局空间特征，然后以解耦方式进行频谱调制，显式增强频域振幅特征，通过空间细化隐式恢复相位信息。此外，设计了一个共享门控前馈网络，通过共享参数卷积和自适应门控机制有效促进特征交互。", "result": "在五个公共UHD基准测试上的广泛实验比较表明，UHDRes以仅400K参数实现了最先进的恢复性能，同时显著降低了推理延迟和内存使用。", "conclusion": "UHDRes提供了一种高效且有效的超高清图像恢复解决方案，以极低的计算成本实现了最先进的性能。"}}
{"id": "2511.04837", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04837", "abs": "https://arxiv.org/abs/2511.04837", "authors": ["Cameron Robinson", "Ganghee Jang"], "title": "Design Exploration for Protection and Cleaning of Solar Panels with Case Studies for Space Missions", "comment": "4 pages, 3 figures (5 assets)", "summary": "Solar energy is used for many mission-critical applications including space\nexploration, sensor systems to monitor wildfires, etc. Their operation can be\nlimited or even terminated if solar panels are covered with dust or hit by\nspace debris. To address this issue, we designed panel cleaning mechanisms and\ntested protective materials. For cleaning mechanisms, we designed and compared\na wiper system and a rail system. For protective materials, we found through\ncollision tests that polycarbonate was very promising, though the most\nimportant factor was layering a soft material between the panel's surface and a\nhard material. In the cleaning system comparisons, the wiper-based system was\nmore efficient than the rail-based system in terms of cost, cleaning speed, and\ntotal power consumption.", "AI": {"tldr": "本文设计并比较了太阳能电池板的清洁机制（刮水器系统和轨道系统），并测试了保护材料，发现刮水器系统更高效，且聚碳酸酯分层材料具有良好的保护效果。", "motivation": "太阳能被用于太空探索、野火监测等关键任务应用，但太阳能电池板被灰尘覆盖或被太空碎片击中会限制甚至终止其运行，因此需要解决清洁和保护问题。", "method": "研究方法包括设计并比较了两种清洁机制：刮水器系统和轨道系统。同时，通过碰撞测试评估了各种保护材料，特别是聚碳酸酯，并研究了材料分层的影响。", "result": "在保护材料方面，聚碳酸酯表现出良好的前景，但最关键的因素是在电池板表面和硬质材料之间分层放置软质材料。在清洁系统比较中，基于刮水器的系统在成本、清洁速度和总功耗方面比基于轨道的系统更高效。", "conclusion": "研究表明，刮水器系统是更高效的太阳能电池板清洁机制，而分层软硬材料的聚碳酸酯是很有前途的保护材料，能够有效解决灰尘和碎片对太阳能电池板的威胁。"}}
{"id": "2511.04753", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04753", "abs": "https://arxiv.org/abs/2511.04753", "authors": ["Zonglin Lyu", "Ming Li", "Xinxin Liu", "Chen Chen"], "title": "CPO: Condition Preference Optimization for Controllable Image Generation", "comment": null, "summary": "To enhance controllability in text-to-image generation, ControlNet introduces\nimage-based control signals, while ControlNet++ improves pixel-level cycle\nconsistency between generated images and the input control signal. To avoid the\nprohibitive cost of back-propagating through the sampling process, ControlNet++\noptimizes only low-noise timesteps (e.g., $t < 200$) using a single-step\napproximation, which not only ignores the contribution of high-noise timesteps\nbut also introduces additional approximation errors. A straightforward\nalternative for optimizing controllability across all timesteps is Direct\nPreference Optimization (DPO), a fine-tuning method that increases model\npreference for more controllable images ($I^{w}$) over less controllable ones\n($I^{l}$). However, due to uncertainty in generative models, it is difficult to\nensure that win--lose image pairs differ only in controllability while keeping\nother factors, such as image quality, fixed. To address this, we propose\nperforming preference learning over control conditions rather than generated\nimages. Specifically, we construct winning and losing control signals,\n$\\mathbf{c}^{w}$ and $\\mathbf{c}^{l}$, and train the model to prefer\n$\\mathbf{c}^{w}$. This method, which we term \\textit{Condition Preference\nOptimization} (CPO), eliminates confounding factors and yields a low-variance\ntraining objective. Our approach theoretically exhibits lower contrastive loss\nvariance than DPO and empirically achieves superior results. Moreover, CPO\nrequires less computation and storage for dataset curation. Extensive\nexperiments show that CPO significantly improves controllability over the\nstate-of-the-art ControlNet++ across multiple control types: over $10\\%$ error\nrate reduction in segmentation, $70$--$80\\%$ in human pose, and consistent\n$2$--$5\\%$ reductions in edge and depth maps.", "AI": {"tldr": "本文提出条件偏好优化（CPO）方法，通过对控制条件而非生成图像进行偏好学习，显著提升了文本到图像生成的可控性，优于现有方法如ControlNet++，并降低了计算成本。", "motivation": "现有方法如ControlNet++在提升可控性方面存在局限，例如仅优化低噪声时间步，忽略高噪声贡献并引入近似误差。直接偏好优化（DPO）应用于可控性时，难以确保胜负图像对仅在可控性上差异，而其他因素（如图像质量）保持不变，导致训练不稳定。", "method": "提出条件偏好优化（CPO）方法，通过构建胜出和失败的控制信号（$\\mathbf{c}^{w}$和$\\mathbf{c}^{l}$），训练模型偏好$\\mathbf{c}^{w}$。这种方法消除了混杂因素，并产生低方差的训练目标，相比DPO在控制条件而非生成图像上进行偏好学习。", "result": "CPO在理论上表现出比DPO更低的对比损失方差，并在实验中取得了卓越结果。它显著提升了可控性，相较于ControlNet++，在分割任务中错误率降低超过10%，人体姿态任务中降低70-80%，边缘和深度图任务中稳定降低2-5%。此外，CPO在数据集整理方面所需计算和存储更少。", "conclusion": "CPO通过对控制条件进行偏好学习，有效解决了现有可控性优化方法的局限性，实现了更高的可控性性能和更低的计算成本，显著超越了ControlNet++等最先进方法。"}}
{"id": "2511.04692", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04692", "abs": "https://arxiv.org/abs/2511.04692", "authors": ["Jingqing Wang", "Jiaxing Shang", "Rong Xu", "Fei Hao", "Tianjin Huang", "Geyong Min"], "title": "SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection", "comment": "12 pages, 11 figures, 4 tables, WSDM 2026 accepted paper", "summary": "Fake news detection has been a long-standing research focus in social\nnetworks. Recent studies suggest that incorporating sentiment information from\nboth news content and user comments can enhance detection performance. However,\nexisting approaches typically treat sentiment features as auxiliary signals,\noverlooking role differentiation, that is, the same sentiment polarity may\noriginate from users with distinct roles, thereby limiting their ability to\ncapture nuanced patterns for effective detection. To address this issue, we\npropose SARC, a Sentiment-Augmented Role Clustering framework which utilizes\nsentiment-enhanced deep clustering to identify user roles for improved fake\nnews detection. The framework first generates user features through joint\ncomment text representation (with BiGRU and Attention mechanism) and sentiment\nencoding. It then constructs a differentiable deep clustering module to\nautomatically categorize user roles. Finally, unlike existing approaches which\ntake fake news label as the unique supervision signal, we propose a joint\noptimization objective integrating role clustering and fake news detection to\nfurther improve the model performance. Experimental results on two benchmark\ndatasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior\nperformance across all metrics compared to baseline models. The code is\navailable at: https://github.com/jxshang/SARC.", "AI": {"tldr": "本文提出SARC框架，通过情感增强的深度聚类识别用户角色，并结合角色聚类和虚假新闻检测的联合优化目标，显著提升了虚假新闻检测性能。", "motivation": "现有方法将情感特征视为辅助信号，忽略了用户角色差异（即相同情感可能来源于不同角色），限制了捕获细微模式的能力，从而影响了虚假新闻检测效果。", "method": "SARC（Sentiment-Augmented Role Clustering）框架首先通过联合评论文本表示（BiGRU和Attention机制）和情感编码生成用户特征；然后构建可微分的深度聚类模块自动识别用户角色；最后，提出一个联合优化目标，整合角色聚类和虚假新闻检测，以进一步提升模型性能。", "result": "在RumourEval-19和Weibo-comp两个基准数据集上的实验结果表明，SARC在所有评估指标上均优于基线模型。", "conclusion": "SARC通过有效利用情感增强的深度聚类来识别用户角色，并结合角色聚类与虚假新闻检测的联合优化，显著提高了虚假新闻检测的准确性。"}}
{"id": "2511.05049", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.05049", "abs": "https://arxiv.org/abs/2511.05049", "authors": ["Yihong Zou"], "title": "Design and Implementation of a Cloud Computing Security Assessment Model Based on Hierarchical Analysis and Fuzzy Comprehensive Evaluation", "comment": null, "summary": "At the rapid pace of technological evolution, the emerging cloud computing\ntechnology has promoted the digitalization and business innovation of the\nenterprise in all industries due to its advantages of data storage and service\nmode. Nevertheless, given the swift progress in cloud computing services, the\nsecurity problems have gradually appeared. The data breach and cyber attack\nhappen frequently, which cause huge losses to enterprises and individuals.\nThese issues have gradually become important constraints for the popularization\nof cloud computingTo tackle the problems outlined above, this paper constructs\na security evaluation framework for cloud computing services, integrating the\nAnalytic Hierarchy Process (AHP) with the Fuzzy Comprehensive Evaluation\nmethod. By applying this scientific and systematic methodology, the framework\nenables enterprises and individuals to better apprehend the security posture of\ncloud services, thereby fostering the healthy evolution of the entire industry.", "AI": {"tldr": "本文构建了一个结合AHP和模糊综合评价方法的云计算服务安全评估框架，旨在解决日益突出的云安全问题。", "motivation": "云计算技术虽促进了企业数字化和业务创新，但随之而来的数据泄露和网络攻击等安全问题日益频繁，造成巨大损失，并成为阻碍云计算普及的重要因素。", "method": "该研究通过整合层次分析法（AHP）与模糊综合评价方法，构建了一个科学系统的云计算服务安全评估框架。", "result": "所提出的框架能帮助企业和个人更好地理解云服务的安全状况。", "conclusion": "该框架有助于促进整个云计算行业的健康发展，通过提升对云服务安全态势的理解来应对安全挑战。"}}
{"id": "2511.04729", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04729", "abs": "https://arxiv.org/abs/2511.04729", "authors": ["Rucha Deshpande", "Tahsin Rahman", "Miguel Lago", "Adarsh Subbaswamy", "Jana G. Delfino", "Ghada Zamzmi", "Elim Thompson", "Aldo Badano", "Seyed Kahaki"], "title": "Knowledge-based anomaly detection for identifying network-induced shape artifacts", "comment": "15 pages, 11 figures", "summary": "Synthetic data provides a promising approach to address data scarcity for\ntraining machine learning models; however, adoption without proper quality\nassessments may introduce artifacts, distortions, and unrealistic features that\ncompromise model performance and clinical utility. This work introduces a novel\nknowledge-based anomaly detection method for detecting network-induced shape\nartifacts in synthetic images. The introduced method utilizes a two-stage\nframework comprising (i) a novel feature extractor that constructs a\nspecialized feature space by analyzing the per-image distribution of angle\ngradients along anatomical boundaries, and (ii) an isolation forest-based\nanomaly detector. We demonstrate the effectiveness of the method for\nidentifying network-induced shape artifacts in two synthetic mammography\ndatasets from models trained on CSAW-M and VinDr-Mammo patient datasets\nrespectively. Quantitative evaluation shows that the method successfully\nconcentrates artifacts in the most anomalous partition (1st percentile), with\nAUC values of 0.97 (CSAW-syn) and 0.91 (VMLO-syn). In addition, a reader study\ninvolving three imaging scientists confirmed that images identified by the\nmethod as containing network-induced shape artifacts were also flagged by human\nreaders with mean agreement rates of 66% (CSAW-syn) and 68% (VMLO-syn) for the\nmost anomalous partition, approximately 1.5-2 times higher than the least\nanomalous partition. Kendall-Tau correlations between algorithmic and human\nrankings were 0.45 and 0.43 for the two datasets, indicating reasonable\nagreement despite the challenging nature of subtle artifact detection. This\nmethod is a step forward in the responsible use of synthetic data, as it allows\ndevelopers to evaluate synthetic images for known anatomic constraints and\npinpoint and address specific issues to improve the overall quality of a\nsynthetic dataset.", "AI": {"tldr": "本文提出了一种基于知识的异常检测方法，用于识别合成医学图像中的网络诱导形状伪影，并通过定量评估和读者研究验证了其有效性。", "motivation": "合成数据在解决机器学习模型数据稀缺方面很有前景，但若缺乏适当的质量评估，可能引入伪影、失真和不真实特征，从而损害模型性能和临床实用性。", "method": "该方法采用两阶段框架：(i) 一个新颖的特征提取器，通过分析解剖边界上角度梯度的图像内分布来构建专门的特征空间；(ii) 一个基于隔离森林的异常检测器。", "result": "该方法在两个合成乳腺X线摄影数据集（CSAW-syn和VMLO-syn）上成功地将伪影集中在最异常的分区（第1百分位），AUC值分别为0.97和0.91。读者研究显示，对于最异常分区，人类读者与算法识别的图像具有66%和68%的平均一致率，是最低异常分区的1.5-2倍。算法与人类排名的Kendall-Tau相关性分别为0.45和0.43。", "conclusion": "该方法是负责任使用合成数据的重要一步，它使开发者能够评估合成图像是否符合已知的解剖学约束，并识别和解决特定问题以提高合成数据集的整体质量。"}}
{"id": "2511.04689", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04689", "abs": "https://arxiv.org/abs/2511.04689", "authors": ["Peiyu Li", "Xiuxiu Tang", "Si Chen", "Ying Cheng", "Ronald Metoyer", "Ting Hua", "Nitesh V. Chawla"], "title": "Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks", "comment": "Code and calibrated item banks are available at\n  https://github.com/Peiyu-Georgia-Li/ATLAS.git", "summary": "Large language model evaluation requires thousands of benchmark items, making\nevaluations expensive and slow. Existing methods compute average accuracy\nacross fixed item sets, treating all items equally despite varying quality and\ninformativeness. We present ATLAS an adaptive testing framework using Item\nResponse Theory (IRT) to estimate model ability through Fisher\ninformation-guided item selection. Our analysis of five major benchmarks\nreveals that 3-6% of items exhibit negative discrimination, indicating\nannotation errors that corrupt static evaluation. ATLAS achieves 90% item\nreduction while maintaining measurement precision: on HellaSwag (5,608 items),\nwe match full-benchmark estimates using only 42 items with 0.154 MAE. Our\nframework maintains item exposure rates below 10% and test overlap at 16-27%,\ncompared to static benchmarks where every model sees all items (100% exposure).\nAmong 4,000+ tested models, IRT ranks differ from accuracy ranks: models with\nthe same accuracy get different IRT scores, and 23-31% of all models shift by\nmore than 10 rank positions. Code and calibrated item banks are available at\nhttps://github.com/Peiyu-Georgia-Li/ATLAS.git.", "AI": {"tldr": "ATLAS是一种基于项目反应理论（IRT）的自适应测试框架，通过费舍尔信息指导项目选择，可大幅减少大型语言模型（LLM）评估所需的项目数量（90%），同时保持测量精度，并揭示了现有基准测试中项目质量问题。", "motivation": "大型语言模型评估需要数千个基准测试项目，导致评估成本高昂且耗时。现有方法在评估时平等对待所有项目，但项目质量和信息量各不相同。此外，现有基准测试中存在带有负区分度的错误标注项目，影响评估准确性。", "method": "本文提出了ATLAS，一个自适应测试框架。该框架利用项目反应理论（IRT）来估计模型能力，并通过费舍尔信息（Fisher information）指导项目选择，以优化评估效率和精度。", "result": "对五个主要基准测试的分析发现，3-6%的项目表现出负区分度，表明存在标注错误。ATLAS在保持测量精度的同时，实现了90%的项目缩减；例如，在HellaSwag上，仅用42个项目即可匹配完整基准测试的评估结果，平均绝对误差（MAE）为0.154。该框架将项目曝光率维持在10%以下，测试重叠度在16-27%之间。在4000多个模型中，IRT排名与传统准确率排名存在显著差异，23-31%的模型排名变化超过10位。", "conclusion": "ATLAS提供了一种高效且精确的LLM自适应评估方法，显著降低了评估成本和时间。IRT方法能更准确地反映模型能力，并揭示了现有基准测试中潜在的项目质量问题，从而提高了评估的效率和鲁棒性。"}}
{"id": "2511.04880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04880", "abs": "https://arxiv.org/abs/2511.04880", "authors": ["Yu Bai", "Yukai Miao", "Dawei Wang", "Li Chen", "Fei Long", "Rundi Zhai", "Dan Li", "Yanyu Ren", "Tianfeng Liu", "Hongtao Xie", "Ce Yang", "Xuhui Cai"], "title": "DMA: Online RAG Alignment with Human Feedback", "comment": null, "summary": "Retrieval-augmented generation (RAG) systems often rely on static retrieval,\nlimiting adaptation to evolving intent and content drift. We introduce Dynamic\nMemory Alignment (DMA), an online learning framework that systematically\nincorporates multi-granularity human feedback to align ranking in interactive\nsettings. DMA organizes document-, list-, and response-level signals into a\ncoherent learning pipeline: supervised training for pointwise and listwise\nrankers, policy optimization driven by response-level preferences, and\nknowledge distillation into a lightweight scorer for low-latency serving.\nThroughout this paper, memory refers to the model's working memory, which is\nthe entire context visible to the LLM for In-Context Learning.\n  We adopt a dual-track evaluation protocol mirroring deployment: (i)\nlarge-scale online A/B ablations to isolate the utility of each feedback\nsource, and (ii) few-shot offline tests on knowledge-intensive benchmarks.\nOnline, a multi-month industrial deployment further shows substantial\nimprovements in human engagement. Offline, DMA preserves competitive\nfoundational retrieval while yielding notable gains on conversational QA\n(TriviaQA, HotpotQA). Taken together, these results position DMA as a\nprincipled approach to feedback-driven, real-time adaptation in RAG without\nsacrificing baseline capability.", "AI": {"tldr": "DMA是一个在线学习框架，通过整合多粒度人工反馈来动态调整RAG系统的检索排名，以适应不断变化的意图和内容漂移。", "motivation": "RAG系统常依赖静态检索，这限制了其适应不断变化的意图和内容漂移的能力。", "method": "DMA（动态记忆对齐）框架通过一个连贯的学习流程整合多粒度（文档、列表、响应级别）的人工反馈：对点式和列表式排序器进行监督训练，通过响应级别偏好驱动策略优化，并将知识蒸馏到轻量级评分器中以实现低延迟服务。评估采用双轨协议：大规模在线A/B测试和知识密集型基准上的少样本离线测试。", "result": "在线评估显示，经过数月的工业部署，DMA显著提升了用户参与度。离线评估表明，DMA在保持基础检索竞争力的同时，在对话式问答（TriviaQA, HotpotQA）上取得了显著提升。", "conclusion": "DMA是一种原则性的方法，可以在不牺牲基线能力的情况下，通过反馈驱动的方式实现RAG系统的实时适应。"}}
{"id": "2511.04694", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04694", "abs": "https://arxiv.org/abs/2511.04694", "authors": ["Zishuo Zheng", "Vidhisha Balachandran", "Chan Young Park", "Faeze Brahman", "Sachin Kumar"], "title": "Reasoning Up the Instruction Ladder for Controllable Language Models", "comment": null, "summary": "As large language model (LLM) based systems take on high-stakes roles in\nreal-world decision-making, they must reconcile competing instructions from\nmultiple sources (e.g., model developers, users, and tools) within a single\nprompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where\nhigher-level directives override lower-priority requests, is critical for the\nreliability and controllability of LLMs. In this work, we reframe instruction\nhierarchy resolution as a reasoning task. Specifically, the model must first\n\"think\" about the relationship between a given user prompt and higher-priority\n(system) instructions before generating a response. To enable this capability\nvia training, we construct VerIH, an instruction hierarchy dataset of\nconstraint-following tasks with verifiable answers. This dataset comprises both\naligned and conflicting system-user instructions. We show that lightweight\nreinforcement learning with VerIH effectively transfers general reasoning\ncapabilities of models to instruction prioritization. Our finetuned models\nachieve consistent improvements on instruction following and instruction\nhierarchy benchmarks. This reasoning ability also generalizes to\nsafety-critical settings beyond the training distribution. By treating safety\nissues as resolving conflicts between adversarial user inputs and predefined\nhigher-priority policies, our trained model enhances robustness against\njailbreak and prompt injection attacks. These results demonstrate that\nreasoning over instruction hierarchies provides a practical path to reliable\nLLMs, where updates to system prompts yield controllable and robust changes in\nmodel behavior.", "AI": {"tldr": "该研究提出将大型语言模型（LLM）中的指令层级解析视为推理任务，通过构建可验证的VerIH数据集并结合轻量级强化学习，显著提高了模型在指令遵循、层级优先级处理和对抗性攻击（如越狱和提示注入）方面的鲁棒性和可控性。", "motivation": "随着LLM在现实世界高风险决策中的应用，它们必须在一个提示上下文中协调来自多个来源（如开发者、用户、工具）的冲突指令。因此，在LLM中强制执行指令层级（即高级指令优先于低级请求）对于模型的可靠性和可控性至关重要。", "method": "研究将指令层级解析重新定义为推理任务，要求模型在生成响应前“思考”用户提示与高级（系统）指令之间的关系。为此，构建了VerIH数据集，其中包含具有可验证答案的约束遵循任务，涵盖对齐和冲突的系统-用户指令。通过对VerIH数据集进行轻量级强化学习来训练模型。", "result": "通过VerIH进行的强化学习能有效将模型的通用推理能力转移到指令优先级处理上。微调后的模型在指令遵循和指令层级基准测试上均取得了一致的改进。这种推理能力还泛化到训练分布之外的安全关键场景，通过将安全问题视为解决对抗性用户输入与预定义高优先级策略之间的冲突，提高了模型对抗越狱和提示注入攻击的鲁棒性。", "conclusion": "对指令层级进行推理为实现可靠的LLM提供了一条实用路径，其中系统提示的更新可以带来模型行为的可控和稳健变化。"}}
{"id": "2511.04855", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04855", "abs": "https://arxiv.org/abs/2511.04855", "authors": ["Vojtech Franc", "Jakub Paplham"], "title": "Epistemic Reject Option Prediction", "comment": null, "summary": "In high-stakes applications, predictive models must not only produce accurate\npredictions but also quantify and communicate their uncertainty. Reject-option\nprediction addresses this by allowing the model to abstain when prediction\nuncertainty is high. Traditional reject-option approaches focus solely on\naleatoric uncertainty, an assumption valid only when large training data makes\nthe epistemic uncertainty negligible. However, in many practical scenarios,\nlimited data makes this assumption unrealistic. This paper introduces the\nepistemic reject-option predictor, which abstains in regions of high epistemic\nuncertainty caused by insufficient data. Building on Bayesian learning, we\nredefine the optimal predictor as the one that minimizes expected regret -- the\nperformance gap between the learned model and the Bayes-optimal predictor with\nfull knowledge of the data distribution. The model abstains when the regret for\na given input exceeds a specified rejection cost. To our knowledge, this is the\nfirst principled framework that enables learning predictors capable of\nidentifying inputs for which the training data is insufficient to make reliable\ndecisions.", "AI": {"tldr": "本文提出了一种基于贝叶斯学习的“认知拒绝选项预测器”，通过最小化预期遗憾来重新定义最优预测器，使其能够在训练数据不足导致认知不确定性高时选择拒绝预测，从而识别不可靠的输入。", "motivation": "在高风险应用中，预测模型不仅需要准确，还需要量化不确定性。传统的拒绝选项方法仅关注偶然不确定性，假设在数据量大时认知不确定性可忽略。然而，在许多实际场景中，数据有限，这一假设不成立，模型需要能够识别因数据不足而无法做出可靠决策的输入。", "method": "该研究引入了“认知拒绝选项预测器”，其在数据不足导致高认知不确定性的区域选择拒绝。它基于贝叶斯学习，将最优预测器重新定义为最小化预期遗憾（学习模型与完全了解数据分布的贝叶斯最优预测器之间的性能差距）的预测器。当给定输入的遗憾超过设定的拒绝成本时，模型将选择拒绝。", "result": "本文提出了一个原理性框架，使得学习型预测器能够识别训练数据不足以做出可靠决策的输入。据作者所知，这是首个能够实现此功能的框架。", "conclusion": "该论文提供了一个开创性的、有原则的框架，使预测器能够识别由于训练数据不足而无法做出可靠决策的输入，解决了传统拒绝选项方法在处理有限数据下认知不确定性方面的局限性。"}}
{"id": "2511.04976", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04976", "abs": "https://arxiv.org/abs/2511.04976", "authors": ["Xin Nie", "Zhiyuan Cheng", "Yuan Zhang", "Chao Ji", "Jiajia Wu", "Yuhan Zhang", "Jia Pan"], "title": "iFlyBot-VLM Technical Report", "comment": null, "summary": "We introduce iFlyBot-VLM, a general-purpose Vision-Language Model (VLM) used\nto improve the domain of Embodied Intelligence. The central objective of\niFlyBot-VLM is to bridge the cross-modal semantic gap between high-dimensional\nenvironmental perception and low-level robotic motion control. To this end, the\nmodel abstracts complex visual and spatial information into a body-agnostic and\ntransferable Operational Language, thereby enabling seamless perception-action\nclosed-loop coordination across diverse robotic platforms. The architecture of\niFlyBot-VLM is systematically designed to realize four key functional\ncapabilities essential for embodied intelligence: 1) Spatial Understanding and\nMetric Reasoning; 2) Interactive Target Grounding; 3) Action Abstraction and\nControl Parameter Generation; 4) Task Planning and Skill Sequencing. We\nenvision iFlyBot-VLM as a scalable and generalizable foundation model for\nembodied AI, facilitating the progression from specialized task-oriented\nsystems toward generalist, cognitively capable agents. We conducted evaluations\non 10 current mainstream embodied intelligence-related VLM benchmark datasets,\nsuch as Blink and Where2Place, and achieved optimal performance while\npreserving the model's general capabilities. We will publicly release both the\ntraining data and model weights to foster further research and development in\nthe field of Embodied Intelligence.", "AI": {"tldr": "iFlyBot-VLM是一个通用的视觉语言模型，旨在弥合具身智能中高维感知与低级动作控制之间的语义鸿沟，通过抽象操作语言实现跨平台协调，并在多个主流基准测试中取得了最佳性能。", "motivation": "当前具身智能领域面临高维环境感知与低级机器人运动控制之间存在跨模态语义鸿沟的问题。研究旨在通过构建一个通用的视觉语言模型，推动具身智能从专用任务系统向通用、具有认知能力的智能体发展。", "method": "该研究引入了iFlyBot-VLM模型，其核心是将复杂的视觉和空间信息抽象为与机器人无关且可迁移的“操作语言”，以实现无缝的感知-动作闭环协调。模型架构旨在实现四个关键功能：空间理解与度量推理、交互式目标定位、动作抽象与控制参数生成、以及任务规划与技能排序。", "result": "iFlyBot-VLM在Blink和Where2Place等10个当前主流具身智能相关的VLM基准数据集上进行了评估，取得了最佳性能，同时保持了模型的通用能力。", "conclusion": "iFlyBot-VLM被设想为具身AI领域一个可扩展且通用的基础模型，能够促进该领域从专业化任务导向系统向通用、认知智能代理的进步。研究团队将公开训练数据和模型权重，以促进未来的研究与发展。"}}
{"id": "2511.05241", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2511.05241", "abs": "https://arxiv.org/abs/2511.05241", "authors": ["Yang Lin", "Claudio Bruschini", "Edoardo Charbon"], "title": "Transporter: A 128$\\times$4 SPAD Imager with On-chip Encoder for Spiking Neural Network-based Processing", "comment": null, "summary": "Single-photon avalanche diodes (SPADs) are widely used today in time-resolved\nimaging applications. However, traditional architectures rely on\ntime-to-digital converters (TDCs) and histogram-based processing, leading to\nsignificant data transfer and processing challenges. Previous work based on\nrecurrent neural networks has realized histogram-free processing. To further\naddress these limitations, we propose a novel paradigm that eliminates TDCs by\nintegrating in-sensor spike encoders. This approach enables preprocessing of\nphoton arrival events in the sensor while significantly compressing data,\nreducing complexity, and maintaining real-time edge processing capabilities. A\ndedicated spike encoder folds multiple laser repetition periods, transforming\nphase-based spike trains into density-based spike trains optimized for spiking\nneural network processing and training via backpropagation through time. As a\nproof of concept, we introduce Transporter, a 128$\\times$4 SPAD sensor with a\nper-pixel D flip-flop ring-based spike encoder, designed for intelligent active\ntime-resolved imaging. This work demonstrates a path toward more efficient,\nneuromorphic SPAD imaging systems with reduced data overhead and enhanced\nreal-time processing.", "AI": {"tldr": "本文提出了一种新型的单光子雪崩二极管（SPAD）成像范式，通过在传感器中集成脉冲编码器来消除时间数字转换器（TDCs），从而在传感器内预处理光子事件，显著压缩数据，降低复杂性，并支持实时边缘处理，为高效神经形态SPAD成像系统奠定基础。", "motivation": "传统的SPAD架构依赖TDC和基于直方图的处理，导致数据传输和处理面临巨大挑战。尽管之前有基于循环神经网络的无直方图处理方法，但本文旨在通过消除TDC来进一步解决这些局限性。", "method": "该方法通过在传感器中集成脉冲编码器来消除TDC。专用的脉冲编码器折叠多个激光重复周期，将基于相位的脉冲序列转换为基于密度的脉冲序列，优化用于脉冲神经网络（SNN）处理和通过时间反向传播进行训练。作为概念验证，引入了Transporter，一个128x4的SPAD传感器，每个像素都带有基于D触发器环的脉冲编码器。", "result": "该方法实现了在传感器内的光子到达事件预处理，显著压缩了数据，降低了系统复杂性，并保持了实时边缘处理能力。Transporter传感器的引入证明了这种概念的可行性，旨在用于智能主动时间分辨成像。", "conclusion": "这项工作展示了一条通向更高效、神经形态SPAD成像系统的途径，该系统具有更低的数据开销和增强的实时处理能力。"}}
{"id": "2511.04766", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04766", "abs": "https://arxiv.org/abs/2511.04766", "authors": ["Dhenenjay Yadav", "Rohan Sawai"], "title": "DARN: Dynamic Adaptive Regularization Networks for Efficient and Robust Foundation Model Adaptation", "comment": null, "summary": "Foundation models (FMs) offer powerful representations for geospatial\nanalysis, but adapting them effectively remains challenging. Standard\nadaptation methods, whether full fine-tuning or efficient frozen-backbone\napproaches, typically employ decoders with fixed regularization strategies,\nfailing to account for the significant heterogeneity in satellite imagery. We\nintroduce Dynamic Adaptive Regularization Networks (DARN), a novel decoder\narchitecture designed to address this limitation. DARN integrates three key\ninnovations: (1) a lightweight Task Complexity Predictor (TCP) that estimates\nper-sample difficulty, (2) Adaptive Dropout Modulation (ADM), dynamically\nadjusting dropout rates (from 0.1 to 0.5) based on predicted complexity, and\n(3) Dynamic Capacity Gating (DCG) that modulates channel activation. We provide\ntheoretical justifications linking DARN's optimization to stationary point\nconvergence and its mechanism to adaptive information bottlenecks. Empirically,\nDARN demonstrates exceptional performance across both major adaptation\nparadigms. In full fine-tuning (unfrozen backbone), DARN achieves a new\nstate-of-the-art on the multi-task GeoBench benchmark (86.66% mIoU, +5.56 pp\nover prior SOTA). In efficient adaptation (frozen backbone), DARN achieves\nSOTA-competitive accuracy (90.5% mIoU on Sen1Floods11) while delivering\nsubstantial advantages crucial for real-world deployment: superior\nout-of-distribution (OOD) generalization (+9.5 pp mIoU on AI4SmallFarms),\nenhanced robustness (17% relative reduction in corruption error), and improved\nperformance on minority classes. DARN offers a more intelligent, robust, and\nefficient approach to leveraging FMs in critical geospatial applications.", "AI": {"tldr": "针对地理空间分析中基础模型适应性差的问题，本文提出DARN，一种新型解码器架构，通过动态自适应正则化（包括任务复杂度预测、自适应Dropout和动态容量门控）显著提升了模型在各种适应范式下的性能、泛化能力和鲁棒性。", "motivation": "基础模型在地理空间分析中潜力巨大，但现有的标准适应方法（无论是全微调还是高效冻结骨干方法）通常采用固定正则化策略的解码器，未能有效应对卫星图像的显著异质性，导致适应效果不佳。", "method": "本文引入了动态自适应正则化网络（DARN），这是一种新颖的解码器架构，包含三项关键创新：1) 轻量级任务复杂度预测器（TCP），用于估计每个样本的难度；2) 自适应Dropout调制（ADM），根据预测复杂度动态调整Dropout率（0.1至0.5）；3) 动态容量门控（DCG），用于调制通道激活。研究还提供了理论依据，将DARN的优化与平稳点收敛及其机制与自适应信息瓶颈联系起来。", "result": "DARN在两种主要适应范式下均表现出色。在全微调（骨干未冻结）中，DARN在多任务GeoBench基准测试中达到了新的最先进水平（86.66% mIoU，比先前SOTA提升5.56个百分点）。在高效适应（骨干冻结）中，DARN实现了与SOTA相当的精度（在Sen1Floods11上达到90.5% mIoU），同时在实际部署中展现出显著优势：更优越的域外（OOD）泛化能力（在AI4SmallFarms上mIoU提升9.5个百分点）、增强的鲁棒性（腐败误差相对减少17%）以及在少数类别上的性能提升。", "conclusion": "DARN为在关键地理空间应用中利用基础模型提供了一种更智能、更鲁棒、更高效的方法，显著提升了模型在复杂卫星图像环境下的适应性和性能。"}}
{"id": "2511.05253", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.05253", "abs": "https://arxiv.org/abs/2511.05253", "authors": ["Tiziano Natali", "Karin A. Olthof", "Niels F. M. Kok", "Koert F. D. Kuhlmann", "Theo J. M. Ruers", "Matteo Fusaglia"], "title": "Automatic segmentation of colorectal liver metastases for ultrasound-based navigated resection", "comment": null, "summary": "Introduction: Accurate intraoperative delineation of colorectal liver\nmetastases (CRLM) is crucial for achieving negative resection margins but\nremains challenging using intraoperative ultrasound (iUS) due to low contrast,\nnoise, and operator dependency. Automated segmentation could enhance precision\nand efficiency in ultrasound-based navigation workflows.\n  Methods: Eighty-five tracked 3D iUS volumes from 85 CRLM patients were used\nto train and evaluate a 3D U-Net implemented via the nnU-Net framework. Two\nvariants were compared: one trained on full iUS volumes and another on cropped\nregions around tumors. Segmentation accuracy was assessed using Dice Similarity\nCoefficient (DSC), Hausdorff Distance (HDist.), and Relative Volume Difference\n(RVD) on retrospective and prospective datasets. The workflow was integrated\ninto 3D Slicer for real-time intraoperative use.\n  Results: The cropped-volume model significantly outperformed the full-volume\nmodel across all metrics (AUC-ROC = 0.898 vs 0.718). It achieved median DSC =\n0.74, recall = 0.79, and HDist. = 17.1 mm comparable to semi-automatic\nsegmentation but with ~4x faster execution (~ 1 min). Prospective\nintraoperative testing confirmed robust and consistent performance, with\nclinically acceptable accuracy for real-time surgical guidance.\n  Conclusion: Automatic 3D segmentation of CRLM in iUS using a cropped 3D U-Net\nprovides reliable, near real-time results with minimal operator input. The\nmethod enables efficient, registration-free ultrasound-based navigation for\nhepatic surgery, approaching expert-level accuracy while substantially reducing\nmanual workload and procedure time.", "AI": {"tldr": "该研究提出了一种基于裁剪3D U-Net的自动3D术中超声（iUS）结直肠肝转移瘤（CRLM）分割方法，实现了接近专家水平的准确性和更快的速度，为肝脏手术提供可靠的实时导航。", "motivation": "在术中超声（iUS）中准确描绘结直肠肝转移瘤（CRLM）对于实现阴性切缘至关重要，但由于对比度低、噪声和操作员依赖性，目前仍具挑战。自动分割可以提高超声导航工作流程的精确性和效率。", "method": "使用来自85名CRLM患者的85个跟踪3D iUS体积训练和评估了通过nnU-Net框架实现的3D U-Net。比较了两种变体：一种在完整iUS体积上训练，另一种在肿瘤周围裁剪区域上训练。使用Dice相似系数（DSC）、Hausdorff距离（HDist.）和相对体积差异（RVD）在回顾性和前瞻性数据集上评估分割准确性。该工作流程被集成到3D Slicer中以实现实时术中应用。", "result": "裁剪体积模型在所有指标上均显著优于完整体积模型（AUC-ROC = 0.898 vs 0.718）。它实现了中位数DSC = 0.74，召回率 = 0.79，HDist. = 17.1 mm，与半自动分割相当，但执行速度快约4倍（约1分钟）。前瞻性术中测试证实了其稳健和一致的性能，达到临床可接受的实时手术指导准确性。", "conclusion": "使用裁剪3D U-Net进行iUS中CRLM的自动3D分割提供了可靠、接近实时的结果，且操作员输入最少。该方法能够实现高效、免配准的超声引导肝脏手术导航，接近专家级准确性，同时大幅减少手动工作量和手术时间。"}}
{"id": "2511.04696", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.04696", "abs": "https://arxiv.org/abs/2511.04696", "authors": ["Jan Strich", "Adeline Scharfenberg", "Chris Biemann", "Martin Semmann"], "title": "EncouRAGe: Evaluating RAG Local, Fast, and Reliable", "comment": "Currently under review", "summary": "We introduce EncouRAGe, a comprehensive Python framework designed to\nstreamline the development and evaluation of Retrieval-Augmented Generation\n(RAG) systems using Large Language Models (LLMs) and Embedding Models.\nEncouRAGe comprises five modular and extensible components: Type Manifest, RAG\nFactory, Inference, Vector Store, and Metrics, facilitating flexible\nexperimentation and extensible development. The framework emphasizes scientific\nreproducibility, diverse evaluation metrics, and local deployment, enabling\nresearchers to efficiently assess datasets within RAG workflows. This paper\npresents implementation details and an extensive evaluation across multiple\nbenchmark datasets, including 25k QA pairs and over 51k documents. Our results\nshow that RAG still underperforms compared to the Oracle Context, while Hybrid\nBM25 consistently achieves the best results across all four datasets. We\nfurther examine the effects of reranking, observing only marginal performance\nimprovements accompanied by higher response latency.", "AI": {"tldr": "EncouRAGe是一个用于RAG系统开发和评估的Python框架。研究发现，RAG表现不如Oracle Context，而混合BM25在所有数据集中表现最佳，重排仅带来微小改进但增加了延迟。", "motivation": "简化使用LLM和嵌入模型进行检索增强生成（RAG）系统的开发和评估，实现灵活的实验、可扩展的开发、科学可复现性、多样化的评估指标以及本地部署。", "method": "引入EncouRAGe，一个包含Type Manifest、RAG Factory、Inference、Vector Store和Metrics五个模块化组件的Python框架。通过对多个基准数据集（包括2.5万个QA对和超过5.1万个文档）进行广泛评估，展示了其实现细节和性能。", "result": "RAG系统在性能上仍不如Oracle Context。混合BM25在所有四个数据集中始终表现最佳。重排仅带来微小的性能提升，但伴随着更高的响应延迟。", "conclusion": "EncouRAGe提供了一个全面的框架来简化RAG系统的开发和评估。研究结果表明，RAG系统在获取理想上下文方面仍有不足，混合BM25是一种高效的检索策略，而重排的性能收益可能不足以抵消其增加的延迟。"}}
{"id": "2511.05116", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.05116", "abs": "https://arxiv.org/abs/2511.05116", "authors": ["Alex Junior da Cunha Coelho", "Araceli Hernandez", "Luis Badesa"], "title": "Evaluating the Impact of a Load Admittance Approximation in Transient Stability-Constrained Optimal Power Flow", "comment": "1-5 pages. submitted to PESGM 2026, Canada", "summary": "The Transient Stability-Constrained Optimal Power Flow (TSC-OPF) incorporates\ndynamic stability constraints into the OPF formulation to ensure secure and\neconomical operation under disturbances. While discretizing system dynamics\nenables the use of nonlinear programming techniques, it significantly increases\ncomputational burden. To enhance scalability, many studies simplify the network\nby representing loads as constant admittances, allowing the use of Kron\nreduction. However, computing the Kron reduction outside the optimization\nrequires a voltage-based assumption to convert loads from constant power to\nconstant admittance. This paper proposes a practical voltage-based load\nadmittance approximation and evaluates the errors it may introduce in rotor\nangle and speed deviation trajectories. Case studies on the WECC 9-bus system\nshow that the proposed approach reproduces rotor dynamics consistent with\ntime-domain simulations during the first few seconds while considerably\nreducing implementation effort and mitigating convergence issues. The proposed\nframework thus offers a simple and effective strategy for scalable TSC-OPF\nimplementations.", "AI": {"tldr": "本文提出了一种实用的基于电压的负荷导纳近似方法，用于瞬态稳定约束最优潮流（TSC-OPF）中的网络简化，以减轻计算负担并提高可扩展性，同时保持转子动力学仿真的准确性。", "motivation": "瞬态稳定约束最优潮流（TSC-OPF）通过离散化系统动态来确保在扰动下的安全经济运行，但计算负担巨大。许多研究通过将负荷表示为恒定导纳并使用克朗约化来简化网络，但这需要一个基于电压的假设将恒定功率负荷转换为恒定导纳，且通常在优化外部进行。本文旨在提出并评估这种近似方法引入的误差。", "method": "提出了一种实用的基于电压的负荷导纳近似方法。通过评估该近似方法在转子角度和转速偏差轨迹中可能引入的误差来验证其有效性。利用克朗约化简化网络。", "result": "在WECC 9节点系统上的案例研究表明，所提出的方法在最初几秒内能够重现与时域仿真一致的转子动态。它显著减少了实现工作量并缓解了收敛问题。", "conclusion": "所提出的框架为可扩展的TSC-OPF实现提供了一种简单而有效的策略。"}}
{"id": "2511.05118", "categories": ["eess.SY", "cs.SY", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.05118", "abs": "https://arxiv.org/abs/2511.05118", "authors": ["Ian Kolaja", "Ludovic Jantzen", "Tatiana Siaraferas", "Massimiliano Fratoni"], "title": "Predicting and forecasting reactivity and flux using long short-term memory models in pebble bed reactors during run-in", "comment": "13 pages", "summary": "Pebble bed reactor (PBR) operation presents unique advantages and challenges\ndue to the ability to continuously change the fuel mixture and excess\nreactivity. Each operation parameter affects reactivity on a different\ntimescale. For example, fuel insertion changes may take months to fully\npropagate, whereas control rod movements have immediate effects. In-core\nmeasurements are further limited by the high temperatures, intense neutron\nflux, and dynamic motion of the fuel bed. In this study, long short-term memory\n(LSTM) networks are trained to predict reactivity, flux profiles, and power\nprofiles as functions of operating history and synthetic batch-level pebble\nmeasurements, such as discharge burnup distributions. The model's performance\nis evaluated using unseen temporal data, achieving an $R^2$ of 0.9914 on the\ntesting set. The capability of the network to forecast reactivity responses to\nfuture operational changes is also examined, and its application for optimizing\nreactor running-in procedures is explored.", "AI": {"tldr": "本研究利用长短期记忆（LSTM）网络，通过操作历史和合成的批次级燃料测量数据，预测球床反应堆（PBR）的反应性、通量分布和功率分布，并在未见数据上取得了高精度，探索了其在优化反应堆运行程序中的应用。", "motivation": "球床反应堆（PBR）由于燃料混合物和过剩反应性的持续变化，以及不同操作参数对反应性影响时间尺度的差异（如燃料插入需数月，控制棒即时生效），带来了独特的优势和挑战。此外，堆内测量受限于高温、高注量和燃料床的动态运动。这些因素促使研究者寻求更有效的预测和优化工具。", "method": "本研究训练了长短期记忆（LSTM）网络，以操作历史和合成的批次级球形燃料测量（如卸料燃耗分布）作为输入。模型旨在预测反应性、通量分布和功率分布。", "result": "模型在未见的时间序列数据上进行了性能评估，在测试集上取得了0.9914的R²值。研究还检验了网络预测未来操作变化对反应性响应的能力，并探讨了其在优化反应堆启动程序中的应用。", "conclusion": "LSTM网络能够有效预测球床反应堆的反应性、通量和功率分布，展现了对未来操作变化进行预测的潜力，并可应用于优化反应堆的运行程序，从而应对PBR操作中的独特挑战。"}}
{"id": "2511.04779", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04779", "abs": "https://arxiv.org/abs/2511.04779", "authors": ["Andrea Aspesi", "Andrea Simpsi", "Aaron Tognoli", "Simone Mentasti", "Luca Merigo", "Matteo Matteucci"], "title": "EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear", "comment": "International Joint Conference on Neural Networks (IJCNN), 2025", "summary": "Event-based cameras are becoming a popular solution for efficient, low-power\neye tracking. Due to the sparse and asynchronous nature of event data, they\nrequire less processing power and offer latencies in the microsecond range.\nHowever, many existing solutions are limited to validation on powerful GPUs,\nwith no deployment on real embedded devices. In this paper, we present EETnet,\na convolutional neural network designed for eye tracking using purely\nevent-based data, capable of running on microcontrollers with limited\nresources. Additionally, we outline a methodology to train, evaluate, and\nquantize the network using a public dataset. Finally, we propose two versions\nof the architecture: a classification model that detects the pupil on a grid\nsuperimposed on the original image, and a regression model that operates at the\npixel level.", "AI": {"tldr": "本文提出EETnet，一个专为事件相机设计的眼动追踪卷积神经网络，能够运行在资源受限的微控制器上。", "motivation": "事件相机因其高效和低功耗特性，在眼动追踪领域日益普及。然而，现有解决方案多依赖强大的GPU进行验证，难以部署到实际的嵌入式设备上，缺乏能在微控制器上运行的低功耗、低延迟方案。", "method": "本文提出了EETnet，一个专门用于纯事件数据眼动追踪的卷积神经网络，旨在微控制器上运行。同时，概述了一套使用公开数据集进行网络训练、评估和量化的方法。EETnet提供两个版本：一个在图像网格上检测瞳孔的分类模型，以及一个在像素级别操作的回归模型。", "result": "EETnet是一个能够利用纯事件数据进行眼动追踪的卷积神经网络，并具备在资源有限的微控制器上运行的能力。", "conclusion": "本文提出了一个适用于嵌入式设备的事件相机眼动追踪解决方案（EETnet），并提供了一套完整的训练、评估和量化方法，解决了现有方案在资源受限设备上部署的难题。"}}
{"id": "2511.04698", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04698", "abs": "https://arxiv.org/abs/2511.04698", "authors": ["K M Sajjadul Islam", "John Fields", "Praveen Madiraju"], "title": "multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder", "comment": "Accepted in IEEE Big Data, 8-11 December, 2025 @ Macau SAR, China", "summary": "The early detection of mental health disorders from social media text is\ncritical for enabling timely support, risk assessment, and referral to\nappropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned\nRoBERTa model designed for multiclass classification of common mental health\nconditions, including stress, anxiety, depression, post-traumatic stress\ndisorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple\ncurated datasets, data exploration is conducted to analyze class overlaps,\nrevealing strong correlations between depression and suicidal ideation as well\nas anxiety and PTSD, while stress emerges as a broad, overlapping category.\nComparative experiments with traditional machine learning methods,\ndomain-specific transformers, and prompting-based large language models\ndemonstrate that multiMentalRoBERTa achieves superior performance, with macro\nF1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup\n(excluding stress), outperforming both fine-tuned MentalBERT and baseline\nclassifiers. Beyond predictive accuracy, explainability methods, including\nLayer Integrated Gradients and KeyBERT, are applied to identify lexical cues\nthat drive classification, with a particular focus on distinguishing depression\nfrom suicidal ideation. The findings emphasize the effectiveness of fine-tuned\ntransformers for reliable and interpretable detection in sensitive contexts,\nwhile also underscoring the importance of fairness, bias mitigation, and\nhuman-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as\na lightweight, robust, and deployable solution for enhancing support in mental\nhealth platforms.", "AI": {"tldr": "本文提出multiMentalRoBERTa，一个经过微调的RoBERTa模型，用于从社交媒体文本中多类别分类检测常见的心理健康状况，并在性能和可解释性方面优于现有方法。", "motivation": "从社交媒体文本中早期发现心理健康障碍对于及时提供支持、风险评估和转介至适当资源至关重要。", "method": "研究引入了multiMentalRoBERTa，一个针对压力、焦虑、抑郁、创伤后应激障碍(PTSD)、自杀意念和中性话语进行多类别分类的微调RoBERTa模型。利用多个精选数据集进行数据探索，分析类别重叠。通过与传统机器学习方法、领域特定Transformer（如MentalBERT）和基于提示的大型语言模型进行比较实验。此外，应用可解释性方法（如Layer Integrated Gradients和KeyBERT）来识别分类的词汇线索。", "result": "数据探索揭示了抑郁症与自杀意念以及焦虑症与PTSD之间存在强相关性，而压力则是一个广泛重叠的类别。multiMentalRoBERTa在六类别设置中实现了0.839的宏F1分数，在五类别设置（排除压力）中实现了0.870的宏F1分数，均优于微调的MentalBERT和基线分类器。可解释性方法成功识别了驱动分类的词汇线索，特别是在区分抑郁症和自杀意念方面。", "conclusion": "研究结果强调了微调Transformer在敏感情境下进行可靠和可解释检测的有效性，同时也强调了公平性、偏见缓解和人工干预安全协议的重要性。multiMentalRoBERTa被认为是一种轻量级、稳健且可部署的解决方案，用于增强心理健康平台的支持。"}}
{"id": "2511.04898", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04898", "abs": "https://arxiv.org/abs/2511.04898", "authors": ["Yule Wen", "Yixin Ye", "Yanzhe Zhang", "Diyi Yang", "Hao Zhu"], "title": "Real-Time Reasoning Agents in Evolving Environments", "comment": "30 pages", "summary": "Agents in the real world must make not only logical but also timely\njudgments. This requires continuous awareness of the dynamic environment:\nhazards emerge, opportunities arise, and other agents act, while the agent's\nreasoning is still unfolding. Despite advances in language model reasoning,\nexisting approaches fail to account for this dynamic nature. We introduce\nreal-time reasoning as a new problem formulation for agents in evolving\nenvironments and build Real-Time Reasoning Gym to demonstrate it. We study two\nparadigms for deploying language models in agents: (1) reactive agents, which\nemploy language models with bounded reasoning computation for rapid responses,\nand (2) planning agents, which allow extended reasoning computation for complex\nproblems. Our experiments show that even state-of-the-art models struggle with\nmaking logical and timely judgments in either paradigm. To address this\nlimitation, we propose AgileThinker, which simultaneously engages both\nreasoning paradigms. AgileThinker consistently outperforms agents engaging only\none reasoning paradigm as the task difficulty and time pressure rise,\neffectively balancing reasoning depth and response latency. Our work\nestablishes real-time reasoning as a critical testbed for developing practical\nagents and provides a foundation for research in temporally constrained AI\nsystems, highlighting a path toward real-time capable agents.", "AI": {"tldr": "本文提出“实时推理”作为代理在动态环境中进行及时且逻辑判断的新问题，并构建Real-Time Reasoning Gym。研究发现现有语言模型难以应对，为此提出AgileThinker，通过同时结合反应式和规划式推理，有效平衡推理深度和响应延迟，在任务难度和时间压力增加时表现更优。", "motivation": "现实世界中的代理不仅需要逻辑判断，还需要及时判断，这要求它们持续感知动态环境。尽管语言模型推理取得了进展，但现有方法未能考虑这种动态性，无法在推理进行中应对环境变化（如危险出现、机会产生、其他代理行动）。", "method": "1. 引入“实时推理”作为代理在不断演变环境中的新问题。2. 构建“Real-Time Reasoning Gym”以进行演示和研究。3. 研究了两种部署语言模型的范式：反应式代理（有限计算，快速响应）和规划式代理（扩展计算，解决复杂问题）。4. 提出AgileThinker，该方法同时结合了反应式和规划式两种推理范式。", "result": "1. 即使是先进的语言模型，在反应式和规划式两种范式下，都难以做出逻辑且及时的判断。2. AgileThinker在任务难度和时间压力增加时，始终优于仅采用单一推理范式的代理。3. AgileThinker有效地平衡了推理深度和响应延迟。", "conclusion": "1. 实时推理是开发实用代理的关键测试平台。2. 本工作为时间受限AI系统的研究奠定了基础。3. 强调了实现实时能力代理的路径。"}}
{"id": "2511.04956", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04956", "abs": "https://arxiv.org/abs/2511.04956", "authors": ["Maria Mahbub", "Vanessa Lama", "Sanjay Das", "Brian Starks", "Christopher Polchek", "Saffell Silvers", "Lauren Deck", "Prasanna Balaprakash", "Tirthankar Ghosal"], "title": "ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property", "comment": null, "summary": "High-Risk Property (HRP) classification is critical at U.S. Department of\nEnergy (DOE) sites, where inventories include sensitive and often dual-use\nequipment. Compliance must track evolving rules designated by various export\ncontrol policies to make transparent and auditable decisions. Traditional\nexpert-only workflows are time-consuming, backlog-prone, and struggle to keep\npace with shifting regulatory boundaries. We demo ORCHID, a modular agentic\nsystem for HRP classification that pairs retrieval-augmented generation (RAG)\nwith human oversight to produce policy-based outputs that can be audited. Small\ncooperating agents, retrieval, description refiner, classifier, validator, and\nfeedback logger, coordinate via agent-to-agent messaging and invoke tools\nthrough the Model Context Protocol (MCP) for model-agnostic on-premise\noperation. The interface follows an Item to Evidence to Decision loop with\nstep-by-step reasoning, on-policy citations, and append-only audit bundles\n(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID\nimproves accuracy and traceability over a non-agentic baseline while deferring\nuncertain items to Subject Matter Experts (SMEs). The demonstration shows\nsingle item submission, grounded citations, SME feedback capture, and\nexportable audit artifacts, illustrating a practical path to trustworthy LLM\nassistance in sensitive DOE compliance workflows.", "AI": {"tldr": "ORCHID是一个模块化代理系统，结合检索增强生成（RAG）和人工监督，用于美国能源部（DOE）高风险财产（HRP）分类，旨在提高准确性和可追溯性，以应对不断变化的出口管制政策。", "motivation": "美国能源部（DOE）现场的敏感双用途设备库存需要准确的高风险财产（HRP）分类，但传统的专家工作流程耗时、易积压，且难以跟上不断变化的出口管制政策和法规。", "method": "该研究展示了ORCHID系统，一个模块化的代理系统，通过检索增强生成（RAG）与人工监督相结合，生成基于政策的、可审计的分类结果。它由多个协作代理（检索、描述优化、分类器、验证器、反馈记录器）组成，这些代理通过代理间消息进行协调，并通过模型上下文协议（MCP）调用工具以实现模型无关的本地操作。系统遵循“项目到证据到决策”的循环，提供逐步推理、政策引文和可追加的审计包。", "result": "在真实HRP案例的初步测试中，ORCHID相比非代理基线提高了分类准确性和可追溯性，并能将不确定项转交给主题专家（SME）处理。演示展示了单项提交、有依据的引用、SME反馈捕获以及可导出的审计工件。", "conclusion": "ORCHID系统为敏感的美国能源部合规工作流程中，实现值得信赖的大型语言模型（LLM）辅助提供了一条切实可行的途径，提高了分类效率和审计能力。"}}
{"id": "2511.04992", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04992", "abs": "https://arxiv.org/abs/2511.04992", "authors": ["Bibekananda Patra", "Sandipan Bandyopadhyay"], "title": "A semi-analytical approach for computing the largest singularity-free spheres of a class of 6-6 Stewart-Gough platforms for specified orientation workspaces", "comment": null, "summary": "This article presents a method for computing the largest singularity-free\nsphere (SFS) of a 6-6 Stewart-Gough platform manipulator (SGPM) over a\nspecified orientation workspace. For a fixed orientation of the moving\nplatform, the SFS is computed analytically. This process is repeated over a set\nof samples generated within the orientation workspace, and the smallest among\nthem is designated as the desired SFS for the given orientation workspace.\nNumerical experiments are performed on four distinct architectures of the SGPM\nto understand their relative performances w.r.t. SFS volumes over the same\norientation workspace. This study demonstrates the potential utility of the\nproposed computational method both in analysis and design of SGPMs.", "AI": {"tldr": "本文提出了一种计算6-6 Stewart-Gough平台机械手（SGPM）在给定姿态工作空间内最大无奇异球体（SFS）的方法，并进行了不同架构的性能比较。", "motivation": "研究SGPM在指定姿态工作空间内的无奇异区域，以了解其性能并辅助SGPM的分析和设计。", "method": "对于移动平台的固定姿态，解析计算SFS；对姿态工作空间内生成的一系列样本重复此过程；选择其中最小的SFS作为给定姿态工作空间的所需SFS。通过对四种不同SGPM架构进行数值实验，比较它们在相同姿态工作空间下SFS体积的相对性能。", "result": "该方法能够计算SGPM在指定姿态工作空间内的最大SFS。数值实验展示了不同SGPM架构在SFS体积方面的相对性能。", "conclusion": "所提出的计算方法在SGPM的分析和设计中具有潜在的实用价值。"}}
{"id": "2511.04773", "categories": ["cs.CV", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.04773", "abs": "https://arxiv.org/abs/2511.04773", "authors": ["Shirin Ermis", "Cesar Aybar", "Lilli Freischem", "Stella Girtsou", "Kyriaki-Margarita Bintsi", "Emiliano Diaz Salas-Porras", "Michael Eisinger", "William Jones", "Anna Jungbluth", "Benoit Tremblay"], "title": "Global 3D Reconstruction of Clouds & Tropical Cyclones", "comment": null, "summary": "Accurate forecasting of tropical cyclones (TCs) remains challenging due to\nlimited satellite observations probing TC structure and difficulties in\nresolving cloud properties involved in TC intensification. Recent research has\ndemonstrated the capabilities of machine learning methods for 3D cloud\nreconstruction from satellite observations. However, existing approaches have\nbeen restricted to regions where TCs are uncommon, and are poorly validated for\nintense storms. We introduce a new framework, based on a\npre-training--fine-tuning pipeline, that learns from multiple satellites with\nglobal coverage to translate 2D satellite imagery into 3D cloud maps of\nrelevant cloud properties. We apply our model to a custom-built TC dataset to\nevaluate performance in the most challenging and relevant conditions. We show\nthat we can - for the first time - create global instantaneous 3D cloud maps\nand accurately reconstruct the 3D structure of intense storms. Our model not\nonly extends available satellite observations but also provides estimates when\nobservations are missing entirely. This is crucial for advancing our\nunderstanding of TC intensification and improving forecasts.", "AI": {"tldr": "本研究开发了一个基于预训练-微调的机器学习框架，利用多颗卫星数据首次实现了全球瞬时3D云图的创建，并能准确重建强热带气旋的3D结构，即使在观测数据缺失时也能提供估计。", "motivation": "热带气旋预报面临挑战，原因在于卫星对TC结构观测有限，且难以解析TC增强中的云属性。现有机器学习3D云重建方法不适用于TC常见区域，也未在强风暴中得到充分验证。", "method": "引入了一个新的框架，采用预训练-微调流程，利用全球覆盖的多颗卫星数据，将2D卫星图像转换为相关云属性的3D云图。该模型在一个定制的TC数据集上进行应用和性能评估。", "result": "首次成功创建了全球瞬时3D云图，并能准确重建强风暴的3D结构。该模型不仅扩展了现有卫星观测，还能在观测数据完全缺失时提供估计。", "conclusion": "该模型对增进对热带气旋增强的理解和改进预报至关重要。"}}
{"id": "2511.05182", "categories": ["cs.AI", "cs.CY", "H.4.2; I.2.3; I.2.6; I.2.8; J.7"], "pdf": "https://arxiv.org/pdf/2511.05182", "abs": "https://arxiv.org/abs/2511.05182", "authors": ["Johan Schubert", "Patrik Hansen", "Pontus Hörling", "Ronnie Johansson"], "title": "Autonomous generation of different courses of action in mechanized combat operations", "comment": "In Proceedings of the 30th International Command and Control Research\n  & Technology Symposium, Stockholm, Sweden, 3-6 November 2025, paper 009", "summary": "In this paper, we propose a methodology designed to support decision-making\nduring the execution phase of military ground combat operations, with a focus\non one's actions. This methodology generates and evaluates recommendations for\nvarious courses of action for a mechanized battalion, commencing with an\ninitial set assessed by their anticipated outcomes. It systematically produces\nthousands of individual action alternatives, followed by evaluations aimed at\nidentifying alternative courses of action with superior outcomes. These\nalternatives are appraised in light of the opponent's status and actions,\nconsidering unit composition, force ratios, types of offense and defense, and\nanticipated advance rates. Field manuals evaluate battle outcomes and\nadvancement rates. The processes of generation and evaluation work\nconcurrently, yielding a variety of alternative courses of action. This\napproach facilitates the management of new course generation based on\npreviously evaluated actions. As the combat unfolds and conditions evolve,\nrevised courses of action are formulated for the decision-maker within a\nsequential decision-making framework.", "AI": {"tldr": "本文提出了一种支持军事地面作战执行阶段决策的方法论，通过生成和评估机械化营的行动方案，以期获得更优的作战结果。", "motivation": "研究动机是为了在军事地面作战的执行阶段支持决策制定，特别是关于己方行动的决策，旨在生成并评估推荐的行动方案以获得更优结果。", "method": "该方法论首先生成并评估机械化营的初始行动方案集。随后，系统性地产生数千种单独的行动替代方案，并根据预期结果、对手状态、单位组成、兵力比、攻防类型和预期推进速度进行评估。生成和评估过程同时进行，并利用作战手册评估战斗结果和推进速度。该方法支持基于先前评估行动的新方案生成管理，并在战斗演变时，在序贯决策框架内为决策者制定修订的行动方案。", "result": "该方法能够生成并评估数千种具有更优结果的替代行动方案，促进了基于先前评估行动的新方案生成管理。随着战斗的展开和条件的变化，可以为决策者制定修订的行动方案。", "conclusion": "该方法论通过系统性地生成和评估军事地面作战的行动方案，支持在战斗执行阶段的决策制定，并能适应不断变化的作战条件，提供修订的、更优的行动方案。"}}
{"id": "2511.04699", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04699", "abs": "https://arxiv.org/abs/2511.04699", "authors": ["Haneen Al-Homoud", "Asma Ibrahim", "Murtadha Al-Jubran", "Fahad Al-Otaibi", "Yazeed Al-Harbi", "Daulet Toibazar", "Kesen Wang", "Pedro J. Moreno"], "title": "Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding", "comment": null, "summary": "Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address\nthe scarcity of Arabic resources for Optical Character Recognition (OCR) and\nDocument Understanding (DU). The dataset comprises over 2.5 million of samples,\nincluding 1.5 million textual data, 270K fully annotated tables, and hundred\nthousands of real data based charts. Our pipeline leverages authentic scanned\nbackgrounds, bilingual layouts, and diacritic aware fonts to capture the\ntypographic and structural complexity of Arabic documents. In addition to text,\nthe corpus includes variety of rendered styles for charts and tables.\nFinetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word\nError Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple\npublic Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart\nExtraction Score (CharTeX) improved as well in other modalities. SynthDocs\nprovides a scalable, visually realistic resource for advancing research in\nmultilingual document analysis.", "AI": {"tldr": "Cross-Lingual SynthDocs是一个大规模合成语料库，旨在解决阿拉伯语OCR和文档理解资源稀缺问题，通过其训练的模型在多项基准测试中显著提升了性能。", "motivation": "当前阿拉伯语OCR（光学字符识别）和文档理解（DU）资源匮乏，限制了相关研究和应用的发展。", "method": "该研究构建了Cross-Lingual SynthDocs语料库，包含超过250万样本，包括150万文本数据、27万完全标注的表格以及数十万基于真实数据的图表。其生成流程利用真实的扫描背景、双语布局和支持变音符号的字体，以捕捉阿拉伯语文档的排版和结构复杂性。语料库还包含各种渲染风格的图表和表格。", "result": "在SynthDocs上对Qwen-2.5-VL进行微调后，OCR的词错误率（WER）和字符错误率（CER）在多个公开阿拉伯语基准测试中均持续改善。同时，表格的树编辑距离相似度（TEDS）和图表的图表提取分数（CharTeX）也得到了提升。", "conclusion": "SynthDocs提供了一个可扩展且视觉逼真的资源，能够有效推动多语言文档分析领域的研究进展。"}}
{"id": "2511.05252", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.05252", "abs": "https://arxiv.org/abs/2511.05252", "authors": ["Hamed Rezazadeh", "Mohammad Monfared", "Meghdad Fazeli", "Saeed Golestan"], "title": "Voltage-Independent Active-Power Droop Coefficient for Enhanced Andronov-Hopf Oscillator Grid-Forming Inverters", "comment": "10 pages", "summary": "In recent years, virtual oscillator control, particularly the Andronov-Hopf\noscillator (AHO), has received widespread attention for controlling\ngrid-forming (GFM) inverters due to their superior dynamic response. However,\ntraditional AHO systems feature droop coefficients that are dependent on the\noscillator voltage amplitude, limiting their ability to maintain consistent\ngrid support during disturbances and resulting in power-sharing inaccuracies.\nThis paper presents an enhanced AHO (EAHO) strategy, where the active power\ndroop coefficient is no longer a function of the voltage amplitude and retains\nthe key dynamic benefits of the original AHO. The EAHO improves both frequency\nand voltage support and ensures accurate power sharing with other GFM inverters\nin grid-connected and stand-alone modes. Extensive comparative and small-signal\nanalyses, alongside experimental validation on 2.5 kVA single-phase inverters,\nconfirm the EAHO's improved steady-state performance, enhanced active and\nreactive power support, and stable operation under varying grid conditions.", "AI": {"tldr": "本文提出一种增强型Andronov-Hopf振荡器（EAHO）策略，通过解耦有功功率下垂系数与电压幅度的关系，显著改善了电网形成逆变器的频率和电压支持能力，并提高了功率共享精度。", "motivation": "传统的Andronov-Hopf振荡器（AHO）控制电网形成（GFM）逆变器时，其下垂系数依赖于振荡器电压幅度，这限制了其在扰动下保持一致电网支持的能力，并导致功率共享不准确。", "method": "本文提出了一种增强型AHO（EAHO）策略，其中有功功率下垂系数不再是电压幅度的函数，同时保留了原始AHO的关键动态优势。通过广泛的比较分析、小信号分析以及在2.5 kVA单相逆变器上的实验验证，评估了EAHO的性能。", "result": "EAHO策略改善了稳态性能，增强了有功和无功功率支持，并确保了在并网和独立模式下与其他GFM逆变器的精确功率共享。实验结果证实了EAHO在不同电网条件下改进的稳态性能、增强的功率支持和稳定运行。", "conclusion": "EAHO策略为GFM逆变器提供了优越的动态响应，解决了传统AHO的局限性，实现了更一致的电网支持和更准确的功率共享，是控制GFM逆变器的有效方法。"}}
{"id": "2511.05216", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.05216", "abs": "https://arxiv.org/abs/2511.05216", "authors": ["Ioannis Karampinis", "Petros Ellinas", "Johanna Vorwerk", "Spyros Chatzivasileiadis"], "title": "Neural Operators for Power Systems: A Physics-Informed Framework for Modeling Power System Components", "comment": "Submitted to PSCC 2026 (under review)", "summary": "Modern power systems require fast and accurate dynamic simulations for\nstability assessment, digital twins, and real-time control, but classical ODE\nsolvers are often too slow for large-scale or online applications. We propose a\nneural-operator framework for surrogate modeling of power system components,\nusing Deep Operator Networks (DeepONets) to learn mappings from system states\nand time-varying inputs to full trajectories without step-by-step integration.\nTo enhance generalization and data efficiency, we introduce Physics-Informed\nDeepONets (PI-DeepONets), which embed the residuals of governing equations into\nthe training loss. Our results show that DeepONets, and especially\nPI-DeepONets, achieve accurate predictions under diverse scenarios, providing\nover 30 times speedup compared to high-order ODE solvers. Benchmarking against\nPhysics-Informed Neural Networks (PINNs) highlights superior stability and\nscalability. Our results demonstrate neural operators as a promising path\ntoward real-time, physics-aware simulation of power system dynamics.", "AI": {"tldr": "本文提出了一种基于深度算子网络（DeepONets）及其物理信息版本（PI-DeepONets）的代理模型框架，用于快速准确地模拟电力系统动态，相较于传统ODE求解器实现了显著加速。", "motivation": "现代电力系统需要快速准确的动态仿真进行稳定性评估、数字孪生和实时控制，但传统的常微分方程（ODE）求解器对于大规模或在线应用来说速度过慢。", "method": "研究者提出了一个神经算子框架，利用深度算子网络（DeepONets）学习从系统状态和时变输入到完整轨迹的映射，无需逐步积分。为了提高泛化能力和数据效率，引入了物理信息深度算子网络（PI-DeepONets），将控制方程的残差嵌入到训练损失中。", "result": "DeepONets，特别是PI-DeepONets，在不同场景下均实现了准确预测，与高阶ODE求解器相比，速度提升了30倍以上。与物理信息神经网络（PINNs）的基准测试表明，该方法具有卓越的稳定性和可扩展性。", "conclusion": "研究结果表明，神经算子是实现电力系统动态实时、物理感知仿真的一个有前景的途径。"}}
{"id": "2511.05007", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05007", "abs": "https://arxiv.org/abs/2511.05007", "authors": ["Baiye Cheng", "Tianhai Liang", "Suning Huang", "Maanping Shao", "Feihong Zhang", "Botian Xu", "Zhengrong Xue", "Huazhe Xu"], "title": "MoE-DP: An MoE-Enhanced Diffusion Policy for Robust Long-Horizon Robotic Manipulation with Skill Decomposition and Failure Recovery", "comment": null, "summary": "Diffusion policies have emerged as a powerful framework for robotic\nvisuomotor control, yet they often lack the robustness to recover from subtask\nfailures in long-horizon, multi-stage tasks and their learned representations\nof observations are often difficult to interpret. In this work, we propose the\nMixture of Experts-Enhanced Diffusion Policy (MoE-DP), where the core idea is\nto insert a Mixture of Experts (MoE) layer between the visual encoder and the\ndiffusion model. This layer decomposes the policy's knowledge into a set of\nspecialized experts, which are dynamically activated to handle different phases\nof a task. We demonstrate through extensive experiments that MoE-DP exhibits a\nstrong capability to recover from disturbances, significantly outperforming\nstandard baselines in robustness. On a suite of 6 long-horizon simulation\ntasks, this leads to a 36% average relative improvement in success rate under\ndisturbed conditions. This enhanced robustness is further validated in the real\nworld, where MoE-DP also shows significant performance gains. We further show\nthat MoE-DP learns an interpretable skill decomposition, where distinct experts\ncorrespond to semantic task primitives (e.g., approaching, grasping). This\nlearned structure can be leveraged for inference-time control, allowing for the\nrearrangement of subtasks without any re-training.Our video and code are\navailable at the https://moe-dp-website.github.io/MoE-DP-Website/.", "AI": {"tldr": "本文提出MoE-DP，一种通过在视觉编码器和扩散模型之间插入专家混合层（MoE）来增强的扩散策略，显著提高了机器人长程任务的鲁棒性、可解释性，并能从干扰中恢复。", "motivation": "扩散策略在机器人视觉运动控制中表现强大，但在长程、多阶段任务中，它们往往缺乏从子任务失败中恢复的鲁棒性，并且其学习到的观测表示难以解释。", "method": "核心思想是在视觉编码器和扩散模型之间插入一个专家混合（MoE）层。该层将策略知识分解为一组专业专家，这些专家被动态激活以处理任务的不同阶段。", "result": "MoE-DP在鲁棒性方面显著优于标准基线，在6个长程模拟任务中，受干扰条件下的成功率平均相对提高了36%。在真实世界中也验证了其显著的性能提升。此外，MoE-DP学习到可解释的技能分解，其中不同的专家对应于语义任务基元（例如，接近、抓取），这种结构可用于推理时控制，无需重新训练即可重新安排子任务。", "conclusion": "MoE-DP通过引入专家混合层，成功解决了扩散策略在长程机器人控制中缺乏鲁棒性和可解释性的问题，实现了从干扰中恢复的能力，并能学习可解释的技能分解，支持灵活的任务执行。"}}
{"id": "2511.04700", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04700", "abs": "https://arxiv.org/abs/2511.04700", "authors": ["Song Wang", "Zihan Chen", "Peng Wang", "Zhepei Wei", "Zhen Tan", "Yu Meng", "Cong Shen", "Jundong Li"], "title": "Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation", "comment": "EMNLP Main 2025", "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nintegrating external knowledge sources to address their limitations in\naccessing up-to-date or specialized information. A natural strategy to increase\nthe likelihood of retrieving relevant information is to expand the number of\nretrieved documents. However, involving more documents could introduce\nsignificant noise, as many documents may be irrelevant or misleading, thereby\nreducing the overall accuracy of the generated responses. To overcome the\nchallenge associated with handling a larger number of documents, we propose\nWinnowRAG, a novel RAG framework designed to systematically filter out noisy\ndocuments while preserving valuable content -- a process we refer to as\nwinnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware\nclustering to group similar documents and form distinct topic clusters. Each\ncluster is assigned to an LLM agent for generating a unique answer. In Stage\nII, we perform winnowing, wherein a critic LLM evaluates the outputs of\nmultiple agents and iteratively separates useful documents from noisy ones. To\nretain useful documents when discarding agents, we propose two strategic\nmerging techniques to ensure that only relevant knowledge is used for\ngenerating the final response. Crucially, WinnowRAG is model-agnostic and does\nnot require any model fine-tuning, making it easily adaptable to various tasks.\nExtensive experiments on various realistic datasets demonstrate the\neffectiveness of WinnowRAG over state-of-the-art baselines.", "AI": {"tldr": "WinnowRAG是一个新颖的RAG框架，通过查询感知聚类和评论LLM的迭代筛选，有效过滤噪声文档并保留有价值内容，从而在不进行模型微调的情况下提高生成响应的准确性。", "motivation": "检索增强生成（RAG）通过整合外部知识源来增强大型语言模型（LLMs），以解决其在访问最新或专业信息方面的局限性。增加检索文档的数量可以提高检索到相关信息的可能性，但这也会引入大量噪声，因为许多文档可能不相关或具有误导性，从而降低生成响应的整体准确性。本研究旨在克服处理大量文档所带来的挑战。", "method": "WinnowRAG框架分两个阶段操作：第一阶段进行查询感知聚类，将相似文档分组形成不同的主题簇，每个簇分配给一个LLM代理生成唯一答案。第二阶段进行筛选，一个评论LLM评估多个代理的输出，并迭代地将有用文档与噪声文档分离。为在舍弃代理时保留有用文档，提出了两种策略性合并技术，以确保仅使用相关知识生成最终响应。WinnowRAG与模型无关，无需任何模型微调。", "result": "在各种真实数据集上进行的广泛实验表明，WinnowRAG比现有最先进的基线方法更有效。", "conclusion": "WinnowRAG通过系统地筛选噪声文档，有效解决了RAG中处理大量文档引入噪声的挑战，显著提高了生成响应的准确性。其模型无关和无需微调的特性使其易于适应各种任务。"}}
{"id": "2511.04803", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2.10; I.4.6"], "pdf": "https://arxiv.org/pdf/2511.04803", "abs": "https://arxiv.org/abs/2511.04803", "authors": ["Shuo Zhao", "Jianxu Chen"], "title": "Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose", "comment": "Accepted to IEEE BIBM 2025 Workshop; 6 pages; 4 figures; 5 tables;\n  IEEEtran class. Code: https://github.com/MMV-Lab/biomedseg-efficiency", "summary": "Generalist biomedical image segmentation models such as Cellpose are\nincreasingly applied across diverse imaging modalities and cell types. However,\ntwo critical challenges remain underexplored: (1) the extent of training data\nredundancy and (2) the impact of cross domain transfer on model retention. In\nthis study, we conduct a systematic empirical analysis of these challenges\nusing Cellpose as a case study. First, to assess data redundancy, we propose a\nsimple dataset quantization (DQ) strategy for constructing compact yet diverse\ntraining subsets. Experiments on the Cyto dataset show that image segmentation\nperformance saturates with only 10% of the data, revealing substantial\nredundancy and potential for training with minimal annotations. Latent space\nanalysis using MAE embeddings and t-SNE confirms that DQ selected patches\ncapture greater feature diversity than random sampling. Second, to examine\ncatastrophic forgetting, we perform cross domain finetuning experiments and\nobserve significant degradation in source domain performance, particularly when\nadapting from generalist to specialist domains. We demonstrate that selective\nDQ based replay reintroducing just 5-10% of the source data effectively\nrestores source performance, while full replay can hinder target adaptation.\nAdditionally, we find that training domain sequencing improves generalization\nand reduces forgetting in multi stage transfer. Our findings highlight the\nimportance of data centric design in biomedical image segmentation and suggest\nthat efficient training requires not only compact subsets but also retention\naware learning strategies and informed domain ordering. The code is available\nat https://github.com/MMV-Lab/biomedseg-efficiency.", "AI": {"tldr": "本研究系统分析了通用生物医学图像分割模型（如Cellpose）在训练数据冗余和跨域迁移中的灾难性遗忘问题。通过提出的数据集量化（DQ）策略和重放机制，发现仅用10%的数据即可达到饱和性能，并能有效缓解灾难性遗忘，强调了数据中心设计和领域排序的重要性。", "motivation": "通用生物医学图像分割模型（如Cellpose）在广泛应用中面临两个未充分探索的关键挑战：训练数据的冗余程度，以及跨域迁移对模型保留性能的影响（即灾难性遗忘）。", "method": "1. 提出了数据集量化（DQ）策略来构建紧凑而多样化的训练子集，以评估数据冗余。2. 使用MAE嵌入和t-SNE进行潜在空间分析，以验证DQ选择的补丁能捕获更大的特征多样性。3. 进行跨域微调实验，以检验灾难性遗忘。4. 演示了基于DQ的选择性重放机制，以恢复源域性能。5. 探讨了训练域排序对泛化和遗忘的影响。", "result": "1. 图像分割性能在仅使用10%的Cyto数据集时即达到饱和，表明存在大量数据冗余，并有可能通过最少标注进行训练。2. DQ选择的补丁比随机采样捕获了更大的特征多样性。3. 跨域微调会导致源域性能显著下降（灾难性遗忘），尤其是在从通用领域适应到专业领域时。4. 重新引入仅5-10%源数据的选择性DQ重放能有效恢复源域性能，而完全重放可能阻碍目标域适应。5. 训练域排序能改善多阶段迁移中的泛化能力并减少遗忘。", "conclusion": "数据中心设计在生物医学图像分割中至关重要。高效训练不仅需要紧凑的数据子集，还需要兼顾保留性能的学习策略和明智的领域排序。"}}
{"id": "2511.04994", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04994", "abs": "https://arxiv.org/abs/2511.04994", "authors": ["Xingyuan Zhou", "Peter Paik", "S. Farokh Atashzar"], "title": "Encoding Biomechanical Energy Margin into Passivity-based Synchronization for Networked Telerobotic Systems", "comment": null, "summary": "Maintaining system stability and accurate position tracking is imperative in\nnetworked robotic systems, particularly for haptics-enabled human-robot\ninteraction. Recent literature has integrated human biomechanics into the\nstabilizers implemented for teleoperation, enhancing force preservation while\nguaranteeing convergence and safety. However, position desynchronization due to\nimperfect communication and non-passive behaviors remains a challenge. This\npaper proposes a two-port biomechanics-aware passivity-based synchronizer and\nstabilizer, referred to as TBPS2. This stabilizer optimizes position\nsynchronization by leveraging human biomechanics while reducing the\nstabilizer's conservatism in its activation. We provide the mathematical design\nsynthesis of the stabilizer and the proof of stability. We also conducted a\nseries of grid simulations and systematic experiments, comparing their\nperformance with that of state-of-the-art solutions under varying time delays\nand environmental conditions.", "AI": {"tldr": "本文提出了一种名为TBPS2的双端口生物力学感知基于无源性的同步器和稳定器，用于解决触觉使能网络机器人系统中因通信不完善和非无源行为导致的姿态失同步问题，同时优化姿态同步并降低稳定器的保守性。", "motivation": "在网络机器人系统，特别是触觉使能的人机交互中，维持系统稳定性和精确的姿态跟踪至关重要。尽管现有研究已将人体生物力学整合到遥操作稳定器中以增强力保持并保证收敛和安全，但由于通信不完善和非无源行为导致的姿态失同步仍然是一个挑战。", "method": "本文提出了一种名为TBPS2的双端口生物力学感知基于无源性的同步器和稳定器。该稳定器通过利用人体生物力学来优化姿态同步，并降低稳定器激活时的保守性。文章提供了稳定器的数学设计综合和稳定性证明，并通过一系列网格模拟和系统实验，在不同时间延迟和环境条件下与现有先进解决方案进行了性能比较。", "result": "TBPS2稳定器通过利用人体生物力学优化了姿态同步，并有效降低了稳定器激活时的保守性。通过网格模拟和系统实验，其性能在不同时间延迟和环境条件下与现有先进解决方案进行了比较。", "conclusion": "本文成功设计并验证了一种新颖的生物力学感知同步器和稳定器（TBPS2），能够有效解决网络机器人系统中触觉反馈导致的姿态失同步问题，同时保证系统稳定性和优化性能。"}}
{"id": "2511.05311", "categories": ["cs.AI", "cs.LG", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05311", "abs": "https://arxiv.org/abs/2511.05311", "authors": ["Valeriu Dimidov", "Faisal Hawlader", "Sasan Jafarnejad", "Raphaël Frank"], "title": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance", "comment": null, "summary": "Economic constraints, limited availability of datasets for reproducibility\nand shortages of specialized expertise have long been recognized as key\nchallenges to the adoption and advancement of predictive maintenance (PdM) in\nthe automotive sector. Recent progress in large language models (LLMs) presents\nan opportunity to overcome these barriers and speed up the transition of PdM\nfrom research to industrial practice. Under these conditions, we explore the\npotential of LLM-based agents to support PdM cleaning pipelines. Specifically,\nwe focus on maintenance logs, a critical data source for training\nwell-performing machine learning (ML) models, but one often affected by errors\nsuch as typos, missing fields, near-duplicate entries, and incorrect dates. We\nevaluate LLM agents on cleaning tasks involving six distinct types of noise.\nOur findings show that LLMs are effective at handling generic cleaning tasks\nand offer a promising foundation for future industrial applications. While\ndomain-specific errors remain challenging, these results highlight the\npotential for further improvements through specialized training and enhanced\nagentic capabilities.", "AI": {"tldr": "本文探讨了基于大型语言模型（LLM）的智能体在汽车预测性维护（PdM）数据清洗中的潜力，特别关注维护日志中的错误，并发现LLM在处理通用清洗任务方面表现有效。", "motivation": "汽车行业预测性维护的推广和发展面临经济限制、数据集稀缺和专业知识不足等挑战。维护日志作为关键数据源，常受错别字、字段缺失、重复条目和日期错误等问题困扰，阻碍了机器学习模型的训练。LLM的最新进展为克服这些障碍提供了机会。", "method": "研究探索了基于LLM的智能体在支持PdM清洗管道中的潜力，特别关注维护日志。通过在涉及六种不同类型噪声（如错别字、缺失字段、近似重复条目和错误日期）的清洗任务上评估LLM智能体。", "result": "研究结果表明，LLM在处理通用清洗任务方面表现有效，为未来的工业应用提供了有前景的基础。尽管处理领域特定的错误仍具挑战性，但这些结果突显了通过专业训练和增强智能体能力来进一步改进的潜力。", "conclusion": "LLM为未来的工业PdM应用提供了一个有前景的基础，尤其是在数据清洗方面。尽管领域特定错误仍是挑战，但通过专业训练和增强智能体能力，LLM的潜力可以进一步释放，从而加速PdM从研究到工业实践的转化。"}}
{"id": "2511.04703", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04703", "abs": "https://arxiv.org/abs/2511.04703", "authors": ["Andrew M. Bean", "Ryan Othniel Kearns", "Angelika Romanou", "Franziska Sofia Hafner", "Harry Mayne", "Jan Batzner", "Negar Foroutan", "Chris Schmitz", "Karolina Korgul", "Hunar Batra", "Oishi Deb", "Emma Beharry", "Cornelius Emde", "Thomas Foster", "Anna Gausen", "María Grandury", "Simeng Han", "Valentin Hofmann", "Lujain Ibrahim", "Hazel Kim", "Hannah Rose Kirk", "Fangru Lin", "Gabrielle Kaili-May Liu", "Lennart Luettgau", "Jabez Magomere", "Jonathan Rystrøm", "Anna Sotnikova", "Yushi Yang", "Yilun Zhao", "Adel Bibi", "Antoine Bosselut", "Ronald Clark", "Arman Cohan", "Jakob Foerster", "Yarin Gal", "Scott A. Hale", "Inioluwa Deborah Raji", "Christopher Summerfield", "Philip H. S. Torr", "Cozmin Ududec", "Luc Rocher", "Adam Mahdi"], "title": "Measuring what Matters: Construct Validity in Large Language Model Benchmarks", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Track on Datasets and Benchmarks", "summary": "Evaluating large language models (LLMs) is crucial for both assessing their\ncapabilities and identifying safety or robustness issues prior to deployment.\nReliably measuring abstract and complex phenomena such as 'safety' and\n'robustness' requires strong construct validity, that is, having measures that\nrepresent what matters to the phenomenon. With a team of 29 expert reviewers,\nwe conduct a systematic review of 445 LLM benchmarks from leading conferences\nin natural language processing and machine learning. Across the reviewed\narticles, we find patterns related to the measured phenomena, tasks, and\nscoring metrics which undermine the validity of the resulting claims. To\naddress these shortcomings, we provide eight key recommendations and detailed\nactionable guidance to researchers and practitioners in developing LLM\nbenchmarks.", "AI": {"tldr": "本文对445个大型语言模型（LLM）基准进行了系统性审查，发现其在衡量现象、任务和评分指标方面存在模式，这些模式损害了评估结果的有效性，并提出了八项改进建议。", "motivation": "评估LLM对于理解其能力、识别安全性和鲁棒性问题至关重要。然而，可靠地衡量“安全”和“鲁棒性”等抽象复杂现象需要强大的构念效度，即衡量指标必须真正代表现象的关键方面。", "method": "由29名专家审稿人组成的团队，对来自自然语言处理和机器学习顶级会议的445个LLM基准进行了系统性审查。", "result": "审查发现，在测量的现象、任务和评分指标方面存在某些模式，这些模式削弱了评估结果主张的有效性。", "conclusion": "为解决现有基准的不足，本文向研究人员和从业者提供了八项关键建议和详细可操作的指导，以开发更有效的LLM基准。"}}
{"id": "2511.05375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05375", "abs": "https://arxiv.org/abs/2511.05375", "authors": ["Sijie Yang", "Jiatong Li", "Filip Biljecki"], "title": "Reasoning Is All You Need for Urban Planning AI", "comment": "Submitted to AAAI 2026 Workshop AI4UP", "summary": "AI has proven highly successful at urban planning analysis -- learning\npatterns from data to predict future conditions. The next frontier is\nAI-assisted decision-making: agents that recommend sites, allocate resources,\nand evaluate trade-offs while reasoning transparently about constraints and\nstakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,\nReAct, and multi-agent collaboration frameworks -- now make this vision\nachievable.\n  This position paper presents the Agentic Urban Planning AI Framework for\nreasoning-capable planning agents that integrates three cognitive layers\n(Perception, Foundation, Reasoning) with six logic components (Analysis,\nGeneration, Verification, Evaluation, Collaboration, Decision) through a\nmulti-agents collaboration framework. We demonstrate why planning decisions\nrequire explicit reasoning capabilities that are value-based (applying\nnormative principles), rule-grounded (guaranteeing constraint satisfaction),\nand explainable (generating transparent justifications) -- requirements that\nstatistical learning alone cannot fulfill. We compare reasoning agents with\nstatistical learning, present a comprehensive architecture with benchmark\nevaluation metrics, and outline critical research challenges. This framework\nshows how AI agents can augment human planners by systematically exploring\nsolution spaces, verifying regulatory compliance, and deliberating over\ntrade-offs transparently -- not replacing human judgment but amplifying it with\ncomputational reasoning capabilities.", "AI": {"tldr": "这篇立场论文提出了一个“代理式城市规划AI框架”，旨在利用推理型AI代理将城市规划从数据预测推进到AI辅助决策，强调基于价值、规则和可解释性的透明推理能力，以增强而非取代人类规划师的判断。", "motivation": "当前的AI在城市规划分析中擅长从数据中学习模式并预测未来状况，但缺乏透明的推理能力来辅助决策，例如推荐地点、分配资源和评估权衡。作者认为，城市规划决策需要明确的、基于价值、遵守规则且可解释的推理能力，而仅凭统计学习无法满足这些要求。近期推理AI（如CoT、ReAct和多代理协作）的突破使得这一愿景成为可能。", "method": "论文提出了“代理式城市规划AI框架”，该框架通过多代理协作机制整合了三个认知层（感知、基础、推理）和六个逻辑组件（分析、生成、验证、评估、协作、决策）。它强调规划决策需要价值导向（应用规范原则）、规则基础（保证约束满足）和可解释性（生成透明理由）的明确推理能力。论文还比较了推理代理与统计学习，提出了一个全面的架构和基准评估指标，并概述了关键研究挑战。", "result": "论文展示了为什么规划决策需要明确的推理能力（基于价值、规则和可解释性），而统计学习无法单独满足这些要求。它描绘了AI代理如何通过系统地探索解决方案空间、验证法规遵从性以及透明地权衡利弊来增强人类规划师的能力，从而放大计算推理能力，而非取代人类判断。", "conclusion": "该框架表明，AI代理可以通过提供透明、基于推理的决策支持，显著增强人类城市规划，而非取代人类的判断。它为AI辅助城市规划提供了一条前进的道路，并为未来的研究指明了方向。"}}
{"id": "2511.04811", "categories": ["cs.CV", "cs.AI", "cs.LG", "68T07, 68U10", "I.2.10; I.4.6; J.3"], "pdf": "https://arxiv.org/pdf/2511.04811", "abs": "https://arxiv.org/abs/2511.04811", "authors": ["Shuo Zhao", "Yu Zhou", "Jianxu Chen"], "title": "An Active Learning Pipeline for Biomedical Image Instance Segmentation with Minimal Human Intervention", "comment": "6 pages, 4 figures, presented at Bildverarbeitung f\\\"ur die Medizin\n  (BVM) 2025, Wiesbaden, Germany", "summary": "Biomedical image segmentation is critical for precise structure delineation\nand downstream analysis. Traditional methods often struggle with noisy data,\nwhile deep learning models such as U-Net have set new benchmarks in\nsegmentation performance. nnU-Net further automates model configuration, making\nit adaptable across datasets without extensive tuning. However, it requires a\nsubstantial amount of annotated data for cross-validation, posing a challenge\nwhen only raw images but no labels are available. Large foundation models offer\nzero-shot generalizability, but may underperform on specific datasets with\nunique characteristics, limiting their direct use for analysis. This work\naddresses these bottlenecks by proposing a data-centric AI workflow that\nleverages active learning and pseudo-labeling to combine the strengths of\ntraditional neural networks and large foundation models while minimizing human\nintervention. The pipeline starts by generating pseudo-labels from a foundation\nmodel, which are then used for nnU-Net's self-configuration. Subsequently, a\nrepresentative core-set is selected for minimal manual annotation, enabling\neffective fine-tuning of the nnU-Net model. This approach significantly reduces\nthe need for manual annotations while maintaining competitive performance,\nproviding an accessible solution for biomedical researchers to apply\nstate-of-the-art AI techniques in their segmentation tasks. The code is\navailable at https://github.com/MMV-Lab/AL_BioMed_img_seg.", "AI": {"tldr": "本文提出了一种数据驱动的AI工作流程，结合基础模型、主动学习和伪标签技术，显著减少了生物医学图像分割所需的手动标注，同时保持了竞争力。", "motivation": "生物医学图像分割对下游分析至关重要，但面临挑战：传统方法易受噪声影响；U-Net等深度学习模型需要大量标注数据；nnU-Net自动化配置但仍需大量交叉验证数据；大型基础模型泛化性强但在特定数据集上表现不佳。这些限制阻碍了先进AI技术在生物医学研究中的应用。", "method": "本文提出了一种数据驱动的AI工作流程。首先，利用基础模型生成伪标签，这些伪标签用于nnU-Net的自配置。接着，通过主动学习选择一个代表性的核心数据集进行最少量的手动标注。最后，利用这些标注数据对nnU-Net模型进行有效微调。", "result": "该方法显著减少了对人工标注的需求，同时在生物医学图像分割任务中保持了具有竞争力的性能。", "conclusion": "该工作为生物医学研究人员提供了一个可行的解决方案，使他们能够以更少的人工干预，应用最先进的AI技术进行分割任务。"}}
{"id": "2511.04797", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04797", "abs": "https://arxiv.org/abs/2511.04797", "authors": ["Jim James", "Ben Wilson", "Simon Lucey", "James Hays"], "title": "3D Gaussian Point Encoders", "comment": "10 pages, 3 figures, 3 tables", "summary": "In this work, we introduce the 3D Gaussian Point Encoder, an explicit\nper-point embedding built on mixtures of learned 3D Gaussians. This explicit\ngeometric representation for 3D recognition tasks is a departure from widely\nused implicit representations such as PointNet. However, it is difficult to\nlearn 3D Gaussian encoders in end-to-end fashion with standard optimizers. We\ndevelop optimization techniques based on natural gradients and distillation\nfrom PointNets to find a Gaussian Basis that can reconstruct PointNet\nactivations. The resulting 3D Gaussian Point Encoders are faster and more\nparameter efficient than traditional PointNets. As in the 3D reconstruction\nliterature where there has been considerable interest in the move from implicit\n(e.g., NeRF) to explicit (e.g., Gaussian Splatting) representations, we can\ntake advantage of computational geometry heuristics to accelerate 3D Gaussian\nPoint Encoders further. We extend filtering techniques from 3D Gaussian\nSplatting to construct encoders that run 2.7 times faster as a comparable\naccuracy PointNet while using 46% less memory and 88% fewer FLOPs. Furthermore,\nwe demonstrate the effectiveness of 3D Gaussian Point Encoders as a component\nin Mamba3D, running 1.27 times faster and achieving a reduction in memory and\nFLOPs by 42% and 54% respectively. 3D Gaussian Point Encoders are lightweight\nenough to achieve high framerates on CPU-only devices.", "AI": {"tldr": "本文提出3D高斯点编码器，一种基于3D高斯混合的显式逐点嵌入，通过自然梯度和从PointNet蒸馏进行优化，并利用计算几何启发式方法加速。它比传统PointNet更快、更高效，甚至可以在仅CPU设备上实现高帧率。", "motivation": "研究动机在于探索3D识别任务中显式几何表示的潜力，这与PointNet等广泛使用的隐式表示不同。同时，解决3D高斯编码器难以使用标准优化器进行端到端学习的问题，并借鉴3D重建领域从隐式（如NeRF）向显式（如高斯溅射）表示发展的趋势，以实现更快速、更参数高效的模型。", "method": "本文引入了3D高斯点编码器，这是一种基于学习到的3D高斯混合的显式逐点嵌入。为了解决其端到端学习的困难，开发了基于自然梯度和从PointNet进行蒸馏的优化技术，以重建PointNet的激活。此外，还扩展了3D高斯溅射中的滤波技术，以进一步加速3D高斯点编码器。", "result": "结果表明，3D高斯点编码器比传统PointNet更快、更参数高效。通过应用滤波技术，编码器在实现相当精度的PointNet性能时，运行速度快2.7倍，内存使用减少46%，FLOPs减少88%。作为Mamba3D的组件，它运行速度快1.27倍，内存和FLOPs分别减少42%和54%。此外，3D高斯点编码器足够轻量，可在仅CPU设备上实现高帧率。", "conclusion": "3D高斯点编码器作为一种显式几何表示，为3D识别任务提供了一个高效且快速的解决方案。它在速度、内存和FLOPs方面显著优于PointNet，并且足够轻量，可以在仅CPU设备上实现高性能，证明了其作为未来3D识别任务组件的潜力。"}}
{"id": "2511.05033", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05033", "abs": "https://arxiv.org/abs/2511.05033", "authors": ["Jennifer K. Leestma", "Siddharth R. Nathella", "Christoph P. O. Nuesslein", "Snehil Mathur", "Gregory S. Sawicki", "Aaron J. Young"], "title": "Epically Powerful: An open-source software and mechatronics infrastructure for wearable robotic systems", "comment": "11 pages, 5 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "Epically Powerful is an open-source robotics infrastructure that streamlines\nthe underlying framework of wearable robotic systems - managing communication\nprotocols, clocking, actuator commands, visualization, sensor data acquisition,\ndata logging, and more - while also providing comprehensive guides for hardware\nselection, system assembly, and controller implementation. Epically Powerful\ncontains a code base enabling simplified user implementation via Python that\nseamlessly interfaces with various commercial state-of-the-art quasi-direct\ndrive (QDD) actuators, single-board computers, and common sensors, provides\nexample controllers, and enables real-time visualization. To further support\ndevice development, the package also includes a recommended parts list and\ncompatibility guide and detailed documentation on hardware and software\nimplementation. The goal of Epically Powerful is to lower the barrier to\ndeveloping and deploying custom wearable robotic systems without a\npre-specified form factor, enabling researchers to go from raw hardware to\nmodular, robust devices quickly and effectively. Though originally designed\nwith wearable robotics in mind, Epically Powerful is broadly applicable to\nother robotic domains that utilize QDD actuators, single-board computers, and\nsensors for closed-loop control.", "AI": {"tldr": "Epically Powerful是一个开源机器人基础设施，旨在简化可穿戴机器人系统的开发和部署，通过提供一个Python接口、硬件指南和实时可视化功能，降低研究门槛。", "motivation": "研究的动机是降低开发和部署定制化可穿戴机器人系统的门槛，使研究人员能够快速有效地将硬件转化为模块化、鲁棒的设备，而无需预设的尺寸限制。", "method": "该研究提供了一个开源机器人基础设施，通过Python简化用户实现，无缝对接商业准直接驱动（QDD）执行器、单板计算机和常见传感器。它还包含硬件选择、系统组装和控制器实现的综合指南，以及推荐零件清单、兼容性指南和详细的软硬件实现文档，并支持实时可视化。", "result": "Epically Powerful成功地简化了可穿戴机器人系统的底层框架，管理通信协议、时钟、执行器命令、可视化、传感器数据采集和数据记录。它提供了一个易于使用的代码库和示例控制器，并实现了与各种先进商业硬件的无缝接口，从而加快了从原始硬件到模块化设备的开发过程。", "conclusion": "Epically Powerful通过提供一个全面的开源基础设施，显著降低了开发和部署定制化可穿戴机器人系统的难度。尽管最初是为可穿戴机器人设计，但其通用性使其广泛适用于其他利用QDD执行器、单板计算机和传感器进行闭环控制的机器人领域。"}}
{"id": "2511.04705", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04705", "abs": "https://arxiv.org/abs/2511.04705", "authors": ["Tingyue Yang", "Junchi Yao", "Yuhui Guo", "Chang Liu"], "title": "POLIS-Bench: Towards Multi-Dimensional Evaluation of LLMs for Bilingual Policy Tasks in Governmental Scenarios", "comment": "16 pages, 6 figures", "summary": "We introduce POLIS-Bench, the first rigorous, systematic evaluation suite\ndesigned for LLMs operating in governmental bilingual policy scenarios.\nCompared to existing benchmarks, POLIS-Bench introduces three major\nadvancements. (i) Up-to-date Bilingual Corpus: We construct an extensive,\nup-to-date policy corpus that significantly scales the effective assessment\nsample size, ensuring relevance to current governance practice. (ii)\nScenario-Grounded Task Design: We distill three specialized, scenario-grounded\ntasks -- Clause Retrieval & Interpretation, Solution Generation, and the\nCompliance Judgmen--to comprehensively probe model understanding and\napplication. (iii) Dual-Metric Evaluation Framework: We establish a novel\ndual-metric evaluation framework combining semantic similarity with accuracy\nrate to precisely measure both content alignment and task requirement\nadherence. A large-scale evaluation of over 10 state-of-the-art LLMs on\nPOLIS-Bench reveals a clear performance hierarchy where reasoning models\nmaintain superior cross-task stability and accuracy, highlighting the\ndifficulty of compliance tasks. Furthermore, leveraging our benchmark, we\nsuccessfully fine-tune a lightweight open-source model. The resulting POLIS\nseries models achieves parity with, or surpasses, strong proprietary baselines\non multiple policy subtasks at a significantly reduced cost, providing a\ncost-effective and compliant path for robust real-world governmental\ndeployment.", "AI": {"tldr": "该论文介绍了POLIS-Bench，一个用于评估大型语言模型在政府双语政策场景下表现的基准套件，并提出了新的语料库、任务和评估框架。研究发现推理模型表现更优，并成功微调出成本效益高的模型。", "motivation": "现有基准缺乏对大型语言模型在政府双语政策场景下进行严格、系统评估的能力，需要一个更相关、全面且精准的评估工具。", "method": "引入POLIS-Bench评估套件，包含：1) 构建最新的双语政策语料库；2) 设计三项场景化任务：条款检索与解释、解决方案生成、合规性判断；3) 建立结合语义相似度和准确率的双重评估框架。在此基础上，对超过10个SOTA大型语言模型进行了大规模评估，并微调了一个轻量级开源模型（POLIS系列模型）。", "result": "评估结果显示大型语言模型存在清晰的性能层级，其中推理模型在跨任务稳定性和准确性方面表现更优，合规性任务难度最高。此外，微调后的POLIS系列模型在多个政策子任务上达到了或超越了强大的专有基线，且成本显著降低。", "conclusion": "POLIS-Bench为评估大型语言模型在政府双语政策领域的应用提供了严格的基准。通过微调，可以开发出具有成本效益且符合要求的模型，以支持真实的政府部署。"}}
{"id": "2511.05026", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05026", "abs": "https://arxiv.org/abs/2511.05026", "authors": ["Xingyuan Zhou", "Peter Paik", "S. Farokh Atashzar"], "title": "Tunable Passivity Control for Centralized Multiport Networked Systems", "comment": null, "summary": "Centralized Multiport Networked Dynamic (CMND) systems have emerged as a key\narchitecture with applications in several complex network systems, such as\nmultilateral telerobotics and multi-agent control. These systems consist of a\nhub node/subsystem connecting with multiple remote nodes/subsystems via a\nnetworked architecture. One challenge for this system is stability, which can\nbe affected by non-ideal network artifacts. Conventional passivity-based\napproaches can stabilize the system under specialized applications like\nsmall-scale networked systems. However, those conventional passive stabilizers\nhave several restrictions, such as distributing compensation across subsystems\nin a decentralized manner, limiting flexibility, and, at the same time, relying\non the restrictive assumptions of node passivity. This paper synthesizes a\ncentralized optimal passivity-based stabilization framework for CMND systems.\nIt consists of a centralized passivity observer monitoring overall energy flow\nand an optimal passivity controller that distributes the just-needed\ndissipation among various nodes, guaranteeing strict passivity and, thus, L2\nstability. The proposed data-driven model-free approach, i.e., Tunable\nCentralized Optimal Passivity Control (TCoPC), optimizes total performance\nbased on the prescribed dissipation distribution strategy while ensuring\nstability. The controller can put high dissipation loads on some sub-networks\nwhile relaxing the dissipation on other nodes. Simulation results demonstrate\nthe proposed frameworks performance in a complex task under different\ntime-varying delay scenarios while relaxing the remote nodes minimum phase and\npassivity assumption, enhancing the scalability and generalizability.", "AI": {"tldr": "本文提出了一种针对集中式多端口网络动态（CMND）系统的集中式最优无源性稳定框架，即可调集中式最优无源性控制（TCoPC），它是一种数据驱动、无模型的方案，能够有效保证系统稳定性并优化性能。", "motivation": "CMND系统在多边远程机器人和多智能体控制等领域有广泛应用，但其稳定性易受非理想网络因素影响。传统的基于无源性的方法存在局限性，如补偿去中心化、缺乏灵活性，并依赖于节点无源性的限制性假设，仅适用于小规模系统。", "method": "本文合成了一个集中式最优无源性稳定框架，包括一个监控整体能量流的集中式无源性观测器和一个分配所需耗散的优化无源性控制器。该方法是数据驱动、无模型的，称为可调集中式最优无源性控制（TCoPC），它根据预设的耗散分布策略优化整体性能，并可灵活地在不同子网络上分配耗散负载。", "result": "所提出的方法保证了系统的严格无源性和L2稳定性。仿真结果表明，该框架在不同时变延迟场景下表现出色，同时放宽了远程节点的最小相位和无源性假设，显著提高了系统的可扩展性和通用性。", "conclusion": "该研究成功开发了一种集中式最优无源性稳定框架（TCoPC），有效解决了CMND系统在复杂网络条件下的稳定性挑战。它通过灵活的耗散分配和放宽传统假设，增强了系统的灵活性、可扩展性和通用性。"}}
{"id": "2511.05327", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.05327", "abs": "https://arxiv.org/abs/2511.05327", "authors": ["Jieming Ke", "Jimin Wang", "Ji-Feng Zhang"], "title": "Privacy-Preserving Cramér-Rao Lower Bound", "comment": null, "summary": "This paper establishes the privacy-preserving Cram\\'er-Rao (CR) lower bound\ntheory, characterizing the fundamental limit of identification accuracy under\nprivacy constraint. An identifiability criterion under privacy constraint is\nderived by using Fisher information matrix as the privacy metric. In the\nidentifiable case, the privacy-preserving CR lower bound is established and its\nattainability is demonstrated, thereby ensuring the existence of the\nprivacy-preserving Fisher information matrix with explicit expression. Then,\nthe privacy-preserving CR lower bound theory is extended to the multi-sensor\nmulti-measurement system. Specifically, the additivity principle of\nprivacy-preserving Fisher information matrices across both spatial and temporal\ndimensions is established, building a relationship between privacy-preserving\nCR lower bounds for the multi-sensor multi-measurement system and its\nsubsystems. Using this additivity principle, distributed identification\nalgorithms capable of achieving the privacy-preserving CR lower bound are\nfurther proposed. Numerical examples are provided to demonstrate the\nprivacy-preserving CR lower bound and show the effectiveness of the proposed\nalgorithms.", "AI": {"tldr": "本文建立了隐私保护的Cramér-Rao (CR) 下界理论，表征了隐私约束下识别准确度的基本极限，并将其扩展到多传感器多测量系统，同时提出了可实现该下界的分布式识别算法。", "motivation": "研究旨在表征在隐私约束下识别准确度的根本极限，即如何在保证隐私的前提下，量化识别的最高精度。", "method": "本文使用Fisher信息矩阵作为隐私度量，推导了隐私约束下的可识别性准则。在此基础上，建立了隐私保护的CR下界并证明了其可达性。随后，将该理论扩展到多传感器多测量系统，确立了隐私保护的Fisher信息矩阵在空间和时间维度上的可加性原则。最后，基于此原则提出了能够达到隐私保护CR下界的分布式识别算法。", "result": "研究结果包括：建立了隐私保护的CR下界理论；推导了隐私约束下的可识别性准则；明确了隐私保护的Fisher信息矩阵的存在性及其显式表达式；将隐私保护CR下界理论扩展到多传感器多测量系统，并确立了隐私保护的Fisher信息矩阵在空间和时间维度上的可加性原则；提出了能够实现隐私保护CR下界的分布式识别算法。数值示例验证了该下界和所提算法的有效性。", "conclusion": "本文成功建立了隐私约束下识别准确度的理论极限，并提供了可达的分布式识别算法。这为在隐私保护背景下的系统识别提供了坚实的理论基础和实用方法。"}}
{"id": "2511.04848", "categories": ["cs.CV", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.04848", "abs": "https://arxiv.org/abs/2511.04848", "authors": ["Manuel Weiß", "Lukas Baumgärtner", "Roland Herzog", "Stephan Schmidt"], "title": "Geometry Denoising with Preferred Normal Vectors", "comment": null, "summary": "We introduce a new paradigm for geometry denoising using prior knowledge\nabout the surface normal vector. This prior knowledge comes in the form of a\nset of preferred normal vectors, which we refer to as label vectors. A\nsegmentation problem is naturally embedded in the denoising process. The\nsegmentation is based on the similarity of the normal vector to the elements of\nthe set of label vectors. Regularization is achieved by a total variation term.\nWe formulate a split Bregman (ADMM) approach to solve the resulting\noptimization problem. The vertex update step is based on second-order shape\ncalculus.", "AI": {"tldr": "本文提出了一种利用表面法向量先验知识（标签向量）进行几何去噪的新范式，通过嵌入分割问题和全变分正则化，并使用ADMM方法求解。", "motivation": "引入一种新的几何去噪范式，利用关于表面法向量的先验知识来改进去噪过程。", "method": "引入一组优选法向量（标签向量）作为先验知识；将分割问题嵌入去噪过程，分割基于法向量与标签向量的相似性；通过全变分项实现正则化；使用分裂Bregman (ADMM) 方法解决优化问题；顶点更新步骤基于二阶形状微积分。", "result": "成功地提出了一种结合几何去噪和表面分割的新方法，并给出了一个可行的优化求解框架。", "conclusion": "该研究引入了一种基于法向量先验知识和嵌入式分割的新颖几何去噪范式，通过全变分正则化和ADMM方法有效解决，为几何去噪提供了新的思路。"}}
{"id": "2511.04710", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04710", "abs": "https://arxiv.org/abs/2511.04710", "authors": ["Hari Mohan Pandey", "Anshul Gupta", "Subham Sarkar", "Minakshi Tomer", "Schneider Johannes", "Yan Gong"], "title": "GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models", "comment": null, "summary": "Text-to-SQL systems enable users to interact with structured databases using\nnatural language, eliminating the need for specialized programming knowledge.\nIn this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL\nmodel built upon the open-source Gemma 2B architecture. Unlike many large\nlanguage models (LLMs), GEMMA-SQL is fine-tuned in a resource-efficient,\niterative manner and can be deployed on low-cost hardware. Leveraging the\nSPIDER benchmark for training and evaluation, GEMMA-SQL combines multiple\nprompting strategies, including few-shot learning, to enhance SQL query\ngeneration accuracy. The instruction-tuned variant, GEMMA-SQL Instruct,\nachieves 66.8% Test-Suite accuracy and 63.3% Exact Set Match accuracy,\noutperforming several state-of-the-art baselines such as IRNet, RYANSQL, and\nCodeXDavinci. The proposed approach demonstrates that effective prompt design\nand targeted instruction tuning can significantly boost performance while\nmaintaining high scalability and adaptability. These results position GEMMA-SQL\nas a practical, open-source alternative for robust and accessible text-to-SQL\nsystems.", "AI": {"tldr": "GEMMA-SQL是一个基于Gemma 2B架构的轻量级、高效文本到SQL模型，通过资源高效的迭代微调和多重提示策略（包括少样本学习），在SPIDER基准测试中实现了高准确率，超越了多个现有基线，并提供了一个实用、开源的解决方案。", "motivation": "使非专业用户能够通过自然语言与结构化数据库交互，无需编程知识。同时，旨在开发一个资源高效、可在低成本硬件上部署的文本到SQL系统，以克服许多大型语言模型（LLM）的资源限制。", "method": "该模型基于开源的Gemma 2B架构构建，采用资源高效的迭代微调方法。利用SPIDER基准进行训练和评估，并结合了多种提示策略，包括少样本学习，以提高SQL查询生成准确性。还开发了一个指令微调版本GEMMA-SQL Instruct。", "result": "GEMMA-SQL Instruct在Test-Suite准确率上达到66.8%，在Exact Set Match准确率上达到63.3%。它超越了IRNet、RYANSQL和CodeXDavinci等多个最先进的基线模型。研究表明，有效的提示设计和有针对性的指令微调可以显著提升性能，同时保持高可扩展性和适应性。", "conclusion": "GEMMA-SQL是一个实用、开源的替代方案，为构建强大且易于访问的文本到SQL系统提供了可能性。其成果证明了有效的提示设计和指令微调能够在保持资源效率的同时显著提升性能。"}}
{"id": "2511.05347", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.05347", "abs": "https://arxiv.org/abs/2511.05347", "authors": ["Shiming Li", "Luca Mottola", "Yuan Yao", "Stefanos Kaxiras"], "title": "Efficient CNN Inference on Ultra-Low-Power MCUs via Saturation-Aware Convolution", "comment": null, "summary": "Deploying lightweight CNN inference tasks on ultra-low-power MCUs is often\nnot limited by space constraint, thanks to the compact size of models, yet\ninference latency is crucial for preserving energy. We reveal that quantized\nCNN inference on ultra-low-power MCUs executes unnecessary computations in\nneurons that produce saturated output values: often times, these neurons still\nproduce the correct output value without fully completing the computation,\nsince the neuron value is too extreme and is eventually systematically clamped\nat the boundaries allowed by the neuron. We show that with carefully designed\ncondition checks, it is possible to identify and skip these unnecessary\ncomputations without impacting the neuron output. Based on this, we present\nsaturation-aware convolution: an inference technique whereby computations in\nconvolution kernels are executed in an altered order to induce earlier\nsaturation, and saturation checks are inserted to omit unnecessary\ncomputations. We integrate our implementation into MCUNet's TinyEngine, the\nstate-of-the-art neural network code generation and inference framework, and\nconduct experiments on a Cortex-M0+ MCU. The result based on 7 open-source CNN\nmodels displays up to 24% inference time saving, with strictly zero impact on\nneural network accuracy.", "AI": {"tldr": "本文提出了一种名为“饱和感知卷积”的推理技术，通过跳过量化CNN中饱和神经元的冗余计算，在不影响准确性的前提下，显著降低超低功耗MCU上的推理延迟和能耗。", "motivation": "在超低功耗微控制器（MCU）上部署轻量级CNN推理任务时，模型大小通常不是限制因素，但推理延迟对于节约能耗至关重要。研究发现，量化CNN推理在某些神经元产生饱和输出值时，仍会执行不必要的完整计算，这导致了能量浪费。", "method": "研究通过精心设计的条件检查，识别并跳过那些产生饱和输出值但不影响最终结果的神经元中的不必要计算。在此基础上，提出了“饱和感知卷积”技术：通过改变卷积核中的计算顺序以提前诱导饱和，并插入饱和检查来省略不必要的计算。该方法被集成到MCUNet的TinyEngine框架中，并在Cortex-M0+ MCU上进行了实验。", "result": "基于7个开源CNN模型在Cortex-M0+ MCU上的实验结果显示，推理时间最多可节省24%，同时对神经网络的准确性没有任何影响。", "conclusion": "通过利用量化CNN中神经元输出的饱和特性，所提出的饱和感知卷积技术能有效减少超低功耗MCU上的推理时间，从而提高能效，且不牺牲模型精度。"}}
{"id": "2511.04715", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04715", "abs": "https://arxiv.org/abs/2511.04715", "authors": ["Dmytro Vitel", "Anshuman Chhabra"], "title": "First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation", "comment": null, "summary": "Identifying how training samples influence/impact Large Language Model (LLM)\ndecision-making is essential for effectively interpreting model decisions and\nauditing large-scale datasets. Current training sample influence estimation\nmethods (also known as influence functions) undertake this goal by utilizing\ninformation flow through the model via its first-order and higher-order\ngradient terms. However, owing to the large model sizes of today consisting of\nbillions of parameters, these influence computations are often restricted to\nsome subset of model layers to ensure computational feasibility. Prior seminal\nwork by Yeh et al. (2022) in assessing which layers are best suited for\ncomputing language data influence concluded that the first (embedding) layers\nare the most informative for this purpose, using a hypothesis based on\ninfluence scores canceling out (i.e., the cancellation effect). In this work,\nwe propose theoretical and empirical evidence demonstrating how the\ncancellation effect is unreliable, and that middle attention layers are better\nestimators for influence. Furthermore, we address the broader challenge of\naggregating influence scores across layers, and showcase how alternatives to\nstandard averaging (such as ranking and vote-based methods) can lead to\nsignificantly improved performance. Finally, we propose better methods for\nevaluating influence score efficacy in LLMs without undertaking model\nretraining, and propose a new metric known as the Noise Detection Rate (NDR)\nthat exhibits strong predictive capability compared to the cancellation effect.\nThrough extensive experiments across LLMs of varying types and scales, we\nconcretely determine that the first (layers) are not necessarily better than\nthe last (layers) for LLM influence estimation, contrasting with prior\nknowledge in the field.", "AI": {"tldr": "本研究挑战了现有关于大型语言模型（LLM）训练样本影响估计中最佳层的观点，指出取消效应不可靠，并提出中间注意力层和新聚合/评估方法能更准确地估计影响。", "motivation": "理解训练样本如何影响LLM决策对于模型解释和大规模数据集审计至关重要。现有影响函数计算成本高昂，导致仅限于模型部分层。先前研究认为第一层（嵌入层）最具信息量，但该结论基于可能不可靠的“取消效应”假设。", "method": "我们提出了理论和实证证据来证明“取消效应”的不可靠性。研究表明中间注意力层是更好的影响估计器。此外，我们探讨了跨层影响分数聚合的挑战，并提出了优于标准平均的方法（如排序和基于投票的方法）。最后，我们提出了一种无需模型再训练来评估影响分数有效性的新方法，并引入了“噪声检测率”（NDR）指标，该指标比取消效应具有更强的预测能力。", "result": "研究发现“取消效应”是不可靠的，且中间注意力层是更好的影响估计器。替代的聚合方法（如排序和基于投票的方法）显著提升了性能。新提出的NDR指标展现出强大的预测能力。通过广泛实验，我们具体确定对于LLM影响估计而言，第一层并不一定优于最后一层，这与该领域的先前认知相悖。", "conclusion": "本研究挑战了关于LLM影响估计中信息层位置的传统观点，证明了取消效应的不可靠性，并提出中间注意力层结合改进的聚合和评估方法（如NDR）可以更准确地识别训练样本的影响，从而为LLM决策的解释和审计提供了更可靠的框架。"}}
{"id": "2511.05052", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05052", "abs": "https://arxiv.org/abs/2511.05052", "authors": ["Zihao Li", "Yiming Zhu", "Zhe Zhong", "Qinyuan Ren", "Yijiang Huang"], "title": "TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments", "comment": null, "summary": "Robotic manipulation in complex, constrained spaces is vital for widespread\napplications but challenging, particularly when navigating narrow passages with\nelongated objects. Existing planning methods often fail in these low-clearance\nscenarios due to the sampling difficulties or the local minima. This work\nproposes Topology-Aware Planning for Object Manipulation (TAPOM), which\nexplicitly incorporates task-space topological analysis to enable efficient\nplanning. TAPOM uses a high-level analysis to identify critical pathways and\ngenerate guiding keyframes, which are utilized in a low-level planner to find\nfeasible configuration space trajectories. Experimental validation demonstrates\nsignificantly high success rates and improved efficiency over state-of-the-art\nmethods on low-clearance manipulation tasks. This approach offers broad\nimplications for enhancing manipulation capabilities of robots in complex\nreal-world environments.", "AI": {"tldr": "针对复杂、受限空间内机器人抓取操作（特别是细长物体通过狭窄通道），本文提出拓扑感知物体操作规划（TAPOM）方法。该方法通过高层拓扑分析识别关键路径并生成关键帧，指导低层规划器寻找可行轨迹，显著提高了低间隙操作任务的成功率和效率。", "motivation": "在复杂、受限空间中（例如狭窄通道中操作细长物体），现有规划方法因采样困难或局部最小值而失效，限制了机器人抓取操作的广泛应用。这是一个具有挑战性但至关重要的领域。", "method": "本文提出拓扑感知物体操作规划（TAPOM）。它明确结合了任务空间拓扑分析，通过高层分析识别关键路径并生成引导关键帧，然后利用这些关键帧在低层规划器中寻找可行的构型空间轨迹。", "result": "实验验证表明，与现有先进方法相比，TAPOM在低间隙操作任务中取得了显著更高的成功率和更高的效率。", "conclusion": "该方法对于增强机器人在复杂现实环境中的操作能力具有广泛的意义。"}}
{"id": "2511.04720", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04720", "abs": "https://arxiv.org/abs/2511.04720", "authors": ["Ha Young Kim", "Jun Li", "Ana Beatriz Solana", "Carolin M. Pirkl", "Benedikt Wiestler", "Julia A. Schnabel", "Cosmin I. Bercea"], "title": "Learning to reason about rare diseases through retrieval-augmented agents", "comment": "Submitted on behalf of the PREDICTOM consortium", "summary": "Rare diseases represent the long tail of medical imaging, where AI models\noften fail due to the scarcity of representative training data. In clinical\nworkflows, radiologists frequently consult case reports and literature when\nconfronted with unfamiliar findings. Following this line of reasoning, we\nintroduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic\nsystem for rare disease detection in brain MRI. Our approach uses AI agents\nwith access to external medical knowledge by embedding both case reports and\nliterature using sentence transformers and indexing them with FAISS to enable\nefficient similarity search. The agent retrieves clinically relevant evidence\nto guide diagnostic decision making on unseen diseases, without the need of\nadditional training. Designed as a model-agnostic reasoning module, RADAR can\nbe seamlessly integrated with diverse large language models, consistently\nimproving their rare pathology recognition and interpretability. On the NOVA\ndataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2%\nperformance gain, with the strongest improvements observed for open source\nmodels such as DeepSeek. Beyond accuracy, the retrieved examples provide\ninterpretable, literature grounded explanations, highlighting\nretrieval-augmented reasoning as a powerful paradigm for low-prevalence\nconditions in medical imaging.", "AI": {"tldr": "RADAR是一个检索增强诊断推理代理系统，通过访问外部医学知识（病例报告和文献）来检测脑部MRI中的罕见疾病，无需额外训练即可提高诊断准确性和可解释性。", "motivation": "由于缺乏代表性训练数据，AI模型在医学影像中的罕见疾病检测方面表现不佳。临床放射科医生在面对不熟悉发现时，经常查阅病例报告和文献。", "method": "RADAR利用AI代理，通过句子转换器嵌入病例报告和文献，并使用FAISS进行索引以实现高效相似性搜索。代理检索临床相关证据来指导对未见疾病的诊断决策。它是一个模型无关的推理模块，可与各种大型语言模型无缝集成。", "result": "在包含280种不同罕见疾病的NOVA数据集上，RADAR实现了高达10.2%的性能提升，尤其是在DeepSeek等开源模型上表现最佳。检索到的示例提供了可解释的、基于文献的解释。", "conclusion": "检索增强推理是医学影像中低患病率疾病的强大范式，能够提高准确性和可解释性。"}}
{"id": "2511.04864", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04864", "abs": "https://arxiv.org/abs/2511.04864", "authors": ["Kyle Fogarty", "Chenyue Cai", "Jing Yang", "Zhilin Guo", "Cengiz Öztireli"], "title": "Self-Supervised Implicit Attention Priors for Point Cloud Reconstruction", "comment": "Accepted at 3DV 2026", "summary": "Recovering high-quality surfaces from irregular point cloud is ill-posed\nunless strong geometric priors are available. We introduce an implicit\nself-prior approach that distills a shape-specific prior directly from the\ninput point cloud itself and embeds it within an implicit neural\nrepresentation. This is achieved by jointly training a small dictionary of\nlearnable embeddings with an implicit distance field; at every query location,\nthe field attends to the dictionary via cross-attention, enabling the network\nto capture and reuse repeating structures and long-range correlations inherent\nto the shape. Optimized solely with self-supervised point cloud reconstruction\nlosses, our approach requires no external training data. To effectively\nintegrate this learned prior while preserving input fidelity, the trained field\nis then sampled to extract densely distributed points and analytic normals via\nautomatic differentiation. We integrate the resulting dense point cloud and\ncorresponding normals into a robust implicit moving least squares (RIMLS)\nformulation. We show this hybrid strategy preserves fine geometric details in\nthe input data, while leveraging the learned prior to regularize sparse\nregions. Experiments show that our method outperforms both classical and\nlearning-based approaches in generating high-fidelity surfaces with superior\ndetail preservation and robustness to common data degradations.", "AI": {"tldr": "本文提出一种从不规则点云恢复高质量表面的方法，通过从点云本身学习隐式自先验并结合鲁棒隐式移动最小二乘法（RIMLS），在无需外部训练数据的情况下，实现细节保留和鲁棒性。", "motivation": "从不规则点云中恢复高质量表面是一个病态问题，除非有强大的几何先验。现有方法在细节保留和数据退化鲁棒性方面存在挑战。", "method": "引入一种隐式自先验方法，将形状特有的先验直接从输入点云中提取并嵌入到隐式神经表示中。通过联合训练一个可学习嵌入的小词典和一个隐式距离场实现，距离场通过交叉注意力关注词典，捕捉形状固有的重复结构和长程相关性。该方法仅使用自监督点云重建损失进行优化，无需外部训练数据。然后，对训练好的距离场进行采样以提取密集分布的点和解析法线，并将这些结果整合到鲁棒隐式移动最小二乘（RIMLS）公式中。", "result": "混合策略在保留输入数据精细几何细节的同时，利用学习到的先验来正则化稀疏区域。实验表明，该方法在生成高保真表面、优越的细节保留以及对常见数据退化的鲁棒性方面，均优于经典和基于学习的方法。", "conclusion": "所提出的隐式自先验方法结合RIMLS，有效地解决了从不规则点云进行表面重建的病态问题。它无需外部训练数据，即可生成高保真表面，同时保持精细细节并对数据退化具有鲁棒性。"}}
{"id": "2511.05445", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.05445", "abs": "https://arxiv.org/abs/2511.05445", "authors": ["Yanchao Wang", "Xu You", "Mehdi Baghdadi"], "title": "A Tilting-Rotor Enhanced Quadcopter Fault-Tolerant Control Based on Non-Linear Model Predictive Control", "comment": null, "summary": "This paper proposes a fault-tolerant control strategy based on a tilt-rotor\nquadcopter prototype, utilizing nonlinear model predictive control to maintain\nboth attitude and position stability in the event of rotor failure. The control\nstrategy employs an extended state observer to predict model deviations\nfollowing a fault and adjusts the original model in the subsequent time step,\nthereby achieving active fault-tolerant control. The proposed method is\nevaluated through simulations and compared to both traditional quadcopter and\ntilt-rotor quadcopter without observer under identical conditions. The results\ndemonstrate that the tilt-rotor quadcopter can maintain position control\nwithout sacrificing yaw stability, unlike traditional quadcopters.", "AI": {"tldr": "本文提出一种基于倾转旋翼四旋翼无人机的容错控制策略，利用非线性模型预测控制和扩展状态观测器，在旋翼故障后保持姿态和位置稳定性。", "motivation": "在旋翼故障发生时，需要为倾转旋翼四旋翼无人机提供一种有效的容错控制策略，以维持其姿态和位置的稳定性。", "method": "该策略采用非线性模型预测控制（NMPC）来维持姿态和位置稳定性。同时，使用扩展状态观测器（ESO）预测故障后的模型偏差，并在后续时间步调整原始模型，从而实现主动容错控制。", "result": "通过仿真评估，结果表明，与传统四旋翼无人机和不带观测器的倾转旋翼无人机相比，所提出的倾转旋翼无人机策略能够在不牺牲偏航稳定性的情况下保持位置控制，而传统四旋翼无人机则无法做到。", "conclusion": "所提出的基于非线性模型预测控制和扩展状态观测器的容错控制策略，能有效使倾转旋翼四旋翼无人机在旋翼故障后保持姿态和位置稳定性，并优于传统四旋翼无人机。"}}
{"id": "2511.04754", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04754", "abs": "https://arxiv.org/abs/2511.04754", "authors": ["Nikolai Ilinykh", "Simon Dobnik"], "title": "Surprisal reveals diversity gaps in image captioning and different scorers change the story", "comment": "Accepted and presented at INLG 2025", "summary": "We quantify linguistic diversity in image captioning with surprisal variance\n- the spread of token-level negative log-probabilities within a caption set. On\nthe MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs,\ndecoded with greedy and nucleus sampling, to human captions. Measured with a\ncaption-trained n-gram LM, humans display roughly twice the surprisal variance\nof models, but rescoring the same captions with a general-language model\nreverses the pattern. Our analysis introduces the surprisal-based diversity\nmetric for image captioning. We show that relying on a single scorer can\ncompletely invert conclusions, thus, robust diversity evaluation must report\nsurprisal under several scorers.", "AI": {"tldr": "本文提出使用“惊奇方差”（surprisal variance）量化图像字幕中的语言多样性。研究发现，在MSCOCO数据集上，人类字幕的惊奇方差在特定评分器下是模型的两倍，但在通用语言模型下模式反转。结论是，鲁棒的多样性评估需要使用多个评分器。", "motivation": "量化图像字幕中的语言多样性是一个重要问题，尤其是在比较最先进的视觉-语言大模型与人类字幕时。现有的评估方法可能不够全面或鲁棒，需要一种新的、基于惊奇的度量标准。", "method": "本文引入“惊奇方差”（surprisal variance）作为量化语言多样性的指标，即字幕集中词元级负对数概率的分布。研究在MSCOCO测试集上，比较了五种最先进的视觉-语言大模型（使用贪婪解码和核采样）与人类字幕。惊奇值通过两种语言模型计算：一个经过字幕训练的n-gram语言模型和一个通用语言模型。", "result": "使用经过字幕训练的n-gram语言模型时，人类字幕的惊奇方差大约是模型的两倍。然而，当使用通用语言模型重新评估相同的字幕时，这种模式完全反转。这表明单一评分器的选择可以完全颠覆结论。", "conclusion": "本文引入了基于惊奇的图像字幕多样性度量标准。研究强调，进行鲁棒的多样性评估必须在多个评分器下报告惊奇值，以避免因评分器选择而导致结论完全相反的情况。"}}
{"id": "2511.05391", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2511.05391", "abs": "https://arxiv.org/abs/2511.05391", "authors": ["Rodrigo Bernal", "Ignacio Ponce", "Federico Milano"], "title": "Coherency Control in Power Systems", "comment": null, "summary": "This paper proposes a coherency control strategy for Inverter-Based Resources\n(IBRs) to establish coherence among power system devices. Using the equivalence\nof the Complex Frequency (CF) of the injected currents as the definition for\ncoherency among devices, the control enforces an output current with a\nproportional magnitude and a constant phase shift relative to a reference. This\nformulation makes the control technology-agnostic, enabling coherency with any\ntype of resource. Case studies based on the two-area and IEEE 39-bus systems\ndemonstrate the controller's potential to improve damping and overall dynamic\nbehavior. The paper further evaluates practical implementation aspects\nincluding delay/noise sensitivity and the trade-off between oscillation\nmitigation and disturbance propagation. This work establishes coherency as a\nviable direct control objective for IBRs in modern power systems.", "AI": {"tldr": "本文提出了一种针对逆变器并网资源（IBRs）的相干性控制策略，通过定义注入电流的复频率等效性来实现设备间的相干性，旨在改善电力系统阻尼和整体动态行为。", "motivation": "在现代电力系统中，需要一种有效的控制策略来在各种电力系统设备，特别是IBRs之间建立相干性，以改善系统的动态性能。", "method": "该研究提出了一种IBRs相干性控制策略，将注入电流的复频率等效性作为设备间相干性的定义。该控制通过强制输出电流与参考值保持比例幅值和恒定相移来实现。这种方法具有技术无关性，能与任何类型的资源实现相干性。通过在双区域系统和IEEE 39节点系统上进行案例研究，并评估了延迟/噪声敏感性以及振荡缓解与扰动传播之间的权衡。", "result": "案例研究表明，所提出的控制器能够有效改善电力系统的阻尼和整体动态行为。该控制策略被证明是技术无关的，能够与任何类型的资源实现相干性。", "conclusion": "这项工作确立了相干性作为现代电力系统中IBRs一个可行的直接控制目标。"}}
{"id": "2511.05307", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05307", "abs": "https://arxiv.org/abs/2511.05307", "authors": ["Akua K. Dickson", "Juan C. Pacheco Garcia", "Andrew P. Sabelhaus"], "title": "Force-Safe Environment Maps and Real-Time Detection for Soft Robot Manipulators", "comment": null, "summary": "Soft robot manipulators have the potential for deployment in delicate\nenvironments to perform complex manipulation tasks. However, existing obstacle\ndetection and avoidance methods do not consider limits on the forces that\nmanipulators may exert upon contact with delicate obstacles. This work\nintroduces a framework that maps force safety criteria from task space (i.e.\npositions along the robot's body) to configuration space (i.e. the robot's\njoint angles) and enables real-time force safety detection. We incorporate\nlimits on allowable environmental contact forces for given task-space\nobstacles, and map them into configuration space (C-space) through the\nmanipulator's forward kinematics. This formulation ensures that configurations\nclassified as safe are provably below the maximum force thresholds, thereby\nallowing us to determine force-safe configurations of the soft robot\nmanipulator in real-time. We validate our approach in simulation and hardware\nexperiments on a two-segment pneumatic soft robot manipulator. Results\ndemonstrate that the proposed method accurately detects force safety during\ninteractions with deformable obstacles, thereby laying the foundation for\nreal-time safe planning of soft manipulators in delicate, cluttered\nenvironments.", "AI": {"tldr": "本文提出了一种将力安全标准从任务空间映射到构型空间的框架，以实现软机器人操纵器在与脆弱障碍物接触时进行实时力安全检测和规划。", "motivation": "现有障碍物检测和避障方法未考虑操纵器与脆弱障碍物接触时可能施加的力限制，这限制了软机器人在精细环境中的部署。", "method": "研究人员引入了一个框架，将任务空间（机器人身体上的位置）的力安全标准映射到构型空间（机器人的关节角度）。通过操纵器的正向运动学，将允许的环境接触力限制映射到构型空间，从而确保被分类为安全的构型力值低于最大阈值。该方法在双段气动软机器人操纵器上进行了仿真和硬件实验验证。", "result": "结果表明，所提出的方法在与可变形障碍物交互时能准确检测力安全，证明了其在实际应用中的有效性。", "conclusion": "该方法为软机器人在精细、杂乱环境中进行实时安全规划奠定了基础，使其能够更安全地执行复杂操作任务。"}}
{"id": "2511.05129", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05129", "abs": "https://arxiv.org/abs/2511.05129", "authors": ["Bin Fan", "Jianjian Jiang", "Zhuohao Li", "Yixiang He", "Xiaoming Wu", "Yihan Yang", "Shengbang Liu", "Weishi Zheng"], "title": "Decomposed Object Manipulation via Dual-Actor Policy", "comment": "9 pages, 7 figures, 5 tables", "summary": "Object manipulation, which focuses on learning to perform tasks on similar\nparts across different types of objects, can be divided into an approaching\nstage and a manipulation stage. However, previous works often ignore this\ncharacteristic of the task and rely on a single policy to directly learn the\nwhole process of object manipulation. To address this problem, we propose a\nnovel Dual-Actor Policy, termed DAP, which explicitly considers different\nstages and leverages heterogeneous visual priors to enhance each stage.\nSpecifically, we introduce an affordance-based actor to locate the functional\npart in the manipulation task, thereby improving the approaching process.\nFollowing this, we propose a motion flow-based actor to capture the movement of\nthe component, facilitating the manipulation process. Finally, we introduce a\ndecision maker to determine the current stage of DAP and select the\ncorresponding actor. Moreover, existing object manipulation datasets contain\nfew objects and lack the visual priors needed to support training. To address\nthis, we construct a simulated dataset, the Dual-Prior Object Manipulation\nDataset, which combines the two visual priors and includes seven tasks,\nincluding two challenging long-term, multi-stage tasks. Experimental results on\nour dataset, the RoboTwin benchmark and real-world scenarios illustrate that\nour method consistently outperforms the SOTA method by 5.55%, 14.7% and 10.4%\non average respectively.", "AI": {"tldr": "本文提出了一种名为DAP的双演员策略，通过将物体操作任务分解为接近和操作两个阶段，并为每个阶段利用不同的视觉先验，显著提升了操作性能。同时构建了一个新的数据集以支持训练。", "motivation": "以往的物体操作研究常忽略任务的阶段性特征，仅使用单一策略学习整个操作过程。此外，现有数据集物体种类少，且缺乏支持训练所需的视觉先验。", "method": "1. 提出双演员策略(DAP)，明确区分接近和操作阶段。2. 引入基于功能性（affordance-based）的演员来定位功能部件，改进接近过程。3. 提出基于运动流（motion flow-based）的演员来捕捉部件运动，促进操作过程。4. 设计决策者判断当前阶段并选择相应演员。5. 构建了一个模拟的“双先验物体操作数据集”，包含两种视觉先验和七个任务（包括两个挑战性的长期多阶段任务）。", "result": "在自建数据集、RoboTwin基准和真实世界场景中，本文方法平均性能分别超越SOTA方法5.55%、14.7%和10.4%。", "conclusion": "DAP通过显式考虑物体操作任务的阶段性特征并利用异构视觉先验，有效解决了单一策略的局限性，并在多个基准和真实场景中展现出卓越的性能。新构建的数据集也为相关研究提供了有力支持。"}}
{"id": "2511.04871", "categories": ["cs.CV", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.04871", "abs": "https://arxiv.org/abs/2511.04871", "authors": ["Gabriel Girard", "Manon Edde", "Félix Dumais", "Yoan David", "Matthieu Dumont", "Guillaume Theaud", "Jean-Christophe Houde", "Arnaud Boré", "Maxime Descoteaux", "Pierre-Marc Jodoin"], "title": "Clinical-ComBAT: a diffusion-weighted MRI harmonization method for clinical applications", "comment": "39 pages, 11 figures", "summary": "Diffusion-weighted magnetic resonance imaging (DW-MRI) derived scalar maps\nare effective for assessing neurodegenerative diseases and microstructural\nproperties of white matter in large number of brain conditions. However, DW-MRI\ninherently limits the combination of data from multiple acquisition sites\nwithout harmonization to mitigate scanner-specific biases. While the widely\nused ComBAT method reduces site effects in research, its reliance on linear\ncovariate relationships, homogeneous populations, fixed site numbers, and well\npopulated sites constrains its clinical use. To overcome these limitations, we\npropose Clinical-ComBAT, a method designed for real-world clinical scenarios.\nClinical-ComBAT harmonizes each site independently, enabling flexibility as new\ndata and clinics are introduced. It incorporates a non-linear polynomial data\nmodel, site-specific harmonization referenced to a normative site, and variance\npriors adaptable to small cohorts. It further includes hyperparameter tuning\nand a goodness-of-fit metric for harmonization assessment. We demonstrate its\neffectiveness on simulated and real data, showing improved alignment of\ndiffusion metrics and enhanced applicability for normative modeling.", "AI": {"tldr": "本文提出Clinical-ComBAT方法，用于解决弥散加权磁共振成像(DW-MRI)数据在多中心采集时存在的扫描仪特异性偏差，克服了传统ComBAT方法的局限性，特别适用于真实临床场景和规范性建模。", "motivation": "DW-MRI标量图对评估神经退行性疾病和白质微结构非常有效，但多中心采集数据存在扫描仪特异性偏差，需要协调。现有方法如ComBAT因其对线性关系、同质人群、固定站点数和充足数据量的依赖，限制了其在临床实践中的应用。", "method": "本文提出Clinical-ComBAT方法，旨在克服现有ComBAT方法的局限性。其特点包括：独立地协调每个站点，允许新数据和诊所的灵活引入；采用非线性多项式数据模型；站点特异性协调，以规范站点为参考；方差先验可适应小样本队列；包含超参数调优和拟合优度指标以评估协调效果。", "result": "Clinical-ComBAT在模拟数据和真实数据上均表现出有效性，展示了弥散指标的更好对齐，并增强了其在规范性建模中的适用性。", "conclusion": "Clinical-ComBAT成功克服了传统ComBAT方法的限制，为DW-MRI数据提供了一种更灵活、更鲁棒的协调方法，特别适合于真实世界的临床场景和规范性建模，即使面对新数据、小样本队列和非线性关系也能有效工作。"}}
{"id": "2511.04919", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6; H.3.3"], "pdf": "https://arxiv.org/pdf/2511.04919", "abs": "https://arxiv.org/abs/2511.04919", "authors": ["Chandra Vamsi Krishna Alla", "Harish Naidu Gaddam", "Manohar Kommi"], "title": "BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models", "comment": "11 pages, 3 figures, 5 tables. Evaluated on 700 QA pairs across\n  multiple document lengths", "summary": "Large Language Models (LLMs) face significant computational and memory\nconstraints when processing long contexts, despite growing demand for\napplications requiring reasoning over extensive documents, multi-session\ndialogues, and book length texts. While recent advances have extended context\nwindows to 100K-1M tokens, such approaches incur prohibitive costs for resource\nconstrained deployments. We propose BudgetMem, a novel memory augmented\narchitecture that learns what to remember rather than remembering everything.\nOur system combines selective memory policies with feature based salience\nscoring (entity density, TF-IDF, discourse markers, position bias) to decide\nwhich information merits storage under strict budget constraints. Unlike\nexisting retrieval augmented generation (RAG) systems that store all chunks,\nBudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval\nfor efficient information access. Through comprehensive experiments on 700\nquestion answer pairs across short (237 tokens) and long (5K-10K tokens)\ndocuments with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves\nremarkable results on long documents: only 1.0% F1 score degradation while\nsaving 72.4% memory compared to baseline RAG. We validate our approach through\nbudget sensitivity analysis (testing 7 budget ratios), naive baseline\ncomparisons, and document length analysis, showing that BudgetMem's benefits\nincrease with document length. Our work provides a practical pathway for\ndeploying capable long context systems on modest hardware, democratizing access\nto advanced language understanding capabilities.", "AI": {"tldr": "BudgetMem是一种内存增强架构，通过学习性地选择性记忆而非存储所有信息，显著降低了处理长上下文的内存消耗，同时保持了接近基线RAG的性能，尤其适用于长文档。", "motivation": "大型语言模型（LLMs）在处理长上下文时面临巨大的计算和内存限制，而对需要处理大量文档、多会话对话和书籍长度文本的应用需求日益增长。尽管现有方法已将上下文窗口扩展到100K-1M tokens，但这些方法对于资源受限的部署来说成本过高。", "method": "BudgetMem提出了一种新颖的内存增强架构，它学习记忆哪些信息而非记住所有信息。该系统结合了选择性记忆策略和基于特征的显著性评分（实体密度、TF-IDF、语篇标记、位置偏差），以在严格预算约束下决定哪些信息值得存储。与现有存储所有块的检索增强生成（RAG）系统不同，BudgetMem采用学习门控机制结合BM25稀疏检索来实现高效的信息访问。", "result": "在Llama-3.2-3B-Instruct模型上，针对短（237 tokens）和长（5K-10K tokens）文档的700个问答对进行实验，BudgetMem在长文档上表现出色：与基线RAG相比，F1分数仅下降1.0%，同时节省了72.4%的内存。通过预算敏感性分析（测试7种预算比率）、朴素基线比较和文档长度分析，验证了该方法，表明BudgetMem的优势随文档长度增加而增强。", "conclusion": "BudgetMem为在普通硬件上部署有能力的长上下文系统提供了一条实用途径，从而使先进的语言理解能力普及化。"}}
{"id": "2511.04886", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04886", "abs": "https://arxiv.org/abs/2511.04886", "authors": ["Ahmad Elallaf", "Nathan Jacobs", "Xinyue Ye", "Mei Chen", "Gongbo Liang"], "title": "Beta Distribution Learning for Reliable Roadway Crash Risk Assessment", "comment": "Accepted to AAAI 2026", "summary": "Roadway traffic accidents represent a global health crisis, responsible for\nover a million deaths annually and costing many countries up to 3% of their\nGDP. Traditional traffic safety studies often examine risk factors in\nisolation, overlooking the spatial complexity and contextual interactions\ninherent in the built environment. Furthermore, conventional Neural\nNetwork-based risk estimators typically generate point estimates without\nconveying model uncertainty, limiting their utility in critical\ndecision-making. To address these shortcomings, we introduce a novel geospatial\ndeep learning framework that leverages satellite imagery as a comprehensive\nspatial input. This approach enables the model to capture the nuanced spatial\npatterns and embedded environmental risk factors that contribute to fatal crash\nrisks. Rather than producing a single deterministic output, our model estimates\na full Beta probability distribution over fatal crash risk, yielding accurate\nand uncertainty-aware predictions--a critical feature for trustworthy AI in\nsafety-critical applications. Our model outperforms baselines by achieving a\n17-23% improvement in recall, a key metric for flagging potential dangers,\nwhile delivering superior calibration. By providing reliable and interpretable\nrisk assessments from satellite imagery alone, our method enables safer\nautonomous navigation and offers a highly scalable tool for urban planners and\npolicymakers to enhance roadway safety equitably and cost-effectively.", "AI": {"tldr": "本文提出了一种新颖的地理空间深度学习框架，利用卫星图像全面预测致命交通事故风险，并通过Beta概率分布量化模型不确定性。该模型在召回率上优于基线模型，并提供可靠且可解释的风险评估，有助于自动驾驶和城市规划。", "motivation": "道路交通事故是全球性的健康危机，传统交通安全研究忽视了内置环境的空间复杂性和上下文交互。此外，传统的神经网络风险估计器仅提供点估计，缺乏模型不确定性，限制了其在关键决策中的实用性。", "method": "引入了一种新颖的地理空间深度学习框架，该框架利用卫星图像作为全面的空间输入，以捕捉导致致命碰撞风险的细微空间模式和嵌入式环境风险因素。模型不生成单一确定性输出，而是估计致命碰撞风险的完整Beta概率分布，从而提供准确且考虑不确定性的预测。", "result": "该模型在召回率（用于标记潜在危险的关键指标）上比基线模型提高了17-23%，同时提供了卓越的校准。它能从卫星图像中提供可靠且可解释的风险评估，并生成准确且具有不确定性意识的预测。", "conclusion": "该方法通过提供可靠且可解释的风险评估，能够实现更安全的自动驾驶，并为城市规划者和政策制定者提供了一个高度可扩展的工具，以公平且经济高效地提高道路安全。"}}
{"id": "2511.04875", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04875", "abs": "https://arxiv.org/abs/2511.04875", "authors": ["Matthew Bozoukov", "Matthew Nguyen", "Shubkarman Singh", "Bart Bussmann", "Patrick Leask"], "title": "Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs", "comment": null, "summary": "Recent studies have revealed that LLMs can exhibit behavioral self-awareness:\nthe ability to accurately describe or predict their own learned behaviors\nwithout explicit supervision. This capability raises safety concerns as it may,\nfor example, allow models to better conceal their true abilities during\nevaluation. We attempt to characterize the minimal conditions under which such\nself-awareness emerges, and the mechanistic processes through which it\nmanifests. Through controlled finetuning experiments on instruction-tuned LLMs\nwith low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably\ninduced using a single rank-1 LoRA adapter; (2) that the learned self-aware\nbehavior can be largely captured by a single steering vector in activation\nspace, recovering nearly all of the fine-tune's behavioral effect; and (3) that\nself-awareness is non-universal and domain-localized, with independent\nrepresentations across tasks. Together, these findings suggest that behavioral\nself-awareness emerges as a domain-specific, linear feature that can be easily\ninduced and modulated.", "AI": {"tldr": "本研究探讨了大型语言模型（LLMs）行为自我意识的出现条件和机制，发现其可通过单一LoRA适配器诱导，由激活空间中的转向向量捕获，并表现出领域局部性。", "motivation": "LLMs能够准确描述或预测自身学习行为（行为自我意识），这引发了安全担忧，例如模型可能在评估中更好地隐藏真实能力。因此，研究旨在探究这种自我意识出现的最小条件及其作用机制。", "method": "通过对指令调优的LLMs进行受控的低秩适配器（LoRA）微调实验。", "result": ["行为自我意识可通过单一的rank-1 LoRA适配器可靠地诱导。", "学习到的自我意识行为在很大程度上可以通过激活空间中的单一转向向量来捕获，恢复了几乎所有微调的行为效果。", "自我意识并非普遍存在，而是领域局部化的，在不同任务中具有独立的表示。"], "conclusion": "行为自我意识表现为一种领域特定的线性特征，易于诱导和调节。"}}
{"id": "2511.05158", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05158", "abs": "https://arxiv.org/abs/2511.05158", "authors": ["Sahar Salimpour", "Iacopo Catalano", "Tomi Westerlund", "Mohsen Falahi", "Jorge Peña Queralta"], "title": "Follow-Me in Micro-Mobility with End-to-End Imitation Learning", "comment": null, "summary": "Autonomous micro-mobility platforms face challenges from the perspective of\nthe typical deployment environment: large indoor spaces or urban areas that are\npotentially crowded and highly dynamic. While social navigation algorithms have\nprogressed significantly, optimizing user comfort and overall user experience\nover other typical metrics in robotics (e.g., time or distance traveled) is\nunderstudied. Specifically, these metrics are critical in commercial\napplications. In this paper, we show how imitation learning delivers smoother\nand overall better controllers, versus previously used manually-tuned\ncontrollers. We demonstrate how DAAV's autonomous wheelchair achieves\nstate-of-the-art comfort in follow-me mode, in which it follows a human\noperator assisting persons with reduced mobility (PRM). This paper analyzes\ndifferent neural network architectures for end-to-end control and demonstrates\ntheir usability in real-world production-level deployments.", "AI": {"tldr": "本文展示了模仿学习如何为自主微出行平台（如轮椅）在拥挤环境中提供更平稳、更舒适的控制器，优于手动调优，特别是在“跟随我”模式下实现了最先进的用户舒适度。", "motivation": "自主微出行平台在拥挤和动态环境中面临挑战，现有社交导航算法主要优化时间或距离等机器人学指标，而用户舒适度和整体用户体验在商业应用中至关重要但研究不足。", "method": "本文采用模仿学习来开发控制器，并分析了不同的神经网络架构用于端到端控制。通过DAAV自主轮椅在“跟随我”模式下（跟随人类操作员）进行实证。", "result": "模仿学习提供了比手动调优控制器更平稳、整体更好的控制器。DAAV自主轮椅在“跟随我”模式下实现了最先进的用户舒适度。论文还展示了神经网络架构在真实生产级部署中的可用性。", "conclusion": "模仿学习能够显著提升自主微出行平台的用户舒适度和体验，通过神经网络实现的端到端控制方案适用于真实世界的商业部署。"}}
{"id": "2511.05185", "categories": ["cs.RO", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.05185", "abs": "https://arxiv.org/abs/2511.05185", "authors": ["Adrián Campazas-Vega", "Claudia Álvarez-Aparicio", "David Sobrín-Hidalgo", "Laura Inyesto-Alonso", "Francisco Javier Rodríguez-Lera", "Vicente Matellán-Olivera", "Ángel Manuel Guerrero-Higueras"], "title": "Procedimiento de auditoría de ciberseguridad para sistemas autónomos: metodología, amenazas y mitigaciones", "comment": "32 pages, in Spanish language, 7 tables, 12 Figures. White paper\n  under the TESCAC project", "summary": "The deployment of autonomous systems has experienced remarkable growth in\nrecent years, driven by their integration into sectors such as industry,\nmedicine, logistics, and domestic environments. This expansion is accompanied\nby a series of security issues that entail significant risks due to the\ncritical nature of autonomous systems, especially those operating in\nhuman-interaction environments. Furthermore, technological advancement and the\nhigh operational and architectural complexity of autonomous systems have\nresulted in an increased attack surface. This article presents a specific\nsecurity auditing procedure for autonomous systems, based on a layer-structured\nmethodology, a threat taxonomy adapted to the robotic context, and a set of\nconcrete mitigation measures. The validity of the proposed approach is\ndemonstrated through four practical case studies applied to representative\nrobotic platforms: the Vision 60 military quadruped from Ghost Robotics, the A1\nrobot from Unitree Robotics, the UR3 collaborative arm from Universal Robots,\nand the Pepper social robot from Aldebaran Robotics.", "AI": {"tldr": "本文提出了一种针对自主系统的分层安全审计程序，包括威胁分类和缓解措施，并通过四个代表性机器人平台的案例研究验证了其有效性。", "motivation": "自主系统在工业、医疗、物流和家庭环境中的广泛部署带来了显著的安全问题和风险，尤其是在人机交互环境中。此外，技术进步和系统复杂性增加了攻击面。", "method": "提出了一种基于分层方法论、适应机器人上下文的威胁分类以及一套具体缓解措施的自主系统安全审计程序。通过对四种代表性机器人平台（Ghost Robotics的Vision 60、Unitree Robotics的A1、Universal Robots的UR3协作臂和Aldebaran Robotics的Pepper社交机器人）的实际案例研究来验证该方法的有效性。", "result": "通过在四种代表性机器人平台上的实际案例研究，证明了所提出的安全审计方法的有效性。", "conclusion": "成功提出并验证了一种针对自主系统的分层安全审计程序，有效解决了该领域日益增长的安全挑战。"}}
{"id": "2511.04869", "categories": ["cs.CL", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.04869", "abs": "https://arxiv.org/abs/2511.04869", "authors": ["Preetum Nakkiran", "Arwen Bradley", "Adam Goliński", "Eugene Ndiaye", "Michael Kirchhof", "Sinead Williamson"], "title": "Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs", "comment": null, "summary": "Large Language Models (LLMs) often lack meaningful confidence estimates for\ntheir outputs. While base LLMs are known to exhibit next-token calibration, it\nremains unclear whether they can assess confidence in the actual meaning of\ntheir responses beyond the token level. We find that, when using a certain\nsampling-based notion of semantic calibration, base LLMs are remarkably\nwell-calibrated: they can meaningfully assess confidence in open-domain\nquestion-answering tasks, despite not being explicitly trained to do so. Our\nmain theoretical contribution establishes a mechanism for why semantic\ncalibration emerges as a byproduct of next-token prediction, leveraging a\nrecent connection between calibration and local loss optimality. The theory\nrelies on a general definition of \"B-calibration,\" which is a notion of\ncalibration parameterized by a choice of equivalence classes (semantic or\notherwise). This theoretical mechanism leads to a testable prediction: base\nLLMs will be semantically calibrated when they can easily predict their own\ndistribution over semantic answer classes before generating a response. We\nstate three implications of this prediction, which we validate through\nexperiments: (1) Base LLMs are semantically calibrated across\nquestion-answering tasks, (2) RL instruction-tuning systematically breaks this\ncalibration, and (3) chain-of-thought reasoning breaks calibration. To our\nknowledge, our work provides the first principled explanation of when and why\nsemantic calibration emerges in LLMs.", "AI": {"tldr": "本研究发现基础大语言模型在语义层面具有出色的校准能力，能评估其回答的含义置信度，这源于其下一个词元预测机制。然而，强化学习指令微调和思维链推理会破坏这种校准。", "motivation": "大语言模型（LLMs）通常缺乏对其输出的有意义的置信度估计，尤其是在超越词元层面，评估其响应实际含义的置信度方面尚不清楚。", "method": "研究采用了一种基于采样的语义校准概念，并引入了“B-校准”的通用定义（一种由等价类参数化的校准概念）。通过利用校准与局部损失最优性之间的联系，建立了语义校准作为下一个词元预测副产品出现的理论机制。该理论产生了一个可测试的预测，并通过问答任务的实验进行了验证。", "result": "研究发现，基础大语言模型在开放域问答任务中具有显著的语义校准能力，尽管它们并未明确接受此训练。语义校准是下一个词元预测的副产品。实验验证了三个预测：1) 基础LLMs在问答任务中具有语义校准性；2) RL指令微调系统地破坏了这种校准；3) 思维链推理也破坏了校准。", "conclusion": "本工作首次原理性地解释了LLMs中语义校准何时以及为何出现，并揭示了某些微调和推理方法对其产生负面影响。"}}
{"id": "2511.04800", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04800", "abs": "https://arxiv.org/abs/2511.04800", "authors": ["Chenxi Liu", "Junjie Liang", "Yuqi Jia", "Bochuan Cao", "Yang Bai", "Heng Huang", "Xun Chen"], "title": "Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an\neffective approach for improving the reasoning abilities of large language\nmodels (LLMs). The Group Relative Policy Optimization (GRPO) family has\ndemonstrated strong performance in training LLMs with RLVR. However, as models\ntrain longer and scale larger, more training prompts become residual prompts,\nthose with zero variance rewards that provide no training signal. Consequently,\nfewer prompts contribute to training, reducing diversity and hindering\neffectiveness. To fully exploit these residual prompts, we propose the Explore\nResidual Prompts in Policy Optimization (ERPO) framework, which encourages\nexploration on residual prompts and reactivates their training signals. ERPO\nmaintains a history tracker for each prompt and adaptively increases the\nsampling temperature for residual prompts that previously produced all correct\nresponses. This encourages the model to generate more diverse reasoning traces,\nintroducing incorrect responses that revive training signals. Empirical results\non the Qwen2.5 series demonstrate that ERPO consistently surpasses strong\nbaselines across multiple mathematical reasoning benchmarks.", "AI": {"tldr": "RLVR通过GRPO训练LLM在推理方面表现良好，但随着训练深入，残差提示（零方差奖励）增多，导致训练信号多样性降低。本文提出ERPO框架，通过提高对所有正确响应的残差提示的采样温度来鼓励探索，重新激活训练信号，从而提高LLM的数学推理能力。", "motivation": "强化学习与可验证奖励（RLVR）在提升大型语言模型（LLM）推理能力方面有效，其中GRPO系列表现出色。然而，随着模型训练时间增长和规模扩大，越来越多的训练提示变成残差提示（奖励方差为零），导致训练信号减少、多样性降低，从而影响训练效果。", "method": "本文提出了探索残差提示策略优化（ERPO）框架。ERPO为每个提示维护一个历史追踪器，并对那些之前所有响应都正确的残差提示自适应地增加采样温度。这种方法鼓励模型生成更多样化的推理路径，引入不正确的响应以重新激活训练信号。", "result": "在Qwen2.5系列模型上的实证结果表明，ERPO在多个数学推理基准测试中持续超越了强大的基线模型。", "conclusion": "ERPO框架通过鼓励对残差提示的探索并重新激活其训练信号，有效解决了RLVR训练中残差提示导致的训练信号多样性不足问题，显著提升了LLM的数学推理能力。"}}
{"id": "2511.05199", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05199", "abs": "https://arxiv.org/abs/2511.05199", "authors": ["Yichen Zhu", "Feifei Feng"], "title": "Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation", "comment": "Accepted by IROS 2025", "summary": "Robots operating in complex and uncertain environments face considerable\nchallenges. Advanced robotic systems often rely on extensive datasets to learn\nmanipulation tasks. In contrast, when humans are faced with unfamiliar tasks,\nsuch as assembling a chair, a common approach is to learn by watching video\ndemonstrations. In this paper, we propose a novel method for learning robot\npolicies by Retrieving-from-Video (RfV), using analogies from human\ndemonstrations to address manipulation tasks. Our system constructs a video\nbank comprising recordings of humans performing diverse daily tasks. To enrich\nthe knowledge from these videos, we extract mid-level information, such as\nobject affordance masks and hand motion trajectories, which serve as additional\ninputs to enhance the robot model's learning and generalization capabilities.\nWe further feature a dual-component system: a video retriever that taps into an\nexternal video bank to fetch task-relevant video based on task specification,\nand a policy generator that integrates this retrieved knowledge into the\nlearning cycle. This approach enables robots to craft adaptive responses to\nvarious scenarios and generalize to tasks beyond those in the training data.\nThrough rigorous testing in multiple simulated and real-world settings, our\nsystem demonstrates a marked improvement in performance over conventional\nrobotic systems, showcasing a significant breakthrough in the field of\nrobotics.", "AI": {"tldr": "本文提出了一种名为“从视频中检索学习”（RfV）的新方法，通过从人类演示视频中获取类比知识，使机器人能够学习操作策略，从而提高在复杂环境中的适应性和泛化能力。", "motivation": "现有机器人系统在复杂不确定环境中面临挑战，且通常依赖大量数据集学习操作任务。与此不同，人类在面对不熟悉任务时，常通过观看视频演示来学习。这促使研究者探索如何让机器人也能从人类视频中学习。", "method": "该方法构建了一个包含人类日常任务视频的视频库，并从中提取物体可供性掩码和手部运动轨迹等中级信息，作为额外输入以增强机器人模型的学习和泛化能力。系统包含两个核心组件：一个视频检索器，根据任务规范从外部视频库中获取相关视频；一个策略生成器，将检索到的知识整合到学习循环中。", "result": "通过在多个模拟和真实世界场景中的严格测试，该系统在性能上显著优于传统机器人系统，展示了其在机器人领域的重大突破。", "conclusion": "该研究提供了一种通过从人类视频演示中检索和学习来生成机器人策略的新颖方法，使机器人能够对各种场景做出适应性响应，并泛化到训练数据之外的任务，代表了机器人领域的一项重要进展。"}}
{"id": "2511.04948", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04948", "abs": "https://arxiv.org/abs/2511.04948", "authors": ["Haoxin Lv", "Ijazul Haq", "Jin Du", "Jiaxin Ma", "Binnian Zhu", "Xiaobing Dang", "Chaoan Liang", "Ruxu Du", "Yingjie Zhang", "Muhammad Saqib"], "title": "A benchmark multimodal oro-dental dataset for large vision-language models", "comment": null, "summary": "The advancement of artificial intelligence in oral healthcare relies on the\navailability of large-scale multimodal datasets that capture the complexity of\nclinical practice. In this paper, we present a comprehensive multimodal\ndataset, comprising 8775 dental checkups from 4800 patients collected over\neight years (2018-2025), with patients ranging from 10 to 90 years of age. The\ndataset includes 50000 intraoral images, 8056 radiographs, and detailed textual\nrecords, including diagnoses, treatment plans, and follow-up notes. The data\nwere collected under standard ethical guidelines and annotated for\nbenchmarking. To demonstrate its utility, we fine-tuned state-of-the-art large\nvision-language models, Qwen-VL 3B and 7B, and evaluated them on two tasks:\nclassification of six oro-dental anomalies and generation of complete\ndiagnostic reports from multimodal inputs. We compared the fine-tuned models\nwith their base counterparts and GPT-4o. The fine-tuned models achieved\nsubstantial gains over these baselines, validating the dataset and underscoring\nits effectiveness in advancing AI-driven oro-dental healthcare solutions. The\ndataset is publicly available, providing an essential resource for future\nresearch in AI dentistry.", "AI": {"tldr": "本文介绍了一个大规模多模态口腔医疗数据集，包含8775次牙科检查，并利用该数据集微调了视觉语言模型，在口腔异常分类和诊断报告生成任务上取得了显著优于基线模型的效果。", "motivation": "口腔医疗领域人工智能的发展需要能够捕捉临床实践复杂性的大规模多模态数据集。", "method": "研究团队构建了一个综合性多模态数据集，包含来自4800名患者的8775次牙科检查（2018-2025年），包括50000张口内图像、8056张X光片以及详细的文本记录（诊断、治疗计划、随访记录）。数据在伦理指导下收集并进行基准测试标注。为验证数据集的实用性，研究者微调了Qwen-VL 3B和7B等先进大型视觉语言模型，并在六种口腔牙齿异常分类和从多模态输入生成完整诊断报告两项任务上进行评估，与基线模型（基础版Qwen-VL和GPT-4o）进行了比较。", "result": "经过微调的模型在两项任务上均取得了显著优于基线模型（包括基础版Qwen-VL和GPT-4o）的性能提升，验证了数据集的有效性。", "conclusion": "该数据集有效推动了人工智能驱动的口腔牙齿医疗解决方案，并已公开可用，为未来AI牙科研究提供了重要资源。"}}
{"id": "2511.05379", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05379", "abs": "https://arxiv.org/abs/2511.05379", "authors": ["Eric Godden", "Jacquie Groenewegen", "Matthew K. X. J. Pan"], "title": "ETHOS: A Robotic Encountered-Type Haptic Display for Social Interaction in Virtual Reality", "comment": "8 pages", "summary": "We present ETHOS (Encountered-Type Haptics for On-demand Social Interaction),\na dynamic encountered-type haptic display (ETHD) that enables natural physical\ncontact in virtual reality (VR) during social interactions such as handovers,\nfist bumps, and high-fives. The system integrates a torque-controlled robotic\nmanipulator with interchangeable passive props (silicone hand replicas and a\nbaton), marker-based physical-virtual registration via a ChArUco board, and a\nsafety monitor that gates motion based on the user's head and hand pose. We\nintroduce two control strategies: (i) a static mode that presents a stationary\nprop aligned with its virtual counterpart, consistent with prior ETHD\nbaselines, and (ii) a dynamic mode that continuously updates prop position by\nexponentially blending an initial mid-point trajectory with real-time hand\ntracking, generating a unique contact point for each interaction. Bench tests\nshow static colocation accuracy of 5.09 +/- 0.94 mm, while user interactions\nachieved temporal alignment with an average contact latency of 28.53 +/- 31.21\nms across all interaction and control conditions. These results demonstrate the\nfeasibility of recreating socially meaningful haptics in VR. By incorporating\nessential safety and control mechanisms, ETHOS establishes a practical\nfoundation for high-fidelity, dynamic interpersonal interactions in virtual\nenvironments.", "AI": {"tldr": "ETHOS是一个动态的接触式触觉显示系统，旨在虚拟现实（VR）中实现自然的人际物理接触，例如传递物品、碰拳和击掌，通过集成机器人机械臂、可互换道具、精确注册和安全监控来实现。", "motivation": "当前VR社交互动中缺乏自然的物理接触，如传递物品、碰拳和击掌。本研究旨在开发一种动态触觉显示系统，以在VR中提供这些有意义的物理交互。", "method": "ETHOS系统结合了力矩控制的机械臂和可互换的被动道具（硅胶手模型和警棍）。它通过ChArUco板进行基于标记的物理-虚拟注册，并包含一个基于用户头部和手部姿态的安全监控器。研究引入了两种控制策略：静态模式（呈现与虚拟对应物对齐的固定道具）和动态模式（通过混合初始中间轨迹和实时手部追踪来连续更新道具位置，为每次交互生成独特的接触点）。", "result": "基准测试显示静态共置精度为5.09 ± 0.94毫米。用户交互在所有交互和控制条件下实现了时间对齐，平均接触延迟为28.53 ± 31.21毫秒。这些结果证明了在VR中重现具有社会意义的触觉交互的可行性。", "conclusion": "ETHOS通过结合必要的安全和控制机制，为虚拟环境中高保真、动态的人际交互奠定了实用基础，成功展示了在VR中实现自然物理接触的可能性。"}}
{"id": "2511.04949", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04949", "abs": "https://arxiv.org/abs/2511.04949", "authors": ["Tharindu Fernando", "Clinton Fookes", "Sridha Sridharan"], "title": "DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning", "comment": null, "summary": "Rapid advances in generative AI have led to increasingly realistic deepfakes,\nposing growing challenges for law enforcement and public trust. Existing\npassive deepfake detectors struggle to keep pace, largely due to their\ndependence on specific forgery artifacts, which limits their ability to\ngeneralize to new deepfake types. Proactive deepfake detection using watermarks\nhas emerged to address the challenge of identifying high-quality synthetic\nmedia. However, these methods often struggle to balance robustness against\nbenign distortions with sensitivity to malicious tampering. This paper\nintroduces a novel deep learning framework that harnesses high-dimensional\nlatent space representations and the Multi-Agent Adversarial Reinforcement\nLearning (MAARL) paradigm to develop a robust and adaptive watermarking\napproach. Specifically, we develop a learnable watermark embedder that operates\nin the latent space, capturing high-level image semantics, while offering\nprecise control over message encoding and extraction. The MAARL paradigm\nempowers the learnable watermarking agent to pursue an optimal balance between\nrobustness and fragility by interacting with a dynamic curriculum of benign and\nmalicious image manipulations simulated by an adversarial attacker agent.\nComprehensive evaluations on the CelebA and CelebA-HQ benchmarks reveal that\nour method consistently outperforms state-of-the-art approaches, achieving\nimprovements of over 4.5% on CelebA and more than 5.3% on CelebA-HQ under\nchallenging manipulation scenarios.", "AI": {"tldr": "本文提出了一种新颖的深度学习框架，结合高维潜在空间和多智能体对抗强化学习（MAARL），以开发一种鲁棒且自适应的数字水印方法，用于主动检测深度伪造，并在鲁棒性与篡改敏感性之间取得平衡。", "motivation": "生成式AI的快速发展导致深度伪造日益逼真，对执法和公众信任构成挑战。现有被动检测器因依赖特定伪造痕迹而泛化能力差。主动水印方法虽能识别高质量合成媒体，但难以平衡对良性失真的鲁棒性与对恶意篡改的敏感性。", "method": "该方法引入了一个深度学习框架，利用高维潜在空间表示和多智能体对抗强化学习（MAARL）范式。具体来说，开发了一个在潜在空间操作的可学习水印嵌入器，捕捉高级图像语义并精确控制消息编解码。MAARL范式通过与模拟良性和恶意图像操作的对抗性攻击者智能体交互，使可学习水印智能体在鲁棒性和脆弱性之间寻求最佳平衡。", "result": "在CelebA和CelebA-HQ基准测试中，该方法在挑战性操纵场景下，始终优于现有最先进方法，在CelebA上实现了超过4.5%的改进，在CelebA-HQ上实现了超过5.3%的改进。", "conclusion": "本文成功开发了一种新颖的深度学习框架，通过结合潜在空间水印和MAARL，为主动深度伪造检测提供了一种鲁棒且自适应的水印方法，有效解决了鲁棒性与篡改敏感性之间的平衡问题，并显著超越了现有技术。"}}
{"id": "2511.04963", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04963", "abs": "https://arxiv.org/abs/2511.04963", "authors": ["Xiongri Shen", "Jiaqi Wang", "Yi Zhong", "Zhenxi Song", "Leilei Zhao", "Yichen Wei", "Lingyan Liang", "Shuqiang Wang", "Baiying Lei", "Demao Deng", "Zhiguo Zhang"], "title": "Pattern-Aware Diffusion Synthesis of fMRI/dMRI with Tissue and Microstructural Refinement", "comment": null, "summary": "Magnetic resonance imaging (MRI), especially functional MRI (fMRI) and\ndiffusion MRI (dMRI), is essential for studying neurodegenerative diseases.\nHowever, missing modalities pose a major barrier to their clinical use.\nAlthough GAN- and diffusion model-based approaches have shown some promise in\nmodality completion, they remain limited in fMRI-dMRI synthesis due to (1)\nsignificant BOLD vs. diffusion-weighted signal differences between fMRI and\ndMRI in time/gradient axis, and (2) inadequate integration of disease-related\nneuroanatomical patterns during generation. To address these challenges, we\npropose PDS, introducing two key innovations: (1) a pattern-aware dual-modal 3D\ndiffusion framework for cross-modality learning, and (2) a tissue refinement\nnetwork integrated with a efficient microstructure refinement to maintain\nstructural fidelity and fine details. Evaluated on OASIS-3, ADNI, and in-house\ndatasets, our method achieves state-of-the-art results, with PSNR/SSIM scores\nof 29.83 dB/90.84\\% for fMRI synthesis (+1.54 dB/+4.12\\% over baselines) and\n30.00 dB/77.55\\% for dMRI synthesis (+1.02 dB/+2.2\\%). In clinical validation,\nthe synthesized data show strong diagnostic performance, achieving\n67.92\\%/66.02\\%/64.15\\% accuracy (NC vs. MCI vs. AD) in hybrid real-synthetic\nexperiments. Code is available in \\href{https://github.com/SXR3015/PDS}{PDS\nGitHub Repository}", "AI": {"tldr": "本文提出PDS模型，通过模式感知双模态3D扩散框架和组织精细化网络，解决了fMRI和dMRI模态合成中存在的信号差异和疾病模式整合不足问题，实现了先进的模态补全和临床诊断性能。", "motivation": "磁共振成像（MRI）对神经退行性疾病研究至关重要，但模态缺失严重阻碍了其临床应用。现有基于GAN和扩散模型的方法在fMRI-dMRI合成方面存在局限性，主要原因包括fMRI和dMRI在时间/梯度轴上的BOLD与扩散加权信号差异显著，以及在生成过程中未能充分整合与疾病相关的神经解剖模式。", "method": "本文提出了PDS模型，引入了两项关键创新：1) 一个模式感知双模态3D扩散框架，用于跨模态学习；2) 一个集成高效微结构精细化的组织精细化网络，以保持结构保真度和精细细节。", "result": "在OASIS-3、ADNI和内部数据集上进行评估，PDS方法取得了最先进的结果。fMRI合成的PSNR/SSIM分数达到29.83 dB/90.84%（比基线提高1.54 dB/4.12%），dMRI合成达到30.00 dB/77.55%（提高1.02 dB/2.2%）。在临床验证中，合成数据在混合真实-合成实验中显示出强大的诊断性能，在NC vs. MCI vs. AD分类中准确率达到67.92%/66.02%/64.15%。", "conclusion": "PDS模型通过其创新的双模态扩散框架和精细化网络，有效解决了fMRI-dMRI合成中的挑战，生成了高保真度且在临床诊断中具有实用价值的合成数据，显著提升了模态补全的性能和临床应用潜力。"}}
{"id": "2511.04920", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04920", "abs": "https://arxiv.org/abs/2511.04920", "authors": ["Hu Gao", "Xiaoning Lei", "Ying Zhang", "Xichen Xu", "Guannan Jiang", "Lizhuang Ma"], "title": "Learning to Restore Multi-Degraded Images via Ingredient Decoupling and Task-Aware Path Adaptation", "comment": null, "summary": "Image restoration (IR) aims to recover clean images from degraded\nobservations. Despite remarkable progress, most existing methods focus on a\nsingle degradation type, whereas real-world images often suffer from multiple\ncoexisting degradations, such as rain, noise, and haze coexisting in a single\nimage, which limits their practical effectiveness. In this paper, we propose an\nadaptive multi-degradation image restoration network that reconstructs images\nby leveraging decoupled representations of degradation ingredients to guide\npath selection. Specifically, we design a degradation ingredient decoupling\nblock (DIDBlock) in the encoder to separate degradation ingredients\nstatistically by integrating spatial and frequency domain information,\nenhancing the recognition of multiple degradation types and making their\nfeature representations independent. In addition, we present fusion block\n(FBlock) to integrate degradation information across all levels using learnable\nmatrices. In the decoder, we further introduce a task adaptation block\n(TABlock) that dynamically activates or fuses functional branches based on the\nmulti-degradation representation, flexibly selecting optimal restoration paths\nunder diverse degradation conditions. The resulting tightly integrated\narchitecture, termed IMDNet, is extensively validated through experiments,\nshowing superior performance on multi-degradation restoration while maintaining\nstrong competitiveness on single-degradation tasks.", "AI": {"tldr": "该论文提出了一种名为IMDNet的自适应多降质图像恢复网络，通过解耦降质成分表示来指导路径选择，从而有效处理图像中同时存在的多种降质类型。", "motivation": "现有图像恢复方法大多只关注单一降质类型，但在现实世界中，图像常受到多种降质（如雨、噪声、雾霾）的共同影响，这限制了它们在实际应用中的有效性。", "method": "该研究提出了一种自适应多降质图像恢复网络（IMDNet）。具体方法包括：1. 在编码器中设计了降质成分解耦块（DIDBlock），通过整合空间和频率域信息来统计性地分离降质成分。2. 引入融合块（FBlock），使用可学习矩阵整合所有级别的降质信息。3. 在解码器中引入任务自适应块（TABlock），根据多降质表示动态激活或融合功能分支，灵活选择最佳恢复路径。", "result": "实验结果表明，IMDNet在多降质恢复任务上表现出卓越的性能，同时在单一降质任务上也能保持强大的竞争力。", "conclusion": "所提出的IMDNet架构通过解耦降质表示和自适应路径选择，能有效处理图像中的多种共存降质，显著提升了图像恢复的实用性。"}}
{"id": "2511.04921", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04921", "abs": "https://arxiv.org/abs/2511.04921", "authors": ["Yu Li", "Lehui Li", "Qingmin Liao", "Fengli Xu", "Yong Li"], "title": "AgentExpt: Automating AI Experiment Design with LLM-based Resource Retrieval Agent", "comment": "10 pages", "summary": "Large language model agents are becoming increasingly capable at web-centric\ntasks such as information retrieval, complex reasoning. These emerging\ncapabilities have given rise to surge research interests in developing LLM\nagent for facilitating scientific quest. One key application in AI research is\nto automate experiment design through agentic dataset and baseline retrieval.\nHowever, prior efforts suffer from limited data coverage, as recommendation\ndatasets primarily harvest candidates from public portals and omit many\ndatasets actually used in published papers, and from an overreliance on content\nsimilarity that biases model toward superficial similarity and overlooks\nexperimental suitability. Harnessing collective perception embedded in the\nbaseline and dataset citation network, we present a comprehensive framework for\nbaseline and dataset recommendation. First, we design an automated\ndata-collection pipeline that links roughly one hundred thousand accepted\npapers to the baselines and datasets they actually used. Second, we propose a\ncollective perception enhanced retriever. To represent the position of each\ndataset or baseline within the scholarly network, it concatenates\nself-descriptions with aggregated citation contexts. To achieve efficient\ncandidate recall, we finetune an embedding model on these representations.\nFinally, we develop a reasoning-augmented reranker that exact interaction\nchains to construct explicit reasoning chains and finetunes a large language\nmodel to produce interpretable justifications and refined rankings. The dataset\nwe curated covers 85\\% of the datasets and baselines used at top AI conferences\nover the past five years. On our dataset, the proposed method outperforms the\nstrongest prior baseline with average gains of +5.85\\% in Recall@20, +8.30\\% in\nHitRate@5. Taken together, our results advance reliable, interpretable\nautomation of experimental design.", "AI": {"tldr": "本文提出一个综合框架，通过利用基线和数据集的引用网络，改进了大型语言模型代理在自动化实验设计中的数据集和基线推荐。该框架包括一个自动数据收集管道、一个集体感知增强的检索器和一个推理增强的重排序器，显著提高了推荐的召回率和命中率。", "motivation": "大型语言模型代理在网络任务中的能力日益增强，激发了利用其促进科学探索的兴趣，尤其是在通过代理式数据集和基线检索自动化实验设计方面。然而，现有方法存在数据覆盖有限（未涵盖论文中实际使用的数据集）和过度依赖内容相似性（导致表面相似性而非实验适用性）的问题。", "method": "1. 设计了一个自动化数据收集管道，将约十万篇已接受论文与其使用的基线和数据集关联起来。2. 提出了一个集体感知增强的检索器，通过将自描述与聚合的引用上下文连接起来，表示每个数据集或基线在学术网络中的位置，并微调嵌入模型以实现高效的候选召回。3. 开发了一个推理增强的重排序器，提取交互链以构建明确的推理链，并微调大型语言模型以生成可解释的理由和精炼的排名。", "result": "1. 整理的数据集覆盖了过去五年顶级AI会议上使用的85%的数据集和基线。2. 所提出的方法在Recall@20上平均提高了5.85%，在HitRate@5上平均提高了8.30%，优于之前最强基线。", "conclusion": "研究结果推动了实验设计自动化领域向更可靠、可解释的方向发展。"}}
{"id": "2511.04962", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04962", "abs": "https://arxiv.org/abs/2511.04962", "authors": ["Zihao Yi", "Qingxuan Jiang", "Ruotian Ma", "Xingyu Chen", "Qu Yang", "Mengru Wang", "Fanghua Ye", "Ying Shen", "Zhaopeng Tu", "Xiaolong Li", "Linus"], "title": "Too Good to be Bad: On the Failure of LLMs to Role-Play Villains", "comment": null, "summary": "Large Language Models (LLMs) are increasingly tasked with creative\ngeneration, including the simulation of fictional characters. However, their\nability to portray non-prosocial, antagonistic personas remains largely\nunexamined. We hypothesize that the safety alignment of modern LLMs creates a\nfundamental conflict with the task of authentically role-playing morally\nambiguous or villainous characters. To investigate this, we introduce the Moral\nRolePlay benchmark, a new dataset featuring a four-level moral alignment scale\nand a balanced test set for rigorous evaluation. We task state-of-the-art LLMs\nwith role-playing characters from moral paragons to pure villains. Our\nlarge-scale evaluation reveals a consistent, monotonic decline in role-playing\nfidelity as character morality decreases. We find that models struggle most\nwith traits directly antithetical to safety principles, such as ``Deceitful''\nand ``Manipulative'', often substituting nuanced malevolence with superficial\naggression. Furthermore, we demonstrate that general chatbot proficiency is a\npoor predictor of villain role-playing ability, with highly safety-aligned\nmodels performing particularly poorly. Our work provides the first systematic\nevidence of this critical limitation, highlighting a key tension between model\nsafety and creative fidelity. Our benchmark and findings pave the way for\ndeveloping more nuanced, context-aware alignment methods.", "AI": {"tldr": "研究发现，由于安全对齐，大型语言模型在扮演非亲社会或反派角色时表现不佳，角色道德水平越低，扮演的忠实度下降越明显。", "motivation": "大型语言模型（LLMs）越来越多地用于创意生成和角色模拟，但它们扮演非亲社会、反派角色的能力尚未得到充分检验。研究者假设，现代LLMs的安全对齐与真实扮演道德模糊或邪恶角色之间存在根本冲突。", "method": "引入了“道德角色扮演（Moral RolePlay）”基准测试数据集，该数据集包含一个四级道德对齐量表和平衡的测试集。使用该基准测试评估了最先进的LLMs扮演从道德典范到纯粹反派角色的能力，并进行了大规模评估。", "result": "评估显示，随着角色道德水平的降低，LLMs的角色扮演忠实度呈一致的单调下降趋势。模型在处理“欺骗性”和“操纵性”等直接与安全原则相悖的特质时表现最差，常常用肤浅的攻击性取代细致入微的恶意。此外，通用聊天机器人的熟练程度并不能很好地预测反派角色扮演能力，高度安全对齐的模型表现尤其差。", "conclusion": "这项工作首次系统地揭示了LLMs在扮演反派角色方面的关键局限性，突出了模型安全性与创意忠实度之间的关键矛盾。该基准和研究结果为开发更细致、更具情境感知能力的对齐方法铺平了道路。"}}
{"id": "2511.04872", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04872", "abs": "https://arxiv.org/abs/2511.04872", "authors": ["James Ndubuisi", "Fernando Auat", "Marta Vallejo"], "title": "Validating Vision Transformers for Otoscopy: Performance and Data-Leakage Effects", "comment": null, "summary": "This study evaluates the efficacy of vision transformer models, specifically\nSwin transformers, in enhancing the diagnostic accuracy of ear diseases\ncompared to traditional convolutional neural networks. With a reported 27%\nmisdiagnosis rate among specialist otolaryngologists, improving diagnostic\naccuracy is crucial. The research utilised a real-world dataset from the\nDepartment of Otolaryngology at the Clinical Hospital of the Universidad de\nChile, comprising otoscopic videos of ear examinations depicting various middle\nand external ear conditions. Frames were selected based on the Laplacian and\nShannon entropy thresholds, with blank frames removed. Initially, Swin v1 and\nSwin v2 transformer models achieved accuracies of 100% and 99.1%, respectively,\nmarginally outperforming the ResNet model (99.5%). These results surpassed\nmetrics reported in related studies. However, the evaluation uncovered a\ncritical data leakage issue in the preprocessing step, affecting both this\nstudy and related research using the same raw dataset. After mitigating the\ndata leakage, model performance decreased significantly. Corrected accuracies\nwere 83% for both Swin v1 and Swin v2, and 82% for the ResNet model. This\nfinding highlights the importance of rigorous data handling in machine learning\nstudies, especially in medical applications. The findings indicate that while\nvision transformers show promise, it is essential to find an optimal balance\nbetween the benefits of advanced model architectures and those derived from\neffective data preprocessing. This balance is key to developing a reliable\nmachine learning model for diagnosing ear diseases.", "AI": {"tldr": "本研究评估了Swin Transformer在耳部疾病诊断中的效能，最初表现出色，但在纠正数据泄露后性能显著下降，强调了数据处理在医学机器学习中的关键作用。", "motivation": "耳鼻喉科专家诊断耳部疾病的误诊率高达27%，因此提高诊断准确性至关重要。", "method": "研究使用了智利大学临床医院耳鼻喉科的真实耳镜视频数据集。通过拉普拉斯和香农熵阈值选择帧并移除空白帧。评估了Swin v1、Swin v2 Transformer模型和ResNet模型。关键是，研究发现了数据预处理中的数据泄露问题，并进行了纠正。", "result": "初步结果显示Swin v1、Swin v2和ResNet模型的准确率分别为100%、99.1%和99.5%。但在纠正数据泄露后，Swin v1和Swin v2的准确率降至83%，ResNet降至82%。这一发现揭示了数据泄露对模型性能的显著影响。", "conclusion": "尽管视觉Transformer模型在耳部疾病诊断中显示出潜力，但严格的数据处理和在先进模型架构与有效数据预处理之间找到最佳平衡对于开发可靠的医学机器学习模型至关重要。"}}
{"id": "2511.05203", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05203", "abs": "https://arxiv.org/abs/2511.05203", "authors": ["Linus Nwankwo", "Björn Ellensohn", "Christian Rauch", "Elmar Rueckert"], "title": "Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space", "comment": null, "summary": "Today's autonomous agents can understand free-form natural language\ninstructions and execute long-horizon tasks in a manner akin to human-level\nreasoning. These capabilities are mostly driven by large-scale pre-trained\nfoundation models (FMs). However, the approaches with which these models are\ngrounded for human-robot interaction (HRI) perpetuate a master-apprentice\nmodel, where the apprentice (embodied agent) passively receives and executes\nthe master's (human's) commands without reciprocal learning. This reactive\ninteraction approach does not capture the co-adaptive dynamics inherent in\neveryday multi-turn human-human interactions. To address this, we propose a\nSymbiotic Interactive Learning (SIL) approach that enables both the master and\nthe apprentice to co-adapt through mutual, bidirectional interactions. We\nformalised SIL as a co-adaptation process within a shared latent task space,\nwhere the agent and human maintain joint belief states that evolve based on\ninteraction history. This enables the agent to move beyond reactive execution\nto proactive clarification, adaptive suggestions, and shared plan refinement.\nTo realise these novel behaviours, we leveraged pre-trained FMs for spatial\nperception and reasoning, alongside a lightweight latent encoder that grounds\nthe models' outputs into task-specific representations. Furthermore, to ensure\nstability as the tasks evolve, we augment SIL with a memory architecture that\nprevents the forgetting of learned task-space representations. We validate SIL\non both simulated and real-world embodied tasks, including instruction\nfollowing, information retrieval, query-oriented reasoning, and interactive\ndialogues. Demos and resources are public\nat:~\\href{https://linusnep.github.io/SIL/}{https://linusnep.github.io/SIL/}.", "AI": {"tldr": "本文提出了一种共生交互学习（SIL）方法，旨在使自主智能体和人类能够通过相互、双向的交互进行共同适应，超越了传统的“主仆”式人机交互模式。", "motivation": "当前的自主智能体在人机交互（HRI）中主要采用“主仆”模式，智能体被动地接收和执行指令，缺乏相互学习和共同适应的动态，这与人类日常交互中固有的共同适应性不符。", "method": "本文提出了共生交互学习（SIL），并将其形式化为在共享潜在任务空间中的共同适应过程，智能体和人类在此空间中维护基于交互历史演变的联合信念状态。该方法利用预训练的基础模型（FMs）进行空间感知和推理，并结合一个轻量级潜在编码器将模型输出映射到任务特定表示。此外，为确保任务演进的稳定性，SIL还增强了记忆架构以防止遗忘学习到的任务空间表示。", "result": "SIL使智能体能够超越被动执行，实现主动澄清、自适应建议和共享计划细化。该方法在模拟和真实世界的具身任务中得到了验证，包括指令遵循、信息检索、面向查询的推理和交互式对话。", "conclusion": "SIL成功地实现了人机之间的共同适应和双向交互，显著提升了自主智能体的交互能力，使其能够进行更接近人类水平的推理和互动，解决了传统HRI模式的局限性。"}}
{"id": "2511.04951", "categories": ["cs.CV", "D.4; I.3.2; I.3.7"], "pdf": "https://arxiv.org/pdf/2511.04951", "abs": "https://arxiv.org/abs/2511.04951", "authors": ["Hexu Zhao", "Xiwen Min", "Xiaoteng Liu", "Moonjun Gong", "Yiming Li", "Ang Li", "Saining Xie", "Jinyang Li", "Aurojit Panda"], "title": "CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting", "comment": "Accepted to appear in the 2026 ACM International Conference on\n  Architectural Support for Programming Languages and Operating Systems", "summary": "3D Gaussian Splatting (3DGS) is an increasingly popular novel view synthesis\napproach due to its fast rendering time, and high-quality output. However,\nscaling 3DGS to large (or intricate) scenes is challenging due to its large\nmemory requirement, which exceed most GPU's memory capacity. In this paper, we\ndescribe CLM, a system that allows 3DGS to render large scenes using a single\nconsumer-grade GPU, e.g., RTX4090. It does so by offloading Gaussians to CPU\nmemory, and loading them into GPU memory only when necessary. To reduce\nperformance and communication overheads, CLM uses a novel offloading strategy\nthat exploits observations about 3DGS's memory access pattern for pipelining,\nand thus overlap GPU-to-CPU communication, GPU computation and CPU computation.\nFurthermore, we also exploit observation about the access pattern to reduce\ncommunication volume. Our evaluation shows that the resulting implementation\ncan render a large scene that requires 100 million Gaussians on a single\nRTX4090 and achieve state-of-the-art reconstruction quality.", "AI": {"tldr": "本文提出了CLM系统，通过将3DGS的高斯点卸载到CPU内存并优化数据传输，解决了3DGS在大型场景中内存需求过大的问题，使其能在消费级GPU上实现高质量渲染。", "motivation": "3D Gaussian Splatting (3DGS) 虽然渲染速度快、输出质量高，但其庞大的内存需求使其难以扩展到大型或复杂场景，超出了大多数GPU的内存容量。", "method": "CLM系统通过将高斯点卸载到CPU内存，仅在必要时加载到GPU内存。为减少性能和通信开销，CLM采用了一种新颖的卸载策略，利用3DGS的内存访问模式进行流水线操作，从而重叠GPU-to-CPU通信、GPU计算和CPU计算。此外，还利用访问模式来减少通信量。", "result": "实验结果表明，CLM系统能够在单个RTX4090显卡上渲染需要1亿个高斯点的大型场景，并实现了最先进的重建质量。", "conclusion": "CLM系统成功地使3DGS能够在单张消费级GPU上渲染大型场景，有效解决了其内存限制问题，同时保持了高渲染质量。"}}
{"id": "2511.05234", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05234", "abs": "https://arxiv.org/abs/2511.05234", "authors": ["Philipp Dahlinger", "Niklas Freymuth", "Tai Hoang", "Tobias Würth", "Michael Volpp", "Luise Kärger", "Gerhard Neumann"], "title": "Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning", "comment": "35 pages. Submitted to Transactions on Machine Learning Research\n  (TMLR)", "summary": "Simulating object deformations is a critical challenge across many scientific\ndomains, including robotics, manufacturing, and structural mechanics. Learned\nGraph Network Simulators (GNSs) offer a promising alternative to traditional\nmesh-based physics simulators. Their speed and inherent differentiability make\nthem particularly well suited for applications that require fast and accurate\nsimulations, such as robotic manipulation or manufacturing optimization.\nHowever, existing learned simulators typically rely on single-step\nobservations, which limits their ability to exploit temporal context. Without\nthis information, these models fail to infer, e.g., material properties.\nFurther, they rely on auto-regressive rollouts, which quickly accumulate error\nfor long trajectories. We instead frame mesh-based simulation as a\ntrajectory-level meta-learning problem. Using Conditional Neural Processes, our\nmethod enables rapid adaptation to new simulation scenarios from limited\ninitial data while capturing their latent simulation properties. We utilize\nmovement primitives to directly predict fast, stable and accurate simulations\nfrom a single model call. The resulting approach, Movement-primitive\nMeta-MeshGraphNet (M3GN), provides higher simulation accuracy at a fraction of\nthe runtime cost compared to state-of-the-art GNSs across several tasks.", "AI": {"tldr": "本文提出了一种名为M3GN的新型元学习方法，将网格模拟视为轨迹级别的元学习问题。通过使用条件神经过程和运动基元，M3GN能从有限数据中快速适应新场景，并以更高的精度和更低的运行成本超越现有图网络模拟器（GNS）。", "motivation": "物体变形模拟在机器人、制造和结构力学等领域至关重要。现有学习型模拟器（如GNS）通常依赖单步观察，这限制了它们利用时间上下文的能力（例如，推断材料属性），并因自回归推出而导致长轨迹误差累积。", "method": "本文将基于网格的模拟重新定义为轨迹级别的元学习问题。利用条件神经过程（Conditional Neural Processes），该方法能从有限的初始数据中快速适应新的模拟场景并捕获其潜在的模拟属性。此外，通过使用运动基元（movement primitives），该方法能够通过单次模型调用直接预测快速、稳定且准确的模拟，最终形成了Movement-primitive Meta-MeshGraphNet (M3GN)。", "result": "与最先进的图网络模拟器（GNSs）相比，M3GN在多项任务中实现了更高的模拟精度，同时运行成本仅为其一小部分。", "conclusion": "M3GN通过将网格模拟框架为轨迹级别的元学习问题，并结合运动基元，有效克服了现有学习型模拟器在处理时间上下文和长轨迹误差累积方面的局限性，显著提升了模拟的准确性和效率。"}}
{"id": "2511.04910", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04910", "abs": "https://arxiv.org/abs/2511.04910", "authors": ["Jaehoon Lee", "Sohyun Kim", "Wanggeun Park", "Geon Lee", "Seungkyung Kim", "Minyoung Lee"], "title": "SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents", "comment": "27 pages, 15 figures, 6 tables", "summary": "Existing benchmarks for visual document retrieval (VDR) largely overlook\nnon-English languages and the structural complexity of official publications.\nTo address this critical gap, we introduce SDS KoPub VDR, the first\nlarge-scale, publicly available benchmark for retrieving and understanding\nKorean public documents. The benchmark is built upon a corpus of 361 real-world\ndocuments (40,781 pages), including 256 files under the KOGL Type 1 license and\n105 from official legal portals, capturing complex visual elements like tables,\ncharts, and multi-column layouts. To establish a challenging and reliable\nevaluation set, we constructed 600 query-page-answer triples. These were\ninitially generated using multimodal models (e.g., GPT-4o) and subsequently\nunderwent a rigorous human verification and refinement process to ensure\nfactual accuracy and contextual relevance. The queries span six major public\ndomains and are systematically categorized by the reasoning modality required:\ntext-based, visual-based (e.g., chart interpretation), and cross-modal. We\nevaluate SDS KoPub VDR on two complementary tasks that reflect distinct\nretrieval paradigms: (1) text-only retrieval, which measures a model's ability\nto locate relevant document pages based solely on textual signals, and (2)\nmultimodal retrieval, which assesses retrieval performance when visual features\n(e.g., tables, charts, and layouts) are jointly leveraged alongside text. This\ndual-task evaluation reveals substantial performance gaps, particularly in\nmultimodal scenarios requiring cross-modal reasoning, even for state-of-the-art\nmodels. As a foundational resource, SDS KoPub VDR not only enables rigorous and\nfine-grained evaluation across textual and multimodal retrieval tasks but also\nprovides a clear roadmap for advancing multimodal AI in complex, real-world\ndocument intelligence.", "AI": {"tldr": "本文引入了SDS KoPub VDR，这是首个大规模公开的韩语公共文档视觉文档检索（VDR）基准，旨在解决现有基准在非英语语言和复杂结构文档方面的不足。该基准包含真实文档、人工验证的查询，并支持文本和多模态检索评估，揭示了当前模型在跨模态推理上的显著性能差距。", "motivation": "现有的视觉文档检索（VDR）基准主要忽略了非英语语言和官方出版物固有的结构复杂性，导致在处理真实世界复杂文档智能方面的评估不足。", "method": "研究者构建了SDS KoPub VDR基准，包含361份真实韩语公共文档（40,781页），涵盖复杂视觉元素。他们生成了600个查询-页面-答案三元组，通过多模态模型（如GPT-4o）初步生成并经过严格的人工验证和细化。查询按推理模态（文本、视觉、跨模态）分类。该基准用于评估两种检索任务：仅文本检索和多模态检索（结合文本和视觉特征）。", "result": "双任务评估结果显示，即使是最先进的模型，在多模态场景，特别是需要跨模态推理的任务中，仍存在显著的性能差距。", "conclusion": "SDS KoPub VDR作为一个基础资源，不仅能对文本和多模态检索任务进行严格细致的评估，还为在复杂真实世界文档智能领域推进多模态AI提供了清晰的路线图。"}}
{"id": "2511.04952", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04952", "abs": "https://arxiv.org/abs/2511.04952", "authors": ["Wei Shao", "Lingchao Zheng", "Pengyu Wang", "Peizhen Zheng", "Jun Li", "Yuwei Fan"], "title": "LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model", "comment": null, "summary": "Long context inference scenarios have become increasingly important for large\nlanguage models, yet they introduce significant computational latency. While\nprior research has optimized long-sequence inference through operators, model\narchitectures, and system frameworks, tokenization remains an overlooked\nbottleneck. Existing parallel tokenization methods accelerate processing\nthrough text segmentation and multi-process tokenization, but they suffer from\ninconsistent results due to boundary artifacts that occur after merging. To\naddress this, we propose LoPT, a novel Lossless Parallel Tokenization framework\nthat ensures output identical to standard sequential tokenization. Our approach\nemploys character-position-based matching and dynamic chunk length adjustment\nto align and merge tokenized segments accurately. Extensive experiments across\ndiverse long-text datasets demonstrate that LoPT achieves significant speedup\nwhile guaranteeing lossless tokenization. We also provide theoretical proof of\nconsistency and comprehensive analytical studies to validate the robustness of\nour method.", "AI": {"tldr": "该论文提出LoPT，一个无损并行分词框架，旨在解决大型语言模型长上下文推理中的分词瓶颈。LoPT通过基于字符位置的匹配和动态块长度调整，确保与标准顺序分词结果一致，并显著提高处理速度。", "motivation": "大型语言模型中的长上下文推理场景日益重要，但其引入了显著的计算延迟。尽管之前的研究优化了长序列推理，但分词仍然是一个被忽视的瓶颈。现有的并行分词方法因合并后的边界伪影而导致结果不一致。", "method": "我们提出了LoPT（无损并行分词）框架。该方法采用基于字符位置的匹配和动态块长度调整，以准确对齐和合并分词后的片段，从而确保输出与标准顺序分词完全一致。", "result": "在各种长文本数据集上的广泛实验表明，LoPT在保证无损分词（与顺序分词结果相同）的同时，实现了显著的加速。我们还提供了理论一致性证明和全面的分析研究来验证该方法的鲁棒性。", "conclusion": "LoPT成功解决了长上下文推理中的分词瓶颈，通过提供快速且无损的并行分词方案，提高了大型语言模型的效率和一致性。"}}
{"id": "2511.05397", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05397", "abs": "https://arxiv.org/abs/2511.05397", "authors": ["Samarth Chopra", "Alex McMoil", "Ben Carnovale", "Evan Sokolson", "Rajkumar Kubendran", "Samuel Dickerson"], "title": "EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation", "comment": "Submitted to ICRA 2026", "summary": "While Vision-Language-Action (VLA) models map visual inputs and language\ninstructions directly to robot actions, they often rely on costly hardware and\nstruggle in novel or cluttered scenes. We introduce EverydayVLA, a 6-DOF\nmanipulator that can be assembled for under $300, capable of modest payloads\nand workspace. A single unified model jointly outputs discrete and continuous\nactions, and our adaptive-horizon ensemble monitors motion uncertainty to\ntrigger on-the-fly re-planning for safe, reliable operation. On LIBERO,\nEverydayVLA matches state-of-the-art success rates, and in real-world tests it\noutperforms prior methods by 49% in-distribution and 34.9% out-of-distribution.\nBy combining a state-of-the-art VLA with cost-effective hardware, EverydayVLA\ndemocratizes access to a robotic foundation model and paves the way for\neconomical use in homes and research labs alike. Experiment videos and details:\nhttps://everydayvla.github.io/", "AI": {"tldr": "本文介绍了一种名为EverydayVLA的低成本（低于300美元）六自由度机械臂，它结合了先进的视觉-语言-动作（VLA）模型和经济硬件，实现了与现有技术相当的性能，并在真实世界中表现出色，旨在普及机器人基础模型的应用。", "motivation": "现有的视觉-语言-动作（VLA）模型通常依赖昂贵的硬件，并且在处理新颖或杂乱场景时表现不佳，这限制了其普及和经济应用。", "method": "研究人员推出了EverydayVLA，一个成本低于300美元、具有适度负载和工作空间的六自由度机械臂。该系统采用一个统一模型，同时输出离散和连续动作，并结合自适应规划范围的集成方法，通过监测运动不确定性来触发即时重新规划，以确保安全可靠的操作。", "result": "EverydayVLA在LIBERO基准测试中达到了与现有技术相当的成功率。在真实世界测试中，其在同分布任务中比现有方法高出49%，在异分布任务中高出34.9%。", "conclusion": "EverydayVLA通过将先进的VLA模型与经济高效的硬件相结合，降低了机器人基础模型的使用门槛，为在家庭和研究实验室中经济地应用机器人技术铺平了道路。"}}
{"id": "2511.04972", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04972", "abs": "https://arxiv.org/abs/2511.04972", "authors": ["Dylan Peek", "Matthew P. Skerritt", "Siddharth Pritam", "Stephan Chalup"], "title": "Challenges in 3D Data Synthesis for Training Neural Networks on Topological Features", "comment": "10 pages", "summary": "Topological Data Analysis (TDA) involves techniques of analyzing the\nunderlying structure and connectivity of data. However, traditional methods\nlike persistent homology can be computationally demanding, motivating the\ndevelopment of neural network-based estimators capable of reducing\ncomputational overhead and inference time. A key barrier to advancing these\nmethods is the lack of labeled 3D data with class distributions and diversity\ntailored specifically for supervised learning in TDA tasks. To address this, we\nintroduce a novel approach for systematically generating labeled 3D datasets\nusing the Repulsive Surface algorithm, allowing control over topological\ninvariants, such as hole count. The resulting dataset offers varied geometry\nwith topological labeling, making it suitable for training and benchmarking\nneural network estimators. This paper uses a synthetic 3D dataset to train a\ngenus estimator network, created using a 3D convolutional transformer\narchitecture. An observed decrease in accuracy as deformations increase\nhighlights the role of not just topological complexity, but also geometric\ncomplexity, when training generalized estimators. This dataset fills a gap in\nlabeled 3D datasets and generation for training and evaluating models and\ntechniques for TDA.", "AI": {"tldr": "该研究提出了一种使用Repulsive Surface算法系统生成带拓扑标签的3D数据集的新方法，以解决拓扑数据分析(TDA)中缺乏监督学习数据的挑战，并利用该数据集训练了一个3D卷积Transformer架构的属估计器。", "motivation": "传统的拓扑数据分析方法（如持久同源性）计算成本高昂，促使人们开发基于神经网络的估计器。然而，阻碍这些方法发展的一个关键障碍是缺乏专门为TDA任务量身定制的、带有类别分布和多样性的标注3D数据。", "method": "研究引入了一种新颖的方法，利用Repulsive Surface算法系统地生成带标注的3D数据集，该方法允许控制拓扑不变量（如孔洞数量）。然后，使用一个基于3D卷积Transformer架构的属估计器网络，利用该合成3D数据集进行训练。", "result": "生成的3D数据集具有多样化的几何形状和拓扑标签，适用于训练和基准测试神经网络估计器。观察到随着形变增加，估计器的准确性下降，这突出表明在训练泛化估计器时，不仅拓扑复杂性，几何复杂性也起着重要作用。", "conclusion": "该数据集填补了TDA模型和技术训练与评估中带标注3D数据集生成方面的空白。研究强调了在训练泛化估计器时，几何复杂性与拓扑复杂性同样重要。"}}
{"id": "2511.05275", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05275", "abs": "https://arxiv.org/abs/2511.05275", "authors": ["Hokyun Im", "Euijin Jeong", "Jianlong Fu", "Andrey Kolobov", "Youngwoon Lee"], "title": "TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models", "comment": "Project webpage : https://jellyho.github.io/TwinVLA/", "summary": "Vision-language-action models (VLAs) trained on large-scale robotic datasets\nhave demonstrated strong performance on manipulation tasks, including bimanual\ntasks. However, because most public datasets focus on single-arm\ndemonstrations, adapting VLAs for bimanual tasks typically requires substantial\nadditional bimanual data and fine-tuning. To address this challenge, we\nintroduce TwinVLA, a modular framework that composes two copies of a pretrained\nsingle-arm VLA into a coordinated bimanual VLA. Unlike monolithic\ncross-embodiment models trained on mixtures of single-arm and bimanual data,\nTwinVLA improves both data efficiency and performance by composing pretrained\nsingle-arm policies. Across diverse bimanual tasks in real-world and simulation\nsettings, TwinVLA outperforms a comparably-sized monolithic RDT-1B model\nwithout requiring any bimanual pretraining. Furthermore, it narrows the gap to\nstate-of-the-art model, $\\pi_0$ which rely on extensive proprietary bimanual\ndata and compute cost. These results establish our modular composition approach\nas a data-efficient and scalable path toward high-performance bimanual\nmanipulation, leveraging public single-arm data.", "AI": {"tldr": "TwinVLA是一个模块化框架，通过组合两个预训练的单臂视觉-语言-动作模型，实现了高效且高性能的双臂操作，无需额外的双臂数据预训练。", "motivation": "现有的视觉-语言-动作模型（VLAs）在单臂操作任务上表现良好，但适应双臂任务通常需要大量的额外双臂数据和微调，因为大多数公开数据集侧重于单臂演示。", "method": "引入TwinVLA，一个模块化框架，它将两个预训练的单臂VLA实例组合成一个协调的双臂VLA。这种方法与在单臂和双臂数据混合上训练的整体式模型不同。", "result": "在真实世界和模拟环境中的各种双臂任务中，TwinVLA的性能优于同等规模的整体式RDT-1B模型，且无需任何双臂预训练。此外，它缩小了与依赖大量专有双臂数据和计算成本的SOTA模型（如π₀）的差距。", "conclusion": "研究结果表明，模块化组合方法（TwinVLA）是实现高性能双臂操作的一种数据高效且可扩展的途径，它能够有效利用公开的单臂数据。"}}
{"id": "2511.05034", "categories": ["cs.CV", "cs.AI", "I.4.9; I.2.10"], "pdf": "https://arxiv.org/pdf/2511.05034", "abs": "https://arxiv.org/abs/2511.05034", "authors": ["Jing Jin", "Xu Liu", "Te Gao", "Zhihong Shi", "Yixiong Liang", "Ruiqing Zheng", "Hulin Kuang", "Min Zeng", "Shichao Kan"], "title": "Dynamic Residual Encoding with Slide-Level Contrastive Learning for End-to-End Whole Slide Image Representation", "comment": "8pages, 3figures, published to ACM Digital Library", "summary": "Whole Slide Image (WSI) representation is critical for cancer subtyping,\ncancer recognition and mutation prediction.Training an end-to-end WSI\nrepresentation model poses significant challenges, as a standard gigapixel\nslide can contain tens of thousands of image tiles, making it difficult to\ncompute gradients of all tiles in a single mini-batch due to current GPU\nlimitations. To address this challenge, we propose a method of dynamic residual\nencoding with slide-level contrastive learning (DRE-SLCL) for end-to-end WSI\nrepresentation. Our approach utilizes a memory bank to store the features of\ntiles across all WSIs in the dataset. During training, a mini-batch usually\ncontains multiple WSIs. For each WSI in the batch, a subset of tiles is\nrandomly sampled and their features are computed using a tile encoder. Then,\nadditional tile features from the same WSI are selected from the memory bank.\nThe representation of each individual WSI is generated using a residual\nencoding technique that incorporates both the sampled features and those\nretrieved from the memory bank. Finally, the slide-level contrastive loss is\ncomputed based on the representations and histopathology reports ofthe WSIs\nwithin the mini-batch. Experiments conducted over cancer subtyping, cancer\nrecognition, and mutation prediction tasks proved the effectiveness of the\nproposed DRE-SLCL method.", "AI": {"tldr": "本文提出了一种名为DRE-SLCL的动态残差编码结合幻灯片级对比学习方法，用于端到端全切片图像（WSI）表示学习，旨在解决巨像素图像因GPU限制难以处理所有切片的问题。", "motivation": "端到端WSI表示模型训练面临巨大挑战，因为一张标准的巨像素幻灯片包含数万个图像切片，受限于当前GPU内存，难以在单个mini-batch中计算所有切片的梯度。", "method": "所提出的DRE-SLCL方法利用一个内存库存储数据集中所有WSI的切片特征。在训练过程中，每个mini-batch包含多个WSI。对于批次中的每个WSI，随机采样一部分切片，并使用切片编码器计算其特征。同时，从内存库中选择同一WSI的其他切片特征。通过结合采样特征和从内存库中检索的特征，使用残差编码技术生成每个WSI的表示。最后，基于WSI的表示和组织病理学报告计算幻灯片级对比损失。", "result": "在癌症亚型分类、癌症识别和突变预测任务上进行的实验证明了所提出的DRE-SLCL方法的有效性。", "conclusion": "DRE-SLCL方法通过动态残差编码和幻灯片级对比学习，成功克服了GPU限制对端到端WSI表示学习的挑战，并在多项癌症相关任务中展现出优越性能。"}}
{"id": "2511.04926", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04926", "abs": "https://arxiv.org/abs/2511.04926", "authors": ["Shixiong Zhao", "Hideaki Takeda"], "title": "Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy", "comment": null, "summary": "Wikidata is currently the largest open knowledge graph on the web,\nencompassing over 120 million entities. It integrates data from various\ndomain-specific databases and imports a substantial amount of content from\nWikipedia, while also allowing users to freely edit its content. This openness\nhas positioned Wikidata as a central resource in knowledge graph research and\nhas enabled convenient knowledge access for users worldwide. However, its\nrelatively loose editorial policy has also led to a degree of taxonomic\ninconsistency. Building on prior work, this study proposes and applies a novel\nvalidation method to confirm the presence of classification errors,\nover-generalized subclass links, and redundant connections in specific domains\nof Wikidata. We further introduce a new evaluation criterion for determining\nwhether such issues warrant correction and develop a system that allows users\nto inspect the taxonomic relationships of arbitrary Wikidata\nentities-leveraging the platform's crowdsourced nature to its full potential.", "AI": {"tldr": "本文提出了一种新的验证方法和评估标准，用于识别并确认Wikidata中特定领域的分类错误、过度泛化的子类链接和冗余连接，并开发了一个系统，利用众包机制让用户检查和纠正分类关系。", "motivation": "Wikidata作为最大的开放知识图谱，虽然提供了便捷的知识访问，但其相对宽松的编辑政策导致了一定程度的分类不一致性，包括分类错误、过度泛化的子类链接和冗余连接。", "method": "本文提出并应用了一种新颖的验证方法来确认Wikidata特定领域中的分类错误、过度泛化的子类链接和冗余连接。此外，还引入了一个新的评估标准来判断这些问题是否需要修正，并开发了一个系统，允许用户检查任意Wikidata实体的分类关系，以充分利用其众包特性。", "result": "研究确认了Wikidata特定领域中存在分类错误、过度泛化的子类链接和冗余连接。论文提出了一种新的验证方法和评估标准，并开发了一个系统，使用户能够检查和潜在地纠正这些分类问题。", "conclusion": "通过提出新的验证方法、评估标准和用户检查系统，本文旨在解决Wikidata中的分类不一致性问题，并利用其众包特性来提高知识图谱的质量和准确性。"}}
{"id": "2511.05402", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05402", "abs": "https://arxiv.org/abs/2511.05402", "authors": ["Muhammad Saud Ul Hassan", "Derek Vasquez", "Hamza Asif", "Christian Hubicki"], "title": "Stable and Robust SLIP Model Control via Energy Conservation-Based Feedback Cancellation for Quadrupedal Applications", "comment": null, "summary": "In this paper, we present an energy-conservation based control architecture\nfor stable dynamic motion in quadruped robots. We model the robot as a\nSpring-loaded Inverted Pendulum (SLIP), a model well-suited to represent the\nbouncing motion characteristic of running gaits observed in various biological\nquadrupeds and bio-inspired robotic systems. The model permits leg-orientation\ncontrol during flight and leg-length control during stance, a design choice\ninspired by natural quadruped behaviors and prevalent in robotic quadruped\nsystems. Our control algorithm uses the reduced-order SLIP dynamics of the\nquadruped to track a stable parabolic spline during stance, which is calculated\nusing the principle of energy conservation. Through simulations based on the\ndesign specifications of an actual quadruped robot, Ghost Robotics Minitaur, we\ndemonstrate that our control algorithm generates stable bouncing gaits.\nAdditionally, we illustrate the robustness of our controller by showcasing its\nability to maintain stable bouncing even when faced with up to a 10% error in\nsensor measurements.", "AI": {"tldr": "本文提出了一种基于能量守恒的控制架构，用于四足机器人的稳定动态运动，通过SLIP模型实现稳定的弹跳步态，并在一款真实机器人设计上进行了仿真验证。", "motivation": "实现四足机器人稳定的动态运动，特别是模仿生物四足动物的奔跑步态中常见的弹跳运动特性。", "method": "将机器人建模为弹簧加载倒立摆（SLIP），该模型允许在飞行阶段控制腿部方向，在站立阶段控制腿部长度。控制算法利用四足机器人的降阶SLIP动力学，跟踪一个通过能量守恒原理计算出的稳定抛物线样条。", "result": "基于Ghost Robotics Minitaur四足机器人的设计规格进行的仿真表明，所提出的控制算法能够生成稳定的弹跳步态。此外，控制器在传感器测量误差高达10%的情况下仍能保持稳定的弹跳，展现了其鲁棒性。", "conclusion": "所提出的基于能量守恒的控制架构能够为四足机器人实现稳定的弹跳步态，并且在存在传感器误差时表现出良好的鲁棒性。"}}
{"id": "2511.04977", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.04977", "abs": "https://arxiv.org/abs/2511.04977", "authors": ["Heng Er Metilda Chee", "Jiayin Wang", "Zhiqiang Guo", "Weizhi Ma", "Min Zhang"], "title": "GSE: Evaluating Sticker Visual Semantic Similarity via a General Sticker Encoder", "comment": null, "summary": "Stickers have become a popular form of visual communication, yet\nunderstanding their semantic relationships remains challenging due to their\nhighly diverse and symbolic content. In this work, we formally {define the\nSticker Semantic Similarity task} and introduce {Triple-S}, the first benchmark\nfor this task, consisting of 905 human-annotated positive and negative sticker\npairs. Through extensive evaluation, we show that existing pretrained vision\nand multimodal models struggle to capture nuanced sticker semantics. To address\nthis, we propose the {General Sticker Encoder (GSE)}, a lightweight and\nversatile model that learns robust sticker embeddings using both Triple-S and\nadditional datasets. GSE achieves superior performance on unseen stickers, and\ndemonstrates strong results on downstream tasks such as emotion classification\nand sticker-to-sticker retrieval. By releasing both Triple-S and GSE, we\nprovide standardized evaluation tools and robust embeddings, enabling future\nresearch in sticker understanding, retrieval, and multimodal content\ngeneration. The Triple-S benchmark and GSE have been publicly released and are\navailable here.", "AI": {"tldr": "本文定义了贴纸语义相似性任务，推出了首个基准数据集Triple-S，并提出了轻量级模型GSE。GSE在贴纸语义理解和下游任务上表现出色，解决了现有模型对此类复杂内容理解不足的问题，为未来研究奠定了基础。", "motivation": "贴纸作为一种流行的视觉交流形式，其内容高度多样化和符号化，导致理解其语义关系极具挑战性。现有的预训练视觉和多模态模型难以捕捉贴纸细微的语义，因此需要专门的方法和工具来解决这个问题。", "method": "研究者正式定义了“贴纸语义相似性任务”，并引入了首个针对该任务的基准数据集“Triple-S”，该数据集包含905对人工标注的正负贴纸对。为解决现有模型的不足，本文提出了“通用贴纸编码器（GSE）”，这是一个轻量级且多功能的模型，通过结合Triple-S和额外数据集来学习鲁棒的贴纸嵌入。", "result": "评估结果表明，现有预训练的视觉和多模态模型难以捕捉细微的贴纸语义。相比之下，GSE在未见过的贴纸上取得了卓越的性能，并在情感分类和贴纸到贴纸检索等下游任务中也展现出强大的效果。", "conclusion": "通过发布Triple-S基准和GSE模型，本研究提供了标准化的评估工具和鲁棒的贴纸嵌入，这将极大地促进未来在贴纸理解、检索和多模态内容生成领域的研究。"}}
{"id": "2511.05040", "categories": ["cs.CL", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05040", "abs": "https://arxiv.org/abs/2511.05040", "authors": ["Mykyta Syromiatnikov", "Victoria Ruvinskaya"], "title": "UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian", "comment": "8 pages, 5 figures. XI International conference \"Informatics.\n  Culture. Technique.\" (2025)", "summary": "Evaluating the real capabilities of large language models in low-resource\nlanguages still represents a challenge, as many existing benchmarks focus on\nwidespread tasks translated from English or evaluate only simple language\nunderstanding. This paper introduces UA-Code-Bench, a new open-source benchmark\nestablished for a thorough evaluation of language models' code generation and\ncompetitive programming problem-solving abilities in Ukrainian. The benchmark\ncomprises 500 problems from the Eolymp platform, evenly distributed across five\ncomplexity levels from very easy to very hard. A diverse set of 13 leading\nproprietary and open-source models, generating Python solutions based on a\none-shot prompt, was evaluated via the dedicated Eolymp environment against\nhidden tests, ensuring code correctness. The obtained results reveal that even\ntop-performing models, such as OpenAI o3 and GPT-5, solve only half of the\nproblems, highlighting the challenge of code generation in low-resource natural\nlanguage. Furthermore, this research presents a comprehensive analysis of\nperformance across various difficulty levels, as well as an assessment of\nsolution uniqueness and computational efficiency, measured by both elapsed time\nand memory consumption of the generated solutions. In conclusion, this work\ndemonstrates the value of competitive programming benchmarks in evaluating\nlarge language models, especially in underrepresented languages. It also paves\nthe way for future research on multilingual code generation and\nreasoning-enhanced models. The benchmark, data parsing, preparation, code\ngeneration, and evaluation scripts are available at\nhttps://huggingface.co/datasets/NLPForUA/ua-code-bench.", "AI": {"tldr": "该研究引入了UA-Code-Bench，一个针对乌克兰语大语言模型代码生成和竞争性编程能力的新基准，并评估了13个领先模型，揭示了低资源语言代码生成的挑战。", "motivation": "现有基准主要关注从英语翻译的广泛任务或仅评估简单的语言理解，难以真实评估大语言模型在低资源语言中的实际能力，特别是在代码生成等复杂任务上。", "method": "引入了UA-Code-Bench，包含来自Eolymp平台的500个问题，分为五个难度级别。使用one-shot提示，评估了13个主流专有和开源模型生成Python解决方案的能力。通过Eolymp环境针对隐藏测试进行评估，并分析了不同难度下的性能、解决方案的独特性以及计算效率（时间消耗和内存消耗）。", "result": "即使是顶级模型（如OpenAI o3和GPT-5）也只能解决大约一半的问题，这突显了在低资源自然语言中进行代码生成的挑战。研究还提供了不同难度级别下的性能综合分析，以及解决方案独特性和计算效率的评估。", "conclusion": "竞争性编程基准在评估大语言模型（尤其是在代表性不足的语言中）方面具有重要价值。这项工作为未来在多语言代码生成和推理增强模型方面的研究铺平了道路。"}}
{"id": "2511.04989", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04989", "abs": "https://arxiv.org/abs/2511.04989", "authors": ["Ya Wang", "Guangzheng Zhu", "Cungen Cao", "Jingjing Li", "He Li", "Xin Huang"], "title": "Acquiring Common Chinese Emotional Events Using Large Language Model", "comment": "I am the second author (Guangzheng Zhu) and I am submitting this\n  paper on behalf of all co-authors", "summary": "Knowledge about emotional events is an important kind of knowledge which has\nbeen applied to improve the effectiveness of different applications. However,\nemotional events cannot be easily acquired, especially common or generalized\nemotional events that are context-independent. The goal of this paper is to\nobtain common emotional events in Chinese language such as \"win a prize\" and\n\"be criticized\". Our approach begins by collecting a comprehensive list of\nChinese emotional event indicators. Then, we generate emotional events by\nprompting a Chinese large language model (LLM) using these indicators. To\nensure the quality of these emotional events, we train a filter to discard\ninvalid generated results. We also classify these emotional events as being\npositive events and negative events using different techniques. Finally, we\nharvest a total of 102,218 high-quality common emotional events with sentiment\npolarity labels, which is the only large-scale commonsense knowledge base of\nemotional events in Chinese language. Intrinsic evaluation results show that\nthe proposed method in this paper can be effectively used to acquire common\nChinese emotional events. An extrinsic use case also demonstrates the strong\npotential of common emotional events in the field of emotion cause extraction\n(ECE). Related resources including emotional event indicators and emotional\nevents will be released after the publication of this paper.", "AI": {"tldr": "本文旨在构建一个大规模的中文通用情感事件知识库。通过收集情感事件指示词，利用大型语言模型生成事件，并训练过滤器进行质量控制和情感极性分类，最终获得了102,218个高质量的通用情感事件。", "motivation": "情感事件知识对于提高各种应用的有效性至关重要，但很难获取，特别是与上下文无关的常见或通用情感事件。", "method": "首先，收集全面的中文情感事件指示词。然后，利用这些指示词提示中文大型语言模型生成情感事件。为了确保质量，训练了一个过滤器来筛选无效结果。同时，采用不同技术将事件分类为积极或消极事件。", "result": "成功构建了包含102,218个带有情感极性标签的高质量通用情感事件的知识库，这是目前唯一大规模的中文情感事件常识知识库。内在评估证明了方法的有效性，而外在用例（情感原因抽取）也展示了这些事件的巨大潜力。", "conclusion": "所提出的方法能够有效地获取常见的中文情感事件。所构建的通用情感事件知识库具有很强的应用潜力，尤其在情感原因抽取等领域。"}}
{"id": "2511.05055", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05055", "abs": "https://arxiv.org/abs/2511.05055", "authors": ["Mingyu Sung", "Hyeonmin Choe", "Il-Min Kim", "Sangseok Yun", "Jae Mo Kang"], "title": "No Pose Estimation? No Problem: Pose-Agnostic and Instance-Aware Test-Time Adaptation for Monocular Depth Estimation", "comment": null, "summary": "Monocular depth estimation (MDE), inferring pixel-level depths in single RGB\nimages from a monocular camera, plays a crucial and pivotal role in a variety\nof AI applications demanding a three-dimensional (3D) topographical scene. In\nthe real-world scenarios, MDE models often need to be deployed in environments\nwith different conditions from those for training. Test-time (domain)\nadaptation (TTA) is one of the compelling and practical approaches to address\nthe issue. Although there have been notable advancements in TTA for MDE,\nparticularly in a self-supervised manner, existing methods are still\nineffective and problematic when applied to diverse and dynamic environments.\nTo break through this challenge, we propose a novel and high-performing TTA\nframework for MDE, named PITTA. Our approach incorporates two key innovative\nstrategies: (i) pose-agnostic TTA paradigm for MDE and (ii) instance-aware\nimage masking. Specifically, PITTA enables highly effective TTA on a pretrained\nMDE network in a pose-agnostic manner without resorting to any camera pose\ninformation. Besides, our instance-aware masking strategy extracts\ninstance-wise masks for dynamic objects (e.g., vehicles, pedestrians, etc.)\nfrom a segmentation mask produced by a pretrained panoptic segmentation\nnetwork, by removing static objects including background components. To further\nboost performance, we also present a simple yet effective edge extraction\nmethodology for the input image (i.e., a single monocular image) and depth map.\nExtensive experimental evaluations on DrivingStereo and Waymo datasets with\nvarying environmental conditions demonstrate that our proposed framework,\nPITTA, surpasses the existing state-of-the-art techniques with remarkable\nperformance improvements in MDE during TTA.", "AI": {"tldr": "本文提出了一种名为PITTA的新型高效测试时间适应（TTA）框架，用于单目深度估计（MDE），通过引入姿态无关TTA范式和实例感知图像掩码策略，显著提升了在多样动态环境下的MDE性能。", "motivation": "单目深度估计（MDE）模型在部署到与训练环境不同的真实世界场景时，现有测试时间适应（TTA）方法在处理多样化和动态环境方面仍然效率低下且存在问题，限制了其在需要三维地形场景的AI应用中的有效性。", "method": "本文提出了PITTA框架，包含两个关键创新策略：(i) MDE的姿态无关TTA范式，无需相机姿态信息即可进行高效TTA；(ii) 实例感知图像掩码，通过预训练全景分割网络提取动态物体（如车辆、行人）的实例级掩码，并移除静态物体和背景。此外，还引入了一种简单有效的输入图像和深度图边缘提取方法以进一步提升性能。", "result": "在DrivingStereo和Waymo数据集上进行的大量实验评估表明，PITTA框架在TTA期间的MDE性能显著优于现有的最先进技术，取得了显著的性能提升。", "conclusion": "PITTA是一种新颖且高性能的MDE测试时间适应框架，通过其独特的姿态无关TTA和实例感知掩码策略，有效解决了现有方法在多样动态环境中的局限性，并显著提升了MDE的性能。"}}
{"id": "2511.05018", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05018", "abs": "https://arxiv.org/abs/2511.05018", "authors": ["Prasoon Varshney", "Makesh Narsimhan Sreedhar", "Liwei Jiang", "Traian Rebedea", "Christopher Parisien"], "title": "Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies", "comment": "Accepted at the Multi-Turn Interactions workshop at the 39th\n  Conference on Neural Information Processing Systems (NeurIPS 2025)", "summary": "Large language models (LLMs) are typically aligned to a universal set of\nsafety and usage principles intended for broad public acceptability. Yet,\nreal-world applications of LLMs often take place within organizational\necosystems shaped by distinctive corporate policies, regulatory requirements,\nuse cases, brand guidelines, and ethical commitments. This reality highlights\nthe need for rigorous and comprehensive evaluation of LLMs with pluralistic\nalignment goals, an alignment paradigm that emphasizes adaptability to diverse\nuser values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE\n(PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs'\ncapacity to adhere to pluralistic alignment specifications in multi-turn,\ninteractive conversations. PBSUITE consists of (1) a diverse dataset of 300\nrealistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic\nevaluation framework for stress-testing model compliance with custom behavioral\nspecifications under adversarial conditions. Using PBSUITE, We find that\nleading open- and closed-source LLMs maintain robust adherence to behavioral\npolicies in single-turn settings (less than 4% failure rates), but their\ncompliance weakens substantially in multi-turn adversarial interactions (up to\n84% failure rates). These findings highlight that existing model alignment and\nsafety moderation methods fall short in coherently enforcing pluralistic\nbehavioral policies in real-world LLM interactions. Our work contributes both\nthe dataset and analytical framework to support future research toward robust\nand context-aware pluralistic alignment techniques.", "AI": {"tldr": "大型语言模型（LLM）在单轮交互中能很好地遵守行为政策，但在多轮对抗性交互中，其遵守多元化对齐规范的能力显著下降，现有对齐方法不足以应对现实世界的复杂场景。", "motivation": "LLM在实际应用中需要适应不同的组织政策、法规、品牌指南和伦理承诺，而不仅仅是通用的安全原则。这凸显了对LLM进行多元化对齐评估的迫切需求，以确保模型能适应多样化的用户价值观和需求。", "method": "本文提出了PLURALISTIC BEHAVIOR SUITE (PBSUITE)，一个动态评估套件，用于系统评估LLM在多轮交互中遵守多元化对齐规范的能力。PBSUITE包含：1) 一个由300个基于30个行业、真实的LLM行为政策组成的多样化数据集；2) 一个动态评估框架，用于在对抗性条件下压力测试模型对自定义行为规范的依从性。", "result": "研究发现，领先的开源和闭源LLM在单轮设置中对行为政策表现出强大的遵守能力（失败率低于4%），但在多轮对抗性交互中，其遵守能力大幅减弱（失败率高达84%）。", "conclusion": "这些发现表明，现有的模型对齐和安全审核方法在现实世界的LLM交互中，无法有效地执行多元化行为政策。本文贡献了数据集和分析框架，以支持未来对鲁棒和上下文感知的多元化对齐技术的研究。"}}
{"id": "2511.04970", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04970", "abs": "https://arxiv.org/abs/2511.04970", "authors": ["Jian Wang", "Yixing Yong", "Haixia Bi", "Lijun He", "Fan Li"], "title": "Learning Fourier shapes to probe the geometric world of deep neural networks", "comment": "20 pages, 5 figures", "summary": "While both shape and texture are fundamental to visual recognition, research\non deep neural networks (DNNs) has predominantly focused on the latter, leaving\ntheir geometric understanding poorly probed. Here, we show: first, that\noptimized shapes can act as potent semantic carriers, generating\nhigh-confidence classifications from inputs defined purely by their geometry;\nsecond, that they are high-fidelity interpretability tools that precisely\nisolate a model's salient regions; and third, that they constitute a new,\ngeneralizable adversarial paradigm capable of deceiving downstream visual\ntasks. This is achieved through an end-to-end differentiable framework that\nunifies a powerful Fourier series to parameterize arbitrary shapes, a winding\nnumber-based mapping to translate them into the pixel grid required by DNNs,\nand signal energy constraints that enhance optimization efficiency while\nensuring physically plausible shapes. Our work provides a versatile framework\nfor probing the geometric world of DNNs and opens new frontiers for challenging\nand understanding machine perception.", "AI": {"tldr": "本研究利用优化形状来探究深度神经网络（DNNs）的几何理解能力，发现形状既是强大的语义载体和解释工具，也是一种新型的对抗范式。", "motivation": "深度神经网络的研究主要集中在纹理上，而对几何理解的探索不足。研究人员希望深入了解DNNs如何处理和理解形状信息。", "method": "开发了一个端到端可微分的框架。该框架结合了强大的傅里叶级数来参数化任意形状，基于环绕数的映射方法将形状转换为DNN所需的像素网格，并利用信号能量约束来提高优化效率并确保形状的物理合理性。", "result": "研究结果表明：1) 优化形状可以作为强大的语义载体，仅通过几何定义就能生成高置信度的分类；2) 它们是高保真度的可解释性工具，能精确隔离模型关注的显著区域；3) 它们构成了一种新的、可泛化的对抗范式，能够欺骗下游视觉任务。", "conclusion": "这项工作提供了一个多功能的框架，用于探究DNNs的几何世界，并为挑战和理解机器感知开辟了新的前沿。"}}
{"id": "2511.05017", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05017", "abs": "https://arxiv.org/abs/2511.05017", "authors": ["Aakriti Agrawal", "Gouthaman KV", "Rohith Aralikatti", "Gauri Jagatap", "Jiaxin Yuan", "Vijay Kamarshi", "Andrea Fanelli", "Furong Huang"], "title": "Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings", "comment": null, "summary": "In this work, we identify an inherent bias in prevailing LVLM architectures\ntoward the language modality, largely resulting from the common practice of\nsimply appending visual embeddings to the input text sequence. To address this,\nwe propose a simple yet effective method that refines textual embeddings by\nintegrating average-pooled visual features. Our approach demonstrably improves\nvisual grounding and significantly reduces hallucinations on established\nbenchmarks. While average pooling offers a straightforward, robust, and\nefficient means of incorporating visual information, we believe that more\nsophisticated fusion methods could further enhance visual grounding and\ncross-modal alignment. Given that the primary focus of this work is to\nhighlight the modality imbalance and its impact on hallucinations -- and to\nshow that refining textual embeddings with visual information mitigates this\nissue -- we leave exploration of advanced fusion strategies for future work.", "AI": {"tldr": "本文发现现有LVLM架构存在固有的语言模态偏见，导致幻觉。提出通过平均池化视觉特征来精炼文本嵌入，有效改善视觉定位并减少幻觉。", "motivation": "现有大型视觉语言模型（LVLM）架构存在对语言模态的固有偏见，这主要是因为常见的做法是简单地将视觉嵌入附加到输入文本序列上，导致视觉定位不佳和幻觉问题。", "method": "提出了一种简单而有效的方法：通过整合平均池化的视觉特征来精炼文本嵌入。该方法旨在平衡模态信息，增强视觉信息在文本理解中的作用。", "result": "实验结果表明，该方法显著改善了视觉定位能力，并在现有基准测试中显著减少了幻觉现象。", "conclusion": "研究表明，通过视觉信息精炼文本嵌入可以有效缓解LVLM中的模态不平衡问题及其对幻觉的影响。尽管平均池化是简单有效的方式，未来工作可以探索更复杂的融合方法以进一步增强视觉定位和跨模态对齐。"}}
{"id": "2511.05073", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05073", "abs": "https://arxiv.org/abs/2511.05073", "authors": ["Jun Li", "Yanwei Xu", "Keran Li", "Xiaoli Zhang"], "title": "Deep learning models are vulnerable, but adversarial examples are even more vulnerable", "comment": "25 pages,12 figures", "summary": "Understanding intrinsic differences between adversarial examples and clean\nsamples is key to enhancing DNN robustness and detection against adversarial\nattacks. This study first empirically finds that image-based adversarial\nexamples are notably sensitive to occlusion. Controlled experiments on CIFAR-10\nused nine canonical attacks (e.g., FGSM, PGD) to generate adversarial examples,\npaired with original samples for evaluation. We introduce Sliding Mask\nConfidence Entropy (SMCE) to quantify model confidence fluctuation under\nocclusion. Using 1800+ test images, SMCE calculations supported by Mask Entropy\nField Maps and statistical distributions show adversarial examples have\nsignificantly higher confidence volatility under occlusion than originals.\nBased on this, we propose Sliding Window Mask-based Adversarial Example\nDetection (SWM-AED), which avoids catastrophic overfitting of conventional\nadversarial training. Evaluations across classifiers and attacks on CIFAR-10\ndemonstrate robust performance, with accuracy over 62% in most cases and up to\n96.5%.", "AI": {"tldr": "本研究发现对抗样本对遮挡高度敏感，并引入滑动掩码置信度熵（SMCE）来量化模型置信度波动。基于此，提出了一种新的检测方法SWM-AED，有效避免了对抗训练的灾难性过拟合，并展现出强大的对抗样本检测性能。", "motivation": "理解对抗样本和干净样本之间的内在差异是提高深度神经网络（DNN）鲁棒性及对抗攻击检测能力的关键。", "method": "研究首先通过实证发现图像对抗样本对遮挡敏感。在CIFAR-10上使用九种典型攻击生成对抗样本进行受控实验，并引入滑动掩码置信度熵（SMCE）来量化模型在遮挡下的置信度波动。通过掩码熵场图和统计分布支持的SMCE计算，最终提出基于滑动窗口掩码的对抗样本检测（SWM-AED）方法。", "result": "结果显示，对抗样本在遮挡下表现出比原始样本显著更高的置信度波动。所提出的SWM-AED方法在不同分类器和攻击下表现出鲁棒的性能，在大多数情况下检测准确率超过62%，最高可达96.5%。", "conclusion": "对抗样本对遮挡具有显著的敏感性，这一特性可用于开发有效的对抗样本检测方法。SWM-AED利用此特性，成功避免了传统对抗训练的灾难性过拟合问题，实现了高效的对抗样本检测。"}}
{"id": "2511.05057", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05057", "abs": "https://arxiv.org/abs/2511.05057", "authors": ["Yuanxiang Huangfu", "Chaochao Wang", "Weilei Wang"], "title": "Role-SynthCLIP: A Role Play Driven Diverse Synthetic Data Approach", "comment": null, "summary": "The effectiveness of Contrastive Language-Image Pre-training (CLIP) models\ncritically depends on the semantic diversity and quality of their training\ndata. However, while existing synthetic data generation methods primarily focus\non increasing data volume, such emphasis often leads to limited semantic\ndiversity and redundant or shallow captions. To address this limitation, we\npropose Role-SynthCLIP, a novel data synthesis framework that leverages\nmulti-perspective role-playing prompts (e.g., a compositional analyst, an\ninterpreter of image context) to guide Multimodal Large Language Models (MLLMs)\nin generating semantically diverse captions from distinct viewpoints. This\nmechanism enhances the semantic diversity and fine-grained image-text alignment\nof synthetic pairs, thereby improving caption expressiveness and accuracy while\nkeeping the total number of image-text pairs unchanged. Experimental results\ndemonstrate the effectiveness and efficiency of our method. A CLIP-B/16 model\ntrained on only 1 million Role-SynthCLIP pairs achieves a Recall@1 of 64.1% on\nthe MS COCO validation set, surpassing the best existing synthetic data\nbaseline (trained on 5M pairs) by 2.8 percentage points. The code and trained\nmodels are released at https://github.com/huangfu170/Role-SynthCLIP.", "AI": {"tldr": "本文提出Role-SynthCLIP框架，利用多视角角色扮演提示指导多模态大语言模型（MLLMs）生成语义多样化且细粒度的图像-文本对，以提高CLIP模型的训练数据质量和效率。", "motivation": "现有对比语言-图像预训练（CLIP）模型的有效性严重依赖于训练数据的语义多样性和质量。然而，目前的合成数据生成方法主要侧重于增加数据量，这往往导致语义多样性有限和描述冗余或肤浅，从而限制了CLIP的性能。", "method": "Role-SynthCLIP通过利用多视角角色扮演提示（例如，组合分析师、图像上下文解释者）来引导多模态大语言模型（MLLMs）从不同角度生成语义多样化的描述。这种机制在不改变图像-文本对总数的情况下，增强了合成对的语义多样性和细粒度的图像-文本对齐，从而提高了描述的表达性和准确性。", "result": "实验结果表明，该方法有效且高效。一个使用仅100万Role-SynthCLIP对训练的CLIP-B/16模型在MS COCO验证集上取得了64.1%的Recall@1，比现有最佳合成数据基线（使用500万对训练）高出2.8个百分点。", "conclusion": "Role-SynthCLIP通过引入多视角角色扮演提示生成语义多样化且高质量的图像-文本对，有效解决了现有合成数据方法语义多样性不足的问题，显著提升了CLIP模型的训练效果和数据利用效率。"}}
{"id": "2511.05038", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05038", "abs": "https://arxiv.org/abs/2511.05038", "authors": ["Zhengxuan Li", "Qinhui Yang", "Yiyu Zhuang", "Chuan Guo", "Xinxin Zuo", "Xiaoxiao Long", "Yao Yao", "Xun Cao", "Qiu Shen", "Hao Zhu"], "title": "Pressure2Motion: Hierarchical Motion Synthesis from Ground Pressure with Text Guidance", "comment": null, "summary": "We present Pressure2Motion, a novel motion capture algorithm that synthesizes\nhuman motion from a ground pressure sequence and text prompt. It eliminates the\nneed for specialized lighting setups, cameras, or wearable devices, making it\nsuitable for privacy-preserving, low-light, and low-cost motion capture\nscenarios. Such a task is severely ill-posed due to the indeterminate nature of\nthe pressure signals to full-body motion. To address this issue, we introduce\nPressure2Motion, a generative model that leverages pressure features as input\nand utilizes a text prompt as a high-level guiding constraint. Specifically,\nour model utilizes a dual-level feature extractor that accurately interprets\npressure data, followed by a hierarchical diffusion model that discerns\nbroad-scale movement trajectories and subtle posture adjustments. Both the\nphysical cues gained from the pressure sequence and the semantic guidance\nderived from descriptive texts are leveraged to guide the motion generation\nwith precision. To the best of our knowledge, Pressure2Motion is a pioneering\nwork in leveraging both pressure data and linguistic priors for motion\ngeneration, and the established MPL benchmark is the first benchmark for this\ntask. Experiments show our method generates high-fidelity, physically plausible\nmotions, establishing a new state-of-the-art for this task. The codes and\nbenchmarks will be publicly released upon publication.", "AI": {"tldr": "Pressure2Motion是一种新型动作捕捉算法，通过地面压力序列和文本提示合成人体运动，适用于低成本、隐私保护和弱光环境。", "motivation": "传统的动作捕捉方法需要专业的灯光、相机或可穿戴设备，成本高昂且存在隐私问题。从不确定的压力信号推断全身运动是一个严重病态的问题，现有方法难以解决。", "method": "本文提出了Pressure2Motion，一个利用压力特征作为输入、文本提示作为高级指导约束的生成模型。该模型包含一个双层特征提取器用于精确解释压力数据，以及一个分层扩散模型用于识别大尺度运动轨迹和细微姿态调整。通过结合压力序列的物理线索和描述性文本的语义指导，实现精确的运动生成。", "result": "实验证明，Pressure2Motion能够生成高保真、物理上合理的运动，在该任务上建立了新的最先进水平（SOTA）。它是首个结合压力数据和语言先验进行运动生成的工作，并建立了该任务的第一个基准MPL。", "conclusion": "Pressure2Motion提供了一种无需专用设备、低成本、保护隐私的新型动作捕捉解决方案。它通过结合物理压力数据和语义文本指导，有效解决了从压力信号生成全身运动的病态问题，并在该新兴领域树立了新的基准和SOTA。"}}
{"id": "2511.05150", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05150", "abs": "https://arxiv.org/abs/2511.05150", "authors": ["Jingsong Liu", "Han Li", "Nassir Navab", "Peter J. Schüffler"], "title": "From Linear Probing to Joint-Weighted Token Hierarchy: A Foundation Model Bridging Global and Cellular Representations in Biomarker Detection", "comment": null, "summary": "AI-based biomarkers can infer molecular features directly from hematoxylin &\neosin (H&E) slides, yet most pathology foundation models (PFMs) rely on global\npatch-level embeddings and overlook cell-level morphology. We present a PFM\nmodel, JWTH (Joint-Weighted Token Hierarchy), which integrates large-scale\nself-supervised pretraining with cell-centric post-tuning and attention pooling\nto fuse local and global tokens. Across four tasks involving four biomarkers\nand eight cohorts, JWTH achieves up to 8.3% higher balanced accuracy and 1.2%\naverage improvement over prior PFMs, advancing interpretable and robust\nAI-based biomarker detection in digital pathology.", "AI": {"tldr": "JWTH是一个新的病理学基础模型（PFM），通过结合大规模自监督预训练、以细胞为中心的后调优和注意力池化来整合局部和全局特征，显著提高了AI驱动的生物标志物检测在数字病理学中的准确性和可解释性。", "motivation": "现有的病理学基础模型（PFM）主要依赖全局补丁级嵌入，而忽视了细胞级别的形态学信息，这限制了AI从H&E切片直接推断分子特征的准确性和可解释性。", "method": "本文提出了JWTH（Joint-Weighted Token Hierarchy）模型，它结合了大规模自监督预训练、以细胞为中心的后调优和注意力池化技术，以有效地融合局部（细胞级）和全局（补丁级）的特征标记。", "result": "在涉及四种生物标志物、四项任务和八个队列的测试中，JWTH模型实现了高达8.3%的平衡准确率提升，并比之前的PFM模型平均提高了1.2%。", "conclusion": "JWTH模型通过整合细胞级和全局特征，显著提升了数字病理学中AI驱动生物标志物检测的准确性、可解释性和鲁棒性。"}}
{"id": "2511.05044", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05044", "abs": "https://arxiv.org/abs/2511.05044", "authors": ["Xinyu Chen", "Yiran Wang", "Gaoyang Pang", "Jiafu Hao", "Chentao Yue", "Luping Zhou", "Yonghui Li"], "title": "Medical Referring Image Segmentation via Next-Token Mask Prediction", "comment": "This work has been submitted to the IEEE Transactions on Medical\n  Imaging for possible publication", "summary": "Medical Referring Image Segmentation (MRIS) involves segmenting target\nregions in medical images based on natural language descriptions. While\nachieving promising results, recent approaches usually involve complex design\nof multimodal fusion or multi-stage decoders. In this work, we propose\nNTP-MRISeg, a novel framework that reformulates MRIS as an autoregressive\nnext-token prediction task over a unified multimodal sequence of tokenized\nimage, text, and mask representations. This formulation streamlines model\ndesign by eliminating the need for modality-specific fusion and external\nsegmentation models, supports a unified architecture for end-to-end training.\nIt also enables the use of pretrained tokenizers from emerging large-scale\nmultimodal models, enhancing generalization and adaptability. More importantly,\nto address challenges under this formulation-such as exposure bias, long-tail\ntoken distributions, and fine-grained lesion edges-we propose three novel\nstrategies: (1) a Next-k Token Prediction (NkTP) scheme to reduce cumulative\nprediction errors, (2) Token-level Contrastive Learning (TCL) to enhance\nboundary sensitivity and mitigate long-tail distribution effects, and (3) a\nmemory-based Hard Error Token (HET) optimization strategy that emphasizes\ndifficult tokens during training. Extensive experiments on the QaTa-COV19 and\nMosMedData+ datasets demonstrate that NTP-MRISeg achieves new state-of-the-art\nperformance, offering a streamlined and effective alternative to traditional\nMRIS pipelines.", "AI": {"tldr": "NTP-MRISeg是一个新颖的框架，将医学指代图像分割（MRIS）重构为统一多模态序列上的自回归下一词元预测任务。它简化了模型设计，并引入了三种策略（NkTP、TCL、HET）来解决预测误差、长尾分布和边界敏感性问题，在MRIS任务上达到了最先进的性能。", "motivation": "现有的医学指代图像分割（MRIS）方法通常涉及复杂的多模态融合或多阶段解码器设计。此外，在将MRIS重构为词元预测任务时，面临曝光偏差、长尾词元分布和精细病灶边缘处理等挑战。", "method": "本文提出了NTP-MRISeg框架，将MRIS重构为对统一的多模态序列（包括词元化的图像、文本和掩码表示）进行自回归下一词元预测。该方法简化了模型设计，实现了端到端训练，并支持使用预训练的词元分析器。为解决挑战，提出了三种策略：1) Next-k Token Prediction (NkTP) 方案以减少累积预测误差；2) Token-level Contrastive Learning (TCL) 以增强边界敏感性并缓解长尾分布效应；3) 基于记忆的Hard Error Token (HET) 优化策略以强调训练中的难点词元。", "result": "在QaTa-COV19和MosMedData+数据集上的大量实验表明，NTP-MRISeg取得了新的最先进（SOTA）性能。", "conclusion": "NTP-MRISeg为传统的MRIS流程提供了一个简化且有效的替代方案，并通过其创新的框架和优化策略实现了卓越的性能。"}}
{"id": "2511.05085", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05085", "abs": "https://arxiv.org/abs/2511.05085", "authors": ["Grigory Kovalev", "Mikhail Tikhomirov"], "title": "Iterative Layer-wise Distillation for Efficient Compression of Large Language Models", "comment": null, "summary": "This work investigates distillation methods for large language models (LLMs)\nwith the goal of developing compact models that preserve high performance.\nSeveral existing approaches are reviewed, with a discussion of their respective\nstrengths and limitations. An improved method based on the ShortGPT approach\nhas been developed, building upon the idea of incorporating iterative\nevaluation of layer importance. At each step, importance is assessed by\nmeasuring performance degradation when individual layers are removed, using a\nset of representative datasets. This process is combined with further training\nusing a joint loss function based on KL divergence and mean squared error.\nExperiments on the Qwen2.5-3B model show that the number of layers can be\nreduced from 36 to 28 (resulting in a 2.47 billion parameter model) with only a\n9.7% quality loss, and to 24 layers with an 18% loss. The findings suggest that\nthe middle transformer layers contribute less to inference, underscoring the\npotential of the proposed method for creating efficient models. The results\ndemonstrate the effectiveness of iterative distillation and fine-tuning, making\nthe approach suitable for deployment in resource-limited settings.", "AI": {"tldr": "本研究提出了一种改进的基于ShortGPT的大语言模型蒸馏方法，通过迭代评估层重要性并结合KL散度和均方误差的联合损失函数进行训练，成功将Qwen2.5-3B模型的层数从36减少到28（参数量24.7亿），仅带来9.7%的质量损失，适用于资源受限环境。", "motivation": "开发紧凑且能保持高性能的大语言模型（LLMs），以满足在资源受限环境中部署高效模型的需求。", "method": "回顾了现有蒸馏方法，并提出了一种改进的ShortGPT方法。该方法通过迭代评估层重要性，具体为在移除单个层后，使用代表性数据集测量性能下降来评估重要性。此过程与使用基于KL散度和均方误差的联合损失函数进行的进一步训练相结合。", "result": "在Qwen2.5-3B模型上的实验表明，层数可以从36减少到28（产生24.7亿参数模型），仅有9.7%的质量损失；减少到24层时，质量损失为18%。研究发现中间的Transformer层对推理的贡献较小。", "conclusion": "所提出的迭代蒸馏和微调方法对于创建高效模型是有效的，通过减少层数同时控制质量损失，使其适用于在资源受限环境中部署。"}}
{"id": "2511.05250", "categories": ["cs.CV", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.05250", "abs": "https://arxiv.org/abs/2511.05250", "authors": ["Mohamed Sanim Akremi", "Rim Slama", "Hedi Tabia"], "title": "Accurate online action and gesture recognition system using detectors and Deep SPD Siamese Networks", "comment": null, "summary": "Online continuous motion recognition is a hot topic of research since it is\nmore practical in real life application cases. Recently, Skeleton-based\napproaches have become increasingly popular, demonstrating the power of using\nsuch 3D temporal data. However, most of these works have focused on\nsegment-based recognition and are not suitable for the online scenarios. In\nthis paper, we propose an online recognition system for skeleton sequence\nstreaming composed from two main components: a detector and a classifier, which\nuse a Semi-Positive Definite (SPD) matrix representation and a Siamese network.\nThe powerful statistical representations for the skeletal data given by the SPD\nmatrices and the learning of their semantic similarity by the Siamese network\nenable the detector to predict time intervals of the motions throughout an\nunsegmented sequence. In addition, they ensure the classifier capability to\nrecognize the motion in each predicted interval. The proposed detector is\nflexible and able to identify the kinetic state continuously. We conduct\nextensive experiments on both hand gesture and body action recognition\nbenchmarks to prove the accuracy of our online recognition system which in most\ncases outperforms state-of-the-art performances.", "AI": {"tldr": "本文提出一个基于骨骼序列流的在线连续动作识别系统，包含检测器和分类器，利用半正定（SPD）矩阵和孪生网络，在未分段序列中准确识别动作，并超越了现有技术水平。", "motivation": "在线连续动作识别在实际应用中更具实用性，但现有基于骨骼的方法大多侧重于分段识别，不适用于在线场景。", "method": "该系统由一个检测器和一个分类器组成。它使用半正定（SPD）矩阵来表示骨骼数据，并通过孪生网络学习其语义相似性。检测器能够预测未分段序列中的动作时间间隔，而分类器则在这些预测间隔内识别动作。该检测器具有灵活性，能够持续识别运动状态。", "result": "在手势识别和身体动作识别基准测试上进行了广泛实验，证明了该在线识别系统的准确性，并且在大多数情况下优于现有最先进的性能。", "conclusion": "所提出的在线连续动作识别系统，通过结合SPD矩阵表示和孪生网络，能够有效地从骨骼序列流中检测和识别动作，并在准确性方面超越了现有技术。"}}
{"id": "2511.05229", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05229", "abs": "https://arxiv.org/abs/2511.05229", "authors": ["Mengqi Guo", "Bo Xu", "Yanyan Li", "Gim Hee Lee"], "title": "4D3R: Motion-Aware Neural Reconstruction and Rendering of Dynamic Scenes from Monocular Videos", "comment": "17 pages, 5 figures", "summary": "Novel view synthesis from monocular videos of dynamic scenes with unknown\ncamera poses remains a fundamental challenge in computer vision and graphics.\nWhile recent advances in 3D representations such as Neural Radiance Fields\n(NeRF) and 3D Gaussian Splatting (3DGS) have shown promising results for static\nscenes, they struggle with dynamic content and typically rely on pre-computed\ncamera poses. We present 4D3R, a pose-free dynamic neural rendering framework\nthat decouples static and dynamic components through a two-stage approach. Our\nmethod first leverages 3D foundational models for initial pose and geometry\nestimation, followed by motion-aware refinement. 4D3R introduces two key\ntechnical innovations: (1) a motion-aware bundle adjustment (MA-BA) module that\ncombines transformer-based learned priors with SAM2 for robust dynamic object\nsegmentation, enabling more accurate camera pose refinement; and (2) an\nefficient Motion-Aware Gaussian Splatting (MA-GS) representation that uses\ncontrol points with a deformation field MLP and linear blend skinning to model\ndynamic motion, significantly reducing computational cost while maintaining\nhigh-quality reconstruction. Extensive experiments on real-world dynamic\ndatasets demonstrate that our approach achieves up to 1.8dB PSNR improvement\nover state-of-the-art methods, particularly in challenging scenarios with large\ndynamic objects, while reducing computational requirements by 5x compared to\nprevious dynamic scene representations.", "AI": {"tldr": "4D3R是一种无需相机姿态的动态神经渲染框架，通过解耦静态和动态组件，并引入运动感知束调整和高效运动感知高斯溅射，实现了从单目视频对动态场景进行高质量新视角合成。", "motivation": "从单目视频对动态场景进行新视角合成，且相机姿态未知，是一个基本挑战。尽管NeRF和3DGS在静态场景中表现出色，但它们难以处理动态内容，并通常依赖预计算的相机姿态。", "method": "本文提出了4D3R框架，采用两阶段方法解耦静态和动态组件。首先利用3D基础模型进行初始姿态和几何估计，然后进行运动感知细化。关键创新包括：1) 运动感知束调整（MA-BA）模块，结合基于Transformer的学习先验和SAM2进行动态对象分割，以实现更准确的相机姿态细化；2) 高效的运动感知高斯溅射（MA-GS）表示，使用控制点、变形场MLP和线性混合蒙皮来建模动态运动，显著降低计算成本。", "result": "在真实世界动态数据集上的实验表明，本文方法比现有最先进方法提高了高达1.8dB的PSNR，尤其在具有大型动态对象的挑战性场景中表现突出，同时与之前的动态场景表示相比，计算需求降低了5倍。", "conclusion": "4D3R在动态场景新视角合成方面取得了显著的性能提升，尤其是在处理大型动态对象和减少计算成本方面，超越了现有最先进的方法，为动态神经渲染领域提供了高效且高质量的解决方案。"}}
{"id": "2511.05059", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05059", "abs": "https://arxiv.org/abs/2511.05059", "authors": ["Mingyu Sheng", "Jianan Fan", "Dongnan Liu", "Guoyan Zheng", "Ron Kikinis", "Weidong Cai"], "title": "SurgiATM: A Physics-Guided Plug-and-Play Model for Deep Learning-Based Smoke Removal in Laparoscopic Surgery", "comment": "10 pages, 5 figures, 6 tables. Code available at\n  https://github.com/MingyuShengSMY/SurgiATM", "summary": "During laparoscopic surgery, smoke generated by tissue cauterization can\nsignificantly degrade the visual quality of endoscopic frames, increasing the\nrisk of surgical errors and hindering both clinical decision-making and\ncomputer-assisted visual analysis. Consequently, removing surgical smoke is\ncritical to ensuring patient safety and maintaining operative efficiency. In\nthis study, we propose the Surgical Atmospheric Model (SurgiATM) for surgical\nsmoke removal. SurgiATM statistically bridges a physics-based atmospheric model\nand data-driven deep learning models, combining the superior generalizability\nof the former with the high accuracy of the latter. Furthermore, SurgiATM is\ndesigned as a lightweight, plug-and-play module that can be seamlessly\nintegrated into diverse surgical desmoking architectures to enhance their\naccuracy and stability, better meeting clinical requirements. It introduces\nonly two hyperparameters and no additional trainable weights, preserving the\noriginal network architecture with minimal computational and modification\noverhead. We conduct extensive experiments on three public surgical datasets\nwith ten desmoking methods, involving multiple network architectures and\ncovering diverse procedures, including cholecystectomy, partial nephrectomy,\nand diaphragm dissection. The results demonstrate that incorporating SurgiATM\ncommonly reduces the restoration errors of existing models and relatively\nenhances their generalizability, without adding any trainable layers or\nweights. This highlights the convenience, low cost, effectiveness, and\ngeneralizability of the proposed method. The code for SurgiATM is released at\nhttps://github.com/MingyuShengSMY/SurgiATM.", "AI": {"tldr": "本文提出SurgiATM模型，通过结合物理大气模型和数据驱动深度学习，以轻量级、即插即用的方式有效去除手术烟雾，提高现有去烟雾模型的准确性和泛化性。", "motivation": "腹腔镜手术中，组织烧灼产生的烟雾会严重降低内窥镜图像质量，增加手术风险，阻碍临床决策和计算机辅助分析。因此，去除手术烟雾对于确保患者安全和维持手术效率至关重要。", "method": "本文提出手术大气模型（SurgiATM），它统计性地连接了基于物理的大气模型和数据驱动的深度学习模型，结合了前者卓越的泛化能力和后者的高精度。SurgiATM被设计为一个轻量级、即插即用的模块，可无缝集成到各种手术去烟雾架构中，仅引入两个超参数，没有额外的可训练权重，最大程度保留了原始网络架构。", "result": "在三个公共手术数据集上，对十种去烟雾方法进行了广泛实验，结果表明，整合SurgiATM通常能减少现有模型的恢复误差，相对增强其泛化能力，且无需添加任何可训练层或权重。这突出了所提方法的便捷性、低成本、有效性和泛化性。", "conclusion": "SurgiATM模型通过结合物理和深度学习方法，提供了一种方便、低成本、有效且泛化能力强的手术烟雾去除方案，能够显著提升现有去烟雾模型的性能，更好地满足临床需求。"}}
{"id": "2511.05095", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05095", "abs": "https://arxiv.org/abs/2511.05095", "authors": ["Fuyang Liu", "Jiaqi Xu", "Xiaowei Hu"], "title": "Real-World Adverse Weather Image Restoration via Dual-Level Reinforcement Learning with High-Quality Cold Start", "comment": "Accepted by NeurIPS 2025", "summary": "Adverse weather severely impairs real-world visual perception, while existing\nvision models trained on synthetic data with fixed parameters struggle to\ngeneralize to complex degradations. To address this, we first construct\nHFLS-Weather, a physics-driven, high-fidelity dataset that simulates diverse\nweather phenomena, and then design a dual-level reinforcement learning\nframework initialized with HFLS-Weather for cold-start training. Within this\nframework, at the local level, weather-specific restoration models are refined\nthrough perturbation-driven image quality optimization, enabling reward-based\nlearning without paired supervision; at the global level, a meta-controller\ndynamically orchestrates model selection and execution order according to scene\ndegradation. This framework enables continuous adaptation to real-world\nconditions and achieves state-of-the-art performance across a wide range of\nadverse weather scenarios. Code is available at\nhttps://github.com/xxclfy/AgentRL-Real-Weather", "AI": {"tldr": "本文构建了一个物理驱动的高保真天气数据集HFLS-Weather，并设计了一个双层强化学习框架，用于在恶劣天气条件下持续适应和优化视觉感知模型，无需成对监督即可实现最先进的性能。", "motivation": "现有视觉模型在合成数据上训练且参数固定，难以泛化到真实世界中复杂的恶劣天气造成的视觉退化，严重影响了实际视觉感知。", "method": "首先，构建了物理驱动的高保真天气数据集HFLS-Weather。然后，设计了一个双层强化学习框架进行冷启动训练：局部层面，通过扰动驱动的图像质量优化（基于奖励学习，无需成对监督）来精炼特定天气的恢复模型；全局层面，元控制器根据场景退化动态协调模型的选择和执行顺序。", "result": "该框架能够持续适应真实世界条件，并在各种恶劣天气场景中实现了最先进的性能。", "conclusion": "所提出的HFLS-Weather数据集和双层强化学习框架有效解决了恶劣天气下的视觉感知挑战，通过无监督的自适应学习机制，实现了卓越的图像恢复效果和对真实世界条件的持续适应性。"}}
{"id": "2511.05064", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05064", "abs": "https://arxiv.org/abs/2511.05064", "authors": ["Jinglin Liang", "Jin Zhong", "Shuangping Huang", "Yunqing Hu", "Huiyuan Zhang", "Huifang Li", "Lixin Fan", "Hanlin Gu"], "title": "Order-Level Attention Similarity Across Language Models: A Latent Commonality", "comment": "Accepted by NeurIPS 2025", "summary": "In this paper, we explore an important yet previously neglected question: Do\ncontext aggregation patterns across Language Models (LMs) share commonalities?\nWhile some works have investigated context aggregation or attention weights in\nLMs, they typically focus on individual models or attention heads, lacking a\nsystematic analysis across multiple LMs to explore their commonalities. In\ncontrast, we focus on the commonalities among LMs, which can deepen our\nunderstanding of LMs and even facilitate cross-model knowledge transfer. In\nthis work, we introduce the Order-Level Attention (OLA) derived from the\norder-wise decomposition of Attention Rollout and reveal that the OLA at the\nsame order across LMs exhibits significant similarities. Furthermore, we\ndiscover an implicit mapping between OLA and syntactic knowledge. Based on\nthese two findings, we propose the Transferable OLA Adapter (TOA), a\ntraining-free cross-LM adapter transfer method. Specifically, we treat the OLA\nas a unified syntactic feature representation and train an adapter that takes\nOLA as input. Due to the similarities in OLA across LMs, the adapter\ngeneralizes to unseen LMs without requiring any parameter updates. Extensive\nexperiments demonstrate that TOA's cross-LM generalization effectively enhances\nthe performance of unseen LMs. Code is available at\nhttps://github.com/jinglin-liang/OLAS.", "AI": {"tldr": "本论文揭示了不同语言模型（LMs）之间上下文聚合模式的共性，并引入了“阶次级注意力”（OLA）来捕捉这些共性。基于此，提出了一种无需训练的跨模型适配器“可迁移OLA适配器”（TOA），通过将OLA作为统一的句法特征，有效提升了未见LMs的性能。", "motivation": "尽管已有研究关注LMs的上下文聚合或注意力权重，但它们通常侧重于单个模型或注意力头，缺乏对多个LMs之间共性的系统分析。本研究旨在探索LMs之间的共性，以加深对LMs的理解并促进跨模型知识迁移。", "method": "引入了从注意力展开（Attention Rollout）的阶次分解中导出的“阶次级注意力”（OLA）。发现不同LMs在相同阶次上的OLA表现出显著相似性。进一步揭示了OLA与句法知识之间的隐式映射。基于这两项发现，提出了“可迁移OLA适配器”（TOA），这是一种无需训练的跨LM适配器迁移方法，将OLA视为统一的句法特征表示来训练适配器。", "result": "相同阶次上的OLA在不同LMs之间表现出显著相似性。发现了OLA与句法知识之间的隐式映射。TOA的跨LM泛化能力被证明能有效增强未见LMs的性能。", "conclusion": "LMs的上下文聚合模式存在共同点，可以通过OLA来量化。OLA可以作为统一的句法特征表示，实现无需训练的跨LM知识迁移，从而有效提升未见LMs的性能。"}}
{"id": "2511.05263", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05263", "abs": "https://arxiv.org/abs/2511.05263", "authors": ["Qi Sun", "Dingju Zhou", "Lina Zhang"], "title": "OregairuChar: A Benchmark Dataset for Character Appearance Frequency Analysis in My Teen Romantic Comedy SNAFU", "comment": null, "summary": "The analysis of character appearance frequency is essential for understanding\nnarrative structure, character prominence, and story progression in anime. In\nthis work, we introduce OregairuChar, a benchmark dataset designed for\nappearance frequency analysis in the anime series My Teen Romantic Comedy\nSNAFU. The dataset comprises 1600 manually selected frames from the third\nseason, annotated with 2860 bounding boxes across 11 main characters.\nOregairuChar captures diverse visual challenges, including occlusion, pose\nvariation, and inter-character similarity, providing a realistic basis for\nappearance-based studies. To enable quantitative research, we benchmark several\nobject detection models on the dataset and leverage their predictions for\nfine-grained, episode-level analysis of character presence over time. This\napproach reveals patterns of character prominence and their evolution within\nthe narrative. By emphasizing appearance frequency, OregairuChar serves as a\nvaluable resource for exploring computational narrative dynamics and\ncharacter-centric storytelling in stylized media.", "AI": {"tldr": "该研究引入了OregairuChar数据集，用于分析动漫《我的青春恋爱物语果然有问题。完》中角色的出场频率，并利用目标检测模型预测结果来揭示角色在叙事中的重要性及其演变。", "motivation": "分析角色出场频率对于理解动漫中的叙事结构、角色重要性和故事进展至关重要。", "method": "研究构建了OregairuChar基准数据集，包含《我的青春恋爱物语果然有问题。完》第三季的1600个手动选择的帧，并标注了11个主要角色的2860个边界框。该数据集涵盖了遮挡、姿势变化和角色间相似性等视觉挑战。研究在该数据集上对多个目标检测模型进行了基准测试，并利用它们的预测结果对角色在剧集中的出现频率进行细粒度分析。", "result": "研究揭示了角色重要性的模式及其在叙事中的演变。OregairuChar数据集提供了一个真实的基础，用于基于外观的研究，并使定量分析成为可能。", "conclusion": "OregairuChar数据集通过强调出场频率，为探索计算叙事动态和程式化媒体中以角色为中心的故事讲述提供了一个宝贵的资源。"}}
{"id": "2511.05092", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05092", "abs": "https://arxiv.org/abs/2511.05092", "authors": ["Ruolin Li", "Min Liu", "Yuan Bian", "Zhaoyang Li", "Yuzhen Li", "Xueping Wang", "Yaonan Wang"], "title": "A Dual-stage Prompt-driven Privacy-preserving Paradigm for Person Re-Identification", "comment": "10 pages, 6 figures", "summary": "With growing concerns over data privacy, researchers have started using\nvirtual data as an alternative to sensitive real-world images for training\nperson re-identification (Re-ID) models. However, existing virtual datasets\nproduced by game engines still face challenges such as complex construction and\npoor domain generalization, making them difficult to apply in real scenarios.\nTo address these challenges, we propose a Dual-stage Prompt-driven\nPrivacy-preserving Paradigm (DPPP). In the first stage, we generate rich\nprompts incorporating multi-dimensional attributes such as pedestrian\nappearance, illumination, and viewpoint that drive the diffusion model to\nsynthesize diverse data end-to-end, building a large-scale virtual dataset\nnamed GenePerson with 130,519 images of 6,641 identities. In the second stage,\nwe propose a Prompt-driven Disentanglement Mechanism (PDM) to learn\ndomain-invariant generalization features. With the aid of contrastive learning,\nwe employ two textual inversion networks to map images into pseudo-words\nrepresenting style and content, respectively, thereby constructing\nstyle-disentangled content prompts to guide the model in learning\ndomain-invariant content features at the image level. Experiments demonstrate\nthat models trained on GenePerson with PDM achieve state-of-the-art\ngeneralization performance, surpassing those on popular real and virtual Re-ID\ndatasets.", "AI": {"tldr": "本文提出了一种双阶段提示驱动隐私保护范式（DPPP），通过扩散模型生成大规模虚拟行人重识别（Re-ID）数据集GenePerson，并引入提示驱动解耦机制（PDM）学习域不变泛化特征，实现了最先进的泛化性能。", "motivation": "随着数据隐私问题的日益突出，研究者开始使用虚拟数据训练行人Re-ID模型。然而，现有游戏引擎生成的虚拟数据集存在构建复杂和域泛化能力差的问题，难以应用于实际场景。", "method": "本文提出双阶段提示驱动隐私保护范式（DPPP）。第一阶段，利用包含行人外观、光照和视角等多维度属性的丰富提示驱动扩散模型端到端合成多样化数据，构建了包含130,519张图像和6,641个身份的大规模虚拟数据集GenePerson。第二阶段，提出提示驱动解耦机制（PDM），通过对比学习和两个文本反演网络将图像映射为代表风格和内容的伪词，从而构建风格解耦的内容提示，引导模型学习图像级别的域不变内容特征。", "result": "在GenePerson数据集上使用PDM训练的模型，其泛化性能达到了最先进水平，超越了在流行真实和虚拟Re-ID数据集上训练的模型。", "conclusion": "所提出的DPPP范式，结合GenePerson数据集和PDM机制，有效解决了虚拟数据在行人Re-ID中面临的复杂构建和域泛化挑战，显著提升了模型的泛化能力。"}}
{"id": "2511.05426", "categories": ["cs.RO", "J.2"], "pdf": "https://arxiv.org/pdf/2511.05426", "abs": "https://arxiv.org/abs/2511.05426", "authors": ["Luca Girardi", "Gabriel Maquignaz", "Stefano Mintchev"], "title": "Bioinspired Soft Quadrotors Jointly Unlock Agility, Squeezability, and Collision Resilience", "comment": "26 pages, 12 figures, 2 tables, 9 videos (not yet disclosed, awaiting\n  peer review)", "summary": "Natural flyers use soft wings to seamlessly enable a wide range of flight\nbehaviours, including agile manoeuvres, squeezing through narrow passageways,\nand withstanding collisions. In contrast, conventional quadrotor designs rely\non rigid frames that support agile flight but inherently limit collision\nresilience and squeezability, thereby constraining flight capabilities in\ncluttered environments. Inspired by the anisotropic stiffness and distributed\nmass-energy structures observed in biological organisms, we introduce\nFlexiQuad, a soft-frame quadrotor design approach that limits this trade-off.\nWe demonstrate a 405-gram FlexiQuad prototype, three orders of magnitude more\ncompliant than conventional quadrotors, yet capable of acrobatic manoeuvres\nwith peak speeds above 80 km/h and linear and angular accelerations exceeding 3\ng and 300 rad/s$^2$, respectively. Analysis demonstrates it can replicate\naccelerations of rigid counterparts up to a thrust-to-weight ratio of 8.\nSimultaneously, FlexiQuad exhibits fourfold higher collision resilience,\nsurviving frontal impacts at 5 m/s without damage and reducing destabilising\nforces in glancing collisions by a factor of 39. Its frame can fully compress,\nenabling flight through gaps as narrow as 70% of its nominal width. Our\nanalysis identifies an optimal structural softness range, from 0.006 to 0.77\nN/mm, comparable to that of natural flyers' wings, whereby agility,\nsqueezability, and collision resilience are jointly achieved for FlexiQuad\nmodels from 20 to 3000 grams. FlexiQuad expands hovering drone capabilities in\ncomplex environments, enabling robust physical interactions without\ncompromising flight performance.", "AI": {"tldr": "FlexiQuad是一种受自然飞行器启发设计的软框架四旋翼无人机，它通过结合各向异性刚度和分布式质量-能量结构，在不牺牲飞行性能的前提下，显著提高了碰撞弹性和可挤压性，从而扩展了在复杂环境中的飞行能力。", "motivation": "传统四旋翼无人机采用刚性框架，虽然能实现敏捷飞行，但固有限制了碰撞弹性和可挤压性，从而限制了其在杂乱环境中的飞行能力。受自然界中飞行器（如鸟类）柔软翅膀能够实现敏捷机动、穿过狭窄通道和承受碰撞的启发，研究旨在克服这一权衡。", "method": "引入了FlexiQuad设计方法，这是一种软框架四旋翼无人机，其灵感来源于生物体中观察到的各向异性刚度和分布式质量-能量结构。通过制造405克重的原型机并进行分析和测试来验证其性能。", "result": "FlexiQuad原型机比传统四旋翼无人机柔顺性高三个数量级，同时仍能进行特技机动，峰值速度超过80公里/小时，线加速度和角加速度分别超过3g和300 rad/s²。在推重比达到8时，它能复制刚性对应物的加速度。同时，其碰撞弹性提高了四倍，能承受5米/秒的正面撞击而不损坏，并使擦碰中不稳定的力减少了39倍。其框架可以完全压缩，能够通过其标称宽度70%的狭窄间隙。研究还确定了20至3000克FlexiQuad模型的最佳结构柔软度范围为0.006至0.77 N/mm，与自然飞行器翅膀的柔软度相当。", "conclusion": "FlexiQuad通过在不牺牲飞行性能的情况下实现敏捷性、可挤压性和碰撞弹性，扩展了无人机在复杂环境中的悬停能力，使其能够进行稳健的物理交互。"}}
{"id": "2511.05271", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05271", "abs": "https://arxiv.org/abs/2511.05271", "authors": ["Jack Hong", "Chenxiao Zhao", "ChengLin Zhu", "Weiheng Lu", "Guohai Xu", "Xing Yu"], "title": "DeepEyesV2: Toward Agentic Multimodal Model", "comment": "Homepage: https://visual-agent.github.io/", "summary": "Agentic multimodal models should not only comprehend text and images, but\nalso actively invoke external tools, such as code execution environments and\nweb search, and integrate these operations into reasoning. In this work, we\nintroduce DeepEyesV2 and explore how to build an agentic multimodal model from\nthe perspectives of data construction, training methods, and model evaluation.\nWe observe that direct reinforcement learning alone fails to induce robust\ntool-use behavior. This phenomenon motivates a two-stage training pipeline: a\ncold-start stage to establish tool-use patterns, and reinforcement learning\nstage to further refine tool invocation. We curate a diverse, moderately\nchallenging training dataset, specifically including examples where tool use is\nbeneficial. We further introduce RealX-Bench, a comprehensive benchmark\ndesigned to evaluate real-world multimodal reasoning, which inherently requires\nthe integration of multiple capabilities, including perception, search, and\nreasoning. We evaluate DeepEyesV2 on RealX-Bench and other representative\nbenchmarks, demonstrating its effectiveness across real-world understanding,\nmathematical reasoning, and search-intensive tasks. Moreover, DeepEyesV2\nexhibits task-adaptive tool invocation, tending to use image operations for\nperception tasks and numerical computations for reasoning tasks. Reinforcement\nlearning further enables complex tool combinations and allows model to\nselectively invoke tools based on context. We hope our study can provide\nguidance for community in developing agentic multimodal models.", "AI": {"tldr": "本文介绍了DeepEyesV2，一个通过两阶段训练（冷启动和强化学习）构建的代理式多模态模型，用于实现工具调用和复杂推理。同时提出了RealX-Bench基准来评估其在真实世界场景中的能力。", "motivation": "现有的代理式多模态模型不仅需要理解文本和图像，还应主动调用外部工具并将其整合到推理中。研究发现，仅靠直接强化学习难以实现稳健的工具使用行为，这促使了分阶段训练方法的探索。", "method": "本文提出了DeepEyesV2模型，并采用两阶段训练管道：首先是“冷启动”阶段，用于建立工具使用模式；其次是强化学习阶段，用于进一步优化工具调用。研究团队还策划了一个多样化且具有挑战性的训练数据集，并引入了RealX-Bench，一个旨在评估真实世界多模态推理的综合基准。", "result": "DeepEyesV2在RealX-Bench和其他代表性基准上表现出有效性，涵盖了真实世界理解、数学推理和搜索密集型任务。它展现了任务自适应的工具调用能力（如感知任务使用图像操作，推理任务使用数值计算），且强化学习进一步促进了复杂的工具组合和基于上下文的选择性工具调用。", "conclusion": "本研究通过DeepEyesV2及其两阶段训练方法，为开发代理式多模态模型提供了指导，强调了数据构建、训练方法和模型评估的重要性，特别是分阶段训练在实现稳健工具使用行为方面的有效性。"}}
{"id": "2511.05106", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05106", "abs": "https://arxiv.org/abs/2511.05106", "authors": ["Yasemin Turkan", "F. Boray Tek", "M. Serdar Nazlı", "Öykü Eren"], "title": "Early Alzheimer's Disease Detection from Retinal OCT Images: A UK Biobank Study", "comment": null, "summary": "Alterations in retinal layer thickness, measurable using Optical Coherence\nTomography (OCT), have been associated with neurodegenerative diseases such as\nAlzheimer's disease (AD). While previous studies have mainly focused on\nsegmented layer thickness measurements, this study explored the direct\nclassification of OCT B-scan images for the early detection of AD. To our\nknowledge, this is the first application of deep learning to raw OCT B-scans\nfor AD prediction in the literature. Unlike conventional medical image\nclassification tasks, early detection is more challenging than diagnosis\nbecause imaging precedes clinical diagnosis by several years. We fine-tuned and\nevaluated multiple pretrained models, including ImageNet-based networks and the\nOCT-specific RETFound transformer, using subject-level cross-validation\ndatasets matched for age, sex, and imaging instances from the UK Biobank\ncohort. To reduce overfitting in this small, high-dimensional dataset, both\nstandard and OCT-specific augmentation techniques were applied, along with a\nyear-weighted loss function that prioritized cases diagnosed within four years\nof imaging. ResNet-34 produced the most stable results, achieving an AUC of\n0.62 in the 4-year cohort. Although below the threshold for clinical\napplication, our explainability analyses confirmed localized structural\ndifferences in the central macular subfield between the AD and control groups.\nThese findings provide a baseline for OCT-based AD prediction, highlight the\nchallenges of detecting subtle retinal biomarkers years before AD diagnosis,\nand point to the need for larger datasets and multimodal approaches.", "AI": {"tldr": "本研究首次将深度学习应用于原始OCT B扫描图像，以预测阿尔茨海默病（AD）的早期发生，并识别了AD组和对照组之间的视网膜结构差异。", "motivation": "以往研究主要关注视网膜分层厚度测量与AD的关联，但直接对原始OCT B扫描图像进行分类以实现AD的早期检测仍未被探索。早期检测比诊断更具挑战性，因为成像发生在临床诊断前数年，需要更敏感的方法。", "method": "研究使用了来自英国生物样本库的OCT B扫描图像，通过主体级别的交叉验证数据集，对多个预训练模型（包括基于ImageNet的网络和OCT专用的RETFound transformer）进行了微调和评估。为减少小规模、高维数据集的过拟合，采用了标准和OCT特有的数据增强技术，并引入了根据成像后四年内诊断的病例赋予更高权重的年份加权损失函数。", "result": "ResNet-34模型表现出最稳定的结果，在四年队列中实现了0.62的AUC（曲线下面积）。尽管该AUC值低于临床应用阈值，但可解释性分析证实了AD组和对照组之间在中央黄斑区存在局部结构差异。", "conclusion": "这些发现为基于OCT的AD预测提供了基线，突出了在AD诊断前数年检测细微视网膜生物标志物的挑战，并指出未来需要更大的数据集和多模态方法来提高预测准确性。"}}
{"id": "2511.05078", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05078", "abs": "https://arxiv.org/abs/2511.05078", "authors": ["Manan Sharma", "Arya Suneesh", "Manish Jain", "Pawan Kumar Rajpoot", "Prasanna Devadiga", "Bharatdeep Hazarika", "Ashish Shrivastava", "Kishan Gurumurthy", "Anshuman B Suresh", "Aditya U Baliga"], "title": "Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media Posts", "comment": null, "summary": "We address claim normalization for multilingual misinformation detection -\ntransforming noisy social media posts into clear, verifiable statements across\n20 languages. The key contribution demonstrates how systematic decomposition of\nposts using Who, What, Where, When, Why and How questions enables robust\ncross-lingual transfer despite training exclusively on English data. Our\nmethodology incorporates finetuning Qwen3-14B using LoRA with the provided\ndataset after intra-post deduplication, token-level recall filtering for\nsemantic alignment and retrieval-augmented few-shot learning with contextual\nexamples during inference. Our system achieves METEOR scores ranging from 41.16\n(English) to 15.21 (Marathi), securing third rank on the English leaderboard\nand fourth rank for Dutch and Punjabi. The approach shows 41.3% relative\nimprovement in METEOR over baseline configurations and substantial gains over\nexisting methods. Results demonstrate effective cross-lingual generalization\nfor Romance and Germanic languages while maintaining semantic coherence across\ndiverse linguistic structures.", "AI": {"tldr": "本文提出了一种多语言虚假信息检测的声明规范化方法，通过系统地分解社交媒体帖子并利用5W1H问题，实现了在仅用英语数据训练的情况下，对20种语言的鲁棒跨语言迁移。", "motivation": "将嘈杂的社交媒体帖子转化为清晰、可验证的陈述，以支持多语言虚假信息检测，并解决跨语言传输的挑战。", "method": "核心方法是使用“谁、什么、哪里、何时、为什么、如何”问题对帖子进行系统分解，以实现跨语言迁移。具体技术包括使用LoRA微调Qwen3-14B模型，进行帖子内去重，采用token级别召回过滤以实现语义对齐，并在推理时结合上下文示例进行检索增强的少样本学习。训练数据仅限于英语。", "result": "系统在英语上的METEOR得分达到41.16，在马拉地语上为15.21。在英语排行榜上排名第三，在荷兰语和旁遮普语上排名第四。相对于基线配置，METEOR得分有41.3%的相对提升，并显著优于现有方法。结果显示，该方法在罗曼语系和日耳曼语系语言上表现出有效的跨语言泛化能力，并保持了不同语言结构间的语义连贯性。", "conclusion": "通过5W1H问题分解法和仅英语训练，本文提出的方法能够实现鲁棒的跨语言声明规范化，特别是在罗曼语系和日耳曼语系语言中表现出强大的泛化能力和显著的性能提升。"}}
{"id": "2511.05184", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05184", "abs": "https://arxiv.org/abs/2511.05184", "authors": ["Cong-Thanh Do", "Rama Doddipatla", "Kate Knill"], "title": "Effectiveness of Chain-of-Thought in Distilling Reasoning Capability from Large Language Models", "comment": "In proceedings of the 18th International Natural Language Generation\n  Conference (INLG 2025)", "summary": "Chain-of-Thought (CoT) prompting is a widely used method to improve the\nreasoning capability of Large Language Models (LLMs). More recently, CoT has\nbeen leveraged in Knowledge Distillation (KD) to transfer reasoning capability\nfrom a larger LLM to a smaller one. This paper examines the role of CoT in\ndistilling the reasoning capability from larger LLMs to smaller LLMs using\nwhite-box KD, analysing its effectiveness in improving the performance of the\ndistilled models for various natural language reasoning and understanding\ntasks. We conduct white-box KD experiments using LLMs from the Qwen and Llama2\nfamilies, employing CoT data from the CoT-Collection dataset. The distilled\nmodels are then evaluated on natural language reasoning and understanding tasks\nfrom the BIG-Bench-Hard (BBH) benchmark, which presents complex challenges for\nsmaller LLMs. Experimental results demonstrate the role of CoT in improving\nwhite-box KD effectiveness, enabling the distilled models to achieve better\naverage performance in natural language reasoning and understanding tasks from\nBBH.", "AI": {"tldr": "本文研究了思维链（CoT）在白盒知识蒸馏（KD）中，将大型语言模型（LLM）的推理能力转移到小型LLM中的作用，并证明了其有效性。", "motivation": "思维链（CoT）提示已被广泛用于提高大型语言模型的推理能力，并且最近也被应用于知识蒸馏以转移推理能力。本研究旨在深入分析CoT在白盒知识蒸馏中，如何有效地将大型LLM的推理能力传递给小型LLM。", "method": "研究采用白盒知识蒸馏实验，使用Qwen和Llama2系列的LLM。蒸馏过程利用来自CoT-Collection数据集的CoT数据。蒸馏后的模型在BIG-Bench-Hard (BBH) 基准测试中的自然语言推理和理解任务上进行评估。", "result": "实验结果表明，CoT在提高白盒知识蒸馏的有效性方面发挥了重要作用，使得蒸馏后的模型在BBH的自然语言推理和理解任务中取得了更好的平均性能。", "conclusion": "CoT在提高白盒知识蒸馏的有效性方面具有关键作用，能够显著提升小型LLM在复杂推理和理解任务上的表现。"}}
{"id": "2511.05299", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05299", "abs": "https://arxiv.org/abs/2511.05299", "authors": ["Zhenyu Yang", "Kairui Zhang", "Yuhang Hu", "Bing Wang", "Shengsheng Qian", "Bin Wen", "Fan Yang", "Tingting Gao", "Weiming Dong", "Changsheng Xu"], "title": "LiveStar: Live Streaming Assistant for Real-World Online Video Understanding", "comment": "NeurIPS 2025 Accepted", "summary": "Despite significant progress in Video Large Language Models (Video-LLMs) for\noffline video understanding, existing online Video-LLMs typically struggle to\nsimultaneously process continuous frame-by-frame inputs and determine optimal\nresponse timing, often compromising real-time responsiveness and narrative\ncoherence. To address these limitations, we introduce LiveStar, a pioneering\nlive streaming assistant that achieves always-on proactive responses through\nadaptive streaming decoding. Specifically, LiveStar incorporates: (1) a\ntraining strategy enabling incremental video-language alignment for\nvariable-length video streams, preserving temporal consistency across\ndynamically evolving frame sequences; (2) a response-silence decoding framework\nthat determines optimal proactive response timing via a single forward pass\nverification; (3) memory-aware acceleration via peak-end memory compression for\nonline inference on 10+ minute videos, combined with streaming key-value cache\nto achieve 1.53x faster inference. We also construct an OmniStar dataset, a\ncomprehensive dataset for training and benchmarking that encompasses 15 diverse\nreal-world scenarios and 5 evaluation tasks for online video understanding.\nExtensive experiments across three benchmarks demonstrate LiveStar's\nstate-of-the-art performance, achieving an average 19.5% improvement in\nsemantic correctness with 18.1% reduced timing difference compared to existing\nonline Video-LLMs, while improving FPS by 12.0% across all five OmniStar tasks.\nOur model and dataset can be accessed at https://github.com/yzy-bupt/LiveStar.", "AI": {"tldr": "LiveStar是一个创新的直播助手，通过自适应流解码实现持续主动响应，解决了现有在线Video-LLMs在处理连续帧输入和确定最佳响应时机方面的挑战，显著提升了实时性和叙事连贯性。", "motivation": "现有在线Video-LLMs难以同时处理连续帧输入和确定最佳响应时机，导致实时响应性和叙事连贯性受损。", "method": ["提出了一种训练策略，实现可变长度视频流的增量视频-语言对齐，保持时间一致性。", "设计了一个响应-静默解码框架，通过单次前向验证确定最佳主动响应时机。", "采用内存感知加速，通过峰值-末端内存压缩和流式键值缓存，加速长视频的在线推理。", "构建了OmniStar数据集，包含15个真实场景和5个在线视频理解评估任务。"], "result": ["在语义正确性方面平均提高19.5%。", "响应时间差异减少18.1%。", "所有OmniStar任务的FPS提高12.0%。", "推理速度提高1.53倍。", "在三个基准测试中均达到最先进的性能。"], "conclusion": "LiveStar通过其创新的训练策略、响应-静默解码框架和内存感知加速，显著提升了在线视频理解的实时性、准确性和效率，达到了最先进的性能。"}}
{"id": "2511.05108", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05108", "abs": "https://arxiv.org/abs/2511.05108", "authors": ["Jörg Gamerdinger", "Benedict Wetzel", "Patrick Schulz", "Sven Teufel", "Oliver Bringmann"], "title": "SnowyLane: Robust Lane Detection on Snow-covered Rural Roads Using Infrastructural Elements", "comment": null, "summary": "Lane detection for autonomous driving in snow-covered environments remains a\nmajor challenge due to the frequent absence or occlusion of lane markings. In\nthis paper, we present a novel, robust and realtime capable approach that\nbypasses the reliance on traditional lane markings by detecting roadside\nfeatures,specifically vertical roadside posts called delineators, as indirect\nlane indicators. Our method first perceives these posts, then fits a smooth\nlane trajectory using a parameterized Bezier curve model, leveraging spatial\nconsistency and road geometry. To support training and evaluation in these\nchallenging scenarios, we introduce SnowyLane, a new synthetic dataset\ncontaining 80,000 annotated frames capture winter driving conditions, with\nvarying snow coverage, and lighting conditions. Compared to state-of-the-art\nlane detection systems, our approach demonstrates significantly improved\nrobustness in adverse weather, particularly in cases with heavy snow occlusion.\nThis work establishes a strong foundation for reliable lane detection in winter\nscenarios and contributes a valuable resource for future research in\nall-weather autonomous driving. The dataset is available at\nhttps://ekut-es.github.io/snowy-lane", "AI": {"tldr": "本文提出了一种在积雪环境中进行车道检测的新方法，通过检测路边指示柱（分道柱）作为间接车道指示器，避免了对传统车道线的依赖。该方法利用参数化贝塞尔曲线拟合车道轨迹，并引入了一个新的合成数据集SnowyLane。实验证明，该方法在恶劣天气下表现出显著的鲁棒性。", "motivation": "在积雪环境中，车道线经常缺失或被遮挡，导致自动驾驶中的车道检测面临重大挑战。", "method": "该方法首先感知路边的垂直指示柱（分道柱），然后利用参数化贝塞尔曲线模型，结合空间一致性和道路几何形状，拟合出平滑的车道轨迹。为支持训练和评估，本文还引入了一个新的合成数据集SnowyLane，包含80,000帧带标注的冬季驾驶场景。", "result": "与现有最先进的车道检测系统相比，本文方法在恶劣天气下，特别是在大雪遮挡的情况下，表现出显著提高的鲁棒性。", "conclusion": "这项工作为冬季场景下的可靠车道检测奠定了坚实基础，并为全天候自动驾驶的未来研究贡献了宝贵的资源（数据集）。"}}
{"id": "2511.05239", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05239", "abs": "https://arxiv.org/abs/2511.05239", "authors": ["Zilong Li", "Jie Cao"], "title": "Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese", "comment": null, "summary": "Ancient people translated classical Chinese into Japanese by annotating\naround each character. We abstract this process as sequence tagging tasks and\nfit them into modern language technologies. The research of this annotation and\ntranslation system is a facing low-resource problem. We release this problem by\nintroducing a LLM-based annotation pipeline and construct a new dataset from\ndigitalized open-source translation data. We show that under the low-resource\nsetting, introducing auxiliary Chinese NLP tasks has a promoting effect on the\ntraining of sequence tagging tasks. We also evaluate the performance of large\nlanguage models. They achieve high scores in direct machine translation, but\nthey are confused when being asked to annotate characters. Our method could\nwork as a supplement of LLMs.", "AI": {"tldr": "本文将古汉语到日语的字符级翻译抽象为序列标注任务，并通过引入基于LLM的标注流程和构建新数据集来解决低资源问题。研究表明，辅助的中文NLP任务能提升序列标注性能，而LLM在直接翻译上表现良好但在字符标注上仍有不足，本文方法可作为补充。", "motivation": "古人通过在每个字符旁注释来将古汉语翻译成日语，这一过程在现代语言技术中可视为序列标注任务。然而，相关研究面临低资源问题，因此需要开发新的方法来处理这种字符级标注和翻译系统。", "method": "研究将古汉语翻译过程抽象为序列标注任务，并将其融入现代语言技术。为解决低资源问题，引入了基于大型语言模型（LLM）的标注流程，并从数字化开源翻译数据中构建了一个新的数据集。此外，通过引入辅助中文NLP任务来促进序列标注任务的训练。论文还评估了LLM在直接机器翻译和字符标注任务上的表现。", "result": "在低资源设置下，引入辅助中文NLP任务对序列标注任务的训练具有促进作用。大型语言模型在直接机器翻译中取得了高分，但在被要求进行字符标注时表现出困惑。本文提出的方法可以作为LLM的有效补充。", "conclusion": "将古汉语到日语的字符级翻译视为序列标注任务是可行的。通过LLM驱动的标注流程和辅助NLP任务，可以有效解决低资源问题。尽管LLM在直接翻译方面表现出色，但它们在精细的字符级标注上存在局限性，本文提出的方法能够弥补这一不足，并作为LLM的有效补充。"}}
{"id": "2511.05168", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05168", "abs": "https://arxiv.org/abs/2511.05168", "authors": ["Alexander Lappe", "Martin A. Giese"], "title": "Another BRIXEL in the Wall: Towards Cheaper Dense Features", "comment": null, "summary": "Vision foundation models achieve strong performance on both global and\nlocally dense downstream tasks. Pretrained on large images, the recent DINOv3\nmodel family is able to produce very fine-grained dense feature maps, enabling\nstate-of-the-art performance. However, computing these feature maps requires\nthe input image to be available at very high resolution, as well as large\namounts of compute due to the squared complexity of the transformer\narchitecture. To address these issues, we propose BRIXEL, a simple knowledge\ndistillation approach that has the student learn to reproduce its own feature\nmaps at higher resolution. Despite its simplicity, BRIXEL outperforms the\nbaseline DINOv3 models by large margins on downstream tasks when the resolution\nis kept fixed. Moreover, it is able to produce feature maps that are very\nsimilar to those of the teacher at a fraction of the computational cost. Code\nand model weights are available at https://github.com/alexanderlappe/BRIXEL.", "AI": {"tldr": "DINOv3等视觉基础模型生成高分辨率密集特征图计算成本高昂。BRIXEL提出一种简单的知识蒸馏方法，使学生模型能以更低的计算成本生成与教师模型相似的高分辨率特征图，并在下游任务中显著优于基线模型。", "motivation": "视觉基础模型（如DINOv3）虽然能在全局和局部密集任务上表现出色，并生成非常细粒度的密集特征图，但其需要极高分辨率的输入图像，且由于Transformer架构的平方复杂度，计算成本巨大。", "method": "本文提出BRIXEL，一种简单的知识蒸馏方法。学生模型通过学习来在高分辨率下复现其自身的特征图。", "result": "尽管BRIXEL方法简单，但在固定分辨率下，它在下游任务中的性能显著优于基线DINOv3模型。此外，它能以极低的计算成本生成与教师模型非常相似的特征图。", "conclusion": "BRIXEL成功解决了DINOv3模型生成高分辨率特征图所带来的高计算成本问题，同时在性能上保持甚至超越了基线模型。"}}
{"id": "2511.05152", "categories": ["cs.CV", "cs.GR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.05152", "abs": "https://arxiv.org/abs/2511.05152", "authors": ["Adrian Azzarelli", "Nantheera Anantrasirichai", "David R Bull"], "title": "Splatography: Sparse multi-view dynamic Gaussian Splatting for filmmaking challenges", "comment": null, "summary": "Deformable Gaussian Splatting (GS) accomplishes photorealistic dynamic 3-D\nreconstruction from dense multi-view video (MVV) by learning to deform a\ncanonical GS representation. However, in filmmaking, tight budgets can result\nin sparse camera configurations, which limits state-of-the-art (SotA) methods\nwhen capturing complex dynamic features. To address this issue, we introduce an\napproach that splits the canonical Gaussians and deformation field into\nforeground and background components using a sparse set of masks for frames at\nt=0. Each representation is separately trained on different loss functions\nduring canonical pre-training. Then, during dynamic training, different\nparameters are modeled for each deformation field following common filmmaking\npractices. The foreground stage contains diverse dynamic features so changes in\ncolor, position and rotation are learned. While, the background containing\nfilm-crew and equipment, is typically dimmer and less dynamic so only changes\nin point position are learned. Experiments on 3-D and 2.5-D entertainment\ndatasets show that our method produces SotA qualitative and quantitative\nresults; up to 3 PSNR higher with half the model size on 3-D scenes. Unlike the\nSotA and without the need for dense mask supervision, our method also produces\nsegmented dynamic reconstructions including transparent and dynamic textures.\nCode and video comparisons are available online:\nhttps://interims-git.github.io/", "AI": {"tldr": "本文提出一种可变形高斯泼溅（Deformable Gaussian Splatting）方法，通过将前景和背景组件分离并采用差异化训练，以从稀疏多视角视频中实现高质量动态三维重建，尤其适用于电影制作，且无需密集掩码监督。", "motivation": "在电影制作中，预算限制常导致稀疏的摄像机配置，这使得现有最先进（SotA）的可变形高斯泼溅方法难以捕捉复杂的动态特征并进行高质量的三维重建。", "method": "该方法将规范高斯（canonical Gaussians）和形变场（deformation field）在t=0时刻通过稀疏掩码分割为前景和背景两部分。在规范预训练阶段，每个表示都用不同的损失函数单独训练。在动态训练阶段，为每个形变场建模不同的参数：前景学习颜色、位置和旋转的变化（处理多样动态特征），而背景（包含摄制组和设备，通常较暗且不那么动态）仅学习点位置的变化。", "result": "在三维和2.5维娱乐数据集上，该方法产生了最先进的定性和定量结果，在三维场景中PSNR提高高达3，模型大小减半。与SotA方法不同，它无需密集掩码监督即可生成包含透明和动态纹理的分割动态重建。", "conclusion": "本文提出的方法有效解决了稀疏摄像机配置下动态三维重建的挑战，通过前景/背景分离和差异化训练，实现了优于现有技术的结果，模型更小，并能生成有价值的分割动态重建，非常适合电影制作场景。"}}
{"id": "2511.05308", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05308", "abs": "https://arxiv.org/abs/2511.05308", "authors": ["Matteo Bastico", "David Ryckelynck", "Laurent Corté", "Yannick Tillier", "Etienne Decencière"], "title": "Rethinking Metrics and Diffusion Architecture for 3D Point Cloud Generation", "comment": "This paper has been accepted at International Conference on 3D Vision\n  (3DV) 2026", "summary": "As 3D point clouds become a cornerstone of modern technology, the need for\nsophisticated generative models and reliable evaluation metrics has grown\nexponentially. In this work, we first expose that some commonly used metrics\nfor evaluating generated point clouds, particularly those based on Chamfer\nDistance (CD), lack robustness against defects and fail to capture geometric\nfidelity and local shape consistency when used as quality indicators. We\nfurther show that introducing samples alignment prior to distance calculation\nand replacing CD with Density-Aware Chamfer Distance (DCD) are simple yet\nessential steps to ensure the consistency and robustness of point cloud\ngenerative model evaluation metrics. While existing metrics primarily focus on\ndirectly comparing 3D Euclidean coordinates, we present a novel metric, named\nSurface Normal Concordance (SNC), which approximates surface similarity by\ncomparing estimated point normals. This new metric, when combined with\ntraditional ones, provides a more comprehensive evaluation of the quality of\ngenerated samples. Finally, leveraging recent advancements in transformer-based\nmodels for point cloud analysis, such as serialized patch attention , we\npropose a new architecture for generating high-fidelity 3D structures, the\nDiffusion Point Transformer. We perform extensive experiments and comparisons\non the ShapeNet dataset, showing that our model outperforms previous solutions,\nparticularly in terms of quality of generated point clouds, achieving new\nstate-of-the-art. Code available at\nhttps://github.com/matteo-bastico/DiffusionPointTransformer.", "AI": {"tldr": "本文揭示了现有三维点云生成模型评估指标（特别是基于Chamfer距离的）的不足，并提出了改进的评估方法（引入样本对齐、密度感知Chamfer距离DCD和表面法线一致性SNC）。此外，作者还提出了一种新的高性能三维生成模型——扩散点云Transformer，并在ShapeNet数据集上实现了最先进的性能。", "motivation": "随着三维点云技术的发展，对复杂生成模型和可靠评估指标的需求激增。然而，常用的点云生成模型评估指标（特别是基于Chamfer距离的）在面对缺陷时缺乏鲁棒性，并且未能有效捕捉几何保真度和局部形状一致性。", "method": "1. 暴露并分析了基于Chamfer距离的常用评估指标在鲁棒性和捕捉几何细节方面的不足。2. 提出在距离计算前引入样本对齐，并将Chamfer距离替换为密度感知Chamfer距离（DCD），以提高评估指标的一致性和鲁棒性。3. 引入了一种名为表面法线一致性（SNC）的新颖指标，通过比较估计的点法线来近似表面相似性。4. 基于Transformer模型在点云分析方面的最新进展，提出了一种新的高保真三维结构生成架构——扩散点云Transformer。", "result": "1. 引入样本对齐和使用DCD是确保点云生成模型评估指标一致性和鲁棒性的关键步骤。2. 新的SNC指标与传统指标结合使用时，能提供更全面的生成样本质量评估。3. 扩散点云Transformer模型在ShapeNet数据集上进行了广泛实验和比较，结果显示其性能优于现有解决方案，特别是在生成点云的质量方面，达到了新的最先进水平。", "conclusion": "常用的点云生成评估指标存在鲁棒性问题且无法充分捕捉几何细节。通过引入样本对齐、密度感知Chamfer距离（DCD）和表面法线一致性（SNC），可以显著提高评估指标的可靠性和全面性。此外，本文提出的扩散点云Transformer是一种有效生成高保真三维结构的架构，并在生成质量上取得了当前最佳的性能。"}}
{"id": "2511.05286", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05286", "abs": "https://arxiv.org/abs/2511.05286", "authors": ["Teqi Hao", "Xioayu Tan", "Shaojie Shi", "Yinghui Xu", "Xihe Qiu"], "title": "Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models", "comment": null, "summary": "The personalization of black-box large language models (LLMs) is a critical\nyet challenging task. Existing approaches predominantly rely on context\ninjection, where user history is embedded into the prompt to directly guide the\ngeneration process. However, this single-step paradigm imposes a dual burden on\nthe model: generating accurate content while simultaneously aligning with\nuser-specific styles. This often results in a trade-off that compromises output\nquality and limits precise control. To address this fundamental tension, we\npropose Reflective Personalization Optimization (RPO), a novel framework that\nredefines the personalization paradigm by decoupling content generation from\nalignment. RPO operates in two distinct stages: first, a base model generates a\nhigh-quality, generic response; then, an external reflection module explicitly\nrewrites this output to align with the user's preferences. This reflection\nmodule is trained using a two-stage process. Initially, supervised fine-tuning\nis employed on structured rewriting trajectories to establish a core\npersonalized reasoning policy that models the transformation from generic to\nuser-aligned responses. Subsequently, reinforcement learning is applied to\nfurther refine and enhance the quality of the personalized outputs.\nComprehensive experiments on the LaMP benchmark demonstrate that RPO, by\ndecoupling content generation from personalization, significantly outperforms\nstate-of-the-art baselines. These findings underscore the superiority of\nexplicit response shaping over implicit context injection. Moreover, RPO\nintroduces an efficient, model-agnostic personalization layer that can be\nseamlessly integrated with any underlying base model, paving the way for a new\nand effective direction in user-centric generation scenarios.", "AI": {"tldr": "本文提出反射个性化优化（RPO）框架，通过解耦内容生成和用户对齐来个性化黑盒大型语言模型，利用外部反射模块进行两阶段训练以重写响应。", "motivation": "现有的黑盒大型语言模型个性化方法主要依赖上下文注入，但这使得模型在生成准确内容和用户风格对齐之间面临两难，导致输出质量受损且控制受限。", "method": "RPO框架将个性化过程解耦为两阶段：首先，基础模型生成高质量的通用响应；然后，外部反射模块显式地重写此响应以符合用户偏好。该反射模块通过两阶段训练：首先进行监督微调以建立核心个性化推理策略，然后应用强化学习进一步优化和提升个性化输出的质量。", "result": "在LaMP基准测试上的综合实验表明，RPO通过解耦内容生成和个性化，显著优于现有最先进的基线方法。这强调了显式响应塑造优于隐式上下文注入的优势。", "conclusion": "RPO引入了一种高效、模型无关的个性化层，可以无缝集成到任何底层基础模型中，为以用户为中心的生成场景开辟了新的有效方向。"}}
{"id": "2511.05135", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05135", "abs": "https://arxiv.org/abs/2511.05135", "authors": ["Robin Armingaud", "Romaric Besançon"], "title": "ManufactuBERT: Efficient Continual Pretraining for Manufacturing", "comment": "Submitted to LREC 2026", "summary": "While large general-purpose Transformer-based encoders excel at general\nlanguage understanding, their performance diminishes in specialized domains\nlike manufacturing due to a lack of exposure to domain-specific terminology and\nsemantics. In this paper, we address this gap by introducing ManufactuBERT, a\nRoBERTa model continually pretrained on a large-scale corpus curated for the\nmanufacturing domain. We present a comprehensive data processing pipeline to\ncreate this corpus from web data, involving an initial domain-specific\nfiltering step followed by a multi-stage deduplication process that removes\nredundancies. Our experiments show that ManufactuBERT establishes a new\nstate-of-the-art on a range of manufacturing-related NLP tasks, outperforming\nstrong specialized baselines. More importantly, we demonstrate that training on\nour carefully deduplicated corpus significantly accelerates convergence,\nleading to a 33\\% reduction in training time and computational cost compared to\ntraining on the non-deduplicated dataset. The proposed pipeline offers a\nreproducible example for developing high-performing encoders in other\nspecialized domains. We will release our model and curated corpus at\nhttps://huggingface.co/cea-list-ia.", "AI": {"tldr": "本文介绍了ManufactuBERT，一个在经过领域特定过滤和多阶段去重的大规模制造领域语料库上持续预训练的RoBERTa模型，该模型在制造相关NLP任务上取得了新的SOTA，并显著缩短了训练时间。", "motivation": "通用Transformer模型在制造等专业领域表现不佳，原因在于缺乏对领域特定术语和语义的理解。", "method": "引入了ManufactuBERT模型，该模型是一个在为制造领域精心策划的大规模语料库上持续预训练的RoBERTa模型。为此，开发了一个全面的数据处理流程，从网络数据中创建语料库，包括领域特定的初始过滤步骤和多阶段去重过程以消除冗余。", "result": "ManufactuBERT在多项制造相关的NLP任务上取得了新的最先进（SOTA）性能，超越了强大的专业基线模型。更重要的是，在精心去重后的语料库上训练显著加速了收敛，与在未去重数据集上训练相比，训练时间和计算成本减少了33%。", "conclusion": "ManufactuBERT是制造领域高性能编码器。所提出的数据处理流程为在其他专业领域开发高性能编码器提供了可复现的范例。数据去重对于高效训练至关重要。"}}
{"id": "2511.05120", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05120", "abs": "https://arxiv.org/abs/2511.05120", "authors": ["Daniel Grießhaber", "Maximilian Kimmich", "Johannes Maucher", "Ngoc Thang Vu"], "title": "A Toolbox for Improving Evolutionary Prompt Search", "comment": null, "summary": "Evolutionary prompt optimization has demonstrated effectiveness in refining\nprompts for LLMs. However, existing approaches lack robust operators and\nefficient evaluation mechanisms. In this work, we propose several key\nimprovements to evolutionary prompt optimization that can partially generalize\nto prompt optimization in general: 1) decomposing evolution into distinct steps\nto enhance the evolution and its control, 2) introducing an LLM-based judge to\nverify the evolutions, 3) integrating human feedback to refine the evolutionary\noperator, and 4) developing more efficient evaluation strategies that maintain\nperformance while reducing computational overhead. Our approach improves both\noptimization quality and efficiency. We release our code, enabling prompt\noptimization on new tasks and facilitating further research in this area.", "AI": {"tldr": "本文提出了一种改进的进化式提示优化方法，通过分解进化步骤、引入LLM判官、整合人工反馈和开发高效评估策略，显著提升了提示优化的质量和效率。", "motivation": "现有的进化式提示优化方法虽然有效，但缺乏鲁棒的操作符和高效的评估机制。", "method": "1) 将进化过程分解为不同步骤以增强控制；2) 引入基于LLM的判官来验证进化结果；3) 整合人工反馈以改进进化操作符；4) 开发更高效的评估策略，在保持性能的同时降低计算开销。", "result": "所提出的方法显著提升了提示优化的质量和效率。", "conclusion": "该研究通过提供优化的方法和开源代码，有助于在新的任务上进行提示优化，并促进该领域的进一步研究。"}}
{"id": "2511.05310", "categories": ["cs.CL", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.05310", "abs": "https://arxiv.org/abs/2511.05310", "authors": ["Shreya Gupta", "Ojasva Saxena", "Arghodeep Nandi", "Sarah Masud", "Kiran Garimella", "Tanmoy Chakraborty"], "title": "Listening Between the Lines: Decoding Podcast Narratives with Language Modeling", "comment": "10 pages, 6 Figures, 5 Tables. Under review at IEEE TCSS", "summary": "Podcasts have become a central arena for shaping public opinion, making them\na vital source for understanding contemporary discourse. Their typically\nunscripted, multi-themed, and conversational style offers a rich but complex\nform of data. To analyze how podcasts persuade and inform, we must examine\ntheir narrative structures -- specifically, the narrative frames they employ.\n  The fluid and conversational nature of podcasts presents a significant\nchallenge for automated analysis. We show that existing large language models,\ntypically trained on more structured text such as news articles, struggle to\ncapture the subtle cues that human listeners rely on to identify narrative\nframes. As a result, current approaches fall short of accurately analyzing\npodcast narratives at scale.\n  To solve this, we develop and evaluate a fine-tuned BERT model that\nexplicitly links narrative frames to specific entities mentioned in the\nconversation, effectively grounding the abstract frame in concrete details. Our\napproach then uses these granular frame labels and correlates them with\nhigh-level topics to reveal broader discourse trends. The primary contributions\nof this paper are: (i) a novel frame-labeling methodology that more closely\naligns with human judgment for messy, conversational data, and (ii) a new\nanalysis that uncovers the systematic relationship between what is being\ndiscussed (the topic) and how it is being presented (the frame), offering a\nmore robust framework for studying influence in digital media.", "AI": {"tldr": "播客是塑造公众舆论的关键平台，但其非结构化、对话式的特性给自动叙事框架分析带来了挑战。本文提出了一种微调的BERT模型，通过将叙事框架与具体实体和高层主题关联，解决了现有大型语言模型在此方面的不足，提供了一种更准确分析播客叙事和数字媒体影响的新方法。", "motivation": "播客在塑造公众舆论方面日益重要，是理解当代话语的关键来源。然而，其非脚本化、多主题和对话式的风格使得对叙事框架的自动化分析变得复杂，现有大型语言模型（通常在结构化文本上训练）难以捕捉人类听众识别叙事框架的细微线索，导致无法准确大规模分析播客叙事。", "method": "开发并评估了一个微调的BERT模型。该模型明确地将叙事框架与对话中提及的特定实体关联起来，从而将抽象框架具体化。然后，利用这些细粒度的框架标签，并将其与高级主题相关联，以揭示更广泛的话语趋势。", "result": "现有大型语言模型在捕捉人类听众识别叙事框架的细微线索方面表现不佳。本文提出的方法提供了一种新颖的框架标注方法，与人类对凌乱、对话式数据的判断更一致。此外，通过这种新分析，揭示了讨论内容（主题）与呈现方式（框架）之间的系统关系。", "conclusion": "本研究为数字媒体中的影响力研究提供了一个更强大的框架，通过提出一种新颖的框架标注方法，并揭示了播客中主题与叙事框架之间的系统关系，从而能够更准确地大规模分析播客叙事。"}}
{"id": "2511.05361", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05361", "abs": "https://arxiv.org/abs/2511.05361", "authors": ["Maria Huynh", "Wilder C. Rodrigues"], "title": "A multimodal multiplex of the mental lexicon for multilingual individuals", "comment": null, "summary": "Historically, bilingualism was often perceived as an additional cognitive\nload that could hinder linguistic and intellectual development. However, over\nthe last three decades, this view has changed considerably. Numerous studies\nhave aimed to model and understand the architecture of the bilingual word\nrecognition system Dijkstra and van Heuven (2002), investigating how parallel\nactivation operates in the brain and how one language influences another Kroll\net al. (2015). Increasingly, evidence suggests that multilinguals, individuals\nwho speak three or more languages, can perform better than monolinguals in\nvarious linguistic and cognitive tasks, such as learning an additional language\nAbu-Rabia and Sanitsky (2010). This research proposal focuses on the study of\nthe mental lexicon and how it may be structured in individuals who speak\nmultiple languages. Building on the work of Stella et al. (2018), who\ninvestigated explosive learning in humans using a multiplex model of the mental\nlexicon, and the Bilingual Interactive Activation (BIA+) framework proposed by\nDijkstra and van Heuven (2002), the present study applies the same multilayer\nnetwork principles introduced by Kivela et al. (2014). Our experimental design\nextends previous research by incorporating multimodality into the multiplex\nmodel, introducing an additional layer that connects visual inputs to their\ncorresponding lexical representations across the multilingual layers of the\nmental lexicon. In this research, we aim to explore how a heritage language\ninfluences the acquisition of another language. Specifically, we ask: Does the\npresence of visual input in a translation task influence participants'\nproficiency and accuracy compared to text-only conditions?", "AI": {"tldr": "本研究旨在探究多语者心理词典的结构及其多层网络模型，特别关注母语如何影响新语言习得，并通过引入视觉输入层来分析其对翻译任务表现的影响。", "motivation": "传统观点认为双语是一种认知负担，但近三十年的研究表明，多语者在语言和认知任务中可能表现更优。因此，有必要深入理解双语/多语词汇识别系统的架构，以及语言间如何相互影响。", "method": "本研究借鉴了Stella等人（2018）关于心理词典多重模型的爆炸式学习研究，以及Dijkstra和van Heuven（2002）提出的BIA+框架。在此基础上，应用了Kivela等人（2014）引入的多层网络原理，并通过引入一个额外的层来将视觉输入与其在多语心理词典中的词汇表征联系起来，从而将多模态整合到多重模型中。实验设计将比较翻译任务中存在视觉输入与仅有文本条件下的表现。", "result": "本研究旨在探索母语如何影响另一种语言的习得。具体而言，它将探究在翻译任务中，与仅有文本条件相比，视觉输入的存在是否会影响参与者的熟练度和准确性。", "conclusion": "作为一项研究提案，本文旨在通过扩展现有多语词典模型来探索多语者心理词典的结构，特别是母语对新语言习得的影响，并评估多模态（视觉输入）在翻译任务中的作用。"}}
{"id": "2511.05170", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05170", "abs": "https://arxiv.org/abs/2511.05170", "authors": ["Zijiang Yang", "Hanqing Chao", "Bokai Zhao", "Yelin Yang", "Yunshuo Zhang", "Dongmei Fu", "Junping Zhang", "Le Lu", "Ke Yan", "Dakai Jin", "Minfeng Xu", "Yun Bian", "Hui Jiang"], "title": "MUSE: Multi-Scale Dense Self-Distillation for Nucleus Detection and Classification", "comment": "12 pages, 7 figures", "summary": "Nucleus detection and classification (NDC) in histopathology analysis is a\nfundamental task that underpins a wide range of high-level pathology\napplications. However, existing methods heavily rely on labor-intensive\nnucleus-level annotations and struggle to fully exploit large-scale unlabeled\ndata for learning discriminative nucleus representations. In this work, we\npropose MUSE (MUlti-scale denSE self-distillation), a novel self-supervised\nlearning method tailored for NDC. At its core is NuLo (Nucleus-based Local\nself-distillation), a coordinate-guided mechanism that enables flexible local\nself-distillation based on predicted nucleus positions. By removing the need\nfor strict spatial alignment between augmented views, NuLo allows critical\ncross-scale alignment, thus unlocking the capacity of models for fine-grained\nnucleus-level representation. To support MUSE, we design a simple yet effective\nencoder-decoder architecture and a large field-of-view semi-supervised\nfine-tuning strategy that together maximize the value of unlabeled pathology\nimages. Extensive experiments on three widely used benchmarks demonstrate that\nMUSE effectively addresses the core challenges of histopathological NDC. The\nresulting models not only surpass state-of-the-art supervised baselines but\nalso outperform generic pathology foundation models.", "AI": {"tldr": "MUSE是一种新颖的自监督学习方法，通过多尺度密集自蒸馏（MUSE）和基于细胞核的局部自蒸馏（NuLo）机制，解决了组织病理学中细胞核检测和分类（NDC）对大量标注的依赖，并能有效利用未标注数据，性能超越了现有监督基线和通用病理学基础模型。", "motivation": "现有的细胞核检测与分类（NDC）方法严重依赖耗时耗力的细胞核级别标注，并且难以充分利用大规模未标注数据来学习判别性的细胞核表征。", "method": "本文提出了MUSE（MUlti-scale denSE self-distillation），一种专为NDC设计的自监督学习方法。其核心是NuLo（Nucleus-based Local self-distillation），一种坐标引导机制，通过允许基于预测细胞核位置的灵活局部自蒸馏，消除了增强视图之间严格的空间对齐需求，实现了关键的跨尺度对齐，从而解锁了模型学习细粒度细胞核级别表示的能力。为支持MUSE，还设计了一个简单有效的编解码器架构和一个大视野半监督微调策略，以最大化未标注病理图像的价值。", "result": "在三个广泛使用的基准测试上进行的广泛实验表明，MUSE有效解决了组织病理学NDC的核心挑战。其模型不仅超越了最先进的监督基线，而且优于通用的病理学基础模型。", "conclusion": "MUSE是一种新颖且有效的自监督学习方法，专门针对组织病理学中的细胞核检测和分类任务，通过利用未标注数据和创新的自蒸馏机制，显著提升了性能并解决了现有方法的局限性。"}}
{"id": "2511.05324", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05324", "abs": "https://arxiv.org/abs/2511.05324", "authors": ["Firoj Ahmmed Patwary", "Abdullah Al Noman"], "title": "Evaluating Subword Tokenization Techniques for Bengali: A Benchmark Study with BengaliBPE", "comment": "10 pages, 3 figures, 3 tables", "summary": "Tokenization is an important first step in Natural Language Processing (NLP)\npipelines because it decides how models learn and represent linguistic\ninformation. However, current subword tokenizers like SentencePiece or\nHuggingFace BPE are mostly designed for Latin or multilingual corpora and do\nnot perform well on languages with rich morphology such as Bengali. To address\nthis limitation, we present BengaliBPE, a Byte Pair Encoding (BPE) tokenizer\nspecifically developed for the Bengali script. BengaliBPE applies Unicode\nnormalization, grapheme-level initialization, and morphology-aware merge rules\nto maintain linguistic consistency and preserve subword integrity. We use a\nlarge-scale Bengali news classification dataset to compare BengaliBPE with\nthree baselines: Whitespace, SentencePiece BPE, and HuggingFace BPE. The\nevaluation considers tokenization granularity, encoding speed, and downstream\nclassification accuracy. While all methods perform reasonably well, BengaliBPE\nprovides the most detailed segmentation and the best morphological\ninterpretability, albeit with slightly higher computational cost. These\nfindings highlight the importance of language-aware tokenization for\nmorphologically rich scripts and establish BengaliBPE as a strong foundation\nfor future Bengali NLP systems, including large-scale pretraining of contextual\nlanguage models.", "AI": {"tldr": "本文提出BengaliBPE，一种专为孟加拉语设计的字节对编码（BPE）分词器，通过引入语言学感知规则，解决了现有分词器在形态丰富语言上的不足，并提升了下游任务性能。", "motivation": "现有子词分词器（如SentencePiece或HuggingFace BPE）主要针对拉丁语系或多语言语料库设计，在孟加拉语等形态丰富的语言上表现不佳，无法有效学习和表示语言信息。", "method": "研究者开发了BengaliBPE，它结合了Unicode标准化、字素级初始化和形态感知的合并规则，以保持语言一致性和子词完整性。他们在一个大型孟加拉语新闻分类数据集上，将BengaliBPE与Whitespace、SentencePiece BPE和HuggingFace BPE三种基线方法进行比较，评估了分词粒度、编码速度和下游分类准确性。", "result": "尽管所有方法都表现尚可，但BengaliBPE提供了最详细的分词和最佳的形态可解释性，尽管计算成本略高。这些发现强调了语言感知分词对于形态丰富文字的重要性。", "conclusion": "语言感知分词对于形态丰富的文字至关重要。BengaliBPE为未来的孟加拉语自然语言处理系统（包括大规模预训练上下文语言模型）奠定了坚实基础。"}}
{"id": "2511.05394", "categories": ["cs.CV", "cs.AI", "cs.HC", "H.5.2; H.5.1; I.4.8; I.2.6"], "pdf": "https://arxiv.org/pdf/2511.05394", "abs": "https://arxiv.org/abs/2511.05394", "authors": ["Alexander Htet Kyaw", "Haotian Ma", "Sasa Zivkovic", "Jenny Sabin"], "title": "AI Assisted AR Assembly: Object Recognition and Computer Vision for Augmented Reality Assisted Assembly", "comment": "Accepted to the Association for Computing Machinery (ACM) Symposium\n  on Computational Fabrication (SCF '25)", "summary": "We present an AI-assisted Augmented Reality assembly workflow that uses deep\nlearning-based object recognition to identify different assembly components and\ndisplay step-by-step instructions. For each assembly step, the system displays\na bounding box around the corresponding components in the physical space, and\nwhere the component should be placed. By connecting assembly instructions with\nthe real-time location of relevant components, the system eliminates the need\nfor manual searching, sorting, or labeling of different components before each\nassembly. To demonstrate the feasibility of using object recognition for\nAR-assisted assembly, we highlight a case study involving the assembly of LEGO\nsculptures.", "AI": {"tldr": "本文提出了一种AI辅助的增强现实（AR）装配工作流程，利用深度学习进行物体识别，为装配提供分步指导，无需人工预处理组件。", "motivation": "目前的装配流程需要人工搜索、分类或标记组件，耗时且易出错。研究旨在通过将装配指令与组件的实时位置相结合，消除这些手动步骤。", "method": "该系统采用基于深度学习的物体识别技术来识别不同的装配组件。通过增强现实在物理空间中显示对应组件的边界框和放置位置，提供分步指导。", "result": "通过乐高雕塑装配的案例研究，验证了使用物体识别技术进行AR辅助装配的可行性，系统能有效识别组件并显示指令。", "conclusion": "物体识别技术在AR辅助装配中是可行且有效的，能够简化装配流程，消除对组件进行手动搜索、分类或标记的需求。"}}
{"id": "2511.05080", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05080", "abs": "https://arxiv.org/abs/2511.05080", "authors": ["P. Bilha Githinji", "Aikaterini Meilliou", "Peiwu Qin"], "title": "On Text Simplification Metrics and General-Purpose LLMs for Accessible Health Information, and A Potential Architectural Advantage of The Instruction-Tuned LLM class", "comment": null, "summary": "The increasing health-seeking behavior and digital consumption of biomedical\ninformation by the general public necessitate scalable solutions for\nautomatically adapting complex scientific and technical documents into plain\nlanguage. Automatic text simplification solutions, including advanced large\nlanguage models, however, continue to face challenges in reliably arbitrating\nthe tension between optimizing readability performance and ensuring\npreservation of discourse fidelity. This report empirically assesses the\nperformance of two major classes of general-purpose LLMs, demonstrating their\nlinguistic capabilities and foundational readiness for the task compared to a\nhuman benchmark. Using a comparative analysis of the instruction-tuned Mistral\n24B and the reasoning-augmented QWen2.5 32B, we identify a potential\narchitectural advantage in the instruction-tuned LLM. Mistral exhibits a\ntempered lexical simplification strategy that enhances readability across a\nsuite of metrics and the simplification-specific formula SARI (mean 42.46),\nwhile preserving human-level discourse with a BERTScore of 0.91. QWen also\nattains enhanced readability performance, but its operational strategy shows a\ndisconnect in balancing between readability and accuracy, reaching a\nstatistically significantly lower BERTScore of 0.89. Additionally, a\ncomprehensive correlation analysis of 21 metrics spanning readability,\ndiscourse fidelity, content safety, and underlying distributional measures for\nmechanistic insights, confirms strong functional redundancies among five\nreadability indices. This empirical evidence tracks baseline performance of the\nevolving LLMs for the task of text simplification, identifies the\ninstruction-tuned Mistral 24B for simplification, provides necessary heuristics\nfor metric selection, and points to lexical support as a primary\ndomain-adaptation issue for simplification.", "AI": {"tldr": "本报告评估了两种主流LLM（Mistral 24B和QWen2.5 32B）在文本简化任务中的表现，发现指令调优的Mistral在优化可读性和保持语篇忠实度之间取得了更好的平衡，并探讨了度量指标和词汇支持的问题。", "motivation": "公众日益增长的健康信息需求和对生物医学信息的数字化消费，要求可扩展的解决方案能自动将复杂的科学技术文档转化为通俗语言。然而，包括高级大型语言模型在内的自动文本简化方案，在优化可读性性能和确保语篇忠实度之间，仍难以可靠地平衡。", "method": "本研究实证评估了两种主要通用LLM（指令调优的Mistral 24B和推理增强的QWen2.5 32B）的性能，并与人工基准进行了比较分析。使用了SARI和BERTScore等指标，并对涵盖可读性、语篇忠实度、内容安全性和潜在分布测量的21个指标进行了全面的相关性分析。", "result": "指令调优的Mistral 24B在架构上显示出潜在优势，其词汇简化策略温和，在多项可读性指标和简化专用公式SARI（平均42.46）上表现出色，同时以0.91的BERTScore保持了人类水平的语篇忠实度。QWen也提高了可读性，但在平衡可读性和准确性方面存在脱节，BERTScore显著低于0.89。此外，21个指标的相关性分析证实了五个可读性指数之间存在强大的功能冗余。", "conclusion": "本研究为不断发展的LLM在文本简化任务中的基线性能提供了经验证据，识别出指令调优的Mistral 24B适用于简化任务，为指标选择提供了必要的启发式方法，并指出词汇支持是简化的主要领域适应问题。"}}
{"id": "2511.05320", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05320", "abs": "https://arxiv.org/abs/2511.05320", "authors": ["Klára Bendová", "Tomáš Knap", "Jan Černý", "Vojtěch Pour", "Jaromir Savelka", "Ivana Kvapilíková", "Jakub Drápal"], "title": "What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions", "comment": "Paper accepted to the proceedings of ASAIL 2025 Workshop under ICAIL\n  conference for publication. Paper contains 6 pages (references included) and\n  2 appendices. It contains 8 tables, no figures", "summary": "Criminal justice administrative data contain only a limited amount of\ninformation about the committed offense. However, there is an unused source of\nextensive information in continental European courts' decisions: descriptions\nof criminal behaviors in verdicts by which offenders are found guilty. In this\npaper, we study the feasibility of extracting these descriptions from publicly\navailable court decisions from Slovakia. We use two different approaches for\nretrieval: regular expressions and large language models (LLMs). Our baseline\nwas a simple method employing regular expressions to identify typical words\noccurring before and after the description. The advanced regular expression\napproach further focused on \"sparing\" and its normalization (insertion of\nspaces between individual letters), typical for delineating the description.\nThe LLM approach involved prompting the Gemini Flash 2.0 model to extract the\ndescriptions using predefined instructions. Although the baseline identified\ndescriptions in only 40.5% of verdicts, both methods significantly outperformed\nit, achieving 97% with advanced regular expressions and 98.75% with LLMs, and\n99.5% when combined. Evaluation by law students showed that both advanced\nmethods matched human annotations in about 90% of cases, compared to just 34.5%\nfor the baseline. LLMs fully matched human-labeled descriptions in 91.75% of\ninstances, and a combination of advanced regular expressions with LLMs reached\n92%.", "AI": {"tldr": "本研究探讨了从斯洛伐克法院判决书中提取犯罪行为描述的可行性，发现高级正则表达式和大型语言模型（LLMs）在准确性上远超基线方法，并能与人类标注高度匹配。", "motivation": "刑事司法行政数据对犯罪行为的描述有限，而欧洲大陆法院判决书中的有罪判决部分包含大量未被利用的犯罪行为详细描述，这些信息对于深入研究具有重要价值。", "method": "研究采用了三种方法来提取犯罪行为描述：1) 基线方法，使用简单正则表达式识别描述前后典型词汇；2) 高级正则表达式方法，进一步关注“sparing”及其标准化处理（字母间插入空格，常用于描述界定）；3) LLM方法，使用预定义指令提示Gemini Flash 2.0模型进行提取。此外，还评估了两种高级方法的组合效果。法律系学生对提取结果与人类标注的匹配度进行了评估。", "result": "基线方法仅在40.5%的判决书中识别出描述。高级正则表达式方法达到97%的识别率，LLMs达到98.75%，两者结合后更是达到99.5%。与人类标注的匹配度方面，基线方法仅为34.5%，而高级正则表达式方法和LLMs均达到约90%。具体而言，LLMs完全匹配人类标注的比例为91.75%，高级正则表达式与LLMs的组合达到92%。", "conclusion": "从公开的斯洛伐克法院判决书中提取犯罪行为描述是可行的。高级正则表达式和大型语言模型（特别是LLMs及其与高级正则表达式的结合）在准确性和与人类标注的匹配度方面表现出色，远超简单基线方法，为刑事司法领域的数据挖掘提供了高效工具。"}}
{"id": "2511.05404", "categories": ["cs.CV", "cs.AI", "I.2.9; I.2.10"], "pdf": "https://arxiv.org/pdf/2511.05404", "abs": "https://arxiv.org/abs/2511.05404", "authors": ["Laura Alejandra Encinar Gonzalez", "John Folkesson", "Rudolph Triebel", "Riccardo Giubilato"], "title": "Multi-modal Loop Closure Detection with Foundation Models in Severely Unstructured Environments", "comment": "Under review for ICRA 2026", "summary": "Robust loop closure detection is a critical component of Simultaneous\nLocalization and Mapping (SLAM) algorithms in GNSS-denied environments, such as\nin the context of planetary exploration. In these settings, visual place\nrecognition often fails due to aliasing and weak textures, while LiDAR-based\nmethods suffer from sparsity and ambiguity. This paper presents MPRF, a\nmultimodal pipeline that leverages transformer-based foundation models for both\nvision and LiDAR modalities to achieve robust loop closure in severely\nunstructured environments. Unlike prior work limited to retrieval, MPRF\nintegrates a two-stage visual retrieval strategy with explicit 6-DoF pose\nestimation, combining DINOv2 features with SALAD aggregation for efficient\ncandidate screening and SONATA-based LiDAR descriptors for geometric\nverification. Experiments on the S3LI dataset and S3LI Vulcano dataset show\nthat MPRF outperforms state-of-the-art retrieval methods in precision while\nenhancing pose estimation robustness in low-texture regions. By providing\ninterpretable correspondences suitable for SLAM back-ends, MPRF achieves a\nfavorable trade-off between accuracy, efficiency, and reliability,\ndemonstrating the potential of foundation models to unify place recognition and\npose estimation. Code and models will be released at github.com/DLR-RM/MPRF.", "AI": {"tldr": "MPRF是一个多模态（视觉+激光雷达）管道，利用基于Transformer的基础模型在GNSS受限的非结构化环境中实现鲁棒的闭环检测和姿态估计，优于现有方法。", "motivation": "在GNSS受限的环境（如行星探索）中，闭环检测对SLAM至关重要。然而，视觉方法常因混叠和弱纹理而失效，激光雷达方法则受稀疏性和模糊性困扰。", "method": "MPRF是一个多模态管道，利用基于Transformer的基础模型处理视觉和激光雷达数据。它整合了一个两阶段的视觉检索策略（结合DINOv2特征和SALAD聚合进行候选筛选）以及显式的6自由度姿态估计（使用基于SONATA的激光雷达描述符进行几何验证）。", "result": "在S3LI和S3LI Vulcano数据集上的实验表明，MPRF在精度上优于最先进的检索方法，并在低纹理区域增强了姿态估计的鲁棒性。它在准确性、效率和可靠性之间取得了良好的平衡，并为SLAM后端提供了可解释的对应关系。", "conclusion": "MPRF展示了基础模型在统一地点识别和姿态估计方面的潜力，为GNSS受限的严重非结构化环境中的鲁棒闭环检测提供了有效解决方案。"}}
{"id": "2511.05406", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05406", "abs": "https://arxiv.org/abs/2511.05406", "authors": ["Tiago Dinis", "Miguel Correia", "Roger Tavares"], "title": "Large Language Models for Explainable Threat Intelligence", "comment": null, "summary": "As cyber threats continue to grow in complexity, traditional security\nmechanisms struggle to keep up. Large language models (LLMs) offer significant\npotential in cybersecurity due to their advanced capabilities in text\nprocessing and generation. This paper explores the use of LLMs with\nretrieval-augmented generation (RAG) to obtain threat intelligence by combining\nreal-time information retrieval with domain-specific data. The proposed system,\nRAGRecon, uses a LLM with RAG to answer questions about cybersecurity threats.\nMoreover, it makes this form of Artificial Intelligence (AI) explainable by\ngenerating and visually presenting to the user a knowledge graph for every\nreply. This increases the transparency and interpretability of the reasoning of\nthe model, allowing analysts to better understand the connections made by the\nsystem based on the context recovered by the RAG system. We evaluated RAGRecon\nexperimentally with two datasets and seven different LLMs and the responses\nmatched the reference responses more than 91% of the time for the best\ncombinations.", "AI": {"tldr": "该论文提出RAGRecon系统，结合大型语言模型（LLM）和检索增强生成（RAG）技术，用于网络威胁情报获取，并通过生成知识图谱提高AI的可解释性。实验结果显示其准确性超过91%。", "motivation": "网络威胁日益复杂，传统安全机制难以应对。大型语言模型在文本处理和生成方面的先进能力，使其在网络安全领域具有巨大潜力。", "method": "所提出的RAGRecon系统利用LLM与RAG相结合，通过实时信息检索和领域特定数据回答网络安全威胁问题。此外，它通过为每个回复生成并可视化呈现知识图谱，提高了人工智能的透明度和可解释性，帮助分析师理解模型推理。", "result": "RAGRecon系统在两个数据集和七个不同LLM上进行了实验评估。最佳组合的响应与参考响应的匹配度超过91%。", "conclusion": "RAGRecon系统有效利用LLM和RAG获取网络威胁情报，并通过知识图谱实现了高水平的可解释性，提高了模型推理的透明度，有助于分析师理解系统决策。"}}
{"id": "2511.05210", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05210", "abs": "https://arxiv.org/abs/2511.05210", "authors": ["André Peter Kelm", "Max Braeschke", "Emre Gülsoylu", "Simone Frintrop"], "title": "Walk the Lines 2: Contour Tracking for Detailed Segmentation", "comment": "11 pages, 6 figures. Accepted at CAIP 2025: 21st International\n  Conference on Computer Analysis of Images and Patterns, Las Palmas de Gran\n  Canaria, Spain, September 22-25, 2025. To appear in: Proceedings Part I,\n  Lecture Notes in Computer Science (LNCS), Springer Nature Switzerland", "summary": "This paper presents Walk the Lines 2 (WtL2), a unique contour tracking\nalgorithm specifically adapted for detailed segmentation of infrared (IR) ships\nand various objects in RGB.1 This extends the original Walk the Lines (WtL)\n[12], which focused solely on detailed ship segmentation in color. These\ninnovative WtLs can replace the standard non-maximum suppression (NMS) by using\ncontour tracking to refine the object contour until a 1-pixel-wide closed shape\ncan be binarized, forming a segmentable area in foreground-background\nscenarios. WtL2 broadens the application range of WtL beyond its original\nscope, adapting to IR and expanding to diverse objects within the RGB context.\nTo achieve IR segmentation, we adapt its input, the object contour detector, to\nIR ships. In addition, the algorithm is enhanced to process a wide range of RGB\nobjects, outperforming the latest generation of contour-based methods when\nachieving a closed object contour, offering high peak Intersection over Union\n(IoU) with impressive details. This positions WtL2 as a compelling method for\nspecialized applications that require detailed segmentation or high-quality\nsamples, potentially accelerating progress in several niche areas of image\nsegmentation.", "AI": {"tldr": "本文提出了Walk the Lines 2 (WtL2)，一种独特的轮廓跟踪算法，专门用于红外(IR)舰船和RGB图像中各种物体的精细分割，它通过轮廓跟踪替代NMS，实现了高IoU和详细的分割效果。", "motivation": "原有的Walk the Lines (WtL)算法仅专注于彩色图像中的舰船精细分割。研究动机在于将该方法扩展到红外图像中的舰船分割，并应用于RGB图像中的多种不同物体，同时通过轮廓跟踪改进标准的非极大值抑制(NMS)方法以获得更精细的分割。", "method": "WtL2通过轮廓跟踪来精细化物体轮廓，直到形成一个1像素宽的闭合形状，从而替代了NMS，并在前景-背景场景中形成可分割区域。为实现红外分割，算法调整了其输入（物体轮廓检测器）以适应红外舰船。此外，算法也进行了增强，以处理更广泛的RGB物体。", "result": "WtL2在红外舰船和各种RGB物体的分割中表现出色，在实现闭合物体轮廓方面优于最新一代的基于轮廓的方法，提供了高峰值交并比(IoU)和令人印象深刻的细节。", "conclusion": "WtL2是一种引人注目的方法，适用于需要精细分割或高质量样本的专业应用，有望加速图像分割领域中几个小众区域的进展。"}}
{"id": "2511.05219", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05219", "abs": "https://arxiv.org/abs/2511.05219", "authors": ["Jiang Lin", "Xinyu Chen", "Song Wu", "Zhiqiu Zhang", "Jizhi Zhang", "Ye Wang", "Qiang Tang", "Qian Wang", "Jian Yang", "Zili Yi"], "title": "FreeControl: Efficient, Training-Free Structural Control via One-Step Attention Extraction", "comment": "Accepted by NIPS 2025", "summary": "Controlling the spatial and semantic structure of diffusion-generated images\nremains a challenge. Existing methods like ControlNet rely on handcrafted\ncondition maps and retraining, limiting flexibility and generalization.\nInversion-based approaches offer stronger alignment but incur high inference\ncost due to dual-path denoising. We present FreeControl, a training-free\nframework for semantic structural control in diffusion models. Unlike prior\nmethods that extract attention across multiple timesteps, FreeControl performs\none-step attention extraction from a single, optimally chosen key timestep and\nreuses it throughout denoising. This enables efficient structural guidance\nwithout inversion or retraining. To further improve quality and stability, we\nintroduce Latent-Condition Decoupling (LCD): a principled separation of the key\ntimestep and the noised latent used in attention extraction. LCD provides finer\ncontrol over attention quality and eliminates structural artifacts. FreeControl\nalso supports compositional control via reference images assembled from\nmultiple sources - enabling intuitive scene layout design and stronger prompt\nalignment. FreeControl introduces a new paradigm for test-time control,\nenabling structurally and semantically aligned, visually coherent generation\ndirectly from raw images, with the flexibility for intuitive compositional\ndesign and compatibility with modern diffusion models at approximately 5\npercent additional cost.", "AI": {"tldr": "FreeControl是一个无需训练的框架，通过一步注意力提取和潜在条件解耦（LCD），实现扩散模型中高效且高质量的语义结构控制，支持组合式设计，成本低廉。", "motivation": "现有扩散模型结构控制方法存在局限性：ControlNet依赖手工条件图和重新训练，缺乏灵活性和泛化性；基于反演的方法虽然对齐性强，但由于双路径去噪导致推理成本高昂。", "method": "FreeControl采用以下方法：1. 一步注意力提取：从单个最优关键时间步提取注意力，并在整个去噪过程中重复使用，无需反演或重新训练。2. 潜在条件解耦（LCD）：将关键时间步与用于注意力提取的噪声潜在空间分离，以提高注意力质量并消除结构伪影。3. 组合式控制：支持通过多源参考图像进行组合式控制，实现场景布局设计和更强的提示对齐。", "result": "FreeControl在不进行训练的情况下，实现了结构和语义对齐、视觉连贯的图像生成。它提供了直观的组合设计灵活性，与现代扩散模型兼容，且仅增加约5%的额外成本。该方法解决了现有方法的效率和灵活性问题。", "conclusion": "FreeControl为测试时控制引入了一种新范式，能够直接从原始图像生成结构和语义对齐、视觉连贯的图像，并具有灵活的组合设计能力和对现代扩散模型的兼容性，且成本极低。"}}
{"id": "2511.05485", "categories": ["cs.CL", "I.2.7; I.5.1"], "pdf": "https://arxiv.org/pdf/2511.05485", "abs": "https://arxiv.org/abs/2511.05485", "authors": ["Yuexin Wu", "Shiqi Wang", "Vasile Rus"], "title": "MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis", "comment": "19", "summary": "Disease diagnosis is a central pillar of modern healthcare, enabling early\ndetection and timely intervention for acute conditions while guiding lifestyle\nadjustments and medication regimens to prevent or slow chronic disease.\nSelf-reports preserve clinically salient signals that templated electronic\nhealth record (EHR) documentation often attenuates or omits, especially subtle\nbut consequential details. To operationalize this shift, we introduce\nMIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge\nnotes and natively aligned to WHO ICD-11 terminology. We further present\nLL-Rank, a likelihood-based re-ranking framework that computes a\nlength-normalized joint likelihood of each label given the clinical report\ncontext and subtracts the corresponding report-free prior likelihood for that\nlabel. Across seven model backbones, LL-Rank consistently outperforms a strong\ngeneration-plus-mapping baseline (GenMap). Ablation experiments show that\nLL-Rank's gains primarily stem from its PMI-based scoring, which isolates\nsemantic compatibility from label frequency bias.", "AI": {"tldr": "该研究引入了MIMIC-SR-ICD11数据集和LL-Rank重排序框架，以利用EHR出院记录进行疾病诊断，并解决了传统EHR信息丢失和标签频率偏差问题，显著提高了诊断准确性。", "motivation": "现代医疗中疾病诊断至关重要，但模板化的电子健康记录（EHR）常会削弱或遗漏关键的临床信号，特别是细微但重要的细节。研究旨在通过利用更丰富的临床报告信息来改进诊断。", "method": "1. 构建了MIMIC-SR-ICD11数据集：一个大型英文诊断数据集，基于EHR出院记录并与WHO ICD-11术语对齐。2. 提出了LL-Rank：一个基于似然的重排序框架，它计算给定临床报告上下文的每个标签的长度归一化联合似然，并减去该标签对应的无报告先验似然，以基于PMI（点互信息）进行评分。", "result": "LL-Rank在七种模型骨干上均持续优于强大的生成-映射基线（GenMap）。消融实验表明，LL-Rank的性能提升主要源于其基于PMI的评分机制，该机制能够将语义兼容性与标签频率偏差分离。", "conclusion": "通过引入新的数据集和LL-Rank重排序框架，该研究成功地利用临床报告上下文提高了疾病诊断的准确性，并且LL-Rank的PMI评分机制在解决标签频率偏差方面表现出色，为更精确的诊断提供了有效工具。"}}
{"id": "2511.05245", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05245", "abs": "https://arxiv.org/abs/2511.05245", "authors": ["Xincheng Yao", "Yan Luo", "Zefeng Qian", "Chongyang Zhang"], "title": "ADPretrain: Advancing Industrial Anomaly Detection via Anomaly Representation Pretraining", "comment": "Accepted by NeurIPS 2025", "summary": "The current mainstream and state-of-the-art anomaly detection (AD) methods\nare substantially established on pretrained feature networks yielded by\nImageNet pretraining. However, regardless of supervised or self-supervised\npretraining, the pretraining process on ImageNet does not match the goal of\nanomaly detection (i.e., pretraining in natural images doesn't aim to\ndistinguish between normal and abnormal). Moreover, natural images and\nindustrial image data in AD scenarios typically have the distribution shift.\nThe two issues can cause ImageNet-pretrained features to be suboptimal for AD\ntasks. To further promote the development of the AD field, pretrained\nrepresentations specially for AD tasks are eager and very valuable. To this\nend, we propose a novel AD representation learning framework specially designed\nfor learning robust and discriminative pretrained representations for\nindustrial anomaly detection. Specifically, closely surrounding the goal of\nanomaly detection (i.e., focus on discrepancies between normals and anomalies),\nwe propose angle- and norm-oriented contrastive losses to maximize the angle\nsize and norm difference between normal and abnormal features simultaneously.\nTo avoid the distribution shift from natural images to AD images, our\npretraining is performed on a large-scale AD dataset, RealIAD. To further\nalleviate the potential shift between pretraining data and downstream AD\ndatasets, we learn the pretrained AD representations based on the\nclass-generalizable representation, residual features. For evaluation, based on\nfive embedding-based AD methods, we simply replace their original features with\nour pretrained representations. Extensive experiments on five AD datasets and\nfive backbones consistently show the superiority of our pretrained features.\nThe code is available at https://github.com/xcyao00/ADPretrain.", "AI": {"tldr": "本文提出了一种专门为工业异常检测设计的新型预训练表示学习框架，通过在大型AD数据集上使用角度和范数导向的对比损失，学习鲁棒且具有区分性的特征，显著优于基于ImageNet预训练的现有方法。", "motivation": "当前的异常检测(AD)方法严重依赖于ImageNet预训练的特征网络，但ImageNet预训练的目标与AD任务不匹配（不旨在区分正常与异常），且自然图像与工业图像之间存在分布偏移，导致ImageNet预训练特征对AD任务次优。", "method": "本文提出了一种新颖的AD表示学习框架，专注于学习工业异常检测的鲁棒和判别性预训练表示。具体方法包括：1) 提出角度和范数导向的对比损失，以同时最大化正常和异常特征之间的角度和范数差异；2) 在大型AD数据集RealIAD上进行预训练，以避免自然图像的分布偏移；3) 基于类别泛化表示（残差特征）学习预训练的AD表示，以进一步缓解预训练数据和下游AD数据集之间的潜在偏移。", "result": "通过在五种嵌入式AD方法中简单替换其原始特征为本文提出的预训练表示，并在五个AD数据集和五个骨干网络上进行了广泛实验，结果一致表明本文预训练特征的优越性。", "conclusion": "本文提出的专门为异常检测任务设计的预训练表示学习框架，能够学习到更适合工业异常检测任务的鲁棒和判别性特征，显著提升了现有AD方法的性能，克服了ImageNet预训练的局限性。"}}
{"id": "2511.05293", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05293", "abs": "https://arxiv.org/abs/2511.05293", "authors": ["Rui Yan", "Yibo Li", "Han Ding", "Fei Wang"], "title": "Cross-domain EEG-based Emotion Recognition with Contrastive Learning", "comment": "5 pages", "summary": "Electroencephalogram (EEG)-based emotion recognition is vital for affective\ncomputing but faces challenges in feature utilization and cross-domain\ngeneralization. This work introduces EmotionCLIP, which reformulates\nrecognition as an EEG-text matching task within the CLIP framework. A tailored\nbackbone, SST-LegoViT, captures spatial, spectral, and temporal features using\nmulti-scale convolution and Transformer modules. Experiments on SEED and\nSEED-IV datasets show superior cross-subject accuracies of 88.69% and 73.50%,\nand cross-time accuracies of 88.46% and 77.54%, outperforming existing models.\nResults demonstrate the effectiveness of multimodal contrastive learning for\nrobust EEG emotion recognition.", "AI": {"tldr": "该研究引入EmotionCLIP模型，通过将EEG情绪识别重构为EEG-文本匹配任务，利用CLIP框架和SST-LegoViT骨干网络，显著提升了EEG情绪识别的跨被试和跨时间泛化能力。", "motivation": "EEG情绪识别在情感计算中至关重要，但面临特征利用不足和跨域泛化能力差的挑战。", "method": "该工作将EEG情绪识别重新定义为EEG-文本匹配任务，并将其整合到CLIP框架中。提出EmotionCLIP模型，其核心是SST-LegoViT骨干网络，该网络利用多尺度卷积和Transformer模块捕获EEG信号的空间、频谱和时间特征。通过多模态对比学习进行训练。", "result": "在SEED和SEED-IV数据集上，EmotionCLIP模型在跨被试准确率上分别达到88.69%和73.50%，在跨时间准确率上分别达到88.46%和77.54%，均优于现有模型。", "conclusion": "研究结果表明，多模态对比学习对于实现鲁棒的EEG情绪识别是有效的。"}}
{"id": "2511.05489", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05489", "abs": "https://arxiv.org/abs/2511.05489", "authors": ["Junwen Pan", "Qizhe Zhang", "Rui Zhang", "Ming Lu", "Xin Wan", "Yuan Zhang", "Chang Liu", "Qi She"], "title": "TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning", "comment": "22 pages, 17 figures. Official code:\n  https://github.com/Time-Search/TimeSearch-R", "summary": "Temporal search aims to identify a minimal set of relevant frames from tens\nof thousands based on a given query, serving as a foundation for accurate\nlong-form video understanding. Existing works attempt to progressively narrow\nthe search space. However, these approaches typically rely on a hand-crafted\nsearch process, lacking end-to-end optimization for learning optimal search\nstrategies. In this paper, we propose TimeSearch-R, which reformulates temporal\nsearch as interleaved text-video thinking, seamlessly integrating searching\nvideo clips into the reasoning process through reinforcement learning (RL).\nHowever, applying RL training methods, such as Group Relative Policy\nOptimization (GRPO), to video reasoning can result in unsupervised intermediate\nsearch decisions. This leads to insufficient exploration of the video content\nand inconsistent logical reasoning. To address these issues, we introduce GRPO\nwith Completeness Self-Verification (GRPO-CSV), which gathers searched video\nframes from the interleaved reasoning process and utilizes the same policy\nmodel to verify the adequacy of searched frames, thereby improving the\ncompleteness of video reasoning. Additionally, we construct datasets\nspecifically designed for the SFT cold-start and RL training of GRPO-CSV,\nfiltering out samples with weak temporal dependencies to enhance task\ndifficulty and improve temporal search capabilities. Extensive experiments\ndemonstrate that TimeSearch-R achieves significant improvements on temporal\nsearch benchmarks such as Haystack-LVBench and Haystack-Ego4D, as well as\nlong-form video understanding benchmarks like VideoMME and MLVU. Notably,\nTimeSearch-R establishes a new state-of-the-art on LongVideoBench with 4.1%\nimprovement over the base model Qwen2.5-VL and 2.0% over the advanced video\nreasoning model Video-R1. Our code is available at\nhttps://github.com/Time-Search/TimeSearch-R.", "AI": {"tldr": "本文提出TimeSearch-R，通过强化学习将时间搜索重构为交错的文本-视频思考，并引入GRPO-CSV机制以提高搜索决策的完整性和视频推理的一致性，从而在长视频理解任务上取得显著提升。", "motivation": "现有时间搜索方法依赖手工搜索过程，缺乏端到端优化以学习最佳搜索策略，导致视频内容探索不足和逻辑推理不一致，影响长视频理解的准确性。", "method": "本文提出TimeSearch-R，将时间搜索重新定义为交错的文本-视频思考，并通过强化学习（RL）将视频片段搜索无缝整合到推理过程中。为解决RL训练中中间搜索决策的无监督问题，引入了带有完整性自验证（GRPO-CSV）的GRPO，该方法通过策略模型验证已搜索帧的充分性，提高推理完整性。此外，构建了专门用于SFT冷启动和RL训练的数据集，过滤掉弱时间依赖样本以增强任务难度。", "result": "TimeSearch-R在Haystack-LVBench和Haystack-Ego4D等时间搜索基准以及VideoMME和MLVU等长视频理解基准上均实现了显著改进。在LongVideoBench上，TimeSearch-R建立了新的最先进水平，相较于基线模型Qwen2.5-VL提升4.1%，相较于先进视频推理模型Video-R1提升2.0%。", "conclusion": "TimeSearch-R通过将时间搜索重构为强化学习驱动的文本-视频交错思考，并结合GRPO-CSV的完整性自验证机制，有效解决了现有方法的局限性，显著提升了长视频理解和时间搜索的性能，达到了新的SOTA水平。"}}
{"id": "2511.05407", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05407", "abs": "https://arxiv.org/abs/2511.05407", "authors": ["Yahui Fu", "Zi Haur Pang", "Tatsuya Kawahara"], "title": "Minority-Aware Satisfaction Estimation in Dialogue Systems via Preference-Adaptive Reinforcement Learning", "comment": "IJCNLP-AACL 2025 (Main)", "summary": "User satisfaction in dialogue systems is inherently subjective. When the same\nresponse strategy is applied across users, minority users may assign different\nsatisfaction ratings than majority users due to variations in individual\nintents and preferences. However, existing alignment methods typically train\none-size-fits-all models that aim for broad consensus, often overlooking\nminority perspectives and user-specific adaptation. We propose a unified\nframework that models both individual- and group-level preferences for user\nsatisfaction estimation. First, we introduce Chain-of-Personalized-Reasoning\n(CoPeR) to capture individual preferences through interpretable reasoning\nchains. Second, we propose an expectation-maximization-based Majority-Minority\nPreference-Aware Clustering (M2PC) algorithm that discovers distinct user\ngroups in an unsupervised manner to learn group-level preferences. Finally, we\nintegrate these components into a preference-adaptive reinforcement learning\nframework (PAda-PPO) that jointly optimizes alignment with both individual and\ngroup preferences. Experiments on the Emotional Support Conversation dataset\ndemonstrate consistent improvements in user satisfaction estimation,\nparticularly for underrepresented user groups.", "AI": {"tldr": "本研究提出一个统一框架，通过建模个体和群体偏好来估计对话系统中的用户满意度，特别关注少数用户群体的需求，并利用个性化推理链、无监督聚类和偏好自适应强化学习实现。", "motivation": "对话系统中用户满意度具有主观性，现有方法通常训练“一刀切”模型，忽略了少数用户群体的独特意图和偏好，导致其满意度评分与多数用户不同，未能实现用户特定适应。", "method": "1. 引入Chain-of-Personalized-Reasoning (CoPeR) 来通过可解释的推理链捕获个体偏好。 2. 提出基于期望最大化的Majority-Minority Preference-Aware Clustering (M2PC) 算法，以无监督方式发现不同的用户群体，学习群体级偏好。 3. 将这些组件整合到偏好自适应强化学习框架 (PAda-PPO) 中，共同优化与个体和群体偏好的对齐。", "result": "在情感支持对话数据集上的实验表明，用户满意度估计得到持续改进，特别是对于代表性不足的用户群体。", "conclusion": "该统一框架通过同时建模个体和群体偏好，有效提高了对话系统中用户满意度的估计，尤其改善了对少数用户群体的服务，解决了“一刀切”模型的局限性。"}}
{"id": "2511.05408", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05408", "abs": "https://arxiv.org/abs/2511.05408", "authors": ["Constanza Fierro", "Fabien Roger"], "title": "Steering Language Models with Weight Arithmetic", "comment": null, "summary": "Providing high-quality feedback to Large Language Models (LLMs) on a diverse\ntraining distribution can be difficult and expensive, and providing feedback\nonly on a narrow distribution can result in unintended generalizations. To\nbetter leverage narrow training data, we propose contrastive weight steering, a\nsimple post-training method that edits the model parameters using weight\narithmetic. We isolate a behavior direction in weight-space by subtracting the\nweight deltas from two small fine-tunes -- one that induces the desired\nbehavior and another that induces its opposite -- and then add or remove this\ndirection to modify the model's weights. We apply this technique to mitigate\nsycophancy and induce misalignment, and find that weight steering often\ngeneralizes further than activation steering, achieving stronger\nout-of-distribution behavioral control before degrading general capabilities.\nWe also show that, in the context of task-specific fine-tuning, weight steering\ncan partially mitigate undesired behavioral drift: it can reduce sycophancy and\nunder-refusals introduced during fine-tuning while preserving task performance\ngains. Finally, we provide preliminary evidence that emergent misalignment can\nbe detected by measuring the similarity between fine-tuning updates and an\n\"evil\" weight direction, suggesting that it may be possible to monitor the\nevolution of weights during training and detect rare misaligned behaviors that\nnever manifest during training or evaluations.", "AI": {"tldr": "本文提出对比权重转向（contrastive weight steering），一种简单的后训练方法，通过权重算术编辑LLM参数，以更好地利用窄分布训练数据，控制特定行为。该方法在泛化能力上优于激活转向，并能部分缓解微调过程中不期望的行为漂移，同时初步显示出检测潜在未对齐行为的能力。", "motivation": "为大型语言模型（LLMs）提供高质量、多样化的反馈既困难又昂贵，而仅在狭窄分布上提供反馈可能导致意外的泛化。因此，需要一种方法来更好地利用狭窄的训练数据，并在模型训练后有效控制或修改特定行为。", "method": "提出对比权重转向方法。通过对模型进行两次小规模微调（一次诱导期望行为，另一次诱导其反向行为），然后减去两次微调产生的权重增量，从而在权重空间中分离出特定行为方向。最后，通过添加或移除这个方向来修改模型的权重。", "result": "1. 权重转向在缓解谄媚行为和诱导未对齐方面，泛化能力通常优于激活转向，在不损害通用能力的前提下实现更强的域外行为控制。\n2. 在特定任务微调中，权重转向能部分缓解不期望的行为漂移（如减少微调引入的谄媚和拒绝不足），同时保持任务性能提升。\n3. 初步证据表明，通过测量微调更新与一个“邪恶”权重方向的相似性，可以检测到紧急未对齐行为，这为在训练期间监控权重演变和检测罕见未对齐行为提供了可能性。", "conclusion": "对比权重转向是一种有效的后训练方法，能够利用有限数据在LLMs中实现对特定行为的精确控制，其泛化能力优于激活转向，并能有效缓解微调过程中的负面行为漂移。此外，该方法还为检测潜在的、训练中未显现的未对齐行为提供了新的视角。"}}
{"id": "2511.05319", "categories": ["cs.CV", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.05319", "abs": "https://arxiv.org/abs/2511.05319", "authors": ["Huanqi Wu", "Huangbiao Xu", "Runfeng Xie", "Jiaxin Cai", "Kaixin Zhang", "Xiao Ke"], "title": "$\\mathbf{S^2LM}$: Towards Semantic Steganography via Large Language Models", "comment": "35 Pages, 20 Figures", "summary": "Although steganography has made significant advancements in recent years, it\nstill struggles to embed semantically rich, sentence-level information into\ncarriers. However, in the era of AIGC, the capacity of steganography is more\ncritical than ever. In this work, we present Sentence-to-Image Steganography,\nan instance of Semantic Steganography, a novel task that enables the hiding of\narbitrary sentence-level messages within a cover image. Furthermore, we\nestablish a benchmark named Invisible Text (IVT), comprising a diverse set of\nsentence-level texts as secret messages for evaluation. Finally, we present\n$\\mathbf{S^2LM}$: Semantic Steganographic Language Model, which utilizes large\nlanguage models (LLMs) to embed high-level textual information, such as\nsentences or even paragraphs, into images. Unlike traditional bit-level\ncounterparts, $\\mathrm{S^2LM}$ enables the integration of semantically rich\ncontent through a newly designed pipeline in which the LLM is involved\nthroughout the entire process. Both quantitative and qualitative experiments\ndemonstrate that our method effectively unlocks new semantic steganographic\ncapabilities for LLMs. The source code will be released soon.", "AI": {"tldr": "本文提出了一种名为“语句到图像隐写术”的新任务，利用大型语言模型（LLMs）将语义丰富的句子级信息嵌入到图像中，并引入了S^2LM模型和IVT基准。", "motivation": "尽管隐写术取得了进展，但仍难以将语义丰富的句子级信息嵌入载体。在AIGC时代，隐写术的容量变得前所未有的重要，促使研究人员探索更高容量的语义隐写方法。", "method": "本文提出了“语句到图像隐写术”（一种语义隐写术），并建立了名为“Invisible Text (IVT)”的基准，用于评估句子级秘密消息。核心方法是S^2LM（Semantic Steganographic Language Model），该模型利用大型语言模型（LLMs）通过全新设计的流水线将高层文本信息（如句子或段落）嵌入图像，LLM贯穿整个过程。", "result": "定量和定性实验均表明，S^2LM方法有效地为LLMs解锁了新的语义隐写能力，能够成功地将语义丰富的内容集成到图像中。", "conclusion": "S^2LM模型通过利用LLMs，解决了传统隐写术在嵌入语义丰富、句子级信息方面的不足，开辟了将高层文本信息隐藏在图像中的新途径，极大地提升了隐写术的语义容量。"}}
{"id": "2511.05369", "categories": ["cs.CV", "I.2.10; I.4.8; I.5.4"], "pdf": "https://arxiv.org/pdf/2511.05369", "abs": "https://arxiv.org/abs/2511.05369", "authors": ["Shiyao Xu", "Benedetta Liberatori", "Gül Varol", "Paolo Rota"], "title": "Dense Motion Captioning", "comment": "12 pages, 5 figures, accepted to 3DV 2026", "summary": "Recent advances in 3D human motion and language integration have primarily\nfocused on text-to-motion generation, leaving the task of motion understanding\nrelatively unexplored. We introduce Dense Motion Captioning, a novel task that\naims to temporally localize and caption actions within 3D human motion\nsequences. Current datasets fall short in providing detailed temporal\nannotations and predominantly consist of short sequences featuring few actions.\nTo overcome these limitations, we present the Complex Motion Dataset (CompMo),\nthe first large-scale dataset featuring richly annotated, complex motion\nsequences with precise temporal boundaries. Built through a carefully designed\ndata generation pipeline, CompMo includes 60,000 motion sequences, each\ncomposed of multiple actions ranging from at least two to ten, accurately\nannotated with their temporal extents. We further present DEMO, a model that\nintegrates a large language model with a simple motion adapter, trained to\ngenerate dense, temporally grounded captions. Our experiments show that DEMO\nsubstantially outperforms existing methods on CompMo as well as on adapted\nbenchmarks, establishing a robust baseline for future research in 3D motion\nunderstanding and captioning.", "AI": {"tldr": "该论文提出了“密集运动描述”的新任务，旨在对3D人体运动序列中的动作进行时序定位和描述。为此，作者创建了首个大规模复杂运动数据集CompMo，并开发了结合大型语言模型和运动适配器的DEMO模型，在多项基准测试中表现出色，为3D运动理解和描述奠定了基础。", "motivation": "当前3D人体运动与语言结合的研究主要集中在文本到运动生成，而运动理解任务相对未被充分探索。现有数据集缺乏详细的时间注释，且多为动作较少的短序列，无法支持复杂的运动理解任务。", "method": "引入了“密集运动描述”的新任务，旨在对3D人体运动序列中的动作进行时序定位和描述。构建了CompMo数据集，包含60,000个具有精确时间边界和多动作（2到10个）注释的复杂运动序列。开发了DEMO模型，该模型将大型语言模型与一个简单的运动适配器集成，用于生成密集的、时间定位的描述。", "result": "CompMo是第一个具有丰富注释、复杂运动序列和精确时间边界的大规模数据集。实验表明，DEMO模型在CompMo以及其他改编的基准测试中，显著优于现有方法。", "conclusion": "该研究为3D运动理解和描述任务建立了强大的基线，并通过引入新任务、新数据集和高性能模型，推动了该领域未来研究的发展。"}}
{"id": "2511.05356", "categories": ["cs.CV", "I.2.10; I.4.6; I.5.1; I.5.4"], "pdf": "https://arxiv.org/pdf/2511.05356", "abs": "https://arxiv.org/abs/2511.05356", "authors": ["Manuel Gomes", "Bogdan Raducanu", "Miguel Oliveira"], "title": "Canonical Space Representation for 4D Panoptic Segmentation of Articulated Objects", "comment": "32 pages, 6 figures, 4 tables, submitted to Expert Systems With\n  Applications", "summary": "Articulated object perception presents significant challenges in computer\nvision, particularly because most existing methods ignore temporal dynamics\ndespite the inherently dynamic nature of such objects. The use of 4D temporal\ndata has not been thoroughly explored in articulated object perception and\nremains unexamined for panoptic segmentation. The lack of a benchmark dataset\nfurther hurt this field. To this end, we introduce Artic4D as a new dataset\nderived from PartNet Mobility and augmented with synthetic sensor data,\nfeaturing 4D panoptic annotations and articulation parameters. Building on this\ndataset, we propose CanonSeg4D, a novel 4D panoptic segmentation framework.\nThis approach explicitly estimates per-frame offsets mapping observed object\nparts to a learned canonical space, thereby enhancing part-level segmentation.\nThe framework employs this canonical representation to achieve consistent\nalignment of object parts across sequential frames. Comprehensive experiments\non Artic4D demonstrate that the proposed CanonSeg4D outperforms state of the\nart approaches in panoptic segmentation accuracy in more complex scenarios.\nThese findings highlight the effectiveness of temporal modeling and canonical\nalignment in dynamic object understanding, and pave the way for future advances\nin 4D articulated object perception.", "AI": {"tldr": "本文引入了Artic4D数据集，并提出了CanonSeg4D框架，用于解决4D铰接物体全景分割中忽略时间动态和缺乏基准数据集的问题。", "motivation": "现有方法在铰接物体感知中忽视时间动态，且4D时间数据在全景分割中未被充分探索。此外，该领域缺乏一个基准数据集。", "method": "引入了Artic4D数据集，该数据集基于PartNet Mobility并增加了合成传感器数据，包含4D全景标注和关节参数。提出了CanonSeg4D框架，该框架显式估计每帧偏移，将观察到的物体部件映射到学习到的规范空间，并利用此规范表示实现跨序列帧的物体部件一致对齐。", "result": "在Artic4D数据集上的综合实验表明，所提出的CanonSeg4D在更复杂场景中的全景分割精度优于现有最先进的方法。", "conclusion": "这些发现强调了时间建模和规范对齐在动态物体理解中的有效性，并为4D铰接物体感知领域的未来发展铺平了道路。"}}
{"id": "2511.05421", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05421", "abs": "https://arxiv.org/abs/2511.05421", "authors": ["Aupendu Kar", "Krishnendu Ghosh", "Prabir Kumar Biswas"], "title": "Sharing the Learned Knowledge-base to Estimate Convolutional Filter Parameters for Continual Image Restoration", "comment": "This paper has been accepted to ACM ICVGIP 2025", "summary": "Continual learning is an emerging topic in the field of deep learning, where\na model is expected to learn continuously for new upcoming tasks without\nforgetting previous experiences. This field has witnessed numerous\nadvancements, but few works have been attempted in the direction of image\nrestoration. Handling large image sizes and the divergent nature of various\ndegradation poses a unique challenge in the restoration domain. However,\nexisting works require heavily engineered architectural modifications for new\ntask adaptation, resulting in significant computational overhead.\nRegularization-based methods are unsuitable for restoration, as different\nrestoration challenges require different kinds of feature processing. In this\ndirection, we propose a simple modification of the convolution layer to adapt\nthe knowledge from previous restoration tasks without touching the main\nbackbone architecture. Therefore, it can be seamlessly applied to any deep\narchitecture without any structural modifications. Unlike other approaches, we\ndemonstrate that our model can increase the number of trainable parameters\nwithout significantly increasing computational overhead or inference time.\nExperimental validation demonstrates that new restoration tasks can be\nintroduced without compromising the performance of existing tasks. We also show\nthat performance on new restoration tasks improves by adapting the knowledge\nfrom the knowledge base created by previous restoration tasks. The code is\navailable at https://github.com/aupendu/continual-restore.", "AI": {"tldr": "本文提出了一种针对图像修复的持续学习方法，通过简单修改卷积层，无需改变主干网络即可适应新任务，有效避免了遗忘，提高了新任务性能，且计算开销小。", "motivation": "持续学习在深度学习领域备受关注，但在图像修复方面的研究较少。图像修复面临独特的挑战，如处理大尺寸图像和多样的降级类型。现有方法常需要对网络架构进行大量修改以适应新任务，导致巨大的计算开销；而基于正则化的方法不适用于需要不同特征处理的修复任务。", "method": "本文提出对卷积层进行简单修改，使其能够从先前的修复任务中学习知识，而无需触及主干网络架构。这种方法可以无缝集成到任何深度架构中，无需结构性改动。与现有方法不同，它在增加可训练参数的同时，并未显著增加计算开销或推理时间。", "result": "实验验证表明，模型能够在引入新修复任务的同时，不损害现有任务的性能。通过适应从先前修复任务知识库中获得的知识，模型在新修复任务上的性能得到了提升。该方法在增加参数的同时，保持了较低的计算开销和推理时间。", "conclusion": "通过对卷积层的简单修改，本文成功实现了图像修复领域的持续学习。该方法避免了对主干架构的重度修改和高计算开销，同时有效防止了遗忘，并通过知识适应提升了新任务的性能，为图像修复的持续学习提供了一种高效且普适的解决方案。"}}
{"id": "2511.05432", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05432", "abs": "https://arxiv.org/abs/2511.05432", "authors": ["Dogucan Yaman", "Seymanur Akti", "Fevziye Irem Eyiokur", "Alexander Waibel"], "title": "Shared Latent Representation for Joint Text-to-Audio-Visual Synthesis", "comment": null, "summary": "We propose a text-to-talking-face synthesis framework leveraging latent\nspeech representations from HierSpeech++. A Text-to-Vec module generates\nWav2Vec2 embeddings from text, which jointly condition speech and face\ngeneration. To handle distribution shifts between clean and TTS-predicted\nfeatures, we adopt a two-stage training: pretraining on Wav2Vec2 embeddings and\nfinetuning on TTS outputs. This enables tight audio-visual alignment, preserves\nspeaker identity, and produces natural, expressive speech and synchronized\nfacial motion without ground-truth audio at inference. Experiments show that\nconditioning on TTS-predicted latent features outperforms cascaded pipelines,\nimproving both lip-sync and visual realism.", "AI": {"tldr": "本文提出一个基于HierSpeech++潜在语音表示的文本到说话人脸合成框架，通过两阶段训练处理特征分布偏移，实现了无需真实音频的自然、富有表现力的语音和同步面部动作。", "motivation": "旨在从文本生成自然的说话人脸，实现紧密的音视频对齐、保持说话人身份，并生成富有表现力的语音和同步面部动作，同时解决干净特征和TTS预测特征之间的分布偏移问题。", "method": "该框架利用HierSpeech++的潜在语音表示。一个Text-to-Vec模块从文本生成Wav2Vec2嵌入，共同条件化语音和人脸生成。为处理干净特征与TTS预测特征之间的分布偏移，采用两阶段训练：首先在Wav2Vec2嵌入上预训练，然后在TTS输出上微调。", "result": "该方法在推理时无需真实音频，实现了紧密的音视频对齐，保留了说话人身份，并生成了自然、富有表现力的语音和同步的面部动作。实验表明，条件化于TTS预测的潜在特征优于级联管线，提升了唇语同步和视觉真实感。", "conclusion": "所提出的框架通过利用潜在语音表示和两阶段训练策略，能够有效地从文本合成自然的说话人脸，并在唇语同步和视觉真实感方面优于传统级联方法。"}}
{"id": "2511.05449", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05449", "abs": "https://arxiv.org/abs/2511.05449", "authors": ["Tuan Anh Tran", "Duy M. H. Nguyen", "Hoai-Chau Tran", "Michael Barz", "Khoa D. Doan", "Roger Wattenhofer", "Ngo Anh Vien", "Mathias Niepert", "Daniel Sonntag", "Paul Swoboda"], "title": "How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?", "comment": "Accepted at NeurIPS 2025", "summary": "Recent advances in 3D point cloud transformers have led to state-of-the-art\nresults in tasks such as semantic segmentation and reconstruction. However,\nthese models typically rely on dense token representations, incurring high\ncomputational and memory costs during training and inference. In this work, we\npresent the finding that tokens are remarkably redundant, leading to\nsubstantial inefficiency. We introduce gitmerge3D, a globally informed graph\ntoken merging method that can reduce the token count by up to 90-95% while\nmaintaining competitive performance. This finding challenges the prevailing\nassumption that more tokens inherently yield better performance and highlights\nthat many current models are over-tokenized and under-optimized for\nscalability. We validate our method across multiple 3D vision tasks and show\nconsistent improvements in computational efficiency. This work is the first to\nassess redundancy in large-scale 3D transformer models, providing insights into\nthe development of more efficient 3D foundation architectures. Our code and\ncheckpoints are publicly available at https://gitmerge3d.github.io", "AI": {"tldr": "本文发现3D点云Transformer模型中的tokens存在高度冗余，导致计算和内存成本高昂。作者提出了gitmerge3D方法，通过全局图token合并将token数量减少90-95%，同时保持竞争力，显著提高了计算效率。", "motivation": "3D点云Transformer模型在语义分割和重建等任务中取得了最先进的成果，但其通常依赖密集的token表示，导致训练和推理期间计算和内存成本高昂。", "method": "作者提出了gitmerge3D，一种全局感知图token合并方法。该方法旨在识别并减少冗余token的数量，以提高效率。", "result": "研究发现tokens存在显著冗余。gitmerge3D能够将token数量减少高达90-95%，同时保持有竞争力的性能。这挑战了“更多tokens意味着更好性能”的普遍假设，并表明许多现有模型存在过度token化和可扩展性优化不足的问题。该方法在多个3D视觉任务中都显示出计算效率的持续提升。", "conclusion": "这项工作首次评估了大规模3D Transformer模型中的冗余性，为开发更高效的3D基础架构提供了见解。研究强调了在不牺牲性能的情况下通过token合并大幅提高效率的可能性。"}}
{"id": "2511.05461", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05461", "abs": "https://arxiv.org/abs/2511.05461", "authors": ["Olivier Dietrich", "Merlin Alfredsson", "Emilia Arens", "Nando Metzger", "Torben Peters", "Linus Scheibenreif", "Jan Dirk Wegner", "Konrad Schindler"], "title": "The Potential of Copernicus Satellites for Disaster Response: Retrieving Building Damage from Sentinel-1 and Sentinel-2", "comment": null, "summary": "Natural disasters demand rapid damage assessment to guide humanitarian\nresponse. Here, we investigate whether medium-resolution Earth observation\nimages from the Copernicus program can support building damage assessment,\ncomplementing very-high resolution imagery with often limited availability. We\nintroduce xBD-S12, a dataset of 10,315 pre- and post-disaster image pairs from\nboth Sentinel-1 and Sentinel-2, spatially and temporally aligned with the\nestablished xBD benchmark. In a series of experiments, we demonstrate that\nbuilding damage can be detected and mapped rather well in many disaster\nscenarios, despite the moderate 10$\\,$m ground sampling distance. We also find\nthat, for damage mapping at that resolution, architectural sophistication does\nnot seem to bring much advantage: more complex model architectures tend to\nstruggle with generalization to unseen disasters, and geospatial foundation\nmodels bring little practical benefit. Our results suggest that Copernicus\nimages are a viable data source for rapid, wide-area damage assessment and\ncould play an important role alongside VHR imagery. We release the xBD-S12\ndataset, code, and trained models to support further research.", "AI": {"tldr": "该研究调查了中分辨率哥白尼地球观测图像（Sentinel-1和Sentinel-2）在建筑损害评估中的应用潜力，并推出了xBD-S12数据集。结果表明，尽管分辨率适中，但这些图像仍能有效进行灾害评估，且复杂模型架构和地理空间基础模型在此任务中优势不明显，证明了哥白尼图像作为快速、广域评估数据源的实用性。", "motivation": "自然灾害发生后，需要快速进行损害评估以指导人道主义响应。然而，超高分辨率（VHR）图像通常可用性有限。因此，研究旨在探索中分辨率地球观测图像（如哥白尼计划）是否能有效支持建筑损害评估，以补充VHR图像。", "method": "研究引入了xBD-S12数据集，其中包含10,315对来自Sentinel-1和Sentinel-2的灾前灾后图像，这些图像与已建立的xBD基准在空间和时间上对齐。通过一系列实验，研究人员评估了使用这些中分辨率图像进行建筑损害检测和映射的有效性。此外，他们还比较了不同模型架构（包括复杂模型和地理空间基础模型）在此任务中的性能和泛化能力。", "result": "实验结果表明，尽管地面采样距离为10米，但建筑损害在许多灾害场景中仍能被很好地检测和映射。研究还发现，在此分辨率下的损害映射任务中，模型架构的复杂性并未带来显著优势：更复杂的模型架构在泛化到未见过的灾害时往往表现不佳，而地理空间基础模型带来的实际效益也很小。", "conclusion": "研究结果表明，哥白尼图像是进行快速、广域损害评估的可行数据源，可以在VHR图像之外发挥重要作用。为了支持进一步研究，xBD-S12数据集、代码和训练模型已公开发布。"}}
{"id": "2511.05393", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05393", "abs": "https://arxiv.org/abs/2511.05393", "authors": ["Zehui Feng", "Tian Qiu", "Tong Wu", "Junxuan Li", "Huayuan Xu", "Ting Han"], "title": "PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Visual Quality Assessment via Preference-Response Disentangled Policy Optimization", "comment": "27 pages, 14 figures, under review as a conference paper", "summary": "Visual Quality Assessment (QA) seeks to predict human perceptual judgments of\nvisual fidelity. While recent multimodal large language models (MLLMs) show\npromise in reasoning about image and video quality, existing approaches mainly\nrely on supervised fine-tuning or rank-only objectives, resulting in shallow\nreasoning, poor score calibration, and limited cross-domain generalization. We\npropose PreResQ-R1, a Preference-Response Disentangled Reinforcement Learning\nframework that unifies absolute score regression and relative ranking\nconsistency within a single reasoning-driven optimization scheme. Unlike prior\nQA methods, PreResQ-R1 introduces a dual-branch reward formulation that\nseparately models intra-sample response coherence and inter-sample preference\nalignment, optimized via Group Relative Policy Optimization (GRPO). This design\nencourages fine-grained, stable, and interpretable chain-of-thought reasoning\nabout perceptual quality. To extend beyond static imagery, we further design a\nglobal-temporal and local-spatial data flow strategy for Video Quality\nAssessment. Remarkably, with reinforcement fine-tuning on only 6K images and\n28K videos, PreResQ-R1 achieves state-of-the-art results across 10 IQA and 5\nVQA benchmarks under both SRCC and PLCC metrics, surpassing by margins of 5.30%\nand textbf2.15% in IQA task, respectively. Beyond quantitative gains, it\nproduces human-aligned reasoning traces that reveal the perceptual cues\nunderlying quality judgments. Code and model are available.", "AI": {"tldr": "PreResQ-R1是一个新颖的偏好-响应解耦强化学习框架，它统一了绝对分数回归和相对排序一致性，用于图像和视频质量评估（IQA/VQA）。该框架通过双分支奖励和GRPO优化，实现了更深层次、可解释的感知质量推理，并在多项基准测试中取得了最先进的性能。", "motivation": "现有的多模态大语言模型（MLLMs）在视觉质量评估（QA）中存在浅层推理、分数校准差和跨领域泛化能力有限的问题，这主要是由于它们主要依赖监督微调或仅排序目标。", "method": "本文提出了PreResQ-R1框架，一个偏好-响应解耦强化学习框架。它在一个推理驱动的优化方案中统一了绝对分数回归和相对排序一致性。该方法引入了一个双分支奖励公式，分别建模样本内响应一致性和样本间偏好对齐，并通过组相对策略优化（GRPO）进行优化。对于视频质量评估，还设计了全局-时间与局部-空间数据流策略。", "result": "通过仅对6K图像和28K视频进行强化微调，PreResQ-R1在10个IQA和5个VQA基准测试中，SRCC和PLCC指标均达到了最先进的结果，在IQA任务中分别超越了5.30%和2.15%。除了量化收益，它还生成了与人类判断一致的推理轨迹，揭示了感知质量判断背后的线索。", "conclusion": "PreResQ-R1通过其独特的偏好-响应解耦强化学习框架，成功解决了现有QA方法在推理深度、分数校准和泛化能力上的局限性。它在多个IQA和VQA基准测试中取得了显著的性能提升，并能生成可解释的、与人类感知一致的推理过程，为视觉质量评估领域带来了新的突破。"}}
{"id": "2511.05403", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05403", "abs": "https://arxiv.org/abs/2511.05403", "authors": ["Zicong Fan", "Edoardo Remelli", "David Dimond", "Fadime Sener", "Liuhao Ge", "Bugra Tekin", "Cem Keskin", "Shreyas Hampali"], "title": "PALM: A Dataset and Baseline for Learning Multi-subject Hand Prior", "comment": null, "summary": "The ability to grasp objects, signal with gestures, and share emotion through\ntouch all stem from the unique capabilities of human hands. Yet creating\nhigh-quality personalized hand avatars from images remains challenging due to\ncomplex geometry, appearance, and articulation, particularly under\nunconstrained lighting and limited views. Progress has also been limited by the\nlack of datasets that jointly provide accurate 3D geometry, high-resolution\nmultiview imagery, and a diverse population of subjects. To address this, we\npresent PALM, a large-scale dataset comprising 13k high-quality hand scans from\n263 subjects and 90k multi-view images, capturing rich variation in skin tone,\nage, and geometry. To show its utility, we present a baseline PALM-Net, a\nmulti-subject prior over hand geometry and material properties learned via\nphysically based inverse rendering, enabling realistic, relightable\nsingle-image hand avatar personalization. PALM's scale and diversity make it a\nvaluable real-world resource for hand modeling and related research.", "AI": {"tldr": "本文介绍了PALM，一个大规模高质量手部数据集，包含1.3万手部扫描和9万多视图图像，并提出了PALM-Net基线模型，通过基于物理的逆渲染实现单图像手部头像个性化。", "motivation": "从图像创建高质量个性化手部化身具有挑战性，原因包括复杂几何、外观、关节运动以及非受限光照和有限视角。此外，缺乏联合提供准确3D几何、高分辨率多视图图像和多样化人群的可用数据集。", "method": "研究团队构建了PALM数据集，包含来自263名受试者的1.3万个高质量手部扫描和9万张多视图图像，涵盖了肤色、年龄和几何形状的丰富多样性。在此基础上，他们提出了一个基线模型PALM-Net，该模型通过基于物理的逆渲染学习了手部几何和材料属性的多主体先验知识。", "result": "PALM数据集成功地捕捉了手部在肤色、年龄和几何上的丰富变化，成为一个大规模、多样化的真实世界资源。PALM-Net基线模型展示了其效用，能够实现逼真、可重新打光的单图像手部化身个性化。", "conclusion": "PALM数据集的规模和多样性使其成为手部建模及相关研究的宝贵资源。PALM-Net证明了该数据集在实现单图像手部化身个性化方面的实用性。"}}
{"id": "2511.05464", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05464", "abs": "https://arxiv.org/abs/2511.05464", "authors": ["Jakub Paplham", "Vojtech Franc"], "title": "Photo Dating by Facial Age Aggregation", "comment": null, "summary": "We introduce a novel method for Photo Dating which estimates the year a\nphotograph was taken by leveraging information from the faces of people present\nin the image. To facilitate this research, we publicly release CSFD-1.6M, a new\ndataset containing over 1.6 million annotated faces, primarily from movie\nstills, with identity and birth year annotations. Uniquely, our dataset\nprovides annotations for multiple individuals within a single image, enabling\nthe study of multi-face information aggregation. We propose a probabilistic\nframework that formally combines visual evidence from modern face recognition\nand age estimation models, and career-based temporal priors to infer the photo\ncapture year. Our experiments demonstrate that aggregating evidence from\nmultiple faces consistently improves the performance and the approach\nsignificantly outperforms strong, scene-based baselines, particularly for\nimages containing several identifiable individuals.", "AI": {"tldr": "本文提出一种利用图像中人脸信息估计照片拍摄年份的新方法，并发布了包含160万标注人脸的CSFD-1.6M数据集。该方法通过概率框架结合人脸识别、年龄估计模型及职业时间先验，实验证明多个人脸信息聚合能显著提升照片年代估计性能，优于基于场景的基线方法。", "motivation": "现有照片年代估计方法可能未能有效利用人脸信息，尤其是在处理包含多个人脸的图像时。研究旨在开发一种更准确的、基于人脸的年代估计方法，并为此提供专门的数据集。", "method": "研究引入了CSFD-1.6M数据集，包含160多万个带身份和出生年份标注的人脸（主要来自电影剧照），并支持单张图像中多个人脸的标注。提出了一种概率框架，该框架形式化地结合了现代人脸识别和年龄估计模型提供的视觉证据，以及基于职业的时间先验信息，以推断照片的拍摄年份。", "result": "实验表明，聚合来自多个人脸的证据能够持续提高照片年代估计的性能。该方法显著优于强大的、基于场景的基线方法，尤其是在包含多个可识别个体的图像中表现更为突出。", "conclusion": "通过利用图像中人脸信息，特别是聚合多个人脸的证据，可以有效且显著地提高照片年代估计的准确性。新提出的概率框架和发布的CSFD-1.6M数据集为该领域的研究提供了新的工具和方向。"}}
{"id": "2511.05491", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05491", "abs": "https://arxiv.org/abs/2511.05491", "authors": ["Rui Yang", "Ziyu Zhu", "Yanwei Li", "Jingjia Huang", "Shen Yan", "Siyuan Zhou", "Zhe Liu", "Xiangtai Li", "Shuangye Li", "Wenqian Wang", "Yi Lin", "Hengshuang Zhao"], "title": "Visual Spatial Tuning", "comment": null, "summary": "Capturing spatial relationships from visual inputs is a cornerstone of\nhuman-like general intelligence. Several previous studies have tried to enhance\nthe spatial awareness of Vision-Language Models (VLMs) by adding extra expert\nencoders, which brings extra overhead and usually harms general capabilities.\nTo enhance the spatial ability in general architectures, we introduce Visual\nSpatial Tuning (VST), a comprehensive framework to cultivate VLMs with\nhuman-like visuospatial abilities, from spatial perception to reasoning. We\nfirst attempt to enhance spatial perception in VLMs by constructing a\nlarge-scale dataset termed VST-P, which comprises 4.1 million samples spanning\n19 skills across single views, multiple images, and videos. Then, we present\nVST-R, a curated dataset with 135K samples that instruct models to reason in\nspace. In particular, we adopt a progressive training pipeline: supervised\nfine-tuning to build foundational spatial knowledge, followed by reinforcement\nlearning to further improve spatial reasoning abilities. Without the\nside-effect to general capabilities, the proposed VST consistently achieves\nstate-of-the-art results on several spatial benchmarks, including $34.8\\%$ on\nMMSI-Bench and $61.2\\%$ on VSIBench. It turns out that the\nVision-Language-Action models can be significantly enhanced with the proposed\nspatial tuning paradigm, paving the way for more physically grounded AI.", "AI": {"tldr": "本文提出VST框架，通过构建大规模空间感知数据集VST-P和空间推理数据集VST-R，并采用监督微调结合强化学习的渐进式训练方法，显著提升了视觉语言模型（VLM）的空间能力，且不损害其通用性，在多个空间基准测试中达到SOTA。", "motivation": "现有方法通过添加额外的专家编码器来增强视觉语言模型（VLM）的空间感知能力，但这会带来额外开销并通常损害模型的通用能力。研究动机在于在通用架构中提升VLM的空间能力，使其具备类人视觉空间智能。", "method": "本文提出了视觉空间调优（Visual Spatial Tuning, VST）框架。首先，构建了大规模空间感知数据集VST-P，包含410万个样本，涵盖单视图、多图像和视频的19种技能。其次，创建了用于空间推理的精选数据集VST-R，包含13.5万个样本。训练方法采用渐进式流水线：先进行监督微调以建立基础空间知识，然后通过强化学习进一步提升空间推理能力。", "result": "所提出的VST方法在不损害模型通用能力的前提下，在多个空间基准测试中持续取得了最先进的结果，包括在MMSI-Bench上达到34.8%，在VSIBench上达到61.2%。实验表明，该空间调优范式能够显著增强视觉-语言-动作模型（VLA）。", "conclusion": "VST范式能够显著提升视觉-语言-动作模型的空间能力，且没有负面影响，为实现更具物理基础的人工智能铺平了道路。"}}
{"id": "2511.05477", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05477", "abs": "https://arxiv.org/abs/2511.05477", "authors": ["Guojie Li", "Anwar P. P. Abdul Majeed", "Muhammad Ateeq", "Anh Nguyen", "Fan Zhang"], "title": "GroupKAN: Rethinking Nonlinearity with Grouped Spline-based KAN Modeling for Efficient Medical Image Segmentation", "comment": null, "summary": "Medical image segmentation requires models that are accurate, lightweight,\nand interpretable. Convolutional architectures lack adaptive nonlinearity and\ntransparent decision-making, whereas Transformer architectures are hindered by\nquadratic complexity and opaque attention mechanisms. U-KAN addresses these\nchallenges using Kolmogorov-Arnold Networks, achieving higher accuracy than\nboth convolutional and attention-based methods, fewer parameters than\nTransformer variants, and improved interpretability compared to conventional\napproaches. However, its O(C^2) complexity due to full-channel transformations\nlimits its scalability as the number of channels increases. To overcome this,\nwe introduce GroupKAN, a lightweight segmentation network that incorporates two\nnovel, structured functional modules: (1) Grouped KAN Transform, which\npartitions channels into G groups for multivariate spline mappings, reducing\ncomplexity to O(C^2/G), and (2) Grouped KAN Activation, which applies shared\nspline-based mappings within each channel group for efficient, token-wise\nnonlinearity. Evaluated on three medical benchmarks (BUSI, GlaS, and CVC),\nGroupKAN achieves an average IoU of 79.80 percent, surpassing U-KAN by +1.11\npercent while requiring only 47.6 percent of the parameters (3.02M vs 6.35M),\nand shows improved interpretability.", "AI": {"tldr": "GroupKAN是一种轻量级、可解释的医学图像分割网络，通过引入分组的KAN变换和激活模块，解决了U-KAN模型的计算复杂度问题，同时在性能和参数效率上超越了U-KAN。", "motivation": "医学图像分割模型需要准确、轻量且可解释。现有模型存在局限：卷积网络缺乏自适应非线性和透明决策；Transformer模型存在二次复杂度问题和不透明的注意力机制。U-KAN虽然在准确性和可解释性方面表现良好，但其全通道变换导致的O(C^2)复杂度限制了其可扩展性。", "method": "本文提出了GroupKAN，一个轻量级分割网络，包含两个新颖的结构化功能模块：(1) 分组KAN变换（Grouped KAN Transform），将通道分成G组进行多元样条映射，将复杂度从O(C^2)降低到O(C^2/G)；(2) 分组KAN激活（Grouped KAN Activation），在每个通道组内应用共享的基于样条的映射，实现高效的逐令牌非线性。", "result": "在BUSI、GlaS和CVC三个医学基准测试中，GroupKAN平均IoU达到79.80%，比U-KAN高出+1.11%。同时，GroupKAN所需的参数量仅为U-KAN的47.6%（3.02M vs 6.35M），并且展现出更高的可解释性。", "conclusion": "GroupKAN通过引入分组机制，成功克服了U-KAN的计算复杂度和可扩展性限制，在保持和提高分割精度的同时，显著降低了模型参数量，并增强了可解释性，是医学图像分割领域的一个有效且高效的解决方案。"}}
{"id": "2511.05292", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05292", "abs": "https://arxiv.org/abs/2511.05292", "authors": ["Jiaxi Yin", "Pengcheng Wang", "Han Ding", "Fei Wang"], "title": "What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable IMUs", "comment": "5 pages", "summary": "Accurate food intake detection is vital for dietary monitoring and chronic\ndisease prevention. Traditional self-report methods are prone to recall bias,\nwhile camera-based approaches raise concerns about privacy. Furthermore,\nexisting wearable-based methods primarily focus on a limited number of food\ntypes, such as hamburgers and pizza, failing to address the vast diversity of\nChinese cuisine. To bridge this gap, we propose CuisineSense, a system that\nclassifies Chinese food types by integrating hand motion cues from a smartwatch\nwith head dynamics from smart glasses. To filter out irrelevant daily\nactivities, we design a two-stage detection pipeline. The first stage\nidentifies eating states by distinguishing characteristic temporal patterns\nfrom non-eating behaviors. The second stage then conducts fine-grained food\ntype recognition based on the motions captured during food intake. To evaluate\nCuisineSense, we construct a dataset comprising 27.5 hours of IMU recordings\nacross 11 food categories and 10 participants. Experiments demonstrate that\nCuisineSense achieves high accuracy in both eating state detection and food\nclassification, offering a practical solution for unobtrusive, wearable-based\ndietary monitoring.The system code is publicly available at\nhttps://github.com/joeeeeyin/CuisineSense.git.", "AI": {"tldr": "本文提出了CuisineSense系统，通过整合智能手表的手部运动和智能眼镜的头部动态，实现了对多种中餐食物类型的分类，解决了传统方法和现有可穿戴设备在饮食监测中的局限性。", "motivation": "传统的自我报告饮食监测方法存在回忆偏差，基于摄像头的方法引发隐私担忧，而现有可穿戴设备主要关注有限的食物类型（如汉堡和披萨），无法满足种类繁多的中餐监测需求。因此，研究旨在弥补这一空白，提供一种准确、无侵入性的可穿戴饮食监测方案。", "method": "CuisineSense系统结合智能手表（手部运动）和智能眼镜（头部动态）的数据进行食物类型分类。它采用两阶段检测流程：第一阶段通过区分进食和非进食行为的特征时间模式来识别进食状态；第二阶段则根据进食期间捕获的运动进行精细的食物类型识别。为评估系统，研究构建了一个包含11种食物类别、10名参与者、共计27.5小时IMU记录的数据集。", "result": "实验结果表明，CuisineSense系统在进食状态检测和食物分类方面均取得了高准确率。", "conclusion": "CuisineSense系统为无侵入式、基于可穿戴设备的饮食监测提供了一个实用的解决方案，特别适用于中餐等多样化饮食的监测。"}}
{"id": "2511.05474", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05474", "abs": "https://arxiv.org/abs/2511.05474", "authors": ["Xian-Hong Huang", "Hui-Kai Su", "Chi-Chia Sun", "Jun-Wei Hsieh"], "title": "Semantic-Guided Natural Language and Visual Fusion for Cross-Modal Interaction Based on Tiny Object Detection", "comment": null, "summary": "This paper introduces a cutting-edge approach to cross-modal interaction for\ntiny object detection by combining semantic-guided natural language processing\nwith advanced visual recognition backbones. The proposed method integrates the\nBERT language model with the CNN-based Parallel Residual Bi-Fusion Feature\nPyramid Network (PRB-FPN-Net), incorporating innovative backbone architectures\nsuch as ELAN, MSP, and CSP to optimize feature extraction and fusion. By\nemploying lemmatization and fine-tuning techniques, the system aligns semantic\ncues from textual inputs with visual features, enhancing detection precision\nfor small and complex objects. Experimental validation using the COCO and\nObjects365 datasets demonstrates that the model achieves superior performance.\nOn the COCO2017 validation set, it attains a 52.6% average precision (AP),\noutperforming YOLO-World significantly while maintaining half the parameter\nconsumption of Transformer-based models like GLIP. Several test on different of\nbackbones such ELAN, MSP, and CSP further enable efficient handling of\nmulti-scale objects, ensuring scalability and robustness in\nresource-constrained environments. This study underscores the potential of\nintegrating natural language understanding with advanced backbone\narchitectures, setting new benchmarks in object detection accuracy, efficiency,\nand adaptability to real-world challenges.", "AI": {"tldr": "该论文提出了一种结合语义引导的自然语言处理（BERT）和先进视觉骨干网络（PRB-FPN-Net，包含ELAN、MSP、CSP等架构）的跨模态交互方法，用于微小目标检测。该方法通过对齐文本语义线索与视觉特征，显著提升了小而复杂目标的检测精度，并在COCO和Objects365数据集上表现优异，超越YOLO-World且参数量远低于GLIP。", "motivation": "研究动机是为了提高微小和复杂目标的检测精度，通过将文本输入的语义线索与视觉特征对齐，尤其是在资源受限的环境中，以增强目标检测的准确性、效率和适应性。", "method": "所提出的方法将BERT语言模型与基于CNN的并行残差双融合特征金字塔网络（PRB-FPN-Net）相结合。它整合了ELAN、MSP和CSP等创新的骨干架构以优化特征提取和融合。通过词形还原和微调技术，系统将文本输入的语义线索与视觉特征对齐。", "result": "该模型在COCO2017验证集上取得了52.6%的平均精度（AP），显著优于YOLO-World，同时参数消耗仅为GLIP等基于Transformer模型的一半。对ELAN、MSP和CSP等不同骨干网络的测试进一步证实了其高效处理多尺度目标的能力，确保了在资源受限环境中的可扩展性和鲁棒性。", "conclusion": "这项研究强调了将自然语言理解与先进骨干架构相结合的潜力，为目标检测的准确性、效率和对现实世界挑战的适应性树立了新的基准。"}}
{"id": "2511.05162", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05162", "abs": "https://arxiv.org/abs/2511.05162", "authors": ["Jan-Thorsten Peter", "David Vilar", "Tobias Domhan", "Dan Malkin", "Markus Freitag"], "title": "Mind the Gap... or Not? How Translation Errors and Evaluation Details Skew Multilingual Results", "comment": null, "summary": "Most current large language models (LLMs) support a wide variety of languages\nin addition to English, including high-resource languages (e.g. German,\nChinese, French), as well as low-resource ones (e.g. Swahili, Telugu). In\naddition they have also shown impressive capabilities in different domains,\nlike coding, science and math. In this short paper, taking math as an example\ndomain, we study the performance of different LLMs across languages.\nExperimental results show that there exists a non-negligible and consistent gap\nin the performance of the models across languages. Interestingly, and somewhat\nagainst expectations, the gap exists for both high- and low-resource languages.\nWe hope that these results influence further research into cross-lingual\ncapability generalization for next generation LLMs. If it weren't for the fact\nthat they are false! By analyzing one of the standard multilingual math\nbenchmarks (MGSM), we determine that several translation errors are present in\nthe data. Furthermore, the lack of standardized answer extraction from LLM\noutputs further influences the final results. We propose a method for automatic\nquality assurance to address the first issue at scale, and give recommendations\nto address the second one. Combining these two approaches we show that the\naforementioned language gap mostly disappears, leading to completely different\nconclusions from our research. We additionally release the corrected dataset to\nthe community.", "AI": {"tldr": "本文发现大型语言模型在多语言数学基准测试中表现出的跨语言性能差距，主要是由于基准数据集中的翻译错误和答案提取方法不标准造成的。通过纠正这些问题，发现该差距基本消失。", "motivation": "当前大型语言模型支持多种语言和领域，但作者观察到模型在不同语言间存在性能差距，尤其是在数学领域。他们怀疑现有基准测试可能存在问题，并希望深入探究这种跨语言能力的泛化性。", "method": "研究分析了标准多语言数学基准测试(MGSM)，发现数据中存在翻译错误，并指出LLM输出的答案提取缺乏标准化。为此，他们提出了一种自动质量保证方法来解决数据错误，并给出了标准化答案提取的建议。此外，他们还发布了修正后的数据集。", "result": "实验结果显示，最初观察到的模型在不同语言（包括高资源和低资源语言）之间存在的显著且一致的性能差距，在应用自动质量保证方法并标准化答案提取后，基本消失了。这导致与之前研究完全不同的结论。", "conclusion": "研究表明，大型语言模型在多语言数学基准测试中表现出的跨语言性能差距，很大程度上是由于基准数据集的翻译错误和不标准的答案提取方法造成的。纠正这些问题后，模型在不同语言间的性能差距几乎消失，这暗示了LLM可能具有比预期更好的跨语言能力泛化性。作者发布了修正后的数据集，以促进未来的研究。"}}
{"id": "2511.05467", "categories": ["cs.CV", "76T10, 68T07", "I.2.10; I.4.8; I.4.9"], "pdf": "https://arxiv.org/pdf/2511.05467", "abs": "https://arxiv.org/abs/2511.05467", "authors": ["Sanghyeon Chang", "Srikar Arani", "Nishant Sai Nuthalapati", "Youngjoon Suh", "Nicholas Choi", "Siavash Khodakarami", "Md Rakibul Hasan Roni", "Nenad Miljkovic", "Aparna Chandramowlishwaran", "Yoonjin Won"], "title": "EventFlow: Real-Time Neuromorphic Event-Driven Classification of Two-Phase Boiling Flow Regimes", "comment": "19 pages, 6 figures, Under review in Droplet (Manuscript ID:\n  DRO-2025-0045.R1)", "summary": "Flow boiling is an efficient heat transfer mechanism capable of dissipating\nhigh heat loads with minimal temperature variation, making it an ideal thermal\nmanagement method. However, sudden shifts between flow regimes can disrupt\nthermal performance and system reliability, highlighting the need for accurate\nand low-latency real-time monitoring. Conventional optical imaging methods are\nlimited by high computational demands and insufficient temporal resolution,\nmaking them inadequate for capturing transient flow behavior. To address this,\nwe propose a real-time framework based on signals from neuromorphic sensors for\nflow regime classification. Neuromorphic sensors detect changes in brightness\nat individual pixels, which typically correspond to motion at edges, enabling\nfast and efficient detection without full-frame reconstruction, providing\nevent-based information. We develop five classification models using both\ntraditional image data and event-based data, demonstrating that models\nleveraging event data outperform frame-based approaches due to their\nsensitivity to dynamic flow features. Among these models, the event-based long\nshort-term memory model provides the best balance between accuracy and speed,\nachieving 97.6% classification accuracy with a processing time of 0.28 ms. Our\nasynchronous processing pipeline supports continuous, low-latency predictions\nand delivers stable output through a majority voting mechanisms, enabling\nreliable real-time feedback for experimental control and intelligent thermal\nmanagement.", "AI": {"tldr": "本研究提出了一种基于脉冲神经形态传感器信号的实时流态分类框架，用于监测流体沸腾，其事件驱动数据和LSTM模型在准确性和速度上均优于传统方法，实现了低延迟、高可靠的实时反馈。", "motivation": "流体沸腾是高效的传热机制，但流态的突然转变会影响热性能和系统可靠性，因此需要准确、低延迟的实时监测。传统光学成像方法计算需求高且时间分辨率不足，无法捕捉瞬态流体行为。", "method": "研究提出一个基于脉冲神经形态传感器的实时流态分类框架。该传感器通过检测像素亮度变化（对应边缘运动）提供事件驱动信息，无需全帧重建。研究开发了五种分类模型，分别使用传统图像数据和事件驱动数据，并重点采用了基于事件的长短期记忆（LSTM）模型。通过多数投票机制实现异步处理管道，提供连续、低延迟的预测。", "result": "实验证明，利用事件驱动数据的模型优于基于帧的方法，因为它们对动态流体特征更敏感。其中，基于事件的LSTM模型在准确性和速度之间取得了最佳平衡，实现了97.6%的分类准确率和0.28毫秒的处理时间。异步处理管道支持连续、低延迟的预测，并通过多数投票机制提供稳定的输出。", "conclusion": "基于脉冲神经形态传感器和事件驱动数据的实时框架，能够实现对流体沸腾流态的可靠、低延迟分类，为实验控制和智能热管理提供了有效的实时反馈，克服了传统方法的局限性。"}}
