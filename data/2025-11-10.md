<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 8]
- [cs.CV](#cs.CV) [Total: 67]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.RO](#cs.RO) [Total: 26]
- [eess.SY](#eess.SY) [Total: 12]
- [eess.IV](#eess.IV) [Total: 4]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024](https://arxiv.org/abs/2511.04685)
*Daniela Guericke,Rolf van der Hulst,Asal Karimpour,Ieke Schrader,Matthias Walter*

Main category: cs.AI

TL;DR: 本文介绍了Twente团队在2024年综合医疗排班竞赛中获得第三名的算法、实现和结果，该方法结合了混合整数规划、约束规划和模拟退火，并首次提供了基准实例的最优解下界。


<details>
  <summary>Details</summary>
Motivation: 参与2024年综合医疗排班竞赛并取得优异成绩，同时分享团队的见解，并为基准实例提供最优解的下界，以推动该领域的发展。

Method: 采用三阶段解决方案，基于子问题分解，结合了混合整数规划（MIP）、约束规划（CP）和模拟退火（SA）三种技术。

Result: 在竞赛中获得第三名，分享了设计决策和见解，并首次为基准实例提供了最优解的下界。

Conclusion: 所提出的结合MIP、CP和SA的三阶段分解方法是有效的，并且指出了未来可以进一步改进该方法的开放性问题。

Abstract: We report about the algorithm, implementation and results submitted to the
Integrated Healthcare Timetabling Competition 2024 by Team Twente, which scored
third in the competition. Our approach combines mixed-integer programming,
constraint programming and simulated annealing in a 3-phase solution approach
based on decomposition into subproblems. Next to describing our approach and
describing our design decisions, we share our insights and, for the first time,
lower bounds on the optimal solution values for the benchmark instances. We
finally highlight open problems for which we think that addressing them could
improve our approach even further.

</details>


### [2] [DMA: Online RAG Alignment with Human Feedback](https://arxiv.org/abs/2511.04880)
*Yu Bai,Yukai Miao,Dawei Wang,Li Chen,Fei Long,Rundi Zhai,Dan Li,Yanyu Ren,Tianfeng Liu,Hongtao Xie,Ce Yang,Xuhui Cai*

Main category: cs.AI

TL;DR: DMA是一个在线学习框架，通过整合多粒度人工反馈来动态调整RAG系统的检索排名，以适应不断变化的意图和内容漂移。


<details>
  <summary>Details</summary>
Motivation: RAG系统常依赖静态检索，这限制了其适应不断变化的意图和内容漂移的能力。

Method: DMA（动态记忆对齐）框架通过一个连贯的学习流程整合多粒度（文档、列表、响应级别）的人工反馈：对点式和列表式排序器进行监督训练，通过响应级别偏好驱动策略优化，并将知识蒸馏到轻量级评分器中以实现低延迟服务。评估采用双轨协议：大规模在线A/B测试和知识密集型基准上的少样本离线测试。

Result: 在线评估显示，经过数月的工业部署，DMA显著提升了用户参与度。离线评估表明，DMA在保持基础检索竞争力的同时，在对话式问答（TriviaQA, HotpotQA）上取得了显著提升。

Conclusion: DMA是一种原则性的方法，可以在不牺牲基线能力的情况下，通过反馈驱动的方式实现RAG系统的实时适应。

Abstract: Retrieval-augmented generation (RAG) systems often rely on static retrieval,
limiting adaptation to evolving intent and content drift. We introduce Dynamic
Memory Alignment (DMA), an online learning framework that systematically
incorporates multi-granularity human feedback to align ranking in interactive
settings. DMA organizes document-, list-, and response-level signals into a
coherent learning pipeline: supervised training for pointwise and listwise
rankers, policy optimization driven by response-level preferences, and
knowledge distillation into a lightweight scorer for low-latency serving.
Throughout this paper, memory refers to the model's working memory, which is
the entire context visible to the LLM for In-Context Learning.
  We adopt a dual-track evaluation protocol mirroring deployment: (i)
large-scale online A/B ablations to isolate the utility of each feedback
source, and (ii) few-shot offline tests on knowledge-intensive benchmarks.
Online, a multi-month industrial deployment further shows substantial
improvements in human engagement. Offline, DMA preserves competitive
foundational retrieval while yielding notable gains on conversational QA
(TriviaQA, HotpotQA). Taken together, these results position DMA as a
principled approach to feedback-driven, real-time adaptation in RAG without
sacrificing baseline capability.

</details>


### [3] [Epistemic Reject Option Prediction](https://arxiv.org/abs/2511.04855)
*Vojtech Franc,Jakub Paplham*

Main category: cs.AI

TL;DR: 本文提出了一种基于贝叶斯学习的“认知拒绝选项预测器”，通过最小化预期遗憾来重新定义最优预测器，使其能够在训练数据不足导致认知不确定性高时选择拒绝预测，从而识别不可靠的输入。


<details>
  <summary>Details</summary>
Motivation: 在高风险应用中，预测模型不仅需要准确，还需要量化不确定性。传统的拒绝选项方法仅关注偶然不确定性，假设在数据量大时认知不确定性可忽略。然而，在许多实际场景中，数据有限，这一假设不成立，模型需要能够识别因数据不足而无法做出可靠决策的输入。

Method: 该研究引入了“认知拒绝选项预测器”，其在数据不足导致高认知不确定性的区域选择拒绝。它基于贝叶斯学习，将最优预测器重新定义为最小化预期遗憾（学习模型与完全了解数据分布的贝叶斯最优预测器之间的性能差距）的预测器。当给定输入的遗憾超过设定的拒绝成本时，模型将选择拒绝。

Result: 本文提出了一个原理性框架，使得学习型预测器能够识别训练数据不足以做出可靠决策的输入。据作者所知，这是首个能够实现此功能的框架。

Conclusion: 该论文提供了一个开创性的、有原则的框架，使预测器能够识别由于训练数据不足而无法做出可靠决策的输入，解决了传统拒绝选项方法在处理有限数据下认知不确定性方面的局限性。

Abstract: In high-stakes applications, predictive models must not only produce accurate
predictions but also quantify and communicate their uncertainty. Reject-option
prediction addresses this by allowing the model to abstain when prediction
uncertainty is high. Traditional reject-option approaches focus solely on
aleatoric uncertainty, an assumption valid only when large training data makes
the epistemic uncertainty negligible. However, in many practical scenarios,
limited data makes this assumption unrealistic. This paper introduces the
epistemic reject-option predictor, which abstains in regions of high epistemic
uncertainty caused by insufficient data. Building on Bayesian learning, we
redefine the optimal predictor as the one that minimizes expected regret -- the
performance gap between the learned model and the Bayes-optimal predictor with
full knowledge of the data distribution. The model abstains when the regret for
a given input exceeds a specified rejection cost. To our knowledge, this is the
first principled framework that enables learning predictors capable of
identifying inputs for which the training data is insufficient to make reliable
decisions.

</details>


### [4] [Real-Time Reasoning Agents in Evolving Environments](https://arxiv.org/abs/2511.04898)
*Yule Wen,Yixin Ye,Yanzhe Zhang,Diyi Yang,Hao Zhu*

Main category: cs.AI

TL;DR: 本文提出“实时推理”作为代理在动态环境中进行及时且逻辑判断的新问题，并构建Real-Time Reasoning Gym。研究发现现有语言模型难以应对，为此提出AgileThinker，通过同时结合反应式和规划式推理，有效平衡推理深度和响应延迟，在任务难度和时间压力增加时表现更优。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的代理不仅需要逻辑判断，还需要及时判断，这要求它们持续感知动态环境。尽管语言模型推理取得了进展，但现有方法未能考虑这种动态性，无法在推理进行中应对环境变化（如危险出现、机会产生、其他代理行动）。

Method: 1. 引入“实时推理”作为代理在不断演变环境中的新问题。2. 构建“Real-Time Reasoning Gym”以进行演示和研究。3. 研究了两种部署语言模型的范式：反应式代理（有限计算，快速响应）和规划式代理（扩展计算，解决复杂问题）。4. 提出AgileThinker，该方法同时结合了反应式和规划式两种推理范式。

Result: 1. 即使是先进的语言模型，在反应式和规划式两种范式下，都难以做出逻辑且及时的判断。2. AgileThinker在任务难度和时间压力增加时，始终优于仅采用单一推理范式的代理。3. AgileThinker有效地平衡了推理深度和响应延迟。

Conclusion: 1. 实时推理是开发实用代理的关键测试平台。2. 本工作为时间受限AI系统的研究奠定了基础。3. 强调了实现实时能力代理的路径。

Abstract: Agents in the real world must make not only logical but also timely
judgments. This requires continuous awareness of the dynamic environment:
hazards emerge, opportunities arise, and other agents act, while the agent's
reasoning is still unfolding. Despite advances in language model reasoning,
existing approaches fail to account for this dynamic nature. We introduce
real-time reasoning as a new problem formulation for agents in evolving
environments and build Real-Time Reasoning Gym to demonstrate it. We study two
paradigms for deploying language models in agents: (1) reactive agents, which
employ language models with bounded reasoning computation for rapid responses,
and (2) planning agents, which allow extended reasoning computation for complex
problems. Our experiments show that even state-of-the-art models struggle with
making logical and timely judgments in either paradigm. To address this
limitation, we propose AgileThinker, which simultaneously engages both
reasoning paradigms. AgileThinker consistently outperforms agents engaging only
one reasoning paradigm as the task difficulty and time pressure rise,
effectively balancing reasoning depth and response latency. Our work
establishes real-time reasoning as a critical testbed for developing practical
agents and provides a foundation for research in temporally constrained AI
systems, highlighting a path toward real-time capable agents.

</details>


### [5] [ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property](https://arxiv.org/abs/2511.04956)
*Maria Mahbub,Vanessa Lama,Sanjay Das,Brian Starks,Christopher Polchek,Saffell Silvers,Lauren Deck,Prasanna Balaprakash,Tirthankar Ghosal*

Main category: cs.AI

TL;DR: ORCHID是一个模块化代理系统，结合检索增强生成（RAG）和人工监督，用于美国能源部（DOE）高风险财产（HRP）分类，旨在提高准确性和可追溯性，以应对不断变化的出口管制政策。


<details>
  <summary>Details</summary>
Motivation: 美国能源部（DOE）现场的敏感双用途设备库存需要准确的高风险财产（HRP）分类，但传统的专家工作流程耗时、易积压，且难以跟上不断变化的出口管制政策和法规。

Method: 该研究展示了ORCHID系统，一个模块化的代理系统，通过检索增强生成（RAG）与人工监督相结合，生成基于政策的、可审计的分类结果。它由多个协作代理（检索、描述优化、分类器、验证器、反馈记录器）组成，这些代理通过代理间消息进行协调，并通过模型上下文协议（MCP）调用工具以实现模型无关的本地操作。系统遵循“项目到证据到决策”的循环，提供逐步推理、政策引文和可追加的审计包。

Result: 在真实HRP案例的初步测试中，ORCHID相比非代理基线提高了分类准确性和可追溯性，并能将不确定项转交给主题专家（SME）处理。演示展示了单项提交、有依据的引用、SME反馈捕获以及可导出的审计工件。

Conclusion: ORCHID系统为敏感的美国能源部合规工作流程中，实现值得信赖的大型语言模型（LLM）辅助提供了一条切实可行的途径，提高了分类效率和审计能力。

Abstract: High-Risk Property (HRP) classification is critical at U.S. Department of
Energy (DOE) sites, where inventories include sensitive and often dual-use
equipment. Compliance must track evolving rules designated by various export
control policies to make transparent and auditable decisions. Traditional
expert-only workflows are time-consuming, backlog-prone, and struggle to keep
pace with shifting regulatory boundaries. We demo ORCHID, a modular agentic
system for HRP classification that pairs retrieval-augmented generation (RAG)
with human oversight to produce policy-based outputs that can be audited. Small
cooperating agents, retrieval, description refiner, classifier, validator, and
feedback logger, coordinate via agent-to-agent messaging and invoke tools
through the Model Context Protocol (MCP) for model-agnostic on-premise
operation. The interface follows an Item to Evidence to Decision loop with
step-by-step reasoning, on-policy citations, and append-only audit bundles
(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID
improves accuracy and traceability over a non-agentic baseline while deferring
uncertain items to Subject Matter Experts (SMEs). The demonstration shows
single item submission, grounded citations, SME feedback capture, and
exportable audit artifacts, illustrating a practical path to trustworthy LLM
assistance in sensitive DOE compliance workflows.

</details>


### [6] [Autonomous generation of different courses of action in mechanized combat operations](https://arxiv.org/abs/2511.05182)
*Johan Schubert,Patrik Hansen,Pontus Hörling,Ronnie Johansson*

Main category: cs.AI

TL;DR: 本文提出了一种支持军事地面作战执行阶段决策的方法论，通过生成和评估机械化营的行动方案，以期获得更优的作战结果。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了在军事地面作战的执行阶段支持决策制定，特别是关于己方行动的决策，旨在生成并评估推荐的行动方案以获得更优结果。

Method: 该方法论首先生成并评估机械化营的初始行动方案集。随后，系统性地产生数千种单独的行动替代方案，并根据预期结果、对手状态、单位组成、兵力比、攻防类型和预期推进速度进行评估。生成和评估过程同时进行，并利用作战手册评估战斗结果和推进速度。该方法支持基于先前评估行动的新方案生成管理，并在战斗演变时，在序贯决策框架内为决策者制定修订的行动方案。

Result: 该方法能够生成并评估数千种具有更优结果的替代行动方案，促进了基于先前评估行动的新方案生成管理。随着战斗的展开和条件的变化，可以为决策者制定修订的行动方案。

Conclusion: 该方法论通过系统性地生成和评估军事地面作战的行动方案，支持在战斗执行阶段的决策制定，并能适应不断变化的作战条件，提供修订的、更优的行动方案。

Abstract: In this paper, we propose a methodology designed to support decision-making
during the execution phase of military ground combat operations, with a focus
on one's actions. This methodology generates and evaluates recommendations for
various courses of action for a mechanized battalion, commencing with an
initial set assessed by their anticipated outcomes. It systematically produces
thousands of individual action alternatives, followed by evaluations aimed at
identifying alternative courses of action with superior outcomes. These
alternatives are appraised in light of the opponent's status and actions,
considering unit composition, force ratios, types of offense and defense, and
anticipated advance rates. Field manuals evaluate battle outcomes and
advancement rates. The processes of generation and evaluation work
concurrently, yielding a variety of alternative courses of action. This
approach facilitates the management of new course generation based on
previously evaluated actions. As the combat unfolds and conditions evolve,
revised courses of action are formulated for the decision-maker within a
sequential decision-making framework.

</details>


### [7] [Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance](https://arxiv.org/abs/2511.05311)
*Valeriu Dimidov,Faisal Hawlader,Sasan Jafarnejad,Raphaël Frank*

Main category: cs.AI

TL;DR: 本文探讨了基于大型语言模型（LLM）的智能体在汽车预测性维护（PdM）数据清洗中的潜力，特别关注维护日志中的错误，并发现LLM在处理通用清洗任务方面表现有效。


<details>
  <summary>Details</summary>
Motivation: 汽车行业预测性维护的推广和发展面临经济限制、数据集稀缺和专业知识不足等挑战。维护日志作为关键数据源，常受错别字、字段缺失、重复条目和日期错误等问题困扰，阻碍了机器学习模型的训练。LLM的最新进展为克服这些障碍提供了机会。

Method: 研究探索了基于LLM的智能体在支持PdM清洗管道中的潜力，特别关注维护日志。通过在涉及六种不同类型噪声（如错别字、缺失字段、近似重复条目和错误日期）的清洗任务上评估LLM智能体。

Result: 研究结果表明，LLM在处理通用清洗任务方面表现有效，为未来的工业应用提供了有前景的基础。尽管处理领域特定的错误仍具挑战性，但这些结果突显了通过专业训练和增强智能体能力来进一步改进的潜力。

Conclusion: LLM为未来的工业PdM应用提供了一个有前景的基础，尤其是在数据清洗方面。尽管领域特定错误仍是挑战，但通过专业训练和增强智能体能力，LLM的潜力可以进一步释放，从而加速PdM从研究到工业实践的转化。

Abstract: Economic constraints, limited availability of datasets for reproducibility
and shortages of specialized expertise have long been recognized as key
challenges to the adoption and advancement of predictive maintenance (PdM) in
the automotive sector. Recent progress in large language models (LLMs) presents
an opportunity to overcome these barriers and speed up the transition of PdM
from research to industrial practice. Under these conditions, we explore the
potential of LLM-based agents to support PdM cleaning pipelines. Specifically,
we focus on maintenance logs, a critical data source for training
well-performing machine learning (ML) models, but one often affected by errors
such as typos, missing fields, near-duplicate entries, and incorrect dates. We
evaluate LLM agents on cleaning tasks involving six distinct types of noise.
Our findings show that LLMs are effective at handling generic cleaning tasks
and offer a promising foundation for future industrial applications. While
domain-specific errors remain challenging, these results highlight the
potential for further improvements through specialized training and enhanced
agentic capabilities.

</details>


### [8] [Reasoning Is All You Need for Urban Planning AI](https://arxiv.org/abs/2511.05375)
*Sijie Yang,Jiatong Li,Filip Biljecki*

Main category: cs.AI

TL;DR: 这篇立场论文提出了一个“代理式城市规划AI框架”，旨在利用推理型AI代理将城市规划从数据预测推进到AI辅助决策，强调基于价值、规则和可解释性的透明推理能力，以增强而非取代人类规划师的判断。


<details>
  <summary>Details</summary>
Motivation: 当前的AI在城市规划分析中擅长从数据中学习模式并预测未来状况，但缺乏透明的推理能力来辅助决策，例如推荐地点、分配资源和评估权衡。作者认为，城市规划决策需要明确的、基于价值、遵守规则且可解释的推理能力，而仅凭统计学习无法满足这些要求。近期推理AI（如CoT、ReAct和多代理协作）的突破使得这一愿景成为可能。

Method: 论文提出了“代理式城市规划AI框架”，该框架通过多代理协作机制整合了三个认知层（感知、基础、推理）和六个逻辑组件（分析、生成、验证、评估、协作、决策）。它强调规划决策需要价值导向（应用规范原则）、规则基础（保证约束满足）和可解释性（生成透明理由）的明确推理能力。论文还比较了推理代理与统计学习，提出了一个全面的架构和基准评估指标，并概述了关键研究挑战。

Result: 论文展示了为什么规划决策需要明确的推理能力（基于价值、规则和可解释性），而统计学习无法单独满足这些要求。它描绘了AI代理如何通过系统地探索解决方案空间、验证法规遵从性以及透明地权衡利弊来增强人类规划师的能力，从而放大计算推理能力，而非取代人类判断。

Conclusion: 该框架表明，AI代理可以通过提供透明、基于推理的决策支持，显著增强人类城市规划，而非取代人类的判断。它为AI辅助城市规划提供了一条前进的道路，并为未来的研究指明了方向。

Abstract: AI has proven highly successful at urban planning analysis -- learning
patterns from data to predict future conditions. The next frontier is
AI-assisted decision-making: agents that recommend sites, allocate resources,
and evaluate trade-offs while reasoning transparently about constraints and
stakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,
ReAct, and multi-agent collaboration frameworks -- now make this vision
achievable.
  This position paper presents the Agentic Urban Planning AI Framework for
reasoning-capable planning agents that integrates three cognitive layers
(Perception, Foundation, Reasoning) with six logic components (Analysis,
Generation, Verification, Evaluation, Collaboration, Decision) through a
multi-agents collaboration framework. We demonstrate why planning decisions
require explicit reasoning capabilities that are value-based (applying
normative principles), rule-grounded (guaranteeing constraint satisfaction),
and explainable (generating transparent justifications) -- requirements that
statistical learning alone cannot fulfill. We compare reasoning agents with
statistical learning, present a comprehensive architecture with benchmark
evaluation metrics, and outline critical research challenges. This framework
shows how AI agents can augment human planners by systematically exploring
solution spaces, verifying regulatory compliance, and deliberating over
trade-offs transparently -- not replacing human judgment but amplifying it with
computational reasoning capabilities.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [9] [IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs](https://arxiv.org/abs/2511.04727)
*Ali Faraz,Akash,Shaharukh Khan,Raja Kolla,Akshat Patidar,Suranjan Goswami,Abhinav Ravi,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

TL;DR: 本文介绍了IndicVisionBench，一个针对印度次大陆文化和语言多样性的新型大规模基准测试，旨在评估现有视觉语言模型（VLMs）在非西方多语言环境中的性能，并发现它们存在显著的性能差距。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型（VLMs）在多模态任务中表现出色，但大多数评估基准仍然以西方为中心，导致其在文化多样和多语言环境（特别是印度次大陆）中的性能表现未知。

Method: 研究者引入了IndicVisionBench，这是一个涵盖英语和10种印度语言的大规模基准测试。该基准包含光学字符识别（OCR）、多模态机器翻译（MMT）和视觉问答（VQA）3种多模态任务（6种问题类型），共约5K张图像和37K+问答对，涉及13个文化主题。此外，还发布了10种印度语言的并行标注语料库。研究评估了8种不同类型的VLM模型。

Result: 实验结果揭示了当前VLM在文化多样性背景下存在显著的性能差距，凸显了它们的局限性。

Conclusion: IndicVisionBench通过关注文化多样性和多语言性，建立了一个可复现的评估框架，为更具包容性的多模态研究铺平了道路，有助于未来开发在不同文化背景下表现更佳的VLM。

Abstract: Vision-language models (VLMs) have demonstrated impressive generalization
across multimodal tasks, yet most evaluation benchmarks remain Western-centric,
leaving open questions about their performance in culturally diverse and
multilingual settings. To address this gap, we introduce IndicVisionBench, the
first large-scale benchmark centered on the Indian subcontinent. Covering
English and 10 Indian languages, our benchmark spans 3 multimodal tasks,
including Optical Character Recognition (OCR), Multimodal Machine Translation
(MMT), and Visual Question Answering (VQA), covering 6 kinds of question types.
Our final benchmark consists of a total of ~5K images and 37K+ QA pairs across
13 culturally grounded topics. In addition, we release a paired parallel corpus
of annotations across 10 Indic languages, creating a unique resource for
analyzing cultural and linguistic biases in VLMs. We evaluate a broad spectrum
of 8 models, from proprietary closed-source systems to open-weights medium and
large-scale models. Our experiments reveal substantial performance gaps,
underscoring the limitations of current VLMs in culturally diverse contexts. By
centering cultural diversity and multilinguality, IndicVisionBench establishes
a reproducible evaluation framework that paves the way for more inclusive
multimodal research.

</details>


### [10] [CPO: Condition Preference Optimization for Controllable Image Generation](https://arxiv.org/abs/2511.04753)
*Zonglin Lyu,Ming Li,Xinxin Liu,Chen Chen*

Main category: cs.CV

TL;DR: 本文提出条件偏好优化（CPO）方法，通过对控制条件而非生成图像进行偏好学习，显著提升了文本到图像生成的可控性，优于现有方法如ControlNet++，并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法如ControlNet++在提升可控性方面存在局限，例如仅优化低噪声时间步，忽略高噪声贡献并引入近似误差。直接偏好优化（DPO）应用于可控性时，难以确保胜负图像对仅在可控性上差异，而其他因素（如图像质量）保持不变，导致训练不稳定。

Method: 提出条件偏好优化（CPO）方法，通过构建胜出和失败的控制信号（$\mathbf{c}^{w}$和$\mathbf{c}^{l}$），训练模型偏好$\mathbf{c}^{w}$。这种方法消除了混杂因素，并产生低方差的训练目标，相比DPO在控制条件而非生成图像上进行偏好学习。

Result: CPO在理论上表现出比DPO更低的对比损失方差，并在实验中取得了卓越结果。它显著提升了可控性，相较于ControlNet++，在分割任务中错误率降低超过10%，人体姿态任务中降低70-80%，边缘和深度图任务中稳定降低2-5%。此外，CPO在数据集整理方面所需计算和存储更少。

Conclusion: CPO通过对控制条件进行偏好学习，有效解决了现有可控性优化方法的局限性，实现了更高的可控性性能和更低的计算成本，显著超越了ControlNet++等最先进方法。

Abstract: To enhance controllability in text-to-image generation, ControlNet introduces
image-based control signals, while ControlNet++ improves pixel-level cycle
consistency between generated images and the input control signal. To avoid the
prohibitive cost of back-propagating through the sampling process, ControlNet++
optimizes only low-noise timesteps (e.g., $t < 200$) using a single-step
approximation, which not only ignores the contribution of high-noise timesteps
but also introduces additional approximation errors. A straightforward
alternative for optimizing controllability across all timesteps is Direct
Preference Optimization (DPO), a fine-tuning method that increases model
preference for more controllable images ($I^{w}$) over less controllable ones
($I^{l}$). However, due to uncertainty in generative models, it is difficult to
ensure that win--lose image pairs differ only in controllability while keeping
other factors, such as image quality, fixed. To address this, we propose
performing preference learning over control conditions rather than generated
images. Specifically, we construct winning and losing control signals,
$\mathbf{c}^{w}$ and $\mathbf{c}^{l}$, and train the model to prefer
$\mathbf{c}^{w}$. This method, which we term \textit{Condition Preference
Optimization} (CPO), eliminates confounding factors and yields a low-variance
training objective. Our approach theoretically exhibits lower contrastive loss
variance than DPO and empirically achieves superior results. Moreover, CPO
requires less computation and storage for dataset curation. Extensive
experiments show that CPO significantly improves controllability over the
state-of-the-art ControlNet++ across multiple control types: over $10\%$ error
rate reduction in segmentation, $70$--$80\%$ in human pose, and consistent
$2$--$5\%$ reductions in edge and depth maps.

</details>


### [11] [Knowledge-based anomaly detection for identifying network-induced shape artifacts](https://arxiv.org/abs/2511.04729)
*Rucha Deshpande,Tahsin Rahman,Miguel Lago,Adarsh Subbaswamy,Jana G. Delfino,Ghada Zamzmi,Elim Thompson,Aldo Badano,Seyed Kahaki*

Main category: cs.CV

TL;DR: 本文提出了一种基于知识的异常检测方法，用于识别合成医学图像中的网络诱导形状伪影，并通过定量评估和读者研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 合成数据在解决机器学习模型数据稀缺方面很有前景，但若缺乏适当的质量评估，可能引入伪影、失真和不真实特征，从而损害模型性能和临床实用性。

Method: 该方法采用两阶段框架：(i) 一个新颖的特征提取器，通过分析解剖边界上角度梯度的图像内分布来构建专门的特征空间；(ii) 一个基于隔离森林的异常检测器。

Result: 该方法在两个合成乳腺X线摄影数据集（CSAW-syn和VMLO-syn）上成功地将伪影集中在最异常的分区（第1百分位），AUC值分别为0.97和0.91。读者研究显示，对于最异常分区，人类读者与算法识别的图像具有66%和68%的平均一致率，是最低异常分区的1.5-2倍。算法与人类排名的Kendall-Tau相关性分别为0.45和0.43。

Conclusion: 该方法是负责任使用合成数据的重要一步，它使开发者能够评估合成图像是否符合已知的解剖学约束，并识别和解决特定问题以提高合成数据集的整体质量。

Abstract: Synthetic data provides a promising approach to address data scarcity for
training machine learning models; however, adoption without proper quality
assessments may introduce artifacts, distortions, and unrealistic features that
compromise model performance and clinical utility. This work introduces a novel
knowledge-based anomaly detection method for detecting network-induced shape
artifacts in synthetic images. The introduced method utilizes a two-stage
framework comprising (i) a novel feature extractor that constructs a
specialized feature space by analyzing the per-image distribution of angle
gradients along anatomical boundaries, and (ii) an isolation forest-based
anomaly detector. We demonstrate the effectiveness of the method for
identifying network-induced shape artifacts in two synthetic mammography
datasets from models trained on CSAW-M and VinDr-Mammo patient datasets
respectively. Quantitative evaluation shows that the method successfully
concentrates artifacts in the most anomalous partition (1st percentile), with
AUC values of 0.97 (CSAW-syn) and 0.91 (VMLO-syn). In addition, a reader study
involving three imaging scientists confirmed that images identified by the
method as containing network-induced shape artifacts were also flagged by human
readers with mean agreement rates of 66% (CSAW-syn) and 68% (VMLO-syn) for the
most anomalous partition, approximately 1.5-2 times higher than the least
anomalous partition. Kendall-Tau correlations between algorithmic and human
rankings were 0.45 and 0.43 for the two datasets, indicating reasonable
agreement despite the challenging nature of subtle artifact detection. This
method is a step forward in the responsible use of synthetic data, as it allows
developers to evaluate synthetic images for known anatomic constraints and
pinpoint and address specific issues to improve the overall quality of a
synthetic dataset.

</details>


### [12] [DARN: Dynamic Adaptive Regularization Networks for Efficient and Robust Foundation Model Adaptation](https://arxiv.org/abs/2511.04766)
*Dhenenjay Yadav,Rohan Sawai*

Main category: cs.CV

TL;DR: 针对地理空间分析中基础模型适应性差的问题，本文提出DARN，一种新型解码器架构，通过动态自适应正则化（包括任务复杂度预测、自适应Dropout和动态容量门控）显著提升了模型在各种适应范式下的性能、泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 基础模型在地理空间分析中潜力巨大，但现有的标准适应方法（无论是全微调还是高效冻结骨干方法）通常采用固定正则化策略的解码器，未能有效应对卫星图像的显著异质性，导致适应效果不佳。

Method: 本文引入了动态自适应正则化网络（DARN），这是一种新颖的解码器架构，包含三项关键创新：1) 轻量级任务复杂度预测器（TCP），用于估计每个样本的难度；2) 自适应Dropout调制（ADM），根据预测复杂度动态调整Dropout率（0.1至0.5）；3) 动态容量门控（DCG），用于调制通道激活。研究还提供了理论依据，将DARN的优化与平稳点收敛及其机制与自适应信息瓶颈联系起来。

Result: DARN在两种主要适应范式下均表现出色。在全微调（骨干未冻结）中，DARN在多任务GeoBench基准测试中达到了新的最先进水平（86.66% mIoU，比先前SOTA提升5.56个百分点）。在高效适应（骨干冻结）中，DARN实现了与SOTA相当的精度（在Sen1Floods11上达到90.5% mIoU），同时在实际部署中展现出显著优势：更优越的域外（OOD）泛化能力（在AI4SmallFarms上mIoU提升9.5个百分点）、增强的鲁棒性（腐败误差相对减少17%）以及在少数类别上的性能提升。

Conclusion: DARN为在关键地理空间应用中利用基础模型提供了一种更智能、更鲁棒、更高效的方法，显著提升了模型在复杂卫星图像环境下的适应性和性能。

Abstract: Foundation models (FMs) offer powerful representations for geospatial
analysis, but adapting them effectively remains challenging. Standard
adaptation methods, whether full fine-tuning or efficient frozen-backbone
approaches, typically employ decoders with fixed regularization strategies,
failing to account for the significant heterogeneity in satellite imagery. We
introduce Dynamic Adaptive Regularization Networks (DARN), a novel decoder
architecture designed to address this limitation. DARN integrates three key
innovations: (1) a lightweight Task Complexity Predictor (TCP) that estimates
per-sample difficulty, (2) Adaptive Dropout Modulation (ADM), dynamically
adjusting dropout rates (from 0.1 to 0.5) based on predicted complexity, and
(3) Dynamic Capacity Gating (DCG) that modulates channel activation. We provide
theoretical justifications linking DARN's optimization to stationary point
convergence and its mechanism to adaptive information bottlenecks. Empirically,
DARN demonstrates exceptional performance across both major adaptation
paradigms. In full fine-tuning (unfrozen backbone), DARN achieves a new
state-of-the-art on the multi-task GeoBench benchmark (86.66% mIoU, +5.56 pp
over prior SOTA). In efficient adaptation (frozen backbone), DARN achieves
SOTA-competitive accuracy (90.5% mIoU on Sen1Floods11) while delivering
substantial advantages crucial for real-world deployment: superior
out-of-distribution (OOD) generalization (+9.5 pp mIoU on AI4SmallFarms),
enhanced robustness (17% relative reduction in corruption error), and improved
performance on minority classes. DARN offers a more intelligent, robust, and
efficient approach to leveraging FMs in critical geospatial applications.

</details>


### [13] [Automatic segmentation of colorectal liver metastases for ultrasound-based navigated resection](https://arxiv.org/abs/2511.05253)
*Tiziano Natali,Karin A. Olthof,Niels F. M. Kok,Koert F. D. Kuhlmann,Theo J. M. Ruers,Matteo Fusaglia*

Main category: cs.CV

TL;DR: 该研究提出了一种基于裁剪3D U-Net的自动3D术中超声（iUS）结直肠肝转移瘤（CRLM）分割方法，实现了接近专家水平的准确性和更快的速度，为肝脏手术提供可靠的实时导航。


<details>
  <summary>Details</summary>
Motivation: 在术中超声（iUS）中准确描绘结直肠肝转移瘤（CRLM）对于实现阴性切缘至关重要，但由于对比度低、噪声和操作员依赖性，目前仍具挑战。自动分割可以提高超声导航工作流程的精确性和效率。

Method: 使用来自85名CRLM患者的85个跟踪3D iUS体积训练和评估了通过nnU-Net框架实现的3D U-Net。比较了两种变体：一种在完整iUS体积上训练，另一种在肿瘤周围裁剪区域上训练。使用Dice相似系数（DSC）、Hausdorff距离（HDist.）和相对体积差异（RVD）在回顾性和前瞻性数据集上评估分割准确性。该工作流程被集成到3D Slicer中以实现实时术中应用。

Result: 裁剪体积模型在所有指标上均显著优于完整体积模型（AUC-ROC = 0.898 vs 0.718）。它实现了中位数DSC = 0.74，召回率 = 0.79，HDist. = 17.1 mm，与半自动分割相当，但执行速度快约4倍（约1分钟）。前瞻性术中测试证实了其稳健和一致的性能，达到临床可接受的实时手术指导准确性。

Conclusion: 使用裁剪3D U-Net进行iUS中CRLM的自动3D分割提供了可靠、接近实时的结果，且操作员输入最少。该方法能够实现高效、免配准的超声引导肝脏手术导航，接近专家级准确性，同时大幅减少手动工作量和手术时间。

Abstract: Introduction: Accurate intraoperative delineation of colorectal liver
metastases (CRLM) is crucial for achieving negative resection margins but
remains challenging using intraoperative ultrasound (iUS) due to low contrast,
noise, and operator dependency. Automated segmentation could enhance precision
and efficiency in ultrasound-based navigation workflows.
  Methods: Eighty-five tracked 3D iUS volumes from 85 CRLM patients were used
to train and evaluate a 3D U-Net implemented via the nnU-Net framework. Two
variants were compared: one trained on full iUS volumes and another on cropped
regions around tumors. Segmentation accuracy was assessed using Dice Similarity
Coefficient (DSC), Hausdorff Distance (HDist.), and Relative Volume Difference
(RVD) on retrospective and prospective datasets. The workflow was integrated
into 3D Slicer for real-time intraoperative use.
  Results: The cropped-volume model significantly outperformed the full-volume
model across all metrics (AUC-ROC = 0.898 vs 0.718). It achieved median DSC =
0.74, recall = 0.79, and HDist. = 17.1 mm comparable to semi-automatic
segmentation but with ~4x faster execution (~ 1 min). Prospective
intraoperative testing confirmed robust and consistent performance, with
clinically acceptable accuracy for real-time surgical guidance.
  Conclusion: Automatic 3D segmentation of CRLM in iUS using a cropped 3D U-Net
provides reliable, near real-time results with minimal operator input. The
method enables efficient, registration-free ultrasound-based navigation for
hepatic surgery, approaching expert-level accuracy while substantially reducing
manual workload and procedure time.

</details>


### [14] [EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear](https://arxiv.org/abs/2511.04779)
*Andrea Aspesi,Andrea Simpsi,Aaron Tognoli,Simone Mentasti,Luca Merigo,Matteo Matteucci*

Main category: cs.CV

TL;DR: 本文提出EETnet，一个专为事件相机设计的眼动追踪卷积神经网络，能够运行在资源受限的微控制器上。


<details>
  <summary>Details</summary>
Motivation: 事件相机因其高效和低功耗特性，在眼动追踪领域日益普及。然而，现有解决方案多依赖强大的GPU进行验证，难以部署到实际的嵌入式设备上，缺乏能在微控制器上运行的低功耗、低延迟方案。

Method: 本文提出了EETnet，一个专门用于纯事件数据眼动追踪的卷积神经网络，旨在微控制器上运行。同时，概述了一套使用公开数据集进行网络训练、评估和量化的方法。EETnet提供两个版本：一个在图像网格上检测瞳孔的分类模型，以及一个在像素级别操作的回归模型。

Result: EETnet是一个能够利用纯事件数据进行眼动追踪的卷积神经网络，并具备在资源有限的微控制器上运行的能力。

Conclusion: 本文提出了一个适用于嵌入式设备的事件相机眼动追踪解决方案（EETnet），并提供了一套完整的训练、评估和量化方法，解决了现有方案在资源受限设备上部署的难题。

Abstract: Event-based cameras are becoming a popular solution for efficient, low-power
eye tracking. Due to the sparse and asynchronous nature of event data, they
require less processing power and offer latencies in the microsecond range.
However, many existing solutions are limited to validation on powerful GPUs,
with no deployment on real embedded devices. In this paper, we present EETnet,
a convolutional neural network designed for eye tracking using purely
event-based data, capable of running on microcontrollers with limited
resources. Additionally, we outline a methodology to train, evaluate, and
quantize the network using a public dataset. Finally, we propose two versions
of the architecture: a classification model that detects the pupil on a grid
superimposed on the original image, and a regression model that operates at the
pixel level.

</details>


### [15] [Global 3D Reconstruction of Clouds & Tropical Cyclones](https://arxiv.org/abs/2511.04773)
*Shirin Ermis,Cesar Aybar,Lilli Freischem,Stella Girtsou,Kyriaki-Margarita Bintsi,Emiliano Diaz Salas-Porras,Michael Eisinger,William Jones,Anna Jungbluth,Benoit Tremblay*

Main category: cs.CV

TL;DR: 本研究开发了一个基于预训练-微调的机器学习框架，利用多颗卫星数据首次实现了全球瞬时3D云图的创建，并能准确重建强热带气旋的3D结构，即使在观测数据缺失时也能提供估计。


<details>
  <summary>Details</summary>
Motivation: 热带气旋预报面临挑战，原因在于卫星对TC结构观测有限，且难以解析TC增强中的云属性。现有机器学习3D云重建方法不适用于TC常见区域，也未在强风暴中得到充分验证。

Method: 引入了一个新的框架，采用预训练-微调流程，利用全球覆盖的多颗卫星数据，将2D卫星图像转换为相关云属性的3D云图。该模型在一个定制的TC数据集上进行应用和性能评估。

Result: 首次成功创建了全球瞬时3D云图，并能准确重建强风暴的3D结构。该模型不仅扩展了现有卫星观测，还能在观测数据完全缺失时提供估计。

Conclusion: 该模型对增进对热带气旋增强的理解和改进预报至关重要。

Abstract: Accurate forecasting of tropical cyclones (TCs) remains challenging due to
limited satellite observations probing TC structure and difficulties in
resolving cloud properties involved in TC intensification. Recent research has
demonstrated the capabilities of machine learning methods for 3D cloud
reconstruction from satellite observations. However, existing approaches have
been restricted to regions where TCs are uncommon, and are poorly validated for
intense storms. We introduce a new framework, based on a
pre-training--fine-tuning pipeline, that learns from multiple satellites with
global coverage to translate 2D satellite imagery into 3D cloud maps of
relevant cloud properties. We apply our model to a custom-built TC dataset to
evaluate performance in the most challenging and relevant conditions. We show
that we can - for the first time - create global instantaneous 3D cloud maps
and accurately reconstruct the 3D structure of intense storms. Our model not
only extends available satellite observations but also provides estimates when
observations are missing entirely. This is crucial for advancing our
understanding of TC intensification and improving forecasts.

</details>


### [16] [Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose](https://arxiv.org/abs/2511.04803)
*Shuo Zhao,Jianxu Chen*

Main category: cs.CV

TL;DR: 本研究系统分析了通用生物医学图像分割模型（如Cellpose）在训练数据冗余和跨域迁移中的灾难性遗忘问题。通过提出的数据集量化（DQ）策略和重放机制，发现仅用10%的数据即可达到饱和性能，并能有效缓解灾难性遗忘，强调了数据中心设计和领域排序的重要性。


<details>
  <summary>Details</summary>
Motivation: 通用生物医学图像分割模型（如Cellpose）在广泛应用中面临两个未充分探索的关键挑战：训练数据的冗余程度，以及跨域迁移对模型保留性能的影响（即灾难性遗忘）。

Method: 1. 提出了数据集量化（DQ）策略来构建紧凑而多样化的训练子集，以评估数据冗余。2. 使用MAE嵌入和t-SNE进行潜在空间分析，以验证DQ选择的补丁能捕获更大的特征多样性。3. 进行跨域微调实验，以检验灾难性遗忘。4. 演示了基于DQ的选择性重放机制，以恢复源域性能。5. 探讨了训练域排序对泛化和遗忘的影响。

Result: 1. 图像分割性能在仅使用10%的Cyto数据集时即达到饱和，表明存在大量数据冗余，并有可能通过最少标注进行训练。2. DQ选择的补丁比随机采样捕获了更大的特征多样性。3. 跨域微调会导致源域性能显著下降（灾难性遗忘），尤其是在从通用领域适应到专业领域时。4. 重新引入仅5-10%源数据的选择性DQ重放能有效恢复源域性能，而完全重放可能阻碍目标域适应。5. 训练域排序能改善多阶段迁移中的泛化能力并减少遗忘。

Conclusion: 数据中心设计在生物医学图像分割中至关重要。高效训练不仅需要紧凑的数据子集，还需要兼顾保留性能的学习策略和明智的领域排序。

Abstract: Generalist biomedical image segmentation models such as Cellpose are
increasingly applied across diverse imaging modalities and cell types. However,
two critical challenges remain underexplored: (1) the extent of training data
redundancy and (2) the impact of cross domain transfer on model retention. In
this study, we conduct a systematic empirical analysis of these challenges
using Cellpose as a case study. First, to assess data redundancy, we propose a
simple dataset quantization (DQ) strategy for constructing compact yet diverse
training subsets. Experiments on the Cyto dataset show that image segmentation
performance saturates with only 10% of the data, revealing substantial
redundancy and potential for training with minimal annotations. Latent space
analysis using MAE embeddings and t-SNE confirms that DQ selected patches
capture greater feature diversity than random sampling. Second, to examine
catastrophic forgetting, we perform cross domain finetuning experiments and
observe significant degradation in source domain performance, particularly when
adapting from generalist to specialist domains. We demonstrate that selective
DQ based replay reintroducing just 5-10% of the source data effectively
restores source performance, while full replay can hinder target adaptation.
Additionally, we find that training domain sequencing improves generalization
and reduces forgetting in multi stage transfer. Our findings highlight the
importance of data centric design in biomedical image segmentation and suggest
that efficient training requires not only compact subsets but also retention
aware learning strategies and informed domain ordering. The code is available
at https://github.com/MMV-Lab/biomedseg-efficiency.

</details>


### [17] [An Active Learning Pipeline for Biomedical Image Instance Segmentation with Minimal Human Intervention](https://arxiv.org/abs/2511.04811)
*Shuo Zhao,Yu Zhou,Jianxu Chen*

Main category: cs.CV

TL;DR: 本文提出了一种数据驱动的AI工作流程，结合基础模型、主动学习和伪标签技术，显著减少了生物医学图像分割所需的手动标注，同时保持了竞争力。


<details>
  <summary>Details</summary>
Motivation: 生物医学图像分割对下游分析至关重要，但面临挑战：传统方法易受噪声影响；U-Net等深度学习模型需要大量标注数据；nnU-Net自动化配置但仍需大量交叉验证数据；大型基础模型泛化性强但在特定数据集上表现不佳。这些限制阻碍了先进AI技术在生物医学研究中的应用。

Method: 本文提出了一种数据驱动的AI工作流程。首先，利用基础模型生成伪标签，这些伪标签用于nnU-Net的自配置。接着，通过主动学习选择一个代表性的核心数据集进行最少量的手动标注。最后，利用这些标注数据对nnU-Net模型进行有效微调。

Result: 该方法显著减少了对人工标注的需求，同时在生物医学图像分割任务中保持了具有竞争力的性能。

Conclusion: 该工作为生物医学研究人员提供了一个可行的解决方案，使他们能够以更少的人工干预，应用最先进的AI技术进行分割任务。

Abstract: Biomedical image segmentation is critical for precise structure delineation
and downstream analysis. Traditional methods often struggle with noisy data,
while deep learning models such as U-Net have set new benchmarks in
segmentation performance. nnU-Net further automates model configuration, making
it adaptable across datasets without extensive tuning. However, it requires a
substantial amount of annotated data for cross-validation, posing a challenge
when only raw images but no labels are available. Large foundation models offer
zero-shot generalizability, but may underperform on specific datasets with
unique characteristics, limiting their direct use for analysis. This work
addresses these bottlenecks by proposing a data-centric AI workflow that
leverages active learning and pseudo-labeling to combine the strengths of
traditional neural networks and large foundation models while minimizing human
intervention. The pipeline starts by generating pseudo-labels from a foundation
model, which are then used for nnU-Net's self-configuration. Subsequently, a
representative core-set is selected for minimal manual annotation, enabling
effective fine-tuning of the nnU-Net model. This approach significantly reduces
the need for manual annotations while maintaining competitive performance,
providing an accessible solution for biomedical researchers to apply
state-of-the-art AI techniques in their segmentation tasks. The code is
available at https://github.com/MMV-Lab/AL_BioMed_img_seg.

</details>


### [18] [3D Gaussian Point Encoders](https://arxiv.org/abs/2511.04797)
*Jim James,Ben Wilson,Simon Lucey,James Hays*

Main category: cs.CV

TL;DR: 本文提出3D高斯点编码器，一种基于3D高斯混合的显式逐点嵌入，通过自然梯度和从PointNet蒸馏进行优化，并利用计算几何启发式方法加速。它比传统PointNet更快、更高效，甚至可以在仅CPU设备上实现高帧率。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索3D识别任务中显式几何表示的潜力，这与PointNet等广泛使用的隐式表示不同。同时，解决3D高斯编码器难以使用标准优化器进行端到端学习的问题，并借鉴3D重建领域从隐式（如NeRF）向显式（如高斯溅射）表示发展的趋势，以实现更快速、更参数高效的模型。

Method: 本文引入了3D高斯点编码器，这是一种基于学习到的3D高斯混合的显式逐点嵌入。为了解决其端到端学习的困难，开发了基于自然梯度和从PointNet进行蒸馏的优化技术，以重建PointNet的激活。此外，还扩展了3D高斯溅射中的滤波技术，以进一步加速3D高斯点编码器。

Result: 结果表明，3D高斯点编码器比传统PointNet更快、更参数高效。通过应用滤波技术，编码器在实现相当精度的PointNet性能时，运行速度快2.7倍，内存使用减少46%，FLOPs减少88%。作为Mamba3D的组件，它运行速度快1.27倍，内存和FLOPs分别减少42%和54%。此外，3D高斯点编码器足够轻量，可在仅CPU设备上实现高帧率。

Conclusion: 3D高斯点编码器作为一种显式几何表示，为3D识别任务提供了一个高效且快速的解决方案。它在速度、内存和FLOPs方面显著优于PointNet，并且足够轻量，可以在仅CPU设备上实现高性能，证明了其作为未来3D识别任务组件的潜力。

Abstract: In this work, we introduce the 3D Gaussian Point Encoder, an explicit
per-point embedding built on mixtures of learned 3D Gaussians. This explicit
geometric representation for 3D recognition tasks is a departure from widely
used implicit representations such as PointNet. However, it is difficult to
learn 3D Gaussian encoders in end-to-end fashion with standard optimizers. We
develop optimization techniques based on natural gradients and distillation
from PointNets to find a Gaussian Basis that can reconstruct PointNet
activations. The resulting 3D Gaussian Point Encoders are faster and more
parameter efficient than traditional PointNets. As in the 3D reconstruction
literature where there has been considerable interest in the move from implicit
(e.g., NeRF) to explicit (e.g., Gaussian Splatting) representations, we can
take advantage of computational geometry heuristics to accelerate 3D Gaussian
Point Encoders further. We extend filtering techniques from 3D Gaussian
Splatting to construct encoders that run 2.7 times faster as a comparable
accuracy PointNet while using 46% less memory and 88% fewer FLOPs. Furthermore,
we demonstrate the effectiveness of 3D Gaussian Point Encoders as a component
in Mamba3D, running 1.27 times faster and achieving a reduction in memory and
FLOPs by 42% and 54% respectively. 3D Gaussian Point Encoders are lightweight
enough to achieve high framerates on CPU-only devices.

</details>


### [19] [Geometry Denoising with Preferred Normal Vectors](https://arxiv.org/abs/2511.04848)
*Manuel Weiß,Lukas Baumgärtner,Roland Herzog,Stephan Schmidt*

Main category: cs.CV

TL;DR: 本文提出了一种利用表面法向量先验知识（标签向量）进行几何去噪的新范式，通过嵌入分割问题和全变分正则化，并使用ADMM方法求解。


<details>
  <summary>Details</summary>
Motivation: 引入一种新的几何去噪范式，利用关于表面法向量的先验知识来改进去噪过程。

Method: 引入一组优选法向量（标签向量）作为先验知识；将分割问题嵌入去噪过程，分割基于法向量与标签向量的相似性；通过全变分项实现正则化；使用分裂Bregman (ADMM) 方法解决优化问题；顶点更新步骤基于二阶形状微积分。

Result: 成功地提出了一种结合几何去噪和表面分割的新方法，并给出了一个可行的优化求解框架。

Conclusion: 该研究引入了一种基于法向量先验知识和嵌入式分割的新颖几何去噪范式，通过全变分正则化和ADMM方法有效解决，为几何去噪提供了新的思路。

Abstract: We introduce a new paradigm for geometry denoising using prior knowledge
about the surface normal vector. This prior knowledge comes in the form of a
set of preferred normal vectors, which we refer to as label vectors. A
segmentation problem is naturally embedded in the denoising process. The
segmentation is based on the similarity of the normal vector to the elements of
the set of label vectors. Regularization is achieved by a total variation term.
We formulate a split Bregman (ADMM) approach to solve the resulting
optimization problem. The vertex update step is based on second-order shape
calculus.

</details>


### [20] [Self-Supervised Implicit Attention Priors for Point Cloud Reconstruction](https://arxiv.org/abs/2511.04864)
*Kyle Fogarty,Chenyue Cai,Jing Yang,Zhilin Guo,Cengiz Öztireli*

Main category: cs.CV

TL;DR: 本文提出一种从不规则点云恢复高质量表面的方法，通过从点云本身学习隐式自先验并结合鲁棒隐式移动最小二乘法（RIMLS），在无需外部训练数据的情况下，实现细节保留和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 从不规则点云中恢复高质量表面是一个病态问题，除非有强大的几何先验。现有方法在细节保留和数据退化鲁棒性方面存在挑战。

Method: 引入一种隐式自先验方法，将形状特有的先验直接从输入点云中提取并嵌入到隐式神经表示中。通过联合训练一个可学习嵌入的小词典和一个隐式距离场实现，距离场通过交叉注意力关注词典，捕捉形状固有的重复结构和长程相关性。该方法仅使用自监督点云重建损失进行优化，无需外部训练数据。然后，对训练好的距离场进行采样以提取密集分布的点和解析法线，并将这些结果整合到鲁棒隐式移动最小二乘（RIMLS）公式中。

Result: 混合策略在保留输入数据精细几何细节的同时，利用学习到的先验来正则化稀疏区域。实验表明，该方法在生成高保真表面、优越的细节保留以及对常见数据退化的鲁棒性方面，均优于经典和基于学习的方法。

Conclusion: 所提出的隐式自先验方法结合RIMLS，有效地解决了从不规则点云进行表面重建的病态问题。它无需外部训练数据，即可生成高保真表面，同时保持精细细节并对数据退化具有鲁棒性。

Abstract: Recovering high-quality surfaces from irregular point cloud is ill-posed
unless strong geometric priors are available. We introduce an implicit
self-prior approach that distills a shape-specific prior directly from the
input point cloud itself and embeds it within an implicit neural
representation. This is achieved by jointly training a small dictionary of
learnable embeddings with an implicit distance field; at every query location,
the field attends to the dictionary via cross-attention, enabling the network
to capture and reuse repeating structures and long-range correlations inherent
to the shape. Optimized solely with self-supervised point cloud reconstruction
losses, our approach requires no external training data. To effectively
integrate this learned prior while preserving input fidelity, the trained field
is then sampled to extract densely distributed points and analytic normals via
automatic differentiation. We integrate the resulting dense point cloud and
corresponding normals into a robust implicit moving least squares (RIMLS)
formulation. We show this hybrid strategy preserves fine geometric details in
the input data, while leveraging the learned prior to regularize sparse
regions. Experiments show that our method outperforms both classical and
learning-based approaches in generating high-fidelity surfaces with superior
detail preservation and robustness to common data degradations.

</details>


### [21] [Clinical-ComBAT: a diffusion-weighted MRI harmonization method for clinical applications](https://arxiv.org/abs/2511.04871)
*Gabriel Girard,Manon Edde,Félix Dumais,Yoan David,Matthieu Dumont,Guillaume Theaud,Jean-Christophe Houde,Arnaud Boré,Maxime Descoteaux,Pierre-Marc Jodoin*

Main category: cs.CV

TL;DR: 本文提出Clinical-ComBAT方法，用于解决弥散加权磁共振成像(DW-MRI)数据在多中心采集时存在的扫描仪特异性偏差，克服了传统ComBAT方法的局限性，特别适用于真实临床场景和规范性建模。


<details>
  <summary>Details</summary>
Motivation: DW-MRI标量图对评估神经退行性疾病和白质微结构非常有效，但多中心采集数据存在扫描仪特异性偏差，需要协调。现有方法如ComBAT因其对线性关系、同质人群、固定站点数和充足数据量的依赖，限制了其在临床实践中的应用。

Method: 本文提出Clinical-ComBAT方法，旨在克服现有ComBAT方法的局限性。其特点包括：独立地协调每个站点，允许新数据和诊所的灵活引入；采用非线性多项式数据模型；站点特异性协调，以规范站点为参考；方差先验可适应小样本队列；包含超参数调优和拟合优度指标以评估协调效果。

Result: Clinical-ComBAT在模拟数据和真实数据上均表现出有效性，展示了弥散指标的更好对齐，并增强了其在规范性建模中的适用性。

Conclusion: Clinical-ComBAT成功克服了传统ComBAT方法的限制，为DW-MRI数据提供了一种更灵活、更鲁棒的协调方法，特别适合于真实世界的临床场景和规范性建模，即使面对新数据、小样本队列和非线性关系也能有效工作。

Abstract: Diffusion-weighted magnetic resonance imaging (DW-MRI) derived scalar maps
are effective for assessing neurodegenerative diseases and microstructural
properties of white matter in large number of brain conditions. However, DW-MRI
inherently limits the combination of data from multiple acquisition sites
without harmonization to mitigate scanner-specific biases. While the widely
used ComBAT method reduces site effects in research, its reliance on linear
covariate relationships, homogeneous populations, fixed site numbers, and well
populated sites constrains its clinical use. To overcome these limitations, we
propose Clinical-ComBAT, a method designed for real-world clinical scenarios.
Clinical-ComBAT harmonizes each site independently, enabling flexibility as new
data and clinics are introduced. It incorporates a non-linear polynomial data
model, site-specific harmonization referenced to a normative site, and variance
priors adaptable to small cohorts. It further includes hyperparameter tuning
and a goodness-of-fit metric for harmonization assessment. We demonstrate its
effectiveness on simulated and real data, showing improved alignment of
diffusion metrics and enhanced applicability for normative modeling.

</details>


### [22] [Beta Distribution Learning for Reliable Roadway Crash Risk Assessment](https://arxiv.org/abs/2511.04886)
*Ahmad Elallaf,Nathan Jacobs,Xinyue Ye,Mei Chen,Gongbo Liang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的地理空间深度学习框架，利用卫星图像全面预测致命交通事故风险，并通过Beta概率分布量化模型不确定性。该模型在召回率上优于基线模型，并提供可靠且可解释的风险评估，有助于自动驾驶和城市规划。


<details>
  <summary>Details</summary>
Motivation: 道路交通事故是全球性的健康危机，传统交通安全研究忽视了内置环境的空间复杂性和上下文交互。此外，传统的神经网络风险估计器仅提供点估计，缺乏模型不确定性，限制了其在关键决策中的实用性。

Method: 引入了一种新颖的地理空间深度学习框架，该框架利用卫星图像作为全面的空间输入，以捕捉导致致命碰撞风险的细微空间模式和嵌入式环境风险因素。模型不生成单一确定性输出，而是估计致命碰撞风险的完整Beta概率分布，从而提供准确且考虑不确定性的预测。

Result: 该模型在召回率（用于标记潜在危险的关键指标）上比基线模型提高了17-23%，同时提供了卓越的校准。它能从卫星图像中提供可靠且可解释的风险评估，并生成准确且具有不确定性意识的预测。

Conclusion: 该方法通过提供可靠且可解释的风险评估，能够实现更安全的自动驾驶，并为城市规划者和政策制定者提供了一个高度可扩展的工具，以公平且经济高效地提高道路安全。

Abstract: Roadway traffic accidents represent a global health crisis, responsible for
over a million deaths annually and costing many countries up to 3% of their
GDP. Traditional traffic safety studies often examine risk factors in
isolation, overlooking the spatial complexity and contextual interactions
inherent in the built environment. Furthermore, conventional Neural
Network-based risk estimators typically generate point estimates without
conveying model uncertainty, limiting their utility in critical
decision-making. To address these shortcomings, we introduce a novel geospatial
deep learning framework that leverages satellite imagery as a comprehensive
spatial input. This approach enables the model to capture the nuanced spatial
patterns and embedded environmental risk factors that contribute to fatal crash
risks. Rather than producing a single deterministic output, our model estimates
a full Beta probability distribution over fatal crash risk, yielding accurate
and uncertainty-aware predictions--a critical feature for trustworthy AI in
safety-critical applications. Our model outperforms baselines by achieving a
17-23% improvement in recall, a key metric for flagging potential dangers,
while delivering superior calibration. By providing reliable and interpretable
risk assessments from satellite imagery alone, our method enables safer
autonomous navigation and offers a highly scalable tool for urban planners and
policymakers to enhance roadway safety equitably and cost-effectively.

</details>


### [23] [A benchmark multimodal oro-dental dataset for large vision-language models](https://arxiv.org/abs/2511.04948)
*Haoxin Lv,Ijazul Haq,Jin Du,Jiaxin Ma,Binnian Zhu,Xiaobing Dang,Chaoan Liang,Ruxu Du,Yingjie Zhang,Muhammad Saqib*

Main category: cs.CV

TL;DR: 本文介绍了一个大规模多模态口腔医疗数据集，包含8775次牙科检查，并利用该数据集微调了视觉语言模型，在口腔异常分类和诊断报告生成任务上取得了显著优于基线模型的效果。


<details>
  <summary>Details</summary>
Motivation: 口腔医疗领域人工智能的发展需要能够捕捉临床实践复杂性的大规模多模态数据集。

Method: 研究团队构建了一个综合性多模态数据集，包含来自4800名患者的8775次牙科检查（2018-2025年），包括50000张口内图像、8056张X光片以及详细的文本记录（诊断、治疗计划、随访记录）。数据在伦理指导下收集并进行基准测试标注。为验证数据集的实用性，研究者微调了Qwen-VL 3B和7B等先进大型视觉语言模型，并在六种口腔牙齿异常分类和从多模态输入生成完整诊断报告两项任务上进行评估，与基线模型（基础版Qwen-VL和GPT-4o）进行了比较。

Result: 经过微调的模型在两项任务上均取得了显著优于基线模型（包括基础版Qwen-VL和GPT-4o）的性能提升，验证了数据集的有效性。

Conclusion: 该数据集有效推动了人工智能驱动的口腔牙齿医疗解决方案，并已公开可用，为未来AI牙科研究提供了重要资源。

Abstract: The advancement of artificial intelligence in oral healthcare relies on the
availability of large-scale multimodal datasets that capture the complexity of
clinical practice. In this paper, we present a comprehensive multimodal
dataset, comprising 8775 dental checkups from 4800 patients collected over
eight years (2018-2025), with patients ranging from 10 to 90 years of age. The
dataset includes 50000 intraoral images, 8056 radiographs, and detailed textual
records, including diagnoses, treatment plans, and follow-up notes. The data
were collected under standard ethical guidelines and annotated for
benchmarking. To demonstrate its utility, we fine-tuned state-of-the-art large
vision-language models, Qwen-VL 3B and 7B, and evaluated them on two tasks:
classification of six oro-dental anomalies and generation of complete
diagnostic reports from multimodal inputs. We compared the fine-tuned models
with their base counterparts and GPT-4o. The fine-tuned models achieved
substantial gains over these baselines, validating the dataset and underscoring
its effectiveness in advancing AI-driven oro-dental healthcare solutions. The
dataset is publicly available, providing an essential resource for future
research in AI dentistry.

</details>


### [24] [DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning](https://arxiv.org/abs/2511.04949)
*Tharindu Fernando,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的深度学习框架，结合高维潜在空间和多智能体对抗强化学习（MAARL），以开发一种鲁棒且自适应的数字水印方法，用于主动检测深度伪造，并在鲁棒性与篡改敏感性之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展导致深度伪造日益逼真，对执法和公众信任构成挑战。现有被动检测器因依赖特定伪造痕迹而泛化能力差。主动水印方法虽能识别高质量合成媒体，但难以平衡对良性失真的鲁棒性与对恶意篡改的敏感性。

Method: 该方法引入了一个深度学习框架，利用高维潜在空间表示和多智能体对抗强化学习（MAARL）范式。具体来说，开发了一个在潜在空间操作的可学习水印嵌入器，捕捉高级图像语义并精确控制消息编解码。MAARL范式通过与模拟良性和恶意图像操作的对抗性攻击者智能体交互，使可学习水印智能体在鲁棒性和脆弱性之间寻求最佳平衡。

Result: 在CelebA和CelebA-HQ基准测试中，该方法在挑战性操纵场景下，始终优于现有最先进方法，在CelebA上实现了超过4.5%的改进，在CelebA-HQ上实现了超过5.3%的改进。

Conclusion: 本文成功开发了一种新颖的深度学习框架，通过结合潜在空间水印和MAARL，为主动深度伪造检测提供了一种鲁棒且自适应的水印方法，有效解决了鲁棒性与篡改敏感性之间的平衡问题，并显著超越了现有技术。

Abstract: Rapid advances in generative AI have led to increasingly realistic deepfakes,
posing growing challenges for law enforcement and public trust. Existing
passive deepfake detectors struggle to keep pace, largely due to their
dependence on specific forgery artifacts, which limits their ability to
generalize to new deepfake types. Proactive deepfake detection using watermarks
has emerged to address the challenge of identifying high-quality synthetic
media. However, these methods often struggle to balance robustness against
benign distortions with sensitivity to malicious tampering. This paper
introduces a novel deep learning framework that harnesses high-dimensional
latent space representations and the Multi-Agent Adversarial Reinforcement
Learning (MAARL) paradigm to develop a robust and adaptive watermarking
approach. Specifically, we develop a learnable watermark embedder that operates
in the latent space, capturing high-level image semantics, while offering
precise control over message encoding and extraction. The MAARL paradigm
empowers the learnable watermarking agent to pursue an optimal balance between
robustness and fragility by interacting with a dynamic curriculum of benign and
malicious image manipulations simulated by an adversarial attacker agent.
Comprehensive evaluations on the CelebA and CelebA-HQ benchmarks reveal that
our method consistently outperforms state-of-the-art approaches, achieving
improvements of over 4.5% on CelebA and more than 5.3% on CelebA-HQ under
challenging manipulation scenarios.

</details>


### [25] [Pattern-Aware Diffusion Synthesis of fMRI/dMRI with Tissue and Microstructural Refinement](https://arxiv.org/abs/2511.04963)
*Xiongri Shen,Jiaqi Wang,Yi Zhong,Zhenxi Song,Leilei Zhao,Yichen Wei,Lingyan Liang,Shuqiang Wang,Baiying Lei,Demao Deng,Zhiguo Zhang*

Main category: cs.CV

TL;DR: 本文提出PDS模型，通过模式感知双模态3D扩散框架和组织精细化网络，解决了fMRI和dMRI模态合成中存在的信号差异和疾病模式整合不足问题，实现了先进的模态补全和临床诊断性能。


<details>
  <summary>Details</summary>
Motivation: 磁共振成像（MRI）对神经退行性疾病研究至关重要，但模态缺失严重阻碍了其临床应用。现有基于GAN和扩散模型的方法在fMRI-dMRI合成方面存在局限性，主要原因包括fMRI和dMRI在时间/梯度轴上的BOLD与扩散加权信号差异显著，以及在生成过程中未能充分整合与疾病相关的神经解剖模式。

Method: 本文提出了PDS模型，引入了两项关键创新：1) 一个模式感知双模态3D扩散框架，用于跨模态学习；2) 一个集成高效微结构精细化的组织精细化网络，以保持结构保真度和精细细节。

Result: 在OASIS-3、ADNI和内部数据集上进行评估，PDS方法取得了最先进的结果。fMRI合成的PSNR/SSIM分数达到29.83 dB/90.84%（比基线提高1.54 dB/4.12%），dMRI合成达到30.00 dB/77.55%（提高1.02 dB/2.2%）。在临床验证中，合成数据在混合真实-合成实验中显示出强大的诊断性能，在NC vs. MCI vs. AD分类中准确率达到67.92%/66.02%/64.15%。

Conclusion: PDS模型通过其创新的双模态扩散框架和精细化网络，有效解决了fMRI-dMRI合成中的挑战，生成了高保真度且在临床诊断中具有实用价值的合成数据，显著提升了模态补全的性能和临床应用潜力。

Abstract: Magnetic resonance imaging (MRI), especially functional MRI (fMRI) and
diffusion MRI (dMRI), is essential for studying neurodegenerative diseases.
However, missing modalities pose a major barrier to their clinical use.
Although GAN- and diffusion model-based approaches have shown some promise in
modality completion, they remain limited in fMRI-dMRI synthesis due to (1)
significant BOLD vs. diffusion-weighted signal differences between fMRI and
dMRI in time/gradient axis, and (2) inadequate integration of disease-related
neuroanatomical patterns during generation. To address these challenges, we
propose PDS, introducing two key innovations: (1) a pattern-aware dual-modal 3D
diffusion framework for cross-modality learning, and (2) a tissue refinement
network integrated with a efficient microstructure refinement to maintain
structural fidelity and fine details. Evaluated on OASIS-3, ADNI, and in-house
datasets, our method achieves state-of-the-art results, with PSNR/SSIM scores
of 29.83 dB/90.84\% for fMRI synthesis (+1.54 dB/+4.12\% over baselines) and
30.00 dB/77.55\% for dMRI synthesis (+1.02 dB/+2.2\%). In clinical validation,
the synthesized data show strong diagnostic performance, achieving
67.92\%/66.02\%/64.15\% accuracy (NC vs. MCI vs. AD) in hybrid real-synthetic
experiments. Code is available in \href{https://github.com/SXR3015/PDS}{PDS
GitHub Repository}

</details>


### [26] [Learning to Restore Multi-Degraded Images via Ingredient Decoupling and Task-Aware Path Adaptation](https://arxiv.org/abs/2511.04920)
*Hu Gao,Xiaoning Lei,Ying Zhang,Xichen Xu,Guannan Jiang,Lizhuang Ma*

Main category: cs.CV

TL;DR: 该论文提出了一种名为IMDNet的自适应多降质图像恢复网络，通过解耦降质成分表示来指导路径选择，从而有效处理图像中同时存在的多种降质类型。


<details>
  <summary>Details</summary>
Motivation: 现有图像恢复方法大多只关注单一降质类型，但在现实世界中，图像常受到多种降质（如雨、噪声、雾霾）的共同影响，这限制了它们在实际应用中的有效性。

Method: 该研究提出了一种自适应多降质图像恢复网络（IMDNet）。具体方法包括：1. 在编码器中设计了降质成分解耦块（DIDBlock），通过整合空间和频率域信息来统计性地分离降质成分。2. 引入融合块（FBlock），使用可学习矩阵整合所有级别的降质信息。3. 在解码器中引入任务自适应块（TABlock），根据多降质表示动态激活或融合功能分支，灵活选择最佳恢复路径。

Result: 实验结果表明，IMDNet在多降质恢复任务上表现出卓越的性能，同时在单一降质任务上也能保持强大的竞争力。

Conclusion: 所提出的IMDNet架构通过解耦降质表示和自适应路径选择，能有效处理图像中的多种共存降质，显著提升了图像恢复的实用性。

Abstract: Image restoration (IR) aims to recover clean images from degraded
observations. Despite remarkable progress, most existing methods focus on a
single degradation type, whereas real-world images often suffer from multiple
coexisting degradations, such as rain, noise, and haze coexisting in a single
image, which limits their practical effectiveness. In this paper, we propose an
adaptive multi-degradation image restoration network that reconstructs images
by leveraging decoupled representations of degradation ingredients to guide
path selection. Specifically, we design a degradation ingredient decoupling
block (DIDBlock) in the encoder to separate degradation ingredients
statistically by integrating spatial and frequency domain information,
enhancing the recognition of multiple degradation types and making their
feature representations independent. In addition, we present fusion block
(FBlock) to integrate degradation information across all levels using learnable
matrices. In the decoder, we further introduce a task adaptation block
(TABlock) that dynamically activates or fuses functional branches based on the
multi-degradation representation, flexibly selecting optimal restoration paths
under diverse degradation conditions. The resulting tightly integrated
architecture, termed IMDNet, is extensively validated through experiments,
showing superior performance on multi-degradation restoration while maintaining
strong competitiveness on single-degradation tasks.

</details>


### [27] [Validating Vision Transformers for Otoscopy: Performance and Data-Leakage Effects](https://arxiv.org/abs/2511.04872)
*James Ndubuisi,Fernando Auat,Marta Vallejo*

Main category: cs.CV

TL;DR: 本研究评估了Swin Transformer在耳部疾病诊断中的效能，最初表现出色，但在纠正数据泄露后性能显著下降，强调了数据处理在医学机器学习中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 耳鼻喉科专家诊断耳部疾病的误诊率高达27%，因此提高诊断准确性至关重要。

Method: 研究使用了智利大学临床医院耳鼻喉科的真实耳镜视频数据集。通过拉普拉斯和香农熵阈值选择帧并移除空白帧。评估了Swin v1、Swin v2 Transformer模型和ResNet模型。关键是，研究发现了数据预处理中的数据泄露问题，并进行了纠正。

Result: 初步结果显示Swin v1、Swin v2和ResNet模型的准确率分别为100%、99.1%和99.5%。但在纠正数据泄露后，Swin v1和Swin v2的准确率降至83%，ResNet降至82%。这一发现揭示了数据泄露对模型性能的显著影响。

Conclusion: 尽管视觉Transformer模型在耳部疾病诊断中显示出潜力，但严格的数据处理和在先进模型架构与有效数据预处理之间找到最佳平衡对于开发可靠的医学机器学习模型至关重要。

Abstract: This study evaluates the efficacy of vision transformer models, specifically
Swin transformers, in enhancing the diagnostic accuracy of ear diseases
compared to traditional convolutional neural networks. With a reported 27%
misdiagnosis rate among specialist otolaryngologists, improving diagnostic
accuracy is crucial. The research utilised a real-world dataset from the
Department of Otolaryngology at the Clinical Hospital of the Universidad de
Chile, comprising otoscopic videos of ear examinations depicting various middle
and external ear conditions. Frames were selected based on the Laplacian and
Shannon entropy thresholds, with blank frames removed. Initially, Swin v1 and
Swin v2 transformer models achieved accuracies of 100% and 99.1%, respectively,
marginally outperforming the ResNet model (99.5%). These results surpassed
metrics reported in related studies. However, the evaluation uncovered a
critical data leakage issue in the preprocessing step, affecting both this
study and related research using the same raw dataset. After mitigating the
data leakage, model performance decreased significantly. Corrected accuracies
were 83% for both Swin v1 and Swin v2, and 82% for the ResNet model. This
finding highlights the importance of rigorous data handling in machine learning
studies, especially in medical applications. The findings indicate that while
vision transformers show promise, it is essential to find an optimal balance
between the benefits of advanced model architectures and those derived from
effective data preprocessing. This balance is key to developing a reliable
machine learning model for diagnosing ear diseases.

</details>


### [28] [CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting](https://arxiv.org/abs/2511.04951)
*Hexu Zhao,Xiwen Min,Xiaoteng Liu,Moonjun Gong,Yiming Li,Ang Li,Saining Xie,Jinyang Li,Aurojit Panda*

Main category: cs.CV

TL;DR: 本文提出了CLM系统，通过将3DGS的高斯点卸载到CPU内存并优化数据传输，解决了3DGS在大型场景中内存需求过大的问题，使其能在消费级GPU上实现高质量渲染。


<details>
  <summary>Details</summary>
Motivation: 3D Gaussian Splatting (3DGS) 虽然渲染速度快、输出质量高，但其庞大的内存需求使其难以扩展到大型或复杂场景，超出了大多数GPU的内存容量。

Method: CLM系统通过将高斯点卸载到CPU内存，仅在必要时加载到GPU内存。为减少性能和通信开销，CLM采用了一种新颖的卸载策略，利用3DGS的内存访问模式进行流水线操作，从而重叠GPU-to-CPU通信、GPU计算和CPU计算。此外，还利用访问模式来减少通信量。

Result: 实验结果表明，CLM系统能够在单个RTX4090显卡上渲染需要1亿个高斯点的大型场景，并实现了最先进的重建质量。

Conclusion: CLM系统成功地使3DGS能够在单张消费级GPU上渲染大型场景，有效解决了其内存限制问题，同时保持了高渲染质量。

Abstract: 3D Gaussian Splatting (3DGS) is an increasingly popular novel view synthesis
approach due to its fast rendering time, and high-quality output. However,
scaling 3DGS to large (or intricate) scenes is challenging due to its large
memory requirement, which exceed most GPU's memory capacity. In this paper, we
describe CLM, a system that allows 3DGS to render large scenes using a single
consumer-grade GPU, e.g., RTX4090. It does so by offloading Gaussians to CPU
memory, and loading them into GPU memory only when necessary. To reduce
performance and communication overheads, CLM uses a novel offloading strategy
that exploits observations about 3DGS's memory access pattern for pipelining,
and thus overlap GPU-to-CPU communication, GPU computation and CPU computation.
Furthermore, we also exploit observation about the access pattern to reduce
communication volume. Our evaluation shows that the resulting implementation
can render a large scene that requires 100 million Gaussians on a single
RTX4090 and achieve state-of-the-art reconstruction quality.

</details>


### [29] [Challenges in 3D Data Synthesis for Training Neural Networks on Topological Features](https://arxiv.org/abs/2511.04972)
*Dylan Peek,Matthew P. Skerritt,Siddharth Pritam,Stephan Chalup*

Main category: cs.CV

TL;DR: 该研究提出了一种使用Repulsive Surface算法系统生成带拓扑标签的3D数据集的新方法，以解决拓扑数据分析(TDA)中缺乏监督学习数据的挑战，并利用该数据集训练了一个3D卷积Transformer架构的属估计器。


<details>
  <summary>Details</summary>
Motivation: 传统的拓扑数据分析方法（如持久同源性）计算成本高昂，促使人们开发基于神经网络的估计器。然而，阻碍这些方法发展的一个关键障碍是缺乏专门为TDA任务量身定制的、带有类别分布和多样性的标注3D数据。

Method: 研究引入了一种新颖的方法，利用Repulsive Surface算法系统地生成带标注的3D数据集，该方法允许控制拓扑不变量（如孔洞数量）。然后，使用一个基于3D卷积Transformer架构的属估计器网络，利用该合成3D数据集进行训练。

Result: 生成的3D数据集具有多样化的几何形状和拓扑标签，适用于训练和基准测试神经网络估计器。观察到随着形变增加，估计器的准确性下降，这突出表明在训练泛化估计器时，不仅拓扑复杂性，几何复杂性也起着重要作用。

Conclusion: 该数据集填补了TDA模型和技术训练与评估中带标注3D数据集生成方面的空白。研究强调了在训练泛化估计器时，几何复杂性与拓扑复杂性同样重要。

Abstract: Topological Data Analysis (TDA) involves techniques of analyzing the
underlying structure and connectivity of data. However, traditional methods
like persistent homology can be computationally demanding, motivating the
development of neural network-based estimators capable of reducing
computational overhead and inference time. A key barrier to advancing these
methods is the lack of labeled 3D data with class distributions and diversity
tailored specifically for supervised learning in TDA tasks. To address this, we
introduce a novel approach for systematically generating labeled 3D datasets
using the Repulsive Surface algorithm, allowing control over topological
invariants, such as hole count. The resulting dataset offers varied geometry
with topological labeling, making it suitable for training and benchmarking
neural network estimators. This paper uses a synthetic 3D dataset to train a
genus estimator network, created using a 3D convolutional transformer
architecture. An observed decrease in accuracy as deformations increase
highlights the role of not just topological complexity, but also geometric
complexity, when training generalized estimators. This dataset fills a gap in
labeled 3D datasets and generation for training and evaluating models and
techniques for TDA.

</details>


### [30] [Dynamic Residual Encoding with Slide-Level Contrastive Learning for End-to-End Whole Slide Image Representation](https://arxiv.org/abs/2511.05034)
*Jing Jin,Xu Liu,Te Gao,Zhihong Shi,Yixiong Liang,Ruiqing Zheng,Hulin Kuang,Min Zeng,Shichao Kan*

Main category: cs.CV

TL;DR: 本文提出了一种名为DRE-SLCL的动态残差编码结合幻灯片级对比学习方法，用于端到端全切片图像（WSI）表示学习，旨在解决巨像素图像因GPU限制难以处理所有切片的问题。


<details>
  <summary>Details</summary>
Motivation: 端到端WSI表示模型训练面临巨大挑战，因为一张标准的巨像素幻灯片包含数万个图像切片，受限于当前GPU内存，难以在单个mini-batch中计算所有切片的梯度。

Method: 所提出的DRE-SLCL方法利用一个内存库存储数据集中所有WSI的切片特征。在训练过程中，每个mini-batch包含多个WSI。对于批次中的每个WSI，随机采样一部分切片，并使用切片编码器计算其特征。同时，从内存库中选择同一WSI的其他切片特征。通过结合采样特征和从内存库中检索的特征，使用残差编码技术生成每个WSI的表示。最后，基于WSI的表示和组织病理学报告计算幻灯片级对比损失。

Result: 在癌症亚型分类、癌症识别和突变预测任务上进行的实验证明了所提出的DRE-SLCL方法的有效性。

Conclusion: DRE-SLCL方法通过动态残差编码和幻灯片级对比学习，成功克服了GPU限制对端到端WSI表示学习的挑战，并在多项癌症相关任务中展现出优越性能。

Abstract: Whole Slide Image (WSI) representation is critical for cancer subtyping,
cancer recognition and mutation prediction.Training an end-to-end WSI
representation model poses significant challenges, as a standard gigapixel
slide can contain tens of thousands of image tiles, making it difficult to
compute gradients of all tiles in a single mini-batch due to current GPU
limitations. To address this challenge, we propose a method of dynamic residual
encoding with slide-level contrastive learning (DRE-SLCL) for end-to-end WSI
representation. Our approach utilizes a memory bank to store the features of
tiles across all WSIs in the dataset. During training, a mini-batch usually
contains multiple WSIs. For each WSI in the batch, a subset of tiles is
randomly sampled and their features are computed using a tile encoder. Then,
additional tile features from the same WSI are selected from the memory bank.
The representation of each individual WSI is generated using a residual
encoding technique that incorporates both the sampled features and those
retrieved from the memory bank. Finally, the slide-level contrastive loss is
computed based on the representations and histopathology reports ofthe WSIs
within the mini-batch. Experiments conducted over cancer subtyping, cancer
recognition, and mutation prediction tasks proved the effectiveness of the
proposed DRE-SLCL method.

</details>


### [31] [GSE: Evaluating Sticker Visual Semantic Similarity via a General Sticker Encoder](https://arxiv.org/abs/2511.04977)
*Heng Er Metilda Chee,Jiayin Wang,Zhiqiang Guo,Weizhi Ma,Min Zhang*

Main category: cs.CV

TL;DR: 本文定义了贴纸语义相似性任务，推出了首个基准数据集Triple-S，并提出了轻量级模型GSE。GSE在贴纸语义理解和下游任务上表现出色，解决了现有模型对此类复杂内容理解不足的问题，为未来研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 贴纸作为一种流行的视觉交流形式，其内容高度多样化和符号化，导致理解其语义关系极具挑战性。现有的预训练视觉和多模态模型难以捕捉贴纸细微的语义，因此需要专门的方法和工具来解决这个问题。

Method: 研究者正式定义了“贴纸语义相似性任务”，并引入了首个针对该任务的基准数据集“Triple-S”，该数据集包含905对人工标注的正负贴纸对。为解决现有模型的不足，本文提出了“通用贴纸编码器（GSE）”，这是一个轻量级且多功能的模型，通过结合Triple-S和额外数据集来学习鲁棒的贴纸嵌入。

Result: 评估结果表明，现有预训练的视觉和多模态模型难以捕捉细微的贴纸语义。相比之下，GSE在未见过的贴纸上取得了卓越的性能，并在情感分类和贴纸到贴纸检索等下游任务中也展现出强大的效果。

Conclusion: 通过发布Triple-S基准和GSE模型，本研究提供了标准化的评估工具和鲁棒的贴纸嵌入，这将极大地促进未来在贴纸理解、检索和多模态内容生成领域的研究。

Abstract: Stickers have become a popular form of visual communication, yet
understanding their semantic relationships remains challenging due to their
highly diverse and symbolic content. In this work, we formally {define the
Sticker Semantic Similarity task} and introduce {Triple-S}, the first benchmark
for this task, consisting of 905 human-annotated positive and negative sticker
pairs. Through extensive evaluation, we show that existing pretrained vision
and multimodal models struggle to capture nuanced sticker semantics. To address
this, we propose the {General Sticker Encoder (GSE)}, a lightweight and
versatile model that learns robust sticker embeddings using both Triple-S and
additional datasets. GSE achieves superior performance on unseen stickers, and
demonstrates strong results on downstream tasks such as emotion classification
and sticker-to-sticker retrieval. By releasing both Triple-S and GSE, we
provide standardized evaluation tools and robust embeddings, enabling future
research in sticker understanding, retrieval, and multimodal content
generation. The Triple-S benchmark and GSE have been publicly released and are
available here.

</details>


### [32] [No Pose Estimation? No Problem: Pose-Agnostic and Instance-Aware Test-Time Adaptation for Monocular Depth Estimation](https://arxiv.org/abs/2511.05055)
*Mingyu Sung,Hyeonmin Choe,Il-Min Kim,Sangseok Yun,Jae Mo Kang*

Main category: cs.CV

TL;DR: 本文提出了一种名为PITTA的新型高效测试时间适应（TTA）框架，用于单目深度估计（MDE），通过引入姿态无关TTA范式和实例感知图像掩码策略，显著提升了在多样动态环境下的MDE性能。


<details>
  <summary>Details</summary>
Motivation: 单目深度估计（MDE）模型在部署到与训练环境不同的真实世界场景时，现有测试时间适应（TTA）方法在处理多样化和动态环境方面仍然效率低下且存在问题，限制了其在需要三维地形场景的AI应用中的有效性。

Method: 本文提出了PITTA框架，包含两个关键创新策略：(i) MDE的姿态无关TTA范式，无需相机姿态信息即可进行高效TTA；(ii) 实例感知图像掩码，通过预训练全景分割网络提取动态物体（如车辆、行人）的实例级掩码，并移除静态物体和背景。此外，还引入了一种简单有效的输入图像和深度图边缘提取方法以进一步提升性能。

Result: 在DrivingStereo和Waymo数据集上进行的大量实验评估表明，PITTA框架在TTA期间的MDE性能显著优于现有的最先进技术，取得了显著的性能提升。

Conclusion: PITTA是一种新颖且高性能的MDE测试时间适应框架，通过其独特的姿态无关TTA和实例感知掩码策略，有效解决了现有方法在多样动态环境中的局限性，并显著提升了MDE的性能。

Abstract: Monocular depth estimation (MDE), inferring pixel-level depths in single RGB
images from a monocular camera, plays a crucial and pivotal role in a variety
of AI applications demanding a three-dimensional (3D) topographical scene. In
the real-world scenarios, MDE models often need to be deployed in environments
with different conditions from those for training. Test-time (domain)
adaptation (TTA) is one of the compelling and practical approaches to address
the issue. Although there have been notable advancements in TTA for MDE,
particularly in a self-supervised manner, existing methods are still
ineffective and problematic when applied to diverse and dynamic environments.
To break through this challenge, we propose a novel and high-performing TTA
framework for MDE, named PITTA. Our approach incorporates two key innovative
strategies: (i) pose-agnostic TTA paradigm for MDE and (ii) instance-aware
image masking. Specifically, PITTA enables highly effective TTA on a pretrained
MDE network in a pose-agnostic manner without resorting to any camera pose
information. Besides, our instance-aware masking strategy extracts
instance-wise masks for dynamic objects (e.g., vehicles, pedestrians, etc.)
from a segmentation mask produced by a pretrained panoptic segmentation
network, by removing static objects including background components. To further
boost performance, we also present a simple yet effective edge extraction
methodology for the input image (i.e., a single monocular image) and depth map.
Extensive experimental evaluations on DrivingStereo and Waymo datasets with
varying environmental conditions demonstrate that our proposed framework,
PITTA, surpasses the existing state-of-the-art techniques with remarkable
performance improvements in MDE during TTA.

</details>


### [33] [Learning Fourier shapes to probe the geometric world of deep neural networks](https://arxiv.org/abs/2511.04970)
*Jian Wang,Yixing Yong,Haixia Bi,Lijun He,Fan Li*

Main category: cs.CV

TL;DR: 本研究利用优化形状来探究深度神经网络（DNNs）的几何理解能力，发现形状既是强大的语义载体和解释工具，也是一种新型的对抗范式。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络的研究主要集中在纹理上，而对几何理解的探索不足。研究人员希望深入了解DNNs如何处理和理解形状信息。

Method: 开发了一个端到端可微分的框架。该框架结合了强大的傅里叶级数来参数化任意形状，基于环绕数的映射方法将形状转换为DNN所需的像素网格，并利用信号能量约束来提高优化效率并确保形状的物理合理性。

Result: 研究结果表明：1) 优化形状可以作为强大的语义载体，仅通过几何定义就能生成高置信度的分类；2) 它们是高保真度的可解释性工具，能精确隔离模型关注的显著区域；3) 它们构成了一种新的、可泛化的对抗范式，能够欺骗下游视觉任务。

Conclusion: 这项工作提供了一个多功能的框架，用于探究DNNs的几何世界，并为挑战和理解机器感知开辟了新的前沿。

Abstract: While both shape and texture are fundamental to visual recognition, research
on deep neural networks (DNNs) has predominantly focused on the latter, leaving
their geometric understanding poorly probed. Here, we show: first, that
optimized shapes can act as potent semantic carriers, generating
high-confidence classifications from inputs defined purely by their geometry;
second, that they are high-fidelity interpretability tools that precisely
isolate a model's salient regions; and third, that they constitute a new,
generalizable adversarial paradigm capable of deceiving downstream visual
tasks. This is achieved through an end-to-end differentiable framework that
unifies a powerful Fourier series to parameterize arbitrary shapes, a winding
number-based mapping to translate them into the pixel grid required by DNNs,
and signal energy constraints that enhance optimization efficiency while
ensuring physically plausible shapes. Our work provides a versatile framework
for probing the geometric world of DNNs and opens new frontiers for challenging
and understanding machine perception.

</details>


### [34] [Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings](https://arxiv.org/abs/2511.05017)
*Aakriti Agrawal,Gouthaman KV,Rohith Aralikatti,Gauri Jagatap,Jiaxin Yuan,Vijay Kamarshi,Andrea Fanelli,Furong Huang*

Main category: cs.CV

TL;DR: 本文发现现有LVLM架构存在固有的语言模态偏见，导致幻觉。提出通过平均池化视觉特征来精炼文本嵌入，有效改善视觉定位并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型（LVLM）架构存在对语言模态的固有偏见，这主要是因为常见的做法是简单地将视觉嵌入附加到输入文本序列上，导致视觉定位不佳和幻觉问题。

Method: 提出了一种简单而有效的方法：通过整合平均池化的视觉特征来精炼文本嵌入。该方法旨在平衡模态信息，增强视觉信息在文本理解中的作用。

Result: 实验结果表明，该方法显著改善了视觉定位能力，并在现有基准测试中显著减少了幻觉现象。

Conclusion: 研究表明，通过视觉信息精炼文本嵌入可以有效缓解LVLM中的模态不平衡问题及其对幻觉的影响。尽管平均池化是简单有效的方式，未来工作可以探索更复杂的融合方法以进一步增强视觉定位和跨模态对齐。

Abstract: In this work, we identify an inherent bias in prevailing LVLM architectures
toward the language modality, largely resulting from the common practice of
simply appending visual embeddings to the input text sequence. To address this,
we propose a simple yet effective method that refines textual embeddings by
integrating average-pooled visual features. Our approach demonstrably improves
visual grounding and significantly reduces hallucinations on established
benchmarks. While average pooling offers a straightforward, robust, and
efficient means of incorporating visual information, we believe that more
sophisticated fusion methods could further enhance visual grounding and
cross-modal alignment. Given that the primary focus of this work is to
highlight the modality imbalance and its impact on hallucinations -- and to
show that refining textual embeddings with visual information mitigates this
issue -- we leave exploration of advanced fusion strategies for future work.

</details>


### [35] [Deep learning models are vulnerable, but adversarial examples are even more vulnerable](https://arxiv.org/abs/2511.05073)
*Jun Li,Yanwei Xu,Keran Li,Xiaoli Zhang*

Main category: cs.CV

TL;DR: 本研究发现对抗样本对遮挡高度敏感，并引入滑动掩码置信度熵（SMCE）来量化模型置信度波动。基于此，提出了一种新的检测方法SWM-AED，有效避免了对抗训练的灾难性过拟合，并展现出强大的对抗样本检测性能。


<details>
  <summary>Details</summary>
Motivation: 理解对抗样本和干净样本之间的内在差异是提高深度神经网络（DNN）鲁棒性及对抗攻击检测能力的关键。

Method: 研究首先通过实证发现图像对抗样本对遮挡敏感。在CIFAR-10上使用九种典型攻击生成对抗样本进行受控实验，并引入滑动掩码置信度熵（SMCE）来量化模型在遮挡下的置信度波动。通过掩码熵场图和统计分布支持的SMCE计算，最终提出基于滑动窗口掩码的对抗样本检测（SWM-AED）方法。

Result: 结果显示，对抗样本在遮挡下表现出比原始样本显著更高的置信度波动。所提出的SWM-AED方法在不同分类器和攻击下表现出鲁棒的性能，在大多数情况下检测准确率超过62%，最高可达96.5%。

Conclusion: 对抗样本对遮挡具有显著的敏感性，这一特性可用于开发有效的对抗样本检测方法。SWM-AED利用此特性，成功避免了传统对抗训练的灾难性过拟合问题，实现了高效的对抗样本检测。

Abstract: Understanding intrinsic differences between adversarial examples and clean
samples is key to enhancing DNN robustness and detection against adversarial
attacks. This study first empirically finds that image-based adversarial
examples are notably sensitive to occlusion. Controlled experiments on CIFAR-10
used nine canonical attacks (e.g., FGSM, PGD) to generate adversarial examples,
paired with original samples for evaluation. We introduce Sliding Mask
Confidence Entropy (SMCE) to quantify model confidence fluctuation under
occlusion. Using 1800+ test images, SMCE calculations supported by Mask Entropy
Field Maps and statistical distributions show adversarial examples have
significantly higher confidence volatility under occlusion than originals.
Based on this, we propose Sliding Window Mask-based Adversarial Example
Detection (SWM-AED), which avoids catastrophic overfitting of conventional
adversarial training. Evaluations across classifiers and attacks on CIFAR-10
demonstrate robust performance, with accuracy over 62% in most cases and up to
96.5%.

</details>


### [36] [Role-SynthCLIP: A Role Play Driven Diverse Synthetic Data Approach](https://arxiv.org/abs/2511.05057)
*Yuanxiang Huangfu,Chaochao Wang,Weilei Wang*

Main category: cs.CV

TL;DR: 本文提出Role-SynthCLIP框架，利用多视角角色扮演提示指导多模态大语言模型（MLLMs）生成语义多样化且细粒度的图像-文本对，以提高CLIP模型的训练数据质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有对比语言-图像预训练（CLIP）模型的有效性严重依赖于训练数据的语义多样性和质量。然而，目前的合成数据生成方法主要侧重于增加数据量，这往往导致语义多样性有限和描述冗余或肤浅，从而限制了CLIP的性能。

Method: Role-SynthCLIP通过利用多视角角色扮演提示（例如，组合分析师、图像上下文解释者）来引导多模态大语言模型（MLLMs）从不同角度生成语义多样化的描述。这种机制在不改变图像-文本对总数的情况下，增强了合成对的语义多样性和细粒度的图像-文本对齐，从而提高了描述的表达性和准确性。

Result: 实验结果表明，该方法有效且高效。一个使用仅100万Role-SynthCLIP对训练的CLIP-B/16模型在MS COCO验证集上取得了64.1%的Recall@1，比现有最佳合成数据基线（使用500万对训练）高出2.8个百分点。

Conclusion: Role-SynthCLIP通过引入多视角角色扮演提示生成语义多样化且高质量的图像-文本对，有效解决了现有合成数据方法语义多样性不足的问题，显著提升了CLIP模型的训练效果和数据利用效率。

Abstract: The effectiveness of Contrastive Language-Image Pre-training (CLIP) models
critically depends on the semantic diversity and quality of their training
data. However, while existing synthetic data generation methods primarily focus
on increasing data volume, such emphasis often leads to limited semantic
diversity and redundant or shallow captions. To address this limitation, we
propose Role-SynthCLIP, a novel data synthesis framework that leverages
multi-perspective role-playing prompts (e.g., a compositional analyst, an
interpreter of image context) to guide Multimodal Large Language Models (MLLMs)
in generating semantically diverse captions from distinct viewpoints. This
mechanism enhances the semantic diversity and fine-grained image-text alignment
of synthetic pairs, thereby improving caption expressiveness and accuracy while
keeping the total number of image-text pairs unchanged. Experimental results
demonstrate the effectiveness and efficiency of our method. A CLIP-B/16 model
trained on only 1 million Role-SynthCLIP pairs achieves a Recall@1 of 64.1% on
the MS COCO validation set, surpassing the best existing synthetic data
baseline (trained on 5M pairs) by 2.8 percentage points. The code and trained
models are released at https://github.com/huangfu170/Role-SynthCLIP.

</details>


### [37] [Pressure2Motion: Hierarchical Motion Synthesis from Ground Pressure with Text Guidance](https://arxiv.org/abs/2511.05038)
*Zhengxuan Li,Qinhui Yang,Yiyu Zhuang,Chuan Guo,Xinxin Zuo,Xiaoxiao Long,Yao Yao,Xun Cao,Qiu Shen,Hao Zhu*

Main category: cs.CV

TL;DR: Pressure2Motion是一种新型动作捕捉算法，通过地面压力序列和文本提示合成人体运动，适用于低成本、隐私保护和弱光环境。


<details>
  <summary>Details</summary>
Motivation: 传统的动作捕捉方法需要专业的灯光、相机或可穿戴设备，成本高昂且存在隐私问题。从不确定的压力信号推断全身运动是一个严重病态的问题，现有方法难以解决。

Method: 本文提出了Pressure2Motion，一个利用压力特征作为输入、文本提示作为高级指导约束的生成模型。该模型包含一个双层特征提取器用于精确解释压力数据，以及一个分层扩散模型用于识别大尺度运动轨迹和细微姿态调整。通过结合压力序列的物理线索和描述性文本的语义指导，实现精确的运动生成。

Result: 实验证明，Pressure2Motion能够生成高保真、物理上合理的运动，在该任务上建立了新的最先进水平（SOTA）。它是首个结合压力数据和语言先验进行运动生成的工作，并建立了该任务的第一个基准MPL。

Conclusion: Pressure2Motion提供了一种无需专用设备、低成本、保护隐私的新型动作捕捉解决方案。它通过结合物理压力数据和语义文本指导，有效解决了从压力信号生成全身运动的病态问题，并在该新兴领域树立了新的基准和SOTA。

Abstract: We present Pressure2Motion, a novel motion capture algorithm that synthesizes
human motion from a ground pressure sequence and text prompt. It eliminates the
need for specialized lighting setups, cameras, or wearable devices, making it
suitable for privacy-preserving, low-light, and low-cost motion capture
scenarios. Such a task is severely ill-posed due to the indeterminate nature of
the pressure signals to full-body motion. To address this issue, we introduce
Pressure2Motion, a generative model that leverages pressure features as input
and utilizes a text prompt as a high-level guiding constraint. Specifically,
our model utilizes a dual-level feature extractor that accurately interprets
pressure data, followed by a hierarchical diffusion model that discerns
broad-scale movement trajectories and subtle posture adjustments. Both the
physical cues gained from the pressure sequence and the semantic guidance
derived from descriptive texts are leveraged to guide the motion generation
with precision. To the best of our knowledge, Pressure2Motion is a pioneering
work in leveraging both pressure data and linguistic priors for motion
generation, and the established MPL benchmark is the first benchmark for this
task. Experiments show our method generates high-fidelity, physically plausible
motions, establishing a new state-of-the-art for this task. The codes and
benchmarks will be publicly released upon publication.

</details>


### [38] [From Linear Probing to Joint-Weighted Token Hierarchy: A Foundation Model Bridging Global and Cellular Representations in Biomarker Detection](https://arxiv.org/abs/2511.05150)
*Jingsong Liu,Han Li,Nassir Navab,Peter J. Schüffler*

Main category: cs.CV

TL;DR: JWTH是一个新的病理学基础模型（PFM），通过结合大规模自监督预训练、以细胞为中心的后调优和注意力池化来整合局部和全局特征，显著提高了AI驱动的生物标志物检测在数字病理学中的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的病理学基础模型（PFM）主要依赖全局补丁级嵌入，而忽视了细胞级别的形态学信息，这限制了AI从H&E切片直接推断分子特征的准确性和可解释性。

Method: 本文提出了JWTH（Joint-Weighted Token Hierarchy）模型，它结合了大规模自监督预训练、以细胞为中心的后调优和注意力池化技术，以有效地融合局部（细胞级）和全局（补丁级）的特征标记。

Result: 在涉及四种生物标志物、四项任务和八个队列的测试中，JWTH模型实现了高达8.3%的平衡准确率提升，并比之前的PFM模型平均提高了1.2%。

Conclusion: JWTH模型通过整合细胞级和全局特征，显著提升了数字病理学中AI驱动生物标志物检测的准确性、可解释性和鲁棒性。

Abstract: AI-based biomarkers can infer molecular features directly from hematoxylin &
eosin (H&E) slides, yet most pathology foundation models (PFMs) rely on global
patch-level embeddings and overlook cell-level morphology. We present a PFM
model, JWTH (Joint-Weighted Token Hierarchy), which integrates large-scale
self-supervised pretraining with cell-centric post-tuning and attention pooling
to fuse local and global tokens. Across four tasks involving four biomarkers
and eight cohorts, JWTH achieves up to 8.3% higher balanced accuracy and 1.2%
average improvement over prior PFMs, advancing interpretable and robust
AI-based biomarker detection in digital pathology.

</details>


### [39] [Medical Referring Image Segmentation via Next-Token Mask Prediction](https://arxiv.org/abs/2511.05044)
*Xinyu Chen,Yiran Wang,Gaoyang Pang,Jiafu Hao,Chentao Yue,Luping Zhou,Yonghui Li*

Main category: cs.CV

TL;DR: NTP-MRISeg是一个新颖的框架，将医学指代图像分割（MRIS）重构为统一多模态序列上的自回归下一词元预测任务。它简化了模型设计，并引入了三种策略（NkTP、TCL、HET）来解决预测误差、长尾分布和边界敏感性问题，在MRIS任务上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的医学指代图像分割（MRIS）方法通常涉及复杂的多模态融合或多阶段解码器设计。此外，在将MRIS重构为词元预测任务时，面临曝光偏差、长尾词元分布和精细病灶边缘处理等挑战。

Method: 本文提出了NTP-MRISeg框架，将MRIS重构为对统一的多模态序列（包括词元化的图像、文本和掩码表示）进行自回归下一词元预测。该方法简化了模型设计，实现了端到端训练，并支持使用预训练的词元分析器。为解决挑战，提出了三种策略：1) Next-k Token Prediction (NkTP) 方案以减少累积预测误差；2) Token-level Contrastive Learning (TCL) 以增强边界敏感性并缓解长尾分布效应；3) 基于记忆的Hard Error Token (HET) 优化策略以强调训练中的难点词元。

Result: 在QaTa-COV19和MosMedData+数据集上的大量实验表明，NTP-MRISeg取得了新的最先进（SOTA）性能。

Conclusion: NTP-MRISeg为传统的MRIS流程提供了一个简化且有效的替代方案，并通过其创新的框架和优化策略实现了卓越的性能。

Abstract: Medical Referring Image Segmentation (MRIS) involves segmenting target
regions in medical images based on natural language descriptions. While
achieving promising results, recent approaches usually involve complex design
of multimodal fusion or multi-stage decoders. In this work, we propose
NTP-MRISeg, a novel framework that reformulates MRIS as an autoregressive
next-token prediction task over a unified multimodal sequence of tokenized
image, text, and mask representations. This formulation streamlines model
design by eliminating the need for modality-specific fusion and external
segmentation models, supports a unified architecture for end-to-end training.
It also enables the use of pretrained tokenizers from emerging large-scale
multimodal models, enhancing generalization and adaptability. More importantly,
to address challenges under this formulation-such as exposure bias, long-tail
token distributions, and fine-grained lesion edges-we propose three novel
strategies: (1) a Next-k Token Prediction (NkTP) scheme to reduce cumulative
prediction errors, (2) Token-level Contrastive Learning (TCL) to enhance
boundary sensitivity and mitigate long-tail distribution effects, and (3) a
memory-based Hard Error Token (HET) optimization strategy that emphasizes
difficult tokens during training. Extensive experiments on the QaTa-COV19 and
MosMedData+ datasets demonstrate that NTP-MRISeg achieves new state-of-the-art
performance, offering a streamlined and effective alternative to traditional
MRIS pipelines.

</details>


### [40] [Accurate online action and gesture recognition system using detectors and Deep SPD Siamese Networks](https://arxiv.org/abs/2511.05250)
*Mohamed Sanim Akremi,Rim Slama,Hedi Tabia*

Main category: cs.CV

TL;DR: 本文提出一个基于骨骼序列流的在线连续动作识别系统，包含检测器和分类器，利用半正定（SPD）矩阵和孪生网络，在未分段序列中准确识别动作，并超越了现有技术水平。


<details>
  <summary>Details</summary>
Motivation: 在线连续动作识别在实际应用中更具实用性，但现有基于骨骼的方法大多侧重于分段识别，不适用于在线场景。

Method: 该系统由一个检测器和一个分类器组成。它使用半正定（SPD）矩阵来表示骨骼数据，并通过孪生网络学习其语义相似性。检测器能够预测未分段序列中的动作时间间隔，而分类器则在这些预测间隔内识别动作。该检测器具有灵活性，能够持续识别运动状态。

Result: 在手势识别和身体动作识别基准测试上进行了广泛实验，证明了该在线识别系统的准确性，并且在大多数情况下优于现有最先进的性能。

Conclusion: 所提出的在线连续动作识别系统，通过结合SPD矩阵表示和孪生网络，能够有效地从骨骼序列流中检测和识别动作，并在准确性方面超越了现有技术。

Abstract: Online continuous motion recognition is a hot topic of research since it is
more practical in real life application cases. Recently, Skeleton-based
approaches have become increasingly popular, demonstrating the power of using
such 3D temporal data. However, most of these works have focused on
segment-based recognition and are not suitable for the online scenarios. In
this paper, we propose an online recognition system for skeleton sequence
streaming composed from two main components: a detector and a classifier, which
use a Semi-Positive Definite (SPD) matrix representation and a Siamese network.
The powerful statistical representations for the skeletal data given by the SPD
matrices and the learning of their semantic similarity by the Siamese network
enable the detector to predict time intervals of the motions throughout an
unsegmented sequence. In addition, they ensure the classifier capability to
recognize the motion in each predicted interval. The proposed detector is
flexible and able to identify the kinetic state continuously. We conduct
extensive experiments on both hand gesture and body action recognition
benchmarks to prove the accuracy of our online recognition system which in most
cases outperforms state-of-the-art performances.

</details>


### [41] [4D3R: Motion-Aware Neural Reconstruction and Rendering of Dynamic Scenes from Monocular Videos](https://arxiv.org/abs/2511.05229)
*Mengqi Guo,Bo Xu,Yanyan Li,Gim Hee Lee*

Main category: cs.CV

TL;DR: 4D3R是一种无需相机姿态的动态神经渲染框架，通过解耦静态和动态组件，并引入运动感知束调整和高效运动感知高斯溅射，实现了从单目视频对动态场景进行高质量新视角合成。


<details>
  <summary>Details</summary>
Motivation: 从单目视频对动态场景进行新视角合成，且相机姿态未知，是一个基本挑战。尽管NeRF和3DGS在静态场景中表现出色，但它们难以处理动态内容，并通常依赖预计算的相机姿态。

Method: 本文提出了4D3R框架，采用两阶段方法解耦静态和动态组件。首先利用3D基础模型进行初始姿态和几何估计，然后进行运动感知细化。关键创新包括：1) 运动感知束调整（MA-BA）模块，结合基于Transformer的学习先验和SAM2进行动态对象分割，以实现更准确的相机姿态细化；2) 高效的运动感知高斯溅射（MA-GS）表示，使用控制点、变形场MLP和线性混合蒙皮来建模动态运动，显著降低计算成本。

Result: 在真实世界动态数据集上的实验表明，本文方法比现有最先进方法提高了高达1.8dB的PSNR，尤其在具有大型动态对象的挑战性场景中表现突出，同时与之前的动态场景表示相比，计算需求降低了5倍。

Conclusion: 4D3R在动态场景新视角合成方面取得了显著的性能提升，尤其是在处理大型动态对象和减少计算成本方面，超越了现有最先进的方法，为动态神经渲染领域提供了高效且高质量的解决方案。

Abstract: Novel view synthesis from monocular videos of dynamic scenes with unknown
camera poses remains a fundamental challenge in computer vision and graphics.
While recent advances in 3D representations such as Neural Radiance Fields
(NeRF) and 3D Gaussian Splatting (3DGS) have shown promising results for static
scenes, they struggle with dynamic content and typically rely on pre-computed
camera poses. We present 4D3R, a pose-free dynamic neural rendering framework
that decouples static and dynamic components through a two-stage approach. Our
method first leverages 3D foundational models for initial pose and geometry
estimation, followed by motion-aware refinement. 4D3R introduces two key
technical innovations: (1) a motion-aware bundle adjustment (MA-BA) module that
combines transformer-based learned priors with SAM2 for robust dynamic object
segmentation, enabling more accurate camera pose refinement; and (2) an
efficient Motion-Aware Gaussian Splatting (MA-GS) representation that uses
control points with a deformation field MLP and linear blend skinning to model
dynamic motion, significantly reducing computational cost while maintaining
high-quality reconstruction. Extensive experiments on real-world dynamic
datasets demonstrate that our approach achieves up to 1.8dB PSNR improvement
over state-of-the-art methods, particularly in challenging scenarios with large
dynamic objects, while reducing computational requirements by 5x compared to
previous dynamic scene representations.

</details>


### [42] [SurgiATM: A Physics-Guided Plug-and-Play Model for Deep Learning-Based Smoke Removal in Laparoscopic Surgery](https://arxiv.org/abs/2511.05059)
*Mingyu Sheng,Jianan Fan,Dongnan Liu,Guoyan Zheng,Ron Kikinis,Weidong Cai*

Main category: cs.CV

TL;DR: 本文提出SurgiATM模型，通过结合物理大气模型和数据驱动深度学习，以轻量级、即插即用的方式有效去除手术烟雾，提高现有去烟雾模型的准确性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜手术中，组织烧灼产生的烟雾会严重降低内窥镜图像质量，增加手术风险，阻碍临床决策和计算机辅助分析。因此，去除手术烟雾对于确保患者安全和维持手术效率至关重要。

Method: 本文提出手术大气模型（SurgiATM），它统计性地连接了基于物理的大气模型和数据驱动的深度学习模型，结合了前者卓越的泛化能力和后者的高精度。SurgiATM被设计为一个轻量级、即插即用的模块，可无缝集成到各种手术去烟雾架构中，仅引入两个超参数，没有额外的可训练权重，最大程度保留了原始网络架构。

Result: 在三个公共手术数据集上，对十种去烟雾方法进行了广泛实验，结果表明，整合SurgiATM通常能减少现有模型的恢复误差，相对增强其泛化能力，且无需添加任何可训练层或权重。这突出了所提方法的便捷性、低成本、有效性和泛化性。

Conclusion: SurgiATM模型通过结合物理和深度学习方法，提供了一种方便、低成本、有效且泛化能力强的手术烟雾去除方案，能够显著提升现有去烟雾模型的性能，更好地满足临床需求。

Abstract: During laparoscopic surgery, smoke generated by tissue cauterization can
significantly degrade the visual quality of endoscopic frames, increasing the
risk of surgical errors and hindering both clinical decision-making and
computer-assisted visual analysis. Consequently, removing surgical smoke is
critical to ensuring patient safety and maintaining operative efficiency. In
this study, we propose the Surgical Atmospheric Model (SurgiATM) for surgical
smoke removal. SurgiATM statistically bridges a physics-based atmospheric model
and data-driven deep learning models, combining the superior generalizability
of the former with the high accuracy of the latter. Furthermore, SurgiATM is
designed as a lightweight, plug-and-play module that can be seamlessly
integrated into diverse surgical desmoking architectures to enhance their
accuracy and stability, better meeting clinical requirements. It introduces
only two hyperparameters and no additional trainable weights, preserving the
original network architecture with minimal computational and modification
overhead. We conduct extensive experiments on three public surgical datasets
with ten desmoking methods, involving multiple network architectures and
covering diverse procedures, including cholecystectomy, partial nephrectomy,
and diaphragm dissection. The results demonstrate that incorporating SurgiATM
commonly reduces the restoration errors of existing models and relatively
enhances their generalizability, without adding any trainable layers or
weights. This highlights the convenience, low cost, effectiveness, and
generalizability of the proposed method. The code for SurgiATM is released at
https://github.com/MingyuShengSMY/SurgiATM.

</details>


### [43] [Real-World Adverse Weather Image Restoration via Dual-Level Reinforcement Learning with High-Quality Cold Start](https://arxiv.org/abs/2511.05095)
*Fuyang Liu,Jiaqi Xu,Xiaowei Hu*

Main category: cs.CV

TL;DR: 本文构建了一个物理驱动的高保真天气数据集HFLS-Weather，并设计了一个双层强化学习框架，用于在恶劣天气条件下持续适应和优化视觉感知模型，无需成对监督即可实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模型在合成数据上训练且参数固定，难以泛化到真实世界中复杂的恶劣天气造成的视觉退化，严重影响了实际视觉感知。

Method: 首先，构建了物理驱动的高保真天气数据集HFLS-Weather。然后，设计了一个双层强化学习框架进行冷启动训练：局部层面，通过扰动驱动的图像质量优化（基于奖励学习，无需成对监督）来精炼特定天气的恢复模型；全局层面，元控制器根据场景退化动态协调模型的选择和执行顺序。

Result: 该框架能够持续适应真实世界条件，并在各种恶劣天气场景中实现了最先进的性能。

Conclusion: 所提出的HFLS-Weather数据集和双层强化学习框架有效解决了恶劣天气下的视觉感知挑战，通过无监督的自适应学习机制，实现了卓越的图像恢复效果和对真实世界条件的持续适应性。

Abstract: Adverse weather severely impairs real-world visual perception, while existing
vision models trained on synthetic data with fixed parameters struggle to
generalize to complex degradations. To address this, we first construct
HFLS-Weather, a physics-driven, high-fidelity dataset that simulates diverse
weather phenomena, and then design a dual-level reinforcement learning
framework initialized with HFLS-Weather for cold-start training. Within this
framework, at the local level, weather-specific restoration models are refined
through perturbation-driven image quality optimization, enabling reward-based
learning without paired supervision; at the global level, a meta-controller
dynamically orchestrates model selection and execution order according to scene
degradation. This framework enables continuous adaptation to real-world
conditions and achieves state-of-the-art performance across a wide range of
adverse weather scenarios. Code is available at
https://github.com/xxclfy/AgentRL-Real-Weather

</details>


### [44] [OregairuChar: A Benchmark Dataset for Character Appearance Frequency Analysis in My Teen Romantic Comedy SNAFU](https://arxiv.org/abs/2511.05263)
*Qi Sun,Dingju Zhou,Lina Zhang*

Main category: cs.CV

TL;DR: 该研究引入了OregairuChar数据集，用于分析动漫《我的青春恋爱物语果然有问题。完》中角色的出场频率，并利用目标检测模型预测结果来揭示角色在叙事中的重要性及其演变。


<details>
  <summary>Details</summary>
Motivation: 分析角色出场频率对于理解动漫中的叙事结构、角色重要性和故事进展至关重要。

Method: 研究构建了OregairuChar基准数据集，包含《我的青春恋爱物语果然有问题。完》第三季的1600个手动选择的帧，并标注了11个主要角色的2860个边界框。该数据集涵盖了遮挡、姿势变化和角色间相似性等视觉挑战。研究在该数据集上对多个目标检测模型进行了基准测试，并利用它们的预测结果对角色在剧集中的出现频率进行细粒度分析。

Result: 研究揭示了角色重要性的模式及其在叙事中的演变。OregairuChar数据集提供了一个真实的基础，用于基于外观的研究，并使定量分析成为可能。

Conclusion: OregairuChar数据集通过强调出场频率，为探索计算叙事动态和程式化媒体中以角色为中心的故事讲述提供了一个宝贵的资源。

Abstract: The analysis of character appearance frequency is essential for understanding
narrative structure, character prominence, and story progression in anime. In
this work, we introduce OregairuChar, a benchmark dataset designed for
appearance frequency analysis in the anime series My Teen Romantic Comedy
SNAFU. The dataset comprises 1600 manually selected frames from the third
season, annotated with 2860 bounding boxes across 11 main characters.
OregairuChar captures diverse visual challenges, including occlusion, pose
variation, and inter-character similarity, providing a realistic basis for
appearance-based studies. To enable quantitative research, we benchmark several
object detection models on the dataset and leverage their predictions for
fine-grained, episode-level analysis of character presence over time. This
approach reveals patterns of character prominence and their evolution within
the narrative. By emphasizing appearance frequency, OregairuChar serves as a
valuable resource for exploring computational narrative dynamics and
character-centric storytelling in stylized media.

</details>


### [45] [A Dual-stage Prompt-driven Privacy-preserving Paradigm for Person Re-Identification](https://arxiv.org/abs/2511.05092)
*Ruolin Li,Min Liu,Yuan Bian,Zhaoyang Li,Yuzhen Li,Xueping Wang,Yaonan Wang*

Main category: cs.CV

TL;DR: 本文提出了一种双阶段提示驱动隐私保护范式（DPPP），通过扩散模型生成大规模虚拟行人重识别（Re-ID）数据集GenePerson，并引入提示驱动解耦机制（PDM）学习域不变泛化特征，实现了最先进的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 随着数据隐私问题的日益突出，研究者开始使用虚拟数据训练行人Re-ID模型。然而，现有游戏引擎生成的虚拟数据集存在构建复杂和域泛化能力差的问题，难以应用于实际场景。

Method: 本文提出双阶段提示驱动隐私保护范式（DPPP）。第一阶段，利用包含行人外观、光照和视角等多维度属性的丰富提示驱动扩散模型端到端合成多样化数据，构建了包含130,519张图像和6,641个身份的大规模虚拟数据集GenePerson。第二阶段，提出提示驱动解耦机制（PDM），通过对比学习和两个文本反演网络将图像映射为代表风格和内容的伪词，从而构建风格解耦的内容提示，引导模型学习图像级别的域不变内容特征。

Result: 在GenePerson数据集上使用PDM训练的模型，其泛化性能达到了最先进水平，超越了在流行真实和虚拟Re-ID数据集上训练的模型。

Conclusion: 所提出的DPPP范式，结合GenePerson数据集和PDM机制，有效解决了虚拟数据在行人Re-ID中面临的复杂构建和域泛化挑战，显著提升了模型的泛化能力。

Abstract: With growing concerns over data privacy, researchers have started using
virtual data as an alternative to sensitive real-world images for training
person re-identification (Re-ID) models. However, existing virtual datasets
produced by game engines still face challenges such as complex construction and
poor domain generalization, making them difficult to apply in real scenarios.
To address these challenges, we propose a Dual-stage Prompt-driven
Privacy-preserving Paradigm (DPPP). In the first stage, we generate rich
prompts incorporating multi-dimensional attributes such as pedestrian
appearance, illumination, and viewpoint that drive the diffusion model to
synthesize diverse data end-to-end, building a large-scale virtual dataset
named GenePerson with 130,519 images of 6,641 identities. In the second stage,
we propose a Prompt-driven Disentanglement Mechanism (PDM) to learn
domain-invariant generalization features. With the aid of contrastive learning,
we employ two textual inversion networks to map images into pseudo-words
representing style and content, respectively, thereby constructing
style-disentangled content prompts to guide the model in learning
domain-invariant content features at the image level. Experiments demonstrate
that models trained on GenePerson with PDM achieve state-of-the-art
generalization performance, surpassing those on popular real and virtual Re-ID
datasets.

</details>


### [46] [DeepEyesV2: Toward Agentic Multimodal Model](https://arxiv.org/abs/2511.05271)
*Jack Hong,Chenxiao Zhao,ChengLin Zhu,Weiheng Lu,Guohai Xu,Xing Yu*

Main category: cs.CV

TL;DR: 本文介绍了DeepEyesV2，一个通过两阶段训练（冷启动和强化学习）构建的代理式多模态模型，用于实现工具调用和复杂推理。同时提出了RealX-Bench基准来评估其在真实世界场景中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的代理式多模态模型不仅需要理解文本和图像，还应主动调用外部工具并将其整合到推理中。研究发现，仅靠直接强化学习难以实现稳健的工具使用行为，这促使了分阶段训练方法的探索。

Method: 本文提出了DeepEyesV2模型，并采用两阶段训练管道：首先是“冷启动”阶段，用于建立工具使用模式；其次是强化学习阶段，用于进一步优化工具调用。研究团队还策划了一个多样化且具有挑战性的训练数据集，并引入了RealX-Bench，一个旨在评估真实世界多模态推理的综合基准。

Result: DeepEyesV2在RealX-Bench和其他代表性基准上表现出有效性，涵盖了真实世界理解、数学推理和搜索密集型任务。它展现了任务自适应的工具调用能力（如感知任务使用图像操作，推理任务使用数值计算），且强化学习进一步促进了复杂的工具组合和基于上下文的选择性工具调用。

Conclusion: 本研究通过DeepEyesV2及其两阶段训练方法，为开发代理式多模态模型提供了指导，强调了数据构建、训练方法和模型评估的重要性，特别是分阶段训练在实现稳健工具使用行为方面的有效性。

Abstract: Agentic multimodal models should not only comprehend text and images, but
also actively invoke external tools, such as code execution environments and
web search, and integrate these operations into reasoning. In this work, we
introduce DeepEyesV2 and explore how to build an agentic multimodal model from
the perspectives of data construction, training methods, and model evaluation.
We observe that direct reinforcement learning alone fails to induce robust
tool-use behavior. This phenomenon motivates a two-stage training pipeline: a
cold-start stage to establish tool-use patterns, and reinforcement learning
stage to further refine tool invocation. We curate a diverse, moderately
challenging training dataset, specifically including examples where tool use is
beneficial. We further introduce RealX-Bench, a comprehensive benchmark
designed to evaluate real-world multimodal reasoning, which inherently requires
the integration of multiple capabilities, including perception, search, and
reasoning. We evaluate DeepEyesV2 on RealX-Bench and other representative
benchmarks, demonstrating its effectiveness across real-world understanding,
mathematical reasoning, and search-intensive tasks. Moreover, DeepEyesV2
exhibits task-adaptive tool invocation, tending to use image operations for
perception tasks and numerical computations for reasoning tasks. Reinforcement
learning further enables complex tool combinations and allows model to
selectively invoke tools based on context. We hope our study can provide
guidance for community in developing agentic multimodal models.

</details>


### [47] [Early Alzheimer's Disease Detection from Retinal OCT Images: A UK Biobank Study](https://arxiv.org/abs/2511.05106)
*Yasemin Turkan,F. Boray Tek,M. Serdar Nazlı,Öykü Eren*

Main category: cs.CV

TL;DR: 本研究首次将深度学习应用于原始OCT B扫描图像，以预测阿尔茨海默病（AD）的早期发生，并识别了AD组和对照组之间的视网膜结构差异。


<details>
  <summary>Details</summary>
Motivation: 以往研究主要关注视网膜分层厚度测量与AD的关联，但直接对原始OCT B扫描图像进行分类以实现AD的早期检测仍未被探索。早期检测比诊断更具挑战性，因为成像发生在临床诊断前数年，需要更敏感的方法。

Method: 研究使用了来自英国生物样本库的OCT B扫描图像，通过主体级别的交叉验证数据集，对多个预训练模型（包括基于ImageNet的网络和OCT专用的RETFound transformer）进行了微调和评估。为减少小规模、高维数据集的过拟合，采用了标准和OCT特有的数据增强技术，并引入了根据成像后四年内诊断的病例赋予更高权重的年份加权损失函数。

Result: ResNet-34模型表现出最稳定的结果，在四年队列中实现了0.62的AUC（曲线下面积）。尽管该AUC值低于临床应用阈值，但可解释性分析证实了AD组和对照组之间在中央黄斑区存在局部结构差异。

Conclusion: 这些发现为基于OCT的AD预测提供了基线，突出了在AD诊断前数年检测细微视网膜生物标志物的挑战，并指出未来需要更大的数据集和多模态方法来提高预测准确性。

Abstract: Alterations in retinal layer thickness, measurable using Optical Coherence
Tomography (OCT), have been associated with neurodegenerative diseases such as
Alzheimer's disease (AD). While previous studies have mainly focused on
segmented layer thickness measurements, this study explored the direct
classification of OCT B-scan images for the early detection of AD. To our
knowledge, this is the first application of deep learning to raw OCT B-scans
for AD prediction in the literature. Unlike conventional medical image
classification tasks, early detection is more challenging than diagnosis
because imaging precedes clinical diagnosis by several years. We fine-tuned and
evaluated multiple pretrained models, including ImageNet-based networks and the
OCT-specific RETFound transformer, using subject-level cross-validation
datasets matched for age, sex, and imaging instances from the UK Biobank
cohort. To reduce overfitting in this small, high-dimensional dataset, both
standard and OCT-specific augmentation techniques were applied, along with a
year-weighted loss function that prioritized cases diagnosed within four years
of imaging. ResNet-34 produced the most stable results, achieving an AUC of
0.62 in the 4-year cohort. Although below the threshold for clinical
application, our explainability analyses confirmed localized structural
differences in the central macular subfield between the AD and control groups.
These findings provide a baseline for OCT-based AD prediction, highlight the
challenges of detecting subtle retinal biomarkers years before AD diagnosis,
and point to the need for larger datasets and multimodal approaches.

</details>


### [48] [LiveStar: Live Streaming Assistant for Real-World Online Video Understanding](https://arxiv.org/abs/2511.05299)
*Zhenyu Yang,Kairui Zhang,Yuhang Hu,Bing Wang,Shengsheng Qian,Bin Wen,Fan Yang,Tingting Gao,Weiming Dong,Changsheng Xu*

Main category: cs.CV

TL;DR: LiveStar是一个创新的直播助手，通过自适应流解码实现持续主动响应，解决了现有在线Video-LLMs在处理连续帧输入和确定最佳响应时机方面的挑战，显著提升了实时性和叙事连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有在线Video-LLMs难以同时处理连续帧输入和确定最佳响应时机，导致实时响应性和叙事连贯性受损。

Method: ['提出了一种训练策略，实现可变长度视频流的增量视频-语言对齐，保持时间一致性。', '设计了一个响应-静默解码框架，通过单次前向验证确定最佳主动响应时机。', '采用内存感知加速，通过峰值-末端内存压缩和流式键值缓存，加速长视频的在线推理。', '构建了OmniStar数据集，包含15个真实场景和5个在线视频理解评估任务。']

Result: ['在语义正确性方面平均提高19.5%。', '响应时间差异减少18.1%。', '所有OmniStar任务的FPS提高12.0%。', '推理速度提高1.53倍。', '在三个基准测试中均达到最先进的性能。']

Conclusion: LiveStar通过其创新的训练策略、响应-静默解码框架和内存感知加速，显著提升了在线视频理解的实时性、准确性和效率，达到了最先进的性能。

Abstract: Despite significant progress in Video Large Language Models (Video-LLMs) for
offline video understanding, existing online Video-LLMs typically struggle to
simultaneously process continuous frame-by-frame inputs and determine optimal
response timing, often compromising real-time responsiveness and narrative
coherence. To address these limitations, we introduce LiveStar, a pioneering
live streaming assistant that achieves always-on proactive responses through
adaptive streaming decoding. Specifically, LiveStar incorporates: (1) a
training strategy enabling incremental video-language alignment for
variable-length video streams, preserving temporal consistency across
dynamically evolving frame sequences; (2) a response-silence decoding framework
that determines optimal proactive response timing via a single forward pass
verification; (3) memory-aware acceleration via peak-end memory compression for
online inference on 10+ minute videos, combined with streaming key-value cache
to achieve 1.53x faster inference. We also construct an OmniStar dataset, a
comprehensive dataset for training and benchmarking that encompasses 15 diverse
real-world scenarios and 5 evaluation tasks for online video understanding.
Extensive experiments across three benchmarks demonstrate LiveStar's
state-of-the-art performance, achieving an average 19.5% improvement in
semantic correctness with 18.1% reduced timing difference compared to existing
online Video-LLMs, while improving FPS by 12.0% across all five OmniStar tasks.
Our model and dataset can be accessed at https://github.com/yzy-bupt/LiveStar.

</details>


### [49] [SnowyLane: Robust Lane Detection on Snow-covered Rural Roads Using Infrastructural Elements](https://arxiv.org/abs/2511.05108)
*Jörg Gamerdinger,Benedict Wetzel,Patrick Schulz,Sven Teufel,Oliver Bringmann*

Main category: cs.CV

TL;DR: 本文提出了一种在积雪环境中进行车道检测的新方法，通过检测路边指示柱（分道柱）作为间接车道指示器，避免了对传统车道线的依赖。该方法利用参数化贝塞尔曲线拟合车道轨迹，并引入了一个新的合成数据集SnowyLane。实验证明，该方法在恶劣天气下表现出显著的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在积雪环境中，车道线经常缺失或被遮挡，导致自动驾驶中的车道检测面临重大挑战。

Method: 该方法首先感知路边的垂直指示柱（分道柱），然后利用参数化贝塞尔曲线模型，结合空间一致性和道路几何形状，拟合出平滑的车道轨迹。为支持训练和评估，本文还引入了一个新的合成数据集SnowyLane，包含80,000帧带标注的冬季驾驶场景。

Result: 与现有最先进的车道检测系统相比，本文方法在恶劣天气下，特别是在大雪遮挡的情况下，表现出显著提高的鲁棒性。

Conclusion: 这项工作为冬季场景下的可靠车道检测奠定了坚实基础，并为全天候自动驾驶的未来研究贡献了宝贵的资源（数据集）。

Abstract: Lane detection for autonomous driving in snow-covered environments remains a
major challenge due to the frequent absence or occlusion of lane markings. In
this paper, we present a novel, robust and realtime capable approach that
bypasses the reliance on traditional lane markings by detecting roadside
features,specifically vertical roadside posts called delineators, as indirect
lane indicators. Our method first perceives these posts, then fits a smooth
lane trajectory using a parameterized Bezier curve model, leveraging spatial
consistency and road geometry. To support training and evaluation in these
challenging scenarios, we introduce SnowyLane, a new synthetic dataset
containing 80,000 annotated frames capture winter driving conditions, with
varying snow coverage, and lighting conditions. Compared to state-of-the-art
lane detection systems, our approach demonstrates significantly improved
robustness in adverse weather, particularly in cases with heavy snow occlusion.
This work establishes a strong foundation for reliable lane detection in winter
scenarios and contributes a valuable resource for future research in
all-weather autonomous driving. The dataset is available at
https://ekut-es.github.io/snowy-lane

</details>


### [50] [Another BRIXEL in the Wall: Towards Cheaper Dense Features](https://arxiv.org/abs/2511.05168)
*Alexander Lappe,Martin A. Giese*

Main category: cs.CV

TL;DR: DINOv3等视觉基础模型生成高分辨率密集特征图计算成本高昂。BRIXEL提出一种简单的知识蒸馏方法，使学生模型能以更低的计算成本生成与教师模型相似的高分辨率特征图，并在下游任务中显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 视觉基础模型（如DINOv3）虽然能在全局和局部密集任务上表现出色，并生成非常细粒度的密集特征图，但其需要极高分辨率的输入图像，且由于Transformer架构的平方复杂度，计算成本巨大。

Method: 本文提出BRIXEL，一种简单的知识蒸馏方法。学生模型通过学习来在高分辨率下复现其自身的特征图。

Result: 尽管BRIXEL方法简单，但在固定分辨率下，它在下游任务中的性能显著优于基线DINOv3模型。此外，它能以极低的计算成本生成与教师模型非常相似的特征图。

Conclusion: BRIXEL成功解决了DINOv3模型生成高分辨率特征图所带来的高计算成本问题，同时在性能上保持甚至超越了基线模型。

Abstract: Vision foundation models achieve strong performance on both global and
locally dense downstream tasks. Pretrained on large images, the recent DINOv3
model family is able to produce very fine-grained dense feature maps, enabling
state-of-the-art performance. However, computing these feature maps requires
the input image to be available at very high resolution, as well as large
amounts of compute due to the squared complexity of the transformer
architecture. To address these issues, we propose BRIXEL, a simple knowledge
distillation approach that has the student learn to reproduce its own feature
maps at higher resolution. Despite its simplicity, BRIXEL outperforms the
baseline DINOv3 models by large margins on downstream tasks when the resolution
is kept fixed. Moreover, it is able to produce feature maps that are very
similar to those of the teacher at a fraction of the computational cost. Code
and model weights are available at https://github.com/alexanderlappe/BRIXEL.

</details>


### [51] [Splatography: Sparse multi-view dynamic Gaussian Splatting for filmmaking challenges](https://arxiv.org/abs/2511.05152)
*Adrian Azzarelli,Nantheera Anantrasirichai,David R Bull*

Main category: cs.CV

TL;DR: 本文提出一种可变形高斯泼溅（Deformable Gaussian Splatting）方法，通过将前景和背景组件分离并采用差异化训练，以从稀疏多视角视频中实现高质量动态三维重建，尤其适用于电影制作，且无需密集掩码监督。


<details>
  <summary>Details</summary>
Motivation: 在电影制作中，预算限制常导致稀疏的摄像机配置，这使得现有最先进（SotA）的可变形高斯泼溅方法难以捕捉复杂的动态特征并进行高质量的三维重建。

Method: 该方法将规范高斯（canonical Gaussians）和形变场（deformation field）在t=0时刻通过稀疏掩码分割为前景和背景两部分。在规范预训练阶段，每个表示都用不同的损失函数单独训练。在动态训练阶段，为每个形变场建模不同的参数：前景学习颜色、位置和旋转的变化（处理多样动态特征），而背景（包含摄制组和设备，通常较暗且不那么动态）仅学习点位置的变化。

Result: 在三维和2.5维娱乐数据集上，该方法产生了最先进的定性和定量结果，在三维场景中PSNR提高高达3，模型大小减半。与SotA方法不同，它无需密集掩码监督即可生成包含透明和动态纹理的分割动态重建。

Conclusion: 本文提出的方法有效解决了稀疏摄像机配置下动态三维重建的挑战，通过前景/背景分离和差异化训练，实现了优于现有技术的结果，模型更小，并能生成有价值的分割动态重建，非常适合电影制作场景。

Abstract: Deformable Gaussian Splatting (GS) accomplishes photorealistic dynamic 3-D
reconstruction from dense multi-view video (MVV) by learning to deform a
canonical GS representation. However, in filmmaking, tight budgets can result
in sparse camera configurations, which limits state-of-the-art (SotA) methods
when capturing complex dynamic features. To address this issue, we introduce an
approach that splits the canonical Gaussians and deformation field into
foreground and background components using a sparse set of masks for frames at
t=0. Each representation is separately trained on different loss functions
during canonical pre-training. Then, during dynamic training, different
parameters are modeled for each deformation field following common filmmaking
practices. The foreground stage contains diverse dynamic features so changes in
color, position and rotation are learned. While, the background containing
film-crew and equipment, is typically dimmer and less dynamic so only changes
in point position are learned. Experiments on 3-D and 2.5-D entertainment
datasets show that our method produces SotA qualitative and quantitative
results; up to 3 PSNR higher with half the model size on 3-D scenes. Unlike the
SotA and without the need for dense mask supervision, our method also produces
segmented dynamic reconstructions including transparent and dynamic textures.
Code and video comparisons are available online:
https://interims-git.github.io/

</details>


### [52] [Rethinking Metrics and Diffusion Architecture for 3D Point Cloud Generation](https://arxiv.org/abs/2511.05308)
*Matteo Bastico,David Ryckelynck,Laurent Corté,Yannick Tillier,Etienne Decencière*

Main category: cs.CV

TL;DR: 本文揭示了现有三维点云生成模型评估指标（特别是基于Chamfer距离的）的不足，并提出了改进的评估方法（引入样本对齐、密度感知Chamfer距离DCD和表面法线一致性SNC）。此外，作者还提出了一种新的高性能三维生成模型——扩散点云Transformer，并在ShapeNet数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 随着三维点云技术的发展，对复杂生成模型和可靠评估指标的需求激增。然而，常用的点云生成模型评估指标（特别是基于Chamfer距离的）在面对缺陷时缺乏鲁棒性，并且未能有效捕捉几何保真度和局部形状一致性。

Method: 1. 暴露并分析了基于Chamfer距离的常用评估指标在鲁棒性和捕捉几何细节方面的不足。2. 提出在距离计算前引入样本对齐，并将Chamfer距离替换为密度感知Chamfer距离（DCD），以提高评估指标的一致性和鲁棒性。3. 引入了一种名为表面法线一致性（SNC）的新颖指标，通过比较估计的点法线来近似表面相似性。4. 基于Transformer模型在点云分析方面的最新进展，提出了一种新的高保真三维结构生成架构——扩散点云Transformer。

Result: 1. 引入样本对齐和使用DCD是确保点云生成模型评估指标一致性和鲁棒性的关键步骤。2. 新的SNC指标与传统指标结合使用时，能提供更全面的生成样本质量评估。3. 扩散点云Transformer模型在ShapeNet数据集上进行了广泛实验和比较，结果显示其性能优于现有解决方案，特别是在生成点云的质量方面，达到了新的最先进水平。

Conclusion: 常用的点云生成评估指标存在鲁棒性问题且无法充分捕捉几何细节。通过引入样本对齐、密度感知Chamfer距离（DCD）和表面法线一致性（SNC），可以显著提高评估指标的可靠性和全面性。此外，本文提出的扩散点云Transformer是一种有效生成高保真三维结构的架构，并在生成质量上取得了当前最佳的性能。

Abstract: As 3D point clouds become a cornerstone of modern technology, the need for
sophisticated generative models and reliable evaluation metrics has grown
exponentially. In this work, we first expose that some commonly used metrics
for evaluating generated point clouds, particularly those based on Chamfer
Distance (CD), lack robustness against defects and fail to capture geometric
fidelity and local shape consistency when used as quality indicators. We
further show that introducing samples alignment prior to distance calculation
and replacing CD with Density-Aware Chamfer Distance (DCD) are simple yet
essential steps to ensure the consistency and robustness of point cloud
generative model evaluation metrics. While existing metrics primarily focus on
directly comparing 3D Euclidean coordinates, we present a novel metric, named
Surface Normal Concordance (SNC), which approximates surface similarity by
comparing estimated point normals. This new metric, when combined with
traditional ones, provides a more comprehensive evaluation of the quality of
generated samples. Finally, leveraging recent advancements in transformer-based
models for point cloud analysis, such as serialized patch attention , we
propose a new architecture for generating high-fidelity 3D structures, the
Diffusion Point Transformer. We perform extensive experiments and comparisons
on the ShapeNet dataset, showing that our model outperforms previous solutions,
particularly in terms of quality of generated point clouds, achieving new
state-of-the-art. Code available at
https://github.com/matteo-bastico/DiffusionPointTransformer.

</details>


### [53] [MUSE: Multi-Scale Dense Self-Distillation for Nucleus Detection and Classification](https://arxiv.org/abs/2511.05170)
*Zijiang Yang,Hanqing Chao,Bokai Zhao,Yelin Yang,Yunshuo Zhang,Dongmei Fu,Junping Zhang,Le Lu,Ke Yan,Dakai Jin,Minfeng Xu,Yun Bian,Hui Jiang*

Main category: cs.CV

TL;DR: MUSE是一种新颖的自监督学习方法，通过多尺度密集自蒸馏（MUSE）和基于细胞核的局部自蒸馏（NuLo）机制，解决了组织病理学中细胞核检测和分类（NDC）对大量标注的依赖，并能有效利用未标注数据，性能超越了现有监督基线和通用病理学基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有的细胞核检测与分类（NDC）方法严重依赖耗时耗力的细胞核级别标注，并且难以充分利用大规模未标注数据来学习判别性的细胞核表征。

Method: 本文提出了MUSE（MUlti-scale denSE self-distillation），一种专为NDC设计的自监督学习方法。其核心是NuLo（Nucleus-based Local self-distillation），一种坐标引导机制，通过允许基于预测细胞核位置的灵活局部自蒸馏，消除了增强视图之间严格的空间对齐需求，实现了关键的跨尺度对齐，从而解锁了模型学习细粒度细胞核级别表示的能力。为支持MUSE，还设计了一个简单有效的编解码器架构和一个大视野半监督微调策略，以最大化未标注病理图像的价值。

Result: 在三个广泛使用的基准测试上进行的广泛实验表明，MUSE有效解决了组织病理学NDC的核心挑战。其模型不仅超越了最先进的监督基线，而且优于通用的病理学基础模型。

Conclusion: MUSE是一种新颖且有效的自监督学习方法，专门针对组织病理学中的细胞核检测和分类任务，通过利用未标注数据和创新的自蒸馏机制，显著提升了性能并解决了现有方法的局限性。

Abstract: Nucleus detection and classification (NDC) in histopathology analysis is a
fundamental task that underpins a wide range of high-level pathology
applications. However, existing methods heavily rely on labor-intensive
nucleus-level annotations and struggle to fully exploit large-scale unlabeled
data for learning discriminative nucleus representations. In this work, we
propose MUSE (MUlti-scale denSE self-distillation), a novel self-supervised
learning method tailored for NDC. At its core is NuLo (Nucleus-based Local
self-distillation), a coordinate-guided mechanism that enables flexible local
self-distillation based on predicted nucleus positions. By removing the need
for strict spatial alignment between augmented views, NuLo allows critical
cross-scale alignment, thus unlocking the capacity of models for fine-grained
nucleus-level representation. To support MUSE, we design a simple yet effective
encoder-decoder architecture and a large field-of-view semi-supervised
fine-tuning strategy that together maximize the value of unlabeled pathology
images. Extensive experiments on three widely used benchmarks demonstrate that
MUSE effectively addresses the core challenges of histopathological NDC. The
resulting models not only surpass state-of-the-art supervised baselines but
also outperform generic pathology foundation models.

</details>


### [54] [AI Assisted AR Assembly: Object Recognition and Computer Vision for Augmented Reality Assisted Assembly](https://arxiv.org/abs/2511.05394)
*Alexander Htet Kyaw,Haotian Ma,Sasa Zivkovic,Jenny Sabin*

Main category: cs.CV

TL;DR: 本文提出了一种AI辅助的增强现实（AR）装配工作流程，利用深度学习进行物体识别，为装配提供分步指导，无需人工预处理组件。


<details>
  <summary>Details</summary>
Motivation: 目前的装配流程需要人工搜索、分类或标记组件，耗时且易出错。研究旨在通过将装配指令与组件的实时位置相结合，消除这些手动步骤。

Method: 该系统采用基于深度学习的物体识别技术来识别不同的装配组件。通过增强现实在物理空间中显示对应组件的边界框和放置位置，提供分步指导。

Result: 通过乐高雕塑装配的案例研究，验证了使用物体识别技术进行AR辅助装配的可行性，系统能有效识别组件并显示指令。

Conclusion: 物体识别技术在AR辅助装配中是可行且有效的，能够简化装配流程，消除对组件进行手动搜索、分类或标记的需求。

Abstract: We present an AI-assisted Augmented Reality assembly workflow that uses deep
learning-based object recognition to identify different assembly components and
display step-by-step instructions. For each assembly step, the system displays
a bounding box around the corresponding components in the physical space, and
where the component should be placed. By connecting assembly instructions with
the real-time location of relevant components, the system eliminates the need
for manual searching, sorting, or labeling of different components before each
assembly. To demonstrate the feasibility of using object recognition for
AR-assisted assembly, we highlight a case study involving the assembly of LEGO
sculptures.

</details>


### [55] [Multi-modal Loop Closure Detection with Foundation Models in Severely Unstructured Environments](https://arxiv.org/abs/2511.05404)
*Laura Alejandra Encinar Gonzalez,John Folkesson,Rudolph Triebel,Riccardo Giubilato*

Main category: cs.CV

TL;DR: MPRF是一个多模态（视觉+激光雷达）管道，利用基于Transformer的基础模型在GNSS受限的非结构化环境中实现鲁棒的闭环检测和姿态估计，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在GNSS受限的环境（如行星探索）中，闭环检测对SLAM至关重要。然而，视觉方法常因混叠和弱纹理而失效，激光雷达方法则受稀疏性和模糊性困扰。

Method: MPRF是一个多模态管道，利用基于Transformer的基础模型处理视觉和激光雷达数据。它整合了一个两阶段的视觉检索策略（结合DINOv2特征和SALAD聚合进行候选筛选）以及显式的6自由度姿态估计（使用基于SONATA的激光雷达描述符进行几何验证）。

Result: 在S3LI和S3LI Vulcano数据集上的实验表明，MPRF在精度上优于最先进的检索方法，并在低纹理区域增强了姿态估计的鲁棒性。它在准确性、效率和可靠性之间取得了良好的平衡，并为SLAM后端提供了可解释的对应关系。

Conclusion: MPRF展示了基础模型在统一地点识别和姿态估计方面的潜力，为GNSS受限的严重非结构化环境中的鲁棒闭环检测提供了有效解决方案。

Abstract: Robust loop closure detection is a critical component of Simultaneous
Localization and Mapping (SLAM) algorithms in GNSS-denied environments, such as
in the context of planetary exploration. In these settings, visual place
recognition often fails due to aliasing and weak textures, while LiDAR-based
methods suffer from sparsity and ambiguity. This paper presents MPRF, a
multimodal pipeline that leverages transformer-based foundation models for both
vision and LiDAR modalities to achieve robust loop closure in severely
unstructured environments. Unlike prior work limited to retrieval, MPRF
integrates a two-stage visual retrieval strategy with explicit 6-DoF pose
estimation, combining DINOv2 features with SALAD aggregation for efficient
candidate screening and SONATA-based LiDAR descriptors for geometric
verification. Experiments on the S3LI dataset and S3LI Vulcano dataset show
that MPRF outperforms state-of-the-art retrieval methods in precision while
enhancing pose estimation robustness in low-texture regions. By providing
interpretable correspondences suitable for SLAM back-ends, MPRF achieves a
favorable trade-off between accuracy, efficiency, and reliability,
demonstrating the potential of foundation models to unify place recognition and
pose estimation. Code and models will be released at github.com/DLR-RM/MPRF.

</details>


### [56] [Walk the Lines 2: Contour Tracking for Detailed Segmentation](https://arxiv.org/abs/2511.05210)
*André Peter Kelm,Max Braeschke,Emre Gülsoylu,Simone Frintrop*

Main category: cs.CV

TL;DR: 本文提出了Walk the Lines 2 (WtL2)，一种独特的轮廓跟踪算法，专门用于红外(IR)舰船和RGB图像中各种物体的精细分割，它通过轮廓跟踪替代NMS，实现了高IoU和详细的分割效果。


<details>
  <summary>Details</summary>
Motivation: 原有的Walk the Lines (WtL)算法仅专注于彩色图像中的舰船精细分割。研究动机在于将该方法扩展到红外图像中的舰船分割，并应用于RGB图像中的多种不同物体，同时通过轮廓跟踪改进标准的非极大值抑制(NMS)方法以获得更精细的分割。

Method: WtL2通过轮廓跟踪来精细化物体轮廓，直到形成一个1像素宽的闭合形状，从而替代了NMS，并在前景-背景场景中形成可分割区域。为实现红外分割，算法调整了其输入（物体轮廓检测器）以适应红外舰船。此外，算法也进行了增强，以处理更广泛的RGB物体。

Result: WtL2在红外舰船和各种RGB物体的分割中表现出色，在实现闭合物体轮廓方面优于最新一代的基于轮廓的方法，提供了高峰值交并比(IoU)和令人印象深刻的细节。

Conclusion: WtL2是一种引人注目的方法，适用于需要精细分割或高质量样本的专业应用，有望加速图像分割领域中几个小众区域的进展。

Abstract: This paper presents Walk the Lines 2 (WtL2), a unique contour tracking
algorithm specifically adapted for detailed segmentation of infrared (IR) ships
and various objects in RGB.1 This extends the original Walk the Lines (WtL)
[12], which focused solely on detailed ship segmentation in color. These
innovative WtLs can replace the standard non-maximum suppression (NMS) by using
contour tracking to refine the object contour until a 1-pixel-wide closed shape
can be binarized, forming a segmentable area in foreground-background
scenarios. WtL2 broadens the application range of WtL beyond its original
scope, adapting to IR and expanding to diverse objects within the RGB context.
To achieve IR segmentation, we adapt its input, the object contour detector, to
IR ships. In addition, the algorithm is enhanced to process a wide range of RGB
objects, outperforming the latest generation of contour-based methods when
achieving a closed object contour, offering high peak Intersection over Union
(IoU) with impressive details. This positions WtL2 as a compelling method for
specialized applications that require detailed segmentation or high-quality
samples, potentially accelerating progress in several niche areas of image
segmentation.

</details>


### [57] [FreeControl: Efficient, Training-Free Structural Control via One-Step Attention Extraction](https://arxiv.org/abs/2511.05219)
*Jiang Lin,Xinyu Chen,Song Wu,Zhiqiu Zhang,Jizhi Zhang,Ye Wang,Qiang Tang,Qian Wang,Jian Yang,Zili Yi*

Main category: cs.CV

TL;DR: FreeControl是一个无需训练的框架，通过一步注意力提取和潜在条件解耦（LCD），实现扩散模型中高效且高质量的语义结构控制，支持组合式设计，成本低廉。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型结构控制方法存在局限性：ControlNet依赖手工条件图和重新训练，缺乏灵活性和泛化性；基于反演的方法虽然对齐性强，但由于双路径去噪导致推理成本高昂。

Method: FreeControl采用以下方法：1. 一步注意力提取：从单个最优关键时间步提取注意力，并在整个去噪过程中重复使用，无需反演或重新训练。2. 潜在条件解耦（LCD）：将关键时间步与用于注意力提取的噪声潜在空间分离，以提高注意力质量并消除结构伪影。3. 组合式控制：支持通过多源参考图像进行组合式控制，实现场景布局设计和更强的提示对齐。

Result: FreeControl在不进行训练的情况下，实现了结构和语义对齐、视觉连贯的图像生成。它提供了直观的组合设计灵活性，与现代扩散模型兼容，且仅增加约5%的额外成本。该方法解决了现有方法的效率和灵活性问题。

Conclusion: FreeControl为测试时控制引入了一种新范式，能够直接从原始图像生成结构和语义对齐、视觉连贯的图像，并具有灵活的组合设计能力和对现代扩散模型的兼容性，且成本极低。

Abstract: Controlling the spatial and semantic structure of diffusion-generated images
remains a challenge. Existing methods like ControlNet rely on handcrafted
condition maps and retraining, limiting flexibility and generalization.
Inversion-based approaches offer stronger alignment but incur high inference
cost due to dual-path denoising. We present FreeControl, a training-free
framework for semantic structural control in diffusion models. Unlike prior
methods that extract attention across multiple timesteps, FreeControl performs
one-step attention extraction from a single, optimally chosen key timestep and
reuses it throughout denoising. This enables efficient structural guidance
without inversion or retraining. To further improve quality and stability, we
introduce Latent-Condition Decoupling (LCD): a principled separation of the key
timestep and the noised latent used in attention extraction. LCD provides finer
control over attention quality and eliminates structural artifacts. FreeControl
also supports compositional control via reference images assembled from
multiple sources - enabling intuitive scene layout design and stronger prompt
alignment. FreeControl introduces a new paradigm for test-time control,
enabling structurally and semantically aligned, visually coherent generation
directly from raw images, with the flexibility for intuitive compositional
design and compatibility with modern diffusion models at approximately 5
percent additional cost.

</details>


### [58] [ADPretrain: Advancing Industrial Anomaly Detection via Anomaly Representation Pretraining](https://arxiv.org/abs/2511.05245)
*Xincheng Yao,Yan Luo,Zefeng Qian,Chongyang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种专门为工业异常检测设计的新型预训练表示学习框架，通过在大型AD数据集上使用角度和范数导向的对比损失，学习鲁棒且具有区分性的特征，显著优于基于ImageNet预训练的现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的异常检测(AD)方法严重依赖于ImageNet预训练的特征网络，但ImageNet预训练的目标与AD任务不匹配（不旨在区分正常与异常），且自然图像与工业图像之间存在分布偏移，导致ImageNet预训练特征对AD任务次优。

Method: 本文提出了一种新颖的AD表示学习框架，专注于学习工业异常检测的鲁棒和判别性预训练表示。具体方法包括：1) 提出角度和范数导向的对比损失，以同时最大化正常和异常特征之间的角度和范数差异；2) 在大型AD数据集RealIAD上进行预训练，以避免自然图像的分布偏移；3) 基于类别泛化表示（残差特征）学习预训练的AD表示，以进一步缓解预训练数据和下游AD数据集之间的潜在偏移。

Result: 通过在五种嵌入式AD方法中简单替换其原始特征为本文提出的预训练表示，并在五个AD数据集和五个骨干网络上进行了广泛实验，结果一致表明本文预训练特征的优越性。

Conclusion: 本文提出的专门为异常检测任务设计的预训练表示学习框架，能够学习到更适合工业异常检测任务的鲁棒和判别性特征，显著提升了现有AD方法的性能，克服了ImageNet预训练的局限性。

Abstract: The current mainstream and state-of-the-art anomaly detection (AD) methods
are substantially established on pretrained feature networks yielded by
ImageNet pretraining. However, regardless of supervised or self-supervised
pretraining, the pretraining process on ImageNet does not match the goal of
anomaly detection (i.e., pretraining in natural images doesn't aim to
distinguish between normal and abnormal). Moreover, natural images and
industrial image data in AD scenarios typically have the distribution shift.
The two issues can cause ImageNet-pretrained features to be suboptimal for AD
tasks. To further promote the development of the AD field, pretrained
representations specially for AD tasks are eager and very valuable. To this
end, we propose a novel AD representation learning framework specially designed
for learning robust and discriminative pretrained representations for
industrial anomaly detection. Specifically, closely surrounding the goal of
anomaly detection (i.e., focus on discrepancies between normals and anomalies),
we propose angle- and norm-oriented contrastive losses to maximize the angle
size and norm difference between normal and abnormal features simultaneously.
To avoid the distribution shift from natural images to AD images, our
pretraining is performed on a large-scale AD dataset, RealIAD. To further
alleviate the potential shift between pretraining data and downstream AD
datasets, we learn the pretrained AD representations based on the
class-generalizable representation, residual features. For evaluation, based on
five embedding-based AD methods, we simply replace their original features with
our pretrained representations. Extensive experiments on five AD datasets and
five backbones consistently show the superiority of our pretrained features.
The code is available at https://github.com/xcyao00/ADPretrain.

</details>


### [59] [Cross-domain EEG-based Emotion Recognition with Contrastive Learning](https://arxiv.org/abs/2511.05293)
*Rui Yan,Yibo Li,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: 该研究引入EmotionCLIP模型，通过将EEG情绪识别重构为EEG-文本匹配任务，利用CLIP框架和SST-LegoViT骨干网络，显著提升了EEG情绪识别的跨被试和跨时间泛化能力。


<details>
  <summary>Details</summary>
Motivation: EEG情绪识别在情感计算中至关重要，但面临特征利用不足和跨域泛化能力差的挑战。

Method: 该工作将EEG情绪识别重新定义为EEG-文本匹配任务，并将其整合到CLIP框架中。提出EmotionCLIP模型，其核心是SST-LegoViT骨干网络，该网络利用多尺度卷积和Transformer模块捕获EEG信号的空间、频谱和时间特征。通过多模态对比学习进行训练。

Result: 在SEED和SEED-IV数据集上，EmotionCLIP模型在跨被试准确率上分别达到88.69%和73.50%，在跨时间准确率上分别达到88.46%和77.54%，均优于现有模型。

Conclusion: 研究结果表明，多模态对比学习对于实现鲁棒的EEG情绪识别是有效的。

Abstract: Electroencephalogram (EEG)-based emotion recognition is vital for affective
computing but faces challenges in feature utilization and cross-domain
generalization. This work introduces EmotionCLIP, which reformulates
recognition as an EEG-text matching task within the CLIP framework. A tailored
backbone, SST-LegoViT, captures spatial, spectral, and temporal features using
multi-scale convolution and Transformer modules. Experiments on SEED and
SEED-IV datasets show superior cross-subject accuracies of 88.69% and 73.50%,
and cross-time accuracies of 88.46% and 77.54%, outperforming existing models.
Results demonstrate the effectiveness of multimodal contrastive learning for
robust EEG emotion recognition.

</details>


### [60] [TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning](https://arxiv.org/abs/2511.05489)
*Junwen Pan,Qizhe Zhang,Rui Zhang,Ming Lu,Xin Wan,Yuan Zhang,Chang Liu,Qi She*

Main category: cs.CV

TL;DR: 本文提出TimeSearch-R，通过强化学习将时间搜索重构为交错的文本-视频思考，并引入GRPO-CSV机制以提高搜索决策的完整性和视频推理的一致性，从而在长视频理解任务上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有时间搜索方法依赖手工搜索过程，缺乏端到端优化以学习最佳搜索策略，导致视频内容探索不足和逻辑推理不一致，影响长视频理解的准确性。

Method: 本文提出TimeSearch-R，将时间搜索重新定义为交错的文本-视频思考，并通过强化学习（RL）将视频片段搜索无缝整合到推理过程中。为解决RL训练中中间搜索决策的无监督问题，引入了带有完整性自验证（GRPO-CSV）的GRPO，该方法通过策略模型验证已搜索帧的充分性，提高推理完整性。此外，构建了专门用于SFT冷启动和RL训练的数据集，过滤掉弱时间依赖样本以增强任务难度。

Result: TimeSearch-R在Haystack-LVBench和Haystack-Ego4D等时间搜索基准以及VideoMME和MLVU等长视频理解基准上均实现了显著改进。在LongVideoBench上，TimeSearch-R建立了新的最先进水平，相较于基线模型Qwen2.5-VL提升4.1%，相较于先进视频推理模型Video-R1提升2.0%。

Conclusion: TimeSearch-R通过将时间搜索重构为强化学习驱动的文本-视频交错思考，并结合GRPO-CSV的完整性自验证机制，有效解决了现有方法的局限性，显著提升了长视频理解和时间搜索的性能，达到了新的SOTA水平。

Abstract: Temporal search aims to identify a minimal set of relevant frames from tens
of thousands based on a given query, serving as a foundation for accurate
long-form video understanding. Existing works attempt to progressively narrow
the search space. However, these approaches typically rely on a hand-crafted
search process, lacking end-to-end optimization for learning optimal search
strategies. In this paper, we propose TimeSearch-R, which reformulates temporal
search as interleaved text-video thinking, seamlessly integrating searching
video clips into the reasoning process through reinforcement learning (RL).
However, applying RL training methods, such as Group Relative Policy
Optimization (GRPO), to video reasoning can result in unsupervised intermediate
search decisions. This leads to insufficient exploration of the video content
and inconsistent logical reasoning. To address these issues, we introduce GRPO
with Completeness Self-Verification (GRPO-CSV), which gathers searched video
frames from the interleaved reasoning process and utilizes the same policy
model to verify the adequacy of searched frames, thereby improving the
completeness of video reasoning. Additionally, we construct datasets
specifically designed for the SFT cold-start and RL training of GRPO-CSV,
filtering out samples with weak temporal dependencies to enhance task
difficulty and improve temporal search capabilities. Extensive experiments
demonstrate that TimeSearch-R achieves significant improvements on temporal
search benchmarks such as Haystack-LVBench and Haystack-Ego4D, as well as
long-form video understanding benchmarks like VideoMME and MLVU. Notably,
TimeSearch-R establishes a new state-of-the-art on LongVideoBench with 4.1%
improvement over the base model Qwen2.5-VL and 2.0% over the advanced video
reasoning model Video-R1. Our code is available at
https://github.com/Time-Search/TimeSearch-R.

</details>


### [61] [$\mathbf{S^2LM}$: Towards Semantic Steganography via Large Language Models](https://arxiv.org/abs/2511.05319)
*Huanqi Wu,Huangbiao Xu,Runfeng Xie,Jiaxin Cai,Kaixin Zhang,Xiao Ke*

Main category: cs.CV

TL;DR: 本文提出了一种名为“语句到图像隐写术”的新任务，利用大型语言模型（LLMs）将语义丰富的句子级信息嵌入到图像中，并引入了S^2LM模型和IVT基准。


<details>
  <summary>Details</summary>
Motivation: 尽管隐写术取得了进展，但仍难以将语义丰富的句子级信息嵌入载体。在AIGC时代，隐写术的容量变得前所未有的重要，促使研究人员探索更高容量的语义隐写方法。

Method: 本文提出了“语句到图像隐写术”（一种语义隐写术），并建立了名为“Invisible Text (IVT)”的基准，用于评估句子级秘密消息。核心方法是S^2LM（Semantic Steganographic Language Model），该模型利用大型语言模型（LLMs）通过全新设计的流水线将高层文本信息（如句子或段落）嵌入图像，LLM贯穿整个过程。

Result: 定量和定性实验均表明，S^2LM方法有效地为LLMs解锁了新的语义隐写能力，能够成功地将语义丰富的内容集成到图像中。

Conclusion: S^2LM模型通过利用LLMs，解决了传统隐写术在嵌入语义丰富、句子级信息方面的不足，开辟了将高层文本信息隐藏在图像中的新途径，极大地提升了隐写术的语义容量。

Abstract: Although steganography has made significant advancements in recent years, it
still struggles to embed semantically rich, sentence-level information into
carriers. However, in the era of AIGC, the capacity of steganography is more
critical than ever. In this work, we present Sentence-to-Image Steganography,
an instance of Semantic Steganography, a novel task that enables the hiding of
arbitrary sentence-level messages within a cover image. Furthermore, we
establish a benchmark named Invisible Text (IVT), comprising a diverse set of
sentence-level texts as secret messages for evaluation. Finally, we present
$\mathbf{S^2LM}$: Semantic Steganographic Language Model, which utilizes large
language models (LLMs) to embed high-level textual information, such as
sentences or even paragraphs, into images. Unlike traditional bit-level
counterparts, $\mathrm{S^2LM}$ enables the integration of semantically rich
content through a newly designed pipeline in which the LLM is involved
throughout the entire process. Both quantitative and qualitative experiments
demonstrate that our method effectively unlocks new semantic steganographic
capabilities for LLMs. The source code will be released soon.

</details>


### [62] [Dense Motion Captioning](https://arxiv.org/abs/2511.05369)
*Shiyao Xu,Benedetta Liberatori,Gül Varol,Paolo Rota*

Main category: cs.CV

TL;DR: 该论文提出了“密集运动描述”的新任务，旨在对3D人体运动序列中的动作进行时序定位和描述。为此，作者创建了首个大规模复杂运动数据集CompMo，并开发了结合大型语言模型和运动适配器的DEMO模型，在多项基准测试中表现出色，为3D运动理解和描述奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 当前3D人体运动与语言结合的研究主要集中在文本到运动生成，而运动理解任务相对未被充分探索。现有数据集缺乏详细的时间注释，且多为动作较少的短序列，无法支持复杂的运动理解任务。

Method: 引入了“密集运动描述”的新任务，旨在对3D人体运动序列中的动作进行时序定位和描述。构建了CompMo数据集，包含60,000个具有精确时间边界和多动作（2到10个）注释的复杂运动序列。开发了DEMO模型，该模型将大型语言模型与一个简单的运动适配器集成，用于生成密集的、时间定位的描述。

Result: CompMo是第一个具有丰富注释、复杂运动序列和精确时间边界的大规模数据集。实验表明，DEMO模型在CompMo以及其他改编的基准测试中，显著优于现有方法。

Conclusion: 该研究为3D运动理解和描述任务建立了强大的基线，并通过引入新任务、新数据集和高性能模型，推动了该领域未来研究的发展。

Abstract: Recent advances in 3D human motion and language integration have primarily
focused on text-to-motion generation, leaving the task of motion understanding
relatively unexplored. We introduce Dense Motion Captioning, a novel task that
aims to temporally localize and caption actions within 3D human motion
sequences. Current datasets fall short in providing detailed temporal
annotations and predominantly consist of short sequences featuring few actions.
To overcome these limitations, we present the Complex Motion Dataset (CompMo),
the first large-scale dataset featuring richly annotated, complex motion
sequences with precise temporal boundaries. Built through a carefully designed
data generation pipeline, CompMo includes 60,000 motion sequences, each
composed of multiple actions ranging from at least two to ten, accurately
annotated with their temporal extents. We further present DEMO, a model that
integrates a large language model with a simple motion adapter, trained to
generate dense, temporally grounded captions. Our experiments show that DEMO
substantially outperforms existing methods on CompMo as well as on adapted
benchmarks, establishing a robust baseline for future research in 3D motion
understanding and captioning.

</details>


### [63] [Canonical Space Representation for 4D Panoptic Segmentation of Articulated Objects](https://arxiv.org/abs/2511.05356)
*Manuel Gomes,Bogdan Raducanu,Miguel Oliveira*

Main category: cs.CV

TL;DR: 本文引入了Artic4D数据集，并提出了CanonSeg4D框架，用于解决4D铰接物体全景分割中忽略时间动态和缺乏基准数据集的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在铰接物体感知中忽视时间动态，且4D时间数据在全景分割中未被充分探索。此外，该领域缺乏一个基准数据集。

Method: 引入了Artic4D数据集，该数据集基于PartNet Mobility并增加了合成传感器数据，包含4D全景标注和关节参数。提出了CanonSeg4D框架，该框架显式估计每帧偏移，将观察到的物体部件映射到学习到的规范空间，并利用此规范表示实现跨序列帧的物体部件一致对齐。

Result: 在Artic4D数据集上的综合实验表明，所提出的CanonSeg4D在更复杂场景中的全景分割精度优于现有最先进的方法。

Conclusion: 这些发现强调了时间建模和规范对齐在动态物体理解中的有效性，并为4D铰接物体感知领域的未来发展铺平了道路。

Abstract: Articulated object perception presents significant challenges in computer
vision, particularly because most existing methods ignore temporal dynamics
despite the inherently dynamic nature of such objects. The use of 4D temporal
data has not been thoroughly explored in articulated object perception and
remains unexamined for panoptic segmentation. The lack of a benchmark dataset
further hurt this field. To this end, we introduce Artic4D as a new dataset
derived from PartNet Mobility and augmented with synthetic sensor data,
featuring 4D panoptic annotations and articulation parameters. Building on this
dataset, we propose CanonSeg4D, a novel 4D panoptic segmentation framework.
This approach explicitly estimates per-frame offsets mapping observed object
parts to a learned canonical space, thereby enhancing part-level segmentation.
The framework employs this canonical representation to achieve consistent
alignment of object parts across sequential frames. Comprehensive experiments
on Artic4D demonstrate that the proposed CanonSeg4D outperforms state of the
art approaches in panoptic segmentation accuracy in more complex scenarios.
These findings highlight the effectiveness of temporal modeling and canonical
alignment in dynamic object understanding, and pave the way for future advances
in 4D articulated object perception.

</details>


### [64] [Sharing the Learned Knowledge-base to Estimate Convolutional Filter Parameters for Continual Image Restoration](https://arxiv.org/abs/2511.05421)
*Aupendu Kar,Krishnendu Ghosh,Prabir Kumar Biswas*

Main category: cs.CV

TL;DR: 本文提出了一种针对图像修复的持续学习方法，通过简单修改卷积层，无需改变主干网络即可适应新任务，有效避免了遗忘，提高了新任务性能，且计算开销小。


<details>
  <summary>Details</summary>
Motivation: 持续学习在深度学习领域备受关注，但在图像修复方面的研究较少。图像修复面临独特的挑战，如处理大尺寸图像和多样的降级类型。现有方法常需要对网络架构进行大量修改以适应新任务，导致巨大的计算开销；而基于正则化的方法不适用于需要不同特征处理的修复任务。

Method: 本文提出对卷积层进行简单修改，使其能够从先前的修复任务中学习知识，而无需触及主干网络架构。这种方法可以无缝集成到任何深度架构中，无需结构性改动。与现有方法不同，它在增加可训练参数的同时，并未显著增加计算开销或推理时间。

Result: 实验验证表明，模型能够在引入新修复任务的同时，不损害现有任务的性能。通过适应从先前修复任务知识库中获得的知识，模型在新修复任务上的性能得到了提升。该方法在增加参数的同时，保持了较低的计算开销和推理时间。

Conclusion: 通过对卷积层的简单修改，本文成功实现了图像修复领域的持续学习。该方法避免了对主干架构的重度修改和高计算开销，同时有效防止了遗忘，并通过知识适应提升了新任务的性能，为图像修复的持续学习提供了一种高效且普适的解决方案。

Abstract: Continual learning is an emerging topic in the field of deep learning, where
a model is expected to learn continuously for new upcoming tasks without
forgetting previous experiences. This field has witnessed numerous
advancements, but few works have been attempted in the direction of image
restoration. Handling large image sizes and the divergent nature of various
degradation poses a unique challenge in the restoration domain. However,
existing works require heavily engineered architectural modifications for new
task adaptation, resulting in significant computational overhead.
Regularization-based methods are unsuitable for restoration, as different
restoration challenges require different kinds of feature processing. In this
direction, we propose a simple modification of the convolution layer to adapt
the knowledge from previous restoration tasks without touching the main
backbone architecture. Therefore, it can be seamlessly applied to any deep
architecture without any structural modifications. Unlike other approaches, we
demonstrate that our model can increase the number of trainable parameters
without significantly increasing computational overhead or inference time.
Experimental validation demonstrates that new restoration tasks can be
introduced without compromising the performance of existing tasks. We also show
that performance on new restoration tasks improves by adapting the knowledge
from the knowledge base created by previous restoration tasks. The code is
available at https://github.com/aupendu/continual-restore.

</details>


### [65] [Shared Latent Representation for Joint Text-to-Audio-Visual Synthesis](https://arxiv.org/abs/2511.05432)
*Dogucan Yaman,Seymanur Akti,Fevziye Irem Eyiokur,Alexander Waibel*

Main category: cs.CV

TL;DR: 本文提出一个基于HierSpeech++潜在语音表示的文本到说话人脸合成框架，通过两阶段训练处理特征分布偏移，实现了无需真实音频的自然、富有表现力的语音和同步面部动作。


<details>
  <summary>Details</summary>
Motivation: 旨在从文本生成自然的说话人脸，实现紧密的音视频对齐、保持说话人身份，并生成富有表现力的语音和同步面部动作，同时解决干净特征和TTS预测特征之间的分布偏移问题。

Method: 该框架利用HierSpeech++的潜在语音表示。一个Text-to-Vec模块从文本生成Wav2Vec2嵌入，共同条件化语音和人脸生成。为处理干净特征与TTS预测特征之间的分布偏移，采用两阶段训练：首先在Wav2Vec2嵌入上预训练，然后在TTS输出上微调。

Result: 该方法在推理时无需真实音频，实现了紧密的音视频对齐，保留了说话人身份，并生成了自然、富有表现力的语音和同步的面部动作。实验表明，条件化于TTS预测的潜在特征优于级联管线，提升了唇语同步和视觉真实感。

Conclusion: 所提出的框架通过利用潜在语音表示和两阶段训练策略，能够有效地从文本合成自然的说话人脸，并在唇语同步和视觉真实感方面优于传统级联方法。

Abstract: We propose a text-to-talking-face synthesis framework leveraging latent
speech representations from HierSpeech++. A Text-to-Vec module generates
Wav2Vec2 embeddings from text, which jointly condition speech and face
generation. To handle distribution shifts between clean and TTS-predicted
features, we adopt a two-stage training: pretraining on Wav2Vec2 embeddings and
finetuning on TTS outputs. This enables tight audio-visual alignment, preserves
speaker identity, and produces natural, expressive speech and synchronized
facial motion without ground-truth audio at inference. Experiments show that
conditioning on TTS-predicted latent features outperforms cascaded pipelines,
improving both lip-sync and visual realism.

</details>


### [66] [How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?](https://arxiv.org/abs/2511.05449)
*Tuan Anh Tran,Duy M. H. Nguyen,Hoai-Chau Tran,Michael Barz,Khoa D. Doan,Roger Wattenhofer,Ngo Anh Vien,Mathias Niepert,Daniel Sonntag,Paul Swoboda*

Main category: cs.CV

TL;DR: 本文发现3D点云Transformer模型中的tokens存在高度冗余，导致计算和内存成本高昂。作者提出了gitmerge3D方法，通过全局图token合并将token数量减少90-95%，同时保持竞争力，显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 3D点云Transformer模型在语义分割和重建等任务中取得了最先进的成果，但其通常依赖密集的token表示，导致训练和推理期间计算和内存成本高昂。

Method: 作者提出了gitmerge3D，一种全局感知图token合并方法。该方法旨在识别并减少冗余token的数量，以提高效率。

Result: 研究发现tokens存在显著冗余。gitmerge3D能够将token数量减少高达90-95%，同时保持有竞争力的性能。这挑战了“更多tokens意味着更好性能”的普遍假设，并表明许多现有模型存在过度token化和可扩展性优化不足的问题。该方法在多个3D视觉任务中都显示出计算效率的持续提升。

Conclusion: 这项工作首次评估了大规模3D Transformer模型中的冗余性，为开发更高效的3D基础架构提供了见解。研究强调了在不牺牲性能的情况下通过token合并大幅提高效率的可能性。

Abstract: Recent advances in 3D point cloud transformers have led to state-of-the-art
results in tasks such as semantic segmentation and reconstruction. However,
these models typically rely on dense token representations, incurring high
computational and memory costs during training and inference. In this work, we
present the finding that tokens are remarkably redundant, leading to
substantial inefficiency. We introduce gitmerge3D, a globally informed graph
token merging method that can reduce the token count by up to 90-95% while
maintaining competitive performance. This finding challenges the prevailing
assumption that more tokens inherently yield better performance and highlights
that many current models are over-tokenized and under-optimized for
scalability. We validate our method across multiple 3D vision tasks and show
consistent improvements in computational efficiency. This work is the first to
assess redundancy in large-scale 3D transformer models, providing insights into
the development of more efficient 3D foundation architectures. Our code and
checkpoints are publicly available at https://gitmerge3d.github.io

</details>


### [67] [The Potential of Copernicus Satellites for Disaster Response: Retrieving Building Damage from Sentinel-1 and Sentinel-2](https://arxiv.org/abs/2511.05461)
*Olivier Dietrich,Merlin Alfredsson,Emilia Arens,Nando Metzger,Torben Peters,Linus Scheibenreif,Jan Dirk Wegner,Konrad Schindler*

Main category: cs.CV

TL;DR: 该研究调查了中分辨率哥白尼地球观测图像（Sentinel-1和Sentinel-2）在建筑损害评估中的应用潜力，并推出了xBD-S12数据集。结果表明，尽管分辨率适中，但这些图像仍能有效进行灾害评估，且复杂模型架构和地理空间基础模型在此任务中优势不明显，证明了哥白尼图像作为快速、广域评估数据源的实用性。


<details>
  <summary>Details</summary>
Motivation: 自然灾害发生后，需要快速进行损害评估以指导人道主义响应。然而，超高分辨率（VHR）图像通常可用性有限。因此，研究旨在探索中分辨率地球观测图像（如哥白尼计划）是否能有效支持建筑损害评估，以补充VHR图像。

Method: 研究引入了xBD-S12数据集，其中包含10,315对来自Sentinel-1和Sentinel-2的灾前灾后图像，这些图像与已建立的xBD基准在空间和时间上对齐。通过一系列实验，研究人员评估了使用这些中分辨率图像进行建筑损害检测和映射的有效性。此外，他们还比较了不同模型架构（包括复杂模型和地理空间基础模型）在此任务中的性能和泛化能力。

Result: 实验结果表明，尽管地面采样距离为10米，但建筑损害在许多灾害场景中仍能被很好地检测和映射。研究还发现，在此分辨率下的损害映射任务中，模型架构的复杂性并未带来显著优势：更复杂的模型架构在泛化到未见过的灾害时往往表现不佳，而地理空间基础模型带来的实际效益也很小。

Conclusion: 研究结果表明，哥白尼图像是进行快速、广域损害评估的可行数据源，可以在VHR图像之外发挥重要作用。为了支持进一步研究，xBD-S12数据集、代码和训练模型已公开发布。

Abstract: Natural disasters demand rapid damage assessment to guide humanitarian
response. Here, we investigate whether medium-resolution Earth observation
images from the Copernicus program can support building damage assessment,
complementing very-high resolution imagery with often limited availability. We
introduce xBD-S12, a dataset of 10,315 pre- and post-disaster image pairs from
both Sentinel-1 and Sentinel-2, spatially and temporally aligned with the
established xBD benchmark. In a series of experiments, we demonstrate that
building damage can be detected and mapped rather well in many disaster
scenarios, despite the moderate 10$\,$m ground sampling distance. We also find
that, for damage mapping at that resolution, architectural sophistication does
not seem to bring much advantage: more complex model architectures tend to
struggle with generalization to unseen disasters, and geospatial foundation
models bring little practical benefit. Our results suggest that Copernicus
images are a viable data source for rapid, wide-area damage assessment and
could play an important role alongside VHR imagery. We release the xBD-S12
dataset, code, and trained models to support further research.

</details>


### [68] [PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Visual Quality Assessment via Preference-Response Disentangled Policy Optimization](https://arxiv.org/abs/2511.05393)
*Zehui Feng,Tian Qiu,Tong Wu,Junxuan Li,Huayuan Xu,Ting Han*

Main category: cs.CV

TL;DR: PreResQ-R1是一个新颖的偏好-响应解耦强化学习框架，它统一了绝对分数回归和相对排序一致性，用于图像和视频质量评估（IQA/VQA）。该框架通过双分支奖励和GRPO优化，实现了更深层次、可解释的感知质量推理，并在多项基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在视觉质量评估（QA）中存在浅层推理、分数校准差和跨领域泛化能力有限的问题，这主要是由于它们主要依赖监督微调或仅排序目标。

Method: 本文提出了PreResQ-R1框架，一个偏好-响应解耦强化学习框架。它在一个推理驱动的优化方案中统一了绝对分数回归和相对排序一致性。该方法引入了一个双分支奖励公式，分别建模样本内响应一致性和样本间偏好对齐，并通过组相对策略优化（GRPO）进行优化。对于视频质量评估，还设计了全局-时间与局部-空间数据流策略。

Result: 通过仅对6K图像和28K视频进行强化微调，PreResQ-R1在10个IQA和5个VQA基准测试中，SRCC和PLCC指标均达到了最先进的结果，在IQA任务中分别超越了5.30%和2.15%。除了量化收益，它还生成了与人类判断一致的推理轨迹，揭示了感知质量判断背后的线索。

Conclusion: PreResQ-R1通过其独特的偏好-响应解耦强化学习框架，成功解决了现有QA方法在推理深度、分数校准和泛化能力上的局限性。它在多个IQA和VQA基准测试中取得了显著的性能提升，并能生成可解释的、与人类感知一致的推理过程，为视觉质量评估领域带来了新的突破。

Abstract: Visual Quality Assessment (QA) seeks to predict human perceptual judgments of
visual fidelity. While recent multimodal large language models (MLLMs) show
promise in reasoning about image and video quality, existing approaches mainly
rely on supervised fine-tuning or rank-only objectives, resulting in shallow
reasoning, poor score calibration, and limited cross-domain generalization. We
propose PreResQ-R1, a Preference-Response Disentangled Reinforcement Learning
framework that unifies absolute score regression and relative ranking
consistency within a single reasoning-driven optimization scheme. Unlike prior
QA methods, PreResQ-R1 introduces a dual-branch reward formulation that
separately models intra-sample response coherence and inter-sample preference
alignment, optimized via Group Relative Policy Optimization (GRPO). This design
encourages fine-grained, stable, and interpretable chain-of-thought reasoning
about perceptual quality. To extend beyond static imagery, we further design a
global-temporal and local-spatial data flow strategy for Video Quality
Assessment. Remarkably, with reinforcement fine-tuning on only 6K images and
28K videos, PreResQ-R1 achieves state-of-the-art results across 10 IQA and 5
VQA benchmarks under both SRCC and PLCC metrics, surpassing by margins of 5.30%
and textbf2.15% in IQA task, respectively. Beyond quantitative gains, it
produces human-aligned reasoning traces that reveal the perceptual cues
underlying quality judgments. Code and model are available.

</details>


### [69] [PALM: A Dataset and Baseline for Learning Multi-subject Hand Prior](https://arxiv.org/abs/2511.05403)
*Zicong Fan,Edoardo Remelli,David Dimond,Fadime Sener,Liuhao Ge,Bugra Tekin,Cem Keskin,Shreyas Hampali*

Main category: cs.CV

TL;DR: 本文介绍了PALM，一个大规模高质量手部数据集，包含1.3万手部扫描和9万多视图图像，并提出了PALM-Net基线模型，通过基于物理的逆渲染实现单图像手部头像个性化。


<details>
  <summary>Details</summary>
Motivation: 从图像创建高质量个性化手部化身具有挑战性，原因包括复杂几何、外观、关节运动以及非受限光照和有限视角。此外，缺乏联合提供准确3D几何、高分辨率多视图图像和多样化人群的可用数据集。

Method: 研究团队构建了PALM数据集，包含来自263名受试者的1.3万个高质量手部扫描和9万张多视图图像，涵盖了肤色、年龄和几何形状的丰富多样性。在此基础上，他们提出了一个基线模型PALM-Net，该模型通过基于物理的逆渲染学习了手部几何和材料属性的多主体先验知识。

Result: PALM数据集成功地捕捉了手部在肤色、年龄和几何上的丰富变化，成为一个大规模、多样化的真实世界资源。PALM-Net基线模型展示了其效用，能够实现逼真、可重新打光的单图像手部化身个性化。

Conclusion: PALM数据集的规模和多样性使其成为手部建模及相关研究的宝贵资源。PALM-Net证明了该数据集在实现单图像手部化身个性化方面的实用性。

Abstract: The ability to grasp objects, signal with gestures, and share emotion through
touch all stem from the unique capabilities of human hands. Yet creating
high-quality personalized hand avatars from images remains challenging due to
complex geometry, appearance, and articulation, particularly under
unconstrained lighting and limited views. Progress has also been limited by the
lack of datasets that jointly provide accurate 3D geometry, high-resolution
multiview imagery, and a diverse population of subjects. To address this, we
present PALM, a large-scale dataset comprising 13k high-quality hand scans from
263 subjects and 90k multi-view images, capturing rich variation in skin tone,
age, and geometry. To show its utility, we present a baseline PALM-Net, a
multi-subject prior over hand geometry and material properties learned via
physically based inverse rendering, enabling realistic, relightable
single-image hand avatar personalization. PALM's scale and diversity make it a
valuable real-world resource for hand modeling and related research.

</details>


### [70] [Photo Dating by Facial Age Aggregation](https://arxiv.org/abs/2511.05464)
*Jakub Paplham,Vojtech Franc*

Main category: cs.CV

TL;DR: 本文提出一种利用图像中人脸信息估计照片拍摄年份的新方法，并发布了包含160万标注人脸的CSFD-1.6M数据集。该方法通过概率框架结合人脸识别、年龄估计模型及职业时间先验，实验证明多个人脸信息聚合能显著提升照片年代估计性能，优于基于场景的基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有照片年代估计方法可能未能有效利用人脸信息，尤其是在处理包含多个人脸的图像时。研究旨在开发一种更准确的、基于人脸的年代估计方法，并为此提供专门的数据集。

Method: 研究引入了CSFD-1.6M数据集，包含160多万个带身份和出生年份标注的人脸（主要来自电影剧照），并支持单张图像中多个人脸的标注。提出了一种概率框架，该框架形式化地结合了现代人脸识别和年龄估计模型提供的视觉证据，以及基于职业的时间先验信息，以推断照片的拍摄年份。

Result: 实验表明，聚合来自多个人脸的证据能够持续提高照片年代估计的性能。该方法显著优于强大的、基于场景的基线方法，尤其是在包含多个可识别个体的图像中表现更为突出。

Conclusion: 通过利用图像中人脸信息，特别是聚合多个人脸的证据，可以有效且显著地提高照片年代估计的准确性。新提出的概率框架和发布的CSFD-1.6M数据集为该领域的研究提供了新的工具和方向。

Abstract: We introduce a novel method for Photo Dating which estimates the year a
photograph was taken by leveraging information from the faces of people present
in the image. To facilitate this research, we publicly release CSFD-1.6M, a new
dataset containing over 1.6 million annotated faces, primarily from movie
stills, with identity and birth year annotations. Uniquely, our dataset
provides annotations for multiple individuals within a single image, enabling
the study of multi-face information aggregation. We propose a probabilistic
framework that formally combines visual evidence from modern face recognition
and age estimation models, and career-based temporal priors to infer the photo
capture year. Our experiments demonstrate that aggregating evidence from
multiple faces consistently improves the performance and the approach
significantly outperforms strong, scene-based baselines, particularly for
images containing several identifiable individuals.

</details>


### [71] [Visual Spatial Tuning](https://arxiv.org/abs/2511.05491)
*Rui Yang,Ziyu Zhu,Yanwei Li,Jingjia Huang,Shen Yan,Siyuan Zhou,Zhe Liu,Xiangtai Li,Shuangye Li,Wenqian Wang,Yi Lin,Hengshuang Zhao*

Main category: cs.CV

TL;DR: 本文提出VST框架，通过构建大规模空间感知数据集VST-P和空间推理数据集VST-R，并采用监督微调结合强化学习的渐进式训练方法，显著提升了视觉语言模型（VLM）的空间能力，且不损害其通用性，在多个空间基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过添加额外的专家编码器来增强视觉语言模型（VLM）的空间感知能力，但这会带来额外开销并通常损害模型的通用能力。研究动机在于在通用架构中提升VLM的空间能力，使其具备类人视觉空间智能。

Method: 本文提出了视觉空间调优（Visual Spatial Tuning, VST）框架。首先，构建了大规模空间感知数据集VST-P，包含410万个样本，涵盖单视图、多图像和视频的19种技能。其次，创建了用于空间推理的精选数据集VST-R，包含13.5万个样本。训练方法采用渐进式流水线：先进行监督微调以建立基础空间知识，然后通过强化学习进一步提升空间推理能力。

Result: 所提出的VST方法在不损害模型通用能力的前提下，在多个空间基准测试中持续取得了最先进的结果，包括在MMSI-Bench上达到34.8%，在VSIBench上达到61.2%。实验表明，该空间调优范式能够显著增强视觉-语言-动作模型（VLA）。

Conclusion: VST范式能够显著提升视觉-语言-动作模型的空间能力，且没有负面影响，为实现更具物理基础的人工智能铺平了道路。

Abstract: Capturing spatial relationships from visual inputs is a cornerstone of
human-like general intelligence. Several previous studies have tried to enhance
the spatial awareness of Vision-Language Models (VLMs) by adding extra expert
encoders, which brings extra overhead and usually harms general capabilities.
To enhance the spatial ability in general architectures, we introduce Visual
Spatial Tuning (VST), a comprehensive framework to cultivate VLMs with
human-like visuospatial abilities, from spatial perception to reasoning. We
first attempt to enhance spatial perception in VLMs by constructing a
large-scale dataset termed VST-P, which comprises 4.1 million samples spanning
19 skills across single views, multiple images, and videos. Then, we present
VST-R, a curated dataset with 135K samples that instruct models to reason in
space. In particular, we adopt a progressive training pipeline: supervised
fine-tuning to build foundational spatial knowledge, followed by reinforcement
learning to further improve spatial reasoning abilities. Without the
side-effect to general capabilities, the proposed VST consistently achieves
state-of-the-art results on several spatial benchmarks, including $34.8\%$ on
MMSI-Bench and $61.2\%$ on VSIBench. It turns out that the
Vision-Language-Action models can be significantly enhanced with the proposed
spatial tuning paradigm, paving the way for more physically grounded AI.

</details>


### [72] [GroupKAN: Rethinking Nonlinearity with Grouped Spline-based KAN Modeling for Efficient Medical Image Segmentation](https://arxiv.org/abs/2511.05477)
*Guojie Li,Anwar P. P. Abdul Majeed,Muhammad Ateeq,Anh Nguyen,Fan Zhang*

Main category: cs.CV

TL;DR: GroupKAN是一种轻量级、可解释的医学图像分割网络，通过引入分组的KAN变换和激活模块，解决了U-KAN模型的计算复杂度问题，同时在性能和参数效率上超越了U-KAN。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割模型需要准确、轻量且可解释。现有模型存在局限：卷积网络缺乏自适应非线性和透明决策；Transformer模型存在二次复杂度问题和不透明的注意力机制。U-KAN虽然在准确性和可解释性方面表现良好，但其全通道变换导致的O(C^2)复杂度限制了其可扩展性。

Method: 本文提出了GroupKAN，一个轻量级分割网络，包含两个新颖的结构化功能模块：(1) 分组KAN变换（Grouped KAN Transform），将通道分成G组进行多元样条映射，将复杂度从O(C^2)降低到O(C^2/G)；(2) 分组KAN激活（Grouped KAN Activation），在每个通道组内应用共享的基于样条的映射，实现高效的逐令牌非线性。

Result: 在BUSI、GlaS和CVC三个医学基准测试中，GroupKAN平均IoU达到79.80%，比U-KAN高出+1.11%。同时，GroupKAN所需的参数量仅为U-KAN的47.6%（3.02M vs 6.35M），并且展现出更高的可解释性。

Conclusion: GroupKAN通过引入分组机制，成功克服了U-KAN的计算复杂度和可扩展性限制，在保持和提高分割精度的同时，显著降低了模型参数量，并增强了可解释性，是医学图像分割领域的一个有效且高效的解决方案。

Abstract: Medical image segmentation requires models that are accurate, lightweight,
and interpretable. Convolutional architectures lack adaptive nonlinearity and
transparent decision-making, whereas Transformer architectures are hindered by
quadratic complexity and opaque attention mechanisms. U-KAN addresses these
challenges using Kolmogorov-Arnold Networks, achieving higher accuracy than
both convolutional and attention-based methods, fewer parameters than
Transformer variants, and improved interpretability compared to conventional
approaches. However, its O(C^2) complexity due to full-channel transformations
limits its scalability as the number of channels increases. To overcome this,
we introduce GroupKAN, a lightweight segmentation network that incorporates two
novel, structured functional modules: (1) Grouped KAN Transform, which
partitions channels into G groups for multivariate spline mappings, reducing
complexity to O(C^2/G), and (2) Grouped KAN Activation, which applies shared
spline-based mappings within each channel group for efficient, token-wise
nonlinearity. Evaluated on three medical benchmarks (BUSI, GlaS, and CVC),
GroupKAN achieves an average IoU of 79.80 percent, surpassing U-KAN by +1.11
percent while requiring only 47.6 percent of the parameters (3.02M vs 6.35M),
and shows improved interpretability.

</details>


### [73] [What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable IMUs](https://arxiv.org/abs/2511.05292)
*Jiaxi Yin,Pengcheng Wang,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: 本文提出了CuisineSense系统，通过整合智能手表的手部运动和智能眼镜的头部动态，实现了对多种中餐食物类型的分类，解决了传统方法和现有可穿戴设备在饮食监测中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的自我报告饮食监测方法存在回忆偏差，基于摄像头的方法引发隐私担忧，而现有可穿戴设备主要关注有限的食物类型（如汉堡和披萨），无法满足种类繁多的中餐监测需求。因此，研究旨在弥补这一空白，提供一种准确、无侵入性的可穿戴饮食监测方案。

Method: CuisineSense系统结合智能手表（手部运动）和智能眼镜（头部动态）的数据进行食物类型分类。它采用两阶段检测流程：第一阶段通过区分进食和非进食行为的特征时间模式来识别进食状态；第二阶段则根据进食期间捕获的运动进行精细的食物类型识别。为评估系统，研究构建了一个包含11种食物类别、10名参与者、共计27.5小时IMU记录的数据集。

Result: 实验结果表明，CuisineSense系统在进食状态检测和食物分类方面均取得了高准确率。

Conclusion: CuisineSense系统为无侵入式、基于可穿戴设备的饮食监测提供了一个实用的解决方案，特别适用于中餐等多样化饮食的监测。

Abstract: Accurate food intake detection is vital for dietary monitoring and chronic
disease prevention. Traditional self-report methods are prone to recall bias,
while camera-based approaches raise concerns about privacy. Furthermore,
existing wearable-based methods primarily focus on a limited number of food
types, such as hamburgers and pizza, failing to address the vast diversity of
Chinese cuisine. To bridge this gap, we propose CuisineSense, a system that
classifies Chinese food types by integrating hand motion cues from a smartwatch
with head dynamics from smart glasses. To filter out irrelevant daily
activities, we design a two-stage detection pipeline. The first stage
identifies eating states by distinguishing characteristic temporal patterns
from non-eating behaviors. The second stage then conducts fine-grained food
type recognition based on the motions captured during food intake. To evaluate
CuisineSense, we construct a dataset comprising 27.5 hours of IMU recordings
across 11 food categories and 10 participants. Experiments demonstrate that
CuisineSense achieves high accuracy in both eating state detection and food
classification, offering a practical solution for unobtrusive, wearable-based
dietary monitoring.The system code is publicly available at
https://github.com/joeeeeyin/CuisineSense.git.

</details>


### [74] [Semantic-Guided Natural Language and Visual Fusion for Cross-Modal Interaction Based on Tiny Object Detection](https://arxiv.org/abs/2511.05474)
*Xian-Hong Huang,Hui-Kai Su,Chi-Chia Sun,Jun-Wei Hsieh*

Main category: cs.CV

TL;DR: 该论文提出了一种结合语义引导的自然语言处理（BERT）和先进视觉骨干网络（PRB-FPN-Net，包含ELAN、MSP、CSP等架构）的跨模态交互方法，用于微小目标检测。该方法通过对齐文本语义线索与视觉特征，显著提升了小而复杂目标的检测精度，并在COCO和Objects365数据集上表现优异，超越YOLO-World且参数量远低于GLIP。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了提高微小和复杂目标的检测精度，通过将文本输入的语义线索与视觉特征对齐，尤其是在资源受限的环境中，以增强目标检测的准确性、效率和适应性。

Method: 所提出的方法将BERT语言模型与基于CNN的并行残差双融合特征金字塔网络（PRB-FPN-Net）相结合。它整合了ELAN、MSP和CSP等创新的骨干架构以优化特征提取和融合。通过词形还原和微调技术，系统将文本输入的语义线索与视觉特征对齐。

Result: 该模型在COCO2017验证集上取得了52.6%的平均精度（AP），显著优于YOLO-World，同时参数消耗仅为GLIP等基于Transformer模型的一半。对ELAN、MSP和CSP等不同骨干网络的测试进一步证实了其高效处理多尺度目标的能力，确保了在资源受限环境中的可扩展性和鲁棒性。

Conclusion: 这项研究强调了将自然语言理解与先进骨干架构相结合的潜力，为目标检测的准确性、效率和对现实世界挑战的适应性树立了新的基准。

Abstract: This paper introduces a cutting-edge approach to cross-modal interaction for
tiny object detection by combining semantic-guided natural language processing
with advanced visual recognition backbones. The proposed method integrates the
BERT language model with the CNN-based Parallel Residual Bi-Fusion Feature
Pyramid Network (PRB-FPN-Net), incorporating innovative backbone architectures
such as ELAN, MSP, and CSP to optimize feature extraction and fusion. By
employing lemmatization and fine-tuning techniques, the system aligns semantic
cues from textual inputs with visual features, enhancing detection precision
for small and complex objects. Experimental validation using the COCO and
Objects365 datasets demonstrates that the model achieves superior performance.
On the COCO2017 validation set, it attains a 52.6% average precision (AP),
outperforming YOLO-World significantly while maintaining half the parameter
consumption of Transformer-based models like GLIP. Several test on different of
backbones such ELAN, MSP, and CSP further enable efficient handling of
multi-scale objects, ensuring scalability and robustness in
resource-constrained environments. This study underscores the potential of
integrating natural language understanding with advanced backbone
architectures, setting new benchmarks in object detection accuracy, efficiency,
and adaptability to real-world challenges.

</details>


### [75] [EventFlow: Real-Time Neuromorphic Event-Driven Classification of Two-Phase Boiling Flow Regimes](https://arxiv.org/abs/2511.05467)
*Sanghyeon Chang,Srikar Arani,Nishant Sai Nuthalapati,Youngjoon Suh,Nicholas Choi,Siavash Khodakarami,Md Rakibul Hasan Roni,Nenad Miljkovic,Aparna Chandramowlishwaran,Yoonjin Won*

Main category: cs.CV

TL;DR: 本研究提出了一种基于脉冲神经形态传感器信号的实时流态分类框架，用于监测流体沸腾，其事件驱动数据和LSTM模型在准确性和速度上均优于传统方法，实现了低延迟、高可靠的实时反馈。


<details>
  <summary>Details</summary>
Motivation: 流体沸腾是高效的传热机制，但流态的突然转变会影响热性能和系统可靠性，因此需要准确、低延迟的实时监测。传统光学成像方法计算需求高且时间分辨率不足，无法捕捉瞬态流体行为。

Method: 研究提出一个基于脉冲神经形态传感器的实时流态分类框架。该传感器通过检测像素亮度变化（对应边缘运动）提供事件驱动信息，无需全帧重建。研究开发了五种分类模型，分别使用传统图像数据和事件驱动数据，并重点采用了基于事件的长短期记忆（LSTM）模型。通过多数投票机制实现异步处理管道，提供连续、低延迟的预测。

Result: 实验证明，利用事件驱动数据的模型优于基于帧的方法，因为它们对动态流体特征更敏感。其中，基于事件的LSTM模型在准确性和速度之间取得了最佳平衡，实现了97.6%的分类准确率和0.28毫秒的处理时间。异步处理管道支持连续、低延迟的预测，并通过多数投票机制提供稳定的输出。

Conclusion: 基于脉冲神经形态传感器和事件驱动数据的实时框架，能够实现对流体沸腾流态的可靠、低延迟分类，为实验控制和智能热管理提供了有效的实时反馈，克服了传统方法的局限性。

Abstract: Flow boiling is an efficient heat transfer mechanism capable of dissipating
high heat loads with minimal temperature variation, making it an ideal thermal
management method. However, sudden shifts between flow regimes can disrupt
thermal performance and system reliability, highlighting the need for accurate
and low-latency real-time monitoring. Conventional optical imaging methods are
limited by high computational demands and insufficient temporal resolution,
making them inadequate for capturing transient flow behavior. To address this,
we propose a real-time framework based on signals from neuromorphic sensors for
flow regime classification. Neuromorphic sensors detect changes in brightness
at individual pixels, which typically correspond to motion at edges, enabling
fast and efficient detection without full-frame reconstruction, providing
event-based information. We develop five classification models using both
traditional image data and event-based data, demonstrating that models
leveraging event data outperform frame-based approaches due to their
sensitivity to dynamic flow features. Among these models, the event-based long
short-term memory model provides the best balance between accuracy and speed,
achieving 97.6% classification accuracy with a processing time of 0.28 ms. Our
asynchronous processing pipeline supports continuous, low-latency predictions
and delivers stable output through a majority voting mechanisms, enabling
reliable real-time feedback for experimental control and intelligent thermal
management.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [76] [Evaluating LLMs' Reasoning Over Ordered Procedural Steps](https://arxiv.org/abs/2511.04688)
*Adrita Anika,Md Messal Monem Miah*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）从打乱的步骤中重建程序序列（食谱）的能力。结果显示，LLMs在处理更长或更混乱的输入时表现不佳，揭示了其在程序推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 程序序列推理对LLMs至关重要，因为步骤顺序直接影响结果。理解LLMs在此类任务中的能力和局限性是推动其发展的关键。

Method: 研究任务是从打乱的食谱步骤中重建全局有序序列。使用自建的食谱数据集，并在零样本和少样本设置下评估了多个LLMs。评估框架采用了排名和序列比对的成熟指标，包括Kendall's Tau、归一化最长公共子序列（NLCS）和归一化编辑距离（NED）。

Result: 模型性能随序列长度增加而下降，且输入步骤位移越大（即打乱程度越严重），性能下降越明显。这表明更长和更无序的程序对LLMs来说更具挑战性。

Conclusion: 当前LLMs在程序推理方面存在局限性，尤其是在处理更长和更混乱的输入时。这些发现为未来改进LLMs在复杂程序推理方面的能力提供了方向。

Abstract: Reasoning over procedural sequences, where the order of steps directly
impacts outcomes, is a critical capability for large language models (LLMs). In
this work, we study the task of reconstructing globally ordered sequences from
shuffled procedural steps, using a curated dataset of food recipes, a domain
where correct sequencing is essential for task success. We evaluate several
LLMs under zero-shot and few-shot settings and present a comprehensive
evaluation framework that adapts established metrics from ranking and sequence
alignment. These include Kendall's Tau, Normalized Longest Common Subsequence
(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects
of ordering quality. Our analysis shows that model performance declines with
increasing sequence length, reflecting the added complexity of longer
procedures. We also find that greater step displacement in the input,
corresponding to more severe shuffling, leads to further degradation. These
findings highlight the limitations of current LLMs in procedural reasoning,
especially with longer and more disordered inputs.

</details>


### [77] [SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection](https://arxiv.org/abs/2511.04692)
*Jingqing Wang,Jiaxing Shang,Rong Xu,Fei Hao,Tianjin Huang,Geyong Min*

Main category: cs.CL

TL;DR: 本文提出SARC框架，通过情感增强的深度聚类识别用户角色，并结合角色聚类和虚假新闻检测的联合优化目标，显著提升了虚假新闻检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将情感特征视为辅助信号，忽略了用户角色差异（即相同情感可能来源于不同角色），限制了捕获细微模式的能力，从而影响了虚假新闻检测效果。

Method: SARC（Sentiment-Augmented Role Clustering）框架首先通过联合评论文本表示（BiGRU和Attention机制）和情感编码生成用户特征；然后构建可微分的深度聚类模块自动识别用户角色；最后，提出一个联合优化目标，整合角色聚类和虚假新闻检测，以进一步提升模型性能。

Result: 在RumourEval-19和Weibo-comp两个基准数据集上的实验结果表明，SARC在所有评估指标上均优于基线模型。

Conclusion: SARC通过有效利用情感增强的深度聚类来识别用户角色，并结合角色聚类与虚假新闻检测的联合优化，显著提高了虚假新闻检测的准确性。

Abstract: Fake news detection has been a long-standing research focus in social
networks. Recent studies suggest that incorporating sentiment information from
both news content and user comments can enhance detection performance. However,
existing approaches typically treat sentiment features as auxiliary signals,
overlooking role differentiation, that is, the same sentiment polarity may
originate from users with distinct roles, thereby limiting their ability to
capture nuanced patterns for effective detection. To address this issue, we
propose SARC, a Sentiment-Augmented Role Clustering framework which utilizes
sentiment-enhanced deep clustering to identify user roles for improved fake
news detection. The framework first generates user features through joint
comment text representation (with BiGRU and Attention mechanism) and sentiment
encoding. It then constructs a differentiable deep clustering module to
automatically categorize user roles. Finally, unlike existing approaches which
take fake news label as the unique supervision signal, we propose a joint
optimization objective integrating role clustering and fake news detection to
further improve the model performance. Experimental results on two benchmark
datasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior
performance across all metrics compared to baseline models. The code is
available at: https://github.com/jxshang/SARC.

</details>


### [78] [Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks](https://arxiv.org/abs/2511.04689)
*Peiyu Li,Xiuxiu Tang,Si Chen,Ying Cheng,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: ATLAS是一种基于项目反应理论（IRT）的自适应测试框架，通过费舍尔信息指导项目选择，可大幅减少大型语言模型（LLM）评估所需的项目数量（90%），同时保持测量精度，并揭示了现有基准测试中项目质量问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型评估需要数千个基准测试项目，导致评估成本高昂且耗时。现有方法在评估时平等对待所有项目，但项目质量和信息量各不相同。此外，现有基准测试中存在带有负区分度的错误标注项目，影响评估准确性。

Method: 本文提出了ATLAS，一个自适应测试框架。该框架利用项目反应理论（IRT）来估计模型能力，并通过费舍尔信息（Fisher information）指导项目选择，以优化评估效率和精度。

Result: 对五个主要基准测试的分析发现，3-6%的项目表现出负区分度，表明存在标注错误。ATLAS在保持测量精度的同时，实现了90%的项目缩减；例如，在HellaSwag上，仅用42个项目即可匹配完整基准测试的评估结果，平均绝对误差（MAE）为0.154。该框架将项目曝光率维持在10%以下，测试重叠度在16-27%之间。在4000多个模型中，IRT排名与传统准确率排名存在显著差异，23-31%的模型排名变化超过10位。

Conclusion: ATLAS提供了一种高效且精确的LLM自适应评估方法，显著降低了评估成本和时间。IRT方法能更准确地反映模型能力，并揭示了现有基准测试中潜在的项目质量问题，从而提高了评估的效率和鲁棒性。

Abstract: Large language model evaluation requires thousands of benchmark items, making
evaluations expensive and slow. Existing methods compute average accuracy
across fixed item sets, treating all items equally despite varying quality and
informativeness. We present ATLAS an adaptive testing framework using Item
Response Theory (IRT) to estimate model ability through Fisher
information-guided item selection. Our analysis of five major benchmarks
reveals that 3-6% of items exhibit negative discrimination, indicating
annotation errors that corrupt static evaluation. ATLAS achieves 90% item
reduction while maintaining measurement precision: on HellaSwag (5,608 items),
we match full-benchmark estimates using only 42 items with 0.154 MAE. Our
framework maintains item exposure rates below 10% and test overlap at 16-27%,
compared to static benchmarks where every model sees all items (100% exposure).
Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with
the same accuracy get different IRT scores, and 23-31% of all models shift by
more than 10 rank positions. Code and calibrated item banks are available at
https://github.com/Peiyu-Georgia-Li/ATLAS.git.

</details>


### [79] [Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694)
*Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar*

Main category: cs.CL

TL;DR: 该研究提出将大型语言模型（LLM）中的指令层级解析视为推理任务，通过构建可验证的VerIH数据集并结合轻量级强化学习，显著提高了模型在指令遵循、层级优先级处理和对抗性攻击（如越狱和提示注入）方面的鲁棒性和可控性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在现实世界高风险决策中的应用，它们必须在一个提示上下文中协调来自多个来源（如开发者、用户、工具）的冲突指令。因此，在LLM中强制执行指令层级（即高级指令优先于低级请求）对于模型的可靠性和可控性至关重要。

Method: 研究将指令层级解析重新定义为推理任务，要求模型在生成响应前“思考”用户提示与高级（系统）指令之间的关系。为此，构建了VerIH数据集，其中包含具有可验证答案的约束遵循任务，涵盖对齐和冲突的系统-用户指令。通过对VerIH数据集进行轻量级强化学习来训练模型。

Result: 通过VerIH进行的强化学习能有效将模型的通用推理能力转移到指令优先级处理上。微调后的模型在指令遵循和指令层级基准测试上均取得了一致的改进。这种推理能力还泛化到训练分布之外的安全关键场景，通过将安全问题视为解决对抗性用户输入与预定义高优先级策略之间的冲突，提高了模型对抗越狱和提示注入攻击的鲁棒性。

Conclusion: 对指令层级进行推理为实现可靠的LLM提供了一条实用路径，其中系统提示的更新可以带来模型行为的可控和稳健变化。

Abstract: As large language model (LLM) based systems take on high-stakes roles in
real-world decision-making, they must reconcile competing instructions from
multiple sources (e.g., model developers, users, and tools) within a single
prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where
higher-level directives override lower-priority requests, is critical for the
reliability and controllability of LLMs. In this work, we reframe instruction
hierarchy resolution as a reasoning task. Specifically, the model must first
"think" about the relationship between a given user prompt and higher-priority
(system) instructions before generating a response. To enable this capability
via training, we construct VerIH, an instruction hierarchy dataset of
constraint-following tasks with verifiable answers. This dataset comprises both
aligned and conflicting system-user instructions. We show that lightweight
reinforcement learning with VerIH effectively transfers general reasoning
capabilities of models to instruction prioritization. Our finetuned models
achieve consistent improvements on instruction following and instruction
hierarchy benchmarks. This reasoning ability also generalizes to
safety-critical settings beyond the training distribution. By treating safety
issues as resolving conflicts between adversarial user inputs and predefined
higher-priority policies, our trained model enhances robustness against
jailbreak and prompt injection attacks. These results demonstrate that
reasoning over instruction hierarchies provides a practical path to reliable
LLMs, where updates to system prompts yield controllable and robust changes in
model behavior.

</details>


### [80] [EncouRAGe: Evaluating RAG Local, Fast, and Reliable](https://arxiv.org/abs/2511.04696)
*Jan Strich,Adeline Scharfenberg,Chris Biemann,Martin Semmann*

Main category: cs.CL

TL;DR: EncouRAGe是一个用于RAG系统开发和评估的Python框架。研究发现，RAG表现不如Oracle Context，而混合BM25在所有数据集中表现最佳，重排仅带来微小改进但增加了延迟。


<details>
  <summary>Details</summary>
Motivation: 简化使用LLM和嵌入模型进行检索增强生成（RAG）系统的开发和评估，实现灵活的实验、可扩展的开发、科学可复现性、多样化的评估指标以及本地部署。

Method: 引入EncouRAGe，一个包含Type Manifest、RAG Factory、Inference、Vector Store和Metrics五个模块化组件的Python框架。通过对多个基准数据集（包括2.5万个QA对和超过5.1万个文档）进行广泛评估，展示了其实现细节和性能。

Result: RAG系统在性能上仍不如Oracle Context。混合BM25在所有四个数据集中始终表现最佳。重排仅带来微小的性能提升，但伴随着更高的响应延迟。

Conclusion: EncouRAGe提供了一个全面的框架来简化RAG系统的开发和评估。研究结果表明，RAG系统在获取理想上下文方面仍有不足，混合BM25是一种高效的检索策略，而重排的性能收益可能不足以抵消其增加的延迟。

Abstract: We introduce EncouRAGe, a comprehensive Python framework designed to
streamline the development and evaluation of Retrieval-Augmented Generation
(RAG) systems using Large Language Models (LLMs) and Embedding Models.
EncouRAGe comprises five modular and extensible components: Type Manifest, RAG
Factory, Inference, Vector Store, and Metrics, facilitating flexible
experimentation and extensible development. The framework emphasizes scientific
reproducibility, diverse evaluation metrics, and local deployment, enabling
researchers to efficiently assess datasets within RAG workflows. This paper
presents implementation details and an extensive evaluation across multiple
benchmark datasets, including 25k QA pairs and over 51k documents. Our results
show that RAG still underperforms compared to the Oracle Context, while Hybrid
BM25 consistently achieves the best results across all four datasets. We
further examine the effects of reranking, observing only marginal performance
improvements accompanied by higher response latency.

</details>


### [81] [multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder](https://arxiv.org/abs/2511.04698)
*K M Sajjadul Islam,John Fields,Praveen Madiraju*

Main category: cs.CL

TL;DR: 本文提出multiMentalRoBERTa，一个经过微调的RoBERTa模型，用于从社交媒体文本中多类别分类检测常见的心理健康状况，并在性能和可解释性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 从社交媒体文本中早期发现心理健康障碍对于及时提供支持、风险评估和转介至适当资源至关重要。

Method: 研究引入了multiMentalRoBERTa，一个针对压力、焦虑、抑郁、创伤后应激障碍(PTSD)、自杀意念和中性话语进行多类别分类的微调RoBERTa模型。利用多个精选数据集进行数据探索，分析类别重叠。通过与传统机器学习方法、领域特定Transformer（如MentalBERT）和基于提示的大型语言模型进行比较实验。此外，应用可解释性方法（如Layer Integrated Gradients和KeyBERT）来识别分类的词汇线索。

Result: 数据探索揭示了抑郁症与自杀意念以及焦虑症与PTSD之间存在强相关性，而压力则是一个广泛重叠的类别。multiMentalRoBERTa在六类别设置中实现了0.839的宏F1分数，在五类别设置（排除压力）中实现了0.870的宏F1分数，均优于微调的MentalBERT和基线分类器。可解释性方法成功识别了驱动分类的词汇线索，特别是在区分抑郁症和自杀意念方面。

Conclusion: 研究结果强调了微调Transformer在敏感情境下进行可靠和可解释检测的有效性，同时也强调了公平性、偏见缓解和人工干预安全协议的重要性。multiMentalRoBERTa被认为是一种轻量级、稳健且可部署的解决方案，用于增强心理健康平台的支持。

Abstract: The early detection of mental health disorders from social media text is
critical for enabling timely support, risk assessment, and referral to
appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned
RoBERTa model designed for multiclass classification of common mental health
conditions, including stress, anxiety, depression, post-traumatic stress
disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple
curated datasets, data exploration is conducted to analyze class overlaps,
revealing strong correlations between depression and suicidal ideation as well
as anxiety and PTSD, while stress emerges as a broad, overlapping category.
Comparative experiments with traditional machine learning methods,
domain-specific transformers, and prompting-based large language models
demonstrate that multiMentalRoBERTa achieves superior performance, with macro
F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup
(excluding stress), outperforming both fine-tuned MentalBERT and baseline
classifiers. Beyond predictive accuracy, explainability methods, including
Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues
that drive classification, with a particular focus on distinguishing depression
from suicidal ideation. The findings emphasize the effectiveness of fine-tuned
transformers for reliable and interpretable detection in sensitive contexts,
while also underscoring the importance of fairness, bias mitigation, and
human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as
a lightweight, robust, and deployable solution for enhancing support in mental
health platforms.

</details>


### [82] [Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding](https://arxiv.org/abs/2511.04699)
*Haneen Al-Homoud,Asma Ibrahim,Murtadha Al-Jubran,Fahad Al-Otaibi,Yazeed Al-Harbi,Daulet Toibazar,Kesen Wang,Pedro J. Moreno*

Main category: cs.CL

TL;DR: Cross-Lingual SynthDocs是一个大规模合成语料库，旨在解决阿拉伯语OCR和文档理解资源稀缺问题，通过其训练的模型在多项基准测试中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前阿拉伯语OCR（光学字符识别）和文档理解（DU）资源匮乏，限制了相关研究和应用的发展。

Method: 该研究构建了Cross-Lingual SynthDocs语料库，包含超过250万样本，包括150万文本数据、27万完全标注的表格以及数十万基于真实数据的图表。其生成流程利用真实的扫描背景、双语布局和支持变音符号的字体，以捕捉阿拉伯语文档的排版和结构复杂性。语料库还包含各种渲染风格的图表和表格。

Result: 在SynthDocs上对Qwen-2.5-VL进行微调后，OCR的词错误率（WER）和字符错误率（CER）在多个公开阿拉伯语基准测试中均持续改善。同时，表格的树编辑距离相似度（TEDS）和图表的图表提取分数（CharTeX）也得到了提升。

Conclusion: SynthDocs提供了一个可扩展且视觉逼真的资源，能够有效推动多语言文档分析领域的研究进展。

Abstract: Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address
the scarcity of Arabic resources for Optical Character Recognition (OCR) and
Document Understanding (DU). The dataset comprises over 2.5 million of samples,
including 1.5 million textual data, 270K fully annotated tables, and hundred
thousands of real data based charts. Our pipeline leverages authentic scanned
backgrounds, bilingual layouts, and diacritic aware fonts to capture the
typographic and structural complexity of Arabic documents. In addition to text,
the corpus includes variety of rendered styles for charts and tables.
Finetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word
Error Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple
public Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart
Extraction Score (CharTeX) improved as well in other modalities. SynthDocs
provides a scalable, visually realistic resource for advancing research in
multilingual document analysis.

</details>


### [83] [Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation](https://arxiv.org/abs/2511.04700)
*Song Wang,Zihan Chen,Peng Wang,Zhepei Wei,Zhen Tan,Yu Meng,Cong Shen,Jundong Li*

Main category: cs.CL

TL;DR: WinnowRAG是一个新颖的RAG框架，通过查询感知聚类和评论LLM的迭代筛选，有效过滤噪声文档并保留有价值内容，从而在不进行模型微调的情况下提高生成响应的准确性。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）通过整合外部知识源来增强大型语言模型（LLMs），以解决其在访问最新或专业信息方面的局限性。增加检索文档的数量可以提高检索到相关信息的可能性，但这也会引入大量噪声，因为许多文档可能不相关或具有误导性，从而降低生成响应的整体准确性。本研究旨在克服处理大量文档所带来的挑战。

Method: WinnowRAG框架分两个阶段操作：第一阶段进行查询感知聚类，将相似文档分组形成不同的主题簇，每个簇分配给一个LLM代理生成唯一答案。第二阶段进行筛选，一个评论LLM评估多个代理的输出，并迭代地将有用文档与噪声文档分离。为在舍弃代理时保留有用文档，提出了两种策略性合并技术，以确保仅使用相关知识生成最终响应。WinnowRAG与模型无关，无需任何模型微调。

Result: 在各种真实数据集上进行的广泛实验表明，WinnowRAG比现有最先进的基线方法更有效。

Conclusion: WinnowRAG通过系统地筛选噪声文档，有效解决了RAG中处理大量文档引入噪声的挑战，显著提高了生成响应的准确性。其模型无关和无需微调的特性使其易于适应各种任务。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
integrating external knowledge sources to address their limitations in
accessing up-to-date or specialized information. A natural strategy to increase
the likelihood of retrieving relevant information is to expand the number of
retrieved documents. However, involving more documents could introduce
significant noise, as many documents may be irrelevant or misleading, thereby
reducing the overall accuracy of the generated responses. To overcome the
challenge associated with handling a larger number of documents, we propose
WinnowRAG, a novel RAG framework designed to systematically filter out noisy
documents while preserving valuable content -- a process we refer to as
winnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware
clustering to group similar documents and form distinct topic clusters. Each
cluster is assigned to an LLM agent for generating a unique answer. In Stage
II, we perform winnowing, wherein a critic LLM evaluates the outputs of
multiple agents and iteratively separates useful documents from noisy ones. To
retain useful documents when discarding agents, we propose two strategic
merging techniques to ensure that only relevant knowledge is used for
generating the final response. Crucially, WinnowRAG is model-agnostic and does
not require any model fine-tuning, making it easily adaptable to various tasks.
Extensive experiments on various realistic datasets demonstrate the
effectiveness of WinnowRAG over state-of-the-art baselines.

</details>


### [84] [Measuring what Matters: Construct Validity in Large Language Model Benchmarks](https://arxiv.org/abs/2511.04703)
*Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H. S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi*

Main category: cs.CL

TL;DR: 本文对445个大型语言模型（LLM）基准进行了系统性审查，发现其在衡量现象、任务和评分指标方面存在模式，这些模式损害了评估结果的有效性，并提出了八项改进建议。


<details>
  <summary>Details</summary>
Motivation: 评估LLM对于理解其能力、识别安全性和鲁棒性问题至关重要。然而，可靠地衡量“安全”和“鲁棒性”等抽象复杂现象需要强大的构念效度，即衡量指标必须真正代表现象的关键方面。

Method: 由29名专家审稿人组成的团队，对来自自然语言处理和机器学习顶级会议的445个LLM基准进行了系统性审查。

Result: 审查发现，在测量的现象、任务和评分指标方面存在某些模式，这些模式削弱了评估结果主张的有效性。

Conclusion: 为解决现有基准的不足，本文向研究人员和从业者提供了八项关键建议和详细可操作的指导，以开发更有效的LLM基准。

Abstract: Evaluating large language models (LLMs) is crucial for both assessing their
capabilities and identifying safety or robustness issues prior to deployment.
Reliably measuring abstract and complex phenomena such as 'safety' and
'robustness' requires strong construct validity, that is, having measures that
represent what matters to the phenomenon. With a team of 29 expert reviewers,
we conduct a systematic review of 445 LLM benchmarks from leading conferences
in natural language processing and machine learning. Across the reviewed
articles, we find patterns related to the measured phenomena, tasks, and
scoring metrics which undermine the validity of the resulting claims. To
address these shortcomings, we provide eight key recommendations and detailed
actionable guidance to researchers and practitioners in developing LLM
benchmarks.

</details>


### [85] [POLIS-Bench: Towards Multi-Dimensional Evaluation of LLMs for Bilingual Policy Tasks in Governmental Scenarios](https://arxiv.org/abs/2511.04705)
*Tingyue Yang,Junchi Yao,Yuhui Guo,Chang Liu*

Main category: cs.CL

TL;DR: 该论文介绍了POLIS-Bench，一个用于评估大型语言模型在政府双语政策场景下表现的基准套件，并提出了新的语料库、任务和评估框架。研究发现推理模型表现更优，并成功微调出成本效益高的模型。


<details>
  <summary>Details</summary>
Motivation: 现有基准缺乏对大型语言模型在政府双语政策场景下进行严格、系统评估的能力，需要一个更相关、全面且精准的评估工具。

Method: 引入POLIS-Bench评估套件，包含：1) 构建最新的双语政策语料库；2) 设计三项场景化任务：条款检索与解释、解决方案生成、合规性判断；3) 建立结合语义相似度和准确率的双重评估框架。在此基础上，对超过10个SOTA大型语言模型进行了大规模评估，并微调了一个轻量级开源模型（POLIS系列模型）。

Result: 评估结果显示大型语言模型存在清晰的性能层级，其中推理模型在跨任务稳定性和准确性方面表现更优，合规性任务难度最高。此外，微调后的POLIS系列模型在多个政策子任务上达到了或超越了强大的专有基线，且成本显著降低。

Conclusion: POLIS-Bench为评估大型语言模型在政府双语政策领域的应用提供了严格的基准。通过微调，可以开发出具有成本效益且符合要求的模型，以支持真实的政府部署。

Abstract: We introduce POLIS-Bench, the first rigorous, systematic evaluation suite
designed for LLMs operating in governmental bilingual policy scenarios.
Compared to existing benchmarks, POLIS-Bench introduces three major
advancements. (i) Up-to-date Bilingual Corpus: We construct an extensive,
up-to-date policy corpus that significantly scales the effective assessment
sample size, ensuring relevance to current governance practice. (ii)
Scenario-Grounded Task Design: We distill three specialized, scenario-grounded
tasks -- Clause Retrieval & Interpretation, Solution Generation, and the
Compliance Judgmen--to comprehensively probe model understanding and
application. (iii) Dual-Metric Evaluation Framework: We establish a novel
dual-metric evaluation framework combining semantic similarity with accuracy
rate to precisely measure both content alignment and task requirement
adherence. A large-scale evaluation of over 10 state-of-the-art LLMs on
POLIS-Bench reveals a clear performance hierarchy where reasoning models
maintain superior cross-task stability and accuracy, highlighting the
difficulty of compliance tasks. Furthermore, leveraging our benchmark, we
successfully fine-tune a lightweight open-source model. The resulting POLIS
series models achieves parity with, or surpasses, strong proprietary baselines
on multiple policy subtasks at a significantly reduced cost, providing a
cost-effective and compliant path for robust real-world governmental
deployment.

</details>


### [86] [GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models](https://arxiv.org/abs/2511.04710)
*Hari Mohan Pandey,Anshul Gupta,Subham Sarkar,Minakshi Tomer,Schneider Johannes,Yan Gong*

Main category: cs.CL

TL;DR: GEMMA-SQL是一个基于Gemma 2B架构的轻量级、高效文本到SQL模型，通过资源高效的迭代微调和多重提示策略（包括少样本学习），在SPIDER基准测试中实现了高准确率，超越了多个现有基线，并提供了一个实用、开源的解决方案。


<details>
  <summary>Details</summary>
Motivation: 使非专业用户能够通过自然语言与结构化数据库交互，无需编程知识。同时，旨在开发一个资源高效、可在低成本硬件上部署的文本到SQL系统，以克服许多大型语言模型（LLM）的资源限制。

Method: 该模型基于开源的Gemma 2B架构构建，采用资源高效的迭代微调方法。利用SPIDER基准进行训练和评估，并结合了多种提示策略，包括少样本学习，以提高SQL查询生成准确性。还开发了一个指令微调版本GEMMA-SQL Instruct。

Result: GEMMA-SQL Instruct在Test-Suite准确率上达到66.8%，在Exact Set Match准确率上达到63.3%。它超越了IRNet、RYANSQL和CodeXDavinci等多个最先进的基线模型。研究表明，有效的提示设计和有针对性的指令微调可以显著提升性能，同时保持高可扩展性和适应性。

Conclusion: GEMMA-SQL是一个实用、开源的替代方案，为构建强大且易于访问的文本到SQL系统提供了可能性。其成果证明了有效的提示设计和指令微调能够在保持资源效率的同时显著提升性能。

Abstract: Text-to-SQL systems enable users to interact with structured databases using
natural language, eliminating the need for specialized programming knowledge.
In this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL
model built upon the open-source Gemma 2B architecture. Unlike many large
language models (LLMs), GEMMA-SQL is fine-tuned in a resource-efficient,
iterative manner and can be deployed on low-cost hardware. Leveraging the
SPIDER benchmark for training and evaluation, GEMMA-SQL combines multiple
prompting strategies, including few-shot learning, to enhance SQL query
generation accuracy. The instruction-tuned variant, GEMMA-SQL Instruct,
achieves 66.8% Test-Suite accuracy and 63.3% Exact Set Match accuracy,
outperforming several state-of-the-art baselines such as IRNet, RYANSQL, and
CodeXDavinci. The proposed approach demonstrates that effective prompt design
and targeted instruction tuning can significantly boost performance while
maintaining high scalability and adaptability. These results position GEMMA-SQL
as a practical, open-source alternative for robust and accessible text-to-SQL
systems.

</details>


### [87] [First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation](https://arxiv.org/abs/2511.04715)
*Dmytro Vitel,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 本研究挑战了现有关于大型语言模型（LLM）训练样本影响估计中最佳层的观点，指出取消效应不可靠，并提出中间注意力层和新聚合/评估方法能更准确地估计影响。


<details>
  <summary>Details</summary>
Motivation: 理解训练样本如何影响LLM决策对于模型解释和大规模数据集审计至关重要。现有影响函数计算成本高昂，导致仅限于模型部分层。先前研究认为第一层（嵌入层）最具信息量，但该结论基于可能不可靠的“取消效应”假设。

Method: 我们提出了理论和实证证据来证明“取消效应”的不可靠性。研究表明中间注意力层是更好的影响估计器。此外，我们探讨了跨层影响分数聚合的挑战，并提出了优于标准平均的方法（如排序和基于投票的方法）。最后，我们提出了一种无需模型再训练来评估影响分数有效性的新方法，并引入了“噪声检测率”（NDR）指标，该指标比取消效应具有更强的预测能力。

Result: 研究发现“取消效应”是不可靠的，且中间注意力层是更好的影响估计器。替代的聚合方法（如排序和基于投票的方法）显著提升了性能。新提出的NDR指标展现出强大的预测能力。通过广泛实验，我们具体确定对于LLM影响估计而言，第一层并不一定优于最后一层，这与该领域的先前认知相悖。

Conclusion: 本研究挑战了关于LLM影响估计中信息层位置的传统观点，证明了取消效应的不可靠性，并提出中间注意力层结合改进的聚合和评估方法（如NDR）可以更准确地识别训练样本的影响，从而为LLM决策的解释和审计提供了更可靠的框架。

Abstract: Identifying how training samples influence/impact Large Language Model (LLM)
decision-making is essential for effectively interpreting model decisions and
auditing large-scale datasets. Current training sample influence estimation
methods (also known as influence functions) undertake this goal by utilizing
information flow through the model via its first-order and higher-order
gradient terms. However, owing to the large model sizes of today consisting of
billions of parameters, these influence computations are often restricted to
some subset of model layers to ensure computational feasibility. Prior seminal
work by Yeh et al. (2022) in assessing which layers are best suited for
computing language data influence concluded that the first (embedding) layers
are the most informative for this purpose, using a hypothesis based on
influence scores canceling out (i.e., the cancellation effect). In this work,
we propose theoretical and empirical evidence demonstrating how the
cancellation effect is unreliable, and that middle attention layers are better
estimators for influence. Furthermore, we address the broader challenge of
aggregating influence scores across layers, and showcase how alternatives to
standard averaging (such as ranking and vote-based methods) can lead to
significantly improved performance. Finally, we propose better methods for
evaluating influence score efficacy in LLMs without undertaking model
retraining, and propose a new metric known as the Noise Detection Rate (NDR)
that exhibits strong predictive capability compared to the cancellation effect.
Through extensive experiments across LLMs of varying types and scales, we
concretely determine that the first (layers) are not necessarily better than
the last (layers) for LLM influence estimation, contrasting with prior
knowledge in the field.

</details>


### [88] [Learning to reason about rare diseases through retrieval-augmented agents](https://arxiv.org/abs/2511.04720)
*Ha Young Kim,Jun Li,Ana Beatriz Solana,Carolin M. Pirkl,Benedikt Wiestler,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.CL

TL;DR: RADAR是一个检索增强诊断推理代理系统，通过访问外部医学知识（病例报告和文献）来检测脑部MRI中的罕见疾病，无需额外训练即可提高诊断准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏代表性训练数据，AI模型在医学影像中的罕见疾病检测方面表现不佳。临床放射科医生在面对不熟悉发现时，经常查阅病例报告和文献。

Method: RADAR利用AI代理，通过句子转换器嵌入病例报告和文献，并使用FAISS进行索引以实现高效相似性搜索。代理检索临床相关证据来指导对未见疾病的诊断决策。它是一个模型无关的推理模块，可与各种大型语言模型无缝集成。

Result: 在包含280种不同罕见疾病的NOVA数据集上，RADAR实现了高达10.2%的性能提升，尤其是在DeepSeek等开源模型上表现最佳。检索到的示例提供了可解释的、基于文献的解释。

Conclusion: 检索增强推理是医学影像中低患病率疾病的强大范式，能够提高准确性和可解释性。

Abstract: Rare diseases represent the long tail of medical imaging, where AI models
often fail due to the scarcity of representative training data. In clinical
workflows, radiologists frequently consult case reports and literature when
confronted with unfamiliar findings. Following this line of reasoning, we
introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic
system for rare disease detection in brain MRI. Our approach uses AI agents
with access to external medical knowledge by embedding both case reports and
literature using sentence transformers and indexing them with FAISS to enable
efficient similarity search. The agent retrieves clinically relevant evidence
to guide diagnostic decision making on unseen diseases, without the need of
additional training. Designed as a model-agnostic reasoning module, RADAR can
be seamlessly integrated with diverse large language models, consistently
improving their rare pathology recognition and interpretability. On the NOVA
dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2%
performance gain, with the strongest improvements observed for open source
models such as DeepSeek. Beyond accuracy, the retrieved examples provide
interpretable, literature grounded explanations, highlighting
retrieval-augmented reasoning as a powerful paradigm for low-prevalence
conditions in medical imaging.

</details>


### [89] [Surprisal reveals diversity gaps in image captioning and different scorers change the story](https://arxiv.org/abs/2511.04754)
*Nikolai Ilinykh,Simon Dobnik*

Main category: cs.CL

TL;DR: 本文提出使用“惊奇方差”（surprisal variance）量化图像字幕中的语言多样性。研究发现，在MSCOCO数据集上，人类字幕的惊奇方差在特定评分器下是模型的两倍，但在通用语言模型下模式反转。结论是，鲁棒的多样性评估需要使用多个评分器。


<details>
  <summary>Details</summary>
Motivation: 量化图像字幕中的语言多样性是一个重要问题，尤其是在比较最先进的视觉-语言大模型与人类字幕时。现有的评估方法可能不够全面或鲁棒，需要一种新的、基于惊奇的度量标准。

Method: 本文引入“惊奇方差”（surprisal variance）作为量化语言多样性的指标，即字幕集中词元级负对数概率的分布。研究在MSCOCO测试集上，比较了五种最先进的视觉-语言大模型（使用贪婪解码和核采样）与人类字幕。惊奇值通过两种语言模型计算：一个经过字幕训练的n-gram语言模型和一个通用语言模型。

Result: 使用经过字幕训练的n-gram语言模型时，人类字幕的惊奇方差大约是模型的两倍。然而，当使用通用语言模型重新评估相同的字幕时，这种模式完全反转。这表明单一评分器的选择可以完全颠覆结论。

Conclusion: 本文引入了基于惊奇的图像字幕多样性度量标准。研究强调，进行鲁棒的多样性评估必须在多个评分器下报告惊奇值，以避免因评分器选择而导致结论完全相反的情况。

Abstract: We quantify linguistic diversity in image captioning with surprisal variance
- the spread of token-level negative log-probabilities within a caption set. On
the MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs,
decoded with greedy and nucleus sampling, to human captions. Measured with a
caption-trained n-gram LM, humans display roughly twice the surprisal variance
of models, but rescoring the same captions with a general-language model
reverses the pattern. Our analysis introduces the surprisal-based diversity
metric for image captioning. We show that relying on a single scorer can
completely invert conclusions, thus, robust diversity evaluation must report
surprisal under several scorers.

</details>


### [90] [BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models](https://arxiv.org/abs/2511.04919)
*Chandra Vamsi Krishna Alla,Harish Naidu Gaddam,Manohar Kommi*

Main category: cs.CL

TL;DR: BudgetMem是一种内存增强架构，通过学习性地选择性记忆而非存储所有信息，显著降低了处理长上下文的内存消耗，同时保持了接近基线RAG的性能，尤其适用于长文档。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理长上下文时面临巨大的计算和内存限制，而对需要处理大量文档、多会话对话和书籍长度文本的应用需求日益增长。尽管现有方法已将上下文窗口扩展到100K-1M tokens，但这些方法对于资源受限的部署来说成本过高。

Method: BudgetMem提出了一种新颖的内存增强架构，它学习记忆哪些信息而非记住所有信息。该系统结合了选择性记忆策略和基于特征的显著性评分（实体密度、TF-IDF、语篇标记、位置偏差），以在严格预算约束下决定哪些信息值得存储。与现有存储所有块的检索增强生成（RAG）系统不同，BudgetMem采用学习门控机制结合BM25稀疏检索来实现高效的信息访问。

Result: 在Llama-3.2-3B-Instruct模型上，针对短（237 tokens）和长（5K-10K tokens）文档的700个问答对进行实验，BudgetMem在长文档上表现出色：与基线RAG相比，F1分数仅下降1.0%，同时节省了72.4%的内存。通过预算敏感性分析（测试7种预算比率）、朴素基线比较和文档长度分析，验证了该方法，表明BudgetMem的优势随文档长度增加而增强。

Conclusion: BudgetMem为在普通硬件上部署有能力的长上下文系统提供了一条实用途径，从而使先进的语言理解能力普及化。

Abstract: Large Language Models (LLMs) face significant computational and memory
constraints when processing long contexts, despite growing demand for
applications requiring reasoning over extensive documents, multi-session
dialogues, and book length texts. While recent advances have extended context
windows to 100K-1M tokens, such approaches incur prohibitive costs for resource
constrained deployments. We propose BudgetMem, a novel memory augmented
architecture that learns what to remember rather than remembering everything.
Our system combines selective memory policies with feature based salience
scoring (entity density, TF-IDF, discourse markers, position bias) to decide
which information merits storage under strict budget constraints. Unlike
existing retrieval augmented generation (RAG) systems that store all chunks,
BudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval
for efficient information access. Through comprehensive experiments on 700
question answer pairs across short (237 tokens) and long (5K-10K tokens)
documents with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves
remarkable results on long documents: only 1.0% F1 score degradation while
saving 72.4% memory compared to baseline RAG. We validate our approach through
budget sensitivity analysis (testing 7 budget ratios), naive baseline
comparisons, and document length analysis, showing that BudgetMem's benefits
increase with document length. Our work provides a practical pathway for
deploying capable long context systems on modest hardware, democratizing access
to advanced language understanding capabilities.

</details>


### [91] [Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs](https://arxiv.org/abs/2511.04875)
*Matthew Bozoukov,Matthew Nguyen,Shubkarman Singh,Bart Bussmann,Patrick Leask*

Main category: cs.CL

TL;DR: 本研究探讨了大型语言模型（LLMs）行为自我意识的出现条件和机制，发现其可通过单一LoRA适配器诱导，由激活空间中的转向向量捕获，并表现出领域局部性。


<details>
  <summary>Details</summary>
Motivation: LLMs能够准确描述或预测自身学习行为（行为自我意识），这引发了安全担忧，例如模型可能在评估中更好地隐藏真实能力。因此，研究旨在探究这种自我意识出现的最小条件及其作用机制。

Method: 通过对指令调优的LLMs进行受控的低秩适配器（LoRA）微调实验。

Result: ['行为自我意识可通过单一的rank-1 LoRA适配器可靠地诱导。', '学习到的自我意识行为在很大程度上可以通过激活空间中的单一转向向量来捕获，恢复了几乎所有微调的行为效果。', '自我意识并非普遍存在，而是领域局部化的，在不同任务中具有独立的表示。']

Conclusion: 行为自我意识表现为一种领域特定的线性特征，易于诱导和调节。

Abstract: Recent studies have revealed that LLMs can exhibit behavioral self-awareness:
the ability to accurately describe or predict their own learned behaviors
without explicit supervision. This capability raises safety concerns as it may,
for example, allow models to better conceal their true abilities during
evaluation. We attempt to characterize the minimal conditions under which such
self-awareness emerges, and the mechanistic processes through which it
manifests. Through controlled finetuning experiments on instruction-tuned LLMs
with low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably
induced using a single rank-1 LoRA adapter; (2) that the learned self-aware
behavior can be largely captured by a single steering vector in activation
space, recovering nearly all of the fine-tune's behavioral effect; and (3) that
self-awareness is non-universal and domain-localized, with independent
representations across tasks. Together, these findings suggest that behavioral
self-awareness emerges as a domain-specific, linear feature that can be easily
induced and modulated.

</details>


### [92] [Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs](https://arxiv.org/abs/2511.04869)
*Preetum Nakkiran,Arwen Bradley,Adam Goliński,Eugene Ndiaye,Michael Kirchhof,Sinead Williamson*

Main category: cs.CL

TL;DR: 本研究发现基础大语言模型在语义层面具有出色的校准能力，能评估其回答的含义置信度，这源于其下一个词元预测机制。然而，强化学习指令微调和思维链推理会破坏这种校准。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）通常缺乏对其输出的有意义的置信度估计，尤其是在超越词元层面，评估其响应实际含义的置信度方面尚不清楚。

Method: 研究采用了一种基于采样的语义校准概念，并引入了“B-校准”的通用定义（一种由等价类参数化的校准概念）。通过利用校准与局部损失最优性之间的联系，建立了语义校准作为下一个词元预测副产品出现的理论机制。该理论产生了一个可测试的预测，并通过问答任务的实验进行了验证。

Result: 研究发现，基础大语言模型在开放域问答任务中具有显著的语义校准能力，尽管它们并未明确接受此训练。语义校准是下一个词元预测的副产品。实验验证了三个预测：1) 基础LLMs在问答任务中具有语义校准性；2) RL指令微调系统地破坏了这种校准；3) 思维链推理也破坏了校准。

Conclusion: 本工作首次原理性地解释了LLMs中语义校准何时以及为何出现，并揭示了某些微调和推理方法对其产生负面影响。

Abstract: Large Language Models (LLMs) often lack meaningful confidence estimates for
their outputs. While base LLMs are known to exhibit next-token calibration, it
remains unclear whether they can assess confidence in the actual meaning of
their responses beyond the token level. We find that, when using a certain
sampling-based notion of semantic calibration, base LLMs are remarkably
well-calibrated: they can meaningfully assess confidence in open-domain
question-answering tasks, despite not being explicitly trained to do so. Our
main theoretical contribution establishes a mechanism for why semantic
calibration emerges as a byproduct of next-token prediction, leveraging a
recent connection between calibration and local loss optimality. The theory
relies on a general definition of "B-calibration," which is a notion of
calibration parameterized by a choice of equivalence classes (semantic or
otherwise). This theoretical mechanism leads to a testable prediction: base
LLMs will be semantically calibrated when they can easily predict their own
distribution over semantic answer classes before generating a response. We
state three implications of this prediction, which we validate through
experiments: (1) Base LLMs are semantically calibrated across
question-answering tasks, (2) RL instruction-tuning systematically breaks this
calibration, and (3) chain-of-thought reasoning breaks calibration. To our
knowledge, our work provides the first principled explanation of when and why
semantic calibration emerges in LLMs.

</details>


### [93] [Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models](https://arxiv.org/abs/2511.04800)
*Chenxi Liu,Junjie Liang,Yuqi Jia,Bochuan Cao,Yang Bai,Heng Huang,Xun Chen*

Main category: cs.CL

TL;DR: RLVR通过GRPO训练LLM在推理方面表现良好，但随着训练深入，残差提示（零方差奖励）增多，导致训练信号多样性降低。本文提出ERPO框架，通过提高对所有正确响应的残差提示的采样温度来鼓励探索，重新激活训练信号，从而提高LLM的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习与可验证奖励（RLVR）在提升大型语言模型（LLM）推理能力方面有效，其中GRPO系列表现出色。然而，随着模型训练时间增长和规模扩大，越来越多的训练提示变成残差提示（奖励方差为零），导致训练信号减少、多样性降低，从而影响训练效果。

Method: 本文提出了探索残差提示策略优化（ERPO）框架。ERPO为每个提示维护一个历史追踪器，并对那些之前所有响应都正确的残差提示自适应地增加采样温度。这种方法鼓励模型生成更多样化的推理路径，引入不正确的响应以重新激活训练信号。

Result: 在Qwen2.5系列模型上的实证结果表明，ERPO在多个数学推理基准测试中持续超越了强大的基线模型。

Conclusion: ERPO框架通过鼓励对残差提示的探索并重新激活其训练信号，有效解决了RLVR训练中残差提示导致的训练信号多样性不足问题，显著提升了LLM的数学推理能力。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an
effective approach for improving the reasoning abilities of large language
models (LLMs). The Group Relative Policy Optimization (GRPO) family has
demonstrated strong performance in training LLMs with RLVR. However, as models
train longer and scale larger, more training prompts become residual prompts,
those with zero variance rewards that provide no training signal. Consequently,
fewer prompts contribute to training, reducing diversity and hindering
effectiveness. To fully exploit these residual prompts, we propose the Explore
Residual Prompts in Policy Optimization (ERPO) framework, which encourages
exploration on residual prompts and reactivates their training signals. ERPO
maintains a history tracker for each prompt and adaptively increases the
sampling temperature for residual prompts that previously produced all correct
responses. This encourages the model to generate more diverse reasoning traces,
introducing incorrect responses that revive training signals. Empirical results
on the Qwen2.5 series demonstrate that ERPO consistently surpasses strong
baselines across multiple mathematical reasoning benchmarks.

</details>


### [94] [AgentExpt: Automating AI Experiment Design with LLM-based Resource Retrieval Agent](https://arxiv.org/abs/2511.04921)
*Yu Li,Lehui Li,Qingmin Liao,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 本文提出一个综合框架，通过利用基线和数据集的引用网络，改进了大型语言模型代理在自动化实验设计中的数据集和基线推荐。该框架包括一个自动数据收集管道、一个集体感知增强的检索器和一个推理增强的重排序器，显著提高了推荐的召回率和命中率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理在网络任务中的能力日益增强，激发了利用其促进科学探索的兴趣，尤其是在通过代理式数据集和基线检索自动化实验设计方面。然而，现有方法存在数据覆盖有限（未涵盖论文中实际使用的数据集）和过度依赖内容相似性（导致表面相似性而非实验适用性）的问题。

Method: 1. 设计了一个自动化数据收集管道，将约十万篇已接受论文与其使用的基线和数据集关联起来。2. 提出了一个集体感知增强的检索器，通过将自描述与聚合的引用上下文连接起来，表示每个数据集或基线在学术网络中的位置，并微调嵌入模型以实现高效的候选召回。3. 开发了一个推理增强的重排序器，提取交互链以构建明确的推理链，并微调大型语言模型以生成可解释的理由和精炼的排名。

Result: 1. 整理的数据集覆盖了过去五年顶级AI会议上使用的85%的数据集和基线。2. 所提出的方法在Recall@20上平均提高了5.85%，在HitRate@5上平均提高了8.30%，优于之前最强基线。

Conclusion: 研究结果推动了实验设计自动化领域向更可靠、可解释的方向发展。

Abstract: Large language model agents are becoming increasingly capable at web-centric
tasks such as information retrieval, complex reasoning. These emerging
capabilities have given rise to surge research interests in developing LLM
agent for facilitating scientific quest. One key application in AI research is
to automate experiment design through agentic dataset and baseline retrieval.
However, prior efforts suffer from limited data coverage, as recommendation
datasets primarily harvest candidates from public portals and omit many
datasets actually used in published papers, and from an overreliance on content
similarity that biases model toward superficial similarity and overlooks
experimental suitability. Harnessing collective perception embedded in the
baseline and dataset citation network, we present a comprehensive framework for
baseline and dataset recommendation. First, we design an automated
data-collection pipeline that links roughly one hundred thousand accepted
papers to the baselines and datasets they actually used. Second, we propose a
collective perception enhanced retriever. To represent the position of each
dataset or baseline within the scholarly network, it concatenates
self-descriptions with aggregated citation contexts. To achieve efficient
candidate recall, we finetune an embedding model on these representations.
Finally, we develop a reasoning-augmented reranker that exact interaction
chains to construct explicit reasoning chains and finetunes a large language
model to produce interpretable justifications and refined rankings. The dataset
we curated covers 85\% of the datasets and baselines used at top AI conferences
over the past five years. On our dataset, the proposed method outperforms the
strongest prior baseline with average gains of +5.85\% in Recall@20, +8.30\% in
HitRate@5. Taken together, our results advance reliable, interpretable
automation of experimental design.

</details>


### [95] [Too Good to be Bad: On the Failure of LLMs to Role-Play Villains](https://arxiv.org/abs/2511.04962)
*Zihao Yi,Qingxuan Jiang,Ruotian Ma,Xingyu Chen,Qu Yang,Mengru Wang,Fanghua Ye,Ying Shen,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CL

TL;DR: 研究发现，由于安全对齐，大型语言模型在扮演非亲社会或反派角色时表现不佳，角色道德水平越低，扮演的忠实度下降越明显。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）越来越多地用于创意生成和角色模拟，但它们扮演非亲社会、反派角色的能力尚未得到充分检验。研究者假设，现代LLMs的安全对齐与真实扮演道德模糊或邪恶角色之间存在根本冲突。

Method: 引入了“道德角色扮演（Moral RolePlay）”基准测试数据集，该数据集包含一个四级道德对齐量表和平衡的测试集。使用该基准测试评估了最先进的LLMs扮演从道德典范到纯粹反派角色的能力，并进行了大规模评估。

Result: 评估显示，随着角色道德水平的降低，LLMs的角色扮演忠实度呈一致的单调下降趋势。模型在处理“欺骗性”和“操纵性”等直接与安全原则相悖的特质时表现最差，常常用肤浅的攻击性取代细致入微的恶意。此外，通用聊天机器人的熟练程度并不能很好地预测反派角色扮演能力，高度安全对齐的模型表现尤其差。

Conclusion: 这项工作首次系统地揭示了LLMs在扮演反派角色方面的关键局限性，突出了模型安全性与创意忠实度之间的关键矛盾。该基准和研究结果为开发更细致、更具情境感知能力的对齐方法铺平了道路。

Abstract: Large Language Models (LLMs) are increasingly tasked with creative
generation, including the simulation of fictional characters. However, their
ability to portray non-prosocial, antagonistic personas remains largely
unexamined. We hypothesize that the safety alignment of modern LLMs creates a
fundamental conflict with the task of authentically role-playing morally
ambiguous or villainous characters. To investigate this, we introduce the Moral
RolePlay benchmark, a new dataset featuring a four-level moral alignment scale
and a balanced test set for rigorous evaluation. We task state-of-the-art LLMs
with role-playing characters from moral paragons to pure villains. Our
large-scale evaluation reveals a consistent, monotonic decline in role-playing
fidelity as character morality decreases. We find that models struggle most
with traits directly antithetical to safety principles, such as ``Deceitful''
and ``Manipulative'', often substituting nuanced malevolence with superficial
aggression. Furthermore, we demonstrate that general chatbot proficiency is a
poor predictor of villain role-playing ability, with highly safety-aligned
models performing particularly poorly. Our work provides the first systematic
evidence of this critical limitation, highlighting a key tension between model
safety and creative fidelity. Our benchmark and findings pave the way for
developing more nuanced, context-aware alignment methods.

</details>


### [96] [SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents](https://arxiv.org/abs/2511.04910)
*Jaehoon Lee,Sohyun Kim,Wanggeun Park,Geon Lee,Seungkyung Kim,Minyoung Lee*

Main category: cs.CL

TL;DR: 本文引入了SDS KoPub VDR，这是首个大规模公开的韩语公共文档视觉文档检索（VDR）基准，旨在解决现有基准在非英语语言和复杂结构文档方面的不足。该基准包含真实文档、人工验证的查询，并支持文本和多模态检索评估，揭示了当前模型在跨模态推理上的显著性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉文档检索（VDR）基准主要忽略了非英语语言和官方出版物固有的结构复杂性，导致在处理真实世界复杂文档智能方面的评估不足。

Method: 研究者构建了SDS KoPub VDR基准，包含361份真实韩语公共文档（40,781页），涵盖复杂视觉元素。他们生成了600个查询-页面-答案三元组，通过多模态模型（如GPT-4o）初步生成并经过严格的人工验证和细化。查询按推理模态（文本、视觉、跨模态）分类。该基准用于评估两种检索任务：仅文本检索和多模态检索（结合文本和视觉特征）。

Result: 双任务评估结果显示，即使是最先进的模型，在多模态场景，特别是需要跨模态推理的任务中，仍存在显著的性能差距。

Conclusion: SDS KoPub VDR作为一个基础资源，不仅能对文本和多模态检索任务进行严格细致的评估，还为在复杂真实世界文档智能领域推进多模态AI提供了清晰的路线图。

Abstract: Existing benchmarks for visual document retrieval (VDR) largely overlook
non-English languages and the structural complexity of official publications.
To address this critical gap, we introduce SDS KoPub VDR, the first
large-scale, publicly available benchmark for retrieving and understanding
Korean public documents. The benchmark is built upon a corpus of 361 real-world
documents (40,781 pages), including 256 files under the KOGL Type 1 license and
105 from official legal portals, capturing complex visual elements like tables,
charts, and multi-column layouts. To establish a challenging and reliable
evaluation set, we constructed 600 query-page-answer triples. These were
initially generated using multimodal models (e.g., GPT-4o) and subsequently
underwent a rigorous human verification and refinement process to ensure
factual accuracy and contextual relevance. The queries span six major public
domains and are systematically categorized by the reasoning modality required:
text-based, visual-based (e.g., chart interpretation), and cross-modal. We
evaluate SDS KoPub VDR on two complementary tasks that reflect distinct
retrieval paradigms: (1) text-only retrieval, which measures a model's ability
to locate relevant document pages based solely on textual signals, and (2)
multimodal retrieval, which assesses retrieval performance when visual features
(e.g., tables, charts, and layouts) are jointly leveraged alongside text. This
dual-task evaluation reveals substantial performance gaps, particularly in
multimodal scenarios requiring cross-modal reasoning, even for state-of-the-art
models. As a foundational resource, SDS KoPub VDR not only enables rigorous and
fine-grained evaluation across textual and multimodal retrieval tasks but also
provides a clear roadmap for advancing multimodal AI in complex, real-world
document intelligence.

</details>


### [97] [LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model](https://arxiv.org/abs/2511.04952)
*Wei Shao,Lingchao Zheng,Pengyu Wang,Peizhen Zheng,Jun Li,Yuwei Fan*

Main category: cs.CL

TL;DR: 该论文提出LoPT，一个无损并行分词框架，旨在解决大型语言模型长上下文推理中的分词瓶颈。LoPT通过基于字符位置的匹配和动态块长度调整，确保与标准顺序分词结果一致，并显著提高处理速度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中的长上下文推理场景日益重要，但其引入了显著的计算延迟。尽管之前的研究优化了长序列推理，但分词仍然是一个被忽视的瓶颈。现有的并行分词方法因合并后的边界伪影而导致结果不一致。

Method: 我们提出了LoPT（无损并行分词）框架。该方法采用基于字符位置的匹配和动态块长度调整，以准确对齐和合并分词后的片段，从而确保输出与标准顺序分词完全一致。

Result: 在各种长文本数据集上的广泛实验表明，LoPT在保证无损分词（与顺序分词结果相同）的同时，实现了显著的加速。我们还提供了理论一致性证明和全面的分析研究来验证该方法的鲁棒性。

Conclusion: LoPT成功解决了长上下文推理中的分词瓶颈，通过提供快速且无损的并行分词方案，提高了大型语言模型的效率和一致性。

Abstract: Long context inference scenarios have become increasingly important for large
language models, yet they introduce significant computational latency. While
prior research has optimized long-sequence inference through operators, model
architectures, and system frameworks, tokenization remains an overlooked
bottleneck. Existing parallel tokenization methods accelerate processing
through text segmentation and multi-process tokenization, but they suffer from
inconsistent results due to boundary artifacts that occur after merging. To
address this, we propose LoPT, a novel Lossless Parallel Tokenization framework
that ensures output identical to standard sequential tokenization. Our approach
employs character-position-based matching and dynamic chunk length adjustment
to align and merge tokenized segments accurately. Extensive experiments across
diverse long-text datasets demonstrate that LoPT achieves significant speedup
while guaranteeing lossless tokenization. We also provide theoretical proof of
consistency and comprehensive analytical studies to validate the robustness of
our method.

</details>


### [98] [Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy](https://arxiv.org/abs/2511.04926)
*Shixiong Zhao,Hideaki Takeda*

Main category: cs.CL

TL;DR: 本文提出了一种新的验证方法和评估标准，用于识别并确认Wikidata中特定领域的分类错误、过度泛化的子类链接和冗余连接，并开发了一个系统，利用众包机制让用户检查和纠正分类关系。


<details>
  <summary>Details</summary>
Motivation: Wikidata作为最大的开放知识图谱，虽然提供了便捷的知识访问，但其相对宽松的编辑政策导致了一定程度的分类不一致性，包括分类错误、过度泛化的子类链接和冗余连接。

Method: 本文提出并应用了一种新颖的验证方法来确认Wikidata特定领域中的分类错误、过度泛化的子类链接和冗余连接。此外，还引入了一个新的评估标准来判断这些问题是否需要修正，并开发了一个系统，允许用户检查任意Wikidata实体的分类关系，以充分利用其众包特性。

Result: 研究确认了Wikidata特定领域中存在分类错误、过度泛化的子类链接和冗余连接。论文提出了一种新的验证方法和评估标准，并开发了一个系统，使用户能够检查和潜在地纠正这些分类问题。

Conclusion: 通过提出新的验证方法、评估标准和用户检查系统，本文旨在解决Wikidata中的分类不一致性问题，并利用其众包特性来提高知识图谱的质量和准确性。

Abstract: Wikidata is currently the largest open knowledge graph on the web,
encompassing over 120 million entities. It integrates data from various
domain-specific databases and imports a substantial amount of content from
Wikipedia, while also allowing users to freely edit its content. This openness
has positioned Wikidata as a central resource in knowledge graph research and
has enabled convenient knowledge access for users worldwide. However, its
relatively loose editorial policy has also led to a degree of taxonomic
inconsistency. Building on prior work, this study proposes and applies a novel
validation method to confirm the presence of classification errors,
over-generalized subclass links, and redundant connections in specific domains
of Wikidata. We further introduce a new evaluation criterion for determining
whether such issues warrant correction and develop a system that allows users
to inspect the taxonomic relationships of arbitrary Wikidata
entities-leveraging the platform's crowdsourced nature to its full potential.

</details>


### [99] [UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian](https://arxiv.org/abs/2511.05040)
*Mykyta Syromiatnikov,Victoria Ruvinskaya*

Main category: cs.CL

TL;DR: 该研究引入了UA-Code-Bench，一个针对乌克兰语大语言模型代码生成和竞争性编程能力的新基准，并评估了13个领先模型，揭示了低资源语言代码生成的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注从英语翻译的广泛任务或仅评估简单的语言理解，难以真实评估大语言模型在低资源语言中的实际能力，特别是在代码生成等复杂任务上。

Method: 引入了UA-Code-Bench，包含来自Eolymp平台的500个问题，分为五个难度级别。使用one-shot提示，评估了13个主流专有和开源模型生成Python解决方案的能力。通过Eolymp环境针对隐藏测试进行评估，并分析了不同难度下的性能、解决方案的独特性以及计算效率（时间消耗和内存消耗）。

Result: 即使是顶级模型（如OpenAI o3和GPT-5）也只能解决大约一半的问题，这突显了在低资源自然语言中进行代码生成的挑战。研究还提供了不同难度级别下的性能综合分析，以及解决方案独特性和计算效率的评估。

Conclusion: 竞争性编程基准在评估大语言模型（尤其是在代表性不足的语言中）方面具有重要价值。这项工作为未来在多语言代码生成和推理增强模型方面的研究铺平了道路。

Abstract: Evaluating the real capabilities of large language models in low-resource
languages still represents a challenge, as many existing benchmarks focus on
widespread tasks translated from English or evaluate only simple language
understanding. This paper introduces UA-Code-Bench, a new open-source benchmark
established for a thorough evaluation of language models' code generation and
competitive programming problem-solving abilities in Ukrainian. The benchmark
comprises 500 problems from the Eolymp platform, evenly distributed across five
complexity levels from very easy to very hard. A diverse set of 13 leading
proprietary and open-source models, generating Python solutions based on a
one-shot prompt, was evaluated via the dedicated Eolymp environment against
hidden tests, ensuring code correctness. The obtained results reveal that even
top-performing models, such as OpenAI o3 and GPT-5, solve only half of the
problems, highlighting the challenge of code generation in low-resource natural
language. Furthermore, this research presents a comprehensive analysis of
performance across various difficulty levels, as well as an assessment of
solution uniqueness and computational efficiency, measured by both elapsed time
and memory consumption of the generated solutions. In conclusion, this work
demonstrates the value of competitive programming benchmarks in evaluating
large language models, especially in underrepresented languages. It also paves
the way for future research on multilingual code generation and
reasoning-enhanced models. The benchmark, data parsing, preparation, code
generation, and evaluation scripts are available at
https://huggingface.co/datasets/NLPForUA/ua-code-bench.

</details>


### [100] [Acquiring Common Chinese Emotional Events Using Large Language Model](https://arxiv.org/abs/2511.04989)
*Ya Wang,Guangzheng Zhu,Cungen Cao,Jingjing Li,He Li,Xin Huang*

Main category: cs.CL

TL;DR: 本文旨在构建一个大规模的中文通用情感事件知识库。通过收集情感事件指示词，利用大型语言模型生成事件，并训练过滤器进行质量控制和情感极性分类，最终获得了102,218个高质量的通用情感事件。


<details>
  <summary>Details</summary>
Motivation: 情感事件知识对于提高各种应用的有效性至关重要，但很难获取，特别是与上下文无关的常见或通用情感事件。

Method: 首先，收集全面的中文情感事件指示词。然后，利用这些指示词提示中文大型语言模型生成情感事件。为了确保质量，训练了一个过滤器来筛选无效结果。同时，采用不同技术将事件分类为积极或消极事件。

Result: 成功构建了包含102,218个带有情感极性标签的高质量通用情感事件的知识库，这是目前唯一大规模的中文情感事件常识知识库。内在评估证明了方法的有效性，而外在用例（情感原因抽取）也展示了这些事件的巨大潜力。

Conclusion: 所提出的方法能够有效地获取常见的中文情感事件。所构建的通用情感事件知识库具有很强的应用潜力，尤其在情感原因抽取等领域。

Abstract: Knowledge about emotional events is an important kind of knowledge which has
been applied to improve the effectiveness of different applications. However,
emotional events cannot be easily acquired, especially common or generalized
emotional events that are context-independent. The goal of this paper is to
obtain common emotional events in Chinese language such as "win a prize" and
"be criticized". Our approach begins by collecting a comprehensive list of
Chinese emotional event indicators. Then, we generate emotional events by
prompting a Chinese large language model (LLM) using these indicators. To
ensure the quality of these emotional events, we train a filter to discard
invalid generated results. We also classify these emotional events as being
positive events and negative events using different techniques. Finally, we
harvest a total of 102,218 high-quality common emotional events with sentiment
polarity labels, which is the only large-scale commonsense knowledge base of
emotional events in Chinese language. Intrinsic evaluation results show that
the proposed method in this paper can be effectively used to acquire common
Chinese emotional events. An extrinsic use case also demonstrates the strong
potential of common emotional events in the field of emotion cause extraction
(ECE). Related resources including emotional event indicators and emotional
events will be released after the publication of this paper.

</details>


### [101] [Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies](https://arxiv.org/abs/2511.05018)
*Prasoon Varshney,Makesh Narsimhan Sreedhar,Liwei Jiang,Traian Rebedea,Christopher Parisien*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）在单轮交互中能很好地遵守行为政策，但在多轮对抗性交互中，其遵守多元化对齐规范的能力显著下降，现有对齐方法不足以应对现实世界的复杂场景。


<details>
  <summary>Details</summary>
Motivation: LLM在实际应用中需要适应不同的组织政策、法规、品牌指南和伦理承诺，而不仅仅是通用的安全原则。这凸显了对LLM进行多元化对齐评估的迫切需求，以确保模型能适应多样化的用户价值观和需求。

Method: 本文提出了PLURALISTIC BEHAVIOR SUITE (PBSUITE)，一个动态评估套件，用于系统评估LLM在多轮交互中遵守多元化对齐规范的能力。PBSUITE包含：1) 一个由300个基于30个行业、真实的LLM行为政策组成的多样化数据集；2) 一个动态评估框架，用于在对抗性条件下压力测试模型对自定义行为规范的依从性。

Result: 研究发现，领先的开源和闭源LLM在单轮设置中对行为政策表现出强大的遵守能力（失败率低于4%），但在多轮对抗性交互中，其遵守能力大幅减弱（失败率高达84%）。

Conclusion: 这些发现表明，现有的模型对齐和安全审核方法在现实世界的LLM交互中，无法有效地执行多元化行为政策。本文贡献了数据集和分析框架，以支持未来对鲁棒和上下文感知的多元化对齐技术的研究。

Abstract: Large language models (LLMs) are typically aligned to a universal set of
safety and usage principles intended for broad public acceptability. Yet,
real-world applications of LLMs often take place within organizational
ecosystems shaped by distinctive corporate policies, regulatory requirements,
use cases, brand guidelines, and ethical commitments. This reality highlights
the need for rigorous and comprehensive evaluation of LLMs with pluralistic
alignment goals, an alignment paradigm that emphasizes adaptability to diverse
user values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE
(PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs'
capacity to adhere to pluralistic alignment specifications in multi-turn,
interactive conversations. PBSUITE consists of (1) a diverse dataset of 300
realistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic
evaluation framework for stress-testing model compliance with custom behavioral
specifications under adversarial conditions. Using PBSUITE, We find that
leading open- and closed-source LLMs maintain robust adherence to behavioral
policies in single-turn settings (less than 4% failure rates), but their
compliance weakens substantially in multi-turn adversarial interactions (up to
84% failure rates). These findings highlight that existing model alignment and
safety moderation methods fall short in coherently enforcing pluralistic
behavioral policies in real-world LLM interactions. Our work contributes both
the dataset and analytical framework to support future research toward robust
and context-aware pluralistic alignment techniques.

</details>


### [102] [Iterative Layer-wise Distillation for Efficient Compression of Large Language Models](https://arxiv.org/abs/2511.05085)
*Grigory Kovalev,Mikhail Tikhomirov*

Main category: cs.CL

TL;DR: 本研究提出了一种改进的基于ShortGPT的大语言模型蒸馏方法，通过迭代评估层重要性并结合KL散度和均方误差的联合损失函数进行训练，成功将Qwen2.5-3B模型的层数从36减少到28（参数量24.7亿），仅带来9.7%的质量损失，适用于资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 开发紧凑且能保持高性能的大语言模型（LLMs），以满足在资源受限环境中部署高效模型的需求。

Method: 回顾了现有蒸馏方法，并提出了一种改进的ShortGPT方法。该方法通过迭代评估层重要性，具体为在移除单个层后，使用代表性数据集测量性能下降来评估重要性。此过程与使用基于KL散度和均方误差的联合损失函数进行的进一步训练相结合。

Result: 在Qwen2.5-3B模型上的实验表明，层数可以从36减少到28（产生24.7亿参数模型），仅有9.7%的质量损失；减少到24层时，质量损失为18%。研究发现中间的Transformer层对推理的贡献较小。

Conclusion: 所提出的迭代蒸馏和微调方法对于创建高效模型是有效的，通过减少层数同时控制质量损失，使其适用于在资源受限环境中部署。

Abstract: This work investigates distillation methods for large language models (LLMs)
with the goal of developing compact models that preserve high performance.
Several existing approaches are reviewed, with a discussion of their respective
strengths and limitations. An improved method based on the ShortGPT approach
has been developed, building upon the idea of incorporating iterative
evaluation of layer importance. At each step, importance is assessed by
measuring performance degradation when individual layers are removed, using a
set of representative datasets. This process is combined with further training
using a joint loss function based on KL divergence and mean squared error.
Experiments on the Qwen2.5-3B model show that the number of layers can be
reduced from 36 to 28 (resulting in a 2.47 billion parameter model) with only a
9.7% quality loss, and to 24 layers with an 18% loss. The findings suggest that
the middle transformer layers contribute less to inference, underscoring the
potential of the proposed method for creating efficient models. The results
demonstrate the effectiveness of iterative distillation and fine-tuning, making
the approach suitable for deployment in resource-limited settings.

</details>


### [103] [Order-Level Attention Similarity Across Language Models: A Latent Commonality](https://arxiv.org/abs/2511.05064)
*Jinglin Liang,Jin Zhong,Shuangping Huang,Yunqing Hu,Huiyuan Zhang,Huifang Li,Lixin Fan,Hanlin Gu*

Main category: cs.CL

TL;DR: 本论文揭示了不同语言模型（LMs）之间上下文聚合模式的共性，并引入了“阶次级注意力”（OLA）来捕捉这些共性。基于此，提出了一种无需训练的跨模型适配器“可迁移OLA适配器”（TOA），通过将OLA作为统一的句法特征，有效提升了未见LMs的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究关注LMs的上下文聚合或注意力权重，但它们通常侧重于单个模型或注意力头，缺乏对多个LMs之间共性的系统分析。本研究旨在探索LMs之间的共性，以加深对LMs的理解并促进跨模型知识迁移。

Method: 引入了从注意力展开（Attention Rollout）的阶次分解中导出的“阶次级注意力”（OLA）。发现不同LMs在相同阶次上的OLA表现出显著相似性。进一步揭示了OLA与句法知识之间的隐式映射。基于这两项发现，提出了“可迁移OLA适配器”（TOA），这是一种无需训练的跨LM适配器迁移方法，将OLA视为统一的句法特征表示来训练适配器。

Result: 相同阶次上的OLA在不同LMs之间表现出显著相似性。发现了OLA与句法知识之间的隐式映射。TOA的跨LM泛化能力被证明能有效增强未见LMs的性能。

Conclusion: LMs的上下文聚合模式存在共同点，可以通过OLA来量化。OLA可以作为统一的句法特征表示，实现无需训练的跨LM知识迁移，从而有效提升未见LMs的性能。

Abstract: In this paper, we explore an important yet previously neglected question: Do
context aggregation patterns across Language Models (LMs) share commonalities?
While some works have investigated context aggregation or attention weights in
LMs, they typically focus on individual models or attention heads, lacking a
systematic analysis across multiple LMs to explore their commonalities. In
contrast, we focus on the commonalities among LMs, which can deepen our
understanding of LMs and even facilitate cross-model knowledge transfer. In
this work, we introduce the Order-Level Attention (OLA) derived from the
order-wise decomposition of Attention Rollout and reveal that the OLA at the
same order across LMs exhibits significant similarities. Furthermore, we
discover an implicit mapping between OLA and syntactic knowledge. Based on
these two findings, we propose the Transferable OLA Adapter (TOA), a
training-free cross-LM adapter transfer method. Specifically, we treat the OLA
as a unified syntactic feature representation and train an adapter that takes
OLA as input. Due to the similarities in OLA across LMs, the adapter
generalizes to unseen LMs without requiring any parameter updates. Extensive
experiments demonstrate that TOA's cross-LM generalization effectively enhances
the performance of unseen LMs. Code is available at
https://github.com/jinglin-liang/OLAS.

</details>


### [104] [Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media Posts](https://arxiv.org/abs/2511.05078)
*Manan Sharma,Arya Suneesh,Manish Jain,Pawan Kumar Rajpoot,Prasanna Devadiga,Bharatdeep Hazarika,Ashish Shrivastava,Kishan Gurumurthy,Anshuman B Suresh,Aditya U Baliga*

Main category: cs.CL

TL;DR: 本文提出了一种多语言虚假信息检测的声明规范化方法，通过系统地分解社交媒体帖子并利用5W1H问题，实现了在仅用英语数据训练的情况下，对20种语言的鲁棒跨语言迁移。


<details>
  <summary>Details</summary>
Motivation: 将嘈杂的社交媒体帖子转化为清晰、可验证的陈述，以支持多语言虚假信息检测，并解决跨语言传输的挑战。

Method: 核心方法是使用“谁、什么、哪里、何时、为什么、如何”问题对帖子进行系统分解，以实现跨语言迁移。具体技术包括使用LoRA微调Qwen3-14B模型，进行帖子内去重，采用token级别召回过滤以实现语义对齐，并在推理时结合上下文示例进行检索增强的少样本学习。训练数据仅限于英语。

Result: 系统在英语上的METEOR得分达到41.16，在马拉地语上为15.21。在英语排行榜上排名第三，在荷兰语和旁遮普语上排名第四。相对于基线配置，METEOR得分有41.3%的相对提升，并显著优于现有方法。结果显示，该方法在罗曼语系和日耳曼语系语言上表现出有效的跨语言泛化能力，并保持了不同语言结构间的语义连贯性。

Conclusion: 通过5W1H问题分解法和仅英语训练，本文提出的方法能够实现鲁棒的跨语言声明规范化，特别是在罗曼语系和日耳曼语系语言中表现出强大的泛化能力和显著的性能提升。

Abstract: We address claim normalization for multilingual misinformation detection -
transforming noisy social media posts into clear, verifiable statements across
20 languages. The key contribution demonstrates how systematic decomposition of
posts using Who, What, Where, When, Why and How questions enables robust
cross-lingual transfer despite training exclusively on English data. Our
methodology incorporates finetuning Qwen3-14B using LoRA with the provided
dataset after intra-post deduplication, token-level recall filtering for
semantic alignment and retrieval-augmented few-shot learning with contextual
examples during inference. Our system achieves METEOR scores ranging from 41.16
(English) to 15.21 (Marathi), securing third rank on the English leaderboard
and fourth rank for Dutch and Punjabi. The approach shows 41.3% relative
improvement in METEOR over baseline configurations and substantial gains over
existing methods. Results demonstrate effective cross-lingual generalization
for Romance and Germanic languages while maintaining semantic coherence across
diverse linguistic structures.

</details>


### [105] [Effectiveness of Chain-of-Thought in Distilling Reasoning Capability from Large Language Models](https://arxiv.org/abs/2511.05184)
*Cong-Thanh Do,Rama Doddipatla,Kate Knill*

Main category: cs.CL

TL;DR: 本文研究了思维链（CoT）在白盒知识蒸馏（KD）中，将大型语言模型（LLM）的推理能力转移到小型LLM中的作用，并证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 思维链（CoT）提示已被广泛用于提高大型语言模型的推理能力，并且最近也被应用于知识蒸馏以转移推理能力。本研究旨在深入分析CoT在白盒知识蒸馏中，如何有效地将大型LLM的推理能力传递给小型LLM。

Method: 研究采用白盒知识蒸馏实验，使用Qwen和Llama2系列的LLM。蒸馏过程利用来自CoT-Collection数据集的CoT数据。蒸馏后的模型在BIG-Bench-Hard (BBH) 基准测试中的自然语言推理和理解任务上进行评估。

Result: 实验结果表明，CoT在提高白盒知识蒸馏的有效性方面发挥了重要作用，使得蒸馏后的模型在BBH的自然语言推理和理解任务中取得了更好的平均性能。

Conclusion: CoT在提高白盒知识蒸馏的有效性方面具有关键作用，能够显著提升小型LLM在复杂推理和理解任务上的表现。

Abstract: Chain-of-Thought (CoT) prompting is a widely used method to improve the
reasoning capability of Large Language Models (LLMs). More recently, CoT has
been leveraged in Knowledge Distillation (KD) to transfer reasoning capability
from a larger LLM to a smaller one. This paper examines the role of CoT in
distilling the reasoning capability from larger LLMs to smaller LLMs using
white-box KD, analysing its effectiveness in improving the performance of the
distilled models for various natural language reasoning and understanding
tasks. We conduct white-box KD experiments using LLMs from the Qwen and Llama2
families, employing CoT data from the CoT-Collection dataset. The distilled
models are then evaluated on natural language reasoning and understanding tasks
from the BIG-Bench-Hard (BBH) benchmark, which presents complex challenges for
smaller LLMs. Experimental results demonstrate the role of CoT in improving
white-box KD effectiveness, enabling the distilled models to achieve better
average performance in natural language reasoning and understanding tasks from
BBH.

</details>


### [106] [Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese](https://arxiv.org/abs/2511.05239)
*Zilong Li,Jie Cao*

Main category: cs.CL

TL;DR: 本文将古汉语到日语的字符级翻译抽象为序列标注任务，并通过引入基于LLM的标注流程和构建新数据集来解决低资源问题。研究表明，辅助的中文NLP任务能提升序列标注性能，而LLM在直接翻译上表现良好但在字符标注上仍有不足，本文方法可作为补充。


<details>
  <summary>Details</summary>
Motivation: 古人通过在每个字符旁注释来将古汉语翻译成日语，这一过程在现代语言技术中可视为序列标注任务。然而，相关研究面临低资源问题，因此需要开发新的方法来处理这种字符级标注和翻译系统。

Method: 研究将古汉语翻译过程抽象为序列标注任务，并将其融入现代语言技术。为解决低资源问题，引入了基于大型语言模型（LLM）的标注流程，并从数字化开源翻译数据中构建了一个新的数据集。此外，通过引入辅助中文NLP任务来促进序列标注任务的训练。论文还评估了LLM在直接机器翻译和字符标注任务上的表现。

Result: 在低资源设置下，引入辅助中文NLP任务对序列标注任务的训练具有促进作用。大型语言模型在直接机器翻译中取得了高分，但在被要求进行字符标注时表现出困惑。本文提出的方法可以作为LLM的有效补充。

Conclusion: 将古汉语到日语的字符级翻译视为序列标注任务是可行的。通过LLM驱动的标注流程和辅助NLP任务，可以有效解决低资源问题。尽管LLM在直接翻译方面表现出色，但它们在精细的字符级标注上存在局限性，本文提出的方法能够弥补这一不足，并作为LLM的有效补充。

Abstract: Ancient people translated classical Chinese into Japanese by annotating
around each character. We abstract this process as sequence tagging tasks and
fit them into modern language technologies. The research of this annotation and
translation system is a facing low-resource problem. We release this problem by
introducing a LLM-based annotation pipeline and construct a new dataset from
digitalized open-source translation data. We show that under the low-resource
setting, introducing auxiliary Chinese NLP tasks has a promoting effect on the
training of sequence tagging tasks. We also evaluate the performance of large
language models. They achieve high scores in direct machine translation, but
they are confused when being asked to annotate characters. Our method could
work as a supplement of LLMs.

</details>


### [107] [Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models](https://arxiv.org/abs/2511.05286)
*Teqi Hao,Xioayu Tan,Shaojie Shi,Yinghui Xu,Xihe Qiu*

Main category: cs.CL

TL;DR: 本文提出反射个性化优化（RPO）框架，通过解耦内容生成和用户对齐来个性化黑盒大型语言模型，利用外部反射模块进行两阶段训练以重写响应。


<details>
  <summary>Details</summary>
Motivation: 现有的黑盒大型语言模型个性化方法主要依赖上下文注入，但这使得模型在生成准确内容和用户风格对齐之间面临两难，导致输出质量受损且控制受限。

Method: RPO框架将个性化过程解耦为两阶段：首先，基础模型生成高质量的通用响应；然后，外部反射模块显式地重写此响应以符合用户偏好。该反射模块通过两阶段训练：首先进行监督微调以建立核心个性化推理策略，然后应用强化学习进一步优化和提升个性化输出的质量。

Result: 在LaMP基准测试上的综合实验表明，RPO通过解耦内容生成和个性化，显著优于现有最先进的基线方法。这强调了显式响应塑造优于隐式上下文注入的优势。

Conclusion: RPO引入了一种高效、模型无关的个性化层，可以无缝集成到任何底层基础模型中，为以用户为中心的生成场景开辟了新的有效方向。

Abstract: The personalization of black-box large language models (LLMs) is a critical
yet challenging task. Existing approaches predominantly rely on context
injection, where user history is embedded into the prompt to directly guide the
generation process. However, this single-step paradigm imposes a dual burden on
the model: generating accurate content while simultaneously aligning with
user-specific styles. This often results in a trade-off that compromises output
quality and limits precise control. To address this fundamental tension, we
propose Reflective Personalization Optimization (RPO), a novel framework that
redefines the personalization paradigm by decoupling content generation from
alignment. RPO operates in two distinct stages: first, a base model generates a
high-quality, generic response; then, an external reflection module explicitly
rewrites this output to align with the user's preferences. This reflection
module is trained using a two-stage process. Initially, supervised fine-tuning
is employed on structured rewriting trajectories to establish a core
personalized reasoning policy that models the transformation from generic to
user-aligned responses. Subsequently, reinforcement learning is applied to
further refine and enhance the quality of the personalized outputs.
Comprehensive experiments on the LaMP benchmark demonstrate that RPO, by
decoupling content generation from personalization, significantly outperforms
state-of-the-art baselines. These findings underscore the superiority of
explicit response shaping over implicit context injection. Moreover, RPO
introduces an efficient, model-agnostic personalization layer that can be
seamlessly integrated with any underlying base model, paving the way for a new
and effective direction in user-centric generation scenarios.

</details>


### [108] [ManufactuBERT: Efficient Continual Pretraining for Manufacturing](https://arxiv.org/abs/2511.05135)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: 本文介绍了ManufactuBERT，一个在经过领域特定过滤和多阶段去重的大规模制造领域语料库上持续预训练的RoBERTa模型，该模型在制造相关NLP任务上取得了新的SOTA，并显著缩短了训练时间。


<details>
  <summary>Details</summary>
Motivation: 通用Transformer模型在制造等专业领域表现不佳，原因在于缺乏对领域特定术语和语义的理解。

Method: 引入了ManufactuBERT模型，该模型是一个在为制造领域精心策划的大规模语料库上持续预训练的RoBERTa模型。为此，开发了一个全面的数据处理流程，从网络数据中创建语料库，包括领域特定的初始过滤步骤和多阶段去重过程以消除冗余。

Result: ManufactuBERT在多项制造相关的NLP任务上取得了新的最先进（SOTA）性能，超越了强大的专业基线模型。更重要的是，在精心去重后的语料库上训练显著加速了收敛，与在未去重数据集上训练相比，训练时间和计算成本减少了33%。

Conclusion: ManufactuBERT是制造领域高性能编码器。所提出的数据处理流程为在其他专业领域开发高性能编码器提供了可复现的范例。数据去重对于高效训练至关重要。

Abstract: While large general-purpose Transformer-based encoders excel at general
language understanding, their performance diminishes in specialized domains
like manufacturing due to a lack of exposure to domain-specific terminology and
semantics. In this paper, we address this gap by introducing ManufactuBERT, a
RoBERTa model continually pretrained on a large-scale corpus curated for the
manufacturing domain. We present a comprehensive data processing pipeline to
create this corpus from web data, involving an initial domain-specific
filtering step followed by a multi-stage deduplication process that removes
redundancies. Our experiments show that ManufactuBERT establishes a new
state-of-the-art on a range of manufacturing-related NLP tasks, outperforming
strong specialized baselines. More importantly, we demonstrate that training on
our carefully deduplicated corpus significantly accelerates convergence,
leading to a 33\% reduction in training time and computational cost compared to
training on the non-deduplicated dataset. The proposed pipeline offers a
reproducible example for developing high-performing encoders in other
specialized domains. We will release our model and curated corpus at
https://huggingface.co/cea-list-ia.

</details>


### [109] [A Toolbox for Improving Evolutionary Prompt Search](https://arxiv.org/abs/2511.05120)
*Daniel Grießhaber,Maximilian Kimmich,Johannes Maucher,Ngoc Thang Vu*

Main category: cs.CL

TL;DR: 本文提出了一种改进的进化式提示优化方法，通过分解进化步骤、引入LLM判官、整合人工反馈和开发高效评估策略，显著提升了提示优化的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的进化式提示优化方法虽然有效，但缺乏鲁棒的操作符和高效的评估机制。

Method: 1) 将进化过程分解为不同步骤以增强控制；2) 引入基于LLM的判官来验证进化结果；3) 整合人工反馈以改进进化操作符；4) 开发更高效的评估策略，在保持性能的同时降低计算开销。

Result: 所提出的方法显著提升了提示优化的质量和效率。

Conclusion: 该研究通过提供优化的方法和开源代码，有助于在新的任务上进行提示优化，并促进该领域的进一步研究。

Abstract: Evolutionary prompt optimization has demonstrated effectiveness in refining
prompts for LLMs. However, existing approaches lack robust operators and
efficient evaluation mechanisms. In this work, we propose several key
improvements to evolutionary prompt optimization that can partially generalize
to prompt optimization in general: 1) decomposing evolution into distinct steps
to enhance the evolution and its control, 2) introducing an LLM-based judge to
verify the evolutions, 3) integrating human feedback to refine the evolutionary
operator, and 4) developing more efficient evaluation strategies that maintain
performance while reducing computational overhead. Our approach improves both
optimization quality and efficiency. We release our code, enabling prompt
optimization on new tasks and facilitating further research in this area.

</details>


### [110] [Listening Between the Lines: Decoding Podcast Narratives with Language Modeling](https://arxiv.org/abs/2511.05310)
*Shreya Gupta,Ojasva Saxena,Arghodeep Nandi,Sarah Masud,Kiran Garimella,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 播客是塑造公众舆论的关键平台，但其非结构化、对话式的特性给自动叙事框架分析带来了挑战。本文提出了一种微调的BERT模型，通过将叙事框架与具体实体和高层主题关联，解决了现有大型语言模型在此方面的不足，提供了一种更准确分析播客叙事和数字媒体影响的新方法。


<details>
  <summary>Details</summary>
Motivation: 播客在塑造公众舆论方面日益重要，是理解当代话语的关键来源。然而，其非脚本化、多主题和对话式的风格使得对叙事框架的自动化分析变得复杂，现有大型语言模型（通常在结构化文本上训练）难以捕捉人类听众识别叙事框架的细微线索，导致无法准确大规模分析播客叙事。

Method: 开发并评估了一个微调的BERT模型。该模型明确地将叙事框架与对话中提及的特定实体关联起来，从而将抽象框架具体化。然后，利用这些细粒度的框架标签，并将其与高级主题相关联，以揭示更广泛的话语趋势。

Result: 现有大型语言模型在捕捉人类听众识别叙事框架的细微线索方面表现不佳。本文提出的方法提供了一种新颖的框架标注方法，与人类对凌乱、对话式数据的判断更一致。此外，通过这种新分析，揭示了讨论内容（主题）与呈现方式（框架）之间的系统关系。

Conclusion: 本研究为数字媒体中的影响力研究提供了一个更强大的框架，通过提出一种新颖的框架标注方法，并揭示了播客中主题与叙事框架之间的系统关系，从而能够更准确地大规模分析播客叙事。

Abstract: Podcasts have become a central arena for shaping public opinion, making them
a vital source for understanding contemporary discourse. Their typically
unscripted, multi-themed, and conversational style offers a rich but complex
form of data. To analyze how podcasts persuade and inform, we must examine
their narrative structures -- specifically, the narrative frames they employ.
  The fluid and conversational nature of podcasts presents a significant
challenge for automated analysis. We show that existing large language models,
typically trained on more structured text such as news articles, struggle to
capture the subtle cues that human listeners rely on to identify narrative
frames. As a result, current approaches fall short of accurately analyzing
podcast narratives at scale.
  To solve this, we develop and evaluate a fine-tuned BERT model that
explicitly links narrative frames to specific entities mentioned in the
conversation, effectively grounding the abstract frame in concrete details. Our
approach then uses these granular frame labels and correlates them with
high-level topics to reveal broader discourse trends. The primary contributions
of this paper are: (i) a novel frame-labeling methodology that more closely
aligns with human judgment for messy, conversational data, and (ii) a new
analysis that uncovers the systematic relationship between what is being
discussed (the topic) and how it is being presented (the frame), offering a
more robust framework for studying influence in digital media.

</details>


### [111] [A multimodal multiplex of the mental lexicon for multilingual individuals](https://arxiv.org/abs/2511.05361)
*Maria Huynh,Wilder C. Rodrigues*

Main category: cs.CL

TL;DR: 本研究旨在探究多语者心理词典的结构及其多层网络模型，特别关注母语如何影响新语言习得，并通过引入视觉输入层来分析其对翻译任务表现的影响。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为双语是一种认知负担，但近三十年的研究表明，多语者在语言和认知任务中可能表现更优。因此，有必要深入理解双语/多语词汇识别系统的架构，以及语言间如何相互影响。

Method: 本研究借鉴了Stella等人（2018）关于心理词典多重模型的爆炸式学习研究，以及Dijkstra和van Heuven（2002）提出的BIA+框架。在此基础上，应用了Kivela等人（2014）引入的多层网络原理，并通过引入一个额外的层来将视觉输入与其在多语心理词典中的词汇表征联系起来，从而将多模态整合到多重模型中。实验设计将比较翻译任务中存在视觉输入与仅有文本条件下的表现。

Result: 本研究旨在探索母语如何影响另一种语言的习得。具体而言，它将探究在翻译任务中，与仅有文本条件相比，视觉输入的存在是否会影响参与者的熟练度和准确性。

Conclusion: 作为一项研究提案，本文旨在通过扩展现有多语词典模型来探索多语者心理词典的结构，特别是母语对新语言习得的影响，并评估多模态（视觉输入）在翻译任务中的作用。

Abstract: Historically, bilingualism was often perceived as an additional cognitive
load that could hinder linguistic and intellectual development. However, over
the last three decades, this view has changed considerably. Numerous studies
have aimed to model and understand the architecture of the bilingual word
recognition system Dijkstra and van Heuven (2002), investigating how parallel
activation operates in the brain and how one language influences another Kroll
et al. (2015). Increasingly, evidence suggests that multilinguals, individuals
who speak three or more languages, can perform better than monolinguals in
various linguistic and cognitive tasks, such as learning an additional language
Abu-Rabia and Sanitsky (2010). This research proposal focuses on the study of
the mental lexicon and how it may be structured in individuals who speak
multiple languages. Building on the work of Stella et al. (2018), who
investigated explosive learning in humans using a multiplex model of the mental
lexicon, and the Bilingual Interactive Activation (BIA+) framework proposed by
Dijkstra and van Heuven (2002), the present study applies the same multilayer
network principles introduced by Kivela et al. (2014). Our experimental design
extends previous research by incorporating multimodality into the multiplex
model, introducing an additional layer that connects visual inputs to their
corresponding lexical representations across the multilingual layers of the
mental lexicon. In this research, we aim to explore how a heritage language
influences the acquisition of another language. Specifically, we ask: Does the
presence of visual input in a translation task influence participants'
proficiency and accuracy compared to text-only conditions?

</details>


### [112] [Evaluating Subword Tokenization Techniques for Bengali: A Benchmark Study with BengaliBPE](https://arxiv.org/abs/2511.05324)
*Firoj Ahmmed Patwary,Abdullah Al Noman*

Main category: cs.CL

TL;DR: 本文提出BengaliBPE，一种专为孟加拉语设计的字节对编码（BPE）分词器，通过引入语言学感知规则，解决了现有分词器在形态丰富语言上的不足，并提升了下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有子词分词器（如SentencePiece或HuggingFace BPE）主要针对拉丁语系或多语言语料库设计，在孟加拉语等形态丰富的语言上表现不佳，无法有效学习和表示语言信息。

Method: 研究者开发了BengaliBPE，它结合了Unicode标准化、字素级初始化和形态感知的合并规则，以保持语言一致性和子词完整性。他们在一个大型孟加拉语新闻分类数据集上，将BengaliBPE与Whitespace、SentencePiece BPE和HuggingFace BPE三种基线方法进行比较，评估了分词粒度、编码速度和下游分类准确性。

Result: 尽管所有方法都表现尚可，但BengaliBPE提供了最详细的分词和最佳的形态可解释性，尽管计算成本略高。这些发现强调了语言感知分词对于形态丰富文字的重要性。

Conclusion: 语言感知分词对于形态丰富的文字至关重要。BengaliBPE为未来的孟加拉语自然语言处理系统（包括大规模预训练上下文语言模型）奠定了坚实基础。

Abstract: Tokenization is an important first step in Natural Language Processing (NLP)
pipelines because it decides how models learn and represent linguistic
information. However, current subword tokenizers like SentencePiece or
HuggingFace BPE are mostly designed for Latin or multilingual corpora and do
not perform well on languages with rich morphology such as Bengali. To address
this limitation, we present BengaliBPE, a Byte Pair Encoding (BPE) tokenizer
specifically developed for the Bengali script. BengaliBPE applies Unicode
normalization, grapheme-level initialization, and morphology-aware merge rules
to maintain linguistic consistency and preserve subword integrity. We use a
large-scale Bengali news classification dataset to compare BengaliBPE with
three baselines: Whitespace, SentencePiece BPE, and HuggingFace BPE. The
evaluation considers tokenization granularity, encoding speed, and downstream
classification accuracy. While all methods perform reasonably well, BengaliBPE
provides the most detailed segmentation and the best morphological
interpretability, albeit with slightly higher computational cost. These
findings highlight the importance of language-aware tokenization for
morphologically rich scripts and establish BengaliBPE as a strong foundation
for future Bengali NLP systems, including large-scale pretraining of contextual
language models.

</details>


### [113] [On Text Simplification Metrics and General-Purpose LLMs for Accessible Health Information, and A Potential Architectural Advantage of The Instruction-Tuned LLM class](https://arxiv.org/abs/2511.05080)
*P. Bilha Githinji,Aikaterini Meilliou,Peiwu Qin*

Main category: cs.CL

TL;DR: 本报告评估了两种主流LLM（Mistral 24B和QWen2.5 32B）在文本简化任务中的表现，发现指令调优的Mistral在优化可读性和保持语篇忠实度之间取得了更好的平衡，并探讨了度量指标和词汇支持的问题。


<details>
  <summary>Details</summary>
Motivation: 公众日益增长的健康信息需求和对生物医学信息的数字化消费，要求可扩展的解决方案能自动将复杂的科学技术文档转化为通俗语言。然而，包括高级大型语言模型在内的自动文本简化方案，在优化可读性性能和确保语篇忠实度之间，仍难以可靠地平衡。

Method: 本研究实证评估了两种主要通用LLM（指令调优的Mistral 24B和推理增强的QWen2.5 32B）的性能，并与人工基准进行了比较分析。使用了SARI和BERTScore等指标，并对涵盖可读性、语篇忠实度、内容安全性和潜在分布测量的21个指标进行了全面的相关性分析。

Result: 指令调优的Mistral 24B在架构上显示出潜在优势，其词汇简化策略温和，在多项可读性指标和简化专用公式SARI（平均42.46）上表现出色，同时以0.91的BERTScore保持了人类水平的语篇忠实度。QWen也提高了可读性，但在平衡可读性和准确性方面存在脱节，BERTScore显著低于0.89。此外，21个指标的相关性分析证实了五个可读性指数之间存在强大的功能冗余。

Conclusion: 本研究为不断发展的LLM在文本简化任务中的基线性能提供了经验证据，识别出指令调优的Mistral 24B适用于简化任务，为指标选择提供了必要的启发式方法，并指出词汇支持是简化的主要领域适应问题。

Abstract: The increasing health-seeking behavior and digital consumption of biomedical
information by the general public necessitate scalable solutions for
automatically adapting complex scientific and technical documents into plain
language. Automatic text simplification solutions, including advanced large
language models, however, continue to face challenges in reliably arbitrating
the tension between optimizing readability performance and ensuring
preservation of discourse fidelity. This report empirically assesses the
performance of two major classes of general-purpose LLMs, demonstrating their
linguistic capabilities and foundational readiness for the task compared to a
human benchmark. Using a comparative analysis of the instruction-tuned Mistral
24B and the reasoning-augmented QWen2.5 32B, we identify a potential
architectural advantage in the instruction-tuned LLM. Mistral exhibits a
tempered lexical simplification strategy that enhances readability across a
suite of metrics and the simplification-specific formula SARI (mean 42.46),
while preserving human-level discourse with a BERTScore of 0.91. QWen also
attains enhanced readability performance, but its operational strategy shows a
disconnect in balancing between readability and accuracy, reaching a
statistically significantly lower BERTScore of 0.89. Additionally, a
comprehensive correlation analysis of 21 metrics spanning readability,
discourse fidelity, content safety, and underlying distributional measures for
mechanistic insights, confirms strong functional redundancies among five
readability indices. This empirical evidence tracks baseline performance of the
evolving LLMs for the task of text simplification, identifies the
instruction-tuned Mistral 24B for simplification, provides necessary heuristics
for metric selection, and points to lexical support as a primary
domain-adaptation issue for simplification.

</details>


### [114] [What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions](https://arxiv.org/abs/2511.05320)
*Klára Bendová,Tomáš Knap,Jan Černý,Vojtěch Pour,Jaromir Savelka,Ivana Kvapilíková,Jakub Drápal*

Main category: cs.CL

TL;DR: 本研究探讨了从斯洛伐克法院判决书中提取犯罪行为描述的可行性，发现高级正则表达式和大型语言模型（LLMs）在准确性上远超基线方法，并能与人类标注高度匹配。


<details>
  <summary>Details</summary>
Motivation: 刑事司法行政数据对犯罪行为的描述有限，而欧洲大陆法院判决书中的有罪判决部分包含大量未被利用的犯罪行为详细描述，这些信息对于深入研究具有重要价值。

Method: 研究采用了三种方法来提取犯罪行为描述：1) 基线方法，使用简单正则表达式识别描述前后典型词汇；2) 高级正则表达式方法，进一步关注“sparing”及其标准化处理（字母间插入空格，常用于描述界定）；3) LLM方法，使用预定义指令提示Gemini Flash 2.0模型进行提取。此外，还评估了两种高级方法的组合效果。法律系学生对提取结果与人类标注的匹配度进行了评估。

Result: 基线方法仅在40.5%的判决书中识别出描述。高级正则表达式方法达到97%的识别率，LLMs达到98.75%，两者结合后更是达到99.5%。与人类标注的匹配度方面，基线方法仅为34.5%，而高级正则表达式方法和LLMs均达到约90%。具体而言，LLMs完全匹配人类标注的比例为91.75%，高级正则表达式与LLMs的组合达到92%。

Conclusion: 从公开的斯洛伐克法院判决书中提取犯罪行为描述是可行的。高级正则表达式和大型语言模型（特别是LLMs及其与高级正则表达式的结合）在准确性和与人类标注的匹配度方面表现出色，远超简单基线方法，为刑事司法领域的数据挖掘提供了高效工具。

Abstract: Criminal justice administrative data contain only a limited amount of
information about the committed offense. However, there is an unused source of
extensive information in continental European courts' decisions: descriptions
of criminal behaviors in verdicts by which offenders are found guilty. In this
paper, we study the feasibility of extracting these descriptions from publicly
available court decisions from Slovakia. We use two different approaches for
retrieval: regular expressions and large language models (LLMs). Our baseline
was a simple method employing regular expressions to identify typical words
occurring before and after the description. The advanced regular expression
approach further focused on "sparing" and its normalization (insertion of
spaces between individual letters), typical for delineating the description.
The LLM approach involved prompting the Gemini Flash 2.0 model to extract the
descriptions using predefined instructions. Although the baseline identified
descriptions in only 40.5% of verdicts, both methods significantly outperformed
it, achieving 97% with advanced regular expressions and 98.75% with LLMs, and
99.5% when combined. Evaluation by law students showed that both advanced
methods matched human annotations in about 90% of cases, compared to just 34.5%
for the baseline. LLMs fully matched human-labeled descriptions in 91.75% of
instances, and a combination of advanced regular expressions with LLMs reached
92%.

</details>


### [115] [Large Language Models for Explainable Threat Intelligence](https://arxiv.org/abs/2511.05406)
*Tiago Dinis,Miguel Correia,Roger Tavares*

Main category: cs.CL

TL;DR: 该论文提出RAGRecon系统，结合大型语言模型（LLM）和检索增强生成（RAG）技术，用于网络威胁情报获取，并通过生成知识图谱提高AI的可解释性。实验结果显示其准确性超过91%。


<details>
  <summary>Details</summary>
Motivation: 网络威胁日益复杂，传统安全机制难以应对。大型语言模型在文本处理和生成方面的先进能力，使其在网络安全领域具有巨大潜力。

Method: 所提出的RAGRecon系统利用LLM与RAG相结合，通过实时信息检索和领域特定数据回答网络安全威胁问题。此外，它通过为每个回复生成并可视化呈现知识图谱，提高了人工智能的透明度和可解释性，帮助分析师理解模型推理。

Result: RAGRecon系统在两个数据集和七个不同LLM上进行了实验评估。最佳组合的响应与参考响应的匹配度超过91%。

Conclusion: RAGRecon系统有效利用LLM和RAG获取网络威胁情报，并通过知识图谱实现了高水平的可解释性，提高了模型推理的透明度，有助于分析师理解系统决策。

Abstract: As cyber threats continue to grow in complexity, traditional security
mechanisms struggle to keep up. Large language models (LLMs) offer significant
potential in cybersecurity due to their advanced capabilities in text
processing and generation. This paper explores the use of LLMs with
retrieval-augmented generation (RAG) to obtain threat intelligence by combining
real-time information retrieval with domain-specific data. The proposed system,
RAGRecon, uses a LLM with RAG to answer questions about cybersecurity threats.
Moreover, it makes this form of Artificial Intelligence (AI) explainable by
generating and visually presenting to the user a knowledge graph for every
reply. This increases the transparency and interpretability of the reasoning of
the model, allowing analysts to better understand the connections made by the
system based on the context recovered by the RAG system. We evaluated RAGRecon
experimentally with two datasets and seven different LLMs and the responses
matched the reference responses more than 91% of the time for the best
combinations.

</details>


### [116] [MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis](https://arxiv.org/abs/2511.05485)
*Yuexin Wu,Shiqi Wang,Vasile Rus*

Main category: cs.CL

TL;DR: 该研究引入了MIMIC-SR-ICD11数据集和LL-Rank重排序框架，以利用EHR出院记录进行疾病诊断，并解决了传统EHR信息丢失和标签频率偏差问题，显著提高了诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 现代医疗中疾病诊断至关重要，但模板化的电子健康记录（EHR）常会削弱或遗漏关键的临床信号，特别是细微但重要的细节。研究旨在通过利用更丰富的临床报告信息来改进诊断。

Method: 1. 构建了MIMIC-SR-ICD11数据集：一个大型英文诊断数据集，基于EHR出院记录并与WHO ICD-11术语对齐。2. 提出了LL-Rank：一个基于似然的重排序框架，它计算给定临床报告上下文的每个标签的长度归一化联合似然，并减去该标签对应的无报告先验似然，以基于PMI（点互信息）进行评分。

Result: LL-Rank在七种模型骨干上均持续优于强大的生成-映射基线（GenMap）。消融实验表明，LL-Rank的性能提升主要源于其基于PMI的评分机制，该机制能够将语义兼容性与标签频率偏差分离。

Conclusion: 通过引入新的数据集和LL-Rank重排序框架，该研究成功地利用临床报告上下文提高了疾病诊断的准确性，并且LL-Rank的PMI评分机制在解决标签频率偏差方面表现出色，为更精确的诊断提供了有效工具。

Abstract: Disease diagnosis is a central pillar of modern healthcare, enabling early
detection and timely intervention for acute conditions while guiding lifestyle
adjustments and medication regimens to prevent or slow chronic disease.
Self-reports preserve clinically salient signals that templated electronic
health record (EHR) documentation often attenuates or omits, especially subtle
but consequential details. To operationalize this shift, we introduce
MIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge
notes and natively aligned to WHO ICD-11 terminology. We further present
LL-Rank, a likelihood-based re-ranking framework that computes a
length-normalized joint likelihood of each label given the clinical report
context and subtracts the corresponding report-free prior likelihood for that
label. Across seven model backbones, LL-Rank consistently outperforms a strong
generation-plus-mapping baseline (GenMap). Ablation experiments show that
LL-Rank's gains primarily stem from its PMI-based scoring, which isolates
semantic compatibility from label frequency bias.

</details>


### [117] [Minority-Aware Satisfaction Estimation in Dialogue Systems via Preference-Adaptive Reinforcement Learning](https://arxiv.org/abs/2511.05407)
*Yahui Fu,Zi Haur Pang,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 本研究提出一个统一框架，通过建模个体和群体偏好来估计对话系统中的用户满意度，特别关注少数用户群体的需求，并利用个性化推理链、无监督聚类和偏好自适应强化学习实现。


<details>
  <summary>Details</summary>
Motivation: 对话系统中用户满意度具有主观性，现有方法通常训练“一刀切”模型，忽略了少数用户群体的独特意图和偏好，导致其满意度评分与多数用户不同，未能实现用户特定适应。

Method: 1. 引入Chain-of-Personalized-Reasoning (CoPeR) 来通过可解释的推理链捕获个体偏好。 2. 提出基于期望最大化的Majority-Minority Preference-Aware Clustering (M2PC) 算法，以无监督方式发现不同的用户群体，学习群体级偏好。 3. 将这些组件整合到偏好自适应强化学习框架 (PAda-PPO) 中，共同优化与个体和群体偏好的对齐。

Result: 在情感支持对话数据集上的实验表明，用户满意度估计得到持续改进，特别是对于代表性不足的用户群体。

Conclusion: 该统一框架通过同时建模个体和群体偏好，有效提高了对话系统中用户满意度的估计，尤其改善了对少数用户群体的服务，解决了“一刀切”模型的局限性。

Abstract: User satisfaction in dialogue systems is inherently subjective. When the same
response strategy is applied across users, minority users may assign different
satisfaction ratings than majority users due to variations in individual
intents and preferences. However, existing alignment methods typically train
one-size-fits-all models that aim for broad consensus, often overlooking
minority perspectives and user-specific adaptation. We propose a unified
framework that models both individual- and group-level preferences for user
satisfaction estimation. First, we introduce Chain-of-Personalized-Reasoning
(CoPeR) to capture individual preferences through interpretable reasoning
chains. Second, we propose an expectation-maximization-based Majority-Minority
Preference-Aware Clustering (M2PC) algorithm that discovers distinct user
groups in an unsupervised manner to learn group-level preferences. Finally, we
integrate these components into a preference-adaptive reinforcement learning
framework (PAda-PPO) that jointly optimizes alignment with both individual and
group preferences. Experiments on the Emotional Support Conversation dataset
demonstrate consistent improvements in user satisfaction estimation,
particularly for underrepresented user groups.

</details>


### [118] [Steering Language Models with Weight Arithmetic](https://arxiv.org/abs/2511.05408)
*Constanza Fierro,Fabien Roger*

Main category: cs.CL

TL;DR: 本文提出对比权重转向（contrastive weight steering），一种简单的后训练方法，通过权重算术编辑LLM参数，以更好地利用窄分布训练数据，控制特定行为。该方法在泛化能力上优于激活转向，并能部分缓解微调过程中不期望的行为漂移，同时初步显示出检测潜在未对齐行为的能力。


<details>
  <summary>Details</summary>
Motivation: 为大型语言模型（LLMs）提供高质量、多样化的反馈既困难又昂贵，而仅在狭窄分布上提供反馈可能导致意外的泛化。因此，需要一种方法来更好地利用狭窄的训练数据，并在模型训练后有效控制或修改特定行为。

Method: 提出对比权重转向方法。通过对模型进行两次小规模微调（一次诱导期望行为，另一次诱导其反向行为），然后减去两次微调产生的权重增量，从而在权重空间中分离出特定行为方向。最后，通过添加或移除这个方向来修改模型的权重。

Result: 1. 权重转向在缓解谄媚行为和诱导未对齐方面，泛化能力通常优于激活转向，在不损害通用能力的前提下实现更强的域外行为控制。
2. 在特定任务微调中，权重转向能部分缓解不期望的行为漂移（如减少微调引入的谄媚和拒绝不足），同时保持任务性能提升。
3. 初步证据表明，通过测量微调更新与一个“邪恶”权重方向的相似性，可以检测到紧急未对齐行为，这为在训练期间监控权重演变和检测罕见未对齐行为提供了可能性。

Conclusion: 对比权重转向是一种有效的后训练方法，能够利用有限数据在LLMs中实现对特定行为的精确控制，其泛化能力优于激活转向，并能有效缓解微调过程中的负面行为漂移。此外，该方法还为检测潜在的、训练中未显现的未对齐行为提供了新的视角。

Abstract: Providing high-quality feedback to Large Language Models (LLMs) on a diverse
training distribution can be difficult and expensive, and providing feedback
only on a narrow distribution can result in unintended generalizations. To
better leverage narrow training data, we propose contrastive weight steering, a
simple post-training method that edits the model parameters using weight
arithmetic. We isolate a behavior direction in weight-space by subtracting the
weight deltas from two small fine-tunes -- one that induces the desired
behavior and another that induces its opposite -- and then add or remove this
direction to modify the model's weights. We apply this technique to mitigate
sycophancy and induce misalignment, and find that weight steering often
generalizes further than activation steering, achieving stronger
out-of-distribution behavioral control before degrading general capabilities.
We also show that, in the context of task-specific fine-tuning, weight steering
can partially mitigate undesired behavioral drift: it can reduce sycophancy and
under-refusals introduced during fine-tuning while preserving task performance
gains. Finally, we provide preliminary evidence that emergent misalignment can
be detected by measuring the similarity between fine-tuning updates and an
"evil" weight direction, suggesting that it may be possible to monitor the
evolution of weights during training and detect rare misaligned behaviors that
never manifest during training or evaluations.

</details>


### [119] [Mind the Gap... or Not? How Translation Errors and Evaluation Details Skew Multilingual Results](https://arxiv.org/abs/2511.05162)
*Jan-Thorsten Peter,David Vilar,Tobias Domhan,Dan Malkin,Markus Freitag*

Main category: cs.CL

TL;DR: 本文发现大型语言模型在多语言数学基准测试中表现出的跨语言性能差距，主要是由于基准数据集中的翻译错误和答案提取方法不标准造成的。通过纠正这些问题，发现该差距基本消失。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型支持多种语言和领域，但作者观察到模型在不同语言间存在性能差距，尤其是在数学领域。他们怀疑现有基准测试可能存在问题，并希望深入探究这种跨语言能力的泛化性。

Method: 研究分析了标准多语言数学基准测试(MGSM)，发现数据中存在翻译错误，并指出LLM输出的答案提取缺乏标准化。为此，他们提出了一种自动质量保证方法来解决数据错误，并给出了标准化答案提取的建议。此外，他们还发布了修正后的数据集。

Result: 实验结果显示，最初观察到的模型在不同语言（包括高资源和低资源语言）之间存在的显著且一致的性能差距，在应用自动质量保证方法并标准化答案提取后，基本消失了。这导致与之前研究完全不同的结论。

Conclusion: 研究表明，大型语言模型在多语言数学基准测试中表现出的跨语言性能差距，很大程度上是由于基准数据集的翻译错误和不标准的答案提取方法造成的。纠正这些问题后，模型在不同语言间的性能差距几乎消失，这暗示了LLM可能具有比预期更好的跨语言能力泛化性。作者发布了修正后的数据集，以促进未来的研究。

Abstract: Most current large language models (LLMs) support a wide variety of languages
in addition to English, including high-resource languages (e.g. German,
Chinese, French), as well as low-resource ones (e.g. Swahili, Telugu). In
addition they have also shown impressive capabilities in different domains,
like coding, science and math. In this short paper, taking math as an example
domain, we study the performance of different LLMs across languages.
Experimental results show that there exists a non-negligible and consistent gap
in the performance of the models across languages. Interestingly, and somewhat
against expectations, the gap exists for both high- and low-resource languages.
We hope that these results influence further research into cross-lingual
capability generalization for next generation LLMs. If it weren't for the fact
that they are false! By analyzing one of the standard multilingual math
benchmarks (MGSM), we determine that several translation errors are present in
the data. Furthermore, the lack of standardized answer extraction from LLM
outputs further influences the final results. We propose a method for automatic
quality assurance to address the first issue at scale, and give recommendations
to address the second one. Combining these two approaches we show that the
aforementioned language gap mostly disappears, leading to completely different
conclusions from our research. We additionally release the corrected dataset to
the community.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [120] [Pixi: Unified Software Development and Distribution for Robotics and AI](https://arxiv.org/abs/2511.04827)
*Tobias Fischer,Wolf Vollprecht,Bas Zalmstra,Ruben Arts,Tim de Jager,Alejandro Fontan,Adam D Hines,Michael Milford,Silvio Traversaro,Daniel Claes,Scarlett Raine*

Main category: cs.RO

TL;DR: Pixi是一个统一的包管理框架，通过捕获精确的依赖状态，解决了机器人和AI研究中软件环境的不可复现性问题，显著提高了依赖解析速度并降低了技术门槛。


<details>
  <summary>Details</summary>
Motivation: 机器人研究面临着科学计算中的可复现性危机，多达70%的算法无法被独立团队复现，且许多算法因创建可共享软件环境过于复杂而未能部署。这些问题源于碎片化、多语言、软硬件混合的工具链导致的“依赖地狱”。

Method: 本文提出了Pixi，一个统一的包管理框架。它通过在项目级锁定文件中捕获精确的依赖状态，确保跨平台的位对位复现性。Pixi采用高性能SAT求解器，并集成了conda-forge和PyPI生态系统，从而无需使用多个管理器。

Result: Pixi实现了位对位复现性，其高性能SAT求解器使依赖解析速度比同类工具快10倍。自2023年以来，Pixi已被超过5300个项目采用，将设置时间从数小时缩短至数分钟，并降低了全球研究人员的技术障碍。

Conclusion: 通过提供可扩展、可复现、协作式的研究基础设施，Pixi加速了机器人和AI领域的进展。

Abstract: The reproducibility crisis in scientific computing constrains robotics
research. Existing studies reveal that up to 70% of robotics algorithms cannot
be reproduced by independent teams, while many others fail to reach deployment
because creating shareable software environments remains prohibitively complex.
These challenges stem from fragmented, multi-language, and hardware-software
toolchains that lead to dependency hell. We present Pixi, a unified
package-management framework that addresses these issues by capturing exact
dependency states in project-level lockfiles, ensuring bit-for-bit
reproducibility across platforms. Its high-performance SAT solver achieves up
to 10x faster dependency resolution than comparable tools, while integration of
the conda-forge and PyPI ecosystems removes the need for multiple managers.
Adopted in over 5,300 projects since 2023, Pixi reduces setup times from hours
to minutes and lowers technical barriers for researchers worldwide. By enabling
scalable, reproducible, collaborative research infrastructure, Pixi accelerates
progress in robotics and AI.

</details>


### [121] [Unified Multimodal Diffusion Forcing for Forceful Manipulation](https://arxiv.org/abs/2511.04812)
*Zixuan Huang,Huaidian Hou,Dmitry Berenson*

Main category: cs.RO

TL;DR: 本文提出了一种名为多模态扩散强制 (MDF) 的统一框架，通过对机器人轨迹进行随机部分掩码并使用扩散模型进行重建，学习跨模态和时间依赖性，从而超越传统的模仿学习，实现多功能性、高性能和对噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标准的模仿学习方法通常只学习从观测到动作的直接映射，忽略了感觉输入、动作和奖励之间丰富的多模态交互，而这些交互对于建模机器人行为和理解任务结果至关重要。

Method: 本文提出了多模态扩散强制 (MDF) 框架。它不建模固定的分布，而是对多模态机器人轨迹应用随机部分掩码，并训练一个扩散模型来重建整个轨迹。这种训练目标鼓励模型学习时间依赖性和跨模态依赖性，例如预测动作对力信号的影响或从部分观测推断状态。

Result: MDF 在模拟和真实世界的接触密集型、强力操纵任务中进行了评估。结果表明，MDF 不仅提供了多功能性，而且实现了强大的性能，并在噪声观测下表现出鲁棒性。

Conclusion: MDF 是一个统一的框架，能够从多模态机器人轨迹中学习，通过重建掩码轨迹来捕捉复杂的跨模态和时间依赖性，从而在具有挑战性的机器人任务中实现多功能性、高性能和对噪声的鲁棒性。

Abstract: Given a dataset of expert trajectories, standard imitation learning
approaches typically learn a direct mapping from observations (e.g., RGB
images) to actions. However, such methods often overlook the rich interplay
between different modalities, i.e., sensory inputs, actions, and rewards, which
is crucial for modeling robot behavior and understanding task outcomes. In this
work, we propose Multimodal Diffusion Forcing, a unified framework for learning
from multimodal robot trajectories that extends beyond action generation.
Rather than modeling a fixed distribution, MDF applies random partial masking
and trains a diffusion model to reconstruct the trajectory. This training
objective encourages the model to learn temporal and cross-modal dependencies,
such as predicting the effects of actions on force signals or inferring states
from partial observations. We evaluate MDF on contact-rich, forceful
manipulation tasks in simulated and real-world environments. Our results show
that MDF not only delivers versatile functionalities, but also achieves strong
performance, and robustness under noisy observations. More visualizations can
be found on our website https://unified-df.github.io

</details>


### [122] [ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling](https://arxiv.org/abs/2511.04758)
*Caelan Garrett,Fabio Ramos*

Main category: cs.RO

TL;DR: ScheduleStream是一个通用的采样操作规划与调度框架，它解决了多臂机器人控制中并行运动的计算挑战，通过混合持续动作和GPU加速，生成更高效的并行任务计划。


<details>
  <summary>Details</summary>
Motivation: 双臂和人形机器人因其多臂协作能力而备受关注，但控制多个机械臂面临混合离散-连续动作空间增长带来的计算挑战。现有的任务与运动规划（TAMP）算法通常生成单臂顺序移动的计划，而非允许并行臂运动的调度。

Method: 本文提出了ScheduleStream，首个用于采样操作的通用规划与调度框架。它使用混合持续动作建模时间动态，这些动作可以异步启动并持续一段时间。该框架提出了领域无关的算法来解决ScheduleStream问题，并将其应用于任务与运动规划与调度（TAMPAS），其中利用GPU加速来加速规划过程中的采样器。

Result: 在模拟中，ScheduleStream算法与多个消融实验相比，能够生成更高效的解决方案。研究还在几个真实世界的双臂机器人任务中展示了ScheduleStream的有效性。

Conclusion: ScheduleStream是一个通用的框架，能够为多臂机器人生成允许并行臂运动的规划与调度，有效解决了传统TAMP算法的局限性，并通过领域无关算法和GPU加速提高了效率。

Abstract: Bimanual and humanoid robots are appealing because of their human-like
ability to leverage multiple arms to efficiently complete tasks. However,
controlling multiple arms at once is computationally challenging due to the
growth in the hybrid discrete-continuous action space. Task and Motion Planning
(TAMP) algorithms can efficiently plan in hybrid spaces but generally produce
plans, where only one arm is moving at a time, rather than schedules that allow
for parallel arm motion. In order to extend TAMP to produce schedules, we
present ScheduleStream, the first general-purpose framework for planning &
scheduling with sampling operations. ScheduleStream models temporal dynamics
using hybrid durative actions, which can be started asynchronously and persist
for a duration that's a function of their parameters. We propose
domain-independent algorithms that solve ScheduleStream problems without any
application-specific mechanisms. We apply ScheduleStream to Task and Motion
Planning & Scheduling (TAMPAS), where we use GPU acceleration within samplers
to expedite planning. We compare ScheduleStream algorithms to several ablations
in simulation and find that they produce more efficient solutions. We
demonstrate ScheduleStream on several real-world bimanual robot tasks at
https://schedulestream.github.io.

</details>


### [123] [ReGen: Generative Robot Simulation via Inverse Design](https://arxiv.org/abs/2511.04769)
*Phat Nguyen,Tsun-Hsuan Wang,Zhang-Wei Hong,Erfan Aasi,Andrew Silva,Guy Rosman,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: 本文介绍ReGen，一个通过逆向设计自动化模拟场景生成的框架。它利用大型语言模型（LLM）从机器人行为和文本描述中推断出合理的场景和环境，从而实现更高效、多样化的机器人学习模拟。


<details>
  <summary>Details</summary>
Motivation: 构建机器人模拟是一个劳动密集型过程，这限制了机器人学习的规模化和策略验证的效率。

Method: ReGen是一个生成式模拟框架，通过逆向设计自动化模拟场景。给定机器人的行为（如运动轨迹或目标函数）及其文本描述，ReGen利用大型语言模型（LLM）通过扩展编码因果关系、相关实体及其属性的有向图来合成场景。这个结构化的图随后被转换为符号程序，用于配置和执行机器人模拟环境。该框架支持基于自我智能体行为的模拟增强、可控的反事实场景生成、智能体认知和心理状态推理，以及不同传感模态的推理。

Result: ReGen在自动驾驶和机器人操作任务中得到了验证。与现有模拟相比，它能生成更多样化、更复杂的模拟环境，并具有高成功率，同时能够为极端情况实现可控生成。

Conclusion: ReGen增强了机器人策略的验证，支持数据或模拟增强，并推动了可扩展机器人学习，以提高泛化能力和鲁棒性。

Abstract: Simulation plays a key role in scaling robot learning and validating
policies, but constructing simulations remains a labor-intensive process. This
paper introduces ReGen, a generative simulation framework that automates
simulation design via inverse design. Given a robot's behavior -- such as a
motion trajectory or an objective function -- and its textual description,
ReGen infers plausible scenarios and environments that could have caused the
behavior. ReGen leverages large language models to synthesize scenarios by
expanding a directed graph that encodes cause-and-effect relationships,
relevant entities, and their properties. This structured graph is then
translated into a symbolic program, which configures and executes a robot
simulation environment. Our framework supports (i) augmenting simulations based
on ego-agent behaviors, (ii) controllable, counterfactual scenario generation,
(iii) reasoning about agent cognition and mental states, and (iv) reasoning
with distinct sensing modalities, such as braking due to faulty GPS signals. We
demonstrate ReGen in autonomous driving and robot manipulation tasks,
generating more diverse, complex simulated environments compared to existing
simulations with high success rates, and enabling controllable generation for
corner cases. This approach enhances the validation of robot policies and
supports data or simulation augmentation, advancing scalable robot learning for
improved generalization and robustness. We provide code and example videos at:
https://regen-sim.github.io/

</details>


### [124] [Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning](https://arxiv.org/abs/2511.04831)
*NVIDIA,:,Mayank Mittal,Pascal Roth,James Tigue,Antoine Richard,Octi Zhang,Peter Du,Antonio Serrano-Muñoz,Xinjie Yao,René Zurbrügg,Nikita Rudin,Lukasz Wawrzyniak,Milad Rakhsha,Alain Denzler,Eric Heiden,Ales Borovicka,Ossama Ahmed,Iretiayo Akinola,Abrar Anwar,Mark T. Carlson,Ji Yuan Feng,Animesh Garg,Renato Gasoto,Lionel Gulich,Yijie Guo,M. Gussert,Alex Hansen,Mihir Kulkarni,Chenran Li,Wei Liu,Viktor Makoviychuk,Grzegorz Malczyk,Hammad Mazhar,Masoud Moghani,Adithyavairavan Murali,Michael Noseworthy,Alexander Poddubny,Nathan Ratliff,Welf Rehberg,Clemens Schwarke,Ritvik Singh,James Latham Smith,Bingjie Tang,Ruchik Thaker,Matthew Trepte,Karl Van Wyk,Fangzhou Yu,Alex Millane,Vikram Ramasamy,Remo Steiner,Sangeeta Subramanian,Clemens Volk,CY Chen,Neel Jawale,Ashwin Varghese Kuruttukulam,Michael A. Lin,Ajay Mandlekar,Karsten Patzwaldt,John Welsh,Huihua Zhao,Fatima Anes,Jean-Francois Lafleche,Nicolas Moënne-Loccoz,Soowan Park,Rob Stepinski,Dirk Van Gelder,Chris Amevor,Jan Carius,Jumyung Chang,Anka He Chen,Pablo de Heras Ciechomski,Gilles Daviet,Mohammad Mohajerani,Julia von Muralt,Viktor Reutskyy,Michael Sauter,Simon Schirm,Eric L. Shi,Pierre Terdiman,Kenny Vilella,Tobias Widmer,Gordon Yeoman,Tiffany Chen,Sergey Grizan,Cathy Li,Lotus Li,Connor Smith,Rafael Wiltz,Kostas Alexis,Yan Chang,David Chu,Linxi "Jim" Fan,Farbod Farshidian,Ankur Handa,Spencer Huang,Marco Hutter,Yashraj Narang,Soha Pouya,Shiwei Sheng,Yuke Zhu,Miles Macklin,Adam Moravanszky,Philipp Reist,Yunrong Guo,David Hoeller,Gavriel State*

Main category: cs.RO

TL;DR: Isaac Lab是Isaac Gym的继任者，一个GPU原生的机器人仿真平台，专为大规模多模态学习设计，整合了高保真物理、逼真渲染、多传感器模拟和数据工具，旨在推动机器人研究突破。


<details>
  <summary>Details</summary>
Motivation: 将GPU原生的机器人仿真范式扩展到大规模多模态学习时代，统一强化学习和模仿学习的最佳实践，并提供一个可扩展的平台来解决复杂的机器人挑战。

Method: Isaac Lab结合了GPU并行物理模拟、逼真渲染、模块化可组合架构，并集成了执行器模型、多频传感器模拟、数据收集管道和域随机化工具。未来还将与可微分、GPU加速的Newton物理引擎集成。

Result: 该平台已应用于全身控制、跨形态移动、接触丰富和灵巧操作，以及整合人类演示进行技能学习等多种挑战。其先进的模拟能力、丰富的传感和数据中心规模的执行将为机器人学习带来新的机遇。

Conclusion: Isaac Lab凭借其先进的模拟能力、丰富的传感和数据中心规模的执行，有望解锁机器人研究领域的下一代突破，特别是在可扩展、数据高效和基于梯度的机器人学习方法方面。

Abstract: We present Isaac Lab, the natural successor to Isaac Gym, which extends the
paradigm of GPU-native robotics simulation into the era of large-scale
multi-modal learning. Isaac Lab combines high-fidelity GPU parallel physics,
photorealistic rendering, and a modular, composable architecture for designing
environments and training robot policies. Beyond physics and rendering, the
framework integrates actuator models, multi-frequency sensor simulation, data
collection pipelines, and domain randomization tools, unifying best practices
for reinforcement and imitation learning at scale within a single extensible
platform. We highlight its application to a diverse set of challenges,
including whole-body control, cross-embodiment mobility, contact-rich and
dexterous manipulation, and the integration of human demonstrations for skill
acquisition. Finally, we discuss upcoming integration with the differentiable,
GPU-accelerated Newton physics engine, which promises new opportunities for
scalable, data-efficient, and gradient-based approaches to robot learning. We
believe Isaac Lab's combination of advanced simulation capabilities, rich
sensing, and data-center scale execution will help unlock the next generation
of breakthroughs in robotics research.

</details>


### [125] [Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning](https://arxiv.org/abs/2511.04835)
*Shubham Natraj,Bruno Sinopoli,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 本文提出一种新颖的非均匀采样策略，通过共形预测生成“认证”区域，并偏向这些区域进行采样，以提高基于采样的运动规划器（SBMPs）的效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于采样的运动规划器（SBMPs）依赖均匀采样，导致在复杂环境中效率低下且规划速度慢。

Method: 该方法通过以下步骤集成到现有SBMPs中：(i) 使用启发式路径预测器（如A*或视觉-语言模型）生成初始路径（可能不可行）；(ii) 应用共形预测量化预测器的不确定性。这会生成围绕初始猜测路径的预测集，这些预测集以用户指定概率保证包含最优解。然后，SBMPs偏向这些“认证”区域进行采样。

Result: 广泛评估表明，该方法比现有基线能更快地找到可行路径，并对未知环境表现出更好的泛化能力。

Conclusion: 本研究首次为SBMPs提供了一种具有采样区域概率正确性保证的非均匀采样方法，显著提高了规划效率和泛化性能。

Abstract: Sampling-based motion planners (SBMPs) are widely used to compute dynamically
feasible robot paths. However, their reliance on uniform sampling often leads
to poor efficiency and slow planning in complex environments. We introduce a
novel non-uniform sampling strategy that integrates into existing SBMPs by
biasing sampling toward `certified' regions. These regions are constructed by
(i) generating an initial, possibly infeasible, path using any heuristic path
predictor (e.g., A* or vision-language models) and (ii) applying conformal
prediction to quantify the predictor's uncertainty. This process yields
prediction sets around the initial-guess path that are guaranteed, with
user-specified probability, to contain the optimal solution. To our knowledge,
this is the first non-uniform sampling approach for SBMPs that provides such
probabilistically correct guarantees on the sampling regions. Extensive
evaluations demonstrate that our method consistently finds feasible paths
faster and generalizes better to unseen environments than existing baselines.

</details>


### [126] [Design Exploration for Protection and Cleaning of Solar Panels with Case Studies for Space Missions](https://arxiv.org/abs/2511.04837)
*Cameron Robinson,Ganghee Jang*

Main category: cs.RO

TL;DR: 本文设计并比较了太阳能电池板的清洁机制（刮水器系统和轨道系统），并测试了保护材料，发现刮水器系统更高效，且聚碳酸酯分层材料具有良好的保护效果。


<details>
  <summary>Details</summary>
Motivation: 太阳能被用于太空探索、野火监测等关键任务应用，但太阳能电池板被灰尘覆盖或被太空碎片击中会限制甚至终止其运行，因此需要解决清洁和保护问题。

Method: 研究方法包括设计并比较了两种清洁机制：刮水器系统和轨道系统。同时，通过碰撞测试评估了各种保护材料，特别是聚碳酸酯，并研究了材料分层的影响。

Result: 在保护材料方面，聚碳酸酯表现出良好的前景，但最关键的因素是在电池板表面和硬质材料之间分层放置软质材料。在清洁系统比较中，基于刮水器的系统在成本、清洁速度和总功耗方面比基于轨道的系统更高效。

Conclusion: 研究表明，刮水器系统是更高效的太阳能电池板清洁机制，而分层软硬材料的聚碳酸酯是很有前途的保护材料，能够有效解决灰尘和碎片对太阳能电池板的威胁。

Abstract: Solar energy is used for many mission-critical applications including space
exploration, sensor systems to monitor wildfires, etc. Their operation can be
limited or even terminated if solar panels are covered with dust or hit by
space debris. To address this issue, we designed panel cleaning mechanisms and
tested protective materials. For cleaning mechanisms, we designed and compared
a wiper system and a rail system. For protective materials, we found through
collision tests that polycarbonate was very promising, though the most
important factor was layering a soft material between the panel's surface and a
hard material. In the cleaning system comparisons, the wiper-based system was
more efficient than the rail-based system in terms of cost, cleaning speed, and
total power consumption.

</details>


### [127] [iFlyBot-VLM Technical Report](https://arxiv.org/abs/2511.04976)
*Xin Nie,Zhiyuan Cheng,Yuan Zhang,Chao Ji,Jiajia Wu,Yuhan Zhang,Jia Pan*

Main category: cs.RO

TL;DR: iFlyBot-VLM是一个通用的视觉语言模型，旨在弥合具身智能中高维感知与低级动作控制之间的语义鸿沟，通过抽象操作语言实现跨平台协调，并在多个主流基准测试中取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 当前具身智能领域面临高维环境感知与低级机器人运动控制之间存在跨模态语义鸿沟的问题。研究旨在通过构建一个通用的视觉语言模型，推动具身智能从专用任务系统向通用、具有认知能力的智能体发展。

Method: 该研究引入了iFlyBot-VLM模型，其核心是将复杂的视觉和空间信息抽象为与机器人无关且可迁移的“操作语言”，以实现无缝的感知-动作闭环协调。模型架构旨在实现四个关键功能：空间理解与度量推理、交互式目标定位、动作抽象与控制参数生成、以及任务规划与技能排序。

Result: iFlyBot-VLM在Blink和Where2Place等10个当前主流具身智能相关的VLM基准数据集上进行了评估，取得了最佳性能，同时保持了模型的通用能力。

Conclusion: iFlyBot-VLM被设想为具身AI领域一个可扩展且通用的基础模型，能够促进该领域从专业化任务导向系统向通用、认知智能代理的进步。研究团队将公开训练数据和模型权重，以促进未来的研究与发展。

Abstract: We introduce iFlyBot-VLM, a general-purpose Vision-Language Model (VLM) used
to improve the domain of Embodied Intelligence. The central objective of
iFlyBot-VLM is to bridge the cross-modal semantic gap between high-dimensional
environmental perception and low-level robotic motion control. To this end, the
model abstracts complex visual and spatial information into a body-agnostic and
transferable Operational Language, thereby enabling seamless perception-action
closed-loop coordination across diverse robotic platforms. The architecture of
iFlyBot-VLM is systematically designed to realize four key functional
capabilities essential for embodied intelligence: 1) Spatial Understanding and
Metric Reasoning; 2) Interactive Target Grounding; 3) Action Abstraction and
Control Parameter Generation; 4) Task Planning and Skill Sequencing. We
envision iFlyBot-VLM as a scalable and generalizable foundation model for
embodied AI, facilitating the progression from specialized task-oriented
systems toward generalist, cognitively capable agents. We conducted evaluations
on 10 current mainstream embodied intelligence-related VLM benchmark datasets,
such as Blink and Where2Place, and achieved optimal performance while
preserving the model's general capabilities. We will publicly release both the
training data and model weights to foster further research and development in
the field of Embodied Intelligence.

</details>


### [128] [A semi-analytical approach for computing the largest singularity-free spheres of a class of 6-6 Stewart-Gough platforms for specified orientation workspaces](https://arxiv.org/abs/2511.04992)
*Bibekananda Patra,Sandipan Bandyopadhyay*

Main category: cs.RO

TL;DR: 本文提出了一种计算6-6 Stewart-Gough平台机械手（SGPM）在给定姿态工作空间内最大无奇异球体（SFS）的方法，并进行了不同架构的性能比较。


<details>
  <summary>Details</summary>
Motivation: 研究SGPM在指定姿态工作空间内的无奇异区域，以了解其性能并辅助SGPM的分析和设计。

Method: 对于移动平台的固定姿态，解析计算SFS；对姿态工作空间内生成的一系列样本重复此过程；选择其中最小的SFS作为给定姿态工作空间的所需SFS。通过对四种不同SGPM架构进行数值实验，比较它们在相同姿态工作空间下SFS体积的相对性能。

Result: 该方法能够计算SGPM在指定姿态工作空间内的最大SFS。数值实验展示了不同SGPM架构在SFS体积方面的相对性能。

Conclusion: 所提出的计算方法在SGPM的分析和设计中具有潜在的实用价值。

Abstract: This article presents a method for computing the largest singularity-free
sphere (SFS) of a 6-6 Stewart-Gough platform manipulator (SGPM) over a
specified orientation workspace. For a fixed orientation of the moving
platform, the SFS is computed analytically. This process is repeated over a set
of samples generated within the orientation workspace, and the smallest among
them is designated as the desired SFS for the given orientation workspace.
Numerical experiments are performed on four distinct architectures of the SGPM
to understand their relative performances w.r.t. SFS volumes over the same
orientation workspace. This study demonstrates the potential utility of the
proposed computational method both in analysis and design of SGPMs.

</details>


### [129] [MoE-DP: An MoE-Enhanced Diffusion Policy for Robust Long-Horizon Robotic Manipulation with Skill Decomposition and Failure Recovery](https://arxiv.org/abs/2511.05007)
*Baiye Cheng,Tianhai Liang,Suning Huang,Maanping Shao,Feihong Zhang,Botian Xu,Zhengrong Xue,Huazhe Xu*

Main category: cs.RO

TL;DR: 本文提出MoE-DP，一种通过在视觉编码器和扩散模型之间插入专家混合层（MoE）来增强的扩散策略，显著提高了机器人长程任务的鲁棒性、可解释性，并能从干扰中恢复。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在机器人视觉运动控制中表现强大，但在长程、多阶段任务中，它们往往缺乏从子任务失败中恢复的鲁棒性，并且其学习到的观测表示难以解释。

Method: 核心思想是在视觉编码器和扩散模型之间插入一个专家混合（MoE）层。该层将策略知识分解为一组专业专家，这些专家被动态激活以处理任务的不同阶段。

Result: MoE-DP在鲁棒性方面显著优于标准基线，在6个长程模拟任务中，受干扰条件下的成功率平均相对提高了36%。在真实世界中也验证了其显著的性能提升。此外，MoE-DP学习到可解释的技能分解，其中不同的专家对应于语义任务基元（例如，接近、抓取），这种结构可用于推理时控制，无需重新训练即可重新安排子任务。

Conclusion: MoE-DP通过引入专家混合层，成功解决了扩散策略在长程机器人控制中缺乏鲁棒性和可解释性的问题，实现了从干扰中恢复的能力，并能学习可解释的技能分解，支持灵活的任务执行。

Abstract: Diffusion policies have emerged as a powerful framework for robotic
visuomotor control, yet they often lack the robustness to recover from subtask
failures in long-horizon, multi-stage tasks and their learned representations
of observations are often difficult to interpret. In this work, we propose the
Mixture of Experts-Enhanced Diffusion Policy (MoE-DP), where the core idea is
to insert a Mixture of Experts (MoE) layer between the visual encoder and the
diffusion model. This layer decomposes the policy's knowledge into a set of
specialized experts, which are dynamically activated to handle different phases
of a task. We demonstrate through extensive experiments that MoE-DP exhibits a
strong capability to recover from disturbances, significantly outperforming
standard baselines in robustness. On a suite of 6 long-horizon simulation
tasks, this leads to a 36% average relative improvement in success rate under
disturbed conditions. This enhanced robustness is further validated in the real
world, where MoE-DP also shows significant performance gains. We further show
that MoE-DP learns an interpretable skill decomposition, where distinct experts
correspond to semantic task primitives (e.g., approaching, grasping). This
learned structure can be leveraged for inference-time control, allowing for the
rearrangement of subtasks without any re-training.Our video and code are
available at the https://moe-dp-website.github.io/MoE-DP-Website/.

</details>


### [130] [Encoding Biomechanical Energy Margin into Passivity-based Synchronization for Networked Telerobotic Systems](https://arxiv.org/abs/2511.04994)
*Xingyuan Zhou,Peter Paik,S. Farokh Atashzar*

Main category: cs.RO

TL;DR: 本文提出了一种名为TBPS2的双端口生物力学感知基于无源性的同步器和稳定器，用于解决触觉使能网络机器人系统中因通信不完善和非无源行为导致的姿态失同步问题，同时优化姿态同步并降低稳定器的保守性。


<details>
  <summary>Details</summary>
Motivation: 在网络机器人系统，特别是触觉使能的人机交互中，维持系统稳定性和精确的姿态跟踪至关重要。尽管现有研究已将人体生物力学整合到遥操作稳定器中以增强力保持并保证收敛和安全，但由于通信不完善和非无源行为导致的姿态失同步仍然是一个挑战。

Method: 本文提出了一种名为TBPS2的双端口生物力学感知基于无源性的同步器和稳定器。该稳定器通过利用人体生物力学来优化姿态同步，并降低稳定器激活时的保守性。文章提供了稳定器的数学设计综合和稳定性证明，并通过一系列网格模拟和系统实验，在不同时间延迟和环境条件下与现有先进解决方案进行了性能比较。

Result: TBPS2稳定器通过利用人体生物力学优化了姿态同步，并有效降低了稳定器激活时的保守性。通过网格模拟和系统实验，其性能在不同时间延迟和环境条件下与现有先进解决方案进行了比较。

Conclusion: 本文成功设计并验证了一种新颖的生物力学感知同步器和稳定器（TBPS2），能够有效解决网络机器人系统中触觉反馈导致的姿态失同步问题，同时保证系统稳定性和优化性能。

Abstract: Maintaining system stability and accurate position tracking is imperative in
networked robotic systems, particularly for haptics-enabled human-robot
interaction. Recent literature has integrated human biomechanics into the
stabilizers implemented for teleoperation, enhancing force preservation while
guaranteeing convergence and safety. However, position desynchronization due to
imperfect communication and non-passive behaviors remains a challenge. This
paper proposes a two-port biomechanics-aware passivity-based synchronizer and
stabilizer, referred to as TBPS2. This stabilizer optimizes position
synchronization by leveraging human biomechanics while reducing the
stabilizer's conservatism in its activation. We provide the mathematical design
synthesis of the stabilizer and the proof of stability. We also conducted a
series of grid simulations and systematic experiments, comparing their
performance with that of state-of-the-art solutions under varying time delays
and environmental conditions.

</details>


### [131] [Epically Powerful: An open-source software and mechatronics infrastructure for wearable robotic systems](https://arxiv.org/abs/2511.05033)
*Jennifer K. Leestma,Siddharth R. Nathella,Christoph P. O. Nuesslein,Snehil Mathur,Gregory S. Sawicki,Aaron J. Young*

Main category: cs.RO

TL;DR: Epically Powerful是一个开源机器人基础设施，旨在简化可穿戴机器人系统的开发和部署，通过提供一个Python接口、硬件指南和实时可视化功能，降低研究门槛。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是降低开发和部署定制化可穿戴机器人系统的门槛，使研究人员能够快速有效地将硬件转化为模块化、鲁棒的设备，而无需预设的尺寸限制。

Method: 该研究提供了一个开源机器人基础设施，通过Python简化用户实现，无缝对接商业准直接驱动（QDD）执行器、单板计算机和常见传感器。它还包含硬件选择、系统组装和控制器实现的综合指南，以及推荐零件清单、兼容性指南和详细的软硬件实现文档，并支持实时可视化。

Result: Epically Powerful成功地简化了可穿戴机器人系统的底层框架，管理通信协议、时钟、执行器命令、可视化、传感器数据采集和数据记录。它提供了一个易于使用的代码库和示例控制器，并实现了与各种先进商业硬件的无缝接口，从而加快了从原始硬件到模块化设备的开发过程。

Conclusion: Epically Powerful通过提供一个全面的开源基础设施，显著降低了开发和部署定制化可穿戴机器人系统的难度。尽管最初是为可穿戴机器人设计，但其通用性使其广泛适用于其他利用QDD执行器、单板计算机和传感器进行闭环控制的机器人领域。

Abstract: Epically Powerful is an open-source robotics infrastructure that streamlines
the underlying framework of wearable robotic systems - managing communication
protocols, clocking, actuator commands, visualization, sensor data acquisition,
data logging, and more - while also providing comprehensive guides for hardware
selection, system assembly, and controller implementation. Epically Powerful
contains a code base enabling simplified user implementation via Python that
seamlessly interfaces with various commercial state-of-the-art quasi-direct
drive (QDD) actuators, single-board computers, and common sensors, provides
example controllers, and enables real-time visualization. To further support
device development, the package also includes a recommended parts list and
compatibility guide and detailed documentation on hardware and software
implementation. The goal of Epically Powerful is to lower the barrier to
developing and deploying custom wearable robotic systems without a
pre-specified form factor, enabling researchers to go from raw hardware to
modular, robust devices quickly and effectively. Though originally designed
with wearable robotics in mind, Epically Powerful is broadly applicable to
other robotic domains that utilize QDD actuators, single-board computers, and
sensors for closed-loop control.

</details>


### [132] [Tunable Passivity Control for Centralized Multiport Networked Systems](https://arxiv.org/abs/2511.05026)
*Xingyuan Zhou,Peter Paik,S. Farokh Atashzar*

Main category: cs.RO

TL;DR: 本文提出了一种针对集中式多端口网络动态（CMND）系统的集中式最优无源性稳定框架，即可调集中式最优无源性控制（TCoPC），它是一种数据驱动、无模型的方案，能够有效保证系统稳定性并优化性能。


<details>
  <summary>Details</summary>
Motivation: CMND系统在多边远程机器人和多智能体控制等领域有广泛应用，但其稳定性易受非理想网络因素影响。传统的基于无源性的方法存在局限性，如补偿去中心化、缺乏灵活性，并依赖于节点无源性的限制性假设，仅适用于小规模系统。

Method: 本文合成了一个集中式最优无源性稳定框架，包括一个监控整体能量流的集中式无源性观测器和一个分配所需耗散的优化无源性控制器。该方法是数据驱动、无模型的，称为可调集中式最优无源性控制（TCoPC），它根据预设的耗散分布策略优化整体性能，并可灵活地在不同子网络上分配耗散负载。

Result: 所提出的方法保证了系统的严格无源性和L2稳定性。仿真结果表明，该框架在不同时变延迟场景下表现出色，同时放宽了远程节点的最小相位和无源性假设，显著提高了系统的可扩展性和通用性。

Conclusion: 该研究成功开发了一种集中式最优无源性稳定框架（TCoPC），有效解决了CMND系统在复杂网络条件下的稳定性挑战。它通过灵活的耗散分配和放宽传统假设，增强了系统的灵活性、可扩展性和通用性。

Abstract: Centralized Multiport Networked Dynamic (CMND) systems have emerged as a key
architecture with applications in several complex network systems, such as
multilateral telerobotics and multi-agent control. These systems consist of a
hub node/subsystem connecting with multiple remote nodes/subsystems via a
networked architecture. One challenge for this system is stability, which can
be affected by non-ideal network artifacts. Conventional passivity-based
approaches can stabilize the system under specialized applications like
small-scale networked systems. However, those conventional passive stabilizers
have several restrictions, such as distributing compensation across subsystems
in a decentralized manner, limiting flexibility, and, at the same time, relying
on the restrictive assumptions of node passivity. This paper synthesizes a
centralized optimal passivity-based stabilization framework for CMND systems.
It consists of a centralized passivity observer monitoring overall energy flow
and an optimal passivity controller that distributes the just-needed
dissipation among various nodes, guaranteeing strict passivity and, thus, L2
stability. The proposed data-driven model-free approach, i.e., Tunable
Centralized Optimal Passivity Control (TCoPC), optimizes total performance
based on the prescribed dissipation distribution strategy while ensuring
stability. The controller can put high dissipation loads on some sub-networks
while relaxing the dissipation on other nodes. Simulation results demonstrate
the proposed frameworks performance in a complex task under different
time-varying delay scenarios while relaxing the remote nodes minimum phase and
passivity assumption, enhancing the scalability and generalizability.

</details>


### [133] [TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments](https://arxiv.org/abs/2511.05052)
*Zihao Li,Yiming Zhu,Zhe Zhong,Qinyuan Ren,Yijiang Huang*

Main category: cs.RO

TL;DR: 针对复杂、受限空间内机器人抓取操作（特别是细长物体通过狭窄通道），本文提出拓扑感知物体操作规划（TAPOM）方法。该方法通过高层拓扑分析识别关键路径并生成关键帧，指导低层规划器寻找可行轨迹，显著提高了低间隙操作任务的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 在复杂、受限空间中（例如狭窄通道中操作细长物体），现有规划方法因采样困难或局部最小值而失效，限制了机器人抓取操作的广泛应用。这是一个具有挑战性但至关重要的领域。

Method: 本文提出拓扑感知物体操作规划（TAPOM）。它明确结合了任务空间拓扑分析，通过高层分析识别关键路径并生成引导关键帧，然后利用这些关键帧在低层规划器中寻找可行的构型空间轨迹。

Result: 实验验证表明，与现有先进方法相比，TAPOM在低间隙操作任务中取得了显著更高的成功率和更高的效率。

Conclusion: 该方法对于增强机器人在复杂现实环境中的操作能力具有广泛的意义。

Abstract: Robotic manipulation in complex, constrained spaces is vital for widespread
applications but challenging, particularly when navigating narrow passages with
elongated objects. Existing planning methods often fail in these low-clearance
scenarios due to the sampling difficulties or the local minima. This work
proposes Topology-Aware Planning for Object Manipulation (TAPOM), which
explicitly incorporates task-space topological analysis to enable efficient
planning. TAPOM uses a high-level analysis to identify critical pathways and
generate guiding keyframes, which are utilized in a low-level planner to find
feasible configuration space trajectories. Experimental validation demonstrates
significantly high success rates and improved efficiency over state-of-the-art
methods on low-clearance manipulation tasks. This approach offers broad
implications for enhancing manipulation capabilities of robots in complex
real-world environments.

</details>


### [134] [Force-Safe Environment Maps and Real-Time Detection for Soft Robot Manipulators](https://arxiv.org/abs/2511.05307)
*Akua K. Dickson,Juan C. Pacheco Garcia,Andrew P. Sabelhaus*

Main category: cs.RO

TL;DR: 本文提出了一种将力安全标准从任务空间映射到构型空间的框架，以实现软机器人操纵器在与脆弱障碍物接触时进行实时力安全检测和规划。


<details>
  <summary>Details</summary>
Motivation: 现有障碍物检测和避障方法未考虑操纵器与脆弱障碍物接触时可能施加的力限制，这限制了软机器人在精细环境中的部署。

Method: 研究人员引入了一个框架，将任务空间（机器人身体上的位置）的力安全标准映射到构型空间（机器人的关节角度）。通过操纵器的正向运动学，将允许的环境接触力限制映射到构型空间，从而确保被分类为安全的构型力值低于最大阈值。该方法在双段气动软机器人操纵器上进行了仿真和硬件实验验证。

Result: 结果表明，所提出的方法在与可变形障碍物交互时能准确检测力安全，证明了其在实际应用中的有效性。

Conclusion: 该方法为软机器人在精细、杂乱环境中进行实时安全规划奠定了基础，使其能够更安全地执行复杂操作任务。

Abstract: Soft robot manipulators have the potential for deployment in delicate
environments to perform complex manipulation tasks. However, existing obstacle
detection and avoidance methods do not consider limits on the forces that
manipulators may exert upon contact with delicate obstacles. This work
introduces a framework that maps force safety criteria from task space (i.e.
positions along the robot's body) to configuration space (i.e. the robot's
joint angles) and enables real-time force safety detection. We incorporate
limits on allowable environmental contact forces for given task-space
obstacles, and map them into configuration space (C-space) through the
manipulator's forward kinematics. This formulation ensures that configurations
classified as safe are provably below the maximum force thresholds, thereby
allowing us to determine force-safe configurations of the soft robot
manipulator in real-time. We validate our approach in simulation and hardware
experiments on a two-segment pneumatic soft robot manipulator. Results
demonstrate that the proposed method accurately detects force safety during
interactions with deformable obstacles, thereby laying the foundation for
real-time safe planning of soft manipulators in delicate, cluttered
environments.

</details>


### [135] [Decomposed Object Manipulation via Dual-Actor Policy](https://arxiv.org/abs/2511.05129)
*Bin Fan,Jianjian Jiang,Zhuohao Li,Yixiang He,Xiaoming Wu,Yihan Yang,Shengbang Liu,Weishi Zheng*

Main category: cs.RO

TL;DR: 本文提出了一种名为DAP的双演员策略，通过将物体操作任务分解为接近和操作两个阶段，并为每个阶段利用不同的视觉先验，显著提升了操作性能。同时构建了一个新的数据集以支持训练。


<details>
  <summary>Details</summary>
Motivation: 以往的物体操作研究常忽略任务的阶段性特征，仅使用单一策略学习整个操作过程。此外，现有数据集物体种类少，且缺乏支持训练所需的视觉先验。

Method: 1. 提出双演员策略(DAP)，明确区分接近和操作阶段。2. 引入基于功能性（affordance-based）的演员来定位功能部件，改进接近过程。3. 提出基于运动流（motion flow-based）的演员来捕捉部件运动，促进操作过程。4. 设计决策者判断当前阶段并选择相应演员。5. 构建了一个模拟的“双先验物体操作数据集”，包含两种视觉先验和七个任务（包括两个挑战性的长期多阶段任务）。

Result: 在自建数据集、RoboTwin基准和真实世界场景中，本文方法平均性能分别超越SOTA方法5.55%、14.7%和10.4%。

Conclusion: DAP通过显式考虑物体操作任务的阶段性特征并利用异构视觉先验，有效解决了单一策略的局限性，并在多个基准和真实场景中展现出卓越的性能。新构建的数据集也为相关研究提供了有力支持。

Abstract: Object manipulation, which focuses on learning to perform tasks on similar
parts across different types of objects, can be divided into an approaching
stage and a manipulation stage. However, previous works often ignore this
characteristic of the task and rely on a single policy to directly learn the
whole process of object manipulation. To address this problem, we propose a
novel Dual-Actor Policy, termed DAP, which explicitly considers different
stages and leverages heterogeneous visual priors to enhance each stage.
Specifically, we introduce an affordance-based actor to locate the functional
part in the manipulation task, thereby improving the approaching process.
Following this, we propose a motion flow-based actor to capture the movement of
the component, facilitating the manipulation process. Finally, we introduce a
decision maker to determine the current stage of DAP and select the
corresponding actor. Moreover, existing object manipulation datasets contain
few objects and lack the visual priors needed to support training. To address
this, we construct a simulated dataset, the Dual-Prior Object Manipulation
Dataset, which combines the two visual priors and includes seven tasks,
including two challenging long-term, multi-stage tasks. Experimental results on
our dataset, the RoboTwin benchmark and real-world scenarios illustrate that
our method consistently outperforms the SOTA method by 5.55%, 14.7% and 10.4%
on average respectively.

</details>


### [136] [Follow-Me in Micro-Mobility with End-to-End Imitation Learning](https://arxiv.org/abs/2511.05158)
*Sahar Salimpour,Iacopo Catalano,Tomi Westerlund,Mohsen Falahi,Jorge Peña Queralta*

Main category: cs.RO

TL;DR: 本文展示了模仿学习如何为自主微出行平台（如轮椅）在拥挤环境中提供更平稳、更舒适的控制器，优于手动调优，特别是在“跟随我”模式下实现了最先进的用户舒适度。


<details>
  <summary>Details</summary>
Motivation: 自主微出行平台在拥挤和动态环境中面临挑战，现有社交导航算法主要优化时间或距离等机器人学指标，而用户舒适度和整体用户体验在商业应用中至关重要但研究不足。

Method: 本文采用模仿学习来开发控制器，并分析了不同的神经网络架构用于端到端控制。通过DAAV自主轮椅在“跟随我”模式下（跟随人类操作员）进行实证。

Result: 模仿学习提供了比手动调优控制器更平稳、整体更好的控制器。DAAV自主轮椅在“跟随我”模式下实现了最先进的用户舒适度。论文还展示了神经网络架构在真实生产级部署中的可用性。

Conclusion: 模仿学习能够显著提升自主微出行平台的用户舒适度和体验，通过神经网络实现的端到端控制方案适用于真实世界的商业部署。

Abstract: Autonomous micro-mobility platforms face challenges from the perspective of
the typical deployment environment: large indoor spaces or urban areas that are
potentially crowded and highly dynamic. While social navigation algorithms have
progressed significantly, optimizing user comfort and overall user experience
over other typical metrics in robotics (e.g., time or distance traveled) is
understudied. Specifically, these metrics are critical in commercial
applications. In this paper, we show how imitation learning delivers smoother
and overall better controllers, versus previously used manually-tuned
controllers. We demonstrate how DAAV's autonomous wheelchair achieves
state-of-the-art comfort in follow-me mode, in which it follows a human
operator assisting persons with reduced mobility (PRM). This paper analyzes
different neural network architectures for end-to-end control and demonstrates
their usability in real-world production-level deployments.

</details>


### [137] [Procedimiento de auditoría de ciberseguridad para sistemas autónomos: metodología, amenazas y mitigaciones](https://arxiv.org/abs/2511.05185)
*Adrián Campazas-Vega,Claudia Álvarez-Aparicio,David Sobrín-Hidalgo,Laura Inyesto-Alonso,Francisco Javier Rodríguez-Lera,Vicente Matellán-Olivera,Ángel Manuel Guerrero-Higueras*

Main category: cs.RO

TL;DR: 本文提出了一种针对自主系统的分层安全审计程序，包括威胁分类和缓解措施，并通过四个代表性机器人平台的案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 自主系统在工业、医疗、物流和家庭环境中的广泛部署带来了显著的安全问题和风险，尤其是在人机交互环境中。此外，技术进步和系统复杂性增加了攻击面。

Method: 提出了一种基于分层方法论、适应机器人上下文的威胁分类以及一套具体缓解措施的自主系统安全审计程序。通过对四种代表性机器人平台（Ghost Robotics的Vision 60、Unitree Robotics的A1、Universal Robots的UR3协作臂和Aldebaran Robotics的Pepper社交机器人）的实际案例研究来验证该方法的有效性。

Result: 通过在四种代表性机器人平台上的实际案例研究，证明了所提出的安全审计方法的有效性。

Conclusion: 成功提出并验证了一种针对自主系统的分层安全审计程序，有效解决了该领域日益增长的安全挑战。

Abstract: The deployment of autonomous systems has experienced remarkable growth in
recent years, driven by their integration into sectors such as industry,
medicine, logistics, and domestic environments. This expansion is accompanied
by a series of security issues that entail significant risks due to the
critical nature of autonomous systems, especially those operating in
human-interaction environments. Furthermore, technological advancement and the
high operational and architectural complexity of autonomous systems have
resulted in an increased attack surface. This article presents a specific
security auditing procedure for autonomous systems, based on a layer-structured
methodology, a threat taxonomy adapted to the robotic context, and a set of
concrete mitigation measures. The validity of the proposed approach is
demonstrated through four practical case studies applied to representative
robotic platforms: the Vision 60 military quadruped from Ghost Robotics, the A1
robot from Unitree Robotics, the UR3 collaborative arm from Universal Robots,
and the Pepper social robot from Aldebaran Robotics.

</details>


### [138] [Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation](https://arxiv.org/abs/2511.05199)
*Yichen Zhu,Feifei Feng*

Main category: cs.RO

TL;DR: 本文提出了一种名为“从视频中检索学习”（RfV）的新方法，通过从人类演示视频中获取类比知识，使机器人能够学习操作策略，从而提高在复杂环境中的适应性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统在复杂不确定环境中面临挑战，且通常依赖大量数据集学习操作任务。与此不同，人类在面对不熟悉任务时，常通过观看视频演示来学习。这促使研究者探索如何让机器人也能从人类视频中学习。

Method: 该方法构建了一个包含人类日常任务视频的视频库，并从中提取物体可供性掩码和手部运动轨迹等中级信息，作为额外输入以增强机器人模型的学习和泛化能力。系统包含两个核心组件：一个视频检索器，根据任务规范从外部视频库中获取相关视频；一个策略生成器，将检索到的知识整合到学习循环中。

Result: 通过在多个模拟和真实世界场景中的严格测试，该系统在性能上显著优于传统机器人系统，展示了其在机器人领域的重大突破。

Conclusion: 该研究提供了一种通过从人类视频演示中检索和学习来生成机器人策略的新颖方法，使机器人能够对各种场景做出适应性响应，并泛化到训练数据之外的任务，代表了机器人领域的一项重要进展。

Abstract: Robots operating in complex and uncertain environments face considerable
challenges. Advanced robotic systems often rely on extensive datasets to learn
manipulation tasks. In contrast, when humans are faced with unfamiliar tasks,
such as assembling a chair, a common approach is to learn by watching video
demonstrations. In this paper, we propose a novel method for learning robot
policies by Retrieving-from-Video (RfV), using analogies from human
demonstrations to address manipulation tasks. Our system constructs a video
bank comprising recordings of humans performing diverse daily tasks. To enrich
the knowledge from these videos, we extract mid-level information, such as
object affordance masks and hand motion trajectories, which serve as additional
inputs to enhance the robot model's learning and generalization capabilities.
We further feature a dual-component system: a video retriever that taps into an
external video bank to fetch task-relevant video based on task specification,
and a policy generator that integrates this retrieved knowledge into the
learning cycle. This approach enables robots to craft adaptive responses to
various scenarios and generalize to tasks beyond those in the training data.
Through rigorous testing in multiple simulated and real-world settings, our
system demonstrates a marked improvement in performance over conventional
robotic systems, showcasing a significant breakthrough in the field of
robotics.

</details>


### [139] [ETHOS: A Robotic Encountered-Type Haptic Display for Social Interaction in Virtual Reality](https://arxiv.org/abs/2511.05379)
*Eric Godden,Jacquie Groenewegen,Matthew K. X. J. Pan*

Main category: cs.RO

TL;DR: ETHOS是一个动态的接触式触觉显示系统，旨在虚拟现实（VR）中实现自然的人际物理接触，例如传递物品、碰拳和击掌，通过集成机器人机械臂、可互换道具、精确注册和安全监控来实现。


<details>
  <summary>Details</summary>
Motivation: 当前VR社交互动中缺乏自然的物理接触，如传递物品、碰拳和击掌。本研究旨在开发一种动态触觉显示系统，以在VR中提供这些有意义的物理交互。

Method: ETHOS系统结合了力矩控制的机械臂和可互换的被动道具（硅胶手模型和警棍）。它通过ChArUco板进行基于标记的物理-虚拟注册，并包含一个基于用户头部和手部姿态的安全监控器。研究引入了两种控制策略：静态模式（呈现与虚拟对应物对齐的固定道具）和动态模式（通过混合初始中间轨迹和实时手部追踪来连续更新道具位置，为每次交互生成独特的接触点）。

Result: 基准测试显示静态共置精度为5.09 ± 0.94毫米。用户交互在所有交互和控制条件下实现了时间对齐，平均接触延迟为28.53 ± 31.21毫秒。这些结果证明了在VR中重现具有社会意义的触觉交互的可行性。

Conclusion: ETHOS通过结合必要的安全和控制机制，为虚拟环境中高保真、动态的人际交互奠定了实用基础，成功展示了在VR中实现自然物理接触的可能性。

Abstract: We present ETHOS (Encountered-Type Haptics for On-demand Social Interaction),
a dynamic encountered-type haptic display (ETHD) that enables natural physical
contact in virtual reality (VR) during social interactions such as handovers,
fist bumps, and high-fives. The system integrates a torque-controlled robotic
manipulator with interchangeable passive props (silicone hand replicas and a
baton), marker-based physical-virtual registration via a ChArUco board, and a
safety monitor that gates motion based on the user's head and hand pose. We
introduce two control strategies: (i) a static mode that presents a stationary
prop aligned with its virtual counterpart, consistent with prior ETHD
baselines, and (ii) a dynamic mode that continuously updates prop position by
exponentially blending an initial mid-point trajectory with real-time hand
tracking, generating a unique contact point for each interaction. Bench tests
show static colocation accuracy of 5.09 +/- 0.94 mm, while user interactions
achieved temporal alignment with an average contact latency of 28.53 +/- 31.21
ms across all interaction and control conditions. These results demonstrate the
feasibility of recreating socially meaningful haptics in VR. By incorporating
essential safety and control mechanisms, ETHOS establishes a practical
foundation for high-fidelity, dynamic interpersonal interactions in virtual
environments.

</details>


### [140] [Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space](https://arxiv.org/abs/2511.05203)
*Linus Nwankwo,Björn Ellensohn,Christian Rauch,Elmar Rueckert*

Main category: cs.RO

TL;DR: 本文提出了一种共生交互学习（SIL）方法，旨在使自主智能体和人类能够通过相互、双向的交互进行共同适应，超越了传统的“主仆”式人机交互模式。


<details>
  <summary>Details</summary>
Motivation: 当前的自主智能体在人机交互（HRI）中主要采用“主仆”模式，智能体被动地接收和执行指令，缺乏相互学习和共同适应的动态，这与人类日常交互中固有的共同适应性不符。

Method: 本文提出了共生交互学习（SIL），并将其形式化为在共享潜在任务空间中的共同适应过程，智能体和人类在此空间中维护基于交互历史演变的联合信念状态。该方法利用预训练的基础模型（FMs）进行空间感知和推理，并结合一个轻量级潜在编码器将模型输出映射到任务特定表示。此外，为确保任务演进的稳定性，SIL还增强了记忆架构以防止遗忘学习到的任务空间表示。

Result: SIL使智能体能够超越被动执行，实现主动澄清、自适应建议和共享计划细化。该方法在模拟和真实世界的具身任务中得到了验证，包括指令遵循、信息检索、面向查询的推理和交互式对话。

Conclusion: SIL成功地实现了人机之间的共同适应和双向交互，显著提升了自主智能体的交互能力，使其能够进行更接近人类水平的推理和互动，解决了传统HRI模式的局限性。

Abstract: Today's autonomous agents can understand free-form natural language
instructions and execute long-horizon tasks in a manner akin to human-level
reasoning. These capabilities are mostly driven by large-scale pre-trained
foundation models (FMs). However, the approaches with which these models are
grounded for human-robot interaction (HRI) perpetuate a master-apprentice
model, where the apprentice (embodied agent) passively receives and executes
the master's (human's) commands without reciprocal learning. This reactive
interaction approach does not capture the co-adaptive dynamics inherent in
everyday multi-turn human-human interactions. To address this, we propose a
Symbiotic Interactive Learning (SIL) approach that enables both the master and
the apprentice to co-adapt through mutual, bidirectional interactions. We
formalised SIL as a co-adaptation process within a shared latent task space,
where the agent and human maintain joint belief states that evolve based on
interaction history. This enables the agent to move beyond reactive execution
to proactive clarification, adaptive suggestions, and shared plan refinement.
To realise these novel behaviours, we leveraged pre-trained FMs for spatial
perception and reasoning, alongside a lightweight latent encoder that grounds
the models' outputs into task-specific representations. Furthermore, to ensure
stability as the tasks evolve, we augment SIL with a memory architecture that
prevents the forgetting of learned task-space representations. We validate SIL
on both simulated and real-world embodied tasks, including instruction
following, information retrieval, query-oriented reasoning, and interactive
dialogues. Demos and resources are public
at:~\href{https://linusnep.github.io/SIL/}{https://linusnep.github.io/SIL/}.

</details>


### [141] [Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning](https://arxiv.org/abs/2511.05234)
*Philipp Dahlinger,Niklas Freymuth,Tai Hoang,Tobias Würth,Michael Volpp,Luise Kärger,Gerhard Neumann*

Main category: cs.RO

TL;DR: 本文提出了一种名为M3GN的新型元学习方法，将网格模拟视为轨迹级别的元学习问题。通过使用条件神经过程和运动基元，M3GN能从有限数据中快速适应新场景，并以更高的精度和更低的运行成本超越现有图网络模拟器（GNS）。


<details>
  <summary>Details</summary>
Motivation: 物体变形模拟在机器人、制造和结构力学等领域至关重要。现有学习型模拟器（如GNS）通常依赖单步观察，这限制了它们利用时间上下文的能力（例如，推断材料属性），并因自回归推出而导致长轨迹误差累积。

Method: 本文将基于网格的模拟重新定义为轨迹级别的元学习问题。利用条件神经过程（Conditional Neural Processes），该方法能从有限的初始数据中快速适应新的模拟场景并捕获其潜在的模拟属性。此外，通过使用运动基元（movement primitives），该方法能够通过单次模型调用直接预测快速、稳定且准确的模拟，最终形成了Movement-primitive Meta-MeshGraphNet (M3GN)。

Result: 与最先进的图网络模拟器（GNSs）相比，M3GN在多项任务中实现了更高的模拟精度，同时运行成本仅为其一小部分。

Conclusion: M3GN通过将网格模拟框架为轨迹级别的元学习问题，并结合运动基元，有效克服了现有学习型模拟器在处理时间上下文和长轨迹误差累积方面的局限性，显著提升了模拟的准确性和效率。

Abstract: Simulating object deformations is a critical challenge across many scientific
domains, including robotics, manufacturing, and structural mechanics. Learned
Graph Network Simulators (GNSs) offer a promising alternative to traditional
mesh-based physics simulators. Their speed and inherent differentiability make
them particularly well suited for applications that require fast and accurate
simulations, such as robotic manipulation or manufacturing optimization.
However, existing learned simulators typically rely on single-step
observations, which limits their ability to exploit temporal context. Without
this information, these models fail to infer, e.g., material properties.
Further, they rely on auto-regressive rollouts, which quickly accumulate error
for long trajectories. We instead frame mesh-based simulation as a
trajectory-level meta-learning problem. Using Conditional Neural Processes, our
method enables rapid adaptation to new simulation scenarios from limited
initial data while capturing their latent simulation properties. We utilize
movement primitives to directly predict fast, stable and accurate simulations
from a single model call. The resulting approach, Movement-primitive
Meta-MeshGraphNet (M3GN), provides higher simulation accuracy at a fraction of
the runtime cost compared to state-of-the-art GNSs across several tasks.

</details>


### [142] [EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation](https://arxiv.org/abs/2511.05397)
*Samarth Chopra,Alex McMoil,Ben Carnovale,Evan Sokolson,Rajkumar Kubendran,Samuel Dickerson*

Main category: cs.RO

TL;DR: 本文介绍了一种名为EverydayVLA的低成本（低于300美元）六自由度机械臂，它结合了先进的视觉-语言-动作（VLA）模型和经济硬件，实现了与现有技术相当的性能，并在真实世界中表现出色，旨在普及机器人基础模型的应用。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型通常依赖昂贵的硬件，并且在处理新颖或杂乱场景时表现不佳，这限制了其普及和经济应用。

Method: 研究人员推出了EverydayVLA，一个成本低于300美元、具有适度负载和工作空间的六自由度机械臂。该系统采用一个统一模型，同时输出离散和连续动作，并结合自适应规划范围的集成方法，通过监测运动不确定性来触发即时重新规划，以确保安全可靠的操作。

Result: EverydayVLA在LIBERO基准测试中达到了与现有技术相当的成功率。在真实世界测试中，其在同分布任务中比现有方法高出49%，在异分布任务中高出34.9%。

Conclusion: EverydayVLA通过将先进的VLA模型与经济高效的硬件相结合，降低了机器人基础模型的使用门槛，为在家庭和研究实验室中经济地应用机器人技术铺平了道路。

Abstract: While Vision-Language-Action (VLA) models map visual inputs and language
instructions directly to robot actions, they often rely on costly hardware and
struggle in novel or cluttered scenes. We introduce EverydayVLA, a 6-DOF
manipulator that can be assembled for under $300, capable of modest payloads
and workspace. A single unified model jointly outputs discrete and continuous
actions, and our adaptive-horizon ensemble monitors motion uncertainty to
trigger on-the-fly re-planning for safe, reliable operation. On LIBERO,
EverydayVLA matches state-of-the-art success rates, and in real-world tests it
outperforms prior methods by 49% in-distribution and 34.9% out-of-distribution.
By combining a state-of-the-art VLA with cost-effective hardware, EverydayVLA
democratizes access to a robotic foundation model and paves the way for
economical use in homes and research labs alike. Experiment videos and details:
https://everydayvla.github.io/

</details>


### [143] [TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models](https://arxiv.org/abs/2511.05275)
*Hokyun Im,Euijin Jeong,Jianlong Fu,Andrey Kolobov,Youngwoon Lee*

Main category: cs.RO

TL;DR: TwinVLA是一个模块化框架，通过组合两个预训练的单臂视觉-语言-动作模型，实现了高效且高性能的双臂操作，无需额外的双臂数据预训练。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型（VLAs）在单臂操作任务上表现良好，但适应双臂任务通常需要大量的额外双臂数据和微调，因为大多数公开数据集侧重于单臂演示。

Method: 引入TwinVLA，一个模块化框架，它将两个预训练的单臂VLA实例组合成一个协调的双臂VLA。这种方法与在单臂和双臂数据混合上训练的整体式模型不同。

Result: 在真实世界和模拟环境中的各种双臂任务中，TwinVLA的性能优于同等规模的整体式RDT-1B模型，且无需任何双臂预训练。此外，它缩小了与依赖大量专有双臂数据和计算成本的SOTA模型（如π₀）的差距。

Conclusion: 研究结果表明，模块化组合方法（TwinVLA）是实现高性能双臂操作的一种数据高效且可扩展的途径，它能够有效利用公开的单臂数据。

Abstract: Vision-language-action models (VLAs) trained on large-scale robotic datasets
have demonstrated strong performance on manipulation tasks, including bimanual
tasks. However, because most public datasets focus on single-arm
demonstrations, adapting VLAs for bimanual tasks typically requires substantial
additional bimanual data and fine-tuning. To address this challenge, we
introduce TwinVLA, a modular framework that composes two copies of a pretrained
single-arm VLA into a coordinated bimanual VLA. Unlike monolithic
cross-embodiment models trained on mixtures of single-arm and bimanual data,
TwinVLA improves both data efficiency and performance by composing pretrained
single-arm policies. Across diverse bimanual tasks in real-world and simulation
settings, TwinVLA outperforms a comparably-sized monolithic RDT-1B model
without requiring any bimanual pretraining. Furthermore, it narrows the gap to
state-of-the-art model, $\pi_0$ which rely on extensive proprietary bimanual
data and compute cost. These results establish our modular composition approach
as a data-efficient and scalable path toward high-performance bimanual
manipulation, leveraging public single-arm data.

</details>


### [144] [Stable and Robust SLIP Model Control via Energy Conservation-Based Feedback Cancellation for Quadrupedal Applications](https://arxiv.org/abs/2511.05402)
*Muhammad Saud Ul Hassan,Derek Vasquez,Hamza Asif,Christian Hubicki*

Main category: cs.RO

TL;DR: 本文提出了一种基于能量守恒的控制架构，用于四足机器人的稳定动态运动，通过SLIP模型实现稳定的弹跳步态，并在一款真实机器人设计上进行了仿真验证。


<details>
  <summary>Details</summary>
Motivation: 实现四足机器人稳定的动态运动，特别是模仿生物四足动物的奔跑步态中常见的弹跳运动特性。

Method: 将机器人建模为弹簧加载倒立摆（SLIP），该模型允许在飞行阶段控制腿部方向，在站立阶段控制腿部长度。控制算法利用四足机器人的降阶SLIP动力学，跟踪一个通过能量守恒原理计算出的稳定抛物线样条。

Result: 基于Ghost Robotics Minitaur四足机器人的设计规格进行的仿真表明，所提出的控制算法能够生成稳定的弹跳步态。此外，控制器在传感器测量误差高达10%的情况下仍能保持稳定的弹跳，展现了其鲁棒性。

Conclusion: 所提出的基于能量守恒的控制架构能够为四足机器人实现稳定的弹跳步态，并且在存在传感器误差时表现出良好的鲁棒性。

Abstract: In this paper, we present an energy-conservation based control architecture
for stable dynamic motion in quadruped robots. We model the robot as a
Spring-loaded Inverted Pendulum (SLIP), a model well-suited to represent the
bouncing motion characteristic of running gaits observed in various biological
quadrupeds and bio-inspired robotic systems. The model permits leg-orientation
control during flight and leg-length control during stance, a design choice
inspired by natural quadruped behaviors and prevalent in robotic quadruped
systems. Our control algorithm uses the reduced-order SLIP dynamics of the
quadruped to track a stable parabolic spline during stance, which is calculated
using the principle of energy conservation. Through simulations based on the
design specifications of an actual quadruped robot, Ghost Robotics Minitaur, we
demonstrate that our control algorithm generates stable bouncing gaits.
Additionally, we illustrate the robustness of our controller by showcasing its
ability to maintain stable bouncing even when faced with up to a 10% error in
sensor measurements.

</details>


### [145] [Bioinspired Soft Quadrotors Jointly Unlock Agility, Squeezability, and Collision Resilience](https://arxiv.org/abs/2511.05426)
*Luca Girardi,Gabriel Maquignaz,Stefano Mintchev*

Main category: cs.RO

TL;DR: FlexiQuad是一种受自然飞行器启发设计的软框架四旋翼无人机，它通过结合各向异性刚度和分布式质量-能量结构，在不牺牲飞行性能的前提下，显著提高了碰撞弹性和可挤压性，从而扩展了在复杂环境中的飞行能力。


<details>
  <summary>Details</summary>
Motivation: 传统四旋翼无人机采用刚性框架，虽然能实现敏捷飞行，但固有限制了碰撞弹性和可挤压性，从而限制了其在杂乱环境中的飞行能力。受自然界中飞行器（如鸟类）柔软翅膀能够实现敏捷机动、穿过狭窄通道和承受碰撞的启发，研究旨在克服这一权衡。

Method: 引入了FlexiQuad设计方法，这是一种软框架四旋翼无人机，其灵感来源于生物体中观察到的各向异性刚度和分布式质量-能量结构。通过制造405克重的原型机并进行分析和测试来验证其性能。

Result: FlexiQuad原型机比传统四旋翼无人机柔顺性高三个数量级，同时仍能进行特技机动，峰值速度超过80公里/小时，线加速度和角加速度分别超过3g和300 rad/s²。在推重比达到8时，它能复制刚性对应物的加速度。同时，其碰撞弹性提高了四倍，能承受5米/秒的正面撞击而不损坏，并使擦碰中不稳定的力减少了39倍。其框架可以完全压缩，能够通过其标称宽度70%的狭窄间隙。研究还确定了20至3000克FlexiQuad模型的最佳结构柔软度范围为0.006至0.77 N/mm，与自然飞行器翅膀的柔软度相当。

Conclusion: FlexiQuad通过在不牺牲飞行性能的情况下实现敏捷性、可挤压性和碰撞弹性，扩展了无人机在复杂环境中的悬停能力，使其能够进行稳健的物理交互。

Abstract: Natural flyers use soft wings to seamlessly enable a wide range of flight
behaviours, including agile manoeuvres, squeezing through narrow passageways,
and withstanding collisions. In contrast, conventional quadrotor designs rely
on rigid frames that support agile flight but inherently limit collision
resilience and squeezability, thereby constraining flight capabilities in
cluttered environments. Inspired by the anisotropic stiffness and distributed
mass-energy structures observed in biological organisms, we introduce
FlexiQuad, a soft-frame quadrotor design approach that limits this trade-off.
We demonstrate a 405-gram FlexiQuad prototype, three orders of magnitude more
compliant than conventional quadrotors, yet capable of acrobatic manoeuvres
with peak speeds above 80 km/h and linear and angular accelerations exceeding 3
g and 300 rad/s$^2$, respectively. Analysis demonstrates it can replicate
accelerations of rigid counterparts up to a thrust-to-weight ratio of 8.
Simultaneously, FlexiQuad exhibits fourfold higher collision resilience,
surviving frontal impacts at 5 m/s without damage and reducing destabilising
forces in glancing collisions by a factor of 39. Its frame can fully compress,
enabling flight through gaps as narrow as 70% of its nominal width. Our
analysis identifies an optimal structural softness range, from 0.006 to 0.77
N/mm, comparable to that of natural flyers' wings, whereby agility,
squeezability, and collision resilience are jointly achieved for FlexiQuad
models from 20 to 3000 grams. FlexiQuad expands hovering drone capabilities in
complex environments, enabling robust physical interactions without
compromising flight performance.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [146] [Computationally Efficient Spline-Based Modeling of DER Dynamics for Voltage Stability in Active Distribution Networks](https://arxiv.org/abs/2511.04917)
*Shadrack T. Asiedu,Tara Aryal,Zongjie Wang,Hossein Moradi Rekabdarkolaee,Timothy M. Hansen*

Main category: eess.SY

TL;DR: 本文提出了一种基于B样条的低计算成本数据驱动方法，用于建模分布式能源（DER）的动态行为，通过将离散数据转换为连续可微函数，并利用线性回归估计低阶常微分方程，以实现接近传统系统辨识方法的精度，但速度快4.8倍，适用于电力系统实时应用。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源（DERs）日益整合到电力系统中，准确表示其在输电层面的动态行为变得至关重要。传统的电磁暂态模型（EMT）因对详细系统信息的依赖而面临可扩展性挑战。数据驱动方法（如系统辨识，SysID）虽然无需详细系统知识，但计算成本高昂，不适用于实时操作。

Method: 本文提出了一种新颖的数据驱动方法。该方法利用B样条将离散系统数据转换为连续可微函数，从而能够通过简单的线性回归估计低阶线性常微分方程来表示底层动态，大大降低了计算成本。此外，提取的动态方程通过后向欧拉法离散化，以便集成到离散时间电力调度模型中。

Result: 验证结果显示，所提模型的拟合优度（GoF）为98.74%，与系统辨识方法99.03%的GoF相当。然而，其运行速度比系统辨识方法快4.8倍。模型执行时间少于一分钟，这使其更适合电力系统运行中的实时应用。

Conclusion: 本文提出的基于B样条的数据驱动模型能够以极低的计算成本准确表示分布式能源的动态行为，其高精度和显著的计算速度优势使其非常适用于电力系统中的实时应用。

Abstract: The increasing integration of Distributed Energy Resources (DERs) into power
systems necessitates the accurate representation of their dynamic behavior at
the transmission level. Traditional electromagnetic transient models (EMT),
while effective, face scalability challenges due to their reliance on detailed
system information. Data-driven approaches, such as System Identification
(SysID), offer a promising alternative by modeling system dynamics without
detailed system knowledge. However, SysID and similar methods are
computationally intensive, requiring the computation of complex ordinary
differential equations (ODEs) or transfer functions estimation. This makes them
less effective for real-time operation. We therefore propose a novel
data-driven approach that simplifies the modeling of DERs dynamics by
leveraging B-splines to transform discrete system data into continuous
differentiable functions. This enables the estimation of lower order linear
ordinary differential equations with simple linear regression to represent the
underlying dynamics at a very low computational cost. Furthermore, the
extracted dynamic equations are discretized by the backward Euler method for
potential integration into discrete-time power dispatch models. Validation
results indicate a goodness-of-fit (GoF) of 98.74%, comparable to the 99.03%
GoF of the SysID method, yet, 4.8 times faster. Our proposed model's execution
time of less than one minute makes it more suitable for real-time applications
in power system operations.

</details>


### [147] [IoT and Predictive Maintenance in Industrial Engineering: A Data-Driven Approach](https://arxiv.org/abs/2511.04923)
*P. Vijaya Bharati,J. S. V. Siva Kumar,Sathish K Anumula,P Vamshi Krishna,Sangam Malla*

Main category: eess.SY

TL;DR: 本文探讨了工业物联网（IoT）与预测性维护在智能制造中的协同作用，强调了其技术、方法和数据分析，以提高运营效率并降低成本。


<details>
  <summary>Details</summary>
Motivation: 第四次工业革命带来了智能制造新时代，物联网和数据驱动方法正在彻底改变传统维护。通过预测故障和优化机器寿命，预测性维护成为工业系统提升效率的关键。

Method: 本文讨论了物联网与预测性维护的协同作用，包括利用物联网的实时数据和机器学习算法。具体方法涉及数据的系统收集、处理和预测建模，以及相关的数据分析技术。

Result: 研究结果表明，实施预测性维护能显著提高运营效率，减少停机时间，并实现成本节约。

Conclusion: 鉴于预测性维护在提高效率、降低成本和减少停机方面的显著优势，当代工业应积极采纳和实施预测性维护。

Abstract: Fourth Industrial Revolution has brought in a new era of smart manufacturing,
wherein, application of Internet of Things , and data-driven methodologies is
revolutionizing the conventional maintenance. With the help of real-time data
from the IoT and machine learning algorithms, predictive maintenance allows
industrial systems to predict failures and optimize machines life. This paper
presents the synergy between the Internet of Things and predictive maintenance
in industrial engineering with an emphasis on the technologies, methodologies,
as well as data analytics techniques, that constitute the integration. A
systematic collection, processing, and predictive modeling of data is
discussed. The outcomes emphasize greater operational efficiency, decreased
downtime, and cost-saving, which makes a good argument as to why predictive
maintenance should be implemented in contemporary industries.

</details>


### [148] [Strategic Decision-Making Under Uncertainty through Bi-Level Game Theory and Distributionally Robust Optimization](https://arxiv.org/abs/2511.04940)
*Jiachen Shen,Jian Shi,Lei Fan,Chenye Wu,Dan Wang,Choong Seon Hong,Zhu Han*

Main category: eess.SY

TL;DR: 本文提出了一种结合双层博弈论和分布鲁棒优化（DRO）的数学框架，用于处理具有层级结构的复杂网络系统中的不确定性决策，并通过转化和算法求解，显著提升了决策质量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在具有不同层级决策者的战略场景中，传统优化方法难以有效处理因信息不完整或外部因素不可预测而产生的不确定性。

Method: 该研究引入了一个数学框架，整合了双层博弈论（用于建模领导者-追随者互动）与分布鲁棒优化（DRO，用于应对最坏情况下的概率分布）。为确保计算可行性，利用KKT条件将双层问题转换为单层模型，并将无限维DRO问题重新表述为有限维等效问题。最后，提出了一种通用算法来求解该集成模型。

Result: 仿真结果表明，在高度不确定性下，所提出的模型与传统随机方法相比，实现了高达22%的成本降低，同时保持了90%以上的服务水平。

Conclusion: 该框架在交通和通信网络等网络系统中具有显著提高决策质量和鲁棒性的潜力。

Abstract: In strategic scenarios where decision-makers operate at different
hierarchical levels, traditional optimization methods are often inadequate for
handling uncertainties from incomplete information or unpredictable external
factors. To fill this gap, we introduce a mathematical framework that
integrates bi-level game theory with distributionally robust optimization
(DRO), particularly suited for complex network systems. Our approach leverages
the hierarchical structure of bi-level games to model leader-follower
interactions while incorporating distributional robustness to guard against
worst-case probability distributions. To ensure computational tractability, the
Karush-Kuhn-Tucker (KKT) conditions are used to transform the bi-level
challenge into a more manageable single-level model, and the
infinite-dimensional DRO problem is reformulated into a finite equivalent. We
propose a generalized algorithm to solve this integrated model. Simulation
results validate our framework's efficacy, demonstrating that under high
uncertainty, the proposed model achieves up to a 22\% cost reduction compared
to traditional stochastic methods while maintaining a service level of over
90\%. This highlights its potential to significantly improve decision quality
and robustness in networked systems such as transportation and communication
networks.

</details>


### [149] [Design and Implementation of a Cloud Computing Security Assessment Model Based on Hierarchical Analysis and Fuzzy Comprehensive Evaluation](https://arxiv.org/abs/2511.05049)
*Yihong Zou*

Main category: eess.SY

TL;DR: 本文构建了一个结合AHP和模糊综合评价方法的云计算服务安全评估框架，旨在解决日益突出的云安全问题。


<details>
  <summary>Details</summary>
Motivation: 云计算技术虽促进了企业数字化和业务创新，但随之而来的数据泄露和网络攻击等安全问题日益频繁，造成巨大损失，并成为阻碍云计算普及的重要因素。

Method: 该研究通过整合层次分析法（AHP）与模糊综合评价方法，构建了一个科学系统的云计算服务安全评估框架。

Result: 所提出的框架能帮助企业和个人更好地理解云服务的安全状况。

Conclusion: 该框架有助于促进整个云计算行业的健康发展，通过提升对云服务安全态势的理解来应对安全挑战。

Abstract: At the rapid pace of technological evolution, the emerging cloud computing
technology has promoted the digitalization and business innovation of the
enterprise in all industries due to its advantages of data storage and service
mode. Nevertheless, given the swift progress in cloud computing services, the
security problems have gradually appeared. The data breach and cyber attack
happen frequently, which cause huge losses to enterprises and individuals.
These issues have gradually become important constraints for the popularization
of cloud computingTo tackle the problems outlined above, this paper constructs
a security evaluation framework for cloud computing services, integrating the
Analytic Hierarchy Process (AHP) with the Fuzzy Comprehensive Evaluation
method. By applying this scientific and systematic methodology, the framework
enables enterprises and individuals to better apprehend the security posture of
cloud services, thereby fostering the healthy evolution of the entire industry.

</details>


### [150] [Evaluating the Impact of a Load Admittance Approximation in Transient Stability-Constrained Optimal Power Flow](https://arxiv.org/abs/2511.05116)
*Alex Junior da Cunha Coelho,Araceli Hernandez,Luis Badesa*

Main category: eess.SY

TL;DR: 本文提出了一种实用的基于电压的负荷导纳近似方法，用于瞬态稳定约束最优潮流（TSC-OPF）中的网络简化，以减轻计算负担并提高可扩展性，同时保持转子动力学仿真的准确性。


<details>
  <summary>Details</summary>
Motivation: 瞬态稳定约束最优潮流（TSC-OPF）通过离散化系统动态来确保在扰动下的安全经济运行，但计算负担巨大。许多研究通过将负荷表示为恒定导纳并使用克朗约化来简化网络，但这需要一个基于电压的假设将恒定功率负荷转换为恒定导纳，且通常在优化外部进行。本文旨在提出并评估这种近似方法引入的误差。

Method: 提出了一种实用的基于电压的负荷导纳近似方法。通过评估该近似方法在转子角度和转速偏差轨迹中可能引入的误差来验证其有效性。利用克朗约化简化网络。

Result: 在WECC 9节点系统上的案例研究表明，所提出的方法在最初几秒内能够重现与时域仿真一致的转子动态。它显著减少了实现工作量并缓解了收敛问题。

Conclusion: 所提出的框架为可扩展的TSC-OPF实现提供了一种简单而有效的策略。

Abstract: The Transient Stability-Constrained Optimal Power Flow (TSC-OPF) incorporates
dynamic stability constraints into the OPF formulation to ensure secure and
economical operation under disturbances. While discretizing system dynamics
enables the use of nonlinear programming techniques, it significantly increases
computational burden. To enhance scalability, many studies simplify the network
by representing loads as constant admittances, allowing the use of Kron
reduction. However, computing the Kron reduction outside the optimization
requires a voltage-based assumption to convert loads from constant power to
constant admittance. This paper proposes a practical voltage-based load
admittance approximation and evaluates the errors it may introduce in rotor
angle and speed deviation trajectories. Case studies on the WECC 9-bus system
show that the proposed approach reproduces rotor dynamics consistent with
time-domain simulations during the first few seconds while considerably
reducing implementation effort and mitigating convergence issues. The proposed
framework thus offers a simple and effective strategy for scalable TSC-OPF
implementations.

</details>


### [151] [Predicting and forecasting reactivity and flux using long short-term memory models in pebble bed reactors during run-in](https://arxiv.org/abs/2511.05118)
*Ian Kolaja,Ludovic Jantzen,Tatiana Siaraferas,Massimiliano Fratoni*

Main category: eess.SY

TL;DR: 本研究利用长短期记忆（LSTM）网络，通过操作历史和合成的批次级燃料测量数据，预测球床反应堆（PBR）的反应性、通量分布和功率分布，并在未见数据上取得了高精度，探索了其在优化反应堆运行程序中的应用。


<details>
  <summary>Details</summary>
Motivation: 球床反应堆（PBR）由于燃料混合物和过剩反应性的持续变化，以及不同操作参数对反应性影响时间尺度的差异（如燃料插入需数月，控制棒即时生效），带来了独特的优势和挑战。此外，堆内测量受限于高温、高注量和燃料床的动态运动。这些因素促使研究者寻求更有效的预测和优化工具。

Method: 本研究训练了长短期记忆（LSTM）网络，以操作历史和合成的批次级球形燃料测量（如卸料燃耗分布）作为输入。模型旨在预测反应性、通量分布和功率分布。

Result: 模型在未见的时间序列数据上进行了性能评估，在测试集上取得了0.9914的R²值。研究还检验了网络预测未来操作变化对反应性响应的能力，并探讨了其在优化反应堆启动程序中的应用。

Conclusion: LSTM网络能够有效预测球床反应堆的反应性、通量和功率分布，展现了对未来操作变化进行预测的潜力，并可应用于优化反应堆的运行程序，从而应对PBR操作中的独特挑战。

Abstract: Pebble bed reactor (PBR) operation presents unique advantages and challenges
due to the ability to continuously change the fuel mixture and excess
reactivity. Each operation parameter affects reactivity on a different
timescale. For example, fuel insertion changes may take months to fully
propagate, whereas control rod movements have immediate effects. In-core
measurements are further limited by the high temperatures, intense neutron
flux, and dynamic motion of the fuel bed. In this study, long short-term memory
(LSTM) networks are trained to predict reactivity, flux profiles, and power
profiles as functions of operating history and synthetic batch-level pebble
measurements, such as discharge burnup distributions. The model's performance
is evaluated using unseen temporal data, achieving an $R^2$ of 0.9914 on the
testing set. The capability of the network to forecast reactivity responses to
future operational changes is also examined, and its application for optimizing
reactor running-in procedures is explored.

</details>


### [152] [Voltage-Independent Active-Power Droop Coefficient for Enhanced Andronov-Hopf Oscillator Grid-Forming Inverters](https://arxiv.org/abs/2511.05252)
*Hamed Rezazadeh,Mohammad Monfared,Meghdad Fazeli,Saeed Golestan*

Main category: eess.SY

TL;DR: 本文提出一种增强型Andronov-Hopf振荡器（EAHO）策略，通过解耦有功功率下垂系数与电压幅度的关系，显著改善了电网形成逆变器的频率和电压支持能力，并提高了功率共享精度。


<details>
  <summary>Details</summary>
Motivation: 传统的Andronov-Hopf振荡器（AHO）控制电网形成（GFM）逆变器时，其下垂系数依赖于振荡器电压幅度，这限制了其在扰动下保持一致电网支持的能力，并导致功率共享不准确。

Method: 本文提出了一种增强型AHO（EAHO）策略，其中有功功率下垂系数不再是电压幅度的函数，同时保留了原始AHO的关键动态优势。通过广泛的比较分析、小信号分析以及在2.5 kVA单相逆变器上的实验验证，评估了EAHO的性能。

Result: EAHO策略改善了稳态性能，增强了有功和无功功率支持，并确保了在并网和独立模式下与其他GFM逆变器的精确功率共享。实验结果证实了EAHO在不同电网条件下改进的稳态性能、增强的功率支持和稳定运行。

Conclusion: EAHO策略为GFM逆变器提供了优越的动态响应，解决了传统AHO的局限性，实现了更一致的电网支持和更准确的功率共享，是控制GFM逆变器的有效方法。

Abstract: In recent years, virtual oscillator control, particularly the Andronov-Hopf
oscillator (AHO), has received widespread attention for controlling
grid-forming (GFM) inverters due to their superior dynamic response. However,
traditional AHO systems feature droop coefficients that are dependent on the
oscillator voltage amplitude, limiting their ability to maintain consistent
grid support during disturbances and resulting in power-sharing inaccuracies.
This paper presents an enhanced AHO (EAHO) strategy, where the active power
droop coefficient is no longer a function of the voltage amplitude and retains
the key dynamic benefits of the original AHO. The EAHO improves both frequency
and voltage support and ensures accurate power sharing with other GFM inverters
in grid-connected and stand-alone modes. Extensive comparative and small-signal
analyses, alongside experimental validation on 2.5 kVA single-phase inverters,
confirm the EAHO's improved steady-state performance, enhanced active and
reactive power support, and stable operation under varying grid conditions.

</details>


### [153] [Neural Operators for Power Systems: A Physics-Informed Framework for Modeling Power System Components](https://arxiv.org/abs/2511.05216)
*Ioannis Karampinis,Petros Ellinas,Johanna Vorwerk,Spyros Chatzivasileiadis*

Main category: eess.SY

TL;DR: 本文提出了一种基于深度算子网络（DeepONets）及其物理信息版本（PI-DeepONets）的代理模型框架，用于快速准确地模拟电力系统动态，相较于传统ODE求解器实现了显著加速。


<details>
  <summary>Details</summary>
Motivation: 现代电力系统需要快速准确的动态仿真进行稳定性评估、数字孪生和实时控制，但传统的常微分方程（ODE）求解器对于大规模或在线应用来说速度过慢。

Method: 研究者提出了一个神经算子框架，利用深度算子网络（DeepONets）学习从系统状态和时变输入到完整轨迹的映射，无需逐步积分。为了提高泛化能力和数据效率，引入了物理信息深度算子网络（PI-DeepONets），将控制方程的残差嵌入到训练损失中。

Result: DeepONets，特别是PI-DeepONets，在不同场景下均实现了准确预测，与高阶ODE求解器相比，速度提升了30倍以上。与物理信息神经网络（PINNs）的基准测试表明，该方法具有卓越的稳定性和可扩展性。

Conclusion: 研究结果表明，神经算子是实现电力系统动态实时、物理感知仿真的一个有前景的途径。

Abstract: Modern power systems require fast and accurate dynamic simulations for
stability assessment, digital twins, and real-time control, but classical ODE
solvers are often too slow for large-scale or online applications. We propose a
neural-operator framework for surrogate modeling of power system components,
using Deep Operator Networks (DeepONets) to learn mappings from system states
and time-varying inputs to full trajectories without step-by-step integration.
To enhance generalization and data efficiency, we introduce Physics-Informed
DeepONets (PI-DeepONets), which embed the residuals of governing equations into
the training loss. Our results show that DeepONets, and especially
PI-DeepONets, achieve accurate predictions under diverse scenarios, providing
over 30 times speedup compared to high-order ODE solvers. Benchmarking against
Physics-Informed Neural Networks (PINNs) highlights superior stability and
scalability. Our results demonstrate neural operators as a promising path
toward real-time, physics-aware simulation of power system dynamics.

</details>


### [154] [Privacy-Preserving Cramér-Rao Lower Bound](https://arxiv.org/abs/2511.05327)
*Jieming Ke,Jimin Wang,Ji-Feng Zhang*

Main category: eess.SY

TL;DR: 本文建立了隐私保护的Cramér-Rao (CR) 下界理论，表征了隐私约束下识别准确度的基本极限，并将其扩展到多传感器多测量系统，同时提出了可实现该下界的分布式识别算法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在表征在隐私约束下识别准确度的根本极限，即如何在保证隐私的前提下，量化识别的最高精度。

Method: 本文使用Fisher信息矩阵作为隐私度量，推导了隐私约束下的可识别性准则。在此基础上，建立了隐私保护的CR下界并证明了其可达性。随后，将该理论扩展到多传感器多测量系统，确立了隐私保护的Fisher信息矩阵在空间和时间维度上的可加性原则。最后，基于此原则提出了能够达到隐私保护CR下界的分布式识别算法。

Result: 研究结果包括：建立了隐私保护的CR下界理论；推导了隐私约束下的可识别性准则；明确了隐私保护的Fisher信息矩阵的存在性及其显式表达式；将隐私保护CR下界理论扩展到多传感器多测量系统，并确立了隐私保护的Fisher信息矩阵在空间和时间维度上的可加性原则；提出了能够实现隐私保护CR下界的分布式识别算法。数值示例验证了该下界和所提算法的有效性。

Conclusion: 本文成功建立了隐私约束下识别准确度的理论极限，并提供了可达的分布式识别算法。这为在隐私保护背景下的系统识别提供了坚实的理论基础和实用方法。

Abstract: This paper establishes the privacy-preserving Cram\'er-Rao (CR) lower bound
theory, characterizing the fundamental limit of identification accuracy under
privacy constraint. An identifiability criterion under privacy constraint is
derived by using Fisher information matrix as the privacy metric. In the
identifiable case, the privacy-preserving CR lower bound is established and its
attainability is demonstrated, thereby ensuring the existence of the
privacy-preserving Fisher information matrix with explicit expression. Then,
the privacy-preserving CR lower bound theory is extended to the multi-sensor
multi-measurement system. Specifically, the additivity principle of
privacy-preserving Fisher information matrices across both spatial and temporal
dimensions is established, building a relationship between privacy-preserving
CR lower bounds for the multi-sensor multi-measurement system and its
subsystems. Using this additivity principle, distributed identification
algorithms capable of achieving the privacy-preserving CR lower bound are
further proposed. Numerical examples are provided to demonstrate the
privacy-preserving CR lower bound and show the effectiveness of the proposed
algorithms.

</details>


### [155] [Efficient CNN Inference on Ultra-Low-Power MCUs via Saturation-Aware Convolution](https://arxiv.org/abs/2511.05347)
*Shiming Li,Luca Mottola,Yuan Yao,Stefanos Kaxiras*

Main category: eess.SY

TL;DR: 本文提出了一种名为“饱和感知卷积”的推理技术，通过跳过量化CNN中饱和神经元的冗余计算，在不影响准确性的前提下，显著降低超低功耗MCU上的推理延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 在超低功耗微控制器（MCU）上部署轻量级CNN推理任务时，模型大小通常不是限制因素，但推理延迟对于节约能耗至关重要。研究发现，量化CNN推理在某些神经元产生饱和输出值时，仍会执行不必要的完整计算，这导致了能量浪费。

Method: 研究通过精心设计的条件检查，识别并跳过那些产生饱和输出值但不影响最终结果的神经元中的不必要计算。在此基础上，提出了“饱和感知卷积”技术：通过改变卷积核中的计算顺序以提前诱导饱和，并插入饱和检查来省略不必要的计算。该方法被集成到MCUNet的TinyEngine框架中，并在Cortex-M0+ MCU上进行了实验。

Result: 基于7个开源CNN模型在Cortex-M0+ MCU上的实验结果显示，推理时间最多可节省24%，同时对神经网络的准确性没有任何影响。

Conclusion: 通过利用量化CNN中神经元输出的饱和特性，所提出的饱和感知卷积技术能有效减少超低功耗MCU上的推理时间，从而提高能效，且不牺牲模型精度。

Abstract: Deploying lightweight CNN inference tasks on ultra-low-power MCUs is often
not limited by space constraint, thanks to the compact size of models, yet
inference latency is crucial for preserving energy. We reveal that quantized
CNN inference on ultra-low-power MCUs executes unnecessary computations in
neurons that produce saturated output values: often times, these neurons still
produce the correct output value without fully completing the computation,
since the neuron value is too extreme and is eventually systematically clamped
at the boundaries allowed by the neuron. We show that with carefully designed
condition checks, it is possible to identify and skip these unnecessary
computations without impacting the neuron output. Based on this, we present
saturation-aware convolution: an inference technique whereby computations in
convolution kernels are executed in an altered order to induce earlier
saturation, and saturation checks are inserted to omit unnecessary
computations. We integrate our implementation into MCUNet's TinyEngine, the
state-of-the-art neural network code generation and inference framework, and
conduct experiments on a Cortex-M0+ MCU. The result based on 7 open-source CNN
models displays up to 24% inference time saving, with strictly zero impact on
neural network accuracy.

</details>


### [156] [A Tilting-Rotor Enhanced Quadcopter Fault-Tolerant Control Based on Non-Linear Model Predictive Control](https://arxiv.org/abs/2511.05445)
*Yanchao Wang,Xu You,Mehdi Baghdadi*

Main category: eess.SY

TL;DR: 本文提出一种基于倾转旋翼四旋翼无人机的容错控制策略，利用非线性模型预测控制和扩展状态观测器，在旋翼故障后保持姿态和位置稳定性。


<details>
  <summary>Details</summary>
Motivation: 在旋翼故障发生时，需要为倾转旋翼四旋翼无人机提供一种有效的容错控制策略，以维持其姿态和位置的稳定性。

Method: 该策略采用非线性模型预测控制（NMPC）来维持姿态和位置稳定性。同时，使用扩展状态观测器（ESO）预测故障后的模型偏差，并在后续时间步调整原始模型，从而实现主动容错控制。

Result: 通过仿真评估，结果表明，与传统四旋翼无人机和不带观测器的倾转旋翼无人机相比，所提出的倾转旋翼无人机策略能够在不牺牲偏航稳定性的情况下保持位置控制，而传统四旋翼无人机则无法做到。

Conclusion: 所提出的基于非线性模型预测控制和扩展状态观测器的容错控制策略，能有效使倾转旋翼四旋翼无人机在旋翼故障后保持姿态和位置稳定性，并优于传统四旋翼无人机。

Abstract: This paper proposes a fault-tolerant control strategy based on a tilt-rotor
quadcopter prototype, utilizing nonlinear model predictive control to maintain
both attitude and position stability in the event of rotor failure. The control
strategy employs an extended state observer to predict model deviations
following a fault and adjusts the original model in the subsequent time step,
thereby achieving active fault-tolerant control. The proposed method is
evaluated through simulations and compared to both traditional quadcopter and
tilt-rotor quadcopter without observer under identical conditions. The results
demonstrate that the tilt-rotor quadcopter can maintain position control
without sacrificing yaw stability, unlike traditional quadcopters.

</details>


### [157] [Coherency Control in Power Systems](https://arxiv.org/abs/2511.05391)
*Rodrigo Bernal,Ignacio Ponce,Federico Milano*

Main category: eess.SY

TL;DR: 本文提出了一种针对逆变器并网资源（IBRs）的相干性控制策略，通过定义注入电流的复频率等效性来实现设备间的相干性，旨在改善电力系统阻尼和整体动态行为。


<details>
  <summary>Details</summary>
Motivation: 在现代电力系统中，需要一种有效的控制策略来在各种电力系统设备，特别是IBRs之间建立相干性，以改善系统的动态性能。

Method: 该研究提出了一种IBRs相干性控制策略，将注入电流的复频率等效性作为设备间相干性的定义。该控制通过强制输出电流与参考值保持比例幅值和恒定相移来实现。这种方法具有技术无关性，能与任何类型的资源实现相干性。通过在双区域系统和IEEE 39节点系统上进行案例研究，并评估了延迟/噪声敏感性以及振荡缓解与扰动传播之间的权衡。

Result: 案例研究表明，所提出的控制器能够有效改善电力系统的阻尼和整体动态行为。该控制策略被证明是技术无关的，能够与任何类型的资源实现相干性。

Conclusion: 这项工作确立了相干性作为现代电力系统中IBRs一个可行的直接控制目标。

Abstract: This paper proposes a coherency control strategy for Inverter-Based Resources
(IBRs) to establish coherence among power system devices. Using the equivalence
of the Complex Frequency (CF) of the injected currents as the definition for
coherency among devices, the control enforces an output current with a
proportional magnitude and a constant phase shift relative to a reference. This
formulation makes the control technology-agnostic, enabling coherency with any
type of resource. Case studies based on the two-area and IEEE 39-bus systems
demonstrate the controller's potential to improve damping and overall dynamic
behavior. The paper further evaluates practical implementation aspects
including delay/noise sensitivity and the trade-off between oscillation
mitigation and disturbance propagation. This work establishes coherency as a
viable direct control objective for IBRs in modern power systems.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [158] [LG-NuSegHop: A Local-to-Global Self-Supervised Pipeline For Nuclei Instance Segmentation](https://arxiv.org/abs/2511.04892)
*Vasileios Magoulianitis,Catherine A. Alexander,Jiaxin Yang,C. -C. Jay Kuo*

Main category: eess.IV

TL;DR: LG-NuSegHop是一种自监督细胞核分割方法，无需手动标注数据或领域适应，在多个数据集中表现出良好的泛化能力和竞争力，且模块透明可解释。


<details>
  <summary>Details</summary>
Motivation: 细胞核分割是组织学图像分析的基础任务，对疾病诊断至关重要。然而，由于细胞核在不同组织和采集过程中的巨大变异性，以及数据标注成本高昂，导致自动化该任务极具挑战性，深度学习模型难以泛化到未见器官或不同领域。

Method: 本文提出了Local-to-Global NuSegHop (LG-NuSegHop)，一个基于问题先验知识和分子生物学的自监督流程。它包含三个模块：(1) 一组局部处理操作以生成伪标签；(2) NuSegHop，一个新颖的数据驱动特征提取模型；(3) 一组全局操作来后处理NuSegHop的预测。值得注意的是，该流程不使用任何手动标注的训练数据或领域适应。

Result: 在三个公开可用数据集上的实验表明，LG-NuSegHop优于其他自监督和弱监督方法，同时在完全监督方法中也具有竞争力。该方法保持了良好的泛化性能。此外，LG-NuSegHop的每个模块都对医生透明且可解释。

Conclusion: LG-NuSegHop提供了一种有效、可泛化且对医生可解释的自监督细胞核分割解决方案，克服了传统方法对大量手动标注数据的依赖，并在不同数据集上展现出强大的性能。

Abstract: Nuclei segmentation is the cornerstone task in histology image reading,
shedding light on the underlying molecular patterns and leading to disease or
cancer diagnosis. Yet, it is a laborious task that requires expertise from
trained physicians. The large nuclei variability across different organ tissues
and acquisition processes challenges the automation of this task. On the other
hand, data annotations are expensive to obtain, and thus, Deep Learning (DL)
models are challenged to generalize to unseen organs or different domains. This
work proposes Local-to-Global NuSegHop (LG-NuSegHop), a self-supervised
pipeline developed on prior knowledge of the problem and molecular biology.
There are three distinct modules: (1) a set of local processing operations to
generate a pseudolabel, (2) NuSegHop a novel data-driven feature extraction
model and (3) a set of global operations to post-process the predictions of
NuSegHop. Notably, even though the proposed pipeline uses { no manually
annotated training data} or domain adaptation, it maintains a good
generalization performance on other datasets. Experiments in three publicly
available datasets show that our method outperforms other self-supervised and
weakly supervised methods while having a competitive standing among fully
supervised methods. Remarkably, every module within LG-NuSegHop is transparent
and explainable to physicians.

</details>


### [159] [J-SGFT: Joint Spatial and Graph Fourier Domain Learning for Point Cloud Attribute Deblocking](https://arxiv.org/abs/2511.05047)
*Muhammad Talha,Qi Yang,Zhu Li,Anique Akhtar,Geert Van Der Auwera*

Main category: eess.IV

TL;DR: 本文提出了一种多尺度后处理框架，结合图傅里叶潜在属性表示、稀疏卷积和通道注意力机制，有效去除几何点云压缩（GPCC）重建点云中的块状伪影，显著提升视觉质量并降低码率。


<details>
  <summary>Details</summary>
Motivation: 点云在AR/VR和自动驾驶中至关重要，但其大小、不规则采样和稀疏性对压缩方案构成挑战。MPEG的GPCC方法虽然能有效降低码率，但会在重建点云中引入明显的块状伪影。

Method: 研究人员引入了一种新颖的多尺度后处理框架。该框架将图傅里叶潜在属性表示与稀疏卷积和通道注意力机制相结合，旨在高效地对重建点云进行去块处理。

Result: 与GPCC TMC13v14基线相比，该方法在8iVFBv2数据集上实现了Y通道18.81%和YUV联合18.14%的BD-rate降低。同时，它显著改善了视觉保真度，且开销极小。

Conclusion: 所提出的多尺度后处理框架能有效去除GPCC压缩点云中的块状伪影，显著提升视觉质量，并在码率降低方面表现出色，具有最小的额外开销。

Abstract: Point clouds (PC) are essential for AR/VR and autonomous driving but
challenge compression schemes with their size, irregular sampling, and
sparsity. MPEG's Geometry-based Point Cloud Compression (GPCC) methods
successfully reduce bitrate; however, they introduce significant blocky
artifacts in the reconstructed point cloud. We introduce a novel multi-scale
postprocessing framework that fuses graph-Fourier latent attribute
representations with sparse convolutions and channel-wise attention to
efficiently deblock reconstructed point clouds. Against the GPCC TMC13v14
baseline, our approach achieves BD-rate reduction of 18.81\% in the Y channel
and 18.14\% in the joint YUV on the 8iVFBv2 dataset, delivering markedly
improved visual fidelity with minimal overhead.

</details>


### [160] [UHDRes: Ultra-High-Definition Image Restoration via Dual-Domain Decoupled Spectral Modulation](https://arxiv.org/abs/2511.05009)
*S. Zhao,W. Lu,B. Wang,T. Wang,K. Zhang,H. Zhao*

Main category: eess.IV

TL;DR: 本文提出UHDRes，一个轻量级双域解耦频谱调制框架，用于超高清图像恢复，在仅400K参数下实现最先进的性能，并显著降低推理延迟和内存使用。


<details>
  <summary>Details</summary>
Motivation: 超高清（UHD）图像常受到模糊、雾霾、雨水或低光等严重退化，其高分辨率和计算需求给图像恢复带来了巨大挑战。

Method: 本文提出UHDRes，一个轻量级双域解耦频谱调制框架。它通过轻量级频谱域调制显式建模振幅谱，同时通过空间域细化隐式恢复相位。引入了时空频谱融合机制，首先使用多尺度上下文聚合器提取局部和全局空间特征，然后以解耦方式进行频谱调制，显式增强频域振幅特征，通过空间细化隐式恢复相位信息。此外，设计了一个共享门控前馈网络，通过共享参数卷积和自适应门控机制有效促进特征交互。

Result: 在五个公共UHD基准测试上的广泛实验比较表明，UHDRes以仅400K参数实现了最先进的恢复性能，同时显著降低了推理延迟和内存使用。

Conclusion: UHDRes提供了一种高效且有效的超高清图像恢复解决方案，以极低的计算成本实现了最先进的性能。

Abstract: Ultra-high-definition (UHD) images often suffer from severe degradations such
as blur, haze, rain, or low-light conditions, which pose significant challenges
for image restoration due to their high resolution and computational demands.
In this paper, we propose UHDRes, a novel lightweight dual-domain decoupled
spectral modulation framework for UHD image restoration. It explicitly models
the amplitude spectrum via lightweight spectrum-domain modulation, while
restoring phase implicitly through spatial-domain refinement. We introduce the
spatio-spectral fusion mechanism, which first employs a multi-scale context
aggregator to extract local and global spatial features, and then performs
spectral modulation in a decoupled manner. It explicitly enhances amplitude
features in the frequency domain while implicitly restoring phase information
through spatial refinement. Additionally, a shared gated feed-forward network
is designed to efficiently promote feature interaction through shared-parameter
convolutions and adaptive gating mechanisms. Extensive experimental comparisons
on five public UHD benchmarks demonstrate that our UHDRes achieves the
state-of-the-art restoration performance with only 400K parameters, while
significantly reducing inference latency and memory usage. The codes and models
are available at https://github.com/Zhao0100/UHDRes.

</details>


### [161] [Transporter: A 128$\times$4 SPAD Imager with On-chip Encoder for Spiking Neural Network-based Processing](https://arxiv.org/abs/2511.05241)
*Yang Lin,Claudio Bruschini,Edoardo Charbon*

Main category: eess.IV

TL;DR: 本文提出了一种新型的单光子雪崩二极管（SPAD）成像范式，通过在传感器中集成脉冲编码器来消除时间数字转换器（TDCs），从而在传感器内预处理光子事件，显著压缩数据，降低复杂性，并支持实时边缘处理，为高效神经形态SPAD成像系统奠定基础。


<details>
  <summary>Details</summary>
Motivation: 传统的SPAD架构依赖TDC和基于直方图的处理，导致数据传输和处理面临巨大挑战。尽管之前有基于循环神经网络的无直方图处理方法，但本文旨在通过消除TDC来进一步解决这些局限性。

Method: 该方法通过在传感器中集成脉冲编码器来消除TDC。专用的脉冲编码器折叠多个激光重复周期，将基于相位的脉冲序列转换为基于密度的脉冲序列，优化用于脉冲神经网络（SNN）处理和通过时间反向传播进行训练。作为概念验证，引入了Transporter，一个128x4的SPAD传感器，每个像素都带有基于D触发器环的脉冲编码器。

Result: 该方法实现了在传感器内的光子到达事件预处理，显著压缩了数据，降低了系统复杂性，并保持了实时边缘处理能力。Transporter传感器的引入证明了这种概念的可行性，旨在用于智能主动时间分辨成像。

Conclusion: 这项工作展示了一条通向更高效、神经形态SPAD成像系统的途径，该系统具有更低的数据开销和增强的实时处理能力。

Abstract: Single-photon avalanche diodes (SPADs) are widely used today in time-resolved
imaging applications. However, traditional architectures rely on
time-to-digital converters (TDCs) and histogram-based processing, leading to
significant data transfer and processing challenges. Previous work based on
recurrent neural networks has realized histogram-free processing. To further
address these limitations, we propose a novel paradigm that eliminates TDCs by
integrating in-sensor spike encoders. This approach enables preprocessing of
photon arrival events in the sensor while significantly compressing data,
reducing complexity, and maintaining real-time edge processing capabilities. A
dedicated spike encoder folds multiple laser repetition periods, transforming
phase-based spike trains into density-based spike trains optimized for spiking
neural network processing and training via backpropagation through time. As a
proof of concept, we introduce Transporter, a 128$\times$4 SPAD sensor with a
per-pixel D flip-flop ring-based spike encoder, designed for intelligent active
time-resolved imaging. This work demonstrates a path toward more efficient,
neuromorphic SPAD imaging systems with reduced data overhead and enhanced
real-time processing.

</details>
