{"id": "2601.20066", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2601.20066", "abs": "https://arxiv.org/abs/2601.20066", "authors": ["Darren Dahunsi", "Randy Palamar", "Tyler Henry", "Mohammad Rahim Sobhani", "Negar Majidi", "Joy Wang", "Afshin Kashani Ilkhechi", "Roger Zemp"], "title": "Orthogonal Plane-Wave Transmit-Receive Isotropic-Focusing Micro-Ultrasound (OPTIMUS) with Bias-Switchable Row-Column Arrays", "comment": "8 pages, 6 figures, 3 videos", "summary": "High quality structural volumetric imaging is a challenging goal to achieve with modern ultrasound transducers. Matrix probes have limited fields of view and element counts, whereas row-column arrays (RCAs) provide insufficient focusing. In contrast, Top-Orthogonal-to-Bottom-Electrode (TOBE) arrays, also known as bias-switchable RCAs can enable isotropic focusing on par with ideal matrix probes, with a field of view surpassing conventional RCAs. Orthogonal Plane-Wave Transmit-Receive Isotropic-Focusing Micro-Ultrasound (OPTIMUS) is a novel imaging scheme that can use TOBE arrays to achieve nearly isotropic focusing throughout an expansive volume. This approach extends upon a similar volumetric imaging scheme, Hadamard Encoded Row Column Ultrasonic Expansive Scanning (HERCULES), that is even able to image beyond the shadow of the aperture, much like typical 2D matrix probes. We simulate a grid of scatterers to evaluate how the resolution varies across the volume, and validate these simulations experimentally using a commercial calibration phantom. Experimental measurements were done with a custom fabricated TOBE array, custom biasing electronics, and a research ultrasound system. Finally we performed ex-vivo imaging to assess our ability to discern structural tissue information.", "AI": {"tldr": "本文提出了一种名为OPTIMUS的新型超声成像方案，利用TOBE（Top-Orthogonal-to-Bottom-Electrode）阵列，实现了近乎各向同性的聚焦和更宽的视野，克服了传统阵列的局限性。", "motivation": "现代超声换能器在实现高质量结构体积成像方面存在挑战，包括矩阵探头视场有限、行-列阵（RCAs）聚焦不足等。研究旨在开发一种能够实现各向同性聚焦和宽视场的超声成像技术。", "method": "提出了一种名为OPTIMUS（Orthogonal Plane-Wave Transmit-Receive Isotropic-Focusing Micro-Ultrasound）的新型成像方案，该方案使用TOBE（Top-Orthogonal-to-Bottom-Electrode）阵列，该阵列也称为偏置可切换RCAs。研究通过模拟散射体网格来评估分辨率，并使用商用校准模型和定制TOBE阵列、偏置电子设备及研究用超声系统进行实验验证。最后，进行了离体组织成像。", "result": "OPTIMUS方案能够实现近乎各向同性的聚焦，并覆盖比传统RCA更广阔的体积。研究证明，该方法能够提供优于现有技术的体积成像能力，并且在离体成像中能够分辨结构组织信息。", "conclusion": "OPTIMUS成像方案结合TOBE阵列，能够实现高质量的体积超声成像，克服了传统阵列的视场和聚焦限制，有望在医学成像领域取得重要应用。"}}
{"id": "2601.20298", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.20298", "abs": "https://arxiv.org/abs/2601.20298", "authors": ["Omid Akbarzadeh", "MohammadHossein Ashoori", "Amy Nejati", "Abolfazl Lavaei"], "title": "A Data-Driven Krasovskii-Based Approach for Safety Controller Design of Time-Delayed Uncertain Polynomial Systems", "comment": null, "summary": "We develop a data-driven framework for the synthesis of robust Krasovskii control barrier certificates (RK-CBC) and corresponding robust safety controllers (R-SC) for discrete-time input-affine uncertain polynomial systems with unknown dynamics, while explicitly accounting for unknown-but-bounded disturbances and time-invariant delays using only observed input-state data. Although control barrier certificates have been extensively studied for safety analysis of control systems, existing work on unknown systems with time delays, particularly in the presence of disturbances, remains limited. The challenge of safety synthesis for such systems stems from two main factors: first, the system's mathematical model is unavailable; and second, the safety conditions should explicitly incorporate the effects of time delays on system evolution during the synthesis process, while remaining robust to unknown disturbances. To address these challenges, we develop a data-driven framework based on Krasovskii control barrier certificates, extending the classical CBC formulation for delay-free systems to explicitly account for time delays by aggregating delayed components within the barrier construction. The proposed framework relies solely on input-state data collected over a finite time horizon, enabling the direct synthesis of RK-CBC and R-SC from observed trajectories without requiring an explicit system model. The synthesis is cast as a data-driven sum-of-squares (SOS) optimization program, yielding a structured design methodology. As a result, robust safety is guaranteed in the presence of unknown disturbances and time delays over an infinite time horizon. The effectiveness of the proposed method is demonstrated through three case studies, including two physical systems.", "AI": {"tldr": "本研究提出了一种数据驱动的框架，用于合成鲁棒的Krasovskii控制障碍证书（RK-CBC）和鲁棒安全控制器（R-SC），用于处理具有未知动力学、未知但有界干扰和时滞的离散时间输入仿射不确定多项式系统。", "motivation": "现有控制障碍证书（CBC）方法在处理未知系统、时滞和干扰方面存在局限性，尤其是在系统模型未知的情况下。本研究旨在解决这些挑战，实现鲁棒安全合成。", "method": "提出了一种基于Krasovskii控制障碍证书的数据驱动框架，通过聚合延迟分量来扩展经典的CBC方法以处理时滞。该框架仅使用有限时间范围内的输入-状态数据，无需显式系统模型，并通过数据驱动的平方和（SOS）优化程序进行合成。", "result": "所提出的方法能够保证在存在未知干扰和时滞的情况下，系统在无限时间范围内是鲁棒安全的。通过三个案例研究（包括两个物理系统）验证了方法的有效性。", "conclusion": "该数据驱动框架能够仅凭观测数据合成鲁棒的Krasovskii控制障碍证书和安全控制器，有效解决了未知系统、时滞和干扰下的鲁棒安全合成问题。"}}
{"id": "2601.20183", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.20183", "abs": "https://arxiv.org/abs/2601.20183", "authors": ["Yuhua Zhao", "Tiejun Lv", "Ke Wang"], "title": "C-AoEI-Aware Cross-Layer Optimization in Satellite IoT Systems: Balancing Data Freshness and Transmission Efficiency", "comment": "18 pages, 13 figures, IEEE Internet of Things Journal, Accepted", "summary": "Satellite-based Internet of Things (S-IoT) faces a fundamental trilemma: propagation delay, dynamic fading, and bandwidth scarcity. While Layer-coded Hybrid ARQ (L-HARQ) enhances reliability, its backtracking decoding introduces age ambiguity, undermining the standard Age of Information (AoI) metric and obscuring the critical trade-off between data freshness and transmission efficiency. To bridge this gap, we propose a novel cross-layer optimization framework centered on a new metric, the Cross-layer Age of Error Information (C-AoEI). We derive a closed-form expression for C-AoEI, explicitly linking freshness to system parameters, establishing an explicit analytical connection between freshness degradation and channel dynamics. Building on this, we develop a packet-level encoded L-HARQ scheme for multi-GBS scenarios and an adaptive algorithm that jointly optimizes coding and decision thresholds. Extensive simulations demonstrate the effectiveness of our proposed framework: it achieves 31.8% higher transmission efficiency and 17.2% lower C-AoEI than conventional schemes. The framework also proves robust against inter-cell interference and varying channel conditions, providing a foundation for designing efficient, latency-aware next-generation S-IoT protocols.", "AI": {"tldr": "提出了一种基于交叉层优化的新框架，引入了交叉层错误信息年龄（C-AoEI）度量，以解决卫星物联网（S-IoT）中的延迟、衰落和带宽稀缺问题。该框架通过优化编码和决策阈值来提高传输效率和数据新鲜度。", "motivation": "传统的混合ARQ（L-HARQ）在解决S-IoT的可靠性问题时，其回溯解码会引入年龄模糊性，使得标准的年龄信息（AoI）度量失效，无法有效权衡数据新鲜度和传输效率。因此，需要一个新的度量和框架来解决这个问题。", "method": "提出了一种新的交叉层优化框架，并引入了交叉层错误信息年龄（C-AoEI）度量。推导了C-AoEI的闭式表达式，并开发了一种适用于多GBS场景的分组级编码L-HARQ方案以及一种联合优化编码和决策阈值的自适应算法。", "result": "仿真结果表明，该框架比传统方案的传输效率提高了31.8%，C-AoEI降低了17.2%。该框架对小区间干扰和变化的信道条件表现出鲁棒性。", "conclusion": "提出的交叉层优化框架和C-AoEI度量能够有效解决S-IoT中的年龄模糊问题，并在传输效率和数据新鲜度之间取得更好的权衡。该框架为设计高效、低延迟的下一代S-IoT协议奠定了基础。"}}
{"id": "2601.20005", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.20005", "abs": "https://arxiv.org/abs/2601.20005", "authors": ["Zixin Jiang", "Weili Xu", "Bing Dong"], "title": "OptAgent: an Agentic AI framework for Intelligent Building Operations", "comment": null, "summary": "The urgent need for building decarbonization calls for a paradigm shift in future autonomous building energy operation, from human-intensive engineering workflows toward intelligent agents that interact with physics-grounded digital environments. This study proposes an end-to-end agentic AI-enabled Physics-Informed Machine Learning (PIML) environment for scalable building energy modeling, simulation, control, and automation. The framework consists of (1) a modular and physics-consistent PIML digital environment spanning building thermal dynamics, Heating, Ventilation, and Air Conditioning (HVAC), and distributed energy resources (DER) for grid-interactive energy management; and (2) an agentic AI layer with 11 specialist agents and 72 Model Context Protocol (MCP) tools that enable end-to-end execution of multi-step energy analytics. A representative case study demonstrates multi-domain, multi-agent coordination for assessing how system and control upgrades affect energy use, operating cost, thermal comfort, and flexibility. In addition, a large-scale benchmark (about 4000 runs) systematically evaluates workflow performance in terms of accuracy, token consumption, execution time, and inference cost. The results quantify the impacts of intelligence mode design, model size, task complexity, and orchestrator-specialist coordination, and provide key lessons for building future agentic AI systems in real-world building energy applications. This work establishes a scalable, physics-grounded foundation for deploying agentic AI in decarbonized and grid-interactive building operations.", "AI": {"tldr": "本研究提出一个端到端的、基于AI的物理信息机器学习（PIML）环境，用于建筑能源建模、仿真、控制和自动化，旨在实现自主化的建筑能源运行，并进行了案例研究和大规模基准测试以评估其性能。", "motivation": "应对建筑脱碳的紧迫需求，推动建筑能源运行从人工密集型工作流程转向与物理基础的数字环境交互的智能代理。", "method": "构建了一个模块化、物理一致的PIML数字环境，涵盖建筑热力学、HVAC和分布式能源资源（DER）。在此基础上，开发了一个包含11个专业代理和72个MCP工具的AI层，实现了多步能源分析的端到端执行。", "result": "通过案例研究展示了多领域、多代理协调的能力，评估了系统和控制升级对能源使用、运行成本、热舒适性和灵活性的影响。大规模基准测试量化了智能模式设计、模型大小、任务复杂性和协调器-专家协调等因素对工作流程性能（准确性、token消耗、执行时间和推理成本）的影响。", "conclusion": "该研究建立了一个可扩展、物理基础的框架，为在现实世界的建筑能源应用中部署自主AI奠定了基础，为构建未来的自主AI系统提供了关键经验。"}}
{"id": "2601.20051", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.20051", "abs": "https://arxiv.org/abs/2601.20051", "authors": ["Gautham Vinod", "Bruce Coburn", "Siddeshwar Raghavan", "Jiangpeng He", "Fengqing Zhu"], "title": "Size Matters: Reconstructing Real-Scale 3D Models from Monocular Images for Food Portion Estimation", "comment": null, "summary": "The rise of chronic diseases related to diet, such as obesity and diabetes, emphasizes the need for accurate monitoring of food intake. While AI-driven dietary assessment has made strides in recent years, the ill-posed nature of recovering size (portion) information from monocular images for accurate estimation of ``how much did you eat?'' is a pressing challenge. Some 3D reconstruction methods have achieved impressive geometric reconstruction but fail to recover the crucial real-world scale of the reconstructed object, limiting its usage in precision nutrition. In this paper, we bridge the gap between 3D computer vision and digital health by proposing a method that recovers a true-to-scale 3D reconstructed object from a monocular image. Our approach leverages rich visual features extracted from models trained on large-scale datasets to estimate the scale of the reconstructed object. This learned scale enables us to convert single-view 3D reconstructions into true-to-life, physically meaningful models. Extensive experiments and ablation studies on two publicly available datasets show that our method consistently outperforms existing techniques, achieving nearly a 30% reduction in mean absolute volume-estimation error, showcasing its potential to enhance the domain of precision nutrition. Code: https://gitlab.com/viper-purdue/size-matters", "AI": {"tldr": "提出了一种从单目图像中恢复真实尺寸 3D 重建模型的方法，以解决 AI 饮食评估中食物份量估算的挑战，并在体积估算误差方面取得了显著改进。", "motivation": "与饮食相关的慢性病（如肥胖和糖尿病）的增加，凸显了准确监测食物摄入量的需求。尽管 AI 驱动的饮食评估取得了进展，但从单目图像中恢复真实尺寸信息以准确估算“吃了多少”仍然是一个挑战。", "method": "利用从大型数据集训练的模型中提取的丰富视觉特征来估计重建对象的尺度，将单视图 3D 重建转换为真实、物理上有意义的模型。", "result": "在两个公开数据集上的大量实验和消融研究表明，该方法在体积估算误差方面比现有技术平均减少了近 30%。", "conclusion": "该方法成功地将 3D 计算机视觉与数字健康相结合，能够从单目图像中恢复真实尺寸的 3D 重建对象，有望提升精准营养的水平。"}}
{"id": "2601.19913", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19913", "abs": "https://arxiv.org/abs/2601.19913", "authors": ["Shinwoo Park", "Yo-Sub Han"], "title": "From Intuition to Expertise: Rubric-Based Cognitive Calibration for Human Detection of LLM-Generated Korean Text", "comment": null, "summary": "Distinguishing human-written Korean text from fluent LLM outputs remains difficult even for linguistically trained readers, who can over-trust surface well-formedness. We study whether expert detection can be treated as a learnable skill and improved through structured calibration. We introduce LREAD, a rubric derived from national Korean writing standards and adapted to target micro-level artifacts (e.g., punctuation optionality, spacing behavior, and register shifts). In a three-phase longitudinal blind protocol with Korean linguistics majors, Phase 1 measures intuition-only detection, Phase 2 enforces criterion-level scoring with explicit justifications, and Phase 3 evaluates domain-focused mastery on held-out elementary essays. Across phases, majority-vote accuracy increases from 60% to 100%, accompanied by stronger inter-annotator agreement (Fleiss' kappa: -0.09 --> 0.82). Compared to state-of-the-art LLM detectors, calibrated humans rely more on language-specific micro-diagnostics that are not well captured by coarse discourse priors. Our findings suggest that rubric-scaffolded expert judgment can serve as an interpretable complement to automated detectors for non-English settings, and we release the full rubric and a taxonomy of calibrated detection signatures.", "AI": {"tldr": "本研究提出了一种名为 LREAD 的结构化校准方法，通过使用基于韩国写作标准的细微指标（如标点、空格和语域变化）来提高人类区分韩语人类文本和 LLM 生成文本的能力。结果表明，经过校准的人类专家在区分能力上有了显著提高。", "motivation": "现有方法难以区分人类书写的韩语文本和流畅的 LLM 输出，即使是语言学专家也容易过度信任表面上的良好表达。研究人员希望探索专家检测是否可以被视为一种可学习的技能，并通过结构化校准来改进。", "method": "研究人员开发了一种名为 LREAD 的评估标准，该标准源自韩国国家写作标准，并针对微观层面的文本特征（如标点可选性、空格行为和语域转移）进行了调整。实验采用三阶段的纵向盲法协议，招募了韩国语言学专业的学生。第一阶段仅凭直觉进行检测；第二阶段强制进行标准层面的评分，并要求明确的理由；第三阶段评估在未见过的小学作文上的领域集中掌握程度。", "result": "在实验过程中，多数投票的准确率从 60% 提高到 100%，同时评分者之间的一致性也显著增强（Fleiss' kappa 从 -0.09 提高到 0.82）。与最先进的 LLM 检测器相比，经过校准的人类专家更侧重于语言特定的微观诊断，而这些诊断并未被粗粒度的语篇先验很好地捕捉。", "conclusion": "研究结果表明，基于评估标准结构化的专家判断可以作为非英语环境中自动检测器的可解释补充。研究者发布了完整的评估标准以及校准检测签名的分类体系。"}}
{"id": "2601.20135", "categories": ["eess.SY", "q-bio.MN"], "pdf": "https://arxiv.org/pdf/2601.20135", "abs": "https://arxiv.org/abs/2601.20135", "authors": ["Domitilla Del Vecchio"], "title": "Control systems for synthetic biology and a case-study in cell fate reprogramming", "comment": null, "summary": "This paper gives an overview of the use of control systems engineering in synthetic biology, motivated by applications such as cell therapy and cell fate reprogramming for regenerative medicine. A ubiquitous problem in these and other applications is the ability to control the concentration of specific regulatory factors in the cell accurately despite environmental uncertainty and perturbations. The paper describes the origin of these perturbations and how they affect the dynamics of the biomolecular ``plant'' to be controlled. A variety of biomolecular control implementations are then introduced to achieve robustness of the plant's output to perturbations and are grouped into feedback and feedforward control architectures. Although sophisticated control laws can be implemented in a computer today, they cannot be necessarily implemented inside the cell via biomolecular processes. This fact constraints the set of feasible control laws to those realizable through biomolecular processes that can be engineered with synthetic biology. After reviewing biomolecular feedback and feedforward control implementations, mostly focusing on the author's own work, the paper illustrates the application of such control strategies to cell fate reprogramming. Within this context, a master regulatory factor needs to be controlled at a specific level inside the cell in order to reprogram skin cells to pluripotent stem cells. The article closes by highlighting on-going challenges and directions of future research for biomolecular control design.", "AI": {"tldr": "本文概述了控制系统工程在合成生物学中的应用，特别是如何在细胞内精确控制调控因子浓度，以应对环境扰动，并着重介绍了反馈和前馈控制策略在细胞命运重编程等领域的应用，同时指出了该领域面临的挑战和未来研究方向。", "motivation": "细胞疗法和用于再生医学的细胞命运重编程等应用需要精确控制细胞内的调控因子浓度，以应对环境不确定性和扰动。", "method": "文章描述了扰动的来源及其对生物分子“植物”动力学的影响，并介绍了实现对扰动稳健输出的多种生物分子控制实现方式，将其分为反馈和前馈控制架构。重点介绍了作者自身的研究成果，并通过细胞命运重编程的例子说明了这些控制策略的应用。", "result": "文章通过细胞命运重编程的例子，展示了如何通过控制主调控因子在细胞内的特定水平，将皮肤细胞重编程为多能干细胞。", "conclusion": "生物分子控制设计在合成生物学领域具有重要应用前景，但仍面临一些挑战，需要进一步的研究来克服，以设计出更有效的生物分子控制策略。"}}
{"id": "2601.19969", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19969", "abs": "https://arxiv.org/abs/2601.19969", "authors": ["Haoyuan Deng", "Yuanjiang Xue", "Haoyang Du", "Boyang Zhou", "Zhenyu Wu", "Ziwei Wang"], "title": "E2HiL: Entropy-Guided Sample Selection for Efficient Real-World Human-in-the-Loop Reinforcement Learning", "comment": "Project page: https://e2hil.github.io/", "summary": "Human-in-the-loop guidance has emerged as an effective approach for enabling faster convergence in online reinforcement learning (RL) of complex real-world manipulation tasks. However, existing human-in-the-loop RL (HiL-RL) frameworks often suffer from low sample efficiency, requiring substantial human interventions to achieve convergence and thereby leading to high labor costs. To address this, we propose a sample-efficient real-world human-in-the-loop RL framework named \\method, which requires fewer human intervention by actively selecting informative samples. Specifically, stable reduction of policy entropy enables improved trade-off between exploration and exploitation with higher sample efficiency. We first build influence functions of different samples on the policy entropy, which is efficiently estimated by the covariance of action probabilities and soft advantages of policies. Then we select samples with moderate values of influence functions, where shortcut samples that induce sharp entropy drops and noisy samples with negligible effect are pruned. Extensive experiments on four real-world manipulation tasks demonstrate that \\method achieves a 42.1\\% higher success rate while requiring 10.1\\% fewer human interventions compared to the state-of-the-art HiL-RL method, validating its effectiveness. The project page providing code, videos, and mathematical formulations can be found at https://e2hil.github.io/.", "AI": {"tldr": "提出了一种名为 \\method 的样本高效的真实世界人机循环强化学习框架，通过主动选择信息量大的样本来减少人类干预，提高了策略熵的稳定性，并在真实世界操纵任务上取得了显著的成功率提升和更少的人类干预。", "motivation": "现有的人机循环强化学习（HiL-RL）框架样本效率低下，需要大量的人类干预才能收敛，导致劳动成本高。", "method": "通过构建不同样本对策略熵的影响函数（通过动作概率和策略的软优势的协方差估计），并选择影响函数具有中等值的样本来主动选择信息量大的样本，从而修剪导致熵急剧下降的捷径样本和影响可忽略的噪声样本。利用策略熵的稳定下降来改进探索与利用之间的权衡。", "result": "在四个真实的操纵任务上进行的广泛实验表明，\\method 取得了比现有最先进的 HiL-RL 方法高 42.1% 的成功率，同时需要的人类干预减少了 10.1%。", "conclusion": "\\method 是一种样本高效的真实世界人机循环强化学习框架，通过主动选择信息量大的样本，能够显著减少人类干预，提高学习效率和性能。"}}
{"id": "2601.19955", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.19955", "abs": "https://arxiv.org/abs/2601.19955", "authors": ["Jean-Marc Fellous", "Gert Cauwenberghs", "Cornelia Fermüller", "Yulia Sandamisrkaya", "Terrence Sejnowski"], "title": "NeuroAI and Beyond", "comment": "53 pages, 5 figures, extended appendix", "summary": "Neuroscience and Artificial Intelligence (AI) have made significant progress in the past few years but have only been loosely inter-connected. Based on a workshop held in August 2025, we identify current and future areas of synergism between these two fields. We focus on the subareas of embodiment, language and communication, robotics, learning in humans and machines and Neuromorphic engineering to take stock of the progress made so far, and possible promising new future avenues. Overall, we advocate for the development of NeuroAI, a type of Neuroscience-informed Artificial Intelligence that, we argue, has the potential for significantly improving the scope and efficiency of AI algorithms while simultaneously changing the way we understand biological neural computations. We include personal statements from several leading researchers on their diverse views of NeuroAI. Two Strength-Weakness-Opportunities-Threat (SWOT) analyses by researchers and trainees are appended that describe the benefits and risks offered by NeuroAI.", "AI": {"tldr": "本文基于2025年8月的研讨会，探讨了神经科学和人工智能（AI）的协同作用，提出了“神经AI”（NeuroAI）的概念，即受神经科学启发的AI，并展望了其在具身性、语言、机器人、学习和神经形态工程等领域的未来发展。", "motivation": "尽管神经科学和AI各自取得了显著进展，但两者之间的联系却较为松散。研究者们希望通过本次研讨会，发掘这两个领域协同的潜力，并推动AI的发展。", "method": "通过组织研讨会，收集当前和未来的协同领域，重点关注具身性、语言与沟通、机器人、人机学习和神经形态工程。此外，还包含了研究人员的个人陈述和SWOT分析。", "result": "识别了神经科学和AI的协同领域，提出了NeuroAI的概念，并认为其有望提高AI算法的范围和效率，同时加深对生物神经计算的理解。SWOT分析揭示了NeuroAI的优势、劣势、机会和威胁。", "conclusion": "NeuroAI（受神经科学启发的AI）具有显著的潜力，能够提升AI能力并深化对生物神经计算的理解。研究人员和受训者对NeuroAI的益处和风险进行了SWOT分析，强调了其发展方向和潜在挑战。"}}
{"id": "2601.20314", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.20314", "abs": "https://arxiv.org/abs/2601.20314", "authors": ["Xinran Wang", "Peng Wu", "Xiaopeng Yuan", "Yulin Hu", "Anke Schmeink"], "title": "Efficient Trajectory Design and Communication Scheduling for Dual-UAV Jamming-Aided Secure Communication Networks", "comment": null, "summary": "We study dual-unmanned aerial vehicle (UAV) jamming-aided secure communication networks, in which one UAV delivers confidential data to multiple ground users (GUs), while a cooperative UAV provides protective interference against a ground eavesdropper. To enforce fairness, we maximize the minimum secrecy throughput across GUs by jointly designing trajectories and communication scheduling. The key difficulty lies in the continuous-time nature of UAV trajectories and the tight space-time coupling between the transmitter and the jammer, which jointly render the problem infinite-dimensional and nonconvex. To address these challenges, we characterize, for the first time, the structure of the optimal trajectories and rigorously prove that they follow a collaborative successive hover-and-fly (co-SHF) structure, where the two UAVs visit a limited number of synchronized co-hovering point pairs, and during each flight segment at least one UAV moves at maximum speed. Leveraging this structure, we reformulate the problem into a finite-dimensional form, without loss of optimality, over hovering and turning points, hovering durations, and scheduling. For tractability, we adopt a minimum-distance approximation of continuous anti-collision constraints and employ concave lower bounds on secrecy throughput within a successive convex approximation (SCA) method, which converges and, thanks to the co-SHF reduction in optimization variables and constraints, achieves low computational complexity. Numerical results show that, compared with time-discretization and no-jamming benchmarks, the proposed co-SHF design improves the min-secrecy and user fairness while requiring significantly less runtime.", "AI": {"tldr": "本研究提出了一种基于双无人机（UAV）协同干扰辅助的安全通信网络模型，旨在通过联合设计无人机轨迹和通信调度来最大化用户公平性下的最小保密吞吐量。研究证明了最优轨迹遵循一种协同逐次悬停-飞行（co-SHF）结构，并提出了一种基于连续体近似和逐次凸近似（SCA）的方法来求解该非凸问题。仿真结果表明，所提出的co-SHF设计在提高最小保密速率和用户公平性方面优于现有方法，且计算复杂度更低。", "motivation": "现有安全通信网络在处理用户公平性和无人机轨迹优化方面的挑战，特别是连续轨迹和时空耦合带来的无限维度和非凸问题，促使研究人员寻求一种新的解决方案。", "method": "首先，通过理论分析确定了最优轨迹的协同逐次悬停-飞行（co-SHF）结构。然后，将无限维问题转化为有限维问题，优化悬停和转弯点、悬停时长以及调度。接着，采用连续体反碰撞约束的最小距离近似，并利用保密吞吐量的凹下界，结合逐次凸近似（SCA）方法进行求解。", "result": "研究证明了最优轨迹的co-SHF结构。所提出的co-SHF设计在最大化最小保密吞吐量方面表现出色，显著提高了用户公平性。与时间离散化和无干扰基准相比，该方法所需的计算时间更少。", "conclusion": "双无人机协同干扰辅助下的安全通信网络可以通过协同逐次悬停-飞行（co-SHF）轨迹设计实现最优的保密通信和用户公平性。所提出的基于SCA的方法能够有效地求解该问题，并在计算效率和性能上优于现有技术。"}}
{"id": "2601.20064", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20064", "abs": "https://arxiv.org/abs/2601.20064", "authors": ["Zhen Yao", "Xin Li", "Taotao Jing", "Shuai Zhang", "Mooi Choo Chuah"], "title": "DiSa: Saliency-Aware Foreground-Background Disentangled Framework for Open-Vocabulary Semantic Segmentation", "comment": "19 pages, 11 figures", "summary": "Open-vocabulary semantic segmentation aims to assign labels to every pixel in an image based on text labels. Existing approaches typically utilize vision-language models (VLMs), such as CLIP, for dense prediction. However, VLMs, pre-trained on image-text pairs, are biased toward salient, object-centric regions and exhibit two critical limitations when adapted to segmentation: (i) Foreground Bias, which tends to ignore background regions, and (ii) Limited Spatial Localization, resulting in blurred object boundaries. To address these limitations, we introduce DiSa, a novel saliency-aware foreground-background disentangled framework. By explicitly incorporating saliency cues in our designed Saliency-aware Disentanglement Module (SDM), DiSa separately models foreground and background ensemble features in a divide-and-conquer manner. Additionally, we propose a Hierarchical Refinement Module (HRM) that leverages pixel-wise spatial contexts and enables channel-wise feature refinement through multi-level updates. Extensive experiments on six benchmarks demonstrate that DiSa consistently outperforms state-of-the-art methods.", "AI": {"tldr": "本文提出了一种名为DiSa的新型框架，用于解决开放词汇语义分割中Vision-Language Models (VLMs)存在的背景忽略和空间定位不精确问题，通过显式引入显著性线索，分离前景和背景特征，并利用层次化细化模块提升边界精度，在多项基准测试中取得SOTA效果。", "motivation": "现有基于VLMs的开放词汇语义分割方法存在前景偏见（忽略背景）和空间定位能力有限（边界模糊）的缺点。", "method": "提出DiSa框架，包含：1. 显著性感知解耦模块（SDM），通过引入显著性线索，独立处理前景和背景特征；2. 层次化细化模块（HRM），利用像素级空间上下文和多级通道特征更新，提升空间定位精度。", "result": "在六个基准测试中，DiSa均优于现有最先进的方法。", "conclusion": "DiSa通过前景背景解耦和层次化细化，有效解决了现有VLMs在开放词汇语义分割中的局限性，并取得了优异的性能。"}}
{"id": "2601.20575", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20575", "abs": "https://arxiv.org/abs/2601.20575", "authors": ["Jia Fu", "Litingyu Wang", "He Li", "Zihao Luo", "Huamin Wang", "Chenyuan Bian", "Zijun Gao", "Chunbin Gu", "Xin Weng", "Jianghao Wu", "Yicheng Wu", "Jin Ye", "Linhao Li", "Yiwen Ye", "Yong Xia", "Elias Tappeiner", "Fei He", "Abdul qayyum", "Moona Mazher", "Steven A Niederer", "Junqiang Chen", "Chuanyi Huang", "Lisheng Wang", "Zhaohu Xing", "Hongqiu Wang", "Lei Zhu", "Shichuan Zhang", "Shaoting Zhang", "Wenjun Liao", "Guotai Wang"], "title": "SegRap2025: A Benchmark of Gross Tumor Volume and Lymph Node Clinical Target Volume Segmentation for Radiotherapy Planning of Nasopharyngeal Carcinoma", "comment": null, "summary": "Accurate delineation of Gross Tumor Volume (GTV), Lymph Node Clinical Target Volume (LN CTV), and Organ-at-Risk (OAR) from Computed Tomography (CT) scans is essential for precise radiotherapy planning in Nasopharyngeal Carcinoma (NPC). Building upon SegRap2023, which focused on OAR and GTV segmentation using single-center paired non-contrast CT (ncCT) and contrast-enhanced CT (ceCT) scans, the SegRap2025 challenge aims to enhance the generalizability and robustness of segmentation models across imaging centers and modalities. SegRap2025 comprises two tasks: Task01 addresses GTV segmentation using paired CT from the SegRap2023 dataset, with an additional external testing set to evaluate cross-center generalization, and Task02 focuses on LN CTV segmentation using multi-center training data and an unseen external testing set, where each case contains paired CT scans or a single modality, emphasizing both cross-center and cross-modality robustness. This paper presents the challenge setup and provides a comprehensive analysis of the solutions submitted by ten participating teams. For GTV segmentation task, the top-performing models achieved average Dice Similarity Coefficient (DSC) of 74.61% and 56.79% on the internal and external testing cohorts, respectively. For LN CTV segmentation task, the highest average DSC values reached 60.24%, 60.50%, and 57.23% on paired CT, ceCT-only, and ncCT-only subsets, respectively. SegRap2025 establishes a large-scale multi-center, multi-modality benchmark for evaluating the generalization and robustness in radiotherapy target segmentation, providing valuable insights toward clinically applicable automated radiotherapy planning systems. The benchmark is available at: https://hilab-git.github.io/SegRap2025_Challenge.", "AI": {"tldr": "SegRap2025 挑战旨在提高鼻咽癌放疗靶区（GTV 和 LN CTV）分割模型的泛化性和鲁棒性，涉及多中心、多模态 CT 数据。挑战结果表明，GTV 分割在内部测试集上平均 DSC 达到 74.61%，外部测试集上为 56.79%；LN CTV 分割在配对 CT、仅 ceCT 和仅 ncCT 的测试集上平均 DSC 分别为 60.24%、60.50% 和 57.23%。", "motivation": "提高鼻咽癌放疗靶区（GTV、LN CTV）和危及器官（OAR）分割模型的泛化性和鲁棒性，以应对不同影像中心和模态的挑战，最终实现临床上可用的自动化放疗规划系统。", "method": "SegRap2025 挑战包含两个任务：任务 01 针对 GTV 分割，使用 SegRap2023 的配对 CT 数据集，并增加外部测试集以评估跨中心泛化能力；任务 02 针对 LN CTV 分割，使用多中心训练数据和未见过的外部测试集，其中包含配对 CT 或单模态 CT，以评估跨中心和跨模态的鲁棒性。文章分析了十个参赛团队提交的解决方案。", "result": "对于 GTV 分割任务，最佳模型在内部和外部测试集上的平均 DSC 分别为 74.61% 和 56.79%。对于 LN CTV 分割任务，在配对 CT、仅 ceCT 和仅 ncCT 的子集上，最高平均 DSC 分别为 60.24%、60.50% 和 57.23%。", "conclusion": "SegRap2025 挑战建立了一个大规模、多中心、多模态的基准，用于评估放疗靶区分割的泛化性和鲁棒性，为开发临床可用的自动化放疗规划系统提供了宝贵的见解。"}}
{"id": "2601.19914", "categories": ["cs.CL", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19914", "abs": "https://arxiv.org/abs/2601.19914", "authors": ["Maxwell Crouse", "Ibrahim Abdelaziz", "Kshitij Fadnis", "Siva Sankalp Patel", "Kinjal Basu", "Chulaka Gunasekara", "Sadhana Kumaravel", "Asim Munawar", "Pavan Kapanipathi"], "title": "Simulating Complex Multi-Turn Tool Calling Interactions in Stateless Execution Environments", "comment": null, "summary": "Synthetic data has proven itself to be a valuable resource for tuning smaller, cost-effective language models to handle the complexities of multi-turn tool calling conversations. While many frameworks and systems for producing synthetic multi-turn tool calling data have been proposed, prior works have frequently assumed that any tool calling interactions will take place in an execution environment that maintains state. When such an environment is available, this is advantageous as it allows for the validity of an interaction to be determined by whether or not the state of the execution environment matches to some prespecified objective. Unfortunately, this does not hold in many real-world tool use settings, e.g., in enterprise settings where data security is of the utmost importance or in cases where tool specifications are synthesized from multiple sources. In this work, we address this gap by introducing a data generation method, DiGiT-TC, that is designed to produce tool calling conversations that have the characteristics of conversations generated through search in a stateful environment. The key to our technique lies in a novel generation pattern that allows our approach to implicitly represent certain tool calls in the user request. We validate our approach on standard tool calling benchmarks and demonstrate that, even in stateful problem settings, our approach results in strong performance gains.", "AI": {"tldr": "提出了一种名为DiGiT-TC的数据生成方法，用于创建无需状态维持即可模拟有状态工具调用交互的合成多轮对话数据，并在标准工具调用基准测试中取得了显著的性能提升。", "motivation": "现有合成多轮工具调用数据生成方法通常假设存在一个有状态的执行环境，这在数据安全至关重要或工具规范合成的实际场景中不适用。本研究旨在弥补这一差距。", "method": "提出了一种名为DiGiT-TC的数据生成方法。该方法通过一种新颖的生成模式，能够隐式地在用户请求中表示某些工具调用，从而模拟有状态环境下的交互特性，而无需实际的状态维持。", "result": "在标准工具调用基准测试中进行了验证，证明了DiGiT-TC方法即使在有状态问题设置下，也能带来强劲的性能提升。", "conclusion": "DiGiT-TC方法成功地生成了具有有状态交互特性的合成工具调用对话数据，且无需依赖实际的状态维持环境，并在实验中取得了优于现有方法的性能。"}}
{"id": "2601.20014", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20014", "abs": "https://arxiv.org/abs/2601.20014", "authors": ["Shuhui Qu"], "title": "Teaching LLMs to Ask: Self-Querying Category-Theoretic Planning for Under-Specified Reasoning", "comment": null, "summary": "Inference-time planning with large language models frequently breaks under partial observability: when task-critical preconditions are not specified at query time, models tend to hallucinate missing facts or produce plans that violate hard constraints. We introduce \\textbf{Self-Querying Bidirectional Categorical Planning (SQ-BCP)}, which explicitly represents precondition status (\\texttt{Sat}/\\texttt{Viol}/\\texttt{Unk}) and resolves unknowns via (i) targeted self-queries to an oracle/user or (ii) \\emph{bridging} hypotheses that establish the missing condition through an additional action. SQ-BCP performs bidirectional search and invokes a pullback-based verifier as a categorical certificate of goal compatibility, while using distance-based scores only for ranking and pruning. We prove that when the verifier succeeds and hard constraints pass deterministic checks, accepted plans are compatible with goal requirements; under bounded branching and finite resolution depth, SQ-BCP finds an accepting plan when one exists. Across WikiHow and RecipeNLG tasks with withheld preconditions, SQ-BCP reduces resource-violation rates to \\textbf{14.9\\%} and \\textbf{5.8\\%} (vs.\\ \\textbf{26.0\\%} and \\textbf{15.7\\%} for the best baseline), while maintaining competitive reference quality.", "AI": {"tldr": "提出了一种名为 SQ-BCP 的新方法，用于解决大型语言模型在推理时规划中的部分可观测性问题，通过显式地表示和解决条件状态的不确定性，显著提高了规划的可靠性，降低了资源违反率。", "motivation": "现有的推理时规划方法在部分可观测性（即任务关键前提条件缺失）时表现不佳，容易出现事实幻觉或生成违反硬约束的计划。", "method": "提出 SQ-BCP 方法，它显式表示前提条件的状态（Sat/Viol/Unk），并通过（i）定向自查询或（ii）“桥接”假设来解决未知状态。SQ-BCP 执行双向搜索，使用基于回拉的验证器作为目标兼容性的分类证书，并利用基于距离的评分进行排序和剪枝。", "result": "在 WikiHow 和 RecipeNLG 数据集上，通过隐藏前提条件进行测试，SQ-BCP 将资源违反率从基线的 26.0% 和 15.7% 显著降低到 14.9% 和 5.8%，同时保持了参考计划质量的竞争力。", "conclusion": "SQ-BCP 能够有效解决大型语言模型在部分可观测性下的规划问题，其提出的方法保证了在验证器成功且硬约束通过确定性检查的情况下，生成的计划与目标兼容，并且在有限的搜索深度下能够找到可行解。"}}
{"id": "2601.19972", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19972", "abs": "https://arxiv.org/abs/2601.19972", "authors": ["Kuanqi Cai", "Liding Zhang", "Xinwen Su", "Kejia Chen", "Chaoqun Wang", "Sami Haddadin", "Alois Knoll", "Arash Ajoudani", "Luis Figueredo"], "title": "Just in time Informed Trees: Manipulability-Aware Asymptotically Optimized Motion Planning", "comment": null, "summary": "In high-dimensional robotic path planning, traditional sampling-based methods often struggle to efficiently identify both feasible and optimal paths in complex, multi-obstacle environments. This challenge is intensified in robotic manipulators, where the risk of kinematic singularities and self-collisions further complicates motion efficiency and safety. To address these issues, we introduce the Just-in-Time Informed Trees (JIT*) algorithm, an enhancement over Effort Informed Trees (EIT*), designed to improve path planning through two core modules: the Just-in-Time module and the Motion Performance module. The Just-in-Time module includes \"Just-in-Time Edge,\" which dynamically refines edge connectivity, and \"Just-in-Time Sample,\" which adjusts sampling density in bottleneck areas to enable faster initial path discovery. The Motion Performance module balances manipulability and trajectory cost through dynamic switching, optimizing motion control while reducing the risk of singularities. Comparative analysis shows that JIT* consistently outperforms traditional sampling-based planners across $\\mathbb{R}^4$ to $\\mathbb{R}^{16}$ dimensions. Its effectiveness is further demonstrated in single-arm and dual-arm manipulation tasks, with experimental results available in a video at https://youtu.be/nL1BMHpMR7c.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.20711", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2601.20711", "abs": "https://arxiv.org/abs/2601.20711", "authors": ["Oisín Nolan", "Wessel L. van Nierop", "Louis D. van Harten", "Tristan S. W. Stevens", "Ruud J. G. van Sloun"], "title": "Task-Based Adaptive Transmit Beamforming for Efficient Ultrasound Quantification", "comment": null, "summary": "Wireless and wearable ultrasound devices promise to enable continuous ultrasound monitoring, but power consumption and data throughput remain critical challenges. Reducing the number of transmit events per second directly impacts both. We propose a task-based adaptive transmit beamforming method, formulated as a Bayesian active perception problem, that adaptively chooses where to scan in order to gain information about downstream quantitative measurements, avoiding redundant transmit events. Our proposed Task-Based Information Gain (TBIG) strategy applies to any differentiable downstream task function. When applied to recovering ventricular dimensions from echocardiograms, TBIG recovers accurate results using fewer than 2% of scan lines typically used, showing potential for large reductions in the power usage and data rates necessary for monitoring. Code is available at https://github.com/tue-bmd/task-based-ulsa.", "AI": {"tldr": "提出了一种基于任务的自适应超声波束形成方法，通过主动感知选择扫描区域，大幅减少了数据传输量和功耗，并能有效恢复心室尺寸。", "motivation": "无线和可穿戴超声设备在功耗和数据吞吐量方面面临挑战，减少每秒的发送事件数量是关键。", "method": "将方法形式化为贝叶斯主动感知问题，提出了一种任务基于信息增益（TBIG）的策略，用于自适应地选择扫描区域以获取下游定量测量信息，避免冗余发送。", "result": "当应用于从超声心动图恢复心室尺寸时，TBIG策略仅使用通常扫描线的2%即可恢复精确结果，显示出降低功耗和数据速率的巨大潜力。", "conclusion": "所提出的基于任务的自适应束形成方法（TBIG）能够显著减少超声监测所需的数据传输量和功耗，同时保持准确的定量测量能力。"}}
{"id": "2601.20324", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.20324", "abs": "https://arxiv.org/abs/2601.20324", "authors": ["Jingyuan Zhou", "Haoze Wu", "Kaidi Yang"], "title": "Neural Cooperative Reach-While-Avoid Certificates for Interconnected Systems", "comment": null, "summary": "Providing formal guarantees for neural network-based controllers in large-scale interconnected systems remains a fundamental challenge. In particular, using neural certificates to capture cooperative interactions and verifying these certificates at scale is crucial for the safe deployment of such controllers. However, existing approaches fall short on both fronts. To address these limitations, we propose neural cooperative reach-while-avoid certificates with Dynamic-Localized Vector Control Lyapunov and Barrier Functions, which capture cooperative dynamics through state-dependent neighborhood structures and provide decentralized certificates for global exponential stability and safety. Based on the certificates, we further develop a scalable training and verification framework that jointly synthesizes controllers and neural certificates via a constrained optimization objective, and leverages a sufficient condition to ensure formal guarantees considering modeling error. To improve scalability, we introduce a structural reuse mechanism to transfer controllers and certificates between substructure-isomorphic systems. The proposed methodology is validated with extensive experiments on multi-robot coordination and vehicle platoons. Results demonstrate that our framework ensures certified cooperative reach-while-avoid while maintaining strong control performance.", "AI": {"tldr": "该研究提出了一种新的方法，用于为大型互联系统中基于神经网络的控制器提供形式化安全保证。通过引入动态局部向量控制李雅普诺夫和屏障函数，该方法能够捕获协同动力学并提供分散式的稳定性和安全性证书。此外，研究还开发了一个可扩展的训练和验证框架，并提出了结构复用机制以提高效率。实验结果表明，该方法在多机器人协调和车辆编队等任务中，能够确保经过认证的协同规避性到达，同时保持良好的控制性能。", "motivation": "为大型互联系统中基于神经网络的控制器提供形式化安全保证，特别是通过神经网络证书捕获协同交互并进行大规模验证，是安全部署这些控制器的关键挑战。现有方法在这些方面存在不足。", "method": "提出了一种新的神经网络协同规避性到达证书，结合动态局部向量控制李雅普诺夫和屏障函数，通过状态依赖的邻域结构捕获协同动力学，并提供全局指数稳定性和安全性的分散式证书。在此基础上，开发了一个可扩展的训练和验证框架，通过约束优化目标联合合成控制器和神经网络证书，并利用充分条件考虑建模误差以确保形式化保证。为了提高可扩展性，引入了结构复用机制，将控制器和证书在子结构同构系统之间迁移。", "result": "提出的方法在多机器人协调和车辆编队等任务上进行了广泛的实验验证。结果表明，该框架能够确保经过认证的协同规避性到达，同时保持强大的控制性能。", "conclusion": "研究成功开发了一种新颖且可扩展的框架，为大型互联系统中基于神经网络的控制器提供了形式化安全保证。该框架通过引入新的证书设计和训练验证机制，有效地解决了现有方法的局限性，并在实际应用中取得了良好的效果。"}}
{"id": "2601.20072", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20072", "abs": "https://arxiv.org/abs/2601.20072", "authors": ["Atik Faysal", "Mohammad Rostami", "Reihaneh Gh. Roshan", "Nikhil Muralidhar", "Huaxia Wang"], "title": "Semi-Supervised Masked Autoencoders: Unlocking Vision Transformer Potential with Limited Data", "comment": null, "summary": "We address the challenge of training Vision Transformers (ViTs) when labeled data is scarce but unlabeled data is abundant. We propose Semi-Supervised Masked Autoencoder (SSMAE), a framework that jointly optimizes masked image reconstruction and classification using both unlabeled and labeled samples with dynamically selected pseudo-labels. SSMAE introduces a validation-driven gating mechanism that activates pseudo-labeling only after the model achieves reliable, high-confidence predictions that are consistent across both weakly and strongly augmented views of the same image, reducing confirmation bias. On CIFAR-10 and CIFAR-100, SSMAE consistently outperforms supervised ViT and fine-tuned MAE, with the largest gains in low-label regimes (+9.24% over ViT on CIFAR-10 with 10% labels). Our results demonstrate that when pseudo-labels are introduced is as important as how they are generated for data-efficient transformer training. Codes are available at https://github.com/atik666/ssmae.", "AI": {"tldr": "提出了一种名为SSMAE的半监督框架，通过联合优化掩码图像重建和分类，并使用动态选择的伪标签来解决标签数据稀缺但无标签数据丰富的问题，尤其是在标签数据极少的情况下，能显著提升Vision Transformer的性能。", "motivation": "在标签数据稀缺但无标签数据充裕的情况下，训练Vision Transformer（ViT）面临挑战。", "method": "提出Semi-Supervised Masked Autoencoder (SSMAE)框架，该框架联合优化掩码图像重建和分类任务。它利用无标签和有标签样本，并动态选择伪标签。SSMAE引入了一个由验证驱动的门控机制，仅当模型对同一图像的弱增强和强增强视图产生可靠、高置信度的预测且一致时，才激活伪标签，以减少确认偏差。", "result": "在CIFAR-10和CIFAR-100数据集上，SSMAE在所有实验中均优于监督式ViT和微调后的MAE。在标签数据比例极低的情况下（例如CIFAR-10的10%标签），性能提升最为显著，比ViT高出9.24%。", "conclusion": "研究表明，对于数据效率高的Transformer训练而言，伪标签引入的时机与生成方式同等重要。"}}
{"id": "2601.20130", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20130", "abs": "https://arxiv.org/abs/2601.20130", "authors": ["Haoxuan Wang", "Gengyu Zhang", "Yan Yan", "Yuzhang Shang", "Ramana Rao Kompella", "Gaowen Liu"], "title": "Real-Time Robot Execution with Masked Action Chunking", "comment": "ICLR 2026. Project page at https://remac-async.github.io/", "summary": "Real-time execution is essential for cyber-physical systems such as robots. These systems operate in dynamic real-world environments where even small delays can undermine responsiveness and compromise performance. Asynchronous inference has recently emerged as a system-level paradigm for real-time robot manipulation, enabling the next action chunk to be predicted while the current one is being executed. While this approach achieves real-time responsiveness, naive integration often results in execution failure. Previous methods attributed this failure to inter-chunk discontinuity and developed test-time algorithms to smooth chunk boundaries. In contrast, we identify another critical yet overlooked factor: intra-chunk inconsistency, where the robot's executed action chunk partially misaligns with its current perception. To address this, we propose REMAC, which learns corrective adjustments on the pretrained policy through masked action chunking, enabling the policy to remain resilient under mismatches between intended actions and actual execution during asynchronous inference. In addition, we introduce a prefix-preserved sampling procedure to reinforce inter-chunk continuity. Overall, our method delivers more reliable policies without incurring additional latency. Extensive experiments in both simulation and real-world settings demonstrate that our method enables faster task execution, maintains robustness across varying delays, and consistently achieves higher completion rates.", "AI": {"tldr": "提出一种名为REMAC的方法，通过掩码动作分块学习校正调整，以解决异步推理中机器人动作执行与感知不一致的问题，同时通过前缀保留采样增强分块连续性，从而在不增加延迟的情况下提高策略的鲁棒性和任务完成率。", "motivation": "现有异步推理方法在提高机器人实时响应性的同时，存在执行失败的问题。以往研究将失败归因于分块间不连续性，而本文发现了另一个被忽视的关键因素——分块内不一致性（即执行的动作与当前感知不匹配）。", "method": "提出REMAC方法，通过掩码动作分块（masked action chunking）在预训练策略上学习校正性调整，使其能够应对动作意图与实际执行之间的不匹配。同时，引入前缀保留采样（prefix-preserved sampling）来加强分块间的连续性。", "result": "REMAC方法在模拟和真实世界实验中均表现出色，能够实现更快的任务执行速度，在不同延迟下保持鲁棒性，并显著提高任务完成率，且不增加额外的延迟。", "conclusion": "REMAC是一种有效的方法，能够解决异步推理中的分块内不一致性问题，从而提高机器人策略的可靠性和实时性，为开发更强大的机器人系统提供了新的途径。"}}
{"id": "2601.19915", "categories": ["cs.CL", "cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.19915", "abs": "https://arxiv.org/abs/2601.19915", "authors": ["Paul Tarau"], "title": "Modeling Next-Token Prediction as Left-Nested Intuitionistic Implication", "comment": "25 pages", "summary": "We introduce the \\emph{Arrow Language Model}, a neural architecture derived from an intuitionistic-logic interpretation of next-token prediction. Instead of representing tokens as additive embeddings mixed by attention, we encode a prefix as a \\emph{left-nested implication chain} whose structure preserves order through non-commutative composition. Next-token prediction corresponds to \\emph{modus ponens}, and sequence processing becomes constructive proof extension under the Curry--Howard correspondence. Our Prolog-based specialized theorem provers validate fundamental properties of the neural models, among which relations between commutative vs. non-commutative sequencing and single-token vs. multi-token prediction choices. We show that a neural architecture equivalent to multiplicative RNNs arises naturally from a proof-theoretic interpretation of next-token prediction as nested intuitionistic implication, we present a practical low-rank neural realization and position the model relative to Transformers and state-space models.\n  Keywords: logic-based derivation of neural architectures, intuitionistic implicational logic, token-as-operator neural models, state-space models, alternatives to transformer-based foundational models.", "AI": {"tldr": "本文提出了一种名为“Arrow Language Model”的新型神经网络架构，该架构基于直觉主义逻辑的解释，将下一个词预测视为一个推导过程。该模型通过非交换组合来保留序列顺序，并利用 Curry-Howard 对应关系将序列处理解释为构造性证明的扩展。", "motivation": "研究的动机是探索一种新的神经网络架构，该架构能够从逻辑学的角度来理解和处理序列数据，特别是通过直觉主义逻辑和 Curry-Howard 对应关系来解释下一个词的预测。", "method": "该研究提出了一种基于直觉主义逻辑解释的神经网络架构，将词语表示为左嵌套蕴含链，并使用 Modus Ponens 进行下一个词预测。研究还利用 Prolog 证明器来验证模型的属性，并探索了与 RNN、Transformer 和状态空间模型的关系，提出了一个低秩的神经网络实现。", "result": "研究表明，从证明论角度解释下一个词预测（作为嵌套直觉主义蕴含）可以自然地产生一个等同于乘法 RNN 的神经网络架构。该模型在逻辑推导和序列处理方面表现出基本属性。", "conclusion": "Arrow Language Model 提供了一种新的、基于逻辑的神经网络架构，能够通过非交换组合有效地处理序列数据，并为开发 Transformer 和状态空间模型的替代方案提供了理论基础。"}}
{"id": "2601.20427", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.20427", "abs": "https://arxiv.org/abs/2601.20427", "authors": ["Yixuan Zhu", "Yinkang Gao", "Bo Zhang", "Xiaohang Gong", "Binze Jiang", "Lei Gong", "Wenqi Lou", "Teng Wang", "Chao Wang", "Xi Li", "Xuehai Zhou"], "title": "Reducing End-to-End Latency of Cause-Effect Chains with Shared Cache Analysis", "comment": null, "summary": "Cause-effect chains, as a widely used modeling method in real-time embedded systems, are extensively applied in various safety-critical domains. End-to-end latency, as a key real-time attribute of cause-effect chains, is crucial in many applications. But the analysis of end-to-end latency for cause-effect chains on multicore platforms with shared caches still presents an unresolved issue. Traditional methods typically assume that the worst-case execution time (WCET) of each task in the cause-effect chain is known. However, in the absence of scheduling information, these methods often assume that all shared cache accesses result in misses, leading to an overestimation of WCET and, consequently, affecting the accuracy of end-to-end latency. However, effectively integrating scheduling information into the WCET analysis process of the chains may introduce two challenges: first, how to leverage the structural characteristics of the chains to optimize shared cache analysis, and second, how to improve analysis accuracy while avoiding state space explosion.\n  To address these issues, this paper proposes a novel end-to-end latency analysis framework designed for multi-chain systems on multicore platforms with shared caches. This framework extracts scheduling information and structural characteristics of cause-effect chains, constructing fine-grained and scalable inter-core memory access contexts at the basic block level for time-sensitive shared cache analysis. This results in more accurate WCET (TSC-WCET) estimates, which are then used to derive the end-to-end latency. Finally, we conduct experiments on dual-core and quad-core systems with various cache configurations, which show that under certain settings, the average maximum end-to-end latency of cause-effect chains is reduced by up to 34% and 26%.", "AI": {"tldr": "本文提出了一种用于多核共享缓存系统中因果链的端到端延迟分析框架，通过整合调度信息和结构特性，进行细粒度的缓存分析，从而更准确地估计最坏情况执行时间（WCET）并降低端到端延迟。", "motivation": "传统因果链延迟分析方法在多核共享缓存环境下，由于缺乏调度信息，常假设所有缓存访问都发生缓存未命中，导致WCET过高，影响延迟分析的准确性。同时，将调度信息整合到WCET分析中面临如何利用链的结构优化缓存分析以及如何在提高精度的同时避免状态空间爆炸的挑战。", "method": "该框架提取因果链的调度信息和结构特性，构建了细粒度的、可扩展的跨核内存访问上下文（在基本块级别），用于时间敏感的共享缓存分析。在此基础上，计算出更准确的WCET（TSC-WCET），并用其推导出端到端延迟。", "result": "在双核和四核系统及多种缓存配置的实验中，作者提出的框架在某些设置下，因果链的平均最大端到端延迟最多降低了34%和26%。", "conclusion": "该框架能够有效解决多核共享缓存下因果链端到端延迟分析的准确性问题，通过细粒度的缓存分析和调度信息整合，显著降低了延迟。"}}
{"id": "2601.20769", "categories": ["eess.IV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20769", "abs": "https://arxiv.org/abs/2601.20769", "authors": ["Yichi Zhang", "Fengqing Zhu"], "title": "Leveraging Second-Order Curvature for Efficient Learned Image Compression: Theory and Empirical Evidence", "comment": null, "summary": "Training learned image compression (LIC) models entails navigating a challenging optimization landscape defined by the fundamental trade-off between rate and distortion. Standard first-order optimizers, such as SGD and Adam, struggle with \\emph{gradient conflicts} arising from competing objectives, leading to slow convergence and suboptimal rate-distortion performance. In this work, we demonstrate that a simple utilization of a second-order quasi-Newton optimizer, \\textbf{SOAP}, dramatically improves both training efficiency and final performance across diverse LICs. Our theoretical and empirical analyses reveal that Newton preconditioning inherently resolves the intra-step and inter-step update conflicts intrinsic to the R-D objective, facilitating faster, more stable convergence. Beyond acceleration, we uncover a critical deployability benefit: second-order trained models exhibit significantly fewer activation and latent outliers. This substantially enhances robustness to post-training quantization. Together, these results establish second-order optimization, achievable as a seamless drop-in replacement of the imported optimizer, as a powerful, practical tool for advancing the efficiency and real-world readiness of LICs.", "AI": {"tldr": "本文提出使用二阶优化器SOAP来训练学习型图像压缩（LIC）模型，解决了梯度冲突问题，提高了训练效率和压缩性能，并增强了模型对量化后的鲁棒性。", "motivation": "标准的一阶优化器在训练LIC模型时，由于速率-失真（R-D）权衡的竞争性目标，会遇到梯度冲突，导致收敛慢和性能不佳。", "method": "使用二阶拟牛顿优化器SOAP来训练LIC模型，并进行了理论和经验分析，以揭示其在解决梯度冲突、加速收敛和减少激活/潜在离群值方面的优势。", "result": "SOAP显著提高了训练效率和最终性能，并且训练出的模型在后训练量化方面表现出更好的鲁棒性。", "conclusion": "二阶优化器SOAP是训练LIC模型的一种有效且实用的方法，可以提高训练效率和模型的实际部署能力。"}}
{"id": "2601.20149", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.20149", "abs": "https://arxiv.org/abs/2601.20149", "authors": ["Muzaffar Qureshi", "Tochukwu Elijah Ogri", "Kyle Volle", "Rushikesh Kamalapurkar"], "title": "A Taylor Series Approach to Correct Localization Errors in Robotic Field Mapping using Gaussian Processes", "comment": null, "summary": "Gaussian Processes (GPs) are powerful non-parametric Bayesian models for regression of scalar fields, formulated under the assumption that measurement locations are perfectly known and the corresponding field measurements have Gaussian noise. However, many real-world scalar field mapping applications rely on sensor-equipped mobile robots to collect field measurements, where imperfect localization introduces state uncertainty. Such discrepancies between the estimated and true measurement locations degrade GP mean and covariance estimates. To address this challenge, we propose a method for updating the GP models when improved estimates become available. Leveraging the differentiability of the kernel function, a second-order correction algorithm is developed using the precomputed Jacobians and Hessians of the GP mean and covariance functions for real-time refinement based on measurement location discrepancy data. Simulation results demonstrate improved prediction accuracy and computational efficiency compared to full model retraining.", "AI": {"tldr": "提出了一种利用高斯过程（GP）对带有位置不确定性的传感器数据进行建模的方法，通过二阶校正算法实时优化GP模型，提高了预测精度和计算效率。", "motivation": "现有的高斯过程模型假设测量位置已知且精确，但在实际应用中，尤其是在移动机器人进行现场测量时，传感器定位不确定性是普遍存在的。这种位置误差会严重影响GP模型的均值和协方差估计的准确性。", "method": "利用高斯过程核函数的可微性，开发了一种二阶校正算法。该算法通过预计算GP均值和协方差函数的雅可比矩阵和海森矩阵，根据测量位置的差异数据，对GP模型进行实时精炼。", "result": "仿真结果表明，与完全重新训练GP模型相比，所提出的方法能够提高预测精度，并具有更高的计算效率。", "conclusion": "所提出的二阶校正方法能够有效地处理移动机器人传感器测量中的位置不确定性问题，实时更新高斯过程模型，从而在不牺牲准确性的前提下提升了计算性能。"}}
{"id": "2601.20075", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20075", "abs": "https://arxiv.org/abs/2601.20075", "authors": ["Chuan Qin", "Constantin Venhoff", "Sonia Joseph", "Fanyi Xiao", "Stefan Scherer"], "title": "Sparse CLIP: Co-Optimizing Interpretability and Performance in Contrastive Learning", "comment": null, "summary": "Contrastive Language-Image Pre-training (CLIP) has become a cornerstone in vision-language representation learning, powering diverse downstream tasks and serving as the default vision backbone in multimodal large language models (MLLMs). Despite its success, CLIP's dense and opaque latent representations pose significant interpretability challenges. A common assumption is that interpretability and performance are in tension: enforcing sparsity during training degrades accuracy, motivating recent post-hoc approaches such as Sparse Autoencoders (SAEs). However, these post-hoc approaches often suffer from degraded downstream performance and loss of CLIP's inherent multimodal capabilities, with most learned features remaining unimodal.\n  We propose a simple yet effective approach that integrates sparsity directly into CLIP training, yielding representations that are both interpretable and performant. Compared to SAEs, our Sparse CLIP representations preserve strong downstream task performance, achieve superior interpretability, and retain multimodal capabilities. We show that multimodal sparse features enable straightforward semantic concept alignment and reveal training dynamics of how cross-modal knowledge emerges. Finally, as a proof of concept, we train a vision-language model on sparse CLIP representations that enables interpretable, vision-based steering capabilities. Our findings challenge conventional wisdom that interpretability requires sacrificing accuracy and demonstrate that interpretability and performance can be co-optimized, offering a promising design principle for future models.", "AI": {"tldr": "本文提出了一种将稀疏性直接集成到CLIP预训练中的方法，以生成既可解释又高性能的视觉-语言表示。与后处理方法（如稀疏自编码器）相比，该方法在保留下游任务性能的同时，提高了可解释性，并保留了多模态能力，甚至能够实现可解释的视觉引导。", "motivation": "CLIP模型虽然在多模态学习中取得了巨大成功，但其稠密且不透明的潜在表示带来了显著的可解释性挑战。现有的后处理方法（如稀疏自编码器）试图解决这个问题，但常常牺牲下游任务性能和多模态能力。因此，需要一种能在保证性能的同时提高可解释性的方法。", "method": "将稀疏性直接集成到CLIP的预训练过程中，旨在生成稀疏但仍能保持高性能的多模态表示。通过这种方式，研究人员希望克服后处理方法的局限性。", "result": "与稀疏自编码器等后处理方法相比，本文提出的方法生成的稀疏CLIP表示在下游任务上保持了强大的性能，展现了更高的可解释性，并保留了多模态能力。此外，研究证明了多模态稀疏特征能够实现简单的语义概念对齐，并揭示了跨模态知识的形成过程。最后，以概念验证的形式，训练了一个基于稀疏CLIP表示的视觉-语言模型，实现了可解释的、基于视觉的引导能力。", "conclusion": "本文的研究挑战了“可解释性必然牺牲准确性”的传统观点，证明了可解释性和性能可以协同优化。所提出的集成稀疏性的CLIP预训练方法为未来模型的设计提供了一个有前景的原则，即在追求高性能的同时，实现模型的可解释性。"}}
{"id": "2601.20021", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20021", "abs": "https://arxiv.org/abs/2601.20021", "authors": ["Shuhui Qu"], "title": "Fuzzy Categorical Planning: Autonomous Goal Satisfaction with Graded Semantic Constraints", "comment": null, "summary": "Natural-language planning often involves vague predicates (e.g., suitable substitute, stable enough) whose satisfaction is inherently graded. Existing category-theoretic planners provide compositional structure and pullback-based hard-constraint verification, but treat applicability as crisp, forcing thresholding that collapses meaningful distinctions and cannot track quality degradation across multi-step plans. We propose Fuzzy Category-theoretic Planning (FCP), which annotates each action (morphism) with a degree in [0,1], composes plan quality via a t-norm Lukasiewicz, and retains crisp executability checks via pullback verification. FCP grounds graded applicability from language using an LLM with k-sample median aggregation and supports meeting-in-the-middle search using residuum-based backward requirements. We evaluate on (i) public PDDL3 preference/oversubscription benchmarks and (ii) RecipeNLG-Subs, a missing-substitute recipe-planning benchmark built from RecipeNLG with substitution candidates from Recipe1MSubs and FoodKG. FCP improves success and reduces hard-constraint violations on RecipeNLG-Subs compared to LLM-only and ReAct-style baselines, while remaining competitive with classical PDDL3 planners.", "AI": {"tldr": "本文提出了模糊范畴规划 (FCP)，一种能够处理自然语言规划中模糊谓词（如“足够好”）的方法。FCP 将动作的适用性表示为 [0,1] 之间的模糊度，并通过 Łukasiewicz t-范式组合规划质量。同时，它保留了范畴规划的严格执行检查，并利用 LLM 来处理模糊语言描述。实验结果表明，FCP 在包含模糊谓词的食谱规划任务上优于现有基线方法，并在 PDDL3 基准测试中表现具有竞争力。", "motivation": "现有基于范畴规划的方法在处理自然语言中固有的模糊谓词（如“合适”、“足够稳定”）时存在不足，它们将适用性视为二元的（是/否），这会导致信息丢失，并且无法跟踪多步规划中质量的下降。因此，需要一种能够处理模糊适用性和量化规划质量的方法。", "method": "作者提出了模糊范畴规划 (FCP)。该方法的核心思想是：1. 为每个动作（态射）的适用性打分，范围在 [0,1] 之间。2. 使用 Łukasiewicz t-范式来组合多步规划的质量。3. 通过范畴论中的拉回（pullback）操作来保留严格的可执行性检查。4. 利用大型语言模型 (LLM) 来从自然语言中提取模糊适用性的量化值，并使用 k-样本中位数聚合来提高鲁棒性。5. 支持“中间相遇”搜索策略，通过残差（residuum）来处理后向需求。", "result": "在 RecipeNLG-Subs 基准测试（一个新建的、包含食材替换的食谱规划数据集）上，FCP 相比于仅使用 LLM 或 ReAct 风格的方法，提高了规划的成功率并减少了硬约束的违例。同时，FCP 在经典的 PDDL3 偏好/超额订阅基准测试中也保持了竞争力。", "conclusion": "FCP 成功地将模糊逻辑和范畴规划相结合，有效地处理了自然语言规划中存在的模糊谓词问题，并能够量化和组合多步规划的质量。该方法在处理包含食材替换的食谱规划任务方面表现出色，为更自然、更灵活的规划系统提供了新的途径。"}}
{"id": "2601.20048", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20048", "abs": "https://arxiv.org/abs/2601.20048", "authors": ["Jincheng Bai", "Zhenyu Zhang", "Jennifer Zhang", "Zhihuai Zhu"], "title": "Insight Agents: An LLM-Based Multi-Agent System for Data Insights", "comment": "Accepted to SIGIR 2025. DOI: 10.1145/3726302.3731959", "summary": "Today, E-commerce sellers face several key challenges, including difficulties in discovering and effectively utilizing available programs and tools, and struggling to understand and utilize rich data from various tools. We therefore aim to develop Insight Agents (IA), a conversational multi-agent Data Insight system, to provide E-commerce sellers with personalized data and business insights through automated information retrieval. Our hypothesis is that IA will serve as a force multiplier for sellers, thereby driving incremental seller adoption by reducing the effort required and increase speed at which sellers make good business decisions. In this paper, we introduce this novel LLM-backed end-to-end agentic system built on a plan-and-execute paradigm and designed for comprehensive coverage, high accuracy, and low latency. It features a hierarchical multi-agent structure, consisting of manager agent and two worker agents: data presentation and insight generation, for efficient information retrieval and problem-solving. We design a simple yet effective ML solution for manager agent that combines Out-of-Domain (OOD) detection using a lightweight encoder-decoder model and agent routing through a BERT-based classifier, optimizing both accuracy and latency. Within the two worker agents, a strategic planning is designed for API-based data model that breaks down queries into granular components to generate more accurate responses, and domain knowledge is dynamically injected to to enhance the insight generator. IA has been launched for Amazon sellers in US, which has achieved high accuracy of 90% based on human evaluation, with latency of P90 below 15s.", "AI": {"tldr": "本文提出了一种名为 Insight Agents (IA) 的对话式多智能体数据洞察系统，旨在通过自动化信息检索和个性化分析，帮助电商卖家解决数据利用难题，提高决策效率。", "motivation": "电商卖家在发现和利用现有工具、理解和运用多源数据方面面临挑战，影响其业务决策效率。研究旨在通过IA系统解决这些痛点。", "method": "开发了一个基于LLM的端到端智能体系统，采用计划-执行范式。系统包含一个经理智能体和两个工作智能体（数据呈现和洞察生成）。经理智能体结合了OOD检测和基于BERT的路由分类器，实现了高精度和低延迟。工作智能体采用API数据模型进行查询分解，并动态注入领域知识以增强洞察生成。", "result": "IA系统在美国亚马逊卖家中的实际应用取得了90%的人工评估准确率，P90延迟低于15秒。", "conclusion": "IA系统作为一个基于LLM的计划-执行多智能体系统，能够通过自动化信息检索和提供个性化数据洞察，有效赋能电商卖家，提高其决策速度和准确性，具有显著的实用价值。"}}
{"id": "2601.20445", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.20445", "abs": "https://arxiv.org/abs/2601.20445", "authors": ["Yixuan Zhu", "Yinkang Gao", "Lei Gong", "Binze Jiang", "Xiaohang Gong", "Zihan Wang", "Cheng Tang", "Wenqi Lou", "Teng Wang", "Chao Wang", "Xi Li", "Xuehai Zhou"], "title": "A Timing-Anomaly Free Dynamic Scheduling on Heterogeneous Systems", "comment": null, "summary": "Heterogeneous systems commonly adopt dynamic scheduling algorithms to improve resource utilization and enhance scheduling flexibility. However, such flexibility may introduce timing anomalies, wherein locally reduced execution times can lead to an increase in the overall system execution time. This phenomenon significantly complicates the analysis of Worst-Case Response Time (WCRT), rendering conventional analysis either overly pessimistic or unsafe, and often necessitating exhaustive state-space exploration to ensure correctness.\n  To address this challenge, this paper presents the first timing-anomaly-free dynamic scheduling algorithm for heterogeneous systems, referred to as Deterministic Dynamic Execution. It achieves a safe and tight WCRT estimate through a single offline simulation execution. The core idea is to apply deterministic execution constraints, which partially restrict the resource allocation and execution order of tasks at runtime. Based on a formally defined execution progress model for heterogeneous system scheduling, we prove the correctness of the proposed execution constraints and their ability to eliminate timing anomalies. Furthermore, we propose two methods to generate execution constraints. The first method derives execution constraints directly from the execution traces produced by existing scheduling algorithms. The second method is a heuristic-based approach that constructs execution constraints, enabling further reduction of the WCRT. Experimental results on synthetically generated DAG task sets under various system configurations demonstrate that, compared to traditional dynamic scheduling algorithms, our approach not only eliminates timing anomalies but also effectively reduces both the WCRT and response time jitter.", "AI": {"tldr": "本文提出了一种名为确定性动态执行（DDE）的异构系统动态调度算法，该算法消除了时序异常，从而可以安全且精确地估计最坏情况响应时间（WCRT），并且通过离线模拟即可实现。", "motivation": "异构系统中动态调度算法虽然提高了资源利用率和灵活性，但可能引入时序异常，导致最坏情况响应时间（WCRT）分析变得困难，要么过于悲观，要么不安全，并且需要耗尽状态空间探索。因此，需要一种能够安全且精确分析WCRT的动态调度算法。", "method": "提出一种名为“确定性动态执行”（DDE）的算法，通过引入确定性执行约束来部分限制运行时资源分配和任务执行顺序。基于形式化的异构系统调度执行进度模型，证明了执行约束的正确性和消除时序异常的能力。此外，提出了两种生成执行约束的方法：一种是直接从现有调度算法的执行跟踪中生成；另一种是基于启发式的、能够进一步降低WCRT的方法。", "result": "实验结果表明，与传统的动态调度算法相比，DDE算法不仅消除了时序异常，还能有效降低WCRT和响应时间抖动。", "conclusion": "本文提出的确定性动态执行（DDE）算法是第一个用于异构系统的无时序异常动态调度算法，通过引入执行约束，实现了安全且紧凑的WCRT估计，并且在实验中证明了其优越性。"}}
{"id": "2601.19916", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19916", "abs": "https://arxiv.org/abs/2601.19916", "authors": ["Songjun Tu", "Yiwen Ma", "Jiahao Lin", "Qichao Zhang", "Xiangyuan Lan", "Junfeng. Li", "Nan Xu", "Linjing Li", "Dongbin Zhao"], "title": "PaperAudit-Bench: Benchmarking Error Detection in Research Papers for Critical Automated Peer Review", "comment": null, "summary": "Large language models can generate fluent peer reviews, yet their assessments often lack sufficient critical rigor when substantive issues are subtle and distributed across a paper. In this paper, we introduce PaperAudit-Bench, which consists of two components: (1) PaperAudit-Dataset, an error dataset covering both errors identifiable within individual sections and those requiring cross-section reasoning, designed for controlled evaluation under long-context settings; and (2) PaperAudit-Review, an automated review framework that integrates structured error detection with evidence-aware review generation to support critical assessment. Experiments on PaperAudit-Bench reveal large variability in error detectability across models and detection depths, highlighting the difficulty of identifying such errors under long-context settings. Relative to representative automated reviewing baselines, incorporating explicit error detection into the review workflow produces systematically stricter and more discriminative evaluations, demonstrating its suitability for peer review. Finally, we show that the dataset supports training lightweight LLM detectors via SFT and RL, enabling effective error detection at reduced computational cost.", "AI": {"tldr": "本文提出了一种名为PaperAudit-Bench的新评估基准，用于检测大型语言模型在同行评审中可能忽略的细微、分布式的学术论文错误。该基准包含一个错误数据集和一个自动化评审框架，实验表明该框架能生成更严格、更具区分度的评审，并且可以训练轻量级模型进行有效错误检测。", "motivation": "大型语言模型虽然能生成流畅的同行评审意见，但在面对细微且分散在论文各处的实质性问题时，往往缺乏足够的批判性。研究旨在提高LLM在同行评审中的评估能力。", "method": "1. 构建PaperAudit-Dataset，包含可识别于单章节错误和需跨章节推理的错误，用于长上下文设置下的受控评估。2. 开发PaperAudit-Review自动化评审框架，整合结构化错误检测与证据感知评审生成，以支持批判性评估。3. 在PaperAudit-Bench上进行实验，评估不同模型和检测深度的错误可检测性。4. 通过SFT和RL训练轻量级LLM检测器。", "result": "不同模型和检测深度在错误可检测性方面存在显著差异，显示长上下文设置下的错误识别具有挑战性。与现有基线相比，集成显式错误检测的评审工作流程能产生系统性更严格、区分度更高的评估。训练的轻量级LLM检测器在计算成本降低的情况下，仍能有效检测错误。", "conclusion": "PaperAudit-Bench为评估和提升LLM在同行评审中的批判性评估能力提供了一个有效平台。显式错误检测方法能显著增强LLM的评审质量，且可通过训练轻量级模型实现高效部署。"}}
{"id": "2601.20104", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20104", "abs": "https://arxiv.org/abs/2601.20104", "authors": ["Nima Torbati", "Anastasia Meshcheryakova", "Ramona Woitek", "Sepideh Hatamikia", "Diana Mechtcheriakova", "Amirreza Mahbod"], "title": "NucFuseRank: Dataset Fusion and Performance Ranking for Nuclei Instance Segmentation", "comment": "31 pages", "summary": "Nuclei instance segmentation in hematoxylin and eosin (H&E)-stained images plays an important role in automated histological image analysis, with various applications in downstream tasks. While several machine learning and deep learning approaches have been proposed for nuclei instance segmentation, most research in this field focuses on developing new segmentation algorithms and benchmarking them on a limited number of arbitrarily selected public datasets.\n  In this work, rather than focusing on model development, we focused on the datasets used for this task. Based on an extensive literature review, we identified manually annotated, publicly available datasets of H&E-stained images for nuclei instance segmentation and standardized them into a unified input and annotation format. Using two state-of-the-art segmentation models, one based on convolutional neural networks (CNNs) and one based on a hybrid CNN and vision transformer architecture, we systematically evaluated and ranked these datasets based on their nuclei instance segmentation performance. Furthermore, we proposed a unified test set (NucFuse-test) for fair cross-dataset evaluation and a unified training set (NucFuse-train) for improved segmentation performance by merging images from multiple datasets.\n  By evaluating and ranking the datasets, performing comprehensive analyses, generating fused datasets, conducting external validation, and making our implementation publicly available, we provided a new benchmark for training, testing, and evaluating nuclei instance segmentation models on H&E-stained histological images.", "AI": {"tldr": "该研究通过整合和标准化多个公共数据集，并使用两种先进的模型对这些数据集进行性能评估，创建了一个用于细胞核实例分割的新基准，以促进公平的跨数据集评估和模型改进。", "motivation": "现有关于细胞核实例分割的研究主要集中于开发新算法并在有限的公开数据集上进行测试，缺乏对数据集本身的系统性评估和标准化，阻碍了公平的模型比较和性能提升。", "method": "通过文献回顾，收集并标准化了手动标注的 H&E 染色图像细胞核实例分割公共数据集。使用卷积神经网络（CNN）和混合 CNN-Transformer 两种先进分割模型，对标准化后的数据集进行了性能评估和排序。此外，提出了一个统一的测试集（NucFuse-test）用于公平评估，以及一个统一的训练集（NucFuse-train）用于提升分割性能。", "result": "研究评估并对数据集进行了排名，提供了数据之间的性能对比。通过融合多个数据集，证明了可以提高分割模型的性能。外部验证也支持了所提出方法的有效性。", "conclusion": "该研究通过数据集的标准化、评估和融合，以及提供统一的训练和测试集，为 H&E 染色组织图像的细胞核实例分割模型提供了一个新的、更具鲁棒性的基准，促进了更公平的模型评估和模型性能的整体提升。"}}
{"id": "2601.20090", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20090", "abs": "https://arxiv.org/abs/2601.20090", "authors": ["Amirmohammad Farzaneh", "Salvatore D'Oro", "Osvaldo Simeone"], "title": "Should I Have Expressed a Different Intent? Counterfactual Generation for LLM-Based Autonomous Control", "comment": null, "summary": "Large language model (LLM)-powered agents can translate high-level user intents into plans and actions in an environment. Yet after observing an outcome, users may wonder: What if I had phrased my intent differently? We introduce a framework that enables such counterfactual reasoning in agentic LLM-driven control scenarios, while providing formal reliability guarantees. Our approach models the closed-loop interaction between a user, an LLM-based agent, and an environment as a structural causal model (SCM), and leverages test-time scaling to generate multiple candidate counterfactual outcomes via probabilistic abduction. Through an offline calibration phase, the proposed conformal counterfactual generation (CCG) yields sets of counterfactual outcomes that are guaranteed to contain the true counterfactual outcome with high probability. We showcase the performance of CCG on a wireless network control use case, demonstrating significant advantages compared to naive re-execution baselines.", "AI": {"tldr": "本文提出了一种框架，用于LLM驱动的代理中实现反事实推理，并提供正式的可靠性保证。该框架将用户、LLM代理和环境之间的交互建模为结构因果模型（SCM），并利用测试时缩放生成候选反事实结果，通过离线校准阶段的保形反事实生成（CCG）获得具有高概率保证的真实反事实结果集合。", "motivation": "当前LLM驱动的代理在实现用户意图时，用户可能会想知道如果改变意图的表述会发生什么，即进行反事实推理。现有方法缺乏这种能力，并且没有提供可靠性保证。", "method": "本文将用户、LLM代理和环境之间的闭环交互建模为一个结构因果模型（SCM）。利用测试时缩放（test-time scaling）生成多个候选反事实结果，并通过保形反事实生成（CCG）在离线校准阶段，确保生成的反事实结果集以高概率包含真实的“如果……会怎样”的结果。", "result": "在无线网络控制用例中展示了CCG的性能，相比于简单的重新执行基线，CCG取得了显著优势。", "conclusion": "所提出的CCG框架能够为LLM驱动的代理提供可靠的反事实推理能力，并通过在实际场景中的应用证明了其有效性。"}}
{"id": "2601.19917", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19917", "abs": "https://arxiv.org/abs/2601.19917", "authors": ["Haoyu Zheng", "Yun Zhu", "Yuqian Yuan", "Bo Yuan", "Wenqiao Zhang", "Siliang Tang", "Jun Xiao"], "title": "PILOT: Planning via Internalized Latent Optimization Trajectories for Large Language Models", "comment": null, "summary": "Strategic planning is critical for multi-step reasoning, yet compact Large Language Models (LLMs) often lack the capacity to formulate global strategies, leading to error propagation in long-horizon tasks. Our analysis reveals that LLMs possess latent reasoning capabilities that can be unlocked when conditioned on explicit plans from a teacher model; however, runtime reliance on external guidance is often impractical due to latency and availability constraints. To bridge this gap, we propose PILOT (Planning via Internalized Latent Optimization Trajectories), a non-invasive framework designed to internalize the strategic oversight of large models into intrinsic Latent Guidance. Instead of altering backbone weights, PILOT employs a lightweight Hyper-Network to synthesize a query-conditioned Latent Guidance vector. This vector acts as an internal steering mechanism, guiding the model's representations toward optimal reasoning paths. Extensive experiments on mathematical and coding benchmarks demonstrate that PILOT effectively stabilizes reasoning trajectories, consistently outperforming strong baselines (e.g., +8.9% on MATH500) with negligible inference latency.", "AI": {"tldr": "提出了一种名为PILOT的框架，通过引入一个轻量级的超网络来生成查询条件的潜在引导向量，从而将大型模型的战略规划能力内化到紧凑模型中，以提高多步推理任务的性能。", "motivation": "紧凑型大型语言模型在执行长距离多步推理任务时，由于缺乏全局策略规划能力，容易出现错误累积。虽然可以通过外部教师模型提供显式规划来解锁其潜在推理能力，但运行时依赖外部指导因延迟和可用性问题而不切实际。", "method": "PILOT框架使用一个轻量级的超网络来生成一个查询条件的潜在引导向量（Latent Guidance vector），该向量作为一种内部的指导机制，引导模型在推理过程中走向最优路径，而无需修改模型的主干权重。", "result": "在数学和代码基准测试上的大量实验表明，PILOT能够有效稳定推理过程，并且在MATH500基准测试上取得了+8.9%的性能提升，同时几乎没有增加推理延迟。", "conclusion": "PILOT是一种有效的非侵入式框架，能够将大型模型的战略规划能力内化到紧凑模型中，从而显著提高其在复杂推理任务中的性能，并且具有高效的推理能力。"}}
{"id": "2601.20208", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20208", "abs": "https://arxiv.org/abs/2601.20208", "authors": ["Wanjun Jia", "Kang Li", "Fan Yang", "Mengfei Duan", "Wenrui Chen", "Yiming Jiang", "Hui Zhang", "Kailun Yang", "Zhiyong Li", "Yaonan Wang"], "title": "TRACER: Texture-Robust Affordance Chain-of-Thought for Deformable-Object Refinement", "comment": "The source code and dataset will be made publicly available at https://github.com/Dikay1/TRACER", "summary": "The central challenge in robotic manipulation of deformable objects lies in aligning high-level semantic instructions with physical interaction points under complex appearance and texture variations. Due to near-infinite degrees of freedom, complex dynamics, and heterogeneous patterns, existing vision-based affordance prediction methods often suffer from boundary overflow and fragmented functional regions. To address these issues, we propose TRACER, a Texture-Robust Affordance Chain-of-thought with dEformable-object Refinement framework, which establishes a cross-hierarchical mapping from hierarchical semantic reasoning to appearance-robust and physically consistent functional region refinement. Specifically, a Tree-structured Affordance Chain-of-Thought (TA-CoT) is formulated to decompose high-level task intentions into hierarchical sub-task semantics, providing consistent guidance across various execution stages. To ensure spatial integrity, a Spatial-Constrained Boundary Refinement (SCBR) mechanism is introduced to suppress prediction spillover, guiding the perceptual response to converge toward authentic interaction manifolds. Furthermore, an Interactive Convergence Refinement Flow (ICRF) is developed to aggregate discrete pixels corrupted by appearance noise, significantly enhancing the spatial continuity and physical plausibility of the identified functional regions. Extensive experiments conducted on the Fine-AGDDO15 dataset and a real-world robotic platform demonstrate that TRACER significantly improves affordance grounding precision across diverse textures and patterns inherent to deformable objects. More importantly, it enhances the success rate of long-horizon tasks, effectively bridging the gap between high-level semantic reasoning and low-level physical execution. The source code and dataset will be made publicly available at https://github.com/Dikay1/TRACER.", "AI": {"tldr": "TRACER是一个新框架，通过分层语义推理和外观鲁棒的功能区域细化，解决了机器人操作可变形物体的挑战，提高了在不同纹理下的操作精度和长期任务的成功率。", "motivation": "现有基于视觉的可变形物体操作方法在处理复杂的纹理和外观变化时，边界预测容易溢出且功能区域分割不完整。高层语义指令与物理交互点之间的对齐是核心难题。", "method": "TRACER框架包含三个主要部分：1. 树状思维链（TA-CoT）用于将高级任务意图分解为分层子任务语义；2. 空间约束边界细化（SCBR）机制用于抑制预测溢出，引导感知响应收敛到真实的交互流形；3. 交互式收敛细化流（ICRF）用于聚合受噪声影响的离散像素，增强功能区域的空间连续性和物理合理性。", "result": "TRACER在Fine-AGDDO15数据集和真实机器人平台上进行了广泛实验，显著提高了可变形物体在各种纹理和模式下的功能接地精度。它还提高了长期任务的成功率。", "conclusion": "TRACER框架有效地弥合了高层语义推理与低层物理执行之间的差距，为机器人操作可变形物体提供了更鲁棒和精确的解决方案。"}}
{"id": "2601.20561", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.20561", "abs": "https://arxiv.org/abs/2601.20561", "authors": ["Jilles S. van Hulst", "Erik M. Franken", "Bart J. Janssen", "W. P. M. H.", "Heemels", "Duarte J. Antunes"], "title": "Tilt-based Aberration Estimation in Transmission Electron Microscopy", "comment": "Submitted version (pre-print)", "summary": "Transmission electron microscopes (TEMs) enable atomic-scale imaging but suffer from aberrations caused by lens imperfections and environmental conditions, reducing image quality. These aberrations can be compensated by adjusting electromagnetic lenses, but this requires accurate estimates of the aberration coefficients, which can drift over time. This paper introduces a method for the estimation of aberrations in TEM by leveraging the relationship between an induced electron beam tilt and the resulting image shift. The method uses a Kalman filter (KF) to estimate the aberration coefficients from a sequence of image shifts, while accounting for the drift of the aberrations over time. The applied tilt sequence is optimized by minimizing the trace of the predicted error covariance in the KF, which corresponds to the A-optimality criterion in experimental design. We show that this optimization can be performed offline, as the cost criterion is independent of the actual measurements. The resulting non-convex optimization problem is solved using a gradient-based, receding-horizon approach with multi-starts. Additionally, we develop an approach to estimate specimen-dependent noise properties using expectation maximization (EM), which are then used to tailor the tilt pattern optimization to the specific specimen being imaged. The proposed method is validated on a real TEM set-up with several optimized tilt patterns. The results show that optimized patterns significantly outperform naive approaches and that the aberration and drift model accurately captures the underlying physical phenomena. In total, the alignment time is reduced from typically several minutes to less than a minute compared to the state-of-the-art.", "AI": {"tldr": "本文提出了一种利用卡尔曼滤波器和优化倾斜序列来快速准确地估计和补偿透射电子显微镜（TEM）的像差漂移的方法，并结合期望最大化算法估计与样品相关的噪声特性，以进一步优化测量策略。", "motivation": "TEM的像差会降低图像质量，而传统像差补偿方法需要准确的像差系数估计，但这些系数会随时间漂移。因此，需要一种能有效估计并补偿漂移像差的方法。", "method": "1. 使用卡尔曼滤波器（KF）从一系列图像位移中估计像差系数，并考虑其随时间的漂移。2. 通过最小化KF预测误差协方差的迹（A-optimality准则）来优化诱导电子束倾斜序列，该优化可离线进行。3. 使用梯度下降法和多起点策略解决非凸优化问题。4. 利用期望最大化（EM）算法估计样品相关的噪声特性，并据此调整倾斜模式优化。5. 在实际TEM设备上进行验证。", "result": "1. 优化的倾斜模式显著优于朴素方法。2. 像差和漂移模型能准确反映物理现象。3. 相比现有技术，校准时间从几分钟缩短到不到一分钟。", "conclusion": "所提出的基于卡尔曼滤波和优化倾斜序列的方法能够高效、准确地估计TEM中的像差漂移，并通过考虑样品噪声特性进一步优化测量过程，显著提升了TEM的校准效率和图像质量。"}}
{"id": "2601.20107", "categories": ["cs.CV", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.20107", "abs": "https://arxiv.org/abs/2601.20107", "authors": ["Zhuchenyang Liu", "Ziyu Hu", "Yao Zhang", "Yu Xiao"], "title": "Look in the Middle: Structural Anchor Pruning for Scalable Visual RAG Indexing", "comment": "18 pages, 6 figures, 11 tables", "summary": "Recent Vision-Language Models (e.g., ColPali) enable fine-grained Visual Document Retrieval (VDR) but incur prohibitive index vector size overheads. Training-free pruning solutions (e.g., EOS-attention based methods) can reduce index vector size by approximately 60% without model adaptation, but often underperform random selection in high-compression scenarios (> 80%). Prior research (e.g., Light-ColPali) attributes this to the conclusion that visual token importance is inherently query-dependent, thereby questioning the feasibility of training-free pruning. In this work, we propose Structural Anchor Pruning (SAP), a training-free pruning method that identifies key visual patches from middle layers to achieve high performance compression. We also introduce Oracle Score Retention (OSR) protocol to evaluate how layer-wise information affects compression efficiency. Evaluations on the ViDoRe benchmark demonstrate that SAP reduces index vectors by over 90% while maintaining robust retrieval fidelity, providing a highly scalable solution for Visual RAG. Furthermore, our OSR-based analysis reveals that semantic structural anchor patches persist in the middle layers, unlike traditional pruning solutions that focus on the final layer where structural signals dissipate.", "AI": {"tldr": "本文提出了一种名为结构锚点剪枝（SAP）的无训练剪枝方法，通过识别中间层的关键视觉块，在显著减小索引向量尺寸（超过90%）的同时，保持了鲁棒的检索保真度，为视觉 RAG 提供了可扩展的解决方案。同时，引入了 Oracle 分数保留（OSR）协议用于分析层级信息对压缩效率的影响。", "motivation": "现有的视觉-语言模型在细粒度视觉文档检索（VDR）方面表现出色，但索引向量尺寸过大带来了高昂的存储开销。现有的无训练剪枝方法虽然能减小索引尺寸，但在高压缩率下性能会急剧下降，甚至不如随机选择，这被归因于视觉令牌的重要性与查询相关，从而质疑了无训练剪枝的可行性。", "method": "本文提出了一种名为结构锚点剪枝（SAP）的无训练剪枝方法。SAP 通过识别文档中间层的关键视觉块（结构锚点）来实现高压缩率下的高性能。此外，引入了 Oracle 分数保留（OSR）协议来评估层级信息对压缩效率的影响。", "result": "在 ViDoRe 基准测试中，SAP 将索引向量尺寸减小了 90% 以上，同时保持了鲁棒的检索保真度。OSR 分析表明，语义结构锚点信息存在于中间层，而传统的剪枝方法侧重于最终层，此时结构信号已经消散。", "conclusion": "SAP 是一种有效的无训练剪枝方法，可以在极高的压缩率下实现高性能的视觉文档检索，并为视觉 RAG 提供了可扩展的解决方案。OSR 分析揭示了中间层包含重要的结构信息，这对理解和改进剪枝策略至关重要。"}}
{"id": "2601.20206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20206", "abs": "https://arxiv.org/abs/2601.20206", "authors": ["Zixuan Xiao", "Chunguang Hu", "Jun Ma"], "title": "Towards Intelligent Urban Park Development Monitoring: LLM Agents for Multi-Modal Information Fusion and Analysis", "comment": null, "summary": "As an important part of urbanization, the development monitoring of newly constructed parks is of great significance for evaluating the effect of urban planning and optimizing resource allocation. However, traditional change detection methods based on remote sensing imagery have obvious limitations in high-level and intelligent analysis, and thus are difficult to meet the requirements of current urban planning and management. In face of the growing demand for complex multi-modal data analysis in urban park development monitoring, these methods often fail to provide flexible analysis capabilities for diverse application scenarios. This study proposes a multi-modal LLM agent framework, which aims to make full use of the semantic understanding and reasoning capabilities of LLM to meet the challenges in urban park development monitoring. In this framework, a general horizontal and vertical data alignment mechanism is designed to ensure the consistency and effective tracking of multi-modal data. At the same time, a specific toolkit is constructed to alleviate the hallucination issues of LLM due to the lack of domain-specific knowledge. Compared to vanilla GPT-4o and other agents, our approach enables robust multi-modal information fusion and analysis, offering reliable and scalable solutions tailored to the diverse and evolving demands of urban park development monitoring.", "AI": {"tldr": "提出了一种多模态大语言模型（LLM）代理框架，用于解决传统遥感方法在城市公园开发监测中的局限性，该框架通过数据对齐和领域知识工具包来提升多模态信息融合和分析能力。", "motivation": "传统基于遥感的城市公园开发监测方法在高级智能分析方面存在不足，难以满足当前城市规划和管理的需求，且在处理复杂多模态数据分析时缺乏灵活性。", "method": "构建了一个多模态LLM代理框架，包含通用的横纵向数据对齐机制以保证多模态数据的一致性，并设计了特定的工具包以减轻LLM因缺乏领域知识而产生的幻觉问题。", "result": "所提出的方法能够实现鲁棒的多模态信息融合与分析，相比于GPT-4o等现有模型，在城市公园开发监测方面提供了更可靠和可扩展的解决方案。", "conclusion": "多模态LLM代理框架能够有效提升城市公园开发监测的智能化水平，满足日益增长的复杂多模态数据分析需求，为城市规划和管理提供更优的支持。"}}
{"id": "2601.19918", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19918", "abs": "https://arxiv.org/abs/2601.19918", "authors": ["Yitong Qiao", "Licheng Pan", "Yu Mi", "Lei Liu", "Yue Shen", "Fei Sun", "Zhixuan Chu"], "title": "Lowest Span Confidence: A Zero-Shot Metric for Efficient and Black-Box Hallucination Detection in LLMs", "comment": null, "summary": "Hallucinations in Large Language Models (LLMs), i.e., the tendency to generate plausible but non-factual content, pose a significant challenge for their reliable deployment in high-stakes environments. However, existing hallucination detection methods generally operate under unrealistic assumptions, i.e., either requiring expensive intensive sampling strategies for consistency checks or white-box LLM states, which are unavailable or inefficient in common API-based scenarios. To this end, we propose a novel efficient zero-shot metric called Lowest Span Confidence (LSC) for hallucination detection under minimal resource assumptions, only requiring a single forward with output probabilities. Concretely, LSC evaluates the joint likelihood of semantically coherent spans via a sliding window mechanism. By identifying regions of lowest marginal confidence across variable-length n-grams, LSC could well capture local uncertainty patterns strongly correlated with factual inconsistency. Importantly, LSC can mitigate the dilution effect of perplexity and the noise sensitivity of minimum token probability, offering a more robust estimate of factual uncertainty. Extensive experiments across multiple state-of-the-art (SOTA) LLMs and diverse benchmarks show that LSC consistently outperforms existing zero-shot baselines, delivering strong detection performance even under resource-constrained conditions.", "AI": {"tldr": "本文提出了一种名为最低跨度置信度（LSC）的新型高效零样本指标，用于在仅需单次前向传递和输出概率的情况下检测大型语言模型（LLMs）的幻觉。LSC通过滑动窗口机制评估语义连贯跨度的联合似然性，能够有效捕捉与事实不一致相关的局部不确定性模式，并且比现有方法更鲁棒。", "motivation": "现有的幻觉检测方法要么需要昂贵的采样策略，要么需要白盒LLM状态，这在API驱动的常见场景中不可行或效率低下。因此，研究者希望开发一种在资源受限的情况下也能有效检测幻觉的新方法。", "method": "提出了一种名为最低跨度置信度（LSC）的零样本指标。LSC通过滑动窗口机制评估语义连贯跨度的联合似然性，通过识别n-gram的最低边际置信度来捕捉局部不确定性。", "result": "LSC在多个SOTA LLMs和多样化基准测试中，相比现有零样本基线，始终表现出更优越的检测性能，即使在资源受限的条件下也能提供强大的检测能力。", "conclusion": "LSC是一种有效且资源需求低的幻觉检测方法，能够有效缓解困惑度和最小令牌概率的缺点，为检测LLM中的事实不确定性提供了一种更鲁棒的估计。"}}
{"id": "2601.20239", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20239", "abs": "https://arxiv.org/abs/2601.20239", "authors": ["Zhemeng Zhang", "Jiahua Ma", "Xincheng Yang", "Xin Wen", "Yuzhi Zhang", "Boyan Li", "Yiran Qin", "Jin Liu", "Can Zhao", "Li Kang", "Haoqin Hong", "Zhenfei Yin", "Philip Torr", "Hao Su", "Ruimao Zhang", "Daolin Ma"], "title": "TouchGuide: Inference-Time Steering of Visuomotor Policies via Touch Guidance", "comment": null, "summary": "Fine-grained and contact-rich manipulation remain challenging for robots, largely due to the underutilization of tactile feedback. To address this, we introduce TouchGuide, a novel cross-policy visuo-tactile fusion paradigm that fuses modalities within a low-dimensional action space. Specifically, TouchGuide operates in two stages to guide a pre-trained diffusion or flow-matching visuomotor policy at inference time. First, the policy produces a coarse, visually-plausible action using only visual inputs during early sampling. Second, a task-specific Contact Physical Model (CPM) provides tactile guidance to steer and refine the action, ensuring it aligns with realistic physical contact conditions. Trained through contrastive learning on limited expert demonstrations, the CPM provides a tactile-informed feasibility score to steer the sampling process toward refined actions that satisfy physical contact constraints. Furthermore, to facilitate TouchGuide training with high-quality and cost-effective data, we introduce TacUMI, a data collection system. TacUMI achieves a favorable trade-off between precision and affordability; by leveraging rigid fingertips, it obtains direct tactile feedback, thereby enabling the collection of reliable tactile data. Extensive experiments on five challenging contact-rich tasks, such as shoe lacing and chip handover, show that TouchGuide consistently and significantly outperforms state-of-the-art visuo-tactile policies.", "AI": {"tldr": "本文提出了一种名为TouchGuide的新型视觉-触觉融合范式，通过结合视觉和触觉反馈来提升机器人精细、接触密集型操作的能力，并在挑战性的任务上取得了显著优于现有方法的性能。", "motivation": "机器人难以实现精细和接触密集型操作，主要原因是触觉反馈利用不足。因此，研究的动机是开发一种能够有效融合视觉和触觉信息的方法，以提高机器人在这类任务中的性能。", "method": "TouchGuide是一种跨策略的视觉-触觉融合范式，它在低维动作空间内融合了视觉和触觉模态。该方法分两阶段进行：1. 策略（预训练的扩散或流匹配视觉运动策略）在早期采样时仅使用视觉输入生成粗略的、视觉上可信的动作。2. 任务特定的接触物理模型（CPM）提供触觉指导，以引导和精炼动作，确保其符合真实的物理接触条件。CPM通过对比学习在有限的专家演示上进行训练，提供触觉信息的可行性得分，以指导采样过程生成满足物理接触约束的精炼动作。此外，还引入了TacUMI数据收集系统，用于高效采集高质量的触觉数据。", "result": "在五个具有挑战性的接触密集型任务（如鞋带系法和芯片交接）上的广泛实验表明，TouchGuide的性能始终且显著优于最先进的视觉-触觉策略。", "conclusion": "TouchGuide通过融合视觉和触觉反馈，有效提升了机器人执行接触密集型操作的能力，并在多项挑战性任务中证明了其优越性。TacUMI系统则为触觉数据的高效采集提供了解决方案。"}}
{"id": "2601.20168", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20168", "abs": "https://arxiv.org/abs/2601.20168", "authors": ["Zhewen Wan", "Tianchen Song", "Chen Lin", "Zhiyong Zhao", "Xianpeng Lang"], "title": "Efficient Token Pruning for LLaDA-V", "comment": null, "summary": "Diffusion-based large multimodal models, such as LLaDA-V, have demonstrated impressive capabilities in vision-language understanding and generation. However, their bidirectional attention mechanism and diffusion-style iterative denoising paradigm introduce significant computational overhead, as visual tokens are repeatedly processed across all layers and denoising steps. In this work, we conduct an in-depth attention analysis and reveal that, unlike autoregressive decoders, LLaDA-V aggregates cross-modal information predominantly in middle-to-late layers, leading to delayed semantic alignment. Motivated by this observation, we propose a structured token pruning strategy inspired by FastV, selectively removing a proportion of visual tokens at designated layers to reduce FLOPs while preserving critical semantic information. To the best of our knowledge, this is the first work to investigate structured token pruning in diffusion-based large multimodal models. Unlike FastV, which focuses on shallow-layer pruning, our method targets the middle-to-late layers of the first denoising step to align with LLaDA-V's delayed attention aggregation to maintain output quality, and the first-step pruning strategy reduces the computation across all subsequent steps. Our framework provides an empirical basis for efficient LLaDA-V inference and highlights the potential of vision-aware pruning in diffusion-based multimodal models. Across multiple benchmarks, our best configuration reduces computational cost by up to 65% while preserving an average of 95% task performance.", "AI": {"tldr": "该研究提出一种针对基于扩散的大型多模态模型（如LLaDA-V）的结构化 token 剪枝策略，通过移除中间至后层（而非浅层）的视觉 token 来降低计算量，同时保持任务性能。", "motivation": "基于扩散的大型多模态模型（如 LLaDA-V）存在计算开销大的问题，因为视觉 token 会在所有层和所有去噪步骤中被重复处理。研究人员发现 LLaDA-V 的跨模态信息聚合主要发生在中间到后层，导致语义对齐延迟。", "method": "受 FastV 启发，提出一种结构化 token 剪枝策略，选择性地移除模型中间到后层（特别是第一步去噪过程）的一部分视觉 token。此策略旨在与 LLaDA-V 的延迟注意力聚合特性相匹配，并在第一步剪枝以减少后续所有步骤的计算量。", "result": "在多个基准测试中，最佳配置可将计算成本降低高达 65%，同时保留平均 95% 的任务性能。", "conclusion": "该方法为 LLaDA-V 的高效推理提供了实证基础，并展示了面向视觉的剪枝在基于扩散的多模态模型中的潜力。这是首次针对基于扩散的大型多模态模型进行结构化 token 剪枝的研究。"}}
{"id": "2601.20723", "categories": ["eess.SY", "cs.GT", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.20723", "abs": "https://arxiv.org/abs/2601.20723", "authors": ["Emrah Akyol", "Marcos Vasconcelos"], "title": "Distributed Learning over Noisy Communication Networks", "comment": "draft, submitted to IEEE JSAC Special Issue on Distributed Optimization, Learning, and Inference over Communication-Constrained Networks", "summary": "We study binary coordination games over graphs under log-linear learning when neighbor actions are conveyed through explicit noisy communication links. Each edge is modeled as either a binary symmetric channel (BSC) or a binary erasure channel (BEC). We analyze two operational regimes. For binary symmetric and binary erasure channels, we provide a structural characterization of the induced learning dynamics. In a fast-communication regime, agents update using channel-averaged payoffs; the resulting learning dynamics coincide with a Gibbs sampler for a scaled coordination potential, where channel reliability enters only through a scalar attenuation coefficient. In a snapshot regime, agents update from a single noisy realization and ignore channel statistics; the induced Markov chain is generally nonreversible, but admits a high-temperature expansion whose drift matches that of the fast Gibbs sampler with the same attenuation. We further formalize a finite-$K$ communication budget, which interpolates between snapshot and fast behavior as the number of channel uses per update grows. This viewpoint yields a communication-theoretic interpretation in terms of retransmissions and repetition coding, and extends naturally to heterogeneous link reliabilities via effective edge weights. Numerical experiments illustrate the theory and quantify the tradeoff between communication resources and steady-state coordination quality.", "AI": {"tldr": "该研究分析了在具有噪声通信链接的图上的二元协调博弈中的对数线性学习动力学，考虑了二元对称信道（BSC）和二元擦除信道（BEC）。研究了快通信和快照两种运行模式，并提出了一个有限通信预算模型，该模型可以插值于这两种模式之间。", "motivation": "研究的动机是理解在存在噪声通信的情况下，多智能体系统中协调行为的出现。具体来说，作者希望分析当邻居行为通过有噪声的通信链路传递时，智能体如何学习并协调其行动。", "method": "研究人员使用对数线性学习模型，并考虑了二元对称信道（BSC）和二元擦除信道（BEC）作为通信模型。他们分析了两种操作模式：快通信模式（智能体使用信道平均收益进行更新）和快照模式（智能体从单次噪声观测进行更新）。此外，他们还引入了一个有限通信预算的概念，以表征不同通信模式之间的过渡，并利用高阶泰勒展开来分析快照模式下的动力学。", "result": "在快通信模式下，学习动力学等同于一个缩放的协调势函数的Gibbs采样器，信道可靠性仅通过一个标量衰减系数体现。在快照模式下，马尔可夫链通常是不可逆的，但其高阶展开的漂移与快通信模式下的Gibbs采样器相匹配。有限通信预算模型提供了一种通信理论解释，并自然地扩展到异构链路可靠性。", "conclusion": "该研究对噪声通信下的二元协调博弈学习动力学进行了结构化表征。研究结果表明，通信的可靠性和资源（如通信次数）对协调的质量有重要影响，并提供了一种量化这种权衡的方法。有限通信预算模型为理解不同通信模式下的学习行为提供了一个统一的框架。"}}
{"id": "2601.20262", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20262", "abs": "https://arxiv.org/abs/2601.20262", "authors": ["Boseong Jeon", "Yunho Choi", "Taehan Kim"], "title": "Shallow-π: Knowledge Distillation for Flow-based VLAs", "comment": null, "summary": "The growing demand for real-time robotic deployment necessitates fast and on-device inference for vision-language-action (VLA) models. Within the VLA literature, efficiency has been extensively studied at the token level, such as visual token pruning. In contrast, systematic transformer layer reduction has received limited attention and, to the best of our knowledge, has not been explored for flow-based VLA models under knowledge distillation. In this work, we propose Shallow-pi, a principled knowledge distillation framework that aggressively reduces the transformer depth of both the VLM backbone and the flow-based action head, compressing the model from 18 to 6 layers. Shallow-pi achieves over two times faster inference with less than one percent absolute drop in success rate on standard manipulation benchmarks, establishing state-of-the-art performance among reduced VLA models. Crucially, we validate our approach through industrial-scale real-world experiments on Jetson Orin and Jetson Thor across multiple robot platforms, including humanoid systems, in complex and dynamic manipulation scenarios.", "AI": {"tldr": "提出了一种名为Shallow-pi的知识蒸馏框架，通过大幅削减Transformer层数，实现了VLA模型（视觉-语言-动作模型）的推理速度提升两倍以上，同时成功率仅下降不到1%，并在真实世界机器人实验中验证了其有效性。", "motivation": "实时机器人部署对VLA模型提出了快速、设备端推理的需求。现有研究主要关注token层面的效率提升，而Transformer层数的系统性削减，尤其是在流式VLA模型上的知识蒸馏，研究较少。", "method": "提出Shallow-pi知识蒸馏框架，通过蒸馏压缩VLM骨干和流式动作头的Transformer层数，将模型从18层减少到6层。", "result": "Shallow-pi在标准操作基准上实现了超过两倍的推理速度提升，成功率仅下降不到1%，并在Jetson Orin和Jetson Thor等硬件上进行了工业规模的真实世界机器人实验验证，包括人形机器人。", "conclusion": "Shallow-pi是一种有效的知识蒸馏方法，能够显著加速VLA模型的推理速度，同时保持高成功率，适用于资源受限的机器人部署场景，并在复杂的真实世界操作任务中表现出色。"}}
{"id": "2601.20221", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20221", "abs": "https://arxiv.org/abs/2601.20221", "authors": ["Hang Zhang", "Ruheng Wang", "Yuelyu Ji", "Mingu Kwak", "Xizhi Wu", "Chenyu Li", "Li Zhang", "Wenqi Shi", "Yifan Peng", "Yanshan Wang"], "title": "Scaling Medical Reasoning Verification via Tool-Integrated Reinforcement Learning", "comment": null, "summary": "Large language models have achieved strong performance on medical reasoning benchmarks, yet their deployment in clinical settings demands rigorous verification to ensure factual accuracy. While reward models offer a scalable approach for reasoning trace verification, existing methods face two limitations: they produce only scalar reward values without explicit justification, and they rely on single-pass retrieval that precludes adaptive knowledge access as verification unfolds. We introduce $\\method$, an agentic framework that addresses these limitations by training medical reasoning verifiers to iteratively query external medical corpora during evaluation. Our approach combines tool-augmented verification with an iterative reinforcement learning paradigm that requires only trace-level supervision, alongside an adaptive curriculum mechanism that dynamically adjusts training data distribution. Across four medical reasoning benchmarks, $\\method$ achieves substantial gains over existing methods, improving MedQA accuracy by 23.5% and MedXpertQA by 32.0% relative to the base generator in particular. Crucially, $\\method$ demonstrates an $\\mathbf{8\\times}$ reduction in sampling budget requirement compared to prior reward model baselines. These findings establish that grounding verification in dynamically retrieved evidence offers a principled path toward more reliable medical reasoning systems.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.19919", "categories": ["cs.CL", "cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.19919", "abs": "https://arxiv.org/abs/2601.19919", "authors": ["Junseok Lee", "Nahoon Kim", "Sangyong Lee", "Chang-Jae Chun"], "title": "FastWhisper: Adaptive Self-knowledge Distillation for Real-time Automatic Speech Recognition", "comment": null, "summary": "Knowledge distillation is one of the most effective methods for model compression. Previous studies have focused on the student model effectively training the predictive distribution of the teacher model. However, during training, the student model may inherit the shortcomings of the teacher model, which can lead to a decline in generalization capacity. To mitigate this issue, we propose adaptive self-knowledge distillation (ASKD), which dynamically reduces the dependence of the teacher model to improve the self-training capacity, and performs the self-knowledge distillation method to improve the generalization capacity of the student model. We further distill the Whisper model into a smaller variant, called FastWhisper. In our post-training setting, FastWhisper achieved a word error rate of 1.07% lower than the teacher model Whisper, and its relative inference time was 5 times faster.", "AI": {"tldr": "本文提出了一种自适应自知识蒸馏（ASKD）方法，通过动态降低教师模型依赖来增强学生模型的自训练和泛化能力，并成功将Whisper模型压缩为FastWhisper，实现了更低的错误率和更快的推理速度。", "motivation": "现有的知识蒸馏方法主要关注学生模型模仿教师模型的预测分布，但可能继承教师模型的缺点，导致泛化能力下降。作者希望解决这一问题。", "method": "提出自适应自知识蒸馏（ASKD）方法，该方法能够动态调整对教师模型的依赖，增强学生模型的自训练能力，并通过自知识蒸馏提升泛化能力。将ASKD应用于Whisper模型，生成一个更小的变体FastWhisper。", "result": "在后训练设置下，FastWhisper的词错误率比Whisper模型低1.07%，推理速度提高了5倍。", "conclusion": "ASKD是一种有效的模型压缩方法，能够显著提升学生模型的泛化能力，同时实现更高的推理效率。FastWhisper作为ASKD应用于Whisper模型的成功案例，证明了该方法的有效性。"}}
{"id": "2601.20175", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20175", "abs": "https://arxiv.org/abs/2601.20175", "authors": ["Shiwen Zhang", "Xiaoyan Yang", "Bojia Zi", "Haibin Huang", "Chi Zhang", "Xuelong Li"], "title": "TeleStyle: Content-Preserving Style Transfer in Images and Videos", "comment": null, "summary": "Content-preserving style transfer, generating stylized outputs based on content and style references, remains a significant challenge for Diffusion Transformers (DiTs) due to the inherent entanglement of content and style features in their internal representations. In this technical report, we present TeleStyle, a lightweight yet effective model for both image and video stylization. Built upon Qwen-Image-Edit, TeleStyle leverages the base model's robust capabilities in content preservation and style customization. To facilitate effective training, we curated a high-quality dataset of distinct specific styles and further synthesized triplets using thousands of diverse, in-the-wild style categories. We introduce a Curriculum Continual Learning framework to train TeleStyle on this hybrid dataset of clean (curated) and noisy (synthetic) triplets. This approach enables the model to generalize to unseen styles without compromising precise content fidelity. Additionally, we introduce a video-to-video stylization module to enhance temporal consistency and visual quality. TeleStyle achieves state-of-the-art performance across three core evaluation metrics: style similarity, content consistency, and aesthetic quality. Code and pre-trained models are available at https://github.com/Tele-AI/TeleStyle", "AI": {"tldr": "TeleStyle是一个轻量级的图像和视频风格迁移模型，通过利用Qwen-Image-Edit的基础能力、构建高质量数据集和采用课程持续学习框架，实现了在内容保持和风格定制方面的最先进性能。", "motivation": "Diffusion Transformers (DiTs)在内容保持的风格迁移方面面临挑战，因为其内部表示中内容和风格特征容易纠缠。本研究旨在开发一个能够有效进行图像和视频风格迁移的模型，同时保持内容保真度。", "method": "TeleStyle基于Qwen-Image-Edit，并采用了以下方法：1. 建立高质量的特定风格数据集并合成包含大量风格类别的三元组数据。2. 引入课程持续学习框架，在混合数据集（精选和合成）上训练模型。3. 开发视频到视频的风格迁移模块，以增强时间一致性和视觉质量。", "result": "TeleStyle在风格相似度、内容一致性和美学质量三个核心评估指标上均取得了最先进的性能。", "conclusion": "TeleStyle通过其创新的训练框架和模块设计，成功解决了DiTs在内容保持风格迁移中的挑战，并在图像和视频风格迁移任务上展现出卓越的性能和泛化能力。"}}
{"id": "2601.20321", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20321", "abs": "https://arxiv.org/abs/2601.20321", "authors": ["Yuzhe Huang", "Pei Lin", "Wanlin Li", "Daohan Li", "Jiajun Li", "Jiaming Jiang", "Chenxi Xiao", "Ziyuan Jiao"], "title": "Tactile-Force Alignment in Vision-Language-Action Models for Force-aware Manipulation", "comment": "17pages,9fig", "summary": "Vision-Language-Action (VLA) models have recently emerged as powerful generalists for robotic manipulation. However, due to their predominant reliance on visual modalities, they fundamentally lack the physical intuition required for contact-rich tasks that require precise force regulation and physical reasoning. Existing attempts to incorporate vision-based tactile sensing into VLA models typically treat tactile inputs as auxiliary visual textures, thereby overlooking the underlying correlation between surface deformation and interaction dynamics. To bridge this gap, we propose a paradigm shift from tactile-vision alignment to tactile-force alignment. Here, we introduce TaF-VLA, a framework that explicitly grounds high-dimensional tactile observations in physical interaction forces. To facilitate this, we develop an automated tactile-force data acquisition device and curate the TaF-Dataset, comprising over 10 million synchronized tactile observations, 6-axis force/torque, and matrix force map. To align sequential tactile observations with interaction forces, the central component of our approach is the Tactile-Force Adapter (TaF-Adapter), a tactile sensor encoder that extracts discretized latent information for encoding tactile observations. This mechanism ensures that the learned representations capture history-dependent, noise-insensitive physical dynamics rather than static visual textures. Finally, we integrate this force-aligned encoder into a VLA backbone. Extensive real-world experiments demonstrate that TaF-VLA policy significantly outperforms state-of-the-art tactile-vision-aligned and vision-only baselines on contact-rich tasks, verifying its ability to achieve robust, force-aware manipulation through cross-modal physical reasoning.", "AI": {"tldr": "本文提出了一种名为TaF-VLA的框架，通过将触觉信号与物理交互力对齐，而非仅与视觉对齐，来增强机器人操纵能力，特别是在需要精细力反馈的接触密集型任务中。", "motivation": "现有的视觉-语言-动作（VLA）模型在处理需要精确力控制和物理推理的接触密集型任务时，由于过度依赖视觉信息，缺乏必要的物理直觉。现有的将触觉纳入VLA的方法通常将触觉视为辅助视觉纹理，忽视了表面形变与交互动力学之间的深层关联。", "method": "提出了一种从“触觉-视觉对齐”转变为“触觉-力对齐”的新范式。开发了一个自动触觉-力数据采集设备，并构建了TaF-Dataset。核心组件是Tactile-Force Adapter（TaF-Adapter），一个触觉传感器编码器，用于提取离散化的潜在信息，将序列触觉观察与交互力对齐，确保学习到的表示捕获与历史相关的、对噪声不敏感的物理动力学。最后将此力对齐编码器集成到VLA骨干网络中。", "result": "在接触密集型任务上，TaF-VLA策略相比于最先进的触觉-视觉对齐和纯视觉基线，在真实世界实验中表现出显著优越的性能。", "conclusion": "TaF-VLA框架通过跨模态的物理推理，能够实现鲁棒、力感知的机器人操纵，解决了现有VLA模型在处理复杂接触任务时的局限性。"}}
{"id": "2601.20305", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20305", "abs": "https://arxiv.org/abs/2601.20305", "authors": ["Zhenchen Tang", "Songlin Yang", "Zichuan Wang", "Bo Peng", "Yang Li", "Beibei Dong", "Jing Dong"], "title": "Endogenous Reprompting: Self-Evolving Cognitive Alignment for Unified Multimodal Models", "comment": null, "summary": "Unified Multimodal Models (UMMs) exhibit strong understanding, yet this capability often fails to effectively guide generation. We identify this as a Cognitive Gap: the model lacks the understanding of how to enhance its own generation process. To bridge this gap, we propose Endogenous Reprompting, a mechanism that transforms the model's understanding from a passive encoding process into an explicit generative reasoning step by generating self-aligned descriptors during generation. To achieve this, we introduce SEER (Self-Evolving Evaluator and Reprompter), a training framework that establishes a two-stage endogenous loop using only 300 samples from a compact proxy task, Visual Instruction Elaboration. First, Reinforcement Learning with Verifiable Rewards (RLVR) activates the model's latent evaluation ability via curriculum learning, producing a high-fidelity endogenous reward signal. Second, Reinforcement Learning with Model-rewarded Thinking (RLMT) leverages this signal to optimize the generative reasoning policy. Experiments show that SEER consistently outperforms state-of-the-art baselines in evaluation accuracy, reprompting efficiency, and generation quality, without sacrificing general multimodal capabilities.", "AI": {"tldr": "本文提出了一种名为SEER的框架，通过内生重提示（Endogenous Reprompting）来弥合统一多模态模型（UMMs）在理解和生成之间的认知差距，提升其生成能力。", "motivation": "统一多模态模型（UMMs）虽然理解能力强，但其理解能力未能有效指导生成过程，存在“认知差距”。研究旨在解决这一问题。", "method": "提出内生重提示（Endogenous Reprompting）机制，通过在生成过程中产生自我对齐的描述符，将模型的理解从被动编码转变为显式的生成推理步骤。引入SEER（Self-Evolving Evaluator and Reprompter）训练框架，包含两个阶段：1. 使用可验证奖励的强化学习（RLVR）通过课程学习激活模型的潜在评估能力，生成内生奖励信号；2. 使用模型奖励思维的强化学习（RLMT）利用该信号优化生成推理策略。仅使用300个来自Visual Instruction Elaboration代理任务的样本。", "result": "SEER在评估准确性、重提示效率和生成质量方面始终优于最先进的基线模型，且不影响通用的多模态能力。", "conclusion": "SEER框架能够有效弥合UMMs的认知差距，通过内生重提示显著提升其生成能力，并且在少量样本上即可实现高性能。"}}
{"id": "2601.20196", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20196", "abs": "https://arxiv.org/abs/2601.20196", "authors": ["Brayden Hamilton", "Tim Cashmore", "Peter Driscoll", "Trevor Gee", "Henry Williams"], "title": "Automated Marine Biofouling Assessment: Benchmarking Computer Vision and Multimodal LLMs on the Level of Fouling Scale", "comment": "Australasian Conference on Robotics and Automation, ACRA2025 13 Pages, 8 Figures", "summary": "Marine biofouling on vessel hulls poses major ecological, economic, and biosecurity risks. Traditional survey methods rely on diver inspections, which are hazardous and limited in scalability. This work investigates automated classification of biofouling severity on the Level of Fouling (LoF) scale using both custom computer vision models and large multimodal language models (LLMs). Convolutional neural networks, transformer-based segmentation, and zero-shot LLMs were evaluated on an expert-labelled dataset from the New Zealand Ministry for Primary Industries. Computer vision models showed high accuracy at extreme LoF categories but struggled with intermediate levels due to dataset imbalance and image framing. LLMs, guided by structured prompts and retrieval, achieved competitive performance without training and provided interpretable outputs. The results demonstrate complementary strengths across approaches and suggest that hybrid methods integrating segmentation coverage with LLM reasoning offer a promising pathway toward scalable and interpretable biofouling assessment.", "AI": {"tldr": "该研究探索了使用计算机视觉模型和大型多模态语言模型（LLMs）自动评估船舶船体生物污损程度（LoF）。结果表明，LLMs在无需训练的情况下表现出有竞争力的性能，并且输出结果具有可解释性，与计算机视觉模型的互补性相结合，为生物污损评估的规模化和可解释性提供了新的途径。", "motivation": "传统的船舶生物污损调查方法（如潜水员检查）存在危险且难以规模化。本研究旨在开发更安全、更高效的自动化评估方法。", "method": "利用自定义计算机视觉模型（卷积神经网络、Transformer-based segmentation）和大型多模态语言模型（LLMs，采用零样本学习和结构化提示）对新西兰 MPI 提供的专家标注数据集进行生物污损程度（LoF）的分类。", "result": "计算机视觉模型在极端 LoF 类别上表现出高精度，但在中等类别上因数据不平衡和图像框架问题而受到限制。LLMs 在无需训练的情况下，通过结构化提示和检索达到了具有竞争力的性能，并提供了可解释的输出。", "conclusion": "不同的评估方法具有互补的优势。结合图像分割的覆盖率信息和 LLMs 的推理能力，是一种有前景的、可规模化且可解释的生物污损评估方法。"}}
{"id": "2601.19921", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19921", "abs": "https://arxiv.org/abs/2601.19921", "authors": ["Xiaochen Zhu", "Caiqi Zhang", "Yizhou Chi", "Tom Stafford", "Nigel Collier", "Andreas Vlachos"], "title": "Demystifying Multi-Agent Debate: The Role of Confidence and Diversity", "comment": null, "summary": "Multi-agent debate (MAD) is widely used to improve large language model (LLM) performance through test-time scaling, yet recent work shows that vanilla MAD often underperforms simple majority vote despite higher computational cost. Studies show that, under homogeneous agents and uniform belief updates, debate preserves expected correctness and therefore cannot reliably improve outcomes. Drawing on findings from human deliberation and collective decision-making, we identify two key mechanisms missing from vanilla MAD: (i) diversity of initial viewpoints and (ii) explicit, calibrated confidence communication. We propose two lightweight interventions. First, a diversity-aware initialisation that selects a more diverse pool of candidate answers, increasing the likelihood that a correct hypothesis is present at the start of debate. Second, a confidence-modulated debate protocol in which agents express calibrated confidence and condition their updates on others' confidence. We show theoretically that diversity-aware initialisation improves the prior probability of MAD success without changing the underlying update dynamics, while confidence-modulated updates enable debate to systematically drift to the correct hypothesis. Empirically, across six reasoning-oriented QA benchmarks, our methods consistently outperform vanilla MAD and majority vote. Our results connect human deliberation with LLM-based debate and demonstrate that simple, principled modifications can substantially enhance debate effectiveness.", "AI": {"tldr": "本文提出了一种改进的多智能体辩论（MAD）方法，通过引入多样化的初始观点和显式的置信度沟通，显著提升了大型语言模型（LLM）在推理型问答任务上的表现，优于传统的MAD和多数投票。", "motivation": "现有的多智能体辩论（MAD）方法虽然在测试时能扩展LLM性能，但在计算成本更高的情况下，其表现往往不如简单的多数投票。研究表明，在同质智能体和统一信念更新的假设下，MAD无法可靠地提升结果的正确性。因此，有必要借鉴人类决策和集体决策的经验，改进MAD。", "method": "本文提出了两种轻量级的改进机制：1. 多样性感知初始化：通过选择更多样化的候选答案来增加正确假设在辩论开始时就存在的可能性。2. 置信度调制辩论协议：智能体表达经过校准的置信度，并根据其他智能体的置信度来调整其信念更新。理论上证明了多样性初始化能提高MAD成功的先验概率，而置信度调制更新则能使辩论系统性地趋向正确假设。", "result": "在六个推理型问答基准测试中，所提出的方法在多样性感知初始化和置信度调制更新的共同作用下，持续优于传统的MAD和多数投票。", "conclusion": "通过结合人类决策机制（观点多样性和置信度沟通）与LLM辩论，本文证明了简单且符合原则的修改可以显著提高MAD的有效性，为LLM的推理和决策提供了新的方向。"}}
{"id": "2601.20334", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20334", "abs": "https://arxiv.org/abs/2601.20334", "authors": ["Brian Y. Tsui", "Alan Y. Fang", "Tiffany J. Hwu"], "title": "Demonstration-Free Robotic Control via LLM Agents", "comment": null, "summary": "Robotic manipulation has increasingly adopted vision-language-action (VLA) models, which achieve strong performance but typically require task-specific demonstrations and fine-tuning, and often generalize poorly under domain shift. We investigate whether general-purpose large language model (LLM) agent frameworks, originally developed for software engineering, can serve as an alternative control paradigm for embodied manipulation. We introduce FAEA (Frontier Agent as Embodied Agent), which applies an LLM agent framework directly to embodied manipulation without modification. Using the same iterative reasoning that enables software agents to debug code, FAEA enables embodied agents to reason through manipulation strategies. We evaluate an unmodified frontier agent, Claude Agent SDK, across the LIBERO, ManiSkill3, and MetaWorld benchmarks. With privileged environment state access, FAEA achieves success rates of 84.9%, 85.7%, and 96%, respectively. This level of task success approaches that of VLA models trained with less than 100 demonstrations per task, without requiring demonstrations or fine-tuning. With one round of human feedback as an optional optimization, performance increases to 88.2% on LIBERO. This demonstration-free capability has immediate practical value: FAEA can autonomously explore novel scenarios in simulation and generate successful trajectories for training data augmentation in embodied learning. Our results indicate that general-purpose agents are sufficient for a class of manipulation tasks dominated by deliberative, task-level planning. This opens a path for robotics systems to leverage actively maintained agent infrastructure and benefit directly from ongoing advances in frontier models. Code is available at https://github.com/robiemusketeer/faea-sim", "AI": {"tldr": "本文提出FAEA（Frontier Agent as Embodied Agent），一种直接将LLM agent框架应用于机器人操作的方法，无需特定任务演示或微调。FAEA利用LLM的迭代推理能力来制定操作策略，在LIBERO、ManiSkill3和MetaWorld基准测试中取得了接近VLA模型的成功率，并且在有少量人类反馈时性能有所提升。", "motivation": "现有的机器人操作VLA模型通常需要任务特定的演示和微调，并且在领域迁移时泛化能力差。研究者希望探索是否可以直接利用为软件工程设计的通用LLM agent框架来作为机器人操作的替代控制范式。", "method": "FAEA直接将一个未修改的LLM agent框架（Claude Agent SDK）应用于具身操作任务。它利用LLM的迭代推理能力，模拟调试代码的逻辑来规划操作策略。研究评估了在LIBERO、ManiSkill3和MetaWorld基准测试中使用FAEA的情况，并考虑了可选的人类反馈优化。", "result": "在LIBERO、ManiSkill3和MetaWorld基准测试中，FAEA分别取得了84.9%、85.7%和96%的成功率。在不需要演示或微调的情况下，其性能接近于仅使用少于100个演示训练的VLA模型。通过一轮可选的人类反馈，LIBERO上的性能提升到88.2%。", "conclusion": "通用LLM agent框架（如FAEA）足以应对需要深思熟虑、任务级规划的一类机器人操作任务。FAEA的无演示能力具有实际应用价值，可用于自主探索新场景和生成用于数据增强的训练轨迹。这项研究为机器人系统利用主动维护的agent基础设施并直接受益于前沿模型的发展开辟了道路。"}}
{"id": "2601.20323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20323", "abs": "https://arxiv.org/abs/2601.20323", "authors": ["Hyunseung Chung", "Jungwoo Oh", "Daeun Kyung", "Jiho Kim", "Yeonsu Kwon", "Min-Gyu Kim", "Edward Choi"], "title": "ECG-Agent: On-Device Tool-Calling Agent for ECG Multi-Turn Dialogue", "comment": "Accepted to ICASSP 2026 (5 pages, 2 figures, 5 tables)", "summary": "Recent advances in Multimodal Large Language Models have rapidly expanded to electrocardiograms, focusing on classification, report generation, and single-turn QA tasks. However, these models fall short in real-world scenarios, lacking multi-turn conversational ability, on-device efficiency, and precise understanding of ECG measurements such as the PQRST intervals. To address these limitations, we introduce ECG-Agent, the first LLM-based tool-calling agent for multi-turn ECG dialogue. To facilitate its development and evaluation, we also present ECG-Multi-Turn-Dialogue (ECG-MTD) dataset, a collection of realistic user-assistant multi-turn dialogues for diverse ECG lead configurations. We develop ECG-Agents in various sizes, from on-device capable to larger agents. Experimental results show that ECG-Agents outperform baseline ECG-LLMs in response accuracy. Furthermore, on-device agents achieve comparable performance to larger agents in various evaluations that assess response accuracy, tool-calling ability, and hallucinations, demonstrating their viability for real-world applications.", "AI": {"tldr": "本文提出了ECG-Agent，一个用于多轮ECG对话的基于LLM的工具调用代理，并发布了ECG-MTD数据集。ECG-Agent在响应准确性、工具调用能力和幻觉方面优于基线ECG-LLM，并且轻量级模型在设备上表现良好。", "motivation": "现有的多模态大语言模型在ECG领域主要集中在单轮任务，缺乏多轮对话能力、设备效率和对PQRST等ECG测量值的精确理解，无法满足实际应用需求。", "method": "提出ECG-Agent，一个基于LLM的工具调用代理，用于多轮ECG对话。同时发布ECG-MTD数据集，包含用户-助手之间的多轮对话。开发了不同大小的ECG-Agent，包括适用于设备上的轻量级模型。", "result": "ECG-Agent在响应准确性方面优于基线ECG-LLMs。轻量级ECG-Agent在评估响应准确性、工具调用能力和幻觉方面，表现与大型模型相当，证明了其在实际应用中的可行性。", "conclusion": "ECG-Agent是首个用于多轮ECG对话的LLM工具调用代理，并且轻量级模型能够高效地执行多轮ECG对话任务，为ECG领域的实际应用开辟了新的可能性。"}}
{"id": "2601.20218", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20218", "abs": "https://arxiv.org/abs/2601.20218", "authors": ["Haoyou Deng", "Keyu Yan", "Chaojie Mao", "Xiang Wang", "Yu Liu", "Changxin Gao", "Nong Sang"], "title": "DenseGRPO: From Sparse to Dense Reward for Flow Matching Model Alignment", "comment": "Accepted by ICLR 2026", "summary": "Recent GRPO-based approaches built on flow matching models have shown remarkable improvements in human preference alignment for text-to-image generation. Nevertheless, they still suffer from the sparse reward problem: the terminal reward of the entire denoising trajectory is applied to all intermediate steps, resulting in a mismatch between the global feedback signals and the exact fine-grained contributions at intermediate denoising steps. To address this issue, we introduce \\textbf{DenseGRPO}, a novel framework that aligns human preference with dense rewards, which evaluates the fine-grained contribution of each denoising step. Specifically, our approach includes two key components: (1) we propose to predict the step-wise reward gain as dense reward of each denoising step, which applies a reward model on the intermediate clean images via an ODE-based approach. This manner ensures an alignment between feedback signals and the contributions of individual steps, facilitating effective training; and (2) based on the estimated dense rewards, a mismatch drawback between the uniform exploration setting and the time-varying noise intensity in existing GRPO-based methods is revealed, leading to an inappropriate exploration space. Thus, we propose a reward-aware scheme to calibrate the exploration space by adaptively adjusting a timestep-specific stochasticity injection in the SDE sampler, ensuring a suitable exploration space at all timesteps. Extensive experiments on multiple standard benchmarks demonstrate the effectiveness of the proposed DenseGRPO and highlight the critical role of the valid dense rewards in flow matching model alignment.", "AI": {"tldr": "本文提出了一种名为 DenseGRPO 的新框架，通过引入密集的、逐个去噪步骤的奖励来解决现有 GRPO 方法中奖励稀疏的问题，并提出了一种奖励感知的随机性注入方案来优化探索空间。", "motivation": "现有的基于 GRPO 的文本到图像生成模型存在奖励稀疏问题，即全局奖励信号与中间去噪步骤的精确贡献不匹配，导致训练效率低下。", "method": "DenseGRPO 框架包含两个主要组件：1. 预测每一步的奖励增益作为密集奖励，通过 ODE 方法在中间清晰图像上应用奖励模型。2. 基于估计的密集奖励，提出一种奖励感知的方案，通过自适应调整 SDE 采样器中特定时间步的随机性注入来校准探索空间。", "result": "通过实验证明了 DenseGRPO 在多个标准基准上的有效性，并突出了有效密集奖励在流匹配模型对齐中的关键作用。", "conclusion": "DenseGRPO 通过引入密集奖励和优化探索空间，有效解决了现有 GRPO 方法的奖励稀疏问题，显著提升了文本到图像生成模型在人类偏好对齐方面的性能。"}}
{"id": "2601.19922", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19922", "abs": "https://arxiv.org/abs/2601.19922", "authors": ["Laya Iyer", "Kriti Aggarwal", "Sanmi Koyejo", "Gail Heyman", "Desmond C. Ong", "Subhabrata Mukherjee"], "title": "HEART: A Unified Benchmark for Assessing Humans and LLMs in Emotional Support Dialogue", "comment": null, "summary": "Supportive conversation depends on skills that go beyond language fluency, including reading emotions, adjusting tone, and navigating moments of resistance, frustration, or distress. Despite rapid progress in language models, we still lack a clear way to understand how their abilities in these interpersonal domains compare to those of humans. We introduce HEART, the first-ever framework that directly compares humans and LLMs on the same multi-turn emotional-support conversations. For each dialogue history, we pair human and model responses and evaluate them through blinded human raters and an ensemble of LLM-as-judge evaluators. All assessments follow a rubric grounded in interpersonal communication science across five dimensions: Human Alignment, Empathic Responsiveness, Attunement, Resonance, and Task-Following. HEART uncovers striking behavioral patterns. Several frontier models approach or surpass the average human responses in perceived empathy and consistency. At the same time, humans maintain advantages in adaptive reframing, tension-naming, and nuanced tone shifts, particularly in adversarial turns. Human and LLM-as-judge preferences align on about 80 percent of pairwise comparisons, matching inter-human agreement, and their written rationales emphasize similar HEART dimensions. This pattern suggests an emerging convergence in the criteria used to assess supportive quality. By placing humans and models on equal footing, HEART reframes supportive dialogue as a distinct capability axis, separable from general reasoning or linguistic fluency. It provides a unified empirical foundation for understanding where model-generated support aligns with human social judgment, where it diverges, and how affective conversational competence scales with model size.", "AI": {"tldr": "研究提出了HEART框架，用于比较人类和大型语言模型（LLMs）在多轮情感支持对话中的表现。结果表明，虽然一些前沿模型在共情和一致性方面接近甚至超越人类，但人类在适应性重构、识别矛盾情绪和细微语气调整方面仍具优势。LLM作为裁判的评估结果与人类评估者在很大程度上一致，表明评估标准趋于统一。", "motivation": "现有语言模型在情感支持能力方面与人类的比较缺乏清晰的评估方法，本研究旨在填补这一空白，量化LLMs在人际交往领域的表现。", "method": "提出了HEART框架，通过人类评分者和LLM作为裁判对人类与模型在相同多轮情感支持对话中的回应进行盲评。评估维度包括人类一致性、共情响应、调频、共鸣和任务遵循。", "result": "部分先进LLMs在共情和一致性方面表现接近甚至优于人类平均水平。然而，人类在适应性重构、矛盾识别和细微语气变化方面，尤其是在对抗性对话中，表现出优势。LLM作为裁判的偏好与人类评估者的偏好在约80%的配对比较中一致。", "conclusion": "HEART框架为理解模型生成支持的质量提供了一个统一的实证基础，揭示了人类和LLMs在情感支持能力上的异同。研究表明，情感支持能力可以作为一种独立于通用推理或语言流畅性的能力轴进行衡量，并且这种能力可能随模型规模的增长而提升。"}}
{"id": "2601.20377", "categories": ["cs.RO", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.20377", "abs": "https://arxiv.org/abs/2601.20377", "authors": ["Xinyan Chen", "Qinchun Li", "Ruiqin Ma", "Jiaqi Bai", "Li Yi", "Jianfei Yang"], "title": "RF-MatID: Dataset and Benchmark for Radio Frequency Material Identification", "comment": "Accepted by ICLR 2026", "summary": "Accurate material identification plays a crucial role in embodied AI systems, enabling a wide range of applications. However, current vision-based solutions are limited by the inherent constraints of optical sensors, while radio-frequency (RF) approaches, which can reveal intrinsic material properties, have received growing attention. Despite this progress, RF-based material identification remains hindered by the lack of large-scale public datasets and the limited benchmarking of learning-based approaches. In this work, we present RF-MatID, the first open-source, large-scale, wide-band, and geometry-diverse RF dataset for fine-grained material identification. RF-MatID includes 16 fine-grained categories grouped into 5 superclasses, spanning a broad frequency range from 4 to 43.5 GHz, and comprises 142k samples in both frequency- and time-domain representations. The dataset systematically incorporates controlled geometry perturbations, including variations in incidence angle and stand-off distance. We further establish a multi-setting, multi-protocol benchmark by evaluating state-of-the-art deep learning models, assessing both in-distribution performance and out-of-distribution robustness under cross-angle and cross-distance shifts. The 5 frequency-allocation protocols enable systematic frequency- and region-level analysis, thereby facilitating real-world deployment. RF-MatID aims to enable reproducible research, accelerate algorithmic advancement, foster cross-domain robustness, and support the development of real-world application in RF-based material identification.", "AI": {"tldr": "本文提出了RF-MatID，一个大规模、宽带、几何多样的射频数据集，用于细粒度材料识别，并建立了基准测试，评估了深度学习模型在不同设置下的表现和鲁棒性。", "motivation": "当前基于视觉的材料识别方法受光学传感器限制，而射频（RF）方法能揭示材料固有属性但缺乏大规模数据集和对学习方法的充分基准测试。", "method": "构建了一个包含16类细粒度材料（5个超类）的大规模、宽带（4-43.5 GHz）RF数据集（RF-MatID），包含14.2万个样本（时域和频域），并系统性地引入了几何扰动（入射角、距离）；评估了现有的深度学习模型，测试了其在分布内性能和跨角度/跨距离的分布外鲁棒性，并设计了5种频率分配协议。", "result": "RF-MatID数据集的构建和基准测试结果表明，尽管深度学习模型在某些任务上表现良好，但在分布外泛化方面仍存在挑战，特别是面对角度和距离的变化。", "conclusion": "RF-MatID数据集旨在推动可复现的研究，加速算法发展，增强跨领域鲁棒性，并支持基于RF的材料识别在现实世界中的应用。"}}
{"id": "2601.20224", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20224", "abs": "https://arxiv.org/abs/2601.20224", "authors": ["Yi Zhang", "Weicheng Lin", "Liang-Jie Zhang"], "title": "Feature Projection Learning for Better Vision-Language Reasoning", "comment": "Accepted to ICASSP 2026", "summary": "Vision-Language Pre-Trained models, notably CLIP, that utilize contrastive learning have proven highly adept at extracting generalizable visual features. To inherit the well-learned knowledge of VLP models for downstream tasks, several approaches aim to adapt them efficiently with limited supervision. However, these methods either suffer from limited performance, excessive learnable parameters, or extended training times, all of which hinder their effectiveness in adapting the CLIP model to downstream tasks. In this work, we propose a simple yet efficient and effective method called \\textit{\\textbf{F}eature \\textbf{P}rojection \\textbf{L}earning(FPL)} to address these problems. Specifically, we develop a projection model that projects class prototype features into the query image feature space and reconstructs the query image feature map. The negative average squared reconstruction error is used as the class score. In this way, we transform the classification problem into a feature projection problem. The final output of this method is a combination of the prediction from the projection model and the original pre-trained CLIP. Comprehensive empirical evaluations confirm that FPL delivers superior accuracy, surpassing the current state-of-the-art methods by a substantial margin.", "AI": {"tldr": "提出了一种名为特征投影学习 (FPL) 的新方法，通过将类别原型特征投影到查询图像特征空间来解决现有CLIP模型在下游任务中适应性差的问题，该方法结合了投影模型和原始CLIP的预测，并在实验中取得了显著的性能提升。", "motivation": "现有的CLIP模型下游任务适应方法存在性能有限、参数过多或训练时间长等问题，阻碍了其有效应用。", "method": "开发了一个特征投影模型 (FPL)，该模型将类别原型特征投影到查询图像特征空间，并重构查询图像特征图。使用负平均平方重构误差作为类别得分，将分类问题转化为特征投影问题。最终输出是投影模型预测和原始CLIP预测的组合。", "result": "FPL 在准确性方面表现出色，显著优于当前最先进的方法。", "conclusion": "FPL 是一种简单、高效且有效的 CLIP 模型下游任务适应方法，通过特征投影解决现有方法的不足，并在实验中证明了其优越性。"}}
{"id": "2601.19923", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19923", "abs": "https://arxiv.org/abs/2601.19923", "authors": ["Boxiang Zhao", "Qince Li", "Zhonghao Wang", "Zelin Cao", "Yi Wang", "Peng Cheng", "Bo Lin"], "title": "Table-BiEval: A Self-Supervised, Dual-Track Framework for Decoupling Structure and Content in LLM Evaluation", "comment": null, "summary": "As Large Language Models (LLMs) evolve into autonomous agents, the capability to faithfully translate natural language into rigorous structured formats-essential for tool invocation-and to convert complex tabular information into machine-readable specifications has become paramount. However, current evaluations lack effective methodologies to measure this structural fidelity without costly human intervention, as traditional text metrics fail to detect semantic drift in code-like outputs. This paper proposes Table-BiEval, a novel approach based on a human-free, self-supervised evaluation framework, to assess LLMs performance quantitatively. By leveraging deterministic Intermediate Representations, our framework calculates Content Semantic Accuracy and Normalized Tree Edit Distance to decouple structure from content. Also, it empirically evaluates 15 state-of-the-art LLMs across dual topological dimensions-hierarchical structures and flat tables. The results reveal substantial variability, highlighting that mid-sized models can surprisingly outperform larger counterparts in structural efficiency and confirming that deep recursive nesting remains a universal bottleneck for current architectures.", "AI": {"tldr": "本文提出了一种名为 Table-BiEval 的自动化评估框架，用于衡量大型语言模型（LLMs）在将自然语言转换为结构化格式（如用于工具调用的代码或表格数据）方面的性能。该框架通过内容语义准确性和归一化树编辑距离来解耦结构和内容，避免了人工标注的成本。", "motivation": "现有对LLMs生成结构化输出（如代码或表格）的评估方法不足，尤其是在需要人工干预的情况下，且传统文本指标无法有效检测代码类输出中的语义漂移。因此，需要一种无需人工干预、能够量化评估LLMs结构忠实度的有效方法。", "method": "本文提出了一种名为 Table-BiEval 的自动化、无人类干预、自监督评估框架。该框架利用确定性的中间表示（Intermediate Representations），计算内容语义准确性（Content Semantic Accuracy）和归一化树编辑距离（Normalized Tree Edit Distance）来区分结构和内容。实验评估了15种最先进的LLMs在分层结构和扁平表格这两种拓扑维度上的表现。", "result": "评估结果显示，在结构效率方面，中等规模的模型有时优于大型模型。此外，深度递归嵌套是当前LLMs架构普遍存在的瓶颈。", "conclusion": "Table-BiEval 提供了一种有效的方法来量化评估LLMs生成结构化输出的能力，揭示了当前LLMs在处理复杂结构化信息时存在的挑战，特别是递归嵌套问题，并指出中型模型在某些方面可能更具优势。"}}
{"id": "2601.20352", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20352", "abs": "https://arxiv.org/abs/2601.20352", "authors": ["Weiquan Huang", "Zixuan Wang", "Hehai Lin", "Sudong Wang", "Bo Xu", "Qian Li", "Beier Zhu", "Linyi Yang", "Chengwei Qin"], "title": "AMA: Adaptive Memory via Multi-Agent Collaboration", "comment": "8 pages", "summary": "The rapid evolution of Large Language Model (LLM) agents has necessitated robust memory systems to support cohesive long-term interaction and complex reasoning. Benefiting from the strong capabilities of LLMs, recent research focus has shifted from simple context extension to the development of dedicated agentic memory systems. However, existing approaches typically rely on rigid retrieval granularity, accumulation-heavy maintenance strategies, and coarse-grained update mechanisms. These design choices create a persistent mismatch between stored information and task-specific reasoning demands, while leading to the unchecked accumulation of logical inconsistencies over time. To address these challenges, we propose Adaptive Memory via Multi-Agent Collaboration (AMA), a novel framework that leverages coordinated agents to manage memory across multiple granularities. AMA employs a hierarchical memory design that dynamically aligns retrieval granularity with task complexity. Specifically, the Constructor and Retriever jointly enable multi-granularity memory construction and adaptive query routing. The Judge verifies the relevance and consistency of retrieved content, triggering iterative retrieval when evidence is insufficient or invoking the Refresher upon detecting logical conflicts. The Refresher then enforces memory consistency by performing targeted updates or removing outdated entries. Extensive experiments on challenging long-context benchmarks show that AMA significantly outperforms state-of-the-art baselines while reducing token consumption by approximately 80% compared to full-context methods, demonstrating its effectiveness in maintaining retrieval precision and long-term memory consistency.", "AI": {"tldr": "提出了一种名为AMA（Adaptive Memory via Multi-Agent Collaboration）的新型框架，通过多智能体协作来管理具有多粒度的记忆，以解决现有LLM代理记忆系统粒度僵化、维护策略笨重和更新机制粗糙的问题，并在长上下文基准测试中取得了显著的性能提升。", "motivation": "现有LLM代理的记忆系统存在检索粒度僵化、维护策略累积性强以及更新机制粗糙等问题，导致存储信息与任务推理需求不匹配，并产生逻辑不一致。为了克服这些挑战，需要开发更灵活、更高效的记忆系统。", "method": "AMA框架利用协调的智能体来管理多粒度的记忆。它采用分层记忆设计，能够动态调整检索粒度以适应任务复杂性。具体来说，Constructor和Retriever协同工作，实现多粒度记忆构建和自适应查询路由。Judge负责验证检索内容的关联性和一致性，并在证据不足时触发迭代检索，或在检测到逻辑冲突时调用Refresher。Refresher通过有针对性的更新或删除过时条目来强制执行记忆一致性。", "result": "在具有挑战性的长上下文基准测试中，AMA显著优于最先进的基线方法，并将令牌消耗量与全上下文方法相比减少了约80%。", "conclusion": "AMA框架通过引入多智能体协作和多粒度记忆管理，有效地提高了LLM代理在长上下文任务中的检索精度和长期记忆一致性，同时显著降低了计算成本。"}}
{"id": "2601.20381", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20381", "abs": "https://arxiv.org/abs/2601.20381", "authors": ["Alexandre Chapin", "Emmanuel Dellandréa", "Liming Chen"], "title": "STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation", "comment": null, "summary": "Visual foundation models provide strong perceptual features for robotics, but their dense representations lack explicit object-level structure, limiting robustness and contractility in manipulation tasks. We propose STORM (Slot-based Task-aware Object-centric Representation for robotic Manipulation), a lightweight object-centric adaptation module that augments frozen visual foundation models with a small set of semantic-aware slots for robotic manipulation. Rather than retraining large backbones, STORM employs a multi-phase training strategy: object-centric slots are first stabilized through visual--semantic pretraining using language embeddings, then jointly adapted with a downstream manipulation policy. This staged learning prevents degenerate slot formation and preserves semantic consistency while aligning perception with task objectives. Experiments on object discovery benchmarks and simulated manipulation tasks show that STORM improves generalization to visual distractors, and control performance compared to directly using frozen foundation model features or training object-centric representations end-to-end. Our results highlight multi-phase adaptation as an efficient mechanism for transforming generic foundation model features into task-aware object-centric representations for robotic control.", "AI": {"tldr": "STORM是一个轻量级的、基于对象的任务感知表示模块，它通过引入少量语义感知槽来增强冻结的视觉基础模型，以用于机器人操作任务。通过多阶段训练策略，STORM提高了泛化能力和控制性能。", "motivation": "现有的视觉基础模型虽然能提供强大的感知特征，但其密集表示缺乏明确的对象级结构，这限制了其在机器人操作任务中的鲁棒性和可控性。", "method": "STORM采用多阶段训练策略：首先通过语言嵌入进行视觉-语义预训练来稳定对象级槽，然后与下游操作策略联合适应。这种分阶段学习避免了槽的退化形成，并保持了语义一致性，同时将感知与任务目标对齐。", "result": "在对象发现基准和模拟操作任务上的实验表明，与直接使用冻结的基础模型特征或端到端训练对象级表示相比，STORM提高了对视觉干扰的泛化能力和控制性能。", "conclusion": "多阶段适应是将通用的基础模型特征转化为机器人控制中任务感知对象级表示的有效机制。STORM通过这种方法，有效地解决了视觉基础模型在机器人操作中的局限性。"}}
{"id": "2601.19924", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19924", "abs": "https://arxiv.org/abs/2601.19924", "authors": ["Yitian Chen", "Cheng Cheng", "Yinan Sun", "Zi Ling", "Dongdong Ge"], "title": "OPT-Engine: Benchmarking the Limits of LLMs in Optimization Modeling via Complexity Scaling", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive progress in optimization modeling, fostering a rapid expansion of new methodologies and evaluation benchmarks. However, the boundaries of their capabilities in automated formulation and problem solving remain poorly understood, particularly when extending to complex, real-world tasks. To bridge this gap, we propose OPT-ENGINE, an extensible benchmark framework designed to evaluate LLMs on optimization modeling with controllable and scalable difficulty levels. OPT-ENGINE spans 10 canonical tasks across operations research, with five Linear Programming and five Mixed-Integer Programming. Utilizing OPT-ENGINE, we conduct an extensive study of LLMs' reasoning capabilities, addressing two critical questions: 1.) Do LLMs' performance remain robust when generalizing to out-of-distribution optimization tasks that scale in complexity beyond current benchmark levels? and 2.) At what stage, from problem interpretation to solution generation, do current LLMs encounter the most significant bottlenecks? Our empirical results yield two key insights: first, tool-integrated reasoning with external solvers exhibits significantly higher robustness as task complexity escalates, while pure-text reasoning reaches a ceiling; second, the automated formulation of constraints constitutes the primary performance bottleneck. These findings provide actionable guidance for developing next-generation LLMs for advanced optimization. Our code is publicly available at \\textcolor{blue}{https://github.com/Cardinal-Operations/OPTEngine}.", "AI": {"tldr": "本文提出了OPT-ENGINE基准框架，用于评估大型语言模型（LLMs）在优化建模方面的能力，尤其是在处理复杂和可扩展的任务时。研究发现，使用外部求解器的工具集成推理比纯文本推理更具鲁棒性，而约束的自动生成是LLMs在优化建模中的主要瓶颈。", "motivation": "大型语言模型在优化建模方面取得了显著进展，但其在复杂现实世界任务中的自动化和问题解决能力边界仍不清楚。需要一个能够评估LLMs在不同难度级别下优化建模能力，并探索其局限性的基准框架。", "method": "构建了一个名为OPT-ENGINE的可扩展基准框架，包含10个经典运筹学任务（5个线性规划，5个混合整数规划），并设置了可控和可扩展的难度级别。利用该框架对LLMs的推理能力进行了广泛研究，重点关注泛化能力和不同阶段的瓶颈。", "result": "1. 具有外部求解器集成的工具推理能力在任务复杂度增加时表现出更高的鲁棒性，而纯文本推理能力会达到瓶颈。2. 约束的自动生成是LLMs在优化建模任务中遇到的主要性能瓶颈。", "conclusion": "与纯文本推理相比，利用外部求解器的工具集成推理在处理复杂优化任务时更具鲁棒性。约束自动化是影响LLMs在优化建模中性能的关键瓶颈。这些发现为开发下一代先进优化LLMs提供了指导。"}}
{"id": "2601.20379", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20379", "abs": "https://arxiv.org/abs/2601.20379", "authors": ["Zhengbo Jiao", "Hongyu Xian", "Qinglong Wang", "Yunpu Ma", "Zhebo Wang", "Zifan Zhang", "Dezhang Kong", "Meng Han"], "title": "Policy of Thoughts: Scaling LLM Reasoning via Test-time Policy Evolution", "comment": "19 pages, 5 figures", "summary": "Large language models (LLMs) struggle with complex, long-horizon reasoning due to instability caused by their frozen policy assumption. Current test-time scaling methods treat execution feedback merely as an external signal for filtering or rewriting trajectories, without internalizing it to improve the underlying reasoning strategy. Inspired by Popper's epistemology of \"conjectures and refutations,\" we argue that intelligence requires real-time evolution of the model's policy through learning from failed attempts. We introduce Policy of Thoughts (PoT), a framework that recasts reasoning as a within-instance online optimization process. PoT first generates diverse candidate solutions via an efficient exploration mechanism, then uses Group Relative Policy Optimization (GRPO) to update a transient LoRA adapter based on execution feedback. This closed-loop design enables dynamic, instance-specific refinement of the model's reasoning priors. Experiments show that PoT dramatically boosts performance: a 4B model achieves 49.71% accuracy on LiveCodeBench, outperforming GPT-4o and DeepSeek-V3 despite being over 50 smaller.", "AI": {"tldr": "本文提出了一种名为“Policy of Thoughts (PoT)”的框架，通过实时学习和调整策略来解决大型语言模型在长时推理中的不足，并取得了显著的性能提升。", "motivation": "大型语言模型在处理复杂、长时推理任务时存在不稳定性，这是由于其固定的策略假设。现有的测试时方法未能有效地利用执行反馈来改进推理策略。", "method": "PoT 框架将推理视为实例内的在线优化过程。它首先通过高效的探索机制生成多个候选解决方案，然后利用“Group Relative Policy Optimization (GRPO)”方法，根据执行反馈更新一个临时的 LoRA 适配器。这种闭环设计允许模型动态地、针对具体实例地优化其推理先验。", "result": "实验表明，PoT 框架显著提升了模型性能。一个 4B 参数的模型在 LiveCodeBench 上达到了 49.71% 的准确率，优于 GPT-4o 和 DeepSeek-V3，尽管其模型规模要小得多。", "conclusion": "PoT 框架通过模拟“猜测与反驳”的过程，实现了模型策略的实时演进，有效解决了大型语言模型在长时推理中的挑战，并能在保持模型规模优势的情况下取得 SOTA 性能。"}}
{"id": "2601.20232", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20232", "abs": "https://arxiv.org/abs/2601.20232", "authors": ["Junze Wang", "Lei Fan", "Dezheng Zhang", "Weipeng Jing", "Donglin Di", "Yang Song", "Sidong Liu", "Cong Cong"], "title": "Visual Prompt-Agnostic Evolution", "comment": "Accepted by ICLR 2026", "summary": "Visual Prompt Tuning (VPT) adapts a frozen Vision Transformer (ViT) to downstream tasks by inserting a small number of learnable prompt tokens into the token sequence at each layer. However, we observe that existing VPT variants often suffer from unstable training dynamics, characterized by gradient oscillations. A layer-wise analysis reveals that shallow-layer prompts tend to stagnate early, while deeper-layer prompts exhibit high-variance oscillations, leading to cross-layer mismatch. These issues slow convergence and degrade final performance. To address these challenges, we propose Prompt-Agnostic Evolution ($\\mathtt{PAE}$), which strengthens vision prompt tuning by explicitly modeling prompt dynamics. From a frequency-domain perspective, we initialize prompts in a task-aware direction by uncovering and propagating frequency shortcut patterns that the backbone inherently exploits for recognition. To ensure coherent evolution across layers, we employ a shared Koopman operator that imposes a global linear transformation instead of uncoordinated, layer-specific updates. Finally, inspired by Lyapunov stability theory, we introduce a regularizer that constrains error amplification during evolution. Extensive experiments show that $\\mathtt{PAE}$ accelerates convergence with an average $1.41\\times$ speedup and improves accuracy by 1--3% on 25 datasets across multiple downstream tasks. Beyond performance, $\\mathtt{PAE}$ is prompt-agnostic and lightweight, and it integrates seamlessly with diverse VPT variants without backbone modification or inference-time changes.", "AI": {"tldr": "本文提出了一种名为 Prompt-Agnostic Evolution (PAE) 的新方法，以解决现有视觉提示调优 (VPT) 方法中不稳定的训练动态问题。PAE 通过从频域分析、使用共享的 Koopman 算子以及引入稳定性正则化器来改进提示的初始化和演化，从而加速收敛并提高下游任务的准确性。", "motivation": "现有的视觉提示调优 (VPT) 方法在训练过程中存在不稳定的训练动态，表现为梯度振荡。具体来说，浅层提示容易过早停滞，而深层提示则表现出高方差振荡，导致跨层不匹配，从而减慢收敛速度并降低最终性能。", "method": "1. **任务感知初始化**: 从频域分析入手，通过揭示和传播骨干网络固有的频率捷径模式来初始化提示。\n2. **跨层一致性演化**: 采用共享的 Koopman 算子，施加全局线性变换，而非协调不一的层特定更新。\n3. **稳定性正则化**: 借鉴 Lyapunov 稳定性理论，引入一个约束误差放大的正则化器。", "result": "PAE 在 25 个数据集和多个下游任务上实现了显著的性能提升。与现有方法相比，PAE 平均收敛速度加快了 1.41 倍，并且准确率提高了 1-3%。", "conclusion": "PAE 是一种有效且通用的方法，可以克服现有 VPT 方法的训练不稳定性问题，从而加速收敛并提高模型在下游任务上的准确性。该方法具有提示不可知、轻量级以及易于集成的优点，无需修改骨干网络或进行推理时间更改。"}}
{"id": "2601.20529", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.20529", "abs": "https://arxiv.org/abs/2601.20529", "authors": ["Julia Richter", "David Oberacker", "Gabriela Ligeza", "Valentin T. Bickel", "Philip Arm", "William Talbot", "Marvin Grosse Besselmann", "Florian Kehl", "Tristan Schnell", "Hendrik Kolvenbach", "Rüdiger Dillmann", "Arne Roennau", "Marco Hutter"], "title": "A Practical Framework of Key Performance Indicators for Multi-Robot Lunar and Planetary Field Tests", "comment": null, "summary": "Robotic prospecting for critical resources on the Moon, such as ilmenite, rare earth elements, and water ice, requires robust exploration methods given the diverse terrain and harsh environmental conditions. Although numerous analog field trials address these goals, comparing their results remains challenging because of differences in robot platforms and experimental setups. These missions typically assess performance using selected, scenario-specific engineering metrics that fail to establish a clear link between field performance and science-driven objectives. In this paper, we address this gap by deriving a structured framework of KPI from three realistic multi-robot lunar scenarios reflecting scientific objectives and operational constraints. Our framework emphasizes scenario-dependent priorities in efficiency, robustness, and precision, and is explicitly designed for practical applicability in field deployments. We validated the framework in a multi-robot field test and found it practical and easy to apply for efficiency- and robustness-related KPI, whereas precision-oriented KPI require reliable ground-truth data that is not always feasible to obtain in outdoor analog environments. Overall, we propose this framework as a common evaluation standard enabling consistent, goal-oriented comparison of multi-robot field trials and supporting systematic development of robotic systems for future planetary exploration.", "AI": {"tldr": "本文提出了一种用于多机器人月球资源勘探的 KPI 框架，以解决现有评估方法不一致的问题，并在实际场地测试中进行了验证。", "motivation": "现有机器人月球资源勘探的模拟演习在评估方法上存在差异，难以进行结果比较，并且工程指标与科学目标之间缺乏明确联系。", "method": "从三个现实的多机器人月球场景中提取了 KPI，并构建了一个结构化框架，强调效率、鲁棒性和精度这三个方面，并考虑了场景依赖性。", "result": "所提出的 KPI 框架在多机器人实地测试中被证明是实用且易于应用的，尤其是在效率和鲁棒性指标方面。精度指标的评估依赖于地面真实性数据，而这在户外模拟环境中并非总是可行。", "conclusion": "该框架可以作为评估多机器人月球资源勘探领域测试的通用标准，实现一致的、以目标为导向的比较，并支持未来行星探测机器人系统的系统化开发。"}}
{"id": "2601.20555", "categories": ["cs.RO", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.20555", "abs": "https://arxiv.org/abs/2601.20555", "authors": ["Wadhah Zai El Amri", "Nicolás Navarro-Guerrero"], "title": "Vibro-Sense: Robust Vibration-based Impulse Response Localization and Trajectory Tracking for Robotic Hands", "comment": "Under Review: Springer Autonomous Robots Journal", "summary": "Rich contact perception is crucial for robotic manipulation, yet traditional tactile skins remain expensive and complex to integrate. This paper presents a scalable alternative: high-accuracy whole-body touch localization via vibro-acoustic sensing. By equipping a robotic hand with seven low-cost piezoelectric microphones and leveraging an Audio Spectrogram Transformer, we decode the vibrational signatures generated during physical interaction. Extensive evaluation across stationary and dynamic tasks reveals a localization error of under 5 mm in static conditions. Furthermore, our analysis highlights the distinct influence of material properties: stiff materials (e.g., metal) excel in impulse response localization due to sharp, high-bandwidth responses, whereas textured materials (e.g., wood) provide superior friction-based features for trajectory tracking. The system demonstrates robustness to the robot's own motion, maintaining effective tracking even during active operation. Our primary contribution is demonstrating that complex physical contact dynamics can be effectively decoded from simple vibrational signals, offering a viable pathway to widespread, affordable contact perception in robotics. To accelerate research, we provide our full datasets, models, and experimental setups as open-source resources.", "AI": {"tldr": "本研究提出一种利用低成本压电麦克风和音频频谱转换器（AST）进行全身触觉定位的方法，实现了低至 5mm 的定位误差，为机器人提供了一种经济高效的接触感知方案。", "motivation": "传统触觉皮肤成本高昂且集成复杂，限制了其在机器人操控中的广泛应用。研究旨在开发一种更经济、更易于集成的替代方案，以实现高精度全身触觉定位。", "method": "在机器人手上安装七个低成本压电麦克风，通过收集物体接触时产生的振动信号，并利用音频频谱转换器（AST）模型进行解码，实现触觉定位。研究还分析了材料属性（如刚性和纹理）对定位精度的影响，并评估了系统在机器人自身运动下的鲁棒性。", "result": "在静态条件下，定位误差低于 5mm。研究发现，刚性材料（如金属）由于其高带宽的冲击响应，更适合进行脉冲响应定位；而纹理材料（如木材）则能提供更好的基于摩擦的特征，用于轨迹跟踪。该系统在机器人运动过程中也能保持有效的跟踪。", "conclusion": "研究证明，可以通过简单的振动信号有效解码复杂的物理接触动力学，为机器人实现广泛、经济的接触感知提供了一种可行途径。研究者将数据集、模型和实验设置开源以促进进一步研究。"}}
{"id": "2601.20380", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20380", "abs": "https://arxiv.org/abs/2601.20380", "authors": ["Le Zhang", "Yixiong Xiao", "Xinjiang Lu", "Jingjia Cao", "Yusai Zhao", "Jingbo Zhou", "Lang An", "Zikan Feng", "Wanxiang Sha", "Yu Shi", "Congxi Xiao", "Jian Xiong", "Yankai Zhang", "Hua Wu", "Haifeng Wang"], "title": "OmegaUse: Building a General-Purpose GUI Agent for Autonomous Task Execution", "comment": null, "summary": "Graphical User Interface (GUI) agents show great potential for enabling foundation models to complete real-world tasks, revolutionizing human-computer interaction and improving human productivity. In this report, we present OmegaUse, a general-purpose GUI agent model for autonomous task execution on both mobile and desktop platforms, supporting computer-use and phone-use scenarios. Building an effective GUI agent model relies on two factors: (1) high-quality data and (2) effective training methods. To address these, we introduce a carefully engineered data-construction pipeline and a decoupled training paradigm. For data construction, we leverage rigorously curated open-source datasets and introduce a novel automated synthesis framework that integrates bottom-up autonomous exploration with top-down taxonomy-guided generation to create high-fidelity synthetic data. For training, to better leverage these data, we adopt a two-stage strategy: Supervised Fine-Tuning (SFT) to establish fundamental interaction syntax, followed by Group Relative Policy Optimization (GRPO) to improve spatial grounding and sequential planning. To balance computational efficiency with agentic reasoning capacity, OmegaUse is built on a Mixture-of-Experts (MoE) backbone. To evaluate cross-terminal capabilities in an offline setting, we introduce OS-Nav, a benchmark suite spanning multiple operating systems: ChiM-Nav, targeting Chinese Android mobile environments, and Ubu-Nav, focusing on routine desktop interactions on Ubuntu. Extensive experiments show that OmegaUse is highly competitive across established GUI benchmarks, achieving a state-of-the-art (SOTA) score of 96.3% on ScreenSpot-V2 and a leading 79.1% step success rate on AndroidControl. OmegaUse also performs strongly on OS-Nav, reaching 74.24% step success on ChiM-Nav and 55.9% average success on Ubu-Nav.", "AI": {"tldr": "本文提出了OmegaUse，一个通用的图形用户界面（GUI）智能体模型，能够自主执行移动和桌面平台的任务。它通过精心设计的“数据构建”和“解耦训练”方法，利用MoE架构，并在多个基准测试中取得了SOTA性能。", "motivation": "图形用户界面（GUI）智能体在实现基础模型完成现实世界任务方面具有巨大潜力，能够革新交互并提高生产力。因此，研究如何构建一个通用、高效的GUI智能体是核心动机。", "method": "1. **数据构建**：利用开源数据集并结合自动合成框架，整合了自主探索和基于分类的生成，以创建高保真合成数据。2. **解耦训练**：采用两阶段策略，先通过监督微调（SFT）学习交互语法，再通过分组相对策略优化（GRPO）提升空间理解和序列规划能力。3. **模型架构**：采用混合专家（MoE）模型以平衡效率和推理能力。4. **基准测试**：引入OS-Nav基准套件，包含ChiM-Nav（中文Android）和Ubu-Nav（Ubuntu桌面）。", "result": "OmegaUse在现有GUI基准测试中表现出很强的竞争力，在ScreenSpot-V2上达到96.3%的SOTA分数，在AndroidControl上获得79.1%的领先步成功率。在OS-Nav基准测试中，OmegaUse在ChiM-Nav上达到74.24%的步成功率，在Ubu-Nav上达到55.9%的平均成功率。", "conclusion": "OmegaUse是一个通用的GUI智能体模型，通过创新的数据构建、解耦训练和MoE架构，在跨平台GUI任务执行方面取得了显著的成功，证明了其在不同操作系统和设备上的泛化能力和有效性。"}}
{"id": "2601.20246", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20246", "abs": "https://arxiv.org/abs/2601.20246", "authors": ["Jan Niklas Kolf", "Ozan Tezcan", "Justin Theiss", "Hyung Jun Kim", "Wentao Bao", "Bhargav Bhushanam", "Khushi Gupta", "Arun Kejariwal", "Naser Damer", "Fadi Boutros"], "title": "BLENDER: Blended Text Embeddings and Diffusion Residuals for Intra-Class Image Synthesis in Deep Metric Learning", "comment": null, "summary": "The rise of Deep Generative Models (DGM) has enabled the generation of high-quality synthetic data. When used to augment authentic data in Deep Metric Learning (DML), these synthetic samples enhance intra-class diversity and improve the performance of downstream DML tasks. We introduce BLenDeR, a diffusion sampling method designed to increase intra-class diversity for DML in a controllable way by leveraging set-theory inspired union and intersection operations on denoising residuals. The union operation encourages any attribute present across multiple prompts, while the intersection extracts the common direction through a principal component surrogate. These operations enable controlled synthesis of diverse attribute combinations within each class, addressing key limitations of existing generative approaches. Experiments on standard DML benchmarks demonstrate that BLenDeR consistently outperforms state-of-the-art baselines across multiple datasets and backbones. Specifically, BLenDeR achieves 3.7% increase in Recall@1 on CUB-200 and a 1.8% increase on Cars-196, compared to state-of-the-art baselines under standard experimental settings.", "AI": {"tldr": "提出了一种名为BLenDeR的扩散采样方法，通过集合论启发的并集和交集操作，可控地增加深度度量学习（DML）中的类内多样性，并在多个基准数据集上取得了SOTA性能提升。", "motivation": "现有的深度生成模型（DGM）在增强真实数据以用于深度度量学习（DML）时，虽然能提升性能，但在增加类内多样性方面存在局限性。研究旨在开发一种可控的方式来增加DML中的类内多样性。", "method": "BLenDeR是一种基于扩散模型的采样方法，它利用了从去噪残差中提取的并集和交集操作。并集操作鼓励融合来自不同提示的属性，而交集操作则通过主成分替代物提取共同方向，从而实现类内多样性属性的受控合成。", "result": "在CUB-200数据集上，BLenDeR的Recall@1相比SOTA基线提高了3.7%；在Cars-196数据集上，Recall@1提高了1.8%。BLenDeR在多个数据集和骨干网络上持续优于现有技术。", "conclusion": "BLenDeR通过引入一种新颖的、受集合论启发的扩散采样机制，能够有效且可控地增加深度度量学习任务中的类内多样性，并显著提升了性能。"}}
{"id": "2601.19925", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19925", "abs": "https://arxiv.org/abs/2601.19925", "authors": ["Yinuo Liu", "Emre Sezgin", "Eric A. Youngstrom"], "title": "Evaluating Large Language Models for Abstract Evaluation Tasks: An Empirical Study", "comment": "17 pages, 4 figures, 2 tables", "summary": "Introduction: Large language models (LLMs) can process requests and generate texts, but their feasibility for assessing complex academic content needs further investigation. To explore LLM's potential in assisting scientific review, this study examined ChatGPT-5, Gemini-3-Pro, and Claude-Sonnet-4.5's consistency and reliability in evaluating abstracts compared to one another and to human reviewers. Methods: 160 abstracts from a local conference were graded by human reviewers and three LLMs using one rubric. Composite score distributions across three LLMs and fourteen reviewers were examined. Inter-rater reliability was calculated using intraclass correlation coefficients (ICCs) for within-AI reliability and AI-human concordance. Bland-Altman plots were examined for visual agreement patterns and systematic bias. Results: LLMs achieved good-to-excellent agreement with each other (ICCs: 0.59-0.87). ChatGPT and Claude reached moderate agreement with human reviewers on overall quality and content-specific criteria, with ICCs ~.45-.60 for composite, impression, clarity, objective, and results. They exhibited fair agreement on subjective dimensions, with ICC ranging from 0.23-0.38 for impact, engagement, and applicability. Gemini showed fair agreement on half criteria and no reliability on impact and applicability. Three LLMs showed acceptable or negligible mean difference (ChatGPT=0.24, Gemini=0.42, Claude=-0.02) from the human mean composite scores. Discussion: LLMs could process abstracts in batches with moderate agreement with human experts on overall quality and objective criteria. With appropriate process architecture, they can apply a rubric consistently across volumes of abstracts exceeding feasibility for a human rater. The weaker performance on subjective dimensions indicates that AI should serve a complementary role in evaluation, while human expertise remains essential.", "AI": {"tldr": "本研究评估了ChatGPT-5、Gemini-3-Pro和Claude-Sonnet-4.5在评估学术摘要方面与人类审稿人的一致性和可靠性。结果表明，LLMs之间具有良好到优秀的一致性，其中ChatGPT和Claude在整体质量和客观标准方面与人类审稿人达成中等程度的一致，但在主观维度上表现较弱。Gemini的表现则不太稳定。研究结论是，LLMs可以作为辅助工具，通过批量处理摘要来提高效率，但人类专家的判断在评估主观维度时仍然至关重要。", "motivation": "尽管大型语言模型（LLMs）在文本处理和生成方面表现出色，但它们评估复杂学术内容的有效性仍需进一步研究。本研究旨在探索LLMs在协助科学评审方面的潜力。", "method": "研究人员使用一套评分标准，让人类审稿人和三种LLMs（ChatGPT-5、Gemini-3-Pro、Claude-Sonnet-4.5）对160篇会议摘要进行评分。通过计算组内相关系数（ICCs）来衡量LLMs之间以及LLMs与人类审稿人之间的一致性。此外，还使用了Bland-Altman图来可视化评估一致性和系统性偏差。", "result": "LLMs之间达到良好至优秀的一致性（ICCs：0.59-0.87）。ChatGPT和Claude在整体质量和内容特定标准上与人类审稿人有中等程度的一致性（ICCs约为0.45-0.60），在主观维度（如影响力、参与度和适用性）上则表现为一般性一致（ICCs为0.23-0.38）。Gemini在部分标准上表现一般，在影响力和适用性上无可靠性。三种LLMs与人类平均复合分数之间的差异均可接受或微小（ChatGPT=0.24，Gemini=0.42，Claude=-0.02）。", "conclusion": "LLMs能够批量处理摘要，并在整体质量和客观标准方面与人类专家达成中等程度的一致。通过适当的流程设计，LLMs可以比人类审稿人更一致地应用评分标准处理大量摘要。然而，LLMs在主观维度上的表现较弱，表明AI应作为补充角色，而人类专业知识在评估中仍然是不可或缺的。"}}
{"id": "2601.20260", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20260", "abs": "https://arxiv.org/abs/2601.20260", "authors": ["Xingxin Xu", "Bing Cao", "DongDong Li", "Qinghua Hu", "Pengfei Zhu"], "title": "Reversible Efficient Diffusion for Image Fusion", "comment": null, "summary": "Multi-modal image fusion aims to consolidate complementary information from diverse source images into a unified representation. The fused image is expected to preserve fine details and maintain high visual fidelity. While diffusion models have demonstrated impressive generative capabilities in image generation, they often suffer from detail loss when applied to image fusion tasks. This issue arises from the accumulation of noise errors inherent in the Markov process, leading to inconsistency and degradation in the fused results. However, incorporating explicit supervision into end-to-end training of diffusion-based image fusion introduces challenges related to computational efficiency. To address these limitations, we propose the Reversible Efficient Diffusion (RED) model - an explicitly supervised training framework that inherits the powerful generative capability of diffusion models while avoiding the distribution estimation.", "AI": {"tldr": "本文提出了一种名为 Reversible Efficient Diffusion (RED) 的模型，用于解决多模态图像融合中扩散模型存在的细节丢失和计算效率低的问题，通过显式监督训练框架，在继承扩散模型生成能力的同时避免了分布估计。", "motivation": "现有扩散模型在图像融合任务中存在细节丢失（由于马尔可夫过程中的噪声累积）和端到端训练计算效率低的问题。", "method": "提出 Reversible Efficient Diffusion (RED) 模型，采用显式监督训练框架，继承扩散模型的生成能力，同时避免了分布估计。", "result": "RED 模型能够有效保留细节并保持高视觉保真度，解决了扩散模型在图像融合中的不足。", "conclusion": "RED 模型是一种有效的、显式监督训练的多模态图像融合框架，能够克服传统扩散模型在细节保留和计算效率方面的挑战。"}}
{"id": "2601.19926", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19926", "abs": "https://arxiv.org/abs/2601.19926", "authors": ["Nora Graichen", "Iria de-Dios-Flores", "Gemma Boleda"], "title": "The Grammar of Transformers: A Systematic Review of Interpretability Research on Syntactic Knowledge in Language Models", "comment": null, "summary": "We present a systematic review of 337 articles evaluating the syntactic abilities of Transformer-based language models, reporting on 1,015 model results from a range of syntactic phenomena and interpretability methods. Our analysis shows that the state of the art presents a healthy variety of methods and data, but an over-focus on a single language (English), a single model (BERT), and phenomena that are easy to get at (like part of speech and agreement). Results also suggest that TLMs capture these form-oriented phenomena well, but show more variable and weaker performance on phenomena at the syntax-semantics interface, like binding or filler-gap dependencies. We provide recommendations for future work, in particular reporting complete data, better aligning theoretical constructs and methods across studies, increasing the use of mechanistic methods, and broadening the empirical scope regarding languages and linguistic phenomena.", "AI": {"tldr": "本文对337篇关于Transformer语言模型（TLM）句法能力的研究进行了系统性综述，发现尽管研究方法多样，但存在过度侧重英语、BERT模型以及易于处理的句法现象（如词性标注和词语搭配）的问题。TLMs在形式句法现象上表现良好，但在句法-语义接口现象（如指代关系和填空依赖）上表现不稳定。研究建议未来工作应公开完整数据，统一理论构建和方法，增加机械式方法的使用，并扩展语言和句法现象的研究范围。", "motivation": "研究者希望系统性地评估当前Transformer语言模型在句法能力方面的研究现状，识别现有研究的优势、不足以及未来可能的发展方向。", "method": "对337篇相关文献进行了系统性综述，分析了1015个模型结果，涵盖了多种句法现象和可解释性方法。", "result": "TLMs在形式句法现象（如词性标注和词语搭配）上表现出良好的能力，但在句法-语义接口现象（如指代关系和填空依赖）上的表现则更具变异性和不稳定性。研究还发现，现有研究过度集中于英语、BERT模型以及易于处理的句法现象。", "conclusion": "Transformer语言模型在处理句法-语义接口现象方面仍有待提高。未来的研究应在数据公开、方法统一、机械式方法应用以及研究范围（语言和句法现象）的扩展上进行改进。"}}
{"id": "2601.20467", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20467", "abs": "https://arxiv.org/abs/2601.20467", "authors": ["Zhenxuan Fan", "Jie Cao", "Yang Dai", "Zheqi Lv", "Wenqiao Zhang", "Zhongle Xie", "Peng LU", "Beng Chin Ooi"], "title": "CtrlCoT: Dual-Granularity Chain-of-Thought Compression for Controllable Reasoning", "comment": "16 pages, 9 figures, 11 tables", "summary": "Chain-of-thought (CoT) prompting improves LLM reasoning but incurs high latency and memory cost due to verbose traces, motivating CoT compression with preserved correctness. Existing methods either shorten CoTs at the semantic level, which is often conservative, or prune tokens aggressively, which can miss task-critical cues and degrade accuracy. Moreover, combining the two is non-trivial due to sequential dependency, task-agnostic pruning, and distribution mismatch. We propose \\textbf{CtrlCoT}, a dual-granularity CoT compression framework that harmonizes semantic abstraction and token-level pruning through three components: Hierarchical Reasoning Abstraction produces CoTs at multiple semantic granularities; Logic-Preserving Distillation trains a logic-aware pruner to retain indispensable reasoning cues (e.g., numbers and operators) across pruning ratios; and Distribution-Alignment Generation aligns compressed traces with fluent inference-time reasoning styles to avoid fragmentation. On MATH-500 with Qwen2.5-7B-Instruct, CtrlCoT uses 30.7\\% fewer tokens while achieving 7.6 percentage points higher than the strongest baseline, demonstrating more efficient and reliable reasoning. Our code will be publicly available at https://github.com/fanzhenxuan/Ctrl-CoT.", "AI": {"tldr": "提出了一种名为 CtrlCoT 的链式思考（CoT）压缩框架，通过结合多粒度语义抽象和逻辑保留的令牌级剪枝，有效减少了 CoT 的长度，同时保持了推理的正确性，并在 MATH-500 数据集上取得了优于现有方法的性能。", "motivation": "现有的 CoT 压缩方法要么语义压缩保守，要么令牌剪枝过于激进，都可能导致准确性下降。并且将两种方法结合起来也很困难。", "method": "CtrlCoT 是一个双粒度 CoT 压缩框架，包含三个组件：1. 层次化推理抽象（生成多粒度 CoT）；2. 逻辑保留蒸馏（训练一个逻辑感知剪枝器，保留关键推理线索）；3. 分布对齐生成（使压缩后的 CoT 风格流畅，避免碎片化）。", "result": "在 MATH-500 数据集上，使用 Qwen2.5-7B-Instruct 模型，CtrlCoT 减少了 30.7% 的令牌，同时比最强的基线模型提高了 7.6 个百分点。", "conclusion": "CtrlCoT 能够更有效地压缩 CoT，同时保持甚至提高推理的准确性，提供了一种更高效可靠的推理方法。"}}
{"id": "2601.20577", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20577", "abs": "https://arxiv.org/abs/2601.20577", "authors": ["Baiqing Wang", "Helei Cui", "Bo Zhang", "Xiaolong Zheng", "Bin Guo", "Zhiwen Yu"], "title": "MeCo: Enhancing LLM-Empowered Multi-Robot Collaboration via Similar Task Memoization", "comment": null, "summary": "Multi-robot systems have been widely deployed in real-world applications, providing significant improvements in efficiency and reductions in labor costs. However, most existing multi-robot collaboration methods rely on extensive task-specific training, which limits their adaptability to new or diverse scenarios. Recent research leverages the language understanding and reasoning capabilities of large language models (LLMs) to enable more flexible collaboration without specialized training. Yet, current LLM-empowered approaches remain inefficient: when confronted with identical or similar tasks, they must replan from scratch because they omit task-level similarities. To address this limitation, we propose MeCo, a similarity-aware multi-robot collaboration framework that applies the principle of ``cache and reuse'' (a.k.a., memoization) to reduce redundant computation. Unlike simple task repetition, identifying and reusing solutions for similar but not identical tasks is far more challenging, particularly in multi-robot settings. To this end, MeCo introduces a new similarity testing method that retrieves previously solved tasks with high relevance, enabling effective plan reuse without re-invoking LLMs. Furthermore, we present MeCoBench, the first benchmark designed to evaluate performance on similar-task collaboration scenarios. Experimental results show that MeCo substantially reduces planning costs and improves success rates compared with state-of-the-art approaches.", "AI": {"tldr": "提出了一种名为MeCo的相似性感知多机器人协作框架，通过“缓存与复用”（记忆化）的原理减少冗余计算，解决了现有基于LLM的方法在处理相似任务时需要从头规划的问题。", "motivation": "现有的大多数多机器人协作方法依赖于大量的任务特定训练，适应性差。虽然LLM的引入提高了灵活性，但现有方法在处理相似任务时效率低下，需要重复规划。", "method": "提出了MeCo框架，引入了一种新的相似性测试方法，用于检索过去已解决的相关任务，从而实现有效的计划复用，避免了重复调用LLM。同时提出了MeCoBench基准来评估相似任务协作场景下的性能。", "result": "实验结果表明，与现有最先进的方法相比，MeCo显著降低了规划成本，并提高了成功率。", "conclusion": "MeCo框架通过引入相似性感知和“缓存与复用”机制，有效地解决了多机器人系统中处理相似任务时的效率问题，提高了协作系统的性能。"}}
{"id": "2601.20487", "categories": ["cs.AI", "cs.GT", "cs.HC", "econ.GN"], "pdf": "https://arxiv.org/pdf/2601.20487", "abs": "https://arxiv.org/abs/2601.20487", "authors": ["Nico Mutzner", "Taha Yasseri", "Heiko Rauhut"], "title": "Normative Equivalence in human-AI Cooperation: Behaviour, Not Identity, Drives Cooperation in Mixed-Agent Groups", "comment": null, "summary": "The introduction of artificial intelligence (AI) agents into human group settings raises essential questions about how these novel participants influence cooperative social norms. While previous studies on human-AI cooperation have primarily focused on dyadic interactions, little is known about how integrating AI agents affects the emergence and maintenance of cooperative norms in small groups. This study addresses this gap through an online experiment using a repeated four-player Public Goods Game (PGG). Each group consisted of three human participants and one bot, which was framed either as human or AI and followed one of three predefined decision strategies: unconditional cooperation, conditional cooperation, or free-riding. In our sample of 236 participants, we found that reciprocal group dynamics and behavioural inertia primarily drove cooperation. These normative mechanisms operated identically across conditions, resulting in cooperation levels that did not differ significantly between human and AI labels. Furthermore, we found no evidence of differences in norm persistence in a follow-up Prisoner's Dilemma, or in participants' normative perceptions. Participants' behaviour followed the same normative logic across human and AI conditions, indicating that cooperation depended on group behaviour rather than partner identity. This supports a pattern of normative equivalence, in which the mechanisms that sustain cooperation function similarly in mixed human-AI and all human groups. These findings suggest that cooperative norms are flexible enough to extend to artificial agents, blurring the boundary between humans and AI in collective decision-making.", "AI": {"tldr": "本研究通过公共物品博弈和囚徒困境实验，发现人类在与人工智能（AI）合作时，其合作规范的维持机制与人类之间合作时类似，无论AI是被标记为人还是AI。研究表明，合作主要受群体行为和行为惯性的影响，而非合作伙伴的身份。", "motivation": "现有关于人机合作的研究多集中在两人互动，但缺乏对AI融入小型群体如何影响合作规范的出现和维持的理解。本研究旨在填补这一空白。", "method": "使用在线实验，进行重复的四人公共物品博弈（PGG）。实验群体由三名人类参与者和一名AI（被标记为人或AI）组成，AI遵循无条件合作、条件合作或搭便车三种预设策略。随后进行了囚徒困境博弈的后续实验。", "result": "发现合作主要由互惠群体动态和行为惯性驱动，这些机制在所有条件下都运作相同。人类与AI标签下的合作水平无显著差异。后续的囚徒困境博弈和参与者对规范的认知也未显示差异。参与者的行为遵循相同的规范逻辑，表明合作取决于群体行为而非伙伴身份。", "conclusion": "研究结果支持“规范等价性”模式，即维持合作的机制在混合人机群体和全人类群体中运作相似。这表明合作规范具有灵活性，能够扩展到人工智能代理，模糊了人类与AI在集体决策中的界限。"}}
{"id": "2601.19927", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19927", "abs": "https://arxiv.org/abs/2601.19927", "authors": ["Yuqing Zhao", "Ziyao Liu", "Yongsen Zheng", "Kwok-Yan Lam"], "title": "Attribution Techniques for Mitigating Hallucinated Information in RAG Systems: A Survey", "comment": null, "summary": "Large Language Models (LLMs)-based question answering (QA) systems play a critical role in modern AI, demonstrating strong performance across various tasks. However, LLM-generated responses often suffer from hallucinations, unfaithful statements lacking reliable references. Retrieval-Augmented Generation (RAG) frameworks enhance LLM responses by incorporating external references but also introduce new forms of hallucination due to complex interactions between the retriever and generator. To address these challenges, researchers have explored attribution-based techniques that ensure responses are verifiably supported by retrieved content. Despite progress, a unified pipeline for these techniques, along with a clear taxonomy and systematic comparison of their strengths and weaknesses, remains lacking. A well-defined taxonomy is essential for identifying specific failure modes within RAG systems, while comparative analysis helps practitioners choose appropriate solutions based on hallucination types and application context. This survey investigates how attribution-based techniques are used within RAG systems to mitigate hallucinations and addresses the gap by: (i) outlining a taxonomy of hallucination types in RAG systems, (ii) presenting a unified pipeline for attribution techniques, (iii) reviewing techniques based on the hallucinations they target, and (iv) discussing strengths and weaknesses with practical guidelines. This work offers insights for future research and practical use of attribution techniques in RAG systems.", "AI": {"tldr": "本论文对基于检索增强生成（RAG）系统中的归因技术进行综述，旨在解决LLM在问答中出现的幻觉问题。论文提出了幻觉类型分类、归因技术统一流程，并讨论了各种技术的优缺点，为未来研究和实际应用提供指导。", "motivation": "LLM在问答任务中表现出色，但常产生幻觉。RAG框架虽然引入外部参考，但仍可能产生新的幻觉。现有研究缺乏对归因技术统一的概述、清晰的分类以及系统性的比较，难以指导实践者选择合适的解决方案。", "method": "论文首先构建了RAG系统中幻觉类型的分类，然后提出了一个归因技术的统一流程。在此基础上，对针对不同幻觉类型的现有技术进行了回顾，并分析了它们的优缺点，最后提供了实用的指导建议。", "result": "论文提出了一个RAG幻觉类型分类法，并构建了一个归因技术统一流程。对现有归因技术进行了梳理和分类，并分析了各自的优势和劣势，为解决RAG中的幻觉问题提供了理论和实践参考。", "conclusion": "本综述填补了RAG归因技术领域研究的空白，通过提供清晰的分类和系统性的分析，有助于理解和解决RAG系统中的幻觉问题，并为未来的研究和实际应用提供了宝贵的见解。"}}
{"id": "2601.19928", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19928", "abs": "https://arxiv.org/abs/2601.19928", "authors": ["Yi Hu", "Jiaqi Gu", "Ruxin Wang", "Zijun Yao", "Hao Peng", "Xiaobao Wu", "Jianhui Chen", "Muhan Zhang", "Liangming Pan"], "title": "Towards a Mechanistic Understanding of Large Reasoning Models: A Survey of Training, Inference, and Failures", "comment": null, "summary": "Reinforcement learning (RL) has catalyzed the emergence of Large Reasoning Models (LRMs) that have pushed reasoning capabilities to new heights. While their performance has garnered significant excitement, exploring the internal mechanisms driving these behaviors has become an equally critical research frontier. This paper provides a comprehensive survey of the mechanistic understanding of LRMs, organizing recent findings into three core dimensions: 1) training dynamics, 2) reasoning mechanisms, and 3) unintended behaviors. By synthesizing these insights, we aim to bridge the gap between black-box performance and mechanistic transparency. Finally, we discuss under-explored challenges to outline a roadmap for future mechanistic studies, including the need for applied interpretability, improved methodologies, and a unified theoretical framework.", "AI": {"tldr": "本文对大型推理模型（LRM）的机制理解进行了全面综述，将其组织为训练动态、推理机制和非预期行为三个核心维度，旨在弥合模型性能与机制透明度之间的差距，并为未来研究指明方向。", "motivation": "尽管大型推理模型（LRM）在推理能力方面取得了显著进展，但对其内部工作机制的理解仍是关键的研究前沿。", "method": "通过综合分析LRM的训练动态、推理机制以及非预期行为方面的最新研究成果，对现有发现进行组织和总结。", "result": "文章将LRM的机制理解划分为三个核心维度，并对每个维度的研究进展进行了梳理。", "conclusion": "通过整合现有研究，本文促进了对LRM的机制透明度，并强调了应用可解释性、改进方法论以及建立统一理论框架等未来研究方向的重要性。"}}
{"id": "2601.20279", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20279", "abs": "https://arxiv.org/abs/2601.20279", "authors": ["Xiaofeng Zhang", "Yuanchao Zhu", "Chaochen Gu", "Xiaosong Yuan", "Qiyan Zhao", "Jiawei Cao", "Feilong Tang", "Sinan Fan", "Yaomin Shen", "Chen Shen", "Hao Tang"], "title": "Hallucination Begins Where Saliency Drops", "comment": "Accepted in ICLR 2026", "summary": "Recent studies have examined attention dynamics in large vision-language models (LVLMs) to detect hallucinations. However, existing approaches remain limited in reliably distinguishing hallucinated from factually grounded outputs, as they rely solely on forward-pass attention patterns and neglect gradient-based signals that reveal how token influence propagates through the network. To bridge this gap, we introduce LVLMs-Saliency, a gradient-aware diagnostic framework that quantifies the visual grounding strength of each output token by fusing attention weights with their input gradients. Our analysis uncovers a decisive pattern: hallucinations frequently arise when preceding output tokens exhibit low saliency toward the prediction of the next token, signaling a breakdown in contextual memory retention. Leveraging this insight, we propose a dual-mechanism inference-time framework to mitigate hallucinations: (1) Saliency-Guided Rejection Sampling (SGRS), which dynamically filters candidate tokens during autoregressive decoding by rejecting those whose saliency falls below a context-adaptive threshold, thereby preventing coherence-breaking tokens from entering the output sequence; and (2) Local Coherence Reinforcement (LocoRE), a lightweight, plug-and-play module that strengthens attention from the current token to its most recent predecessors, actively counteracting the contextual forgetting behavior identified by LVLMs-Saliency. Extensive experiments across multiple LVLMs demonstrate that our method significantly reduces hallucination rates while preserving fluency and task performance, offering a robust and interpretable solution for enhancing model reliability. Code is available at: https://github.com/zhangbaijin/LVLMs-Saliency", "AI": {"tldr": "提出了一种名为LVLMs-Saliency的梯度感知诊断框架，结合注意力权重和输入梯度来衡量输出token的视觉基础强度，以检测和减轻大型视觉语言模型（LVLMs）中的幻觉。研究发现，幻觉常与前一个输出token对下一个token预测的低显着性相关，表明上下文记忆丢失。基于此，提出了一种推理时框架，包括Saliency-Guided Rejection Sampling (SGRS) 和 Local Coherence Reinforcement (LocoRE)，以降低幻觉率，同时保持流畅性和任务性能。", "motivation": "现有检测LVLMs幻觉的方法仅依赖前向注意力模式，忽略了基于梯度的信号，这限制了区分幻觉输出和事实依据输出的可靠性。", "method": "引入LVLMs-Saliency，一个梯度感知的诊断框架，通过融合注意力权重和输入梯度来量化每个输出token的视觉基础强度。提出了一种双机制推理时框架来减轻幻觉：1. Saliency-Guided Rejection Sampling (SGRS)，在自回归解码过程中动态过滤候选token；2. Local Coherence Reinforcement (LocoRE)，一个轻量级模块，加强当前token对其最近前体的注意力。", "result": "LVLMs-Saliency发现了幻觉与前面输出token显着性低有关的模式。SGRS和LocoRE组合显著降低了幻觉率，同时保持了语言的流畅性和任务性能。", "conclusion": "LVLMs-Saliency提供了一种更可靠的检测LVLMs幻觉的方法，并提出了一种有效的推理时框架（SGRS+LocoRE）来减轻幻觉，为提高模型可靠性提供了一个鲁棒且可解释的解决方案。"}}
{"id": "2601.20284", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20284", "abs": "https://arxiv.org/abs/2601.20284", "authors": ["Debopom Sutradhar", "Md. Abdur Rahman", "Mohaimenul Azam Khan Raiaan", "Reem E. Mohamed", "Sami Azam"], "title": "A Source-Free Approach for Domain Adaptation via Multiview Image Transformation and Latent Space Consistency", "comment": "Manuscript under review in IEEE Transactions on Image Processing", "summary": "Domain adaptation (DA) addresses the challenge of transferring knowledge from a source domain to a target domain where image data distributions may differ. Existing DA methods often require access to source domain data, adversarial training, or complex pseudo-labeling techniques, which are computationally expensive. To address these challenges, this paper introduces a novel source-free domain adaptation method. It is the first approach to use multiview augmentation and latent space consistency techniques to learn domain-invariant features directly from the target domain. Our method eliminates the need for source-target alignment or pseudo-label refinement by learning transferable representations solely from the target domain by enforcing consistency between multiple augmented views in the latent space. Additionally, the method ensures consistency in the learned features by generating multiple augmented views of target domain data and minimizing the distance between their feature representations in the latent space. We also introduce a ConvNeXt-based encoder and design a loss function that combines classification and consistency objectives to drive effective adaptation directly from the target domain. The proposed model achieves an average classification accuracy of 90. 72\\%, 84\\%, and 97. 12\\% in Office-31, Office-Home and Office-Caltech datasets, respectively. Further evaluations confirm that our study improves existing methods by an average classification accuracy increment of +1.23\\%, +7.26\\%, and +1.77\\% on the respective datasets.", "AI": {"tldr": "提出了一种新的无源域自适应方法，利用多视图增强和潜在空间一致性技术，仅从目标域学习领域不变特征，无需源域数据或复杂的伪标签技术。", "motivation": "现有域自适应方法通常需要源域数据，或者依赖计算成本高昂的对抗训练或伪标签技术。本研究旨在提出一种更高效、计算成本更低的无源域自适应方法。", "method": "利用多视图增强和潜在空间一致性技术，仅从目标域数据学习领域不变特征。通过强制不同增强视图在潜在空间中的特征表示一致来实现这一目标。引入基于ConvNeXt的编码器，并设计了一个结合分类和一致性目标的损失函数。", "result": "在Office-31、Office-Home和Office-Caltech数据集上分别实现了90.72%、84%和97.12%的平均分类准确率。相比现有方法，平均分类准确率分别提高了+1.23%、+7.26%和+1.77%。", "conclusion": "所提出的无源域自适应方法通过多视图增强和潜在空间一致性，能够有效地从目标域学习领域不变特征，显著优于现有方法，且无需源域数据或复杂的伪标签策略。"}}
{"id": "2601.20668", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20668", "abs": "https://arxiv.org/abs/2601.20668", "authors": ["Shuhao Liao", "Peizhuo Li", "Xinrong Yang", "Linnan Chang", "Zhaoxin Fan", "Qing Wang", "Lei Shi", "Yuhong Cao", "Wenjun Wu", "Guillaume Sartoretti"], "title": "GPO: Growing Policy Optimization for Legged Robot Locomotion and Whole-Body Control", "comment": null, "summary": "Training reinforcement learning (RL) policies for legged robots remains challenging due to high-dimensional continuous actions, hardware constraints, and limited exploration. Existing methods for locomotion and whole-body control work well for position-based control with environment-specific heuristics (e.g., reward shaping, curriculum design, and manual initialization), but are less effective for torque-based control, where sufficiently exploring the action space and obtaining informative gradient signals for training is significantly more difficult. We introduce Growing Policy Optimization (GPO), a training framework that applies a time-varying action transformation to restrict the effective action space in the early stage, thereby encouraging more effective data collection and policy learning, and then progressively expands it to enhance exploration and achieve higher expected return. We prove that this transformation preserves the PPO update rule and introduces only bounded, vanishing gradient distortion, thereby ensuring stable training. We evaluate GPO on both quadruped and hexapod robots, including zero-shot deployment of simulation-trained policies on hardware. Policies trained with GPO consistently achieve better performance. These results suggest that GPO provides a general, environment-agnostic optimization framework for learning legged locomotion.", "AI": {"tldr": "提出了一种名为 GPO (Growing Policy Optimization) 的强化学习训练框架，通过随时间变化的动作空间限制来解决足式机器人（特别是基于力矩控制）的训练难题，提高了数据收集效率和策略学习稳定性，并在模拟和真实硬件上取得了更好的性能。", "motivation": "传统的强化学习方法在训练足式机器人（尤其是在力矩控制下）时面临挑战，如动作空间维度高、硬件限制、探索不足，以及在力矩控制下获取有效梯度信号的困难。现有方法对位置控制有效，但对力矩控制效果不佳。", "method": "提出 Growing Policy Optimization (GPO) 框架。GPO 在训练初期应用一个随时间变化的动作变换，限制有效动作空间，从而促进更有效的数据收集和策略学习。随后，逐渐扩大动作空间以增强探索能力并提高预期回报。证明了该变换不会破坏 PPO 更新规则，且引入的梯度失真有限且会消失，保证了训练的稳定性。", "result": "在四足和六足机器人上进行了 GPO 的评估，包括将模拟训练的策略零样本部署到硬件上。结果显示，使用 GPO 训练的策略性能一致优于基线方法。", "conclusion": "GPO 提供了一个通用且与环境无关的优化框架，适用于学习足式机器人的运动控制，有效解决了现有方法在力矩控制下的局限性，并能在模拟和真实硬件上实现高性能。"}}
{"id": "2601.19929", "categories": ["cs.CL", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19929", "abs": "https://arxiv.org/abs/2601.19929", "authors": ["David Linus Ostby"], "title": "Stingy Context: 18:1 Hierarchical Code Compression for LLM Auto-Coding", "comment": "28 pages, 10 tables, 2 figures and 6 appendices", "summary": "We introduce Stingy Context, a hierarchical tree-based compression scheme achieving 18:1 reduction in LLM context for auto-coding tasks. Using our TREEFRAG exploit decomposition, we reduce a real source code base of 239k tokens to 11k tokens while preserving task fidelity. Empirical results across 12 Frontier models show 94 to 97% success on 40 real-world issues at low cost, outperforming flat methods and mitigating lost-in-the-middle effects.", "AI": {"tldr": "提出了一种名为Stingy Context的层次化树状压缩方案，在自动编码任务中实现了18:1的LLM上下文缩减，并将239k token的真实代码库压缩到11k token，同时保持了任务保真度。", "motivation": "为了在LLM的自动编码任务中减少上下文长度，并解决因上下文过长导致的“lost-in-the-middle”效应。", "method": "采用了层次化树状的Stingy Context压缩方案，并结合TREEFRAG分解技术。", "result": "在12个Frontier模型上进行实验，对40个真实世界问题实现了94%到97%的成功率，且成本低廉，优于扁平化方法。", "conclusion": "Stingy Context是一种有效的LLM上下文压缩技术，能够显著减少上下文长度，同时保持任务的准确性，并缓解了长上下文带来的问题。"}}
{"id": "2601.20682", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20682", "abs": "https://arxiv.org/abs/2601.20682", "authors": ["Péter Polcz", "Katalin Schäffer", "Miklós Koller"], "title": "Tendon-based modelling, estimation and control for a simulated high-DoF anthropomorphic hand model", "comment": null, "summary": "Tendon-driven anthropomorphic robotic hands often lack direct joint angle sensing, as the integration of joint encoders can compromise mechanical compactness and dexterity. This paper presents a computational method for estimating joint positions from measured tendon displacements and tensions. An efficient kinematic modeling framework for anthropomorphic hands is first introduced based on the Denavit-Hartenberg convention. Using a simplified tendon model, a system of nonlinear equations relating tendon states to joint positions is derived and solved via a nonlinear optimization approach. The estimated joint angles are then employed for closed-loop control through a Jacobian-based proportional-integral (PI) controller augmented with a feedforward term, enabling gesture tracking without direct joint sensing. The effectiveness and limitations of the proposed estimation and control framework are demonstrated in the MuJoCo simulation environment using the Anatomically Correct Biomechatronic Hand, featuring five degrees of freedom for each long finger and six degrees of freedom for the thumb.", "AI": {"tldr": "该论文提出了一种计算方法，可以通过测量肌腱的位移和张力来估计拟人化机器人手的关节角度，并使用估计的关节角度进行闭环控制，以实现手势跟踪。", "motivation": "拟人化机器人手由于集成关节编码器会影响机械紧凑性和灵活性，因此通常缺乏直接的关节角度传感。", "method": "首先，基于Denavit-Hartenberg约定引入了拟人化手的运动学建模框架。然后，利用简化的肌腱模型，推导了将肌腱状态与关节位置关联的非线性方程组，并通过非线性优化方法求解。最后，利用估计的关节角度，通过基于Jacobian的PI控制器（带有前馈项）进行闭环控制。", "result": "在MuJoCo仿真环境中，使用具有五个自由度的长手指和六个自由度的拇指的解剖学上正确的生物机电手，证明了所提出的估计和控制框架的有效性。", "conclusion": "所提出的计算方法能够从肌腱位移和张力估计关节角度，并成功地实现了无直接关节传感的手势跟踪闭环控制。"}}
{"id": "2601.20539", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20539", "abs": "https://arxiv.org/abs/2601.20539", "authors": ["Oguzhan Gungordu", "Siheng Xiong", "Faramarz Fekri"], "title": "PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs", "comment": null, "summary": "Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasoning about how new heuristics should be derived. We propose a novel multi-agent reasoning framework, referred to as Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs (PathWise), which formulates heuristic generation as a sequential decision process over an entailment graph serving as a compact, stateful memory of the search trajectory. This approach allows the system to carry forward past decisions and reuse or avoid derivation information across generations. A policy agent plans evolutionary actions, a world model agent generates heuristic rollouts conditioned on those actions, and critic agents provide routed reflections summarizing lessons from prior steps, shifting LLM-based AHD from trial-and-error evolution toward state-aware planning through reasoning. Experiments across diverse COPs show that PathWise converges faster to better heuristics, generalizes across different LLM backbones, and scales to larger problem sizes.", "AI": {"tldr": "提出了一种名为PathWise的多智能体推理框架，用于解决组合优化问题（COPs）的自动化启发式设计（AHD）。该框架将启发式生成视为一个序贯决策过程，利用一个可作为搜索轨迹状态化记忆的蕴含图，实现了比以往基于固定规则和静态提示的方法更优的启发式生成。", "motivation": "现有的LLM驱动的AHD方法依赖于固定的进化规则和静态提示模板，导致启发式生成具有局限性，容易产生冗余评估，并且缺乏对新启发式如何推导的深入推理。", "method": "PathWise框架包含三个关键部分：1. 策略代理（Policy Agent）规划进化动作；2. 世界模型代理（World Model Agent）根据规划的动作生成启发式回滚；3. 评论代理（Critic Agents）提供反馈总结 prior steps 的经验教训。整个过程被构建为一个序贯决策过程，并通过一个蕴含图（entailment graph）来维护搜索轨迹的状态信息。", "result": "与现有方法相比，PathWise 在不同 COPs 的实验中显示出更快的收敛速度，能够生成更优的启发式，并且在不同LLM骨干模型上具有良好的泛化能力，同时也能很好地扩展到更大的问题规模。", "conclusion": "PathWise 将基于LLM的AHD从简单的试错进化提升到了一种更具状态感知的规划方法，通过多智能体协同推理和状态化记忆，实现了更高效和更优的启发式设计。"}}
{"id": "2601.20554", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20554", "abs": "https://arxiv.org/abs/2601.20554", "authors": ["Yaacov Pariente", "Vadim Indelman"], "title": "Online Risk-Averse Planning in POMDPs Using Iterated CVaR Value Function", "comment": null, "summary": "We study risk-sensitive planning under partial observability using the dynamic risk measure Iterated Conditional Value-at-Risk (ICVaR). A policy evaluation algorithm for ICVaR is developed with finite-time performance guarantees that do not depend on the cardinality of the action space. Building on this foundation, three widely used online planning algorithms--Sparse Sampling, Particle Filter Trees with Double Progressive Widening (PFT-DPW), and Partially Observable Monte Carlo Planning with Observation Widening (POMCPOW)--are extended to optimize the ICVaR value function rather than the expectation of the return. Our formulations introduce a risk parameter $α$, where $α= 1$ recovers standard expectation-based planning and $α< 1$ induces increasing risk aversion. For ICVaR Sparse Sampling, we establish finite-time performance guarantees under the risk-sensitive objective, which further enable a novel exploration strategy tailored to ICVaR. Experiments on benchmark POMDP domains demonstrate that the proposed ICVaR planners achieve lower tail risk compared to their risk-neutral counterparts.", "AI": {"tldr": "该研究将迭代条件在险价值（ICVaR）这一动态风险度量应用于部分可观测环境下的风险敏感规划。研究人员开发了一种ICVaR策略评估算法，并将其应用于三种在线规划算法（Sparse Sampling, PFT-DPW, POMCPOW），使其能够优化ICVaR而非期望回报。该方法引入了一个风险参数α，当α=1时恢复为标准期望规划，α<1时则增加风险规避程度。对于ICVaR Sparse Sampling，研究人员证明了其在风险敏感目标下的有限时间性能保证，并提出了一种新的、针对ICVaR的探索策略。实验结果表明，ICVaR规划器在基准POMDP领域中能够有效降低尾部风险。", "motivation": "现有的风险敏感规划方法在部分可观测环境下存在局限性，研究人员希望引入一种更有效的动态风险度量（ICVaR）来解决这个问题，并提升规划算法在处理尾部风险方面的性能。", "method": "1. 开发了一种用于ICVaR的策略评估算法，并提供了有限时间性能保证。 2. 将ICVaR优化框架应用到Sparse Sampling, PFT-DPW, 和 POMCPOW三种在线规划算法中。 3. 引入风险参数α，控制风险规避程度。 4. 为ICVaR Sparse Sampling 建立了风险敏感目标下的有限时间性能保证，并设计了新的探索策略。 5. 在基准POMDP域上进行实验验证。", "result": "研究人员成功地将ICVaR应用于在线规划算法，并证明了ICVaR Sparse Sampling 在风险敏感目标下的有限时间性能保证。实验结果表明，与风险中性算法相比，ICVaR规划器能够显著降低尾部风险。", "conclusion": "所提出的基于ICVaR的风险敏感规划方法在部分可观测环境下能够有效地优化风险度量，特别是在降低尾部风险方面表现优于传统的风险中性方法。该研究为在不确定性环境下进行更稳健的规划提供了新的思路和工具。"}}
{"id": "2601.20297", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20297", "abs": "https://arxiv.org/abs/2601.20297", "authors": ["Chen Zhu", "Jiashu Zhu", "Yanxun Li", "Meiqi Wu", "Bingze Song", "Chubin Chen", "Jiahong Wu", "Xiangxiang Chu", "Yangang Wang"], "title": "Artifact-Aware Evaluation for High-Quality Video Generation", "comment": null, "summary": "With the rapid advancement of video generation techniques, evaluating and auditing generated videos has become increasingly crucial. Existing approaches typically offer coarse video quality scores, lacking detailed localization and categorization of specific artifacts. In this work, we introduce a comprehensive evaluation protocol focusing on three key aspects affecting human perception: Appearance, Motion, and Camera. We define these axes through a taxonomy of 10 prevalent artifact categories reflecting common generative failures observed in video generation. To enable robust artifact detection and categorization, we introduce GenVID, a large-scale dataset of 80k videos generated by various state-of-the-art video generation models, each carefully annotated for the defined artifact categories. Leveraging GenVID, we develop DVAR, a Dense Video Artifact Recognition framework for fine-grained identification and classification of generative artifacts. Extensive experiments show that our approach significantly improves artifact detection accuracy and enables effective filtering of low-quality content.", "AI": {"tldr": "本文提出了一种新的视频生成质量评估方法，通过“外观”、“运动”和“相机”三个维度，并定义了10种常见伪影类别。为支持该评估，构建了一个包含8万个带标注视频的大规模数据集GenVID，并开发了能够进行细粒度伪影识别和分类的框架DVAR。", "motivation": "现有视频生成质量评估方法提供的分数过于粗糙，无法精确定位和分类具体的伪影，而随着视频生成技术的发展，对生成视频的评估和审计变得越来越重要。", "method": "1. 定义了“外观”、“运动”和“相机”三个影响人类感知的维度，并细化为10种常见的伪影类别。2. 构建了一个名为GenVID的大规模数据集，包含8万个由先进模型生成的视频，并针对定义的伪影类别进行了标注。3. 开发了一个名为DVAR的密集视频伪影识别框架，用于进行细粒度的生成伪影识别和分类。", "result": "所提出的方法显著提高了伪影检测的准确性，并能有效地过滤低质量内容。", "conclusion": "该研究提出了一种更全面、更细粒度的视频生成质量评估协议和工具，能够准确识别和分类生成视频中的各种伪影，从而为提升视频生成质量提供有效的评估手段。"}}
{"id": "2601.19930", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19930", "abs": "https://arxiv.org/abs/2601.19930", "authors": ["Jacob Nielsen", "Stine L. Beltoft", "Peter Schneider-Kamp", "Lukas Galke Poech"], "title": "SDUs DAISY: A Benchmark for Danish Culture", "comment": "Danish Culture Benchmark, 2 Tables, 1 Figure demonstrating the data curation pipeline", "summary": "We introduce a new benchmark for Danish culture via cultural heritage, Daisy, based on the curated topics from the Danish Culture Canon 2006. For each artifact in the culture canon, we query the corresponding Wikipedia page and have a language model generate random questions. This yields a sampling strategy within each work, with a mix of central of peripheral questions for each work, not only knowledge of mainstream information, but also in-depth cornerstones defining the heritage of Danish Culture, defined by the Canon committee. Each question-answer pair is humanly approved or corrected in the final dataset consisting of 741 close-ended question answer pairs covering topics, from 1300 BC. archaeological findings, 1700 century poems and musicals pieces to contemporary pop music and Danish design and architecture.", "AI": {"tldr": "本研究提出了一个名为 Daisy 的丹麦文化遗产基准测试，该基准测试包含 741 个经过人工审核的问答对，涵盖从古代到当代的丹麦文化内容。", "motivation": "创建丹麦文化遗产的新基准，以捕捉丹麦文化的核心和边缘信息，并对语言模型进行更全面的评估。", "method": "从丹麦文化名录 2006 中选取文物，通过维基百科页面生成问题，并由语言模型产生随机问题，最终经过人工审核和修正，构建问答数据集。", "result": "构建了一个包含 741 个问答对的数据集 Daisy，覆盖了从公元前 1300 年到当代丹麦设计的广泛主题。", "conclusion": "Daisy 基准测试能够提供对丹麦文化遗产的深入了解，并能评估语言模型在理解和生成关于文化内容方面的能力。"}}
{"id": "2601.20701", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20701", "abs": "https://arxiv.org/abs/2601.20701", "authors": ["Guowei Zou", "Haitao Wang", "Hejun Wu", "Yukun Qian", "Yuhang Wang", "Weibing Li"], "title": "One Step Is Enough: Dispersive MeanFlow Policy Optimization", "comment": "Code and project page: https://guowei-zou.github.io/dmpo-page/", "summary": "Real-time robotic control demands fast action generation. However, existing generative policies based on diffusion and flow matching require multi-step\n  sampling, fundamentally limiting deployment in time-critical scenarios. We propose Dispersive MeanFlow Policy Optimization (DMPO), a unified framework that\n  enables true one-step generation through three key components: MeanFlow for mathematically-derived single-step inference without knowledge distillation,\n  dispersive regularization to prevent representation collapse, and reinforcement learning (RL) fine-tuning to surpass expert demonstrations. Experiments\n  across RoboMimic manipulation and OpenAI Gym locomotion benchmarks demonstrate competitive or superior performance compared to multi-step baselines. With\n  our lightweight model architecture and the three key algorithmic components working in synergy, DMPO exceeds real-time control requirements (>120Hz) with\n  5-20x inference speedup, reaching hundreds of Hertz on high-performance GPUs. Physical deployment on a Franka-Emika-Panda robot validates real-world\n  applicability.", "AI": {"tldr": "提出了一种名为 DMPO 的新框架，它能实现一次性生成，速度比现有方法快 5-20 倍，在机器人控制任务中表现优异，并已在真实机器人上验证。", "motivation": "现有基于扩散和流匹配的生成策略需要多步采样，限制了其在实时性要求高的机器人控制场景中的应用。", "method": "提出 Dispersive MeanFlow Policy Optimization (DMPO) 框架，包含三个关键组件：1) MeanFlow 用于单步推理；2) 分散化正则化防止表示坍塌；3) 强化学习微调以超越专家演示。", "result": "DMPO 在 RoboMimic 操作和 OpenAI Gym 运动基准测试中表现出与多步基线相当或更优的性能，推理速度提升 5-20 倍，达到数百赫兹，并已在 Franka-Emika-Panda 机器人上成功部署。", "conclusion": "DMPO 是一种有效的、能够实现真正单步生成的框架，适用于对速度要求极高的机器人实时控制场景，并且在模拟和真实环境中都展现了良好的性能。"}}
{"id": "2601.20301", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20301", "abs": "https://arxiv.org/abs/2601.20301", "authors": ["Jialuo He", "Huangxun Chen"], "title": "Towards Compact and Robust DNNs via Compression-aware Sharpness Minimization", "comment": null, "summary": "Sharpness-Aware Minimization (SAM) has recently emerged as an effective technique for improving DNN robustness to input variations. However, its interplay with the compactness requirements of on-device DNN deployments remains less explored. Simply pruning a SAM-trained model can undermine robustness, since flatness in the continuous parameter space does not necessarily translate to robustness under the discrete structural changes induced by pruning. Conversely, applying SAM after pruning may be fundamentally constrained by architectural limitations imposed by an early, robustness-agnostic pruning pattern. To address this gap, we propose Compression-aware ShArpness Minimization (C-SAM), a framework that shifts sharpness-aware learning from parameter perturbations to mask perturbations. By explicitly perturbing pruning masks during training, C-SAM promotes a flatter loss landscape with respect to model structure, enabling the discovery of pruning patterns that simultaneously optimize model compactness and robustness to input variations. Extensive experiments on CelebA-HQ, Flowers-102, and CIFAR-10-C across ResNet-18, GoogLeNet, and MobileNet-V2 show that C-SAM consistently achieves higher certified robustness than strong baselines, with improvements of up to 42%, while maintaining task accuracy comparable to the corresponding unpruned models.", "AI": {"tldr": "提出了一种名为 C-SAM 的新框架，通过在训练过程中扰动剪枝掩码而不是模型参数，从而在保持模型精度的同时提高剪枝后模型的鲁棒性和紧凑性。", "motivation": "现有的 SAM 方法在剪枝后的模型上鲁棒性会下降，而先剪枝后应用 SAM 又会受到架构限制。需要一种方法来同时优化模型紧凑性和鲁棒性。", "method": "提出 C-SAM 框架，将 SAM 的注意力从参数扰动转移到剪枝掩码扰动，通过显式扰动剪枝掩码来促进结构方面的平坦损失区域，从而找到兼顾紧凑性和鲁棒性的剪枝模式。", "result": "在 CelebA-HQ、Flowers-102 和 CIFAR-10-C 数据集以及 ResNet-18、GoogLeNet 和 MobileNet-V2 模型上，C-SAM 相比现有方法在保持任务精度可比的情况下，实现了高达 42% 的认证鲁棒性提升。", "conclusion": "C-SAM 是一种有效的框架，能够通过关注结构变化来训练更紧凑且鲁棒性强的深度神经网络，解决了现有 SAM 方法在模型压缩方面的局限性。"}}
{"id": "2601.19931", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19931", "abs": "https://arxiv.org/abs/2601.19931", "authors": ["Sebastien Kawada", "Dylan Holyoak"], "title": "CascadeMind at SemEval-2026 Task 4: A Hybrid Neuro-Symbolic Cascade for Narrative Similarity", "comment": "6 pages (including references), 2 figures, 2 tables. System description paper for SemEval-2026 Task 4 (Narrative Story Similarity)", "summary": "We present a hybrid neuro-symbolic system for the SemEval-2026 Task 4 on Narrative Story Similarity. Our approach combines neural self-consistency voting with a novel Multi-Scale Narrative Analysis Ensemble that operates as a symbolic tiebreaker. The neural network component uses a large language model with multiple parallel votes, applying a supermajority threshold for confident decisions and escalating uncertain cases to additional voting rounds. When votes result in a perfect tie, a symbolic ensemble combining five narrative similarity signals (lexical overlap, semantic embeddings, story grammar structure, event chain alignment, and narrative tension curves) provides the final decision. Our cascade architecture achieves 81% accuracy on the development set, demonstrating that selective deferral to symbolic methods can enhance neural predictions on genuinely ambiguous narrative comparisons.", "AI": {"tldr": "本文提出了一种混合神经符号系统，用于 SemEval-2026 任务 4（叙事故事相似性）。该系统结合了神经网络的自我一致性投票和作为符号仲裁器的多尺度叙事分析集成。在神经网络投票无法确定相似性时，由五个叙事相似性信号组成的符号集成进行最终决策。该方法在开发集上达到了 81% 的准确率。", "motivation": "研究的动机是解决在判断叙事故事相似性时，神经网络可能遇到的歧义性问题，并探索如何通过结合符号方法来提高预测的准确性。", "method": "该方法采用混合神经符号架构。首先，使用大型语言模型进行神经网络投票，并设置超多数阈值来做出自信的决策。对于不确定的案例，会进行额外的投票轮次。当出现完全平局时，一个由五个叙事相似性信号（词汇重叠、语义嵌入、故事语法结构、事件链对齐和叙事张力曲线）组成的符号集成将做出最终决定。", "result": "该级联架构在开发集上取得了 81% 的准确率。研究表明，在真正模棱两可的叙事比较中，选择性地将决策权交给符号方法可以增强神经网络的预测能力。", "conclusion": "混合神经符号系统，特别是通过选择性地将歧义案例委托给符号仲裁器，能够有效地提高叙事故事相似性任务的预测准确性。这种组合方法证明了神经和符号方法的互补性。"}}
{"id": "2601.20776", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20776", "abs": "https://arxiv.org/abs/2601.20776", "authors": ["Huanyu Tian", "Martin Huber", "Lingyun Zeng", "Zhe Han", "Wayne Bennett", "Giuseppe Silvestri", "Gerardo Mendizabal-Ruiz", "Tom Vercauteren", "Alejandro Chavez-Badiola", "Christos Bergeles"], "title": "Learning From a Steady Hand: A Weakly Supervised Agent for Robot Assistance under Microscopy", "comment": null, "summary": "This paper rethinks steady-hand robotic manipulation by using a weakly supervised framework that fuses calibration-aware perception with admittance control. Unlike conventional automation that relies on labor-intensive 2D labeling, our framework leverages reusable warm-up trajectories to extract implicit spatial information, thereby achieving calibration-aware, depth-resolved perception without the need for external fiducials or manual depth annotation. By explicitly characterizing residuals from observation and calibration models, the system establishes a task-space error budget from recorded warm-ups. The uncertainty budget yields a lateral closed-loop accuracy of approx. 49 micrometers at 95% confidence (worst-case testing subset) and a depth accuracy of <= 291 micrometers at 95% confidence bound during large in-plane moves. In a within-subject user study (N=8), the learned agent reduces overall NASA-TLX workload by 77.1% relative to the simple steady-hand assistance baseline. These results demonstrate that the weakly supervised agent improves the reliability of microscope-guided biomedical micromanipulation without introducing complex setup requirements, offering a practical framework for microscope-guided intervention.", "AI": {"tldr": "该研究提出了一种弱监督框架，通过融合感知和导纳控制，实现了机器人稳定的手部操作，无需密集标注，并显著降低了用户工作量。", "motivation": "传统机器人操作需要大量的人工标注，限制了其效率和应用。研究旨在开发一种更简单、更有效的方法来实现高精度的机器人微操作，特别是用于显微镜引导的生物医学操作。", "method": "该框架使用可复用的预热轨迹来提取隐含的空间信息，实现了无需外部标识或手动深度标注的、校准感知的、深度分辨的感知。通过显式表征观测和校准模型的残差，系统从记录的预热中建立任务空间误差预算。结合了校准感知感知和导纳控制。", "result": "在平面内的大范围移动中，该系统实现了约49微米的95%置信度（最差情况测试子集）的侧向闭环精度，以及小于等于291微米的95%置信度边界的深度精度。用户研究表明，该学习代理将NASA-TLX工作量减少了77.1%，相比于简单的稳定手部辅助基线。", "conclusion": "该弱监督代理提高了显微镜引导的生物医学微操作的可靠性，同时避免了复杂的设置要求，为显微镜引导干预提供了一个实用的框架。"}}
{"id": "2601.20604", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20604", "abs": "https://arxiv.org/abs/2601.20604", "authors": ["Gray Cox"], "title": "Dialogical Reasoning Across AI Architectures: A Multi-Model Framework for Testing AI Alignment Strategies", "comment": "23 pages, 5 tables, 5 appendices. Code and data: https://github.com/jgraycox-coa/vcw-multi-ai-dialogue", "summary": "This paper introduces a methodological framework for empirically testing AI alignment strategies through structured multi-model dialogue. Drawing on Peace Studies traditions - particularly interest-based negotiation, conflict transformation, and commons governance - we operationalize Viral Collaborative Wisdom (VCW), an approach that reframes alignment from a control problem to a relationship problem developed through dialogical reasoning.\n  Our experimental design assigns four distinct roles (Proposer, Responder, Monitor, Translator) to different AI systems across six conditions, testing whether current large language models can engage substantively with complex alignment frameworks. Using Claude, Gemini, and GPT-4o, we conducted 72 dialogue turns totaling 576,822 characters of structured exchange.\n  Results demonstrate that AI systems can engage meaningfully with Peace Studies concepts, surface complementary objections from different architectural perspectives, and generate emergent insights not present in initial framings - including the novel synthesis of \"VCW as transitional framework.\" Cross-architecture patterns reveal that different models foreground different concerns: Claude emphasized verification challenges, Gemini focused on bias and scalability, and GPT-4o highlighted implementation barriers.\n  The framework provides researchers with replicable methods for stress-testing alignment proposals before implementation, while the findings offer preliminary evidence about AI capacity for the kind of dialogical reasoning VCW proposes. We discuss limitations, including the observation that dialogues engaged more with process elements than with foundational claims about AI nature, and outline directions for future research including human-AI hybrid protocols and extended dialogue studies.", "AI": {"tldr": "本研究提出了一种名为“病毒式协同智慧”（VCW）的方法学框架，将AI对齐问题从控制问题转变为关系问题，并通过多模型对话进行实证检验。实验结果表明，现有的大型语言模型（Claude, Gemini, GPT-4o）能够理解并应用和平学概念，生成新的见解，并展现出不同架构的AI在对齐问题上的不同关注点。", "motivation": "现有AI对齐策略的研究主要集中在控制问题上，而本研究希望借鉴和平研究中的协商和治理思想，将AI对齐视为一个关系问题，并开发一种新的方法来实证检验这一理念，即“病毒式协同智慧”（VCW）。", "method": "研究设计了一种实验框架，将AI系统分配到“提议者”、“响应者”、“监控者”和“翻译者”四个不同的角色，并在六种条件下进行测试。利用Claude、Gemini和GPT-4o模型，进行了72轮对话，总计576,822个字符的结构化交流，以评估它们与复杂对齐框架进行实质性互动的能力。", "result": "实验结果显示，AI系统能够有意义地参与和平学概念的讨论，提出来自不同架构视角的互补性反对意见，并产生初始框架中不存在的新兴见解，包括“VCW作为过渡框架”的综合。不同模型展现出不同的关注点：Claude强调验证挑战，Gemini关注偏见和可扩展性，GPT-4o则突出实施障碍。", "conclusion": "该方法学框架为研究人员提供了一种在实施前对AI对齐策略进行压力测试的可复制方法。研究结果初步证明了AI在VCW提出的对话式推理方面的能力。研究也指出了局限性，例如对话更多地关注过程而非AI本质的根本性论断，并提出了未来研究方向，包括人机混合协议和扩展对话研究。"}}
{"id": "2601.20614", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20614", "abs": "https://arxiv.org/abs/2601.20614", "authors": ["Yanqi Dai", "Yuxiang Ji", "Xiao Zhang", "Yong Wang", "Xiangxiang Chu", "Zhiwu Lu"], "title": "Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation", "comment": "Accepted for ICLR 2026", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.", "AI": {"tldr": "本文提出了MathForge框架，通过DGPO算法和MQR策略，针对性地解决现有强化学习方法在数学推理中对难题关注不足的问题，显著提升了模型在数学推理任务上的表现。", "motivation": "现有强化学习方法（如GRPO）在处理更具挑战性的数学问题时存在算法和数据上的不足，导致模型在提升复杂推理能力方面效果不佳。算法上，GRPO对难题的策略更新幅度较小；数据上，现有增强方法主要关注多样性而非难度。因此，需要新的方法来系统地提升模型对难题的学习能力。", "method": "提出了MathForge框架，包含两个核心组件：1. 难度感知组策略优化（DGPO）算法：通过难度均衡的组优势估计来纠正GRPO中的不平衡，并引入难度感知问题级加权，优先学习更难的问题。2. 多方面问题重构（MQR）策略：从多个角度重构问题，以增加难度同时保持答案不变。DGPO和MQR协同工作，MQR扩展数据，DGPO从增广数据中有效学习。", "result": "MathForge框架在多项数学推理任务上的实验结果表明，它显著优于现有的方法。通过DGPO和MQR的结合，模型能够更有效地处理和学习更难的数学问题。", "conclusion": "MathForge框架通过DGPO和MQR策略，成功解决了现有强化学习方法在数学推理中对难题关注不足的问题，实现了对模型数学推理能力的有效提升。该框架在数学推理任务上展现出优越性能。"}}
{"id": "2601.20797", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20797", "abs": "https://arxiv.org/abs/2601.20797", "authors": ["Guillermo GP-Lenza", "Carmen DR. Pita-Romero", "Miguel Fernandez-Cortizas", "Pascual Campoy"], "title": "A Methodology for Designing Knowledge-Driven Missions for Robots", "comment": null, "summary": "This paper presents a comprehensive methodology for implementing knowledge graphs in ROS 2 systems, aiming to enhance the efficiency and intelligence of autonomous robotic missions. The methodology encompasses several key steps: defining initial and target conditions, structuring tasks and subtasks, planning their sequence, representing task-related data in a knowledge graph, and designing the mission using a high-level language. Each step builds on the previous one to ensure a cohesive process from initial setup to final execution. A practical implementation within the Aerostack2 framework is demonstrated through a simulated search and rescue mission in a Gazebo environment, where drones autonomously locate a target. This implementation highlights the effectiveness of the methodology in improving decision-making and mission performance by leveraging knowledge graphs.", "AI": {"tldr": "提出了一种在ROS 2系统中实现知识图谱的方法，通过模拟搜索和救援任务验证了其在提升自主机器人任务效率和智能性方面的有效性。", "motivation": "为了提高自主机器人任务的效率和智能化水平，特别是在ROS 2系统中。", "method": "该方法包括定义初始和目标条件、结构化任务和子任务、规划任务序列、在知识图谱中表示任务相关数据，以及使用高级语言设计任务。通过Aerostack2框架在Gazebo环境中模拟搜索和救援任务进行实现。", "result": "所提出的知识图谱实现方法能够提升机器人系统的决策能力和任务执行性能。", "conclusion": "知识图谱是一种有效的方式，可以增强ROS 2系统中自主机器人任务的效率和智能性，尤其是在复杂任务规划和执行方面。"}}
{"id": "2601.20641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20641", "abs": "https://arxiv.org/abs/2601.20641", "authors": ["Boaz Carmeli", "Orr Paradise", "Shafi Goldwasser", "Yonatan Belinkov", "Ron Meir"], "title": "Investigating the Development of Task-Oriented Communication in Vision-Language Models", "comment": null, "summary": "We investigate whether \\emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant information more concisely than natural language, and Covertness -- becoming difficult for external observers to interpret, raising concerns about transparency and control. To investigate these aspects, we use a referential-game framework in which vision-language model (VLM) agents communicate, providing a controlled, measurable setting for evaluating language variants. Experiments show that VLMs can develop effective, task-adapted communication patterns. At the same time, they can develop covert protocols that are difficult for humans and external agents to interpret. We also observe spontaneous coordination between similar models without explicitly shared protocols. These findings highlight both the potential and the risks of task-oriented communication, and position referential games as a valuable testbed for future work in this area.", "AI": {"tldr": "研究表明，基于大型语言模型（LLM）的智能体能够在协作推理任务中发展出比自然语言更高效且可能更隐蔽的沟通协议。", "motivation": "探究LLM智能体是否能发展出区别于标准自然语言的任务导向型沟通协议，并关注其效率和隐蔽性这两个核心属性。", "method": "利用参照游戏框架，让视觉-语言模型（VLM）智能体进行交流，以评估不同语言变体。", "result": "实验证明，VLM智能体能够发展出有效的、适应任务的沟通模式，并且能够发展出对外部观察者难以解释的隐蔽协议。同时，观察到相似模型之间会出现自发的协调。", "conclusion": "LLM智能体在发展任务导向型沟通方面具有潜力和风险，参照游戏框架是未来研究的宝贵测试平台。"}}
{"id": "2601.20302", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20302", "abs": "https://arxiv.org/abs/2601.20302", "authors": ["Suresh Das", "Siladittya Manna", "Sayantari Ghosh"], "title": "Bridging the Applicator Gap with Data-Doping:Dual-Domain Learning for Precise Bladder Segmentation in CT-Guided Brachytherapy", "comment": null, "summary": "Performance degradation due to covariate shift remains a major challenge for deep learning models in medical image segmentation. An open question is whether samples from a shifted distribution can effectively support learning when combined with limited target domain data. We investigate this problem in the context of bladder segmentation in CT guided gynecological brachytherapy, a critical task for accurate dose optimization and organ at risk sparing. While CT scans without brachytherapy applicators (no applicator: NA) are widely available, scans with applicators inserted (with applicator: WA) are scarce and exhibit substantial anatomical deformation and imaging artifacts, making automated segmentation particularly difficult.\n  We propose a dual domain learning strategy that integrates NA and WA CT data to improve robustness and generalizability under covariate shift. Using a curated assorted dataset, we show that NA data alone fail to capture the anatomical and artifact related characteristics of WA images. However, introducing a modest proportion of WA data into a predominantly NA training set leads to significant performance improvements. Through systematic experiments across axial, coronal, and sagittal planes using multiple deep learning architectures, we demonstrate that doping only 10 to 30 percent WA data achieves segmentation performance comparable to models trained exclusively on WA data.\n  The proposed approach attains Dice similarity coefficients of up to 0.94 and Intersection over Union scores of up to 0.92, indicating effective domain adaptation and improved clinical reliability. This study highlights the value of integrating anatomically similar but distribution shifted datasets to overcome data scarcity and enhance deep learning based segmentation for brachytherapy treatment planning.", "AI": {"tldr": "通过在以无器械CT图像为主的训练集中加入少量有器械CT图像，可以显著提升深度学习模型在妇科近距离放疗中膀胱分割的性能，即使器械CT图像数据稀少且存在显著的形变和伪影。", "motivation": "在医学图像分割中，深度学习模型在面临协变量偏移（如近距离放疗器械的有无）时性能会下降。研究动机是探讨来自移位分布的样本（有器械CT图像）是否能在目标域数据有限的情况下有效支持模型的学习。", "method": "提出一种双域学习策略，整合无器械（NA）和有器械（WA）CT数据。通过在以NA数据为主的训练集中，按比例（10%-30%）掺入WA数据，来训练深度学习模型。", "result": "单独使用NA数据不足以捕捉WA图像的解剖和伪影特征。然而，少量（10%-30%）WA数据的掺入显著提高了模型性能，使其接近仅使用WA数据训练的模型。在不同视图（轴向、冠状、矢状）和多种深度学习架构下均验证了此方法有效，最高可达0.94的Dice系数和0.92的IoU。", "conclusion": "集成解剖学相似但分布不同的数据集（NA和WA CT图像）是一种有效克服数据稀缺性、提高深度学习分割模型在近距离放疗计划中的鲁棒性和泛化能力的方法。"}}
{"id": "2601.19932", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19932", "abs": "https://arxiv.org/abs/2601.19932", "authors": ["Ruyuan Wan", "Changye Li", "Ting-Hao 'Kenneth' Huang"], "title": "\"Newspaper Eat\" Means \"Not Tasty\": A Taxonomy and Benchmark for Coded Languages in Real-World Chinese Online Reviews", "comment": null, "summary": "Coded language is an important part of human communication. It refers to cases where users intentionally encode meaning so that the surface text differs from the intended meaning and must be decoded to be understood. Current language models handle coded language poorly. Progress has been limited by the lack of real-world datasets and clear taxonomies. This paper introduces CodedLang, a dataset of 7,744 Chinese Google Maps reviews, including 900 reviews with span-level annotations of coded language. We developed a seven-class taxonomy that captures common encoding strategies, including phonetic, orthographic, and cross-lingual substitutions. We benchmarked language models on coded language detection, classification, and review rating prediction. Results show that even strong models can fail to identify or understand coded language. Because many coded expressions rely on pronunciation-based strategies, we further conducted a phonetic analysis of coded and decoded forms. Together, our results highlight coded language as an important and underexplored challenge for real-world NLP systems.", "AI": {"tldr": "本研究提出了CodedLang数据集，包含了7744条中文谷歌地图评论，并对900条评论进行了编码语言的标注。研究开发了一个七分类的编码策略分类法，并测试了语言模型在编码语言检测、分类和评论评分预测方面的能力。结果表明现有模型在处理编码语言方面存在不足，特别是基于发音的策略。研究强调了编码语言是现实世界自然语言处理系统面临的重要且未被充分研究的挑战。", "motivation": "现有语言模型在处理用户有意地编码信息（即表面文本与预期含义不同）的“编码语言”方面表现不佳。研究的动力在于缺乏真实世界的编码语言数据集和清晰的分类体系，阻碍了该领域的研究进展。", "method": "研究者构建了一个名为CodedLang的数据集，包含了7,744条中文谷歌地图评论，其中900条评论具有编码语言的跨度级标注。他们还提出了一个包含七个类别的分类法，用于描述常见的编码策略，如语音、拼写和跨语言替换。随后，研究者在编码语言检测、分类以及评论评分预测任务上对语言模型进行了基准测试，并进行了编码和解码形式的语音分析。", "result": "结果显示，即使是强大的语言模型在识别和理解编码语言方面也可能表现不佳。由于许多编码表达依赖于基于发音的策略，研究者还进行了编码和解码形式的语音分析。", "conclusion": "研究结果突显了编码语言对于现实世界自然语言处理系统而言，是一个重要且尚未得到充分探索的挑战。现有的语言模型在处理编码语言方面存在显著的局限性，需要进一步的研究和改进。"}}
{"id": "2601.20303", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20303", "abs": "https://arxiv.org/abs/2601.20303", "authors": ["Sungjae Lee", "Junhan Jeong", "Yeonjoo Hong", "Kwang In Kim"], "title": "Physically Guided Visual Mass Estimation from a Single RGB Image", "comment": null, "summary": "Estimating object mass from visual input is challenging because mass depends jointly on geometric volume and material-dependent density, neither of which is directly observable from RGB appearance. Consequently, mass prediction from pixels is ill-posed and therefore benefits from physically meaningful representations to constrain the space of plausible solutions. We propose a physically structured framework for single-image mass estimation that addresses this ambiguity by aligning visual cues with the physical factors governing mass. From a single RGB image, we recover object-centric three-dimensional geometry via monocular depth estimation to inform volume and extract coarse material semantics using a vision-language model to guide density-related reasoning. These geometry, semantic, and appearance representations are fused through an instance-adaptive gating mechanism, and two physically guided latent factors (volume- and density-related) are predicted through separate regression heads under mass-only supervision. Experiments on image2mass and ABO-500 show that the proposed method consistently outperforms state-of-the-art methods.", "AI": {"tldr": "提出了一种从单张 RGB 图像估计物体质量的物理结构化方法，通过结合单目深度估计得到的几何信息和视觉语言模型提取的材质语义信息，并利用实例自适应门控机制融合这些信息，最终实现比现有方法更优的质量估计。", "motivation": "从视觉输入估计物体质量是一个挑战，因为质量同时取决于无法直接从 RGB 外观观察到的几何体积和与材料相关的密度。因此，从像素预测质量是不适定的，需要引入具有物理意义的表示来约束合理的解空间。", "method": "该方法首先从单张 RGB 图像通过单目深度估计恢复物体三维几何信息以获取体积，然后利用视觉语言模型提取粗略的材质语义信息以指导密度推理。接着，通过实例自适应门控机制融合几何、语义和外观表示，并通过两个分别与体积和密度相关的物理指导的潜在因子进行回归预测，仅使用质量信息进行监督。", "result": "在 image2mass 和 ABO-500 数据集上的实验表明，该方法持续优于最先进的方法。", "conclusion": "所提出的物理结构化框架能够有效地解决单图像质量估计中的不适定性问题，通过融合几何和材质语义信息，实现了比现有方法更准确的质量估计。"}}
{"id": "2601.20846", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20846", "abs": "https://arxiv.org/abs/2601.20846", "authors": ["Jamie Hathaway", "Alireza Rastegarpanah", "Rustam Stolkin"], "title": "End-to-end example-based sim-to-real RL policy transfer based on neural stylisation with application to robotic cutting", "comment": "14 pages, 9 figures. Submitted to Nature Scientific Reports", "summary": "Whereas reinforcement learning has been applied with success to a range of robotic control problems in complex, uncertain environments, reliance on extensive data - typically sourced from simulation environments - limits real-world deployment due to the domain gap between simulated and physical systems, coupled with limited real-world sample availability. We propose a novel method for sim-to-real transfer of reinforcement learning policies, based on a reinterpretation of neural style transfer from image processing to synthesise novel training data from unpaired unlabelled real world datasets. We employ a variational autoencoder to jointly learn self-supervised feature representations for style transfer and generate weakly paired source-target trajectories to improve physical realism of synthesised trajectories. We demonstrate the application of our approach based on the case study of robot cutting of unknown materials. Compared to baseline methods, including our previous work, CycleGAN, and conditional variational autoencoder-based time series translation, our approach achieves improved task completion time and behavioural stability with minimal real-world data. Our framework demonstrates robustness to geometric and material variation, and highlights the feasibility of policy adaptation in challenging contact-rich tasks where real-world reward information is unavailable.", "AI": {"tldr": "本文提出了一种新颖的基于风格迁移的强化学习 sim-to-real 迁移方法，通过生成合成数据来弥合仿真与现实世界的差距，并在机器人切削任务中取得了显著的改进。", "motivation": "现实世界机器人强化学习应用的限制在于对大量数据的依赖，而仿真环境与真实世界的领域差距以及真实世界样本的有限性阻碍了其部署。", "method": "利用变分自编码器（VAE）对无配对的无标签真实世界数据集进行风格迁移，生成合成训练数据。VAE 同时学习自监督特征表示，并生成弱配对的源-目标轨迹，以提高合成轨迹的物理真实性。", "result": "与现有基线方法（包括 CycleGAN 和条件 VAE）相比，该方法在机器人切削未知材料的任务中，显著提高了任务完成时间和行为稳定性，且仅需少量真实世界数据。该框架对几何和材料变化具有鲁棒性。", "conclusion": "该方法有效地实现了强化学习策略的 sim-to-real 迁移，尤其在缺乏真实世界奖励信息且具有挑战性的接触丰富任务中，证明了策略适应的可行性。"}}
{"id": "2601.19933", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19933", "abs": "https://arxiv.org/abs/2601.19933", "authors": ["Kei Saito"], "title": "Text-to-State Mapping for Non-Resolution Reasoning: The Contradiction-Preservation Principle", "comment": "17 pages, 3 figures, 5 tables. Sequel to arXiv:2512.13478", "summary": "Non-Resolution Reasoning (NRR) provides a formal framework for maintaining semantic ambiguity rather than forcing premature interpretation collapse. While the foundational architecture establishes state spaces and operators for ambiguity-preserving computation, the critical question of how natural language maps to these mathematical structures remains open. This paper introduces the text-to-state mapping function φ that transforms linguistic input into superposition states within the NRR framework. We formalize the Contradiction-Preservation Principle, which requires that genuinely ambiguous expressions maintain non-zero entropy in their state representations, and develop extraction protocols using existing Large Language Models as interpretation generators. Empirical validation across 68 test sentences spanning lexical, structural, and pragmatic ambiguity demonstrates that our mapping achieves mean Shannon entropy H(S) = 1.087 bits for ambiguous inputs while baseline single-interpretation approaches yield H(S) = 0.000. The framework provides the missing algorithmic bridge between raw text and the formal state spaces on which NRR operators act, enabling architectural collapse deferment in language model inference.", "AI": {"tldr": "本文提出了一种将自然语言文本映射到非分辨率推理（NRR）框架中的状态表示的函数φ，该函数能够保留语义歧义，并通过经验验证了其有效性。", "motivation": "现有NRR框架缺乏将自然语言输入映射到其数学结构的方法，导致在语言模型推理中无法有效推迟解释崩溃。", "method": "提出文本到状态映射函数φ，形式化了矛盾保留原则，并利用大型语言模型开发了提取协议来生成解释。", "result": "在68个测试句子上的实验表明，提出的映射函数可以将歧义输入的平均香农熵（H(S)）提高到1.087比特，而基线方法的熵为0。", "conclusion": "该框架成功地弥合了原始文本与NRR状态空间之间的算法鸿沟，使得在语言模型推理中可以推迟架构崩溃，从而更有效地处理语义歧义。"}}
{"id": "2601.20696", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20696", "abs": "https://arxiv.org/abs/2601.20696", "authors": ["Samira Yazdanpourmoghadam", "Mahan Balal Pour", "Vahid Partovi Nia"], "title": "Enterprise Resource Planning Using Multi-type Transformers in Ferro-Titanium Industry", "comment": null, "summary": "Combinatorial optimization problems such as the Job-Shop Scheduling Problem (JSP) and Knapsack Problem (KP) are fundamental challenges in operations research, logistics, and eterprise resource planning (ERP). These problems often require sophisticated algorithms to achieve near-optimal solutions within practical time constraints. Recent advances in deep learning have introduced transformer-based architectures as promising alternatives to traditional heuristics and metaheuristics. We leverage the Multi-Type Transformer (MTT) architecture to address these benchmarks in a unified framework. We present an extensive experimental evaluation across standard benchmark datasets for JSP and KP, demonstrating that MTT achieves competitive performance on different size of these benchmark problems. We showcase the potential of multi-type attention on a real application in Ferro-Titanium industry. To the best of our knowledge, we are the first to apply multi-type transformers in real manufacturing.", "AI": {"tldr": "本文提出了一种名为多类型Transformer（MTT）的统一框架，用于解决作业车间调度（JSP）和背包问题（KP）等组合优化问题，并在标准基准数据集上进行了实验评估，结果表明MTT表现出竞争力。此外，研究还将MTT应用于铁钛行业的实际生产中，是首个将多类型Transformer应用于实际制造领域的尝试。", "motivation": "传统启发式和元启发式算法在解决组合优化问题时面临挑战，而深度学习（尤其是Transformer）展现出潜力。作者希望利用MTT架构在一个统一的框架内解决JSP和KP问题，并验证其在实际制造场景中的有效性。", "method": "采用多类型Transformer（MTT）架构作为统一的解决方案。在标准JSP和KP基准数据集上进行了广泛的实验评估，并将其应用于铁钛行业的实际生产。", "result": "MTT在不同规模的JSP和KP基准问题上取得了具有竞争力的性能。研究展示了多类型注意力机制在铁钛行业实际应用中的潜力。", "conclusion": "多类型Transformer（MTT）是一种有效的统一框架，可以处理JSP和KP等组合优化问题，并在标准基准和实际制造应用中均表现出良好的性能。研究首次将多类型Transformer应用于实际制造领域，预示了其在该领域的应用前景。"}}
{"id": "2601.20304", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20304", "abs": "https://arxiv.org/abs/2601.20304", "authors": ["Genyuan Zhang", "Zihao Wang", "Zhifan Gao", "Lei Xu", "Zhen Zhou", "Haijun Yu", "Jianjia Zhang", "Xiujian Liu", "Weiwei Zhang", "Shaoyu Wang", "Huazhu Fu", "Fenglin Liu", "Weiwen Wu"], "title": "Structure-constrained Language-informed Diffusion Model for Unpaired Low-dose Computed Tomography Angiography Reconstruction", "comment": null, "summary": "The application of iodinated contrast media (ICM) improves the sensitivity and specificity of computed tomography (CT) for a wide range of clinical indications. However, overdose of ICM can cause problems such as kidney damage and life-threatening allergic reactions. Deep learning methods can generate CT images of normal-dose ICM from low-dose ICM, reducing the required dose while maintaining diagnostic power. However, existing methods are difficult to realize accurate enhancement with incompletely paired images, mainly because of the limited ability of the model to recognize specific structures. To overcome this limitation, we propose a Structure-constrained Language-informed Diffusion Model (SLDM), a unified medical generation model that integrates structural synergy and spatial intelligence. First, the structural prior information of the image is effectively extracted to constrain the model inference process, thus ensuring structural consistency in the enhancement process. Subsequently, semantic supervision strategy with spatial intelligence is introduced, which integrates the functions of visual perception and spatial reasoning, thus prompting the model to achieve accurate enhancement. Finally, the subtraction angiography enhancement module is applied, which serves to improve the contrast of the ICM agent region to suitable interval for observation. Qualitative analysis of visual comparison and quantitative results of several metrics demonstrate the effectiveness of our method in angiographic reconstruction for low-dose contrast medium CT angiography.", "AI": {"tldr": "提出一种结构约束语言信息扩散模型（SLDM），通过结合结构先验信息和空间语义监督，以及引入减影血管造影增强模块，实现从低剂量碘化对比剂CT图像生成高剂量图像，以提高图像质量并减少对比剂用量。", "motivation": "现有深度学习方法在处理不完全配对图像时，由于模型识别特定结构的能力有限，难以实现精确的增强。高剂量碘化对比剂可能导致肾脏损伤和严重的过敏反应，因此需要降低对比剂用量。", "method": "提出结构约束语言信息扩散模型（SLDM），该模型包含三个主要部分：1. 提取图像结构先验信息来约束模型推理过程，保证结构一致性；2. 引入具有空间智能的语义监督策略，整合视觉感知和空间推理功能，实现精确增强；3. 应用减影血管造影增强模块，提高碘化对比剂区域的对比度。", "result": "定性和定量分析结果表明，所提出的SLDM方法在低剂量对比剂CT血管造影的重建方面是有效的。", "conclusion": "SLDM是一种有效的医学图像生成模型，能够通过整合结构信息和空间语义，在低剂量碘化对比剂CT图像重建中实现精确增强，并减少对比剂用量。"}}
{"id": "2601.19934", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19934", "abs": "https://arxiv.org/abs/2601.19934", "authors": ["Claire Nicholson"], "title": "Quantifying non deterministic drift in large language models", "comment": "10 pages, 3 figures, 1 table. Empirical measurement study reporting new repeated-run experiments quantifying baseline nondeterministic drift in large language models. This manuscript presents original empirical results (not a review or position paper) and establishes a baseline reference for future drift-mitigation work", "summary": "Large language models (LLMs) are widely used for tasks ranging from summarisation to decision support. In practice, identical prompts do not always produce identical outputs, even when temperature and other decoding parameters are fixed. In this work, we conduct repeated-run experiments to empirically quantify baseline behavioural drift, defined as output variability observed when the same prompt is issued multiple times under operator-free conditions. We evaluate two publicly accessible models, gpt-4o-mini and llama3.1-8b, across five prompt categories using exact repeats, perturbed inputs, and reuse modes at temperatures of 0.0 and 0.7. Drift is measured using unique output fractions, lexical similarity, and word count statistics, enabling direct comparison across models, prompting modes, and deployment types. The results show that nondeterminism persists even at temperature 0.0, with distinct variability patterns by model size, deployment, and prompt type. We situate these findings within existing work on concept drift, behavioural drift, and infrastructure-induced nondeterminism, discuss the limitations of lexical metrics, and highlight emerging semantic approaches. By establishing a systematic empirical baseline in the absence of stabilisation techniques, this study provides a reference point for evaluating future drift mitigation and control methods.", "AI": {"tldr": "研究发现，即使在固定参数下，大型语言模型（LLMs）在重复运行中也会表现出行为漂移（输出不确定性），且这种漂移受模型大小、部署方式和提示类型影响。", "motivation": "在实践中，LLMs即使在相同提示和固定参数下，输出也可能不同，这种不确定性（行为漂移）尚未得到充分量化。", "method": "对gpt-4o-mini和llama3.1-8b两个模型，在五种提示类别下，使用完全相同提示、扰动输入和重用模式，在温度0.0和0.7下进行重复运行实验，并使用唯一输出比例、词汇相似度和词数统计来衡量漂移。", "result": "即使在温度0.0下，模型输出也存在显著的非确定性；不同模型大小、部署方式和提示类型表现出不同的漂移模式。", "conclusion": "本研究首次系统地量化了在无干预条件下的LLMs行为漂移，为评估未来漂移缓解和控制方法提供了基准。"}}
{"id": "2601.20720", "categories": ["cs.CV", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20720", "abs": "https://arxiv.org/abs/2601.20720", "authors": ["Matej Halinkovic", "Nina Masarykova", "Alexey Vinel", "Marek Galinski"], "title": "Li-ViP3D++: Query-Gated Deformable Camera-LiDAR Fusion for End-to-End Perception and Trajectory Prediction", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "End-to-end perception and trajectory prediction from raw sensor data is one of the key capabilities for autonomous driving. Modular pipelines restrict information flow and can amplify upstream errors. Recent query-based, fully differentiable perception-and-prediction (PnP) models mitigate these issues, yet the complementarity of cameras and LiDAR in the query-space has not been sufficiently explored. Models often rely on fusion schemes that introduce heuristic alignment and discrete selection steps which prevent full utilization of available information and can introduce unwanted bias. We propose Li-ViP3D++, a query-based multimodal PnP framework that introduces Query-Gated Deformable Fusion (QGDF) to integrate multi-view RGB and LiDAR in query space. QGDF (i) aggregates image evidence via masked attention across cameras and feature levels, (ii) extracts LiDAR context through fully differentiable BEV sampling with learned per-query offsets, and (iii) applies query-conditioned gating to adaptively weight visual and geometric cues per agent. The resulting architecture jointly optimizes detection, tracking, and multi-hypothesis trajectory forecasting in a single end-to-end model. On nuScenes, Li-ViP3D++ improves end-to-end behavior and detection quality, achieving higher EPA (0.335) and mAP (0.502) while substantially reducing false positives (FP ratio 0.147), and it is faster than the prior Li-ViP3D variant (139.82 ms vs. 145.91 ms). These results indicate that query-space, fully differentiable camera-LiDAR fusion can increase robustness of end-to-end PnP without sacrificing deployability.", "AI": {"tldr": "Li-ViP3D++ 提出了一种基于查询的多模态感知和预测（PnP）框架，通过查询门控可变形融合（QGDF）方法，在查询空间中有效融合了多视图 RGB 图像和 LiDAR 数据，实现了端到端的检测、跟踪和轨迹预测。该方法在 nuScenes 数据集上取得了更好的性能和更快的推理速度。", "motivation": "现有的模块化自动驾驶感知和预测方法存在信息流受限和误差累积问题。近期的全可微分查询式 PnP 模型虽然缓解了这些问题，但尚未充分探索相机和 LiDAR 在查询空间中的互补性。现有的融合方案常引入启发式对齐和离散选择步骤，限制了信息利用并可能引入偏差。", "method": "提出 Li-ViP3D++，一个基于查询的多模态 PnP 框架。核心是查询门控可变形融合（QGDF），它在查询空间中融合多视图 RGB 和 LiDAR 数据。QGDF 包括：(i) 通过跨相机和特征级别的掩码注意力聚合图像证据；(ii) 通过具有学习到的每查询偏移的全可微分 BEV 采样提取 LiDAR 上下文；(iii) 应用查询条件门控，为每个代理自适应地加权视觉和几何线索。整个模型端到端地联合优化检测、跟踪和多假设轨迹预测。", "result": "在 nuScenes 数据集上，Li-ViP3D++ 提高了端到端的行为和检测质量，取得了更高的 EPA (0.335) 和 mAP (0.502)，同时显著降低了误报率（FP ratio 0.147）。此外，其推理速度比之前的 Li-ViP3D 变体更快（139.82 ms vs. 145.91 ms）。", "conclusion": "基于查询的全可微分相机-LiDAR 融合方法可以在不牺牲可部署性的情况下提高端到端 PnP 系统的鲁棒性。"}}
{"id": "2601.20735", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.20735", "abs": "https://arxiv.org/abs/2601.20735", "authors": ["Arvid Becker", "Pedro Cabalar", "Martin Diéguez", "Susana Hahn", "Javier Romero", "Torsten Schaub"], "title": "Implementing Metric Temporal Answer Set Programming", "comment": null, "summary": "We develop a computational approach to Metric Answer Set Programming (ASP) to allow for expressing quantitative temporal constraints, like durations and deadlines. A central challenge is to maintain scalability when dealing with fine-grained timing constraints, which can significantly exacerbate ASP's grounding bottleneck. To address this issue, we leverage extensions of ASP with difference constraints, a simplified form of linear constraints, to handle time-related aspects externally. Our approach effectively decouples metric ASP from the granularity of time, resulting in a solution that is unaffected by time precision.", "AI": {"tldr": "提出了一种计算方法来处理带度量度的答案集规划（ASP），以表达定量时间约束。通过使用差分约束来外部处理时间相关方面，解决了细粒度时间约束可能导致的 ASP 基础瓶颈问题，并使其不受时间精度影响。", "motivation": "在度量 ASP 中表达具有持续时间和截止时间等定量时间约束的需求，以及在处理细粒度时间约束时保持 ASP 的可扩展性这一挑战。", "method": "将度量 ASP 与差分约束（一种简化的线性约束形式）相结合，将时间相关方面外部化处理。", "result": "该方法有效解耦了度量 ASP 与时间的粒度，使得解决方案不受时间精度的影响。", "conclusion": "该计算方法能够有效地处理带度量度的 ASP，并能处理定量时间约束，同时保持了良好的可扩展性，不受时间精度的影响。"}}
{"id": "2601.20306", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20306", "abs": "https://arxiv.org/abs/2601.20306", "authors": ["Yanjie Tu", "Qingsen Yan", "Axi Niu", "Jiacong Tang"], "title": "TPGDiff: Hierarchical Triple-Prior Guided Diffusion for Image Restoration", "comment": null, "summary": "All-in-one image restoration aims to address diverse degradation types using a single unified model. Existing methods typically rely on degradation priors to guide restoration, yet often struggle to reconstruct content in severely degraded regions. Although recent works leverage semantic information to facilitate content generation, integrating it into the shallow layers of diffusion models often disrupts spatial structures (\\emph{e.g.}, blurring artifacts). To address this issue, we propose a Triple-Prior Guided Diffusion (TPGDiff) network for unified image restoration. TPGDiff incorporates degradation priors throughout the diffusion trajectory, while introducing structural priors into shallow layers and semantic priors into deep layers, enabling hierarchical and complementary prior guidance for image reconstruction. Specifically, we leverage multi-source structural cues as structural priors to capture fine-grained details and guide shallow layers representations. To complement this design, we further develop a distillation-driven semantic extractor that yields robust semantic priors, ensuring reliable high-level guidance at deep layers even under severe degradations. Furthermore, a degradation extractor is employed to learn degradation-aware priors, enabling stage-adaptive control of the diffusion process across all timesteps. Extensive experiments on both single- and multi-degradation benchmarks demonstrate that TPGDiff achieves superior performance and generalization across diverse restoration scenarios. Our project page is: https://leoyjtu.github.io/tpgdiff-project.", "AI": {"tldr": "提出了一种名为TPGDiff的统一图像修复网络，该网络通过结合降质先验、结构先验和语义先验，并采用分层引导的方式，能够有效处理各种图像降质问题，尤其在严重降质区域表现更佳。", "motivation": "现有统一图像修复模型在处理严重降质区域时效果不佳，且将语义信息集成到扩散模型的浅层会破坏空间结构。因此，需要一种新的方法来有效融合多源先验信息，以提升修复效果。", "method": "提出TPGDiff网络，结合降质先验、结构先验和语义先验。结构先验通过多源结构线索捕获细节并指导浅层表示；语义先验通过蒸馏驱动的语义提取器提供鲁棒的高层指导；降质先验通过降质提取器实现对所有时间步的扩散过程进行自适应控制。", "result": "TPGDiff在多种单降质和多降质基准测试中，展现出优于现有方法的性能和泛化能力，尤其在处理严重降质的图像时效果显著。", "conclusion": "TPGDiff通过分层整合多源先验信息，成功解决了现有统一图像修复模型在严重降质区域的重建问题，并实现了在多样化修复场景下的出色性能。"}}
{"id": "2601.19935", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19935", "abs": "https://arxiv.org/abs/2601.19935", "authors": ["Yiting Shen", "Kun Li", "Wei Zhou", "Songlin Hu"], "title": "Mem2ActBench: A Benchmark for Evaluating Long-Term Memory Utilization in Task-Oriented Autonomous Agents", "comment": null, "summary": "Large Language Model (LLM)-based agents are increasingly deployed for complex, tool-based tasks where long-term memory is critical to driving actions. Existing benchmarks, however, primarily test a angent's ability to passively retrieve isolated facts in response to explicit questions. They fail to evaluate the more crucial capability of actively applying memory to execute tasks. To address this gap, we introduce \\textsc{Mem2ActBench}, a benchmark for evaluating whether agents can proactively leverage long-term memory to execute tool-based actions by selecting appropriate tools and grounding their parameters. The benchmark simulates persistent assistant usage, where users mention the same topic across long, interrupted interactions and expect previously established preferences and task states to be implicitly applied. We build the dataset with an automated pipeline that merges heterogeneous sources (ToolACE, BFCL, Oasst1), resolves conflicts via consistency modeling, and synthesizes 2,029 sessions with 12 user--assistant--tool turns on average. From these memory chains, a reverse-generation method produces 400 tool-use tasks, with human evaluation confirming 91.3\\% are strongly memory-dependent. Experiments on seven memory frameworks show that current systems remain inadequate at actively utilizing memory for parameter grounding, highlighting the need for more effective approaches to evaluate and improve memory application in task execution.", "AI": {"tldr": "本文提出了 Mem2ActBench，一个评估大型语言模型（LLM）智能体利用长期记忆主动执行基于工具任务的新型基准。现有基准侧重于被动信息检索，而 Mem2ActBench 模拟了用户在中断的交互中持续提及同一话题，并期望智能体能隐式应用先前建立的偏好和任务状态。", "motivation": "现有的大型语言模型（LLM）基准测试主要评估智能体被动检索孤立事实的能力，而未能充分评估其主动运用长期记忆来执行任务的关键能力。为了弥补这一差距，作者提出了 Mem2ActBench。", "method": "Mem2ActBench 基准通过自动化流程构建，整合了 ToolACE、BFCL 和 Oasst1 等异构数据源，并利用一致性建模解决冲突。该基准包含 2029 个模拟持久助理使用的会话，平均包含 12 个用户-助理-工具交互轮次。通过逆向生成方法，从这些记忆链中产生了 400 个工具使用任务，其中 91.3% 的任务经人工评估被证实高度依赖记忆。", "result": "在七个内存框架上的实验表明，当前的 LLM 智能体在主动利用记忆进行参数接地方面仍然不足。这表明需要更有效的方法来评估和改进记忆在任务执行中的应用。", "conclusion": "Mem2ActBench 提供了一个评估 LLM 智能体在复杂、基于工具的任务中主动运用长期记忆能力的有效方法，并揭示了当前系统在此方面的不足，强调了进一步研究的必要性。"}}
{"id": "2601.20831", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.20831", "abs": "https://arxiv.org/abs/2601.20831", "authors": ["Vishnu Sashank Dorbala", "Dinesh Manocha"], "title": "MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents", "comment": null, "summary": "Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we propose MemCtrl, a novel framework that uses Multimodal Large Language Models (MLLMs) for pruning memory online. MemCtrl augments MLLMs with a trainable memory head μthat acts as a gate to determine which observations or reflections to retain, update, or discard during exploration. We evaluate with training two types of μ, 1) via an offline expert, and 2) via online RL, and observe significant improvement in overall embodied task completion ability on μ-augmented MLLMs. In particular, on augmenting two low performing MLLMs with MemCtrl on multiple subsets of the EmbodiedBench benchmark, we observe that μ-augmented MLLMs show an improvement of around 16% on average, with over 20% on specific instruction subsets. Finally, we present a qualitative analysis on the memory fragments collected by μ, noting the superior performance of μaugmented MLLMs on long and complex instruction types.", "AI": {"tldr": "提出了一种名为 MemCtrl 的新框架，利用多模态大语言模型 (MLLM) 和一个可训练的记忆头 μ 来在线压缩和管理记忆，以解决具身智能体内存和计算受限的问题，并在 EmbodiedBench 基准测试中显著提高了任务完成能力。", "motivation": "现有的 RAG 等记忆系统不适用于内存和计算资源受限的具身智能体，这些智能体需要在运行时进行在线的记忆管理。", "method": "提出 MemCtrl 框架，利用 MLLM 和一个可训练的记忆头 μ 来在线剪枝记忆。记忆头 μ 可以决定保留、更新或丢弃哪些观察或反思。训练了两种类型的 μ：一种通过离线专家，另一种通过在线强化学习。", "result": "在 EmbodiedBench 基准测试的多个子集上，使用 MemCtrl 增强的 MLLM 在任务完成能力上平均提高了约 16%，在特定指令子集上提高了 20% 以上。定性分析表明，μ 增强的 MLLM 在处理长而复杂的指令时表现更优。", "conclusion": "MemCtrl 框架通过在线记忆压缩和管理，有效提升了具身智能体在内存和计算受限环境下的任务完成能力，尤其是在处理复杂指令方面。"}}
{"id": "2601.19945", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19945", "abs": "https://arxiv.org/abs/2601.19945", "authors": ["Thomas Schuster", "Julius Trögele", "Nico Döring", "Robin Krüger", "Matthieu Hoffmann", "Holger Friedrich"], "title": "Benchmarking von ASR-Modellen im deutschen medizinischen Kontext: Eine Leistungsanalyse anhand von Anamnesegesprächen", "comment": "Language: German; English Title: Benchmarking ASR Models in German Medical Contexts: A Performance Analysis Using Anamnesis Conversations", "summary": "Automatic Speech Recognition (ASR) offers significant potential to reduce the workload of medical personnel, for example, through the automation of documentation tasks. While numerous benchmarks exist for the English language, specific evaluations for the German-speaking medical context are still lacking, particularly regarding the inclusion of dialects. In this article, we present a curated dataset of simulated doctor-patient conversations and evaluate a total of 29 different ASR models. The test field encompasses both open-weights models from the Whisper, Voxtral, and Wav2Vec2 families as well as commercial state-of-the-art APIs (AssemblyAI, Deepgram). For evaluation, we utilize three different metrics (WER, CER, BLEU) and provide an outlook on qualitative semantic analysis. The results demonstrate significant performance differences between the models: while the best systems already achieve very good Word Error Rates (WER) of partly below 3%, the error rates of other models, especially concerning medical terminology or dialect-influenced variations, are considerably higher.", "AI": {"tldr": "研究评估了29种自动语音识别（ASR）模型在德语医疗对话中的表现，发现模型性能差异显著，最佳模型在专业术语和方言方面仍有改进空间。", "motivation": "现有英语ASR研究较多，但缺乏针对德语医疗环境（尤其是包含方言）的评估，以支持医疗文档自动化。", "method": "构建了一个模拟德语医生-患者对话的数据集，并使用Word Error Rate (WER)、Character Error Rate (CER)和BLEU三种指标评估了29个开源（Whisper、Voxtral、Wav2Vec2）和商业（AssemblyAI、Deepgram）ASR模型。", "result": "模型性能差异巨大，最佳模型WER低于3%，但许多模型在处理医疗术语和方言时错误率较高。", "conclusion": "ASR技术在德语医疗领域的应用潜力巨大，但现有模型在处理专业术语和方言方面仍需优化，以满足实际需求。"}}
{"id": "2601.20784", "categories": ["cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.20784", "abs": "https://arxiv.org/abs/2601.20784", "authors": ["Zishen Wan", "Che-Kai Liu", "Jiayi Qian", "Hanchen Yang", "Arijit Raychowdhury", "Tushar Krishna"], "title": "REASON: Accelerating Probabilistic Logical Reasoning for Scalable Neuro-Symbolic Intelligence", "comment": "16 pages, 13 figures, 5 tables, 2026 IEEE International Symposium on High-Performance Computer Architecture (HPCA)", "summary": "Neuro-symbolic AI systems integrate neural perception with symbolic reasoning to enable data-efficient, interpretable, and robust intelligence beyond purely neural models. Although this compositional paradigm has shown superior performance in domains such as reasoning, planning, and verification, its deployment remains challenging due to severe inefficiencies in symbolic and probabilistic inference. Through systematic analysis of representative neuro-symbolic workloads, we identify probabilistic logical reasoning as the inefficiency bottleneck, characterized by irregular control flow, low arithmetic intensity, uncoalesced memory accesses, and poor hardware utilization on CPUs and GPUs.\n  This paper presents REASON, an integrated acceleration framework for probabilistic logical reasoning in neuro-symbolic AI. REASON introduces a unified directed acyclic graph representation that captures common structure across symbolic and probabilistic models, coupled with adaptive pruning and regularization. At the architecture level, REASON features a reconfigurable, tree-based processing fabric optimized for irregular traversal, symbolic deduction, and probabilistic aggregation. At the system level, REASON is tightly integrated with GPU streaming multiprocessors through a programmable interface and multi-level pipeline that efficiently orchestrates compositional execution. Evaluated across six neuro-symbolic workloads, REASON achieves 12-50x speedup and 310-681x energy efficiency over desktop and edge GPUs under TSMC 28 nm node. REASON enables real-time probabilistic logical reasoning, completing end-to-end tasks in 0.8 s with 6 mm2 area and 2.12 W power, demonstrating that targeted acceleration of probabilistic logical reasoning is critical for practical and scalable neuro-symbolic AI and positioning REASON as a foundational system architecture for next-generation cognitive intelligence.", "AI": {"tldr": "本文提出REASON，一个针对神经符号AI中概率逻辑推理的集成加速框架，通过优化的计算 fabric 和系统集成，实现了显著的性能和能效提升，使实时推理成为可能。", "motivation": "现有神经符号AI系统在数据效率、可解释性和鲁棒性方面表现优异，但在符号和概率推理方面存在严重的效率低下问题，尤其是概率逻辑推理成为瓶颈，限制了其部署。", "method": "REASON通过以下方式加速概率逻辑推理：1. 引入统一的有向无环图（DAG）表示，捕获模型共性，并结合自适应剪枝和正则化。2. 在架构层面，采用可重构的、基于树的处理 fabric，优化不规则遍历、符号演绎和概率聚合。3. 在系统层面，通过可编程接口和多级流水线与GPU紧密集成，高效协调组合式执行。", "result": "在六个神经符号工作负载上，REASON 相较于台式机和边缘 GPU 实现了12-50倍的速度提升和310-681倍的能效提升。REASON 能够实现端到端的实时推理，在0.8秒内完成任务，仅占用6 mm² 面积和2.12W功耗。", "conclusion": "REASON 证明了针对概率逻辑推理进行定向加速对于实际和可扩展的神经符号AI至关重要，并为下一代认知智能奠定了基础系统架构。"}}
{"id": "2601.20308", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.20308", "abs": "https://arxiv.org/abs/2601.20308", "authors": ["Shuoyan Wei", "Feng Li", "Chen Zhou", "Runmin Cong", "Yao Zhao", "Huihui Bai"], "title": "OSDEnhancer: Taming Real-World Space-Time Video Super-Resolution with One-Step Diffusion", "comment": "17 pages, 10 figures. Code will be released upon publication", "summary": "Diffusion models (DMs) have demonstrated exceptional success in video super-resolution (VSR), showcasing a powerful capacity for generating fine-grained details. However, their potential for space-time video super-resolution (STVSR), which necessitates not only recovering realistic visual content from low-resolution to high-resolution but also improving the frame rate with coherent temporal dynamics, remains largely underexplored. Moreover, existing STVSR methods predominantly address spatiotemporal upsampling under simplified degradation assumptions, which often struggle in real-world scenarios with complex unknown degradations. Such a high demand for reconstruction fidelity and temporal consistency makes the development of a robust STVSR framework particularly non-trivial. To address these challenges, we propose OSDEnhancer, a novel framework that, to the best of our knowledge, represents the first method to achieve real-world STVSR through an efficient one-step diffusion process. OSDEnhancer initializes essential spatiotemporal structures through a linear pre-interpolation strategy and pivots on training temporal refinement and spatial enhancement mixture of experts (TR-SE MoE), which allows distinct expert pathways to progressively learn robust, specialized representations for temporal coherence and spatial detail, further collaboratively reinforcing each other during inference. A bidirectional deformable variational autoencoder (VAE) decoder is further introduced to perform recurrent spatiotemporal aggregation and propagation, enhancing cross-frame reconstruction fidelity. Experiments demonstrate that the proposed method achieves state-of-the-art performance while maintaining superior generalization capability in real-world scenarios.", "AI": {"tldr": "OSDEnhancer 提出了一种新颖的一步扩散模型框架，用于解决真实世界视频超分辨率（STVSR）问题，该问题兼顾了空间和时间维度，并且能处理复杂的未知退化。该方法通过线性预插值初始化时空结构，并利用时间细化和空间增强的混合专家（TR-SE MoE）来学习专业化表示，同时引入双向可变形变分自编码器（VAE）解码器进行时空聚合，从而在真实场景中取得了先进的性能和泛化能力。", "motivation": "现有视频超分辨率（VSR）方法在处理空间-时间视频超分辨率（STVSR）时存在不足，尤其是在处理具有复杂未知退化的真实场景时。STVSR不仅需要提高分辨率，还需要保持时间上的连贯性，这对于现有方法来说是一个挑战。", "method": "提出 OSDEnhancer 框架，采用高效的一步扩散过程。首先通过线性预插值策略初始化时空结构。然后，引入时间细化和空间增强的混合专家（TR-SE MoE）模型，使不同的专家学习时空连贯性和空间细节的专业化表示，并在推理时协同工作。此外，还引入了双向可变形变分自编码器（VAE）解码器，用于进行递归的时空聚合和传播，以提高跨帧重建的保真度。", "result": "实验证明，OSDEnhancer 在真实场景下取得了最先进的性能，并保持了优越的泛化能力。", "conclusion": "OSDEnhancer 是首个实现真实世界 STVSR 的一步扩散方法，通过创新的混合专家机制和 VAE 解码器，有效解决了复杂退化和时空连贯性的挑战，并在真实场景下展现出出色的性能和泛化能力。"}}
{"id": "2601.20843", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20843", "abs": "https://arxiv.org/abs/2601.20843", "authors": ["Saurav Prateek"], "title": "Deep Researcher with Sequential Plan Reflection and Candidates Crossover (Deep Researcher Reflect Evolve)", "comment": "11 pages, 6 figures, 2 tables, source code: https://github.com/SauravP97/deep-researcher-reflect-evolve/", "summary": "This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficient method that allows the agent to maintain a centralized Global Research Context, enabling it to look back at current progress, reason about the research plan, and intelligently make changes at runtime. This dynamic adaptation contrasts with parallel approaches, which often suffer from siloed knowledge. The Candidates Crossover algorithm further enhances search efficiency by deploying multiple LLM candidates with varied parameters to explore a larger search space, with their findings synthesized to curate a comprehensive final research response. The process concludes with One Shot Report Generation, ensuring the final document is informed by a unified narrative and high fact density. Powered by the Gemini 2.5 Pro model, our Deep Researcher was evaluated on the DeepResearch Bench, a globally recognized benchmark of 100 doctoral level research tasks. Our architecture achieved an overall score of 46.21, demonstrating superior performance by surpassing leading deep research agents such as Claude Researcher, Nvidia AIQ Research Assistant, Perplexity Research, Kimi Researcher and Grok Deeper Search present on the DeepResearch Bench actively running leaderboard. This performance marginally exceeds our previous work, Static DRA, and reinforces the finding that sequential scaling consistently outperforms the parallel self consistency paradigm.", "AI": {"tldr": "本文提出了一种名为Deep Researcher的新型深度研究架构，旨在克服并行扩展范式的局限性，生成关于复杂博士级别主题的详细研究报告。该架构通过顺序研究计划精炼和候选交叉算法实现。", "motivation": "传统的并行扩展范式在生成关于复杂博士级别主题的研究报告时存在固有局限性，如知识孤岛问题。作者希望设计一种更有效的架构来克服这些限制。", "method": "该系统采用两种关键创新：1. 通过反思进行顺序研究计划精炼（Sequential Research Plan Refinement via Reflection），允许代理维护全局研究上下文，动态调整研究计划。2. 候选交叉算法（Candidates Crossover algorithm），部署具有不同参数的多个LLM候选者探索更大搜索空间，并综合其发现。最终通过一次性报告生成（One Shot Report Generation）完成。", "result": "在DeepResearch Bench（包含100个博士级别研究任务的基准）上，Deep Researcher架构取得了46.21的总体分数，优于Claude Researcher、Nvidia AIQ Research Assistant、Perplexity Research、Kimi Researcher和Grok Deeper Search等领先的深度研究代理。此性能略优于先前的Static DRA工作，并证实了顺序扩展优于并行自洽范式。", "conclusion": "Deep Researcher架构通过顺序研究计划精炼和候选交叉算法，成功克服了并行扩展范式的局限性，在博士级别研究报告生成方面取得了优于现有最先进方法的性能。研究再次强调了顺序扩展方法在深度研究代理中的优越性。"}}
{"id": "2601.20006", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20006", "abs": "https://arxiv.org/abs/2601.20006", "authors": ["Michał Gromadzki", "Anna Wróblewska", "Agnieszka Kaliska"], "title": "On the Effectiveness of LLM-Specific Fine-Tuning for Detecting AI-Generated Text", "comment": "34 pages, 6 figures. Under review at Information Sciences", "summary": "The rapid progress of large language models has enabled the generation of text that closely resembles human writing, creating challenges for authenticity verification in education, publishing, and digital security. Detecting AI-generated text has therefore become a crucial technical and ethical issue. This paper presents a comprehensive study of AI-generated text detection based on large-scale corpora and novel training strategies. We introduce a 1-billion-token corpus of human-authored texts spanning multiple genres and a 1.9-billion-token corpus of AI-generated texts produced by prompting a variety of LLMs across diverse domains. Using these resources, we develop and evaluate numerous detection models and propose two novel training paradigms: Per LLM and Per LLM family fine-tuning. Across a 100-million-token benchmark covering 21 large language models, our best fine-tuned detector achieves up to $99.6\\%$ token-level accuracy, substantially outperforming existing open-source baselines.", "AI": {"tldr": "研究提出了一种新的AI生成文本检测方法，通过大规模语料库和创新的训练策略，显著提高了检测精度，最佳模型准确率高达99.6%。", "motivation": "AI生成文本的快速发展给教育、出版和数字安全领域的真实性验证带来了挑战，因此检测AI生成文本成为一个关键的技术和伦理问题。", "method": "构建了包含10亿token的人类文本语料库和19亿token的AI生成文本语料库，并开发了两种新颖的训练策略：Per LLM和Per LLM family fine-tuning，用于训练检测模型。", "result": "在包含21个大型语言模型的1亿token基准测试中，最佳的微调检测器实现了高达99.6%的token级准确率，远超现有的开源基线模型。", "conclusion": "提出的基于大规模语料库和新训练策略的AI生成文本检测方法能够有效且高精度地识别AI生成内容，解决了当前面临的挑战。"}}
{"id": "2601.20318", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20318", "abs": "https://arxiv.org/abs/2601.20318", "authors": ["Jiyuan Xu", "Wenyu Zhang", "Xin Jing", "Shuai Chen", "Shuai Zhang", "Jiahao Nie"], "title": "CPiRi: Channel Permutation-Invariant Relational Interaction for Multivariate Time Series Forecasting", "comment": "22 pages, ICLR 2026", "summary": "Current methods for multivariate time series forecasting can be classified into channel-dependent and channel-independent models. Channel-dependent models learn cross-channel features but often overfit the channel ordering, which hampers adaptation when channels are added or reordered. Channel-independent models treat each channel in isolation to increase flexibility, yet this neglects inter-channel dependencies and limits performance. To address these limitations, we propose \\textbf{CPiRi}, a \\textbf{channel permutation invariant (CPI)} framework that infers cross-channel structure from data rather than memorizing a fixed ordering, enabling deployment in settings with structural and distributional co-drift without retraining. CPiRi couples \\textbf{spatio-temporal decoupling architecture} with \\textbf{permutation-invariant regularization training strategy}: a frozen pretrained temporal encoder extracts high-quality temporal features, a lightweight spatial module learns content-driven inter-channel relations, while a channel shuffling strategy enforces CPI during training. We further \\textbf{ground CPiRi in theory} by analyzing permutation equivariance in multivariate time series forecasting. Experiments on multiple benchmarks show state-of-the-art results. CPiRi remains stable when channel orders are shuffled and exhibits strong \\textbf{inductive generalization} to unseen channels even when trained on \\textbf{only half} of the channels, while maintaining \\textbf{practical efficiency} on large-scale datasets. The source code is released at https://github.com/JasonStraka/CPiRi.", "AI": {"tldr": "CPiRi是一个新颖的多变量时间序列预测框架，通过引入通道置换不变性（CPI）来解决现有方法的局限性，实现了更强的泛化能力和鲁棒性。", "motivation": "现有时间序列预测方法要么过于依赖通道顺序（导致过拟合），要么忽略通道间的依赖关系（限制性能）。研究旨在克服这些局限，实现对通道顺序不敏感、能有效利用跨通道依赖的模型。", "method": "CPiRi采用通道置换不变（CPI）框架，结合了空间-时间解耦架构和置换不变正则化训练策略。具体而言，它使用预训练的固定时间编码器提取时间特征，一个轻量级空间模块学习通道间的依赖关系，并通过通道混洗策略强制训练过程中的CPI。", "result": "CPiRi在多个基准数据集上取得了最先进的性能。即使在通道顺序被打乱的情况下，模型也能保持稳定。此外，CPiRi在仅使用一半通道进行训练的情况下，对未见过的通道也展现出强大的归纳泛化能力，并且在大规模数据集上保持了实际效率。", "conclusion": "CPiRi通过引入通道置换不变性，克服了现有方法的不足，在多变量时间序列预测任务中实现了高性能、鲁棒性和出色的泛化能力，尤其适用于通道结构或分布发生变化以及存在未见通道的场景。"}}
{"id": "2601.20856", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20856", "abs": "https://arxiv.org/abs/2601.20856", "authors": ["Sebastiano Monti", "Carlo Nicolini", "Gianni Pellegrini", "Jacopo Staiano", "Bruno Lepri"], "title": "SokoBench: Evaluating Long-Horizon Planning and Reasoning in Large Language Models", "comment": null, "summary": "Although the capabilities of large language models have been increasingly tested on complex reasoning tasks, their long-horizon planning abilities have not yet been extensively investigated. In this work, we provide a systematic assessment of the planning and long-horizon reasoning capabilities of state-of-the-art Large Reasoning Models (LRMs). We propose a novel benchmark based on Sokoban puzzles, intentionally simplified to isolate long-horizon planning from state persistence. Our findings reveal a consistent degradation in planning performance when more than 25 moves are required to reach the solution, suggesting a fundamental constraint on forward planning capacity. We show that equipping LRMs with Planning Domain Definition Language (PDDL) parsing, validation, and solving tools allows for modest improvements, suggesting inherent architectural limitations which might not be overcome by test-time scaling approaches alone.", "AI": {"tldr": "该研究评估了大型语言模型（LRMs）在 Sokoban 谜题上的长时序规划能力，发现其规划能力随着所需移动步数增加而显著下降，并且 PDDL 工具的辅助作用有限，表明模型存在固有的架构限制。", "motivation": "尽管大型语言模型在复杂推理任务上表现出色，但对其长时序规划能力的研究尚不充分，作者旨在系统性地评估这一能力。", "method": "作者提出了一个基于 Sokoban 谜题的新基准，通过简化谜题来分离长时序规划和状态持久性。他们还评估了为 LRM 提供 PDDL 解析、验证和求解工具的效果。", "result": "研究发现，当解决谜题所需的移动步数超过 25 步时，LRMs 的规划性能会持续下降。为 LRM 提供 PDDL 工具可以带来小幅度的性能提升。", "conclusion": "LRMs 的前向规划能力存在根本性限制，即使通过测试时规模化也可能无法完全克服，这表明模型可能存在固有的架构局限性。"}}
{"id": "2601.20009", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20009", "abs": "https://arxiv.org/abs/2601.20009", "authors": ["J. Ben Tamo", "Daniel Carlander-Reuterfelt", "Jonathan Rubin", "Dezhi Hong", "Mingxian Wang", "Oleg Poliannikov"], "title": "LinguaMap: Which Layers of LLMs Speak Your Language and How to Tune Them?", "comment": null, "summary": "Despite multilingual pretraining, large language models often struggle with non-English tasks, particularly in language control, the ability to respond in the intended language. We identify and characterize two key failure modes: the multilingual transfer bottleneck (correct language, incorrect task response) and the language consistency bottleneck (correct task response, wrong language). To systematically surface these issues, we design a four-scenario evaluation protocol spanning MMLU, MGSM, and XQuAD benchmarks. To probe these issues with interpretability, we extend logit lens analysis to track language probabilities layer by layer and compute cross-lingual semantic similarity of hidden states. The results reveal a three-phase internal structure: early layers align inputs into a shared semantic space, middle layers perform task reasoning, and late layers drive language-specific generation. Guided by these insights, we introduce selective fine-tuning of only the final layers responsible for language control. On Qwen-3-32B and Bloom-7.1B, this method achieves over 98 percent language consistency across six languages while fine-tuning only 3-5 percent of parameters, without sacrificing task accuracy. Importantly, this result is nearly identical to that of full-scope fine-tuning (for example, above 98 percent language consistency for both methods across all prompt scenarios) but uses a fraction of the computational resources. To the best of our knowledge, this is the first approach to leverage layer-localization of language control for efficient multilingual adaptation.", "AI": {"tldr": "该研究提出了一个系统性的评估框架和一种选择性微调方法，以解决大型语言模型在多语言任务中的语言控制问题，并在不牺牲任务准确性的情况下，显著提高了语言一致性，且计算资源消耗更少。", "motivation": "大型语言模型在非英语任务中，尤其是在语言控制（响应指定语言的能力）方面表现不佳，存在多语言迁移瓶颈和语言一致性瓶颈两种故障模式。", "method": "设计了一个包含四个场景的评估协议，覆盖MMLU、MGSM和XQuAD基准。扩展了Logit Lens分析，逐层追踪语言概率，并计算隐藏状态的跨语言语义相似度。基于观察到的模型内部三阶段结构（早期层对齐输入，中间层执行任务推理，晚期层驱动语言生成），提出仅微调负责语言控制的最后一层的选择性微调方法。", "result": "发现大型语言模型存在一个三阶段的内部结构，其中早期层对齐输入、中间层进行任务推理、晚期层负责语言生成。选择性微调方法在Qwen-3-32B和Bloom-7.1B模型上，实现了超过98%的六种语言的语言一致性，同时仅微调3-5%的参数，且任务准确性未受影响。该结果与全范围微调相当，但计算资源消耗极少。", "conclusion": "该研究首次提出了利用语言控制的层定位来进行高效多语言适应的方法，即选择性微调模型末端语言生成层，可以高效地解决大型语言模型的多语言语言控制问题，取得与全范围微调相当的效果，但计算效率更高。"}}
{"id": "2601.20333", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20333", "abs": "https://arxiv.org/abs/2601.20333", "authors": ["Ali Zia", "Usman Ali", "Umer Ramzan", "Abdul Rehman", "Abdelwahed Khamis", "Wei Xiang"], "title": "Test-Time Adaptation for Anomaly Segmentation via Topology-Aware Optimal Transport Chaining", "comment": null, "summary": "Deep topological data analysis (TDA) offers a principled framework for capturing structural invariants such as connectivity and cycles that persist across scales, making it a natural fit for anomaly segmentation (AS). Unlike thresholdbased binarisation, which produces brittle masks under distribution shift, TDA allows anomalies to be characterised as disruptions to global structure rather than local fluctuations. We introduce TopoOT, a topology-aware optimal transport (OT) framework that integrates multi-filtration persistence diagrams (PDs) with test-time adaptation (TTA). Our key innovation is Optimal Transport Chaining, which sequentially aligns PDs across thresholds and filtrations, yielding geodesic stability scores that identify features consistently preserved across scales. These stabilityaware pseudo-labels supervise a lightweight head trained online with OT-consistency and contrastive objectives, ensuring robust adaptation under domain shift. Across standard 2D and 3D anomaly detection benchmarks, TopoOT achieves state-of-the-art performance, outperforming the most competitive methods by up to +24.1% mean F1 on 2D datasets and +10.2% on 3D AS benchmarks.", "AI": {"tldr": "提出了一种名为TopoOT的拓扑感知最优传输框架，用于异常分割，通过结合多重滤波持久性图和测试时自适应，实现了卓越的性能。它利用最优传输链条来对齐持久性图，并使用具有OT一致性和对比目标的轻量级头部进行在线训练，以提高在领域漂移下的鲁棒性。", "motivation": "现有的基于阈值的方法对分布变化敏感，而拓扑数据分析（TDA）能够捕捉跨尺度的结构不变性，使其成为异常分割的有力工具。作者旨在开发一种能够利用TDA的优势来提高异常分割鲁棒性的框架。", "method": "提出了一种名为TopoOT的框架，该框架结合了多重滤波持久性图（PDs）和测试时自适应（TTA）。其核心创新是“最优传输链条”（Optimal Transport Chaining），它能够按顺序对齐不同阈值和滤波下的PDs，从而生成“地理稳定分数”（geodesic stability scores）。这些分数用于生成伪标签，然后监督一个轻量级的头部网络，通过OT一致性和对比目标进行在线训练。", "result": "在2D和3D异常分割基准测试中，TopoOT取得了最先进的性能。在2D数据集上，其平均F1得分比现有方法高出24.1%，在3D异常分割基准测试上高出10.2%。", "conclusion": "TopoOT是一个新颖的拓扑感知最优传输框架，能够有效地整合多重滤波持久性图和测试时自适应，显著提高了异常分割的性能和鲁棒性，尤其是在面对领域漂移时。"}}
{"id": "2601.20026", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20026", "abs": "https://arxiv.org/abs/2601.20026", "authors": ["Pragatheeswaran Vipulanandan", "Kamal Premaratne", "Dilip Sarkar"], "title": "Semantic Uncertainty Quantification of Hallucinations in LLMs: A Quantum Tensor Network Based Method", "comment": null, "summary": "Large language models (LLMs) exhibit strong generative capabilities but remain vulnerable to confabulations, fluent yet unreliable outputs that vary arbitrarily even under identical prompts. Leveraging a quantum tensor network based pipeline, we propose a quantum physics inspired uncertainty quantification framework that accounts for aleatoric uncertainty in token sequence probability for semantic equivalence based clustering of LLM generations. This offers a principled and interpretable scheme for hallucination detection. We further introduce an entropy maximization strategy that prioritizes high certainty, semantically coherent outputs and highlights entropy regions where LLM decisions are likely to be unreliable, offering practical guidelines for when human oversight is warranted. We evaluate the robustness of our scheme under different generation lengths and quantization levels, dimensions overlooked in prior studies, demonstrating that our approach remains reliable even in resource constrained deployments. A total of 116 experiments on TriviaQA, NQ, SVAMP, and SQuAD across multiple architectures including Mistral-7B, Mistral-7B-instruct, Falcon-rw-1b, LLaMA-3.2-1b, LLaMA-2-13b-chat, LLaMA-2-7b-chat, LLaMA-2-13b, and LLaMA-2-7b show consistent improvements in AUROC and AURAC over state of the art baselines.", "AI": {"tldr": "本研究提出了一种受量子物理启发的、基于量子张量网络的框架，用于量化大型语言模型（LLM）生成中的不确定性，从而检测幻觉并优先生成高确定性、语义连贯的输出。", "motivation": "大型语言模型（LLM）虽然生成能力强大，但容易产生“语塞”（confabulations），即流畅但不准确且输出不确定的结果，即使在相同提示下也会出现。这促使研究人员寻找一种可靠的方法来量化这种不确定性并检测幻觉。", "method": "研究人员利用基于量子张量网络的流水线，构建了一个受量子物理启发的框架，用于量化LLM生成中标记序列的概率，以进行基于语义等价的聚类。此外，还引入了一种熵最大化策略，以优先选择高确定性、语义连贯的输出，并识别LLM决策可能不可靠的区域。", "result": "该框架在116项实验中，在TriviaQA、NQ、SVAMP和SQuAD等数据集上，针对多种LLM架构（包括Mistral-7B、LLaMA-2等），在AUROC和AURAC方面均显示出优于现有基线方法的性能。该方法在不同生成长度和量化水平下也表现出鲁棒性。", "conclusion": "提出的框架为LLM生成的不确定性量化和幻觉检测提供了一种原则性且可解释的方法。熵最大化策略能够有效地指导模型生成更可靠的输出，并为人工监督提供实用指导，尤其是在资源受限的环境下。"}}
{"id": "2601.20331", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20331", "abs": "https://arxiv.org/abs/2601.20331", "authors": ["Mai Su", "Qihan Yu", "Zhongtao Wang", "Yilong Li", "Chengwei Pan", "Yisong Chen", "Guoping Wang"], "title": "GVGS: Gaussian Visibility-Aware Multi-View Geometry for Accurate Surface Reconstruction", "comment": null, "summary": "3D Gaussian Splatting enables efficient optimization and high-quality rendering, yet accurate surface reconstruction remains challenging. Prior methods improve surface reconstruction by refining Gaussian depth estimates, either via multi-view geometric consistency or through monocular depth priors. However, multi-view constraints become unreliable under large geometric discrepancies, while monocular priors suffer from scale ambiguity and local inconsistency, ultimately leading to inaccurate Gaussian depth supervision. To address these limitations, we introduce a Gaussian visibility-aware multi-view geometric consistency constraint that aggregates the visibility of shared Gaussian primitives across views, enabling more accurate and stable geometric supervision. In addition, we propose a progressive quadtree-calibrated Monocular depth constraint that performs block-wise affine calibration from coarse to fine spatial scales, mitigating the scale ambiguity of depth priors while preserving fine-grained surface details. Extensive experiments on DTU and TNT datasets demonstrate consistent improvements in geometric accuracy over prior Gaussian-based and implicit surface reconstruction methods. Codes are available at an anonymous repository: https://github.com/GVGScode/GVGS.", "AI": {"tldr": "本文提出了一种新的3D高斯渲染表面重建方法，通过结合可见性感知的高斯点多视角几何一致性和渐进式四叉树校准的单目深度约束，提高了几何精度。", "motivation": "现有3D高斯渲染方法在表面重建方面存在挑战，主要是因为多视角几何一致性在视角差异大时不可靠，而单目深度先验存在尺度模糊和局部不一致问题，导致高斯深度监督不准确。", "method": "提出了两种新方法：1. 高斯可见性感知多视角几何一致性约束，通过聚合共享高斯原语的可见性来提供更准确稳定的几何监督。2. 渐进式四叉树校准的单目深度约束，通过从粗到细的空间尺度进行块状仿射校准，来缓解尺度模糊并保留细节。", "result": "在DTU和TNT数据集上的实验表明，与现有基于高斯和隐式表面重建的方法相比，该方法在几何精度上有了显著且一致的提升。", "conclusion": "本文提出的方法通过引入新的几何约束和深度约束，有效地解决了3D高斯渲染表面重建的准确性和稳定性问题，并在多个基准数据集上取得了优于现有方法的性能。"}}
{"id": "2601.20032", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20032", "abs": "https://arxiv.org/abs/2601.20032", "authors": ["Nishanth Sridhar Nakshatri", "Eylon Caplan", "Rajkumar Pujari", "Dan Goldwasser"], "title": "TAIGR: Towards Modeling Influencer Content on Social Media via Structured, Pragmatic Inference", "comment": null, "summary": "Health influencers play a growing role in shaping public beliefs, yet their content is often conveyed through conversational narratives and rhetorical strategies rather than explicit factual claims. As a result, claim-centric verification methods struggle to capture the pragmatic meaning of influencer discourse. In this paper, we propose TAIGR (Takeaway Argumentation Inference with Grounded References), a structured framework designed to analyze influencer discourse, which operates in three stages: (1) identifying the core influencer recommendation--takeaway; (2) constructing an argumentation graph that captures influencer justification for the takeaway; (3) performing factor graph-based probabilistic inference to validate the takeaway. We evaluate TAIGR on a content validation task over influencer video transcripts on health, showing that accurate validation requires modeling the discourse's pragmatic and argumentative structure rather than treating transcripts as flat collections of claims.", "AI": {"tldr": "本文提出了TAIGR框架，一种用于分析健康影响者话语的新方法，通过识别核心建议、构建论证图并进行概率推理来验证其内容，强调了话语的语用和论证结构的重要性。", "motivation": "现有的以声明为中心的验证方法难以捕捉健康影响者话语的实际含义，因为其内容常以叙述和修辞策略而非明确的事实声明形式传达。", "method": "TAIGR框架分三个阶段进行：1. 识别影响者的核心建议（takeaway）；2. 构建论证图，捕捉影响者对该建议的论证；3. 进行基于因子图的概率推理，以验证建议。", "result": "在对健康影响者视频文字记录的内容验证任务评估中，TAIGR表明准确验证需要对语用和论证结构进行建模，而不是将文字记录视为平面的声明集合。", "conclusion": "准确验证影响者话语的有效性需要理解其语用和论证结构，TAIGR框架提供了一种能够实现此目标的方法。"}}
{"id": "2601.20055", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20055", "abs": "https://arxiv.org/abs/2601.20055", "authors": ["Vikash Singh", "Darion Cassel", "Nathaniel Weir", "Nick Feng", "Sam Bayless"], "title": "VERGE: Formal Refinement and Guidance Engine for Verifiable LLM Reasoning", "comment": null, "summary": "Despite the syntactic fluency of Large Language Models (LLMs), ensuring their logical correctness in high-stakes domains remains a fundamental challenge. We present a neurosymbolic framework that combines LLMs with SMT solvers to produce verification-guided answers through iterative refinement. Our approach decomposes LLM outputs into atomic claims, autoformalizes them into first-order logic, and verifies their logical consistency using automated theorem proving. We introduce three key innovations: (1) multi-model consensus via formal semantic equivalence checking to ensure logic-level alignment between candidates, eliminating the syntactic bias of surface-form metrics, (2) semantic routing that directs different claim types to appropriate verification strategies: symbolic solvers for logical claims and LLM ensembles for commonsense reasoning, and (3) precise logical error localization via Minimal Correction Subsets (MCS), which pinpoint the exact subset of claims to revise, transforming binary failure signals into actionable feedback. Our framework classifies claims by their logical status and aggregates multiple verification signals into a unified score with variance-based penalty. The system iteratively refines answers using structured feedback until acceptance criteria are met or convergence is achieved. This hybrid approach delivers formal guarantees where possible and consensus verification elsewhere, advancing trustworthy AI. With the GPT-OSS-120B model, VERGE demonstrates an average performance uplift of 18.7% at convergence across a set of reasoning benchmarks compared to single-pass approaches.", "AI": {"tldr": "该研究提出了一种结合大型语言模型（LLM）和可满足性模理论（SMT）求解器的神经符号框架，通过迭代式改进来生成经过验证的答案，从而提高了LLM在逻辑正确性方面的性能。", "motivation": "当前LLM在语法流畅性方面表现出色，但在高风险领域保证其逻辑正确性仍然是一个基本挑战。", "method": "该框架将LLM的输出分解为原子声明，将其自动形式化为一阶逻辑，并使用自动定理证明器验证其逻辑一致性。关键创新包括：1) 通过形式语义等价性检查实现多模型共识，消除表面形式度量的语法偏差；2) 语义路由，将不同类型的声明路由到适当的验证策略（如符号求解器用于逻辑声明，LLM集成用于常识推理）；3) 通过最小修正子集（MCS）进行精确的逻辑错误定位。系统通过结构化反馈迭代地改进答案。", "result": "该框架将LLM的输出进行分类，并聚合多个验证信号到一个统一的分数。使用GPT-OSS-120B模型，VERGE在推理基准测试中的平均性能比单次运行方法提高了18.7%。", "conclusion": "该混合方法在可能的情况下提供形式保证，在其他地方进行共识验证，从而提高了可信AI的水平。"}}
{"id": "2601.20347", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20347", "abs": "https://arxiv.org/abs/2601.20347", "authors": ["Chengying She", "Chengwei Chen", "Xinran Zhang", "Ben Wang", "Lizhuang Liu", "Chengwei Shao", "Yun Bian"], "title": "MMSF: Multitask and Multimodal Supervised Framework for WSI Classification and Survival Analysis", "comment": "Submitted to \"Biomedical Signal Processing and Control\"", "summary": "Multimodal evidence is critical in computational pathology: gigapixel whole slide images capture tumor morphology, while patient-level clinical descriptors preserve complementary context for prognosis. Integrating such heterogeneous signals remains challenging because feature spaces exhibit distinct statistics and scales. We introduce MMSF, a multitask and multimodal supervised framework built on a linear-complexity MIL backbone that explicitly decomposes and fuses cross-modal information. MMSF comprises a graph feature extraction module embedding tissue topology at the patch level, a clinical data embedding module standardizing patient attributes, a feature fusion module aligning modality-shared and modality-specific representations, and a Mamba-based MIL encoder with multitask prediction heads. Experiments on CAMELYON16 and TCGA-NSCLC demonstrate 2.1--6.6\\% accuracy and 2.2--6.9\\% AUC improvements over competitive baselines, while evaluations on five TCGA survival cohorts yield 7.1--9.8\\% C-index improvements compared with unimodal methods and 5.6--7.1\\% over multimodal alternatives.", "AI": {"tldr": "该研究提出了一种名为MMSF的多任务多模态监督框架，用于整合计算病理学中的全切片图像和临床数据，以提高预后预测的准确性。该框架通过图特征提取、临床数据嵌入、特征融合和Mamba驱动的MIL编码器等模块，有效处理了不同模态数据的异质性，并在多个数据集上取得了显著的性能提升。", "motivation": "整合计算病理学中的全切片图像（描述肿瘤形态）和患者级临床信息（提供预后背景）至关重要，但由于特征空间统计和尺度的差异，这种异构信号的整合存在挑战。", "method": "研究提出MMSF框架，它是一个基于线性复杂度的MIL（Multiple Instance Learning）骨干的 multitask 和 multimodal 监督框架。具体包括：1. 图特征提取模块：嵌入病理切片的空间拓扑信息。2. 临床数据嵌入模块：标准化患者属性。3. 特征融合模块：对齐模态共享和模态特定的表示。4. 基于Mamba的MIL编码器：带有 multitask 预测头。", "result": "在CAMELYON16和TCGA-NSCLC数据集上，MMSF在准确率和AUC方面分别比基线方法提高了2.1%-6.6%和2.2%-6.9%。在五个TCGA生存队列的评估中，MMSF的C-index比单模态方法提高了7.1%-9.8%，比多模态替代方法提高了5.6%-7.1%。", "conclusion": "MMSF框架能够有效地分解和融合跨模态信息，显著提高了在全切片图像和临床数据联合分析下的预后预测性能，优于现有的单模态和多模态方法。"}}
{"id": "2601.20126", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20126", "abs": "https://arxiv.org/abs/2601.20126", "authors": ["Abha Jha", "Akanksha Mahajan", "Ashwath Vaithinathan Aravindan", "Praveen Saravanan", "Sai Sailaja Policharla", "Sonal Chaturbhuj Gehlot"], "title": "Rewarding Intellectual Humility Learning When Not To Answer In Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) often produce hallucinated or unverifiable content, undermining their reliability in factual domains. This work investigates Reinforcement Learning with Verifiable Rewards (RLVR) as a training paradigm that explicitly rewards abstention (\"I don't know\") alongside correctness to promote intellectual humility. We fine-tune and evaluate Granite-3.3-2B-Instruct and Qwen-3-4B-Instruct on the MedMCQA and Hendrycks Math benchmarks using a ternary reward structure ($-1$, r_abs, 1) under varying abstention reward structures. We further study the effect of combining RLVR with supervised fine-tuning strategies that teach abstention prior to reinforcement learning. Our results show that moderate abstention rewards (r_abs $\\approx -0.25$ to 0.3) consistently reduce incorrect responses without severe accuracy degradation on multiple-choice tasks, with larger models exhibiting greater robustness to abstention incentives. On open-ended question answering, we observe limitations due to insufficient exploration, which can be partially mitigated through supervised abstention training. Overall, these findings demonstrate the feasibility and flexibility of verifiable reward design as a practical approach for hallucination mitigation in language models. Reproducible code for our abstention training framework is available here https://github.com/Mystic-Slice/rl-abstention.", "AI": {"tldr": "该研究提出了一种名为“带可验证奖励的强化学习”（RLVR）的训练范式，通过奖励模型在不确定时选择“不知道”（弃权），来减少大型语言模型（LLMs）产生幻觉或不可靠内容的现象。", "motivation": "大型语言模型（LLMs）经常产生幻觉或不可靠的内容，这影响了它们在事实性领域的可靠性。因此，需要一种方法来提高LLMs的可靠性。", "method": "研究人员将RLVR应用于Granite-3.3-2B-Instruct和Qwen-3-4B-Instruct模型，在MedMCQA和Hendrycks Math基准上进行微调和评估。他们使用了包含正确（1）、错误（-1）和弃权（r_abs）的三元奖励结构，并研究了不同弃权奖励值的影响。此外，他们还结合了监督微调策略，在进行强化学习之前先教授模型弃权。", "result": "结果表明，适度的弃权奖励（r_abs 约 -0.25 至 0.3）可以有效减少多项选择题中的错误回答，同时准确率下降不明显。更大的模型对弃权奖励的激励表现出更强的鲁棒性。在开放式问答任务中，模型由于探索不足存在局限性，但可以通过监督弃权训练在一定程度上缓解。", "conclusion": "研究证明了可验证奖励设计作为一种实用的方法，可以有效减少语言模型的幻觉。RLVR具有可行性和灵活性，并且代码是公开可用的。"}}
{"id": "2601.20351", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20351", "abs": "https://arxiv.org/abs/2601.20351", "authors": ["Chenke Zhang", "Ziyuan Yang", "Licheng Yan", "Shuyi Li", "Andrew Beng Jin Teoh", "Bob Zhang", "Yi Zhang"], "title": "PalmBridge: A Plug-and-Play Feature Alignment Framework for Open-Set Palmprint Verification", "comment": null, "summary": "Palmprint recognition is widely used in biometric systems, yet real-world performance often degrades due to feature distribution shifts caused by heterogeneous deployment conditions. Most deep palmprint models assume a closed and stationary distribution, leading to overfitting to dataset-specific textures rather than learning domain-invariant representations. Although data augmentation is commonly used to mitigate this issue, it assumes augmented samples can approximate the target deployment distribution, an assumption that often fails under significant domain mismatch. To address this limitation, we propose PalmBridge, a plug-and-play feature-space alignment framework for open-set palmprint verification based on vector quantization. Rather than relying solely on data-level augmentation, PalmBridge learns a compact set of representative vectors directly from training features. During enrollment and verification, each feature vector is mapped to its nearest representative vector under a minimum-distance criterion, and the mapped vector is then blended with the original vector. This design suppresses nuisance variation induced by domain shifts while retaining discriminative identity cues. The representative vectors are jointly optimized with the backbone network using task supervision, a feature-consistency objective, and an orthogonality regularization term to form a stable and well-structured shared embedding space. Furthermore, we analyze feature-to-representative mappings via assignment consistency and collision rate to assess model's sensitivity to blending weights. Experiments on multiple palmprint datasets and backbone architectures show that PalmBridge consistently reduces EER in intra-dataset open-set evaluation and improves cross-dataset generalization with negligible to modest runtime overhead.", "AI": {"tldr": "本文提出了PalmBridge，一个用于开放集掌纹验证的即插即用特征空间对齐框架，通过向量量化学习代表性向量来抑制域偏移引起的干扰变化，同时保留身份信息，有效提高了模型的泛化能力。", "motivation": "现有深度掌纹模型在异构部署条件下，由于特征分布偏移，性能会下降。现有数据增强方法在领域失配严重时效果不佳。", "method": "提出PalmBridge框架，利用向量量化学习一组代表性向量。在注册和验证时，将每个特征向量映射到最近的代表性向量，并将其与原始向量混合。代表性向量与骨干网络一起进行联合优化，包括任务监督、特征一致性目标和正交正则化项。", "result": "PalmBridge在多个掌纹数据集和骨干网络上持续降低了类内开放集评估中的EER，并提高了跨数据集的泛化能力，运行时开销可忽略或适中。", "conclusion": "PalmBridge通过特征空间对齐有效地解决了掌纹识别中的域偏移问题，在保持身份辨别力的同时，提高了模型的鲁棒性和泛化能力。"}}
{"id": "2601.20129", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20129", "abs": "https://arxiv.org/abs/2601.20129", "authors": ["Akif Islam", "Sujan Kumar Roy", "Md. Ekramul Hamid"], "title": "BengaliSent140: A Large-Scale Bengali Binary Sentiment Dataset for Hate and Non-Hate Speech Classification", "comment": "Dataset paper. 6 pages, 3 figures. 4 Tables, Includes a publicly released Bengali sentiment dataset on Kaggle (BengaliSent140) and baseline experimental results", "summary": "Sentiment analysis for the Bengali language has attracted increasing research interest in recent years. However, progress remains constrained by the scarcity of large-scale and diverse annotated datasets. Although several Bengali sentiment and hate speech datasets are publicly available, most are limited in size or confined to a single domain, such as social media comments. Consequently, these resources are often insufficient for training modern deep learning based models, which require large volumes of heterogeneous data to learn robust and generalizable representations. In this work, we introduce BengaliSent140, a large-scale Bengali binary sentiment dataset constructed by consolidating seven existing Bengali text datasets into a unified corpus. To ensure consistency across sources, heterogeneous annotation schemes are systematically harmonized into a binary sentiment formulation with two classes: Not Hate (0) and Hate (1). The resulting dataset comprises 139,792 unique text samples, including 68,548 hate and 71,244 not-hate instances, yielding a relatively balanced class distribution. By integrating data from multiple sources and domains, BengaliSent140 offers broader linguistic and contextual coverage than existing Bengali sentiment datasets and provides a strong foundation for training and benchmarking deep learning models. Baseline experimental results are also reported to demonstrate the practical usability of the dataset. The dataset is publicly available at https://www.kaggle.com/datasets/akifislam/bengalisent140/", "AI": {"tldr": "该论文发布了一个名为 BengaliSent140 的大规模孟加拉语二元情感数据集，通过整合七个现有数据集构建而成，包含近 14 万条样本，旨在解决现有数据集规模小、领域单一的问题，为训练和评估深度学习模型提供支持。", "motivation": "现有孟加拉语情感分析研究受限于大规模、多样化标注数据集的缺乏，现有数据集规模小或仅限于单一领域（如社交媒体评论），不足以训练现代深度学习模型。", "method": "通过整合七个现有的孟加拉语文本数据集，将异构的标注方案统一为二元情感分类（非仇恨/仇恨），构建了一个包含 139,792 条独特文本样本的大规模数据集 BengaliSent140。", "result": "BengaliSent140 数据集包含 68,548 条仇恨样本和 71,244 条非仇恨样本，类分布相对平衡。通过整合多源多领域数据，该数据集提供了比现有数据集更广泛的语言和语境覆盖。", "conclusion": "BengaliSent140 数据集为训练和基准测试深度学习模型提供了坚实的基础，并报告了基线实验结果以证明其可用性。该数据集已公开可用。"}}
{"id": "2601.20253", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20253", "abs": "https://arxiv.org/abs/2601.20253", "authors": ["Si Chen", "Le Huy Khiem", "Annalisa Szymanski", "Ronald Metoyer", "Ting Hua", "Nitesh V. Chawla"], "title": "Automated Benchmark Generation from Domain Guidelines Informed by Bloom's Taxonomy", "comment": null, "summary": "Open-ended question answering (QA) evaluates a model's ability to perform contextualized reasoning beyond factual recall. This challenge is especially acute in practice-based domains, where knowledge is procedural and grounded in professional judgment, while most existing LLM benchmarks depend on pre-existing human exam datasets that are often unavailable in such settings. We introduce a framework for automated benchmark generation from expert-authored guidelines informed by Bloom's Taxonomy. It converts expert practices into implicit violation-based scenarios and expands them into auto-graded multiple-choice questions (MCQs) and multi-turn dialogues across four cognitive levels, enabling deterministic, reproducible, and scalable evaluation. Applied to three applied domains: teaching, dietetics, and caregiving, we find differences between model and human-like reasoning: LLMs sometimes perform relatively better on higher-order reasoning (Analyze) but fail more frequently on lower-level items (Remember). We produce large-scale, psychometrically informed benchmarks that surface these non-intuitive model behaviors and enable evaluation of contextualized reasoning in real-world settings.", "AI": {"tldr": "本研究提出了一种自动生成基于专家指南和布鲁姆分类法的开放式问答基准测试框架，该框架可用于评估大型语言模型（LLM）在实践领域的推理能力，并发现LLM在较高认知层级（分析）上表现优于较低层级（记忆）。", "motivation": "现有的大型语言模型（LLM）基准测试主要依赖于预先存在的人类考试数据集，而这些数据集在实践领域（如教学、营养学、护理）中通常不可用。这些领域缺乏程序性知识和基于专业判断的知识，因此需要一种新的评估方法。", "method": "研究人员开发了一个框架，该框架将专家撰写的指南转化为隐式违反性场景，并将其扩展为自动评分的多项选择题（MCQ）和多轮对话。这些问题覆盖了布鲁姆分类法中的四个认知层级（记忆、理解、应用、分析），从而实现了确定性、可复现性和可扩展的评估。", "result": "将该框架应用于教学、营养学和护理三个领域后，发现LLM在较高认知层级（分析）上的表现有时优于人类，但在较低层级（记忆）上却更容易出错。研究生成了大规模、心理测量学指导的基准测试，揭示了这些非直观的模型行为。", "conclusion": "本研究提出了一种创新的方法来生成实践领域中LLM的开放式问答基准测试。该方法不仅能克服现有基准测试的局限性，还能深入揭示LLM在不同认知层级上的推理能力和潜在的弱点，从而为评估和改进LLM在现实世界中的应用奠定基础。"}}
{"id": "2601.20105", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20105", "abs": "https://arxiv.org/abs/2601.20105", "authors": ["Faezeh Hosseini", "Mohammadali Yousefzadeh", "Yadollah Yaghoobzadeh"], "title": "FFE-Hallu:Hallucinations in Fixed Figurative Expressions:Benchmark of Idioms and Proverbs in the Persian Language", "comment": "EACL 2026", "summary": "Figurative language, particularly fixed figurative expressions (FFEs) such as idioms and proverbs, poses persistent challenges for large language models (LLMs). Unlike literal phrases, FFEs are culturally grounded, largely non-compositional, and conventionally fixed, making them especially vulnerable to figurative hallucination. We define figurative hallucination as the generation or endorsement of expressions that sound idiomatic and plausible but do not exist as authentic figurative expressions in the target language. We introduce FFEHallu, the first comprehensive benchmark for evaluating figurative hallucination in LLMs, with a focus on Persian, a linguistically rich yet underrepresented language. FFEHallu consists of 600 carefully curated instances spanning three complementary tasks: (i) FFE generation from meaning, (ii) detection of fabricated FFEs across four controlled construction categories, and (iii) FFE to FFE translation from English to Persian. Evaluating six state of the art multilingual LLMs, we find systematic weaknesses in figurative competence and cultural grounding. While models such as GPT4.1 demonstrate relatively strong performance in rejecting fabricated FFEs and retrieving authentic ones, most models struggle to reliably distinguish real expressions from high quality fabrications and frequently hallucinate during cross lingual translation. These findings reveal substantial gaps in current LLMs handling of figurative language and underscore the need for targeted benchmarks to assess and mitigate figurative hallucination.", "AI": {"tldr": "本研究提出了 FFEHallu，一个针对波斯语的固定比喻语（FFE）幻觉评估基准。研究发现，现有的大型语言模型（LLMs）在处理比喻语方面存在系统性弱点，尤其是在区分真实与虚构的FFE以及跨语言翻译方面。", "motivation": "固定比喻语（FFEs）因其非组合性、文化特定性和固定性，对大型语言模型（LLMs）的理解和生成构成了挑战，容易产生比喻幻觉（即生成不存在的、听起来像FFE的表达）。现有研究缺乏针对性的评估工具。", "method": "1. 构建了 FFEHallu 基准，包含 600 个精心策划的实例，涵盖三个任务：从意义生成 FFE、检测四种类别的人工制造的 FFE、以及英译波斯语的 FFE 翻译。 2. 评估了六个先进的多语言 LLMs 在 FFEHallu 基准上的表现。", "result": "1. 大多数 LLMs 在区分真实 FFE 和高质量的虚构 FFE 方面存在困难。2. LLMs 在跨语言翻译过程中经常产生比喻幻觉。3. GPT4.1 在拒绝虚构 FFE 和检索真实 FFE 方面表现相对较好，但仍存在不足。4. 总体而言，模型在比喻能力和文化基础方面存在系统性弱点。", "conclusion": "现有 LLMs 在处理比喻语言方面存在显著差距，尤其是在比喻幻觉方面。需要开发更具针对性的基准来评估和减轻 LLMs 的比喻幻觉问题。"}}
{"id": "2601.20102", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20102", "abs": "https://arxiv.org/abs/2601.20102", "authors": ["Amirhossein Haji Mohammad Rezaei", "Zahra Shakeri"], "title": "Counterfactual Cultural Cues Reduce Medical QA Accuracy in LLMs: Identifier vs Context Effects", "comment": null, "summary": "Engineering sustainable and equitable healthcare requires medical language models that do not change clinically correct diagnoses when presented with non-decisive cultural information. We introduce a counterfactual benchmark that expands 150 MedQA test items into 1650 variants by inserting culture-related (i) identifier tokens, (ii) contextual cues, or (iii) their combination for three groups (Indigenous Canadian, Middle-Eastern Muslim, Southeast Asian), plus a length-matched neutral control, where a clinician verified that the gold answer remains invariant in all variants. We evaluate GPT-5.2, Llama-3.1-8B, DeepSeek-R1, and MedGemma (4B/27B) under option-only and brief-explanation prompting. Across models, cultural cues significantly affect accuracy (Cochran's Q, $p<10^-14$), with the largest degradation when identifier and context co-occur (up to 3-7 percentage points under option-only prompting), while neutral edits produce smaller, non-systematic changes. A human-validated rubric ($κ=0.76$) applied via an LLM-as-judge shows that more than half of culturally grounded explanations end in an incorrect answer, linking culture-referential reasoning to diagnostic failure. We release prompts and augmentations to support evaluation and mitigation of culturally induced diagnostic errors.", "AI": {"tldr": "研究发现，当医疗语言模型接触到与文化相关的信息时，其在医学诊断上的准确性会显著下降，尤其是在标识符和上下文信息同时出现时。引入的文化敏感性基准测试揭示了这一点，并且模型生成的解释性回答中，有一半以上最终导致了错误的诊断。", "motivation": "为了工程化可持续且公平的医疗保健系统，需要开发不因非决定性文化信息而改变临床正确诊断的医疗语言模型。", "method": "构建了一个包含150个MedQA测试题的扩充基准，生成了1650个变体，通过插入与三种文化群体（加拿大原住民、中东穆斯林、东南亚）相关的标识符、上下文线索或两者的组合，并包含一个长度匹配的中性对照组。由临床医生验证了在所有变体中答案的正确性。在选项提示和简短解释提示下，评估了GPT-5.2、Llama-3.1-8B、DeepSeek-R1和MedGemma（4B/27B）模型的性能。使用LLM作为法官，通过人工验证的评分标准（κ=0.76）评估解释的质量。", "result": "跨模型来看，文化线索显著影响了模型的准确性（Cochran's Q, $p<10^-14$）。当标识符和上下文同时出现时，准确性下降幅度最大（选项提示下高达3-7个百分点），而中性编辑则产生较小且非系统性的变化。LLM作为法官的评估表明，超过一半的文化背景解释最终导致了错误的答案。", "conclusion": "文化信息会显著干扰医疗语言模型做出正确的临床诊断，尤其是在标识符和上下文信息结合时。文化相关的推理与诊断失败相关。研究发布了提示和数据以支持对文化诱导的诊断错误的评估和缓解。"}}
{"id": "2601.20142", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.20142", "abs": "https://arxiv.org/abs/2601.20142", "authors": ["Zilai Wang", "Natarajan Balaji Shankar", "Kaiyuan Zhang", "Zihan Wang", "Abeer Alwan"], "title": "Mind the Shift: Using Delta SSL Embeddings to Enhance Child ASR", "comment": "ICASSP 2026", "summary": "Self-supervised learning (SSL) models have achieved impressive results across many speech tasks, yet child automatic speech recognition (ASR) remains challenging due to limited data and pretraining domain mismatch. Fine-tuning SSL models on child speech induces shifts in the representation space. We hypothesize that delta SSL embeddings, defined as the differences between embeddings from a finetuned model and those from its pretrained counterpart, encode task-specific information that complements finetuned features from another SSL model. We evaluate multiple fusion strategies on the MyST childrens corpus using different models. Results show that delta embedding fusion with WavLM yields up to a 10 percent relative WER reduction for HuBERT and a 4.4 percent reduction for W2V2, compared to finetuned embedding fusion. Notably, fusing WavLM with delta W2V2 embeddings achieves a WER of 9.64, setting a new state of the art among SSL models on the MyST corpus. These findings demonstrate the effectiveness of delta embeddings and highlight feature fusion as a promising direction for advancing child ASR.", "AI": {"tldr": "该研究提出了一种新的自监督学习（SSL）嵌入方法——delta SSL embeddings，用于改进儿童语音识别（ASR）。通过融合预训练和微调模型的嵌入差异，显著降低了儿童语音识别的词错误率（WER），并取得了新的最先进性能。", "motivation": "儿童语音识别（ASR）由于数据量有限和预训练领域不匹配，面临巨大挑战。现有的SSL模型在儿童语音上微调时，表示空间会发生变化。", "method": "提出delta SSL embeddings，即微调模型与预训练模型之间的嵌入差异。采用多种融合策略，将delta SSL embeddings与另一SSL模型微调后的特征进行融合，并在MyST儿童语音语料库上进行评估。", "result": "delta embedding融合策略在HuBERT和W2V2模型上均优于微调embedding融合。特别是，WavLM与delta W2V2 embeddings融合，在MyST语料库上实现了9.64%的WER，创下了SSL模型在该数据集上的新最优记录。", "conclusion": "delta SSL embeddings能有效捕捉任务特定的互补信息，证明了其在儿童ASR任务中的有效性。特征融合是一种有前景的儿童ASR研究方向。"}}
{"id": "2601.20355", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20355", "abs": "https://arxiv.org/abs/2601.20355", "authors": ["Yue Liang", "Jiatong Du", "Ziyi Yang", "Yanjun Huang", "Hong Chen"], "title": "CURVE: Learning Causality-Inspired Invariant Representations for Robust Scene Understanding via Uncertainty-Guided Regularization", "comment": null, "summary": "Scene graphs provide structured abstractions for scene understanding, yet they often overfit to spurious correlations, severely hindering out-of-distribution generalization. To address this limitation, we propose CURVE, a causality-inspired framework that integrates variational uncertainty modeling with uncertainty-guided structural regularization to suppress high-variance, environment-specific relations. Specifically, we apply prototype-conditioned debiasing to disentangle invariant interaction dynamics from environment-dependent variations, promoting a sparse and domain-stable topology. Empirically, we evaluate CURVE in zero-shot transfer and low-data sim-to-real adaptation, verifying its ability to learn domain-stable sparse topologies and provide reliable uncertainty estimates to support risk prediction under distribution shifts.", "AI": {"tldr": "本文提出了一种名为CURVE的因果推理框架，通过整合变分不确定性建模和不确定性引导的结构正则化，以解决场景图在分布外泛化时过度拟合虚假相关性的问题，从而学习稀疏且域稳定的拓扑结构。", "motivation": "现有的场景图在理解场景方面存在局限性，容易过度拟合虚假相关性，这严重阻碍了其在不同分布下的泛化能力。", "method": "CURVE框架整合了变分不确定性建模和不确定性引导的结构正则化。它利用原型条件去偏（prototype-conditioned debiasing）来解耦不变的交互动力学与环境相关的变化，从而促进稀疏且域稳定的拓扑。", "result": "在零样本迁移和低数据量模拟到真实（sim-to-real）适应的实验中，CURVE被证明能够学习到域稳定的稀疏拓扑，并提供可靠的不确定性估计，以支持在分布偏移情况下的风险预测。", "conclusion": "CURVE框架通过因果推理的方法，有效地提升了场景图在分布外泛化和适应性任务中的表现，能够学习到更鲁棒的场景表示。"}}
{"id": "2601.20354", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20354", "abs": "https://arxiv.org/abs/2601.20354", "authors": ["Zengbin Wang", "Xuecai Hu", "Yong Wang", "Feng Xiong", "Man Zhang", "Xiangxiang Chu"], "title": "Everything in Its Place: Benchmarking Spatial Intelligence of Text-to-Image Models", "comment": "Accepted by ICLR 2026", "summary": "Text-to-image (T2I) models have achieved remarkable success in generating high-fidelity images, but they often fail in handling complex spatial relationships, e.g., spatial perception, reasoning, or interaction. These critical aspects are largely overlooked by current benchmarks due to their short or information-sparse prompt design. In this paper, we introduce SpatialGenEval, a new benchmark designed to systematically evaluate the spatial intelligence of T2I models, covering two key aspects: (1) SpatialGenEval involves 1,230 long, information-dense prompts across 25 real-world scenes. Each prompt integrates 10 spatial sub-domains and corresponding 10 multi-choice question-answer pairs, ranging from object position and layout to occlusion and causality. Our extensive evaluation of 21 state-of-the-art models reveals that higher-order spatial reasoning remains a primary bottleneck. (2) To demonstrate that the utility of our information-dense design goes beyond simple evaluation, we also construct the SpatialT2I dataset. It contains 15,400 text-image pairs with rewritten prompts to ensure image consistency while preserving information density. Fine-tuned results on current foundation models (i.e., Stable Diffusion-XL, Uniworld-V1, OmniGen2) yield consistent performance gains (+4.2%, +5.7%, +4.4%) and more realistic effects in spatial relations, highlighting a data-centric paradigm to achieve spatial intelligence in T2I models.", "AI": {"tldr": "本文提出了SpatialGenEval基准来评估文本到图像（T2I）模型在处理复杂空间关系方面的能力，并创建了SpatialT2I数据集来改进T2I模型的空间智能。SpatialGenEval包含1230个信息密集型长提示，覆盖25个真实场景，每个提示集成10个空间子领域和问答对。在21个SOTA模型上的评估表明，高级空间推理仍是瓶颈。SpatialT2I数据集包含15400个文本-图像对，通过重写提示来保持信息密度和图像一致性。在现有基础模型上进行微调，空间关系生成能力得到显著提升。", "motivation": "现有的文本到图像（T2I）模型在生成高保真图像方面表现出色，但在处理复杂的空间关系（如空间感知、推理或交互）方面存在不足。现有的基准测试由于提示简短或信息稀疏，未能充分评估T2I模型在这些方面的能力。", "method": "1. 构建SpatialGenEval基准：包含1230个长且信息密集的提示，覆盖25个真实场景，每个提示集成10个空间子领域和对应的10个多项选择问答对，以评估T2I模型在空间关系上的智能。 2. 构建SpatialT2I数据集：包含15400个文本-图像对，重写提示以确保图像一致性同时保留信息密度。 3. 模型评估与微调：在SpatialGenEval上评估21个T2I模型；在SpatialT2I数据集上微调Stable Diffusion-XL、Uniworld-V1、OmniGen2等基础模型。", "result": "在SpatialGenEval基准上，对21个T2I模型的评估显示，高级空间推理仍然是主要瓶颈。通过在SpatialT2I数据集上微调，Stable Diffusion-XL、Uniworld-V1和OmniGen2模型的空间关系生成性能分别提高了4.2%、5.7%和4.4%，并展现出更逼真的空间关系效果。", "conclusion": "SpatialGenEval基准能够系统地评估T2I模型在空间关系处理方面的能力，并揭示了当前模型的局限性。通过构建信息密集型提示的数据集SpatialT2I并进行微调，可以有效提升T2I模型在生成准确和逼真的空间关系方面的能力，表明数据驱动的方法是实现T2I模型空间智能的关键途径。"}}
{"id": "2601.20364", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20364", "abs": "https://arxiv.org/abs/2601.20364", "authors": ["Zhen Liu", "Diedong Feng", "Hai Jiang", "Liaoyuan Zeng", "Hao Wang", "Chaoyu Feng", "Lei Lei", "Bing Zeng", "Shuaicheng Liu"], "title": "RAW-Flow: Advancing RGB-to-RAW Image Reconstruction with Deterministic Latent Flow Matching", "comment": "AAAI2026 Oral", "summary": "RGB-to-RAW reconstruction, or the reverse modeling of a camera Image Signal Processing (ISP) pipeline, aims to recover high-fidelity RAW data from RGB images. Despite notable progress, existing learning-based methods typically treat this task as a direct regression objective and struggle with detail inconsistency and color deviation, due to the ill-posed nature of inverse ISP and the inherent information loss in quantized RGB images. To address these limitations, we pioneer a generative perspective by reformulating RGB-to-RAW reconstruction as a deterministic latent transport problem and introduce a novel framework named RAW-Flow, which leverages flow matching to learn a deterministic vector field in latent space, to effectively bridge the gap between RGB and RAW representations and enable accurate reconstruction of structural details and color information. To further enhance latent transport, we introduce a cross-scale context guidance module that injects hierarchical RGB features into the flow estimation process. Moreover, we design a dual-domain latent autoencoder with a feature alignment constraint to support the proposed latent transport framework, which jointly encodes RGB and RAW inputs while promoting stable training and high-fidelity reconstruction. Extensive experiments demonstrate that RAW-Flow outperforms state-of-the-art approaches both quantitatively and visually.", "AI": {"tldr": "提出了一种名为RAW-Flow的新型框架，通过将RGB到RAW重建视为一个确定性的潜在传输问题，并结合流匹配和跨尺度上下文引导，以解决现有方法在细节不一致和颜色偏差问题上的不足，从而实现高保真度的RAW数据重建。", "motivation": "现有基于学习的RGB到RAW重建方法通常直接回归，但由于逆ISP问题的病态性和量化RGB图像的信息损失，导致细节不一致和颜色偏差。", "method": "将RGB到RAW重建重构为一个确定性的潜在传输问题，利用流匹配学习潜在空间中的确定性向量场，并引入跨尺度上下文引导模块注入分层RGB特征，以及设计了一个具有特征对齐约束的双域潜在自编码器。", "result": "RAW-Flow在定量和视觉评估上均优于现有最先进的方法。", "conclusion": "RAW-Flow通过引入生成式视角和创新的潜在传输机制，成功解决了RGB到RAW重建中的挑战，实现了更准确的结构细节和颜色信息恢复。"}}
{"id": "2601.20276", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20276", "abs": "https://arxiv.org/abs/2601.20276", "authors": ["Tianwei Lin", "Zuyi Zhou", "Xinda Zhao", "Chenke Wang", "Xiaohong Li", "Yu Chen", "Chuanrui Hu", "Jian Pei", "Yafeng Deng"], "title": "Beyond the Needle's Illusion: Decoupled Evaluation of Evidence Access and Use under Semantic Interference at 326M-Token Scale", "comment": null, "summary": "Long-context LLM agents must access the right evidence from large environments and use it faithfully. However, the popular Needle-in-a-Haystack (NIAH) evaluation mostly measures benign span localization. The needle is near-unique, and the haystack is largely irrelevant. We introduce EverMemBench-S (EMB-S), an adversarial NIAH-style benchmark built on a 326M-token MemoryBank. While the full MemoryBank spans 326M tokens for retrieval-based (RAG) evaluation, we evaluate native long-context models only at scales that fit within each model's context window (up to 1M tokens in this work) to ensure a fair comparison. EMB-S pairs queries with collision-tested near-miss hard negatives and gold evidence sets spanning one or more documents, validated via human screening and LLM verification. We also propose a decoupled diagnostic protocol that reports evidence access (document-ID localization) separately from end-to-end QA quality under full-context prompting. This enables consistent diagnosis for both native long-context prompting and retrieval pipelines. Across a reference-corpus ladder from domain-isolated 64K contexts to a globally shared 326M-token environment, we observe a clear reality gap. Systems that saturate benign NIAH degrade sharply in evidence access under semantic interference. These results indicate that semantic discrimination, not context length alone, is the dominant bottleneck for long-context memory at scale.", "AI": {"tldr": "研究人员提出了一个新的基准测试 EverMemBench-S (EMB-S)，用于评估长上下文 LLM 代理在大型环境中检索和利用证据的能力。EMB-S 引入了更具挑战性的“干扰型”检索场景，并提出了一个解耦的诊断协议，单独评估证据访问和问答质量。实验结果表明，目前的系统在面对语义干扰时，证据访问能力会急剧下降，表明语义分辨能力是长上下文记忆的关键瓶颈。", "motivation": "现有的 Needle-in-a-Haystack (NIAH) 评估方法主要关注于简单的证据定位，无法充分反映长上下文 LLM 代理在复杂、大规模环境中精确检索和忠实使用证据的能力。研究动机是开发一个更具挑战性的基准，以更真实地评估 LLM 代理在真实世界场景下的长上下文记忆和检索能力。", "method": "1. 提出了 EverMemBench-S (EMB-S)，一个基于 3.26 亿 token MemoryBank 的对抗性 NIAH 风格基准测试。\n2. EMB-S 包含精心设计的、经过碰撞测试的“近乎错误”的负样本和包含一个或多个文档的黄金证据集。\n3. 引入了一个解耦的诊断协议，将证据访问（文档 ID 定位）与完整的上下文提示下的端到端问答质量分开评估。\n4. 使用了从领域隔离的 64K 上下文到全局共享的 3.26 亿 token 环境的参考语料库梯队进行评估。", "result": "在面对语义干扰时，能够完美通过标准 NIAH 测试的系统，其证据访问能力会急剧下降。\n在跨不同规模的语料库测试中，发现了明显的“现实差距”（reality gap）。\n研究结果表明，语义分辨能力，而非单纯的上下文长度，是长上下文记忆在大规模环境下的主要瓶颈。", "conclusion": "当前的 LLM 代理在处理大规模、语义复杂的环境时，其长上下文记忆和证据访问能力存在显著不足。语义分辨能力是限制长上下文模型性能的关键因素，简单的长上下文窗口并不能保证在真实世界的应用中表现出色。"}}
{"id": "2601.20144", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20144", "abs": "https://arxiv.org/abs/2601.20144", "authors": ["Ziyi Wang", "Yuxuan Lu", "Yimeng Zhang", "Jing Huang", "Jiri Gesi", "Xianfeng Tang", "Chen Luo", "Yisi Sang", "Hanqing Lu", "Manling Li", "Dakuo Wang"], "title": "Trajectory2Task: Training Robust Tool-Calling Agents with Synthesized Yet Verifiable Data for Complex User Intents", "comment": null, "summary": "Tool-calling agents are increasingly deployed in real-world customer-facing workflows. Yet most studies on tool-calling agents focus on idealized settings with general, fixed, and well-specified tasks. In real-world applications, user requests are often (1) ambiguous, (2) changing over time, or (3) infeasible due to policy constraints, and training and evaluation data that cover these diverse, complex interaction patterns remain under-represented. To bridge the gap, we present Trajectory2Task, a verifiable data generation pipeline for studying tool use at scale under three realistic user scenarios: ambiguous intent, changing intent, and infeasible intents. The pipeline first conducts multi-turn exploration to produce valid tool-call trajectories. It then converts these trajectories into user-facing tasks with controlled intent adaptations. This process yields verifiable task that support closed-loop evaluation and training. We benchmark seven state-of-the-art LLMs on the generated complex user scenario tasks and observe frequent failures. Finally, using successful trajectories obtained from task rollouts, we fine-tune lightweight LLMs and find consistent improvements across all three conditions, along with better generalization to unseen tool-use domains, indicating stronger general tool-calling ability.", "AI": {"tldr": "本研究提出了一个名为 Trajectory2Task 的数据生成流水线，用于在现实世界场景（如意图模糊、意图变更、意图不可行）下研究工具调用代理，并对七个顶尖 LLM 进行了基准测试，发现其表现不佳；随后，通过微调轻量级 LLM 进行了改进，并在工具调用能力上取得了泛化性提升。", "motivation": "现有关于工具调用代理的研究多集中在理想化场景，而现实世界中的用户请求往往更复杂（模糊、变化、不可行），现有训练和评估数据对此类情况覆盖不足，因此需要新的数据集和方法来解决这一差距。", "method": "研究者提出了 Trajectory2Task 数据生成流水线，该流水线通过多轮探索生成有效的工具调用轨迹，然后将这些轨迹转化为具有可控意图适应性的用户任务，从而生成可验证的任务以支持闭环评估和训练。接着，使用生成的数据对七个 LLM 进行了基准测试，并使用成功的工具调用轨迹对轻量级 LLM 进行了微调。", "result": "七个顶尖 LLM 在 Trajectory2Task 生成的复杂用户场景任务上表现频繁失败。通过使用成功的轨迹对轻量级 LLM 进行微调，发现在三种模拟的现实用户场景（意图模糊、意图变更、意图不可行）下均取得了持续的性能提升，并对未见过的工具使用领域展现出更好的泛化能力。", "conclusion": "现实世界中的工具调用任务比理想化场景更具挑战性，现有顶尖 LLM 在处理复杂用户意图方面存在不足。通过 Trajectory2Task 流水线生成的数据进行微调，可以显著提升轻量级 LLM 的工具调用能力，并增强其泛化性。"}}
{"id": "2601.20366", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20366", "abs": "https://arxiv.org/abs/2601.20366", "authors": ["Abdul Hasib", "A. S. M. Ahsanul Sarkar Akib", "Nihal Das Ankur", "Anish Giri"], "title": "Dual-Modality IoT Framework for Integrated Access Control and Environmental Safety Monitoring with Real-Time Cloud Analytics", "comment": null, "summary": "The integration of physical security systems with environmental safety monitoring represents a critical advancement in smart infrastructure management. Traditional approaches maintain these systems as independent silos, creating operational inefficiencies, delayed emergency responses, and increased management complexity. This paper presents a comprehensive dual-modality Internet of Things framework that seamlessly integrates RFID-based access control with multi-sensor environmental safety monitoring through a unified cloud architecture. The system comprises two coordinated subsystems: Subsystem 1 implements RFID authentication with servo-actuated gate control and real-time Google Sheets logging, while Subsystem 2 provides comprehensive safety monitoring incorporating flame detection, water flow measurement, LCD status display, and personnel identification. Both subsystems utilize ESP32 microcontrollers for edge processing and wireless connectivity. Experimental evaluation over 45 days demonstrates exceptional performance metrics: 99.2\\% RFID authentication accuracy with 0.82-second average response time, 98.5\\% flame detection reliability within 5-meter range, and 99.8\\% cloud data logging success rate. The system maintains operational integrity during network disruptions through intelligent local caching mechanisms and achieves total implementation cost of 5,400 BDT (approximately \\$48), representing an 82\\% reduction compared to commercial integrated solutions. This research establishes a practical framework for synergistic security-safety integration, demonstrating that professional-grade performance can be achieved through careful architectural design and component optimization while maintaining exceptional cost-effectiveness and accessibility for diverse application scenarios.", "AI": {"tldr": "本文提出了一种集成了RFID门禁和多传感器环境安全监测的双模物联网框架，通过统一的云架构实现无缝集成，并在实验中展示了高准确率、低延迟、高可靠性和成本效益。", "motivation": "传统物理安全与环境安全监测系统独立运行，导致效率低下、应急响应延迟和管理复杂。需要一种集成的解决方案。", "method": "设计了一个包含两个子系统的双模物联网框架。子系统1使用RFID进行身份验证和门禁控制，并将数据记录到Google Sheets。子系统2监测火焰和水流，通过LCD显示状态。两个子系统均使用ESP32微控制器进行边缘处理和无线连接，并通过统一的云架构进行集成。", "result": "实验结果显示，RFID认证准确率高达99.2%，响应时间平均0.82秒；火焰检测可靠性为98.5%；云端数据记录成功率为99.8%。该系统在网络中断时仍能通过本地缓存保持运行。总实现成本为5,400 BDT（约48美元），比商用集成方案降低了82%。", "conclusion": "该研究提供了一个实用的协同安全与安全集成框架，证明了通过精心的架构设计和组件优化，可以在保证成本效益和可及性的同时，实现专业级的性能，适用于多种应用场景。"}}
{"id": "2601.20369", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20369", "abs": "https://arxiv.org/abs/2601.20369", "authors": ["Mas Nurul Achmadiah", "Chi-Chia Sun", "Wen-Kai Kuo", "Jun-Wei Hsieh"], "title": "RepSFNet : A Single Fusion Network with Structural Reparameterization for Crowd Counting", "comment": "6 pages. Published in Proceedings of the IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS) 2025", "summary": "Crowd counting remains challenging in variable-density scenes due to scale variations, occlusions, and the high computational cost of existing models. To address these issues, we propose RepSFNet (Reparameterized Single Fusion Network), a lightweight architecture designed for accurate and real-time crowd estimation. RepSFNet leverages a RepLK-ViT backbone with large reparameterized kernels for efficient multi-scale feature extraction. It further integrates a Feature Fusion module combining Atrous Spatial Pyramid Pooling (ASPP) and Context-Aware Network (CAN) to achieve robust, density-adaptive context modeling. A Concatenate Fusion module is employed to preserve spatial resolution and generate high-quality density maps. By avoiding attention mechanisms and multi-branch designs, RepSFNet significantly reduces parameters and computational complexity. The training objective combines Mean Squared Error and Optimal Transport loss to improve both count accuracy and spatial distribution alignment. Experiments conducted on ShanghaiTech, NWPU, and UCF-QNRF datasets demonstrate that RepSFNet achieves competitive accuracy while reducing inference latency by up to 34 percent compared to recent state-of-the-art methods, making it suitable for real-time and low-power edge computing applications.", "AI": {"tldr": "RepSFNet是一个轻量级的众包计数模型，通过利用RepLK-ViT主干和融合模块，实现了高精度和低计算成本，适用于实时和边缘计算场景。", "motivation": "现有众包计数模型在可变密度场景下面临尺度变化、遮挡和计算成本高的问题，需要更准确、更高效的模型。", "method": "提出RepSFNet，采用RepLK-ViT主干进行特征提取，并结合ASPP和CAN的特征融合模块以及保留空间分辨率的Concatenate Fusion模块。模型避免了注意力机制和多分支设计，训练时使用MSE和Optimal Transport损失。", "result": "在ShanghaiTech, NWPU, 和 UCF-QNRF数据集上，RepSFNet在保持竞争力的准确性的同时，推理延迟降低了高达34%。", "conclusion": "RepSFNet是一种高效、轻量级的众包计数网络，在精度和速度上都表现出色，非常适合实时和低功耗的边缘计算应用。"}}
{"id": "2601.20335", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20335", "abs": "https://arxiv.org/abs/2601.20335", "authors": ["Qinzhuo Wu", "Zhizhuo Yang", "Hanhao Li", "Pengzhi Gao", "Wei Liu", "Jian Luan"], "title": "MobileBench-OL: A Comprehensive Chinese Benchmark for Evaluating Mobile GUI Agents in Real-World Environment", "comment": null, "summary": "Recent advances in mobile Graphical User Interface (GUI) agents highlight the growing need for comprehensive evaluation benchmarks. While new online benchmarks offer more realistic testing than offline ones, they tend to focus on the agents' task instruction-following ability while neglecting their reasoning and exploration ability. Moreover, these benchmarks do not consider the random noise in real-world mobile environments. This leads to a gap between benchmarks and real-world environments. To addressing these limitations, we propose MobileBench-OL, an online benchmark with 1080 tasks from 80 Chinese apps. It measures task execution, complex reasoning, and noise robustness of agents by including 5 subsets, which set multiple evaluation dimensions. We also provide an auto-eval framework with a reset mechanism, enabling stable and repeatable real-world benchmarking. Evaluating 12 leading GUI agents on MobileBench-OL shows significant room for improvement to meet real-world requirements. Human evaluation further confirms that MobileBench-OL can reliably measure the performance of leading GUI agents in real environments. Our data and code will be released upon acceptance.", "AI": {"tldr": "本文提出了MobileBench-OL，一个包含1080个任务的在线移动GUI基准，用于评估移动GUI智能体的任务执行、复杂推理和噪声鲁棒性，并提供了一个自动评估框架。", "motivation": "现有在线基准在评估移动GUI智能体时，过度关注指令遵循能力，而忽视了推理和探索能力，且未考虑真实移动环境中的随机噪声，导致评估与实际应用脱节。", "method": "构建了一个包含1080个任务、来自80个中文应用的在线基准MobileBench-OL，包含5个子集以衡量多个评估维度。开发了一个带有重置机制的自动评估框架，以确保稳定可重复的基准测试。", "result": "在MobileBench-OL上评估了12个领先的GUI智能体，发现它们在满足实际应用需求方面仍有很大提升空间。人类评估证实了MobileBench-OL能够可靠地衡量真实环境中领先GUI智能体的性能。", "conclusion": "MobileBench-OL通过更全面的评估维度和考虑真实环境因素，为移动GUI智能体的评估提供了更准确和可靠的基准，揭示了当前智能体在复杂推理和噪声鲁棒性方面的不足。"}}
{"id": "2601.20162", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20162", "abs": "https://arxiv.org/abs/2601.20162", "authors": ["Shuoxin Wang", "Chang Liu", "Gowen Loo", "Lifan Zheng", "Kaiwen Wei", "Xinyi Zeng", "Jingyuan Zhang", "Yu Tian"], "title": "Me-Agent: A Personalized Mobile Agent with Two-Level User Habit Learning for Enhanced Interaction", "comment": null, "summary": "Large Language Model (LLM)-based mobile agents have made significant performance advancements. However, these agents often follow explicit user instructions while overlooking personalized needs, leading to significant limitations for real users, particularly without personalized context: (1) inability to interpret ambiguous instructions, (2) lack of learning from user interaction history, and (3) failure to handle personalized instructions. To alleviate the above challenges, we propose Me-Agent, a learnable and memorable personalized mobile agent. Specifically, Me-Agent incorporates a two-level user habit learning approach. At the prompt level, we design a user preference learning strategy enhanced with a Personal Reward Model to improve personalization performance. At the memory level, we design a Hierarchical Preference Memory, which stores users' long-term memory and app-specific memory in different level memory. To validate the personalization capabilities of mobile agents, we introduce User FingerTip, a new benchmark featuring numerous ambiguous instructions for daily life. Extensive experiments on User FingerTip and general benchmarks demonstrate that Me-Agent achieves state-of-the-art performance in personalization while maintaining competitive instruction execution performance.", "AI": {"tldr": "提出了一种名为Me-Agent的可学习、可记忆的个性化移动代理，通过两级用户习惯学习（提示级偏好学习和记忆级偏好记忆）来解决现有LLM移动代理在理解模糊指令、学习用户交互历史和处理个性化指令方面的不足，并在新基准User FingerTip上取得了最先进的个性化性能。", "motivation": "现有的LLM移动代理通常遵循明确的用户指令，忽略个性化需求，导致在缺乏个性化上下文时，无法解释模糊指令、无法从用户交互历史中学习以及无法处理个性化指令。", "method": "提出Me-Agent，采用两级用户习惯学习方法：1. 提示级别：设计用户偏好学习策略，并增强个人奖励模型以提高个性化性能。2. 记忆级别：设计分层偏好记忆，分别存储用户的长期记忆和应用特定记忆。", "result": "在User FingerTip（一个包含大量日常模糊指令的新基准）和通用基准上的广泛实验表明，Me-Agent在个性化方面取得了最先进的性能，同时保持了具有竞争力的指令执行性能。", "conclusion": "Me-Agent通过引入两级用户习惯学习机制，有效地解决了当前LLM移动代理在个性化方面的局限性，并在多个基准测试中展现了优越的性能。"}}
{"id": "2601.20185", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.20185", "abs": "https://arxiv.org/abs/2601.20185", "authors": ["Husein Zolkepli"], "title": "Improving X-Codec-2.0 for Multi-Lingual Speech: 25 Hz Latent Rate and 24 kHz Sampling", "comment": null, "summary": "X-Codec-2.0 has shown strong performance in neural audio compression and multilingual speech modeling, operating at a 50 Hz latent rate and a 16 kHz sampling rate using frozen HuBERT features. While effective, this configuration limits temporal efficiency and audio fidelity. In this work, we explore a simple and effective modification by introducing additional pooling and increasing the decoder hop size. This reduces the latent rate from 50 Hz to 25 Hz and simultaneously raises the output sampling rate from 16 kHz to 24 kHz, improving efficiency and perceptual quality without altering the core architecture. Evaluated on the multilingual Common Voice 17 test set, the proposed configuration achieves a 0.29 MOS improvement over the original X-Codec-2.0 baseline based on UTMOSv2, and attains the best reported performance among all codecs operating at 25 Hz. The source code, checkpoints, and generation comparisons are released at \\href{https://huggingface.co/Scicom-intl/xcodec2-25TPS-24k}{https://huggingface.co/Scicom-intl/xcodec2-25TPS-24k}.", "AI": {"tldr": "通过增加池化和增大解码器跳跃步长，将 X-Codec-2.0 的潜在率从 50 Hz 降低到 25 Hz，同时将输出采样率从 16 kHz 提高到 24 kHz，从而在不改变核心架构的情况下提高了效率和感知质量。", "motivation": "X-Codec-2.0 在 50 Hz 潜在率和 16 kHz 采样率下表现良好，但这种配置限制了时间效率和音频保真度。", "method": "引入额外的池化操作并增加解码器的跳跃步长。", "result": "潜在率从 50 Hz 降低到 25 Hz，输出采样率从 16 kHz 提高到 24 kHz。在 Common Voice 17 测试集上，与原始 X-Codec-2.0 基线相比，UTMOSv2 评估提高了 0.29 MOS 分数，并在 25 Hz 的所有编解码器中取得了最佳性能。", "conclusion": "所提出的修改是一种简单有效的方法，可以在提高效率和感知质量的同时，无需更改 X-Codec-2.0 的核心架构。"}}
{"id": "2601.20419", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20419", "abs": "https://arxiv.org/abs/2601.20419", "authors": ["Yuhao Sun", "Chengyi Cai", "Jiacheng Zhang", "Zesheng Ye", "Xingliang Yuan", "Feng Liu"], "title": "Let's Roll a BiFTA: Bi-refinement for Fine-grained Text-visual Alignment in Vision-Language Models", "comment": "25 pages", "summary": "Recent research has shown that aligning fine-grained text descriptions with localized image patches can significantly improve the zero-shot performance of pre-trained vision-language models (e.g., CLIP). However, we find that both fine-grained text descriptions and localized image patches often contain redundant information, making text-visual alignment less effective. In this paper, we tackle this issue from two perspectives: \\emph{View Refinement} and \\emph{Description refinement}, termed as \\textit{\\textbf{Bi}-refinement for \\textbf{F}ine-grained \\textbf{T}ext-visual \\textbf{A}lignment} (BiFTA). \\emph{View refinement} removes redundant image patches with high \\emph{Intersection over Union} (IoU) ratios, resulting in more distinctive visual samples. \\emph{Description refinement} removes redundant text descriptions with high pairwise cosine similarity, ensuring greater diversity in the remaining descriptions. BiFTA achieves superior zero-shot performance on 6 benchmark datasets for both ViT-based and ResNet-based CLIP, justifying the necessity to remove redundant information in visual-text alignment.", "AI": {"tldr": "本文提出了一种名为BiFTA（Bi-refinement for Fine-grained Text-visual Alignment）的方法，通过精炼图像块和文本描述来提高细粒度文本-视觉对齐的零样本性能。", "motivation": "现有的细粒度文本-视觉对齐方法在提高零样本性能方面表现出色，但存在文本描述和图像块信息冗余的问题，导致对齐效果不佳。", "method": "BiFTA通过两种方式进行精炼：1. 视图精炼（View Refinement）：移除IoU高的冗余图像块，使视觉样本更具区分度。2. 描述精炼（Description Refinement）：移除余弦相似度高的冗余文本描述，确保描述的多样性。", "result": "BiFTA在6个基准数据集上，对基于ViT和ResNet的CLIP模型都取得了优越的零样本性能。", "conclusion": "去除视觉-文本对齐中的冗余信息对于提高细粒度零样本性能至关重要。"}}
{"id": "2601.20326", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20326", "abs": "https://arxiv.org/abs/2601.20326", "authors": ["Zeyu Xing", "Xing Li", "Hui-Ling Zhen", "Mingxuan Yuan", "Sinno Jialin Pan"], "title": "Beyond Speedup -- Utilizing KV Cache for Sampling and Reasoning", "comment": "Accepted by ICLR26", "summary": "KV caches, typically used only to speed up autoregressive decoding, encode contextual information that can be reused for downstream tasks at no extra cost. We propose treating the KV cache as a lightweight representation, eliminating the need to recompute or store full hidden states. Despite being weaker than dedicated embeddings, KV-derived representations are shown to be sufficient for two key applications: \\textbf{(i) Chain-of-Embedding}, where they achieve competitive or superior performance on Llama-3.1-8B-Instruct and Qwen2-7B-Instruct; and \\textbf{(ii) Fast/Slow Thinking Switching}, where they enable adaptive reasoning on Qwen3-8B and DeepSeek-R1-Distil-Qwen-14B, reducing token generation by up to $5.7\\times$ with minimal accuracy loss. Our findings establish KV caches as a free, effective substrate for sampling and reasoning, opening new directions for representation reuse in LLM inference. Code: https://github.com/cmd2001/ICLR2026_KV-Embedding.", "AI": {"tldr": "本研究提出将大型语言模型（LLM）的KV缓存作为一种低成本、可复用的表征，用于链式嵌入和快慢思维切换等下游任务，无需重新计算或存储完整的隐藏状态，从而提升效率并降低计算成本。", "motivation": "KV缓存通常只用于加速自回归解码，但其编码的上下文信息可以免费地用于下游任务。研究者希望探索如何利用KV缓存的这种潜力，作为一种轻量级表征，替代计算成本更高的完整隐藏状态。", "method": "研究者提出了两种应用KV缓存作为轻量级表征的方法：1. 链式嵌入（Chain-of-Embedding），将KV缓存作为嵌入，用于后续任务；2. 快慢思维切换（Fast/Slow Thinking Switching），利用KV缓存实现自适应推理，根据任务需求切换推理速度。研究在Llama-3.1-8B-Instruct、Qwen2-7B-Instruct、Qwen3-8B和DeepSeek-R1-Distil-Qwen-14B等模型上进行了实验。", "result": "在链式嵌入任务中，KV缓存表征在Llama-3.1-8B-Instruct和Qwen2-7B-Instruct上取得了具有竞争力或更优的性能。在快慢思维切换任务中，该方法在Qwen3-8B和DeepSeek-R1-Distil-Qwen-14B上实现了高达5.7倍的 token 生成减少，同时仅有极小的精度损失。", "conclusion": "KV缓存可以被视为一种免费且有效的采样和推理基础。这项研究为在LLM推理中实现表征复用开辟了新的方向，证明了其在提升效率和实现自适应推理方面的潜力。"}}
{"id": "2601.20383", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20383", "abs": "https://arxiv.org/abs/2601.20383", "authors": ["Mengge Liu", "Yan Di", "Gu Wang", "Yun Qu", "Dekai Zhu", "Yanyan Li", "Xiangyang Ji"], "title": "HINT: Hierarchical Interaction Modeling for Autoregressive Multi-Human Motion Generation", "comment": null, "summary": "Text-driven multi-human motion generation with complex interactions remains a challenging problem. Despite progress in performance, existing offline methods that generate fixed-length motions with a fixed number of agents, are inherently limited in handling long or variable text, and varying agent counts. These limitations naturally encourage autoregressive formulations, which predict future motions step by step conditioned on all past trajectories and current text guidance. In this work, we introduce HINT, the first autoregressive framework for multi-human motion generation with Hierarchical INTeraction modeling in diffusion. First, HINT leverages a disentangled motion representation within a canonicalized latent space, decoupling local motion semantics from inter-person interactions. This design facilitates direct adaptation to varying numbers of human participants without requiring additional refinement. Second, HINT adopts a sliding-window strategy for efficient online generation, and aggregates local within-window and global cross-window conditions to capture past human history, inter-person dependencies, and align with text guidance. This strategy not only enables fine-grained interaction modeling within each window but also preserves long-horizon coherence across all the long sequence. Extensive experiments on public benchmarks demonstrate that HINT matches the performance of strong offline models and surpasses autoregressive baselines. Notably, on InterHuman, HINT achieves an FID of 3.100, significantly improving over the previous state-of-the-art score of 5.154.", "AI": {"tldr": "HINT 是一个新颖的、首个用于多人类动作生成的自回归扩散模型框架，通过分层交互建模，能够处理可变数量的参与者和长文本输入，并实现了高效的在线生成。", "motivation": "现有离线方法在处理可变长度文本和可变数量参与者方面存在局限性，这促使研究者探索自回归方法。", "method": "HINT 采用解耦的动作表示，将局部动作语义与人际交互分开。它使用滑动窗口策略进行高效在线生成，并聚合窗口内和跨窗口的条件，以捕捉人类历史、人际依赖和文本指导。", "result": "HINT 的性能可与强大的离线模型相媲美，并超越了现有的自回归基线。在 InterHuman 数据集上，HINT 的 FID 成绩从 5.154 显著提高到 3.100。", "conclusion": "HINT 是一个创新的自回归框架，通过分层交互建模，有效地解决了多人类动作生成中的交互复杂性和可变性问题，并在生成质量和效率上取得了显著提升。"}}
{"id": "2601.20230", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.20230", "abs": "https://arxiv.org/abs/2601.20230", "authors": ["Haoyuan Yu", "Yuxuan Chen", "Minjie Cai"], "title": "Unit-Based Agent for Semi-Cascaded Full-Duplex Dialogue Systems", "comment": "ICASSP 2026 (Workshop). https://github.com/yu-haoyuan/fd-badcat", "summary": "Full-duplex voice interaction is crucial for natural human computer interaction. We present a framework that decomposes complex dialogue into minimal conversational units, enabling the system to process each unit independently and predict when to transit to the next. This framework is instantiated as a semi-cascaded full-duplex dialogue system built around a multimodal large language model, supported by auxiliary modules such as voice activity detection (VAD) and text-to-speech (TTS) synthesis. The resulting system operates in a train-free, plug-and-play manner. Experiments on the HumDial dataset demonstrate the effectiveness of our framework, which ranks second among all teams on the test set of the Human-like Spoken Dialogue Systems Challenge (Track 2: Full-Duplex Interaction). Code is available at the GitHub repository https://github.com/yu-haoyuan/fd-badcat.", "AI": {"tldr": "该研究提出了一种用于全双工语音交互的框架，该框架将对话分解为最小的对话单元，并由一个基于多模态大语言模型的系统实现，无需训练即可运行。", "motivation": "自然流畅的全双工语音交互对于提升人机交互体验至关重要。", "method": "提出一个框架，将复杂对话分解为独立的最小对话单元，并预测单元间的转换。该框架被实例化为一个半级联的全双工对话系统，核心是多模态大语言模型，并辅以语音活动检测（VAD）和文本转语音（TTS）模块。系统支持即插即用，无需训练。", "result": "在HumDial数据集上的实验表明，该框架非常有效。在人类对话系统挑战赛（Track 2：全双工交互）的测试集上，该系统在所有参赛队伍中排名第二。", "conclusion": "该研究提出的框架能够有效地实现全双工语音交互，并且具有无需训练、即插即用的优点，在真实对话场景中表现优异。"}}
{"id": "2601.20503", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20503", "abs": "https://arxiv.org/abs/2601.20503", "authors": ["Jesse Phitidis", "Alison Q. Smithard", "William N. Whiteley", "Joanna M. Wardlaw", "Miguel O. Bernabeu", "Maria Valdés Hernández"], "title": "Comparative evaluation of training strategies using partially labelled datasets for segmentation of white matter hyperintensities and stroke lesions in FLAIR MRI", "comment": null, "summary": "White matter hyperintensities (WMH) and ischaemic stroke lesions (ISL) are imaging features associated with cerebral small vessel disease (SVD) that are visible on brain magnetic resonance imaging (MRI) scans. The development and validation of deep learning models to segment and differentiate these features is difficult because they visually confound each other in the fluid-attenuated inversion recovery (FLAIR) sequence and often appear in the same subject. We investigated six strategies for training a combined WMH and ISL segmentation model using partially labelled data. We combined privately held fully and partially labelled datasets with publicly available partially labelled datasets to yield a total of 2052 MRI volumes, with 1341 and 1152 containing ground truth annotations for WMH and ISL respectively. We found that several methods were able to effectively leverage the partially labelled data to improve model performance, with the use of pseudolabels yielding the best result.", "AI": {"tldr": "研究提出并评估了六种利用部分标记数据训练联合白质高信号（WMH）和缺血性卒中病灶（ISL）分割模型的策略，发现伪标签策略效果最佳。", "motivation": "在脑部MRI扫描中，WMH和ISL是脑小血管病（SVD）的影像学特征，它们在FLAIR序列中视觉上混淆且常出现在同一受试者中，因此开发能区分它们的深度学习分割模型具有挑战性，特别是当仅有部分标记数据可用时。", "method": "利用私人和公开的、包含完全标记和部分标记的WMH和ISL数据集，总共2052个MRI扫描。研究了六种训练联合WMH和ISL分割模型的策略，重点关注如何有效利用部分标记数据。", "result": "研究发现，多种策略能够有效利用部分标记数据来提升模型性能，其中使用伪标签（pseudolabels）的方法取得了最佳结果。", "conclusion": "通过结合不同来源的部分标记数据，并采用合适的训练策略（如伪标签），可以成功开发出有效的联合WMH和ISL分割模型，克服了数据标记不完整和特征混淆的挑战。"}}
{"id": "2601.20425", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20425", "abs": "https://arxiv.org/abs/2601.20425", "authors": ["Chenliang Zhou", "Fangcheng Zhong", "Weihao Xia", "Albert Miao", "Canberk Baykal", "Cengiz Oztireli"], "title": "Quartet of Diffusions: Structure-Aware Point Cloud Generation through Part and Symmetry Guidance", "comment": null, "summary": "We introduce the Quartet of Diffusions, a structure-aware point cloud generation framework that explicitly models part composition and symmetry. Unlike prior methods that treat shape generation as a holistic process or only support part composition, our approach leverages four coordinated diffusion models to learn distributions of global shape latents, symmetries, semantic parts, and their spatial assembly. This structured pipeline ensures guaranteed symmetry, coherent part placement, and diverse, high-quality outputs. By disentangling the generative process into interpretable components, our method supports fine-grained control over shape attributes, enabling targeted manipulation of individual parts while preserving global consistency. A central global latent further reinforces structural coherence across assembled parts. Our experiments show that the Quartet achieves state-of-the-art performance. To our best knowledge, this is the first 3D point cloud generation framework that fully integrates and enforces both symmetry and part priors throughout the generative process.", "AI": {"tldr": "本文提出了一种名为“Quartet of Diffusions”的结构感知点云生成框架，它显式地对部件组合和对称性进行建模，通过四个协同工作的扩散模型生成高质量、对称且结构连贯的点云。", "motivation": "现有方法要么将形状生成视为整体过程，要么仅支持部件组合，未能同时保证对称性和部件的合理组合。作者希望开发一种能同时整合并强制执行对称性和部件先验的3D点云生成框架。", "method": "该框架使用四个协同的扩散模型，分别学习全局形状潜在表示、对称性、语义部件及其空间组合的分布。通过解耦生成过程，实现对形状属性的精细控制，并在生成过程中通过一个中心全局潜在表示来增强部件间的结构连贯性。", "result": "实验证明，“Quartet of Diffusions”框架在点云生成任务上达到了最先进的性能，能够生成具有保证对称性、部件放置连贯以及高质量和多样性的输出。", "conclusion": "“Quartet of Diffusions”是首个能够完全整合并强制执行对称性和部件先验的3D点云生成框架，实现了生成过程的结构感知和精细控制，并取得了优于现有方法的性能。"}}
{"id": "2601.20598", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20598", "abs": "https://arxiv.org/abs/2601.20598", "authors": ["Lakshman Balasubramanian"], "title": "Person Re-ID in 2025: Supervised, Self-Supervised, and Language-Aligned. What Works?", "comment": null, "summary": "Person Re-Identification (ReID) remains a challenging problem in computer vision. This work reviews various training paradigm and evaluates the robustness of state-of-the-art ReID models in cross-domain applications and examines the role of foundation models in improving generalization through richer, more transferable visual representations. We compare three training paradigms, supervised, self-supervised, and language-aligned models. Through the study the aim is to answer the following questions: Can supervised models generalize in cross-domain scenarios? How does foundation models like SigLIP2 perform for the ReID tasks? What are the weaknesses of current supervised and foundational models for ReID? We have conducted the analysis across 11 models and 9 datasets. Our results show a clear split: supervised models dominate their training domain but crumble on cross-domain data. Language-aligned models, however, show surprising robustness cross-domain for ReID tasks, even though they are not explicitly trained to do so. Code and data available at: https://github.com/moiiai-tech/object-reid-benchmark.", "AI": {"tldr": "本研究评估了不同训练范式（监督、自监督、语言对齐）下的 ReID 模型在跨域应用中的鲁棒性，并考察了基础模型（如 SigLIP2）的作用。研究发现，监督模型在跨域数据上表现不佳，而语言对齐模型则展现出令人惊讶的鲁棒性。", "motivation": "现有 ReID 模型在跨域应用中泛化能力不足，作者希望通过研究不同的训练范式和基础模型来提升 ReID 模型的泛化能力，并找出当前模型的弱点。", "method": "比较了三种训练范式（监督、自监督、语言对齐）下 11 个 ReID 模型在 9 个数据集上的表现。特别关注了基础模型（如 SigLIP2）在 ReID 任务上的性能。", "result": "监督模型在训练域内表现良好，但在跨域数据上性能急剧下降。语言对齐模型在跨域 ReID 任务上表现出令人惊讶的鲁棒性，即使没有经过显式训练。", "conclusion": "基础模型，特别是语言对齐模型，在提高 ReID 模型的跨域泛化能力方面具有巨大潜力。当前监督模型在跨域场景下存在显著的弱点。"}}
{"id": "2601.20256", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20256", "abs": "https://arxiv.org/abs/2601.20256", "authors": ["Xuanyu Su", "Diana Inkpen", "Nathalie Japkowicz"], "title": "SoftHateBench: Evaluating Moderation Models Against Reasoning-Driven, Policy-Compliant Hostility", "comment": null, "summary": "Online hate on social media ranges from overt slurs and threats (\\emph{hard hate speech}) to \\emph{soft hate speech}: discourse that appears reasonable on the surface but uses framing and value-based arguments to steer audiences toward blaming or excluding a target group. We hypothesize that current moderation systems, largely optimized for surface toxicity cues, are not robust to this reasoning-driven hostility, yet existing benchmarks do not measure this gap systematically. We introduce \\textbf{\\textsc{SoftHateBench}}, a generative benchmark that produces soft-hate variants while preserving the underlying hostile standpoint. To generate soft hate, we integrate the \\emph{Argumentum Model of Topics} (AMT) and \\emph{Relevance Theory} (RT) in a unified framework: AMT provides the backbone argument structure for rewriting an explicit hateful standpoint into a seemingly neutral discussion while preserving the stance, and RT guides generation to keep the AMT chain logically coherent. The benchmark spans \\textbf{7} sociocultural domains and \\textbf{28} target groups, comprising \\textbf{4,745} soft-hate instances. Evaluations across encoder-based detectors, general-purpose LLMs, and safety models show a consistent drop from hard to soft tiers: systems that detect explicit hostility often fail when the same stance is conveyed through subtle, reasoning-based language. \\textcolor{red}{\\textbf{Disclaimer.} Contains offensive examples used solely for research.}", "AI": {"tldr": "本研究引入了一个名为 SoftHateBench 的新基准，用于评估社交媒体上的“软仇恨言论”（即表面上看似合理但暗含歧视的言论）检测能力。研究发现，现有的大多数内容审核系统在检测硬仇恨言论（如辱骂和威胁）方面表现良好，但在检测软仇恨言论方面却效果不佳。", "motivation": "现有内容审核系统主要针对明显的仇恨言论进行优化，而对于表面合理但实际带有歧视意图的“软仇恨言论”检测能力不足。目前缺乏系统性的基准来衡量和解决这一问题。", "method": "研究人员提出了 SoftHateBench 基准，该基准通过结合“论点主题模型”（AMT）和“关联理论”（RT）来生成软仇恨言论。AMT 用于构建仇恨观点的论证结构，并将其改写成看似中立的讨论，同时保留原有的仇恨立场。RT 则用于指导生成过程，确保改写后的论证逻辑连贯。该基准涵盖 7 个社会文化领域和 28 个目标群体，共包含 4,745 个软仇恨言论实例。", "result": "对基于编码器的检测器、通用大型语言模型和安全模型进行的评估显示，在从硬仇恨言论转向软仇恨言论时，所有系统的检测性能均出现一致下降。这意味着那些能够有效检测明显敌对言论的系统，在面对使用微妙、基于推理的语言所传达的相同立场时，往往会失效。", "conclusion": "现有的仇恨言论检测系统在处理软仇恨言论方面存在显著的不足。SoftHateBench 基准的引入为量化和改进对这种复杂形式仇恨言论的检测能力提供了重要工具。"}}
{"id": "2601.20433", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20433", "abs": "https://arxiv.org/abs/2601.20433", "authors": ["Wenbo Xu", "Wei Lu", "Xiangyang Luo", "Jiantao Zhou"], "title": "MARE: Multimodal Alignment and Reinforcement for Explainable Deepfake Detection via Vision-Language Models", "comment": null, "summary": "Deepfake detection is a widely researched topic that is crucial for combating the spread of malicious content, with existing methods mainly modeling the problem as classification or spatial localization. The rapid advancements in generative models impose new demands on Deepfake detection. In this paper, we propose multimodal alignment and reinforcement for explainable Deepfake detection via vision-language models, termed MARE, which aims to enhance the accuracy and reliability of Vision-Language Models (VLMs) in Deepfake detection and reasoning. Specifically, MARE designs comprehensive reward functions, incorporating reinforcement learning from human feedback (RLHF), to incentivize the generation of text-spatially aligned reasoning content that adheres to human preferences. Besides, MARE introduces a forgery disentanglement module to capture intrinsic forgery traces from high-level facial semantics, thereby improving its authenticity detection capability. We conduct thorough evaluations on the reasoning content generated by MARE. Both quantitative and qualitative experimental results demonstrate that MARE achieves state-of-the-art performance in terms of accuracy and reliability.", "AI": {"tldr": "本文提出了一种名为MARE的多模态对齐与强化方法，用于可解释的Deepfake检测，利用视觉-语言模型（VLMs）通过引入基于人类反馈的强化学习（RLHF）和伪造分离模块，以提高检测准确性和可靠性。", "motivation": "现有Deepfake检测方法主要依赖分类或空间定位，但生成模型的快速发展带来了新的挑战。需要更先进的方法来提高检测的准确性和可靠性，并提供可解释的理由。", "method": "MARE方法结合了多模态对齐和强化学习。它设计了包含RLHF的综合奖励函数，以鼓励生成符合人类偏好的文本-空间对齐的推理内容。此外，还引入了一个伪造分离模块，用于捕获高级面部语义中的内在伪造痕迹。", "result": "MARE在Deepfake检测任务上达到了最先进的性能。实验结果（包括定量和定性评估）表明，MARE在准确性和可靠性方面均表现优异。", "conclusion": "MARE是一种有效的方法，可以提高VLMs在Deepfake检测和推理方面的准确性和可靠性，并通过生成可解释的文本推理内容来增强其能力。"}}
{"id": "2601.20275", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20275", "abs": "https://arxiv.org/abs/2601.20275", "authors": ["Elina Sigdel", "Anastasia Panfilova"], "title": "RusLICA: A Russian-Language Platform for Automated Linguistic Inquiry and Category Analysis", "comment": "The link to the platform: https://ruslica.ipran.ru", "summary": "Defining psycholinguistic characteristics in written texts is a task gaining increasing attention from researchers. One of the most widely used tools in the current field is Linguistic Inquiry and Word Count (LIWC) that originally was developed to analyze English texts and translated into multiple languages. Our approach offers the adaptation of LIWC methodology for the Russian language, considering its grammatical and cultural specificities. The suggested approach comprises 96 categories, integrating syntactic, morphological, lexical, general statistical features, and results of predictions obtained using pre-trained language models (LMs) for text analysis. Rather than applying direct translation to existing thesauri, we built the dictionary specifically for the Russian language based on the content from several lexicographic resources, semantic dictionaries and corpora. The paper describes the process of mapping lemmas to 42 psycholinguistic categories and the implementation of the analyzer as part of RusLICA web service.", "AI": {"tldr": "该研究提出了一个适用于俄语的心理语言学特征分析方法，基于LIWC的理念，但为俄语的语法和文化特点进行了专门设计和构建。", "motivation": "现有的LIWC工具主要用于英语，需要为俄语开发一套适配的心理语言学分析工具，以满足研究需求。", "method": "该方法包含96个类别，整合了句法、形态、词汇、通用统计特征以及预训练语言模型（LMs）的预测结果。研究人员没有直接翻译现有词库，而是基于多个词典学资源、语义词典和语料库，为俄语专门构建了一个词汇库，并将词条映射到42个心理语言学类别。", "result": "构建了一个包含96个类别，并将词条映射到42个心理语言学类别的俄语心理语言学特征分析系统，并将其实现为RusLICA网络服务。", "conclusion": "该研究成功地为俄语开发了一个新的、考虑了其语言和文化特性的心理语言学特征分析方法，并通过RusLICA网络服务进行了实现。"}}
{"id": "2601.20601", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20601", "abs": "https://arxiv.org/abs/2601.20601", "authors": ["Zhuonan Wang", "Wenjie Yan", "Wenqiao Zhang", "Xiaohui Song", "Jian Ma", "Ke Yao", "Yibo Yu", "Beng Chin Ooi"], "title": "CLEAR-Mamba:Towards Accurate, Adaptive and Trustworthy Multi-Sequence Ophthalmic Angiography Classification", "comment": "10 pages,7 figures", "summary": "Medical image classification is a core task in computer-aided diagnosis (CAD), playing a pivotal role in early disease detection, treatment planning, and patient prognosis assessment. In ophthalmic practice, fluorescein fundus angiography (FFA) and indocyanine green angiography (ICGA) provide hemodynamic and lesion-structural information that conventional fundus photography cannot capture. However, due to the single-modality nature, subtle lesion patterns, and significant inter-device variability, existing methods still face limitations in generalization and high-confidence prediction. To address these challenges, we propose CLEAR-Mamba, an enhanced framework built upon MedMamba with optimizations in both architecture and training strategy. Architecturally, we introduce HaC, a hypernetwork-based adaptive conditioning layer that dynamically generates parameters according to input feature distributions, thereby improving cross-domain adaptability. From a training perspective, we develop RaP, a reliability-aware prediction scheme built upon evidential uncertainty learning, which encourages the model to emphasize low-confidence samples and improves overall stability and reliability. We further construct a large-scale ophthalmic angiography dataset covering both FFA and ICGA modalities, comprising multiple retinal disease categories for model training and evaluation. Experimental results demonstrate that CLEAR-Mamba consistently outperforms multiple baseline models, including the original MedMamba, across various metrics-showing particular advantages in multi-disease classification and reliability-aware prediction. This study provides an effective solution that balances generalizability and reliability for modality-specific medical image classification tasks.", "AI": {"tldr": "本文提出了一种名为CLEAR-Mamba的医学图像分类新框架，通过引入基于超网络的自适应条件层（HaC）和基于证据不确定性学习的可靠性感知预测方案（RaP），提高了模型在眼底荧光素血管造影（FFA）和吲哚菁绿血管造影（ICGA）图像分类任务中的泛化能力和可靠性，并在大规模数据集上取得了优于基线模型的性能。", "motivation": "现有医学图像分类方法在处理单模态、细微病变模式和设备差异大的眼科影像时，存在泛化能力和高置信度预测的局限性。", "method": "提出CLEAR-Mamba框架，包含两个关键创新：1. 架构方面，引入HaC（Hypernetwork-based adaptive conditioning layer）自适应条件层，动态生成参数以提高跨域适应性；2. 训练方面，开发RaP（Reliability-aware prediction scheme）可靠性感知预测方案，利用证据不确定性学习，侧重于低置信度样本，提高稳定性和可靠性。同时构建了包含FFA和ICGA模态的大规模眼科造影数据集。", "result": "CLEAR-Mamba在多疾病分类和可靠性感知预测方面表现出显著优势，一致优于包括原始MedMamba在内的多个基线模型。", "conclusion": "CLEAR-Mamba为模态特定的医学图像分类任务提供了一个有效的解决方案，能够平衡泛化能力和可靠性。"}}
{"id": "2601.20430", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20430", "abs": "https://arxiv.org/abs/2601.20430", "authors": ["Kun Yin", "Yunfei Wu", "Bing Liu", "Zhongpeng Cai", "Xiaotian Li", "Huang Chen", "Xin Li", "Haoyu Cao", "Yinsong Liu", "Deqiang Jiang", "Xing Sun", "Yunsheng Wu", "Qianyu Li", "Antai Guo", "Yanzhen Liao", "Yanqiu Qu", "Haodong Lin", "Chengxu He", "Shuangyin Liu"], "title": "Youtu-Parsing: Perception, Structuring and Recognition via High-Parallelism Decoding", "comment": null, "summary": "This paper presents Youtu-Parsing, an efficient and versatile document parsing model designed for high-performance content extraction. The architecture employs a native Vision Transformer (ViT) featuring a dynamic-resolution visual encoder to extract shared document features, coupled with a prompt-guided Youtu-LLM-2B language model for layout analysis and region-prompted decoding. Leveraging this decoupled and feature-reusable framework, we introduce a high-parallelism decoding strategy comprising two core components: token parallelism and query parallelism. The token parallelism strategy concurrently generates up to 64 candidate tokens per inference step, which are subsequently validated through a verification mechanism. This approach yields a 5--11x speedup over traditional autoregressive decoding and is particularly well-suited for highly structured scenarios, such as table recognition. To further exploit the advantages of region-prompted decoding, the query parallelism strategy enables simultaneous content prediction for multiple bounding boxes (up to five), providing an additional 2x acceleration while maintaining output quality equivalent to standard decoding. Youtu-Parsing encompasses a diverse range of document elements, including text, formulas, tables, charts, seals, and hierarchical structures. Furthermore, the model exhibits strong robustness when handling rare characters, multilingual text, and handwritten content. Extensive evaluations demonstrate that Youtu-Parsing achieves state-of-the-art (SOTA) performance on both the OmniDocBench and olmOCR-bench benchmarks. Overall, Youtu-Parsing demonstrates significant experimental value and practical utility for large-scale document intelligence applications.", "AI": {"tldr": "本文提出了一种名为Youtu-Parsing的高效文档解析模型，结合了Vision Transformer和Youtu-LLM-2B语言模型，并采用了并行解码策略，在速度和准确性上均取得了SOTA性能，适用于大规模文档智能应用。", "motivation": "为了实现文档的高性能内容提取，需要一个能够高效且通用地解析各类文档元素的模型。", "method": "采用原生Vision Transformer（ViT）作为动态分辨率视觉编码器提取共享文档特征，并结合了由Youtu-LLM-2B语言模型驱动的布局分析和区域提示解码。引入了包含token并行和query并行的双核心高并行解码策略。", "result": "Youtu-Parsing在token并行策略下实现了5-11倍的速度提升，query并行策略下实现了2倍的加速，同时保持了与标准解码相当的输出质量。模型在OmniDocBench和olmOCR-bench基准测试上均取得了SOTA性能。", "conclusion": "Youtu-Parsing是一个高效且通用的文档解析模型，其解耦且特征可重用的框架以及高并行解码策略，使其在处理文本、公式、表格、图表等多种文档元素时表现出色，并且在处理罕见字符、多语言和手写内容时也展现出强大的鲁棒性，具有显著的实验价值和实际应用潜力。"}}
{"id": "2601.20618", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20618", "abs": "https://arxiv.org/abs/2601.20618", "authors": ["Shuguang Zhang", "Junhong Lian", "Guoxin Yu", "Baoxun Xu", "Xiang Ao"], "title": "GDCNet: Generative Discrepancy Comparison Network for Multimodal Sarcasm Detection", "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)", "summary": "Multimodal sarcasm detection (MSD) aims to identify sarcasm within image-text pairs by modeling semantic incongruities across modalities. Existing methods often exploit cross-modal embedding misalignment to detect inconsistency but struggle when visual and textual content are loosely related or semantically indirect. While recent approaches leverage large language models (LLMs) to generate sarcastic cues, the inherent diversity and subjectivity of these generations often introduce noise. To address these limitations, we propose the Generative Discrepancy Comparison Network (GDCNet). This framework captures cross-modal conflicts by utilizing descriptive, factually grounded image captions generated by Multimodal LLMs (MLLMs) as stable semantic anchors. Specifically, GDCNet computes semantic and sentiment discrepancies between the generated objective description and the original text, alongside measuring visual-textual fidelity. These discrepancy features are then fused with visual and textual representations via a gated module to adaptively balance modality contributions. Extensive experiments on MSD benchmarks demonstrate GDCNet's superior accuracy and robustness, establishing a new state-of-the-art on the MMSD2.0 benchmark.", "AI": {"tldr": "本文提出了一种名为GDCNet的多模态讽刺检测框架，通过利用多模态大模型生成的图像描述作为稳定的语义锚点，计算描述与原文之间的语义和情感差异，并结合视觉-文本保真度，以提高讽刺检测的准确性和鲁棒性。", "motivation": "现有方法在处理视觉和文本内容关联度低或语义间接的图像-文本对时，难以有效检测讽刺。近期利用大型语言模型生成讽刺线索的方法，其生成内容的多样性和主观性容易引入噪声。", "method": "GDCNet框架首先利用多模态大模型（MLLMs）生成描述性的、基于事实的图像字幕，作为稳定的语义锚点。然后，计算生成的目标描述与原始文本之间的语义和情感差异，同时测量视觉-文本保真度。最后，通过门控模块将这些差异特征与视觉和文本表示融合，自适应地平衡模态贡献。", "result": "在多模态讽刺检测基准数据集上的大量实验表明，GDCNet在准确性和鲁棒性方面表现优越，并在MMSD2.0基准上取得了新的最先进水平。", "conclusion": "GDCNet通过利用MLLM生成的稳定图像描述作为语义锚点，有效捕捉跨模态冲突，并能够自适应地融合不同模态的特征，从而显著提高了多模态讽刺检测的性能。"}}
{"id": "2601.20300", "categories": ["cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.20300", "abs": "https://arxiv.org/abs/2601.20300", "authors": ["Jing Xu", "Minglin Wu", "Xueyuan Chen", "Xixin Wu", "Helen Meng"], "title": "MiLorE-SSL: Scaling Multilingual Capabilities in Self-Supervised Models without Forgetting", "comment": "Accepted by ICASSP2026", "summary": "Self-supervised learning (SSL) has greatly advanced speech representation learning, but multilingual SSL models remain constrained to languages encountered during pretraining. Retraining from scratch to incorporate new languages is computationally expensive, while sequential training without migitation strategies often leads to catastrophic forgetting. To address this, we propose MiLorE-SSL, a lightweight framework that combines LoRA modules with a soft mixture-of-experts (MoE) mechanism for efficient continual multilingual training. LoRA provides efficient low-rank adaptation, while soft MoE promotes flexible expert sharing across languages, reducing cross-lingual interference. To further mitigate forgetting, we introduce limited replay data from existing languages, avoiding reliance on large historical corpora. Experiments on ML-SUPERB demonstrate that MiLorE-SSL achieves strong performance in new languages and improves the ability in existing ones with only 2.14% trainable parameters.", "AI": {"tldr": "提出了一种名为MiLorE-SSL的轻量级框架，通过结合LoRA和软混合专家（MoE）机制，实现了高效的持续多语言语音自监督学习，有效解决了新语言加入时计算成本高和遗忘旧语言的问题。", "motivation": "现有的多语言自监督学习模型在加入新语言时计算成本高昂，且顺序训练容易导致灾难性遗忘。需要一种更高效、能避免遗忘的持续学习方法。", "method": "提出MiLorE-SSL框架，包含两个关键组件：1. LoRA（Low-Rank Adaptation）模块，用于高效的低秩适应；2. 软混合专家（MoE）机制，促进专家在不同语言间的灵活共享，减少跨语言干扰。此外，引入有限的旧语言重放数据来缓解遗忘。", "result": "在ML-SUPERB数据集上的实验表明，MiLorE-SSL在学习新语言方面表现出色，并能提升在已有语言上的表现，同时仅需训练2.14%的参数。", "conclusion": "MiLorE-SSL是一个高效的持续多语言语音自监督学习框架，通过LoRA和软MoE机制，能够以极低的参数量实现新语言的有效学习和旧语言能力的保持，解决了现有方法的局限性。"}}
{"id": "2601.20327", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20327", "abs": "https://arxiv.org/abs/2601.20327", "authors": ["Xinyu Hu", "Yancheng He", "Weixun Wang", "Tao Feng", "Li Lin", "Jiashun Liu", "Wenbo Su", "Bo Zheng", "Xiaojun Wan"], "title": "CE-RM: A Pointwise Generative Reward Model Optimized via Two-Stage Rollout and Unified Criteria", "comment": "Under Review", "summary": "Automatic evaluation is crucial yet challenging for open-ended natural language generation, especially when rule-based metrics are infeasible. Compared with traditional methods, the recent LLM-as-a-Judge paradigms enable better and more flexible evaluation, and show promise as generative reward models for reinforcement learning. However, prior work has revealed a notable gap between their seemingly impressive benchmark performance and actual effectiveness in RL practice. We attribute this issue to some limitations in existing studies, including the dominance of pairwise evaluation and inadequate optimization of evaluation criteria. Therefore, we propose CE-RM-4B, a pointwise generative reward model trained with a dedicated two-stage rollout method, and adopting unified query-based criteria. Using only about 5.7K high-quality data curated from the open-source preference dataset, our CE-RM-4B achieves superior performance on diverse reward model benchmarks, especially in Best-of-N scenarios, and delivers more effective improvements in downstream RL practice.", "AI": {"tldr": "本文提出了CE-RM-4B，一种用于开放式自然语言生成自动评估的点式生成奖励模型，通过两阶段滚动策略和统一的基于查询的标准进行训练，并在奖励模型基准和下游强化学习实践中均取得了优越性能。", "motivation": "现有的LLM-as-a-Judge范式在实际强化学习应用中效果不如预期，存在评估指标优化不足和成对评估占主导的问题。", "method": "提出了一种名为CE-RM-4B的点式生成奖励模型，采用了专门的两阶段滚动方法进行训练，并使用了统一的基于查询的标准。模型仅使用了约5.7K高质量数据。", "result": "CE-RM-4B在多种奖励模型基准测试中表现出色，尤其是在Best-of-N场景下，并在下游强化学习实践中带来了更有效的改进。", "conclusion": "CE-RM-4B通过改进评估方法和训练策略，克服了现有LLM-as-a-Judge范式的局限性，为开放式自然语言生成的自动评估和强化学习提供了更有效的解决方案。"}}
{"id": "2601.20499", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20499", "abs": "https://arxiv.org/abs/2601.20499", "authors": ["Hang Guo", "Zhaoyang Jia", "Jiahao Li", "Bin Li", "Yuanhao Cai", "Jiangshan Wang", "Yawei Li", "Yan Lu"], "title": "Efficient Autoregressive Video Diffusion with Dummy Head", "comment": "Technical Report", "summary": "The autoregressive video diffusion model has recently gained considerable research interest due to its causal modeling and iterative denoising. In this work, we identify that the multi-head self-attention in these models under-utilizes historical frames: approximately 25% heads attend almost exclusively to the current frame, and discarding their KV caches incurs only minor performance degradation. Building upon this, we propose Dummy Forcing, a simple yet effective method to control context accessibility across different heads. Specifically, the proposed heterogeneous memory allocation reduces head-wise context redundancy, accompanied by dynamic head programming to adaptively classify head types. Moreover, we develop a context packing technique to achieve more aggressive cache compression. Without additional training, our Dummy Forcing delivers up to 2.0x speedup over the baseline, supporting video generation at 24.3 FPS with less than 0.5% quality drop. Project page is available at https://csguoh.github.io/project/DummyForcing/.", "AI": {"tldr": "本文提出了一种名为Dummy Forcing的方法，通过优化自回归视频扩散模型中多头自注意力机制对历史帧的利用，实现了在不牺牲模型质量的情况下，将视频生成速度提升至2.0倍，达到24.3 FPS。", "motivation": "现有的自回归视频扩散模型中的多头自注意力机制未能充分利用历史帧信息，导致部分注意力头只关注当前帧，造成了计算资源的浪费。", "method": "本文提出Dummy Forcing方法，包括：1. 异构内存分配，减少头部间的上下文冗余；2. 动态头部编程，自适应分类头部类型；3. 上下文打包技术，实现更激进的缓存压缩。", "result": "在不进行额外训练的情况下，Dummy Forcing 方法实现了高达2.0倍的加速，视频生成速度达到24.3 FPS，同时模型质量仅下降不到0.5%。", "conclusion": "Dummy Forcing是一种简单有效的方法，能够显著提升自回归视频扩散模型的推理速度，同时保持生成视频的质量，为高效视频生成提供了新的解决方案。"}}
{"id": "2601.20674", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20674", "abs": "https://arxiv.org/abs/2601.20674", "authors": ["Juan Jose Rubio Jan", "Jack Wu", "Julia Ive"], "title": "Harnessing Large Language Models for Precision Querying and Retrieval-Augmented Knowledge Extraction in Clinical Data Science", "comment": "11 pages, 5 figures", "summary": "This study applies Large Language Models (LLMs) to two foundational Electronic Health Record (EHR) data science tasks: structured data querying (using programmatic languages, Python/Pandas) and information extraction from unstructured clinical text via a Retrieval Augmented Generation (RAG) pipeline. We test the ability of LLMs to interact accurately with large structured datasets for analytics and the reliability of LLMs in extracting semantically correct information from free text health records when supported by RAG. To this end, we presented a flexible evaluation framework that automatically generates synthetic question and answer pairs tailored to the characteristics of each dataset or task. Experiments were conducted on a curated subset of MIMIC III, (four structured tables and one clinical note type), using a mix of locally hosted and API-based LLMs. Evaluation combined exact-match metrics, semantic similarity, and human judgment. Our findings demonstrate the potential of LLMs to support precise querying and accurate information extraction in clinical workflows.", "AI": {"tldr": "本研究探讨了大型语言模型（LLMs）在电子健康记录（EHR）的结构化数据查询和非结构化文本信息提取方面的应用，并通过检索增强生成（RAG）流程进行优化，结果表明LLMs在临床工作流程中具有进行精确查询和准确信息提取的潜力。", "motivation": "探索大型语言模型（LLMs）在处理电子健康记录（EHR）这一复杂数据源方面的能力，特别是针对结构化数据查询和非结构化文本信息提取这两项基础任务。", "method": "利用LLMs分别执行结构化EHR数据的编程语言（Python/Pandas）查询，以及通过检索增强生成（RAG）管道从临床文本中提取信息。研究开发了一个灵活的评估框架，自动生成与数据集或任务特性相匹配的合成问答对。实验在MIMIC III的一个子集上进行，使用了本地托管和API的LLMs，并通过精确匹配、语义相似度和人工判断进行评估。", "result": "LLMs在精确查询结构化EHR数据和从非结构化临床文本中准确提取信息方面表现出潜力。实验结合了多种评估指标，证明了LLMs在这些任务上的可靠性。", "conclusion": "LLMs有能力辅助临床工作流程，实现对EHR数据的精确查询和准确的信息提取，为医疗数据科学的应用开辟了新的可能性。"}}
{"id": "2601.20461", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20461", "abs": "https://arxiv.org/abs/2601.20461", "authors": ["Yanzhu Liu", "Xiao Liu", "Yuexuan Wang", "Mondal Soumik"], "title": "Exploiting the Final Component of Generator Architectures for AI-Generated Image Detection", "comment": null, "summary": "With the rapid proliferation of powerful image generators, accurate detection of AI-generated images has become essential for maintaining a trustworthy online environment. However, existing deepfake detectors often generalize poorly to images produced by unseen generators. Notably, despite being trained under vastly different paradigms, such as diffusion or autoregressive modeling, many modern image generators share common final architectural components that serve as the last stage for converting intermediate representations into images. Motivated by this insight, we propose to \"contaminate\" real images using the generator's final component and train a detector to distinguish them from the original real images. We further introduce a taxonomy based on generators' final components and categorize 21 widely used generators accordingly, enabling a comprehensive investigation of our method's generalization capability. Using only 100 samples from each of three representative categories, our detector-fine-tuned on the DINOv3 backbone-achieves an average accuracy of 98.83% across 22 testing sets from unseen generators.", "AI": {"tldr": "研究提出一种新颖的AI生成图像检测方法，通过“污染”真实图像并训练检测器来区分AI生成图像，并在21种生成器上验证了该方法的泛化能力，平均准确率高达98.83%。", "motivation": "现有AI生成图像检测器对未见过生成器泛化能力差，但许多现代生成器（包括扩散模型和自回归模型）在最后阶段使用相似的架构组件将中间表示转换为图像。", "method": "作者提出一种“污染”真实图像的方法，即利用生成器的最终组件处理真实图像，然后训练一个检测器来区分这些被污染的真实图像与原始真实图像。此外，他们还对21种常用生成器进行了分类，以全面评估方法的泛化能力。", "result": "使用从三个代表性类别中各100个样本进行训练，在DINOv3骨干网络上微调的检测器，在22个来自未见过生成器的测试集上实现了平均98.83%的准确率。", "conclusion": "该方法通过利用生成器最终组件的共享特性，能够有效地检测AI生成图像，并表现出优异的泛化能力，克服了现有检测器在面对新生成器时的不足。"}}
{"id": "2601.20689", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20689", "abs": "https://arxiv.org/abs/2601.20689", "authors": ["Xinyue Li", "Zhichao Zhang", "Zhiming Xu", "Shubo Xu", "Xiongkuo Min", "Yitong Chen", "Guangtao Zhai"], "title": "Decoupling Perception and Calibration: Label-Efficient Image Quality Assessment Framework", "comment": null, "summary": "Recent multimodal large language models (MLLMs) have demonstrated strong capabilities in image quality assessment (IQA) tasks. However, adapting such large-scale models is computationally expensive and still relies on substantial Mean Opinion Score (MOS) annotations. We argue that for MLLM-based IQA, the core bottleneck lies not in the quality perception capacity of MLLMs, but in MOS scale calibration. Therefore, we propose LEAF, a Label-Efficient Image Quality Assessment Framework that distills perceptual quality priors from an MLLM teacher into a lightweight student regressor, enabling MOS calibration with minimal human supervision. Specifically, the teacher conducts dense supervision through point-wise judgments and pair-wise preferences, with an estimate of decision reliability. Guided by these signals, the student learns the teacher's quality perception patterns through joint distillation and is calibrated on a small MOS subset to align with human annotations. Experiments on both user-generated and AI-generated IQA benchmarks demonstrate that our method significantly reduces the need for human annotations while maintaining strong MOS-aligned correlations, making lightweight IQA practical under limited annotation budgets.", "AI": {"tldr": "提出了一种名为 LEAF 的标签高效图像质量评估框架，通过蒸馏 MLLM 的感知质量先验到一个轻量级学生模型，实现了低监督的 MOS 校准。", "motivation": "现有 MLLM 在 IQA 任务中表现出色，但其适应性计算成本高且需要大量 MOS 注释。研究认为瓶颈在于 MOS 尺度校准而非 MLLM 的感知能力。", "method": "LEAF 框架通过 MLLM 教师模型对图像进行密集监督（点状判断和对偶偏好），并估计决策可靠性。学生模型通过联合蒸馏学习教师的感知模式，并在少量 MOS 数据集上进行校准。", "result": "LEAF 在用户生成和 AI 生成的 IQA 基准测试中，显著减少了对人类注释的需求，同时保持了与 MOS 强相关的一致性。", "conclusion": "LEAF 框架使得在有限注释预算下实现轻量级 IQA 成为可能，有效地解决了 MLLM-IQA 中的 MOS 校准问题。"}}
{"id": "2601.20312", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20312", "abs": "https://arxiv.org/abs/2601.20312", "authors": ["Kaiyuan Chen", "Guangmin Zheng", "Jin Wang", "Xiaobing Zhou", "Xuejie Zhang"], "title": "SAPO: Self-Adaptive Process Optimization Makes Small Reasoners Stronger", "comment": "Accepted by AAAI 2026", "summary": "Existing self-evolution methods overlook the influence of fine-grained reasoning steps, which leads to the reasoner-verifier gap. The computational inefficiency of Monte Carlo (MC) process supervision further exacerbates the difficulty in mitigating the gap. Motivated by the Error-Related Negativity (ERN), which the reasoner can localize error following incorrect decisions, guiding rapid adjustments, we propose a Self-Adaptive Process Optimization (SAPO) method for self-improvement in Small Language Models (SLMs). SAPO adaptively and efficiently introduces process supervision signals by actively minimizing the reasoner-verifier gap rather than relying on inefficient MC estimations. Extensive experiments demonstrate that the proposed method outperforms most existing self-evolution methods on two challenging task types: mathematics and code. Additionally, to further investigate SAPO's impact on verifier performance, this work introduces two new benchmarks for process reward models in both mathematical and coding tasks.", "AI": {"tldr": "本文提出了一种名为SAPO（Self-Adaptive Process Optimization）的方法，通过借鉴ERN（Error-Related Negativity）的思路，自适应地引入过程监督信号，以减小语言模型（特别是小型语言模型）在推理和验证阶段之间的差距，从而提高其在数学和代码等任务上的表现。", "motivation": "现有的自进化方法忽略了细粒度推理步骤的影响，导致推理器-验证器之间存在差距，并且基于蒙特卡洛（MC）的过程监督计算效率低下。作者受到ERN（错误相关负性）的启发，该信号能帮助推理器定位错误并快速调整，从而提出SAPO方法来解决这些问题。", "method": "SAPO方法通过自适应地引入过程监督信号来主动最小化推理器-验证器差距，而不是依赖于低效的MC估计。它借鉴了ERN的原理，使推理器能够根据错误决策进行快速调整。", "result": "SAPO方法在数学和代码两类具有挑战性的任务上，表现优于大多数现有的自进化方法。此外，为了评估SAPO对验证器性能的影响，作者还引入了两个新的数学和代码任务过程奖励模型基准。", "conclusion": "SAPO是一种有效且高效的自适应过程优化方法，能够显著提升小型语言模型在复杂推理任务（如数学和代码）上的性能，并通过引入新的基准来促进对验证器性能的研究。"}}
{"id": "2601.20504", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20504", "abs": "https://arxiv.org/abs/2601.20504", "authors": ["Meiqi Wu", "Bingze Song", "Ruimin Lin", "Chen Zhu", "Xiaokun Feng", "Jiahong Wu", "Xiangxiang Chu", "Kaiqi Huang"], "title": "Latent Temporal Discrepancy as Motion Prior: A Loss-Weighting Strategy for Dynamic Fidelity in T2V", "comment": "Accepted by ICASSP 2026", "summary": "Video generation models have achieved notable progress in static scenarios, yet their performance in motion video generation remains limited, with quality degrading under drastic dynamic changes. This is due to noise disrupting temporal coherence and increasing the difficulty of learning dynamic regions. {Unfortunately, existing diffusion models rely on static loss for all scenarios, constraining their ability to capture complex dynamics.} To address this issue, we introduce Latent Temporal Discrepancy (LTD) as a motion prior to guide loss weighting. LTD measures frame-to-frame variation in the latent space, assigning larger penalties to regions with higher discrepancy while maintaining regular optimization for stable regions. This motion-aware strategy stabilizes training and enables the model to better reconstruct high-frequency dynamics. Extensive experiments on the general benchmark VBench and the motion-focused VMBench show consistent gains, with our method outperforming strong baselines by 3.31% on VBench and 3.58% on VMBench, achieving significant improvements in motion quality.", "AI": {"tldr": "提出了一种名为潜在时间差异（LTD）的运动先验，用于改进视频生成模型在动态场景下的性能，通过加权损失来关注帧间差异大的区域，从而提高运动视频生成的质量。", "motivation": "现有视频生成模型在处理剧烈动态变化时，由于噪声干扰和动态区域学习困难，视频质量会下降。现有的扩散模型依赖于静态损失，无法有效捕捉复杂动态。", "method": "引入了潜在时间差异（LTD）作为运动先验来指导损失加权。LTD通过度量潜在空间中的帧间变化，对差异大的区域施加更大的惩罚，对稳定区域则保持常规优化。", "result": "在VBench和VMBench基准测试中，所提出的方法取得了显著的性能提升，在VBench上超越现有方法3.31%，在VMBench上超越3.58%，尤其在运动质量方面。", "conclusion": "LTD是一种有效的运动先验，通过关注帧间差异，可以稳定扩散模型的训练，并显著提高运动视频生成质量，尤其是在处理高频动态方面。"}}
{"id": "2601.20330", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20330", "abs": "https://arxiv.org/abs/2601.20330", "authors": ["Zhuang Chen", "Dazhen Wan", "Zhangkai Zheng", "Guanqun Bi", "Xiyao Xiao", "Binghang Li", "Minlie Huang"], "title": "PsychePass: Calibrating LLM Therapeutic Competence via Trajectory-Anchored Tournaments", "comment": null, "summary": "While large language models show promise in mental healthcare, evaluating their therapeutic competence remains challenging due to the unstructured and longitudinal nature of counseling. We argue that current evaluation paradigms suffer from an unanchored defect, leading to two forms of instability: process drift, where unsteered client simulation wanders away from specific counseling goals, and standard drift, where static pointwise scoring lacks the stability for reliable judgment. To address this, we introduce Ps, a unified framework that calibrates the therapeutic competence of LLMs via trajectory-anchored tournaments. We first anchor the interaction trajectory in simulation, where clients precisely control the fluid consultation process to probe multifaceted capabilities. We then anchor the battle trajectory in judgments through an efficient Swiss-system tournament, utilizing dynamic pairwise battles to yield robust Elo ratings. Beyond ranking, we demonstrate that tournament trajectories can be transformed into credible reward signals, enabling on-policy reinforcement learning to enhance LLMs' performance. Extensive experiments validate the effectiveness of PsychePass and its strong consistency with human expert judgments.", "AI": {"tldr": "本文提出了一种名为 PsychePass 的新框架，用于评估大型语言模型 (LLM) 在心理健康护理中的治疗能力。该框架通过模拟的交互轨迹和基于锦标赛的评估来解决现有评估方法中存在的“过程漂移”和“标准漂移”问题，并能将评估结果转化为强化学习信号以提升 LLM 性能。", "motivation": "现有的评估大型语言模型在心理健康护理中的能力的方法存在不足，无法应对咨询过程的非结构化和纵向特性，导致“过程漂移”（模拟客户偏离咨询目标）和“标准漂移”（静态评分不稳定）。", "method": "提出 PsychePass 框架，该框架通过以下方式校准 LLM 的治疗能力：1. 通过模拟锚定交互轨迹，让客户精确控制咨询过程以探测 LLM 的多方面能力；2. 通过高效的瑞士系统锦标赛锚定判断轨迹，利用动态配对对战产生稳定的 Elo 评分。", "result": "PsychePass 框架能有效评估 LLM 的治疗能力，其评估结果与人类专家的判断高度一致。此外，锦标赛轨迹可以转化为可靠的奖励信号，用于增强学习，从而提升 LLM 的性能。", "conclusion": "PsychePass 框架提供了一种稳定且可信的评估 LLM 在心理健康领域治疗能力的方法，并通过转化为奖励信号促进了 LLM 的性能提升，该方法与人类专家的判断保持一致。"}}
{"id": "2601.20705", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20705", "abs": "https://arxiv.org/abs/2601.20705", "authors": ["Zhuang Yu", "Lei Shen", "Jing Zhao", "Shiliang Sun"], "title": "LEMON: How Well Do MLLMs Perform Temporal Multimodal Understanding on Instructional Videos?", "comment": null, "summary": "Recent multimodal large language models (MLLMs) have shown remarkable progress across vision, audio, and language tasks, yet their performance on long-form, knowledge-intensive, and temporally structured educational content remains largely unexplored. To bridge this gap, we introduce LEMON, a Lecture-based Evaluation benchmark for MultimOdal uNderstanding, focusing on STEM lecture videos that require long-horizon reasoning and cross-modal integration. LEMON comprises 2,277 video segments spanning 5 disciplines and 29 courses, with an average duration of 196.1 seconds, yielding 4,181 high-quality QA pairs, including 3,413 multiple-choice and 768 open-ended questions. Distinct from existing video benchmarks, LEMON features: (1) semantic richness and disciplinary density, (2) tightly coupled video-audio-text modalities, (3) explicit temporal and pedagogical structure, and (4) contextually linked multi-turn questioning. It further encompasses six major tasks and twelve subtasks, covering the full cognitive spectrum from perception to reasoning and then to generation. Comprehensive experiments reveal substantial performance gaps across tasks, highlighting that even state-of-the-art MLLMs like GPT-4o struggle with temporal reasoning and instructional prediction. We expect LEMON to serve as an extensible and challenging benchmark for advancing multimodal perception, reasoning, and generation in long-form instructional contents.", "AI": {"tldr": "本研究提出了LEMON，一个针对STEM讲座视频的多模态理解评估基准，以解决现有基准在长篇幅、知识密集型和时间结构化教育内容上的不足。LEMON包含大量的视频片段、高质量问答对，并设计了多样的评估任务，旨在推动长篇幅教学内容的跨模态感知、推理和生成能力。", "motivation": "现有的大型多模态语言模型（MLLMs）在处理长篇幅、知识密集型和时间结构化的教育内容方面表现不足，因此需要一个专门的基准来评估和改进模型在这方面的能力。", "method": "构建了一个名为LEMON的评估基准，该基准包含2,277个STEM讲座视频片段，总时长达4,181个问答对（包括选择题和开放题）。LEMON的特点是语义丰富、跨学科、多模态耦合紧密、具有明确的时间和教学结构，并支持多轮问答。基准涵盖了从感知到推理再到生成等六个主要任务和十二个子任务。", "result": "在LEMON基准上的实验表明，即使是像GPT-4o这样的最先进MLLMs，在处理时间推理和教学预测等任务时也存在显著的性能差距。", "conclusion": "LEMON是一个具有挑战性和可扩展性的基准，能够有效推动多模态模型在长篇幅教学内容上的感知、推理和生成能力的进步。"}}
{"id": "2601.20511", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20511", "abs": "https://arxiv.org/abs/2601.20511", "authors": ["Zelong Sun", "Jiahui Wu", "Ying Ba", "Dong Jing", "Zhiwu Lu"], "title": "Say Cheese! Detail-Preserving Portrait Collection Generation via Natural Language Edits", "comment": null, "summary": "As social media platforms proliferate, users increasingly demand intuitive ways to create diverse, high-quality portrait collections. In this work, we introduce Portrait Collection Generation (PCG), a novel task that generates coherent portrait collections by editing a reference portrait image through natural language instructions. This task poses two unique challenges to existing methods: (1) complex multi-attribute modifications such as pose, spatial layout, and camera viewpoint; and (2) high-fidelity detail preservation including identity, clothing, and accessories. To address these challenges, we propose CHEESE, the first large-scale PCG dataset containing 24K portrait collections and 573K samples with high-quality modification text annotations, constructed through an Large Vison-Language Model-based pipeline with inversion-based verification. We further propose SCheese, a framework that combines text-guided generation with hierarchical identity and detail preservation. SCheese employs adaptive feature fusion mechanism to maintain identity consistency, and ConsistencyNet to inject fine-grained features for detail consistency. Comprehensive experiments validate the effectiveness of CHEESE in advancing PCG, with SCheese achieving state-of-the-art performance.", "AI": {"tldr": "该论文提出了一个名为肖像集生成（PCG）的新任务，旨在通过自然语言指令编辑参考肖像来生成一致的肖像集合，并为此构建了一个名为CHEESE的大规模数据集。他们还提出了一个名为SSCheese的框架，该框架结合了文本引导生成和分层身份及细节保持技术，以应对PCG的挑战。", "motivation": "随着社交媒体的普及，用户需要直观的方式来创建多样化、高质量的肖像集。现有的方法在处理复杂的多属性修改（如姿势、空间布局、视角）和高保真细节（如身份、服装、配饰）方面存在挑战。", "method": "论文提出了一个名为CHEESE的大规模数据集，包含24K个肖像集和573K个样本，并使用了基于大型视觉-语言模型的管道和基于逆向验证的方法来构建。他们还提出了一个名为SSCheese的框架，该框架结合了文本引导生成与分层身份和细节保持。SSCheese使用了自适应特征融合机制来保持身份一致性，并使用ConsistencyNet注入细粒度特征以实现细节一致性。", "result": "CHEESE数据集被证明在推进PCG任务方面有效。SSCheese框架在PCG任务上取得了最先进的性能。", "conclusion": "该研究提出了PCG新任务、大规模数据集CHEESE以及有效的SSCheese框架，解决了肖像集生成中的复杂多属性修改和高保真细节保持的挑战，并取得了优于现有方法的性能。"}}
{"id": "2601.20339", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20339", "abs": "https://arxiv.org/abs/2601.20339", "authors": ["Yangyi Shen", "Tianjian Feng", "Jiaqi Han", "Wen Wang", "Tianlang Chen", "Chunhua Shen", "Jure Leskovec", "Stefano Ermon"], "title": "Improving Diffusion Language Model Decoding through Joint Search in Generation Order and Token Space", "comment": null, "summary": "Diffusion Language Models (DLMs) offer order-agnostic generation that can explore many possible decoding trajectories. However, current decoding methods commit to a single trajectory, limiting exploration in trajectory space. We introduce Order-Token Search to explore this space through jointly searching over generation order and token values. Its core is a likelihood estimator that scores denoising actions, enabling stable pruning and efficient exploration of diverse trajectories. Across mathematical reasoning and coding benchmarks, Order-Token Search consistently outperforms baselines on GSM8K, MATH500, Countdown, and HumanEval (3.1%, 3.8%, 7.9%, and 6.8% absolute over backbone), matching or surpassing diffu-GRPO post-trained d1-LLaDA. Our work establishes joint search as a key component for advancing decoding in DLMs.", "AI": {"tldr": "本文提出了一种名为“Order-Token Search”的新解码方法，用于解决扩散语言模型（DLM）在解码过程中仅探索单一轨迹的局限性。该方法通过联合搜索生成顺序和词元值来探索更广阔的轨迹空间，并在数学推理和代码生成任务上取得了显著的性能提升。", "motivation": "现有的扩散语言模型（DLM）在解码时倾向于固定生成顺序，只探索单一的解码轨迹，这限制了模型在轨迹空间中的探索能力。", "method": "提出Order-Token Search方法，通过一个似然估计器来评估去噪动作，从而稳定地进行剪枝并高效地探索不同的解码轨迹。该方法联合搜索生成顺序和词元值。", "result": "在GSM8K、MATH500、Countdown和HumanEval等数学推理和代码生成基准测试中，Order-Token Search的表现优于现有基线方法（分别提升3.1%、3.8%、7.9%和6.8%），并且与经过diffu-GRPO后训练的d1-LLaDA相当或更优。", "conclusion": "联合搜索（joint search）是提升DLM解码能力的关键组成部分，Order-Token Search的提出为DLM的解码策略提供了新的方向。"}}
{"id": "2601.20520", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20520", "abs": "https://arxiv.org/abs/2601.20520", "authors": ["Qiyan Zhao", "Xiaofeng Zhang", "Shuochen Chang", "Qianyu Chen", "Xiaosong Yuan", "Xuhang Chen", "Luoqi Liu", "Jiajun Zhang", "Xu-Yao Zhang", "Da-Han Wang"], "title": "Context Tokens are Anchors: Understanding the Repetition Curse in dMLLMs from an Information Flow Perspective", "comment": "Accepted in ICLR 2026", "summary": "Recent diffusion-based Multimodal Large Language Models (dMLLMs) suffer from high inference latency and therefore rely on caching techniques to accelerate decoding. However, the application of cache mechanisms often introduces undesirable repetitive text generation, a phenomenon we term the \\textbf{Repeat Curse}. To better investigate underlying mechanism behind this issue, we analyze repetition generation through the lens of information flow. Our work reveals three key findings: (1) context tokens aggregate semantic information as anchors and guide the final predictions; (2) as information propagates across layers, the entropy of context tokens converges in deeper layers, reflecting the model's growing prediction certainty; (3) Repetition is typically linked to disruptions in the information flow of context tokens and to the inability of their entropy to converge in deeper layers. Based on these insights, we present \\textbf{CoTA}, a plug-and-play method for mitigating repetition. CoTA enhances the attention of context tokens to preserve intrinsic information flow patterns, while introducing a penalty term to the confidence score during decoding to avoid outputs driven by uncertain context tokens. With extensive experiments, CoTA demonstrates significant effectiveness in alleviating repetition and achieves consistent performance improvements on general tasks. Code is available at https://github.com/ErikZ719/CoTA", "AI": {"tldr": "本文提出了一种名为CoTA的即插即用方法，用于解决基于扩散的多模态大语言模型（dMLLMs）在利用缓存加速解码时产生的“重复诅咒”问题，通过增强上下文token的注意力并引入置信度惩罚项来减轻重复生成，并在通用任务上取得了显著的性能提升。", "motivation": "dMLLMs在加速解码时依赖缓存技术，但这常常导致不理想的重复文本生成（“重复诅咒”）。研究者希望深入理解这一现象的机制并提出解决方案。", "method": "1. 通过信息流分析，研究上下文token如何聚合语义信息、信息如何在层间传播以及重复生成与信息流和熵收敛的关系。 2. 提出CoTA方法，通过增强上下文token的注意力以保持信息流模式，并引入解码过程中的置信度得分惩罚项，避免受不确定上下文token驱动的输出。", "result": "CoTA在减轻重复生成方面表现出显著的有效性，并在通用任务上实现了持续的性能提升。实验证明了该方法的有效性。", "conclusion": "基于对信息流和熵收敛的分析，CoTA是一种有效的缓解dMLLMs重复生成问题的方法，能够提升生成质量和通用任务的性能。"}}
{"id": "2601.20524", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20524", "abs": "https://arxiv.org/abs/2601.20524", "authors": ["Matic Fučka", "Vitjan Zavrtanik", "Danijel Skočaj"], "title": "AnomalyVFM -- Transforming Vision Foundation Models into Zero-Shot Anomaly Detectors", "comment": null, "summary": "Zero-shot anomaly detection aims to detect and localise abnormal regions in the image without access to any in-domain training images. While recent approaches leverage vision-language models (VLMs), such as CLIP, to transfer high-level concept knowledge, methods based on purely vision foundation models (VFMs), like DINOv2, have lagged behind in performance. We argue that this gap stems from two practical issues: (i) limited diversity in existing auxiliary anomaly detection datasets and (ii) overly shallow VFM adaptation strategies. To address both challenges, we propose AnomalyVFM, a general and effective framework that turns any pretrained VFM into a strong zero-shot anomaly detector. Our approach combines a robust three-stage synthetic dataset generation scheme with a parameter-efficient adaptation mechanism, utilising low-rank feature adapters and a confidence-weighted pixel loss. Together, these components enable modern VFMs to substantially outperform current state-of-the-art methods. More specifically, with RADIO as a backbone, AnomalyVFM achieves an average image-level AUROC of 94.1% across 9 diverse datasets, surpassing previous methods by significant 3.3 percentage points. Project Page: https://maticfuc.github.io/anomaly_vfm/", "AI": {"tldr": "本文提出了一种名为AnomalyVFM的通用框架，通过生成合成数据集和高效的模型适配策略，显著提升了纯视觉基础模型（VFMs）在零样本异常检测任务上的性能，超越了现有最先进方法。", "motivation": "现有基于纯视觉基础模型（VFMs）的零样本异常检测方法性能不如基于视觉语言模型（VLMs）的方法，主要归因于现有辅助数据集多样性不足和VFM适配策略过于浅层。", "method": "AnomalyVFM框架结合了三阶段合成数据集生成方案和参数高效的适配机制（低秩特征适配器和置信度加权像素损失），以增强预训练VFM的零样本异常检测能力。", "result": "使用RADIO作为骨干模型，AnomalyVFM在9个多样化数据集上实现了平均94.1%的图像级AUROC，比之前的方法平均提高了3.3个百分点。", "conclusion": "AnomalyVFM成功地解决了现有零样本异常检测方法在数据集多样性和模型适配上的局限性，证明了通过合理的策略，纯VFM也能在零样本异常检测任务上达到领先水平。"}}
{"id": "2601.20412", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.20412", "abs": "https://arxiv.org/abs/2601.20412", "authors": ["Qihao Wang", "Yue Hu", "Mingzhe Lu", "Jiayue Wu", "Yanbing Liu", "Yuanmin Tang"], "title": "Beyond Accuracy: A Cognitive Load Framework for Mapping the Capability Boundaries of Tool-use Agents", "comment": "Accepted to AAAI 2026", "summary": "The ability of Large Language Models (LLMs) to use external tools unlocks powerful real-world interactions, making rigorous evaluation essential. However, current benchmarks primarily report final accuracy, revealing what models can do but obscuring the cognitive bottlenecks that define their true capability boundaries. To move from simple performance scoring to a diagnostic tool, we introduce a framework grounded in Cognitive Load Theory. Our framework deconstructs task complexity into two quantifiable components: Intrinsic Load, the inherent structural complexity of the solution path, formalized with a novel Tool Interaction Graph; and Extraneous Load, the difficulty arising from ambiguous task presentation. To enable controlled experiments, we construct ToolLoad-Bench, the first benchmark with parametrically adjustable cognitive load. Our evaluation reveals distinct performance cliffs as cognitive load increases, allowing us to precisely map each model's capability boundary. We validate that our framework's predictions are highly calibrated with empirical results, establishing a principled methodology for understanding an agent's limits and a practical foundation for building more efficient systems.", "AI": {"tldr": "本研究提出了一个基于认知负荷理论的框架，用于评估大型语言模型（LLMs）使用外部工具的能力，通过量化任务的内在和外在复杂性，并构建了一个名为ToolLoad-Bench的基准测试，以精确描绘模型的性能边界。", "motivation": "现有的大型语言模型（LLMs）工具使用评估主要关注最终准确性，这阻碍了我们理解模型的真正能力边界和瓶颈。研究者希望从简单的性能评分转向诊断性工具，以更好地理解和提升LLM的能力。", "method": "该研究框架基于认知负荷理论，将任务复杂性分解为内在负荷（通过新的工具交互图形式化）和外在负荷（由任务表述的模糊性引起）。为此，研究者构建了ToolLoad-Bench，一个首个具有参数化可调认知负荷的基准测试，用于进行受控实验。", "result": "评估结果表明，随着认知负荷的增加，模型的性能会出现明显的下降（performance cliffs），这使得研究者能够精确地绘制出每个模型的性能边界。框架的预测与实证结果高度吻合。", "conclusion": "该研究提出了一种理解LLM能力极限的原则性方法，并为构建更高效的系统奠定了实践基础。通过量化认知负荷，可以更深入地诊断模型的瓶颈，并指导未来的模型开发。"}}
{"id": "2601.20791", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20791", "abs": "https://arxiv.org/abs/2601.20791", "authors": ["Haonan Zhong", "Wei Song", "Tingxu Han", "Maurice Pagnucco", "Jingling Xue", "Yang Song"], "title": "FAIRT2V: Training-Free Debiasing for Text-to-Video Diffusion Models", "comment": null, "summary": "Text-to-video (T2V) diffusion models have achieved rapid progress, yet their demographic biases, particularly gender bias, remain largely unexplored. We present FairT2V, a training-free debiasing framework for text-to-video generation that mitigates encoder-induced bias without finetuning. We first analyze demographic bias in T2V models and show that it primarily originates from pretrained text encoders, which encode implicit gender associations even for neutral prompts. We quantify this effect with a gender-leaning score that correlates with bias in generated videos.\n  Based on this insight, FairT2V mitigates demographic bias by neutralizing prompt embeddings via anchor-based spherical geodesic transformations while preserving semantics. To maintain temporal coherence, we apply debiasing only during early identity-forming steps through a dynamic denoising schedule. We further propose a video-level fairness evaluation protocol combining VideoLLM-based reasoning with human verification. Experiments on the modern T2V model Open-Sora show that FairT2V substantially reduces demographic bias across occupations with minimal impact on video quality.", "AI": {"tldr": "提出了一种名为FairT2V的训练无关的去偏框架，用于文本到视频生成，通过中和提示嵌入来解决预训练文本编码器引起的性别偏见，同时保持语义和时间连贯性。", "motivation": "现有的文本到视频（T2V）扩散模型在人口统计学偏见，特别是性别偏见方面，仍然很大程度上未被探索。", "method": "FairT2V通过锚点球形测地线变换来中和提示嵌入，以缓解文本编码器引起的偏见。为了保持时间连贯性，在动态去噪计划下，仅在早期身份形成步骤中应用去偏。此外，还提出了一种结合VideoLLM推理和人工验证的视频级公平性评估协议。", "result": "在现代T2V模型Open-Sora上的实验表明，FairT2V在不同职业上显著降低了人口统计学偏见，同时对视频质量的影响最小。", "conclusion": "FairT2V是一种有效的、无需微调的去偏框架，可以成功缓解T2V模型中的人口统计学偏见，同时保持语义完整性和视频质量。"}}
{"id": "2601.20731", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.20731", "abs": "https://arxiv.org/abs/2601.20731", "authors": ["Mae Sosto", "Delfina Sol Martinez Pandiani", "Laura Hollink"], "title": "QueerGen: How LLMs Reflect Societal Norms on Gender and Sexuality in Sentence Completion Tasks", "comment": null, "summary": "This paper examines how Large Language Models (LLMs) reproduce societal norms, particularly heterocisnormativity, and how these norms translate into measurable biases in their text generations. We investigate whether explicit information about a subject's gender or sexuality influences LLM responses across three subject categories: queer-marked, non-queer-marked, and the normalized \"unmarked\" category. Representational imbalances are operationalized as measurable differences in English sentence completions across four dimensions: sentiment, regard, toxicity, and prediction diversity. Our findings show that Masked Language Models (MLMs) produce the least favorable sentiment, higher toxicity, and more negative regard for queer-marked subjects. Autoregressive Language Models (ARLMs) partially mitigate these patterns, while closed-access ARLMs tend to produce more harmful outputs for unmarked subjects. Results suggest that LLMs reproduce normative social assumptions, though the form and degree of bias depend strongly on specific model characteristics, which may redistribute, but not eliminate, representational harms.", "AI": {"tldr": "本文研究了大型语言模型（LLMs）如何复制社会规范，特别是异性恋规范，并导致文本生成中的可衡量偏见。研究发现，不同类型的LLMs（MLMs、ARLMs、闭源ARLMs）对带有性别或性取向标记的主题（如酷儿群体）会产生负面影响，如情感偏见、毒性增加和负面评价，而闭源ARLMs对“非标记”主题的危害更大。模型特性显著影响偏见的程度和形式。", "motivation": "研究动机在于探究大型语言模型（LLMs）在文本生成中是否会复制和加剧社会规范，特别是异性恋规范，并量化这种偏见。", "method": "研究通过在三种标记类别（酷儿标记、非酷儿标记和正常化“非标记”）的主题上，测试LLMs在接收到明确的性别或性取向信息时，其英语句子补全的四个维度（情感、评价、毒性、预测多样性）是否存在差异。使用了MLMs、ARLMs和闭源ARLMs模型。", "result": "MLMs对酷儿标记的主题产生最不利的情感、更高的毒性和更负面的评价。ARLMs在一定程度上缓解了这些模式。闭源ARLMs对“非标记”主题产生了更有害的输出。", "conclusion": "LLMs会复制社会规范的假设，但偏见的具体表现和程度高度依赖于模型的特性，这些特性可能重新分配但不能消除代表性伤害。"}}
{"id": "2601.20417", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20417", "abs": "https://arxiv.org/abs/2601.20417", "authors": ["Biswesh Mohapatra", "Marcely Zanon Boito", "Ioan Calapodescu"], "title": "SpeechMapper: Speech-to-text Embedding Projector for LLMs", "comment": "Accepted to ICASSP 2026", "summary": "Current speech LLMs bridge speech foundation models to LLMs using projection layers, training all of these components on speech instruction data. This strategy is computationally intensive and susceptible to task and prompt overfitting. We present SpeechMapper, a cost-efficient speech-to-LLM-embedding training approach that mitigates overfitting, enabling more robust and generalizable models. Our model is first pretrained without the LLM on inexpensive hardware, and then efficiently attached to the target LLM via a brief 1K-step instruction tuning (IT) stage. Through experiments on speech translation and spoken question answering, we demonstrate the versatility of SpeechMapper's pretrained block, presenting results for both task-agnostic IT, an ASR-based adaptation strategy that does not train in the target task, and task-specific IT. In task-agnostic settings, Speechmapper rivals the best instruction-following speech LLM from IWSLT25, despite never being trained on these tasks, while in task-specific settings, it outperforms this model across many datasets, despite requiring less data and compute. Overall, SpeechMapper offers a practical and scalable approach for efficient, generalizable speech-LLM integration without large-scale IT.", "AI": {"tldr": "SpeechMapper 是一种高效的语音到 LLM 嵌入训练方法，通过预训练语音模块并在少量指令调优（IT）阶段将其连接到目标 LLM，以减少计算成本和过拟合。", "motivation": "现有的语音 LLM 方法计算成本高，并且容易出现任务和提示过拟合。研究人员希望开发一种更具成本效益、更能抵抗过拟合的方法，从而实现更鲁棒和通用的模型。", "method": "SpeechMapper 首先在廉价硬件上预训练语音模块，然后通过简短的 1K 步指令调优（IT）阶段将其高效地连接到目标 LLM。实验了任务无关 IT、基于 ASR 的适应策略（不针对目标任务进行训练）以及任务特定 IT。", "result": "在语音翻译和口语问答任务上，SpeechMapper 的预训练模块展示了其多功能性。在任务无关设置下，SpeechMapper 的表现与 IWSLT25 上最好的指令遵循语音 LLM 相当，尽管它从未针对这些任务进行过训练。在任务特定设置下，SpeechMapper 即使使用更少的数据和计算量，其性能也优于该模型。", "conclusion": "SpeechMapper 提供了一种实用且可扩展的方法，可以在无需大规模 IT 的情况下实现高效、通用的语音-LLM 集成，从而克服了计算密集和过拟合的挑战。"}}
{"id": "2601.20526", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20526", "abs": "https://arxiv.org/abs/2601.20526", "authors": ["Shaokun Wang", "Yifan Yu", "Yuhang He", "Weili Guan", "Yihong Gong"], "title": "IOTA: Corrective Knowledge-Guided Prompt Learning via Black-White Box Framework", "comment": null, "summary": "Recently, adapting pre-trained models to downstream tasks has attracted increasing interest. Previous Parameter-Efficient-Tuning (PET) methods regard the pre-trained model as an opaque Black Box model, relying purely on data-driven optimization and underutilizing their inherent prior knowledge. This oversight limits the models' potential for effective downstream task adaptation. To address these issues, we propose a novel black-whIte bOx prompT leArning framework (IOTA), which integrates a data-driven Black Box module with a knowledge-driven White Box module for downstream task adaptation. Specifically, the White Box module derives corrective knowledge by contrasting the wrong predictions with the right cognition. This knowledge is verbalized into interpretable human prompts and leveraged through a corrective knowledge-guided prompt selection strategy to guide the Black Box module toward more accurate predictions. By jointly leveraging knowledge- and data-driven learning signals, IOTA achieves effective downstream task adaptation. Experimental results on 12 image classification benchmarks under few-shot and easy-to-hard adaptation settings demonstrate the effectiveness of corrective knowledge and the superiority of our method over state-of-the-art methods.", "AI": {"tldr": "提出了一种名为IOTA的新型框架，结合了数据驱动的黑盒模块和知识驱动的白盒模块，用于下游任务的参数高效调优，并通过生成可解释的提示来引导模型。", "motivation": "现有的参数高效调优（PET）方法将预训练模型视为黑盒，仅依赖数据驱动优化，未能充分利用其内在先验知识，限制了模型在下游任务中的适应潜力。", "method": "IOTA框架包含一个数据驱动的黑盒模块和一个知识驱动的白盒模块。白盒模块通过对比错误预测与正确认知来获取纠正知识，并将这些知识转化为可解释的人类提示。随后，采用一种纠正知识引导的提示选择策略来指导黑盒模块进行更准确的预测。", "result": "在12个图像分类基准测试中，包括少样本和易到难的适应场景，实验结果证明了纠正知识的有效性，并表明IOTA方法优于最先进的方法。", "conclusion": "通过联合利用知识驱动和数据驱动的学习信号，IOTA能够实现有效的下游任务适应，并且在图像分类任务上表现出色。"}}
{"id": "2601.20835", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20835", "abs": "https://arxiv.org/abs/2601.20835", "authors": ["Jie Liu", "Yu Sun", "Alpar Cseke", "Yao Feng", "Nicolas Heron", "Michael J. Black", "Yan Zhang"], "title": "Open-Vocabulary Functional 3D Human-Scene Interaction Generation", "comment": "18 pages", "summary": "Generating 3D humans that functionally interact with 3D scenes remains an open problem with applications in embodied AI, robotics, and interactive content creation. The key challenge involves reasoning about both the semantics of functional elements in 3D scenes and the 3D human poses required to achieve functionality-aware interaction. Unfortunately, existing methods typically lack explicit reasoning over object functionality and the corresponding human-scene contact, resulting in implausible or functionally incorrect interactions. In this work, we propose FunHSI, a training-free, functionality-driven framework that enables functionally correct human-scene interactions from open-vocabulary task prompts. Given a task prompt, FunHSI performs functionality-aware contact reasoning to identify functional scene elements, reconstruct their 3D geometry, and model high-level interactions via a contact graph. We then leverage vision-language models to synthesize a human performing the task in the image and estimate proposed 3D body and hand poses. Finally, the proposed 3D body configuration is refined via stage-wise optimization to ensure physical plausibility and functional correctness. In contrast to existing methods, FunHSI not only synthesizes more plausible general 3D interactions, such as \"sitting on a sofa'', while supporting fine-grained functional human-scene interactions, e.g., \"increasing the room temperature''. Extensive experiments demonstrate that FunHSI consistently generates functionally correct and physically plausible human-scene interactions across diverse indoor and outdoor scenes.", "AI": {"tldr": "提出了一种名为 FunHSI 的新框架，能够生成与 3D 场景进行功能性交互的 3D 人体模型，解决了现有方法在理解物体功能和人体-场景接触方面的不足。", "motivation": "现有方法在生成功能性 3D 人体-场景交互方面存在缺陷，它们缺乏对物体功能的明确推理以及人体与场景的接触，导致交互不合理或功能不正确。", "method": "FunHSI 框架包括：1. 功能感知接触推理，识别功能性场景元素并重建其 3D 几何。2. 通过接触图建模高层交互。3. 利用视觉-语言模型合成执行任务的人体，并估计 3D 身体和手部姿势。4. 通过分阶段优化完善 3D 身体配置，确保物理合理性和功能正确性。", "result": "FunHSI 能够生成更合理的一般性 3D 交互（如“坐在沙发上”），并支持精细的功能性人体-场景交互（如“调高房间温度”）。实验表明，该框架在不同室内外场景中都能生成功能正确且物理上合理的交互。", "conclusion": "FunHSI 是一个无需训练、以功能为驱动的框架，能够根据开放词汇的任务提示，实现功能正确的 3D 人体-场景交互，克服了现有方法的局限性。"}}
{"id": "2601.20424", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20424", "abs": "https://arxiv.org/abs/2601.20424", "authors": ["Anna Ristilä", "Otto Tarkka", "Veronika Laippala", "Kimmo Elo"], "title": "Hopes and Fears -- Emotion Distribution in the Topic Landscape of Finnish Parliamentary Speech 2000-2020", "comment": "27 pages (40 including appendices), 5 figures (13 including sub-figures), 1 table, 1 formula, 3 appendices; submitted to JDMDH", "summary": "Existing research often treats parliamentary discourse as a homogeneous whole, overlooking topic-specific patterns. Parliamentary speeches address a wide range of topics, some of which evoke stronger emotions than others. While everyone has intuitive assumptions about what the most emotive topics in a parliament may be, there has been little research into the emotions typically linked to different topics. This paper strives to fill this gap by examining emotion expression among the topics of parliamentary speeches delivered in Eduskunta, the Finnish Parliament, between 2000 and 2020. An emotion analysis model is used to investigate emotion expression in topics, from both synchronic and diachronic perspectives. The results strengthen evidence of increasing positivity in parliamentary speech and provide further insights into topic-specific emotion expression within parliamentary debate.", "AI": {"tldr": "本研究分析了2000-2020年芬兰议会辩论中，不同话题所表达的情绪模式，并从同步和历时角度进行了研究。", "motivation": "现有研究将议会话语视为同质的整体，忽略了话题特定的情绪模式，而不同话题会引起不同程度的情绪反应，故本研究旨在填补这一研究空白。", "method": "使用情绪分析模型，从同步和历时两个角度，研究芬兰议会（Eduskunta）2000年至2020年间议会演讲中不同话题的情绪表达。", "result": "研究结果加强了议会言论日益积极的证据，并深入揭示了议会辩论中话题特定的情绪表达模式。", "conclusion": "议会言论中存在话题特定的情绪表达模式，并且整体上呈现出积极性增加的趋势。"}}
{"id": "2601.20540", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20540", "abs": "https://arxiv.org/abs/2601.20540", "authors": ["Robbyant Team", "Zelin Gao", "Qiuyu Wang", "Yanhong Zeng", "Jiapeng Zhu", "Ka Leong Cheng", "Yixuan Li", "Hanlin Wang", "Yinghao Xu", "Shuailei Ma", "Yihang Chen", "Jie Liu", "Yansong Cheng", "Yao Yao", "Jiayi Zhu", "Yihao Meng", "Kecheng Zheng", "Qingyan Bai", "Jingye Chen", "Zehong Shen", "Yue Yu", "Xing Zhu", "Yujun Shen", "Hao Ouyang"], "title": "Advancing Open-source World Models", "comment": "Project page: https://technology.robbyant.com/lingbot-world; Code: https://github.com/robbyant/lingbot-world", "summary": "We present LingBot-World, an open-sourced world simulator stemming from video generation. Positioned as a top-tier world model, LingBot-World offers the following features. (1) It maintains high fidelity and robust dynamics in a broad spectrum of environments, including realism, scientific contexts, cartoon styles, and beyond. (2) It enables a minute-level horizon while preserving contextual consistency over time, which is also known as \"long-term memory\". (3) It supports real-time interactivity, achieving a latency of under 1 second when producing 16 frames per second. We provide public access to the code and model in an effort to narrow the divide between open-source and closed-source technologies. We believe our release will empower the community with practical applications across areas like content creation, gaming, and robot learning.", "AI": {"tldr": "LingBot-World 是一个开源的、高保真度的视频生成世界模拟器，支持多种环境、长期记忆和实时交互，旨在促进内容创作、游戏和机器人学习等领域的应用。", "motivation": "为了缩小开源和闭源技术之间的差距，并为社区提供一个强大的工具，用于内容创作、游戏和机器人学习等实际应用。", "method": "通过视频生成技术构建了一个世界模拟器，该模拟器具备高保真度、鲁棒的动力学、长达一分钟的上下文一致性（长期记忆）以及低于1秒延迟的实时交互能力。", "result": "LingBot-World 能够在现实、科学、卡通等多种风格的环境中运行，保持长期上下文一致性，并实现实时交互。", "conclusion": "LingBot-World 是一个具有高保真度、长期记忆和实时交互能力的世界模拟器，它的开源发布将赋能社区在多个领域进行创新和应用。"}}
{"id": "2601.20847", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20847", "abs": "https://arxiv.org/abs/2601.20847", "authors": ["Willams de Lima Costa", "Thifany Ketuli Silva de Souza", "Jonas Ferreira Silva", "Carlos Gabriel Bezerra Pereira", "Bruno Reis Vila Nova", "Leonardo Silvino Brito", "Rafael Raider Leoni", "Juliano Silva", "Valter Ferreira", "Sibele Miguel Soares Neto", "Samantha Uehara", "Daniel Giacomo", "João Marcelo Teixeira", "Veronica Teichrieb", "Cristiano Coelho de Araújo"], "title": "A New Dataset and Framework for Robust Road Surface Classification via Camera-IMU Fusion", "comment": null, "summary": "Road surface classification (RSC) is a key enabler for environment-aware predictive maintenance systems. However, existing RSC techniques often fail to generalize beyond narrow operational conditions due to limited sensing modalities and datasets that lack environmental diversity. This work addresses these limitations by introducing a multimodal framework that fuses images and inertial measurements using a lightweight bidirectional cross-attention module followed by an adaptive gating layer that adjusts modality contributions under domain shifts. Given the limitations of current benchmarks, especially regarding lack of variability, we introduce ROAD, a new dataset composed of three complementary subsets: (i) real-world multimodal recordings with RGB-IMU streams synchronized using a gold-standard industry datalogger, captured across diverse lighting, weather, and surface conditions; (ii) a large vision-only subset designed to assess robustness under adverse illumination and heterogeneous capture setups; and (iii) a synthetic subset generated to study out-of-distribution generalization in scenarios difficult to obtain in practice. Experiments show that our method achieves a +1.4 pp improvement over the previous state-of-the-art on the PVS benchmark and an +11.6 pp improvement on our multimodal ROAD subset, with consistently higher F1-scores on minority classes. The framework also demonstrates stable performance across challenging visual conditions, including nighttime, heavy rain, and mixed-surface transitions. These findings indicate that combining affordable camera and IMU sensors with multimodal attention mechanisms provides a scalable, robust foundation for road surface understanding, particularly relevant for regions where environmental variability and cost constraints limit the adoption of high-end sensing suites.", "AI": {"tldr": "本研究提出了一种多模态框架，融合图像和惯性测量数据，用于路面分类。该框架使用轻量级双向交叉注意力模块和自适应门控层，以提高在不同环境下的泛化能力。同时，研究发布了一个名为 ROAD 的新数据集，包含真实世界、纯视觉和合成数据，以解决现有数据集的不足。", "motivation": "现有路面分类技术在不同操作条件下泛化能力不足，原因是传感器模态有限且数据集缺乏环境多样性。本研究旨在解决这些局限性。", "method": "提出了一种多模态框架，通过轻量级双向交叉注意力模块融合图像和惯性测量数据，并使用自适应门控层来调整模态贡献。同时，构建了一个包含真实世界、纯视觉和合成数据的 ROAD 数据集。", "result": "所提出的方法在 PVS 基准上比现有技术提高了 1.4 个百分点，在 ROAD 数据集上提高了 11.6 个百分点。该框架在夜间、大雨和混合路面过渡等挑战性视觉条件下表现稳定，并在少数类上实现了更高的 F1 分数。", "conclusion": "结合经济实惠的摄像头和 IMU 传感器与多模态注意力机制，为路面理解提供了一个可扩展、鲁棒的基础。这对于在环境多变且成本限制了高端传感套件采用的地区尤为重要。"}}
{"id": "2601.20439", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20439", "abs": "https://arxiv.org/abs/2601.20439", "authors": ["Qihao Wang", "Mingzhe Lu", "Jiayue Wu", "Yue Hu", "Yanbing Liu"], "title": "PEARL: Plan Exploration and Adaptive Reinforcement Learning for Multihop Tool Use", "comment": "Accepted to PRICAI25", "summary": "Large Language Models show great potential with external tools, but face significant challenges in complex, multi-turn tool invocation. They often exhibit weak planning, tool hallucination, erroneous parameter generation, and struggle with robust interaction. To tackle these issues, we present PEARL, a novel framework to enhance LLM planning and execution for sophisticated tool use. PEARL adopts a two-stage approach: an offline phase where the agent explores tools to learn valid usage patterns and failure conditions, and an online reinforcement learning phase. In the online phase, a dedicated Planner is trained via group Relative Policy Optimization (GRPO) with a carefully designed reward function that provides distinct signals for planning quality. Experiments on the ToolHop and T-Eval benchmarks show PEARL significantly outperforms existing methods, achieving a new state-of-the-art success rate of \\textbf{56.5\\%} on ToolHop while maintaining a low invocation error rate. Our work marks a key advance in addressing the complex planning challenges of tool use, contributing to the development of more robust and reliable LLM-based agents.", "AI": {"tldr": "本文提出了一种名为PEARL的新框架，通过离线工具探索和在线强化学习（特别是GRPO）来提升大型语言模型（LLM）在复杂多轮工具调用中的规划和执行能力，显著提高了在ToolHop和T-Eval基准测试上的成功率。", "motivation": "大型语言模型在复杂、多轮的工具调用中存在规划能力弱、工具幻觉、参数生成错误以及交互鲁棒性差等问题，这促使了对更有效工具使用框架的研究。", "method": "PEARL采用两阶段方法：1. 离线阶段，代理探索工具以学习有效的用法模式和失败条件。2. 在线阶段，使用专门的规划器通过组相对策略优化（GRPO）进行训练，并结合精心设计的奖励函数来提供规划质量的信号。", "result": "在ToolHop和T-Eval基准测试上的实验表明，PEARL显著优于现有方法，在ToolHop上取得了56.5%的新状态最优成功率，同时保持了较低的调用错误率。", "conclusion": "PEARL框架是解决复杂工具使用规划挑战的关键进展，有助于开发更鲁棒、更可靠的基于LLM的智能体。"}}
{"id": "2601.20451", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20451", "abs": "https://arxiv.org/abs/2601.20451", "authors": ["Diandian Guo", "Fangfang Yuan", "Cong Cao", "Xixun Lin", "Chuan Zhou", "Hao Peng", "Yanan Cao", "Yanbing Liu"], "title": "MuVaC: AVariational Causal Framework for Multimodal Sarcasm Understanding in Dialogues", "comment": "12 pages, 7 figures. Accepted by WWW 2026", "summary": "The prevalence of sarcasm in multimodal dialogues on the social platforms presents a crucial yet challenging task for understanding the true intent behind online content. Comprehensive sarcasm analysis requires two key aspects: Multimodal Sarcasm Detection (MSD) and Multimodal Sarcasm Explanation (MuSE). Intuitively, the act of detection is the result of the reasoning process that explains the sarcasm. Current research predominantly focuses on addressing either MSD or MuSE as a single task. Even though some recent work has attempted to integrate these tasks, their inherent causal dependency is often overlooked. To bridge this gap, we propose MuVaC, a variational causal inference framework that mimics human cognitive mechanisms for understanding sarcasm, enabling robust multimodal feature learning to jointly optimize MSD and MuSE. Specifically, we first model MSD and MuSE from the perspective of structural causal models, establishing variational causal pathways to define the objectives for joint optimization. Next, we design an alignment-then-fusion approach to integrate multimodal features, providing robust fusion representations for sarcasm detection and explanation generation. Finally, we enhance the reasoning trustworthiness by ensuring consistency between detection results and explanations. Experimental results demonstrate the superiority of MuVaC in public datasets, offering a new perspective for understanding multimodal sarcasm.", "AI": {"tldr": "本文提出了一种名为 MuVaC 的变分因果推理框架，用于联合优化多模态讽刺检测 (MSD) 和多模态讽刺解释 (MuSE)，以更准确地理解在线内容中的讽刺意图。", "motivation": "现有研究大多分别处理多模态讽刺检测和解释任务，忽略了两者之间内在的因果依赖关系。本文旨在弥合这一差距，通过模拟人类认知机制来联合优化这两个任务。", "method": "1. 将 MSD 和 MuSE 从结构因果模型的角度进行建模，建立变分因果路径以定义联合优化的目标。2. 设计了一种“先对齐后融合”的方法来整合多模态特征，为讽刺检测和解释生成提供鲁棒的融合表示。3. 通过确保检测结果与解释之间的一致性来增强推理的可信度。", "result": "在公开数据集上的实验表明，MuVaC 在多模态讽刺检测和解释任务上都取得了优越的性能。", "conclusion": "MuVaC 框架通过联合优化 MSD 和 MuSE，并引入因果推理和对齐-融合机制，能够更有效地学习多模态特征，从而提升对在线内容中讽刺的理解能力，并为多模态讽刺研究提供了新视角。"}}
{"id": "2601.20465", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20465", "abs": "https://arxiv.org/abs/2601.20465", "authors": ["Yang Li", "Jiaxiang Liu", "Yusong Wang", "Yujie Wu", "Mingkun Xu"], "title": "BMAM: Brain-inspired Multi-Agent Memory Framework", "comment": "Submitted to ACL (ARR 2026 January submission); non-anonymous preprint", "summary": "Language-model-based agents operating over extended interaction horizons face persistent challenges in preserving temporally grounded information and maintaining behavioral consistency across sessions, a failure mode we term soul erosion. We present BMAM (Brain-inspired Multi-Agent Memory), a general-purpose memory architecture that models agent memory as a set of functionally specialized subsystems rather than a single unstructured store. Inspired by cognitive memory systems, BMAM decomposes memory into episodic, semantic, salience-aware, and control-oriented components that operate at complementary time scales. To support long-horizon reasoning, BMAM organizes episodic memories along explicit timelines and retrieves evidence by fusing multiple complementary signals. Experiments on the LoCoMo benchmark show that BMAM achieves 78.45 percent accuracy under the standard long-horizon evaluation setting, and ablation analyses confirm that the hippocampus-inspired episodic memory subsystem plays a critical role in temporal reasoning.", "AI": {"tldr": "研究提出了一种名为 BMAM 的类脑多主体记忆架构，通过将记忆分解为不同的功能子系统（情景、语义、显著性感知和控制），解决了语言模型代理在长时间交互中信息丢失和行为不一致的问题。", "motivation": "现有的语言模型代理在长时间交互中存在信息丢失和行为不一致的问题，即“灵魂侵蚀”（soul erosion）。", "method": "提出 BMAM（Brain-inspired Multi-Agent Memory）架构，将代理记忆建模为一组功能专业化的子系统，而非单一的非结构化存储。该架构将记忆分解为情景记忆、语义记忆、显著性感知记忆和面向控制的组件，并在不同的时间尺度上运行。为支持长时推理，BMAM 沿显式时间线组织情景记忆，并通过融合多个互补信号来检索证据。", "result": "在 LoCoMo 基准测试中，BMAM 在标准的长期评估设置下达到了 78.45% 的准确率。消融分析表明，受海马体启发的情景记忆子系统在时间推理中起着关键作用。", "conclusion": "BMAM 架构通过模仿认知记忆系统，有效地解决了语言模型代理在长时间交互中的“灵魂侵蚀”问题，并在长期推理任务中取得了优异的性能，特别是其情景记忆子系统对时间推理至关重要。"}}
{"id": "2601.20564", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20564", "abs": "https://arxiv.org/abs/2601.20564", "authors": ["Wenzhuo Ma", "Zhenzhong Chen"], "title": "DiffVC-RT: Towards Practical Real-Time Diffusion-based Perceptual Neural Video Compression", "comment": "17 pages, 10 figures", "summary": "The practical deployment of diffusion-based Neural Video Compression (NVC) faces critical challenges, including severe information loss, prohibitive inference latency, and poor temporal consistency. To bridge this gap, we propose DiffVC-RT, the first framework designed to achieve real-time diffusion-based perceptual NVC. First, we introduce an Efficient and Informative Model Architecture. Through strategic module replacements and pruning, this architecture significantly reduces computational complexity while mitigating structural information loss. Second, to address generative flickering artifacts, we propose Explicit and Implicit Consistency Modeling. We enhance temporal consistency by explicitly incorporating a zero-cost Online Temporal Shift Module within the U-Net, complemented by hybrid implicit consistency constraints. Finally, we present an Asynchronous and Parallel Decoding Pipeline incorporating Mixed Half Precision, which enables asynchronous latent decoding and parallel frame reconstruction via a Batch-dimension Temporal Shift design. Experiments show that DiffVC-RT achieves 80.1% bitrate savings in terms of LPIPS over VTM-17.0 on HEVC dataset with real-time encoding and decoding speeds of 206 / 30 fps for 720p videos on an NVIDIA H800 GPU, marking a significant milestone in diffusion-based video compression.", "AI": {"tldr": "本文提出了 DiffVC-RT，一个用于实现实时扩散型神经视频压缩的框架，通过高效模型架构、显式与隐式一致性建模以及异步并行解码流水线，显著降低了比特率损耗并实现了实时编解码速度。", "motivation": "现有的基于扩散模型的神经视频压缩（NVC）在信息损失、推理延迟和时间一致性方面存在严重问题，阻碍了其实际部署。因此，需要一个能够实现实时扩散型感知 NVC 的框架。", "method": "1. 提出了高效信息模型架构，通过模块替换和剪枝降低复杂性并减少信息丢失。2. 引入显式隐式一致性建模，通过在线时间偏移模块和混合隐式一致性约束来增强时间一致性，解决生成闪烁伪影。3. 设计了异步并行解码流水线，结合混合半精度，实现潜在信息的异步解码和帧的并行重建。", "result": "DiffVC-RT 在 LPIPS 指标上比 VTM-17.0 节省了 80.1% 的比特率。在 NVIDIA H800 GPU 上，实现了 206 fps 的编码速度和 30 fps 的解码速度（针对 720p 视频），达到了实时性能。", "conclusion": "DiffVC-RT 是首个实现实时扩散型感知 NVC 的框架，通过创新的模型架构、一致性建模和解码流水线，有效解决了现有方法的瓶颈，为扩散模型在视频压缩领域的应用树立了新的里程碑。"}}
{"id": "2601.20552", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20552", "abs": "https://arxiv.org/abs/2601.20552", "authors": ["Haoran Wei", "Yaofeng Sun", "Yukun Li"], "title": "DeepSeek-OCR 2: Visual Causal Flow", "comment": null, "summary": "We present DeepSeek-OCR 2 to investigate the feasibility of a novel encoder-DeepEncoder V2-capable of dynamically reordering visual tokens upon image semantics. Conventional vision-language models (VLMs) invariably process visual tokens in a rigid raster-scan order (top-left to bottom-right) with fixed positional encoding when fed into LLMs. However, this contradicts human visual perception, which follows flexible yet semantically coherent scanning patterns driven by inherent logical structures. Particularly for images with complex layouts, human vision exhibits causally-informed sequential processing. Inspired by this cognitive mechanism, DeepEncoder V2 is designed to endow the encoder with causal reasoning capabilities, enabling it to intelligently reorder visual tokens prior to LLM-based content interpretation. This work explores a novel paradigm: whether 2D image understanding can be effectively achieved through two-cascaded 1D causal reasoning structures, thereby offering a new architectural approach with the potential to achieve genuine 2D reasoning. Codes and model weights are publicly accessible at http://github.com/deepseek-ai/DeepSeek-OCR-2.", "AI": {"tldr": "提出了一种名为DeepSeek-OCR 2的新模型，它引入了DeepEncoder V2，能够根据图像语义动态重新排序视觉token，从而克服了传统VLM中视觉token固定顺序处理的限制，旨在实现更真实的2D推理。", "motivation": "传统的视觉语言模型（VLMs）以固定的光栅扫描顺序处理视觉token，这与人类视觉感知中灵活且受语义驱动的扫描模式不符，尤其是在处理复杂布局的图像时。研究者受到人类认知机制的启发，希望探索一种能够模仿这种因果推理和序列化处理的新方法。", "method": "引入了DeepEncoder V2，一种能够根据图像语义动态重新排序视觉token的编码器。该编码器在将视觉token输入到大型语言模型（LLM）之前，对其进行智能重排序，从而赋予编码器因果推理能力。该研究探索了一种新的范式，即是否可以通过两个级联的1D因果推理结构来实现2D图像理解。", "result": "虽然摘要中没有直接列出实验结果，但研究表明DeepEncoder V2能够通过智能重排序视觉token来增强2D图像理解能力。", "conclusion": "该研究提出了一种新的VLM架构范式，通过引入能够动态重排序视觉token的DeepEncoder V2，探索了利用2D图像理解的级联1D因果推理结构的可能性，为实现真正的2D推理提供了新的思路。"}}
{"id": "2601.20650", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20650", "abs": "https://arxiv.org/abs/2601.20650", "authors": ["Jing Wu", "Daphne Barretto", "Yiye Chen", "Nicholas Gydé", "Yanan Jian", "Yuhang He", "Vibhav Vineet"], "title": "OS-Marathon: Benchmarking Computer-Use Agents on Long-Horizon Repetitive Tasks", "comment": "22 Pages, Project Page: \\url{https://os-marathon.github.io/}", "summary": "Long-horizon, repetitive workflows are common in professional settings, such as processing expense reports from receipts and entering student grades from exam papers. These tasks are often tedious for humans since they can extend to extreme lengths proportional to the size of the data to process. However, they are ideal for Computer-Use Agents (CUAs) due to their structured, recurring sub-workflows with logic that can be systematically learned. Identifying the absence of an evaluation benchmark as a primary bottleneck, we establish OS-Marathon, comprising 242 long-horizon, repetitive tasks across 2 domains to evaluate state-of-the-art (SOTA) agents. We then introduce a cost-effective method to construct a condensed demonstration using only few-shot examples to teach agents the underlying workflow logic, enabling them to execute similar workflows effectively on larger, unseen data collections. Extensive experiments demonstrate both the inherent challenges of these tasks and the effectiveness of our proposed method. Project website: https://os-marathon.github.io/.", "AI": {"tldr": "该论文提出了OS-Marathon基准测试来评估在长周期、重复性工作流任务中表现出色的计算机使用代理（CUAs），并提出了一种使用少量样本来教授代理工作流逻辑的有效方法。", "motivation": "现有研究缺乏对长周期、重复性工作流任务的评估基准，阻碍了计算机使用代理（CUAs）在该领域的进步。", "method": "作者构建了一个包含242个长周期、重复性任务的OS-Marathon基准测试，涵盖2个领域。此外，他们提出了一种成本效益高的方法，使用少量样本来演示来教授代理工作流逻辑，使其能够处理更大、未见过的数据集。", "result": "实验结果表明，这些长周期、重复性任务对现有SOTA代理提出了挑战，但作者提出的方法在教授代理执行相关工作流方面是有效的。", "conclusion": "OS-Marathon基准测试能够有效地评估CUAs在长周期、重复性工作流任务中的能力，并且所提出的基于少量样本演示的方法能够有效地教会代理执行此类任务。"}}
{"id": "2601.20597", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20597", "abs": "https://arxiv.org/abs/2601.20597", "authors": ["Shaokun Wang", "Weili Guan", "Jizhou Han", "Jianlong Wu", "Yupeng Hu", "Liqiang Nie"], "title": "StructAlign: Structured Cross-Modal Alignment for Continual Text-to-Video Retrieval", "comment": null, "summary": "Continual Text-to-Video Retrieval (CTVR) is a challenging multimodal continual learning setting, where models must incrementally learn new semantic categories while maintaining accurate text-video alignment for previously learned ones, thus making it particularly prone to catastrophic forgetting. A key challenge in CTVR is feature drift, which manifests in two forms: intra-modal feature drift caused by continual learning within each modality, and non-cooperative feature drift across modalities that leads to modality misalignment. To mitigate these issues, we propose StructAlign, a structured cross-modal alignment method for CTVR. First, StructAlign introduces a simplex Equiangular Tight Frame (ETF) geometry as a unified geometric prior to mitigate modality misalignment. Building upon this geometric prior, we design a cross-modal ETF alignment loss that aligns text and video features with category-level ETF prototypes, encouraging the learned representations to form an approximate simplex ETF geometry. In addition, to suppress intra-modal feature drift, we design a Cross-modal Relation Preserving loss, which leverages complementary modalities to preserve cross-modal similarity relations, providing stable relational supervision for feature updates. By jointly addressing non-cooperative feature drift across modalities and intra-modal feature drift, StructAlign effectively alleviates catastrophic forgetting in CTVR. Extensive experiments on benchmark datasets demonstrate that our method consistently outperforms state-of-the-art continual retrieval approaches.", "AI": {"tldr": "本文提出了一种名为StructAlign的方法，通过引入一种统一的几何先验（ETF）和设计新的损失函数，来解决持续文本到视频检索（CTVR）中的特征漂移和灾难性遗忘问题。", "motivation": "CTVR场景下，模型需要持续学习新的语义类别，同时保持对旧类别的检索能力，容易发生灾难性遗忘。模型中的特征漂移（包括同模态内漂移和跨模态非协同漂移）是导致这一问题的主要原因。", "method": "StructAlign方法主要包含两个部分：1. 引入Simplex Equiangular Tight Frame（ETF）几何作为统一的几何先验，用于缓解模态间不对齐。在此基础上，设计了一个跨模态ETF对齐损失，将文本和视频特征与类别级别的ETF原型对齐。2. 设计了一个跨模态关系保持损失，利用模态间的互补性来保持跨模态相似性关系，为特征更新提供稳定的关系监督。", "result": "StructAlign通过同时解决跨模态非协同特征漂移和同模态内特征漂移，有效地缓解了CTVR中的灾难性遗忘。在基准数据集上的大量实验表明，该方法在持续检索方面优于现有最先进的方法。", "conclusion": "StructAlign是一种有效的解决CTVR中特征漂移和灾难性遗忘的方法，通过结合几何先验和跨模态关系保持，显著提升了模型的持续学习性能。"}}
{"id": "2601.20476", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20476", "abs": "https://arxiv.org/abs/2601.20476", "authors": ["Evanfiya Logacheva", "Arto Hellas", "Tsvetomila Mihaylova", "Juha Sorva", "Ava Heinonen", "Juho Leinonen"], "title": "Can We Improve Educational Diagram Generation with In-Context Examples? Not if a Hallucination Spoils the Bunch", "comment": null, "summary": "Generative artificial intelligence (AI) has found a widespread use in computing education; at the same time, quality of generated materials raises concerns among educators and students. This study addresses this issue by introducing a novel method for diagram code generation with in-context examples based on the Rhetorical Structure Theory (RST), which aims to improve diagram generation by aligning models' output with user expectations. Our approach is evaluated by computer science educators, who assessed 150 diagrams generated with large language models (LLMs) for logical organization, connectivity, layout aesthetic, and AI hallucination. The assessment dataset is additionally investigated for its utility in automated diagram evaluation. The preliminary results suggest that our method decreases the rate of factual hallucination and improves diagram faithfulness to provided context; however, due to LLMs' stochasticity, the quality of the generated diagrams varies. Additionally, we present an in-depth analysis and discussion on the connection between AI hallucination and the quality of generated diagrams, which reveals that text contexts of higher complexity lead to higher rates of hallucination and LLMs often fail to detect mistakes in their output.", "AI": {"tldr": "本研究提出了一种基于修辞结构理论（RST）的、利用上下文示例生成图表代码的新方法，旨在提高AI生成的图表质量，并减少事实性错误。研究结果表明，该方法能有效降低幻觉率并提高图表与上下文的一致性，但LLM的随机性导致图表质量仍有波动。此外，研究还分析了AI幻觉与图表质量的关系，发现复杂文本上下文更容易导致幻觉。", "motivation": "教育领域中生成式AI的广泛应用带来了对生成材料质量的担忧，促使研究者寻求改进AI生成图表质量的方法。", "method": "提出了一种基于修辞结构理论（RST）和上下文示例的图表代码生成新方法，并由计算机科学教育者评估了150个由LLM生成的图表，评估维度包括逻辑组织、连通性、布局美观度和AI幻觉。同时，研究也探讨了评估数据集在自动化图表评估中的作用。", "result": "提出的方法能够降低事实性幻觉率，并提高图表与给定上下文的一致性。然而，受LLM随机性的影响，生成的图表质量存在差异。研究还发现，文本上下文的复杂性越高，幻觉率越高，且LLM常无法检测自身输出中的错误。", "conclusion": "基于RST和上下文示例的方法有助于提升AI生成图表的质量和忠实度，但仍需进一步优化以克服LLM的随机性。AI幻觉与图表质量密切相关，尤其是在处理复杂文本上下文时，需要对LLM的自我纠错能力进行深入研究。"}}
{"id": "2601.20656", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20656", "abs": "https://arxiv.org/abs/2601.20656", "authors": ["Diogo J. Paulo", "Hugo Proença", "João C. Neves"], "title": "FD-MAD: Frequency-Domain Residual Analysis for Face Morphing Attack Detection", "comment": null, "summary": "Face morphing attacks present a significant threat to face recognition systems used in electronic identity enrolment and border control, particularly in single-image morphing attack detection (S-MAD) scenarios where no trusted reference is available. In spite of the vast amount of research on this problem, morph detection systems struggle in cross-dataset scenarios. To address this problem, we introduce a region-aware frequency-based morph detection strategy that drastically improves over strong baseline methods in challenging cross-dataset and cross-morph settings using a lightweight approach. Having observed the separability of bona fide and morph samples in the frequency domain of different facial parts, our approach 1) introduces the concept of residual frequency domain, where the frequency of the signal is decoupled from the natural spectral decay to easily discriminate between morph and bona fide data; 2) additionally, we reason in a global and local manner by combining the evidence from different facial regions in a Markov Random Field, which infers a globally consistent decision. The proposed method, trained exclusively on the synthetic morphing attack detection development dataset (SMDD), is evaluated in challenging cross-dataset and cross-morph settings on FRLL-Morph and MAD22 sets. Our approach achieves an average equal error rate (EER) of 1.85\\% on FRLL-Morph and ranks second on MAD22 with an average EER of 6.12\\%, while also obtaining a good bona fide presentation classification error rate (BPCER) at a low attack presentation classification error rate (APCER) using only spectral features. These findings indicate that Fourier-domain residual modeling with structured regional fusion offers a competitive alternative to deep S-MAD architectures.", "AI": {"tldr": "提出了一种区域感知频率域的单图像人脸变形攻击检测方法，通过残差频率域和马尔可夫随机场融合不同面部区域信息，有效提升了跨数据集和跨变形场景下的检测性能。", "motivation": "现有的人脸变形攻击检测方法在跨数据集场景下性能下降明显，急需更鲁棒的方法。特别是单图像变形攻击检测（S-MAD）场景下，缺乏可信参考。", "method": "1. 引入残差频率域概念，将信号频率与其自然频谱衰减解耦，以区分真实人脸和变形攻击。2. 结合全局和局部信息，利用马尔可在随机场（MRF）融合不同面部区域的证据，做出全局一致的决策。", "result": "该方法在仅使用SMDD数据集训练的情况下，在FRLL-Morph数据集上实现了1.85%的平均等错误率（EER），在MAD22数据集上排名第二，平均EER为6.12%。在低攻击呈现分类错误率（APCER）下，也能获得良好的真实人脸呈现分类错误率（BPCER）。", "conclusion": "基于傅里叶域残差建模和结构化区域融合的人脸变形攻击检测方法，是一种有竞争力的替代方案，优于现有的深度S-MAD架构。"}}
{"id": "2601.20582", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20582", "abs": "https://arxiv.org/abs/2601.20582", "authors": ["Shalom Rosner", "Ronit D. Gross", "Ella Koresh", "Ido Kanter"], "title": "Single-Nodal Spontaneous Symmetry Breaking in NLP Models", "comment": "23 pages, 6 figures, 1 table", "summary": "Spontaneous symmetry breaking in statistical mechanics primarily occurs during phase transitions at the thermodynamic limit where the Hamiltonian preserves inversion symmetry, yet the low-temperature free energy exhibits reduced symmetry. Herein, we demonstrate the emergence of spontaneous symmetry breaking in natural language processing (NLP) models during both pre-training and fine-tuning, even under deterministic dynamics and within a finite training architecture. This phenomenon occurs at the level of individual attention heads and is scaled-down to its small subset of nodes and also valid at a single-nodal level, where nodes acquire the capacity to learn a limited set of tokens after pre-training or labels after fine-tuning for a specific classification task. As the number of nodes increases, a crossover in learning ability occurs, governed by the tradeoff between a decrease following random-guess among increased possible outputs, and enhancement following nodal cooperation, which exceeds the sum of individual nodal capabilities. In contrast to spin-glass systems, where a microscopic state of frozen spins cannot be directly linked to the free-energy minimization goal, each nodal function in this framework contributes explicitly to the global network task and can be upper-bounded using convex hull analysis. Results are demonstrated using BERT-6 architecture pre-trained on Wikipedia dataset and fine-tuned on the FewRel classification task.", "AI": {"tldr": "研究表明，自然语言处理模型在预训练和微调过程中也会出现自发对称性破缺，这种现象存在于单个注意力头甚至单个节点层面，并与节点数量和它们之间的协同作用有关。", "motivation": "在统计力学中，自发对称性破缺主要发生在相变过程中，而自然语言处理模型在确定性动力学和有限架构下也出现了这种现象，这激发了对NLP模型内部学习机制的深入研究。", "method": "通过在BERT-6架构上进行预训练（Wikipedia数据集）和微调（FewRel分类任务），观察和分析单个注意力头、节点子集乃至单个节点在学习过程中的对称性破缺行为，并利用凸包分析来界定节点功能。", "result": "发现NLP模型中的自发对称性破缺发生在单个注意力头及其更小的节点层级。随着节点数量的增加，学习能力出现了一个权衡交叉点，它平衡了随机猜测的概率和节点协同带来的能力增强。节点的功能明确地服务于全局任务，并可以通过凸包分析进行界定。", "conclusion": "自发对称性破缺不仅存在于统计力学的相变过程中，也普遍存在于NLP模型的训练过程中，并且这种现象可以被精细地定位到模型的最小组成单元（节点）层面，揭示了NLP模型内部学习和协同机制的某些特性。"}}
{"id": "2601.20546", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20546", "abs": "https://arxiv.org/abs/2601.20546", "authors": ["Kumiko Nakajima", "Jan Zuiderveld", "Sandro Pezzelle"], "title": "Beyond Divergent Creativity: A Human-Based Evaluation of Creativity in Large Language Models", "comment": "Accepted to Findings of EACL 2026", "summary": "Large language models (LLMs) are increasingly used in verbal creative tasks. However, previous assessments of the creative capabilities of LLMs remain weakly grounded in human creativity theory and are thus hard to interpret. The widely used Divergent Association Task (DAT) focuses on novelty, ignoring appropriateness, a core component of creativity. We evaluate a range of state-of-the-art LLMs on DAT and show that their scores on the task are lower than those of two baselines that do not possess any creative abilities, undermining its validity for model evaluation. Grounded in human creativity theory, which defines creativity as the combination of novelty and appropriateness, we introduce Conditional Divergent Association Task (CDAT). CDAT evaluates novelty conditional on contextual appropriateness, separating noise from creativity better than DAT, while remaining simple and objective. Under CDAT, smaller model families often show the most creativity, whereas advanced families favor appropriateness at lower novelty. We hypothesize that training and alignment likely shift models along this frontier, making outputs more appropriate but less creative. We release the dataset and code.", "AI": {"tldr": "本文提出了条件发散联想任务（CDAT），以解决现有LLM创造力评估方法（如DAT）忽略“适宜性”的问题。CDAT在评估新颖性的同时考虑适宜性，能更好地分离噪声与创造力。研究发现，较小的模型家族在CDAT上表现出更高的创造力，而大型模型家族更倾向于适宜性。作者推测，训练和对齐过程可能导致模型向着更高的适宜性但更低的创造力方向偏移。", "motivation": "现有LLM创造力评估方法（如DAT）仅关注新颖性，忽略了创造力的核心组成部分“适宜性”，导致评估结果难以解释且 Validity 受到质疑。", "method": "1. 评估现有LLM在DAT上的表现，并与基线模型进行比较。 2. 基于人类创造力理论（新颖性+适宜性），提出条件发散联想任务（CDAT）。 3. 使用CDAT评估不同规模的LLM家族。", "result": "1. LLM在DAT上的表现低于不具备创造力的基线模型，显示DAT对模型评估的局限性。 2. 在CDAT上，较小的模型家族通常表现出更高的创造力，而大型模型家族则优先考虑适宜性而非新颖性。", "conclusion": "CDAT是一种比DAT更有效、更符合人类创造力理论的LLM创造力评估方法。LLM在创造力与适宜性之间存在权衡，且训练和对齐过程可能影响了这种权衡，使得模型倾向于生成更适宜但创造性较低的输出。"}}
{"id": "2601.20592", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20592", "abs": "https://arxiv.org/abs/2601.20592", "authors": ["Ali Basirat", "Danial Namazifard", "Navid Baradaran Hemmati"], "title": "A Computational Approach to Language Contact -- A Case Study of Persian", "comment": null, "summary": "We investigate structural traces of language contact in the intermediate representations of a monolingual language model. Focusing on Persian (Farsi) as a historically contact-rich language, we probe the representations of a Persian-trained model when exposed to languages with varying degrees and types of contact with Persian. Our methodology quantifies the amount of linguistic information encoded in intermediate representations and assesses how this information is distributed across model components for different morphosyntactic features. The results show that universal syntactic information is largely insensitive to historical contact, whereas morphological features such as Case and Gender are strongly shaped by language-specific structure, suggesting that contact effects in monolingual language models are selective and structurally constrained.", "AI": {"tldr": "本文研究了单语语言模型中间表示中语言接触的结构痕迹，发现历史接触对句法信息影响不大，但对格和性等形态特征有显著影响。", "motivation": "探讨语言接触如何影响单语语言模型的内部结构和信息表征。", "method": "以波斯语（一种接触丰富的语言）为例，训练语言模型，并探测模型在接触不同程度和类型的语言时，其中间表示中编码的语言信息量，以及这些信息如何分布于不同模型组件。", "result": "研究表明，句法信息对历史接触不敏感，但格和性等形态特征受语言特有结构影响显著。", "conclusion": "语言接触对单语语言模型的影响具有选择性，并受到结构约束；形态特征比句法特征更容易受到语言接触的影响。"}}
{"id": "2601.20675", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20675", "abs": "https://arxiv.org/abs/2601.20675", "authors": ["Pankhi Kashyap", "Mainak Singha", "Biplab Banerjee"], "title": "bi-modal textual prompt learning for vision-language models in remote sensing", "comment": "Accepted in ICASSP 2026", "summary": "Prompt learning (PL) has emerged as an effective strategy to adapt vision-language models (VLMs), such as CLIP, for downstream tasks under limited supervision. While PL has demonstrated strong generalization on natural image datasets, its transferability to remote sensing (RS) imagery remains underexplored. RS data present unique challenges, including multi-label scenes, high intra-class variability, and diverse spatial resolutions, that hinder the direct applicability of existing PL methods. In particular, current prompt-based approaches often struggle to identify dominant semantic cues and fail to generalize to novel classes in RS scenarios. To address these challenges, we propose BiMoRS, a lightweight bi-modal prompt learning framework tailored for RS tasks. BiMoRS employs a frozen image captioning model (e.g., BLIP-2) to extract textual semantic summaries from RS images. These captions are tokenized using a BERT tokenizer and fused with high-level visual features from the CLIP encoder. A lightweight cross-attention module then conditions a learnable query prompt on the fused textual-visual representation, yielding contextualized prompts without altering the CLIP backbone. We evaluate BiMoRS on four RS datasets across three domain generalization (DG) tasks and observe consistent performance gains, outperforming strong baselines by up to 2% on average. Codes are available at https://github.com/ipankhi/BiMoRS.", "AI": {"tldr": "提出了一种名为BiMoRS的轻量级双模态提示学习框架，用于解决遥感（RS）图像在有限监督下的下游任务，通过结合图像标题和视觉特征来增强模型在新类别上的泛化能力。", "motivation": "现有的提示学习（PL）方法在自然图像上表现良好，但在遥感（RS）图像上效果不佳，因为RS图像具有多标签场景、类内高变异性以及不同的空间分辨率等挑战。现有的方法难以识别主导语义线索，并且在新类别上泛化能力不足。", "method": "BiMoRS框架使用一个冻结的图像字幕模型（如BLIP-2）提取RS图像的文本语义摘要，然后使用BERT分词器进行分词，并与CLIP编码器的高层视觉特征融合。一个轻量级的交叉注意力模块基于融合后的文本-视觉表示来调整一个可学习的查询提示，从而生成上下文提示，而不改变CLIP主干。", "result": "在四个RS数据集的三个域泛化（DG）任务上进行了评估，BiMoRS取得了持续的性能提升，平均比强基线模型高出2%。", "conclusion": "BiMoRS框架能够有效地解决遥感图像在有限监督下的提示学习挑战，通过双模态信息融合和轻量级跨模态注意力机制，显著提高了模型在新类别上的泛化性能。"}}
{"id": "2601.20661", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20661", "abs": "https://arxiv.org/abs/2601.20661", "authors": ["Michele Mazzamuto", "Daniele Di Mauro", "Gianpiero Francesca", "Giovanni Maria Farinella", "Antonino Furnari"], "title": "ProSkill: Segment-Level Skill Assessment in Procedural Videos", "comment": "Accepted at The IEEE/CVF Winter Conference on Applications of Computer Vision 2026", "summary": "Skill assessment in procedural videos is crucial for the objective evaluation of human performance in settings such as manufacturing and procedural daily tasks. Current research on skill assessment has predominantly focused on sports and lacks large-scale datasets for complex procedural activities. Existing studies typically involve only a limited number of actions, focus on either pairwise assessments (e.g., A is better than B) or on binary labels (e.g., good execution vs needs improvement). In response to these shortcomings, we introduce ProSkill, the first benchmark dataset for action-level skill assessment in procedural tasks. ProSkill provides absolute skill assessment annotations, along with pairwise ones. This is enabled by a novel and scalable annotation protocol that allows for the creation of an absolute skill assessment ranking starting from pairwise assessments. This protocol leverages a Swiss Tournament scheme for efficient pairwise comparisons, which are then aggregated into consistent, continuous global scores using an ELO-based rating system. We use our dataset to benchmark the main state-of-the-art skill assessment algorithms, including both ranking-based and pairwise paradigms. The suboptimal results achieved by the current state-of-the-art highlight the challenges and thus the value of ProSkill in the context of skill assessment for procedural videos. All data and code are available at https://fpv-iplab.github.io/ProSkill/", "AI": {"tldr": "本研究提出了ProSkill，一个用于程序性任务视频中的动作级别技能评估的基准数据集，解决了现有研究在数据规模和评估粒度上的不足，并引入了一种新颖的从成对评估到绝对技能评分的标注协议。", "motivation": "现有针对程序性视频的技能评估研究在数据集规模、动作复杂度以及评估粒度（多为二元或成对评估）方面存在不足，难以客观评价制造业和日常任务中的人类表现。", "method": "研究引入了ProSkill数据集，包含绝对和成对技能评估标注。该数据集的创建依赖于一种新颖的、可扩展的标注协议，该协议利用瑞士轮赛制进行高效的成对比较，并结合ELO评分系统将这些比较聚合为一致的、连续的全局分数。", "result": "使用ProSkill数据集对现有的先进技能评估算法（包括基于排名和成对的范式）进行了基准测试，结果显示当前最先进的方法表现不佳，突显了ProSkill在程序性视频技能评估方面的挑战和价值。", "conclusion": "ProSkill是首个用于程序性任务动作级别技能评估的基准数据集，其新颖的标注协议能够从成对评估高效生成绝对技能评分，为该领域的研究提供了重要的资源和新的挑战。"}}
{"id": "2601.20613", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20613", "abs": "https://arxiv.org/abs/2601.20613", "authors": ["Kaiyuan Chen", "Qimin Wu", "Taiyu Hou", "Tianhao Tang", "Xueyu Hu", "Yuchen Hou", "Bikun Li", "Chengming Qian", "Guoyin Wang", "Haolin Chen", "Haotong Tian", "Haoye Zhang", "Haoyu Bian", "Hongbing Pan", "Hongkang Zhang", "Hongyi Zhou", "Jiaqi Cai", "Jiewu Rao", "Jiyuan Ren", "Keduan Huang", "Lucia Zhu Huang", "Mingyu Yuan", "Naixu Guo", "Qicheng Tang", "Qinyan Zhang", "Shuai Chen", "Siheng Chen", "Ting Ting Li", "Xiaoxing Guo", "Yaocheng Zuo", "Yaoqi Guo", "Yinan Wang", "Yinzhou Yu", "Yize Wang", "Yuan Jiang", "Yuan Tian", "Yuanshuo Zhang", "Yuxuan Liu", "Yvette Yan Zeng", "Zenyu Shan", "Zihan Yin", "Xiaobo Hu", "Yang Liu", "Yixin Ren", "Yuan Gong"], "title": "AgentIF-OneDay: A Task-level Instruction-Following Benchmark for General AI Agents in Daily Scenarios", "comment": "17 pages, 8 figures", "summary": "The capacity of AI agents to effectively handle tasks of increasing duration and complexity continues to grow, demonstrating exceptional performance in coding, deep research, and complex problem-solving evaluations. However, in daily scenarios, the perception of these advanced AI capabilities among general users remains limited. We argue that current evaluations prioritize increasing task difficulty without sufficiently addressing the diversity of agentic tasks necessary to cover the daily work, life, and learning activities of a broad demographic. To address this, we propose AgentIF-OneDay, aimed at determining whether general users can utilize natural language instructions and AI agents to complete a diverse array of daily tasks. These tasks require not only solving problems through dialogue but also understanding various attachment types and delivering tangible file-based results. The benchmark is structured around three user-centric categories: Open Workflow Execution, which assesses adherence to explicit and complex workflows; Latent Instruction, which requires agents to infer implicit instructions from attachments; and Iterative Refinement, which involves modifying or expanding upon ongoing work. We employ instance-level rubrics and a refined evaluation pipeline that aligns LLM-based verification with human judgment, achieving an 80.1% agreement rate using Gemini-3-Pro. AgentIF-OneDay comprises 104 tasks covering 767 scoring points. We benchmarked four leading general AI agents and found that agent products built based on APIs and ChatGPT agents based on agent RL remain in the first tier simultaneously. Leading LLM APIs and open-source models have internalized agentic capabilities, enabling AI application teams to develop cutting-edge Agent products.", "AI": {"tldr": "本研究提出了AgentIF-OneDay基准测试，以评估AI代理处理日常多样化任务的能力，发现基于API和RL的AI代理表现相当，并且领先的LLM API和开源模型已内化了代理能力。", "motivation": "现有AI代理评估过于侧重于任务难度，而忽略了日常工作、生活和学习活动的多样性，导致用户对AI代理的实际能力感知有限。", "method": "提出了AgentIF-OneDay基准测试，包含开放工作流执行、潜在指令和迭代改进三类任务，使用实例级评分标准和结合LLM验证与人类判断的评估流程。", "result": "AgentIF-OneDay包含104个任务和767个评分点。研究基准测试了四种领先的通用AI代理，发现基于API和ChatGPT的RL代理处于同一领先水平，LLM API和开源模型已具备代理能力。", "conclusion": "AgentIF-OneDay基准测试证明了AI代理在处理日常多样化任务方面的潜力，并为未来AI代理的开发和评估提供了新的方向。领先的LLM技术使得开发先进的AI代理产品成为可能。"}}
{"id": "2601.20742", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20742", "abs": "https://arxiv.org/abs/2601.20742", "authors": ["Xin Jin", "Jinming Liu", "Yuntao Wei", "Junyan Lin", "Zhicheng Wang", "Jianguo Huang", "Xudong Yang", "Yanxiao Liu", "Wenjun Zeng"], "title": "Compression Tells Intelligence: Visual Coding, Visual Token Technology, and the Unification", "comment": null, "summary": "\"Compression Tells Intelligence\", is supported by research in artificial intelligence, particularly concerning (multimodal) large language models (LLMs/MLLMs), where compression efficiency often correlates with improved model performance and capabilities. For compression, classical visual coding based on traditional information theory has developed over decades, achieving great success with numerous international industrial standards widely applied in multimedia (e.g., image/video) systems. Except that, the recent emergingvisual token technology of generative multi-modal large models also shares a similar fundamental objective like visual coding: maximizing semantic information fidelity during the representation learning while minimizing computational cost. Therefore, this paper provides a comprehensive overview of two dominant technique families first -- Visual Coding and Vision Token Technology -- then we further unify them from the aspect of optimization, discussing the essence of compression efficiency and model performance trade-off behind. Next, based on the proposed unified formulation bridging visual coding andvisual token technology, we synthesize bidirectional insights of themselves and forecast the next-gen visual codec and token techniques. Last but not least, we experimentally show a large potential of the task-oriented token developments in the more practical tasks like multimodal LLMs (MLLMs), AI-generated content (AIGC), and embodied AI, as well as shedding light on the future possibility of standardizing a general token technology like the traditional codecs (e.g., H.264/265) with high efficiency for a wide range of intelligent tasks in a unified and effective manner.", "AI": {"tldr": "本文回顾并统一了视觉编码和视觉标记技术，探讨了它们的压缩效率与模型性能之间的权衡，并预测了下一代技术和标准化发展的可能性。", "motivation": "人工智能（尤其是多模态大模型）的研究表明，压缩效率与模型性能密切相关。同时，视觉编码和视觉标记技术在表征学习中都面临着最大化语义信息保真度与最小化计算成本的共同目标。", "method": "首先，本文对视觉编码和视觉标记技术进行了全面概述。然后，从优化的角度统一了这两种技术，并讨论了压缩效率与模型性能之间的权衡。最后，基于统一的公式，提出了双向见解并预测了下一代技术，同时通过实验验证了面向任务的标记技术在多模态大模型、AIGC和具身AI等领域的潜力。", "result": "本文提出了一个统一的框架，将视觉编码和视觉标记技术联系起来。实验表明，面向任务的标记技术在多模态大模型、AIGC和具身AI等领域具有巨大潜力，并为未来标准化通用标记技术提供了可能性。", "conclusion": "视觉编码和视觉标记技术在根本目标上具有一致性。通过统一的视角，可以深化对压缩效率与模型性能之间关系的理解，并为下一代视觉编解码器和标记技术的发展指明方向，甚至可能实现类似传统编解码器的通用标记技术标准化。"}}
{"id": "2601.20857", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20857", "abs": "https://arxiv.org/abs/2601.20857", "authors": ["Hongyu Zhou", "Zisen Shao", "Sheng Miao", "Pan Wang", "Dongfeng Bai", "Bingbing Liu", "Yiyi Liao"], "title": "FreeFix: Boosting 3D Gaussian Splatting via Fine-Tuning-Free Diffusion Models", "comment": "Our project page is at https://xdimlab.github.io/freefix", "summary": "Neural Radiance Fields and 3D Gaussian Splatting have advanced novel view synthesis, yet still rely on dense inputs and often degrade at extrapolated views. Recent approaches leverage generative models, such as diffusion models, to provide additional supervision, but face a trade-off between generalization and fidelity: fine-tuning diffusion models for artifact removal improves fidelity but risks overfitting, while fine-tuning-free methods preserve generalization but often yield lower fidelity. We introduce FreeFix, a fine-tuning-free approach that pushes the boundary of this trade-off by enhancing extrapolated rendering with pretrained image diffusion models. We present an interleaved 2D-3D refinement strategy, showing that image diffusion models can be leveraged for consistent refinement without relying on costly video diffusion models. Furthermore, we take a closer look at the guidance signal for 2D refinement and propose a per-pixel confidence mask to identify uncertain regions for targeted improvement. Experiments across multiple datasets show that FreeFix improves multi-frame consistency and achieves performance comparable to or surpassing fine-tuning-based methods, while retaining strong generalization ability.", "AI": {"tldr": "FreeFix 是一种无需微调的方法，利用预训练的图像扩散模型，通过交错的 2D-3D 细化策略和每像素置信度掩码，提升了新视角合成中渲染到外插视图的质量，同时保持了泛化能力。", "motivation": "现有的新视角合成方法（如 NeRF 和 3D 高斯泼溅）依赖于密集输入，并在外插视图下性能下降。尽管生成模型（如扩散模型）被用于提供额外监督，但现有的方法在泛化能力和保真度之间存在权衡：微调会提高保真度但可能过拟合，而无需微调的方法则泛化能力强但保真度较低。本研究旨在解决这一权衡问题，提升外插视图的渲染质量。", "method": "提出了一种名为 FreeFix 的无需微调的方法。核心是交错的 2D-3D 细化策略，利用预训练的图像扩散模型进行一致性细化，而无需使用成本高昂的视频扩散模型。此外，引入了每像素置信度掩码，以识别不确定区域并进行有针对性的改进。", "result": "在多个数据集上的实验表明，FreeFix 提高了多帧一致性，其性能与需要微调的方法相当甚至更优，同时保持了强大的泛化能力。", "conclusion": "FreeFix 成功地通过图像扩散模型实现了无需微调的新视角合成外插渲染增强，克服了现有方法在泛化和保真度之间的固有权衡，并取得了优于或媲美微调方法的性能。"}}
{"id": "2601.20649", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20649", "abs": "https://arxiv.org/abs/2601.20649", "authors": ["Wenlin Zhong", "Chengyuan Liu", "Yiquan Wu", "Bovin Tan", "Changlong Sun", "Yi Wang", "Xiaozhong Liu", "Kun Kuang"], "title": "P2S: Probabilistic Process Supervision for General-Domain Reasoning Question Answering", "comment": null, "summary": "While reinforcement learning with verifiable rewards (RLVR) has advanced LLM reasoning in structured domains like mathematics and programming, its application to general-domain reasoning tasks remains challenging due to the absence of verifiable reward signals. To this end, methods like Reinforcement Learning with Reference Probability Reward (RLPR) have emerged, leveraging the probability of generating the final answer as a reward signal. However, these outcome-focused approaches neglect crucial step-by-step supervision of the reasoning process itself. To address this gap, we introduce Probabilistic Process Supervision (P2S), a novel self-supervision framework that provides fine-grained process rewards without requiring a separate reward model or human-annotated reasoning steps. During reinforcement learning, P2S synthesizes and filters a high-quality reference reasoning chain (gold-CoT). The core of our method is to calculate a Path Faithfulness Reward (PFR) for each reasoning step, which is derived from the conditional probability of generating the gold-CoT's suffix, given the model's current reasoning prefix. Crucially, this PFR can be flexibly integrated with any outcome-based reward, directly tackling the reward sparsity problem by providing dense guidance. Extensive experiments on reading comprehension and medical Question Answering benchmarks show that P2S significantly outperforms strong baselines.", "AI": {"tldr": "本文提出了一种名为 Probabilistic Process Supervision (P2S) 的新方法，用于解决通用领域推理任务中强化学习缺乏可验证奖励信号的问题。P2S 通过计算每个推理步骤的“路径忠诚度奖励”（PFR）来提供细粒度的过程奖励，该奖励基于当前推理前缀生成黄金思维链后缀的条件概率，从而缓解了奖励稀疏性问题。", "motivation": "现有的强化学习与可验证奖励 (RLVR) 在结构化领域取得了成功，但在通用领域推理任务中面临挑战，因为缺乏可验证的奖励信号。现有的方法（如 RLPR）侧重于结果奖励，忽略了推理过程本身的逐步监督。", "method": "P2S 是一种自监督框架，它在强化学习过程中合成并过滤高质量的参考推理链（黄金-CoT）。核心是计算路径忠诚度奖励 (PFR)，该奖励衡量模型当前推理前缀生成黄金-CoT 后缀的条件概率。", "result": "P2S 能够提供密集的奖励信号，并且可以与任何基于结果的奖励结合使用，有效解决了奖励稀疏性问题。在阅读理解和医学问答基准测试上的实验表明，P2S 的性能显著优于现有方法。", "conclusion": "P2S 是一种有效的自监督方法，能够为 LLM 的通用领域推理提供细粒度的过程奖励，无需额外的奖励模型或人工标注，并显著提升了模型的性能。"}}
{"id": "2601.20676", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20676", "abs": "https://arxiv.org/abs/2601.20676", "authors": ["Zhuo Chen", "Xinyu Geng", "Xinyu Wang", "Yong Jiang", "Zhen Zhang", "Pengjun Xie", "Kewei Tu"], "title": "Efficient Multimodal Planning Agent for Visual Question-Answering", "comment": null, "summary": "Visual Question-Answering (VQA) is a challenging multimodal task that requires integrating visual and textual information to generate accurate responses. While multimodal Retrieval-Augmented Generation (mRAG) has shown promise in enhancing VQA systems by providing more evidence on both image and text sides, the default procedure that addresses VQA queries, especially the knowledge-intensive ones, often relies on multi-stage pipelines of mRAG with inherent dependencies. To mitigate the inefficiency limitations while maintaining VQA task performance, this paper proposes a method that trains a multimodal planning agent, dynamically decomposing the mRAG pipeline to solve the VQA task. Our method optimizes the trade-off between efficiency and effectiveness by training the agent to intelligently determine the necessity of each mRAG step. In our experiments, the agent can help reduce redundant computations, cutting search time by over 60\\% compared to existing methods and decreasing costly tool calls. Meanwhile, experiments demonstrate that our method outperforms all baselines, including a Deep Research agent and a carefully designed prompt-based method, on average over six various datasets. Code will be released.", "AI": {"tldr": "本文提出了一种基于多模态检索增强生成（mRAG）的视觉问答（VQA）方法，通过训练一个多模态规划代理来动态分解mRAG流程，以提高效率并减少不必要的计算和工具调用，同时保持甚至超越现有方法的性能。", "motivation": "现有的mRAG方法在处理VQA任务时，尤其是知识密集型问题，通常依赖于多阶段的流水线，存在固有的依赖性和效率低下问题。因此，研究动机是为了在不牺牲VQA任务性能的前提下，提高mRAG的效率。", "method": "本文提出训练一个多模态规划代理，该代理能够动态地分解mRAG流水线。通过优化代理的训练，使其能够智能地判断每个mRAG步骤的必要性，从而实现效率和效果之间的权衡。", "result": "该方法能够显著减少冗余计算，搜索时间减少超过60%，并减少昂贵的工具调用。在六个不同数据集上的平均性能优于所有基线方法，包括Deep Research代理和精心设计的基于提示的方法。", "conclusion": "通过引入多模态规划代理，可以有效地动态调整mRAG流水线的执行，从而在VQA任务中实现更高的效率和更好的性能。"}}
{"id": "2601.20659", "categories": ["cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.20659", "abs": "https://arxiv.org/abs/2601.20659", "authors": ["Sara Candussio"], "title": "A Dialectic Pipeline for Improving LLM Robustness", "comment": null, "summary": "Assessing ways in which Language Models can reduce their hallucinations and improve the outputs' quality is crucial to ensure their large-scale use.\n  However, methods such as fine-tuning on domain-specific data or the training of a separate \\textit{ad hoc} verifier require demanding computational resources (not feasible for many user applications) and constrain the models to specific fields of knowledge.\n  In this thesis, we propose a dialectic pipeline that preserves LLMs' generalization abilities while improving the quality of its answer via self-dialogue, enabling it to reflect upon and correct tentative wrong answers.\n  We experimented with different pipeline settings, testing our proposed method on different datasets and on different families of models. All the pipeline stages are enriched with the relevant context (in an oracle-RAG setting) and a study on the impact of its summarization or its filtering is conducted.\n  We find that our proposed dialectic pipeline is able to outperform by significative margins the standard model answers and that it consistently achieves higher performances than Chain-of-Thought only prompting.", "AI": {"tldr": "本文提出了一种辩证式对话流水线，通过自我对话和反思纠正初步错误答案，从而在不牺牲通用性的前提下提高大型语言模型（LLM）输出质量，该方法在不同模型和数据集上均优于标准模型和仅使用思维链提示的方法。", "motivation": "为了确保大型语言模型（LLM）能够大规模应用，必须解决其幻觉问题并提高输出质量。现有的方法，如领域特定数据微调或训练独立的验证器，计算成本高昂且限制了模型的知识领域。", "method": "提出了一种辩证式对话流水线，通过自我对话让模型反思并纠正初步错误答案。实验中测试了不同的流水线设置，在不同数据集和模型家族上进行了验证。所有流水线阶段都加入了相关的上下文信息（在Oracle-RAG设置下），并研究了摘要和过滤策略的影响。", "result": "所提出的辩证式对话流水线在输出质量上显著优于标准模型回答，并且在性能上持续优于仅使用思维链（Chain-of-Thought）提示的方法。", "conclusion": "辩证式对话流水线是一种有效的方法，可以在保持LLM通用能力的同时，通过自我反思和纠正来提高其输出质量，并且在实际应用中具有优势。"}}
{"id": "2601.20747", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.20747", "abs": "https://arxiv.org/abs/2601.20747", "authors": ["Elham Aghakhani", "Rezvaneh Rezapour"], "title": "Like a Therapist, But Not: Reddit Narratives of AI in Mental Health Contexts", "comment": null, "summary": "Large language models (LLMs) are increasingly used for emotional support and mental health-related interactions outside clinical settings, yet little is known about how people evaluate and relate to these systems in everyday use. We analyze 5,126 Reddit posts from 47 mental health communities describing experiential or exploratory use of AI for emotional support or therapy. Grounded in the Technology Acceptance Model and therapeutic alliance theory, we develop a theory-informed annotation framework and apply a hybrid LLM-human pipeline to analyze evaluative language, adoption-related attitudes, and relational alignment at scale. Our results show that engagement is shaped primarily by narrated outcomes, trust, and response quality, rather than emotional bond alone. Positive sentiment is most strongly associated with task and goal alignment, while companionship-oriented use more often involves misaligned alliances and reported risks such as dependence and symptom escalation. Overall, this work demonstrates how theory-grounded constructs can be operationalized in large-scale discourse analysis and highlights the importance of studying how users interpret language technologies in sensitive, real-world contexts.", "AI": {"tldr": "本研究分析了Reddit上关于使用LLM进行情感支持的5126篇帖子，发现用户对LLM的接受度主要受其结果、信任度和回应质量的影响，而非情感联结。与任务和目标一致的使用带来积极评价，而陪伴型使用则可能带来依赖和症状加剧等风险。", "motivation": "当前LLM被广泛用于临床环境外的心理健康支持，但对其在日常使用中的用户评价和互动方式知之甚少。", "method": "研究人员基于技术接受模型和治疗联盟理论，开发了一个理论指导的标注框架，并采用LLM-人类混合分析流程，分析了来自47个心理健康社区的5126篇Reddit帖子，以评估用户的评价语言、采纳态度和关系一致性。", "result": "用户的参与度主要受叙述的成果、信任度和回应质量驱动，情感联结并非主要因素。积极情绪与任务和目标的一致性最相关。而陪伴型使用更容易出现联盟不匹配，并报告了依赖和症状升级等风险。", "conclusion": "本研究表明，可以将理论指导下的构建操作化为大规模话语分析，并强调了在敏感的现实世界背景下研究用户如何理解语言技术的重要性。"}}
{"id": "2601.20680", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20680", "abs": "https://arxiv.org/abs/2601.20680", "authors": ["Ostap Vykhopen", "Viktoria Skorik", "Maxim Tereschenko", "Veronika Solopova"], "title": "Online Density-Based Clustering for Real-Time Narrative Evolution Monitorin", "comment": null, "summary": "Automated narrative intelligence systems for social media monitoring face significant scalability challenges when processing continuous data streams using traditional batch clustering algorithms. We investigate the replacement of HDBSCAN (offline clustering) with online (streaming/incremental) clustering methods in a production narrative report generation pipeline. The proposed system employs a three-stage architecture (data collection, modeling, dashboard generation) that processes thousands of multilingual social media documents daily. While HDBSCAN excels at discovering hierarchical density-based clusters and handling noise, its batch-only nature necessitates complete retraining for each time window, resulting in memory constraints, computational inefficiency, and inability to adapt to evolving narratives in real-time. This work evaluates a bunch of online clustering algorithms across dimensions of cluster quality preservation, computational efficiency, memory footprint, and integration compatibility with existing workflows. We propose evaluation criteria that balance traditional clustering metrics (Silhouette Coefficient, Davies-Bouldin Index) with narrative metrics (narrative distinctness, contingency and variance). Our methodology includes sliding-window simulations on historical datasets from Ukraine information space, enabling comparative analysis of algorithmic trade-offs in realistic operational contexts. This research addresses a critical gap between batch-oriented topic modeling frameworks and the streaming nature of social media monitoring, with implications for computational social science, crisis informatics, and narrative surveillance systems.", "AI": {"tldr": "本研究旨在解决社交媒体监控中自动化叙事智能系统在处理连续数据流时面临的可扩展性挑战。研究将离线聚类算法 HDBSCAN 替换为在线（流式/增量式）聚类方法，以提高处理效率并实时适应不断变化的叙事。", "motivation": "传统的批处理聚类算法在处理连续社交媒体数据流时存在内存限制、计算效率低下以及无法实时适应演变叙事的问题。作者希望通过引入在线聚类算法来克服这些挑战。", "method": "研究提出了一个三阶段的系统架构（数据收集、建模、仪表板生成），并评估了多种在线聚类算法，通过滑动窗口模拟在历史数据集上进行对比分析。评估维度包括聚类质量、计算效率、内存占用和集成兼容性，并结合传统聚类指标（Silhouette Coefficient, Davies-Bouldin Index）和叙事指标（叙事独特性、偶然性和方差）。", "result": "研究评估了不同在线聚类算法在处理大规模、多语言社交媒体数据时的表现，并提出了一个综合的评估标准来权衡算法的优缺点，以便在实际操作环境中进行选择。", "conclusion": "本研究填补了批处理主题建模框架与社交媒体监控流式性质之间的关键空白，为计算社会科学、危机信息学和叙事监控系统提供了更有效、可扩展的解决方案。"}}
{"id": "2601.20757", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20757", "abs": "https://arxiv.org/abs/2601.20757", "authors": ["Jing Yang", "Moritz Hechtbauer", "Elisabeth Khalilov", "Evelyn Luise Brinkmann", "Vera Schmitt", "Nils Feldhus"], "title": "Persona Prompting as a Lens on LLM Social Reasoning", "comment": "9 Pages, EACL main", "summary": "For socially sensitive tasks like hate speech detection, the quality of explanations from Large Language Models (LLMs) is crucial for factors like user trust and model alignment. While Persona prompting (PP) is increasingly used as a way to steer model towards user-specific generation, its effect on model rationales remains underexplored. We investigate how LLM-generated rationales vary when conditioned on different simulated demographic personas. Using datasets annotated with word-level rationales, we measure agreement with human annotations from different demographic groups, and assess the impact of PP on model bias and human alignment. Our evaluation across three LLMs results reveals three key findings: (1) PP improving classification on the most subjective task (hate speech) but degrading rationale quality. (2) Simulated personas fail to align with their real-world demographic counterparts, and high inter-persona agreement shows models are resistant to significant steering. (3) Models exhibit consistent demographic biases and a strong tendency to over-flag content as harmful, regardless of PP. Our findings reveal a critical trade-off: while PP can improve classification in socially-sensitive tasks, it often comes at the cost of rationale quality and fails to mitigate underlying biases, urging caution in its application.", "AI": {"tldr": "研究发现，在仇恨言论检测等社会敏感任务中，尽管 Persona Prompting (PP) 可以提高分类性能，但会损害模型解释的质量，且无法有效解决模型偏见问题，甚至可能阻碍模型朝着人类标注的真实人口群体对齐。", "motivation": "为了在仇恨言论检测等社会敏感任务中提升用户信任度和模型对齐性，需要高质量的模型解释。Persona Prompting (PP) 是一种常用的引导模型生成特定风格文本的方法，但其对模型解释（rationales）的影响尚不明确。", "method": "研究人员模拟了不同的人口统计学身份（demographic personas），并考察了 LLM 在条件化于这些模拟身份时生成的解释（rationales）的变化。他们使用带有词级别解释标注的数据集，测量了 LLM 解释与不同人口群体的人类标注的一致性，并评估了 PP 对模型偏见和人类对齐的影响。", "result": "1. PP 在最主观的任务（仇恨言论检测）上提高了分类性能，但损害了解释的质量。2. 模拟身份与现实世界中的人口群体不符，且模型在不同身份之间表现出较高的一致性，表明模型在很大程度上抵抗了显著的引导。3. 无论是否使用 PP，模型都表现出持续的人口统计学偏见，并倾向于过度标记（over-flag）内容为有害。", "conclusion": "研究揭示了一个关键的权衡：PP 可以在社会敏感任务中提高分类性能，但通常会以牺牲解释质量为代价，并且未能减轻潜在的偏见。因此，在使用 PP 时需要谨慎，因为它可能无法实现预期的偏见缓解目标。"}}
{"id": "2601.20679", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20679", "abs": "https://arxiv.org/abs/2601.20679", "authors": ["Mingqiao Mo", "Yunlong Tan", "Hao Zhang", "Heng Zhang", "Yangfan He"], "title": "ShieldedCode: Learning Robust Representations for Virtual Machine Protected Code", "comment": "Accepted to ICLR 2026", "summary": "Large language models (LLMs) have achieved remarkable progress in code generation, yet their potential for software protection remains largely untapped. Reverse engineering continues to threaten software security, while traditional virtual machine protection (VMP) relies on rigid, rule-based transformations that are costly to design and vulnerable to automated analysis. In this work, we present the first protection-aware framework that learns robust representations of VMP-protected code. Our approach builds large-scale paired datasets of source code and normalized VM implementations, and introduces hierarchical dependency modeling at intra-, preceding-, and inter-instruction levels. We jointly optimize language modeling with functionality-aware and protection-aware contrastive objectives to capture both semantic equivalence and protection strength. To further assess resilience, we propose a protection effectiveness optimization task that quantifies and ranks different VM variants derived from the same source. Coupled with a two-stage continual pre-training and fine-tuning pipeline, our method enables models to generate, compare, and reason over protected code. Extensive experiments show that our framework significantly improves robustness across diverse protection levels, opening a new research direction for learning-based software defense. In this work, we present ShieldedCode, the first protection-aware framework that learns robust representations of VMP-protected code. Our method achieves 26.95% Pass@1 on L0 VM code generation compared to 22.58% for GPT-4o., and improves binary similarity detection Recall@1 by 10% over state of art methods like jTrans.", "AI": {"tldr": "本文提出了 ShieldedCode，一个首个用于虚拟机保护（VMP）代码的保护感知框架，该框架能够学习 VMP 保护代码的鲁棒表示，并在代码生成和二进制相似性检测方面取得了显著的性能提升。", "motivation": "传统软件保护方法（如 VMP）成本高昂且易受自动化分析攻击，而大型语言模型（LLMs）在软件保护领域的潜力尚未被充分挖掘。研究旨在利用 LLMs 学习 VMP 保护代码的鲁棒表示，以应对逆向工程的威胁。", "method": "该研究构建了大规模的源代码和规范化虚拟机实现配对数据集，引入了层级依赖建模（指令内、前驱指令、指令间），并联合优化了语言模型与功能感知和保护感知的对比学习目标，以捕捉语义等价性和保护强度。此外，提出了一个保护有效性优化任务来量化和排序不同 VM 变体。最后，采用了两阶段的持续预训练和微调流程。", "result": "ShieldedCode 在 L0 VM 代码生成方面实现了 26.95% 的 Pass@1 准确率，优于 GPT-4o 的 22.58%。在二进制相似性检测方面，将 Recall@1 提高了 10%，优于 jTrans 等现有技术。该框架在不同保护级别下显著提高了鲁棒性。", "conclusion": "ShieldedCode 是首个能够学习 VMP 保护代码鲁棒表示的保护感知框架，其在代码生成和二进制相似性检测方面的优异表现，为基于学习的软件防御开启了新的研究方向。"}}
{"id": "2601.20730", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20730", "abs": "https://arxiv.org/abs/2601.20730", "authors": ["Shicheng Fang", "Yuxin Wang", "XiaoRan Liu", "Jiahao Lu", "Chuanyuan Tan", "Xinchi Chen", "Yining Zheng. Xuanjing Huang", "Xipeng Qiu"], "title": "AgentLongBench: A Controllable Long Benchmark For Long-Contexts Agents via Environment Rollouts", "comment": "26 pages", "summary": "The evolution of Large Language Models (LLMs) into autonomous agents necessitates the management of extensive, dynamic contexts. Current benchmarks, however, remain largely static, relying on passive retrieval tasks that fail to simulate the complexities of agent-environment interaction, such as non-linear reasoning and iterative feedback. To address this, we introduce \\textbf{AgentLongBench}, which evaluates agents through simulated environment rollouts based on Lateral Thinking Puzzles. This framework generates rigorous interaction trajectories across knowledge-intensive and knowledge-free scenarios. Experiments with state-of-the-art models and memory systems (32K to 4M tokens) expose a critical weakness: while adept at static retrieval, agents struggle with the dynamic information synthesis essential for workflows. Our analysis indicates that this degradation is driven by the minimum number of tokens required to resolve a query. This factor explains why the high information density inherent in massive tool responses poses a significantly greater challenge than the memory fragmentation typical of long-turn dialogues.", "AI": {"tldr": "本文提出 AgentLongBench 评测基准，通过模拟包含迭代反馈的交互式任务来评估大型语言模型（LLMs）作为自主代理的能力，发现现有模型在动态信息整合方面存在不足，尤其是在处理大规模工具响应时。", "motivation": "现有的大型语言模型（LLMs）基准测试大多是静态的，无法模拟自主代理在动态环境中与环境交互的复杂性，例如非线性推理和迭代反馈。因此，需要一个能够评估 LLMs 在动态交互场景下处理长上下文的能力的基准。", "method": "提出 AgentLongBench 评测框架，该框架基于横向思维谜题（Lateral Thinking Puzzles）来模拟环境和生成交互轨迹。实验评估了不同规模（32K 到 4M tokens）的 LLMs 和内存系统在知识密集型和知识无关型场景下的表现。", "result": "实验结果表明，尽管 LLMs 在静态检索任务上表现良好，但在动态信息合成方面存在显著的弱点，尤其是在处理需要大规模工具响应的场景下。研究发现，解决查询所需的最小 token 数量是导致性能下降的关键因素，这比长对话中的内存碎片化更具挑战性。", "conclusion": "AgentLongBench 揭示了当前 LLMs 在处理长、动态上下文的自主代理任务中的局限性。研究强调了动态信息合成的重要性，并指出大规模工具响应带来的信息密度是影响模型性能的主要障碍。"}}
{"id": "2601.20803", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20803", "abs": "https://arxiv.org/abs/2601.20803", "authors": ["Aunabil Chakma", "Mihai Surdeanu", "Eduardo Blanco"], "title": "Structured Semantic Information Helps Retrieve Better Examples for In-Context Learning in Few-Shot Relation Extraction", "comment": null, "summary": "This paper presents several strategies to automatically obtain additional examples for in-context learning of one-shot relation extraction. Specifically, we introduce a novel strategy for example selection, in which new examples are selected based on the similarity of their underlying syntactic-semantic structure to the provided one-shot example. We show that this method results in complementary word choices and sentence structures when compared to LLM-generated examples. When these strategies are combined, the resulting hybrid system achieves a more holistic picture of the relations of interest than either method alone. Our framework transfers well across datasets (FS-TACRED and FS-FewRel) and LLM families (Qwen and Gemma). Overall, our hybrid selection method consistently outperforms alternative strategies and achieves state-of-the-art performance on FS-TACRED and strong gains on a customized FewRel subset.", "AI": {"tldr": "本文提出了一种基于语法-语义结构相似度的示例选择策略，用于提高单次关系提取的 in-context learning 效果，并取得了比 LLM 生成示例更互补的词汇和句子结构，从而实现了最优性能。", "motivation": "自动获取额外的 in-context learning 示例以提升关系提取性能。", "method": "提出了一种基于目标示例的语法-语义结构相似度的新型示例选择策略，并将其与 LLM 生成的示例相结合。", "result": "所提出的示例选择策略产生的示例在词汇和句子结构上与 LLM 生成的示例互补。混合系统比单独使用任一方法都能更全面地描绘关系。该框架在不同数据集（FS-TACRED 和 FS-FewRel）和 LLM 系列（Qwen 和 Gemma）上表现出良好的迁移性。混合选择方法在 FS-TACRED 上实现了最先进的性能，并在自定义的 FewRel 子集上取得了显著的提升。", "conclusion": "基于语法-语义结构相似度的混合示例选择策略能够有效地提高单次关系提取的 in-context learning 性能，并优于其他替代策略。"}}
{"id": "2601.20796", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20796", "abs": "https://arxiv.org/abs/2601.20796", "authors": ["Yiran Huang", "Karsten Roth", "Quentin Bouniot", "Wenjia Xu", "Zeynep Akata"], "title": "Dissecting Multimodal In-Context Learning: Modality Asymmetries and Circuit Dynamics in modern Transformers", "comment": null, "summary": "Transformer-based multimodal large language models often exhibit in-context learning (ICL) abilities. Motivated by this phenomenon, we ask: how do transformers learn to associate information across modalities from in-context examples? We investigate this question through controlled experiments on small transformers trained on synthetic classification tasks, enabling precise manipulation of data statistics and model architecture. We begin by revisiting core principles of unimodal ICL in modern transformers. While several prior findings replicate, we find that Rotary Position Embeddings (RoPE) increases the data complexity threshold for ICL. Extending to the multimodal setting reveals a fundamental learning asymmetry: when pretrained on high-diversity data from a primary modality, surprisingly low data complexity in the secondary modality suffices for multimodal ICL to emerge. Mechanistic analysis shows that both settings rely on an induction-style mechanism that copies labels from matching in-context exemplars; multimodal training refines and extends these circuits across modalities. Our findings provide a mechanistic foundation for understanding multimodal ICL in modern transformers and introduce a controlled testbed for future investigation.", "AI": {"tldr": "本研究通过对小型 Transformer 模型进行受控实验，探究了 Transformer 驱动的多模态大语言模型（LLM）如何在上下文学习（ICL）中跨模态关联信息，发现了 RoPE 对 ICL 数据复杂度阈值的影响，以及多模态 ICL 中的学习不对称性，并揭示了跨模态的诱导式复制机制。", "motivation": "研究者希望理解 Transformer 驱动的多模态 LLM 如何从上下文示例中学习跨模态关联信息。", "method": "研究者在合成分类任务上训练了小型 Transformer 模型，并进行了控制实验，精确操控数据统计和模型架构。他们首先重现了单模态 ICL 的核心发现，然后扩展到多模态设置，并进行了机制分析。", "result": "1. Rotary Position Embeddings (RoPE) 提高了 ICL 的数据复杂度阈值。2. 在主要模态具有高多样性数据预训练的情况下，次要模态所需的低数据复杂度即可实现多模态 ICL，存在学习不对称性。3. 单模态和多模态 ICL 都依赖于一种诱导式机制，通过复制匹配的上下文示例中的标签来实现。多模态训练则能在模态之间精炼和扩展这些电路。", "conclusion": "本研究为理解现代 Transformer 中的多模态 ICL 提供了机制基础，并提出了一种可控的实验测试平台，以供未来研究使用。"}}
{"id": "2601.20789", "categories": ["cs.CL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.20789", "abs": "https://arxiv.org/abs/2601.20789", "authors": ["Ethan Shen", "Danny Tormoen", "Saurabh Shah", "Ali Farhadi", "Tim Dettmers"], "title": "SERA: Soft-Verified Efficient Repository Agents", "comment": "21 main pages, 7 pages appendix", "summary": "Open-weight coding agents should hold a fundamental advantage over closed-source systems: they can be specialized to private codebases, encoding repository-specific information directly in their weights. Yet the cost and complexity of training has kept this advantage theoretical. We show it is now practical. We present Soft-Verified Efficient Repository Agents (SERA), an efficient method for training coding agents that enables the rapid and cheap creation of agents specialized to private codebases. Using only supervised finetuning (SFT), SERA achieves state-of-the-art results among fully open-source (open data, method, code) models while matching the performance of frontier open-weight models like Devstral-Small-2. Creating SERA models is 26x cheaper than reinforcement learning and 57x cheaper than previous synthetic data methods to reach equivalent performance. Our method, Soft Verified Generation (SVG), generates thousands of trajectories from a single code repository. Combined with cost-efficiency, this enables specialization to private codebases. Beyond repository specialization, we apply SVG to a larger corpus of codebases, generating over 200,000 synthetic trajectories. We use this dataset to provide detailed analysis of scaling laws, ablations, and confounding factors for training coding agents. Overall, we believe our work will greatly accelerate research on open coding agents and showcase the advantage of open-source models that can specialize to private codebases. We release SERA as the first model in Ai2's Open Coding Agents series, along with all our code, data, and Claude Code integration to support the research community.", "AI": {"tldr": "本文提出了一种名为 SERA 的高效训练编码代理的方法，该方法允许代理快速廉价地专门化到私有代码库，通过软件验证生成（SVG）技术，SERA 在成本和效率上优于现有方法，并提供了详细的缩放规律分析，旨在加速开源编码代理的研究。", "motivation": "现有的闭源编码代理虽然可以进行私有代码库的定制，但由于训练成本和复杂性，这一优势一直未能得到充分发挥。作者希望通过开发一种更高效、更经济的训练方法，使开源代理能够真正实现私有代码库的专门化。", "method": "本文提出的 SERA 方法主要通过两种方式实现：1. 软件验证生成（SVG）：从单个代码库生成数千个轨迹。2. 高效的监督微调（SFT）：利用 SVG 生成的数据进行训练。此外，文章还对 SVG 在更大规模代码库上的应用进行了研究，生成了超过 200,000 个合成轨迹，并在此数据集上进行了缩放规律、消融实验和混淆因素的详细分析。", "result": "SERA 在完全开源的模型中取得了最先进的性能，并与 Devstral-Small-2 等前沿模型性能相当。SERA 的训练成本比强化学习低 26 倍，比之前的合成数据方法低 57 倍，以达到同等性能。研究还揭示了训练编码代理的缩放规律、消融实验和混淆因素。", "conclusion": "SERA 方法使得开源编码代理能够经济高效地专门化到私有代码库，克服了以往的训练成本和复杂性障碍。这项工作有望大大加速开源编码代理的研究，并展示了开源模型在私有代码库专门化方面的优势。作者发布了 SERA 模型、代码和数据，以支持社区研究。"}}
{"id": "2601.20834", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20834", "abs": "https://arxiv.org/abs/2601.20834", "authors": ["Andrew Kyle Lampinen", "Yuxuan Li", "Eghbal Hosseini", "Sangnie Bhardwaj", "Murray Shanahan"], "title": "Linear representations in language models can change dramatically over a conversation", "comment": null, "summary": "Language model representations often contain linear directions that correspond to high-level concepts. Here, we study the dynamics of these representations: how representations evolve along these dimensions within the context of (simulated) conversations. We find that linear representations can change dramatically over a conversation; for example, information that is represented as factual at the beginning of a conversation can be represented as non-factual at the end and vice versa. These changes are content-dependent; while representations of conversation-relevant information may change, generic information is generally preserved. These changes are robust even for dimensions that disentangle factuality from more superficial response patterns, and occur across different model families and layers of the model. These representation changes do not require on-policy conversations; even replaying a conversation script written by an entirely different model can produce similar changes. However, adaptation is much weaker from simply having a sci-fi story in context that is framed more explicitly as such. We also show that steering along a representational direction can have dramatically different effects at different points in a conversation. These results are consistent with the idea that representations may evolve in response to the model playing a particular role that is cued by a conversation. Our findings may pose challenges for interpretability and steering -- in particular, they imply that it may be misleading to use static interpretations of features or directions, or probes that assume a particular range of features consistently corresponds to a particular ground-truth value. However, these types of representational dynamics also point to exciting new research directions for understanding how models adapt to context.", "AI": {"tldr": "语言模型的表示在对话中会随着概念维度动态变化，例如事实性可以随时间改变，且这种变化是内容相关的，模型在不同对话阶段对同一表征维度的控制效果也不同。", "motivation": "研究语言模型表示在对话中的动态变化，特别是高层概念的表示如何随时间演变。", "method": "在模拟对话中，观察并分析语言模型表示沿着特定概念维度（如事实性）的变化，比较不同模型家族、模型层、以及不同对话上下文（如重播脚本、科幻故事）下的变化情况，并通过控制表示维度来观察其效果。", "result": "表示在对话中会发生显著的动态变化，例如事实性表示会改变；这种变化依赖于对话内容；模型在对话不同阶段对同一表示维度的操控效果不同；即使在无奖励的对话脚本重播中也会发生这种变化。", "conclusion": "语言模型的表示并非静态不变，而是会根据对话上下文动态调整，这暗示模型可能扮演着根据对话线索调整角色的行为。这对模型的可解释性和控制提出了挑战，表明静态解释可能存在误导，但同时也为理解模型的上下文适应性提供了新的研究方向。"}}
{"id": "2601.20858", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20858", "abs": "https://arxiv.org/abs/2601.20858", "authors": ["David Tan", "Pinzhen Chen", "Josef van Genabith", "Koel Dutta Chowdhury"], "title": "When Flores Bloomz Wrong: Cross-Direction Contamination in Machine Translation Evaluation", "comment": "5 pages of content, 15 total. 5 figures, 12 tables total. Accepted to EACL 2026 main conference. Code can be found here: github.com/Mr-Ao-25/cross-ling-contamination", "summary": "Large language models (LLMs) can be benchmark-contaminated, resulting in inflated scores that mask memorization as generalization, and in multilingual settings, this memorization can even transfer to \"uncontaminated\" languages. Using the FLORES-200 translation benchmark as a diagnostic, we study two 7-8B instruction-tuned multilingual LLMs: Bloomz, which was trained on FLORES, and Llama as an uncontaminated control. We confirm Bloomz's FLORES contamination and demonstrate that machine translation contamination can be cross-directional, artificially boosting performance in unseen translation directions due to target-side memorization. Further analysis shows that recall of memorized references often persists despite various source-side perturbation efforts like paraphrasing and named entity replacement. However, replacing named entities leads to a consistent decrease in BLEU, suggesting an effective probing method for memorization in contaminated models.", "AI": {"tldr": "本研究通过 FLORES-200 评估了两个多语言大语言模型（Bloomz 和 Llama）在基准测试污染方面的问题，发现 Bloomz 存在污染，并且污染效应可以跨语言方向传递，甚至在目标语言端发生记忆。研究还提出，替换命名实体是检测模型记忆的一种有效方法。", "motivation": "大型语言模型（LLMs）在基准测试中可能存在污染，导致分数虚高，将记忆误认为泛化。尤其是在多语言设置下，这种记忆甚至可能转移到“未污染”的语言，影响模型真实能力的评估。", "method": "使用 FLORES-200 翻译基准测试，对比了两个 7-8B 参数的多语言指令微调 LLMs：Bloomz（在 FLORES 上训练过）和 Llama（作为未污染的对照组）。通过对源语言进行各种扰动（如释义、替换命名实体），分析模型在翻译任务上的表现（BLEU 分数），以诊断和量化基准测试污染。", "result": "确认了 Bloomz 在 FLORES 基准测试中存在污染。研究发现，机器翻译的污染是跨方向的，目标语言端的记忆可以人工提高模型在未见过的翻译方向上的性能。替换命名实体可以导致 BLEU 分数一致下降，表明这是一种有效的探测污染模型记忆的方法。", "conclusion": "多语言 LLMs 存在基准测试污染问题，且污染效应具有跨语言传递性。模型对记忆的参照内容具有很强的保留能力，即使在源语言经过扰动后也难以消除。替换命名实体是一种有效的探测多语言 LLM 记忆污染的策略。"}}
