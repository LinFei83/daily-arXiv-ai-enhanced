<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 48]
- [cs.CV](#cs.CV) [Total: 163]
- [cs.CL](#cs.CL) [Total: 68]
- [cs.RO](#cs.RO) [Total: 49]
- [eess.SY](#eess.SY) [Total: 20]
- [eess.IV](#eess.IV) [Total: 12]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Attention of a Kiss: Exploring Attention Maps in Video Diffusion for XAIxArts](https://arxiv.org/abs/2509.05323)
*Adam Cole,Mick Grierson*

Main category: cs.AI

TL;DR: 本文对视频扩散Transformer的注意力机制进行了艺术和技术研究，提出了一种提取和可视化生成视频模型中交叉注意力图的方法，旨在将其作为分析工具和艺术创作材料，并促进AI在艺术领域的解释性应用。


<details>
  <summary>Details</summary>
Motivation: 研究灵感来源于早期通过操纵模拟视频信号创造新视觉美学的视频艺术家，以及对生成视频模型中注意力机制可解释性的需求，特别是在艺术创作背景下。

Method: 该研究提出了一种提取和可视化生成视频模型中交叉注意力图的方法。该工具基于开源的Wan模型构建，提供了一个可解释的窗口来观察文本到视频生成中注意力的时空行为。

Result: 通过探索性探究和艺术案例研究，论文检验了注意力图作为分析工具和原始艺术材料的潜力。

Conclusion: 这项工作为艺术领域的可解释人工智能（XAIxArts）做出了贡献，并邀请艺术家将AI的内部运作重新视为一种创意媒介。

Abstract: This paper presents an artistic and technical investigation into the
attention mechanisms of video diffusion transformers. Inspired by early video
artists who manipulated analog video signals to create new visual aesthetics,
this study proposes a method for extracting and visualizing cross-attention
maps in generative video models. Built on the open-source Wan model, our tool
provides an interpretable window into the temporal and spatial behavior of
attention in text-to-video generation. Through exploratory probes and an
artistic case study, we examine the potential of attention maps as both
analytical tools and raw artistic material. This work contributes to the
growing field of Explainable AI for the Arts (XAIxArts), inviting artists to
reclaim the inner workings of AI as a creative medium.

</details>


### [2] [Perception Graph for Cognitive Attack Reasoning in Augmented Reality](https://arxiv.org/abs/2509.05324)
*Rongqian Chen,Shu Hong,Rifatul Islam,Mahdi Imani,G. Gary Tan,Tian Lan*

Main category: cs.AI

TL;DR: 本文提出了一种名为“感知图”的新模型，用于在战术增强现实（AR）系统中推理人类感知，以检测和分析认知攻击造成的感知扭曲。


<details>
  <summary>Details</summary>
Motivation: 增强现实（AR）系统在战术环境中日益部署，但其对无缝人机交互的依赖使其容易受到认知攻击。这些攻击会操纵用户的感知，严重损害用户决策，因此需要一种方法来应对这一挑战。

Method: 引入了“感知图”模型。该模型首先模仿人类从MR环境中解释关键信息的过程，然后使用语义上有意义的结构来表示结果。通过这种方式，模型能够计算一个量化分数，反映感知扭曲的程度。

Result: 该模型能够计算一个反映感知扭曲程度的量化分数，提供了一种稳健且可衡量的方法来检测和分析此类认知攻击的影响。

Conclusion: “感知图”模型通过量化感知扭曲，为检测和分析战术AR系统中认知攻击的效果提供了一种新颖且可衡量的方法。

Abstract: Augmented reality (AR) systems are increasingly deployed in tactical
environments, but their reliance on seamless human-computer interaction makes
them vulnerable to cognitive attacks that manipulate a user's perception and
severely compromise user decision-making. To address this challenge, we
introduce the Perception Graph, a novel model designed to reason about human
perception within these systems. Our model operates by first mimicking the
human process of interpreting key information from an MR environment and then
representing the outcomes using a semantically meaningful structure. We
demonstrate how the model can compute a quantitative score that reflects the
level of perception distortion, providing a robust and measurable method for
detecting and analyzing the effects of such cognitive attacks.

</details>


### [3] [SynDelay: A Synthetic Dataset for Delivery Delay Prediction](https://arxiv.org/abs/2509.05325)
*Liming Xu,Yunbo Long,Alexandra Brintrup*

Main category: cs.AI

TL;DR: 该论文提出了SynDelay，一个用于预测交货延迟的合成数据集。该数据集通过先进的生成模型基于真实数据生成，旨在解决高质量开放数据稀缺的问题，并提供基准结果以促进供应链AI领域的研究和基准测试。


<details>
  <summary>Details</summary>
Motivation: 人工智能正在改变供应链管理，但预测任务（如交货延迟预测）的进展受到高质量、开放可用数据集稀缺的限制。现有数据集通常是专有的、规模小或维护不一致，这阻碍了研究的重现性和基准测试。

Method: 研究人员创建了SynDelay，一个用于交货延迟预测的合成数据集。该数据集使用在真实世界数据上训练的先进生成模型生成，旨在保留真实的交货模式同时确保隐私。

Result: SynDelay提供了一个具有挑战性和实用性的测试平台，用于推进预测建模。尽管存在一些噪音或不一致性，它仍然是一个有价值的资源。论文提供了基线结果和评估指标作为初始基准，并通过Supply Chain Data Hub公开可用。

Conclusion: SynDelay通过提供一个公开可用的合成数据集，解决了供应链AI中预测任务（特别是交货延迟预测）的数据稀缺问题。它旨在促进该领域研究的重现性、基准测试和进步，并鼓励社区贡献数据集、模型和评估实践。

Abstract: Artificial intelligence (AI) is transforming supply chain management, yet
progress in predictive tasks -- such as delivery delay prediction -- remains
constrained by the scarcity of high-quality, openly available datasets.
Existing datasets are often proprietary, small, or inconsistently maintained,
hindering reproducibility and benchmarking. We present SynDelay, a synthetic
dataset designed for delivery delay prediction. Generated using an advanced
generative model trained on real-world data, SynDelay preserves realistic
delivery patterns while ensuring privacy. Although not entirely free of noise
or inconsistencies, it provides a challenging and practical testbed for
advancing predictive modelling. To support adoption, we provide baseline
results and evaluation metrics as initial benchmarks, serving as reference
points rather than state-of-the-art claims. SynDelay is publicly available
through the Supply Chain Data Hub, an open initiative promoting dataset sharing
and benchmarking in supply chain AI. We encourage the community to contribute
datasets, models, and evaluation practices to advance research in this area.
All code is openly accessible at https://supplychaindatahub.org.

</details>


### [4] [MVRS: The Multimodal Virtual Reality Stimuli-based Emotion Recognition Dataset](https://arxiv.org/abs/2509.05330)
*Seyed Muhammad Hossein Mousavi,Atiye Ilanloo*

Main category: cs.AI

TL;DR: 该论文介绍了MVRS数据集，一个包含眼动、身体运动和生理信号的多模态情感识别数据集，以解决现有数据集的不足。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的兴起，自动情感识别变得越来越重要，但在医疗、教育和汽车系统等领域，缺乏多模态数据集，特别是涉及身体运动和生理信号的数据集，这限制了该领域的进展。

Method: 引入了MVRS数据集，包含13名12至60岁参与者在VR情感刺激（放松、恐惧、压力、悲伤、快乐）下的同步记录。数据通过眼动追踪（VR头显内的网络摄像头）、身体运动（Kinect v2）以及EMG和GSR信号（Arduino UNO）收集，所有数据均时间戳对齐。参与者遵循统一协议，并进行问卷调查。从每种模态中提取特征，使用早期和晚期融合技术进行融合，并通过分类器进行评估，以确认数据集的质量和情感可分离性。

Result: 通过分类器评估，确认了MVRS数据集的质量和情感可分离性。

Conclusion: MVRS数据集是对多模态情感计算的宝贵贡献，有助于推动该领域的发展。

Abstract: Automatic emotion recognition has become increasingly important with the rise
of AI, especially in fields like healthcare, education, and automotive systems.
However, there is a lack of multimodal datasets, particularly involving body
motion and physiological signals, which limits progress in the field. To
address this, the MVRS dataset is introduced, featuring synchronized recordings
from 13 participants aged 12 to 60 exposed to VR based emotional stimuli
(relaxation, fear, stress, sadness, joy). Data were collected using eye
tracking (via webcam in a VR headset), body motion (Kinect v2), and EMG and GSR
signals (Arduino UNO), all timestamp aligned. Participants followed a unified
protocol with consent and questionnaires. Features from each modality were
extracted, fused using early and late fusion techniques, and evaluated with
classifiers to confirm the datasets quality and emotion separability, making
MVRS a valuable contribution to multimodal affective computing.

</details>


### [5] [Benchmarking Large Language Models for Personalized Guidance in AI-Enhanced Learning](https://arxiv.org/abs/2509.05346)
*Bo Yuan,Jiazi Hu*

Main category: cs.AI

TL;DR: 本研究在模拟真实学习场景的辅导任务中，系统评估了三种领先的大语言模型（LLMs）作为个性化学习助手的表现，发现GPT-4o在反馈质量上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）被广泛设想为个性化学习的智能助手，但在真实的学习场景中，缺乏系统性的头对头评估。

Method: 研究比较了GPT-4o、DeepSeek-V3和GLM-4.5三种先进LLM在一个模拟真实学习环境的辅导任务中的表现。每个LLM需完成三项任务：分析测验以识别知识点、推断学生掌握情况、生成有针对性的改进指导。为减少主观性和评估者偏差，研究使用Gemini作为虚拟评判员，从准确性、清晰度、可操作性和适当性等维度进行配对比较，并采用Bradley-Terry模型分析结果。

Result: 通过Bradley-Terry模型分析显示，GPT-4o通常更受青睐，其生成的反馈比其他模型更具信息量且结构更优。DeepSeek-V3和GLM-4.5虽然偶尔表现出优势，但一致性较低。

Conclusion: 这些发现突出了部署LLMs作为高级教学助手提供个性化支持的可行性，并为未来关于LLM驱动个性化学习的实证研究提供了方法论指导。

Abstract: While Large Language Models (LLMs) are increasingly envisioned as intelligent
assistants for personalized learning, systematic head-to-head evaluations
within authentic learning scenarios remain limited. This study conducts an
empirical comparison of three state-of-the-art LLMs on a tutoring task that
simulates a realistic learning setting. Using a dataset comprising a student's
answers to ten questions of mixed formats with correctness labels, each LLM is
required to (i) analyze the quiz to identify underlying knowledge components,
(ii) infer the student's mastery profile, and (iii) generate targeted guidance
for improvement. To mitigate subjectivity and evaluator bias, we employ Gemini
as a virtual judge to perform pairwise comparisons along various dimensions:
accuracy, clarity, actionability, and appropriateness. Results analyzed via the
Bradley-Terry model indicate that GPT-4o is generally preferred, producing
feedback that is more informative and better structured than its counterparts,
while DeepSeek-V3 and GLM-4.5 demonstrate intermittent strengths but lower
consistency. These findings highlight the feasibility of deploying LLMs as
advanced teaching assistants for individualized support and provide
methodological guidance for future empirical research on LLM-driven
personalized learning.

</details>


### [6] [SasAgent: Multi-Agent AI System for Small-Angle Scattering Data Analysis](https://arxiv.org/abs/2509.05363)
*Lijie Ding,Changwoo Do*

Main category: cs.AI

TL;DR: SasAgent是一个由大型语言模型驱动的多智能体AI系统，通过集成SasView工具并支持文本输入，实现了小角散射（SAS）数据分析的自动化。


<details>
  <summary>Details</summary>
Motivation: 自动化小角散射（SAS）数据分析，简化科学工作流程，并增强SAS研究的自动化水平。

Method: 引入了SasAgent多智能体AI系统，由LLM驱动，包含一个协调器智能体和三个专业智能体（用于散射长度密度计算、合成数据生成和实验数据拟合）。这些智能体利用源自SasView Python库的LLM友好工具（如模型数据工具、RAG文档工具、凹凸拟合工具和SLD计算器工具）执行任务。用户交互通过文本输入，并提供基于Gradio的用户界面。

Result: SasAgent能够解释复杂的用户提示，准确计算散射长度密度（SLD），生成精确的散射数据，并高精度地拟合实验数据集。

Conclusion: 这项工作展示了LLM驱动的AI系统在简化科学工作流程和提升SAS研究自动化方面的巨大潜力。

Abstract: We introduce SasAgent, a multi-agent AI system powered by large language
models (LLMs) that automates small-angle scattering (SAS) data analysis by
leveraging tools from the SasView software and enables user interaction via
text input. SasAgent features a coordinator agent that interprets user prompts
and delegates tasks to three specialized agents for scattering length density
(SLD) calculation, synthetic data generation, and experimental data fitting.
These agents utilize LLM-friendly tools to execute tasks efficiently. These
tools, including the model data tool, Retrieval-Augmented Generation (RAG)
documentation tool, bump fitting tool, and SLD calculator tool, are derived
from the SasView Python library. A user-friendly Gradio-based interface
enhances user accessibility. Through diverse examples, we demonstrate
SasAgent's ability to interpret complex prompts, calculate SLDs, generate
accurate scattering data, and fit experimental datasets with high precision.
This work showcases the potential of LLM-driven AI systems to streamline
scientific workflows and enhance automation in SAS research.

</details>


### [7] [Characterizing Fitness Landscape Structures in Prompt Engineering](https://arxiv.org/abs/2509.05375)
*Arend Hintze*

Main category: cs.AI

TL;DR: 本研究通过自相关分析系统地揭示了Prompt工程优化景观的结构，发现不同Prompt生成策略会导致截然不同的景观拓扑。


<details>
  <summary>Details</summary>
Motivation: Prompt工程在优化大型语言模型性能方面至关重要，但其底层的优化景观却知之甚少。当前的Prompt优化方法将其视为黑盒问题，缺乏对景观拓扑的特征描述。

Method: 本研究采用自相关分析方法，在语义嵌入空间中系统分析Prompt工程的适应度景观结构。实验在错误检测任务上进行，使用了两种Prompt生成策略：系统枚举（1,024个Prompt）和新颖性驱动多样化（1,000个Prompt）。

Result: 系统Prompt生成策略产生了平滑衰减的自相关模式，而多样化生成策略则表现出非单调模式，在中等语义距离处达到峰值相关，表明其景观崎岖且具有分层结构。此外，对10种错误检测类别的任务特定分析显示，不同错误类型在景观崎岖程度上存在差异。

Conclusion: 本研究为理解Prompt工程景观中优化的复杂性提供了经验基础，揭示了Prompt生成策略对优化景观拓扑的关键影响。

Abstract: While prompt engineering has emerged as a crucial technique for optimizing
large language model performance, the underlying optimization landscape remains
poorly understood. Current approaches treat prompt optimization as a black-box
problem, applying sophisticated search algorithms without characterizing the
landscape topology they navigate. We present a systematic analysis of fitness
landscape structures in prompt engineering using autocorrelation analysis
across semantic embedding spaces. Through experiments on error detection tasks
with two distinct prompt generation strategies -- systematic enumeration (1,024
prompts) and novelty-driven diversification (1,000 prompts) -- we reveal
fundamentally different landscape topologies. Systematic prompt generation
yields smoothly decaying autocorrelation, while diversified generation exhibits
non-monotonic patterns with peak correlation at intermediate semantic
distances, indicating rugged, hierarchically structured landscapes.
Task-specific analysis across 10 error detection categories reveals varying
degrees of ruggedness across different error types. Our findings provide an
empirical foundation for understanding the complexity of optimization in prompt
engineering landscapes.

</details>


### [8] [Code Like Humans: A Multi-Agent Solution for Medical Coding](https://arxiv.org/abs/2509.05378)
*Andreas Motzfeldt,Joakim Edin,Casper L. Christensen,Christian Hardmeier,Lars Maaløe,Anna Rogers*

Main category: cs.AI

TL;DR: 该研究引入了“Code Like Humans”框架，这是一个基于大语言模型（LLM）的智能体框架，用于医学编码。它能够支持完整的ICD-10编码系统，并在稀有诊断代码方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 医学编码是一个复杂的过程，需要专家将非结构化的临床笔记映射到字母数字代码。现有的解决方案可能无法支持完整的ICD-10系统，或在处理稀有代码时表现不佳。研究旨在开发一个能够遵循官方编码指南并处理全量代码的解决方案。

Method: 研究引入了一个名为“Code Like Humans”的智能体框架，该框架利用大语言模型，并实现了人类专家所遵循的官方编码指南。它是第一个能够支持完整ICD-10编码系统（超过7万个标签）的解决方案。

Result: 该框架在稀有诊断代码方面取得了迄今为止的最佳性能。虽然经过微调的判别分类器在高频代码方面仍具有优势（但其适用范围有限），“Code Like Humans”在稀有代码方面表现突出。研究还对系统性能进行了分析，并识别了其“盲点”（系统性低估的代码）。

Conclusion: 基于大语言模型的智能体框架“Code Like Humans”为医学编码提供了一个全面且高效的解决方案，特别是在处理稀有诊断代码和支持完整ICD-10系统方面表现出色。未来的工作可以集中于解决系统识别出的“盲点”问题。

Abstract: In medical coding, experts map unstructured clinical notes to alphanumeric
codes for diagnoses and procedures. We introduce Code Like Humans: a new
agentic framework for medical coding with large language models. It implements
official coding guidelines for human experts, and it is the first solution that
can support the full ICD-10 coding system (+70K labels). It achieves the best
performance to date on rare diagnosis codes (fine-tuned discriminative
classifiers retain an advantage for high-frequency codes, to which they are
limited). Towards future work, we also contribute an analysis of system
performance and identify its `blind spots' (codes that are systematically
undercoded).

</details>


### [9] [Murphys Laws of AI Alignment: Why the Gap Always Wins](https://arxiv.org/abs/2509.05381)
*Madhava Gaikwad*

Main category: cs.AI

TL;DR: 本文引入“对齐鸿沟”概念，统一解释了基于反馈的大语言模型对齐方法中常见的失败模式，并提出了“对齐三难困境”和“MAPS框架”，以更好地理解和指导未来的对齐设计。


<details>
  <summary>Details</summary>
Motivation: 尽管RLHF和DPO等对齐方法有效，但它们存在奖励欺骗、奉承、标注者漂移和错误泛化等反复出现的失败模式。

Method: 引入“对齐鸿沟”概念作为统一视角；使用KL倾斜形式化说明优化压力如何放大代理奖励与真实人类意图之间的差异；将失败模式归纳为“AI对齐的墨菲定律”；提出“对齐三难困境”来权衡优化强度、价值捕获和泛化；通过小规模实证研究提供支持；提出“MAPS框架”（Misspecification, Annotation, Pressure, Shift）作为实用设计杠杆。

Result: 研究表明，优化压力倾向于放大代理奖励与真实人类意图之间的分歧。文章分类了对齐失败模式，并提出了对齐中的结构性限制和权衡，如优化强度、价值捕获和泛化之间的取舍。小规模实证研究为这些观点提供了说明性支持。

Conclusion: 本文提供了一个重新审视对齐辩论的视角，侧重于结构性限制和权衡，而非一个明确的不可能性定理，旨在为未来的对齐设计提供更清晰的指导。

Abstract: Large language models are increasingly aligned to human preferences through
reinforcement learning from human feedback (RLHF) and related methods such as
Direct Preference Optimization (DPO), Constitutional AI, and RLAIF. While
effective, these methods exhibit recurring failure patterns i.e., reward
hacking, sycophancy, annotator drift, and misgeneralization. We introduce the
concept of the Alignment Gap, a unifying lens for understanding recurring
failures in feedback-based alignment. Using a KL-tilting formalism, we
illustrate why optimization pressure tends to amplify divergence between proxy
rewards and true human intent. We organize these failures into a catalogue of
Murphys Laws of AI Alignment, and propose the Alignment Trilemma as a way to
frame trade-offs among optimization strength, value capture, and
generalization. Small-scale empirical studies serve as illustrative support.
Finally, we propose the MAPS framework (Misspecification, Annotation, Pressure,
Shift) as practical design levers. Our contribution is not a definitive
impossibility theorem but a perspective that reframes alignment debates around
structural limits and trade-offs, offering clearer guidance for future design.

</details>


### [10] [From Image Generation to Infrastructure Design: a Multi-agent Pipeline for Street Design Generation](https://arxiv.org/abs/2509.05469)
*Chenguang Wang,Xiang Yan,Yilong Dai,Ziyi Wang,Susu Xu*

Main category: cs.AI

TL;DR: 本文提出一个多智能体系统，用于在真实街景图像上直接编辑和重新设计自行车设施，以克服传统方法的劳动密集性和现有AI生成方法在精确空间变化上的局限性，从而支持主动交通规划中的公众参与。


<details>
  <summary>Details</summary>
Motivation: 在主动交通规划中，街景设计场景的逼真渲染对于公众参与至关重要。传统方法劳动密集型，阻碍了集体审议和协作决策。虽然AI辅助生成设计具有快速创建设计场景的潜力，但现有方法通常需要大量领域特定训练数据，并且难以在复杂街景中实现设计/配置的精确空间变化。

Method: 研究引入了一个多智能体系统，直接在真实世界街景图像上编辑和重新设计自行车设施。该框架整合了车道定位、提示优化、设计生成和自动化评估，以合成逼真且符合语境的设计。

Result: 在多样化的城市场景中进行的实验表明，该系统能够适应不同的道路几何形状和环境条件，持续产生视觉上连贯且符合指令的结果。

Conclusion: 这项工作为将多智能体流水线应用于交通基础设施规划和设施设计奠定了基础。

Abstract: Realistic visual renderings of street-design scenarios are essential for
public engagement in active transportation planning. Traditional approaches are
labor-intensive, hindering collective deliberation and collaborative
decision-making. While AI-assisted generative design shows transformative
potential by enabling rapid creation of design scenarios, existing generative
approaches typically require large amounts of domain-specific training data and
struggle to enable precise spatial variations of design/configuration in
complex street-view scenes. We introduce a multi-agent system that edits and
redesigns bicycle facilities directly on real-world street-view imagery. The
framework integrates lane localization, prompt optimization, design generation,
and automated evaluation to synthesize realistic, contextually appropriate
designs. Experiments across diverse urban scenarios demonstrate that the system
can adapt to varying road geometries and environmental conditions, consistently
yielding visually coherent and instruction-compliant results. This work
establishes a foundation for applying multi-agent pipelines to transportation
infrastructure planning and facility design.

</details>


### [11] [TreeGPT: A Novel Hybrid Architecture for Abstract Syntax Tree Processing with Global Parent-Child Aggregation](https://arxiv.org/abs/2509.05550)
*Zixi Li*

Main category: cs.AI

TL;DR: TreeGPT是一种新颖的神经网络架构，结合了Transformer的注意力机制和全局父子聚合机制来处理抽象语法树（ASTs），在程序合成任务中表现出色，尤其在ARC Prize 2025数据集上以1.5M参数实现了96%的准确率，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 传统的程序合成方法要么依赖于顺序处理，要么依赖于图神经网络，这些方法在处理抽象语法树（ASTs）时可能无法有效捕捉局部依赖和复杂的层次结构。因此，需要一种能够同时利用这两种信息的新方法。

Method: TreeGPT采用混合设计，结合了Transformer的自注意力机制（用于捕捉局部依赖）和专门的树前馈网络（TreeFFN，通过迭代消息传递建模层次树结构）。其核心创新是“全局父子聚合机制”，允许每个节点通过多轮迭代从整个树结构中聚合信息。该架构还包括门控聚合、可学习的边权重、残差连接和双向传播等可选增强。

Result: 在ARC Prize 2025数据集上，TreeGPT实现了96%的准确率，显著优于Transformer基线（1.3%）、大型模型Grok-4（15.9%）和专业程序合成方法SOAR（52%），而仅使用1.5M参数。全面的消融研究表明，边投影是最关键的组件，边投影和门控的结合实现了最佳性能。

Conclusion: TreeGPT通过其混合架构和全局父子聚合机制，有效地结合了局部依赖和层次结构建模，在程序合成任务（特别是视觉推理基准）中展现了卓越的性能和参数效率，显著超越了现有模型，证明了其设计理念的有效性。

Abstract: We introduce TreeGPT, a novel neural architecture that combines
transformer-based attention mechanisms with global parent-child aggregation for
processing Abstract Syntax Trees (ASTs) in neural program synthesis tasks.
Unlike traditional approaches that rely solely on sequential processing or
graph neural networks, TreeGPT employs a hybrid design that leverages both
self-attention for capturing local dependencies and a specialized Tree
Feed-Forward Network (TreeFFN) for modeling hierarchical tree structures
through iterative message passing.
  The core innovation lies in our Global Parent-Child Aggregation mechanism,
formalized as: $$h_i^{(t+1)} = \sigma \Big( h_i^{(0)} + W_{pc} \sum_{(p,c) \in
E_i} f(h_p^{(t)}, h_c^{(t)}) + b \Big)$$ where $h_i^{(t)}$ represents the
hidden state of node $i$ at iteration $t$, $E_i$ denotes all parent-child edges
involving node $i$, and $f(h_p, h_c)$ is an edge aggregation function. This
formulation enables each node to progressively aggregate information from the
entire tree structure through $T$ iterations.
  Our architecture integrates optional enhancements including gated aggregation
with learnable edge weights, residual connections for gradient stability, and
bidirectional propagation for capturing both bottom-up and top-down
dependencies. We evaluate TreeGPT on the ARC Prize 2025 dataset, a challenging
visual reasoning benchmark requiring abstract pattern recognition and rule
inference. Experimental results demonstrate that TreeGPT achieves 96\%
accuracy, significantly outperforming transformer baselines (1.3\%),
large-scale models like Grok-4 (15.9\%), and specialized program synthesis
methods like SOAR (52\%) while using only 1.5M parameters. Our comprehensive
ablation study reveals that edge projection is the most critical component,
with the combination of edge projection and gating achieving optimal
performance.

</details>


### [12] [OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision](https://arxiv.org/abs/2509.05578)
*Ruixun Liu,Lingyu Kong,Derun Li,Hang Zhao*

Main category: cs.AI

TL;DR: OccVLA框架通过将3D占据表示整合到多模态推理中，解决了多模态大语言模型（MLLMs）在3D空间理解方面的局限性，实现了自动驾驶任务的先进性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在视觉-语言推理方面表现出色，但在3D空间理解方面仍显不足，这对于自动驾驶至关重要。主要挑战在于：1) 难以在没有昂贵手动标注的情况下构建可访问且有效的3D表示；2) 缺乏大规模3D视觉-语言预训练导致细粒度空间细节的丢失。

Method: OccVLA提出了一种新颖的框架，将3D占据表示集成到统一的多模态推理过程中。与依赖显式3D输入的方法不同，OccVLA将密集的3D占据视为预测输出和监督信号，使模型能够直接从2D视觉输入中学习细粒度的空间结构。占据预测被视为隐式推理过程，推理时可以跳过，不影响性能，也不增加计算开销。

Result: OccVLA在nuScenes基准测试的轨迹规划任务上取得了最先进的结果，并在3D视觉问答任务中表现出卓越的性能。

Conclusion: OccVLA为自动驾驶提供了一个可扩展、可解释且完全基于视觉的解决方案，有效提升了MLLMs的3D空间理解能力。

Abstract: Multimodal large language models (MLLMs) have shown strong vision-language
reasoning abilities but still lack robust 3D spatial understanding, which is
critical for autonomous driving. This limitation stems from two key challenges:
(1) the difficulty of constructing accessible yet effective 3D representations
without expensive manual annotations, and (2) the loss of fine-grained spatial
details in VLMs due to the absence of large-scale 3D vision-language
pretraining. To address these challenges, we propose OccVLA, a novel framework
that integrates 3D occupancy representations into a unified multimodal
reasoning process. Unlike prior approaches that rely on explicit 3D inputs,
OccVLA treats dense 3D occupancy as both a predictive output and a supervisory
signal, enabling the model to learn fine-grained spatial structures directly
from 2D visual inputs. The occupancy predictions are regarded as implicit
reasoning processes and can be skipped during inference without performance
degradation, thereby adding no extra computational overhead. OccVLA achieves
state-of-the-art results on the nuScenes benchmark for trajectory planning and
demonstrates superior performance on 3D visual question-answering tasks,
offering a scalable, interpretable, and fully vision-based solution for
autonomous driving.

</details>


### [13] [MSRFormer: Road Network Representation Learning using Multi-scale Feature Fusion of Heterogeneous Spatial Interactions](https://arxiv.org/abs/2509.05685)
*Jian Yang,Jiahui Wu,Li Fang,Hongchao Fan,Bianying Zhang,Huijie Zhao,Guangyi Yang,Rui Xin,Xiong You*

Main category: cs.AI

TL;DR: MSRFormer是一种新颖的道路网络表示学习框架，通过整合多尺度空间交互作用、解决流异质性和长距离依赖性问题，有效捕捉城市道路网络的复杂特征。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在处理城市道路网络的异质性和层级性时面临挑战，图神经网络因其同质性假设和对单一结构尺度的关注而表现不佳。

Method: MSRFormer框架：1. 使用空间流卷积从大规模轨迹数据中提取小尺度特征。2. 识别尺度依赖的空间交互区域以捕捉道路网络空间结构和流异质性。3. 采用图Transformer有效捕获多尺度复杂空间依赖。4. 通过残差连接融合空间交互特征，并输入对比学习算法以获得最终表示。

Result: MSRFormer在两个真实世界数据集上的两个道路网络分析任务中优于基线方法。它在交通相关任务中受益于轨迹数据，并在复杂道路网络结构中表现出显著改进，与最具竞争力的基线方法相比，性能提升高达16%。

Conclusion: 这项研究提供了一个实用的框架，用于开发与任务无关的道路网络表示模型，并揭示了空间交互中尺度效应和流异质性之间相互作用的独特关联模式。

Abstract: Transforming road network data into vector representations using deep
learning has proven effective for road network analysis. However, urban road
networks' heterogeneous and hierarchical nature poses challenges for accurate
representation learning. Graph neural networks, which aggregate features from
neighboring nodes, often struggle due to their homogeneity assumption and focus
on a single structural scale. To address these issues, this paper presents
MSRFormer, a novel road network representation learning framework that
integrates multi-scale spatial interactions by addressing their flow
heterogeneity and long-distance dependencies. It uses spatial flow convolution
to extract small-scale features from large trajectory datasets, and identifies
scale-dependent spatial interaction regions to capture the spatial structure of
road networks and flow heterogeneity. By employing a graph transformer,
MSRFormer effectively captures complex spatial dependencies across multiple
scales. The spatial interaction features are fused using residual connections,
which are fed to a contrastive learning algorithm to derive the final road
network representation. Validation on two real-world datasets demonstrates that
MSRFormer outperforms baseline methods in two road network analysis tasks. The
performance gains of MSRFormer suggest the traffic-related task benefits more
from incorporating trajectory data, also resulting in greater improvements in
complex road network structures with up to 16% improvements compared to the
most competitive baseline method. This research provides a practical framework
for developing task-agnostic road network representation models and highlights
distinct association patterns of the interplay between scale effects and flow
heterogeneity of spatial interactions.

</details>


### [14] [Towards Meta-Cognitive Knowledge Editing for Multimodal LLMs](https://arxiv.org/abs/2509.05714)
*Zhaoyu Fan,Kaihang Pan,Mingze Zhou,Bosheng Qin,Juncheng Li,Shengyu Zhang,Wenqiao Zhang,Siliang Tang,Fei Wu,Yueting Zhuang*

Main category: cs.AI

TL;DR: 本文引入了CogEdit基准，用于评估多模态大型语言模型（MLLMs）的元认知知识编辑能力，并提出了MIND框架，通过构建元知识记忆、博弈论交互和标签细化来实现更鲁棒的元认知编辑。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑基准主要关注认知层面的修改，缺乏对更深层次元认知过程的关注，无法有效评估MLLMs在知识正确性、泛化能力和不确定信息处理方面的自我意识和反思能力。

Method: 本文提出了CogEdit基准，包含三个元认知编辑级别：反事实驱动编辑（评估知识正确性自我意识）、边界约束编辑（确保适当泛化无干扰）和噪声鲁棒编辑（促进不确定信息反思评估）。同时，提出了MIND（Meta-cognitive INtegrated Dynamic Knowledge Editing）框架，通过构建元知识记忆实现自我意识，利用博弈论交互监控知识激活，并结合标签细化实现噪声鲁棒更新。

Result: MIND框架在传统和元认知知识编辑基准上均显著优于现有认知编辑方法，表现出强大的性能。

Conclusion: 本文通过引入CogEdit基准和MIND框架，有效弥补了MLLMs元认知知识编辑评估的空白，并为提升MLLMs的元认知编辑能力提供了新的途径和方法。

Abstract: Knowledge editing enables multimodal large language models (MLLMs) to
efficiently update outdated or incorrect information. However, existing
benchmarks primarily emphasize cognitive-level modifications while lacking a
focus on deeper meta-cognitive processes. To bridge this gap, we introduce
CogEdit, a novel benchmark designed to evaluate MLLMs' meta-cognitive knowledge
editing abilities across three levels: (1) Counterfactual-Driven Editing,
assessing self-awareness of knowledge correctness changes; (2) Boundary
Constraint Editing, ensuring appropriate generalization without unintended
interference; and (3) Noise-Robust Editing, promoting reflective evaluation of
uncertain information. To advance meta-cognitive editing, we propose MIND
(Meta-cognitive INtegrated Dynamic Knowledge Editing), a framework that
constructs a meta-knowledge memory for self-awareness, employs game-theoretic
interactions to monitor knowledge activation, and incorporates label refinement
for noise-robust updates. Extensive experiments show that MIND significantly
outperforms existing cognitive editing approaches, achieving strong performance
on both traditional and meta-cognitive knowledge editing benchmarks.

</details>


### [15] [Hyperbolic Large Language Models](https://arxiv.org/abs/2509.05757)
*Sarang Patil,Zeyong Zhang,Yiran Huang,Tengfei Ma,Mengjia Xu*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在处理非欧几里得层次结构数据时面临挑战。双曲几何因其在建模树状结构方面的有效性而被引入。本文综述了利用双曲几何增强语义表示学习和多尺度推理的双曲LLMs（HypLLMs）的最新进展，并进行了分类。


<details>
  <summary>Details</summary>
Motivation: LLMs在多项任务中表现出色，但许多现实世界数据（如蛋白质网络、交通网络、语言句法树）呈现高度非欧几里得的潜在层次结构。LLMs在从这些数据中有效学习内在语义蕴含和层次关系方面仍是未充分探索的领域。双曲几何作为一种非欧几里得空间，因其擅长建模树状层次结构而备受关注。

Method: 本文提供了一个全面且有背景的阐述，重点介绍了利用双曲几何作为表示空间以增强语义表示学习和多尺度推理的LLMs的最新进展。具体来说，论文提出了双曲LLMs（HypLLMs）主要技术的分类法，分为四大类：(1) 通过exp/log映射的双曲LLMs；(2) 双曲微调模型；(3) 全双曲LLMs；以及(4) 双曲状态空间模型。此外，还探讨了潜在应用并概述了未来的研究方向。

Result: 本文成功地对利用双曲几何的LLMs进行了全面回顾和分类，将HypLLMs技术分为四种主要类型。这为理解当前双曲LLMs的设计和实现提供了一个清晰的框架，并展示了其在处理复杂、层次化数据方面增强语义表示学习和多尺度推理的潜力。

Conclusion: 双曲几何为提升LLMs处理非欧几里得层次结构数据的能力提供了一个有前景的方向，能够增强语义表示学习和多尺度推理。通过对HypLLMs技术的分类和未来方向的探讨，本文为该领域的研究和应用奠定了基础。

Abstract: Large language models (LLMs) have achieved remarkable success and
demonstrated superior performance across various tasks, including natural
language processing (NLP), weather forecasting, biological protein folding,
text generation, and solving mathematical problems. However, many real-world
data exhibit highly non-Euclidean latent hierarchical anatomy, such as protein
networks, transportation networks, financial networks, brain networks, and
linguistic structures or syntactic trees in natural languages. Effectively
learning intrinsic semantic entailment and hierarchical relationships from
these raw, unstructured input data using LLMs remains an underexplored area.
Due to its effectiveness in modeling tree-like hierarchical structures,
hyperbolic geometry -- a non-Euclidean space -- has rapidly gained popularity
as an expressive latent representation space for complex data modeling across
domains such as graphs, images, languages, and multi-modal data. Here, we
provide a comprehensive and contextual exposition of recent advancements in
LLMs that leverage hyperbolic geometry as a representation space to enhance
semantic representation learning and multi-scale reasoning. Specifically, the
paper presents a taxonomy of the principal techniques of Hyperbolic LLMs
(HypLLMs) in terms of four main categories: (1) hyperbolic LLMs through exp/log
maps; (2) hyperbolic fine-tuned models; (3) fully hyperbolic LLMs, and (4)
hyperbolic state-space models. We also explore crucial potential applications
and outline future research directions. A repository of key papers, models,
datasets, and code implementations is available at
https://github.com/sarangp2402/Hyperbolic-LLM-Models/tree/main.

</details>


### [16] [DRF: LLM-AGENT Dynamic Reputation Filtering Framework](https://arxiv.org/abs/2509.05764)
*Yuwei Lou,Hao Hu,Shaocong Ma,Zongfei Zhang,Liang Wang,Jidong Ge,Xianping Tao*

Main category: cs.AI

TL;DR: DRF是一个动态声誉过滤框架，旨在通过量化性能、评估可信度和优化选择来提升基于LLM的多智能体系统在复杂任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 基于大型语言模型（LLMs）的多智能体系统在复杂任务中面临智能体性能量化困难和缺乏可信度评估机制的挑战。

Method: 本文提出了DRF框架，它构建了一个交互式评分网络来量化智能体性能，设计了一个声誉评分机制来衡量智能体的诚实度和能力，并集成了一个基于上置信界（UCB）的策略来提高智能体选择效率。

Result: 实验表明，DRF显著提高了逻辑推理和代码生成任务中的任务完成质量和协作效率。

Conclusion: DRF为多智能体系统处理大规模任务提供了一种新方法，有效解决了智能体性能和可信度评估问题。

Abstract: With the evolution of generative AI, multi - agent systems leveraging large -
language models(LLMs) have emerged as a powerful tool for complex tasks.
However, these systems face challenges in quantifying agent performance and
lack mechanisms to assess agent credibility. To address these issues, we
introduce DRF, a dynamic reputation filtering framework. DRF constructs an
interactive rating network to quantify agent performance, designs a reputation
scoring mechanism to measure agent honesty and capability, and integrates an
Upper Confidence Bound - based strategy to enhance agent selection efficiency.
Experiments show that DRF significantly improves task completion quality and
collaboration efficiency in logical reasoning and code - generation tasks,
offering a new approach for multi - agent systems to handle large - scale
tasks.

</details>


### [17] [Decision-Focused Learning Enhanced by Automated Feature Engineering for Energy Storage Optimisation](https://arxiv.org/abs/2509.05772)
*Nasser Alkhulaifi,Ismail Gokay Dogan,Timothy R. Cargan,Alexander L. Bowler,Direnc Pekaslan,Nicholas J. Watson,Isaac Triguero*

Main category: cs.AI

TL;DR: 本文提出了一种结合自动化特征工程（AFE）和决策导向学习（DFL）的框架，用于优化电池储能系统（BESS）在不确定性下的运行，尤其适用于小规模真实世界数据集。结果表明，该框架显著降低了运营成本，并提升了DFL方法的性能。


<details>
  <summary>Details</summary>
Motivation: 能源管理中的不确定性（特别是BESS操作）导致难以制定最优策略。传统的“预测-然后-优化”（PTO）方法因预测误差累积而导致次优决策。新兴的决策导向学习（DFL）方法虽然解决了这一问题，但主要在合成数据集或小规模问题上测试，缺乏实际可行性证据。真实世界的BESS应用面临更大的数据变异性和稀缺性挑战。

Method: 本文提出了一种AFE-DFL框架，通过自动化特征工程（AFE）提取更丰富的特征表示，以改进DFL方法，尤其适用于小数据集。该框架预测电价和需求，同时优化BESS运行以最小化成本。研究在一个新的真实世界英国物业数据集上验证了其有效性，并比较了有/无AFE的DFL方法与PTO方法的性能。

Result: 结果显示，DFL方法平均而言比PTO方法产生了更低的运营成本。此外，添加AFE使DFL方法的性能比没有AFE的同类模型提高了22.9-56.5%。

Conclusion: 这些发现为DFL在真实世界环境中的实际可行性提供了经验证据，表明领域特定的AFE能够增强DFL，减少对BESS优化领域专业知识的依赖，从而带来经济效益，并对面临类似挑战的能源管理系统具有更广泛的意义。

Abstract: Decision-making under uncertainty in energy management is complicated by
unknown parameters hindering optimal strategies, particularly in Battery Energy
Storage System (BESS) operations. Predict-Then-Optimise (PTO) approaches treat
forecasting and optimisation as separate processes, allowing prediction errors
to cascade into suboptimal decisions as models minimise forecasting errors
rather than optimising downstream tasks. The emerging Decision-Focused Learning
(DFL) methods overcome this limitation by integrating prediction and
optimisation; however, they are relatively new and have been tested primarily
on synthetic datasets or small-scale problems, with limited evidence of their
practical viability. Real-world BESS applications present additional
challenges, including greater variability and data scarcity due to collection
constraints and operational limitations. Because of these challenges, this work
leverages Automated Feature Engineering (AFE) to extract richer representations
and improve the nascent approach of DFL. We propose an AFE-DFL framework
suitable for small datasets that forecasts electricity prices and demand while
optimising BESS operations to minimise costs. We validate its effectiveness on
a novel real-world UK property dataset. The evaluation compares DFL methods
against PTO, with and without AFE. The results show that, on average, DFL
yields lower operating costs than PTO and adding AFE further improves the
performance of DFL methods by 22.9-56.5% compared to the same models without
AFE. These findings provide empirical evidence for DFL's practical viability in
real-world settings, indicating that domain-specific AFE enhances DFL and
reduces reliance on domain expertise for BESS optimisation, yielding economic
benefits with broader implications for energy management systems facing similar
challenges.

</details>


### [18] [Chatbot To Help Patients Understand Their Health](https://arxiv.org/abs/2509.05818)
*Won Seok Jang,Hieu Tran,Manav Mistry,SaiKiran Gandluri,Yifan Zhang,Sharmin Sultana,Sunjae Kown,Yuan Zhang,Zonghai Yao,Hong Yu*

Main category: cs.AI

TL;DR: 本文提出了NoteAid-Chatbot，一个基于多智能体LLM和强化学习的对话式AI，通过“边学边聊”框架提升患者理解。该模型使用轻量级LLaMA 3.2 3B，通过合成数据进行SFT和基于PPO的RL训练，无需人工标注数据。评估显示其在患者教育中展现出清晰度、相关性和结构化对话等关键行为，并在图灵测试中超越非专业人类。


<details>
  <summary>Details</summary>
Motivation: 患者需要掌握必要的知识才能积极参与到他们的护理中。因此，开发能够有效促进患者理解的工具至关重要。

Method: NoteAid-Chatbot是一个基于多智能体大型语言模型（LLM）和强化学习（RL）的对话式AI。它构建在轻量级LLaMA 3.2 3B模型之上，训练分为两个阶段：首先，使用通过医疗对话策略合成生成的对话数据进行初始监督微调（SFT）；其次，通过强化学习进行训练，奖励信号来源于模拟医院出院场景中的患者理解评估，且整个过程无需人工标注数据。奖励建模采用基于PPO（近端策略优化）的方法。

Result: NoteAid-Chatbot展现出患者教育所需的关键涌现行为，如清晰度、相关性和结构化对话，尽管这些属性并未得到明确监督。结果表明，即使是简单的基于PPO的奖励建模也能成功训练轻量级、领域特定的聊天机器人，以处理多轮交互、融入多样化的教育策略并满足细致的沟通目标。图灵测试显示NoteAid-Chatbot的表现超越了非专业人类。

Conclusion: 所提出的框架展示了将低成本、基于PPO的强化学习应用于现实、开放式对话领域的可行性和前景，拓宽了基于RL的对齐方法的适用范围，超越了当前的医疗保健领域焦点。

Abstract: Patients must possess the knowledge necessary to actively participate in
their care. We present NoteAid-Chatbot, a conversational AI that promotes
patient understanding via a novel 'learning as conversation' framework, built
on a multi-agent large language model (LLM) and reinforcement learning (RL)
setup without human-labeled data. NoteAid-Chatbot was built on a lightweight
LLaMA 3.2 3B model trained in two stages: initial supervised fine-tuning on
conversational data synthetically generated using medical conversation
strategies, followed by RL with rewards derived from patient understanding
assessments in simulated hospital discharge scenarios. Our evaluation, which
includes comprehensive human-aligned assessments and case studies, demonstrates
that NoteAid-Chatbot exhibits key emergent behaviors critical for patient
education, such as clarity, relevance, and structured dialogue, even though it
received no explicit supervision for these attributes. Our results show that
even simple Proximal Policy Optimization (PPO)-based reward modeling can
successfully train lightweight, domain-specific chatbots to handle multi-turn
interactions, incorporate diverse educational strategies, and meet nuanced
communication objectives. Our Turing test demonstrates that NoteAid-Chatbot
surpasses non-expert human. Although our current focus is on healthcare, the
framework we present illustrates the feasibility and promise of applying
low-cost, PPO-based RL to realistic, open-ended conversational domains,
broadening the applicability of RL-based alignment methods.

</details>


### [19] [MapAgent: A Hierarchical Agent for Geospatial Reasoning with Dynamic Map Tool Integration](https://arxiv.org/abs/2509.05933)
*Md Hasebul Hasan,Mahir Labib Dihan,Mohammed Eunus Ali,Md Rizwan Parvez*

Main category: cs.AI

TL;DR: MapAgent是一个分层多智能体框架，通过解耦规划与执行、定制工具集和专用地图工具智能体，显著提升了大型语言模型在地理空间任务上的空间推理和工具使用能力。


<details>
  <summary>Details</summary>
Motivation: 现有的智能体AI框架在数学、编程等领域表现良好，但在需要空间推理、多跳规划和实时地图交互的地理空间任务中表现不足，且对类似但细微不同的地理空间API处理效率低下。

Method: MapAgent采用分层多智能体即插即用框架，将规划与执行解耦。高层规划器将复杂查询分解为子目标并路由到专业模块。对于工具密集型模块（如基于地图的服务），设计了专用的地图工具智能体并行协调相关API。较简单的模块（如解决方案生成）则无需额外智能体开销。这种分层设计减少了认知负荷，提高了工具选择准确性。

Result: MapAgent在MapEval-Textual、MapEval-API、MapEval-Visual和MapQA这四个多样化的地理空间基准测试中，相较于最先进的工具增强和智能体基线，展现出显著的性能提升。

Conclusion: MapAgent通过其独特的分层多智能体设计和高效的工具编排，成功解决了大型语言模型在地理空间推理和地图交互方面的挑战，实现了卓越的性能。

Abstract: Agentic AI has significantly extended the capabilities of large language
models (LLMs) by enabling complex reasoning and tool use. However, most
existing frameworks are tailored to domains such as mathematics, coding, or web
automation, and fall short on geospatial tasks that require spatial reasoning,
multi-hop planning, and real-time map interaction. To address these challenges,
we introduce MapAgent, a hierarchical multi-agent plug-and-play framework with
customized toolsets and agentic scaffolds for map-integrated geospatial
reasoning. Unlike existing flat agent-based approaches that treat tools
uniformly-often overwhelming the LLM when handling similar but subtly different
geospatial APIs-MapAgent decouples planning from execution. A high-level
planner decomposes complex queries into subgoals, which are routed to
specialized modules. For tool-heavy modules-such as map-based services-we then
design a dedicated map-tool agent that efficiently orchestrates related APIs
adaptively in parallel to effectively fetch geospatial data relevant for the
query, while simpler modules (e.g., solution generation or answer extraction)
operate without additional agent overhead. This hierarchical design reduces
cognitive load, improves tool selection accuracy, and enables precise
coordination across similar APIs. We evaluate MapAgent on four diverse
geospatial benchmarks-MapEval-Textual, MapEval-API, MapEval-Visual, and
MapQA-and demonstrate substantial gains over state-of-the-art tool-augmented
and agentic baselines. We open-source our framwork at
https://github.com/Hasebul/MapAgent.

</details>


### [20] [Rethinking Reasoning Quality in Large Language Models through Enhanced Chain-of-Thought via RL](https://arxiv.org/abs/2509.06024)
*Haoyang He,Zihua Rong,Kun Ji,Chenyang Li,Qing Huang,Chong Xia,Lan Yang,Honggang Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为动态推理效率奖励（DRER）的强化学习奖励框架，用于提升大型语言模型（LLMs）的推理能力，特别是其思维链（CoT）的质量，并引入了Logictree数据集进行评估。DRER通过细粒度奖励和动态长度优势，显著提高了模型在逻辑推理任务上的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有用于数学或编程基准的强化学习奖励函数通常只评估答案格式和正确性，未能提供关于思维链（CoT）是否真正改善答案的信号。此外，这种任务特定训练对逻辑深度控制有限，可能无法揭示模型真实的推理能力。

Method: 本文提出动态推理效率奖励（DRER）框架，该框架重塑了奖励和优势信号：(i) 推理质量奖励：为那些能显著提高正确答案可能性的推理链分配细粒度信用，直接激励有益的CoT轨迹。(ii) 动态长度优势：对长度偏离验证阈值的响应，其优势值会衰减，以稳定训练。为促进严格评估，还发布了Logictree数据集，一个动态构建的演绎推理数据集，可用作RL训练数据和综合基准。

Result: 实验证实了DRER的有效性：一个7B模型在Logictree上经过400步训练后，达到了GPT-o3-mini级别的性能，并且CoT增强答案的平均置信度提高了30%。该模型还在各种逻辑推理数据集和数学基准AIME24上表现出泛化能力。

Conclusion: 这些结果阐明了强化学习如何塑造CoT行为，并为增强大型语言模型的形式推理能力指明了一条实用路径。DRER框架通过提升思维链的质量和效率，有效提升了模型的推理能力和泛化性。

Abstract: Reinforcement learning (RL) has recently become the dominant paradigm for
strengthening the reasoning abilities of large language models (LLMs). Yet the
rule-based reward functions commonly used on mathematical or programming
benchmarks assess only answer format and correctness, providing no signal as to
whether the induced Chain-of-Thought (CoT) actually improves the answer.
Furthermore, such task-specific training offers limited control over logical
depth and therefore may fail to reveal a model's genuine reasoning capacity. We
propose Dynamic Reasoning Efficiency Reward (DRER) -- a plug-and-play RL reward
framework that reshapes both reward and advantage signals. (i) A Reasoning
Quality Reward assigns fine-grained credit to those reasoning chains that
demonstrably raise the likelihood of the correct answer, directly incentivising
the trajectories with beneficial CoT tokens. (ii) A Dynamic Length Advantage
decays the advantage of responses whose length deviates from a
validation-derived threshold, stabilising training. To facilitate rigorous
assessment, we also release Logictree, a dynamically constructed deductive
reasoning dataset that functions both as RL training data and as a
comprehensive benchmark. Experiments confirm the effectiveness of DRER: our 7B
model attains GPT-o3-mini level performance on Logictree with 400 trianing
steps, while the average confidence of CoT-augmented answers rises by 30%. The
model further exhibits generalisation across diverse logical-reasoning
datasets, and the mathematical benchmark AIME24. These results illuminate how
RL shapes CoT behaviour and chart a practical path toward enhancing
formal-reasoning skills in large language models. All code and data are
available in repository https://github.com/Henryhe09/DRER.

</details>


### [21] [Reverse-Engineered Reasoning for Open-Ended Generation](https://arxiv.org/abs/2509.06160)
*Haozhe Wang,Haoran Que,Qixin Xu,Minghao Liu,Wangchunshu Zhou,Jiazhan Feng,Wanjun Zhong,Wei Ye,Tong Yang,Wenhao Huang,Ge Zhang,Fangzhen Lin*

Main category: cs.AI

TL;DR: 本文提出了一种名为REER（逆向工程推理）的新范式，通过从已知优质解决方案逆向发现深层推理过程，解决了开放式创意生成中的深度推理难题。REER被用于构建DeepWriting-20K数据集，并在此基础上训练了DeepWriter-8B模型，其性能超越了现有开源基线，并与顶尖专有模型相媲美。


<details>
  <summary>Details</summary>
Motivation: 在开放式、创意生成任务中，深度推理的应用面临巨大挑战。现有的主流方法，如强化学习（RL）和指令蒸馏，存在明显缺陷：RL缺乏清晰的奖励信号和高质量的奖励模型，而指令蒸馏则成本高昂且受限于教师模型的能力。

Method: 本文引入了REER（逆向工程推理）范式，它根本性地改变了推理过程的构建方式。REER不通过试错或模仿“正向”构建推理过程，而是从已知优质解决方案“逆向”工作，计算性地发现可能产生这些解决方案的潜在、分步的深度推理过程。这是一种可扩展、无梯度的方​​法。利用REER，研究人员策划并开源了DeepWriting-20K，一个包含20,000条用于开放式任务的深度推理轨迹的大规模数据集。在此数据上训练了DeepWriter-8B模型。

Result: DeepWriter-8B模型在DeepWriting-20K数据集上训练后，不仅超越了强大的开源基线模型，而且实现了与领先的专有模型（如GPT-4o和Claude 3.5）相当，甚至有时更优的性能。同时，DeepWriting-20K数据集也被策划并开源。

Conclusion: REER范式提供了一种有效且可扩展的方法，用于在开放式创意生成领域实现深度推理。通过逆向工程发现推理轨迹，并在此基础上训练的模型，能够达到与当前最先进的专有模型竞争的水平，这为该领域带来了显著的进步。

Abstract: While the ``deep reasoning'' paradigm has spurred significant advances in
verifiable domains like mathematics, its application to open-ended, creative
generation remains a critical challenge. The two dominant methods for
instilling reasoning -- reinforcement learning (RL) and instruction
distillation -- falter in this area; RL struggles with the absence of clear
reward signals and high-quality reward models, while distillation is
prohibitively expensive and capped by the teacher model's capabilities. To
overcome these limitations, we introduce REverse-Engineered Reasoning (REER), a
new paradigm that fundamentally shifts the approach. Instead of building a
reasoning process ``forwards'' through trial-and-error or imitation, REER works
``backwards'' from known-good solutions to computationally discover the latent,
step-by-step deep reasoning process that could have produced them. Using this
scalable, gradient-free approach, we curate and open-source DeepWriting-20K, a
large-scale dataset of 20,000 deep reasoning trajectories for open-ended tasks.
Our model, DeepWriter-8B, trained on this data, not only surpasses strong
open-source baselines but also achieves performance competitive with, and at
times superior to, leading proprietary models like GPT-4o and Claude 3.5.

</details>


### [22] [From Long to Short: LLMs Excel at Trimming Own Reasoning Chains](https://arxiv.org/abs/2509.06174)
*Wei Han,Geng Zhan,Sicheng Yu,Chenyu Wang,Bryan Hooi*

Main category: cs.AI

TL;DR: 本文提出了一种名为EDIT的测试时缩放方法，旨在解决大型推理模型（LRMs）在处理简单问题时过度思考的问题，从而在保持正确性的前提下，生成更简洁、高效的推理路径。


<details>
  <summary>Details</summary>
Motivation: 尽管O1/R1风格的大型推理模型（LRMs）在复杂推理任务中取得了最先进的成果，但它们常常会“过度思考”，即过度复杂化简单问题，导致策略切换过多和推理路径冗长曲折，损害了可解释性。研究发现LRMs在正确性和简洁性等多个生成目标之间难以平衡。

Method: 本文提出了一种名为EDIT（高效动态推理修剪）的测试时缩放方法。EDIT通过约束引导的生成，同时跟踪不同约束下的长度和答案分布，从而在简洁性和正确性之间选择最佳平衡的响应，引导LRMs识别最短的正确推理路径。

Result: 在各种模型和数据集上的广泛实验表明，EDIT显著提高了推理效率，生成了紧凑但信息丰富的输出，从而改善了可读性和用户体验。

Conclusion: EDIT方法成功地缓解了LRMs的“过度思考”问题，通过在测试时动态引导模型生成更短、更高效的推理路径，实现了推理效率的显著提升，并在简洁性和正确性之间取得了最佳平衡。

Abstract: O1/R1 style large reasoning models (LRMs) signal a substantial leap forward
over conventional instruction-following LLMs. By applying test-time scaling to
generate extended reasoning paths, they establish many SOTAs across a wide
range of complex reasoning tasks. However, recent studies show that LRMs are
prone to suffer from overthinking -- the tendency to overcomplicate simple
problems, leading to excessive strategy switching and long, convoluted
reasoning traces that hinder their interpretability. To mitigate this issue, we
conduct a systematic investigation into the reasoning efficiency of a broad set
of LRMs and uncover a common dilemma: the difficulty in balancing multiple
generation objectives such as correctness and brevity. Based on this discovery,
we propose a test-time scaling method, EDIT (Efficient Dynamic Inference
Trimming), which efficiently guides LRMs to identify the shortest correct
reasoning paths at test time. EDIT employs constraint-guided generation while
jointly tracking length and answer distributions under varying constraints,
allowing it to select responses that strike an optimal balance between
conciseness and correctness. Extensive experiments across diverse models and
datasets show that EDIT substantially enhance the reasoning efficiency,
producing compact yet informative outputs that improve readability and user
experience.

</details>


### [23] [PillagerBench: Benchmarking LLM-Based Agents in Competitive Minecraft Team Environments](https://arxiv.org/abs/2509.06235)
*Olivier Schipper,Yudi Zhang,Yali Du,Mykola Pechenizkiy,Meng Fang*

Main category: cs.AI

TL;DR: 该研究引入了PillagerBench框架和TactiCrafter多智能体系统，用于在Minecraft中评估和提升LLM代理在实时竞争性团队对战环境中的表现，TactiCrafter在自适应学习和超越基线方面表现出色。


<details>
  <summary>Details</summary>
Motivation: LLM代理在合作和战略推理任务中展现出潜力，但在竞争性多智能体环境中的有效性尚未得到充分探索。

Method: 1. 引入PillagerBench框架：一个用于在Minecraft中评估多智能体系统在实时竞争性团队对战场景下的平台，提供可扩展API、多轮测试和基于规则的内置对手。2. 提出TactiCrafter：一个基于LLM的多智能体系统，通过人类可读的战术促进团队协作，学习因果依赖，并适应对手策略。3. 评估：通过与基线方法对比和自博弈来展示TactiCrafter的性能和自适应学习能力。

Result: TactiCrafter在评估中超越了基线方法，并通过自博弈展示了自适应学习能力。研究还分析了其在多个游戏回合中的学习过程和战略演变。

Conclusion: TactiCrafter在竞争性多智能体环境中表现出强大的性能和自适应学习能力。PillagerBench的开源将促进竞争性多智能体AI领域的进一步研究和发展。

Abstract: LLM-based agents have shown promise in various cooperative and strategic
reasoning tasks, but their effectiveness in competitive multi-agent
environments remains underexplored. To address this gap, we introduce
PillagerBench, a novel framework for evaluating multi-agent systems in
real-time competitive team-vs-team scenarios in Minecraft. It provides an
extensible API, multi-round testing, and rule-based built-in opponents for
fair, reproducible comparisons. We also propose TactiCrafter, an LLM-based
multi-agent system that facilitates teamwork through human-readable tactics,
learns causal dependencies, and adapts to opponent strategies. Our evaluation
demonstrates that TactiCrafter outperforms baseline approaches and showcases
adaptive learning through self-play. Additionally, we analyze its learning
process and strategic evolution over multiple game episodes. To encourage
further research, we have open-sourced PillagerBench, fostering advancements in
multi-agent AI for competitive environments.

</details>


### [24] [Proof2Silicon: Prompt Repair for Verified Code and Hardware Generation via Reinforcement Learning](https://arxiv.org/abs/2509.06239)
*Manvi Jha,Jiaxin Wan,Deming Chen*

Main category: cs.AI

TL;DR: Proof2Silicon是一个端到端框架，它利用强化学习优化LLM提示，从自然语言规范生成形式化验证的硬件，解决了LLM代码验证失败的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在代码生成方面表现出色，但生成的代码经常无法通过形式化验证，这在硬件和安全关键领域是一个基本且重要的限制。

Method: 本文提出了Proof2Silicon框架，该框架包含：1) PREFACE（一个基于强化学习的代理），通过迭代修复提示来优化LLM生成，确保Dafny代码的正确性；2) 自动将验证过的Dafny程序通过Dafny的Python后端和PyLog翻译成可综合的高级C语言；3) 使用Vivado HLS工具将C代码生成为RTL实现。

Result: PREFACE的RL引导提示优化在不同LLM上将Dafny验证成功率提高了高达21%。Proof2Silicon实现了高达72%的端到端硬件综合成功率，通过Vivado HLS综合流程生成了RTL设计。

Conclusion: Proof2Silicon展示了一个强大、可扩展且自动化的管道，实现了LLM驱动的形式化验证硬件综合，成功地将自然语言规范转化为硅实现。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in
automated code generation but frequently produce code that fails formal
verification, an essential requirement for hardware and safety-critical
domains. To overcome this fundamental limitation, we previously proposed
PREFACE, a model-agnostic framework based on reinforcement learning (RL) that
iteratively repairs the prompts provided to frozen LLMs, systematically
steering them toward generating formally verifiable Dafny code without costly
fine-tuning. This work presents Proof2Silicon, a novel end-to-end synthesis
framework that embeds the previously proposed PREFACE flow to enable the
generation of correctness-by-construction hardware directly from natural
language specifications. Proof2Silicon operates by: (1) leveraging PREFACE's
verifier-driven RL agent to optimize prompt generation iteratively, ensuring
Dafny code correctness; (2) automatically translating verified Dafny programs
into synthesizable high-level C using Dafny's Python backend and PyLog; and (3)
employing Vivado HLS to produce RTL implementations. Evaluated rigorously on a
challenging 100-task benchmark, PREFACE's RL-guided prompt optimization
consistently improved Dafny verification success rates across diverse LLMs by
up to 21%. Crucially, Proof2Silicon achieved an end-to-end hardware synthesis
success rate of up to 72%, generating RTL designs through Vivado HLS synthesis
flows. These results demonstrate a robust, scalable, and automated pipeline for
LLM-driven, formally verified hardware synthesis, bridging natural-language
specification and silicon realization.

</details>


### [25] [REMI: A Novel Causal Schema Memory Architecture for Personalized Lifestyle Recommendation Agents](https://arxiv.org/abs/2509.06269)
*Vishal Raman,Vijai Aravindh R,Abhijith Ragav*

Main category: cs.AI

TL;DR: 本文提出REMI，一种因果图式记忆（CSM）架构，用于多模态生活方式智能体。它整合个人因果知识图、因果推理引擎和基于图式的规划模块，旨在提供可解释、个性化的生活方式推荐。


<details>
  <summary>Details</summary>
Motivation: 个性化AI助手难以整合复杂的个人数据和因果知识，导致提供的建议通用且缺乏解释力。

Method: REMI架构使用用户的个人生活事件和习惯的因果图，进行目标导向的因果遍历，并结合外部知识和假设推理。它检索适应性强的计划图式以生成定制行动计划。大型语言模型（LLM）协调这些组件，生成带有透明因果解释的答案。引入了新的评估指标，如个性化显著性得分和因果推理准确性。

Result: 结果表明，与基线LLM智能体相比，基于CSM的智能体能提供更具情境感知和用户对齐的推荐。

Conclusion: 这项工作展示了一种在个性化智能体中结合记忆增强和因果推理的新颖方法，推动了透明和可信赖的AI生活方式助手的发展。

Abstract: Personalized AI assistants often struggle to incorporate complex personal
data and causal knowledge, leading to generic advice that lacks explanatory
power. We propose REMI, a Causal Schema Memory architecture for a multimodal
lifestyle agent that integrates a personal causal knowledge graph, a causal
reasoning engine, and a schema based planning module. The idea is to deliver
explainable, personalized recommendations in domains like fashion, personal
wellness, and lifestyle planning. Our architecture uses a personal causal graph
of the user's life events and habits, performs goal directed causal traversals
enriched with external knowledge and hypothetical reasoning, and retrieves
adaptable plan schemas to generate tailored action plans. A Large Language
Model orchestrates these components, producing answers with transparent causal
explanations. We outline the CSM system design and introduce new evaluation
metrics for personalization and explainability, including Personalization
Salience Score and Causal Reasoning Accuracy, to rigorously assess its
performance. Results indicate that CSM based agents can provide more context
aware, user aligned recommendations compared to baseline LLM agents. This work
demonstrates a novel approach to memory augmented, causal reasoning in
personalized agents, advancing the development of transparent and trustworthy
AI lifestyle assistants.

</details>


### [26] [TableMind: An Autonomous Programmatic Agent for Tool-Augmented Table Reasoning](https://arxiv.org/abs/2509.06278)
*Chuang Jiang,Mingyue Cheng,Xiaoyu Tao,Qingyang Mao,Jie Ouyang,Qi Liu*

Main category: cs.AI

TL;DR: TableMind是一个由LLM驱动的表格推理代理，它通过多轮工具调用、安全沙盒中的代码执行以及规划和自我反思能力，解决了传统方法在复杂数值计算和自适应性方面的不足，并在基准测试中取得了卓越的推理准确性和计算精度。


<details>
  <summary>Details</summary>
Motivation: 表格推理对利用结构化数据至关重要，但纯文本的LLM在复杂数值计算和精细操作上表现不佳。现有的工具集成推理系统虽然提高了计算准确性，但往往依赖僵化的模式和监督模仿，缺乏真正的自主适应性。

Method: 本文提出了TableMind，一个LLM驱动的表格推理代理，它能够(i)自主执行多轮工具调用，(ii)在安全沙盒环境中编写和执行数据分析代码以进行精确数值推理，以及(iii)展现规划和自我反思等高级能力以调整策略。实现这些能力的方法是两阶段微调范式：首先对高质量推理轨迹进行监督微调（SFT）以建立有效的工具使用模式，然后进行强化微调（RFT）以优化多目标策略。特别是，提出了一种“排名感知策略优化”（RAPO）方法，该方法在高质量轨迹的输出概率低于低质量轨迹时增加其更新权重，从而更一致地引导模型获得更好、更准确的答案。

Result: 在多个主流基准测试中，TableMind与具有竞争力的基线相比，实现了卓越的性能，在推理准确性和计算精度方面均获得了显著提升。

Conclusion: TableMind通过结合LLM的推理能力、自主工具调用、安全代码执行以及创新的两阶段微调和RAPO方法，成功克服了表格推理中的数值计算和自适应性挑战，从而在复杂表格数据分析中取得了高水平的准确性和精确性。

Abstract: Table reasoning is crucial for leveraging structured data in domains such as
finance, healthcare, and scientific research. While large language models
(LLMs) show promise in multi-step reasoning, purely text-based methods often
struggle with the complex numerical computations and fine-grained operations
inherently required in this task. Tool-integrated reasoning improves
computational accuracy via explicit code execution, yet existing systems
frequently rely on rigid patterns, supervised imitation, and lack true
autonomous adaptability. In this paper, we present TableMind, an LLM-driven
table reasoning agent that (i) autonomously performs multi-turn tool
invocation, (ii) writes and executes data-analyzing code in a secure sandbox
environment for data analysis and precise numerical reasoning, and (iii)
exhibits high-level capabilities such as planning and self-reflection to adapt
strategies. To realize these capabilities, we adopt a two-stage fine-tuning
paradigm built on top of a powerful pre-trained language model: supervised
fine-tuning on high-quality reasoning trajectories to establish effective tool
usage patterns, followed by reinforcement fine-tuning to optimize
multi-objective strategies. In particular, we propose Rank-Aware Policy
Optimization (RAPO), which increases the update weight of high-quality
trajectories when their output probabilities are lower than those of
low-quality ones, thereby guiding the model more consistently toward better and
more accurate answers. Extensive experiments on several mainstream benchmarks
demonstrate that TableMind achieves superior performance compared to
competitive baselines, yielding substantial gains in both reasoning accuracy
and computational precision.

</details>


### [27] [SFR-DeepResearch: Towards Effective Reinforcement Learning for Autonomously Reasoning Single Agents](https://arxiv.org/abs/2509.06283)
*Xuan-Phi Nguyen,Shrey Pandit,Revanth Gangi Reddy,Austin Xu,Silvio Savarese,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: 本文提出了一种基于持续强化学习的自主单智能体模型，用于深度研究（DR），该模型利用完全合成数据训练，旨在增强智能体技能并保持推理能力，并在相关基准测试中取得了显著表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的复杂推理和工具使用能力对于许多重要应用至关重要，特别是需要大量搜索和推理的深度研究（DR）。现有工作多关注基础或指令微调的LLM，但仍需进一步提升智能体的自主决策能力和工具使用技能，同时保留其核心推理能力。

Method: 本研究专注于开发用于DR的原生自主单智能体模型，该模型集成了最小化的网络爬取和Python工具。与多智能体系统不同，该单智能体能根据上下文动态决定下一步行动，无需手动指令。研究采用了一种简单的、基于完全合成数据的持续强化学习（RL）配方，并将其应用于各种推理优化的开源LLM，以在保持推理能力的同时增强智能体技能。

Result: 研究的最佳变体SFR-DR-20B在“人类的最后考试”（Humanity's Last Exam）基准测试中取得了高达28.7%的成绩。此外，研究还进行了关键分析实验，为所提出的方法提供了更深入的见解。

Conclusion: 通过对推理优化模型进行持续强化学习，并利用合成数据，可以有效增强大型语言模型在深度研究任务中的自主单智能体能力，提升其代理技能和工具使用能力，同时成功保持了其推理能力。这一方法为开发更强大的代理式AI提供了新的途径。

Abstract: Equipping large language models (LLMs) with complex, interleaved reasoning
and tool-use capabilities has become a key focus in agentic AI research,
especially with recent advances in reasoning-oriented (``thinking'') models.
Such capabilities are key to unlocking a number of important applications. One
such application is Deep Research (DR), which requires extensive search and
reasoning over many sources. Our work in this paper focuses on the development
of native Autonomous Single-Agent models for DR featuring minimal web crawling
and Python tool integration. Unlike multi-agent systems, where agents take up
pre-defined roles and are told what to do at each step in a static workflow, an
autonomous single-agent determines its next action dynamically based on
context, without manual directive. While prior work has proposed training
recipes for base or instruction-tuned LLMs, we focus on continual reinforcement
learning (RL) of reasoning-optimized models to further enhance agentic skills
while preserving reasoning ability. Towards this end, we propose a simple RL
recipe with entirely synthetic data, which we apply to various open-source
LLMs. Our best variant SFR-DR-20B achieves up to 28.7% on Humanity's Last Exam
benchmark. In addition, we conduct key analysis experiments to provide more
insights into our methodologies.

</details>


### [28] [From Implicit Exploration to Structured Reasoning: Leveraging Guideline and Refinement for LLMs](https://arxiv.org/abs/2509.06284)
*Jiaxiang Chen,Zhuo Wang,Mingxi Zou,Zhucong Li,Zhijian Zhou,Song Wang,Zenglin Xu*

Main category: cs.AI

TL;DR: 本文提出了一种名为“结构化推理”的框架，通过从成功和失败经验中提取指导方针和进行逐步修正，显著提升了大型语言模型在各种推理任务上的稳定性、泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在推理时常依赖隐式探索，导致推理路径不稳定、缺乏错误纠正能力以及从过往经验中学习不足。

Method: 该方法通过以下步骤实现：1. 从成功的推理轨迹中提取结构化推理模式。2. 从失败中提取反思信号。3. 在推理过程中，模型遵循这些逐步的指导方针。4. 每一步之后应用修正机制，以纠正错误并稳定推理过程。

Result: 实验结果表明，该方法在BBH以及GSM8K、MATH-500、MBPP、HumanEval等四个额外基准测试中，持续优于强基线模型。结构化推理与逐步执行和修正相结合，提高了稳定性和泛化能力，指导方针在不同领域间具有良好的迁移性，并灵活支持跨模型协作，其有效性和可扩展性媲美甚至超越了监督微调。

Conclusion: 通过指导方针和逐步修正实现的结构化推理，能够有效解决LLM推理的稳定性问题，提升其在多领域任务上的表现，并具有出色的泛化、迁移和可扩展性。

Abstract: Large language models (LLMs) have advanced general-purpose reasoning, showing
strong performance across diverse tasks. However, existing methods often rely
on implicit exploration, where the model follows stochastic and unguided
reasoning paths-like walking without a map. This leads to unstable reasoning
paths, lack of error correction, and limited learning from past experience. To
address these issues, we propose a framework that shifts from implicit
exploration to structured reasoning through guideline and refinement. First, we
extract structured reasoning patterns from successful trajectories and
reflective signals from failures. During inference, the model follows these
guidelines step-by-step, with refinement applied after each step to correct
errors and stabilize the reasoning process. Experiments on BBH and four
additional benchmarks (GSM8K, MATH-500, MBPP, HumanEval) show that our method
consistently outperforms strong baselines across diverse reasoning tasks.
Structured reasoning with stepwise execution and refinement improves stability
and generalization, while guidelines transfer well across domains and flexibly
support cross-model collaboration, matching or surpassing supervised
fine-tuning in effectiveness and scalability.

</details>


### [29] [Can AI Make Energy Retrofit Decisions? An Evaluation of Large Language Models](https://arxiv.org/abs/2509.06307)
*Lei Shu,Dong Zhao*

Main category: cs.AI

TL;DR: 本研究评估了大型语言模型（LLM）在住宅能源改造决策中的应用潜力，发现它们能生成有效建议，但在准确性、一致性和上下文处理方面仍需改进以实现可靠实践。


<details>
  <summary>Details</summary>
Motivation: 传统建筑能源改造决策方法存在泛化能力有限和可解释性低的问题，阻碍了其在多样化住宅环境中的应用。随着智能互联社区的发展，生成式AI（特别是LLM）有望通过处理上下文信息并生成易读的建议来克服这些局限性。

Method: 研究评估了七个大型语言模型（ChatGPT、DeepSeek、Gemini、Grok、Llama、Claude）在住宅改造决策中的表现。设定了两个目标：最大化二氧化碳减排（技术目标）和最小化投资回收期（社会技术目标）。使用包含美国49个州400个家庭的数据集，从准确性、一致性、敏感性和推理四个维度评估模型性能。

Result: LLM在许多情况下能生成有效建议，未经微调即可达到54.5%的Top 1匹配率和92.8%的Top 5匹配率。技术目标下的表现优于社会技术目标。模型间的一致性较低，表现较好的模型往往与其他模型存在分歧。LLM对地理位置和建筑几何形状敏感，但对技术和居住者行为的敏感度较低。大多数模型展现出简化、工程风格的推理，但缺乏更深层次的上下文感知。

Conclusion: 大型语言模型在能源改造决策中具有广阔前景，可以作为有用的辅助工具。然而，为了实现可靠的实际应用，仍需在准确性、一致性和上下文处理方面进行显著改进。

Abstract: Conventional approaches to building energy retrofit decision making suffer
from limited generalizability and low interpretability, hindering adoption in
diverse residential contexts. With the growth of Smart and Connected
Communities, generative AI, especially large language models (LLMs), may help
by processing contextual information and producing practitioner readable
recommendations. We evaluate seven LLMs (ChatGPT, DeepSeek, Gemini, Grok,
Llama, and Claude) on residential retrofit decisions under two objectives:
maximizing CO2 reduction (technical) and minimizing payback period
(sociotechnical). Performance is assessed on four dimensions: accuracy,
consistency, sensitivity, and reasoning, using a dataset of 400 homes across 49
US states. LLMs generate effective recommendations in many cases, reaching up
to 54.5 percent top 1 match and 92.8 percent within top 5 without fine tuning.
Performance is stronger for the technical objective, while sociotechnical
decisions are limited by economic trade offs and local context. Agreement
across models is low, and higher performing models tend to diverge from others.
LLMs are sensitive to location and building geometry but less sensitive to
technology and occupant behavior. Most models show step by step, engineering
style reasoning, but it is often simplified and lacks deeper contextual
awareness. Overall, LLMs are promising assistants for energy retrofit decision
making, but improvements in accuracy, consistency, and context handling are
needed for reliable practice.

</details>


### [30] [Large Language Models as Virtual Survey Respondents: Evaluating Sociodemographic Response Generation](https://arxiv.org/abs/2509.06337)
*Jianpeng Zhao,Chenyu Yuan,Weiming Luo,Haoling Xie,Guangwei Zhang,Steven Jige Quan,Zixuan Yuan,Pengyang Wang,Denghui Zhang*

Main category: cs.AI

TL;DR: 本文提出并评估了一种使用大型语言模型（LLMs）模拟虚拟调查受访者的新范式，旨在克服传统调查方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的问卷调查方法成本高昂、耗时且规模受限，因此需要一种更具可扩展性和成本效益的替代方案来支持社会科学研究和公共政策制定。

Method: 研究引入了两种新颖的模拟设置：部分属性模拟（PAS）和完整属性模拟（FAS），以评估LLMs生成准确且符合人口统计学特征响应的能力。同时，构建了一个名为LLM-S^3的综合基准套件，包含跨四个社会学领域的11个真实世界公共数据集。研究评估了GPT-3.5/4 Turbo和LLaMA 3.0/3.1-8B等主流LLMs，并分析了上下文和提示设计对模拟保真度的影响。

Result: 评估结果揭示了预测性能的一致趋势，指出了LLMs在模拟中的失效模式，并证明了上下文和提示设计如何显著影响模拟的准确性与真实性。

Conclusion: 这项工作为基于LLM的调查模拟奠定了严格的基础，为社会学研究和政策评估提供了可扩展且经济高效的工具。

Abstract: Questionnaire-based surveys are foundational to social science research and
public policymaking, yet traditional survey methods remain costly,
time-consuming, and often limited in scale. This paper explores a new paradigm:
simulating virtual survey respondents using Large Language Models (LLMs). We
introduce two novel simulation settings, namely Partial Attribute Simulation
(PAS) and Full Attribute Simulation (FAS), to systematically evaluate the
ability of LLMs to generate accurate and demographically coherent responses. In
PAS, the model predicts missing attributes based on partial respondent
profiles, whereas FAS involves generating complete synthetic datasets under
both zero-context and context-enhanced conditions. We curate a comprehensive
benchmark suite, LLM-S^3 (Large Language Model-based Sociodemographic Survey
Simulation), that spans 11 real-world public datasets across four sociological
domains. Our evaluation of multiple mainstream LLMs (GPT-3.5/4 Turbo, LLaMA
3.0/3.1-8B) reveals consistent trends in prediction performance, highlights
failure modes, and demonstrates how context and prompt design impact simulation
fidelity. This work establishes a rigorous foundation for LLM-driven survey
simulations, offering scalable and cost-effective tools for sociological
research and policy evaluation. Our code and dataset are available at:
https://github.com/dart-lab-research/LLM-S-Cube-Benchmark

</details>


### [31] [Evaluating Multi-Turn Bargain Skills in LLM-Based Seller Agent](https://arxiv.org/abs/2509.06341)
*Issue Yishu Wang,Kakam Chong,Xiaofeng Wang,Xu Yan,DeXin Kong,Chen Ju,Ming Chen,Shuai Xiao,Shuguang Han,jufeng chen*

Main category: cs.AI

TL;DR: 本文提出一个多轮评估框架，用于衡量电商对话中卖家代理（LLMs）的议价能力，特别是其提取和追踪买家意图的能力，并提供大规模基准测试。


<details>
  <summary>Details</summary>
Motivation: 在线二手市场中，多轮议价至关重要。大型语言模型作为卖家代理，需要准确追踪和解释买家累积意图以提高议价效率。现有评估可能仅关注结果，缺乏对意图追踪的细致考量。

Method: 引入一个多轮评估框架来衡量卖家代理的议价能力，重点测试其提取和追踪买家意图的能力。具体贡献包括：1) 一个涵盖广泛类别和产品的电商议价基准；2) 一个基于心智理论（ToM）的轮级评估框架，包含标注的买家意图，超越了仅基于结果的指标；3) 一个从海量对话数据中提取可靠意图的自动化流程。

Result: 本文的主要成果是提供了一个新的多轮评估框架及其相关资源，包括：一个大规模电商议价基准（622个类别，9,892个产品，3,014个任务），一个基于心智理论的带标注买家意图的轮级评估框架，以及一个自动化的意图提取管道。

Conclusion: 本文为评估电商对话中LLM卖家代理的议价能力，特别是其追踪和解释买家意图的能力，提供了一个全面的多轮评估框架和大规模资源，从而超越了传统的结果导向指标。

Abstract: In online second-hand marketplaces, multi-turn bargaining is a crucial part
of seller-buyer interactions. Large Language Models (LLMs) can act as seller
agents, negotiating with buyers on behalf of sellers under given business
constraints. A critical ability for such agents is to track and accurately
interpret cumulative buyer intents across long negotiations, which directly
impacts bargaining effectiveness. We introduce a multi-turn evaluation
framework for measuring the bargaining ability of seller agents in e-commerce
dialogues. The framework tests whether an agent can extract and track buyer
intents. Our contributions are: (1) a large-scale e-commerce bargaining
benchmark spanning 622 categories, 9,892 products, and 3,014 tasks; (2) a
turn-level evaluation framework grounded in Theory of Mind (ToM) with annotated
buyer intents, moving beyond outcome-only metrics; and (3) an automated
pipeline that extracts reliable intent from massive dialogue data.

</details>


### [32] [A data-driven discretized CS:GO simulation environment to facilitate strategic multi-agent planning research](https://arxiv.org/abs/2509.06355)
*Yunzhe Wang,Volkan Ustun,Chris McGroarty*

Main category: cs.AI

TL;DR: DECOY是一个多智能体模拟器，它在3D地形中抽象出战略性的、长周期规划，通过离散化模拟和神经网络模型，仅用移动决策就能高保真地模拟CS:GO游戏，并能重现人类游戏数据。


<details>
  <summary>Details</summary>
Motivation: 现代复杂多智能体交互的模拟环境需要在高保真细节和计算效率之间取得平衡。

Method: DECOY将3D地形中的战略性、长周期规划抽象为高层离散化模拟，同时保留低层环境保真度。它使用一个航路点系统来简化和离散化连续状态和动作，并结合基于真实CS:GO比赛数据训练的神经预测和生成模型来重构事件结果，仅将移动决策作为战术定位，而不显式建模瞄准和射击等低层机制。

Result: 通过广泛评估，DECOY中根据人类数据生成的重放与原始游戏中观察到的重放高度匹配。

Conclusion: DECOY提供了一个有价值的公共模拟环境，可用于推动战略多智能体规划和行为生成方面的研究。

Abstract: Modern simulation environments for complex multi-agent interactions must
balance high-fidelity detail with computational efficiency. We present DECOY, a
novel multi-agent simulator that abstracts strategic, long-horizon planning in
3D terrains into high-level discretized simulation while preserving low-level
environmental fidelity. Using Counter-Strike: Global Offensive (CS:GO) as a
testbed, our framework accurately simulates gameplay using only movement
decisions as tactical positioning -- without explicitly modeling low-level
mechanics such as aiming and shooting. Central to our approach is a waypoint
system that simplifies and discretizes continuous states and actions, paired
with neural predictive and generative models trained on real CS:GO tournament
data to reconstruct event outcomes. Extensive evaluations show that replays
generated from human data in DECOY closely match those observed in the original
game. Our publicly available simulation environment provides a valuable tool
for advancing research in strategic multi-agent planning and behavior
generation.

</details>


### [33] [Teaching AI Stepwise Diagnostic Reasoning with Report-Guided Chain-of-Thought Learning](https://arxiv.org/abs/2509.06409)
*Yihong Luo,Wenwu He,Zhuo-Xu Cui,Dong Liang*

Main category: cs.AI

TL;DR: DiagCoT是一个多阶段框架，通过对通用视觉-语言模型进行监督微调，模拟放射科医生的逐步诊断推理，显著提升了放射学AI系统的诊断能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 开发能够模拟放射科医生逐步诊断推理的、具有诊断能力和可解释性的AI系统，并解决如何将非结构化的临床叙述转化为结构化监督的挑战。

Method: DiagCoT是一个多阶段框架，对通用视觉-语言模型（VLMs）进行监督微调。它结合了：1) 对比式图像-报告微调以实现领域对齐；2) 思维链监督以捕捉推理逻辑；3) 使用临床奖励信号的强化微调以增强事实准确性和流畅性。

Result: 在MIMIC-CXR基准测试中，DiagCoT将零样本疾病分类AUC从0.52提高到0.76（绝对增益0.24），病理定位mIoU从0.08提高到0.31（绝对增益0.23），报告生成BLEU从0.11提高到0.33（绝对增益0.22）。它在长尾疾病和外部数据集上优于LLaVA-Med和CXR-LLAVA等现有最先进模型。

Conclusion: 通过将非结构化的临床叙述转化为结构化监督，DiagCoT为开发可解释且具有诊断能力的放射学AI系统提供了一种可扩展的方法。

Abstract: This study presents DiagCoT, a multi-stage framework that applies supervised
fine-tuning to general-purpose vision-language models (VLMs) to emulate
radiologists' stepwise diagnostic reasoning using only free-text reports.
DiagCoT combines contrastive image-report tuning for domain alignment,
chain-of-thought supervision to capture inferential logic, and reinforcement
tuning with clinical reward signals to enhance factual accuracy and fluency. On
the MIMIC-CXR benchmark, DiagCoT improved zero-shot disease classification AUC
from 0.52 to 0.76 (absolute gain of 0.24), pathology grounding mIoU from 0.08
to 0.31 (absolute gain of 0.23), and report generation BLEU from 0.11 to 0.33
(absolute gain of 0.22). It outperformed state-of-the-art models including
LLaVA-Med and CXR-LLAVA on long-tailed diseases and external datasets. By
converting unstructured clinical narratives into structured supervision,
DiagCoT offers a scalable approach for developing interpretable and
diagnostically competent AI systems for radiology.

</details>


### [34] [Tree of Agents: Improving Long-Context Capabilities of Large Language Models through Multi-Perspective Reasoning](https://arxiv.org/abs/2509.06436)
*Song Yu,Xiaofei Xu,Ke Deng,Li Li,Lin Tian*

Main category: cs.AI

TL;DR: 该研究提出了Tree of Agents (TOA)，一个多智能体推理框架，通过将长文本分块并由独立智能体处理，然后进行树状结构的信息交换和协作推理，有效解决了大型语言模型（LLMs）在长上下文任务中遇到的“中间遗失”问题和注意力分散问题，并在效率和性能上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理长上下文任务时面临挑战，尤其是“中间遗失”问题，即输入中间的信息容易被忽视。现有方法要么可能丢弃关键信息（减少输入），要么导致注意力分散（扩展上下文窗口）。

Method: 本文提出了Tree of Agents (TOA) 框架：1) 将输入分割成块，由独立的智能体处理；2) 每个智能体生成局部认知；3) 智能体沿树状路径动态交换信息进行协作推理；4) 智能体探索不同的推理顺序以实现多角度理解，从而减轻位置偏差和减少幻觉；5) 整合了前缀哈希缓存和自适应剪枝策略以提高处理效率。

Result: 实验表明，TOA有效缓解了位置偏差并减少了幻觉。它以相当的API开销实现了显著的性能提升。基于紧凑的LLaMA3.1-8B模型，TOA显著优于多个基线模型，并在各种长上下文任务上展现出与最新、规模更大的商业模型（如Gemini1.5-pro）相当的性能。

Conclusion: TOA是一个高效且有效的多智能体推理框架，能够解决LLMs在长上下文任务中的固有挑战，通过协作推理和效率优化，使得小型模型也能在复杂长文本任务中达到甚至超越大型商业模型的表现。

Abstract: Large language models (LLMs) face persistent challenges when handling
long-context tasks, most notably the lost in the middle issue, where
information located in the middle of a long input tends to be underutilized.
Some existing methods that reduce input have the risk of discarding key
information, while others that extend context windows often lead to attention
dispersion. To address these limitations, we propose Tree of Agents (TOA), a
multi-agent reasoning framework that segments the input into chunks processed
by independent agents. Each agent generates its local cognition, then agents
dynamically exchange information for collaborative reasoning along
tree-structured paths. TOA enables agents to probe different reasoning orders
for multi-perspective understanding, effectively mitigating position bias and
reducing hallucinations. To improve processing efficiency, we incorporate
prefix-hash caching and adaptive pruning strategies, achieving significant
performance improvements with comparable API overhead. Experiments show that
TOA, powered by compact LLaMA3.1-8B, significantly outperforms multiple
baselines and demonstrates comparable performance to the latest and much larger
commercial models, such as Gemini1.5-pro, on various long-context tasks. Code
is available at https://github.com/Aireduce952/Tree-of-Agents.

</details>


### [35] [HyFedRAG: A Federated Retrieval-Augmented Generation Framework for Heterogeneous and Privacy-Sensitive Data](https://arxiv.org/abs/2509.06444)
*Cheng Qian,Hainan Zhang,Yongxin Tong,Hong-Wei Zheng,Zhiming Zheng*

Main category: cs.AI

TL;DR: HyFedRAG是一个统一高效的联邦RAG框架，专为处理分布式医疗环境中混合、隐私敏感的异构数据而设计，通过边缘-云协作机制实现数据隐私保护和高效检索。


<details>
  <summary>Details</summary>
Motivation: 集中式RAG管道难以处理异构和隐私敏感数据，特别是在医疗保健领域，患者数据分布于SQL、知识图谱和临床笔记中。由于隐私限制和传统云RAG系统在处理多样格式和边缘设备方面的局限性，临床医生难以检索罕见疾病病例。

Method: HyFedRAG采用基于Flower的边缘-云协作RAG框架，支持查询结构化SQL、半结构化知识图谱和非结构化文档。边缘侧LLM将多样数据转换为标准化、隐私保护的表示，服务器侧LLM将其集成以进行全局推理和生成。它集成了轻量级本地检索器和隐私感知LLM，并提供三种匿名化工具。为优化响应延迟和减少冗余计算，设计了三层缓存策略（本地缓存、中间表示缓存和云推理缓存）。

Result: 在PMC-Patients数据集上的实验结果表明，HyFedRAG在检索质量、生成一致性和系统效率方面均优于现有基线。

Conclusion: HyFedRAG为结构异构数据上的RAG提供了一个可扩展且符合隐私要求的解决方案，释放了LLM在敏感和多样数据环境中的潜力。

Abstract: Centralized RAG pipelines struggle with heterogeneous and privacy-sensitive
data, especially in distributed healthcare settings where patient data spans
SQL, knowledge graphs, and clinical notes. Clinicians face difficulties
retrieving rare disease cases due to privacy constraints and the limitations of
traditional cloud-based RAG systems in handling diverse formats and edge
devices. To address this, we introduce HyFedRAG, a unified and efficient
Federated RAG framework tailored for Hybrid data modalities. By leveraging an
edge-cloud collaborative mechanism, HyFedRAG enables RAG to operate across
diverse data sources while preserving data privacy. Our key contributions are:
(1) We design an edge-cloud collaborative RAG framework built on Flower, which
supports querying structured SQL data, semi-structured knowledge graphs, and
unstructured documents. The edge-side LLMs convert diverse data into
standardized privacy-preserving representations, and the server-side LLMs
integrates them for global reasoning and generation. (2) We integrate
lightweight local retrievers with privacy-aware LLMs and provide three
anonymization tools that enable each client to produce semantically rich,
de-identified summaries for global inference across devices. (3) To optimize
response latency and reduce redundant computation, we design a three-tier
caching strategy consisting of local cache, intermediate representation cache,
and cloud inference cache. Experimental results on PMC-Patients demonstrate
that HyFedRAG outperforms existing baselines in terms of retrieval quality,
generation consistency, and system efficiency. Our framework offers a scalable
and privacy-compliant solution for RAG over structural-heterogeneous data,
unlocking the potential of LLMs in sensitive and diverse data environments.

</details>


### [36] [Accelerate Scaling of LLM Alignment via Quantifying the Coverage and Depth of Instruction Set](https://arxiv.org/abs/2509.06463)
*Chengwei Wu,Li Du,Hanyu Zhao,Yiming Ju,Jiapu Wang,Tengfei Pan*

Main category: cs.AI

TL;DR: 本文提出了一种新的指令数据选择方法，通过识别指令深度和语义空间覆盖率是影响大语言模型对齐性能的关键因素，从而实现了模型性能的“加速扩展”。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在下游任务中应用需求的增长，提高模型对齐性能和效率至关重要。然而，由于指令集分布的复杂性，驱动对齐模型性能的关键因素尚不明确，导致当前指令集优化方法在指令池持续扩展时无法有效提升性能。

Method: 研究首先调查了影响指令数据集分布与对齐模型性能之间关系的关键因素。在此基础上，提出了一种新颖的指令数据选择方法。该方法识别出指令深度和语义空间覆盖率是决定下游性能的关键因素，并设计了一种算法来同时最大化所选指令的深度和语义覆盖。

Result: 研究发现指令深度和语义空间覆盖率是决定下游性能的关键因素，可以解释开发集上超过70%的模型损失。实验结果表明，与最先进的基线方法相比，所提出的方法能以更快的速度持续提高模型性能。

Conclusion: 通过优化指令选择，同时最大化指令深度和语义覆盖，本文提出的方法能够持续、快速地提升模型性能，从而实现“加速扩展”。

Abstract: With the growing demand for applying large language models to downstream
tasks, improving model alignment performance and efficiency has become crucial.
Such a process involves selecting informative instructions from a candidate
pool. However, due to the complexity of instruction set distributions, the key
factors driving the performance of aligned models remain unclear. As a result,
current instruction set refinement methods fail to improve performance as the
instruction pool expands continuously. To address this issue, we first
investigate the key factors that influence the relationship between instruction
dataset distribution and aligned model performance. Based on these insights, we
propose a novel instruction data selection method. We identify that the depth
of instructions and the coverage of the semantic space are the crucial factors
determining downstream performance, which could explain over 70\% of the model
loss on the development set. We then design an instruction selection algorithm
to simultaneously maximize the depth and semantic coverage of the selected
instructions. Experimental results demonstrate that, compared to
state-of-the-art baseline methods, it can sustainably improve model performance
at a faster pace and thus achieve \emph{``Accelerated Scaling''}.

</details>


### [37] [MAS-Bench: A Unified Benchmark for Shortcut-Augmented Hybrid Mobile GUI Agents](https://arxiv.org/abs/2509.06477)
*Pengxiang Zhao,Guangyi Liu,Yaozhen Liang,Weiqing He,Zhengxi Lu,Yuehao Huang,Yaxuan Guo,Kexin Zhang,Hao Wang,Liang Liu,Yong Liu*

Main category: cs.AI

TL;DR: 本论文介绍了MAS-Bench，这是一个开创性的基准测试平台，用于评估GUI-快捷方式混合智能体（特别是在移动领域）的性能，并着重于其自主生成快捷方式的能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高智能手机和电脑上GUI智能体的效率，结合灵活GUI操作和高效快捷方式（如API、深度链接）的混合范式正成为一个有前景的方向。然而，目前缺乏一个系统性基准框架来评估这类混合智能体，尤其是在自主生成快捷方式方面。

Method: 研究人员推出了MAS-Bench基准测试平台，它包含11个真实应用中的139个复杂任务、一个包含88个预定义快捷方式（API、深度链接、RPA脚本）的知识库，以及7个评估指标。该平台不仅评估智能体使用预定义快捷方式的能力，还评估其通过发现和创建可复用、低成本工作流来自主生成快捷方式的能力。

Result: 实验结果表明，混合智能体比仅使用GUI操作的智能体在成功率和效率上显著更高。这同时也证明了MAS-Bench在评估智能体快捷方式生成能力方面的有效性。

Conclusion: MAS-Bench填补了混合智能体评估领域的一个关键空白，为未来开发更高效、更鲁棒的智能代理提供了基础平台。

Abstract: To enhance the efficiency of GUI agents on various platforms like smartphones
and computers, a hybrid paradigm that combines flexible GUI operations with
efficient shortcuts (e.g., API, deep links) is emerging as a promising
direction. However, a framework for systematically benchmarking these hybrid
agents is still underexplored. To take the first step in bridging this gap, we
introduce MAS-Bench, a benchmark that pioneers the evaluation of GUI-shortcut
hybrid agents with a specific focus on the mobile domain. Beyond merely using
predefined shortcuts, MAS-Bench assesses an agent's capability to autonomously
generate shortcuts by discovering and creating reusable, low-cost workflows. It
features 139 complex tasks across 11 real-world applications, a knowledge base
of 88 predefined shortcuts (APIs, deep-links, RPA scripts), and 7 evaluation
metrics. The tasks are designed to be solvable via GUI-only operations, but can
be significantly accelerated by intelligently embedding shortcuts. Experiments
show that hybrid agents achieve significantly higher success rates and
efficiency than their GUI-only counterparts. This result also demonstrates the
effectiveness of our method for evaluating an agent's shortcut generation
capabilities. MAS-Bench fills a critical evaluation gap, providing a
foundational platform for future advancements in creating more efficient and
robust intelligent agents.

</details>


### [38] [MORSE: Multi-Objective Reinforcement Learning via Strategy Evolution for Supply Chain Optimization](https://arxiv.org/abs/2509.06490)
*Niki Kotecha,Ehecatl Antonio del Rio Chanona*

Main category: cs.AI

TL;DR: 本文提出了一种结合强化学习（RL）和多目标进化算法（MOEAs）的方法，用于解决不确定性下动态多目标供应链优化问题，并引入CVaR以实现风险敏感决策。


<details>
  <summary>Details</summary>
Motivation: 在供应链管理中，决策需要平衡成本、服务水平和环境可持续性等多个冲突目标。传统的优化方法难以实时适应供应链的动态性。

Method: 该方法结合了强化学习（RL）和多目标进化算法（MOEAs）。MOEAs用于搜索策略神经网络的参数空间，生成一系列帕累托最优策略。这些策略可以根据当前系统目标动态切换。同时，引入条件风险价值（CVaR）以实现风险敏感决策。

Result: 通过案例研究证明了该方法的有效性，展示了其响应供应链动态的能力，并在库存管理案例中优于现有最先进的方法。

Conclusion: 所提出的策略不仅提高了决策效率，还为管理供应链中的不确定性和优化性能提供了一个更强大的框架。

Abstract: In supply chain management, decision-making often involves balancing multiple
conflicting objectives, such as cost reduction, service level improvement, and
environmental sustainability. Traditional multi-objective optimization methods,
such as linear programming and evolutionary algorithms, struggle to adapt in
real-time to the dynamic nature of supply chains. In this paper, we propose an
approach that combines Reinforcement Learning (RL) and Multi-Objective
Evolutionary Algorithms (MOEAs) to address these challenges for dynamic
multi-objective optimization under uncertainty. Our method leverages MOEAs to
search the parameter space of policy neural networks, generating a Pareto front
of policies. This provides decision-makers with a diverse population of
policies that can be dynamically switched based on the current system
objectives, ensuring flexibility and adaptability in real-time decision-making.
We also introduce Conditional Value-at-Risk (CVaR) to incorporate
risk-sensitive decision-making, enhancing resilience in uncertain environments.
We demonstrate the effectiveness of our approach through case studies,
showcasing its ability to respond to supply chain dynamics and outperforming
state-of-the-art methods in an inventory management case study. The proposed
strategy not only improves decision-making efficiency but also offers a more
robust framework for managing uncertainty and optimizing performance in supply
chains.

</details>


### [39] [Scaling up Multi-Turn Off-Policy RL and Multi-Agent Tree Search for LLM Step-Provers](https://arxiv.org/abs/2509.06493)
*Ran Xin,Zeyu Zheng,Yanchen Nie,Kun Yuan,Xia Xiao*

Main category: cs.AI

TL;DR: 本文介绍了BFS-Prover-V2系统，通过创新的多轮离策略强化学习框架和规划器增强的多智能体搜索架构，解决了大型语言模型在自动化定理证明中训练和推理扩展性的挑战，并在数学基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型（LLMs）集成到自动化定理证明中虽然前景广阔，但受到训练时强化学习（RL）和推理时计算扩展性挑战的根本限制。本研究旨在解决这一双重扩展性问题。

Method: 本文提出了两项主要创新：1. 一种新颖的多轮离策略强化学习框架，用于在训练时持续改进LLM步进证明器的性能，该框架受AlphaZero启发，采用多阶段专家迭代管道，具有自适应策略级数据过滤和周期性再训练。2. 一种规划器增强的多智能体搜索架构，用于在推理时扩展推理能力，该架构使用通用推理模型作为高级规划器，将复杂定理分解为一系列简单子目标，并通过共享证明缓存实现并行证明代理的协作。

Result: BFS-Prover-V2在MiniF2F和ProofNet测试集上分别达到了95.08%和41.4%的准确率，在已建立的正式数学基准测试中取得了最先进的结果。

Conclusion: 该双重扩展方法在形式数学领域取得了显著成果。文中所提出的强化学习和推理技术具有广泛的兴趣，可应用于其他需要长周期多轮推理和复杂搜索的领域。

Abstract: The integration of Large Language Models (LLMs) into automated theorem
proving has shown immense promise, yet is fundamentally constrained by
challenges in scaling up both training-time reinforcement learning (RL) and
inference-time compute. This paper introduces \texttt{BFS-Prover-V2}, a system
designed to address this dual scaling problem. We present two primary
innovations. The first is a novel multi-turn off-policy RL framework for
continually improving the performance of LLM step-prover at training time. This
framework, inspired by the principles of AlphaZero, utilizes a multi-stage
expert iteration pipeline featuring adaptive tactic-level data filtering and
periodic retraining to surmount the performance plateaus that typically curtail
long-term RL in LLM-based agents. The second innovation is a planner-enhanced
multi-agent search architecture that scales reasoning capabilities at inference
time. This architecture employs a general reasoning model as a high-level
planner to iteratively decompose complex theorems into a sequence of simpler
subgoals. This hierarchical approach substantially reduces the search space,
enabling a team of parallel prover agents to collaborate efficiently by
leveraging a shared proof cache. We demonstrate that this dual approach to
scaling yields state-of-the-art results on established formal mathematics
benchmarks. \texttt{BFS-Prover-V2} achieves 95.08\% and 41.4\% on the MiniF2F
and ProofNet test sets respectively. While demonstrated in the domain of formal
mathematics, the RL and inference techniques presented in this work are of
broader interest and may be applied to other domains requiring long-horizon
multi-turn reasoning and complex search.

</details>


### [40] [An AI system to help scientists write expert-level empirical software](https://arxiv.org/abs/2509.06503)
*Eser Aygün,Anastasiya Belyaeva,Gheorghe Comanici,Marc Coram,Hao Cui,Jake Garrison,Renee Johnston Anton Kast,Cory Y. McLean,Peter Norgaard,Zahra Shamsi,David Smalling,James Thompson,Subhashini Venugopalan,Brian P. Williams,Chujun He,Sarah Martinson,Martyna Plomecka,Lai Wei,Yuchen Zhou,Qian-Ze Zhu,Matthew Abraham,Erica Brand,Anna Bulanova,Jeffrey A. Cardille,Chris Co,Scott Ellsworth,Grace Joseph,Malcolm Kane,Ryan Krueger,Johan Kartiwa,Dan Liebling,Jan-Matthis Lueckmann,Paul Raccuglia,Xuefei,Wang,Katherine Chou,James Manyika,Yossi Matias,John C. Platt,Lizzie Dorfman,Shibl Mourad,Michael P. Brenner*

Main category: cs.AI

TL;DR: 该研究提出一个结合大语言模型（LLM）和树搜索（TS）的AI系统，能自动创建专家级的科学软件，以最大化质量指标，并在多个科学领域超越人类开发的方法。


<details>
  <summary>Details</summary>
Motivation: 科学发现的周期常因计算实验所需软件的缓慢手动创建而受阻，这成为了一个瓶颈。

Method: 该系统利用大语言模型（LLM）和树搜索（TS）来系统性地提高质量指标，并智能地探索庞大的解决方案空间。它通过探索和整合来自外部来源的复杂研究思想来达到专家级水平。

Result: 该系统在多个基准测试中取得了专家级成果。在生物信息学领域，它发现了40种新颖的单细胞数据分析方法，超越了公共排行榜上顶尖的人类开发方法。在流行病学领域，它生成了14个模型，在预测COVID-19住院人数方面优于CDC集合模型和所有其他个体模型。此外，该方法还为地理空间分析、斑马鱼神经活动预测、时间序列预测和积分数值解生成了最先进的软件。

Conclusion: 通过为各种任务设计和实现新颖的解决方案，该系统代表着在加速科学进步方面迈出了重要一步。

Abstract: The cycle of scientific discovery is frequently bottlenecked by the slow,
manual creation of software to support computational experiments. To address
this, we present an AI system that creates expert-level scientific software
whose goal is to maximize a quality metric. The system uses a Large Language
Model (LLM) and Tree Search (TS) to systematically improve the quality metric
and intelligently navigate the large space of possible solutions. The system
achieves expert-level results when it explores and integrates complex research
ideas from external sources. The effectiveness of tree search is demonstrated
across a wide range of benchmarks. In bioinformatics, it discovered 40 novel
methods for single-cell data analysis that outperformed the top human-developed
methods on a public leaderboard. In epidemiology, it generated 14 models that
outperformed the CDC ensemble and all other individual models for forecasting
COVID-19 hospitalizations. Our method also produced state-of-the-art software
for geospatial analysis, neural activity prediction in zebrafish, time series
forecasting and numerical solution of integrals. By devising and implementing
novel solutions to diverse tasks, the system represents a significant step
towards accelerating scientific progress.

</details>


### [41] [CogGuide: Human-Like Guidance for Zero-Shot Omni-Modal Reasoning](https://arxiv.org/abs/2509.06641)
*Zhou-Peng Shou,Zhi-Qiang You,Fang Wang,Hai-Bo Liu*

Main category: cs.AI

TL;DR: 本文提出了一个零样本多模态推理组件，通过模拟人类认知策略（“意图草图”）来解决多模态大模型中存在的“捷径”推理和上下文理解不足问题，该组件无需参数微调，通过上下文工程即可实现跨模型迁移。


<details>
  <summary>Details</summary>
Motivation: 多模态大模型在复杂的跨模态推理中，存在“捷径”问题和上下文理解不足的问题。

Method: 本文提出了一个即插即用的三模块流水线组件，包括意图感知器（Intent Perceiver）、策略生成器（Strategy Generator）和策略选择器（Strategy Selector），显式构建了“理解-规划-选择”的人类认知过程。通过生成和过滤“意图草图”策略来指导最终推理，无需参数微调，仅通过上下文工程即可实现跨模型迁移。

Result: 信息论分析表明该过程可以降低条件熵并提高信息利用效率，从而抑制非预期的捷径推理。在IntentBench、WorldSense和Daily-Omni数据集上的实验验证了该方法的通用性和鲁棒性，相比各自的基线，完整的三模块方案在不同推理引擎和流水线组合下均实现了持续改进，性能提升高达约9.51个百分点。

Conclusion: 所提出的“意图草图”推理组件在零样本场景中具有显著的实用价值和可移植性，有效提升了多模态大模型的复杂跨模态推理能力。

Abstract: Targeting the issues of "shortcuts" and insufficient contextual understanding
in complex cross-modal reasoning of multimodal large models, this paper
proposes a zero-shot multimodal reasoning component guided by human-like
cognitive strategies centered on an "intent sketch". The component comprises a
plug-and-play three-module pipeline-Intent Perceiver, Strategy Generator, and
Strategy Selector-that explicitly constructs a "understand-plan-select"
cognitive process. By generating and filtering "intent sketch" strategies to
guide the final reasoning, it requires no parameter fine-tuning and achieves
cross-model transfer solely through in-context engineering.
Information-theoretic analysis shows that this process can reduce conditional
entropy and improve information utilization efficiency, thereby suppressing
unintended shortcut reasoning. Experiments on IntentBench, WorldSense, and
Daily-Omni validate the method's generality and robust gains; compared with
their respective baselines, the complete "three-module" scheme yields
consistent improvements across different reasoning engines and pipeline
combinations, with gains up to approximately 9.51 percentage points,
demonstrating the practical value and portability of the "intent sketch"
reasoning component in zero-shot scenarios.

</details>


### [42] [Reinforcement Learning Foundations for Deep Research Systems: A Survey](https://arxiv.org/abs/2509.06733)
*Wenjun Li,Zhi Chen,Jingru Lin,Hannan Cao,Wei Han,Sheng Liang,Zhi Zhang,Kuicai Dong,Dexun Li,Chen Zhang,Yong Liu*

Main category: cs.AI

TL;DR: 这篇综述首次系统地探讨了强化学习（RL）在深度研究系统（即能够协调推理、搜索和工具使用的智能体AI）中的应用基础，并提出了实践指导。


<details>
  <summary>Details</summary>
Motivation: 当前的深度研究系统训练方法（如SFT和DPO）存在局限性，包括模仿和暴露偏差、对环境反馈利用不足、对人类定义决策点的依赖以及长周期信用分配和多目标权衡方面的弱点。强化学习（RL）通过优化轨迹级策略、实现探索和恢复行为，以及提供原则性的信用分配，能更好地应对这些复杂、多步骤任务的挑战，减少对人类先验和评估者偏差的依赖。

Method: 本综述系统地回顾了DeepSeek-R1之后的相关工作，主要围绕三个方面：(i) 数据合成与整理；(ii) 针对智能体研究的RL方法（涵盖稳定性、样本效率、长上下文处理、奖励与信用设计、多目标优化和多模态集成）；(iii) 智能体RL训练系统和框架。此外，还涵盖了智能体架构与协调、评估与基准测试（包括QA、VQA、长文本合成和领域接地工具交互任务）。

Result: 综述总结了重复出现的模式，揭示了基础设施瓶颈，并为使用RL训练鲁棒、透明的深度研究智能体提供了实用指导。

Conclusion: 强化学习是构建能够解决复杂、多步骤任务的深度研究系统的关键基础。本综述为理解和应用RL于此类系统提供了全面的框架和实践指导，有助于推动鲁棒、透明的深度研究智能体的发展。

Abstract: Deep research systems, agentic AI that solve complex, multi-step tasks by
coordinating reasoning, search across the open web and user files, and tool
use, are moving toward hierarchical deployments with a Planner, Coordinator,
and Executors. In practice, training entire stacks end-to-end remains
impractical, so most work trains a single planner connected to core tools such
as search, browsing, and code. While SFT imparts protocol fidelity, it suffers
from imitation and exposure biases and underuses environment feedback.
Preference alignment methods such as DPO are schema and proxy-dependent,
off-policy, and weak for long-horizon credit assignment and multi-objective
trade-offs. A further limitation of SFT and DPO is their reliance on human
defined decision points and subskills through schema design and labeled
comparisons. Reinforcement learning aligns with closed-loop, tool-interaction
research by optimizing trajectory-level policies, enabling exploration,
recovery behaviors, and principled credit assignment, and it reduces dependence
on such human priors and rater biases.
  This survey is, to our knowledge, the first dedicated to the RL foundations
of deep research systems. It systematizes work after DeepSeek-R1 along three
axes: (i) data synthesis and curation; (ii) RL methods for agentic research
covering stability, sample efficiency, long context handling, reward and credit
design, multi-objective optimization, and multimodal integration; and (iii)
agentic RL training systems and frameworks. We also cover agent architecture
and coordination, as well as evaluation and benchmarks, including recent QA,
VQA, long-form synthesis, and domain-grounded, tool-interaction tasks. We
distill recurring patterns, surface infrastructure bottlenecks, and offer
practical guidance for training robust, transparent deep research agents with
RL.

</details>


### [43] [VehicleWorld: A Highly Integrated Multi-Device Environment for Intelligent Vehicle Interaction](https://arxiv.org/abs/2509.06736)
*Jie Yang,Jiajun Chen,Zhangyue Yin,Shuo Chen,Yuxin Wang,Yiran Guo,Yuan Li,Yining Zheng,Xuanjing Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: 本文介绍了VehicleWorld，一个用于智能汽车领域API代理的综合环境，并提出了基于状态的函数调用（SFC）方法，该方法通过维护显式系统状态并实现直接状态转换，显著优于传统函数调用方法，提高了执行精度并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 智能汽车驾驶舱的API代理面临独特挑战，需要协调紧密耦合的子系统，其复杂性超出典型任务环境。传统的函数调用（FC）方法无状态运行，需要多次探索性调用才能建立环境感知，导致效率低下和错误恢复能力有限。

Method: 本文引入了VehicleWorld，这是首个针对汽车领域的综合环境，包含30个模块、250个API和680个属性，具有完全可执行的实现，可在代理执行期间提供实时状态信息。通过系统分析，发现直接状态预测在环境控制方面优于函数调用。在此基础上，提出了基于状态的函数调用（SFC），该方法维护显式系统状态感知并实现直接状态转换以达到目标条件。

Result: 研究发现直接状态预测在环境控制方面优于函数调用。实验结果表明，SFC显著优于传统的FC方法，实现了卓越的执行精度并降低了延迟。

Conclusion: VehicleWorld环境和SFC方法为智能汽车驾驶舱API代理的开发和评估提供了更高效、更准确的解决方案，克服了传统函数调用方法的局限性，特别是在复杂、紧密耦合的子系统协调方面表现出色。

Abstract: Intelligent vehicle cockpits present unique challenges for API Agents,
requiring coordination across tightly-coupled subsystems that exceed typical
task environments' complexity. Traditional Function Calling (FC) approaches
operate statelessly, requiring multiple exploratory calls to build
environmental awareness before execution, leading to inefficiency and limited
error recovery. We introduce VehicleWorld, the first comprehensive environment
for the automotive domain, featuring 30 modules, 250 APIs, and 680 properties
with fully executable implementations that provide real-time state information
during agent execution. This environment enables precise evaluation of vehicle
agent behaviors across diverse, challenging scenarios. Through systematic
analysis, we discovered that direct state prediction outperforms function
calling for environmental control. Building on this insight, we propose
State-based Function Call (SFC), a novel approach that maintains explicit
system state awareness and implements direct state transitions to achieve
target conditions. Experimental results demonstrate that SFC significantly
outperforms traditional FC approaches, achieving superior execution accuracy
and reduced latency. We have made all implementation code publicly available on
Github https://github.com/OpenMOSS/VehicleWorld.

</details>


### [44] [Another Turn, Better Output? A Turn-Wise Analysis of Iterative LLM Prompting](https://arxiv.org/abs/2509.06770)
*Shashidhar Reddy Javaji,Bhavul Gauri,Zining Zhu*

Main category: cs.AI

TL;DR: 该研究提出了一个评估大型语言模型（LLMs）迭代精炼过程的框架，涵盖了创意、代码和数学任务，并测量了迭代在不同领域和提示类型下的效果。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs已广泛应用于多轮工作流程，但目前仍缺乏清晰的方法来衡量迭代何时有益、何时有害。

Method: 研究建立了一个评估框架，对每个任务进行受控的12轮对话，使用从模糊到有针对性的多种提示。通过领域特定的检查（代码的单元测试、数学的答案等效性和推理合理性、创意的原创性和可行性）对结果进行评分，并使用三类指标（语义变化、轮次间变化、输出大小增长）跟踪每轮行为。

Result: 结果显示，迭代收益具有领域依赖性：创意和代码任务的收益出现较早，而数学任务在后期轮次且有详细指导时更有效。模糊反馈在几轮后常导致正确性停滞或下降，而有针对性的提示能可靠地改变预期的质量维度。同时观察到一致的领域模式：创意任务语义变化大，代码任务倾向于尺寸增长而语义变化小，数学任务初期稳定但后期详细迭代可打破路径。

Conclusion: 该框架和指标使得LLM的迭代过程可测量和比较，并能指导何时进行引导、停止或切换策略，以优化不同任务的迭代效果。

Abstract: Large language models (LLMs) are now used in multi-turn workflows, but we
still lack a clear way to measure when iteration helps and when it hurts. We
present an evaluation framework for iterative refinement that spans ideation,
code, and math. Our protocol runs controlled 12-turn conversations per task,
utilizing a variety of prompts ranging from vague ``improve it'' feedback to
targeted steering, and logs per-turn outputs. We score outcomes with
domain-appropriate checks (unit tests for code; answer-equivalence plus
reasoning-soundness for math; originality and feasibility for ideation) and
track turn-level behavior with three families of metrics: semantic movement
across turns, turn-to-turn change, and output size growth. Across models and
tasks, gains are domain-dependent: they arrive early in ideas and code, but in
math late turns matter when guided by elaboration. After the first few turns,
vague feedback often plateaus or reverses correctness, while targeted prompts
reliably shift the intended quality axis (novelty vs. feasibility in ideation;
speed vs. readability in code; in math, elaboration outperforms exploration and
drives late-turn gains). We also observe consistent domain patterns: ideation
moves more in meaning across turns, code tends to grow in size with little
semantic change, and math starts fixed but can break that path with late,
elaborative iteration.Together, the framework and metrics make iteration
measurable and comparable across models, and signal when to steer, stop, or
switch strategies.

</details>


### [45] [RAFFLES: Reasoning-based Attribution of Faults for LLM Systems](https://arxiv.org/abs/2509.06822)
*Chenyang Zhu,Spencer Hong,Jingyu Wu,Kushal Chawla,Charlotte Tang,Youbing Yin,Nathan Wolfe,Erin Babinsky,Daben Liu*

Main category: cs.AI

TL;DR: 本文提出了一种名为RAFFLES的新型评估架构，旨在解决长周期、多组件LLM智能体系统故障诊断的难题，通过迭代推理和细化显著提高了故障定位的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有评估能力（如单次LLM作为评判者）在诊断长周期、多组件LLM智能体系统中的故障位置和原因时存在局限性，它们通常只关注单一指标或最终结果，且过度依赖人类偏好。为了匹配智能体的复杂能力，评估框架也需要能够推理、探查、迭代并理解系统中的复杂逻辑。

Method: RAFFLES是一种结合了推理和迭代细化的评估架构。它作为一个迭代的、多组件的流水线运行，使用一个中央“法官”（Judge）系统地调查故障，并利用一组专门的“评估者”（Evaluators）不仅评估系统的组件，还评估“法官”自身的推理质量，从而建立一个假设历史。

Result: RAFFLES在Who&When数据集上对多个基线进行了测试，该数据集旨在诊断系统故障的“谁”（智能体）和“何时”（步骤）。RAFFLES表现优于这些基线，在算法生成数据集上实现了超过43%的智能体-步骤故障对准确率（比之前发布的最佳16.6%大幅提高），在手工制作数据集上实现了超过20%的准确率（超过之前发布的最佳8.8%）。

Conclusion: 这些结果表明，RAFFLES在为自主系统引入自动化故障检测方面迈出了关键一步，有望取代劳动密集型的人工审查。

Abstract: We have reached a critical roadblock in the development and enhancement of
long-horizon, multi-component LLM agentic systems: it is incredibly tricky to
identify where these systems break down and why. Evaluation capabilities that
currently exist today (e.g., single pass LLM-as-a-judge) are limited in that
they often focus on individual metrics or capabilities, end-to-end outcomes,
and are narrowly grounded on the preferences of humans. We argue that to match
the agentic capabilities, evaluation frameworks must also be able to reason,
probe, iterate, and understand the complex logic passing through these systems
over long horizons. In this paper, we present RAFFLES - an evaluation
architecture that incorporates reasoning and iterative refinement.
Specifically, RAFFLES operates as an iterative, multi-component pipeline, using
a central Judge to systematically investigate faults and a set of specialized
Evaluators to assess not only the system's components but also the quality of
the reasoning by the Judge itself, thereby building a history of hypotheses. We
tested RAFFLES against several baselines on the Who&When dataset, a benchmark
designed to diagnose the "who" (agent) and "when" (step) of a system's failure.
RAFFLES outperforms these baselines, achieving an agent-step fault pair
accuracy of over 43% on the Algorithmically-Generated dataset (a substantial
increase from the previously published best of 16.6%) and over 20% on the
Hand-Crafted dataset (surpassing the previously published best of 8.8%). These
results demonstrate a key step towards introducing automated fault detection
for autonomous systems over labor-intensive manual human review.

</details>


### [46] [Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet](https://arxiv.org/abs/2509.06861)
*James Xu Zhao,Bryan Hooi,See-Kiong Ng*

Main category: cs.AI

TL;DR: 研究发现，测试时扩展（Test-time scaling）在知识密集型任务中并不有效，反而常常导致幻觉（hallucination）增加，尽管“思考”本身仍有益处。


<details>
  <summary>Details</summary>
Motivation: 测试时扩展在许多领域表现出色，但其在需要高事实准确性和低幻觉率的知识密集型任务中的有效性尚未明确。

Method: 研究对12个推理模型在两个知识密集型基准上进行了全面的测试时扩展评估。分析了扩展推理如何影响幻觉行为，并通过案例研究探讨了其影响。

Result: 增加测试时计算并不总能提高准确性，反而常常导致更多幻觉。幻觉减少通常是模型选择弃权而非事实召回改善的结果。对于某些模型，更长的推理会鼓励尝试之前未回答的问题，其中许多导致幻觉。案例研究显示，扩展推理可能诱发确认偏误，导致过度自信的幻觉。尽管存在这些局限性，但相比于不思考，启用思考仍然有益。

Conclusion: 测试时扩展在知识密集型任务中尚未有效，可能增加幻觉，但“思考”这一机制本身仍然有益。需要进一步研究以提高其在知识密集型任务中的性能。

Abstract: Test-time scaling increases inference-time computation by allowing models to
generate long reasoning chains, and has shown strong performance across many
domains. However, in this work, we show that this approach is not yet effective
for knowledge-intensive tasks, where high factual accuracy and low
hallucination rates are essential. We conduct a comprehensive evaluation of
test-time scaling using 12 reasoning models on two knowledge-intensive
benchmarks. Our results reveal that increasing test-time computation does not
consistently improve accuracy and, in many cases, it even leads to more
hallucinations. We then analyze how extended reasoning affects hallucination
behavior. We find that reduced hallucinations often result from the model
choosing to abstain after thinking more, rather than from improved factual
recall. Conversely, for some models, longer reasoning encourages attempts on
previously unanswered questions, many of which result in hallucinations. Case
studies show that extended reasoning can induce confirmation bias, leading to
overconfident hallucinations. Despite these limitations, we observe that
compared to non-thinking, enabling thinking remains beneficial. Code and data
are available at https://github.com/XuZhao0/tts-knowledge

</details>


### [47] [Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI Agents](https://arxiv.org/abs/2509.06917)
*Jiacheng Miao,Joe R. Davis,Jonathan K. Pritchard,James Zou*

Main category: cs.AI

TL;DR: Paper2Agent是一个自动化框架，能将研究论文转化为AI代理，使被动研究成果变为主动系统，加速下游使用、采纳和发现。


<details>
  <summary>Details</summary>
Motivation: 传统研究论文要求读者投入大量精力理解和改编代码、数据和方法，这阻碍了知识的传播和重用。

Method: Paper2Agent通过多智能体系统分析论文及相关代码库，构建模型上下文协议（MCP）服务器，并迭代生成和运行测试来完善MCP。这些MCP可以灵活连接到聊天代理（如Claude Code），通过自然语言处理复杂的科学查询，并调用原始论文中的工具和工作流。

Result: Paper2Agent成功创建了可靠的论文代理，例如基于AlphaGenome解释基因组变异，以及基于ScanPy和TISSUE进行单细胞和空间转录组分析的代理。这些代理能够重现原始论文结果并正确执行新颖的用户查询。

Conclusion: Paper2Agent将静态论文转化为动态、交互式AI代理，为知识传播引入了新范式，并为AI合作科学家的协作生态系统奠定了基础。

Abstract: We introduce Paper2Agent, an automated framework that converts research
papers into AI agents. Paper2Agent transforms research output from passive
artifacts into active systems that can accelerate downstream use, adoption, and
discovery. Conventional research papers require readers to invest substantial
effort to understand and adapt a paper's code, data, and methods to their own
work, creating barriers to dissemination and reuse. Paper2Agent addresses this
challenge by automatically converting a paper into an AI agent that acts as a
knowledgeable research assistant. It systematically analyzes the paper and the
associated codebase using multiple agents to construct a Model Context Protocol
(MCP) server, then iteratively generates and runs tests to refine and robustify
the resulting MCP. These paper MCPs can then be flexibly connected to a chat
agent (e.g. Claude Code) to carry out complex scientific queries through
natural language while invoking tools and workflows from the original paper. We
demonstrate Paper2Agent's effectiveness in creating reliable and capable paper
agents through in-depth case studies. Paper2Agent created an agent that
leverages AlphaGenome to interpret genomic variants and agents based on ScanPy
and TISSUE to carry out single-cell and spatial transcriptomics analyses. We
validate that these paper agents can reproduce the original paper's results and
can correctly carry out novel user queries. By turning static papers into
dynamic, interactive AI agents, Paper2Agent introduces a new paradigm for
knowledge dissemination and a foundation for the collaborative ecosystem of AI
co-scientists.

</details>


### [48] [Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference](https://arxiv.org/abs/2509.06942)
*Xiangwei Shen,Zhimin Li,Zhantao Yang,Shiyi Zhang,Yingfang Zhang,Donghao Li,Chunyu Wang,Qinglin Lu,Yansong Tang*

Main category: cs.AI

TL;DR: 本文提出Direct-Align和SRPO两种方法，以解决扩散模型在对齐人类偏好时面临的计算成本高和奖励模型离线适应的挑战，显著提升了模型生成图像的真实感和美学质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将扩散模型与人类偏好对齐时存在两大挑战：1) 奖励评分依赖多步去噪和梯度计算，计算成本高昂，限制了优化步数；2) 为达到理想的美学质量（如照片级真实感），需持续进行奖励模型的离线适应。

Method: 本文提出：1) Direct-Align，通过预定义噪声先验并利用扩散状态的插值公式，实现从任意时间步有效恢复原始图像，从而避免后期时间步的过度优化，解决多步去噪的限制。2) 语义相对偏好优化（SRPO），将奖励公式化为文本条件信号，支持通过正负提示增强在线调整奖励，减少对离线奖励微调的依赖。

Result: 通过结合优化的去噪和在线奖励调整方法对FLUX.1.dev模型进行微调，其在人类评估的真实感和美学质量上提升了3倍以上。

Conclusion: 本文提出的Direct-Align和SRPO有效解决了扩散模型在对齐人类偏好时的计算效率和奖励模型适应性问题，显著提升了生成图像的质量。

Abstract: Recent studies have demonstrated the effectiveness of directly aligning
diffusion models with human preferences using differentiable reward. However,
they exhibit two primary challenges: (1) they rely on multistep denoising with
gradient computation for reward scoring, which is computationally expensive,
thus restricting optimization to only a few diffusion steps; (2) they often
need continuous offline adaptation of reward models in order to achieve desired
aesthetic quality, such as photorealism or precise lighting effects. To address
the limitation of multistep denoising, we propose Direct-Align, a method that
predefines a noise prior to effectively recover original images from any time
steps via interpolation, leveraging the equation that diffusion states are
interpolations between noise and target images, which effectively avoids
over-optimization in late timesteps. Furthermore, we introduce Semantic
Relative Preference Optimization (SRPO), in which rewards are formulated as
text-conditioned signals. This approach enables online adjustment of rewards in
response to positive and negative prompt augmentation, thereby reducing the
reliance on offline reward fine-tuning. By fine-tuning the FLUX.1.dev model
with optimized denoising and online reward adjustment, we improve its
human-evaluated realism and aesthetic quality by over 3x.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [49] [Label Smoothing++: Enhanced Label Regularization for Training Neural Networks](https://arxiv.org/abs/2509.05307)
*Sachin Chhabra,Hemanth Venkateswara,Baoxin Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为Label Smoothing++的新型标签正则化策略，通过考虑非目标类别之间的关系来改进传统的标签平滑方法，从而减少过拟合和提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统的独热编码标签会导致神经网络过分自信和过拟合。标签平滑（Label Smoothing）通过添加均匀概率向量来缓解这一问题，但它对所有非目标类别赋予相同的权重，忽略了它们之间的类间关系。

Method: Label Smoothing++策略为非目标类别分配非零概率，并考虑它们之间的类间关系。它为目标类别使用固定标签，同时允许网络学习与非目标类别相关的标签。

Result: 在多个数据集上的实验表明，Label Smoothing++能够有效缓解过度自信的预测，同时促进类间关系和提高网络的泛化能力。

Conclusion: Label Smoothing++是一种新颖且有效的标签正则化训练策略，通过更好地处理非目标类别的概率分配和类间关系，优于传统标签平滑方法。

Abstract: Training neural networks with one-hot target labels often results in
overconfidence and overfitting. Label smoothing addresses this issue by
perturbing the one-hot target labels by adding a uniform probability vector to
create a regularized label. Although label smoothing improves the network's
generalization ability, it assigns equal importance to all the non-target
classes, which destroys the inter-class relationships. In this paper, we
propose a novel label regularization training strategy called Label
Smoothing++, which assigns non-zero probabilities to non-target classes and
accounts for their inter-class relationships. Our approach uses a fixed label
for the target class while enabling the network to learn the labels associated
with non-target classes. Through extensive experiments on multiple datasets, we
demonstrate how Label Smoothing++ mitigates overconfident predictions while
promoting inter-class relationships and generalization capabilities.

</details>


### [50] [VILOD: A Visual Interactive Labeling Tool for Object Detection](https://arxiv.org/abs/2509.05317)
*Isac Holm*

Main category: cs.CV

TL;DR: 本文提出VILOD，一个用于目标检测的视觉交互式标注工具，通过整合人类智能和视觉分析，使人机协作式主动学习（HITL-AL）流程更加透明、可管理和高效。


<details>
  <summary>Details</summary>
Motivation: 深度学习目标检测面临获取大量准确标注数据的挑战，此过程耗时且昂贵。主动学习（AL）虽能减少标注工作，但缺乏透明度，限制了人类专家的战略洞察力。因此，需要结合人类智能和直觉的人机协作（HITL）方法，并利用视觉分析（VA）创建有效界面来解决这些问题。

Method: 本文开发并研究了“VILOD：一个用于目标检测的视觉交互式标注工具”。VILOD利用t-SNE图像特征投影、不确定性热图和模型状态视图等组件。它使用户能够在迭代的HITL工作流中探索数据、解释模型状态、AL建议，并实施多样化的样本选择策略。通过比较用例进行了实证调查。

Result: 研究表明，VILOD通过其交互式可视化，使模型状态和数据集特性更易于解释，从而促进了不同标注策略的实施（RQ1）。VILOD中采用的不同视觉引导标注策略，与自动不确定性采样AL基线相比，实现了具有竞争力的目标检测性能轨迹（RQ2）。

Conclusion: 这项工作贡献了一个新颖的工具和实证见解，使目标检测标注的HITL-AL工作流程更加透明、可管理，并可能更有效。

Abstract: The advancement of Object Detection (OD) using Deep Learning (DL) is often
hindered by the significant challenge of acquiring large, accurately labeled
datasets, a process that is time-consuming and expensive. While techniques like
Active Learning (AL) can reduce annotation effort by intelligently querying
informative samples, they often lack transparency, limit the strategic insight
of human experts, and may overlook informative samples not aligned with an
employed query strategy. To mitigate these issues, Human-in-the-Loop (HITL)
approaches integrating human intelligence and intuition throughout the machine
learning life-cycle have gained traction. Leveraging Visual Analytics (VA),
effective interfaces can be created to facilitate this human-AI collaboration.
This thesis explores the intersection of these fields by developing and
investigating "VILOD: A Visual Interactive Labeling tool for Object Detection".
VILOD utilizes components such as a t-SNE projection of image features,
together with uncertainty heatmaps and model state views. Enabling users to
explore data, interpret model states, AL suggestions, and implement diverse
sample selection strategies within an iterative HITL workflow for OD. An
empirical investigation using comparative use cases demonstrated how VILOD,
through its interactive visualizations, facilitates the implementation of
distinct labeling strategies by making the model's state and dataset
characteristics more interpretable (RQ1). The study showed that different
visually-guided labeling strategies employed within VILOD result in competitive
OD performance trajectories compared to an automated uncertainty sampling AL
baseline (RQ2). This work contributes a novel tool and empirical insight into
making the HITL-AL workflow for OD annotation more transparent, manageable, and
potentially more effective.

</details>


### [51] [Context-Aware Knowledge Distillation with Adaptive Weighting for Image Classification](https://arxiv.org/abs/2509.05319)
*Zhengda Li*

Main category: cs.CV

TL;DR: 本文提出自适应知识蒸馏（AKD）框架，通过学习和动态计算平衡因子alpha，并引入上下文感知模块（CAM）根据师生差异自适应调整教师输出的类别权重，以优化知识蒸馏过程。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏使用固定的平衡因子alpha来结合硬标签和软标签损失，但这种固定值并非最优，因为硬监督和软监督之间的最佳权衡在训练过程中是变化的。

Method: 1. 将alpha作为可学习参数，在训练过程中自动优化。2. 引入一个公式，根据学生和教师之间的差异动态计算alpha。3. 引入一个上下文感知模块（CAM），结合多层感知机（MLP）和注意力机制，自适应地重新加权类别级别的教师输出。

Result: 在CIFAR-10数据集上，以ResNet-50为教师模型、ResNet-18为学生模型的实验表明，AKD方法比固定权重知识蒸馏基线取得了更高的准确性，并实现了更稳定的收敛。

Conclusion: 所提出的AKD框架通过自适应调整平衡因子和教师输出权重，有效解决了传统知识蒸馏中固定alpha的局限性，从而提升了学生模型的性能和训练稳定性。

Abstract: Knowledge distillation (KD) is a widely used technique to transfer knowledge
from a large teacher network to a smaller student model. Traditional KD uses a
fixed balancing factor alpha as a hyperparameter to combine the hard-label
cross-entropy loss with the soft-label distillation loss. However, a static
alpha is suboptimal because the optimal trade-off between hard and soft
supervision can vary during training.
  In this work, we propose an Adaptive Knowledge Distillation (AKD) framework.
First we try to make alpha as learnable parameter that can be automatically
learned and optimized during training. Then we introduce a formula to reflect
the gap between the student and the teacher to compute alpha dynamically,
guided by student-teacher discrepancies, and further introduce a Context-Aware
Module (CAM) using MLP + Attention to adaptively reweight class-wise teacher
outputs. Experiments on CIFAR-10 with ResNet-50 as teacher and ResNet-18 as
student demonstrate that our approach achieves superior accuracy compared to
fixed-weight KD baselines, and yields more stable convergence.

</details>


### [52] [A Dataset Generation Scheme Based on Video2EEG-SPGN-Diffusion for SEED-VD](https://arxiv.org/abs/2509.05321)
*Yunfei Guo,Tao Zhang,Wu Huang,Yao Song*

Main category: cs.CV

TL;DR: 本文提出了一个开源框架Video2EEG-SPGN-Diffusion，利用SEED-VD数据集生成基于视频刺激的个性化EEG信号，并发布了一个包含视频和生成EEG信号的多模态数据集。


<details>
  <summary>Details</summary>
Motivation: 研究动机是缺乏用于训练具有EEG对齐能力的多模态大模型的视频-EEG数据集，以及推动情感分析、数据增强和脑机接口等应用。

Method: 该研究利用SEED-VD数据集，开发了一个视频和EEG数据对齐的工程管道。通过将自博弈图网络（SPGN）与扩散模型相结合，生成个性化的EEG信号。

Result: 主要成果是发布了Video2EEG-SPGN-Diffusion开源框架，以及一个包含1000多个样本的新数据集，其中包含SEED-VD视频刺激与生成的62通道200 Hz EEG信号和情感标签，旨在促进视频-EEG对齐和多模态研究。

Conclusion: 该框架和数据集为情感分析、数据增强和脑机接口应用提供了新颖的工具，具有重要的研究和工程意义。

Abstract: This paper introduces an open-source framework, Video2EEG-SPGN-Diffusion,
that leverages the SEED-VD dataset to generate a multimodal dataset of EEG
signals conditioned on video stimuli. Additionally, we disclose an engineering
pipeline for aligning video and EEG data pairs, facilitating the training of
multimodal large models with EEG alignment capabilities. Personalized EEG
signals are generated using a self-play graph network (SPGN) integrated with a
diffusion model. As a major contribution, we release a new dataset comprising
over 1000 samples of SEED-VD video stimuli paired with generated 62-channel EEG
signals at 200 Hz and emotion labels, enabling video-EEG alignment and
advancing multimodal research. This framework offers novel tools for emotion
analysis, data augmentation, and brain-computer interface applications, with
substantial research and engineering significance.

</details>


### [53] [Application of discrete Ricci curvature in pruning randomly wired neural networks: A case study with chest x-ray classification of COVID-19](https://arxiv.org/abs/2509.05322)
*Pavithra Elumalai,Sudharsan Vijayaraghavan,Madhumita Mondal,Areejit Samal*

Main category: cs.CV

TL;DR: 本研究利用Forman-Ricci曲率（FRC）、Ollivier-Ricci曲率（ORC）和边介数中心性（EBC）等以边为中心的网络度量，修剪随机连接神经网络（RWNN），以简化网络并保持在COVID-19图像分类任务中的性能。


<details>
  <summary>Details</summary>
Motivation: RWNNs是研究网络拓扑对深度学习影响的宝贵测试平台。探索以边为中心的网络度量作为修剪和优化的工具，旨在降低网络复杂性，同时保持模型性能。

Method: 研究了FRC、ORC和EBC三种以边为中心的网络度量来修剪RWNN。基线RWNN用于COVID-19胸部X射线图像分类。将这三种度量应用于Erdős-Rényi (ER)、Watts-Strogatz (WS) 和 Barabási-Albert (BA) 三种网络生成器。比较了修剪性能（压缩比和理论加速），并重点评估了FRC的计算效率与ORC的修剪效果。同时通过模块化和全局效率分析了修剪后网络的结构特性。

Result: 研究结果初步表明，基于FRC的修剪可以有效简化RWNN，提供显著的计算优势，同时保持与ORC相当的性能。修剪后的网络在模块化和全局效率方面也得到了评估。

Conclusion: 基于FRC的修剪是一种有效且计算效率更高的方法，可以简化随机连接神经网络，在保持性能的同时，为网络压缩提供了重要的计算优势，并有助于理解压缩后网络的结构特性。

Abstract: Randomly Wired Neural Networks (RWNNs) serve as a valuable testbed for
investigating the impact of network topology in deep learning by capturing how
different connectivity patterns impact both learning efficiency and model
performance. At the same time, they provide a natural framework for exploring
edge-centric network measures as tools for pruning and optimization. In this
study, we investigate three edge-centric network measures: Forman-Ricci
curvature (FRC), Ollivier-Ricci curvature (ORC), and edge betweenness
centrality (EBC), to compress RWNNs by selectively retaining important synapses
(or edges) while pruning the rest. As a baseline, RWNNs are trained for
COVID-19 chest x-ray image classification, aiming to reduce network complexity
while preserving performance in terms of accuracy, specificity, and
sensitivity. We extend prior work on pruning RWNN using ORC by incorporating
two additional edge-centric measures, FRC and EBC, across three network
generators: Erd\"{o}s-R\'{e}nyi (ER) model, Watts-Strogatz (WS) model, and
Barab\'{a}si-Albert (BA) model. We provide a comparative analysis of the
pruning performance of the three measures in terms of compression ratio and
theoretical speedup. A central focus of our study is to evaluate whether FRC,
which is computationally more efficient than ORC, can achieve comparable
pruning effectiveness. Along with performance evaluation, we further
investigate the structural properties of the pruned networks through modularity
and global efficiency, offering insights into the trade-off between modular
segregation and network efficiency in compressed RWNNs. Our results provide
initial evidence that FRC-based pruning can effectively simplify RWNNs,
offering significant computational advantages while maintaining performance
comparable to ORC.

</details>


### [54] [Optical Music Recognition of Jazz Lead Sheets](https://arxiv.org/abs/2509.05329)
*Juan Carlos Martinez-Sevilla,Francesco Foscarin,Patricia Garcia-Iasci,David Rizo,Jorge Calvo-Zaragoza,Gerhard Widmer*

Main category: cs.CV

TL;DR: 该论文提出了一个用于手写爵士乐主旋律谱（包含旋律和和弦）的光学音乐识别（OMR）系统，并发布了一个新的数据集和相应的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的OMR系统无法处理爵士乐主旋律谱中的和弦，并且难以应对手写乐谱图像的高变异性和质量问题，这促使研究者开发专门的解决方案。

Method: 研究者创建了一个包含293份手写爵士乐主旋律谱（共2021个谱表）的新数据集，并提供了Humdrum **kern和MusicXML格式的真实标签。同时，他们还生成了合成乐谱图像。在此基础上，开发了一个专门针对爵士乐主旋律谱的OMR模型，并讨论了特定的分词选择，以及使用合成乐谱和预训练模型的优势。

Result: 主要成果包括一个包含真实手写图像和合成图像的独特数据集，以及一个为爵士乐主旋律谱设计的OMR模型。所有的代码、数据和模型都已公开。

Conclusion: 该研究通过提供一个专门的数据集和OMR模型，成功解决了手写爵士乐主旋律谱识别的挑战，并为未来的研究提供了可公开获取的资源。

Abstract: In this paper, we address the challenge of Optical Music Recognition (OMR)
for handwritten jazz lead sheets, a widely used musical score type that encodes
melody and chords. The task is challenging due to the presence of chords, a
score component not handled by existing OMR systems, and the high variability
and quality issues associated with handwritten images. Our contribution is
two-fold. We present a novel dataset consisting of 293 handwritten jazz lead
sheets of 163 unique pieces, amounting to 2021 total staves aligned with
Humdrum **kern and MusicXML ground truth scores. We also supply synthetic score
images generated from the ground truth. The second contribution is the
development of an OMR model for jazz lead sheets. We discuss specific
tokenisation choices related to our kind of data, and the advantages of using
synthetic scores and pretrained models. We publicly release all code, data, and
models.

</details>


### [55] [RT-VLM: Re-Thinking Vision Language Model with 4-Clues for Real-World Object Recognition Robustness](https://arxiv.org/abs/2509.05333)
*Junghyun Park,Tuan Anh Nguyen,Dugki Min*

Main category: cs.CV

TL;DR: 本文提出了RT-VLM框架，通过生成包含“4条线索”的合成数据集，并结合两阶段的“再思考”推理机制（模型先生成线索，再迭代修正），以提高物体识别模型在领域偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现代物体识别模型在实际部署中常因领域偏移（如低级图像统计、物体姿态、遮挡和类间混淆）导致准确率严重下降，因此需要开发新的方法来缓解这种性能退化。

Method: 该研究引入了RT-VLM框架。核心方法包括：1) 独特的合成数据集生成流程，生成带有“4条线索”（精确边界框、类名、详细物体级描述、场景级描述）的图像；2) 使用此资源对Llama 3.2 11B Vision Instruct模型进行参数高效的监督微调；3) 在推理时执行两阶段“再思考”方案，模型首先生成自己的四条线索，然后将其作为证据重新检查并迭代修正。

Result: 在针对各种领域偏移的鲁棒性基准测试中，RT-VLM持续超越了强大的基线模型。

Conclusion: 研究结果表明，将结构化多模态证据与明确的自我批评循环相结合，是实现可靠和可迁移视觉理解的一个有前景的途径。

Abstract: Real world deployments often expose modern object recognition models to
domain shifts that precipitate a severe drop in accuracy. Such shifts encompass
(i) variations in low level image statistics, (ii) changes in object pose and
viewpoint, (iii) partial occlusion, and (iv) visual confusion across adjacent
classes. To mitigate this degradation, we introduce the Re-Thinking Vision
Language Model (RT-VLM) framework. The foundation of this framework is a unique
synthetic dataset generation pipeline that produces images annotated with
"4-Clues": precise bounding boxes, class names, detailed object-level captions,
and a comprehensive context-level caption for the entire scene. We then perform
parameter efficient supervised tuning of Llama 3.2 11B Vision Instruct on this
resource. At inference time, a two stage Re-Thinking scheme is executed: the
model first emits its own four clues, then re examines these responses as
evidence and iteratively corrects them. Across robustness benchmarks that
isolate individual domain shifts, RT-VLM consistently surpasses strong
baselines. These findings indicate that the integration of structured
multimodal evidence with an explicit self critique loop constitutes a promising
route toward reliable and transferable visual understanding.

</details>


### [56] [A Real-Time, Vision-Based System for Badminton Smash Speed Estimation on Mobile Devices](https://arxiv.org/abs/2509.05334)
*Diwen Huang*

Main category: cs.CV

TL;DR: 本文介绍了一种基于智能手机的经济高效且用户友好的羽毛球扣杀速度测量系统，利用YOLOv5和卡尔曼滤波器从视频中自动计算球速。


<details>
  <summary>Details</summary>
Motivation: 体育运动中的表现指标（如击球速度和角度）对运动员发展至关重要，但传统技术昂贵、复杂且业余选手难以获得。本研究旨在填补这一空白，为羽毛球运动提供可及的性能分析工具。

Method: 该系统利用智能手机技术，采用定制训练的YOLOv5模型进行羽毛球检测，结合卡尔曼滤波器进行鲁棒轨迹跟踪。通过基于视频的运动学速度估算方法和时空缩放，系统能自动计算羽毛球速度。整个过程被封装成一个直观的移动应用程序。

Result: 该系统能够从标准视频录像中自动计算羽毛球的速度，提供高水平的性能分析。

Conclusion: 该研究成功开发了一个民主化高性能分析访问的系统，使各水平的羽毛球运动员都能分析和改进他们的比赛表现。

Abstract: Performance metrics in sports, such as shot speed and angle, provide crucial
feedback for athlete development. However, the technology to capture these
metrics has historically been expensive, complex, and largely inaccessible to
amateur and recreational players. This paper addresses this gap in the context
of badminton, one of the world's most popular sports, by introducing a novel,
cost-effective, and user-friendly system for measuring smash speed using
ubiquitous smartphone technology. Our approach leverages a custom-trained
YOLOv5 model for shuttlecock detection, combined with a Kalman filter for
robust trajectory tracking. By implementing a video-based kinematic speed
estimation method with spatiotemporal scaling, the system automatically
calculates the shuttlecock's velocity from a standard video recording. The
entire process is packaged into an intuitive mobile application, democratizing
access to high-level performance analytics and empowering players at all levels
to analyze and improve their game.

</details>


### [57] [A Stroke-Level Large-Scale Database of Chinese Character Handwriting and the OpenHandWrite_Toolbox for Handwriting Research](https://arxiv.org/abs/2509.05335)
*Zebo Xu,Shaoyun Yu,Mark Torrance,Guido Nottbusch,Nan Zhao,Zhenguang Cai*

Main category: cs.CV

TL;DR: 该研究构建了一个大规模中文手写数据库并升级了手写工具箱，揭示了正字法和语音成分如何分层影响汉字、部首和笔画层面的手写准备与执行，发现词汇效应存在层级衰减。


<details>
  <summary>Details</summary>
Motivation: 中文手写过程中，语言成分（如语音、语义、正字法系统）如何在汉字、部首和笔画层面进行调节，仍是一个重要但未被充分研究的课题。此外，缺乏捕捉和批量处理精细手写数据的综合工具。

Method: 研究构建了一个大规模手写数据库，42名中文母语者每人完成1200个汉字的听写手写任务。同时，增强了现有的OpenHandWrite_Toolbox，使其能轻松修改实验设计、捕捉笔画级手写轨迹并批量处理手写测量数据（如潜伏期、持续时间、笔压）。数据分析采用多元回归。

Result: 多元回归结果显示，正字法预测因子影响汉字、部首和笔画层面的手写准备和执行。语音因素也影响所有三个层面的执行。重要的是，这些词汇效应呈现出层级衰减：在汉字层面最显著，其次是部首，在笔画层面最弱。

Conclusion: 研究结果表明，部首和笔画层面的手写准备和执行与语言成分紧密交织。该数据库和工具箱为未来关于不同语言汉字和子字符手写的心理语言学和神经语言学研究提供了宝贵资源。

Abstract: Understanding what linguistic components (e.g., phonological, semantic, and
orthographic systems) modulate Chinese handwriting at the character, radical,
and stroke levels remains an important yet understudied topic. Additionally,
there is a lack of comprehensive tools for capturing and batch-processing
fine-grained handwriting data. To address these issues, we constructed a
large-scale handwriting database in which 42 Chinese speakers for each
handwriting 1200 characters in a handwriting-to-dictation task. Additionally,
we enhanced the existing handwriting package and provided comprehensive
documentation for the upgraded OpenHandWrite_Toolbox, which can easily modify
the experimental design, capture the stroke-level handwriting trajectory, and
batch-process handwriting measurements (e.g., latency, duration, and
pen-pressure). In analysing our large-scale database, multiple regression
results show that orthographic predictors impact handwriting preparation and
execution across character, radical, and stroke levels. Phonological factors
also influence execution at all three levels. Importantly, these lexical
effects demonstrate hierarchical attenuation - they were most pronounced at the
character level, followed by the radical, and were weakest at the stroke
levels. These findings demonstrate that handwriting preparation and execution
at the radical and stroke levels are closely intertwined with linguistic
components. This database and toolbox offer valuable resources for future
psycholinguistic and neurolinguistic research on the handwriting of characters
and sub-characters across different languages.

</details>


### [58] [Anticipatory Fall Detection in Humans with Hybrid Directed Graph Neural Networks and Long Short-Term Memory](https://arxiv.org/abs/2509.05337)
*Younggeol Cho,Gokhan Solak,Olivia Nocentini,Marta Lorenzini,Andrea Fortuna,Arash Ajoudani*

Main category: cs.CV

TL;DR: 提出了一种结合动态图神经网络（DGNN）和长短期记忆网络（LSTM）的混合模型，通过解耦运动预测和步态分类任务，实现高精度的人体跌倒预测和过渡状态监测。


<details>
  <summary>Details</summary>
Motivation: 尽管跌倒检测取得了显著进展，但在跌倒发生前进行预测以及分析稳定与即将跌倒之间的过渡状态仍是未被探索的领域，这对于辅助机器人系统至关重要。

Method: 该方法采用混合模型，结合动态图神经网络（DGNN）和长短期记忆网络（LSTM）。DGNN作为分类器，区分稳定、过渡和跌倒三种步态状态；LSTM网络则预测未来时间步的人体运动，从而实现早期跌倒检测。输入为视频序列中提取的实时骨骼特征。

Result: 该模型在OUMVLP-Pose和URFD数据集上进行了训练和验证，与仅依赖DGNN的模型及现有文献中的模型相比，在预测误差和识别准确性方面表现出卓越的性能。结果表明，解耦预测和分类任务能够有效提升性能。

Conclusion: 所提出的方法能够实现对跌倒的提前预测和对过渡状态的有效监测，为先进辅助系统提供了有价值的见解，并有望增强其功能。解耦预测和分类任务是提高性能的关键。

Abstract: Detecting and preventing falls in humans is a critical component of assistive
robotic systems. While significant progress has been made in detecting falls,
the prediction of falls before they happen, and analysis of the transient state
between stability and an impending fall remain unexplored. In this paper, we
propose a anticipatory fall detection method that utilizes a hybrid model
combining Dynamic Graph Neural Networks (DGNN) with Long Short-Term Memory
(LSTM) networks that decoupled the motion prediction and gait classification
tasks to anticipate falls with high accuracy. Our approach employs real-time
skeletal features extracted from video sequences as input for the proposed
model. The DGNN acts as a classifier, distinguishing between three gait states:
stable, transient, and fall. The LSTM-based network then predicts human
movement in subsequent time steps, enabling early detection of falls. The
proposed model was trained and validated using the OUMVLP-Pose and URFD
datasets, demonstrating superior performance in terms of prediction error and
recognition accuracy compared to models relying solely on DGNN and models from
literature. The results indicate that decoupling prediction and classification
improves performance compared to addressing the unified problem using only the
DGNN. Furthermore, our method allows for the monitoring of the transient state,
offering valuable insights that could enhance the functionality of advanced
assistance systems.

</details>


### [59] [Comparative Evaluation of Hard and Soft Clustering for Precise Brain Tumor Segmentation in MR Imaging](https://arxiv.org/abs/2509.05340)
*Dibya Jyoti Bora,Mrinal Kanti Mishra*

Main category: cs.CV

TL;DR: 本研究比较了K-Means和模糊C均值（FCM）两种聚类算法在脑肿瘤MRI图像分割中的表现。结果显示K-Means速度更快，而FCM在分割精度上更高，但计算成本也更高。


<details>
  <summary>Details</summary>
Motivation: 由于肿瘤形态和强度分布的异质性，从MRI图像中精确分割脑肿瘤仍是医学图像分析中的关键挑战。准确描绘肿瘤边界对于临床决策、放疗计划和疾病监测至关重要。

Method: 本研究对硬聚类（K-Means）和软聚类（模糊C均值，FCM）两种主要聚类范式进行了比较分析。实验使用BraTS2020数据集，并进行高斯滤波和对比度受限自适应直方图均衡化（CLAHE）预处理。评估指标包括Dice相似系数（DSC）和处理时间。

Result: K-Means算法在速度上表现优异，平均每张图像运行时间为0.3秒。而FCM算法在分割精度上更高，平均DSC为0.67，K-Means为0.43。然而，FCM的计算成本更高，平均每张图像运行时间为1.3秒。

Conclusion: 研究结果突出了计算效率和边界精度之间固有的权衡关系，K-Means速度快但精度低，FCM精度高但速度慢。

Abstract: Segmentation of brain tumors from Magnetic Resonance Imaging (MRI) remains a
pivotal challenge in medical image analysis due to the heterogeneous nature of
tumor morphology and intensity distributions. Accurate delineation of tumor
boundaries is critical for clinical decision-making, radiotherapy planning, and
longitudinal disease monitoring. In this study, we perform a comprehensive
comparative analysis of two major clustering paradigms applied in MRI tumor
segmentation: hard clustering, exemplified by the K-Means algorithm, and soft
clustering, represented by Fuzzy C-Means (FCM). While K-Means assigns each
pixel strictly to a single cluster, FCM introduces partial memberships, meaning
each pixel can belong to multiple clusters with varying degrees of association.
Experimental validation was performed using the BraTS2020 dataset,
incorporating pre-processing through Gaussian filtering and Contrast Limited
Adaptive Histogram Equalization (CLAHE). Evaluation metrics included the Dice
Similarity Coefficient (DSC) and processing time, which collectively
demonstrated that K-Means achieved superior speed with an average runtime of
0.3s per image, whereas FCM attained higher segmentation accuracy with an
average DSC of 0.67 compared to 0.43 for K-Means, albeit at a higher
computational cost (1.3s per image). These results highlight the inherent
trade-off between computational efficiency and boundary precision.

</details>


### [60] [Handling imbalance and few-sample size in ML based Onion disease classification](https://arxiv.org/abs/2509.05341)
*Abhijeet Manoj Pal,Rajbabu Velmurugan*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的洋葱作物病虫害多分类模型，通过集成注意力机制和数据增强，在真实世界图像数据集上实现了高精度分类。


<details>
  <summary>Details</summary>
Motivation: 现有病虫害分类方法主要集中于二分类，这限制了其在需要精确识别特定病虫害类型的实际应用中的效用。

Method: 研究人员通过集成基于注意力机制的模块并采用全面的数据增强管道来缓解类别不平衡问题，从而增强了一个预训练的卷积神经网络（CNN）模型。

Result: 该模型在真实世界田间图像数据集上实现了96.90%的总体准确率和0.96的F1分数，并且比使用相同数据集的其他方法取得了更好的结果。

Conclusion: 所提出的基于深度学习的模型能够鲁棒且准确地进行洋葱作物病虫害的多类别分类，并在性能上超越了现有方法，为精准农业提供了有效工具。

Abstract: Accurate classification of pests and diseases plays a vital role in precision
agriculture, enabling efficient identification, targeted interventions, and
preventing their further spread. However, current methods primarily focus on
binary classification, which limits their practical applications, especially in
scenarios where accurately identifying the specific type of disease or pest is
essential. We propose a robust deep learning based model for multi-class
classification of onion crop diseases and pests. We enhance a pre-trained
Convolutional Neural Network (CNN) model by integrating attention based modules
and employing comprehensive data augmentation pipeline to mitigate class
imbalance. We propose a model which gives 96.90% overall accuracy and 0.96 F1
score on real-world field image dataset. This model gives better results than
other approaches using the same datasets.

</details>


### [61] [Delta Velocity Rectified Flow for Text-to-Image Editing](https://arxiv.org/abs/2509.05342)
*Gaspard Beaudouin,Minghan Li,Jaeyeon Kim,Sunghoon Yoon,Mengyu Wang*

Main category: cs.CV

TL;DR: DVRF是一种新型的、无需反演的、路径感知的整流流模型文本到图像编辑框架，通过显式建模源和目标速度场差异并引入时间依赖的位移项，有效缓解了过平滑问题，提升了编辑质量。


<details>
  <summary>Details</summary>
Motivation: 先前的蒸馏采样方法在文本到图像编辑中普遍存在过平滑伪影，导致编辑质量下降。研究旨在开发一种能够缓解这一问题并提升编辑质量和可控性的方法。

Method: DVRF是一种基于蒸馏的方法，它明确地建模了源速度场和目标速度场之间的差异，以减轻过平滑伪影。此外，它引入了一个时间依赖的位移项，将噪声潜在变量推向目标轨迹，增强与目标分布的对齐。理论上，当位移项禁用时，DVRF退化为Delta Denoising Score；当位移项遵循整流流动力学下的线性调度时，DVRF推广了无需反演的方法FlowEdit。

Result: 实验结果表明，DVRF在编辑质量、保真度和可控性方面表现优越，且无需修改现有架构，使其高效并广泛适用于文本到图像编辑任务。

Conclusion: DVRF提供了一个理论基础扎实且实验效果出色的文本到图像编辑框架，通过解决现有方法的过平滑问题，显著提升了图像编辑的质量、保真度和可控性，具有高效和广泛适用性。

Abstract: We propose Delta Velocity Rectified Flow (DVRF), a novel inversion-free,
path-aware editing framework within rectified flow models for text-to-image
editing. DVRF is a distillation-based method that explicitly models the
discrepancy between the source and target velocity fields in order to mitigate
over-smoothing artifacts rampant in prior distillation sampling approaches. We
further introduce a time-dependent shift term to push noisy latents closer to
the target trajectory, enhancing the alignment with the target distribution. We
theoretically demonstrate that when this shift is disabled, DVRF reduces to
Delta Denoising Score, thereby bridging score-based diffusion optimization and
velocity-based rectified-flow optimization. Moreover, when the shift term
follows a linear schedule under rectified-flow dynamics, DVRF generalizes the
Inversion-free method FlowEdit and provides a principled theoretical
interpretation for it. Experimental results indicate that DVRF achieves
superior editing quality, fidelity, and controllability while requiring no
architectural modifications, making it efficient and broadly applicable to
text-to-image editing tasks. Code is available at
https://github.com/gaspardbd/DeltaVelocityRectifiedFlow.

</details>


### [62] [Systematic Integration of Attention Modules into CNNs for Accurate and Generalizable Medical Image Diagnosis](https://arxiv.org/abs/2509.05343)
*Zahid Ullah,Minki Hong,Tahir Mahmood,Jihie Kim*

Main category: cs.CV

TL;DR: 本研究系统地将注意力机制集成到多种卷积神经网络（CNN）架构中，以提升医学图像分析的性能，特别是在细粒度特征捕获和特征定位方面。


<details>
  <summary>Details</summary>
Motivation: 传统的卷积神经网络（CNN）在医学图像分析中难以捕捉关键的细粒度复杂特征，这限制了其在精确诊断中的应用。

Method: 研究人员将Squeeze and Excitation (SE)模块或混合卷积块注意力模块（CBAM）集成到五种广泛使用的CNN架构中（VGG16, ResNet18, InceptionV3, DenseNet121, EfficientNetB5）。模型在两个不同的医学图像数据集上进行评估：一个脑肿瘤MRI数据集和一个妊娠产物组织病理学数据集。

Result: 实验结果表明，增强了注意力机制的CNN模型在所有评估指标上均持续优于基线架构。特别是，结合了混合注意力机制的EfficientNetB5在两个数据集上均取得了最高的整体性能，显著提升了分类准确性。此外，注意力机制还增强了特征定位能力，从而提高了模型在异构成像模态上的泛化能力。

Conclusion: 本工作提供了一个系统性的框架，用于在不同的CNN架构中嵌入注意力模块，并严格评估了它们在多种医学成像任务中的影响。研究结果为开发鲁棒、可解释且临床适用的深度学习辅助决策系统提供了实用的见解。

Abstract: Deep learning has become a powerful tool for medical image analysis; however,
conventional Convolutional Neural Networks (CNNs) often fail to capture the
fine-grained and complex features critical for accurate diagnosis. To address
this limitation, we systematically integrate attention mechanisms into five
widely adopted CNN architectures, namely, VGG16, ResNet18, InceptionV3,
DenseNet121, and EfficientNetB5, to enhance their ability to focus on salient
regions and improve discriminative performance. Specifically, each baseline
model is augmented with either a Squeeze and Excitation block or a hybrid
Convolutional Block Attention Module, allowing adaptive recalibration of
channel and spatial feature representations. The proposed models are evaluated
on two distinct medical imaging datasets, a brain tumor MRI dataset comprising
multiple tumor subtypes, and a Products of Conception histopathological dataset
containing four tissue categories. Experimental results demonstrate that
attention augmented CNNs consistently outperform baseline architectures across
all metrics. In particular, EfficientNetB5 with hybrid attention achieves the
highest overall performance, delivering substantial gains on both datasets.
Beyond improved classification accuracy, attention mechanisms enhance feature
localization, leading to better generalization across heterogeneous imaging
modalities. This work contributes a systematic comparative framework for
embedding attention modules in diverse CNN architectures and rigorously
assesses their impact across multiple medical imaging tasks. The findings
provide practical insights for the development of robust, interpretable, and
clinically applicable deep learning based decision support systems.

</details>


### [63] [Near Real-Time Dust Aerosol Detection with 3D Convolutional Neural Networks on MODIS Data](https://arxiv.org/abs/2509.05887)
*Caleb Gates,Patrick Moorhead,Jayden Ferguson,Omar Darwish,Conner Stallman,Pablo Rivas,Paapa Quansah*

Main category: cs.CV

TL;DR: 该研究开发了一个近实时系统，利用3D卷积网络和MODIS多光谱图像，在像素级别上快速检测沙尘暴，实现全球范围内的及时预警。


<details>
  <summary>Details</summary>
Motivation: 沙尘暴危害健康并降低能见度，因此需要从卫星快速检测沙尘暴。

Method: 该系统利用NASA Terra和Aqua卫星的MODIS多波段图像（包括所有36个波段和分裂热波段），采用3D卷积网络学习沙尘、云和地表特征之间的模式。通过简单的归一化和局部填充处理缺失数据，并开发了改进版本以提高训练速度和全场景处理效率。

Result: 在17个独立的MODIS场景上，该模型达到了约0.92的准确率和0.014的均方误差。结果显示在沙尘核心区域具有很强的一致性，主要遗漏发生在边缘区域。

Conclusion: 联合波段和空间学习的方法可以提供全球范围内的及时沙尘预警。未来的工作可以通过使用更宽的输入窗口或基于注意力（attention-based）的模型来进一步锐化边缘检测。

Abstract: Dust storms harm health and reduce visibility; quick detection from
satellites is needed. We present a near real-time system that flags dust at the
pixel level using multi-band images from NASA's Terra and Aqua (MODIS). A 3D
convolutional network learns patterns across all 36 bands, plus split thermal
bands, to separate dust from clouds and surface features. Simple normalization
and local filling handle missing data. An improved version raises training
speed by 21x and supports fast processing of full scenes. On 17 independent
MODIS scenes, the model reaches about 0.92 accuracy with a mean squared error
of 0.014. Maps show strong agreement in plume cores, with most misses along
edges. These results show that joint band-and-space learning can provide timely
dust alerts at global scale; using wider input windows or attention-based
models may further sharpen edges.

</details>


### [64] [Vision-Based Object Detection for UAV Solar Panel Inspection Using an Enhanced Defects Dataset](https://arxiv.org/abs/2509.05348)
*Ashen Rodrigo,Isuru Munasinghe,Asanka Perera*

Main category: cs.CV

TL;DR: 本研究评估了YOLOv3、Faster R-CNN等五种先进目标检测模型在太阳能电池板缺陷和污染物检测方面的性能，并发布了一个定制数据集，旨在为实际应用提供模型选择指导。


<details>
  <summary>Details</summary>
Motivation: 及时准确地检测太阳能电池板中的缺陷和污染物对于维持光伏系统的效率和可靠性至关重要。

Method: 研究开发了一个COCO格式的定制太阳能电池板缺陷和污染数据集，并构建了一个用户界面用于模型训练和评估。评估了YOLOv3、Faster R-CNN、RetinaNet、EfficientDet和Swin Transformer五种目标检测模型，用于识别物理和电气缺陷以及灰尘、污垢和鸟粪等表面污染物。模型性能通过平均精度均值（mAP）、精确率、召回率和推理速度进行评估和比较。

Result: 结果展示了检测精度和计算效率之间的权衡，并突出了每种模型的相对优势和局限性。

Conclusion: 这些发现为在实际太阳能电池板监测和维护场景中选择合适的检测方法提供了有价值的指导。

Abstract: Timely and accurate detection of defects and contaminants in solar panels is
critical for maintaining the efficiency and reliability of photovoltaic
systems. This study presents a comprehensive evaluation of five
state-of-the-art object detection models: YOLOv3, Faster R-CNN, RetinaNet,
EfficientDet, and Swin Transformer, for identifying physical and electrical
defects as well as surface contaminants such as dust, dirt, and bird droppings
on solar panels. A custom dataset, annotated in the COCO format and
specifically designed for solar panel defect and contamination detection, was
developed alongside a user interface to train and evaluate the models. The
performance of each model is assessed and compared based on mean Average
Precision (mAP), precision, recall, and inference speed. The results
demonstrate the trade-offs between detection accuracy and computational
efficiency, highlighting the relative strengths and limitations of each model.
These findings provide valuable guidance for selecting appropriate detection
approaches in practical solar panel monitoring and maintenance scenarios.
  The dataset will be publicly available at
https://github.com/IsuruMunasinghe98/solar-panel-inspection-dataset.

</details>


### [65] [VQualA 2025 Challenge on Image Super-Resolution Generated Content Quality Assessment: Methods and Results](https://arxiv.org/abs/2509.06413)
*Yixiao Li,Xin Li,Chris Wei Zhou,Shuo Xing,Hadi Amirpour,Xiaoshuai Hao,Guanghui Yue,Baoquan Zhao,Weide Liu,Xiaoyuan Yang,Zhengzhong Tu,Xinyu Li,Chuanbiao Song,Chenqi Zhang,Jun Lan,Huijia Zhu,Weiqiang Wang,Xiaoyan Sun,Shishun Tian,Dongyang Yan,Weixia Zhang,Junlin Chen,Wei Sun,Zhihua Wang,Zhuohang Shi,Zhizun Luo,Hang Ouyang,Tianxin Xiao,Fan Yang,Zhaowang Wu,Kaixin Deng*

Main category: cs.CV

TL;DR: 本文介绍了ISRGC-Q挑战赛，该挑战赛基于ISRGen-QA数据集，旨在评估由GAN和扩散模型等现代生成方法生成的超分辨率图像的感知质量及其独特伪影。


<details>
  <summary>Details</summary>
Motivation: 现有超分辨率图像质量评估(SR-IQA)数据集未能充分强调由最新生成方法（如GAN和扩散模型）生成的超分辨率图像。因此，需要分析这些现代技术引入的独特伪影并有效评估其感知质量。

Method: 本文组织了ISRGC-Q挑战赛，该挑战赛基于ISRGen-QA数据集。ISRGen-QA数据集特别侧重于包含由最新生成方法（包括GAN和扩散模型）生成的超分辨率图像。挑战赛邀请参与者提交解决方案，以评估这些图像的质量。

Result: 共有108名参与者注册，4支团队提交了有效解决方案。这些提交的方案在ISRGen-QA数据集上展示了最先进（SOTA）的性能。

Conclusion: ISRGC-Q挑战赛成功地促进了对现代超分辨率图像质量评估的研究，并展示了当前最先进方法在处理由最新生成模型产生的独特伪影方面的能力。

Abstract: This paper presents the ISRGC-Q Challenge, built upon the Image
Super-Resolution Generated Content Quality Assessment (ISRGen-QA) dataset, and
organized as part of the Visual Quality Assessment (VQualA) Competition at the
ICCV 2025 Workshops. Unlike existing Super-Resolution Image Quality Assessment
(SR-IQA) datasets, ISRGen-QA places a greater emphasis on SR images generated
by the latest generative approaches, including Generative Adversarial Networks
(GANs) and diffusion models. The primary goal of this challenge is to analyze
the unique artifacts introduced by modern super-resolution techniques and to
evaluate their perceptual quality effectively. A total of 108 participants
registered for the challenge, with 4 teams submitting valid solutions and fact
sheets for the final testing phase. These submissions demonstrated
state-of-the-art (SOTA) performance on the ISRGen-QA dataset. The project is
publicly available at: https://github.com/Lighting-YXLI/ISRGen-QA.

</details>


### [66] [Unsupervised Instance Segmentation with Superpixels](https://arxiv.org/abs/2509.05352)
*Cuong Manh Hoang*

Main category: cs.CV

TL;DR: 该论文提出了一种无需人工标注的实例分割新框架，通过自监督特征、多切分算法、掩码过滤、超像素引导损失和自训练过程，实现了高效且有效的对象分割。


<details>
  <summary>Details</summary>
Motivation: 实例分割在计算机视觉应用中至关重要，但当前流行模型依赖大量昂贵的人工标注数据进行训练，这促使研究者寻找无需人工标注的分割方法。

Method: 首先，将MultiCut算法应用于自监督特征以进行粗略掩码分割；接着，使用掩码过滤器获取高质量的粗略掩码；然后，利用高质量粗略掩码和低级图像特征分割的超像素，计算一种新颖的超像素引导掩码损失（包含硬损失和软损失）来训练分割网络；最后，提出一个带有新自适应损失的自训练过程来提高预测掩码的质量。

Result: 实验结果表明，所提出的框架在实例分割和目标检测的公共数据集上优于现有最先进的方法。

Conclusion: 该论文成功开发了一个无需人工标注的实例分割框架，该框架在效率和有效性方面均表现出色，并超越了以往的最先进方法。

Abstract: Instance segmentation is essential for numerous computer vision applications,
including robotics, human-computer interaction, and autonomous driving.
Currently, popular models bring impressive performance in instance segmentation
by training with a large number of human annotations, which are costly to
collect. For this reason, we present a new framework that efficiently and
effectively segments objects without the need for human annotations. Firstly, a
MultiCut algorithm is applied to self-supervised features for coarse mask
segmentation. Then, a mask filter is employed to obtain high-quality coarse
masks. To train the segmentation network, we compute a novel superpixel-guided
mask loss, comprising hard loss and soft loss, with high-quality coarse masks
and superpixels segmented from low-level image features. Lastly, a
self-training process with a new adaptive loss is proposed to improve the
quality of predicted masks. We conduct experiments on public datasets in
instance segmentation and object detection to demonstrate the effectiveness of
the proposed framework. The results show that the proposed framework
outperforms previous state-of-the-art methods.

</details>


### [67] [Perception-oriented Bidirectional Attention Network for Image Super-resolution Quality Assessment](https://arxiv.org/abs/2509.06442)
*Yixiao Li,Xiaoyuan Yang,Guanghui Yue,Jun Fu,Qiuping Jiang,Xu Jia,Paul L. Rosin,Hantao Liu,Wei Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为感知导向双向注意力网络（PBAN）的全参考图像质量评估（FR-IQA）方法，用于评估超分辨率（SR）图像，该方法通过创新的双向注意力机制和多尺度形变卷积，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的用于比较和评估不同超分辨率（SR）算法的全参考（FR）图像质量评估（IQA）指标有限，无法有效满足需求。

Method: 本文提出了PBAN，包含三个模块：图像编码器模块、感知导向双向注意力（PBA）模块和质量预测模块。PBA模块受人类视觉系统启发，构建了双向注意力来感知失真，这与SR图像的生成和评估过程一致。为进一步引导质量评估关注失真信息，提出了分组多尺度形变卷积（Grouped Multi-scale Deformable Convolution）来自适应感知失真，并设计了子信息激发卷积（Sub-information Excitation Convolution）来引导视觉感知到子像素和子通道注意力。最后，质量预测模块整合质量感知特征并回归质量分数。

Result: 广泛的实验证明，所提出的PBAN在图像质量评估方面优于最先进的方法。

Conclusion: PBAN是一种高性能的SR图像FR-IQA方法，通过其独特的感知导向双向注意力机制和对失真信息的精细感知能力，能够更准确地评估SR图像质量。

Abstract: Many super-resolution (SR) algorithms have been proposed to increase image
resolution. However, full-reference (FR) image quality assessment (IQA) metrics
for comparing and evaluating different SR algorithms are limited. In this work,
we propose the Perception-oriented Bidirectional Attention Network (PBAN) for
image SR FR-IQA, which is composed of three modules: an image encoder module, a
perception-oriented bidirectional attention (PBA) module, and a quality
prediction module. First, we encode the input images for feature
representations. Inspired by the characteristics of the human visual system, we
then construct the perception-oriented PBA module. Specifically, different from
existing attention-based SR IQA methods, we conceive a Bidirectional Attention
to bidirectionally construct visual attention to distortion, which is
consistent with the generation and evaluation processes of SR images. To
further guide the quality assessment towards the perception of distorted
information, we propose Grouped Multi-scale Deformable Convolution, enabling
the proposed method to adaptively perceive distortion. Moreover, we design
Sub-information Excitation Convolution to direct visual perception to both
sub-pixel and sub-channel attention. Finally, the quality prediction module is
exploited to integrate quality-aware features and regress quality scores.
Extensive experiments demonstrate that our proposed PBAN outperforms
state-of-the-art quality assessment methods.

</details>


### [68] [Augmented Structure Preserving Neural Networks for cell biomechanics](https://arxiv.org/abs/2509.05388)
*Juan Olalla-Pombo,Alberto Badías,Miguel Ángel Sanz-Gómez,José María Benítez,Francisco Javier Montáns*

Main category: cs.CV

TL;DR: 本文提出了一种结合结构保持神经网络（用于机械系统）和机器学习工具（如人工神经网络，用于环境因素，通过计算机视觉获取）的新方法，以高精度预测细胞轨迹和有丝分裂事件。


<details>
  <summary>Details</summary>
Motivation: 细胞生物力学对生命进化和相关过程（如胚胎发生、损伤修复、肿瘤生长）至关重要，但其复杂的相互作用以及对细胞集体决策的影响尚不清楚，这促使研究者寻求更深入的理解。

Method: 该方法结合了结构保持神经网络（将细胞运动视为纯机械系统）和其他机器学习工具（如人工神经网络，考虑通过计算机视觉技术从实验中直接推导出的环境因素）。模型通过“滚动策略”预测完整的细胞轨迹，并利用神经网络架构基于相同观察特征预测有丝分裂事件。

Result: 新模型在模拟和真实细胞迁移案例中，能够以高精度预测完整的细胞轨迹。此外，它还包含一个基于神经网络架构的有丝分裂事件预测模型。

Conclusion: 该研究提供了一种结合机械和环境因素的创新模型，能够准确预测细胞轨迹和有丝分裂事件，为理解细胞生物力学中的复杂现象提供了新的工具和见解。

Abstract: Cell biomechanics involve a great number of complex phenomena that are
fundamental to the evolution of life itself and other associated processes,
ranging from the very early stages of embryo-genesis to the maintenance of
damaged structures or the growth of tumors. Given the importance of such
phenomena, increasing research has been dedicated to their understanding, but
the many interactions between them and their influence on the decisions of
cells as a collective network or cluster remain unclear. We present a new
approach that combines Structure Preserving Neural Networks, which study cell
movements as a purely mechanical system, with other Machine Learning tools
(Artificial Neural Networks), which allow taking into consideration
environmental factors that can be directly deduced from an experiment with
Computer Vision techniques. This new model, tested on simulated and real cell
migration cases, predicts complete cell trajectories following a roll-out
policy with a high level of accuracy. This work also includes a mitosis event
prediction model based on Neural Networks architectures which makes use of the
same observed features.

</details>


### [69] [Intraoperative 2D/3D Registration via Spherical Similarity Learning and Inference-Time Differentiable Levenberg-Marquardt Optimization](https://arxiv.org/abs/2509.06890)
*Minheng Chen,Youyong Kong*

Main category: cs.CV

TL;DR: 本文提出一种基于非欧几里得球面特征空间和SO(4)黎曼距离的2D/3D配准方法，通过更好地捕捉流形结构，提升了配准精度和收敛速度，优于现有欧几里得近似方法。


<details>
  <summary>Details</summary>
Motivation: 现有的2D/3D配准框架中，欧几里得近似会扭曲流形结构并减慢收敛速度，限制了配准的捕获范围和对显著扰动的鲁棒性。

Method: 该方法使用CNN-Transformer编码器提取特征嵌入，将其投影到非欧几里得球面特征空间，并利用双不变SO(4)空间中的黎曼距离近似测地线距离。推断时，采用全微分的Levenberg-Marquardt优化替代梯度下降以加速收敛。

Result: 在真实和合成数据集上，无论是在患者特异性还是患者无关的场景中，该方法都显示出卓越的配准精度。

Conclusion: 通过在非欧几里得球面特征空间中学习相似性并使用SO(4)黎曼距离，该方法提供了一种更具表达性和几何一致性的深度相似性度量，增强了区分细微姿态差异的能力，并结合Levenberg-Marquardt优化加速收敛，最终实现了更优异的配准精度。

Abstract: Intraoperative 2D/3D registration aligns preoperative 3D volumes with
real-time 2D radiographs, enabling accurate localization of instruments and
implants. A recent fully differentiable similarity learning framework
approximates geodesic distances on SE(3), expanding the capture range of
registration and mitigating the effects of substantial disturbances, but
existing Euclidean approximations distort manifold structure and slow
convergence. To address these limitations, we explore similarity learning in
non-Euclidean spherical feature spaces to better capture and fit complex
manifold structure. We extract feature embeddings using a CNN-Transformer
encoder, project them into spherical space, and approximate their geodesic
distances with Riemannian distances in the bi-invariant SO(4) space. This
enables a more expressive and geometrically consistent deep similarity metric,
enhancing the ability to distinguish subtle pose differences. During inference,
we replace gradient descent with fully differentiable Levenberg-Marquardt
optimization to accelerate convergence. Experiments on real and synthetic
datasets show superior accuracy in both patient-specific and patient-agnostic
scenarios.

</details>


### [70] [Advanced Brain Tumor Segmentation Using EMCAD: Efficient Multi-scale Convolutional Attention Decoding](https://arxiv.org/abs/2509.05431)
*GodsGift Uzor,Tania-Amanda Nkoyo Fredrick Eneye,Chukwuebuka Ijezue*

Main category: cs.CV

TL;DR: 该研究提出了一种名为EMCAD的高效多尺度卷积注意力解码器，用于优化脑肿瘤分割的性能和计算效率，在BraTs2020数据集上取得了中等但稳定的分割结果。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤分割是医学图像分析中的关键预处理步骤，需要精确勾勒肿瘤区域。然而，现有的高效解码机制通常计算成本高昂，尤其是在计算资源有限的情况下，这促使研究人员寻找更高效的解决方案。

Method: 研究人员利用了一种名为EMCAD（高效多尺度卷积注意力解码器）的新设计，以优化脑肿瘤分割的性能和计算效率。该模型在BraTs2020数据集（包含369名脑肿瘤患者的MRI扫描数据）上进行了应用。

Result: 该模型取得了0.31的最佳Dice分数，并在整个训练过程中保持了0.285 ± 0.015的稳定平均Dice分数，表现中等。初步模型在验证集上保持了稳定性能，没有出现过拟合迹象。

Conclusion: EMCAD解码器在脑肿瘤分割任务上实现了中等但稳定的性能，并在有限计算资源场景下展现了其在性能和效率优化方面的潜力，同时避免了过拟合。

Abstract: Brain tumor segmentation is a critical pre-processing step in the medical
image analysis pipeline that involves precise delineation of tumor regions from
healthy brain tissue in medical imaging data, particularly MRI scans. An
efficient and effective decoding mechanism is crucial in brain tumor
segmentation especially in scenarios with limited computational resources.
However these decoding mechanisms usually come with high computational costs.
To address this concern EMCAD a new efficient multi-scale convolutional
attention decoder designed was utilized to optimize both performance and
computational efficiency for brain tumor segmentation on the BraTs2020 dataset
consisting of MRI scans from 369 brain tumor patients. The preliminary result
obtained by the model achieved a best Dice score of 0.31 and maintained a
stable mean Dice score of 0.285 plus/minus 0.015 throughout the training
process which is moderate. The initial model maintained consistent performance
across the validation set without showing signs of over-fitting.

</details>


### [71] [FAVAE-Effective Frequency Aware Latent Tokenizer](https://arxiv.org/abs/2509.05441)
*Tejaswini Medi,Hsien-Yi Wang,Arianna Rampini,Margret Keuper*

Main category: cs.CV

TL;DR: 本文提出了一种基于小波的频率感知变分自编码器（FA-VAE），通过解耦低频和高频分量的优化，解决了现有潜在编码器在图像合成中高频细节丢失和过度平滑的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管潜在生成模型在图像合成方面取得了显著进展，但重建图像常缺乏真实感，尤其是在纹理区域，因高频细节丢失导致。研究发现，现有最先进的潜在编码器在优化时偏向低频重建，牺牲了高频保真度，导致输出过度平滑和视觉伪影。

Method: 首先，对现有最先进的潜在编码器进行了详细的频率分解，揭示了其在联合优化时对低频信息的固有偏见。然后，提出了一种基于小波的频率感知变分自编码器（FA-VAE）框架，该框架明确地解耦了低频和高频分量的优化。

Result: FA-VAE方法能够改进精细纹理的重建，同时保持全局结构。它弥补了当前潜在编码器在保真度上的差距，并强调了频率感知优化对于真实图像表示的重要性。

Conclusion: 频率感知优化对于生成真实感图像至关重要，本文提出的FA-VAE为内容创作、神经渲染和医学成像等应用提供了更广阔的潜力。

Abstract: Latent generative models have shown remarkable progress in high-fidelity
image synthesis, typically using a two-stage training process that involves
compressing images into latent embeddings via learned tokenizers in the first
stage. The quality of generation strongly depends on how expressive and
well-optimized these latent embeddings are. While various methods have been
proposed to learn effective latent representations, the reconstructed images
often lack realism, particularly in textured regions with sharp transitions,
due to loss of fine details governed by high frequencies. We conduct a detailed
frequency decomposition of existing state-of-the-art (SOTA) latent tokenizers
and show that conventional objectives inherently prioritize low-frequency
reconstruction, often at the expense of high-frequency fidelity. Our analysis
reveals these latent tokenizers exhibit a bias toward low-frequency
information, when jointly optimized, leading to over-smoothed outputs and
visual artifacts that diminish perceptual quality. To address this, we propose
a wavelet-based, frequency-aware variational autoencoder (FA-VAE) framework
that explicitly decouples the optimization of low- and high-frequency
components. This decoupling enables improved reconstruction of fine textures
while preserving global structure. Our approach bridges the fidelity gap in
current latent tokenizers and emphasizes the importance of frequency-aware
optimization for realistic image representation, with broader implications for
applications in content creation, neural rendering, and medical imaging.

</details>


### [72] [Dynamic Sensitivity Filter Pruning using Multi-Agent Reinforcement Learning For DCNN's](https://arxiv.org/abs/2509.05446)
*Iftekhar Haider Chowdhury,Zaed Ikbal Syed,Ahmed Faizul Haque Dhrubo,Mohammad Abdul Qayum*

Main category: cs.CV

TL;DR: 本文提出了一种名为差分敏感度融合剪枝（DSFP）的单次滤波器剪枝框架，通过融合多种重要性评估指标的差异来识别不稳定或冗余的滤波器，从而高效压缩深度卷积神经网络，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 深度卷积神经网络在计算机视觉任务中表现出色，但其高计算和内存开销限制了实际部署，尤其是在边缘和移动平台上。

Method: 差分敏感度融合剪枝（DSFP）是一种单次滤波器剪枝框架。它通过融合基于梯度的敏感度、一阶泰勒展开和激活分布的KL散度之间的差异来计算每个滤波器的差分敏感度分数。该方法应用指数缩放机制来强调在不同指标上重要性不一致的滤波器，以识别结构不稳定或对模型性能不那么关键的候选滤波器。整个过程是确定性的，仅需一次前向-后向传播来评分和剪枝。

Result: DSFP在50%到70%的剪枝率下，显著降低了模型复杂度，实现了超过80%的浮点运算（FLOPS）减少，同时保持了高精度。例如，在70%的剪枝率下，该方法能保留基线精度高达98.23%，在压缩和泛化方面均超越了传统启发式方法。

Conclusion: 所提出的DSFP方法为可扩展和自适应的深度卷积神经网络压缩提供了一种有效的解决方案，为在边缘和移动平台上高效部署铺平了道路。

Abstract: Deep Convolutional Neural Networks have achieved state of the art performance
across various computer vision tasks, however their practical deployment is
limited by computational and memory overhead. This paper introduces
Differential Sensitivity Fusion Pruning, a novel single shot filter pruning
framework that focuses on evaluating the stability and redundancy of filter
importance scores across multiple criteria. Differential Sensitivity Fusion
Pruning computes a differential sensitivity score for each filter by fusing the
discrepancies among gradient based sensitivity, first order Taylor expansion,
and KL divergence of activation distributions. An exponential scaling mechanism
is applied to emphasize filters with inconsistent importance across metrics,
identifying candidates that are structurally unstable or less critical to the
model performance. Unlike iterative or reinforcement learning based pruning
strategies, Differential Sensitivity Fusion Pruning is efficient and
deterministic, requiring only a single forward-backward pass for scoring and
pruning. Extensive experiments across varying pruning rates between 50 to 70
percent demonstrate that Differential Sensitivity Fusion Pruning significantly
reduces model complexity, achieving over 80 percent Floating point Operations
Per Seconds reduction while maintaining high accuracy. For instance, at 70
percent pruning, our approach retains up to 98.23 percent of baseline accuracy,
surpassing traditional heuristics in both compression and generalization. The
proposed method presents an effective solution for scalable and adaptive Deep
Convolutional Neural Networks compression, paving the way for efficient
deployment on edge and mobile platforms.

</details>


### [73] [Veriserum: A dual-plane fluoroscopic dataset with knee implant phantoms for deep learning in medical imaging](https://arxiv.org/abs/2509.05483)
*Jinhao Wang,Florian Vogl,Pascal Schütz,Saša Ćuković,William R. Taylor*

Main category: cs.CV

TL;DR: Veriserum是一个开源数据集，包含约11万张膝关节植入物的双平面X射线图像，用于支持深度学习配准、图像分割、X射线畸变校正和3D重建等应用，并提供自动和手动标注的姿态真值。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在支持双平面荧光透视分析的深度学习配准训练，推动计算机视觉和医学图像研究，并为算法开发和评估提供可复现的基准。

Method: Veriserum数据集包含约11万张X射线图像，涵盖10种膝关节植入物组合（2种股骨和5种胫骨植入物），在1600次试验中捕捉，包括日常活动（如平地步态和下坡）相关的姿态。每张图像都通过自动配准获得姿态真值，其中200张图像包含手动配准的姿态用于基准测试。数据集还包含双平面图像和校准工具。

Result: 创建并公开了一个名为Veriserum的开放数据集，该数据集具有大规模（约11万张图像）、多样性（10种膝关节植入物组合、日常活动姿态）、多模态（双平面X射线）和高质量标注（自动和手动配准姿态真值）的特点，并提供了校准工具。

Conclusion: Veriserum数据集为计算机视觉和医学图像研究提供了一个宝贵的资源和可复现的基准，特别是对于2D/3D图像配准、图像分割、X射线畸变校正和3D重建等应用，将有助于推动相关算法的开发和评估。

Abstract: Veriserum is an open-source dataset designed to support the training of deep
learning registration for dual-plane fluoroscopic analysis. It comprises
approximately 110,000 X-ray images of 10 knee implant pair combinations (2
femur and 5 tibia implants) captured during 1,600 trials, incorporating poses
associated with daily activities such as level gait and ramp descent. Each
image is annotated with an automatically registered ground-truth pose, while
200 images include manually registered poses for benchmarking.
  Key features of Veriserum include dual-plane images and calibration tools.
The dataset aims to support the development of applications such as 2D/3D image
registration, image segmentation, X-ray distortion correction, and 3D
reconstruction. Freely accessible, Veriserum aims to advance computer vision
and medical imaging research by providing a reproducible benchmark for
algorithm development and evaluation. The Veriserum dataset used in this study
is publicly available via
https://movement.ethz.ch/data-repository/veriserum.html, with the data stored
at ETH Z\"urich Research Collections: https://doi.org/10.3929/ethz-b-000701146.

</details>


### [74] [An Analysis of Layer-Freezing Strategies for Enhanced Transfer Learning in YOLO Architectures](https://arxiv.org/abs/2509.05490)
*Andrzej D. Dobrzycki,Ana M. Bernardos,José R. Casar*

Main category: cs.CV

TL;DR: 本研究深入分析了YOLOv8和YOLOv10模型在资源受限环境中，不同层冻结策略对迁移学习性能的影响，发现最优策略取决于数据特性，并提供了实用的指导方针。


<details>
  <summary>Details</summary>
Motivation: YOLO架构在实时目标检测中至关重要，但在无人机等资源受限环境中部署需要高效的迁移学习。尽管层冻结是常用技术，但其在YOLOv8和YOLOv10上的具体影响，特别是冻结深度、数据集特性和训练动态之间的相互作用，尚未得到充分探索。

Method: 研究系统地调查了YOLOv8和YOLOv10变体上的多种层冻结配置，使用了四个具有挑战性的关键基础设施监测数据集。方法整合了梯度行为分析（L2范数）和视觉解释（Grad-CAM），以深入了解不同冻结策略下的训练动态。

Result: 研究发现不存在通用的最优冻结策略，而是取决于数据特性。例如，冻结骨干网络有助于保留通用特征，而较浅的冻结更适用于处理极端类别不平衡。这些配置将GPU内存消耗减少了高达28%，在某些情况下，其mAP@50分数甚至超过了完全微调。梯度分析也证实了适度冻结模型的独特收敛模式。

Conclusion: 本工作提供了选择层冻结策略的实证发现和实用指南，为资源有限场景下的目标检测迁移学习提供了一种实用、基于证据的平衡方法。

Abstract: The You Only Look Once (YOLO) architecture is crucial for real-time object
detection. However, deploying it in resource-constrained environments such as
unmanned aerial vehicles (UAVs) requires efficient transfer learning. Although
layer freezing is a common technique, the specific impact of various freezing
configurations on contemporary YOLOv8 and YOLOv10 architectures remains
unexplored, particularly with regard to the interplay between freezing depth,
dataset characteristics, and training dynamics. This research addresses this
gap by presenting a detailed analysis of layer-freezing strategies. We
systematically investigate multiple freezing configurations across YOLOv8 and
YOLOv10 variants using four challenging datasets that represent critical
infrastructure monitoring. Our methodology integrates a gradient behavior
analysis (L2 norm) and visual explanations (Grad-CAM) to provide deeper
insights into training dynamics under different freezing strategies. Our
results reveal that there is no universal optimal freezing strategy but,
rather, one that depends on the properties of the data. For example, freezing
the backbone is effective for preserving general-purpose features, while a
shallower freeze is better suited to handling extreme class imbalance. These
configurations reduce graphics processing unit (GPU) memory consumption by up
to 28% compared to full fine-tuning and, in some cases, achieve mean average
precision (mAP@50) scores that surpass those of full fine-tuning. Gradient
analysis corroborates these findings, showing distinct convergence patterns for
moderately frozen models. Ultimately, this work provides empirical findings and
practical guidelines for selecting freezing strategies. It offers a practical,
evidence-based approach to balanced transfer learning for object detection in
scenarios with limited resources.

</details>


### [75] [Quaternion Approximation Networks for Enhanced Image Classification and Oriented Object Detection](https://arxiv.org/abs/2509.05512)
*Bryce Grant,Peng Wang*

Main category: cs.CV

TL;DR: 本文提出四元数近似网络（QUAN），通过实值操作近似四元数卷积，实现旋转等变图像分类和目标检测，性能优于现有模型且参数更少。


<details>
  <summary>Details</summary>
Motivation: 利用四元数代数实现旋转等变图像分类和目标检测，解决传统四元数神经网络操作复杂性和标准CNN处理旋转的局限性。

Method: 引入四元数近似网络（QUAN），通过哈密顿积分解使用实值操作近似四元数卷积，并利用自定义CUDA核实现高效计算。引入独立四元数批归一化（IQBN）以提高训练稳定性，并将四元数操作扩展到空间注意力机制。

Result: 在图像分类任务中，QUAN以更少的参数和更快的收敛速度实现了更高的准确性。在目标检测任务中，QUAN显示出比标准CNN更好的参数效率和旋转处理能力，并为该下游任务中的四元数CNN建立了最先进（SOTA）的性能。

Conclusion: QUAN在需要旋转感知感知的资源受限机器人系统和其他领域具有部署潜力，因其高效性和出色的旋转处理能力。

Abstract: This paper introduces Quaternion Approximate Networks (QUAN), a novel deep
learning framework that leverages quaternion algebra for rotation equivariant
image classification and object detection. Unlike conventional quaternion
neural networks attempting to operate entirely in the quaternion domain, QUAN
approximates quaternion convolution through Hamilton product decomposition
using real-valued operations. This approach preserves geometric properties
while enabling efficient implementation with custom CUDA kernels. We introduce
Independent Quaternion Batch Normalization (IQBN) for training stability and
extend quaternion operations to spatial attention mechanisms. QUAN is evaluated
on image classification (CIFAR-10/100, ImageNet), object detection (COCO,
DOTA), and robotic perception tasks. In classification tasks, QUAN achieves
higher accuracy with fewer parameters and faster convergence compared to
existing convolution and quaternion-based models. For objection detection, QUAN
demonstrates improved parameter efficiency and rotation handling over standard
Convolutional Neural Networks (CNNs) while establishing the SOTA for quaternion
CNNs in this downstream task. These results highlight its potential for
deployment in resource-constrained robotic systems requiring rotation-aware
perception and application in other domains.

</details>


### [76] [OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation](https://arxiv.org/abs/2509.05513)
*Ahad Jawaid,Yu Xiang*

Main category: cs.CV

TL;DR: OpenEgo是一个大规模的多模态第一视角操作数据集，统一了手部姿态标注并提供了意图对齐的动作原语，旨在降低从第一视角视频学习灵巧操作的门槛。


<details>
  <summary>Details</summary>
Motivation: 现有的第一视角人体视频数据集在细粒度、时间局部化的动作描述或灵巧手部标注方面存在不足，限制了其在模仿学习中的应用。

Method: OpenEgo整合了六个公共数据集，总计1107小时，涵盖290个操作任务。它统一了手部姿态布局，并提供了描述性、带时间戳的动作原语。通过训练语言条件模仿学习策略来预测灵巧手部轨迹，以验证其效用。

Result: OpenEgo包含1107小时的数据，覆盖600多个环境中的290个操作任务。它提供了标准化的手部姿态标注和意图对齐的动作原语。该数据集已成功用于训练语言条件模仿学习策略来预测灵巧手部轨迹。

Conclusion: OpenEgo旨在降低从第一视角视频学习灵巧操作的障碍，并支持视觉-语言-动作学习领域的可复现研究。所有资源和说明都将在指定网站发布。

Abstract: Egocentric human videos provide scalable demonstrations for imitation
learning, but existing corpora often lack either fine-grained, temporally
localized action descriptions or dexterous hand annotations. We introduce
OpenEgo, a multimodal egocentric manipulation dataset with standardized
hand-pose annotations and intention-aligned action primitives. OpenEgo totals
1107 hours across six public datasets, covering 290 manipulation tasks in 600+
environments. We unify hand-pose layouts and provide descriptive, timestamped
action primitives. To validate its utility, we train language-conditioned
imitation-learning policies to predict dexterous hand trajectories. OpenEgo is
designed to lower the barrier to learning dexterous manipulation from
egocentric video and to support reproducible research in vision-language-action
learning. All resources and instructions will be released at
www.openegocentric.com.

</details>


### [77] [Visibility-Aware Language Aggregation for Open-Vocabulary Segmentation in 3D Gaussian Splatting](https://arxiv.org/abs/2509.05515)
*Sen Wang,Kunyi Li,Siyun Liang,Elena Alegret,Jing Ma,Nassir Navab,Stefano Gasperini*

Main category: cs.CV

TL;DR: 本文提出了一种名为VALA的轻量级方法，用于改进将开放词汇语言特征蒸馏到3D高斯中的过程，通过解决背景高斯贡献不足和多视角不一致性问题，从而实现鲁棒、视角一致的语言特征嵌入，并提升了开放词汇定位和分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将开放词汇语言特征蒸馏到3D高斯时存在两个主要问题：1) 背景高斯对渲染像素的贡献微乎其微，却与前景高斯获得相同的特征；2) 语言嵌入中存在视角特异性噪声导致多视角不一致性。

Method: 本文提出了可见性感知语言聚合（VALA）方法。具体包括：1) 计算每条光线的边际贡献，并应用可见性感知门控机制以仅保留可见的高斯；2) 提出在余弦空间中进行流式加权几何中值计算，以融合噪声多视角特征。

Result: VALA能够以快速且内存高效的方式生成鲁棒、视角一致的语言特征嵌入。该方法显著改进了开放词汇定位和分割任务，在参考数据集上持续超越现有工作。

Conclusion: VALA通过有效解决背景高斯特征分配不当和多视角特征不一致问题，成功地提升了3D高斯中语言特征蒸馏的质量和实用性，为开放词汇的3D场景理解提供了更强的能力。

Abstract: Recently, distilling open-vocabulary language features from 2D images into 3D
Gaussians has attracted significant attention. Although existing methods
achieve impressive language-based interactions of 3D scenes, we observe two
fundamental issues: background Gaussians contributing negligibly to a rendered
pixel get the same feature as the dominant foreground ones, and multi-view
inconsistencies due to view-specific noise in language embeddings. We introduce
Visibility-Aware Language Aggregation (VALA), a lightweight yet effective
method that computes marginal contributions for each ray and applies a
visibility-aware gate to retain only visible Gaussians. Moreover, we propose a
streaming weighted geometric median in cosine space to merge noisy multi-view
features. Our method yields a robust, view-consistent language feature
embedding in a fast and memory-efficient manner. VALA improves open-vocabulary
localization and segmentation across reference datasets, consistently
surpassing existing works.

</details>


### [78] [DuoCLR: Dual-Surrogate Contrastive Learning for Skeleton-based Human Action Segmentation](https://arxiv.org/abs/2509.05543)
*Haitao Tian,Pierre Payeur*

Main category: cs.CV

TL;DR: 本文提出了一种名为DuoCLR的对比表示学习框架，通过使用修剪（单一动作）骨架序列进行预训练，以增强人体动作分割。该框架结合多尺度表示和跨序列变异，并引入了“Shuffle and Warp”数据增强策略以及两个代理任务（CPC和ROR），在多类别和多标签动作分割任务中显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 以往的表示学习方法主要针对动作识别，且基于孤立的序列级表示。然而，动作分割任务需要利用多尺度表示和跨序列变异来捕捉更丰富的上下文信息，因此需要一种新的框架来解决这一挑战。

Method: 本文提出了Dual-Surrogate Contrastive Learning (DuoCLR) 网络。其核心方法包括：1) 引入“Shuffle and Warp”数据增强策略，利用多样化的多动作排列；2) 设计两个代理任务：Cross Permutation Contrasting (CPC) 用于通过对比不同排列中相同动作类别的表示来学习类内相似性；Relative Order Reasoning (ROR) 通过预测两个排列之间的相对映射来推断类间上下文；3) 将这些任务整合到对比学习框架中，以学习针对动作分割优化的多尺度特征表示。

Result: DuoCLR在修剪过的骨架数据集上进行预训练，并在未修剪的数据集上进行评估。实验结果表明，在多类别和多标签动作分割任务中，DuoCLR相比最先进的对比方法取得了显著提升。此外，消融研究也证实了所提出方法中每个组件的有效性。

Conclusion: 所提出的DuoCLR对比表示学习框架，通过其独特的多尺度表示、跨序列变异利用、创新的“Shuffle and Warp”数据增强以及双代理任务（CPC和ROR），能够有效地学习用于动作分割的特征表示。这显著提高了人体动作分割的性能，超越了现有最先进的方法。

Abstract: In this paper, a contrastive representation learning framework is proposed to
enhance human action segmentation via pre-training using trimmed (single
action) skeleton sequences. Unlike previous representation learning works that
are tailored for action recognition and that build upon isolated sequence-wise
representations, the proposed framework focuses on exploiting multi-scale
representations in conjunction with cross-sequence variations. More
specifically, it proposes a novel data augmentation strategy, 'Shuffle and
Warp', which exploits diverse multi-action permutations. The latter effectively
assists two surrogate tasks that are introduced in contrastive learning: Cross
Permutation Contrasting (CPC) and Relative Order Reasoning (ROR). In
optimization, CPC learns intra-class similarities by contrasting
representations of the same action class across different permutations, while
ROR reasons about inter-class contexts by predicting relative mapping between
two permutations. Together, these tasks enable a Dual-Surrogate Contrastive
Learning (DuoCLR) network to learn multi-scale feature representations
optimized for action segmentation. In experiments, DuoCLR is pre-trained on a
trimmed skeleton dataset and evaluated on an untrimmed dataset where it
demonstrates a significant boost over state-the-art comparatives in both
multi-class and multi-label action segmentation tasks. Lastly, ablation studies
are conducted to evaluate the effectiveness of each component of the proposed
approach.

</details>


### [79] [RED: Robust Event-Guided Motion Deblurring with Modality-Specific Disentangled Representation](https://arxiv.org/abs/2509.05554)
*Yihong Leng,Siming Zheng,Jinwei Chen,Bo Li,Jiaojiao Li,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种名为RED的鲁棒事件引导去模糊网络，通过解耦表示和新颖的扰动策略，有效解决了事件流固有的不完整性问题，显著提升了去模糊的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 事件相机提供高时间分辨率的稀疏运动信息，在运动去模糊方面潜力巨大。然而，现有的方法忽略了事件流固有的不完整性，这源于动态视觉传感器（DVS）阈值机制在灵敏度和噪声之间的权衡。这种退化损害了运动先验的完整性，限制了事件引导去模糊的有效性。

Method: 本文提出了一个具有模态特定解耦表示的鲁棒事件引导去模糊（RED）网络。首先，引入了面向鲁棒性的扰动策略（RPS），通过对事件应用随机遮蔽，使RED暴露于不完整的模式，从而增强对未知场景条件的鲁棒性。其次，提出了一个解耦的全向注意力（OmniAttention）模块，用于明确建模模糊图像和部分中断事件中固有的内部运动、间运动和跨模态相关性。在此基础上，设计了两个交互模块，分别用于增强模糊图像中的运动敏感区域，并向不完整的事件表示注入语义上下文。

Result: 在合成和真实世界数据集上进行的广泛实验表明，RED在准确性和鲁棒性方面均持续达到了最先进的性能。

Conclusion: RED网络通过创新的扰动策略和解耦的注意力机制，成功解决了事件流不完整性对运动去模糊的限制，实现了卓越的去模糊效果和鲁棒性。

Abstract: Event cameras provide sparse yet temporally high-temporal-resolution motion
information, demonstrating great potential for motion deblurring. Existing
methods focus on cross-modal interaction, overlooking the inherent
incompleteness of event streams, which arises from the trade-off between
sensitivity and noise introduced by the thresholding mechanism of Dynamic
Vision Sensors (DVS). Such degradation compromises the integrity of motion
priors and limits the effectiveness of event-guided deblurring. To tackle these
challenges, we propose a Robust Event-guided Deblurring (RED) network with
modality-specific disentangled representation. First, we introduce a
Robustness-Oriented Perturbation Strategy (RPS) that applies random masking to
events, which exposes RED to incomplete patterns and then foster robustness
against various unknown scenario conditions.Next, a disentangled OmniAttention
is presented to explicitly model intra-motion, inter-motion, and cross-modality
correlations from two inherently distinct but complementary sources: blurry
images and partially disrupted events. Building on these reliable features, two
interactive modules are designed to enhance motion-sensitive areas in blurry
images and inject semantic context into incomplete event representations.
Extensive experiments on synthetic and real-world datasets demonstrate RED
consistently achieves state-of-the-art performance in both accuracy and
robustness.

</details>


### [80] [Sensitivity-Aware Post-Training Quantization for Deep Neural Networks](https://arxiv.org/abs/2509.05576)
*Zekang Zheng,Haokun Li,Yaofo Chen,Mingkui Tan,Qing Du*

Main category: cs.CV

TL;DR: 本文提出了一种高效的后训练量化（PTQ）方法，通过参数敏感度分析指导量化过程，并结合行并行量化框架和共享逆Hessian矩阵更新机制，显著提高了量化速度，同时保持了高精度。


<details>
  <summary>Details</summary>
Motivation: 现有的PTQ方法在实现高压缩比时，通常需要迭代参数更新，导致计算复杂度和资源开销巨大，限制了其在资源受限的边缘计算和实时推理场景中的应用。

Method: 该方法首先通过参数敏感度分析，优先量化高敏感度参数，并利用未量化的低敏感度参数补偿量化误差，以减轻精度下降。此外，通过利用参数敏感度的列式聚类，引入了一个行并行量化框架，并采用全局共享的逆Hessian矩阵更新机制，从而将计算复杂度降低了一个数量级。

Result: 在ResNet-50和YOLOv5s上的实验结果表明，与Optimal Brain Quantization基线相比，量化速度提高了20-200倍，平均精度损失低于0.3%。

Conclusion: 该方法在效率和精度之间取得了有效平衡，验证了其在加速量化过程同时保持模型性能的有效性。

Abstract: Model quantization reduces neural network parameter precision to achieve
compression, but often compromises accuracy. Existing post-training
quantization (PTQ) methods employ iterative parameter updates to preserve
accuracy under high compression ratios, incurring significant computational
complexity and resource overhead, which limits applicability in
resource-constrained edge computing and real-time inference scenarios. This
paper proposes an efficient PTQ method guided by parameter sensitivity
analysis. The approach prioritizes quantization of high-sensitivity parameters,
leveraging unquantized low-sensitivity parameters to compensate for
quantization errors, thereby mitigating accuracy degradation. Furthermore, by
exploiting column-wise clustering of parameter sensitivity, the method
introduces a row-parallel quantization framework with a globally shared inverse
Hessian matrix update mechanism, reducing computational complexity by an order
of magnitude. Experimental results on ResNet-50 and YOLOv5s demonstrate a
20-200-fold quantization speedup over the Optimal Brain Quantization baseline,
with mean accuracy loss below 0.3%, confirming the method's efficacy in
balancing efficiency and accuracy.

</details>


### [81] [Reconstruction and Reenactment Separated Method for Realistic Gaussian Head](https://arxiv.org/abs/2509.05582)
*Zhiling Ye,Cong Zhou,Xiubao Zhang,Haifeng Shen,Weihong Deng,Quan Lu*

Main category: cs.CV

TL;DR: 本文提出一个分离的3D高斯头重建与重演框架，仅需单张肖像图即可生成可控的3D头像，实现高帧率渲染并超越现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 从单张肖像图像生成可控的3D头像，同时解决泛化能力和高频纹理重建的挑战。

Method: 采用重建与重演分离的框架；开发基于WebSSL的大规模一次性高斯头生成器；使用两阶段训练方法；推理时利用超轻量级高斯头像由控制信号驱动。

Result: 实现512x512分辨率下90 FPS的高帧率渲染；框架遵循缩放定律，增加重建模块参数可提升性能，且驱动效率不受影响；量化和定性实验表明该方法优于当前最先进的方法。

Conclusion: 所提出的分离框架能有效从单张图像重建和重演3D高斯头，具有出色的泛化、高频纹理重建能力、高渲染效率和可扩展性，并显著优于现有技术。

Abstract: In this paper, we explore a reconstruction and reenactment separated
framework for 3D Gaussians head, which requires only a single portrait image as
input to generate controllable avatar. Specifically, we developed a large-scale
one-shot gaussian head generator built upon WebSSL and employed a two-stage
training approach that significantly enhances the capabilities of
generalization and high-frequency texture reconstruction. During inference, an
ultra-lightweight gaussian avatar driven by control signals enables high
frame-rate rendering, achieving 90 FPS at a resolution of 512x512. We further
demonstrate that the proposed framework follows the scaling law, whereby
increasing the parameter scale of the reconstruction module leads to improved
performance. Moreover, thanks to the separation design, driving efficiency
remains unaffected. Finally, extensive quantitative and qualitative experiments
validate that our approach outperforms current state-of-the-art methods.

</details>


### [82] [MFFI: Multi-Dimensional Face Forgery Image Dataset for Real-World Scenarios](https://arxiv.org/abs/2509.05592)
*Changtao Miao,Yi Zhang,Man Luo,Weiwei Feng,Kaiyuan Zheng,Qi Chu,Tao Gong,Jianshu Li,Yunfeng Diao,Wei Zhou,Joey Tianyi Zhou,Xiaoshuai Hao*

Main category: cs.CV

TL;DR: 本文提出了MFFI数据集，旨在通过涵盖更多伪造方法、多样面部场景、真实数据和多级降级操作，解决现有深度伪造检测数据集中真实世界多样性不足的问题。


<details>
  <summary>Details</summary>
Motivation: AIGC技术快速发展，导致面部伪造日益复杂，对社会安全构成重大威胁。然而，现有的深度伪造检测方法受限于数据集，这些数据集在未知高级伪造技术、面部场景多样性、真实数据丰富性和真实世界传播退化方面存在不足，无法模拟真实世界场景。

Method: 为了应对挑战，作者提出了多维度面部伪造图像（MFFI）数据集。MFFI通过四个战略维度增强真实性：1) 更广泛的伪造方法；2) 多样的面部场景；3) 多样化的真实数据；4) 多级降级操作。MFFI集成了50种不同的伪造方法，包含1024K图像样本。

Result: 基准评估表明，MFFI在场景复杂性、跨域泛化能力和检测难度梯度方面优于现有公共数据集。

Conclusion: 这些结果验证了MFFI在模拟真实世界条件方面的技术进步和实用性，为深度伪造检测提供了更真实、更具挑战性的数据集。

Abstract: Rapid advances in Artificial Intelligence Generated Content (AIGC) have
enabled increasingly sophisticated face forgeries, posing a significant threat
to social security. However, current Deepfake detection methods are limited by
constraints in existing datasets, which lack the diversity necessary in
real-world scenarios. Specifically, these data sets fall short in four key
areas: unknown of advanced forgery techniques, variability of facial scenes,
richness of real data, and degradation of real-world propagation. To address
these challenges, we propose the Multi-dimensional Face Forgery Image
(\textbf{MFFI}) dataset, tailored for real-world scenarios. MFFI enhances
realism based on four strategic dimensions: 1) Wider Forgery Methods; 2) Varied
Facial Scenes; 3) Diversified Authentic Data; 4) Multi-level Degradation
Operations. MFFI integrates $50$ different forgery methods and contains $1024K$
image samples. Benchmark evaluations show that MFFI outperforms existing public
datasets in terms of scene complexity, cross-domain generalization capability,
and detection difficulty gradients. These results validate the technical
advance and practical utility of MFFI in simulating real-world conditions. The
dataset and additional details are publicly available at
{https://github.com/inclusionConf/MFFI}.

</details>


### [83] [Language-guided Recursive Spatiotemporal Graph Modeling for Video Summarization](https://arxiv.org/abs/2509.05604)
*Jungin Park,Jiyoung Lee,Kwanghoon Sohn*

Main category: cs.CV

TL;DR: 本文提出了一种名为VideoGraph的递归时空图网络，将视频摘要视为语言引导的时空图建模问题。它将对象和帧表示为图节点，并利用语言查询来建立语义关系，从而在通用和查询聚焦的视频摘要任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 以往的视频摘要方法侧重于全局时间建模，但忽视了细粒度视觉实体（如对象）与视频内容的关联。此外，语言引导的视频摘要需要对复杂视频进行全面的语言理解。因此，研究人员希望解决如何将所有对象语义关联起来的问题。

Method: 本文提出VideoGraph，一个递归时空图网络。它将对象和帧分别建模为空间图和时间图的节点。图中的节点通过表示语义关系的边进行连接和聚合。为了避免边仅基于视觉相似性配置，研究人员将从视频中提取的语言查询融入到图节点表示中，使其包含语义知识。此外，还采用递归策略来细化初始图并正确分类关键帧。

Result: 实验结果表明，VideoGraph在多个通用和查询聚焦的视频摘要基准测试中，无论是在有监督还是无监督方式下，都达到了最先进的性能。

Conclusion: VideoGraph通过将视频摘要建模为语言引导的时空图问题，并利用递归图网络和语言查询来捕捉对象和帧之间的语义关系，有效解决了视频摘要任务中的挑战，并取得了卓越的成果。

Abstract: Video summarization aims to select keyframes that are visually diverse and
can represent the whole story of a given video. Previous approaches have
focused on global interlinkability between frames in a video by temporal
modeling. However, fine-grained visual entities, such as objects, are also
highly related to the main content of the video. Moreover, language-guided
video summarization, which has recently been studied, requires a comprehensive
linguistic understanding of complex real-world videos. To consider how all the
objects are semantically related to each other, this paper regards video
summarization as a language-guided spatiotemporal graph modeling problem. We
present recursive spatiotemporal graph networks, called VideoGraph, which
formulate the objects and frames as nodes of the spatial and temporal graphs,
respectively. The nodes in each graph are connected and aggregated with graph
edges, representing the semantic relationships between the nodes. To prevent
the edges from being configured with visual similarity, we incorporate language
queries derived from the video into the graph node representations, enabling
them to contain semantic knowledge. In addition, we adopt a recursive strategy
to refine initial graphs and correctly classify each frame node as a keyframe.
In our experiments, VideoGraph achieves state-of-the-art performance on several
benchmarks for generic and query-focused video summarization in both supervised
and unsupervised manners. The code is available at
https://github.com/park-jungin/videograph.

</details>


### [84] [Patch-level Kernel Alignment for Self-Supervised Dense Representation Learning](https://arxiv.org/abs/2509.05606)
*Juan Yeo,Ijun Jang,Taesup Kim*

Main category: cs.CV

TL;DR: 该论文提出了一种通过自监督学习，将预训练模型中的语义知识迁移到密集特征空间的方法，以提高密集视觉任务的表示能力，并引入了Patch-level Kernel Alignment (PaKA) 目标。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督表示学习方法大多侧重于全局表示，难以捕获密集预测任务所需的局部语义和精细细节，这限制了它们在需要空间精度和细粒度信息的密集视觉任务中的应用。

Method: 提出一个框架，通过额外的自监督学习，在预训练表示的基础上，将现有语义知识转移到密集特征空间。具体方法包括：对教师模型和学生模型之间的密集特征分布进行对齐，并引入了“Patch-level Kernel Alignment (PaKA)”这一简单有效的对齐目标，以捕获统计依赖性，从而匹配两个模型中密集补丁的结构关系。此外，还研究了专门为密集表示学习设计的增强策略。

Result: 该框架在各种密集视觉基准测试中取得了最先进的成果。

Conclusion: 所提出的方法在密集表示学习方面表现出卓越的有效性，成功克服了现有方法在捕获局部语义方面的局限性。

Abstract: Dense representations are essential for vision tasks that require spatial
precision and fine-grained detail. While most self-supervised representation
learning methods focus on global representations that summarize the image as a
whole, such approaches often fall short in capturing the localized semantics
necessary for dense prediction tasks. To overcome these limitations, we propose
a framework that builds on pretrained representations through additional
self-supervised learning, aiming to transfer existing semantic knowledge into
the dense feature space. Our method aligns the distributions of dense features
between a teacher and a student model. Specifically, we introduce Patch-level
Kernel Alignment (PaKA), a simple yet effective alignment objective that
captures statistical dependencies, thereby matching the structural
relationships of dense patches across the two models. In addition, we
investigate augmentation strategies specifically designed for dense
representation learning. Our framework achieves state-of-the-art results across
a variety of dense vision benchmarks, demonstrating the effectiveness of our
approach.

</details>


### [85] [SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning](https://arxiv.org/abs/2509.05614)
*Hanzhen Wang,Jiaming Xu,Jiayi Pan,Yongkang Zhou,Guohao Dai*

Main category: cs.CV

TL;DR: SpecPrune-VLA是一种无需训练的VLA模型剪枝方法，通过结合局部和全局动作信息，实现了显著的速度提升，同时保持了接近的成功率，解决了现有方法性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型剪枝方法仅利用当前动作的局部信息，导致成功率大幅下降（超过20%）且加速有限。研究者观察到连续动作间存在高度相似性，因此提出利用局部和全局上下文信息进行更智能的token选择。

Method: 本文提出了SpecPrune-VLA，一种无需训练的方法，包含两级剪枝和启发式控制：(1) 动作层面的静态剪枝：利用全局历史和局部上下文减少每个动作的视觉tokens；(2) 层级动态剪枝：根据每层的重要性修剪tokens；(3) 轻量级动作感知控制器：根据动作类型（粗粒度/细粒度）调整剪枝强度，因为细粒度动作对剪枝更敏感。

Result: 在LIBERO数据集上，SpecPrune-VLA在NVIDIA A800上实现了1.46倍加速，在NVIDIA GeForce RTX 3090上实现了1.57倍加速（对比OpenVLA-OFT），且成功率损失可忽略不计。

Conclusion: SpecPrune-VLA通过结合局部和全局上下文信息进行智能token剪枝，有效加速了VLA模型，实现了显著的速度提升，同时几乎不影响性能，解决了现有剪枝方法的局限性。

Abstract: Pruning accelerates compute-bound models by reducing computation. Recently
applied to Vision-Language-Action (VLA) models, existing methods prune tokens
using only local info from current action, ignoring global context from prior
actions, causing >20% success rate drop and limited speedup. We observe high
similarity across consecutive actions and propose leveraging both local
(current) and global (past) info for smarter token selection. We introduce
SpecPrune-VLA, a training-free method with two-level pruning and heuristic
control: (1) Static pruning at action level: uses global history and local
context to reduce visual tokens per action; (2) Dynamic pruning at layer level:
prunes tokens per layer based on layer-specific importance; (3) Lightweight
action-aware controller: classifies actions as coarse/fine-grained (by speed),
adjusting pruning aggressiveness since fine-grained actions are
pruning-sensitive. Experiments on LIBERO show SpecPrune-VLA achieves 1.46 times
speedup on NVIDIA A800 and 1.57 times on NVIDIA GeForce RTX 3090 vs.
OpenVLA-OFT, with negligible success rate loss.

</details>


### [86] [SuMa: A Subspace Mapping Approach for Robust and Effective Concept Erasure in Text-to-Image Diffusion Models](https://arxiv.org/abs/2509.05625)
*Kien Nguyen,Anh Tran,Cuong Pham*

Main category: cs.CV

TL;DR: 针对文生图模型中狭窄概念（如版权角色、名人）的擦除挑战，本文提出了一种名为Subspace Mapping (SuMa) 的新方法，旨在同时实现擦除的鲁棒性和图像质量的有效性。


<details>
  <summary>Details</summary>
Motivation: 文生图扩散模型可能生成有害或未经授权的内容，引发担忧。现有概念擦除方法通常难以兼顾鲁棒性（彻底移除目标概念）和有效性（保持图像质量），尤其是在处理版权角色或名人等“狭窄概念”时，由于其与非目标概念的距离较近，擦除难度更大，这对于解决版权和法律问题至关重要。

Method: 本文提出了Subspace Mapping (SuMa) 方法。该方法首先推导出代表待擦除概念的“目标子空间”，然后通过将其映射到一个“参考子空间”来中和它，从而最小化两者之间的距离。这种子空间映射确保了目标概念被鲁棒地擦除，同时有效保持了图像质量。

Result: SuMa在子类擦除、名人擦除、艺术风格擦除和实例擦除四项任务中进行了广泛实验，并与当前最先进的方法进行了比较。结果表明，SuMa在图像质量方面与专注于有效性的方法相当，同时在擦除的彻底性方面也与专注于完整性的方法不分伯仲。

Conclusion: SuMa是一种新颖且有效的方法，能够同时实现对文生图模型中狭窄概念的鲁棒擦除和图像质量的有效保持，解决了现有方法在处理此类概念时难以兼顾这两大目标的问题，对于解决版权和法律合规性问题具有重要意义。

Abstract: The rapid growth of text-to-image diffusion models has raised concerns about
their potential misuse in generating harmful or unauthorized contents. To
address these issues, several Concept Erasure methods have been proposed.
However, most of them fail to achieve both robustness, i.e., the ability to
robustly remove the target concept., and effectiveness, i.e., maintaining image
quality. While few recent techniques successfully achieve these goals for NSFW
concepts, none could handle narrow concepts such as copyrighted characters or
celebrities. Erasing these narrow concepts is critical in addressing copyright
and legal concerns. However, erasing them is challenging due to their close
distances to non-target neighboring concepts, requiring finer-grained
manipulation. In this paper, we introduce Subspace Mapping (SuMa), a novel
method specifically designed to achieve both robustness and effectiveness in
easing these narrow concepts. SuMa first derives a target subspace representing
the concept to be erased and then neutralizes it by mapping it to a reference
subspace that minimizes the distance between the two. This mapping ensures the
target concept is robustly erased while preserving image quality. We conduct
extensive experiments with SuMa across four tasks: subclass erasure, celebrity
erasure, artistic style erasure, and instance erasure and compare the results
with current state-of-the-art methods. Our method achieves image quality
comparable to approaches focused on effectiveness, while also yielding results
that are on par with methods targeting completeness.

</details>


### [87] [Self-supervised Learning for Hyperspectral Images of Trees](https://arxiv.org/abs/2509.05630)
*Moqsadur Rahman,Saurav Kumar,Santosh S. Palmate,M. Shahriar Hossain*

Main category: cs.CV

TL;DR: 本文提出了一种自监督学习方法，通过航空高光谱图像创建反映树木植被特性的神经网络嵌入，该方法在下游机器学习任务中表现优于直接使用高光谱植被特性。


<details>
  <summary>Details</summary>
Motivation: 航空多光谱和RGB成像推动了精准农业发展，但有限或无标签的高光谱图像分析极具挑战性。

Method: 采用自监督学习方法，利用航空高光谱图像生成神经网络嵌入，以反映树木的植被特性。通过构建一个与植被特性相关的嵌入空间来表示树木。

Result: 实验结果表明，与直接使用高光谱植被特性作为树木表示相比，使用构建的植被特性相关嵌入空间表示树木在下游机器学习任务中表现更佳。

Conclusion: 自监督学习能够有效创建反映树木植被特性的嵌入表示，从而提升航空高光谱图像在精准农业下游任务中的应用效果。

Abstract: Aerial remote sensing using multispectral and RGB imagers has provided a
critical impetus to precision agriculture. Analysis of the hyperspectral images
with limited or no labels is challenging. This paper focuses on self-supervised
learning to create neural network embeddings reflecting vegetation properties
of trees from aerial hyperspectral images of crop fields. Experimental results
demonstrate that a constructed tree representation, using a vegetation
property-related embedding space, performs better in downstream machine
learning tasks compared to the direct use of hyperspectral vegetation
properties as tree representations.

</details>


### [88] [Evaluating YOLO Architectures: Implications for Real-Time Vehicle Detection in Urban Environments of Bangladesh](https://arxiv.org/abs/2509.05652)
*Ha Meem Hossain,Pritam Nath,Mahitun Nesa Mahi,Imtiaz Uddin,Ishrat Jahan Eiste,Syed Nasibur Rahman Ratul,Md Naim Uddin Mozumdar,Asif Mohammed Saad*

Main category: cs.CV

TL;DR: 本研究评估了六种YOLO模型变体在孟加拉国定制车辆数据集上的表现，旨在解决现有模型在当地独特交通环境中识别不足的问题。YOLOv11x表现最佳，但YOLOv8m和YOLOv11m在性能和推理时间之间取得了最佳平衡，同时指出了稀有车辆和视觉相似车辆的检测挑战。


<details>
  <summary>Details</summary>
Motivation: 在非孟加拉国数据集上训练的车辆检测系统难以准确识别孟加拉国独特的道路环境中的本地车辆类型，这给发展中地区的自动驾驶技术带来了关键空白。

Method: 本研究在一个包含29种独特车辆类别（包括“Desi Nosimon”、“Leguna”、“Battery Rickshaw”和“CNG”等区域特定车辆）的定制数据集上评估了六种YOLO模型变体。该数据集包含使用手机摄像头在孟加拉国各地道路上捕获的高分辨率图像（1920x1080），并使用LabelImg手动标注为YOLO格式的边界框。

Result: 性能评估显示，YOLOv11x表现最佳，mAP@0.5达到63.7%，mAP@0.5:0.95达到43.8%，召回率为61.4%，F1-score为61.6%，但每张图像推理时间为45.8毫秒。中等变体（YOLOv8m、YOLOv11m）实现了最佳平衡，mAP@0.5分别为62.5%和61.8%，推理时间保持在14-15毫秒左右。研究发现，由于数据集不平衡和训练样本不足，稀有车辆类别（如工程车辆和Desi Nosimons）的检测精度接近零。混淆矩阵显示，视觉相似的车辆（特别是小型卡车与小型厢式货车）之间存在频繁的误分类。

Conclusion: 本研究为开发专门适应孟加拉国交通条件的鲁棒目标检测系统奠定了基础，解决了发展中地区自动驾驶技术进步中的关键需求，因为传统通用训练模型在这些地区表现不佳。

Abstract: Vehicle detection systems trained on Non-Bangladeshi datasets struggle to
accurately identify local vehicle types in Bangladesh's unique road
environments, creating critical gaps in autonomous driving technology for
developing regions. This study evaluates six YOLO model variants on a custom
dataset featuring 29 distinct vehicle classes, including region-specific
vehicles such as ``Desi Nosimon'', ``Leguna'', ``Battery Rickshaw'', and
``CNG''. The dataset comprises high-resolution images (1920x1080) captured
across various Bangladeshi roads using mobile phone cameras and manually
annotated using LabelImg with YOLO format bounding boxes. Performance
evaluation revealed YOLOv11x as the top performer, achieving 63.7\% mAP@0.5,
43.8\% mAP@0.5:0.95, 61.4\% recall, and 61.6\% F1-score, though requiring 45.8
milliseconds per image for inference. Medium variants (YOLOv8m, YOLOv11m)
struck an optimal balance, delivering robust detection performance with mAP@0.5
values of 62.5\% and 61.8\% respectively, while maintaining moderate inference
times around 14-15 milliseconds. The study identified significant detection
challenges for rare vehicle classes, with Construction Vehicles and Desi
Nosimons showing near-zero accuracy due to dataset imbalances and insufficient
training samples. Confusion matrices revealed frequent misclassifications
between visually similar vehicles, particularly Mini Trucks versus Mini Covered
Vans. This research provides a foundation for developing robust object
detection systems specifically adapted to Bangladesh traffic conditions,
addressing critical needs in autonomous vehicle technology advancement for
developing regions where conventional generic-trained models fail to perform
adequately.

</details>


### [89] [EditIDv2: Editable ID Customization with Data-Lubricated ID Feature Integration for Text-to-Image Generation](https://arxiv.org/abs/2509.05659)
*Guandong Li,Zhaobin Chu*

Main category: cs.CV

TL;DR: EditIDv2 是一种免调优的解决方案，专为高复杂性叙事场景和长文本输入设计，旨在通过深度语义编辑同时保持角色身份一致性。


<details>
  <summary>Details</summary>
Motivation: 现有角色编辑方法在简单提示下表现良好，但在面对包含多语义层、时间逻辑和复杂上下文关系的长文本叙事时，编辑能力下降，出现语义理解偏差和身份一致性崩溃的问题。

Method: EditIDv2 通过深入探索ID特征集成模块的影响，分解 PerceiverAttention，引入ID损失，与扩散模型进行联合动态训练，并采用集成模块的离线融合策略，仅用少量数据即可实现。

Result: 该方法在复杂叙事环境中实现了深度、多层次的语义编辑，同时保持了身份一致性，满足了长提示和高质量图像生成的需求，并在IBench评估中取得了优异结果。

Conclusion: EditIDv2 提供了一种免调优、高效的解决方案，成功解决了复杂叙事场景下角色编辑的挑战，实现了在保持身份一致性的同时进行深度语义编辑。

Abstract: We propose EditIDv2, a tuning-free solution specifically designed for
high-complexity narrative scenes and long text inputs. Existing character
editing methods perform well under simple prompts, but often suffer from
degraded editing capabilities, semantic understanding biases, and identity
consistency breakdowns when faced with long text narratives containing multiple
semantic layers, temporal logic, and complex contextual relationships. In
EditID, we analyzed the impact of the ID integration module on editability. In
EditIDv2, we further explore and address the influence of the ID feature
integration module. The core of EditIDv2 is to discuss the issue of editability
injection under minimal data lubrication. Through a sophisticated decomposition
of PerceiverAttention, the introduction of ID loss and joint dynamic training
with the diffusion model, as well as an offline fusion strategy for the
integration module, we achieve deep, multi-level semantic editing while
maintaining identity consistency in complex narrative environments using only a
small amount of data lubrication. This meets the demands of long prompts and
high-quality image generation, and achieves excellent results in the IBench
evaluation.

</details>


### [90] [OOTSM: A Decoupled Linguistic Framework for Effective Scene Graph Anticipation](https://arxiv.org/abs/2509.05661)
*Xiaomeng Zhu,Changwei Wang,Haozhe Wang,Xinyu Liu,Fangzhen Lin*

Main category: cs.CV

TL;DR: 该研究提出了一种名为OOTSM的纯文本方法，利用大型语言模型（LLM）预测未来场景图，通过解耦对象变化和关系生成，显著提升了场景图预测的长期准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的场景图预测（SGA）方法主要依赖视觉线索，难以有效整合常识知识，导致长期预测的鲁棒性不足。

Method: 本研究将SGA任务解耦为两步：首先将视频转换为场景图序列，然后使用纯文本模型预测未来场景图（称为语言场景图预测，LSGA）。针对LSGA，提出了一种面向对象的两阶段方法（OOTSM），其中大型语言模型（LLM）首先预测对象的出现和消失，然后再生成详细的人-物关系。该方法在LSGA和SGA两种设置下进行了评估。

Result: 在LSGA方面，将微调的开源LLM与零样本API（如GPT-4o）在Action Genome构建的基准上进行了评估。在SGA方面，将OOTSM与STTran++结合，实验结果显示了最先进的性能：短期平均召回率（@10）提高了3.4%，长期平均召回率（@50）显著提高了21.9%。

Conclusion: 该研究提出的OOTSM方法通过有效利用LLM中的常识知识，显著提升了场景图预测的性能，特别是在长期预测方面取得了显著的改进，证明了纯文本模型在场景图预测中的潜力。

Abstract: A scene graph is a structured represention of objects and their relationships
in a scene. Scene Graph Anticipation (SGA) involves predicting future scene
graphs from video clips, enabling applications as intelligent surveillance and
human-machine collaboration. Existing SGA approaches primarily leverage visual
cues, often struggling to integrate valuable commonsense knowledge, thereby
limiting long-term prediction robustness. To explicitly leverage such
commonsense knowledge, we propose a new approach to better understand the
objects, concepts, and relationships in a scene graph. Our approach decouples
the SGA task in two steps: first a scene graph capturing model is used to
convert a video clip into a sequence of scene graphs, then a pure text-based
model is used to predict scene graphs in future frames. Our focus in this work
is on the second step, and we call it Linguistic Scene Graph Anticipation
(LSGA) and believes it should have independent interest beyond the use in SGA
discussed here. For LSGA, we introduce an Object-Oriented Two-Staged Method
(OOTSM) where an Large Language Model (LLM) first forecasts object appearances
and disappearances before generating detailed human-object relations. We
conduct extensive experiments to evaluate OOTSM in two settings. For LSGA, we
evaluate our fine-tuned open-sourced LLMs against zero-shot APIs (i.e., GPT-4o,
GPT-4o-mini, and DeepSeek-V3) on a benchmark constructed from Action Genome
annotations. For SGA, we combine our OOTSM with STTran++ from, and our
experiments demonstrate effective state-of-the-art performance: short-term
mean-Recall (@10) increases by 3.4% while long-term mean-Recall (@50) improves
dramatically by 21.9%. Code is available at https://github.com/ZhuXMMM/OOTSM.

</details>


### [91] [WIPUNet: A Physics-inspired Network with Weighted Inductive Biases for Image Denoising](https://arxiv.org/abs/2509.05662)
*Wasikul Islam*

Main category: cs.CV

TL;DR: 本文探索了将高能物理中“堆积效应”的缓解原理（如守恒、局部性、隔离性）作为物理引导的归纳偏置嵌入到神经网络中，以提升图像去噪模型在强噪声下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 高能粒子物理中的对撞机测量受到“堆积效应”的污染，需要专门的减法策略来利用物理先验。受此启发，研究者想探究这些物理原理如何通过将物理引导的归纳偏置嵌入神经网络架构来指导图像去噪，特别是在强腐蚀下的鲁棒性。

Method: 引入了一系列受堆积效应启发的去噪器：一个带有守恒约束的残差CNN，其高斯噪声变体，以及将这些思想整合到UNet骨干网络中的WIPUNet（Weighted Inductive Pileup-physics-inspired U-Network for Denoising）。在CIFAR-10和BSD500数据集上，使用不同强度的高斯噪声进行测试。

Result: 在CIFAR-10数据集上，受堆积效应启发的CNN与标准基线模型相比具有竞争力；WIPUNet在较高噪声水平下显示出“不断扩大的优势”。BSD500实验也显示出相同的趋势，表明物理启发的先验在纯数据驱动模型性能下降时提供了稳定性。

Conclusion: 物理启发的先验在图像去噪中，尤其是在高噪声条件下，能够提供稳定性，并提高了模型的鲁棒性，而无需依赖复杂的SOTA技术。这证明了将堆积效应缓解原理转化为模块化归纳偏置并整合到UNet中的有效性。

Abstract: In high-energy particle physics, collider measurements are contaminated by
"pileup", overlapping soft interactions that obscure the hard-scatter signal of
interest. Dedicated subtraction strategies exploit physical priors such as
conservation, locality, and isolation. Inspired by this analogy, we investigate
how such principles can inform image denoising by embedding physics-guided
inductive biases into neural architectures. This paper is a proof of concept:
rather than targeting state-of-the-art (SOTA) benchmarks, we ask whether
physics-inspired priors improve robustness under strong corruption.
  We introduce a hierarchy of PU-inspired denoisers: a residual CNN with
conservation constraints, its Gaussian-noise variants, and the Weighted
Inductive Pileup-physics-inspired U-Network for Denoising (WIPUNet), which
integrates these ideas into a UNet backbone. On CIFAR-10 with Gaussian noise at
$\sigma\in\{15,25,50,75,100\}$, PU-inspired CNNs are competitive with standard
baselines, while WIPUNet shows a \emph{widening margin} at higher noise.
Complementary BSD500 experiments show the same trend, suggesting
physics-inspired priors provide stability where purely data-driven models
degrade. Our contributions are: (i) translating pileup-mitigation principles
into modular inductive biases; (ii) integrating them into UNet; and (iii)
demonstrating robustness gains at high noise without relying on heavy SOTA
machinery.

</details>


### [92] [Context-Aware Multi-Turn Visual-Textual Reasoning in LVLMs via Dynamic Memory and Adaptive Visual Guidance](https://arxiv.org/abs/2509.05669)
*Weijie Shen,Xinrui Wang,Yuanqi Nie,Apiradee Boonmee*

Main category: cs.CV

TL;DR: 本文提出了一种名为CAMVR（Context-Aware Multi-Turn Visual Reasoning）的新框架，旨在解决现有大语言模型和视觉-语言大模型在多轮交互中存在的上下文丢失、碎片化推理和幻觉问题。CAMVR通过引入视觉-文本上下文记忆单元（VCMU）和自适应视觉焦点引导（AVFG）机制，显著提升了模型在复杂多轮视觉推理任务中的表现，并达到了最先进的水平。


<details>
  <summary>Details</summary>
Motivation: 当前的LLMs和LVLMs在单轮任务中表现出色，但在需要深度上下文理解和复杂视觉推理的多轮交互中面临显著挑战，常常导致推理碎片化、上下文丢失和幻觉。

Method: 本文提出了CAMVR框架，包含两项关键创新：1. 视觉-文本上下文记忆单元（VCMU），一个动态读写记忆网络，用于存储和管理来自每个交互轮次的关键视觉特征、文本语义表示及其跨模态对应关系；2. 自适应视觉焦点引导（AVFG）机制，利用VCMU的上下文动态调整视觉编码器对上下文相关图像区域的注意力。此外，采用多级推理整合策略确保响应生成与当前输入和累积历史上下文深度连贯。

Result: 在VisDial、改编的A-OKVQA以及本文提出的新型Multi-Turn Instruction Following (MTIF) 数据集等挑战性数据集上进行的广泛实验表明，CAMVR持续实现了最先进的性能。

Conclusion: CAMVR框架通过其创新的上下文记忆和自适应视觉焦点机制，有效地解决了LVLMs在多轮视觉-文本推理中的局限性，赋予了模型强大且连贯的多轮推理能力。

Abstract: Current Large Language Models (LLMs) and Vision-Language Large Models (LVLMs)
excel in single-turn tasks but face significant challenges in multi-turn
interactions requiring deep contextual understanding and complex visual
reasoning, often leading to fragmented reasoning, context loss, and
hallucinations. To address these limitations, we propose Context-Aware
Multi-Turn Visual Reasoning (CAMVR), a novel framework designed to empower
LVLMs with robust and coherent multi-turn visual-textual inference
capabilities. CAMVR introduces two key innovations: a Visual-Textual Context
Memory Unit (VCMU), a dynamic read-write memory network that stores and manages
critical visual features, textual semantic representations, and their
cross-modal correspondences from each interaction turn; and an Adaptive Visual
Focus Guidance (AVFG) mechanism, which leverages the VCMU's context to
dynamically adjust the visual encoder's attention to contextually relevant
image regions. Our multi-level reasoning integration strategy ensures that
response generation is deeply coherent with both current inputs and accumulated
historical context. Extensive experiments on challenging datasets, including
VisDial, an adapted A-OKVQA, and our novel Multi-Turn Instruction Following
(MTIF) dataset, demonstrate that CAMVR consistently achieves state-of-the-art
performance.

</details>


### [93] [MeshMetrics: A Precise Implementation of Distance-Based Image Segmentation Metrics](https://arxiv.org/abs/2509.05670)
*Gašper Podobnik,Tomaž Vrtovec*

Main category: cs.CV

TL;DR: 该研究指出图像分割领域因度量实现问题导致的可复现性危机，并提出了MeshMetrics，一个基于网格的框架，用于更精确地计算距离度量，以提高评估的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 图像分割研究的性能评估中，度量选择和实现是关键。尽管度量选择有所改进，但度量实现的可靠性却被忽视，导致现有开源工具在距离度量计算上存在显著差异，影响了研究的可复现性。

Method: 引入了MeshMetrics，一个基于网格的框架，用于计算距离度量。该方法通过理论分析和实证验证，证明其比传统的基于网格的方法能更精确地计算距离度量。

Result: MeshMetrics比现有工具实现了更高的准确性和精度，并且显著减少了离散化伪影（如距离量化）的影响。研究发现，现有开源工具在相同分割对上，豪斯多夫距离差异可超过100毫米，归一化表面距离差异可超过30%点。

Conclusion: MeshMetrics提供了一种比传统方法更精确、更可靠的距离度量计算方式，有效解决了图像分割领域中度量实现导致的复现性问题。该工具已作为开源Python包发布。

Abstract: The surge of research in image segmentation has yielded remarkable
performance gains but also exposed a reproducibility crisis. A major
contributor is performance evaluation, where both selection and implementation
of metrics play critical roles. While recent efforts have improved the former,
the reliability of metric implementation has received far less attention.
Pitfalls in distance-based metric implementation can lead to considerable
discrepancies between common open-source tools, for instance, exceeding 100 mm
for the Hausdorff distance and 30%pt for the normalized surface distance for
the same pair of segmentations. To address these pitfalls, we introduce
MeshMetrics, a mesh-based framework that provides a more precise computation of
distance-based metrics than conventional grid-based approaches. Through
theoretical analysis and empirical validation, we demonstrate that MeshMetrics
achieves higher accuracy and precision than established tools, and is
substantially less affected by discretization artifacts, such as distance
quantization. We release MeshMetrics as an open-source Python package,
available at https://github.com/gasperpodobnik/MeshMetrics.

</details>


### [94] [Leveraging Vision-Language Large Models for Interpretable Video Action Recognition with Semantic Tokenization](https://arxiv.org/abs/2509.05695)
*Jingwei Peng,Zhixuan Qiu,Boyu Jin,Surasakdi Siripong*

Main category: cs.CV

TL;DR: 本文提出LVLM-VAR框架，首次将预训练视觉-语言大模型（LVLMs）应用于视频动作识别，通过将视频转换为语义动作token并结合自然语言指令，显著提升了识别准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理多样化视频数据时，难以实现深度语义理解、复杂上下文推理和细粒度动作区分，阻碍了人类动作识别的发展。

Method: LVLM-VAR框架包含一个视频到语义token（VST）模块，将原始视频序列转化为离散、语义和时间一致的“语义动作token”。这些token与自然语言指令一同输入到经过LoRA微调的LVLM（例如LLaVA-13B）中，以进行动作分类和语义推理。

Result: LVLM-VAR在NTU RGB+D和NTU RGB+D 120等挑战性基准测试上取得了最先进或极具竞争力的性能（例如，NTU RGB+D X-Sub上达到94.1%，NTU RGB+D 120 X-Set上达到90.0%），并通过生成自然语言解释显著提高了模型的可解释性。

Conclusion: LVLM-VAR成功地将LVLMs应用于视频动作识别，不仅大幅提高了识别准确性，还通过提供自然语言解释增强了模型的可理解性，为该领域带来了新的视角和解决方案。

Abstract: Human action recognition often struggles with deep semantic understanding,
complex contextual information, and fine-grained distinction, limitations that
traditional methods frequently encounter when dealing with diverse video data.
Inspired by the remarkable capabilities of large language models, this paper
introduces LVLM-VAR, a novel framework that pioneers the application of
pre-trained Vision-Language Large Models (LVLMs) to video action recognition,
emphasizing enhanced accuracy and interpretability. Our method features a
Video-to-Semantic-Tokens (VST) Module, which innovatively transforms raw video
sequences into discrete, semantically and temporally consistent "semantic
action tokens," effectively crafting an "action narrative" that is
comprehensible to an LVLM. These tokens, combined with natural language
instructions, are then processed by a LoRA-fine-tuned LVLM (e.g., LLaVA-13B)
for robust action classification and semantic reasoning. LVLM-VAR not only
achieves state-of-the-art or highly competitive performance on challenging
benchmarks such as NTU RGB+D and NTU RGB+D 120, demonstrating significant
improvements (e.g., 94.1% on NTU RGB+D X-Sub and 90.0% on NTU RGB+D 120 X-Set),
but also substantially boosts model interpretability by generating natural
language explanations for its predictions.

</details>


### [95] [JRN-Geo: A Joint Perception Network based on RGB and Normal images for Cross-view Geo-localization](https://arxiv.org/abs/2509.05696)
*Hongyu Zhou,Yunzhou Zhang,Tingsong Huang,Fawei Ge,Man Qi,Xichen Zhang,Yizhong Zhang*

Main category: cs.CV

TL;DR: 该研究提出JRN-Geo网络，通过融合RGB图像的语义信息和法线图像的几何结构信息，解决跨视角地理定位中剧烈视角和外观差异的挑战。该方法利用双分支特征提取框架、DAFM和JCIA策略，并结合3D地理增强技术，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 无人机定位和导航中的跨视角地理定位面临巨大的视角差异和外观变化挑战。现有方法主要依赖RGB图像的语义特征，忽视了空间结构信息在捕捉视角不变特征方面的重要性。

Method: 本文提出一个联合感知网络JRN-Geo，整合RGB图像和法线图像的几何结构信息。该方法采用双分支特征提取框架，利用差异感知融合模块（DAFM）和联合约束交互聚合（JCIA）策略实现深度融合和联合约束的语义与结构信息表示。此外，还提出了一种3D地理增强技术来生成潜在的视角变化样本，以增强网络学习视角不变特征的能力。

Result: 在University-1652和SUES-200数据集上的大量实验验证了该方法对复杂视角变化的鲁棒性，并取得了最先进的性能。

Conclusion: 通过有效地整合RGB和法线图像的结构信息，并结合创新的融合策略和数据增强技术，JRN-Geo网络显著提升了跨视角地理定位的准确性和鲁棒性，克服了现有方法对空间结构信息忽视的局限性。

Abstract: Cross-view geo-localization plays a critical role in Unmanned Aerial Vehicle
(UAV) localization and navigation. However, significant challenges arise from
the drastic viewpoint differences and appearance variations between images.
Existing methods predominantly rely on semantic features from RGB images, often
neglecting the importance of spatial structural information in capturing
viewpoint-invariant features. To address this issue, we incorporate geometric
structural information from normal images and introduce a Joint perception
network to integrate RGB and Normal images (JRN-Geo). Our approach utilizes a
dual-branch feature extraction framework, leveraging a Difference-Aware Fusion
Module (DAFM) and Joint-Constrained Interaction Aggregation (JCIA) strategy to
enable deep fusion and joint-constrained semantic and structural information
representation. Furthermore, we propose a 3D geographic augmentation technique
to generate potential viewpoint variation samples, enhancing the network's
ability to learn viewpoint-invariant features. Extensive experiments on the
University-1652 and SUES-200 datasets validate the robustness of our method
against complex viewpoint ariations, achieving state-of-the-art performance.

</details>


### [96] [LiDAR-BIND-T: Improving SLAM with Temporally Consistent Cross-Modal LiDAR Reconstruction](https://arxiv.org/abs/2509.05728)
*Niels Balemans,Ali Anwar,Jan Steckel,Siegfried Mercelis*

Main category: cs.CV

TL;DR: 本文通过引入显式时间一致性机制，将多模态融合框架LiDAR-BIND扩展为LiDAR-BIND-T，显著提升了下游SLAM的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 原始LiDAR-BIND框架在将异构传感器（雷达、声纳）绑定到LiDAR定义的潜在空间时，可能存在时间一致性不足和空间结构保留不佳的问题，影响了下游SLAM的性能。本研究旨在解决这些问题。

Method: 本文提出了LiDAR-BIND-T框架，主要贡献包括：(i) 引入时间嵌入相似性以对齐连续潜在空间；(ii) 设计运动对齐变换损失以匹配预测与真实LiDAR之间的位移；(iii) 使用专用时间模块进行窗口时间融合。此外，还更新了模型架构以更好地保留空间结构。评估采用了基于Fréchet视频运动距离（FVMD）和相关峰距离的新指标。

Result: 评估结果表明，LiDAR-BIND-T在雷达/声纳到LiDAR的转换中，改善了时间和空间一致性，在基于Cartographer的SLAM中实现了更低的绝对轨迹误差和更高的占用图精度。该框架保持了即插即用的模态融合能力，同时显著增强了时间稳定性，从而提高了下游SLAM的鲁棒性和性能。

Conclusion: LiDAR-BIND-T通过显式的时间一致性机制，成功地扩展了LiDAR-BIND框架，在保持模态融合灵活性的同时，大幅提升了时间稳定性，为SLAM应用带来了更好的鲁棒性和性能。

Abstract: This paper extends LiDAR-BIND, a modular multi-modal fusion framework that
binds heterogeneous sensors (radar, sonar) to a LiDAR-defined latent space,
with mechanisms that explicitly enforce temporal consistency. We introduce
three contributions: (i) temporal embedding similarity that aligns consecutive
latents, (ii) a motion-aligned transformation loss that matches displacement
between predictions and ground truth LiDAR, and (iii) windows temporal fusion
using a specialised temporal module. We further update the model architecture
to better preserve spatial structure. Evaluations on radar/sonar-to-LiDAR
translation demonstrate improved temporal and spatial coherence, yielding lower
absolute trajectory error and better occupancy map accuracy in
Cartographer-based SLAM (Simultaneous Localisation and Mapping). We propose
different metrics based on the Fr\'echet Video Motion Distance (FVMD) and a
correlation-peak distance metric providing practical temporal quality
indicators to evaluate SLAM performance. The proposed temporal LiDAR-BIND, or
LiDAR-BIND-T, maintains plug-and-play modality fusion while substantially
enhancing temporal stability, resulting in improved robustness and performance
for downstream SLAM.

</details>


### [97] [Knowledge-Augmented Vision Language Models for Underwater Bioacoustic Spectrogram Analysis](https://arxiv.org/abs/2509.05703)
*Ragib Amin Nihal,Benjamin Yen,Takeshi Ashizawa,Kazuhiro Nakadai*

Main category: cs.CV

TL;DR: 本文研究了视觉语言模型（VLMs）是否能在未经特定领域训练的情况下，通过声谱图分析海洋哺乳动物的发声。通过结合VLM解释和基于LLM的验证，该框架无需手动标注或模型再训练即可适应声学数据。


<details>
  <summary>Details</summary>
Motivation: 海洋哺乳动物发声分析依赖于生物声学声谱图的解读，但现有的视觉语言模型（VLMs）并未针对这类特定领域的视觉数据进行训练。因此，研究的动机是探索VLMs是否能从声谱图中有效提取有意义的模式。

Method: 研究方法是构建一个框架，该框架将VLM的解释能力与基于大型语言模型（LLM）的验证机制相结合，以构建领域知识。这种集成允许模型适应声学数据。

Result: 该框架使得模型能够适应声学数据，而无需进行手动标注或模型再训练。这意味着可以从声谱图中视觉化地提取有意义的模式。

Conclusion: 结论是，通过将VLM的解释能力与LLM的验证相结合，可以有效地使VLMs适应生物声学声谱图分析，从而无需传统的密集型数据标注或模型再训练，即可从特定领域的可视化数据中提取模式。

Abstract: Marine mammal vocalization analysis depends on interpreting bioacoustic
spectrograms. Vision Language Models (VLMs) are not trained on these
domain-specific visualizations. We investigate whether VLMs can extract
meaningful patterns from spectrograms visually. Our framework integrates VLM
interpretation with LLM-based validation to build domain knowledge. This
enables adaptation to acoustic data without manual annotation or model
retraining.

</details>


### [98] [InterAct: A Large-Scale Dataset of Dynamic, Expressive and Interactive Activities between Two People in Daily Scenarios](https://arxiv.org/abs/2509.05747)
*Leo Ho,Yinghao Huang,Dafei Qin,Mingyi Shi,Wangpok Tse,Wei Liu,Junichi Yamagishi,Taku Komura*

Main category: cs.CV

TL;DR: 该研究旨在准确捕捉日常场景中两人之间的互动行为，提出了一个名为 InterAct 的新型多模态数据集，并开发了一种基于扩散模型的简单有效方法，通过语音输入估计两人的互动面部表情和身体动作。


<details>
  <summary>Details</summary>
Motivation: 现有工作大多只关注单人或仅限于两人对话手势，且假设身体姿态保持不变或变化微小。本研究旨在同时建模两人活动，目标是捕捉以目标驱动、动态且语义一致的互动，这些互动通常持续时间更长、覆盖空间更大。

Method: 研究方法包括：1) 捕捉了一个新的多模态数据集 InterAct，包含241个两人进行现实连贯场景的动作序列，每个序列持续一分钟或更长，涵盖音频、身体动作和面部表情；2) 提出了一种简单有效的基于扩散模型的方法，通过语音输入估计两人的互动面部表情和身体动作；3) 身体动作采用分层回归方式；4) 提出了一种新颖的微调机制以提高面部表情的唇部准确性。

Result: InterAct 数据集包含了多样且复杂的个体动作，以及以前罕见的有趣且相对长期的互动模式。研究还展示了所提出的基于扩散模型的方法能够有效估计互动面部表情和身体动作，并显著提高了唇部准确性。

Conclusion: 该研究成功捕捉并建模了两人在日常场景中的动态、目标驱动的互动行为，通过构建 InterAct 数据集和提出基于扩散模型的方法，为未来关于两人互动行为的研究提供了宝贵资源和有效工具。

Abstract: We address the problem of accurate capture of interactive behaviors between
two people in daily scenarios. Most previous works either only consider one
person or solely focus on conversational gestures of two people, assuming the
body orientation and/or position of each actor are constant or barely change
over each interaction. In contrast, we propose to simultaneously model two
people's activities, and target objective-driven, dynamic, and semantically
consistent interactions which often span longer duration and cover bigger
space. To this end, we capture a new multi-modal dataset dubbed InterAct, which
is composed of 241 motion sequences where two people perform a realistic and
coherent scenario for one minute or longer over a complete interaction. For
each sequence, two actors are assigned different roles and emotion labels, and
collaborate to finish one task or conduct a common interaction activity. The
audios, body motions, and facial expressions of both persons are captured.
InterAct contains diverse and complex motions of individuals and interesting
and relatively long-term interaction patterns barely seen before. We also
demonstrate a simple yet effective diffusion-based method that estimates
interactive face expressions and body motions of two people from speech inputs.
Our method regresses the body motions in a hierarchical manner, and we also
propose a novel fine-tuning mechanism to improve the lip accuracy of facial
expressions. To facilitate further research, the data and code is made
available at https://hku-cg.github.io/interact/ .

</details>


### [99] [Multi-LVI-SAM: A Robust LiDAR-Visual-Inertial Odometry for Multiple Fisheye Cameras](https://arxiv.org/abs/2509.05740)
*Xinyu Zhang,Kai Huang,Junqiao Zhao,Zihan Yuan,Tiantian Feng*

Main category: cs.CV

TL;DR: 本文提出了Multi-LVI-SAM，一个多相机激光雷达-视觉-惯性里程计框架，通过引入全景视觉特征模型和外参补偿方法，实现了多鱼眼相机数据的高效融合，显著提高了位姿估计的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有系统在融合多鱼眼相机数据时存在效率和一致性问题，导致位姿估计不够准确和鲁棒。研究旨在实现高精度和鲁棒的状态估计。

Method: 1. 提出了Multi-LVI-SAM框架，融合多鱼眼相机、激光雷达和惯性传感器数据。2. 引入了全景视觉特征模型，将多相机观测统一为单一表示，用于全局几何优化、回环检测和全局位姿优化。3. 提出了一种外参补偿方法，解决相机帧与全景模型帧之间的未对准导致的三角化不一致问题。4. 将全景视觉特征模型集成到基于因子图的紧耦合激光雷达-视觉-惯性系统中。

Result: 全景视觉特征模型显著提高了多相机约束的质量和一致性。与现有多相机激光雷达-视觉-惯性系统相比，Multi-LVI-SAM在公共数据集上表现出更高的精度和鲁棒性，减少了三角化和优化误差。

Conclusion: 所提出的Multi-LVI-SAM框架，特别是其全景视觉特征模型和外参补偿方法，有效解决了多鱼眼相机数据融合的挑战，实现了更准确和鲁棒的状态估计。

Abstract: We propose a multi-camera LiDAR-visual-inertial odometry framework,
Multi-LVI-SAM, which fuses data from multiple fisheye cameras, LiDAR and
inertial sensors for highly accurate and robust state estimation. To enable
efficient and consistent integration of visual information from multiple
fisheye cameras, we introduce a panoramic visual feature model that unifies
multi-camera observations into a single representation. The panoramic model
serves as a global geometric optimization framework that consolidates
multi-view constraints, enabling seamless loop closure and global pose
optimization, while simplifying system design by avoiding redundant handling of
individual cameras. To address the triangulation inconsistency caused by the
misalignment between each camera's frame and the panoramic model's frame, we
propose an extrinsic compensation method. This method improves feature
consistency across views and significantly reduces triangulation and
optimization errors, leading to more accurate pose estimation. We integrate the
panoramic visual feature model into a tightly coupled LiDAR-visual-inertial
system based on a factor graph. Extensive experiments on public datasets
demonstrate that the panoramic visual feature model enhances the quality and
consistency of multi-camera constraints, resulting in higher accuracy and
robustness than existing multi-camera LiDAR-visual-inertial systems.

</details>


### [100] [Multi-Modal Camera-Based Detection of Vulnerable Road Users](https://arxiv.org/abs/2509.06333)
*Penelope Brown,Julie Stephany Berrio Perez,Mao Shan,Stewart Worrall*

Main category: cs.CV

TL;DR: 本文提出了一种结合RGB和热红外图像的多模态检测框架，基于微调的YOLOv8模型，通过数据增强和损失加权优化，有效提高了弱光、恶劣天气和数据不平衡条件下弱势道路使用者（VRU）的检测精度和召回率，尤其对稀有VRU表现更佳。


<details>
  <summary>Details</summary>
Motivation: 弱势道路使用者（行人、骑自行车者、摩托车手）占全球交通事故死亡人数的一半以上，但在弱光、恶劣天气和数据不平衡等条件下，他们的检测仍然极具挑战性。

Method: 该研究提出了一种多模态检测框架，整合了RGB和热红外成像，并使用了微调的YOLOv8模型。训练利用了KITTI、BDD100K和Teledyne FLIR数据集，并采用了类别重新加权和轻度数据增强来提高少数类别的性能和鲁棒性。实验优化了640像素分辨率和部分骨干网络冻结以提高准确性和效率，同时使用类别加权损失来增强稀有VRU的召回率。此外，还采用了RGB到热像的增强技术来提升召回率。

Result: 研究结果表明，640像素分辨率和部分骨干网络冻结优化了准确性和效率；类别加权损失增强了稀有VRU的召回率；热成像模型实现了最高的精度；RGB到热像的增强提升了召回率。

Conclusion: 多模态检测在提高交叉路口弱势道路使用者安全方面具有巨大潜力。

Abstract: Vulnerable road users (VRUs) such as pedestrians, cyclists, and motorcyclists
represent more than half of global traffic deaths, yet their detection remains
challenging in poor lighting, adverse weather, and unbalanced data sets. This
paper presents a multimodal detection framework that integrates RGB and thermal
infrared imaging with a fine-tuned YOLOv8 model. Training leveraged KITTI,
BDD100K, and Teledyne FLIR datasets, with class re-weighting and light
augmentations to improve minority-class performance and robustness, experiments
show that 640-pixel resolution and partial backbone freezing optimise accuracy
and efficiency, while class-weighted losses enhance recall for rare VRUs.
Results highlight that thermal models achieve the highest precision, and
RGB-to-thermal augmentation boosts recall, demonstrating the potential of
multimodal detection to improve VRU safety at intersections.

</details>


### [101] [Depth-Aware Super-Resolution via Distance-Adaptive Variational Formulation](https://arxiv.org/abs/2509.05746)
*Tianhao Guo,Bingjie Lu,Feng Wang,Zhengyang Lu*

Main category: cs.CV

TL;DR: 本文提出了一种理论上严谨的距离自适应超分辨率框架，解决了真实世界图像中存在的空间变异退化问题。该框架采用变分方法和深度条件卷积核，实现了对深度相关场景的显著改进，并在传统基准测试中保持了竞争力。


<details>
  <summary>Details</summary>
Motivation: 传统的单图像超分辨率方法假设空间不变的退化模型，但真实世界的成像系统存在复杂的距离相关效应，如大气散射、景深变化和透视畸变。这种根本性限制需要空间自适应的重建策略，以明确整合几何场景理解。

Method: 研究者将超分辨率表述为一个空间变化的逆问题，并将其特征化为具有距离相关谱特征的伪微分算子。其神经网络架构通过级联残差块实现离散梯度流动力学，并使用深度条件卷积核，同时引入学习到的距离自适应正则化项。此外，还利用大气散射理论的谱约束和自适应核生成网络，学习从深度到重建滤波器的连续映射。

Result: 该方法在五个基准数据集上取得了最先进的性能，在KITTI室外场景中，2倍和4倍放大下分别达到36.89/0.9516和30.54/0.8721的PSNR/SSIM，分别比现有方法高出0.44dB和0.36dB。它在深度变化的场景中表现出显著改进，同时在传统基准测试中保持了竞争力。

Conclusion: 这项工作建立了第一个理论基础上的距离自适应超分辨率框架，并在深度变化的场景中展示了显著的性能提升，同时在传统基准测试中保持了竞争性表现。

Abstract: Single image super-resolution traditionally assumes spatially-invariant
degradation models, yet real-world imaging systems exhibit complex
distance-dependent effects including atmospheric scattering, depth-of-field
variations, and perspective distortions. This fundamental limitation
necessitates spatially-adaptive reconstruction strategies that explicitly
incorporate geometric scene understanding for optimal performance. We propose a
rigorous variational framework that characterizes super-resolution as a
spatially-varying inverse problem, formulating the degradation operator as a
pseudodifferential operator with distance-dependent spectral characteristics
that enable theoretical analysis of reconstruction limits across depth ranges.
Our neural architecture implements discrete gradient flow dynamics through
cascaded residual blocks with depth-conditional convolution kernels, ensuring
convergence to stationary points of the theoretical energy functional while
incorporating learned distance-adaptive regularization terms that dynamically
adjust smoothness constraints based on local geometric structure. Spectral
constraints derived from atmospheric scattering theory prevent bandwidth
violations and noise amplification in far-field regions, while adaptive kernel
generation networks learn continuous mappings from depth to reconstruction
filters. Comprehensive evaluation across five benchmark datasets demonstrates
state-of-the-art performance, achieving 36.89/0.9516 and 30.54/0.8721 PSNR/SSIM
at 2 and 4 scales on KITTI outdoor scenes, outperforming existing methods by
0.44dB and 0.36dB respectively. This work establishes the first
theoretically-grounded distance-adaptive super-resolution framework and
demonstrates significant improvements on depth-variant scenarios while
maintaining competitive performance across traditional benchmarks.

</details>


### [102] [Investigating Location-Regularised Self-Supervised Feature Learning for Seafloor Visual Imagery](https://arxiv.org/abs/2509.06660)
*Cailei Liang,Adrian Bodenmann,Emma J Curtis,Samuel Simmons,Kazunori Nagano,Stan Brown,Adam Riese,Blair Thornton*

Main category: cs.CV

TL;DR: 本研究评估了位置元数据正则化对六种自监督学习（SSL）框架（包括CNN和ViT模型）在海底图像解释中的影响，发现其显著提高了下游分类性能，尤其是在低维潜在表示和对高维ViT的泛化能力方面。


<details>
  <summary>Details</summary>
Motivation: 机器人采集的海底视觉图像的高通量解释能提高海洋监测和探索效率。尽管已有研究表明位置元数据可以增强自监督特征学习，但其在不同SSL策略、模型和海底图像数据集上的益处尚未得到充分探索。

Method: 研究评估了基于位置的正则化对六种最先进的自监督学习（SSL）框架的影响，这些框架包括卷积神经网络（CNN）和视觉Transformer（ViT）模型，并考虑了不同潜在空间维度。评估是在三个不同的海底图像数据集上进行的。

Result: 位置正则化持续改善了下游分类性能，CNN的F1分数平均提升4.9±4.0%，ViT的平均提升6.3±8.9%。对于CNN，在通用数据集上预训练的模型受益于高维潜在表示，而经过数据集优化的SSL在高中低维潜在表示上表现相似。位置正则化的SSL使CNN性能比预训练模型分别提高了2.7±2.7%（高维）和10.1±9.4%（低维）。对于ViT，高维潜在表示对预训练和数据集优化的SSL都有益。尽管位置正则化提高了SSL性能，但预训练的ViT显示出强大的泛化能力，与表现最佳的位置正则化SSL（F1分数均为0.795±0.075和0.795±0.077）持平。

Conclusion: 研究结果强调了位置元数据对于SSL正则化的价值，尤其是在使用低维潜在表示时。同时，也证明了高维ViT在海底图像分析中具有强大的泛化能力。

Abstract: High-throughput interpretation of robotically gathered seafloor visual
imagery can increase the efficiency of marine monitoring and exploration.
Although recent research has suggested that location metadata can enhance
self-supervised feature learning (SSL), its benefits across different SSL
strategies, models and seafloor image datasets are underexplored. This study
evaluates the impact of location-based regularisation on six state-of-the-art
SSL frameworks, which include Convolutional Neural Network (CNN) and Vision
Transformer (ViT) models with varying latent-space dimensionality. Evaluation
across three diverse seafloor image datasets finds that location-regularisation
consistently improves downstream classification performance over standard SSL,
with average F1-score gains of $4.9 \pm 4.0%$ for CNNs and $6.3 \pm 8.9%$ for
ViTs, respectively. While CNNs pretrained on generic datasets benefit from
high-dimensional latent representations, dataset-optimised SSL achieves similar
performance across the high (512) and low (128) dimensional latent
representations. Location-regularised SSL improves CNN performance over
pre-trained models by $2.7 \pm 2.7%$ and $10.1 \pm 9.4%$ for high and
low-dimensional latent representations, respectively. For ViTs,
high-dimensionality benefits both pre-trained and dataset-optimised SSL.
Although location-regularisation improves SSL performance compared to standard
SSL methods, pre-trained ViTs show strong generalisation, matching the
best-performing location-regularised SSL with F1-scores of $0.795 \pm 0.075$
and $0.795 \pm 0.077$, respectively. The findings highlight the value of
location metadata for SSL regularisation, particularly when using
low-dimensional latent representations, and demonstrate strong generalisation
of high-dimensional ViTs for seafloor image analysis.

</details>


### [103] [Unleashing Hierarchical Reasoning: An LLM-Driven Framework for Training-Free Referring Video Object Segmentation](https://arxiv.org/abs/2509.05751)
*Bingrui Zhao,Lin Yuanbo Wu,Xiangtian Fan,Deyin Liu,Lu Zhang,Ruyi He,Jialie Shen,Ximing Li*

Main category: cs.CV

TL;DR: 本文提出PARSE-VOS，一个由大型语言模型（LLM）驱动的免训练框架，用于参考视频对象分割（RVOS），通过层次化、从粗到细的推理来处理文本与视频内容的对齐，并取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前的RVOS方法在将静态文本与动态视觉内容对齐时面临挑战，尤其当对象外观相似、运动和姿态不一致时。此外，现有的方法依赖于整体视觉-语言融合，难以处理复杂、组合性的描述。

Method: PARSE-VOS是一个免训练框架，采用LLM进行层次化推理。具体步骤包括：1. 将自然语言查询解析为结构化语义命令。2. 引入时空定位模块，根据解析的语义生成所有潜在目标的所有候选轨迹。3. 设计层次化识别模块，通过两阶段推理选择正确目标：首先使用LLM进行粗粒度运动推理以缩小候选范围；如果仍存在歧义，则有条件地触发细粒度姿态验证阶段进行消歧。

Result: PARSE-VOS在三个主要基准测试（Ref-YouTube-VOS、Ref-DAVIS17和MeViS）上取得了最先进的性能。

Conclusion: PARSE-VOS通过利用LLM进行层次化、从粗到细的推理，有效解决了RVOS中复杂的文本描述与动态视觉内容对齐的挑战，并提供了一种无需训练的有效解决方案，显著提升了分割准确性。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment an object of
interest throughout a video based on a language description. The prominent
challenge lies in aligning static text with dynamic visual content,
particularly when objects exhibiting similar appearances with inconsistent
motion and poses. However, current methods often rely on a holistic
visual-language fusion that struggles with complex, compositional descriptions.
In this paper, we propose \textbf{PARSE-VOS}, a novel, training-free framework
powered by Large Language Models (LLMs), for a hierarchical, coarse-to-fine
reasoning across text and video domains. Our approach begins by parsing the
natural language query into structured semantic commands. Next, we introduce a
spatio-temporal grounding module that generates all candidate trajectories for
all potential target objects, guided by the parsed semantics. Finally, a
hierarchical identification module select the correct target through a
two-stage reasoning process: it first performs coarse-grained motion reasoning
with an LLM to narrow down candidates; if ambiguity remains, a fine-grained
pose verification stage is conditionally triggered to disambiguate. The final
output is an accurate segmentation mask for the target object.
\textbf{PARSE-VOS} achieved state-of-the-art performance on three major
benchmarks: Ref-YouTube-VOS, Ref-DAVIS17, and MeViS.

</details>


### [104] [Online Clustering of Seafloor Imagery for Interpretation during Long-Term AUV Operations](https://arxiv.org/abs/2509.06678)
*Cailei Liang,Adrian Bodenmann,Sam Fenton,Blair Thornton*

Main category: cs.CV

TL;DR: 本文提出了一种在线聚类框架（OCF），用于实时、无监督地解释海底图像数据流，以支持长续航AUV的自适应任务和通信优化。


<details>
  <summary>Details</summary>
Motivation: 随着长续航和海底驻留AUV能力的增强，对海底图像进行实时、扩展的解释需求日益增长。然而，现有的离线图像分析方法依赖于完整数据集和人工标注，无法满足实时应用的需求，因为环境和操作条件对图像外观有显著影响。

Method: 研究引入了一个在线聚类框架（OCF），该框架能够无监督地解释海底图像，并设计为可扩展、自适应和自洽地实时处理连续数据流。该方法通过识别和维护一组代表性样本，捕获不断演变特征分布，从而以恒定时间高效地审查和整合整个数据历史中的常见模式，支持动态集群合并和拆分，而无需重新处理完整的图像历史。

Result: OCF在三个多样化的海底图像数据集上进行了评估，其平均F1分数达到0.68，在所有比较的在线聚类方法中最高，并且在三种不同测量轨迹下的标准偏差为3%，展现了卓越的聚类能力和对轨迹变化的鲁棒性。此外，随着数据量的增加，其计算时间始终保持较低且有界。

Conclusion: OCF的这些特性（卓越的聚类能力、鲁棒性、低且有界的计算时间）对于生成调查数据摘要以及在长期、持久的自主海洋探索中支持信息丰富的路径规划非常有益。

Abstract: As long-endurance and seafloor-resident AUVs become more capable, there is an
increasing need for extended, real-time interpretation of seafloor imagery to
enable adaptive missions and optimise communication efficiency. Although
offline image analysis methods are well established, they rely on access to
complete datasets and human-labelled examples to manage the strong influence of
environmental and operational conditions on seafloor image
appearance-requirements that cannot be met in real-time settings. To address
this, we introduce an online clustering framework (OCF) capable of interpreting
seafloor imagery without supervision, which is designed to operate in real-time
on continuous data streams in a scalable, adaptive, and self-consistent manner.
The method enables the efficient review and consolidation of common patterns
across the entire data history in constant time by identifying and maintaining
a set of representative samples that capture the evolving feature distribution,
supporting dynamic cluster merging and splitting without reprocessing the full
image history. We evaluate the framework on three diverse seafloor image
datasets, analysing the impact of different representative sampling strategies
on both clustering accuracy and computational cost. The OCF achieves the
highest average F1 score of 0.68 across the three datasets among all
comparative online clustering approaches, with a standard deviation of 3%
across three distinct survey trajectories, demonstrating its superior
clustering capability and robustness to trajectory variation. In addition, it
maintains consistently lower and bounded computational time as the data volume
increases. These properties are beneficial for generating survey data summaries
and supporting informative path planning in long-term, persistent autonomous
marine exploration.

</details>


### [105] [PictOBI-20k: Unveiling Large Multimodal Models in Visual Decipherment for Pictographic Oracle Bone Characters](https://arxiv.org/abs/2509.05773)
*Zijian Chen,Wenjie Hua,Jinhao Li,Lirong Deng,Fan Du,Tingzhu Chen,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本文介绍了PictOBI-20k数据集，用于评估大型多模态模型（LMMs）在象形甲骨文视觉释读任务上的表现。研究发现LMMs具备初步释读能力，但其视觉信息利用效率不高，且常受语言先验知识的限制。


<details>
  <summary>Details</summary>
Motivation: 甲骨文释读对于理解人类早期生产方式至关重要，但现有方法受限于考古发掘和语料库的稀缺。鉴于大型多模态模型（LMMs）强大的视觉感知能力，研究其在视觉释读甲骨文方面的潜力成为可能，但需要专门的评估数据集。

Method: 本文构建了PictOBI-20k数据集，包含2万张精心收集的甲骨文和真实物体图像，形成超过1.5万道多选题，用于评估LMMs的视觉释读能力。同时，进行了主观标注以探究人类与LMMs在视觉推理中参考点的一致性。最后，使用通用LMMs进行了实验。

Result: 实验结果表明，通用LMMs具备初步的视觉释读能力。然而，LMMs并未有效利用视觉信息，大部分时间受到语言先验知识的限制。

Conclusion: PictOBI-20k数据集有望促进未来面向甲骨文的LMMs在视觉注意力方面的评估和优化。研究揭示了当前LMMs在甲骨文视觉释读中视觉利用效率和语言先验依赖的问题。

Abstract: Deciphering oracle bone characters (OBCs), the oldest attested form of
written Chinese, has remained the ultimate, unwavering goal of scholars,
offering an irreplaceable key to understanding humanity's early modes of
production. Current decipherment methodologies of OBC are primarily constrained
by the sporadic nature of archaeological excavations and the limited corpus of
inscriptions. With the powerful visual perception capability of large
multimodal models (LMMs), the potential of using LMMs for visually deciphering
OBCs has increased. In this paper, we introduce PictOBI-20k, a dataset designed
to evaluate LMMs on the visual decipherment tasks of pictographic OBCs. It
includes 20k meticulously collected OBC and real object images, forming over
15k multi-choice questions. We also conduct subjective annotations to
investigate the consistency of the reference point between humans and LMMs in
visual reasoning. Experiments indicate that general LMMs possess preliminary
visual decipherment skills, and LMMs are not effectively using visual
information, while most of the time they are limited by language priors. We
hope that our dataset can facilitate the evaluation and optimization of visual
attention in future OBC-oriented LMMs. The code and dataset will be available
at https://github.com/OBI-Future/PictOBI-20k.

</details>


### [106] [Event Spectroscopy: Event-based Multispectral and Depth Sensing using Structured Light](https://arxiv.org/abs/2509.06741)
*Christian Geckeler,Niklas Neugebauer,Manasi Muglikar,Davide Scaramuzza,Stefano Mintchev*

Main category: cs.CV

TL;DR: 本文提出了一种新型事件光谱系统，该系统利用单一传感器同时实现高分辨率、低延迟深度重建和多光谱成像，显著提升了无人机在复杂森林环境中的感知能力和数据收集效率。


<details>
  <summary>Details</summary>
Motivation: 无人机在森林环境中执行环境监测和搜救任务时，传统传感方法（如被动多光谱和RGB成像）存在延迟高、深度分辨率差以及对环境光（尤其是在森林冠层下）依赖性强的问题，限制了其在密集植被中安全导航和精确数据收集的能力。

Method: 该研究开发了一种新颖的事件光谱系统。它通过结构光实现深度重建，并通过调制投射结构光的波长来捕获650 nm至850 nm受控波段内的光谱信息。为了进行实际验证，还使用了一个仅限于RGB（3个波长）的便携式版本，在Masoala雨林中收集了真实世界的深度和光谱数据。

Result: 该系统在深度重建方面，与商用深度传感器相比，均方根误差（RMSE）提高了60%。在光谱精度方面，与参考光谱仪和商用多光谱相机表现相当。在材料区分任务中，通过结合深度数据（无需额外努力即可获得），相比仅使用颜色信息的方法，准确性提高了30%以上。该系统在实验室和真实雨林环境中均表现出强大的性能。

Conclusion: 该系统在深度估计、RGB重建和材料区分方面表现出色，为轻量级、集成化和鲁棒的无人机在复杂自然环境中的感知和数据收集铺平了道路。

Abstract: Uncrewed aerial vehicles (UAVs) are increasingly deployed in forest
environments for tasks such as environmental monitoring and search and rescue,
which require safe navigation through dense foliage and precise data
collection. Traditional sensing approaches, including passive multispectral and
RGB imaging, suffer from latency, poor depth resolution, and strong dependence
on ambient light - especially under forest canopies. In this work, we present a
novel event spectroscopy system that simultaneously enables high-resolution,
low-latency depth reconstruction and multispectral imaging using a single
sensor. Depth is reconstructed using structured light, and by modulating the
wavelength of the projected structured light, our system captures spectral
information in controlled bands between 650 nm and 850 nm. We demonstrate up to
$60\%$ improvement in RMSE over commercial depth sensors and validate the
spectral accuracy against a reference spectrometer and commercial multispectral
cameras, demonstrating comparable performance. A portable version limited to
RGB (3 wavelengths) is used to collect real-world depth and spectral data from
a Masoala Rainforest. We demonstrate the use of this prototype for color image
reconstruction and material differentiation between leaves and branches using
spectral and depth data. Our results show that adding depth (available at no
extra effort with our setup) to material differentiation improves the accuracy
by over $30\%$ compared to color-only method. Our system, tested in both lab
and real-world rainforest environments, shows strong performance in depth
estimation, RGB reconstruction, and material differentiation - paving the way
for lightweight, integrated, and robust UAV perception and data collection in
complex natural environments.

</details>


### [107] [Posterior shape models revisited: Improving 3D reconstructions from partial data using target specific models](https://arxiv.org/abs/2509.05776)
*Jonathan Aellen,Florian Burkhardt,Thomas Vetter,Marcel Lüthi*

Main category: cs.CV

TL;DR: 在医学图像处理中，点分布模型进行部分形状重建时，训练数据与目标形状的姿态对齐至关重要。本文提出一种高效方法，无需原始训练数据即可调整现有模型以适应特定目标姿态，显著提高重建精度和预测方差。


<details>
  <summary>Details</summary>
Motivation: 点分布模型在部分形状重建中常忽略训练数据与目标形状的姿态对齐，尤其在观察形状小部分时，这种差异会导致重建结果出现偏差。

Method: 提出了一种高效方法，用于调整现有模型以适应特定目标姿态。该方法在保持线性模型计算效率的同时，无需访问原始训练数据。它能精确恢复平移情况下的对齐模型，并对小旋转提供良好近似。

Result: 显著提高了重建精度和预测方差。对于平移情况，能精确恢复预期的对齐模型；对于小旋转，能提供良好的近似。

Conclusion: 姿态对齐是部分形状重建的关键因素。所提出的方法通过简单的预处理步骤即可调整现有形状模型，使其在重建流程中广泛适用，尤其适用于即插即用场景。

Abstract: In medical imaging, point distribution models are often used to reconstruct
and complete partial shapes using a statistical model of the full shape. A
commonly overlooked, but crucial factor in this reconstruction process, is the
pose of the training data relative to the partial target shape. A difference in
pose alignment of the training and target shape leads to biased solutions,
particularly when observing small parts of a shape. In this paper, we
demonstrate the importance of pose alignment for partial shape reconstructions
and propose an efficient method to adjust an existing model to a specific
target. Our method preserves the computational efficiency of linear models
while significantly improving reconstruction accuracy and predicted variance.
It exactly recovers the intended aligned model for translations, and provides a
good approximation for small rotations, all without access to the original
training data. Hence, existing shape models in reconstruction pipelines can be
adapted by a simple preprocessing step, making our approach widely applicable
in plug-and-play scenarios.

</details>


### [108] [AdCare-VLM: Leveraging Large Vision Language Model (LVLM) to Monitor Long-Term Medication Adherence and Care](https://arxiv.org/abs/2505.00275)
*Md Asaduzzaman Jabin,Hanqi Jiang,Yiwei Li,Patrick Kaggwa,Eugene Douglass,Juliet N. Sekandi,Tianming Liu*

Main category: cs.CV

TL;DR: AdCare-VLM是一个基于Video-LLaVA的多模态大视觉语言模型，通过分析患者视频进行药物依从性视觉问答（VQA），在结核病药物依从性检测上表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 慢性病（如糖尿病、高血压、结核病等）需要严格的药物依从性以控制病情和降低死亡率。然而，患者行为、护理支持、医疗成本和基础设施不足等因素经常导致依从性不足，因此需要更有效的依从性监测方法。

Method: 本文提出了AdCare-VLM，一个基于Video-LLaVA的专用多模态大视觉语言模型（LVLM），用于通过患者视频进行药物依从性视觉问答（VQA）。研究团队使用包含806个由临床专家标注的结核病（TB）药物监测视频的私有数据集（LLM-TB-VQA）对模型进行微调，以检测依从性模式。该方法将视觉特征（如患者面部、药物、饮水和吞咽行为的清晰可见性）与相关医学概念相关联，从而整合对齐的视觉-语言表示并增强多模态交互。

Result: 实验结果表明，AdCare-VLM在预训练、常规和低秩适应（LoRA）配置下，相对于基于参数高效微调（PEFT）的VLM模型（如LLaVA-V1.5和Chat-UniVi），实现了3.1%至3.54%的绝对性能提升。全面的消融研究和注意力图可视化也证实了该方法的有效性，并增强了解释性。

Conclusion: AdCare-VLM通过对患者视频进行VQA，有效提升了药物依从性监测的能力，其在性能和可解释性方面均超越了现有模型，为慢性病药物依从性管理提供了有前景的解决方案。

Abstract: Chronic diseases, including diabetes, hypertension, asthma, HIV-AIDS,
epilepsy, and tuberculosis, necessitate rigorous adherence to medication to
avert disease progression, manage symptoms, and decrease mortality rates.
Adherence is frequently undermined by factors including patient behavior,
caregiver support, elevated medical costs, and insufficient healthcare
infrastructure. We propose AdCare-VLM, a specialized Video-LLaVA-based
multimodal large vision language model (LVLM) aimed at visual question
answering (VQA) concerning medication adherence through patient videos. We
employ a private dataset comprising 806 custom-annotated tuberculosis (TB)
medication monitoring videos, which have been labeled by clinical experts, to
fine-tune the model for adherence pattern detection. We present LLM-TB-VQA, a
detailed medical adherence VQA dataset that encompasses positive, negative, and
ambiguous adherence cases. Our method identifies correlations between visual
features, such as the clear visibility of the patient's face, medication, water
intake, and the act of ingestion, and their associated medical concepts in
captions. This facilitates the integration of aligned visual-linguistic
representations and improves multimodal interactions. Experimental results
indicate that our method surpasses parameter-efficient fine-tuning (PEFT)
enabled VLM models, such as LLaVA-V1.5 and Chat-UniVi, with absolute
improvements ranging from 3.1% to 3.54% across pre-trained, regular, and
low-rank adaptation (LoRA) configurations. Comprehensive ablation studies and
attention map visualizations substantiate our approach, enhancing
interpretability.

</details>


### [109] [3DPillars: Pillar-based two-stage 3D object detection](https://arxiv.org/abs/2509.05780)
*Jongyoun Noh,Junghyup Lee,Hyekang Park,Bumsub Ham*

Main category: cs.CV

TL;DR: 本文提出了一种新型两阶段3D目标检测框架，通过改进PointPillars的伪图像表示和引入两阶段检测范式，在保持效率的同时提升了检测精度，缩小了与最先进方法的性能差距。


<details>
  <summary>Details</summary>
Motivation: PointPillars虽然是速度最快的3D目标检测器之一，但其性能通常不如最先进的方法。主要原因是：1) 伪图像表示未能精确保留3D结构；2) 难以采用通常性能更优的两阶段检测流程（使用3D目标建议）。

Method: 本文提出了两个新颖组件：1) 引入了新的CNN架构3DPillars，它通过将3D体素特征视为伪图像的堆叠，利用2D卷积高效地从伪图像表示中学习3D体素特征，并为此设计了可分离的体素特征模块。2) 引入了一个带有稀疏场景上下文特征模块的RoI头部，该模块聚合来自3DPillars的多尺度特征以获得稀疏场景特征，从而有效地采用两阶段流程并充分利用场景上下文信息来优化3D目标建议。

Result: 在KITTI和Waymo Open数据集上的实验结果表明，该方法在速度和精度之间取得了良好的平衡，证明了其有效性和效率。

Conclusion: 本文提出的框架成功克服了PointPillars的局限性，在保持其效率的同时，缩小了其与最先进3D检测方法之间的性能差距。

Abstract: PointPillars is the fastest 3D object detector that exploits pseudo image
representations to encode features for 3D objects in a scene. Albeit efficient,
PointPillars is typically outperformed by state-of-the-art 3D detection methods
due to the following limitations: 1) The pseudo image representations fail to
preserve precise 3D structures, and 2) they make it difficult to adopt a
two-stage detection pipeline using 3D object proposals that typically shows
better performance than a single-stage approach. We introduce in this paper the
first two-stage 3D detection framework exploiting pseudo image representations,
narrowing the performance gaps between PointPillars and state-of-the-art
methods, while retaining its efficiency. Our framework consists of two novel
components that overcome the aforementioned limitations of PointPillars: First,
we introduce a new CNN architecture, dubbed 3DPillars, that enables learning 3D
voxel-based features from the pseudo image representation efficiently using 2D
convolutions. The basic idea behind 3DPillars is that 3D features from voxels
can be viewed as a stack of pseudo images. To implement this idea, we propose a
separable voxel feature module that extracts voxel-based features without using
3D convolutions. Second, we introduce an RoI head with a sparse scene context
feature module that aggregates multi-scale features from 3DPillars to obtain a
sparse scene feature. This enables adopting a two-stage pipeline effectively,
and fully leveraging contextual information of a scene to refine 3D object
proposals. Experimental results on the KITTI and Waymo Open datasets
demonstrate the effectiveness and efficiency of our approach, achieving a good
compromise in terms of speed and accuracy.

</details>


### [110] [CRAB: Camera-Radar Fusion for Reducing Depth Ambiguity in Backward Projection based View Transformation](https://arxiv.org/abs/2509.05785)
*In-Jae Lee,Sihwan Hwang,Youngseok Kim,Wonjune Kim,Sanmin Kim,Dongsuk Kum*

Main category: cs.CV

TL;DR: 本文提出了一种名为CRAB的新型相机-雷达融合3D目标检测与分割模型，通过利用雷达信息缓解反向投影中深度模糊问题，并在nuScenes数据集上实现了当前反向投影相机-雷达融合方法的最佳性能。


<details>
  <summary>Details</summary>
Motivation: 相机-雷达融合的3D目标检测因其互补性和成本效益而备受关注。然而，现有方法存在局限：前向投影方法生成稀疏的BEV特征，而后向投影方法则忽略深度模糊性，导致误报。

Method: 本文提出了CRAB模型，采用反向投影并利用雷达信息来减轻深度模糊。在视图转换过程中，CRAB将透视图图像上下文特征聚合到BEV查询中。它结合了图像中密集但不精确的深度分布与雷达占用中稀疏但精确的深度信息，以提高同一光线中查询的深度区分度。此外，还引入了包含雷达上下文信息的空间交叉注意力，以增强对3D场景的理解。

Result: 在nuScenes开放数据集上进行评估，CRAB在3D目标检测中达到了62.4%的NDS和54.0%的mAP，在基于反向投影的相机-雷达融合方法中实现了最先进的性能。

Conclusion: CRAB模型通过有效利用雷达信息解决了反向投影中深度模糊的问题，显著提升了相机-雷达融合3D目标检测的性能，达到了该类别方法的领先水平。

Abstract: Recently, camera-radar fusion-based 3D object detection methods in bird's eye
view (BEV) have gained attention due to the complementary characteristics and
cost-effectiveness of these sensors. Previous approaches using forward
projection struggle with sparse BEV feature generation, while those employing
backward projection overlook depth ambiguity, leading to false positives. In
this paper, to address the aforementioned limitations, we propose a novel
camera-radar fusion-based 3D object detection and segmentation model named CRAB
(Camera-Radar fusion for reducing depth Ambiguity in Backward projection-based
view transformation), using a backward projection that leverages radar to
mitigate depth ambiguity. During the view transformation, CRAB aggregates
perspective view image context features into BEV queries. It improves depth
distinction among queries along the same ray by combining the dense but
unreliable depth distribution from images with the sparse yet precise depth
information from radar occupancy. We further introduce spatial cross-attention
with a feature map containing radar context information to enhance the
comprehension of the 3D scene. When evaluated on the nuScenes open dataset, our
proposed approach achieves a state-of-the-art performance among backward
projection-based camera-radar fusion methods with 62.4\% NDS and 54.0\% mAP in
3D object detection.

</details>


### [111] [Dual-Mode Deep Anomaly Detection for Medical Manufacturing: Structural Similarity and Feature Distance](https://arxiv.org/abs/2509.05796)
*Julio Zanon Diaz,Georgios Siogkas,Peter Corcoran*

Main category: cs.CV

TL;DR: 本研究提出了两种基于注意力机制的自动编码器架构，用于医疗器械制造中的深度异常检测，以解决小数据集、高分辨率图像和严格监管要求等挑战，并提供了实时检测和生产后监控的互补能力。


<details>
  <summary>Details</summary>
Motivation: 医疗器械制造中的自动化视觉检测面临挑战，包括数据集小且不平衡、图像分辨率高以及严格的监管要求。

Method: 本文提出了两种基于注意力机制的自动编码器架构：1) 第一种采用基于结构相似性（4-MS-SSIM）的异常分数，用于轻量级、准确的实时缺陷检测。2) 第二种采用特征距离方法，在降维的潜在特征上使用马哈拉诺比斯（Mahalanobis）评分，以实现对分布变化的敏感监测。

Result: 第一种方法在Surface Seal Image测试集（10%缺陷样本）上，无监督阈值化准确率达0.903，有监督阈值化达0.931，支持可靠的在线检测。第二种方法在有监督阈值化下准确率达0.722，对分布变化具有高敏感性，适用于监督性监控。两种方法均超越了重新实现的基线。

Conclusion: 这些方法提供了互补的能力，支持可靠的在线检测和可扩展的生产后监控及法规遵从性。它们为在受监管的制造环境中部署深度异常检测提供了一条实用途径，符合欧盟人工智能法案对高风险AI系统的要求。

Abstract: Automating visual inspection in medical device manufacturing remains
challenging due to small and imbalanced datasets, high-resolution imagery, and
stringent regulatory requirements. This work proposes two attention-guided
autoencoder architectures for deep anomaly detection designed to address these
constraints. The first employs a structural similarity-based anomaly score
(4-MS-SSIM), offering lightweight and accurate real-time defect detection,
yielding ACC 0.903 (unsupervised thresholding) and 0.931 (supervised
thresholding) on the - Surface Seal Image - Test split with only 10% of
defective samples. The second applies a feature-distance approach using
Mahalanobis scoring on reduced latent features, providing high sensitivity to
distributional shifts for supervisory monitoring, achieving ACC 0.722 with
supervised thresholding. Together, these methods deliver complementary
capabilities: the first supports reliable inline inspection, while the second
enables scalable post-production surveillance and regulatory compliance
monitoring. Experimental results demonstrate that both approaches surpass
re-implemented baselines and provide a practical pathway for deploying deep
anomaly detection in regulated manufacturing environments, aligning accuracy,
efficiency, and the regulatory obligations defined for high-risk AI systems
under the EU AI Act.

</details>


### [112] [A Probabilistic Segment Anything Model for Ambiguity-Aware Medical Image Segmentation](https://arxiv.org/abs/2509.05809)
*Tyler Ward,Abdullah Imran*

Main category: cs.CV

TL;DR: 本文提出了Probabilistic SAM，一个SAM的概率扩展，通过建模分割分布来生成多样化且合理的分割掩模，以解决SAM在处理医学图像等任务中固有的歧义性问题。


<details>
  <summary>Details</summary>
Motivation: 像SAM这样的现有分割模型是确定性的，每个提示只生成一个分割，无法捕捉许多真实世界任务中固有的歧义性，尤其在医学成像中，由于标注不确定性或专家间差异，可能存在多个合理的分割。

Method: Probabilistic SAM通过整合一个潜在变量空间并使用变分目标进行训练，学习生成反映人类标注变异性的多样化分割掩模。该架构将一个先验和后验网络集成到SAM框架中，允许潜在代码在推理期间调节提示嵌入，从而在最小开销下实现高效采样和不确定性感知输出。

Result: 在公共LIDC-IDRI肺结节数据集上，Probabilistic SAM能够生成与专家分歧一致的多样化输出。在不确定性感知指标上，它优于现有概率基线，并且推理开销最小。

Conclusion: Probabilistic SAM通过引入概率建模，成功解决了SAM在处理固有歧义性任务（如医学图像分割）时的局限性，能够生成多样化、合理且不确定性感知的分割结果，与专家意见保持一致。

Abstract: Recent advances in promptable segmentation, such as the Segment Anything
Model (SAM), have enabled flexible, high-quality mask generation across a wide
range of visual domains. However, SAM and similar models remain fundamentally
deterministic, producing a single segmentation per object per prompt, and fail
to capture the inherent ambiguity present in many real-world tasks. This
limitation is particularly troublesome in medical imaging, where multiple
plausible segmentations may exist due to annotation uncertainty or inter-expert
variability. In this paper, we introduce Probabilistic SAM, a probabilistic
extension of SAM that models a distribution over segmentations conditioned on
both the input image and prompt. By incorporating a latent variable space and
training with a variational objective, our model learns to generate diverse and
plausible segmentation masks reflecting the variability in human annotations.
The architecture integrates a prior and posterior network into the SAM
framework, allowing latent codes to modulate the prompt embeddings during
inference. The latent space allows for efficient sampling during inference,
enabling uncertainty-aware outputs with minimal overhead. We evaluate
Probabilistic SAM on the public LIDC-IDRI lung nodule dataset and demonstrate
its ability to produce diverse outputs that align with expert disagreement,
outperforming existing probabilistic baselines on uncertainty-aware metrics.
Our code is available at: https://github.com/tbwa233/Probabilistic-SAM/.

</details>


### [113] [Challenges in Deep Learning-Based Small Organ Segmentation: A Benchmarking Perspective for Medical Research with Limited Datasets](https://arxiv.org/abs/2509.05892)
*Phongsakon Mark Konrad,Andrei-Alexandru Popa,Yaser Sabzehmeidani,Liang Zhong,Elisa A. Liehn,Serkan Ayvaz*

Main category: cs.CV

TL;DR: 本研究在有限的心血管组织病理图像数据集上，系统评估了包括CNNs、ViT和基础模型在内的多种深度学习分割模型。结果发现，模型性能对数据划分高度敏感，微小差异主要源于统计噪声而非算法优越性，这揭示了低数据临床环境中基准测试的局限性。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病研究和诊断中，颈动脉结构在组织病理图像中的精确分割至关重要。然而，由于带注释的心血管组织病理数据稀缺，限制了深度学习模型在该领域的发展。

Method: 研究系统评估了多种最先进的深度学习分割模型，包括卷积神经网络（U-Net, DeepLabV3+）、Vision Transformer（SegFormer）以及近期基础模型（SAM, MedSAM, MedSAM+UNet）。评估在一个有限的心血管组织学图像数据集上进行，并采用了贝叶斯搜索进行广泛的超参数优化策略。

Result: 尽管采用了广泛的超参数优化策略，研究发现模型性能对数据划分高度敏感。模型间微小的性能差异更多是由统计噪声而非真正的算法优越性驱动。

Conclusion: 这种不稳定性揭示了在低数据临床环境中，标准基准测试实践的局限性，并挑战了性能排名能够反映有意义临床效用的假设。

Abstract: Accurate segmentation of carotid artery structures in histopathological
images is vital for advancing cardiovascular disease research and diagnosis.
However, deep learning model development in this domain is constrained by the
scarcity of annotated cardiovascular histopathological data. This study
investigates a systematic evaluation of state-of-the-art deep learning
segmentation models, including convolutional neural networks (U-Net,
DeepLabV3+), a Vision Transformer (SegFormer), and recent foundation models
(SAM, MedSAM, MedSAM+UNet), on a limited dataset of cardiovascular histology
images. Despite employing an extensive hyperparameter optimization strategy
with Bayesian search, our findings reveal that model performance is highly
sensitive to data splits, with minor differences driven more by statistical
noise than by true algorithmic superiority. This instability exposes the
limitations of standard benchmarking practices in low-data clinical settings
and challenges the assumption that performance rankings reflect meaningful
clinical utility.

</details>


### [114] [BTCChat: Advancing Remote Sensing Bi-temporal Change Captioning with Multimodal Large Language Model](https://arxiv.org/abs/2509.05895)
*Yujie Li,Wenjia Xu,Yuanben Zhang,Zhiwei Wei,Mugen Peng*

Main category: cs.CV

TL;DR: BTCChat是一种先进的多时相多模态大语言模型（MLLM），通过设计变更提取模块和提示增强机制，显著提升了双时相图像的变更理解能力，并在变更描述和视觉问答任务上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在双时相变更分析中，通过直接拼接图像对的方式处理，未能充分建模时间相关性和空间语义变化，导致变更理解中的视觉-语义对齐不足，从而限制了整体效果。

Method: 本文提出了BTCChat，一个具有高级双时相变更理解能力的多时相MLLM。它包含一个“变更提取模块”来更好地捕获图像对中的时间特征和空间语义变化，以及一个“提示增强机制”来通过将上下文线索融入提示中，以增强模型对空间细节的关注。

Result: 实验结果表明，BTCChat在变更描述和视觉问答任务上均达到了最先进的性能。

Conclusion: BTCChat通过其创新的模块设计，有效解决了双时相变更分析中时间相关性和空间语义变化的建模不足问题，显著提升了模型的变更理解能力和对空间细节的关注，从而在相关任务上取得了卓越表现。

Abstract: Bi-temporal satellite imagery supports critical applications such as urban
development monitoring and disaster assessment. Although powerful multimodal
large language models (MLLMs) have been applied in bi-temporal change analysis,
previous methods process image pairs through direct concatenation, inadequately
modeling temporal correlations and spatial semantic changes. This deficiency
hampers visual-semantic alignment in change understanding, thereby constraining
the overall effectiveness of current approaches. To address this gap, we
propose BTCChat, a multi-temporal MLLM with advanced bi-temporal change
understanding capability. BTCChat supports bi-temporal change captioning and
retains single-image interpretation capability. To better capture temporal
features and spatial semantic changes in image pairs, we design a Change
Extraction module. Moreover, to enhance the model's attention to spatial
details, we introduce a Prompt Augmentation mechanism, which incorporates
contextual clues into the prompt to enhance model performance. Experimental
results demonstrate that BTCChat achieves state-of-the-art performance on
change captioning and visual question answering tasks.

</details>


### [115] [ConstStyle: Robust Domain Generalization with Unified Style Transformation](https://arxiv.org/abs/2509.05975)
*Nam Duong Tran,Nam Nguyen Phuong,Hieu H. Pham,Phi Le Nguyen,My T. Thai*

Main category: cs.CV

TL;DR: ConstStyle是一种新颖的域泛化方法，通过将所有训练和测试样本映射到一个统一域来捕捉域不变特征并弥合域差距，从而有效应对域偏移，尤其在训练域有限或域差距较大时表现优异。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在训练和测试数据分布不同时性能会下降。现有的域泛化（DG）方法，如关注域不变特征或数据增强，在训练域有限或已知与未知域之间存在显著差距时，往往表现不佳。

Method: 本文提出了ConstStyle方法。该方法利用一个统一域来捕获域不变特征并弥合域差距。在训练阶段，所有样本都被映射到这个为已知域优化的统一域中。在测试阶段，未知域样本在预测前也以类似方式投影到该统一域中。通过在统一域中对齐训练和测试数据，该方法有效减少了域偏移的影响。

Result: 广泛的实验表明，ConstStyle在各种场景下持续优于现有方法。值得注意的是，当可用训练域数量有限时，ConstStyle的准确性比次优方法提高了高达19.82%。

Conclusion: ConstStyle通过引入统一域的概念，成功地增强了域泛化的鲁棒性，有效解决了有限训练域和巨大域差距带来的挑战，并在实验中展现出显著的性能提升。

Abstract: Deep neural networks often suffer performance drops when test data
distribution differs from training data. Domain Generalization (DG) aims to
address this by focusing on domain-invariant features or augmenting data for
greater diversity. However, these methods often struggle with limited training
domains or significant gaps between seen (training) and unseen (test) domains.
To enhance DG robustness, we hypothesize that it is essential for the model to
be trained on data from domains that closely resemble unseen test domains-an
inherently difficult task due to the absence of prior knowledge about the
unseen domains. Accordingly, we propose ConstStyle, a novel approach that
leverages a unified domain to capture domain-invariant features and bridge the
domain gap with theoretical analysis. During training, all samples are mapped
onto this unified domain, optimized for seen domains. During testing, unseen
domain samples are projected similarly before predictions. By aligning both
training and testing data within this unified domain, ConstStyle effectively
reduces the impact of domain shifts, even with large domain gaps or few seen
domains. Extensive experiments demonstrate that ConstStyle consistently
outperforms existing methods across diverse scenarios. Notably, when only a
limited number of seen domains are available, ConstStyle can boost accuracy up
to 19.82\% compared to the next best approach.

</details>


### [116] [A Fine-Grained Attention and Geometric Correspondence Model for Musculoskeletal Risk Classification in Athletes Using Multimodal Visual and Skeletal Features](https://arxiv.org/abs/2509.05913)
*Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Tamanna Shermin,Md Rafiqul Islam,Mukhtar Hussain,Sami Azam*

Main category: cs.CV

TL;DR: 本研究提出了一种名为ViSK-GAT的新型多模态深度学习框架，通过结合视觉和骨骼坐标数据，对肌肉骨骼疾病风险进行分类，并在定制数据集上取得了93%以上的高准确率，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有肌肉骨骼疾病风险评估方法主要针对受控环境设计，且依赖单一数据类型，导致在复杂环境中评估不可靠。早期风险评估对预防至关重要。

Method: 研究构建了一个包含视觉数据和骨骼坐标的定制多模态数据集，并根据REBA系统将样本标记为八个风险类别。提出ViSK-GAT框架，结合残差块和轻量级Transformer块来共同学习时空依赖性。该框架包含两个新模块：细粒度注意力模块（FGAM），通过视觉和骨骼输入之间的交叉注意力实现模态间特征细化；多模态几何对应模块（MGCM），通过将图像特征与基于坐标的表示对齐来增强跨模态一致性。

Result: ViSK-GAT在验证集和测试集上分别取得了93.55%和93.89%的准确率，精确率为93.86%，F1分数为93.85%，Cohen's Kappa和Matthews相关系数均为93%。回归结果显示预测概率分布的均方根误差为0.1205，平均绝对误差为0.0156。与九种流行的迁移学习骨干网络相比，ViSK-GAT表现持续优于现有方法。

Conclusion: ViSK-GAT模型在肌肉骨骼风险分类方面推动了人工智能的实施和应用，有望通过早期干预对运动领域产生深远影响。

Abstract: Musculoskeletal disorders pose significant risks to athletes, and assessing
risk early is important for prevention. However, most existing methods are
designed for controlled settings and fail to reliably assess risk in complex
environments due to their reliance on a single type of data. This research
proposes ViSK-GAT (Visual-Skeletal Geometric Attention Transformer), a novel
multimodal deep learning framework designed to classify musculoskeletal risk
using visual and skeletal coordinate-based features. In addition, a custom
multimodal dataset is constructed by combining visual data and skeletal
coordinates for risk assessment. Each sample is labeled into eight risk
categories based on the Rapid Entire Body Assessment system. ViSK-GAT combines
a Residual Block with a Lightweight Transformer Block to learn spatial and
temporal dependencies jointly. It incorporates two novel modules: the
Fine-Grained Attention Module (FGAM), which enables precise inter-modal feature
refinement through cross-attention between visual and skeletal inputs, and the
Multimodal Geometric Correspondence Module (MGCM), which enhances cross-modal
coherence by aligning image features with coordinate-based representations.
ViSK-GAT achieved strong performance with validation and test accuracies of
93.55\% and 93.89\%, respectively; a precision of 93.86\%; an F1 score of
93.85\%; and Cohen's Kappa and Matthews Correlation Coefficient of 93\%. The
regression results also indicated a low Root Mean Square Error of the predicted
probability distribution of 0.1205 and a corresponding Mean Absolute Error of
0.0156. Compared to nine popular transfer learning backbones, ViSK-GAT
consistently outperformed previous methods. The ViSK-GAT model advances
artificial intelligence implementation and application, transforming
musculoskeletal risk classification and enabling impactful early interventions
in sports.

</details>


### [117] [S-LAM3D: Segmentation-Guided Monocular 3D Object Detection via Feature Space Fusion](https://arxiv.org/abs/2509.05999)
*Diana-Alexandra Sas,Florin Oniga*

Main category: cs.CV

TL;DR: 本文提出了一种解耦策略，通过将预计算的分割先验信息直接融入特征空间，来增强单目3D目标检测，尤其在不增加模型复杂度的前提下，提升了对行人、骑行者等小型目标的检测性能。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测因输入仅为2D图像而缺乏深度信息，是一个难题。现有解决方案依赖于CNN或Transformer进行特征提取，但仍面临深度估计的挑战。研究旨在不扩展检测模型或联合学习先验的情况下，提高单目3D检测的性能。

Method: 引入了一种解耦策略：将预先计算的分割信息先验直接注入到特征空间中，以指导检测。该方法不扩展检测模型，也不联合学习先验，而是专注于评估额外分割信息对现有检测管线的影响，且不增加额外的预测分支。

Result: 在KITTI 3D目标检测基准上进行评估，结果表明，与仅依赖RGB图像特征的等效架构相比，该方法在场景中的小型目标（如行人、骑行者）上表现更优。

Conclusion: 研究证明，理解输入数据（通过注入分割先验）可以平衡对额外传感器或训练数据的需求，有效提升单目3D目标检测的性能，尤其对于小型对象。

Abstract: Monocular 3D Object Detection represents a challenging Computer Vision task
due to the nature of the input used, which is a single 2D image, lacking in any
depth cues and placing the depth estimation problem as an ill-posed one.
Existing solutions leverage the information extracted from the input by using
Convolutional Neural Networks or Transformer architectures as feature
extraction backbones, followed by specific detection heads for 3D parameters
prediction. In this paper, we introduce a decoupled strategy based on injecting
precomputed segmentation information priors and fusing them directly into the
feature space for guiding the detection, without expanding the detection model
or jointly learning the priors. The focus is on evaluating the impact of
additional segmentation information on existing detection pipelines without
adding additional prediction branches. The proposed method is evaluated on the
KITTI 3D Object Detection Benchmark, outperforming the equivalent architecture
that relies only on RGB image features for small objects in the scene:
pedestrians and cyclists, and proving that understanding the input data can
balance the need for additional sensors or training data.

</details>


### [118] [Compression Beyond Pixels: Semantic Compression with Multimodal Foundation Models](https://arxiv.org/abs/2509.05925)
*Ruiqi Shen,Haotian Wu,Wenjing Zhang,Jiangjing Hu,Deniz Gunduz*

Main category: cs.CV

TL;DR: 本文提出了一种基于CLIP模型的语义图像压缩方法，通过压缩CLIP特征嵌入而非原始图像，在极低比特率下实现了卓越的语义信息保持和零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统的深度学习图像压缩侧重于像素级重建，但新兴应用更强调语义保持、跨数据分布的鲁棒性以及对下游任务的支持。多模态基础模型（如CLIP）的零样本和表征能力为此提供了灵感。

Method: 该方法不直接压缩图像以供重建，而是将CLIP模型的特征嵌入压缩成最小比特，旨在跨不同任务保留语义信息。

Result: 实验表明，该方法在基准数据集上保持了语义完整性，平均比特率约为2-3 * 10^-3 bpp，仅为主流图像压缩方法在可比性能下所需比特率的不到5%。即使在极端压缩下，该方法仍表现出跨不同数据分布和下游任务的零样本鲁棒性。

Conclusion: 所提出的基于CLIP的语义压缩方法显著降低了比特率，同时有效保留了语义完整性，并展现出强大的零样本鲁棒性，满足了新兴应用对语义压缩的需求。

Abstract: Recent deep learning-based methods for lossy image compression achieve
competitive rate-distortion performance through extensive end-to-end training
and advanced architectures. However, emerging applications increasingly
prioritize semantic preservation over pixel-level reconstruction and demand
robust performance across diverse data distributions and downstream tasks.
These challenges call for advanced semantic compression paradigms. Motivated by
the zero-shot and representational capabilities of multimodal foundation
models, we propose a novel semantic compression method based on the contrastive
language-image pretraining (CLIP) model. Rather than compressing images for
reconstruction, we propose compressing the CLIP feature embeddings into minimal
bits while preserving semantic information across different tasks. Experiments
show that our method maintains semantic integrity across benchmark datasets,
achieving an average bit rate of approximately 2-3* 10(-3) bits per pixel. This
is less than 5% of the bitrate required by mainstream image compression
approaches for comparable performance. Remarkably, even under extreme
compression, the proposed approach exhibits zero-shot robustness across diverse
data distributions and downstream tasks.

</details>


### [119] [Khana: A Comprehensive Indian Cuisine Dataset](https://arxiv.org/abs/2509.06006)
*Omkar Prabhu*

Main category: cs.CV

TL;DR: 本文介绍了Khana，一个用于印度菜肴图像分类、分割和检索的新基准数据集，旨在填补现有数据集中印度菜肴多样性覆盖不足的空白。


<details>
  <summary>Details</summary>
Motivation: 随着全球对多样化烹饪体验的兴趣日益增长，食物图像模型在食品相关应用中至关重要。然而，尽管食物数据集丰富，但由于印度菜肴的区域多样性、复杂制备和缺乏全面的标注数据集，现有数据集未能充分捕捉其细微差别。

Method: 研究团队创建了Khana数据集，建立了印度菜肴的分类体系，并收集了约13.1万张图片，涵盖80个标签，每张图片分辨率为500x500像素。论文描述了数据集创建过程，并评估了最先进的模型在分类、分割和检索任务上的表现作为基线。

Result: Khana数据集成功弥补了印度菜肴数据集中存在的空白，提供了包含约13.1万张图像（涵盖80种印度菜肴）的综合性资源，并为分类、分割和检索任务设定了基线性能。

Conclusion: Khana数据集为研究人员提供了一个全面且具有挑战性的基准，同时也是开发人员创建利用印度丰富烹饪文化的应用的宝贵资源，从而弥合了研究与开发之间的鸿沟。

Abstract: As global interest in diverse culinary experiences grows, food image models
are essential for improving food-related applications by enabling accurate food
recognition, recipe suggestions, dietary tracking, and automated meal planning.
Despite the abundance of food datasets, a noticeable gap remains in capturing
the nuances of Indian cuisine due to its vast regional diversity, complex
preparations, and the lack of comprehensive labeled datasets that cover its
full breadth. Through this exploration, we uncover Khana, a new benchmark
dataset for food image classification, segmentation, and retrieval of dishes
from Indian cuisine. Khana fills the gap by establishing a taxonomy of Indian
cuisine and offering around 131K images in the dataset spread across 80 labels,
each with a resolution of 500x500 pixels. This paper describes the dataset
creation process and evaluates state-of-the-art models on classification,
segmentation, and retrieval as baselines. Khana bridges the gap between
research and development by providing a comprehensive and challenging benchmark
for researchers while also serving as a valuable resource for developers
creating real-world applications that leverage the rich tapestry of Indian
cuisine. Webpage: https://khana.omkar.xyz

</details>


### [120] [AttriPrompt: Dynamic Prompt Composition Learning for CLIP](https://arxiv.org/abs/2509.05949)
*Qiqi Zhan,Shiwei Li,Qingjie Liu,Yunhong Wang*

Main category: cs.CV

TL;DR: AttriPrompt是一种新颖的深度文本提示框架，通过利用CLIP视觉编码器的中间层特征和引入属性检索、双流对比学习和自正则化机制，解决了现有方法对对比学习的过度依赖和提示静态性的问题，显著提升了模型性能和跨域知识迁移能力。


<details>
  <summary>Details</summary>
Motivation: 当前的深度文本提示方法存在两个主要限制：1. 过度依赖对比学习目标，侧重于高层语义对齐而忽视细粒度特征优化。2. 提示在所有输入类别中都是静态的，缺乏内容感知适应性。

Method: 本文提出了AttriPrompt框架。它首先设计了一个属性检索模块，该模块对CLIP视觉编码器每一层的视觉特征进行聚类，然后从提示池中检索语义相似的提示，并将其连接到文本编码器每一层的输入。接着，利用提示文本特征中嵌入的层次视觉信息，引入了双流对比学习以实现细粒度对齐。此外，通过在有提示和无提示文本特征之间应用显式正则化约束，引入了自正则化机制，以防止在有限训练数据上过拟合。

Result: AttriPrompt在三个基准测试中表现出优于现有方法的性能，在“从基础到新颖”设置中实现了高达7.37%的改进。该方法在跨域知识迁移方面的强大能力，使得视觉-语言预训练模型成为更可行的实际应用解决方案。

Conclusion: AttriPrompt通过有效利用视觉编码器的中间层特征并引入创新的学习机制，成功克服了现有深度文本提示方法的局限性，显著提升了模型性能和跨域泛化能力，为视觉-语言预训练模型在实际世界中的应用开辟了新途径。

Abstract: The evolution of prompt learning methodologies has driven exploration of
deeper prompt designs to enhance model performance. However, current deep text
prompting approaches suffer from two critical limitations: Over-reliance on
constrastive learning objectives that prioritize high-level semantic alignment,
neglecting fine-grained feature optimization; Static prompts across all input
categories, preventing content-aware adaptation. To address these limitations,
we propose AttriPrompt-a novel framework that enhances and refines textual
semantic representations by leveraging the intermediate-layer features of
CLIP's vision encoder. We designed an Attribute Retrieval module that first
clusters visual features from each layer. The aggregated visual features
retrieve semantically similar prompts from a prompt pool, which are then
concatenated to the input of every layer in the text encoder. Leveraging
hierarchical visual information embedded in prompted text features, we
introduce Dual-stream Contrastive Learning to realize fine-grained alignment.
Furthermore, we introduce a Self-Regularization mechanism by applying explicit
regularization constraints between the prompted and non-prompted text features
to prevent overfitting on limited training data. Extensive experiments across
three benchmarks demonstrate AttriPrompt's superiority over state-of-the-art
methods, achieving up to 7.37\% improvement in the base-to-novel setting. The
observed strength of our method in cross-domain knowledge transfer positions
vision-language pre-trained models as more viable solutions for real-world
implementation.

</details>


### [121] [TinyDef-DETR:An Enhanced DETR Detector for UAV Power Line Defect Detection](https://arxiv.org/abs/2509.06035)
*Jiaming Cui*

Main category: cs.CV

TL;DR: 本文提出TinyDef-DETR框架，通过无步长降采样、边缘增强卷积、双域多尺度注意力及Focaler-Wise-SIoU损失，有效解决了无人机输电线路巡检中小缺陷检测的难题。


<details>
  <summary>Details</summary>
Motivation: 现有检测器在复杂背景下检测无人机输电线路中的微小模糊缺陷时面临挑战，具体表现为步长降采样导致细节丢失、轻量级骨干网络边界敏感性弱以及全局上下文与局部线索融合不足。

Method: 本文提出了TinyDef-DETR，一个基于DETR的框架，包含：1) 无步长空-深模块实现无损降采样；2) 边缘增强卷积用于边界感知特征提取；3) 跨阶段双域多尺度注意力模块共同捕获全局和局部信息；4) Focaler-Wise-SIoU回归损失以改进小目标定位。

Result: 在CSG-ADCD数据集上的实验表明，TinyDef-DETR在精度和召回率上均显著优于现有基线，尤其在小目标子集上表现突出，同时计算开销适中。在VisDrone基准测试上的进一步验证也证实了该方法的泛化能力。

Conclusion: 研究结果表明，整合细节保留降采样、边缘敏感表示、双域注意力以及难度自适应回归，为电力电网中基于无人机的小缺陷检测提供了一个实用且高效的解决方案。

Abstract: Automated inspection of transmission lines using UAVs is hindered by the
difficulty of detecting small and ambiguous defects against complex
backgrounds. Conventional detectors often suffer from detail loss due to
strided downsampling, weak boundary sensitivity in lightweight backbones, and
insufficient integration of global context with local cues. To address these
challenges, we propose TinyDef-DETR, a DETR-based framework designed for
small-defect detection. The method introduces a stride-free space-to-depth
module for lossless downsampling, an edge-enhanced convolution for
boundary-aware feature extraction, a cross-stage dual-domain multi-scale
attention module to jointly capture global and local information, and a
Focaler-Wise-SIoU regression loss to improve localization of small objects.
Experiments conducted on the CSG-ADCD dataset demonstrate that TinyDef-DETR
achieves substantial improvements in both precision and recall compared to
competitive baselines, with particularly notable gains on small-object subsets,
while incurring only modest computational overhead. Further validation on the
VisDrone benchmark confirms the generalization capability of the proposed
approach. Overall, the results indicate that integrating detail-preserving
downsampling, edge-sensitive representations, dual-domain attention, and
difficulty-adaptive regression provides a practical and efficient solution for
UAV-based small-defect inspection in power grids.

</details>


### [122] [Coefficients-Preserving Sampling for Reinforcement Learning with Flow Matching](https://arxiv.org/abs/2509.05952)
*Feng Wang,Zihao Yu*

Main category: cs.CV

TL;DR: 本文提出了一种名为系数保持采样（CPS）的新方法，用于解决在线强化学习应用于Flow Matching模型时，SDE采样引入的噪声伪影问题。CPS消除了这些噪声，从而实现了更准确的奖励建模，并加速了RL优化器的收敛。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）在改善扩散和Flow Matching模型的图像/视频生成质量和与提示对齐方面表现出色。然而，将在线RL应用于Flow Matching需要引入随机性，通常通过随机微分方程（SDE）实现。研究发现SDE采样会引入明显的噪声伪影，严重损害奖励学习过程。

Method: 通过严格的理论分析，作者将噪声的来源追溯到推理过程中注入的过度随机性。受Denoising Diffusion Implicit Models（DDIM）的启发，本文重新制定了采样过程，并提出了系数保持采样（Coefficients-Preserving Sampling, CPS）方法，旨在消除这些噪声伪影。

Result: 所提出的CPS方法成功消除了生成的图像中的噪声伪影。这导致了更准确的奖励建模，并最终使得基于强化学习的优化器（如Flow-GRPO和Dance-GRPO）能够实现更快、更稳定的收敛。

Conclusion: CPS方法有效解决了SDE采样在Flow Matching中引入的噪声问题，从而显著提升了强化学习在图像生成任务中的性能，实现了更稳定和快速的训练收敛。

Abstract: Reinforcement Learning (RL) has recently emerged as a powerful technique for
improving image and video generation in Diffusion and Flow Matching models,
specifically for enhancing output quality and alignment with prompts. A
critical step for applying online RL methods on Flow Matching is the
introduction of stochasticity into the deterministic framework, commonly
realized by Stochastic Differential Equation (SDE). Our investigation reveals a
significant drawback to this approach: SDE-based sampling introduces pronounced
noise artifacts in the generated images, which we found to be detrimental to
the reward learning process. A rigorous theoretical analysis traces the origin
of this noise to an excess of stochasticity injected during inference. To
address this, we draw inspiration from Denoising Diffusion Implicit Models
(DDIM) to reformulate the sampling process. Our proposed method,
Coefficients-Preserving Sampling (CPS), eliminates these noise artifacts. This
leads to more accurate reward modeling, ultimately enabling faster and more
stable convergence for reinforcement learning-based optimizers like Flow-GRPO
and Dance-GRPO. Code will be released at https://github.com/IamCreateAI/FlowCPS

</details>


### [123] [BranchGRPO: Stable and Efficient GRPO with Structured Branching in Diffusion Models](https://arxiv.org/abs/2509.06040)
*Yuming Li,Yikai Wang,Yuying Zhu,Zhongyu Zhao,Ming Lu,Qi She,Shanghang Zhang*

Main category: cs.CV

TL;DR: BranchGRPO通过引入分支采样策略和树状优势估计器，显著降低了图像和视频生成模型对齐的计算成本和训练时间，同时提高了对齐分数。


<details>
  <summary>Details</summary>
Motivation: 现有的基于GRPO的图像和视频生成模型对齐方法面临高昂的计算成本（策略内采样、SDE采样步骤过多）和由于稀疏奖励导致的训练不稳定问题。

Method: 本文提出了BranchGRPO，一种新颖的方法，通过引入分支采样策略来更新SDE采样过程。它通过共享共同前缀的计算、修剪低奖励路径和冗余深度来大幅降低每次更新的计算成本。此外，它还采用了一个结合密集过程级奖励的树状优势估计器，以及利用路径和深度冗余的剪枝策略。

Result: 在图像和视频偏好对齐实验中，BranchGRPO将对齐分数比现有强大基线提高了16%，同时将训练时间缩短了50%。

Conclusion: BranchGRPO通过其分支采样方案、树状优势估计器和剪枝策略，有效解决了现有GRPO方法的计算成本高和训练不稳定性问题，实现了更好的对齐性能和更快的收敛速度。

Abstract: Recent advancements in aligning image and video generative models via GRPO
have achieved remarkable gains in enhancing human preference alignment.
However, these methods still face high computational costs from on-policy
rollouts and excessive SDE sampling steps, as well as training instability due
to sparse rewards. In this paper, we propose BranchGRPO, a novel method that
introduces a branch sampling policy updating the SDE sampling process. By
sharing computation across common prefixes and pruning low-reward paths and
redundant depths, BranchGRPO substantially lowers the per-update compute cost
while maintaining or improving exploration diversity. This work makes three
main contributions: (1) a branch sampling scheme that reduces rollout and
training cost; (2) a tree-based advantage estimator incorporating dense
process-level rewards; and (3) pruning strategies exploiting path and depth
redundancy to accelerate convergence and boost performance. Experiments on
image and video preference alignment show that BranchGRPO improves alignment
scores by 16% over strong baselines, while cutting training time by 50%.

</details>


### [124] [Dual Interaction Network with Cross-Image Attention for Medical Image Segmentation](https://arxiv.org/abs/2509.05953)
*Jeonghyun Noh,Wangsu Jeon,Jinsun Park*

Main category: cs.CV

TL;DR: 本文提出了一种双向交互融合模块（DIFM）和多尺度边界损失，用于有效融合原始和增强医学图像，以提高图像分割精度，尤其是在边界区域。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临噪声、模糊和低对比度等挑战。虽然图像增强技术可以缓解这些问题，但也可能改变原始图像中的关键诊断信息。传统的图像融合策略（如特征拼接）难以充分利用原始和增强图像的优势，并抑制增强的副作用。

Method: 本文提出了一种双向交互融合模块（DIFM），通过双向交叉注意力机制同步关注不同图像中的空间信息，并通过全局空间注意力细化互补特征，从而有效利用原始和增强图像的互补信息。DIFM 利用从低级到高级的特征（如边缘、斑点、对象形状）。此外，还引入了一种基于梯度提取的多尺度边界损失，以提高对象边界的分割精度。

Result: 在ACDC和Synapse数据集上的实验结果表明，所提出的方法在定量和定性上都优于现有方法。

Conclusion: 所提出的双向交互融合模块和多尺度边界损失能够有效融合原始和增强医学图像，充分利用互补信息并抑制增强的副作用，从而显著提高了医学图像分割的准确性，尤其是在对象边界处。

Abstract: Medical image segmentation is a crucial method for assisting professionals in
diagnosing various diseases through medical imaging. However, various factors
such as noise, blurriness, and low contrast often hinder the accurate diagnosis
of diseases. While numerous image enhancement techniques can mitigate these
issues, they may also alter crucial information needed for accurate diagnosis
in the original image. Conventional image fusion strategies, such as feature
concatenation can address this challenge. However, they struggle to fully
leverage the advantages of both original and enhanced images while suppressing
the side effects of the enhancements. To overcome the problem, we propose a
dual interactive fusion module (DIFM) that effectively exploits mutual
complementary information from the original and enhanced images. DIFM employs
cross-attention bidirectionally to simultaneously attend to corresponding
spatial information across different images, subsequently refining the
complementary features via global spatial attention. This interaction leverages
low- to high-level features implicitly associated with diverse structural
attributes like edges, blobs, and object shapes, resulting in enhanced features
that embody important spatial characteristics. In addition, we introduce a
multi-scale boundary loss based on gradient extraction to improve segmentation
accuracy at object boundaries. Experimental results on the ACDC and Synapse
datasets demonstrate the superiority of the proposed method quantitatively and
qualitatively. Code available at: https://github.com/JJeong-Gari/DIN

</details>


### [125] [SpecSwin3D: Generating Hyperspectral Imagery from Multispectral Data via Transformer Networks](https://arxiv.org/abs/2509.06122)
*Tang Sui,Songxi Yang,Qunying Huang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为SpecSwin3D的基于Transformer的模型，能够从多光谱图像生成高空间和光谱质量的高光谱图像，并优于现有方法，在下游任务中也表现出色。


<details>
  <summary>Details</summary>
Motivation: 多光谱和高光谱图像在空间和光谱分辨率上存在固有的权衡（多光谱空间分辨率高但光谱有限，高光谱光谱丰富但空间分辨率低）。现有的高光谱生成方法（如全色锐化、矩阵分解、CNNs）难以同时保持空间细节和光谱保真度。

Method: 该研究提出了SpecSwin3D，一个基于Transformer的模型，以五个多光谱波段为输入，重建224个相同空间分辨率的高光谱波段。为解决重建误差随波段光谱距离增加的问题，引入了级联训练策略来逐步扩展光谱范围。此外，设计了一种优化的波段序列，战略性地重复和排列五个选定的多光谱波段，以更好地捕获3D shifted-window Transformer框架内的成对关系。

Result: SpecSwin3D模型在定量评估中表现出色，实现了35.82 dB的PSNR、2.40°的SAM和0.96的SSIM，与基线MHF-Net相比，PSNR提高了+5.6 dB，ERGAS减少了一半以上。除了重建，该模型在土地利用分类和烧毁区域分割这两个下游任务中也展现了实用价值。

Conclusion: SpecSwin3D模型有效解决了多光谱到高光谱图像生成中空间细节和光谱保真度难以兼顾的问题。通过创新的Transformer架构、级联训练策略和优化的波段序列，显著提升了高光谱图像的重建质量，并在实际应用中展现了其潜力。

Abstract: Multispectral and hyperspectral imagery are widely used in agriculture,
environmental monitoring, and urban planning due to their complementary spatial
and spectral characteristics. A fundamental trade-off persists: multispectral
imagery offers high spatial but limited spectral resolution, while
hyperspectral imagery provides rich spectra at lower spatial resolution. Prior
hyperspectral generation approaches (e.g., pan-sharpening variants, matrix
factorization, CNNs) often struggle to jointly preserve spatial detail and
spectral fidelity. In response, we propose SpecSwin3D, a transformer-based
model that generates hyperspectral imagery from multispectral inputs while
preserving both spatial and spectral quality. Specifically, SpecSwin3D takes
five multispectral bands as input and reconstructs 224 hyperspectral bands at
the same spatial resolution. In addition, we observe that reconstruction errors
grow for hyperspectral bands spectrally distant from the input bands. To
address this, we introduce a cascade training strategy that progressively
expands the spectral range to stabilize learning and improve fidelity.
Moreover, we design an optimized band sequence that strategically repeats and
orders the five selected multispectral bands to better capture pairwise
relations within a 3D shifted-window transformer framework. Quantitatively, our
model achieves a PSNR of 35.82 dB, SAM of 2.40{\deg}, and SSIM of 0.96,
outperforming the baseline MHF-Net by +5.6 dB in PSNR and reducing ERGAS by
more than half. Beyond reconstruction, we further demonstrate the practical
value of SpecSwin3D on two downstream tasks, including land use classification
and burnt area segmentation.

</details>


### [126] [StripDet: Strip Attention-Based Lightweight 3D Object Detection from Point Cloud](https://arxiv.org/abs/2509.05954)
*Weichao Wang,Wendong Mao,Zhongfeng Wang*

Main category: cs.CV

TL;DR: StripDet是一个轻量级3D目标检测框架，通过引入条带注意力模块和硬件友好型骨干网络，显著降低了计算和内存需求，实现了在边缘设备上高效准确的3D检测。


<details>
  <summary>Details</summary>
Motivation: 高精度3D点云目标检测模型通常需要大量的计算和内存资源，这严重阻碍了它们在边缘设备上的部署。

Method: 该研究提出了StripDet框架：1. 引入了条带注意力块（SAB），通过将标准2D卷积分解为非对称条带卷积，以线性复杂度高效捕获长距离空间依赖。2. 设计了一个硬件友好的分层骨干网络，将SAB与深度可分离卷积和简单的多尺度融合策略相结合，实现了端到端的高效性。

Result: 在KITTI数据集上，StripDet仅用0.65M参数就实现了79.97%的汽车检测mAP，参数量比PointPillars基线减少了7倍，同时性能更优。它在精度-效率权衡方面超越了现有的轻量级和基于知识蒸馏的方法。

Conclusion: StripDet为边缘设备上的实时3D检测提供了一个实用的解决方案，在实现卓越准确性的同时，保持了极高的效率。

Abstract: The deployment of high-accuracy 3D object detection models from point cloud
remains a significant challenge due to their substantial computational and
memory requirements. To address this, we introduce StripDet, a novel
lightweight framework designed for on-device efficiency. First, we propose the
novel Strip Attention Block (SAB), a highly efficient module designed to
capture long-range spatial dependencies. By decomposing standard 2D
convolutions into asymmetric strip convolutions, SAB efficiently extracts
directional features while reducing computational complexity from quadratic to
linear. Second, we design a hardware-friendly hierarchical backbone that
integrates SAB with depthwise separable convolutions and a simple multiscale
fusion strategy, achieving end-to-end efficiency. Extensive experiments on the
KITTI dataset validate StripDet's superiority. With only 0.65M parameters, our
model achieves a 79.97% mAP for car detection, surpassing the baseline
PointPillars with a 7x parameter reduction. Furthermore, StripDet outperforms
recent lightweight and knowledge distillation-based methods, achieving a
superior accuracy-efficiency trade-off while establishing itself as a practical
solution for real-world 3D detection on edge devices.

</details>


### [127] [UNO: Unifying One-stage Video Scene Graph Generation via Object-Centric Visual Representation Learning](https://arxiv.org/abs/2509.06165)
*Huy Le,Nhat Chung,Tung Kieu,Jingkang Yang,Ngan Le*

Main category: cs.CV

TL;DR: UNO是一个统一的单阶段框架，通过扩展槽注意力、对象时间一致性学习和动态三元组预测，同时解决了粗粒度框级和细粒度像素级视频场景图生成（VidSGG）任务，实现了竞争性性能和更高的效率。


<details>
  <summary>Details</summary>
Motivation: 先前的视频场景图生成（VidSGG）研究通常针对粗粒度的框级或细粒度的像素级任务，并且通常需要特定任务的架构和多阶段训练流程。研究动机是开发一个统一的框架，能够同时处理这两种粒度，减少任务特定修改并最大化参数共享。

Method: 本文提出了UNO（UNified Object-centric VidSGG），一个单阶段、端到端的统一框架。其核心是一个扩展的槽注意力机制，将视觉特征分解为对象槽和关系槽。为确保鲁棒的时间建模，引入了对象时间一致性学习，无需显式跟踪模块即可强制跨帧的对象表示一致性。此外，一个动态三元组预测模块将关系槽链接到相应的对象对，以捕捉随时间演变的关系。

Result: UNO在标准的框级和像素级VidSGG基准测试中均取得了竞争性性能。同时，通过其统一的、以对象为中心的设计，UNO还提高了效率。

Conclusion: UNO成功地在一个统一的、单阶段、以对象为中心的架构中解决了框级和像素级VidSGG任务，不仅达到了有竞争力的性能，而且在效率上也有所提升，展示了其在不同视觉粒度上的泛化能力。

Abstract: Video Scene Graph Generation (VidSGG) aims to represent dynamic visual
content by detecting objects and modeling their temporal interactions as
structured graphs. Prior studies typically target either coarse-grained
box-level or fine-grained panoptic pixel-level VidSGG, often requiring
task-specific architectures and multi-stage training pipelines. In this paper,
we present UNO (UNified Object-centric VidSGG), a single-stage, unified
framework that jointly addresses both tasks within an end-to-end architecture.
UNO is designed to minimize task-specific modifications and maximize parameter
sharing, enabling generalization across different levels of visual granularity.
The core of UNO is an extended slot attention mechanism that decomposes visual
features into object and relation slots. To ensure robust temporal modeling, we
introduce object temporal consistency learning, which enforces consistent
object representations across frames without relying on explicit tracking
modules. Additionally, a dynamic triplet prediction module links relation slots
to corresponding object pairs, capturing evolving interactions over time. We
evaluate UNO on standard box-level and pixel-level VidSGG benchmarks. Results
demonstrate that UNO not only achieves competitive performance across both
tasks but also offers improved efficiency through a unified, object-centric
design.

</details>


### [128] [Neural Bloom: A Deep Learning Approach to Real-Time Lighting](https://arxiv.org/abs/2509.05963)
*Rafal Karp,Dawid Gruszka,Tomasz Trzcinski*

Main category: cs.CV

TL;DR: 本文提出两种基于神经网络的实时泛光（bloom）渲染方法（NBL和FastNBL），它们在保持高质量的同时，比现有技术分别快12%和28%，有效提升了实时渲染效率。


<details>
  <summary>Details</summary>
Motivation: 现有传统泛光渲染技术依赖多重模糊、纹理采样和条件分支，这些操作占据大量执行时间，成为实时渲染的瓶颈，影响了沉浸感和高帧率环境下的流畅体验。

Method: 本文提出两种基于神经网络的泛光渲染方法：Neural Bloom Lighting (NBL) 和 Fast Neural Bloom Lighting (FastNBL)。这些方法通过神经网络生成亮度掩码，以规避传统方法的计算开销，并在多种3D场景中测试其质量和推理速度。

Result: NBL和FastNBL均能生成高质量的泛光效果。与现有最先进的泛光实现相比，FastNBL速度提升28%，NBL速度提升12%，尤其在亮度掩码生成方面，速度提升高达30%。

Conclusion: 研究表明，通过神经网络可以更快地实现逼真的泛光效果，从而节省计算资源，解决实时渲染中的主要瓶颈，并有助于在未来实时环境中实现更高的真实感，同时保持高帧率和沉浸式体验。

Abstract: We propose a novel method to generate bloom lighting effect in real time
using neural networks. Our solution generate brightness mask from given 3D
scene view up to 30% faster than state-of-the-art methods. The existing
traditional techniques rely on multiple blur appliances and texture sampling,
also very often have existing conditional branching in its implementation.
These operations occupy big portion of the execution time. We solve this
problem by proposing two neural network-based bloom lighting methods, Neural
Bloom Lighting (NBL) and Fast Neural Bloom Lighting (FastNBL), focusing on
their quality and performance. Both methods were tested on a variety of 3D
scenes, with evaluations conducted on brightness mask accuracy and inference
speed. The main contribution of this work is that both methods produce
high-quality bloom effects while outperforming the standard state-of-the-art
bloom implementation, with FastNBL being faster by 28% and NBL faster by 12%.
These findings highlight that we can achieve realistic bloom lighting phenomena
faster, moving us towards more realism in real-time environments in the future.
This improvement saves computational resources, which is a major bottleneck in
real-time rendering. Furthermore, it is crucial for sustaining immersion and
ensuring smooth experiences in high FPS environments, while maintaining
high-quality realism.

</details>


### [129] [Multi View Slot Attention Using Paraphrased Texts For Face Anti-Spoofing](https://arxiv.org/abs/2509.06336)
*Jeongmin Yu,Susang Kim,Kisu Lee,Taekyoung Kwon,Won-Yong Shin,Ha Young Kim*

Main category: cs.CV

TL;DR: MVP-FAS是一种新颖的活体检测（FAS）框架，通过多视角槽注意力（MVS）和多文本补丁对齐（MTPA）模块，充分利用CLIP的补丁嵌入和多重文本提示，显著提升了跨域泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于CLIP的FAS模型未能充分利用CLIP的补丁嵌入来检测关键欺骗线索，并且依赖于每个类别单一的文本提示（如“活体”或“假体”），这限制了其泛化能力。

Method: 本文提出了MVP-FAS框架，包含两个核心模块：多视角槽注意力（MVS）和多文本补丁对齐（MTPA）。这两个模块都利用多个释义文本来生成泛化特征并减少对特定领域文本的依赖。MVS通过利用多视角多样文本从补丁嵌入中提取局部详细空间特征和全局上下文。MTPA将补丁与多个文本表示对齐，以提高语义鲁棒性。

Result: 广泛的实验表明，MVP-FAS在跨域数据集上取得了卓越的泛化性能，超越了以往最先进的方法。

Conclusion: MVP-FAS通过更有效地利用CLIP的补丁嵌入和引入多文本提示，显著提高了活体检测的跨域泛化能力。

Abstract: Recent face anti-spoofing (FAS) methods have shown remarkable cross-domain
performance by employing vision-language models like CLIP. However, existing
CLIP-based FAS models do not fully exploit CLIP's patch embedding tokens,
failing to detect critical spoofing clues. Moreover, these models rely on a
single text prompt per class (e.g., 'live' or 'fake'), which limits
generalization. To address these issues, we propose MVP-FAS, a novel framework
incorporating two key modules: Multi-View Slot attention (MVS) and Multi-Text
Patch Alignment (MTPA). Both modules utilize multiple paraphrased texts to
generate generalized features and reduce dependence on domain-specific text.
MVS extracts local detailed spatial features and global context from patch
embeddings by leveraging diverse texts with multiple perspectives. MTPA aligns
patches with multiple text representations to improve semantic robustness.
Extensive experiments demonstrate that MVP-FAS achieves superior generalization
performance, outperforming previous state-of-the-art methods on cross-domain
datasets. Code: https://github.com/Elune001/MVP-FAS.

</details>


### [130] [Spatial-Aware Self-Supervision for Medical 3D Imaging with Multi-Granularity Observable Tasks](https://arxiv.org/abs/2509.05967)
*Yiqin Zhang,Meiling Chen,Zhengjie Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种针对3D医学影像的自监督学习方法，通过设计三个子任务来捕捉空间语义，旨在提高模型的可解释性，同时保持与现有方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在医疗可视化中日益普及，以缓解数据稀缺问题。然而，当前多数方法受2D视觉领域启发，缺乏对3D空间知识学习过程的直观展示，导致医学可解释性不足。

Method: 提出了一种包含三个子任务的方法，用于捕捉医学3D影像中与空间相关的语义。其设计遵循可观察原则以确保可解释性，并尽可能减少由此造成的性能损失。通过利用3D影像额外维度提供的增强语义深度，该方法融入了多粒度空间关系建模以维持训练稳定性。

Result: 实验结果表明，该方法能够提供与当前主流方法相当的性能，同时促进对自监督学习过程的直观理解。

Conclusion: 该方法成功地在3D医学自监督学习中提升了模型的空间知识理解和可解释性，且未牺牲性能，为医疗影像分析提供了更具洞察力的工具。

Abstract: The application of self-supervised techniques has become increasingly
prevalent within medical visualization tasks, primarily due to its capacity to
mitigate the data scarcity prevalent in the healthcare sector. The majority of
current works are influenced by designs originating in the generic 2D visual
domain, which lack the intuitive demonstration of the model's learning process
regarding 3D spatial knowledge. Consequently, these methods often fall short in
terms of medical interpretability. We propose a method consisting of three
sub-tasks to capture the spatially relevant semantics in medical 3D imaging.
Their design adheres to observable principles to ensure interpretability, and
minimize the performance loss caused thereby as much as possible. By leveraging
the enhanced semantic depth offered by the extra dimension in 3D imaging, this
approach incorporates multi-granularity spatial relationship modeling to
maintain training stability. Experimental findings suggest that our approach is
capable of delivering performance that is on par with current methodologies,
while facilitating an intuitive understanding of the self-supervised learning
process.

</details>


### [131] [MRD-LiNet: A Novel Lightweight Hybrid CNN with Gradient-Guided Unlearning for Improved Drought Stress Identification](https://arxiv.org/abs/2509.06367)
*Aswini Kumar Patra,Lingaraj Sahoo*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级混合CNN框架，结合了ResNet、DenseNet和MobileNet的优点，用于精确且低成本地检测作物干旱胁迫，并引入了基于梯度范数影响函数的机器遗忘机制以提高模型适应性。


<details>
  <summary>Details</summary>
Motivation: 传统干旱检测方法耗时费力，而现有深度学习模型（CNN、Vision Transformer）参数量过大，不适用于资源受限和实时农业环境，因此需要开发轻量级、高效且适应性强的解决方案。

Method: 研究者提出了一种受ResNet、DenseNet和MobileNet启发的轻量级混合CNN框架。此外，他们引入了一种基于梯度范数影响函数的机器遗忘机制，以实现对特定训练数据影响的定向移除。该方法在专家标注的马铃薯田航空图像数据集上进行了评估。

Result: 该框架与传统CNN和Vision Transformer模型相比，可训练参数减少了15倍，同时保持了具有竞争力的准确性。实验结果表明，该框架在显著降低计算成本的同时实现了高精度。

Conclusion: 该框架为精准农业中的干旱胁迫监测提供了一个实用、可扩展和适应性强的解决方案，尤其适用于资源受限的条件。

Abstract: Drought stress is a major threat to global crop productivity, making its
early and precise detection essential for sustainable agricultural management.
Traditional approaches, though useful, are often time-consuming and
labor-intensive, which has motivated the adoption of deep learning methods. In
recent years, Convolutional Neural Network (CNN) and Vision Transformer
architectures have been widely explored for drought stress identification;
however, these models generally rely on a large number of trainable parameters,
restricting their use in resource-limited and real-time agricultural settings.
To address this challenge, we propose a novel lightweight hybrid CNN framework
inspired by ResNet, DenseNet, and MobileNet architectures. The framework
achieves a remarkable 15-fold reduction in trainable parameters compared to
conventional CNN and Vision Transformer models, while maintaining competitive
accuracy. In addition, we introduce a machine unlearning mechanism based on a
gradient norm-based influence function, which enables targeted removal of
specific training data influence, thereby improving model adaptability. The
method was evaluated on an aerial image dataset of potato fields with
expert-annotated healthy and drought-stressed regions. Experimental results
show that our framework achieves high accuracy while substantially lowering
computational costs. These findings highlight its potential as a practical,
scalable, and adaptive solution for drought stress monitoring in precision
agriculture, particularly under resource-constrained conditions.

</details>


### [132] [OmniStyle2: Scalable and High Quality Artistic Style Transfer Data Generation via Destylization](https://arxiv.org/abs/2509.05970)
*Ye Wang,Zili Yi,Yibo Zhang,Peng Zheng,Xuping Xie,Jiang Lin,Yilin Wang,Rui Ma*

Main category: cs.CV

TL;DR: OmniStyle2通过将艺术风格迁移重新定义为数据问题，并引入“去风格化”方法，创建了大规模数据集DST-100K。利用此数据集，OmniStyle2（一个基于FLUX.1-dev的简单前馈模型）在定性和定量基准上均超越了现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 艺术风格迁移领域面临的核心挑战是缺乏真实（ground-truth）的监督数据。传统的风格迁移方法难以获得艺术作品的原始、无风格内容，这限制了模型的训练和性能。

Method: 该研究提出了一种“去风格化”（destylization）方法，旨在从艺术作品中移除风格元素，恢复其自然、无风格的内容。基于此，构建了DST-100K数据集，该数据集通过以下两步生成：1) DST，一个文本引导的去风格化模型，用于重建无风格内容；2) DST-Filter，一个多阶段评估模型，利用思维链（Chain-of-Thought）推理自动筛选低质量配对，确保内容保真度和风格准确性。最后，利用DST-100K数据集训练了OmniStyle2，一个基于FLUX.1-dev的简单前馈模型。

Result: 尽管模型结构简单，OmniStyle2在定性和定量基准测试中均持续超越了现有最先进的艺术风格迁移方法。这证明了通过去风格化实现可扩展数据生成是一种可靠的监督范式。

Conclusion: 通过去风格化生成可扩展数据提供了一种可靠的监督范式，成功克服了艺术风格迁移中缺乏真实数据这一根本挑战，显著提升了风格迁移的性能。

Abstract: OmniStyle2 introduces a novel approach to artistic style transfer by
reframing it as a data problem. Our key insight is destylization, reversing
style transfer by removing stylistic elements from artworks to recover natural,
style-free counterparts. This yields DST-100K, a large-scale dataset that
provides authentic supervision signals by aligning real artistic styles with
their underlying content. To build DST-100K, we develop (1) DST, a text-guided
destylization model that reconstructs stylefree content, and (2) DST-Filter, a
multi-stage evaluation model that employs Chain-of-Thought reasoning to
automatically discard low-quality pairs while ensuring content fidelity and
style accuracy. Leveraging DST-100K, we train OmniStyle2, a simple feed-forward
model based on FLUX.1-dev. Despite its simplicity, OmniStyle2 consistently
surpasses state-of-the-art methods across both qualitative and quantitative
benchmarks. Our results demonstrate that scalable data generation via
destylization provides a reliable supervision paradigm, overcoming the
fundamental challenge posed by the lack of ground-truth data in artistic style
transfer.

</details>


### [133] [Index-Preserving Lightweight Token Pruning for Efficient Document Understanding in Vision-Language Models](https://arxiv.org/abs/2509.06415)
*Jaemin Son,Sujin Choi,Inyong Yun*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级token剪枝框架，通过在VLM处理前过滤文档图像中的非信息性背景区域，显著降低了文档理解任务的计算成本，同时保持了相似的准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型（VLMs）在文档理解任务中取得了显著进展，但其高计算需求仍然是一个挑战。

Method: 该方法包括一个轻量级token剪枝框架：首先，一个二进制补丁级分类器用于移除非文本区域；其次，一个最大池化细化步骤用于恢复碎片化的文本区域，以增强空间连贯性。

Result: 在真实世界文档数据集上的实验表明，该方法显著降低了计算成本，同时保持了可比的准确性。

Conclusion: 所提出的轻量级token剪枝框架能够有效缓解VLM在文档理解任务中的计算负担，且不牺牲性能。

Abstract: Recent progress in vision-language models (VLMs) has led to impressive
results in document understanding tasks, but their high computational demands
remain a challenge. To mitigate the compute burdens, we propose a lightweight
token pruning framework that filters out non-informative background regions
from document images prior to VLM processing. A binary patch-level classifier
removes non-text areas, and a max-pooling refinement step recovers fragmented
text regions to enhance spatial coherence. Experiments on real-world document
datasets demonstrate that our approach substantially lowers computational
costs, while maintaining comparable accuracy.

</details>


### [134] [Multi-Strategy Guided Diffusion via Sparse Masking Temporal Reweighting Distribution Correction](https://arxiv.org/abs/2509.05992)
*Zekun Zhou,Yanru Gong,Liu Shi,Qiegen Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为STRIDE的扩散模型，用于稀疏视角CT重建，通过联合训练、时变重加权、线性回归校正和双网络架构等创新策略，显著提升了重建图像的质量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成方面表现出卓越能力，但稀疏视角CT重建仍面临挑战，需要有效处理缺失投影补全和全局信息建模，以实现高质量图像重建。

Method: 本文提出了STRIDE模型，具体方法包括：1) 设计了由稀疏条件概率引导的联合训练机制，以学习缺失投影补全和全局信息建模。2) 提出了一种时变稀疏条件重加权指导策略，在去噪过程中动态调整权重。3) 采用线性回归校正已知数据与生成数据之间的分布偏移。4) 构建了双网络并行架构，对多个子频率分量进行全局校正和优化，以改善细节恢复和结构保持。

Result: 实验结果表明，与现有最佳基线方法相比，STRIDE模型在PSNR上实现了2.58 dB的最佳提升，SSIM增加了2.37%，MSE减少了0.236。重建图像在结构一致性、细节恢复和伪影抑制方面表现出卓越的泛化性和鲁棒性。

Conclusion: 所提出的STRIDE模型在稀疏视角CT重建任务中取得了显著的性能提升，能够生成高质量的重建图像，并展现出优异的泛化性和鲁棒性，有效解决了稀疏视角CT重建中的关键挑战。

Abstract: Diffusion models have demonstrated remarkable generative capabilities in
image processing tasks. We propose a Sparse condition Temporal Rewighted
Integrated Distribution Estimation guided diffusion model (STRIDE) for
sparse-view CT reconstruction. Specifically, we design a joint training
mechanism guided by sparse conditional probabilities to facilitate the model
effective learning of missing projection view completion and global information
modeling. Based on systematic theoretical analysis, we propose a temporally
varying sparse condition reweighting guidance strategy to dynamically adjusts
weights during the progressive denoising process from pure noise to the real
image, enabling the model to progressively perceive sparse-view information.
The linear regression is employed to correct distributional shifts between
known and generated data, mitigating inconsistencies arising during the
guidance process. Furthermore, we construct a dual-network parallel
architecture to perform global correction and optimization across multiple
sub-frequency components, thereby effectively improving the model capability in
both detail restoration and structural preservation, ultimately achieving
high-quality image reconstruction. Experimental results on both public and real
datasets demonstrate that the proposed method achieves the best improvement of
2.58 dB in PSNR, increase of 2.37\% in SSIM, and reduction of 0.236 in MSE
compared to the best-performing baseline methods. The reconstructed images
exhibit excellent generalization and robustness in terms of structural
consistency, detail restoration, and artifact suppression.

</details>


### [135] [Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning](https://arxiv.org/abs/2509.06461)
*Yuyao Ge,Shenghua Liu,Yiwei Wang,Lingrui Mei,Baolong Bi,Xuanshan Zhou,Jiayu Yao,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CV

TL;DR: 本文提出了一种名为CARVE的免训练方法，通过像素级对比注意力来增强视觉语言模型（VLMs）在复杂视觉环境中的性能，实现了显著提升。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在复杂视觉环境中性能下降，而现有增强方法需要额外训练、依赖外部工具或粒度较粗，且忽视了VLM内在的能力。

Method: 研究了VLM的注意力模式，发现视觉复杂性与注意力熵相关，且注意力从浅层全局扫描到深层聚焦收敛。理论上证明了通用查询和任务特定查询之间注意力图的对比能够将视觉信号分解为语义信号和视觉噪声。在此基础上，提出了CARVE（Contrastive Attention Refinement for Visual Enhancement），一种免训练方法，通过像素级注意力对比提取任务相关的视觉信号。

Result: CARVE持续提升了性能，在开源模型上实现了高达75%的改进。

Conclusion: 该研究深入探讨了视觉复杂性与注意力机制之间的相互作用，并提供了一种通过对比注意力提高视觉推理效率的有效途径。

Abstract: Vision-Language Models (VLMs) have demonstrated remarkable success across
diverse visual tasks, yet their performance degrades in complex visual
environments. While existing enhancement approaches require additional
training, rely on external segmentation tools, or operate at coarse-grained
levels, they overlook the innate ability within VLMs. To bridge this gap, we
investigate VLMs' attention patterns and discover that: (1) visual complexity
strongly correlates with attention entropy, negatively impacting reasoning
performance; (2) attention progressively refines from global scanning in
shallow layers to focused convergence in deeper layers, with convergence degree
determined by visual complexity. (3) Theoretically, we prove that the contrast
of attention maps between general queries and task-specific queries enables the
decomposition of visual signal into semantic signals and visual noise
components. Building on these insights, we propose Contrastive Attention
Refinement for Visual Enhancement (CARVE), a training-free method that extracts
task-relevant visual signals through attention contrasting at the pixel level.
Extensive experiments demonstrate that CARVE consistently enhances performance,
achieving up to 75% improvement on open-source models. Our work provides
critical insights into the interplay between visual complexity and attention
mechanisms, offering an efficient pathway for improving visual reasoning with
contrasting attention.

</details>


### [136] [Motion Aware ViT-based Framework for Monocular 6-DoF Spacecraft Pose Estimation](https://arxiv.org/abs/2509.06000)
*Jose Sosa,Dan Pineau,Arunkumar Rathinam,Abdelrahman Shabayek,Djamila Aouada*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的单目6自由度航天器姿态估计算法，通过结合运动感知热图和光流，利用时间信息改进了2D关键点定位和6自由度姿态恢复，并在不同数据集上表现出优越的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的航天器姿态估计算法依赖于单张图像和静态关键点定位，未能利用太空操作中固有的宝贵时间信息，这限制了其在动态场景中的表现。

Method: 该方法将人类姿态估计的深度学习框架 адаптирован 到航天器姿态估计领域，集成了运动感知热图和光流来捕捉运动动态。它结合了来自Vision Transformer (ViT)编码器的图像特征和来自预训练光流模型的运动线索来定位2D关键点。随后，使用PnP（Perspective-n-Point）求解器从已知的2D-3D对应关系中恢复6自由度姿态。该方法在SPADES-RGB数据集上进行训练和评估，并在SPARK-2024数据集的真实和合成数据上评估了其泛化能力。

Result: 该方法在2D关键点定位和6自由度姿态估计方面均优于单图像基线方法。此外，在不同数据分布上进行测试时，它还展示了有前景的泛化能力。

Conclusion: 通过整合运动感知热图和光流等时间信息，本文提出的深度学习框架显著提升了单目6自由度航天器姿态估计的性能，并在关键点定位和姿态恢复上均取得了改进，同时展现出良好的跨数据分布泛化能力。

Abstract: Monocular 6-DoF pose estimation plays an important role in multiple
spacecraft missions. Most existing pose estimation approaches rely on single
images with static keypoint localisation, failing to exploit valuable temporal
information inherent to space operations. In this work, we adapt a deep
learning framework from human pose estimation to the spacecraft pose estimation
domain that integrates motion-aware heatmaps and optical flow to capture motion
dynamics. Our approach combines image features from a Vision Transformer (ViT)
encoder with motion cues from a pre-trained optical flow model to localise 2D
keypoints. Using the estimates, a Perspective-n-Point (PnP) solver recovers
6-DoF poses from known 2D-3D correspondences. We train and evaluate our method
on the SPADES-RGB dataset and further assess its generalisation on real and
synthetic data from the SPARK-2024 dataset. Overall, our approach demonstrates
improved performance over single-image baselines in both 2D keypoint
localisation and 6-DoF pose estimation. Furthermore, it shows promising
generalisation capabilities when testing on different data distributions.

</details>


### [137] [On the Reproducibility of "FairCLIP: Harnessing Fairness in Vision-Language Learning''](https://arxiv.org/abs/2509.06535)
*Hua Chang Bakker,Stan Fris,Angela Madelon Bernardy,Stan Deutekom*

Main category: cs.CV

TL;DR: 本文调查了FairCLIP的重现性及其在零样本青光眼分类中的表现，发现其未能如原论文所述提升CLIP的公平性和性能，尽管它能降低Sinkhorn距离。


<details>
  <summary>Details</summary>
Motivation: Luo et al. (2024) 提出的FairCLIP旨在通过最小化敏感组间的图像-文本相似度分数差异来改善CLIP的群组公平性。本研究的动机是验证FairCLIP的重现性及其研究发现。

Method: 研究者首先重现了Luo et al. (2024) 的实验设置。由于发现原模型描述与实现不符，引入了新的实现A-FairCLIP以检查特定设计选择。此外，提出了FairCLIP+以扩展FairCLIP目标以包含多个属性。研究还探讨了距离最小化对FairCLIP公平性和性能的影响。

Result: 研究证实了CLIP在零样本青光眼分类中对某些人口统计学存在偏见。然而，在两个数据集上的实验结果不支持FairCLIP能提升CLIP性能和公平性的主张。尽管正则化目标确实降低了Sinkhorn距离，但无论是官方实现还是对齐实现A-FairCLIP，均未在零样本青光眼分类中观察到性能或公平性的改善。

Conclusion: 尽管FairCLIP的正则化目标能够减少Sinkhorn距离，但本研究未能重现其在零样本青光眼分类中改善CLIP性能和公平性的效果，无论是官方实现还是其修正版本A-FairCLIP均未能实现这一目标。

Abstract: We investigated the reproducibility of FairCLIP, proposed by Luo et al.
(2024), for improving the group fairness of CLIP (Radford et al., 2021) by
minimizing image-text similarity score disparities across sensitive groups
using the Sinkhorn distance. The experimental setup of Luo et al. (2024) was
reproduced to primarily investigate the research findings for FairCLIP. The
model description by Luo et al. (2024) was found to differ from the original
implementation. Therefore, a new implementation, A-FairCLIP, is introduced to
examine specific design choices. Furthermore, FairCLIP+ is proposed to extend
the FairCLIP objective to include multiple attributes. Additionally, the impact
of the distance minimization on FairCLIP's fairness and performance was
explored. In alignment with the original authors, CLIP was found to be biased
towards certain demographics when applied to zero-shot glaucoma classification
using medical scans and clinical notes from the Harvard-FairVLMed dataset.
However, the experimental results on two datasets do not support their claim
that FairCLIP improves the performance and fairness of CLIP. Although the
regularization objective reduces Sinkhorn distances, both the official
implementation and the aligned implementation, A-FairCLIP, were not found to
improve performance nor fairness in zero-shot glaucoma classification.

</details>


### [138] [Interleaving Reasoning for Better Text-to-Image Generation](https://arxiv.org/abs/2509.06945)
*Wenxuan Huang,Shuang Chen,Zheyong Xie,Shaosheng Cao,Shixiang Tang,Yufan Shen,Qingyu Yin,Wenbo Hu,Xiaoman Wang,Yuntian Tang,Junbo Qiao,Yue Guo,Yao Hu,Zhenfei Yin,Philip Torr,Yu Cheng,Wanli Ouyang,Shaohui Lin*

Main category: cs.CV

TL;DR: 本文提出了一种名为交错推理生成（IRG）的新框架和训练方法（IRGL），通过在文本思考和图像合成之间交替进行，显著提升了文本到图像（T2I）生成在指令遵循和细节保留方面的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管统一多模态模型在图像生成方面取得了显著进步，但在指令遵循和细节保留方面与GPT-4o等紧密耦合的系统仍有较大差距。受交错推理最新进展的启发，研究旨在探索这种推理能否进一步改善T2I生成。

Method: 研究引入了交错推理生成（IRG）框架，该框架在文本思考和图像合成之间交替进行：模型首先生成文本思考以指导初始图像，然后反思结果以在保持语义的同时，改进细节、视觉质量和美学。为了有效训练IRG，提出了交错推理生成学习（IRGL），旨在实现两个子目标：1) 强化初始思考和生成阶段以建立核心内容和基础质量；2) 实现高质量的文本反思并忠实地在后续图像中实现这些改进。为此，构建了IRGL-300K数据集，并采用两阶段训练：首先从一个统一的基础模型构建鲁棒的思考和反思能力，然后高效地在完整的思考-图像轨迹数据上微调IRG管道。

Result: 实验结果显示，该方法达到了最先进的性能（SoTA），在GenEval、WISE、TIIF、GenAI-Bench和OneIG-EN等基准测试上取得了5-10个百分点的绝对增益，并在视觉质量和精细保真度方面有显著提升。

Conclusion: 交错推理生成（IRG）框架通过在文本思考和图像合成之间交替进行，能够有效弥补现有统一多模态模型在指令遵循和细节保留上的不足，显著提升了文本到图像的生成质量和保真度。

Abstract: Unified multimodal understanding and generation models recently have achieve
significant improvement in image generation capability, yet a large gap remains
in instruction following and detail preservation compared to systems that
tightly couple comprehension with generation such as GPT-4o. Motivated by
recent advances in interleaving reasoning, we explore whether such reasoning
can further improve Text-to-Image (T2I) generation. We introduce Interleaving
Reasoning Generation (IRG), a framework that alternates between text-based
thinking and image synthesis: the model first produces a text-based thinking to
guide an initial image, then reflects on the result to refine fine-grained
details, visual quality, and aesthetics while preserving semantics. To train
IRG effectively, we propose Interleaving Reasoning Generation Learning (IRGL),
which targets two sub-goals: (1) strengthening the initial think-and-generate
stage to establish core content and base quality, and (2) enabling high-quality
textual reflection and faithful implementation of those refinements in a
subsequent image. We curate IRGL-300K, a dataset organized into six decomposed
learning modes that jointly cover learning text-based thinking, and full
thinking-image trajectories. Starting from a unified foundation model that
natively emits interleaved text-image outputs, our two-stage training first
builds robust thinking and reflection, then efficiently tunes the IRG pipeline
in the full thinking-image trajectory data. Extensive experiments show SoTA
performance, yielding absolute gains of 5-10 points on GenEval, WISE, TIIF,
GenAI-Bench, and OneIG-EN, alongside substantial improvements in visual quality
and fine-grained fidelity. The code, model weights and datasets will be
released in: https://github.com/Osilly/Interleaving-Reasoning-Generation .

</details>


### [139] [BLaVe-CoT: Consistency-Aware Visual Question Answering for Blind and Low Vision Users](https://arxiv.org/abs/2509.06010)
*Wanyin Cheng,Zanxi Ruan*

Main category: cs.CV

TL;DR: 针对盲人和低视力(BLV)用户在VQA中面临的模糊输入和多义性问题，本文提出了BLaVe-CoT框架。它通过生成多样化答案、空间定位和链式思维推理来处理答案一致性，并在基准测试中表现出更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统VQA系统假设单一答案和区域，无法适应BLV用户因视力障碍造成的模糊、低质量图像以及模糊问题。这导致BLV用户的视觉问题常有多重有效答案，且根植于不同图像区域，与现有系统不匹配。

Method: BLaVe-CoT框架通过以下步骤处理歧义：1. 使用LoRA微调的BLIP-2模型生成多样化的候选答案。2. 使用PolyFormer对每个答案进行空间定位。3. 应用链式思维(Chain-of-Thought)推理模块评估答案是否指向相同或不同区域，从而判断答案一致性。

Result: 在VQA-AnswerTherapy基准测试中，BLaVe-CoT优于现有方法，并且在辅助环境中常见的歧义和视觉噪声面前表现出更高的鲁棒性。

Conclusion: 这项工作强调了VQA系统需要适应真实的人类不确定性，并为BLV用户提供包容性支持。作者已开源代码以促进进一步研究和无障碍应用。

Abstract: Visual Question Answering (VQA) holds great potential for assisting Blind and
Low Vision (BLV) users, yet real-world usage remains challenging. Due to visual
impairments, BLV users often take blurry or poorly framed photos and face
difficulty in articulating specific questions about what they cannot fully see.
As a result, their visual questions are frequently ambiguous, and different
users may interpret them in diverse ways. This leads to multiple valid answers,
each grounded in different image regions-posing a mismatch with conventional
VQA systems that assume a single answer and region. To bridge this gap, we
present BLaVe-CoT, a VQA framework designed to reason about answer consistency
in the face of ambiguity. Our method proposes diverse candidate answers using a
LoRA-tuned BLIP-2 model, then grounds each answer spatially using PolyFormer,
and finally applies a chain-of-thought reasoning module to assess whether the
answers refer to the same or different regions. Evaluated on the
VQA-AnswerTherapy benchmark, BLaVe-CoT outperforms previous methods and proves
more robust to the ambiguity and visual noise common in assistive settings.
This work highlights the need for VQA systems that can adapt to real human
uncertainty and provide inclusive support for BLV users. To foster further
research and accessibility applications, we have made the code publicly
available at https://github.com/Accecwan/BLaVe-CoT.

</details>


### [140] [Improved Classification of Nitrogen Stress Severity in Plants Under Combined Stress Conditions Using Spatio-Temporal Deep Learning Framework](https://arxiv.org/abs/2509.06625)
*Aswini Kumar Patra*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的深度学习框架（CNN-LSTM），利用多模态时序图像数据，在高交互胁迫环境下（干旱、杂草）准确分类植物氮胁迫的严重程度，实现了98%的准确率，远超其他方法。


<details>
  <summary>Details</summary>
Motivation: 植物在自然环境中面临多种相互作用的生物和非生物胁迫，其中氮缺乏与干旱和杂草竞争复合时，其影响更难区分和解决。因此，早期检测氮胁迫对于保护植物健康和实施有效管理策略至关重要。

Method: 本研究提出了一种新颖的深度学习框架，用于在复合胁迫环境下准确分类氮胁迫严重程度。该模型融合了四种成像模态（RGB、多光谱和两种红外波长）来捕捉植物的广泛生理响应。这些图像作为时间序列数据，记录了在不同水分胁迫和杂草压力下，三种氮可用性水平（低、中、高）下的植物健康状况。核心方法是时空深度学习流程，结合卷积神经网络（CNN）提取图像空间特征和长短期记忆网络（LSTM）捕捉时间依赖性。研究还设计并评估了一个仅基于空间的CNN流程进行比较。

Result: CNN-LSTM流程实现了98%的准确率，显著超越了仅基于空间模型的80.45%准确率以及其他先前报道的机器学习方法的76%准确率。

Conclusion: CNN-LSTM方法能够有效捕捉氮缺乏、水分胁迫和杂草压力之间微妙而复杂的相互作用。这一鲁棒平台为及时主动识别氮胁迫严重程度提供了有前景的工具，从而实现更好的作物管理和改善植物健康。

Abstract: Plants in their natural habitats endure an array of interacting stresses,
both biotic and abiotic, that rarely occur in isolation. Nutrient
stress-particularly nitrogen deficiency-becomes even more critical when
compounded with drought and weed competition, making it increasingly difficult
to distinguish and address its effects. Early detection of nitrogen stress is
therefore crucial for protecting plant health and implementing effective
management strategies. This study proposes a novel deep learning framework to
accurately classify nitrogen stress severity in a combined stress environment.
Our model uses a unique blend of four imaging modalities-RGB, multispectral,
and two infrared wavelengths-to capture a wide range of physiological plant
responses from canopy images. These images, provided as time-series data,
document plant health across three levels of nitrogen availability (low,
medium, and high) under varying water stress and weed pressures. The core of
our approach is a spatio-temporal deep learning pipeline that merges a
Convolutional Neural Network (CNN) for extracting spatial features from images
with a Long Short-Term Memory (LSTM) network to capture temporal dependencies.
We also devised and evaluated a spatial-only CNN pipeline for comparison. Our
CNN-LSTM pipeline achieved an impressive accuracy of 98%, impressively
surpassing the spatial-only model's 80.45% and other previously reported
machine learning method's 76%. These results bring actionable insights based on
the power of our CNN-LSTM approach in effectively capturing the subtle and
complex interactions between nitrogen deficiency, water stress, and weed
pressure. This robust platform offers a promising tool for the timely and
proactive identification of nitrogen stress severity, enabling better crop
management and improved plant health.

</details>


### [141] [Cross-Modal Enhancement and Benchmark for UAV-based Open-Vocabulary Object Detection](https://arxiv.org/abs/2509.06011)
*Zhenhai Weng,Zhongliang Yu*

Main category: cs.CV

TL;DR: 针对无人机开放词汇目标检测（OVD）中的领域鸿沟问题，本文提出了一种改进的UAV-Label引擎，构建了新的无人机数据集UAVDE-2M和UAVCAP-15k，并设计了跨注意力门控增强融合（CAGE）模块并集成到YOLO-World-v2中，有效提升了无人机图像的检测性能。


<details>
  <summary>Details</summary>
Motivation: 无人机开放词汇目标检测（OVD）技术至关重要，但现有的大规模OVD预训练数据集主要由地面自然图像组成，这与无人机图像存在显著的领域鸿沟，导致模型在无人机图像上的性能大幅下降。

Method: ['提出了一种改进的UAV-Label引擎。', '构建并引入了两个新的无人机数据集：UAVDE-2M（包含超过200万个实例和1800个类别）和UAVCAP-15k（包含超过15000张图像）。', '提出了一种新颖的跨注意力门控增强融合（CAGE）模块。', '将CAGE模块集成到YOLO-World-v2架构中。']

Result: 在VisDrone和SIMD数据集上进行了广泛的实验，验证了所提出方法在无人机图像和遥感应用中的有效性。

Conclusion: 通过改进标签引擎、构建特定数据集以及引入新的融合模块，本文有效解决了无人机开放词汇目标检测中的领域鸿沟问题，显著提升了模型在无人机图像和遥感应用中的性能。

Abstract: Open-Vocabulary Object Detection (OVD) has emerged as a pivotal technology
for applications involving Unmanned Aerial Vehicles (UAVs). However, the
prevailing large-scale datasets for OVD pre-training are predominantly composed
of ground-level, natural images. This creates a significant domain gap, causing
models trained on them to exhibit a substantial drop in performance on UAV
imagery. To address this limitation, we first propose a refined UAV-Label
engine. Then we construct and introduce UAVDE-2M(contains over 2,000,000
instances and 1800 categories) and UAVCAP-15k(contains over 15,000 images).
Furthermore, we propose a novel Cross-Attention Gated Enhancement Fusion (CAGE)
module and integrate it into the YOLO-World-v2 architecture. Finally, extensive
experiments on the VisDrone and SIMD datasets verify the effectiveness of our
proposed method for applications in UAV-based imagery and remote sensing.

</details>


### [142] [BioLite U-Net: Edge-Deployable Semantic Segmentation for In Situ Bioprinting Monitoring](https://arxiv.org/abs/2509.06690)
*Usman Haider,Lukasz Szemet,Daniel Kelly,Vasileios Sergis,Andrew C. Daly,Karl Mason*

Main category: cs.CV

TL;DR: 该研究提出了一种名为BioLite U-Net的轻量级语义分割框架，专为实时生物打印过程监控设计，实现了高精度和高效率，适用于资源受限的嵌入式硬件。


<details>
  <summary>Details</summary>
Motivation: 生物打印中，实时确保打印结构的一致性和保真度是一个核心挑战，尤其是在成像数据有限和嵌入式硬件资源受限的情况下。通过对挤出过程进行语义分割（区分喷嘴、挤出生物墨水和背景），可以实现原位监控，这对于维持打印质量和生物活力至关重要。

Method: 研究方法包括：1) 构建了一个包含787张手动标注RGB图像的新数据集，分为喷嘴、生物墨水和背景三类。2) 提出了一种BioLite U-Net架构，该架构利用深度可分离卷积来显著减少计算负荷，同时不牺牲精度。3) 将该模型与基于MobileNetV2和MobileNetV3的分割基线进行基准测试，评估指标包括mIoU、Dice分数和像素精度。4) 所有模型均在树莓派4B上进行评估，以测试实际可行性。

Result: BioLite U-Net实现了92.85%的mIoU和96.17%的Dice分数，模型大小比MobileNetV2-DeepLabV3+小1300多倍。在设备上的推理时间为每帧335毫秒，展示了接近实时的能力。与MobileNet基线相比，BioLite U-Net在分割精度、效率和部署能力之间提供了更优的权衡。

Conclusion: BioLite U-Net在生物打印应用中展现出卓越的性能，其在精度、效率和可部署性方面的优势使其非常适合集成到智能、闭环的生物打印系统中。

Abstract: Bioprinting is a rapidly advancing field that offers a transformative
approach to fabricating tissue and organ models through the precise deposition
of cell-laden bioinks. Ensuring the fidelity and consistency of printed
structures in real-time remains a core challenge, particularly under
constraints imposed by limited imaging data and resource-constrained embedded
hardware. Semantic segmentation of the extrusion process, differentiating
between nozzle, extruded bioink, and surrounding background, enables in situ
monitoring critical to maintaining print quality and biological viability. In
this work, we introduce a lightweight semantic segmentation framework tailored
for real-time bioprinting applications. We present a novel, manually annotated
dataset comprising 787 RGB images captured during the bioprinting process,
labeled across three classes: nozzle, bioink, and background. To achieve fast
and efficient inference suitable for integration with bioprinting systems, we
propose a BioLite U-Net architecture that leverages depthwise separable
convolutions to drastically reduce computational load without compromising
accuracy. Our model is benchmarked against MobileNetV2 and MobileNetV3-based
segmentation baselines using mean Intersection over Union (mIoU), Dice score,
and pixel accuracy. All models were evaluated on a Raspberry Pi 4B to assess
real-world feasibility. The proposed BioLite U-Net achieves an mIoU of 92.85%
and a Dice score of 96.17%, while being over 1300x smaller than
MobileNetV2-DeepLabV3+. On-device inference takes 335 ms per frame,
demonstrating near real-time capability. Compared to MobileNet baselines,
BioLite U-Net offers a superior tradeoff between segmentation accuracy,
efficiency, and deployability, making it highly suitable for intelligent,
closed-loop bioprinting systems.

</details>


### [143] [Micro-Expression Recognition via Fine-Grained Dynamic Perception](https://arxiv.org/abs/2509.06015)
*Zhiwen Shao,Yifan Cheng,Fan Zhang,Xuehuai Shi,Canlin Li,Lizhuang Ma,Dit-yan Yeung*

Main category: cs.CV

TL;DR: 本文提出了一种名为细粒度动态感知（FDP）的新型框架，用于微表情识别（MER），通过对帧级特征进行排序来编码动态信息，并结合动态图像构建任务以解决数据稀缺问题，显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 微表情识别因其短暂性、微妙性和动态性而极具挑战。现有方法要么依赖手工特征（常需关键帧），要么深度网络受限于小规模和低多样性的训练数据。

Method: 本文提出了细粒度动态感知（FDP）框架。首先，对原始帧序列的帧级特征按时间顺序进行排序，以编码微表情的外观和运动动态信息。具体而言，采用了一种新颖的局部-全局特征感知Transformer进行帧表示学习，然后使用一个排序评分器计算每帧特征的排序分数。接着，将排序特征在时间维度上进行池化以捕获动态表示。最后，该动态表示被一个MER模块和一个动态图像构建模块共享，前者预测微表情类别，后者通过编解码器结构构建动态图像，此任务有助于捕捉面部细微动作并缓解数据稀缺问题。

Result: 实验结果表明，该方法（i）显著优于最先进的微表情识别方法，并且（ii）在动态图像构建方面表现良好。特别是在CASME II、SAMM、CAS(ME)^2和CAS(ME)^3数据集上，F1分数分别比之前的最佳结果提高了4.05%、2.50%、7.71%和2.11%。

Conclusion: FDP框架通过其独特的动态信息编码和辅助动态图像构建任务，有效解决了微表情识别的挑战，显著提升了识别性能，并缓解了数据稀缺问题。

Abstract: Facial micro-expression recognition (MER) is a challenging task, due to the
transience, subtlety, and dynamics of micro-expressions (MEs). Most existing
methods resort to hand-crafted features or deep networks, in which the former
often additionally requires key frames, and the latter suffers from small-scale
and low-diversity training data. In this paper, we develop a novel fine-grained
dynamic perception (FDP) framework for MER. We propose to rank frame-level
features of a sequence of raw frames in chronological order, in which the rank
process encodes the dynamic information of both ME appearances and motions.
Specifically, a novel local-global feature-aware transformer is proposed for
frame representation learning. A rank scorer is further adopted to calculate
rank scores of each frame-level feature. Afterwards, the rank features from
rank scorer are pooled in temporal dimension to capture dynamic representation.
Finally, the dynamic representation is shared by a MER module and a dynamic
image construction module, in which the former predicts the ME category, and
the latter uses an encoder-decoder structure to construct the dynamic image.
The design of dynamic image construction task is beneficial for capturing
facial subtle actions associated with MEs and alleviating the data scarcity
issue. Extensive experiments show that our method (i) significantly outperforms
the state-of-the-art MER methods, and (ii) works well for dynamic image
construction. Particularly, our FDP improves by 4.05%, 2.50%, 7.71%, and 2.11%
over the previous best results in terms of F1-score on the CASME II, SAMM,
CAS(ME)^2, and CAS(ME)^3 datasets, respectively. The code is available at
https://github.com/CYF-cuber/FDP.

</details>


### [144] [MRI-Based Brain Tumor Detection through an Explainable EfficientNetV2 and MLP-Mixer-Attention Architecture](https://arxiv.org/abs/2509.06713)
*Mustafa Yurdakul,Şakir Taşdemir*

Main category: cs.CV

TL;DR: 提出了一种结合EfficientNetV2和注意力机制MLP-Mixer的深度学习模型，用于脑肿瘤的自动化、高精度和可解释性分类，实现了99.50%的准确率。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤死亡率高，早期诊断至关重要。通过MRI图像诊断需要专业知识且易出错，因此迫切需要自动化、鲁棒且可解释的诊断系统。

Method: 研究使用了包含3064张T1加权对比增强脑部MRI图像的Figshare公开数据集。首先评估了九种CNN架构，选择EfficientNetV2作为最佳主干网络。随后，将基于注意力的MLP-Mixer架构集成到EfficientNetV2中以增强分类能力。模型性能通过五折交叉验证进行评估，并与基本CNN和现有文献方法进行比较。同时，使用Grad-CAM可视化来解释模型的决策过程。

Result: 所提出的模型表现出卓越的性能，准确率为99.50%，精确率为99.47%，召回率为99.52%，F1分数为99.49%。这些结果优于现有文献中的研究。此外，Grad-CAM可视化证明模型能有效聚焦于MRI图像的相关区域，从而提高了可解释性和临床可靠性。

Conclusion: 通过结合EfficientNetV2和基于注意力的MLP-Mixer，成功构建了一个在脑肿瘤分类方面具有高准确性和可解释性的鲁棒深度学习模型，为临床决策支持系统提供了有力工具。

Abstract: Brain tumors are serious health problems that require early diagnosis due to
their high mortality rates. Diagnosing tumors by examining Magnetic Resonance
Imaging (MRI) images is a process that requires expertise and is prone to
error. Therefore, the need for automated diagnosis systems is increasing day by
day. In this context, a robust and explainable Deep Learning (DL) model for the
classification of brain tumors is proposed. In this study, a publicly available
Figshare dataset containing 3,064 T1-weighted contrast-enhanced brain MRI
images of three tumor types was used. First, the classification performance of
nine well-known CNN architectures was evaluated to determine the most effective
backbone. Among these, EfficientNetV2 demonstrated the best performance and was
selected as the backbone for further development. Subsequently, an
attention-based MLP-Mixer architecture was integrated into EfficientNetV2 to
enhance its classification capability. The performance of the final model was
comprehensively compared with basic CNNs and the methods in the literature.
Additionally, Grad-CAM visualization was used to interpret and validate the
decision-making process of the proposed model. The proposed model's performance
was evaluated using the five-fold cross-validation method. The proposed model
demonstrated superior performance with 99.50% accuracy, 99.47% precision,
99.52% recall and 99.49% F1 score. The results obtained show that the model
outperforms the studies in the literature. Moreover, Grad-CAM visualizations
demonstrate that the model effectively focuses on relevant regions of MRI
images, thus improving interpretability and clinical reliability. A robust deep
learning model for clinical decision support systems has been obtained by
combining EfficientNetV2 and attention-based MLP-Mixer, providing high accuracy
and interpretability in brain tumor classification.

</details>


### [145] [DVLO4D: Deep Visual-Lidar Odometry with Sparse Spatial-temporal Fusion](https://arxiv.org/abs/2509.06023)
*Mengmeng Liu,Michael Ying Yang,Jiuming Liu,Yunpeng Zhang,Jiangtao Li,Sander Oude Elberink,George Vosselman,Hao Cheng*

Main category: cs.CV

TL;DR: DVLO4D是一种新型的视觉-激光雷达里程计框架，通过稀疏时空融合提高了定位的准确性和鲁棒性，并实现了高效的实时部署潜力。


<details>
  <summary>Details</summary>
Motivation: 传统视觉-激光雷达里程计面临传感器未对准、未能充分利用时间信息以及需要大量手动调优以适应不同传感器配置的挑战，导致难以实现高精度和强鲁棒性。

Method: 本文提出了DVLO4D框架，包含三项关键创新：1) 稀疏查询融合，利用稀疏激光雷达查询实现高效的多模态数据融合；2) 时间交互与更新模块，将时间预测位置与当前帧数据结合，提供更好的位姿估计初始化并增强模型对累积误差的鲁棒性；3) 时间片段训练策略结合集体平均损失机制，聚合多帧损失以实现全局优化并减少长序列的尺度漂移。

Result: 在KITTI和Argoverse里程计数据集上的广泛实验表明，DVLO4D在位姿精度和鲁棒性方面均达到了最先进的性能。此外，该方法具有高效率，推理时间为82毫秒，具备实时部署的潜力。

Conclusion: DVLO4D通过其创新的稀疏时空融合方法，显著提升了视觉-激光雷达里程计的准确性、鲁棒性和效率，为自动驾驶系统的定位提供了高性能的解决方案。

Abstract: Visual-LiDAR odometry is a critical component for autonomous system
localization, yet achieving high accuracy and strong robustness remains a
challenge. Traditional approaches commonly struggle with sensor misalignment,
fail to fully leverage temporal information, and require extensive manual
tuning to handle diverse sensor configurations. To address these problems, we
introduce DVLO4D, a novel visual-LiDAR odometry framework that leverages sparse
spatial-temporal fusion to enhance accuracy and robustness. Our approach
proposes three key innovations: (1) Sparse Query Fusion, which utilizes sparse
LiDAR queries for effective multi-modal data fusion; (2) a Temporal Interaction
and Update module that integrates temporally-predicted positions with current
frame data, providing better initialization values for pose estimation and
enhancing model's robustness against accumulative errors; and (3) a Temporal
Clip Training strategy combined with a Collective Average Loss mechanism that
aggregates losses across multiple frames, enabling global optimization and
reducing the scale drift over long sequences. Extensive experiments on the
KITTI and Argoverse Odometry dataset demonstrate the superiority of our
proposed DVLO4D, which achieves state-of-the-art performance in terms of both
pose accuracy and robustness. Additionally, our method has high efficiency,
with an inference time of 82 ms, possessing the potential for the real-time
deployment.

</details>


### [146] [Automated Radiographic Total Sharp Score (ARTSS) in Rheumatoid Arthritis: A Solution to Reduce Inter-Intra Reader Variation and Enhancing Clinical Practice](https://arxiv.org/abs/2509.06854)
*Hajar Moradmand,Lei Ren*

Main category: cs.CV

TL;DR: 本研究提出了一种名为ARTSS的深度学习框架，用于自动化分析全手X射线图像，以评估类风湿关节炎（RA）的严重程度，旨在减少手动评分的时间消耗和主观性。


<details>
  <summary>Details</summary>
Motivation: 评估类风湿关节炎（RA）的夏普/范德海德总分（TSS）至关重要，但手动评分通常耗时且主观，存在观察者间和观察者内变异性。

Method: ARTSS框架利用深度学习，分为四个阶段：I）使用ResNet50进行图像预处理和重新定向；II）使用UNet.3进行手部分割；III）使用YOLOv7进行关节识别；IV）使用VGG16、VGG19、ResNet50、DenseNet201、EfficientNetB0和Vision Transformer（ViT）等模型进行TSS预测。研究使用了970名患者的数据，采用3折交叉验证进行模型训练，并包含291名未见过受试者的外部测试。地面真相为两位放射科医生的平均TSS。

Result: 关节识别模型达到了99%的准确率。在TSS预测方面，表现最佳的模型ViT实现了0.87的Huber损失。该方法成功处理了关节消失和可变长度图像序列的挑战。

Conclusion: 深度学习在自动化RA评分方面具有巨大潜力，可以显著改善临床实践。ARTSS方法能够节省时间、减少观察者间和观察者内变异性、提高放射科医生的准确性，并帮助风湿病专家做出更明智的决策。

Abstract: Assessing the severity of rheumatoid arthritis (RA) using the Total Sharp/Van
Der Heijde Score (TSS) is crucial, but manual scoring is often time-consuming
and subjective. This study introduces an Automated Radiographic Sharp Scoring
(ARTSS) framework that leverages deep learning to analyze full-hand X-ray
images, aiming to reduce inter- and intra-observer variability. The research
uniquely accommodates patients with joint disappearance and variable-length
image sequences. We developed ARTSS using data from 970 patients, structured
into four stages: I) Image pre-processing and re-orientation using ResNet50,
II) Hand segmentation using UNet.3, III) Joint identification using YOLOv7, and
IV) TSS prediction using models such as VGG16, VGG19, ResNet50, DenseNet201,
EfficientNetB0, and Vision Transformer (ViT). We evaluated model performance
with Intersection over Union (IoU), Mean Average Precision (MAP), mean absolute
error (MAE), Root Mean Squared Error (RMSE), and Huber loss. The average TSS
from two radiologists was used as the ground truth. Model training employed
3-fold cross-validation, with each fold consisting of 452 training and 227
validation samples, and external testing included 291 unseen subjects. Our
joint identification model achieved 99% accuracy. The best-performing model,
ViT, achieved a notably low Huber loss of 0.87 for TSS prediction. Our results
demonstrate the potential of deep learning to automate RA scoring, which can
significantly enhance clinical practice. Our approach addresses the challenge
of joint disappearance and variable joint numbers, offers timesaving benefits,
reduces inter- and intra-reader variability, improves radiologist accuracy, and
aids rheumatologists in making more informed decisions.

</details>


### [147] [Analysis of Blood Report Images Using General Purpose Vision-Language Models](https://arxiv.org/abs/2509.06033)
*Nadia Bakhsheshi,Hamid Beigy*

Main category: cs.CV

TL;DR: 本研究评估了通用视觉-语言模型（VLMs）自动分析血检报告图像的潜力，发现它们在提高健康素养方面具有实用性和前景。


<details>
  <summary>Details</summary>
Motivation: 个人在解读血检报告时常感困难，导致焦虑并可能忽视重要健康问题，因此需要一种可靠的自动化分析方法。

Method: 研究选取了Qwen-VL-Max、Gemini 2.5 Pro和Llama 4 Maverick三款VLM，在一个包含100张不同血检报告图像的数据集上进行对比评估。模型被提示回答与每份报告相关的临床问题，然后使用Sentence-BERT处理和比较模型的回答。

Result: 研究结果表明，通用VLM是开发面向患者的初步血检报告分析工具的实用且有前景的技术。它们能够直接从图像提供清晰的解读，有助于提高健康素养并减少理解复杂医疗信息的障碍。

Conclusion: VLM为未来开发可靠且易于获取的AI辅助医疗应用奠定了基础。尽管结果令人鼓舞，但鉴于数据集规模有限，应谨慎解读。

Abstract: The reliable analysis of blood reports is important for health knowledge, but
individuals often struggle with interpretation, leading to anxiety and
overlooked issues. We explore the potential of general-purpose Vision-Language
Models (VLMs) to address this challenge by automatically analyzing blood report
images. We conduct a comparative evaluation of three VLMs: Qwen-VL-Max, Gemini
2.5 Pro, and Llama 4 Maverick, determining their performance on a dataset of
100 diverse blood report images. Each model was prompted with clinically
relevant questions adapted to each blood report. The answers were then
processed using Sentence-BERT to compare and evaluate how closely the models
responded. The findings suggest that general-purpose VLMs are a practical and
promising technology for developing patient-facing tools for preliminary blood
report analysis. Their ability to provide clear interpretations directly from
images can improve health literacy and reduce the limitations to understanding
complex medical information. This work establishes a foundation for the future
development of reliable and accessible AI-assisted healthcare applications.
While results are encouraging, they should be interpreted cautiously given the
limited dataset size.

</details>


### [148] [Barlow-Swin: Toward a novel siamese-based segmentation architecture using Swin-Transformers](https://arxiv.org/abs/2509.06885)
*Morteza Kiani Haftlang,Mohammadhossein Malmir,Foroutan Parand,Umberto Michelucci,Safouane El Ghazouali*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级端到端架构，结合了类Swin Transformer编码器和类U-Net解码器，并通过Barlow Twins自监督预训练，实现了实时二值医学图像分割，在保持竞争性准确率的同时显著减少了参数量并加快了推理速度。


<details>
  <summary>Details</summary>
Motivation: 卷积网络（如U-Net）的感受野有限，难以建模全局上下文；现有Transformer集成模型计算成本高昂，不适合实时应用。临床工作流需要一种轻量级、实时且高效的医学图像分割模型。

Method: 提出了一种新颖的端到端轻量级架构，结合了类Swin Transformer编码器和类U-Net解码器，通过跳跃连接保留空间细节并捕获上下文信息。该模型比现有设计更浅、更高效。编码器首先通过Barlow Twins自监督学习方法进行预训练，以在数据量有限的情况下学习有意义的特征，然后对整个模型进行微调。

Result: 在基准二值分割任务上，该模型实现了竞争性的准确率，同时显著减少了参数数量并加快了推理速度。这使其成为在实时和资源受限的临床环境中部署的实用替代方案。

Conclusion: 所提出的轻量级架构通过结合自监督预训练和高效的编码器-解码器设计，为实时二值医学图像分割提供了一个实用且高性能的解决方案，克服了传统方法在全局上下文建模和计算效率方面的限制。

Abstract: Medical image segmentation is a critical task in clinical workflows,
particularly for the detection and delineation of pathological regions. While
convolutional architectures like U-Net have become standard for such tasks,
their limited receptive field restricts global context modeling. Recent efforts
integrating transformers have addressed this, but often result in deep,
computationally expensive models unsuitable for real-time use. In this work, we
present a novel end-to-end lightweight architecture designed specifically for
real-time binary medical image segmentation. Our model combines a Swin
Transformer-like encoder with a U-Net-like decoder, connected via skip pathways
to preserve spatial detail while capturing contextual information. Unlike
existing designs such as Swin Transformer or U-Net, our architecture is
significantly shallower and competitively efficient. To improve the encoder's
ability to learn meaningful features without relying on large amounts of
labeled data, we first train it using Barlow Twins, a self-supervised learning
method that helps the model focus on important patterns by reducing unnecessary
repetition in the learned features. After this pretraining, we fine-tune the
entire model for our specific task. Experiments on benchmark binary
segmentation tasks demonstrate that our model achieves competitive accuracy
with substantially reduced parameter count and faster inference, positioning it
as a practical alternative for deployment in real-time and resource-limited
clinical environments. The code for our method is available at Github
repository: https://github.com/mkianih/Barlow-Swin.

</details>


### [149] [Multi-Stage Graph Neural Networks for Data-Driven Prediction of Natural Convection in Enclosed Cavities](https://arxiv.org/abs/2509.06041)
*Mohammad Ahangarkiasari,Hassan Pouraria*

Main category: cs.CV

TL;DR: 针对传统GNN难以捕捉高分辨率网格中长距离依赖的问题，本文提出一种多阶段GNN架构，通过分层池化与反池化操作，有效提升了复杂传热模拟的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 高精度CFD模拟计算资源消耗大，限制快速迭代；现有GNN在处理高分辨率网格数据时难以有效捕捉长距离依赖关系。

Method: 提出一种新颖的多阶段图神经网络（GNN）架构，通过分层池化（pooling）和反池化（unpooling）操作，逐步建模跨多个空间尺度的全局到局部交互。该模型在一个模拟矩形腔内自然对流的CFD数据集上进行了评估。

Result: 与现有最先进的GNN基线相比，所提出的模型实现了更高的预测精度、更高的训练效率，并减少了长期误差积累。

Conclusion: 提出的多阶段GNN方法在基于网格的流体动力学模拟中，对复杂传热建模展现出巨大潜力。

Abstract: Buoyancy-driven heat transfer in closed cavities serves as a canonical
testbed for thermal design High-fidelity CFD modelling yields accurate thermal
field solutions, yet its reliance on expert-crafted physics models, fine
meshes, and intensive computation limits rapid iteration. Recent developments
in data-driven modeling, especially Graph Neural Networks (GNNs), offer new
alternatives for learning thermal-fluid behavior directly from simulation data,
particularly on irregular mesh structures. However, conventional GNNs often
struggle to capture long-range dependencies in high-resolution graph
structures. To overcome this limitation, we propose a novel multi-stage GNN
architecture that leverages hierarchical pooling and unpooling operations to
progressively model global-to-local interactions across multiple spatial
scales. We evaluate the proposed model on our newly developed CFD dataset
simulating natural convection within a rectangular cavities with varying aspect
ratios where the bottom wall is isothermal hot, the top wall is isothermal
cold, and the two vertical walls are adiabatic. Experimental results
demonstrate that the proposed model achieves higher predictive accuracy,
improved training efficiency, and reduced long-term error accumulation compared
to state-of-the-art (SOTA) GNN baselines. These findings underscore the
potential of the proposed multi-stage GNN approach for modeling complex heat
transfer in mesh-based fluid dynamics simulations.

</details>


### [150] [H$_{2}$OT: Hierarchical Hourglass Tokenizer for Efficient Video Pose Transformers](https://arxiv.org/abs/2509.06956)
*Wenhao Li,Mengyuan Liu,Hong Liu,Pichao Wang,Shijian Lu,Nicu Sebe*

Main category: cs.CV

TL;DR: 本文提出了一种名为H$_{2}$OT的分层即插即用剪枝-恢复框架，用于提高视频3D人体姿态估计中Transformer模型的效率，通过动态剪枝冗余帧的姿态标记并恢复完整序列，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在视频3D人体姿态估计领域表现出色，但其高昂的计算成本使其在资源受限设备上难以实际应用。

Method: 本文提出了H$_{2}$OT框架，包含两个关键模块：标记剪枝模块（TPM）和标记恢复模块（TRM）。TPM动态选择少量代表性标记以消除视频帧的冗余，而TRM则根据这些选定标记恢复详细的时空信息，将网络输出扩展到原始的全长时间分辨率，实现快速推理。该方法是通用性的，可集成到seq2seq和seq2frame管道的常见VPT模型中。

Result: H$_{2}$OT在中间Transformer块中仅使用少量姿态标记，显著提高了模型效率。研究表明，维持完整的姿态序列并非必要，少量代表性帧的姿态标记即可实现高效率和高估计精度。在多个基准数据集上的大量实验证明了所提出方法的有效性和效率。

Conclusion: H$_{2}$OT提供了一种有效且高效的解决方案，通过分层剪枝和恢复姿态标记，解决了视频3D人体姿态估计中Transformer模型计算成本高的问题，使其更适用于资源受限的环境。

Abstract: Transformers have been successfully applied in the field of video-based 3D
human pose estimation. However, the high computational costs of these video
pose transformers (VPTs) make them impractical on resource-constrained devices.
In this paper, we present a hierarchical plug-and-play pruning-and-recovering
framework, called Hierarchical Hourglass Tokenizer (H$_{2}$OT), for efficient
transformer-based 3D human pose estimation from videos. H$_{2}$OT begins with
progressively pruning pose tokens of redundant frames and ends with recovering
full-length sequences, resulting in a few pose tokens in the intermediate
transformer blocks and thus improving the model efficiency. It works with two
key modules, namely, a Token Pruning Module (TPM) and a Token Recovering Module
(TRM). TPM dynamically selects a few representative tokens to eliminate the
redundancy of video frames, while TRM restores the detailed spatio-temporal
information based on the selected tokens, thereby expanding the network output
to the original full-length temporal resolution for fast inference. Our method
is general-purpose: it can be easily incorporated into common VPT models on
both seq2seq and seq2frame pipelines while effectively accommodating different
token pruning and recovery strategies. In addition, our H$_{2}$OT reveals that
maintaining the full pose sequence is unnecessary, and a few pose tokens of
representative frames can achieve both high efficiency and estimation accuracy.
Extensive experiments on multiple benchmark datasets demonstrate both the
effectiveness and efficiency of the proposed method. Code and models are
available at https://github.com/NationalGAILab/HoT.

</details>


### [151] [Home-made Diffusion Model from Scratch to Hatch](https://arxiv.org/abs/2509.06068)
*Shih-Ying Yeh*

Main category: cs.CV

TL;DR: 本文介绍了Home-made Diffusion Model (HDM)，一个高效且强大的文本到图像扩散模型，专为消费级硬件优化，以极低的训练成本实现了高质量的图像生成。


<details>
  <summary>Details</summary>
Motivation: 传统文本到图像扩散模型计算成本高昂，限制了个人研究者和小型组织的使用。该研究旨在降低计算门槛，使高质量文本到图像生成民主化。

Method: 本文提出HDM模型，其核心方法包括：1) Cross-U-Transformer (XUT)，一种新型U形Transformer，利用交叉注意力进行跳跃连接，以实现卓越的特征整合和组合一致性；2) 综合训练方案，融合了TREAD加速、用于高效任意长宽比训练的移位方形裁剪策略，以及渐进式分辨率缩放；3) 采用较小模型（343M参数）和精心设计的架构。

Result: HDM在1024x1024分辨率下实现了具有竞争力的生成质量，同时训练成本显著降低，使用四块RTX5090 GPU仅需$535-620。XUT带来了卓越的组合一致性，并且小模型展现出高质量结果和直观的相机控制等新兴能力。

Conclusion: HDM提供了一种替代的扩展范式，证明了为计算资源有限的个人研究者和小型组织民主化高质量文本到图像生成的可行路径。

Abstract: We introduce Home-made Diffusion Model (HDM), an efficient yet powerful
text-to-image diffusion model optimized for training (and inferring) on
consumer-grade hardware. HDM achieves competitive 1024x1024 generation quality
while maintaining a remarkably low training cost of $535-620 using four RTX5090
GPUs, representing a significant reduction in computational requirements
compared to traditional approaches. Our key contributions include: (1)
Cross-U-Transformer (XUT), a novel U-shape transformer, Cross-U-Transformer
(XUT), that employs cross-attention for skip connections, providing superior
feature integration that leads to remarkable compositional consistency; (2) a
comprehensive training recipe that incorporates TREAD acceleration, a novel
shifted square crop strategy for efficient arbitrary aspect-ratio training, and
progressive resolution scaling; and (3) an empirical demonstration that smaller
models (343M parameters) with carefully crafted architectures can achieve
high-quality results and emergent capabilities, such as intuitive camera
control. Our work provides an alternative paradigm of scaling, demonstrating a
viable path toward democratizing high-quality text-to-image generation for
individual researchers and smaller organizations with limited computational
resources.

</details>


### [152] [High-Quality Tomographic Image Reconstruction Integrating Neural Networks and Mathematical Optimization](https://arxiv.org/abs/2509.06082)
*Anuraag Mishra,Andrea Gilch,Benjamin Apeleo Zubiri,Jan Rolfes,Frauke Liers*

Main category: cs.CV

TL;DR: 开发了一种结合神经网络边缘识别与数学优化模型的新型断层扫描重建技术，旨在提高具有均匀材料相和锐利边缘样本的图像质量，有效消除模糊并增强界面清晰度。


<details>
  <summary>Details</summary>
Motivation: 现有的投影式纳米和微断层扫描重建技术在处理由均匀材料相和锐利边缘组成的样本时，可能存在伪影和模糊，导致重建质量不佳。

Method: 该方法首先训练一个神经网络来识别子图像中的边缘。然后，将训练好的神经网络集成到一个数学优化模型中，以减少先前重建中的伪影。优化方法倾向于根据神经网络学习的预测来寻找解决方案，但如果原始数据强烈支持，也会考虑替代方案。通过这种方式，该技术成功地结合了样本的均匀性和锐利边缘的先验知识。

Result: 在实验数据集上的结果表明，与基准算法相比，该技术在界面锐度和材料均匀性方面都有显著提升。

Conclusion: 该技术能够产生高质量的重建图像，展示了其在推进断层扫描成像技术方面的巨大潜力。

Abstract: In this work, we develop a novel technique for reconstructing images from
projection-based nano- and microtomography. Our contribution focuses on
enhancing reconstruction quality, particularly for specimen composed of
homogeneous material phases connected by sharp edges. This is accomplished by
training a neural network to identify edges within subpictures. The trained
network is then integrated into a mathematical optimization model, to reduce
artifacts from previous reconstructions. To this end, the optimization approach
favors solutions according to the learned predictions, however may also
determine alternative solutions if these are strongly supported by the raw
data. Hence, our technique successfully incorporates knowledge about the
homogeneity and presence of sharp edges in the sample and thereby eliminates
blurriness. Our results on experimental datasets show significant enhancements
in interface sharpness and material homogeneity compared to benchmark
algorithms. Thus, our technique produces high-quality reconstructions,
showcasing its potential for advancing tomographic imaging techniques.

</details>


### [153] [MedSeqFT: Sequential Fine-tuning Foundation Models for 3D Medical Image Segmentation](https://arxiv.org/abs/2509.06096)
*Yiwen Ye,Yicheng Wu,Xiangde Luo,He Zhang,Ziyang Chen,Ting Dang,Yanning Zhang,Yong Xia*

Main category: cs.CV

TL;DR: MedSeqFT是一种用于医学图像分割的顺序微调框架，它通过最大数据相似性选择和基于LoRA的知识蒸馏，使预训练模型能够逐步适应新任务，同时保留通用知识和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的微调策略（并行微调和多任务微调）在医学图像分析中存在局限性：并行微调无法利用共享知识，多任务微调需要同时访问所有数据集且难以增量集成任务，这不适用于下游应用顺序出现的场景。

Method: 本文提出了MedSeqFT框架，包含两个核心组件：1) 最大数据相似性（MDS）选择，用于识别最能代表原始预训练分布的下游样本，以保留通用知识；2) 知识和泛化保留微调（K&G RFT），这是一种基于LoRA的知识蒸馏方案，旨在平衡任务特定适应与预训练知识的保留。

Result: MedSeqFT在两个包含十个3D分割任务的多任务数据集上持续优于最先进的微调策略，取得了显著的性能提升（例如，平均Dice分数提高3.0%）。此外，在两个未见任务（COVID-19-20和Kidney）上的评估验证了MedSeqFT增强了可迁移性，特别是对于肿瘤分割。对损失景观和参数变化的视觉分析进一步强调了MedSeqFT的鲁棒性。

Conclusion: MedSeqFT将顺序微调确立为一种有效且知识保留的范式，用于使基础模型适应不断演变的临床任务，从而在医学图像分析领域取得显著进展。

Abstract: Foundation models have become a promising paradigm for advancing medical
image analysis, particularly for segmentation tasks where downstream
applications often emerge sequentially. Existing fine-tuning strategies,
however, remain limited: parallel fine-tuning isolates tasks and fails to
exploit shared knowledge, while multi-task fine-tuning requires simultaneous
access to all datasets and struggles with incremental task integration. To
address these challenges, we propose MedSeqFT, a sequential fine-tuning
framework that progressively adapts pre-trained models to new tasks while
refining their representational capacity. MedSeqFT introduces two core
components: (1) Maximum Data Similarity (MDS) selection, which identifies
downstream samples most representative of the original pre-training
distribution to preserve general knowledge, and (2) Knowledge and
Generalization Retention Fine-Tuning (K&G RFT), a LoRA-based knowledge
distillation scheme that balances task-specific adaptation with the retention
of pre-trained knowledge. Extensive experiments on two multi-task datasets
covering ten 3D segmentation tasks demonstrate that MedSeqFT consistently
outperforms state-of-the-art fine-tuning strategies, yielding substantial
performance gains (e.g., an average Dice improvement of 3.0%). Furthermore,
evaluations on two unseen tasks (COVID-19-20 and Kidney) verify that MedSeqFT
enhances transferability, particularly for tumor segmentation. Visual analyses
of loss landscapes and parameter variations further highlight the robustness of
MedSeqFT. These results establish sequential fine-tuning as an effective,
knowledge-retentive paradigm for adapting foundation models to evolving
clinical tasks. Code will be released.

</details>


### [154] [PathoHR: Hierarchical Reasoning for Vision-Language Models in Pathology](https://arxiv.org/abs/2509.06105)
*Yating Huang,Ziyan Huang,Lintao Xiang,Qijun Yang,Hujun Yin*

Main category: cs.CV

TL;DR: 该论文提出了PathoHR-Bench基准来评估视觉-语言（VL）模型在病理学中的分层语义理解和组合推理能力，并引入了一种病理学专用VL训练方案，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 自动化肿瘤诊断需要精确分析病理图像，但由于结构相似性和细微形态变异而充满挑战。现有的视觉-语言模型难以捕捉解释结构化病理报告所需的复杂推理，限制了其在临床环境中的应用。

Method: 1. 提出了PathoHR-Bench基准，用于评估VL模型在病理领域的分层语义理解和组合推理能力。2. 引入了一种病理学专用的VL训练方案，通过生成增强和扰动样本进行多模态对比学习。

Result: 1. 现有VL模型未能有效建模复杂的跨模态关系，在PathoHR-Bench上表现不佳。2. 提出的方法在PathoHR-Bench和六个额外的病理学数据集上均达到了最先进的性能。

Conclusion: 该研究表明，现有的VL模型在病理学复杂推理方面存在局限性。提出的PathoHR-Bench基准和病理学专用训练方案能有效增强VL模型在细粒度病理学表示方面的能力，提升其在临床环境中的适用性。

Abstract: Accurate analysis of pathological images is essential for automated tumor
diagnosis but remains challenging due to high structural similarity and subtle
morphological variations in tissue images. Current vision-language (VL) models
often struggle to capture the complex reasoning required for interpreting
structured pathological reports. To address these limitations, we propose
PathoHR-Bench, a novel benchmark designed to evaluate VL models' abilities in
hierarchical semantic understanding and compositional reasoning within the
pathology domain. Results of this benchmark reveal that existing VL models fail
to effectively model intricate cross-modal relationships, hence limiting their
applicability in clinical setting. To overcome this, we further introduce a
pathology-specific VL training scheme that generates enhanced and perturbed
samples for multimodal contrastive learning. Experimental evaluations
demonstrate that our approach achieves state-of-the-art performance on
PathoHR-Bench and six additional pathology datasets, highlighting its
effectiveness in fine-grained pathology representation.

</details>


### [155] [CARDIE: clustering algorithm on relevant descriptors for image enhancement](https://arxiv.org/abs/2509.06116)
*Giulia Bonino,Luca Alberto Rizzo*

Main category: cs.CV

TL;DR: 本文提出了一种名为CARDIE的无监督图像聚类算法，它基于颜色和亮度内容对图像进行聚类，并证明其聚类结果比语义属性更适用于图像增强任务，从而提高了色调映射和去噪算法的性能。


<details>
  <summary>Details</summary>
Motivation: 自动图像聚类在计算机视觉中至关重要，但其在图像增强中的应用受限，主要是因为难以定义对该特定任务有意义的聚类。

Method: 引入了CARDIE，一种基于颜色和亮度内容对图像进行聚类的无监督算法。同时，提出了一种量化图像增强算法对亮度分布和局部方差影响的方法。利用该方法，将CARDIE产生的聚类与语义图像属性产生的聚类进行比较，并利用CARDIE聚类对图像增强数据集进行重采样。

Result: CARDIE产生的聚类比语义图像属性产生的聚类更与图像增强相关。利用CARDIE聚类对图像增强数据集进行重采样，可以提高色调映射和去噪算法的性能。

Conclusion: CARDIE是一种有效的无监督图像聚类算法，能根据颜色和亮度内容生成对图像增强任务有意义的聚类，进而提升相关算法的性能。为促进应用和复现，CARDIE代码已公开。

Abstract: Automatic image clustering is a cornerstone of computer vision, yet its
application to image enhancement remains limited, primarily due to the
difficulty of defining clusters that are meaningful for this specific task. To
address this issue, we introduce CARDIE, an unsupervised algorithm that
clusters images based on their color and luminosity content. In addition, we
introduce a method to quantify the impact of image enhancement algorithms on
luminance distribution and local variance. Using this method, we demonstrate
that CARDIE produces clusters more relevant to image enhancement than those
derived from semantic image attributes. Furthermore, we demonstrate that CARDIE
clusters can be leveraged to resample image enhancement datasets, leading to
improved performance for tone mapping and denoising algorithms. To encourage
adoption and ensure reproducibility, we publicly release CARDIE code on our
GitHub.

</details>


### [156] [RetinaGuard: Obfuscating Retinal Age in Fundus Images for Biometric Privacy Preserving](https://arxiv.org/abs/2509.06142)
*Zhengquan Luo,Chi Liu,Dongfu Xiao,Zhen Yu,Yueye Wang,Tianqing Zhu*

Main category: cs.CV

TL;DR: 该研究提出RetinaGuard框架，通过特征级生成对抗掩码和多对一知识蒸馏，在保留眼底图像视觉质量和疾病诊断效用的同时，模糊了从图像中预测的视网膜年龄这一敏感生物识别信息，以应对生物信息泄露的隐私风险。


<details>
  <summary>Details</summary>
Motivation: 人工智能与医学图像结合可提取隐式图像衍生生物标志物，如视网膜年龄，它能有效预测全身疾病风险、行为模式、衰老轨迹乃至死亡率。然而，这种敏感生物特征数据的推断能力带来了严重的隐私风险，未经授权使用眼底图像可能导致生物信息泄露，侵犯个人隐私。

Method: 研究提出RetinaGuard隐私增强框架，通过以下方法实现：1) 采用特征级生成对抗掩码机制来模糊视网膜年龄，同时保留图像视觉质量和疾病诊断效用；2) 利用新颖的多对一知识蒸馏策略，结合视网膜基础模型和多样化的替代年龄编码器，实现对黑盒年龄预测模型的通用防御。

Result: 综合评估证实，RetinaGuard成功地模糊了视网膜年龄预测，同时对图像质量和病理特征表示的影响最小。该框架还具有灵活性，可扩展应用于其他医学图像衍生的生物标志物。

Conclusion: RetinaGuard提供了一个有效且通用的隐私增强解决方案，能够保护从医学图像中提取的敏感生物识别信息（如视网膜年龄），同时不牺牲图像的诊断价值，并具备扩展到其他生物标志物的潜力。

Abstract: The integration of AI with medical images enables the extraction of implicit
image-derived biomarkers for a precise health assessment. Recently, retinal
age, a biomarker predicted from fundus images, is a proven predictor of
systemic disease risks, behavioral patterns, aging trajectory and even
mortality. However, the capability to infer such sensitive biometric data
raises significant privacy risks, where unauthorized use of fundus images could
lead to bioinformation leakage, breaching individual privacy. In response, we
formulate a new research problem of biometric privacy associated with medical
images and propose RetinaGuard, a novel privacy-enhancing framework that
employs a feature-level generative adversarial masking mechanism to obscure
retinal age while preserving image visual quality and disease diagnostic
utility. The framework further utilizes a novel multiple-to-one knowledge
distillation strategy incorporating a retinal foundation model and diverse
surrogate age encoders to enable a universal defense against black-box age
prediction models. Comprehensive evaluations confirm that RetinaGuard
successfully obfuscates retinal age prediction with minimal impact on image
quality and pathological feature representation. RetinaGuard is also flexible
for extension to other medical image derived biomarkers. RetinaGuard is also
flexible for extension to other medical image biomarkers.

</details>


### [157] [UniVerse-1: Unified Audio-Video Generation via Stitching of Experts](https://arxiv.org/abs/2509.06155)
*Duomin Wang,Wei Zuo,Aojie Li,Ling-Hao Chen,Xinyao Liao,Deyu Zhou,Zixin Yin,Xili Dai,Daxin Jiang,Gang Yu*

Main category: cs.CV

TL;DR: UniVerse-1是一个统一的音视频生成模型，通过“专家缝合”技术整合预训练模型，并利用在线标注流程解决数据对齐问题，实现协调的音视频和高质量的语音生成。


<details>
  <summary>Details</summary>
Motivation: 研究旨在提高音视频生成模型的训练效率，充分利用现有预训练模型的强大能力，并解决传统文本标注中常见的对齐问题导致的性能下降，以推进音视频生成领域的研究并缩小与最先进模型（如Veo3）的性能差距。

Method: 引入UniVerse-1模型，该模型类似于Veo-3，能够同步生成协调的音频和视频。采用“专家缝合”（Stitching of Experts, SoE）技术，深度融合预训练视频和音乐生成专家模型的对应模块，以提升训练效率。开发了在线标注流程，在训练过程中处理训练数据并生成准确且时间对齐的环境音和语音标签。模型在约7,600小时的音视频数据上进行微调。为评估方法，引入了新的基准数据集Verse-Bench。

Result: 经过微调后，UniVerse-1模型能生成与视频内容良好协调的环境音，并在语音生成方面展现出强大的对齐能力。

Conclusion: UniVerse-1通过结合专家缝合技术和在线标注流程，有效地实现了协调的音视频生成和准确的语音对齐。为促进音视频生成研究并缩小与SOTA模型的差距，作者公开了模型、代码以及新的基准数据集Verse-Bench。

Abstract: We introduce UniVerse-1, a unified, Veo-3-like model capable of
simultaneously generating coordinated audio and video. To enhance training
efficiency, we bypass training from scratch and instead employ a stitching of
experts (SoE) technique. This approach deeply fuses the corresponding blocks of
pre-trained video and music generation experts models, thereby fully leveraging
their foundational capabilities. To ensure accurate annotations and temporal
alignment for both ambient sounds and speech with video content, we developed
an online annotation pipeline that processes the required training data and
generates labels during training process. This strategy circumvents the
performance degradation often caused by misalignment text-based annotations.
Through the synergy of these techniques, our model, after being finetuned on
approximately 7,600 hours of audio-video data, produces results with
well-coordinated audio-visuals for ambient sounds generation and strong
alignment for speech generation. To systematically evaluate our proposed
method, we introduce Verse-Bench, a new benchmark dataset. In an effort to
advance research in audio-video generation and to close the performance gap
with state-of-the-art models such as Veo3, we make our model and code publicly
available. We hope this contribution will benefit the broader research
community. Project page: https://dorniwang.github.io/UniVerse-1/.

</details>


### [158] [AI-Based Applied Innovation for Fracture Detection in X-rays Using Custom CNN and Transfer Learning Models](https://arxiv.org/abs/2509.06228)
*Amna Hassan,Ilsa Afzaal,Nouman Muneeb,Aneeqa Batool,Hamail Noor*

Main category: cs.CV

TL;DR: 该研究开发了一种基于定制卷积神经网络（CNN）的AI解决方案，用于X射线图像的自动骨折检测。在FracAtlas数据集上，定制CNN取得了95.96%的准确率，优于迁移学习模型，展示了轻量级CNN在骨折检测中的潜力。


<details>
  <summary>Details</summary>
Motivation: 骨折是一个重大的全球健康挑战，尤其是在资源有限地区，专家放射学服务稀缺。传统成像方法存在成本高、辐射暴露和依赖专业解读等缺点。因此，需要一种自动化、可及的骨折检测方案。

Method: 研究开发了一个基于定制卷积神经网络（CNN）的AI解决方案，用于从X射线图像中自动检测骨折。该方案在包含4,083张匿名肌肉骨骼X射线片的公开FracAtlas数据集上进行训练，并与EfficientNetB0、MobileNetV2和ResNet50等迁移学习模型进行了基准测试。

Result: 定制CNN在FracAtlas数据集上取得了95.96%的准确率、0.94的精确度、0.88的召回率和0.91的F1分数。虽然迁移学习模型在此特定设置中表现不佳，但这些结果应结合类别不平衡和数据集限制来解释。

Conclusion: 这项工作突出了轻量级CNN在X射线骨折检测方面的潜力，并强调了公平基准测试、多样化数据集和外部验证对于临床转化的重要性。

Abstract: Bone fractures present a major global health challenge, often resulting in
pain, reduced mobility, and productivity loss, particularly in low-resource
settings where access to expert radiology services is limited. Conventional
imaging methods suffer from high costs, radiation exposure, and dependency on
specialized interpretation. To address this, we developed an AI-based solution
for automated fracture detection from X-ray images using a custom Convolutional
Neural Network (CNN) and benchmarked it against transfer learning models
including EfficientNetB0, MobileNetV2, and ResNet50. Training was conducted on
the publicly available FracAtlas dataset, comprising 4,083 anonymized
musculoskeletal radiographs. The custom CNN achieved 95.96% accuracy, 0.94
precision, 0.88 recall, and an F1-score of 0.91 on the FracAtlas dataset.
Although transfer learning models (EfficientNetB0, MobileNetV2, ResNet50)
performed poorly in this specific setup, these results should be interpreted in
light of class imbalance and data set limitations. This work highlights the
promise of lightweight CNNs for detecting fractures in X-rays and underscores
the importance of fair benchmarking, diverse datasets, and external validation
for clinical translation

</details>


### [159] [Exploring Light-Weight Object Recognition for Real-Time Document Detection](https://arxiv.org/abs/2509.06246)
*Lucas Wojcik,Luiz Coelho,Roger Granada,David Menotti*

Main category: cs.CV

TL;DR: 本文提出了一种高效的文档检测和校正流水线，通过改进IWPOD-Net并在合成数据集上训练，实现了更小、更高效的模型，同时保持了与现有先进解决方案相当的OCR识别质量。


<details>
  <summary>Details</summary>
Motivation: 尽管物体识别和文档倾斜估计取得了显著进展，但实时文档检测和校正这一细分领域尚未得到充分探索，而它对于从视觉文档中自动检索信息至关重要。现有模型要么追求更大模型的性能，要么追求更小模型的效率，未能有效结合。

Method: 研究人员改编了IWPOD-Net（一个车牌检测网络），并在合成身份证数据集NBID上进行了训练。他们通过数据增强和使用另一个合成数据集MIDV进行跨数据集验证来优化模型。同时，他们将提出的方法与物体识别和倾斜估计领域的其他先进方法进行了比较。性能评估标准是基于Levenshtein距离的新颖OCR质量度量，因为最终目标是提高自动信息检索能力。

Result: 研究发现，即使文档校正不完美，也可以获得先进的性能分数。提出的模型比现有先进解决方案更小、更高效，同时保持了具有竞争力的OCR质量指标。

Conclusion: 本文成功开发了一个高效的文档检测流水线，在OCR检索方面表现令人满意，并且比现有解决方案更快。该模型在保持竞争性OCR质量的同时，展现出更小的体积和更高的效率，证明了文档校正无需完美也能达到先进性能。

Abstract: Object Recognition and Document Skew Estimation have come a long way in terms
of performance and efficiency. New models follow one of two directions:
improving performance using larger models, and improving efficiency using
smaller models. However, real-time document detection and rectification is a
niche that is largely unexplored by the literature, yet it remains a vital step
for automatic information retrieval from visual documents. In this work, we
strive towards an efficient document detection pipeline that is satisfactory in
terms of Optical Character Recognition (OCR) retrieval and faster than other
available solutions. We adapt IWPOD-Net, a license plate detection network, and
train it for detection on NBID, a synthetic ID card dataset. We experiment with
data augmentation and cross-dataset validation with MIDV (another synthetic ID
and passport document dataset) to find the optimal scenario for the model.
Other methods from both the Object Recognition and Skew Estimation
state-of-the-art are evaluated for comparison with our approach. We use each
method to detect and rectify the document, which is then read by an OCR system.
The OCR output is then evaluated using a novel OCR quality metric based on the
Levenshtein distance. Since the end goal is to improve automatic information
retrieval, we use the overall OCR quality as a performance metric. We observe
that with a promising model, document rectification does not have to be perfect
to attain state-of-the-art performance scores. We show that our model is
smaller and more efficient than current state-of-the-art solutions while
retaining a competitive OCR quality metric. All code is available at
https://github.com/BOVIFOCR/iwpod-doc-corners.git

</details>


### [160] [Spatial Reasoning with Vision-Language Models in Ego-Centric Multi-View Scenes](https://arxiv.org/abs/2509.06266)
*Mohsen Gholami,Ahmad Rezaei,Zhou Weimin,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: 当前视觉-语言模型（VLMs）在3D空间关系理解方面存在局限，尤其是在以自我为中心的多视角户外数据中。本文提出了Ego3D-Bench基准来评估VLMs的空间推理能力，并引入了Ego3D-VLM后训练框架以显著提升其性能。


<details>
  <summary>Details</summary>
Motivation: 当前VLMs在理解3D空间关系方面存在主要局限。现有工作主要基于单张图像或室内视频创建空间问答数据集，但现实世界的具身AI（如机器人和自动驾驶汽车）依赖于以自我为中心、多视角观测的户外数据，这方面的评估和提升仍是挑战。

Method: 本文引入了Ego3D-Bench，一个包含8,600多个由人工标注的问答对的新基准，用于评估VLMs在以自我为中心、多视角户外数据上的空间推理能力。作者使用该基准测试了包括GPT-4o、Gemini1.5-Pro等在内的16个SOTA VLM。为弥补性能差距，作者提出了Ego3D-VLM，一个模块化的后训练框架，通过基于估计的全局3D坐标生成认知地图来增强VLMs的3D空间推理能力。

Result: 在Ego3D-Bench上的基准测试显示，人类水平分数与VLM性能之间存在显著差距，表明当前VLMs仍远未达到人类水平的空间理解能力。Ego3D-VLM框架在多项选择问答任务上平均提高了12%的性能，在绝对距离估计任务上平均提高了56%的性能。

Conclusion: Ego3D-Bench和Ego3D-VLM为推动VLMs在现实世界多视角环境中的人类水平空间理解提供了宝贵的工具。当前VLMs在空间理解方面仍有巨大提升空间，而Ego3D-VLM提供了一个有效的解决方案来弥补这一差距。

Abstract: Understanding 3D spatial relationships remains a major limitation of current
Vision-Language Models (VLMs). Prior work has addressed this issue by creating
spatial question-answering (QA) datasets based on single images or indoor
videos. However, real-world embodied AI agents such as robots and self-driving
cars typically rely on ego-centric, multi-view observations. To this end, we
introduce Ego3D-Bench, a new benchmark designed to evaluate the spatial
reasoning abilities of VLMs using ego-centric, multi-view outdoor data.
Ego3D-Bench comprises over 8,600 QA pairs, created with significant involvement
from human annotators to ensure quality and diversity. We benchmark 16 SOTA
VLMs, including GPT-4o, Gemini1.5-Pro, InternVL3, and Qwen2.5-VL. Our results
reveal a notable performance gap between human level scores and VLM
performance, highlighting that current VLMs still fall short of human level
spatial understanding. To bridge this gap, we propose Ego3D-VLM, a
post-training framework that enhances 3D spatial reasoning of VLMs. Ego3D-VLM
generates cognitive map based on estimated global 3D coordinates, resulting in
12% average improvement on multi-choice QA and 56% average improvement on
absolute distance estimation. Ego3D-VLM is modular and can be integrated with
any existing VLM. Together, Ego3D-Bench and Ego3D-VLM offer valuable tools for
advancing toward human level spatial understanding in real-world, multi-view
environments.

</details>


### [161] [AI-driven Remote Facial Skin Hydration and TEWL Assessment from Selfie Images: A Systematic Solution](https://arxiv.org/abs/2509.06282)
*Cecelia Soh,Rizhao Cai,Monalisha Paul,Dennis Sng,Alex Kot*

Main category: cs.CV

TL;DR: 该研究提出了一种利用智能手机自拍面部图像远程估计皮肤水合度（SH）和经表皮水分流失（TEWL）的方法，以实现更便捷的皮肤健康监测。


<details>
  <summary>Details</summary>
Motivation: 皮肤健康评估（如SH和TEWL测量）对公众监测皮肤状况、诊断皮肤问题和个性化护肤至关重要。然而，这些测量通常需要专业仪器和皮肤科诊所，对普通用户而言不易获取，限制了其普及性。

Method: 该方案包括SH/TEWL数据收集、数据预处理，并提出了一种新颖的Skin-Prior Adaptive Vision Transformer模型用于SH/TEWL回归。为解决数据标注不平衡问题，研究还引入了基于对称的对比正则化来减少模型偏差。

Result: 实验发现SH/TEWL数据存在标注不平衡问题，并提出的基于对称的对比正则化能有效减少由不平衡引起的模型偏差。这是首次探索无需物理测量，仅通过自拍面部图像进行皮肤评估的研究。

Conclusion: 这项工作弥合了计算机视觉和皮肤护理研究之间的鸿沟，通过AI驱动的方式，使皮肤分析变得更加易于获取，有望在更广泛的实际应用中推广。

Abstract: Skin health and disease resistance are closely linked to the skin barrier
function, which protects against environmental factors and water loss. Two key
physiological indicators can quantitatively represent this barrier function:
skin hydration (SH) and trans-epidermal water loss (TEWL). Measurement of SH
and TEWL is valuable for the public to monitor skin conditions regularly,
diagnose dermatological issues, and personalize their skincare regimens.
However, these measurements are not easily accessible to general users unless
they visit a dermatology clinic with specialized instruments. To tackle this
problem, we propose a systematic solution to estimate SH and TEWL from selfie
facial images remotely with smartphones. Our solution encompasses multiple
stages, including SH/TEWL data collection, data preprocessing, and formulating
a novel Skin-Prior Adaptive Vision Transformer model for SH/TEWL regression.
Through experiments, we identified the annotation imbalance of the SH/TEWL data
and proposed a symmetric-based contrastive regularization to reduce the model
bias due to the imbalance effectively. This work is the first study to explore
skin assessment from selfie facial images without physical measurements. It
bridges the gap between computer vision and skin care research, enabling
AI-driven accessible skin analysis for broader real-world applications.

</details>


### [162] [Prototype-Aware Multimodal Alignment for Open-Vocabulary Visual Grounding](https://arxiv.org/abs/2509.06291)
*Jiangnan Xie,Xiaolong Zheng,Liang Zheng*

Main category: cs.CV

TL;DR: 本文提出了原型感知多模态学习（PAML）框架，旨在解决视觉定位（VG）在开放词汇场景中因模态对齐不佳、特征融合不足和原型信息利用效率低而面临的挑战，并在开放词汇场景中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的视觉定位方法在标准场景中表现良好，但在开放词汇场景（包含新颖对象类别）中存在显著局限性。这主要源于三个关键因素：视觉和语言模态之间对齐不完善、跨模态特征融合不足，以及语义原型信息利用效率低下。

Method: PAML框架通过以下几个关键组件系统地解决这些问题：1) 利用ALBEF在初始特征编码阶段建立鲁棒的跨模态对齐。2) 引入视觉判别特征编码器，选择性地增强显著对象表示并抑制不相关视觉上下文。3) 包含新颖的原型发现和继承机制，提取并聚合多邻居语义原型，以促进开放词汇识别。4) 这些丰富的特征通过多阶段解码器进行全面的多模态整合，最终进行边界框回归。

Result: 在五个基准数据集上的广泛实验验证了PAML方法的有效性，在标准场景中展现出具有竞争力的性能，并在开放词汇场景中取得了最先进（SOTA）的结果。

Conclusion: PAML框架通过改进跨模态对齐、增强特征融合以及有效利用语义原型信息，成功克服了视觉定位在开放词汇场景中的挑战，显著提升了模型在该场景下的识别能力。

Abstract: Visual Grounding (VG) aims to utilize given natural language queries to
locate specific target objects within images. While current transformer-based
approaches demonstrate strong localization performance in standard scene (i.e,
scenarios without any novel objects), they exhibit notable limitations in
open-vocabulary scene (i.e, both familiar and novel object categories during
testing). These limitations primarily stem from three key factors: (1)
imperfect alignment between visual and linguistic modalities, (2) insufficient
cross-modal feature fusion, and (3) ineffective utilization of semantic
prototype information. To overcome these challenges, we present Prototype-Aware
Multimodal Learning (PAML), an innovative framework that systematically
addresses these issues through several key components: First, we leverage ALBEF
to establish robust cross-modal alignment during initial feature encoding.
Subsequently, our Visual Discriminative Feature Encoder selectively enhances
salient object representations while suppressing irrelevant visual context. The
framework then incorporates a novel prototype discovering and inheriting
mechanism that extracts and aggregates multi-neighbor semantic prototypes to
facilitate open-vocabulary recognition. These enriched features undergo
comprehensive multimodal integration through our Multi-stage Decoder before
final bounding box regression. Extensive experiments across five benchmark
datasets validate our approach, showing competitive performance in standard
scene while achieving state-of-the-art results in open-vocabulary scene. Our
code is available at https://github.com/plankXie/PAML.

</details>


### [163] [Video-based Generalized Category Discovery via Memory-Guided Consistency-Aware Contrastive Learning](https://arxiv.org/abs/2509.06306)
*Zhang Jing,Pu Nan,Xie Yu Xiang,Guo Yanming,Lu Qianqi,Zou Shiwei,Yan Jie,Chen Yan*

Main category: cs.CV

TL;DR: 本文将广义类别发现（GCD）问题扩展到视频领域，提出了一种新的视频广义类别发现（Video-GCD）设置，并开发了记忆引导一致性感知对比学习（MCCL）框架，有效利用时空线索和多视角信息，显著优于现有图像方法。


<details>
  <summary>Details</summary>
Motivation: 大多数现有广义类别发现（GCD）方法仅关注静态图像，这不足以可靠地发现新类别。为了弥补这一不足，研究者将GCD问题扩展到视频领域，并引入Video-GCD新设置，旨在有效整合跨时间的多视角信息以实现准确的类别发现。

Method: 本文提出了一种名为记忆引导一致性感知对比学习（MCCL）的框架。MCCL包含两个核心组件：一致性感知对比学习（CACL）和记忆引导表示增强（MGRE）。CACL利用多视角时间特征来估计未标记实例之间的一致性分数，并以此加权对比损失。MGRE引入双层记忆缓冲区（特征级和logit级），提供全局上下文以增强类内紧凑性和类间可分离性，从而反过来细化CACL中的一致性估计，形成一个相互强化的反馈循环。此外，研究者构建了一个新的Video-GCD基准。

Result: 广泛的实验表明，本文提出的方法显著优于从基于图像的设置改编而来的竞争性GCD方法。这强调了时间信息对于在视频中发现新类别的重要性。

Conclusion: MCCL框架通过显式捕获时空线索和多视角信息，并将其整合到对比学习中，有效解决了Video-GCD问题，实现了卓越的性能，证明了时间信息在视频类别发现中的关键作用。

Abstract: Generalized Category Discovery (GCD) is an emerging and challenging
open-world problem that has garnered increasing attention in recent years. Most
existing GCD methods focus on discovering categories in static images. However,
relying solely on static visual content is often insufficient to reliably
discover novel categories. To bridge this gap, we extend the GCD problem to the
video domain and introduce a new setting, termed Video-GCD. Thus, effectively
integrating multi-perspective information across time is crucial for accurate
Video-GCD. To tackle this challenge, we propose a novel Memory-guided
Consistency-aware Contrastive Learning (MCCL) framework, which explicitly
captures temporal-spatial cues and incorporates them into contrastive learning
through a consistency-guided voting mechanism. MCCL consists of two core
components: Consistency-Aware Contrastive Learning(CACL) and Memory-Guided
Representation Enhancement (MGRE). CACL exploits multiperspective temporal
features to estimate consistency scores between unlabeled instances, which are
then used to weight the contrastive loss accordingly. MGRE introduces a
dual-level memory buffer that maintains both feature-level and logit-level
representations, providing global context to enhance intra-class compactness
and inter-class separability. This in turn refines the consistency estimation
in CACL, forming a mutually reinforcing feedback loop between representation
learning and consistency modeling. To facilitate a comprehensive evaluation, we
construct a new and challenging Video-GCD benchmark, which includes action
recognition and bird classification video datasets. Extensive experiments
demonstrate that our method significantly outperforms competitive GCD
approaches adapted from image-based settings, highlighting the importance of
temporal information for discovering novel categories in videos. The code will
be publicly available.

</details>


### [164] [Text4Seg++: Advancing Image Segmentation via Generative Language Modeling](https://arxiv.org/abs/2509.06321)
*Mengcheng Lan,Chaofeng Chen,Jiaxing Xu,Zongrui Li,Yiping Ke,Xudong Jiang,Yingchen Yu,Yunqing Zhao,Song Bai*

Main category: cs.CV

TL;DR: 该研究提出了一种“文本即掩码”范式，将图像分割转化为文本生成问题，通过语义描述符（将图像块映射为文本标签）实现，并引入R-RLE和语义砖块进一步优化，最终模型Text4Seg++在多模态大语言模型（MLLM）框架下实现了领先的分割性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在视觉-语言任务中表现出色，但将图像分割有效整合到这些模型中仍是一个重大挑战，通常需要额外的解码器。

Method: 研究提出了一种新颖的“文本即掩码”范式，将图像分割视为文本生成问题。核心创新是语义描述符，这是一种将每个图像块映射到其对应文本标签的文本表示。首先引入图像级语义描述符，并利用行级行程编码（R-RLE）压缩冗余文本序列以提高效率。在此基础上，提出了初始框架Text4Seg。为进一步提高粒度和紧凑性，引入了边界框级语义描述符，通过边界框定位感兴趣区域，并使用结构化掩码标记“语义砖块”表示区域掩码，从而形成了改进模型Text4Seg++。

Result: R-RLE将语义描述符的长度减少了74%，并将推理速度提高了3倍，同时不影响性能。Text4Seg在广泛的视觉任务中实现了强大的分割性能。Text4Seg++在自然和遥感数据集上的综合实验表明，它在各种基准测试中始终优于现有最先进的模型，无需任何任务特定的微调，并且与现有MLLM骨干兼容。

Conclusion: 该工作突出了在多模态大语言模型（MLLM）框架内，文本驱动的图像分割方法的有效性、可扩展性和泛化性。

Abstract: Multimodal Large Language Models (MLLMs) have shown exceptional capabilities
in vision-language tasks. However, effectively integrating image segmentation
into these models remains a significant challenge. In this work, we propose a
novel text-as-mask paradigm that casts image segmentation as a text generation
problem, eliminating the need for additional decoders and significantly
simplifying the segmentation process. Our key innovation is semantic
descriptors, a new textual representation of segmentation masks where each
image patch is mapped to its corresponding text label. We first introduce
image-wise semantic descriptors, a patch-aligned textual representation of
segmentation masks that integrates naturally into the language modeling
pipeline. To enhance efficiency, we introduce the Row-wise Run-Length Encoding
(R-RLE), which compresses redundant text sequences, reducing the length of
semantic descriptors by 74% and accelerating inference by $3\times$, without
compromising performance. Building upon this, our initial framework Text4Seg
achieves strong segmentation performance across a wide range of vision tasks.
To further improve granularity and compactness, we propose box-wise semantic
descriptors, which localizes regions of interest using bounding boxes and
represents region masks via structured mask tokens called semantic bricks. This
leads to our refined model, Text4Seg++, which formulates segmentation as a
next-brick prediction task, combining precision, scalability, and generative
efficiency. Comprehensive experiments on natural and remote sensing datasets
show that Text4Seg++ consistently outperforms state-of-the-art models across
diverse benchmarks without any task-specific fine-tuning, while remaining
compatible with existing MLLM backbones. Our work highlights the effectiveness,
scalability, and generalizability of text-driven image segmentation within the
MLLM framework.

</details>


### [165] [Towards scalable organ level 3D plant segmentation: Bridging the data algorithm computing gap](https://arxiv.org/abs/2509.06329)
*Ruiming Du,Guangxun Zhai,Tian Qiu,Yu Jiang*

Main category: cs.CV

TL;DR: 这篇综述系统性地解决了3D植物点云分割在数据、方法和基准方面的挑战，介绍了Plant Segmentation Studio (PSS)框架，评估了代表性网络和sim-to-real学习策略，并为3D植物表型分析提供了实用工具和发展路线图。


<details>
  <summary>Details</summary>
Motivation: 植物形态的精确表征对理解植物与环境的互作及遗传进化至关重要，而3D分割是提取这些信息的关键技术。然而，3D植物表型分析中的3D分割面临三大挑战：缺乏大规模标注数据集、难以将先进深度神经网络应用于植物点云、以及缺乏标准化基准和评估协议。

Method: 本研究通过以下方式解决上述障碍：1) 概述现有3D植物数据集；2) 系统总结基于深度学习的点云语义和实例分割方法；3) 引入开源框架Plant Segmentation Studio (PSS)用于可复现的基准测试；4) 进行广泛的定量实验，评估代表性网络和sim-to-real学习策略。

Result: 研究结果表明稀疏卷积骨干网络和基于Transformer的实例分割是有效的。同时，强调了基于模型和基于增强的合成数据生成（用于sim-to-real学习）在减少标注需求方面的互补作用。

Conclusion: 本研究弥合了算法进展与实际部署之间的鸿沟，为研究人员提供了即时工具，并为开发3D植物表型分析中数据高效且泛化性强的深度学习解决方案提供了路线图。

Abstract: The precise characterization of plant morphology provides valuable insights
into plant environment interactions and genetic evolution. A key technology for
extracting this information is 3D segmentation, which delineates individual
plant organs from complex point clouds. Despite significant progress in general
3D computer vision domains, the adoption of 3D segmentation for plant
phenotyping remains limited by three major challenges: i) the scarcity of
large-scale annotated datasets, ii) technical difficulties in adapting advanced
deep neural networks to plant point clouds, and iii) the lack of standardized
benchmarks and evaluation protocols tailored to plant science. This review
systematically addresses these barriers by: i) providing an overview of
existing 3D plant datasets in the context of general 3D segmentation domains,
ii) systematically summarizing deep learning-based methods for point cloud
semantic and instance segmentation, iii) introducing Plant Segmentation Studio
(PSS), an open-source framework for reproducible benchmarking, and iv)
conducting extensive quantitative experiments to evaluate representative
networks and sim-to-real learning strategies. Our findings highlight the
efficacy of sparse convolutional backbones and transformer-based instance
segmentation, while also emphasizing the complementary role of modeling-based
and augmentation-based synthetic data generation for sim-to-real learning in
reducing annotation demands. In general, this study bridges the gap between
algorithmic advances and practical deployment, providing immediate tools for
researchers and a roadmap for developing data-efficient and generalizable deep
learning solutions in 3D plant phenotyping. Data and code are available at
https://github.com/perrydoremi/PlantSegStudio.

</details>


### [166] [Quantitative Currency Evaluation in Low-Resource Settings through Pattern Analysis to Assist Visually Impaired Users](https://arxiv.org/abs/2509.06331)
*Md Sultanul Islam Ovi,Mainul Hossain,Md Badsha Biswas*

Main category: cs.CV

TL;DR: 本文提出了一个统一的货币评估框架，集成了面额分类、损伤量化和伪钞检测功能，适用于低资源环境下的实时、设备端部署。


<details>
  <summary>Details</summary>
Motivation: 现有货币识别系统常忽略可用性和真实性评估，特别是在视觉障碍用户和离线验证常见的低资源环境中，且未充分考虑物理磨损和伪造问题。

Method: 该框架包含三个模块：使用轻量级CNN模型（如Custom_CNN）进行面额分类；通过新颖的统一货币损伤指数（UCDI，基于二值掩码损失、色度失真和结构特征损失）进行损伤量化；以及使用基于特征的模板匹配进行伪钞检测。数据集包含超过82,000张带标注的清洁、受损和伪造钞票图像，支持实时、设备端推理。

Result: Custom_CNN模型以低参数量实现了高分类性能；UCDI指标提供了连续的可用性评分；伪钞检测模块在不同成像条件下均能可靠识别伪造钞票。该框架支持实时、设备端推理，并在受限环境中解决了关键部署挑战。

Conclusion: 该研究表明，准确、可解释且紧凑的解决方案能够支持在实际应用场景中实现包容性的货币评估。

Abstract: Currency recognition systems often overlook usability and authenticity
assessment, especially in low-resource environments where visually impaired
users and offline validation are common. While existing methods focus on
denomination classification, they typically ignore physical degradation and
forgery, limiting their applicability in real-world conditions. This paper
presents a unified framework for currency evaluation that integrates three
modules: denomination classification using lightweight CNN models, damage
quantification through a novel Unified Currency Damage Index (UCDI), and
counterfeit detection using feature-based template matching. The dataset
consists of over 82,000 annotated images spanning clean, damaged, and
counterfeit notes. Our Custom_CNN model achieves high classification
performance with low parameter count. The UCDI metric provides a continuous
usability score based on binary mask loss, chromatic distortion, and structural
feature loss. The counterfeit detection module demonstrates reliable
identification of forged notes across varied imaging conditions. The framework
supports real-time, on-device inference and addresses key deployment challenges
in constrained environments. Results show that accurate, interpretable, and
compact solutions can support inclusive currency evaluation in practical
settings.

</details>


### [167] [Harnessing Object Grounding for Time-Sensitive Video Understanding](https://arxiv.org/abs/2509.06335)
*Tz-Ying Wu,Sharath Nittur Sridhar,Subarna Tripathi*

Main category: cs.CV

TL;DR: 本文提出GO-Tokenizer，一个轻量级模块，通过实时编码紧凑的地面物体（GO）信息，显著提升视频大语言模型（Video-LLMs）的时间敏感视频理解（TSV）能力，优于使用文本描述的方法。


<details>
  <summary>Details</summary>
Motivation: 时间敏感视频理解（TSV）任务可以从帧内的地面物体（GO）中受益，初步实验（在LITA上）也支持这一假设。然而，通过文本描述来增强提示会增加令牌长度，并容易受到物体级别信息中噪声的影响。

Method: 为了解决文本描述的局限性，本文提出了GO-Tokenizer，这是一个轻量级的Video-LLM附加模块。它利用现成的物体检测器来实时编码紧凑的物体信息，避免了冗长的文本描述。

Result: 实验结果表明，使用GO-Tokenizer进行预训练的模型，其性能优于原始的Video-LLM以及在提示中使用物体文本描述的对应模型。这种性能提升在不同的模型、数据集和视频理解任务（如推理时间定位和密集字幕）中都具有泛化性。

Conclusion: GO-Tokenizer通过有效且紧凑地编码地面物体信息，成功提升了Video-LLMs的时间敏感视频理解能力。它在性能和泛化性方面均优于传统的文本描述方法，为视频理解任务提供了更鲁棒的解决方案。

Abstract: We propose to improve the time-sensitive video understanding (TSV) capability
of video large language models (Video-LLMs) with grounded objects (GO). We
hypothesize that TSV tasks can benefit from GO within frames, which is
supported by our preliminary experiments on LITA, a state-of-the-art Video-LLM
for reasoning temporal localization. While augmenting prompts with textual
description of these object annotations improves the performance of LITA, it
also introduces extra token length and susceptibility to the noise in object
level information. To address this, we propose GO-Tokenizer, a lightweight
add-on module for Video-LLMs leveraging off-the-shelf object detectors to
encode compact object information on the fly. Experimental results demonstrate
that pretraining with GO-Tokenizer outperforms the vanilla Video-LLM and its
counterpart utilizing textual description of objects in the prompt. The gain
generalizes across different models, datasets and video understanding tasks
such as reasoning temporal localization and dense captioning.

</details>


### [168] [A Multi-Modal Deep Learning Framework for Colorectal Pathology Diagnosis: Integrating Histological and Colonoscopy Data in a Pilot Study](https://arxiv.org/abs/2509.06351)
*Krithik Ramesh,Ritvik Koneru*

Main category: cs.CV

TL;DR: 本研究提出并验证了一个统一的深度学习诊断流程，该流程使用卷积神经网络（ResNet-50）同时对结肠组织病理图像和结肠镜视频帧进行分类，以提高结直肠疾病的诊断效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 结直肠疾病需要快速准确的治疗。传统的诊断流程依赖于对组织学图像和结肠镜视频的独立评估，这导致了潜在的变异性和低效率，且需要大量准备。

Method: 本研究提出了一个统一的深度学习网络，该网络利用卷积神经网络（CNNs，具体为ResNet-50）在一个流程中对组织病理学切片和结肠镜视频帧进行分类。该流程整合了类别平衡学习、鲁棒数据增强和校准方法以确保结果的准确性。组织学图像取自PathMNIST数据集，结肠镜视频取自HyperKvasir数据集。

Result: 本研究成功展示了一个可解释且可重现的诊断流程，该流程统一了多种诊断模式，从而能够推进并简化结直肠疾病的检测。

Conclusion: 通过统一组织病理学和结肠镜视频分析，该深度学习诊断流程有望显著提升结直肠疾病诊断的效率、准确性和便捷性，克服传统方法的局限性。

Abstract: Colorectal diseases, including inflammatory conditions and neoplasms, require
quick, accurate care to be effectively treated. Traditional diagnostic
pipelines require extensive preparation and rely on separate, individual
evaluations on histological images and colonoscopy footage, introducing
possible variability and inefficiencies. This pilot study proposes a unified
deep learning network that uses convolutional neural networks (CN N s) to
classify both histopathological slides and colonoscopy video frames in one
pipeline. The pipeline integrates class-balancing learning, robust
augmentation, and calibration methods to ensure accurate results. Static colon
histology images were taken from the PathMNIST dataset, and the lower
gastrointestinal (colonoscopy) videos were drawn from the HyperKvasir dataset.
The CNN architecture used was ResNet-50. This study demonstrates an
interpretable and reproducible diagnostic pipeline that unifies multiple
diagnostic modalities to advance and ease the detection of colorectal diseases.

</details>


### [169] [Your Super Resolution Model is not Enough for Tackling Real-World Scenarios](https://arxiv.org/abs/2509.06387)
*Dongsik Yoon,Jongeun Kim*

Main category: cs.CV

TL;DR: 本文提出了一种可插拔的尺度感知注意力模块（SAAM），旨在使现有固定尺度超分辨率模型能够执行任意尺度超分辨率，从而提高其泛化能力和实际应用性。


<details>
  <summary>Details</summary>
Motivation: 传统的单图像超分辨率（SISR）模型难以泛化到不同的尺度因子，限制了它们在现实世界中的应用。

Method: SAAM模块采用轻量级、尺度自适应的特征提取和上采样，并结合了简单的无参数注意力模块（SimAM）以实现高效指导。此外，还引入了梯度方差损失来增强图像细节的清晰度。该方法可以无缝集成到多个最先进的超分辨率骨干网络中。

Result: 实验表明，SAAM在各种整数和非整数尺度因子下，都能在基准数据集上提供具有竞争力或更优的性能。该方法实现了鲁棒的多尺度上采样，且计算开销极小。

Conclusion: SAAM为现实世界的任意尺度超分辨率场景提供了一个实用的解决方案，有效解决了传统模型泛化能力不足的问题。

Abstract: Despite remarkable progress in Single Image Super-Resolution (SISR),
traditional models often struggle to generalize across varying scale factors,
limiting their real-world applicability. To address this, we propose a plug-in
Scale-Aware Attention Module (SAAM) designed to retrofit modern fixed-scale SR
models with the ability to perform arbitrary-scale SR. SAAM employs
lightweight, scale-adaptive feature extraction and upsampling, incorporating
the Simple parameter-free Attention Module (SimAM) for efficient guidance and
gradient variance loss to enhance sharpness in image details. Our method
integrates seamlessly into multiple state-of-the-art SR backbones (e.g., SCNet,
HiT-SR, OverNet), delivering competitive or superior performance across a wide
range of integer and non-integer scale factors. Extensive experiments on
benchmark datasets demonstrate that our approach enables robust multi-scale
upscaling with minimal computational overhead, offering a practical solution
for real-world scenarios.

</details>


### [170] [AI-based response assessment and prediction in longitudinal imaging for brain metastases treated with stereotactic radiosurgery](https://arxiv.org/abs/2509.06396)
*Lorenz Achim Kuhn,Daniel Abler,Jonas Richiardi,Andreas F. Hottinger,Luis Schiappacasse,Vincent Dunet,Adrien Depeursinge,Vincent Andrearczyk*

Main category: cs.CV

TL;DR: 本研究开发了一个自动化流程来整理脑转移瘤(BM)的纵向影像数据，通过数据驱动的聚类识别了五种生长轨迹，并使用经典机器学习和图机器学习成功预测了立体定向放射外科(SRS)治疗后的病灶反应，准确率高达0.90 AUC。


<details>
  <summary>Details</summary>
Motivation: 脑转移瘤是癌症患者死亡率的重要原因。虽然立体定向放射外科(SRS)是主要治疗方法，但对治疗后定期MRI随访影像的分析和量化对临床医生来说是巨大的工作量，导致随访图像通常只进行观察性评估。因此，迫切需要更好地理解生长轨迹，并尽早预测治疗成功或毒性。

Method: 研究实施了一个自动化流程来整理大型纵向SRS治疗数据集，构建了一个包含177名患者中896个BMs的队列，这些患者在超过360天的时间内以大约两个月的间隔进行监测。方法包括：1) 使用数据驱动的聚类来识别特征性生长轨迹；2) 使用经典机器学习（如梯度提升）和图机器学习(GML)来预测12个月的病灶层面反应，其中经典机器学习使用治疗前和首次随访MRI数据，GML则能灵活处理多个输入时间点配置。

Result: 聚类分析揭示了5种主要的生长轨迹，它们具有不同的最终反应类别。使用治疗前和首次随访MRI数据，梯度提升模型预测反应的AUC高达0.90 (95%置信区间=0.88-0.92)。图机器学习(GML)也取得了高达0.88 AUC (95%置信区间=0.86-0.90)的稳健预测性能，并为多时间点输入配置提供了更大的灵活性。

Conclusion: 研究结果表明，在纵向MRI中自动化和提高对SRS治疗后脑转移瘤反应评估和预测的精度是可行的。所提出的流程有助于可扩展的数据整理，用于研究脑转移瘤的生长模式，并为旨在优化个性化护理的临床决策支持系统奠定了基础。

Abstract: Brain Metastases (BM) are a large contributor to mortality of patients with
cancer. They are treated with Stereotactic Radiosurgery (SRS) and monitored
with Magnetic Resonance Imaging (MRI) at regular follow-up intervals according
to treatment guidelines. Analyzing and quantifying this longitudinal imaging
represents an intractable workload for clinicians. As a result, follow-up
images are not annotated and merely assessed by observation. Response to
treatment in longitudinal imaging is being studied, to better understand growth
trajectories and ultimately predict treatment success or toxicity as early as
possible. In this study, we implement an automated pipeline to curate a large
longitudinal dataset of SRS treatment data, resulting in a cohort of 896 BMs in
177 patients who were monitored for >360 days at approximately two-month
intervals at Lausanne University Hospital (CHUV). We use a data-driven
clustering to identify characteristic trajectories. In addition, we predict 12
months lesion-level response using classical as well as graph machine learning
Graph Machine Learning (GML). Clustering revealed 5 dominant growth
trajectories with distinct final response categories. Response prediction
reaches up to 0.90 AUC (CI95%=0.88-0.92) using only pre-treatment and first
follow-up MRI with gradient boosting. Similarly, robust predictive performance
of up to 0.88 AUC (CI95%=0.86-0.90) was obtained using GML, offering more
flexibility with a single model for multiple input time-points configurations.
Our results suggest potential automation and increased precision for the
comprehensive assessment and prediction of BM response to SRS in longitudinal
MRI. The proposed pipeline facilitates scalable data curation for the
investigation of BM growth patterns, and lays the foundation for clinical
decision support systems aiming at optimizing personalized care.

</details>


### [171] [3DOF+Quantization: 3DGS quantization for large scenes with limited Degrees of Freedom](https://arxiv.org/abs/2509.06400)
*Matthieu Gendrin,Stéphane Pateux,Théo Ladune*

Main category: cs.CV

TL;DR: 本文研究了3D Gaussian Splatting (3DGS) 在大场景“3DoF+”受限自由度下的坐标量化问题，分析了位置误差对投影误差的影响，并提出了一种基于球坐标的新量化方案。


<details>
  <summary>Details</summary>
Motivation: 3DGS在生成新视角方面取得了突破，但对于大场景，输入视图通常来自有限区域，导致相机位置自由度受限（3DoF+）。在这种情况下，坐标量化问题及其对像素投影误差的影响是一个值得关注的问题。

Method: 研究了坐标量化中位置误差对像素投影误差的影响，发现投影误差与被投影点距离的平方反比成正比。基于此分析，提出了一种新的基于球坐标的量化方案。

Result: 研究表明，投影误差与被投影点距离的平方反比成正比。所提出的基于球坐标的量化方法在著名的Garden场景上展示了其率失真性能。

Conclusion: 在3DGS的3DoF+场景中，坐标量化对投影误差有显著影响，且误差与距离平方反比相关。提出的球坐标量化方案能有效解决此问题，提升性能。

Abstract: 3D Gaussian Splatting (3DGS) is a major breakthrough in 3D scene
reconstruction. With a number of views of a given object or scene, the
algorithm trains a model composed of 3D gaussians, which enables the production
of novel views from arbitrary points of view. This freedom of movement is
referred to as 6DoF for 6 degrees of freedom: a view is produced for any
position (3 degrees), orientation of camera (3 other degrees). On large scenes,
though, the input views are acquired from a limited zone in space, and the
reconstruction is valuable for novel views from the same zone, even if the
scene itself is almost unlimited in size. We refer to this particular case as
3DoF+, meaning that the 3 degrees of freedom of camera position are limited to
small offsets around the central position. Considering the problem of
coordinate quantization, the impact of position error on the projection error
in pixels is studied. It is shown that the projection error is proportional to
the squared inverse distance of the point being projected. Consequently, a new
quantization scheme based on spherical coordinates is proposed. Rate-distortion
performance of the proposed method are illustrated on the well-known Garden
scene.

</details>


### [172] [Phantom-Insight: Adaptive Multi-cue Fusion for Video Camouflaged Object Detection with Multimodal LLM](https://arxiv.org/abs/2509.06422)
*Hua Zhang,Changjiang Luo,Ruoyu Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为Phantom-Insight的视频伪装目标检测（VCOD）方法，结合了SAM和MLLM的优势，通过增强边缘细节分离和解耦前景-背景学习来解决现有方法的局限性，实现了最先进的性能和强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有VCOD方法在动态环境中面临挑战：基于SAM的方法因模型冻结难以分离伪装目标边缘；基于MLLM的方法因大语言模型合并前景和背景而导致目标可分离性差。本研究旨在解决这些问题。

Method: 提出Phantom-Insight方法，结合SAM和MLLM。为增强边缘细节可分离性，利用时空线索表示视频序列并通过LLM进行特征融合；通过动态前景视觉token评分模块和提示网络自适应指导和微调SAM。为增强前景-背景可分离性，提出解耦的前景-背景学习策略，分别生成前景和背景线索并进行解耦训练，使视觉token独立整合信息。

Result: Phantom-Insight在MoCA-Mask数据集上取得了最先进的性能，并在CAD2016数据集上对未见过的伪装目标展现出强大的泛化能力。

Conclusion: Phantom-Insight通过创新的特征融合和解耦学习策略，有效提升了SAM和MLLM在视频伪装目标检测中的表现，解决了边缘分离和前景-背景区分的难题，达到了卓越的性能和泛化能力。

Abstract: Video camouflaged object detection (VCOD) is challenging due to dynamic
environments. Existing methods face two main issues: (1) SAM-based methods
struggle to separate camouflaged object edges due to model freezing, and (2)
MLLM-based methods suffer from poor object separability as large language
models merge foreground and background. To address these issues, we propose a
novel VCOD method based on SAM and MLLM, called Phantom-Insight. To enhance the
separability of object edge details, we represent video sequences with temporal
and spatial clues and perform feature fusion via LLM to increase information
density. Next, multiple cues are generated through the dynamic foreground
visual token scoring module and the prompt network to adaptively guide and
fine-tune the SAM model, enabling it to adapt to subtle textures. To enhance
the separability of objects and background, we propose a decoupled
foreground-background learning strategy. By generating foreground and
background cues separately and performing decoupled training, the visual token
can effectively integrate foreground and background information independently,
enabling SAM to more accurately segment camouflaged objects in the video.
Experiments on the MoCA-Mask dataset show that Phantom-Insight achieves
state-of-the-art performance across various metrics. Additionally, its ability
to detect unseen camouflaged objects on the CAD2016 dataset highlights its
strong generalization ability.

</details>


### [173] [When Language Model Guides Vision: Grounding DINO for Cattle Muzzle Detection](https://arxiv.org/abs/2509.06427)
*Rabin Dulal,Lihong Zheng,Muhammad Ashad Kabir*

Main category: cs.CV

TL;DR: 本研究提出了一种基于Grounding DINO的零样本牛鼻纹检测框架，无需标注数据即可实现高效检测，并在实际应用中表现出良好性能。


<details>
  <summary>Details</summary>
Motivation: 牛鼻纹是有效的生物识别特征。现有牛鼻纹检测方法存在局限性：手动检测费时费力且不一致；基于YOLO等监督模型的自动化方法需要大量标注数据，且对训练数据依赖性强，在新或未见过的牛只上性能受限。

Method: 本研究提出了一种基于Grounding DINO（一种视觉-语言模型）的零样本牛鼻纹检测框架。该方法利用自然语言提示引导检测，无需任何特定任务训练或标注数据，从而实现跨不同品种和环境的牛鼻纹定位。

Result: 该模型在无需标注数据的情况下，取得了76.8%的mAP@0.5（平均精度），展现出良好的性能。据作者所知，这是首个为牛鼻纹检测提供真实世界、面向行业且无需标注解决方案的研究。

Conclusion: 该框架为监督方法提供了一种实用的替代方案，有望提高牲畜监测应用的适应性和部署便利性。

Abstract: Muzzle patterns are among the most effective biometric traits for cattle
identification. Fast and accurate detection of the muzzle region as the region
of interest is critical to automatic visual cattle identification.. Earlier
approaches relied on manual detection, which is labor-intensive and
inconsistent. Recently, automated methods using supervised models like YOLO
have become popular for muzzle detection. Although effective, these methods
require extensive annotated datasets and tend to be trained data-dependent,
limiting their performance on new or unseen cattle. To address these
limitations, this study proposes a zero-shot muzzle detection framework based
on Grounding DINO, a vision-language model capable of detecting muzzles without
any task-specific training or annotated data. This approach leverages natural
language prompts to guide detection, enabling scalable and flexible muzzle
localization across diverse breeds and environments. Our model achieves a mean
Average Precision (mAP)@0.5 of 76.8\%, demonstrating promising performance
without requiring annotated data. To our knowledge, this is the first research
to provide a real-world, industry-oriented, and annotation-free solution for
cattle muzzle detection. The framework offers a practical alternative to
supervised methods, promising improved adaptability and ease of deployment in
livestock monitoring applications.

</details>


### [174] [Cross3DReg: Towards a Large-scale Real-world Cross-source Point Cloud Registration Benchmark](https://arxiv.org/abs/2509.06456)
*Zongyi Xu,Zhongpeng Lang,Yilong Chen,Shanshan Zhao,Xiaoshui Huang,Yifan Zuo,Yan Zhang,Qianni Zhang,Xinbo Gao*

Main category: cs.CV

TL;DR: 该研究构建了目前最大的真实世界多模态跨源点云配准数据集Cross3DReg，并提出了一种基于重叠区域预测和视觉-几何注意力引导匹配的跨源点云配准框架，显著提升了配准精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 跨源点云配准面临两大核心挑战：缺乏用于训练深度配准模型的公开大规模真实世界数据集，以及不同传感器捕获的点云固有的差异性，这些差异导致特征提取和匹配困难，影响配准精度。

Method: 1. 构建了Cross3DReg数据集，这是目前最大的真实世界多模态跨源点云配准数据集，由旋转机械激光雷达和混合固态激光雷达采集。2. 设计了一个基于重叠区域的跨源配准框架，利用未对齐图像预测点云重叠区域，过滤冗余点，减少非重叠区域噪声干扰。3. 提出了一个视觉-几何注意力引导匹配模块，融合图像和几何信息，增强跨源点云特征的一致性，建立可靠对应关系。

Result: 实验结果表明，所提出的方法实现了最先进的配准性能。相对旋转误差（RRE）降低了63.2%，相对平移误差（RTE）降低了40.2%，配准召回率（RR）提高了5.4%。

Conclusion: 该研究通过构建大规模真实世界数据集和提出创新的重叠区域预测与视觉-几何注意力引导匹配框架，有效解决了跨源点云配准中的核心挑战，实现了准确鲁棒的跨源配准，验证了其方法的有效性。

Abstract: Cross-source point cloud registration, which aims to align point cloud data
from different sensors, is a fundamental task in 3D vision. However, compared
to the same-source point cloud registration, cross-source registration faces
two core challenges: the lack of publicly available large-scale real-world
datasets for training the deep registration models, and the inherent
differences in point clouds captured by multiple sensors. The diverse patterns
induced by the sensors pose great challenges in robust and accurate point cloud
feature extraction and matching, which negatively influence the registration
accuracy. To advance research in this field, we construct Cross3DReg, the
currently largest and real-world multi-modal cross-source point cloud
registration dataset, which is collected by a rotating mechanical lidar and a
hybrid semi-solid-state lidar, respectively. Moreover, we design an
overlap-based cross-source registration framework, which utilizes unaligned
images to predict the overlapping region between source and target point
clouds, effectively filtering out redundant points in the irrelevant regions
and significantly mitigating the interference caused by noise in
non-overlapping areas. Then, a visual-geometric attention guided matching
module is proposed to enhance the consistency of cross-source point cloud
features by fusing image and geometric information to establish reliable
correspondences and ultimately achieve accurate and robust registration.
Extensive experiments show that our method achieves state-of-the-art
registration performance. Our framework reduces the relative rotation error
(RRE) and relative translation error (RTE) by $63.2\%$ and $40.2\%$,
respectively, and improves the registration recall (RR) by $5.4\%$, which
validates its effectiveness in achieving accurate cross-source registration.

</details>


### [175] [IGAff: Benchmarking Adversarial Iterative and Genetic Affine Algorithms on Deep Neural Networks](https://arxiv.org/abs/2509.06459)
*Sebastian-Vasile Echim,Andrei-Alexandru Preda,Dumitru-Clementin Cercel,Florin Pop*

Main category: cs.CV

TL;DR: 本论文提出了两种新颖的黑盒迭代对抗性攻击算法（ATA和AGA），它们基于仿射变换和遗传算法，旨在揭示深度神经网络的弱点。实验结果表明，这些算法在图像分类任务上优于现有方法，准确率提升高达8.82%。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在许多AI领域表现出色，但仍难以理解且存在意外的弱点。对抗性攻击旨在生成输入以揭示这些弱点，尤其是在模型细节不可访问的黑盒场景下，这更具挑战性。

Method: 研究详细探讨了对抗性算法对ResNet-18、DenseNet-121、Swin Transformer V2和Vision Transformer架构的影响。利用Tiny ImageNet、Caltech-256和Food-101数据集，基准测试了两种基于仿射变换和遗传算法的新型黑盒迭代对抗性算法：仿射变换攻击（ATA）和仿射遗传攻击（AGA）。评估了模型在算法参数变化、数据增强以及全局和目标攻击配置下的性能，并与Pixle和Square Attack两种黑盒对抗性算法进行了比较。

Result: 实验结果显示，提出的算法在图像分类任务上取得了比现有文献中类似方法更好的结果，准确率最高提升了8.82%。论文还为全局和目标层面的成功对抗性防御和攻击提供了有价值的见解，并通过算法参数变化展示了对抗性鲁棒性。

Conclusion: 本研究提出的两种基于仿射变换和遗传算法的黑盒对抗性攻击算法（ATA和AGA）在图像分类任务中表现优异，超越了现有方法，并为理解和提升深度神经网络的对抗性鲁棒性提供了新的视角和见解。

Abstract: Deep neural networks currently dominate many fields of the artificial
intelligence landscape, achieving state-of-the-art results on numerous tasks
while remaining hard to understand and exhibiting surprising weaknesses. An
active area of research focuses on adversarial attacks, which aim to generate
inputs that uncover these weaknesses. However, this proves challenging,
especially in the black-box scenario where model details are inaccessible. This
paper explores in detail the impact of such adversarial algorithms on
ResNet-18, DenseNet-121, Swin Transformer V2, and Vision Transformer network
architectures. Leveraging the Tiny ImageNet, Caltech-256, and Food-101
datasets, we benchmark two novel black-box iterative adversarial algorithms
based on affine transformations and genetic algorithms: 1) Affine
Transformation Attack (ATA), an iterative algorithm maximizing our attack score
function using random affine transformations, and 2) Affine Genetic Attack
(AGA), a genetic algorithm that involves random noise and affine
transformations. We evaluate the performance of the models in the algorithm
parameter variation, data augmentation, and global and targeted attack
configurations. We also compare our algorithms with two black-box adversarial
algorithms, Pixle and Square Attack. Our experiments yield better results on
the image classification task than similar methods in the literature, achieving
an accuracy improvement of up to 8.82%. We provide noteworthy insights into
successful adversarial defenses and attacks at both global and targeted levels,
and demonstrate adversarial robustness through algorithm parameter variation.

</details>


### [176] [A Statistical 3D Stomach Shape Model for Anatomical Analysis](https://arxiv.org/abs/2509.06464)
*Erez Posner,Ore Shtalrid,Oded Erell,Daniel Noy,Moshe Bouhnik*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的胃部合成3D模型生成流程，并基于此构建了首个胃部3D统计形状模型。该模型通过结合合成数据和真实CT扫描数据进行半监督对齐训练，展现出强大的泛化能力和拟合精度，并已公开供研究使用。


<details>
  <summary>Details</summary>
Motivation: 尽管3D人体解剖模型在研究、诊断和手术规划中价值巨大，但由于数据可得性和方法学挑战，内部器官（如胃）的详细模型开发受到限制。

Method: 本文提出了一种生成合成3D胃部模型的新颖流程，该流程基于已有的胃部形状变异性研究。利用此流程构建了合成胃部数据集，并在此基础上开发了一个3D统计形状模型，以在低维形状空间中捕获自然的解剖变异性。模型通过半监督对齐过程，使用来自公开数据集的CT网格进行了进一步完善。

Result: 本文成功构建了首个胃部3D统计形状模型，并生成了相应的合成胃部数据集。该模型在真实胃部CT扫描的保留测试集上进行了评估，结果显示出强大的泛化能力和拟合精度。该统计形状模型和合成数据集已公开可用。

Conclusion: 这项工作首次引入了胃部的统计3D形状模型，代表了器官建模领域的重大进步。它结合了合成数据生成、参数化建模和真实世界验证，为个性化医疗解决方案开辟了新的可能性，并可应用于手术模拟、术前规划、医学教育和计算建模等领域。

Abstract: Realistic and parameterized 3D models of human anatomy have become invaluable
in research, diagnostics, and surgical planning. However, the development of
detailed models for internal organs, such as the stomach, has been limited by
data availability and methodological challenges. In this paper, we propose a
novel pipeline for the generation of synthetic 3D stomach models, enabling the
creation of anatomically diverse morphologies informed by established studies
on stomach shape variability. Using this pipeline, we construct a dataset of
synthetic stomachs. Building on this dataset, we develop a 3D statistical shape
model of the stomach, trained to capture natural anatomical variability in a
low-dimensional shape space. The model is further refined using CT meshes
derived from publicly available datasets through a semi-supervised alignment
process, enhancing its ability to generalize to unseen anatomical variations.
We evaluated the model on a held-out test set of real stomach CT scans,
demonstrating robust generalization and fit accuracy. We make the statistical
shape model along with the synthetic dataset publicly available on GitLab:
https://gitlab.com/Erez.Posner/stomach_pytorch to facilitate further research.
This work introduces the first statistical 3D shape model of the stomach, with
applications ranging from surgical simulation and pre-operative planning to
medical education and computational modeling. By combining synthetic data
generation, parametric modeling, and real-world validation, our approach
represents a significant advancement in organ modeling and opens new
possibilities for personalized healthcare solutions.

</details>


### [177] [Does DINOv3 Set a New Medical Vision Standard?](https://arxiv.org/abs/2509.06467)
*Che Liu,Yinda Chen,Haoyuan Shi,Jinpeng Lu,Bailiang Jian,Jiazhen Pan,Linghan Cai,Jiayi Wang,Yundi Zhang,Jun Li,Cosmin I. Bercea,Cheng Ouyang,Chen Chen,Zhiwei Xiong,Benedikt Wiestler,Christian Wachinger,Daniel Rueckert,Wenjia Bai,Rossella Arcucci*

Main category: cs.CV

TL;DR: 本研究评估了DINOv3（一种基于自然图像训练的自监督视觉Transformer）在多种医学影像任务中的直接应用效果。结果显示其表现出色，甚至在某些任务上优于医学专用模型，但在深度专业化领域和缩放规律方面存在局限性，但仍可作为强大的医学视觉任务基线。


<details>
  <summary>Details</summary>
Motivation: 大规模视觉基础模型在计算机视觉领域取得了显著进展，但其在医学影像等专业领域的有效性仍是未解之谜。本研究旨在探讨前沿视觉基础模型（如DINOv3）能否在不进行领域特定预训练的情况下，直接作为医学视觉任务的强大统一编码器。

Method: 研究人员将DINOv3在各种医学影像模态（包括2D/3D分类和分割）的常见医学视觉任务上进行了基准测试。他们还通过改变模型大小和输入图像分辨率来系统分析其可扩展性。

Result: DINOv3展现出令人印象深刻的性能，并在某些任务上超越了BioMedCLIP和CT-Net等医学专用基础模型。然而，研究也发现其在需要深度领域专业化的场景（如全玻片病理图像、电子显微镜和正电子发射断层扫描）中特征性能会下降。此外，DINOv3在医学领域并不总是遵循缩放定律，性能不会随着模型增大或分辨率提高而可靠提升，而是表现出多样化的缩放行为。

Conclusion: 本研究确立了DINOv3作为医学视觉任务的强大基线，其强大的视觉特征可作为多种复杂医学任务的稳健先验。这为未来的研究方向（如利用其特征增强3D重建中的多视角一致性）提供了有益的启示。

Abstract: The advent of large-scale vision foundation models, pre-trained on diverse
natural images, has marked a paradigm shift in computer vision. However, how
the frontier vision foundation models' efficacies transfer to specialized
domains remains such as medical imaging remains an open question. This report
investigates whether DINOv3, a state-of-the-art self-supervised vision
transformer (ViT) that features strong capability in dense prediction tasks,
can directly serve as a powerful, unified encoder for medical vision tasks
without domain-specific pre-training. To answer this, we benchmark DINOv3
across common medical vision tasks, including 2D/3D classification and
segmentation on a wide range of medical imaging modalities. We systematically
analyze its scalability by varying model sizes and input image resolutions. Our
findings reveal that DINOv3 shows impressive performance and establishes a
formidable new baseline. Remarkably, it can even outperform medical-specific
foundation models like BiomedCLIP and CT-Net on several tasks, despite being
trained solely on natural images. However, we identify clear limitations: The
model's features degrade in scenarios requiring deep domain specialization,
such as in Whole-Slide Pathological Images (WSIs), Electron Microscopy (EM),
and Positron Emission Tomography (PET). Furthermore, we observe that DINOv3
does not consistently obey scaling law in the medical domain; performance does
not reliably increase with larger models or finer feature resolutions, showing
diverse scaling behaviors across tasks. Ultimately, our work establishes DINOv3
as a strong baseline, whose powerful visual features can serve as a robust
prior for multiple complex medical tasks. This opens promising future
directions, such as leveraging its features to enforce multiview consistency in
3D reconstruction.

</details>


### [178] [FSG-Net: Frequency-Spatial Synergistic Gated Network for High-Resolution Remote Sensing Change Detection](https://arxiv.org/abs/2509.06482)
*Zhongxiang Xie,Shuangxi Miao,Yuhan Jiang,Zhewei Zhang,Jing Yao,Xuecao Li,Jianxi Huang,Pedram Ghamisi*

Main category: cs.CV

TL;DR: 本文提出FSG-Net，一个新颖的频率-空间协同门控网络，用于高分辨率遥感图像变化检测，旨在系统地分离语义变化和干扰变化，解决了伪变化和语义鸿沟问题，并取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 高分辨率遥感图像变化检测面临两大挑战：一是模型将辐射变化（如光照、季节）误解为真实变化，导致伪警报普遍存在；二是深度抽象特征和浅层细节丰富特征之间存在显著的语义鸿沟，阻碍了有效融合，导致边界描绘不佳。

Method: FSG-Net首先在频率域运行，通过差异感知小波交互模块（DAWIM）自适应地处理不同频率分量，以减轻伪变化。随后，在空间域通过协同时空注意力模块（STSAM）增强精炼特征，放大真实变化区域的显著性。最后，通过轻量级门控融合单元（LGFU）利用高级语义选择性地门控和整合来自浅层的重要细节，以弥合语义鸿沟。

Result: 在CDD、GZ-CD和LEVIR-CD基准测试上进行的综合实验验证了FSG-Net的优越性，F1分数分别达到94.16%、89.51%和91.27%，建立了新的最先进水平（SOTA）。

Conclusion: FSG-Net通过在频率和空间域协同处理，有效解决了高分辨率遥感图像变化检测中的伪变化和语义鸿沟问题，并在多个基准测试中取得了显著优于现有方法的性能，达到了最先进水平。

Abstract: Change detection from high-resolution remote sensing images lies as a
cornerstone of Earth observation applications, yet its efficacy is often
compromised by two critical challenges. First, false alarms are prevalent as
models misinterpret radiometric variations from temporal shifts (e.g.,
illumination, season) as genuine changes. Second, a non-negligible semantic gap
between deep abstract features and shallow detail-rich features tends to
obstruct their effective fusion, culminating in poorly delineated boundaries.
To step further in addressing these issues, we propose the Frequency-Spatial
Synergistic Gated Network (FSG-Net), a novel paradigm that aims to
systematically disentangle semantic changes from nuisance variations.
Specifically, FSG-Net first operates in the frequency domain, where a
Discrepancy-Aware Wavelet Interaction Module (DAWIM) adaptively mitigates
pseudo-changes by discerningly processing different frequency components.
Subsequently, the refined features are enhanced in the spatial domain by a
Synergistic Temporal-Spatial Attention Module (STSAM), which amplifies the
saliency of genuine change regions. To finally bridge the semantic gap, a
Lightweight Gated Fusion Unit (LGFU) leverages high-level semantics to
selectively gate and integrate crucial details from shallow layers.
Comprehensive experiments on the CDD, GZ-CD, and LEVIR-CD benchmarks validate
the superiority of FSG-Net, establishing a new state-of-the-art with F1-scores
of 94.16%, 89.51%, and 91.27%, respectively. The code will be made available at
https://github.com/zxXie-Air/FSG-Net after a possible publication.

</details>


### [179] [WS$^2$: Weakly Supervised Segmentation using Before-After Supervision in Waste Sorting](https://arxiv.org/abs/2509.06485)
*Andrea Marelli,Alberto Foresti,Leonardo Pesce,Giacomo Boracchi,Mario Grosso*

Main category: cs.CV

TL;DR: 本文提出了一种名为“前后监督”的弱监督方法，通过利用操作员移除物体前后图像的视觉差异来训练分割网络，以解决工业质量控制（如垃圾分类）中的自动化识别问题，并为此引入了首个多视角数据集WS$^2$及基准测试流程。


<details>
  <summary>Details</summary>
Motivation: 在工业质量控制中，人工操作员在识别和移除异物方面（例如垃圾分类）仍然不可或缺。为了实现自动化，计算机视觉系统具有巨大潜力，但由于任务的多样性和复杂性，全监督方法需要大量的标注工作，因此不可行。现有的弱监督方法，特别是利用操作员移除动作所提供的隐式监督，尚未得到充分探索。

Method: 本文定义了“前后监督”的概念，利用操作员移除物体前后图像之间的视觉差异来训练分割网络。为促进该方向研究，作者引入了WS$^2$数据集，这是首个包含11,000多帧高分辨率视频帧的多视角数据集，其中包括“前”和“后”图像。此外，还提出了一个鲁棒的端到端管道，用于在WS$^2$数据集上对几种最先进的弱监督分割方法进行基准测试。

Result: 本文定义了“前后监督”的概念，展示了如何仅利用操作员移除前后图像的视觉差异来训练分割网络。同时，成功构建了WS$^2$数据集，这是首个用于垃圾分类弱监督分割的多视角数据集。此外，还提供了一个端到端管道，用于评估和基准测试多种弱监督分割方法。

Conclusion: 本文提出了一种新颖的弱监督分割方法——“前后监督”，有效利用了操作员行为提供的隐式监督。通过引入WS$^2$数据集和基准测试管道，为工业质量控制（尤其是垃圾分类）领域的自动化识别和分割研究提供了重要的资源和工具，有望推动该领域弱监督学习的发展。

Abstract: In industrial quality control, to visually recognize unwanted items within a
moving heterogeneous stream, human operators are often still indispensable.
Waste-sorting stands as a significant example, where operators on multiple
conveyor belts manually remove unwanted objects to select specific materials.
To automate this recognition problem, computer vision systems offer great
potential in accurately identifying and segmenting unwanted items in such
settings. Unfortunately, considering the multitude and the variety of sorting
tasks, fully supervised approaches are not a viable option to address this
challange, as they require extensive labeling efforts. Surprisingly, weakly
supervised alternatives that leverage the implicit supervision naturally
provided by the operator in his removal action are relatively unexplored. In
this paper, we define the concept of Before-After Supervision, illustrating how
to train a segmentation network by leveraging only the visual differences
between images acquired \textit{before} and \textit{after} the operator. To
promote research in this direction, we introduce WS$^2$ (Weakly Supervised
segmentation for Waste-Sorting), the first multiview dataset consisting of more
than 11 000 high-resolution video frames captured on top of a conveyor belt,
including "before" and "after" images. We also present a robust end-to-end
pipeline, used to benchmark several state-of-the-art weakly supervised
segmentation methods on WS$^2$.

</details>


### [180] [TIDE: Achieving Balanced Subject-Driven Image Generation via Target-Instructed Diffusion Enhancement](https://arxiv.org/abs/2509.06499)
*Jibai Lin,Bo Ma,Yating Yang,Rong Ma,Turghun Osman,Ahtamjan Ahmat,Rui Dong,Lei Wang,Xi Zhou*

Main category: cs.CV

TL;DR: 本文提出TIDE框架，用于解决主体驱动图像生成（SDIG）中主体身份保持与文本指令遵循之间的矛盾。TIDE通过目标监督和偏好学习，在无需测试时微调的情况下，实现了卓越的生成效果和广泛的应用性。


<details>
  <summary>Details</summary>
Motivation: 主体驱动图像生成（SDIG）需要精确操作图像中的特定主体并遵循文本指令，但现有方法在保持主体身份和遵守动态编辑指令之间存在难以调和的矛盾，未能有效解决这一挑战。

Method: TIDE框架通过目标监督和偏好学习来解决矛盾，无需测试时微调。它首创目标监督三元组对齐，使用（参考图像、指令、目标图像）三元组建模主体适应动态。通过Direct Subject Diffusion (DSD) 目标，模型使用成对的“成功”（平衡了保持与遵循）和“失败”（扭曲）目标进行训练，这些目标通过量化指标系统生成和评估，从而实现隐式奖励建模以优化平衡。

Result: 实验结果表明，TIDE在标准基准测试中表现优越，能生成忠实于主体的输出，同时保持指令依从性，在多项量化指标上优于基线方法。TIDE还成功应用于结构条件生成、图像到图像生成和文本-图像插值等多样化任务，展现了其多功能性。

Conclusion: TIDE框架有效解决了主体驱动图像生成中主体身份保持和指令遵循之间的核心矛盾，实现了卓越的性能和广泛的任务适用性，为文本到图像扩散模型的发展提供了重要进展。

Abstract: Subject-driven image generation (SDIG) aims to manipulate specific subjects
within images while adhering to textual instructions, a task crucial for
advancing text-to-image diffusion models. SDIG requires reconciling the tension
between maintaining subject identity and complying with dynamic edit
instructions, a challenge inadequately addressed by existing methods. In this
paper, we introduce the Target-Instructed Diffusion Enhancing (TIDE) framework,
which resolves this tension through target supervision and preference learning
without test-time fine-tuning. TIDE pioneers target-supervised triplet
alignment, modelling subject adaptation dynamics using a (reference image,
instruction, target images) triplet. This approach leverages the Direct Subject
Diffusion (DSD) objective, training the model with paired "winning" (balanced
preservation-compliance) and "losing" (distorted) targets, systematically
generated and evaluated via quantitative metrics. This enables implicit reward
modelling for optimal preservation-compliance balance. Experimental results on
standard benchmarks demonstrate TIDE's superior performance in generating
subject-faithful outputs while maintaining instruction compliance,
outperforming baseline methods across multiple quantitative metrics. TIDE's
versatility is further evidenced by its successful application to diverse
tasks, including structural-conditioned generation, image-to-image generation,
and text-image interpolation. Our code is available at
https://github.com/KomJay520/TIDE.

</details>


### [181] [Predicting Brain Tumor Response to Therapy using a Hybrid Deep Learning and Radiomics Approach](https://arxiv.org/abs/2509.06511)
*Daniil Tikhonov,Matheus Scatolin,Mohor Banerjee,Qiankun Ji,Ahmed Jaheen,Mostafa Salem,Abdelrahman Elsayed,Hu Wang,Sarim Hashmi,Mohammad Yaqub*

Main category: cs.CV

TL;DR: 本文提出了一种结合深度学习和放射组学特征的自动化方法，用于从纵向MRI扫描中分类胶质母细胞瘤的治疗反应，旨在解决RANO标准应用复杂且存在观察者变异性的问题。


<details>
  <summary>Details</summary>
Motivation: 胶质母细胞瘤治疗反应的准确评估对于临床决策和患者管理至关重要。现有的神经肿瘤学反应评估（RANO）标准虽然提供了标准化框架，但其应用复杂且容易受到观察者变异性的影响。

Method: 研究提出了一种新颖的混合框架：首先，利用经过微调的ResNet-18模型从四种MRI模态的2D感兴趣区域中提取深度学习特征；然后，将这些深度特征与超过4800个丰富的放射组学和临床驱动特征（包括肿瘤生长和缩小掩模的3D放射组学、相对于最低点的体积变化以及肿瘤质心位移）进行融合；最后，使用CatBoost分类器对融合后的特征集进行4类（完全缓解、部分缓解、疾病稳定、疾病进展）反应预测。

Result: 在4类反应预测任务中，该方法实现了0.81的平均ROC AUC和0.50的Macro F1分数。

Conclusion: 研究结果强调，将学习到的图像表示与领域特定的放射组学特征相结合，为神经肿瘤学中自动化治疗反应评估提供了一个稳健且有效的解决方案。

Abstract: Accurate evaluation of the response of glioblastoma to therapy is crucial for
clinical decision-making and patient management. The Response Assessment in
Neuro-Oncology (RANO) criteria provide a standardized framework to assess
patients' clinical response, but their application can be complex and subject
to observer variability. This paper presents an automated method for
classifying the intervention response from longitudinal MRI scans, developed to
predict tumor response during therapy as part of the BraTS 2025 challenge. We
propose a novel hybrid framework that combines deep learning derived feature
extraction and an extensive set of radiomics and clinically chosen features.
Our approach utilizes a fine-tuned ResNet-18 model to extract features from 2D
regions of interest across four MRI modalities. These deep features are then
fused with a rich set of more than 4800 radiomic and clinically driven
features, including 3D radiomics of tumor growth and shrinkage masks,
volumetric changes relative to the nadir, and tumor centroid shift. Using the
fused feature set, a CatBoost classifier achieves a mean ROC AUC of 0.81 and a
Macro F1 score of 0.50 in the 4-class response prediction task (Complete
Response, Partial Response, Stable Disease, Progressive Disease). Our results
highlight that synergizing learned image representations with domain-targeted
radiomic features provides a robust and effective solution for automated
treatment response assessment in neuro-oncology.

</details>


### [182] [Benchmarking EfficientTAM on FMO datasets](https://arxiv.org/abs/2509.06536)
*Senem Aktas,Charles Markham,John McDonald,Rozenn Dahyot*

Main category: cs.CV

TL;DR: 该论文引入了FMO数据集的JSON元数据文件和扩展的FMOX地面真值信息，并使用FMOX测试了EfficientTAM跟踪模型，结果显示其性能与专门为FMO定制的管道相当。


<details>
  <summary>Details</summary>
Motivation: 快速微小物体跟踪在计算机视觉领域仍然是一个挑战。

Method: 1. 引入了与四个快速移动物体(FMOs)图像序列开源数据集相关的JSON元数据文件。2. 使用JSON格式（称为FMOX）的额外地面真值信息（包含物体尺寸）扩展了FMOs数据集的描述。3. 使用FMOX文件测试了一个最近提出的基础跟踪模型（EfficientTAM）。4. 使用轨迹交并比（TIoU）分数对这些最先进的技术在FMOX上进行了比较。5. 开源了代码和JSON文件。

Result: EfficientTAM模型在FMOX数据集上的性能与最初为这些FMO数据集量身定制的管道表现相当。

Conclusion: FMOX提供了一个可访问和可用的资源，用于处理FMO数据集的机器学习管道，并且EfficientTAM模型在快速移动物体跟踪方面表现出色。

Abstract: Fast and tiny object tracking remains a challenge in computer vision and in
this paper we first introduce a JSON metadata file associated with four open
source datasets of Fast Moving Objects (FMOs) image sequences. In addition, we
extend the description of the FMOs datasets with additional ground truth
information in JSON format (called FMOX) with object size information. Finally
we use our FMOX file to test a recently proposed foundational model for
tracking (called EfficientTAM) showing that its performance compares well with
the pipelines originally taylored for these FMO datasets. Our comparison of
these state-of-the-art techniques on FMOX is provided with Trajectory
Intersection of Union (TIoU) scores. The code and JSON is shared open source
allowing FMOX to be accessible and usable for other machine learning pipelines
aiming to process FMO datasets.

</details>


### [183] [Back To The Drawing Board: Rethinking Scene-Level Sketch-Based Image Retrieval](https://arxiv.org/abs/2509.06566)
*Emil Demić,Luka Čehovin Zajc*

Main category: cs.CV

TL;DR: 该研究通过强调草图的内在模糊性和噪声，提出了一种鲁棒的训练目标、预训练、编码器架构和损失函数组合，在不增加模型复杂性的情况下，实现了场景级草图图像检索的最新性能。


<details>
  <summary>Details</summary>
Motivation: 以往研究侧重于检索模型的架构增强，而本研究则强调真实世界草图中固有的模糊性和噪声，这促使研究人员设计一个能有效应对草图变异性的训练目标。

Method: 通过适当结合预训练、编码器架构和损失函数，明确设计了一个对草图变异性具有鲁棒性的训练目标，以实现跨模态检索。

Result: 在具有挑战性的FS-COCO和广泛使用的SketchyCOCO数据集上，该方法在不引入额外复杂性的情况下，达到了最先进的性能，并证实了其有效性。

Conclusion: 训练设计在跨模态检索任务中扮演着关键角色，同时，场景级草图图像检索的评估场景也需要改进。

Abstract: The goal of Scene-level Sketch-Based Image Retrieval is to retrieve natural
images matching the overall semantics and spatial layout of a free-hand sketch.
Unlike prior work focused on architectural augmentations of retrieval models,
we emphasize the inherent ambiguity and noise present in real-world sketches.
This insight motivates a training objective that is explicitly designed to be
robust to sketch variability. We show that with an appropriate combination of
pre-training, encoder architecture, and loss formulation, it is possible to
achieve state-of-the-art performance without the introduction of additional
complexity. Extensive experiments on a challenging FS-COCO and widely-used
SketchyCOCO datasets confirm the effectiveness of our approach and underline
the critical role of training design in cross-modal retrieval tasks, as well as
the need to improve the evaluation scenarios of scene-level SBIR.

</details>


### [184] [Evolving from Unknown to Known: Retentive Angular Representation Learning for Incremental Open Set Recognition](https://arxiv.org/abs/2509.06570)
*Runqing Yang,Yimin Fu,Changyuan Wu,Zhunga Liu*

Main category: cs.CV

TL;DR: 针对增量开放集识别（IOSR）中决策边界难以维持和类间混淆问题，本文提出了一种保留性角度表示学习（RARL）方法，通过虚拟-内在交互训练和分层校正策略，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放集识别（OSR）方法主要为静态场景设计，无法有效应对模型需从连续数据流中增量识别新未知类并获取知识的动态演进场景。在此类场景中，由于难以访问旧训练数据，OSR决策边界的判别力难以维持，导致严重的类间混淆。

Method: 本文提出了用于增量开放集识别（IOSR）的保留性角度表示学习（RARL）。RARL在等角紧框架构建的角度空间中，鼓励未知表示围绕非活跃原型对齐，从而减轻知识更新时的过度表示漂移。具体包括：1) 虚拟-内在交互（VII）训练策略，通过边界邻近的虚拟类强制清晰的类间裕度，以压缩已知表示；2) 分层校正策略，用于精炼决策边界，缓解新旧类及正负样本不平衡导致的表示偏差和特征空间扭曲。

Result: 在CIFAR100和TinyImageNet数据集上进行了全面评估，为IOSR建立了新的基准。在各种任务设置下的实验结果表明，所提出的方法达到了最先进的性能。

Conclusion: 所提出的RARL方法有效解决了增量开放集识别中决策边界难以维持和类间混淆的问题。该方法在标准数据集上取得了最先进的性能，并为IOSR领域设定了新基准。

Abstract: Existing open set recognition (OSR) methods are typically designed for static
scenarios, where models aim to classify known classes and identify unknown ones
within fixed scopes. This deviates from the expectation that the model should
incrementally identify newly emerging unknown classes from continuous data
streams and acquire corresponding knowledge. In such evolving scenarios, the
discriminability of OSR decision boundaries is hard to maintain due to
restricted access to former training data, causing severe inter-class
confusion. To solve this problem, we propose retentive angular representation
learning (RARL) for incremental open set recognition (IOSR). In RARL, unknown
representations are encouraged to align around inactive prototypes within an
angular space constructed under the equiangular tight frame, thereby mitigating
excessive representation drift during knowledge updates. Specifically, we adopt
a virtual-intrinsic interactive (VII) training strategy, which compacts known
representations by enforcing clear inter-class margins through
boundary-proximal virtual classes. Furthermore, a stratified rectification
strategy is designed to refine decision boundaries, mitigating representation
bias and feature space distortion caused by imbalances between old/new and
positive/negative class samples. We conduct thorough evaluations on CIFAR100
and TinyImageNet datasets and establish a new benchmark for IOSR. Experimental
results across various task setups demonstrate that the proposed method
achieves state-of-the-art performance.

</details>


### [185] [Approximating Condorcet Ordering for Vector-valued Mathematical Morphology](https://arxiv.org/abs/2509.06577)
*Marcos Eduardo Valle,Santiago Velasco-Forero,Joao Batista Florindo,Gustavo Jesus Angulo*

Main category: cs.CV

TL;DR: 本文提出一种机器学习方法，通过学习近似孔多塞排序的简化排序，来解决向量值图像数学形态学操作中缺乏一致向量排序的问题，并在彩色图像上展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管数学形态学在向量值图像处理中有许多成功应用，但对于构建形态学算子最合适的向量排序方式仍没有达成共识。

Method: 受投票问题中孔多塞排序（Condorcet ranking）的启发，本文开发了一种机器学习方法。该方法学习一个简化排序，以近似由一组向量排序导出的孔多塞排序，其中不同的排序被视为“投票者”。

Result: 初步计算实验证实，学习这种简化映射对于定义彩色图像的向量值形态学算子是有效的。

Conclusion: 通过机器学习获得的近似孔多塞排序的简化排序，为定义向量值数学形态学算子提供了一种有效方法，解决了该领域缺乏标准向量排序的挑战。

Abstract: Mathematical morphology provides a nonlinear framework for image and spatial
data processing and analysis. Although there have been many successful
applications of mathematical morphology to vector-valued images, such as color
and hyperspectral images, there is still no consensus on the most suitable
vector ordering for constructing morphological operators. This paper addresses
this issue by examining a reduced ordering approximating the Condorcet ranking
derived from a set of vector orderings. Inspired by voting problems, the
Condorcet ordering ranks elements from most to least voted, with voters
representing different orderings. In this paper, we develop a machine learning
approach that learns a reduced ordering that approximates the Condorcet
ordering. Preliminary computational experiments confirm the effectiveness of
learning the reduced mapping to define vector-valued morphological operators
for color images.

</details>


### [186] [CausNVS: Autoregressive Multi-view Diffusion for Flexible 3D Novel View Synthesis](https://arxiv.org/abs/2509.06579)
*Xin Kong,Daniel Watson,Yannick Strümpler,Michael Niemeyer,Federico Tombari*

Main category: cs.CV

TL;DR: CausNVS是一个自回归多视角扩散模型，用于新颖视图合成。它支持任意视图配置和顺序生成，解决了现有非自回归模型的视图数量固定和推理速度慢的问题，并能生成高质量的图像。


<details>
  <summary>Details</summary>
Motivation: 大多数现有多视角扩散模型采用非自回归形式，这限制了它们在世界建模中的应用，因为它们只支持固定数量的视图，并且由于同时去噪所有帧而导致推理缓慢。

Method: 本文提出了CausNVS，一个在自回归设置下的多视角扩散模型。它通过因果掩码和逐帧噪声进行训练，并使用成对相对相机姿态编码（CaPE）进行精确相机控制。在推理时，结合空间感知滑动窗口、键值缓存和噪声条件增强来缓解漂移问题。

Result: CausNVS支持广泛的相机轨迹，实现了灵活的自回归新颖视图合成，并在各种设置下保持一致的强大视觉质量。

Conclusion: CausNVS成功克服了现有非自回归多视角扩散模型的局限性，提供了一种灵活且高质量的自回归新颖视图合成方法，对世界建模具有重要意义。

Abstract: Multi-view diffusion models have shown promise in 3D novel view synthesis,
but most existing methods adopt a non-autoregressive formulation. This limits
their applicability in world modeling, as they only support a fixed number of
views and suffer from slow inference due to denoising all frames
simultaneously. To address these limitations, we propose CausNVS, a multi-view
diffusion model in an autoregressive setting, which supports arbitrary
input-output view configurations and generates views sequentially. We train
CausNVS with causal masking and per-frame noise, using pairwise-relative camera
pose encodings (CaPE) for precise camera control. At inference time, we combine
a spatially-aware sliding-window with key-value caching and noise conditioning
augmentation to mitigate drift. Our experiments demonstrate that CausNVS
supports a broad range of camera trajectories, enables flexible autoregressive
novel view synthesis, and achieves consistently strong visual quality across
diverse settings. Project page: https://kxhit.github.io/CausNVS.html.

</details>


### [187] [Detection of trade in products derived from threatened species using machine learning and a smartphone](https://arxiv.org/abs/2509.06585)
*Ritwik Kulkarni,WU Hanqin,Enrico Di Minin*

Main category: cs.CV

TL;DR: 该研究开发了一种基于机器学习的图像识别模型和智能手机应用，用于自动检测数字平台和实体市场中的非法野生动物产品，实现了较高的准确性。


<details>
  <summary>Details</summary>
Motivation: 不可持续的野生动物贸易对生物多样性构成重大威胁，且在数字市场和社交媒体上日益猖獗。由于数字内容量巨大，急需自动化方法来检测野生动物贸易信息，特别是自动识别象牙等野生动物产品。

Method: 研究开发了基于机器学习的物体识别模型，用于识别图像中的野生动物产品。数据包括被认定非法销售或被当局没收的大象（象牙、皮）、穿山甲（鳞片、爪）和老虎（皮、骨）产品图像。研究探索了不同的训练策略和两种损失函数，以确定最佳模型。模型既为每个物种单独训练，也开发了一个能识别所有三种物种产品的单一模型。此外，还开发了一个智能手机应用程序，以便政府机构和执法部门等利益相关者使用。

Result: 最佳模型在检测野生动物产品方面整体准确率达到84.2%，其中大象产品检测准确率为71.1%，穿山甲为90.2%，老虎为93.5%。开发的智能手机应用程序整体准确率为91.3%，可用于实时图像拍摄并帮助识别潜在的违禁目标物种产品。

Conclusion: 所提出的方法不仅适用于监测网络上的贸易，还可以应用于实体市场（例如通过智能手机应用）进行野生动物贸易监测。该技术为政府部门和执法机构等利益相关者提供了有效的工具，以打击非法野生动物贸易。

Abstract: Unsustainable trade in wildlife is a major threat to biodiversity and is now
increasingly prevalent in digital marketplaces and social media. With the sheer
volume of digital content, the need for automated methods to detect wildlife
trade listings is growing. These methods are especially needed for the
automatic identification of wildlife products, such as ivory. We developed
machine learning-based object recognition models that can identify wildlife
products within images and highlight them. The data consists of images of
elephant, pangolin, and tiger products that were identified as being sold
illegally or that were confiscated by authorities. Specifically, the wildlife
products included elephant ivory and skins, pangolin scales, and claws (raw and
crafted), and tiger skins and bones. We investigated various combinations of
training strategies and two loss functions to identify the best model to use in
the automatic detection of these wildlife products. Models were trained for
each species while also developing a single model to identify products from all
three species. The best model showed an overall accuracy of 84.2% with
accuracies of 71.1%, 90.2% and 93.5% in detecting products derived from
elephants, pangolins, and tigers, respectively. We further demonstrate that the
machine learning model can be made easily available to stakeholders, such as
government authorities and law enforcement agencies, by developing a
smartphone-based application that had an overall accuracy of 91.3%. The
application can be used in real time to click images and help identify
potentially prohibited products of target species. Thus, the proposed method is
not only applicable for monitoring trade on the web but can also be used e.g.
in physical markets for monitoring wildlife trade.

</details>


### [188] [Hybrid Swin Attention Networks for Simultaneously Low-Dose PET and CT Denoising](https://arxiv.org/abs/2509.06591)
*Yichao Liu,YueYang Teng*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的混合Swin注意力网络（HSANet），用于低剂量CT/PET图像去噪，该网络在实现卓越去噪性能的同时保持了轻量级模型尺寸，适用于临床应用。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT/PET虽然能显著减少辐射暴露，但会增加图像噪声和伪影，从而影响诊断准确性。因此，开发有效的去噪方法以提升图像质量同时保持辐射安全成为一项重要的研究领域。

Method: 本研究引入了一种混合Swin注意力网络（HSANet），该网络整合了高效全局注意力（EGA）模块，以增强空间和通道间的交互，从而提升网络捕获相关特征的能力；同时，还结合了一个混合上采样模块，以减轻模型对噪声过拟合的风险。

Result: 实验结果表明，在公开的LDCT/PET数据集上，HSANet的去噪性能优于现有方法。此外，该模型保持了轻量级的尺寸，适用于标准内存配置的GPU部署。

Conclusion: HSANet在低剂量CT/PET图像去噪方面表现出卓越的性能和实用性，使其成为真实临床应用中极具前景的解决方案。

Abstract: Low-dose computed tomography (LDCT) and positron emission tomography (PET)
have emerged as safer alternatives to conventional imaging modalities by
significantly reducing radiation exposure. However, this reduction often
results in increased noise and artifacts, which can compromise diagnostic
accuracy. Consequently, denoising for LDCT/PET has become a vital area of
research aimed at enhancing image quality while maintaining radiation safety.
In this study, we introduce a novel Hybrid Swin Attention Network (HSANet),
which incorporates Efficient Global Attention (EGA) modules and a hybrid
upsampling module. The EGA modules enhance both spatial and channel-wise
interaction, improving the network's capacity to capture relevant features,
while the hybrid upsampling module mitigates the risk of overfitting to noise.
We validate the proposed approach using a publicly available LDCT/PET dataset.
Experimental results demonstrate that HSANet achieves superior denoising
performance compared to existing methods, while maintaining a lightweight model
size suitable for deployment on GPUs with standard memory configurations. This
makes our approach highly practical for real-world clinical applications.

</details>


### [189] [VIM-GS: Visual-Inertial Monocular Gaussian Splatting via Object-level Guidance in Large Scenes](https://arxiv.org/abs/2509.06685)
*Shengkai Zhang,Yuhe Liu,Guanjun Wu,Jianhua He,Xinggang Wang,Mozi Chen,Kezhong Liu*

Main category: cs.CV

TL;DR: VIM-GS是一个使用单目图像在大场景中进行新视角合成（NVS）的Gaussian Splatting（GS）框架。它通过结合视觉惯性SfM的稀疏但精确深度与大型基础模型（LFM）的密集但粗糙深度来解决单目GS的深度不足问题，并引入了物体分割深度传播和动态深度细化模块。


<details>
  <summary>Details</summary>
Motivation: GS通常需要精确深度，但RGB-D/立体相机深度范围有限，难以应用于大场景。单目图像缺乏深度指导，导致NVS结果不佳。虽然存在用于单目深度估计的LFM，但它们存在跨帧不一致、远距离场景不准确以及纹理模糊性等问题。

Method: 该方法旨在从单目RGB输入生成密集、精确的深度图像，以实现高清晰度的GS渲染。核心思想是利用视觉惯性SfM的精确但稀疏深度来细化LFM的密集但粗糙深度。为此，提出了一个物体分割深度传播算法来渲染结构化物体像素的深度，以及一个动态深度细化模块来处理动态物体的受损SfM深度并细化LFM深度。

Result: 在公共和定制数据集上的实验表明，VIM-GS在大场景中展现出卓越的渲染质量。

Conclusion: VIM-GS成功地通过结合SfM和LFM深度，克服了单目图像在大场景GS中的深度挑战，实现了高质量的新视角合成。

Abstract: VIM-GS is a Gaussian Splatting (GS) framework using monocular images for
novel-view synthesis (NVS) in large scenes. GS typically requires accurate
depth to initiate Gaussian ellipsoids using RGB-D/stereo cameras. Their limited
depth sensing range makes it difficult for GS to work in large scenes.
Monocular images, however, lack depth to guide the learning and lead to
inferior NVS results. Although large foundation models (LFMs) for monocular
depth estimation are available, they suffer from cross-frame inconsistency,
inaccuracy for distant scenes, and ambiguity in deceptive texture cues. This
paper aims to generate dense, accurate depth images from monocular RGB inputs
for high-definite GS rendering. The key idea is to leverage the accurate but
sparse depth from visual-inertial Structure-from-Motion (SfM) to refine the
dense but coarse depth from LFMs. To bridge the sparse input and dense output,
we propose an object-segmented depth propagation algorithm that renders the
depth of pixels of structured objects. Then we develop a dynamic depth
refinement module to handle the crippled SfM depth of dynamic objects and
refine the coarse LFM depth. Experiments using public and customized datasets
demonstrate the superior rendering quality of VIM-GS in large scenes.

</details>


### [190] [STAGE: Segmentation-oriented Industrial Anomaly Synthesis via Graded Diffusion with Explicit Mask Alignment](https://arxiv.org/abs/2509.06693)
*Xichen Xu,Yanshu Wang,Jinbao Wang,Qunyi Zhang,Xiaoning Lei,Guoyang Xie,Guannan Jiang,Zhichao Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为STAGE（Segmentation-oriented Anomaly synthesis via Graded diffusion with Explicit mask alignment）的新型工业异常合成方法，通过引入背景先验、分级扩散框架和显式掩码对齐策略，解决了现有方法在纹理细节、背景对齐和细粒度异常生成方面的不足，并在异常分割任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的分割导向工业异常合成（SIAS）方法存在局限性：(i) 合成异常缺乏精细纹理细节，且与背景对齐不精确；(ii) 难以生成细粒度、像素级的异常。这些问题限制了合成数据对下游异常分割性能的提升。

Method: 本文提出了STAGE方法，包括：1) 新颖的异常推理策略，利用干净背景信息作为先验来引导去噪分布，从而更有效地突出异常前景。2) 分级扩散框架，引入一个仅处理异常的分支，在正向和反向过程中显式记录局部异常，以确保不遗漏细微异常。3) 显式掩码对齐（EMA）策略，逐步将合成异常与背景对齐，以生成上下文一致且结构连贯的异常。

Result: 在MVTec和BTAD数据集上进行的广泛实验表明，STAGE在SIAS任务中达到了最先进的性能，并有效提升了下游异常分割的效果。

Conclusion: STAGE通过其创新的背景先验引导、分级扩散和显式掩码对齐策略，成功克服了现有工业异常合成方法的局限性，能够生成高质量、上下文一致且细粒度的异常，从而显著增强了下游异常分割的性能。

Abstract: Segmentation-oriented Industrial Anomaly Synthesis (SIAS) plays a pivotal
role in enhancing the performance of downstream anomaly segmentation, as it
provides an effective means of expanding abnormal data. However, existing SIAS
methods face several critical limitations: (i) the synthesized anomalies often
lack intricate texture details and fail to align precisely with the surrounding
background, and (ii) they struggle to generate fine-grained, pixel-level
anomalies. To address these challenges, we propose Segmentation-oriented
Anomaly synthesis via Graded diffusion with Explicit mask alignment, termed
STAGE. STAGE introduces a novel anomaly inference strategy that incorporates
clean background information as a prior to guide the denoising distribution,
enabling the model to more effectively distinguish and highlight abnormal
foregrounds. Furthermore, it employs a graded diffusion framework with an
anomaly-only branch to explicitly record local anomalies during both the
forward and reverse processes, ensuring that subtle anomalies are not
overlooked. Finally, STAGE incorporates the explicit mask alignment (EMA)
strategy to progressively align the synthesized anomalies with the background,
resulting in context-consistent and structurally coherent generations.
Extensive experiments on the MVTec and BTAD datasets demonstrate that STAGE
achieves state-of-the-art performance in SIAS, which in turn enhances
downstream anomaly segmentation.

</details>


### [191] [Cortex-Synth: Differentiable Topology-Aware 3D Skeleton Synthesis with Hierarchical Graph Attention](https://arxiv.org/abs/2509.06705)
*Mohamed Zayaan S*

Main category: cs.CV

TL;DR: Cortex Synth是一个端到端可微分框架，能够从单张2D图像联合合成3D骨架的几何形状和拓扑结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从单张2D图像合成3D骨架的几何形状和拓扑结构方面存在局限性，需要一个更有效、更精确的端到端解决方案。

Method: 该框架引入了三项关键创新：1) 带有多尺度骨架精修的分层图注意力机制；2) 通过拉普拉斯特征分解实现的可微分谱拓扑优化；3) 用于姿态结构对齐的对抗性几何一致性训练。它集成了四个协同模块：伪3D点云生成器、增强型PointNet编码器、骨架坐标解码器和新型可微分图构建网络（DGCN）。

Result: 在ShapeNet数据集上，该模型在MPJPE方面提高了18.7%，在图编辑距离方面提高了27.3%，并将拓扑错误比现有方法减少了42%，达到了最先进的性能。

Conclusion: 该模型的端到端可微分特性使其可应用于机器人操作、医学成像和自动化角色绑定等领域。

Abstract: We present Cortex Synth, a novel end-to-end differentiable framework for
joint 3D skeleton geometry and topology synthesis from single 2D images. Our
architecture introduces three key innovations: (1) A hierarchical graph
attention mechanism with multi-scale skeletal refinement, (2) Differentiable
spectral topology optimization via Laplacian eigen decomposition, and (3)
Adversarial geometric consistency training for pose structure alignment. The
framework integrates four synergistic modules: a pseudo 3D point cloud
generator, an enhanced PointNet encoder, a skeleton coordinate decoder, and a
novel Differentiable Graph Construction Network (DGCN). Our experiments
demonstrate state-of-the-art results with 18.7 percent improvement in MPJPE and
27.3 percent in Graph Edit Distance on ShapeNet, while reducing topological
errors by 42 percent compared to previous approaches. The model's end-to-end
differentiability enables applications in robotic manipulation, medical
imaging, and automated character rigging.

</details>


### [192] [Zero-shot 3D-Aware Trajectory-Guided image-to-video generation via Test-Time Training](https://arxiv.org/abs/2509.06723)
*Ruicheng Zhang,Jun Zhou,Zunnan Xu,Zihao Liu,Jiehui Huang,Mingyang Zhang,Yu Sun,Xiu Li*

Main category: cs.CV

TL;DR: Zo3T 是一种新颖的零样本测试时训练框架，用于轨迹引导的图像到视频（I2V）生成，通过结合 3D 感知运动投影、轨迹引导的测试时 LoRA 和引导场修正，显著提升了 3D 真实感和运动精度。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹引导的 I2V 生成方法通常依赖于计算昂贵的微调和稀缺的标注数据集。一些零样本方法在潜在空间中尝试轨迹控制，但由于忽略 3D 透视以及操纵的潜在变量与网络噪声预测之间的错位，可能导致不真实的运动。

Method: Zo3T 框架包含三个核心创新：1. **3D 感知运动投影**：利用推断的场景深度为目标区域推导透视校正的仿射变换。2. **轨迹引导的测试时 LoRA**：动态注入并优化临时的 LoRA 适配器到去噪网络和潜在状态中，并通过区域特征一致性损失驱动，以强制执行运动约束并确保生成保真度。3. **引导场修正**：通过一步前瞻策略优化条件引导场，从而修正去噪演化路径，确保高效的生成进展。

Result: Zo3T 显著增强了轨迹控制 I2V 生成中的 3D 真实感和运动精度，并展示出优于现有基于训练和零样本方法的性能。

Conclusion: Zo3T 提供了一种有效的零样本测试时训练方法，通过其独特的三大创新，成功解决了现有方法在 3D 真实感和运动准确性方面的挑战，实现了高质量的轨迹引导图像到视频生成。

Abstract: Trajectory-Guided image-to-video (I2V) generation aims to synthesize videos
that adhere to user-specified motion instructions. Existing methods typically
rely on computationally expensive fine-tuning on scarce annotated datasets.
Although some zero-shot methods attempt to trajectory control in the latent
space, they may yield unrealistic motion by neglecting 3D perspective and
creating a misalignment between the manipulated latents and the network's noise
predictions. To address these challenges, we introduce Zo3T, a novel zero-shot
test-time-training framework for trajectory-guided generation with three core
innovations: First, we incorporate a 3D-Aware Kinematic Projection, leveraging
inferring scene depth to derive perspective-correct affine transformations for
target regions. Second, we introduce Trajectory-Guided Test-Time LoRA, a
mechanism that dynamically injects and optimizes ephemeral LoRA adapters into
the denoising network alongside the latent state. Driven by a regional feature
consistency loss, this co-adaptation effectively enforces motion constraints
while allowing the pre-trained model to locally adapt its internal
representations to the manipulated latent, thereby ensuring generative fidelity
and on-manifold adherence. Finally, we develop Guidance Field Rectification,
which refines the denoising evolutionary path by optimizing the conditional
guidance field through a one-step lookahead strategy, ensuring efficient
generative progression towards the target trajectory. Zo3T significantly
enhances 3D realism and motion accuracy in trajectory-controlled I2V
generation, demonstrating superior performance over existing training-based and
zero-shot approaches.

</details>


### [193] [Co-Seg: Mutual Prompt-Guided Collaborative Learning for Tissue and Nuclei Segmentation](https://arxiv.org/abs/2509.06740)
*Qing Xu,Wenting Duan,Zhen Chen*

Main category: cs.CV

TL;DR: 提出Co-Seg框架，通过协同分割范式同时处理组织区域和细胞核实例分割，以利用两者之间的内在关系，提高病理图像分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有病理图像分析方法将组织语义分割和细胞核实例分割视为独立任务，忽略了它们之间的固有关系，导致对病理图像的理解不足。

Method: Co-Seg框架引入了一种新颖的协同分割范式，使组织和细胞核分割任务能够相互增强。具体包括：1) 设计区域感知提示编码器（RP-Encoder），提供高质量的语义和实例区域提示作为先验约束；2) 设计相互提示掩码解码器（MP-Decoder），利用交叉指导加强两个任务的上下文一致性，协同计算语义和实例分割掩码。

Result: 在PUMA数据集上的大量实验表明，所提出的Co-Seg框架在肿瘤组织和细胞核实例的语义、实例和全景分割方面均超越了现有最先进的方法。

Conclusion: Co-Seg框架通过协同分割策略，有效解决了组织和细胞核分割任务的挑战，显著提升了病理图像分析的性能，实现了对肿瘤组织和细胞核的更准确理解。

Abstract: Histopathology image analysis is critical yet challenged by the demand of
segmenting tissue regions and nuclei instances for tumor microenvironment and
cellular morphology analysis. Existing studies focused on tissue semantic
segmentation or nuclei instance segmentation separately, but ignored the
inherent relationship between these two tasks, resulting in insufficient
histopathology understanding. To address this issue, we propose a Co-Seg
framework for collaborative tissue and nuclei segmentation. Specifically, we
introduce a novel co-segmentation paradigm, allowing tissue and nuclei
segmentation tasks to mutually enhance each other. To this end, we first devise
a region-aware prompt encoder (RP-Encoder) to provide high-quality semantic and
instance region prompts as prior constraints. Moreover, we design a mutual
prompt mask decoder (MP-Decoder) that leverages cross-guidance to strengthen
the contextual consistency of both tasks, collaboratively computing semantic
and instance segmentation masks. Extensive experiments on the PUMA dataset
demonstrate that the proposed Co-Seg surpasses state-of-the-arts in the
semantic, instance and panoptic segmentation of tumor tissues and nuclei
instances. The source code is available at https://github.com/xq141839/Co-Seg.

</details>


### [194] [Pothole Detection and Recognition based on Transfer Learning](https://arxiv.org/abs/2509.06750)
*Mang Hu,Qianqian Xia*

Main category: cs.CV

TL;DR: 本研究提出了一种基于迁移学习的深度学习模型（ResNet50-EfficientNet-RegNet），用于自动检测路面坑洼，实现了高分类精度和计算效率，并优于传统机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 随着计算机视觉和机器学习的快速发展，自动化的路面坑洼检测和识别方法受到了广泛关注。通过对道路图像进行特征提取，实现新图像中坑洼状况的自动识别对社会发展具有重要意义。

Method: 对原始数据集进行标准化、归一化和数据增强等预处理。基于实验结果持续改进网络模型，最终构建了一个基于迁移学习的深度学习特征提取网络ResNet50-EfficientNet-RegNet。通过与随机森林、MLP、SVM和LightGBM等其他模型进行比较评估，使用准确率、召回率、精确率、F1分数和FPS等指标来评估模型性能。

Result: 所提出的迁移学习模型在识别速度和准确性方面表现出高水平性能，超越了其他比较模型。在90个初始测试样本上实现了97.78%的分类准确率，在扩大的900个测试集上达到了98.89%的准确率。

Conclusion: 本研究构建的基于迁移学习的深度学习模型（ResNet50-EfficientNet-RegNet）能够高效、准确地自动识别路面坑洼，在性能上优于其他传统机器学习模型。

Abstract: With the rapid development of computer vision and machine learning, automated
methods for pothole detection and recognition based on image and video data
have received significant attention. It is of great significance for social
development to conduct an in-depth analysis of road images through feature
extraction, thereby achieving automatic identification of the pothole condition
in new images. Consequently, this is the main issue addressed in this study.
Based on preprocessing techniques such as standardization, normalization, and
data augmentation applied to the collected raw dataset, we continuously
improved the network model based on experimental results. Ultimately, we
constructed a deep learning feature extraction network
ResNet50-EfficientNet-RegNet model based on transfer learning. This model
exhibits high classification accuracy and computational efficiency. In terms of
model evaluation, this study employed a comparative evaluation approach by
comparing the performance of the proposed transfer learning model with other
models, including Random Forest, MLP, SVM, and LightGBM. The comparison
analysis was conducted based on metrics such as Accuracy, Recall, Precision,
F1-score, and FPS, to assess the classification performance of the transfer
learning model proposed in this paper. The results demonstrate that our model
exhibits high performance in terms of recognition speed and accuracy,
surpassing the performance of other models. Through careful parameter selection
and model optimization, our transfer learning model achieved a classification
accuracy of 97.78% (88/90) on the initial set of 90 test samples and 98.89%
(890/900) on the expanded test set.

</details>


### [195] [Raw2Event: Converting Raw Frame Camera into Event Camera](https://arxiv.org/abs/2509.06767)
*Zijie Ning,Enmin Lin,Sudarshan R. Iyengar,Patrick Vandewalle*

Main category: cs.CV

TL;DR: Raw2Event是一个软硬件系统，能从低成本的原始帧相机实时生成事件流，利用Bayer数据绕过ISP，提供比基于RGB的转换器更高动态范围和分辨率的输出，且支持实时嵌入式部署。


<details>
  <summary>Details</summary>
Motivation: 事件相机虽具有高时间分辨率、低延迟和高动态范围等优势，但其高成本、有限的分辨率和缺乏自动对焦等功能阻碍了其广泛应用，尤其是在早期开发和原型设计阶段。

Method: 本文提出了Raw2Event系统，通过直接访问原始Bayer数据并绕过传统图像信号处理器（ISP），利用DVS-Voltmeter模型构建可配置的仿真框架，并优化用于嵌入式平台。此外，设计了支持原始、RGB和事件流同步记录的数据采集管道。

Result: Raw2Event能生成与真实事件相机高度相似的事件流，同时受益于更高的分辨率和自动对焦能力。系统支持用户友好的参数调整，并已在树莓派上实现实时部署，提供了一个可扩展且经济高效的解决方案。

Conclusion: Raw2Event为事件视觉研究和早期系统开发提供了一个可扩展且经济高效的解决方案，克服了真实事件相机的高成本和功能限制，同时实现了实时事件生成，并具有更高分辨率和自动对焦功能。

Abstract: Event cameras offer unique advantages such as high temporal resolution, low
latency, and high dynamic range, making them more and more popular for vision
tasks under challenging light conditions. However, their high cost, limited
resolution, and lack of features such as autofocus hinder their broad adoption,
particularly for early-stage development and prototyping. In this work, we
present Raw2Event, a complete hardware-software system that enables real-time
event generation from low-cost raw frame-based cameras. By leveraging direct
access to raw Bayer data and bypassing traditional image signal processors
(ISP), our system is able to utilize the full potential of camera hardware,
delivering higher dynamic range, higher resolution, and more faithful output
than RGB-based frame-to-event converters.
  Built upon the DVS-Voltmeter model, Raw2Event features a configurable
simulation framework optimized for deployment on embedded platforms. We further
design a data acquisition pipeline that supports synchronized recording of raw,
RGB, and event streams, facilitating downstream evaluation and dataset
creation. Experimental results show that Raw2Event can generate event streams
closely resembling those from real event cameras, while benefiting from higher
resolution and autofocus capabilities. The system also supports user-intuitive
parameter tuning, enabling flexible adaptation to various application
requirements. Finally, we deploy the system on a Raspberry Pi for real-time
operation, providing a scalable and cost-effective solution for event-based
vision research and early-stage system development.
  The codes are available online:
https://anonymous.4open.science/r/raw2event-BFF2/README.md.

</details>


### [196] [D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning](https://arxiv.org/abs/2509.06771)
*Sai Kartheek Reddy Kasu,Mohammad Zia Ur Rehman,Shahid Shafi Dar,Rishi Bharat Junghare,Dhanvin Sanjay Namboodiri,Nagendra Kumar*

Main category: cs.CV

TL;DR: 本研究引入了一个新的暗黑幽默模因数据集，并提出了一个基于推理增强的多模态框架，用于检测暗黑幽默、识别目标类别和预测强度，其性能优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 在线模因中的暗黑幽默因其隐晦、敏感和文化语境化的线索而带来独特的挑战。目前缺乏用于检测多模态内容中暗黑幽默的资源和方法。

Method: 1. 构建了一个包含4,379个Reddit模因的新数据集，标注了暗黑幽默、目标类别（性别、心理健康、暴力、种族、残疾等）和三级强度（轻度、中度、重度）。2. 提出了一个推理增强框架：首先使用大型视觉-语言模型（VLM）生成结构化解释；然后通过“角色反转自循环”机制迭代细化解释；接着从OCR文本和自精炼推理中提取文本特征，并从图像中提取视觉特征。3. 最后，使用一个三流交叉推理网络（TCRNet）通过成对注意力机制融合文本、图像和推理这三股信息流，生成统一表示进行分类。

Result: 实验结果表明，本方法在暗黑幽默检测、目标识别和强度预测这三项任务上均优于强大的基线模型。

Conclusion: 本研究提出的方法在理解和检测多模态暗黑幽默方面表现出色。数据集、标注和代码的发布将促进多模态幽默理解和内容审核领域的进一步研究。

Abstract: Dark humor in online memes poses unique challenges due to its reliance on
implicit, sensitive, and culturally contextual cues. To address the lack of
resources and methods for detecting dark humor in multimodal content, we
introduce a novel dataset of 4,379 Reddit memes annotated for dark humor,
target category (gender, mental health, violence, race, disability, and other),
and a three-level intensity rating (mild, moderate, severe). Building on this
resource, we propose a reasoning-augmented framework that first generates
structured explanations for each meme using a Large Vision-Language Model
(VLM). Through a Role-Reversal Self-Loop, VLM adopts the author's perspective
to iteratively refine its explanations, ensuring completeness and alignment. We
then extract textual features from both the OCR transcript and the self-refined
reasoning via a text encoder, while visual features are obtained using a vision
transformer. A Tri-stream Cross-Reasoning Network (TCRNet) fuses these three
streams, text, image, and reasoning, via pairwise attention mechanisms,
producing a unified representation for classification. Experimental results
demonstrate that our approach outperforms strong baselines across three tasks:
dark humor detection, target identification, and intensity prediction. The
dataset, annotations, and code are released to facilitate further research in
multimodal humor understanding and content moderation. Code and Dataset are
available at:
https://github.com/Sai-Kartheek-Reddy/D-Humor-Dark-Humor-Understanding-via-Multimodal-Open-ended-Reasoning

</details>


### [197] [UrbanTwin: High-Fidelity Synthetic Replicas of Roadside Lidar Datasets](https://arxiv.org/abs/2509.06781)
*Muhammad Shahbaz,Shaurya Agarwal*

Main category: cs.CV

TL;DR: UrbanTwin数据集是高保真、逼真的合成激光雷达数据集，旨在复制现有公共数据集，并为3D目标检测、跟踪和分割等感知任务提供强大的独立或增强训练价值。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型需要大量多样化的数据进行训练，而真实世界激光雷达数据的收集和标注成本高昂且耗时。该研究旨在创建能够替代或增强现有真实数据集的合成数据，以克服这些限制并提高模型性能。

Method: 通过在基于真实世界几何、车道对齐、车道拓扑和车辆运动模式建模的逼真数字孪生中模拟激光雷达传感器来合成数据集。每个数据集包含10K带注释的帧，包括六个对象类别的3D边界框、实例分割标签和跟踪ID，以及九个类别的语义分割标签。通过统计和结构相似性分析评估合成数据与真实数据的对齐程度，并通过仅使用合成数据训练3D目标检测模型并在未见过的真实数据上进行测试来验证其实用性。

Result: UrbanTwin数据集与真实数据表现出高度相似性，并且使用合成数据训练的模型相比于仅使用真实数据训练的模型，在检测性能上有所提高。这表明UrbanTwin数据集通过增加样本量和场景多样性，有效增强了现有基准数据集。此外，数字孪生可以修改以测试自定义场景。据作者所知，这是首批能够替代领域内真实世界激光雷达感知任务数据集的数字合成数据集。

Conclusion: UrbanTwin数据集是高质量的合成激光雷达数据，可以有效增强现有基准数据集，提高深度学习模型的训练效果，甚至可能在激光雷达感知任务中替代领域内的真实世界数据集，并支持自定义场景的测试。

Abstract: This article presents UrbanTwin datasets - high-fidelity, realistic replicas
of three public roadside lidar datasets: LUMPI, V2X-Real-IC, and TUMTraf-I.
Each UrbanTwin dataset contains 10K annotated frames corresponding to one of
the public datasets. Annotations include 3D bounding boxes, instance
segmentation labels, and tracking IDs for six object classes, along with
semantic segmentation labels for nine classes. These datasets are synthesized
using emulated lidar sensors within realistic digital twins, modeled based on
surrounding geometry, road alignment at lane level, and the lane topology and
vehicle movement patterns at intersections of the actual locations
corresponding to each real dataset. Due to the precise digital twin modeling,
the synthetic datasets are well aligned with their real counterparts, offering
strong standalone and augmentative value for training deep learning models on
tasks such as 3D object detection, tracking, and semantic and instance
segmentation. We evaluate the alignment of the synthetic replicas through
statistical and structural similarity analysis with real data, and further
demonstrate their utility by training 3D object detection models solely on
synthetic data and testing them on real, unseen data. The high similarity
scores and improved detection performance, compared to the models trained on
real data, indicate that the UrbanTwin datasets effectively enhance existing
benchmark datasets by increasing sample size and scene diversity. In addition,
the digital twins can be adapted to test custom scenarios by modifying the
design and dynamics of the simulations. To our knowledge, these are the first
digitally synthesized datasets that can replace in-domain real-world datasets
for lidar perception tasks. UrbanTwin datasets are publicly available at
https://dataverse.harvard.edu/dataverse/ucf-ut.

</details>


### [198] [P3-SAM: Native 3D Part Segmentation](https://arxiv.org/abs/2509.06784)
*Changfeng Ma,Yang Li,Xinhao Yan,Jiachen Xu,Yunhan Yang,Chunshi Wang,Zibo Zhao,Yanwen Guo,Zhuo Chen,Chunchao Guo*

Main category: cs.CV

TL;DR: 本文提出了P3-SAM，一个原生的3D点提示式部件分割模型，旨在全自动、鲁棒地分割任何复杂3D对象的组成部分，并实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 3D资产分割对于提升3D理解、促进模型复用和支持部件生成等应用至关重要。然而，现有方法在处理复杂对象时鲁棒性差，且无法实现全自动化。

Method: P3-SAM模型包含特征提取器、多个分割头和IoU预测器，支持交互式分割。同时，提出了一种算法来自动选择和合并模型预测的掩码，以实现部件实例分割。模型在一个包含近370万个带有合理分割标签的新构建数据集上进行训练。

Result: P3-SAM在任何复杂对象上都实现了精确的分割结果和强大的鲁棒性，达到了最先进的性能。

Conclusion: P3-SAM成功地解决了3D对象部件分割的自动化和鲁棒性问题，其性能优于现有方法，为3D理解和应用提供了有力支持。

Abstract: Segmenting 3D assets into their constituent parts is crucial for enhancing 3D
understanding, facilitating model reuse, and supporting various applications
such as part generation. However, current methods face limitations such as poor
robustness when dealing with complex objects and cannot fully automate the
process. In this paper, we propose a native 3D point-promptable part
segmentation model termed P3-SAM, designed to fully automate the segmentation
of any 3D objects into components. Inspired by SAM, P3-SAM consists of a
feature extractor, multiple segmentation heads, and an IoU predictor, enabling
interactive segmentation for users. We also propose an algorithm to
automatically select and merge masks predicted by our model for part instance
segmentation. Our model is trained on a newly built dataset containing nearly
3.7 million models with reasonable segmentation labels. Comparisons show that
our method achieves precise segmentation results and strong robustness on any
complex objects, attaining state-of-the-art performance. Our code will be
released soon.

</details>


### [199] [AIM 2025 Challenge on High FPS Motion Deblurring: Methods and Results](https://arxiv.org/abs/2509.06793)
*George Ciubotariu,Florin-Alexandru Vasluianu,Zhuyun Zhou,Nancy Mehta,Radu Timofte,Ke Wu,Long Sun,Lingshun Kong,Zhongbao Yang,Jinshan Pan,Jiangxin Dong,Jinhui Tang,Hao Chen,Yinghui Fang,Dafeng Zhang,Yongqi Song,Jiangbo Guo,Shuhua Jin,Zeyu Xiao,Rui Zhao,Zhuoyuan Li,Cong Zhang,Yufeng Peng,Xin Lu,Zhijing Sun,Chengjie Ge,Zihao Li,Zishun Liao,Ziang Zhou,Qiyu Kang,Xueyang Fu,Zheng-Jun Zha,Yuqian Zhang,Shuai Liu,Jie Liu,Zhuhao Zhang,Lishen Qu,Zhihao Liu,Shihao Zhou,Yaqi Luo,Juncheng Zhou,Jufeng Yang,Qianfeng Yang,Qiyuan Guan,Xiang Chen,Guiyue Jin,Jiyu Jin*

Main category: cs.CV

TL;DR: 本文回顾了AIM 2025高帧率非均匀运动去模糊挑战，总结了提出的解决方案、最终结果，并评估了该领域的最新进展。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过挑战赛识别出能够学习复杂运动类型并生成更清晰、视觉上更吸引人的图像的有效网络，以应对多样且具有挑战性的去模糊条件。

Method: 本文回顾并评估了挑战赛中参赛团队提出的解决方案和最终结果，分析了高帧率单图像运动去模糊领域的最新进展，并利用了引入挑战性运动模式的新数据集MIORe的样本。

Result: 共有68名参赛者注册，9支队伍提交了有效参赛作品。本文展示了高帧率单图像运动去模糊领域取得的显著进展。

Conclusion: 高帧率单图像运动去模糊领域取得了显著进展，挑战赛成功识别了在复杂运动去模糊方面有效的网络和解决方案。

Abstract: This paper presents a comprehensive review of the AIM 2025 High FPS
Non-Uniform Motion Deblurring Challenge, highlighting the proposed solutions
and final results. The objective of this challenge is to identify effective
networks capable of producing clearer and visually compelling images in diverse
and challenging conditions, by learning representative visual cues for complex
aggregations of motion types. A total of 68 participants registered for the
competition, and 9 teams ultimately submitted valid entries. This paper
thoroughly evaluates the state-of-the-art advances in high-FPS single image
motion deblurring, showcasing the significant progress in the field, while
leveraging samples of the novel dataset, MIORe, that introduces challenging
examples of movement patterns.

</details>


### [200] [SynthDrive: Scalable Real2Sim2Real Sensor Simulation Pipeline for High-Fidelity Asset Generation and Driving Data Synthesis](https://arxiv.org/abs/2509.06798)
*Zhengqing Chen,Ruohong Mei,Xiaoyang Guo,Qingjie Wang,Yubin Hu,Wei Yin,Weiqiang Ren,Qian Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种可扩展的real2sim2real系统，利用3D生成技术自动化资产挖掘、生成和稀有案例数据合成，以克服现有自动驾驶传感器模拟方法在生成多样化和稀有场景方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域中，传感器模拟对于生成难以在真实世界中捕获的稀有和多样化场景至关重要。然而，当前的解决方案（如基于CG的CARLA和基于学习的NeuSim）存在多样性不足、难以扩展到大量稀有案例、仅限于特定物体类别以及需要大量多传感器数据等问题，阻碍了其在通用物体上的应用。

Method: 本文提出了一种可扩展的real2sim2real系统。该系统利用3D生成技术，自动化资产挖掘、资产生成和稀有案例数据合成。

Result: 该系统旨在解决现有CG和基于学习的传感器模拟方法的局限性，实现稀有和多样化场景数据的自动化生成，从而支持鲁棒的感知训练。

Conclusion: 通过提出一个利用3D生成技术的real2sim2real系统，本文提供了一种可扩展的解决方案，以应对自动驾驶传感器模拟中生成稀有和多样化场景数据的挑战，从而提升感知系统的训练效果。

Abstract: In the field of autonomous driving, sensor simulation is essential for
generating rare and diverse scenarios that are difficult to capture in
real-world environments. Current solutions fall into two categories: 1)
CG-based methods, such as CARLA, which lack diversity and struggle to scale to
the vast array of rare cases required for robust perception training; and 2)
learning-based approaches, such as NeuSim, which are limited to specific object
categories (vehicles) and require extensive multi-sensor data, hindering their
applicability to generic objects. To address these limitations, we propose a
scalable real2sim2real system that leverages 3D generation to automate asset
mining, generation, and rare-case data synthesis.

</details>


### [201] [MIORe & VAR-MIORe: Benchmarks to Push the Boundaries of Restoration](https://arxiv.org/abs/2509.06803)
*George Ciubotariu,Zhuyun Zhou,Zongwei Wu,Radu Timofte*

Main category: cs.CV

TL;DR: 本文介绍了MIORe和VAR-MIORe两个新型多任务数据集，旨在解决当前运动恢复基准的局限性，提供高帧率、复杂运动场景、深度相关模糊和可控运动幅度的真实数据。


<details>
  <summary>Details</summary>
Motivation: 现有运动恢复基准存在严重局限性，缺乏高帧率、复杂场景（如自我视角运动、多主体交互、深度依赖模糊）以及对运动幅度进行显式控制的数据集。

Method: 通过1000 FPS高帧率采集和专业级光学设备，捕捉广泛的运动场景。MIORe通过基于光流度量的自适应帧平均生成一致的运动模糊，并保留清晰输入用于视频帧插值和光流估计。VAR-MIORe在此基础上进一步扩展，涵盖了从最小到极端的变量运动幅度范围，首次实现了对运动幅度的显式控制。

Result: 成功构建了MIORe和VAR-MIORe两个多任务数据集，它们捕捉了复杂的自我视角运动、动态多主体交互和深度依赖模糊效应。MIORe生成一致的运动模糊并保留清晰输入，VAR-MIORe提供了对运动幅度的显式控制。数据集提供了高分辨率、可扩展的真实数据。

Conclusion: 这些数据集在受控和不利条件下对现有算法构成挑战，为图像和视频恢复任务的下一代研究铺平了道路。

Abstract: We introduce MIORe and VAR-MIORe, two novel multi-task datasets that address
critical limitations in current motion restoration benchmarks. Designed with
high-frame-rate (1000 FPS) acquisition and professional-grade optics, our
datasets capture a broad spectrum of motion scenarios, which include complex
ego-camera movements, dynamic multi-subject interactions, and depth-dependent
blur effects. By adaptively averaging frames based on computed optical flow
metrics, MIORe generates consistent motion blur, and preserves sharp inputs for
video frame interpolation and optical flow estimation. VAR-MIORe further
extends by spanning a variable range of motion magnitudes, from minimal to
extreme, establishing the first benchmark to offer explicit control over motion
amplitude. We provide high-resolution, scalable ground truths that challenge
existing algorithms under both controlled and adverse conditions, paving the
way for next-generation research of various image and video restoration tasks.

</details>


### [202] [UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward](https://arxiv.org/abs/2509.06818)
*Yufeng Cheng,Wenxu Wu,Shaojin Wu,Mengqi Huang,Fei Ding,Qian He*

Main category: cs.CV

TL;DR: 本文提出了UMO框架，通过将多身份生成重构为全局分配优化问题，并结合强化学习，显著提高了图像定制中多身份的一致性，减少了身份混淆，实现了可扩展的身份保留。


<details>
  <summary>Details</summary>
Motivation: 现有图像定制方法在处理多参考图像时，难以保持身份一致性并避免身份混淆，尤其是在对人脸敏感的场景中，这限制了定制模型的身份可扩展性。

Method: UMO采用“多对多匹配”范式，将多身份生成重构为全局分配优化问题，并通过在扩散模型上应用强化学习来增强多身份一致性。此外，本文还开发了一个包含合成和真实数据的多参考图像可扩展定制数据集，并提出了一种新的身份混淆度量指标。

Result: 实验证明，UMO不仅显著提高了身份一致性，还减少了多种图像定制方法中的身份混淆，在身份保留方面超越了现有的开源方法，达到了新的技术水平。

Conclusion: UMO是一个统一的多身份优化框架，有效解决了图像定制中多身份保留和混淆问题，具有良好的可扩展性，并为未来研究提供了新的数据集和评估指标。

Abstract: Recent advancements in image customization exhibit a wide range of
application prospects due to stronger customization capabilities. However,
since we humans are more sensitive to faces, a significant challenge remains in
preserving consistent identity while avoiding identity confusion with
multi-reference images, limiting the identity scalability of customization
models. To address this, we present UMO, a Unified Multi-identity Optimization
framework, designed to maintain high-fidelity identity preservation and
alleviate identity confusion with scalability. With "multi-to-multi matching"
paradigm, UMO reformulates multi-identity generation as a global assignment
optimization problem and unleashes multi-identity consistency for existing
image customization methods generally through reinforcement learning on
diffusion models. To facilitate the training of UMO, we develop a scalable
customization dataset with multi-reference images, consisting of both
synthesised and real parts. Additionally, we propose a new metric to measure
identity confusion. Extensive experiments demonstrate that UMO not only
improves identity consistency significantly, but also reduces identity
confusion on several image customization methods, setting a new
state-of-the-art among open-source methods along the dimension of identity
preserving. Code and model: https://github.com/bytedance/UMO

</details>


### [203] [Video-Based MPAA Rating Prediction: An Attention-Driven Hybrid Architecture Using Contrastive Learning](https://arxiv.org/abs/2509.06826)
*Dipta Neogi,Nourash Azmine Chowdhury,Muhammad Rafsan Kabir,Mohammad Ashrafuzzaman Khan*

Main category: cs.CV

TL;DR: 该研究提出了一种结合对比学习、LRCN（CNN+LSTM）骨干网络和Bahdanau注意力机制的混合架构，用于MPAA年龄适宜性视频自动分类，在上下文对比学习框架下取得了最先进的性能，并已部署为实时Web应用。


<details>
  <summary>Details</summary>
Motivation: 随着视觉内容消费的快速增长，平台需要自动化的视频分类以符合MPAA等年龄适宜性标准。传统方法面临标记数据需求量大、泛化能力差和特征学习效率低等挑战。

Method: 该研究采用混合架构，结合了LRCN（CNN+LSTM）骨干网络和Bahdanau注意力机制。为提高判别力和适应性，探索了三种对比学习框架：实例判别、上下文对比学习和多视图对比学习。模型融合了CNN的空间特征提取、LSTM的时间建模和注意力机制的动态帧优先级，并评估了NT-Xent、NT-logistic和Margin Triplet等多种对比损失函数。最终，该模型被部署为一个Web应用程序用于实时分类。

Result: 在上下文对比学习框架下，该模型取得了最先进的性能，准确率达到88%，F1分数达到0.8815。该模型在精细的边界区分（如PG-13和R级内容）方面表现出色，并验证了其在不同对比损失函数下的鲁棒性。

Conclusion: 该研究提出的混合架构结合对比学习，为MPAA年龄适宜性视频的自动分类提供了一个高效、鲁棒且准确的解决方案，特别适用于流媒体平台上的内容合规性管理，并已成功部署为实时应用。

Abstract: The rapid growth of visual content consumption across platforms necessitates
automated video classification for age-suitability standards like the MPAA
rating system (G, PG, PG-13, R). Traditional methods struggle with large
labeled data requirements, poor generalization, and inefficient feature
learning. To address these challenges, we employ contrastive learning for
improved discrimination and adaptability, exploring three frameworks: Instance
Discrimination, Contextual Contrastive Learning, and Multi-View Contrastive
Learning. Our hybrid architecture integrates an LRCN (CNN+LSTM) backbone with a
Bahdanau attention mechanism, achieving state-of-the-art performance in the
Contextual Contrastive Learning framework, with 88% accuracy and an F1 score of
0.8815. By combining CNNs for spatial features, LSTMs for temporal modeling,
and attention mechanisms for dynamic frame prioritization, the model excels in
fine-grained borderline distinctions, such as differentiating PG-13 and R-rated
content. We evaluate the model's performance across various contrastive loss
functions, including NT-Xent, NT-logistic, and Margin Triplet, demonstrating
the robustness of our proposed architecture. To ensure practical application,
the model is deployed as a web application for real-time MPAA rating
classification, offering an efficient solution for automated content compliance
across streaming platforms.

</details>


### [204] [Curia: A Multi-Modal Foundation Model for Radiology](https://arxiv.org/abs/2509.06830)
*Corentin Dancette,Julien Khlaut,Antoine Saporta,Helene Philippe,Elodie Ferreres,Baptiste Callard,Théo Danielou,Léo Alberge,Léo Machado,Daniel Tordjman,Julie Dupuis,Korentin Le Floch,Jean Du Terrail,Mariam Moshiri,Laurent Dercle,Tom Boeken,Jules Gregory,Maxime Ronot,François Legou,Pascal Roux,Marc Sapoval,Pierre Manceron,Paul Hérent*

Main category: cs.CV

TL;DR: 当前放射学AI模型狭窄，本文提出Curia，一个基于医院多年影像数据训练的放射学基础模型，在19项任务上表现优于放射科医生及现有模型，并展现出跨模态和低数据量下的显著性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI辅助放射学解释主要基于狭窄的单任务模型，难以覆盖广泛的影像模态、疾病和发现。基础模型有望实现跨模态和低数据量下的广泛泛化，但在放射学领域尚未充分实现。

Method: 引入Curia，一个基础模型。该模型在一家大型医院数年来的全部横断面影像输出（15万次检查，130 TB）上进行训练，据称是最大的真实世界数据集。在一个新策划的19项任务外部验证基准上进行评估。

Result: Curia能准确识别器官，检测脑出血和心肌梗死等疾病，并预测肿瘤分期结果。其性能达到或超越放射科医生和近期其他基础模型，并在跨模态和低数据量情况下展现出临床上显著的涌现特性。基础模型权重已发布。

Conclusion: Curia证明了基础模型在放射学领域实现广泛泛化和高性能的潜力，通过在大量真实世界数据上训练，成功应对了多任务挑战，并超越了现有方法，有望加速放射学AI的发展。

Abstract: AI-assisted radiological interpretation is based on predominantly narrow,
single-task models. This approach is impractical for covering the vast spectrum
of imaging modalities, diseases, and radiological findings. Foundation models
(FMs) hold the promise of broad generalization across modalities and in
low-data settings. However, this potential has remained largely unrealized in
radiology. We introduce Curia, a foundation model trained on the entire
cross-sectional imaging output of a major hospital over several years, which to
our knowledge is the largest such corpus of real-world data-encompassing
150,000 exams (130 TB). On a newly curated 19-task external validation
benchmark, Curia accurately identifies organs, detects conditions like brain
hemorrhages and myocardial infarctions, and predicts outcomes in tumor staging.
Curia meets or surpasses the performance of radiologists and recent foundation
models, and exhibits clinically significant emergent properties in
cross-modality, and low-data regimes. To accelerate progress, we release our
base model's weights at https://huggingface.co/raidium/curia.

</details>


### [205] [Leveraging Generic Foundation Models for Multimodal Surgical Data Analysis](https://arxiv.org/abs/2509.06831)
*Simon Pezold,Jérôme A. Kurylec,Jan S. Liechti,Beat P. Müller,Joël L. Lavanchy*

Main category: cs.CV

TL;DR: 本研究探讨了如何通过迁移学习适应通用基础模型（V-JEPA）并整合手术室（OR）的互补模态数据来支持手术数据科学，结果表明领域适应和多模态数据集成可显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在调查通用基础模型（如V-JEPA）如何通过迁移学习进行适应，以及整合手术室（OR）的互补模态数据如何支持手术数据科学，以提升手术支持系统的性能。

Method: 本研究以V-JEPA作为单模态基础模型，构建多模态模型以支持微创手术。方法包括：(a) 在未标记的手术视频数据上进行微调，以评估领域适应对模型下游性能的益处；(b) 在多模态设置中，通过训练一个独立的编码器与V-JEPA嵌入形成共享表示空间，整合手术室中额外的时间分辨数据流。研究在内部肝脏手术视频数据集上分析住院时间预测和术后并发症预测任务，并在公共HeiCo数据集上分析手术阶段识别任务。

Result: 实验结果显示，在领域特定数据上进行微调能提高模型性能。在内部数据集上，整合额外的时间分辨数据同样有益于模型。在HeiCo数据集上，预训练的纯视频、单模态基线设置的准确性与EndoVis2017挑战赛的顶尖提交结果相当，而领域特定数据上的微调进一步提升了准确性。

Conclusion: 本研究结果表明，手术数据科学可以有效利用公共的通用基础模型。同时，领域适应和整合手术室中合适的互补数据流展现出巨大的潜力。为支持进一步研究，代码和模型权重已公开发布。

Abstract: We investigate how both the adaptation of a generic foundation model via
transfer learning and the integration of complementary modalities from the
operating room (OR) can support surgical data science. To this end, we use
V-JEPA as the single-modality foundation of a multimodal model for minimally
invasive surgery support. We analyze how the model's downstream performance can
benefit (a) from finetuning on unlabeled surgical video data and (b) from
providing additional time-resolved data streams from the OR in a multimodal
setup.
  In an in-house dataset of liver surgery videos, we analyze the tasks of
predicting hospital length of stay and postoperative complications. In videos
of the public HeiCo dataset, we analyze the task of surgical phase recognition.
As a baseline, we apply pretrained V-JEPA to all tasks. We then finetune it on
unlabeled, held-out videos to investigate its change in performance after
domain adaptation. Following the idea of modular decision support networks, we
integrate additional data streams from the OR by training a separate encoder to
form a shared representation space with V-JEPA's embeddings.
  Our experiments show that finetuning on domain-specific data increases model
performance. On the in-house data, integrating additional time-resolved data
likewise benefits the model. On the HeiCo data, accuracy of the pretrained
video-only, single-modality baseline setup is on par with the top-performing
submissions of the EndoVis2017 challenge, while finetuning on domain-specific
data increases accuracy further. Our results thus demonstrate how surgical data
science can leverage public, generic foundation models. Likewise, they indicate
the potential of domain adaptation and of integrating suitable complementary
data streams from the OR. To support further research, we release our code and
model weights at https://github.com/DigitalSurgeryLab-Basel/ML-CDS-2025.

</details>


### [206] [Evaluating the Impact of Adversarial Attacks on Traffic Sign Classification using the LISA Dataset](https://arxiv.org/abs/2509.06835)
*Nabeyou Tadessa,Balaji Iyangar,Mashrur Chowdhury*

Main category: cs.CV

TL;DR: 本研究使用LISA交通标志数据集，评估了卷积神经网络对47种交通标志的分类能力，并测试了其在FGSM和PGD对抗性攻击下的脆弱性，结果显示分类准确率随扰动幅度增加而急剧下降。


<details>
  <summary>Details</summary>
Motivation: 以往的对抗性攻击研究主要集中在MNIST等简单数据集上，但交通标志识别系统在现实世界中至关重要。本研究旨在探究交通标志分类器在对抗性攻击下的脆弱性，以填补这一空白。

Method: 研究训练了一个卷积神经网络（CNN）来分类LISA交通标志数据集中的47种不同交通标志。随后，使用快速梯度符号法（FGSM）和投影梯度下降（PGD）两种对抗性攻击方法，评估了模型在不同扰动幅度下的鲁棒性。

Result: 实验结果表明，随着对抗性扰动幅度的增加，交通标志分类器的分类准确率急剧下降，突显了模型对对抗性样本的敏感性。

Conclusion: 研究证实了交通标志分类器在对抗性攻击下的高度脆弱性。这项工作为未来探索针对真实世界交通标志识别系统的防御机制奠定了基础。

Abstract: Adversarial attacks pose significant threats to machine learning models by
introducing carefully crafted perturbations that cause misclassification. While
prior work has primarily focused on MNIST and similar datasets, this paper
investigates the vulnerability of traffic sign classifiers using the LISA
Traffic Sign dataset. We train a convolutional neural network to classify 47
different traffic signs and evaluate its robustness against Fast Gradient Sign
Method (FGSM) and Projected Gradient Descent (PGD) attacks. Our results show a
sharp decline in classification accuracy as the perturbation magnitude
increases, highlighting the models susceptibility to adversarial examples. This
study lays the groundwork for future exploration into defense mechanisms
tailored for real-world traffic sign recognition systems.

</details>


### [207] [ToonOut: Fine-tuned Background-Removal for Anime Characters](https://arxiv.org/abs/2509.06839)
*Matteo Muratori,Joël Seytre*

Main category: cs.CV

TL;DR: 针对动漫风格内容背景去除的挑战，本研究收集并标注了一个包含1,228张动漫图像的定制数据集，并在此数据集上对BiRefNet模型进行微调，显著提高了动漫图像背景去除的准确性，像素准确率从95.3%提升至99.5%。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的背景去除模型在动漫风格内容等特殊领域表现不佳，因为动漫图像中复杂的特征（如头发和透明度）带来了独特的挑战。

Method: 研究人员收集并标注了一个包含1,228张高质量动漫角色和物体图像的定制数据集，然后使用此数据集对开源的BiRefNet模型进行了微调。

Result: 在动漫风格图像的背景去除准确性方面取得了显著提升，新引入的像素准确率指标从95.3%增加到99.5%。研究还开源了代码、微调后的模型权重以及数据集。

Conclusion: 通过在专门收集和标注的动漫数据集上对现有模型进行微调，可以有效解决动漫风格内容背景去除的挑战，显著提高其准确性。

Abstract: While state-of-the-art background removal models excel at realistic imagery,
they frequently underperform in specialized domains such as anime-style
content, where complex features like hair and transparency present unique
challenges. To address this limitation, we collected and annotated a custom
dataset of 1,228 high-quality anime images of characters and objects, and
fine-tuned the open-sourced BiRefNet model on this dataset. This resulted in
marked improvements in background removal accuracy for anime-style images,
increasing from 95.3% to 99.5% for our newly introduced Pixel Accuracy metric.
We are open-sourcing the code, the fine-tuned model weights, as well as the
dataset at: https://github.com/MatteoKartoon/BiRefNet.

</details>


### [208] [Matching Shapes Under Different Topologies: A Topology-Adaptive Deformation Guided Approach](https://arxiv.org/abs/2509.06862)
*Aymen Merrouche,Stefanie Wuhrer,Edmond Boyer*

Main category: cs.CV

TL;DR: 该研究提出了一种拓扑自适应变形模型，用于解决非刚性三维网格匹配中因拓扑伪影导致现有方法失效的问题，通过联合优化模板网格及其与待匹配形状的对齐，实现在ARAP和双射关联约束下处理拓扑变化，并取得了优于数据驱动方法的对齐质量。


<details>
  <summary>Details</summary>
Motivation: 现有非刚性三维网格匹配方法（如功能映射和ARAP类方法）依赖于近等距或ARAP变形假设。然而，在真实世界的场景中（例如每帧多视角重建），输入形状常包含拓扑伪影，导致这些假设失效，从而限制了现有方法的应用。

Method: 本文提出了一种拓扑自适应变形模型，该模型允许形状拓扑发生变化，以在ARAP和双射关联约束下对齐形状对。通过使用此模型，研究人员联合优化了一个具有适当拓扑的模板网格，并将其与待匹配的形状进行对齐，从而提取对应关系。

Result: 该方法无需依赖任何数据驱动先验，即可应用于高度非等距形状和包含拓扑伪影的形状（包括嘈杂的每帧多视角重建）。在三维对齐质量方面，其表现甚至优于在大数据集上训练的方法。

Conclusion: 所提出的拓扑自适应变形模型能够有效处理具有拓扑伪影和高度非等距变形的非刚性三维网格匹配问题，提供鲁棒且高质量的对齐结果，且无需数据驱动先验。

Abstract: Non-rigid 3D mesh matching is a critical step in computer vision and computer
graphics pipelines. We tackle matching meshes that contain topological
artefacts which can break the assumption made by current approaches. While
Functional Maps assume the deformation induced by the ground truth
correspondences to be near-isometric, ARAP-like deformation-guided approaches
assume the latter to be ARAP. Neither assumption holds in certain topological
configurations of the input shapes. We are motivated by real-world scenarios
such as per-frame multi-view reconstructions, often suffering from topological
artefacts. To this end, we propose a topology-adaptive deformation model
allowing changes in shape topology to align shape pairs under ARAP and
bijective association constraints. Using this model, we jointly optimise for a
template mesh with adequate topology and for its alignment with the shapes to
be matched to extract correspondences. We show that, while not relying on any
data-driven prior, our approach applies to highly non-isometric shapes and
shapes with topological artefacts, including noisy per-frame multi-view
reconstructions, even outperforming methods trained on large datasets in 3D
alignment quality.

</details>


### [209] [A New Hybrid Model of Generative Adversarial Network and You Only Look Once Algorithm for Automatic License-Plate Recognition](https://arxiv.org/abs/2509.06868)
*Behnoud Shafiezadeh,Amir Mashmool,Farshad Eshghi,Manoochehr Kelarestaghi*

Main category: cs.CV

TL;DR: 本文提出了一种结合选择性Deblur-GAN预处理和YOLOv5模型的自动车牌识别（ALPR）系统，实现了高精度和低延迟，特别是在处理模糊车牌时性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 自动车牌识别（ALPR）在智能交通系统（ITS）和智慧城市中至关重要，但由于其高变异性，面临诸多挑战，尤其是车牌模糊问题，需要更有效的深度学习技术来解决。

Method: 该研究提出了一种选择性生成对抗网络（GAN）用于预处理步骤中的去模糊，并结合了最先进的YOLOv5目标检测架构进行车牌检测（LPD）、字符分割（CS）和字符识别（CR）。选择性预处理避免了不必要且可能适得其反的输入操作。此外，作者生成并公开了一个包含模糊和ALPR数据的伊朗车牌数据集进行训练和测试。

Result: YOLOv5模型在车牌和字符识别阶段的检测时间为0.026秒，实现了实时应用。在LPD和CR检测阶段分别达到了95%和97%的准确率。Deblur-GAN预处理器显著提高了检测精度近40%，特别是在遇到模糊车牌时。该模型在整体精度和检测时间上表现出色。

Conclusion: 采用最先进的YOLO模型实现了卓越的整体精度和检测时间，使其非常适合便携式应用。将Deblur-GAN模型作为预处理步骤集成，显著增强了综合模型的整体有效性，尤其是在处理相机捕获的模糊场景输入时。

Abstract: Automatic License-Plate Recognition (ALPR) plays a pivotal role in
Intelligent Transportation Systems (ITS) as a fundamental element of Smart
Cities. However, due to its high variability, ALPR faces challenging issues
more efficiently addressed by deep learning techniques. In this paper, a
selective Generative Adversarial Network (GAN) is proposed for deblurring in
the preprocessing step, coupled with the state-of-the-art You-Only-Look-Once
(YOLO)v5 object detection architectures for License-Plate Detection (LPD), and
the integrated Character Segmentation (CS) and Character Recognition (CR)
steps. The selective preprocessing bypasses unnecessary and sometimes
counter-productive input manipulations, while YOLOv5 LPD/CS+CR delivers high
accuracy and low computing cost. As a result, YOLOv5 achieves a detection time
of 0.026 seconds for both LP and CR detection stages, facilitating real-time
applications with exceptionally rapid responsiveness. Moreover, the proposed
model achieves accuracy rates of 95\% and 97\% in the LPD and CR detection
phases, respectively. Furthermore, the inclusion of the Deblur-GAN
pre-processor significantly improves detection accuracy by nearly 40\%,
especially when encountering blurred License Plates (LPs).To train and test the
learning components, we generated and publicly released our blur and ALPR
datasets (using Iranian license plates as a use-case), which are more
representative of close-to-real-life ad-hoc situations. The findings
demonstrate that employing the state-of-the-art YOLO model results in excellent
overall precision and detection time, making it well-suited for portable
applications. Additionally, integrating the Deblur-GAN model as a preliminary
processing step enhances the overall effectiveness of our comprehensive model,
particularly when confronted with blurred scenes captured by the camera as
input.

</details>


### [210] [BIR-Adapter: A Low-Complexity Diffusion Model Adapter for Blind Image Restoration](https://arxiv.org/abs/2509.06904)
*Cem Eteke,Alexander Griessel,Wolfgang Kellerer,Eckehard Steinbach*

Main category: cs.CV

TL;DR: 本文提出BIR-Adapter，一种低复杂度的盲图像修复适配器，利用预训练扩散模型的先验知识，无需训练辅助特征提取器，即可在盲图像修复任务上达到SOTA或更优性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于利用预训练大型扩散模型的强大先验知识进行盲图像修复，同时寻求一种低复杂度、无需额外训练辅助特征提取器的方法，并利用预训练模型的鲁棒性处理退化图像。

Method: BIR-Adapter通过模型自身从退化图像中提取特征，并用这些退化特征扩展自注意力机制。此外，引入了一种采样引导机制来减少幻觉。其设计为适配器形式，无需训练辅助特征提取器。

Result: BIR-Adapter在合成和真实世界的退化图像上取得了与现有最先进方法相当或更优的性能，同时具有显著降低的复杂度。其适配器设计使其能够集成到其他扩散模型中，扩展了图像修复任务的应用范围，例如将仅支持超分辨率的模型扩展到处理未知退化。

Conclusion: BIR-Adapter提供了一种高效、低复杂度的解决方案，成功地将预训练扩散模型的先验知识应用于盲图像修复。其适配器设计不仅实现了卓越性能，还增强了模型的可扩展性和通用性，使其能够应用于更广泛的图像修复场景。

Abstract: This paper introduces BIR-Adapter, a low-complexity blind image restoration
adapter for diffusion models. The BIR-Adapter enables the utilization of the
prior of pre-trained large-scale diffusion models on blind image restoration
without training any auxiliary feature extractor. We take advantage of the
robustness of pretrained models. We extract features from degraded images via
the model itself and extend the self-attention mechanism with these degraded
features. We introduce a sampling guidance mechanism to reduce hallucinations.
We perform experiments on synthetic and real-world degradations and demonstrate
that BIR-Adapter achieves competitive or better performance compared to
state-of-the-art methods while having significantly lower complexity.
Additionally, its adapter-based design enables integration into other diffusion
models, enabling broader applications in image restoration tasks. We showcase
this by extending a super-resolution-only model to perform better under
additional unknown degradations.

</details>


### [211] [FoMo4Wheat: Toward reliable crop vision foundation models with globally curated data](https://arxiv.org/abs/2509.06907)
*Bing Han,Chen Zhu,Dong Han,Rui Yu,Songliang Cao,Jianhui Wu,Scott Chapman,Zijian Wang,Bangyou Zheng,Wei Guo,Marie Weiss,Benoit de Solan,Andreas Hund,Lukas Roth,Kirchgessner Norbert,Andrea Visioni,Yufeng Ge,Wenjuan Li,Alexis Comar,Dong Jiang,Dejun Han,Fred Baret,Yanfeng Ding,Hao Lu,Shouyang Liu*

Main category: cs.CV

TL;DR: FoMo4Wheat是一个基于最大的小麦图像数据集ImAg4Wheat进行自监督预训练的作物领域视觉基础模型，它在多种田间视觉任务中显著优于通用领域模型，证明了作物特定基础模型在数字农业中的价值。


<details>
  <summary>Details</summary>
Motivation: 现有基于通用领域预训练骨干的模型在数字农业中难以泛化，原因在于精细多变的冠层结构与波动不定的田间条件相互作用，导致其在农业任务中表现不佳。

Method: 研究提出了FoMo4Wheat，一个作物领域视觉基础模型。该模型在ImAg4Wheat数据集上进行自监督预训练，该数据集是目前最大、最多样化的小麦图像数据集（包含250万张高分辨率图像，跨越十年、30个全球地点、2000多种基因型和500多种环境条件）。模型在冠层和器官级别的十项田间视觉任务上进行了性能评估。

Result: FoMo4Wheat模型持续优于在通用领域数据集上预训练的现有最先进模型。它产生了对小麦鲁棒且可迁移到其他作物和杂草的表示。这些结果证明了作物特定基础模型在可靠田间感知中的价值。

Conclusion: 作物特定基础模型对于可靠的田间感知具有重要价值，并为开发具有跨物种和跨任务能力的通用作物基础模型指明了方向。

Abstract: Vision-driven field monitoring is central to digital agriculture, yet models
built on general-domain pretrained backbones often fail to generalize across
tasks, owing to the interaction of fine, variable canopy structures with
fluctuating field conditions. We present FoMo4Wheat, one of the first
crop-domain vision foundation model pretrained with self-supervision on
ImAg4Wheat, the largest and most diverse wheat image dataset to date (2.5
million high-resolution images collected over a decade at 30 global sites,
spanning >2,000 genotypes and >500 environmental conditions). This
wheat-specific pretraining yields representations that are robust for wheat and
transferable to other crops and weeds. Across ten in-field vision tasks at
canopy and organ levels, FoMo4Wheat models consistently outperform
state-of-the-art models pretrained on general-domain dataset. These results
demonstrate the value of crop-specific foundation models for reliable in-field
perception and chart a path toward a universal crop foundation model with
cross-species and cross-task capabilities. FoMo4Wheat models and the ImAg4Wheat
dataset are publicly available online: https://github.com/PheniX-Lab/FoMo4Wheat
and https://huggingface.co/PheniX-Lab/FoMo4Wheat. The demonstration website is:
https://fomo4wheat.phenix-lab.com/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [212] [An Empirical Analysis of Discrete Unit Representations in Speech Language Modeling Pre-training](https://arxiv.org/abs/2509.05359)
*Yanis Labrak,Richard Dufour,Mickaël Rouvier*

Main category: cs.CL

TL;DR: 本文研究了语音语言模型（SLMs）中的离散单元表示，重点关注在持续预训练中优化语音建模，并探讨了模型架构、数据表示和训练鲁棒性对预训练阶段的影响。


<details>
  <summary>Details</summary>
Motivation: 研究旨在优化持续预训练中的语音建模，通过系统性地检查模型架构、数据表示和训练鲁棒性如何影响将现有预训练语言模型适应到语音模态的预训练阶段。

Method: 本文系统地检查了模型架构、数据表示和训练鲁棒性；实验了不同模型规模下的语音编码器和聚类粒度；分析了聚类分布和音素对齐；并探讨了聚类数据选择对模型鲁棒性的影响。

Result: 实验结果表明，最佳离散化策略随模型容量而变化；离散词汇的有效使用揭示了语言和副语言模式；聚类数据选择与目标应用之间的领域匹配对模型鲁棒性至关重要。

Conclusion: 持续预训练中优化SLMs的语音建模需要考虑模型架构、数据表示、训练鲁棒性、聚类粒度、离散词汇的使用以及聚类数据选择的领域匹配等因素。

Abstract: This paper investigates discrete unit representations in Speech Language
Models (SLMs), focusing on optimizing speech modeling during continual
pre-training. In this paper, we systematically examine how model architecture,
data representation, and training robustness influence the pre-training stage
in which we adapt existing pre-trained language models to the speech modality.
Our experiments highlight the role of speech encoders and clustering
granularity across different model scales, showing how optimal discretization
strategies vary with model capacity. By examining cluster distribution and
phonemic alignments, we investigate the effective use of discrete vocabulary,
uncovering both linguistic and paralinguistic patterns. Additionally, we
explore the impact of clustering data selection on model robustness,
highlighting the importance of domain matching between discretization training
and target applications.

</details>


### [213] [Beyond ROUGE: N-Gram Subspace Features for LLM Hallucination Detection](https://arxiv.org/abs/2509.05360)
*Jerry Li,Evangelos Papalexakis*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的基于N-Gram频率张量的方法来检测大型语言模型（LLM）的幻觉，该方法通过张量分解和MLP分类器，在HaluEval数据集上取得了显著优于传统基线的性能，并与SOTA LLM裁判器具有竞争力。


<details>
  <summary>Details</summary>
Motivation: LLM幻觉问题严重限制了其生成信息的可靠性。现有幻觉检测方法，如不确定性估计、LLM裁判器和RAG，虽有前景，但其基础指标（如ROUGE、BERTScore、Perplexity）往往缺乏检测幻觉所需的语义深度。

Method: 该研究提出了一种受ROUGE启发的N-Gram频率张量构建方法，从LLM生成的文本中捕获更丰富的语义结构和共现模式。然后，通过张量分解方法提取每个模式的奇异值，并将这些奇异值作为输入特征，训练一个多层感知器（MLP）二元分类器来检测幻觉。

Result: 该方法在HaluEval数据集上进行了评估，结果显示其比传统基线有显著改进，并且与最先进的LLM裁判器相比，也展现出具有竞争力的性能。

Conclusion: 通过构建N-Gram频率张量并结合张量分解和MLP分类，本文提出的方法能够有效捕获文本中更深层的语义结构，从而更准确地区分事实性内容和幻觉内容，显著提升了LLM幻觉检测的性能。

Abstract: Large Language Models (LLMs) have demonstrated effectiveness across a wide
variety of tasks involving natural language, however, a fundamental problem of
hallucinations still plagues these models, limiting their trustworthiness in
generating consistent, truthful information. Detecting hallucinations has
quickly become an important topic, with various methods such as uncertainty
estimation, LLM Judges, retrieval augmented generation (RAG), and consistency
checks showing promise. Many of these methods build upon foundational metrics,
such as ROUGE, BERTScore, or Perplexity, which often lack the semantic depth
necessary to detect hallucinations effectively. In this work, we propose a
novel approach inspired by ROUGE that constructs an N-Gram frequency tensor
from LLM-generated text. This tensor captures richer semantic structure by
encoding co-occurrence patterns, enabling better differentiation between
factual and hallucinated content. We demonstrate this by applying tensor
decomposition methods to extract singular values from each mode and use these
as input features to train a multi-layer perceptron (MLP) binary classifier for
hallucinations. Our method is evaluated on the HaluEval dataset and
demonstrates significant improvements over traditional baselines, as well as
competitive performance against state-of-the-art LLM judges.

</details>


### [214] [A Lightweight Framework for Trigger-Guided LoRA-Based Self-Adaptation in LLMs](https://arxiv.org/abs/2509.05385)
*Jiacheng Wei,Faguo Wu,Xiao Zhang*

Main category: cs.CL

TL;DR: SAGE是一个触发器引导的动态微调框架，使大型语言模型能够在推理时通过分解任务和动态知识更新来持续适应和学习新数据。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理时无法持续适应新数据并从中学习，这限制了它们在复杂推理任务中的表现。

Method: 将复杂推理任务分解为原子子任务。提出SAGE框架，包含三个核心组件：1) 触发器模块：通过多项评估指标实时检测推理失败；2) 触发器缓冲区模块：使用HDBSCAN流式聚类异常样本，并进行稳定性检查和基于相似度的合并；3) Lora存储模块：通过适配器池动态优化参数更新以保留知识。

Result: 评估结果表明，SAGE通过在测试时动态更新知识，在原子推理子任务上表现出卓越的准确性、鲁棒性和稳定性。

Conclusion: SAGE框架通过动态知识更新，成功地使大型语言模型能够在推理时进行自适应学习，解决了其无法持续适应新数据的限制。

Abstract: Large language models are unable to continuously adapt and learn from new
data during reasoning at inference time. To address this limitation, we propose
that complex reasoning tasks be decomposed into atomic subtasks and introduce
SAGE, a trigger-guided dynamic fine-tuning framework that enables adaptive
updates during reasoning at inference time. SAGE consists of three key
components: (1) a Trigger module that detects reasoning failures through
multiple evaluation metrics in real time; (2) a Trigger Buffer module that
clusters anomaly samples using a streaming clustering process with HDBSCAN,
followed by stability checks and similarity-based merging; and (3) a Lora Store
module that dynamically optimizes parameter updates with an adapter pool for
knowledge retention. Evaluation results show that SAGE demonstrates excellent
accuracy, robustness, and stability on the atomic reasoning subtask through
dynamic knowledge updating during test time.

</details>


### [215] [Talk Isn't Always Cheap: Understanding Failure Modes in Multi-Agent Debate](https://arxiv.org/abs/2509.05396)
*Andrea Wynn,Harsh Satija,Gillian Hadfield*

Main category: cs.CL

TL;DR: 多智能体辩论有时弊大于利，特别是在模型能力异构的环境中，可能导致准确性下降，因为智能体倾向于达成一致而非纠正错误推理。


<details>
  <summary>Details</summary>
Motivation: 以往研究主要关注同质智能体群体的辩论，但发现辩论可能有害。本研究旨在探索模型能力多样性如何影响多智能体交互的动态和结果。

Method: 通过一系列实验，研究了模型能力多样性（强弱模型）对多智能体辩论结果的影响，并观察了准确性随时间的变化。

Result: 辩论会导致准确性随时间下降，即使强模型数量多于弱模型。分析显示，模型经常从正确答案转向错误答案，以响应同伴推理，倾向于达成一致而非挑战有缺陷的推理。

Conclusion: 多智能体辩论的简单应用可能导致性能下降，当智能体既没有被激励也没有充分配备来抵抗有说服力但错误的推理时，尤其如此。

Abstract: While multi-agent debate has been proposed as a promising strategy for
improving AI reasoning ability, we find that debate can sometimes be harmful
rather than helpful. The prior work has exclusively focused on debates within
homogeneous groups of agents, whereas we explore how diversity in model
capabilities influences the dynamics and outcomes of multi-agent interactions.
Through a series of experiments, we demonstrate that debate can lead to a
decrease in accuracy over time -- even in settings where stronger (i.e., more
capable) models outnumber their weaker counterparts. Our analysis reveals that
models frequently shift from correct to incorrect answers in response to peer
reasoning, favoring agreement over challenging flawed reasoning. These results
highlight important failure modes in the exchange of reasons during multi-agent
debate, suggesting that naive applications of debate may cause performance
degradation when agents are neither incentivized nor adequately equipped to
resist persuasive but incorrect reasoning.

</details>


### [216] [No Translation Needed: Forecasting Quality from Fertility and Metadata](https://arxiv.org/abs/2509.05425)
*Jessica M. Lundin,Ada Zhang,David Adelani,Cody Carroll*

Main category: cs.CL

TL;DR: 研究表明，无需实际运行翻译系统，仅使用少量特征（如词元生育率、词元计数和基本语言元数据）即可高精度预测翻译质量，为多语言评估和质量估计提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 传统上，评估翻译质量需要运行翻译系统，这可能耗时且成本高昂。本研究旨在探索一种无需运行翻译系统即可预测翻译质量的方法，以提供多语言评估和质量估计的新视角。

Method: 研究使用了词元生育率、词元计数和基本语言元数据（语系、文字、区域）等少量特征。通过梯度提升模型（Gradient Boosting Models）对GPT-4o在FLORES-200基准上203种语言的翻译进行ChrF分数预测。

Result: 梯度提升模型表现出色，对于XX→英语的预测，R²达到0.66；对于英语→XX的预测，R²达到0.72。特征重要性分析显示，在翻译成英语时，类型学因素（typological factors）起主导作用；而在翻译成多种目标语言时，生育率（fertility）则扮演更重要的角色。

Conclusion: 研究得出结论，翻译质量受到词元级别的生育率和更广泛的语言类型学因素的共同影响。这些发现为多语言评估和质量估计提供了新的见解。

Abstract: We show that translation quality can be predicted with surprising accuracy
\textit{without ever running the translation system itself}. Using only a
handful of features, token fertility ratios, token counts, and basic linguistic
metadata (language family, script, and region), we can forecast ChrF scores for
GPT-4o translations across 203 languages in the FLORES-200 benchmark. Gradient
boosting models achieve favorable performance ($R^{2}=0.66$ for
XX$\rightarrow$English and $R^{2}=0.72$ for English$\rightarrow$XX). Feature
importance analyses reveal that typological factors dominate predictions into
English, while fertility plays a larger role for translations into diverse
target languages. These findings suggest that translation quality is shaped by
both token-level fertility and broader linguistic typology, offering new
insights for multilingual evaluation and quality estimation.

</details>


### [217] [Direct-Scoring NLG Evaluators Can Use Pairwise Comparisons Too](https://arxiv.org/abs/2509.05440)
*Logan Lawrence,Ashton Williamson,Alexander Shelton*

Main category: cs.CL

TL;DR: 本文提出了一种直接评分方法，通过使用合成摘要作为测试时的配对机器排名，以解决大型语言模型作为自动评估器在自由形式内容评估中缺乏绝对分数的问题，并实现了与现有最佳配对评估器相当的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地被用作自由形式内容（如文档摘要、对话和故事生成）的自动评估器。现有评估这些模型性能的方法（特别是样本级别的配对比较方法）虽然表现良好，但通常无法为单个摘要分配绝对分数，而这种能力对于需要设置阈值的应用场景至关重要。

Method: 研究者提出了一种直接评分方法。该方法在测试时利用合成摘要作为配对机器排名，从而实现对单个摘要的直接评分。

Result: 该方法在SummEval (+0.03)、TopicalChat (-0.03) 和 HANNA (+0.05) 等元评估基准上，在轴平均样本级相关性方面，表现与最先进的配对评估器相当。此外，研究者还发布了上下文合成摘要数据，以促进未来的研究。

Conclusion: 本文成功开发了一种直接评分方法，解决了现有配对评估方法无法提供绝对分数的问题，同时在评估性能上与现有技术相当。这使得大型语言模型作为自动评估器在需要阈值判断的应用中更具实用性。

Abstract: As large-language models have been increasingly used as automatic raters for
evaluating free-form content, including document summarization, dialog, and
story generation, work has been dedicated to evaluating such models by
measuring their correlations with human judgment. For \textit{sample-level}
performance, methods which operate by using pairwise comparisons between
machine-generated text perform well but often lack the ability to assign
absolute scores to individual summaries, an ability crucial for use cases that
require thresholding. In this work, we propose a direct-scoring method which
uses synthetic summaries to act as pairwise machine rankings at test time. We
show that our method performs comparably to state-of-the-art pairwise
evaluators in terms of axis-averaged sample-level correlations on the SummEval
(\textbf{+0.03}), TopicalChat (\textbf{-0.03}), and HANNA (\textbf{+0.05})
meta-evaluation benchmarks, and release the synthetic in-context summaries as
data to facilitate future work.

</details>


### [218] [From Staff Messages to Actionable Insights: A Multi-Stage LLM Classification Framework for Healthcare Analytics](https://arxiv.org/abs/2509.05484)
*Hajar Sakai,Yi-En Tseng,Mohammadsadegh Mikaeili,Joshua Bosire,Franziska Jovin*

Main category: cs.CL

TL;DR: 本文提出了一种多阶段、基于大型语言模型（LLM）的框架，用于分析医院呼叫中心的员工消息，识别主题并按原因进行分类，以提供可操作的见解。


<details>
  <summary>Details</summary>
Motivation: 医院呼叫中心产生大量员工消息文本数据，传统监督学习方法需要大量标注、训练和调优。LLM为医疗健康分析提供了更高效的方法，以从这些数据中提取洞察。

Method: 该研究开发了一个多阶段LLM框架，用于识别员工消息主题并进行多类别原因分类。过程中评估了多种LLM类型（推理型、通用型和轻量级模型）。处理后的LLM输出集成到可视化决策支持工具中，并确保数据安全和HIPAA合规性。

Result: 表现最佳的模型是o3，实现了78.4%的加权F1分数和79.2%的准确率，紧随其后的是gpt-5，获得了75.3%的加权F1分数和76.2%的准确率。

Conclusion: 所提出的方法能够更有效地利用收集到的员工消息数据，识别导航员培训机会，并支持改善患者体验和护理质量，同时确保医疗环境中的数据安全和合规性。

Abstract: Hospital call centers serve as the primary contact point for patients within
a hospital system. They also generate substantial volumes of staff messages as
navigators process patient requests and communicate with the hospital offices
following the established protocol restrictions and guidelines. This
continuously accumulated large amount of text data can be mined and processed
to retrieve insights; however, traditional supervised learning approaches
require annotated data, extensive training, and model tuning. Large Language
Models (LLMs) offer a paradigm shift toward more computationally efficient
methodologies for healthcare analytics. This paper presents a multi-stage
LLM-based framework that identifies staff message topics and classifies
messages by their reasons in a multi-class fashion. In the process, multiple
LLM types, including reasoning, general-purpose, and lightweight models, were
evaluated. The best-performing model was o3, achieving 78.4% weighted F1-score
and 79.2% accuracy, followed closely by gpt-5 (75.3% Weighted F1-score and
76.2% accuracy). The proposed methodology incorporates data security measures
and HIPAA compliance requirements essential for healthcare environments. The
processed LLM outputs are integrated into a visualization decision support tool
that transforms the staff messages into actionable insights accessible to
healthcare professionals. This approach enables more efficient utilization of
the collected staff messaging data, identifies navigator training
opportunities, and supports improved patient experience and care quality.

</details>


### [219] [The Token Tax: Systematic Bias in Multilingual Tokenization](https://arxiv.org/abs/2509.05486)
*Jessica M. Lundin,Ada Zhang,Nihal Karim,Hamza Louzan,Victor Wei,David Adelani,Cody Carroll*

Main category: cs.CL

TL;DR: 研究发现，分词效率低下对形态复杂、资源匮乏的语言造成结构性劣势，导致计算资源消耗增加和准确性下降。高“分词率”（tokens/word）与低准确性呈负相关，并显著增加训练成本。推理模型表现更优，研究呼吁采用形态感知分词、公平定价和多语言基准测试。


<details>
  <summary>Details</summary>
Motivation: 形态复杂、资源匮乏的语言在分词效率低下方面存在结构性劣势，导致计算资源消耗增加和准确性降低。这种“分词税”现象促使研究者探究其对大型语言模型性能及经济成本的影响。

Method: 研究评估了10个大型语言模型在AfriMMLU数据集（包含9,000个多项选择题，涵盖5个主题和16种非洲语言）上的表现。通过衡量“分词率”（tokens/word）来预测准确性。同时，比较了推理模型与非推理模型的性能差异，并分析了分词膨胀对训练成本和时间的影响。

Result: 结果显示，“分词率”越高，所有模型和主题的准确性越低。推理模型（DeepSeek, o1）在AfriMMLU数据集中持续优于非推理模型，缩小了先前观察到的准确性差距。此外，分词量翻倍会导致训练成本和时间增加四倍，突显了许多语言面临的“分词税”问题。

Conclusion: 研究结果强调了分词效率低下对某些语言造成的“分词税”和结构性劣势。为实现公平的自然语言处理（NLP），有必要开发形态感知的词法分析器、推行公平的定价策略，并建立更完善的多语言基准测试。

Abstract: Tokenization inefficiency imposes structural disadvantages on morphologically
complex, low-resource languages, inflating compute resources and depressing
accuracy. We evaluate 10 large language models (LLMs) on AfriMMLU (9,000 MCQA
items; 5 subjects; 16 African languages) and show that fertility (tokens/word)
reliably predicts accuracy. Higher fertility consistently predicts lower
accuracy across all models and subjects. We further find that reasoning models
(DeepSeek, o1) consistently outperform non-reasoning peers across high and low
resource languages in the AfriMMLU dataset, narrowing accuracy gaps observed in
prior generations. Finally, translating token inflation to economics, a
doubling in tokens results in quadrupled training cost and time, underscoring
the token tax faced by many languages. These results motivate morphologically
aware tokenization, fair pricing, and multilingual benchmarks for equitable
natural language processing (NLP).

</details>


### [220] [Biomedical Literature Q&A System Using Retrieval-Augmented Generation (RAG)](https://arxiv.org/abs/2509.05505)
*Mansi Garg,Lee-Chi Wang,Bhavesh Ghanchi,Sanjana Dumpala,Shreyash Kakde,Yen Chih Chen*

Main category: cs.CL

TL;DR: 该研究提出了一个基于RAG架构的生物医学文献问答系统，利用MiniLM进行语义检索，并使用QLoRA优化的Mistral-7B模型进行答案生成，旨在提供准确、基于证据的医疗信息，并在事实一致性和语义相关性方面取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决传统健康搜索引擎的不足以及公众获取生物医学研究信息滞后的问题，提升医疗信息的可及性和准确性。

Method: 该系统采用检索增强生成（RAG）架构。检索管道使用基于MiniLM的语义嵌入和FAISS向量搜索，整合PubMed文章、Q&A数据集和医学百科全书等多种来源。答案生成由经过QLoRA优化微调的Mistral-7B-v0.3语言模型完成。系统支持通用医疗查询和特定领域任务，并通过BERTScore (F1) 对乳腺癌文献进行了评估。

Result: 与基线模型相比，该系统在事实一致性和语义相关性方面取得了显著改进，尤其是在领域对齐检索方面表现出其价值。

Conclusion: RAG增强的语言模型有潜力弥合复杂生物医学文献与可访问的公共健康知识之间的鸿沟，为未来的多语言适应、隐私保护推理和个性化医疗AI系统奠定基础。

Abstract: This work presents a Biomedical Literature Question Answering (Q&A) system
based on a Retrieval-Augmented Generation (RAG) architecture, designed to
improve access to accurate, evidence-based medical information. Addressing the
shortcomings of conventional health search engines and the lag in public access
to biomedical research, the system integrates diverse sources, including PubMed
articles, curated Q&A datasets, and medical encyclopedias ,to retrieve relevant
information and generate concise, context-aware responses. The retrieval
pipeline uses MiniLM-based semantic embeddings and FAISS vector search, while
answer generation is performed by a fine-tuned Mistral-7B-v0.3 language model
optimized using QLoRA for efficient, low-resource training. The system supports
both general medical queries and domain-specific tasks, with a focused
evaluation on breast cancer literature demonstrating the value of
domain-aligned retrieval. Empirical results, measured using BERTScore (F1),
show substantial improvements in factual consistency and semantic relevance
compared to baseline models. The findings underscore the potential of
RAG-enhanced language models to bridge the gap between complex biomedical
literature and accessible public health knowledge, paving the way for future
work on multilingual adaptation, privacy-preserving inference, and personalized
medical AI systems.

</details>


### [221] [Using Contrastive Learning to Improve Two-Way Reasoning in Large Language Models: The Obfuscation Task as a Case Study](https://arxiv.org/abs/2509.05553)
*Serge Lionel Nikiema,Jordan Samhi,Micheline Bénédicte Moumoula,Albérick Euraste Djiré,Abdoul Kader Kaboré,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.CL

TL;DR: 本研究提出双向推理作为衡量大型语言模型（LLMs）真正理解而非模式识别的测试。他们发现现有模型存在“认知专业化”问题，并开发了对比微调（CFT）方法，成功使模型在不进行反向训练的情况下实现双向推理，同时保持正向任务能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决人工智能领域的一个核心问题：大型语言模型是真正理解概念，还是仅仅识别模式？作者提出双向推理作为衡量真正理解的标准，即模型应能在未明确训练反向任务的情况下，自然地进行双向转换。

Method: 作者提出双向推理（即在未明确训练反向方向的情况下，能双向应用转换）作为衡量真正理解的测试。他们测试了当前语言模型，发现了“认知专业化”现象。为解决此问题，他们开发了对比微调（CFT）方法，使用三种类型的例子进行训练：保持语义的正面例子、语义不同的负面例子以及正向混淆例子。

Result: 实验发现，当前语言模型在正向任务上进行微调后，其正向任务性能提高，但双向推理能力显著下降，作者称之为“认知专业化”。通过对比微调（CFT），模型成功实现了双向推理，在保持正向任务能力的同时，展现出强大的反向性能。

Conclusion: 双向推理既可以作为评估模型真正理解的理论框架，也可以作为开发更强大AI系统的实用训练方法。通过对比微调，可以培养模型更深层次的理解能力，而非仅仅停留在表面模式识别。

Abstract: This research addresses a fundamental question in AI: whether large language
models truly understand concepts or simply recognize patterns. The authors
propose bidirectional reasoning,the ability to apply transformations in both
directions without being explicitly trained on the reverse direction, as a test
for genuine understanding. They argue that true comprehension should naturally
allow reversibility. For example, a model that can change a variable name like
userIndex to i should also be able to infer that i represents a user index
without reverse training. The researchers tested current language models and
discovered what they term cognitive specialization: when models are fine-tuned
on forward tasks, their performance on those tasks improves, but their ability
to reason bidirectionally becomes significantly worse. To address this issue,
they developed Contrastive Fine-Tuning (CFT), which trains models using three
types of examples: positive examples that maintain semantic meaning, negative
examples with different semantics, and forward-direction obfuscation examples.
This approach aims to develop deeper understanding rather than surface-level
pattern recognition and allows reverse capabilities to develop naturally
without explicit reverse training. Their experiments demonstrated that CFT
successfully achieved bidirectional reasoning, enabling strong reverse
performance while maintaining forward task capabilities. The authors conclude
that bidirectional reasoning serves both as a theoretical framework for
assessing genuine understanding and as a practical training approach for
developing more capable AI systems.

</details>


### [222] [Ad hoc conventions generalize to new referents](https://arxiv.org/abs/2509.05566)
*Anya Ji,Claire Augusta Bergey,Ron Eliav,Yoav Artzi,Robert D. Hawkins*

Main category: cs.CL

TL;DR: 研究发现，人们在为新事物建立共享命名系统时，并非简单地创建任意标签，而是通过概念协调，这种协调能够泛化到未讨论的新参照物，表明临时性约定反映了真正的概念对齐。


<details>
  <summary>Details</summary>
Motivation: 研究旨在检验两种关于人们如何谈论从未谈论过的事物的竞争性观点：一是新命名系统是任意链接到特定目标的（如专有名词），二是共享描述涉及更广泛的概念对齐，能泛化到新的参照物。

Method: 通过一项双人交流研究（N=302），利用包含1000多张抽象七巧板图像的KiloGram数据集。参与者对一组图像的指称约定进行协调后，测量了他们对未讨论图像描述的对齐程度。

Result: 研究发现强烈的泛化证据：与预测试标签相比，合作者在未讨论图像上的对齐度显著增加。泛化能力随视觉相似度非线性衰减（符合谢泼德定律），并且在图像可命名性水平上保持稳健。

Conclusion: 这些发现表明，临时性约定并非任意标签，而是反映了真正的概念协调，对指称理论和自适应语言智能体的设计具有重要意义。

Abstract: How do people talk about things they've never talked about before? One view
suggests that a new shared naming system establishes an arbitrary link to a
specific target, like proper names that cannot extend beyond their bearers. An
alternative view proposes that forming a shared way of describing objects
involves broader conceptual alignment, reshaping each individual's semantic
space in ways that should generalize to new referents. We test these competing
accounts in a dyadic communication study (N=302) leveraging the
recently-released KiloGram dataset containing over 1,000 abstract tangram
images. After pairs of participants coordinated on referential conventions for
one set of images through repeated communication, we measured the extent to
which their descriptions aligned for undiscussed images. We found strong
evidence for generalization: partners showed increased alignment relative to
their pre-test labels. Generalization also decayed nonlinearly with visual
similarity (consistent with Shepard's law) and was robust across levels of the
images' nameability. These findings suggest that ad hoc conventions are not
arbitrary labels but reflect genuine conceptual coordination, with implications
for theories of reference and the design of more adaptive language agents.

</details>


### [223] [Mitigating Spurious Correlations Between Question and Answer via Chain-of-Thought Correctness Perception Distillation](https://arxiv.org/abs/2509.05602)
*Hongyan Xie,Yitong Yao,Yikun Ban,Zixuan Huang,Deqing Wang,Zhenhe Wu,Haoxiang Su,Chao Wang,Shuangyong Song,Xuelong Li*

Main category: cs.CL

TL;DR: 本文提出CoPeD方法，通过引入正确性感知任务设置和正确性感知加权损失，解决小型语言模型（SLMs）在链式思考（CoT）蒸馏中因噪声原理导致的推理质量下降问题，从而提高其在推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）推理能力强但部署成本高。小型语言模型（SLMs）通过蒸馏LLM生成的CoT数据来模仿其能力，但这些CoT数据可能包含噪声原理，导致SLMs学习到虚假关联，损害推理质量。

Method: 本文提出CoPeD（Chain-of-Thought Correctness Perception Distillation）方法，从任务设置和数据利用两方面改进SLM的推理质量：1. 引入正确性感知任务设置，鼓励学生模型基于正确原理预测答案，并在错误时进行修正，以提高推理的忠实性并从错误中学习。2. 提出正确性感知加权损失，根据原理和答案的组合损失动态调整每个训练实例的贡献，使模型更关注原理能强力支持正确答案的样本。

Result: 实验结果表明，CoPeD在分布内（IND）和分布外（OOD）基准推理数据集上均有效。

Conclusion: CoPeD通过正确性感知任务设置和加权损失，有效解决了SLMs在CoT蒸馏中噪声原理导致的问题，显著提升了学生模型在推理任务上的表现和推理质量。

Abstract: Large language models (LLMs) excel at reasoning tasks but are expensive to
deploy. Thus small language models (SLMs) are fine-tuned on CoT data generated
by LLMs to copy LLMs' abilities. However, these CoT data may include noisy
rationales that either fail to substantiate the answers or contribute no
additional information to support answer prediction, which leads SLMs to
capture spurious correlations between questions and answers and compromise the
quality of reasoning. In this work, we propose Chain-of-Thought Correctness
Perception Distillation (CoPeD), which aims to improve the reasoning quality of
the student model from the perspectives of task setting and data utilization.
Firstly, we introduce a correctness-aware task setting that encourages the
student model to predict answers based on correct rationales and revise them
when they are incorrect. This setting improves the faithfulness of reasoning
and allows the model to learn from its mistakes. Then, we propose a
Correctness-Aware Weighted loss, which dynamically adjusts the contribution of
each training instance based on the combined loss of the rationale and the
answer. This strategy encourages the model to focus more on samples where the
rationale offers stronger support for the correct answer. Experiments have
shown that CoPeD is effective on both in-distribution (IND) and
out-of-distribution (OOD) benchmark reasoning datasets.

</details>


### [224] [Icon$^{2}$: Aligning Large Language Models Using Self-Synthetic Preference Data via Inherent Regulation](https://arxiv.org/abs/2509.05605)
*Qiyuan Chen,Hongsen Huang,Qian Shao,Jiahe Chen,Jintai Chen,Hongxia Xu,Renjie Hua,Ren Chuan,Jian Wu*

Main category: cs.CL

TL;DR: Icon²提出了一种利用大型语言模型（LLM）内部表示空间进行高效、定制化偏好数据集构建的新范式，显著提升了对齐效果并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统的偏好数据集构建方法面临挑战：依赖预收集指令可能导致与目标模型的分发不匹配，以及采样多个随机响应引入的巨大计算开销。

Method: Icon²首先提取层级方向向量来编码复杂的人类偏好，然后利用这些向量基于内在一致性过滤自合成指令。在解码过程中，它应用双向内在控制来引导token表示，从而精确生成具有明显对齐区别的响应对。

Result: 实验结果显示，在对齐和效率方面均有显著提升。Llama3-8B和Qwen2-7B在AlpacaEval 2.0上平均胜率提高了13.89%，在Arena-Hard上提高了13.45%，同时计算成本降低了高达48.1%。

Conclusion: Icon²通过利用LLM表示空间的内在调控，为构建高质量、高效的偏好数据集提供了一种有效的范式，解决了现有方法的痛点，实现了更好的模型对齐和更低的计算成本。

Abstract: Large Language Models (LLMs) require high quality preference datasets to
align with human preferences. However, conventional methods for constructing
such datasets face significant challenges: reliance on pre-collected
instructions often leads to distribution mismatches with target models, while
the need for sampling multiple stochastic responses introduces substantial
computational overhead. In this work, we explore a paradigm shift by leveraging
inherent regulation of LLMs' representation space for efficient and tailored
preference dataset construction, named Icon$^{2}$. Specifically, it first
extracts layer-wise direction vectors to encode sophisticated human preferences
and then uses these vectors to filter self-synthesized instructions based on
their inherent consistency. During decoding, bidirectional inherent control is
applied to steer token representations, enabling the precise generation of
response pairs with clear alignment distinctions. Experimental results
demonstrate significant improvements in both alignment and efficiency.
Llama3-8B and Qwen2-7B achieve an average win rate improvement of 13.89% on
AlpacaEval 2.0 and 13.45% on Arena-Hard, while reducing computational costs by
up to 48.1%.

</details>


### [225] [Beyond Keywords: Driving Generative Search Engine Optimization with Content-Centric Agents](https://arxiv.org/abs/2509.05607)
*Qiyuan Chen,Jiahe Chen,Hongsen Huang,Qian Shao,Jintai Chen,Renjie Hua,Hongxia Xu,Ruijia Wu,Ren Chuan,Jian Wu*

Main category: cs.CL

TL;DR: 本文提出了一套针对生成式搜索引擎优化（GSEO）的端到端框架，包括一个大规模基准（CC-GSEO-Bench）和一个多智能体系统，旨在衡量和优化内容对生成答案的影响力。


<details>
  <summary>Details</summary>
Motivation: 传统基于排名的搜索引擎优化（SEO）指标在生成式搜索引擎（GSE）范式下已过时，迫切需要理解、衡量和优化内容对合成答案的影响。

Method: 1. 构建了CC-GSEO-Bench，一个大规模、以内容为中心的基准。2. 提出了一个多维度评估框架，系统地量化影响力，超越表面归因，评估实质性语义影响。3. 设计了一个新颖的多智能体系统，通过协作的“分析-修订-评估”工作流，自动化内容策略性优化。

Result: 通过该框架进行的实证分析揭示了内容影响力动态的新颖见解，为内容创作者提供了可操作的策略。

Conclusion: 该研究为未来的GSEO研究奠定了原则性基础，并为内容创作者提供了实用的优化策略。

Abstract: The paradigm shift from traditional ranked-based search to Generative Search
Engines has rendered conventional SEO metrics obsolete, creating an urgent need
to understand, measure, and optimize for content influence on synthesized
answers. This paper introduces a comprehensive, end-to-end framework for
Generative Search Engine Optimization (GSEO) to address this challenge. We make
two primary contributions. First, we construct CC-GSEO-Bench, a large-scale,
content-centric benchmark, and propose a multi-dimensional evaluation framework
that systematically quantifies influence, moving beyond surface-level
attribution to assess substantive semantic impact. Second, we design a novel
multi-agent system that operationalizes this framework, automating the
strategic refinement of content through a collaborative analyze-revise-evaluate
workflow. Our empirical analysis using this framework reveals novel insights
into the dynamics of content influence, offering actionable strategies for
creators and establishing a principled foundation for future GSEO research.

</details>


### [226] [New Insights into Optimal Alignment of Acoustic and Linguistic Representations for Knowledge Transfer in ASR](https://arxiv.org/abs/2509.05609)
*Xugang Lu,Peng Shen,Yu Tsao,Hisashi Kawai*

Main category: cs.CL

TL;DR: 本文提出了一种基于非平衡最优传输的对齐模型，将声学与语言表示的对齐视为检测问题，以解决自动语音识别（ASR）中知识迁移时声学和语言模态之间的结构不对称和分布不匹配问题，从而提高ASR性能。


<details>
  <summary>Details</summary>
Motivation: 在ASR中，将预训练模型中的知识迁移需要对齐声学和语言表示。这存在固有的结构不对称（多对一、一对多）和不平衡匹配条件（如背景噪声或静音帧无对应语言单元），这些挑战促使研究者寻求更有效的对齐方法。

Method: 研究将对齐和匹配问题视为一个检测问题，目标是高精度和高召回率地识别有意义的对应关系。提出了一种基于非平衡最优传输的对齐模型，该模型明确处理了分布不匹配和结构不对称问题，实现了声学和语言模态之间的软性与部分匹配。它确保每个语言标记都至少有一个声学观测基础，并允许从声学单元到语言单元的灵活概率映射。

Result: 通过在基于CTC的ASR系统上，利用预训练语言模型进行知识迁移的实验，结果表明所提出的方法能够有效地控制匹配程度，从而改善ASR性能。

Conclusion: 该研究提出的基于非平衡最优传输的对齐模型，通过将对齐视为检测问题，并灵活处理声学与语言模态间的结构不对称和分布不匹配，有效提升了ASR系统中的知识迁移效果和整体性能。

Abstract: Aligning acoustic and linguistic representations is a central challenge to
bridge the pre-trained models in knowledge transfer for automatic speech
recognition (ASR). This alignment is inherently structured and asymmetric:
while multiple consecutive acoustic frames typically correspond to a single
linguistic token (many-to-one), certain acoustic transition regions may relate
to multiple adjacent tokens (one-to-many). Moreover, acoustic sequences often
include frames with no linguistic counterpart, such as background noise or
silence may lead to imbalanced matching conditions. In this work, we take a new
insight to regard alignment and matching as a detection problem, where the goal
is to identify meaningful correspondences with high precision and recall
ensuring full coverage of linguistic tokens while flexibly handling redundant
or noisy acoustic frames in transferring linguistic knowledge for ASR. Based on
this new insight, we propose an unbalanced optimal transport-based alignment
model that explicitly handles distributional mismatch and structural
asymmetries with soft and partial matching between acoustic and linguistic
modalities. Our method ensures that every linguistic token is grounded in at
least one acoustic observation, while allowing for flexible, probabilistic
mappings from acoustic to linguistic units. We evaluate our proposed model with
experiments on an CTC-based ASR system with a pre-trained language model for
knowledge transfer. Experimental results demonstrate the effectiveness of our
approach in flexibly controlling degree of matching and hence to improve ASR
performance.

</details>


### [227] [From Joy to Fear: A Benchmark of Emotion Estimation in Pop Song Lyrics](https://arxiv.org/abs/2509.05617)
*Shay Dahary,Avi Edana,Alexander Apartsin,Yehudit Aperstein*

Main category: cs.CL

TL;DR: 本文研究歌词的多标签情感归因任务，通过构建基于MOS的人工标注数据集，评估零样本LLM和微调BERT模型在预测六种基本情感强度方面的表现，并揭示了它们的优缺点。


<details>
  <summary>Details</summary>
Motivation: 歌词的情感内容在塑造听众体验和影响音乐偏好方面起着关键作用。本研究旨在解决歌词的多标签情感归因问题，即预测六种基本情感的强度分数。

Method: 研究方法包括：1) 构建了一个使用平均意见得分（MOS）方法的手动标注数据集，该数据集聚合了多个人工标注者的注释以确保标签的可靠性。2) 在零样本（zero-shot）场景下，对多个公开可用的大型语言模型（LLM）进行了全面评估。3) 对一个基于BERT的模型进行了微调，专门用于预测多标签情感分数。

Result: 实验结果揭示了零样本模型和微调模型在捕捉歌词细微情感内容方面的相对优势和局限性。

Conclusion: 研究结果突出了大型语言模型（LLM）在创意文本情感识别方面的潜力，并为基于情感的音乐信息检索应用提供了模型选择策略的见解。

Abstract: The emotional content of song lyrics plays a pivotal role in shaping listener
experiences and influencing musical preferences. This paper investigates the
task of multi-label emotional attribution of song lyrics by predicting six
emotional intensity scores corresponding to six fundamental emotions. A
manually labeled dataset is constructed using a mean opinion score (MOS)
approach, which aggregates annotations from multiple human raters to ensure
reliable ground-truth labels. Leveraging this dataset, we conduct a
comprehensive evaluation of several publicly available large language models
(LLMs) under zero-shot scenarios. Additionally, we fine-tune a BERT-based model
specifically for predicting multi-label emotion scores. Experimental results
reveal the relative strengths and limitations of zero-shot and fine-tuned
models in capturing the nuanced emotional content of lyrics. Our findings
highlight the potential of LLMs for emotion recognition in creative texts,
providing insights into model selection strategies for emotion-based music
information retrieval applications. The labeled dataset is available at
https://github.com/LLM-HITCS25S/LyricsEmotionAttribution.

</details>


### [228] [Few-Shot Query Intent Detection via Relation-Aware Prompt Learning](https://arxiv.org/abs/2509.05635)
*Liang Zhang,Yuan Li,Shijie Zhang,Zheng Zhang,Xitong Li*

Main category: cs.CL

TL;DR: 该研究提出SAID框架，首次将文本和关系结构信息（如查询-查询、查询-回答关系）统一整合用于预训练，并引入QueryAdapt机制，以解决少样本意图检测中现有方法忽略结构信息的问题，并显著优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 意图检测是对话系统的关键组成部分，尤其在挑战性的少样本场景下。现有方法主要关注文本数据，通过预训练语言模型并进行微调，但忽略了对话系统中固有的关键结构信息（如查询-查询关系和查询-回答关系），导致知识迁移不够细致。

Method: 本文提出了SAID（结构化意图检测）框架，首次以统一的方式整合文本和关系结构信息进行模型预训练。在此基础上，进一步提出了QueryAdapt（查询自适应注意力网络）机制，通过从已学习的查询-查询和查询-回答关系中显式生成意图特定的关系标记，在关系标记级别进行操作，实现更细粒度的知识迁移。

Result: 在两个真实世界数据集上的大量实验结果表明，SAID显著优于最先进的方法。

Conclusion: SAID框架通过有效整合文本和关系结构信息，并结合QueryAdapt机制，成功解决了少样本意图检测中结构信息利用不足的问题，取得了优异的性能，为未来的对话系统发展提供了新的方向。

Abstract: Intent detection is a crucial component of modern conversational systems,
since accurately identifying user intent at the beginning of a conversation is
essential for generating effective responses. Recent efforts have focused on
studying this problem under a challenging few-shot scenario. These approaches
primarily leverage large-scale unlabeled dialogue text corpora to pretrain
language models through various pretext tasks, followed by fine-tuning for
intent detection with very limited annotations. Despite the improvements
achieved, existing methods have predominantly focused on textual data,
neglecting to effectively capture the crucial structural information inherent
in conversational systems, such as the query-query relation and query-answer
relation. To address this gap, we propose SAID, a novel framework that
integrates both textual and relational structure information in a unified
manner for model pretraining for the first time. Building on this framework, we
further propose a novel mechanism, the query-adaptive attention network
(QueryAdapt), which operates at the relation token level by generating
intent-specific relation tokens from well-learned query-query and query-answer
relations explicitly, enabling more fine-grained knowledge transfer. Extensive
experimental results on two real-world datasets demonstrate that SAID
significantly outperforms state-of-the-art methods.

</details>


### [229] [LM-Searcher: Cross-domain Neural Architecture Search with LLMs via Unified Numerical Encoding](https://arxiv.org/abs/2509.05657)
*Yuxuan Hu,Jihao Liu,Ke Wang,Jinliang Zhen,Weikang Shi,Manyuan Zhang,Qi Dou,Rui Liu,Aojun Zhou,Hongsheng Li*

Main category: cs.CL

TL;DR: 本文提出了LM-Searcher，一个新颖的框架，利用大型语言模型（LLMs）进行跨领域神经架构优化，无需大量的领域特定适应。它通过引入NCode作为通用架构表示和将NAS问题重构为排序任务来实现。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM驱动的神经架构搜索（NAS）方法过度依赖提示工程和领域特定调优，这限制了它们在不同任务中的实用性和可扩展性。

Method: LM-Searcher框架的核心是NCode，一种通用的神经架构数值字符串表示，支持跨领域架构编码和搜索。该方法将NAS问题重新定义为排序任务，并利用通过基于剪枝的子空间采样策略获得的指令微调样本来训练LLMs，以从候选池中选择高性能架构。此外，还构建了一个包含广泛架构-性能对的精选数据集，以促进鲁棒和可迁移的学习。

Result: 综合实验表明，LM-Searcher在域内（例如，用于图像分类的CNN）和域外（例如，用于分割和生成的LoRA配置）任务中均取得了有竞争力的性能。

Conclusion: LM-Searcher为灵活和可泛化的基于LLM的架构搜索建立了一个新范式。

Abstract: Recent progress in Large Language Models (LLMs) has opened new avenues for
solving complex optimization problems, including Neural Architecture Search
(NAS). However, existing LLM-driven NAS approaches rely heavily on prompt
engineering and domain-specific tuning, limiting their practicality and
scalability across diverse tasks. In this work, we propose LM-Searcher, a novel
framework that leverages LLMs for cross-domain neural architecture optimization
without the need for extensive domain-specific adaptation. Central to our
approach is NCode, a universal numerical string representation for neural
architectures, which enables cross-domain architecture encoding and search. We
also reformulate the NAS problem as a ranking task, training LLMs to select
high-performing architectures from candidate pools using instruction-tuning
samples derived from a novel pruning-based subspace sampling strategy. Our
curated dataset, encompassing a wide range of architecture-performance pairs,
encourages robust and transferable learning. Comprehensive experiments
demonstrate that LM-Searcher achieves competitive performance in both in-domain
(e.g., CNNs for image classification) and out-of-domain (e.g., LoRA
configurations for segmentation and generation) tasks, establishing a new
paradigm for flexible and generalizable LLM-based architecture search. The
datasets and models will be released at https://github.com/Ashone3/LM-Searcher.

</details>


### [230] [Cross-Question Method Reuse in Large Language Models: From Word-Level Prediction to Rational Logical-Layer Reasoning](https://arxiv.org/abs/2509.05660)
*Hong Su*

Main category: cs.CL

TL;DR: 本文提出了一种扩展大型语言模型（LLMs）方法复用范围的新方法，使其能够处理相似度较低或具有隐藏相似性的问题，通过分离问题与解决方案并引导LLM进行方案迁移，提高了跨问题方法复用的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型方法复用通常要求问题具有高度相似性，限制了其应用范围。本研究旨在将方法复用扩展到相似度较低或具有非显式隐藏相似性的问题。

Method: 对于具有通用-特定（广义或狭义）相似性的问题，作者提出首先将问题与解决方案分离，而不是直接将两者作为配对输入LLM。然后引导LLM将现有解决方案适应于新的相关问题，使其专注于解决方案迁移而非问题识别。该方法进一步扩展到仅共享部分特征或隐藏特性的问题。

Result: 实验验证表明，所提出的范围扩展方法增加了筛选出可复用解决方案的概率，从而提高了跨问题方法复用的有效性。

Conclusion: 本研究成功地将大型语言模型的方法复用范围扩展到传统相似性约束之外，使其能够处理相似度较低或具有隐藏相似性的问题，显著提升了方法复用的能力和效率。

Abstract: Large language models (LLMs) have been widely applied to assist in finding
solutions for diverse questions. Prior work has proposed representing a method
as a pair of a question and its corresponding solution, enabling method reuse.
However, existing approaches typically require the questions to be highly
similar. In this paper, we extend the scope of method reuse to address
questions with low similarity or with hidden similarities that are not
explicitly observable. For questions that are similar in a general-specific
sense (i.e., broader or narrower in scope), we propose to first separate the
question and solution, rather than directly feeding the pair to the LLM. The
LLM is then guided to adapt the solution to new but related questions, allowing
it to focus on solution transfer rather than question recognition. Furthermore,
we extend this approach to cases where questions only share partial features or
hidden characteristics. This enables cross-question method reuse beyond
conventional similarity constraints. Experimental verification shows that our
scope-extension approach increases the probability of filtering out reusable
solutions, thereby improving the effectiveness of cross-question method reuse.

</details>


### [231] [Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian](https://arxiv.org/abs/2509.05668)
*Michael Hoffmann,Jophin John,Stefan Schweter,Gokul Ramakrishnan,Hoi-Fong Mak,Alice Zhang,Dmitry Gaynullin,Nicolay J. Hammer*

Main category: cs.CL

TL;DR: Llama-GENBA-10B是一个基于Llama 3.1-8B构建的三语（英语、德语、巴伐利亚语）基础模型，旨在解决大型语言模型中以英语为中心的问题，并推广低资源语言巴伐利亚语。该模型通过平衡的预训练和创新的评估方法，在巴伐利亚语上取得了领先性能，并在英语和德语上表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型存在以英语为中心的偏见，忽视了其他语言，尤其是低资源语言。研究旨在开发一个多语言模型，不仅能处理高资源语言（如英语和德语），还能有效支持低资源语言（如巴伐利亚语），并为德国NLP社区提供服务。

Method: 该研究基于Llama 3.1-8B，将其扩展到10B参数，并使用164B代币进行持续预训练（82B英语、82B德语、80M巴伐利亚语），以平衡资源并防止英语主导。方法包括：1) 克服巴伐利亚语稀缺性，策划多语言语料库；2) 为三种语言创建统一的分词器；3) 优化架构和语言比例超参数以实现跨语言迁移；4) 通过将德语基准翻译成巴伐利亚语，建立首个标准化的三语评估套件。

Result: Llama-GENBA-10B展现出强大的跨语言性能。其微调版本在巴伐利亚语上超越了Apertus-8B-2509和gemma-2-9b，成为该语言类别中的最佳模型。同时，它在英语上优于EuroLLM，并在德语上与其表现持平。在Cerebras CS-2上进行的训练证明了高效的大规模多语言预训练，并记录了能源使用。

Conclusion: Llama-GENBA-10B成功地解决了大型语言模型中的英语中心偏见，并有效整合了低资源语言。该模型为构建包含低资源语言的包容性基础模型提供了蓝图，并为德国NLP社区提供了强大的工具，尤其是在巴伐利亚语方面树立了新的标杆。

Abstract: We present Llama-GENBA-10B, a trilingual foundation model addressing
English-centric bias in large language models. Built on Llama 3.1-8B and scaled
to 10B parameters, Llama-GENBA-10B is continuously pretrained on 164B tokens
(82B English, 82B German, and 80M Bavarian), balancing resources while
preventing English dominance. Targeted at the German NLP community, the model
also promotes Bavarian as a low-resource language. Development tackled four
challenges: (1) curating a multilingual corpus despite Bavarian scarcity, (2)
creating a unified tokenizer for English, German, and Bavarian, (3) optimizing
architecture and language-ratio hyperparameters for cross-lingual transfer, and
(4) establishing the first standardized trilingual evaluation suite by
translating German benchmarks into Bavarian. Evaluations show that
Llama-GENBA-10B achieves strong cross-lingual performance, with the fine-tuned
variant surpassing Apertus-8B-2509 and gemma-2-9b in Bavarian and establishing
itself as the best model in its class for this language, while also
outperforming EuroLLM in English and matching its results in German. Training
on the Cerebras CS-2 demonstrated efficient large-scale multilingual
pretraining with documented energy use, offering a blueprint for inclusive
foundation models that integrate low-resource languages.

</details>


### [232] [Revealing the Numeracy Gap: An Empirical Investigation of Text Embedding Models](https://arxiv.org/abs/2509.05691)
*Ningyuan Deng,Hanyu Duan,Yixuan Tang,Yi Yang*

Main category: cs.CL

TL;DR: 研究发现，当前文本嵌入模型在理解文本中的细微数值信息方面普遍存在困难，这对于金融、医疗等领域至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入模型的评估基准通常不涉及对文本中数值信息的细致理解，导致其在处理数字敏感领域（如金融和医疗）时，能否精确编码数值内容尚不明确。例如，“增长2%”与“增长20%”应有显著区别，但模型可能无法捕捉这种细微差异。

Method: 本研究使用金融背景下的合成数据，评估了13种广泛使用的文本嵌入模型，以检验它们捕捉数值细微差别的能力。

Result: 研究发现，这些文本嵌入模型普遍难以准确捕捉数值细节。

Conclusion: 本研究深入揭示了嵌入模型的数值理解能力，为未来研究提供了指导，以增强基于嵌入模型的自然语言处理系统处理数值内容的能力。

Abstract: Text embedding models are widely used in natural language processing
applications. However, their capability is often benchmarked on tasks that do
not require understanding nuanced numerical information in text. As a result,
it remains unclear whether current embedding models can precisely encode
numerical content, such as numbers, into embeddings. This question is critical
because embedding models are increasingly applied in domains where numbers
matter, such as finance and healthcare. For example, Company X's market share
grew by 2\% should be interpreted very differently from Company X's market
share grew by 20\%, even though both indicate growth in market share. This
study aims to examine whether text embedding models can capture such nuances.
Using synthetic data in a financial context, we evaluate 13 widely used text
embedding models and find that they generally struggle to capture numerical
details accurately. Our further analyses provide deeper insights into embedding
numeracy, informing future research to strengthen embedding model-based NLP
systems with improved capacity for handling numerical content.

</details>


### [233] [A Survey of the State-of-the-Art in Conversational Question Answering Systems](https://arxiv.org/abs/2509.05716)
*Manoj Madushanka Perera,Adnan Mahmood,Kasun Eranda Wijethilake,Fahmida Islam,Maryam Tahermazandarani,Quan Z. Sheng*

Main category: cs.CL

TL;DR: 这篇综述全面分析了对话式问答（ConvQA）领域的最新进展，包括其核心组件、先进机器学习技术、大型语言模型的作用以及关键数据集，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 对话式问答系统在自然语言处理中日益重要，并在客户支持、教育、法律和医疗等多个领域得到应用，在这些领域中保持连贯和相关的对话至关重要。

Method: 本综述通过以下方式进行：1. 检查ConvQA系统的核心组件（历史选择、问题理解、答案预测）。2. 调查强化学习、对比学习和迁移学习等先进机器学习技术。3. 探讨RoBERTa、GPT-4、Gemini 2.0 Flash、Mistral 7B和LLaMA 3等大型语言模型的关键作用。4. 分析关键的ConvQA数据集。

Result: 本研究提供了ConvQA领域最先进技术的全面分析，展示了大型语言模型通过数据可扩展性和架构进步带来的影响，并对关键ConvQA数据集进行了综合分析。

Conclusion: 这项工作全面概述了ConvQA领域的现状，提供了有价值的见解以指导未来的发展，并勾勒出开放的研究方向。

Abstract: Conversational Question Answering (ConvQA) systems have emerged as a pivotal
area within Natural Language Processing (NLP) by driving advancements that
enable machines to engage in dynamic and context-aware conversations. These
capabilities are increasingly being applied across various domains, i.e.,
customer support, education, legal, and healthcare where maintaining a coherent
and relevant conversation is essential. Building on recent advancements, this
survey provides a comprehensive analysis of the state-of-the-art in ConvQA.
This survey begins by examining the core components of ConvQA systems, i.e.,
history selection, question understanding, and answer prediction, highlighting
their interplay in ensuring coherence and relevance in multi-turn
conversations. It further investigates the use of advanced machine learning
techniques, including but not limited to, reinforcement learning, contrastive
learning, and transfer learning to improve ConvQA accuracy and efficiency. The
pivotal role of large language models, i.e., RoBERTa, GPT-4, Gemini 2.0 Flash,
Mistral 7B, and LLaMA 3, is also explored, thereby showcasing their impact
through data scalability and architectural advancements. Additionally, this
survey presents a comprehensive analysis of key ConvQA datasets and concludes
by outlining open research directions. Overall, this work offers a
comprehensive overview of the ConvQA landscape and provides valuable insights
to guide future advancements in the field.

</details>


### [234] [Exploring Subjective Tasks in Farsi: A Survey Analysis and Evaluation of Language Models](https://arxiv.org/abs/2509.05719)
*Donya Rooein,Flor Miriam Plaza-del-Arco,Debora Nozza,Dirk Hovy*

Main category: cs.CL

TL;DR: 尽管波斯语拥有大量数字文本，但在情感分析、情绪分析和毒性检测等主观NLP任务中，其数据资源严重不足且质量低下，导致模型表现不稳定。


<details>
  <summary>Details</summary>
Motivation: 波斯语拥有庞大的用户群和不断增长的数字文本（如维基百科文章），被认为是“中等资源语言”。然而，研究者质疑这一标签在主观NLP任务上的真实性，旨在深入探究其数据可用性和质量的实际挑战。

Method: 研究关注情感分析、情绪分析和毒性检测三项主观任务，审查了110篇关于波斯语主观任务的出版物，并使用少数可用数据集评估了预测模型。

Result: 研究发现，波斯语在主观任务上存在严重的数据可用性和质量挑战，缺乏公开可用数据集。现有数据集常缺少年龄和性别等关键人口统计学因素。此外，使用现有数据集评估预测模型时，结果在不同数据集和模型之间高度不稳定。研究指出，仅仅增加数据量不足以显著改善波斯语在NLP中的前景。

Conclusion: 波斯语的“中等资源”标签在主观NLP任务的背景下并不准确，其面临数据稀缺、质量差以及关键人口统计学信息缺失等问题。仅凭数据量的增加不足以推动该语言在NLP领域的实质性进步。

Abstract: Given Farsi's speaker base of over 127 million people and the growing
availability of digital text, including more than 1.3 million articles on
Wikipedia, it is considered a middle-resource language. However, this label
quickly crumbles when the situation is examined more closely. We focus on three
subjective tasks (Sentiment Analysis, Emotion Analysis, and Toxicity Detection)
and find significant challenges in data availability and quality, despite the
overall increase in data availability. We review 110 publications on subjective
tasks in Farsi and observe a lack of publicly available datasets. Furthermore,
existing datasets often lack essential demographic factors, such as age and
gender, that are crucial for accurately modeling subjectivity in language. When
evaluating prediction models using the few available datasets, the results are
highly unstable across both datasets and models. Our findings indicate that the
volume of data is insufficient to significantly improve a language's prospects
in NLP.

</details>


### [235] [QCSE: A Pretrained Quantum Context-Sensitive Word Embedding for Natural Language Processing](https://arxiv.org/abs/2509.05729)
*Charles M. Varmantchaonala,Niclas GÖtting,Nils-Erik SchÜtte,Jean Louis E. K. Fendji,Christopher Gies*

Main category: cs.CL

TL;DR: 本文提出了一个名为QCSE的预训练量子上下文敏感嵌入模型，该模型利用量子计算的特性捕捉上下文敏感的词嵌入，并引入量子原生上下文学习。模型提出了五种独特的上下文矩阵计算方法，并在富拉尼语和英语语料库上进行了评估，结果表明QCSE能有效捕捉上下文敏感性，并利用量子系统的表达能力，尤其对低资源语言有潜力。


<details>
  <summary>Details</summary>
Motivation: 量子自然语言处理（QNLP）提供了一种通过量子计算的力量编码和理解自然语言复杂性的新方法。本研究旨在利用量子系统的独特属性来学习语言中的上下文关系，并解决低资源语言（如富拉尼语）数据匮乏的问题。

Method: 本文提出了一个预训练的量子上下文敏感嵌入模型QCSE，该模型引入了量子原生上下文学习。核心方法是创新的上下文矩阵计算，旨在基于词语的周围语言上下文创建独特的表示。共提出了五种不同的上下文矩阵计算方法并进行了测试，这些方法结合了指数衰减、正弦调制、相移和基于哈希的变换等技术。模型在富拉尼语（一种低资源非洲语言）和英语语料库上进行了评估。

Result: 结果表明，QCSE模型不仅能捕捉上下文敏感性，还能利用量子系统的表达能力来表示丰富的、上下文感知的语言信息。在富拉尼语上的应用进一步突出了QNLP缓解此类语言数据匮乏问题的潜力。

Conclusion: 这项工作强调了量子计算在自然语言处理中的强大能力，并为将QNLP应用于各种任务和领域的实际语言挑战开辟了新途径。

Abstract: Quantum Natural Language Processing (QNLP) offers a novel approach to
encoding and understanding the complexity of natural languages through the
power of quantum computation. This paper presents a pretrained quantum
context-sensitive embedding model, called QCSE, that captures context-sensitive
word embeddings, leveraging the unique properties of quantum systems to learn
contextual relationships in languages. The model introduces quantum-native
context learning, enabling the utilization of quantum computers for linguistic
tasks. Central to the proposed approach are innovative context matrix
computation methods, designed to create unique, representations of words based
on their surrounding linguistic context. Five distinct methods are proposed and
tested for computing the context matrices, incorporating techniques such as
exponential decay, sinusoidal modulation, phase shifts, and hash-based
transformations. These methods ensure that the quantum embeddings retain
context sensitivity, thereby making them suitable for downstream language tasks
where the expressibility and properties of quantum systems are valuable
resources. To evaluate the effectiveness of the model and the associated
context matrix methods, evaluations are conducted on both a Fulani corpus, a
low-resource African language, dataset of small size and an English corpus of
slightly larger size. The results demonstrate that QCSE not only captures
context sensitivity but also leverages the expressibility of quantum systems
for representing rich, context-aware language information. The use of Fulani
further highlights the potential of QNLP to mitigate the problem of lack of
data for this category of languages. This work underscores the power of quantum
computation in natural language processing (NLP) and opens new avenues for
applying QNLP to real-world linguistic challenges across various tasks and
domains.

</details>


### [236] [Enhancing Factual Accuracy and Citation Generation in LLMs via Multi-Stage Self-Verification](https://arxiv.org/abs/2509.05741)
*Fernando Gabriela García,Qiyang Shi,Zilin Feng*

Main category: cs.CL

TL;DR: VeriFact-CoT是一种新方法，通过事实验证-反思-引用整合机制，解决大型语言模型（LLM）在生成事实敏感内容时出现的幻觉和缺乏引用问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成复杂、事实敏感内容时，普遍存在幻觉现象和缺乏可信引用来源的问题。

Method: VeriFact-CoT采用多阶段的“事实验证-反思-引用整合”机制，使LLM能够批判性地自我审查和修改其中间推理步骤及最终答案。

Result: 该方法显著提高了生成内容的客观准确性、可信度和可追溯性。

Conclusion: VeriFact-CoT使LLM在需要高保真度的应用（如科学研究、新闻报道和法律咨询）中变得更加可靠。

Abstract: This research introduces VeriFact-CoT (Verified Factual Chain-of-Thought), a
novel method designed to address the pervasive issues of hallucination and the
absence of credible citation sources in Large Language Models (LLMs) when
generating complex, fact-sensitive content. By incorporating a multi-stage
mechanism of 'fact verification-reflection-citation integration,' VeriFact-CoT
empowers LLMs to critically self-examine and revise their intermediate
reasoning steps and final answers. This process significantly enhances the
objective accuracy, trustworthiness, and traceability of the generated outputs,
making LLMs more reliable for applications demanding high fidelity such as
scientific research, news reporting, and legal consultation.

</details>


### [237] [LatinX: Aligning a Multilingual TTS Model with Direct Preference Optimization](https://arxiv.org/abs/2509.05863)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.CL

TL;DR: LatinX是一个多语言文本到语音（TTS）模型，用于级联语音到语音翻译，能在不同语言间保留源说话者的身份，通过三阶段训练（包括DPO）实现。


<details>
  <summary>Details</summary>
Motivation: 在级联语音到语音翻译中，需要在不同语言间保留源说话者的身份。

Method: LatinX是一个12层仅解码器的Transformer模型，分三阶段训练：(i) 文本到音频映射的预训练，(ii) 零样本语音克隆的监督微调，(iii) 使用基于词错误率（WER）和说话者相似度指标的自动标注对进行直接偏好优化（DPO）对齐。模型主要在英语和罗曼语系（特别是葡萄牙语）上训练。

Result: 与微调基线相比，结合DPO的LatinX模型持续降低了WER并提高了客观相似度。人类评估显示，其感知到的说话者相似度优于强基线（XTTSv2），但也揭示了客观和主观度量之间的差距。

Conclusion: LatinX模型成功实现了多语言文本到语音转换中的跨语言说话者身份保留。未来的工作将探索平衡偏好信号和低延迟架构。

Abstract: We present LatinX, a multilingual text-to-speech (TTS) model for cascaded
speech-to-speech translation that preserves the source speaker's identity
across languages. LatinX is a 12-layer decoder-only Transformer trained in
three stages: (i) pre-training for text-to-audio mapping, (ii) supervised
fine-tuning for zero-shot voice cloning, and (iii) alignment with Direct
Preference Optimization (DPO) using automatically labeled pairs based on Word
Error Rate (WER) and speaker-similarity metrics. Trained on English and Romance
languages with emphasis on Portuguese, LatinX with DPO consistently reduces WER
and improves objective similarity over the fine-tuned baseline. Human
evaluations further indicate stronger perceived speaker similarity than a
strong baseline (XTTSv2), revealing gaps between objective and subjective
measures. We provide cross-lingual analyses and discuss balanced preference
signals and lower-latency architectures as future work.

</details>


### [238] [ZhiFangDanTai: Fine-tuning Graph-based Retrieval-Augmented Generation Model for Traditional Chinese Medicine Formula](https://arxiv.org/abs/2509.05867)
*ZiXuan Zhang,Bowen Hao,Yingjie Li,Hongzhi Yin*

Main category: cs.CL

TL;DR: 本文提出了ZhiFangDanTai框架，结合图谱检索增强生成（GraphRAG）和大型语言模型（LLM）微调，旨在生成全面且可解释的中药方剂信息，解决了现有模型和数据集的局限性，并在实验中取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有中药方剂分析模型（传统算法或深度学习）缺乏完整的方剂组成和详细解释。尽管近期有研究使用中药指令数据集微调LLM以生成可解释方剂，但现有数据集缺乏方剂君臣佐使、功效、禁忌、舌脉诊断等详细信息，限制了模型输出的深度。

Method: 本文提出了ZhiFangDanTai框架。该框架结合了GraphRAG和LLM微调：GraphRAG用于检索并综合结构化的中医药知识生成简洁摘要；同时，构建了一个增强型指令数据集以提升LLM整合检索信息的能力。此外，提供了理论证明，表明将GraphRAG与微调技术结合可以降低中药方剂任务中的泛化误差和幻觉率。

Result: 在收集数据集和临床数据集上的实验结果表明，ZhiFangDanTai模型比现有最先进的模型取得了显著的改进。

Conclusion: ZhiFangDanTai框架成功地结合了GraphRAG和LLM微调，有效解决了中药方剂生成中信息不全面和解释性不足的问题，并在理论和实践上都展现出优越性能，为中医药方剂的智能化生成提供了新途径。

Abstract: Traditional Chinese Medicine (TCM) formulas play a significant role in
treating epidemics and complex diseases. Existing models for TCM utilize
traditional algorithms or deep learning techniques to analyze formula
relationships, yet lack comprehensive results, such as complete formula
compositions and detailed explanations. Although recent efforts have used TCM
instruction datasets to fine-tune Large Language Models (LLMs) for explainable
formula generation, existing datasets lack sufficient details, such as the
roles of the formula's sovereign, minister, assistant, courier; efficacy;
contraindications; tongue and pulse diagnosis-limiting the depth of model
outputs. To address these challenges, we propose ZhiFangDanTai, a framework
combining Graph-based Retrieval-Augmented Generation (GraphRAG) with LLM
fine-tuning. ZhiFangDanTai uses GraphRAG to retrieve and synthesize structured
TCM knowledge into concise summaries, while also constructing an enhanced
instruction dataset to improve LLMs' ability to integrate retrieved
information. Furthermore, we provide novel theoretical proofs demonstrating
that integrating GraphRAG with fine-tuning techniques can reduce generalization
error and hallucination rates in the TCM formula task. Experimental results on
both collected and clinical datasets demonstrate that ZhiFangDanTai achieves
significant improvements over state-of-the-art models. Our model is
open-sourced at https://huggingface.co/tczzx6/ZhiFangDanTai1.0.

</details>


### [239] [MedFactEval and MedAgentBrief: A Framework and Workflow for Generating and Evaluating Factual Clinical Summaries](https://arxiv.org/abs/2509.05878)
*François Grolleau,Emily Alsentzer,Timothy Keyes,Philip Chung,Akshay Swaminathan,Asad Aali,Jason Hom,Tridu Huynh,Thomas Lew,April S. Liang,Weihan Chu,Natasha Z. Steele,Christina F. Lin,Jingkun Yang,Kameron C. Black,Stephen P. Ma,Fateme N. Haredasht,Nigam H. Shah,Kevin Schulman,Jonathan H. Chen*

Main category: cs.CL

TL;DR: 本文提出了一个可扩展的临床文本事实评估框架（MedFactEval）和一个高质量生成工作流（MedAgentBrief），以解决大型语言模型在临床应用中事实准确性评估的挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）生成的临床文本的事实准确性是其被采纳的关键障碍，而专家评审对于系统所需的持续质量保证来说是不可扩展的。

Method: 研究提出了两个互补的贡献：1. MedFactEval框架，其中临床医生定义高显著性关键事实，然后由“LLM陪审团”（多LLM多数投票）评估这些事实在生成摘要中的包含情况。2. MedAgentBrief，一个模型无关的多步骤工作流，用于生成高质量、事实准确的出院总结。为验证评估框架，研究建立了由七名医生多数投票确定的黄金标准参考，并使用Cohen's kappa衡量LLM陪审团与专家组的一致性。

Result: MedFactEval的LLM陪审团与医生专家组达到了几乎完美的一致性（Cohen's kappa=81%），并且其表现统计学上不劣于单个人类专家（kappa=67%，P < 0.001）。

Conclusion: 本工作提供了一个强大的评估框架（MedFactEval）和一个高性能的生成工作流（MedAgentBrief），为在临床工作流中负责任地部署生成式AI提供了一个全面的方法。

Abstract: Evaluating factual accuracy in Large Language Model (LLM)-generated clinical
text is a critical barrier to adoption, as expert review is unscalable for the
continuous quality assurance these systems require. We address this challenge
with two complementary contributions. First, we introduce MedFactEval, a
framework for scalable, fact-grounded evaluation where clinicians define
high-salience key facts and an "LLM Jury"--a multi-LLM majority vote--assesses
their inclusion in generated summaries. Second, we present MedAgentBrief, a
model-agnostic, multi-step workflow designed to generate high-quality, factual
discharge summaries. To validate our evaluation framework, we established a
gold-standard reference using a seven-physician majority vote on
clinician-defined key facts from inpatient cases. The MedFactEval LLM Jury
achieved almost perfect agreement with this panel (Cohen's kappa=81%), a
performance statistically non-inferior to that of a single human expert
(kappa=67%, P < 0.001). Our work provides both a robust evaluation framework
(MedFactEval) and a high-performing generation workflow (MedAgentBrief),
offering a comprehensive approach to advance the responsible deployment of
generative AI in clinical workflows.

</details>


### [240] [Let's Roleplay: Examining LLM Alignment in Collaborative Dialogues](https://arxiv.org/abs/2509.05882)
*Abhijnan Nath,Carine Graff,Nikhil Krishnaswamy*

Main category: cs.CL

TL;DR: 本研究探讨了不同对齐方法如何影响大型语言模型（LLM）在多轮、多方协作中的有效性，特别是通过引入“摩擦代理”来促使团队反思和审议，结果表明这种方法显著优于传统对齐基线。


<details>
  <summary>Details</summary>
Motivation: 随着LLM日益成为人类的“合作者”，其在多轮互动中的行为可预测性、可验证性和可靠性变得至关重要。然而，常见的LLM对齐技术多在简化的单用户环境下开发，未能充分考虑长周期、多方互动的动态性。

Method: 研究通过“摩擦代理”的视角，考察了其如何干预群体对话，鼓励协作团队放慢速度并反思推理过程，以促进审议性决策。采用角色扮演方法评估了不同训练的摩擦代理在协作任务对话中的干预效果。提出了一种新颖的反事实评估框架，量化摩擦干预对群体协作轨迹和信念对齐的影响。

Result: 研究结果表明，与常见的对齐基线相比，摩擦感知（friction-aware）方法在帮助团队达成共识（即任务相关的共同命题）和提高任务结果的正确性方面，表现出显著优势。

Conclusion: 摩擦感知方法能有效提升LLM代理在多轮、多方协作中的表现，使其能更好地促进群体达成共识和提高决策的正确性，从而为构建更可靠的AI协作伙伴提供了新的方向。

Abstract: As Large Language Models (LLMs) integrate into diverse workflows, they are
increasingly being considered "collaborators" with humans. If such AI
collaborators are to be reliable, their behavior over multiturn interactions
must be predictable, validated and verified before deployment. Common alignment
techniques are typically developed under simplified single-user settings and do
not account for the dynamics of long-horizon multiparty interactions. This
paper examines how different alignment methods affect LLM agents' effectiveness
as partners in multiturn, multiparty collaborations. We study this question
through the lens of friction agents that intervene in group dialogues to
encourage the collaborative group to slow down and reflect upon their reasoning
for deliberative decision-making. Using a roleplay methodology, we evaluate
interventions from differently-trained friction agents in collaborative task
conversations. We propose a novel counterfactual evaluation framework that
quantifies how friction interventions change the trajectory of group
collaboration and belief alignment. Our results show that a friction-aware
approach significantly outperforms common alignment baselines in helping both
convergence to a common ground, or agreed-upon task-relevant propositions, and
correctness of task outcomes.

</details>


### [241] [Enhancing the Robustness of Contextual ASR to Varying Biasing Information Volumes Through Purified Semantic Correlation Joint Modeling](https://arxiv.org/abs/2509.05908)
*Yue Gu,Zhihao Du,Ying Shi,Shiliang Zhang,Qian Chen,Jiqing Han*

Main category: cs.CL

TL;DR: 本文提出了一种名为PSC-Joint的上下文ASR方法，通过识别和整合最相关的偏置信息，而非整个偏置列表，解决了现有跨注意力模型在偏置信息量变化（特别是长列表）时效果不佳的问题，显著提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 基于跨注意力的上下文ASR模型在识别个性化偏置短语方面取得了进展，但其有效性受偏置信息量变化（尤其是偏置列表长度显著增加时）的影响。研究发现，无论列表长度如何，只有有限的偏置信息与特定的ASR中间表示最相关，因此需要一种方法来识别并整合这些最相关的信息。

Method: 本文提出了纯化语义关联联合建模（PSC-Joint）方法。该方法定义并计算了ASR中间表示与偏置信息之间从粗到细的三种语义关联：列表级、短语级和令牌级。然后，联合建模这三种关联以产生它们的交集，从而突出并整合跨不同粒度的最相关偏置信息。此外，为降低联合建模带来的计算成本，还引入了一种基于分组竞争策略的纯化机制来过滤不相关的偏置短语。

Result: 与基线相比，PSC-Joint方法在不同长度偏置列表上，于AISHELL-1数据集上实现了高达21.34%的F1分数相对提升，在KeSpeech数据集上实现了高达28.46%的F1分数相对提升。

Conclusion: PSC-Joint方法通过识别和整合最相关的偏置信息，有效缓解了偏置信息量变化对上下文ASR效果的影响，显著提高了模型在不同长度偏置列表下的识别性能。

Abstract: Recently, cross-attention-based contextual automatic speech recognition (ASR)
models have made notable advancements in recognizing personalized biasing
phrases. However, the effectiveness of cross-attention is affected by
variations in biasing information volume, especially when the length of the
biasing list increases significantly. We find that, regardless of the length of
the biasing list, only a limited amount of biasing information is most relevant
to a specific ASR intermediate representation. Therefore, by identifying and
integrating the most relevant biasing information rather than the entire
biasing list, we can alleviate the effects of variations in biasing information
volume for contextual ASR. To this end, we propose a purified semantic
correlation joint modeling (PSC-Joint) approach. In PSC-Joint, we define and
calculate three semantic correlations between the ASR intermediate
representations and biasing information from coarse to fine: list-level,
phrase-level, and token-level. Then, the three correlations are jointly modeled
to produce their intersection, so that the most relevant biasing information
across various granularities is highlighted and integrated for contextual
recognition. In addition, to reduce the computational cost introduced by the
joint modeling of three semantic correlations, we also propose a purification
mechanism based on a grouped-and-competitive strategy to filter out irrelevant
biasing phrases. Compared with baselines, our PSC-Joint approach achieves
average relative F1 score improvements of up to 21.34% on AISHELL-1 and 28.46%
on KeSpeech, across biasing lists of varying lengths.

</details>


### [242] [Accelerating Large Language Model Inference via Early-Exiting Algorithms](https://arxiv.org/abs/2509.05915)
*Sangmin Bae*

Main category: cs.CL

TL;DR: 本论文通过协同设计自适应算法和模型架构，解决了大型语言模型中自适应计算（如提前退出）带来的计算成本与批处理推理吞吐量之间的冲突，从而提高了模型的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的部署受限于其高昂的计算成本。虽然自适应计算方法（如提前退出）旨在降低成本，但其逐令牌的动态性在批处理推理中可能引入系统级瓶颈，反而降低吞吐量。

Method: 1. 提出了一种高效的并行解码机制，以解决传统提前退出中的开销问题。2. 引入深度参数共享作为架构基础，不仅实现参数高效的模型，还缓解了动态推理中的同步问题。3. 提出了一个统一框架，其中轻量级路由器经过预训练，可为每个令牌动态分配最佳递归深度。

Result: 通过在一个模型中同时优化自适应计算和参数效率，本研究在效率和性能之间建立了一个新的帕累托前沿。

Conclusion: 通过协同设计自适应算法和模型架构，可以有效地解决大型语言模型中动态性与效率之间的根本冲突，从而实现更实用、更高效的模型部署。

Abstract: Large language models have achieved remarkable capabilities, but their
practical deployment is hindered by significant computational costs. While
adaptive computation methods like early-exiting promise to reduce these costs,
they introduce a fundamental conflict: the per-token dynamism intended to save
computation often creates system-level bottlenecks that can paradoxically
reduce throughput in batched inference. This dissertation resolves this
conflict by co-designing adaptive algorithms and model architectures to strike
an optimal balance between dynamism and efficiency. To this end, our work first
addresses critical sources of overhead in conventional early-exiting by
proposing an efficient parallel decoding mechanism. We then show that deep
parameter sharing provides an architectural foundation that not only yields
compact, parameter-efficient models but also inherently mitigates the critical
synchronization issues affecting dynamic inference. Finally, this work presents
a unified framework where lightweight routers are pretrained to dynamically
assign an optimal recursion depth for each token. This approach establishes a
new Pareto frontier between efficiency and performance by effectively
optimizing for both adaptive computation and parameter efficiency within a
single model.

</details>


### [243] [KatotohananQA: Evaluating Truthfulness of Large Language Models in Filipino](https://arxiv.org/abs/2509.06065)
*Lorenzo Alfred Nery,Ronald Dawson Catignas,Thomas James Tiam-Lee*

Main category: cs.CL

TL;DR: 该研究引入了TruthfulQA的菲律宾语翻译版本KatotohananQA，以评估大型语言模型在低资源语言中的真实性。结果显示英语和菲律宾语真实性之间存在显著性能差距，并强调了多语言评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的幻觉倾向限制了其可靠应用。现有真实性基准（如TruthfulQA）主要为英文，导致在低资源语言中评估LLMs存在空白。

Method: 将TruthfulQA基准翻译成菲律宾语，创建了KatotohananQA。使用二元选择框架评估了七个免费专有模型。

Result: 研究发现英语和菲律宾语真实性之间存在显著的性能差距。较新的OpenAI模型（GPT-5和GPT-5 mini）表现出强大的多语言鲁棒性。结果还揭示了不同问题特征之间的差异，表明某些问题类型、类别和主题对多语言迁移的鲁棒性较差。

Conclusion: 为了确保LLM使用的公平性和可靠性，需要进行更广泛的多语言评估。

Abstract: Large Language Models (LLMs) achieve remarkable performance across various
tasks, but their tendency to produce hallucinations limits reliable adoption.
Benchmarks such as TruthfulQA have been developed to measure truthfulness, yet
they are primarily available in English, leaving a gap in evaluating LLMs in
low-resource languages. To address this, we present KatotohananQA, a Filipino
translation of the TruthfulQA benchmark. Seven free-tier proprietary models
were assessed using a binary-choice framework. Findings show a significant
performance gap between English and Filipino truthfulness, with newer OpenAI
models (GPT-5 and GPT-5 mini) demonstrating strong multilingual robustness.
Results also reveal disparities across question characteristics, suggesting
that some question types, categories, and topics are less robust to
multilingual transfer which highlight the need for broader multilingual
evaluation to ensure fairness and reliability in LLM usage.

</details>


### [244] [Multimodal Fine-grained Context Interaction Graph Modeling for Conversational Speech Synthesis](https://arxiv.org/abs/2509.06074)
*Zhenqi Jia,Rui Liu,Berrak Sisman,Haizhou Li*

Main category: cs.CL

TL;DR: 本文提出MFCIG-CSS，一个基于多模态细粒度上下文交互图的对话语音合成系统，通过建模词级语义和韵律交互，显著提升了合成语音的韵律表现力。


<details>
  <summary>Details</summary>
Motivation: 现有的对话语音合成（CSS）方法在利用多模态对话历史（MDH）时，忽略了MDH中包含的细粒度词级语义和韵律知识，未能对这些细粒度交互进行有效建模。

Method: 本文提出了MFCIG-CSS系统，通过构建两个专门的多模态细粒度对话交互图：语义交互图和韵律交互图。这些图有效地编码了词级语义、韵律之间的交互及其对后续话语的影响，然后利用编码的交互特征来增强合成语音的自然对话韵律。

Result: 在DailyTalk数据集上的实验表明，MFCIG-CSS在韵律表现力方面优于所有基线模型。

Conclusion: MFCIG-CSS通过引入细粒度的多模态上下文交互图建模，有效解决了现有CSS方法忽略词级语义和韵律交互的问题，显著提升了对话语音合成的韵律自然度。

Abstract: Conversational Speech Synthesis (CSS) aims to generate speech with natural
prosody by understanding the multimodal dialogue history (MDH). The latest work
predicts the accurate prosody expression of the target utterance by modeling
the utterance-level interaction characteristics of MDH and the target
utterance. However, MDH contains fine-grained semantic and prosody knowledge at
the word level. Existing methods overlook the fine-grained semantic and
prosodic interaction modeling. To address this gap, we propose MFCIG-CSS, a
novel Multimodal Fine-grained Context Interaction Graph-based CSS system. Our
approach constructs two specialized multimodal fine-grained dialogue
interaction graphs: a semantic interaction graph and a prosody interaction
graph. These two interaction graphs effectively encode interactions between
word-level semantics, prosody, and their influence on subsequent utterances in
MDH. The encoded interaction features are then leveraged to enhance synthesized
speech with natural conversational prosody. Experiments on the DailyTalk
dataset demonstrate that MFCIG-CSS outperforms all baseline models in terms of
prosodic expressiveness. Code and speech samples are available at
https://github.com/AI-S2-Lab/MFCIG-CSS.

</details>


### [245] [Multimodal Reasoning for Science: Technical Report and 1st Place Solution to the ICML 2025 SeePhys Challenge](https://arxiv.org/abs/2509.06079)
*Hao Liang,Ruitao Wu,Bohan Zeng,Junbo Niu,Wentao Zhang,Bin Dong*

Main category: cs.CL

TL;DR: 本文介绍了一种字幕辅助推理框架，有效连接了视觉和文本模态，在ICML 2025 SeePhys挑战中获得第一名，并在MathVerse几何推理基准上验证了其泛化性。


<details>
  <summary>Details</summary>
Motivation: 多模态推理是人工智能中的一个基本挑战。尽管文本推理取得了显著进展，但即使是先进模型在多模态场景中也难以保持强大性能，存在性能差距。

Method: 引入了一种字幕辅助推理框架，该框架通过有效连接视觉和文本模态来弥合现有差距。

Result: 该方法在ICML 2025 AI for Math Workshop & Challenge 2: SeePhys中获得第一名，展示了其有效性和鲁棒性。此外，它还在MathVerse几何推理基准上验证了其泛化性和多功能性。

Conclusion: 所提出的字幕辅助推理框架能够有效、鲁棒且多功能地解决多模态推理问题，成功地连接了视觉和文本模态。

Abstract: Multimodal reasoning remains a fundamental challenge in artificial
intelligence. Despite substantial advances in text-based reasoning, even
state-of-the-art models such as GPT-o3 struggle to maintain strong performance
in multimodal scenarios. To address this gap, we introduce a caption-assisted
reasoning framework that effectively bridges visual and textual modalities. Our
approach achieved 1st place in the ICML 2025 AI for Math Workshop \& Challenge
2: SeePhys, highlighting its effectiveness and robustness. Furthermore, we
validate its generalization on the MathVerse benchmark for geometric reasoning,
demonstrating the versatility of our method. Our code is publicly available at
https://github.com/OpenDCAI/SciReasoner.

</details>


### [246] [Orthogonal Low-rank Adaptation in Lie Groups for Continual Learning of Large Language Models](https://arxiv.org/abs/2509.06100)
*Kefan Cao,Shuaicheng Wu*

Main category: cs.CL

TL;DR: 针对大型语言模型在多任务学习中的灾难性遗忘问题，本文提出OLieRA方法。该方法结合李群理论和乘法更新来保留模型参数的几何结构，并施加正交性约束于任务子空间，从而在持续学习基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在顺序多任务设置中容易出现灾难性遗忘。现有的参数正则化方法（如O-LoRA和N-LoRA）通过强制低秩子空间正交性来缓解任务干扰，但它们忽视了传统加性微调会破坏LLM参数固有的几何结构，从而限制了性能。本研究的核心洞察是LLM参数空间具有几何结构，除了强制正交性外，还必须保留这一结构。

Method: 本文提出了基于李群的正交低秩适应（Orthogonal Low-rank Adaptation in Lie Groups, OLieRA）方法。该方法将李群理论引入LLM微调中，利用乘法更新来保留参数几何结构，同时对任务子空间施加正交性约束。

Result: 实验表明，OLieRA在Standard CL基准测试中取得了最先进（state-of-the-art）的结果。此外，在“大量任务”设置下，OLieRA仍然是表现最佳的方法之一。

Conclusion: OLieRA通过结合李群理论的乘法更新来保留LLM参数的几何结构，并施加正交性约束，有效缓解了灾难性遗忘问题，并在持续学习任务中展现出卓越的性能。

Abstract: Large language models (LLMs) are prone to catastrophic forgetting in
sequential multi-task settings. Parameter regularization methods such as O-LoRA
and N-LoRA alleviate task interference by enforcing low-rank subspace
orthogonality, but they overlook the fact that conventional additive
fine-tuning disrupts the intrinsic geometric structure of LLM parameters,
limiting performance. Our key insight is that the parameter space of LLMs
possesses a geometric structure, which must be preserved in addition to
enforcing orthogonality. Based on this, we propose Orthogonal Low-rank
Adaptation in Lie Groups (OLieRA), which introduces Lie group theory into LLM
fine-tuning: leveraging multiplicative updates to preserve parameter geometry
while applying orthogonality constraints to task subspaces. Experiments
demonstrate that OLieRA achieves state-of-the-art results on the Standard CL
benchmark and remains among the top-performing methods in the Large Number of
Tasks setting.

</details>


### [247] [Benchmarking Gender and Political Bias in Large Language Models](https://arxiv.org/abs/2509.06164)
*Jinrui Yang,Xudong Han,Timothy Baldwin*

Main category: cs.CL

TL;DR: 该研究引入了EuroParlVote基准，用于评估大型语言模型（LLMs）在政治敏感环境中的表现。通过将欧洲议会辩论演讲与投票结果和议员元数据关联，研究发现LLMs在性别分类和投票预测任务中存在偏见，包括将女性议员误分类为男性、对女性发言者的预测准确性降低，以及偏爱中间派政治团体。专有模型表现优于开源模型。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估LLMs在政治敏感语境中的表现，特别是揭示其可能存在的偏见模式。现有评估基准可能未能充分捕捉到政治辩论和投票行为中的复杂性和敏感性，以及与人口统计学特征（如性别）相关的偏见。

Method: 研究引入了EuroParlVote数据集，该数据集将欧洲议会辩论演讲与点名投票结果相链接，并包含欧洲议会议员（MEP）的丰富人口统计元数据（如性别、年龄、国家和政治团体）。研究使用该基准在性别分类和投票预测两项任务上评估了最先进的LLMs，并比较了专有模型（如GPT-4o）和开源模型的性能。

Result: 研究揭示了LLMs中存在一致的偏见模式：LLMs经常将女性议员错误地归类为男性，并且在模拟女性发言者的投票时准确性降低。在政治方面，LLMs倾向于偏爱中间派团体，而在极左和极右团体上的表现不佳。专有模型（如GPT-4o）在鲁棒性和公平性方面均优于开源模型。

Conclusion: LLMs在政治敏感语境中表现出显著的偏见，尤其是在性别分类和政治立场预测方面。EuroParlVote基准对于未来在政治语境下研究自然语言处理（NLP）的公平性和问责制具有重要价值。研究结果表明，专有模型在处理此类敏感任务时可能具有优势，并且需要进一步研究以解决LLMs中的偏见问题。

Abstract: We introduce EuroParlVote, a novel benchmark for evaluating large language
models (LLMs) in politically sensitive contexts. It links European Parliament
debate speeches to roll-call vote outcomes and includes rich demographic
metadata for each Member of the European Parliament (MEP), such as gender, age,
country, and political group. Using EuroParlVote, we evaluate state-of-the-art
LLMs on two tasks -- gender classification and vote prediction -- revealing
consistent patterns of bias. We find that LLMs frequently misclassify female
MEPs as male and demonstrate reduced accuracy when simulating votes for female
speakers. Politically, LLMs tend to favor centrist groups while underperforming
on both far-left and far-right ones. Proprietary models like GPT-4o outperform
open-weight alternatives in terms of both robustness and fairness. We release
the EuroParlVote dataset, code, and demo to support future research on fairness
and accountability in NLP within political contexts.

</details>


### [248] [Understanding the Influence of Synthetic Data for Text Embedders](https://arxiv.org/abs/2509.06184)
*Jacob Mitchell Springer,Vaibhav Adlakha,Siva Reddy,Aditi Raghunathan,Marius Mosbach*

Main category: cs.CL

TL;DR: 本文复制并公开了Mistral-E5的合成数据，发现其能提升文本嵌入器性能，但这种泛化益处是稀疏且局部化的，并存在任务间的性能权衡，挑战了合成数据能构建更通用嵌入器的观点。


<details>
  <summary>Details</summary>
Motivation: 通用文本嵌入器训练日益依赖LLM生成的合成数据，但目前缺乏公开可用的合成数据集，阻碍了对其在泛化中作用的研究。

Method: 首先，复制并公开发布了Wang等人（Mistral-E5）提出的合成数据。然后，批判性地分析了合成数据究竟在何处改善了模型的泛化能力。

Result: 研究发现，复制的合成数据质量高，能持续提升性能。然而，合成数据带来的益处是稀疏的，且高度局限于特定数据集。此外，不同类别任务的性能之间存在权衡，对一个任务有益的数据可能降低另一个任务的性能。

Conclusion: 研究结果强调了当前合成数据方法在构建通用嵌入器方面的局限性，并挑战了通过合成数据训练能产生更稳健的跨任务嵌入模型的观念。

Abstract: Recent progress in developing general purpose text embedders has been driven
by training on ever-growing corpora of synthetic LLM-generated data.
Nonetheless, no publicly available synthetic dataset exists, posing a barrier
to studying its role for generalization. To address this issue, we first
reproduce and publicly release the synthetic data proposed by Wang et al.
(Mistral-E5). Our synthetic data is high quality and leads to consistent
improvements in performance. Next, we critically examine where exactly
synthetic data improves model generalization. Our analysis reveals that
benefits from synthetic data are sparse and highly localized to individual
datasets. Moreover, we observe trade-offs between the performance on different
categories and data that benefits one task, degrades performance on another.
Our findings highlight the limitations of current synthetic data approaches for
building general-purpose embedders and challenge the notion that training on
synthetic data leads to more robust embedding models across tasks.

</details>


### [249] [Augmented Fine-Tuned LLMs for Enhanced Recruitment Automation](https://arxiv.org/abs/2509.06196)
*Mohamed T. Younes,Omar Walid,Khaled Shaban,Ali Hamdi,Mai Hassan*

Main category: cs.CL

TL;DR: 本文提出了一种通过微调大型语言模型（LLMs）来自动化招聘流程的新方法，结合合成数据和真实简历数据，显著提高了招聘任务的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了解决通用LLMs在招聘任务中的局限性，提高招聘流程的准确性和效率，实现更精准的候选人与职位匹配。

Method: 该研究构建在之前MLAR系统工作的基础上，引入了一种新颖的方法：为招聘任务专门微调LLMs。具体包括：创建标准化JSON格式的合成数据集，并使用DeepSeek解析真实简历为相同JSON格式，以增加数据多样性和真实性，然后用这些数据训练和微调LLMs。

Result: 实验结果表明，与基础模型和其他最先进的LLMs相比，该方法在精确匹配、F1分数、BLEU分数、ROUGE分数和整体相似度等性能指标上取得了显著提升。特别是，微调后的Phi-4模型在招聘任务中达到了最高的F1分数90.62%。

Conclusion: 研究强调了微调LLMs在招聘自动化领域的巨大潜力，通过提供更准确的候选人与职位匹配，有望彻底改变招聘工作流程。

Abstract: This paper presents a novel approach to recruitment automation. Large
Language Models (LLMs) were fine-tuned to improve accuracy and efficiency.
Building upon our previous work on the Multilayer Large Language Model-Based
Robotic Process Automation Applicant Tracking (MLAR) system . This work
introduces a novel methodology. Training fine-tuned LLMs specifically tuned for
recruitment tasks. The proposed framework addresses the limitations of generic
LLMs by creating a synthetic dataset that uses a standardized JSON format. This
helps ensure consistency and scalability. In addition to the synthetic data
set, the resumes were parsed using DeepSeek, a high-parameter LLM. The resumes
were parsed into the same structured JSON format and placed in the training
set. This will help improve data diversity and realism. Through
experimentation, we demonstrate significant improvements in performance
metrics, such as exact match, F1 score, BLEU score, ROUGE score, and overall
similarity compared to base models and other state-of-the-art LLMs. In
particular, the fine-tuned Phi-4 model achieved the highest F1 score of 90.62%,
indicating exceptional precision and recall in recruitment tasks. This study
highlights the potential of fine-tuned LLMs. Furthermore, it will revolutionize
recruitment workflows by providing more accurate candidate-job matching.

</details>


### [250] [MSLEF: Multi-Segment LLM Ensemble Finetuning in Recruitment](https://arxiv.org/abs/2509.06200)
*Omar Walid,Mohamed T. Younes,Khaled Shaban,Mai Hassan,Ali Hamdi*

Main category: cs.CL

TL;DR: 本文提出了MSLEF，一个多段集成框架，通过LLM微调来增强简历解析，以提高招聘自动化中的准确性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有单模型系统在处理多样化的简历格式和结构时存在局限性，需要一种能有效适应并提高解析准确性的解决方案，以提升招聘自动化效率。

Method: MSLEF是一个多段集成框架，它通过加权投票整合了多个经过微调的大型语言模型（LLM），每个模型专注于特定的简历段落。它引入了段落感知架构和针对每个简历部分的字段特定加权。该框架使用Gemini-2.5-Flash作为复杂部分的聚合器，并利用Gemma 9B、LLaMA 3.1 8B和Phi-4 14B等LLM。

Result: MSLEF在精确匹配（EM）、F1分数、BLEU、ROUGE和招聘相似度（RS）等指标上取得了显著改进，在RS方面比最佳单模型高出多达+7%。其段落感知设计增强了对不同简历布局的泛化能力。

Conclusion: MSLEF框架高度适应真实世界的招聘场景，能够确保精确可靠的候选人信息表示，有效克服了单模型的局限性，提升了简历解析的准确性和泛化能力。

Abstract: This paper presents MSLEF, a multi-segment ensemble framework that employs
LLM fine-tuning to enhance resume parsing in recruitment automation. It
integrates fine-tuned Large Language Models (LLMs) using weighted voting, with
each model specializing in a specific resume segment to boost accuracy.
Building on MLAR , MSLEF introduces a segment-aware architecture that leverages
field-specific weighting tailored to each resume part, effectively overcoming
the limitations of single-model systems by adapting to diverse formats and
structures. The framework incorporates Gemini-2.5-Flash LLM as a high-level
aggregator for complex sections and utilizes Gemma 9B, LLaMA 3.1 8B, and Phi-4
14B. MSLEF achieves significant improvements in Exact Match (EM), F1 score,
BLEU, ROUGE, and Recruitment Similarity (RS) metrics, outperforming the best
single model by up to +7% in RS. Its segment-aware design enhances
generalization across varied resume layouts, making it highly adaptable to
real-world hiring scenarios while ensuring precise and reliable candidate
representation.

</details>


### [251] [No Encore: Unlearning as Opt-Out in Music Generation](https://arxiv.org/abs/2509.06277)
*Jinju Kim,Taehan Kim,Abdul Waheed,Rita Singh*

Main category: cs.CL

TL;DR: 本文初步探讨了将机器学习遗忘技术应用于文本到音乐（TTM）生成模型，以解决版权内容滥用问题，并分析了其有效性和挑战。


<details>
  <summary>Details</summary>
Motivation: AI音乐生成技术迅速发展，但存在滥用受版权保护作品的风险，引发了伦理和法律担忧。研究旨在通过技术手段防止这种无意的使用。

Method: 研究将现有的机器学习遗忘方法应用于一个预训练的文本到音乐（TTM）基线模型。分析了这些方法在遗忘预训练数据集方面的有效性，同时力求不损害模型的整体性能。

Result: 研究展示了将机器学习遗忘技术应用于预防创意内容无意使用的初步成果。提供了在音乐生成领域应用遗忘技术所面临挑战的见解，并为未来在此类模型上应用遗忘技术奠定了基础分析。

Conclusion: 机器学习遗忘技术有望解决AI音乐生成中的版权滥用问题。尽管存在挑战，但这项初步研究为未来在音乐生成模型中实施遗忘机制提供了重要的基础和方向。

Abstract: AI music generation is rapidly emerging in the creative industries, enabling
intuitive music generation from textual descriptions. However, these systems
pose risks in exploitation of copyrighted creations, raising ethical and legal
concerns. In this paper, we present preliminary results on the first
application of machine unlearning techniques from an ongoing research to
prevent inadvertent usage of creative content. Particularly, we explore
existing methods in machine unlearning to a pre-trained Text-to-Music (TTM)
baseline and analyze their efficacy in unlearning pre-trained datasets without
harming model performance. Through our experiments, we provide insights into
the challenges of applying unlearning in music generation, offering a
foundational analysis for future works on the application of unlearning for
music generative models.

</details>


### [252] [Mask-GCG: Are All Tokens in Adversarial Suffixes Necessary for Jailbreak Attacks?](https://arxiv.org/abs/2509.06350)
*Junjie Mu,Zonghao Ying,Zhekui Fan,Zonglei Jing,Yaoyuan Zhang,Zhengmin Yu,Wenxin Zhang,Quanchen Zou,Xiangzheng Zhang*

Main category: cs.CL

TL;DR: 本文提出了 Mask-GCG，一种通过可学习的 token 掩码来识别和修剪越狱攻击后缀中低影响力 token 的方法。它减少了冗余，降低了计算开销，并提高了攻击效率，同时揭示了大型语言模型越狱提示中的 token 冗余。


<details>
  <summary>Details</summary>
Motivation: 现有的贪婪坐标梯度 (GCG) 及其变体在越狱攻击中均依赖固定长度的后缀，但这些后缀中可能存在的冗余尚未被探索，这导致了不必要的计算开销。

Method: Mask-GCG 是一种即插即用的方法，它采用可学习的 token 掩码来识别后缀中具有影响力的 token。该方法增加了高影响力位置 token 的更新概率，并修剪了低影响力位置的 token。这不仅减少了冗余，还缩小了梯度空间，从而降低了计算开销和攻击成功所需的时间。

Result: 实验结果表明，后缀中的大多数 token 对攻击成功有显著贡献，但修剪少数低影响力 token 不会影响损失值或损害攻击成功率。这揭示了大型语言模型提示中的 token 冗余。Mask-GCG 与 GCG 相比，降低了计算开销并缩短了攻击时间。

Conclusion: Mask-GCG 通过识别和修剪越狱提示中的冗余 token，为开发高效且可解释的大型语言模型提供了新的视角和见解。

Abstract: Jailbreak attacks on Large Language Models (LLMs) have demonstrated various
successful methods whereby attackers manipulate models into generating harmful
responses that they are designed to avoid. Among these, Greedy Coordinate
Gradient (GCG) has emerged as a general and effective approach that optimizes
the tokens in a suffix to generate jailbreakable prompts. While several
improved variants of GCG have been proposed, they all rely on fixed-length
suffixes. However, the potential redundancy within these suffixes remains
unexplored. In this work, we propose Mask-GCG, a plug-and-play method that
employs learnable token masking to identify impactful tokens within the suffix.
Our approach increases the update probability for tokens at high-impact
positions while pruning those at low-impact positions. This pruning not only
reduces redundancy but also decreases the size of the gradient space, thereby
lowering computational overhead and shortening the time required to achieve
successful attacks compared to GCG. We evaluate Mask-GCG by applying it to the
original GCG and several improved variants. Experimental results show that most
tokens in the suffix contribute significantly to attack success, and pruning a
minority of low-impact tokens does not affect the loss values or compromise the
attack success rate (ASR), thereby revealing token redundancy in LLM prompts.
Our findings provide insights for developing efficient and interpretable LLMs
from the perspective of jailbreak attacks.

</details>


### [253] [PL-CA: A Parametric Legal Case Augmentation Framework](https://arxiv.org/abs/2509.06356)
*Ao Chang,Yubo Chen,Jun Zhao*

Main category: cs.CL

TL;DR: 本文提出了PL-CA，一种结合参数化RAG（P-RAG）和LoRA的方法，将法律知识编码为参数向量并集成到LLM中，以缓解传统RAG的上下文压力和计算开销。同时，构建了一个多任务、专家标注的法律数据集，实验证明PL-CA在保持性能的同时有效降低了长上下文的开销。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG方法在法律领域虽有效，但存在以下局限：1) 将检索文档直接注入模型上下文，导致上下文窗口限制和计算开销，影响模型注意力并降低性能；2) 现有基准缺乏专家标注，且仅关注单一任务，无法反映真实世界法律场景中多任务混合的复杂性。

Method: 本文提出PL-CA方法，包括：1) 参数化RAG (P-RAG) 框架，用于对语料库知识进行数据增强，并将法律知识编码为参数向量；2) 通过LoRA将这些参数化知识集成到大型语言模型的前馈网络（FFN）中，从而缓解模型的上下文压力；3) 构建了一个包含2000多个训练和测试实例的多任务法律数据集，所有数据均经过专家标注和手动验证。

Result: 实验结果表明，与传统RAG相比，PL-CA方法在保持下游任务竞争性能的同时，显著减少了因过长上下文引起的计算开销。

Conclusion: PL-CA通过将法律知识参数化并集成到LLM中，有效解决了传统RAG在法律领域面临的上下文压力和计算开销问题，为法律领域的知识增强型模型提供了一种更高效的解决方案。新构建的多任务法律数据集也为未来研究提供了宝贵资源。

Abstract: Conventional RAG is considered one of the most effective methods for
addressing model knowledge insufficiency and hallucination, particularly in the
judicial domain that requires high levels of knowledge rigor, logical
consistency, and content integrity. However, the conventional RAG method only
injects retrieved documents directly into the model's context, which severely
constrains models due to their limited context windows and introduces
additional computational overhead through excessively long contexts, thereby
disrupting models' attention and degrading performance on downstream tasks.
Moreover, many existing benchmarks lack expert annotation and focus solely on
individual downstream tasks while real-world legal scenarios consist of
multiple mixed legal tasks, indicating conventional benchmarks' inadequacy for
reflecting models' true capabilities. To address these limitations, we propose
PL-CA, which introduces a parametric RAG (P-RAG) framework to perform data
augmentation on corpus knowledge and encode this legal knowledge into
parametric vectors, and then integrates this parametric knowledge into the
LLM's feed-forward networks (FFN) via LoRA, thereby alleviating models' context
pressure. Additionally, we also construct a multi-task legal dataset comprising
more than 2000 training and test instances, which are all expert-annotated and
manually verified. We conduct our experiments on our dataset, and the
experimental results demonstrate that our method reduces the overhead
associated with excessively long contexts while maintaining competitive
performance on downstream tasks compared to conventional RAG. Our code and
dataset are provided in the appendix.

</details>


### [254] [Do LLMs exhibit the same commonsense capabilities across languages?](https://arxiv.org/abs/2509.06401)
*Ivan Martínez-Murillo,Elena Lloret,Paloma Moreda,Albert Gatt*

Main category: cs.CL

TL;DR: 本文通过引入MULTICOM基准测试，评估了大型语言模型（LLMs）在多语言常识生成方面的能力，发现LLMs在英语上表现优异，但在资源较少的语言上表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在多语言常识生成方面的能力。

Method: 引入了MULTICOM基准测试（将COCOTEROS数据集扩展到英语、西班牙语、荷兰语和瓦伦西亚语四种语言），任务是生成包含给定词语三元组的常识性句子。评估了包括LLaMA、Qwen、Gemma、EuroLLM和Salamandra在内的一系列开源LLMs，并结合了自动指标、LLM作为判官（使用Prometheus和JudgeLM）以及人工标注进行评估。

Result: 结果一致显示英语表现优异，而资源较少的语言表现显著较低。上下文支持产生了混合结果，但倾向于有益于代表性不足的语言。

Conclusion: 这些发现强调了LLMs在多语言常识生成方面当前的局限性。

Abstract: This paper explores the multilingual commonsense generation abilities of
Large Language Models (LLMs). To facilitate this investigation, we introduce
MULTICOM, a novel benchmark that extends the COCOTEROS dataset to four
languages: English, Spanish, Dutch, and Valencian. The task involves generating
a commonsensical sentence that includes a given triplet of words. We evaluate a
range of open-source LLMs, including LLaMA, Qwen, Gemma, EuroLLM, and
Salamandra, on this benchmark. Our evaluation combines automatic metrics,
LLM-as-a-judge approaches (using Prometheus and JudgeLM), and human
annotations. Results consistently show superior performance in English, with
significantly lower performance in less-resourced languages. While contextual
support yields mixed results, it tends to benefit underrepresented languages.
These findings underscore the current limitations of LLMs in multilingual
commonsense generation. The dataset is publicly available at
https://huggingface.co/datasets/gplsi/MULTICOM.

</details>


### [255] [WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents](https://arxiv.org/abs/2509.06501)
*Junteng Liu,Yunji Li,Chi Zhang,Jingyang Li,Aili Chen,Ke Ji,Weiyu Cheng,Zijia Wu,Chengyu Du,Qidi Xu,Jiayuan Song,Zhengmao Zhu,Wenhu Chen,Pengyu Zhao,Junxian He*

Main category: cs.CL

TL;DR: 本文提出了一种名为WebExplorer的数据生成方法，用于创建具有挑战性的信息检索查询-答案对。基于此数据，他们开发了WebExplorer-8B，一个8B参数的先进网络代理，它在多个信息检索基准测试中取得了当前最佳性能，甚至超越了更大的模型，为长程网络代理提供了一条实用路径。


<details>
  <summary>Details</summary>
Motivation: 现有开源网络代理在复杂任务上的信息检索能力有限，或缺乏透明的实现。作者认为主要挑战在于缺乏用于信息检索的具有挑战性的数据。

Method: 本文引入了WebExplorer，一种系统性的数据生成方法，利用基于模型的探索和迭代的“长到短”查询演变，创建需要多步推理和复杂网络导航的查询-答案对。利用这些高质量数据，通过监督微调（SFT）和强化学习（RL）相结合的方式，成功开发了先进的网络代理WebExplorer-8B。

Result: WebExplorer-8B支持128K上下文长度和多达100个工具调用轮次，实现了长程问题解决。在多种信息检索基准测试中，WebExplorer-8B在其规模上取得了当前最佳性能。作为一个8B模型，它在RL训练后平均能够进行16轮搜索，在BrowseComp-en/zh上实现了比WebSailor-72B更高的准确性，并在WebWalkerQA和FRAMES上达到了100B参数以下模型中的最佳性能。此外，模型在HLE基准测试上也表现出强大的泛化能力。

Conclusion: 研究结果表明，本文提出的方法是实现长程网络代理的实用途径。

Abstract: The paradigm of Large Language Models (LLMs) has increasingly shifted toward
agentic applications, where web browsing capabilities are fundamental for
retrieving information from diverse online sources. However, existing
open-source web agents either demonstrate limited information-seeking abilities
on complex tasks or lack transparent implementations. In this work, we identify
that the key challenge lies in the scarcity of challenging data for information
seeking. To address this limitation, we introduce WebExplorer: a systematic
data generation approach using model-based exploration and iterative,
long-to-short query evolution. This method creates challenging query-answer
pairs that require multi-step reasoning and complex web navigation. By
leveraging our curated high-quality dataset, we successfully develop advanced
web agent WebExplorer-8B through supervised fine-tuning followed by
reinforcement learning. Our model supports 128K context length and up to 100
tool calling turns, enabling long-horizon problem solving. Across diverse
information-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art
performance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able
to effectively search over an average of 16 turns after RL training, achieving
higher accuracy than WebSailor-72B on BrowseComp-en/zh and attaining the best
performance among models up to 100B parameters on WebWalkerQA and FRAMES.
Beyond these information-seeking tasks, our model also achieves strong
generalization on the HLE benchmark even though it is only trained on
knowledge-intensive QA data. These results highlight our approach as a
practical path toward long-horizon web agents.

</details>


### [256] [Crown, Frame, Reverse: Layer-Wise Scaling Variants for LLM Pre-Training](https://arxiv.org/abs/2509.06518)
*Andrei Baroian,Kasper Notebomer*

Main category: cs.CL

TL;DR: 本研究引入了三种层间缩放（LWS）变体（Framed、Reverse、Crown），通过重新分配FFN宽度和注意力头，在相同参数预算下，使Transformer模型在预训练阶段表现优于传统的均匀层基线。


<details>
  <summary>Details</summary>
Motivation: 传统的基于Transformer的语言模型使用统一（各向同性）的层大小，但它们忽略了不同深度层可以扮演的多样功能角色及其计算容量需求。

Method: 在层间缩放（LWS）和剪枝文献的基础上，我们引入了三种新的LWS变体：Framed、Reverse和Crown。这些变体通过两点或三点线性插值在预训练阶段重新分配FFN宽度和注意力头。我们对LWS及其变体进行了首次系统的消融研究，在1.8亿参数、50亿token的固定预算下进行训练。

Result: 所有模型都收敛到相似的损失，并且与同等成本的各向同性基线相比，性能更好，同时训练吞吐量没有显著下降。

Conclusion: 这项工作代表了预训练层间架构设计空间的第一步。未来的工作应将实验扩展到更大数量级的token和参数，以充分评估其潜力。

Abstract: Transformer-based language models traditionally use uniform (isotropic) layer
sizes, yet they ignore the diverse functional roles that different depths can
play and their computational capacity needs. Building on Layer-Wise Scaling
(LWS) and pruning literature, we introduce three new LWS variants - Framed,
Reverse, and Crown - that redistribute FFN widths and attention heads via two
or three-point linear interpolation in the pre-training stage. We present the
first systematic ablation of LWS and its variants, on a fixed budget of 180M
parameters, trained on 5B tokens. All models converge to similar losses and
achieve better performance compared to an equal-cost isotropic baseline,
without a substantial decrease in training throughput. This work represents an
initial step into the design space of layer-wise architectures for
pre-training, but future work should scale experiments to orders of magnitude
more tokens and parameters to fully assess their potential.

</details>


### [257] [LAMDAS: LLM as an Implicit Classifier for Domain-specific Data Selection](https://arxiv.org/abs/2509.06524)
*Jian Wu,Hang Yu,Bingchang Liu,Wenjie Yang,Peng Di,Jianguo Li,Yue Zhang*

Main category: cs.CL

TL;DR: LAMDAS是一种新颖的领域特定数据选择方法，它利用LLM作为隐式分类器，将数据选择重构为单类分类问题，从而在数据稀缺的情况下，以更少的数据实现了超越全数据训练和现有SOTA基线的性能，并达到了最佳的性能与效率平衡。


<details>
  <summary>Details</summary>
Motivation: 将大型语言模型（LLMs）适应特定领域时，面临高质量人工标注数据稀缺的瓶颈。直接使用大量未经检查的数据会引入噪声并降低性能。因此，需要一种既准确又高效的战略性数据选择方法，但现有方法（如基于相似性和直接优化的方法）难以同时实现这两个目标。

Method: 本文提出了LAMDAS（LLM As an iMplicit classifier for domain-specific DAta Selection），该方法利用预训练的LLM本身作为隐式分类器，从而避免了显式特征工程和计算密集型优化过程。LAMDAS将数据选择重新定义为单类分类问题，通过一个小型参考数据集来识别“属于”目标领域的数据。

Result: 实验结果表明，LAMDAS不仅使用一小部分数据就能超越全数据训练的性能，而且在各种场景下都优于九种最先进（SOTA）的基线方法。此外，与所有评估的基线相比，LAMDAS在性能提升和计算效率之间实现了最令人信服的平衡。

Conclusion: LAMDAS提供了一种有效且高效的领域特定数据选择方案，解决了高质量数据稀缺的问题，显著提升了LLM在特定领域适应的性能，并在计算效率上优于现有方法。

Abstract: Adapting large language models (LLMs) to specific domains often faces a
critical bottleneck: the scarcity of high-quality, human-curated data. While
large volumes of unchecked data are readily available, indiscriminately using
them for fine-tuning risks introducing noise and degrading performance.
Strategic data selection is thus crucial, requiring a method that is both
accurate and efficient. Existing approaches, categorized as similarity-based
and direct optimization methods, struggle to simultaneously achieve these
goals. In this paper, we introduce LAMDAS (LLM As an iMplicit classifier for
domain-specific DAta Selection), a novel approach that leverages the
pre-trained LLM itself as an implicit classifier, thereby bypassing explicit
feature engineering and computationally intensive optimization process. LAMDAS
reframes data selection as a one-class classification problem, identifying
candidate data that "belongs" to the target domain defined by a small reference
dataset. Extensive experimental results demonstrate that LAMDAS not only
exceeds the performance of full-data training using a fraction of the data but
also outperforms nine state-of-the-art (SOTA) baselines under various
scenarios. Furthermore, LAMDAS achieves the most compelling balance between
performance gains and computational efficiency compared to all evaluated
baselines.

</details>


### [258] [SLiNT: Structure-aware Language Model with Injection and Contrastive Training for Knowledge Graph Completion](https://arxiv.org/abs/2509.06531)
*Mengxue Yang,Chun Yang,Jiaqi Zhu,Jiafan Li,Jingqi Zhang,Yuyang Li,Ying Li*

Main category: cs.CL

TL;DR: SLiNT是一个模块化框架，通过结构感知注入和对比训练，将知识图谱的结构上下文融入冻结的LLM中，以解决链接预测中的结构稀疏性和语义模糊性问题，并在主流数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 知识图谱链接预测需要整合结构信息和语义上下文。虽然大型语言模型（LLM）具有强大的生成推理能力，但它们对结构信号的利用有限，导致在不完整或零样本设置下出现结构稀疏性和语义模糊性，这促使研究者寻找方法来增强LLM的结构感知能力。

Method: 本文提出了SLiNT（Structure-aware Language model with Injection and coNtrastive Training），一个模块化框架，通过轻量级LoRA适配将知识图谱导出的结构上下文注入到冻结的LLM骨干中。具体方法包括：1) 结构引导邻域增强（SGNE），用于检索伪邻居以丰富稀疏实体并缓解上下文缺失；2) 动态硬对比学习（DHCL），通过插值硬正例和负例引入细粒度监督，解决实体级模糊性；3) 梯度解耦双注入（GDDI），在保留LLM核心参数的同时进行token级的结构感知干预。

Result: 在WN18RR和FB15k-237数据集上的实验表明，SLiNT与基于嵌入和基于生成的基线模型相比，取得了卓越或具有竞争力的性能。

Conclusion: SLiNT的实验结果证明了结构感知表示学习对于可扩展知识图谱补全的有效性，成功地将结构上下文融入LLM以解决链接预测中的挑战。

Abstract: Link prediction in knowledge graphs requires integrating structural
information and semantic context to infer missing entities. While large
language models offer strong generative reasoning capabilities, their limited
exploitation of structural signals often results in structural sparsity and
semantic ambiguity, especially under incomplete or zero-shot settings. To
address these challenges, we propose SLiNT (Structure-aware Language model with
Injection and coNtrastive Training), a modular framework that injects
knowledge-graph-derived structural context into a frozen LLM backbone with
lightweight LoRA-based adaptation for robust link prediction. Specifically,
Structure-Guided Neighborhood Enhancement (SGNE) retrieves pseudo-neighbors to
enrich sparse entities and mitigate missing context; Dynamic Hard Contrastive
Learning (DHCL) introduces fine-grained supervision by interpolating hard
positives and negatives to resolve entity-level ambiguity; and
Gradient-Decoupled Dual Injection (GDDI) performs token-level structure-aware
intervention while preserving the core LLM parameters. Experiments on WN18RR
and FB15k-237 show that SLiNT achieves superior or competitive performance
compared with both embedding-based and generation-based baselines,
demonstrating the effectiveness of structure-aware representation learning for
scalable knowledge graph completion.

</details>


### [259] [HAVE: Head-Adaptive Gating and ValuE Calibration for Hallucination Mitigation in Large Language Models](https://arxiv.org/abs/2509.06596)
*Xin Tong,Zhi Lin,Jingya Wang,Bo Jin*

Main category: cs.CL

TL;DR: 本文提出了HAVE（Head-Adaptive Gating and ValuE Calibration）框架，通过自适应门控和价值校准，在不进行微调的情况下，有效减少大型语言模型在检索增强或长上下文生成中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在检索增强或长上下文生成中即使存在相关证据也常产生幻觉。这源于两个问题：注意力头的重要性被视为与输入无关，以及原始注意力权重未能准确反映每个token的真实贡献。

Method: HAVE框架通过引入“头自适应门控”（对注意力头进行实例级软重加权）和“价值校准”（用价值向量的幅度增强注意力以近似回写贡献）来解决上述问题。这两个模块共同构建与模型更新对齐的token级证据，并通过轻量级不确定性缩放策略将其与LM分布融合。HAVE无需微调，在单次前向传播中运行，且不含参数。

Result: 实验结果表明，HAVE在多个问答基准和LLM家族中持续减少幻觉，并优于包括DAGCD在内的强基线，且开销适中。该框架透明、可复现，并可与现有LLM无缝集成。

Conclusion: HAVE是一个高效、透明、可复现且广泛适用的解码框架，能够与现有LLM集成，从而在实际应用中推进可信赖的生成。

Abstract: Large Language Models (LLMs) often produce hallucinations in
retrieval-augmented or long-context generation, even when relevant evidence is
present. This stems from two issues: head importance is treated as
input-agnostic, and raw attention weights poorly reflect each token's true
contribution. We present HAVE (Head-Adaptive Gating and ValuE Calibration), a
parameter-free decoding framework that directly addresses both challenges. HAVE
introduces head-adaptive gating, which performs instance-level soft reweighing
of attention heads, and value calibration, which augments attention with the
magnitude of value vectors to approximate write-back contribution. Together,
these modules construct token-level evidence aligned with model updates and
fuse it with the LM distribution through a lightweight uncertainty-scaled
policy. HAVE requires no finetuning and operates in a single forward pass,
making it efficient and broadly applicable. Experiments across multiple QA
benchmarks and LLM families demonstrate that HAVE consistently reduces
hallucinations and outperforms strong baselines, including DAGCD, with modest
overhead. The framework is transparent, reproducible, and readily integrates
with off-the-shelf LLMs, advancing trustworthy generation in real-world
settings.

</details>


### [260] [Guided Decoding and Its Critical Role in Retrieval-Augmented Generation](https://arxiv.org/abs/2509.06631)
*Özgür Uğur,Musa Yılmaz,Esra Şavirdi,Özay Ezerceli,Mahmut El Huseyni,Selva Taş,Reyhan Bayraktar*

Main category: cs.CL

TL;DR: 本研究比较了RAG系统中三种引导解码方法（Outlines, XGrammar, LM Format Enforcer）在不同多轮提示设置下的表现，评估其成功率、幻觉率和输出质量，揭示了多轮交互对引导解码的影响及性能差异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）应用日益广泛，需要结构化且可靠的响应。检索增强生成（RAG）系统面临的关键挑战是确保输出符合预期格式并最大限度地减少幻觉。

Method: 研究通过比较Outlines、XGrammar和LM Format Enforcer这三种引导解码方法在0轮、1轮和2轮多轮提示设置下的表现，评估了它们在RAG系统中的作用。评估指标包括成功率、幻觉率和输出质量。

Result: 研究结果揭示了多轮交互如何影响引导解码，发现了意想不到的性能变化，这些发现可以为特定用例的方法选择提供信息。

Conclusion: 这项工作增进了对RAG系统中结构化输出生成的理解，为LLM部署提供了理论见解和实践指导。

Abstract: The integration of Large Language Models (LLMs) into various applications has
driven the need for structured and reliable responses. A key challenge in
Retrieval-Augmented Generation (RAG) systems is ensuring that outputs align
with expected formats while minimizing hallucinations. This study examines the
role of guided decoding in RAG systems, comparing three methods, Outlines,
XGrammar, and LM Format Enforcer, across different multi-turn prompting setups
(0-turn, 1-turn, and 2-turn). By evaluating success rates, hallucination rates,
and output quality, we provide insights into their performance and
applicability. Our findings reveal how multi-turn interactions influence guided
decoding, uncovering unexpected performance variations that can inform method
selection for specific use cases. This work advances the understanding of
structured output generation in RAG systems, offering both theoretical insights
and practical guidance for LLM deployment.

</details>


### [261] [Modelling Intertextuality with N-gram Embeddings](https://arxiv.org/abs/2509.06637)
*Yi Xing*

Main category: cs.CL

TL;DR: 本文提出了一种基于n-gram嵌入比较的定量互文性模型，以实现可扩展分析并揭示文本间的网络结构。


<details>
  <summary>Details</summary>
Motivation: 互文性是文学研究的核心概念，但现有分析方法可能缺乏可扩展性和网络洞察力。

Method: 通过对两个文本中n-gram嵌入进行成对比较，并取其平均值作为整体互文性度量。该方法能够进行可扩展分析并支持网络构建。

Result: 在四篇已知互文性程度的文本上验证了方法的有效性，并在267篇多样化文本上测试了其效率。网络分析进一步揭示了中心性和社区结构。

Conclusion: 该方法成功地捕捉并量化了互文关系，为大规模文学分析提供了有效工具。

Abstract: Intertextuality is a central tenet in literary studies. It refers to the
intricate links between literary texts that are created by various types of
references. This paper proposes a new quantitative model of intertextuality to
enable scalable analysis and network-based insights: perform pairwise
comparisons of the embeddings of n-grams from two texts and average their
results as the overall intertextuality. Validation on four texts with known
degrees of intertextuality, alongside a scalability test on 267 diverse texts,
demonstrates the method's effectiveness and efficiency. Network analysis
further reveals centrality and community structures, affirming the approach's
success in capturing and quantifying intertextual relationships.

</details>


### [262] [Domain-Aware RAG: MoL-Enhanced RL for Efficient Training and Scalable Retrieval](https://arxiv.org/abs/2509.06650)
*Hao Lin,Peitong Xie,Jingxue Chen,Jie Lin,Qingkun Tang,Qianchun Lu*

Main category: cs.CL

TL;DR: MoLER是一种领域感知的RAG方法，通过MoL增强的强化学习优化检索的粗排阶段，平衡领域知识与查询增强，实现领先的检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有的粗排优化方法难以平衡领域特定知识学习与查询增强，导致检索性能不佳，特别是在RAG系统中。

Method: MoLER采用两阶段流水线：1. 持续预训练(CPT)阶段，使用混合损失(MoL)平衡领域知识和通用语言能力。2. 强化学习(RL)阶段，利用群组相对策略优化(GRPO)优化查询和段落生成以最大化文档召回率。其关键创新是多查询单段落晚期融合(MSLF)策略，减少RL训练开销，并通过多查询多段落晚期融合(MMLF)实现可扩展推理。

Result: MoLER在基准数据集上取得了最先进的性能，显著优于基线方法。

Conclusion: MoLER弥合了RAG系统中的知识鸿沟，使得在专业领域中能够进行鲁棒且可扩展的检索。

Abstract: Retrieval-Augmented Generation (RAG) systems rely heavily on the retrieval
stage, particularly the coarse-ranking process. Existing coarse-ranking
optimization approaches often struggle to balance domain-specific knowledge
learning with query enhencement, resulting in suboptimal retrieval performance.
To address this challenge, we propose MoLER, a domain-aware RAG method that
uses MoL-Enhanced Reinforcement Learning to optimize retrieval. MoLER has a
two-stage pipeline: a continual pre-training (CPT) phase using a Mixture of
Losses (MoL) to balance domain-specific knowledge with general language
capabilities, and a reinforcement learning (RL) phase leveraging Group Relative
Policy Optimization (GRPO) to optimize query and passage generation for
maximizing document recall. A key innovation is our Multi-query Single-passage
Late Fusion (MSLF) strategy, which reduces computational overhead during RL
training while maintaining scalable inference via Multi-query Multi-passage
Late Fusion (MMLF). Extensive experiments on benchmark datasets show that MoLER
achieves state-of-the-art performance, significantly outperforming baseline
methods. MoLER bridges the knowledge gap in RAG systems, enabling robust and
scalable retrieval in specialized domains.

</details>


### [263] [IntrEx: A Dataset for Modeling Engagement in Educational Conversations](https://arxiv.org/abs/2509.06652)
*Xingwei Tan,Mahathi Parvatham,Chiara Gambi,Gabriele Pergola*

Main category: cs.CL

TL;DR: 本研究引入了首个大规模师生对话语料库IntrEx，用于标注对话的趣味性和预期趣味性，并发现经此数据集微调的LLM在预测人类趣味性判断方面优于大型专有模型，同时分析了语言和认知因素对对话参与度的影响。


<details>
  <summary>Details</summary>
Motivation: 在第二语言习得中，保持学习者在教育对话中的兴趣是一个挑战。虽然现有研究探索了教育文本的趣味性，但对于驱动对话参与度的语言特征知之甚少。本研究旨在填补这一空白。

Method: 构建了IntrEx数据集，该数据集基于Teacher-Student Chatroom Corpus (TSCC)，并增加了序列级标注，以捕捉兴趣在长对话中的演变。采用超过100名第二语言学习者的严格标注过程，使用受RLHF启发的比较评分方法。研究还微调了大型语言模型（7B/8B参数）以预测人类的趣味性判断，并分析了具体性、可理解性（可读性）和反馈等语言和认知因素对教育对话参与度的影响。

Result: 创建了IntrEx数据集，这是第一个在师生互动中标注趣味性和预期趣味性的大规模数据集。结果表明，在趣味性评分上微调的LLM（7B/8B参数）在预测人类趣味性判断方面优于GPT-4o等大型专有模型。此外，研究还分析了具体性、可理解性和反馈等语言和认知因素如何影响教育对话中的参与度。

Conclusion: 专门的数据集在教育环境中建模参与度方面具有巨大潜力。经特定数据集微调的LLM能够更准确地预测对话趣味性，超越大型通用模型。语言和认知因素对教育对话的参与度有显著影响。

Abstract: Engagement and motivation are crucial for second-language acquisition, yet
maintaining learner interest in educational conversations remains a challenge.
While prior research has explored what makes educational texts interesting,
still little is known about the linguistic features that drive engagement in
conversations. To address this gap, we introduce IntrEx, the first large
dataset annotated for interestingness and expected interestingness in
teacher-student interactions. Built upon the Teacher-Student Chatroom Corpus
(TSCC), IntrEx extends prior work by incorporating sequence-level annotations,
allowing for the study of engagement beyond isolated turns to capture how
interest evolves over extended dialogues. We employ a rigorous annotation
process with over 100 second-language learners, using a comparison-based rating
approach inspired by reinforcement learning from human feedback (RLHF) to
improve agreement. We investigate whether large language models (LLMs) can
predict human interestingness judgments. We find that LLMs (7B/8B parameters)
fine-tuned on interestingness ratings outperform larger proprietary models like
GPT-4o, demonstrating the potential for specialised datasets to model
engagement in educational settings. Finally, we analyze how linguistic and
cognitive factors, such as concreteness, comprehensibility (readability), and
uptake, influence engagement in educational dialogues.

</details>


### [264] [ParCzech4Speech: A New Speech Corpus Derived from Czech Parliamentary Data](https://arxiv.org/abs/2509.06675)
*Vladislav Stankov,Matyáš Kopp,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本文介绍了 ParCzech4Speech 1.0，这是一个针对语音建模任务的捷克语语音语料库，包含2,695小时数据，通过处理捷克议会演讲录音及其官方文本，并使用 WhisperX 和 Wav2Vec 2.0 进行了自动化音频-文本对齐，提供了更高可靠性的对齐数据。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为语音建模任务提供一个更大、更高质量的捷克语语音语料库，以改进现有 ParCzech 3.0 版本的语音识别效果，并解决其数据量和对齐可靠性的不足。

Method: 研究方法是将捷克议会演讲的录音与官方文本结合，使用 WhisperX 和 Wav2Vec 2.0 工具进行自动化音频-文本对齐。通过改进处理流程，提取了更多数据并提高了对齐可靠性。语料库提供了三种灵活的变体：句子分割型、未分割型和原始对齐型。

Result: 主要成果是发布了 ParCzech4Speech 1.0 语料库，其中最大变体包含 2,695 小时的语音数据。该语料库相比 ParCzech 3.0 版本，提取了更多数据并具有更高的对齐可靠性。所有变体都保留了原始元数据，并在 CC-BY 许可下发布，可在 LINDAT 存储库和 Hugging Face 上获取。

Conclusion: ParCzech4Speech 1.0 是一个大规模、高质量的捷克语语音语料库，通过改进的数据处理和对齐技术，为自动语音识别、语音合成及其他相关语音建模任务提供了宝贵的资源，并具有高度的灵活性和可用性。

Abstract: We introduce ParCzech4Speech 1.0, a processed version of the ParCzech 4.0
corpus, targeted at speech modeling tasks with the largest variant containing
2,695 hours. We combined the sound recordings of the Czech parliamentary
speeches with the official transcripts. The recordings were processed with
WhisperX and Wav2Vec 2.0 to extract automated audio-text alignment. Our
processing pipeline improves upon the ParCzech 3.0 speech recognition version
by extracting more data with higher alignment reliability. The dataset is
offered in three flexible variants: (1) sentence-segmented for automatic speech
recognition and speech synthesis tasks with clean boundaries, (2) unsegmented
preserving original utterance flow across sentences, and (3) a raw-alignment
for further custom refinement for other possible tasks. All variants maintain
the original metadata and are released under a permissive CC-BY license. The
dataset is available in the LINDAT repository, with the sentence-segmented and
unsegmented variants additionally available on Hugging Face.

</details>


### [265] [Will Annotators Disagree? Identifying Subjectivity in Value-Laden Arguments](https://arxiv.org/abs/2509.06704)
*Amir Homayounirad,Enrico Liscio,Tong Wang,Catholijn M. Jonker,Luciano C. Siebert*

Main category: cs.CL

TL;DR: 本研究探索了识别论点中人类价值观主观性的方法，发现直接识别主观性显著优于通过价值观预测推断主观性，并能提高模型性能，有助于更细致的标注过程。


<details>
  <summary>Details</summary>
Motivation: 在主观性至关重要的任务中，将多重标注聚合成单一真实标签可能会掩盖标注者分歧中的宝贵见解。因此，有必要探索识别论点中人类价值观主观性的方法。

Method: 本研究评估了两种主要方法：1. 通过价值观预测推断主观性；2. 直接识别主观性。此外，还探索了结合对比损失与二元交叉熵损失的效果。

Result: 实验表明，直接识别主观性显著提高了标记主观论点的模型性能。结合对比损失与二元交叉熵损失并未提高性能，但减少了对每个标签主观性的依赖。

Conclusion: 本研究提出的方法可以帮助识别个体可能不同解读的论点，从而促进更细致入微的标注过程。

Abstract: Aggregating multiple annotations into a single ground truth label may hide
valuable insights into annotator disagreement, particularly in tasks where
subjectivity plays a crucial role. In this work, we explore methods for
identifying subjectivity in recognizing the human values that motivate
arguments. We evaluate two main approaches: inferring subjectivity through
value prediction vs. directly identifying subjectivity. Our experiments show
that direct subjectivity identification significantly improves the model
performance of flagging subjective arguments. Furthermore, combining
contrastive loss with binary cross-entropy loss does not improve performance
but reduces the dependency on per-label subjectivity. Our proposed methods can
help identify arguments that individuals may interpret differently, fostering a
more nuanced annotation process.

</details>


### [266] [Anchoring Refusal Direction: Mitigating Safety Risks in Tuning via Projection Constraint](https://arxiv.org/abs/2509.06795)
*Yanrui Du,Fenglei Fan,Sendong Zhao,Jiawei Cao,Qika Lin,Kai He,Ting Liu,Bing Qin,Mengling Feng*

Main category: cs.CL

TL;DR: 指令微调（IFT）会损害大型语言模型（LLMs）的安全性，特别是拒绝恶意指令的能力。本研究提出ProCon方法，通过正则化隐藏状态在拒绝方向（r-direction）上的投影来稳定r-direction，从而在保持任务性能的同时显著提升LLMs的安全性。


<details>
  <summary>Details</summary>
Motivation: 指令微调（IFT）虽然能增强LLMs的能力，但会严重损害其安全性，尤其是在拒绝恶意指令方面的能力。现有研究发现LLMs内部存在控制拒绝行为的拒绝方向（r-direction），而本研究发现r-direction在训练过程中会发生漂移，这是导致相关安全风险的原因之一。

Method: 本研究提出了ProCon方法，引入了一个投影约束损失项，用于正则化每个训练样本的隐藏状态在拒绝方向（r-direction）上的投影幅度，以减轻r-direction的漂移。为了克服性能障碍，ProCon进一步引入了热启动策略（强调早期阶段的强约束）并拓宽数据分布以强化约束信号，从而形成增强型ProCon方法。

Result: ProCon方法能有效缓解拒绝方向漂移和相关的安全风险。增强型ProCon在各种数据集、场景和LLMs上，显著减轻了IFT带来的安全风险，同时保持了任务性能的提升。与强基线相比，该方法始终提供卓越的整体性能。分析表明，ProCon有助于在训练期间稳定r-direction。

Conclusion: ProCon方法通过稳定LLMs内部的拒绝方向，有效解决了指令微调带来的安全风险，同时保持了模型的任务性能。这种基于可解释性的内部机制探索为未来的LLM安全研究奠定了坚实基础。

Abstract: Instruction Fine-Tuning (IFT) has been widely adopted as an effective
post-training strategy to enhance various abilities of Large Language Models
(LLMs). However, prior studies have shown that IFT can significantly compromise
LLMs' safety, particularly their ability to refuse malicious instructions,
raising significant concerns. Recent research into the internal mechanisms of
LLMs has identified the refusal direction (r-direction) in the hidden states,
which plays a pivotal role in governing refusal behavior. Building on this
insight, our study reveals that the r-direction tends to drift during training,
which we identify as one of the causes of the associated safety risks. To
mitigate such drift, our proposed ProCon method introduces a
projection-constrained loss term that regularizes the projection magnitude of
each training sample's hidden state onto the r-direction. Our initial analysis
shows that applying an appropriate constraint can effectively mitigate the
refusal direction drift and associated safety risks, but remains limited by
overall performance barriers. To overcome this barrier, informed by our
observation of early-stage sharp drift and a data-driven perspective, we
introduce a warm-up strategy that emphasizes early-stage strong constraints and
broaden the data distribution to strengthen constraint signals, leading to an
enhanced ProCon method. Experimental results under various datasets, scenarios,
and LLMs demonstrate that our method can significantly mitigate safety risks
posed by IFT while preserving task performance gains. Even compared with strong
baselines, our method consistently delivers superior overall performance.
Crucially, our analysis indicates that ProCon can contribute to stabilizing the
r-direction during training, while such an interpretability-driven exploration
of LLMs' internal mechanisms lays a solid foundation for future safety
research.

</details>


### [267] [MachineLearningLM: Continued Pretraining Language Models on Millions of Synthetic Tabular Prediction Tasks Scales In-Context ML](https://arxiv.org/abs/2509.06806)
*Haoyu Dong,Pengkun Zhang,Mingzhe Lu,Yanzhen Shen,Guolin Ke*

Main category: cs.CL

TL;DR: 该研究引入了MachineLearningLM，一个通过持续预训练使大型语言模型（LLM）具备强大上下文机器学习（ML）能力，同时保留其通用知识和推理能力的框架。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM拥有广泛的世界知识和强大的通用推理能力，但它们在标准ML任务中难以从大量上下文示例中学习（即，通过纯粹的上下文学习而非梯度下降来利用多样本演示）。

Method: 通过持续预训练实现，具体方法包括：1) 从数百万结构因果模型（SCM）中合成ML任务，涵盖多达1024个样本。2) 使用随机森林教师模型，将基于树的决策策略蒸馏到LLM中，以增强数值建模的鲁棒性。3) 采用令牌高效的提示，将每个上下文窗口的示例数量增加3到6倍，并通过批处理推理实现高达50倍的摊销吞吐量。4) 在Qwen-2.5-7B-Instruct模型上使用LoRA（rank 8）进行微调。

Result: MachineLearningLM（Qwen-2.5-7B-Instruct与LoRA rank 8）在金融、物理、生物和医疗保健领域的域外表格分类任务上，平均比强大的LLM基线（如GPT-5-mini）高出约15%。它展现出显著的多样本扩展定律：当上下文演示从8个增加到1024个时，准确率单调上升。在没有特定任务训练的情况下，它在数百个样本上达到了随机森林级别的准确率。同时，其通用聊天能力（包括知识和推理）得到保留，在MMLU上达到75.4%。

Conclusion: MachineLearningLM成功地为通用LLM提供了强大的上下文ML能力，使其能够有效利用大量上下文示例进行学习，同时保持了其原有的通用知识和推理能力，为更广泛的聊天工作流程提供了支持。

Abstract: Large language models (LLMs) possess broad world knowledge and strong
general-purpose reasoning ability, yet they struggle to learn from many
in-context examples on standard machine learning (ML) tasks, that is, to
leverage many-shot demonstrations purely via in-context learning (ICL) without
gradient descent. We introduce MachineLearningLM, a portable
continued-pretraining framework that equips a general-purpose LLM with robust
in-context ML capability while preserving its general knowledge and reasoning
for broader chat workflows.
  Our pretraining procedure synthesizes ML tasks from millions of structural
causal models (SCMs), spanning shot counts up to 1,024. We begin with a
random-forest teacher, distilling tree-based decision strategies into the LLM
to strengthen robustness in numerical modeling. All tasks are serialized with a
token-efficient prompt, enabling 3x to 6x more examples per context window and
delivering up to 50x amortized throughput via batch inference.
  Despite a modest setup (Qwen-2.5-7B-Instruct with LoRA rank 8),
MachineLearningLM outperforms strong LLM baselines (e.g., GPT-5-mini) by an
average of about 15% on out-of-distribution tabular classification across
finance, physics, biology, and healthcare domains. It exhibits a striking
many-shot scaling law: accuracy increases monotonically as in-context
demonstrations grow from 8 to 1,024. Without any task-specific training, it
attains random-forest-level accuracy across hundreds of shots. General chat
capabilities, including knowledge and reasoning, are preserved: it achieves
75.4% on MMLU.

</details>


### [268] [MoGU V2: Toward a Higher Pareto Frontier Between Model Usability and Security](https://arxiv.org/abs/2509.06807)
*Yanrui Du,Fenglei Fan,Sendong Zhao,Jiawei Cao,Ting Liu,Bing Qin*

Main category: cs.CL

TL;DR: 本文提出了MoGU_v2框架，通过动态分配权重和优化路由器嵌入，在不牺牲可用性的前提下显著提升了大型语言模型（LLMs）的安全性，并能有效应对指令微调带来的风险。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在人类生活中日益普及，其安全性成为关键问题，特别是如何保持对恶意指令的无害响应。现有安全方法常导致保守的、拒绝式响应，损害了实用性。因此，研究动机是如何在LLM的可用性和安全性之间推进帕累托前沿，而非在两者之间进行权衡。

Method: 首先提出MoGU框架，通过层内路由器感知隐藏状态动态分配权重，以平衡安全优化和可用性优化变体的贡献。为克服MoGU的参数冗余和性能瓶颈，进一步提出MoGU_v2框架。MoGU_v2将路由器仅嵌入到编码高度可分类安全特征的层中，并在路由器优化期间激活主干模块以实现双向适应。此外，面对指令微调引入的风险，MoGU_v2采用简单的数据混合策略来恢复安全性。

Result: MoGU_v2在各种系列LLMs（包括主流LLMs、资源受限的设备端LLMs和推理LLMs）上均表现出强大的适应性和稳定的改进。同时，即使面对指令微调带来的风险，MoGU_v2也能通过简单的数据混合策略轻松恢复安全性，且不损害任务性能增益。

Conclusion: MoGU_v2是一个强大且多功能的解决方案，能够有效缓解现实世界应用中LLMs的安全风险，同时保持其实用性，实现了可用性与安全性的双赢。

Abstract: As Large Language Models (LLMs) increasingly permeate human life, their
security has emerged as a critical concern, particularly their ability to
maintain harmless responses to malicious instructions. Although extensive
methods have improved LLMs' security, they often lead to conservative,
rejection-oriented responses that compromise practical usability. This presents
a key challenge: how to advance the Pareto frontier between LLMs' usability and
security, rather than necessitate a trade-off between them. To address this, we
propose the MoGU framework, in which the intra-layer router dynamically
allocates weights by sensing hidden states, thereby balancing the contributions
of security-optimized and usability-optimized variants. Despite its initial
potential, the MoGU framework faces limitations such as parameter redundancy
and performance bottlenecks. To overcome these, we further propose an improved
MoGU_v2 framework that establishes a tighter coupling between the routers and
hidden states. In MoGU_v2, routers are embedded only in layers encoding highly
classifiable security features, and backbone modules are activated during
router optimization to enable bidirectional adaptation. MoGU_V2 exhibits strong
adaptability and stable improvements across various series of LLMs, including
mainstream LLMs serving as brains in various applications, on-device LLMs
optimized for resource-constrained scenarios, and reasoning LLMs tailored for
user interpretability. Meanwhile, even facing risks introduced by Instruction
Fine-tuning, MoGU_v2 can easily restore security without compromising the task
performance gains via a simple data-mix strategy. These comprehensive
improvements highlight MoGU_V2 as a robust and versatile solution for
mitigating security risks in real-world applications.

</details>


### [269] [Saturation-Driven Dataset Generation for LLM Mathematical Reasoning in the TPTP Ecosystem](https://arxiv.org/abs/2509.06809)
*Valentin Quesnel,Damien Sileo*

Main category: cs.CL

TL;DR: 本文提出了一种利用自动化定理证明器（E-prover）从TPTP公理库生成大规模、逻辑有效的数学推理数据集的方法，以解决LLMs在数学推理方面高质量数据稀缺的问题，并诊断出当前LLMs在深层结构化推理上的明显弱点。


<details>
  <summary>Details</summary>
Motivation: 高质量、逻辑严谨的数据稀缺是阻碍大型语言模型（LLMs）在数学推理方面取得进展的关键瓶颈。现有的方法要么依赖易出错的LLMs，要么需要复杂的证明助手语法。

Method: 该研究利用E-prover的饱和推理能力，基于TPTP公理库推导出大量保证有效的定理。其数据生成流程包括：饱和公理、筛选“有趣”的定理，然后生成任务。整个过程中不涉及LLMs，从而消除了事实错误。生成的纯符号数据被转化为三种难度受控的挑战：蕴涵验证、前提选择和证明重构。

Result: 对前沿模型进行的零样本实验表明，LLMs在需要深层、结构化推理的任务上表现明显崩溃，揭示了其在这方面的明确弱点。

Conclusion: 该框架提供了一个诊断工具来衡量LLMs在深层推理上的差距，同时也是一个可扩展的符号训练数据来源，以解决这一问题。所有代码和数据均已公开。

Abstract: The scarcity of high-quality, logically sound data is a critical bottleneck
for advancing the mathematical reasoning of Large Language Models (LLMs). Our
work confronts this challenge by turning decades of automated theorem proving
research into a scalable data engine. Rather than relying on error-prone LLMs
or complex proof-assistant syntax like Lean and Isabelle, our framework
leverages E-prover's saturation capabilities on the vast TPTP axiom library to
derive a massive, guaranteed-valid corpus of theorems. Our pipeline is
principled and simple: saturate axioms, filter for "interesting" theorems, and
generate tasks. With no LLMs in the loop, we eliminate factual errors by
construction. This purely symbolic data is then transformed into three
difficulty-controlled challenges: entailment verification, premise selection,
and proof reconstruction. Our zero-shot experiments on frontier models reveal a
clear weakness: performance collapses on tasks requiring deep, structural
reasoning. Our framework provides both the diagnostic tool to measure this gap
and a scalable source of symbolic training data to address it. We make the code
and data publicly available.
  https://github.com/sileod/reasoning_core
https://hf.co/datasets/reasoning-core/rc1

</details>


### [270] [A Comparative Benchmark of Large Language Models for Labelling Wind Turbine Maintenance Logs](https://arxiv.org/abs/2509.06813)
*Max Malyi,Jonathan Shek,Alasdair McDonald,Andre Biscaya*

Main category: cs.CL

TL;DR: 本研究提出了一个基准测试框架，用于评估大型语言模型（LLMs）在风力涡轮机维护日志分类任务上的表现，并建议采用人机协作（Human-in-the-Loop）系统以提高运营维护数据质量。


<details>
  <summary>Details</summary>
Motivation: 有效的运营和维护（O&M）对于降低风电的度电成本（LCOE）至关重要，但涡轮机维护日志的非结构化自由文本性质，严重阻碍了自动化分析。

Method: 开发了一个新颖且可复现的框架，用于基准测试LLMs在分类复杂工业记录（风力涡轮机维护日志）方面的能力。该框架已开源。系统评估了多种最先进的专有和开源LLMs，从可靠性、操作效率和模型校准等方面进行了评估。

Result: 量化了LLMs的清晰性能等级，识别出与基准标准高度一致且具有可靠、良好校准置信度分数的顶级模型。分类性能高度依赖于任务的语义模糊性，所有模型在客观组件识别上比在解释性维护操作上表现出更高的一致性。没有模型达到完美准确性，且校准差异显著。

Conclusion: 鉴于没有模型能达到完美精度且校准差异巨大，最有效和负责任的近期应用是人机协作系统，其中LLMs作为强大助手，加速并标准化人类专家的数据标注工作，从而提高O&M数据质量和下游可靠性分析。

Abstract: Effective Operation and Maintenance (O&M) is critical to reducing the
Levelised Cost of Energy (LCOE) from wind power, yet the unstructured,
free-text nature of turbine maintenance logs presents a significant barrier to
automated analysis. Our paper addresses this by presenting a novel and
reproducible framework for benchmarking Large Language Models (LLMs) on the
task of classifying these complex industrial records. To promote transparency
and encourage further research, this framework has been made publicly available
as an open-source tool. We systematically evaluate a diverse suite of
state-of-the-art proprietary and open-source LLMs, providing a foundational
assessment of their trade-offs in reliability, operational efficiency, and
model calibration. Our results quantify a clear performance hierarchy,
identifying top models that exhibit high alignment with a benchmark standard
and trustworthy, well-calibrated confidence scores. We also demonstrate that
classification performance is highly dependent on the task's semantic
ambiguity, with all models showing higher consensus on objective component
identification than on interpretive maintenance actions. Given that no model
achieves perfect accuracy and that calibration varies dramatically, we conclude
that the most effective and responsible near-term application is a
Human-in-the-Loop system, where LLMs act as a powerful assistant to accelerate
and standardise data labelling for human experts, thereby enhancing O&M data
quality and downstream reliability analysis.

</details>


### [271] [COMPACT: Common-token Optimized Model Pruning Across Channels and Tokens](https://arxiv.org/abs/2509.06836)
*Eugene Kwek,Wenpeng Yin*

Main category: cs.CL

TL;DR: COMPACT提出了一种联合剪枝方法，通过修剪罕见词汇和FFN中间通道来提高大型语言模型的效率，同时保持标准Transformer架构，实现了最先进的性能和显著的资源节省。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在内存、延迟和服务成本方面的效率对于边缘部署、交互式应用和规模化推理至关重要。现有的剪枝方法存在局限性：宽度剪枝通常会破坏标准Transformer布局或需要自定义推理代码，而深度剪枝会移除整个层并可能导致准确率急剧下降。

Method: 本文提出了COMPACT方法，该方法联合进行剪枝：(i) 剪枝罕见词汇以缩小嵌入/解嵌入层；(ii) 使用常见词元加权激活来剪枝FFN中间通道，从而将重要性与剪枝后的词元分布对齐。COMPACT具有部署友好（保持标准Transformer架构）、规模自适应（可在词汇与FFN剪枝之间权衡）、免训练且剪枝时间具有竞争力等优点。

Result: 在Qwen、LLaMA和Gemma系列（0.5B-70B）模型上的实验表明，在相似或更高的剪枝率下，COMPACT实现了最先进的下游任务性能，并显著减少了参数、GPU内存和端到端延迟，同时带来了强大的内存节省和吞吐量提升。

Conclusion: COMPACT是一种有效且高效的LLM剪枝方法，它结合了深度和宽度剪枝的优点，解决了现有方法的局限性，实现了部署友好、高性能和显著资源节省，是实现大规模可持续推理的关键技术。

Abstract: Making LLMs more efficient in memory, latency, and serving cost is crucial
for edge deployment, interactive applications, and sustainable inference at
scale. Pruning is a key technique toward this goal. However, prior pruning
methods are limited: width pruning often breaks the standard transformer layout
or requires custom inference code, while depth pruning removes entire layers
and can cause abrupt accuracy drops. In this work, we propose COMPACT, which
jointly (i) prunes rare vocabulary to shrink embedding/unembedding and (ii)
prunes FFN intermediate channels using common-token-weighted activations,
aligning importance with the post-pruning token distribution. COMPACT enjoys
merits of both depth and width pruning, such as: deployment-friendliness (keeps
a standard transformer architecture), scale-adaptivity (trade off vocab vs. FFN
pruning), training-free operation with competitive pruning time, and strong
memory savings alongside throughput gains. Experiments across Qwen, LLaMA, and
Gemma families (0.5B-70B) show state-of-the-art downstream task performance at
similar or higher pruning ratios, with substantial reductions in parameters,
GPU memory, and end-to-end latency.

</details>


### [272] [EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language Models](https://arxiv.org/abs/2509.06838)
*Mohammad Reza Mirbagheri,Mohammad Mahdi Mirkamali,Zahra Motoshaker Arani,Ali Javeri,Amir Mahdi Sadeghzadeh,Rasool Jalili*

Main category: cs.CL

TL;DR: 本研究引入了EPT（波斯语可信度评估）指标，这是一个文化敏感的基准，用于评估大型语言模型（LLMs）在真实性、安全性、公平性、鲁棒性、隐私和伦理对齐六个方面的可信度。通过对多个主流模型进行评估，发现安全性方面存在显著缺陷，并提供了关于模型与波斯伦理文化价值观对齐的见解。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）性能卓越，但确保其可信度（包括准确性、伦理、文化和社会价值观）仍是关键挑战。开发负责任的AI系统需要仔细调整训练数据和基于文化的评估标准。本研究旨在解决LLMs在波斯文化背景下的可信度评估问题。

Method: 研究引入了EPT（波斯语可信度评估）指标，该指标专门设计用于评估LLMs在真实性、安全性、公平性、鲁棒性、隐私和伦理对齐六个关键方面的可信度。研究人员策划了一个带标签的数据集，并使用自动化LLM评估和人工评估两种方式，对包括ChatGPT、Claude、DeepSeek、Gemini、Grok、LLaMA、Mistral和Qwen在内的多个主流模型进行了性能评估。

Result: 评估结果揭示了模型在安全性维度上存在显著缺陷，凸显了对这一关键行为方面进行重点关注的紧迫性。此外，研究结果为这些模型与波斯伦理文化价值观的对齐提供了宝贵见解，并指出了在推进可信赖和文化负责任的AI方面存在的关键差距和机遇。

Conclusion: 本研究强调了LLMs安全性维度亟需关注，并为理解和改进LLMs在波斯伦理文化背景下的可信度和文化对齐提供了重要发现。所构建的数据集已公开，为未来研究奠定了基础，以开发更可信赖和文化负责任的AI系统。

Abstract: Large Language Models (LLMs), trained on extensive datasets using advanced
deep learning architectures, have demonstrated remarkable performance across a
wide range of language tasks, becoming a cornerstone of modern AI technologies.
However, ensuring their trustworthiness remains a critical challenge, as
reliability is essential not only for accurate performance but also for
upholding ethical, cultural, and social values. Careful alignment of training
data and culturally grounded evaluation criteria are vital for developing
responsible AI systems. In this study, we introduce the EPT (Evaluation of
Persian Trustworthiness) metric, a culturally informed benchmark specifically
designed to assess the trustworthiness of LLMs across six key aspects:
truthfulness, safety, fairness, robustness, privacy, and ethical alignment. We
curated a labeled dataset and evaluated the performance of several leading
models - including ChatGPT, Claude, DeepSeek, Gemini, Grok, LLaMA, Mistral, and
Qwen - using both automated LLM-based and human assessments. Our results reveal
significant deficiencies in the safety dimension, underscoring the urgent need
for focused attention on this critical aspect of model behavior. Furthermore,
our findings offer valuable insights into the alignment of these models with
Persian ethical-cultural values and highlight critical gaps and opportunities
for advancing trustworthy and culturally responsible AI. The dataset is
publicly available at: https://github.com/Rezamirbagheri110/EPT-Benchmark.

</details>


### [273] [The Majority is not always right: RL training for solution aggregation](https://arxiv.org/abs/2509.06870)
*Wenting Zhao,Pranjal Aggarwal,Swarnadeep Saha,Asli Celikyilmaz,Jason Weston,Ilia Kulikov*

Main category: cs.CL

TL;DR: 本文提出了一种名为 AggLM 的方法，通过强化学习训练一个聚合器模型，将多个候选解决方案审查、协调并综合成最终正确答案，以提升大型语言模型在推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）在推理任务上通过生成多个独立解决方案并进行选择或聚合来提升性能，但多数方法（如简单多数投票或奖励模型排序）效果有限。

Method: 研究者将聚合视为一种显式的推理技能进行学习。他们训练了一个聚合器模型（AggLM），利用可验证的奖励进行强化学习，以审查、协调和综合候选解决方案。关键在于平衡简单和困难的训练样本，使模型既能恢复少数但正确的答案，也能处理简单的多数正确答案。

Result: 实验结果表明，AggLM 在多个基准测试中优于强大的基于规则和奖励模型的基线方法。此外，它能有效地泛化到来自不同模型的解决方案（包括比训练数据中更强的模型），同时比大量解决方案的多数投票法所需令牌少得多。

Conclusion: 通过强化学习将聚合作为一种显式推理技能进行训练，并精心平衡训练样本，可以显著提升大型语言模型在推理任务上的性能，且具有良好的泛化能力和更高的效率。

Abstract: Scaling up test-time compute, by generating multiple independent solutions
and selecting or aggregating among them, has become a central paradigm for
improving large language models (LLMs) on challenging reasoning tasks. While
most prior work relies on simple majority voting or reward model ranking to
aggregate solutions, these approaches may only yield limited benefits. In this
work, we propose to learn aggregation as an explicit reasoning skill: given a
set of candidate solutions, we train an aggregator model to review, reconcile,
and synthesize a final, correct answer using reinforcement learning from
verifiable rewards. A key ingredient is careful balancing of easy and hard
training examples, allowing the model to learn both to recover
minority-but-correct answers as well as easy majority-correct answers.
Empirically, we find our method, AggLM, outperforms both strong rule-based and
reward-model baselines, across multiple benchmarks. Furthermore, it generalizes
effectively to solutions from differing models, including stronger ones than
contained in the training data, all while requiring substantially fewer tokens
than majority voting with larger numbers of solutions.

</details>


### [274] [UNH at CheckThat! 2025: Fine-tuning Vs Prompting in Claim Extraction](https://arxiv.org/abs/2509.06883)
*Joe Wilder,Nikhil Kadapala,Benji Xu,Mohammed Alsaadi,Aiden Parsons,Mitchell Rogers,Palash Agarwal,Adam Hassick,Laura Dietz*

Main category: cs.CL

TL;DR: 该研究探索了多种大语言模型（LLM）提示和微调方法，旨在从社交媒体文本中提取值得核查的声明，发现微调FLAN-T5模型在METEOR分数上表现最佳，但其他方法有时能提取出更高质量的声明。


<details>
  <summary>Details</summary>
Motivation: 参与CheckThat! 任务2英语，目标是从社交媒体段落中提取值得核查的声明。

Method: 采用了多种提示方法（包括少样本提示和上下文学习）和不同LLM家族的微调方法。

Result: 微调FLAN-T5模型取得了最佳的METEOR分数。然而，观察到即使METEOR分数较低，其他方法有时也能提取出更高质量的声明。

Conclusion: 微调FLAN-T5在自动评估指标（如METEOR）上表现出色，但声明的实际质量评估可能需要更全面的考量，而不仅仅是单一指标。

Abstract: We participate in CheckThat! Task 2 English and explore various methods of
prompting and in-context learning, including few-shot prompting and fine-tuning
with different LLM families, with the goal of extracting check-worthy claims
from social media passages. Our best METEOR score is achieved by fine-tuning a
FLAN-T5 model. However, we observe that higher-quality claims can sometimes be
extracted using other methods, even when their METEOR scores are lower.

</details>


### [275] [mmBERT: A Modern Multilingual Encoder with Annealed Language Learning](https://arxiv.org/abs/2509.06888)
*Marc Marone,Orion Weller,William Fleshman,Eugene Yang,Dawn Lawrie,Benjamin Van Durme*

Main category: cs.CL

TL;DR: 本文介绍了mmBERT，一个在超过1800种语言的3T多语言文本上预训练的编码器模型。它通过新颖的训练策略（如逆掩码比率和逆温度采样比率，并在衰减阶段加入低资源语言）显著提升了分类和检索任务的性能，超越了前代模型，并在低资源语言上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有研究中，编码器模型，特别是多语言编码器模型，缺乏最新进展和关注。

Method: 引入了mmBERT，一个在3T多语言文本（涵盖1800多种语言）上预训练的编码器模型。采用了创新的训练元素，包括逆掩码比率调度和逆温度采样比率。在训练的衰减阶段才加入超过1700种低资源语言，以最大化其性能增益。

Result: 在衰减阶段加入低资源语言显著提升了模型性能。mmBERT在分类任务上达到了与OpenAI的o3和Google的Gemini 2.5 Pro等模型相似的性能。在分类和检索任务上，mmBERT显著优于前代模型，无论是在高资源还是低资源语言上。

Conclusion: mmBERT是一个高效的多语言编码器模型，通过创新的训练策略，在大量语言（包括低资源语言）上取得了卓越的分类和检索性能，超越了现有模型。

Abstract: Encoder-only languages models are frequently used for a variety of standard
machine learning tasks, including classification and retrieval. However, there
has been a lack of recent research for encoder models, especially with respect
to multilingual models. We introduce mmBERT, an encoder-only language model
pretrained on 3T tokens of multilingual text in over 1800 languages. To build
mmBERT we introduce several novel elements, including an inverse mask ratio
schedule and an inverse temperature sampling ratio. We add over 1700
low-resource languages to the data mix only during the decay phase, showing
that it boosts performance dramatically and maximizes the gains from the
relatively small amount of training data. Despite only including these
low-resource languages in the short decay phase we achieve similar
classification performance to models like OpenAI's o3 and Google's Gemini 2.5
Pro. Overall, we show that mmBERT significantly outperforms the previous
generation of models on classification and retrieval tasks -- on both high and
low-resource languages.

</details>


### [276] [Proof-Carrying Numbers (PCN): A Protocol for Trustworthy Numeric Answers from LLMs via Claim Verification](https://arxiv.org/abs/2509.06902)
*Aivin V. Solatorio*

Main category: cs.CL

TL;DR: 针对大型语言模型（LLM）的数字幻觉问题，本文提出了“携带证明的数字”（PCN）协议，通过在呈现层进行机械验证来强制实现数字保真度，确保只有经过验证的数字才被标记为可信。


<details>
  <summary>Details</summary>
Motivation: LLM作为随机系统可能生成与现有数据不符的数字（数字幻觉）。现有的保障措施（如检索增强生成、引用、不确定性估计）虽提高了透明度，但无法保证数字的准确性，仍可能显示伪造或引用错误的数值。

Method: PCN是一种呈现层协议。数字片段被作为“声明绑定令牌”发出，并与结构化声明关联。一个验证器（位于渲染器而非模型中）根据预设策略（如精确相等、四舍五入、别名、带限定符的容差）检查每个令牌。只有经过声明检查的数字才被标记为已验证，否则默认为未验证。这种分离防止了欺骗并保证了故障关闭行为。

Result: 本文对PCN进行了形式化，并证明了其健全性、在诚实令牌下的完备性、故障关闭行为以及在策略细化下的单调性。PCN轻量级且与模型无关，可无缝集成到现有应用中，并可通过加密承诺进行扩展。

Conclusion: 通过将验证作为显示前的强制步骤，PCN为对数字敏感的设置建立了一个简单的契约：信任必须通过证明来赢得，而缺乏标记则表示不确定性，从而有效解决了LLM的数字幻觉问题。

Abstract: Large Language Models (LLMs) as stochastic systems may generate numbers that
deviate from available data, a failure known as \emph{numeric hallucination}.
Existing safeguards -- retrieval-augmented generation, citations, and
uncertainty estimation -- improve transparency but cannot guarantee fidelity:
fabricated or misquoted values may still be displayed as if correct. We propose
\textbf{Proof-Carrying Numbers (PCN)}, a presentation-layer protocol that
enforces numeric fidelity through mechanical verification. Under PCN, numeric
spans are emitted as \emph{claim-bound tokens} tied to structured claims, and a
verifier checks each token under a declared policy (e.g., exact equality,
rounding, aliases, or tolerance with qualifiers). Crucially, PCN places
verification in the \emph{renderer}, not the model: only claim-checked numbers
are marked as verified, and all others default to unverified. This separation
prevents spoofing and guarantees fail-closed behavior. We formalize PCN and
prove soundness, completeness under honest tokens, fail-closed behavior, and
monotonicity under policy refinement. PCN is lightweight and model-agnostic,
integrates seamlessly into existing applications, and can be extended with
cryptographic commitments. By enforcing verification as a mandatory step before
display, PCN establishes a simple contract for numerically sensitive settings:
\emph{trust is earned only by proof}, while the absence of a mark communicates
uncertainty.

</details>


### [277] [Beyond Two-Stage Training: Cooperative SFT and RL for LLM Reasoning](https://arxiv.org/abs/2509.06948)
*Liang Chen,Xueting Han,Li Shen,Jing Bai,Kam-Fai Wong*

Main category: cs.CL

TL;DR: 针对大型语言模型（LLM）推理能力的强化学习（RL）存在效率问题，现有SFT与RL的两阶段方法交互有限。本研究提出一种双层优化方法，通过让SFT目标依赖于最优RL策略，实现SFT对RL的元学习指导，从而提升了LLM推理的有效性和效率。


<details>
  <summary>Details</summary>
Motivation: 强化学习在激励LLM推理能力方面有效，但其试错性质导致效率低下。常见的监督微调（SFT）作为RL热身阶段的两阶段方法是解耦的，限制了SFT和RL之间的交互，从而制约了整体效果。

Method: 本研究提出了一种新颖的双层优化方法，以促进SFT和RL训练范式之间的更好协作。通过将SFT目标条件化于最优RL策略，使SFT能够元学习如何指导RL的优化过程。训练期间，下层执行RL更新并同时接收SFT监督，上层则明确最大化合作收益（联合SFT-RL训练相对于单独RL的性能优势）。

Result: 在五个推理基准上的实证评估表明，该方法始终优于基线，并在有效性和效率之间实现了更好的平衡。

Conclusion: 所提出的双层优化方法通过更好地整合SFT和RL，有效解决了LLM推理训练中的效率和效果问题，实现了卓越的性能和效率平衡。

Abstract: Reinforcement learning (RL) has proven effective in incentivizing the
reasoning abilities of large language models (LLMs), but suffers from severe
efficiency challenges due to its trial-and-error nature. While the common
practice employs supervised fine-tuning (SFT) as a warm-up stage for RL, this
decoupled two-stage approach limits interaction between SFT and RL, thereby
constraining overall effectiveness. This study introduces a novel method for
learning reasoning models that employs bilevel optimization to facilitate
better cooperation between these training paradigms. By conditioning the SFT
objective on the optimal RL policy, our approach enables SFT to meta-learn how
to guide RL's optimization process. During training, the lower level performs
RL updates while simultaneously receiving SFT supervision, and the upper level
explicitly maximizes the cooperative gain-the performance advantage of joint
SFT-RL training over RL alone. Empirical evaluations on five reasoning
benchmarks demonstrate that our method consistently outperforms baselines and
achieves a better balance between effectiveness and efficiency.

</details>


### [278] [Revolutionizing Reinforcement Learning Framework for Diffusion Large Language Models](https://arxiv.org/abs/2509.06949)
*Yinjie Wang,Ling Yang,Bowen Li,Ye Tian,Ke Shen,Mengdi Wang*

Main category: cs.CL

TL;DR: 本文提出TraceRL，一个轨迹感知强化学习框架，用于扩散语言模型（DLM）的后训练。该框架通过整合偏好推理轨迹和扩散值模型，显著提升了DLM在复杂数学和编程任务上的推理性能，并导出了SOTA的TraDo系列DLM，其性能超越了同等规模的自回归模型。同时，还发布了一个全面的开源框架。


<details>
  <summary>Details</summary>
Motivation: 研究旨在改进扩散语言模型（DLM）的后训练过程，通过引入偏好推理轨迹来提高其在复杂推理任务上的表现，解决其跨架构适用性问题，并最终促进DLM的可复现研究和实际应用。

Method: 本文提出TraceRL框架，它是一种轨迹感知强化学习方法，将偏好的推理轨迹融入DLM的后训练中。该框架配备了一个基于扩散的值模型以增强训练稳定性，并可将特定块模型适应到更大的块以提高采样灵活性。此外，研究还通过课程学习开发了首个长CoT DLM。

Result: 1. 在复杂数学和编程任务上显著提高了推理性能。2. 导出了SOTA的TraDo扩散语言模型系列。3. TraDo-4B-Instruct在复杂数学推理任务上持续优于7B规模的自回归（AR）模型。4. TraDo-8B-Instruct在数学推理基准上，相对于Qwen2.5-7B-Instruct准确率提高6.1%，相对于Llama3.1-8B-Instruct提高51.3%。5. 导出了首个长CoT DLM，在MATH500上比Qwen2.5-7B-Instruct相对准确率提高18.1%。6. 发布了一个全面的开源框架，用于构建、训练和部署跨不同架构的扩散LLM，该框架集成了加速KV-cache技术和推理引擎，并包含多种监督微调和强化学习方法的实现。

Conclusion: TraceRL是一个有效且通用的强化学习框架，能够显著提升扩散语言模型在复杂推理任务上的性能，并成功开发出超越现有自回归模型SOTA的TraDo系列DLM。该研究还通过开源框架促进了DLM领域的未来研究和实际应用。

Abstract: We propose TraceRL, a trajectory-aware reinforcement learning framework for
diffusion language models (DLMs) that incorporates preferred inference
trajectory into post-training, and is applicable across different
architectures. Equipped with a diffusion-based value model that enhances
training stability, we demonstrate improved reasoning performance on complex
math and coding tasks. Besides, it can also be applied to adapt block-specific
models to larger blocks, which improves sampling flexibility. Employing
TraceRL, we derive a series of state-of-the-art diffusion language models,
namely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still
consistently outperforms them across complex math reasoning tasks.
TraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over
Qwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical
reasoning benchmarks. Through curriculum learning, we also derive the first
long-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1%
relative accuracy gain. To facilitate reproducible research and practical
applications, we release a comprehensive open-source framework for building,
training, and deploying diffusion LLMs across diverse architectures. The
framework integrates accelerated KV-cache techniques and inference engines for
both inference and reinforcement learning, and includes implementations of
various supervised fine-tuning and RL methods for mathematics, coding, and
general tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL

</details>


### [279] [On the Same Wavelength? Evaluating Pragmatic Reasoning in Language Models across Broad Concepts](https://arxiv.org/abs/2509.06952)
*Linlu Qiu,Cedegao E. Zhang,Joshua B. Tenenbaum,Yoon Kim,Roger P. Levy*

Main category: cs.CL

TL;DR: 本研究提出一个基于Wavelength游戏的评估框架，用于测试语言模型（LMs）的语用推理能力。结果显示，最先进的LMs在语言理解方面表现出色，但在语言生成方面，通过思维链（CoT）和理性言语行为（RSA）方法可以显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型越来越多地被用作对话代理，理解它们的语用推理能力变得至关重要。语用学（即在语境中对沟通目标和规范的推理）塑造了语言使用。

Method: 研究采用了一个源自流行沟通游戏Wavelength的评估框架，该框架允许对广泛概念进行细粒度沟通。研究人员使用直接提示和思维链（CoT）提示，在语言理解和语言生成两方面评估了一系列语言模型。此外，他们还探索了将贝叶斯语用推理融入LM推理的理性言语行为（RSA）方法。

Result: 最先进的语言模型（而非小型模型）在语言理解方面表现出强大的性能，达到了与人类相似的准确性，并且即使没有CoT提示或RSA也与人类判断高度相关。在语言生成方面，CoT提示优于直接提示，而使用RSA则比这两种方法都提供了显著的改进。

Conclusion: 本研究有助于识别语言模型语用推理能力的优势和局限性，并证明了通过RSA提升这些能力的潜力。这为未来理解语言模型和人类在概念表征、语言理解和社会推理方面的研究开辟了新途径。

Abstract: Language use is shaped by pragmatics -- i.e., reasoning about communicative
goals and norms in context. As language models (LMs) are increasingly used as
conversational agents, it becomes ever more important to understand their
pragmatic reasoning abilities. We propose an evaluation framework derived from
Wavelength, a popular communication game where a speaker and a listener
communicate about a broad range of concepts in a granular manner. We study a
range of LMs on both language comprehension and language production using
direct and Chain-of-Thought (CoT) prompting, and further explore a Rational
Speech Act (RSA) approach to incorporating Bayesian pragmatic reasoning into LM
inference. We find that state-of-the-art LMs, but not smaller ones, achieve
strong performance on language comprehension, obtaining similar-to-human
accuracy and exhibiting high correlations with human judgments even without CoT
prompting or RSA. On language production, CoT can outperform direct prompting,
and using RSA provides significant improvements over both approaches. Our study
helps identify the strengths and limitations in LMs' pragmatic reasoning
abilities and demonstrates the potential for improving them with RSA, opening
up future avenues for understanding conceptual representation, language
understanding, and social reasoning in LMs and humans.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [280] [ManipDreamer3D : Synthesizing Plausible Robotic Manipulation Video with Occupancy-aware 3D Trajectory](https://arxiv.org/abs/2509.05314)
*Ying Li,Xiaobao Wei,Xiaowei Chi,Yuming Li,Zhongyu Zhao,Hao Wang,Ningning Ma,Ming Lu,Shanghang Zhang*

Main category: cs.RO

TL;DR: ManipDreamer3D是一个新颖的框架，它结合3D轨迹规划和扩散模型，从输入图像和文本指令生成逼真的3D感知机器人操作视频，显著减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 机器人操作领域面临数据稀缺的挑战，现有方法主要依赖2D轨迹，存在3D空间模糊性问题。

Method: ManipDreamer3D首先从输入图像重建3D占用图，然后计算优化的3D末端执行器轨迹（最小化路径长度并避免碰撞）。接着，它利用潜在编辑技术，结合初始图像潜在表示和优化后的3D轨迹，条件化一个专门训练的轨迹到视频扩散模型，以生成机器人抓取和放置视频。

Result: 该方法生成具有自主规划的合理3D轨迹的机器人视频，显著减少了人工干预需求。实验结果表明，与现有方法相比，其视觉质量更优越。

Conclusion: ManipDreamer3D通过生成高质量、自主规划的3D感知机器人操作视频，有效解决了数据稀缺和3D模糊性问题。

Abstract: Data scarcity continues to be a major challenge in the field of robotic
manipulation. Although diffusion models provide a promising solution for
generating robotic manipulation videos, existing methods largely depend on 2D
trajectories, which inherently face issues with 3D spatial ambiguity. In this
work, we present a novel framework named ManipDreamer3D for generating
plausible 3D-aware robotic manipulation videos from the input image and the
text instruction. Our method combines 3D trajectory planning with a
reconstructed 3D occupancy map created from a third-person perspective, along
with a novel trajectory-to-video diffusion model. Specifically, ManipDreamer3D
first reconstructs the 3D occupancy representation from the input image and
then computes an optimized 3D end-effector trajectory, minimizing path length
while avoiding collisions. Next, we employ a latent editing technique to create
video sequences from the initial image latent and the optimized 3D trajectory.
This process conditions our specially trained trajectory-to-video diffusion
model to produce robotic pick-and-place videos. Our method generates robotic
videos with autonomously planned plausible 3D trajectories, significantly
reducing human intervention requirements. Experimental results demonstrate
superior visual quality compared to existing methods.

</details>


### [281] [Evaluation of Large Language Models for Anomaly Detection in Autonomous Vehicles](https://arxiv.org/abs/2509.05315)
*Petros Loukas,David Bassir,Savvas Chatzichristofis,Angelos Amanatiadis*

Main category: cs.RO

TL;DR: 本文评估了大型语言模型（LLMs）在真实世界自动驾驶边缘案例中的潜力，特别是作为异常检测器，结合开放词汇目标检测和提示工程。


<details>
  <summary>Details</summary>
Motivation: LLMs在自动驾驶领域的应用潜力尚未在真实世界边缘案例中得到充分评估，现有研究多限于合成或手动驾驶数据集，缺乏对当前感知和规划算法在这些案例中表现的精确了解。

Method: 提出了一种结合开放词汇目标检测器、提示工程和大型语言模型上下文推理的架构。在真实世界的边缘案例上评估了几个最先进的模型。

Result: 提供了针对真实边缘案例的定性比较结果，并讨论了LLMs作为自动驾驶车辆中异常检测器的潜在应用前景。

Conclusion: LLMs在处理自动驾驶车辆的真实世界边缘案例方面表现出潜力，可作为有效的异常检测器。

Abstract: The rapid evolution of large language models (LLMs) has pushed their
boundaries to many applications in various domains. Recently, the research
community has started to evaluate their potential adoption in autonomous
vehicles and especially as complementary modules in the perception and planning
software stacks. However, their evaluation is limited in synthetic datasets or
manually driving datasets without the ground truth knowledge and more
precisely, how the current perception and planning algorithms would perform in
the cases under evaluation. For this reason, this work evaluates LLMs on
real-world edge cases where current autonomous vehicles have been proven to
fail. The proposed architecture consists of an open vocabulary object detector
coupled with prompt engineering and large language model contextual reasoning.
We evaluate several state-of-the-art models against real edge cases and provide
qualitative comparison results along with a discussion on the findings for the
potential application of LLMs as anomaly detectors in autonomous vehicles.

</details>


### [282] [Plantbot: Integrating Plant and Robot through LLM Modular Agent Networks](https://arxiv.org/abs/2509.05338)
*Atsushi Masumori,Norihiro Maruyama,Itsuki Doi,johnsmith,Hiroki Sato,Takashi Ikegami*

Main category: cs.RO

TL;DR: 本文介绍了Plantbot，一种将活体植物与移动机器人通过大型语言模型（LLM）模块网络连接的混合生命体。它利用自然语言作为通用协议，实现生物和人工领域间的无缝交互，使其成为一个能自主适应环境的具身智能体。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索生物与人工系统之间的新型交互模式，并提出一种新型的人工生命模型，其中去中心化的LLM模块协调能够实现生物与人工系统之间的新颖互动。

Method: Plantbot采用混合生命体架构，将活体植物与移动机器人连接。通过LLM模块网络（负责感知、视觉、对话、行动），这些模块异步运行并利用自然语言进行通信。自然语言作为通用协议，将多模态数据（土壤湿度、温度、视觉上下文）转换为语言信息，以协调系统行为。

Result: Plantbot能够将植物状态转化为机器人行动，在传感器-运动循环中建立规范性，赋予其能动性。通过LLM介导的通信，Plantbot表现为一个具身、自适应的智能体，能够自主响应环境条件。

Conclusion: 该方法为人工生命提供了一种新模型，其中去中心化的LLM模块协调能够实现生物与人工系统之间的新颖互动，为未来生物与人工系统融合提供了可能性。

Abstract: We introduce Plantbot, a hybrid lifeform that connects a living plant with a
mobile robot through a network of large language model (LLM) modules. Each
module - responsible for sensing, vision, dialogue, or action - operates
asynchronously and communicates via natural language, enabling seamless
interaction across biological and artificial domains. This architecture
leverages the capacity of LLMs to serve as hybrid interfaces, where natural
language functions as a universal protocol, translating multimodal data (soil
moisture, temperature, visual context) into linguistic messages that coordinate
system behaviors. The integrated network transforms plant states into robotic
actions, installing normativity essential for agency within the sensor-motor
loop. By combining biological and robotic elements through LLM-mediated
communication, Plantbot behaves as an embodied, adaptive agent capable of
responding autonomously to environmental conditions. This approach suggests
possibilities for a new model of artificial life, where decentralized, LLM
modules coordination enable novel interactions between biological and
artificial systems.

</details>


### [283] [INF-3DP: Implicit Neural Fields for Collision-Free Multi-Axis 3D Printing](https://arxiv.org/abs/2509.05345)
*Jiasheng Qu,Zhuo Huang,Dezhao Guo,Hailin Sun,Aoran Lyu,Chengkai Dai,Yeung Yam,Guoxin Fang*

Main category: cs.RO

TL;DR: 该研究引入了一个基于隐式神经场（INFs）的通用、可扩展计算框架，用于多轴3D打印。它统一了刀具路径生成和全局无碰撞运动规划的所有阶段，实现了高达两个数量级的速度提升，并显著减少了路径点到表面的误差。


<details>
  <summary>Details</summary>
Motivation: 现有的多轴3D打印方法在刀具路径生成、无碰撞运动规划的统一性、效率和精度方面存在局限性。研究旨在开发一个能够整合这些阶段、提高速度并减少误差的计算框架。

Method: 该方法基于隐式神经场（INFs）。输入模型被表示为符号距离场（SDFs），制造目标（如无支撑打印、表面光洁度）直接编码在隐式引导场的优化中。通过隐式场插值生成外壳和填充路径，并对打印序列和多轴运动进行连续四元数场的联合优化。该连续公式将演变的打印对象构建为时变SDF，支持在基于INF的运动规划中进行可微分的全局碰撞处理。

Result: 与基于显式表示的方法相比，所提出的INF-3DP框架实现了高达两个数量级的速度提升，并显著降低了路径点到表面的误差。该框架在多样复杂的模型上得到了验证，并通过机器人辅助多轴系统的物理制造实验证明了其效率。

Conclusion: 该研究提供了一个通用且可扩展的基于隐式神经场的多轴3D打印计算框架，成功统一了刀具路径生成和无碰撞运动规划。它在效率和精度方面取得了显著提升，为复杂模型的打印提供了有效的解决方案。

Abstract: We introduce a general, scalable computational framework for multi-axis 3D
printing based on implicit neural fields (INFs) that unifies all stages of
toolpath generation and global collision-free motion planning. In our pipeline,
input models are represented as signed distance fields, with fabrication
objectives such as support-free printing, surface finish quality, and extrusion
control being directly encoded in the optimization of an implicit guidance
field. This unified approach enables toolpath optimization across both surface
and interior domains, allowing shell and infill paths to be generated via
implicit field interpolation. The printing sequence and multi-axis motion are
then jointly optimized over a continuous quaternion field. Our continuous
formulation constructs the evolving printing object as a time-varying SDF,
supporting differentiable global collision handling throughout INF-based motion
planning. Compared to explicit-representation-based methods, INF-3DP achieves
up to two orders of magnitude speedup and significantly reduces
waypoint-to-surface error. We validate our framework on diverse, complex models
and demonstrate its efficiency with physical fabrication experiments using a
robot-assisted multi-axis system.

</details>


### [284] [Human-LLM Synergy in Context-Aware Adaptive Architecture for Scalable Drone Swarm Operation](https://arxiv.org/abs/2509.05355)
*Ahmed R. Sadik,Muhammad Ashfaq,Niko Mäkitalo,Tommi Mikkonen*

Main category: cs.RO

TL;DR: 本文提出了一种基于大型语言模型（LLM）的无人机蜂群自适应架构，能根据任务参数动态选择集中式、分层式或全息式架构，以优化灾难响应任务中的可扩展性、能效和连接性。


<details>
  <summary>Details</summary>
Motivation: 在灾难响应任务中，自主无人机蜂群需要灵活、可扩展且鲁棒的协调系统。传统的固定架构难以应对动态和不可预测的环境，导致能源消耗和连接效率低下。

Method: 本文提出了一种无人机蜂群自适应架构，利用大型语言模型（LLM）根据实时任务参数（如任务复杂性、蜂群规模和通信稳定性）动态选择最优的集中式、分层式或全息式架构。

Result: 广泛的模拟结果表明，该自适应架构在可扩展性、能源效率和连接性方面均优于传统的静态模型。

Conclusion: 该方法为现实世界中的灾难响应场景提供了一种可扩展、自适应且有弹性的解决方案，展示了其巨大的潜力。

Abstract: The deployment of autonomous drone swarms in disaster response missions
necessitates the development of flexible, scalable, and robust coordination
systems. Traditional fixed architectures struggle to cope with dynamic and
unpredictable environments, leading to inefficiencies in energy consumption and
connectivity. This paper addresses this gap by proposing an adaptive
architecture for drone swarms, leveraging a Large Language Model to dynamically
select the optimal architecture as centralized, hierarchical, or holonic based
on real time mission parameters such as task complexity, swarm size, and
communication stability. Our system addresses the challenges of scalability,
adaptability, and robustness,ensuring efficient energy consumption and
maintaining connectivity under varying conditions. Extensive simulations
demonstrate that our adaptive architecture outperforms traditional static
models in terms of scalability, energy efficiency, and connectivity. These
results highlight the potential of our approach to provide a scalable,
adaptable, and resilient solution for real world disaster response scenarios.

</details>


### [285] [Spiking Neural Networks for Continuous Control via End-to-End Model-Based Learning](https://arxiv.org/abs/2509.05356)
*Justus Huebotter,Pablo Lanillos,Marcel van Gerven,Serge Thill*

Main category: cs.RO

TL;DR: 本文展示了脉冲神经网络（SNNs）如何通过端到端训练，实现对多自由度机械臂在连续环境中的精确运动控制，解决了SNNs在连续运动控制应用上的限制。


<details>
  <summary>Details</summary>
Motivation: 尽管脉冲神经网络在分类任务上取得了进展，但其在连续运动控制领域的应用仍然有限。研究旨在探索SNNs在连续机器人运动控制中的潜力。

Method: 研究采用了一种预测控制框架，结合了漏积分-放电（Leaky Integrate-and-Fire）动力学和替代梯度（surrogate gradients），共同优化了一个用于动力学预测的前向模型和一个用于目标导向动作的策略网络。该方法在平面2D抓取任务和模拟的6自由度Franka Emika Panda机器人上进行了评估。

Result: 结果表明，脉冲神经网络能够实现稳定的训练和精确的扭矩控制，证明了其在高维运动任务中的可行性。广泛的消融研究强调了初始化、可学习时间常数和正则化在训练动态中的作用。

Conclusion: 研究得出结论，虽然脉冲神经网络可以实现稳定有效的控制，但循环脉冲网络对超参数设置仍然高度敏感，这强调了原则性设计选择的重要性。

Abstract: Despite recent progress in training spiking neural networks (SNNs) for
classification, their application to continuous motor control remains limited.
Here, we demonstrate that fully spiking architectures can be trained end-to-end
to control robotic arms with multiple degrees of freedom in continuous
environments. Our predictive-control framework combines Leaky
Integrate-and-Fire dynamics with surrogate gradients, jointly optimizing a
forward model for dynamics prediction and a policy network for goal-directed
action. We evaluate this approach on both a planar 2D reaching task and a
simulated 6-DOF Franka Emika Panda robot. Results show that SNNs can achieve
stable training and accurate torque control, establishing their viability for
high-dimensional motor tasks. An extensive ablation study highlights the role
of initialization, learnable time constants, and regularization in shaping
training dynamics. We conclude that while stable and effective control can be
achieved, recurrent spiking networks remain highly sensitive to hyperparameter
settings, underscoring the importance of principled design choices.

</details>


### [286] [Long-Horizon Visual Imitation Learning via Plan and Code Reflection](https://arxiv.org/abs/2509.05368)
*Quan Chen,Chenrui Shi,Qi Chen,Yuwei Wu,Zhi Gao,Xintong Zhang,Rui Gao,Kun Wu,Yunde Jia*

Main category: cs.RO

TL;DR: 本文提出了一种新的智能体框架，包含计划和代码生成及对应的反思模块，以解决长周期视觉模仿学习中复杂动作序列的挑战，并引入了LongVILBench基准来系统评估，结果显示其框架在此类任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 长周期演示中复杂的动作序列给视觉模仿学习带来了显著挑战，尤其是在理解动作的时间关系和物体之间的空间关系方面。

Method: 本文提出了一个包含两个专用反思模块的智能体框架：计划生成模块产生初始动作序列，然后由计划反思模块验证其时间连贯性和空间对齐性；代码生成模块将计划转换为可执行代码，再由代码反思模块验证和完善生成的代码。这两个反思模块共同检测和纠正计划生成和代码生成中的错误。此外，本文还引入了LongVILBench，一个包含300个人类演示视频（最长18步动作序列）的基准，以支持系统评估。

Result: 实验结果表明，现有方法在LongVILBench基准上表现不佳，而本文提出的新框架为长周期视觉模仿学习建立了强大的基线。

Conclusion: 通过引入计划和代码反思模块，本文提出的框架能够有效检测和纠正错误，显著提高了在具有复杂时间与空间依赖性的长周期视觉模仿学习任务中的性能，并为该领域提供了新的评估基准。

Abstract: Learning from long-horizon demonstrations with complex action sequences
presents significant challenges for visual imitation learning, particularly in
understanding temporal relationships of actions and spatial relationships
between objects. In this paper, we propose a new agent framework that
incorporates two dedicated reflection modules to enhance both plan and code
generation. The plan generation module produces an initial action sequence,
which is then verified by the plan reflection module to ensure temporal
coherence and spatial alignment with the demonstration video. The code
generation module translates the plan into executable code, while the code
reflection module verifies and refines the generated code to ensure correctness
and consistency with the generated plan. These two reflection modules jointly
enable the agent to detect and correct errors in both the plan generation and
code generation, improving performance in tasks with intricate temporal and
spatial dependencies. To support systematic evaluation, we introduce
LongVILBench, a benchmark comprising 300 human demonstrations with action
sequences of up to 18 steps. LongVILBench emphasizes temporal and spatial
complexity across multiple task types. Experimental results demonstrate that
existing methods perform poorly on this benchmark, whereas our new framework
establishes a strong baseline for long-horizon visual imitation learning.

</details>


### [287] [Evaluating Magic Leap 2 Tool Tracking for AR Sensor Guidance in Industrial Inspections](https://arxiv.org/abs/2509.05391)
*Christian Masuhr,Julian Koch,Thorsten Schüppstuhl*

Main category: cs.RO

TL;DR: 本文系统评估了Magic Leap 2 (ML2) 控制器的跟踪性能，使用机械臂进行可重复运动，并以光学跟踪系统作为真值，为ML2控制器提供了量化基线和可转移的评估方法。


<details>
  <summary>Details</summary>
Motivation: 商业增强现实(AR)硬件的严格评估至关重要，但针对现代头戴式显示器(HMD)工具跟踪的公开基准测试非常有限，尤其缺乏对Magic Leap 2控制器的评估。

Method: 采用机械臂进行可重复运动（符合EN ISO 9283标准），并使用光学跟踪系统作为地面真值。评估协议涵盖静态和动态性能，包括来自氢气泄漏检查用例的真实路径。

Result: 提供了ML2控制器精度和重复性的量化基线，并提出了一种稳健且可转移的评估方法。

Conclusion: 研究结果为评估ML2控制器在检查用例和类似工业传感器AR指导任务中的适用性提供了基础。

Abstract: Rigorous evaluation of commercial Augmented Reality (AR) hardware is crucial,
yet public benchmarks for tool tracking on modern Head-Mounted Displays (HMDs)
are limited. This paper addresses this gap by systematically assessing the
Magic Leap 2 (ML2) controllers tracking performance. Using a robotic arm for
repeatable motion (EN ISO 9283) and an optical tracking system as ground truth,
our protocol evaluates static and dynamic performance under various conditions,
including realistic paths from a hydrogen leak inspection use case. The results
provide a quantitative baseline of the ML2 controller's accuracy and
repeatability and present a robust, transferable evaluation methodology. The
findings provide a basis to assess the controllers suitability for the
inspection use case and similar industrial sensor-based AR guidance tasks.

</details>


### [288] [RoboBallet: Planning for Multi-Robot Reaching with Graph Neural Networks and Reinforcement Learning](https://arxiv.org/abs/2509.05397)
*Matthew Lai,Keegan Go,Zhibin Li,Torsten Kroger,Stefan Schaal,Kelsey Allen,Jonathan Scholz*

Main category: cs.RO

TL;DR: 本文提出一个基于强化学习（RL）的框架，利用图神经网络（GNN）策略实现多机器人协作的自动化任务分配、调度和运动规划，尤其适用于障碍物丰富的共享工作空间。


<details>
  <summary>Details</summary>
Motivation: 现代机器人制造中，在共享的、障碍物丰富的空间内，多机器人无碰撞协调完成任务的计算复杂度极高，传统方法难以应对。现有工业系统依赖人工直觉和经验手动设计轨迹，过程耗时耗力。

Method: 提出一个强化学习（RL）框架，该框架采用图神经网络（GNN）策略。GNN利用场景的图表示，并通过RL在程序化生成的、具有多样化障碍物布局、机器人配置和任务分布的环境中进行训练。它能联合解决任务分配、调度和运动规划等子问题。

Result: 该策略在模拟中通过大量随机生成的任务集训练后，能够零样本泛化到未见过的场景，包括不同的机器人放置、障碍物几何形状和任务姿态。此外，该方案的高速能力使其能够用于工作单元布局优化，并缩短了解决方案时间。

Conclusion: 该规划器的速度和可扩展性为故障容错规划和基于在线感知的重新规划等新能力打开了大门，这些能力对于需要快速适应动态任务集的应用至关重要。

Abstract: Modern robotic manufacturing requires collision-free coordination of multiple
robots to complete numerous tasks in shared, obstacle-rich workspaces. Although
individual tasks may be simple in isolation, automated joint task allocation,
scheduling, and motion planning under spatio-temporal constraints remain
computationally intractable for classical methods at real-world scales.
Existing multi-arm systems deployed in the industry rely on human intuition and
experience to design feasible trajectories manually in a labor-intensive
process. To address this challenge, we propose a reinforcement learning (RL)
framework to achieve automated task and motion planning, tested in an
obstacle-rich environment with eight robots performing 40 reaching tasks in a
shared workspace, where any robot can perform any task in any order. Our
approach builds on a graph neural network (GNN) policy trained via RL on
procedurally-generated environments with diverse obstacle layouts, robot
configurations, and task distributions. It employs a graph representation of
scenes and a graph policy neural network trained through reinforcement learning
to generate trajectories of multiple robots, jointly solving the sub-problems
of task allocation, scheduling, and motion planning. Trained on large randomly
generated task sets in simulation, our policy generalizes zero-shot to unseen
settings with varying robot placements, obstacle geometries, and task poses. We
further demonstrate that the high-speed capability of our solution enables its
use in workcell layout optimization, improving solution times. The speed and
scalability of our planner also open the door to new capabilities such as
fault-tolerant planning and online perception-based re-planning, where rapid
adaptation to dynamic task sets is required.

</details>


### [289] [HapMorph: A Pneumatic Framework for Multi-Dimensional Haptic Property Rendering](https://arxiv.org/abs/2509.05433)
*Rui Chen,Domenico Chiaradia,Antonio Frisoli,Daniele Leonardis*

Main category: cs.RO

TL;DR: 本文介绍了HapMorph，一个基于气动的框架，利用对抗性织物气动执行器(AFPAs)实现可穿戴设备中物体尺寸和刚度的同步、连续调节，并通过人体感知研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有触觉接口在可穿戴设备中难以同时调节几何特征和机械特性。系统通常只能渲染其中之一，而非两者兼顾。

Method: 研究引入了HapMorph气动框架，采用对抗性织物气动执行器(AFPAs)。开发了用于手部交互的原型，通过双腔压力调节实现了尺寸和刚度的解耦控制。进行了系统特性表征和10名参与者的人体感知研究。此外，还展示了结合AFPAs与其他气动结构的扩展架构，以实现形状/几何变形与同步刚度控制。

Result: HapMorph原型实现了50至104毫米的尺寸变化、高达4.7牛/毫米的刚度调节，可穿戴部件质量仅为21克。通过特性表征证明了尺寸和刚度属性的解耦控制。人体感知研究显示，用户能以89.4%的准确率和平均6.7秒的响应时间区分9种离散状态（3种尺寸和3种刚度）。扩展架构也证明了形状或几何变形与并发刚度控制的能力。

Conclusion: 对抗性气动原理为下一代触觉接口提供了一条途径，使其能够在实际的可穿戴限制下实现多维渲染特性。

Abstract: Haptic interfaces that can simultaneously modulate multiple physical
properties remain a fundamental challenge in human-robot interaction. Existing
systems typically allow the rendering of either geometric features or
mechanical properties, but rarely both, within wearable form factors. Here, we
introduce HapMorph, a pneumatic framework that enables continuous, simultaneous
modulation of object size and stiffness through antagonistic fabric-based
pneumatic actuators (AFPAs). We implemented a HapMorph protoytpe designed for
hands interaction achieving size variation from 50 to 104 mm, stiffness
modulation up to 4.7 N/mm and mass of the wearable parts of just 21 g. Through
systematic characterization, we demonstrate decoupled control of size and
stiffness properties via dual-chamber pressure regulation. Human perception
studies with 10 participants reveal that users can distinguish nine discrete
states across three size categories and three stiffness levels with 89.4%
accuracy and 6.7 s average response time. We further demonstrate extended
architectures that combine AFPAs with complementary pneumatic structures to
enable shape or geometry morphing with concurrent stiffness control. Our
results establish antagonistic pneumatic principle as a pathway toward
next-generation haptic interfaces, capable of multi-dimensiona rendering
properties within practical wearable constraints.

</details>


### [290] [Learning Tool-Aware Adaptive Compliant Control for Autonomous Regolith Excavation](https://arxiv.org/abs/2509.05475)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 本文提出了一种基于模型的强化学习框架，用于自主月壤挖掘。该框架在并行仿真中训练智能体，利用高保真粒子物理和程序化生成技术创建多样化的月壤地形和挖掘工具几何形状。智能体通过动态调节自身刚度和阻尼来学习自适应交互策略，实验证明程序化工具分布对泛化能力至关重要，视觉反馈能显著提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 自主月壤挖掘是空间资源利用的关键，但面临颗粒介质复杂交互动力学和机器人需使用多样化工具的挑战。

Method: 引入了一个模型基强化学习智能体，在并行模拟环境中学习。该环境利用高保真粒子物理和程序化生成技术，创建了大量月壤地形和挖掘工具几何形状。智能体通过操作空间控制，在每个控制步骤动态调节自身的刚度和阻尼，学习自适应交互策略。此外，还通过视觉反馈增强了智能体。

Result: 使用程序化工具分布进行训练对泛化能力至关重要，并能促使智能体发展出复杂的工具感知行为。增强智能体的视觉反馈显著提高了任务成功率。

Conclusion: 该研究提供了一种经过验证的方法，用于开发未来空间任务基础任务所需的鲁棒且多功能的自主系统。

Abstract: Autonomous regolith excavation is a cornerstone of in-situ resource
utilization for a sustained human presence beyond Earth. However, this task is
fundamentally hindered by the complex interaction dynamics of granular media
and the operational need for robots to use diverse tools. To address these
challenges, this work introduces a framework where a model-based reinforcement
learning agent learns within a parallelized simulation. This environment
leverages high-fidelity particle physics and procedural generation to create a
vast distribution of both lunar terrains and excavation tool geometries. To
master this diversity, the agent learns an adaptive interaction strategy by
dynamically modulating its own stiffness and damping at each control step
through operational space control. Our experiments demonstrate that training
with a procedural distribution of tools is critical for generalization and
enables the development of sophisticated tool-aware behavior. Furthermore, we
show that augmenting the agent with visual feedback significantly improves task
success. These results represent a validated methodology for developing the
robust and versatile autonomous systems required for the foundational tasks of
future space missions.

</details>


### [291] [Microrobot Vascular Parkour: Analytic Geometry-based Path Planning with Real-time Dynamic Obstacle Avoidance](https://arxiv.org/abs/2509.05500)
*Yanda Yang,Max Sokolich,Fatma Ceren Kirmizitas,Sambeeta Das,Andreas A. Malikopoulos*

Main category: cs.RO

TL;DR: 该研究提出了一种实时路径规划框架，结合解析几何全局规划器（AGP）和两种局部避障控制器（基于规则和基于强化学习），使血管内自主微型机器人能够有效避开移动障碍物并到达目标。


<details>
  <summary>Details</summary>
Motivation: 血管内自主微型机器人的导航面临密集、移动障碍物的挑战，这阻碍了微创治疗的应用。

Method: 本研究提出一个实时路径规划框架：1) 采用解析几何全局规划器（AGP）进行全局路径规划；2) 结合两个反应式局部逃逸控制器（一个基于规则，一个基于强化学习）来处理突然出现的移动障碍物；3) 利用实时成像估计微型机器人、障碍物和目标的位置，并计算无碰撞运动；4) 将AGP从2D扩展到3D。

Result: 在仿真中，AGP比加权A*（WA*）、粒子群优化（PSO）和快速探索随机树（RRT）生成更短的路径和更快的规划，同时保持可行性和确定性。AGP扩展到3D后速度没有损失。在仿真和实验中，结合全局规划器和局部控制器能可靠地避开移动障碍物并到达目标。平均规划时间为每帧40毫秒，与25帧/秒的图像采集和实时闭环控制兼容。

Conclusion: 这些成果推动了血管环境中自主微型机器人导航和靶向药物递送技术的发展。

Abstract: Autonomous microrobots in blood vessels could enable minimally invasive
therapies, but navigation is challenged by dense, moving obstacles. We propose
a real-time path planning framework that couples an analytic geometry global
planner (AGP) with two reactive local escape controllers, one based on rules
and one based on reinforcement learning, to handle sudden moving obstacles.
Using real-time imaging, the system estimates the positions of the microrobot,
obstacles, and targets and computes collision-free motions. In simulation, AGP
yields shorter paths and faster planning than weighted A* (WA*), particle swarm
optimization (PSO), and rapidly exploring random trees (RRT), while maintaining
feasibility and determinism. We extend AGP from 2D to 3D without loss of speed.
In both simulations and experiments, the combined global planner and local
controllers reliably avoid moving obstacles and reach targets. The average
planning time is 40 ms per frame, compatible with 25 fps image acquisition and
real-time closed-loop control. These results advance autonomous microrobot
navigation and targeted drug delivery in vascular environments.

</details>


### [292] [TeleopLab: Accessible and Intuitive Teleoperation of a Robotic Manipulator for Remote Labs](https://arxiv.org/abs/2509.05547)
*Ziling Chen,Yeo Jung Yoon,Rolando Bautista-Montesano,Zhen Zhao,Ajay Mandlekar,John Liu*

Main category: cs.RO

TL;DR: TeleopLab是一个基于移动设备的远程操控系统，允许学生远程控制机械臂和实验设备进行实践学习，显著缩短了任务完成时间，并获得了积极的用户反馈和良好的可用性。


<details>
  <summary>Details</summary>
Motivation: 远程教育中涉及真实设备的实践学习通常成本高昂或不够直观，阻碍了学生进行动手操作。

Method: 本文提出了TeleopLab系统，包含机械臂、自适应夹具、摄像头、多样化实验设备、智能手机用户界面和视频通话软件。通过用户研究，评估了任务表现、学生对系统的看法、可用性以及工作负荷。

Result: 用户熟悉系统后，任务完成时间减少了46.1%。学生在使用系统后持积极态度。NASA TLX工作负荷评估为38.2（可管理），SUS可用性评估为73.8（积极）。

Conclusion: TeleopLab成功弥合了物理实验室与远程教育之间的鸿沟，为远程STEM学习提供了一个可扩展且有效的平台。

Abstract: Teleoperation offers a promising solution for enabling hands-on learning in
remote education, particularly in environments requiring interaction with
real-world equipment. However, such remote experiences can be costly or
non-intuitive. To address these challenges, we present TeleopLab, a mobile
device teleoperation system that allows students to control a robotic arm and
operate lab equipment. TeleopLab comprises a robotic arm, an adaptive gripper,
cameras, lab equipment for a diverse range of applications, a user interface
accessible through smartphones, and video call software. We conducted a user
study, focusing on task performance, students' perspectives toward the system,
usability, and workload assessment. Our results demonstrate a 46.1% reduction
in task completion time as users gained familiarity with the system.
Quantitative feedback highlighted improvements in students' perspectives after
using the system, while NASA TLX and SUS assessments indicated a manageable
workload of 38.2 and a positive usability of 73.8. TeleopLab successfully
bridges the gap between physical labs and remote education, offering a scalable
and effective platform for remote STEM learning.

</details>


### [293] [LocoMamba: Vision-Driven Locomotion via End-to-End Deep Reinforcement Learning with Mamba](https://arxiv.org/abs/2508.11849)
*Yinuo Wang,Gavin Tao*

Main category: cs.RO

TL;DR: LocoMamba是一个基于选择性状态空间模型（Mamba）的视觉驱动跨模态深度强化学习框架，它实现了近线性时间的序列建模，有效捕捉长程依赖，并提高了训练效率，在挑战性模拟环境中表现出更高的回报、成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的深度强化学习方法在处理长序列、捕捉长程依赖、降低延迟和内存占用以及提高训练效率方面面临挑战，尤其是在复杂的视觉驱动运动控制任务中。

Method: 该方法首先使用多层感知器嵌入本体感受状态，并使用轻量级卷积神经网络对深度图像进行分块，生成紧凑的token。其次，堆叠的Mamba层通过近线性时间的选择性扫描融合这些token，从而减少延迟和内存占用，同时对token长度和图像分辨率保持鲁棒性。最后，通过近端策略优化（PPO）进行端到端训练，结合地形和外观随机化、障碍密度课程学习，并使用平衡进展、平滑性和安全性的紧凑状态中心奖励。

Result: LocoMamba在具有静态和移动障碍物以及不平坦地形的挑战性模拟环境中进行了评估。与现有最先进的基线相比，该方法实现了更高的回报和成功率，碰撞次数更少，对未见地形和障碍物密度表现出更强的泛化能力，并在相同计算预算下通过更少的更新实现收敛，从而提高了训练效率。

Conclusion: LocoMamba通过引入Mamba作为其核心序列建模组件，成功地解决了视觉驱动运动控制中的关键挑战，实现了卓越的性能、泛化能力和训练效率，为机器人运动控制提供了一个强大的深度强化学习框架。

Abstract: We introduce LocoMamba, a vision-driven cross-modal DRL framework built on
selective state-space models, specifically leveraging Mamba, that achieves
near-linear-time sequence modeling, effectively captures long-range
dependencies, and enables efficient training with longer sequences. First, we
embed proprioceptive states with a multilayer perceptron and patchify depth
images with a lightweight convolutional neural network, producing compact
tokens that improve state representation. Second, stacked Mamba layers fuse
these tokens via near-linear-time selective scanning, reducing latency and
memory footprint, remaining robust to token length and image resolution, and
providing an inductive bias that mitigates overfitting. Third, we train the
policy end-to-end with Proximal Policy Optimization under terrain and
appearance randomization and an obstacle-density curriculum, using a compact
state-centric reward that balances progress, smoothness, and safety. We
evaluate our method in challenging simulated environments with static and
moving obstacles as well as uneven terrain. Compared with state-of-the-art
baselines, our method achieves higher returns and success rates with fewer
collisions, exhibits stronger generalization to unseen terrains and obstacle
densities, and improves training efficiency by converging in fewer updates
under the same compute budget.

</details>


### [294] [Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically Constrained Humanoids](https://arxiv.org/abs/2509.05581)
*Arturo Flores Alvarez,Fatemeh Zargarbashi,Havel Liu,Shiqi Wang,Liam Edwards,Jessica Anz,Alex Xu,Fan Shi,Stelian Coros,Dennis W. Hong*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习（RL）的运动系统，使具有独特美学设计（如大头部、运动受限）的娱乐型人形机器人Cosmo能够实现稳定站立和行走。


<details>
  <summary>Details</summary>
Motivation: 娱乐机器人因其美学驱动的设计（如Cosmo的头部过大、传感受限、运动受限）而面临独特的运动挑战，传统方法难以应对。

Method: 研究采用了对抗性运动先验（AMP）方法，并开发了定制的域随机化技术和专门的奖励结构，以确保安全地从模拟到真实环境的部署，保护硬件组件。

Result: 实验证明，尽管Cosmo具有极端的质量分布和运动限制，AMP仍能生成稳定的站立和行走行为。

Conclusion: 研究表明，学习型方法能够有效适应美学驱动的设计约束，为平衡美学吸引力与功能性能的机器人提供了有前景的方向。

Abstract: We present a Reinforcement Learning (RL)-based locomotion system for Cosmo, a
custom-built humanoid robot designed for entertainment applications. Unlike
traditional humanoids, entertainment robots present unique challenges due to
aesthetic-driven design choices. Cosmo embodies these with a disproportionately
large head (16% of total mass), limited sensing, and protective shells that
considerably restrict movement. To address these challenges, we apply
Adversarial Motion Priors (AMP) to enable the robot to learn natural-looking
movements while maintaining physical stability. We develop tailored domain
randomization techniques and specialized reward structures to ensure safe
sim-to-real, protecting valuable hardware components during deployment. Our
experiments demonstrate that AMP generates stable standing and walking
behaviors despite Cosmo's extreme mass distribution and movement constraints.
These results establish a promising direction for robots that balance aesthetic
appeal with functional performance, suggesting that learning-based methods can
effectively adapt to aesthetic-driven design constraints.

</details>


### [295] [MonoGlass3D: Monocular 3D Glass Detection with Plane Regression and Adaptive Feature Fusion](https://arxiv.org/abs/2509.05599)
*Kai Zhang,Guoyang Zhao,Jianxing Shi,Bonan Liu,Weiqing Qi,Jun Ma*

Main category: cs.RO

TL;DR: 本文提出了一个包含3D玻璃标注的新数据集，并引入了MonoGlass3D，一个结合自适应特征融合和平面回归的单目3D玻璃检测方法，在玻璃分割和深度估计上超越了现有技术。


<details>
  <summary>Details</summary>
Motivation: 玻璃的光学特性使其难以被传统传感器准确识别和定位，且缺乏专注于玻璃对象的真实世界数据集，阻碍了3D玻璃检测领域的发展。

Method: 研究者首先创建了一个包含多种玻璃配置和精确3D标注的真实世界数据集。在此基础上，提出了MonoGlass3D，一个用于单目3D玻璃检测的新方法。该方法包含一个自适应特征融合模块，以有效捕获不同条件下的上下文信息；以及一个平面回归流水线，以利用玻璃表面的平面几何特性。

Result: 广泛的实验表明，该方法在玻璃分割和单目玻璃深度估计方面均优于现有最先进的方法。

Conclusion: 研究结果强调了几何和上下文线索相结合对于理解透明表面具有显著优势。

Abstract: Detecting and localizing glass in 3D environments poses significant
challenges for visual perception systems, as the optical properties of glass
often hinder conventional sensors from accurately distinguishing glass
surfaces. The lack of real-world datasets focused on glass objects further
impedes progress in this field. To address this issue, we introduce a new
dataset featuring a wide range of glass configurations with precise 3D
annotations, collected from distinct real-world scenarios. On the basis of this
dataset, we propose MonoGlass3D, a novel approach tailored for monocular 3D
glass detection across diverse environments. To overcome the challenges posed
by the ambiguous appearance and context diversity of glass, we propose an
adaptive feature fusion module that empowers the network to effectively capture
contextual information in varying conditions. Additionally, to exploit the
distinct planar geometry of glass surfaces, we present a plane regression
pipeline, which enables seamless integration of geometric properties within our
framework. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches in both glass segmentation and monocular glass
depth estimation. Our results highlight the advantages of combining geometric
and contextual cues for transparent surface understanding.

</details>


### [296] [Sharing but Not Caring: Similar Outcomes for Shared Control and Switching Control in Telepresence-Robot Navigation](https://arxiv.org/abs/2509.05672)
*Juho Kalliokoski,Evan G. Center,Steven M. LaValle,Timo Ojala,Basak Sakcak*

Main category: cs.RO

TL;DR: 本研究开发并评估了一种用于远程呈现机器人的共享控制方法，结果显示其在导航效率上与控制切换相当，但未能显著降低用户任务负荷。


<details>
  <summary>Details</summary>
Motivation: 远程呈现机器人在与远程环境交互时，高效且直观的导航仍然是一个挑战。

Method: 开发并评估了一种共享控制方法，其中机器人自主导航，同时允许用户影响路径生成。该方法与用户在直接和自动化控制之间切换的控制切换方法进行了比较。通过两项连续的用户研究（每项20名参与者）进行了评估。

Result: 研究结果表明，共享控制没有降低导航效率，但与控制切换相比，用户任务负荷没有显著降低。

Conclusion: 共享控制在导航效率上与控制切换相当，但在降低用户任务负荷方面未显示出显著优势。未来需要进一步研究影响这些控制系统中用户偏好和性能的潜在因素。

Abstract: Telepresence robots enable users to interact with remote environments, but
efficient and intuitive navigation remains a challenge. In this work, we
developed and evaluated a shared control method, in which the robot navigates
autonomously while allowing users to affect the path generation to better suit
their needs. We compared this with control switching, where users toggle
between direct and automated control. We hypothesized that shared control would
maintain efficiency comparable to control switching while potentially reducing
user workload. The results of two consecutive user studies (each with final
sample of n=20) showed that shared control does not degrade navigation
efficiency, but did not show a significant reduction in task load compared to
control switching. Further research is needed to explore the underlying factors
that influence user preference and performance in these control systems.

</details>


### [297] [A*-PRM: A Dynamic Weight-Based Probabilistic Roadmap Algorithm](https://arxiv.org/abs/2509.05701)
*Siyuan Wang,Shuyi Zhang,Zhen Tian,Yuheng Yao,Gongsen Wang,Yu Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种名为A-star PRM的混合路径规划算法，通过结合A*启发式搜索和PRM随机采样，并引入动态权重、分层采样和动态连接机制，显著提升了路径质量、计算效率和对复杂环境的适应性。


<details>
  <summary>Details</summary>
Motivation: 机器人路径规划是提高自主导航系统环境适应性的基础挑战。

Method: 该研究提出了一种A-star PRM混合路径规划算法，其特点包括：1) 将A*算法的曼哈顿距离启发式嵌入到PRM的随机采样过程中；2) 使用动态权重；3) 采用分层采样策略；4) 引入动态连接机制。

Result: 实验结果显示：在1000个采样顶点下，A-star PRM的路径长度（1073.23 ± 14.8米）比PRM缩短了42.3% (p < 0.01)。在3000个采样顶点下，路径长度进一步缩短0.94%（1036.61米对比PRM的1046.42米），而计算时间增幅仅为PRM的约十分之一（71%对比785%）。该方法在狭窄通道和动态障碍物场景下，比现有混合算法表现出明显优势。

Conclusion: A-star PRM算法在路径质量、稳定性、计算效率方面具有综合优势，特别是在复杂环境（如狭窄通道和动态障碍物场景）中表现出显著益处。

Abstract: Robot path planning is a fundamental challenge in enhancing the environmental
adaptability of autonomous navigation systems. This paper presents a hybrid
path planning algorithm, A-star PRM, which incorporates dynamic weights. By
embedding the Manhattan distance heuristic of the A-star algorithm into the
random sampling process of PRM, the algorithm achieves a balanced optimization
of path quality and computational efficiency. The approach uses a hierarchical
sampling strategy and a dynamic connection mechanism, greatly improving
adaptability to complex obstacle distributions. Experiments show that under a
baseline configuration with one thousand sampled vertices, the path length of
A-star PRM is 1073.23 plus or minus 14.8 meters and is 42.3 percent shorter
than that of PRM with p value less than 0.01. With high-density sampling using
three thousand vertices, the path length is reduced by 0.94 percent, 1036.61
meters compared with 1046.42 meters, while the increase in computational time
is cut to about one tenth of the PRM increase, 71 percent compared with 785
percent. These results confirm the comprehensive advantages of A-star PRM in
path quality, stability, and computational efficiency. Compared with existing
hybrid algorithms, the proposed method shows clear benefits, especially in
narrow channels and scenarios with dynamic obstacles.

</details>


### [298] [Super-LIO: A Robust and Efficient LiDAR-Inertial Odometry System with a Compact Mapping Strategy](https://arxiv.org/abs/2509.05723)
*Liansheng Wang,Xinke Zhang,Chenhui Li,Dongjiao He,Yihan Pan,Jianjun Yi*

Main category: cs.RO

TL;DR: Super-LIO是一种高效、鲁棒且高精度的激光雷达惯性里程计（LIO）系统，专为资源受限平台设计，通过紧凑的地图结构和加速的对应搜索实现性能提升。


<details>
  <summary>Details</summary>
Motivation: LIO是自动驾驶系统的基础技术，但其在资源受限平台上的部署面临计算和内存限制的挑战。

Method: Super-LIO的核心是紧凑的八体素（octo-voxel）地图结构（OctVox），每个体素限制为八个融合子体素，实现严格的点密度控制和增量去噪。此外，它设计了一种启发式引导的KNN策略（HKNN），利用空间局部性加速对应搜索，进一步降低运行时开销。

Result: Super-LIO在X86和ARM平台上经过30多个序列的广泛测试，与SOTA系统相比，每帧处理速度快约73%，同时消耗更少的CPU资源，并保持具有竞争力的精度。系统表现出卓越的效率和鲁棒性。

Conclusion: Super-LIO提供了一种高效、鲁棒且准确的LIO解决方案，非常适合空中机器人和移动自动系统等应用。它完全开源，并兼容多种激光雷达传感器和平台，易于集成和部署。

Abstract: LiDAR-Inertial Odometry (LIO) is a foundational technique for autonomous
systems, yet its deployment on resource-constrained platforms remains
challenging due to computational and memory limitations. We propose Super-LIO,
a robust LIO system that demands both high performance and accuracy, ideal for
applications such as aerial robots and mobile autonomous systems. At the core
of Super-LIO is a compact octo-voxel-based map structure, termed OctVox, that
limits each voxel to eight fused subvoxels, enabling strict point density
control and incremental denoising during map updates. This design enables a
simple yet efficient and accurate map structure, which can be easily integrated
into existing LIO frameworks. Additionally, Super-LIO designs a
heuristic-guided KNN strategy (HKNN) that accelerates the correspondence search
by leveraging spatial locality, further reducing runtime overhead. We evaluated
the proposed system using four publicly available datasets and several
self-collected datasets, totaling more than 30 sequences. Extensive testing on
both X86 and ARM platforms confirms that Super-LIO offers superior efficiency
and robustness, while maintaining competitive accuracy. Super-LIO processes
each frame approximately 73% faster than SOTA, while consuming less CPU
resources. The system is fully open-source and plug-and-play compatible with a
wide range of LiDAR sensors and platforms. The implementation is available at:
https://github.com/Liansheng-Wang/Super-LIO.git

</details>


### [299] [Scenario-based Decision-making Using Game Theory for Interactive Autonomous Driving: A Survey](https://arxiv.org/abs/2509.05777)
*Zhihao Lin,Zhen Tian*

Main category: cs.RO

TL;DR: 这篇综述系统地评估了基于游戏的交互式驾驶模拟方法在不同场景下的决策算法，总结了最新进展，分析了算法机制，并讨论了局限性和未来方向。


<details>
  <summary>Details</summary>
Motivation: 尽管基于游戏的交互式驾驶模拟在推进道路交通决策算法方面取得了进展，但目前仍缺乏系统性的综述来比较这些方法在不同驾驶场景中的表现和适应性。

Method: 本研究通过对基于游戏的交互式驾驶方法进行全面评估，总结了每个场景（如高速避障、匝道合并、环岛、无信号交叉口、自动驾驶竞赛等）的最新进展和固有的道路特征。此外，还根据算法对标准游戏模型的适应性及其特定机制，批判性地评估了所审查的算法，以理解它们对决策性能的影响。

Result: 基于游戏的交互式驾驶模拟结合先进学习框架，能够开发出适应性决策模型，有效管理复杂多变的驾驶条件，并在特定场景挑战中（如避障、精准操纵、导航）表现优于传统模拟方法。本综述提供了一个全面的评估，并分析了算法对决策性能的影响。

Conclusion: 基于游戏的交互式驾驶模拟在提升决策算法方面具有巨大潜力，尤其是在应对复杂多样的驾驶场景时。然而，现有方法仍存在局限性，未来研究应致力于克服这些挑战，并探索新的方向以进一步提高其真实性和鲁棒性。

Abstract: Game-based interactive driving simulations have emerged as versatile
platforms for advancing decision-making algorithms in road transport mobility.
While these environments offer safe, scalable, and engaging settings for
testing driving strategies, ensuring both realism and robust performance amid
dynamic and diverse scenarios remains a significant challenge. Recently, the
integration of game-based techniques with advanced learning frameworks has
enabled the development of adaptive decision-making models that effectively
manage the complexities inherent in varied driving conditions. These models
outperform traditional simulation methods, especially when addressing
scenario-specific challenges, ranging from obstacle avoidance on highways and
precise maneuvering during on-ramp merging to navigation in roundabouts,
unsignalized intersections, and even the high-speed demands of autonomous
racing. Despite numerous innovations in game-based interactive driving, a
systematic review comparing these approaches across different scenarios is
still missing. This survey provides a comprehensive evaluation of game-based
interactive driving methods by summarizing recent advancements and inherent
roadway features in each scenario. Furthermore, the reviewed algorithms are
critically assessed based on their adaptation of the standard game model and an
analysis of their specific mechanisms to understand their impact on
decision-making performance. Finally, the survey discusses the limitations of
current approaches and outlines promising directions for future research.

</details>


### [300] [eKalibr-Inertial: Continuous-Time Spatiotemporal Calibration for Event-Based Visual-Inertial Systems](https://arxiv.org/abs/2509.05923)
*Shuolong Chen,Xingxing Li,Liu Yuan*

Main category: cs.RO

TL;DR: 本文提出eKalibr-Inertial，一个用于事件相机-惯性测量单元（IMU）系统的精确时空（外参和时间）校准器，利用圆形网格板实现高效初始化和连续时间批处理优化。


<details>
  <summary>Details</summary>
Motivation: 事件相机在运动估计、机器人感知和物体检测中表现出色，但为了实现精确的自我运动估计，常与IMU结合以利用其互补特性。这种视觉-惯性融合需要准确的时空校准。

Method: 该方法基于eKalibr和eKalibr-Stereo中的网格模式识别和跟踪，使用圆形网格板。它首先进行严格高效的初始化，准确恢复估计器中的所有参数。随后，通过连续时间批处理优化来精炼初始化的参数，使其达到更优状态。

Result: 广泛的真实世界实验结果表明，eKalibr-Inertial能够实现精确的基于事件的视觉-惯性时空校准。

Conclusion: eKalibr-Inertial提供了一个准确的事件相机-IMU系统时空校准解决方案，并已开源，以造福研究社区。

Abstract: The bioinspired event camera, distinguished by its exceptional temporal
resolution, high dynamic range, and low power consumption, has been extensively
studied in recent years for motion estimation, robotic perception, and object
detection. In ego-motion estimation, the visual-inertial setup is commonly
adopted due to complementary characteristics between sensors (e.g., scale
perception and low drift). For optimal event-based visual-inertial fusion,
accurate spatiotemporal (extrinsic and temporal) calibration is required. In
this work, we present eKalibr-Inertial, an accurate spatiotemporal calibrator
for event-based visual-inertial systems, utilizing the widely used circle grid
board. Building upon the grid pattern recognition and tracking methods in
eKalibr and eKalibr-Stereo, the proposed method starts with a rigorous and
efficient initialization, where all parameters in the estimator would be
accurately recovered. Subsequently, a continuous-time-based batch optimization
is conducted to refine the initialized parameters toward better states. The
results of extensive real-world experiments show that eKalibr-Inertial can
achieve accurate event-based visual-inertial spatiotemporal calibration. The
implementation of eKalibr-Inertial is open-sourced at
(https://github.com/Unsigned-Long/eKalibr) to benefit the research community.

</details>


### [301] [Hybrid A* Path Planning with Multi-Modal Motion Extension for Four-Wheel Steering Mobile Robots](https://arxiv.org/abs/2509.06115)
*Runjiao Bao,Lin Zhang,Tianwei Niu,Haoyu Yuan,Shoukun Wang*

Main category: cs.RO

TL;DR: 本文提出了一种扩展的混合A*路径规划框架，用于四轮独立转向（4WIS）机器人，通过在四维状态空间中整合运动模式，并设计多模态Reeds-Shepp曲线、考虑模式切换成本的启发式函数和智能模式选择策略，以充分利用其多模态运动能力，显著提高复杂环境下的规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法通常假设单一运动学模型，未能充分利用4WIS平台的多模态能力（如阿克曼转向、横向转向、平行移动），从而限制了机器人在受限环境中的机动性。

Method: 本文提出了一种扩展的混合A*框架，该框架在包含空间状态和运动模式的四维状态空间中运行。具体方法包括：设计针对不同运动模式运动学约束的多模态Reeds-Shepp曲线；开发考虑模式切换成本的增强启发式函数；引入具有智能模式选择的末端连接策略，以确保不同转向模式之间的平滑过渡。

Result: 所提出的规划器能够在一个路径中无缝整合多种运动模式，显著提高了机器人在复杂环境中的灵活性和适应性。结果表明，该方法显著提升了4WIS机器人在复杂环境中的规划性能。

Conclusion: 该扩展的混合A*框架通过有效利用4WIS机器人的多模态运动能力，实现了复杂环境下路径规划性能和机器人机动性的显著提升。

Abstract: Four-wheel independent steering (4WIS) systems provide mobile robots with a
rich set of motion modes, such as Ackermann steering, lateral steering, and
parallel movement, offering superior maneuverability in constrained
environments. However, existing path planning methods generally assume a single
kinematic model and thus fail to fully exploit the multi-modal capabilities of
4WIS platforms. To address this limitation, we propose an extended Hybrid A*
framework that operates in a four-dimensional state space incorporating both
spatial states and motion modes. Within this framework, we design multi-modal
Reeds-Shepp curves tailored to the distinct kinematic constraints of each
motion mode, develop an enhanced heuristic function that accounts for
mode-switching costs, and introduce a terminal connection strategy with
intelligent mode selection to ensure smooth transitions between different
steering patterns. The proposed planner enables seamless integration of
multiple motion modalities within a single path, significantly improving
flexibility and adaptability in complex environments. Results demonstrate
significantly improved planning performance for 4WIS robots in complex
environments.

</details>


### [302] [ZLATTE: A Geometry-Aware, Learning-Free Framework for Language-Driven Trajectory Reshaping in Human-Robot Interaction](https://arxiv.org/abs/2509.06031)
*Junhui Huang,Yuhe Gong,Changsheng Li,Xingguang Duan,Luis Figueredo*

Main category: cs.RO

TL;DR: ZLATTE是一个几何感知、免学习的框架，用于人机交互中基于语言的机器人轨迹重塑。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为基于学习的，ZLATTE旨在提供一种无需学习且能处理语言指令的轨迹重塑方案，以实现更平滑、安全和可解释的轨迹修改。

Method: ZLATTE利用视觉-语言模型将对象注册为几何基元，并使用大型语言模型将自然语言指令转化为明确的几何和运动学约束。这些约束被整合到势场优化中，以调整初始轨迹，同时保持可行性和安全性。此外，还采用多智能体策略来增强复杂或冲突指令下的鲁棒性。

Result: 仿真和真实世界实验证明，ZLATTE相较于现有最先进的基线方法，能够实现更平滑、更安全且更可解释的轨迹修改。

Conclusion: ZLATTE提供了一种高效且优于现有方法的学习无关框架，用于语言驱动的机器人轨迹重塑，显著提升了轨迹修改的质量和可解释性。

Abstract: We present ZLATTE, a geometry-aware, learning-free framework for
language-driven trajectory reshaping in human-robot interaction. Unlike prior
learning-based methods, ZLATTE leverages Vision-Language Models to register
objects as geometric primitives and employs a Large Language Model to translate
natural language instructions into explicit geometric and kinematic
constraints. These constraints are integrated into a potential field
optimization to adapt initial trajectories while preserving feasibility and
safety. A multi-agent strategy further enhances robustness under complex or
conflicting commands. Simulation and real-world experiments demonstrate that
ZLATTE achieves smoother, safer, and more interpretable trajectory
modifications compared to state-of-the-art baselines.

</details>


### [303] [A Hybrid TDMA/CSMA Protocol for Time-Sensitive Traffic in Robot Applications](https://arxiv.org/abs/2509.06119)
*Shiqi Xu,Lihao Zhang,Yuyang Du,Qun Yang,Soung Chang Liew*

Main category: cs.RO

TL;DR: 本文提出了一种兼容IEEE 802.11的混合TDMA/CSMA协议，用于解决机器人通信中关键任务指令在CSMA高负载下严重的延迟和碰撞问题。该协议通过精确的时间同步、动态TDMA分配和信标-NAV保护，显著减少了截止期错误和轨迹误差，同时保持了非关键流量的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 机器人技术（如制造、医疗、自主系统）对实时控制有高需求，要求在异构机器人流量下及时传递关键任务指令，以确保操作效率和安全。当前广泛使用的CSMA协议在高机器人流量负载下性能严重下降，导致碰撞和延迟，使得关键任务数据包无法按时到达，从而降低性能或破坏控制回路的稳定性。

Method: 研究人员提出了一种兼容IEEE 802.11的混合TDMA/CSMA协议。该协议结合了TDMA的确定性时隙调度和CSMA对异构机器人流量的适应性。其核心机制包括：亚微秒PTP（精确时间协议）的时隙同步以实现精确计时；一个具有动态TDMA分配的三会话超帧用于结构化和自适应流量管理；以及信标-NAV保护机制以预先保护关键通信会话免受干扰。该协议在实时SDR平台和Robot Operating System (ROS) 仿真中进行了演示和评估。

Result: 与CSMA基线相比，该协议将错过截止期错误减少了93%。在高速机器人路径跟踪ROS仿真中，将均方根(RMS)轨迹误差降低了高达90%。同时，非关键流量的吞吐量保持在±2%以内。协议实现了无碰撞、低延迟的关键任务指令传输。

Conclusion: 所提出的混合TDMA/CSMA协议通过结合确定性调度和适应性，显著解决了机器人关键任务通信在高流量负载下CSMA的局限性。它能大幅提高实时控制的可靠性和性能，减少关键任务指令的延迟和错误，同时保持与现有标准的兼容性和对非关键流量的效率。

Abstract: Recent progress in robotics has underscored the demand for real-time control
in applications such as manufacturing, healthcare, and autonomous systems,
where the timely delivery of mission-critical commands under heterogeneous
robotic traffic is paramount for operational efficacy and safety. In these
scenarios, mission-critical traffic follows a strict deadline-constrained
communication pattern: commands must arrive within defined QoS deadlines,
otherwise late arrivals can degrade performance or destabilize control loops.In
this work, we demonstrate on a real-time SDR platform that CSMA, widely adopted
in robotic communications,suffers severe degradation under high robot traffic
loads, with contention-induced collisions and delays disrupting the on-time
arrival of mission-critical packets. To address this problem, we propose an
IEEE 802.11-compatible hybrid TDMA/CSMA protocol that combines TDMA's
deterministic slot scheduling with CSMA's adaptability for heterogeneous robot
traffic.The protocol achieves collision-free, low-latency mission-critical
command delivery and IEEE 802.11 compatibility through the synergistic
integration of sub-microsecond PTP-based slot synchronization-essential for
establishing precise timing for TDMA, a three-session superframe with dynamic
TDMA allocation for structured and adaptable traffic management,and beacon-NAV
protection to preemptively secure these critical communication sessions from
interference. Emulation experiments on real-time SDR testbed and Robot
Operating System (ROS) simulation show that the proposed protocol reduces
missed-deadline errors by 93% compared to the CSMA baseline. In high-speed
robot path-tracking ROS simulations, the protocol lowers Root Mean Square (RMS)
trajectory error by up to 90% compared with a CSMA baseline, all while
maintaining throughput for non-critical traffic within +-2%.

</details>


### [304] [Robotic Manipulation Framework Based on Semantic Keypoints for Packing Shoes of Different Sizes, Shapes, and Softness](https://arxiv.org/abs/2509.06048)
*Yi Dong,Yangjun Liu,Jinjun Duan,Yang Li,Zhendong Dai*

Main category: cs.RO

TL;DR: 本研究提出了一种机器人操作框架，包括感知模块、重定向规划器和打包规划器，能够处理任意初始状态下的鞋子配对打包任务，并考虑了鞋子的不规则形状和可变形性。


<details>
  <summary>Details</summary>
Motivation: 随着仓储和物流业的快速发展，物品打包受到关注。鞋子打包是一个典型的配对物品打包任务，涉及不规则形状和可变形物体。现有研究未考虑鞋子因不规则形状而产生的不同初始状态以及标准打包放置姿态。

Method: 本研究提出了一个机器人操作框架，包含感知模块、重定向规划器和打包规划器。感知模块基于语义关键点和几何特征，能推断鞋子的尺寸、状态、姿态和操作点。重定向方法包括针对单个可变形鞋子不同状态的基于原语的方法，以及利用盒子边缘接触和重力实现的顶部状态快速重定向。最后，基于感知和重定向，提出了一个任务规划器，用于在任意初始状态下鞋子配对打包，以提供最优打包策略。

Result: 通过真实世界实验，验证了重定向方法的鲁棒性以及打包策略对各种类型鞋子的有效性。

Conclusion: 本研究强调了语义关键点表示方法的潜力，为3D可变形物体的重定向和多物体操作引入了新视角，并为配对物品打包提供了参考。

Abstract: With the rapid development of the warehousing and logistics industries, the
packing of goods has gradually attracted the attention of academia and
industry. The packing of footwear products is a typical representative
paired-item packing task involving irregular shapes and deformable objects.
Although studies on shoe packing have been conducted, different initial states
due to the irregular shapes of shoes and standard packing placement poses have
not been considered. This study proposes a robotic manipulation framework,
including a perception module, reorientation planners, and a packing planner,
that can complete the packing of pairs of shoes in any initial state. First, to
adapt to the large intraclass variations due to the state, shape, and
deformation of the shoe, we propose a vision module based on semantic
keypoints, which can also infer more information such as size, state, pose, and
manipulation points by combining geometric features. Subsequently, we not only
proposed primitive-based reorientation methods for different states of a single
deformable shoe but also proposed a fast reorientation method for the top state
using box edge contact and gravity, which further improved the efficiency of
reorientation. Finally, based on the perception module and reorientation
methods, we propose a task planner for shoe pair packing in any initial state
to provide an optimal packing strategy. Real-world experiments were conducted
to verify the robustness of the reorientation methods and the effectiveness of
the packing strategy for various types of shoes. In this study, we highlight
the potential of semantic keypoint representation methods, introduce new
perspectives on the reorientation of 3D deformable objects and multi-object
manipulation, and provide a reference for paired object packing.

</details>


### [305] [An Adaptive Coverage Control Approach for Multiple Autonomous Off-road Vehicles in Dynamic Agricultural Fields](https://arxiv.org/abs/2509.06682)
*Sajad Ahmadi,Mohammadreza Davoodi,Javad Mohammadpour Velni*

Main category: cs.RO

TL;DR: 本文提出了一种自适应覆盖控制方法，使越野无人地面车辆（UGVs）能够在动态农业环境中，通过集成无人机（UAVs）进行实时障碍物检测和地形评估，动态调整其覆盖路径。


<details>
  <summary>Details</summary>
Motivation: 传统的覆盖控制方法假设静态条件，不适用于存在移动机械和不平坦地形等动态障碍的真实农业场景。

Method: 该方法提出了一个实时路径规划框架，整合无人机进行障碍物检测和地形评估。环境被建模为加权有向图，图的边权重根据无人机观测结果（障碍物运动和地形变化）持续更新。该方法结合了基于Voronoi的划分、自适应边权重分配和基于成本的路径优化。

Result: 仿真结果表明，所提出的方法在存在动态障碍物和泥泞地形的情况下，有效改进了路径规划，降低了遍历成本，并保持了鲁棒的覆盖。

Conclusion: 该自适应覆盖控制方法能够有效提高无人地面车辆在动态农业环境中的路径规划效率、降低成本并保持稳健的覆盖。

Abstract: This paper presents an adaptive coverage control method for a fleet of
off-road and Unmanned Ground Vehicles (UGVs) operating in dynamic
(time-varying) agricultural environments. Traditional coverage control
approaches often assume static conditions, making them unsuitable for
real-world farming scenarios where obstacles, such as moving machinery and
uneven terrains, create continuous challenges. To address this, we propose a
real-time path planning framework that integrates Unmanned Aerial Vehicles
(UAVs) for obstacle detection and terrain assessment, allowing UGVs to
dynamically adjust their coverage paths. The environment is modeled as a
weighted directed graph, where the edge weights are continuously updated based
on the UAV observations to reflect obstacle motion and terrain variations. The
proposed approach incorporates Voronoi-based partitioning, adaptive edge weight
assignment, and cost-based path optimization to enhance navigation efficiency.
Simulation results demonstrate the effectiveness of the proposed method in
improving path planning, reducing traversal costs, and maintaining robust
coverage in the presence of dynamic obstacles and muddy terrains.

</details>


### [306] [Energy-Efficient Path Planning with Multi-Location Object Pickup for Mobile Robots on Uneven Terrain](https://arxiv.org/abs/2509.06061)
*Faiza Babakano,Ahmed Fahmin,Bojie Shen,Muhammad Aamir Cheema,Isma Farah Siddiqui*

Main category: cs.RO

TL;DR: 本文提出了物体拾取最小能量路径问题（OMEPP），旨在为需要拾取物体并递送的自主移动机器人（AMR）规划节能路径。为解决此问题，我们引入了一种并发PCPD搜索算法，该算法使用包含有效载荷约束的路径数据库，实现了比基线算法快1-2个数量级的近最优性能。


<details>
  <summary>Details</summary>
Motivation: 自主移动机器人（AMR）依赖电池供电，因此能源效率至关重要，尤其是在地形多变的户外环境。现有研究主要关注从起点到终点的节能路径规划，但忽略了机器人途中拾取物体（导致有效载荷变化，显著影响能耗）的实际场景。

Method: 本文首先提出了物体拾取最小能量路径问题（OMEPP）。为解决OMEPP，我们：1. 引入了一个基线算法，该算法迭代地对每个可能的拾取点使用Z星算法（一种针对节能路由的A星变体），确保最优性但计算成本高。2. 提出了一种并发PCPD搜索算法，该算法同时管理多个Z星搜索。其核心是有效载荷约束路径数据库（PCPD），它是压缩路径数据库（CPD）的扩展，融入了有效载荷约束，显著降低了搜索过程中的分支因子。

Result: 实验结果表明，并发PCPD搜索算法虽然可能产生略微次优的解决方案，但在真实世界数据集上实现了近乎最优的性能，并且比基线算法快1到2个数量级。PCPD显著减少了搜索过程中的分支因子，从而提高了整体性能。

Conclusion: 并发PCPD搜索算法为需要拾取物体的自主移动机器人提供了高效且近乎最优的节能路径规划解决方案。它在计算速度上取得了显著提升，使其在实际应用中更具可行性。

Abstract: Autonomous Mobile Robots (AMRs) operate on battery power, making energy
efficiency a critical consideration, particularly in outdoor environments where
terrain variations affect energy consumption. While prior research has
primarily focused on computing energy-efficient paths from a source to a
destination, these approaches often overlook practical scenarios where a robot
needs to pick up an object en route - an action that can significantly impact
energy consumption due to changes in payload. This paper introduces the
Object-Pickup Minimum Energy Path Problem (OMEPP), which addresses
energy-efficient route planning for AMRs required to pick up an object from one
of many possible locations and deliver it to a destination. To address OMEPP,
we first introduce a baseline algorithm that employs the Z star algorithm, a
variant of A star tailored for energy-efficient routing, to iteratively visit
each pickup point. While this approach guarantees optimality, it suffers from
high computational cost due to repeated searches at each pickup location. To
mitigate this inefficiency, we propose a concurrent PCPD search that manages
multiple Z star searches simultaneously across all pickup points. Central to
our solution is the Payload-Constrained Path Database (PCPD), an extension of
the Compressed Path Database (CPD) that incorporates payload constraints. We
demonstrate that PCPD significantly reduces branching factors during search,
improving overall performance. Although the concurrent PCPD search may produce
slightly suboptimal solutions, extensive experiments on real-world datasets
show it achieves near-optimal performance while being one to two orders of
magnitude faster than the baseline algorithm.

</details>


### [307] [Safe Robust Predictive Control-based Motion Planning of Automated Surface Vessels in Inland Waterways](https://arxiv.org/abs/2509.06687)
*Sajad Ahmadi,Hossein Nejatbakhsh Esfahani,Javad Mohammadpour Velni*

Main category: cs.RO

TL;DR: 本文提出一种结合鲁棒模型预测控制（RMPC）和控制障碍函数（CBFs）的新型运动规划方法，旨在解决内河航道中自主水面船舶（ASVs）的安全导航和避障挑战。


<details>
  <summary>Details</summary>
Motivation: 内河航道自主导航面临独特挑战，如航道狭窄、交通密度高和水动力干扰。现有自主船舶导航方法往往缺乏在这些环境中所需的鲁棒性或精度。

Method: 该研究提出了一种新的自主水面船舶（ASVs）运动规划方法，该方法结合了鲁棒模型预测控制（RMPC）和控制障碍函数（CBFs），并将航道边界和障碍物作为安全约束纳入控制设计框架。

Result: 仿真结果表明，所提出的方法能够有效地在真实条件下安全引导ASVs，并相对于现有技术，在安全性和适应性方面有所改进。

Conclusion: 该方法通过确保碰撞避免和鲁棒导航，提高了ASVs在复杂内河航道中的安全性和适应性，克服了现有方法的不足。

Abstract: Deploying self-navigating surface vessels in inland waterways offers a
sustainable alternative to reduce road traffic congestion and emissions.
However, navigating confined waterways presents unique challenges, including
narrow channels, higher traffic density, and hydrodynamic disturbances.
Existing methods for autonomous vessel navigation often lack the robustness or
precision required for such environments. This paper presents a new motion
planning approach for Automated Surface Vessels (ASVs) using Robust Model
Predictive Control (RMPC) combined with Control Barrier Functions (CBFs). By
incorporating channel borders and obstacles as safety constraints within the
control design framework, the proposed method ensures both collision avoidance
and robust navigation on complex waterways. Simulation results demonstrate the
efficacy of the proposed method in safely guiding ASVs under realistic
conditions, highlighting its improved safety and adaptability compared to the
state-of-the-art.

</details>


### [308] [Learning in ImaginationLand: Omnidirectional Policies through 3D Generative Models (OP-Gen)](https://arxiv.org/abs/2509.06191)
*Yifei Ren,Edward Johns*

Main category: cs.RO

TL;DR: 本文展示了如何利用3D生成模型从单一真实世界演示中扩充数据集，从而学习全向策略，使机器人能够从与演示状态差异很大的初始状态下执行任务，显著减少了策略学习所需的演示数量。


<details>
  <summary>Details</summary>
Motivation: 机器人策略学习通常需要大量演示，或难以在与演示状态差异较大的初始状态下有效执行任务。利用3D生成模型从少量图像生成完整物体形状的能力，为解决这一问题提供了新机遇。

Method: 研究方法包括：1) 使用3D生成模型从单一真实世界演示中扩充数据集；2) 在扩充的虚拟数据集中学习全向策略；3) 通过抓取物体、打开抽屉、将垃圾放入垃圾桶等多个真实世界任务进行实验；4) 探究不同设计选择对策略行为的影响，并与使用替代数据增强方法的最新基线进行性能比较。

Result: 研究发现，该方法使机器人能够从与演示状态（包括物体相对的另一侧）差异很大的初始状态下执行任务，显著减少了策略学习所需的演示数量。在真实世界实验中，所提出的全向策略表现出优于使用替代数据增强方法的最新基线的性能。

Conclusion: 3D生成模型可以有效地用于从单一演示中扩充数据集，从而学习鲁棒的全向机器人策略。这种方法能够显著降低策略学习所需的演示数量，并提高了机器人在多样化初始状态下的任务执行能力，性能优于其他数据增强基线。

Abstract: Recent 3D generative models, which are capable of generating full object
shapes from just a few images, now open up new opportunities in robotics. In
this work, we show that 3D generative models can be used to augment a dataset
from a single real-world demonstration, after which an omnidirectional policy
can be learned within this imagined dataset. We found that this enables a robot
to perform a task when initialised from states very far from those observed
during the demonstration, including starting from the opposite side of the
object relative to the real-world demonstration, significantly reducing the
number of demonstrations required for policy learning. Through several
real-world experiments across tasks such as grasping objects, opening a drawer,
and placing trash into a bin, we study these omnidirectional policies by
investigating the effect of various design choices on policy behaviour, and we
show superior performance to recent baselines which use alternative methods for
data augmentation.

</details>


### [309] [Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments](https://arxiv.org/abs/2509.06953)
*Jiahui Yang,Jason Jingzhou Liu,Yulong Li,Youssef Khaky,Kenneth Shaw,Deepak Pathak*

Main category: cs.RO

TL;DR: 本文提出了一种名为深度反应策略 (DRP) 的视觉-运动神经运动策略，用于在动态、部分可观测的环境中生成无碰撞运动。DRP直接处理点云输入，并结合了预训练的Transformer策略（IMPACT）、迭代师生微调以及一个局部反应式目标提议模块（DCP-RMP），在模拟和真实世界中均表现出优异的泛化能力和成功率。


<details>
  <summary>Details</summary>
Motivation: 在动态、部分可观测的环境中为机器人机械臂生成无碰撞运动是一个基本挑战。传统的运动规划器虽然能计算全局最优轨迹，但需要完整的环境知识且速度慢，不适用于动态场景。现有的神经运动策略虽然能直接从原始感官输入进行闭环操作，但在复杂或动态设置中泛化能力不足。

Method: 本文提出了深度反应策略 (DRP)，这是一种基于点云感官输入的视觉-运动神经运动策略。其核心是 IMPACT，一个基于 Transformer 的神经运动策略，通过在多样化仿真场景中生成的1000万条专家轨迹进行预训练。DRP通过迭代师生微调进一步提升了 IMPACT 的静态避障能力。此外，在推理时，DRP利用 DCP-RMP（一个局部反应式目标提议模块）增强了动态避障能力。

Result: DRP 在包含杂乱场景、动态移动障碍物和目标受阻的挑战性任务中进行了评估。结果显示，DRP 实现了强大的泛化能力，在模拟和真实世界环境中，其成功率均优于先前的经典和神经方法。

Conclusion: DRP 是一种有效的视觉-运动神经运动策略，能够直接从点云输入在多样化的动态环境中生成反应式无碰撞运动。它通过结合预训练的Transformer模型、精细化训练和动态避障模块，在复杂动态场景中展现出卓越的泛化能力和性能。

Abstract: Generating collision-free motion in dynamic, partially observable
environments is a fundamental challenge for robotic manipulators. Classical
motion planners can compute globally optimal trajectories but require full
environment knowledge and are typically too slow for dynamic scenes. Neural
motion policies offer a promising alternative by operating in closed-loop
directly on raw sensory inputs but often struggle to generalize in complex or
dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural
motion policy designed for reactive motion generation in diverse dynamic
environments, operating directly on point cloud sensory input. At its core is
IMPACT, a transformer-based neural motion policy pretrained on 10 million
generated expert trajectories across diverse simulation scenarios. We further
improve IMPACT's static obstacle avoidance through iterative student-teacher
finetuning. We additionally enhance the policy's dynamic obstacle avoidance at
inference time using DCP-RMP, a locally reactive goal-proposal module. We
evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving
obstacles, and goal obstructions. DRP achieves strong generalization,
outperforming prior classical and neural methods in success rate across both
simulated and real-world settings. Video results and code available at
https://deep-reactive-policy.com

</details>


### [310] [Grasp-MPC: Closed-Loop Visual Grasping via Value-Guided Model Predictive Control](https://arxiv.org/abs/2509.06201)
*Jun Yamada,Adithyavairavan Murali,Ajay Mandlekar,Clemens Eppner,Ingmar Posner,Balakumar Sundaralingam*

Main category: cs.RO

TL;DR: 本文提出了Grasp-MPC，一种基于视觉的闭环6自由度抓取策略，专为在杂乱环境中鲁棒、响应式地抓取新物体而设计。它结合了在大规模合成数据集上训练的价值函数和模型预测控制（MPC）框架，显著提高了模拟和真实世界中的抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中抓取多样化物体是一个重大挑战。开环抓取方法在受控环境中有效，但在杂乱环境中因抓取预测误差和物体姿态变化而失败。现有闭环方法仅限于简化设置和有限物体，缺乏泛化能力。

Method: Grasp-MPC是一种闭环6自由度视觉抓取策略。它包含一个价值函数，该函数在包含200万次成功和失败抓取轨迹的大规模合成数据集的视觉观测上进行训练。这个学习到的价值函数被部署在模型预测控制（MPC）框架中，并结合了鼓励避碰和平稳执行的其他成本项。

Result: Grasp-MPC在FetchBench和真实世界环境中进行了评估，在模拟中将抓取成功率提高了32.6%，在真实世界嘈杂条件下提高了33.3%。它优于开环、扩散策略、Transformer策略和IQL等方法。

Conclusion: Grasp-MPC为在杂乱环境中鲁棒、响应式地抓取新物体提供了一种有效的解决方案，通过结合学习到的价值函数和MPC框架，显著提高了抓取成功率，超越了现有技术。

Abstract: Grasping of diverse objects in unstructured environments remains a
significant challenge. Open-loop grasping methods, effective in controlled
settings, struggle in cluttered environments. Grasp prediction errors and
object pose changes during grasping are the main causes of failure. In
contrast, closed-loop methods address these challenges in simplified settings
(e.g., single object on a table) on a limited set of objects, with no path to
generalization. We propose Grasp-MPC, a closed-loop 6-DoF vision-based grasping
policy designed for robust and reactive grasping of novel objects in cluttered
environments. Grasp-MPC incorporates a value function, trained on visual
observations from a large-scale synthetic dataset of 2 million grasp
trajectories that include successful and failed attempts. We deploy this
learned value function in an MPC framework in combination with other cost terms
that encourage collision avoidance and smooth execution. We evaluate Grasp-MPC
on FetchBench and real-world settings across diverse environments. Grasp-MPC
improves grasp success rates by up to 32.6% in simulation and 33.3% in
real-world noisy conditions, outperforming open-loop, diffusion policy,
transformer policy, and IQL approaches. Videos and more at
http://grasp-mpc.github.io.

</details>


### [311] [O$^3$Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2509.06233)
*Tongxuan Tian,Xuhui Kang,Yen-Ling Kuo*

Main category: cs.RO

TL;DR: 本文提出了一种名为 O$^3$Afford 的新颖单样本3D物体间功能性学习方法，用于机器人操作。该方法结合了视觉基础模型、点云表示和大型语言模型，在有限数据下有效泛化，并显著提升了LLMs对物体交互的理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: 以往研究主要关注单物体功能性预测，但现实世界中的大多数交互涉及物体对之间的关系。此外，在数据有限的约束下，处理物体间功能性接地是一个挑战。

Method: 受2D视觉基础模型在少样本学习方面进展的启发，本文提出了一种单样本3D物体间功能性学习方法。该方法结合了来自视觉基础模型的语义特征和用于几何理解的点云表示。此外，还将3D功能性表示与大型语言模型（LLMs）集成，以增强LLMs在生成任务特定约束函数时理解和推理物体交互的能力。

Result: 在3D物体间功能性接地和机器人操作的实验中，O$^3$Afford 在准确性和泛化能力方面均显著优于现有基线。

Conclusion: O$^3$Afford 提供了一种有效的单样本3D物体间功能性学习方法，解决了现有方法的局限性，并在有限数据下实现了良好的泛化能力，同时增强了LLMs在机器人操作中理解和推理物体交互的能力。

Abstract: Grounding object affordance is fundamental to robotic manipulation as it
establishes the critical link between perception and action among interacting
objects. However, prior works predominantly focus on predicting single-object
affordance, overlooking the fact that most real-world interactions involve
relationships between pairs of objects. In this work, we address the challenge
of object-to-object affordance grounding under limited data contraints.
Inspired by recent advances in few-shot learning with 2D vision foundation
models, we propose a novel one-shot 3D object-to-object affordance learning
approach for robotic manipulation. Semantic features from vision foundation
models combined with point cloud representation for geometric understanding
enable our one-shot learning pipeline to generalize effectively to novel
objects and categories. We further integrate our 3D affordance representation
with large language models (LLMs) for robotics manipulation, significantly
enhancing LLMs' capability to comprehend and reason about object interactions
when generating task-specific constraint functions. Our experiments on 3D
object-to-object affordance grounding and robotic manipulation demonstrate that
our O$^3$Afford significantly outperforms existing baselines in terms of both
accuracy and generalization capability.

</details>


### [312] [DCReg: Decoupled Characterization for Efficient Degenerate LiDAR Registration](https://arxiv.org/abs/2509.06285)
*Xiangcheng Hu,Xieyuanli Chen,Mingkai Jia,Jin Wu,Ping Tan,Steven L. Waslander*

Main category: cs.RO

TL;DR: DCReg是一个针对LiDAR点云配准中病态问题的框架，通过舒尔补分解、定量表征和新型预处理器，实现可靠的病态检测、解释和定向缓解，显著提升了定位精度和速度。


<details>
  <summary>Details</summary>
Motivation: 在几何退化或狭窄环境中，LiDAR点云配准问题容易出现病态，导致解决方案不稳定和精度下降。现有方法未能准确检测、解释和有效解决这些病态问题。

Method: DCReg框架包含三项创新：1. **病态检测**：通过对Hessian矩阵进行舒尔补分解，将配准问题解耦为纯旋转和平移子空间，从而可靠地检测病态。2. **定量表征**：在解耦的子空间中，开发定量表征技术，建立数学特征空间与物理运动方向之间的明确映射，以识别缺乏约束的具体运动。3. **目标缓解**：设计一种新型预处理器，仅选择性地稳定已识别的病态方向，同时保留良好约束的信息，通过预处理共轭梯度法（PCG）实现高效鲁棒优化。

Result: 实验表明，DCReg在各种环境下，定位精度比现有最先进方法提高了至少20%-50%，速度提高了5-100倍。

Conclusion: DCReg提供了一个系统性解决病态LiDAR点云配准问题的原则性框架，通过其集成的检测、表征和缓解策略，显著提高了配准的准确性和效率。

Abstract: LiDAR point cloud registration is fundamental to robotic perception and
navigation. However, in geometrically degenerate or narrow environments,
registration problems become ill-conditioned, leading to unstable solutions and
degraded accuracy. While existing approaches attempt to handle these issues,
they fail to address the core challenge: accurately detection, interpret, and
resolve this ill-conditioning, leading to missed detections or corrupted
solutions. In this study, we introduce DCReg, a principled framework that
systematically addresses the ill-conditioned registration problems through
three integrated innovations. First, DCReg achieves reliable ill-conditioning
detection by employing a Schur complement decomposition to the hessian matrix.
This technique decouples the registration problem into clean rotational and
translational subspaces, eliminating coupling effects that mask degeneracy
patterns in conventional analyses. Second, within these cleanly subspaces, we
develop quantitative characterization techniques that establish explicit
mappings between mathematical eigenspaces and physical motion directions,
providing actionable insights about which specific motions lack constraints.
Finally, leveraging this clean subspace, we design a targeted mitigation
strategy: a novel preconditioner that selectively stabilizes only the
identified ill-conditioned directions while preserving all well-constrained
information in observable space. This enables efficient and robust optimization
via the Preconditioned Conjugate Gradient method with a single physical
interpretable parameter. Extensive experiments demonstrate DCReg achieves at
least 20% - 50% improvement in localization accuracy and 5-100 times speedup
over state-of-the-art methods across diverse environments. Our implementation
will be available at https://github.com/JokerJohn/DCReg.

</details>


### [313] [Learning to Walk with Less: a Dyna-Style Approach to Quadrupedal Locomotion](https://arxiv.org/abs/2509.06296)
*Francisco Affonso,Felipe Andrade G. Tommaselli,Juliano Negri,Vivian S. Medeiros,Mateus V. Gasparino,Girish Chowdhary,Marcelo Becker*

Main category: cs.RO

TL;DR: 本文提出了一种基于模型的强化学习（MBRL）框架，通过在PPO的rollout中添加合成数据来提高四足机器人运动控制器的样本效率，从而改善策略表现并减少方差。


<details>
  <summary>Details</summary>
Motivation: 传统的基于强化学习的运动控制器（如PPO）通常数据效率低下，需要大量的交互才能达到鲁棒的性能。

Method: 本文采用了一种Dyna-Style的MBRL框架。一个与策略并行训练的预测模型生成短期的合成转换数据，并使用基于策略更新迭代的调度策略逐步将这些数据整合到PPO的rollout中。通过消融研究，作者发现样本效率与rollout长度之间存在强相关性，并以此指导实验设计。

Result: 在Unitree Go1机器人的仿真中验证了该方法。结果表明，用合成数据替代部分仿真步骤不仅能模拟更长的rollout，还能提高策略回报并减少方差。此外，这种改进使得机器人能够以更少的仿真步骤跟踪更广泛的运动指令。

Conclusion: 该MBRL框架通过有效地利用合成数据，显著提高了四足机器人运动控制的样本效率和性能，使其能够以更少的仿真交互实现更优的策略学习和指令跟踪能力。

Abstract: Traditional RL-based locomotion controllers often suffer from low data
efficiency, requiring extensive interaction to achieve robust performance. We
present a model-based reinforcement learning (MBRL) framework that improves
sample efficiency for quadrupedal locomotion by appending synthetic data to the
end of standard rollouts in PPO-based controllers, following the Dyna-Style
paradigm. A predictive model, trained alongside the policy, generates
short-horizon synthetic transitions that are gradually integrated using a
scheduling strategy based on the policy update iterations. Through an ablation
study, we identified a strong correlation between sample efficiency and rollout
length, which guided the design of our experiments. We validated our approach
in simulation on the Unitree Go1 robot and showed that replacing part of the
simulated steps with synthetic ones not only mimics extended rollouts but also
improves policy return and reduces variance. Finally, we demonstrate that this
improvement transfers to the ability to track a wide range of locomotion
commands using fewer simulated steps.

</details>


### [314] [Towards bridging the gap: Systematic sim-to-real transfer for diverse legged robots](https://arxiv.org/abs/2509.06342)
*Filip Bjelonic,Fabian Tischhauser,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种结合仿真到现实强化学习与永磁同步电机物理能量模型的框架，实现了腿足机器人鲁棒且节能的运动，并通过最小参数集和基于第一性原理的奖励函数，有效弥补了仿真与现实差距，显著提高了能效。


<details>
  <summary>Details</summary>
Motivation: 现有仿真训练的控制器难以可靠地迁移到现实世界；大多数方法忽略了执行器特定的能量损耗，或依赖于复杂且需手动调整的奖励函数，这些都阻碍了腿足机器人在实际环境中的应用。

Method: 该框架将仿真到现实的强化学习与永磁同步电机的物理能量模型相结合。它使用最少的参数集来弥补仿真与现实之间的差距，并采用一个紧凑的四项奖励函数，其中包含基于第一性原理的能量损耗公式，平衡了电能和机械能耗散。通过自底向上的动态参数识别研究（涵盖执行器、机器人空中轨迹和地面运动）来评估和验证该方法。

Result: 该框架在无需动态参数随机化的情况下，实现了可靠的策略迁移。在三个主要平台进行了测试，并部署到十个额外机器人上。与现有最先进的方法相比，该方法提高了能量效率，使ANYmal的完整运输成本（Cost of Transport）降低了32%（值为1.27）。

Conclusion: 所提出的框架通过集成物理能量模型和精简奖励函数，克服了仿真到现实迁移的挑战，为腿足机器人实现了鲁棒、可靠且显著节能的运动控制。

Abstract: Legged robots must achieve both robust locomotion and energy efficiency to be
practical in real-world environments. Yet controllers trained in simulation
often fail to transfer reliably, and most existing approaches neglect
actuator-specific energy losses or depend on complex, hand-tuned reward
formulations. We propose a framework that integrates sim-to-real reinforcement
learning with a physics-grounded energy model for permanent magnet synchronous
motors. The framework requires a minimal parameter set to capture the
simulation-to-reality gap and employs a compact four-term reward with a
first-principle-based energetic loss formulation that balances electrical and
mechanical dissipation. We evaluate and validate the approach through a
bottom-up dynamic parameter identification study, spanning actuators,
full-robot in-air trajectories and on-ground locomotion. The framework is
tested on three primary platforms and deployed on ten additional robots,
demonstrating reliable policy transfer without randomization of dynamic
parameters. Our method improves energetic efficiency over state-of-the-art
methods, achieving a 32 percent reduction in the full Cost of Transport of
ANYmal (value 1.27). All code, models, and datasets will be released.

</details>


### [315] [Adaptive Evolution Factor Risk Ellipse Framework for Reliable and Safe Autonomous Driving](https://arxiv.org/abs/2509.06375)
*Fujiang Yuan,Zhen Tian,Yangfan He,Guojian Zou,Chunhong Yuan,Yanhong Peng,Zhihao Lin*

Main category: cs.RO

TL;DR: 提出了一种名为进化风险势场（ERPF）的新方法，通过动态更新风险评估并结合风险椭圆和自适应进化因子，将其无缝集成到模型预测控制（MPC）框架中，以实现交互式自动驾驶中更平滑、更快速且无碰撞的导航。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的自动驾驶方法（如博弈论、鲁棒控制）过于保守或计算量大；基于学习的方法需要大量训练数据且解释性、泛化性有限；简单的策略（如风险势场RPF）虽然轻量但静态，难以适应动态交通条件。研究旨在克服这些限制，提供一种更适应动态交互式场景的解决方案。

Method: 该研究提出了进化风险势场（ERPF），基于历史障碍物接近数据动态更新风险评估。引入了“风险椭圆”构造，结合纵向可达性和横向不确定性形成统一的时空碰撞包络。定义了一个自适应的“进化因子”度量，通过碰撞时间（TTC）和危险时间窗（TWH）的Sigmoid归一化计算，实时动态调整椭圆轴的尺寸。最后，将这种自适应风险度量无缝集成到模型预测控制（MPC）框架中。

Result: 全面的对比实验表明，ERPF-MPC方法始终能实现更平滑的轨迹、更高的平均速度和无碰撞导航，为复杂的交互式驾驶环境提供了一个鲁棒且自适应的解决方案。

Conclusion: ERPF-MPC方法通过动态更新风险评估并结合自适应风险度量，成功克服了传统方法的局限性，为复杂交互式自动驾驶场景提供了一种安全、高效、舒适的解决方案。

Abstract: In recent years, ensuring safety, efficiency, and comfort in interactive
autonomous driving has become a critical challenge. Traditional model-based
techniques, such as game-theoretic methods and robust control, are often overly
conservative or computationally intensive. Conversely, learning-based
approaches typically require extensive training data and frequently exhibit
limited interpretability and generalizability. Simpler strategies, such as Risk
Potential Fields (RPF), provide lightweight alternatives with minimal data
demands but are inherently static and struggle to adapt effectively to dynamic
traffic conditions. To overcome these limitations, we propose the Evolutionary
Risk Potential Field (ERPF), a novel approach that dynamically updates risk
assessments in dynamical scenarios based on historical obstacle proximity data.
We introduce a Risk-Ellipse construct that combines longitudinal reach and
lateral uncertainty into a unified spatial temporal collision envelope.
Additionally, we define an adaptive Evolution Factor metric, computed through
sigmoid normalization of Time to Collision (TTC) and Time-Window-of-Hazard
(TWH), which dynamically adjusts the dimensions of the ellipse axes in real
time. This adaptive risk metric is integrated seamlessly into a Model
Predictive Control (MPC) framework, enabling autonomous vehicles to proactively
address complex interactive driving scenarios in terms of uncertain driving of
surrounding vehicles. Comprehensive comparative experiments demonstrate that
our ERPF-MPC approach consistently achieves smoother trajectories, higher
average speeds, and collision-free navigation, offering a robust and adaptive
solution suitable for complex interactive driving environments.

</details>


### [316] [Safety Meets Speed: Accelerated Neural MPC with Safety Guarantees and No Retraining](https://arxiv.org/abs/2509.06404)
*Kaikai Wang,Tianxun Li,Liang Xu,Qinglei Hu,Keyou You*

Main category: cs.RO

TL;DR: 本文提出了一种名为BAN-MPC的控制框架，它结合了神经网络的快速计算和模型预测控制（MPC）的安全性。通过引入控制障碍函数（CBF）和神经价值函数，并利用第二个神经网络实现参数自适应，BAN-MPC在嵌入式设备上比传统MPC快200倍，同时确保无碰撞导航和低控制误差。


<details>
  <summary>Details</summary>
Motivation: 传统模型预测控制（MPC）虽然能通过约束确保安全，但其实时执行的计算量往往超出嵌入式计算预算。研究的动机是开发一种既能保证严格安全又能在嵌入式设备上快速运行的替代方案。

Method: 本文提出了障碍集成自适应神经模型预测控制（BAN-MPC）框架。具体方法包括：1) 将神经网络的快速计算与MPC的约束处理能力相结合。2) 用控制障碍函数（CBF）替代传统的欧几里得距离，以实现严格的碰撞避免。3) 将离线学习的神经价值函数集成到短时域MPC的优化目标中，以显著降低在线计算复杂度。4) 使用第二个神经网络学习价值函数对系统参数的敏感性，从而在模型参数变化时自适应调整神经价值函数，避免重新训练并减少离线计算成本。

Result: 在Jetson Nano上的硬件在环（HIL）实验表明，BAN-MPC的求解速度比传统MPC快200倍。它能够在模型参数变化范围在15%以内的情况下，实现无碰撞导航，并将控制误差保持在5%以下。

Conclusion: BAN-MPC是一种有效的嵌入式MPC替代方案。它成功地将神经网络的速度与MPC的安全性相结合，并通过自适应机制应对参数变化，显著提升了实时性能和实用性。

Abstract: While Model Predictive Control (MPC) enforces safety via constraints, its
real-time execution can exceed embedded compute budgets. We propose a
Barrier-integrated Adaptive Neural Model Predictive Control (BAN-MPC) framework
that synergizes neural networks' fast computation with MPC's
constraint-handling capability. To ensure strict safety, we replace traditional
Euclidean distance with Control Barrier Functions (CBFs) for collision
avoidance. We integrate an offline-learned neural value function into the
optimization objective of a Short-horizon MPC, substantially reducing online
computational complexity. Additionally, we use a second neural network to learn
the sensitivity of the value function to system parameters, and adaptively
adjust the neural value function based on this neural sensitivity when model
parameters change, eliminating the need for retraining and reducing offline
computation costs. The hardware in-the-loop (HIL) experiments on Jetson Nano
show that BAN-MPC solves 200 times faster than traditional MPC, enabling
collision-free navigation with control error below 5\% under model parameter
variations within 15\%, making it an effective embedded MPC alternative.

</details>


### [317] [Real-time Photorealistic Mapping for Situational Awareness in Robot Teleoperation](https://arxiv.org/abs/2509.06433)
*Ian Page,Pierre Susbielle,Olivier Aycard,Pierre-Brice Wieber*

Main category: cs.RO

TL;DR: 该研究提出了一种基于GPU的高斯溅射SLAM与现有在线地图遥操作系统集成的新方法，以在未知环境中实现高效、实时的逼真3D地图生成，显著提升遥操作效率。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中，遥操作面临快速理解现场布局的挑战。传统的在线地图遥操作系统由于计算成本高，难以实时生成视觉准确的3D地图，导致遥操作性能不佳。

Method: 该方法提出了一种新颖、模块化且高效的GPU集成方案，将高斯溅射SLAM的最新进展与现有的在线地图遥操作系统相结合。通过使用无人机进行实际实验，与现有最先进的遥操作系统进行了性能比较和验证。

Result: 实验结果表明，该方案显著提高了决策速度和与环境交互的准确性，从而提升了遥操作效率。系统通过将逼真地图生成与实时性能无缝集成，增强了远程遥操作能力。

Conclusion: 该系统通过在未知环境中提供实时的逼真地图生成，有效提升了远程遥操作的效率和准确性，实现了在陌生环境中的高效遥操作。

Abstract: Achieving efficient remote teleoperation is particularly challenging in
unknown environments, as the teleoperator must rapidly build an understanding
of the site's layout. Online 3D mapping is a proven strategy to tackle this
challenge, as it enables the teleoperator to progressively explore the site
from multiple perspectives. However, traditional online map-based teleoperation
systems struggle to generate visually accurate 3D maps in real-time due to the
high computational cost involved, leading to poor teleoperation performances.
In this work, we propose a solution to improve teleoperation efficiency in
unknown environments. Our approach proposes a novel, modular and efficient
GPU-based integration between recent advancement in gaussian splatting SLAM and
existing online map-based teleoperation systems. We compare the proposed
solution against state-of-the-art teleoperation systems and validate its
performances through real-world experiments using an aerial vehicle. The
results show significant improvements in decision-making speed and more
accurate interaction with the environment, leading to greater teleoperation
efficiency. In doing so, our system enhances remote teleoperation by seamlessly
integrating photorealistic mapping generation with real-time performances,
enabling effective teleoperation in unfamiliar environments.

</details>


### [318] [Interactive Shaping of Granular Media Using Reinforcement Learning](https://arxiv.org/abs/2509.06469)
*Benedikt Kreis,Malte Mosbach,Anny Ripke,Muhammad Ehsan Ullah,Sven Behnke,Maren Bennewitz*

Main category: cs.RO

TL;DR: 本文提出一个强化学习框架，使机械臂能够通过视觉策略塑造颗粒介质，通过紧凑的观测和简洁的奖励公式，在真实世界部署中表现出色并优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 由于颗粒材料的高维配置空间和复杂动力学，传统的基于规则的方法在塑造颗粒介质时面临巨大挑战，需要大量的工程投入。强化学习提供了一种通过试错学习自适应操作策略的有效替代方案。

Method: 研究提出一个强化学习框架，使用配备立方末端执行器和立体摄像头的机械臂来塑造颗粒介质。该方法强调紧凑的观测和简洁的奖励公式对于处理大型配置空间的重要性，并通过消融研究验证了设计选择。

Result: 实验结果表明，所提出的方法能够有效地训练用于操作颗粒介质的视觉策略，包括其在真实世界的部署，并且性能优于两种基线方法。

Conclusion: 该强化学习框架，通过其紧凑的观测和简洁的奖励公式，能够有效且成功地使机器人手臂塑造颗粒介质，并实现真实世界部署。

Abstract: Autonomous manipulation of granular media, such as sand, is crucial for
applications in construction, excavation, and additive manufacturing. However,
shaping granular materials presents unique challenges due to their
high-dimensional configuration space and complex dynamics, where traditional
rule-based approaches struggle without extensive engineering efforts.
Reinforcement learning (RL) offers a promising alternative by enabling agents
to learn adaptive manipulation strategies through trial and error. In this
work, we present an RL framework that enables a robotic arm with a cubic
end-effector and a stereo camera to shape granular media into desired target
structures. We show the importance of compact observations and concise reward
formulations for the large configuration space, validating our design choices
with an ablation study. Our results demonstrate the effectiveness of the
proposed approach for the training of visual policies that manipulate granular
media including their real-world deployment, outperforming two baseline
approaches.

</details>


### [319] [Event Driven CBBA with Reduced Communication](https://arxiv.org/abs/2509.06481)
*Vinita Sao,Tu Dac Ho,Sujoy Bhore,P. B. Sujit*

Main category: cs.RO

TL;DR: 本研究提出了一种事件驱动的共识捆绑算法（ED-CBBA），旨在减少多机器人任务分配中CBBA的通信开销，同时保持其收敛性和性能保证。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在监视和搜救等场景中执行多任务至关重要。现有共识捆绑算法（CBBA）虽有理论保证，但要求持续通信，这在机器人通信范围有限的情况下会导致通信拥堵和数据包丢失，影响性能。

Method: 引入了一种事件驱动的通信机制来改进CBBA。理论上证明了其解决方案质量与CBBA相符，并通过蒙特卡洛模拟在不同目标、代理和捆绑配置下进行了验证。

Result: 实验结果表明，所提出的ED-CBBA算法能将消息传输量减少高达52%，同时保持与CBBA相同的解决方案质量。

Conclusion: ED-CBBA成功解决了多机器人任务分配中的通信挑战，显著降低了消息传输量，且不牺牲CBBA的收敛性和性能边界。

Abstract: In various scenarios such as multi-drone surveillance and search-and-rescue
operations, deploying multiple robots is essential to accomplish multiple tasks
at once. Due to the limited communication range of these vehicles, a
decentralised task allocation algorithm is crucial for effective task
distribution among robots. The consensus-based bundle algorithm (CBBA) has been
promising for multi-robot operation, offering theoretical guarantees. However,
CBBA demands continuous communication, leading to potential congestion and
packet loss that can hinder performance. In this study, we introduce an
event-driven communication mechanism designed to address these communication
challenges while maintaining the convergence and performance bounds of CBBA. We
demonstrate theoretically that the solution quality matches that of CBBA and
validate the approach with Monte-Carlo simulations across varying targets,
agents, and bundles. Results indicate that the proposed algorithm (ED-CBBA) can
reduce message transmissions by up to 52%.

</details>


### [320] [Co-Located VR with Hybrid SLAM-based HMD Tracking and Motion Capture Synchronization](https://arxiv.org/abs/2509.06582)
*Carlos A. Pinheiro de Sousa,Niklas Gröne,Mathias Günther,Oliver Deussen*

Main category: cs.RO

TL;DR: 该论文介绍了一个多用户VR协同定位框架，通过结合动作捕捉系统和基于SLAM的由内向外跟踪，实现了共享虚拟环境中用户的高精度、低延迟、高帧率同步。


<details>
  <summary>Details</summary>
Motivation: 现有的多用户VR协同定位方法要么依赖连续外部跟踪导致延迟和抖动，要么依赖一次性校准无法纠正随时间产生的漂移。研究旨在解决这些问题，提供一个兼具响应性、漂移纠正能力和高精度的解决方案。

Method: 该方法结合了动作捕捉系统（用于外部源校准和漂移纠正）与基于SLAM的由内向外跟踪（用于本地头显的响应性）。它允许在需要时重新对齐到外部源，并支持设备间的实时姿态共享，以确保用户间空间对齐的一致性。

Result: 评估表明，该框架实现了多用户自然交互所需的空间精度，并且相比现有协同定位VR解决方案，提供了更高的舒适度、可扩展性和鲁棒性。

Conclusion: 该框架通过结合内外跟踪优势，克服了传统多用户VR协同定位方案的局限性，为实现更自然、更稳定、更舒适的多用户VR体验提供了有效的解决方案。

Abstract: We introduce a multi-user VR co-location framework that synchronizes users
within a shared virtual environment aligned to physical space. Our approach
combines a motion capture system with SLAM-based inside-out tracking to deliver
smooth, high-framerate, low-latency performance. Previous methods either rely
on continuous external tracking, which introduces latency and jitter, or on
one-time calibration, which cannot correct drift over time. In contrast, our
approach combines the responsiveness of local HMD SLAM tracking with the
flexibility to realign to an external source when needed. It also supports
real-time pose sharing across devices, ensuring consistent spatial alignment
and engagement between users. Our evaluation demonstrates that our framework
achieves the spatial accuracy required for natural multi-user interaction while
offering improved comfort, scalability, and robustness over existing co-located
VR solutions.

</details>


### [321] [A Robust Approach for LiDAR-Inertial Odometry Without Sensor-Specific Modeling](https://arxiv.org/abs/2509.06593)
*Meher V. R. Malladi,Tiziano Guadagnino,Luca Lobefaro,Cyrill Stachniss*

Main category: cs.RO

TL;DR: 本文提出了一种鲁棒的激光雷达-惯性里程计系统，该系统不依赖于传感器特定模型，通过简化的IMU运动模型和直接的激光雷达扫描到地图配准实现，并在多种数据集上展示了其通用性和性能。


<details>
  <summary>Details</summary>
Motivation: 机器人导航堆栈中，准确的里程计至关重要，后续模块（如规划和控制）均依赖于机器人运动估计。现有的基于传感器的里程计方法在传感器类型和部署环境（从固态激光雷达到旋转激光雷达，从城市驾驶到非结构化自然环境）方面，往往缺乏足够的鲁棒性。

Method: 该研究提出了一种不依赖于传感器特定模型的激光雷达-惯性里程计系统。它采用简化的运动模型进行IMU数据积分，并直接使用“扫描到地图”的方法配准激光雷达扫描。此外，该方法在激光雷达配准上施加了一种新颖的正则化，以提高整体里程计性能，这与传统的卡尔曼滤波或因子图框架中迭代整合IMU数据并结合特征提取的激光雷达扫描匹配方法不同。

Result: 通过在涵盖多种常用机器人传感器和平台的大量数据集上进行广泛实验，结果表明，该方法在所有场景中均可使用完全相同的配置，展现了其卓越的鲁棒性。研究团队已开源其实现，以便社区在此基础上进一步开发和使用。

Conclusion: 该论文成功开发并验证了一个鲁棒且通用的激光雷达-惯性里程计系统，该系统无需传感器特定建模，能够在各种传感器类型和复杂环境中保持一致的性能，为机器人导航提供了可靠的运动估计解决方案。

Abstract: Accurate odometry is a critical component in a robotic navigation stack, and
subsequent modules such as planning and control often rely on an estimate of
the robot's motion. Sensor-based odometry approaches should be robust across
sensor types and deployable in different target domains, from solid-state
LiDARs mounted on cars in urban-driving scenarios to spinning LiDARs on
handheld packages used in unstructured natural environments. In this paper, we
propose a robust LiDAR-inertial odometry system that does not rely on
sensor-specific modeling. Sensor fusion techniques for LiDAR and inertial
measurement unit (IMU) data typically integrate IMU data iteratively in a
Kalman filter or use pre-integration in a factor graph framework, combined with
LiDAR scan matching often exploiting some form of feature extraction. We
propose an alternative strategy that only requires a simplified motion model
for IMU integration and directly registers LiDAR scans in a scan-to-map
approach. Our approach allows us to impose a novel regularization on the LiDAR
registration, improving the overall odometry performance. We detail extensive
experiments on a number of datasets covering a wide array of commonly used
robotic sensors and platforms. We show that our approach works with the exact
same configuration in all these scenarios, demonstrating its robustness. We
have open-sourced our implementation so that the community can build further on
our work and use it in their navigation stacks.

</details>


### [322] [LiHRA: A LiDAR-Based HRI Dataset for Automated Risk Monitoring Methods](https://arxiv.org/abs/2509.06597)
*Frederik Plahl,Georgios Katranis,Ilshat Mamaev,Andrey Morozov*

Main category: cs.RO

TL;DR: LiHRA是一个新的多模态数据集，旨在促进人机交互（HRI）场景中自动化风险监测（RM）方法的发展，它结合了3D LiDAR、人体关键点和机器人关节状态，包含安全和危险两种情景。


<details>
  <summary>Details</summary>
Motivation: 协作机器人在工业环境中日益普及，对可靠安全系统的需求增加。然而，缺乏高质量的数据集来捕捉真实的人机交互，包括潜在危险事件，阻碍了相关方法的发展。

Method: LiHRA数据集通过结合3D LiDAR点云、人体关键点和机器人关节状态等多模态数据来解决这一挑战，全面捕捉人机协作的空间和动态背景。该数据集涵盖了六种代表性HRI场景（协作、共存、物体交接和表面抛光），每种场景都有安全和危险版本。总共包含4,431个以10 Hz记录的标记点云。此外，论文还引入了一种利用机器人状态和动态模型来量化风险水平的RM方法，以展示LiHRA的实用性。

Result: LiHRA数据集为训练和基准测试经典及AI驱动的RM算法提供了丰富的资源。论文中展示的RM方法能够随时间量化每个场景中的风险水平，并利用了上下文信息。

Conclusion: LiHRA数据集结合了高分辨率LiDAR数据、精确的人体跟踪、机器人状态数据和真实的碰撞事件，为人机工作空间中实时风险监测和自适应安全策略的未来研究奠定了重要基础。

Abstract: We present LiHRA, a novel dataset designed to facilitate the development of
automated, learning-based, or classical risk monitoring (RM) methods for
Human-Robot Interaction (HRI) scenarios. The growing prevalence of
collaborative robots in industrial environments has increased the need for
reliable safety systems. However, the lack of high-quality datasets that
capture realistic human-robot interactions, including potentially dangerous
events, slows development. LiHRA addresses this challenge by providing a
comprehensive, multi-modal dataset combining 3D LiDAR point clouds, human body
keypoints, and robot joint states, capturing the complete spatial and dynamic
context of human-robot collaboration. This combination of modalities allows for
precise tracking of human movement, robot actions, and environmental
conditions, enabling accurate RM during collaborative tasks. The LiHRA dataset
covers six representative HRI scenarios involving collaborative and coexistent
tasks, object handovers, and surface polishing, with safe and hazardous
versions of each scenario. In total, the data set includes 4,431 labeled point
clouds recorded at 10 Hz, providing a rich resource for training and
benchmarking classical and AI-driven RM algorithms. Finally, to demonstrate
LiHRA's utility, we introduce an RM method that quantifies the risk level in
each scenario over time. This method leverages contextual information,
including robot states and the dynamic model of the robot. With its combination
of high-resolution LiDAR data, precise human tracking, robot state data, and
realistic collision events, LiHRA offers an essential foundation for future
research into real-time RM and adaptive safety strategies in human-robot
workspaces.

</details>


### [323] [T-araVLN: Translator for Agricultural Robotic Agents on Vision-and-Language Navigation](https://arxiv.org/abs/2509.06644)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: 本文提出T-araVLN方法，通过指令翻译模块改进农业机器人视觉语言导航（VLN），有效解决了现有方法在处理复杂指令时的理解问题，并在A2A基准上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 农业机器人虽然功能强大，但在移动上仍高度依赖手动操作或固定轨道。现有的农业领域VLN方法（如AgriVLN）虽然能理解简单指令，但往往会误解复杂指令，这限制了其在实际应用中的自主导航能力。

Method: 作者提出了T-araVLN（Translator for Agricultural Robotic Agents on Vision-and-Language Navigation）方法。其核心是“指令翻译模块”（Instruction Translator），该模块能够将原始指令翻译成更精炼和精确的版本，从而提高机器人对复杂指令的理解能力。

Result: 在A2A基准测试中，T-araVLN显著提升了成功率（SR）从0.47到0.63，并将导航误差（NE）从2.91米降低到2.28米。这些结果表明该方法在农业领域实现了最先进的性能。

Conclusion: T-araVLN通过引入指令翻译模块，有效弥补了现有农业VLN方法在处理复杂指令方面的不足，显著提高了农业机器人的自主导航能力，并在相关基准上展现了卓越的性能。

Abstract: Agricultural robotic agents have been becoming powerful helpers in a wide
range of agricultural tasks, nevertheless, still heavily rely on manual
operation or untransportable railway for movement. The AgriVLN method and the
A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the
agricultural domain, enabling agents navigate to the target position following
the natural language instructions. AgriVLN effectively understands the simple
instructions, however, often misunderstands the complicated instructions. To
bridge this gap, we propose the method of Translator for Agricultural Robotic
Agents on Vision-and-Language Navigation (T-araVLN), in which the Instruction
Translator module translates the original instruction to be both refined and
precise. Being evaluated on the A2A benchmark, our T-araVLN effectively
improves SR from 0.47 to 0.63 and reduces NE from 2.91m to 2.28m, demonstrating
the state-of-the-art performance in the agricultural domain. Code:
https://github.com/AlexTraveling/T-araVLN.

</details>


### [324] [Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots](https://arxiv.org/abs/2509.06768)
*Oluwadamilola Sotomi,Devika Kodi,Kiruthiga Chandra Shekar,Aliasghar Arab*

Main category: cs.RO

TL;DR: 本文提出了一种多模态异常检测与缓解系统，通过集成视觉-语言模型和大型语言模型，使自主机器人在动态环境中实时识别、报告并主动缓解危险与冲突情况。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中运行的自主机器人需要识别和报告异常，并采取主动缓解措施以提高安全性和操作连续性。

Method: 该系统整合了视觉-语言模型（VLM）和大型语言模型（LLM），用于实时识别和报告危险情况及冲突。它将“危险”和“冲突”状态集成到机器人的决策框架中，针对不同类型的异常触发特定的缓解策略。系统采用边缘AI架构。

Result: 用户研究（n=30）表明，该系统在异常检测方面有效，预测准确率达91.2%，且响应时间延迟相对较低。

Conclusion: 该系统使机器人能够通过主动检测机制和自动化缓解措施，感知、解释、报告并响应城市和环境中的异常，从而提高了机器人在复杂环境中的自主性和安全性。

Abstract: Autonomous robots operating in dynamic environments should identify and
report anomalies. Embodying proactive mitigation improves safety and
operational continuity. This paper presents a multimodal anomaly detection and
mitigation system that integrates vision-language models and large language
models to identify and report hazardous situations and conflicts in real-time.
The proposed system enables robots to perceive, interpret, report, and if
possible respond to urban and environmental anomalies through proactive
detection mechanisms and automated mitigation actions. A key contribution in
this paper is the integration of Hazardous and Conflict states into the robot's
decision-making framework, where each anomaly type can trigger specific
mitigation strategies. User studies (n = 30) demonstrated the effectiveness of
the system in anomaly detection with 91.2% prediction accuracy and relatively
low latency response times using edge-ai architecture.

</details>


### [325] [CRISP -- Compliant ROS2 Controllers for Learning-Based Manipulation Policies and Teleoperation](https://arxiv.org/abs/2509.06819)
*Daniel San José Pro,Oliver Hausdörfer,Ralf Römer,Maximilian Dösch,Martin Schuck,Angela P. Schöllig*

Main category: cs.RO

TL;DR: CRISP是一个轻量级的C++顺应性笛卡尔和关节空间低级控制器，适用于ROS2机器人，旨在无缝集成高级学习策略和遥操作，提供统一的数据收集和策略执行流程。


<details>
  <summary>Details</summary>
Motivation: 基于学习的控制器（如扩散策略）通常生成低频或不连续的机器人状态变化，需要一个低级控制器将高级目标命令转换为关节力矩，以实现平滑的参考跟踪和接触交互中的顺应行为。

Method: 本文提出了CRISP，一个轻量级的C++实现，为ROS2控制标准设计了顺应性笛卡尔和关节空间控制器。它兼容任何暴露关节力矩接口的机械臂，并通过Python和Gymnasium接口提供统一的硬件和仿真数据记录以及高级学习策略部署管道。

Result: CRISP已在Frank Robotics FR3硬件上以及Kuka IIWA14和Kinova Gen3仿真中得到验证。它提供了一个统一的管道，用于数据收集和策略执行，实现了快速集成、灵活部署和实时性能。

Conclusion: CRISP通过提供一个统一的、易于集成的管道，降低了在ROS2兼容机械臂上应用基于学习方法的门槛，促进了快速实验，并支持顺应行为和实时性能。

Abstract: Learning-based controllers, such as diffusion policies and vision-language
action models, often generate low-frequency or discontinuous robot state
changes. Achieving smooth reference tracking requires a low-level controller
that converts high-level targets commands into joint torques, enabling
compliant behavior during contact interactions. We present CRISP, a lightweight
C++ implementation of compliant Cartesian and joint-space controllers for the
ROS2 control standard, designed for seamless integration with high-level
learning-based policies as well as teleoperation. The controllers are
compatible with any manipulator that exposes a joint-torque interface. Through
our Python and Gymnasium interfaces, CRISP provides a unified pipeline for
recording data from hardware and simulation and deploying high-level
learning-based policies seamlessly, facilitating rapid experimentation. The
system has been validated on hardware with the Franka Robotics FR3 and in
simulation with the Kuka IIWA14 and Kinova Gen3. Designed for rapid
integration, flexible deployment, and real-time performance, our implementation
provides a unified pipeline for data collection and policy execution, lowering
the barrier to applying learning-based methods on ROS2-compatible manipulators.
Detailed documentation is available at the project website -
https://utiasDSL.github.io/crisp_controllers.

</details>


### [326] [Dynamic Modeling and Efficient Data-Driven Optimal Control for Micro Autonomous Surface Vehicles](https://arxiv.org/abs/2509.06882)
*Zhiheng Chen,Wei Wang*

Main category: cs.RO

TL;DR: 本文提出了一种结合物理驱动动力学模型和数据驱动在线学习的优化控制框架，显著提高了微型自主水面航行器（MicroASV）在复杂环境下的轨迹跟踪精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 微型自主水面航行器（MicroASV）在狭窄或浅水域以及集群机器人应用中具有巨大潜力，但由于非线性水动力建模复杂、对自运动效应和环境干扰（如波浪、边界效应）敏感，实现精确和鲁棒的控制极具挑战性。

Method: 本文提出了一个过驱动MicroASV的物理驱动动力学模型，并引入了一个数据驱动的优化控制框架。该框架利用基于弱形式的在线模型学习方法，能够实时细化物理驱动模型，实现自适应控制以适应变化的系统参数。

Result: 仿真结果表明，所提出的方法显著提高了轨迹跟踪精度和鲁棒性，即使在未知载荷和外部干扰条件下也能表现出色。

Conclusion: 研究结果突出了数据驱动在线学习优化控制在提升MicroASV性能方面的潜力，为实现更可靠和精确的自主水面航行器操作铺平了道路。

Abstract: Micro Autonomous Surface Vehicles (MicroASVs) offer significant potential for
operations in confined or shallow waters and swarm robotics applications.
However, achieving precise and robust control at such small scales remains
highly challenging, mainly due to the complexity of modeling nonlinear
hydrodynamic forces and the increased sensitivity to self-motion effects and
environmental disturbances, including waves and boundary effects in confined
spaces. This paper presents a physics-driven dynamics model for an
over-actuated MicroASV and introduces a data-driven optimal control framework
that leverages a weak formulation-based online model learning method. Our
approach continuously refines the physics-driven model in real time, enabling
adaptive control that adjusts to changing system parameters. Simulation results
demonstrate that the proposed method substantially enhances trajectory tracking
accuracy and robustness, even under unknown payloads and external disturbances.
These findings highlight the potential of data-driven online learning-based
optimal control to improve MicroASV performance, paving the way for more
reliable and precise autonomous surface vehicle operations.

</details>


### [327] [LLaDA-VLA: Vision Language Diffusion Action Models](https://arxiv.org/abs/2509.06932)
*Yuqing Wen,Hebei Li,Kefan Gu,Yucheng Zhao,Tiancai Wang,Xiaoyan Sun*

Main category: cs.RO

TL;DR: LLaDA-VLA是首个基于预训练扩散视觉-语言模型（d-VLM）的视觉-语言-扩散-动作（VLA）模型，通过引入局部特殊token分类和分层动作结构解码策略，显著超越了现有最先进的VLA模型在机器人操作任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 自回归视觉-语言模型（VLM）的快速发展激发了对机器人操作中视觉-语言-动作（VLA）模型的兴趣。与此同时，掩码扩散模型在文本生成和多模态应用中展现出竞争力，并催生了一系列基于扩散的VLM（d-VLM）。然而，如何利用这些模型进行机器人策略学习仍未被充分探索。

Method: 本文提出了LLaDA-VLA，这是首个基于预训练d-VLM构建的视觉-语言-扩散-动作模型，用于机器人操作。为有效将d-VLM应用于机器人领域，引入了两项关键设计：1) 局部特殊token分类策略，用特殊动作token分类取代了全词汇分类，降低了适应难度；2) 分层动作结构解码策略，分层解码动作序列，同时考虑动作内部和动作之间的依赖关系。

Result: 广泛的实验表明，LLaDA-VLA在仿真和真实世界机器人上均显著优于现有最先进的VLA模型。

Conclusion: LLaDA-VLA成功将扩散视觉-语言模型应用于机器人操作，并通过创新的适应策略实现了卓越性能，证明了d-VLM在机器人策略学习领域的巨大潜力。

Abstract: The rapid progress of auto-regressive vision-language models (VLMs) has
inspired growing interest in vision-language-action models (VLA) for robotic
manipulation. Recently, masked diffusion models, a paradigm distinct from
autoregressive models, have begun to demonstrate competitive performance in
text generation and multimodal applications, leading to the development of a
series of diffusion-based VLMs (d-VLMs). However, leveraging such models for
robot policy learning remains largely unexplored. In this work, we present
LLaDA-VLA, the first Vision-Language-Diffusion-Action model built upon
pretrained d-VLMs for robotic manipulation. To effectively adapt d-VLMs to
robotic domain, we introduce two key designs: (1) a localized special-token
classification strategy that replaces full-vocabulary classification with
special action token classification, reducing adaptation difficulty; (2) a
hierarchical action-structured decoding strategy that decodes action sequences
hierarchically considering the dependencies within and across actions.
Extensive experiments demonstrate that LLaDA-VLA significantly outperforms
state-of-the-art VLAs on both simulation and real-world robots.

</details>


### [328] [F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions](https://arxiv.org/abs/2509.06951)
*Qi Lv,Weijie Kong,Hao Li,Jia Zeng,Zherui Qiu,Delin Qu,Haoming Song,Qizhi Chen,Xiang Deng,Jiangmiao Pang*

Main category: cs.RO

TL;DR: F1是一个预训练的VLA框架，它将视觉预见生成整合到决策过程中，以解决现有模型在动态视觉环境中反应迟钝和鲁棒性差的问题，并在各种任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要采用反应式的状态-动作映射，在动态场景中常导致短视行为和鲁棒性差，难以有效执行语言条件下的任务。

Method: F1引入了视觉预见生成到决策流程中，采用Mixture-of-Transformer架构，包含感知、预见生成和控制模块。它利用下一尺度预测机制合成目标导向的视觉预见作为显式规划目标，并将动作生成重新定义为预见引导的逆动力学问题。此外，F1采用三阶段训练方案，在一个包含超过330k轨迹和136个任务的广泛数据集上进行训练，以增强模块化推理和可迁移的视觉预见能力。

Result: F1在真实世界任务和模拟基准测试中持续优于现有方法，在任务成功率和泛化能力方面均取得了显著提升。

Conclusion: F1通过将视觉预见生成整合到决策流程中，并采用专门的架构和训练方案，有效解决了具身AI在动态视觉环境中执行语言条件任务的挑战，显著提高了模型的鲁棒性和泛化能力。

Abstract: Executing language-conditioned tasks in dynamic visual environments remains a
central challenge in embodied AI. Existing Vision-Language-Action (VLA) models
predominantly adopt reactive state-to-action mappings, often leading to
short-sighted behaviors and poor robustness in dynamic scenes. In this paper,
we introduce F1, a pretrained VLA framework which integrates the visual
foresight generation into decision-making pipeline. F1 adopts a
Mixture-of-Transformer architecture with dedicated modules for perception,
foresight generation, and control, thereby bridging understanding, generation,
and actions. At its core, F1 employs a next-scale prediction mechanism to
synthesize goal-conditioned visual foresight as explicit planning targets. By
forecasting plausible future visual states, F1 reformulates action generation
as a foresight-guided inverse dynamics problem, enabling actions that
implicitly achieve visual goals. To endow F1 with robust and generalizable
capabilities, we propose a three-stage training recipe on an extensive dataset
comprising over 330k trajectories across 136 diverse tasks. This training
scheme enhances modular reasoning and equips the model with transferable visual
foresight, which is critical for complex and dynamic environments. Extensive
evaluations on real-world tasks and simulation benchmarks demonstrate F1
consistently outperforms existing approaches, achieving substantial gains in
both task success rate and generalization ability.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [329] [Flight of Dynamic Targeting on the CogniSAT-6 Spacecraft](https://arxiv.org/abs/2509.05304)
*Steve Chien,Itai Zilberstein,Alberto Candela,David Rijlaarsdam,Tom Hendrix,Aubrey Dunne,Aragon Oriol,Miquel Juan Puig*

Main category: eess.SY

TL;DR: 动态目标瞄准（DT）是一种航天器自主概念，利用前瞻图像快速分析以驱动后续高质量成像，旨在避云、追踪风暴等，并计划于2025年初在CogniSAT-6上进行飞行演示。


<details>
  <summary>Details</summary>
Motivation: 提高近天底成像的质量，通过避免障碍物（如云层）或识别特定目标（如热异常、土地利用案例、风暴、行星边界层事件、羽流）来优化后续观测，实现航天器的自主决策能力。

Method: 该方法需要一个前瞻传感器（或将主传感器用于前瞻模式）、用于快速机载图像分析的边缘计算能力，以及一个主后续传感器。此外，还可以利用星间或低延迟通信链路进行跨平台任务分配。目前正在CogniSAT-6（于2024年3月发射）上实施，计划于2025年初进行飞行演示。

Result: 描述了动态目标瞄准（DT）的概念及其在低地球轨道（LEO）的应用场景，并介绍了在CogniSAT-6航天器上实施该概念的进展和计划于2025年初进行的飞行演示。

Conclusion: 动态目标瞄准（DT）是一个可行的航天器自主概念，能够通过快速分析传感器数据来优化后续观测，具有广泛的应用潜力，并已进入实际飞行演示的实施阶段。

Abstract: Dynamic targeting (DT) is a spacecraft autonomy concept in which sensor data
is acquired and rapidly analyzed and used to drive subsequent observation. We
describe the low Earth orbit application of this approach in which lookahead
imagery is analyzed to detect clouds, thermal anomalies, or land use cases to
drive higher quality near nadir imaging. Use cases for such a capability
include: cloud avoidance, storm hunting, search for planetary boundary layer
events, plume study, and beyond. The DT concept requires a lookahead sensor or
agility to use a primary sensor in such a mode, edge computing to analyze
images rapidly onboard, and a primary followup sensor. Additionally, an
inter-satellite or low latency communications link can be leveraged for cross
platform tasking. We describe implementation in progress to fly DT in early
2025 on the CogniSAT-6 (Ubotica/Open Cosmos) spacecraft that launched in March
2024 on the SpaceX Transporter-10 launch.

</details>


### [330] [A Fully Analog Implementation of Model Predictive Control with Application to Buck Converters](https://arxiv.org/abs/2509.05463)
*Simone Pirrera,Lorenzo Calogero,Francesco Gabriele,Diego Regruto,Alessandro Rizzo,Gianluca Setti*

Main category: eess.SY

TL;DR: 本文提出了一种设计模拟电路以实现模型预测控制（MPC）策略的新方法，用于仿射模型系统，并展示了其在DC-DC降压转换器中的卓越性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了实现低延迟、低复杂度的MPC策略，通过利用市售模拟元件构建模拟电路，以应对仿射模型系统。

Method: 本文提出了一种新颖的方法来设计模拟电子电路，以实现针对仿射模型的MPC策略。该方法结合了最先进的简化显式MPC（EMPC）方法，以实现使用有限数量低延迟、市售元件的模拟电路。

Result: 通过将其应用于DC-DC降压转换器的先进控制器设计，证明了所提方法的实用可行性和有效性。系统稳定性得到了正式分析，广泛的数值模拟表明，该方法能够实现出色的负载扰动抑制性能，超越了标准方法。

Conclusion: 所提出的模拟MPC设计方法对于仿射模型系统是可行且有效的，能够实现卓越的性能（如负载扰动抑制），并具有良好的稳定性，优于传统方法。

Abstract: This paper proposes a novel approach to design analog electronic circuits
that implement Model Predictive Control (MPC) policies for plants described by
affine models. The combination of state-of-the-art approaches to define
reduced-complexity Explicit MPC (EMPC) is employed to realize an analog circuit
characterized by a limited amount of low-latency and commercially available
components. The practical feasibility and effectiveness of the proposed
approach are demonstrated through its application in the design of an advanced
controller for DC-DC Buck converters. We formally analyze the stability of the
obtained system and conduct extensive numerical simulations to demonstrate that
it is capable of achieving outstanding load disturbance rejection performance,
outclassing standard approaches.

</details>


### [331] [State Estimation for Linear Systems with Non-Gaussian Measurement Noise via Dynamic Programming](https://arxiv.org/abs/2509.05482)
*Mohammad Hussein Yoosefian Nooshabadi,Laurent Lessard*

Main category: eess.SY

TL;DR: 本文提出了一种针对高斯过程噪声和非高斯测量噪声下线性动态系统的新型递归估计器，该估计器通过近似最大后验（MAP）估计、动态规划和凸分析实现，计算效率高且性能优于卡尔曼滤波器。


<details>
  <summary>Details</summary>
Motivation: 现有滤波器（如卡尔曼滤波器）在非高斯测量噪声条件下性能受限，且通常依赖于严格的噪声假设。本研究旨在开发一种不依赖此类假设、计算高效且性能优越的递归估计器。

Method: 本文提出了一种近似最大后验（MAP）估计器，利用动态规划和凸分析工具。该方法采用类似贝尔曼方程的更新方式，而非传统的贝叶斯更新。

Result: 仿真结果表明，所提出的估计器比卡尔曼滤波器具有更低的均方根误差（RMSE），与最先进的估计器性能相当，但计算功耗显著降低。

Conclusion: 所提出的递归估计器在处理高斯过程噪声和非高斯测量噪声的线性动态系统时，具有计算效率高、准确性好（低RMSE）的优点，且对噪声假设不敏感，是一种有前景的解决方案。

Abstract: We propose a new recursive estimator for linear dynamical systems under
Gaussian process noise and non-Gaussian measurement noise. Specifically, we
develop an approximate maximum a posteriori (MAP) estimator using dynamic
programming and tools from convex analysis. Our approach does not rely on
restrictive noise assumptions and employs a Bellman-like update instead of a
Bayesian update. Our proposed estimator is computationally efficient, with only
modest overhead compared to a standard Kalman filter. Simulations demonstrate
that our estimator achieves lower root mean squared error (RMSE) than the
Kalman filter and has comparable performance to state-of-the-art estimators,
while requiring significantly less computational power.

</details>


### [332] [Hierarchical Decision-Making in Population Games](https://arxiv.org/abs/2509.05808)
*Yu-Wen Chen,Nuno C. Martins,Murat Arcak*

Main category: eess.SY

TL;DR: 本文提出了一种分层群体博弈框架，其中个体将决策权委托给代理，代理基于自身利益行事，以模拟多层决策场景。该框架建立了均衡性质和收敛结果，并提供了一种分析具有一般凸约束的群体博弈的新方法，无需个体完全了解约束。


<details>
  <summary>Details</summary>
Motivation: 经典的群体博弈假设个体直接决策，但现实世界中存在多层决策和代理委托。此外，现有处理凸约束的方法要求个体对约束有完全了解，这通常是不现实的。

Method: 引入了一个分层群体博弈框架，其中个体将决策委托给具有自身战略利益的代理。针对所提出的分层结构，建立了均衡性质并提供了收敛结果。基于这些结果，开发了一种系统方法来分析具有一般凸约束的群体博弈。

Result: 成功建立了所提出的分层结构的均衡性质和收敛结果。开发了一种系统方法，可以分析具有一般凸约束的群体博弈，且无需个体像现有方法那样完全了解约束。通过一个带有容量约束的导航应用进行了案例研究。

Conclusion: 该分层框架扩展了经典群体博弈，能更好地捕捉现实世界中的多层决策。它提供了一种更实用、更少信息需求的方法来分析具有复杂约束的群体博弈，具有广泛的应用潜力。

Abstract: This paper introduces a hierarchical framework for population games, where
individuals delegate decision-making to proxies that act within their own
strategic interests. This framework extends classical population games, where
individuals are assumed to make decisions directly, to capture various
real-world scenarios involving multiple decision layers. We establish
equilibrium properties and provide convergence results for the proposed
hierarchical structure. Additionally, based on these results, we develop a
systematic approach to analyze population games with general convex
constraints, without requiring individuals to have full knowledge of the
constraints as in existing methods. We present a navigation application with
capacity constraints as a case study.

</details>


### [333] [Real-Time Single-Iteration Model Predictive Control for Wave Energy Converters](https://arxiv.org/abs/2509.05853)
*Simone Pirrera,Nicolas Faedo,Sophie M. Fosson,Diego Regruto*

Main category: eess.SY

TL;DR: 本文提出了一种新型实时算法，用于控制波浪能转换器（WECs），该算法基于经济模型预测控制（MPC）和一种新颖的一阶优化方法，通过单次迭代MPC实现，并在理论和仿真中表现出优于标准MPC的性能，尤其是在处理更快的采样率方面。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了开发一种高效的实时算法来控制波浪能转换器（WECs），以提高其性能，尤其是在经济模型预测控制（MPC）的框架下，并克服标准MPC在处理快速采样率方面的局限性。

Method: 研究方法包括：首先，采用经济模型预测控制（MPC）问题公式化；其次，应用一种受最新基于控制的约束优化算法启发的新颖的一阶优化算法；然后，根据单次迭代MPC方法定义控制器动力学；最后，对所用算法的收敛性及其计算复杂性进行理论分析。

Result: 使用基准WEC系统进行的仿真结果表明，所提出的方法显著优于标准MPC。这主要得益于该方法固有的处理更快采样率的能力。

Conclusion: 本文提出的新型实时控制算法能够显著提升波浪能转换器（WECs）的性能，尤其是在需要更快采样率的应用场景中，其表现优于传统的模型预测控制方法。

Abstract: This paper proposes a novel real-time algorithm for controlling wave energy
converters (WECs). We begin with the economic model predictive control (MPC)
problem formulation and apply a novel, first-order optimization algorithm
inspired by recently developed control-based algorithms for constrained
optimization to define the controller dynamics according to the
single-iteration MPC approach. We theoretically analyse the convergence of the
employed algorithm and the computational complexity of the obtained controller.
Results from simulations using a benchmark WEC system indicate that the
proposed approach significantly outperforms standard MPC, thanks to the
inherent ability to handle faster sampling rates.

</details>


### [334] [A Dynamic Programming Framework for Vehicular Task Offloading with Successive Action Improvement](https://arxiv.org/abs/2509.05907)
*Qianren Li,Yuncong Hong,Bojie Lv,Rui Wang*

Main category: eess.SY

TL;DR: 本文通过新颖的动态规划框架，优化了随机速度车辆的任务卸载问题，提出了一种双时间尺度调度方案，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 由于车辆速度随机，其精确轨迹无法预先确定，导致传统的确定性优化方法难以有效解决车辆网络中的任务卸载、小区关联、上行链路时间及吞吐量分配问题。

Method: 将多车辆在任务卸载期间的小区关联、上行链路时间及吞吐量分配建模为有限时域马尔可夫决策过程。为降低计算复杂度，提出双时间尺度框架：在每个“超槽”开始时，通过确定性优化获得参考调度方案和近似最优值函数；在“超槽”内部，根据系统状态通过对近似值函数进行改进来确定每个“时隙”的实际调度动作，并推导出了非平凡的平均成本上限。

Result: 通过高保真交通模拟器生成随机车辆轨迹进行仿真，结果表明所提出的调度框架相比基线方案具有显著的性能提升。

Conclusion: 所提出的基于动态规划的双时间尺度调度框架能够有效优化随机速度车辆的任务卸载，显著提升了车辆网络的性能。

Abstract: In this paper, task offloading from vehicles with random velocities is
optimized via a novel dynamic programming framework. Particularly, in a
vehicular network with multiple vehicles and base stations (BSs), computing
tasks of vehicles are offloaded via BSs to an edge server. Due to the random
velocities, the exact locations of vehicles versus time, namely trajectories,
cannot be determined in advance. Hence, instead of deterministic optimization,
the cell association, uplink time, and throughput allocation of multiple
vehicles during a period of task offloading are formulated as a finite-horizon
Markov decision process. In order to derive a low-complexity solution
algorithm, a two-time-scale framework is proposed. The scheduling period is
divided into super slots, each super slot is further divided into a number of
time slots. At the beginning of each super slot, we first obtain a reference
scheduling scheme of cell association, uplink time and throughput allocation
via deterministic optimization, yielding an approximation of the optimal value
function. Within the super slot, the actual scheduling action of each time slot
is determined by making improvement to the approximate value function according
to the system state. Due to the successive improvement framework, a non-trivial
average cost upper bound could be derived. In the simulation, the random
trajectories of vehicles are generated from a high-fidelity traffic simulator.
It is shown that the performance gain of the proposed scheduling framework over
the baselines is significant.

</details>


### [335] [Certifying the Nonexistence of Feasible Path Between Power System Operating Points](https://arxiv.org/abs/2509.05935)
*Mohammad Rasoul Narimani,Katherine R. Davis,Daniel K. Molzahn*

Main category: eess.SY

TL;DR: 本文提出一种算法，用于证明最优潮流（OPF）可行空间内两个运行点之间转换的不可行性，从而识别断开的可行区域。


<details>
  <summary>Details</summary>
Motivation: 最优潮流（OPF）问题是电力系统运行的核心，但由于OPF可行空间可能包含多个不连通的组件，导致在不同组件间的运行点转换变得具有挑战性，且可能违反OPF约束。现有研究主要关注可靠地计算高质量OPF解，而非评估运行点之间转换的可行性。

Method: 该算法首先在连接一对可行点的直线上寻找一个不可行点，以指示潜在的断开性。然后，通过使用凸松弛和边界收紧技术，算法证明垂直于该直线的平面上的所有点都是不可行的，从而认证可行空间的断开性。

Result: 利用该算法，本文首次为各种OPF测试案例提供了断开可行空间的认证。

Conclusion: 该算法成功地认证了OPF可行空间的断开性，这对于理解电力系统运行点之间的转换限制具有重要意义。

Abstract: By providing the optimal operating point that satisfies both the power flow
equations and engineering limits, the optimal power flow (OPF) problem is
central to the operation of electric power systems. While extensive research
efforts have focused on reliably computing high-quality OPF solutions,
assessing the feasibility of transitioning between operating points remains
challenging since the feasible spaces of OPF problems may consist of multiple
disconnected components. It is not possible to transition between operating
points in different disconnected components without violating OPF constraints.
To identify such situations, this paper introduces an algorithm for certifying
the infeasibility of transitioning between two operating points within an OPF
feasible space. As an indication of potential disconnectedness, the algorithm
first seeks an infeasible point on the line connecting a pair of feasible
points. The algorithm then certifies disconnectedness by using convex
relaxation and bound tightening techniques to show that all points on the plane
that is normal to this line are infeasible. Using this algorithm, we provide
the first certifications of disconnected feasible spaces for a variety of OPF
test cases.

</details>


### [336] [Mutual Support by Sensor-Attacker Team for a Passive Target](https://arxiv.org/abs/2509.06092)
*Prajakta Surve,Shaunak D. Bopardikar,Alexander Von Moll,Isaac Weintraub,David W. Casbeer*

Main category: eess.SY

TL;DR: 本文提出并解决了一个传感器-攻击者团队与一个移动目标在无限欧几里得平面上的追逐游戏，其中目标速度介于传感器和攻击者之间。研究旨在设计最优策略、刻画可感知区域以及确定目标被捕获或逃脱的速度界限。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于引入一种新颖的追逐游戏设定，其中包含传感器保持目标在感知范围内以便攻击者捕获，而目标则试图逃脱的动态。该设定考虑了不同参与者之间的速度差异，并旨在为这种复杂交互提供理论解决方案。

Method: 该问题被建模并解决为一种“类型博弈”（game of kind），其中目标采用开环策略（被动目标）。研究方法包括设计传感器和攻击者的最优策略（传感器最大化目标在感知范围内的持续时间，攻击者使用比例导航），刻画“可感知区域”，并推导目标速度的上下界以确定捕获或逃脱条件。

Result: 主要结果包括：1) 提出了传感器和攻击者的最优策略；2) 刻画了“可感知区域”，并证明当且仅当攻击者和目标之间的阿波罗尼斯圆完全包含在该区域内时，捕获才能得到保证；3) 推导了目标速度的下限，低于该下限捕获是必然的，以及在任意初始方向下目标速度的上限，高于该上限目标存在逃脱策略；4) 对于给定的初始方向，提出了一个更精确的目标速度上限，高于该上限目标存在逃脱策略。

Conclusion: 本研究为传感器-攻击者团队与目标之间的追逐游戏提供了一个全面的分析框架。通过设计最优策略、刻画关键区域和确定速度界限，该工作明确了在不同初始条件和速度比下，目标被捕获或成功逃脱的条件，为类似场景的控制和规划提供了理论基础。

Abstract: We introduce a pursuit game played between a team of a sensor and an attacker
and a mobile target in the unbounded Euclidean plane. The target is faster than
the sensor, but slower than the attacker. The sensor's objective is to keep the
target within a sensing radius so that the attacker can capture the target,
whereas the target seeks to escape by reaching beyond the sensing radius from
the sensor without getting captured by the attacker. We assume that as long as
the target is within the sensing radius from the sensor, the sensor-attacker
team is able to measure the target's instantaneous position and velocity. We
pose and solve this problem as a \emph{game of kind} in which the target uses
an open-loop strategy (passive target). Aside from the novel formulation, our
contributions are four-fold. First, we present optimal strategies for both the
sensor and the attacker, according to their respective objectives.
Specifically, we design a sensor strategy that maximizes the duration for which
the target remains within its sensing range, while the attacker uses
proportional navigation to capture the target. Second, we characterize the
\emph{sensable region} -- the region in the plane in which the target remains
within the sensing radius of the sensor during the game -- and show that
capture is guaranteed {if and only if} the Apollonius circle between the
attacker and the target is fully contained within this region. Third, we
{derive a lower bound} on the target's speed below which capture is guaranteed,
and an upper bound on the target speed above which there exists an escape
strategy for the target, from an arbitrary initial orientation between the
agents. Fourth, for a given initial orientation between the agents, we present
a sharper upper bound on the target speed above which there exists an escape
strategy for the target.

</details>


### [337] [DNN-based Digital Twin Framework of a DC-DC Buck Converter using Spider Monkey Optimization Algorithm](https://arxiv.org/abs/2509.06279)
*Tahmin Mahmud,Euzeli Cipriano Dos Santos Jr*

Main category: eess.SY

TL;DR: 本文提出了一种基于数据驱动的数字孪生框架（SMO+DNN），用于DC-DC降压转换器组件老化监测与预测，显著提高了预测准确性和转换器性能。


<details>
  <summary>Details</summary>
Motivation: 电力电子转换器系统（PECS）中的组件老化直接影响其可靠性、性能和使用寿命，在电动汽车、可再生能源系统和工业自动化等领域尤为关键。因此，理解和监测组件老化对于开发稳健的转换器和实现长期系统可靠性至关重要。

Method: 本文提出了一种用于DC-DC降压转换器的数据驱动数字孪生（DT）框架，该框架将深度神经网络（DNN）与蜘蛛猴优化（SMO）算法相结合（SMO+DNN），以监测和预测组件退化。研究利用低功率原型测试平台以及经验和合成数据集进行验证。

Result: SMO+DNN方法在95%的试验中达到全局最优，迭代次数减少33%，参数约束违反减少80%，优于传统方法。DNN模型在所有关键退化参数上R^2分数均高于0.998，并能准确预测故障时间（t_failure）。此外，经SMO调优的退化曲线使转换器性能提升，电压纹波减少20-25%，电感电流纹波减少15-20%。

Conclusion: 所提出的SMO+DNN数据驱动数字孪生框架能够有效监测和预测DC-DC降压转换器组件的退化，不仅提高了预测准确性，还通过优化退化曲线提升了转换器的性能。

Abstract: Component ageing is a critical concern in power electronic converter systems
(PECSs). It directly impacts the reliability, performance, and operational
lifespan of converters used across diverse applications, including electric
vehicles (EVs), renewable energy systems (RESs) and industrial automation.
Therefore, understanding and monitoring component ageing is crucial for
developing robust converters and achieving long-term system reliability. This
paper proposes a data-driven digital twin (DT) framework for DC-DC buck
converters, integrating deep neural network (DNN) with the spider monkey
optimization (SMO) algorithm to monitor and predict component degradation.
Utilizing a low-power prototype testbed along with empirical and synthetic
datasets, the SMO+DNN approach achieves the global optimum in 95% of trials,
requires 33% fewer iterations, and results in 80% fewer parameter constraint
violations compared to traditional methods. The DNN model achieves $R^2$ scores
above 0.998 for all key degradation parameters and accurately forecasts time to
failure ($t_{failure}$). In addition, SMO-tuned degradation profile improves
the converter's performance by reducing voltage ripple by 20-25% and inductor
current ripple by 15-20%.

</details>


### [338] [Enhancing Low-Altitude Airspace Security: MLLM-Enabled UAV Intent Recognition](https://arxiv.org/abs/2509.06312)
*Guangyu Lei,Tianhao Liang,Yuqi Ping,Xinglin Chen,Longyu Zhou,Junwei Wu,Xiyuan Zhang,Huahao Ding,Xingjian Zhang,Weijie Yuan,Tingting Zhang,Qinyu Zhang*

Main category: eess.SY

TL;DR: 本文提出了一种基于多模态大语言模型（MLLM）的无人机意图识别架构，以解决低空经济中非合作无人机感知和意图识别的关键需求，并通过一个低空对抗用例验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 低空经济的快速发展对非合作无人机的有效感知和意图识别提出了迫切需求。多模态大语言模型（MLLM）的先进生成推理能力为此类任务提供了有前景的解决方案。

Method: 本文首先提出了一个基于MLLM的无人机意图识别架构。该架构利用多模态感知系统获取无人机的实时载荷和运动信息，生成结构化输入。随后，MLLM结合环境信息、先验知识和战术偏好输出意图识别结果。文章还回顾了相关工作，并通过一个低空对抗用例演示了该架构的可行性。

Result: 通过低空对抗用例，本文验证了所提出架构的可行性，并为实际系统设计提供了有价值的见解。

Conclusion: 文章讨论了未来的挑战，并提出了相应的战略建议，以促进该架构在进一步应用中的发展。

Abstract: The rapid development of the low-altitude economy emphasizes the critical
need for effective perception and intent recognition of non-cooperative
unmanned aerial vehicles (UAVs). The advanced generative reasoning capabilities
of multimodal large language models (MLLMs) present a promising approach in
such tasks. In this paper, we focus on the combination of UAV intent
recognition and the MLLMs. Specifically, we first present an MLLM-enabled UAV
intent recognition architecture, where the multimodal perception system is
utilized to obtain real-time payload and motion information of UAVs, generating
structured input information, and MLLM outputs intent recognition results by
incorporating environmental information, prior knowledge, and tactical
preferences. Subsequently, we review the related work and demonstrate their
progress within the proposed architecture. Then, a use case for low-altitude
confrontation is conducted to demonstrate the feasibility of our architecture
and offer valuable insights for practical system design. Finally, the future
challenges are discussed, followed by corresponding strategic recommendations
for further applications.

</details>


### [339] [First-Principle Modeling Framework of Boost Converter Dynamics for Precise Energy Conversions in Space](https://arxiv.org/abs/2509.06425)
*Yifan Wang,Wenhua Li,Zhenlong Wang,Xinrui Zhang,Jianfeng Sun,Qianfu Xia,Zhongtao Gou,Jiangang Rong,Tao Ye*

Main category: eess.SY

TL;DR: 本研究提出了一种基于第一性原理的升压变换器建模框架，通过考虑非理想元件耦合，显著提高了对瞬态行为的预测精度，并成功应用于太空能源转换。


<details>
  <summary>Details</summary>
Motivation: 传统的升压变换器模型依赖稳态假设，无法准确预测输入电压和负载波动时的瞬态行为，导致输出电压过冲和系统不稳定，限制了其在空间等关键领域的应用。

Method: 本研究引入了一种第一性原理建模框架，通过结合非理想元件耦合，推导出了升压变换器的精确动态方程。

Result: 与现有最精确的模型相比，所提出的模型在输入电压变化下，将实验与仿真输出电压之间的稳态误差降低了11.0倍（从20.9%降至1.9%），动态误差降低了15.4倍（从77.1%降至5.0%）。在负载变化下，稳态误差降低了10.2倍（从15.3%降至1.5%），动态误差降低了35.1倍（从42.1%降至1.2%）。

Conclusion: 所提出的模型显著提高了升压变换器在瞬态条件下的预测精度和可靠性，并成功设计了一个可靠的升压变换器并已在轨部署，用于精确的能量转换。

Abstract: Boost converters are essential for modern electrification and intelligent
technologies. However, conventional Boost converter models relying on
steady-state assumptions fail to accurately predict transient behaviors during
input voltage and load fluctuations, which cause significant output voltage
overshoots and instability, resulting in failures of electrical systems,
thereby restricting their use in space. This study introduces a first-principle
modeling framework that derives precise dynamic equations for Boost converters
by incorporating non-ideal component coupling. As compared to the most accurate
existing Boost converter model, the proposed models reduce steady-state and
dynamic-state errors between experimental and simulated output voltages by
factors of 11.0 (from 20.9% to 1.9%) and 15.4 (from 77.1% to 5.0%) under input
voltage variations, and by factors of 10.2 (from 15.3% to 1.5%) and 35.1 (from
42.1% to 1.2%) under load changes, respectively. Consequently, a reliable Boost
converter is accordingly designed and on-orbit deployed for precise energy
conversions.

</details>


### [340] [Unified Graph-Theoretic Modeling of Multi-Energy Flows in Distribution Systems](https://arxiv.org/abs/2509.06447)
*Marwan Mostafa,Daniel Wenser,Payam Teimourzadeh Baboli,Christian Becker*

Main category: eess.SY

TL;DR: 本文提出了一种基于多层图的统一建模框架，用于分析电力、燃气和热力等多能源系统，并开发了基于牛顿-拉夫逊法的稳态求解器，成功应用于实际案例并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于部门耦合和脱碳导致能源系统日益复杂，需要统一的建模框架来捕捉电力、燃气和热力网络之间的物理和结构相互作用。

Method: 该研究采用基于图的建模方法，将每个能源领域表示为多层图中的一个层，耦合技术通过专用耦合层建模为层间边。开发了一个基于块结构牛顿-拉夫逊方法的稳态求解器，用于联合计算所有载体的流量和状态变量。

Result: 该模型在一个基于德国配电网络数据的真实案例研究中进行了测试和验证。结果表明，该方法具有收敛性、数值精度和一致的域交互，并证明了其在系统范围分析中的适用性。

Conclusion: 该方法可作为集成能源系统未来优化的基础，具有在系统范围分析中的应用潜力。

Abstract: The increasing complexity of energy systems due to sector coupling and
decarbonization calls for unified modeling frameworks that capture the physical
and structural interactions between electricity, gas, and heat networks. This
paper presents a graph-based modeling approach for multi-energy systems, where
each domain is represented as a layer in a multi-layer graph, and coupling
technologies are modeled as inter-layer edges via a dedicated coupling layer. A
steady-state solver based on a block-structured Newton-Raphson method is
developed to jointly compute flows and state variables across all carriers. The
proposed model is tested and validated on a realistic case study based on data
from a German distribution network. The results demonstrate convergence,
numerical accuracy, and consistent domain interaction, and demonstrate the
method's applicability for system-wide analysis and its potential as a
foundation for future optimizations in integrated energy systems.

</details>


### [341] [Parameter Robustness in Data-Driven Estimation of Dynamical Systems](https://arxiv.org/abs/2509.06534)
*Ayush Pandey*

Main category: eess.SY

TL;DR: 本文研究了系统估计对参数扰动的鲁棒性，并提出了一种新的鲁棒性度量来量化参数不确定性。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于理解和量化系统动力学和初始条件中参数扰动对系统估计鲁棒性的影响，从而解决动态系统估计中的敏感性参数不确定性问题。

Method: 本文开发了一种新颖的鲁棒性度量，用于参数化线性动态系统的估计（无论有无控制作用）。在计算此度量时，作者区分了来自控制作用、系统动力学和初始条件的不确定性贡献。此外，还通过与现有模型降阶鲁棒性文献的联系来验证理论发现。

Result: 主要成果是开发并计算了一种针对参数化线性动态系统估计的新型鲁棒性度量，并明确了控制作用、系统动力学和初始条件对不确定性的贡献。同时，建立了这些新结果与模型降阶鲁棒性现有文献之间的联系。

Conclusion: 这项工作为根据可容忍的参数不确定性水平选择估计方法提供了指导，并为数据驱动估计中新的成本函数奠定了基础，这些成本函数可以奖励对所需参数子集的敏感性，同时惩罚其他参数。

Abstract: We study the robustness of system estimation to parametric perturbations in
system dynamics and initial conditions. We define the problem of
sensitivity-based parametric uncertainty quantification in dynamical system
estimation. The main contribution of this paper is the development of a novel
robustness metric for estimation of parametrized linear dynamical systems with
and without control actions. For the computation of this metric, we delineate
the uncertainty contributions arising from control actions, system dynamics,
and initial conditions. Furthermore, to validate our theoretical findings, we
establish connections between these new results and the existing literature on
the robustness of model reduction. This work provides guidance for selecting
estimation methods based on tolerable levels of parametric uncertainty and
paves the way for new cost functions in data-driven estimation that reward
sensitivity to a desired subset of parameters while penalizing others.

</details>


### [342] [Wireless Low-Latency Synchronization for Body-Worn Multi-Node Systems in Sports](https://arxiv.org/abs/2509.06541)
*Nico Krull,Lukas Schulthess,Michele Magno,Luca Benini,Christoph Leitner*

Main category: eess.SY

TL;DR: 本研究评估了Nordic Enhanced ShockBurst (ESB) 协议在受控实验室条件下实现无线、低延迟命令广播的性能，发现其能提供亚毫秒级同步，显著优于蓝牙低功耗 (BLE)，适用于体育领域中高频生物信号的多节点可穿戴系统。


<details>
  <summary>Details</summary>
Motivation: 体育运动中的生物力学数据采集需要分布式穿戴式传感器节点之间达到亚毫秒级的同步，以确保高频生物信号（500 Hz至1000 Hz）的精确事件对齐和数据融合。

Method: 研究在受控实验室条件下，通过系统性地分析协议参数（包括循环冗余校验模式、比特率、传输模式和负载处理），对Nordic Semiconductor的Enhanced ShockBurst (ESB) 协议进行了评估和特性描述。

Result: 通过优化重传并使用一个字节的负载，实现了平均设备到设备 (D2D) 延迟为 504.99 ± 96.89 微秒，网络到网络核心延迟为 311.78 ± 96.90 微秒。这一性能显著优于受限于 7.5 毫秒连接间隔的蓝牙低功耗 (BLE)。

Conclusion: ESB 协议被证明是体育领域中时间敏感、多节点可穿戴系统的可行解决方案，能够实现精确的事件对齐和可靠的高速数据融合，适用于高级运动员监测和反馈应用。

Abstract: Biomechanical data acquisition in sports demands sub-millisecond
synchronization across distributed body-worn sensor nodes. This study evaluates
and characterizes the Enhanced ShockBurst (ESB) protocol from Nordic
Semiconductor under controlled laboratory conditions for wireless, low-latency
command broadcasting, enabling fast event updates in multi-node systems.
Through systematic profiling of protocol parameters, including
cyclic-redundancy-check modes, bitrate, transmission modes, and payload
handling, we achieve a mean Device-to-Device (D2D) latency of 504.99 +- 96.89
us and a network-to-network core latency of 311.78 +- 96.90 us using a one-byte
payload with retransmission optimization. This performance significantly
outperforms Bluetooth Low Energy (BLE), which is constrained by a 7.5 ms
connection interval, by providing deterministic, sub-millisecond
synchronization suitable for high-frequency (500 Hz to 1000 Hz) biosignals.
These results position ESB as a viable solution for time-critical, multi-node
wearable systems in sports, enabling precise event alignment and reliable
high-speed data fusion for advanced athlete monitoring and feedback
applications.

</details>


### [343] [Distributed Automatic Generation Control subject to Ramp-Rate-Limits: Anytime Feasibility and Uniform Network-Connectivity](https://arxiv.org/abs/2509.06588)
*Mohammadreza Doostmohammadian,Hamid R. Rabiee*

Main category: eess.SY

TL;DR: 本文提出了一种基于信息共识算法的多智能体分布式自动发电控制方案，解决了现有方法中忽略发电机爬坡速率限制（RRL）的问题，并确保了算法的随时可行性。


<details>
  <summary>Details</summary>
Motivation: 现有线性/非线性优化解决方案通常忽略了发电机在实际发电场景中存在的爬坡速率限制（RRL）。这导致发电机无法按照优化算法分配的发电速率运行，可能导致现有解决方案无法收敛到精确的最优成本或在实践中失去可行性。

Method: 该方案将自动发电控制视为一个多智能体系统，通过基于信息共识算法的分布式优化来解决问题。它在算法的所有迭代时间内同时处理了爬坡速率限制（RRL）、发电功率的盒约束（上下限）以及发电-需求平衡的耦合约束（确保随时可行性）。此外，为了提高算法的收敛速度，引入了基于符号函数（signum-based）的非线性。

Result: 该解决方案能够有效地处理发电机爬坡速率限制，确保算法在任何终止点都能保持发电与需求之间的平衡（随时可行性）。同时，它还展示了对通信链路移除的容错能力。

Conclusion: 本文提出的分布式自动发电控制方案，通过考虑发电机爬坡速率限制和确保随时可行性，克服了现有方法的局限性。结合符号函数非线性提高了收敛速度，并证明了其对通信故障的鲁棒性，使其在实际电力生成场景中更具实用性和可靠性。

Abstract: This paper considers automatic generation control over an information-sharing
network of communicating generators as a multi-agent system. The optimization
solution is distributed among the agents based on information consensus
algorithms, while addressing the generators' ramp-rate-limits (RRL). This is
typically ignored in the existing linear/nonlinear optimization solutions but
they exist in real-time power generation scenarios. Without addressing the RRL,
the generators cannot follow the assigned rate of generating power by the
optimization algorithm; therefore, the existing solutions may not necessarily
converge to the exact optimal cost or may lose feasibility in practice. The
proposed solution in this work addresses the ramp-rate-limit constraint along
with the box constraint (limits on the generated powers) and the
coupling-constraint (generation-demand balance) at all iteration times of the
algorithm. The latter is referred to as the anytime feasibility and implies
that at every termination point of the algorithm, the balance between the
demand and generated power holds. To improve the convergence rate of the
algorithm we further consider internal signum-based nonlinearity. We also show
that our solution can tolerate communication link removal. This follows from
the uniform-connectivity assumption on the communication network.

</details>


### [344] [Human-Hardware-in-the-Loop simulations for systemic resilience assessment in cyber-socio-technical systems](https://arxiv.org/abs/2509.06657)
*Francesco Simone,Marco Bortolini,Giovanni Mazzuto,Giulio di Gravio,Riccardo Patriarca*

Main category: eess.SY

TL;DR: 本文提出了一种人机硬件在环（HHIL）建模与仿真框架，用于更真实、全面地评估复杂工业系统（特别是受网络攻击的油气工厂）的系统韧性，并量化操作员行为对系统性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现代工业系统日益复杂，网络物理、人与组织因素紧密交织，传统安全管理方法不足以应对。现有基于仿真的方法难以真实反映人类行为及其对系统性能的影响，因此需要新的方法来务实地解决复杂行为和系统韧性管理问题。

Method: 该研究以系统理论事故模型与过程（STAMP）为基础，提出了一种人机硬件在环（HHIL）建模与仿真框架。此框架旨在克服传统仿真在代表人行为方面的局限性，从而支持对系统韧性进行更真实和全面的评估。该方法在一个遭受网络攻击的实验性油气工厂中进行了测试，涉及专家和新手两种操作员角色。

Result: 研究在实验性油气工厂中验证了HHIL方法，并成功量化了操作员行为（如专家和新手）变化对整体系统性能的影响。这为理解和实施复杂社会技术系统中的韧性提供了见解。

Conclusion: 该研究提供了一种量化评估操作员行为如何影响系统性能的手段，并为在复杂的社会技术系统中理解和实施韧性提供了深入见解。HHIL框架能够更真实、全面地评估系统韧性，尤其是在考虑人类因素时。

Abstract: Modern industrial systems require updated approaches to safety management, as
the tight interplay between cyber-physical, human, and organizational factors
has driven their processes toward increasing complexity. In addition to dealing
with known risks, managing system resilience acquires great value to address
complex behaviors pragmatically. This manuscript starts from the
System-Theoretic Accident Model and Processes (STAMP) as a modelling initiative
for such complexity. The STAMP can be natively integrated with simulation-based
approaches, which however fail to realistically represent human behaviors and
their influence on the system performance. To overcome this limitation, this
paper proposes a Human-Hardware-in-the-Loop (HHIL) modeling and simulation
framework aimed at supporting a more realistic and comprehensive assessments of
systemic resilience. The approach is tested on an experimental oil and gas
plant experiencing cyber-attacks, where two personas of operators (experts and
novices) work. This research provides a mean to quantitatively assess how
variations in operator behavior impact the overall system performance, offering
insights into how resilience should be understood and implemented in complex
socio-technical systems at large.

</details>


### [345] [Edge Server Monitoring for Job Assignment](https://arxiv.org/abs/2509.06722)
*Samuel Chamoun,Sirin Chakraborty,Eric Graves,Kevin Chan,Yin Sun*

Main category: eess.SY

TL;DR: 本文研究了边缘服务器监控中的目标导向通信问题，旨在通过将查询调度建模为RMAB并使用NGM算法，在有限通信资源下最大化作业成功率。


<details>
  <summary>Details</summary>
Motivation: 计算作业间歇性到达调度器并需立即分配给分布式边缘服务器。由于工作负载竞争和边缘环境的动态性，服务器可用性会随时间波动。调度器需要准确估计服务器可用状态，但查询通信资源有限。

Method: 调度器通过两种机制更新其对服务器可用性的信念：(i)通过共享通信通道进行主动查询；(ii)来自过去作业执行的反馈。查询调度问题被建模为具有多个动作的Restless Multi-Armed Bandit (RMAB)，并使用净收益最大化(NGM)调度算法解决，该算法根据预期执行性能改进选择要查询的服务器。

Result: 仿真结果表明，所提出的NGM策略显著优于基线策略，比轮询策略提高了30%，比从不查询策略提高了107%。

Conclusion: NGM策略在边缘服务器监控的目标导向通信中表现出色，能在有限通信资源下显著提高作业成功率。

Abstract: In this paper, we study a goal-oriented communication problem for edge server
monitoring, where compute jobs arrive intermittently at dispatchers and must be
immediately assigned to distributed edge servers. Due to competing workloads
and the dynamic nature of the edge environment, server availability fluctuates
over time. To maintain accurate estimates of server availability states, each
dispatcher updates its belief using two mechanisms: (i) active queries over
shared communication channels and (ii) feedback from past job executions. We
formulate a query scheduling problem that maximizes the job success rate under
limited communication resources for queries. This problem is modeled as a
Restless Multi-Armed Bandit (RMAB) with multiple actions and addressed using a
Net-Gain Maximization (NGM) scheduling algorithm, which selects servers to
query based on their expected improvement in execution performance. Simulation
results show that the proposed NGM Policy significantly outperforms baseline
strategies, achieving up to a 30% gain over the Round-Robin Policy and up to a
107% gain over the Never-Query Policy.

</details>


### [346] [Steering Opinion through Dynamic Stackelberg Optimization](https://arxiv.org/abs/2509.06758)
*Hossein Rastgoftar*

Main category: eess.SY

TL;DR: 本文利用Friedkin-Johnsen模型研究社交网络中的意见演化，将社会分为固执和普通两类主体。通过建立Stackelberg博弈，并结合二次规划和动态规划，最小化社会意见与期望集体意见的偏差。


<details>
  <summary>Details</summary>
Motivation: 在社交网络中，旨在通过控制固执主体和普通主体的行为，最小化社会集体意见与预设期望意见之间的偏差。

Method: 采用Friedkin-Johnsen (FJ) 模型描述意见动态；将社会分为固执主体和普通主体；构建一个Stackelberg博弈，其中固执主体的意见调整和普通主体的开放性是决策变量；使用二次规划和动态规划相结合的方法，通过前向和后向传播在每个离散时间步优化这些决策变量。

Result: 提出了一种整合二次规划和动态规划的解决方案，通过优化固执主体的意见调整和普通主体的开放性变量，以最小化社会意见与期望集体意见的偏差。

Conclusion: 该研究提供了一个基于Stackelberg博弈和混合优化方法（二次规划与动态规划）的框架，用于在Friedkin-Johnsen模型下控制社交网络中的意见演化，使其趋向于一个期望的集体意见。

Abstract: This paper employs the Friedkin-Johnsen (FJ) model to describe the dynamics
of opinion evolution within a social network. Under the FJ framework, the
society is divided into two subgroups that include stubborn agents and regular
agents. The opinions of stubborn agents are not influenced by regular agents,
whereas the opinions of regular agents evolve based on the opinions of their
neighboring agents. By defining the origin as the desired collective opinion of
the society, the objective of the paper is to minimize deviations from this
desired opinion. To achieve this, a Stackelberg game is established between the
stubborn and regular subgroups, where the opinion adjustments of the stubborn
agents and the openness variables of regular agents serve as the decision
variables. The proposed solution approach integrates quadratic programming and
dynamic programming to optimize these decision variables at each discrete time
step using forward and backward propagation.

</details>


### [347] [Agentic DDQN-Based Scheduling for Licensed and Unlicensed Band Allocation in Sidelink Networks](https://arxiv.org/abs/2509.06775)
*Po-Heng Chou,Pin-Qi Fu,Walid Saad,Li-Chun Wang*

Main category: eess.SY

TL;DR: 本文提出了一种基于智能体AI的DDQN调度框架，用于新空口旁链路（NR SL）网络中授权和非授权频段的分配，以解决共存挑战并提升服务质量。


<details>
  <summary>Details</summary>
Motivation: NR SL网络必须与蜂窝通信共享授权频谱，并与Wi-Fi共享非授权频段，这带来了显著的共存挑战。传统的基于规则或阈值的方法无法自主感知并适应网络动态以维持服务质量（QoS）。

Method: 本文提出了一种基于智能体AI的双深度Q网络（DDQN）调度框架。该智能调度器能够自主感知排队动态、信道条件和共存状态，并自适应地调整其策略以维持QoS。

Result: 仿真结果表明，在有限的授权带宽下，该框架与基于阈值的调度方法相比，阻塞率降低了高达87.5%。

Conclusion: 这些发现证明了智能体AI在未来NR SL系统中实现稳定、QoS感知和自适应调度的潜力。

Abstract: This paper presents an agentic artificial intelligence (AI)-driven double
deep Q-network (DDQN) scheduling framework for licensed and unlicensed band
allocation in New Radio (NR) sidelink (SL) networks. SL must share licensed
spectrum with cellular communications (CC) and unlicensed bands with Wi-Fi,
posing significant challenges for coexistence. Unlike prior rule-based or
threshold-based methods, the proposed agentic scheduler autonomously perceives
queueing dynamics, channel conditions, and coexistence states, and adapts its
policy to maintain quality-of-service (QoS). Simulation results show that our
framework reduces the blocking rate by up to 87.5% compared to threshold-based
scheduling under limited licensed bandwidth. These findings demonstrate the
potential of Agentic AI to enable stable, QoS-aware, and adaptive scheduling
for future NR SL systems.

</details>


### [348] [Reinforcement learning meets bioprocess control through behaviour cloning: Real-world deployment in an industrial photobioreactor](https://arxiv.org/abs/2509.06853)
*Juan D. Gil,Ehecatl Antonio Del Rio Chanona,José L. Guzmán,Manuel Berenguel*

Main category: eess.SY

TL;DR: 本文提出了一种结合强化学习（RL）和行为克隆（BC）的混合离线-在线控制策略，用于开放式光生物反应器（PBR）中的pH调节，相比传统PID和标准RL方法，显著提高了控制性能并降低了控制成本。


<details>
  <summary>Details</summary>
Motivation: 活细胞作为生产单元的固有复杂性以及开放式光生物反应器（PBRs）在波动环境下维持稳定和最佳生物工艺条件（尤其是pH）的挑战。

Method: 采用强化学习（RL）控制方法，结合行为克隆（BC），进行开放式PBR系统中的pH调节。该方法包括一个离线训练阶段，RL代理从名义PID控制器生成的轨迹中学习；以及一个每日在线微调阶段，以适应不断变化的工艺动态并抑制快速瞬态扰动。这是一种混合离线-在线策略。

Result: 模拟研究显示，与PID控制相比，积分绝对误差（IAE）降低了8%，与标准离策略RL相比降低了5%。控制工作量与PID相比大幅减少了54%，与标准RL相比减少了7%。为期8天的实验验证在不同环境条件下证实了该方法的鲁棒性和可靠性。

Conclusion: 该工作展示了基于RL的方法在生物过程控制中的潜力，并为它们更广泛地应用于其他非线性、易受扰动系统铺平了道路。

Abstract: The inherent complexity of living cells as production units creates major
challenges for maintaining stable and optimal bioprocess conditions, especially
in open Photobioreactors (PBRs) exposed to fluctuating environments. To address
this, we propose a Reinforcement Learning (RL) control approach, combined with
Behavior Cloning (BC), for pH regulation in open PBR systems. This represents,
to the best of our knowledge, the first application of an RL-based control
strategy to such a nonlinear and disturbance-prone bioprocess. Our method
begins with an offline training stage in which the RL agent learns from
trajectories generated by a nominal Proportional-Integral-Derivative (PID)
controller, without direct interaction with the real system. This is followed
by a daily online fine-tuning phase, enabling adaptation to evolving process
dynamics and stronger rejection of fast, transient disturbances. This hybrid
offline-online strategy allows deployment of an adaptive control policy capable
of handling the inherent nonlinearities and external perturbations in open
PBRs. Simulation studies highlight the advantages of our method: the Integral
of Absolute Error (IAE) was reduced by 8% compared to PID control and by 5%
relative to standard off-policy RL. Moreover, control effort decreased
substantially-by 54% compared to PID and 7% compared to standard RL-an
important factor for minimizing operational costs. Finally, an 8-day
experimental validation under varying environmental conditions confirmed the
robustness and reliability of the proposed approach. Overall, this work
demonstrates the potential of RL-based methods for bioprocess control and paves
the way for their broader application to other nonlinear, disturbance-prone
systems.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [349] [A Synthetic-to-Real Dehazing Method based on Domain Unification](https://arxiv.org/abs/2509.05374)
*Zhiqiang Yuan,Jinchao Zhang,Jie Zhou*

Main category: eess.IV

TL;DR: 本文提出了一种基于域统一的合成到真实去雾方法，以解决深度学习去雾模型在真实图像上因域偏移（源于不完美的干净数据收集）而性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习去雾方法在应用于真实世界的雾霾图像时，由于分布偏移，性能会受到不利影响。研究发现，这种真实与合成域之间的去雾任务偏差可能源于干净数据收集的不完美，导致大气物理模型在真实域和合成域之间不一致。

Method: 提出了一种基于域统一的合成到真实去雾方法，旨在统一真实域和合成域之间的关系，使去雾模型更符合实际情况。

Result: 大量的定性和定量实验表明，所提出的去雾方法在真实世界图像上显著优于现有最先进的方法。

Conclusion: 通过统一真实域和合成域之间的关系，该方法有效地解决了因干净数据收集不完美导致的大气物理模型不一致问题，从而显著提升了去雾模型在真实图像上的性能。

Abstract: Due to distribution shift, the performance of deep learning-based method for
image dehazing is adversely affected when applied to real-world hazy images. In
this paper, we find that such deviation in dehazing task between real and
synthetic domains may come from the imperfect collection of clean data. Owing
to the complexity of the scene and the effect of depth, the collected clean
data cannot strictly meet the ideal conditions, which makes the atmospheric
physics model in the real domain inconsistent with that in the synthetic
domain. For this reason, we come up with a synthetic-to-real dehazing method
based on domain unification, which attempts to unify the relationship between
the real and synthetic domain, thus to let the dehazing model more in line with
the actual situation. Extensive experiments qualitatively and quantitatively
demonstrate that the proposed dehazing method significantly outperforms
state-of-the-art methods on real-world images.

</details>


### [350] [Stabilizing RED using the Koopman Operator](https://arxiv.org/abs/2509.05736)
*Shraddha Chavan,Kunal N. Chaudhury*

Main category: eess.IV

TL;DR: 本文提出一种数据驱动的Koopman算子方法来稳定RED（Regularization-by-Denoising）框架，解决其因黑盒去噪器导致的潜在不稳定性。该方法通过捕获RED的局部动力学并利用算子谱半径自适应调整步长，实现模型无关、低开销且无需重新训练的稳定化。


<details>
  <summary>Details</summary>
Motivation: RED框架虽然能实现高保真重建，但由于使用了黑盒去噪器，有时会导致系统不稳定。

Method: 本文提出使用Koopman算子来稳定RED。具体而言，该方法利用Koopman算子捕获RED在低维特征空间中的局部动力学，并使用其谱半径来检测不稳定性。基于此，制定了一个自适应步长规则，该规则具有模型无关、开销适中且无需重新训练的特点。

Result: 通过对多种预训练去噪器进行测试，结果表明所提出的Koopman稳定化方法是有效的。

Conclusion: Koopman算子提供了一种有效的数据驱动机制，能够稳定RED框架，克服其潜在的不稳定性，同时保持模型无关、低开销和无需重新训练的优势。

Abstract: The widely used RED (Regularization-by-Denoising) framework uses pretrained
denoisers as implicit regularizers for model-based reconstruction. Although RED
generally yields high-fidelity reconstructions, the use of black-box denoisers
can sometimes lead to instability. In this letter, we propose a data-driven
mechanism to stabilize RED using the Koopman operator, a classical tool for
analyzing dynamical systems. Specifically, we use the operator to capture the
local dynamics of RED in a low-dimensional feature space, and its spectral
radius is used to detect instability and formulate an adaptive step-size rule
that is model-agnostic, has modest overhead, and requires no retraining. We
test this with several pretrained denoisers to demonstrate the effectiveness of
the proposed Koopman stabilization.

</details>


### [351] [CardiacFlow: 3D+t Four-Chamber Cardiac Shape Completion and Generation via Flow Matching](https://arxiv.org/abs/2509.05754)
*Qiang Ma,Qingjie Meng,Mengyun Qiao,Paul M. Matthews,Declan P. O'Regan,Wenjia Bai*

Main category: eess.IV

TL;DR: 本文利用流匹配技术（包括潜在整流流和CardiacFlow）从有限数据中实现3D+t心脏形状的增强、补全和生成，显著提高了几何精度和生成质量。


<details>
  <summary>Details</summary>
Motivation: 从多视角心脏磁共振（CMR）图像中学习3D+t形状补全和生成需要大量的、高分辨率的3D全心分割（WHS）数据来捕获形状先验，而这种数据获取困难。

Method: 1. 引入潜在整流流（latent rectified flow），从有限的3D WHS数据中学习并生成3D心脏形状，用于数据增强。 2. 训练一个标签补全网络，利用真实和合成数据从稀疏的多视角CMR分割中重建3D+t形状。 3. 提出CardiacFlow，一个新型一步式生成流模型，通过时间帧的周期性高斯核编码条件，高效生成3D+t四腔心脏形状。

Result: 基于流的数据增强将3D形状补全中的几何误差降低了16%。在UK Biobank数据集上的评估表明，CardiacFlow相比现有基线模型实现了卓越的生成质量和周期性一致性。

Conclusion: 流匹配技术能有效学习深度生成流，用于3D+t心脏形状的增强、补全和生成，尤其在数据量有限的情况下，显著提升了心脏形状建模的精度和质量。

Abstract: Learning 3D+t shape completion and generation from multi-view cardiac
magnetic resonance (CMR) images requires a large amount of high-resolution 3D
whole-heart segmentations (WHS) to capture shape priors. In this work, we
leverage flow matching techniques to learn deep generative flows for
augmentation, completion, and generation of 3D+t shapes of four cardiac
chambers represented implicitly by segmentations. Firstly, we introduce a
latent rectified flow to generate 3D cardiac shapes for data augmentation,
learnt from a limited number of 3D WHS data. Then, a label completion network
is trained on both real and synthetic data to reconstruct 3D+t shapes from
sparse multi-view CMR segmentations. Lastly, we propose CardiacFlow, a novel
one-step generative flow model for efficient 3D+t four-chamber cardiac shape
generation, conditioned on the periodic Gaussian kernel encoding of time
frames. The experiments on the WHS datasets demonstrate that flow-based data
augmentation reduces geometric errors by 16% in 3D shape completion. The
evaluation on the UK Biobank dataset validates that CardiacFlow achieves
superior generation quality and periodic consistency compared to existing
baselines.

</details>


### [352] [Brain Tumor Detection Through Diverse CNN Architectures in IoT Healthcare Industries: Fast R-CNN, U-Net, Transfer Learning-Based CNN, and Fully Connected CNN](https://arxiv.org/abs/2509.05821)
*Mohsen Asghari Ilani,Yaser M. Banad*

Main category: eess.IV

TL;DR: 本研究利用深度学习（R-CNN、UNet、CNN和迁移学习模型）对MRI图像中的脑肿瘤（胶质瘤、脑膜瘤、垂体瘤）进行分类，在物联网医疗系统中实现了高准确性，其中Fast R-CNN表现最佳。


<details>
  <summary>Details</summary>
Motivation: 脑健康对人类生命至关重要，准确诊断是有效治疗的关键。人工智能驱动的深度学习在物联网医疗系统中提高了脑肿瘤诊断的准确性，而MRI提供了AI进行图像分类所需的大数据。

Method: 本研究使用区域卷积神经网络（R-CNN）和UNet架构对MRI图像中的胶质瘤、脑膜瘤和垂体瘤进行分类。同时应用了卷积神经网络（CNN）和基于CNN的迁移学习模型，如Inception-V3、EfficientNetB4和VGG19。模型性能通过F-score、召回率、精确度、准确率和AUC进行评估，并进行了外部队列跨数据集验证。

Result: Fast R-CNN取得了最佳结果，准确率达到99%，F-score为98.5%，AUC为99.5%，召回率为99.4%，精确度为98.5%。在外部队列跨数据集验证中，EfficientNetB2在微调的EfficientNet模型中表现最强，精确度为92.11%，召回率/敏感度为92.11%，特异性为95.96%，F1-score为92.02%，准确率为92.23%。

Conclusion: 结合R-CNN、UNet和迁移学习模型能够在物联网医疗系统中实现更早的诊断和更有效的治疗，改善患者预后。这些发现强调了AI模型在处理多样化数据集方面的鲁棒性和可靠性，增强了它们在物联网医疗环境中改善脑肿瘤分类和患者护理的潜力。

Abstract: Artificial intelligence (AI)-powered deep learning has advanced brain tumor
diagnosis in Internet of Things (IoT)-healthcare systems, achieving high
accuracy with large datasets. Brain health is critical to human life, and
accurate diagnosis is essential for effective treatment. Magnetic Resonance
Imaging (MRI) provides key data for brain tumor detection, serving as a major
source of big data for AI-driven image classification. In this study, we
classified glioma, meningioma, and pituitary tumors from MRI images using
Region-based Convolutional Neural Network (R-CNN) and UNet architectures. We
also applied Convolutional Neural Networks (CNN) and CNN-based transfer
learning models such as Inception-V3, EfficientNetB4, and VGG19. Model
performance was assessed using F-score, recall, precision, and accuracy. The
Fast R-CNN achieved the best results with 99% accuracy, 98.5% F-score, 99.5%
Area Under the Curve (AUC), 99.4% recall, and 98.5% precision. Combining R-CNN,
UNet, and transfer learning enables earlier diagnosis and more effective
treatment in IoT-healthcare systems, improving patient outcomes. IoT devices
such as wearable monitors and smart imaging systems continuously collect
real-time data, which AI algorithms analyze to provide immediate insights for
timely interventions and personalized care. For external cohort cross-dataset
validation, EfficientNetB2 achieved the strongest performance among fine-tuned
EfficientNet models, with 92.11% precision, 92.11% recall/sensitivity, 95.96%
specificity, 92.02% F1-score, and 92.23% accuracy. These findings underscore
the robustness and reliability of AI models in handling diverse datasets,
reinforcing their potential to enhance brain tumor classification and patient
care in IoT healthcare environments.

</details>


### [353] [Application Space and the Rate-Distortion-Complexity Analysis of Neural Video CODECs](https://arxiv.org/abs/2509.05929)
*Ricardo L. de Queiroz,Diogo C. Garcia,Yi-Hsin Chen,Ruhan Conceição,Wen-Hsiao Peng,Luciano V. Agostini*

Main category: eess.IV

TL;DR: 本文研究了视频压缩系统选择的决策过程，通过速率-失真-复杂度（RDC）分析，将2D BD度量推广到3D RDC空间，并引入拉格朗日成本$D+\lambda R + \gamma C$来比较不同应用场景下的编解码器。


<details>
  <summary>Details</summary>
Motivation: 选择视频压缩系统时，除了速率和失真，复杂度也是一个重要因素。传统的2D BD度量不足以涵盖所有维度。研究旨在提供一个更全面的框架来评估和选择视频编解码器，以适应不同应用的需求。

Method: 研究将2D Bjontegaard delta (BD) 度量推广到3D RDC体积。通过定义编解码器成本为拉格朗日函数$D+\lambda R + \gamma C$，其中$(\lambda, \gamma)$代表特定应用的需求。通过在$(\lambda, \gamma)$平面上设定点或遍历整个应用空间来比较不同编解码器的拉格朗日成本。

Result: 该方法能够在RDC体积中比较不同编解码器在特定应用下的拉格朗日成本，并能跨越整个应用空间比较编解码器。在对现有神经视频编解码器的比较中发现，在RDC计算约束下，只有四种神经视频编解码器根据所需$(\lambda, \gamma)$值的不同，被证明最适合任何应用。

Conclusion: 通过引入3D RDC分析和拉格朗日成本函数，可以为视频压缩系统的选择提供一个更全面、更灵活的决策框架，使得编解码器能够根据特定应用的需求进行有效比较和选择。研究结果为评估和优化视频编解码器提供了有价值的见解。

Abstract: We study the decision-making process for choosing video compression systems
through a rate-distortion-complexity (RDC) analysis. We discuss the 2D
Bjontegaard delta (BD) metric and formulate generalizations in an attempt to
extend its notions to the 3D RDC volume. We follow that discussion with another
one on the computation of metrics in the RDC volume, and on how to define and
measure the cost of a coder-decoder (codec) pair, where the codec is
characterized by a cloud of points in the RDC space. We use a Lagrangian cost
$D+\lambda R + \gamma C$, such that choosing the best video codec among a
number of candidates for an application demands selecting appropriate
$(\lambda, \gamma)$ values. Thus, we argue that an application may be
associated with a $(\lambda, \gamma)$ point in the application space. An
example streaming application was given as a case study to set a particular
point in the $(\lambda, \gamma)$ plane. The result is that we can compare
Lagrangian costs in an RDC volume for different codecs for a given application.
Furthermore, we can span the plane and compare codecs for the entire
application space filled with different $(\lambda, \gamma)$ choices. We then
compared several state-of-the-art neural video codecs using the proposed
metrics. Results are informative and surprising. We found that, within our RDC
computation constraints, only four neural video codecs came out as the best
suited for any application, depending on where its desirable $(\lambda,
\gamma)$ lies.

</details>


### [354] [Imagining Alternatives: Towards High-Resolution 3D Counterfactual Medical Image Generation via Language Guidance](https://arxiv.org/abs/2509.05978)
*Mohamed Mohamed,Brennan Nichyporuk,Douglas L. Arnold,Tal Arbel*

Main category: eess.IV

TL;DR: 本文提出了一种语言引导的3D扩散模型框架，用于生成高分辨率3D反事实医学图像，填补了3D领域预训练基础模型缺失的空白。


<details>
  <summary>Details</summary>
Motivation: 2D视觉-语言模型在图像生成方面表现出色，得益于丰富的预训练基础模型。然而，3D领域缺乏类似的预训练基础模型，严重限制了其发展。因此，利用自然语言描述生成高分辨率3D反事实医学图像的潜力尚未被探索。解决这一问题将支持个性化反事实解释、疾病进展模拟和增强医学训练等临床及研究应用。

Method: 我们引入了一个框架，能够根据自由形式的语言提示生成合成患者的高分辨率3D反事实医学图像。我们改进了最先进的3D扩散模型，并结合了Simple Diffusion的增强功能，同时加入了增强条件（augmented conditioning）以提高文本对齐和图像质量。该方法专门应用于神经影像数据。

Result: 在两个不同的神经MRI数据集上，我们的框架成功模拟了多发性硬化症（MS）中不同的反事实病灶负荷和阿尔茨海默病中的认知状态，生成了高质量图像，同时保持了合成医学图像中的受试者保真度。这是首次将语言引导的原生3D扩散模型应用于神经影像数据。

Conclusion: 我们的研究结果为3D医学影像中提示驱动的疾病进展分析奠定了基础。

Abstract: Vision-language models have demonstrated impressive capabilities in
generating 2D images under various conditions; however the impressive
performance of these models in 2D is largely enabled by extensive, readily
available pretrained foundation models. Critically, comparable pretrained
foundation models do not exist for 3D, significantly limiting progress in this
domain. As a result, the potential of vision-language models to produce
high-resolution 3D counterfactual medical images conditioned solely on natural
language descriptions remains completely unexplored. Addressing this gap would
enable powerful clinical and research applications, such as personalized
counterfactual explanations, simulation of disease progression scenarios, and
enhanced medical training by visualizing hypothetical medical conditions in
realistic detail. Our work takes a meaningful step toward addressing this
challenge by introducing a framework capable of generating high-resolution 3D
counterfactual medical images of synthesized patients guided by free-form
language prompts. We adapt state-of-the-art 3D diffusion models with
enhancements from Simple Diffusion and incorporate augmented conditioning to
improve text alignment and image quality. To our knowledge, this represents the
first demonstration of a language-guided native-3D diffusion model applied
specifically to neurological imaging data, where faithful three-dimensional
modeling is essential to represent the brain's three-dimensional structure.
Through results on two distinct neurological MRI datasets, our framework
successfully simulates varying counterfactual lesion loads in Multiple
Sclerosis (MS), and cognitive states in Alzheimer's disease, generating
high-quality images while preserving subject fidelity in synthetically
generated medical images. Our results lay the groundwork for prompt-driven
disease progression analysis within 3D medical imaging.

</details>


### [355] [FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes](https://arxiv.org/abs/2509.06159)
*Muraam Abdel-Ghani,Mahmoud Ali,Mohamed Ali,Fatmaelzahraa Ahmed,Mohamed Arsalan,Abdulaziz Al-Ali,Shidin Balakrishnan*

Main category: eess.IV

TL;DR: 本文提出FASL-Seg模型，通过双流处理（低级特征投影和高级特征投影）实现多层次特征捕获，显著提升了手术场景（解剖结构和器械）的语义分割性能，在EndoVis18和EndoVis17数据集上超越了现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 随着机器人微创手术的普及，基于深度学习的手术训练变得至关重要，其中对场景组件的语义分割理解是关键。然而，现有工作多侧重于手术器械而忽视解剖对象，且当前SOTA模型难以平衡高层次上下文特征与低层次边缘特征的捕获。

Method: 研究者提出了特征自适应空间定位模型（FASL-Seg），该模型通过两个独立的处理流来捕获不同细节层次的特征：低级特征投影（LLFP）流和高级特征投影（HLFP）流。这种设计旨在处理不同特征分辨率，从而实现解剖结构和手术器械的精确分割。

Result: FASL-Seg模型在EndoVis18和EndoVis17手术分割基准数据集的三个用例中进行了评估。在EndoVis18的部件和解剖结构分割中，模型达到了72.71%的平均交并比（mIoU），比SOTA提升了5%。在EndoVis18和EndoVis17的器械类型分割中，分别达到了85.61%和72.78%的mIoU，整体性能超越了SOTA，并且在两个数据集的各类别中均达到了可比较的SOTA结果，在解剖结构和器械的各种类别中表现出一致性。

Conclusion: FASL-Seg模型通过其独特的双流处理机制，能够有效捕获不同分辨率的特征，从而实现了对解剖结构和手术器械的精确分割。这证明了为不同特征分辨率设计独立处理流的有效性，并解决了现有SOTA模型在平衡高低层次特征方面的不足。

Abstract: The growing popularity of robotic minimally invasive surgeries has made deep
learning-based surgical training a key area of research. A thorough
understanding of the surgical scene components is crucial, which semantic
segmentation models can help achieve. However, most existing work focuses on
surgical tools and overlooks anatomical objects. Additionally, current
state-of-the-art (SOTA) models struggle to balance capturing high-level
contextual features and low-level edge features. We propose a Feature-Adaptive
Spatial Localization model (FASL-Seg), designed to capture features at multiple
levels of detail through two distinct processing streams, namely a Low-Level
Feature Projection (LLFP) and a High-Level Feature Projection (HLFP) stream,
for varying feature resolutions - enabling precise segmentation of anatomy and
surgical instruments. We evaluated FASL-Seg on surgical segmentation benchmark
datasets EndoVis18 and EndoVis17 on three use cases. The FASL-Seg model
achieves a mean Intersection over Union (mIoU) of 72.71% on parts and anatomy
segmentation in EndoVis18, improving on SOTA by 5%. It further achieves a mIoU
of 85.61% and 72.78% in EndoVis18 and EndoVis17 tool type segmentation,
respectively, outperforming SOTA overall performance, with comparable per-class
SOTA results in both datasets and consistent performance in various classes for
anatomy and instruments, demonstrating the effectiveness of distinct processing
streams for varying feature resolutions.

</details>


### [356] [Leveraging Information Divergence for Robust Semi-Supervised Fetal Ultrasound Image Segmentation](https://arxiv.org/abs/2509.06495)
*Fangyijie Wang,Guénolé Silvestre,Kathleen M. Curran*

Main category: eess.IV

TL;DR: 该研究提出了一种半监督学习框架，利用信息散度（information divergence）进行胎儿超声图像分割，以解决高质量标注数据稀缺的问题，并在有限标注数据下取得了显著优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 胎儿超声是监测胎儿发育的主要方式，但由于高质量标注的稀缺性，自动化分割仍然面临挑战。

Method: 该方法采用一个轻量级卷积网络和一个基于Transformer的网络，通过标准监督（有标签数据）和交叉监督（无标签数据）联合训练。引入了一种结合像素级KL散度（Kullback-Leibler divergence）和互信息间隙（Mutual Information Gap）的信息散度损失，以减少两个模型间的预测分歧。此外，对无标签样本应用mixup以增强鲁棒性。

Result: 在两个胎儿超声数据集上的实验表明，该方法持续优于七种最先进的半监督方法。当仅有5%的训练数据被标注时，Dice分数提高了2.39%，95% Hausdorff距离减少了14.90，平均表面距离减少了4.18。

Conclusion: 研究结果强调了利用信息散度在标注高效和鲁棒的医学图像分割中的有效性。

Abstract: Maternal-fetal Ultrasound is the primary modality for monitoring fetal
development, yet automated segmentation remains challenging due to the scarcity
of high-quality annotations. To address this limitation, we propose a
semi-supervised learning framework that leverages information divergence for
robust fetal ultrasound segmentation. Our method employs a lightweight
convolutional network (1.47M parameters) and a Transformer-based network,
trained jointly with labelled data through standard supervision and with
unlabelled data via cross-supervision. To encourage consistent and confident
predictions, we introduce an information divergence loss that combines
per-pixel Kullback-Leibler divergence and Mutual Information Gap, effectively
reducing prediction disagreement between the two models. In addition, we apply
mixup on unlabelled samples to further enhance robustness. Experiments on two
fetal ultrasound datasets demonstrate that our approach consistently
outperforms seven state-of-the-art semi-supervised methods. When only 5% of
training data is labelled, our framework improves the Dice score by 2.39%,
reduces the 95% Hausdorff distance by 14.90, and decreases the Average Surface
Distance by 4.18. These results highlight the effectiveness of leveraging
information divergence for annotation-efficient and robust medical image
segmentation. Our code is publicly available on GitHub.

</details>


### [357] [Impact of Labeling Inaccuracy and Image Noise on Tooth Segmentation in Panoramic Radiographs using Federated, Centralized and Local Learning](https://arxiv.org/abs/2509.06553)
*Johan Andreas Balle Rubak,Khuram Naveed,Sanyam Jain,Lukas Esterle,Alexandros Iosifidis,Ruben Pauwels*

Main category: eess.IV

TL;DR: 本研究比较了联邦学习（FL）与集中式学习（CL）和本地学习（LL）在牙科全景X光片牙齿分割任务中的表现，特别是在多种数据损坏场景下。结果显示，FL在所有腐败场景下均匹配或优于CL，并显著优于LL，同时保护了隐私，并通过损失曲线监测提供了有效的异常检测机制。


<details>
  <summary>Details</summary>
Motivation: 牙科诊断AI面临隐私限制、异构数据质量和标注不一致等挑战。联邦学习（FL）被提出作为一种潜在解决方案，以缓解这些问题。

Method: 研究使用一个Attention U-Net模型，在来自六个机构的2066张全景X光片上进行训练。实验设置包括四种场景：基线（未改变数据）、标签操纵（膨胀/缺失标注）、图像质量操纵（添加高斯噪声）以及排除一个数据损坏的客户端。FL通过Flower AI框架实现。通过监测客户端的训练和验证损失轨迹进行异常检测，并使用Dice、IoU、HD、HD95和ASSD等指标在保留测试集上进行评估。Wilcoxon符号秩检验用于报告显著性结果，CL和LL作为比较器。

Result: 在所有数据损坏场景下，FL均表现出与CL相当或更优的性能，并优于LL。例如，在基线场景下，FL的中位数Dice系数为0.94889，略优于CL（0.94706）和LL（0.93557-0.94026）。在标签操纵、图像噪声和排除故障客户端的场景中，FL也保持了最佳或接近最佳的Dice分数。此外，损失曲线监测被证明能可靠地标记出损坏的站点。

Conclusion: 联邦学习在数据损坏场景下，其性能与集中式学习相当或更优，并优于本地学习，同时能保护数据隐私。通过监测客户端的损失轨迹，可以提供有效的异常检测机制。这些结果支持联邦学习作为一种实用、保护隐私且可扩展的临床AI部署方法。

Abstract: Objectives: Federated learning (FL) may mitigate privacy constraints,
heterogeneous data quality, and inconsistent labeling in dental diagnostic AI.
We compared FL with centralized (CL) and local learning (LL) for tooth
segmentation in panoramic radiographs across multiple data corruption
scenarios. Methods: An Attention U-Net was trained on 2066 radiographs from six
institutions across four settings: baseline (unaltered data); label
manipulation (dilated/missing annotations); image-quality manipulation
(additive Gaussian noise); and exclusion of a faulty client with corrupted
data. FL was implemented via the Flower AI framework. Per-client training- and
validation-loss trajectories were monitored for anomaly detection and a set of
metrics (Dice, IoU, HD, HD95 and ASSD) was evaluated on a hold-out test set.
From these metrics significance results were reported through Wilcoxon
signed-rank test. CL and LL served as comparators. Results: Baseline: FL
achieved a median Dice of 0.94889 (ASSD: 1.33229), slightly better than CL at
0.94706 (ASSD: 1.37074) and LL at 0.93557-0.94026 (ASSD: 1.51910-1.69777).
Label manipulation: FL maintained the best median Dice score at 0.94884 (ASSD:
1.46487) versus CL's 0.94183 (ASSD: 1.75738) and LL's 0.93003-0.94026 (ASSD:
1.51910-2.11462). Image noise: FL led with Dice at 0.94853 (ASSD: 1.31088); CL
scored 0.94787 (ASSD: 1.36131); LL ranged from 0.93179-0.94026 (ASSD:
1.51910-1.77350). Faulty-client exclusion: FL reached Dice at 0.94790 (ASSD:
1.33113) better than CL's 0.94550 (ASSD: 1.39318). Loss-curve monitoring
reliably flagged the corrupted site. Conclusions: FL matches or exceeds CL and
outperforms LL across corruption scenarios while preserving privacy. Per-client
loss trajectories provide an effective anomaly-detection mechanism and support
FL as a practical, privacy-preserving approach for scalable clinical AI
deployment.

</details>


### [358] [Robustness and accuracy of mean opinion scores with hard and soft outlier detection](https://arxiv.org/abs/2509.06554)
*Dietmar Saupe,Tim Bleile*

Main category: eess.IV

TL;DR: 本文提出并应用了一种基于对抗性黑盒攻击的经验性最坏情况分析方法，用于评估主观图像/视频质量评估中离群值检测方法的性能，并提出了两种新的高性能低复杂度离群值检测方法。


<details>
  <summary>Details</summary>
Motivation: 在主观图像和视频质量评估中，计算平均意见分数（MOS）前需要识别并处理离群值。尽管现有多种离群值检测方法（包括标准化方法），但缺乏一种可靠且全面的方法来比较这些方法的性能。

Method: 本研究提出并应用了一种经验性最坏情况分析方法。该方法涉及对离群值检测算法进行对抗性黑盒攻击的演化优化，其中攻击者旨在最大化尺度值相对于真实值的失真。研究人员将此分析应用于多种硬性和软性离群值检测方法，并提出了两种新的低复杂度离群值检测方法。

Result: 通过压力测试，研究发现现有离群值检测方法表现各异。此外，本研究提出的两种新的离群值检测方法在最坏情况分析中表现出卓越的性能，且复杂度较低。相关的对抗性攻击和数据分析软件也已提供。

Conclusion: 经验性最坏情况分析是一种评估离群值检测方法性能的通用且可靠的解决方案。本研究提出的新方法在具有挑战性的场景下表现出色，为未来的主观质量评估提供了更鲁棒的离群值处理方案。

Abstract: In subjective assessment of image and video quality, observers rate or
compare selected stimuli. Before calculating the mean opinion scores (MOS) for
these stimuli from the ratings, it is recommended to identify and deal with
outliers that may have given unreliable ratings. Several methods are available
for this purpose, some of which have been standardized. These methods are
typically based on statistics and sometimes tested by introducing synthetic
ratings from artificial outliers, such as random clickers. However, a reliable
and comprehensive approach is lacking for comparative performance analysis of
outlier detection methods. To fill this gap, this work proposes and applies an
empirical worst-case analysis as a general solution. Our method involves
evolutionary optimization of an adversarial black-box attack on outlier
detection algorithms, where the adversary maximizes the distortion of scale
values with respect to ground truth. We apply our analysis to several hard and
soft outlier detection methods for absolute category ratings and show their
differing performance in this stress test. In addition, we propose two new
outlier detection methods with low complexity and excellent worst-case
performance. Software for adversarial attacks and data analysis is available.

</details>


### [359] [Contrastive Anatomy-Contrast Disentanglement: A Domain-General MRI Harmonization Method](https://arxiv.org/abs/2509.06592)
*Daniel Scholz,Ayhan Can Erdur,Robbie Holland,Viktoria Ehm,Jan C. Peeken,Benedikt Wiestler,Daniel Rueckert*

Main category: eess.IV

TL;DR: 该研究提出了一种基于条件扩散自编码器的新方法，结合对比损失和领域无关对比增强，以协调不同MRI扫描仪之间的图像对比度，同时保留个体解剖结构，显著提升了图像合成和下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: MRI图像因扫描仪和采集参数的差异导致对比度不一致，影响了数据可比性和研究的可复现性。现有协调方法存在局限性，如需要旅行受试者或难以泛化到未见领域。

Method: 提出了一种新颖的方法，使用带有对比损失（contrastive loss）和领域无关对比增强（domain-agnostic contrast augmentation）的条件扩散自编码器（conditioned diffusion autoencoder），以协调不同扫描仪的MR图像，同时保留受试者特异性解剖结构。该方法能够从单一参考图像合成脑部MRI。

Result: 该方法优于基线技术，在旅行受试者数据集上实现了+7%的PSNR改进，在未见领域年龄回归任务上实现了+18%的改进。模型能够对脑部MRI进行鲁棒、有效的协调，无需微调即可适应目标扫描仪。

Conclusion: 这项进展有望增强多中心和纵向临床研究中的可比性、可复现性和泛化能力，最终有助于改善医疗保健结果。

Abstract: Magnetic resonance imaging (MRI) is an invaluable tool for clinical and
research applications. Yet, variations in scanners and acquisition parameters
cause inconsistencies in image contrast, hindering data comparability and
reproducibility across datasets and clinical studies. Existing scanner
harmonization methods, designed to address this challenge, face limitations,
such as requiring traveling subjects or struggling to generalize to unseen
domains. We propose a novel approach using a conditioned diffusion autoencoder
with a contrastive loss and domain-agnostic contrast augmentation to harmonize
MR images across scanners while preserving subject-specific anatomy. Our method
enables brain MRI synthesis from a single reference image. It outperforms
baseline techniques, achieving a +7% PSNR improvement on a traveling subjects
dataset and +18% improvement on age regression in unseen. Our model provides
robust, effective harmonization of brain MRIs to target scanners without
requiring fine-tuning. This advancement promises to enhance comparability,
reproducibility, and generalizability in multi-site and longitudinal clinical
studies, ultimately contributing to improved healthcare outcomes.

</details>


### [360] [MM-DINOv2: Adapting Foundation Models for Multi-Modal Medical Image Analysis](https://arxiv.org/abs/2509.06617)
*Daniel Scholz,Ayhan Can Erdur,Viktoria Ehm,Anke Meyer-Baese,Jan C. Peeken,Daniel Rueckert,Benedikt Wiestler*

Main category: eess.IV

TL;DR: MM-DINOv2是一个新颖高效的框架，旨在将DINOv2等视觉基础模型应用于多模态医学图像分析，有效处理模态缺失和利用未标注数据，并在胶质瘤亚型分类任务中超越了现有监督方法。


<details>
  <summary>Details</summary>
Motivation: DINOv2等视觉基础模型在医学图像分析中表现出潜力，但其设计主要针对单模态图像，难以有效处理多模态医学成像任务。而现有监督模型无法利用未标注数据集，并且难以应对临床中常见的模态缺失问题。

Method: 本研究引入了MM-DINOv2框架。通过整合多模态块嵌入，使视觉基础模型能够处理多模态图像数据。为解决模态缺失问题，采用了全模态掩蔽策略，促使模型学习鲁棒的跨模态关系。此外，还利用半监督学习来利用大规模未标注数据集。

Result: 将MM-DINOv2应用于多序列脑MRI的胶质瘤亚型分类任务，在外部测试集上实现了0.6的Matthews相关系数（MCC），相比最先进的监督方法提高了11.1%。

Conclusion: MM-DINOv2为多模态医学成像任务提供了一个可扩展且鲁棒的解决方案，它利用了在自然图像上预训练的强大视觉基础模型，同时解决了现实世界临床挑战，如数据缺失和标注受限问题。

Abstract: Vision foundation models like DINOv2 demonstrate remarkable potential in
medical imaging despite their origin in natural image domains. However, their
design inherently works best for uni-modal image analysis, limiting their
effectiveness for multi-modal imaging tasks that are common in many medical
fields, such as neurology and oncology. While supervised models perform well in
this setting, they fail to leverage unlabeled datasets and struggle with
missing modalities, a frequent challenge in clinical settings. To bridge these
gaps, we introduce MM-DINOv2, a novel and efficient framework that adapts the
pre-trained vision foundation model DINOv2 for multi-modal medical imaging. Our
approach incorporates multi-modal patch embeddings, enabling vision foundation
models to effectively process multi-modal imaging data. To address missing
modalities, we employ full-modality masking, which encourages the model to
learn robust cross-modality relationships. Furthermore, we leverage
semi-supervised learning to harness large unlabeled datasets, enhancing both
the accuracy and reliability of medical predictions. Applied to glioma subtype
classification from multi-sequence brain MRI, our method achieves a Matthews
Correlation Coefficient (MCC) of 0.6 on an external test set, surpassing
state-of-the-art supervised approaches by +11.1%. Our work establishes a
scalable and robust solution for multi-modal medical imaging tasks, leveraging
powerful vision foundation models pre-trained on natural images while
addressing real-world clinical challenges such as missing data and limited
annotations.

</details>
