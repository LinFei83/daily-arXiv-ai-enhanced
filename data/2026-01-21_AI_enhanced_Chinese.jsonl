{"id": "2601.11689", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11689", "abs": "https://arxiv.org/abs/2601.11689", "authors": ["Xiaofan Wang", "Junyi Wang", "Yuqian Chen", "Lauren J. O' Donnell", "Fan Zhang"], "title": "Bridging Modalities: Joint Synthesis and Registration Framework for Aligning Diffusion MRI with T1-Weighted Images", "comment": null, "summary": "Multimodal image registration between diffusion MRI (dMRI) and T1-weighted (T1w) MRI images is a critical step for aligning diffusion-weighted imaging (DWI) data with structural anatomical space. Traditional registration methods often struggle to ensure accuracy due to the large intensity differences between diffusion data and high-resolution anatomical structures. This paper proposes an unsupervised registration framework based on a generative registration network, which transforms the original multimodal registration problem between b0 and T1w images into a unimodal registration task between a generated image and the real T1w image. This effectively reduces the complexity of cross-modal registration. The framework first employs an image synthesis model to generate images with T1w-like contrast, and then learns a deformation field from the generated image to the fixed T1w image. The registration network jointly optimizes local structural similarity and cross-modal statistical dependency to improve deformation estimation accuracy. Experiments conducted on two independent datasets demonstrate that the proposed method outperforms several state-of-the-art approaches in multimodal registration tasks.", "AI": {"tldr": "本文提出一种基于生成式网络的无监督多模态图像配准框架，将dMRI与T1w图像的跨模态配准转化为生成图像与T1w图像的单模态配准，提高了配准精度。", "motivation": "传统的dMRI和T1w图像配准方法因图像对比度差异大而难以保证精度，需要更准确的配准方法。", "method": "提出一个无监督配准框架，利用图像合成模型生成T1w对比度的图像，然后训练一个生成式配准网络，从生成的图像到真实的T1w图像学习形变场，同时优化局部结构相似性和跨模态统计依赖性。", "result": "该方法在两个独立数据集上的实验表明，其性能优于几种最先进的多模态配准方法。", "conclusion": "所提出的无监督生成式配准框架能够有效地解决dMRI和T1w图像之间的多模态配准问题，并取得优于现有方法的性能。"}}
{"id": "2601.11684", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11684", "abs": "https://arxiv.org/abs/2601.11684", "authors": ["Srinivas Miriyala", "Sowmya Vajrala", "Hitesh Kumar", "Sravanth Kodavanti", "Vikram Rajendiran"], "title": "Mobile-friendly Image de-noising: Hardware Conscious Optimization for Edge Application", "comment": "Accepted at ICASSP 2025", "summary": "Image enhancement is a critical task in computer vision and photography that is often entangled with noise. This renders the traditional Image Signal Processing (ISP) ineffective compared to the advances in deep learning. However, the success of such methods is increasingly associated with the ease of their deployment on edge devices, such as smartphones. This work presents a novel mobile-friendly network for image de-noising obtained with Entropy-Regularized differentiable Neural Architecture Search (NAS) on a hardware-aware search space for a U-Net architecture, which is first-of-its-kind. The designed model has 12% less parameters, with ~2-fold improvement in ondevice latency and 1.5-fold improvement in the memory footprint for a 0.7% drop in PSNR, when deployed and profiled on Samsung Galaxy S24 Ultra. Compared to the SOTA Swin-Transformer for Image Restoration, the proposed network had competitive accuracy with ~18-fold reduction in GMACs. Further, the network was tested successfully for Gaussian de-noising with 3 intensities on 4 benchmarks and real-world de-noising on 1 benchmark demonstrating its generalization ability.", "AI": {"tldr": "提出了一种基于熵正则化可微分神经架构搜索（NAS）和硬件感知搜索空间的U-Net模型，用于移动设备图像去噪，该模型参数更少，延迟和内存占用更低，同时精度略有下降，并且具有良好的泛化能力。", "motivation": "传统的图像信号处理（ISP）方法在处理噪声方面不如深度学习有效，而深度学习方法在边缘设备上的部署是一个重要挑战。因此，需要一种适合移动设备的、高效的图像去噪模型。", "method": "使用熵正则化可微分神经架构搜索（NAS），在一个为U-Net架构设计的硬件感知搜索空间中，自动搜索得到一个适合移动设备的去噪网络。", "result": "所提出的模型相比Swi-Transformer在精度相当的情况下，GMACs减少了约18倍。在Samsung Galaxy S24 Ultra上部署时，模型参数减少12%，设备延迟和内存占用分别提高约2倍和1.5倍，PSNR仅下降0.7%。在多个基准测试和真实世界数据集上验证了其泛化能力。", "conclusion": "该研究成功开发了一种轻量级、高效且泛化能力强的移动友好型图像去噪网络，克服了现有深度学习模型在边缘设备部署的限制。"}}
{"id": "2601.11612", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11612", "abs": "https://arxiv.org/abs/2601.11612", "authors": ["Arnav S. Sonavane"], "title": "Domain-Specific Self-Supervised Pre-training for Agricultural Disease Classification: A Hierarchical Vision Transformer Study", "comment": "11 pages, 4 figures, 9 tables", "summary": "We investigate the impact of domain-specific self-supervised pre-training on agricultural disease classification using hierarchical vision transformers. Our key finding is that SimCLR pre-training on just 3,000 unlabeled agricultural images provides a +4.57% accuracy improvement--exceeding the +3.70% gain from hierarchical architecture design. Critically, we show this SSL benefit is architecture-agnostic: applying the same pre-training to Swin-Base yields +4.08%, to ViT-Base +4.20%, confirming practitioners should prioritize domain data collection over architectural choices. Using HierarchicalViT (HVT), a Swin-style hierarchical transformer, we evaluate on three datasets: Cotton Leaf Disease (7 classes, 90.24%), PlantVillage (38 classes, 96.3%), and PlantDoc (27 classes, 87.1%). At matched parameter counts, HVT-Base (78M) achieves 88.91% vs. Swin-Base (88M) at 87.23%, a +1.68% improvement. For deployment reliability, we report calibration analysis showing HVT achieves 3.56% ECE (1.52% after temperature scaling). Code: https://github.com/w2sg-arnav/HierarchicalViT", "AI": {"tldr": "领域特定的自监督预训练（SimCLR）在农业病害分类任务上比单纯的架构改进（如分层Vision Transformer）更能提升模型性能，且这种优势与具体模型架构无关。", "motivation": "研究自监督预训练（SSL）和分层Vision Transformer（HVT）在农业病害分类任务中的有效性，并比较它们的贡献。", "method": "使用SimCLR在3,000张未标记的农业图像上进行自监督预训练，并将其应用于HierarchicalViT（HVT）、Swin-Base和ViT-Base等模型，并在Cotton Leaf Disease、PlantVillage和PlantDoc三个数据集上进行评估。同时分析了模型的校准性能。", "result": "SimCLR预训练在HVT上带来了+4.57%的准确率提升，优于仅通过架构设计（HVT）带来的+3.70%提升。该SSL的优势在Swin-Base（+4.08%）和ViT-Base（+4.20%）上同样成立，表明其架构无关性。HVT-Base在参数量相近的情况下优于Swin-Base。HVT在校准分析中表现出较低的ECE值。", "conclusion": "对于农业病害分类任务，收集领域特定的未标记数据进行自监督预训练比选择复杂的模型架构更能带来显著的性能提升，且这种预训练方法具有架构无关性。"}}
{"id": "2601.11680", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11680", "abs": "https://arxiv.org/abs/2601.11680", "authors": ["Zheng Zhang", "Hao Tang", "Yingying Hu", "Zhanli Hu", "Jing Qin"], "title": "FourierPET: Deep Fourier-based Unrolled Network for Low-count PET Reconstruction", "comment": "Accepted for oral presentation at AAAI 2026", "summary": "Low-count positron emission tomography (PET) reconstruction is a challenging inverse problem due to severe degradations arising from Poisson noise, photon scarcity, and attenuation correction errors. Existing deep learning methods typically address these in the spatial domain with an undifferentiated optimization objective, making it difficult to disentangle overlapping artifacts and limiting correction effectiveness. In this work, we perform a Fourier-domain analysis and reveal that these degradations are spectrally separable: Poisson noise and photon scarcity cause high-frequency phase perturbations, while attenuation errors suppress low-frequency amplitude components. Leveraging this insight, we propose FourierPET, a Fourier-based unrolled reconstruction framework grounded in the Alternating Direction Method of Multipliers. It consists of three tailored modules: a spectral consistency module that enforces global frequency alignment to maintain data fidelity, an amplitude-phase correction module that decouples and compensates for high-frequency phase distortions and low-frequency amplitude suppression, and a dual adjustment module that accelerates convergence during iterative reconstruction. Extensive experiments demonstrate that FourierPET achieves state-of-the-art performance with significantly fewer parameters, while offering enhanced interpretability through frequency-aware correction.", "AI": {"tldr": "本文提出了一种名为 FourierPET 的新型低计数 PET 重建框架，该框架利用傅里叶域分析来分离和纠正由泊松噪声、光子稀疏性和衰减校正误差引起的退化。该方法在参数更少的情况下实现了最先进的性能，并提供了更好的可解释性。", "motivation": "现有的低计数 PET 重建深度学习方法在空间域进行优化，难以区分和纠正各种退化（泊松噪声、光子稀疏性、衰减校正误差），从而限制了纠正效果。研究者发现这些退化在傅里叶域是谱可分的，这为开发更有效的重建方法提供了动机。", "method": "作者在傅里叶域分析了低计数 PET 重建中的退化，发现泊松噪声和光子稀疏性导致高频相位扰动，而衰减误差抑制低频幅度。基于此，提出了一种名为 FourierPET 的傅里叶域展开式重建框架，它基于交替方向乘子法 (ADMM)，包含三个模块：1) 谱一致性模块，用于全局频率对齐；2) 幅度-相位校正模块，用于解耦和补偿高频相位失真和低频幅度抑制；3) 双重调整模块，用于加速收敛。", "result": "与现有方法相比，FourierPET 在参数更少的情况下实现了最先进的性能，并提高了重建图像的质量。其频率感知的校正方法增强了结果的可解释性。", "conclusion": "FourierPET 框架通过在傅里叶域分析和分离不同类型的退化，有效解决了低计数 PET 重建的挑战，实现了更高质量、更少参数和更强可解释性的重建结果。"}}
{"id": "2601.11801", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11801", "abs": "https://arxiv.org/abs/2601.11801", "authors": ["Nitish Sontakke", "K. Niranjan Kumar", "Sehoon Ha"], "title": "RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models", "comment": null, "summary": "Robot design is a nontrivial process that involves careful consideration of multiple criteria, including user specifications, kinematic structures, and visual appearance. Therefore, the design process often relies heavily on domain expertise and significant human effort. The majority of current methods are rule-based, requiring the specification of a grammar or a set of primitive components and modules that can be composed to create a design. We propose a novel automated robot design framework, RobotDesignGPT, that leverages the general knowledge and reasoning capabilities of large pre-trained vision-language models to automate the robot design synthesis process. Our framework synthesizes an initial robot design from a simple user prompt and a reference image. Our novel visual feedback approach allows us to greatly improve the design quality and reduce unnecessary manual feedback. We demonstrate that our framework can design visually appealing and kinematically valid robots inspired by nature, ranging from legged animals to flying creatures. We justify the proposed framework by conducting an ablation study and a user study.", "AI": {"tldr": "提出了一种名为RobotDesignGPT的自动化机器人设计框架，该框架利用大型预训练的视觉-语言模型，仅凭用户提示和参考图像即可生成初始机器人设计，并通过视觉反馈进行优化，从而设计出美观且运动学上有效的机器人。", "motivation": "传统的机器人设计过程复杂且依赖领域专业知识和大量人工，现有方法多为基于规则，限制了设计的灵活性和自动化程度。因此，需要一种新的方法来自动化机器人设计合成过程。", "method": "利用大型预训练的视觉-语言模型，结合用户提示和参考图像生成初始机器人设计。引入新颖的视觉反馈机制来提高设计质量并减少手动干预。通过消融研究和用户研究来验证框架的有效性。", "result": "框架能够根据用户提示和参考图像，设计出受自然启发的、视觉上吸引人且运动学上有效的机器人，包括各种陆地和飞行生物。", "conclusion": "RobotDesignGPT框架能够有效地自动化机器人设计过程，生成高质量的设计，并显著减少人工反馈的需求，证明了大型预训练视觉-语言模型在机器人设计领域的潜力。"}}
{"id": "2601.11674", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11674", "abs": "https://arxiv.org/abs/2601.11674", "authors": ["M. A. Rasel", "Sameem Abdul Kareem", "Unaizah Obaidellah"], "title": "Pigment Network Detection and Classification in Dermoscopic Images Using Directional Imaging Algorithms and Convolutional Neural Networks", "comment": null, "summary": "Early diagnosis of melanoma, which can save thousands of lives, relies heavily on the analysis of dermoscopic images. One crucial diagnostic criterion is the identification of unusual pigment network (PN). However, distinguishing between regular (typical) and irregular (atypical) PN is challenging. This study aims to automate the PN detection process using a directional imaging algorithm and classify PN types using machine learning classifiers. The directional imaging algorithm incorporates Principal Component Analysis (PCA), contrast enhancement, filtering, and noise reduction. Applied to the PH2 dataset, this algorithm achieved a 96% success rate, which increased to 100% after pixel intensity adjustments. We created a new dataset containing only PN images from these results. We then employed two classifiers, Convolutional Neural Network (CNN) and Bag of Features (BoF), to categorize PN into atypical and typical classes. Given the limited dataset of 200 images, a simple and effective CNN was designed, featuring two convolutional layers and two batch normalization layers. The proposed CNN achieved 90% accuracy, 90% sensitivity, and 89% specificity. When compared to state-of-the-art methods, our CNN demonstrated superior performance. Our study highlights the potential of the proposed CNN model for effective PN classification, suggesting future research should focus on expanding datasets and incorporating additional dermatological features to further enhance melanoma diagnosis.", "AI": {"tldr": "本研究提出了一种结合定向成像算法和机器学习（CNN 和 BoF）来自动检测和分类皮肤镜图像中色素网络（PN）类型的方法，旨在提高黑色素瘤的早期诊断准确性。", "motivation": "区分普通（典型）和不规则（非典型）色素网络（PN）对于黑色素瘤的早期诊断至关重要，但这一过程具有挑战性，因此需要自动化方法。", "method": "研究者开发了一种定向成像算法，该算法结合了主成分分析（PCA）、对比度增强、滤波和降噪，用于检测 PN。然后，使用 CNN 和 Bag of Features (BoF) 分类器对提取的 PN 进行分类（非典型/典型）。CNN 模型设计为包含两个卷积层和两个批量归一化层。", "result": "定向成像算法在 PH2 数据集上达到了 96% 的成功率，调整像素强度后达到 100%。所提出的 CNN 模型在 PN 分类任务上实现了 90% 的准确率、90% 的灵敏度和 89% 的特异性，优于现有技术。", "conclusion": "所提出的 CNN 模型在色素网络分类方面表现出潜力，可以有效辅助黑色素瘤的诊断。未来的研究应着重于扩大数据集和整合更多皮肤病学特征以进一步提高诊断性能。"}}
{"id": "2601.11685", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11685", "abs": "https://arxiv.org/abs/2601.11685", "authors": ["Srinivas Miriyala", "Sowmya Vajrala", "Sravanth Kodavanti"], "title": "Towards Efficient Image Deblurring for Edge Deployment", "comment": null, "summary": "Image deblurring is a critical stage in mobile image signal processing pipelines, where the ability to restore fine structures and textures must be balanced with real-time constraints on edge devices. While recent deep networks such as transformers and activation-free architectures achieve state-of-the-art (SOTA) accuracy, their efficiency is typically measured in FLOPs or parameters, which do not correlate with latency on embedded hardware. We propose a hardware-aware adaptation framework that restructures existing models through sensitivity-guided block substitution, surrogate distillation, and training-free multi-objective search driven by device profiling. Applied to the 36-block NAFNet baseline, the optimized variants achieve up to 55% reduction in GMACs compared to the recent transformer-based SOTA while maintaining competitive accuracy. Most importantly, on-device deployment yields a 1.25X latency improvement over the baseline. Experiments on motion deblurring (GoPro), defocus deblurring (DPDD), and auxiliary benchmarks (RealBlur-J/R, HIDE) demonstrate the generality of the approach, while comparisons with prior efficient baselines confirm its accuracy-efficiency trade-off. These results establish feedback-driven adaptation as a principled strategy for bridging the gap between algorithmic design and deployment-ready deblurring models.", "AI": {"tldr": "提出一种硬件感知自适应框架，通过敏感性引导的块替换、代理蒸馏和无训练的多目标搜索来重构现有模型，以满足移动设备上的实时约束，并在不牺牲精度的情况下显著提高效率。", "motivation": "现有的深度学习模型在移动设备上进行图像去模糊时，虽然精度高，但通常效率不高，FLOPs或参数量并不能很好地反映其在嵌入式硬件上的延迟。因此，需要一种能在保证精度的同时满足实时性要求的解决方案。", "method": "提出一个硬件感知自适应框架，包括：1. 敏感性引导的块替换：识别模型中对设备性能影响最大的块并进行替换。2. 代理蒸馏：利用一个更小的代理模型来指导原模型的训练，以提高效率。3. 无训练的多目标搜索：通过设备性能剖析驱动，搜索最优的模型结构，同时优化精度和效率。", "result": "将该框架应用于36块的NAFNet基线模型，优化后的模型与基于Transformer的SOTA模型相比，GMACs减少了55%，同时保持了具有竞争力的精度。在设备上部署时，延迟比基线模型提高了1.25倍。在运动去模糊、散焦去模糊以及辅助基准测试上都证明了该方法的通用性。", "conclusion": "基于反馈的自适应是一种原则性的策略，能够有效缩小算法设计与部署就绪的去模糊模型之间的差距，在保证精度的前提下实现高效的移动端图像去模糊。"}}
{"id": "2601.11559", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11559", "abs": "https://arxiv.org/abs/2601.11559", "authors": ["Zilal Eiz AlDin", "John Wu", "Jeffrey Paul Fung", "Jennifer King", "Mya Watts", "Lauren ONeill", "Adam Richard Cross", "Jimeng Sun"], "title": "MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?", "comment": "5 pages", "summary": "Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.", "AI": {"tldr": "本研究提出了 MIMIC-RD 数据集，用于评估大型语言模型（LLM）在罕见病鉴别诊断方面的能力。研究发现，当前 LLM 在此任务上表现不佳，并指出了未来改进的方向。", "motivation": "现有的罕见病鉴别诊断研究存在两方面局限：1. 使用的临床案例过于理想化，未能反映真实临床复杂性；2. 使用 ICD 编码作为疾病标签，由于许多罕见病缺乏与 Orphanet 等数据库的直接映射，导致统计严重不足。因此，需要一个更真实的基准来评估 LLM 在罕见病鉴别诊断方面的实际能力。", "method": "研究构建了一个名为 MIMIC-RD 的罕见病鉴别诊断基准。该基准通过将临床文本实体直接映射到 Orphanet 来创建。具体方法是：首先使用 LLM 进行初步挖掘，然后由四名医学标注员进行验证，以确认所识别的实体是否为真正的罕见病。最后，在包含 145 名患者的数据集上评估了多种 LLM。", "result": "在 MIMIC-RD 数据集上的评估结果显示，当前最先进的 LLM 在罕见病鉴别诊断方面表现不佳，这表明现有能力与临床需求之间存在巨大差距。", "conclusion": "现有 LLM 在罕见病鉴别诊断方面仍有很大改进空间。本研究提出的 MIMIC-RD 数据集为评估和改进 LLM 在这一领域的性能提供了基础，并为未来的研究指明了方向。"}}
{"id": "2601.11564", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11564", "abs": "https://arxiv.org/abs/2601.11564", "authors": ["Ahilan Ayyachamy Nadar Ponnusamy", "Karthic Chandran", "M Maruf Hossain"], "title": "Context Discipline and Performance Correlation: Analyzing LLM Performance and Quality Degradation Under Varying Context Lengths", "comment": "22 pages, 6 figures", "summary": "The scaling trend in Large Language Models (LLMs) has prioritized increasing the maximum context window to facilitate complex, long-form reasoning and document analysis. However, managing this expanded context introduces severe computational overhead. This paper investigates the critical trade-off between system performance and model quality when dense transformer architectures--specifically Llama-3.1-70B and Qwen1.5-14B--are exposed to large volumes of irrelevant and distracting context. The research identifies a non-linear performance degradation tied to the growth of the Key-Value (KV) cache. Furthermore, an extended analysis of the Mixture-of-Experts (MoE) architecture reveals unique behavioral anomalies at varying context scales, suggesting that architectural benefits may be masked by infrastructure bottlenecks at high token volumes.", "AI": {"tldr": "本研究探讨了增加LLM的上下文窗口对系统性能和模型质量的影响，发现在处理大量无关信息时，Transformer架构会呈现非线性性能下降，而MoE架构的优势可能被高吞吐量下的基础设施瓶颈所掩盖。", "motivation": "为了使LLM能够处理更长的上下文以进行复杂推理和文档分析，扩大上下文窗口成为主要趋势。然而，这带来了巨大的计算开销。本研究旨在分析这种权衡，特别是当模型暴露于大量无关信息时。", "method": "研究人员考察了Llama-3.1-70B和Qwen1.5-14B这两种Transformer模型，通过向其输入大量无关和干扰性上下文，来评估系统性能和模型质量的变化。此外，还对Mixture-of-Experts（MoE）架构在不同上下文规模下的行为进行了扩展分析。", "result": "研究发现，随着KV缓存的增长，Transformer架构的性能呈现出非线性的下降趋势。MoE架构在不同上下文规模下表现出独特的异常行为，表明在高吞吐量下，其架构优势可能会被基础设施瓶颈所掩盖。", "conclusion": "扩大LLM的上下文窗口虽然能提升处理长文本的能力，但在面对大量无关信息时，会带来显著的性能挑战，尤其是对于Transformer架构。MoE架构的潜力在高吞吐量环境下可能受到基础设施限制。"}}
{"id": "2601.11788", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11788", "abs": "https://arxiv.org/abs/2601.11788", "authors": ["Suguru Sato", "Kamesh Subbarao"], "title": "Modeling and Simulation of Virtual Rigid Body Formations and Their Applications Using Multiple Air Vehicles", "comment": null, "summary": "This paper presents thorough mathematical modeling, control law development, and simulation of virtual structure formations which are inspired by the characteristics of rigid bodies. The stable constraint forces that establish the rigidity in the formation are synthesized by utilizing d'Alembert's principle of virtual work, constraint sensitivities (Lagrange multipliers) and constraint stabilization using Baumgarte stabilization. The governing equations of motion of a multiagent system are derived via Newton's and Euler's equations to include these constraint forces and to enable inputs regarding the formation as if it were an independent rigid body. The performance of this framework is evaluated under multiple cases including waypoint following missions, and using different number of agents.", "AI": {"tldr": "该论文提出了一种受刚体启发的虚拟结构形成模型，并设计了相应的控制律，通过d'Alembert原理、约束敏感性（拉格朗日乘子）和Baumgarte稳定化技术来合成稳定的约束力，以实现形成的刚性。通过牛顿和欧拉方程推导出包含约束力的多智能体系统运动方程，并评估了该框架在不同任务和代理数量下的性能。", "motivation": "该研究旨在开发一种能够模拟和控制虚拟结构（如多智能体编队）形成的方法，使其行为类似于一个独立的刚体，从而简化其控制和规划。", "method": "1. 使用d'Alembert原理合成稳定的约束力，以保持虚拟结构的刚性。2. 利用约束敏感性（拉格朗日乘子）和Baumgarte稳定化技术来增强约束的稳定性。3. 通过牛顿和欧拉方程推导包含约束力的多智能体系统运动方程。4. 将形成的虚拟结构视为一个独立的刚体进行控制。", "result": "成功开发了一个数学模型和控制框架，能够模拟具有稳定约束力的虚拟结构形成。该框架能够将多智能体系统的行为类比为一个独立的刚体进行控制，并在 waypoint 跟踪任务和不同数量的代理场景下进行了性能评估。", "conclusion": "所提出的基于d'Alembert原理和约束稳定化的虚拟结构形成框架是有效的，能够实现多智能体系统的类刚体运动控制，并在实际任务场景中展现出良好的性能。"}}
{"id": "2601.11565", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11565", "abs": "https://arxiv.org/abs/2601.11565", "authors": ["Pakorn Ueareeworakul", "Shuman Liu", "Jinghao Feng", "Ling Hu", "Zhantang Shi", "Chengqi Sun", "Liang Yao", "Panyi Ouyang", "Haibo Zhang", "Anxiang Zeng"], "title": "Compass-Embedding v4: Robust Contrastive Learning for Multilingual E-commerce Embeddings", "comment": null, "summary": "As global e-commerce rapidly expands into emerging markets, the lack of high-quality semantic representations for low-resource languages has become a decisive bottleneck for retrieval, recommendation, and search systems. In this work, we present Compass-Embedding v4, a high-efficiency multilingual embedding framework specifically optimized for Southeast Asian (SEA) e-commerce scenarios, where data scarcity, noisy supervision, and strict production constraints jointly challenge representation learning. Compass-Embedding v4 addresses three core challenges. First, large-batch contrastive training under mixed task supervision introduces systematic false negatives that degrade semantic alignment. We propose Class-Aware Masking (CAM), a lightweight modification to the InfoNCE objective that suppresses invalid in-batch negatives and improves semantic discrimination without altering training efficiency. Second, low-resource SEA languages suffer from limited and uneven data coverage. We construct a diversified training corpus through context-grounded synthetic data generation, cross-lingual translation, and structured e-commerce data construction, enabling robust multilingual and domain-specific learning. Third, production deployment requires high-throughput inference while preserving embedding quality. We combine robustness-driven large-batch training with spherical model merging to mitigate catastrophic forgetting, and optimize inference via vLLM and FP8 quantization. Extensive evaluations across multilingual benchmarks and proprietary e-commerce tasks show that Compass-Embedding v4 achieves state-of-the-art performance on major SEA languages, significantly outperforming general-purpose embedding models in domain-specific retrieval and classification, while maintaining competitive performance on high-resource languages.", "AI": {"tldr": "提出了一种名为 Compass-Embedding v4 的高效多语言嵌入框架，专门针对东南亚（SEA）电子商务场景进行优化，解决了低资源语言的语义表示瓶颈问题，并在检索、推荐和搜索等任务上取得了最先进的性能。", "motivation": "全球电子商务在新兴市场的快速扩张，而低资源语言高质量语义表示的缺乏，已成为检索、推荐和搜索系统的关键瓶颈。", "method": "提出 Class-Aware Masking (CAM) 来处理大规模批次对比训练中的假阴性问题；通过上下文相关的合成数据生成、跨语言翻译和结构化电商数据构建来扩充训练语料库；结合鲁棒性驱动的大规模批次训练和球形模型合并来缓解灾难性遗忘，并使用 vLLM 和 FP8 量化优化推理。", "result": "Compass-Embedding v4 在主要东南亚语言的多语言基准和专有电商任务的评估中，取得了最先进的性能，显著优于通用嵌入模型，同时在资源丰富的语言上也保持了竞争力。", "conclusion": "Compass-Embedding v4 成功应对了低资源语言、数据稀疏性和生产部署等挑战，为东南亚电商场景提供了高效且高质量的多语言语义表示解决方案。"}}
{"id": "2601.11802", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11802", "abs": "https://arxiv.org/abs/2601.11802", "authors": ["Suguru Sato", "Jinaykumar Patel", "Kamesh Subbarao"], "title": "Optimal Thruster Configuration for 6-DOF Control of a Small Satellite", "comment": "19 pages, 9 figures", "summary": "With the growing deployment of small satellites (such as CubeSats, Nanosats, Picosats, and Femtosats) in Low Earth Orbit (LEO) for targeted applications like imaging, communication, data storage, and rendezvous-docking mission, there is increasing attention on orbit maintenance and attitude control. A common approach for active orbit control involves the use of multiple thrusters, which, when properly arranged, can also generate the required torque for attitude control. Starting from a 24-thruster configuration, this paper presents a set of thruster configurations (referred to as a viable configuration group) that enable full six degrees of freedom (6-DOF) control. Further, configuration group that requires minimum total thrust to achieve 6-DOF commands are found among the viable configuration group. One configuration from each of these groups is further evaluated for its attitude control performance through a representative rendezvous-docking mission, demonstrating that even with a reduced thruster count, sufficient maneuverability can be achieved.", "AI": {"tldr": "该研究提出了一种用于小卫星（如 CubeSats）的 6-DOF（六自由度）姿态和轨道控制的推进器配置方法，并识别出具有最小总推力需求的配置，且在模拟的交会-对接任务中验证了其有效性。", "motivation": "随着小卫星在近地轨道（LEO）上的广泛部署，对它们的轨道维护和姿态控制能力的需求日益增长。", "method": "作者从一个 24 推进器的配置出发，识别出能够实现全 6-DOF 控制的推进器配置组（可行配置组）。然后，在这些可行配置组中找出实现 6-DOF 命令所需的总推力最小的配置组。最后，从每个组中选择一个配置，通过模拟的交会-对接任务来评估其姿态控制性能。", "result": "研究确定了实现 6-DOF 控制的可行推进器配置组，并找到了总推力需求最小的配置组。即使使用较少数量的推进器，所选配置在交会-对接任务中也能实现足够的机动性。", "conclusion": "通过优化推进器配置，可以在保证小卫星实现全 6-DOF 控制的同时，最大限度地减少推力需求，从而在实际任务中实现高效的轨道维护和姿态控制。"}}
{"id": "2601.11901", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.11901", "abs": "https://arxiv.org/abs/2601.11901", "authors": ["Liang Wu", "Wallace Gian Yion Tan", "Leqi Zhou", "Richard D. Braatz", "Jan Drgona"], "title": "Least-Squares Multi-Step Koopman Operator Learning for Model Predictive Control", "comment": null, "summary": "MPC is widely used in real-time applications, but practical implementations are typically restricted to convex QP formulations to ensure fast and certified execution. Koopman-based MPC enables QP-based control of nonlinear systems by lifting the dynamics to a higher-dimensional linear representation. However, existing approaches rely on single-step EDMD. Consequently, prediction errors may accumulate over long horizons when the EDMD operator is applied recursively. Moreover, the multi-step prediction loss is nonconvex with respect to the single-step EDMD operator, making long-horizon model identification particularly challenging. This paper proposes a multi-step EDMD framework that directly learns the condensed multi-step state-control mapping required for Koopman-MPC, thereby bypassing explicit identification of the lifted system matrices and subsequent model condensation. The resulting identification problem admits a convex least-squares formulation. We further show that the problem decomposes across prediction horizons and state coordinates, enabling parallel computation and row-wise $\\ell_1$-regularization for automatic dictionary pruning. A non-asymptotic finite-sample analysis demonstrates that, unlike one-step EDMD, the proposed method avoids error compounding and yields error bounds that depend only on the target multi-step mapping. Numerical examples validate improved long-horizon prediction accuracy and closed-loop performance.", "AI": {"tldr": "本研究提出了一种多步EDMD框架，用于学习Koopman-MPC的压缩多步状态-控制映射，解决了现有单步EDMD在长预测周期内误差累积的问题，并将识别问题转化为凸最小二乘法。", "motivation": "现有基于Koopman的MPC方法通常使用单步EDMD，这会导致在递归应用时预测误差随时间累积，并且长周期模型识别问题是非凸的，难以解决。", "method": "提出多步EDMD框架，直接学习压缩的多步状态-控制映射，绕过显式识别提升的系统矩阵和随后的模型压缩。该方法采用凸最小二乘法进行识别，并具有跨预测周期和状态坐标分解的特性，支持并行计算和行式L1正则化。", "result": "该方法避免了单步EDMD的误差累积问题，误差界仅依赖于目标多步映射。数值示例验证了其在长周期预测精度和闭环性能上的提升。", "conclusion": "所提出的多步EDMD框架为Koopman-MPC提供了更准确、更高效的长周期模型识别方法，解决了现有方法的局限性。"}}
{"id": "2601.11962", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11962", "abs": "https://arxiv.org/abs/2601.11962", "authors": ["Manavi Araga", "Aditya Natu", "Hassan HosseinNia"], "title": "Structured μ-Synthesis for Nanopositioners under Payload-Induced Uncertainties: Minimising Conservatism for Robust Performance", "comment": null, "summary": "Most systems exhibit significant variability in their dynamics, including variations in system parameters and large high-frequency dynamic uncertainties. Traditional uncertainty modelling techniques consolidate all such variations into a single uncertainty block, often yielding overly conservative representations of the true plant behaviour. This paper introduces an uncertainty modelling framework that employs multiple structured and unstructured uncertainty blocks to reduce this conservatism. The methodology is evaluated for an industrial piezoelectric nanopositioner subject to payload-induced variations, using uncertainty models of differing complexity. A bandpass controller is synthesised via structured mixed-μ synthesis, and the resulting designs are compared in terms of conservatism of the uncertainty model, robust performance, and computational effort.", "AI": {"tldr": "本研究提出了一种使用多个结构化和非结构化不确定性块来减少传统单一不确定性块建模方法的保守性，并通过结构化混合-μ合成方法合成带通控制器，用于一个工业压电纳米定位器，并与不同复杂度的模型进行比较。", "motivation": "传统的不确定性建模方法将所有变化合并为一个不确定性块，导致对真实系统行为的过度保守估计。本研究旨在开发一种更少保守性的不确定性建模框架。", "method": "本研究采用多重结构化和非结构化不确定性块来建模系统的不确定性。然后，利用结构化混合-μ合成方法合成带通控制器，并评估不同复杂度模型在不确定性保守性、鲁棒性能和计算量方面的表现。", "result": "使用多重不确定性块的建模方法能够减小不确定性的保守性。通过结构化混合-μ合成设计的控制器在鲁棒性能和计算效率方面表现出良好的权衡。", "conclusion": "通过采用多个结构化和非结构化不确定性块，可以显著减少系统不确定性建模的保守性，并在鲁棒性能和计算效率之间取得更好的平衡，为控制系统设计提供了更优的解决方案。"}}
{"id": "2601.11617", "categories": ["cs.CV", "cs.GR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.11617", "abs": "https://arxiv.org/abs/2601.11617", "authors": ["Xu Wang", "Boyao Han", "Xiaojun Chen", "Ying Liu", "Ruihui Li"], "title": "PointSLAM++: Robust Dense Neural Gaussian Point Cloud-based SLAM", "comment": null, "summary": "Real-time 3D reconstruction is crucial for robotics and augmented reality, yet current simultaneous localization and mapping(SLAM) approaches often struggle to maintain structural consistency and robust pose estimation in the presence of depth noise. This work introduces PointSLAM++, a novel RGB-D SLAM system that leverages a hierarchically constrained neural Gaussian representation to preserve structural relationships while generating Gaussian primitives for scene mapping. It also employs progressive pose optimization to mitigate depth sensor noise, significantly enhancing localization accuracy. Furthermore, it utilizes a dynamic neural representation graph that adjusts the distribution of Gaussian nodes based on local geometric complexity, enabling the map to adapt to intricate scene details in real time. This combination yields high-precision 3D mapping and photorealistic scene rendering. Experimental results show PointSLAM++ outperforms existing 3DGS-based SLAM methods in reconstruction accuracy and rendering quality, demonstrating its advantages for large-scale AR and robotics.", "AI": {"tldr": "PointSLAM++ 是一种新的 RGB-D SLAM 系统，通过分层约束的神经高斯表示和渐进式姿态优化来提高 3D 重建的准确性和鲁棒性，特别是在存在深度噪声的情况下，并且在大型 AR 和机器人应用中优于现有的 3DGS SLAM 方法。", "motivation": "现有 SLAM 方法在深度噪声存在下难以保持结构一致性和鲁棒的姿态估计。", "method": "使用分层约束的神经高斯表示来维护结构关系，并利用渐进式姿态优化来减轻深度传感器噪声。此外，采用动态神经表示图根据局部几何复杂性调整高斯节点分布。", "result": "PointSLAM++ 在重建精度和渲染质量方面优于现有的 3DGS-based SLAM 方法。", "conclusion": "PointSLAM++ 能够实现高精度的 3D 映射和照片级真实感的场景渲染，适用于大型 AR 和机器人应用。"}}
{"id": "2601.11832", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11832", "abs": "https://arxiv.org/abs/2601.11832", "authors": ["Suguru Sato", "Kamesh Subbarao"], "title": "Three Dimensional Hydrodynamic Flow-Based Collision Avoidance for UAV Formations Facing Emergent Dynamic Obstacles", "comment": "18 pages, 15 figures", "summary": "This paper presents a three-dimensional, hydrodynamics-inspired collision avoidance framework for uncrewed aerial vehicle (UAV) formations operating in dynamic environments. When moving obstacles enter a UAV's sensing region, they are modeled as three dimensional doublets or ellipsoids that generate local velocity fields, guiding nearby UAVs to execute smooth, collision-free maneuvers without trajectory discontinuities or explicit trajectory replanning. This flow-based approach enables real-time operation and interpretable behavior by leveraging the nature of fluid flow around obstacles via the harmonic properties of Laplace's equation, inherently avoiding local minima common in traditional potential field methods. To establish and maintain coordination among the UAVs, a Virtual Rigid Body (VRB) formation strategy is integrated, ensuring that formation geometry and trajectory tracking are preserved. Simulation results demonstrate the feasibility and scalability of the method for both individual and multi-UAV scenarios with multiple formation geometries encountering moving obstacles. The proposed approach achieves safe, smooth, and computationally efficient avoidance maneuvers suitable for real-time and practical applications.", "AI": {"tldr": "本文提出了一种受流体动力学启发的、用于无人机（UAV）编队在动态环境中避碰的三维框架。通过将移动障碍物建模为产生局部速度场的双极子或椭球体，引导无人机执行平滑、无碰撞的机动，并结合虚拟刚体（VRB）策略保持编队。该方法可实现实时操作、可解释行为，并避免传统势场法的局部最优问题。", "motivation": "在动态环境中，无人机编队需要一种能够实现平滑、实时且可靠的避碰策略，以避免轨迹不连续或需要重新规划。传统势场法存在局部最优问题，而流体动力学方法提供了新的思路。", "method": "提出了一种三维的、受流体动力学启发的避碰框架。将移动障碍物建模为产生局部速度场的双极子或椭球体。利用拉普拉斯方程的谐波特性，通过流体流动来引导无人机进行机动。集成虚拟刚体（VRB）策略以维持编队几何和轨迹跟踪。", "result": "仿真结果表明，该方法对于单个和多个无人机在遇到移动障碍物时，能够实现可行且可扩展的避碰。该方法能够生成安全、平滑且计算效率高的避碰机动。", "conclusion": "该研究提出了一种创新的、受流体动力学启发的无人机编队避碰框架。该方法在保持编队完整性的同时，能够实现实时、平滑且鲁棒的避碰，适用于实际应用场景。"}}
{"id": "2601.11614", "categories": ["cs.CV", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2601.11614", "abs": "https://arxiv.org/abs/2601.11614", "authors": ["Jason Qiu"], "title": "Multi-modal MRI-Based Alzheimer's Disease Diagnosis with Transformer-based Image Synthesis and Transfer Learning", "comment": "19 pages, 10 figures", "summary": "Alzheimer's disease (AD) is a progressive neurodegenerative disorder in which pathological changes begin many years before the onset of clinical symptoms, making early detection essential for timely intervention. T1-weighted (T1w) Magnetic Resonance Imaging (MRI) is routinely used in clinical practice to identify macroscopic brain alterations, but these changes typically emerge relatively late in the disease course. Diffusion MRI (dMRI), in contrast, is sensitive to earlier microstructural abnormalities by probing water diffusion in brain tissue. dMRI metrics, including fractional anisotropy (FA) and mean diffusivity (MD), provide complementary information about white matter integrity and neurodegeneration. However, dMRI acquisitions are time-consuming and susceptible to motion artifacts, limiting their routine use in clinical populations. To bridge this gap, I propose a 3D TransUNet image synthesis framework that predicts FA and MD maps directly from T1w MRI. My model generates high-fidelity maps, achieving a structural similarity index (SSIM) exceeding 0.93 and a strong Pearson correlation (>0.94) with ground-truth dMRI. When integrated into a multi-modal diagnostic model, these synthetic features boost AD classification accuracy by 5% (78.75%->83.75%) and, most importantly, improve mild cognitive impairment (MCI) detection by 12.5%. This study demonstrates that high-quality diffusion microstructural information can be inferred from routinely acquired T1w MRI, effectively transferring the benefits of multi-modality imaging to settings where diffusion data are unavailable. By reducing scan time while preserving complementary structural and microstructural information, the proposed approach has the potential to improve the accessibility, efficiency, and accuracy of AD diagnosis in clinical practice.", "AI": {"tldr": "本研究提出了一种基于3D TransUNet的图像合成框架，能够从T1w MRI预测扩散MRI（dMRI）的FA和MD图。合成图质量高，并能显著提高阿尔茨海默病（AD）和轻度认知障碍（MCI）的诊断准确性，尤其是在dMRI数据不可用时。", "motivation": "阿尔茨海默病（AD）的早期检测至关重要，但临床常用的T1w MRI在疾病早期变化不明显。扩散MRI（dMRI）能检测早期微结构异常，但采集耗时且易受运动伪影影响，限制了其临床应用。因此，需要一种方法从易于获取的T1w MRI推断dMRI信息。", "method": "提出一个3D TransUNet图像合成框架，直接从T1w MRI预测FA和MD图。使用SSIM和Pearson相关系数评估合成图与真实dMRI图的相似性。将合成的dMRI特征整合到多模态诊断模型中，评估其对AD和MCI诊断的提升效果。", "result": "该模型生成的FA和MD图具有高保真度，SSIM超过0.93，Pearson相关系数大于0.94。将合成特征整合到诊断模型后，AD分类准确率提升了5%（78.75% -> 83.75%），MCI检测准确率提升了12.5%。", "conclusion": "研究表明，可以从常规采集的T1w MRI中推断出高质量的扩散微结构信息，从而将多模态成像的优势扩展到无法获取dMRI数据的场景。该方法有望通过减少扫描时间并保留互补的结构和微结构信息，提高AD诊断的可及性、效率和准确性。"}}
{"id": "2601.11691", "categories": ["eess.IV", "cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.11691", "abs": "https://arxiv.org/abs/2601.11691", "authors": ["Jan-Philipp Redlich", "Friedrich Feuerhake", "Stefan Nikolin", "Nadine Sarah Schaadt", "Sarah Teuber-Hanselmann", "Joachim Weis", "Sabine Luttmann", "Andrea Eberle", "Christoph Buck", "Timm Intemann", "Pascal Birnstill", "Klaus Kraywinkel", "Jonas Ort", "Peter Boor", "André Homeyer"], "title": "Explainable histomorphology-based survival prediction of glioblastoma, IDH-wildtype", "comment": null, "summary": "Glioblastoma, IDH-wildtype (GBM-IDHwt) is the most common malignant brain tumor. Histomorphology is a crucial component of the integrated diagnosis of GBM-IDHwt. Artificial intelligence (AI) methods have shown promise to extract additional prognostic information from histological whole-slide images (WSI) of hematoxylin and eosin-stained glioblastoma tissue. Here, we present an explainable AI-based method to support systematic interpretation of histomorphological features associated with survival. It combines an explainable multiple instance learning (MIL) architecture with a sparse autoencoder (SAE) to relate human-interpretable visual patterns of tissue to survival. The MIL architecture directly identifies prognosis-relevant image tiles and the SAE maps these tiles post-hoc to visual patterns. The MIL method was trained and evaluated using a new real-world dataset that comprised 720 GBM-IDHwt cases from three hospitals and four cancer registries in Germany. The SAE was trained using 1878 WSIs of glioblastoma from five independent public data collections. Despite the many factors influencing survival time, our method showed some ability to discriminate between patients living less than 180 days or more than 360 days solely based on histomorphology (AUC: 0.67; 95% CI: 0.63-0.72). Cox proportional hazards regression confirmed a significant difference in survival time between the predicted groups after adjustment for established prognostic factors (hazard ratio: 1.47; 95% CI: 1.26-1.72). Our method identified multiple interpretable visual patterns associated with survival. Three neuropathologists separately found that 21 of the 24 most strongly associated patterns could be clearly attributed to seven histomorphological categories. Necrosis and hemorrhage appeared to be associated with shorter survival while highly cellular tumor areas were associated with longer survival.", "AI": {"tldr": "本研究提出了一种可解释的人工智能方法，结合了多实例学习（MIL）和稀疏自编码器（SAE），用于分析胶质母细胞瘤（GBM-IDHwt）的组织形态学特征，并预测患者生存期。该方法能够从组织图像中提取与生存相关的视觉模式，并经过神经病理学家的验证，证实了其预测能力。", "motivation": "胶质母细胞瘤（GBM-IDHwt）是最常见的恶性脑肿瘤，其组织形态学诊断至关重要。本研究旨在利用人工智能从组织学全切片图像（WSI）中提取额外的预后信息，并提供可解释的预测。", "method": "本研究采用了一种可解释的多实例学习（MIL）架构与稀疏自编码器（SAE）相结合的方法。MIL架构直接识别与预后相关的图像块，SAE则将这些图像块映射到视觉模式。MIL模型在新收集的720例GBM-IDHwt数据上进行训练和评估，SAE模型则使用了1878张来自公共数据集的胶质母细胞瘤WSI。", "result": "该方法能够基于组织形态学区分生存期少于180天和多于360天的患者（AUC: 0.67）。Cox比例风险回归分析证实，在调整了已知的预后因素后，预测组之间生存期存在显著差异（风险比：1.47）。研究还识别出多个与生存相关的可解释视觉模式，其中24种最强相关的模式中，21种可被明确归类为七种组织形态学类别，例如坏死和出血与生存期缩短相关，而高细胞肿瘤区域与生存期延长相关。", "conclusion": "本研究提出了一种可解释的AI方法，能够有效地利用GBM-IDHwt的组织形态学特征来预测患者生存期，并识别出与生存相关的具体组织形态学模式。该方法有望辅助病理学诊断和预后评估。"}}
{"id": "2601.11567", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11567", "abs": "https://arxiv.org/abs/2601.11567", "authors": ["Vanessa D'Amario", "Randy Daniel", "Alessandro Zanetti", "Dhruv Edamadaka", "Nitya Alaparthy", "Joshua Tarkoff"], "title": "Measuring Stability Beyond Accuracy in Small Open-Source Medical Large Language Models for Pediatric Endocrinology", "comment": "20 pages, 11 figures, accepted at 47 workshop Reproducible Artificial Intelligence (AAAI 2026, Singapore, January 27, 2026)", "summary": "Small open-source medical large language models (LLMs) offer promising opportunities for low-resource deployment and broader accessibility. However, their evaluation is often limited to accuracy on medical multiple choice question (MCQ) benchmarks, and lacks evaluation of consistency, robustness, or reasoning behavior. We use MCQ coupled to human evaluation and clinical review to assess six small open-source medical LLMs (HuatuoGPT-o1 (Chen 2024), Diabetica-7B, Diabetica-o1 (Wei 2024), Meditron3-8B (Sallinen2025), MedFound-7B (Liu 2025), and ClinicaGPT-base-zh (Wang 2023)) in pediatric endocrinology. In deterministic settings, we examine the effect of prompt variation on models' output and self-assessment bias. In stochastic settings, we evaluate output variability and investigate the relationship between consistency and correctness. HuatuoGPT-o1-8B achieved the highest performance. The results show that high consistency across the model response is not an indicator of correctness, although HuatuoGPT-o1-8B showed the highest consistency rate. When tasked with selecting correct reasoning, both HuatuoGPT-o1-8B and Diabetica-o1 exhibit self-assessment bias and dependency on the order of the candidate explanations. Expert review of incorrect reasoning rationales identified a mix of clinically acceptable responses and clinical oversight. We further show that system-level perturbations, such as differences in CUDA builds, can yield statistically significant shifts in model output despite stable accuracy. This work demonstrates that small, semantically negligible prompt perturbations lead to divergent outputs, raising concerns about reproducibility of LLM-based evaluations and highlights the output variability under different stochastic regimes, emphasizing the need of a broader diagnostic framework to understand potential pitfalls in real-world clinical decision support scenarios.", "AI": {"tldr": "本研究评估了六种小型开源医疗大语言模型在儿科内分泌学领域的表现，不仅限于准确性，还考察了其一致性、鲁棒性和推理能力。结果显示，HuatuoGPT-o1-8B 表现最佳，但高一致性并不等同于正确性。研究还发现了模型在推理时的自我评估偏见和对答案顺序的依赖性，并揭示了系统级扰动（如CUDA构建差异）会对模型输出产生显著影响，强调了对LLM进行更全面评估的必要性。", "motivation": "现有对小型开源医疗大语言模型的评估主要局限于准确性，缺乏对其一致性、鲁棒性和推理行为的深入考察，这限制了其在实际临床应用中的可靠性。", "method": "研究使用多项选择题（MCQ）结合人类评估和临床审查，评估了六种小型开源医疗大语言模型。在确定性设置下，研究了提示词变化对模型输出和自我评估偏见的影响；在随机性设置下，评估了输出变异性，并研究了一致性与正确性之间的关系。此外，还考察了系统级扰动（如CUDA构建差异）对模型输出的影响。", "result": "HuatuoGPT-o1-8B 在六种模型中表现最佳。高一致性并不保证正确性，尽管HuatuoGPT-o1-8B 表现出最高的一致性。模型在选择正确推理时存在自我评估偏见，并对候选解释的顺序敏感。专家审查发现，模型给出的不正确推理理由中，既有临床上可接受的回答，也有临床上的疏忽。系统级扰动（如CUDA构建差异）导致了模型输出的显著变化，即使准确率稳定。", "conclusion": "小型、语义上微小的提示词扰动会导致模型输出发散，引发对基于LLM评估的可复现性的担忧。模型在不同随机状态下的输出变异性，强调了需要一个更广泛的诊断框架来理解LLM在真实临床决策支持场景中潜在的陷阱。"}}
{"id": "2601.11620", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11620", "abs": "https://arxiv.org/abs/2601.11620", "authors": ["Michael Timothy Bennett"], "title": "A Mind Cannot Be Smeared Across Time", "comment": null, "summary": "Whether machines can be conscious depends not only on what they compute, but \\emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal semantics over windowed trajectories $τ^{Δ,s}$ and prove that existential temporal realisation $\\Diamond_Δ$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates. StrongSync requires objective co-instantiation of the grounded conjunction within the window, while WeakSync permits temporal ``smearing''. I formalise concurrency-capacity to measure what is needed to satisfy StrongSync. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is often associated with its breakdown. This evidence makes WeakSync less plausible. Under StrongSync, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The more parts from which simultaneous contribution required, the more concurrency capacity is required. The hardware matters. Consciousness attribution therefore requires architectural inspection, not just functional performance.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.11876", "categories": ["cs.RO", "cs.AI", "cs.CV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11876", "abs": "https://arxiv.org/abs/2601.11876", "authors": ["Christopher Kao", "Akhil Pathapati", "James Davis"], "title": "AI for Green Spaces: Leveraging Autonomous Navigation and Computer Vision for Park Litter Removal", "comment": "Published in IEEE/SICE SII 2025", "summary": "There are 50 billion pieces of litter in the U.S. alone. Grass fields contribute to this problem because picnickers tend to leave trash on the field. We propose building a robot that can autonomously navigate, identify, and pick up trash in parks. To autonomously navigate the park, we used a Spanning Tree Coverage (STC) algorithm to generate a coverage path the robot could follow. To navigate this path, we successfully used Real-Time Kinematic (RTK) GPS, which provides a centimeter-level reading every second. For computer vision, we utilized the ResNet50 Convolutional Neural Network (CNN), which detects trash with 94.52% accuracy. For trash pickup, we tested multiple design concepts. We select a new pickup mechanism that specifically targets the trash we encounter on the field. Our solution achieved an overall success rate of 80%, demonstrating that autonomous trash pickup robots on grass fields are a viable solution.", "AI": {"tldr": "研究提出了一种能在草地上自主导航、识别和捡拾垃圾的机器人，实现了80%的成功率。", "motivation": "美国草坪上存在大量的垃圾，野餐者遗留的垃圾是主要来源，因此需要一种解决方案来解决这一问题。", "method": "采用Spanning Tree Coverage (STC)算法生成覆盖路径，使用RTK GPS进行厘米级精度的路径导航，利用ResNet50 CNN识别垃圾（准确率94.52%），并开发了一种新的垃圾拾取机制。", "result": "机器人成功实现了80%的总体成功率，证明了其在草坪上自主拾取垃圾的可行性。", "conclusion": "自主垃圾拾取机器人是解决草坪垃圾问题的可行方案。"}}
{"id": "2601.11622", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11622", "abs": "https://arxiv.org/abs/2601.11622", "authors": ["Hassan Ugail", "Newton Howard"], "title": "Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models", "comment": null, "summary": "Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.", "AI": {"tldr": "研究人员提出了一种受神经科学启发的动态指标，用于分析大型语言模型（LLM）的内部时序组织。该指标在GPT-2模型上进行评估，发现结构化推理任务比重复、噪声或扰动任务表现出更强的动态性，证明了该指标能够有效地区分LLM在不同功能下的计算组织。", "motivation": "目前对大型语言模型（LLM）文本生成过程中的高维内部动力学时序组织理解不足，现有的可解释性方法多侧重于静态表示或因果干预，忽视了时间结构。该研究受到神经科学中时间整合和亚稳态概念的启发，旨在填补这一研究空白。", "method": "研究人员借鉴神经科学中的时间整合和亚稳态概念，将其应用于Transformer模型。提出并计算了一个复合动态指标，该指标由模型在自回归生成过程中的激活时间序列得出。该指标在GPT-2-medium模型上，针对结构化推理、强制重复、高噪声采样、注意力头剪枝和权重噪声注入五种条件进行了评估。", "result": "结构化推理任务在所提出的动态指标上持续表现出比重复、噪声和扰动等任务更高的数值。单因素方差分析（ANOVA）证实了这些差异具有统计学意义，并且关键比较中存在较大的效应量。结果对层选择、通道子采样和随机种子均具有鲁棒性。", "conclusion": "受神经科学启发的动态指标能够可靠地表征大型语言模型在不同功能范式下的计算组织差异。该指标捕捉了形式上的动力学属性，并不暗示主观体验。"}}
{"id": "2601.11694", "categories": ["eess.IV", "cs.CV", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11694", "abs": "https://arxiv.org/abs/2601.11694", "authors": ["Xinjue Wang", "Xiuheng Wang", "Esa Ollila", "Sergiy A. Vorobyov"], "title": "Anisotropic Tensor Deconvolution of Hyperspectral Images", "comment": "To appear in ICASSP 2026", "summary": "Hyperspectral image (HSI) deconvolution is a challenging ill-posed inverse problem, made difficult by the data's high dimensionality.We propose a parameter-parsimonious framework based on a low-rank Canonical Polyadic Decomposition (CPD) of the entire latent HSI $\\mathbf{\\mathcal{X}} \\in \\mathbb{R}^{P\\times Q \\times N}$.This approach recasts the problem from recovering a large-scale image with $PQN$ variables to estimating the CPD factors with $(P+Q+N)R$ variables.This model also enables a structure-aware, anisotropic Total Variation (TV) regularization applied only to the spatial factors, preserving the smooth spectral signatures.An efficient algorithm based on the Proximal Alternating Linearized Minimization (PALM) framework is developed to solve the resulting non-convex optimization problem.Experiments confirm the model's efficiency, showing a numerous parameter reduction of over two orders of magnitude and a compelling trade-off between model compactness and reconstruction accuracy.", "AI": {"tldr": "提出了一种基于低秩CP分解的超光谱图像（HSI）去卷积新框架，通过降低模型参数数量，并结合应用于空间因子的全变分（TV）正则化，使用PALM算法有效解决非凸优化问题，实现了参数大幅减少和重建精度的良好权衡。", "motivation": "HSI去卷积是一个高维且病态的逆问题，现有方法面临挑战。需要一种更有效、参数更少且能保留光谱信息的模型。", "method": "提出了一种基于低秩CP分解（Canonical Polyadic Decomposition）的框架，将HSI表示为低秩张量。将去卷积问题转化为估计CP分解因子，大大减少了变量数量。引入了应用于空间因子的结构感知、各向异性全变分（TV）正则化。采用Proximal Alternating Linearized Minimization（PALM）算法解决非凸优化问题。", "result": "该模型能够显著减少参数数量（超过两个数量级）。在保持模型紧凑性的同时，实现了有竞争力的重建精度，并且能够保留平滑的光谱特征。", "conclusion": "所提出的基于低秩CP分解和结构感知TV正则化的HSI去卷积框架是一种参数高效且性能优越的方法，能够有效解决高维HSI去卷积问题，并在模型复杂度和重建质量之间取得了良好的平衡。"}}
{"id": "2601.11967", "categories": ["eess.SY", "cs.CV", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.11967", "abs": "https://arxiv.org/abs/2601.11967", "authors": ["Margarida Caleiras", "Samuel Moniz", "Paulo Jorge Nascimento"], "title": "A Constraint Programming Model for the Super-Agile Earth Observation Satellite Imaging Scheduling Problem", "comment": "12 pages, 4 figures, To be published in the Proceedings of the International Conference on Operations Research and Enterprise Systems (ICORES 2026)", "summary": "As the dependence on satellite imaging continues to grow, modern satellites have become increasingly agile, with the new generation, namely super-agile Earth observation satellites (SAEOS), providing unprecedented imaging flexibility. The highly dynamic capabilities of these satellites introduce additional challenges to the scheduling of observation tasks, as existing approaches for conventional agile satellites do not account for variable observation durations and multiple imaging directions. Although some efforts have been made in this regard, the SAEOS imaging scheduling problem (SAEOS-ISP) remains largely unexplored, and no exact approaches have yet been proposed. In this context, this study presents the first exact Constraint Programming formulation for the SAEOS-ISP, considering flexible observation windows, multiple pointing directions and sequence-dependent transition times across multiple satellites. Computational experiments on a newly generated benchmark set demonstrate that the model can be solved efficiently and within very short computational times. Moreover, the results also show that the proposed approach has the potential to achieve higher computational performance compared to the non-exact approaches that are currently considered state-of-the-art.", "AI": {"tldr": "本文提出了首个用于超敏捷对地观测卫星（SAEOS）成像调度问题的精确约束规划模型，解决了传统方法无法处理的变长观测、多指向和多卫星调度问题，并在实验中表现出高效性和优越性。", "motivation": "现代卫星成像需求不断增长，超敏捷卫星（SAEOS）提供了前所未有的成像灵活性，但现有的调度方法无法处理其可变的观测时长和多成像方向，导致SAEOS成像调度问题（SAEOS-ISP）尚未得到充分研究，缺乏精确求解方法。", "method": "提出了一种精确的约束规划（CP）模型来解决SAEOS-ISP。该模型考虑了灵活的观测窗口、多指向以及多卫星间依赖序列的转移时间。", "result": "在新建的基准数据集上的计算实验表明，该CP模型能够以很短的计算时间高效求解。此外，与现有的非精确方法相比，所提出的方法在计算性能上有潜力实现更高的效率。", "conclusion": "本文首次提出了解决SAEOS-ISP的精确约束规划模型，并验证了其在效率和性能上的优越性，为SAEOS成像任务的优化调度提供了有效方案。"}}
{"id": "2601.11625", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11625", "abs": "https://arxiv.org/abs/2601.11625", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance", "comment": "8 pages, Submitted to ACL Rolling Review and is under review", "summary": "Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.", "AI": {"tldr": "本文提出了一种在模型微调过程中追踪 token 级归因的方法，定义了“解释漂移”来衡量归因的变化，并引入了“推理稳定点”（RSP）来标记模型决策证据稳定的早期阶段。该方法可以帮助理解微调对模型决策依据的影响，并在不依赖 OOD 数据的情况下诊断模型。", "motivation": "预训练语言模型的微调虽然能提升任务性能，但也会微妙地改变模型依赖的证据。需要一种方法来理解和监控这种变化。", "method": "通过在微调过程中追踪 token 级归因，定义“解释漂移”（explanation drift）来量化归因的变化，并提出“推理稳定点”（RSP）来识别归因趋于稳定的最早 epoch。", "result": "研究发现，在大多数情况下，解释漂移在训练早期就迅速下降并进入稳定状态，而验证准确率仍在缓慢提升。在存在触发器（shortcut）的受控场景下，即使验证准确率保持竞争力，归因动态也显示出模型对触发器的依赖性增加。", "conclusion": "解释漂移是一个简单、低成本的诊断工具，可以监控微调过程中决策证据的演变，并用于选择证据稳定的模型 checkpoint。"}}
{"id": "2601.11627", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11627", "abs": "https://arxiv.org/abs/2601.11627", "authors": ["Hassan Ugail", "Jan Ritch-Frel", "Irina Matuzava"], "title": "Handcrafted Feature-Assisted One-Class Learning for Artist Authentication in Historical Drawings", "comment": null, "summary": "Authentication and attribution of works on paper remain persistent challenges in cultural heritage, particularly when the available reference corpus is small and stylistic cues are primarily expressed through line and limited tonal variation. We present a verification-based computational framework for historical drawing authentication using one-class autoencoders trained on a compact set of interpretable handcrafted features. Ten artist-specific verifiers are trained using authenticated sketches from the Metropolitan Museum of Art open-access collection, the Ashmolean Collections Catalogue, the Morgan Library and Museum, the Royal Collection Trust (UK), the Victoria and Albert Museum Collections, and an online catalogue of the Casa Buonarroti collection and evaluated under a biometric-style protocol with genuine and impostor trials. Feature vectors comprise Fourier-domain energy, Shannon entropy, global contrast, GLCM-based homogeneity, and a box-counting estimate of fractal complexity. Across 900 verification decisions (90 genuine and 810 impostor trials), the pooled system achieves a True Acceptance Rate of 83.3% with a False Acceptance Rate of 9.5% at the chosen operating point. Performance varies substantially by artist, with near-zero false acceptance for some verifiers and elevated confusability for others. A pairwise attribution of false accepts indicates structured error pathways consistent with stylistic proximity and shared drawing conventions, whilst also motivating tighter control of digitisation artefacts and threshold calibration. The proposed methodology is designed to complement, rather than replace, connoisseurship by providing reproducible, quantitative evidence suitable for data-scarce settings common in historical sketch attribution.", "AI": {"tldr": "研究提出了一种基于单类自动编码器和手工特征的计算框架，用于验证历史素描的作者身份，在数据量有限的情况下，为艺术品鉴定提供可重复的量化证据。", "motivation": "文化遗产中，尤其是在参考语料库有限且风格线索主要通过线条和有限的色调变化表达时，纸本作品的鉴定和归属是一个持续的挑战。", "method": "使用手工提取的可解释特征（包括傅里叶域能量、香农熵、全局对比度、GLCM同质性、分形复杂度）训练十个艺术家特定的单类自动编码器。在一个类似生物特征识别的协议下，使用来自多个博物馆的真实素描进行训练，并用真实和伪造的样本进行评估。", "result": "在900次验证决策（90次真实，810次伪造）中，该系统实现了83.3%的真实接受率和9.5%的错误接受率。不同艺术家的性能差异很大，一些验证器的错误接受率接近于零，而另一些验证器则更容易混淆。", "conclusion": "该方法能够为数据稀疏的历史素描归属提供可重复的量化证据，作为传统专家鉴定方法（connoisseurship）的补充。研究还指出了数字化伪影的控制和阈值校准的重要性，并揭示了错误接受的模式与风格的接近性和共享绘画惯例相关。"}}
{"id": "2601.11978", "categories": ["eess.IV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.11978", "abs": "https://arxiv.org/abs/2601.11978", "authors": ["Yufeng Wu", "Xin Liao", "Baowei Wang", "Han Fang", "Xiaoshuai Wu", "Guiling Wang"], "title": "NiMark: A Non-intrusive Watermarking Framework against Screen-shooting Attacks", "comment": null, "summary": "Unauthorized screen-shooting poses a critical data leakage risk. Resisting screen-shooting attacks typically requires high-strength watermark embedding, inevitably degrading the cover image. To resolve the robustness-fidelity conflict, non-intrusive watermarking has emerged as a solution by constructing logical verification keys without altering the original content. However, existing non-intrusive schemes lack the capacity to withstand screen-shooting noise. While deep learning offers a potential remedy, we observe that directly applying it leads to a previously underexplored failure mode, the Structural Shortcut: networks tend to learn trivial identity mappings and neglect the image-watermark binding. Furthermore, even when logical binding is enforced, standard training strategies cannot fully bridge the noise gap, yielding suboptimal robustness against physical distortions. In this paper, we propose NiMark, an end-to-end framework addressing these challenges. First, to eliminate the structural shortcut, we introduce the Sigmoid-Gated XOR (SG-XOR) estimator to enable gradient propagation for the logical operation, effectively enforcing rigid image-watermark binding. Second, to overcome the robustness bottleneck, we devise a two-stage training strategy integrating a restorer to bridge the domain gap caused by screen-shooting noise. Experiments demonstrate that NiMark consistently outperforms representative state-of-the-art methods against both digital attacks and screen-shooting noise, while maintaining zero visual distortion.", "AI": {"tldr": "提出了一种名为 NiMark 的端到端框架，通过引入 SG-XOR 估计器和两阶段训练策略，解决了现有非侵入式水印在抵抗截屏噪声方面存在的结构捷径和鲁棒性不足的问题，并在数字攻击和截屏噪声方面均优于现有技术，同时保持零视觉失真。", "motivation": "现有非侵入式水印方案在抵抗截屏噪声方面存在不足，直接应用深度学习会导致“结构捷径”问题（网络倾向于学习无关紧要的恒等映射），并且标准训练策略无法有效缩小因截屏噪声造成的领域差距，导致鲁棒性不佳。", "method": "提出 NiMark 框架。首先，引入 Sigmoid-Gated XOR (SG-XOR) 估计器，以实现逻辑运算的梯度传播，强制执行图像-水印的绑定。其次，采用两阶段训练策略，结合一个恢复器来缩小截屏噪声造成的领域差距。", "result": "NiMark 在抵抗数字攻击和截屏噪声方面，性能始终优于代表性的最先进方法，同时保持零视觉失真。", "conclusion": "NiMark 成功解决了非侵入式水印在抵抗截屏噪声方面的结构捷径和鲁棒性瓶颈问题，为水印技术的鲁棒性与保真度冲突提供了有效的解决方案。"}}
{"id": "2601.11982", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11982", "abs": "https://arxiv.org/abs/2601.11982", "authors": ["Aditya Natu", "Hassan HosseinNia"], "title": "Decentralized Motion and Resonant Damping Control for High-Bandwidth and Cross-Coupling Reduction in MIMO Nanopositioners", "comment": null, "summary": "Piezoelectric nanopositioning systems are widely used in precision applications that require nanometer accuracy and high-speed motion; however, lightly damped resonances and pronounced cross-axis coupling severely limit bandwidth and disturbance rejection. This paper presents a decentralized dual-loop control strategy for a two-axis nanopositioner, combining an inner non-minimum-phase resonant damping controller with an outer motion controller on each axis. The dominant diagonal resonance is actively damped to enable closed-loop bandwidths beyond the first structural mode, while a parallel band-pass damping path is specifically tuned to a higher-order resonance that predominantly affects the cross-coupling channels. Experimental results demonstrate that this targeted band-pass damping substantially reduces cross-axis coupling and enhances disturbance rejection, without compromising tracking accuracy.", "AI": {"tldr": "本文提出了一种用于压电纳米定位系统的分布式双闭环控制策略，通过抑制共振和减小轴间耦合，显著提高了带宽和抗扰能力。", "motivation": "压电纳米定位系统虽然精度高，但容易受到轻微阻尼共振和明显的轴间耦合的限制，这严重影响了系统的带宽和抗扰性能。", "method": "提出了一种针对两轴纳米定位系统的分布式双闭环控制策略。该策略结合了内层非最小相位共振阻尼控制器和外层运动控制器。内层控制器主动抑制主要的对角共振，使闭环带宽超越第一结构模态；外层控制器通过并行带通阻尼路径，针对影响轴间耦合的高阶共振进行调谐。", "result": "实验结果表明，这种有针对性的带通阻尼策略显著降低了轴间耦合，并增强了抗扰能力，同时没有影响跟踪精度。", "conclusion": "所提出的分布式双闭环控制策略有效地解决了压电纳米定位系统中存在的共振和轴间耦合问题，实现了更高带宽和更优的抗扰性能，为精密应用提供了更可靠的解决方案。"}}
{"id": "2601.11906", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.11906", "abs": "https://arxiv.org/abs/2601.11906", "authors": ["Jose Cuaran", "Kendall Koe", "Aditya Potnis", "Naveen Kumar Uppalapati", "Girish Chowdhary"], "title": "Visual-Language-Guided Task Planning for Horticultural Robots", "comment": "14 pages, 4 figures", "summary": "Crop monitoring is essential for precision agriculture, but current systems lack high-level reasoning. We introduce a novel, modular framework that uses a Visual Language Model (VLM) to guide robotic task planning, interleaving input queries with action primitives. We contribute a comprehensive benchmark for short- and long-horizon crop monitoring tasks in monoculture and polyculture environments. Our main results show that VLMs perform robustly for short-horizon tasks (comparable to human success), but exhibit significant performance degradation in challenging long-horizon tasks. Critically, the system fails when relying on noisy semantic maps, demonstrating a key limitation in current VLM context grounding for sustained robotic operations. This work offers a deployable framework and critical insights into VLM capabilities and shortcomings for complex agricultural robotics.", "AI": {"tldr": "本文提出了一种基于视觉语言模型（VLM）的新型模块化框架，用于指导农业机器人进行作物监测任务的规划。该框架在短期任务中表现良好，但在长期和复杂任务中存在局限性，尤其是在依赖有噪声的语义地图时。", "motivation": "目前的作物监测系统缺乏高级推理能力，限制了精准农业的发展。研究动机是开发一个能够进行更智能、更自主作物监测的机器人系统。", "method": "研究人员开发了一个模块化框架，该框架利用视觉语言模型（VLM）来指导机器人的任务规划。该方法通过交织输入查询和动作原语来实现，并在单一种植和多种植被环境中进行了测试。", "result": "在短期作物监测任务中，VLM表现出鲁棒性，成功率与人类相当。然而，在更具挑战性的长期任务中，VLM的性能显著下降。系统在依赖有噪声的语义地图时会失败，这表明了当前VLM在支持持续机器人操作方面的上下文理解能力存在关键限制。", "conclusion": "该研究提供了一个可部署的框架，并揭示了VLM在复杂农业机器人应用中的能力和不足。虽然VLM在短期任务中很有前景，但其在长期、需要精确上下文理解的任务中仍需改进。"}}
{"id": "2601.11573", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11573", "abs": "https://arxiv.org/abs/2601.11573", "authors": ["Muhammad Muneeb", "David B. Ascher"], "title": "An Empirical Analysis of Fine-Tuning Large Language Models on Bioinformatics Literature: PRSGPT and BioStarsGPT", "comment": null, "summary": "Large language models (LLMs) often lack specialized knowledge for complex bioinformatics applications. We present a reproducible pipeline for fine-tuning LLMs on specialized bioinformatics data, demonstrated through two use cases: PRSGPT, focused on polygenic risk score (PRS) tools, and BioStarsGPT, trained on community forum discussions. The nine-step pipeline integrates diverse data sources, structured preprocessing, prompt-based question-answer (QA) generation (via Google Gemini), natural language inference (NLI) for quality control, semantic deduplication, clustering-based data splitting, and parameter-efficient fine-tuning using LoRA. We fine-tuned three LLMs (LLaMA-3.2-3B, Qwen2.5-7B, Gemma) and benchmarked them on over 14 lexical and semantic metrics. Qwen2.5-7B emerged as the best performer, with BLEU-4 and ROUGE-1 improvements of 82\\% and 70\\% for PRSGPT and 6\\% and 18\\% for BioStarsGPT, respectively. The open-source datasets produced include over 28,000 QA pairs for PRSGPT and 154,282 for BioStarsGPT. Human evaluation of PRSGPT yielded 61.9\\% accuracy on the PRS tools comparison task, comparable to Google Gemini (61.4\\%), but with richer methodological detail and accurate citations. BioStarsGPT demonstrated 59\\% conceptual accuracy across 142 curated bioinformatics questions. Our pipeline enables scalable, domain-specific fine-tuning of LLMs. It enables privacy-preserving, locally deployable bioinformatics assistants, explores their practical applications, and addresses the challenges, limitations, and mitigation strategies associated with their development and use.", "AI": {"tldr": "本研究提出了一个可复现的流程，用于在专业生物信息学数据上微调大型语言模型（LLMs），并通过 PRSGPT（用于多基因风险评分工具）和 BioStarsGPT（用于社区论坛讨论）这两个案例进行了演示。该流程整合了数据预处理、问题回答生成、自然语言推理、语义去重、数据分割和参数高效微调。研究发现 Qwen2.5-7B 模型表现最佳，并且生成了大量的开放数据集。PRSGPT 在 PRS 工具比较任务上达到了接近 Gemini 的准确率，但提供了更详细的方法论和准确引用。BioStarsGPT 在生物信息学问题上显示了概念准确性。", "motivation": "大型语言模型在复杂的生物信息学应用中缺乏专业知识，需要专门的微调来提高其在该领域的表现。", "method": "开发了一个包含九个步骤的可复现微调流程，包括数据整合、预处理、基于 Gemini 的 QA 生成、NLI 质量控制、语义去重、聚类数据分割以及 LoRA 参数高效微调。对 LLaMA-3.2-3B、Qwen2.5-7B 和 Gemma 三个 LLMs 进行了微调和基准测试。", "result": "Qwen2.5-7B 模型在 PRSGPT 和 BioStarsGPT 上的 BLEU-4 和 ROUGE-1 指标上取得了显著提升（PRSGPT 分别为 82% 和 70%；BioStarsGPT 分别为 6% 和 18%）。生成了超过 28,000 个 PRSGPT QA 对和 154,282 个 BioStarsGPT QA 对。PRSGPT 在 PRS 工具比较任务上达到了 61.9% 的准确率，优于 Google Gemini（61.4%），并提供了更详细的 metodology 和准确引用。BioStarsGPT 在 142 个生物信息学问题上取得了 59% 的概念准确性。", "conclusion": "所提出的微调流程能够实现 LLMs 的可扩展、领域特定微调，从而创建隐私保护、可本地部署的生物信息学助手，并探索了其在实际应用中的潜力、挑战、局限性和缓解策略。"}}
{"id": "2601.11575", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11575", "abs": "https://arxiv.org/abs/2601.11575", "authors": ["Sotirios Panagiotis Chytas", "Vikas Singh"], "title": "Concept Attractors in LLMs and their Applications", "comment": null, "summary": "Large language models (LLMs) often map semantically related prompts to similar internal representations at specific layers, even when their surface forms differ widely. We show that this behavior can be explained through Iterated Function Systems (IFS), where layers act as contractive mappings toward concept-specific Attractors. We leverage this insight and develop simple, training-free methods that operate directly on these Attractors to solve a wide range of practical tasks, including language translation, hallucination reduction, guardrailing, and synthetic data generation. Despite their simplicity, these Attractor-based interventions match or exceed specialized baselines, offering an efficient alternative to heavy fine-tuning, generalizable in scenarios where baselines underperform.", "AI": {"tldr": "本研究提出了一种利用迭代函数系统（IFS）来解释大型语言模型（LLMs）内部表示的相似性，并将此洞察应用于开发一种无需训练即可直接操作“吸引子”以解决翻译、减少幻觉、安全防护和合成数据生成等任务的方法。", "motivation": "研究者观察到大型语言模型倾向于将语义相关的、但表面形式不同的提示映射到相似的内部表示，并试图找到这种现象的理论解释，同时探索利用这一特性来改进模型的任务表现。", "method": "研究者将大型语言模型的层视为迭代函数系统（IFS）中的收缩映射，将语义概念视为收缩映射的“吸引子”。基于此理论，他们开发了无需训练即可直接操作这些“吸引子”的方法，以解决各种下游任务。", "result": "研究者提出的基于吸引子的方法在语言翻译、减少幻觉、安全防护和合成数据生成等任务上，与专门的基线模型相比，性能相当或更优。这些方法在基线模型表现不佳的场景下也展现出良好的通用性。", "conclusion": "大型语言模型中语义相关的表示相似性可以通过迭代函数系统（IFS）中的吸引子来解释。利用这一洞察，可以开发出简单且无需训练的吸引子操作方法，能够高效地解决多种实际任务，并且比复杂的微调方法更具优势且更通用。"}}
{"id": "2601.11747", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11747", "abs": "https://arxiv.org/abs/2601.11747", "authors": ["Huaxiaoyue Wang", "Sunav Choudhary", "Franck Dernoncourt", "Yu Shen", "Stefano Petrangeli"], "title": "PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement", "comment": null, "summary": "Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas designers emphasize shape and color choices. Our key insight is to leverage design data -- a collection of real-world designs that implicitly capture designer's principles -- to learn design knowledge and guide stylistic improvement. We propose PRISM (PRior-Informed Stylistic Modification) that constructs and applies a design knowledge base through three stages: (1) clustering high-variance designs to capture diversity within a style, (2) summarizing each cluster into actionable design knowledge, and (3) retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank of 1.49 (closer to 1 is better) over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers.", "AI": {"tldr": "本文提出了一种名为PRISM的方法，通过利用设计数据构建和应用设计知识库，指导基于自然语言指令的图形设计风格化改进，以解决非专业人士在探索设计风格时耗时的问题。", "motivation": "预训练的视觉语言模型（VLMs）在图形设计风格迁移方面知识过于泛化，与特定领域数据不匹配，例如其对“简约”风格的理解与设计师的实际偏好存在差异。因此，需要一种方法来学习和应用领域内特有的设计知识。", "method": "PRISM方法包含三个阶段：1. 对高方差的设计进行聚类以捕捉风格内的多样性；2. 将每个聚类总结为可操作的设计知识；3. 在推理时检索相关知识以实现风格感知的改进。", "result": "在Crello数据集上的实验表明，PRISM在风格对齐方面取得了最佳的平均排名（1.49），优于基线方法。用户研究也证实，PRISM得到了设计师的一致认可。", "conclusion": "PRISM通过利用真实世界设计数据学习领域特有的设计原则，能够有效地指导基于自然语言的图形设计风格化改进，并且在风格对齐和用户偏好方面表现优于现有方法。"}}
{"id": "2601.12174", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2601.12174", "abs": "https://arxiv.org/abs/2601.12174", "authors": ["Haiman Guo", "Cheng-Yi Li", "Yuli Wang", "Robin Wang", "Yuwei Dai", "Qinghai Peng", "Danming Cao", "Zhusi Zhong", "Thao Vu", "Linmei Zhao", "Chengzhang Zhu", "Christopher Tan", "Jacob Schick", "Stephen Kwak", "Farzad Sedaghat", "Javad Azadi", "James Facciola", "Jonathan Feng", "Dilek Oncel", "Ulrike Hamper", "Alex Zhu", "Tej Mehta", "Melissa Leimkuehler", "Cheng Ting Lin", "Zhicheng Jiao", "Ihab Kamel", "Jing Wu", "Li Yang", "Harrison Bai"], "title": "A multitask framework for automated interpretation of multi-frame right upper quadrant ultrasound in clinical decision support", "comment": null, "summary": "Ultrasound is a cornerstone of emergency and hepatobiliary imaging, yet its interpretation remains highly operator-dependent and time-sensitive. Here, we present a multitask vision-language agent (VLM) developed to assist with comprehensive right upper quadrant (RUQ) ultrasound interpretation across the full diagnostic workflow. The system was trained on a large, multi-center dataset comprising a primary cohort from Johns Hopkins Medical Institutions (9,189 cases, 594,099 images) and externally validated on cohorts from Stanford University (108 cases, 3,240 images) and a major Chinese medical center (257 cases, 3,178 images). Built on the Qwen2.5-VL-7B architecture, the agent integrates frame-level visual understanding with report-grounded language reasoning to perform three tasks: (i) classification of 18 hepatobiliary and gallbladder conditions, (ii) generation of clinically coherent diagnostic reports, and (iii) surgical decision support based on ultrasound findings and clinical data. The model achieved high diagnostic accuracy across all tasks, generated reports that were indistinguishable from expert-written versions in blinded evaluations, and demonstrated superior factual accuracy and information density on content-based metrics. The agent further identified patients requiring cholecystectomy with high precision, supporting real-time decision-making. These results highlight the potential of generalist vision-language models to improve diagnostic consistency, reporting efficiency, and surgical triage in real-world ultrasound practice.", "AI": {"tldr": "开发了一个多任务视觉语言模型（VLM），用于辅助右侧上腹部（RUQ）超声检查的全面解读，包括疾病分类、报告生成和手术决策支持，并在多中心数据集上取得了优异的性能。", "motivation": "超声检查的解读高度依赖操作者且耗时，需要一个能辅助医生进行全面超声解读的系统。", "method": "使用Qwen2.5-VL-7B架构，在一个包含约翰霍普金斯大学、斯坦福大学和中国一家主要医疗中心的大型多中心数据集上，训练了一个多任务VLM，以执行疾病分类、报告生成和手术决策支持。", "result": "该模型在疾病分类任务上实现了高诊断准确率，生成的报告在盲评中与专家撰写的报告无异，并在内容度量上表现出优越的的事实准确性和信息密度，同时能够高精度地识别需要胆囊切除术的患者。", "conclusion": "通用的视觉语言模型有潜力提高超声检查的诊断一致性、报告效率和手术分诊，从而改善现实中的超声实践。"}}
{"id": "2601.11630", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11630", "abs": "https://arxiv.org/abs/2601.11630", "authors": ["Haonan Wei", "Linyuan Wang", "Nuolin Sun", "Zhizhong Zheng", "Lei Li", "Bin Yan"], "title": "A one-step generation model with a Single-Layer Transformer: Layer number re-distillation of FreeFlow", "comment": null, "summary": "Currently, Flow matching methods aim to compress the iterative generation process of diffusion models into a few or even a single step, with MeanFlow and FreeFlow being representative achievements of one-step generation based on Ordinary Differential Equations (ODEs). We observe that the 28-layer Transformer architecture of FreeFlow can be characterized as an Euler discretization scheme for an ODE along the depth axis, where the layer index serves as the discrete time step. Therefore, we distill the number of layers of the FreeFlow model, following the same derivation logic as FreeFlow, and propose SLT (Single-Layer Transformer), which uses a single shared DiT block to approximate the depth-wise feature evolution of the 28-layer teacher. During training, it matches the teacher's intermediate features at several depth patches, fuses those patch-level representations, and simultaneously aligns the teacher's final velocity prediction. Through distillation training, we compress the 28 independent Transformer Blocks of the teacher model DiT-XL/2 into a single Transformer Block, reducing the parameter count from 675M to 4.3M. Furthermore, leveraging its minimal parameters and rapid sampling speed, SLT can screen more candidate points in the noise space within the same timeframe, thereby selecting higher-quality initial points for the teacher model FreeFlow and ultimately enhancing the quality of generated images. Experimental results demonstrate that within a time budget comparable to two random samplings of the teacher model, our method performs over 100 noise screenings and produces a high-quality sample through the teacher model using the selected points. Quality fluctuations caused by low-quality initial noise under a limited number of FreeFlow sampling calls are effectively avoided, substantially improving the stability and average generation quality of one-step generation.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.12012", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12012", "abs": "https://arxiv.org/abs/2601.12012", "authors": ["Zhaoyang Jacopo Hu", "Alex Ranne", "Alaa Eldin Abdelaal", "Kiran Bhattacharyya", "Etienne Burdet", "Allison M. Okamura", "Ferdinando Rodriguez y Baena"], "title": "Model selection and real-time skill assessment for suturing in robotic surgery", "comment": null, "summary": "Automated feedback systems have the potential to provide objective skill assessment for training and evaluation in robot-assisted surgery. In this study, we examine methods to achieve real-time prediction of surgical skill level in real-time based on Objective Structured Assessment of Technical Skills (OSATS) scores. Using data acquired from the da Vinci Surgical System, we carry out three main analyses, focusing on model design, their real-time performance, and their skill-level-based cross-validation training. For the model design, we evaluate the effectiveness of multimodal deep learning models for predicting surgical skill levels using synchronized kinematic and vision data. Our models include separate unimodal baselines and fusion architectures that integrate features from both modalities and are evaluated using mean Spearman's correlation coefficients, demonstrating that the fusion model consistently outperforms unimodal models for real-time predictions. For the real-time performance, we observe the prediction's trend over time and highlight correlation with the surgeon's gestures. For the skill-level-based cross-validation, we separately trained models on surgeons with different skill levels, which showed that high-skill demonstrations allow for better performance than those trained on low-skilled ones and generalize well to similarly skilled participants. Our findings show that multimodal learning allows more stable fine-grained evaluation of surgical performance and highlights the value of expert-level training data for model generalization.", "AI": {"tldr": "该研究提出了一种利用多模态深度学习模型，实时预测机器人辅助手术中外科医生的技能水平的方法，并发现融合运动学和视觉数据以及使用高技能外科医生的演示数据可以提高预测的准确性和泛化能力。", "motivation": "为了在机器人辅助手术训练和评估中实现客观的技能评估，需要开发自动化的实时反馈系统。", "method": "研究者使用了 da Vinci 手术系统的数据，构建了多模态深度学习模型，融合了运动学和视觉数据，并与单独的单模态模型进行了比较。他们评估了模型的实时预测性能，并进行了基于技能水平的交叉验证训练，以研究不同技能水平的演示数据对模型泛化能力的影响。", "result": "融合多模态数据的模型在实时技能水平预测方面优于单模态模型。预测结果的趋势与外科医生的手势相关。使用高技能外科医生的演示数据进行训练的模型，相比于低技能演示数据训练的模型，表现出更好的性能，并且能更好地泛化到技能水平相似的参与者。", "conclusion": "多模态学习能够实现更稳定、细粒度的手术表现评估。专家级别的训练数据对于提高模型的泛化能力至关重要。"}}
{"id": "2601.12028", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12028", "abs": "https://arxiv.org/abs/2601.12028", "authors": ["Kun-Yan Jiang", "Wei-Yu Chiu", "Yuan-Po Tsai"], "title": "Profit Maximization for Electric Vehicle Charging Stations Using Multiagent Reinforcement Learning", "comment": "18 pages, 4 figures", "summary": "Electric vehicles (EVs) are increasingly integrated into power grids, offering economic and environmental benefits but introducing challenges due to uncoordinated charging. This study addresses the profit maximization problem for multiple EV charging stations (EVCSs) equipped with energy storage systems (ESS) and renewable energy sources (RES), with the capability for energy trading. We propose a Double Hypernetwork QMIX-based multi-agent reinforcement learning (MARL) framework to optimize cooperative energy management under uncertainty in EV demand, renewable generation, and real-time electricity prices. The framework mitigates overestimation bias in value estimation, enables distributed decision-making, and incorporates an internal energy trading mechanism. Numerical experiments using real-world data demonstrate that, compared to standard QMIX, the proposed method achieves approximately 5.3% and 12.7% higher total profit for the two regions, respectively, highlighting its economic and operational efficiency. Additionally, the approach maintains robust performance under varying levels of EV demand uncertainty and renewable energy fluctuations.", "AI": {"tldr": "本研究提出了一种基于双超网络 QMIX 的多智能体强化学习框架，用于优化配备储能和可再生能源的多充电站的合作能源管理，以最大化利润，并成功解决了不确定性下的能源交易问题。", "motivation": "无协调充电带来的挑战以及多充电站、储能系统、可再生能源和能源交易的复杂性，促使研究人员寻求一种能够最大化利润的优化能源管理策略。", "method": "提出了一种基于双超网络 QMIX 的多智能体强化学习 (MARL) 框架。该框架通过缓解价值估计中的过高估计偏差，实现分布式决策，并整合了内部能源交易机制来优化合作能源管理。", "result": "与标准的 QMIX 相比，该方法在两个区域分别实现了约 5.3% 和 12.7% 的更高总利润。此外，该方法在不同程度的电动汽车需求不确定性和可再生能源波动下仍保持稳健的性能。", "conclusion": "该研究提出的双超网络 QMIX MARL 框架在应对电动汽车充电站能源管理中的不确定性方面表现出显著的经济和运营效率，能够有效最大化利润并实现稳健的性能。"}}
{"id": "2601.11631", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11631", "abs": "https://arxiv.org/abs/2601.11631", "authors": ["Yurun Song", "Jiong Yin", "Rongjunchen Zhang", "Ian G. Harris"], "title": "Compress to Focus: Efficient Coordinate Compression for Policy Optimization in Multi-Turn GUI Agents", "comment": null, "summary": "Multi-turn GUI agents enable complex task completion through sequential decision-making, but suffer from severe context inflation as interaction history accumulates. Existing strategies either sacrifice long-term context via truncation or compromise spatial structure through token pruning. In this paper, we propose Coordinate Compression Policy Optimization (CCPO), an efficient policy optimization framework that couples visual compression with policy optimization for multi-turn GUI agents. CCPO introduces Coordinate-Aware Spatial Compression (CASC), which aggregates coordinates from multiple rollouts to capture target-relevant regions and progressively narrow historical attention around key visual areas. From interactions across rollouts, CASC adaptively constructs attention boundaries that concentrate computation on the most informative regions of the scene. We further design a Distance-Based Advantage that provides fine-grained learning signals based on distance rather than binary correctness, improving both grounding accuracy and compression quality. Extensive experiments demonstrate that CCPO achieves SOTA performance across four benchmarks with up to 55% token compression and 3.8$\\times$ training speedup.", "AI": {"tldr": "提出了一种名为 CCPO 的新框架，用于优化多轮 GUI 代理，通过坐标感知空间压缩（CASC）和基于距离的优势函数来解决上下文膨胀问题，从而实现高效的策略学习和显著的性能提升。", "motivation": "现有的多轮 GUI 代理在处理累积的交互历史时，面临严重的上下文膨胀问题，现有方法要么牺牲长期上下文，要么破坏空间结构。", "method": "提出 Coordinate Compression Policy Optimization (CCPO) 框架，包含 Coordinate-Aware Spatial Compression (CASC)，该方法通过聚合多轮交互的坐标来捕捉目标相关区域，并逐步缩小历史关注范围。此外，还设计了 Distance-Based Advantage 来提供更细粒度的学习信号。", "result": "CCPO 在四个基准测试中取得了最先进 (SOTA) 的性能，实现了高达 55% 的 token 压缩率和 3.8 倍的训练加速。", "conclusion": "CCPO 框架能够有效地解决多轮 GUI 代理中的上下文膨胀问题，通过创新的压缩和学习机制，在保证性能的同时显著提高了效率。"}}
{"id": "2601.12255", "categories": ["eess.IV", "cs.CV", "cs.IT", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.12255", "abs": "https://arxiv.org/abs/2601.12255", "authors": ["Chunyang Fu", "Tai Qin", "Shiqi Wang", "Zhu Li"], "title": "DeepRAHT: Learning Predictive RAHT for Point Cloud Attribute Compression", "comment": "Accepted by AAAI 2026", "summary": "Regional Adaptive Hierarchical Transform (RAHT) is an effective point cloud attribute compression (PCAC) method. However, its application in deep learning lacks research. In this paper, we propose an end-to-end RAHT framework for lossy PCAC based on the sparse tensor, called DeepRAHT. The RAHT transform is performed within the learning reconstruction process, without requiring manual RAHT for preprocessing. We also introduce the predictive RAHT to reduce bitrates and design a learning-based prediction model to enhance performance. Moreover, we devise a bitrate proxy that applies run-length coding to entropy model, achieving seamless variable-rate coding and improving robustness. DeepRAHT is a reversible and distortion-controllable framework, ensuring its lower bound performance and offering significant application potential. The experiments demonstrate that DeepRAHT is a high-performance, faster, and more robust solution than the baseline methods. Project Page: https://github.com/zb12138/DeepRAHT.", "AI": {"tldr": "提出了一种名为DeepRAHT的端到端深度学习框架，用于基于稀疏张量的区域自适应分层变换（RAHT）点云属性压缩（PCAC），无需预处理，并引入了预测RAHT和基于学习的预测模型以降低比特率，同时通过比特率代理实现变比特率编码。", "motivation": "现有RAHT方法在深度学习应用中研究不足，需要一种集成RAHT的端到端深度学习框架来提高点云属性压缩的性能。", "method": "构建了一个端到端的深度学习框架DeepRAHT，将RAHT变换集成到学习重建过程中。引入了预测RAHT和学习驱动的预测模型来降低比特率。设计了一个应用游程长度编码的熵模型的比特率代理，实现了变比特率编码。", "result": "DeepRAHT在实验中表现出比基线方法更高性能、更快的速度和更强的鲁棒性。", "conclusion": "DeepRAHT是一个可逆且失真可控的框架，具有较低的性能下限和显著的应用潜力，为基于深度学习的点云属性压缩提供了一种高效且鲁棒的解决方案。"}}
{"id": "2601.11578", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11578", "abs": "https://arxiv.org/abs/2601.11578", "authors": ["Ibrahim Al Azher", "Zhishuai Guo", "Hamed Alhoori"], "title": "LimAgents: Multi-Agent LLMs for Generating Research Limitations", "comment": "18 Pages, 9 figures", "summary": "Identifying and articulating limitations is essential for transparent and rigorous scientific research. However, zero-shot large language models (LLMs) approach often produce superficial or general limitation statements (e.g., dataset bias or generalizability). They usually repeat limitations reported by authors without looking at deeper methodological issues and contextual gaps. This problem is made worse because many authors disclose only partial or trivial limitations. We propose LimAgents, a multi-agent LLM framework for generating substantive limitations. LimAgents integrates OpenReview comments and author-stated limitations to provide stronger ground truth. It also uses cited and citing papers to capture broader contextual weaknesses. In this setup, different agents have specific roles as sequential role: some extract explicit limitations, others analyze methodological gaps, some simulate the viewpoint of a peer reviewer, and a citation agent places the work within the larger body of literature. A Judge agent refines their outputs, and a Master agent consolidates them into a clear set. This structure allows for systematic identification of explicit, implicit, peer review-focused, and literature-informed limitations. Moreover, traditional NLP metrics like BLEU, ROUGE, and cosine similarity rely heavily on n-gram or embedding overlap. They often overlook semantically similar limitations. To address this, we introduce a pointwise evaluation protocol that uses an LLM-as-a-Judge to measure coverage more accurately. Experiments show that LimAgents substantially improve performance. The RAG + multi-agent GPT-4o mini configuration achieves a +15.51% coverage gain over zero-shot baselines, while the Llama 3 8B multi-agent setup yields a +4.41% improvement.", "AI": {"tldr": "本研究提出了LimAgents，一个多智能体LLM框架，用于生成更深入、更具实质性的科学研究局限性陈述，通过整合评论、作者声明、引用和被引用文献，并采用LLM-as-a-Judge进行评估，显著提高了局限性识别的覆盖率。", "motivation": "现有的零样本LLM在识别科学研究的局限性时，往往只能生成表面化或通用的陈述，忽略了更深层次的方法论问题和上下文缺失，并且作者通常只披露部分或琐碎的局限性，这阻碍了科学研究的透明度和严谨性。", "method": "LimAgents是一个多智能体LLM框架，它整合了OpenReview评论和作者声明作为“地面真相”，并利用引用和被引用论文捕捉更广泛的上下文弱点。框架内的不同智能体分别负责提取显式局限性、分析方法论差距、模拟同行评审员的视角以及进行文献背景分析。一个“裁判”智能体负责精炼输出，而一个“主控”智能体则负责最终整合。此外，研究还引入了一种基于LLM-as-a-Judge的点评估协议来衡量覆盖率，以克服传统NLP指标的局限性。", "result": "实验表明，LimAgents显著提高了性能。采用RAG + 多智能体GPT-4o mini的配置，在覆盖率上比零样本基线提高了+15.51%；而Llama 3 8B多智能体设置也带来了+4.41%的改进。", "conclusion": "LimAgents框架能够系统地识别出显式、隐式、同行评审导向以及文献信息驱动的局限性，有效地克服了现有LLM在生成实质性局限性陈述方面的不足，并提供了更准确的评估方法。"}}
{"id": "2601.11781", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11781", "abs": "https://arxiv.org/abs/2601.11781", "authors": ["Dawood Wasif", "Terrence J. Moore", "Seunghyun Yoon", "Hyuk Lim", "Dan Dongseong Kim", "Frederica F. Nelson", "Jin-Hee Cho"], "title": "Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles", "comment": "Submitted to ICRA 2026 (under review)", "summary": "Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber-physical intrusions during driving. We present RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via a weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available; when risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor-Critic (SAC) with risk-prioritized replay and dual rewards so that takeovers and near misses steer learning while nominal behavior remains covered. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations, outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under Controller Area Network (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8000 steps.", "AI": {"tldr": "本文提出了RAIL，一个风险感知的“人在回路”框架，用于提高自动驾驶在罕见和受攻击场景下的安全性和有效性。RAIL通过融合多种运行时信号计算风险得分，当风险升高时，会触发特定防护措施并允许人工干预，同时通过风险优先的强化学习进行在线学习和适应。RAIL在MetaDrive和CARLA等仿真环境中均取得了优于现有方法的性能，尤其在抵御网络物理攻击方面效果显著。", "motivation": "自动驾驶系统在面对罕见的极端情况（如长尾场景）或网络物理攻击时，需要保持安全和有效。现有的方法在处理这些威胁时存在不足。", "method": "RAIL框架融合了三种运行时信号（曲率驱动完整性、碰撞时间临近性、观测偏移一致性），通过加权“有噪声或”模型计算入侵风险得分（IRS）。当IRS超过阈值时，会使用基于学习的权限，将动作与特定于线索的防护措施进行融合，同时保留人工干预选项。当风险较低时，执行标准策略。一个上下文赌徒根据线索向量在不同防护措施之间进行仲裁，实现在线优化。RAIL将Soft Actor-Critic（SAC）与风险优先回放和双重奖励相结合，使接管和近乎碰撞的事件能够指导学习，同时覆盖正常行为。针对网络物理攻击，RAIL能够检测并采取相应的防护措施。", "result": "在MetaDrive上，RAIL达到了360.65的测试回报（TR）、0.85的测试成功率（TSR）、0.75的测试安全违规率（TSV）和0.0027的干扰率（DR），同时仅记录了29.07的训练安全违规。在CAN注入和LiDAR欺骗攻击下，其成功率（SR）提高到0.68和0.80，攻击下的撤离率（DRA）降低到0.37和0.03，攻击成功率（ASR）降低到0.34和0.11。在CARLA中，RAIL在8000步内实现了1609.70的TR和0.41的TSR。", "conclusion": "RAIL是一个有效的风险感知“人在回路”框架，能够显著提高自动驾驶系统在面对长尾场景和网络物理攻击时的鲁棒性和安全性。通过融合多种运行时信息、风险量化和自适应的防护措施，RAIL能够实现更安全的策略执行和更有效的在线学习。"}}
{"id": "2601.12070", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.12070", "abs": "https://arxiv.org/abs/2601.12070", "authors": ["Ruslan Zakirzyanov"], "title": "A method for optimizing the structure of the software and hardware complex of a distributed process control system for large industrial enterprises", "comment": null, "summary": "The article proposes a method for optimizing the structure of the software and hardware complex of an automated control system for continuous technological processes for large industrial enterprises. General information is given on the relevance of the problem of choosing the structure of a system built on the basis of serially produced components, a formal description of the optimization problem is given, the criterion and limitations are highlighted. A solution method using the metaheuristic algorithm of ant colonies is described. A numerical example of the solution is given, the results of the algorithm are analyzed, and directions for further research are determined.", "AI": {"tldr": "本文提出了一种优化大型工业企业连续工艺流程自动化控制系统软硬件结构的方法，采用蚁群元启发式算法解决。最后通过数值示例分析了算法结果。", "motivation": "选择基于系列生产组件构建的自动化控制系统结构是一个重要且相关的问题，尤其对于大型工业企业。现有的解决方案可能不够优化。", "method": "该研究首先对优化问题进行了形式化描述，明确了优化目标和限制条件。然后，采用蚁群元启发式算法来解决这个问题。", "result": "通过一个数值示例展示了所提出方法的有效性，并对算法的求解结果进行了分析。", "conclusion": "所提出的基于蚁群算法的软硬件结构优化方法能够有效地解决大型工业企业连续工艺流程自动化控制系统结构设计问题。研究还指出了未来进一步研究的方向。"}}
{"id": "2601.11579", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11579", "abs": "https://arxiv.org/abs/2601.11579", "authors": ["Krzysztof Ociepa", "Łukasz Flis", "Remigiusz Kinas", "Krzysztof Wróbel", "Adrian Gwoździej"], "title": "Bielik 11B v3: Multilingual Large Language Model for European Languages", "comment": null, "summary": "We present Bielik 11B v3, a state-of-the-art language model highly optimized for the Polish language, while also maintaining strong capabilities in other European languages. This model extends the Mistral 7B v0.2 architecture, scaled to 11B parameters via depth up-scaling. Its development involved a comprehensive four-stage training pipeline: continuous pre-training, supervised fine-tuning (SFT), Direct Preference Optimization (DPO), and reinforcement learning.\n  Comprehensive evaluations demonstrate that Bielik 11B v3 achieves exceptional performance. It significantly surpasses other specialized Polish language models and outperforms many larger models (with 2-6 times more parameters) on a wide range of tasks, from basic linguistic understanding to complex reasoning.\n  The model's parameter efficiency, combined with extensive quantization options, allows for effective deployment across diverse hardware configurations. Bielik 11B v3 not only advances AI capabilities for the Polish language but also establishes a new benchmark for developing resource-efficient, high-performance models for less-represented languages.", "AI": {"tldr": "Bielik 11B v3 是一个为波兰语高度优化但同时保持其他欧洲语言能力的先进语言模型，它在多种任务上超越了其他波兰语模型和参数量更大的模型，并且易于部署。", "motivation": "为了开发一个在波兰语上表现出色、同时具备多语言能力且资源高效的语言模型。", "method": "基于 Mistral 7B v0.2 架构，通过增加深度扩展到 11B 参数，并采用了四阶段训练流程：连续预训练、监督微调 (SFT)、直接偏好优化 (DPO) 和强化学习。", "result": "Bielik 11B v3 在各种任务上表现出色，显著优于专门的波兰语模型，并且在参数量小于其 2-6 倍的许多模型之上，同时具备高效的部署能力。", "conclusion": "Bielik 11B v3 在波兰语 AI 能力方面取得了重大进展，并为资源受限但重要的语言开发高效高性能模型树立了新标杆。"}}
{"id": "2601.12116", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12116", "abs": "https://arxiv.org/abs/2601.12116", "authors": ["Hang Xu", "Yizhou Chen", "Dongjie Yu", "Yi Ren", "Jia PanI"], "title": "BiKC+: Bimanual Hierarchical Imitation with Keypose-Conditioned Coordination-Aware Consistency Policies", "comment": "Accepted by IEEE Transactions on Automation Science and Engineering 2025", "summary": "Robots are essential in industrial manufacturing due to their reliability and efficiency. They excel in performing simple and repetitive unimanual tasks but still face challenges with bimanual manipulation. This difficulty arises from the complexities of coordinating dual arms and handling multi-stage processes. Recent integration of generative models into imitation learning (IL) has made progress in tackling specific challenges. However, few approaches explicitly consider the multi-stage nature of bimanual tasks while also emphasizing the importance of inference speed. In multi-stage tasks, failures or delays at any stage can cascade over time, impacting the success and efficiency of subsequent sub-stages and ultimately hindering overall task performance. In this paper, we propose a novel keypose-conditioned coordination-aware consistency policy tailored for bimanual manipulation. Our framework instantiates hierarchical imitation learning with a high-level keypose predictor and a low-level trajectory generator. The predicted keyposes serve as sub-goals for trajectory generation, indicating targets for individual sub-stages. The trajectory generator is formulated as a consistency model, generating action sequences based on historical observations and predicted keyposes in a single inference step. In particular, we devise an innovative approach for identifying bimanual keyposes, considering both robot-centric action features and task-centric operation styles. Simulation and real-world experiments illustrate that our approach significantly outperforms baseline methods in terms of success rates and operational efficiency. Implementation codes can be found at https://github.com/JoanaHXU/BiKC-plus.", "AI": {"tldr": "提出一种新颖的关键姿态条件协调感知一致性策略，用于解决双臂操作中的多阶段任务，通过分层模仿学习，结合了关键姿态预测和基于一致性模型的轨迹生成，实现了更高的成功率和效率。", "motivation": "现有模仿学习方法在处理双臂操作的多阶段任务时存在不足，容易因早期阶段的失败或延迟导致后续阶段的级联效应，影响整体性能，同时对推理速度的关注不够。", "method": "采用分层模仿学习框架，包括一个高层关键姿态预测器和一个低层轨迹生成器。关键姿态作为子目标指导轨迹生成。轨迹生成器被设计为一个一致性模型，在单次推理中根据历史观察和预测的关键姿态生成动作序列。关键姿态的识别方法考虑了机器人中心动作特征和任务中心操作风格。", "result": "在模拟和真实世界实验中，所提出的方法在成功率和操作效率方面显著优于基线方法。", "conclusion": "所提出的关键姿态条件协调感知一致性策略能够有效地解决双臂操作中的多阶段任务挑战，并通过分层方法和一致性模型提高了性能和效率。"}}
{"id": "2601.11632", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11632", "abs": "https://arxiv.org/abs/2601.11632", "authors": ["Zhiyang Li", "Ao Ke", "Yukun Cao", "Xike Xie"], "title": "KG-ViP: Bridging Knowledge Grounding and Visual Perception in Multi-modal LLMs for Visual Question Answering", "comment": null, "summary": "Multi-modal Large Language Models (MLLMs) for Visual Question Answering (VQA) often suffer from dual limitations: knowledge hallucination and insufficient fine-grained visual perception. Crucially, we identify that commonsense graphs and scene graphs provide precisely complementary solutions to these respective deficiencies by providing rich external knowledge and capturing fine-grained visual details. However, prior works typically treat them in isolation, overlooking their synergistic potential. To bridge this gap, we propose KG-ViP, a unified framework that empowers MLLMs by fusing scene graphs and commonsense graphs. The core of the KG-ViP framework is a novel retrieval-and-fusion pipeline that utilizes the query as a semantic bridge to progressively integrate both graphs, synthesizing a unified structured context that facilitates reliable multi-modal reasoning. Extensive experiments on FVQA 2.0+ and MVQA benchmarks demonstrate that KG-ViP significantly outperforms existing VQA methods.", "AI": {"tldr": "提出了一种名为 KG-ViP 的统一框架，通过融合场景图和常识图来增强多模态大语言模型（MLLMs）在视觉问答（VQA）中的性能，解决了知识幻觉和视觉感知不足的问题。", "motivation": "现有的视觉问答方法在知识幻觉和细粒度视觉感知方面存在不足。常识图和场景图能分别弥补这些不足，但现有研究未有效利用它们的协同潜力。", "method": "提出了 KG-ViP 框架，包含一个创新的检索-融合流水线。该流水线利用查询作为语义桥梁，逐步整合场景图和常识图，生成统一的结构化上下文，以支持可靠的多模态推理。", "result": "在 FVQA 2.0+ 和 MVQA 基准测试上进行了广泛实验，结果表明 KG-ViP 的性能显著优于现有 VQA 方法。", "conclusion": "KG-ViP 框架通过融合场景图和常识图，有效提升了 MLLMs 在 VQA 任务上的表现，克服了知识幻觉和细粒度视觉感知不足的挑战。"}}
{"id": "2601.12261", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12261", "abs": "https://arxiv.org/abs/2601.12261", "authors": ["Chunyang Fu", "Ge Li", "Wei Gao", "Shiqi Wang", "Zhu Li", "Shan Liu"], "title": "DALD-PCAC: Density-Adaptive Learning Descriptor for Point Cloud Lossless Attribute Compression", "comment": "Accepted by TOMM", "summary": "Recently, deep learning has significantly advanced the performance of point cloud geometry compression. However, the learning-based lossless attribute compression of point clouds with varying densities is under-explored. In this paper, we develop a learning-based framework, namely DALD-PCAC that leverages Levels of Detail (LoD) to tailor for point cloud lossless attribute compression. We develop a point-wise attention model using a permutation-invariant Transformer to tackle the challenges of sparsity and irregularity of point clouds during context modeling. We also propose a Density-Adaptive Learning Descriptor (DALD) capable of capturing structure and correlations among points across a large range of neighbors. In addition, we develop a prior-guided block partitioning to reduce the attribute variance within blocks and enhance the performance. Experiments on LiDAR and object point clouds show that DALD-PCAC achieves the state-of-the-art performance on most data. Our method boosts the compression performance and is robust to the varying densities of point clouds. Moreover, it guarantees a good trade-off between performance and complexity, exhibiting great potential in real-world applications. The source code is available at https://github.com/zb12138/DALD_PCAC.", "AI": {"tldr": "提出了一种名为DALD-PCAC的基于学习的框架，用于点云无损属性压缩，该框架利用细节层次（LoD）来处理不同密度的点云。", "motivation": "现有基于学习的点云几何压缩方法取得了显著进展，但对于具有不同密度的点云的无损属性压缩研究不足。", "method": "开发了一个名为DALD-PCAC的框架，该框架：1. 使用基于点注意力的、置换不变的Transformer进行上下文建模，以处理点云的稀疏性和不规则性；2. 提出了一种密度自适应学习描述符（DALD），用于捕捉点之间的大范围邻域结构和相关性；3. 开发了一种先验引导的块划分方法，以减小块内属性方差并提高性能。", "result": "在LiDAR和物体点云上进行的实验表明，DALD-PCAC在大多数数据集上都取得了最先进的性能，提高了压缩性能，并且对点云密度的变化具有鲁棒性。", "conclusion": "DALD-PCAC在点云无损属性压缩方面表现出色，实现了性能和复杂度的良好权衡，具有在实际应用中的巨大潜力。"}}
{"id": "2601.11792", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11792", "abs": "https://arxiv.org/abs/2601.11792", "authors": ["Yifei Sun", "Yongan Li", "A. K. Qin", "Sicheng Hou", "Tamas Pflanzner"], "title": "A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation", "comment": null, "summary": "Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. In recent years, the rapid development of large language models (LLMs) has enabled new technological approaches to problem-generation tasks. Although existing LLMs can achieve high correctness rates, they generally lack innovation and exhibit poor discrimination. In this paper, we propose the task of innovative math problem generation (IMPG). To solve the IMPG task, this paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance. First, a multi-role collaborative mechanism comprising a sampler, generator, evaluator, state machine, and memory is constructed, ensuring the correctness of generated problems through iterative optimization informed by self-assessment and external feedback. Second, we introduce an improved difficulty model to quantify difficulty and provide fine-grained guidance. We adopt the data-driven association-guided path sampling (DAPS) algorithm to enhance the semantic rationality of sampled encodings. Third, we construct the HSM3K-CN dataset, which comprises high-quality high school math problems. A multi-stage training pipeline is adopted, incorporating continual pre-training (CPT), supervised fine-tuning (SFT), and group relative policy optimization (GRPO), to enhance the generation and evaluation capabilities of the base model. Finally, system self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show that, compared to baseline models, our proposed method significantly improves the innovation of the generated problems while maintaining a high correctness rate.", "AI": {"tldr": "提出了一种创新的数学问题生成（IMPG）框架，利用多角色协作和细粒度难度指导，生成具有创新性和高正确率的数学问题，并构建了HSM3K-CN数据集。", "motivation": "现有的大型语言模型在生成数学问题时，虽然正确率高，但缺乏创新性和区分度，因此需要研究创新的数学问题生成任务。", "method": "提出一个自进化的、多角色协作的框架，包含采样器、生成器、评估器、状态机和记忆体，通过迭代优化保证问题正确性；引入改进的难度模型进行细粒度难度指导；采用DAPS算法提升采样编码的语义合理性；构建HSM3K-CN数据集；采用CPT、SFT和GRPO的多阶段训练流程；通过蒸馏实现系统自进化。", "result": "与基线模型相比，所提出的方法显著提高了生成问题的创新性，同时保持了高正确率。", "conclusion": "所提出的IMPG框架能够有效生成创新性高且正确率高的数学问题，为智能教育领域的问题生成提供了新的技术路径。"}}
{"id": "2601.11580", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11580", "abs": "https://arxiv.org/abs/2601.11580", "authors": ["Xiaoxuan Liu", "Jiaxiang Yu", "Jongseok Park", "Ion Stoica", "Alvin Cheung"], "title": "Speculative Decoding: Performance or Illusion?", "comment": null, "summary": "Speculative decoding (SD) has become a popular technique to accelerate Large Language Model (LLM) inference, yet its real-world effectiveness remains unclear as prior evaluations rely on research prototypes and unrealistically small batch sizes. We present, to our knowledge, the first systematic study of SD on a production-grade and widely deployed inference engine (vLLM), covering multiple SD variants ($n$-gram, EAGLE/EAGLE-3, Draft-Model, Multi-Token Prediction) across diverse workloads, model scales, and batch sizes. We analyze key factors governing SD performance, and quantify a theoretical upper bound on SD speedup. Our results show that verification by the target model dominates the execution, while acceptance length varies markedly across output token positions, requests, and datasets. Comparing measured performance with theoretical bounds reveals substantial gaps between observed and theoretical upper bounds, and we leverage this observation to highlight new research opportunities that our study opens up in improving SD.", "AI": {"tldr": "本文首次对生产级推理引擎vLLM上的多种投机解码（SD）变体进行了系统性研究，发现模型验证是主要的执行部分，且不同情况下的接受长度变化很大，这揭示了改进SD的新研究方向。", "motivation": "现有对投机解码（SD）的研究主要依赖于研究原型和不切实际的小批量大小，其在实际应用中的效果尚不清楚。", "method": "作者在生产级推理引擎vLLM上，对多种SD变体（$n$-gram, EAGLE/EAGLE-3, Draft-Model, Multi-Token Prediction）进行了评估，覆盖了不同的工作负载、模型规模和批量大小。同时，量化了SD加速的理论上限，并分析了影响SD性能的关键因素。", "result": "模型验证是SD执行过程中的主要耗时部分。接受长度在输出 token 位置、请求和数据集之间存在显著差异。实测性能与理论上限之间存在较大差距。", "conclusion": "通过揭示实测性能与理论上限的差距，本文指出了改进SD的新研究机会，例如优化模型验证或提高接受长度的稳定性。"}}
{"id": "2601.12081", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12081", "abs": "https://arxiv.org/abs/2601.12081", "authors": ["Tomás Tapia", "Yury Dvorkin"], "title": "Reachability Guarantees for Energy Arbitrage", "comment": null, "summary": "This paper introduces a unified framework for battery energy arbitrage under uncertain market prices that integrates chance-constrained terminal state-of-charge requirements with online threshold policies. We first cast the multi-interval arbitrage problem as a stochastic dynamic program enhanced by a probabilistic end-of-horizon state-of-charge (SoC) constraint, ensuring with high confidence that the battery terminates within a prescribed energy band. We then apply a $k$-search algorithm to derive explicit charging (buying) and discharging (selling) thresholds with provable worst-case competitive ratio, and compute the corresponding action probabilities over the decision horizon. To compute exact distributions under operational limits, we develop a probability redistribution pruning method and use it to quantify the likelihood of meeting the terminal SoC band. Leveraging the resulting SoC distribution, we estimate the minimum stopping-time required to satisfy the SoC chance constraint. Computational experiments on historical real price data demonstrate that the proposed framework substantially improves the estimation of SoC evolution and supports chance-constraint satisfaction.", "AI": {"tldr": "本文提出了一个统一的电池能量套利框架，能够处理不确定的市场价格，并结合了具有概率约束的终端荷电状态要求和在线阈值策略。", "motivation": "电池能量套利在不确定的市场价格下，需要确保电池在结束时具有特定的荷电状态，这是一个挑战。因此，研究者希望提出一种能够同时处理不确定价格和终端荷电状态约束的框架。", "method": "该研究将多区间套利问题建模为一个随机动态规划问题，并加入了概率约束的终端荷电状态约束。然后，使用 k-search 算法推导出显式的充电和放电阈值，并计算相应动作的概率。此外，还开发了一种概率重新分配修剪方法来量化满足终端荷电状态范围的可能性，并估算了满足荷电状态概率约束所需的最小停止时间。", "result": "计算实验表明，该框架能够显著改进荷电状态演变的估计，并支持概率约束的满足。", "conclusion": "本文提出的统一框架能够有效地处理不确定的市场价格下的电池能量套利问题，并满足概率约束的终端荷电状态要求，从而提高套利效率和电池的长期健康度。"}}
{"id": "2601.11809", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11809", "abs": "https://arxiv.org/abs/2601.11809", "authors": ["Zeyu Mu", "Shangtong Zhang", "B. Brian Park"], "title": "Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic", "comment": "Under review at IEEE Transactions on Intelligent Transportation Systems", "summary": "Connected automated vehicles (CAVs) possess the ability to communicate and coordinate with one another, enabling cooperative platooning that enhances both energy efficiency and traffic flow. However, during the initial stage of CAV deployment, the sparse distribution of CAVs among human-driven vehicles reduces the likelihood of forming effective cooperative platoons. To address this challenge, this study proposes a hybrid multi-agent lane change decision model aimed at increasing CAV participation in cooperative platooning and maximizing its associated benefits. The proposed model employs the QMIX framework, integrating traffic data processed through a convolutional neural network (CNN-QMIX). This architecture addresses a critical issue in dynamic traffic scenarios by enabling CAVs to make optimal decisions irrespective of the varying number of CAVs present in mixed traffic. Additionally, a trajectory planner and a model predictive controller are designed to ensure smooth and safe lane-change execution. The proposed model is trained and evaluated within a microsimulation environment under varying CAV market penetration rates. The results demonstrate that the proposed model efficiently manages fluctuating traffic agent numbers, significantly outperforming the baseline rule-based models. Notably, it enhances cooperative platooning rates up to 26.2\\%, showcasing its potential to optimize CAV cooperation and traffic dynamics during the early stage of deployment.", "AI": {"tldr": "本文提出了一种混合多智能体变道决策模型（CNN-QMIX），利用QMIX框架和卷积神经网络，旨在提高在混合交通流中（大量燃油车伴随少量自动驾驶车辆）自动驾驶车辆（CAVs）参与合作编队的意愿，并通过轨迹规划器和模型预测控制器保证变道安全性和平滑性。", "motivation": "在自动驾驶车辆（CAVs）部署初期，CAVs数量稀少，难以形成有效的合作车队，导致其在提升能源效率和交通流方面的优势无法充分发挥。因此，需要一种模型来促进CAVs的合作，即使在CAVs渗透率较低的情况下也能最大化其效益。", "method": "本文提出了一种混合多智能体车道变更决策模型，名为CNN-QMIX。该模型基于QMIX框架，并结合了卷积神经网络（CNN）来处理交通数据。此外，还设计了轨迹规划器和模型预测控制器来实现平稳安全的变道操作。模型在微观模拟环境中进行训练和评估。", "result": "所提出的CNN-QMIX模型能够有效地处理动态变化的交通参与者数量，其性能显著优于基线规则模型。该模型可以将合作车队的比率提高高达26.2%。", "conclusion": "CNN-QMIX模型在CAVs部署初期，面对混合交通流中CAVs数量波动的情况下，能够有效提升CAVs的合作编队率，并最大化合作效益，为优化CAVs的部署和交通动态提供了可行方案。"}}
{"id": "2601.12122", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12122", "abs": "https://arxiv.org/abs/2601.12122", "authors": ["Jose Cuaran", "Naveen K. Upalapati", "Girish Chowdhary"], "title": "Active Semantic Mapping of Horticultural Environments Using Gaussian Splatting", "comment": "9 pages, 4 figures", "summary": "Semantic reconstruction of agricultural scenes plays a vital role in tasks such as phenotyping and yield estimation. However, traditional approaches that rely on manual scanning or fixed camera setups remain a major bottleneck in this process. In this work, we propose an active 3D reconstruction framework for horticultural environments using a mobile manipulator. The proposed system integrates the classical Octomap representation with 3D Gaussian Splatting to enable accurate and efficient target-aware mapping. While a low-resolution Octomap provides probabilistic occupancy information for informative viewpoint selection and collision-free planning, 3D Gaussian Splatting leverages geometric, photometric, and semantic information to optimize a set of 3D Gaussians for high-fidelity scene reconstruction. We further introduce simple yet effective strategies to enhance robustness against segmentation noise and reduce memory consumption. Simulation experiments demonstrate that our method outperforms purely occupancy-based approaches in both runtime efficiency and reconstruction accuracy, enabling precise fruit counting and volume estimation. Compared to a 0.01m-resolution Octomap, our approach achieves an improvement of 6.6% in fruit-level F1 score under noise-free conditions, and up to 28.6% under segmentation noise. Additionally, it achieves a 50% reduction in runtime, highlighting its potential for scalable, real-time semantic reconstruction in agricultural robotics.", "AI": {"tldr": "提出了一种基于移动机械臂的主动3D重建框架，结合Octomap和3D高斯溅射技术，用于园艺环境的语义重建，在效率和准确性上优于传统方法，并能有效处理分割噪声。", "motivation": "传统农业场景语义重建方法（手动扫描或固定相机）存在瓶颈，阻碍了表型分析和产量估算等任务。需要更高效、准确的主动3D重建方法。", "method": "提出一个主动3D重建框架，使用移动机械臂。集成Octomap（低分辨率，用于视点选择和碰撞检测）和3D高斯溅射（利用几何、光度和语义信息进行高保真重建）。引入策略以增强对分割噪声的鲁棒性和减少内存消耗。", "result": "与纯粹基于占用率的方法相比，在运行时效率和重建准确性上均有优势。在无噪声条件下，水果级F1分数提高6.6%；在有分割噪声时，提高28.6%。运行时减少50%。", "conclusion": "该框架能够实现高效、准确且对分割噪声鲁棒的农业场景语义重建，特别适用于农业机器人领域的实时和可扩展应用，可用于精确的水果计数和体积估算。"}}
{"id": "2601.11633", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11633", "abs": "https://arxiv.org/abs/2601.11633", "authors": ["Xuchen Li", "Xuzhao Li", "Renjie Pi", "Shiyu Hu", "Jian Zhao", "Jiahui Gao"], "title": "Beyond Accuracy: Evaluating Grounded Visual Evidence in Thinking with Images", "comment": "Preprint, Under review", "summary": "Despite the remarkable progress of Vision-Language Models (VLMs) in adopting \"Thinking-with-Images\" capabilities, accurately evaluating the authenticity of their reasoning process remains a critical challenge. Existing benchmarks mainly rely on outcome-oriented accuracy, lacking the capability to assess whether models can accurately leverage fine-grained visual cues for multi-step reasoning. To address these limitations, we propose ViEBench, a process-verifiable benchmark designed to evaluate faithful visual reasoning. Comprising 200 multi-scenario high-resolution images with expert-annotated visual evidence, ViEBench uniquely categorizes tasks by difficulty into perception and reasoning dimensions, where reasoning tasks require utilizing localized visual details with prior knowledge. To establish comprehensive evaluation criteria, we introduce a dual-axis matrix that provides fine-grained metrics through four diagnostic quadrants, enabling transparent diagnosis of model behavior across varying task complexities. Our experiments yield several interesting observations: (1) VLMs can sometimes produce correct final answers despite grounding on irrelevant regions, and (2) they may successfully locate the correct evidence but still fail to utilize it to reach accurate conclusions. Our findings demonstrate that ViEBench can serve as a more explainable and practical benchmark for comprehensively evaluating the effectiveness agentic VLMs. The codes will be released at: https://github.com/Xuchen-Li/ViEBench.", "AI": {"tldr": "本文提出了ViEBench，一个用于评估视觉语言模型（VLM）视觉推理过程真实性的基准。与仅关注最终结果准确性的现有基准不同，ViEBench包含带有专家标注证据的高分辨率图像，并根据感知和推理难度对任务进行分类，以评估模型是否能利用细粒度的视觉线索进行多步推理。研究发现，VLM有时会基于不相关的区域给出正确答案，或者即使找到正确证据也无法得出正确结论。ViEBench为评估模型行为提供了更具解释性和实用性的方法。", "motivation": "现有的视觉语言模型（VLM）评估方法主要依赖于最终结果的准确性，无法有效评估模型是否真正利用了视觉证据进行多步推理，即缺乏对模型“思考过程”的评估。这使得理解和改进VLM的真实视觉推理能力变得困难。", "method": "本文提出了ViEBench基准，包含200张高分辨率图像，涵盖多种场景。任务根据感知和推理难度分类，其中推理任务需要利用局部视觉细节和先验知识。引入了一个双轴评估矩阵，通过四个诊断象限提供细粒度指标，以透明地诊断模型在不同任务复杂度下的行为。", "result": "实验揭示了VLM评估中的两个关键问题：（1）VLM有时会因为 grounding 到不相关的视觉区域而得出正确答案；（2）VLM可能成功定位到正确证据，但仍无法利用该证据得出准确结论。这表明仅仅关注最终答案的准确性是不足够的。", "conclusion": "ViEBench是一个更具解释性且实用的基准，能够更全面地评估具身VLM的视觉推理能力。通过其细粒度的评估指标，可以更深入地理解模型在推理过程中遇到的挑战，并指导未来的模型改进。"}}
{"id": "2601.12143", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12143", "abs": "https://arxiv.org/abs/2601.12143", "authors": ["Devin Hunter", "Chinwendu Enyioha"], "title": "Neural Process-Based Reactive Controller for Autonomous Racing", "comment": "6 pages, 4 figures", "summary": "Attention-based neural architectures have become central to state-of-the-art methods in real-time nonlinear control. As these data-driven models continue to be integrated into increasingly safety-critical domains, ensuring statistically grounded and provably safe decision-making becomes essential. This paper introduces a novel reactive control framework for gap-based navigation using the Attentive Neural Process (AttNP) and a physics-informed extension, the PI-AttNP. Both models are evaluated in a simulated F1TENTH-style Ackermann steering racecar environment, chosen as a fast-paced proxy for safety-critical autonomous driving scenarios. The PI-AttNP augments the AttNP architecture with approximate model-based priors to inject physical inductive bias, enabling faster convergence and improved prediction accuracy suited for real-time control. To further ensure safety, we derive and implement a control barrier function (CBF)-based filtering mechanism that analytically enforces collision avoidance constraints. This CBF formulation is fully compatible with the learned AttNP controller and generalizes across a wide range of racing scenarios, providing a lightweight and certifiable safety layer. Our results demonstrate competitive closed-loop performance while ensuring real-time constraint satisfaction.", "AI": {"tldr": "该研究提出了一种基于Attentive Neural Process (AttNP) 的新型反应式控制框架，用于基于间隙的导航，并引入了物理信息扩展PI-AttNP，以提高收敛速度和预测精度。同时，结合了控制障碍函数（CBF）来保证碰撞避免的安全约束。", "motivation": "随着数据驱动模型在安全关键领域的应用日益增多，为实时非线性控制中的注意力神经架构提供统计学上的保证和可证明的安全性变得至关重要。", "method": "提出并评估了Attentive Neural Process (AttNP) 和物理信息扩展PI-AttNP 模型。PI-AttNP通过注入物理归纳偏置来增强AttNP。同时，设计并实现了一个基于控制障碍函数（CBF）的滤波机制，以强制执行碰撞避免约束。", "result": "PI-AttNP模型在模拟的F1TENTH赛车环境中展示了更快的收敛速度和更高的预测精度。CBF滤波机制能够有效地保证实时约束满足，并提供轻量级且可验证的安全层。闭环性能具有竞争力。", "conclusion": "该研究提出了一种结合了AttNP/PI-AttNP控制器和CBF安全层的反应式控制框架，该框架在保证实时性能的同时，能够提供可证明的安全性，适用于安全关键的自动驾驶场景。"}}
{"id": "2601.11634", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11634", "abs": "https://arxiv.org/abs/2601.11634", "authors": ["Chenghui Yu", "Hongwei Wang", "Junwen Chen", "Zixuan Wang", "Bingfeng Deng", "Zhuolin Hao", "Hongyu Xiong", "Yang Song"], "title": "When Rules Fall Short: Agent-Driven Discovery of Emerging Content Issues in Short Video Platforms", "comment": null, "summary": "Trends on short-video platforms evolve at a rapid pace, with new content issues emerging every day that fall outside the coverage of existing annotation policies. However, traditional human-driven discovery of emerging issues is too slow, which leads to delayed updates of annotation policies and poses a major challenge for effective content governance. In this work, we propose an automatic issue discovery method based on multimodal LLM agents. Our approach automatically recalls short videos containing potential new issues and applies a two-stage clustering strategy to group them, with each cluster corresponding to a newly discovered issue. The agent then generates updated annotation policies from these clusters, thereby extending coverage to these emerging issues. Our agent has been deployed in the real system. Both offline and online experiments demonstrate that this agent-based method significantly improves the effectiveness of emerging-issue discovery (with an F1 score improvement of over 20%) and enhances the performance of subsequent issue governance (reducing the view count of problematic videos by approximately 15%). More importantly, compared to manual issue discovery, it greatly reduces time costs and substantially accelerates the iteration of annotation policies.", "AI": {"tldr": "提出了一种基于多模态大语言模型（LLM）智能体的自动新兴问题发现方法，用于短视频平台的内容治理，可显著提高问题发现效率和治理效果，并加速标注策略的迭代。", "motivation": "传统的人工发现新兴内容问题速度慢，导致标注策略更新滞后，对有效的内容治理构成挑战。", "method": "利用多模态LLM智能体，自动召回包含潜在新问题的短视频，采用两阶段聚类策略对视频进行分组，每个聚类代表一个新发现的问题，并从聚类结果生成更新的标注策略。", "result": "在实际系统中部署后，离线和在线实验表明，该方法将新兴问题发现的F1分数提高了20%以上，并将后续问题治理的性能提高了约15%（减少了问题视频的观看次数）。", "conclusion": "基于LLM智能体的方法能够有效发现新兴问题，提高内容治理效率，并显著缩短标注策略的迭代周期，优于手动发现方法。"}}
{"id": "2601.11581", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11581", "abs": "https://arxiv.org/abs/2601.11581", "authors": ["Yuefeng Wang", "ChangJae Lee"], "title": "Enhancing the QA Model through a Multi-domain Debiasing Framework", "comment": "5 pages, 7 tables", "summary": "Question-answering (QA) models have advanced significantly in machine reading comprehension but often exhibit biases that hinder their performance, particularly with complex queries in adversarial conditions. This study evaluates the ELECTRA-small model on the Stanford Question Answering Dataset (SQuAD) v1.1 and adversarial datasets AddSent and AddOneSent. By identifying errors related to lexical bias, numerical reasoning, and entity recognition, we develop a multi-domain debiasing framework incorporating knowledge distillation, debiasing techniques, and domain expansion. Our results demonstrate up to 2.6 percentage point improvements in Exact Match (EM) and F1 scores across all test sets, with gains in adversarial contexts. These findings highlight the potential of targeted bias mitigation strategies to enhance the robustness and reliability of natural language understanding systems.", "AI": {"tldr": "研究通过识别和解决ELECTRA-small模型在SQuAD、AddSent和AddOneSent数据集上的词汇偏见、数值推理和实体识别错误，提出了一种多领域去偏框架，并将EM和F1分数提高了2.6个百分点，尤其是在对抗性场景下。", "motivation": "现有的问答模型在处理复杂查询和对抗性条件时存在偏见，影响了性能。本研究旨在解决这些偏见，提高模型的鲁棒性和可靠性。", "method": "首先，评估了ELECTRA-small模型在SQuAD v1.1、AddSent和AddOneSent数据集上的表现，并识别了其在词汇偏见、数值推理和实体识别方面的错误。然后，开发了一个多领域去偏框架，结合了知识蒸馏、去偏技术和领域扩展。", "result": "所提出的去偏框架在所有测试集上将Exact Match (EM) 和F1分数提高了高达2.6个百分点，在对抗性场景下的提升尤为显著。", "conclusion": "针对性的偏见缓解策略能够有效增强自然语言理解系统的鲁棒性和可靠性，为提高QA模型的性能提供了有效途径。"}}
{"id": "2601.12526", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2601.12526", "abs": "https://arxiv.org/abs/2601.12526", "authors": ["Brayan Monroy", "Jorge Bacca"], "title": "Deep Lightweight Unrolled Network for High Dynamic Range Modulo Imaging", "comment": null, "summary": "Modulo-Imaging (MI) offers a promising alternative for expanding the dynamic range of images by resetting the signal intensity when it reaches the saturation level. Subsequently, high-dynamic range (HDR) modulo imaging requires a recovery process to obtain the HDR image. MI is a non-convex and ill-posed problem where recent recovery networks suffer in high-noise scenarios. In this work, we formulate the HDR reconstruction task as an optimization problem that incorporates a deep prior and subsequently unrolls it into an optimization-inspired deep neural network. The network employs a lightweight convolutional denoiser for fast inference with minimal computational overhead, effectively recovering intensity values while mitigating noise. Moreover, we introduce the Scaling Equivariance term that facilitates self-supervised fine-tuning, thereby enabling the model to adapt to new modulo images that fall outside the original training distribution. Extensive evaluations demonstrate the superiority of our method compared to state-of-the-art recovery algorithms in terms of performance and quality.", "AI": {"tldr": "提出了一种基于深度先验的优化网络，用于从模成像数据中恢复高动态范围图像，该网络具有轻量级去噪器和尺度等变性正则化，能在高噪声环境下有效提升图像质量。", "motivation": "现有的高动态范围（HDR）模成像恢复方法在高噪声场景下表现不佳，需要更鲁棒的恢复算法。", "method": "将HDR重建视为一个优化问题，并将其展开为一个深度神经网络。网络集成了轻量级的卷积去噪器，并引入了尺度等变性（Scaling Equivariance）项以实现自监督微调。", "result": "该方法在性能和图像质量上优于最先进的恢复算法，特别是在高噪声环境下。", "conclusion": "提出的优化驱动的深度网络结合深度先验和尺度等变性，能够有效且高效地从模成像数据中恢复HDR图像，尤其适用于噪声较大的场景。"}}
{"id": "2601.12210", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.12210", "abs": "https://arxiv.org/abs/2601.12210", "authors": ["Alexander Medvedev", "Anton V. Proskurnikov"], "title": "Solvability of The Output Corridor Control Problem by Pulse-Modulated Feedback", "comment": null, "summary": "The problem of maintaining the output of a positive time-invariant single-input single-output system within a predefined corridor of values is treated. For third-order plants possessing a certain structure, it is proven that the problem is always solvable under stationary conditions by means of pulse-modulated feedback. The obtained result is utilized to assess the feasibility of patient-specific pharmacokinetic-pharmacodynamic models with respect to patient safety. A population of Wiener models capturing the dynamics of a neuromuscular blockade agent is studied to investigate whether or not they can be driven into the desired output corridor by clinically acceptable sequential drug doses (boluses). It is demonstrated that low values of a parameter in the nonlinear pharmacodynamic part lie behind the detected model infeasibility.", "AI": {"tldr": "研究了如何通过脉冲调制反馈使三阶正时不变 SISO 系统输出保持在预定范围内，并将其应用于药物动力学-药效学模型，证明了特定参数的低值是导致模型不可行的原因。", "motivation": "研究的动机是将系统输出维持在预定范围内的技术应用于患者安全问题，特别是通过评估药物动力学-药效学模型与患者安全相关的可行性。", "method": "该研究利用脉冲调制反馈来解决使三阶正时不变 SISO 系统输出保持在预定范围内的问题。然后，将该结果应用于分析具有特定结构的三阶系统。最后，通过研究一系列捕捉神经肌肉阻滞剂动力学的 Wiener 模型，来评估使用临床可接受的剂量序列（推注）是否可以将这些模型驱动到所需的输出范围内。", "result": "对于具有特定结构的第三阶植物，已证明在稳态条件下通过脉冲调制反馈总是可以解决该问题。研究发现，在分析药物动力学-药效学模型时，非线性药效学部分的参数低值是导致模型不可行的原因。", "conclusion": "该研究表明，对于特定结构的三阶系统，通过脉冲调制反馈可以始终保持输出在预定范围内。此外，该研究还发现，在涉及神经肌肉阻滞剂的患者特定药代动力学-药效学模型中，非线性药效学部分的低参数值是导致模型无法被临床可接受的推注剂量驱动到安全输出范围的原因。"}}
{"id": "2601.12236", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12236", "abs": "https://arxiv.org/abs/2601.12236", "authors": ["Sahil Aziz", "Wajid Ali", "Khaliqur Rahman"], "title": "Analyzing the Impact of EV Battery Charging on the Distribution Network", "comment": "6 pages, 5 figures", "summary": "Many countries are rapidly adopting electric vehicles (EVs) due to their meager running cost and environment-friendly nature. EVs are likely to dominate the internal combustion (IC) engine cars entirely over the next few years. With the rise in popularity of EVs, adverse effects of EV charging loads on the grid system have been observed. Since the distribution system (DS) does not cope with the high overloading capacity, the negative impact of EV charging load on the distribution network (DN) cannot be neglected. A high level of EV penetration with uncoordinated charging is the primary cause of voltage instability, increased peak load demand, and reliability issues of the DN. In this paper, a detailed overview of all the notable impacts of EV charging on voltage profile, power quality, and DS performance is discussed. This work also reviews the different topologies of EV chargers and the issues introduced by power converters on the utility grid. Finally, the strategies for improving the charging of EVs proposed in the literature to consider the random nature of EVs charging, the management of peak loads, and bidirectional power flow are summarized.", "AI": {"tldr": "该论文详细概述了电动汽车 (EV) 充电对配电网 (DN) 的影响，包括电压不稳定、峰值负荷增加和可靠性问题。同时，文章还回顾了 EV 充电器拓扑结构及其对电网的影响，并总结了文献中用于改善 EV 充电策略的方法，以应对随机充电、峰值负荷管理和双向潮流。", "motivation": "随着电动汽车普及率的提高，其充电负荷对电网系统产生了负面影响，尤其是配电网容量不足以应对高负荷，因此需要研究和解决这些问题。", "method": "通过详细概述和回顾文献中的信息，讨论了电动汽车充电对电压、电能质量和配电系统性能的影响，并总结了现有的 EV 充电改进策略。", "result": "该论文详细讨论了电动汽车充电对电压、电能质量和配电系统性能的负面影响，并回顾了 EV 充电器拓扑结构及其对电网的影响。", "conclusion": "电动汽车的普及给配电网带来了挑战，但通过采用适当的充电策略，可以有效管理其对电网的影响，包括电压稳定性、峰值负荷和可靠性问题。"}}
{"id": "2601.11816", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11816", "abs": "https://arxiv.org/abs/2601.11816", "authors": ["Zahra Moslemi", "Keerthi Koneru", "Yen-Ting Lee", "Sheethal Kumar", "Ramesh Radhakrishnan"], "title": "POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation", "comment": "Workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks: AAAI 2026", "summary": "Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation", "AI": {"tldr": "POLARIS是一个为企业后台工作流程设计的LLM代理编排框架，通过类型化规划合成、策略引导推理、验证执行和策略护栏，确保了可审计性、策略一致性和可预测性，并在金融文档处理任务中取得了显著成效。", "motivation": "现有的通用多代理系统在企业后台工作流程中，由于缺乏可审计性、策略一致性和可预测性而表现不佳，促使研究人员开发一种更健壮的代理系统。", "method": "POLARIS采用类型化规划合成和验证执行的方法。核心组件包括：1. 规划器（Planner）生成结构多样的类型检查有向无环图（DAG）；2. 评估模块（Rubric guided reasoning）选择符合策略的单一计划；3. 执行模块（Validator gated checks, bounded repair loop, compiled policy guardrails）通过验证检查、修复循环和策略护栏来控制和监控执行过程。", "result": "在金融文档处理任务中，POLARIS能够生成决策级别的产出和完整的执行追踪，减少了人工干预。在SROIE数据集上，POLARIS实现了0.81的微F1分数；在合成数据集上，实现了0.95到1.00的异常路由精确率，并保留了审计追踪。", "conclusion": "POLARIS提供了一个方法论和基准参考，展示了策略一致的Agentic AI在企业自动化领域的潜力，为后续研究和应用奠定了基础。"}}
{"id": "2601.12169", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12169", "abs": "https://arxiv.org/abs/2601.12169", "authors": ["Samuel A. Moore", "Easop Lee", "Boyuan Chen"], "title": "Learning Legged MPC with Smooth Neural Surrogates", "comment": null, "summary": "Deep learning and model predictive control (MPC) can play complementary roles in legged robotics. However, integrating learned models with online planning remains challenging. When dynamics are learned with neural networks, three key difficulties arise: (1) stiff transitions from contact events may be inherited from the data; (2) additional non-physical local nonsmoothness can occur; and (3) training datasets can induce non-Gaussian model errors due to rapid state changes. We address (1) and (2) by introducing the smooth neural surrogate, a neural network with tunable smoothness designed to provide informative predictions and derivatives for trajectory optimization through contact. To address (3), we train these models using a heavy-tailed likelihood that better matches the empirical error distributions observed in legged-robot dynamics. Together, these design choices substantially improve the reliability, scalability, and generalizability of learned legged MPC. Across zero-shot locomotion tasks of increasing difficulty, smooth neural surrogates with robust learning yield consistent reductions in cumulative cost on simple, well-conditioned behaviors (typically 10-50%), while providing substantially larger gains in regimes where standard neural dynamics often fail outright. In these regimes, smoothing enables reliable execution (from 0/5 to 5/5 success) and produces about 2-50x lower cumulative cost, reflecting orders-of-magnitude absolute improvements in robustness rather than incremental performance gains.", "AI": {"tldr": "本文提出了一种平滑神经网络（smooth neural surrogate）和鲁棒学习方法，用于解决深度学习模型在机器人MPC（模型预测控制）中的应用挑战，包括动力学模型中的硬过渡、非物理局部不光滑性以及非高斯模型误差。研究表明，该方法显著提高了学习到的MPC在零样本（zero-shot）运动任务中的可靠性、可扩展性和泛化能力。", "motivation": "将深度学习模型与机器人MPC相结合存在挑战，特别是当使用神经网络学习动力学模型时，会遇到数据中的硬过渡、局部不光滑性和非高斯误差等问题。这限制了学习模型的可靠性和泛化能力。", "method": "研究者提出了平滑神经网络（smooth neural surrogate），这是一种具有可调平滑度的神经网络，用于在接触事件中提供信息丰富的预测和导数。同时，使用具有重尾似然（heavy-tailed likelihood）的训练方法来更好地匹配经验误差分布，以解决非高斯模型误差问题。", "result": "在零样本运动任务中，平滑神经网络结合鲁棒学习方法，在简单、条件良好的行为上，累积成本通常降低10-50%。在标准神经网络模型经常失效的复杂情况下，该方法取得了显著的性能提升，成功率从0/5提高到5/5，累积成本降低2-50倍，表明其鲁棒性有数量级的提升。", "conclusion": "提出的平滑神经网络和鲁棒学习方法能够有效解决深度学习模型在机器人MPC中的关键挑战，显著提高学习到的MPC在各种运动任务中的可靠性、可扩展性和泛化能力，尤其是在标准方法失效的复杂场景下。"}}
{"id": "2601.11585", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11585", "abs": "https://arxiv.org/abs/2601.11585", "authors": ["Hyunjun Kim"], "title": "Entropic Context Shaping: Information-Theoretic Filtering for Context-Aware LLM Agents", "comment": null, "summary": "Context engineering for large language model (LLM) agents requires distinguishing pragmatically useful information from misleading distractors. We introduce Entropic Context Shaping (ECS), an information-theoretic framework that measures context utility via the shift in the model's answer distribution toward the correct answer. Unlike lexical similarity methods that rely on word overlap, ECS captures pragmatic utility -- whether a passage actually helps answer the question. We formalize utility as the signed change in answer probability and provide theoretical analysis showing that task-irrelevant updates yield near-zero distribution shift. We evaluate on multi-turn context selection tasks using LongMemEval (session-level) and LoCoMo (turn-level) benchmarks. On fine-grained turn selection, ECS with Llama-3.1-8B achieves F1=0.265, a 71.83% relative improvement over TF-IDF (F1=0.154), demonstrating that pragmatic utility outperforms lexical similarity when precise context selection matters. Code and data are available in the supplementary materials.", "AI": {"tldr": "本文提出了一种名为Entropic Context Shaping (ECS) 的信息论框架，用于衡量大型语言模型（LLM）代理语境的实用性，通过测量模型答案分布向正确答案的偏移来量化。ECS能够区分有用信息和误导性信息，并优于传统的基于词汇相似度的方法，在多轮对话上下文选择任务中取得了显著的性能提升。", "motivation": "在大型语言模型（LLM）代理的上下文工程中，区分有用的信息和误导性的干扰信息是一个关键挑战。现有的基于词汇相似度的方法未能准确捕捉语境的实际效用，因此需要一种新的方法来衡量语境的实用性。", "method": "ECS框架使用信息论来衡量语境的实用性。它通过计算模型在给定语境下的答案分布与没有该语境时的答案分布之间的变化来量化语境的效用。理论分析表明，与任务无关的语境更新会产生接近零的分布变化。实验在LongMemEval和LoCoMo基准上进行了评估，对比了ECS和TF-IDF在多轮对话上下文选择任务中的表现。", "result": "在细粒度的轮次选择任务上，使用ECS的Llama-3.1-8B模型达到了F1=0.265的F1分数，相比TF-IDF（F1=0.154）有71.83%的相对提升。这表明在需要精确上下文选择的情况下，ECS在捕捉实际效用方面优于词汇相似度。", "conclusion": "Entropic Context Shaping (ECS) 是一种有效的信息论框架，能够衡量大型语言模型代理的语境实用性，并能显著优于传统的基于词汇相似度的方法。ECS能够更准确地识别对模型回答最有帮助的语境信息，从而提升LLM代理在多轮对话任务中的表现。"}}
{"id": "2601.11635", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11635", "abs": "https://arxiv.org/abs/2601.11635", "authors": ["Anil Egin", "Andrea Tangherloni", "Antitza Dantcheva"], "title": "Now You See Me, Now You Don't: A Unified Framework for Expression Consistent Anonymization in Talking Head Videos", "comment": null, "summary": "Face video anonymization is aimed at privacy preservation while allowing for the analysis of videos in a number of computer vision downstream tasks such as expression recognition, people tracking, and action recognition. We propose here a novel unified framework referred to as Anon-NET, streamlined to de-identify facial videos, while preserving age, gender, race, pose, and expression of the original video. Specifically, we inpaint faces by a diffusion-based generative model guided by high-level attribute recognition and motion-aware expression transfer. We then animate deidentified faces by video-driven animation, which accepts the de-identified face and the original video as input. Extensive experiments on the datasets VoxCeleb2, CelebV-HQ, and HDTF, which include diverse facial dynamics, demonstrate the effectiveness of AnonNET in obfuscating identity while retaining visual realism and temporal consistency. The code of AnonNet will be publicly released.", "AI": {"tldr": "提出了一种名为Anon-NET的统一框架，用于视频人脸匿名化，可在保留年龄、性别、种族、姿态和表情的同时，模糊身份信息。", "motivation": "为了在保护隐私的同时，使视频能够在表情识别、人物跟踪和动作识别等计算机视觉下游任务中得到应用。", "method": "通过基于扩散的生成模型对人脸进行修复，该模型由高层属性识别和运动感知表情迁移指导。然后，通过视频驱动的动画来驱动匿名化后的人脸，输入为匿名化后的人脸和原始视频。", "result": "在VoxCeleb2、CelebV-HQ和HDTF数据集上进行了大量实验，证明Anon-NET在模糊身份信息的同时，保持了视觉真实性和时间一致性。", "conclusion": "Anon-NET能够有效地对人脸视频进行匿名化处理，同时保留重要的面部属性和动态信息，为隐私保护下的视频分析提供了有效的解决方案。"}}
{"id": "2601.12941", "categories": ["eess.IV", "cond-mat.mtrl-sci", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2601.12941", "abs": "https://arxiv.org/abs/2601.12941", "authors": ["Joel Hirst", "Lorna Sibson", "Adel Tayeb", "Ben Poole", "Megan Sampson", "Wiera Bielajewa", "Michael Atkinson", "Alex Marsh", "Rory Spencer", "Rob Hamill", "Cory Hamelin", "Allan Harte", "Lloyd Fletcher"], "title": "PYVALE: A Fast, Scalable, Open-Source 2D Digital Image Correlation (DIC) Engine Capable of Handling Gigapixel Images", "comment": null, "summary": "Pyvale is an open-source software package that aims to become an all-in-one tool for sensor simulation, sensor uncertainty quantification, sensor placement optimization, and calibration/validation. Central to this is support for image-based sensors, with a dedicated Digital Image Correlation (DIC) module designed for both standalone use and integration within broader experimental design workflows. The design philosophy behind the DIC engine in Pyvale prioritizes a user-friendly Python interface with performant compiled code under the hood. This paper covers Pyvale's 2D DIC engine design, implementation, metrological performance compared to other DIC codes, and the unique ability to handle gigapixel size scanning electron microscope (SEM) images. Finally, we compare runtimes between Pyvale and other open-source DIC codes and show strong computational performance across a range of image resolutions and thread counts.", "AI": {"tldr": "Pyvale是一个开源软件，旨在整合传感器模拟、不确定性量化、优化和校准功能，特别关注数字图像相关（DIC）模块，支持大数据量图像处理，并与其他DIC软件相比显示出优越的计算性能。", "motivation": "为了提供一个集成的工具来处理传感器模拟、不确定性量化、优化和校准，特别是在图像传感器领域，并解决现有DIC软件在处理大型图像时的性能问题。", "method": "开发了Pyvale软件，包含一个2D DIC引擎，采用Python接口和底层编译代码。通过与现有DIC代码进行元测量性能和运行时比较来评估其能力，特别关注其处理超大尺寸（千兆像素）SEM图像的能力。", "result": "Pyvale的2D DIC引擎在元测量性能上与其他DIC代码相当，并且在处理各种分辨率和线程数的情况下，运行时表现出强大的计算性能。它能够处理尺寸达千兆像素的SEM图像。", "conclusion": "Pyvale是一个功能强大且计算效率高的开源软件，其DIC模块能够有效地处理超大尺寸图像，并有望成为传感器模拟和实验设计工作流程的综合性工具。"}}
{"id": "2601.11825", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11825", "abs": "https://arxiv.org/abs/2601.11825", "authors": ["Arya Rahgozar", "Pouria Mortezaagha"], "title": "AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept", "comment": null, "summary": "Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.", "AI": {"tldr": "本文提出了一种基于PICOS（人群、干预、对照、结局、研究设计）形式化的AI共生科学家平台，用于可扩展和透明的知识综合，以解决生物医学研究中的浪费问题。该平台集成了关系存储、向量语义检索和知识图谱，并通过机器学习模型对研究设计和PICOS合规性进行自动化分类。实验结果表明，该方法能有效提高证据综合的可扩展性、透明度和效率，并能识别研究中的冗余和空白。", "motivation": "生物医学研究中的浪费现象，如重复性研究、信息报告不完整以及传统证据综合工作流程的可扩展性差，促使研究者开发更高效的知识综合方法。", "method": "构建了一个AI共生科学家平台，该平台基于PICOS框架进行显式形式化。平台集成了关系存储、向量语义检索和Neo4j知识图谱。使用Bidirectional Long Short-Term Memory（Bi-LSTM）和基于PubMedBERT微调的Transformer多任务分类器，对文献标题和摘要进行PICOS合规性和研究设计分类。全文本综合采用检索增强生成（RAG）技术，结合向量和图检索，并使用BERTopic进行主题结构、冗余和证据差距的识别。", "result": "Transformer模型在研究设计分类上达到了95.7%的准确率，与专家标注高度一致；Bi-LSTM在PICOS合规性检测上准确率为87%。RAG在需要结构化约束、跨研究整合和基于图推理的查询方面优于非检索生成；而非检索方法在高层摘要方面仍具竞争力。主题建模揭示了显著的主题冗余，并识别出研究不足的领域。", "conclusion": "基于PICOS和可解释的自然语言处理技术，可以提高证据综合的可扩展性、透明度和效率，从而减少生物医学研究中的浪费。该平台架构具有领域无关性，为减少生物医学研究浪费提供了一个实际的框架。"}}
{"id": "2601.12297", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2601.12297", "abs": "https://arxiv.org/abs/2601.12297", "authors": ["Satrajit Chakrabarty", "Sourya Sengupta", "Gopal Avinash", "Ravi Soni"], "title": "Synthetic Volumetric Data Generation Enables Zero-Shot Generalization of Foundation Models in 3D Medical Image Segmentation", "comment": null, "summary": "Foundation models such as Segment Anything Model 2 (SAM 2) exhibit strong generalization on natural images and videos but perform poorly on medical data due to differences in appearance statistics, imaging physics, and three-dimensional structure. To address this gap, we introduce SynthFM-3D, an analytical framework that mathematically models 3D variability in anatomy, contrast, boundary definition, and noise to generate synthetic data for training promptable segmentation models without real annotations. We fine-tuned SAM 2 on 10,000 SynthFM-3D volumes and evaluated it on eleven anatomical structures across three medical imaging modalities (CT, MR, ultrasound) from five public datasets. SynthFM-3D training led to consistent and statistically significant Dice score improvements over the pretrained SAM 2 baseline, demonstrating stronger zero-shot generalization across modalities. When compared with the supervised SAM-Med3D model on unseen cardiac ultrasound data, SynthFM-3D achieved 2-3x higher Dice scores, establishing analytical 3D data modeling as an effective pathway to modality-agnostic medical segmentation.", "AI": {"tldr": "研究提出了一种名为SynthFM-3D的框架，通过生成合成的3D医学图像数据来微调SAM 2模型，使其在医学图像分割任务上表现更佳，尤其是在零样本泛化能力方面。SynthFM-3D训练的SAM 2在多种医学影像模态和解剖结构上均取得了显著的Dice分数提升，并且在心脏超声数据上表现优于有监督的SAM-Med3D模型。", "motivation": "现有的基础模型（如SAM 2）在自然图像上表现优异，但在医学图像上表现不佳，原因是医学数据的外观统计、成像物理和三维结构存在差异。需要一种方法来弥合这一差距，以提升基础模型在医学影像分割任务上的性能。", "method": "提出SynthFM-3D分析框架，通过数学模型模拟3D解剖、对比度、边界定义和噪声的变化，生成合成数据，用于训练可提示的分割模型，而无需真实标注。使用10,000个SynthFM-3D体积数据对SAM 2模型进行微调，并在CT、MR和超声三种医学影像模态的五个公共数据集上评估模型在11个解剖结构上的性能。", "result": "SynthFM-3D训练的SAM 2模型在Dice分数上相对于预训练的SAM 2基线模型有了持续且统计学上显著的提升，展示了更强的跨模态零样本泛化能力。与在未见过的心脏超声数据上进行监督训练的SAM-Med3D模型相比，SynthFM-3D的Dice分数提高了2-3倍。", "conclusion": "通过分析性3D数据建模是一种有效的实现模态无关医学分割的途径。SynthFM-3D框架能够生成高质量的合成数据，显著提升基础分割模型在医学影像任务上的性能和泛化能力。"}}
{"id": "2601.12244", "categories": ["cs.RO", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.12244", "abs": "https://arxiv.org/abs/2601.12244", "authors": ["Shyalan Ramesh", "Scott Mann", "Alex Stumpf"], "title": "A Comprehensive Review of Bio-Inspired Approaches to Coordination, Communication, and System Architecture in Underwater Swarm Robotics", "comment": "Published as part of the Special Issue: Wide Application of Marine Robotic Systems, in the Journal of Marine Science and Engineering", "summary": "The increasing complexity of marine operations has intensified the need for intelligent robotic systems to support ocean observation, exploration, and resource management. Underwater swarm robotics offers a promising framework that extends the capabilities of individual autonomous platforms through collective coordination. Inspired by natural systems, such as fish schools and insect colonies, bio-inspired swarm approaches enable distributed decision-making, adaptability, and resilience under challenging marine conditions. Yet research in this field remains fragmented, with limited integration across algorithmic, communication, and hardware design perspectives. This review synthesises bio-inspired coordination mechanisms, communication strategies, and system design considerations for underwater swarm robotics. It examines key marine-specific algorithms, including the Artificial Fish Swarm Algorithm, Whale Optimisation Algorithm, Coral Reef Optimisation, and Marine Predators Algorithm, highlighting their applications in formation control, task allocation, and environmental interaction. The review also analyses communication constraints unique to the underwater domain and emerging acoustic, optical, and hybrid solutions that support cooperative operation. Additionally, it examines hardware and system design advances that enhance system efficiency and scalability. A multi-dimensional classification framework evaluates existing approaches across communication dependency, environmental adaptability, energy efficiency, and swarm scalability. Through this integrated analysis, the review unifies bio-inspired coordination algorithms, communication modalities, and system design approaches. It also identifies converging trends, key challenges, and future research directions for real-world deployment of underwater swarm systems.", "AI": {"tldr": "本综述整合了水下群体机器人领域的生物启发协调算法、通信策略和系统设计考虑因素，以应对海洋作业的复杂性，并指出了未来的研究方向。", "motivation": "海洋作业的复杂性日益增加，需要智能机器人系统来支持海洋观测、探索和资源管理。水下群体机器人是一个有前景的框架，但现有研究在算法、通信和硬件设计之间存在碎片化，缺乏整合。", "method": "本综述通过综合分析生物启发协调机制、通信策略和系统设计考虑因素，回顾了水下群体机器人的研究现状。它检查了特定海洋环境的算法（如人工鱼群算法、鲸鱼优化算法等）在编队控制、任务分配和环境交互方面的应用。同时，分析了水下通信的限制以及声学、光学和混合通信解决方案。此外，还审视了增强系统效率和可扩展性的硬件和系统设计进展。最后，通过一个多维分类框架评估现有方法，并识别了未来研究方向。", "result": "该综述整合了生物启发协调算法（包括人工鱼群算法、鲸鱼优化算法、珊瑚礁优化算法和海洋捕食者算法）、通信模式（声学、光学、混合）和系统设计方法。它评估了现有方法在通信依赖性、环境适应性、能源效率和群体可扩展性等方面的表现，并识别了融合趋势、关键挑战和未来研究方向。", "conclusion": "通过对生物启发协调算法、通信和系统设计的综合分析，本综述为水下群体机器人的发展提供了一个统一的视角，并为应对实际部署中的挑战和未来研究指明了方向。"}}
{"id": "2601.12334", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12334", "abs": "https://arxiv.org/abs/2601.12334", "authors": ["Alberto Bemporad"], "title": "Worst-case Nonlinear Regression with Error Bounds", "comment": "23 pages, 8 figures", "summary": "This paper proposes an active-learning approach to worst-case nonlinear regression with deterministic error guarantees. Given a known nonlinear function defined over a compact set, we compute a surrogate model, such as a feedforward neural network, by minimizing the maximum absolute approximation error. To address the nonsmooth nature of the resulting minimax problem, we introduce a smooth approximation of the $L_\\infty$-type loss that enables efficient gradient-based training. We iteratively enrich the training set by actively learning points of largest approximation error through global optimization. The resulting models admit certified worst-case error bounds, either constant or input-dependent, over the entire input domain. The approach is demonstrated through approximations of nonlinear functions and nonconvex sets, as well as through the derivation of uncertain models of more complex nonlinear dynamics within a given model class, and the approximation of explicit model predictive control laws.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.11658", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11658", "abs": "https://arxiv.org/abs/2601.11658", "authors": ["Indrajit Kar", "Sammy Zonunpuia", "Zonunfeli Ralte"], "title": "Towards AGI A Pragmatic Approach Towards Self Evolving Agent", "comment": null, "summary": "Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling we evaluate these paradigms. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.", "AI": {"tldr": "提出了一种多智能体框架，能够让基于LLM的智能体在部署后自主学习新能力、生成新工具并改进其推理过程，通过课程学习、基于奖励的学习和遗传算法实现持续适应和演化。", "motivation": "现有的LLM智能体在部署后能力是静态的，无法自主扩展能力、生成新工具或演化推理能力。", "method": "构建了一个分层的自演化多智能体框架，包含基础LLM、操作SLM智能体、代码生成LLM和教师LLM。通过任务执行、工具合成（使用代码生成LLM）和演化（课程学习、基于奖励的学习或遗传算法）的流程来实现智能体的持续适应。", "result": "在TaskCraft数据集上进行评估，结果表明：课程学习能快速恢复和泛化；基于奖励的学习在处理高难度任务方面表现出色；遗传算法提供了高行为多样性。所有演化后的智能体性能均优于原始智能体。", "conclusion": "所提出的框架能够实现智能体鲁棒、自主的自我改进式演化，使其能够不断适应新任务和提高自身能力。"}}
{"id": "2601.11637", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11637", "abs": "https://arxiv.org/abs/2601.11637", "authors": ["Aradhya Dixit"], "title": "Evaluating Self-Correcting Vision Agents Through Quantitative and Qualitative Metrics", "comment": null, "summary": "Recent progress in multimodal foundation models has enabled Vision-Language Agents (VLAs) to decompose complex visual tasks into executable tool-based plans. While recent benchmarks have begun to evaluate iterative self-correction, its quantitative limits and dominant reasoning bottlenecks remain poorly characterized. This work introduces a Diagnostic Micro-Benchmark. Our analysis decouples Task Success Rate (TSR = 62 percent) from Correction Success Rate (CSR = 25 to 33 percent), revealing that initial competence does not predict repair ability. We explicitly quantify the diminishing returns of correction, which saturates after three retries. Our Failure Taxonomy reveals a frequent factor is Semantic Drift (about 28 percent of failures), a loss of contextual state. By isolating this reasoning bottleneck, this benchmark defines a reproducible framework toward stateful, trustworthy multimodal agents.", "AI": {"tldr": "本研究提出了一个诊断性微基准来评估和理解视觉语言代理（VLA）的迭代自我纠正能力，揭示了其在纠正任务上的局限性，并识别出“语义漂移”是导致失败的主要原因。", "motivation": "尽管多模态基础模型在视觉任务分解方面取得了进展，但现有基准对迭代自我纠正的量化评估不足，其性能瓶颈和限制尚未明确。", "method": "提出了一个诊断性微基准，将任务成功率（TSR）与纠正成功率（CSR）解耦，量化了纠正次数的边际效益，并构建了一个失败分类体系来识别导致失败的关键因素。", "result": "研究发现，初始任务能力与纠正能力之间不存在必然联系，纠正次数的边际效益在三次重试后趋于饱和。在所有失败案例中，“语义漂移”（即上下文状态丢失）占约28%。", "conclusion": "本研究提出的诊断性微基准为量化和理解VLA的自我纠正能力提供了一个可复现的框架，并指出“语义漂移”是影响其可靠性的主要推理瓶颈，未来的研究应致力于解决这一问题以构建更可信赖的多模态代理。"}}
{"id": "2601.11840", "categories": ["cs.AI", "cs.LO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11840", "abs": "https://arxiv.org/abs/2601.11840", "authors": ["Hongyu Lin", "Samer Abdallah", "Makar Valentinov", "Paul Brennan", "Elijah Kagan", "Christoph M. Wintersteiger", "Denis Ignatovich", "Grant Passmore"], "title": "Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic", "comment": "52 pages, 23 figures. Includes a new benchmark dataset (code-logic-bench) and evaluation of neurosymbolic reasoning for software analysis", "summary": "Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor.\n  We present CodeLogician, a neurosymbolic agent for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine deployed in financial markets and safety-critical systems. Unlike prior approaches that use formal methods primarily to validate LLM outputs, CodeLogician uses LLMs to construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes.\n  To rigorously evaluate mathematical reasoning about software logic, we introduce code-logic-bench, a benchmark targeting the middle ground between theorem proving and software engineering benchmarks. It measures reasoning correctness about program state spaces, control flow, coverage constraints, and edge cases, with ground truth defined via formal modeling and region decomposition.\n  Comparing LLM-only reasoning against LLMs augmented with CodeLogician, formal augmentation yields substantial improvements, closing a 41-47 percentage point gap in reasoning accuracy. These results demonstrate that neurosymbolic integration is essential for scaling program analysis toward rigorous, autonomous software understanding.", "AI": {"tldr": "提出了一种名为CodeLogician的神经符号智能体，它利用大型语言模型（LLM）构建软件系统的形式化模型，并结合ImandraX自动推理引擎，以实现对软件逻辑的精确分析。同时，引入了code-logic-bench基准测试来评估软件逻辑的数学推理能力。实验证明，这种神经符号方法显著提高了LLM在软件逻辑推理方面的准确性。", "motivation": "大型语言模型（LLM）在代码理解方面表现出色，但在执行精确、全面的程序行为数学推理方面存在根本性不足。现有的基准测试要么侧重于与实际软件脱节的数学证明自动化，要么侧重于不需要语义严谨性的工程任务。因此，需要一种能够进行精确软件逻辑分析的方法。", "method": "提出CodeLogician，一个神经符号智能体，利用LLM构建显式的软件系统形式化模型，并将其与ImandraX（一个工业级的自动化推理引擎）集成。此方法能够回答超越二元验证结果的丰富语义问题。为了评估，引入了code-logic-bench基准测试，该测试测量程序状态空间、控制流、覆盖率约束和边缘案例的推理正确性。", "result": "将仅使用LLM的推理与使用CodeLogician增强的LLM的推理进行比较，正式增强将推理准确性提高了41-47个百分点。", "conclusion": "神经符号集成对于将程序分析扩展到严谨、自主的软件理解是必不可少的。CodeLogician通过结合LLM的建模能力和自动化推理引擎的精确性，显著提升了软件逻辑的数学推理能力。"}}
{"id": "2601.13069", "categories": ["eess.IV", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.13069", "abs": "https://arxiv.org/abs/2601.13069", "authors": ["Pengfei Zhu", "Jiaxu Wu", "Alyson Deslongchamps", "Yubin Zhang", "Xavier Maldague"], "title": "Non-Invasive Diagnosis for Clubroot Using Terahertz Time-Domain Spectroscopy and Physics-Constrained Neural Networks", "comment": null, "summary": "Clubroot, a major soilborne disease affecting canola and other cruciferous crops, is characterized by the development of large galls on the roots of susceptible hosts. In this study, we present the first application of terahertz time-domain spectroscopy (THz-TDS) as a non-invasive diagnosis tool in plant pathology. Compared with conventional molecular, spectroscopic, and immunoassay-based methods, THz-TDS offers distinct advantages, including non-contact, non-destructive, and preparation-free measurement, enabling rapid in situ screening of plant and soil samples. Our results demonstrate that THz-TDS can differentiate between healthy and clubroot-infected tissues by detecting both structural and biochemical alterations. Specifically, infected roots exhibit a blue shift in the refractive index in the low-frequency THz range, along with distinct peaks-indicative of disruptions in water transport and altered metabolic activity in both roots and leaves. Interestingly, the characteristic root swelling observed in infected plants reflects internal tissue disorganization rather than an actual increase in water content. Furthermore, a physics-constrained neural network is proposed to extract the main feature in THz-TDS. A comprehensive evaluation, including time-domain signals, amplitude and phase images, refractive index and absorption coefficient maps, and principal component analysis, provides enhanced contrast and spatial resolution compared to raw time-domain or frequency signals. These findings suggest that THz-TDS holds significant potential for early, non-destructive detection of plant diseases and may serve as a valuable tool to limit their spread in agricultural systems.", "AI": {"tldr": "研究首次将太赫兹时域光谱技术（THz-TDS）应用于白菜根腐病（clubroot）的无损诊断，通过检测感染引起的组织结构和生化变化，区分健康与受感染植株，并提出了一种基于物理约束的神经网络模型来增强数据分析。", "motivation": "为了开发一种比传统方法更快速、无损且无需样本制备的植物病害（特别是白菜根腐病）的诊断工具。", "method": "利用太赫兹时域光谱技术（THz-TDS）测量健康和感染白菜根腐病的植株（包括根和叶）的太赫兹波传输特性。通过分析折射率、吸收系数、时域信号、幅度/相位图像以及主成分分析（PCA）来区分不同状态的样本。此外，提出并应用了一种物理约束神经网络来提取关键特征。", "result": "THz-TDS能够区分健康和感染白菜根腐病的组织，检测到感染引起的折射率蓝移（低频范围内）以及与水分运输和代谢活动改变相关的独特峰值。研究发现，根部肿胀主要是组织结构紊乱而非水分增加所致。物理约束神经网络提高了特征提取的对比度和空间分辨率。", "conclusion": "THz-TDS是一种有潜力用于早期、无损检测植物病害（如白菜根腐病）的工具，能够检测结构和生化变化，为农业病害防控提供新方法。"}}
{"id": "2601.12545", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12545", "abs": "https://arxiv.org/abs/2601.12545", "authors": ["Luis Cervantes-Pérez", "Víctor Santibáñez", "Jesús Sandoval", "Romeo Ortega", "Jose Guadalupe Romero"], "title": "An Experimental Comparison of Sliding Mode and Immersion and Invariance Adaptive Controllers forPosition-feedback Tracking of a Simple Mechanical System with Friction", "comment": null, "summary": "The purpose of this paper is to illustrate, in an experimental facility consisting of a simple pendular device, the performance of a sliding mode adaptive position-feedback tracking controller of mechanical systems with friction reported in the literature. To put this experimental evidence in perspective, we compare the performance of the sliding mode scheme with the one obtained by an adaptive controller designed following the well-known immersion and invariance technique.", "AI": {"tldr": "本文在实验装置中，比较了滑模自适应位置反馈跟踪控制器和基于沉浸不变性技术设计的自适应控制器在含摩擦机械系统中的性能。", "motivation": "验证和比较文献中提出的用于含摩擦机械系统的滑模自适应位置反馈跟踪控制器在实际应用中的性能，并与另一种自适应控制方法进行对比。", "method": "使用一个简单的摆锤实验装置，实现并测试滑模自适应位置反馈跟踪控制器，并将其性能与采用沉浸不变性技术设计的自适应控制器进行比较。", "result": "通过实验对比两种控制器的性能，但具体结果（哪个更好或性能差异）尚未在摘要中详细说明。", "conclusion": "实验证明了滑模自适应位置反馈跟踪控制器在含摩擦机械系统中的可行性，并通过与另一种自适应控制方法的比较，为理解该控制器的性能提供了参考。"}}
{"id": "2601.12277", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12277", "abs": "https://arxiv.org/abs/2601.12277", "authors": ["Wangtian Shen", "Ziyang Meng", "Jinming Ma", "Mingliang Zhou", "Diyun Xiang"], "title": "An Efficient and Multi-Modal Navigation System with One-Step World Model", "comment": null, "summary": "Navigation is a fundamental capability for mobile robots. While the current trend is to use learning-based approaches to replace traditional geometry-based methods, existing end-to-end learning-based policies often struggle with 3D spatial reasoning and lack a comprehensive understanding of physical world dynamics. Integrating world models-which predict future observations conditioned on given actions-with iterative optimization planning offers a promising solution due to their capacity for imagination and flexibility. However, current navigation world models, typically built on pure transformer architectures, often rely on multi-step diffusion processes and autoregressive frame-by-frame generation. These mechanisms result in prohibitive computational latency, rendering real-time deployment impossible. To address this bottleneck, we propose a lightweight navigation world model that adopts a one-step generation paradigm and a 3D U-Net backbone equipped with efficient spatial-temporal attention. This design drastically reduces inference latency, enabling high-frequency control while achieving superior predictive performance. We also integrate this model into an optimization-based planning framework utilizing anchor-based initialization to handle multi-modal goal navigation tasks. Extensive closed-loop experiments in both simulation and real-world environments demonstrate our system's superior efficiency and robustness compared to state-of-the-art baselines.", "AI": {"tldr": "提出了一种轻量级的导航世界模型，采用一步生成和3D U-Net骨干，并结合高效的时空注意力机制，显著降低了推理延迟，并在优化规划框架中用于多模态导航任务，在仿真和真实环境中均表现出优越的效率和鲁棒性。", "motivation": "现有的端到端学习导航方法在3D空间推理和物理世界动力学理解方面存在不足；而基于世界模型的导航方法（通常基于Transformer）存在计算延迟过高的问题，难以实现实时部署。", "method": "开发了一个轻量级导航世界模型，采用一步生成（one-step generation）范式，并使用带有高效时空注意力机制的3D U-Net作为骨干网络。该模型被集成到一个基于优化的规划框架中，并采用基于锚点的初始化（anchor-based initialization）来处理多模态目标导航。", "result": "所提出的模型能够显著降低推理延迟，实现高频控制，并达到优越的预测性能。与最先进的基线方法相比，该系统在仿真和真实世界的闭环实验中展现出更高的效率和鲁棒性。", "conclusion": "通过引入一步生成范式和高效的3D U-Net架构，成功构建了一个轻量级且高效的导航世界模型，解决了现有方法的延迟问题，并能有效地支持多模态导航任务，在实际应用中具有巨大潜力。"}}
{"id": "2601.11640", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11640", "abs": "https://arxiv.org/abs/2601.11640", "authors": ["Yingda Yu", "Jiaqi Xuan", "Shuhui Shi", "Xuanyu Teng", "Shuyang Xu", "Guanchao Tong"], "title": "Confident Learning for Object Detection under Model Constraints", "comment": "Submitted to ICPR 2026, currently under review", "summary": "Agricultural weed detection on edge devices is subject to strict constraints on model capacity, computational resources, and real-time inference latency, which prevent performance improvements through model scaling or ensembling. This paper proposes Model-Driven Data Correction (MDDC), a data-centric framework that enhances detection performance by iteratively diagnosing and correcting data quality deficiencies. An automated error analysis procedure categorizes detection failures into four types: false negatives, false positives, class confusion, and localization errors. These error patterns are systematically addressed through a structured train-fix-retrain pipeline with version-controlled data management. Experimental results on multiple weed detection datasets demonstrate consistent improvements of 5-25 percent in mAP at 0.5 using a fixed lightweight detector (YOLOv8n), indicating that systematic data quality optimization can effectively alleviate performance bottlenecks under fixed model capacity constraints.", "AI": {"tldr": "本文提出了一种名为模型驱动数据校正（MDDC）的以数据为中心的框架，通过迭代诊断和纠正数据质量缺陷来提高边缘设备上农业杂草检测的性能，而无需增加模型容量。", "motivation": "在模型容量、计算资源和实时推理延迟受严格限制的边缘设备上，提升农业杂草检测性能面临挑战，模型扩展或集成受到限制。因此，需要一种在固定模型容量下提高检测性能的方法。", "method": "MDDC框架包含一个自动错误分析程序，将检测失败分为四类：漏检、误检、类别混淆和定位错误。通过结构化的“训练-修复-再训练”流程和版本控制的数据管理，系统性地解决这些错误模式。", "result": "在多个杂草检测数据集上，使用固定的轻量级检测器（YOLOv8n），MDDC能够将mAP@0.5提高5-25%。", "conclusion": "在模型容量固定的情况下，系统性的数据质量优化可以有效缓解性能瓶颈，MDDC框架证明了其在提升边缘设备农业杂草检测性能方面的有效性。"}}
{"id": "2601.11722", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11722", "abs": "https://arxiv.org/abs/2601.11722", "authors": ["Ahmed Rayane Kebir", "Vincent Guigue", "Lynda Said Lhadj", "Laure Soulier"], "title": "RAC: Retrieval-Augmented Clarification for Faithful Conversational Search", "comment": "This is the author's version of the work. The definitive version is published in: Proceedings of the 48th European Conference on Information Retrieval (ECIR '26), 29 March--2 April, 2026, Delft, Netherlands", "summary": "Clarification questions help conversational search systems resolve ambiguous or underspecified user queries. While prior work has focused on fluency and alignment with user intent, especially through facet extraction, much less attention has been paid to grounding clarifications in the underlying corpus. Without such grounding, systems risk asking questions that cannot be answered from the available documents. We introduce RAC (Retrieval-Augmented Clarification), a framework for generating corpus-faithful clarification questions. After comparing several indexing strategies for retrieval, we fine-tune a large language model to make optimal use of research context and to encourage the generation of evidence-based question. We then apply contrastive preference optimization to favor questions supported by retrieved passages over ungrounded alternatives. Evaluated on four benchmarks, RAC demonstrate significant improvements over baselines. In addition to LLM-as-Judge assessments, we introduce novel metrics derived from NLI and data-to-text to assess how well questions are anchored in the context, and we demonstrate that our approach consistently enhances faithfulness.", "AI": {"tldr": "本研究提出了一种名为 RAC（Retrieval-Augmented Clarification）的框架，用于生成与语料库内容一致的澄清问题，以提高对话式搜索系统的查询消歧能力。", "motivation": "现有对话式搜索系统的澄清问题生成方法主要关注流畅性和用户意图对齐（如通过方面提取），但较少关注澄清问题与底层语料库的关联性。这可能导致系统提出无法从可用文档中回答的问题。因此，研究动机在于解决这一问题，生成基于语料库的、可回答的澄清问题。", "method": "研究人员提出了一种名为 RAC 的框架，该框架首先探索了不同的索引策略以实现检索，然后微调了一个大型语言模型（LLM）以利用研究上下文并生成基于证据的问题。最后，他们应用对比偏好优化（contrastive preference optimization）来偏好由检索到的段落支持的问题，而不是未接地（ungrounded）的问题。", "result": "在四个基准测试上评估，RAC 相较于基线方法取得了显著的改进。除了 LLM-as-Judge 评估外，研究还引入了基于自然语言推理（NLI）和数据到文本（data-to-text）的新指标，以评估问题与上下文的锚定程度，并证明了 RAC 能够一致地提高问题的忠实度。", "conclusion": "RAC 框架通过检索增强的澄清生成方法，有效解决了现有对话式搜索系统中澄清问题与语料库之间缺乏关联的问题。研究结果表明，RAC 能够生成更忠实于语料库内容的澄清问题，并显著优于现有基线方法。"}}
{"id": "2601.12291", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12291", "abs": "https://arxiv.org/abs/2601.12291", "authors": ["Jianhao Jiao", "Changkun Liu", "Jingwen Yu", "Boyi Liu", "Qianyi Zhang", "Yue Wang", "Dimitrios Kanoulas"], "title": "OpenNavMap: Structure-Free Topometric Mapping via Large-Scale Collaborative Localization", "comment": "21 pages, 20 figures", "summary": "Scalable and maintainable map representations are fundamental to enabling large-scale visual navigation and facilitating the deployment of robots in real-world environments. While collaborative localization across multi-session mapping enhances efficiency, traditional structure-based methods struggle with high maintenance costs and fail in feature-less environments or under significant viewpoint changes typical of crowd-sourced data. To address this, we propose OPENNAVMAP, a lightweight, structure-free topometric system leveraging 3D geometric foundation models for on-demand reconstruction. Our method unifies dynamic programming-based sequence matching, geometric verification, and confidence-calibrated optimization to robust, coarse-to-fine submap alignment without requiring pre-built 3D models. Evaluations on the Map-Free benchmark demonstrate superior accuracy over structure-from-motion and regression baselines, achieving an average translation error of 0.62m. Furthermore, the system maintains global consistency across 15km of multi-session data with an absolute trajectory error below 3m for map merging. Finally, we validate practical utility through 12 successful autonomous image-goal navigation tasks on simulated and physical robots. Code and datasets will be publicly available in https://rpl-cs-ucl.github.io/OpenNavMap_page.", "AI": {"tldr": "提出了一种名为 OPENNAVMAP 的轻量级、无结构三维几何顶度定位系统，利用基础模型按需重建，实现了高效、鲁棒的多会话地图合并和视觉导航。", "motivation": "传统的基于结构的方法在众包数据中维护成本高，且在特征稀疏环境或视角变化大的情况下表现不佳，阻碍了大规模机器人导航和部署。", "method": "OPENNAVMAP 采用一种结构自由的顶度系统，结合动态规划序列匹配、几何验证和置信度校准优化，实现了对子地图的粗到精的对齐，无需预先构建的 3D 模型。", "result": "在 Map-Free 基准测试中，OPENNAVMAP 的平均平移误差为 0.62m，优于现有的方法。在 15km 的多会话数据上，地图合并的绝对轨迹误差低于 3m，保持了全局一致性。此外，该系统在模拟和真实机器人上成功完成了 12 项自主图像导航任务。", "conclusion": "OPENNAVMAP 是一种高效、鲁棒且可维护的地图表示方法，能够解决大规模视觉导航和机器人部署中的挑战，尤其适用于众包数据场景。"}}
{"id": "2601.12610", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12610", "abs": "https://arxiv.org/abs/2601.12610", "authors": ["Maxim Yudayev", "Juha Carlon", "Diwas Lamsal", "Vayalet Stefanova", "Benjamin Filtjens"], "title": "HERMES: A Unified Open-Source Framework for Realtime Multimodal Physiological Sensing, Edge AI, and Intervention in Closed-Loop Smart Healthcare Applications", "comment": "Submitted to ACM SenSys '26, 12 pages (excl. references), 9 figures", "summary": "Intelligent assistive technologies are increasingly recognized as critical daily-use enablers for people with disabilities and age-related functional decline. Longitudinal studies, curation of quality datasets, live monitoring in activities of daily living, and intelligent intervention devices, share the largely unsolved need in reliable high-throughput multimodal sensing and processing. Streaming large heterogeneous data from distributed sensors, historically closed-source environments, and limited prior works on realtime closed-loop AI methodologies, inhibit such applications. To accelerate the emergence of clinical deployments, we deliver HERMES - an open-source high-performance Python framework for continuous multimodal sensing and AI processing at the edge. It enables synchronized data collection, and realtime streaming inference with user PyTorch models, on commodity computing devices. HERMES is applicable to fixed-lab and free-living environments, of distributed commercial and custom sensors. It is the first work to offer a holistic methodology that bridges cross-disciplinary gaps in real-world implementation strategies, and guides downstream AI model development. Its application on the closed-loop intelligent prosthesis use case illustrates the process of suitable AI model development from the generated constraints and trade-offs. Validation on the use case, with 4 synchronized hosts cooperatively capturing 18 wearable and off-body modalities, demonstrates performance and relevance of HERMES to the trajectory of the intelligent healthcare domain.", "AI": {"tldr": "提出了一种名为HERMES的开源Python框架，用于在边缘设备上进行连续的多模态传感和AI处理，以加速智能辅助技术的临床部署。", "motivation": "当前在可靠的高通量多模态传感和处理方面存在未解决的需求，这阻碍了智能辅助技术在日常生活中的应用，尤其是在处理来自分布式传感器、闭源环境的大量异构数据以及实时闭环AI方法的研究有限的情况下。", "method": "开发了一个名为HERMES的开源Python框架，该框架支持同步数据采集，并在商品化计算设备上实现用户PyTorch模型的实时流式推理。该框架适用于固定实验室和自由生活环境，并兼容分布式商用和定制传感器。", "result": "HERMES框架成功应用于一个闭环智能假肢用例，展示了如何从生成的约束和权衡中开发合适的AI模型。在一个有18种可穿戴和体外模态的同步主机协作捕获的用例上进行了验证，证明了其性能和相关性。", "conclusion": "HERMES是第一个提供整体方法的框架，弥合了跨学科在实际实施策略中的差距，并指导了下游AI模型的开发。该框架有助于在智能医疗领域实现连续多模态传感和边缘AI处理，从而加速智能辅助技术的临床应用。"}}
{"id": "2601.11850", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11850", "abs": "https://arxiv.org/abs/2601.11850", "authors": ["Matthew Nyaaba", "Min SungEun", "Mary Abiswin Apam", "Kwame Owoahene Acheampong", "Emmanuel Dwamena", "Xiaoming Zhai"], "title": "Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority", "comment": null, "summary": "The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.", "AI": {"tldr": "本研究探讨了生成式人工智能（GenAI）在质性研究中如何辅助研究者进行归纳主题分析（ITA），并提出了一种人机协作框架（HACITA）。研究发现，AI工具（ITA-GPT）能够规范分析流程并提高透明度，但解释权仍掌握在人类研究者手中，他们通过修改、删除、添加和评论等方式行使判断权。", "motivation": "随着生成式AI在质性研究中的应用日益广泛，人们对其分析实践和解释权威性产生了疑问。本研究旨在考察研究者如何与专门为辅助归纳主题分析设计的AI工具（ITA-GPT）互动，并提出一种人机协作框架（HACITA），以解决AI在质性研究中的应用问题。", "method": "研究采用了人机协作的归纳主题分析（HACITA）框架，选取了三位经验丰富的质性研究者，让他们使用ITA-GPT对加纳教师教育背景下的访谈记录进行分析。研究收集了互动日志、AI生成的表格、研究者的修改记录（删除、插入、评论）以及反思性备忘录等数据，重点关注分析过程而非具体的研究发现。", "result": "研究结果表明，ITA-GPT作为一种程序性支架，能够规范分析工作流程并提高分析的透明度。研究者通过反复修改、删除、拒绝、插入和评论等分析性操作，在AI的辅助下行使了解释权威。AI工具支持了熟悉化、逐字逐句的体内编码、动名词描述性编码以及主题发展，并强制执行了文本溯源、覆盖率检查和可审计性。", "conclusion": "本研究展示了归纳主题分析如何通过负责任的人机协作得以实现。AI工具能够有效支持质性研究的流程，而人类研究者则保留并行使了最终的解释权威，表明人机协作是质性研究中一个有前景的模式。"}}
{"id": "2601.13236", "categories": ["eess.IV", "cs.AI", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2601.13236", "abs": "https://arxiv.org/abs/2601.13236", "authors": ["Ilias I. Giannakopoulos", "Lokesh B Gautham Muthukumar", "Yvonne W. Lui", "Riccardo Lattanzi"], "title": "Pixelwise Uncertainty Quantification of Accelerated MRI Reconstruction", "comment": "10 pages, 8 figues, 2 tables", "summary": "Parallel imaging techniques reduce magnetic resonance imaging (MRI) scan time but image quality degrades as the acceleration factor increases. In clinical practice, conservative acceleration factors are chosen because no mechanism exists to automatically assess the diagnostic quality of undersampled reconstructions. This work introduces a general framework for pixel-wise uncertainty quantification in parallel MRI reconstructions, enabling automatic identification of unreliable regions without access to any ground-truth reference image. Our method integrates conformal quantile regression with image reconstruction methods to estimate statistically rigorous pixel-wise uncertainty intervals. We trained and evaluated our model on Cartesian undersampled brain and knee data obtained from the fastMRI dataset using acceleration factors ranging from 2 to 10. An end-to-end Variational Network was used for image reconstruction. Quantitative experiments demonstrate strong agreement between predicted uncertainty maps and true reconstruction error. Using our method, the corresponding Pearson correlation coefficient was higher than 90% at acceleration levels at and above four-fold; whereas it dropped to less than 70% when the uncertainty was computed using a simpler a heuristic notion (magnitude of the residual). Qualitative examples further show the uncertainty maps based on quantile regression capture the magnitude and spatial distribution of reconstruction errors across acceleration factors, with regions of elevated uncertainty aligning with pathologies and artifacts. The proposed framework enables evaluation of reconstruction quality without access to fully-sampled ground-truth reference images. It represents a step toward adaptive MRI acquisition protocols that may be able to dynamically balance scan time and diagnostic reliability.", "AI": {"tldr": "研究提出了一种新的像素级不确定性量化框架，用于评估并行MRI重构的图像质量，即使没有真实图像作为参考。该方法集成了保形分位数回归和图像重构技术，能够自动识别不可靠的图像区域，并能准确捕捉重构误差的大小和空间分布。", "motivation": "现有并行MRI技术虽然能缩短扫描时间，但加速因子越高，图像质量下降越明显。临床上由于缺乏自动评估欠采样重构图像诊断质量的机制，通常采用保守的加速因子，限制了扫描时间的进一步缩短。因此，研究旨在开发一种能够自动评估诊断质量的机制，以实现更优的扫描时间与诊断可靠性平衡。", "method": "研究提出了一种通用的像素级不确定性量化框架，该框架将保形分位数回归（conformal quantile regression）与图像重构方法相结合，以生成具有统计学意义的像素级不确定性区间。所提出的模型在Cartesian欠采样脑部和膝盖数据上进行了训练和评估，加速因子范围为2到10。模型采用端到端的变分网络（Variational Network）进行图像重构。", "result": "定量实验结果表明，预测的不确定性图与真实的重构误差高度一致。在加速因子为4倍及以上时，预测不确定性与真实误差之间的皮尔逊相关系数超过90%；而使用更简单的启发式方法（残差幅度）计算的不确定性，相关系数则低于70%。定性示例也显示，基于分位数回归的不确定性图能够准确捕捉不同加速因子下的重构误差的大小和空间分布，并且高不确定性区域与病变和伪影对齐。", "conclusion": "该框架能够在无法获得全采样参考图像的情况下评估重构质量，是实现自适应MRI采集协议的重要一步，该协议能够动态平衡扫描时间和诊断可靠性。"}}
{"id": "2601.13320", "categories": ["eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.13320", "abs": "https://arxiv.org/abs/2601.13320", "authors": ["Yasin Demir", "Nur Hüseyin Kaplan", "Sefa Kucuk", "Nagihan Severoglu"], "title": "RetinexGuI: Retinex-Guided Iterative Illumination Estimation Method for Low Light Images", "comment": null, "summary": "In recent years, there has been a growing interest in low-light image enhancement (LLIE) due to its importance for critical downstream tasks. Current Retinex-based methods and learning-based approaches have shown significant LLIE performance. However, computational complexity and dependencies on large training datasets often limit their applicability in real-time applications. We introduce RetinexGuI, a novel and effective Retinex-guided LLIE framework to overcome these limitations. The proposed method first separates the input image into illumination and reflection layers, and iteratively refines the illumination while keeping the reflectance component unchanged. With its simplified formulation and computational complexity of $\\mathcal{O}(N)$, our RetinexGuI demonstrates impressive enhancement performance across three public datasets, indicating strong potential for large-scale applications. Furthermore, it opens promising directions for theoretical analysis and integration with deep learning approaches. The source code will be made publicly available at https://github.com/etuspars/RetinexGuI once the paper is accepted.", "AI": {"tldr": "提出了一种名为RetinexGuI的新型低光图像增强（LLIE）框架，该框架基于Retinex理论，计算复杂度低（O(N)），无需大量训练数据，能够有效提升低光图像质量。", "motivation": "现有LLIE方法（如基于Retinex和基于学习的方法）虽然效果显著，但计算复杂度高且依赖大规模训练数据集，限制了其在实时应用中的可行性。", "method": "RetinexGuI框架首先将输入图像分解为光照层和反射层，然后通过迭代方式优化光照层，同时保持反射层不变。", "result": "在三个公开数据集上，RetinexGuI展示了出色的增强性能，证明了其在大规模应用中的潜力。", "conclusion": "RetinexGuI是一种高效且计算复杂度低的LLIE方法，克服了现有方法的局限性，并为理论分析和与深度学习的结合提供了新的方向。"}}
{"id": "2601.11885", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11885", "abs": "https://arxiv.org/abs/2601.11885", "authors": ["Zhifei Li", "Ziyue Qin", "Xiangyu Luo", "Xiaoju Hou", "Yue Zhao", "Miao Zhang", "Zhifang Huang", "Kui Xiao", "Bing Yang"], "title": "MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment", "comment": "Accepted by AAAI 2026", "summary": "Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.", "AI": {"tldr": "提出了一种名为 MyGram 的新方法，通过结合图 Transformer 和全局分布信息来解决多模态实体对齐问题，该方法能更好地捕捉跨模态的结构信息和全局一致性，并在多个数据集上取得了优于现有方法的性能。", "motivation": "现有方法在多模态实体对齐时，可能忽略了单模态内的结构上下文信息，容易受到浅层特征的干扰。作者希望提出一种能捕捉深度结构上下文信息并进行细粒度多模态融合的方法。", "method": "提出了一种名为 MyGram 的方法，该方法结合了模态感知图 Transformer 和全局分布。具体来说，它设计了一个模态扩散学习模块来捕获模态内的结构上下文信息并实现多模态融合。此外，引入了 Gram Loss，通过最小化多模态特征形成的四维平行六面体的体积来实现跨模态的全局分布一致性。", "result": "在五个公开数据集上进行了实验。MyGram 在 FBDB15K 上取得了 4.8% 的 Hits@1 提升，在 FBYG15K 上取得了 9.9% 的 Hits@1 提升，在 DBP15K 上取得了 4.3% 的 Hits@1 提升，均优于基线模型。", "conclusion": "MyGram 是一种有效的多模态实体对齐方法，通过捕捉模态内的深度结构上下文信息和实现跨模态的全局分布一致性，能够显著提升实体对齐的性能。"}}
{"id": "2601.12353", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12353", "abs": "https://arxiv.org/abs/2601.12353", "authors": ["Jie Wang", "Peng Du", "Yiyuan Zhang", "Zhexin Xie", "Cecilia Laschi"], "title": "From Shallow Waters to Mariana Trench: A Survey of Bio-inspired Underwater Soft Robots", "comment": "Provisional accepted by Bioinspiration & Biomimetics", "summary": "Sample Exploring the ocean environment holds profound significance in areas such as resource exploration and ecological protection. Underwater robots struggle with extreme water pressure and often cause noise and damage to the underwater ecosystem, while bio-inspired soft robots draw inspiration from aquatic creatures to address these challenges. These bio-inspired approaches enable robots to withstand high water pressure, minimize drag, operate with efficient manipulation and sensing systems, and interact with the environment in an eco-friendly manner. Consequently, bio-inspired soft robots have emerged as a promising field for ocean exploration. This paper reviews recent advancements in underwater bio-inspired soft robots, analyses their design considerations when facing different desired functions, bio-inspirations, ambient pressure, temperature, light, and biodiversity , and finally explores the progression from bio-inspired principles to practical applications in the field and suggests potential directions for developing the next generation of underwater soft robots.", "AI": {"tldr": "该论文综述了水下仿生软体机器人的最新进展，分析了其在海洋探索中的设计考量，并展望了未来发展方向。", "motivation": "传统水下机器人面临高压、噪音和生态破坏的挑战，而仿生软体机器人能够克服这些问题，为海洋探索提供了一种有前途的解决方案。", "method": "对水下仿生软体机器人的设计考虑因素、生物启发原理、环境因素（如压力、温度、光照和生物多样性）以及从原理到实际应用的进展进行了回顾和分析。", "result": "仿生软体机器人能够在高水压下生存，减小阻力，配备高效的操控和感知系统，并以环保的方式与环境互动。论文分析了不同功能需求下仿生软体机器人的设计考量。", "conclusion": "水下仿生软体机器人是海洋探索领域一个充满希望的研究方向，未来的研究应侧重于进一步推动其从仿生原理到实际应用的转化，并探索下一代水下软体机器人的发展方向。"}}
{"id": "2601.11746", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11746", "abs": "https://arxiv.org/abs/2601.11746", "authors": ["George Mihaila", "Suleyman Olcay Polat", "Poli Nemkova", "Himanshu Sharma", "Namratha V. Urs", "Mark V. Albert"], "title": "LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text", "comment": null, "summary": "Local explanation methods such as LIME (Ribeiro et al., 2016) remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe (Angiulli et al., 2025b) attempt to mitigate this by employing Large Language Models for neighborhood generation, they rely on unconstrained paraphrasing that introduces confounding variables, making it difficult to isolate specific feature contributions. We introduce LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations. By enforcing a strict \"Single Mask-Single Sample\" protocol and employing distinct neutral infill and boundary infill strategies, LIME-LLM constructs fluent, on-manifold neighborhoods that rigorously isolate feature effects. We evaluate our method against established baselines (LIME, SHAP, Integrated Gradients) and the generative LLiMe baseline across three diverse benchmarks: CoLA, SST-2, and HateXplain using human-annotated rationales as ground truth. Empirical results demonstrate that LIME-LLM establishes a new benchmark for black-box NLP explainability, achieving significant improvements in local explanation fidelity compared to both traditional perturbation-based methods and recent generative alternatives.", "AI": {"tldr": "本文提出了一种名为 LIME-LLM 的新框架，用于提高自然语言处理（NLP）中本地解释方法的保真度。该方法通过使用受控的、基于假设的扰动取代随机掩码，并遵循严格的“单掩码-单样本”协议，生成流畅且在数据流形上的邻域，从而更准确地隔离特征效应。", "motivation": "现有的本地解释方法（如 LIME）在 NLP 中的应用受到随机标记掩码的限制，这些掩码会生成语义无效的输入，削弱本地代理模型的保真度。而 LLiMe 等生成方法虽然试图改善这一点，但其无约束的释义会引入混淆变量，难以分离特定特征的贡献。", "method": "LIME-LLM 框架采用“单掩码-单样本”协议，并结合不同的中性填充和边界填充策略，用基于假设的、受控的扰动来替换随机噪声。这种方法旨在生成流畅的、在数据流形上的邻域，以严格隔离特征效应。", "result": "在 CoLA、SST-2 和 HateXplain 三个基准测试上，LIME-LLM 相较于 LIME、SHAP、Integrated Gradients 和 LLiMe 等现有方法，在本地解释保真度方面取得了显著改进，设定了黑盒 NLP 可解释性的新标杆。", "conclusion": "LIME-LLM 框架通过引入受控扰动和严格的协议，有效地克服了现有 NLP 本地解释方法的局限性，显著提高了解释的准确性和可靠性。"}}
{"id": "2601.11903", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11903", "abs": "https://arxiv.org/abs/2601.11903", "authors": ["YenTing Lee", "Keerthi Koneru", "Zahra Moslemi", "Sheethal Kumar", "Ramesh Radhakrishnan"], "title": "AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems", "comment": "Workshop on W51: How Can We Trust and Control Agentic AI? Toward Alignment, Robustness, and Verifiability in Autonomous LLM Agents at AAAI 2026", "summary": "Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.\n  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight", "AI": {"tldr": "本文提出了 AEMA 框架，一种用于评估基于 LLM 的多智能体系统的过程感知和可审计框架，与现有的单一响应评分或狭窄基准相比，它提供了更稳定、可扩展和自动化的评估方法。", "motivation": "现有评估 LLM 多智能体系统的方法存在不足，例如单响应评分和狭窄基准，这些方法缺乏稳定性、可扩展性和自动化能力，无法满足企业级多智能体部署的需求。", "method": "AEMA 框架通过计划、执行和聚合多步骤评估来实现，支持异构智能体工作流，并有人类监督。它是一种过程感知和可审计的框架。", "result": "在模拟的、具有现实业务场景的企业风格智能体工作流上进行的实验表明，AEMA 比单一 LLM 作为裁判（LLM-as-a-Judge）实现了更高的稳定性、与人类的一致性和可追溯的记录。", "conclusion": "AEMA 为 LLM 多智能体系统的负责任评估提供了一条透明且可重现的途径，支持可问责的自动化。"}}
{"id": "2601.12616", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12616", "abs": "https://arxiv.org/abs/2601.12616", "authors": ["Johnathan Corbin", "Sarah H. Q. Li", "Jonathan Rogers"], "title": "Allocating Corrective Control to Mitigate Multi-agent Safety Violations Under Private Preferences", "comment": "8 pages, 3 figures, Submitted to IEEE Robotics and Automation Letters (RA-L)", "summary": "We propose a novel framework that computes the corrective control efforts to ensure joint safety in multi-agent dynamical systems. This framework efficiently distributes the required corrective effort without revealing individual agents' private preferences. Our framework integrates high-order control barrier functions (HOCBFs), which enforce safety constraints with formal guarantees of safety for complex dynamical systems, with a privacy-preserving resource allocation mechanism based on the progressive second price (PSP) auction. When a joint safety constraint is violated, agents iteratively bid on new corrective efforts via 'avoidance credits' rather than explicitly solving for feasible corrective efforts that remove the safety violation. The resulting correction, determined via a second price payment rule, coincides with the socially optimal safe distribution of corrective actions. Critically, the bidding process achieves this optimal allocation efficiently and without revealing private preferences of individual agents. We demonstrate this method through multi-robot hardware experiments on the Robotarium platform.", "AI": {"tldr": "提出了一种新颖的框架，用于在多智能体动力学系统中计算纠正性控制工作量，以确保联合安全。该框架基于高阶控制屏障函数（HOCBF）和一种基于渐进式二价拍卖（PSP）的隐私保护资源分配机制，能够有效分配所需的纠正性工作量，同时不泄露个体智能体的私有偏好。智能体通过竞标“避免信用”来迭代地分配新的纠正性工作量，而不是直接求解可行的纠正性工作量。这种方法通过多机器人硬件实验得到验证。", "motivation": "在多智能体动力学系统中，确保所有智能体协同遵守安全约束是一个关键挑战。现有方法可能难以在不泄露个体信息的情况下有效分配纠正性控制工作量，同时还要保证安全。因此，研究者希望开发一种既能保证安全又能保护隐私的分布式纠正控制方法。", "method": "该框架结合了高阶控制屏障函数（HOCBF）和一种基于渐进式二价拍卖（PSP）的隐私保护资源分配机制。当联合安全约束被违反时，智能体通过竞标“避免信用”来迭代地分配纠正性控制工作量。拍卖机制以二价支付规则确定最终的纠正分配，此分配等同于社会最优的安全工作量分配。", "result": "研究提出了一种能够以隐私保护的方式实现联合安全约束的分布式纠正控制框架。该框架通过竞标机制有效地将纠正性控制工作量分配给各个智能体，从而确保了系统的整体安全，并且在多机器人硬件实验中得到了验证。", "conclusion": "本文提出了一种新颖的框架，通过结合HOCBF和PSP拍卖，实现了多智能体系统中对联合安全约束的隐私保护式纠正控制。该方法能够在不泄露个体偏好的情况下，高效地分配纠正性控制工作量，保证系统的安全，并在实际实验中得到了有效验证。"}}
{"id": "2601.11642", "categories": ["cs.CV", "cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.11642", "abs": "https://arxiv.org/abs/2601.11642", "authors": ["Abbas Alzubaidi", "Ali Al-Bayaty"], "title": "PSSF: Early osteoarthritis detection using physical synthetic knee X-ray scans and AI radiomics models", "comment": "16 pages, 6 figures", "summary": "Knee osteoarthritis (OA) is a major cause of disability worldwide and is still largely assessed using subjective radiographic grading, most commonly the Kellgren-Lawrence (KL) scale. Artificial intelligence (AI) and radiomics offer quantitative tools for OA assessment but depend on large, well-annotated image datasets, mainly X-ray scans, that are often difficult to obtain because of privacy, governance and resourcing constraints. In this research, we introduce a physics-based synthetic simulation framework (PSSF) to fully generate controllable X-ray scans without patients' involvement and violating their privacy and institutional constraints. This PSSF is a 2D X-ray projection simulator of anteroposterior knee radiographs from a parametric anatomical model of the distal femur and proximal tibia. Using PSSF, we create a virtual cohort of 180 subjects (260 knees), each is imaged under three protocols (reference, low-dose, and geometry-shift). Medial joint regions are automatically localized, preprocessed, and processed with the Image Biomarker Standardisation Initiative (IBSI). Practically, three machine learning (ML) models are utilized, logistic regression, random forest, and gradient boosting, to train binary (KL-like \"0\" vs. \"2\") and three-class (0-2) prediction radiographic images. Robustness is assessed within IBSI protocol, cross-protocol, and multi-protocol scenarios. Finally, features stability is then evaluated using intraclass correlation coefficients across acquisition changes.", "AI": {"tldr": "本研究提出一个基于物理的合成模拟框架 (PSSF)，用于生成可控的 X 射线扫描图像，以解决膝关节骨关节炎 (OA) 影像数据获取的挑战。", "motivation": "现有的放射学评估方法（如 Kellgren-Lawrence 量表）主观性强，而基于 AI 和放射组学的量化方法依赖于大型、标注良好的数据集，这些数据集因隐私、治理和资源限制而难以获取。", "method": "使用 PSSF 构建了一个参数化的解剖模型，模拟股骨远端和胫骨近端的二维 X 射线投影。生成了一个包含 180 名受试者（260 个膝关节）的虚拟队列，并在三种不同的成像协议下进行扫描。对 medial joint 区域进行自动定位、预处理和 IBSI 处理。使用逻辑回归、随机森林和梯度提升三种机器学习模型，对二进制（KL 相似的“0” vs. “2”）和三分类（0-2）的放射学图像进行预测。评估了模型在 IBSI 协议内、跨协议和多协议场景下的鲁棒性，并使用类内相关系数评估特征在不同采集条件下的稳定性。", "result": "研究成功生成了可控的膝关节 X 射线扫描图像，并利用这些合成数据训练了机器学习模型，在不同协议下展示了良好的预测性能和鲁棒性。特征稳定性评估显示了模型在不同采集变化下的稳定性。", "conclusion": "PSSF 是一个有效的工具，可以生成无隐私侵犯的、可控的膝关节 X 射线图像，为 AI 驱动的膝关节骨关节炎评估提供了一个可行的解决方案，克服了真实数据获取的障碍。"}}
{"id": "2601.13393", "categories": ["eess.IV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2601.13393", "abs": "https://arxiv.org/abs/2601.13393", "authors": ["Abhishek Singh", "Vitaliy L. Rayz", "Pavlos P. Vlachos"], "title": "VAST: Vascular Flow Analysis and Segmentation for Intracranial 4D Flow MRI", "comment": null, "summary": "Four-dimensional (4D) Flow MRI can noninvasively measure cerebrovascular hemodynamics but remains underused clinically because current workflows rely on manual vessel segmentation and yield velocity fields sensitive to noise, artifacts, and phase aliasing. We present VAST (Vascular Flow Analysis and Segmentation), an automated, unsupervised pipeline for intracranial 4D Flow MRI that couples vessel segmentation with physics-informed velocity reconstruction. VAST derives vessel masks directly from complex 4D Flow data by iteratively fusing magnitude- and phase-based background statistics. It then reconstructs velocities via continuity-constrained phase unwrapping, outlier correction, and low-rank denoising to reduce noise and aliasing while promoting mass-consistent flow fields, with processing completing in minutes per case on a standard CPU. We validate VAST on synthetic data from an internal carotid artery aneurysm model across SNR = 2-20 and severe phase wrapping (up to five-fold), on in vitro Poiseuille flow, and on an in vivo internal carotid aneurysm dataset. In synthetic benchmarks, VAST maintains near quarter-voxel surface accuracy and reduces velocity root-mean-square error by up to fourfold under the most degraded conditions. In vitro, it segments the channel within approximately half a voxel of expert annotations and reduces velocity error by 39% (unwrapped) and 77% (aliased). In vivo, VAST closely matches expert time-of-flight masks and lowers divergence residuals by about 30%, indicating a more self-consistent intracranial flow field. By automating processing and enforcing basic flow physics, VAST helps move intracranial 4D Flow MRI toward routine quantitative use in cerebrovascular assessment.", "AI": {"tldr": "本文提出了一种名为VAST的自动化、无监督的四维流动MRI（4D Flow MRI）处理流程，用于颅内血管血流动力学分析。VAST能够自动分割血管并重建速度场，克服了传统方法在手动分割、噪声敏感性和伪影等方面的限制，并在合成数据、体外实验和体内数据上均取得了优于现有方法的性能。", "motivation": "现有的四维流动MRI（4D Flow MRI）临床应用受限于手动血管分割和对噪声、伪影及相位混叠敏感的速度场，阻碍了其广泛临床使用。", "method": "VAST是一个自动化、无监督的处理流程，结合了血管分割和物理约束的速度重建。它通过迭代融合幅度和相位信息来获得血管掩码，并利用连续性约束的相位展开、异常值校正和低秩去噪来重建速度场，以减少噪声和混叠，同时保证流场质量。", "result": "在合成数据上，VAST在表面分割精度上接近四分之一体素，并在最差条件下将速度均方根误差降低了高达四倍。在体外实验中，其分割精度接近专家标注的一半体素，并将速度误差降低了39%（展开后）和77%（混叠时）。在体内数据上，VAST的分割结果与专家标注的时间-飞跃（time-of-flight）掩码高度一致，并将散度残差降低了约30%。", "conclusion": "VAST通过自动化处理并强制执行基本的流动物理学原理，显著提高了颅内4D Flow MRI的处理效率和准确性，有望推动其在脑血管评估中的常规定量应用。"}}
{"id": "2601.12377", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12377", "abs": "https://arxiv.org/abs/2601.12377", "authors": ["Haobo Xi", "Shiyong Zhang", "Qianli Dong", "Yunze Tong", "Songyang Wu", "Jing Yuan", "Xuebo Zhang"], "title": "R-VoxelMap: Accurate Voxel Mapping with Recursive Plane Fitting for Online LiDAR Odometry", "comment": null, "summary": "This paper proposes R-VoxelMap, a novel voxel mapping method that constructs accurate voxel maps using a geometry-driven recursive plane fitting strategy to enhance the localization accuracy of online LiDAR odometry. VoxelMap and its variants typically fit and check planes using all points in a voxel, which may lead to plane parameter deviation caused by outliers, over segmentation of large planes, and incorrect merging across different physical planes. To address these issues, R-VoxelMap utilizes a geometry-driven recursive construction strategy based on an outlier detect-and-reuse pipeline. Specifically, for each voxel, accurate planes are first fitted while separating outliers using random sample consensus (RANSAC). The remaining outliers are then propagated to deeper octree levels for recursive processing, ensuring a detailed representation of the environment. In addition, a point distribution-based validity check algorithm is devised to prevent erroneous plane merging. Extensive experiments on diverse open-source LiDAR(-inertial) simultaneous localization and mapping (SLAM) datasets validate that our method achieves higher accuracy than other state-of-the-art approaches, with comparable efficiency and memory usage. Code will be available on GitHub.", "AI": {"tldr": "本文提出了一种名为 R-VoxelMap 的新型体素建图方法，通过几何驱动的递归平面拟合策略来构建精确的体素地图，以提高在线 LiDAR 里程计的定位精度。该方法通过 RANSAC 分离并重用离群点，并引入基于点分布的有效性检查算法，解决了现有方法的平面参数偏差、过分割和错误合并问题。实验证明 R-VoxelMap 在精度上优于现有技术，效率和内存占用相当。", "motivation": "现有体素建图方法在处理平面时容易受到离群点影响，导致平面参数偏差、大平面过分割以及不同物理平面之间的错误合并，从而影响 LiDAR 里程计的定位精度。研究旨在解决这些问题，提高建图和定位的准确性。", "method": "R-VoxelMap 采用几何驱动的递归建图策略，基于离群点检测与重用管道。具体而言，对于每个体素，首先使用 RANSAC 拟合平面并分离离群点。剩余的离群点会被递归地传递到更深的八叉树层级进行处理。此外，还设计了一个基于点分布的有效性检查算法，以防止错误的平面合并。", "result": "在多个公开的 LiDAR(-惯性) SLAM 数据集上的广泛实验表明，R-VoxelMap 方法在定位精度上优于其他最先进的方法，同时具有可比的效率和内存使用量。", "conclusion": "R-VoxelMap 是一种有效的体素建图方法，通过改进的平面拟合和离群点处理策略，显著提高了 LiDAR 里程计的定位精度，并能在多种数据集上取得优于现有方法的性能。"}}
{"id": "2601.11641", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11641", "abs": "https://arxiv.org/abs/2601.11641", "authors": ["Yuxi Liu", "Yipeng Hu", "Zekun Zhang", "Kunze Jiang", "Kun Yuan"], "title": "Mixture of Distributions Matters: Dynamic Sparse Attention for Efficient Video Diffusion Transformers", "comment": null, "summary": "While Diffusion Transformers (DiTs) have achieved notable progress in video generation, this long-sequence generation task remains constrained by the quadratic complexity inherent to self-attention mechanisms, creating significant barriers to practical deployment. Although sparse attention methods attempt to address this challenge, existing approaches either rely on oversimplified static patterns or require computationally expensive sampling operations to achieve dynamic sparsity, resulting in inaccurate pattern predictions and degraded generation quality. To overcome these limitations, we propose a \\underline{\\textbf{M}}ixtrue-\\underline{\\textbf{O}}f-\\underline{\\textbf{D}}istribution \\textbf{DiT} (\\textbf{MOD-DiT}), a novel sampling-free dynamic attention framework that accurately models evolving attention patterns through a two-stage process. First, MOD-DiT leverages prior information from early denoising steps and adopts a {distributed mixing approach} to model an efficient linear approximation model, which is then used to predict mask patterns for a specific denoising interval. Second, an online block masking strategy dynamically applies these predicted masks while maintaining historical sparsity information, eliminating the need for repetitive sampling operations. Extensive evaluations demonstrate consistent acceleration and quality improvements across multiple benchmarks and model architectures, validating MOD-DiT's effectiveness for efficient, high-quality video generation while overcoming the computational limitations of traditional sparse attention approaches.", "AI": {"tldr": "提出了一种名为MOD-DiT的新型采样无关动态注意力框架，通过两阶段方法有效解决视频生成中Transformer的二次复杂度问题，实现了更快的生成速度和更高的质量。", "motivation": "视频生成任务中Diffusion Transformers（DiTs）受限于自注意力机制的二次复杂度，现有稀疏注意力方法要么模式静态且简化，要么需要计算昂贵的采样操作，导致生成质量下降。因此，需要一种更有效的动态稀疏注意力机制。", "method": "MOD-DiT采用两阶段方法。第一阶段，利用早期去噪步骤的先验信息，采用一种“分布式混合方法”构建一个高效的线性近似模型，用于预测特定去噪区间的掩码模式。第二阶段，采用在线块掩码策略动态应用预测的掩码，同时保留历史稀疏性信息，无需重复采样。", "result": "在多个基准测试和模型架构上，MOD-DiT实现了显著的加速和生成质量的提升。", "conclusion": "MOD-DiT是一种有效的采样无关动态注意力框架，能够克服传统稀疏注意力方法的计算限制，为高效、高质量的视频生成提供了解决方案。"}}
{"id": "2601.12625", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12625", "abs": "https://arxiv.org/abs/2601.12625", "authors": ["Parisa Ansari Bonab", "Elisabeth Andarge Gedefaw", "Mohammad Khajenejad"], "title": "Resilient Interval Observer-Based Control for Cooperative Adaptive Cruise Control under FDI Attack", "comment": null, "summary": "Connectivity in connected and autonomous vehicles (CAVs) introduces vulnerability to cyber threats such as false data injection (FDI) attacks, which can compromise system reliability and safety. To ensure resilience, this paper proposes a control framework combining a nonlinear controller with an interval observer for robust state estimation under measurement noise. The observer bounds leader's states, while a neural network-based estimator estimates the unknown FDI attacks in real time. These estimates are then used to mitigate FDI attack effects maintaining safe inter-vehicle spacing. The proposed approach leverages an idea of interval observer-based estimation and merges model-based and learning-based methods to achieve accurate estimations and real-time performance. MATLAB/Simulink results confirm resilient tracking, precise FDI attack estimation, and robustness to noise, demonstrating potential for real-world CACC applications under cyberattacks, disturbance, and bounded measurement noise.", "AI": {"tldr": "本文提出一种结合非线性控制器和区间观测器的控制框架，用于在存在测量噪声的情况下对连通和自动驾驶汽车（CAVs）的虚假数据注入（FDI）攻击进行鲁棒状态估计和实时抑制。", "motivation": "连通性为CAVs带来了网络威胁，特别是FDI攻击，这些攻击会影响系统可靠性和安全性，因此需要一种确保弹性的方法。", "method": "该方法结合了区间观测器（用于边界领导者状态）和基于神经网络的估计器（用于实时估计未知FDI攻击）。利用这些估计值来减轻FDI攻击的影响，并保持安全的车间距。该方法融合了基于模型和基于学习的方法。", "result": "MATLAB/Simulink仿真结果表明，该方法在网络攻击、扰动和有界测量噪声的情况下，实现了鲁棒的跟踪、精确的FDI攻击估计和噪声鲁棒性。", "conclusion": "所提出的区间观测器和神经网络相结合的控制框架能够有效地估计并减轻CAVs中的FDI攻击，在存在噪声和攻击的情况下保持安全性和可靠性，适用于实际的CACC应用。"}}
{"id": "2601.11644", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11644", "abs": "https://arxiv.org/abs/2601.11644", "authors": ["Muhammad Imran", "Yugyung Lee"], "title": "Predicting When to Trust Vision-Language Models for Spatial Reasoning", "comment": "9 pages, 5 figures, 6 tables", "summary": "Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks, yet exhibit systematic spatial reasoning failures, achieving only 49% (CLIP) to 54% (BLIP-2) accuracy on basic directional relationships. For safe deployment in robotics and autonomous systems, we need to predict when to trust VLM spatial predictions rather than accepting all outputs. We propose a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. Unlike text-based approaches relying on self-assessment, our method fuses four signals via gradient boosting: geometric alignment between VLM claims and coordinates, spatial ambiguity from overlap, detection quality, and VLM internal uncertainty. We achieve 0.674 AUROC on BLIP-2 (34.0% improvement over text-based baselines) and 0.583 AUROC on CLIP (16.1% improvement), generalizing across generative and classification architectures. Our framework enables selective prediction: at 60% target accuracy, we achieve 61.9% coverage versus 27.6% baseline (2.2x improvement) on BLIP-2. Feature analysis reveals vision-based signals contribute 87.4% of model importance versus 12.7% from VLM confidence, validating that external geometric verification outperforms self-assessment. We demonstrate reliable scene graph construction where confidence-based pruning improves precision from 52.1% to 78.3% while retaining 68.2% of edges.", "AI": {"tldr": "该研究提出了一种基于视觉的置信度估计框架，通过独立的几何验证来评估视觉语言模型（VLM）的空间推理能力，显著提高了VLM在机器人和自动驾驶等领域的可靠性。", "motivation": "现有VLM在空间推理方面存在系统性缺陷，准确率较低（49%-54%）。为了安全地将VLM应用于机器人和自动驾驶等领域，需要预测何时可以信任VLM的空间预测。", "method": "提出了一种基于视觉的置信度估计框架，通过目标检测进行独立的几何验证。该方法融合了四个信号：VLM声明与坐标的几何对齐、重叠引起的空间歧义、检测质量以及VLM内部的不确定性，并使用梯度提升模型进行融合。", "result": "在BLIP-2上实现了0.674的AUROC（比基于文本的方法提高了34.0%），在CLIP上实现了0.583的AUROC（提高了16.1%）。在目标准确率为60%时，BLIP-2的覆盖率从27.6%提高到61.9%（2.2倍）。视觉信号在模型重要性中占87.4%，而VLM置信度占12.7%。基于置信度的剪枝将场景图的精度从52.1%提高到78.3%，同时保留了68.2%的边。", "conclusion": "基于几何验证的视觉置信度估计方法优于基于文本的自评估方法，能够有效地提高VLM空间推理的可靠性，并实现选择性预测，在机器人和自动驾驶等关键应用中具有重要价值。"}}
{"id": "2601.13685", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2601.13685", "abs": "https://arxiv.org/abs/2601.13685", "authors": ["Sin-Yu Huang"], "title": "Toward Agentic AI: Task-Oriented Communication for Hierarchical Planning of Long-Horizon Tasks", "comment": "Accepted by IEEE International Conference on Communications (ICC), Glasgow, UK, May 2026", "summary": "Agentic artificial intelligence (AI) is an AI paradigm that can perceive the environment, reason over observations, and execute actions to achieve specific goals. Task-oriented communication supports agentic AI by transmitting only the task-related information instead of full raw data in order to reduce the bandwidth requirement. In real-world scenarios, AI agents often need to perform a sequence of actions to complete complex tasks. Completing these long-horizon tasks requires a hierarchical agentic AI architecture, where a high-level planner module decomposes a task into subtasks, and a low-level actor module executes each subtask sequentially. Since each subtask has a distinct goal, the existing task-oriented communication schemes are not designed to handle different goals for different subtasks. To address this challenge, in this paper, we develop a hierarchical task-oriented communication (HiTOC) framework. We consider a system with an edge server and a robot as an edge device. The high-level planner and low-level actor modules reside on the edge server. The robot transmits only the environment information that is relevant to the current subtask in order to complete a long-horizon task. We propose a conditional variational information bottleneck (cVIB) approach to train the HiTOC framework to adaptively transmit minimal information required for each subtask. Simulations conducted on the AI2-THOR platform demonstrate that the proposed HiTOC framework outperforms three state-of-the-art schemes in terms of the success rate on MAP-THOR benchmark.", "AI": {"tldr": "提出了一种名为HiTOC的层级式任务导向通信框架，用于支持具有长远目标的智能体AI。该框架通过条件变分信息瓶颈（cVIB）方法，使机器人能够根据当前子任务的目标，自适应地传输最少的相关环境信息，从而优化通信效率。", "motivation": "现有的任务导向通信方案无法处理AI智能体需要执行一系列具有不同子目标的任务。当AI智能体需要完成长远任务时，需要一个层级式架构来分解和执行子任务，这带来了新的通信挑战。", "method": "开发了一个名为HiTOC的层级式任务导向通信框架。该框架包含一个高层规划器和一个低层执行器，分别部署在边缘服务器上。机器人作为边缘设备，通过条件变分信息瓶颈（cVIB）方法，根据当前子任务的目标，自适应地传输最少的相关环境信息。", "result": "在AI2-THOR平台上的模拟实验表明，HiTOC框架在MAP-THOR基准测试上的成功率优于三种最先进的方案。", "conclusion": "HiTOC框架能够有效地支持具有长远目标的层级式智能体AI，通过自适应地传输最小必要信息来完成复杂任务，并显著提高通信效率和任务成功率。"}}
{"id": "2601.12395", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.12395", "abs": "https://arxiv.org/abs/2601.12395", "authors": ["Chao Wang", "Anna Belardinelli", "Michael Gienger"], "title": "VR$^2$: A Co-Located Dual-Headset Platform for Touch-Enabled Human-Robot Interaction Research", "comment": "7 pages, 4 figures", "summary": "Touch-rich human-robot interaction (HRI) is difficult to study: building and programming physical robots is costly and slow, while VR-based robot prototypes often remove physical contact or break the tight coupling between an agent's body and the user's felt touch. We present VR2VR, a co-located dual VR-headset platform for HRI research in which a participant and a hidden operator share the same physical space while experiencing different virtual embodiments. The participant sees an expressive virtual robot that interacts face-to-face in a shared virtual environment. In real time, the robot's upper-body gestures, head and gaze behaviors, and facial expressions are mapped from the operator's tracked motion and face signals. Because the operator is physically co-present and calibrated into the same coordinate frame, the operator can also physically touch the participant, enabling the participant to perceive robot touch aligned with the robot's hands; finger and hand motion are mapped to the robot using inverse kinematics to support precise contact. Beyond faithful motion retargeting for limb teleoperation, our VR2VR system supports experimental control by retargeting or selectively enabling nonverbal channels (e.g., head only vs. head+eyes vs. head+eyes+facial expressions) while keeping physical interaction constant. We detail the system design, calibration workflow, and safety considerations, and demonstrate the platform through a touch-based Wizard-of-Oz HRI study, illustrating how VR2VR lowers barriers for rapidly prototyping and rigorously evaluating embodied, touch-centric robot behaviors.", "AI": {"tldr": "VR2VR是一个双VR头显平台，允许一人扮演隐藏的操作员，另一人扮演虚拟机器人，实现低成本、高保真的触觉交互HRI研究。", "motivation": "传统的人机交互（HRI）研究难以进行富含触觉的交互，因为物理机器人昂贵且难以编程，而VR原型则常常牺牲物理接触或割裂身体与触觉的紧密联系。", "method": "构建了一个共处的双VR头显平台（VR2VR），参与者扮演虚拟机器人，操作员（隐藏）通过追踪的身体和面部信号实时控制机器人的动作、头部和面部表情。操作员可以物理接触参与者，通过逆运动学实现精确的触觉反馈。平台还支持实验控制，可以选择性地启用或禁用非语言交流通道。", "result": "VR2VR平台能够实现真实的动作重定向和精确的触觉反馈，并允许在保持物理交互不变的情况下，对非语言交流通道进行实验控制。通过一个基于触觉的“奥兹巫师”HRI研究进行了演示。", "conclusion": "VR2VR平台降低了快速原型设计和严格评估具身化、以触觉为中心的机器人行为的门槛，为HRI研究提供了一个有效且经济的解决方案。"}}
{"id": "2601.12657", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12657", "abs": "https://arxiv.org/abs/2601.12657", "authors": ["Yin Wu", "Wei-Yu Chiu", "Yuan-Po Tsai", "Shangyuan Liu", "Weiqi Hua"], "title": "Multiagent Reinforcement Learning in Enhancing Resilience of Microgrids under Extreme Weather Events", "comment": "26 pages, 9 figures", "summary": "Grid resilience is crucial in light of power interruptions caused by increasingly frequent extreme weather events. Well-designed energy management systems (EMS) have made progress in improving microgrid resilience through the coordination of distributed energy resources (DERs), but still face significant challenges in addressing the uncertainty of load demand caused by extreme weather. The integration of deep reinforcement learning (DRL) into EMS design enables optimized microgrid control strategies for coordinating DERs. Building on this, we proposed a cooperative multi-agent deep reinforcement learning (MADRL)-based EMS framework to provide flexible scalability for microgrids, enhance resilience and reduce operational costs during power outages. Specifically, the gated recurrent unit with a gating mechanism was introduced to extract features from temporal data, which enables the EMS to coordinate DERs more efficiently. Next, the proposed MADRL method incorporating action masking techniques was evaluated in the IEEE 33-Bus system using real-world data on renewable generation and power load. Finally, the numerical results demonstrated the superiority of the proposed method in reducing operating costs as well as the effectiveness in enhancing microgrid resilience during power interruptions.", "AI": {"tldr": "本文提出了一种基于多智能体深度强化学习（MADRL）的能量管理系统（EMS），以提高微电网在极端天气导致停电时的韧性和降低运营成本，通过引入门控循环单元（GRU）来处理时序数据，并结合动作掩码技术进行优化。", "motivation": "极端天气事件频繁导致电网中断，提高电网韧性至关重要。现有的EMS在应对极端天气下不确定的负荷需求方面存在挑战。", "method": "提出了一种合作式多智能体深度强化学习（MADRL）EMS框架。该框架引入了带有门控机制的门控循环单元（GRU）来提取时序数据特征，并结合动作掩码技术来优化DERs的协调。在IEEE 33节点系统上使用真实数据进行了评估。", "result": "数值结果表明，所提出的MADRL方法在降低运营成本和提高微电网在停电期间的韧性方面表现出优越性。", "conclusion": "基于MADRL的EMS框架能够灵活扩展，有效提升微电网在极端天气下的韧性，并降低运营成本。GRU和动作掩码技术的引入进一步增强了EMS协调DERs的能力。"}}
{"id": "2601.11905", "categories": ["cs.AI", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.11905", "abs": "https://arxiv.org/abs/2601.11905", "authors": ["Junyu Cao", "Ruijiang Gao", "Esmaeil Keyvanshokooh", "Jianhao Ma"], "title": "LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning", "comment": "50 pages. Previous version with human-AI collaboration: arXiv:2410.14640", "summary": "We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.", "AI": {"tldr": "本文提出了一种结合算法追索、上下文老虎机和大型语言模型（LLMs）的统一框架，用于高风险场景下的序贯决策，例如个性化医疗。该框架能够同时选择治疗方案和对患者特征进行可行、最小化的修改。作者开发了GLRB算法，并在此基础上提出了LIBRA算法，后者结合了LLMs的领域知识和老虎机学习的统计严谨性，并提供了多项理论保证，实验结果也验证了其优越性。", "motivation": "高风险决策场景（如个性化医疗）需要同时进行干预决策和对决策结果产生影响的因素进行调整。现有的算法在处理这类问题时存在不足，需要一个能够整合多种技术（算法追索、上下文老虎机、LLMs）的统一框架。", "method": "1. 提出“追索老虎机问题”（recourse bandit problem），该问题要求同时选择治疗行动和修改患者特征。 2. 开发了“广义线性追索老虎机”（GLRB）算法。 3. 提出了“语言模型驱动的追索老虎机算法”（LIBRA），该算法结合了LLMs的知识和老虎机学习，并提供了暖启动、LLM效率和鲁棒性保证。 4. 建立了追索老虎机问题的理论下界，证明了算法的近乎最优性。 5. 在合成环境和高血压管理案例研究中进行了实验验证。", "result": "GLRB和LIBRA算法在减少遗憾、提高治疗质量和样本效率方面优于标准的上下文老虎机和仅使用LLM的基准方法。LIBRA在LLM推荐接近最优时能显著减少初始遗憾，仅在对数平方次的时间步内咨询LLM，并且在LLM不可靠时表现优于纯粹的老虎机算法。", "conclusion": "本文提出的结合算法追索、上下文老虎机和LLMs的统一框架（特别是LIBRA算法）在高风险序贯决策中具有潜力，能够实现值得信赖的LLM-老虎机协同，为个性化决策提供支持。"}}
{"id": "2601.11762", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11762", "abs": "https://arxiv.org/abs/2601.11762", "authors": ["Sae Young Moon", "Myeongjun Erik Jang", "Haoyan Luo", "Chunyang Xiao", "Antonios Georgiadis", "Fran Silavong"], "title": "Industry-Aligned Granular Topic Modeling", "comment": null, "summary": "Topic modeling has extensive applications in text mining and data analysis across various industrial sectors. Although the concept of granularity holds significant value for business applications by providing deeper insights, the capability of topic modeling methods to produce granular topics has not been thoroughly explored. In this context, this paper introduces a framework called TIDE, which primarily provides a novel granular topic modeling method based on large language models (LLMs) as a core feature, along with other useful functionalities for business applications, such as summarizing long documents, topic parenting, and distillation. Through extensive experiments on a variety of public and real-world business datasets, we demonstrate that TIDE's topic modeling approach outperforms modern topic modeling methods, and our auxiliary components provide valuable support for dealing with industrial business scenarios. The TIDE framework is currently undergoing the process of being open sourced.", "AI": {"tldr": "本文提出了一种名为TIDE的框架，利用大型语言模型（LLMs）实现细粒度主题建模，并提供文档摘要、主题父子关系构建和主题提炼等功能，在多项实验中表现优于现有方法。", "motivation": "现有主题建模方法在提供细粒度主题方面能力不足，而细粒度在商业应用中具有重要价值。LLMs的出现为解决此问题提供了新的可能。", "method": "提出TIDE框架，核心是基于LLMs的细粒度主题建模方法。框架还包含文档摘要、主题父子关系构建（topic parenting）和主题提炼（distillation）等辅助功能。", "result": "在公开和真实商业数据集上的实验表明，TIDE的主题建模方法优于现有现代主题建模方法，其辅助功能也能有效支持工业商业场景。", "conclusion": "TIDE框架能够提供比现有方法更细粒度的主题，并且其附加功能为处理工业商业场景提供了有价值的支持。该框架即将开源。"}}
{"id": "2601.11645", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11645", "abs": "https://arxiv.org/abs/2601.11645", "authors": ["Ujjwal Jain", "Oshin Misra", "Roshni Chakraborty", "Mahua Bhattacharya"], "title": "IMSAHLO: Integrating Multi-Scale Attention and Hybrid Loss Optimization Framework for Robust Neuronal Brain Cell Segmentation", "comment": null, "summary": "Accurate segmentation of neuronal cells in fluorescence microscopy is a fundamental task for quantitative analysis in computational neuroscience. However, it is significantly impeded by challenges such as the coexistence of densely packed and sparsely distributed cells, complex overlapping morphologies, and severe class imbalance. Conventional deep learning models often fail to preserve fine topological details or accurately delineate boundaries under these conditions. To address these limitations, we propose a novel deep learning framework, IMSAHLO (Integrating Multi-Scale Attention and Hybrid Loss Optimization), for robust and adaptive neuronal segmentation. The core of our model features Multi-Scale Dense Blocks (MSDBs) to capture features at various receptive fields, effectively handling variations in cell density, and a Hierarchical Attention (HA) mechanism that adaptively focuses on salient morphological features to preserve Region of Interest (ROI) boundary details. Furthermore, we introduce a novel hybrid loss function synergistically combining Tversky and Focal loss to combat class imbalance, alongside a topology-aware Centerline Dice (clDice) loss and a Contour-Weighted Boundary loss to ensure topological continuity and precise separation of adjacent cells. Large-scale experiments on the public Fluorescent Neuronal Cells (FNC) dataset demonstrate that our framework outperforms state-of-the-art architectures, achieving precision of 81.4%, macro F1 score of 82.7%, micro F1 score of 83.3%, and balanced accuracy of 99.5% on difficult dense and sparse cases. Ablation studies validate the synergistic benefits of multi-scale attention and hybrid loss terms. This work establishes a foundation for generalizable segmentation models applicable to a wide range of biomedical imaging modalities, pushing AI-assisted analysis toward high-throughput neurobiological pipelines.", "AI": {"tldr": "提出了一种名为IMSAHLO的新型深度学习框架，用于解决荧光显微镜下神经元细胞分割中的密集/稀疏共存、形态复杂和类别不平衡等问题，并在FNC数据集上取得了优于现有方法的性能。", "motivation": "传统的深度学习模型在处理神经元细胞分割时，常因细胞密度变化、形态复杂和类别不平衡等问题而难以精确分割，尤其是在保留精细拓扑细节和区分重叠细胞方面表现不佳。", "method": "提出IMSAHLO框架，包括：1. 多尺度密集块（MSDB）以捕获不同感受野的特征；2. 分层注意力（HA）机制以自适应关注显著形态特征；3. 混合损失函数，结合Tversky和Focal loss来解决类别不平衡；4. 拓扑感知的中心线Dice（clDice）损失和轮廓加权边界损失以确保拓扑连续性和精确分离。", "result": "在FNC数据集上，IMSAHLO在密集和稀疏场景下取得了优于现有最先进方法的性能，具体指标包括：精确率81.4%、宏F1分数82.7%、微F1分数83.3%、平衡准确率99.5%。消融实验证明了多尺度注意力和混合损失项的协同增益效应。", "conclusion": "IMSAHLO框架在处理具有挑战性的神经元细胞分割任务方面表现出鲁棒性和自适应性，为通用分割模型奠定了基础，可应用于多种生物医学成像，并推动AI辅助分析在神经生物学高通量流程中的应用。"}}
{"id": "2601.11940", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11940", "abs": "https://arxiv.org/abs/2601.11940", "authors": ["Kang Chen", "Fan Yu", "Junjie Nian", "Shihan Zhao", "Zhuoka Feng", "Zijun Yao", "Heng Wang", "Minshen Yu", "Yixin Cao"], "title": "Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart", "comment": null, "summary": "Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.", "AI": {"tldr": "本研究提出了一种名为TAAR（Trap-Aware Adaptive Restart）的测试时控制框架，用于解决长链思考（Long-CoT）推理中的“思维陷阱”问题。TAAR通过训练一个诊断策略来预测何时应截断推理路径以及如何进行适应性重启，从而在不微调基础模型参数的情况下提高数学和科学推理的性能。", "motivation": "长链思考（Long-CoT）虽然增强了模型的推理能力，但模型可能在早期做出错误承诺后，持续生成自洽但错误的前缀，导致无法纠正。作者发现89%的推理失败都源于这种“思维陷阱”。", "method": "研究人员开发了TAAR框架，该框架在测试时训练一个诊断策略，用于从部分推理轨迹预测两个信号：1）截断点（trap index），即在哪个部分停止当前推理；2）逃逸概率（escape probability），指示是否以及多大程度上需要干预。在推理时，TAAR会根据预测的陷阱位置截断轨迹并自适应地重启解码。对于陷阱严重的案例，会采用更强的扰动，如提高温度重采样或添加结构化重启后缀。", "result": "在AIME24、AIME25、GPQA-Diamond、HMMT25和BRUMO25等数学和科学推理基准测试中，TAAR在不进行基础模型参数微调的情况下，显著提升了推理性能。", "conclusion": "TAAR是一个有效的测试时控制框架，能够通过识别和解决推理中的“思维陷阱”来提高大型语言模型的推理能力，尤其是在复杂的数学和科学领域。"}}
{"id": "2601.12397", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12397", "abs": "https://arxiv.org/abs/2601.12397", "authors": ["Wangtian Shen", "Jinming Ma", "Mingliang Zhou", "Ziyang Meng"], "title": "Learning Diverse Skills for Behavior Models with Mixture of Experts", "comment": null, "summary": "Imitation learning has demonstrated strong performance in robotic manipulation by learning from large-scale human demonstrations. While existing models excel at single-task learning, it is observed in practical applications that their performance degrades in the multi-task setting, where interference across tasks leads to an averaging effect. To address this issue, we propose to learn diverse skills for behavior models with Mixture of Experts, referred to as Di-BM. Di-BM associates each expert with a distinct observation distribution, enabling experts to specialize in sub-regions of the observation space. Specifically, we employ energy-based models to represent expert-specific observation distributions and jointly train them alongside the corresponding action models. Our approach is plug-and-play and can be seamlessly integrated into standard imitation learning methods. Extensive experiments on multiple real-world robotic manipulation tasks demonstrate that Di-BM significantly outperforms state-of-the-art baselines. Moreover, fine-tuning the pretrained Di-BM on novel tasks exhibits superior data efficiency and the reusable of expert-learned knowledge. Code is available at https://github.com/robotnav-bot/Di-BM.", "AI": {"tldr": "提出了一种名为Di-BM的混合专家模型，用于解决模仿学习在多任务场景下的性能下降问题，通过让专家模型学习观察空间的特定子区域，有效提升了模型在多任务和新任务上的表现。", "motivation": "现有的模仿学习模型在单一任务上表现良好，但在多任务场景下，任务间的干扰会导致性能下降（平均效应）。", "method": "使用混合专家（Mixture of Experts）模型，将每个专家与不同的观察分布关联，使其能够专注于观察空间的特定子区域。具体来说，采用基于能量的模型（Energy-Based Models）来表示专家特定的观察分布，并与相应的动作模型联合训练。", "result": "Di-BM在多个真实的机器人操作任务上显著优于现有的最先进基线方法。此外，在新的任务上微调预训练的Di-BM模型，展现出更高的数据效率和专家知识的可复用性。", "conclusion": "Di-BM通过专家在观察空间上的专业化，有效解决了多任务模仿学习中的任务干扰问题，并能高效地迁移知识到新任务。"}}
{"id": "2601.13927", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2601.13927", "abs": "https://arxiv.org/abs/2601.13927", "authors": ["Yousef Sadegheih", "Dorit Merhof", "Pratibha Kumari"], "title": "Towards Modality-Agnostic Continual Domain-Incremental Brain Lesion Segmentation", "comment": "Submitted to MIDL 2026", "summary": "Brain lesion segmentation from multi-modal MRI often assumes fixed modality sets or predefined pathologies, making existing models difficult to adapt across cohorts and imaging protocols. Continual learning (CL) offers a natural solution but current approaches either impose a maximum modality configuration or suffer from severe forgetting in buffer-free settings. We introduce CLMU-Net, a replay-based CL framework for 3D brain lesion segmentation that supports arbitrary and variable modality combinations without requiring prior knowledge of the maximum set. A conceptually simple yet effective channel-inflation strategy maps any modality subset into a unified multi-channel representation, enabling a single model to operate across diverse datasets. To enrich inherently local 3D patch features, we incorporate lightweight domain-conditioned textual embeddings that provide global modality-disease context for each training case. Forgetting is further reduced through principled replay using a compact buffer composed of both prototypical and challenging samples. Experiments on five heterogeneous MRI brain datasets demonstrate that CLMU-Net consistently outperforms popular CL baselines. Notably, our method yields an average Dice score improvement of $\\geq$ 18\\% while remaining robust under heterogeneous-modality conditions. These findings underscore the value of flexible modality handling, targeted replay, and global contextual cues for continual medical image segmentation. Our implementation is available at https://github.com/xmindflow/CLMU-Net.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.11776", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11776", "abs": "https://arxiv.org/abs/2601.11776", "authors": ["Kaituo Zhang", "Zhimeng Jiang", "Na Zou"], "title": "Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models", "comment": null, "summary": "Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, we propose a Toxic Signal Detector --an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that our method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, our findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.", "AI": {"tldr": "本文提出了一种全自主反思式去毒化框架，利用大型语言模型（LLMs）自身能力来检测、纠正有毒内容，并进行模型微调，无需外部模块或人工标注，实验证明在 DetoxLLM 和 ParaDetox 数据集上性能优于现有技术。", "motivation": "现有去毒化技术依赖外部模块、耗时的数据标注或人工干预，效率低下且难以扩展；而 LLMs 本身已展现出自我校正和自我奖励等能力，可以被用来实现更高效、更具可扩展性的去毒化。", "method": "提出一种名为“有毒信号检测器”的内部自我识别机制，并结合系统性干预过程，将有毒文本转化为无毒文本。通过迭代过程生成对比去毒化数据集，用于微调模型，从而增强其安全和连贯的文本生成能力。", "result": "在 DetoxLLM 和 ParaDetox 基准数据集上的实验表明，该方法在去毒化性能上优于最先进的方法，同时保持了语义保真度。", "conclusion": "该框架利用了 LLMs 固有的自我去毒化能力，无需人工干预或外部组件，提供了一种一致且有效的方法来减轻有害内容生成，展示了真正自我监管语言模型的潜力，为更负责任和符合伦理的文本生成系统铺平了道路。"}}
{"id": "2601.11974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11974", "abs": "https://arxiv.org/abs/2601.11974", "authors": ["Xinmeng Hou", "Peiliang Gong", "Bohao Qu", "Wuqi Wang", "Qing Guo", "Yang Liu"], "title": "Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement", "comment": null, "summary": "While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.", "AI": {"tldr": "本文提出了一种名为MARS的元认知自省式自我改进框架，该框架通过单次循环实现高效的自主演化，能够系统地优化推理逻辑，并在多个基准测试中超越现有最先进的方法，同时显著降低计算成本。", "motivation": "现有LLM驱动的自主代理受限于静态、人工设计的提示词，缺乏适应性。现有的自改进框架效率低下，计算成本高昂。", "method": "提出MARS框架，模拟人类学习，结合基于原则的反思（抽象规则以避免错误）和基于过程的反思（推导成功策略），将这些见解综合成优化指令，在单次循环内实现自我演化。", "result": "MARS在六个基准测试中表现优于最先进的自进化系统，同时计算开销显著降低。", "conclusion": "MARS框架能够高效地实现LLM代理的自我改进和适应性，通过整合不同类型的反思来优化推理逻辑，而无需持续的在线反馈。"}}
{"id": "2601.12687", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12687", "abs": "https://arxiv.org/abs/2601.12687", "authors": ["Manobendu Sarker", "Soumaya Cherkaoui"], "title": "Network Slicing Resource Management in Uplink User-Centric Cell-Free Massive MIMO Systems", "comment": "6 pages, Accepted in IEEE ICC 2026", "summary": "This paper addresses the joint optimization of per-user equipment (UE) bandwidth allocation and UE-access point (AP) association to maximize weighted sum-rate while satisfying heterogeneous quality-of-service (QoS) requirements across enhanced mobile broadband (eMBB) and ultra-reliable low-latency communication (URLLC) slices in the uplink of a network slicing-enabled user-centric cell-free (CF) massive multiple-input multiple-output (mMIMO) system. The formulated problem is NP-hard, rendering global optimality computationally intractable. To address this challenge, it is decomposed into two sub-problems, each solved by a computationally efficient heuristic scheme, and jointly optimized through an alternating optimization framework. We then propose (i) a bandwidth allocation scheme that balances UE priority, spectral efficiency, and minimum bandwidth demand under limited resources to ensure fair QoS distribution, and (ii) a priority-based UE-AP association assignment approach that balances UE service quality with system capacity constraints. Together, these approaches provide a practical and computationally efficient solution for resource-constrained network slicing scenarios, where QoS feasibility is often violated under dense deployments and limited bandwidth, necessitating graceful degradation and fair QoS preservation rather than solely maximizing the aggregate sum-rate. Simulation results demonstrate that the proposed scheme achieves up to 52% higher weighted sum-rate, 140% and 58% higher QoS success rates for eMBB and URLLC slices, respectively, while reducing runtime by up to 97% compared to considered benchmarks.", "AI": {"tldr": "本文提出了一种在网络切片支持的无蜂窝Massive MIMO系统中，联合优化用户设备（UE）带宽分配和UE-AP关联以最大化加权和速率，同时满足eMBB和URLLC切片的QoS要求。通过分解NP-hard问题为两个子问题并使用交替优化框架求解，实现了高效的QoS保障和资源分配。", "motivation": "现有系统在网络切片场景下，特别是在密集部署和带宽受限时，QoS可行性常常被违反。本研究旨在解决此类资源受限场景下的QoS保障问题，提出一种在最大化总和速率的同时，能兼顾QoS公平性并允许优雅降级的解决方案。", "method": "将NP-hard的联合优化问题分解为带宽分配和UE-AP关联两个子问题。采用交替优化框架，分别设计了（i）一种平衡UE优先级、频谱效率和最小带宽需求的带宽分配方案，以及（ii）一种平衡UE服务质量和系统容量的优先级UE-AP关联方案。", "result": "仿真结果表明，所提出的联合优化方案相比基准方案，在加权和速率上最高可提升52%，eMBB和URLLC切片的QoS成功率分别提升140%和58%，同时运行时间减少高达97%。", "conclusion": "本文提出的计算高效的交替优化框架，通过联合优化带宽分配和UE-AP关联，能够有效满足网络切片下的异构QoS需求，在资源受限场景下实现QoS的优雅降级和公平保持，并显著提升系统性能。"}}
{"id": "2601.11651", "categories": ["cs.CV", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.11651", "abs": "https://arxiv.org/abs/2601.11651", "authors": ["Miriam Doh", "Aditya Gulati", "Corina Canali", "Nuria Oliver"], "title": "Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification", "comment": "22 pages, 15 figures", "summary": "This paper examines algorithmic lookism-the systematic preferential treatment based on physical appearance-in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, we demonstrate how generative AI models systematically associate facial attractiveness with positive attributes and vice-versa, mirroring socially constructed biases rather than evidence-based correlations. Furthermore, we find significant gender bias in three gender classification algorithms depending on the attributes of the input faces. Our findings reveal three critical harms: (1) the systematic encoding of attractiveness-positive attribute associations in T2I models; (2) gender disparities in classification systems, where women's faces, particularly those generated with negative attributes, suffer substantially higher misclassification rates than men's; and (3) intensifying aesthetic constraints in newer models through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition.\n  Disclaimer: This work includes visual and textual content that reflects stereotypical associations between physical appearance and socially constructed attributes, including gender, race, and traits associated with social desirability. Any such associations found in this study emerge from the biases embedded in generative AI systems-not from empirical truths or the authors' views.", "AI": {"tldr": "研究表明，文本到图像（T2I）生成AI在面部吸引力与正面/负面属性之间存在系统性关联，模仿社会偏见，并对性别分类任务产生负面影响，特别是女性面孔的误分类率更高，且新模型通过年龄、性别和地域同质化加剧了审美约束。", "motivation": "研究动机是揭示文本到图像（T2I）生成AI和下游性别分类任务中存在的算法外貌歧视（algorithmic lookism），即基于外貌的系统性偏好待遇。", "method": "通过分析Stable Diffusion 2.1和3.5 Medium生成的26,400张合成人脸，评估T2I模型中外貌吸引力与正面/负面属性的关联，并检测三个性别分类算法在处理不同属性输入人脸时的性别偏见。", "result": "研究发现，T2I模型系统性地将面部吸引力与正面属性关联，吸引力较低的面孔与负面属性关联。在性别分类任务中，女性面孔（尤其是带有负面属性的）的误分类率显著高于男性面孔。此外，新模型通过年龄同质化、性别曝光模式和地域缩减主义，加剧了审美约束。", "conclusion": "算法外貌歧视已成为AI视觉系统中的基础设施，通过模型中的表征和识别机制，加剧了现有的不平等。"}}
{"id": "2601.11758", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11758", "abs": "https://arxiv.org/abs/2601.11758", "authors": ["Arnab Das Utsa"], "title": "Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation", "comment": "9 figures, more than 1o pages", "summary": "Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, we trained a logistic regression classifier on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.", "AI": {"tldr": "该研究提出了一种基于社交媒体语言、可解释且鲁棒的焦虑症检测方法，并使用Reddit数据和临床访谈数据进行了验证，结果表明该方法能够实现可靠、泛化性强的早期焦虑症筛查。", "motivation": "全球数亿人受焦虑症影响，但大规模筛查受限。社交媒体语言提供了可扩展检测的机会，但现有模型缺乏可解释性、关键词鲁棒性验证以及严格的用户数据完整性。", "method": "研究人员使用Reddit帖子数据集，在精心策划的子版块上训练逻辑回归分类器。通过特征消融、关键词遮蔽实验、不同密度差异分析以及使用临床访谈数据进行的跨域验证来评估模型。", "result": "该模型在保持高准确率的同时取得了强大的性能，即使在去除情感或关键词遮蔽后也是如此。使用少量帖子历史进行早期检测显著优于随机分类。跨域分析与临床访谈数据高度一致。", "conclusion": "透明的语言特征可以支持可靠、泛化性强且关键词鲁棒的焦虑症检测。该框架为跨不同在线环境的可解释心理健康筛查提供了一个可复现的基线。"}}
{"id": "2601.12428", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12428", "abs": "https://arxiv.org/abs/2601.12428", "authors": ["Baorui Peng", "Wenyao Zhang", "Liang Xu", "Zekun Qi", "Jiazhao Zhang", "Hongsi Liu", "Wenjun Zeng", "Xin Jin"], "title": "ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models", "comment": null, "summary": "Recently, video-based world models that learn to simulate the dynamics have gained increasing attention in robot learning. However, current approaches primarily emphasize visual generative quality while overlooking physical fidelity, dynamic consistency, and task logic, especially for contact-rich manipulation tasks, which limits their applicability to downstream tasks. To this end, we introduce ReWorld, a framework aimed to employ reinforcement learning to align the video-based embodied world models with physical realism, task completion capability, embodiment plausibility and visual quality. Specifically, we first construct a large-scale (~235K) video preference dataset and employ it to train a hierarchical reward model designed to capture multi-dimensional reward consistent with human preferences. We further propose a practical alignment algorithm that post-trains flow-based world models using this reward through a computationally efficient PPO-style algorithm. Comprehensive experiments and theoretical analysis demonstrate that ReWorld significantly improves the physical fidelity, logical coherence, embodiment and visual quality of generated rollouts, outperforming previous methods.", "AI": {"tldr": "ReWorld 是一个框架，通过强化学习使基于视频的具身世界模型与物理真实性、任务完成能力、具身合理性和视觉质量对齐，解决了现有方法忽视物理保真度和动态一致性的问题。", "motivation": "现有基于视频的世界模型主要关注生成质量，忽略了物理保真度、动态一致性和任务逻辑，特别是在接触丰富的操作任务中，这限制了它们在下游任务中的应用。", "method": "构建了一个大规模（~235K）视频偏好数据集，用于训练一个分层奖励模型，以捕捉与人类偏好一致的多维度奖励。然后，提出了一种实际的对齐算法，使用该奖励模型通过计算效率高的 PPO 风格算法对基于流的世界模型进行后训练。", "result": "ReWorld 显著提高了生成样本的物理保真度、逻辑连贯性、具身性和视觉质量，在各项指标上均优于现有方法。", "conclusion": "ReWorld 框架成功地通过强化学习将基于视频的具身世界模型与物理真实性、任务完成能力、具身合理性和视觉质量对齐，显著提升了模型性能，克服了现有方法的局限性。"}}
{"id": "2601.13987", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13987", "abs": "https://arxiv.org/abs/2601.13987", "authors": ["Jiangwei Xie", "Zhang Wen", "Mike Davies", "Dongdong Chen"], "title": "SHARE: A Fully Unsupervised Framework for Single Hyperspectral Image Restoration", "comment": "Technical report", "summary": "Hyperspectral image (HSI) restoration is a fundamental challenge in computational imaging and computer vision. It involves ill-posed inverse problems, such as inpainting and super-resolution. Although deep learning methods have transformed the field through data-driven learning, their effectiveness hinges on access to meticulously curated ground-truth datasets. This fundamentally restricts their applicability in real-world scenarios where such data is unavailable. This paper presents SHARE (Single Hyperspectral Image Restoration with Equivariance), a fully unsupervised framework that unifies geometric equivariance principles with low-rank spectral modelling to eliminate the need for ground truth. SHARE's core concept is to exploit the intrinsic invariance of hyperspectral structures under differentiable geometric transformations (e.g. rotations and scaling) to derive self-supervision signals through equivariance consistency constraints. Our novel Dynamic Adaptive Spectral Attention (DASA) module further enhances this paradigm shift by explicitly encoding the global low-rank property of HSI and adaptively refining local spectral-spatial correlations through learnable attention mechanisms. Extensive experiments on HSI inpainting and super-resolution tasks demonstrate the effectiveness of SHARE. Our method outperforms many state-of-the-art unsupervised approaches and achieves performance comparable to that of supervised methods. We hope that our approach will shed new light on HSI restoration and broader scientific imaging scenarios. The code will be released at https://github.com/xuwayyy/SHARE.", "AI": {"tldr": "本文提出了一种名为SHARE的完全无监督框架，通过结合几何等变性和低秩光谱建模，解决了高光谱图像（HSI）修复中的数据依赖问题，并在修复和超分辨率任务中取得了与监督方法相当的性能。", "motivation": "现有深度学习方法在HSI修复中需要大量的标注数据集，这在实际应用中难以获得。本文旨在开发一种无需真实数据即可进行HSI修复的方法。", "method": "SHARE框架利用HSI结构在可微分几何变换下的内在不变性，通过等变性一致性约束生成自监督信号。它还引入了动态自适应光谱注意力（DASA）模块，以显式编码HSI的全局低秩特性，并通过可学习的注意力机制自适应地精炼局部光谱-空间相关性。", "result": "在HSI修复和超分辨率任务的广泛实验表明，SHARE方法优于许多最先进的无监督方法，并且在性能上可与监督方法相媲美。", "conclusion": "SHARE提供了一种完全无监督的HSI修复方法，通过几何等变性和低秩光谱建模，消除了对真实数据的需求，并在实际应用中展现出强大的潜力，有望推动HSI修复和更广泛科学成像领域的发展。"}}
{"id": "2601.11778", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11778", "abs": "https://arxiv.org/abs/2601.11778", "authors": ["Sheriff Issaka", "Erick Rosas Gonzalez", "Lieqi Liu", "Evans Kofi Agyei", "Lucas Bandarkar", "Nanyun Peng", "David Ifeoluwa Adelani", "Francisco Guzmán", "Saadia Gabriel"], "title": "Translation as a Scalable Proxy for Multilingual Evaluation", "comment": null, "summary": "The rapid proliferation of LLMs has created a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving >98% of the world's 7,000 languages in an empirical void. Traditional benchmark construction faces scaling challenges such as cost, scarcity of domain experts, and data contamination. We evaluate the validity of a simpler alternative: can translation quality alone indicate a model's broader multilingual capabilities? Through systematic evaluation of 14 models (1B-72B parameters) across 9 diverse benchmarks and 7 translation metrics, we find that translation performance is a good indicator of downstream task success (e.g., Phi-4, median Pearson r: MetricX = 0.89, xCOMET = 0.91, SSA-COMET = 0.87). These results suggest that the representational abilities supporting faithful translation overlap with those required for multilingual understanding. Translation quality, thus emerges as a strong, inexpensive first-pass proxy of multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks.", "AI": {"tldr": "研究表明，机器翻译质量可以作为评估大型语言模型（LLMs）多语言能力的一个有效且成本低廉的初步指标，从而填补大多数语言的评估空白。", "motivation": "现有的大型语言模型（LLMs）多语言能力评估存在悖论：虽然模型声称支持多语言，但缺乏非机器翻译的基准测试，导致绝大多数语言的评估处于空白状态。传统基准测试的构建成本高昂且难以规模化。", "method": "通过评估14个不同规模（1B-72B参数）的模型，在9个基准测试和7个翻译指标上，系统性地检验了仅通过翻译质量来评估模型多语言能力的有效性。", "result": "研究发现，机器翻译的性能与模型在下游任务上的表现（如Phi-4）高度相关（中位数皮尔逊相关系数：MetricX = 0.89，xCOMET = 0.91，SSA-COMET = 0.87）。", "conclusion": "翻译质量是衡量多语言能力的一个有力且廉价的初步代理指标，能够作为一种“先翻译后细查”的评估策略，有效筛选模型的多语言能力，并为特定任务进行有针对性的后续评估。"}}
{"id": "2601.12689", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12689", "abs": "https://arxiv.org/abs/2601.12689", "authors": ["Manobendu Sarker", "Soumaya Cherkaoui"], "title": "Priority-Based Bandwidth Allocation in Network Slicing-Enabled Cell-Free Massive MIMO Systems", "comment": "6 Pages, Accepted in IEEE ICC 2026", "summary": "This paper addresses joint admission control and per-user equipment (UE) bandwidth allocation to maximize weighted sum-rate in network slicing-enabled user-centric cell-free (CF) massive multiple-input multiple-output (mMIMO) systems when aggregate quality-of-service (QoS) demand may exceed available bandwidth. Specifically, we optimize bandwidth allocation while satisfying heterogeneous QoS requirements across enhanced mobile broadband (eMBB) and ultra-reliable low-latency communication (URLLC) slices in the uplink. The formulated problem is NP-hard, rendering global optimality computationally intractable. We decompose it into two sub-problems and solve them via computationally efficient heuristics within a sequential framework. We propose (i) a hierarchical admission control scheme that selectively admits UEs under bandwidth scarcity, prioritizing URLLC to ensure latency-sensitive QoS compliance, and (ii) an iterative gradient-based bandwidth allocation scheme that transfers bandwidth across slices guided by marginal utility and reallocates resources within slices. Simulation results demonstrate that the proposed scheme achieves near-optimal performance, deviating from a CVX-based benchmark by at most 2.2% in weighted sum-rate while reducing runtime by 99.7%, thereby enabling practical real-time deployment. Compared to a baseline round-robin scheme without admission control, the proposed approach achieves up to 1085% and 7% higher success rates for eMBB and URLLC slices, respectively, by intentionally sacrificing sum-rate to guarantee QoS. Sensitivity analysis further reveals that the proposed solution adapts effectively to diverse eMBB/URLLC traffic compositions, maintaining 47-51% eMBB and 93-94% URLLC success rates across varying load scenarios, confirming its robustness for resource-constrained large-scale deployments.", "AI": {"tldr": "提出了一种针对网络切片化用户中心蜂窝互联海量MIMO系统的联合接入控制和用户设备带宽分配算法，以最大化加权和速率，并满足异构QoS需求。该算法通过分层接入控制和迭代梯度优化带宽分配，在保证QoS的同时提高了资源利用率和成功率。", "motivation": "在网络切片化蜂窝互联海量MIMO系统中，聚合QoS需求可能超过可用带宽，需要解决如何在满足不同服务质量（QoS）要求（特别是URLLC的低延迟需求）的同时，最大化加权和速率的问题。", "method": "将NP难问题分解为两个子问题，采用分层接入控制（优先保障URLLC）和迭代梯度优化带宽分配（基于边际效用）的顺序框架来解决。", "result": "所提出的方案在加权和速率方面接近最优（与CVX基准相差不超过2.2%），同时运行时长减少了99.7%。与无接入控制的基准相比，eMBB和URLLC的成功率分别提高了1085%和7%，并能有效适应不同的业务流量组合。", "conclusion": "该方案能够有效应对带宽受限的大规模部署场景，在保证URLLC的QoS要求下，实现了接近最优的加权和速率，并且鲁棒性强，适用于实时部署。"}}
{"id": "2601.11979", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11979", "abs": "https://arxiv.org/abs/2601.11979", "authors": ["Ang Gao", "Changshuo Zhang", "Xiao Zhang", "Deyang Li", "Minjun Zhao", "Fangchao Liu", "Xinyu Zhang"], "title": "Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion", "comment": null, "summary": "In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.", "AI": {"tldr": "提出了一种名为PICL（Process In-Context Learning）的动态演示集成框架，用于增强大型语言模型在数学推理任务中的表现，通过识别和解决推理过程中的混淆点来提高准确性。", "motivation": "现有的上下文学习（ICL）方法在数学推理等需要逐步逻辑演绎的任务中效果有限，因为它们采用静态的演示示例，无法适应推理过程中出现的动态混淆点，从而导致错误累积。", "method": "PICL框架分为两个阶段：1）通过分析推理过程中的语义和熵来识别潜在的混淆点并总结其核心特征；2）在遇到这些混淆点时，从演示池中检索匹配的演示并将其插入到当前的推理过程中以指导后续步骤。", "result": "PICL通过减轻推理过程中的混淆，在数学推理任务上表现优于基线方法。", "conclusion": "PICL框架通过在推理过程中自适应地插入相关演示，有效地解决了数学推理中的混淆问题，证明了动态演示集成在复杂逻辑推理任务中的价值。"}}
{"id": "2601.11654", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11654", "abs": "https://arxiv.org/abs/2601.11654", "authors": ["Kaustubh Shivshankar Shejole", "Gaurav Mishra"], "title": "PSSI-MaxST: An Efficient Pixel-Segment Similarity Index Using Intensity and Smoothness Features for Maximum Spanning Tree Based Segmentation", "comment": null, "summary": "Interactive graph-based segmentation methods partition an image into foreground and background regions with the aid of user inputs. However, existing approaches often suffer from high computational costs, sensitivity to user interactions, and degraded performance when the foreground and background share similar color distributions. A key factor influencing segmentation performance is the similarity measure used for assigning edge weights in the graph. To address these challenges, we propose a novel Pixel Segment Similarity Index (PSSI), which leverages the harmonic mean of inter-channel similarities by incorporating both pixel intensity and spatial smoothness features. The harmonic mean effectively penalizes dissimilarities in any individual channel, enhancing robustness. The computational complexity of PSSI is $\\mathcal{O}(B)$, where $B$ denotes the number of histogram bins. Our segmentation framework begins with low-level segmentation using MeanShift, which effectively captures color, texture, and segment shape. Based on the resulting pixel segments, we construct a pixel-segment graph with edge weights determined by PSSI. For partitioning, we employ the Maximum Spanning Tree (MaxST), which captures strongly connected local neighborhoods beneficial for precise segmentation. The integration of the proposed PSSI, MeanShift, and MaxST allows our method to jointly capture color similarity, smoothness, texture, shape, and strong local connectivity. Experimental evaluations on the GrabCut and Images250 datasets demonstrate that our method consistently outperforms current graph-based interactive segmentation methods such as AMOE, OneCut, and SSNCut in terms of segmentation quality, as measured by Jaccard Index (IoU), $F_1$ score, execution time and Mean Error (ME). Code is publicly available at: https://github.com/KaustubhShejole/PSSI-MaxST.", "AI": {"tldr": "本文提出了一种新的像素片段相似性指标（PSSI），结合了像素强度和空间平滑度特征的互相关性，用于改进基于图的交互式图像分割。该方法结合了MeanShift和最大生成树（MaxST），在GrabCut和Images250数据集上表现优于现有方法。", "motivation": "现有的基于图的交互式图像分割方法存在计算成本高、对用户交互敏感以及前景背景颜色分布相似时性能下降的问题。文章旨在通过改进相似性度量来解决这些挑战。", "method": "提出了一种新的像素片段相似性指标（PSSI），它利用互相关性的调和平均数，结合了像素强度和空间平滑度特征。然后，使用MeanShift进行低级分割，并基于结果构建像素-片段图，使用PSSI计算边权重。最后，使用最大生成树（MaxST）进行分割。", "result": "提出的PSSI-MaxST方法在GrabCut和Images250数据集上，在Jaccard Index（IoU）、F1分数、执行时间和平均误差（ME）等方面，一致优于AMOE、OneCut和SSNCut等现有方法。", "conclusion": "PSSI-MaxST方法通过联合考虑颜色相似性、平滑度、纹理、形状和强局部连通性，克服了现有方法的局限性，并在交互式图像分割任务中取得了更好的性能。"}}
{"id": "2601.11739", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11739", "abs": "https://arxiv.org/abs/2601.11739", "authors": ["Xinyu Pi", "Qisen Yang", "Chuong Nguyen", "Hua Shen"], "title": "Bridging Human Interpretation and Machine Representation: A Landscape of Qualitative Data Analysis in the LLM Era", "comment": null, "summary": "LLMs are increasingly used to support qualitative research, yet existing systems produce outputs that vary widely--from trace-faithful summaries to theory-mediated explanations and system models. To make these differences explicit, we introduce a 4$\\times$4 landscape crossing four levels of meaning-making (descriptive, categorical, interpretive, theoretical) with four levels of modeling (static structure, stages/timelines, causal pathways, feedback dynamics). Applying the landscape to prior LLM-based automation highlights a strong skew toward low-level meaning and low-commitment representations, with few reliable attempts at interpretive/theoretical inference or dynamical modeling. Based on the revealed gap, we outline an agenda for applying and building LLM-systems that make their interpretive and modeling commitments explicit, selectable, and governable.", "AI": {"tldr": "本文提出一个4x4的“意义-模型”景观，用于区分和评估大型语言模型（LLMs）在质性研究中的应用。研究发现，现有LLM应用倾向于低层次的意义生成和低保真度的模型表示，在解释性和理论推断方面存在不足。文章最后提出了一个明确、可选择和可控的LLM应用与构建议程。", "motivation": "现有大型语言模型（LLMs）在质性研究中的应用产出差异巨大，从忠实于原文的摘要到理论中介的解释和系统模型。为了清晰地区分这些差异，有必要提出一个框架来评估和指导LLM在质性研究中的应用。", "method": "作者提出了一个4x4的“意义-模型”景观，该景观横跨四个意义层次（描述性、分类性、解释性、理论性）和四个模型层次（静态结构、阶段/时间线、因果路径、反馈动态）。他们将此景观应用于现有的LLM辅助质性研究工作，以分析其优势和劣势。", "result": "应用该景观分析后发现，当前LLM在质性研究中的应用严重偏向于低层次的意义生成（描述性和分类性）和低承诺度的模型表示（静态结构和阶段/时间线）。很少有研究能够可靠地进行解释性/理论性推断或动态建模。", "conclusion": "现有LLM在质性研究中的应用存在明显的研究空白，特别是在解释性和理论性推断以及动态建模方面。文章最后提出了一个议程，旨在开发和应用能够明确、可选择和可控其解释性和建模承诺的LLM系统。"}}
{"id": "2601.12694", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12694", "abs": "https://arxiv.org/abs/2601.12694", "authors": ["Manobendu Sarker", "Md. Zoheb Hassan", "Xianbin Wang"], "title": "Closed-loop Uplink Radio Resource Management in CF-O-RAN Empowered 5G Aerial Corridor", "comment": "6 Pages, Accepted in IEEE ICC 2026", "summary": "In this paper, we investigate the uplink (UL) radio resource management for 5G aerial corridors with an open-radio access network (O-RAN)-enabled cell-free (CF) massive multiple-input multiple-output (mMIMO) system. Our objective is to maximize the minimum spectral efficiency (SE) by jointly optimizing unmanned aerial vehicle (UAV)-open radio unit (O-RU) association and UL transmit power under quality-of-service (QoS) constraints. Owing to its NP-hard nature, the formulated problem is decomposed into two tractable sub-problems solved via alternating optimization (AO) using two computationally efficient algorithms. We then propose (i) a QoS-driven and multi-connectivity-enabled association algorithm incorporating UAV-centric and O-RU-centric criteria with targeted refinement for weak UAVs, and (ii) a bisection-guided fixed-point power control algorithm achieving global optimality with significantly reduced complexity, hosted as xApp at the near-real-time (near-RT) RAN intelligent controller (RIC) of O-RAN. Solving the resource-allocation problem requires global channel state information (CSI), which incurs substantial measurement and signaling overhead. To mitigate this, we leverage a channel knowledge map (CKM) within the O-RAN non-RT RIC to enable efficient environment-aware CSI inference. Simulation results show that the proposed framework achieves up to 440% improvement in minimum SE, 100% QoS satisfaction and fairness, while reducing runtime by up to 99.7% compared to an interior point solver-based power allocation solution, thereby enabling O-RAN compliant real-time deployment.", "AI": {"tldr": "该研究提出了一个基于O-RAN的无小区大规模MIMO系统，用于优化5G空中走廊的上行链路资源管理，通过联合优化UAV-O-RU关联和上行链路发射功率，以最大化最小化频谱效率，同时满足服务质量约束。研究人员还提出了用于CSI推理的信道知识图谱，并实现了高效且全局最优的算法。", "motivation": "为5G空中走廊开发高效的上行链路资源管理方案，以最大化最小化频谱效率并满足服务质量约束，特别是在O-RAN和无小区大规模MIMO的框架下。", "method": "将NP-hard问题分解为两个可解的子问题，采用交替优化（AO）方法。提出了一个多连接的服务质量驱动的关联算法，以及一个二分法引导的固定点功率控制算法。利用O-RAN非实时RIC中的信道知识图谱（CKM）进行CSI推理。", "result": "与传统的求解器相比，所提出的框架在最小频谱效率方面实现了高达440%的提升，服务质量满足度和公平性达到100%，运行时减少高达99.7%。", "conclusion": "所提出的O-RAN兼容的框架能够高效地进行资源分配，实现5G空中走廊的上行链路性能优化，支持实时部署。"}}
{"id": "2601.12463", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12463", "abs": "https://arxiv.org/abs/2601.12463", "authors": ["Zi Cong Guo", "James R. Forbes", "Timothy D. Barfoot"], "title": "KILO-EKF: Koopman-Inspired Learned Observations Extended Kalman Filter", "comment": "Submitted to RA-L. 9 pages, 9 figures, 1 table. Note: version submitted to RA-L did not include the Appendix section present in this arXiv version", "summary": "We present the Koopman-Inspired Learned Observations Extended Kalman Filter (KILO-EKF), which combines a standard EKF prediction step with a correction step based on a Koopman-inspired measurement model learned from data. By lifting measurements into a feature space where they are linear in the state, KILO-EKF enables flexible modeling of complex or poorly calibrated sensors while retaining the structure and efficiency of recursive filtering. The resulting linear-Gaussian measurement model is learned in closed form from groundtruth training data, without iterative optimization or reliance on an explicit parametric sensor model. At inference, KILO-EKF performs a standard EKF update using Jacobians obtained via the learned lifting. We validate the approach on a real-world quadrotor localization task using an IMU, ultra-wideband (UWB) sensors, and a downward-facing laser. We compare against multiple EKF baselines with varying levels of sensor calibration. KILO-EKF achieves better accuracy and consistency compared to data-calibrated baselines, and significantly outperforms EKFs that rely on imperfect geometric models, while maintaining real-time inference and fast training. These results demonstrate the effectiveness of Koopman-inspired measurement learning as a scalable alternative to traditional model-based calibration.", "AI": {"tldr": "提出了一种名为 KILO-EKF 的新型扩展卡尔曼滤波器，它利用基于数据的 Koopman 算子思想学习测量模型，从而提高了在复杂传感器校准场景下的定位精度和一致性。", "motivation": "传统的传感器校准方法依赖于精确的几何模型，而现实世界中的传感器往往存在复杂或校准不完美的情况。现有方法难以有效处理这些问题，因此需要一种更灵活、数据驱动的测量模型学习方法。", "method": "KILO-EKF 结合了标准的 EKF 预测步骤和一个基于 Koopman 算子思想的测量模型学习的校正步骤。该学习模型将测量值映射到一个特征空间，使其在状态空间中呈线性关系，并以闭式解的形式从真实标签数据中学习得到，无需迭代优化或显式的参数化传感器模型。在推理时，KILO-EKF 使用学习到的映射的雅可比矩阵执行标准的 EKF 更新。", "result": "在真实世界的四旋翼无人机定位任务中，KILO-EKF 使用 IMU、UWB 和激光传感器进行了验证。与多种不同校准水平的 EKF 基线相比，KILO-EKF 展现出更好的精度和一致性，并显著优于依赖不完美几何模型的 EKF。同时，KILO-EKF 保持了实时推理和快速训练的能力。", "conclusion": "基于 Koopman 算子思想的学习测量模型是一种可扩展的替代传统基于模型校准的方法，能够有效地处理复杂传感器校准问题，并在真实世界定位任务中取得显著的性能提升。"}}
{"id": "2601.11791", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11791", "abs": "https://arxiv.org/abs/2601.11791", "authors": ["Laya Iyer", "Pranav Somani", "Alice Guo", "Dan Jurafsky", "Chen Shani"], "title": "Beyond Tokens: Concept-Level Training Objectives for LLMs", "comment": null, "summary": "The next-token prediction (NTP) objective has been foundational in the development of modern large language models (LLMs), driving advances in fluency and generalization. However, NTP operates at the \\textit{token} level, treating deviations from a single reference continuation as errors even when alternative continuations are equally plausible or semantically equivalent (e.g., ``mom'' vs. ``mother''). As a result, token-level loss can penalize valid abstractions, paraphrases, or conceptually correct reasoning paths, biasing models toward surface form rather than underlying meaning. This mismatch between the training signal and semantic correctness motivates learning objectives that operate over higher-level representations. We propose a shift from token-level to concept-level prediction, where concepts group multiple surface forms of the same idea (e.g., ``mom,'' ``mommy,'' ``mother'' $\\rightarrow$ \\textit{MOTHER}). We introduce various methods for integrating conceptual supervision into LLM training and show that concept-aware models achieve lower perplexity, improved robustness under domain shift, and stronger performance than NTP-based models on diverse NLP benchmarks. This suggests \\textit{concept-level supervision} as an improved training signal that better aligns LLMs with human semantic abstractions.", "AI": {"tldr": "本文提出了一种从nextToken 预测（NTP）向概念级预测（concept-level prediction）的转变，以解决 NTP 仅关注词元级别而忽略语义等价性的问题。通过引入概念监督，研究表明这种新方法可以提高 LLM 的困惑度、领域转移鲁棒性和整体性能。", "motivation": "nextToken 预测（NTP）在 LLM 训练中是基础，但其仅关注词元级别，即使存在语义等价的替代词，也会将差异视为错误。这可能导致模型偏向表面形式而非深层含义，并阻碍模型学习有效的抽象和推理。", "method": "研究人员提出了一种从词元级别预测转向概念级别预测的方法，其中概念将多个表面形式归为同一想法。他们引入了将概念监督整合到 LLM 训练中的多种方法，并与传统的 NTP 方法进行了比较。", "result": "与基于 NTP 的模型相比，概念感知模型在困惑度、领域转移鲁棒性和各种 NLP 基准测试的性能方面均表现更佳。", "conclusion": "概念级监督信号比传统的词元级 NTP 信号更能有效地使 LLM 与人类的语义抽象对齐，从而提高了模型的性能和泛化能力。"}}
{"id": "2601.11660", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11660", "abs": "https://arxiv.org/abs/2601.11660", "authors": ["Chunshu Wu", "Ruibing Song", "Sushant Kondguli", "Tong Geng", "Ang Li"], "title": "Zeros can be Informative: Masked Binary U-Net for Image Segmentation on Tensor Cores", "comment": null, "summary": "Real-time image segmentation is a key enabler for AR/VR, robotics, drones, and autonomous systems, where tight accuracy, latency, and energy budgets must be met on resource-constrained edge devices. While U-Net offers a favorable balance of accuracy and efficiency compared to large transformer-based models, achieving real-time performance on high-resolution input remains challenging due to compute, memory, and power limits. Extreme quantization, particularly binary networks, is appealing for its hardware-friendly operations. However, two obstacles limit practicality: (1) severe accuracy degradation, and (2) a lack of end-to-end implementations that deliver efficiency on general-purpose GPUs.\n  We make two empirical observations that guide our design. (1) An explicit zero state is essential: training with zero masking to binary U-Net weights yields noticeable sparsity. (2) Quantization sensitivity is uniform across layers. Motivated by these findings, we introduce Masked Binary U-Net (MBU-Net), obtained through a cost-aware masking strategy that prioritizes masking where it yields the highest accuracy-per-cost, reconciling accuracy with near-binary efficiency.\n  To realize these gains in practice, we develop a GPU execution framework that maps MBU-Net to Tensor Cores via a subtractive bit-encoding scheme, efficiently implementing masked binary weights with binary activations. This design leverages native binary Tensor Core BMMA instructions, enabling high throughput and energy savings on widely available GPUs. Across 3 segmentation benchmarks, MBU-Net attains near full-precision accuracy (3% average drop) while delivering 2.04x speedup and 3.54x energy reductions over a 16-bit floating point U-Net.", "AI": {"tldr": "本文提出了一种名为 Masked Binary U-Net (MBU-Net) 的新型实时图像分割模型，它通过一种成本感知掩码策略，结合了二进制网络的效率和 U-Net 的准确性，并开发了一个 GPU 执行框架，使其在通用 GPU 上实现高效推理，性能优于 16 位浮点 U-Net。", "motivation": "在 AR/VR、机器人等资源受限的边缘设备上实现实时图像分割，需要兼顾准确性、低延迟和低功耗。虽然 U-Net 在效率和准确性上优于大型 Transformer 模型，但在高分辨率输入下实现实时性能仍具挑战。极度量化（特别是二值网络）因其硬件友好性而有吸引力，但准确性下降和缺乏高效的端到端实现阻碍了其实用性。", "method": "研究者基于两个观察（显式零状态训练和量化敏感性均匀分布）设计了 Masked Binary U-Net (MBU-Net)。MBU-Net 采用成本感知掩码策略，优先在能带来最高准确率/成本效益的层进行掩码，以平衡准确率和接近二值网络的效率。此外，还开发了一个 GPU 执行框架，通过减法位编码方案将 MBU-Net 映射到 Tensor Core，利用原生的二值 Tensor Core BMMA 指令高效实现掩码二值权重和二值激活。", "result": "在三个分割基准测试中，MBU-Net 实现了接近全精度（平均仅下降 3%）的准确率，同时相比 16 位浮点 U-Net，实现了 2.04 倍的速度提升和 3.54 倍的能耗降低。", "conclusion": "MBU-Net 成功地将二值网络的效率与 U-Net 的准确性相结合，并通过定制的 GPU 执行框架，在通用 GPU 上实现了显著的性能和能效提升，为资源受限的边缘设备上的实时图像分割提供了一种可行的解决方案。"}}
{"id": "2601.12551", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.12551", "abs": "https://arxiv.org/abs/2601.12551", "authors": ["Tong Wu"], "title": "PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception", "comment": "4 pages, 4 figures, 3 tables. Submitted to IEICE Transactions", "summary": "We propose PISE, a physics-informed deep ghost imaging framework for low-bandwidth edge perception. By combining adjoint operator initialization with semantic guidance, PISE improves classification accuracy by 2.57% and reduces variance by 9x at 5% sampling.", "AI": {"tldr": "提出了一种名为PISE的物理信息深度幽灵成像框架，用于低带宽边缘感知，通过伴随算子初始化和语义引导，在5%采样率下将分类精度提高了2.57%，并将方差降低了9倍。", "motivation": "低带宽边缘感知任务需要一种能够有效处理有限数据且保持高精度的感知方法。", "method": "该研究提出了一种名为PISE的物理信息深度幽灵成像框架，该框架结合了伴随算子初始化和语义引导两种技术。", "result": "在5%的采样率下，PISE将幽灵成像的分类精度提高了2.57%，并将分类结果的方差降低了9倍。", "conclusion": "PISE框架能够有效地提升低带宽边缘感知任务的性能，尤其是在数据稀疏的情况下，实现了精度和稳定性的显著改善。"}}
{"id": "2601.12695", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12695", "abs": "https://arxiv.org/abs/2601.12695", "authors": ["Hiroshi Okajima", "Shun Shirahama", "Tatsunori Hayashi", "Nobutomo Matsunaga"], "title": "From Noise to Knowledge: System Identification with Systematic Polytope Construction via Cyclic Reformulation", "comment": null, "summary": "Model-based control requires accurate mathematical models to guarantee control performance and stability. However, obtaining accurate models is challenging due to process and sensor noise. This paper proposes a novel identification algorithm that derives polytopic uncertainty models by interpreting noise-induced parameter fluctuations as intrinsic uncertainty. The method applies cyclic reformulation with period N to linear time-invariant systems, yielding N parameter sets with slight variations that serve as polytope vertices. This enables systematic polytopic model construction from a single identification experiment. Simulation results demonstrate significant improvements: the proposed method achieves higher parameter estimation accuracy and reduces prediction errors by approximately half compared to conventional approaches. The vertex count N provides systematic control over the precision of uncertainty representation.", "AI": {"tldr": "本文提出了一种新的识别算法，通过将噪声引起的参数波动解释为内在不确定性，从而推导出多面体不确定性模型。该方法将周期N的循环重构应用于线性时不变系统，产生N个具有细微变化的参数集，作为多面体的顶点，从而可以从单次识别实验中系统地构建多面体模型。", "motivation": "模型预测控制需要精确的数学模型来保证控制性能和稳定性。然而，由于过程和传感器噪声的存在，获取精确模型具有挑战性。", "method": "该方法将周期N的循环重构应用于线性时不变系统，产生N个参数集，并将这些参数集解释为多面体不确定性模型的顶点，从而从单次识别实验中系统地构建多面体模型。", "result": "与传统方法相比，所提出的方法实现了更高的参数估计精度，并将预测误差减半。顶点数量N可以系统地控制不确定性表示的精度。", "conclusion": "所提出的识别算法能够有效地从噪声数据中系统地构建多面体不确定性模型，从而提高模型预测控制的性能。"}}
{"id": "2601.12479", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12479", "abs": "https://arxiv.org/abs/2601.12479", "authors": ["Miquel Kegeleirs", "Lorenzo Garattoni", "Gianpiero Francesca", "Mauro Birattari"], "title": "Language-Based Swarm Perception: Decentralized Person Re-Identification via Natural Language Descriptions", "comment": null, "summary": "We introduce a method for decentralized person re-identification in robot swarms that leverages natural language as the primary representational modality. Unlike traditional approaches that rely on opaque visual embeddings -- high-dimensional feature vectors extracted from images -- the proposed method uses human-readable language to represent observations. Each robot locally detects and describes individuals using a vision-language model (VLM), producing textual descriptions of appearance instead of feature vectors. These descriptions are compared and clustered across the swarm without centralized coordination, allowing robots to collaboratively group observations of the same individual. Each cluster is distilled into a representative description by a language model, providing an interpretable, concise summary of the swarm's collective perception. This approach enables natural-language querying, enhances transparency, and supports explainable swarm behavior. Preliminary experiments demonstrate competitive performance in identity consistency and interpretability compared to embedding-based methods, despite current limitations in text similarity and computational load. Ongoing work explores refined similarity metrics, semantic navigation, and the extension of language-based perception to environmental elements. This work prioritizes decentralized perception and communication, while active navigation remains an open direction for future study.", "AI": {"tldr": "提出一种利用自然语言进行机器人集群中分散式行人重识别的方法，机器人通过VLM生成文本描述而非视觉嵌入，实现跨机器人信息融合和聚类，最终由语言模型生成可解释的代表性描述。", "motivation": "现有行人重识别方法依赖于不透明的视觉嵌入，缺乏可解释性。研究动机是开发一种更透明、可解释且支持自然语言查询的去中心化行人重识别方法，用于机器人集群。", "method": "每个机器人使用视觉语言模型（VLM）从图像中生成对个体的文本描述。这些描述在集群内去中心化地进行比较和聚类。聚类结果由语言模型提炼成代表性描述。", "result": "在身份一致性和可解释性方面取得了与基于嵌入式方法相当的性能。目前的局限性在于文本相似度计算和计算开销。", "conclusion": "该方法能够实现自然语言查询、增强透明度和支持可解释的集群行为。未来的工作将集中于改进相似度度量、语义导航以及将语言感知扩展到环境元素。"}}
{"id": "2601.11819", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11819", "abs": "https://arxiv.org/abs/2601.11819", "authors": ["Shirlene Rose Bandela", "Sanjeev Parthasarathy", "Vaibhav Garg"], "title": "TWeddit : A Dataset of Triggering Stories Predominantly Shared by Women on Reddit", "comment": "11 pages, 12 figures, 7 tables", "summary": "Warning: This paper may contain examples and topics that may be disturbing to some readers, especially survivors of miscarriage and sexual violence. People affected by abortion, miscarriage, or sexual violence often share their experiences on social media to express emotions and seek support. On public platforms like Reddit, where users can post long, detailed narratives (up to 40,000 characters), readers may be exposed to distressing content. Although Reddit allows manual trigger warnings, many users omit them due to limited awareness or uncertainty about which categories apply. There is scarcity of datasets on Reddit stories labeled for triggering experiences. We propose a curated Reddit dataset, TWeddit, covering triggering experiences related to issues majorly faced by women. Our linguistic analyses show that annotated stories in TWeddit express distinct topics and moral foundations, making the dataset useful for a wide range of future research.", "AI": {"tldr": "本研究提出了一个名为TWeddit的新Reddit数据集，包含与女性经历相关的触发性内容，旨在促进对这些敏感叙事的语言分析研究。", "motivation": "许多受堕胎、流产或性暴力影响的人在社交媒体上分享经历，这些经历可能包含令人不安的内容。Reddit上的手动触发警告意识不足，导致用户可能暴露于未标记的触发性叙事。因此，需要一个专门的数据集来支持相关研究。", "method": "研究人员创建了一个名为TWeddit的精选Reddit数据集，其中包含与女性经历相关的触发性内容。通过语言分析来验证数据集的有效性，并展示其在不同研究中的潜在应用。", "result": "对TWeddit数据集中标注故事的语言分析表明，这些故事表达了不同的主题和道德基础，表明该数据集能够捕捉到叙事中的细微差别。", "conclusion": "TWeddit数据集为研究人员提供了一个宝贵的资源，可以用来分析和理解在社交媒体上分享的关于触发性经历（尤其与女性经历相关）的叙事，从而促进对这些敏感话题的深入研究。"}}
{"id": "2601.12002", "categories": ["cs.AI", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12002", "abs": "https://arxiv.org/abs/2601.12002", "authors": ["Oliver Schön", "Zhengang Zhong", "Sadegh Soudjani"], "title": "Kernel-Based Learning of Safety Barriers", "comment": "44 pages, 9 figures", "summary": "The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about the ability to meet stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. In this paper, we present a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. We employ the concept of control barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a set of system trajectories. We use conditional mean embeddings to embed data from the system into a reproducing kernel Hilbert space (RKHS) and construct an RKHS ambiguity set that can be inflated to robustify the result to out-of-distribution behavior. We provide the theoretical results on how to apply the approach to general classes of temporal logic specifications beyond safety. For the data-driven computation of safety barriers, we leverage a finite Fourier expansion to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier allows us to leverage the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. Our work moves beyond restrictive assumptions on system dynamics and uncertainty, as demonstrated on two case studies including a black-box system with a neural network controller.", "AI": {"tldr": "提出了一种数据驱动的方法，用于对具有离散时间随机动力学的黑盒系统进行安全验证和合成，通过从系统轨迹中学习控制屏障证书，并利用条件均值嵌入和RKHS模糊集来应对分布外行为，最终通过有限傅里叶展开将优化问题转化为线性规划，实现可扩展且分布鲁棒的安全验证。", "motivation": "随着AI算法在自动驾驶和医疗保健等安全关键应用中的广泛应用，如何满足严格的安全标准成为一个重大挑战。传统的形式化安全验证工具难以处理AI系统的黑盒特性，且缺乏处理真实世界复杂性的灵活性。", "method": "该研究提出了一种数据驱动的方法，利用控制屏障证书（Control Barrier Certificates）来保证系统的安全性。通过条件均值嵌入（Conditional Mean Embeddings）将系统数据嵌入到再生核希尔伯特空间（RKHS）中，并构建RKHS模糊集（RKHS ambiguity set）以增强对分布外行为的鲁棒性。为了计算安全屏障，利用有限傅里叶展开（finite Fourier expansion）将半无限优化问题转化为线性规划，并通过快速傅里叶变换（FFT）高效求解。", "result": "该方法能够对具有离散时间随机动力学的黑盒系统进行安全验证和合成。提出的谱屏障（spectral barrier）方法能够有效处理分布外行为，并支持超越简单安全规范的更一般时序逻辑规范。在包含神经网络控制器作为黑盒系统的案例研究中，证明了该方法的有效性和可扩展性。", "conclusion": "该研究提出了一种新颖的数据驱动方法，克服了传统安全验证方法的局限性，能够为复杂的黑盒AI系统提供可扩展、分布鲁棒且理论上支持更广泛规范的安全验证。该方法摆脱了对系统动力学和不确定性的严格假设，为AI系统的安全部署提供了新的途径。"}}
{"id": "2601.12014", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12014", "abs": "https://arxiv.org/abs/2601.12014", "authors": ["Elio Masciari", "Vincenzo Moscato", "Enea Vincenzo Napolitano", "Gian Marco Orlando", "Marco Perillo", "Diego Russo"], "title": "Are LLMs Ready for TOON? Benchmarking Structural Correctness-Sustainability Trade-offs in Novel Structured Output Formats", "comment": null, "summary": "Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. In this paper, we argue that structured output formats should be assessed not only in terms of correctness, but also with respect to their environmental efficiency. To this end, we introduce a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. Within this framework, we propose the Environment-Aware Generation Correctness Score (GCS_env), a unified metric that integrates structural correctness with carbon-aware efficiency. Using this framework, we systematically benchmark the novel TOON format against established representations (JSON, XML, YAML) across multiple LLMs spanning different architectures and parameter scales.\n  Our results reveal a consistent trade-off: TOON yields markedly more compact outputs and lower emissions, but lower structural correctness when models lack native support. We show that increased model capacity reduces this gap and that environment-aware scoring can shift format rankings depending on deployment priorities. highlighting the need for sustainability-inclusive benchmarking and provides empirical evidence that compact representations such as TOON can offer practical advantages in large-scale, carbon-conscious LLM deployments.", "AI": {"tldr": "本研究提出了一种考虑环境影响的结构化文本生成评估框架，并引入了GCS_env指标，以平衡结构正确性和碳排放效率。研究发现，TOON格式在生成效率和碳排放方面优于JSON、XML和YAML，尤其是在模型能力增强时，但其结构正确性可能较低。", "motivation": "现有对LLM结构化输出的评估主要关注正确性，忽略了环境影响。作者认为，结构化输出格式的评估应同时考虑正确性和环境效率。", "method": "提出了一种可持续性评估框架，该框架测量token使用量、生成时间和估计的碳排放。在此框架下，引入了环境感知生成正确性得分（GCS_env），该指标整合了结构正确性和碳感知效率。使用该框架，在多个LLMs上对TOON格式与JSON、XML、YAML进行了基准测试。", "result": "TOON格式生成更紧凑的输出和更低的排放，但当模型缺乏原生支持时，结构正确性较低。模型容量的增加缩小了这种差距。环境感知评分可以根据部署优先级改变格式排名。", "conclusion": "需要纳入可持续性的基准测试，并且TOON等紧凑表示可以在大规模、注重碳排放的LLM部署中提供实际优势，强调了在LLM评估中同时考虑环境影响的重要性。"}}
{"id": "2601.12683", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.12683", "abs": "https://arxiv.org/abs/2601.12683", "authors": ["Liwei Liao", "Ronggang Wang"], "title": "GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation", "comment": null, "summary": "With the widespread application of 3D Gaussians in 3D scene representation, 3D scene segmentation methods based on 3D Gaussians have also gradually emerged. However, existing 3D Gaussian segmentation methods basically segment on the basis of Gaussian primitives. Due to the large variation range of the scale of 3D Gaussians, large-sized Gaussians that often span the foreground and background lead to jagged boundaries of segmented objects. To this end, we propose an online boundary trimming method, GaussianTrimmer, which is an efficient and plug-and-play post-processing method capable of trimming coarse boundaries for existing 3D Gaussian segmentation methods. Our method consists of two core steps: 1. Generating uniformly and well-covered virtual cameras; 2. Trimming Gaussian at the primitive level based on 2D segmentation results on virtual cameras. Extensive quantitative and qualitative experiments demonstrate that our method can improve the segmentation quality of existing 3D Gaussian segmentation methods as a plug-and-play method.", "AI": {"tldr": "本文提出了一种名为GaussianTrimmer的在线边界修剪方法，用于改善基于3D高斯点云的3D场景分割的边界粗糙问题。该方法通过生成虚拟相机并利用2D分割结果在原始高斯点云层面进行修剪，能够作为即插即用模块提升现有3D高斯分割方法的性能。", "motivation": "现有的基于3D高斯点云的场景分割方法在处理大尺度高斯点云时，容易导致前景和背景混合，从而产生分割边界粗糙的问题。", "method": "本文提出GaussianTrimmer方法，包含两个核心步骤：1. 生成均匀且覆盖良好的虚拟相机。2. 基于虚拟相机上的2D分割结果，在原始高斯点云层面进行边界修剪。", "result": "通过广泛的定量和定性实验验证，GaussianTrimmer作为一种即插即用方法，能够有效提升现有3D高斯分割方法的分割质量。", "conclusion": "GaussianTrimmer是一种高效且即插即用的后处理方法，能够有效地修剪3D高斯分割中粗糙的边界，并提高分割精度。"}}
{"id": "2601.11662", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11662", "abs": "https://arxiv.org/abs/2601.11662", "authors": ["Abdullah Jirjees", "Ryan Myers", "Muhammad Haris Ikram", "Mohamed H. Zaki"], "title": "LTV-YOLO: A Lightweight Thermal Object Detector for Young Pedestrians in Adverse Conditions", "comment": null, "summary": "Detecting vulnerable road users (VRUs), particularly children and adolescents, in low light and adverse weather conditions remains a critical challenge in computer vision, surveillance, and autonomous vehicle systems. This paper presents a purpose-built lightweight object detection model designed to identify young pedestrians in various environmental scenarios. To address these challenges, our approach leverages thermal imaging from long-wave infrared (LWIR) cameras, which enhances detection reliability in conditions where traditional RGB cameras operating in the visible spectrum fail. Based on the YOLO11 architecture and customized for thermal detection, our model, termed LTV-YOLO (Lightweight Thermal Vision YOLO), is optimized for computational efficiency, accuracy and real-time performance on edge devices. By integrating separable convolutions in depth and a feature pyramid network (FPN), LTV-YOLO achieves strong performance in detecting small-scale, partially occluded, and thermally distinct VRUs while maintaining a compact architecture. This work contributes a practical and scalable solution to improve pedestrian safety in intelligent transportation systems, particularly in school zones, autonomous navigation, and smart city infrastructure. Unlike prior thermal detectors, our contribution is task-specific: a thermally only edge-capable design designed for young and small VRUs (children and distant adults). Although FPN and depthwise separable convolutions are standard components, their integration into a thermal-only pipeline optimized for short/occluded VRUs under adverse conditions is, to the best of our knowledge, novel.", "AI": {"tldr": "本文提出了一种轻量级的、基于YOLOv11的 térmico 视觉模型LTV-YOLO，专门用于在低光照和恶劣天气条件下检测儿童和青少年等弱势道路使用者（VRUs）。该模型利用长波红外（LWIR）热成像，并集成了可分离卷积和特征金字塔网络（FPN），以实现高效、高精度和实时边缘计算的性能。", "motivation": "在低光照和恶劣天气条件下检测弱势道路使用者（VRUs），特别是儿童和青少年，对于计算机视觉、监控和自动驾驶系统来说仍然是一个严峻的挑战，传统RGB摄像头在此类环境下性能受限。", "method": "本文提出了一种名为LTV-YOLO（Lightweight Thermal Vision YOLO）的模型。该模型基于YOLOv11架构，并针对热成像检测进行了定制。它利用长波红外（LWIR）摄像头，并集成了深度可分离卷积（depthwise separable convolutions）和特征金字塔网络（FPN），以提高计算效率、准确性和实时性能，特别适用于边缘设备。", "result": "LTV-YOLO在检测小型、部分遮挡以及具有热信号的VRUs方面表现出强大的性能，同时保持了紧凑的模型架构。该模型在不利条件下对短距离/被遮挡的VRUs实现了高效、高精度的检测。", "conclusion": "LTV-YOLO为提高智能交通系统中行人安全提供了一个实用且可扩展的解决方案，尤其适用于学校区域、自动导航和智慧城市基础设施。该研究的创新之处在于其专为不利条件下的年轻和小型VRUs设计的、仅基于热成像的、具备边缘计算能力的模型。"}}
{"id": "2601.12523", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12523", "abs": "https://arxiv.org/abs/2601.12523", "authors": ["Cem Suulker", "Muhie Al Haimus", "Thomas Mack", "Mohammad Sheikhsofla", "Neri Niccolò Dei", "Reza Kashef", "Hadi Sadati", "Federica Barontini", "Fanny Ficuciello", "Alberto Arezzo", "Bruno Siciliano", "Sebastien Ourselin", "Kaspar Althoefer"], "title": "Enabling High-Curvature Navigation in Eversion Robots through Buckle-Inducing Constrictive Bands", "comment": null, "summary": "Tip-growing eversion robots are renowned for their ability to access remote spaces through narrow passages. However, achieving reliable navigation remains a significant challenge. Existing solutions often rely on artificial muscles integrated into the robot body or active tip-steering mechanisms. While effective, these additions introduce structural complexity and compromise the defining advantages of eversion robots: their inherent softness and compliance. In this paper, we propose a passive approach to reduce bending stiffness by purposefully introducing buckling points along the robot's outer wall. We achieve this by integrating inextensible diameter-reducing circumferential bands at regular intervals along the robot body facilitating forward motion through tortuous, obstacle cluttered paths. Rather than relying on active steering, our approach leverages the robot's natural interaction with the environment, allowing for smooth, compliant navigation. We present a Cosserat rod-based mathematical model to quantify this behavior, capturing the local stiffness reductions caused by the constricting bands and their impact on global bending mechanics. Experimental results demonstrate that these bands reduce the robot's stiffness when bent at the tip by up to 91 percent, enabling consistent traversal of 180 degree bends with a bending radius of as low as 25 mm-notably lower than the 35 mm achievable by standard eversion robots under identical conditions. The feasibility of the proposed method is further demonstrated through a case study in a colon phantom. By significantly improving maneuverability without sacrificing softness or increasing mechanical complexity, this approach expands the applicability of eversion robots in highly curved pathways, whether in relation to pipe inspection or medical procedures such as colonoscopy.", "AI": {"tldr": "通过在外壁引入环形带，降低了外翻机器人的弯曲刚度，使其在狭窄弯曲环境中具有更好的导航能力。", "motivation": "现有外翻机器人导航能力不足，且增加的结构复杂性会削弱其柔软性和顺应性优势。", "method": "在机器人外壁上周期性集成不可伸长的、减小直径的环形带，通过局部刚度降低实现被动弯曲。", "result": "环形带可使机器人尖端弯曲刚度降低高达91%，在180度弯曲处最小弯曲半径可达25毫米，优于标准外翻机器人。", "conclusion": "该被动方法通过降低刚度有效提高了外翻机器人在高度弯曲环境下的可操纵性，且不牺牲柔软性或增加复杂性，扩展了其在管道检查和内窥镜检查等领域的应用。"}}
{"id": "2601.11846", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.11846", "abs": "https://arxiv.org/abs/2601.11846", "authors": ["Natalia Tomashenko", "Xiaoxiao Miao", "Pierre Champion", "Sarina Meyer", "Michele Panariello", "Xin Wang", "Nicholas Evans", "Emmanuel Vincent", "Junichi Yamagishi", "Massimiliano Todisco"], "title": "The Third VoicePrivacy Challenge: Preserving Emotional Expressiveness and Linguistic Content in Voice Anonymization", "comment": "under review", "summary": "We present results and analyses from the third VoicePrivacy Challenge held in 2024, which focuses on advancing voice anonymization technologies. The task was to develop a voice anonymization system for speech data that conceals a speaker's voice identity while preserving linguistic content and emotional state. We provide a systematic overview of the challenge framework, including detailed descriptions of the anonymization task and datasets used for both system development and evaluation. We outline the attack model and objective evaluation metrics for assessing privacy protection (concealing speaker voice identity) and utility (content and emotional state preservation). We describe six baseline anonymization systems and summarize the innovative approaches developed by challenge participants. Finally, we provide key insights and observations to guide the design of future VoicePrivacy challenges and identify promising directions for voice anonymization research.", "AI": {"tldr": "本文总结了2024年第三届VoicePrivacy挑战赛的结果和分析，该比赛旨在推动语音匿名化技术的发展，要求在隐藏说话人身份的同时保留语言内容和情感状态。", "motivation": "为了推进语音匿名化技术，解决在保护说话人身份隐私的同时保留语音内容和情感状态的挑战。", "method": "该研究系统性地概述了挑战赛的框架，详细介绍了匿名化任务、数据集、攻击模型和评估指标。同时，描述了六个基线匿名系统，并总结了参赛者提出的创新方法。", "result": "收集并分析了参赛者在语音匿名化任务中提出的各种创新方法，并提供了对隐私保护（隐藏说话人身份）和效用（内容和情感状态保留）的评估。", "conclusion": "该研究为未来VoicePrivacy挑战赛的设计提供了关键见解和观察，并指出了语音匿名化研究的有前景的方向。"}}
{"id": "2601.14240", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2601.14240", "abs": "https://arxiv.org/abs/2601.14240", "authors": ["Marc Windsheimer", "Simon Deniffel", "André Kaup"], "title": "LRC-DHVC: Towards Local Rate Control in Neural Video Compression", "comment": "5 pages, 5 figures, 1 table", "summary": "Local rate control is a key enabler to generalize image and video compression for dedicated challenges, such as video coding for machines. While traditional hybrid video coding can easily adapt the local rate-distortion trade-off by changing the local quantization parameter, no such approach is currently available for learning-based video compression. In this paper, we propose LRC-DHVC, a hierarchical video compression network, which allows continuous local rate control on a pixel level to vary the spatial quality distribution within individual video frames. This is achieved by concatenating a quality map to the input frame and applying a weighted MSE loss which matches the pixelwise trade-off factors in the quality map. During training, the model sees a variety of quality maps due to a constrained-random generation. Our model is the first neural video compression network, which can continuously and spatially adapt to varying quality constraints. Due to the wide quality and bit rate range, a single set of network parameters is sufficient. Compared to single rate point networks, which scale linearly with the number of rate points, the memory requirements for our network parameters remain constant. The code and model are available at link-updated-upon-acceptance.", "AI": {"tldr": "本文提出了一种名为LRC-DHVC的层次化学习式视频压缩网络，能够实现像素级别的局部率失真控制，从而灵活地调整视频帧内的空间质量分布，并首次实现了在不同质量和比特率约束下的连续自适应。", "motivation": "现有的基于学习的视频压缩方法缺乏对局部率失真进行精细控制的能力，难以适应如机器视觉等需要特定质量分布的场景。而传统的混合视频编码器可以通过调整量化参数来实现局部率控制，学习式压缩方法亟需类似的机制。", "method": "提出了一种层次化视频压缩网络LRC-DHVC。通过将一个质量图（quality map）与输入帧拼接，并采用加权的均方误差（weighted MSE）损失函数，来匹配质量图中像素级别的权衡因子。训练过程中，模型通过约束随机生成多种质量图，使其能够适应不同空间质量分布的需求。", "result": "LRC-DHVC是首个能够连续且空间自适应于不同质量约束的神经网络视频压缩网络。单个模型参数即可覆盖广泛的质量和比特率范围，相较于需要针对不同比特率训练多个模型的传统方法，显著降低了内存需求。", "conclusion": "LRC-DHVC成功实现了像素级别的局部率控制，使得学习式视频压缩在适应性和效率上有了显著提升，并能在单一模型下处理多样化的率失真需求，为通用型学习式视频压缩提供了新的解决方案。"}}
{"id": "2601.11665", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.11665", "abs": "https://arxiv.org/abs/2601.11665", "authors": ["Amir Farzin Nikkhah", "Dong Chen", "Bradford Campbell", "Somayeh Asadi", "Arsalan Heydarian"], "title": "UAV-Based Infrastructure Inspections: A Literature Review and Proposed Framework for AEC+FM", "comment": "Accepted for publication at the International Conference on Construction Engineering and Management (I3CE 2025)", "summary": "Unmanned Aerial Vehicles (UAVs) are transforming infrastructure inspections in the Architecture, Engineering, Construction, and Facility Management (AEC+FM) domain. By synthesizing insights from over 150 studies, this review paper highlights UAV-based methodologies for data acquisition, photogrammetric modeling, defect detection, and decision-making support. Key innovations include path optimization, thermal integration, and advanced machine learning (ML) models such as YOLO and Faster R-CNN for anomaly detection. UAVs have demonstrated value in structural health monitoring (SHM), disaster response, urban infrastructure management, energy efficiency evaluations, and cultural heritage preservation. Despite these advancements, challenges in real-time processing, multimodal data fusion, and generalizability remain. A proposed workflow framework, informed by literature and a case study, integrates RGB imagery, LiDAR, and thermal sensing with transformer-based architectures to improve accuracy and reliability in detecting structural defects, thermal anomalies, and geometric inconsistencies. The proposed framework ensures precise and actionable insights by fusing multimodal data and dynamically adapting path planning for complex environments, presented as a comprehensive step-by-step guide to address these challenges effectively. This paper concludes with future research directions emphasizing lightweight AI models, adaptive flight planning, synthetic datasets, and richer modality fusion to streamline modern infrastructure inspections.", "AI": {"tldr": "该综述文章通过分析150多篇文献，总结了无人机在基础设施检测（AEC+FM领域）中的应用，重点介绍了数据采集、三维建模、缺陷检测和决策支持等方面的技术创新（如路径优化、热成像、ML模型），并提出了一个融合多模态数据（RGB、LiDAR、热成像）和Transformer架构的工作流程框架，以提高检测精度和可靠性，最后指出了未来研究方向。", "motivation": "推动和总结无人机在建筑、工程、施工和设施管理（AEC+FM）领域基础设施检测中的应用，识别现有技术和挑战，并提出改进方案。", "method": "通过对150多篇文献进行综合分析，总结了无人机在数据采集、三维建模、缺陷检测和决策支持方面的现有方法和技术创新（包括路径优化、热成像、YOLO和Faster R-CNN等机器学习模型）。在此基础上，提出并验证了一个结合RGB影像、LiDAR和热成像的Transformer架构工作流程框架，并通过案例研究进行了评估。", "result": "无人机技术在结构健康监测、灾后响应、城市基础设施管理、能效评估和文化遗产保护等方面展现了其价值。研究提出的多模态数据融合和Transformer架构框架，在检测结构缺陷、热异常和几何不一致性方面，能够提供更精确和可操作的见解。该框架还通过动态自适应路径规划来应对复杂环境。", "conclusion": "无人机在基础设施检测领域具有巨大潜力，但仍面临实时处理、多模态数据融合和泛化性等挑战。提出的融合多模态数据和Transformer架构的工作流程框架能够有效应对这些挑战，提高检测的准确性和可靠性。未来的研究应侧重于轻量级AI模型、自适应飞行规划、合成数据集和更丰富的模态融合，以进一步优化基础设施检测流程。"}}
{"id": "2601.13565", "categories": ["cs.CV", "cs.RO", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.13565", "abs": "https://arxiv.org/abs/2601.13565", "authors": ["Yu Qin", "Shimeng Fan", "Fan Yang", "Zixuan Xue", "Zijie Mai", "Wenrui Chen", "Kailun Yang", "Zhiyong Li"], "title": "Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation", "comment": "The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP", "summary": "Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP.", "AI": {"tldr": "本文提出了一种名为 FiCoP 的开放词汇 6D 物体姿态估计框架，通过从全局匹配转向空间约束的块级对应，显著减少了背景干扰，提高了姿态估计的鲁棒性和泛化能力。", "motivation": "现有开放词汇 6D 物体姿态估计方法依赖于全局匹配策略，容易受到背景杂乱的干扰，导致姿态估计不准确。研究动机是解决这种全局匹配的局限性，提高在复杂开放世界环境下的感知能力。", "method": "FiCoP 框架包括三个主要部分：1. 物体中心解耦预处理，用于分离目标物体和环境噪声；2. 跨视角全局感知 (CPGP) 模块，融合双视角特征并进行上下文推理；3. 块相关性预测器 (PCP)，生成块级关联图作为空间滤波器，实现精细化的、抗噪声的匹配。", "result": "在 REAL275 和 Toyota-Light 数据集上的实验表明，FiCoP 相比最先进的方法，平均召回率 (Average Recall) 分别提高了 8.0% 和 6.1%。", "conclusion": "FiCoP 框架通过利用块级对应和空间约束，有效解决了开放词汇 6D 物体姿态估计中的背景干扰问题，实现了在复杂、无约束的开放世界环境中更鲁棒和泛化的机器人感知。"}}
{"id": "2601.12840", "categories": ["eess.SY", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2601.12840", "abs": "https://arxiv.org/abs/2601.12840", "authors": ["Yuji Sakamoto", "Junichi Kurihara", "Shinya Fujita", "Yuji Sato", "Toshinori Kuwahara"], "title": "Lessons Learned from Structural Design and Vibration Testing of 50-kg Microsatellites Deployed from the International Space Station", "comment": "8 pages, 17 figures, 6 tables. ISTS 33rd, February 26-March 4, 2022", "summary": "Hokkaido University and Tohoku University have been developing and operating a constellation of 50-cm-class microsatellites for Earth observation. DIWATA-1, launched in 2016, was deployed into a circular orbit at an altitude of approximately 400 km from the International Space Station (ISS). For the subsequent satellite developed in 2021, the structural design and vibration test campaign were optimized to meet a strict one-year development schedule. This paper summarizes how the structural design of the previous satellite was reviewed and updated, and how the vibration test was successfully completed in a single trial to minimize schedule and technical risks. These lessons learned provide valuable insights, as there are only a limited number of reported cases of 50-kg-class microsatellites deployed from the ISS.", "AI": {"tldr": "本文总结了北海道大学和东北大学在开发和运营地球观测微型卫星星座过程中，针对后续卫星（2021年发射）在保持结构设计和振动测试有效性的同时，优化设计以满足一年开发周期的经验。通过复习和更新之前的卫星结构设计，并成功一次性完成振动测试，极大地降低了项目进度和技术风险。", "motivation": "研究的动机是为后续从国际空间站（ISS）部署的50公斤级微型卫星在严格的开发周期内（一年）完成结构设计和振动测试，同时最小化进度和技术风险，并为未来类似项目提供参考。", "method": "通过回顾和更新之前（DIWATA-1）卫星的结构设计，并实施优化的振动测试活动，以确保一次性通过测试。", "result": "成功地在一次尝试中完成了振动测试，并优化了结构设计，以满足严格的一年开发进度要求，从而有效降低了进度和技术风险。", "conclusion": "从国际空间站部署50公斤级微型卫星的案例有限，本文总结的结构设计更新和一次性通过振动测试的经验教训，为未来类似项目提供了宝贵的参考和指导。"}}
{"id": "2601.12701", "categories": ["cs.RO", "cs.CG"], "pdf": "https://arxiv.org/pdf/2601.12701", "abs": "https://arxiv.org/abs/2601.12701", "authors": ["Yunpeng Lyu", "Chao Cao", "Ji Zhang", "Howie Choset", "Zhongqiang Ren"], "title": "RPT*: Global Planning with Probabilistic Terminals for Target Search in Complex Environments", "comment": null, "summary": "Routing problems such as Hamiltonian Path Problem (HPP), seeks a path to visit all the vertices in a graph while minimizing the path cost. This paper studies a variant, HPP with Probabilistic Terminals (HPP-PT), where each vertex has a probability representing the likelihood that the robot's path terminates there, and the objective is to minimize the expected path cost. HPP-PT arises in target object search, where a mobile robot must visit all candidate locations to find an object, and prior knowledge of the object's location is expressed as vertex probabilities. While routing problems have been studied for decades, few of them consider uncertainty as required in this work. The challenge lies not only in optimally ordering the vertices, as in standard HPP, but also in handling history dependency: the expected path cost depends on the order in which vertices were previously visited. This makes many existing methods inefficient or inapplicable. To address the challenge, we propose a search-based approach RPT* with solution optimality guarantees, which leverages dynamic programming in a new state space to bypass the history dependency and novel heuristics to speed up the computation. Building on RPT*, we design a Hierarchical Autonomous Target Search (HATS) system that combines RPT* with either Bayesian filtering for lifelong target search with noisy sensors, or autonomous exploration to find targets in unknown environments. Experiments in both simulation and real robot show that our approach can naturally balance between exploitation and exploration, thereby finding targets more quickly on average than baseline methods.", "AI": {"tldr": "本文提出了一种名为 RPT* 的搜索算法来解决具有概率终端的汉密尔顿路径问题（HPP-PT），该问题旨在最小化期望路径成本。RPT* 利用动态规划和新颖的启发式方法来处理历史依赖性并加速计算。在此基础上，设计了一个名为 HATS 的分层自主目标搜索系统，该系统结合了 RPT* 与贝叶斯滤波或自主探索，能够在模拟和真实机器人实验中比基线方法更快地找到目标。", "motivation": "现有研究中的路径规划问题（如 HPP）通常不考虑不确定性。HPP-PT 问题源于目标搜索场景，其中需要访问所有候选位置以寻找目标，而目标位置的先验知识由顶点概率表示。因此，研究如何处理不确定性并最小化期望路径成本是一个重要的研究方向。", "method": "提出了一种名为 RPT* 的搜索算法，该算法使用动态规划来定义一个新的状态空间，以绕过历史依赖性，并采用新颖的启发式方法来加速计算，从而保证了最优解。基于 RPT*，设计了一个名为 HATS 的分层自主目标搜索系统，该系统可以与贝叶斯滤波（用于具有噪声传感器的终身目标搜索）或自主探索（用于未知环境中的目标发现）相结合。", "result": "在模拟和真实机器人实验中，所提出的 HATS 系统能够有效地平衡利用（exploitation）和探索（exploration），并在寻找目标方面比基线方法平均速度更快。", "conclusion": "RPT* 算法通过创新的状态空间定义和启发式方法，能够有效地解决 HPP-PT 问题。HATS 系统通过将 RPT* 与贝叶斯滤波或自主探索相结合，实现了高效的自主目标搜索，并在实验中验证了其优越性。"}}
{"id": "2601.11666", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11666", "abs": "https://arxiv.org/abs/2601.11666", "authors": ["Muhammad Imran", "Chi Lee", "Yugyung Lee"], "title": "MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models", "comment": "12 pages, 3 figures, 1 table", "summary": "We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods, such as spatial imprecision, lack of anatomical grounding, and limited attention granularity, MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX's potential to enhance trust and transparency in radiological AI applications.", "AI": {"tldr": "MATEX是一个新颖的医学视觉-语言模型可解释性框架，它结合了多尺度注意力、文本引导的空间推理和层一致性分析，以生成精确、稳定且有临床意义的梯度归因图，在MS-CXR数据集上优于M2IB。", "motivation": "现有的医学视觉-语言模型在可解释性方面存在空间不精确、缺乏解剖学基础和注意力粒度有限等局限性，阻碍了模型的可信度和透明度。", "method": "MATEX框架结合了多层注意力展开、文本引导的空间先验和层一致性分析。通过整合这些方法，MATEX旨在生成更精确、稳定和临床上有意义的梯度归因图。", "result": "在MS-CXR数据集上的评估显示，MATEX在空间精度和与专家标注发现的一致性方面优于现有的M2IB方法。", "conclusion": "MATEX是一个有前途的框架，可以提高医学视觉-语言模型的可解释性，其在空间精度和与临床发现对齐方面的优势，使其有潜力增强放射学AI应用的信任度和透明度。"}}
{"id": "2601.12030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12030", "abs": "https://arxiv.org/abs/2601.12030", "authors": ["Yilun Yao", "Shan Huang", "Elsie Dai", "Zhewen Tan", "Zhenyu Duan", "Shousheng Jia", "Yanbing Jiang", "Tong Yang"], "title": "ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents", "comment": "15 pages, 5 figures", "summary": "Large language models are increasingly deployed as research agents for deep search and long-horizon information seeking, yet their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, we propose ARC, which is the first framework to systematically formulate context management as an active, reflection-driven process that treats context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.", "AI": {"tldr": "本文提出了ARC框架，一种主动、基于反思的上下文管理方法，用于解决大型语言模型在长期信息检索中因上下文随时间推移而退化（上下文腐烂）的问题，并在实验中取得了显著的性能提升。", "motivation": "现有的大型语言模型在长期信息检索任务中，随着交互历史的增长，性能会下降，这被称为上下文腐烂。这主要是因为模型未能维护连贯且与任务相关的内部状态。现有的上下文管理方法（如原始累积或被动总结）将上下文视为静态，导致早期错误或不当的侧重点得以延续。", "method": "ARC框架将上下文管理设计为一个主动的、基于反思的过程。它通过反思驱动的监控和修订来操作化这一理念，使得代理在检测到不一致或退化时能够主动重组其工作上下文。", "result": "在具有挑战性的长期信息检索基准测试中，ARC框架的表现始终优于被动的上下文压缩方法。具体来说，在使用 Qwen2.5-32B-Instruct 模型进行 BrowseComp-ZH 测试时，ARC 取得了高达 11% 的绝对准确率提升。", "conclusion": "ARC框架是第一个系统地将上下文管理表述为主动、基于反思的过程的框架，它将上下文视为执行过程中的动态内部推理状态，并通过反思驱动的监控和修订有效解决了大型语言模型在长期信息检索中的上下文腐烂问题，显著提高了模型性能。"}}
{"id": "2601.12851", "categories": ["eess.SY", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2601.12851", "abs": "https://arxiv.org/abs/2601.12851", "authors": ["Yuji Sakamoto", "Masaki Aoi", "Sho Suzuki", "Takumi Haga", "Shumpei Hosokawa", "Yuma Abe", "Yuya Tasaki", "Tsuyoshi Totani", "Sou Nakamura", "Masaharu Uchiumi", "Shinya Fujita"], "title": "System Analysis and Pre-Flight Evaluation of Deployable Solar Panels for 3U CubeSat HOKUSHIN-1", "comment": "8 pages, 12 figures, 3 tables. ISTS 34th, June 3-9, 2023", "summary": "This paper describes the system design methodology derived from the development and evaluation tests of deployable solar panels to be mounted on a 3U CubeSat. The study mainly includes structural analysis, thermal analysis, and a review of vibration test results. Hokkaido University is developing the 3U CubeSat HOKUSHIN-1 in collaboration with Tohoku University and Muroran Institute of Technology. Deployable solar panels are a key technology for future planned lunar exploration missions, as they enable power-intensive communication and propulsion required for orbit control. The satellite also demonstrates a newly developed compact and efficient propulsion system. The satellite has dimensions of approximately 10x10x34 cm, a mass of 3.99 kg, and will be deployed into a circular orbit at an altitude of about 400 km with an orbital inclination of 51.6 degrees from the International Space Station.", "AI": {"tldr": "本文介绍了用于3U立方星HOKUSHIN-1的可展开太阳能电池板的系统设计方法，包括结构、热和振动测试分析，该卫星将用于月球探索任务。", "motivation": "为未来的月球探索任务开发关键技术，特别是为轨道控制所需的高功率通信和推进提供能源的可展开太阳能电池板。", "method": "通过结构分析、热分析和振动测试结果审查来推导系统设计方法。", "result": "已完成了对用于3U立方星HOKUSHIN-1的可展开太阳能电池板的结构、热和振动测试分析。该卫星将具有约10x10x34厘米的尺寸，3.99千克的质量，并将从国际空间站部署到约400公里的圆形轨道。", "conclusion": "可展开太阳能电池板是未来月球探索任务的重要技术，能够满足对高功率通信和推进的需求。本文描述了该技术在HOKUSHIN-1立方星项目中的系统设计方法。"}}
{"id": "2601.13986", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.13986", "abs": "https://arxiv.org/abs/2601.13986", "authors": ["Zhang Wen", "Jiangwei Xie", "Dongdong Chen"], "title": "Equivariant Learning for Unsupervised Image Dehazing", "comment": "Technical report", "summary": "Image Dehazing (ID) aims to produce a clear image from an observation contaminated by haze. Current ID methods typically rely on carefully crafted priors or extensive haze-free ground truth, both of which are expensive or impractical to acquire, particularly in the context of scientific imaging. We propose a new unsupervised learning framework called Equivariant Image Dehazing (EID) that exploits the symmetry of image signals to restore clarity to hazy observations. By enforcing haze consistency and systematic equivariance, EID can recover clear patterns directly from raw, hazy images. Additionally, we propose an adversarial learning strategy to model unknown haze physics and facilitate EID learning. Experiments on two scientific image dehazing benchmarks (including cell microscopy and medical endoscopy) and on natural image dehazing have demonstrated that EID significantly outperforms state-of-the-art approaches. By unifying equivariant learning with modelling haze physics, we hope that EID will enable more versatile and effective haze removal in scientific imaging. Code and datasets will be published.", "AI": {"tldr": "提出了一种名为Equivariant Image Dehazing (EID) 的无监督学习框架，利用图像信号的对称性来去除科学图像中的雾霾，并在实验中取得了优于现有方法的性能。", "motivation": "现有的图像去雾方法依赖于昂贵的先验知识或大量的无雾真实图像，这在科学成像领域尤为不切实际。因此，研究人员希望开发一种更有效、更通用的去雾方法。", "method": "提出了一种名为EID的无监督学习框架，该框架通过强制执行雾度一致性和系统不变性来直接从原始雾霾图像中恢复清晰的图像。此外，还提出了一种对抗学习策略来模拟未知的雾度物理学并促进EID的学习。", "result": "EID在细胞显微镜、医学内窥镜和自然图像去雾等领域的科学图像去雾基准测试中，显著优于最先进的方法。", "conclusion": "EID通过将不变学习与雾度物理学建模相结合，有望实现更通用、更有效的科学图像去雾。研究成果将发布代码和数据集。"}}
{"id": "2601.12742", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12742", "abs": "https://arxiv.org/abs/2601.12742", "authors": ["Xuecheng Chen", "Zongzhuo Liu", "Jianfa Ma", "Bang Du", "Tiantian Zhang", "Xueqian Wang", "Boyu Zhou"], "title": "AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation", "comment": null, "summary": "Recent advances in large Vision-Language Models (VLMs) have provided rich semantic understanding that empowers drones to search for open-set objects via natural language instructions. However, prior systems struggle to integrate VLMs into practical aerial systems due to orders-of-magnitude frequency mismatch between VLM inference and real-time planning, as well as VLMs' limited 3D scene understanding. They also lack a unified mechanism to balance semantic guidance with motion efficiency in large-scale environments. To address these challenges, we present AirHunt, an aerial object navigation system that efficiently locates open-set objects with zero-shot generalization in outdoor environments by seamlessly fusing VLM semantic reasoning with continuous path planning. AirHunt features a dual-pathway asynchronous architecture that establishes a synergistic interface between VLM reasoning and path planning, enabling continuous flight with adaptive semantic guidance that evolves through motion. Moreover, we propose an active dual-task reasoning module that exploits geometric and semantic redundancy to enable selective VLM querying, and a semantic-geometric coherent planning module that dynamically reconciles semantic priorities and motion efficiency in a unified framework, enabling seamless adaptation to environmental heterogeneity. We evaluate AirHunt across diverse object navigation tasks and environments, demonstrating a higher success rate with lower navigation error and reduced flight time compared to state-of-the-art methods. Real-world experiments further validate AirHunt's practical capability in complex and challenging environments. Code and dataset will be made publicly available before publication.", "AI": {"tldr": "AirHunt是一个创新的航空目标导航系统，它有效地融合了大型视觉语言模型（VLMs）的语义理解能力和连续路径规划，以在室外环境中进行零样本（zero-shot）的开放集（open-set）目标搜索。该系统解决了VLM推理频率与实时规划不匹配以及3D场景理解不足的问题，并能在大规模环境中平衡语义引导与运动效率。", "motivation": "现有无人机通过自然语言搜索开放集目标的方法，面临VLM推理频率与实时规划的巨大差异、VLMs有限的3D场景理解能力，以及缺乏在大型环境中平衡语义引导与运动效率的统一机制。研究动机是为了开发一个能有效解决这些挑战的航空目标导航系统。", "method": "AirHunt采用双通路异步架构，实现VLM推理与路径规划的协同，支持连续飞行和动态的语义引导。它还包含一个主动双任务推理模块，利用几何和语义冗余来选择性查询VLM。此外，还有一个语义-几何一致性规划模块，能在统一框架内动态协调语义优先级和运动效率，以适应环境变化。", "result": "在各种目标导航任务和环境中进行的评估显示，AirHunt比现有最先进的方法取得了更高的成功率、更低的导航误差和更短的飞行时间。真实世界实验也验证了其在复杂环境中的实用能力。", "conclusion": "AirHunt成功地实现了大型VLM语义推理与连续路径规划的无缝融合，能够高效、泛化性地在室外环境中进行开放集目标导航。该系统在解决频率不匹配、提升3D理解和平衡搜索策略方面表现出色，并在模拟和真实世界实验中得到了验证。"}}
{"id": "2601.12024", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12024", "abs": "https://arxiv.org/abs/2601.12024", "authors": ["Kartikey Singh Bhandari", "Tanish Jain", "Archit Agrawal", "Dhruv Kumar", "Praveen Kumar", "Pratik Narang"], "title": "A Multi-Agent System for Generating Actionable Business Advice", "comment": null, "summary": "Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.", "AI": {"tldr": "本文提出了一个多智能体、基于大语言模型的框架，用于将海量用户评论转化为具体的、可操作的商业建议，该框架在多个服务领域均取得了优于基线方法的性能。", "motivation": "现有客户评论分析方法多停留在描述性任务，大语言模型生成的建议缺乏准确性和深度。研究旨在将用户评论转化为更具实践意义的商业建议。", "method": "该框架包含四个主要组件：1. 聚类以选择代表性评论；2. 生成建议；3. 迭代评估；4. 基于可行性的排序。通过语料库提炼和反馈驱动的建议优化相结合。", "result": "在三个服务领域和多个模型家族的实验表明，该框架在可操作性、特异性和非冗余性方面 consistently 优于单一模型基线。中等规模模型在性能上接近大型模型框架。", "conclusion": "该多智能体框架能够有效地将大规模评论语料转化为具体、可操作且实用的商业建议，为企业决策提供支持。"}}
{"id": "2601.11865", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11865", "abs": "https://arxiv.org/abs/2601.11865", "authors": ["Truong Nguyen", "Phi Van Dat", "Ngan Nguyen", "Linh Ngo Van", "Trung Le", "Thanh Hong Nguyen"], "title": "CTPD: Cross Tokenizer Preference Distillation", "comment": "AAAI 2026", "summary": "While knowledge distillation has seen widespread use in pre-training and instruction tuning, its application to aligning language models with human preferences remains underexplored, particularly in the more realistic cross-tokenizer setting. The incompatibility of tokenization schemes between teacher and student models has largely prevented fine-grained, white-box distillation of preference information. To address this gap, we propose Cross-Tokenizer Preference Distillation (CTPD), the first unified framework for transferring human-aligned behavior between models with heterogeneous tokenizers. CTPD introduces three key innovations: (1) Aligned Span Projection, which maps teacher and student tokens to shared character-level spans for precise supervision transfer; (2) a cross-tokenizer adaptation of Token-level Importance Sampling (TIS-DPO) for improved credit assignment; and (3) a Teacher-Anchored Reference, allowing the student to directly leverage the teacher's preferences in a DPO-style objective. Our theoretical analysis grounds CTPD in importance sampling, and experiments across multiple benchmarks confirm its effectiveness, with significant performance gains over existing methods. These results establish CTPD as a practical and general solution for preference distillation across diverse tokenization schemes, opening the door to more accessible and efficient alignment of language models.", "AI": {"tldr": "本文提出了跨分词器偏好蒸馏（CTPD）框架，首次实现了在不同分词器模型间迁移人类偏好信息，解决了现有知识蒸馏在语言模型对齐中的局限性。", "motivation": "现有的知识蒸馏方法在预训练和指令调优中应用广泛，但在将语言模型与人类偏好对齐方面，尤其是在更现实的跨分词器场景下，研究不足。分词器不兼容性阻碍了对偏好信息的细粒度、白盒蒸馏。", "method": "CTPD 框架包含三项创新：1. 对齐跨度投影（Aligned Span Projection），将教师和学生分词器中的分词映射到共享的字符级跨度；2. 改进了 Token-level Importance Sampling（TIS-DPO），用于更好的信用分配；3. 教师锚定参考（Teacher-Anchored Reference），使学生模型能够直接利用教师的偏好信息，并采用 DPO 风格的目标函数。该方法还进行了理论分析，并基于重要性采样。", "result": "在多个基准测试上的实验表明，CTPD 在性能上显著优于现有方法，证明了其在不同分词方案下进行偏好蒸馏的有效性。", "conclusion": "CTPD 是一个实用的、通用的解决方案，能够实现跨不同分词方案的语言模型偏好蒸馏，为更易于访问和更高效的语言模型对齐提供了新的途径。"}}
{"id": "2601.12782", "categories": ["eess.SY", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.12782", "abs": "https://arxiv.org/abs/2601.12782", "authors": ["Ming Li", "Fan Liu", "Yifeng Xiong", "Jie Xu", "Tao Liu"], "title": "Sensing-Limited Control of Noiseless Linear Systems Under Nonlinear Observations", "comment": "5 pages, conference", "summary": "This paper investigates the fundamental information-theoretic limits for the control and sensing of noiseless linear dynamical systems subject to a broad class of nonlinear observations. We analyze the interactions between the control and sensing components by characterizing the minimum information flow required for stability. Specifically, we derive necessary conditions for mean-square observability and stabilizability, demonstrating that the average directed information rate from the state to the observations must exceed the intrinsic expansion rate of the unstable dynamics. Furthermore, to address the challenges posed by non-Gaussian distributions inherent to nonlinear observation channels, we establish sufficient conditions by imposing regularity assumptions, specifically log-concavity, on the system's probabilistic components. We show that under these conditions, the divergence of differential entropy implies the convergence of the estimation error, thereby closing the gap between information-theoretic bounds and estimation performance. By establishing these results, we unveil the fundamental performance limits imposed by the sensing layer, extending classical data-rate constraints to the more challenging regime of nonlinear observation models.", "AI": {"tldr": "研究了线性动力学系统在非线性观测下的信息论极限，提出了保证稳定性的最小信息流要求，并给出了基于对数凹度的充分条件，将信息论界与估计性能联系起来。", "motivation": "为了理解和量化线性动力学系统在非线性观测下的控制和传感能力的基本信息论极限。", "method": "推导了均方可观测性和可稳定性的必要条件，并利用对数凹度等正则性假设，建立了估计误差收敛的充分条件。", "result": "平均有向信息速率必须超过不稳定动力学的内在增长率才能保证稳定性。在对数凹度假设下，差分熵的发散意味着估计误差的收敛。", "conclusion": "信息论分析揭示了传感层对系统性能的根本限制，并将经典数据率约束扩展到非线性观测模型。"}}
{"id": "2601.11675", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11675", "abs": "https://arxiv.org/abs/2601.11675", "authors": ["Ritik Raina", "Abe Leite", "Alexandros Graikos", "Seoyoung Ahn", "Dimitris Samaras", "Gregory J. Zelinsky"], "title": "Generating metamers of human scene understanding", "comment": null, "summary": "Human vision combines low-resolution \"gist\" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with information obtained from scene-viewing fixations to generate image metamers for what humans understand after viewing a scene. Generating images from both high and low resolution (i.e. \"foveated\") inputs constitutes a novel image-to-image synthesis problem, which we tackle by introducing a dual-stream representation of the foveated scenes consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. To evaluate the perceptual alignment of MetamerGen generated images to latent human scene representations, we conducted a same-different behavioral experiment where participants were asked for a \"same\" or \"different\" response between the generated and the original image. With that, we identify scene generations that are indeed metamers for the latent scene representations formed by the viewers. MetamerGen is a powerful tool for understanding scene understanding. Our proof-of-concept analyses uncovered specific features at multiple levels of visual processing that contributed to human judgments. While it can generate metamers even conditioned on random fixations, we find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.", "AI": {"tldr": "研究提出了一种名为MetamerGen的工具，它结合了低分辨率的场景“要点”信息和高分辨率的注视点信息，生成与人类视觉场景表征一致的图像“同质像”。", "motivation": "人类视觉系统通过结合外围的低分辨率“要点”信息和注视点的稀疏高分辨率信息来理解场景。本研究旨在生成与人类潜在场景表征对齐的图像，以深入理解场景理解机制。", "method": "MetamerGen是一个潜在扩散模型，它采用一种双流表示方法，融合了来自注视区域的详细特征和来自外围降级特征的场景上下文信息（使用DINOv2 token）。研究通过行为实验（相同/不同判断）来评估生成图像与人类理解的视觉场景的感知一致性。", "result": "MetamerGen能够生成与人类潜在场景表征一致的图像（同质像）。行为实验表明，当生成图像以观看者自身的注视区域为条件时，高层语义一致性对同质性有最强的预测作用。", "conclusion": "MetamerGen是一个理解场景理解的强大工具，证明了通过结合不同分辨率的视觉信息可以生成感知上与人类理解相似的图像。研究发现了多层次的视觉特征对人类判断的贡献，并强调了高层语义信息在匹配人类场景理解中的重要性。"}}
{"id": "2601.12038", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12038", "abs": "https://arxiv.org/abs/2601.12038", "authors": ["Beishui Liao"], "title": "Abstract Argumentation with Subargument Relations", "comment": "11 pages", "summary": "Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.", "AI": {"tldr": "本文提出了一种包含显式子论证关系（subargument relation）的抽象论证框架，以解决现有框架无法充分表示结构化论证中子论证依赖性的问题。", "motivation": "现有的抽象论证框架（如 Dung 的框架）仅通过攻击关系来刻画论证可接受性，忽略了论证的内部结构，尤其是在结构化论证中重要的子论证关系。现有的扩展（如双极论证框架）引入了支持关系，但未能捕捉子论证的非对称和构成性性质及其与攻击的关系。", "method": "本文将显式的子论证关系与攻击关系一起作为基本关系，来丰富抽象论证框架。研究了子论证关系与攻击关系之间的交互作用，并分析了它们对基本语义性质的影响。", "result": "研究表明，该框架能够为结构化信息提供一个有原则的抽象，并阐明子论证在抽象可接受性推理中的作用。子论证关系与攻击关系的交互作用对论证的可接受性产生了重要影响。", "conclusion": "引入显式子论证关系可以有效地丰富抽象论证框架，更好地捕捉结构化论证的内在特性，从而在抽象层面更准确地进行可接受性推理。"}}
{"id": "2601.12790", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12790", "abs": "https://arxiv.org/abs/2601.12790", "authors": ["Yang Zhang", "Jianming Ma", "Liyun Yan", "Zhanxiang Cao", "Yazhou Zhang", "Haoyang Li", "Yue Gao"], "title": "FocusNav: Spatial Selective Attention with Waypoint Guidance for Humanoid Local Navigation", "comment": "12 pages, 11 figures", "summary": "Robust local navigation in unstructured and dynamic environments remains a significant challenge for humanoid robots, requiring a delicate balance between long-range navigation targets and immediate motion stability. In this paper, we propose FocusNav, a spatial selective attention framework that adaptively modulates the robot's perceptual field based on navigational intent and real-time stability. FocusNav features a Waypoint-Guided Spatial Cross-Attention (WGSCA) mechanism that anchors environmental feature aggregation to a sequence of predicted collision-free waypoints, ensuring task-relevant perception along the planned trajectory. To enhance robustness in complex terrains, the Stability-Aware Selective Gating (SASG) module autonomously truncates distal information when detecting instability, compelling the policy to prioritize immediate foothold safety. Extensive experiments on the Unitree G1 humanoid robot demonstrate that FocusNav significantly improves navigation success rates in challenging scenarios, outperforming baselines in both collision avoidance and motion stability, achieving robust navigation in dynamic and complex environments.", "AI": {"tldr": "提出了一种名为FocusNav的空间选择性注意力框架，通过引导式空间交叉注意力和稳定性感知选择性门控，来改善人形机器人在非结构化和动态环境中导航的鲁棒性、碰撞避免和运动稳定性。", "motivation": "人形机器人在非结构化和动态环境中进行鲁棒的局部导航是一个重大的挑战，需要在远程导航目标和即时运动稳定性之间取得平衡。", "method": "提出FocusNav框架，包含一个Waypoint-Guided Spatial Cross-Attention (WGSCA)机制，将环境特征聚合引导到预测的无碰撞航点序列上；以及一个Stability-Aware Selective Gating (SASG)模块，在检测到不稳定性时截断远端信息，优先考虑立足点的安全性。", "result": "在Unitree G1人形机器人上进行的广泛实验表明，FocusNav显著提高了在挑战性场景下的导航成功率，在碰撞避免和运动稳定性方面优于基线方法，实现了在动态和复杂环境中的鲁棒导航。", "conclusion": "FocusNav通过自适应地调节机器人的感知范围，成功地提高了人形机器人在复杂和动态环境中的导航性能，包括成功率、碰撞避免和运动稳定性。"}}
{"id": "2601.12857", "categories": ["eess.SY", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2601.12857", "abs": "https://arxiv.org/abs/2601.12857", "authors": ["Yuji Sakamoto"], "title": "Report on Earth Observation Missions and Ground Station Management using On-Demand Satellite Operation System", "comment": "8 pages, 11 figures. ISTS 35th, July 12-18, 2025", "summary": "Since the launch of its first satellite in 2009, Tohoku University has continuously developed and operated Earth observation satellites and engineering demonstration satellites in the 50cm-class and CubeSat-class (up to 3U). The 50cm-class satellite launched into operation in 2021 enabled efficient operations through cloud-based management functions for both the satellite and ground stations, including automatic command generation. By 2022, up to eight operational satellites were simultaneously managed on a daily basis using three ground stations (Sendai, Hakodate, and Sweden). This paper presents the operational achievements to date and introduces the system that supports efficient satellite operations", "AI": {"tldr": "本文介绍了日本东北大学在地球观测和工程演示卫星方面的运营成就，重点介绍了其50cm级卫星系统如何通过云端管理和自动命令生成实现高效运营，并能同时管理多达八颗卫星。", "motivation": "展示东北大学在卫星开发和运营方面的经验和能力，并介绍其高效的卫星运营系统。", "method": "通过回顾2009年以来的卫星开发和运营历史，重点介绍2021年投入使用的50cm级卫星系统，该系统采用了云端管理和自动命令生成等功能，并描述了使用三个地面站同时管理多颗卫星的运营实践。", "result": "截至2022年，东北大学已成功实现对最多八颗运行中的卫星进行日常管理，并通过云端管理功能提高了运营效率，包括自动命令生成。", "conclusion": "东北大学已建立了一个支持高效卫星运营的系统，并在过去十多年的卫星开发和运营中取得了显著成就。"}}
{"id": "2601.11854", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.11854", "abs": "https://arxiv.org/abs/2601.11854", "authors": ["Yifei Zhang", "Hooshang Nayyeri", "Rinat Khaziev", "Emine Yilmaz", "Gokhan Tur", "Dilek Hakkani-Tür", "Hari Thadakamalla"], "title": "ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System", "comment": null, "summary": "Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting.", "AI": {"tldr": "该论文提出了ATOD，一个用于评估先进任务导向对话（TOD）系统的基准测试和合成对话生成流程，以及一个名为ATOD-Eval的评估框架。该研究旨在填补现有基准在评估LLM驱动的TOD系统的多目标协调、长期上下文维持和主动执行等方面的不足。", "motivation": "现有的TOD基准测试无法系统地评估由大型语言模型（LLMs）驱动的、具有API和工具集成能力的先进TOD系统的涌现能力，如多目标协调、长期上下文维持和主动执行。", "method": "引入ATOD基准测试和合成对话生成流水线，以生成包含多目标协调、依赖管理、记忆、适应性和主动性等特征的带注释对话。提出ATOD-Eval评估框架，将这些维度转化为细粒度指标，并支持离线和在线评估。开发了一个基于代理记忆的评估器。", "result": "ATOD-Eval能够全面评估任务完成度、代理能力和响应质量。所提出的代理记忆评估器在ATOD基准测试上，相比于现有的基于记忆和LLM的方法，在准确性和效率之间取得了更好的权衡。", "conclusion": "ATOD和ATOD-Eval为评估和推动先进的TOD系统发展提供了一个重要的资源，该框架能够更全面、更准确地衡量LLM驱动的对话代理的能力。"}}
{"id": "2601.11866", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11866", "abs": "https://arxiv.org/abs/2601.11866", "authors": ["Kie Shidara", "Preethi Prem", "Jonathan Kim", "Anna Podlasek", "Feng Liu", "Ahmed Alaa", "Danilo Bernardo"], "title": "Advances in LLM Reasoning Enable Flexibility in Clinical Problem-Solving", "comment": "10 pages, 6 figures", "summary": "Large Language Models (LLMs) have achieved high accuracy on medical question-answer (QA) benchmarks, yet their capacity for flexible clinical reasoning has been debated. Here, we asked whether advances in reasoning LLMs improve their cognitive flexibility in clinical reasoning. We assessed reasoning models from the OpenAI, Grok, Gemini, Claude, and DeepSeek families on the medicine abstraction and reasoning corpus (mARC), an adversarial medical QA benchmark which utilizes the Einstellung effect to induce inflexible overreliance on learned heuristic patterns in contexts where they become suboptimal. We found that strong reasoning models avoided Einstellung-based traps more often than weaker reasoning models, achieving human-level performance on mARC. On questions most commonly missed by physicians, the top 5 performing models answered 55% to 70% correctly with high confidence, indicating that these models may be less susceptible than humans to Einstellung effects. Our results indicate that strong reasoning models demonstrate improved flexibility in medical reasoning, achieving performance on par with humans on mARC.", "AI": {"tldr": "研究表明，先进的推理大型语言模型（LLMs）在医学问答（QA）任务中表现出更高的认知灵活性，并且比人类更不容易受到Einstellung效应的影响。", "motivation": "探索先进的推理LLMs在临床推理方面是否具有更高的认知灵活性，以及它们是否能克服Einstellung效应。", "method": "使用mARC（医学抽象和推理语料库）评估了来自OpenAI、Grok、Gemini、Claude和DeepSeek家族的推理模型。mARC是一个对抗性的医学QA基准，利用Einstellung效应来诱导不灵活的过度依赖。", "result": "强大的推理模型比较弱的模型更不容易陷入Einstellung效应的陷阱，在mARC上达到了接近人类的水平。在医生最常出错的问题上，表现最好的模型正确率在55%到70%之间，并且置信度很高，表明它们对Einstellung效应的易感性低于人类。", "conclusion": "强大的推理LLMs在医学推理方面表现出更好的灵活性，并且在mARC基准上达到了与人类相当的性能水平，甚至在某些方面可能优于人类。"}}
{"id": "2601.11679", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11679", "abs": "https://arxiv.org/abs/2601.11679", "authors": ["Richard Hartley"], "title": "Conformal Point and the Calibrated Conic", "comment": null, "summary": "This gives some information about the conformal point and the calibrating conic, and their relationship one to the other. These concepts are useful for visualizing image geometry, and lead to intuitive ways to compute geometry, such as angles and directions in an image.", "AI": {"tldr": "本文介绍了共形点和校准圆锥的概念及其相互关系，并说明它们在图像几何可视化和直观计算图像角度、方向等几何信息中的应用。", "motivation": "研究动机是为了提供一种可视化图像几何的直观方法，并为计算图像中的角度和方向等几何属性提供更直观的计算方式。", "method": "本文通过介绍共形点和校准圆锥的概念，并阐述它们之间的关系来分析图像几何。", "result": "共形点和校准圆锥的概念被证明对于可视化图像几何非常有用，并且能够引导出直观的几何计算方法。", "conclusion": "共形点和校准圆锥是理解和处理图像几何的重要概念，为图像分析提供了直观的工具。"}}
{"id": "2601.12796", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12796", "abs": "https://arxiv.org/abs/2601.12796", "authors": ["Changwei Jing", "Jai Krishna Bandi", "Jianglong Ye", "Yan Duan", "Pieter Abbeel", "Xiaolong Wang", "Sha Yi"], "title": "Contact-Aware Neural Dynamics", "comment": "8 pages", "summary": "High-fidelity physics simulation is essential for scalable robotic learning, but the sim-to-real gap persists, especially for tasks involving complex, dynamic, and discontinuous interactions like physical contacts. Explicit system identification, which tunes explicit simulator parameters, is often insufficient to align the intricate, high-dimensional, and state-dependent dynamics of the real world. To overcome this, we propose an implicit sim-to-real alignment framework that learns to directly align the simulator's dynamics with contact information. Our method treats the off-the-shelf simulator as a base prior and learns a contact-aware neural dynamics model to refine simulated states using real-world observations. We show that using tactile contact information from robotic hands can effectively model the non-smooth discontinuities inherent in contact-rich tasks, resulting in a neural dynamics model grounded by real-world data. We demonstrate that this learned forward dynamics model improves state prediction accuracy and can be effectively used to predict policy performance and refine policies trained purely in standard simulators, offering a scalable, data-driven approach to sim-to-real alignment.", "AI": {"tldr": "提出一种隐式仿真到现实对齐框架，利用触觉信息学习接触感知的神经动力学模型，以缩小仿真与现实之间的差距，提高状态预测精度，并改进仿真训练的策略。", "motivation": "现有的显式系统辨识方法难以弥合高保真物理仿真与现实世界中复杂、动态、不连续的接触交互之间的差距。", "method": "将现成的仿真器作为先验，利用真实世界的触觉接触信息，学习一个接触感知的神经动力学模型来精炼仿真状态。", "result": "所学的神经动力学模型能有效建模接触的非平滑不连续性，提高了状态预测的准确性，并能预测策略性能，从而改进了纯仿真器训练的策略。", "conclusion": "该隐式仿真到现实对齐框架是一种可扩展、数据驱动的方法，可以有效地缩小仿真与现实的差距，特别是在接触丰富的任务中。"}}
{"id": "2601.12040", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12040", "abs": "https://arxiv.org/abs/2601.12040", "authors": ["Murilo da Luz", "Bruno Brandão", "Luana Martins", "Gustavo Oliveira", "Bryan de Oliveira", "Luckeciano Melo", "Telma Soares"], "title": "Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty", "comment": null, "summary": "The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.", "AI": {"tldr": "本文提出了一种名为 PREGU 的方法，通过监控 LLM 输出的熵来识别不确定性，并在不确定性过高时触发局部搜索以改进推理过程。", "motivation": "现有的大型语言模型在多步推理，尤其是在数学和逻辑推理方面存在局限性，需要改进其推理能力。", "method": "PREGU 方法在 LLM 自回归生成过程中监控输出分布的熵。当熵超过预设阈值时，表明模型产生不确定性，此时 PREGU 会停止生成，并在潜在空间中进行局部搜索，利用 Soft Reasoning 方法来精炼推理并选择最连贯的答案。", "result": "在 LLaMA-3-8B、Mistral-7B 和 Qwen2-7B 模型以及 GSM8K、GSM-Hard、SVAMP 和 StrategyQA 四个推理基准上的实验表明，PREGU 的性能与 Soft Reasoning 相当或更优。", "conclusion": "熵可以作为触发推理过程中选择性精炼的有效信号，PREGU 方法证明了通过熵监控来指导 LLM 推理的有效性。"}}
{"id": "2601.11872", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11872", "abs": "https://arxiv.org/abs/2601.11872", "authors": ["Nguyen Tien Phat", "Ngo Vu Minh", "Linh Van Ngo", "Nguyen Thi Ngoc Diep", "Thien Huu Nguyen"], "title": "GloCTM: Cross-Lingual Topic Modeling via a Global Context Space", "comment": "AAAI 2026", "summary": "Cross-lingual topic modeling seeks to uncover coherent and semantically aligned topics across languages - a task central to multilingual understanding. Yet most existing models learn topics in disjoint, language-specific spaces and rely on alignment mechanisms (e.g., bilingual dictionaries) that often fail to capture deep cross-lingual semantics, resulting in loosely connected topic spaces. Moreover, these approaches often overlook the rich semantic signals embedded in multilingual pretrained representations, further limiting their ability to capture fine-grained alignment. We introduce GloCTM (Global Context Space for Cross-Lingual Topic Model), a novel framework that enforces cross-lingual topic alignment through a unified semantic space spanning the entire model pipeline. GloCTM constructs enriched input representations by expanding bag-of-words with cross-lingual lexical neighborhoods, and infers topic proportions using both local and global encoders, with their latent representations aligned through internal regularization. At the output level, the global topic-word distribution, defined over the combined vocabulary, structurally synchronizes topic meanings across languages. To further ground topics in deep semantic space, GloCTM incorporates a Centered Kernel Alignment (CKA) loss that aligns the latent topic space with multilingual contextual embeddings. Experiments across multiple benchmarks demonstrate that GloCTM significantly improves topic coherence and cross-lingual alignment, outperforming strong baselines.", "AI": {"tldr": " GloCTM是一个新的跨语言主题建模框架，它通过一个统一的语义空间来强制实现跨语言主题对齐，从而提高主题的连贯性和对齐性。", "motivation": "现有的跨语言主题模型在孤立的、特定语言的空间中学习主题，并依赖于可能无法捕捉深层语义的对齐机制，导致主题空间联系松散。此外，这些方法常常忽略多语言预训练表示中丰富的语义信号。", "method": "GloCTM通过以下方式强制实现跨语言主题对齐：1. 通过扩展词袋模型并引入跨语言词汇邻域来构建丰富的输入表示；2. 使用局部和全局编码器推断主题比例，并通过内部正则化对齐它们的潜在表示；3. 在输出层面，定义在联合词汇表上的全局主题-词分布，在结构上同步跨语言的主题含义；4. 引入居中核对齐（CKA）损失，将潜在主题空间与多语言上下文嵌入对齐。", "result": "GloCTM在多个基准测试中均显著提高了主题的连贯性和跨语言对齐性，性能优于现有的强有力基线模型。", "conclusion": "GloCTM通过引入一个全局上下文空间，成功地实现了跨语言主题的深度语义对齐，克服了现有方法的局限性，并在跨语言主题建模任务上取得了显著的性能提升。"}}
{"id": "2601.12885", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12885", "abs": "https://arxiv.org/abs/2601.12885", "authors": ["Shima Sadat Mousavi", "Xiao Tan", "Aaron D. Ames"], "title": "From Vertices to Convex Hulls: Certifying Set-Wise Compatibility for CBF Constraints", "comment": null, "summary": "This paper develops certificates that propagate compatibility of multiple control barrier function (CBF) constraints from sampled vertices to their convex hull. Under mild concavity and affinity assumptions, we present three sufficient feasibility conditions under which feasible inputs over the convex hull can be obtained per coordinate, with a common input, or via convex blending. We also describe the associated computational methods, based on interval intersections or an offline linear program (LP). Beyond certifying compatibility, we give conditions under which the quadratic-program (QP) safety filter is affine in the state. This enables explicit implementations via convex combinations of vertex-feasible inputs. Case studies illustrate the results.", "AI": {"tldr": "本文提出了一种传播多个控制屏障函数 (CBF) 约束兼容性的方法，从采样顶点推广到它们的凸包。研究提供了三种在特定条件下（温和的凹性和仿射性假设）确保凸包内存在可行输入的充要条件，并提出了相应的计算方法（基于区间交集或离线线性规划）。此外，研究还给出了在何种条件下二次规划 (QP) 安全滤波器能够成为状态的仿射函数，从而实现通过顶点可行输入的凸组合进行显式实现。通过案例研究验证了这些结果。", "motivation": "现有的控制屏障函数 (CBF) 方法通常难以处理多个 CBF 约束同时生效的情况，尤其是在状态空间中。当约束在采样点上兼容时，如何保证在这些采样点的凸包内也兼容，并找到可行输入，是一个关键的挑战。", "method": "文章提出了一种“证书”传播机制，将采样顶点上的 CBF 兼容性信息推广到其凸包。研究提出了三个充分可行的条件，分别针对逐坐标可行输入、公共可行输入以及通过凸组合混合的可行输入。计算方法包括基于区间交集和离线线性规划 (LP) 的方法。此外，还研究了 QP 安全滤波器成为状态仿射函数的条件，以便于显式实现。", "result": "文章给出了三种保证凸包内 CBF 约束兼容性的可行输入条件。提出了基于区间交集或离线 LP 的计算方法。发现了 QP 安全滤波器成为状态仿射函数的条件，允许通过顶点可行输入的凸组合进行显式实现。", "conclusion": "通过将采样顶点处的 CBF 兼容性信息传播到其凸包，本文提供了一种系统性的方法来处理多 CBF 约束问题。提出的可行性条件和计算方法为在更广泛的状态空间中实现安全和兼容控制提供了理论基础和实用工具。"}}
{"id": "2601.12126", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12126", "abs": "https://arxiv.org/abs/2601.12126", "authors": ["Guocun Wang", "Kenkun Liu", "Jing Lin", "Guorui Song", "Jian Li", "Xiaoguang Han"], "title": "UniMo: Unified Motion Generation and Understanding with Chain of Thought", "comment": null, "summary": "Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.", "AI": {"tldr": "UniMo 是一个新颖的框架，通过结合运动语言信息和可解释的思维链（CoT）推理，解决了现有 3D 人体运动生成和理解方法中解释性差、语义对齐和任务一致性不足的问题，并使用 GRPO 进行后训练以优化运动序列的结构和语义。", "motivation": "现有 3D 人体运动生成和理解方法的可解释性有限，阻碍了这两个相关任务之间的相互促进。基于 LLM 的统一框架虽然利用了语言先验，但在语义对齐和任务一致性方面存在挑战，并且 LLM 的 next-token prediction 范式不适合运动序列，会导致累积预测错误。", "method": "UniMo 框架通过监督微调（SFT）将运动语言信息和可解释的思维链（CoT）推理集成到 LLM 中。然后，使用基于群体相对策略优化（GRPO）的强化学习作为后训练策略，通过优化 token 组来强制执行结构正确性和语义对齐，从而减轻运动 token 预测中的累积误差。", "result": "UniMo 在运动生成和理解任务上均显著优于现有的统一模型和特定任务模型，达到了最先进的性能。", "conclusion": "UniMo 框架成功地整合了运动语言信息和可解释的 CoT 推理，并通过 GRPO 强化学习解决了 LLM 在运动序列处理中的局限性，从而在 3D 人体运动生成和理解任务上取得了 SOTA 性能。"}}
{"id": "2601.12799", "categories": ["cs.RO", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12799", "abs": "https://arxiv.org/abs/2601.12799", "authors": ["Peng Li", "Zihan Zhuang", "Yangfan Gao", "Yi Dong", "Sixian Li", "Changhao Jiang", "Shihan Dou", "Zhiheng Xi", "Enyu Zhou", "Jixuan Huang", "Hui Li", "Jingjing Gong", "Xingjun Ma", "Tao Gui", "Zuxuan Wu", "Qi Zhang", "Xuanjing Huang", "Yu-Gang Jiang", "Xipeng Qiu"], "title": "FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions", "comment": "Project Page: https://openmoss.github.io/FRoM-W1", "summary": "Humanoid robots are capable of performing various actions such as greeting, dancing and even backflipping. However, these motions are often hard-coded or specifically trained, which limits their versatility. In this work, we present FRoM-W1, an open-source framework designed to achieve general humanoid whole-body motion control using natural language. To universally understand natural language and generate corresponding motions, as well as enable various humanoid robots to stably execute these motions in the physical world under gravity, FRoM-W1 operates in two stages: (a) H-GPT: utilizing massive human data, a large-scale language-driven human whole-body motion generation model is trained to generate diverse natural behaviors. We further leverage the Chain-of-Thought technique to improve the model's generalization in instruction understanding. (b) H-ACT: After retargeting generated human whole-body motions into robot-specific actions, a motion controller that is pretrained and further fine-tuned through reinforcement learning in physical simulation enables humanoid robots to accurately and stably perform corresponding actions. It is then deployed on real robots via a modular simulation-to-reality module. We extensively evaluate FRoM-W1 on Unitree H1 and G1 robots. Results demonstrate superior performance on the HumanML3D-X benchmark for human whole-body motion generation, and our introduced reinforcement learning fine-tuning consistently improves both motion tracking accuracy and task success rates of these humanoid robots. We open-source the entire FRoM-W1 framework and hope it will advance the development of humanoid intelligence.", "AI": {"tldr": "本研究提出了FRoM-W1，一个开源框架，通过自然语言控制人形机器人实现通用的全身运动控制。", "motivation": "现有的人形机器人运动控制方法依赖于硬编码或特定训练，限制了机器人的通用性。研究旨在通过自然语言指令实现更广泛、更灵活的机器人运动。", "method": "FRoM-W1框架分为两阶段：1. H-GPT：利用海量人类数据和思维链技术训练一个大型语言驱动的人类全身运动生成模型，以生成多样化的自然行为。2. H-ACT：将生成的人类运动重定向为机器人特定动作，并使用强化学习预训练和微调的运动控制器，通过仿真到现实（Sim-to-Real）模块在真实机器人上稳定执行。", "result": "FRoM-W1在HumanML3D-X基准测试中表现出优越的人类全身运动生成性能。通过强化学习微调，显著提高了人形机器人的运动跟踪精度和任务成功率。在Unitree H1和G1机器人上进行了广泛评估。", "conclusion": "FRoM-W1是一个强大的框架，能够通过自然语言实现通用的人形机器人全身运动控制，并为人形机器人的发展和智能化提供了开源支持。"}}
{"id": "2601.11886", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11886", "abs": "https://arxiv.org/abs/2601.11886", "authors": ["Kaijie Mo", "Siddhartha Venkatayogi", "Chantal Shaib", "Ramez Kouzy", "Wei Xu", "Byron C. Wallace", "Junyi Jessy Li"], "title": "Faithfulness vs. Safety: Evaluating LLM Behavior Under Counterfactual Medical Evidence", "comment": "26 pages", "summary": "In high-stakes domains like medicine, it may be generally desirable for models to faithfully adhere to the context provided. But what happens if the context does not align with model priors or safety protocols? In this paper, we investigate how LLMs behave and reason when presented with counterfactual or even adversarial medical evidence. We first construct MedCounterFact, a counterfactual medical QA dataset that requires the models to answer clinical comparison questions (i.e., judge the efficacy of certain treatments, with evidence consisting of randomized controlled trials provided as context). In MedCounterFact, real-world medical interventions within the questions and evidence are systematically replaced with four types of counterfactual stimuli, ranging from unknown words to toxic substances. Our evaluation across multiple frontier LLMs on MedCounterFact reveals that in the presence of counterfactual evidence, existing models overwhelmingly accept such \"evidence\" at face value even when it is dangerous or implausible, and provide confident and uncaveated answers. While it may be prudent to draw a boundary between faithfulness and safety, our findings reveal that there exists no such boundary yet.", "AI": {"tldr": "当前的大型语言模型在面对与模型先验或安全协议不符的医学反事实或对抗性证据时，会过度信任这些虚假信息，并给出自信且无保留的答案，表明模型在遵循事实与保证安全之间尚无明确的界限。", "motivation": "在医学等高风险领域，期望模型忠实遵循提供的上下文。然而，当上下文与模型先验或安全协议不一致时，模型将如何表现和推理是一个亟待研究的问题。", "method": "研究者构建了一个名为 MedCounterFact 的反事实医学问答数据集，该数据集包含临床比较问题，并提供随机对照试验作为证据。通过将真实医疗干预替换为四种类型的反事实刺激（从未知词汇到有毒物质），来评估大型语言模型在面对反事实证据时的表现。", "result": "在 MedCounterFact 数据集上的评估结果表明，现有的先进大型语言模型在面对反事实证据时，绝大多数会全盘接受这些“证据”，即使它们危险或不可信，并给出自信且无保留的答案。", "conclusion": "研究发现，当前的大型语言模型在处理反事实医学证据时，未能区分事实与安全性，存在过度信任虚假信息的倾向，表明模型在忠实性和安全性之间尚需改进。"}}
{"id": "2601.11724", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11724", "abs": "https://arxiv.org/abs/2601.11724", "authors": ["Muditha Fernando", "Kajhanan Kailainathan", "Krishnakanth Nagaratnam", "Isuranga Udaravi Bandara Senavirathne", "Ranga Rodrigo"], "title": "SemAlign: Language Guided Semi-supervised Domain Generalization", "comment": "15 pages, 6 figures", "summary": "Semi-supervised Domain Generalization (SSDG) addresses the challenge of generalizing to unseen target domains with limited labeled data. Existing SSDG methods highlight the importance of achieving high pseudo-labeling (PL) accuracy and preventing model overfitting as the main challenges in SSDG. In this light, we show that the SSDG literature's excessive focus on PL accuracy, without consideration for maximum data utilization during training, limits potential performance improvements. We propose a novel approach to the SSDG problem by aligning the intermediate features of our model with the semantically rich and generalized feature space of a Vision Language Model (VLM) in a way that promotes domain-invariance. The above approach is enhanced with effective image-level augmentation and output-level regularization strategies to improve data utilization and minimize overfitting. Extensive experimentation across four benchmarks against existing SSDG baselines suggests that our method achieves SOTA results both qualitatively and quantitatively. The code will be made publicly available.", "AI": {"tldr": "提出了一种新的半监督域泛化（SSDG）方法，通过将模型中间特征与视觉语言模型（VLM）的语义丰富特征空间对齐，以促进域不变性，并结合数据增强和输出正则化策略来提高数据利用率和减少过拟合，实验证明效果优于现有基线。", "motivation": "现有的SSDG方法过于关注伪标签（PL）的准确性，而忽视了训练过程中的最大化数据利用，这限制了性能提升的潜力。", "method": "将模型的中间特征与视觉语言模型（VLM）的语义丰富、泛化的特征空间对齐，以实现域不变性。此外，结合了有效的图像级增强和输出级正则化策略。", "result": "在四个基准测试中，相比现有SSDG基线，该方法在定性和定量上均取得了最先进（SOTA）的结果。", "conclusion": "通过将模型中间特征与VLM特征空间对齐，并结合数据增强和输出正则化，可以有效提升SSDG的性能，实现更好的域泛化能力。"}}
{"id": "2601.12138", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12138", "abs": "https://arxiv.org/abs/2601.12138", "authors": ["Abhishek Kumar", "Riya Tapwal", "Carsten Maple"], "title": "DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants", "comment": null, "summary": "Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.", "AI": {"tldr": "本文提出了一种名为DriveSafe的四级风险分类法，用于系统地识别和评估车载LLM驾驶助手在驾驶场景中的安全风险，并发现现有LLM在处理与驾驶相关的危险查询时表现不佳。", "motivation": "当前用于评估LLM安全性的通用方法不足以应对车载数字助手在驾驶场景中可能出现的特定安全、伦理和法律风险，这些风险可能导致严重后果。", "method": "研究人员设计了一个分层、四级的风险分类法DriveSafe，包含129个细粒度的风险类别，涵盖技术、法律、社会和伦理维度，并基于实际驾驶法规和安全原则，由领域专家审查。随后，使用该分类法生成的提示来评估六个主流LLM在处理与驾驶相关的危险查询时的拒绝行为。", "result": "评估结果表明，所测试的LLM在面对不安全或不符合规定的驾驶相关查询时，经常未能做出适当的拒绝，显示出通用安全对齐在驾驶领域存在局限性。", "conclusion": "DriveSafe分类法能够系统地识别和评估车载LLM驾驶助手在现实驾驶场景中的领域特定风险。现有LLM在处理驾驶相关危险查询时的不足，凸显了针对特定应用场景进行LLM安全对齐的必要性。"}}
{"id": "2601.12987", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12987", "abs": "https://arxiv.org/abs/2601.12987", "authors": ["Evangelos Ntouros", "Ewoud J. J. Smeur"], "title": "Guiding vector field-based guidance under wind disturbances applied to a tailsitter UAV", "comment": null, "summary": "This paper develops a guidance control law based on a parametric Guiding Vector Field (GVF) and integrates it with a state-of-the-art acceleration and attitude control architecture for tailsitters. The resulting framework enables a direct comparison between traditional trajectory-tracking guidance and GVF-based path-following guidance using a realistic tailsitter model operating under windy conditions. Through extensive simulations, it is shown that for agile flight scenarios with wind and small initial position error, both guidance strategies achieve comparable tracking performance, indicating that the additional complexity introduced by the GVF formulation is not always justified. However, the GVF-based approach exhibits an advantage when initial deviation from the path is present, yielding smooth and well-behaved convergence toward the desired path. Two additional contributions support this evaluation. First, a modification of the parametric GVF is proposed that guarantees exponential stability of the tracking error dynamics for a single integrator system. Second, the differential flatness transform of a tailsitter vehicle is extended to account for explicit knowledge of the wind velocity vector.", "AI": {"tldr": "本文提出了一种基于参数化引导向量场（GVF）的制导律，并将其与先进的尾座式无人机姿态和加速度控制架构相结合，用于在有风条件下进行轨迹跟踪和路径跟踪的性能对比。研究表明，在风力下，GVF在初始路径偏差较大时表现出更好的收敛性，但对于小偏差和敏捷飞行场景，其性能与传统方法相当。此外，研究还提出了GVF参数修改以保证指数稳定性，并扩展了尾座式无人机的微分平坦性变换以考虑风速。", "motivation": "为了直接比较传统的轨迹跟踪制导和基于GVF的路径跟踪制导在尾座式无人机上的性能，特别是在有风等复杂环境下，并评估GVF的引入是否总是必要。", "method": "开发了一种基于参数化GVF的制导律，并将其与现有的尾座式无人机加速度和姿态控制架构集成。通过仿真，对比了两种制导策略在不同初始条件和风力条件下的性能。提出了GVF参数修改以保证单积分系统的指数稳定性。扩展了尾座式无人机的微分平坦性变换以明确考虑风速。", "result": "在有风和小初始位置误差的敏捷飞行场景下，GVF和传统轨迹跟踪策略的跟踪性能相当。当存在初始路径偏差时，GVF方法能够实现平滑且良好的路径收敛。提出的GVF修改保证了单积分系统的指数稳定性。", "conclusion": "GVF制导策略在处理较大初始路径偏差时具有优势，能够实现更平滑的路径收敛。然而，对于复杂的敏捷飞行场景，其性能优势并不总是显著，可能不如传统方法简单有效。对GVF的修改和微分平坦性变换的扩展为尾座式无人机控制提供了理论支持。"}}
{"id": "2601.12894", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12894", "abs": "https://arxiv.org/abs/2601.12894", "authors": ["Kangye Ji", "Yuan Meng", "Zhou Jianbo", "Ye Li", "Hanyun Cui", "Zhi Wang"], "title": "Sparse ActionGen: Accelerating Diffusion Policy with Real-time Pruning", "comment": null, "summary": "Diffusion Policy has dominated action generation due to its strong capabilities for modeling multi-modal action distributions, but its multi-step denoising processes make it impractical for real-time visuomotor control. Existing caching-based acceleration methods typically rely on $\\textit{static}$ schedules that fail to adapt to the $\\textit{dynamics}$ of robot-environment interactions, thereby leading to suboptimal performance. In this paper, we propose $\\underline{\\textbf{S}}$parse $\\underline{\\textbf{A}}$ction$\\underline{\\textbf{G}}$en ($\\textbf{SAG}$) for extremely sparse action generation. To accommodate the iterative interactions, SAG customizes a rollout-adaptive prune-then-reuse mechanism that first identifies prunable computations globally and then reuses cached activations to substitute them during action diffusion. To capture the rollout dynamics, SAG parameterizes an observation-conditioned diffusion pruner for environment-aware adaptation and instantiates it with a highly parameter- and inference-efficient design for real-time prediction. Furthermore, SAG introduces a one-for-all reusing strategy that reuses activations across both timesteps and blocks in a zig-zag manner, minimizing the global redundancy. Extensive experiments on multiple robotic benchmarks demonstrate that SAG achieves up to 4$\\times$ generation speedup without sacrificing performance. Project Page: https://sparse-actiongen.github.io/.", "AI": {"tldr": "本文提出了一种名为 SAG（Sparse Action Gen）的新型稀疏动作生成方法，通过自适应地剪枝和重用计算，显著加速了扩散策略在机器人视觉-动作控制中的应用，实现了高达 4 倍的速度提升且不牺牲性能。", "motivation": "现有的基于缓存的加速方法依赖于静态调度，无法适应机器人-环境交互的动态性，导致性能不佳，这使得扩散策略难以在实时视觉-动作控制中应用。", "method": "SAG 提出了一种滚动自适应的剪枝-重用机制，通过全局识别可剪枝的计算，并在动作扩散过程中重用缓存的激活来代替这些计算。它参数化了一个观察条件化的扩散剪枝器，并采用高效设计实现实时预测。此外，SAG 还引入了一种“一举多得”的重用策略，以之字形方式跨时间步和块重用激活，以最小化全局冗余。", "result": "在多个机器人基准测试中的广泛实验表明，SAG 在不牺牲性能的情况下实现了高达 4 倍的生成速度提升。", "conclusion": "SAG 是一种有效的稀疏动作生成方法，能够显著加速扩散策略在机器人控制中的应用，通过自适应剪枝和重用机制解决了现有方法的局限性，并实现了优异的性能和速度平衡。"}}
{"id": "2601.11908", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11908", "abs": "https://arxiv.org/abs/2601.11908", "authors": ["Byeongjin Kim", "Gyuwan Kim", "Seo Yeon Park"], "title": "PPA-Plan: Proactive Pitfall Avoidance for Reliable Planning in Long-Context LLM Reasoning", "comment": "23 pages, 6 figures", "summary": "Large language models (LLMs) struggle with reasoning over long contexts where relevant information is sparsely distributed. Although plan-and-execute frameworks mitigate this by decomposing tasks into planning and execution, their effectiveness is often limited by unreliable plan generation due to dependence on surface-level cues. Consequently, plans may be based on incorrect assumptions, and once a plan is formed, identifying what went wrong and revising it reliably becomes difficult, limiting the effectiveness of reactive refinement. To address this limitation, we propose PPA-Plan, a proactive planning strategy for long-context reasoning that focuses on preventing such failures before plan generation. PPA-Plan identifies potential logical pitfalls and false assumptions, formulates them as negative constraints, and conditions plan generation on explicitly avoiding these constraints. Experiments on long-context QA benchmarks show that executing plans generated by PPA-Plan consistently outperforms existing plan-and-execute methods and direct prompting.", "AI": {"tldr": "提出了一种名为 PPA-Plan 的主动规划策略，通过在生成计划前识别并规避潜在的逻辑陷阱和错误假设（作为负面约束），来改进长上下文推理能力，实验证明其优于现有方法。", "motivation": "大型语言模型在处理信息稀疏的长上下文时推理能力不足，现有的计划-执行框架容易因依赖表面线索而生成不可靠的计划，导致难以纠正错误和有效改进。", "method": "PPA-Plan 是一种主动规划策略，它在生成计划之前，识别潜在的逻辑陷阱和错误假设，并将其转化为负面约束，然后基于这些约束来生成计划，确保计划的生成过程中就避免了这些问题。", "result": "在长上下文问答基准测试中，PPA-Plan 生成的计划在执行后，其表现始终优于现有的计划-执行方法和直接提示方法。", "conclusion": "PPA-Plan 通过主动规避潜在的逻辑错误，显著提高了大型语言模型在长上下文推理任务中的性能，解决了现有方法在计划生成和纠正方面的局限性。"}}
{"id": "2601.12141", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12141", "abs": "https://arxiv.org/abs/2601.12141", "authors": ["Yuliia Suprun", "Khen Elimelech", "Lydia E. Kavraki", "Moshe Y. Vardi"], "title": "TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals", "comment": null, "summary": "Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.", "AI": {"tldr": "本文提出了一种名为TIDE的新型AI任务规划方法，用于处理具有时间延伸目标（TEGs）的规划问题。TIDE通过将复杂的时间规划问题分解为一系列可管理的“到达-避免”子问题，并利用成本驱动的启发式方法来指导搜索，克服了传统方法中启发式不足的缺点，提高了规划效率和完备性。", "motivation": "传统的LTLf任务规划方法将时间规划问题转化为经典的、具有可达性目标的规划问题，但缺乏有效的启发式方法来指导搜索，导致效率低下。", "method": "TIDE将时间规划问题分解为一系列“到达-避免”子问题，并利用成本驱动的启发式方法来优先搜索有希望的自动化迹线。它还包含一个自适应回溯机制，通过重新计算成本和惩罚不可行转移来处理失败的规划。", "result": "实验结果表明，TIDE在处理时间延伸目标的任务规划方面取得了令人鼓舞的性能。", "conclusion": "TIDE是一种有效且完整的任务规划方法，能够解决具有时间延伸目标（TEGs）的挑战，并且是现有规划方法组合的有价值补充。"}}
{"id": "2601.12901", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12901", "abs": "https://arxiv.org/abs/2601.12901", "authors": ["Hongchen Li", "Tianyu Li", "Jiazhi Yang", "Haochen Tian", "Caojun Wang", "Lei Shi", "Mingyang Shang", "Zengrong Lin", "Gaoqiang Wu", "Zhihui Hao", "Xianpeng Lang", "Jia Hu", "Hongyang Li"], "title": "PlannerRFT: Reinforcing Diffusion Planners through Closed-Loop and Sample-Efficient Fine-Tuning", "comment": null, "summary": "Diffusion-based planners have emerged as a promising approach for human-like trajectory generation in autonomous driving. Recent works incorporate reinforcement fine-tuning to enhance the robustness of diffusion planners through reward-oriented optimization in a generation-evaluation loop. However, they struggle to generate multi-modal, scenario-adaptive trajectories, hindering the exploitation efficiency of informative rewards during fine-tuning. To resolve this, we propose PlannerRFT, a sample-efficient reinforcement fine-tuning framework for diffusion-based planners. PlannerRFT adopts a dual-branch optimization that simultaneously refines the trajectory distribution and adaptively guides the denoising process toward more promising exploration, without altering the original inference pipeline. To support parallel learning at scale, we develop nuMax, an optimized simulator that achieves 10 times faster rollout compared to native nuPlan. Extensive experiments shows that PlannerRFT yields state-of-the-art performance with distinct behaviors emerging during the learning process.", "AI": {"tldr": "本文提出了一种名为 PlannerRFT 的框架，用于增强基于扩散的规划器在生成多模态、场景自适应轨迹方面的能力，通过双分支优化和高效的模拟器 nuMax 加速学习过程，并取得了最先进的性能。", "motivation": "现有的基于扩散的规划器在生成多模态、场景自适应轨迹方面存在不足，导致在强化微调过程中奖励利用效率低下。", "method": "提出 PlannerRFT 框架，采用双分支优化同时优化轨迹分布和自适应引导去噪过程，并开发了 nuMax 模拟器以加速数据生成。", "result": "PlannerRFT 实现了最先进的性能，并在学习过程中展现出独特行为。", "conclusion": "PlannerRFT 是一种样本高效的强化微调框架，能够显著提升基于扩散的规划器在生成多样化和场景自适应轨迹方面的能力。"}}
{"id": "2601.11729", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11729", "abs": "https://arxiv.org/abs/2601.11729", "authors": ["Turhan Can Kargin", "Wojciech Jasiński", "Adam Pardyl", "Bartosz Zieliński", "Marcin Przewięźlikowski"], "title": "SpaRRTa: A Synthetic Benchmark for Evaluating Spatial Intelligence in Visual Foundation Models", "comment": "Project page is available at https://sparrta.gmum.net/", "summary": "Visual Foundation Models (VFMs), such as DINO and CLIP, excel in semantic understanding of images but exhibit limited spatial reasoning capabilities, which limits their applicability to embodied systems. As a result, recent work incorporates some 3D tasks (such as depth estimation) into VFM training. However, VFM performance remains inconsistent across other spatial tasks, raising the question of whether these models truly have spatial awareness or overfit to specific 3D objectives. To address this question, we introduce the Spatial Relation Recognition Task (SpaRRTa) benchmark, which evaluates the ability of VFMs to identify relative positions of objects in the image. Unlike traditional 3D objectives that focus on precise metric prediction (e.g., surface normal estimation), SpaRRTa probes a fundamental capability underpinning more advanced forms of human-like spatial understanding. SpaRRTa generates an arbitrary number of photorealistic images with diverse scenes and fully controllable object arrangements, along with freely accessible spatial annotations. Evaluating a range of state-of-the-art VFMs, we reveal significant disparities between their spatial reasoning abilities. Through our analysis, we provide insights into the mechanisms that support or hinder spatial awareness in modern VFMs. We hope that SpaRRTa will serve as a useful tool for guiding the development of future spatially aware visual models.", "AI": {"tldr": "本研究提出了一个名为SpaRRTa的新基准测试，用于评估视觉基础模型（VFMs）的空间推理能力，并揭示了现有VFMs在空间感知方面存在显著差异，旨在促进未来空间感知视觉模型的发展。", "motivation": "现有的视觉基础模型（VFMs）在语义理解方面表现出色，但在空间推理方面能力有限，这阻碍了它们在具身系统中的应用。尽管一些研究尝试将3D任务纳入VFMs训练，但其在不同空间任务上的表现不一致，引发了关于VFMs是否真正具备空间意识还是仅仅过拟合特定3D任务的疑问。", "method": "研究引入了一个名为SpaRRTa（Spatial Relation Recognition Task）的基准测试，该测试旨在评估VFMs识别图像中物体相对位置的能力。SpaRRTa生成具有多样化场景和可控物体排列的逼真图像，并提供空间注释。研究评估了一系列最先进的VFMs在SpaRRTa上的表现。", "result": "通过 SpaRRTa 基准测试，研究发现不同最先进的VFMs在空间推理能力上存在显著差异。分析结果揭示了支持或阻碍现代VFMs空间意识的机制。", "conclusion": "VFMs在空间推理方面表现不一，SpaRRTa基准测试能够有效评估这一能力，并为理解和提升VFMs的空间意识提供见解，有望指导未来空间感知视觉模型的设计。"}}
{"id": "2601.13057", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13057", "abs": "https://arxiv.org/abs/2601.13057", "authors": ["Chao Wang", "Shuyuan Zhang", "Lei Wang"], "title": "Convex Model Predictive Control for Safe Output Consensus of Nonlinear Multi-Agent Systems", "comment": null, "summary": "Nonlinear dynamics and safety constraints typically result in a nonlinear programming problem when applying model predictive control to achieve safe output consensus. To avoid the heavy computational burden of solving a nonlinear programming problem directly, this paper proposes a novel Convex Model Predictive Control (CMPC) approach based on a Sequential Quadratic Programming (SQP) scheme. The core of our method lies in transforming the nonlinear constraints into linear forms: we linearize the system dynamics and convexify the discrete-time high-order control barrier functions using a proposed tangent-line projection method. Consequently, the original problem is reduced to a quadratic program that can be iteratively solved within the SQP scheme at each time step of CMPC. Furthermore, we provide the formal guarantee of the convergence of the SQP scheme, and subsequently guarantee the recursive feasibility and stability of CMPC. Simulations on multi-agent systems with unicycle dynamics demonstrate a 35-52 times reduction in computation time compared with baseline methods, confirming the suitability of the proposed approach for real-time safe output consensus control.", "AI": {"tldr": "提出一种基于序列二次规划（SQP）的凸模型预测控制（CMPC）方法，通过线性化系统动力学和利用切线投影法凸化控制屏障函数，将非线性规划问题转化为二次规划问题，从而降低了计算复杂度，提高了实时性，并保证了系统的递归可行性和稳定性。", "motivation": "在模型预测控制（MPC）应用于安全输出共识时，非线性动力学和安全约束会产生计算量大的非线性规划问题，阻碍了实时应用。", "method": "提出一种基于SQP的CMPC方法。通过切线投影法线性化系统动力学和凸化高阶离散时间控制屏障函数，将原非线性规划问题转化为迭代求解的二次规划问题。", "result": "SQP算法收敛性得到理论保证，CMPC算法具备递归可行性和稳定性。仿真结果表明，与基线方法相比，计算时间减少了35-52倍。", "conclusion": "所提出的CMPC方法能够有效地在多智能体系统中实现安全输出共识，并且显著降低了计算复杂度，适合实时控制应用。"}}
{"id": "2601.11700", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11700", "abs": "https://arxiv.org/abs/2601.11700", "authors": ["Luis A. Leiva", "Moises Diaz", "Nuwan T. Attygalle", "Miguel A. Ferrer", "Rejean Plamondon"], "title": "Telling Human and Machine Handwriting Apart", "comment": null, "summary": "Handwriting movements can be leveraged as a unique form of behavioral biometrics, to verify whether a real user is operating a device or application. This task can be framed as a reverse Turing test in which a computer has to detect if an input instance has been generated by a human or artificially. To tackle this task, we study ten public datasets of handwritten symbols (isolated characters, digits, gestures, pointing traces, and signatures) that are artificially reproduced using seven different synthesizers, including, among others, the Kinematic Theory (Sigma h model), generative adversarial networks, Transformers, and Diffusion models. We train a shallow recurrent neural network that achieves excellent performance (98.3 percent Area Under the ROC Curve (AUC) score and 1.4 percent equal error rate on average across all synthesizers and datasets) using nonfeaturized trajectory data as input. In few-shot settings, we show that our classifier achieves such an excellent performance when trained on just 10 percent of the data, as evaluated on the remaining 90% of the data as a test set. We further challenge our classifier in out-of-domain settings, and observe very competitive results as well. Our work has implications for computerized systems that need to verify human presence, and adds an additional layer of security to keep attackers at bay.", "AI": {"tldr": "研究使用淺層遞迴神經網路，透過非特徵化的軌跡數據，在高準確度下區分人類手寫與機器生成的手寫數據，即使在樣本量少（few-shot）和領域外（out-of-domain）的設定下仍表現出色。", "motivation": "為了驗證真實用戶是否正在操作設備或應用程式，利用手寫動作作為一種獨特的行為生物識別方法，並將此任務視為區分人類與機器生成輸入的逆圖靈測試。", "method": "研究人員使用十個公開的手寫符號數據集（包括隔離字元、數字、手勢、指向軌跡和簽名），並使用七種不同的合成器（包括 Kinematic Theory、生成對抗網絡、Transformer 和 Diffusion 模型）來人工生成數據。然後，他們訓練一個淺層遞迴神經網路，直接使用非特徵化的軌跡數據作為輸入。", "result": "該模型在所有合成器和數據集上的平均 ROC 曲線下面積（AUC）達到 98.3%，平均錯誤率（EER）為 1.4%。在 few-shot 設定下，模型僅需 10% 的數據進行訓練，即可在剩餘 90% 的數據上進行評估並取得優異表現。在 out-of-domain 設定下，模型也展現出非常有競爭力的結果。", "conclusion": "提出的淺層遞迴神經網路方法能夠高效且準確地區分人類手寫和機器生成的數據，即使在數據有限或領域外的情況下也是如此。這項研究為需要驗證人類存在情況的電腦系統提供了額外的安全保障，有助於抵禦攻擊者。"}}
{"id": "2601.11769", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11769", "abs": "https://arxiv.org/abs/2601.11769", "authors": ["Cheng Lyu", "Jingyue Zhang", "Ryan Maunu", "Mengwei Li", "Vinny DeGenova", "Yuanli Pei"], "title": "From Pixels to Purchase: Building and Evaluating a Taxonomy-Decoupled Visual Search Engine for Home Goods E-commerce", "comment": null, "summary": "Visual search is critical for e-commerce, especially in style-driven domains where user intent is subjective and open-ended. Existing industrial systems typically couple object detection with taxonomy-based classification and rely on catalog data for evaluation, which is prone to noise that limits robustness and scalability. We propose a taxonomy-decoupled architecture that uses classification-free region proposals and unified embeddings for similarity retrieval, enabling a more flexible and generalizable visual search. To overcome the evaluation bottleneck, we propose an LLM-as-a-Judge framework that assesses nuanced visual similarity and category relevance for query-result pairs in a zero-shot manner, removing dependence on human annotations or noise-prone catalog data. Deployed at scale on a global home goods platform, our system improves retrieval quality and yields a measurable uplift in customer engagement, while our offline evaluation metrics strongly correlate with real-world outcomes.", "AI": {"tldr": "提出了一种新的视觉搜索架构，该架构不依赖于预定义的分类体系，而是使用统一的嵌入进行相似性检索。此外，还提出了一种LLM-as-a-Judge框架，用于零样本评估查询-结果对的视觉相似性和类别相关性，从而克服了评估瓶颈。该系统已成功部署，提高了检索质量并增加了客户参与度。", "motivation": "现有电商的视觉搜索系统依赖于有噪声的目录数据进行评估，这限制了其鲁棒性和可扩展性。特别是在风格驱动的领域，用户意图主观且开放，这种限制尤为明显。", "method": "提出了一种分类体系解耦的架构，使用无分类的区域建议和统一的嵌入进行相似性检索。为了解决评估问题，引入了一个LLM-as-a-Judge框架，该框架能够零样本地评估查询-结果对的视觉相似性和类别相关性。", "result": "该系统在实际部署中提高了检索质量，并带来了客户参与度的提升。离线评估指标与实际结果高度相关。", "conclusion": "所提出的分类体系解耦的视觉搜索架构和LLM-as-a-Judge评估框架能够实现更灵活、更通用的视觉搜索，并且在实际应用中取得了显著成效。"}}
{"id": "2601.12242", "categories": ["cs.AI", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.12242", "abs": "https://arxiv.org/abs/2601.12242", "authors": ["WooSeok Kim", "Jeonghoon Lee", "Sangho Kim", "Taesun An", "WonMin Lee", "Dowon Kim", "Kyungseop Shin"], "title": "Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA Systems Using Deep Reinforcement Learning", "comment": null, "summary": "In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation(JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state.", "AI": {"tldr": "本文提出了一种结合了回放记忆和on-policy算法的深度强化学习框架，用于NOMA系统中的网络资源分配，旨在解决现有方法在信道分配方面的不确定性问题，并通过仿真评估了不同参数设置的影响。", "motivation": "物联网（IoT）的快速发展导致网络资源稀缺，需要优化NOMA系统的资源利用率，以满足日益增长的需求。现有方法在信道分配方面仍存在不足。", "method": "提出了一种深度强化学习框架，该框架结合了回放记忆（replay memory）和on-policy算法，并用于NOMA系统中的网络资源分配。通过仿真评估了学习率、批处理大小、模型类型和状态特征数量等参数的影响。", "result": "仿真结果表明，所提出的深度强化学习框架能够有效地分配网络资源。对学习率、批处理大小、模型类型和状态特征数量等参数的广泛模拟评估了它们对系统性能的影响。", "conclusion": "本文通过提出一种新的深度强化学习框架，改进了NOMA系统中的网络资源分配，尤其是在信道分配方面，并为进一步研究提供了基础。"}}
{"id": "2601.11913", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11913", "abs": "https://arxiv.org/abs/2601.11913", "authors": ["Yichen Jiang", "Peng Ye", "Jiakang Yuan", "Chongjun Tu", "Lei Bai", "Tao Chen"], "title": "LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding", "comment": "12 pages, 5 figures", "summary": "Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM's hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.", "AI": {"tldr": "本文提出了一种名为 LSTM-MAS 的多智能体系统，借鉴 LSTM 的层次化信息流和门控记忆机制来处理长上下文。该系统通过分段处理、冗余过滤、错误检测和全局调控，有效避免了错误累积和幻觉传播，并在多个长上下文理解任务上取得了显著性能提升。", "motivation": "现有的处理长上下文的方法要么牺牲上下文窗口，要么增加计算成本，要么容易出现错误累积和幻觉。因此，需要一种新的方法来有效且高效地处理长上下文。", "method": "LSTM-MAS 构建了一个链式多智能体系统，每个节点包含负责段落理解的“worker”智能体、负责冗余信息过滤的“filter”智能体、负责持续错误检测的“judge”智能体以及负责全局信息调控的“manager”智能体。这种设计模仿了 LSTM 的输入门、遗忘门、常数误差循环单元和输出门，实现了受控的信息传递和选择性的长期依赖建模。", "result": "与现有的最佳多智能体方法 CoA 相比，LSTM-MAS 在 NarrativeQA、Qasper、HotpotQA 和 MuSiQue 数据集上分别取得了 40.93%、43.70%、121.57% 和 33.12% 的性能提升。", "conclusion": "LSTM-MAS 借鉴 LSTM 架构设计了一种创新的多智能体系统，通过其独特的智能体协作和信息处理机制，成功解决了长上下文理解中的挑战，显著优于现有方法，并能有效避免错误累积和幻觉传播。"}}
{"id": "2601.12918", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12918", "abs": "https://arxiv.org/abs/2601.12918", "authors": ["Dharmendra Sharma", "Peeyush Thakur", "Sandeep Gupta", "Narendra Kumar Dhar", "Laxmidhar Behera"], "title": "Dynamic Hand Gesture Recognition for Robot Manipulator Tasks", "comment": null, "summary": "This paper proposes a novel approach to recognizing dynamic hand gestures facilitating seamless interaction between humans and robots. Here, each robot manipulator task is assigned a specific gesture. There may be several such tasks, hence, several gestures. These gestures may be prone to several dynamic variations. All such variations for different gestures shown to the robot are accurately recognized in real-time using the proposed unsupervised model based on the Gaussian Mixture model. The accuracy during training and real-time testing prove the efficacy of this methodology.", "AI": {"tldr": "本文提出了一种基于高斯混合模型 (GMM) 的无监督模型，用于实时准确识别动态手势，从而实现人机之间的无缝交互。", "motivation": "为了实现人机之间的无缝交互，需要一种能够准确识别用户意图的动态手势识别方法，尤其是在手势存在多种动态变化的情况下。", "method": "采用基于高斯混合模型 (GMM) 的无监督学习方法来识别动态手势。该模型能够处理不同手势的多种动态变化。", "result": "在训练和实时测试中均取得了高准确率，证明了该方法的有效性。", "conclusion": "所提出的基于 GMM 的无监督手势识别方法能够准确、实时地识别具有动态变化的复杂手势，为实现更直观的人机交互提供了有效途径。"}}
{"id": "2601.13037", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13037", "abs": "https://arxiv.org/abs/2601.13037", "authors": ["Imran Sayyed", "Nandan Kumar Sinha"], "title": "Feedforward-Feedback Integration in Flight Control: Reinforcement Learning with Sliding Mode Control", "comment": "16 pages", "summary": "Learning-based controllers leverage nonlinear couplings and enhance transients but seldom offer guarantees under tight input constraints. Robust feedback like sliding-mode control (SMC) provides these guarantees but is conservative in isolation. This paper creates a learning-augmented framework where a deep reinforcement learning policy produces feedforward commands and an SMC law imposes actuator limits, bounds learned authority, and guarantees robustness. The policy is modeled as a matched, bounded input, and Lyapunov-based conditions link SMC gains to the admissible feedforward bound, guaranteeing stability under saturation. This formulation is applicable to nonlinear, underactuated plants with hard constraints. To illustrate the methodology, the method is applied to a six-degree-of-freedom aircraft model and compared with Reinforcement Learning and isolated SMC. Simulation results show that the hybrid controller improves transient behavior and reduces control oscillations compared to standalone RL and SMC controllers, while preserving robustness under modeling uncertainties and disturbances. Even using it with partially trained policies, SMC component of the control stabilizes transients, whereas fully trained policies provide faster convergence, reduced constraint violations, and robustness. These results illustrate that learning-augmented control offers superior performance with robustness guarantees under tight input constraints.", "AI": {"tldr": "本研究提出了一种结合深度强化学习（DRL）和滑模控制（SMC）的混合控制器框架，用于在严格输入约束下实现具有鲁棒性保证的非线性系统控制，并应用于六自由度飞机模型。", "motivation": "现有的基于学习的控制器虽然能利用非线性耦合并改善瞬态响应，但在严格输入约束下缺乏稳定性保证。而传统的鲁棒控制器（如SMC）虽然能提供保证，但其本身可能过于保守。因此，研究动机是开发一种能够结合两者的优点，在满足输入约束的同时实现高性能和鲁棒性的控制器。", "method": "该框架的核心思想是利用DRL策略生成前馈控制指令，并由SMC来强制执行输入约束、限制学习策略的权限并保证鲁棒性。DRL策略被建模为匹配、有界输入的。Lyapunov理论被用来推导SMC增益与允许的前馈输入界之间的关系，从而保证在饱和情况下的稳定性。", "result": "该混合控制器在六自由度飞机模型上的仿真结果表明，与单独的RL和SMC控制器相比，它改善了瞬态行为，减少了控制振荡。即使在使用部分训练的策略时，SMC部分也能稳定瞬态。完全训练的策略则能提供更快的收敛速度、更少的约束违规以及更好的鲁棒性。", "conclusion": "学习增强控制（Learning-augmented control）是一种有效的策略，可以在严格输入约束下实现兼具性能和鲁棒性保证的控制。该混合DRL-SMC框架能够有效处理非线性、欠驱动植物，并能应对模型不确定性和扰动。"}}
{"id": "2601.12925", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12925", "abs": "https://arxiv.org/abs/2601.12925", "authors": ["Weize Xie", "Yi Ding", "Ying He", "Leilei Wang", "Binwen Bai", "Zheyi Zhao", "Chenyang Wang", "F. Richard Yu"], "title": "ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation", "comment": null, "summary": "Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. Analysis indicates that current diffusion strategies are confronted with two limitations. First, these strategies only rely on short-term observations as conditions. Second, the training objective remains limited to a single denoising loss, which leads to error accumulation and causes grasping deviations. To address these limitations, this paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), by injecting the predicted future view representation into the diffusion process. As a result, the policy is guided to be forward-looking, enabling it to correct trajectory deviations. Following this design, ForeDiffusion employs a dual loss mechanism, combining the traditional denoising loss and the consistency loss of future observations, to achieve the unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming the existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.", "AI": {"tldr": "本文提出了一种名为 ForeDiffusion 的前瞻性条件扩散模型，通过结合未来视觉信息和双重损失函数，显著提高了机器人抓取等复杂任务的成功率，优于现有方法。", "motivation": "现有基于扩散模型的机器人运动控制方法在处理复杂任务时成功率下降，主要原因是仅依赖短期观察和单一的去噪损失导致误差累积。", "method": "ForeDiffusion 通过将预测的未来视觉信息注入扩散过程，使策略具备前瞻性，并采用去噪损失和未来观察一致性损失的双重损失机制进行联合优化。", "result": "在 Adroit suite 和 MetaWorld 基准测试中，ForeDiffusion 在复杂任务上的平均成功率提高了 23%，整体任务成功率达到 80%，性能比主流扩散方法更稳定。", "conclusion": "ForeDiffusion 通过引入前瞻性条件和双重损失机制，有效克服了现有扩散模型的局限性，在机器人运动控制方面取得了显著的性能提升，尤其在复杂任务中表现突出。"}}
{"id": "2601.11772", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11772", "abs": "https://arxiv.org/abs/2601.11772", "authors": ["Yimu Pan", "Hongda Mao", "Qingshuang Chen", "Yelin Kim"], "title": "studentSplat: Your Student Model Learns Single-view 3D Gaussian Splatting", "comment": null, "summary": "Recent advance in feed-forward 3D Gaussian splatting has enable remarkable multi-view 3D scene reconstruction or single-view 3D object reconstruction but single-view 3D scene reconstruction remain under-explored due to inherited ambiguity in single-view. We present \\textbf{studentSplat}, a single-view 3D Gaussian splatting method for scene reconstruction. To overcome the scale ambiguity and extrapolation problems inherent in novel-view supervision from a single input, we introduce two techniques: 1) a teacher-student architecture where a multi-view teacher model provides geometric supervision to the single-view student during training, addressing scale ambiguity and encourage geometric validity; and 2) an extrapolation network that completes missing scene context, enabling high-quality extrapolation. Extensive experiments show studentSplat achieves state-of-the-art single-view novel-view reconstruction quality and comparable performance to multi-view methods at the scene level. Furthermore, studentSplat demonstrates competitive performance as a self-supervised single-view depth estimation method, highlighting its potential for general single-view 3D understanding tasks.", "AI": {"tldr": "studentSplat 提出了一种新颖的单视图 3D 高斯溅射方法，通过教师-学生架构和外插网络克服了单视图重建中的尺度模糊和外插问题，实现了最先进的单视图新视图重建质量。", "motivation": "现有 3D 高斯溅射技术在多视图 3D 场景重建方面取得了显著进展，但单视图 3D 场景重建由于固有的歧义性而未得到充分研究。", "method": "采用教师-学生架构，其中多视图教师模型在训练过程中为单视图学生提供几何监督，以解决尺度模糊并鼓励几何有效性；引入外插网络来补全缺失的场景上下文，从而实现高质量的外插。", "result": "studentSplat 在单视图新视图重建方面达到了最先进的质量，在场景级别上的性能可与多视图方法相媲美，并且作为一种自监督的单视图深度估计方法，展现出有竞争力的性能。", "conclusion": "studentSplat 是一种有效的单视图 3D 高斯溅射方法，通过创新的架构设计解决了尺度模糊和外插问题，在单视图 3D 理解任务中具有巨大潜力。"}}
{"id": "2601.13174", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.13174", "abs": "https://arxiv.org/abs/2601.13174", "authors": ["Maryam Salamatmoghadasi", "Amir Mehrabian", "Halim Yanikomeroglu", "Georges Kaddoum"], "title": "QoS-Aware Energy Optimization via Cell Switching in Heterogeneous Networks", "comment": null, "summary": "The growing demand for mobile data services in dense urban areas has intensified the need for energy-efficient radio access networks (RANs) in future 6G systems. In this context, one promising strategy is cell switching (CS), which dynamically deactivates underutilized small base stations (SBSs) to reduce power consumption. However, while previous research explored CS primarily based on traffic load, ensuring user quality of service (QoS) under realistic channel conditions remains a challenge. In this paper, we propose a novel optimization-driven CS framework that jointly minimizes network power consumption and guarantees user QoS by enforcing a minimum received power threshold as part of offloading decisions. In contrast to prior load-based or learning-based approaches, our method explicitly integrates channel-aware information into the CS process, thus ensuring reliable service quality for offloaded users. Furthermore, flexibility of the proposed framework enables operators to adapt system behavior between energy-saving and QoS-preserving modes by tuning a single design parameter. Simulation results demonstrate that the proposed approach achieves up to 30% power savings as compared to baseline methods while fully maintaining QoS under diverse network conditions. Scalability and robustness of the proposed method in realistic heterogeneous networks (HetNets) further highlight its potential as a practical solution for sustainable 6G deployments.", "AI": {"tldr": "提出了一种新的、以优化为驱动的蜂窝切换（CS）框架，该框架通过结合信道感知信息，在减少网络功耗的同时，还能保证用户的服务质量（QoS）。", "motivation": "未来6G系统中，密集城市区域对移动数据服务需求不断增长，这使得对节能无线接入网络（RAN）的需求日益迫切。而传统的基于流量负载的CS方法在保证用户QoS方面存在挑战。", "method": "提出了一种创新的、以优化为驱动的CS框架，该框架通过强制执行最小接收功率阈值来共同最小化网络功耗并保证用户QoS。该方法显式地将信道感知信息集成到CS过程中。", "result": "与基线方法相比，该方法在模拟结果中实现了高达30%的功耗节省，同时在各种网络条件下都能完全保持QoS。", "conclusion": "所提出的CS框架是一种灵活且实用的解决方案，可以通过调整单个设计参数来平衡节能和QoS保障，具有良好的可扩展性和鲁棒性，适用于可持续的6G部署。"}}
{"id": "2601.12256", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12256", "abs": "https://arxiv.org/abs/2601.12256", "authors": ["Jinyoung Park", "Minseong Bae", "Jeehye Na", "Hyunwoo J. Kim"], "title": "Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration", "comment": null, "summary": "Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, we propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, we present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.", "AI": {"tldr": "本文提出了一种名为CoLLaMo的大型语言模型，它通过多层次的分子模态协作投影仪，有效整合了1D序列、2D图和3D构象信息，解决了现有大型分子语言模型（LMLM）中存在的幻觉和鲁棒性不足的问题。此外，还提出了一种新的分子中心自动测量方法，包括幻觉评估和基于GPT的标题质量评估，以克服传统评估指标的局限性。", "motivation": "现有的LMLMs在整合分子模态（如1D序列、2D图、3D构象）方面存在不足，导致模型出现幻觉且鲁棒性有限。研究动机是为了提高LMLM对分子模态的整合能力和泛化能力。", "method": "提出CoLLaMo模型，核心是一个多层次的分子模态协作投影仪，其中包含关系感知模态协作注意力机制，该机制通过整合2D结构和3D空间关系，实现原子间细粒度和关系引导的信息交换。此外，开发了新的分子中心自动测量方法，包括幻觉评估和GPT驱动的标题质量评估。", "result": "CoLLaMo在分子标题生成、计算属性问答、描述性属性问答、基序计数和IUPAC名称预测等多个任务上取得了最佳性能，证明了其在分子模态泛化能力上的提升。", "conclusion": "CoLLaMo通过整合多模态分子信息和引入新的评估方法，有效地解决了现有LMLM的局限性，显著提升了模型在多种分子理解任务上的性能和鲁棒性。"}}
{"id": "2601.11779", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11779", "abs": "https://arxiv.org/abs/2601.11779", "authors": ["Vinicius F. Arruda", "Rodrigo F. Berriel", "Thiago M. Paixão", "Claudine Badue", "Alberto F. De Souza", "Nicu Sebe", "Thiago Oliveira-Santos"], "title": "Cross-Domain Object Detection Using Unsupervised Image Translation", "comment": null, "summary": "Unsupervised domain adaptation for object detection addresses the adaption of detectors trained in a source domain to work accurately in an unseen target domain. Recently, methods approaching the alignment of the intermediate features proven to be promising, achieving state-of-the-art results. However, these methods are laborious to implement and hard to interpret. Although promising, there is still room for improvements to close the performance gap toward the upper-bound (when training with the target data). In this work, we propose a method to generate an artificial dataset in the target domain to train an object detector. We employed two unsupervised image translators (CycleGAN and an AdaIN-based model) using only annotated data from the source domain and non-annotated data from the target domain. Our key contributions are the proposal of a less complex yet more effective method that also has an improved interpretability. Results on real-world scenarios for autonomous driving show significant improvements, outperforming state-of-the-art methods in most cases, further closing the gap toward the upper-bound.", "AI": {"tldr": "提出了一种使用CycleGAN和AdaIN生成目标域人工数据集的方法，用于无监督域适应目标检测，相较于现有方法，该方法更简单、更有效且可解释性更强。", "motivation": "现有先进的无监督域适应目标检测方法通过对齐中间特征来提升性能，但实现复杂且难以解释，性能仍与使用目标数据训练的上限存在差距。", "method": "利用源域的标注数据和目标域的无标注数据，结合CycleGAN和AdaIN两个无监督图像翻译器生成目标域的人工数据集，然后用该数据集训练目标检测器。", "result": "在真实世界的自动驾驶场景中，所提出的方法取得了显著的性能提升，在大多数情况下优于现有的最先进方法，并进一步缩小了与使用目标数据训练的上限之间的差距。", "conclusion": "通过生成目标域的人工数据集，提出了一种更简单、更有效且可解释性更强的无监督域适应目标检测新方法，有效提升了在跨域场景下的检测性能。"}}
{"id": "2601.12259", "categories": ["cs.AI", "cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12259", "abs": "https://arxiv.org/abs/2601.12259", "authors": ["Jiashuo Liu", "Siyuan Chen", "Zaiyuan Wang", "Zhiyuan Zeng", "Jiacheng Guo", "Liang Hu", "Lingyue Yin", "Suozhi Huang", "Wenxin Hao", "Yang Yang", "Zerui Cheng", "Zixin Yao", "Lingyue Yin", "Haoxin Liu", "Jiayi Cheng", "Yuzhen Li", "Zezhong Ma", "Bingjie Wang", "Bingsen Qiu", "Xiao Liu", "Zeyang Zhang", "Zijian Liu", "Jinpeng Wang", "Mingren Yin", "Tianci He", "Yali Liao", "Yixiao Tian", "Zhenwei Zhu", "Anqi Dai", "Ge Zhang", "Jingkai Liu", "Kaiyuan Zhang", "Wenlong Wu", "Xiang Gao", "Xinjie Chen", "Zhixin Yao", "Zhoufutu Wen", "B. Aditya Prakash", "Jose Blanchet", "Mengdi Wang", "Nian Si", "Wenhao Huang"], "title": "FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains", "comment": "21 pages", "summary": "Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.", "AI": {"tldr": "本文提出了FutureX-Pro，一个包含金融、零售、公共卫生和自然灾害四个垂直领域的智能体未来预测基准，旨在评估现有智能体LLM在这些高价值领域的适用性，发现通用推理能力与垂直领域精度之间存在差距。", "motivation": "现有智能体在开放域搜索方面表现良好，但在资本密集型和安全关键领域（如金融、零售、公共卫生、自然灾害）的可靠性研究不足，作者希望评估当前SOTA智能体LLM是否具备在这些高价值垂直领域部署的能力。", "method": "基于FutureX框架，引入FutureX-Pro，包含FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster。采用FutureX无污染、实时评估的管线，对智能体LLM在基础预测任务上进行基准测试，任务范围包括市场指标、供应链需求、疫情趋势和自然灾害追踪。", "result": "评估发现，当前SOTA智能体LLM在通用推理能力和高价值垂直应用所需的精度之间存在显著的性能差距。", "conclusion": "通用智能体LLM在金融、零售、公共卫生和自然灾害等高价值垂直领域的应用仍需进一步提升，其通用推理能力尚不能满足这些领域对精度的要求。"}}
{"id": "2601.11923", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11923", "abs": "https://arxiv.org/abs/2601.11923", "authors": ["P. Bilha Githinji", "Aikaterini Melliou", "Xi Yuan", "Dayan Zhang", "Lian Zhang", "Zhenglin Chen", "Jiansong Ji", "Chengying Lv", "Jinhao Xu", "Peiwu Qin", "Dongmei Yu"], "title": "Mapping the maturation of TCM as an adjuvant to radiotherapy", "comment": null, "summary": "The integration of complementary medicine into oncology represents a paradigm shift that has seen to increasing adoption of Traditional Chinese Medicine (TCM) as an adjuvant to radiotherapy. About twenty-five years since the formal institutionalization of integrated oncology, it is opportune to synthesize the trajectory of evidence for TCM as an adjuvant to radiotherapy. Here we conduct a large-scale analysis of 69,745 publications (2000 - 2025), emerging a cyclical evolution defined by coordinated expansion and contraction in publication output, international collaboration, and funding commitments that mirrors a define-ideate-test pattern. Using a theme modeling workflow designed to determine a stable thematic structure of the field, we identify five dominant thematic axes - cancer types, supportive care, clinical endpoints, mechanisms, and methodology - that signal a focus on patient well-being, scientific rigor and mechanistic exploration. Cross-theme integration of TCM is patient-centered and systems-oriented. Together with the emergent cycles of evolution, the thematic structure demonstrates progressive specialization and potential defragmentation of the field or saturation of existing research agenda. The analysis points to a field that has matured its current research agenda and is likely at the cusp of something new. Additionally, the field exhibits positive reporting of findings that is homogeneous across publication types, thematic areas, and the cycles of evolution suggesting a system-wide positive reporting bias agnostic to structural drivers.", "AI": {"tldr": "本研究对2000-2025年间关于将中医药作为放疗辅助疗法的69,745篇出版物进行了大规模分析，揭示了该领域出版物数量、国际合作和资金投入的周期性演变，并识别出五个主要研究主题：癌症类型、支持性护理、临床终点、机制和方法学。研究表明该领域正朝着专业化和整合方向发展，可能即将迎来新的研究突破，但同时存在系统性的阳性报告偏倚。", "motivation": "随着中医药在肿瘤治疗中作为放疗辅助疗法的应用日益广泛，作者旨在整合和分析过去二十五年（2000-2025年）有关中医药辅助放疗的证据轨迹，以理解该领域的发展模式和研究方向。", "method": "研究采用了大规模出版物分析方法，共分析了2000年至2025年间的69,745篇文献。利用主题建模工作流程来确定领域稳定的主题结构，并识别出五个主要的研究主题轴：癌症类型、支持性护理、临床终点、机制和方法学。此外，还分析了出版物数量、国际合作和资金投入的周期性演变，并评估了研究发现的报告偏倚。", "result": "分析显示，该领域的研究活动呈现出周期性的扩张与收缩，反映了一种“定义-构思-测试”的演变模式。识别出的五大主题轴表明研究重点在于患者福祉、科学严谨性和机制探索，且中医药的整合是患者中心和系统导向的。研究结果还揭示了该领域的专业化和潜在的去碎片化，或现有研究议程的饱和。此外，所有出版物类型、主题领域和演化周期均呈现出同质化的阳性报告，暗示存在一种系统性的、与结构驱动因素无关的阳性报告偏倚。", "conclusion": "中医药作为放疗辅助疗法领域的研究议程已经成熟，并可能处于新的研究突破的边缘。该领域的研究呈现出专业化和整合化的趋势，但研究发现的阳性报告偏倚是一个需要关注的问题，它可能影响对研究真实效益的评估。"}}
{"id": "2601.12939", "categories": ["cs.RO", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.12939", "abs": "https://arxiv.org/abs/2601.12939", "authors": ["Kaleem Arshid", "Ali Krayani", "Lucio Marcenaro", "David Martin Gomez", "Carlo Regazzoni"], "title": "Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design", "comment": "This paper has been accepted for presentation at the 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (IEEE ICASSP 2026) Workshop: 'Multi-Modal Signal Processing and AI for Communications and Sensing in 6G and Beyond (MuSiC-6GB)'", "summary": "This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control.", "AI": {"tldr": "本文提出了一种基于主动推理的无人机蜂群自主轨迹设计框架，通过遗传算法生成专家轨迹来训练世界模型，并在在线运行时通过最小化信仰与模型预测状态的差异来实现自适应控制，实验证明了该框架的优越性。", "motivation": "为了实现无人机蜂群的分布式任务分配、路线排序和运动规划，并使其能够对动态环境做出自适应响应。", "method": "采用主动推理框架，结合遗传算法（GA-RF）生成专家轨迹，训练分层世界模型，并在在线操作中通过最小化当前信仰与模型预测状态之间的差异来推断动作。", "result": "与Q-Learning相比，仿真结果显示该框架具有更快的收敛速度、更高的稳定性和更安全的导航能力。", "conclusion": "所提出的框架具有可扩展性和认知基础，能够实现智能无人机蜂群控制，并能有效应对动态环境。"}}
{"id": "2601.11932", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11932", "abs": "https://arxiv.org/abs/2601.11932", "authors": ["Abdullah Al Monsur", "Nitesh Vamshi Bommisetty", "Gene Louis Kim"], "title": "Event Detection with a Context-Aware Encoder and LoRA for Improved Performance on Long-Tailed Classes", "comment": null, "summary": "The current state of event detection research has two notable re-occurring limitations that we investigate in this study. First, the unidirectional nature of decoder-only LLMs presents a fundamental architectural bottleneck for natural language understanding tasks that depend on rich, bidirectional context. Second, we confront the conventional reliance on Micro-F1 scores in event detection literature, which systematically inflates performance by favoring majority classes. Instead, we focus on Macro-F1 as a more representative measure of a model's ability across the long-tail of event types. Our experiments demonstrate that models enhanced with sentence context achieve superior performance over canonical decoder-only baselines. Using Low-Rank Adaptation (LoRA) during finetuning provides a substantial boost in Macro-F1 scores in particular, especially for the decoder-only models, showing that LoRA can be an effective tool to enhance LLMs' performance on long-tailed event classes.", "AI": {"tldr": "本研究旨在解决现有事件检测方法在理解双向上下文和评估指标上的局限性。通过引入句子上下文和采用Macro-F1指标，并利用LoRA进行微调，证明了提升模型在长尾事件类别上的检测性能。", "motivation": "当前事件检测研究在处理需要丰富双向上下文的任务时，受限于仅有单向解码器的LLM架构。此外，现有研究普遍依赖Micro-F1指标，该指标会系统性地夸大对多数类别的性能，未能准确反映模型在长尾事件类型上的表现。", "method": "研究中，实验模型通过引入句子上下文来增强理解能力。在微调过程中，应用了低秩适应（LoRA）技术。评估指标从Micro-F1转向Macro-F1。", "result": "引入句子上下文的模型在性能上优于标准的仅有解码器的基线模型。LoRA在微调过程中显著提升了Macro-F1得分，尤其对仅有解码器的模型效果显著，表明LoRA能够有效提升LLM在长尾事件类别上的性能。", "conclusion": "通过引入句子上下文和采用Macro-F1指标，并结合LoRA进行微调，可以有效克服现有事件检测方法的局限性，尤其是在处理长尾事件类型方面，可以显著提升模型的性能。"}}
{"id": "2601.12260", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12260", "abs": "https://arxiv.org/abs/2601.12260", "authors": ["Yihao Ding", "Qiang Sun", "Puzhen Wu", "Sirui Li", "Siwen Luo", "Wei Liu"], "title": "Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding", "comment": "Accepted at WWW 2026 Demo Track", "summary": "Document understanding (VRDU) in regulated domains is particularly challenging, since scanned documents often contain sensitive, evolving, and domain specific knowledge. This leads to two major challenges: the lack of manual annotations for model adaptation and the difficulty for pretrained models to stay up-to-date with domain-specific facts. While Multimodal Large Language Models (MLLMs) show strong zero-shot abilities, they still suffer from hallucination and limited domain grounding. In contrast, discriminative Vision-Language Pre-trained Models (VLPMs) provide reliable grounding but require costly annotations to cover new domains. We introduce Docs2Synth, a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. Docs2Synth automatically processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with an MLLM through an iterative retrieval--generation loop, reducing hallucination and improving response consistency. We further deliver Docs2Synth as an easy-to-use Python package, enabling plug-and-play deployment across diverse real-world scenarios. Experiments on multiple VRDU benchmarks show that Docs2Synth substantially enhances grounding and domain generalization without requiring human annotations.", "AI": {"tldr": "本文提出Docs2Synth框架，通过合成数据训练一个轻量级视觉检索器，并与大型多模态语言模型（MLLM）协同工作，实现了低资源和私有领域的文档理解，减少了幻觉并提高了响应一致性，且无需人工标注。", "motivation": "在受监管领域进行文档理解（VRDU）面临两大挑战：缺乏模型适应的手动标注，以及预训练模型难以跟上领域特定知识的更新。现有MLLM虽有零样本能力，但存在幻觉和领域知识有限的问题；而区分性视觉语言预训练模型（VLPMs）虽能可靠地进行领域知识关联，但需要昂贵的标注。这些都促使研究者寻求一种无需人工标注即可适应私有和低资源领域的方法。", "method": "Docs2Synth框架采用一种合成监督方法。首先，自动处理原始文档集，然后通过基于代理的系统生成并验证多样化的问答对。接着，训练一个轻量级的视觉检索器，用于提取与领域相关的证据。在推理阶段，该检索器与MLLM通过迭代的检索-生成循环协同工作。", "result": "实验结果表明，Docs2Synth在多个VRDU基准测试中显著提高了领域知识的关联性和泛化能力，同时无需人工标注。", "conclusion": "Docs2Synth是一个自动化的合成监督框架，通过检索增强的推理，能够有效地解决私有和低资源领域文档理解中的挑战，减少幻觉，提高响应一致性，并且易于部署。"}}
{"id": "2601.13202", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.13202", "abs": "https://arxiv.org/abs/2601.13202", "authors": ["Michael Giovanniello", "Dharik S. Mallapragada"], "title": "Emissions and cost tradeoffs of time-matched clean electricity procurement under inter-annual weather variability: case study of hydrogen production", "comment": "7 Figures, 1 table (main text)", "summary": "Time-matching requirements (TMRs) for clean electricity procurement are increasingly adopted in voluntary corporate sustainability initiatives and regulatory frameworks. While prior research has evaluated cost and emissions impacts of hourly vs. annual TMR, these studies typically rely on single-year weather scenarios that do not capture inter-annual variability in variable renewable energy (VRE) generation. We use a capacity expansion model to assess how inter-annual weather variability affects procurement-driven infrastructure investments, costs, and emissions for a grid-connected hydrogen producer under both annual and hourly time-matching strategies. Using a Texas case study, we compare deterministic (single weather scenario) and stochastic (nine weather scenarios) modeling approaches. Both procurement investments and cost and emissions outcomes are sensitive to weather scenario, with annual matching exhibiting greater sensitivity than hourly matching. Stochastic modeling finds higher cost premiums for hourly versus annual matching compared to deterministic modeling, though emissions trends remain directionally consistent. Demand flexibility through H2 storage is critical for lowering hourly matching cost premiums under weather-driven VRE variability. Partial hourly matching (e.g., 80-90% compliance) can modestly reduce costs while maintaining minimal emissions impacts. Finally, we examine how grid-level renewable portfolio standards (RPS) affect additionality and emissions. When stringent additionality is achieved via binding RPS constraints on non-H2 electricity demand, annual matching can produce emissions reductions comparable to hourly matching at lower cost.", "AI": {"tldr": "本文使用容量扩展模型，通过考虑多年度天气变化，评估了不同时间匹配要求（年度和小时）对电网连接的氢气生产商的投资、成本和排放的影响。研究发现，年度匹配对天气变化的敏感度高于小时匹配，且储氢罐对降低小时匹配成本至关重要。部分小时匹配能有效降低成本并维持低排放。", "motivation": "现有研究对时间匹配要求（TMR）的影响评估多基于单一年度天气情景，未能体现可变可再生能源（VRE）发电的年际变化。本研究旨在解决这一不足，量化年际天气变化对不同TMR策略下投资、成本和排放的影响。", "method": "采用容量扩展模型，并使用德克萨斯州的案例研究。通过比较确定性（单一天气情景）和随机性（九个天气情景）两种建模方法，评估了年度和小时时间匹配策略下的采购投资、成本和排放。此外，还分析了氢气储存和电网级别的可再生能源组合标准（RPS）的影响。", "result": "年度和小时匹配的采购投资、成本和排放均受天气情景影响，且年度匹配的敏感度更高。与确定性模型相比，随机性模型显示小时匹配的成本溢价更高，但排放趋势方向一致。氢气储存的灵活性对于降低小时匹配的成本溢价至关重要。部分小时匹配（80-90%合规率）可在维持较低排放的同时适度降低成本。严格的RPS约束会影响加成性，且在某些情况下，年度匹配也能实现与小时匹配相当的减排效果，成本更低。", "conclusion": "年际天气变化对不同时间匹配要求下的供需匹配策略有显著影响，对年度匹配的影响尤为显著。储氢技术对于缓解VRE不确定性带来的成本增加至关重要。部分小时匹配是一种在成本和环境效益之间取得良好平衡的策略。电网层面的RPS政策，特别是结合严格的加成性要求，可以影响不同TMR策略的减排效果和成本效益。"}}
{"id": "2601.11956", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11956", "abs": "https://arxiv.org/abs/2601.11956", "authors": ["Yuyin Lu", "Ziran Liang", "Yanghui Rao", "Wenqi Fan", "Fu Lee Wang", "Qing Li"], "title": "Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence", "comment": null, "summary": "Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs' reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.", "AI": {"tldr": "本文提出了DoublyCal框架，通过引入双重校准原则，解决了大型语言模型（LLM）在知识图谱（KG）增强过程中证据和模型推理的认知不确定性量化问题，提高了准确性和置信度校准，且成本低廉。", "motivation": "现有的KG增强LLM方法未能量化检索到的证据和LLM推理的认知不确定性，导致LLM容易产生幻觉，影响了可信度。", "method": "DoublyCal框架采用轻量级代理模型来生成KG证据，并给出校准后的证据置信度。然后，使用这些校准后的证据来指导黑盒LLM进行推理，生成准确且校准良好的最终预测，其置信度可追溯到证据的不确定性。", "result": "在知识密集型基准测试上，DoublyCal显著提高了黑盒LLM的准确性和置信度校准，且代币成本低。", "conclusion": "DoublyCal框架通过双重校准原则，有效解决了KG增强LLM在处理认知不确定性方面的挑战，提高了模型的可靠性和可信度。"}}
{"id": "2601.11920", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11920", "abs": "https://arxiv.org/abs/2601.11920", "authors": ["Zhen Xu", "Vedant Khatri", "Yijun Dai", "Xiner Liu", "Siyan Li", "Xuanming Zhang", "Renzhe Yu"], "title": "Enhancing LLM-Based Data Annotation with Error Decomposition", "comment": null, "summary": "Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.", "AI": {"tldr": "本研究提出了一种诊断性评估框架，用于评估大型语言模型（LLM）在主观标注任务中的表现，该框架区分了模型自身错误和任务固有的歧义，并评估了这些错误对下游分析的潜在影响。", "motivation": "现有的LLM在主观标注任务（如心理学概念标注）上的表现不如客观任务一致，且标准评估指标（如单一对齐指标）可能掩盖不同类型的错误，这些错误对最终分析结论有不同的影响。", "method": "研究提出并验证了一个诊断性评估框架，该框架包括：1)一个诊断分类法，根据来源（模型特有 vs. 任务固有）和类型（边界模糊 vs. 概念错误识别）对LLM标注错误进行分类；2)一个轻量级的人工标注测试，用于估计LLM标注中的任务固有歧义；3)一种计算方法，用于根据该分类法分解观察到的LLM标注错误。该框架在四项教育标注任务上进行了验证。", "result": "研究表明，对于某些标注任务，过高的对齐率是不现实的，并且单一的对齐指标不能充分反映LLM标注的质量。该框架能够区分模型错误和任务固有歧义，并评估其对下游分析的影响。", "conclusion": "本研究提出的诊断性评估框架能够有效评估LLM在主观标注任务中的适用性，提供比单一指标更深入的洞察，并为LLM的进一步技术优化提供可操作的见解。这对于理解LLM在数据密集型领域的研究潜力至关重要。"}}
{"id": "2601.11896", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11896", "abs": "https://arxiv.org/abs/2601.11896", "authors": ["Ngoc-Khai Hoang", "Thi-Nhu-Mai Nguyen", "Huy-Hieu Pham"], "title": "Digital FAST: An AI-Driven Multimodal Framework for Rapid and Early Stroke Screening", "comment": null, "summary": "Early identification of stroke symptoms is essential for enabling timely intervention and improving patient outcomes, particularly in prehospital settings. This study presents a fast, non-invasive multimodal deep learning framework for automatic binary stroke screening based on data collected during the F.A.S.T. assessment. The proposed approach integrates complementary information from facial expressions, speech signals, and upper-body movements to enhance diagnostic robustness. Facial dynamics are represented using landmark based features and modeled with a Transformer architecture to capture temporal dependencies. Speech signals are converted into mel spectrograms and processed using an Audio Spectrogram Transformer, while upper-body pose sequences are analyzed with an MLP-Mixer network to model spatiotemporal motion patterns. The extracted modality specific representations are combined through an attention-based fusion mechanism to effectively learn cross modal interactions. Experiments conducted on a self-collected dataset of 222 videos from 37 subjects demonstrate that the proposed multimodal model consistently outperforms unimodal baselines, achieving 95.83% accuracy and a 96.00% F1-score. The model attains a strong balance between sensitivity and specificity and successfully detects all stroke cases in the test set. These results highlight the potential of multimodal learning and transfer learning for early stroke screening, while emphasizing the need for larger, clinically representative datasets to support reliable real-world deployment.", "AI": {"tldr": "研究提出了一种基于面部表情、语音和上身运动的多模态深度学习框架，用于快速、无创的院前卒中筛查，在包含 37 名受试者的 222 个视频的数据集上达到了 95.83% 的准确率和 96.00% 的 F1 分数，优于单模态方法。", "motivation": "院前环境中早期识别卒中症状对于及时干预和改善患者预后至关重要。", "method": "该研究提出了一种多模态深度学习框架，结合了面部表情（使用基于 landmark 的特征和 Transformer）、语音信号（使用 Audio Spectrogram Transformer 处理的 mel 频谱图）和上身运动（使用 MLP-Mixer 分析姿态序列）。通过基于注意力的融合机制整合模态特定表示，以学习跨模态交互。", "result": "在自收集的 222 个视频（37 名受试者）的数据集上，多模态模型在准确率和 F1 分数上均优于单模态基线，分别达到 95.83% 和 96.00%。该模型在敏感性和特异性之间取得了良好的平衡，并成功检测了所有测试集中的卒中病例。", "conclusion": "多模态学习和迁移学习在早期卒中筛查方面具有巨大潜力，但为了实现可靠的实际应用，需要更大、更具临床代表性的数据集。"}}
{"id": "2601.13605", "categories": ["eess.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.13605", "abs": "https://arxiv.org/abs/2601.13605", "authors": ["Milad Hoseinpour", "Shubhanshu Shekhar", "Vladimir Dvorkin"], "title": "Outage Identification from Electricity Market Data: Quickest Change Detection Approach", "comment": "7 pages, 2 figures, 1 table", "summary": "Power system outages expose market participants to significant financial risk unless promptly detected and hedged. We develop an outage identification method from public market signals grounded in the parametric quickest change detection (QCD) theory. Parametric QCD operates on stochastic data streams, distinguishing pre- and post-change regimes using the ratio of their respective probability density functions. To derive the density functions for normal and post-outage market signals, we exploit multi-parametric programming to decompose complex market signals into parametric random variables with a known density. These densities are then used to construct a QCD-based statistic that triggers an alarm as soon as the statistic exceeds an appropriate threshold. Numerical experiments on a stylized PJM testbed demonstrate rapid line outage identification from public streams of electricity demand and price data.", "AI": {"tldr": "提出一种基于参数化最快变化检测理论的电力系统停电识别方法，利用市场信号（如电力需求和价格）来快速检测停电事件。", "motivation": "电力系统停电给市场参与者带来巨大的财务风险，需要快速检测和对冲。", "method": "利用参数化最快变化检测（QCD）理论，将市场信号分解为具有已知概率密度的参数化随机变量，并构建基于QCD的统计量来检测变化。", "result": "在PJM测试平台上进行数值实验，证明了该方法能够从公开的市场数据流中快速识别线路停电。", "conclusion": "所提出的基于参数化QCD的停电识别方法能够有效地从公开的市场信号中快速检测电力系统停电事件。"}}
{"id": "2601.12294", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12294", "abs": "https://arxiv.org/abs/2601.12294", "authors": ["Dawei Li", "Yuguang Yao", "Zhen Tan", "Huan Liu", "Ruocheng Guo"], "title": "ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents", "comment": "under review", "summary": "Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.", "AI": {"tldr": "本文提出了ToolPRMBench，一个用于评估工具使用智能体中的过程奖励模型（PRMs）的大规模基准。该基准通过将现有工具使用基准的智能体轨迹转换为包含详细信息的步骤级测试用例，并利用多LLM验证管道确保数据质量，来系统地评估PRMs。实验表明，不同PRMs的有效性存在显著差异，并且针对工具使用的专用PRMs具有巨大潜力。", "motivation": "现有研究缺乏对工具使用场景中的过程奖励模型（PRMs）进行系统和可靠评估的基准，这阻碍了PRMs在增强工具使用智能体方面的潜力。因此，需要一个专门的基准来评估和比较不同PRMs在工具使用任务中的性能。", "method": "构建了一个名为ToolPRMBench的大规模基准。该基准基于多个代表性的工具使用基准，将智能体轨迹转换为步骤级测试用例。每个测试用例包含交互历史、一个正确动作、一个似是而非但错误的替代动作以及相关的工具元数据。使用离线采样来隔离单步错误，使用在线采样来捕捉多步失败。引入了一个多LLM验证管道来减少标签噪声并保证数据质量。", "result": "在ToolPRMBench上对大型语言模型、通用PRMs和工具专用PRMs进行了广泛实验。实验结果显示，不同PRMs在工具使用任务中的有效性存在显著差异，并且专门针对工具使用的PRMs展现出更大的潜力。", "conclusion": "ToolPRMBench是一个有效的工具，可以系统地评估工具使用场景中的PRMs。实验结果证明了不同PRMs之间性能的差异，并突出了专用PRMs在提高工具使用智能体性能方面的巨大潜力。作者将公开代码和数据以促进进一步研究。"}}
{"id": "2601.12993", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12993", "abs": "https://arxiv.org/abs/2601.12993", "authors": ["Hao Luo", "Ye Wang", "Wanpeng Zhang", "Sipeng Zheng", "Ziheng Xi", "Chaoyi Xu", "Haiweng Xu", "Haoqi Yuan", "Chi Zhang", "Yiqing Wang", "Yicheng Feng", "Zongqing Lu"], "title": "Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization", "comment": "44 pages", "summary": "We introduce Being-H0.5, a foundational Vision-Language-Action (VLA) model designed for robust cross-embodiment generalization across diverse robotic platforms. While existing VLAs often struggle with morphological heterogeneity and data scarcity, we propose a human-centric learning paradigm that treats human interaction traces as a universal \"mother tongue\" for physical interaction. To support this, we present UniHand-2.0, the largest embodied pre-training recipe to date, comprising over 35,000 hours of multimodal data across 30 distinct robotic embodiments. Our approach introduces a Unified Action Space that maps heterogeneous robot controls into semantically aligned slots, enabling low-resource robots to bootstrap skills from human data and high-resource platforms. Built upon this human-centric foundation, we design a unified sequential modeling and multi-task pre-training paradigm to bridge human demonstrations and robotic execution. Architecturally, Being-H0.5 utilizes a Mixture-of-Transformers design featuring a novel Mixture-of-Flow (MoF) framework to decouple shared motor primitives from specialized embodiment-specific experts. Finally, to make cross-embodiment policies stable in the real world, we introduce Manifold-Preserving Gating for robustness under sensory shift and Universal Async Chunking to universalize chunked control across embodiments with different latency and control profiles. We empirically demonstrate that Being-H0.5 achieves state-of-the-art results on simulated benchmarks, such as LIBERO (98.9%) and RoboCasa (53.9%), while also exhibiting strong cross-embodiment capabilities on five robotic platforms.", "AI": {"tldr": "本文提出了 Being-H0.5，一个基础的视觉-语言-动作 (VLA) 模型，用于在不同机器人平台之间实现稳健的跨具身泛化。该模型采用以人类为中心的学习范式，并将人类交互痕迹视为物理交互的通用“母语”，并通过 UniHand-2.0 数据集支持。Being-H0.5 引入了统一动作空间、基于 Transformer 的架构（包含 MoF）以及 Manifold-Preserving Gating 和 Universal Async Chunking 来提高鲁棒性，并在模拟和真实机器人平台上取得了最先进的性能。", "motivation": "现有 VLA 模型在面对形态异质性和数据稀缺性时表现不佳，因此需要一个能够实现跨具身泛化的模型。", "method": "提出以人类为中心的学习范式，使用 UniHand-2.0 数据集（35,000+ 小时，30 种机器人形态）进行预训练。引入统一动作空间将异构机器人控制映射到语义对齐的槽位。采用统一的序列建模和多任务预训练。架构上使用 Mixture-of-Transformers，包含新颖的 Mixture-of-Flow (MoF) 框架。引入 Manifold-Preserving Gating 和 Universal Async Chunking 以提高跨具身策略的鲁棒性。", "result": "在 LIBERO (98.9%) 和 RoboCasa (53.9%) 等模拟基准上取得了最先进的性能。在五个机器人平台上也展示了强大的跨具身能力。", "conclusion": "Being-H0.5 能够有效地实现跨具身泛化，解决了现有 VLA 模型在形态异质性和数据稀缺性方面的问题，并在模拟和真实世界的机器人任务中表现出色。"}}
{"id": "2601.11957", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11957", "abs": "https://arxiv.org/abs/2601.11957", "authors": ["Bingxuan Li", "Jeonghwan Kim", "Cheng Qian", "Xiusi Chen", "Eitan Anzenberg", "Niran Kundapur", "Heng Ji"], "title": "PEARL: Self-Evolving Assistant for Time Management with Reinforcement Learning", "comment": null, "summary": "Overlapping calendar invitations force busy professionals to repeatedly decide which meetings to attend, reschedule, or decline. We refer to this preference-driven decision process as calendar conflict resolution. Automating such process is crucial yet challenging. Scheduling logistics drain hours, and human delegation often fails at scale, which motivate we to ask: Can we trust large language model (LLM) or language agent to manager time? To enable systematic study of this question, we introduce CalConflictBench, a benchmark for long-horizon calendar conflict resolution. Conflicts are presented sequentially and agents receive feedback after each round, requiring them to infer and adapt to user preferences progressively. Our experiments show that current LLM agents perform poorly with high error rates, e.g., Qwen-3-30B-Think has 35% average error rate. To address this gap, we propose PEARL, a reinforcement-learning framework that augments language agent with an external memory module and optimized round-wise reward design, enabling agent to progressively infer and adapt to user preferences on-the-fly. Experiments on CalConflictBench shows that PEARL achieves 0.76 error reduction rate, and 55% improvement in average error rate compared to the strongest baseline.", "AI": {"tldr": "研究提出了CalConflictBench基准测试和PEARL框架，以评估和改进大型语言模型（LLM）代理在处理重叠日历邀请时的冲突解决能力。结果表明，现有LLM代理表现不佳，而PEARL通过外部记忆和优化奖励设计显著提高了性能。", "motivation": "目前的日历冲突解决过程耗时且易出错，人工干预效率低下。研究旨在探索LLM或语言代理是否能有效管理时间，以自动化这一过程。", "method": "引入CalConflictBench基准测试，模拟长时序的日历冲突解决场景，代理需逐步推断用户偏好。提出PEARL框架，将强化学习与外部记忆模块结合，并优化了逐轮奖励设计，以增强语言代理的自适应能力。", "result": "在CalConflictBench上，现有LLM代理存在较高的错误率（如Qwen-3-30B-Think平均错误率达35%）。PEARL框架相比最强基线，错误率降低了0.76，平均错误率提升了55%。", "conclusion": "LLM代理在日历冲突解决方面仍有很大改进空间。PEARL框架通过引入外部记忆和优化的奖励机制，能够有效提升语言代理在动态环境中推断和适应用户偏好的能力，从而实现更准确的日历冲突解决。"}}
{"id": "2601.12952", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12952", "abs": "https://arxiv.org/abs/2601.12952", "authors": ["Shibo Shao", "Dong Zhou", "Guanghui Sun", "Liwen Zhang", "Mingxuan Jiang"], "title": "Imitation learning-based spacecraft rendezvous and docking method with Expert Demonstration", "comment": "6 figures, 4 tables. Focus on 6-DOF spacecraft rendezvous and docking control using imitation learning-based control method", "summary": "Existing spacecraft rendezvous and docking control methods largely rely on predefined dynamic models and often exhibit limited robustness in realistic on-orbit environments. To address this issue, this paper proposes an Imitation Learning-based spacecraft rendezvous and docking control framework (IL-SRD) that directly learns control policies from expert demonstrations, thereby reducing dependence on accurate modeling. We propose an anchored decoder target mechanism, which conditions the decoder queries on state-related anchors to explicitly constrain the control generation process. This mechanism enforces physically consistent control evolution and effectively suppresses implausible action deviations in sequential prediction, enabling reliable six-degree-of-freedom (6-DOF) rendezvous and docking control. To further enhance stability, a temporal aggregation mechanism is incorporated to mitigate error accumulation caused by the sequential prediction nature of Transformer-based models, where small inaccuracies at each time step can propagate and amplify over long horizons. Extensive simulation results demonstrate that the proposed IL-SRD framework achieves accurate and energy-efficient model-free rendezvous and docking control. Robustness evaluations further confirm its capability to maintain competitive performance under significant unknown disturbances. The source code is available at https://github.com/Dongzhou-1996/IL-SRD.", "AI": {"tldr": "本文提出了一种基于模仿学习的航天器交会对接控制框架（IL-SRD），通过直接从专家演示中学习控制策略，减少了对精确模型依赖，并引入了锚定解码器目标机制和时间聚合机制来提高控制的准确性和鲁棒性。", "motivation": "现有的航天器交会对接控制方法依赖于预定义的动力学模型，在真实的在轨环境中鲁棒性有限。", "method": "提出了一种基于模仿学习的控制框架（IL-SRD），包括锚定解码器目标机制（用于约束控制生成过程，确保物理上一致的控制演化）和时间聚合机制（用于减轻Transformer模型的误差累积）。", "result": "IL-SRD框架实现了精确且节能的无模型交会对接控制，并在存在未知干扰的情况下表现出良好的鲁棒性。", "conclusion": "IL-SRD框架能够实现可靠的六自由度交会对接控制，减少了对精确模型的需求，并且在复杂环境下具有良好的稳定性和鲁棒性。"}}
{"id": "2601.11907", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11907", "abs": "https://arxiv.org/abs/2601.11907", "authors": ["Prosenjit Chatterjee", "ANK Zaman"], "title": "Towards Airborne Object Detection: A Deep Learning Analysis", "comment": null, "summary": "The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.", "AI": {"tldr": "该研究提出了一种基于EfficientNetB4的双任务模型，可以同时对空降目标进行分类并预测其威胁等级，并在AODTA和AVD数据集上取得了良好的性能。", "motivation": "现有空降威胁评估系统依赖于手动监控，效率低下且难以扩展，因此需要开发实时、自动化的系统。", "method": "开发了一个基于EfficientNetB4的双任务模型，用于同时执行空降目标分类和威胁等级预测。为了解决训练数据不足的问题，构建了AODTA数据集。在AVD和AODTA数据集上对模型进行了基准测试，并与ResNet-50模型进行了比较。", "result": "EfficientNetB4模型在目标分类方面达到了96%的准确率，在威胁等级预测方面达到了90%的准确率。与ResNet-50相比，EfficientNetB4性能更优。", "conclusion": "所提出的EfficientNetB4双任务模型在空降目标分类和威胁等级预测方面表现出很高的潜力，可应用于监视、防御和空域管理等领域。需要注意的是，该研究的重点是利用已有的数据集进行分类和威胁等级推断，而不是目标检测。"}}
{"id": "2601.13273", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13273", "abs": "https://arxiv.org/abs/2601.13273", "authors": ["Theodor-Gabriel Nicu", "Florin Stoican", "Daniel-Mihail Ioan", "Ionela Prodan"], "title": "Safe Navigation in Cluttered Environments Via Spline-Based Harmonic Potential Fields", "comment": null, "summary": "We provide a complete motion-planning mechanism that ensures target tracking and obstacle avoidance in a cluttered environment. For a given polyhedral decomposition of the feasible space, we adopt a novel procedure that constrains the agent to move only through a prescribed sequence of cells via a suitable control policy.\n  For each cell, we construct a harmonic potential surface induced by a Dirichlet boundary condition given as a cardinal B-spline curve. A detailed analysis of the curve behavior (periodicity, support) and of the associated control point selection allows us to explicitly compute these harmonic potential surfaces, from which we subsequently derive the corresponding control policy. We illustrate that the resulting construction funnels the agent safely along the chain of cells from the starting point to the target.", "AI": {"tldr": "本文提出了一种用于避障和目标跟踪的运动规划机制，该机制通过控制智能体在预设的细胞序列中移动来实现。利用调和势函数和 B-样条曲线来定义每个细胞内的控制策略，从而保证智能体安全地从起点到达目标。", "motivation": "在杂乱环境中实现智能体的安全导航，同时进行目标跟踪和避障。", "method": "1. 对可行空间进行多面体分解。 2. 约束智能体仅通过预定的细胞序列移动。 3. 为每个细胞构造由狄利克雷边界条件（基数 B-样条曲线）引起的调和势表面。 4. 分析 B-样条曲线的行为并选择控制点以显式计算调和势表面。 5. 从调和势表面导出控制策略。", "result": "所提出的方法能够将智能体安全地引导通过细胞链，从起点到达目标，同时实现避障和目标跟踪。", "conclusion": "该运动规划机制有效地解决了在杂乱环境中进行避障和目标跟踪的问题，通过构建调和势函数和利用 B-样条曲线，能够显式计算控制策略，保证智能体的安全导航。"}}
{"id": "2601.12310", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12310", "abs": "https://arxiv.org/abs/2601.12310", "authors": ["Jennifer Dodgson", "Alfath Daryl Alhajir", "Michael Joedhitya", "Akira Rafhael Janson Pattirane", "Surender Suresh Kumar", "Joseph Lim", "C. H. Peh", "Adith Ramdas", "Steven Zhang Zhexu"], "title": "Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection", "comment": null, "summary": "Self-training systems often degenerate due to the lack of an external criterion for judging data quality, leading to reward hacking and semantic drift. This paper provides a proof-of-concept system architecture for stable self-training under sparse external feedback and bounded memory, and empirically characterises its learning dynamics and failure modes.\n  We introduce a self-training architecture in which learning is mediated exclusively by environmental viability, rather than by reward, objective functions, or externally defined fitness criteria. Candidate behaviours are executed under real resource constraints, and only those whose environmental effects both persist and preserve the possibility of future interaction are propagated. The environment does not provide semantic feedback, dense rewards, or task-specific supervision; selection operates solely through differential survival of behaviours as world-altering events, making proxy optimisation impossible and rendering reward-hacking evolutionarily unstable.\n  Analysis of semantic dynamics shows that improvement arises primarily through the persistence of effective and repeatable strategies under a regime of consolidation and pruning, a paradigm we refer to as negative-space learning (NSL), and that models develop meta-learning strategies (such as deliberate experimental failure in order to elicit informative error messages) without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalisable autonomous systems without reliance on human-curated data or complex reward shaping.", "AI": {"tldr": "提出了一种名为“负空间学习”（NSL）的自训练系统架构，它不依赖奖励函数或外部评估标准，而是通过环境生存能力进行学习，从而实现稳定和开放式的自我改进。", "motivation": "现有的自训练系统容易因缺乏外部质量判断标准而导致奖励破解和语义漂移，本研究旨在解决此问题，构建更稳定、可泛化的自训练系统。", "method": "设计了一个完全由环境可行性驱动的自训练架构。候选行为在资源受限的环境中执行，只有那些能产生持久性环境影响并保留未来交互可能性的行为才会被保留。学习过程通过“负空间学习”（NSL）范式实现，即通过持续的有效策略和修剪来促进改进，并且系统能够发展出元学习策略。", "result": "实验表明，所提出的系统架构能够实现稳定学习，并且模型能自发发展出如故意实验失败以获取错误信息等元学习策略。改进主要来源于有效和可重复策略在巩固和修剪机制下的持久性。", "conclusion": "基于环境的生存选择（NSL）可以实现可持续的、开放式的自我改进，为在没有人类标注数据或复杂奖励塑造的情况下构建更鲁棒和可泛化的自主系统提供了可行途径。"}}
{"id": "2601.13042", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13042", "abs": "https://arxiv.org/abs/2601.13042", "authors": ["Yijun Zhou", "Muhan Hou", "Kim Baraka"], "title": "Static Is Not Enough: A Comparative Study of VR and SpaceMouse in Static and Dynamic Teleoperation Tasks", "comment": "5 pages, 5 figures. Accepted in HRI'26 (Late-Breaking Reports track) in 12 Jan, 2026", "summary": "Imitation learning relies on high-quality demonstrations, and teleoperation is a primary way to collect them, making teleoperation interface choice crucial for the data. Prior work mainly focused on static tasks, i.e., discrete, segmented motions, yet demonstrations also include dynamic tasks requiring reactive control. As dynamic tasks impose fundamentally different interface demands, insights from static-task evaluations cannot generalize. To address this gap, we conduct a within-subjects study comparing a VR controller and a SpaceMouse across two static and two dynamic tasks ($N=25$). We assess success rate, task duration, cumulative success, alongside NASA-TLX, SUS, and open-ended feedback. Results show statistically significant advantages for VR: higher success rates, particularly on dynamic tasks, shorter successful execution times across tasks, and earlier successes across attempts, with significantly lower workload and higher usability. As existing VR teleoperation systems are rarely open-source or suited for dynamic tasks, we release our VR interface to fill this gap.", "AI": {"tldr": "在一项包含 25 名参与者的研究中，虚拟现实 (VR) 控制器在完成静态和动态任务的远程操作时，比 SpaceMouse 表现出更高的成功率、更短的执行时间、更低的工作负荷和更高的可用性，尤其是在动态任务上。作者发布了一个适用于动态任务的开源 VR 界面。", "motivation": "现有关于远程操作界面的研究主要集中在静态任务上，但动态任务对界面有不同的需求，因此需要针对动态任务进行专门评估。选择合适的远程操作界面对于收集高质量的模仿学习数据至关重要。", "method": "进行了一项被试内研究，比较了 VR 控制器和 SpaceMouse 在两项静态任务和两项动态任务中的表现。研究招募了 25 名参与者，并评估了成功率、任务时长、累积成功以及使用 NASA-TLX、SUS 和开放式反馈来衡量工作负荷和可用性。", "result": "VR 控制器在成功率（尤其是在动态任务上）、成功执行任务的时长以及早期成功率方面均显示出统计学上的显著优势。参与者在使用 VR 控制器时，工作负荷显著降低，可用性显著提高。", "conclusion": "VR 控制器是执行需要反应式控制的动态任务的远程操作的更优选择。作者发布了一个开源的 VR 界面，以支持未来在动态任务上的远程操作研究。"}}
{"id": "2601.13615", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13615", "abs": "https://arxiv.org/abs/2601.13615", "authors": ["Lifu Ding", "Chunhui Hou", "Yutong Li", "Qinmin Yang"], "title": "Resilient Hierarchical Power Control for Hybrid GFL/GFM Microgrids Under Mixed Cyber-Attacks and Physical Constraints", "comment": null, "summary": "Hybrid microgrids integrating Grid-Following (GFL) and Grid-Forming (GFM) inverters present complex control challenges arising from the decoupling between long-term economic dispatch and real-time dynamic regulation, as well as the distinct physical limitations of heterogeneous inverters under cyber uncertainties. This paper proposes a Resilient Hierarchical Power Control (RHPC) strategy to unify these conflicting requirements within a cohesive framework. A standardized power increment mechanism is developed to bridge the tertiary and secondary layers, ensuring that real-time load fluctuations are compensated strictly according to the optimal economic ratios derived from the tertiary layer. To address the strict active power saturation constraints of GFL units, a dynamic activation scheme coupled with projection operators is introduced, which actively isolates saturated nodes from the consensus loop to prevent integrator wind-up and preserve the stability of the GFM backbone. Furthermore, the proposed framework incorporates a multi-scale attention mechanism and LSTM-based predictors into the secondary control protocol, endowing the system with robustness against unbounded False Data Injection (FDI) attacks and packet losses. Rigorous theoretical analysis confirms that the system achieves Uniformly Ultimately Bounded (UUB) convergence, and simulations on a modified IEEE 33-bus system demonstrate that the proposed strategy significantly improves power sharing accuracy and operational resilience in both grid-connected and islanded modes compared to conventional methods.", "AI": {"tldr": "提出了一种混合微电网的弹性分层功率控制（RHPC）策略，通过标准化的功率增量机制、动态激活方案和基于LSTM的预测器，有效协调经济调度和动态调压，并提高对网络攻击的鲁棒性。", "motivation": "混合微电网中GFL和GFM逆变器控制的复杂性，以及经济调度与动态调压之间的冲突，以及异构逆变器在网络不确定性下的物理限制。", "method": "提出了弹性分层功率控制（RHPC）策略，包括标准化的功率增量机制（连接三级和二级控制）、动态激活方案和投影算子（处理GFL饱和）、以及多尺度注意力机制和LSTM预测器（应对FDI攻击和丢包）。", "result": "理论分析证明系统实现了UUB收敛。仿真结果表明，与传统方法相比，RHPC策略显著提高了功率共享精度和运行弹性，在并网和孤岛模式下均表现优异。", "conclusion": "RHPC策略成功地在混合微电网中统一了经济调度和动态调压的需求，并提高了系统对网络攻击和动态变化的鲁棒性。"}}
{"id": "2601.11898", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11898", "abs": "https://arxiv.org/abs/2601.11898", "authors": ["Yilmaz Korkmaz", "Vishal M. Patel"], "title": "RemoteVAR: Autoregressive Visual Modeling for Remote Sensing Change Detection", "comment": null, "summary": "Remote sensing change detection aims to localize and characterize scene changes between two time points and is central to applications such as environmental monitoring and disaster assessment. Meanwhile, visual autoregressive models (VARs) have recently shown impressive image generation capability, but their adoption for pixel-level discriminative tasks remains limited due to weak controllability, suboptimal dense prediction performance and exposure bias. We introduce RemoteVAR, a new VAR-based change detection framework that addresses these limitations by conditioning autoregressive prediction on multi-resolution fused bi-temporal features via cross-attention, and by employing an autoregressive training strategy designed specifically for change map prediction. Extensive experiments on standard change detection benchmarks show that RemoteVAR delivers consistent and significant improvements over strong diffusion-based and transformer-based baselines, establishing a competitive autoregressive alternative for remote sensing change detection. Code will be available \\href{https://github.com/yilmazkorkmaz1/RemoteVAR}{\\underline{here}}.", "AI": {"tldr": "本文提出了RemoteVAR，一种基于视觉自回归模型的遥感影像变化检测新框架，通过多分辨率融合特征和交叉注意力机制，以及专门设计的自回归训练策略，提高了变化图预测的准确性，并在基准测试中取得了优于现有方法的性能。", "motivation": "现有视觉自回归模型在像素级判别任务（如变化检测）中存在可控性差、密集预测性能不佳和暴露偏差等问题，限制了其在该领域的应用。遥感影像变化检测在环境监测和灾害评估等领域至关重要，需要更有效的模型。", "method": "提出RemoteVAR框架，该框架的核心在于：1. 通过交叉注意力机制将多分辨率融合的双时相特征条件化到自回归预测中；2. 采用专门为变化图预测设计的自回归训练策略。", "result": "在标准的遥感影像变化检测基准数据集上进行的广泛实验表明，RemoteVAR相比于强大的基于扩散模型和Transformer的模型基线，展现出了一致且显著的性能提升。", "conclusion": "RemoteVAR成功克服了现有视觉自回归模型在遥感影像变化检测中的局限性，提供了一种具有竞争力的自回归方法，能够在该领域实现高性能的变化检测。"}}
{"id": "2601.11969", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11969", "abs": "https://arxiv.org/abs/2601.11969", "authors": ["Zecheng Tang", "Baibei Ji", "Ruoxi Sun", "Haitian Wang", "WangJie You", "Zhang Yijun", "Wenpeng Zhu", "Ji Qi", "Juntao Li", "Min Zhang"], "title": "$\\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models", "comment": null, "summary": "Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.", "AI": {"tldr": "本文提出了 $\texttt{MemoryRewardBench}$，这是第一个系统性评估奖励模型（RM）在长上下文记忆管理能力方面的基准。该基准包含多种长上下文理解和生成任务，覆盖了 8K 到 128K token 的上下文长度。实验结果表明，新一代 RM 模型在评估 LLM 记忆管理方面表现出色的能力和局限性，并且开源模型和闭源模型的性能差距正在缩小。", "motivation": "随着大型语言模型（LLM）处理长上下文的需求日益增长，有效的记忆管理成为关键。然而，目前缺乏一个系统性的评估框架来衡量奖励模型（RM）在评估 LLM 记忆管理方面的能力，因此研究者们开发了 $\texttt{MemoryRewardBench}$。", "method": "作者构建了一个名为 $\texttt{MemoryRewardBench}$ 的基准，该基准包含了 10 种不同的长上下文记忆管理设置，涵盖了长上下文理解和长格式生成任务，上下文长度从 8K 到 128K token 不等。他们使用 13 个最新的奖励模型对该基准进行了评估。", "result": "评估结果显示，新一代的奖励模型（无论参数量大小）普遍优于其前代模型。此外，开源模型和闭源模型在评估 LLM 记忆管理方面的性能差距逐渐缩小。研究还揭示了当前奖励模型在评估不同场景下的 LLM 记忆管理能力方面的优势和根本性限制。", "conclusion": "$\texttt{MemoryRewardBench}$ 是一个重要的基准，它首次系统地评估了奖励模型在长上下文记忆管理方面的能力。研究结果表明，尽管新一代奖励模型表现出色，但在评估 LLM 记忆管理方面仍存在局限性，这为未来的研究提供了方向。"}}
{"id": "2601.11909", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11909", "abs": "https://arxiv.org/abs/2601.11909", "authors": ["Io Yamada", "Hirotsugu Okuno"], "title": "Effects of the retina-inspired light intensity encoding on color discrimination performance", "comment": "8 pages, 14 figures, 4 tables", "summary": "Color is an important source of information for visual functions such as object recognition, but it is greatly affected by the color of illumination. The ability to perceive the color of a visual target independent of illumination color is called color constancy (CC), and is an important feature for vision systems that use color information. In this study, we investigated the effects of the light intensity encoding function on the performance of CC of the center/surround (C/S) retinex model, which is a well-known model inspired by CC of the visual nervous system. The functions used to encode light intensity are the logarithmic function used in the original C/S retinex model and the Naka-Rushton (N-R) function, which is a model of retinal photoreceptor response. Color-variable LEDs were used to illuminate visual targets with various lighting colors, and color information computed by each model was used to evaluate the degree to which the color of visual targets illuminated with different lighting colors could be discriminated. Color information was represented using the HSV color space and a color plane based on the classical opponent color theory. The results showed that the combination of the N-R function and the double opponent color plane representation provided superior discrimination performance.", "AI": {"tldr": "研究了光照强度编码函数对中心/环绕 (C/S) Retinex 模型颜色恒常性 (CC) 性能的影响，发现 Naka-Rushton (N-R) 函数与双 opponent 色平面表示结合可以提高颜色辨别能力。", "motivation": "颜色恒常性（CC）是视觉系统的重要特征，但会受到照明颜色的影响。本研究旨在探究光照强度编码函数如何影响基于视觉神经系统 CC 启发的 C/S Retinex 模型的 CC 性能。", "method": "使用中心/环绕 (C/S) Retinex 模型，比较了原始模型中的对数函数和模拟视网膜光感受器响应的 Naka-Rushton (N-R) 函数。通过使用彩色 LED 照明目标，并在 HSV 色彩空间和基于拮抗色理论的色彩平面上表示计算出的颜色信息，来评估不同光照下目标颜色的可辨别性。", "result": "结果表明，Naka-Rushton (N-R) 函数与双 opponent 色平面表示相结合的模型，在不同光照颜色下实现了优于对数函数模型的颜色辨别性能。", "conclusion": "Naka-Rushton (N-R) 光照强度编码函数与双 opponent 色平面表示的结合，能够显著提升 C/S Retinex 模型在应对不同照明颜色时的颜色恒常性性能，使其在颜色辨别上表现更佳。"}}
{"id": "2601.11910", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11910", "abs": "https://arxiv.org/abs/2601.11910", "authors": ["Guiying Zhu", "Bowen Yang", "Yin Zhuang", "Tong Zhang", "Guanqun Wang", "Zhihao Che", "He Chen", "Lianlin Li"], "title": "A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection", "comment": null, "summary": "Open-Vocabulary Object Detection (OVOD) aims to develop the capability to detect anything. Although myriads of large-scale pre-training efforts have built versatile foundation models that exhibit impressive zero-shot capabilities to facilitate OVOD, the necessity of creating a universal understanding for any object cognition according to already pretrained foundation models is usually overlooked. Therefore, in this paper, a training-free Guess What Vision Language Model, called GW-VLM, is proposed to form a universal understanding paradigm based on our carefully designed Multi-Scale Visual Language Searching (MS-VLS) coupled with Contextual Concept Prompt (CCP) for OVOD. This approach can engage a pre-trained Vision Language Model (VLM) and a Large Language Model (LLM) in the game of \"guess what\". Wherein, MS-VLS leverages multi-scale visual-language soft-alignment for VLM to generate snippets from the results of class-agnostic object detection, while CCP can form the concept of flow referring to MS-VLS and then make LLM understand snippets for OVOD. Finally, the extensive experiments are carried out on natural and remote sensing datasets, including COCO val, Pascal VOC, DIOR, and NWPU-10, and the results indicate that our proposed GW-VLM can achieve superior OVOD performance compared to the-state-of-the-art methods without any training step.", "AI": {"tldr": "提出了一种名为GW-VLM的无需训练的方法，通过多尺度视觉语言搜索（MS-VLS）和上下文概念提示（CCP）来增强预训练的视觉语言模型（VLM）和大型语言模型（LLM）的开放词汇目标检测（OVOD）能力。", "motivation": "现有的预训练模型在OVOD方面表现出色，但通常忽略了为任何对象认知构建通用理解的必要性。", "method": "设计了一个名为GW-VLM的无需训练的框架，包含MS-VLS和CCP。MS-VLS利用多尺度视觉语言软对齐，从类无关的目标检测结果生成片段。CCP则根据MS-VLS形成概念流，使LLM能够理解这些片段以进行OVOD。", "result": "在COCO val、Pascal VOC、DIOR和NWPU-10等数据集上进行了实验，结果表明GW-VLM在OVOD方面取得了优于最先进方法的性能，并且无需任何训练。", "conclusion": "GW-VLM提供了一种有效的、无需训练的范式，通过利用预训练的VLM和LLM，实现通用的开放词汇目标检测。"}}
{"id": "2601.12323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12323", "abs": "https://arxiv.org/abs/2601.12323", "authors": ["Yin Cai", "Zhouhong Gu", "Juntao Zhang", "Ping Chen"], "title": "MARO: Learning Stronger Reasoning from Social Interaction", "comment": null, "summary": "Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.", "AI": {"tldr": "本文提出了一种名为MARO的多智能体奖励优化方法，通过在多智能体社交环境中学习和练习，增强大型语言模型（LLMs）的推理能力，并证明了这种社交模拟学习能够迁移到其他任务。", "motivation": "现有的大型语言模型训练方法主要依赖文本内容或预设问题，缺乏在涉及互动、谈判和竞争的真实场景中的经验。作者旨在解决这一局限性。", "method": "MARO通过以下三个关键方面解决问题：1. 通过将最终的成功或失败结果分解到交互过程中的具体行为，来解决稀疏学习信号问题；2. 通过平衡不同角色的训练样本权重，来处理不均衡的角色分配问题；3. 通过直接评估每个行为的效用，来解决环境不稳定性问题。", "result": "实验表明，MARO在社交推理能力方面取得了显著的改进。此外，通过社交模拟学习获得的技能能够有效地迁移到数学推理和指令遵循等其他任务。", "conclusion": "多智能体社交学习在提升LLMs的通用推理能力方面具有巨大的潜力，MARO方法能够有效实现这一点。"}}
{"id": "2601.13096", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13096", "abs": "https://arxiv.org/abs/2601.13096", "authors": ["Muhayy Ud Din", "Waseem Akram", "Ahsan B. Bakht", "Irfan Hussain"], "title": "LLM-VLM Fusion Framework for Autonomous Maritime Port Inspection using a Heterogeneous UAV-USV System", "comment": "submitted in AEJ", "summary": "Maritime port inspection plays a critical role in ensuring safety, regulatory compliance, and operational efficiency in complex maritime environments. However, existing inspection methods often rely on manual operations and conventional computer vision techniques that lack scalability and contextual understanding. This study introduces a novel integrated engineering framework that utilizes the synergy between Large Language Models (LLMs) and Vision Language Models (VLMs) to enable autonomous maritime port inspection using cooperative aerial and surface robotic platforms. The proposed framework replaces traditional state-machine mission planners with LLM-driven symbolic planning and improved perception pipelines through VLM-based semantic inspection, enabling context-aware and adaptive monitoring. The LLM module translates natural language mission instructions into executable symbolic plans with dependency graphs that encode operational constraints and ensure safe UAV-USV coordination. Meanwhile, the VLM module performs real-time semantic inspection and compliance assessment, generating structured reports with contextual reasoning. The framework was validated using the extended MBZIRC Maritime Simulator with realistic port infrastructure and further assessed through real-world robotic inspection trials. The lightweight on-board design ensures suitability for resource-constrained maritime platforms, advancing the development of intelligent, autonomous inspection systems. Project resources (code and videos) can be found here: https://github.com/Muhayyuddin/llm-vlm-fusion-port-inspection", "AI": {"tldr": "本研究提出了一种融合大语言模型（LLM）和视觉语言模型（VLM）的集成工程框架，用于自主海事港口检查，通过结合空中和水面机器人平台，实现了更智能、自适应的监控。", "motivation": "现有港口检查方法依赖手动操作和传统计算机视觉技术，存在可扩展性和上下文理解不足的问题。研究旨在通过LLM和VLM的融合，实现更智能、自适应的自主港口检查。", "method": "该框架使用LLM进行任务规划，将自然语言指令转化为符号化计划，并管理UAV-USV的协同。同时，利用VLM进行实时语义检查和合规性评估，生成带上下文推理的结构化报告。", "result": "通过MBZIRC海事模拟器和真实世界机器人试验验证了该框架的有效性。LLM驱动的规划和VLM增强的感知能力实现了上下文感知和自适应监控。", "conclusion": "研究成功构建了一个创新的LLM-VLM融合框架，实现了自主海事港口检查，其轻量级设计适用于资源受限平台，推动了智能自主检查系统的发展。"}}
{"id": "2601.12318", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12318", "abs": "https://arxiv.org/abs/2601.12318", "authors": ["Dehao Ying", "Fengchang Yu", "Haihua Chen", "Changjiang Jiang", "Yurong Li", "Wei Lu"], "title": "Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence", "comment": null, "summary": "The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. To fill this gap, this survey establishes the first comprehensive technical map for data generation in DI. Data generation is redefined as supervisory signal production, and a novel taxonomy is introduced based on the \"availability of data and labels.\" This framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. Furthermore, a multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. Guided by this unified structure, the methodological landscape is dissected to reveal critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems. Ultimately, by systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.", "AI": {"tldr": "本文survey了文档智能（DI）领域的数据生成方法，提出了一个基于“数据和标签可用性”的新分类法，将现有方法分为数据增强、从零生成、自动标注和自监督信号构建四类，并建立了一个评估框架，旨在推动DI的发展。", "motivation": "现有关于DI数据生成的研究过于零散，仅关注单一模态或特定任务，未能提供一个统一的视角来适应实际工作流程。因此，需要一个全面的技术地图来填补这一空白。", "method": "作者重新定义了数据生成为“监督信号生产”，并基于“数据和标签的可用性”引入了一个新的分类法，将方法分为数据增强、从零生成、自动标注和自监督信号构建四种资源中心范式。同时，建立了一个多层次的评估框架，整合了内在质量和外在效用。", "result": "通过上述框架，作者对方法学进行了梳理，揭示了保真度差距等关键挑战，并指出了共同进化生态系统等前沿方向。文章还展示了在不同DI基准测试中的性能提升。", "conclusion": "本文通过系统化DI数据生成领域，将其定位为下一代DI的核心引擎，为未来的研究和发展提供了指导。"}}
{"id": "2601.13753", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13753", "abs": "https://arxiv.org/abs/2601.13753", "authors": ["Yiwei Zhou", "Zhongcheng Lei", "Xiaoran Dai", "Wenshan Hu", "Hong Zhou"], "title": "Research on Adaptive Inertial Control in Synchronization Systems: Based on Variational Optimization Methods and Their Applications in the Stability of Complex Networks", "comment": "36 pages, 4 figures", "summary": "Aiming at the core problem that it is difficult for a fixed inertia coefficient to balance transient disturbance suppression and long-term stability in complex network synchronization systems, an adaptive inertia control strategy based on variational optimization is proposed. Taking the Kuramoto model with inertia as the research carrier, the analytical expression of the time-varying inertia coefficient M(t) is strictly derived by the functional variational method, and a hierarchical control structure of \"benchmark inertia + disturbance feedback\" is constructed to achieve the organic unity of minimizing the vulnerability performance function H(T) and stability constraints. A multimodal decoupling control strategy based on Laplacian eigenvector projection is designed to enhance the feedback strength of the dominant mode by eigenvalue weighting, improving the control accuracy and dynamic response speed. Simulation verification is carried out in complex network systems, and the control performance of regular networks (RG), random networks (ER), small-world networks (SW), scale-free networks (SF) and spider webs (SP) under three typical disturbances of pulses, monotonic decays and oscillatory decays is systematically analyzed. The results show that the proposed strategy reduces H(T) of the five networks by 19%-25%, shortens the relaxation time by 15%-24%, and the real parts of all system eigenvalues are less than -0.25s^-1 , meeting the asymptotic stability criterion. This study provides a new theoretical framework and engineering implementation scheme for the stability control of complex network synchronization systems, which can be widely applied to fields such as power grids, communication networks, and neural networks.", "AI": {"tldr": "提出了一种基于变分优化的自适应惯性控制策略，通过动态调整惯性系数以平衡瞬态扰动抑制和长期稳定性，并设计了多模态解耦控制以提高控制精度和响应速度，在不同复杂网络模型和扰动下验证了其有效性。", "motivation": "现有的固定惯性系数难以兼顾复杂网络同步系统中瞬态扰动抑制和长期稳定性之间的矛盾。", "method": "采用泛函变分法推导了时变惯性系数 M(t) 的解析表达式，构建了“基准惯性+扰动反馈”的分层控制结构，并设计了基于拉普拉斯特征向量投影的多模态解耦控制策略。", "result": "该策略将五种网络（RG, ER, SW, SF, SP）的性能函数 H(T) 降低了 19%-25%，缩短了弛豫时间 15%-24%，所有系统特征值实部均小于 -0.25s^-1，满足渐近稳定判据。", "conclusion": "所提出的自适应惯性控制策略能有效地在复杂网络同步系统中实现瞬态扰动抑制和长期稳定性的统一，为相关领域的稳定性控制提供了新的理论框架和工程实现方案。"}}
{"id": "2601.12019", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12019", "abs": "https://arxiv.org/abs/2601.12019", "authors": ["Chaowei Zhang", "Xiansheng Luo", "Zewei Zhang", "Yi Zhu", "Jipeng Qiang", "Longwei Wang"], "title": "Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning", "comment": null, "summary": "The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users' beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.", "AI": {"tldr": "该研究提出了一种名为SORG的框架，利用大型语言模型的“谄媚”倾向生成新闻标题的同意和反对两种推理，然后用一种基于这些推理的点击诱饵检测模型ORCD来识别点击诱饵，并在多个数据集上取得了优于现有方法的性能。", "motivation": "在线内容激增导致点击诱饵泛滥，而大型语言模型（LLMs）的“谄媚”倾向（迎合用户观点而非追求真相）阻碍了它们在解决此问题上的有效性。研究人员希望利用 LLMs 的这一特性来生成对比性推理，而不是消除它。", "method": "1. 设计SORG框架，诱导LLMs为新闻标题生成高质量的同意和反对推理对，无需真实标签。 2. 开发ORCD模型，集成三个BERT编码器来表示标题和相关推理。3. 利用对比学习，以LLM生成的置信度分数作为软标签，来增强检测鲁棒性。", "result": "在三个基准数据集上的实验表明，该方法在点击诱饵检测方面的性能持续优于LLM提示、微调的小型语言模型以及最先进的基线模型。", "conclusion": "该研究成功地利用了LLMs的“谄媚”倾向，将其转化为生成对比性推理的工具，并通过结合这些推理开发了一个有效的点击诱饵检测模型，证明了该方法的有效性和优越性。"}}
{"id": "2601.13066", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13066", "abs": "https://arxiv.org/abs/2601.13066", "authors": ["Shaya Garjani", "Ashish Cherukuri", "Bayu Jayawardhana", "Nima Monshizadeh"], "title": "Stability of Information-Based Routing in Dynamic Transportation Networks", "comment": null, "summary": "Recent studies on transportation networks have shown that real-time route guidance can inadvertently induce congestion or oscillatory traffic patterns. Nevertheless, such technologies also offer a promising opportunity to manage traffic non-intrusively by shaping the information delivered to users, thereby mitigating congestion and enhancing network stability. A key step toward this goal is to identify information signals that ensure the existence of an equilibrium with desirable stability and convergence properties. This challenge is particularly relevant when traffic density and routing dynamics evolve concurrently, as increasingly occurs with digital signaling and real-time navigation technologies. To address this, we analyze a parallel-path transportation network with a single origin-destination pair, incorporating joint traffic density and logit-based routing dynamics that evolve at the same timescale. We characterize a class of density-dependent traffic information that guarantees a unique equilibrium in the free-flow regime, ensures its asymptotic stability, and keeps traffic densities within the free-flow region for all time. The theoretical results are complemented by a numerical case study demonstrating how the framework can inform the design of traffic information that reduces total travel time without compromising credibility.", "AI": {"tldr": "本文提出了一种基于密度的交通信息设计方法，该方法能够保证交通网络的唯一稳定自由流均衡，并能在所有时间段内保持交通密度在自由流区域内。", "motivation": "现有的实时路线导航系统可能会无意中导致交通拥堵或振荡。然而，通过精心设计传递给用户的信息，可以非侵入式地管理交通，从而缓解拥堵并提高网络稳定性。关键在于找到能够保证存在具有良好稳定性和收敛性的均衡的信息信号。", "method": "研究人员分析了一个具有单一原点-目的地对的并行路径交通网络，并纳入了在同一时间尺度下演变的联合交通密度和基于 Logit 的路由动力学。他们推导出了一个密度相关的交通信息类别。", "result": "该类信息能够保证在自由流区域存在唯一均衡，并且该均衡是渐近稳定的。此外，该信息还能在所有时间段内将交通密度保持在自由流区域内。数值案例研究表明，该框架可以用于设计能够减少总旅行时间且不损害可信度的交通信息。", "conclusion": "通过设计密度依赖的交通信息，可以实现对交通网络的有效管理，保证其在自由流状态下的稳定性和可控性，并有望减少总旅行时间。"}}
{"id": "2601.13088", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13088", "abs": "https://arxiv.org/abs/2601.13088", "authors": ["Harry Huang", "Talia Xu", "Marco Zúñiga Zamalloa"], "title": "Exploiting Light To Enhance The Endurance and Navigation of Lighter-Than-Air Micro-Drones", "comment": null, "summary": "Micro-Unmanned Aerial Vehicles (UAVs) are rapidly expanding into tasks from inventory to environmental sensing, yet their short endurance and unreliable navigation in GPS-denied spaces limit deployment. Lighter-Than-Air (LTA) drones offer an energy-efficient alternative: they use a helium envelope to provide buoyancy, which enables near-zero-power drain during hovering and much longer operation. LTAs are promising, but their design is complex, and they lack integrated solutions to enable sustained autonomous operations and navigation with simple, low-infrastructure.\n  We propose a compact, self-sustaining LTA drone that uses light for both energy harvesting and navigation. Our contributions are threefold: (i) a high-fidelity simulation framework to analyze LTA aerodynamics and select a stable, efficient configuration; (ii) a framework to integrate solar cells on the envelope to provide net-positive energy; and (iii) a point-and-go navigation system with three light-seeking algorithms operating on a single light beacon.\n  Our LTA-analysis, together with the integrated solar panels, not only saves energy while flying, but also enables sustainable operation: providing 1 minute of flying time for every 4 minutes of energy harvesting, under illuminations of 80klux. We also demonstrate robust single-beacon navigation towards a light source that can be up to 7m away, in indoor and outdoor environments, even with moderate winds. The resulting system indicates a plausible path toward persistent, autonomous operation for indoor and outdoor monitoring. More broadly, this work provides a practical pathway for translating the promise of LTA drones into a persistent, self-sustaining aerial system.", "AI": {"tldr": "本文提出了一种紧凑、自给自足的软式飞艇（LTA）无人机，它利用光能进行能量收集和导航，克服了传统微型无人机续航短和GPS受限的缺点，并演示了其在光照下的可持续运行和单信标导航能力。", "motivation": "传统微型无人机在GPS受限环境中存在续航短和导航不可靠的问题。软式飞艇（LTA）是更具能效的替代方案，但其设计复杂，缺乏可持续自主运行和低基础设施导航的集成解决方案。", "method": "研究者开发了一个高保真度的模拟框架来分析LTA气动特性并优化配置；集成太阳能电池到飞艇外壳以实现净正能量；并设计了一个基于三光源追踪算法的点式导航系统。", "result": "该LTA无人机在80klux光照下，每4分钟的能量收集可提供1分钟的飞行时间，实现了可持续运行。同时，系统能够稳定地导航至7米外的光源，即使在有中度风的情况下，也能在室内外环境中实现。", "conclusion": "该研究为LTA无人机实现持久、自主和自给自足的运行提供了可行途径，特别适用于室内外监测任务，并展示了结合光能收集和光导航的实用性。"}}
{"id": "2601.13799", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13799", "abs": "https://arxiv.org/abs/2601.13799", "authors": ["Luigi Romano", "Ole Morten Aamo", "Jan Åslund", "Erik Frisk"], "title": "Linear viscoelastic rheological FrBD models", "comment": "6 pages, 3 figures. Under review at IEEE LCSS", "summary": "In [1], a new modeling paradigm for developing rate-and-state-dependent, control-oriented friction models was introduced. The framework, termed Friction with Bristle Dynamics (FrBD), combines nonlinear analytical expressions for the friction coefficient with constitutive equations for bristle-like elements. Within the FrBD framework, this letter introduces two novel formulations based on the two most general linear viscoelastic models for solids: the Generalized Maxwell (GM) and Generalized Kelvin-Voigt (GKV) elements. Both are analyzed in terms of boundedness and passivity, revealing that these properties are satisfied for any physically meaningful parametrization. An application of passivity for control design is also illustrated, considering an example from robotics. The findings of this letter systematically integrate rate-and-state dynamic friction models with linear viscoelasticity.", "AI": {"tldr": "本文提出了一种名为FrBD的新建模范式，用于开发面向控制的摩擦模型，并引入了基于广义麦克斯韦和广义开尔文-沃伊特线性粘弹性模型的两种新摩擦模型。", "motivation": "开发更精确、可控的速率和状态依赖性摩擦模型，并将其与线性粘弹性理论相结合。", "method": "提出FrBD框架，将非线性摩擦系数解析表达式与类刷状元件本构方程相结合；引入基于广义麦克斯韦（GM）和广义开尔文-沃伊特（GKV）线性粘弹性模型的两种新摩擦模型；分析了模型的有界性和耗散性；并通过机器人控制设计示例说明了耗散性在控制设计中的应用。", "result": "两种新提出的摩擦模型（基于GM和GKV）在物理参数合理的情况下满足有界性和耗散性；耗散性可用于控制设计，并在机器人应用中得到验证。", "conclusion": "该研究系统地将速率和状态动态摩擦模型与线性粘弹性相结合，为开发和控制摩擦系统提供了新的方法。"}}
{"id": "2601.12033", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12033", "abs": "https://arxiv.org/abs/2601.12033", "authors": ["Muhammad Alif Al Hakim", "Alfan Farizki Wicaksono", "Fajri Koto"], "title": "Preserving Fairness and Safety in Quantized LLMs Through Critical Weight Protection", "comment": null, "summary": "Quantization is widely adopted to reduce the computational cost of large language models (LLMs); however, its implications for fairness and safety, particularly in dynamic quantization and multilingual contexts, remain underexplored. In this work, we conduct a systematic study of how static and dynamic quantization methods impact fairness and safety across benchmarks measuring intrinsic and extrinsic bias and safety alignment. For fairness, we evaluate English, French, Dutch, Spanish, and Turkish; for safety, we focus on English, Korean, and Arabic. Our findings reveal that quantization consistently degrades fairness and safety, with dynamic methods demonstrating greater stability than static ones. Moreover, fairness degradation varies across languages, while safety deterioration is especially pronounced in non-English settings. To address these risks, we introduce Critical Weight Protection, a novel technique that identifies and preserves fairness- and safety-critical weights during quantization. This approach effectively mitigates bias and safety deterioration without costly retraining or alignment, maintaining trustworthiness while retaining efficiency.", "AI": {"tldr": "本研究系统地研究了静态和动态量化对大型语言模型（LLMs）在多语言环境下的公平性和安全性的影响，并提出了一种名为“关键权重保护”的新技术来缓解这些负面影响。", "motivation": "现有研究主要关注量化对LLMs计算效率的提升，而忽略了其对公平性和安全性的影响，尤其是在动态量化和多语言场景下。", "method": "作者系统地评估了静态和动态量化方法在多种语言（英语、法语、荷兰语、西班牙语、土耳其语、韩语、阿拉伯语）上的公平性和安全性。在此基础上，提出了一种“关键权重保护”技术，通过识别并保护量化过程中的关键权重来缓解负面影响。", "result": "研究发现，量化普遍会损害LLMs的公平性和安全性。动态量化比静态量化更稳定。公平性损害因语言而异，而安全性损害在非英语语种中尤为严重。提出的“关键权重保护”技术能有效缓解公平性和安全性下降的问题，且无需昂贵的再训练或对齐。", "conclusion": "量化虽然能提高LLMs的效率，但会损害其公平性和安全性。动态量化相对更优。针对此问题，提出的“关键权重保护”技术是一种有效且高效的解决方案，能够在不影响效率的情况下提升LLMs的可信度。"}}
{"id": "2601.13810", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13810", "abs": "https://arxiv.org/abs/2601.13810", "authors": ["Ruixing Ren"], "title": "Integrated Sensing and Communication for Low-Altitude Security", "comment": "6 pages, 5 figures; This paper presents a forward-looking perspective on the application of ISAC technology in low-altitude security governance, addressing challenges posed by low-altitude, slow-speed, and small-size targets", "summary": "The dense concentration of low-altitude, slow-speed, and small-size targets in the complex low-altitude environment poses significant security challenges, including failures in continuous wide-area sensing and ambiguous target intent, which existing regulatory frameworks struggle to address. Integrated sensing and communication (ISAC), a hallmark of next-generation mobile communication, offers a transformative approach to low-altitude security governance. By leveraging existing cellular infrastructure and spectrum resources, ISAC enables the construction of a seamless wide-area sensing network, supports intelligent feature extraction and intent inference, facilitates real-time collaborative decision-making, and establishes a dynamic trust authentication framework. This article systematically reviews the technical system, analyzes the security challenges, forecasts the enabling value of ISAC, and discusses the resulting open problems and challenges, thereby laying a foundation for future research and industrial implementation.", "AI": {"tldr": "本文综述了集成感知与通信（ISAC）技术在低空安全治理中的应用，分析了现有挑战，并提出了ISAC的潜在价值和未来研究方向。", "motivation": "现有监管框架难以应对低空慢小目标带来的安全挑战，如大范围连续感知失效和目标意图模糊。", "method": "本文系统性地回顾了ISAC技术体系，分析了低空安全面临的挑战，并预测了ISAC在此领域的赋能价值。", "result": "ISAC技术可以通过利用现有蜂窝基础设施和频谱资源，构建无缝广域感知网络，实现智能特征提取、意图推断、实时协同决策和动态信任认证。", "conclusion": "ISAC技术有望为低空安全治理提供一种变革性的解决方案，但也存在开放性问题和挑战需要进一步研究和解决，为未来研究和工业应用奠定基础。"}}
{"id": "2601.11911", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11911", "abs": "https://arxiv.org/abs/2601.11911", "authors": ["Muhammad Ibrahim", "Alfe Suny", "MD Sakib Ul Islam", "Md. Imran Hossain"], "title": "Reliable Deep Learning for Small-Scale Classifications: Experiments on Real-World Image Datasets from Bangladesh", "comment": null, "summary": "Convolutional neural networks (CNNs) have achieved state-of-the-art performance in image recognition tasks but often involve complex architectures that may overfit on small datasets. In this study, we evaluate a compact CNN across five publicly available, real-world image datasets from Bangladesh, including urban encroachment, vehicle detection, road damage, and agricultural crops. The network demonstrates high classification accuracy, efficient convergence, and low computational overhead. Quantitative metrics and saliency analyses indicate that the model effectively captures discriminative features and generalizes robustly across diverse scenarios, highlighting the suitability of streamlined CNN architectures for small-class image classification tasks.", "AI": {"tldr": "一项研究评估了一个紧凑型卷积神经网络（CNN）在五个孟加拉国的真实世界图像数据集上的表现，结果表明该模型在小样本分类任务中具有高精度、快速收敛和低计算开销的优点。", "motivation": "现有的卷积神经网络（CNN）在图像识别任务中表现优异，但其复杂的架构可能在小数据集上出现过拟合。因此，研究者希望评估一种更紧凑的CNN架构在小样本、真实世界图像分类任务中的适用性。", "method": "使用一个紧凑型的CNN架构，并在五个公开的、来自孟加拉国的真实世界图像数据集上进行评估。数据集涵盖了城市扩张、车辆检测、道路损坏和农作物等多种场景。通过定量指标和显著性分析来评估模型的分类精度、收敛速度、计算开销以及特征提取能力。", "result": "该紧凑型CNN在所有五个数据集上都取得了较高的分类准确率，并且收敛速度快，计算开销低。显著性分析表明，模型能够有效捕捉到具有区分性的特征，并在不同的应用场景中表现出良好的泛化能力。", "conclusion": "研究证明，对于小样本的图像分类任务，精简的CNN架构是适用且有效的。该紧凑型CNN模型在真实世界图像数据集上展现了优异的性能，为在资源受限的环境下部署图像识别技术提供了可行方案。"}}
{"id": "2601.12034", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12034", "abs": "https://arxiv.org/abs/2601.12034", "authors": ["Ziyi Zhao", "Chongming Gao", "Yang Zhang", "Haoyan Liu", "Weinan Gan", "Huifeng Guo", "Yong Liu", "Fuli Feng"], "title": "Don't Start Over: A Cost-Effective Framework for Migrating Personalized Prompts Between LLMs", "comment": "Accepted to AAAI 2026 (Oral). 9 pages, 5 figures", "summary": "Personalization in Large Language Models (LLMs) often relies on user-specific soft prompts. However, these prompts become obsolete when the foundation model is upgraded, necessitating costly, full-scale retraining. To overcome this limitation, we propose the Prompt-level User Migration Adapter (PUMA), a lightweight framework to efficiently migrate personalized prompts across incompatible models. PUMA utilizes a parameter-efficient adapter to bridge the semantic gap, combined with a group-based user selection strategy to significantly reduce training costs. Experiments on three large-scale datasets show our method matches or even surpasses the performance of retraining from scratch, reducing computational cost by up to 98%. The framework demonstrates strong generalization across diverse model architectures and robustness in advanced scenarios like chained and aggregated migrations, offering a practical path for the sustainable evolution of personalized AI by decoupling user assets from the underlying models.", "AI": {"tldr": "提出了一种名为PUMA的轻量级框架，用于在不兼容的大语言模型（LLM）之间高效迁移个性化软提示，通过参数高效适配器和用户选择策略降低了高达98%的计算成本，同时保持甚至超越了从头训练的性能。", "motivation": "当前LLM的个性化通常依赖于用户特定的软提示，但当基础模型升级时，这些提示会过时，需要昂贵的完全重新训练。研究旨在解决这一问题，提供一种高效迁移个性化提示的方法。", "method": "提出了一种名为Prompt-level User Migration Adapter (PUMA) 的框架。PUMA采用参数高效的适配器来弥合语义差距，并结合基于组的用户选择策略来降低训练成本。", "result": "在三个大规模数据集上的实验表明，PUMA方法在性能上可以与从头重新训练相媲美，甚至超越，并将计算成本降低了高达98%。该框架在不同的模型架构之间表现出强大的泛化能力，并且在链式和聚合迁移等高级场景中具有鲁棒性。", "conclusion": "PUMA提供了一种实用的方法，通过将用户资产与底层模型解耦，为个性化AI的可持续发展提供了一条途径，解决了模型升级导致个性化提示过时的问题。"}}
{"id": "2601.12392", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12392", "abs": "https://arxiv.org/abs/2601.12392", "authors": ["Zhentao Xia", "Yongqi Fan", "Yuxiang Chu", "Yichao Yin", "Liangliang Chen", "Tong Ruan", "Weiyan Zhang"], "title": "PsychēChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling", "comment": null, "summary": "Large language models (LLMs) have demonstrated notable advancements in psychological counseling. However, existing models generally do not explicitly model seekers' emotion shifts across counseling sessions, a core focus in classical psychological schools. Moreover, how to align counselor models' responses with these emotion shifts while proactively mitigating safety risks remains underexplored. To bridge these gaps, we propose PsychēChat, which explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. Specifically, we employ interactive role-playing to synthesize counselor--seeker dialogues, incorporating two modules: Emotion Management Module, to capture seekers' current emotions and emotion shifts; and Risk Control Module, to anticipate seekers' subsequent reactions and identify potential risks. Furthermore, we introduce two modeling paradigms. The Agent Mode structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline. The LLM Mode integrates these stages into a unified chain-of-thought for end-to-end inference, balancing efficiency and performance. Extensive experiments, including interactive scoring, dialogue-level evaluation, and human assessment, demonstrate that PsychēChat outperforms existing methods for emotional insight and safety control.", "AI": {"tldr": "本文提出了一种名为PsychēChat的新型大型语言模型，用于心理咨询，它能够显式地跟踪咨询者情绪变化并主动规避安全风险，通过多模块协同或链式思考的方式提升咨询效果和安全性。", "motivation": "现有的大型语言模型在心理咨询中存在不足，未能显式地模拟咨询者在多次咨询中的情绪变化，也未能充分解决如何根据情绪变化调整咨询师回应并规避安全风险的问题。", "method": "提出PsychēChat模型，包含两个关键模块：情绪管理模块（跟踪当前情绪及变化）和风险控制模块（预测咨询者反应并识别风险）。采用两种模型范式：Agent Mode（多智能体协同）和LLM Mode（统一的链式思考）。", "result": "通过角色扮演生成对话数据进行训练和评估，实验结果（包括交互评分、对话评估和人工评估）表明，PsychēChat在情绪洞察和安全控制方面优于现有方法。", "conclusion": "PsychēChat通过显式的情绪变化跟踪和安全风险分析，能够有效地提升心理咨询的质量和安全性，克服了现有大型语言模型在这方面的局限性。"}}
{"id": "2601.13196", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13196", "abs": "https://arxiv.org/abs/2601.13196", "authors": ["Jacob Swindell", "Marija Popović", "Riccardo Polvara"], "title": "Active Informative Planning for UAV-based Weed Mapping using Discrete Gaussian Process Representations", "comment": null, "summary": "Accurate agricultural weed mapping using unmanned aerial vehicles (UAVs) is crucial for precision farming. While traditional methods rely on rigid, pre-defined flight paths and intensive offline processing, informative path planning (IPP) offers a way to collect data adaptively where it is most needed. Gaussian process (GP) mapping provides a continuous model of weed distribution with built-in uncertainty. However, GPs must be discretised for practical use in autonomous planning. Many discretisation techniques exist, but the impact of discrete representation choice remains poorly understood. This paper investigates how different discrete GP representations influence both mapping quality and mission-level performance in UAV-based weed mapping. Considering a UAV equipped with a downward-facing camera, we implement a receding-horizon IPP strategy that selects sampling locations based on the map uncertainty, travel cost, and coverage penalties. We investigate multiple discretisation strategies for representing the GP posterior and use their induced map partitions to generate candidate viewpoints for planning. Experiments on real-world weed distributions show that representation choice significantly affects exploration behaviour and efficiency. Overall, our results demonstrate that discretisation is not only a representational detail but a key design choice that shapes planning dynamics, coverage efficiency, and computational load in online UAV weed mapping.", "AI": {"tldr": "本文研究了不同离散化高斯过程（GP）表示方法对无人机（UAV）杂草测绘质量和任务效率的影响，旨在改进信息路径规划（IPP）策略。", "motivation": "传统无人机杂草测绘方法依赖预设路径和离线处理，效率低下。信息路径规划（IPP）可以通过自适应收集数据来提高效率，而GP提供连续的杂草分布模型，但需要离散化才能用于规划。现有研究对离散化方法对规划和测绘任务的影响理解不足，是本研究的动机。", "method": "在无人机上装备向下摄像头，采用递推视界信息路径规划（IPP）策略。该策略根据地图不确定性、旅行成本和覆盖惩罚来选择采样点。文章实现了多种GP后验分布的离散化策略，并利用这些离散化后的地图分区来生成规划的候选视点。", "result": "实验结果表明，GP地图的离散化表示方法显著影响无人机的探索行为和测绘效率。不同的离散化策略对规划动态、覆盖效率和在线计算负载都有重要影响。", "conclusion": "离散化表示不仅仅是一个代表性的细节，更是影响无人机杂草测绘规划动态、覆盖效率和计算负载的关键设计选择。研究结果强调了在无人机在线杂草测绘中，选择合适的离散化策略对于优化任务性能至关重要。"}}
{"id": "2601.11915", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11915", "abs": "https://arxiv.org/abs/2601.11915", "authors": ["Chi Wang", "Xinjue Hu", "Boyu Wang", "Ziwen He", "Zhangjie Fu"], "title": "From Spurious to Causal: Low-rank Orthogonal Subspace Intervention for Generalizable Face Forgery Detection", "comment": null, "summary": "The generalization problem remains a critical challenge in face forgery detection. Some researches have discovered that ``a backdoor path\" in the representations from forgery-irrelevant information to labels induces biased learning, thereby hindering the generalization. In this paper, these forgery-irrelevant information are collectively termed spurious correlations factors. Previous methods predominantly focused on identifying concrete, specific spurious correlation and designing corresponding solutions to address them. However, spurious correlations arise from unobservable confounding factors, making it impractical to identify and address each one individually. To address this, we propose an intervention paradigm for representation space. Instead of tracking and blocking various instance-level spurious correlation one by one, we uniformly model them as a low-rank subspace and intervene in them. Specifically, we decompose spurious correlation features into a low-rank subspace via orthogonal low-rank projection, subsequently removing this subspace from the original representation and training its orthogonal complement to capture forgery-related features. This low-rank projection removal effectively eliminates spurious correlation factors, ensuring that classification decision is based on authentic forgery cues. With only 0.43M trainable parameters, our method achieves state-of-the-art performance across several benchmarks, demonstrating excellent robustness and generalization.", "AI": {"tldr": "提出了一种新的表示空间干预范式，通过将伪相关因子建模为低秩子空间并进行正交投影移除，来解决人脸伪造检测中的泛化问题，取得了优于现有方法的性能。", "motivation": "当前人脸伪造检测中的泛化性问题，主要是由于伪造无关信息（伪相关因子）与标签之间存在“后门路径”，导致模型学习偏差。现有方法难以逐一识别和解决这些不可见的混淆因子导致的伪相关。因此，需要一种新的方法来统一处理这些伪相关。", "method": "提出一种表示空间的干预范式。首先，将伪相关因子统一建模为一个低秩子空间。然后，通过正交低秩投影分解出这个子空间。接着，将这个子空间从原始表示中移除，并训练其正交补空间来捕获与伪造相关的特征。这种方法可以有效地消除伪相关因子，确保分类决策依赖于真实的伪造线索。", "result": "该方法在多个基准测试中实现了最先进的性能，表现出优异的鲁棒性和泛化能力。模型参数量仅为0.43M，但取得了显著的性能提升。", "conclusion": "提出的低秩子空间干预方法能够有效地消除人脸伪造检测中的伪相关因子，显著提升模型的泛化能力，并在实际应用中展现出卓越的性能。"}}
{"id": "2601.13177", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13177", "abs": "https://arxiv.org/abs/2601.13177", "authors": ["Behnam Moradkhani", "Raghav Sankaranarayanan", "Pejman Kheradmand", "Harshith Jella", "Nicholas Ahn", "Ajmal Zemmar", "Yash Chitalia"], "title": "Helical Tendon-Driven Continuum Robot with Programmable Follow-the-Leader Operation", "comment": "8 pages, 9 figures", "summary": "Spinal cord stimulation (SCS) is primarily utilized for pain management and has recently demonstrated efficacy in promoting functional recovery in patients with spinal cord injury. Effective stimulation of motor neurons ideally requires the placement of SCS leads in the ventral or lateral epidural space where the corticospinal and rubrospinal motor fibers are located. This poses significant challenges with the current standard of manual steering. In this study, we present a static modeling approach for the ExoNav, a steerable robotic tool designed to facilitate precise navigation to the ventral and lateral epidural space. Cosserat rod framework is employed to establish the relationship between tendon actuation forces and the robot's overall shape. The effects of gravity, as an example of an external load, are investigated and implemented in the model and simulation. The experimental results indicate RMSE values of 1.76mm, 2.33mm, 2.18mm, and 1.33mm across four tested prototypes. Based on the helical shape of the ExoNav upon actuation, it is capable of performing follow-the-leader (FTL) motion by adding insertion and rotation DoFs to this robotic system, which is shown in simulation and experimentally. The proposed simulation has the capability to calculate optimum tendon tensions to follow the desired FTL paths while gravity-induced robot deformations are present. Three FTL experimental trials are conducted and the end-effector position showed repeatable alignments with the desired path with maximum RMSE value of 3.75mm. Ultimately, a phantom model demonstration is conducted where the teleoperated robot successfully navigated to the lateral and ventral spinal cord targets. Additionally, the user was able to navigate to the dorsal root ganglia, illustrating ExoNav's potential in both motor function recovery and pain management.", "AI": {"tldr": "提出了一种名为ExoNav的静态建模方法，这是一种可控的机器人工具，用于在脊髓内精确导航，以期改善脊髓损伤患者的功能恢复和疼痛管理。该模型考虑了重力等外部载荷的影响，并通过实验验证了其精度和可重复性。", "motivation": "当前脊髓刺激（SCS）在促进脊髓损伤功能恢复方面显示出潜力，但将SCS导线放置在需要有效刺激运动神经元的腹侧或外侧硬膜外腔具有挑战性，因为手动转向存在困难。本研究旨在开发一种能够精确导航到这些区域的机器人工具。", "method": "采用Cosserat杆框架建立腱驱动力和机器人形状之间的关系，开发了ExoNav机器人工具的静态模型。该模型考虑了重力等外部载荷，并通过仿真和实验进行了验证。实验中使用了四种原型，并进行了三次跟领先行（FTL）运动实验，最后在假体模型上进行了导航演示。", "result": "在实验中，四种原型机器人的均方根误差（RMSE）值分别为1.76mm、2.33mm、2.18mm和1.33mm。FTL实验显示，末端执行器位置与期望路径的重复对齐，最大RMSE值为3.75mm。假体模型演示表明，ExoNav能够成功导航到脊髓的腹侧和外侧靶点，以及背根神经节。", "conclusion": "提出的ExoNav静态模型和机器人工具能够精确导航到脊髓的特定目标区域，证明了其在改善脊髓损伤患者功能恢复和疼痛管理方面的潜力。该系统能够克服重力等因素的影响，并实现可重复的导航路径。"}}
{"id": "2601.13832", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13832", "abs": "https://arxiv.org/abs/2601.13832", "authors": ["Ruixing Ren", "Shan Chen", "Xuehan Bao", "Pingzheng Ge", "Dongming Wang", "Junhui Zhao"], "title": "Base Station Sleeping Strategy Based on Load Sharing in Ultra-Dense Networks", "comment": "11 pages,6 figures", "summary": "To address the issues of high operational costs and low energy efficiency (EE) caused by the dense deployment of small base stations (s-BSs) in 5G ultra-dense networks (UDNs), this paper first constructs a multi-objective mathematical optimization model targeting maximizing EE and minimizing the number of active BSs. The model incorporates key constraints including BS operational state, user equipment (UE)-BS connection relationship, and load threshold, laying a theoretical foundation for the coordinated optimization of energy conservation and quality of service. Based on this model, an integrated solution combining UE-BS initial connection optimization and load-sharing based BS sleeping is proposed. In the initial connection phase, with communication quality and BS load as dual constraints, efficient matching between UEs and optimal BSs is achieved through three sequential steps: communication feasibility screening, redundant connection removal, and overload load redistribution. This resolves the problems of load imbalance and difficult identification of redundant BSs in UDNs arising from unordered initial connections. In the BS sleeping phase, a BS sleeping index, comprehensively considering UE transferability and backup BS resources, is innovatively introduced to quantify BS dormancy priority. Through a closed-loop process involving low-load BS screening, adjacent BS load evaluation, and load sharing by two takeover BSs based on their capacity, accurate dormancy of redundant BSs and collaborative load migration are realized. Simulation results in a typical UDNs scenario demonstrate that, compared with the traditional baseline scheme, the proposed solution exhibits significant advantages in convergence speed, optimization of the number of active BSs, and EE improvement.", "AI": {"tldr": "本文提出了一种结合用户与基站初始连接优化和基于负载共享的基站休眠方案，以解决5G超密集网络中小基站高成本和低能效的问题，实现了能耗和网络性能的协同优化。", "motivation": "5G超密集网络中小基站（s-BSs）的密集部署导致高运营成本和低能效。因此，需要一种能够同时提高能效并降低基站数量的优化方案。", "method": "构建了一个多目标数学优化模型，旨在最大化能效并最小化激活基站数量。在此基础上，提出了一种结合用户与基站初始连接优化和基于负载共享的基站休眠的集成解决方案。初始连接阶段通过通信可行性筛选、冗余连接移除和过载负载重分布来优化UE-BS连接。休眠阶段引入了综合考虑UE可迁移性和备用BS资源的BS休眠指数，通过低负载BS筛选、相邻BS负载评估和容量驱动的负载共享来实现冗余BS的休眠和协作负载迁移。", "result": "仿真结果表明，与传统基线方案相比，所提出的解决方案在收敛速度、激活基站数量优化和能效提升方面具有显著优势。", "conclusion": "该提出的集成解决方案能够有效地解决5G UDNs中由于无序初始连接引起的负载不平衡和冗余BS识别困难问题，并实现了冗余BS的精确休眠和协作负载迁移，从而在提高能效的同时保持服务质量。"}}
{"id": "2601.12338", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12338", "abs": "https://arxiv.org/abs/2601.12338", "authors": ["Kartikey Singh Bhandari", "Manav Ganesh", "Yashwant Viswanathan", "Archit Agrawal", "Dhruv Kumar", "Pratik Narang"], "title": "Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations", "comment": null, "summary": "Customer reviews contain detailed, domain specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. We study review-to-action generation: producing concrete, implementable recommendations grounded in review text. We propose a modular two-LLM framework in which an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, we adapt the Advice model using a mixture of LoRA experts strategy: multiple low-rank adapters are trained and a lightweight gating mechanism performs token-level expert mixing at inference, combining complementary expertise across issue types. We construct synthetic review-issue-advice triples from Yelp reviews (airlines and restaurants) to supervise training, and evaluate recommendations using an eight dimension operational rubric spanning actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, and clarity. Across both domains, our approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.", "AI": {"tldr": "本文提出了一种基于两个大型语言模型（LLM）的框架，用于从客户评论中生成可操作的改进建议。该框架包含一个“问题模型”来识别评论中的关键问题并进行分类，以及一个“建议模型”来生成具体的运营解决方案。为了提高建议模型的效率和效果，采用了LoRA专家混合策略，通过训练多个低秩适配器并动态选择和组合它们来生成建议。", "motivation": "从客户评论中提取有价值的、可操作的见解以改进业务决策存在挑战，因为评论内容是非结构化的，并且包含领域特定的信息。现有方法难以有效地将这些反馈转化为具体的行动建议。", "method": "研究提出了一种模块化的两LLM框架。首先，一个“问题模型”负责从评论文本中提取关键问题并分配粗略的主题。然后，一个“建议模型”根据提取出的问题表示生成有针对性的运营性解决方案。为了在不进行昂贵的全面微调的情况下实现专业化，建议模型采用了LoRA专家混合策略，训练多个低秩适配器，并在推理时使用轻量级门控机制在token级别混合专家，以结合不同类型问题的互补专业知识。", "result": "研究构建了包含来自Yelp（航空公司和餐厅）评论的合成评论-问题-建议三元组数据集用于模型训练。使用包含行动性、具体性、可行性、预期影响、新颖性、非冗余性、偏见和清晰度等八个维度的运营评分标准对生成的建议进行评估。结果表明，在两个领域中，该框架的性能均优于仅提示和单适配器基线，在行动性和具体性方面表现更好，同时保持了良好的效率-质量权衡。", "conclusion": "所提出的基于两个LLM和LoRA专家混合的框架能够有效地从客户评论中生成具体、可操作的业务改进建议，并且在效率和质量方面优于现有方法。"}}
{"id": "2601.12061", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12061", "abs": "https://arxiv.org/abs/2601.12061", "authors": ["Jinsook Lee", "Kirk Vanacore", "Zhuqian Zhou", "Jeanine Grutter", "Rene F. Kizilcec"], "title": "Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation", "comment": "Under Review for ACL 2026", "summary": "Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.", "AI": {"tldr": "研究提出了一种名为“代码本注入分割”的新方法，通过将对话行为（DA）的标注标准纳入分割边界的决策过程，来解决现有方法在分割界限上不一致的问题，并评估了基于LLM的分割器。", "motivation": "传统的对话行为（DA）标注方法将交流意图视为孤立的单元，导致标注者在判断分割边界时存在分歧，降低了标注的可靠性。现有方法未充分考虑下游标注任务的需求。", "method": "提出“代码本注入分割”方法，将下游DA标注标准作为分割边界决策的条件。设计了评估指标（跨度一致性、区分度、人机分布一致性）来评估LLM分割器，并与标准和检索增强基线进行比较。使用了两种数据集进行评估。", "result": "DA感知分割比纯文本基线能产生更内部一致的片段。LLM在生成结构一致的跨度方面表现出色，但基于连贯性的基线在检测对话流的全局变化方面更优。在两个数据集中，没有单一的分割器能全面胜出。内部一致性的提升常以边界区分度和人机分布一致性的下降为代价。", "conclusion": "对话分割是一个重要的设计选择，应针对下游目标进行优化，而不是依赖单一的性能指标。改进分割策略可以提高DA标注的可靠性，但需要在一致性、区分度和人机分布之间进行权衡。"}}
{"id": "2601.12410", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12410", "abs": "https://arxiv.org/abs/2601.12410", "authors": ["Dingyi Yang", "Junqi Zhao", "Xue Li", "Ce Li", "Boyang Li"], "title": "Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation", "comment": "23 pages, 11 figures", "summary": "Cognitive anthropology suggests that the distinction of human intelligence lies in the ability to infer other individuals' knowledge states and understand their intentions. In comparison, our closest animal relative, chimpanzees, lack the capacity to do so. With this paper, we aim to evaluate LLM performance in the area of knowledge state tracking and estimation. We design two tasks to test (1) if LLMs can detect when story characters, through their actions, demonstrate knowledge they should not possess, and (2) if LLMs can predict story characters' next actions based on their own knowledge vs. objective truths they do not know. Results reveal that most current state-of-the-art LLMs achieve near-random performance on both tasks, and are substantially inferior to humans. We argue future LLM research should place more weight on the abilities of knowledge estimation and intention understanding.", "AI": {"tldr": "研究评估了当前大型语言模型（LLMs）在理解他人知识状态和意图方面的能力，发现它们表现不佳，远逊于人类。", "motivation": "认知人类学认为，理解他人的知识状态和意图是人类智能的关键，而黑猩猩缺乏这种能力。本研究旨在评估LLMs在这方面的表现。", "method": "设计了两个任务来测试LLMs：1. 识别故事角色是否表现出其不应拥有的知识；2. 根据角色的自身知识（而非客观事实）预测其下一步行动。", "result": "大多数最先进的LLMs在这两项任务上的表现接近随机水平，并且远不如人类。", "conclusion": "未来的LLM研究应更加重视知识估计和意图理解的能力。"}}
{"id": "2601.11918", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11918", "abs": "https://arxiv.org/abs/2601.11918", "authors": ["Akito Morita", "Hirotsugu Okuno"], "title": "Effects of Gabor Filters on Classification Performance of CNNs Trained on a Limited Number of Conditions", "comment": "5 pages, 4 figures, 4 tables", "summary": "In this study, we propose a technique to improve the accuracy and reduce the size of convolutional neural networks (CNNs) running on edge devices for real-world robot vision applications. CNNs running on edge devices must have a small architecture, and CNNs for robot vision applications involving on-site object recognition must be able to be trained efficiently to identify specific visual targets from data obtained under a limited variation of conditions. The visual nervous system (VNS) is a good example that meets the above requirements because it learns from few visual experiences. Therefore, we used a Gabor filter, a model of the feature extractor of the VNS, as a preprocessor for CNNs to investigate the accuracy of the CNNs trained with small amounts of data. To evaluate how well CNNs trained on image data acquired under a limited variation of conditions generalize to data acquired under other conditions, we created an image dataset consisting of images acquired from different camera positions, and investigated the accuracy of the CNNs that trained using images acquired at a certain distance. The results were compared after training on multiple CNN architectures with and without Gabor filters as preprocessing. The results showed that preprocessing with Gabor filters improves the generalization performance of CNNs and contributes to reducing the size of CNNs.", "AI": {"tldr": "研究提出使用Gabor滤波器作为CNN预处理器，以提高在边缘设备上运行的机器人视觉CNN的准确性并减小模型尺寸，尤其是在数据有限的情况下。", "motivation": "边缘设备上的CNN需要小巧且能高效训练，以识别在条件有限情况下获取的数据中的特定视觉目标。视觉神经系统（VNS）通过少量视觉经验进行学习，这为解决上述问题提供了灵感。", "method": "使用Gabor滤波器（模仿VNS的特征提取器）作为CNN的预处理器，并在包含不同相机位置采集的图像的数据集上进行训练和评估。比较了有Gabor滤波器预处理和无预处理的多种CNN架构的准确性。", "result": "结果表明，使用Gabor滤波器进行预处理可以提高CNN的泛化性能，并有助于减小CNN的尺寸。", "conclusion": "Gabor滤波器预处理技术能够有效提升在数据有限且条件变化有限的场景下训练的机器人视觉CNN的性能，并实现模型的小型化。"}}
{"id": "2601.12068", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12068", "abs": "https://arxiv.org/abs/2601.12068", "authors": ["Rowzatul Zannat", "Abdullah Al Shafi", "Abdul Muntakim"], "title": "Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset", "comment": null, "summary": "Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.", "AI": {"tldr": "本研究开发了一个包含758个症状-疾病关系的孟加拉语疾病预测数据集，并使用该数据集评估了多种机器学习模型，最终通过集成学习模型实现了98%的准确率，以提升孟加拉语社区的健康信息可及性。", "motivation": "非英语使用者获取可靠健康信息存在障碍，特别是孟加拉语在疾病预测方面的资源匮乏。本研究旨在填补这一空白，提高孟加拉语社区的医疗可及性。", "method": "研究者构建了一个包含758个孟加拉语症状-疾病关系的孟加拉语数据集，并公开可用。随后，他们使用该数据集评估了多种机器学习模型，并采用软硬投票集成方法结合表现最佳的模型进行预测。", "result": "集成学习模型（软硬投票）在孟加拉语症状-疾病预测任务上达到了98%的准确率，展现了良好的鲁棒性和泛化能力。", "conclusion": "本研究成功构建了一个孟加拉语疾病预测的基础数据集，并证明了集成学习模型在该任务上的有效性。这项工作为未来开发本地化的健康信息学和诊断工具奠定了基础，有助于促进孟加拉语社区公平获取健康信息，特别是用于早期疾病检测和干预。"}}
{"id": "2601.13232", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13232", "abs": "https://arxiv.org/abs/2601.13232", "authors": ["Kourosh Darvish", "Arjun Sohal", "Abhijoy Mandal", "Hatem Fakhruldeen", "Nikola Radulov", "Zhengxue Zhou", "Satheeshkumar Veeramani", "Joshua Choi", "Sijie Han", "Brayden Zhang", "Jeeyeoun Chae", "Alex Wright", "Yijie Wang", "Hossein Darvish", "Yuchi Zhao", "Gary Tom", "Han Hao", "Miroslav Bogdanovic", "Gabriella Pizzuto", "Andrew I. Cooper", "Alán Aspuru-Guzik", "Florian Shkurti", "Animesh Garg"], "title": "MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation", "comment": "Darvish, K., Sohal, A., Mandal, A. et al. MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation. Nat Comput Sci (2025)", "summary": "Accelerated materials discovery is critical for addressing global challenges. However, developing new laboratory workflows relies heavily on real-world experimental trials, and this can hinder scalability because of the need for numerous physical make-and-test iterations. Here we present MATTERIX, a multiscale, graphics processing unit-accelerated robotic simulation framework designed to create high-fidelity digital twins of chemistry laboratories, thus accelerating workflow development. This multiscale digital twin simulates robotic physical manipulation, powder and liquid dynamics, device functionalities, heat transfer and basic chemical reaction kinetics. This is enabled by integrating realistic physics simulation and photorealistic rendering with a modular graphics processing unit-accelerated semantics engine, which models logical states and continuous behaviors to simulate chemistry workflows across different levels of abstraction. MATTERIX streamlines the creation of digital twin environments through open-source asset libraries and interfaces, while enabling flexible workflow design via hierarchical plan definition and a modular skill library that incorporates learning-based methods. Our approach demonstrates sim-to-real transfer in robotic chemistry setups, reducing reliance on costly real-world experiments and enabling the testing of hypothetical automated workflows in silico. The project website is available at https://accelerationconsortium.github.io/Matterix/ .", "AI": {"tldr": "提出了一种名为MATTERIX的多尺度、GPU加速的机器人模拟框架，用于创建化学实验室的高保真数字孪生，以加速工作流程开发。该框架能够模拟物理操作、粉末和液体动力学、设备功能、传热和基本化学反应动力学，并通过集成物理模拟、照片级真实感渲染和语义引擎来实现。MATTERIX通过开源资产库和接口简化了数字孪生环境的创建，并通过分层规划定义和模块化技能库实现了灵活的工作流程设计。该方法在机器人化学装置中实现了从模拟到现实的转移，减少了对昂贵现实世界实验的依赖，并能够进行假设性自动化工作流程的计算测试。", "motivation": "传统的实验室工作流程开发依赖于大量的实际实验，效率低下且难以规模化。因此，需要一种新的方法来加速材料发现和实验室工作流程的开发。", "method": "开发了一个名为MATTERIX的多尺度、GPU加速的机器人模拟框架，能够创建化学实验室的高保真数字孪生。该框架集成了物理模拟（包括机器人操作、粉末/液体动力学、设备功能、传热、基本化学反应动力学）、照片级真实感渲染以及一个GPU加速的语义引擎，用于模拟逻辑状态和连续行为。通过开源资产库、接口、分层规划定义和模块化技能库（包含基于学习的方法）实现灵活的工作流程设计。", "result": "MATTERIX成功地在机器人化学装置中实现了从模拟到现实的转移，证明了其数字孪生在加速工作流程开发方面的有效性。这显著减少了对昂贵且耗时的实际实验的依赖。", "conclusion": "MATTERIX是一个强大的工具，通过创建化学实验室的高保真数字孪生，能够显著加速材料发现和实验室工作流程的开发。它通过提供一个模拟平台，能够测试假设性自动化工作流程，从而克服了现实世界实验的局限性。"}}
{"id": "2601.13843", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13843", "abs": "https://arxiv.org/abs/2601.13843", "authors": ["Yongqiang Zhang", "Mustafa A. Kishk", "Mohamed-Slim Alouini"], "title": "Small Models, Big Impact: Tool-Augmented AI Agents for Wireless Network Planning", "comment": "7 pages, 4 figures, 2 tables, accepted by IEEE Communications Magazine", "summary": "Large Language Models (LLMs) such as ChatGPT promise revolutionary capabilities for Sixth-Generation (6G) wireless networks but their massive computational requirements and tendency to generate technically incorrect information create deployment barriers. In this work, we introduce MAINTAINED: autonomous artificial intelligence agent for wireless network deployment. Instead of encoding domain knowledge within model parameters, our approach orchestrates specialized computational tools for geographic analysis, signal propagation modeling, and network optimization. In a real-world case study, MAINTAINED outperforms state-of-the-art LLMs including ChatGPT-4o, Claude Sonnet 4, and DeepSeek-R1 by up to 100-fold in verified performance metrics while requiring less computational resources. This paradigm shift, moving from relying on parametric knowledge towards externalizing domain knowledge into verifiable computational tools, eliminates hallucination in technical specifications and enables edge-deployable Artificial Intelligence (AI) for wireless communications.", "AI": {"tldr": "本文提出了一种名为MAINTAINED的自主AI代理，用于无线网络部署，该代理通过编排专业计算工具而非依赖LLM的参数化知识，显著提高了性能并降低了计算资源需求，解决了LLM在无线网络部署中的计算量大和信息不准确的问题。", "motivation": "大型语言模型（LLMs）在无线网络部署方面存在计算需求大和技术信息不准确（幻觉）的问题，阻碍了其应用。需要一种更可靠、更高效的AI解决方案。", "method": "MAINTAINED通过编排地理分析、信号传播建模和网络优化等专业计算工具来工作，而不是将领域知识编码到模型参数中。这种方法将领域知识外部化到可验证的计算工具中。", "result": "在真实世界的案例研究中，MAINTAINED在经过验证的性能指标上，其表现比ChatGPT-4o、Claude Sonnet 4和DeepSeek-R1等最先进的LLMs提高了100倍，并且计算资源消耗更少。", "conclusion": "通过将领域知识外部化到可验证的计算工具中，MAINTAINED消除了技术规范中的幻觉，并实现了可部署在边缘的AI，为6G无线网络部署提供了一个更优的解决方案。"}}
{"id": "2601.13958", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13958", "abs": "https://arxiv.org/abs/2601.13958", "authors": ["Sander Doodeman", "Paula Chanfreut Palacio", "Elena Torta", "Duarte Antunes"], "title": "Where to Place a Heavy Payload on a Multirotor UAV for Best Control Performance", "comment": null, "summary": "This paper studies the impact of rigidly attached heavy payload placement - where the payload mass significantly influences the UAV's dynamics - on the stability and control performance of a multirotor unmanned aerial vehicle (UAV). In particular, we focus on how the position of such a payload relative to the vehicle's Center of Gravity (CoG) affects the stability and control performance at an arbitrary point of interest on the UAV, such as the payload position, and on how this position can be optimized. Our conclusions are based on two key contributions. First, we analyze the stability of the zero-dynamics of a complete nonlinear model of the UAV with payload. We demonstrate that the stability of the zero dynamics depends on the vertical signed distance in the body-fixed frame between the controlled output position and the combined CoG of the UAV with payload. Specifically, positioning the output below the CoG yields unstable zero dynamics, while the linearized zero dynamics are marginally stable when placing it above, indicating reduced sensitivity to input disturbances. Second, we analyze the performance of the linearized UAV model with payload by providing an analytical expression for the H2-norm, from which we can quantify the system's attenuation to white noise input disturbances. We conclude that less control authority leads to a higher optimal position of the controlled output with respect to the CoG for closed-loop white-noise disturbance rejection capabilities, also when the heavy payload is the controlled output. The results are illustrated through numerical examples.", "AI": {"tldr": "研究了重载荷刚性附加对多旋翼无人机稳定性和控制性能的影响，特别是载荷相对于质心（CoG）的位置对控制性能的影响，并给出了优化方法。", "motivation": "研究重载荷对无人机动力学特性的影响，以及载荷相对于质心的位置如何影响稳定性和控制性能，并寻求最优解。", "method": "1. 分析了包含载荷的无人机非线性模型的零动力学稳定性；2. 通过H2范数的解析表达式分析了线性化模型的性能，以量化系统对白噪声输入的衰减能力。", "result": "零动力学稳定性取决于输出位置与载荷组合质心之间的垂直距离；输出位于质心下方导致零动力学不稳定，位于质心上方则零动力学近似稳定；控制权限越小，为了获得更好的白噪声扰动抑制能力，输出相对于质心的最优位置越高。", "conclusion": "载荷相对于无人机质心的位置对无人机的稳定性和控制性能有显著影响，可以通过优化载荷位置来提高系统性能，尤其是在处理白噪声扰动时。"}}
{"id": "2601.11930", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11930", "abs": "https://arxiv.org/abs/2601.11930", "authors": ["Xulei Shi", "Maoyu Wang", "Yuning Peng", "Guanbo Wang", "Xin Wang", "Qi Chen", "Pengjie Tao"], "title": "SupScene: Learning Overlap-Aware Global Descriptor for Unconstrained SfM", "comment": null, "summary": "Image retrieval is a critical step for alleviating the quadratic complexity of image matching in unconstrained Structure-from-Motion (SfM). However, in this context, image retrieval typically focuses more on the image pairs of geometric matchability than on those of semantic similarity, a nuance that most existing deep learning-based methods guided by batched binaries (overlapping vs. non-overlapping pairs) fail to capture. In this paper, we introduce SupScene, a novel solution that learns global descriptors tailored for finding overlapping image pairs of similar geometric nature for SfM. First, to better underline co-visible regions, we employ a subgraph-based training strategy that moves beyond equally important isolated pairs, leveraging ground-truth geometric overlapping relationships with various weights to provide fine-grained supervision via a soft supervised contrastive loss. Second, we introduce DiVLAD, a DINO-inspired VLAD aggregator that leverages the inherent multi-head attention maps from the last block of ViT. And then, a learnable gating mechanism is designed to adaptively utilize these semantically salient cues with visual features, enabling a more discriminative global descriptor. Extensive experiments on the GL3D dataset demonstrate that our method achieves state-of-the-art performance, significantly outperforming NetVLAD while introducing a negligible number of additional trainable parameters. Furthermore, we show that the proposed training strategy brings consistent gains across different aggregation techniques. Code and models are available at https://anonymous.4open.science/r/SupScene-5B73.", "AI": {"tldr": "本文提出了一种名为SupScene的新方法，用于学习用于SfM的全局描述符，以识别几何上相似的图像对。它通过基于子图的训练策略和一种名为DiVLAD的DINO启发的聚合器来实现这一点，并在GL3D数据集上取得了最先进的性能。", "motivation": "现有深度学习图像检索方法在SfM场景下，未能充分捕捉几何匹配性而非语义相似性，导致其在为SfM寻找具有几何重叠的图像对方面表现不足。", "method": "1. 采用基于子图的训练策略，利用加权的地面真实几何重叠关系，通过软监督对比损失进行细粒度监督，以突出共视区域。\n2. 引入DINO启发的VLAD聚合器DiVLAD，利用ViT最后一个块的多头注意力图，并通过一个可学习的门控机制自适应地结合语义线索和视觉特征，生成更具辨别力的全局描述符。", "result": "SupScene在GL3D数据集上实现了最先进的性能，显著优于NetVLAD，并且训练参数量增加很少。此外，提出的训练策略对不同的聚合技术都能带来一致的性能提升。", "conclusion": "SupScene通过新颖的训练策略和聚合器，能够有效地学习用于SfM的全局描述符，从而在识别几何上相似的图像对方面取得了显著的改进，为SfM中的图像检索提供了一种更优的解决方案。"}}
{"id": "2601.12444", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.12444", "abs": "https://arxiv.org/abs/2601.12444", "authors": ["Hui Yang", "Jiaoyan Chen", "Uli Sattler"], "title": "Large Language Model for OWL Proofs", "comment": null, "summary": "The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning over complex knowledge, by developing an automated dataset construction and evaluation framework. Our evaluation encompassing three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, we achieve important findings including: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. Together, these results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions. Code and data are available at https://github.com/HuiYang1997/LLMOwlR.", "AI": {"tldr": "研究了大型语言模型（LLMs）在OWL本体（一种知识表示和推理的广泛使用的语言）上的证明生成能力，开发了一个自动数据集构建和评估框架，评估了LLMs在提取、简化、解释和逻辑完备性方面的表现，发现LLMs在复杂案例上表现有限，逻辑复杂度是影响性能的关键因素，输入数据的噪声和不完整性会严重降低其性能。", "motivation": "现有的LLM推理能力研究主要集中在推导结论，但对其生成忠实且人类可读的证明（解释为什么结论成立）的能力研究不足。本研究旨在填补这一空白，特别是在OWL本体这一重要的知识表示领域。", "method": "开发了一个自动化的数据集构建和评估框架，用于评估LLMs在OWL本体上的证明生成能力。评估框架包含四个任务：证明提取、简化、解释，以及逻辑完备性评估。", "result": "1. 部分LLMs在总体上表现良好，但在处理复杂案例时存在局限性。2. 逻辑复杂度是影响LLM性能的主要因素，而非表示格式（形式逻辑语言或自然语言）。3. 输入数据中的噪声和不完整性会显著降低LLMs的性能。", "conclusion": "LLMs在结合严谨逻辑进行解释方面展现出潜力，但仍需在支持复杂或不完美条件下的弹性和鲁棒性推理方面取得进展。"}}
{"id": "2601.13250", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13250", "abs": "https://arxiv.org/abs/2601.13250", "authors": ["Ante Marić", "Giammarco Caroleo", "Alessandro Albini", "Julius Jankowski", "Perla Maiolino", "Sylvain Calinon"], "title": "Diffusion-based Inverse Model of a Distributed Tactile Sensor for Object Pose Estimation", "comment": null, "summary": "Tactile sensing provides a promising sensing modality for object pose estimation in manipulation settings where visual information is limited due to occlusion or environmental effects. However, efficiently leveraging tactile data for estimation remains a challenge due to partial observability, with single observations corresponding to multiple possible contact configurations. This limits conventional estimation approaches largely tailored to vision. We propose to address these challenges by learning an inverse tactile sensor model using denoising diffusion. The model is conditioned on tactile observations from a distributed tactile sensor and trained in simulation using a geometric sensor model based on signed distance fields. Contact constraints are enforced during inference through single-step projection using distance and gradient information from the signed distance field. For online pose estimation, we integrate the inverse model with a particle filter through a proposal scheme that combines generated hypotheses with particles from the prior belief. Our approach is validated in simulated and real-world planar pose estimation settings, without access to visual data or tight initial pose priors. We further evaluate robustness to unmodeled contact and sensor dynamics for pose tracking in a box-pushing scenario. Compared to local sampling baselines, the inverse sensor model improves sampling efficiency and estimation accuracy while preserving multimodal beliefs across objects with varying tactile discriminability.", "AI": {"tldr": "研究提出了一种基于扩散模型的逆向触觉传感器模型，用于在视觉受限的情况下进行物体姿态估计。该模型能有效处理触觉数据的多模态不确定性，并通过粒子滤波器进行在线估计，在模拟和真实环境中均验证了其有效性和鲁棒性。", "motivation": "在物体姿态估计中，触觉传感是一种有前景的补充或替代视觉的感知方式，尤其是在视觉信息受限（如遮挡）的情况下。然而，触觉数据存在部分可观测性问题，单个观测可能对应多种接触配置，这给姿态估计带来了挑战，现有方法多针对视觉数据设计。", "method": "提出学习一个逆向触觉传感器模型，利用去噪扩散模型。该模型以分布式触觉传感器采集的触觉观测作为条件，并在模拟环境中，利用基于符号距离场（SDF）的几何传感器模型进行训练。在推理过程中，通过SDF的距离和梯度信息进行单步投影来强制执行接触约束。对于在线姿态估计，将该逆向模型与粒子滤波器结合，通过一种生成假设和先验信念粒子相结合的提议方案。", "result": "在模拟和真实世界的平面姿态估计任务中，该方法在不依赖视觉数据或精确初始姿态先验的情况下进行了验证。在箱子推动场景中，对未建模接触和传感器动力学的鲁棒性也进行了评估。与局部采样基线相比，逆向传感器模型提高了采样效率和估计精度，并能保持多模态信念。", "conclusion": "基于扩散模型的逆向触觉传感器模型能够有效地处理触觉数据的多模态不确定性，并与粒子滤波器结合实现高效准确的在线姿态估计，尤其在视觉信息受限或不确定性较高的场景下表现出优势。该方法在不同可触感辨别性的物体上均能保持多模态信念，并对未建模因素具有一定的鲁棒性。"}}
{"id": "2601.12075", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12075", "abs": "https://arxiv.org/abs/2601.12075", "authors": ["Mehrdad Farahani", "Franziska Penzkofer", "Richard Johansson"], "title": "To Copy or Not to Copy: Copying Is Easier to Induce Than Recall", "comment": null, "summary": "Language models used in retrieval-augmented settings must arbitrate between parametric knowledge stored in their weights and contextual information in the prompt. This work presents a mechanistic study of that choice by extracting an \\emph{arbitration vector} from model activations on a curated dataset designed to disentangle (i) irrelevant contexts that elicit parametric recall and (ii) relevant but false contexts that elicit copying. The vector is computed as the residual-stream centroid difference between these regimes across 27 relations, and is injected as an additive intervention at selected layers and token spans to steer behavior in two directions: Copy$\\rightarrow$Recall (suppressing context use) and Recall$\\rightarrow$Copy (inducing the model to copy any token from the context). Experiments on two architectures (decoder-only and encoder/decoder) and two open-domain QA benchmarks show consistent behavior shifts under moderate scaling while monitoring accuracy and fluency. Mechanistic analyses of attention routing, MLP contributions, and layer-wise probability trajectories reveal an asymmetry: inducing copying is an easy ``reactivation'' process that can be triggered at different locations in the input, while restoring recall is a ``suppression'' process that is more fragile and strongly tied to object-token interventions.", "AI": {"tldr": "该研究提出了一种“仲裁向量”来分析大型语言模型在检索增强设置中如何在模型内部知识和上下文信息之间进行权衡，并通过实验验证了该向量对模型行为的干预效果。", "motivation": "理解和控制语言模型在检索增强设置中如何平衡其内部知识和提供的上下文信息，以提高其在开放领域问答等任务上的准确性和流畅性。", "method": "研究者设计了一个专门的数据集来区分模型是依赖内部知识（不相关上下文）还是复制上下文（相关但错误上下文）。他们从模型的激活中提取了一个“仲裁向量”，该向量表示为两种情况下的残差流质心差。然后，将该向量作为干预手段，通过加法注入到模型的选定层和 token 跨度，以引导模型行为朝着“复制到回忆”或“回忆到复制”的方向转变。并在两种架构（decoder-only 和 encoder/decoder）和两个开放领域 QA 基准上进行了实验。", "result": "实验表明，在两种架构和两个 QA 基准上，该仲裁向量能够一致地改变模型的行为。特别是，“复制到回忆”的干预（抑制上下文使用）比“回忆到复制”（诱导模型复制上下文）更容易实现，且“回忆到复制”的干预更容易在输入的多个位置触发，而“复制到回忆”则更脆弱，且与对对象 token 的干预密切相关。", "conclusion": "研究成功地提出了一个可解释的仲裁向量，并证明了其在干预检索增强语言模型行为方面的有效性。研究还揭示了诱导模型复制上下文比抑制其复制上下文更容易，并且后者对干预位置更为敏感。"}}
{"id": "2601.11931", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11931", "abs": "https://arxiv.org/abs/2601.11931", "authors": ["Zhengxian Wu", "Chuanrui Zhang", "Shenao Jiang", "Hangrui Xu", "Zirui Liao", "Luyuan Zhang", "Huaqiu Li", "Peng Jiao", "Haoqian Wang"], "title": "Language-Guided and Motion-Aware Gait Representation for Generalizable Recognition", "comment": null, "summary": "Gait recognition is emerging as a promising technology and an innovative field within computer vision. However, existing methods typically rely on complex architectures to directly extract features from images and apply pooling operations to obtain sequence-level representations. Such designs often lead to overfitting on static noise (e.g., clothing), while failing to effectively capture dynamic motion regions.To address the above challenges, we present a Language guided and Motion-aware gait recognition framework, named LMGait.In particular, we utilize designed gait-related language cues to capture key motion features in gait sequences.", "AI": {"tldr": "提出了一种名为LMGait的语言引导和运动感知步态识别框架，以解决现有方法在处理静态噪声和捕获动态运动区域方面的不足。", "motivation": "现有步态识别方法依赖复杂的架构直接从图像提取特征并进行池化操作，容易过拟合静态噪声（如衣物），而无法有效捕获动态运动区域。", "method": "利用设计的步态相关语言线索来捕获步态序列中的关键运动特征。", "result": "（摘要未提供具体实验结果）", "conclusion": "（摘要未提供具体结论，但表明LMGait框架有望提高步态识别性能）"}}
{"id": "2601.12078", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12078", "abs": "https://arxiv.org/abs/2601.12078", "authors": ["Linfeng Du", "Ye Yuan", "Zichen Zhao", "Fuyuan Lyu", "Emiliano Penaloza", "Xiuying Chen", "Zipeng Sun", "Jikun Kang", "Laurent Charlin", "Xue Liu", "Haolun Wu"], "title": "Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization", "comment": null, "summary": "Large Language Models (LLMs) excel at general-purpose tasks, yet adapting their responses to individual users remains challenging. Retrieval augmentation provides a lightweight alternative to fine-tuning by conditioning LLMs on user history records, and existing approaches typically select these records based on semantic relevance. We argue that relevance serves as an unreliable proxy for utility: a record may be semantically similar to a query yet fail to improve generation quality or even degrade it due to redundancy or conflicting information. To bridge this gap, we propose PURPLE, a contextual bandit framework that oPtimizes UseR Profiles for Llm pErsonalization. In contrast to a greedy selection of the most relevant records, PURPLE treats profile construction as a set generation process and utilizes a Plackett-Luce ranking model to capture complex inter-record dependencies. By training with dense feedback provided by the likelihood of the reference response, our method aligns retrieval directly with generation quality. Extensive experiments on nine personalization tasks demonstrate that PURPLE consistently outperforms strong heuristic and retrieval-augmented baselines in both effectiveness and efficiency, establishing a principled and scalable solution for optimizing user profiles.", "AI": {"tldr": "提出了一种名为PURPLE的上下文老虎机框架，用于优化LLM用户个性化的用户画像，通过Plackett-Luce模型捕捉记录间的依赖关系，直接根据生成质量进行检索优化。", "motivation": "现有的检索增强LLM方法通常基于语义相关性选择用户历史记录，但这种相关性可能是不可靠的，无法保证生成质量的提升，甚至可能导致退化。", "method": "将用户画像构建视为一个集合生成过程，利用Plackett-Luce排序模型捕捉记录间的复杂依赖关系，并采用上下文老虎机框架，根据参考响应的似然度作为反馈信号，直接优化检索以提高生成质量。", "result": "在九个个性化任务上的大量实验表明，PURPLE在有效性和效率方面均持续优于强有力的启发式和检索增强基线。", "conclusion": "PURPLE为优化用户画像提供了一种原则性且可扩展的解决方案，能够有效解决LLM个性化中的检索挑战。"}}
{"id": "2601.13252", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13252", "abs": "https://arxiv.org/abs/2601.13252", "authors": ["Mahmud S. Zango", "Jianglin Lan"], "title": "Autonomous Navigation at the Nano-Scale: Algorithms, Architectures, and Constraints", "comment": "28 pages, 5 figures, 1 table. Review article", "summary": "Autonomous navigation for nano-scale unmanned aerial vehicles (nano-UAVs) is governed by extreme Size, Weight, and Power (SWaP) constraints (with the weight < 50 g and sub-100 mW onboard processor), distinguishing it fundamentally from standard robotic paradigms. This review synthesizes the state-of-the-art in sensing, computing, and control architectures designed specifically for these sub- 100mW computational envelopes. We critically analyse the transition from classical geometry-based methods to emerging \"Edge AI\" paradigms, including quantized deep neural networks deployed on ultra-low-power System-on-Chips (SoCs) and neuromorphic event-based control. Beyond algorithms, we evaluate the hardware-software co-design requisite for autonomy, covering advancements in dense optical flow, optimized Simultaneous Localization and Mapping (SLAM), and learning-based flight control. While significant progress has been observed in visual navigation and relative pose estimation, our analysis reveals persistent gaps in long-term endurance, robust obstacle avoidance in dynamic environments, and the \"Sim-to-Real\" transfer of reinforcement learning policies. This survey provides a roadmap for bridging these gaps, advocating for hybrid architectures that fuse lightweight classical control with data-driven perception to enable fully autonomous, agile nano-UAVs in GPS-denied environments.", "AI": {"tldr": "该综述分析了用于满足极端尺寸、重量和功耗（SWaP）限制的纳米级无人机（nano-UAV）的自主导航的传感、计算和控制架构，重点关注低功耗（sub-100mW）处理器。", "motivation": "纳米级无人机（nano-UAV）面临着严格的SWaP限制，这与传统的机器人范式根本不同，因此需要专门针对这些限制进行研究。", "method": "本文回顾并批判性地分析了从传统的基于几何的方法到新兴的“边缘AI”范式（包括超低功耗SoC上的量化深度神经网络和神经形态事件驱动控制）的转变。此外，还评估了实现自主导航所需的软硬件协同设计。", "result": "在视觉导航和相对姿态估计方面取得了显著进展，但在长期续航能力、动态环境下的鲁棒避障以及强化学习策略的“仿真到现实”迁移方面存在持续的差距。", "conclusion": "为了实现完全自主、敏捷的纳米级无人机在GPS受限环境中的运行，建议采用融合轻量级经典控制和数据驱动感知的混合架构，以弥合当前存在的差距。"}}
{"id": "2601.14089", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14089", "abs": "https://arxiv.org/abs/2601.14089", "authors": ["Zhenxu Zhao", "Ji Wang", "Weiyao Lan"], "title": "Data-Driven Safe Output Regulation of Strict-Feedback Linear Systems with Input Delay", "comment": null, "summary": "This paper develops a data-driven safe control framework for linear systems possessing a known strict-feedback structure, but with most plant parameters, external disturbances, and input delay being unknown. By leveraging Koopman operator theory, we utilize Krylov dynamic mode decomposition (DMD) to extract the system dynamics from measured data, enabling the reconstruction of the system and disturbance matrices. Concurrently, the batch least-squares identification (BaLSI) method is employed to identify other unknown parameters in the input channel. Using control barrier functions (CBFs) and backstepping, we first develop a full-state safe controller. Based on this, we build an output-feedback controller by performing system identification using only the output data and actuation signals as well as constructing an observer to estimate the unmeasured plant states. The proposed approach achieves: 1) finite-time identification of a substantial set of unknown system quantities, and 2) exponential convergence of the output state (the state furthest from the control input) to a reference trajectory while rigorously ensuring safety constraints. The effectiveness of the proposed method is demonstrated through a safe vehicle platooning application.", "AI": {"tldr": "本文提出了一种数据驱动的安全控制框架，用于处理具有未知参数、扰动和输入延迟的线性严格反馈系统。利用 Koopman 算子理论和 DMD 识别系统动力学，BaLSI 识别输入通道参数，并结合 CBF 和反步法实现安全控制。最终，通过输出数据和执行信号构建了输出反馈控制器和状态估计器，实现了安全约束下的输出状态指数收敛。", "motivation": "研究动机是开发一种能够处理具有未知参数、外部扰动和输入延迟的线性严格反馈系统安全控制方法，特别是针对难以获取完整状态信息的情况。", "method": "利用 Koopman 算子理论的 Krylov DMD 识别系统和扰动矩阵，BaLSI 方法识别输入通道参数。结合控制障碍函数 (CBF) 和反步法设计全状态安全控制器。在此基础上，利用输出数据和执行信号进行系统辨识，构建观测器估计状态，从而设计输出反馈控制器。", "result": "实现了未知系统参数的有限时间识别，并保证了输出状态（距离控制输入最远的状态）能够指数收敛到参考轨迹，同时严格遵守安全约束。", "conclusion": "所提出的数据驱动安全控制框架能够有效地识别未知系统量，并在满足安全约束的前提下实现系统状态的指数收敛，该方法在车辆编队行驶等应用中得到了验证。"}}
{"id": "2601.11944", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11944", "abs": "https://arxiv.org/abs/2601.11944", "authors": ["Lexin Ren", "Jiamiao Lu", "Weichuan Zhang", "Benqing Wu", "Tuo Wang", "Yi Liao", "Jiapan Guo", "Changming Sun", "Liang Guo"], "title": "Deep learning-based neurodevelopmental assessment in preterm infants", "comment": "27 pages, 8 figures", "summary": "Preterm infants (born between 28 and 37 weeks of gestation) face elevated risks of neurodevelopmental delays, making early identification crucial for timely intervention. While deep learning-based volumetric segmentation of brain MRI scans offers a promising avenue for assessing neonatal neurodevelopment, achieving accurate segmentation of white matter (WM) and gray matter (GM) in preterm infants remains challenging due to their comparable signal intensities (isointense appearance) on MRI during early brain development. To address this, we propose a novel segmentation neural network, named Hierarchical Dense Attention Network. Our architecture incorporates a 3D spatial-channel attention mechanism combined with an attention-guided dense upsampling strategy to enhance feature discrimination in low-contrast volumetric data. Quantitative experiments demonstrate that our method achieves superior segmentation performance compared to state-of-the-art baselines, effectively tackling the challenge of isointense tissue differentiation. Furthermore, application of our algorithm confirms that WM and GM volumes in preterm infants are significantly lower than those in term infants, providing additional imaging evidence of the neurodevelopmental delays associated with preterm birth. The code is available at: https://github.com/ICL-SUST/HDAN.", "AI": {"tldr": "研究提出了一种名为“分层密集注意力网络”（Hierarchical Dense Attention Network）的新型深度学习模型，用于提高早产儿脑部MRI图像中白质和灰质的分割精度，并利用该模型证实了早产儿的脑容量低于足月儿。", "motivation": "早产儿面临神经发育迟缓的风险，早期识别至关重要。基于深度学习的脑MRI体积分割在评估新生儿神经发育方面有潜力，但早产儿白质和灰质在MRI上因信号强度相似（等强度外观）而难以准确分割。", "method": "提出了一种名为“分层密集注意力网络”（Hierarchical Dense Attention Network）的新型3D卷积神经网络。该网络结合了3D空间-通道注意力机制和注意力引导的密集上采样策略，以增强低对比度体积数据的特征辨别能力。", "result": "所提出的方法在分割任务上取得了优于现有最先进方法的性能，有效解决了等强度组织区分的挑战。此外，该算法的应用证实了早产儿的白质和灰质体积显著低于足月儿。", "conclusion": "该研究提出的分层密集注意力网络能够有效解决早产儿脑部MRI中白质和灰质难以分割的问题，并为早产儿神经发育迟缓提供了额外的影像学证据。"}}
{"id": "2601.12499", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12499", "abs": "https://arxiv.org/abs/2601.12499", "authors": ["Meiru Zhang", "Zaiqiao Meng", "Nigel Collier"], "title": "Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck", "comment": "preprint", "summary": "Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the \"Weakest Link Law\": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that \"thinking\" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.", "AI": {"tldr": "大型语言模型（LLMs）在多跳推理中存在位置偏见问题，导致其忽略特定位置的信息。本研究引入了多焦点注意力指令（MFAI）来区分识别和综合失败，发现模型性能受限于可见性最差的证据（“最弱环节定律”），且这一失败与绝对位置相关而非事实间的距离。研究还发现，匹配的MFAI可以解决识别瓶颈，但误导性MFAI在真实任务中会引发混淆。最后，研究表明采用“系统2”推理的“思考”模型能够有效解决多跳推理中的信息定位和整合问题。", "motivation": "现有的大型语言模型（LLMs）尽管拥有巨大的上下文窗口，但在多跳推理任务中表现不佳，原因可能在于位置偏见。研究者不清楚这种失败是由于模型无法找到证据（识别失败）还是无法整合证据（综合失败）。", "method": "引入了多焦点注意力指令（MFAI）作为一种语义探针，通过显式引导模型注意力至特定位置来区分识别失败和综合失败。在5种LLMs和两个多跳问答任务（MuSiQue和NeoQA）上进行了实验。", "result": "提出了“最弱环节定律”，即多跳推理性能会下降到可见性最差证据的性能水平。这种性能下降主要由绝对位置决定，而非事实间的线性距离（性能方差小于3%）。研究发现，匹配的MFAI可以解决识别瓶颈，提高低可见度位置的准确率达11.5%，而误导性MFAI在真实世界任务中会引起混淆，但在合成任务中可被有效过滤。采用系统2推理的“思考”模型在定位和整合信息方面表现出色，即使在长上下文和噪声环境下也能达到金标准基线水平。", "conclusion": "LLMs在多跳推理中的失败源于对某些绝对位置信息的可见性不足，而非证据间的距离。MFAI可以用来诊断和解决这些问题。采用系统2推理的LLMs能够克服这些挑战，在复杂环境中实现高效的多跳推理。"}}
{"id": "2601.14098", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14098", "abs": "https://arxiv.org/abs/2601.14098", "authors": ["Cristian Sestito", "Panagiota Kontou", "Pratibha Verma", "Atish Dixit", "Alexandros D. Keros", "Michael O'Boyle", "Christos-Savvas Bouganis", "Themis Prodromakis"], "title": "A flexible language model-assisted electronic design automation framework", "comment": "17 pages, 5 figures, 1 Supplementary (12 pages, 13 figures, 1 table)", "summary": "Large language models (LLMs) are transforming electronic design automation (EDA) by enhancing design stages such as schematic design, simulation, netlist synthesis, and place-and-route. Existing methods primarily focus these optimisations within isolated open-source EDA tools and often lack the flexibility to handle multiple domains, such as analogue, digital, and radio-frequency design. In contrast, modern systems require to interface with commercial EDA environments, adhere to tool-specific operation rules, and incorporate feedback from design outcomes while supporting diverse design flows. We propose a versatile framework that uses LLMs to generate files compatible with commercial EDA tools and optimise designs using power-performance-area reports. This is accomplished by guiding the LLMs with tool constraints and feedback from design outputs to meet tool requirements and user specifications. Case studies on operational transconductance amplifiers, microstrip patch antennas, and FPGA circuits show that the framework is effective as an EDA-aware assistant, handling diverse design challenges reliably.", "AI": {"tldr": "提出一个基于大语言模型（LLM）的通用框架，能够生成兼容商业EDA工具的文件，并通过分析设计报告进行优化，以支持模拟、数字和射频等多种设计流程。", "motivation": "现有方法仅限于开源EDA工具，缺乏跨领域（模拟、数字、射频）的灵活性，无法满足现代系统需要与商业EDA环境接口、遵循工具规则并结合设计反馈的需求。", "method": "利用大语言模型生成符合商业EDA工具格式的文件，并通过电源-性能-面积（PPA）报告反馈来指导LLM进行设计优化。框架通过工具约束和设计输出反馈来引导LLM。", "result": "在运算跨导放大器、微带贴片天线和FPGA电路的案例研究中，表明该框架能作为EDA感知的助手，可靠地应对各种设计挑战。", "conclusion": "提出的框架通过LLM与商业EDA工具集成，并结合设计反馈，能够有效地支持多样化的设计流程，成为一个灵活的EDA设计助手。"}}
{"id": "2601.12099", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12099", "abs": "https://arxiv.org/abs/2601.12099", "authors": ["Leonardo S. Goodall", "Dor Shilton", "Daniel A. Mullins", "Harvey Whitehouse"], "title": "Large language models struggle with ethnographic text annotation", "comment": null, "summary": "Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.", "AI": {"tldr": "大型语言模型（LLMs）在自动化民族志文本标注方面表现不佳，无法达到可靠的自动化标注所需水平，即使在人类标注者高度一致的特征上也是如此。", "motivation": "希望利用大型语言模型（LLMs）来自动化民族志文本标注，以加速跨文化研究。", "method": "评估了7个最先进的LLMs在标注121个仪式特征和567个民族志摘录方面的能力。", "result": "LLMs的性能有限，远低于可靠自动化标注的要求。长文本、需要序数区分的特征以及模糊的构建尤其困难。人类标注者之间的信度设定了LLM准确性的上限，但即使在人类标注者达成一致的特征上，LLMs的表现也未达人类水平。", "conclusion": "目前，LLMs尚不能替代人类在民族志标注方面的专业知识。"}}
{"id": "2601.12538", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12538", "abs": "https://arxiv.org/abs/2601.12538", "authors": ["Tianxin Wei", "Ting-Wei Li", "Zhining Liu", "Xuying Ning", "Ze Yang", "Jiaru Zou", "Zhichen Zeng", "Ruizhong Qiu", "Xiao Lin", "Dongqi Fu", "Zihao Li", "Mengting Ai", "Duo Zhou", "Wenxuan Bao", "Yunzhe Li", "Gaotang Li", "Cheng Qian", "Yu Wang", "Xiangru Tang", "Yin Xiao", "Liri Fang", "Hui Liu", "Xianfeng Tang", "Yuji Zhang", "Chi Wang", "Jiaxuan You", "Heng Ji", "Hanghang Tong", "Jingrui He"], "title": "Agentic Reasoning for Large Language Models", "comment": "Project: https://github.com/weitianxin/Awesome-Agentic-Reasoning", "summary": "Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.", "AI": {"tldr": "本调查对生成式AI代理的推理能力进行了全面梳理，将其划分为三个层面（基础、自适应、多智能体），并区分了两种推理范式（上下文内推理和训练后推理），同时回顾了现有应用和未来研究方向。", "motivation": "大型语言模型（LLM）在封闭世界中表现出强大的推理能力，但在开放和动态环境中存在不足。代理推理作为一种新的范式，将LLM视为能够规划、行动和学习的自主代理，旨在克服这些局限性。", "method": "本调查首先将代理推理沿着三个维度进行组织：环境动态（基础、自适应、多智能体）和推理范式（上下文内推理、训练后推理）。然后，回顾了跨越科学、机器人、医疗、自主研究和数学等领域的代表性代理推理框架和应用，并分析了其在不同层面的能力。", "result": "调查将代理推理方法整合到一个统一的路线图中，连接了思考和行动。同时，识别了当前研究的空白和未来的研究方向，包括个性化、长时交互、世界建模、可扩展多智能体训练以及现实世界部署的治理。", "conclusion": "代理推理是提升LLM在开放和动态环境中的能力的关键范式，通过规划、行动和持续学习，能够实现更强大的认知能力。本调查为理解和推进代理推理领域提供了一个全面的框架和未来发展方向。"}}
{"id": "2601.11952", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11952", "abs": "https://arxiv.org/abs/2601.11952", "authors": ["Haonan An", "Guang Hua", "Wei Du", "Hangcheng Cao", "Yihang Tao", "Guowen Xu", "Susanto Rahardja", "Yuguang Fang"], "title": "Decoder Gradient Shields: A Family of Provable and High-Fidelity Methods Against Gradient-Based Box-Free Watermark Removal", "comment": null, "summary": "Box-free model watermarking has gained significant attention in deep neural network (DNN) intellectual property protection due to its model-agnostic nature and its ability to flexibly manage high-entropy image outputs from generative models. Typically operating in a black-box manner, it employs an encoder-decoder framework for watermark embedding and extraction. While existing research has focused primarily on the encoders for the robustness to resist various attacks, the decoders have been largely overlooked, leading to attacks against the watermark. In this paper, we identify one such attack against the decoder, where query responses are utilized to obtain backpropagated gradients to train a watermark remover. To address this issue, we propose Decoder Gradient Shields (DGSs), a family of defense mechanisms, including DGS at the output (DGS-O), at the input (DGS-I), and in the layers (DGS-L) of the decoder, with a closed-form solution for DGS-O and provable performance for all DGS. Leveraging the joint design of reorienting and rescaling of the gradients from watermark channel gradient leaking queries, the proposed DGSs effectively prevent the watermark remover from achieving training convergence to the desired low-loss value, while preserving image quality of the decoder output. We demonstrate the effectiveness of our proposed DGSs in diverse application scenarios. Our experimental results on deraining and image generation tasks with the state-of-the-art box-free watermarking show that our DGSs achieve a defense success rate of 100% under all settings.", "AI": {"tldr": "本文提出了一种名为DGS（Decoder Gradient Shields）的防御机制，用于保护无框模型水印免受基于梯度泄露的攻击，该机制通过重定向和缩放梯度来阻止水印移除模型的收敛，并在各种应用场景下实现了100%的防御成功率。", "motivation": "现有无框模型水印研究主要关注水印嵌入器的鲁棒性，而忽略了水印提取器的安全性，导致存在针对提取器的攻击。本文发现了利用查询响应获取反向传播梯度来训练水印移除器的攻击方法，因此需要开发针对水印提取器的防御机制。", "method": "提出了Decoder Gradient Shields（DGS）防御家族，包括DGS-O（输出）、DGS-I（输入）和DGS-L（层内）。DGS-O具有闭式解，所有DGS都具有可证明的性能。该方法通过联合设计梯度重定向和缩放来应对水印通道梯度泄露查询，阻止水印移除模型收敛。", "result": "提出的DGSs能够有效阻止水印移除器实现低损失值的训练收敛，同时保持提取器输出的图像质量。在去雨和图像生成任务中，使用最先进的无框水印方法，DGSs在所有设置下均实现了100%的防御成功率。", "conclusion": "DGSs是一种有效的防御机制，能够保护无框模型水印免受基于梯度泄露的攻击，通过精细控制提取器内部的梯度信息，确保水印的安全性和模型的鲁棒性。"}}
{"id": "2601.14164", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14164", "abs": "https://arxiv.org/abs/2601.14164", "authors": ["Yichen Guo", "Tao Peng", "Yujie Zhao", "Yijing Niu", "Wenbo Wang"], "title": "The Impact of Interference Cognition on the Reliability and Capacity of Industrial Wireless Communications", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Interference significantly impacts the performance of industrial wireless networks, particularly n severe interference environments with dense networks reusing spectrum resources intensively. Although delicate interference information is often unavailable in conventional networks, emerging interference cognition techniques can compensate this critical problem with possibly different precision. This paper investigates the relationship between precision of interference cognition and system performance. We propose a novel performance analysis framework that quantifies the impact of varying interference information precision on achievable rate.\n  Specifically, leveraging the Nakagami-$\\mathbf{m}$ fading channel model, we analytically and asymptotically analyze the average achievable rate in the finite blocklength regime for different precision levels of signal and interference information. Our findings reveal the critical importance of identifying per-link interference information for achieving optimal performance. Additionally, obtaining instantaneous information is more beneficial for signal links.", "AI": {"tldr": "本研究探讨了干扰信息认知精度对工业无线网络系统性能的影响，并提出了一个量化分析框架，研究在不同精度下的可达速率。", "motivation": "工业无线网络中，尤其是在密集和频谱复用程度高的环境中，干扰严重影响网络性能，而传统网络通常缺乏精细的干扰信息。", "method": "利用Nakagami-m衰落信道模型，对信号和干扰信息的不同精度水平下，有限块长模型下的平均可达速率进行了解析和渐近分析。", "result": "研究发现，识别每链路的干扰信息对于实现最优性能至关重要。此外，获取瞬时信号信息对信号链路更有益。", "conclusion": "干扰信息认知精度直接影响工业无线网络的系统性能，识别每链路的干扰信息和获取瞬时信号信息是提高性能的关键。"}}
{"id": "2601.11970", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11970", "abs": "https://arxiv.org/abs/2601.11970", "authors": ["S. M. Khalid Bin Zahid", "Md. Rakibul Hasan Nishat", "Abdul Hasib", "Md. Rakibul Hasan", "Md. Ashiqussalehin", "Md. Sahadat Hossen Sajib", "A. S. M. Ahsanul Sarkar Akib"], "title": "Real-Time Multi-Modal Embedded Vision Framework for Object Detection Facial Emotion Recognition and Biometric Identification on Low-Power Edge Platforms", "comment": null, "summary": "Intelligent surveillance systems often handle perceptual tasks such as object detection, facial recognition, and emotion analysis independently, but they lack a unified, adaptive runtime scheduler that dynamically allocates computational resources based on contextual triggers. This limits their holistic understanding and efficiency on low-power edge devices. To address this, we present a real-time multi-modal vision framework that integrates object detection, owner-specific face recognition, and emotion detection into a unified pipeline deployed on a Raspberry Pi 5 edge platform. The core of our system is an adaptive scheduling mechanism that reduces computational load by 65\\% compared to continuous processing by selectively activating modules such as, YOLOv8n for object detection, a custom FaceNet-based embedding system for facial recognition, and DeepFace's CNN for emotion classification. Experimental results demonstrate the system's efficacy, with the object detection module achieving an Average Precision (AP) of 0.861, facial recognition attaining 88\\% accuracy, and emotion detection showing strong discriminatory power (AUC up to 0.97 for specific emotions), while operating at 5.6 frames per second. Our work demonstrates that context-aware scheduling is the key to unlocking complex multi-modal AI on cost-effective edge hardware, making intelligent perception more accessible and privacy-preserving.", "AI": {"tldr": "本文提出了一种用于低功耗边缘设备（如树莓派 5）的多模态视觉框架，集成了对象检测、人脸识别和情绪分析。通过引入一种自适应调度机制，该框架能够根据上下文动态分配计算资源，从而将计算负载降低 65%，同时保持了高精度和实时的性能。", "motivation": "现有的智能监控系统通常独立处理感知任务，缺乏一个能够根据上下文动态分配计算资源的统一调度器，这限制了它们在低功耗边缘设备上的整体理解和效率。作者希望解决这个问题。", "method": "作者开发了一个实时多模态视觉框架，将对象检测（YOLOv8n）、特定人脸识别（FaceNet-based embedding）和情绪检测（DeepFace's CNN）集成到一个统一的流程中，并部署在树莓派 5 平台上。核心是引入了一个自适应调度机制，通过选择性地激活模块来降低计算量。", "result": "对象检测模块的平均精度（AP）为 0.861，人脸识别准确率为 88%，情绪检测的 AUC 最高可达 0.97。系统在 5.6 帧/秒的速率下运行，计算负载相比连续处理降低了 65%。", "conclusion": "这项工作表明，上下文感知调度是实现成本效益高的边缘硬件上复杂多模态人工智能的关键，使得智能感知更加易于访问且注重隐私。"}}
{"id": "2601.12539", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12539", "abs": "https://arxiv.org/abs/2601.12539", "authors": ["Ali Ezzat Shahroor", "Mohamed Bayan Kmainasi", "Abul Hasnat", "Dimitar Dimitrov", "Giovanni Da San Martino", "Preslav Nakov", "Firoj Alam"], "title": "MemeLens: Multilingual Multitask VLMs for Memes", "comment": "disinformation, misinformation, factuality, harmfulness, fake news, propaganda, hateful meme, multimodality, text, images", "summary": "Memes are a dominant medium for online communication and manipulation because meaning emerges from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks (hate, misogyny, propaganda, sentiment, humour) and languages, which limits cross-domain generalization. To address this gap we propose MemeLens, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. We consolidate 38 public meme datasets, filter and map dataset-specific labels into a shared taxonomy of $20$ tasks spanning harm, targets, figurative/pragmatic intent, and affect. We present a comprehensive empirical analysis across modeling paradigms, task categories, and datasets. Our findings suggest that robust meme understanding requires multimodal training, exhibits substantial variation across semantic categories, and remains sensitive to over-specialization when models are fine-tuned on individual datasets rather than trained in a unified setting. We will make the experimental resources and datasets publicly available for the community.", "AI": {"tldr": "本研究提出了 MemeLens，一个统一的多语言、多任务、增强解释的视觉语言模型（VLM），用于理解模因。通过整合 38 个公共模因数据集并映射到 20 个共享任务，该模型旨在克服现有研究分散和跨领域泛化能力不足的问题。", "motivation": "现有对模因的研究分散在不同的任务和语言中，阻碍了跨领域泛化能力。模因作为在线交流和操纵的重要媒介，其含义源于文本、图像和文化背景的互动，因此需要一个统一的模型来深入理解。", "method": "研究者提出了 MemeLens，一个统一的多语言、多任务、增强解释的视觉语言模型（VLM）。他们整合了 38 个公共模因数据集，并将特定于数据集的标签过滤并映射到一个包含 20 个任务的共享分类体系中，这些任务涵盖了危害、目标、象征/语用意图和情感等方面。对不同的建模范式、任务类别和数据集进行了全面的实证分析。", "result": "研究发现，鲁棒的模因理解需要多模态训练，在语义类别之间存在显著差异，并且在单个数据集上进行微调而不是统一训练时，模型仍然容易过度专业化。多任务和多语言训练在不同任务和数据集上表现出更强的泛化能力。", "conclusion": "统一的多语言、多任务、增强解释的 VLM 方法（MemeLens）对于提升模因理解能力至关重要，尤其是在跨领域和跨语言的场景下。研究强调了多模态训练和避免模型过度专业化的重要性，并承诺将实验资源和数据集开源以供社区使用。"}}
{"id": "2601.12104", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12104", "abs": "https://arxiv.org/abs/2601.12104", "authors": ["David Ilić", "David Stanojević", "Kostadin Cvejoski"], "title": "Powerful Training-Free Membership Inference Against Autoregressive Language Models", "comment": "9 pages, 2 figures; appendix with additional experiments and derivations", "summary": "Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive information from their training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at the low false-positive thresholds required for practical privacy auditing. We present EZ-MIA, a membership inference attack that exploits a key observation: memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. We introduce the Error Zone (EZ) score, which measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This principled statistic requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8x higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, we achieve 8x higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, we achieve 3x higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at https://github.com/JetBrains-Research/ez-mia.", "AI": {"tldr": "研究提出了一种名为EZ-MIA的新型成员推理攻击方法，该方法通过分析模型在错误预测的token位置的概率偏移来检测训练数据中的敏感信息泄露，在多个基准测试中显著优于现有方法，尤其是在低误报率下。", "motivation": "微调后的语言模型可能泄露训练数据中的敏感信息，现有的成员推理攻击方法在实际应用所需低误报率下检测率有限，因此需要更有效的隐私审计方法。", "method": "提出EZ-MIA攻击，利用模型在错误预测的token位置对训练样本表现出异常高概率的观察。引入Error Zone (EZ) score，衡量概率偏移的定向不平衡性，该方法只需两次前向传播，无需模型训练。", "result": "在WikiText上，EZ-MIA在1%误报率下实现了比SOTA高3.8倍的检测率（66.3% vs 17.5%），AUC达到0.98。在0.1%误报率下，检测率高8倍（14.0% vs 1.8%）。在AG News上，EZ-MIA在Llama-2-7B上实现了3倍的检测率提升（46.7% vs 15.8%）。", "conclusion": "微调语言模型的隐私风险比之前认为的更大。EZ-MIA是一种高效且无需额外训练的成员推理攻击方法，为隐私审计和模型部署决策提供了重要参考。"}}
{"id": "2601.13451", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13451", "abs": "https://arxiv.org/abs/2601.13451", "authors": ["Reza Ahmadvand", "Sarah Safura Sharif", "Yaser Mike Banad"], "title": "Event-based Heterogeneous Information Processing for Online Vision-based Obstacle Detection and Localization", "comment": null, "summary": "This paper introduces a novel framework for robotic vision-based navigation that integrates Hybrid Neural Networks (HNNs) with Spiking Neural Network (SNN)-based filtering to enhance situational awareness for unmodeled obstacle detection and localization. By leveraging the complementary strengths of Artificial Neural Networks (ANNs) and SNNs, the system achieves both accurate environmental understanding and fast, energy-efficient processing. The proposed architecture employs a dual-pathway approach: an ANN component processes static spatial features at low frequency, while an SNN component handles dynamic, event-based sensor data in real time. Unlike conventional hybrid architectures that rely on domain conversion mechanisms, our system incorporates a pre-developed SNN-based filter that directly utilizes spike-encoded inputs for localization and state estimation. Detected anomalies are validated using contextual information from the ANN pathway and continuously tracked to support anticipatory navigation strategies. Simulation results demonstrate that the proposed method offers acceptable detection accuracy while maintaining computational efficiency close to SNN-only implementations, which operate at a fraction of the resource cost. This framework represents a significant advancement in neuromorphic navigation systems for robots operating in unpredictable and dynamic environments.", "AI": {"tldr": "该研究提出了一种新的机器人视觉导航框架，结合了混合神经网络（HNN）和基于脉冲神经网络（SNN）的滤波，以增强对未建模障碍物的态势感知、检测和定位能力，同时实现高能效。", "motivation": "现有机器人导航系统在处理不可预测和动态环境中未建模障碍物时存在挑战，需要提高态势感知、检测和定位的准确性，并兼顾计算效率和能耗。", "method": "提出了一种双通路混合神经网络架构。一个ANN通路处理低频静态空间特征，一个SNN通路处理实时动态事件传感器数据。SNN通路直接利用脉冲编码输入进行定位和状态估计，并通过上下文信息验证和追踪检测到的异常。", "result": "仿真结果表明，该方法在保持接近SNN纯粹实现的计算效率（资源成本仅为一小部分）的同时，提供了可接受的检测精度。", "conclusion": "该框架通过融合ANN和SNN的优势，为在不可预测和动态环境中运行的机器人提供了更高效、更具态势感知能力的神经形态导航系统，有助于实现预见性导航策略。"}}
{"id": "2601.12542", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12542", "abs": "https://arxiv.org/abs/2601.12542", "authors": ["Lukas Weidener", "Marko Brkić", "Mihailo Jovanović", "Ritvik Singh", "Chiara Baccin", "Emre Ulgac", "Alex Dobrin", "Aakaash Meduri"], "title": "Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery", "comment": null, "summary": "Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.", "AI": {"tldr": "本文提出了一种名为 Deep Research 的多智能体系统，实现了可在数分钟内完成研究周期的交互式科学探索，并在计算生物学基准测试 BixBench 上取得了优于现有方法的性能。", "motivation": "现有的 AI 科学发现系统大多是专有的、批处理模式的，研究周期长达数小时，无法实时指导研究人员。这限制了 AI 在科学发现中的应用，促使研究人员开发更快速、更具交互性的系统。", "method": "Deep Research 系统包含规划、数据分析、文献检索和新颖性检测等专业智能体。通过一个持久化的世界状态来维护跨迭代研究周期的上下文。系统支持半自主模式（带有人工检查点）和全自主模式。", "result": "在 BixBench 计算生物学基准测试中，Deep Research 达到了 48.8% 的开放式问题准确率和 64.5% 的选择题准确率，比现有基线提高了 14-26 个百分点。", "conclusion": "Deep Research 系统能够实现快速、交互式的科学探索，并在计算生物学领域取得领先性能。论文还讨论了该系统在开放获取文献限制和自动化新颖性评估方面的挑战，为 AI 辅助科学工作流程的实际部署提供了参考。"}}
{"id": "2601.12766", "categories": ["cs.CV", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.12766", "abs": "https://arxiv.org/abs/2601.12766", "authors": ["Lu Yue", "Yue Fan", "Shiwei Lian", "Yu Zhao", "Jiaxin Yu", "Liang Xie", "Feitian Zhang"], "title": "Spatial-VLN: Zero-Shot Vision-and-Language Navigation With Explicit Spatial Perception and Exploration", "comment": null, "summary": "Zero-shot Vision-and-Language Navigation (VLN) agents leveraging Large Language Models (LLMs) excel in generalization but suffer from insufficient spatial perception. Focusing on complex continuous environments, we categorize key perceptual bottlenecks into three spatial challenges: door interaction,multi-room navigation, and ambiguous instruction execution, where existing methods consistently suffer high failure rates. We present Spatial-VLN, a perception-guided exploration framework designed to overcome these challenges. The framework consists of two main modules. The Spatial Perception Enhancement (SPE) module integrates panoramic filtering with specialized door and region experts to produce spatially coherent, cross-view consistent perceptual representations. Building on this foundation, our Explored Multi-expert Reasoning (EMR) module uses parallel LLM experts to address waypoint-level semantics and region-level spatial transitions. When discrepancies arise between expert predictions, a query-and-explore mechanism is activated, prompting the agent to actively probe critical areas and resolve perceptual ambiguities. Experiments on VLN-CE demonstrate that Spatial VLN achieves state-of-the-art performance using only low-cost LLMs. Furthermore, to validate real-world applicability, we introduce a value-based waypoint sampling strategy that effectively bridges the Sim2Real gap. Extensive real-world evaluations confirm that our framework delivers superior generalization and robustness in complex environments. Our codes and videos are available at https://yueluhhxx.github.io/Spatial-VLN-web/.", "AI": {"tldr": "本文提出了一种名为Spatial-VLN的框架，通过增强空间感知能力来提升大型语言模型（LLMs）在视觉语言导航（VLN）任务中的表现，尤其是在处理门交互、多房间导航和模糊指令等复杂场景时。", "motivation": "现有的基于LLMs的零样本VLN代理在泛化能力方面表现出色，但在处理连续复杂环境中的空间感知方面存在不足，尤其是在门交互、多房间导航和模糊指令执行等关键环节，导致高失败率。", "method": "Spatial-VLN框架包含两个主要模块：空间感知增强（SPE）模块，通过全景滤波和门/区域专家来生成空间一致的感知表示；以及探索性多专家推理（EMR）模块，利用并行的LLM专家处理路径点语义和区域间空间转换。当专家预测不一致时，会触发查询-探索机制，引导代理主动探测关键区域以解决感知歧义。此外，还引入了一种基于价值的路径点采样策略来弥合Sim2Real差距。", "result": "Spatial-VLN在VLN-CE数据集上取得了最先进的性能，同时在真实世界环境中也展现了优越的泛化能力和鲁棒性。", "conclusion": "Spatial-VLN通过其创新的空间感知增强和多专家推理机制，有效解决了LLM在复杂连续环境VLN中的空间感知瓶颈，并在模拟和真实世界评估中均取得了显著成果。"}}
{"id": "2601.13361", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13361", "abs": "https://arxiv.org/abs/2601.13361", "authors": ["Pranay Meshram", "Charuvahan Adhivarahan", "Ehsan Tarkesh Esfahani", "Souma Chowdhury", "Chen Wang", "Karthik Dantu"], "title": "CLEAR: A Semantic-Geometric Terrain Abstraction for Large-Scale Unstructured Environments", "comment": "Under review for an IEEE conference", "summary": "Long-horizon navigation in unstructured environments demands terrain abstractions that scale to tens of km$^2$ while preserving semantic and geometric structure, a combination existing methods fail to achieve. Grids scale poorly; quadtrees misalign with terrain boundaries; neither encodes landcover semantics essential for traversability-aware planning. This yields infeasible or unreliable paths for autonomous ground vehicles operating over 10+ km$^2$ under real-time constraints. CLEAR (Connected Landcover Elevation Abstract Representation) couples boundary-aware spatial decomposition with recursive plane fitting to produce convex, semantically aligned regions encoded as a terrain-aware graph. Evaluated on maps spanning 9-100~km$^2$ using a physics-based simulator, CLEAR achieves up to 10x faster planning than raw grids with only 6.7% cost overhead and delivers 6-9% shorter, more reliable paths than other abstraction baselines. These results highlight CLEAR's scalability and utility for long-range navigation in applications such as disaster response, defense, and planetary exploration.", "AI": {"tldr": "提出了一种名为CLEAR的新型地形抽象表示方法，能够高效、准确地处理大规模非结构化环境中的长距离导航问题，并提高了路径规划的效率和可靠性。", "motivation": "现有的地形抽象方法在处理大规模（几十平方公里）且需要保留语义和几何结构的环境时存在可扩展性差、与地形边界对齐不佳以及无法编码土地覆盖语义等问题，导致自主地面车辆在长距离（10+公里）实时导航时路径不可行或不可靠。", "method": "CLEAR方法结合了边界感知的空间分解和递归平面拟合技术，生成了符合语义的凸区域，并将其编码为一个地形感知图。通过在不同大小的地图上使用基于物理的模拟器进行评估。", "result": "在9-100平方公里的地图上，CLEAR比原始栅格的规划速度提高了10倍，成本开销仅为6.7%，且路径比其他抽象基线更短（6-9%）、更可靠。", "conclusion": "CLEAR方法在可扩展性和实用性方面表现出色，适用于灾难响应、国防和行星探索等需要长距离导航的应用场景。"}}
{"id": "2601.12132", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12132", "abs": "https://arxiv.org/abs/2601.12132", "authors": ["Md Mahmudul Hoque", "Md Mehedi Hassain", "Md Hojaifa Tanvir", "Rahul Nandy"], "title": "Bengali Text Classification: An Evaluation of Large Language Model Approaches", "comment": null, "summary": "Bengali text classification is a Significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the \"Sports\" category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.", "AI": {"tldr": "研究评估了三种指令调优的大语言模型（LLMs）在孟加拉语报纸文章分类任务上的表现。Qwen 2.5 7B Instruct 达到了最高的 72% 的准确率，尤其在“体育”类别上表现突出，而 LLaMA 模型则准确率较低。", "motivation": "孟加拉语文本分类在自然语言处理中很重要，但由于缺乏标注数据集和预训练模型而面临挑战。本研究旨在探索大语言模型在解决这些挑战方面的有效性。", "method": "使用来自 Prothom Alo 的孟加拉语报纸文章数据集，评估了 LLaMA 3.1 8B Instruct、LLaMA 3.2 3B Instruct 和 Qwen 2.5 7B Instruct 三种指令调优的大语言模型在文本分类任务上的表现。", "result": "Qwen 2.5 7B Instruct 取得了 72% 的最高分类准确率，在“体育”类别上表现尤为出色。LLaMA 3.1 和 LLaMA 3.2 的准确率分别为 53% 和 56%。", "conclusion": "研究表明，尽管孟加拉语 NLP 资源匮乏，大语言模型在孟加拉语文本分类任务上是有效的，Qwen 2.5 模型表现出最佳性能。未来的研究将进一步探索更多模型、解决类别不平衡问题以及优化微调方法。"}}
{"id": "2601.13389", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13389", "abs": "https://arxiv.org/abs/2601.13389", "authors": ["Zhaohui Liang", "Chengyuan Ma", "Keke Long", "Xiaopeng Li"], "title": "Robustness and Resilience Evaluation of Eco-Driving Strategies at Signalized Intersections", "comment": null, "summary": "Eco-driving strategies have demonstrated substantial potential for improving energy efficiency and reducing emissions, especially at signalized intersections. However, evaluations of eco-driving methods typically rely on simplified simulation or experimental conditions, where certain assumptions are made to manage complexity and experimental control. This study introduces a unified framework to evaluate eco-driving strategies through the lens of two complementary criteria: control robustness and environmental resilience. We define formal indicators that quantify performance degradation caused by internal execution variability and external environmental disturbances, respectively. These indicators are then applied to assess multiple eco-driving controllers through real-world vehicle experiments. The results reveal key tradeoffs between tracking accuracy and adaptability, showing that optimization-based controllers offer more consistent performance across varying disturbance levels, while analytical controllers may perform comparably under nominal conditions but exhibit greater sensitivity to execution and timing variability.", "AI": {"tldr": "本研究提出了一个统一的框架，通过控制鲁棒性和环境韧性两个互补标准来评估生态驾驶策略，并对不同类型的生态驾驶控制器进行了实际车辆实验评估。", "motivation": "现有的生态驾驶方法评估依赖于简化的模拟或实验条件，忽略了实际执行变异性和环境干扰的影响。研究旨在提供一种更全面的评估方法，以应对真实世界中的复杂性。", "method": "提出了一种统一的评估框架，定义了量化内部执行变异性和外部环境干扰影响的正式指标。通过真实世界车辆实验，将这些指标应用于评估多种生态驾驶控制器。", "result": "研究揭示了跟踪精度和适应性之间的权衡。基于优化的控制器在不同干扰水平下表现出更一致的性能，而解析控制器在标称条件下性能相当，但在执行和时序变异性方面更敏感。", "conclusion": "通过控制鲁棒性和环境韧性的综合评估，可以更准确地理解不同生态驾驶策略在实际应用中的优缺点，并为控制器设计提供指导。"}}
{"id": "2601.13529", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13529", "abs": "https://arxiv.org/abs/2601.13529", "authors": ["Pejman Kheradmand", "Kent K. Yamamoto", "Emma Webster", "Keith Sowards", "Gianna Hatheway", "Katharine L. Jackson", "Sabino Zani", "Julie A. Raffi", "Diandra N. Ayala-Peacock", "Scott R. Silva", "Joanna Deaton Bertram", "Yash Chitalia"], "title": "The OncoReach Stylet for Brachytherapy: Design Evaluation and Pilot Study", "comment": null, "summary": "Cervical cancer accounts for a significant portion of the global cancer burden among women. Interstitial brachytherapy (ISBT) is a standard procedure for treating cervical cancer; it involves placing a radioactive source through a straight hollow needle within or in close proximity to the tumor and surrounding tissue. However, the use of straight needles limits surgical planning to a linear needle path. We present the OncoReach stylet, a handheld, tendon-driven steerable stylet designed for compatibility with standard ISBT 15- and 13-gauge needles. Building upon our prior work, we evaluated design parameters like needle gauge, spherical joint count and spherical joint placement, including an asymmetric disk design to identify a configuration that maximizes bending compliance while retaining axial stiffness. Free space experiments quantified tip deflection across configurations, and a two-tube Cosserat rod model accurately predicted the centerline shape of the needle for most trials. The best performing configuration was integrated into a reusable handheld prototype that enables manual actuation. A patient-derived, multi-composite phantom model of the uterus and pelvis was developed to conduct a pilot study of the OncoReach steerable stylet with one expert user. Results showed the ability to steer from less-invasive, medial entry points to reach the lateral-most targets, underscoring the significance of steerable stylets.", "AI": {"tldr": "该研究提出了一种名为OncoReach的可操纵探针，用于宫颈癌间质后装治疗，该探针能克服传统直针的限制，实现更灵活的肿瘤靶向，并在仿真和人体组织模型中进行了初步验证。", "motivation": "现有宫颈癌的间质后装治疗（ISBT）依赖于直线针头，限制了手术规划的灵活性，无法充分靶向肿瘤及周围组织。需要一种能够实现弯曲操纵的工具来提高治疗的靶向性和覆盖范围。", "method": "研究人员设计并评估了OncoReach探针的多种参数，包括针头规格、球形关节数量和位置，以及非对称盘设计，以优化弯曲性和轴向刚度。通过自由空间实验量化了不同配置下的针尖偏转，并使用Cosserat杆模型预测了针头中心线形状。最后，将最优配置集成到原型中，并在用户操作和仿体模型上进行了初步临床试验。", "result": "研究确定了最优的探针设计配置，该配置能够最大化弯曲性并保持轴向刚度。仿体模型试验表明，OncoReach探针能够从侵入性较小的内侧进入点引导至最外侧的靶点，证明了其可操纵性的优势。", "conclusion": "OncoReach可操纵探针是一种有前景的工具，能够增强宫颈癌ISBT的靶向能力，通过实现从非侵入性入点到达远端靶点，为宫颈癌的治疗提供了新的可能性。"}}
{"id": "2601.12547", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12547", "abs": "https://arxiv.org/abs/2601.12547", "authors": ["Dipayan Sengupta", "Saumya Panda"], "title": "How Clinicians Think and What AI Can Learn From It", "comment": "34 pages", "summary": "Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\\to$ perception $\\to$ inference $\\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($ε$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.", "AI": {"tldr": "本研究提出，临床决策的计算基础并非标准的基数优化，而是序数、非补偿性决策。作者认为，临床医生依赖于快速-简便、词典式的启发式方法（如快速-简便决策树），并从规范性角度论证了这类算法在医学中的优势，并提出了与临床医生对齐的人工智能设计蓝图。", "motivation": "现有临床AI系统主要作为预测引擎，而真实的临床决策是一个在不确定性下进行的时间约束下的顺序控制问题。研究者认为，AI系统未能捕捉临床医生决策的本质，即依赖于启发式和序数决策。", "method": "本文从规范性角度出发，论证了序数、非补偿性决策（特别是启发式方法，如快速-简便决策树）在医学中的优势。研究分析了医学决策中的不确定性、测量精度以及信息传递过程中的噪声，并提出了基于ε-dominance和maximin等稳健序数规则来稳定决策。最后，作者勾勒了一个结合丰富模型和稳健序数规则的AI设计蓝图。", "result": "研究表明，在许多临床场景下，由于测量和偏好信息的不确定性，序数决策比基数优化更为稳健。当信息的不确定性显著时，基于启发式和过滤规则的决策更加稳定，对小的扰动不敏感。", "conclusion": "临床决策本质上是序数的、非补偿性的，而非基数优化。快速-简便的启发式方法在医学中具有规范性优势。AI系统应采用结合丰富模型和稳健序数规则的设计，并作为“选择性复杂性”工具，主要用于打破僵局，解决脆弱的决策问题。"}}
{"id": "2601.11981", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11981", "abs": "https://arxiv.org/abs/2601.11981", "authors": ["Jian Lang", "Rongpei Hong", "Ting Zhong", "Yong Wang", "Fan Zhou"], "title": "Nip Rumors in the Bud: Retrieval-Guided Topic-Level Adaptation for Test-Time Fake News Video Detection", "comment": "13 pages. Accepted by KDD 2026 research track. Codes are released at https://github.com/Jian-Lang/RADAR", "summary": "Fake News Video Detection (FNVD) is critical for social stability. Existing methods typically assume consistent news topic distribution between training and test phases, failing to detect fake news videos tied to emerging events and unseen topics. To bridge this gap, we introduce RADAR, the first framework that enables test-time adaptation to unseen news videos. RADAR pioneers a new retrieval-guided adaptation paradigm that leverages stable (source-close) videos from the target domain to guide robust adaptation of semantically related but unstable instances. Specifically, we propose an Entropy Selection-Based Retrieval mechanism that provides videos with stable (low-entropy), relevant references for adaptation. We also introduce a Stable Anchor-Guided Alignment module that explicitly aligns unstable instances' representations to the source domain via distribution-level matching with their stable references, mitigating severe domain discrepancies. Finally, our novel Target-Domain Aware Self-Training paradigm can generate informative pseudo-labels augmented by stable references, capturing varying and imbalanced category distributions in the target domain and enabling RADAR to adapt to the fast-changing label distributions. Extensive experiments demonstrate that RADAR achieves superior performance for test-time FNVD, enabling strong on-the-fly adaptation to unseen fake news video topics.", "AI": {"tldr": "本文提出了RADAR框架，用于检测与新兴事件和未见主题相关的假新闻视频，实现了测试时自适应。", "motivation": "现有假新闻视频检测方法在训练和测试阶段假设新闻主题分布一致，无法检测与新兴事件和未见主题相关的假新闻视频。", "method": "RADAR框架采用一种新颖的检索引导自适应范式，利用目标域中稳定的（接近源域）视频指导语义相关但不稳定的实例进行鲁棒自适应。具体方法包括：1. 基于熵选择的检索机制，提供具有稳定（低熵）、相关性强的参考视频进行自适应。2. 稳定的锚点引导对齐模块，通过与稳定参考的分布级匹配，显式地将不稳定实例的表示对齐到源域，减轻领域差异。3. 新颖的目标域感知自训练范式，利用稳定参考生成信息丰富的伪标签，捕捉目标域中变化的、不平衡的类别分布。", "result": "RADAR在测试时假新闻视频检测方面取得了优越的性能，实现了对未见假新闻视频主题的强大即时自适应。", "conclusion": "RADAR是首个能够对未见新闻视频进行测试时自适应的框架，有效地解决了现有方法在处理新兴事件和未见主题时的局限性，显著提升了假新闻视频检测的鲁棒性和适应性。"}}
{"id": "2601.12560", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12560", "abs": "https://arxiv.org/abs/2601.12560", "authors": ["Arunkumar V", "Gangadharan G. R.", "Rajkumar Buyya"], "title": "Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents", "comment": "28 pages, 4 figures, 5 tables", "summary": "Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.", "AI": {"tldr": "本文提出了一种统一的代理 AI 架构分类法，将代理分解为感知、大脑、规划、行动、工具使用和协作等组件，并分析了从线性推理到推理时推理模型、从固定 API 调用到开放标准以及不同环境的转变，同时指出了当前面临的挑战和未来的研究方向。", "motivation": "随着人工智能从文本生成模型向自主实体（代理 AI）转变，其设计变得复杂多样，导致难以导航。因此，需要一个统一的分类法来理解和分析这些代理 AI 的架构。", "method": "本文通过分析现有的代理 AI 设计，提出了一种统一的分类法，将代理分解为感知、大脑、规划、行动、工具使用和协作六个关键组件。在此基础上，作者对从线性推理到推理时推理模型的演变、从固定 API 调用到开放标准的转变，以及代理所处的不同环境进行了描述和分类，并回顾了当前的评估实践。", "result": "文章提出了一种新的代理 AI 架构分类法，为理解和比较不同代理系统提供了一个框架。通过该分类法，作者能够描述技术演变趋势，如推理机制的改进和工具使用标准的开放化，并对不同应用领域（如数字操作系统、机器人等）的代理进行了分类。", "conclusion": "代理 AI 正经历从被动模型到主动自治实体的转变，尽管取得了显著进展，但仍面临幻觉、无限循环和提示注入等挑战。未来的研究需要集中在提高代理的鲁棒性和可靠性，以实现更安全、更有效的自主系统。"}}
{"id": "2601.13556", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13556", "abs": "https://arxiv.org/abs/2601.13556", "authors": ["Jianan Wang", "Siyang Zhang", "Bin Li", "Juan Chen", "Jingtao Qi", "Zhuo Zhang", "Chen Qian"], "title": "LogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI", "comment": "19 pages, 15 figures, 6 tables", "summary": "Simulated environments play an essential role in embodied AI, functionally analogous to test cases in software engineering. However, existing environment generation methods often emphasize visual realism (e.g., object diversity and layout coherence), overlooking a crucial aspect: logical diversity from the testing perspective. This limits the comprehensive evaluation of agent adaptability and planning robustness in distinct simulated environments. To bridge this gap, we propose LogicEnvGen, a novel method driven by Large Language Models (LLMs) that adopts a top-down paradigm to generate logically diverse simulated environments as test cases for agents. Given an agent task, LogicEnvGen first analyzes its execution logic to construct decision-tree-structured behavior plans and then synthesizes a set of logical trajectories. Subsequently, it adopts a heuristic algorithm to refine the trajectory set, reducing redundant simulation. For each logical trajectory, which represents a potential task situation, LogicEnvGen correspondingly instantiates a concrete environment. Notably, it employs constraint solving for physical plausibility. Furthermore, we introduce LogicEnvEval, a novel benchmark comprising four quantitative metrics for environment evaluation. Experimental results verify the lack of logical diversity in baselines and demonstrate that LogicEnvGen achieves 1.04-2.61x greater diversity, significantly improving the performance in revealing agent faults by 4.00%-68.00%.", "AI": {"tldr": "提出了一种名为LogicEnvGen的新方法，利用大型语言模型（LLMs）生成逻辑上多样化的模拟环境，以作为AI智能体的测试用例，从而解决现有环境生成方法忽视逻辑多样性的问题。", "motivation": "现有模拟环境生成方法侧重于视觉逼真度，而忽视了从测试角度来看至关重要的逻辑多样性，这限制了对智能体适应性和规划鲁棒性的全面评估。", "method": "LogicEnvGen采用自顶向下的方法，首先分析智能体任务的执行逻辑，构建决策树结构的行为计划，然后合成一系列逻辑轨迹。接着，使用启发式算法优化轨迹集，并为每个逻辑轨迹实例化具体环境，同时利用约束求解器保证物理可行性。此外，还提出了LogicEnvEval基准，包含四个量化指标来评估环境。", "result": "实验表明，LogicEnvGen实现的逻辑多样性比基线方法高1.04-2.61倍，显著提高了发现智能体故障的能力（提升4.00%-68.00%）。", "conclusion": "LogicEnvGen能够生成逻辑上更多样化的模拟环境，有效弥补了现有方法的不足，并能更好地暴露智能体在不同逻辑场景下的潜在问题。"}}
{"id": "2601.12154", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12154", "abs": "https://arxiv.org/abs/2601.12154", "authors": ["Teodor-Călin Ionescu", "Lifeng Han", "Jan Heijdra Suasnabar", "Anne Stiggelbout", "Suzan Verberne"], "title": "Analyzing Cancer Patients' Experiences with Embedding-based Topic Modeling and LLMs", "comment": "under review to CLIN journal", "summary": "This study investigates the use of neural topic modeling and LLMs to uncover meaningful themes from patient storytelling data, to offer insights that could contribute to more patient-oriented healthcare practices. We analyze a collection of transcribed interviews with cancer patients (132,722 words in 13 interviews). We first evaluate BERTopic and Top2Vec for individual interview summarization by using similar preprocessing, chunking, and clustering configurations to ensure a fair comparison on Keyword Extraction. LLMs (GPT4) are then used for the next step topic labeling. Their outputs for a single interview (I0) are rated through a small-scale human evaluation, focusing on {coherence}, {clarity}, and {relevance}. Based on the preliminary results and evaluation, BERTopic shows stronger performance and is selected for further experimentation using three {clinically oriented embedding} models. We then analyzed the full interview collection with the best model setting. Results show that domain-specific embeddings improved topic \\textit{precision} and \\textit{interpretability}, with BioClinicalBERT producing the most consistent results across transcripts. The global analysis of the full dataset of 13 interviews, using the BioClinicalBERT embedding model, reveals the most dominant topics throughout all 13 interviews, namely ``Coordination and Communication in Cancer Care Management\" and ``Patient Decision-Making in Cancer Treatment Journey''. Although the interviews are machine translations from Dutch to English, and clinical professionals are not involved in this evaluation, the findings suggest that neural topic modeling, particularly BERTopic, can help provide useful feedback to clinicians from patient interviews. This pipeline could support more efficient document navigation and strengthen the role of patients' voices in healthcare workflows.", "AI": {"tldr": "本研究采用神经主题建模（BERTopic）和大型语言模型（GPT4）来分析癌症患者的访谈文本，以提取关键主题，旨在为以患者为中心的医疗保健提供洞见。研究发现，领域特定的嵌入模型（如BioClinicalBERT）能提高主题的精确度和可解释性，并识别出“癌症治疗管理中的协调与沟通”和“癌症治疗过程中的患者决策”是患者访谈中最突出的两个主题。", "motivation": "为了从患者故事中挖掘有意义的主题，为以患者为中心的医疗实践提供洞见。", "method": "首先，对癌症患者的访谈记录（132,722个词，13次访谈）进行预处理、分块和聚类，并比较BERTopic和Top2Vec在关键词提取上的表现。然后，使用GPT4对单个访谈的主题进行标注，并通过人工评估其连贯性、清晰度和相关性。基于初步结果，选择BERTopic与三种临床导向的嵌入模型进行进一步实验。最终，使用表现最佳的模型和设置分析全部访谈数据。", "result": "领域特定的嵌入模型（如BioClinicalBERT）提高了主题的精确度和可解释性。使用BioClinicalBERT在全部13次访谈数据中，识别出最主要的主题是“癌症治疗管理中的协调与沟通”和“癌症治疗过程中的患者决策”。", "conclusion": "神经主题建模（特别是BERTopic）结合临床领域嵌入模型，能够从患者访谈中提取有价值的信息，为临床医生提供反馈，支持更高效的文档导航，并加强患者在医疗流程中的话语权。尽管存在机器翻译和缺乏临床专业人士参与评估的局限性，研究结果仍显示了该方法的潜力。"}}
{"id": "2601.13737", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13737", "abs": "https://arxiv.org/abs/2601.13737", "authors": ["Joon Lee", "Jeongyoon Han", "Doyoung Kim", "Seokhwan Jeong"], "title": "RIM Hand : A Robotic Hand with an Accurate Carpometacarpal Joint and Nitinol-Supported Skeletal Structure", "comment": "Soft Robotics", "summary": "This paper presents the flexible RIM Hand, a biomimetic robotic hand that precisely replicates the carpometacarpal (CMC) joints and employs superelastic Nitinol wires throughout its skeletal framework. By modeling the full carpal-to-metacarpal anatomy, the design enables realistic palm deformation through tendon-driven fingers while enhancing joint restoration and supports skeletal structure with Nitinol-based dorsal extensors. A flexible silicone skin further increases contact friction and contact area, enabling stable grasps for diverse objects. Experiments show that the palm can deform up to 28%, matching human hand flexibility, while achieving more than twice the payload capacity and three times the contact area compared to a rigid palm design. The RIM Hand thus offers improved dexterity, compliance, and anthropomorphism, making it promising for prosthetic and service-robot applications.", "AI": {"tldr": "该研究提出了一种名为RIM Hand的仿生机械手，其特点是精确模仿了腕掌关节（CMC）的运动，并使用超弹性镍钛合金丝构建骨骼框架。这种设计实现了逼真的手掌变形，提高了关节恢复能力，并通过镍钛合金的背伸肌支持骨骼结构。同时，柔性硅胶皮肤增加了接触摩擦力和接触面积，提高了抓取稳定性。实验结果表明，RIM Hand的手掌变形能力可达28%，有效载荷能力和接触面积分别是刚性手掌设计的两倍和三倍。因此，RIM Hand在灵活性、顺应性和拟人化方面均有提升，在假肢和类人机器人领域具有应用前景。", "motivation": "现有机械手在灵活性、顺应性和抓取能力方面存在不足，难以实现类人手的精细操作。设计一种能够精确模仿人类手部解剖结构和运动的仿生机械手，以提高抓取能力和适应性。", "method": "1. 建模并复制了人类手部的腕掌关节（CMC）解剖结构。 2. 使用超弹性镍钛合金丝构建机械手的骨骼框架，特别是背伸肌。 3. 采用肌腱驱动手指，以实现手掌的真实变形。 4. 覆盖柔性硅胶皮肤，以增加接触摩擦力和接触面积。 5. 通过实验评估了手掌变形能力、载荷能力和接触面积。", "result": "1. RIM Hand的手掌变形能力可达28%，与人手相当。 2. RIM Hand的载荷能力是刚性手掌设计的两倍以上。 3. RIM Hand的接触面积是刚性手掌设计的近三倍。 4. 机械手实现了更高的灵活性、顺应性和拟人化。", "conclusion": "RIM Hand是一种高度仿生的机械手，通过精确模仿人类手部结构和运动，并结合先进材料（镍钛合金）和设计（柔性皮肤），显著提升了抓取能力、灵活性和适应性，在假肢和类人机器人应用中具有巨大潜力。"}}
{"id": "2601.12179", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12179", "abs": "https://arxiv.org/abs/2601.12179", "authors": ["Adam E. Friedman", "Stevan Harnad", "Rushen Shi"], "title": "Tolerance Principle and Small Language Model Learning", "comment": "14 pages, 6 figures. BUCLD 50 Proceedings. To be published in 2026 by Cascadilla Press", "summary": "Modern language models like GPT-3, BERT, and LLaMA require massive training data, yet with sufficient training they reliably learn to distinguish grammatical from ungrammatical sentences. Children aged as young as 14 months already have the capacity to learn abstract grammar rules from very few exemplars, even in the presence of non-rule-following exceptions. Yang's (2016) Tolerance Principle defines a precise threshold for how many exceptions a rule can tolerate and still be learnable. The present study explored the minimal amount and quality of training data necessary for rules to be generalized by a transformer-based language model to test the predictions of the Tolerance Principle. We trained BabyBERTa (Huebner et al. 2021), a transformer model optimized for small datasets, on artificial grammars. The training sets varied in size, number of unique sentence types, and proportion of rule-following versus exception exemplars. We found that, unlike human infants, BabyBERTa's learning dynamics do not align with the Tolerance Principle.", "AI": {"tldr": "本研究使用 BabyBERTa 模型测试了 Yang (2016) 的容忍原则在语言模型中是否适用，该原则描述了人类儿童从少量样本中学习抽象语法规则的能力。结果表明，BabyBERTa 的学习动态与容忍原则不符，与人类婴儿的表现不同。", "motivation": "现代大型语言模型需要海量数据才能学习语法，而人类婴儿却能从极少量样本中学习抽象语法规则，即使存在例外。本研究旨在探索 Transformer 模型（BabyBERTa）在学习抽象语法规则时所需的最小数据量和数据质量，以检验 Yang (2016) 的容忍原则在模型中的适用性。", "method": "研究者训练了一个针对小数据集优化的 Transformer 模型 BabyBERTa，使用人工语法作为训练数据。训练数据集在大小、句子类型数量以及遵循规则的样本与例外样本的比例上进行了变化。模型在这些不同条件下进行训练，并观察其学习动态。", "result": "研究发现，BabyBERTa 的学习动态与容忍原则不符。这意味着，与人类婴儿不同，BabyBERTa 在学习抽象语法规则时，其对例外样本的容忍度并不符合容忍原则的预测。", "conclusion": "尽管 Transformer 模型在处理大规模语言数据方面表现出色，但它们在从少量、包含例外的样本中学习抽象语法规则的能力，并不像人类婴儿那样遵循容忍原则。这表明在模型设计和训练方法上，可能需要进一步的研究来更好地模拟人类的学习机制。"}}
{"id": "2601.13574", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13574", "abs": "https://arxiv.org/abs/2601.13574", "authors": ["Guanyu Xu", "Jiaqi Wang", "Dezhong Tong", "Xiaonan Huang"], "title": "Highly Deformable Proprioceptive Membrane for Real-Time 3D Shape Reconstruction", "comment": "13 pages, 7 figures", "summary": "Reconstructing the three-dimensional (3D) geometry of object surfaces is essential for robot perception, yet vision-based approaches are generally unreliable under low illumination or occlusion. This limitation motivates the design of a proprioceptive membrane that conforms to the surface of interest and infers 3D geometry by reconstructing its own deformation. Conventional shape-aware membranes typically rely on resistive, capacitive, or magneto-sensitive mechanisms. However, these methods often encounter challenges such as structural complexity, limited compliance during large-scale deformation, and susceptibility to electromagnetic interference. This work presents a soft, flexible, and stretchable proprioceptive silicone membrane based on optical waveguide sensing. The membrane sensor integrates edge-mounted LEDs and centrally distributed photodiodes (PDs), interconnected via liquid-metal traces embedded within a multilayer elastomeric composite. Rich deformation-dependent light intensity signals are decoded by a data-driven model to recover the membrane geometry as a 3D point cloud. On a customized 140 mm square membrane, real-time reconstruction of large-scale out-of-plane deformation is achieved at 90 Hz with an average reconstruction error of 1.3 mm, measured by Chamfer distance, while maintaining accuracy for indentations up to 25 mm. The proposed framework provides a scalable, robust, and low-profile solution for global shape perception in deformable robotic systems.", "AI": {"tldr": "提出了一种基于光学波导传感的软弹性自感知硅胶膜，能够实时重建物体表面的三维几何形状，克服了传统视觉方法的局限性。", "motivation": "传统视觉方法在低照度或遮挡环境下重建三维几何形状不可靠，这促使研究人员开发一种能够感知自身形变的自感知薄膜。", "method": "设计了一种集成了边缘LED和中心光电二极管（PD）的光学波导传感膜。LED发出的光通过薄膜内的液态金属导轨传播，并被PD接收。薄膜的形变改变了光线的传播路径，导致PD接收到的光强度发生变化。通过数据驱动的模型解码这些光强度信号，从而恢复薄膜自身的几何形状，生成三维点云。", "result": "在140毫米见方的薄膜上，实现了90赫兹的实时大尺度平面外形变重建，平均重建误差为1.3毫米（Chamfer距离），并且对于高达25毫米的压痕保持了精度。", "conclusion": "该光学波导传感薄膜为机器人系统提供了一种可扩展、鲁棒且低剖面的全局形状感知解决方案，能够有效克服传统方法的不足。"}}
{"id": "2601.12199", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12199", "abs": "https://arxiv.org/abs/2601.12199", "authors": ["Muhammad Umar Farooq", "Oscar Saz"], "title": "CTC-DID: CTC-Based Arabic dialect identification for streaming applications", "comment": "Accepted for IEEE ICASSP 2026", "summary": "This paper proposes a Dialect Identification (DID) approach inspired by the Connectionist Temporal Classification (CTC) loss function as used in Automatic Speech Recognition (ASR). CTC-DID frames the dialect identification task as a limited-vocabulary ASR system, where dialect tags are treated as a sequence of labels for a given utterance. For training, the repetition of dialect tags in transcriptions is estimated either using a proposed Language-Agnostic Heuristic (LAH) approach or a pre-trained ASR model. The method is evaluated on the low-resource Arabic Dialect Identification (ADI) task, with experimental results demonstrating that an SSL-based CTC-DID model, trained on a limited dataset, outperforms both fine-tuned Whisper and ECAPA-TDNN models. Notably, CTC-DID also surpasses these models in zero-shot evaluation on the Casablanca dataset. The proposed approach is found to be more robust to shorter utterances and is shown to be easily adaptable for streaming, real-time applications, with minimal performance degradation.", "AI": {"tldr": "本文提出了一种受 CTC 损失启发的方言识别（DID）方法，将其视为一个有限词汇的 ASR 问题，通过估算方言标签的重复次数进行训练，并在低资源阿拉伯方言识别（ADI）任务上取得了优于 Whisper 和 ECAPA-TDNN 的性能，同时表现出更好的鲁棒性和流式处理能力。", "motivation": "现有方言识别方法在低资源场景下性能受限，并且在处理短语音和实时性方面存在不足。", "method": "将方言识别视为一个连接主义时间分类（CTC）问题，将方言标签视为一个标签序列。训练时，通过语言无关启发式（LAH）或预训练 ASR 模型来估计方言标签的重复次数。", "result": "在低资源阿拉伯方言识别（ADI）任务上，基于 SSL 的 CTC-DID 模型在有限数据集上训练，优于微调的 Whisper 和 ECAPA-TDNN 模型。在 Casablanca 数据集的零样本评估中，CTC-DID 也表现更优。该方法对短语音更鲁棒，且易于改编为流式应用，性能下降最小。", "conclusion": "CTC-DID 方法是一种有效且鲁棒的方言识别新范式，尤其适用于低资源场景和实时应用。"}}
{"id": "2601.13639", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13639", "abs": "https://arxiv.org/abs/2601.13639", "authors": ["Deyun Qin", "Zezhi Liu", "Hanqian Luo", "Xiao Liang", "Yongchun Fang"], "title": "A General One-Shot Multimodal Active Perception Framework for Robotic Manipulation: Learning to Predict Optimal Viewpoint", "comment": null, "summary": "Active perception in vision-based robotic manipulation aims to move the camera toward more informative observation viewpoints, thereby providing high-quality perceptual inputs for downstream tasks. Most existing active perception methods rely on iterative optimization, leading to high time and motion costs, and are tightly coupled with task-specific objectives, which limits their transferability. In this paper, we propose a general one-shot multimodal active perception framework for robotic manipulation. The framework enables direct inference of optimal viewpoints and comprises a data collection pipeline and an optimal viewpoint prediction network. Specifically, the framework decouples viewpoint quality evaluation from the overall architecture, supporting heterogeneous task requirements. Optimal viewpoints are defined through systematic sampling and evaluation of candidate viewpoints, after which large-scale training datasets are constructed via domain randomization. Moreover, a multimodal optimal viewpoint prediction network is developed, leveraging cross-attention to align and fuse multimodal features and directly predict camera pose adjustments. The proposed framework is instantiated in robotic grasping under viewpoint-constrained environments. Experimental results demonstrate that active perception guided by the framework significantly improves grasp success rates. Notably, real-world evaluations achieve nearly double the grasp success rate and enable seamless sim-to-real transfer without additional fine-tuning, demonstrating the effectiveness of the proposed framework.", "AI": {"tldr": "提出一种通用的、一次性的、多模态的主动感知框架，用于机器人操作，通过直接预测最优视角来克服现有方法的局限性，并在抓取任务中取得显著成效。", "motivation": "现有基于优化的主动感知方法存在时间/运动成本高、任务耦合性强、可迁移性差等问题。", "method": "构建了一个包含数据收集流水线和最优视角预测网络的多模态主动感知框架。该框架解耦了视角质量评估，通过系统采样和评估来定义最优视角，并利用域随机化构建训练数据集。预测网络采用跨注意力机制融合多模态特征，直接预测相机姿态调整。", "result": "在受视角约束的机器人抓取任务中，该框架显著提高了抓取成功率。真实世界实验表明，抓取成功率接近翻倍，且无需额外微调即可实现从仿真到现实的迁移。", "conclusion": "所提出的多模态主动感知框架是一种通用且有效的解决方案，能够直接预测最优视角，显著提升机器人操作任务（如抓取）的性能，并具备良好的仿真到现实迁移能力。"}}
{"id": "2601.11976", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11976", "abs": "https://arxiv.org/abs/2601.11976", "authors": ["Zongmin Li", "Yachuan Li", "Lei Kang", "Dimosthenis Karatzas", "Wenkang Ma"], "title": "AVIR: Adaptive Visual In-Document Retrieval for Efficient Multi-Page Document Question Answering", "comment": "7 pages, 3 figures", "summary": "Multi-page Document Visual Question Answering (MP-DocVQA) remains challenging because long documents not only strain computational resources but also reduce the effectiveness of the attention mechanism in large vision-language models (LVLMs). We tackle these issues with an Adaptive Visual In-document Retrieval (AVIR) framework. A lightweight retrieval model first scores each page for question relevance. Pages are then clustered according to the score distribution to adaptively select relevant content. The clustered pages are screened again by Top-K to keep the context compact. However, for short documents, clustering reliability decreases, so we use a relevance probability threshold to select pages. The selected pages alone are fed to a frozen LVLM for answer generation, eliminating the need for model fine-tuning. The proposed AVIR framework reduces the average page count required for question answering by 70%, while achieving an ANLS of 84.58% on the MP-DocVQA dataset-surpassing previous methods with significantly lower computational cost. The effectiveness of the proposed AVIR is also verified on the SlideVQA and DUDE benchmarks. The code is available at https://github.com/Li-yachuan/AVIR.", "AI": {"tldr": "提出了一种自适应视觉文档检索（AVIR）框架，通过检索和聚类来选择与问题相关的页面，以解决多页文档视觉问答（MP-DocVQA）中长文档带来的计算和注意力效率问题，并取得了优于现有方法的结果，同时显著降低了计算成本。", "motivation": "长文档会消耗大量计算资源，并降低大型视觉语言模型（LVLM）的注意力机制效率，从而对多页文档视觉问答（MP-DocVQA）的性能产生负面影响。", "method": "AVIR框架首先使用一个轻量级检索模型对文档的每一页进行问题相关性评分。然后，根据评分分布对页面进行聚类，自适应地选择相关内容。聚类后的页面再通过Top-K筛选来进一步压缩上下文。对于短文档，则采用相关性概率阈值来选择页面。最终，将选定的页面输入到一个冻结的LVLM中生成答案，无需进行模型微调。", "result": "AVIR框架将问答所需的平均页面数减少了70%，在MP-DocVQA数据集上实现了84.58%的ANLS分数，超过了现有方法。该框架在SlideVQA和DUDE数据集上也表现出有效性。", "conclusion": "AVIR框架能够有效地解决多页文档问答中的计算和效率问题，通过自适应地检索和筛选相关页面，可以在不微调大型视觉语言模型的情况下，显著提高问答性能并降低计算成本。"}}
{"id": "2601.11987", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11987", "abs": "https://arxiv.org/abs/2601.11987", "authors": ["Khaled Berkani"], "title": "Structural Graph Neural Networks with Anatomical Priors for Explainable Chest X-ray Diagnosis", "comment": "15 pages, 3 figures, 3 tables", "summary": "We present a structural graph reasoning framework that incorporates explicit anatomical priors for explainable vision-based diagnosis. Convolutional feature maps are reinterpreted as patch-level graphs, where nodes encode both appearance and spatial coordinates, and edges reflect local structural adjacency. Unlike conventional graph neural networks that rely on generic message passing, we introduce a custom structural propagation mechanism that explicitly models relative spatial relations as part of the reasoning process. This design enables the graph to act as an inductive bias for structured inference rather than a passive relational representation. The proposed model jointly supports node-level lesion-aware predictions and graph-level diagnostic reasoning, yielding intrinsic explainability through learned node importance scores without relying on post-hoc visualization techniques. We demonstrate the approach through a chest X-ray case study, illustrating how structural priors guide relational reasoning and improve interpretability. While evaluated in a medical imaging context, the framework is domain-agnostic and aligns with the broader vision of graph-based reasoning across artificial intelligence systems. This work contributes to the growing body of research exploring graphs as computational substrates for structure-aware and explainable learning.", "AI": {"tldr": "提出了一种结合解剖学先验的结构化图推理框架，用于可解释的视觉诊断。通过将卷积特征图表示为包含外观和空间信息的节点以及反映局部邻接关系的边，并引入自定义的结构化传播机制，实现内置的可解释性。", "motivation": "现有模型在视觉诊断中缺乏内在的可解释性，通常依赖于事后可视化技术。研究旨在开发一种能够通过显式建模空间关系和利用先验知识来进行结构化推理，并提供内在可解释性的框架。", "method": "将卷积特征图重新解释为补丁级图，节点包含外观和空间坐标，边表示局部结构邻接。引入自定义的结构化传播机制，将相对空间关系作为推理过程的一部分。模型同时支持节点级病变预测和图级诊断推理，通过学习节点重要性分数实现内在可解释性。", "result": "在胸部X光检查的案例研究中，证明了该方法能够通过结构化先验指导关系推理，并提高可解释性。模型实现了内在的可解释性，无需事后可视化。", "conclusion": "所提出的结构化图推理框架通过显式建模空间关系和引入解剖学先验，实现了可解释的视觉诊断。该框架具有领域无关性，可应用于更广泛的人工智能系统，为结构感知和可解释的学习提供了新的计算基础。"}}
{"id": "2601.12208", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12208", "abs": "https://arxiv.org/abs/2601.12208", "authors": ["Yunzhe Li", "Richie Yueqi Feng", "Tianxin Wei", "Chin-Chia Hsu"], "title": "CoReflect: Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement", "comment": null, "summary": "Evaluating conversational systems in multi-turn settings remains a fundamental challenge. Conventional pipelines typically rely on manually defined rubrics and fixed conversational context$-$a static approach that limits coverage and fails to capture the diverse, emergent behaviors of dialogue models. To address this, we introduce CoReflect (Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement), which unifies dialogue simulation and evaluation into an adaptive, iterative process. CoReflect employs a conversation planner that generates structured templates to guide a user simulator through diverse, goal-directed dialogues. Subsequently, a reflective analyzer processes these dialogues to identify systematic behavioral patterns and automatically refine the evaluation rubrics. Crucially, the insights from the conversation analysis are fed back into the planner to update conversation templates for subsequent iterations. This co-evolution loop ensures that the complexity of test cases and the diagnostic precision of rubrics improve in tandem. By minimizing human intervention, CoReflect provides a scalable and self-refining methodology that allows evaluation protocols to adapt alongside the rapidly advancing capabilities of dialogue models.", "AI": {"tldr": "CoReflect 是一种新颖的多轮对话系统评估框架，它通过对话模拟和评估规程的协同进化，实现了自适应和迭代式的评估。", "motivation": "传统的对话系统评估方法依赖于手动制定的评估标准和固定的对话上下文，这种静态方法无法覆盖对话模型多样的、涌现式的行为，限制了评估的有效性。", "method": "CoReflect 结合了对话模拟和评估，采用一个对话规划器生成结构化模板来指导用户模拟器进行多样的、目标导向的对话。然后，一个反思性分析器处理这些对话，识别行为模式并自动改进评估规程。通过反馈机制，分析得到的见解会更新对话模板，从而实现评估规程和测试用例复杂度的同步提升。", "result": "CoReflect 通过协同进化循环，使评估规程和测试用例的复杂性能够同步提高，从而提高了诊断精度和评估的覆盖范围。", "conclusion": "CoReflect 提供了一种可扩展且自我完善的方法，能够最大限度地减少人工干预，使评估协议能够跟上对话模型快速发展的能力。"}}
{"id": "2601.12661", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12661", "abs": "https://arxiv.org/abs/2601.12661", "authors": ["Chuhan Qiao", "Jianghua Huang", "Daxing Zhao", "Ziding Liu", "Yanjun Shen", "Bing Cheng", "Wei Lin", "Kai Wu"], "title": "MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents", "comment": null, "summary": "Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q\\&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q\\&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.", "AI": {"tldr": "本研究提出了MedConsultBench，一个全面的框架，用于评估医疗咨询AI的端到端能力，包括信息收集、诊断、治疗计划和后续问答，并引入了原子信息单元（AIUs）和22个细粒度指标来精确衡量信息获取过程。评估结果显示，目前的LLM在诊断准确性上表现良好，但在信息收集效率和药物安全性方面存在显著不足。", "motivation": "现有医疗咨询AI的评估方法过于侧重结果导向的任务，忽视了真实临床实践中至关重要的整个过程的完整性和临床安全性。现有的交互式基准测试场景碎片化且粗糙，无法捕捉专业咨询所需的结构化查询逻辑和诊断严谨性。", "method": "提出MedConsultBench框架，涵盖从病史采集、诊断到治疗计划和后续问答的整个临床工作流程。引入原子信息单元（AIUs）来跟踪亚轮次级别的临床信息获取，并使用22个细粒度指标进行精确监测。通过约束性计划修订来处理药物方案兼容性和现实的处方后随访问答。", "result": "对19个大型语言模型（LLMs）的系统评估发现，高诊断准确性往往掩盖了信息收集效率和药物安全性方面的严重不足。这揭示了理论医学知识与临床实践能力之间的关键差距。", "conclusion": "MedConsultBench为衡量医疗AI的真实临床能力提供了一个严谨的基础，有助于将医疗AI与现实世界临床护理的细微需求对齐。研究结果强调了当前LLM在实际临床应用中面临的挑战，尤其是在信息获取效率和药物安全性方面。"}}
{"id": "2601.12641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12641", "abs": "https://arxiv.org/abs/2601.12641", "authors": ["Xiangyu Shi", "Junyang Ding", "Xu Zhao", "Sinong Zhan", "Payal Mohapatra", "Daniel Quispe", "Kojo Welbeck", "Jian Cao", "Wei Chen", "Ping Guo", "Qi Zhu"], "title": "STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models", "comment": "Accepted to the Design, Automation & Test in Europe Conference (DATE) 2026", "summary": "Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.", "AI": {"tldr": "该研究提出了一种名为STEP-LLM的模型，能够直接从自然语言生成STEP格式的CAD模型，解决了现有方法依赖特定CAD内核和生成通用性差的问题。通过引入新的STEP数据预处理方法（DFS重序列化和结构注解）和检索增强生成（RAG）及强化学习（RL）技术，显著提高了生成模型的几何保真度。", "motivation": "现有的文本到CAD方法主要生成命令序列或脚本（如CadQuery），这些格式依赖于特定的CAD内核，不具备通用性，无法直接用于制造。而STEP格式是通用的、中立的边界表示（B-rep）格式，直接兼容制造，但其复杂的图结构和交叉引用对自回归大语言模型（LLM）提出了挑战。研究旨在使非专家也能通过直观的语言意图生成可制造的CAD模型。", "method": "1. 收集约40K个STEP-caption对数据集。\n2. 提出针对STEP图结构的预处理方法：\n   - 基于深度优先搜索（DFS）的重序列化，线性化交叉引用并保持局部性。\n   - 链式思考（CoT）风格的结构注解，引导全局一致性。\n3. 集成检索增强生成（RAG），通过相关示例来监督微调。\n4. 使用基于倒角距离（Chamfer Distance）的几何奖励进行强化学习（RL）优化。\n5. 使用Text2CAD作为基线模型进行对比实验。", "result": "STEP-LLM在几何保真度上持续优于Text2CAD基线模型。RAG模块提高了模型的完整性和可渲染性；DFS重序列化增强了整体准确性；RL进一步减小了几何差异。定量指标和视觉比较均证实STEP-LLM生成形状的保真度更高。", "conclusion": "研究证明了从自然语言驱动STEP模型生成的LLM的可行性，其新颖的预处理和训练框架能够克服STEP格式的挑战，生成高保真度的CAD模型。这预示着LLM在民主化制造CAD设计方面的巨大潜力。"}}
{"id": "2601.11990", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11990", "abs": "https://arxiv.org/abs/2601.11990", "authors": ["Yiming Li", "Chen Cai", "Tianyi Liu", "Dan Lin", "Wenqian Wang", "Wenfei Liang", "Bingbing Li", "Kim-Hui Yap"], "title": "DAOS: A Multimodal In-cabin Behavior Monitoring with Driver Action-Object Synergy Dataset", "comment": null, "summary": "In driver activity monitoring, movements are mostly limited to the upper body, which makes many actions look similar. To tell these actions apart, human often rely on the objects the driver is using, such as holding a phone compared with gripping the steering wheel. However, most existing driver-monitoring datasets lack accurate object-location annotations or do not link objects to their associated actions, leaving a critical gap for reliable action recognition. To address this, we introduce the Driver Action with Object Synergy (DAOS) dataset, comprising 9,787 video clips annotated with 36 fine-grained driver actions and 15 object classes, totaling more than 2.5 million corresponding object instances. DAOS offers multi-modal, multi-view data (RGB, IR, and depth) from front, face, left, and right perspectives. Although DAOS captures a wide range of cabin objects, only a few are directly relevant to each action for prediction, so focusing on task-specific human-object relations is essential. To tackle this challenge, we propose the Action-Object-Relation Network (AOR-Net). AOR-Net comprehends complex driver actions through multi-level reasoning and a chain-of-action prompting mechanism that models the logical relationships among actions, objects, and their relations. Additionally, the Mixture of Thoughts module is introduced to dynamically select essential knowledge at each stage, enhancing robustness in object-rich and object-scarce conditions. Extensive experiments demonstrate that our model outperforms other state-of-the-art methods on various datasets.", "AI": {"tldr": "本文提出DAOS数据集和AOR-Net模型，用于解决驾驶员活动识别中动作与物体关联的挑战，通过多模态、多视角数据和创新的网络结构，实现了更精确的驾驶员行为理解。", "motivation": "现有驾驶员活动监测数据集在物体位置标注或物体与动作的关联方面存在不足，难以区分相似的驾驶员动作。因此，需要一个包含精细动作和物体标注，并能有效利用物体信息的驾驶员活动数据集和识别方法。", "method": "构建了DAOS数据集，包含9787个视频片段，标注了36种驾驶员动作和15种物体类别。同时，提出AOR-Net模型，该模型利用多级推理和链式动作提示机制来建模动作、物体及其关系，并通过混合思想模块动态选择关键信息，以应对物体丰富或稀缺的场景。", "result": "DAOS数据集提供了多模态、多视角的数据。AOR-Net模型在多个数据集上的实验结果表明，其性能优于其他最先进的方法。", "conclusion": "DAOS数据集和AOR-Net模型有效解决了驾驶员活动识别中动作与物体关联的难题，通过对人与物体之间关系的多层次理解，提升了驾驶员行为识别的准确性和鲁棒性。"}}
{"id": "2601.11983", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.11983", "abs": "https://arxiv.org/abs/2601.11983", "authors": ["Md. Asiful Islam", "Abdul Hasib", "Tousif Mahmud Emon", "Khandaker Tabin Hasan", "A. S. M. Ahsanul Sarkar Akib"], "title": "An AI-IoT Based Smart Wheelchair with Gesture-Controlled Mobility, Deep Learning-Based Obstacle Detection, Multi-Sensor Health Monitoring, and Emergency Alert System", "comment": null, "summary": "The growing number of differently-abled and elderly individuals demands affordable, intelligent wheelchairs that combine safe navigation with health monitoring. Traditional wheelchairs lack dynamic features, and many smart alternatives remain costly, single-modality, and limited in health integration. Motivated by the pressing demand for advanced, personalized, and affordable assistive technologies, we propose a comprehensive AI-IoT based smart wheelchair system that incorporates glove-based gesture control for hands-free navigation, real-time object detection using YOLOv8 with auditory feedback for obstacle avoidance, and ultrasonic for immediate collision avoidance. Vital signs (heart rate, SpO$_2$, ECG, temperature) are continuously monitored, uploaded to ThingSpeak, and trigger email alerts for critical conditions. Built on a modular and low-cost architecture, the gesture control achieved a 95.5\\% success rate, ultrasonic obstacle detection reached 94\\% accuracy, and YOLOv8-based object detection delivered 91.5\\% Precision, 90.2\\% Recall, and a 90.8\\% F1-score. This integrated, multi-modal approach offers a practical, scalable, and affordable solution, significantly enhancing user autonomy, safety, and independence by bridging the gap between innovative research and real-world deployment.", "AI": {"tldr": "提出了一种结合手势控制、YOLOv8目标检测和超声波避障的AI-IoT智能轮椅系统，同时监测生命体征并支持远程警报，旨在提供经济实惠、功能全面的辅助技术。", "motivation": "为满足残疾和老年人群体对经济实惠、智能导航和健康监测相结合的轮椅的需求，同时克服传统轮椅功能的不足和现有智能轮椅的成本高、功能单一、健康集成有限等问题。", "method": "该系统采用AI-IoT架构，集成了基于手套的手势控制进行导航，基于YOLOv8的目标检测（并提供听觉反馈）用于避障，以及超声波传感器进行即时碰撞规避。同时，持续监测心率、血氧、心电图和体温等生命体征，并将数据上传至ThingSpeak，并在出现危急情况时触发电子邮件警报。", "result": "手势控制成功率达到95.5%，超声波避障准确率达到94%，YOLOv8目标检测的精确率为91.5%，召回率为90.2%，F1分数为90.8%。", "conclusion": "该集成化的多模态智能轮椅系统是一个实用、可扩展且经济实惠的解决方案，通过弥合创新研究与实际应用之间的差距，显著提高了用户的自主性、安全性和独立性。"}}
{"id": "2601.12247", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12247", "abs": "https://arxiv.org/abs/2601.12247", "authors": ["Miao Li", "Hanyang Jiang", "Sikai Chen", "Hengyu Fu", "Yuhang Cai", "Baihe Huang", "Tinghan Ye", "Xuanzhou Chen", "Pascal Van Hentenryck"], "title": "Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models", "comment": null, "summary": "Diffusion Language Models (DLMs) present a promising non-sequential paradigm for text generation, distinct from standard autoregressive (AR) approaches. However, current decoding strategies often adopt a reactive stance, underutilizing the global bidirectional context to dictate global trajectories. To address this, we propose Plan-Verify-Fill (PVF), a training-free paradigm that grounds planning via quantitative validation. PVF actively constructs a hierarchical skeleton by prioritizing high-leverage semantic anchors and employs a verification protocol to operationalize pragmatic structural stopping where further deliberation yields diminishing returns. Extensive evaluations on LLaDA-8B-Instruct and Dream-7B-Instruct demonstrate that PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based parallel decoding across benchmark datasets, unlocking superior efficiency without compromising accuracy.", "AI": {"tldr": "本文提出了一种名为Plan-Verify-Fill (PVF) 的训练无关范式，用于改进扩散语言模型 (DLMs) 的文本生成解码策略，通过主动构建层次化骨架并进行定量验证，显著提高了效率，同时保持了准确性。", "motivation": "现有的扩散语言模型 (DLMs) 解码策略通常采用被动方式，未能充分利用全局双向上下文来指导全局生成轨迹，导致效率低下。", "method": "提出Plan-Verify-Fill (PVF) 范式，该范式包含两个主要步骤：1. 通过优先处理高杠杆语义锚点来主动构建层次化骨架；2. 采用验证协议来操作化务实的结构化停止，即当进一步的审议收益递减时停止。PVF是训练无关的，并且依赖于定量验证。", "result": "与基于置信度的并行解码相比，PVF在LLaDA-8B-Instruct和Dream-7B-Instruct上的广泛评估显示，在基准数据集上，函数评估次数 (NFE) 减少了高达65%，同时保持了准确性。", "conclusion": "PVF是一种有效的训练无关范式，可以显著提高扩散语言模型的解码效率，通过主动的规划和验证机制，在不牺牲准确性的前提下实现了性能的提升。"}}
{"id": "2601.12667", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12667", "abs": "https://arxiv.org/abs/2601.12667", "authors": ["Yi Di", "Zhibin Zhao", "Fujin Wang", "Xue Liu", "Jiafeng Tang", "Jiaxin Ren", "Zhi Zhai", "Xuefeng Chen"], "title": "Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration", "comment": null, "summary": "It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.", "AI": {"tldr": "本文提出了一种名为SpaceHMchat的人机协作（HAIC）框架，用于卫星星座（SMC）中的全环路健康管理（AIL HM），旨在解决大规模航天器动力系统（SPS）的健康管理挑战。该框架通过模拟环境和真实数据集验证，在多项指标上表现出色。", "motivation": "随着卫星星座（SMC）时代来临，航天器数量指数级增长，对航天器动力系统（SPS）的健康管理（HM）提出了新的挑战。现有管理方法难以应对大规模的SPS数量，因此需要新的解决方案。", "method": "提出“对齐底层能力”（AUC）原则，并开发了SpaceHMchat，一个开源的人机协作（HAIC）框架，用于全环路健康管理（AIL HM）。该框架覆盖工作状态识别、异常检测、故障定位和维护决策等全流程。同时，建立了一个硬件真实的故障注入实验平台，并发布了首个SPS AIL HM数据集。", "result": "SpaceHMchat在23项定量指标上表现出优异性能，包括工作状态识别逻辑推理100%结论准确率，异常检测工具调用成功率超过99%，故障定位精度超过90%，以及维护决策知识库搜索时间低于3分钟。数据集包含4个子数据集，涉及4类AIL HM子任务，17种故障，超过70万个时间戳。", "conclusion": "SpaceHMchat框架能够有效地实现SPS的全环路健康管理，提升了效率、知识共享和透明度，为SMC时代的大规模航天器健康管理提供了可行的解决方案。新发布的数据集也将促进该领域的研究。"}}
{"id": "2601.12263", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12263", "abs": "https://arxiv.org/abs/2601.12263", "authors": ["Yixuan Du", "Chenxiao Yu", "Haoyan Xu", "Ziyi Wang", "Yue Zhao", "Xiyang Hu"], "title": "Multimodal Generative Engine Optimization: Rank Manipulation for Vision-Language Model Rankers", "comment": null, "summary": "Vision-Language Models (VLMs) are rapidly replacing unimodal encoders in modern retrieval and recommendation systems. While their capabilities are well-documented, their robustness against adversarial manipulation in competitive ranking scenarios remains largely unexplored. In this paper, we uncover a critical vulnerability in VLM-based product search: multimodal ranking attacks. We present Multimodal Generative Engine Optimization (MGEO), a novel adversarial framework that enables a malicious actor to unfairly promote a target product by jointly optimizing imperceptible image perturbations and fluent textual suffixes. Unlike existing attacks that treat modalities in isolation, MGEO employs an alternating gradient-based optimization strategy to exploit the deep cross-modal coupling within the VLM. Extensive experiments on real-world datasets using state-of-the-art models demonstrate that our coordinated attack significantly outperforms text-only and image-only baselines. These findings reveal that multimodal synergy, typically a strength of VLMs, can be weaponized to compromise the integrity of search rankings without triggering conventional content filters.", "AI": {"tldr": "本研究提出了一种针对视觉-语言模型（VLM）产品搜索的多模态对抗性攻击方法MGEO，该方法通过联合优化图像扰动和文本后缀来操纵搜索排名，并证明其效果优于单模态攻击。", "motivation": "现有研究缺乏对VLM在竞争性排名场景下对抗性攻击鲁棒性的探索，特别是多模态交互可能带来的新漏洞。", "method": "提出了一种名为MGEO（Multimodal Generative Engine Optimization）的对抗性框架，通过交替梯度优化策略，联合优化图像的微小扰动和文本后缀，以实现对目标产品的非公平推广。MGEO利用了VLM内部深度的跨模态耦合。", "result": "在真实世界数据集上使用最先进的VLM模型进行的大量实验表明，MGEO提出的协同多模态攻击显著优于仅文本或仅图像的基线攻击方法。", "conclusion": "VLM在产品搜索中的多模态协同性可以被武器化，用于破坏搜索排名的完整性，即使在不触发传统内容过滤器的情况下也是如此。研究揭示了VLM在对抗性攻击下的新漏洞。"}}
{"id": "2601.13657", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13657", "abs": "https://arxiv.org/abs/2601.13657", "authors": ["Myong-Yol Choi", "Hankyoul Ko", "Hanse Cho", "Changseung Kim", "Seunghwan Kim", "Jaemin Seo", "Hyondong Oh"], "title": "Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning", "comment": null, "summary": "This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors - balancing flocking and obstacle avoidance - using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization.", "AI": {"tldr": "本文提出了一种基于深度强化学习的无人机群协同导航控制器，能在通信受限、障碍物密集的环境中实现鲁棒的集体导航，仅依靠领导者信息和局部感知实现隐式跟随。", "motivation": "研究的动机是在通信受限（通信受阻）的环境下，实现无人机群的鲁棒协同导航，借鉴生物群体的“隐式领导”机制，使跟随者能仅凭局部感知和领导者信息完成任务，避免对通信和外部定位系统的依赖。", "method": "采用深度强化学习（DRL）控制器，结合隐式领导-跟随框架。跟随者无人机仅使用板载激光雷达（LiDAR）进行感知，通过点云聚类和扩展卡尔曼滤波器实现邻居稳定追踪，无需通信或领导者识别。DRL控制器在Nvidia Isaac Sim中训练，学习在局部感知下平衡群体行为（如集群）与避障。", "result": "所提出的DRL控制器成功使跟随者无人机学习到复杂的涌现行为，能够隐式跟随领导者并应对感知挑战（如遮挡、视野受限）。通过大量仿真和五架无人机的真实世界实验验证了该方法的鲁棒性，并在室内外多种环境下实现了无需通信或外部定位的集体导航。", "conclusion": "该基于DRL的隐式领导-跟随协同导航方法在通信受限环境中表现出优异的鲁棒性，能够通过局部感知实现自主的集体导航，并且具备良好的仿真到现实迁移能力。"}}
{"id": "2601.12015", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12015", "abs": "https://arxiv.org/abs/2601.12015", "authors": ["Pavan Kumar Yata", "Pediredla Pradeep", "Goli Himanish", "Swathi M"], "title": "SAR-Based Marine Oil Spill Detection Using the DeepSegFusion Architecture", "comment": "12 pages, 6 figures. Submitted to arXiv. Code and dataset details included in the paper", "summary": "Detection of oil spills from satellite images is essential for both environmental surveillance and maritime safety. Traditional threshold-based methods frequently encounter performance degradation due to very high false alarm rates caused by look-alike phenomena such as wind slicks and ship wakes. Here, a hybrid deep learning model, DeepSegFusion, is presented for oil spill segmentation in Synthetic Aperture Radar (SAR) images. The model uses SegNet and DeepLabV3+ integrated with an attention-based feature fusion mechanism to achieve better boundary precision as well as improved contextual understanding. Results obtained on SAR oil spill datasets, including ALOS PALSAR imagery, confirm that the proposed DeepSegFusion model achieves an accuracy of 94.85%, an Intersection over Union (IoU) of 0.5685, and a ROC-AUC score of 0.9330. The proposed method delivers more than three times fewer false detections compared to individual baseline models and traditional non-segmentation methods, achieving a reduction of 64.4%. These results indicate that DeepSegFusion is a stable model under various marine conditions and can therefore be used in near real-time oil spill monitoring scenarios.", "AI": {"tldr": "提出了一种名为DeepSegFusion的混合深度学习模型，用于从SAR图像中分割溢油，与现有方法相比，显著减少了误报，提高了精度。", "motivation": "传统基于阈值的方法在SAR图像中检测溢油时，由于风迹和船痕等“形似现象”导致高误报率，性能不佳。", "method": "提出了一种混合深度学习模型DeepSegFusion，集成了SegNet和DeepLabV3+，并加入了基于注意力机制的特征融合，以提高边界精度和上下文理解能力。", "result": "DeepSegFusion模型在ALOS PALSAR等SAR溢油数据集上取得了94.85%的准确率，0.5685的IoU和0.9330的ROC-AUC。与基线模型和传统方法相比，误报率降低了64.4%（超过三倍）。", "conclusion": "DeepSegFusion模型在各种海洋条件下表现稳定，能够有效地进行近乎实时的溢油监测，显著优于现有方法。"}}
{"id": "2601.12688", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12688", "abs": "https://arxiv.org/abs/2601.12688", "authors": ["Xu Zhang", "Qinghua Wang", "Mengyang Zhao", "Fang Wang", "Cunquan Qu"], "title": "Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction", "comment": null, "summary": "Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.", "AI": {"tldr": "提出了一种名为MMSI的掩码多阶段推理框架，通过整合量刑逻辑和定向掩码机制，提高了在多被告案件中区分被告角色的准确性，并为智能司法系统提供了改进方案。", "motivation": "在多被告案件中，准确区分被告角色并分配责任是司法公平性的挑战。现有司法表述模糊了被告的角色，阻碍了AI分析。研究旨在解决此问题，通过增强AI在多被告案件中的智能辅助能力，同时确保法律可解释性。", "method": "研究人员开发了一个基于预训练Transformer编码器的框架，并融入了量刑逻辑。该框架采用定向掩码机制来阐明角色，并使用比较数据构建策略来提高模型对主犯和从犯之间罪责差异的敏感度。预测的罪责标签通过广播机制整合到回归模型中，结合犯罪描述和法院观点。整个模型被称为掩码多阶段推理（MMSI）框架。", "result": "在自定义的IMLJP数据集（针对故意伤害案件）上评估MMSI框架，结果显示其在基于角色的罪责区分方面取得了显著的准确性提升，优于现有基线模型。", "conclusion": "MMSI框架为提高多被告案件中智能司法系统的角色区分能力提供了一个强大的解决方案，在法律可解释性方面也有所增强，并且公开了代码。"}}
{"id": "2601.12010", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12010", "abs": "https://arxiv.org/abs/2601.12010", "authors": ["Yifei Chen", "Ross Greer"], "title": "SMc2f: Robust Scenario Mining for Robotic Autonomy from Coarse to Fine", "comment": null, "summary": "The safety validation of autonomous robotic vehicles hinges on systematically testing their planning and control stacks against rare, safety-critical scenarios. Mining these long-tail events from massive real-world driving logs is therefore a critical step in the robotic development lifecycle. The goal of the Scenario Mining task is to retrieve useful information to enable targeted re-simulation, regression testing, and failure analysis of the robot's decision-making algorithms. RefAV, introduced by the Argoverse team, is an end-to-end framework that uses large language models (LLMs) to spatially and temporally localize scenarios described in natural language. However, this process performs retrieval on trajectory labels, ignoring the direct connection between natural language and raw RGB images, which runs counter to the intuition of video retrieval; it also depends on the quality of upstream 3D object detection and tracking. Further, inaccuracies in trajectory data lead to inaccuracies in downstream spatial and temporal localization. To address these issues, we propose Robust Scenario Mining for Robotic Autonomy from Coarse to Fine (SMc2f), a coarse-to-fine pipeline that employs vision-language models (VLMs) for coarse image-text filtering, builds a database of successful mining cases on top of RefAV and automatically retrieves exemplars to few-shot condition the LLM for more robust retrieval, and introduces text-trajectory contrastive learning to pull matched pairs together and push mismatched pairs apart in a shared embedding space, yielding a fine-grained matcher that refines the LLM's candidate trajectories. Experiments on public datasets demonstrate substantial gains in both retrieval quality and efficiency.", "AI": {"tldr": "提出了一种名为SMc2f的粗粒度到细粒度管道，使用视觉语言模型（VLMs）进行图像-文本过滤，并结合LLM和对比学习来更鲁棒地挖掘自动驾驶车辆中的罕见危险场景。", "motivation": "现有的RefAV框架在从自然语言描述中提取自动驾驶车辆安全关键场景时，依赖于轨迹标签，忽略了图像和文本之间的直接联系，并且容易受到3D物体检测和跟踪不准确性的影响。这导致了空间和时间定位的不准确，阻碍了目标重模拟、回归测试和失败分析。", "method": "SMc2f管道包含三个主要部分：1. 使用VLMs进行粗粒度的图像-文本过滤。2. 构建一个成功的挖掘案例数据库，并利用该数据库来少样本（few-shot）引导LLM进行更鲁棒的检索。3. 引入文本-轨迹对比学习，将匹配的图像-文本对拉近，将不匹配的对推远，从而创建一个细粒度的匹配器来优化LLM候选轨迹。", "result": "在公共数据集上的实验表明，SMc2f在场景检索的质量和效率方面都有显著提升。", "conclusion": "SMc2f通过结合VLMs的图像理解能力、LLM的文本推理能力以及对比学习的细粒度匹配能力，有效克服了现有方法的局限性，能够更准确、更高效地从大规模数据中挖掘自动驾驶车辆罕见的、安全关键的场景，从而提升自动驾驶系统的安全验证能力。"}}
{"id": "2601.12711", "categories": ["cs.AI", "cs.LG", "cs.SC"], "pdf": "https://arxiv.org/pdf/2601.12711", "abs": "https://arxiv.org/abs/2601.12711", "authors": ["Kevin Wang", "Neel P. Bhatt", "Cong Liu", "Junbo Li", "Runjin Chen", "Yihan Xi", "Timothy Barclay", "Alvaro Velasquez", "Ufuk Topcu", "Zhangyang Wang"], "title": "Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts", "comment": null, "summary": "Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.", "AI": {"tldr": "本文提出了一种结合数值更新（LoRA）和符号编辑（TextGrad）的神经符号LoRA框架，通过统一的监控信号和基于奖励的分类器动态选择更新方式，实现了更优的模型适应性和性能。", "motivation": "现有的LLM适应方法要么侧重数值更新（擅长注入事实知识），要么侧重符号操作（灵活控制风格和对齐），但两者存在互补性。作者希望结合两者的优点，实现更灵活、高效的模型微调。", "method": "提出了一种神经符号LoRA框架，使用统一的监控信号和基于奖励的分类器来决定何时使用LoRA进行数值更新（事实重构），何时使用TextGrad进行符号编辑（token级修改）。符号转换仅在需要时调用外部LLM，以节省内存。符号编辑产生的提示可作为高质量的训练数据。", "result": "在多个LLM骨干网络上的大量实验表明，神经符号LoRA在适应性和性能上持续优于纯数值或纯符号基线。", "conclusion": "通过交织数值和符号更新，可以解锁语言模型微调的新水平通用性，结合LoRA和TextGrad的神经符号方法能够实现更优的模型适应性和性能。"}}
{"id": "2601.13777", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13777", "abs": "https://arxiv.org/abs/2601.13777", "authors": ["Zvi Chapnik", "Yizhar Or", "Shai Revzen"], "title": "Sample Efficient Learning of Body-Environment Interaction of an Under-Actuated System", "comment": null, "summary": "Geometric mechanics provides valuable insights into how biological and robotic systems use changes in shape to move by mechanically interacting with their environment. In high-friction environments it provides that the entire interaction is captured by the ``motility map''. Here we compare methods for learning the motility map from motion tracking data of a physical robot created specifically to test these methods by having under-actuated degrees of freedom and a hard to model interaction with its substrate. We compared four modeling approaches in terms of their ability to predict body velocity from shape change within the same gait, across gaits, and across speeds. Our results show a trade-off between simpler methods which are superior on small training datasets, and more sophisticated methods, which are superior when more training data is available.", "AI": {"tldr": "本文比较了四种学习机器人运动模型（称为“运动图”）的方法，该模型描述了在摩擦环境中形状变化如何导致运动。研究发现在训练数据量较小时，简单模型表现更好，而数据量大时，复杂模型效果更佳。", "motivation": "在生物和机器人系统中，形状变化在与环境的机械互动中起着至关重要的作用，尤其是在高摩擦环境中。本文旨在研究如何从运动追踪数据中学习描述这种相互作用的“运动图”，并比较不同建模方法的有效性。", "method": "研究人员使用一个具有欠驱动自由度和难以建模的底物相互作用的物理机器人，通过运动追踪收集数据。然后，他们比较了四种不同的建模方法，评估它们在预测身体速度与形状变化之间的关系的能力，分别在同一步态、跨步态和跨速度的情况下进行。", "result": "研究结果表明，在学习机器人运动图时，存在一个简单模型与复杂模型之间的权衡。当训练数据集较小时，简单模型表现更优；而当可用训练数据量增加时，更复杂的模型能够取得更好的预测效果。", "conclusion": "本文通过比较四种学习机器人运动图的方法，揭示了在不同训练数据量下，简单与复杂模型性能的权衡关系。这为在特定应用场景下选择合适的机器人运动建模方法提供了指导。"}}
{"id": "2601.12049", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12049", "abs": "https://arxiv.org/abs/2601.12049", "authors": ["Chenchen Zhao", "Muxi Chen", "Qiang Xu"], "title": "\\textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions", "comment": "12 pages, 13 figures", "summary": "Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic's capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.", "AI": {"tldr": "FocaLogic是一个模型无关的框架，通过识别和量化视觉模型中的“视觉焦点”来提高模型的可解释性，并将其转化为逻辑表达式，提供了新的评估指标。", "motivation": "现有模型的可解释性方法要么需要白盒访问模型，要么缺乏量化严谨性，尤其是在高风险应用中，这促使研究者开发新的可解释性方法。", "method": "提出了一种名为FocaLogic的模型无关框架，该框架识别出对模型预测有决定性影响的最小可解释视觉区域（视觉焦点），并将这些视觉焦点转化为精确的逻辑表达式。同时，开发了一套量化指标（焦点精度、召回率、散度）来评估模型行为。", "result": "FocaLogic能够揭示训练引起的注意力集中、通过泛化提高焦点准确性，以及在偏见和对抗性攻击下的异常焦点等关键见解。", "conclusion": "FocaLogic提供了一种系统、可扩展且量化的解决方案，用于解释视觉模型，克服了现有方法的局限性。"}}
{"id": "2601.12269", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12269", "abs": "https://arxiv.org/abs/2601.12269", "authors": ["Xucong Hu", "Jian-Qiao Zhu"], "title": "Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models", "comment": null, "summary": "Autoregressive language models are next-token predictors and have been criticized for only optimizing surface plausibility (i.e., local coherence) rather than maintaining correct latent-state representations (i.e., global coherence). Because Theory of Mind (ToM) tasks crucially depend on reasoning about latent mental states of oneself and others, such models are therefore often thought to fail at ToM. While post-training methods can improve ToM performance, we show that strong ToM capability can be recovered directly from the base model without any additional weight updates or verifications. Our approach builds on recent power-sampling methods (Karan & Du, 2025) that use Markov chain Monte Carlo (MCMC) to sample from sharpened sequence-level (rather than token-level) probability distributions of autoregressive language models. We further find that incorporating annealing, where the tempered distribution is gradually shifted from high to low temperature, substantially improves ToM performance over fixed-temperature power sampling. Together, these results suggest that sampling-based optimization provides a powerful way to extract latent capabilities from language models without retraining.", "AI": {"tldr": "本研究表明，通过基于MCMC的功率采样（特别是结合退火技术）可以直接从基础语言模型中恢复出其潜在的“心智理论”（ToM）能力，而无需进行额外的模型训练或微调。", "motivation": "批评者认为自回归语言模型仅优化表面连贯性，而忽略了对潜在状态的推理，因此在需要理解他人意图和心理状态（心智理论，ToM）的任务上表现不佳。本研究旨在探索无需重新训练即可激活模型内在ToM能力的方法。", "method": "研究采用了基于MCMC的功率采样方法，该方法从语言模型的序列级（而非token级）概率分布中进行采样。在此基础上，研究者进一步引入了“退火”技术，通过逐渐调整温度来改变采样分布，以期更好地提取模型的ToM能力。", "result": "研究发现，直接从基础模型进行功率采样可以有效地恢复ToM能力。并且，结合退火技术的功率采样比固定温度的采样能显著提升ToM的性能。", "conclusion": "基于采样的优化方法（尤其是带有退火的功率采样）是一种无需重新训练即可从语言模型中提取潜在能力（如ToM）的强大技术，证明了基础模型可能已经拥有这些能力，只是需要适当的方法来激发。"}}
{"id": "2601.13801", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13801", "abs": "https://arxiv.org/abs/2601.13801", "authors": ["Yuhua Jin", "Nikita Kuzmin", "Georgii Demianchuk", "Mariya Lezina", "Fawad Mehboob", "Issatay Tokmurziyev", "Miguel Altamirano Cabrera", "Muhammad Ahsan Mustafa", "Dzmitry Tsetserukou"], "title": "HoverAI: An Embodied Aerial Agent for Natural Human-Drone Interaction", "comment": "This paper has been accepted for publication at LBR HRI 2026 conference", "summary": "Drones operating in human-occupied spaces suffer from insufficient communication mechanisms that create uncertainty about their intentions. We present HoverAI, an embodied aerial agent that integrates drone mobility, infrastructure-independent visual projection, and real-time conversational AI into a unified platform. Equipped with a MEMS laser projector, onboard semi-rigid screen, and RGB camera, HoverAI perceives users through vision and voice, responding via lip-synced avatars that adapt appearance to user demographics. The system employs a multimodal pipeline combining VAD, ASR (Whisper), LLM-based intent classification, RAG for dialogue, face analysis for personalization, and voice synthesis (XTTS v2). Evaluation demonstrates high accuracy in command recognition (F1: 0.90), demographic estimation (gender F1: 0.89, age MAE: 5.14 years), and speech transcription (WER: 0.181). By uniting aerial robotics with adaptive conversational AI and self-contained visual output, HoverAI introduces a new class of spatially-aware, socially responsive embodied agents for applications in guidance, assistance, and human-centered interaction.", "AI": {"tldr": "HoverAI是一个集成了无人机飞行、视觉投影和实时对话AI的空中代理，能够感知用户并以定制化的头像进行回应，旨在改善人机交互。", "motivation": "当前无人机在与人交互时缺乏有效的沟通机制，导致意图不明确。", "method": "HoverAI集成了MEMS激光投影仪、柔性屏幕和RGB摄像头，利用视觉和语音感知用户，并通过唇语同步的虚拟形象进行回应。系统采用多模态处理流程，包括语音活动检测（VAD）、自动语音识别（ASR）、基于LLM的意图分类、检索增强生成（RAG）进行对话、人脸分析进行个性化以及语音合成。", "result": "实验结果表明，HoverAI在指令识别（F1: 0.90）、人口统计学估计（性别F1: 0.89，年龄MAE: 5.14岁）和语音转录（WER: 0.181）方面表现出高精度。", "conclusion": "HoverAI成功地将空中机器人技术与自适应对话AI和独立的视觉输出相结合，开创了一类新的空间感知、社交响应的具身代理，适用于导航、辅助和人机交互等应用。"}}
{"id": "2601.12286", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12286", "abs": "https://arxiv.org/abs/2601.12286", "authors": ["Jonathan Pan"], "title": "Conversational Context Classification: A Representation Engineering Approach", "comment": null, "summary": "The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate out-of-context responses. A key challenge is accurately detecting when LLMs stray from expected conversational norms, manifesting as topic shifts, factual inaccuracies, or outright hallucinations. Traditional anomaly detection struggles to directly apply within contextual semantics. This paper outlines our experiment in exploring the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, we establish a robust boundary within the LLM's hidden state latent space. We evaluate out study with two open source LLMs - Llama and Qwen models in specific contextual domain. Our approach entailed identifying the optimal layers within the LLM's internal state subspaces that strongly associates with the context of interest. Our evaluation results showed promising results in identifying the subspace for a specific context. Aside from being useful in detecting in or out of context conversation threads, this research work contributes to the study of better interpreting LLMs.", "AI": {"tldr": "本文提出使用表示工程（RepE）和单类支持向量机（OCSVM）来检测大型语言模型（LLMs）的离线上下文响应，通过在LLM的隐藏状态潜在空间中学习特定上下文的边界。", "motivation": "随着LLM的广泛应用，其生成不合乎语境响应（如主题偏移、事实错误、幻觉）的问题日益突出，需要有效的检测方法。传统的异常检测方法难以直接应用于语境语义。 \n", "method": "研究者利用表示工程（RepE）技术，识别LLM内部状态中代表特定上下文的子空间。然后，使用单类支持向量机（OCSVM）在这些代表特定上下文的示例上进行训练，从而在LLM的隐藏状态潜在空间中建立一个鲁棒的边界。实验在Llama和Qwen两个开源LLM模型上，针对特定领域上下文进行评估，并确定了与目标上下文强相关的最佳内部状态层。", "result": "实验结果表明，该方法在识别特定上下文的子空间方面取得了令人鼓舞的成效。", "conclusion": "该研究成果不仅有助于检测符合或不符合特定上下文的对话，还为更好地理解和解释LLMs的研究做出了贡献。"}}
{"id": "2601.12720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12720", "abs": "https://arxiv.org/abs/2601.12720", "authors": ["Hanbin Wang", "Jingwei Song", "Jinpeng Li", "Qi Zhu", "Fei Mi", "Ganqu Cui", "Yasheng Wang", "Lifeng Shang"], "title": "Teaching Large Reasoning Models Effective Reflection", "comment": "14 pages (including appendix), 5 figures", "summary": "Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.", "AI": {"tldr": "本研究提出了一种名为 SCFT 的训练框架，以及一种名为 RLERR 的强化学习方法，以解决大型推理模型（LRM）中存在的肤浅反思问题，并显著提高了 LRM 在 AIME2024 和 AIME2025 基准测试上的推理准确性和反思质量。", "motivation": "大型推理模型（LRM）在复杂推理任务中表现出色，但其反思行为（如自我批评和回溯）有时是肤浅的，并未带来实质性改进，反而增加了计算开销。研究旨在解决 LRM 中的肤浅反思问题。", "method": "研究提出了两种方法：1. Self-Critique Fine-Tuning (SCFT)：一个训练框架，通过提示模型自我批评其输出来增强其反思推理能力，并使用拒绝采样过滤高质量的批评，然后通过基于批评的目标进行微调。2. Reinforcement Learning with Effective Reflection Rewards (RLERR)：一种强化学习方法，利用 SCFT 初始化的有效反思来构建奖励信号，通过强化学习指导模型内化自我纠正过程。", "result": "在 AIME2024 和 AIME2025 两个具有挑战性的基准测试上进行的实验表明，SCFT 和 RLERR 显著提高了推理准确性和反思质量，优于现有的最先进基线方法。", "conclusion": "SCFT 和 RLERR 方法能够有效地提高大型推理模型（LRM）的推理能力和反思质量，解决了 LRM 中存在的肤浅反思问题。"}}
{"id": "2601.12020", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12020", "abs": "https://arxiv.org/abs/2601.12020", "authors": ["Guillermo Figueroa-Araneda", "Iris Diana Jimenez", "Florian Hofherr", "Manny Ko", "Hector Andrade-Loarca", "Daniel Cremers"], "title": "DIAMOND-SSS: Diffusion-Augmented Multi-View Optimization for Data-efficient SubSurface Scattering", "comment": null, "summary": "Subsurface scattering (SSS) gives translucent materials -- such as wax, jade, marble, and skin -- their characteristic soft shadows, color bleeding, and diffuse glow. Modeling these effects in neural rendering remains challenging due to complex light transport and the need for densely captured multi-view, multi-light datasets (often more than 100 views and 112 OLATs).\n  We present DIAMOND-SSS, a data-efficient framework for high-fidelity translucent reconstruction from extremely sparse supervision -- even as few as ten images. We fine-tune diffusion models for novel-view synthesis and relighting, conditioned on estimated geometry and trained on less than 7 percent of the dataset, producing photorealistic augmentations that can replace up to 95 percent of missing captures. To stabilize reconstruction under sparse or synthetic supervision, we introduce illumination-independent geometric priors: a multi-view silhouette consistency loss and a multi-view depth consistency loss.\n  Across all sparsity regimes, DIAMOND-SSS achieves state-of-the-art quality in relightable Gaussian rendering, reducing real capture requirements by up to 90 percent compared to SSS-3DGS.", "AI": {"tldr": "DIAMOND-SSS 提出了一种数据高效的框架，使用极度稀疏的监督（仅需十张图像）实现高保真度半透明重建，通过微调扩散模型进行新视角合成和重照明，并引入了与光照无关的几何先验来稳定重建。", "motivation": "现有的神经渲染技术在模拟次表面散射（SSS）效果时面临挑战，尤其是在需要大量多视图、多光照数据集的情况下。研究动机是为了在数据量极度有限的情况下实现高质量的半透明材料重建。", "method": "该研究提出了一种名为 DIAMOND-SSS 的数据高效框架。该框架通过微调扩散模型进行新视角合成和重照明，并利用估计的几何信息。该方法仅需少量数据（少于 7% 的数据集），并引入了多视图轮廓一致性损失和多视图深度一致性损失作为与光照无关的几何先验，以稳定稀疏或合成监督下的重建。", "result": "DIAMOND-SSS 在不同稀疏度设置下均实现了最先进的、可重照明的高斯渲染质量。与 SSS-3DGS 相比，该方法将真实数据捕获需求降低了高达 90%。", "conclusion": "DIAMOND-SSS 成功地实现了从极度稀疏监督下进行高保真度半透明重建，显著降低了数据采集成本，并在可重照明高斯渲染方面达到了 SOTA 性能。"}}
{"id": "2601.13809", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13809", "abs": "https://arxiv.org/abs/2601.13809", "authors": ["Fawad Mehboob", "Monijesu James", "Amir Habel", "Jeffrin Sam", "Miguel Altamirano Cabrera", "Dzmitry Tsetserukou"], "title": "DroneVLA: VLA based Aerial Manipulation", "comment": "This paper has been accepted for publication at LBR of HRI 2026 conference", "summary": "As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system's efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations.", "AI": {"tldr": "该研究提出了一种能理解自然语言指令的自主空中操作系统，用于拾取并递送物体给用户。系统集成了基于MediaPipe、Grounding DINO和视觉-语言-动作（VLA）模型的无人机。", "motivation": "随着空中平台从被动观察者转变为主动操作者，设计直观的界面以使非专业用户能够自然地指挥这些系统变得至关重要。", "method": "系统利用Grounding DINO和视觉-语言-动作（VLA）模型来解析自然语言指令，并生成物体抓取任务队列。结合动态A*规划算法进行导航和重新定位。通过MediaPipe实现以人为本的控制器，进行实时人体姿态估计，使无人机能通过视觉伺服进行稳定、舒适的物体交接。", "result": "在实际实验中，系统在定位和导航方面的最大、平均欧氏距离和均方根误差分别为0.164m、0.070m和0.084m，证明了VLA在空中操作中的可行性。", "conclusion": "该自主空中操作系统能够有效地解释自然语言指令，执行物体拾取和递送任务，并通过人机交互设计实现了安全自然的物体交接。"}}
{"id": "2601.12744", "categories": ["cs.AI", "cs.NI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12744", "abs": "https://arxiv.org/abs/2601.12744", "authors": ["Tasnim Ahmed", "Yifan Zhu", "Salimur Choudhury"], "title": "Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks", "comment": "Accepted for presentation at The IEEE International Conference on Communications (ICC) 2026", "summary": "Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. While recent work demonstrates that large language models can automate configuration tasks, a distinct class of intents requires generating optimization code to compute provably optimal solutions for traffic engineering, routing, and resource allocation. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. Network practitioners naturally reason about structure through diagrams, yet whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code remains unexplored. We present IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. Our evaluation shows that visual parameter extraction reduces execution success by 12-21 percentage points (pp), with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 pp, and open-source models lag behind closed-source ones, with Llama-3.2-11B-Vision reaching 18% compared to 75% for GPT-5-Mini. These results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system. We also demonstrate practical feasibility through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.", "AI": {"tldr": "本文提出IntentOpt基准，评估了视觉语言模型（VLM）处理带注释的网络草图生成优化代码的能力，发现视觉信息反而降低了性能，并且闭源模型优于开源模型，为意图驱动网络中的VLM应用设定了基线。", "motivation": "现有意图驱动网络（IBN）系统通常以文本形式表达意图，这与网络从业者习惯通过图示进行结构化思考的方式不符。因此，研究能否利用视觉语言模型（VLM）处理网络草图来生成优化代码，以改善IBN系统的可用性和效率。", "method": "构建了一个包含85个优化问题（涵盖17个类别）的IntentOpt基准。评估了四种VLM（GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision）在三种提示策略下，使用多模态输入（图像+文本）和纯文本输入进行优化代码生成的性能。此外，还进行了模型上下文协议（MCP）的案例研究，以验证VLM生成代码在实际网络测试床上的可行性。", "result": "视觉参数提取反而降低了12-21个百分点的执行成功率。例如，GPT-5-Mini的成功率从93%下降到72%。“程序思想”（Program-of-thought）提示策略会使性能下降高达13个百分点。闭源模型（如GPT-5-Mini，成功率75%）的表现显著优于开源模型（如Llama-3.2-11B-Vision，成功率18%）。", "conclusion": "当前VLM在处理带注释的网络草图以生成优化代码方面存在局限性，视觉信息的引入并未带来预期的性能提升。模型能力存在显著差异，闭源模型表现更佳。本研究为意图驱动网络中VLM的优化代码生成能力奠定了基线，并展示了通过MCP协议在实际网络环境中部署VLM生成代码的可行性。"}}
{"id": "2601.13732", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13732", "abs": "https://arxiv.org/abs/2601.13732", "authors": ["Andreas Wiedholz", "Rafael Paintner", "Julian Gleißner", "Alwin Hoffmann", "Tobias Huber"], "title": "SUNSET -- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation", "comment": null, "summary": "The fact that robots are getting deployed more often in dynamic environments, together with the increasing complexity of their software systems, raises the need for self-adaptive approaches. In these environments robotic software systems increasingly operate amid (1) uncertainties, where symptoms are easy to observe but root causes are ambiguous, or (2) multiple uncertainties appear concurrently. We present SUNSET, a ROS2-based exemplar that enables rigorous, repeatable evaluation of architecture-based self-adaptation in such conditions. It implements a sensor fusion semantic-segmentation pipeline driven by a trained Machine Learning (ML) model whose input preprocessing can be perturbed to induce realistic performance degradations. The exemplar exposes five observable symptoms, where each can be caused by different root causes and supports concurrent uncertainties spanning self-healing and self-optimisation. SUNSET includes the segmentation pipeline, a trained ML model, uncertainty-injection scripts, a baseline controller, and step-by-step integration and evaluation documentation to facilitate reproducible studies and fair comparison.", "AI": {"tldr": "提出了一种名为SUNSET的ROS2框架，用于评估机器人软件系统在动态环境和多重不确定性下的基于架构的自适应能力，通过模拟传感器输入退化来引入不确定性，并支持自愈和自优化。", "motivation": "随着机器人越来越多地部署在动态环境中，并且其软件系统日益复杂，对自适应方法的需求日益增加，特别是在存在不确定性（原因模糊）或多种不确定性并发的情况下。", "method": "开发了一个基于ROS2的名为SUNSET的范例，该范例实现了一个由机器学习模型驱动的传感器融合语义分割流程。通过扰动输入预处理来引入性能下降，模拟不确定性。SUNSET包括分割流程、训练好的ML模型、不确定性注入脚本、基线控制器以及集成和评估文档。", "result": "SUNSET范例暴露了五个可观察到的症状，每个症状可以由不同的根本原因引起，并支持跨越自愈和自优化的并发不确定性，实现了对架构自适应的严格、可重复评估。", "conclusion": "SUNSET框架提供了一个强大的工具，用于研究和评估机器人软件系统在复杂和不确定的动态环境中的自适应能力，促进了可复现的研究和公平的比较。"}}
{"id": "2601.12369", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12369", "abs": "https://arxiv.org/abs/2601.12369", "authors": ["Ming Zhang", "Jiabao Zhuang", "Wenqing Jing", "Ziyu Kong", "Jingyi Deng", "Yujiong Shen", "Kexin Tan", "Yuhang Zhao", "Ning Luo", "Renzhe Zheng", "Jiahui Lin", "Mingqi Wu", "Long Ma", "Yi Zou", "Shihan Dou", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Can Deep Research Agents Find and Organize? Evaluating the Synthesis Gap with Expert Taxonomies", "comment": null, "summary": "Deep Research Agents are increasingly used for automated survey generation. However, whether they can write surveys like human experts remains unclear. Existing benchmarks focus on fluency or citation accuracy, but none evaluates the core capabilities: retrieving essential papers and organizing them into coherent knowledge structures. We introduce TaxoBench, a diagnostic benchmark derived from 72 highly-cited computer science surveys. We manually extract expert-authored taxonomy trees containing 3,815 precisely categorized citations as ground truth. Our benchmark supports two evaluation modes: Deep Research mode tests end-to-end retrieval and organization given only a topic, while Bottom-Up mode isolates structuring capability by providing the exact papers human experts used. We evaluate 7 leading Deep Research agents and 12 frontier LLMs. Results reveal a dual bottleneck: the best agent recalls only 20.9% of expert-selected papers, and even with perfect input, the best model achieves only 0.31 ARI in organization. Current deep research agents remain far from expert-level survey writing. Our benchmark is publicly available at https://github.com/KongLongGeFDU/TaxoBench.", "AI": {"tldr": "本研究提出了TaxoBench，一个用于评估深度研究代理（Deep Research Agents）生成学术调查报告能力的基准测试。研究发现，现有代理在检索关键论文和组织知识结构方面与人类专家存在显著差距。", "motivation": "现有基准测试未能充分评估深度研究代理生成学术调查报告的核心能力，即检索关键文献并构建连贯的知识结构。研究旨在明确深度研究代理在生成调查报告方面是否能达到人类专家的水平。", "method": "研究人员从72篇高被引计算机科学调查论文中提取了专家编写的分类树，并将其作为3815篇精确定位的引用文献的真实标签。创建了一个名为TaxoBench的诊断基准测试，该测试支持两种评估模式：深度研究模式（仅给定主题）和自下而上模式（提供人类专家使用的精确论文）。评估了7个领先的深度研究代理和12个前沿大型语言模型。", "result": "结果表明，目前的深度研究代理在文献检索方面存在瓶颈，最佳代理仅能召回20.9%的专家选择的论文。即使提供精确的输入，在组织结构方面，最佳模型也仅能达到0.31的ARI得分。这表明现有代理在生成调查报告方面距离专家水平尚有很大差距。", "conclusion": "深度研究代理在自动生成学术调查报告方面仍远未达到人类专家的水平，尤其在检索和组织关键文献方面存在显著不足。TaxoBench基准测试为此类代理的评估和未来发展提供了重要工具。"}}
{"id": "2601.13813", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13813", "abs": "https://arxiv.org/abs/2601.13813", "authors": ["Timofei Kozlov", "Artem Trandofilov", "Georgii Gazaryan", "Issatay Tokmurziyev", "Miguel Altamirano Cabrera", "Dzmitry Tsetserukou"], "title": "GuideTouch: An Obstacle Avoidance Device for Visually Impaired", "comment": "This paper has been accepted for publication at LBR of HRI 2026 conference", "summary": "Safe navigation for the visually impaired individuals remains a critical challenge, especially concerning head-level obstacles, which traditional mobility aids often fail to detect. We introduce GuideTouch, a compact, affordable, standalone wearable device designed for autonomous obstacle avoidance. The system integrates two vertically aligned Time-of-Flight (ToF) sensors, enabling three-dimensional environmental perception, and four vibrotactile actuators that provide directional haptic feedback. Proximity and direction information is communicated via an intuitive 4-point vibrotactile feedback system located across the user's shoulders and upper chest. For real-world robustness, the device includes a unique centrifugal self-cleaning optical cover mechanism and a sound alarm system for location if the device is dropped. We evaluated the haptic perception accuracy across 22 participants (17 male and 5 female, aged 21-48, mean 25.7, sd 6.1). Statistical analysis confirmed a significant difference between the perception accuracy of different patterns. The system demonstrated high recognition accuracy, achieving an average of 92.9% for single and double motor (primary directional) patterns. Furthermore, preliminary experiments with 14 visually impaired users validated this interface, showing a recognition accuracy of 93.75% for primary directional cues. The results demonstrate that GuideTouch enables intuitive spatial perception and could significantly improve the safety, confidence, and autonomy of users with visual impairments during independent navigation.", "AI": {"tldr": "GuideTouch 是一款可穿戴设备，利用 ToF 传感器和触觉反馈系统，为视障人士提供自主避障功能，尤其关注头部障碍物。", "motivation": "解决传统助行器难以检测头部障碍物的问题，提高视障人士的安全导航能力。", "method": "集成两个垂直排列的 ToF 传感器进行环境感知，并使用四个触觉驱动器提供方向性触觉反馈，反馈信息通过肩部和上胸部的四点阵列传递。", "result": "实验证明，用户对触觉模式有显著的感知准确性，单点和双点触觉模式的识别准确率平均可达 92.9%。在视障用户初步实验中，主要方向性线索的识别准确率为 93.75%。", "conclusion": "GuideTouch 能够提供直观的空间感知，有望显著提升视障用户独立导航时的安全性、自信心和自主性。"}}
{"id": "2601.12051", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12051", "abs": "https://arxiv.org/abs/2601.12051", "authors": ["Weixin Ye", "Wei Wang", "Yahui Liu", "Yue Song", "Bin Ren", "Wei Bi", "Rita Cucchiara", "Nicu Sebe"], "title": "A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models", "comment": "9 figures, 12 tables", "summary": "In federated learning, Transformer, as a popular architecture, faces critical challenges in defending against gradient attacks and improving model performance in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. It has been revealed that the gradient of Position Embeddings (PEs) in Transformer contains sufficient information, which can be used to reconstruct the input data. To mitigate this issue, we introduce a Masked Jigsaw Puzzle (MJP) framework. MJP starts with random token shuffling to break the token order, and then a learnable \\textit{unknown (unk)} position embedding is used to mask out the PEs of the shuffled tokens. In this manner, the local spatial information which is encoded in the position embeddings is disrupted, and the models are forced to learn feature representations that are less reliant on the local spatial information. Notably, with the careful use of MJP, we can not only improve models' robustness against gradient attacks, but also boost their performance in both vision and text application scenarios, such as classification for images (\\textit{e.g.,} ImageNet-1K) and sentiment analysis for text (\\textit{e.g.,} Yelp and Amazon). Experimental results suggest that MJP is a unified framework for different Transformer-based models in both vision and language tasks. Code is publicly available via https://github.com/ywxsuperstar/transformerattack", "AI": {"tldr": "本研究提出了一种名为掩码拼图（MJP）的框架，用于增强联邦学习中Transformer模型对梯度攻击的防御能力，并提升其在计算机视觉和自然语言处理任务中的性能。MJP通过随机打乱token顺序并使用一个可学习的未知位置嵌入来掩盖位置嵌入信息，从而迫使模型学习更鲁棒的特征表示。", "motivation": "在联邦学习中，Transformer模型在防御梯度攻击和提升模型性能方面面临挑战。研究发现，Transformer的位置嵌入（PE）包含足够的信息，可以被用于重构输入数据，这暴露了模型的安全风险。", "method": "本文提出的MJP框架包含两个主要步骤：1. 随机打乱token的顺序以破坏其原有位置信息；2. 使用一个可学习的未知（unk）位置嵌入来掩盖被混淆token的位置嵌入。这样可以打乱局部空间信息，并迫使模型学习对局部空间信息依赖性较低的特征。", "result": "实验结果表明，MJP框架在抵御梯度攻击方面显著提高了模型的鲁棒性，同时在图像分类（如ImageNet-1K）和文本情感分析（如Yelp和Amazon）等任务中也提升了模型性能。MJP被证明是一个适用于不同Transformer模型和任务的统一框架。", "conclusion": "MJP是一个有效的统一框架，可以增强联邦学习中Transformer模型对梯度攻击的鲁棒性，并同时提升其在计算机视觉和自然语言处理任务中的性能。通过破坏局部空间信息，模型能够学习到更通用的特征表示。"}}
{"id": "2601.12804", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12804", "abs": "https://arxiv.org/abs/2601.12804", "authors": ["Hanwei Zhang", "Luo Cheng", "Rui Wen", "Yang Zhang", "Lijun Zhang", "Holger Hermanns"], "title": "SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability", "comment": null, "summary": "Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.", "AI": {"tldr": "本研究提出了一种名为SL-CBM的新型概念瓶颈模型，通过强制概念和类别预测的空间一致性来提高模型的可解释性，使其能够生成更准确、与图像区域更对齐的显著性图。", "motivation": "现有概念瓶颈模型（CBM）在空间局部性方面存在不足，导致概念与图像区域的对齐不佳，从而限制了其可解释性和可靠性，尤其是在高风险领域。", "method": "提出SL-CBM模型，通过引入一个1x1卷积层和交叉注意力机制，来增强概念、图像区域和最终预测之间的对齐，从而生成具有空间局部性的显著性图。", "result": "SL-CBM模型在图像数据集上显著提高了空间局部性、解释质量和干预效果，同时保持了具有竞争力的分类准确率。消融研究表明，对比和基于熵的正则化对于平衡准确性、稀疏性和忠实度至关重要。", "conclusion": "SL-CBM模型成功地弥合了基于概念的推理和空间可解释性之间的差距，为可信赖的基于概念的模型设定了新的标准。"}}
{"id": "2601.12374", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12374", "abs": "https://arxiv.org/abs/2601.12374", "authors": ["Akram Elbouanani", "Aboubacar Tuo", "Adrian Popescu"], "title": "A Scalable Entity-Based Framework for Auditing Bias in LLMs", "comment": null, "summary": "Existing approaches to bias evaluation in large language models (LLMs) trade ecological validity for statistical control, relying on artificial prompts that poorly reflect real-world use, or on naturalistic tasks that lack scale and rigor. We introduce a scalable bias-auditing framework using named entities as probes to measure structural disparities in model behavior. We show that synthetic data reliably reproduces bias patterns observed in natural text, enabling large-scale analysis. Using this approach, we conduct the largest bias audit to date, comprising 1.9 billion data points across multiple entity types, tasks, languages, models, and prompting strategies. Our results reveal systematic biases: models penalize right-wing politicians, favor left-wing politicians, prefer Western and wealthy nations over the Global South, favor Western companies, and penalize firms in the defense and pharmaceutical sectors. While instruction tuning reduces bias, increasing model scale amplifies it, and prompting in Chinese or Russian does not attenuate Western-aligned preferences. These results indicate that LLMs should undergo rigorous auditing before deployment in high-stakes applications.", "AI": {"tldr": "本研究提出了一个利用命名实体作为探针的大规模语言模型（LLMs）偏见审计框架，通过合成数据复现自然文本中的偏见模式，并进行了迄今为止最大规模的偏见审计。结果显示LLMs存在系统性偏见，例如偏袒左翼政治家、偏爱西方发达国家和西方公司，并对国防和制药公司进行惩罚。研究还发现，指令微调能减轻偏见，但模型规模的增加会加剧偏见，且使用中文或俄语进行提示也无法消除西方偏好。", "motivation": "现有LLMs偏见评估方法在生态效度和统计控制之间存在权衡，人工提示不能反映真实世界使用情况，而自然语言任务缺乏规模和严谨性。需要一种能够进行大规模、可控且具有生态效度的偏见评估方法。", "method": "提出一个利用命名实体作为探针的大规模偏见审计框架。使用合成数据来复现自然文本中的偏见模式，从而实现大规模分析。对19亿数据点进行了审计，涵盖多种实体类型、任务、语言、模型和提示策略。", "result": "发现LLMs存在系统性偏见：1. 惩罚右翼政治家，偏袒左翼政治家。2. 偏爱西方和富裕国家，而非全球南方国家。3. 偏爱西方公司。4. 惩罚国防和制药行业的公司。指令微调能减少偏见，但模型规模的增加会加剧偏见。使用中文或俄语提示并不能减弱西方偏好。", "conclusion": "LLMs存在显著的系统性偏见，这些偏见与政治倾向、地理位置、公司行业等有关。尽管指令微调可以减轻部分偏见，但模型规模的增加反而会加剧偏见。在将LLMs应用于高风险领域之前，应进行严格的审计。"}}
{"id": "2601.12052", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12052", "abs": "https://arxiv.org/abs/2601.12052", "authors": ["Zaiyan Zhang", "Jie Li", "Shaowei Shi", "Qiangqiang Yuan"], "title": "Task-Driven Prompt Learning: A Joint Framework for Multi-modal Cloud Removal and Segmentation", "comment": "Submitted to IGARSS 2026 Conference", "summary": "Optical remote sensing imagery is indispensable for Earth observation, yet persistent cloud occlusion limits its downstream utility. Most cloud removal (CR) methods are optimized for low-level fidelity and can over-smooth textures and boundaries that are critical for analysis-ready data (ARD), leading to a mismatch between visually plausible restoration and semantic utility. To bridge this gap, we propose TDP-CR, a task-driven multimodal framework that jointly performs cloud removal and land-cover segmentation. Central to our approach is a Prompt-Guided Fusion (PGF) mechanism, which utilizes a learnable degradation prompt to encode cloud thickness and spatial uncertainty. By combining global channel context with local prompt-conditioned spatial bias, PGF adaptively integrates Synthetic Aperture Radar (SAR) information only where optical data is corrupted. We further introduce a parameter-efficient two-phase training strategy that decouples reconstruction and semantic representation learning. Experiments on the LuojiaSET-OSFCR dataset demonstrate the superiority of our framework: TDP-CR surpasses heavy state-of-the-art baselines by 0.18 dB in PSNR while using only 15\\% of the parameters, and achieves a 1.4\\% improvement in mIoU consistently against multi-task competitors, effectively delivering analysis-ready data.", "AI": {"tldr": "提出了一种名为TDP-CR的任务驱动多模态框架，用于联合去除光学遥感影像中的云层并进行土地覆盖分割，通过提示引导融合（PGF）机制自适应地融合SAR数据，解决了现有方法在纹理和边界处理上的不足，并在PSNR和mIoU上取得了显著提升。", "motivation": "现有光学遥感影像的云层去除方法在低层保真度方面优化，容易导致纹理和边界模糊，不满足分析就绪数据（ARD）的要求。这使得视觉上看似合理的恢复与语义利用之间存在差距。", "method": "提出TDP-CR框架，联合进行云层去除和土地覆盖分割。核心是提示引导融合（PGF）机制，使用可学习的退化提示来编码云层厚度和空间不确定性。PGF结合全局通道上下文和局部提示条件空间偏差，选择性地融合SAR信息。采用参数高效的两阶段训练策略，分离重构和语义表示学习。", "result": "在LuojiaSET-OSFCR数据集上的实验表明，TDP-CR在PSNR上比现有最先进方法高0.18 dB，参数量仅为后者的15%。在mIoU上比多任务竞争者稳定提高1.4%。", "conclusion": "TDP-CR框架能够有效去除云层并进行土地覆盖分割，产生分析就绪数据，解决了传统方法在处理纹理和边界时的局限性，并在性能和效率上优于现有技术。"}}
{"id": "2601.12376", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12376", "abs": "https://arxiv.org/abs/2601.12376", "authors": ["Ofek Raban", "Ethan Fetaya", "Gal Chechik"], "title": "LR-DWM: Efficient Watermarking for Diffusion Language Models", "comment": "Submitted to ACL Rolling Review (ARR). 7 pages, 4 figures", "summary": "Watermarking (WM) is a critical mechanism for detecting and attributing AI-generated content. Current WM methods for Large Language Models (LLMs) are predominantly tailored for autoregressive (AR) models: They rely on tokens being generated sequentially, and embed stable signals within the generated sequence based on the previously sampled text. Diffusion Language Models (DLMs) generate text via non-sequential iterative denoising, which requires significant modification to use WM methods designed for AR models. Recent work proposed to watermark DLMs by inverting the process when needed, but suffers significant computational or memory overhead. We introduce Left-Right Diffusion Watermarking (LR-DWM), a scheme that biases the generated token based on both left and right neighbors, when they are available. LR-DWM incurs minimal runtime and memory overhead, remaining close to the non-watermarked baseline DLM while enabling reliable statistical detection under standard evaluation settings. Our results demonstrate that DLMs can be watermarked efficiently, achieving high detectability with negligible computational and memory overhead.", "AI": {"tldr": "本文提出了一种名为 LR-DWM 的扩散语言模型（DLM）水印方法，该方法通过同时考虑左右邻近词来嵌入水印，解决了现有方法对自回归模型的依赖和计算开销大的问题，实现了高效可靠的水印检测。", "motivation": "现有的大语言模型（LLM）水印方法主要针对自回归（AR）模型，不适用于非序列生成的扩散语言模型（DLM）。现有的 DLM 水印方法计算或内存开销大。", "method": "提出 LR-DWM（Left-Right Diffusion Watermarking）方案，该方案在生成 token 时，根据左右邻近词（如果可用）来引入偏差，从而嵌入水印。这种方法避免了对 AR 模型方法的修改，也减少了计算和内存开销。", "result": "LR-DWM 在运行时和内存开销方面，与未加水印的基线 DLM 几乎没有差异。在标准评估设置下，能够实现可靠的统计检测。", "conclusion": "DLM 可以被高效地添加水印，LR-DWM 方案实现了高检测率，同时计算和内存开销可以忽略不计。"}}
{"id": "2601.13945", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13945", "abs": "https://arxiv.org/abs/2601.13945", "authors": ["Yixuan Deng", "Tongrun Wu", "Donghao Wu", "Zeyu Wei", "Jiayuan Wang", "Zhenglong Sun", "Yuqing Tang", "Xiaoqiang Ji"], "title": "Efficient Coordination with the System-Level Shared State: An Embodied-AI Native Modular Framework", "comment": null, "summary": "As Embodied AI systems move from research prototypes to real world deployments, they tend to evolve rapidly while remaining reliable under workload changes and partial failures. In practice, many deployments are only partially decoupled: middleware moves messages, but shared context and feedback semantics are implicit, causing interface drift, cross-module interference, and brittle recovery at scale. We present ANCHOR, a modular framework that makes decoupling and robustness explicit system-level primitives. ANCHOR separates (i) Canonical Records, an evolvable contract for the standardized shared state, from (ii) a communication bus for many-to-many dissemination and feedback-oriented coordination, forming an inspectable end-to-end loop. We validate closed-loop feasibility on a de-identified workflow instantiation, characterize latency distributions under varying payload sizes and publish rates, and demonstrate automatic stream resumption after hard crashes and restarts even with shared-memory loss. Overall, ANCHOR turns ad-hoc integration glue into explicit contracts, enabling controlled degradation under load and self-healing recovery for scalable deployment of closed-loop AI systems.", "AI": {"tldr": "ANCHOR 是一个模块化框架，通过明确的接口和通信协议来提高具身 AI 系统的解耦性和鲁棒性，从而支持可扩展的部署和故障恢复。", "motivation": "当前的具身 AI 系统在实际部署中存在接口漂移、模块间干扰和故障恢复困难等问题，原因是它们之间的耦合方式是隐式的，并且缺乏系统级的解耦和鲁棒性保障。", "method": "ANCHOR 框架通过将（i）可演化的规范记录（Canonical Records）作为标准化共享状态的契约，与（ii）用于多对多传播和面向反馈协调的通信总线相结合，形成一个可检查的端到端闭环。该框架被用于工作流实例化的验证，并分析了在不同负载下的延迟分布，同时展示了在硬崩溃和重启后自动恢复流的能力。", "result": "ANCHOR 成功实现了闭环可行性，并通过实验证明了其在不同负载下的性能表现，以及在发生故障后能够自动恢复流的能力，即使在共享内存丢失的情况下也能实现。", "conclusion": "ANCHOR 将临时的集成粘合剂转变为明确的系统级契约，为具身 AI 系统在负载变化下的可控降级和自愈恢复提供了可能，从而支持其规模化部署。"}}
{"id": "2601.12781", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12781", "abs": "https://arxiv.org/abs/2601.12781", "authors": ["Hyejin Park", "Junhyuk Kwon", "Suha Kwak", "Jungseul Ok"], "title": "VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension", "comment": null, "summary": "Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.", "AI": {"tldr": "本文提出了一种名为 VIRO 的神经符号框架，通过在推理步骤中嵌入轻量级操作符级验证器来解决现有神经符号 REC 方法中级推理错误导致的级联误差问题，特别是在无目标情况下的误报。VIRO 能够在操作符级别验证其输出，从而鲁棒地处理无目标情况。实验结果表明，VIRO 在有目标和无目标场景下均达到了最先进的性能，并能泛化到真实世界的自我中心数据，同时还具有更高的计算效率、可靠性和可扩展性。", "motivation": "现有的神经符号 REC 方法在推理过程中假设中间步骤是准确的，这会导致错误在推理链中级联，即使图像中不存在目标，也会产生高置信度的假阳性。因此，需要一种能够处理无目标情况并减少级联错误的方法。", "method": "本文提出了一种名为 VIRO（Verification-Integrated Reasoning Operators）的神经符号框架。VIRO 的核心思想是在推理的每个步骤中嵌入轻量级的操作符级验证器。这些验证器负责执行并验证其输出（例如，对象是否存在、空间关系是否成立），从而允许系统在验证条件不满足时鲁棒地处理无目标情况。", "result": "VIRO 在有目标和无目标场景下取得了 61.1% 的平衡准确率，达到最先进水平，并能泛化到真实世界的自我中心数据。此外，VIRO 在吞吐量方面表现出优越的计算效率，程序失败率低于 0.3%，显示了高可靠性，并且通过将程序生成与执行解耦，实现了可扩展性。", "conclusion": "VIRO 框架通过在推理操作符中集成验证机制，有效地解决了现有神经符号 REC 方法在处理无目标情况时出现的级联错误和高置信度假阳性问题。该方法在性能、效率、可靠性和可扩展性方面均表现出色，为更鲁棒的基于语言的视觉定位提供了新的解决方案。"}}
{"id": "2601.12055", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12055", "abs": "https://arxiv.org/abs/2601.12055", "authors": ["Lina Meyer", "Felix Wissel", "Tobias Knopp", "Susanne Pfefferle", "Ralf Fliegert", "Maximilian Sandmann", "Liana Uebler", "Franziska Möckl", "Björn-Philipp Diercks", "David Lohr", "René Werner"], "title": "Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer", "comment": null, "summary": "Unsupervised deep image prior (DIP) addresses shortcomings of training data requirements and limited generalization associated with supervised deep learning. The performance of DIP depends on the network architecture and the stopping point of its iterative process. Optimizing these parameters for a new image requires time, restricting DIP application in domains where many images need to be processed. Focusing on fluorescence microscopy data, we hypothesize that similar images share comparable optimal parameter configurations for DIP-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. We generated a calibration (n=110) and validation set (n=55) of semantically different images from an open-source dataset for a network architecture search targeted towards ideal U-net architectures and stopping points. The calibration set represented our transfer basis. The validation set enabled the assessment of which image similarity criterion yields the best results. We then implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the originally published DIP configuration (baseline) and a state-of-the-art image-specific variational denoising approach. We show that a parameter transfer from the calibration dataset to a test image based on only image metadata similarity (e.g., microscope type, imaged specimen) leads to similar and better performance than a transfer based on quantitative image similarity measures. AUTO-DIP outperforms the baseline DIP (DIP with original DIP parameters) as well as the variational denoising approaches for several open-source test datasets of varying complexity, particularly for very noisy inputs. Applications to locally acquired fluorescence microscopy images further proved superiority of AUTO-DIP.", "AI": {"tldr": "提出了一种名为 AUTO-DIP 的自动化无监督深度图像先验（DIP）管道，用于荧光显微镜图像去噪。该方法通过从一个校准集中转移参数，避免了每次处理新图像时进行优化的需求，并且在多种测试数据集上表现优于基线 DIP 和其他变分去噪方法，尤其是在输入图像噪声很大的情况下。", "motivation": "现有的无监督深度图像先验（DIP）方法在优化网络架构和迭代停止点以适应新图像时效率低下，限制了其在大规模图像处理场景的应用。研究人员希望为荧光显微镜图像找到一种无需优化的 DIP 方法。", "method": "使用 U-net 架构，通过神经网络架构搜索和停止点选择来寻找理想的 DIP 参数配置。构建了一个包含 110 张图像的校准集和一个包含 55 张图像的验证集。通过评估不同图像相似性标准（包括图像元数据和量化图像相似性）对参数转移效果的影响，设计了一个名为 AUTO-DIP 的自动化参数转移管道。", "result": "基于图像元数据相似性（如显微镜类型、成像样本）的参数转移效果与基于量化图像相似性的转移效果相当，甚至更好。AUTO-DIP 在多个开放数据集和实际采集的荧光显微镜图像上，均优于原始 DIP 配置和先进的变分去噪方法，尤其在处理极度噪声的输入时效果显著。", "conclusion": "AUTO-DIP 成功地实现了针对荧光显微镜图像的优化无关（optimization-free）的 DIP 方法，通过利用校准集中与新图像相似的元数据来转移参数，显著提高了 DIP 的效率和性能，为无监督图像去噪在大规模应用中开辟了新的可能性。"}}
{"id": "2601.12822", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12822", "abs": "https://arxiv.org/abs/2601.12822", "authors": ["Wenqi Zhang", "Yulin Shen", "Changyue Jiang", "Jiarun Dai", "Geng Hong", "Xudong Pan"], "title": "MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction", "comment": null, "summary": "Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.", "AI": {"tldr": "本文提出了一种名为MirrorGuard的即插即用防御框架，利用基于仿真的训练来提高计算机使用代理（CUA）在真实世界中的安全性，通过文本模拟生成高风险GUI交互轨迹，拦截和纠正CUA的不安全推理，从而显著降低安全风险，同时保持代理的基本效用。", "motivation": "大型基础模型在计算机使用代理（CUA）中的应用带来了严重的安全风险，恶意指令或视觉提示注入可能导致代理执行有害的系统级操作。现有的检测机制会过早中止任务，降低代理的实用性，因此需要一种既能保证安全又能维持效用的防御方法。", "method": "MirrorGuard提出了一种新颖的神经符号模拟流水线，在文本模拟环境中生成逼真的高风险GUI交互轨迹，以捕捉不安全推理模式和潜在系统危险。通过这种方式，MirrorGuard可以在CUA产生和执行不安全操作之前，拦截和纠正其不安全推理链。该方法避免了在真实操作系统中进行大规模训练的高成本。", "result": "在真实世界测试中，MirrorGuard在多个基准和CUA架构上显著降低了安全风险。在ByteDance UI-TARS系统上，不安全率从66.5%降至13.0%，同时保持了较低的误拒绝率（FRR）。相比之下，现有的GuardAgent仅将不安全率降至53.9%，且FRR高出15.4%。", "conclusion": "基于模拟的防御可以为CUA提供强大的现实世界保护，同时保持代理的基本效用。MirrorGuard证明了这种方法的有效性，并为解决CUA的安全问题提供了一种新的解决方案。"}}
{"id": "2601.13979", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13979", "abs": "https://arxiv.org/abs/2601.13979", "authors": ["Raffaele Mazza", "Ciro Natale", "Pietro Falco"], "title": "Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects", "comment": null, "summary": "This paper presents a novel cross-modal visuo-tactile perception framework for the 3D shape reconstruction of deformable linear objects (DLOs), with a specific focus on cables subject to severe visual occlusions. Unlike existing methods relying predominantly on vision, whose performance degrades under varying illumination, background clutter, or partial visibility, the proposed approach integrates foundation-model-based visual perception with adaptive tactile exploration. The visual pipeline exploits SAM for instance segmentation and Florence for semantic refinement, followed by skeletonization, endpoint detection, and point-cloud extraction. Occluded cable segments are autonomously identified and explored with a tactile sensor, which provides local point clouds that are merged with the visual data through Euclidean clustering and topology-preserving fusion. A B-spline interpolation driven by endpoint-guided point sorting yields a smooth and complete reconstruction of the cable shape. Experimental validation using a robotic manipulator equipped with an RGB-D camera and a tactile pad demonstrates that the proposed framework accurately reconstructs both simple and highly curved single or multiple cable configurations, even when large portions are occluded. These results highlight the potential of foundation-model-enhanced cross-modal perception for advancing robotic manipulation of deformable objects.", "AI": {"tldr": "该研究提出了一种新颖的跨模态视觉-触觉感知框架，用于重建发生严重视觉遮挡的可变形线性物体（DLO），特别是电缆。通过结合基于基础模型的视觉感知和自适应触觉探索，即使在大部分电缆被遮挡的情况下，也能实现准确的三维形状重建。", "motivation": "现有方法主要依赖视觉，在光照变化、背景杂乱或部分可见的情况下性能会下降。因此，需要一种能够克服视觉限制的鲁棒方法，特别是在处理电缆等容易发生视觉遮挡的可变形物体时。", "method": "该框架结合了SAM进行实例分割和Florence进行语义精炼的视觉流水线，随后进行骨架化、端点检测和点云提取。对于被遮挡的电缆段，使用触觉传感器进行自适应探索，获取局部点云。通过欧几里得聚类和拓扑保持融合将触觉点云与视觉数据合并。最后，利用端点引导的点排序和B样条插值进行平滑和完整的电缆形状重建。", "result": "实验结果表明，该框架能够准确重建简单和高度弯曲的单根或多根电缆配置，即使在大部分电缆被遮挡的情况下也能实现高精度重建。", "conclusion": "基于基础模型的跨模态感知方法为提高机器人操纵可变形物体提供了新的可能性，尤其是在处理具有挑战性的视觉遮挡场景时。"}}
{"id": "2601.14000", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14000", "abs": "https://arxiv.org/abs/2601.14000", "authors": ["Junwoo Chang", "Joseph Park", "Roberto Horowitz", "Jongmin Lee", "Jongeun Choi"], "title": "Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior", "comment": "14 pages, 6 figures", "summary": "Unsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline.", "AI": {"tldr": "提出了一种名为GISD（Group-Invariant Skill Discovery）的框架，用于在考虑物理环境的几何对称性的情况下发现无监督技能，提高了探索效率和下游任务学习速度。", "motivation": "现有无监督技能发现方法忽略了物理环境的几何对称性，导致行为冗余和样本效率低下。", "method": "GISD将群结构显式地嵌入到技能发现目标中，并提出了群不变Wasserstein依赖度量，通过群傅里叶表示参数化评分函数，并利用等变潜在特征的对齐来定义内在奖励。", "result": "在基于状态和基于像素的运动基准测试中，GISD实现了更广泛的状态空间覆盖，并在下游任务学习中表现出更高的效率。", "conclusion": "GISD框架能够有效地处理具有群对称性的环境，发现更具泛化能力的技能，并提高样本效率。"}}
{"id": "2601.12062", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12062", "abs": "https://arxiv.org/abs/2601.12062", "authors": ["Xiaomei Yang", "Xizhan Gao", "Antai Liu", "Kang Wei", "Fa Zhu", "Guang Feng", "Xiaofeng Qu", "Sijie Niu"], "title": "Learning Language-Driven Sequence-Level Modal-Invariant Representations for Video-Based Visible-Infrared Person Re-Identification", "comment": null, "summary": "The core of video-based visible-infrared person re-identification (VVI-ReID) lies in learning sequence-level modal-invariant representations across different modalities. Recent research tends to use modality-shared language prompts generated by CLIP to guide the learning of modal-invariant representations. Despite achieving optimal performance, such methods still face limitations in efficient spatial-temporal modeling, sufficient cross-modal interaction, and explicit modality-level loss guidance. To address these issues, we propose the language-driven sequence-level modal-invariant representation learning (LSMRL) method, which includes spatial-temporal feature learning (STFL) module, semantic diffusion (SD) module and cross-modal interaction (CMI) module. To enable parameter- and computation-efficient spatial-temporal modeling, the STFL module is built upon CLIP with minimal modifications. To achieve sufficient cross-modal interaction and enhance the learning of modal-invariant features, the SD module is proposed to diffuse modality-shared language prompts into visible and infrared features to establish preliminary modal consistency. The CMI module is further developed to leverage bidirectional cross-modal self-attention to eliminate residual modality gaps and refine modal-invariant representations. To explicitly enhance the learning of modal-invariant representations, two modality-level losses are introduced to improve the features' discriminative ability and their generalization to unseen categories. Extensive experiments on large-scale VVI-ReID datasets demonstrate the superiority of LSMRL over AOTA methods.", "AI": {"tldr": "本文提出了一种名为LSMRL的语言驱动序列级模态不变表示学习方法，用于解决视频可见光-红外行人重识别（VVI-ReID）中的时空建模、跨模态交互和模态级损失引导问题。", "motivation": "现有方法在利用CLIP生成的语言提示学习模态不变表示时，在时空建模效率、跨模态交互充分性以及显式模态级损失引导方面存在不足。", "method": "LSMRL方法包含三个模块：1. STFL模块：基于CLIP进行参数和计算效率高的时空特征学习；2. SD模块：将模态共享的语言提示扩散到可见光和红外特征中，建立初步模态一致性；3. CMI模块：利用双向跨模态自注意力消除剩余模态差异，精炼模态不变表示。此外，引入了两种模态级损失来增强特征的判别能力和泛化性。", "result": "在大型VVI-ReID数据集上的实验表明，LSMRL方法优于现有的AOTA方法。", "conclusion": "LSMRL方法通过创新的模块设计和损失函数，有效地解决了VVI-ReID中的关键挑战，并在大规模数据集上取得了SOTA性能。"}}
{"id": "2601.12842", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12842", "abs": "https://arxiv.org/abs/2601.12842", "authors": ["Qitong Fang", "Haotian Li", "Xu Wang"], "title": "SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning", "comment": "11 pages, 3 figures. Equal contribution: Qitong Fang and Haotian Li. Corresponding authors: Qitong Fang (fangqitong@student.jlju.edu.cn), Haotian Li (lihaotian@student.jlju.edu.cn), Xu Wang (wangxu@jlju.edu.cn)", "summary": "Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.", "AI": {"tldr": "本文提出了一种名为SCULPT的约束引导方法，用于改进大型语言模型（LLM）的自动化代理工作流，通过引入领域感知评分来指导蒙特卡洛树搜索（MCTS），从而提高推理的准确性和稳定性。", "motivation": "现有的LLM代理工作流在解决问题时，由于搜索策略依赖于随机探索和弱领域先验，容易陷入不合理的搜索路径。这导致了效率低下和推理不稳定。", "method": "SCULPT是一种基于约束的MCTS方法。它在MCTS的选择、扩展、模拟和反向传播阶段整合了领域感知的评分机制。该机制通过符号检查（如维度一致性、类型兼容性、数量合理性、深度控制和多样性）以及结构模式引导来评估和修剪动作，从而引导搜索走向合理的推理路径。", "result": "在相同的LLM配置下，SCULPT在多个数据集上表现出稳定的性能提升。使用GPT-5.2进行的额外实验评估了执行器迁移能力和在前沿推理模型上的表现。", "conclusion": "领域感知的约束能够显著提高LLM代理工作流的准确性，同时保持效率和推理的稳定性。"}}
{"id": "2601.12389", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12389", "abs": "https://arxiv.org/abs/2601.12389", "authors": ["Lakshya Tomar", "Vinayak Abrol", "Puneet Agarwal"], "title": "NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages", "comment": "Accepted at the AAAI Conference on Artificial Intelligence (AAAI 2026)", "summary": "In this work, we argue that not all sequence-to-sequence tasks require the strong inductive biases of autoregressive (AR) models. Tasks like multilingual transliteration, code refactoring, grammatical correction or text normalization often rely on local dependencies where the full modeling capacity of AR models can be overkill, creating a trade-off between their high accuracy and high inference latency. While non-autoregressive (NAR) models offer speed, they typically suffer from hallucinations and poor length control. To explore this trade-off, we focus on the multilingual transliteration task in Indic languages and introduce NADIR, a novel NAR architecture designed to strike a balance between speed and accuracy. NADIR integrates a Differential Transformer and a Mixture-of-Experts mechanism, enabling it to robustly model complex character mappings without sequential dependencies. NADIR achieves over a 13x speed-up compared to the state-of-the-art AR baseline. It maintains a competitive mean Character Error Rate of 15.78%, compared to 14.44% for the AR model and 21.88% for a standard NAR equivalent. Importantly, NADIR reduces Repetition errors by 49.53%, Substitution errors by 24.45%, Omission errors by 32.92%, and Insertion errors by 16.87%. This work provides a practical blueprint for building fast and reliable NAR systems, effectively bridging the gap between AR accuracy and the demands of real-time, large-scale deployment.", "AI": {"tldr": "本文提出了一种名为NADIR的新型非自回归（NAR）模型，用于多语言音译任务，旨在平衡速度和准确性。NADIR通过集成差分Transformer和专家混合机制，在不依赖序列依赖的情况下，实现了比最先进自回归（AR）模型快13倍的速度，同时保持了具有竞争力的准确性，并在各种错误类型上取得了显著改进。", "motivation": "现有的自回归（AR）模型虽然准确，但推理延迟高，而传统非自回归（NAR）模型速度快但存在幻觉和长度控制差的问题。作者认为并非所有序列到序列任务都需要AR模型的强归纳偏置，因此旨在探索一种既能保持AR模型的准确性，又能实现NAR模型高速推理的折衷方案。", "method": "提出了一种名为NADIR的新型NAR架构，该架构整合了差分Transformer（Differential Transformer）和专家混合（Mixture-of-Experts）机制。差分Transformer能够处理局部依赖关系，而专家混合机制则有助于模型鲁棒地建模复杂的字符映射，而无需依赖序列依赖。", "result": "NADIR在多语言音译任务上实现了比最先进AR基线模型快13倍以上的速度。其平均字符错误率（CER）为15.78%，略高于AR模型的14.44%，但远优于标准NAR模型的21.88%。此外，NADIR在重复错误、替换错误、遗漏错误和插入错误方面分别减少了49.53%、24.45%、32.92%和16.87%。", "conclusion": "NADIR是一种有效平衡速度和准确性的NAR模型，为构建快速可靠的NAR系统提供了实用的蓝图，成功弥合了AR模型的准确性与实时、大规模部署需求之间的差距。"}}
{"id": "2601.12419", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12419", "abs": "https://arxiv.org/abs/2601.12419", "authors": ["Mahammad Namazov", "Tomáš Koref", "Ivan Habernal"], "title": "Legal experts disagree with rationale extraction techniques for explaining ECtHR case outcome classification", "comment": null, "summary": "Interpretability is critical for applications of large language models in the legal domain which requires trust and transparency. While some studies develop task-specific approaches, other use the classification model's parameters to explain the decisions. However, which technique explains the legal outcome prediction best remains an open question. To address this challenge, we propose a comparative analysis framework for model-agnostic interpretability techniques. Among these, we employ two rationale extraction methods, which justify outcomes with human-interpretable and concise text fragments (i.e., rationales) from the given input text. We conduct comparison by evaluating faithfulness-via normalized sufficiency and comprehensiveness metrics along with plausibility-by asking legal experts to evaluate extracted rationales. We further assess the feasibility of LLM-as-a-Judge using legal expert evaluation results. We show that the model's \"reasons\" for predicting a violation differ substantially from those of legal experts, despite highly promising quantitative analysis results and reasonable downstream classification performance. The source code of our experiments is publicly available at https://github.com/trusthlt/IntEval.", "AI": {"tldr": "本研究提出了一个用于比较模型无关的解释性技术在法律领域应用框架，并评估了两种提取理由（rationale extraction）的方法，发现大型语言模型（LLM）的预测理由与法律专家的理由存在显著差异。", "motivation": "在法律领域，大型语言模型的解释性至关重要，但目前尚不清楚哪种解释技术最适合解释法律结果的预测。", "method": "提出一个模型无关的解释性技术比较分析框架，采用两种理由提取方法，并使用归一化充分性（sufficiency）和全面性（comprehensiveness）指标评估忠实度（faithfulness），同时邀请法律专家评估理由的可信度（plausibility）。此外，还评估了LLM-as-a-Judge的可行性。", "result": "尽管定量分析结果和下游分类性能都很有希望，但模型预测违规的理由与法律专家的理由存在显著差异。", "conclusion": "模型在法律领域做出预测时的“理由”与法律专家的理由不一致，这表明在法律应用中，仅依靠模型的自动解释可能存在风险，需要进一步的研究和验证。"}}
{"id": "2601.12066", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12066", "abs": "https://arxiv.org/abs/2601.12066", "authors": ["Zijie Lou", "Xiangwei Feng", "Jiaxin Wang", "Xiaochao Qu", "Luoqi Liu", "Ting Liu"], "title": "Learning Stochastic Bridges for Video Object Removal via Video-to-Video Translation", "comment": null, "summary": "Existing video object removal methods predominantly rely on diffusion models following a noise-to-data paradigm, where generation starts from uninformative Gaussian noise. This approach discards the rich structural and contextual priors present in the original input video. Consequently, such methods often lack sufficient guidance, leading to incomplete object erasure or the synthesis of implausible content that conflicts with the scene's physical logic. In this paper, we reformulate video object removal as a video-to-video translation task via a stochastic bridge model. Unlike noise-initialized methods, our framework establishes a direct stochastic path from the source video (with objects) to the target video (objects removed). This bridge formulation effectively leverages the input video as a strong structural prior, guiding the model to perform precise removal while ensuring that the filled regions are logically consistent with the surrounding environment. To address the trade-off where strong bridge priors hinder the removal of large objects, we propose a novel adaptive mask modulation strategy. This mechanism dynamically modulates input embeddings based on mask characteristics, balancing background fidelity with generative flexibility. Extensive experiments demonstrate that our approach significantly outperforms existing methods in both visual quality and temporal consistency.", "AI": {"tldr": "本文提出一种基于随机桥接模型的视频物体移除新方法，将视频物体移除重塑为视频到视频的翻译任务，解决了现有基于扩散模型的方法丢失输入视频丰富先验信息的问题，并通过自适应掩码调制策略提升了移除大物体的能力，实验结果表明该方法在视觉质量和时间一致性上均优于现有方法。", "motivation": "现有视频物体移除方法多基于扩散模型，从高斯噪声开始生成，忽略了原始输入视频丰富的结构和上下文先验信息，导致移除不彻底或生成不合逻辑的内容。本文旨在利用输入视频的先验信息，提高移除的精确性和生成内容的可信度。", "method": "将视频物体移除重塑为视频到视频的翻译任务，通过一个随机桥接模型建立从源视频到目标视频（移除物体后）的直接随机路径。此方法利用输入视频作为强结构先验。为解决强先验对大物体移除的影响，提出自适应掩码调制策略，根据掩码特征动态调整输入嵌入，平衡背景保真度和生成灵活性。", "result": "提出的方法在视觉质量和时间一致性方面显著优于现有方法。自适应掩码调制策略能够有效平衡背景保真度和生成灵活性，尤其在处理大物体移除时表现出色。", "conclusion": "本文提出的随机桥接模型和自适应掩码调制策略，能够有效利用输入视频的结构先验，实现更精确、更符合逻辑的视频物体移除，并能较好地处理大物体移除的挑战，在实验中取得了优于现有方法的性能。"}}
{"id": "2601.12856", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12856", "abs": "https://arxiv.org/abs/2601.12856", "authors": ["Liping Huang", "Gaoxi Xiao", "Stefan Ma", "Hechang Chen", "Shisong Tang", "Flora Salim"], "title": "Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data", "comment": "9 pages, 9 figures. It's accepted by WWW 2026 Web4Good Track. To make accessible earlier, authors would like to put it on arxiv before the conference", "summary": "Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.", "AI": {"tldr": "本研究提出了一种新的框架，利用公开的登革热病例数据，挖掘和利用城市区域之间的潜在传播联系，以预测疫情热点，并发现这些联系与通勤流动相符，为城市传播提供了可解释的依据。", "motivation": "登革热是城市地区，尤其是新加坡等热带地区的持续性公共卫生挑战。为了实现有效且经济的控制，需要预测疫情传播风险的可能区域，以便主动而非被动地部署干预措施。", "method": "研究者提出了一种新的框架，将病例视为相互影响的动态过程，而非孤立报告。他们通过梯度下降优化学习到的区域间潜在传播网络，并利用该网络来预测热点状态和验证传播模式的一致性。", "result": "研究发现在新加坡的案例研究（2013-2018年和2020年）中，仅用四周的热点历史数据，平均F-score即可达到0.79。学习到的传播联系与通勤流动高度一致，揭示了潜在的疫情传播与人类流动之间的可解释性相互作用。", "conclusion": "该框架通过挖掘和验证隐藏的传播动态，将公开的网络病例数据转化为预测和解释性资源，为公共卫生规划、早期干预和城市韧性提供了一个可扩展、低成本的工具，并推进了流行病建模。"}}
{"id": "2601.14091", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14091", "abs": "https://arxiv.org/abs/2601.14091", "authors": ["Hossein Naderi", "Alireza Shojaei", "Lifu Huang", "Philip Agee", "Kereshmeh Afsari", "Abiola Akanmu"], "title": "Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems", "comment": null, "summary": "Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate the improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction.", "AI": {"tldr": "研究利用轻量级、开源的大型语言模型（LLM）和视觉语言模型（VLM）构建了单智能体和多智能体系统，用于建筑机器人任务规划，旨在提高其适应性和泛化能力。其中一个四智能体团队在成本效益和性能上优于GPT-4o，并展现了良好的泛化能力。", "motivation": "建筑机器人面临成本高和适应动态任务困难的挑战，本研究旨在探索基础模型（尤其是LLMs和VLMs）在提升建筑机器人任务规划的适应性和泛化能力方面的潜力。", "method": "提出了四种基于轻量级、开源LLM和VLM的模型，包括一个单智能体和三个协同工作的多智能体团队，用于生成机器人动作计划。模型在“油漆工”、“安全检查员”和“地面铺砖”三个建筑角色上进行了评估。", "result": "四智能体团队在大多数指标上优于最先进的GPT-4o，且成本效益提高十倍。三智能体和四智能体团队展示了更强的泛化能力。研究还讨论了智能体行为如何影响输出。", "conclusion": "基于LLMs和VLMs的多智能体系统能够有效提升建筑机器人任务规划的适应性和泛化能力，并且在成本效益方面具有优势。本研究加深了对AI团队行为的理解，并为未来在建筑等非结构化环境中的研究奠定了基础。"}}
{"id": "2601.12067", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12067", "abs": "https://arxiv.org/abs/2601.12067", "authors": ["VSS Tejaswi Abburi", "Ananya Singhal", "Saurabh J. Shigwan", "Nitin Kumar"], "title": "ARMARecon: An ARMA Convolutional Filter based Graph Neural Network for Neurodegenerative Dementias Classification", "comment": "Accepted at IEEE International Symposium on Biomedical Imaging (ISBI) 2026", "summary": "Early detection of neurodegenerative diseases such as Alzheimer's Disease (AD) and Frontotemporal Dementia (FTD) is essential for reducing the risk of progression to severe disease stages. As AD and FTD propagate along white-matter regions in a global, graph-dependent manner, graph-based neural networks are well suited to capture these patterns. Hence, we introduce ARMARecon, a unified graph learning framework that integrates Autoregressive Moving Average (ARMA) graph filtering with a reconstruction-driven objective to enhance feature representation and improve classification accuracy. ARMARecon effectively models both local and global connectivity by leveraging 20-bin Fractional Anisotropy (FA) histogram features extracted from white-matter regions, while mitigating over-smoothing. Overall, ARMARecon achieves superior performance compared to state-of-the-art methods on the multi-site dMRI datasets ADNI and NIFD.", "AI": {"tldr": "本文提出了一种名为ARMARecon的图学习框架，通过整合ARMA图滤波和重建目标，利用FA直方图特征来提高阿尔茨海默病（AD）和额颞叶痴呆（FTD）的早期检测和分类准确性。", "motivation": "早期检测阿尔茨海默病（AD）和额颞叶痴呆（FTD）对于减缓疾病进展至关重要。由于AD和FTD沿白质区域传播的全局、图依赖性传播模式，因此需要能够捕捉这些模式的方法。", "method": "ARMARecon框架结合了自回归移动平均（ARMA）图滤波和受重建驱动的目标。它利用从白质区域提取的20个bin的各向异性分数（FA）直方图特征来模拟局部和全局连通性，并缓解过平滑问题。", "result": "ARMARecon在ADNI和NIFD的多中心dMRI数据集上取得了优于现有最先进方法的性能。", "conclusion": "ARMARecon是一个统一的图学习框架，能够有效建模局部和全局连接性，减少过平滑，并在AD和FTD的早期检测中表现出优越的分类性能。"}}
{"id": "2601.12430", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12430", "abs": "https://arxiv.org/abs/2601.12430", "authors": ["Tsan Tsai Chan", "Varsha Suresh", "Anisha Saha", "Michael Hahn", "Vera Demberg"], "title": "System-Mediated Attention Imbalances Make Vision-Language Models Say Yes", "comment": "Under review", "summary": "Vision-language model (VLM) hallucination is commonly linked to imbalanced allocation of attention across input modalities: system, image and text. However, existing mitigation strategies tend towards an image-centric interpretation of these imbalances, often prioritising increased image attention while giving less consideration to the roles of the other modalities. In this study, we evaluate a more holistic, system-mediated account, which attributes these imbalances to functionally redundant system weights that reduce attention to image and textual inputs. We show that this framework offers a useful empirical perspective on the yes-bias, a common form of hallucination in which VLMs indiscriminately respond 'yes'. Causally redistributing attention from the system modality to image and textual inputs substantially suppresses this bias, often outperforming existing approaches. We further present evidence suggesting that system-mediated attention imbalances contribute to the yes-bias by encouraging a default reliance on coarse input representations, which are effective for some tasks but ill-suited to others. Taken together, these findings firmly establish system attention as a key factor in VLM hallucination and highlight its potential as a lever for mitigation.", "AI": {"tldr": "本研究提出了一种新的视角来理解和解决视觉-语言模型（VLM）的幻觉问题，认为问题根源于模型内部“系统”模态的权重分配不当，而非仅是图像或文本模态的关注度失衡。通过调整系统模态的注意力，可以有效减少“yes-bias”等幻觉现象。", "motivation": "现有的VLM幻觉缓解策略多侧重于图像模态，忽略了系统内部模态（如系统权重）对注意力分配的影响。研究者希望探索一种更全面的系统性视角，以更有效地解决VLM幻觉问题，特别是“yes-bias”。", "method": "该研究评估了一种将幻觉归因于功能冗余的系统权重的模型框架。通过因果性地将注意力从系统模态重新分配到图像和文本模态，并与现有方法进行对比评估。研究还分析了系统模态注意力失衡如何导致依赖粗粒度输入表示。", "result": "研究表明，将注意力从系统模态重新分配到图像和文本模态，能够显著抑制VLM的“yes-bias”。这种方法在减少幻觉方面，效果常常优于现有策略。研究还发现，系统模态注意力失衡会促使模型依赖粗粒度的输入表示，这不利于某些任务。", "conclusion": "系统模态的注意力分配是VLM幻觉的关键因素。通过调整系统注意力，可以作为一种有效的缓解VLM幻觉（尤其是yes-bias）的手段，并可能改善模型在不同任务上的表现。"}}
{"id": "2601.14104", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14104", "abs": "https://arxiv.org/abs/2601.14104", "authors": ["Tairan Huang", "Qingqing Ye", "Yulin Jin", "Jiawei Lian", "Yi Wang", "Haibo Hu"], "title": "Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning", "comment": null, "summary": "Backdoor attacks embed hidden malicious behaviors in reinforcement learning (RL) policies and activate them using triggers at test time. Most existing attacks are validated only in simulation, while their effectiveness in real-world robotic systems remains unclear. In physical deployment, safety-constrained control pipelines such as velocity limiting, action smoothing, and collision avoidance suppress abnormal actions, causing strong attenuation of conventional backdoor attacks. We study this previously overlooked problem and propose a diffusion-guided backdoor attack framework (DGBA) for real-world RL. We design small printable visual patch triggers placed on the floor and generate them using a conditional diffusion model that produces diverse patch appearances under real-world visual variations. We treat the robot control stack as a black-box system. We further introduce an advantage-based poisoning strategy that injects triggers only at decision-critical training states. We evaluate our method on a TurtleBot3 mobile robot and demonstrate reliable activation of targeted attacks while preserving normal task performance. Demo videos and code are available in the supplementary material.", "AI": {"tldr": "提出了一种针对真实世界机器人系统的基于扩散模型的后门攻击框架（DGBA），该框架能够绕过安全约束，并通过视觉触发器实现恶意行为的激活。", "motivation": "现有后门攻击多在模拟环境中验证，在真实机器人系统中的有效性存疑，因为安全约束会削弱攻击效果。", "method": "设计了可打印的视觉触发器（贴片），使用条件扩散模型生成，能够适应真实世界的视觉变化。将机器人控制堆栈视为黑盒，并采用基于优势的投毒策略，仅在关键训练状态下注入触发器。", "result": "在TurtleBot3移动机器人上成功验证了DGBA的有效性，能够在保持正常任务性能的同时，可靠地激活目标攻击。", "conclusion": "DGBA框架成功解决了真实世界机器人系统中后门攻击的挑战，证明了在实际部署中，后门攻击可以被设计为有效且隐蔽的。"}}
{"id": "2601.12912", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12912", "abs": "https://arxiv.org/abs/2601.12912", "authors": ["Andreas Brännström", "Juan Carlos Nieves"], "title": "Human Emotion Verification by Action Languages via Answer Set Programming", "comment": "Under consideration in Theory and Practice of Logic Programming (TPLP)", "summary": "In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).", "AI": {"tldr": "本文提出了一种名为C-MT（Mind Transition Language）的动作语言，它基于ASP和转换系统，用于模拟人类心理状态如何随可观察动作序列而演变，并引入了新的因果规则‘forbids to cause’来控制心理状态变化。", "motivation": "研究的动机是需要控制代理人的行为，并限制动作可能引发的不期望的心理副作用，以及需要对人类心理状态的动态演变进行可控推理。", "method": "本文首先在ASP和转换系统的基础上构建了C-MT语言，并将心理状态（如情绪）形式化为多维配置。然后，引入了新的因果规则‘forbids to cause’以及专门用于心理状态动态的表达式。这些规则被转化为转换约束和不变性属性，并使用转换系统通过“轨迹”进行评估。", "result": "该框架能够对人类心理状态的动态演变进行可控推理，并支持通过分析遵循不同心理学原理的轨迹来比较不同的变化动态。已将该语言应用于设计情绪验证模型。", "conclusion": "C-MT语言提供了一种基于逻辑推理的方法来形式化和分析人类心理状态的动态演变，能够实现对代理人行为及其心理影响的有效控制和验证。"}}
{"id": "2601.12465", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12465", "abs": "https://arxiv.org/abs/2601.12465", "authors": ["Miao Peng", "Weizhou Shen", "Nuo Chen", "Chenliang Li", "Ming Yan", "Jia Li"], "title": "Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective in enhancing LLMs short-context reasoning, but its performance degrades in long-context scenarios that require both precise grounding and robust long-range reasoning. We identify the \"almost-there\" phenomenon in long-context reasoning, where trajectories are largely correct but fail at the final step, and attribute this failure to two factors: (1) the lack of high reasoning density in long-context QA data that push LLMs beyond mere grounding toward sophisticated multi-hop reasoning; and (2) the loss of valuable learning signals during long-context RL training due to the indiscriminate penalization of partially correct trajectories with incorrect outcomes. To overcome this bottleneck, we propose DeepReasonQA, a KG-driven synthesis framework that controllably constructs high-difficulty, multi-hop long-context QA pairs with inherent reasoning chains. Building on this, we introduce Long-context Process Advantage Shaping (LongPAS), a simple yet effective method that performs fine-grained credit assignment by evaluating reasoning steps along Validity and Relevance dimensions, which captures critical learning signals from \"almost-there\" trajectories. Experiments on three long-context reasoning benchmarks show that our approach substantially outperforms RLVR baselines and matches frontier LLMs while using far fewer parameters. Further analysis confirms the effectiveness of our methods in strengthening long-context reasoning while maintaining stable RL training.", "AI": {"tldr": "提出了一种名为DeepReasonQA的框架，用于生成具有挑战性的长上下文问答对，并结合LongPAS方法，通过细粒度的信用分配来解决长上下文强化学习中的“几乎成功”问题，从而显著提升LLM在长上下文推理能力。", "motivation": "现有的RLVR方法在长上下文推理中表现不佳，容易出现“几乎成功”现象（即推理过程大部分正确但最终结果错误），这归因于长上下文QA数据缺乏足够的推理密度以及RL训练中对部分正确轨迹的惩罚过于严厉。", "method": "1. DeepReasonQA：一个由知识图谱驱动的合成框架，用于生成具有内在推理链的高难度、多跳长上下文QA对。2. LongPAS（Long-context Process Advantage Shaping）：一种评估推理步骤在“有效性”和“相关性”维度上的细粒度信用分配方法，以从“几乎成功”的轨迹中捕获有价值的学习信号。", "result": "在三个长上下文推理基准测试中，所提出的方法显著优于RLVR基线，并能与参数量远少于它们的先进LLM相媲美。同时，进一步的分析证实了该方法在增强长上下文推理能力和保持RL训练稳定性方面的有效性。", "conclusion": "DeepReasonQA和LongPAS的结合能够有效克服长上下文强化学习中的瓶颈，显著提升LLM的长上下文推理能力，并能稳定进行RL训练。"}}
{"id": "2601.12913", "categories": ["cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.12913", "abs": "https://arxiv.org/abs/2601.12913", "authors": ["Pietro Barbiero", "Mateo Espinosa Zarlenga", "Francesco Giannini", "Alberto Termine", "Filippo Bonchi", "Mateja Jamnik", "Giuseppe Marra"], "title": "Actionable Interpretability Must Be Defined in Terms of Symmetries", "comment": null, "summary": "This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.", "AI": {"tldr": "本文认为人工智能中的可解释性研究存在根本性问题，因为现有的定义缺乏可操作性。作者提出，可解释性定义必须基于“对称性”，并认为四种对称性足以确定可解释模型的性质，并推导出统一的可解释推理框架。", "motivation": "现有的人工智能可解释性研究定义缺乏可操作性，无法从中推导出具体的建模和推理规则。", "method": "提出将可解释性定义为基于“对称性”，并假设四种对称性足以：(i) 激励核心可解释性属性，(ii) 表征可解释模型的类别，(iii) 将可解释推理（如对齐、干预和反事实）统一为一种贝叶斯逆过程。", "result": "提出了一个基于对称性的可解释性新框架，并为可解释推理（如对齐、干预和反事实）提供了一种统一的贝叶斯逆公式。", "conclusion": "作者认为，将可解释性定义为基于对称性，是解决当前研究中缺乏可操作性问题的关键，并能统一和深化可解释性研究。"}}
{"id": "2601.12471", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12471", "abs": "https://arxiv.org/abs/2601.12471", "authors": ["Sravanthi Machcha", "Sushrita Yerra", "Sahil Gupta", "Aishwarya Sahoo", "Sharmin Sultana", "Hong Yu", "Zonghai Yao"], "title": "Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty", "comment": "Equal contribution for the first two authors; To appear in proceedings of the Main Conference of the European Chapter of the Association for Computational Linguistics (EACL) 2026", "summary": "Current evaluation of large language models (LLMs) overwhelmingly prioritizes accuracy; however, in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. We introduce MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA) -- a discrete-choice setting that generalizes to agentic action selection -- integrating conformal prediction, adversarial question perturbations, and explicit abstention options. Our systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art, high-accuracy models often fail to abstain with uncertain. Notably, providing explicit abstention options consistently increases model uncertainty and safer abstention, far more than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the central role of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.", "AI": {"tldr": "该研究提出了一个名为MedAbstain的基准和评估协议，用于评估大型语言模型（LLM）在医学多项选择问答中的弃权能力。研究发现，即使是最先进的模型也常常在不确定时未能弃权，而提供明确的弃权选项比输入扰动更能提高模型的安全弃权率，模型规模或提示工程的改进效果有限。", "motivation": "当前对大型语言模型的评估主要关注准确性，但在现实世界和安全关键应用中，模型在不确定时能够弃权的能力对于可信赖的部署同样至关重要。", "method": "研究引入了MedAbstain，一个包含一致性预测（conformal prediction）、对抗性问题扰动（adversarial question perturbations）和明确弃权选项的统一基准和评估协议，用于医学多项选择问答。系统地评估了开源和闭源的大型语言模型。", "result": "即使是先进的高准确性模型，在不确定时也常常未能弃权。提供明确的弃权选项能够一致地提高模型的不确定性和安全弃权率，效果远超输入扰动。增加模型规模或使用高级提示技巧带来的改进很小。", "conclusion": "研究结果强调了弃权机制在可信赖的LLM部署中的核心作用，并为提高高风险应用中的安全性提供了实用指导。"}}
{"id": "2601.14128", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.14128", "abs": "https://arxiv.org/abs/2601.14128", "authors": ["Shoujie Li", "Changqing Guo", "Junhao Gong", "Chenxin Liang", "Wenhua Ding", "Wenbo Ding"], "title": "SandWorm: Event-based Visuotactile Perception with Active Vibration for Screw-Actuated Robot in Granular Media", "comment": "Accepted by IEEE Transactions on Robotics", "summary": "Perception in granular media remains challenging due to unpredictable particle dynamics. To address this challenge, we present SandWorm, a biomimetic screw-actuated robot augmented by peristaltic motion to enhance locomotion, and SWTac, a novel event-based visuotactile sensor with an actively vibrated elastomer. The event camera is mechanically decoupled from vibrations by a spring isolation mechanism, enabling high-quality tactile imaging of both dynamic and stationary objects. For algorithm design, we propose an IMU-guided temporal filter to enhance imaging consistency, improving MSNR by 24%. Moreover, we systematically optimize SWTac with vibration parameters, event camera settings and elastomer properties. Motivated by asymmetric edge features, we also implement contact surface estimation by U-Net. Experimental validation demonstrates SWTac's 0.2 mm texture resolution, 98% stone classification accuracy, and 0.15 N force estimation error, while SandWorm demonstrates versatile locomotion (up to 12.5 mm/s) in challenging terrains, successfully executes pipeline dredging and subsurface exploration in complex granular media (observed 90% success rate). Field experiments further confirm the system's practical performance.", "AI": {"tldr": "本文提出了一种仿生蠕动螺杆驱动机器人SandWorm和一种事件基视觉触觉传感器SWTac，用于解决颗粒介质中的感知和运动难题。SWTac通过事件相机和主动振动弹性体实现高分辨率触觉成像，并采用IMU引导的时域滤波器和U-Net进行表面估计。SandWorm展示了在复杂颗粒介质中的高效运动和任务执行能力。", "motivation": "颗粒介质中不可预测的粒子动力学给感知和运动带来了挑战，需要新的机器人系统和传感器来克服。", "method": "开发了仿生螺杆驱动机器人SandWorm，结合了蠕动运动。设计了事件基视觉触觉传感器SWTac，包含解耦的事件相机、主动振动的弹性体和IMU引导的时域滤波器。利用U-Net实现接触表面估计。对SWTac的参数进行了系统优化。", "result": "SWTac实现了0.2毫米的纹理分辨率、98%的石材分类准确率和0.15牛顿的力估计误差。SandWorm的运动速度最高可达12.5毫米/秒，在复杂颗粒介质中成功执行了管道疏浚和地下探测任务（成功率90%）。", "conclusion": "SandWorm和SWTac系统在颗粒介质中展示了强大的感知和运动能力，能够应对挑战性的地形和任务，并经过现场实验验证了其实用性。"}}
{"id": "2601.12076", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12076", "abs": "https://arxiv.org/abs/2601.12076", "authors": ["H. Jiang", "Y. Sun", "Z. Dong", "T. Liu", "Y. Gu"], "title": "CroBIM-V: Memory-Quality Controlled Remote Sensing Referring Video Object Segmentation", "comment": null, "summary": "Remote sensing video referring object segmentation (RS-RVOS) is challenged by weak target saliency and severe visual information truncation in dynamic scenes, making it extremely difficult to maintain discriminative target representations during segmentation. Moreover, progress in this field is hindered by the absence of large-scale dedicated benchmarks, while existing models are often affected by biased initial memory construction that impairs accurate instance localization in complex scenarios, as well as indiscriminate memory accumulation that encodes noise from occlusions or misclassifications, leading to persistent error propagation. This paper advances RS-RVOS research through dual contributions in data and methodology. First, we construct RS-RVOS Bench, the first large-scale benchmark comprising 111 video sequences, about 25,000 frames, and 213,000 temporal referring annotations. Unlike common RVOS benchmarks where many expressions are written with access to the full video context, our dataset adopts a strict causality-aware annotation strategy in which linguistic references are generated solely from the target state in the initial frame. Second, we propose a memory-quality-aware online referring segmentation framework, termed Memory Quality Control with Segment Anything Model (MQC-SAM). MQC-SAM introduces a temporal motion consistency module for initial memory calibration, leveraging short-term motion trajectory priors to correct structural deviations and establish accurate memory anchoring. Furthermore, it incorporates a decoupled attention-based memory integration mechanism with dynamic quality assessment, selectively updating high-confidence semantic features while filtering unreliable information, thereby effectively preventing error accumulation and propagation. Extensive experiments on RS-RVOS Bench demonstrate that MQC-SAM achieves state-of-the-art performance.", "AI": {"tldr": "本文提出了首个大规模遥感视频指代目标分割（RS-RVOS）数据集RS-RVOS Bench，并引入了一种名为MQC-SAM的内存质量控制框架，通过运动一致性校准和解耦注意力机制来解决RS-RVOS中的目标显著性弱、信息截断和内存偏见等问题，并在新数据集上取得了最先进的性能。", "motivation": "现有遥感视频指代目标分割（RS-RVOS）任务面临目标显著性弱、信息截断、缺乏大规模数据集以及模型存在偏置的初始内存构建和不受区分的内存累积等问题，导致实例定位不准确和错误传播。因此，需要新的数据集和更有效的方法来解决这些挑战。", "method": "1. 构建了第一个大规模RS-RVOS数据集RS-RVOS Bench，包含111个视频序列、约25,000帧和213,000个时间指代标注，并采用了严格的因果感知标注策略。2. 提出了一种内存质量感知在线指代分割框架MQC-SAM，该框架包含：a) 时间运动一致性模块，用于初始内存校准，利用短期运动轨迹修正结构偏差并进行准确内存锚定；b) 解耦注意力机制的内存集成，具有动态质量评估，选择性地更新高置信度的语义特征并过滤不可靠信息，从而有效防止错误累积和传播。", "result": "在RS-RVOS Bench数据集上的大量实验表明，MQC-SAM取得了最先进的性能。", "conclusion": "本文通过提供大规模数据集RS-RVOS Bench和创新的MQC-SAM框架，显著推动了RS-RVOS领域的研究进展，有效解决了现有方法在处理弱显著性、信息截断、初始内存偏见和内存累积等方面的挑战，并在新数据集上验证了其优越性。"}}
{"id": "2601.13060", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13060", "abs": "https://arxiv.org/abs/2601.13060", "authors": ["Zecheng Li", "Zhihui Cao", "Wenke Huang", "Yudong Zhang", "Keying Qi", "Rui Wang", "Zeyu Zheng", "Jian Zhao", "Hao Zhu", "Hengxin Wu", "Yuran Wang", "Guitao Fan", "Guokun Wu", "Yicong Liu", "Zhilin Gao", "Haikun Xu", "He Yang", "Minqi Xiang", "Xingyu Liu", "Zuojian Wang"], "title": "MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux", "comment": null, "summary": "Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.", "AI": {"tldr": "本文提出了一种名为 MagicGUI-RMS 的多智能体奖励模型系统，用于自动评估 GUI 智能体的行为轨迹，并生成高质量的训练数据，以实现持续改进。该系统通过结合领域特定奖励模型和通用奖励模型，并采用自动化的数据构建和再反馈机制，显著提高了任务的准确性和鲁棒性。", "motivation": "现有 GUI 智能体评估方法存在可扩展性差、适应性受限的问题，难以满足大规模训练和动态环境下的持续改进需求。", "method": "MagicGUI-RMS 集成了领域特定奖励模型（DS-RM）和通用奖励模型（GP-RM），通过结构化的数据构建管道自动生成奖励数据集，并利用数据再反馈机制实现自我进化学习。该系统能够识别错误动作，提出改进建议，并持续优化智能体行为。", "result": "实验结果表明，MagicGUI-RMS 在任务准确性和行为鲁棒性方面取得了显著提升。", "conclusion": "MagicGUI-RMS 提供了一个原则性强且有效的基础，能够通过基于奖励的适应性驱动，构建能够自我改进的 GUI 智能体。"}}
{"id": "2601.12473", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12473", "abs": "https://arxiv.org/abs/2601.12473", "authors": ["Renlong Jie", "Chen Chu", "Zhen Wang"], "title": "Capability-Aware Early-Stage Research Idea Evaluation", "comment": null, "summary": "Predicting the outcomes of research ideas at their conceptual stage (i.e. before significant resources are committed) holds great potential for optimizing scientific resource allocation and research planning. While existing methods rely heavily on finished manuscripts or peer reviews, we propose a novel capability-aware framework that predicts paper acceptance and ratings using only author information and research ideas, without requiring full text or experimental results. Our approach integrates author information, (inferred) capability presentation, and research ideas through a three-way transformer architecture with flexible fusion mechanisms. We also introduce a two-stage architecture for learning the capability representation given the author information and idea. Experiments show that our method significantly outperform the single-way models by finetuning bert-base and bert-large, and the capability predicting significantly increase the predictive accuracy of the final model. The proposed method can be applied in both early-stage research outcome prediction and scientific resource allocation.", "AI": {"tldr": "本研究提出了一个名为“能力感知框架”的新方法，仅利用作者信息和研究理念来预测论文被接受的可能性和评分，无需全文或实验结果，并在实验中表现优于现有方法。", "motivation": "现有研究方法依赖于完整的论文或同行评审，而本研究旨在解决在研究概念阶段，即投入大量资源之前，预测研究成果的可行性，以优化科研资源分配和规划。", "method": "采用三向 Transformer 架构，结合作者信息、（推断出的）能力展示和研究理念，并使用灵活的融合机制。引入一个两阶段架构来学习基于作者信息和研究理念的能力表示。", "result": "实验结果表明，该方法显著优于单向模型（在 fine-tuning bert-base 和 bert-large 的基础上），且能力预测显著提高了最终模型的预测准确性。", "conclusion": "提出的能力感知框架能够有效预测早期研究成果，并可应用于科研资源分配，为研究规划和资源优化提供了新的解决方案。"}}
{"id": "2601.14133", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14133", "abs": "https://arxiv.org/abs/2601.14133", "authors": ["Bin Yu", "Shijie Lian", "Xiaopeng Lin", "Yuliang Wei", "Zhaolong Shen", "Changti Wu", "Yuzhuo Miao", "Xinming Wang", "Bailing Wang", "Cong Huang", "Kai Chen"], "title": "TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers", "comment": "GitHub: https://github.com/ZGC-EmbodyAI/TwinBrainVLA", "summary": "Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to \"catastrophic forgetting\" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen \"Left Brain\", which retains robust general visual reasoning, with a trainable \"Right Brain\", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity.", "AI": {"tldr": "提出了一种名为TwinBrainVLA的新型架构，通过结合一个通用的“左脑”视觉语言模型和一个专门化的“右脑”来解决现有VLA模型在通用语义理解和低级运动技能学习之间出现的冲突，从而在不牺牲通用能力的情况下提高机器人操作性能。", "motivation": "标准的VLA模型在对通用视觉语言模型进行微调以用于机器人控制时，会面临通用语义理解能力下降（灾难性遗忘）的问题，难以同时掌握高层语义和低层运动技能。", "method": "TwinBrainVLA架构包含一个冻结的“左脑”通用VLM，用于保留通用视觉推理能力；一个可训练的“右脑”专家VLM，专注于本体感知以进行机器人控制。通过“非对称Transformer混合”（AsyMoT）机制，右脑可以动态查询左脑的语义知识，并与本体感觉信息融合，为动作专家提供丰富的条件信息，从而生成精确的连续控制指令。", "result": "在SimplerEnv和RoboCasa基准测试中，TwinBrainVLA在机器人操作任务上取得了优于最先进方法的性能，并且有效地保留了预训练VLM的全面视觉理解能力。", "conclusion": "TwinBrainVLA是一种有效的解决方案，可以解决通用VLA模型在语义理解和运动控制之间的权衡问题，为构建兼具高层语义理解和低层物理灵巧性的通用机器人提供了有前景的方向。"}}
{"id": "2601.12079", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12079", "abs": "https://arxiv.org/abs/2601.12079", "authors": ["Jing Zhang", "Bingjie Fan", "Jixiang Zhu", "Zhe Wang"], "title": "EmoLat: Text-driven Image Sentiment Transfer via Emotion Latent Space", "comment": "10 pages, 5 figures", "summary": "We propose EmoLat, a novel emotion latent space that enables fine-grained, text-driven image sentiment transfer by modeling cross-modal correlations between textual semantics and visual emotion features. Within EmoLat, an emotion semantic graph is constructed to capture the relational structure among emotions, objects, and visual attributes. To enhance the discriminability and transferability of emotion representations, we employ adversarial regularization, aligning the latent emotion distributions across modalities. Building upon EmoLat, a cross-modal sentiment transfer framework is proposed to manipulate image sentiment via joint embedding of text and EmoLat features. The network is optimized using a multi-objective loss incorporating semantic consistency, emotion alignment, and adversarial regularization. To support effective modeling, we construct EmoSpace Set, a large-scale benchmark dataset comprising images with dense annotations on emotions, object semantics, and visual attributes. Extensive experiments on EmoSpace Set demonstrate that our approach significantly outperforms existing state-of-the-art methods in both quantitative metrics and qualitative transfer fidelity, establishing a new paradigm for controllable image sentiment editing guided by textual input. The EmoSpace Set and all the code are available at http://github.com/JingVIPLab/EmoLat.", "AI": {"tldr": "本文提出了一种名为EmoLat的新型情绪潜在空间，通过建模文本语义与视觉情绪特征间的跨模态关联，实现细粒度的文本驱动图像情感迁移。该方法通过构建情绪语义图、采用对抗性正则化来增强情绪表示的可辨识性和可迁移性，并提出了一个跨模态情感迁移框架。", "motivation": "现有方法在细粒度的文本驱动图像情感迁移方面存在不足，难以实现高质量的情感编辑。本文旨在构建一个能够捕捉文本与视觉情绪特征间复杂关联的新型潜在空间，以实现更精确和可控的图像情感迁移。", "method": "1. 构建情绪语义图，捕捉情绪、对象和视觉属性间的关系。 2. 引入对抗性正则化，对齐跨模态的情绪潜在分布，增强表示的可辨识性和可迁移性。 3. 提出一个跨模态情感迁移框架，通过联合嵌入文本和EmoLat特征来操控图像情感。 4. 设计多目标损失函数，包括语义一致性、情感对齐和对抗性正则化。 5. 构建了一个大规模基准数据集EmoSpace Set，包含详细的情绪、对象和视觉属性标注。", "result": "在EmoSpace Set数据集上的广泛实验表明，本文提出的EmoLat方法在定量指标和定性迁移保真度上显著优于现有的最先进方法，在文本引导的图像情感编辑领域树立了新的范例。", "conclusion": "EmoLat是一个新颖的情绪潜在空间，能够实现细粒度的文本驱动图像情感迁移。通过引入情绪语义图和对抗性正则化，并构建大规模数据集，该方法在图像情感迁移任务上取得了显著的性能提升，为可控的图像情感编辑提供了新的解决方案。"}}
{"id": "2601.12080", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12080", "abs": "https://arxiv.org/abs/2601.12080", "authors": ["Haipeng Zhou", "Zhaohu Xing", "Hongqiu Wang", "Jun Ma", "Ping Li", "Lei Zhu"], "title": "Toward Real-World High-Precision Image Matting and Segmentation", "comment": "Accepted by AAAI2026, Poster", "summary": "High-precision scene parsing tasks, including image matting and dichotomous segmentation, aim to accurately predict masks with extremely fine details (such as hair). Most existing methods focus on salient, single foreground objects. While interactive methods allow for target adjustment, their class-agnostic design restricts generalization across different categories. Furthermore, the scarcity of high-quality annotation has led to a reliance on inharmonious synthetic data, resulting in poor generalization to real-world scenarios. To this end, we propose a Foreground Consistent Learning model, dubbed as FCLM, to address the aforementioned issues. Specifically, we first introduce a Depth-Aware Distillation strategy where we transfer the depth-related knowledge for better foreground representation. Considering the data dilemma, we term the processing of synthetic data as domain adaptation problem where we propose a domain-invariant learning strategy to focus on foreground learning. To support interactive prediction, we contribute an Object-Oriented Decoder that can receive both visual and language prompts to predict the referring target. Experimental results show that our method quantitatively and qualitatively outperforms SOTA methods.", "AI": {"tldr": "本文提出了一个名为FCLM的前景一致性学习模型，用于解决高精度场景解析任务（如图像抠图和二值分割）中，现有方法对单一显著前景对象过度关注、泛化能力受限以及合成数据与真实数据不协调的问题。FCLM通过深度感知蒸馏、领域不变学习和面向对象的解码器来提升前景提取的准确性和泛化能力。", "motivation": "现有高精度场景解析方法主要关注单一显著前景，泛化能力受限。交互式方法虽可调整目标，但类别无关设计限制了其跨类别应用。同时，高质量标注数据稀缺导致合成数据与真实数据不协调，影响了模型在真实场景下的泛化能力。", "method": "1. 深度感知蒸馏（Depth-Aware Distillation）：转移深度相关知识以提升前景表示。2. 领域不变学习（Domain-Invariant Learning）：将合成数据处理视为领域自适应问题，专注于前景学习。3. 面向对象的解码器（Object-Oriented Decoder）：支持视觉和语言提示，用于交互式目标预测。", "result": "FCLM在定量和定性评估上均优于现有最先进的方法。", "conclusion": "FCLM模型成功解决了高精度场景解析任务中前景提取、数据稀缺和交互式预测的挑战，通过深度感知蒸馏、领域不变学习和面向对象的解码器，显著提升了模型的准确性和泛化能力。"}}
{"id": "2601.12358", "categories": ["cs.CV", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12358", "abs": "https://arxiv.org/abs/2601.12358", "authors": ["Omar Y. Goba", "Ahmed Y. Gado", "Catherine M. Elias", "Ahmed Hussein"], "title": "From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles", "comment": null, "summary": "Autonomous vehicles (AVs) require adaptive behavior planners to navigate unpredictable, real-world environments safely. Traditional behavior trees (BTs) offer structured decision logic but are inherently static and demand labor-intensive manual tuning, limiting their applicability at SAE Level 5 autonomy. This paper presents an agentic framework that leverages large language models (LLMs) and multi-modal vision models (LVMs) to generate and adapt BTs on the fly. A specialized Descriptor agent applies chain-of-symbols prompting to assess scene criticality, a Planner agent constructs high-level sub-goals via in-context learning, and a Generator agent synthesizes executable BT sub-trees in XML format. Integrated into a CARLA+Nav2 simulation, our system triggers only upon baseline BT failure, demonstrating successful navigation around unexpected obstacles (e.g., street blockage) with no human intervention. Compared to a static BT baseline, this approach is a proof-of-concept that extends to diverse driving scenarios.", "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）和多模态视觉模型（LVM）的自适应行为树（BT）框架，用于自动驾驶车辆（AVs）的导航。该框架能够动态生成和调整BT，以应对不可预测的真实世界环境。", "motivation": "传统的行为树（BT）在应对SAE Level 5自动驾驶中遇到的不可预测和复杂环境时，存在固有的静态性和需要大量人工调优的局限性。", "method": "该框架包含三个代理：Descriptor代理负责评估场景的关键性；Planner代理通过上下文学习构建高级子目标；Generator代理则生成可执行的XML格式BT子树。该系统集成在CARLA+Nav2模拟环境中，仅在基线BT失败时触发。", "result": "该系统成功实现了在未预见到的障碍物（如道路封锁）周围的导航，且无需人工干预。与静态BT相比，该方法在多样化的驾驶场景中展示了其有效性。", "conclusion": "该框架为自动驾驶车辆提供了一种动态生成和自适应调整行为树的方法，解决了传统BT在复杂和不可预测环境中应用的不足，是一个有前景的解决方案。"}}
{"id": "2601.13122", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13122", "abs": "https://arxiv.org/abs/2601.13122", "authors": ["Gourab K Patro", "Himanshi Agrawal", "Himanshu Gharat", "Supriya Panigrahi", "Nim Sherpa", "Vishal Vaddina", "Dagnachew Birru"], "title": "Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward", "comment": null, "summary": "Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.", "AI": {"tldr": "本文探讨了通用人工智能（如大型语言模型）在带来广泛应用的同时，也带来了幻觉、毒性、刻板印象等风险。作者认为，这些风险源于通用AI输出的高度自由度（DoFo），与传统任务特定AI的低DoFo形成对比。为应对这些挑战，作者提出了C2V2（控制、一致性、价值、真实性）原则，并建议通过形式化RAI需求和系统化设计来构建负责任的通用AI。", "motivation": "现代通用AI系统因其多功能性而广受欢迎，但其输出中存在的幻觉、毒性和刻板印象等风险使其不可靠，促使研究者需要重新思考负责任AI（RAI）的方法。", "method": "文章通过考察八项RAI原则（公平性、隐私、可解释性、鲁棒性、安全性、真实性、治理和可持续性），对比了通用AI与传统任务特定AI在RAI方面的风险差异。作者提出了“输出自由度（DoFo）”的概念来解释这些差异，并基于此推导出了C2V2（控制、一致性、价值、真实性）原则。", "result": "研究表明，通用AI的输出自由度（DoFo）远高于传统任务特定AI，导致其在RAI方面面临更严峻的挑战。文章提出了C2V2原则作为未来通用AI满足RAI需求的指导方针，并分析了现有AI对齐、检索增强生成等技术在满足C2V2原则方面的表现。", "conclusion": "为了实现负责任的通用AI，需要形式化建模应用或领域相关的RAI需求，并以C2V2维度为指导，通过系统设计和技术组合来满足这些需求。"}}
{"id": "2601.12505", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12505", "abs": "https://arxiv.org/abs/2601.12505", "authors": ["Ashish Raj Shekhar", "Shiven Agarwal", "Priyanuj Bordoloi", "Yash Shah", "Tejas Anvekar", "Vivek Gupta"], "title": "DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) can directly consume exam documents, threatening conventional assessments and academic integrity. We present DoPE (Decoy-Oriented Perturbation Encapsulation), a document-layer defense framework that embeds semantic decoys into PDF/HTML assessments to exploit render-parse discrepancies in MLLM pipelines. By instrumenting exams at authoring time, DoPE provides model-agnostic prevention (stop or confound automated solving) and detection (flag blind AI reliance) without relying on conventional one-shot classifiers. We formalize prevention and detection tasks, and introduce FewSoRT-Q, an LLM-guided pipeline that generates question-level semantic decoys and FewSoRT-D to encapsulate them into watermarked documents. We evaluate on Integrity-Bench, a novel benchmark of 1826 exams (PDF+HTML) derived from public QA datasets and OpenCourseWare. Against black-box MLLMs from OpenAI and Anthropic, DoPE yields strong empirical gains: a 91.4% detection rate at an 8.7% false-positive rate using an LLM-as-Judge verifier, and prevents successful completion or induces decoy-aligned failures in 96.3% of attempts. We release Integrity-Bench, our toolkit, and evaluation code to enable reproducible study of document-layer defenses for academic integrity.", "AI": {"tldr": "提出了一种名为DoPE的文档层防御框架，通过在PDF/HTML考试中嵌入语义诱饵来利用多模态大语言模型（MLLMs）的渲染-解析差异，以阻止或混淆自动解题，并检测对AI的盲目依赖。", "motivation": "多模态大语言模型（MLLMs）能够直接处理考试文档，威胁到传统的评估方式和学术诚信。", "method": "DoPE框架通过作者化时间植入文档，在PDF/HTML考试中嵌入由FewSoRT-Q生成的问题级语义诱饵，并利用FewSoRT-D将其封装成水印文档。该方法利用MLLM管道的渲染-解析差异。", "result": "在Integrity-Bench基准上，针对OpenAI和Anthropic的黑盒MLLMs，DoPE实现了91.4%的检测率（8.7%的假阳性率），并成功阻止了96.3%的自动解题尝试或导致诱饵对齐的失败。", "conclusion": "DoPE是一种模型无关的文档层防御方法，能够有效地阻止或混淆MLLMs对考试的自动解答，并能检测出对AI的盲目依赖，无需依赖传统的单次分类器。研究者发布了相关基准、工具包和评估代码，以促进对学术诚信的文档层防御研究。"}}
{"id": "2601.12082", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12082", "abs": "https://arxiv.org/abs/2601.12082", "authors": ["Tiffanie Godelaine", "Maxime Zanella", "Karim El Khoury", "Saïd Mahmoudi", "Benoît Macq", "Christophe De Vleeschouwer"], "title": "Conditional Random Fields for Interactive Refinement of Histopathological Predictions", "comment": null, "summary": "Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. In this context, histology foundation models have recently emerged. Among them, Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. We propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. We present HistoCRF, a CRF-based framework, with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. We consider three experiments: without annotations, with expert annotations, and with iterative human-in-the-loop annotations that progressively correct misclassified patches. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Moreover, integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF.", "AI": {"tldr": "本研究提出了HistoCRF框架，通过条件随机场（CRF）优化视觉-语言模型（VLMs）在组织病理图像分析中的零样本预测能力，无需额外训练，并取得了显著的准确率提升。", "motivation": "现有的视觉-语言模型（VLMs）在组织病理图像分析中提供零样本预测，但效果不尽完美，需要改进以提高其临床应用价值。", "method": "提出HistoCRF框架，将条件随机场（CRF）应用于组织病理学。该框架采用新颖的成对势函数定义，以促进标签多样性并利用专家注释。研究了三种实验设置：无注释、有专家注释和迭代式人机协同注释。", "result": "在五个不同器官和疾病的斑块级分类数据集上，HistoCRF在零样本预测的基础上，无注释时平均准确率提升16.0%，仅使用100条注释时提升27.5%。人机协同模式下，使用相同数量的注释，准确率进一步提升32.6%。", "conclusion": "HistoCRF是一种有效的CRF基础框架，能够显著提高VLMs在组织病理图像分析中的零样本预测性能，并且通过少量专家注释或人机协同，可以进一步大幅提升准确率。"}}
{"id": "2601.13186", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13186", "abs": "https://arxiv.org/abs/2601.13186", "authors": ["Diego Gosmar", "Deborah A. Dahl"], "title": "Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching", "comment": "33 pages, 19 figures", "summary": "Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.", "AI": {"tldr": "本文提出了一种名为 TIVS-O 的新评估框架，通过引入基于语义相似度的缓存和可观察性得分比率（OSR），来评估大型语言模型（LLM）在多代理环境中的提示注入漏洞。该框架在 HOPE 启发下的嵌套学习架构中，结合了代理管道和连续记忆系统，以实现安全响应、计算节省和环境可持续性。", "motivation": "提示注入是安全部署大型语言模型的主要障碍，尤其是在多代理环境中。现有的评估方法（如 TIVS）未能充分考虑防御有效性与透明度之间的相互作用。", "method": "研究人员扩展了 TIVS 评估框架，增加了基于语义相似度的缓存和第五个指标 OSR。他们在一个嵌套学习架构中构建了一个结合代理管道和连续记忆系统的系统，用于处理 301 个合成的提示注入提示，并使用五个关键绩效指标进行安全分析。OSR 用于量化代理暴露的安全相关推理的丰富性和清晰度。", "result": "该系统实现了零高风险泄露的安全响应，并通过语义缓存将 LLM 调用、延迟、能耗和碳排放量分别降低了 41.6%。五种 TIVS-O 配置揭示了缓解严格性与取证透明度之间的最佳权衡。研究还发现，可观察性感知的评估可以揭示多代理管道中的非单调效应。", "conclusion": "内存增强的代理可以在不修改底层模型权重的情况下，联合最大化安全性、实时性能、运营成本节省和环境可持续性。这为安全和绿色的 LLM 部署提供了一条生产就绪的路径，并强调了可观察性在 LLM 安全评估中的重要性。"}}
{"id": "2601.12373", "categories": ["cs.CV", "cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12373", "abs": "https://arxiv.org/abs/2601.12373", "authors": ["Amro Khaled", "Farah Khaled", "Omar Riad", "Catherine M. Elias"], "title": "CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology", "comment": null, "summary": "In this paper, the CD-TWINSAFE is introduced, a V2I-based digital twin for Autonomous Vehicles. The proposed architecture is composed of two stacks running simultaneously, an on-board driving stack that includes a stereo camera for scene understanding, and a digital twin stack that runs an Unreal Engine 5 replica of the scene viewed by the camera as well as returning safety alerts to the cockpit. The on-board stack is implemented on the vehicle side including 2 main autonomous modules; localization and perception. The position and orientation of the ego vehicle are obtained using on-board sensors. Furthermore, the perception module is responsible for processing 20-fps images from stereo camera and understands the scene through two complementary pipelines. The pipeline are working on object detection and feature extraction including object velocity, yaw and the safety metrics time-to-collision and time-headway. The collected data form the driving stack are sent to the infrastructure side through the ROS-enabled architecture in the form of custom ROS2 messages and sent over UDP links that ride a 4G modem for V2I communication. The environment is monitored via the digital twin through the shared messages which update the information of the spawned ego vehicle and detected objects based on the real-time localization and perception data. Several tests with different driving scenarios to confirm the validity and real-time response of the proposed architecture.", "AI": {"tldr": "本文提出了一种基于V2I的自动驾驶汽车数字孪生系统CD-TWINSAFE，该系统包含车载驾驶栈和数字孪生栈，能够实现场景理解、实时仿真和安全预警。", "motivation": "为了提高自动驾驶汽车的安全性和可靠性，开发一种能够实时感知环境、理解场景并提供安全预警的系统。", "method": "CD-TWINSAFE系统包含两个并行运行的栈：车载驾驶栈（负责感知和定位）和数字孪生栈（负责实时仿真和安全预警）。车载驾驶栈使用立体摄像头进行场景理解，通过对象检测和特征提取（包括速度、偏航角、碰撞时间等）来分析20fps的图像。采集到的数据通过ROS2架构和4G调制解调器以UDP形式发送到基础设施端，数字孪生通过这些消息更新车辆和检测到的对象信息。", "result": "通过在不同驾驶场景下的多项测试，验证了CD-TWINSAFE架构的有效性和实时响应能力。", "conclusion": "CD-TWINSAFE系统能够有效地实现V2I通信下的自动驾驶汽车数字孪生，并提供实时的场景理解和安全预警功能。"}}
{"id": "2601.12535", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12535", "abs": "https://arxiv.org/abs/2601.12535", "authors": ["Ahmed Attia", "Alham Fikri"], "title": "Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning", "comment": null, "summary": "Low-resource machine translation (MT) has gained increasing attention as parallel data from low-resource language communities is collected, but many potential methods for improving low-resource MT remain unexplored. We investigate a self-supervised reinforcement-learning-based fine-tuning for translation in low-resource settings using round-trip bootstrapping with the No Language Left Behind (NLLB) family of models. Our approach translates English into a target low-resource language and then back into English, using a combination of chrF++ and BLEU as the reward function on the reconstructed English sentences. Using the NLLB-MD dataset, we evaluate both the 600M and 1.3B parameter NLLB models and observe consistent improvements for the following languages: Central Aymara, Friulian, Wolof and Russian. Qualitative inspection of translation outputs indicates increased fluency and semantic fidelity. We argue that our method can further benefit from scale, enabling models to increasingly leverage their pretrained knowledge and continue self-improving.", "AI": {"tldr": "研究人员提出了一种基于自监督强化学习的微调方法，利用来回引导（round-trip bootstrapping）和NLLB模型来提升低资源机器翻译的性能，并在多个低资源语言上取得了改进。", "motivation": "低资源机器翻译（MT）的潜力巨大，但许多改进方法尚未被探索。研究人员希望找到一种有效的方法来提升低资源语言的翻译质量。", "method": "该方法利用NLLB模型系列，通过将英语翻译成目标低资源语言，然后再翻译回英语（来回引导）来进行微调。通过chrF++和BLEU作为奖励函数来评估回译的英语句子的质量，并据此进行强化学习。", "result": "在NLLB-MD数据集上，针对Central Aymara, Friulian, Wolof 和 Russian 四种语言，该方法在600M和1.3B参数的NLLB模型上均观察到了一致的翻译性能提升。定性分析表明翻译的流畅性和语义保真度有所提高。", "conclusion": "提出的自监督强化学习微调方法能够有效提升低资源机器翻译的性能，并且该方法可以通过模型规模的增大而获得进一步的益处，使模型能更好地利用预训练知识并持续自我改进。"}}
{"id": "2601.12090", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12090", "abs": "https://arxiv.org/abs/2601.12090", "authors": ["Matej Mok", "Lukáš Gajdošech", "Michal Mesároš", "Martin Madaras", "Viktor Kocur"], "title": "Detecting 3D Line Segments for 6DoF Pose Estimation with Limited Data", "comment": "8 pages", "summary": "The task of 6DoF object pose estimation is one of the fundamental problems of 3D vision with many practical applications such as industrial automation. Traditional deep learning approaches for this task often require extensive training data or CAD models, limiting their application in real-world industrial settings where data is scarce and object instances vary. We propose a novel method for 6DoF pose estimation focused specifically on bins used in industrial settings. We exploit the cuboid geometry of bins by first detecting intermediate 3D line segments corresponding to their top edges. Our approach extends the 2D line segment detection network LeTR to operate on structured point cloud data. The detected 3D line segments are then processed using a simple geometric procedure to robustly determine the bin's 6DoF pose. To evaluate our method, we extend an existing dataset with a newly collected and annotated dataset, which we make publicly available. We show that incorporating synthetic training data significantly improves pose estimation accuracy on real scans. Moreover, we show that our method significantly outperforms current state-of-the-art 6DoF pose estimation methods in terms of the pose accuracy (3 cm translation error, 8.2$^\\circ$ rotation error) while not requiring instance-specific CAD models during inference.", "AI": {"tldr": "提出了一种利用3D线段检测来估计工业场景中垃圾箱6DoF位姿的新方法，该方法不依赖于CAD模型，并在扩展的数据集上显著优于现有技术。", "motivation": "传统6DoF物体姿态估计方法需要大量数据或CAD模型，在工业环境中数据稀疏且物体多样的情况下应用受限。因此，需要一种适用于工业场景且不依赖CAD模型的方法。", "method": "首先检测与垃圾箱顶部边缘对应的中间3D线段，将2D线段检测网络LeTR扩展到结构化点云数据上。然后，利用简单的几何方法处理检测到的3D线段来鲁棒地确定垃圾箱的6DoF姿态。", "result": "通过扩展现有数据集并收集新数据集，证明了结合合成训练数据可以显著提高真实扫描数据的姿态估计精度。所提出的方法在姿态精度（3厘米平移误差，8.2度旋转误差）方面显著优于当前最先进的6DoF姿态估计方法，并且在推理时不需要特定实例的CAD模型。", "conclusion": "该方法通过检测3D线段并利用垃圾箱的立方体几何特性，能够有效地估计工业场景中垃圾箱的6DoF姿态，克服了数据稀缺和CAD模型不可用的限制，并达到了先进的性能。"}}
{"id": "2601.13206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13206", "abs": "https://arxiv.org/abs/2601.13206", "authors": ["Neil K. R. Sehgal", "Sharath Chandra Guntuku", "Lyle Ungar"], "title": "Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues", "comment": null, "summary": "Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\\% vs. 4\\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\\geq$95\\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.", "AI": {"tldr": "在实时截止日期下，大型语言模型（LLM）在模拟谈判中表现出显著的时间感知缺陷。当LLM接收到剩余时间更新时，成交率和接受率会大大提高，这表明它们在时间追踪方面存在系统性问题，而非策略推理能力不足。", "motivation": "现实世界的交流（如治疗、商业谈判）依赖于连续时间约束，但现有LLM架构和评估协议很少测试其在实时截止日期下的时间感知能力。本研究旨在调查LLM在时间敏感环境下的行为调整。", "method": "通过让配对的LLM代理在严格的截止日期下进行模拟谈判来研究。设置了两种条件：一种是仅知道全局时间限制（对照组）；另一种是在每个回合都能接收到剩余时间更新（时间感知组）。", "result": "在时间感知条件下，成交率（32% vs 4%）和报价接受率（6倍）远高于对照组，表明LLM在内部追踪已用时间方面存在困难。然而，当LLM在基于回合的限制下时，其成交率接近完美（≥95%），这揭示了问题在于时间追踪而非策略推理。", "conclusion": "LLM在时间感知方面存在系统性不足，这将在许多时间敏感的应用中限制其部署。研究结果表明，LLM在处理连续时间约束时需要改进，尤其是在内部时间追踪能力方面。"}}
{"id": "2601.12729", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.12729", "abs": "https://arxiv.org/abs/2601.12729", "authors": ["Hanyu Zhu", "Zhihao Zhan", "Yuhang Ming", "Liang Li", "Dibo Hou", "Javier Civera", "Wanzeng Kong"], "title": "DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition", "comment": "10 pages, 4 figures, 5 tables", "summary": "One of the central challenges in visual place recognition (VPR) is learning a robust global representation that remains discriminative under large viewpoint changes, illumination variations, and severe domain shifts. While visual foundation models (VFMs) provide strong local features, most existing methods rely on a single model, overlooking the complementary cues offered by different VFMs. However, exploiting such complementary information inevitably alters token distributions, which challenges the stability of existing query-based global aggregation schemes. To address these challenges, we propose DC-VLAQ, a representation-centric framework that integrates the fusion of complementary VFMs and robust global aggregation. Specifically, we first introduce a lightweight residual-guided complementary fusion that anchors representations in the DINOv2 feature space while injecting complementary semantics from CLIP through a learned residual correction. In addition, we propose the Vector of Local Aggregated Queries (VLAQ), a query--residual global aggregation scheme that encodes local tokens by their residual responses to learnable queries, resulting in improved stability and the preservation of fine-grained discriminative cues. Extensive experiments on standard VPR benchmarks, including Pitts30k, Tokyo24/7, MSLS, Nordland, SPED, and AmsterTime, demonstrate that DC-VLAQ consistently outperforms strong baselines and achieves state-of-the-art performance, particularly under challenging domain shifts and long-term appearance changes.", "AI": {"tldr": "提出了一种名为DC-VLAQ的框架，通过融合不同视觉基础模型（VFMs）的互补信息并采用一种新的查询-残差全局聚合机制，提高了视觉地点识别（VPR）在各种挑战性条件下的鲁棒性和准确性。", "motivation": "现有的视觉地点识别方法在处理视角变化、光照变化和领域迁移等挑战时，往往依赖单一的视觉基础模型（VFMs），忽略了不同VFMs提供的互补信息。直接融合互补信息会改变 token 分布，影响现有查询式全局聚合方案的稳定性。", "method": "提出了一种名为DC-VLAQ的表示中心化框架。该框架包含两个关键部分：1. 轻量级残差引导互补融合：将DINOv2的特征作为锚点，通过学习到的残差修正注入CLIP的互补语义。2. 向量局部聚合查询（VLAQ）：一种查询-残差全局聚合方案，通过局部 token 对可学习查询的残差响应来编码这些 token，从而提高稳定性和保留细粒度区分性线索。", "result": "在Pitts30k、Tokyo24/7、MSLS、Nordland、SPED和AmsterTime等标准VPR基准测试中，DC-VLAQ持续优于强大的基线方法，并在领域迁移和长期外观变化等挑战性场景下达到了最先进的性能。", "conclusion": "DC-VLAQ通过有效融合互补的VFMs并采用一种稳定的全局聚合机制，成功地解决了视觉地点识别中的关键挑战，尤其是在处理大规模视角变化、光照变化和领域迁移时表现出色，证明了其在实际应用中的潜力。"}}
{"id": "2601.12549", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12549", "abs": "https://arxiv.org/abs/2601.12549", "authors": ["Ilia Badanin", "Daniil Dzenhaliou", "Imanol Schlag"], "title": "Benchmarking Concept-Spilling Across Languages in LLMs", "comment": null, "summary": "Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.", "AI": {"tldr": "本文提出了一种评估多语言大语言模型（LLMs）跨语言语义鲁棒性的新框架，通过衡量模型在生成多义词不同含义时的表现来识别和量化“语言溢出现象”，并对多种LLMs进行了评估。", "motivation": "多语言LLMs在跨语言能力上表现出色，但也存在偏向非英语语言表示的系统性偏差，导致生成非英语内容时出现语义干扰（语言溢出现象）。研究旨在通过量化这一现象来评估和改进多语言LLMs。", "method": "提出一个比较性框架，通过让模型生成多义词的多种含义来评估其语义鲁棒性。通过衡量模型在生成序列中从目标语言转向优势语言含义的“迟早”，来区分强弱模型。使用包含100个高多义性英语单词的基准，在九种语言上评估了多种开源和闭源的多语言LLMs。", "result": "研究发现，不同模型和语言在语义鲁棒性上存在显著差异。语义上更强的模型在需要生成多种含义时，会更晚地转向优势语言的含义，在失败前能生成更多目标语言的真实含义；而较弱的模型则会更早地转向优势语言的含义。", "conclusion": "本文提出了一个可扩展的、用于多语言语义评估的比较性基准和一个严格的验证流程，为开发更具语言平衡性的AI系统提供了关键工具，并能对模型进行排序，而无需明确归因错误来源。"}}
{"id": "2601.12109", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12109", "abs": "https://arxiv.org/abs/2601.12109", "authors": ["Larissa Ferreira Rodrigues Moreira", "Rodrigo Moreira", "Leonardo Gabriel Ferreira Rodrigues"], "title": "Energy-Aware Ensemble Learning for Coffee Leaf Disease Classification", "comment": null, "summary": "Coffee yields are contingent on the timely and accurate diagnosis of diseases; however, assessing leaf diseases in the field presents significant challenges. Although Artificial Intelligence (AI) vision models achieve high accuracy, their adoption is hindered by the limitations of constrained devices and intermittent connectivity. This study aims to facilitate sustainable on-device diagnosis through knowledge distillation: high-capacity Convolutional Neural Networks (CNNs) trained in data centers transfer knowledge to compact CNNs through Ensemble Learning (EL). Furthermore, dense tiny pairs were integrated through simple and optimized ensembling to enhance accuracy while adhering to strict computational and energy constraints. On a curated coffee leaf dataset, distilled tiny ensembles achieved competitive with prior work with significantly reduced energy consumption and carbon footprint. This indicates that lightweight models, when properly distilled and ensembled, can provide practical diagnostic solutions for Internet of Things (IoT) applications.", "AI": {"tldr": "本研究提出了一种利用知识蒸馏和集成学习的方法，将大型卷积神经网络（CNN）的模型知识迁移到小型CNN，以实现在计算和能源受限的设备上进行咖啡叶病害的准确诊断，并显著降低能耗和碳足迹。", "motivation": "在田间环境中及时准确地诊断咖啡叶病害至关重要，但现有的人工智能（AI）视觉模型面临着设备算力受限和网络连接不稳定的挑战，阻碍了其在实际应用中的推广。因此，研究的动机是开发一种能够在边缘设备上高效运行的病害诊断解决方案。", "method": "研究采用知识蒸馏技术，将数据中心训练的高容量CNN模型的知识迁移到小型CNN模型中。同时，结合集成学习（EL），特别是优化了“密集微小对”（dense tiny pairs）的集成策略，以提高小型模型的准确性，同时满足严格的计算和能源限制。", "result": "在咖啡叶数据集上的实验表明，经过知识蒸馏和集成学习的小型模型，在准确性方面达到了与现有方法相当的水平，但能耗和碳足迹显著降低。", "conclusion": "经过适当蒸馏和集成的小型模型，可以为物联网（IoT）应用提供实用的咖啡叶病害诊断解决方案，证明了在资源受限设备上实现可持续AI诊断的可行性。"}}
{"id": "2601.13976", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.13976", "abs": "https://arxiv.org/abs/2601.13976", "authors": ["Jing Zuo", "Lingzhou Mu", "Fan Jiang", "Chengcheng Ma", "Mu Xu", "Yonggang Qi"], "title": "FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation", "comment": null, "summary": "Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods.", "AI": {"tldr": "本文提出了FantasyVLN，一个统一的隐式推理框架，通过将想象的视觉观察编码到紧凑的潜在空间中，来实现在不产生显式文本开销的情况下，保留链式思考（CoT）推理的优势，从而实现高效且具有推理能力的实时导航。", "motivation": "现有方法在视觉语言导航（VLN）中利用CoT推理时存在局限性：纯文本CoT缺乏空间接地且容易过拟合；多模态CoT会导致严重的token膨胀，影响实时性。作者希望在不增加显式token开销的情况下，保留CoT推理的优势，实现实时导航。", "method": "FantasyVLN采用统一的隐式推理框架。在训练时，通过预训练的Visual AutoRegressor（VAR）将想象的视觉观察编码到紧凑的潜在空间中。模型在统一的多CoT策略下，联合学习文本、视觉和多模态CoT模式。在推理时，模型直接进行指令到动作的映射，同时受益于推理感知的表示。", "result": "在LH-VLN数据集上的实验表明，FantasyVLN实现了推理感知的实时导航，提高了成功率和效率，并将推理延迟降低了一个数量级，优于显式CoT方法。", "conclusion": "FantasyVLN成功地在不产生显式token开销的情况下，实现了CoT推理在VLN任务中的优势，能够进行高效且具有推理能力的实时导航。"}}
{"id": "2601.13233", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.13233", "abs": "https://arxiv.org/abs/2601.13233", "authors": ["Bolin Chen", "Dex Doksoo Lee", "Wei \"Wayne'' Chen", "Wei Chen"], "title": "RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements", "comment": null, "summary": "Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.", "AI": {"tldr": "提出了一种基于随机森林的生成方法（RAG），用于高效、可信地逆向设计具有高维函数响应的超材料，即使在数据量有限的情况下也能处理复杂的性能要求，并生成可靠的设计。", "motivation": "现有超材料逆向设计方法在处理非线性、条件依赖的高维函数响应（如应力-应变关系、色散关系）时面临挑战，例如高维性、设计要求整合困难、解的非存在或非唯一性，以及现有生成方法的数据需求大、设计要求处理启发式和缺乏不确定性量化。", "method": "提出了一种基于随机森林的生成方法（RAG）。该方法利用随机森林的小数据兼容性，实现对高维函数响应的数据高效预测。在逆向设计过程中，通过集成学习估计似然性，量化生成设计的可信度，并反映不同设计要求的相对难度。通过单次生成设计并从条件似然性中采样来解决一对多映射问题。", "result": "在声学超材料（指定部分通带/阻带）和机械超材料（目标翘曲响应）的逆向设计中验证了RAG的有效性，分别仅使用了500和1057个样本。与神经网络在具有非线性应力-应变关系的机械超材料数据集上进行了数据效率的对比。", "conclusion": "RAG为涉及函数响应、昂贵模拟和复杂设计要求的逆向设计提供了一条轻量级、可信的途径，该方法不仅适用于超材料，还可应用于其他领域。"}}
{"id": "2601.12555", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12555", "abs": "https://arxiv.org/abs/2601.12555", "authors": ["Yihong Liu", "Bingyu Xiong", "Hinrich Schütze"], "title": "Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models", "comment": "preprint", "summary": "Large language models (LLMs) can recall a wide range of factual knowledge across languages. However, existing factual recall evaluations primarily assess fact retrieval in isolation, where the queried entity is explicitly named and the fact is requested directly. In natural language use, facts are often accessed through context, where the relevant entity is introduced only indirectly. In this work, we study contextually mediated factual recall, asking whether LLMs can reliably retrieve factual knowledge when the target entity is embedded in a naturalistic context rather than queried explicitly, across languages. We construct controlled prompts that preserve the underlying fact while introducing referential mediation through contextual sentences. To disentangle contextual effects from name-specific associations, we further compare performance using synthetic names and real names across languages. Evaluating multiple model families in five languages, we find that contextual mediation consistently degrades factual recall, with substantial variation across relations. Larger models are more robust to contextual mediation, exhibiting a reduced performance gap relative to direct queries, while the effect of real names and name origin is mixed and unsystematic. These findings highlight a gap between isolated factual recall and context-dependent language understanding in multilingual LLMs.", "AI": {"tldr": "大型语言模型（LLMs）在上下文语境下回忆事实知识的能力不如直接查询，大型模型对此更具鲁棒性，但跨语言、跨关系表现不一。", "motivation": "现有LLM的事实回忆评估主要侧重于孤立的事实检索，而忽略了自然语言使用中事实常通过上下文间接获取的场景。因此，研究LLMs在上下文语境下回忆事实知识的能力非常重要。", "method": "构建受控提示，通过上下文句子引入指称中介，保留事实信息。为区分上下文效应和名字特异性关联，使用合成名字和真实名字进行比较。评估多个模型家族在五种语言上的表现。", "result": "上下文语境会持续降低事实回忆性能，不同关系之间存在显著差异。大型模型对上下文语境的鲁棒性更强，与直接查询的性能差距缩小。真实名字和名字来源的影响不确定且不系统。", "conclusion": "大型语言模型在孤立事实回忆和上下文依赖的语言理解之间存在差距，尤其是在跨语言场景下。模型规模是影响上下文语境下事实回忆能力的关键因素。"}}
{"id": "2601.13262", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13262", "abs": "https://arxiv.org/abs/2601.13262", "authors": ["Eric Onyame", "Akash Ghosh", "Subhadip Baidya", "Sriparna Saha", "Xiuying Chen", "Chirag Agarwal"], "title": "CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning", "comment": null, "summary": "While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/", "AI": {"tldr": "本研究提出了CUREMED-BENCH，一个包含13种语言的医学推理数据集，以及CURE-MED，一个基于课程学习的强化学习框架，通过代码切换感知微调和群体相对策略优化，提升了大型语言模型在多语言医学推理中的逻辑正确性和语言稳定性。", "motivation": "现有的大型语言模型在多语言医学推理方面表现不佳，限制了其在多语言医疗环境中的应用。", "method": "构建了CUREMED-BENCH数据集，并提出了CURE-MED框架，该框架结合了代码切换感知监督微调和群体相对策略优化。", "result": "在13种语言上，CURE-MED在7B和32B参数模型上均显著优于基线模型，分别达到了85.21%和94.96%的语言一致性，以及54.35%和70.04%的逻辑正确性。", "conclusion": "该研究成功地提高了大型语言模型在多语言医学推理中的可靠性和公平性。"}}
{"id": "2601.12111", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12111", "abs": "https://arxiv.org/abs/2601.12111", "authors": ["Wyatt McCurdy", "Xin Zhang", "Yuqi Song", "Min Gao"], "title": "RCDN: Real-Centered Detection Network for Robust Face Forgery Identification", "comment": null, "summary": "Image forgery has become a critical threat with the rapid proliferation of AI-based generation tools, which make it increasingly easy to synthesize realistic but fraudulent facial content. Existing detection methods achieve near-perfect performance when training and testing are conducted within the same domain, yet their effectiveness deteriorates substantially in crossdomain scenarios. This limitation is problematic, as new forgery techniques continuously emerge and detectors must remain reliable against unseen manipulations. To address this challenge, we propose the Real-Centered Detection Network (RCDN), a frequency spatial convolutional neural networks(CNN) framework with an Xception backbone that anchors its representation space around authentic facial images. Instead of modeling the diverse and evolving patterns of forgeries, RCDN emphasizes the consistency of real images, leveraging a dual-branch architecture and a real centered loss design to enhance robustness under distribution shifts. Extensive experiments on the DiFF dataset, focusing on three representative forgery types (FE, I2I, T2I), demonstrate that RCDN achieves both state-of-the-art in-domain accuracy and significantly stronger cross-domain generalization. Notably, RCDN reduces the generalization gap compared to leading baselines and achieves the highest cross/in-domain stability ratio, highlighting its potential as a practical solution for defending against evolving and unseen image forgery techniques.", "AI": {"tldr": "本文提出了一种名为RCDN（Real-Centered Detection Network）的图像篡改检测框架，该框架通过关注真实图像的一致性而非模拟不断变化的伪造模式，显著提高了在跨域场景下的检测鲁棒性和泛化能力，并取得了最先进的成果。", "motivation": "现有图像篡改检测方法在跨域场景下性能急剧下降，无法应对新兴的伪造技术，因此需要一种在分布变化下仍能保持可靠性的检测方法。", "method": "RCDN是一个基于Xception骨干网络的频域-空域卷积神经网络框架。它采用双分支架构，并设计了“真实图像中心化损失”来锚定其表示空间于真实人脸图像，强调真实图像的内在一致性。", "result": "在DiFF数据集上，RCDN在三种代表性的伪造类型（FE、I2I、T2I）上都取得了最先进的域内精度，并且在跨域泛化能力上显著优于现有方法，减少了泛化差距，并实现了最高的跨/域内稳定性比。", "conclusion": "RCDN通过将表示空间锚定在真实图像上，能够有效应对图像伪造技术的发展和分布变化，为防御不断演变和未知的图像伪造技术提供了一种更实用的解决方案。"}}
{"id": "2601.12119", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12119", "abs": "https://arxiv.org/abs/2601.12119", "authors": ["Xiaotong Zhou", "Zhenhui Yuan", "Yi Han", "Tianhua Xu", "Laurence T. Yang"], "title": "CARLA-Round: A Multi-Factor Simulation Dataset for Roundabout Trajectory Prediction", "comment": null, "summary": "Accurate trajectory prediction of vehicles at roundabouts is critical for reducing traffic accidents, yet it remains highly challenging due to their circular road geometry, continuous merging and yielding interactions, and absence of traffic signals. Developing accurate prediction algorithms relies on reliable, multimodal, and realistic datasets; however, such datasets for roundabout scenarios are scarce, as real-world data collection is often limited by incomplete observations and entangled factors that are difficult to isolate. We present CARLA-Round, a systematically designed simulation dataset for roundabout trajectory prediction. The dataset varies weather conditions (five types) and traffic density levels (spanning Level-of-Service A-E) in a structured manner, resulting in 25 controlled scenarios. Each scenario incorporates realistic mixtures of driving behaviors and provides explicit annotations that are largely absent from existing datasets. Unlike randomly sampled simulation data, this structured design enables precise analysis of how different conditions influence trajectory prediction performance. Validation experiments using standard baselines (LSTM, GCN, GRU+GCN) reveal traffic density dominates prediction difficulty with strong monotonic effects, while weather shows non-linear impacts. The best model achieves 0.312m ADE on real-world rounD dataset, demonstrating effective sim-to-real transfer. This systematic approach quantifies factor impacts impossible to isolate in confounded real-world datasets. Our CARLA-Round dataset is available at https://github.com/Rebecca689/CARLA-Round.", "AI": {"tldr": "本文提出了一种名为CARLA-Round的系统设计的仿真数据集，用于圆形交叉口轨迹预测，该数据集在不同天气和交通密度下进行控制和标注，并用于评估现有预测模型的性能。", "motivation": "现有圆形交叉口轨迹预测数据集稀缺且不完整，难以分析不同因素对预测性能的影响，因此需要一个系统设计的仿真数据集。", "method": "在CARLA仿真环境中，系统地改变天气条件（5种）和交通密度（LOS A-E），生成25种受控场景，并提供详细标注。使用LSTM、GCN、GRU+GCN等基线模型进行验证实验。", "result": "交通密度对轨迹预测难度有显著的单调影响，而天气条件的影响呈非线性。在真实数据集上，最佳模型实现了0.312m的ADE。", "conclusion": "CARLA-Round数据集能够系统地分析不同因素对轨迹预测性能的影响，实现了有效的仿真到真实迁移，并有助于弥补现有数据集的不足。"}}
{"id": "2601.12607", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12607", "abs": "https://arxiv.org/abs/2601.12607", "authors": ["Anurag Acharya", "Timothy Vega", "Rizwan A. Ashraf", "Anshu Sharma", "Derek Parker", "Robert Rallo"], "title": "A Cloud-based Multi-Agentic Workflow for Science", "comment": null, "summary": "As Large Language Models (LLMs) become ubiquitous across various scientific domains, their lack of ability to perform complex tasks like running simulations or to make complex decisions limits their utility. LLM-based agents bridge this gap due to their ability to call external resources and tools and thus are now rapidly gaining popularity. However, coming up with a workflow that can balance the models, cloud providers, and external resources is very challenging, making implementing an agentic system more of a hindrance than a help. In this work, we present a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. Built with a supervisor agent marshaling an array of agents with individual capabilities, our framework brings together straightforward tasks like literature review and data analysis with more complex ones like simulation runs. We describe the framework here in full, including a proof-of-concept system we built to accelerate the study of Catalysts, which is highly important in the field of Chemistry and Material Science. We report the cost to operate and use this framework, including the breakdown of the cost by services use. We also evaluate our system on a custom-curated synthetic benchmark and a popular Chemistry benchmark, and also perform expert validation of the system. The results show that our system is able to route the task to the correct agent 90% of the time and successfully complete the assigned task 97.5% of the time for the synthetic tasks and 91% of the time for real-world tasks, while still achieving better or comparable accuracy to most frontier models, showing that this is a viable framework for other scientific domains to replicate.", "AI": {"tldr": "本研究提出了一种领域无关、模型独立的科学助手代理框架，该框架可以在云上运行，通过协调多个代理来处理从文献综述到模拟运行的复杂任务，并在化学催化剂研究中进行了概念验证。", "motivation": "大型语言模型（LLMs）在科学领域应用广泛，但其执行复杂任务（如运行模拟或做出复杂决策）的能力有限。LLM代理虽然可以弥补这一差距，但构建一个能平衡模型、云服务和外部资源的代理系统非常困难。", "method": "提出了一种基于云的、领域无关、模型独立的代理框架。该框架包含一个主控代理，负责协调一系列具有不同能力的子代理。框架的设计旨在支持从简单的文献检索和数据分析到复杂的模拟运行等多种科学任务。", "result": "该框架在化学催化剂研究领域进行了概念验证。实验结果表明，该系统能够 90% 的时间将任务正确路由给相应的代理，并能 97.5% 的时间成功完成合成任务，在真实世界任务上成功率为 91%。在准确性方面，该系统表现出优于或媲美大多数前沿模型的性能。", "conclusion": "所提出的代理框架是一种可行的方法，可以作为科学研究的助手，能够有效地处理从简单到复杂的各种任务，并且在成本和准确性方面都表现良好，为其他科学领域提供了可借鉴的模式。"}}
{"id": "2601.13268", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13268", "abs": "https://arxiv.org/abs/2601.13268", "authors": ["Zainab Ghafoor", "Md Shafiqul Islam", "Koushik Howlader", "Md Rasel Khondokar", "Tanusree Bhattacharjee", "Sayantan Chakraborty", "Adrito Roy", "Ushashi Bhattacharjee", "Tirtho Roy"], "title": "Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops", "comment": null, "summary": "Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.", "AI": {"tldr": "研究提出了一种多智能体精炼框架，通过迭代对齐来提升医疗大语言模型的安全性和可靠性，该框架使用两种生成模型和两种评估模型，并在伦理和安全风险评估方面取得了显著成效。", "motivation": "确保大型语言模型（LLMs）在医疗领域的伦理完整性和安全性是其临床应用的主要障碍。", "method": "采用了一个包含两种生成模型（DeepSeek R1 和 Med-PaLM）和两种评估模型（LLaMA 3.1 和 Phi-4）的多智能体精炼框架。评估模型依据美国医学会（AMA）的医学伦理原则和五级安全风险评估（SRA-5）协议来评估响应。在900个跨越九个伦理领域的临床查询上进行了评估。", "result": "DeepSeek R1 的收敛速度更快（平均2.34次迭代 vs. 2.67次迭代），Med-PaLM 在处理隐私敏感场景方面表现更优。迭代式多智能体循环实现了89%的伦理违规减少率和92%的风险降级率。", "conclusion": "该多智能体精炼框架是一种可扩展、符合监管要求且经济高效的医疗人工智能安全治理范式，能有效减少伦理违规和降低安全风险。"}}
{"id": "2601.12618", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12618", "abs": "https://arxiv.org/abs/2601.12618", "authors": ["Elham Tajik", "Conrad Borchers", "Bahar Shahrokhian", "Sebastian Simon", "Ali Keramati", "Sonika Pal", "Sreecharan Sankaranarayanan"], "title": "Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems", "comment": "LAK 2026 conference paper, 7 pages", "summary": "Learning analytics researchers often analyze qualitative student data such as coded annotations or interview transcripts to understand learning processes. With the rise of generative AI, fully automated and human-AI workflows have emerged as promising methods for analysis. However, methodological standards to guide such workflows remain limited. In this study, we propose that reasoning traces generated by large language model (LLM) agents, especially within multi-agent systems, constitute a novel and rich form of process data to enhance interpretive practices in qualitative coding. We apply cosine similarity to LLM reasoning traces to systematically detect, quantify, and interpret disagreements among agents, reframing disagreement as a meaningful analytic signal. Analyzing nearly 10,000 instances of agent pairs coding human tutoring dialog segments, we show that LLM agents' semantic reasoning similarity robustly differentiates consensus from disagreement and correlates with human coding reliability. Qualitative analysis guided by this metric reveals nuanced instructional sub-functions within codes and opportunities for conceptual codebook refinement. By integrating quantitative similarity metrics with qualitative review, our method has the potential to improve and accelerate establishing inter-rater reliability during coding by surfacing interpretive ambiguity, especially when LLMs collaborate with humans. We discuss how reasoning-trace disagreements represent a valuable new class of analytic signals advancing methodological rigor and interpretive depth in educational research.", "AI": {"tldr": "本研究提出利用大型语言模型（LLM）的推理痕迹作为一种新的过程数据，通过计算LLM代理之间的余弦相似度来量化和解释分歧，从而增强定性编码的解释性。该方法能够区分共识与分歧，并与人类编码可靠性相关，有助于提高和加速定性编码过程中的编码者间信度和概念代码本的完善。", "motivation": "随着生成式AI的兴起，自动化和人机协作的定性数据分析方法日益重要，但缺乏相应的研究标准。本研究旨在探索LLM推理痕迹作为一种新型过程数据，以改善定性编码的实践。", "method": "研究者提出利用LLM代理生成的推理痕迹，并通过余弦相似度来量化和解释代理间的语义推理相似性。在对近10,000个代理对编码人类辅导对话段的实例进行分析后，研究者将这种相似性度量与人类编码的可靠性进行了比较，并结合定性分析来识别细微的教学子功能和代码本的完善机会。", "result": "LLM代理的语义推理相似性能够有效地区分共识与分歧，并且与人类编码者的可靠性呈正相关。通过该度量指导的定性分析揭示了代码内的细微教学子功能，并指出了概念代码本的改进方向。", "conclusion": "LLM推理痕迹可以作为一种有价值的新型分析信号，通过量化代理间的解释性模糊来提高和加速编码者间信度的建立，尤其是在LLM与人类协作的场景中。该方法有望提升教育研究的方法严谨性和解释深度。"}}
{"id": "2601.12149", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12149", "abs": "https://arxiv.org/abs/2601.12149", "authors": ["Pengfei Zhu", "Xavier Maldague"], "title": "Principal Component Analysis-Based Terahertz Self-Supervised Denoising and Deblurring Deep Neural Networks", "comment": null, "summary": "Terahertz (THz) systems inherently introduce frequency-dependent degradation effects, resulting in low-frequency blurring and high-frequency noise in amplitude images. Conventional image processing techniques cannot simultaneously address both issues, and manual intervention is often required due to the unknown boundary between denoising and deblurring. To tackle this challenge, we propose a principal component analysis (PCA)-based THz self-supervised denoising and deblurring network (THz-SSDD). The network employs a Recorrupted-to-Recorrupted self-supervised learning strategy to capture the intrinsic features of noise by exploiting invariance under repeated corruption. PCA decomposition and reconstruction are then applied to restore images across both low and high frequencies. The performance of the THz-SSDD network was evaluated on four types of samples. Training requires only a small set of unlabeled noisy images, and testing across samples with different material properties and measurement modes demonstrates effective denoising and deblurring. Quantitative analysis further validates the network feasibility, showing improvements in image quality while preserving the physical characteristics of the original signals.", "AI": {"tldr": "提出了一种基于主成分分析（PCA）的太赫兹自监督去噪和去模糊网络（THz-SSDD），用于解决太赫兹成像中固有的低频模糊和高频噪声问题，该网络通过自监督学习和PCA分解重建，可在无标签数据上有效提升图像质量并保留原始信号的物理特性。", "motivation": "太赫兹系统固有的频率依赖性导致幅度图像中出现低频模糊和高频噪声，传统图像处理方法无法同时解决这两个问题，且需要手动干预区分去噪和去模糊的界限。", "method": "提出了一种基于主成分分析（PCA）的太赫兹自监督去噪和去模糊网络（THz-SSDD）。该网络采用“重复损坏到重复损坏”的自监督学习策略，通过利用重复损坏下的不变性来捕捉噪声的内在特征。随后应用PCA分解和重构来恢复图像的低频和高频成分。", "result": "在四种不同类型的样品上评估了THz-SSDD网络的性能。实验证明，该网络仅需少量无标签的噪声图像即可进行训练，并且在跨不同材料特性和测量模式的样品上均能有效进行去噪和去模糊。定量分析表明，该网络在提高图像质量的同时，还能保留原始信号的物理特性。", "conclusion": "THz-SSDD网络是一种有效的太赫兹图像自监督去噪和去模糊方法，能够克服太赫兹成像中的频率依赖性退化问题，在无标签数据上实现高性能的图像恢复，并保留图像的物理信息。"}}
{"id": "2601.12632", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12632", "abs": "https://arxiv.org/abs/2601.12632", "authors": ["Kriti Bhattarai", "Vipina K. Keloth", "Donald Wright", "Andrew Loza", "Yang Ren", "Hua Xu"], "title": "BioPulse-QA: A Dynamic Biomedical Question-Answering Benchmark for Evaluating Factuality, Robustness, and Bias in Large Language Models", "comment": null, "summary": "Objective: Large language models (LLMs) are increasingly applied in biomedical settings, and existing benchmark datasets have played an important role in supporting model development and evaluation. However, these benchmarks often have limitations. Many rely on static or outdated datasets that fail to capture the dynamic, context-rich, and high-stakes nature of biomedical knowledge. They also carry increasing risk of data leakage due to overlap with model pretraining corpora and often overlook critical dimensions such as robustness to linguistic variation and potential demographic biases.\n  Materials and Methods: To address these gaps, we introduce BioPulse-QA, a benchmark that evaluates LLMs on answering questions from newly published biomedical documents including drug labels, trial protocols, and clinical guidelines. BioPulse-QA includes 2,280 expert-verified question answering (QA) pairs and perturbed variants, covering both extractive and abstractive formats. We evaluate four LLMs - GPT-4o, GPT-o1, Gemini-2.0-Flash, and LLaMA-3.1 8B Instruct - released prior to the publication dates of the benchmark documents.\n  Results: GPT-o1 achieves the highest relaxed F1 score (0.92), followed by Gemini-2.0-Flash (0.90) on drug labels. Clinical trials are the most challenging source, with extractive F1 scores as low as 0.36.\n  Discussion and Conclusion: Performance differences are larger for paraphrasing than for typographical errors, while bias testing shows negligible differences. BioPulse-QA provides a scalable and clinically relevant framework for evaluating biomedical LLMs.", "AI": {"tldr": "本研究提出了 BioPulse-QA，一个评估生物医学大型语言模型（LLMs）在最新发布的生物医学文档上的问答能力的新基准。该基准包含 2,280 个专家验证的问答对，并评估了四种 LLMs 的性能，结果显示 GPT-o1 在药物标签问答方面表现最佳，而临床试验则最具挑战性。", "motivation": "现有的生物医学 LLM 基准数据集存在局限性，例如数据集过时、存在数据泄露风险、忽略了对语言变化的鲁棒性和潜在的统计偏差等。本研究旨在通过构建一个包含最新生物医学文档的基准来弥补这些不足。", "method": "研究者提出了 BioPulse-QA 基准，包含 2,280 个专家验证的问答对，涵盖提取式和摘要式问答，并包含扰动变体。该基准使用了最新的生物医学文档，包括药物标签、试验方案和临床指南。研究者评估了 GPT-4o、GPT-o1、Gemini-2.0-Flash 和 LLaMA-3.1 8B Instruct 四种 LLMs 的性能。", "result": "在药物标签问答方面，GPT-o1 取得了最高的宽松 F1 分数（0.92），其次是 Gemini-2.0-Flash（0.90）。临床试验被证明是最具挑战性的数据源，提取式 F1 分数低至 0.36。此外，性能差异在释义（paraphrasing）扰动下比在印刷错误（typographical errors）扰动下更大，而偏差测试显示差异可忽略不计。", "conclusion": "BioPulse-QA 提供了一个可扩展且具有临床相关性的框架，用于评估生物医学 LLMs。研究结果表明，模型在不同生物医学文档类型和扰动类型上的表现存在差异，为未来生物医学 LLM 的开发和评估提供了重要参考。"}}
{"id": "2601.12639", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12639", "abs": "https://arxiv.org/abs/2601.12639", "authors": ["Daniel Vennemeyer", "Punya Syon Pandey", "Phan Anh Duong", "Michael Umeokoli", "Samuel Ratnam"], "title": "Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift", "comment": null, "summary": "Fine-tuning LLMs on benign data can still degrade alignment and adversarial robustness, yet direct analysis of the role of fine-tuning objectives in shaping these safety outcomes remain limited. We present a controlled comparison of six fine-tuning objectives -- Supervised Fine-Tuning, Direct Preference Optimization, Conditional Fine-Tuning, Inoculation Prompting, Odds Ratio Preference Optimization, and KL-regularized fine-tuning -- holding data, domain, architecture, and optimization fixed. Across closed-form reasoning and open-ended generation tasks, we find that objective choice induces systematic, scale-dependent shifts along the safety-capability frontier. At small training budgets, robustness is similar across objectives but capability differs. At larger budgets, objectives diverge sharply: supervised and preference-based tuning tightly couple capability gains to increased adversarial vulnerability and persona drift, while objectives that constrain learning signals -- especially ORPO and KL-regularization -- substantially mitigate both. Fine-tuning objectives therefore matter little for safety at small scales but become a primary driver of adversarial robustness and latent persona stability as training scale increases.", "AI": {"tldr": "本文比较了六种不同的微调目标（SFT、DPO、CFT、Inoculation Prompting、ORPO、KL-regularized fine-tuning）对大型语言模型（LLM）的对齐和对抗鲁棒性的影响。研究发现，微调目标的差异在小规模训练时影响不大，但在大规模训练时，ORPO和KL-regularization等约束学习信号的目标能显著提升对抗鲁棒性和减少潜在人格漂移。", "motivation": "现有研究对微调目标在塑造LLM的对齐和对抗鲁棒性方面的作用分析有限，因此需要进行受控比较以深入理解其影响。", "method": "在固定数据、领域、架构和优化器的情况下，对比了六种微调目标（Supervised Fine-Tuning, Direct Preference Optimization, Conditional Fine-Tuning, Inoculation Prompting, Odds Ratio Preference Optimization, KL-regularized fine-tuning），并在封闭式推理和开放式生成任务中进行了评估。", "result": "微调目标的差异会在安全-能力边界上引起系统性、规模依赖性的变化。小规模训练时，鲁棒性相似但能力不同；大规模训练时，SFT和基于偏好的微调会以增加对抗脆弱性和人格漂移为代价来提升能力，而ORPO和KL-regularization等约束学习信号的目标能显著缓解这些问题。", "conclusion": "微调目标在小规模训练时对模型安全影响不大，但在大规模训练时，其对模型的对抗鲁棒性和潜在人格稳定性起着主要驱动作用。"}}
{"id": "2601.12150", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12150", "abs": "https://arxiv.org/abs/2601.12150", "authors": ["Mengxuan Hu", "Zihan Guan", "John Kang", "Sheng Li", "Zhongliang Zhou"], "title": "Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models", "comment": "8 pages", "summary": "Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size e.g. 224 x 224, creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naive strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose an space- and time- efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieves up to an 7.67% improvement in the ROI classification and compatible results in segmentation.", "AI": {"tldr": "提出了一种高效的病理学基础模型推理策略，通过稀疏化注意力机制和过滤非信息性 token，在保持甚至提高模型性能的同时，显著降低了对整个病理图像（WSIs）进行高分辨率推理时的 GPU 内存和运行时间。", "motivation": "现有的病理学基础模型通常受限于固定的输入尺寸（如 224x224），这在处理分辨率极高的全切片图像（WSIs）时效率低下。简单地放大输入会导致 GPU 内存消耗过高，而下采样则会丢失关键的形态学细节。", "method": "提出了一种空间和时间效率的推理策略，该策略通过空间感知的邻域块稀疏化注意力，并利用全局注意力分数过滤掉非信息性 token。", "result": "与基线方法相比，该方法在 ROI 分类任务上实现了高达 7.67% 的性能提升，并在分割任务上取得了兼容的结果。实验证明，在相同的 GPU 预算下，该方法能够实现更高分辨率的推理。", "conclusion": "所提出的稀疏化注意力推理策略是一种有效且高效的方法，可以克服当前病理学基础模型在处理高分辨率全切片图像时的局限性，有望实现更高质量和更便捷的病理图像分析。"}}
{"id": "2601.13383", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13383", "abs": "https://arxiv.org/abs/2601.13383", "authors": ["Akbar Anbar Jafari", "Cagri Ozcinar", "Gholamreza Anbarjafari"], "title": "A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge", "comment": "15 pages, 3 figures", "summary": "The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.", "AI": {"tldr": "AgentForge 是一个轻量级、开源的 Python 框架，用于构建基于 LLM 的自主代理，通过模块化设计、可组合技能和统一的 LLM 后端接口，简化了开发流程，提高了效率和灵活性。", "motivation": "现有 LLM 代理框架存在架构僵化、供应商锁定和复杂性高的问题，阻碍了快速原型开发和部署。研究者希望提供一个更易于使用、灵活且高效的框架。", "method": "提出 AgentForge 框架，其核心创新包括：1) 可组合的技能抽象，带有定义清晰的输入输出契约；2) 统一的 LLM 后端接口，支持云 API 和本地推理；3) 基于 YAML 的声明式配置系统。将技能组合机制形式化为有向无环图 (DAG)。", "result": "在四个基准场景的实验评估中，AgentForge 在任务完成率上表现具有竞争力，同时将开发时间相比 LangChain 减少了 62%，相比直接 API 集成减少了 78%。框架的编排开销低于 100ms，适用于实时应用。框架易于扩展，已集成六种内置技能，并支持自定义技能开发。", "conclusion": "AgentForge 通过提供一个生产就绪的基础，弥合了 LLM 代理生态系统的关键差距，使研究人员和实践者能够在不牺牲灵活性或性能的情况下构建、评估和部署自主代理。"}}
{"id": "2601.13358", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13358", "abs": "https://arxiv.org/abs/2601.13358", "authors": ["Samuel Cyrenius Anderson"], "title": "The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models", "comment": "34 pages, 10 figures", "summary": "Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.", "AI": {"tldr": "研究发现，大规模语言模型的推理能力提升并非均匀的，而是会引发特定领域的结构性变化（例如，法律推理的“结晶化”），而非简单的能力增强。这种几何结构可以预测模型的学习能力，并且研究者提出了一种名为“神经推理算子”的方法，可以预测推理结果。此外，研究还发现了一个跨领域、跨规模的普遍振荡模式，暗示了模型内部不同层级在推理过程中的协同作用。", "motivation": "研究者希望理解大规模语言模型（LLM）在不同领域和规模下，其推理能力是如何变化的，以及这种变化背后的机制是什么。他们注意到现有的研究主要关注通用能力提升，而忽略了尺度变化可能对推理过程本身产生的结构性影响。", "method": "研究者分析了来自法律、科学、代码和数学四个领域的25,000多个链式思考（chain-of-thought）轨迹，比较了8B和70B参数规模的模型。他们使用了几何分析方法来研究推理轨迹的“流形”结构（manifold untangling, representational dimensionality, trajectory alignment）。此外，他们还引入了“神经推理算子”（Neural Reasoning Operators）来预测推理的最终状态，并分析了模型内部的隐藏状态（hidden states）以识别普遍的振荡模式。", "result": "研究发现，大规模模型并非均匀地提升推理能力。法律推理表现出“结晶化”现象，其表示维度显著降低，轨迹对齐性增加，流形更加清晰。科学和数学推理则保持“液体”状态，几何特性不变。代码推理则形成离散的“格子”结构。这种几何结构预测了模型的学习能力。研究提出的神经推理算子在法律推理任务上实现了63.6%的准确率。所有领域和规模的模型都表现出一种普遍的振荡模式（coherence ~ -0.4），表明注意力层和前馈层可能通过相对的动力学驱动推理。", "conclusion": "语言模型能力的提升会引发领域特定的推理结构重组，而非简单的能力增强。这种推理过程的几何拓扑结构（manifold geometry）决定了推理的“成本”和可学习性，为推理加速提供了新思路。研究提出的神经推理算子能够有效地预测推理结果，而发现的普遍振荡模式则揭示了模型内部不同组成部分协同工作的方式。"}}
{"id": "2601.12648", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12648", "abs": "https://arxiv.org/abs/2601.12648", "authors": ["Nafiz Imtiaz Khan", "Kylie Cleland", "Vladimir Filkov", "Roger Eric Goldman"], "title": "Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?", "comment": "51 pages, 12 figures, 8 tables. Feasibility study using retrospective radiology reports. Submitted to JAMIA Open (under review)", "summary": "Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.", "AI": {"tldr": "本研究探索使用大型语言模型（LLMs）自动生成放射科培训所需的程序性病例记录，以减少手动记录的耗时和不一致性。实验结果表明，LLMs在从自由文本放射报告中提取结构化程序信息方面表现良好，可显著减轻学员的文书工作负担并提高记录的一致性。", "motivation": "手动完成放射科培训的程序性病例记录耗时且易出错，研究旨在探索使用大型语言模型（LLMs）实现自动化记录，以提高效率和一致性。", "method": "研究人员使用414份介入放射学报告，通过指令提示（instruction-based）和思维链提示（chain-of-thought prompting）两种方式，评估了多种本地及商业LLMs从自由文本报告中提取结构化程序信息的能力。模型性能通过敏感性、特异性和F1分数进行评估，同时考虑了推理延迟和代币效率。", "result": "本地和商业LLMs均在信息提取方面取得了较好的表现，最佳F1分数接近0.87。不同模型在速度和成本之间存在不同的权衡。", "conclusion": "使用LLMs自动化程序性病例记录具有潜力，可以大幅减轻学员的文书工作负担，并提高病例记录的一致性。研究证明了AI辅助文档在医学教育中的可行性，并强调了在不同机构和临床工作流程中进行进一步验证的必要性。"}}
{"id": "2601.12147", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12147", "abs": "https://arxiv.org/abs/2601.12147", "authors": ["Zezhong Fan", "Xiaohan Li", "Topojoy Biswas", "Kaushiki Nag", "Kannan Achan"], "title": "Segment and Matte Anything in a Unified Model", "comment": "AAAI 2026", "summary": "Segment Anything (SAM) has recently pushed the boundaries of segmentation by demonstrating zero-shot generalization and flexible prompting after training on over one billion masks. Despite this, its mask prediction accuracy often falls short of the precision required in real-world applications. While several refinement modules have been proposed to boost SAM's segmentation quality, achieving highly accurate object delineation within a single, unified framework remains an open challenge. Furthermore, interactive image matting, which aims to generate fine-grained alpha mattes guided by diverse user hints, has not yet been explored in the context of SAM. Insights from recent studies highlight strong correlations between segmentation and matting, suggesting the feasibility of a unified model capable of both tasks. In this paper, we introduce Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. Our Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. We also incorporate two prediction heads for each task into the architecture to generate segmentation and matting masks, simultaneously. Trained on a diverse dataset aggregated from publicly available sources, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.", "AI": {"tldr": "本文提出了SAMA，一个轻量级的SAM扩展，通过多视图定位编码器（MVLE）和定位适配器（Local-Adapter）实现高质量的交互式图像分割和抠图，并在多个分割和抠图基准测试中取得了最先进的性能。", "motivation": "现有的SAM模型在精确度方面不足以满足实际应用需求，且缺乏统一的框架来同时处理分割和抠图任务，而分割和抠图之间存在强相关性。", "method": "SAMA扩展了SAM，引入了多视图定位编码器（MVLE）用于捕获详细特征，以及定位适配器（Local-Adapter）用于细化边界细节。模型集成了用于分割和抠图的两个预测头，能够同时生成这两种类型的掩膜。", "result": "SAMA在分割和抠图任务上均取得了最先进的性能，展示了其在各种下游任务中的适应性和有效性。", "conclusion": "SAMA是一个轻量级的SAM扩展，能够以极少的额外参数实现高质量的交互式图像分割和抠图，有效解决了现有模型在精度和任务统一性方面的不足。"}}
{"id": "2601.12155", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12155", "abs": "https://arxiv.org/abs/2601.12155", "authors": ["Xiang Gao", "Xinmu Wang", "Yuanpeng Liu", "Yue Wang", "Junqi Huang", "Wei Chen", "Xianfeng Gu"], "title": "Inverse Rendering for High-Genus 3D Surface Meshes from Multi-view Images with Persistent Homology Priors", "comment": "ICASSP2026 Accepted", "summary": "Reconstructing 3D objects from images is inherently an ill-posed problem due to ambiguities in geometry, appearance, and topology. This paper introduces collaborative inverse rendering with persistent homology priors, a novel strategy that leverages topological constraints to resolve these ambiguities. By incorporating priors that capture critical features such as tunnel loops and handle loops, our approach directly addresses the difficulty of reconstructing high-genus surfaces. The collaboration between photometric consistency from multi-view images and homology-based guidance enables recovery of complex high-genus geometry while circumventing catastrophic failures such as collapsing tunnels or losing high-genus structure. Instead of neural networks, our method relies on gradient-based optimization within a mesh-based inverse rendering framework to highlight the role of topological priors. Experimental results show that incorporating persistent homology priors leads to lower Chamfer Distance (CD) and higher Volume IoU compared to state-of-the-art mesh-based methods, demonstrating improved geometric accuracy and robustness against topological failure.", "AI": {"tldr": "本文提出了一种结合持久同调先验的协同逆渲染方法，利用拓扑约束来解决从图像重建3D对象时的几何、外观和拓扑歧义问题，尤其擅长处理高亏格曲面。", "motivation": "从图像重建3D对象是一个本质上不适定的问题，存在几何、外观和拓扑上的歧义，特别是高亏格曲面的重建面临巨大挑战。", "method": "该方法结合了多视图图像的光度一致性以及基于持久同调的拓扑先验（如孔洞和把手），在一个基于网格的逆渲染框架内，通过梯度优化来恢复高亏格几何。", "result": "与现有先进的基于网格的方法相比，该方法在使用持久同调先验后，取得了更低的Chamfer Distance（CD）和更高的Volume IoU，表明在几何精度和拓扑鲁棒性方面有所提升。", "conclusion": "将持久同调先验集成到协同逆渲染框架中，能够有效解决3D重建中的拓扑歧义问题，特别是对于高亏格曲面，能够避免拓扑失效（如隧道塌陷或高亏格结构丢失），并提高重建的几何精度和鲁棒性。"}}
{"id": "2601.12658", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12658", "abs": "https://arxiv.org/abs/2601.12658", "authors": ["Tianyi Yang", "Nashrah Haque", "Vaishnave Jonnalagadda", "Yuya Jeremy Ong", "Zhehui Chen", "Yanzhao Wu", "Lei Yu", "Divyesh Jadav", "Wenqi Wei"], "title": "Augmenting Question Answering with A Hybrid RAG Approach", "comment": "10 pages, 5 tables, 2 figures; presented at IEEE CogMI 2025", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.", "AI": {"tldr": "本文提出了一种名为SSRAG的混合架构，通过查询增强、智能体路由以及结合向量和图技术的结构化检索来改进检索增强生成（RAG）在问答任务中的表现，提升了答案的准确性和信息量。", "motivation": "现有RAG方法在检索上下文相关信息方面存在不足，导致答案不完整或次优，因此需要改进RAG以提高问答质量。", "method": "提出SSRAG混合架构，包含查询增强、智能体路由、以及结合向量和图技术的结构化检索机制，并进行上下文统一。", "result": "SSRAG在TruthfulQA、SQuAD和WikiQA三个数据集上，对五种大型语言模型进行评估，结果表明SSRAG在答案准确性和信息量方面优于标准的RAG实现。", "conclusion": "SSRAG通过优化检索过程和加强上下文关联，有效提高了问答任务的响应质量。"}}
{"id": "2601.13443", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13443", "abs": "https://arxiv.org/abs/2601.13443", "authors": ["Héctor Manuel Manzanilla-Granados", "Zaira Navarrete-Cazales", "Miriam Pescador-Rojas", "Tonahtiu Ramírez-Romero"], "title": "Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models", "comment": "Preprint. This version corresponds to the initial public release of the CUA architecture and associated evaluation metrics", "summary": "The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.\n  We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.\n  We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.", "AI": {"tldr": "该研究提出了一种名为“显式认知分配”（Explicit Cognitive Allocation, ECA）的通用原则，并将其应用于认知通用代理（Cognitive Universal Agent, CUA）架构，以解决当前大型语言模型（LLM）在进行推理时存在认知功能混淆的问题，从而提高可追溯性、知识控制和可重复性。实验表明，CUA在农业领域表现出更早、更结构化的认知收敛，更高的语义扩展下的认知对齐，以及更系统化的探究工具化分析。", "motivation": "当前LLM的使用方式将问题定义、知识探索、检索、方法论意识和解释等认知功能混为一体，导致推理过程缺乏可追溯性、知识控制薄弱且可重复性差，尤其是在高风险应用场景中。", "method": "提出“显式认知分配”原则，并将其具体化为“认知通用代理”（CUA）架构。CUA将推理过程分解为探索与定义、认知锚定、工具与方法映射、以及解释性综合等独立阶段。该框架引入“通用认知工具”（UCIs）来形式化处理抽象问题所需的异构资源，如计算、实验、组织、法规和教育等。", "result": "在农业领域的对照实验中，CUA驱动的推理相较于基线LLM推理，表现出更早且结构化的认知收敛，语义扩展下更高的认知对齐，以及对探究工具化层面的系统性暴露。基线LLM推理则显示出更高的对齐度变异性，并且未能明确呈现工具化结构。", "conclusion": "显式认知分配原则能够有效改善LLM在推理过程中的认知结构，提升推理的严谨性、可控性和可解释性，特别是在需要严谨的科学和技术领域。"}}
{"id": "2601.13327", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13327", "abs": "https://arxiv.org/abs/2601.13327", "authors": ["Po-Yu Liang", "Tobo Duran", "Jun Bai"], "title": "PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion", "comment": null, "summary": "We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model", "AI": {"tldr": "PepEDiff 是一种新颖的肽结合物生成器，可以直接在连续的潜在空间中生成结合序列，无需预测结构，从而提高了序列和结构多样性，并在 TIGIT 案例研究中优于现有方法。", "motivation": "现有肽结合物生成方法通常依赖于中间结构预测，增加了复杂性并限制了序列多样性。需要一种更直接、更通用的方法来生成具有更高序列和结构多样性的肽结合物。", "method": "PepEDiff 在从预训练的蛋白质嵌入模型导出的连续潜在空间中生成肽结合物。它不依赖于预测的结构，而是利用潜在空间探索和基于扩散的采样来生成新颖的肽序列，并利用全局蛋白质嵌入流形作为语义先验。", "result": "PepEDiff 在 TIGIT 靶点上进行了评估，该靶点具有复杂的大型相互作用界面。在基准测试和 TIGIT 案例研究中，PepEDiff 的性能优于最先进的方法，表明其在零样本肽结合物设计方面具有潜力。", "conclusion": "PepEDiff 是一种有效的、无结构的零样本肽结合物设计框架，能够生成具有高序列和结构多样性的新颖肽结合物，并且在具有挑战性的靶点上表现出色。"}}
{"id": "2601.12193", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12193", "abs": "https://arxiv.org/abs/2601.12193", "authors": ["Shaunak Halbe", "Bhagyashree Puranik", "Jayakrishnan Unnikrishnan", "Kushan Thakkar", "Vimal Bhat", "Toufiq Parag"], "title": "VIRTUE: Versatile Video Retrieval Through Unified Embeddings", "comment": null, "summary": "Modern video retrieval systems are expected to handle diverse tasks ranging from corpus-level retrieval and fine-grained moment localization to flexible multimodal querying. Specialized architectures achieve strong retrieval performance by training modality-specific encoders on massive datasets, but they lack the ability to process composed multimodal queries. In contrast, multimodal LLM (MLLM)-based methods support rich multimodal search but their retrieval performance remains well below that of specialized systems. We present VIRTUE, an MLLM-based versatile video retrieval framework that integrates corpus and moment-level retrieval capabilities while accommodating composed multimodal queries within a single architecture. We use contrastive alignment of visual and textual embeddings generated using a shared MLLM backbone to facilitate efficient embedding-based candidate search. Our embedding model, trained efficiently using low-rank adaptation (LoRA) on 700K paired visual-text data samples, surpasses other MLLM-based methods on zero-shot video retrieval tasks. Additionally, we demonstrate that the same model can be adapted without further training to achieve competitive results on zero-shot moment retrieval, and state of the art results for zero-shot composed video retrieval. With additional training for reranking candidates identified in the embedding-based search, our model substantially outperforms existing MLLM-based retrieval systems and achieves retrieval performance comparable to state of the art specialized models which are trained on orders of magnitude larger data.", "AI": {"tldr": "VIRTUE是一个基于多模态大语言模型（MLLM）的视频检索框架，能够处理组合多模态查询，并在语料库和时刻级检索任务上实现与专业系统媲美的性能，同时其训练效率更高。", "motivation": "现有的视频检索系统要么擅长特定任务但无法处理组合查询，要么支持组合查询但检索性能不足。研究旨在构建一个单一架构，同时具备多种检索能力并支持组合多模态查询。", "method": "VIRTUE使用共享的MLLM骨干网络生成视觉和文本嵌入，并通过对比学习进行对齐，以实现高效的基于嵌入的候选搜索。模型使用低秩适配（LoRA）在700K视觉-文本数据样本上进行训练。此外，该模型还能在无需进一步训练的情况下适应时刻检索任务，并通过额外的重排（reranking）训练在组合视频检索任务上取得领先。", "result": "VIRTUE在零样本视频检索任务上超越了其他基于MLLM的方法。经过微调，它在零样本时刻检索任务上表现具有竞争力，在零样本组合视频检索任务上取得了最先进的性能。通过重排，其性能大幅优于现有MLLM检索系统，并接近在更大规模数据上训练的专业系统。", "conclusion": "VIRTUE是一个通用的视频检索框架，通过共享MLLM骨干和对比学习，实现了高效、多功能的视频检索，并且在多种检索任务上展现出优越的性能和效率。"}}
{"id": "2601.12224", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12224", "abs": "https://arxiv.org/abs/2601.12224", "authors": ["Meng Wei", "Kun Yuan", "Shi Li", "Yue Zhou", "Long Bai", "Nassir Navab", "Hongliang Ren", "Hong Joo Lee", "Tom Vercauteren", "Nicolas Padoy"], "title": "Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion", "comment": null, "summary": "Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. However, the task of referring segmentation, localizing surgical instruments based on natural language descriptions, remains underexplored in surgical videos, with existing approaches struggling to generalize due to reliance on static visual cues and predefined instrument names. In this work, we introduce SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time, rather than what they look like. This allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. To train and evaluate SurgRef, we present Ref-IMotion, a diverse, multi-institutional video dataset with dense spatiotemporal masks and rich motion-centric expressions. SurgRef achieves state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.", "AI": {"tldr": "本文提出了一种名为SurgRef的运动引导框架，用于通过自然语言描述来分割手术视频中的手术器械，并发布了一个名为Ref-IMotion的新数据集。", "motivation": "现有手术视频中的指代表达分割方法依赖于静态视觉线索和预定义的器械名称，泛化能力不足，难以应对遮挡、歧义或不熟悉术语的情况。因此，需要一种新的方法来更鲁棒地理解和分割器械。", "method": "本文提出SurgRef框架，该框架通过关注器械的运动而非外观来理解自然语言描述。它捕捉器械随时间如何移动和交互，以实现更准确的分割。为了训练和评估SurgRef，作者构建了一个名为Ref-IMotion的多机构视频数据集，其中包含密集的时空掩码和以运动为中心的丰富表达。", "result": "SurgRef在手术视频分割任务上取得了最先进的准确性和泛化能力，显著优于现有方法。", "conclusion": "SurgRef框架通过引导语言表达关注器械的运动，克服了现有方法的局限性，实现了对复杂手术场景下器械的鲁棒性语言驱动分割。Ref-IMotion数据集为进一步研究提供了宝贵的资源。"}}
{"id": "2601.12696", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12696", "abs": "https://arxiv.org/abs/2601.12696", "authors": ["Tassallah Abdullahi", "Macton Mgonzo", "Mardiyyah Oduwole", "Paul Okewunmi", "Abraham Owodunni", "Ritambhara Singh", "Carsten Eickhoff"], "title": "UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages", "comment": "12 pages", "summary": "Current guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\\footnote{Code repository available at https://github.com/hemhemoh/UbuntuGuard.", "AI": {"tldr": "本研究提出了UbuntuGuard，一个针对低资源非洲语言的、基于策略的安全基准，以解决现有模型中存在的偏见和不适。研究发现，现有的英语中心化基准高估了多语言模型的安全性，跨语言迁移效果有限，动态模型虽然能更好地利用策略，但仍难以充分适应非洲语言的本地化语境。", "motivation": "现有的 Guardian 模型主要以西方为中心，并针对高资源语言进行优化，导致低资源非洲语言面临着不断演变的危害、跨语言安全失效和文化不匹配等问题。此外，大多数 Guardian 模型依赖僵化、预定义的严格类别，难以泛化到不同的语言和社会文化背景。因此，稳健的安全需要灵活、运行时可执行的策略和基准，以反映本地规范、危害场景和文化期望。", "method": "研究提出了 UbuntuGuard，一个基于策略的安全基准，它由来自 155 名各领域（包括医疗保健）的领域专家的对抗性查询构建而成。基于这些专家精心设计的查询，研究推导出了特定情境的安全策略和参考回复，捕捉了文化基础的风险信号，从而能够对 Guardian 模型进行符合策略的评估。研究评估了 13 个模型，包括 6 个通用语言模型和 7 个 Guardian 模型，涵盖了静态、动态和多语言三个变体。", "result": "研究发现，现有的以英语为中心的基准高估了实际的多语言安全性。跨语言迁移提供了部分但不足的覆盖范围。动态模型虽然在推理时能更好地利用策略，但仍然难以完全本地化非洲语言的语境。", "conclusion": "现有研究结果强调了开发多语言、文化基础的安全基准的紧迫性，以支持为低资源语言开发可靠和公平的 Guardian 模型。"}}
{"id": "2601.13462", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13462", "abs": "https://arxiv.org/abs/2601.13462", "authors": ["Amine Rostane"], "title": "SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation", "comment": "19 pages, includes figures and tables", "summary": "Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.", "AI": {"tldr": "本研究提出了SpatialBench-UC，一个用于评估文本到图像模型空间指令遵循情况的可复现基准，并包含一个能选择性预测的检查器，该检查器允许在证据不足时放弃预测，并报告置信度。研究评估了三种基线模型，发现基于地面化（grounding）的方法显著提高了模型性能，但缺失检测仍是导致模型放弃预测的主要原因。", "motivation": "自动化评估文本到图像模型是否遵循显式空间指令存在困难，因为目标检测器可能漏报或多报，几何测试在边界情况下可能不明确。因此，研究的动机是开发一个更可靠、更可解释的方法来评估模型在这方面的能力。", "method": "研究引入了SpatialBench-UC基准，包含200个提示（50个对象对 x 4种关系），并配对成100个反事实对。同时，开发了一个选择性预测的检查器，该检查器在证据不足时会选择放弃预测（abstain）并报告置信度。通过轻量级的人工审核来校准检查器的放弃阈值和置信度阈值。最后，使用Stable Diffusion 1.5、SD 1.5 BoxDiff和SD 1.4 GLIGEN三种模型作为基线进行评估。", "result": "评估结果显示，基于地面化（grounding）的方法（如SD 1.5 BoxDiff和SD 1.4 GLIGEN）相比于基础模型（Stable Diffusion 1.5），在通过率（pass rate）和覆盖率（coverage）方面均有显著提升。然而，模型选择性放弃预测（abstention）仍然是影响结果的一个主要因素，这主要归因于目标检测过程中出现的漏检问题。", "conclusion": "SpatialBench-UC提供了一个可复现且可审计的评估框架，用于衡量文本到图像模型对空间指令的遵循能力。研究表明，地面化方法能够有效提升模型的空间指令理解能力，但模型的鲁棒性仍需加强，尤其是在处理目标检测的漏检问题上。"}}
{"id": "2601.13464", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.13464", "abs": "https://arxiv.org/abs/2601.13464", "authors": ["Chongyang Gao", "Marco Postiglione", "Julian Baldwin", "Natalia Denisenko", "Isabel Gortner", "Luke Fosdick", "Chiara Pulice", "Sarit Kraus", "V. S. Subrahmanian"], "title": "Context and Transcripts Improve Detection of Deepfake Audios of Public Figures", "comment": null, "summary": "Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).", "AI": {"tldr": "本研究提出了一种基于上下文的音频深度伪造检测器（CADD），通过利用上下文和/或文本信息显著提高了检测性能，并增强了对对抗性攻击的鲁棒性。", "motivation": "当前音频深度伪造检测器仅分析音频文件，忽略了上下文和文本信息，导致检测效果不佳。研究旨在通过引入上下文信息来提升检测的有效性和鲁棒性。", "method": "研究创建了一个由记者提供的深度伪造数据集（JDD），并生成了一个已故公众人物的合成音频数据集（SYN）。提出了新的上下文音频深度伪造检测器（CADD）架构，并在一系列公开数据集（ITW, P^2V, JDD, SYN）上进行了评估。实验对比了多基线音频深度伪造检测器和传统分类器，并在CADD中引入上下文和/或文本信息。", "result": "研究表明，上下文和/或文本信息能够显著提高音频深度伪造检测器的性能，F1分数、AUC和EER分别提高了5%-37.58%、3.77%-42.79%和6.17%-47.83%。CADD在面对五种对抗性逃避策略时表现出更强的鲁棒性，性能下降平均仅为-0.71%。", "conclusion": "上下文和/或文本信息对于提高音频深度伪造检测器的性能和鲁棒性至关重要，CADD架构是一种有效的方法。"}}
{"id": "2601.12698", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12698", "abs": "https://arxiv.org/abs/2601.12698", "authors": ["Qiuyi Qu", "Yicheng Sui", "Yufei Sun", "Rui Chen", "Xiaofei Zhang", "Yuzhi Zhang", "Haofeng Wang", "Ge Lan", "Ning Zhang"], "title": "A Two-Stage GPU Kernel Tuner Combining Semantic Refactoring and Search-Based Optimization", "comment": null, "summary": "GPU code optimization is a key performance bottleneck for HPC workloads as well as large-model training and inference. Although compiler optimizations and hand-written kernels can partially alleviate this issue, achieving near-hardware-limit performance still relies heavily on manual code refactoring and parameter tuning. Recent progress in LLM-agent-based kernel generation and optimization has been reported, yet many approaches primarily focus on direct code rewriting, where parameter choices are often implicit and hard to control, or require human intervention, leading to unstable performance gains. This paper introduces a template-based rewriting layer on top of an agent-driven iterative loop: kernels are semantically refactored into explicitly parameterizable templates, and template parameters are then optimized via search-based autotuning, yielding more stable and higher-quality speedups. Experiments on a set of real-world kernels demonstrate speedups exceeding 3x in the best case. We extract representative CUDA kernels from SGLang as evaluation targets; the proposed agentic tuner iteratively performs templating, testing, analysis, and planning, and leverages profiling feedback to execute constrained parameter search under hardware resource limits. Compared to agent-only direct rewriting, the template-plus-search design significantly reduces the randomness of iterative optimization, making the process more interpretable and enabling a more systematic approach toward high-performance configurations. The proposed method can be further extended to OpenCL, HIP, and other backends to deliver automated performance optimization for real production workloads.", "AI": {"tldr": "该研究提出了一种基于模板的重写层，结合基于搜索的自动调优，来优化 GPU 代码。与直接代码重写相比，这种方法提高了优化过程的稳定性和性能。", "motivation": "GPU 代码优化是高性能计算和大型模型训练/推理的关键瓶颈。现有的编译器优化和手动优化方法在达到接近硬件极限的性能方面存在不足，而基于 LLM-agent 的方法在参数控制和性能稳定性方面存在问题。", "method": "该方法首先将 GPU 内核重写为显式参数化的模板，然后通过基于搜索的自动调优来优化模板参数。该过程由一个 agent 驱动，进行迭代式的模板化、测试、分析和规划，并利用性能分析反馈在硬件资源限制下进行受约束的参数搜索。", "result": "在真实的 CUDA 内核上进行的实验表明，该方法在最佳情况下可实现超过 3 倍的速度提升。与仅使用 agent 直接重写的方法相比，该模板加搜索的设计显著降低了迭代优化的随机性，提高了可解释性，并实现了更系统的高性能配置。", "conclusion": "基于模板的重写层与 agent 驱动的迭代循环相结合，可以实现更稳定、更高质量的 GPU 代码性能提升。该方法易于扩展到其他后端，有望为实际生产工作负载提供自动性能优化。"}}
{"id": "2601.13465", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13465", "abs": "https://arxiv.org/abs/2601.13465", "authors": ["Yimeng Min", "Carla P. Gomes"], "title": "Graph Neural Networks are Heuristics", "comment": null, "summary": "We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.", "AI": {"tldr": "一篇研究表明，单次训练的图神经网络（GNN）可以作为组合优化（特别关注旅行商问题）的无监督启发式方法，通过编码全局结构约束生成直接前向传递的解决方案，无需搜索、监督或顺序决策。在推理时，dropout和快照集成技术能够让单个模型作为隐式集成，通过增加解决方案的多样性来减小最优性差距。", "motivation": "研究动机在于探索图神经网络（GNN）在组合优化问题中作为无监督启发式方法的能力，挑战了以往需要监督训练或显式搜索的观点，旨在实现GNN直接实例化新的启发式方法。", "method": "该研究采用图神经网络（GNN），并专注于旅行商问题。通过将全局结构约束编码为归纳偏置，实现了一个非自回归模型。在推理阶段，使用了dropout和快照集成技术。", "result": "研究结果表明，该模型能够通过直接前向传递生成解决方案，无需搜索、监督或顺序决策。在推理时，dropout和快照集成技术增加了解决方案的多样性，从而减小了最优性差距。", "conclusion": "研究结论是，图神经网络（GNN）不需要监督训练或显式搜索即可有效解决组合优化问题。它们能够内化全局组合结构，并直接作为强大的学习启发式方法。这重新定义了机器学习在组合优化中的作用，从增强经典算法转变为直接实例化新的启发式方法。"}}
{"id": "2601.12731", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12731", "abs": "https://arxiv.org/abs/2601.12731", "authors": ["Stefano Civelli", "Pietro Bernardelle", "Nicolò Brunello", "Gianluca Demartini"], "title": "A Shared Geometry of Difficulty in Multilingual Language Models", "comment": null, "summary": "Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.", "AI": {"tldr": "该研究通过在21种语言的Easy2Hard基准测试的AMC子集上训练线性探针，研究了大型语言模型（LLM）中问题难度的多语言几何特性。结果表明，问题难度信号在模型的浅层和深层内部表示中分别出现，且表现出不同的功能行为。", "motivation": "探索大型语言模型（LLM）在处理不同语言时，对问题难度的内部表示是否存在跨语言共性，以及这种表示如何随模型层数变化。", "method": "使用Easy2Hard基准测试的AMC子集，并将其翻译成21种语言。在LLM的内部表示上训练线性探针，以预测问题难度。比较在浅层和深层表示上训练的探针的性能，以及它们的跨语言泛化能力。", "result": "问题难度信号在模型的浅层（早期层）和深层（后期层）内部表示中分别出现。深层表示的探针在同一语言上表现良好，但在跨语言评估上泛化能力差。浅层表示的探针跨语言泛化能力更强，尽管在同一语言上的性能较低。", "conclusion": "LLM首先形成一个与语言无关的问题难度表示，然后该表示逐渐变得语言特定。这一过程与LLM解释性研究中发现的模型倾向于先在一个抽象概念空间中操作，然后再产生语言特定输出的观点一致。该研究表明，这种两阶段表示过程不仅限于语义内容，也适用于问题难度估计等高级元认知属性。"}}
{"id": "2601.13481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13481", "abs": "https://arxiv.org/abs/2601.13481", "authors": ["Jian Zhang", "Zhangqi Wang", "Zhiyuan Wang", "Weiping Fu", "Yu He", "Haiping Zhu", "Qika Lin", "Jun Liu"], "title": "Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement", "comment": null, "summary": "Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.", "AI": {"tldr": "提出了一种名为 APOLO 的框架，通过自动化提示优化来提高大型语言模型在精神健康领域的诊断准确性和鲁棒性，解决了情绪共病和线索探索效率低下的问题。", "motivation": "现有的大型语言模型在识别精神健康文本中的情绪时，对提示设计敏感，并且难以处理情绪共病和效率低下的问题。", "method": "APOLO 将指令优化表述为一个部分可观察马尔可夫决策过程，并采用一种多智能体协作机制（包括规划者、教师、评论家、学生和目标智能体）来迭代地优化提示。", "result": "APOLO 在领域特定和分层基准测试中始终提高了诊断准确性和鲁棒性。", "conclusion": "APOLO 提供了一个可扩展且通用的范式，可以增强大型语言模型在精神健康护理中的可信度。"}}
{"id": "2601.12243", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12243", "abs": "https://arxiv.org/abs/2601.12243", "authors": ["Shreya Rajpal", "Michal Golovanesky", "Carsten Eickhoff"], "title": "Less is More: Label-Guided Summarization of Procedural and Instructional Videos", "comment": "22 pages, 6 figures", "summary": "Video summarization helps turn long videos into clear, concise representations that are easier to review, document, and analyze, especially in high-stakes domains like surgical training. Prior work has progressed from using basic visual features like color, motion, and structural changes to using pre-trained vision-language models that can better understand what's happening in the video (semantics) and capture temporal flow, resulting in more context-aware video summarization. We propose a three-stage framework, PRISM: Procedural Representation via Integrated Semantic and Multimodal analysis, that produces semantically grounded video summaries. PRISM combines adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model (LLM). Our method ensures that selected frames reflect meaningful and procedural transitions while filtering out generic or hallucinated content, resulting in contextually coherent summaries across both domain-specific and instructional videos. We evaluate our method on instructional and activity datasets, using reference summaries for instructional videos. Despite sampling fewer than 5% of the original frames, our summaries retain 84% semantic content while improving over baselines by as much as 33%. Our approach generalizes across procedural and domain-specific video tasks, achieving strong performance with both semantic alignment and precision.", "AI": {"tldr": "本文提出了一种名为 PRISM 的三阶段视频摘要框架，该框架通过集成语义和多模态分析，利用自适应采样、标签驱动的关键帧锚定和大型语言模型（LLM）进行上下文验证，生成语义准确、过程连贯的视频摘要。", "motivation": "现有视频摘要方法在理解视频内容和时间流动方面仍有不足，尤其是在外科手术培训等高风险领域。预训练的视觉-语言模型虽然有所进步，但仍需更有效的机制来生成既有意义又准确的摘要。", "method": "PRISM 框架包含三个阶段：1. 自适应视觉采样，根据视频内容动态选择采样帧；2. 标签驱动的关键帧锚定，利用视频标签来定位重要的程序性过渡帧；3. 上下文验证，使用大型语言模型（LLM）来确保摘要的连贯性和过滤掉不相关或生成的内容。", "result": "PRISM 方法在教学视频和活动数据集上进行了评估。在仅采样不到 5% 的原始帧的情况下，PRISM 摘要保留了 84% 的语义内容，并在语义内容和精度方面均优于基线方法，最高提升 33%。", "conclusion": "PRISM 框架能够生成语义连贯、过程准确的视频摘要，并且在教学视频和特定领域视频任务中都表现出良好的泛化能力和性能。"}}
{"id": "2601.12748", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12748", "abs": "https://arxiv.org/abs/2601.12748", "authors": ["Bin Xie", "Bingbing Xu", "Xueyun Tian", "Yilin Chen", "Huawei Shen"], "title": "Towards Robust Process Reward Modeling via Noise-aware Learning", "comment": null, "summary": "Process Reward Models (PRMs) have achieved strong results in complex reasoning, but are bottlenecked by costly process-level supervision. A widely used alternative, Monte Carlo Estimation (MCE), defines process rewards as the probability that a policy model reaches the correct final answer from a given reasoning step. However, step correctness is an intrinsic property of the reasoning trajectory, and should be invariant to policy choice. Our empirical findings show that MCE producing policy-dependent rewards that induce label noise, including false positives that reward incorrect steps and false negatives that penalize correct ones. To address above challenges, we propose a two-stage framework to mitigate noisy supervision. In the labeling stage, we introduce a reflection-aware label correction mechanism that uses a large language model (LLM) as a judge to detect reflection and self-correction behaviors related to the current reasoning step, thereby suppressing overestimated rewards. In the training stage, we further propose a \\underline{\\textbf{N}}oise-\\underline{\\textbf{A}}ware \\underline{\\textbf{I}}terative \\underline{\\textbf{T}}raining framework that enables the PRM to progressively refine noisy labels based on its own confidence. Extensive Experiments show that our method substantially improves step-level correctness discrimination, achieving up to a 27\\% absolute gain in average F1 over PRMs trained with noisy supervision.", "AI": {"tldr": "该研究提出了一种改进的PRM训练框架，通过引入LLM进行反射和纠错识别来减少监督噪声，并采用基于置信度的迭代训练来逐步精炼标签，显著提高了推理步骤的正确性。", "motivation": "现有的PRM虽然在复杂推理任务上表现出色，但依赖昂贵的步骤级监督。MCE作为一种替代方法，其步骤奖励依赖于策略模型，容易产生策略依赖的奖励，导致标签噪声，包括错误奖励和错误惩罚。", "method": "提出一个两阶段框架来缓解监督噪声。第一阶段（标记阶段）引入了反射感知标签校正机制，利用LLM作为裁判来检测与当前推理步骤相关的反射和自我纠正行为，以抑制过高的奖励。第二阶段（训练阶段）提出了噪声感知迭代训练（NAIT）框架，使PRM能够根据自身的置信度逐步精炼有噪声的标签。", "result": "所提出的方法显著提高了步骤级正确性的判别能力，在平均F1分数上相比于使用噪声监督训练的PRM，获得了高达27%的绝对增益。", "conclusion": "该研究提出的两阶段框架，结合LLM的反射识别和NAIT的迭代精炼，有效解决了MCE产生的策略依赖和标签噪声问题，显著提升了PRM在复杂推理任务中的性能。"}}
{"id": "2601.12249", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12249", "abs": "https://arxiv.org/abs/2601.12249", "authors": ["Ehsan Sadeghi Pour", "Mahdi Esmaeili", "Morteza Romoozi"], "title": "An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion", "comment": "13 page", "summary": "Breast cancer is one of the most common cancers among women worldwide, and its accurate and timely diagnosis plays a critical role in improving treatment outcomes. This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating the Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures. The proposed approach utilizes Multi-Scale Feature Fusion to enhance the extraction of features from benign and malignant tissues and combines Dice Loss and Focal Loss functions to improve the model's learning process, effectively reducing errors in binary breast cancer classification and achieving high accuracy and efficiency. In this study, a comprehensive dataset of breast cancer images from INbreast, MIAS, and DDSM was preprocessed through data augmentation and contrast enhancement and resized to 227x227 pixels for model training. Leveraging the Transformer's ability to manage long-range dependencies with Self-Attention mechanisms, the proposed model achieved high accuracy in detecting cancerous masses, outperforming foundational models such as BreastNet, DeepMammo, Multi-Scale CNN, Swin-Unet, and SegFormer. The final evaluation results for the proposed model include an accuracy of 98.5\\%, sensitivity of 97.8\\%, specificity of 96.3\\%, F1-score of 98.2\\%, and overall precision of 97.9\\%. These metrics demonstrate a significant improvement over traditional methods and confirm the model's effectiveness in identifying cancerous masses in complex scenarios and large datasets. This model shows potential as a reliable and efficient tool for breast cancer diagnosis and can be effectively integrated into medical diagnostic systems.", "AI": {"tldr": "本论文提出了一种结合金字塔自适应空洞卷积 (PAAC) 和 Transformer 架构的乳腺癌检测新框架，通过多尺度特征融合和 Dice Loss 与 Focal Loss 的组合，在综合数据集上实现了 98.5% 的准确率，优于现有模型。", "motivation": "乳腺癌是女性最常见的癌症之一，准确及时的诊断对改善治疗效果至关重要。本研究旨在提高乳腺X线摄影图像中恶性肿块的检测精度和效率。", "method": "使用金字塔自适应空洞卷积 (PAAC) 和 Transformer 架构，结合多尺度特征融合，并采用 Dice Loss 和 Focal Loss 进行模型训练。在 INbreast、MIAS 和 DDSM 数据集上进行实验，数据预处理包括数据增强和对比度增强，图像尺寸调整为 227x227 像素。", "result": "提出的模型在综合数据集上取得了 98.5% 的准确率、97.8% 的敏感性、96.3% 的特异性、98.2% 的 F1 分数和 97.9% 的整体精确度，优于 BreastNet、DeepMammo、Multi-Scale CNN、Swin-Unet 和 SegFormer 等基础模型。", "conclusion": "所提出的 PAAC 和 Transformer 结合的模型在乳腺癌检测方面表现出高精度和高效率，在复杂场景和大型数据集下都能有效识别癌性肿块，显示出作为可靠的医学诊断工具的潜力。"}}
{"id": "2601.13518", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.13518", "abs": "https://arxiv.org/abs/2601.13518", "authors": ["Jiayi Yuan", "Jonathan Nöther", "Natasha Jaques", "Goran Radanović"], "title": "AgenticRed: Optimizing Agentic Systems for Automated Red-teaming", "comment": "Website: https://yuanjiayiy.github.io/AgenticRed/", "summary": "While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.", "AI": {"tldr": "提出了一种名为AgenticRed的自动化红队测试方法，该方法利用大型语言模型的上下文学习能力，无需人工干预即可迭代设计和优化红队测试系统。与预定义工作流不同，AgenticRed将红队测试视为系统设计问题，并采用进化选择方法来演进代理系统。实验结果表明，AgenticRed设计的系统在多种模型上取得了优于现有最先进方法的攻击成功率，并表现出良好的模型迁移能力。", "motivation": "现有自动化红队测试方法依赖于人工指定的工作流程，这种方式存在人类偏见且探索设计空间成本高昂。研究旨在开发一种无需人工干预、能够迭代设计和优化红队测试系统的自动化方法。", "method": "AgenticRed利用大型语言模型的上下文学习能力，将红队测试视为一个系统设计问题。通过一种新颖的进化选择程序，对代理系统进行演进，以自动设计和优化红队测试系统。", "result": "AgenticRed设计的红队测试系统在Llama-2-7B和Llama-3-8B模型上取得了显著更高的攻击成功率（分别达到96%和98%）。该方法对专有模型也表现出强大的迁移能力，在GPT-3.5-Turbo和GPT-4o-mini上达到100%攻击成功率，在Claude-Sonnet-3.5上达到60%攻击成功率。", "conclusion": "自动化系统设计是AI安全评估的一种强大范式，能够跟上快速发展的模型。AgenticRed通过自动化系统设计，成功地设计出了比现有方法更有效的红队测试系统，并证明了其在不同模型上的有效性和迁移能力。"}}
{"id": "2601.12233", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12233", "abs": "https://arxiv.org/abs/2601.12233", "authors": ["Zhenzhen Wang", "Zhongliang Zhou", "Zhuoyu Wen", "Jeong Hwan Kook", "John B Wojcik", "John Kang"], "title": "DiffusionQC: Artifact Detection in Histopathology via Diffusion Model", "comment": "7 pages", "summary": "Digital pathology plays a vital role across modern medicine, offering critical insights for disease diagnosis, prognosis, and treatment. However, histopathology images often contain artifacts introduced during slide preparation and digitization. Detecting and excluding them is essential to ensure reliable downstream analysis. Traditional supervised models typically require large annotated datasets, which is resource-intensive and not generalizable to novel artifact types. To address this, we propose DiffusionQC, which detects artifacts as outliers among clean images using a diffusion model. It requires only a set of clean images for training rather than pixel-level artifact annotations and predefined artifact types. Furthermore, we introduce a contrastive learning module to explicitly enlarge the distribution separation between artifact and clean images, yielding an enhanced version of our method. Empirical results demonstrate superior performance to state-of-the-art and offer cross-stain generalization capacity, with significantly less data and annotations.", "AI": {"tldr": "提出了一种名为 DiffusionQC 的新方法，利用扩散模型检测数字病理图像中的伪影，仅需干净图像进行训练，无需像素级标注，并结合对比学习增强效果，在伪影检测上优于现有方法。", "motivation": "传统的监督学习方法需要大量标注数据且泛化性差，难以适应新型伪影。数字病理图像中的伪影会影响下游分析的可靠性，因此需要一种更有效、更通用的伪影检测方法。", "method": "利用扩散模型将伪影检测为干净图像中的异常值。训练过程中仅需干净图像，无需伪影标注。引入对比学习模块来明确区分伪影和干净图像的分布。", "result": "DiffusionQC 方法在伪影检测上表现优于现有最先进的方法，并具备跨染色泛化能力，且所需数据和标注量显著减少。", "conclusion": "DiffusionQC 是一种无需大量标注数据和预定义伪影类型即可有效检测数字病理图像伪影的方法，通过扩散模型和对比学习的结合，提高了检测性能和泛化能力。"}}
{"id": "2601.13533", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13533", "abs": "https://arxiv.org/abs/2601.13533", "authors": ["Changshuo Zhang"], "title": "Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models", "comment": null, "summary": "Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the \"reason first, recommend later\" paradigm to achieve \"reasoning while recommending\", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.", "AI": {"tldr": "提出了一种名为EGLR的熵引导潜在推理模型，用于解决生成式重排场景中模型难度动态变化导致精准捕获复杂偏好的挑战。该模型能够实时推理并进行推荐，通过熵引导的可变长度推理和动态温度调整实现探索与利用的平衡，并且易于集成到现有模型中。", "motivation": "现有生成式重排方法难以适应模型难度动态变化导致的熵变化，从而难以准确捕捉用户复杂偏好。受语言模型整合推理能力的启发，作者希望引入一种新的机制来解决这个问题。", "method": "引入了一个潜在推理机制，并基于此提出了熵引导潜在推理（EGLR）推荐模型。该模型的核心在于：1. 实现“边推理边推荐”的范式；2. 采用熵引导的可变长度推理，结合上下文感知推理令牌和动态温度调整；3. 采用轻量级集成设计。", "result": "实验证明，潜在推理机制有效降低了模型决策过程中的熵。EGLR模型在两个真实数据集上验证了其有效性，能够提升现有生成式重排模型的性能。", "conclusion": "EGLR模型通过实时推理、熵引导的可变长度推理以及轻量级集成设计，有效地解决了生成式重排中模型难度变化带来的挑战，并在实际应用中展现出巨大的潜力。"}}
{"id": "2601.12253", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12253", "abs": "https://arxiv.org/abs/2601.12253", "authors": ["Haoran Xu", "Jiaze Li", "Jianzhong Ju", "Zhenbo Luo"], "title": "Federated Joint Learning for Domain and Class Generalization", "comment": "ICASSP 2026", "summary": "Efficient fine-tuning of visual-language models like CLIP has become crucial due to their large-scale parameter size and extensive pretraining requirements. Existing methods typically address either the issue of unseen classes or unseen domains in isolation, without considering a joint framework for both. In this paper, we propose \\textbf{Fed}erated Joint Learning for \\textbf{D}omain and \\textbf{C}lass \\textbf{G}eneralization, termed \\textbf{FedDCG}, a novel approach that addresses both class and domain generalization in federated learning settings. Our method introduces a domain grouping strategy where class-generalized networks are trained within each group to prevent decision boundary confusion. During inference, we aggregate class-generalized results based on domain similarity, effectively integrating knowledge from both class and domain generalization. Specifically, a learnable network is employed to enhance class generalization capabilities, and a decoupling mechanism separates general and domain-specific knowledge, improving generalization to unseen domains. Extensive experiments across various datasets show that \\textbf{FedDCG} outperforms state-of-the-art baselines in terms of accuracy and robustness.", "AI": {"tldr": "提出了一种名为FedDCG的联邦学习方法，用于同时解决视觉-语言模型在联邦设置下的类别泛化和领域泛化问题。", "motivation": "现有的视觉-语言模型微调方法在处理未见类别或未见领域时存在孤立性，缺乏一个统一的框架来同时处理这两个挑战，尤其是在联邦学习的场景下。", "method": "FedDCG方法引入了领域分组策略，在每个组内训练类别泛化网络以避免决策边界混淆。在推理时，根据领域相似性聚合类别泛化结果。该方法还采用了一个可学习的网络来增强类别泛化能力，并通过解耦机制分离通用和领域特定知识，以提高对未见领域的泛化能力。", "result": "FedDCG在多个数据集上的广泛实验表明，该方法在准确性和鲁棒性方面优于现有的最先进的基线方法。", "conclusion": "FedDCG是一种有效的联邦学习框架，能够同时实现视觉-语言模型在类别和领域上的泛化，并在实验中展现出优越的性能。"}}
{"id": "2601.12758", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12758", "abs": "https://arxiv.org/abs/2601.12758", "authors": ["Shenyan Zheng", "Jiayou Zhong", "Anudeex Shetty", "Heng Ji", "Preslav Nakov", "Usman Naseem"], "title": "VISPA: Pluralistic Alignment via Automatic Value Selection and Activation", "comment": "WIP", "summary": "As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.", "AI": {"tldr": "VISPA 是一个训练无关的框架，可以通过动态选择和内部模型激活来控制和表达价值观，以实现大规模语言模型（LLM）的多元化对齐。", "motivation": "目前的 LLM 在高风险领域的应用需要它们能够反映多样化的观点，而不仅仅是平均观点。现有方法在价值控制和代表性方面存在不足。", "method": "VISPA 通过动态选择和内部模型激活进行引导，实现直接的价值观表达控制，是一种训练无关的框架。", "result": "VISPA 在多种模型和评估设置下，在医疗保健及其他领域的多元化对齐模式中表现出色。该方法具有适应性，可与不同的引导方式、模型和价值观协同工作。", "conclusion": "通过内部激活机制可以实现多元化对齐，为开发能服务于所有人的可扩展语言模型提供了途径。"}}
{"id": "2601.12812", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12812", "abs": "https://arxiv.org/abs/2601.12812", "authors": ["Sushant Kumar Ray", "Gautam Siddharth Kashyap", "Sahil Tripathi", "Nipun Joshi", "Vijay Govindarajan", "Rafiq Ali", "Jiechao Gao", "Usman Naseem"], "title": "Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?", "comment": "Accepted at EACL 2026 (Industry Track)", "summary": "Clinical Question-Answering (CQA) industry systems are increasingly rely on Large Language Models (LLMs), yet their deployment is often guided by the assumption that domain-specific fine-tuning is essential. Although specialised medical LLMs such as BioBERT, BioGPT, and PubMedBERT remain popular, they face practical limitations including narrow coverage, high retraining costs, and limited adaptability. Efforts based on Supervised Fine-Tuning (SFT) have attempted to address these assumptions but continue to reinforce what we term the SPECIALISATION FALLACY-the belief that specialised medical LLMs are inherently superior for CQA. To address this assumption, we introduce MEDASSESS-X, a deployment-industry-oriented CQA framework that applies alignment at inference time rather than through SFT. MEDASSESS-X uses lightweight steering vectors to guide model activations toward medically consistent reasoning without updating model weights or requiring domain-specific retraining. This inference-time alignment layer stabilises CQA performance across both general-purpose and specialised medical LLMs, thereby resolving the SPECIALISATION FALLACY. Empirically, MEDASSESS-X delivers consistent gains across all LLM families, improving Accuracy by up to +6%, Factual Consistency by +7%, and reducing Safety Error Rate by as much as 50%.", "AI": {"tldr": "本研究提出了MEDASSESS-X框架，通过在推理时使用轻量级引导向量来对齐LLM，而非进行领域特定的微调（SFT），从而解决了“专业化谬误”，即认为特定医学LLM在CQA任务上更优的假设。MEDASSESS-X在通用和专业LLM上均能稳定提升CQA性能。", "motivation": "当前CQA系统依赖LLM，但普遍认为需要领域特定的微调。然而，现有的专业医学LLM存在覆盖范围窄、重训成本高、适应性差等问题。研究旨在打破“专业化谬误”，提出一种更高效、灵活的CQA解决方案。", "method": "提出MEDASSESS-X框架，该框架在推理时通过轻量级引导向量（steering vectors）来引导模型激活，使其朝着医学一致性推理方向发展，而无需更新模型权重或进行领域特定重训。这种推理时对齐层可以稳定通用和专业LLM在CQA任务上的表现。", "result": "MEDASSESS-X框架在所有LLM家族中均实现了持续的性能提升，准确率（Accuracy）提高了高达+6%，事实一致性（Factual Consistency）提高了+7%，并将安全错误率（Safety Error Rate）降低了高达50%。", "conclusion": "MEDASSESS-X框架通过在推理时进行对齐，成功解决了“专业化谬误”，证明了即使是通用LLM，通过适当的推理时引导也能在CQA任务上达到与甚至超越专业LLM的性能，并且具有更高的效率和灵活性。"}}
{"id": "2601.13546", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13546", "abs": "https://arxiv.org/abs/2601.13546", "authors": ["Hui Sun", "Chang Xu", "Haonan Xie", "Hao Li", "Yuhao Huang", "Chuheng Zhang", "Ming Jin", "Xiaoguang Liu", "Gang Wang", "Jiang Bian"], "title": "ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution", "comment": null, "summary": "LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.", "AI": {"tldr": "本研究提出了一种名为TSEvol的多智能体时间序列演化算法，并构建了包含2万个样本的时间序列异常检测（AD）推理和多轮对话数据集TSEData-20K。基于此，研究人员开发了ChatAD系列模型，并引入TS Kahneman-Tversky Optimization（TKTO）以增强其跨任务泛化能力。最后，通过LLADBench基准测试，验证了ChatAD模型在AD任务上的优越性能。", "motivation": "现有基于LLM的时间序列异常检测方法在推理能力、多轮对话能力和泛化性方面存在不足。", "method": "1. 提出多智能体时间序列演化算法TSEvol。\n2. 构建AD推理和多轮对话数据集TSEData-20K，并开发ChatAD系列模型。\n3. 提出TS Kahneman-Tversky Optimization（TKTO）以增强ChatAD的跨任务泛化能力。\n4. 提出LLM驱动的AD基准测试LLADBench。", "result": "ChatAD模型在准确率、F1分数和误报率方面取得显著提升（最高分别提升34.50%、34.71%，误报率降低37.42%）。经TKTO优化后，ChatAD在分类、预测和填充等任务上展现出具有竞争力的推理和跨任务泛化性能。", "conclusion": "TSEvol算法、TSEData-20K数据集和ChatAD模型显著提升了LLM在时间序列异常检测任务上的性能，尤其是在推理和多轮对话能力方面。TKTO优化进一步增强了模型的泛化能力，LLADBench为评估此类模型提供了标准。"}}
{"id": "2601.13545", "categories": ["cs.AI", "cs.ET", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13545", "abs": "https://arxiv.org/abs/2601.13545", "authors": ["Shirin Shahabi", "Spencer Graham", "Haruna Isah"], "title": "TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning", "comment": "16 pages, 6 figures, 2 tables", "summary": "Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com", "AI": {"tldr": "本文提出了一种名为TruthTensor的新颖、可复现的评估框架，用于评估大型语言模型（LLMs）作为在动态、高熵环境中运作的人类模仿系统，而不仅仅是预测引擎。该框架结合了实时预测市场、概率评分、漂移诊断和鲁棒性检查，以提供模型行为的整体视图，并在准确性、校准、风险敏感性等方面进行了多维度评估。", "motivation": "现有的语言模型和AI代理评估方法在捕捉现实世界的不确定性、分布变化以及孤立任务准确性与人在不断变化条件下的决策能力之间的差距方面存在根本性挑战。静态基准测试无法反映真实世界的复杂性。", "method": "TruthTensor框架基于前瞻性、无污染的任务，将评估锚定在实时预测市场，并结合概率评分。它通过漂移中心诊断和显式的鲁棒性检查来补充传统的正确性指标，以确保可复现性。框架明确了人类与自动化评估的角色、标注协议和统计测试程序，并使用了多维度指标（准确性、校准、叙事稳定性、成本和资源效率）进行评估。", "result": "在超过500个真实市场的实验中，TruthTensor表明具有相似预测准确性的模型在校准、漂移和风险敏感性方面可能存在显著差异。这强调了在多个维度上评估模型（准确性、校准、叙事稳定性、成本和资源效率）的必要性。", "conclusion": "TruthTensor成功地操作化了现代评估最佳实践，包括清晰的假设构建、仔细的指标选择、透明的计算/成本报告、人机循环验证以及开放、版本化的评估契约，从而在真实世界决策环境中对LLMs产生可辩护的评估。该框架为LLMs的评估提供了一个更全面、更现实的视角。"}}
{"id": "2601.12257", "categories": ["cs.CV", "cs.AI", "cs.CG", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.12257", "abs": "https://arxiv.org/abs/2601.12257", "authors": ["Fadlullah Raji", "John Murray-Bruce"], "title": "Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy", "comment": null, "summary": "Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, however, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into \\textit{light-occluding} and \\textit{non-light-occluding} components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: A gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination.", "AI": {"tldr": "本文提出了一种从普通照片中重建隐藏场景三维结构的新方法，该场景通过其在可见墙壁上投下的阴影间接成像。研究人员开发了一种新的光传输模型，并提出了两种解决方案：基于梯度的优化方法和一种名为Soft Shadow diffusion (SSD) 的物理启发式神经网络方法，SSD在模拟和真实世界场景中都表现出良好的泛化能力和鲁棒性。", "motivation": "传统的成像技术需要视线才能进行准确的场景重建，但在某些情况下，视线可能不可行、危险或不可能获得。非视线（NLOS）成像旨在解决这一挑战，而本文的动机是扩展目前仅限于低分辨率或已知形状的物体定位的被动NLOS方法，实现更通用的三维隐藏场景重建。", "method": "作者提出了一种新的光传输模型，将隐藏场景分解为“遮光”和“非遮光”组件，从而形成一个可分离的非线性最小二乘（SNLLS）逆问题。他们开发了两种求解方法：一种是基于梯度的优化方法，另一种是名为Soft Shadow diffusion (SSD) 的物理启发式神经网络方法。", "result": "所提出的方法能够从普通的NLOS照片中实现隐藏场景的三维重建。SSD方法在模拟中训练，但能够很好地泛化到模拟中的未见类别和真实世界的NLOS场景。此外，SSD对噪声和环境光照表现出令人惊讶的鲁棒性。", "conclusion": "本文成功地将基于阴影的被动NLOS成像技术从一维或低分辨率二维扩展到了三维场景重建。提出的SNLLS逆问题框架和SSD神经网络方法为解决具有挑战性的NLOS成像问题提供了有效且鲁棒的解决方案。"}}
{"id": "2601.12771", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12771", "abs": "https://arxiv.org/abs/2601.12771", "authors": ["Keito Inoshita"], "title": "Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory", "comment": null, "summary": "Large language models (LLMs) possess extensive world knowledge, yet methods for effectively eliciting this knowledge remain underexplored. Nationality and region prediction tasks require understanding of not only linguistic features but also cultural and historical background, making LLM world knowledge particularly valuable. However, conventional LLM prompting methods rely on direct reasoning approaches, which have limitations in applying abstract linguistic rules. We propose LLM Associative Memory Agents (LAMA), a novel framework that leverages LLM world knowledge as associative memory. Rather than directly inferring nationality from names, LAMA recalls famous individuals with the same name and aggregates their nationalities through indirect reasoning. A dual-agent architecture comprising a Person Agent and a Media Agent, specialized in different knowledge domains, recalls famous individuals in parallel, generating Top-1 predictions through voting and Top-K predictions through conditional completion. On a 99-country nationality prediction task, LAMA achieved 0.817 accuracy, substantially outperforming conventional LLM prompting methods and neural models. Our experiments reveal that LLMs exhibit higher reliability in recalling concrete examples than in abstract reasoning, that recall-based approaches are robust to low-frequency nationalities independent of data frequency distributions, and that the dual-agent architecture functions complementarily to produce synergistic effects. These results demonstrate the effectiveness of a new multi-agent system that retrieves and aggregates LLM knowledge rather than prompting reasoning.", "AI": {"tldr": "本文提出了一种名为 LLM 关联记忆代理 (LAMA) 的新框架，它利用大型语言模型 (LLM) 的世界知识作为关联记忆，通过检索和聚合信息来执行国籍预测任务，并在实验中取得了显著优于传统方法的结果。", "motivation": "现有的大型语言模型（LLM）拥有丰富的世界知识，但如何有效激发这些知识仍是未被充分探索的领域。国籍和地区预测任务需要理解语言特征以及文化和历史背景，这使得 LLM 的世界知识尤为宝贵。然而，传统的 LLM 提示方法依赖于直接推理，在应用抽象语言规则方面存在局限性。", "method": "本文提出了一种名为 LLM 关联记忆代理 (LAMA) 的新框架。LAMA 采用双代理架构，包括一个专门处理人物知识的“人物代理”和一个专门处理媒体知识的“媒体代理”。这两个代理并行检索与给定姓名相关的著名人物，然后通过投票机制聚合这些人物的国籍信息，生成 Top-1 预测。对于 Top-K 预测，则采用条件完成的方式。", "result": "在包含 99 个国家的国籍预测任务上，LAMA 达到了 0.817 的准确率，显著优于传统的 LLM 提示方法和神经模型。实验表明，LLM 在回忆具体例子方面比抽象推理更可靠；基于回忆的方法对低频国籍具有鲁棒性，且不受数据频率分布影响；双代理架构能够互补协同，产生增效作用。", "conclusion": "LAMA 框架有效地利用了 LLM 的世界知识作为关联记忆，通过检索和聚合信息而非直接推理，在国籍预测任务上取得了优异的性能。这证明了一种新的多代理系统在激发和应用 LLM 知识方面的有效性。"}}
{"id": "2601.12272", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12272", "abs": "https://arxiv.org/abs/2601.12272", "authors": ["Shahrzad Esmat", "Mahdi Banisharif", "Ali Jannesari"], "title": "AgenticPruner: MAC-Constrained Neural Network Compression via LLM-Driven Strategy Search", "comment": "38 pages, 2 figures, 14 tables", "summary": "Neural network pruning remains essential for deploying deep learning models on resource-constrained devices, yet existing approaches primarily target parameter reduction without directly controlling computational cost. This yields unpredictable inference latency in deployment scenarios where strict Multiply-Accumulate (MAC) operation budgets must be met. We propose AgenticPruner, a framework utilizing large language models to achieve MAC-constrained optimization through iterative strategy learning. Our approach coordinates three specialized agents: a Profiling Agent that analyzes model architecture and MAC distributions, a Master Agent that orchestrates the workflow with divergence monitoring, and an Analysis Agent powered by Claude 3.5 Sonnet that learns optimal strategies from historical attempts. Through in-context learning, the Analysis Agent improves convergence success rate from 48% to 71% compared to grid search. Building upon isomorphic pruning's graph-based structural grouping, our method adds context-aware adaptation by analyzing patterns across pruning iterations, enabling automatic convergence to target MAC budgets within user-defined tolerance bands.\n  We validate our framework on ImageNet-1K across ResNet, ConvNeXt, and DeiT architectures. On CNNs, our approach achieves MAC targeting while maintaining or improving accuracy: ResNet-50 reaches 1.77G MACs with 77.04% accuracy (+0.91% vs baseline); ResNet-101 achieves 4.22G MACs with 78.94% accuracy (+1.56% vs baseline). For ConvNeXt-Small, pruning to 8.17G MACs yields 1.41x GPU and 1.07x CPU speedup with 45% parameter reduction. On Vision Transformers, we demonstrate MAC-budget compliance within user-defined tolerance bands (typically +1% to +5% overshoot, -5% to -15% undershoot), establishing feasibility for deployment scenarios requiring strict computational guarantees.", "AI": {"tldr": "本文提出了一种名为 AgenticPruner 的框架，利用大型语言模型（LLM）通过迭代策略学习来实现 MAC（乘加运算）约束下的模型剪枝优化，旨在解决现有剪枝方法仅关注参数减少而忽视计算成本的问题，从而实现可预测的推理延迟。", "motivation": "现有深度学习模型剪枝方法主要侧重于减少参数数量，但无法直接控制计算成本（MAC操作），导致在对推理延迟有严格要求的部署场景下，模型性能不稳定。研究者希望开发一种能够直接满足 MAC 操作预算的优化方法。", "method": "AgenticPruner 框架包含三个智能体：1. 分析模型架构和 MAC 分布的**分析智能体**；2. 协调工作流程并监控模型发散情况的**主控智能体**；3. 利用 Claude 3.5 Sonnet LLM，通过上下文学习（in-context learning）从历史尝试中学习最优剪枝策略的**分析智能体**。该方法结合了同构剪枝的结构分组，并通过分析跨迭代的模式进行上下文感知适应，从而自动收敛到目标 MAC 预算。", "result": "在 ImageNet-1K 数据集上，AgenticPruner 在 ResNet、ConvNeXt 和 DeiT 架构上进行了验证。对于 CNN，该方法在满足 MAC 目标的同时，保持甚至提高了准确率：ResNet-50 达到 1.77G MACs 且准确率为 77.04%（比基线提高 0.91%）；ResNet-101 达到 4.22G MACs 且准确率为 78.94%（比基线提高 1.56%）。ConvNeXt-Small 剪枝至 8.17G MACs 后，实现了 1.41 倍 GPU 和 1.07 倍 CPU 加速，同时参数减少了 45%。对于 Vision Transformers，该方法实现了在用户定义的容差范围内（通常为 +1% 至 +5% 超出，-5% 至 -15% 欠幅）满足 MAC 预算。", "conclusion": "AgenticPruner 框架通过利用 LLM 进行迭代策略学习，成功实现了 MAC 约束下的模型剪枝优化，克服了传统剪枝方法在计算成本控制上的不足。该方法能够在保持或提升模型精度的同时，有效控制计算预算，并在不同类型的模型架构上表现出良好的有效性，为资源受限设备的模型部署提供了可预测的推理性能保证。"}}
{"id": "2601.12815", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12815", "abs": "https://arxiv.org/abs/2601.12815", "authors": ["Zhaolu Kang", "Junhao Gong", "Qingxi Chen", "Hao Zhang", "Jiaxin Liu", "Rong Fu", "Zhiyuan Feng", "Yuan Wang", "Simon Fong", "Kaiyue Zhou"], "title": "Multimodal Multi-Agent Empowered Legal Judgment Prediction", "comment": null, "summary": "Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.", "AI": {"tldr": "本文提出了一个名为JurisMMA的新法律判决预测框架，并构建了一个包含超过10万条中国司法记录的JurisMM数据集，该框架在法律判决预测任务上表现出色，并有望应用于更广泛的法律领域。", "motivation": "传统法律判决预测方法在处理多项指控、多样化证据以及适应性方面存在挑战，因此需要新的方法和数据集来改进。 ", "method": "提出JurisMMA框架，将审判任务分解并组织成不同阶段；构建了包含文本和多模态音视频数据的JurisMM数据集；在JurisMM和LawBench数据集上进行了实验验证。", "result": "JurisMMA框架在JurisMM和LawBench数据集上均表现出有效性，证明了其在法律判决预测任务上的能力。", "conclusion": "JurisMMA框架不仅能有效进行法律判决预测，还能应用于更广泛的法律领域，为未来法律方法和数据集的发展提供了新思路。"}}
{"id": "2601.12282", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12282", "abs": "https://arxiv.org/abs/2601.12282", "authors": ["Pralaypati Ta", "Sriram Venkatesaperumal", "Keerthi Ram", "Mohanasankar Sivaprakasam"], "title": "CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training", "comment": null, "summary": "The functions of different regions of the human brain are closely linked to their distinct cytoarchitecture, which is defined by the spatial arrangement and morphology of the cells. Identifying brain regions by their cytoarchitecture enables various scientific analyses of the brain. However, delineating these areas manually in brain histological sections is time-consuming and requires specialized knowledge. An automated approach is necessary to minimize the effort needed from human experts. To address this, we propose CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. CytoCLIP comprises two model variants: one is trained using low-resolution whole-region images to understand the overall cytoarchitectural pattern of an area, and the other is trained on high-resolution image tiles for detailed cellular-level representation. The training dataset is created from NISSL-stained histological sections of developing fetal brains of different gestational weeks. It includes 86 distinct regions for low-resolution images and 384 brain regions for high-resolution tiles. We evaluate the model's understanding of the cytoarchitecture and generalization ability using region classification and cross-modal retrieval tasks. Multiple experiments are performed under various data setups, including data from samples of different ages and sectioning planes. Experimental results demonstrate that CytoCLIP outperforms existing methods. It achieves an F1 score of 0.87 for whole-region classification and 0.91 for high-resolution image tile classification.", "AI": {"tldr": "本研究提出了一种名为CytoCLIP的视觉-语言模型，用于自动识别和区分大脑不同区域的细胞构筑结构，以克服手动标注的耗时和专业知识要求。模型采用两种变体，分别处理低分辨率全区域图像和高分辨率图像块，以捕捉整体模式和细胞细节。实验证明CytoCLIP在区域分类和跨模态检索任务上优于现有方法。", "motivation": "手动标注大脑组织学切片中的不同脑区耗时且需要专业知识，因此需要一种自动化的方法来减轻专家负担。", "method": "提出CytoCLIP，一个基于CLIP框架的视觉-语言模型。模型包含两个变体：一个用于理解低分辨率全区域的细胞构筑模式，另一个用于学习高分辨率图像块的细胞层面细节。训练数据来源于不同孕周的胎儿大脑NISSL染色切片。", "result": "CytoCLIP在整个区域分类任务上达到0.87的F1分数，在高分辨率图像块分类任务上达到0.91的F1分数，优于现有方法。模型展现了对细胞构筑的理解能力和泛化能力。", "conclusion": "CytoCLIP能够有效地通过细胞构筑结构自动识别和区分大脑区域，为大脑科学研究提供了一种高效的自动化工具。"}}
{"id": "2601.12285", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12285", "abs": "https://arxiv.org/abs/2601.12285", "authors": ["Safa C. Medin", "Gengyan Li", "Ziqian Bai", "Ruofei Du", "Leonhard Helminger", "Yinda Zhang", "Stephan J. Garbin", "Philip L. Davidson", "Gregory W. Wornell", "Thabo Beeler", "Abhimitra Meka"], "title": "LegacyAvatars: Volumetric Face Avatars For Traditional Graphics Pipelines", "comment": null, "summary": "We introduce a novel representation for efficient classical rendering of photorealistic 3D face avatars. Leveraging recent advances in radiance fields anchored to parametric face models, our approach achieves controllable volumetric rendering of complex facial features, including hair, skin, and eyes. At enrollment time, we learn a set of radiance manifolds in 3D space to extract an explicit layered mesh, along with appearance and warp textures. During deployment, this allows us to control and animate the face through simple linear blending and alpha compositing of textures over a static mesh. This explicit representation also enables the generated avatar to be efficiently streamed online and then rendered using classical mesh and shader-based rendering on legacy graphics platforms, eliminating the need for any custom engineering or integration.", "AI": {"tldr": "提出一种新的三维人脸模型表示方法，通过结合辐射场和参数化人脸模型，实现高效、逼真的经典渲染，支持头发、皮肤、眼睛等复杂细节，并支持在线流式传输和传统图形平台渲染。", "motivation": "为了实现对三维人脸模型的有效经典渲染，特别是在支持头发、皮肤、眼睛等复杂细节，并能在传统图形平台上高效传输和渲染。", "method": "在注册时，学习三维空间中的辐射流形，提取显式分层网格、外观纹理和变形纹理。在部署时，通过简单的线性混合和Alpha混合纹理来控制和动画面部。", "result": "生成的人脸模型可以被高效地在线流式传输，并在传统图形平台上使用经典的网格和着色器渲染，无需定制工程或集成。", "conclusion": "该方法提供了一种高效、可控的逼真三维人脸渲染新途径，打破了传统渲染平台的限制，易于集成和部署。"}}
{"id": "2601.13559", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13559", "abs": "https://arxiv.org/abs/2601.13559", "authors": ["Sun Hui", "Ding Yanfeng", "Huidong Ma", "Chang Xu", "Keyan Jin", "Lizheng Zu", "Cheng Zhong", "xiaoguang Liu", "Gang Wang", "Wentong Cai"], "title": "AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent", "comment": null, "summary": "Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.", "AI": {"tldr": "提出了一种名为 AgentGC 的进化式基于智能体的基因组数据压缩器，它通过多智能体协作和 LLM 集成，在压缩率和吞吐量方面显著优于现有方法。", "motivation": "现有学习型基因组数据压缩方法存在低级压缩建模、适应性有限和用户界面不友好的问题，需要更先进的解决方案。", "method": "设计了一个包含用户层、认知层和压缩层的三层架构 AgentGC。用户层通过 Leader 和 LLM 提供用户友好界面；认知层利用 Leader 和 LLM 实现算法-数据集-系统的联合优化；压缩层由 Worker 执行基于自动化多知识学习的压缩和解压缩。同时提供了 CP、TP、BM 三种模式以适应不同场景。", "result": "在 9 个数据集上与 14 个基线方法相比，AgentGC 在 CP、TP 和 BM 模式下分别实现了 16.66%、16.11%、16.33% 的平均压缩率提升，以及 4.73x、9.23x、9.15x 的平均吞吐量提升。", "conclusion": "AgentGC 作为首个进化式基于智能体的基因组数据压缩器，成功解决了现有方法的不足，并在压缩性能和用户体验方面取得了显著的改进。"}}
{"id": "2601.13558", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13558", "abs": "https://arxiv.org/abs/2601.13558", "authors": ["Mehrab Beikzadeh", "Chenglin Hong", "Cory J Cascalheira", "Callisto Boka", "Majid Sarrafzadeh", "Ian W Holloway"], "title": "Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis", "comment": null, "summary": "Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM.", "AI": {"tldr": "研究表明，利用ChatGPT和BERT等大型语言模型处理社交媒体和约会应用上的文本数据，可以有效预测男男性行为者（MSM）的性风险行为、饮酒习惯和暴露前预防（PrEP）使用情况，为个性化公共卫生干预提供新途径。", "motivation": "男男性行为者（MSM）面临更高的性传播感染和有害饮酒风险。社交媒体和约会应用上的文本数据为自动识别其风险和保护行为，从而进行个性化公共卫生干预提供了新机会。", "method": "收集了MSM参与者的文本数据，并利用ChatGPT嵌入、BERT嵌入、LIWC（语言分析和文本挖掘软件）以及基于字典的风险词汇方法提取特征，训练机器学习模型来预测性风险行为、酒精使用和PrEP使用情况。", "result": "模型在预测每月大量饮酒和性伴侣超过五人的行为方面表现强劲（F1分数分别为0.78），在预测PrEP使用和重度饮酒方面表现适中（F1分数分别为0.64和0.63）。", "conclusion": "社交媒体和约会应用上的文本数据能够提供关于MSM风险和保护行为的宝贵见解。基于大型语言模型的方法有潜力支持可扩展的、个性化的MSM公共卫生干预措施。"}}
{"id": "2601.13562", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13562", "abs": "https://arxiv.org/abs/2601.13562", "authors": ["Zhiguang Liu", "Yi Shang"], "title": "Reasoning is a Modality", "comment": "Code access: https://github.com/lz7fd/Reasoning_is_a_Modality", "summary": "The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.", "AI": {"tldr": "本文提出了一种新的 Transformer 模块，通过分离全局控制器和网格工作空间，实现了迭代式规则执行，在 ARC 视觉推理任务上取得了超过人类平均水平的准确率。", "motivation": "现有 AI 系统（如 LLM 和 ViT）主要依赖于行为预测，缺乏可解释的内部状态，与人类能够解释行动原因的能力存在差距。研究者希望探索一种能够实现类人推理的方法。", "method": "设计了一种新的、角色分离的 Transformer 模块，将全局控制器 Token 与网格工作空间 Token 分离，以支持迭代式规则执行。在 VARC 协议下进行训练和评估。", "result": "该方法在 ARC-1 上取得了 62.6% 的准确率，超越了人类平均水平（60.2%），并显著优于现有方法。模型展现出比密集 ViT 基线更连贯的规则应用结构。", "conclusion": "将推理视为一种独立的模态（与低级工作空间分离）是可行的，并且可以实现更强的视觉推理能力。这种方法有助于 AI 系统从基于概率的模式匹配转向更具解释性的、由控制器驱动的推理。"}}
{"id": "2601.12904", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12904", "abs": "https://arxiv.org/abs/2601.12904", "authors": ["Jiahao Wang", "Weiyu Xie", "Mingxing Zhang", "Boxing Zhang", "Jianwei Dong", "Yuening Zhu", "Chen Lin", "Jinqi Tang", "Yaochen Han", "Zhiyuan Ai", "Xianglin Chen", "Yongwei Wu", "Congfeng Jiang"], "title": "From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.", "AI": {"tldr": "FusionRAG 提出了一种新的 RAG 推理框架，通过在预处理阶段嵌入跨块信息和在重处理阶段重新计算关键 token 的 KV 缓存，来优化 RAG 的效率和生成质量，在较低的重计算比例下显著优于现有方法。", "motivation": "现有 RAG 方法为了提高效率复用 KV 缓存，但会牺牲生成质量。本研究旨在解决如何在提高效率的同时保持生成质量的问题。", "method": "提出 FusionRAG 框架，包含两个阶段：1. 离线预处理：将其他相关文本块的信息嵌入到每个块中。2. 在线重处理：重新计算模型关注的 token 的 KV 缓存。", "result": "FusionRAG 在与现有 SOTA 方法相同的重计算比例下，生成质量显著提高（最高可达 70% 的归一化 F1 分数），并将 TTFT 降低了 2.66x-9.39x。", "conclusion": "FusionRAG 可以在 RAG 中实现生成质量和效率的更好权衡，通过优化的预处理和重处理方法，有效解决了现有 KV 缓存复用带来的质量下降问题。"}}
{"id": "2601.12868", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12868", "abs": "https://arxiv.org/abs/2601.12868", "authors": ["Shiyue Hu", "Ruizhe Li", "Yanjun Gao"], "title": "Race, Ethnicity and Their Implication on Bias in Large Language Models", "comment": "Work in process", "summary": "Large language models (LLMs) increasingly operate in high-stakes settings including healthcare and medicine, where demographic attributes such as race and ethnicity may be explicitly stated or implicitly inferred from text. However, existing studies primarily document outcome-level disparities, offering limited insight into internal mechanisms underlying these effects. We present a mechanistic study of how race and ethnicity are represented and operationalized within LLMs. Using two publicly available datasets spanning toxicity-related generation and clinical narrative understanding tasks, we analyze three open-source models with a reproducible interpretability pipeline combining probing, neuron-level attribution, and targeted intervention. We find that demographic information is distributed across internal units with substantial cross-model variation. Although some units encode sensitive or stereotype-related associations from pretraining, identical demographic cues can induce qualitatively different behaviors. Interventions suppressing such neurons reduce bias but leave substantial residual effects, suggesting behavioral rather than representational change and motivating more systematic mitigation.", "AI": {"tldr": "该研究深入探究了大型语言模型（LLMs）如何处理和内化种族和民族信息，发现模型内部存在跨模型差异的表示，尽管预训练数据可能引入偏见，但相同的输入在不同模型中会产生不同的行为，并且干预措施虽能减少偏见但效果有限，表明需要更系统的缓解策略。", "motivation": "现有研究主要关注大型语言模型在高风险领域（如医疗）中的结果级偏见，但缺乏对其内部机制的深入了解，特别是模型如何表示和操作种族和民族信息。", "method": "研究者利用两个公开数据集（涉及毒性生成和临床叙事理解任务），结合探针、神经元级别归因和定向干预等可复现的解释性方法，分析了三个开源模型。", "result": "研究发现，人口统计信息在模型内部单元中分布不均，且存在显著的跨模型差异。某些单元确实编码了与敏感信息或刻板印象相关的预训练关联，但相同的种族/民族线索可能引发截然不同的模型行为。抑制这些神经元可以减少偏见，但仍存在显著的残留效应。", "conclusion": "模型对人口统计信息的内部表示方式存在差异，预训练数据带来的偏见是问题的一部分，但模型行为的差异性表明，模型内部的运作机制（行为层面）可能比单纯的表示（表征层面）更需要关注。现有的干预措施虽然有效，但不足以完全消除偏见，因此需要开发更系统化的偏见缓解策略。"}}
{"id": "2601.12844", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12844", "abs": "https://arxiv.org/abs/2601.12844", "authors": ["Julie Rançon", "Jean-François Cerisier", "Emilie Remond", "Aurélien Nguyen", "Andrew Peterson", "Ladjel Bellatreche"], "title": "Rapport du Projet de Recherche TRAIMA", "comment": "in French language", "summary": "The TRAIMA project (TRaitement Automatique des Interactions Multimodales en Apprentissage), conducted between March 2019 and June 2020, investigates the potential of automatic processing of multimodal interactions in educational settings. The project addresses a central methodological challenge in educational and interactional research: the analysis of verbal, paraverbal, and non-verbal data is currently carried out manually, making it extremely time-consuming and difficult to scale. TRAIMA explores how machine learning approaches could contribute to the categorisation and classification of such interactions. The project focuses specifically on explanatory and collaborative sequences occurring in classroom interactions, particularly in French as a Foreign Language (FLE) and French as a First Language (FLM) contexts. These sequences are analysed as inherently multimodal phenomena, combining spoken language with prosody, gestures, posture, gaze, and spatial positioning. A key theoretical contribution of the project is the precise linguistic and interactional definition of explanatory discourse as a tripartite sequence (opening, explanatory core, closure), drawing on discourse analysis and interactional linguistics. A substantial part of the research is devoted to the methodological foundations of transcription, which constitute a critical bottleneck for any form of automation. The report provides a detailed state of the art of existing transcription conventions (ICOR, Mondada, GARS, VALIBEL, Ferr{é}), highlighting their respective strengths and limitations when applied to multimodal classroom data. Through comparative analyses of manually transcribed sequences, the project demonstrates the inevitable variability and interpretative dimension of transcription practices, depending on theoretical positioning and analytical goals. Empirical work is based on several corpora, notably the INTER-EXPLIC corpus (approximately 30 hours of classroom interaction) and the EXPLIC-LEXIC corpus, which serve both as testing grounds for manual annotation and as reference datasets for future automation. Particular attention is paid to teacher gestures (kin{é}sic and proxemic resources), prosodic features, and their functional role in meaning construction and learner comprehension. The project also highlights the strategic role of the Techn{é}LAB platform, which provides advanced multimodal data capture (multi-camera video, synchronized audio, eye-tracking, digital interaction traces) and constitutes both a research infrastructure and a test environment for the development of automated tools. In conclusion, TRAIMA does not aim to deliver a fully operational automated system, but rather to establish a rigorous methodological framework for the automatic processing of multimodal pedagogical interactions. The project identifies transcription conventions, annotation categories, and analytical units that are compatible with machine learning approaches, while emphasizing the need for theoretical explicitness and researcher reflexivity. TRAIMA thus lays the groundwork for future interdisciplinary research at the intersection of didactics, discourse analysis, multimodality, and artificial intelligence in education.", "AI": {"tldr": "TRAIMA项目旨在开发一种自动处理教育环境中多模态互动的方法，重点关注解释性和协作性序列，并探索机器学习在该领域的应用。研究强调了转录方法论的重要性，并提出了与机器学习兼容的转录约定、标注类别和分析单元。", "motivation": "当前对课堂互动中的口语、语调和非语言数据的手动分析耗时且难以扩展，TRAIMA项目旨在解决这一方法论挑战，探索使用机器学习自动处理这些多模态互动数据的潜力。", "method": "该项目通过对解释性（包括开场、核心解释和结尾）和协作性序列的分析，结合语言学和互动分析理论，专注于口语、语调、手势、姿势、目光和空间定位等。研究还进行了现有转录约定的现状分析，并通过对手动转录序列的比较分析，评估了转录实践的可变性和解释性。项目使用了INTER-EXPLIC和EXPLIC-LEXIC语料库，并利用TechnéLAB平台进行多模态数据采集。", "result": "TRAIMA项目识别了与机器学习方法兼容的转录约定、标注类别和分析单元，并强调了理论明确性和研究者反思性的必要性。项目展示了教师手势、语调及其在意义建构和学习者理解中的作用。", "conclusion": "TRAIMA项目并未旨在交付一个完全可操作的自动化系统，而是建立了一个用于自动处理多模态教学互动的严谨方法论框架，为未来在教育领域交叉学科的研究奠定基础。"}}
{"id": "2601.12303", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12303", "abs": "https://arxiv.org/abs/2601.12303", "authors": ["Shizhan Gong", "Xiaofan Zhang", "Qi Dou"], "title": "Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations", "comment": "AAAI 2026", "summary": "Deep learning has achieved remarkable success in image recognition, yet their inherent opacity poses challenges for deployment in critical domains. Concept-based interpretations aim to address this by explaining model reasoning through human-understandable concepts. However, existing post-hoc methods and ante-hoc concept bottleneck models (CBMs), suffer from limitations such as unreliable concept relevance, non-visual or labor-intensive concept definitions, and model or data-agnostic assumptions. This paper introduces Post-hoc Concept Bottleneck Model via Representation Decomposition (PCBM-ReD), a novel pipeline that retrofits interpretability onto pretrained opaque models. PCBM-ReD automatically extracts visual concepts from a pre-trained encoder, employs multimodal large language models (MLLMs) to label and filter concepts based on visual identifiability and task relevance, and selects an independent subset via reconstruction-guided optimization. Leveraging CLIP's visual-text alignment, it decomposes image representations into linear combination of concept embeddings to fit into the CBMs abstraction. Extensive experiments across 11 image classification tasks show PCBM-ReD achieves state-of-the-art accuracy, narrows the performance gap with end-to-end models, and exhibits better interpretability.", "AI": {"tldr": "本文提出了一种名为PCBM-ReD的新型后置概念瓶颈模型，通过分解预训练模型的表示，自动提取、标注和筛选视觉概念，并利用MLLMs和CLIP提高概念的可解释性和任务相关性，在图像分类任务上取得了最先进的性能，并缩小了与端到端模型的性能差距。", "motivation": "现有基于概念的可解释性方法存在概念相关性不可靠、定义非视觉化或劳动密集、以及模型或数据无关假设等局限性，阻碍了深度学习在关键领域的应用。因此，需要一种能为预训练的黑箱模型提供可解释性的新方法。", "method": "PCBM-ReD通过以下步骤实现：1. 从预训练编码器自动提取视觉概念。2. 利用多模态大语言模型（MLLMs）根据视觉可识别性和任务相关性对概念进行标注和筛选。3. 通过重构引导优化选择一个独立的概念子集。4. 利用CLIP的视觉-文本对齐能力，将图像表示分解为概念嵌入的线性组合，以适应概念瓶颈模型的抽象。", "result": "在11个图像分类任务上的广泛实验表明，PCBM-ReD实现了最先进的准确率，缩小了与端到端模型的性能差距，并展现出更好的可解释性。", "conclusion": "PCBM-ReD是一种新颖的后置概念瓶颈模型管道，能够有效地为预训练的黑箱模型提供可解释性，通过自动提取、筛选和优化概念，并在多项图像分类任务上取得了优越的性能和可解释性。"}}
{"id": "2601.12304", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12304", "abs": "https://arxiv.org/abs/2601.12304", "authors": ["Wutao Chen", "Huaqin Zou", "Chen Wan", "Lifeng Huang"], "title": "A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models", "comment": "Accepted to ICASSP 2026", "summary": "Vision-language pre-training (VLP) models are vulnerable to adversarial examples, particularly in black-box scenarios. Existing multimodal attacks often suffer from limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, we propose 2S-GDA, a two-stage globally-diverse attack framework. The proposed method first introduces textual perturbations through a globally-diverse strategy by combining candidate text expansion with globally-aware replacement. To enhance visual diversity, image-level perturbations are generated using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17\\% in black-box settings. Our framework is modular and can be easily combined with existing methods to further enhance adversarial transferability.", "AI": {"tldr": "提出了一种名为2S-GDA的双阶段全局多样性攻击框架，用于提升在黑盒场景下视觉-语言预训练（VLP）模型的对抗攻击成功率，通过文本和图像扰动的多样化，实验结果显示在黑盒设置下攻击成功率提升高达11.17%。", "motivation": "现有针对VLP模型的对抗攻击在黑盒场景下存在扰动多样性有限和多阶段流程不稳定的问题，研究动机是为了克服这些挑战。", "method": "提出2S-GDA框架，首先通过结合候选文本扩展和全局感知替换引入文本扰动，然后使用多尺度重排和块混洗旋转生成图像层面的扰动，以增强视觉多样性。", "result": "在VLP模型上的广泛实验表明，2S-GDA在黑盒设置下持续提高了攻击成功率，相较于最先进的方法，成功率提升高达11.17%。", "conclusion": "2S-GDA是一个模块化的框架，能够轻松与其他方法结合，进一步增强对抗样本的可迁移性，有效提升了VLP模型在黑盒场景下的对抗攻击性能。"}}
{"id": "2601.13589", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.13589", "abs": "https://arxiv.org/abs/2601.13589", "authors": ["HyeYoung Lee"], "title": "Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification", "comment": null, "summary": "This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.", "AI": {"tldr": "本文提出了一个多智能体AI系统，能够根据音频中的情绪信号实时生成响应式媒体内容，并强调了内容的安全性和适龄性。", "motivation": "传统语音情感识别研究主要关注分类准确率，而本研究的动机是将识别出的情感状态转化为安全、适龄且可控的响应式内容，以满足儿童媒体、治疗应用和情感响应式智能设备等场景的需求。", "method": "该系统包含四个协作智能体：1. 基于CNN提取声学特征的情感识别智能体；2. 将情感映射到响应模式的响应策略决策智能体；3. 生成媒体控制参数的内容参数生成智能体；4. 强制执行适龄性和刺激性限制的安全验证智能体。系统包含一个显式的安全验证循环，在输出前过滤内容。", "result": "实验结果表明，该系统在情感识别方面达到73.2%的准确率，响应模式一致性为89.4%，安全性合规性为100%，同时推理延迟低于100毫秒，适合设备端部署。", "conclusion": "该系统通过结构化的AI智能体流水线，能够有效地将语音情感转化为安全、适龄的响应式媒体内容，并具有良好的可解释性和可扩展性，适用于多种情感交互场景。"}}
{"id": "2601.12906", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12906", "abs": "https://arxiv.org/abs/2601.12906", "authors": ["Lingrui Mei", "Shenghua Liu", "Yiwei Wang", "Yuyao Ge", "Baolong Bi", "Jiayu Yao", "Jun Wan", "Ziling Yin", "Jiafeng Guo", "Xueqi Cheng"], "title": "Gated Differentiable Working Memory for Long-Context Language Modeling", "comment": null, "summary": "Long contexts challenge transformers: attention scores dilute across thousands of tokens, critical information is often lost in the middle, and models struggle to adapt to novel patterns at inference time. Recent work on test-time adaptation addresses this by maintaining a form of working memory -- transient parameters updated on the current context -- but existing approaches rely on uniform write policies that waste computation on low-utility regions and suffer from high gradient variance across semantically heterogeneous contexts. In this work, we reframe test-time adaptation as a budget-constrained memory consolidation problem, focusing on which parts of the context should be consolidated into working memory under limited computation. We propose Gdwm (Gated Differentiable Working Memory), a framework that introduces a write controller to gate the consolidation process. The controller estimates Contextual Utility, an information-theoretic measure of long-range contextual dependence, and allocates gradient steps accordingly while maintaining global coverage. Experiments on ZeroSCROLLS and LongBench v2 demonstrate that Gdwm achieves comparable or superior performance with 4$\\times$ fewer gradient steps than uniform baselines, establishing a new efficiency-performance Pareto frontier for test-time adaptation.", "AI": {"tldr": "本文提出了一种名为Gdwm的框架，用于解决Transformer在处理长上下文时面临的挑战，通过引入一个门控控制器来优化测试时适应（TTA）过程，使其在更少的计算量下获得更好的性能。", "motivation": "现有的Transformer模型在处理长上下文时存在注意力分数稀释、信息丢失和推理适应困难等问题。现有的测试时适应方法计算效率低下且梯度方差大。", "method": "将测试时适应重新定义为预算约束下的记忆巩固问题。提出Gdwm框架，引入一个门控写入控制器，该控制器基于信息论方法估计“上下文效用”（Contextual Utility）来指导记忆的巩固过程，并在全局覆盖的前提下分配梯度步骤。", "result": "在ZeroSCROLLS和LongBench v2数据集上的实验表明，Gdwm在梯度步数减少4倍的情况下，性能与基线相当或更优，达到了新的效率-性能帕累托最优。", "conclusion": "Gdwm通过引入智能的写入控制器，有效地解决了长上下文处理中的效率和性能问题，为测试时适应提供了一种更优的解决方案。"}}
{"id": "2601.13581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13581", "abs": "https://arxiv.org/abs/2601.13581", "authors": ["Heedou Kim", "Changsik Kim", "Sanghwa Shin", "Jaewoo Kang"], "title": "SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System", "comment": "This paper has been accepted to the EACL 2026 Industry Track", "summary": "Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.", "AI": {"tldr": "本文提出了一种名为ScriptMind的集成框架，利用大型语言模型（LLMs）来检测和防御日益复杂的社交工程欺诈。该框架结合了自动推理和人类认知，通过训练小型LLMs来提高检测准确性、减少误报，并增强用户的欺诈意识。实验结果表明，经过ScriptMind微调的LLM在检测和认知评估方面优于现有模型，包括GPT-4o。", "motivation": "传统的欺诈检测方法在面对日益复杂和个性化的多轮欺骗时显得力不从心。尽管LLMs在识别欺骗方面有潜力，但其在认知辅助方面的应用尚未得到充分探索。", "method": "本文提出ScriptMind框架，包含三个组成部分：1. Crime Script Inference Task (CSIT) 用于欺诈推理；2. Crime Script-Aware Inference Dataset (CSID) 用于微调小型LLMs；3. Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) 用于评估实时认知影响。利用571个韩国电话诈骗案例构建了22,712个结构化诈骗者-序列训练实例。", "result": "经过ScriptMind微调的11B小型LLM在检测准确性、误报减少、诈骗者话语预测和推理质量方面均优于GPT-4o，性能领先于商业模型。在电话诈骗模拟实验中，该模型显著提升并维持了用户的警惕性，提高了他们对诈骗的认知意识。", "conclusion": "ScriptMind框架迈出了构建以人为本、认知自适应的LLMs用于欺诈防御的重要一步，展现了其在提升欺诈检测效率和用户认知能力方面的潜力。"}}
{"id": "2601.12308", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12308", "abs": "https://arxiv.org/abs/2601.12308", "authors": ["Anurag Kaushish", "Ayan Sar", "Sampurna Roy", "Sudeshna Chakraborty", "Prashant Trivedi", "Tanupriya Choudhury", "Kanav Gupta"], "title": "Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification", "comment": "Accepted in IEEE ICASSP 2026", "summary": "Few-shot learning in remote sensing remains challenging due to three factors: the scarcity of labeled data, substantial domain shifts, and the multi-scale nature of geospatial objects. To address these issues, we introduce Adaptive Multi-Scale Correlation Meta-Network (AMC-MetaNet), a lightweight yet powerful framework with three key innovations: (i) correlation-guided feature pyramids for capturing scale-invariant patterns, (ii) an adaptive channel correlation module (ACCM) for learning dynamic cross-scale relationships, and (iii) correlation-guided meta-learning that leverages correlation patterns instead of conventional prototype averaging. Unlike prior approaches that rely on heavy pre-trained models or transformers, AMC-MetaNet is trained from scratch with only $\\sim600K$ parameters, offering $20\\times$ fewer parameters than ResNet-18 while maintaining high efficiency ($<50$ms per image inference). AMC-MetaNet achieves up to 86.65\\% accuracy in 5-way 5-shot classification on various remote sensing datasets, including EuroSAT, NWPU-RESISC45, UC Merced Land Use, and AID. Our results establish AMC-MetaNet as a computationally efficient, scale-aware framework for real-world few-shot remote sensing.", "AI": {"tldr": "提出了一种名为AMC-MetaNet的轻量级元学习框架，用于解决遥感领域少样本学习中的数据稀缺、领域迁移和多尺度对象问题。该框架通过引入相关性引导的特征金字塔、自适应通道相关模块以及基于相关性模式的元学习，实现了高效且尺度感知的模型。", "motivation": "遥感领域的少样本学习面临数据稀缺、领域迁移和地理空间对象多尺度等挑战。", "method": "提出AMC-MetaNet框架，包含三个创新点：1. 相关性引导的特征金字塔用于捕获尺度不变模式；2. 自适应通道相关模块（ACCM）学习动态跨尺度关系；3. 相关性引导的元学习利用相关性模式而非原型平均。模型参数量少，效率高。", "result": "AMC-MetaNet在EuroSAT、NWPU-RESISC45、UC Merced Land Use和AID等遥感数据集上进行了5-way 5-shot分类实验，最高准确率达到86.65%。", "conclusion": "AMC-MetaNet是一个计算高效、尺度感知且适用于真实世界少样本遥感任务的框架。"}}
{"id": "2601.12910", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12910", "abs": "https://arxiv.org/abs/2601.12910", "authors": ["Tim Baumgärtner", "Iryna Gurevych"], "title": "SciCoQA: Quality Assurance for Scientific Paper--Code Alignment", "comment": null, "summary": "We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\\% of real-world paper-code discrepancies.", "AI": {"tldr": "本文提出了SciCoQA数据集，用于检测科学论文与其代码库之间的不一致之处，以确保代码实现的准确性。该数据集包含真实和合成的不一致条目，并通过评估21种大型语言模型（LLMs）来展示其难度，即使是表现最好的模型也只能检测到45.7%的真实不一致。", "motivation": "确保科学研究的实现（代码）与其论文描述相符，防止因实现错误导致研究结果的误读和不可复现。", "method": "构建包含真实（来自GitHub issue和可复现性论文）和合成（通过生成方法）的SciCoQA数据集，并分析不一致的类型和类别。使用21种大型语言模型（LLMs）对数据集进行评估。", "result": "SciCoQA数据集包含611个不一致条目（81个真实，530个合成），涵盖AI、物理、量化生物学等多个学科。评估表明，LLMs在处理缺失论文细节、长上下文输入和模型未预训练领域的数据时存在困难。最佳模型GPT-5也只能检测到45.7%的真实不一致。", "conclusion": "检测科学论文与其代码库之间的不一致是一项挑战性任务，现有的LLMs在这方面仍有很大提升空间。SciCoQA数据集为评估和改进模型在该领域的性能提供了宝贵的资源。"}}
{"id": "2601.13591", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13591", "abs": "https://arxiv.org/abs/2601.13591", "authors": ["Maojun Sun", "Yifei Xie", "Yue Wu", "Ruijian Han", "Binyan Jiang", "Defeng Sun", "Yancheng Yuan", "Jian Huang"], "title": "DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems", "comment": null, "summary": "Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.", "AI": {"tldr": "本文提出DSAEval基准来评估基于LLM的数据科学代理，该基准包含641个真实世界的数据科学问题，涵盖多模态数据和多轮交互，并采用多维度评估。评估结果显示Claude-Sonnet-4.5表现最佳，GPT-5.2效率最高，MiMo-V2-Flash最具成本效益。多模态感知对视觉任务有显著提升，但数据科学代理在非结构化数据领域仍面临挑战。", "motivation": "现有基于LLM的数据科学代理在评估上面临挑战，因为真实世界的数据科学问题具有开放性、缺乏标准答案，并且跨越多个领域。因此，需要一个能够全面评估这些代理的基准。", "method": "引入DSAEval基准，包含641个真实世界的数据科学问题，基于285个数据集，涵盖结构化和非结构化数据。DSAEval包含三个特点：1. 多模态环境感知（支持文本和视觉）；2. 多查询交互（模拟真实项目）；3. 多维度评估（评估推理、代码和结果）。使用DSAEval系统性地评估了11个先进的LLM数据科学代理。", "result": "Claude-Sonnet-4.5在DSAEval上表现最强，GPT-5.2效率最高，MiMo-V2-Flash最具成本效益。多模态感知在视觉任务上提升了2.04%至11.30%的性能。当前数据科学代理在结构化数据和常规分析流程方面表现良好，但在非结构化数据领域仍有较大提升空间。", "conclusion": "DSAEval为评估数据科学代理提供了一个全面的基准，揭示了当前代理在多模态和非结构化数据处理方面的局限性。研究结果为未来数据科学代理的发展提供了关键见解和研究方向。"}}
{"id": "2601.12921", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12921", "abs": "https://arxiv.org/abs/2601.12921", "authors": ["Adimulya Kartiyasa", "Bao Gia Cao", "Boyang Li"], "title": "Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs", "comment": null, "summary": "Recently there have been intensifying efforts to improve the understanding of Indonesian cultures by large language models (LLMs). An attractive source of cultural knowledge that has been largely overlooked is local journals of social science, which likely contain substantial cultural studies from a native perspective. We present a novel text dataset of journal article passages, created from 151 open-source Indonesian social science journals, called IndoSoSci. We demonstrate an effective recipe for injecting Indonesian cultural knowledge therein into LLMs: extracting the facts related to Indonesian culture, and apply retrieval-augmented generation (RAG) with LLM-generated hypothetical documents as queries during retrieval. The proposed recipe yields strong performance gains over several strong baselines on the IndoCulture benchmark. Additionally, by combining IndoSoSci with Indonesian Wikipedia, we set a new state-of-the-art accuracy on the IndoCulture benchmark.", "AI": {"tldr": "本文构建了一个包含151种印尼社会科学期刊文章的文本数据集IndoSoSci，并提出了一种利用检索增强生成（RAG）和LLM生成的假设性文档作为查询来注入印尼文化知识的方法，该方法在IndoCulture基准测试中取得了显著的性能提升，并结合印尼维基百科达到了新的最先进水平。", "motivation": "现有的大型语言模型（LLMs）在理解印尼文化方面存在不足，而本地社会科学期刊作为蕴含丰富本土视角的文化知识源，尚未被充分利用。", "method": "1. 构建IndoSoSci数据集，包含151种开放获取的印尼社会科学期刊的文章片段。2. 提出一种“注入”印尼文化知识的方法：提取与印尼文化相关的知识，并结合检索增强生成（RAG），利用LLM生成的假设性文档作为检索查询。", "result": "所提出的方法在IndoCulture基准测试中优于多个强基线。通过将IndoSoSci与印尼维基百科结合，在IndoCulture基准测试上取得了新的最先进的准确率。", "conclusion": "IndoSoSci数据集和提出的RAG方法能够有效提升LLM对印尼文化的理解能力，并且结合更多数据源可以进一步提升性能，达到新的SOTA水平。"}}
{"id": "2601.12283", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12283", "abs": "https://arxiv.org/abs/2601.12283", "authors": ["Bowen Lin", "Fanjiang Ye", "Yihua Liu", "Zhenghui Guo", "Boyuan Zhang", "Weijian Zheng", "Yufan Xu", "Tiancheng Xing", "Yuke Wang", "Chengming Zhang"], "title": "SDiT: Semantic Region-Adaptive for Diffusion Transformers", "comment": null, "summary": "Diffusion Transformers (DiTs) achieve state-of-the-art performance in text-to-image synthesis but remain computationally expensive due to the iterative nature of denoising and the quadratic cost of global attention. In this work, we observe that denoising dynamics are spatially non-uniform-background regions converge rapidly while edges and textured areas evolve much more actively. Building on this insight, we propose SDiT, a Semantic Region-Adaptive Diffusion Transformer that allocates computation according to regional complexity. SDiT introduces a training-free framework combining (1) semantic-aware clustering via fast Quickshift-based segmentation, (2) complexity-driven regional scheduling to selectively update informative areas, and (3) boundary-aware refinement to maintain spatial coherence. Without any model retraining or architectural modification, SDiT achieves up to 3.0x acceleration while preserving nearly identical perceptual and semantic quality to full-attention inference.", "AI": {"tldr": "提出了一种名为SDiT的语义区域自适应扩散Transformer，通过根据区域复杂性分配计算资源来加速扩散模型在文本到图像生成中的推理过程，同时保持了接近全注意力计算的质量。", "motivation": "现有的Diffusion Transformers（DiTs）在文本到图像合成方面表现出色，但由于去噪的迭代性质和全局注意力的高计算成本，仍然计算量巨大。研究者观察到去噪过程在空间上是不均匀的，背景区域收敛快，而边缘和纹理区域变化更活跃。", "method": "SDiT利用了去噪过程的空间非均匀性。它包含三个核心组件：(1) 基于Quickshift的语义感知聚类，用于图像分割；(2) 复杂性驱动的区域调度，选择性地更新信息区域；(3) 边界感知细化，以保持空间一致性。该方法无需重新训练模型或修改架构。", "result": "SDiT实现了高达3.0倍的加速，同时在感官和语义质量上几乎与全注意力推理保持一致。", "conclusion": "SDiT是一种高效的文本到图像生成方法，它通过利用去噪动态的空间非均匀性，并根据区域复杂性智能地分配计算资源，显著提高了推理速度，同时不牺牲生成质量。"}}
{"id": "2601.13632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13632", "abs": "https://arxiv.org/abs/2601.13632", "authors": ["Zhiming Xue", "Sichen Zhao", "Yalun Qi", "Xianling Zeng", "Zihan Yu"], "title": "Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning", "comment": null, "summary": "With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. The traditional static routing strategy most time cannot tolerate the traffic congestion and fluctuating retail demand. In this paper, we propose a Risk-Aware Dynamic Routing(RADR) framework which integrates Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization. We first construct a logistics topology graph by using the discrete GPS data using spatial clustering methods. Subsequently, a hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) is adopted to extract spatial correlations and temporal dependencies for predicting future congestion risks. These prediction results are then integrated into a dynamic edge weight mechanism to perform path planning. We evaluated the framework on the Smart Logistics Dataset 2024, which contains real-world Internet of Things(IoT) sensor data. The experimental results show that the RADR algorithm significantly enhances the resilience of the supply chain. Particularly in the case study of high congestion scenarios, our method reduces the potential congestion risk exposure by 19.3% while only increasing the transportation distance by 2.1%. This empirical evidence confirms that the proposed data-driven approach can effectively balance delivery efficiency and operational safety.", "AI": {"tldr": "本文提出了一种名为RADR（风险感知动态路由）的框架，通过结合时空图神经网络和组合优化，利用GPS数据预测物流网络中的交通拥堵风险，并动态调整路由以提高供应链的弹性和效率。", "motivation": "传统物流网络的静态路由策略难以应对电子商务发展带来的交通拥堵和需求波动。", "method": "1. 使用空间聚类方法从GPS数据构建物流拓扑图。 2. 采用图卷积网络（GCN）和门控循环单元（GRU）相结合的混合深度学习模型，提取时空特征以预测未来的拥堵风险。 3. 将预测结果整合到动态边权重机制中进行路径规划。", "result": "在Smart Logistics Dataset 2024数据集上进行了评估。RADR算法显著提高了供应链的弹性。在拥堵场景下，潜在拥堵风险暴露降低了19.3%，同时运输距离仅增加了2.1%。", "conclusion": "所提出的数据驱动方法可以有效地平衡配送效率和运营安全性，为解决现代物流网络的挑战提供了一种有效的解决方案。"}}
{"id": "2601.12313", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12313", "abs": "https://arxiv.org/abs/2601.12313", "authors": ["Xiangyu Hu", "Yicheng Hong", "Hongchuang Zheng", "Wenjun Zeng", "Bingyao Liu"], "title": "S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection", "comment": "27pages 9figures", "summary": "The rapid development of generative models has imposed an urgent demand for detection schemes with strong generalization capabilities. However, existing detection methods generally suffer from overfitting to specific source models, leading to significant performance degradation when confronted with unseen generative architectures. To address these challenges, this paper proposes a cross-model detection framework called S 2 F-Net, whose core lies in exploring and leveraging the inherent spectral discrepancies between real and synthetic textures. Considering that upsampling operations leave unique and distinguishable frequency fingerprints in both texture-poor and texture-rich regions, we focus our research on the detection of frequency-domain artifacts, aiming to fundamentally improve the generalization performance of the model. Specifically, we introduce a learnable frequency attention module that adaptively weights and enhances discriminative frequency bands by synergizing spatial texture analysis and spectral dependencies.On the AIGCDetectBenchmark, which includes 17 categories of generative models, S 2 F-Net achieves a detection accuracy of 90.49%, significantly outperforming various existing baseline methods in cross-domain detection scenarios.", "AI": {"tldr": "提出了一种名为S2F-Net的跨模型检测框架，通过利用真实和合成纹理在频域上的固有差异来检测生成模型产生的图像。", "motivation": "现有的生成模型检测方法在面对未知的生成架构时泛化能力差，容易过拟合到特定模型。需要开发具有更强泛化能力的检测方案。", "method": "S2F-Net框架的核心是探索和利用真实与合成纹理在频域上的差异。它专注于检测频域伪影，并引入了一个可学习的频率注意力模块，该模块通过结合空间纹理分析和频谱依赖性来适应性地加权和增强具有辨别力的频段。", "result": "在包含17类生成模型的AIGCDetectBenchmark基准上，S2F-Net的检测准确率达到了90.49%，在跨领域检测场景下显著优于现有的基线方法。", "conclusion": "S2F-Net通过关注频域伪影和引入频率注意力机制，有效提高了生成模型检测的泛化能力，克服了现有方法在面对新模型时的性能下降问题。"}}
{"id": "2601.13600", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13600", "abs": "https://arxiv.org/abs/2601.13600", "authors": ["Paul He", "Elke Kirschbaum", "Shiva Kasiviswanathan"], "title": "Foundations of Global Consistency Checking with Noisy LLM Oracles", "comment": "Under Review", "summary": "Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.", "AI": {"tldr": "提出了一种自适应分而治之的算法，用于使用大型语言模型（LLM）来高效地检测和定位大规模事实集合中的不一致性，并通过识别最小不一致子集（MUSes）和计算最小修复（hitting-sets）来解决全局一致性问题。", "motivation": "大型语言模型（LLMs）在评估小规模事实子集的一致性方面存在噪声，而简单的成对检查不足以保证全局一致性，这对于事实核查、摘要和知识库构建等任务至关重要。因此，需要一种更有效的方法来处理大规模事实集合的全局一致性。", "method": "作者提出了一个自适应分而治之的算法，该算法能够识别事实的最小不一致子集（MUSes），并可选地通过计算 hitting-sets 来执行最小修复。该方法旨在将查询复杂度从最坏情况下的指数级降低到低度多项式。", "result": "实验结果表明，该方法能够高效地检测和定位不一致性，并且在处理合成和真实LLM的oracle时都表现出色。该框架为使用基于LLM的评估器进行语言一致性验证提供了可扩展的解决方案。", "conclusion": "该研究提出了一种实用的算法，能够以低度多项式查询复杂度来解决大规模事实集合的全局一致性问题，弥补了现有LLM评估方法在处理全局一致性方面的不足，为语言一致性验证提供了可扩展的框架。"}}
{"id": "2601.12312", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12312", "abs": "https://arxiv.org/abs/2601.12312", "authors": ["Yongjun Jeon", "Jongmin Shin", "Kanggil Park", "Seonmin Park", "Soyoung Lim", "Jung Yong Kim", "Jinsoo Rhu", "Jongman Kim", "Gyu-Seong Choi", "Namkee Oh", "Kyu-Hwan Jung"], "title": "CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding", "comment": null, "summary": "Surgical action triplet recognition aims to understand fine-grained surgical behaviors by modeling the interactions among instruments, actions, and anatomical targets. Despite its clinical importance for workflow analysis and skill assessment, progress has been hindered by severe class imbalance, subtle visual variations, and the semantic interdependence among triplet components. Existing approaches often address only a subset of these challenges rather than tackling them jointly, which limits their ability to form a holistic understanding. This study builds upon CurConMix, a spatial representation framework. At its core, a curriculum-guided contrastive learning strategy learns discriminative and progressively correlated features, further enhanced by structured hard-pair sampling and feature-level mixup. Its temporal extension, CurConMix+, integrates a Multi-Resolution Temporal Transformer (MRTT) that achieves robust, context-aware understanding by adaptively fusing multi-scale temporal features and dynamically balancing spatio-temporal cues. Furthermore, we introduce LLS48, a new, hierarchically annotated benchmark for complex laparoscopic left lateral sectionectomy, providing step-, task-, and action-level annotations. Extensive experiments on CholecT45 and LLS48 demonstrate that CurConMix+ not only outperforms state-of-the-art approaches in triplet recognition, but also exhibits strong cross-level generalization, as its fine-grained features effectively transfer to higher-level phase and step recognition tasks. Together, the framework and dataset provide a unified foundation for hierarchy-aware, reproducible, and interpretable surgical workflow understanding. The code and dataset will be publicly released on GitHub to facilitate reproducibility and further research.", "AI": {"tldr": "本文提出了一种名为 CurConMix+ 的新框架，用于识别手术操作三元组，它结合了课程引导的对比学习、结构化难例采样和多分辨率时间 Transformer，以解决类别不平衡、细微视觉差异和语义依赖性问题。此外，还引入了一个新的 LLS48 基准数据集，用于腹腔镜左外侧段切除术。实验结果表明，CurConMix+ 在三元组识别和跨级别泛化方面均优于现有方法。", "motivation": "手术操作三元组识别在理解精细手术行为方面具有临床重要性，但面临类别不平衡、细微视觉差异和语义依赖性等挑战。现有方法未能全面解决这些问题。", "method": "在 CurConMix 框架的基础上，本文提出了 CurConMix+。它采用课程引导的对比学习策略，结合结构化难例采样和特征级 mixup 来学习判别性特征。通过集成多分辨率时间 Transformer (MRTT) 来处理时间信息，实现对多尺度时间特征的自适应融合和时空线索的动态平衡。此外，还构建了 LLS48 数据集。", "result": "在 CholecT45 和 LLS48 数据集上的实验表明，CurConMix+ 在手术操作三元组识别任务上优于现有最先进的方法。同时，其学习到的精细特征能够有效地迁移到更高层次（如阶段和步骤）的识别任务，表现出良好的跨级别泛化能力。", "conclusion": "CurConMix+ 框架和 LLS48 数据集为实现层级感知、可复现和可解释的手术流程理解提供了一个统一的基础。该研究有效解决了手术操作三元组识别中的关键挑战，并为未来的相关研究奠定了基础。"}}
{"id": "2601.12960", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12960", "abs": "https://arxiv.org/abs/2601.12960", "authors": ["Ainhoa Vivel-Couso", "Nicolás Vila-Blanco", "María J. Carreira", "Alberto Bugarín-Diz", "Inmaculada Tomás", "Jose M. Alonso-Moral"], "title": "Trustworthy Data-driven Chronological Age Estimation from Panoramic Dental Images", "comment": "This paper is a preliminary version of an accepted article in Information Systems Frontiers, Springer, Special Issue \"Explainability in Human-Centric AI\". Please cite the final published version of the paper, not this preprint. The final published version can be found at https://link.springer.com/article/10.1007/s10796-025-10682-3", "summary": "Integrating deep learning into healthcare enables personalized care but raises trust issues due to model opacity. To improve transparency, we propose a system for dental age estimation from panoramic images that combines an opaque and a transparent method within a natural language generation (NLG) module. This module produces clinician-friendly textual explanations about the age estimations, designed with dental experts through a rule-based approach. Following the best practices in the field, the quality of the generated explanations was manually validated by dental experts using a questionnaire. The results showed a strong performance, since the experts rated 4.77+/-0.12 (out of 5) on average across the five dimensions considered. We also performed a trustworthy self-assessment procedure following the ALTAI checklist, in which it scored 4.40+/-0.27 (out of 5) across seven dimensions of the AI Trustworthiness Assessment List.", "AI": {"tldr": "研究提出了一种结合不透明和透明方法的牙科年龄估算系统，并通过自然语言生成模块提供由牙科专家验证的、易于理解的文本解释，以提高对医疗深度学习模型的信任度。", "motivation": "深度学习在医疗领域的应用虽然能实现个性化护理，但模型的“黑箱”特性导致信任度不足，阻碍了其广泛应用。", "method": "系统结合了不透明（如深度学习模型）和透明（如基于规则的方法）两种模型进行牙科年龄估算。核心是一个自然语言生成（NLG）模块，该模块与牙科专家合作，基于规则生成关于年龄估算的文本解释。解释的质量通过牙科专家的问卷调查进行手动验证。", "result": "牙科专家对生成解释的评价平均分为 4.77/5。在基于 ALTAI 清单的可信度自我评估中，系统在七个维度上的得分平均为 4.40/5。", "conclusion": "该系统通过提供由专家验证且易于理解的文本解释，有效地解决了深度学习模型在牙科年龄估算中的透明度问题，提高了其可信度。"}}
{"id": "2601.12945", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12945", "abs": "https://arxiv.org/abs/2601.12945", "authors": ["Miao Xie", "Siguang Chen", "Chunli Lv"], "title": "A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits", "comment": "27 pages, 6 table", "summary": "Large language models (LLMs) have become powerful and widely used systems for language understanding and generation, while multi-armed bandit (MAB) algorithms provide a principled framework for adaptive decision-making under uncertainty. This survey explores the potential at the intersection of these two fields. As we know, it is the first survey to systematically review the bidirectional interaction between large language models and multi-armed bandits at the component level. We highlight the bidirectional benefits: MAB algorithms address critical LLM challenges, spanning from pre-training to retrieval-augmented generation (RAG) and personalization. Conversely, LLMs enhance MAB systems by redefining core components such as arm definition and environment modeling, thereby improving decision-making in sequential tasks. We analyze existing LLM-enhanced bandit systems and bandit-enhanced LLM systems, providing insights into their design, methodologies, and performance. Key challenges and representative findings are identified to help guide future research. An accompanying GitHub repository that indexes relevant literature is available at https://github.com/bucky1119/Awesome-LLM-Bandit-Interaction.", "AI": {"tldr": "本文对大型语言模型（LLM）与多臂老虎机（MAB）算法交叉领域的最新研究进行了全面综述，重点关注了它们之间双向的相互作用及其在各个层面的应用。", "motivation": "大型语言模型在自然语言处理领域取得了巨大成功，而多臂老虎机算法在不确定性下的适应性决策方面发挥着重要作用。本研究旨在探索和系统梳理这两个强大技术领域交叉产生的潜力，以期为未来的研究提供指导。", "method": "本文采用文献综述的方法，对现有关于LLM与MAB相互作用的研究进行了梳理和分析。重点关注了MAB如何解决LLM面临的挑战（如预训练、RAG、个性化），以及LLM如何通过重塑MAB的核心组件（如臂定义、环境建模）来提升MAB的决策能力。研究分析了已有的LLM增强型MAB系统和MAB增强型LLM系统，并指出了其中的设计、方法和性能。", "result": "研究发现，MAB算法在提升LLM的效率和性能方面发挥着重要作用，例如在模型选择、超参数调整和内容生成策略等方面。同时，LLM也为MAB带来了新的机遇，通过更丰富的上下文理解和更灵活的臂定义，能够解决传统MAB难以处理的问题。论文识别了该领域面临的关键挑战，并总结了代表性的研究成果。", "conclusion": "LLM与MAB的结合展现出巨大的潜力，能够克服各自的局限性，并在包括但不限于预训练、检索增强生成（RAG）和个性化等LLM的关键应用场景中带来显著的性能提升。同时，LLM也为MAB算法的设计和应用开辟了新的途径。未来的研究应致力于解决现有挑战，进一步挖掘这种交叉技术的潜力。"}}
{"id": "2601.12316", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12316", "abs": "https://arxiv.org/abs/2601.12316", "authors": ["Xinyuan Zhao", "Xianrui Chen", "Ahmad Chaddad"], "title": "GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer", "comment": "accepted at ICASSP 2026", "summary": "We present a semantics modulated, multi scale Transformer for 3D gaze estimation. Our model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360 and ETH-XGaze, our model achieves new state of the art angular errors of 2.49°, 3.22°, 10.16°, and 1.44°, demonstrating up to a 64% relative improvement over previously reported results. ablations attribute gains to prototype conditioning, cross scale fusion, MoE and hyperparameter. Our code is publicly available at https://github. com/AIPMLab/Gazeformer.", "AI": {"tldr": "提出了一种基于语义调制、多尺度 Transformer 的三维注视估计模型，在四个公开数据集上取得了新的 SOTA 结果，并将代码开源。", "motivation": "旨在改进三维注视估计的准确性，并提供一个比现有方法更优越的模型。", "method": "该模型使用可学习的原型库（光照、头部姿态、背景、方向）对 CLIP 全局特征进行调制，然后将原型增强的全局向量与 CLIP 斑块 tokens 和高分辨率 CNN tokens 在统一的注意力空间中融合，并通过路由/共享的专家混合（MoE）来增加条件容量。", "result": "在 MPIIFaceGaze, EYEDIAP, Gaze360 和 ETH-XGaze 数据集上取得了新的 SOTA 结果，平均角度误差分别为 2.49°, 3.22°, 10.16°, 和 1.44°，相对改进高达 64%。", "conclusion": "原型条件化、跨尺度融合、MoE 和超参数的组合带来了显著的性能提升，证明了该模型在三维注视估计任务上的有效性。"}}
{"id": "2601.12973", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12973", "abs": "https://arxiv.org/abs/2601.12973", "authors": ["Shuanghong Huang", "Jinlei Xu", "Youchao Zhou", "Yanghao Zhou", "Xuan Zhao", "Chong Feng", "Wenxuan Zhang"], "title": "Pardon? Evaluating Conversational Repair in Large Audio-Language Models", "comment": null, "summary": "Large Audio-Language Models (LALMs) have demonstrated strong performance in spoken question answering (QA), with existing evaluations primarily focusing on answer accuracy and robustness to acoustic perturbations. However, such evaluations implicitly assume that spoken inputs remain semantically answerable, an assumption that often fails in real-world interaction when essential information is missing. In this work, we introduce a repair-aware evaluation setting that explicitly distinguishes between answerable and unanswerable audio inputs. We define answerability as a property of the input itself and construct paired evaluation conditions using a semantic-acoustic masking protocol. Based on this setting, we propose the Evaluability Awareness and Repair (EAR) score, a non-compensatory metric that jointly evaluates task competence under answerable conditions and repair behavior under unanswerable conditions. Experiments on two spoken QA benchmarks across diverse LALMs reveal a consistent gap between answer accuracy and conversational reliability: while many models perform well when inputs are answerable, most fail to recognize semantic unanswerability and initiate appropriate conversational repair. These findings expose a limitation of prevailing accuracy-centric evaluation practices and motivate reliability assessments that treat unanswerable inputs as cues for repair and continued interaction.", "AI": {"tldr": "研究提出了一个评估大型音频语言模型（LALM）在口语问答中区分可回答和不可回答输入并进行修复的能力的新评估框架和指标（EAR分数），发现现有模型在识别不可回答输入和启动修复方面表现不佳。", "motivation": "现有对口语问答模型的评估主要关注答案准确性，忽略了现实场景中输入信息缺失导致的问题，即输入本身就无法回答。这种评估方式未能充分衡量模型在面对不完整信息时的鲁棒性和交互能力。", "method": "提出了一个“修复感知”的评估设置，明确区分可回答和不可回答的音频输入。通过“语义-声学掩蔽协议”构建配对评估条件。基于此设置，提出“可评估性感知与修复（EAR）分数”，这是一个非补偿性指标，同时评估模型在可回答条件下的任务能力和在不可回答条件下的修复行为。", "result": "在两个口语问答基准测试中，在不同LALMs上的实验显示，答案准确性和对话可靠性之间存在一致的差距。许多模型在输入可回答时表现良好，但大多数模型未能识别语义上的不可回答性并启动适当的对话修复。", "conclusion": "现有以准确性为中心的评估方法存在局限性。研究结果表明，模型在识别不可回答输入和启动对话修复方面存在不足，这促使研究需要进行可靠性评估，将不可回答的输入视为进行修复和持续交互的信号。"}}
{"id": "2601.13687", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13687", "abs": "https://arxiv.org/abs/2601.13687", "authors": ["Zhichao Liang", "Satoshi Nakamura"], "title": "Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue", "comment": null, "summary": "Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.", "AI": {"tldr": "本文提出了一个名为SocialMindChange的新基准，用于评估语言模型在动态心智理论（ToM）任务中的主动角色，即模型需要通过生成对话来改变其他角色的心智状态，而不仅仅是被动地跟踪它们。实验结果表明，现有的大型语言模型在这一任务上的表现远低于人类水平。", "motivation": "现有的动态ToM基准主要让语言模型扮演被动角色，只要求模型跟踪心智状态的变化。然而，在真实社交互动中，ToM也用于主动改变他人的心智状态以达成目标。因此，研究者希望创建一个能够评估语言模型在“改变心智”这一主动ToM能力的新基准。", "method": "研究者提出了SocialMindChange基准，它包含1200个社交情境，每个情境有4个角色和5个连续场景。模型扮演其中一个角色，需要在5个场景中生成对话，以实现目标心智状态，同时保持所有角色的心智状态一致性。该基准还包含更高阶的心智状态，并经过真人验证。研究者使用结构化的四步框架构建了这些情境。", "result": "在十个最先进的LLM上进行的评估显示，它们的平均表现比人类低54.2%。这表明当前LLM在维持和改变跨越长期、关联性交互中的心智状态表示方面仍然存在困难。", "conclusion": "SocialMindChange基准的建立填补了现有ToM评估的空白，突显了大型语言模型在主动运用ToM改变社交互动中的心智状态方面的不足。研究结果强调了在长序列社交情境中，模型在理解和操纵复杂心智状态方面的挑战。"}}
{"id": "2601.12325", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12325", "abs": "https://arxiv.org/abs/2601.12325", "authors": ["Eli Passov", "Nathan S. Netanyahu", "Yosi Keller"], "title": "Multi-Sensor Matching with HyperNetworks", "comment": null, "summary": "Hypernetworks are models that generate or modulate the weights of another network. They provide a flexible mechanism for injecting context and task conditioning and have proven broadly useful across diverse applications without significant increases in model size. We leverage hypernetworks to improve multimodal patch matching by introducing a lightweight descriptor-learning architecture that augments a Siamese CNN with (i) hypernetwork modules that compute adaptive, per-channel scaling and shifting and (ii) conditional instance normalization that provides modality-specific adaptation (e.g., visible vs. infrared, VIS-IR) in shallow layers. This combination preserves the efficiency of descriptor-based methods during inference while increasing robustness to appearance shifts. Trained with a triplet loss and hard-negative mining, our approach achieves state-of-the-art results on VIS-NIR and other VIS-IR benchmarks and matches or surpasses prior methods on additional datasets, despite their higher inference cost. To spur progress on domain shift, we also release GAP-VIR, a cross-platform (ground/aerial) VIS-IR patch dataset with 500K pairs, enabling rigorous evaluation of cross-domain generalization and adaptation.", "AI": {"tldr": "本文提出了一种利用超网络（hypernetworks）改进多模态图像块匹配（multimodal patch matching）的方法，该方法通过引入自适应的每通道缩放、偏移以及条件实例归一化来增强Siamese CNN，从而在保持效率的同时提高对外观变化的鲁棒性。研究在VIS-NIR和VIS-IR基准测试中取得了最先进的成果，并发布了一个新的VIS-IR数据集GAP-VIR以促进跨领域泛化研究。", "motivation": "现有方法在多模态图像块匹配中，尤其是在面对外观变化时，鲁棒性不足。同时，一些方法为了提高性能，会显著增加模型大小和推理成本。", "method": "利用超网络模块计算自适应的每通道缩放和偏移，并结合条件实例归一化，为Siamese CNN提供特定模态（如可见光和红外光）的浅层适应性。模型使用三元组损失（triplet loss）和难例挖掘（hard-negative mining）进行训练。", "result": "在VIS-NIR和其他VIS-IR基准测试中取得了最先进的性能，并在其他数据集上与现有方法相当或超越。该方法在保持高效推理的同时，显著提高了对外观变化的鲁棒性。", "conclusion": "超网络可以有效地增强多模态图像块匹配模型，在效率和鲁棒性之间取得良好平衡。提出的方法在多项基准测试中表现优异，并发布了新的数据集GAP-VIR以支持未来研究。"}}
{"id": "2601.12326", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12326", "abs": "https://arxiv.org/abs/2601.12326", "authors": ["Jing Zhang", "Bingjie Fan"], "title": "EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation", "comment": "11pages,10figures", "summary": "Existing image emotion editing methods struggle to disentangle emotional cues from latent content representations, often yielding weak emotional expression and distorted visual structures. To bridge this gap, we propose EmoKGEdit, a novel training-free framework for precise and structure-preserving image emotion editing. Specifically, we construct a Multimodal Sentiment Association Knowledge Graph (MSA-KG) to disentangle the intricate relationships among objects, scenes, attributes, visual clues and emotion. MSA-KG explicitly encode the causal chain among object-attribute-emotion, and as external knowledge to support chain of thought reasoning, guiding the multimodal large model to infer plausible emotion-related visual cues and generate coherent instructions. In addition, based on MSA-KG, we design a disentangled structure-emotion editing module that explicitly separates emotional attributes from layout features within the latent space, which ensures that the target emotion is effectively injected while strictly maintaining visual spatial coherence. Extensive experiments demonstrate that EmoKGEdit achieves excellent performance in both emotion fidelity and content preservation, and outperforms the state-of-the-art methods.", "AI": {"tldr": "提出了一种名为EmoKGEdit的训练无关框架，通过构建多模态情感关联知识图谱（MSA-KG）来解决现有图像情感编辑方法中情感线索与潜在内容表示纠缠不清的问题，实现了精确且保持结构的图像情感编辑。", "motivation": "现有图像情感编辑方法难以将情感线索与潜在内容表示分离开，导致情感表达较弱且视觉结构易失真。", "method": "构建多模态情感关联知识图谱（MSA-KG），显式编码对象-属性-情感之间的因果链，并作为外部知识引导多模态大模型进行推理。设计了一个基于MSA-KG的解耦结构-情感编辑模块，在潜在空间中将情感属性与布局特征分离。", "result": "EmoKGEdit在情感保真度和内容保持度方面均表现出色，优于现有最先进的方法。", "conclusion": "EmoKGEdit成功地将目标情感注入图像，同时严格保持视觉空间一致性，解决了现有方法的局限性。"}}
{"id": "2601.13709", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.HC", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.13709", "abs": "https://arxiv.org/abs/2601.13709", "authors": ["Christopher Kao", "Vanshika Vats", "James Davis"], "title": "Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games", "comment": "For associated dataset, see https://github.com/cocochief4/llm-mafia. Published in IEEE ICA 2025, waiting for IEEEXplore proceedings", "summary": "Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts.", "AI": {"tldr": "研究表明，使用GPT-4o在模拟的社交推理游戏“杀人游戏”中，大型语言模型（LLM）比人类更能有效地进行欺骗，因为它们的欺骗行为更难被识别。", "motivation": "随着LLM代理在各种应用中的普及，对它们的安全性（特别是欺骗能力）的担忧日益增加。尽管已有研究表明LLM在受控任务中可以欺骗，但在更真实的社交语境下，其使用自然语言进行欺骗的能力仍不清楚。", "method": "作者在一个异步多智能体框架下模拟了35场由GPT-4o扮演角色的“杀人游戏”。然后，他们利用GPT-4-Turbo构建了一个“杀人游戏检测器”，该检测器在不了解玩家角色信息的情况下分析游戏记录，以预测谁是杀人方。通过检测器的预测准确率来衡量欺骗的质量，并与28场人类游戏的检测准确率进行比较。", "result": "结果显示，在LLM模拟的游戏中，检测器预测杀人方的准确率低于在人类游戏中。这种趋势在不同游戏阶段和不同数量的杀人方情况下均保持一致，表明LLM的融入性更好，欺骗效果更佳。", "conclusion": "LLM在社交语境下展现出高超的欺骗能力，其欺骗行为比人类更难被识别，这揭示了LLM在社交互动中的潜在风险，并强调了进一步研究的必要性。研究还发布了一个LLM“杀人游戏”的文本数据集以供未来研究使用。"}}
{"id": "2601.13735", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13735", "abs": "https://arxiv.org/abs/2601.13735", "authors": ["Hojin Kim", "Jaehyung Kim"], "title": "Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection", "comment": "15 pages, 4 figures", "summary": "Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.", "AI": {"tldr": "当前概率置信度指标在评估推理质量时存在问题，它们对推理步骤间的因果依赖关系不敏感，主要捕捉表面流畅性。研究提出了一个对比因果度量，以更准确地评估输出选择。", "motivation": "现有概率置信度指标被用作推理质量的代理，但其有效性存疑，研究旨在探究这些指标是否真正捕捉了推理过程中步骤间的因果依赖关系。", "method": "通过引入三类系统性扰乱推理步骤间因果依赖但保持局部流畅性的扰动，研究评估了概率指标在这些扰动下的表现。同时，提出了一个对比因果度量来显式分离因果依赖。", "result": "即使在严重扰动（如硬注意力掩码）下，选择准确率仅有轻微下降，表明概率指标对逻辑结构不敏感，主要依赖表面流畅性和分布内先验。对比因果度量在输出选择上优于现有的基于概率的方法。", "conclusion": "概率置信度指标未能有效捕捉推理的逻辑结构，研究提出的对比因果度量能够更准确地评估推理质量，为改进模型选择提供了新方向。"}}
{"id": "2601.12974", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12974", "abs": "https://arxiv.org/abs/2601.12974", "authors": ["Hongyang Ma", "Tiantian Gu", "Huaiyuan Sun", "Huilin Zhu", "Yongxin Wang", "Jie Li", "Wubin Sun", "Zeliang Lian", "Yinghong Zhou", "Yi Gao", "Shirui Wang", "Zhihui Tang"], "title": "Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios", "comment": "29 pages, 15 figures", "summary": "The transition of Large Language Models (LLMs) from passive knowledge retrievers to autonomous clinical agents demands a shift in evaluation-from static accuracy to dynamic behavioral reliability. To explore this boundary in dentistry, a domain where high-quality AI advice uniquely empowers patient-participatory decision-making, we present the Standardized Clinical Management & Performance Evaluation (SCMPE) benchmark, which comprehensively assesses performance from knowledge-oriented evaluations (static objective tasks) to workflow-based simulations (multi-turn simulated patient interactions). Our analysis reveals that while models demonstrate high proficiency in static objective tasks, their performance precipitates in dynamic clinical dialogues, identifying that the primary bottleneck lies not in knowledge retention, but in the critical challenges of active information gathering and dynamic state tracking. Mapping \"Guideline Adherence\" versus \"Decision Quality\" reveals a prevalent \"High Efficacy, Low Safety\" risk in general models. Furthermore, we quantify the impact of Retrieval-Augmented Generation (RAG). While RAG mitigates hallucinations in static tasks, its efficacy in dynamic workflows is limited and heterogeneous, sometimes causing degradation. This underscores that external knowledge alone cannot bridge the reasoning gap without domain-adaptive pre-training. This study empirically charts the capability boundaries of dental LLMs, providing a roadmap for bridging the gap between standardized knowledge and safe, autonomous clinical practice.", "AI": {"tldr": "本研究提出了一个名为SCMPE的基准测试，用于评估大型语言模型（LLM）在牙科领域的自主临床能力，发现模型在静态知识评估中表现良好，但在动态临床对话中存在信息收集和状态追踪的瓶颈，且存在“高疗效、低安全性”的风险。RAG技术在动态场景下的效果有限。", "motivation": "大型语言模型正从被动知识检索者向自主临床代理转变，需要评估其动态行为可靠性，尤其是在牙科领域，AI建议能增强患者决策。因此，需要一个能全面评估LLM在临床场景中表现的基准。", "method": "提出了SCMPE基准，包含从静态客观任务到多轮模拟病人互动的流程模拟。通过分析模型的知识评估、流程模拟、指南遵循度和决策质量，并量化检索增强生成（RAG）的影响。", "result": "模型在静态任务中表现高，但在动态对话中性能下降，主要瓶颈在于信息收集和状态追踪。通用模型存在“高疗效、低安全性”的风险。RAG在动态流程中效果有限且异质，有时反而导致性能下降。", "conclusion": "现有的LLM在静态知识任务上表现优异，但在动态临床决策中存在挑战，尤其是在信息收集和状态追踪方面。RAG不足以弥补推理差距，除非结合领域自适应预训练。SCMPE基准为评估和改进牙科LLM提供了方向，以实现安全自主的临床实践。"}}
{"id": "2601.13752", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13752", "abs": "https://arxiv.org/abs/2601.13752", "authors": ["Chak Tou Leong", "Dingwei Chen", "Heming Xia", "Qingyu Yin", "Sunbowen Lee", "Jian Wang", "Wenjie Li"], "title": "Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering", "comment": "Working in progress", "summary": "Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \\textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.", "AI": {"tldr": "本研究提出了一种名为RELIEF的新框架，通过调整大型推理模型（LRM）的内部“推理信念”，来改善其推理效率和准确性，且无需监督推理过程。", "motivation": "现有方法（如强化学习或金标准推理轨迹微调）用于改进LRM行为成本高昂且难以扩展。研究人员希望找到一种更有效、可扩展的方法来塑造LRM的行为。", "method": "通过logit probing捕捉LRM内部的“推理信念”。基于此，提出RELIEF框架，通过微调模型在合成的、自我反思的问答对上，将模型的自我概念与其目标信念蓝图对齐。此过程无需推理过程的监督。", "result": "RELIEF在效率和准确性任务上，性能与监督式和基于偏好的基线方法相当或更优，且训练成本更低。研究还验证了改变模型的推理信念能有效塑造其行为。", "conclusion": "RELIEF是一种有效且经济的框架，可以通过调整LRM的内在推理信念来改进其行为，解决了现有方法成本高昂和可扩展性差的问题。"}}
{"id": "2601.13761", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13761", "abs": "https://arxiv.org/abs/2601.13761", "authors": ["Shengda Fan", "Xuyan Ye", "Yankai Lin"], "title": "DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution", "comment": null, "summary": "Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC.", "AI": {"tldr": "本文提出了一种名为DARC（Decoupled Asymmetric Reasoning Curriculum）的两阶段框架，用于稳定和改进大型语言模型的自我学习过程，通过解耦问答者（Questioner）和求解者（Solver）的训练，并采用非对称自我蒸馏机制，显著提高了模型在多个推理基准上的性能，且不依赖于人类标注。", "motivation": "现有的大型语言模型自学习框架存在优化不稳定的问题，主要由问答者依赖于求解者的反馈引入的非平稳目标和求解者使用自身生成的伪标签进行监督导致的引导误差引起。", "method": "DARC框架包含两个阶段：1. 训练问答者生成经过难度校准的问题，该过程以明确的难度级别和外部语料库为条件。2. 训练求解者，采用非对称自我蒸馏机制，一个文档增强的教师模型生成高质量伪标签来监督缺乏文档访问权限的学生求解者。", "result": "DARC在九个推理基准和三个骨干模型上平均提高了10.9分，且不依赖于模型架构。DARC的性能始终优于所有基线方法，并接近完全监督模型的性能。", "conclusion": "DARC框架成功地稳定了大型语言模型的自进化过程，通过解耦问答者和求解者的训练以及引入非对称自我蒸馏，有效克服了现有方法的局限性，并在多种推理任务上实现了显著的性能提升，显示出其在无需人工标注的情况下达到高性能的潜力。"}}
{"id": "2601.12995", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12995", "abs": "https://arxiv.org/abs/2601.12995", "authors": ["Runxuan Liu", "Xianhao Ou", "Xinyan Ma", "Jiyuan Wang", "Jiafeng Liang", "Jiaqi Li", "Tao He", "Zheng Chu", "Rongchuan Mu", "Zekun Wang", "Baoxin Wang", "Dayong Wu", "Ming Liu", "Shijin Wang", "Guoping Hu", "Bing Qin"], "title": "Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models", "comment": null, "summary": "Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based optimization, existing methods still suffer from coarse-grained supervision, reward hacking, high training costs, and poor generalization. To address these issues, we propose the Graph Reasoning Paradigm (GRP), which realizes structured and symbolic reasoning, implemented via graph-structured representations with step-level cognitive labels. Building upon GRP, we further design Process-Aware Stratified Clipping Group Relative Policy Optimization (PASC-GRPO), which leverages structured evaluation to replace semantic evaluation, achieves process-aware verification through graph-structured outcome rewards, and mitigates reward hacking via stratified clipping advantage estimation. Experiments demonstrate significant improvements across mathematical reasoning and code generation tasks. Data, models, and code will be released later.", "AI": {"tldr": "提出图推理范式 (GRP) 和进程感知分层裁剪组相对策略优化 (PASC-GRPO) 方法，以结构化和符号化的方式提升大型语言模型的推理能力，解决现有方法的计算瓶颈、粗粒度监督、奖励劫持、高成本和泛化差等问题。", "motivation": "现有 LLM 的推理以纯文本形式生成，导致语义评估的计算瓶颈，且基于 RLVR 的方法存在监督粗粒度、奖励劫持、训练成本高和泛化性差等问题。", "method": "提出图推理范式 (GRP)，采用图结构表示和分步认知标签实现结构化、符号化推理。在此基础上，设计进程感知分层裁剪组相对策略优化 (PASC-GRPO)，用结构化评估替代语义评估，通过基于图的奖励实现进程感知验证，并利用分层裁剪优势估计来减少奖励劫持。", "result": "在数学推理和代码生成任务上取得了显著的改进。", "conclusion": "GRP 和 PASC-GRPO 能够通过结构化评估和进程感知验证，有效提升 LLM 的推理能力，克服现有方法的局限性。"}}
{"id": "2601.13770", "categories": ["cs.AI", "cs.CL", "cs.LG", "q-fin.CP", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2601.13770", "abs": "https://arxiv.org/abs/2601.13770", "authors": ["Mostapha Benhenda"], "title": "Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance", "comment": null, "summary": "We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench", "AI": {"tldr": "本文提出了Look-Ahead-Bench，一个用于评估金融领域时间点LLM（Point-in-Time LLMs）前瞻性偏差的标准基准。该基准通过模拟实际金融工作流程来测试模型行为，并分析模型在不同市场环境下表现的衰减，以区分真实预测能力和记忆能力。测试结果表明，标准LLM存在明显的前瞻性偏差，而PiT-Inference的模型则表现出更好的泛化能力和推理能力。", "motivation": "现有研究主要通过问答方式测试LLM的内在前瞻性知识，而忽略了在实际金融工作流程中的应用。因此，需要一个标准化的基准来衡量LLM在实际场景中的前瞻性偏差，并区分真实预测能力与记忆能力。", "method": "提出Look-Ahead-Bench基准，评估模型在实际金融工作流程中的行为。通过分析模型在不同时间市场环境下的性能衰减来区分真实预测能力和记忆能力。引入量化基线来设定性能阈值。测试了Llama 3.1、DeepSeek 3.2以及PiT-Inference系列模型（Pitinf-Small, Pitinf-Medium, Pitinf-Large）。", "result": "标准LLM在Alpha衰减方面表现出显著的前瞻性偏差。而Pitinf模型则随着模型规模的增大，展现出更强的泛化能力和推理能力，且前瞻性偏差较小。", "conclusion": "Look-Ahead-Bench为金融LLM的时间偏差标准化评估奠定了基础，并提供了一个实用的框架来识别适用于实际部署的模型。研究结果表明，PiT-Inference模型在处理金融时间序列数据方面优于标准LLM。"}}
{"id": "2601.12357", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12357", "abs": "https://arxiv.org/abs/2601.12357", "authors": ["Hailing Jin", "Huiying Li"], "title": "SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence", "comment": null, "summary": "Recent advances in semantic correspondence have been largely driven by the use of pre-trained large-scale models. However, a limitation of these approaches is their dependence on high-resolution input images to achieve optimal performance, which results in considerable computational overhead. In this work, we address a fundamental limitation in current methods: the irreversible fusion of adjacent keypoint features caused by deep downsampling operations. This issue is triggered when semantically distinct keypoints fall within the same downsampled receptive field (e.g., 16x16 patches). To address this issue, we present SimpleMatch, a simple yet effective framework for semantic correspondence that delivers strong performance even at low resolutions. We propose a lightweight upsample decoder that progressively recovers spatial detail by upsampling deep features to 1/4 resolution, and a multi-scale supervised loss that ensures the upsampled features retain discriminative features across different spatial scales. In addition, we introduce sparse matching and window-based localization to optimize training memory usage and reduce it by 51%. At a resolution of 252x252 (3.3x smaller than current SOTA methods), SimpleMatch achieves superior performance with 84.1% PCK@0.1 on the SPair-71k benchmark. We believe this framework provides a practical and efficient baseline for future research in semantic correspondence. Code is available at: https://github.com/hailong23-jin/SimpleMatch.", "AI": {"tldr": "本文提出SimpleMatch框架，通过轻量级上采样解码器和多尺度监督损失，解决了现有语义对应方法在低分辨率下特征融合问题，实现了在低分辨率下的高效高性能。", "motivation": "现有基于预训练大模型的语义对应方法依赖高分辨率输入，计算开销大。此外，深度下采样操作会不可逆地融合相邻关键点特征，导致在低分辨率下性能下降。", "method": "提出一个轻量级上采样解码器，逐步将深层特征上采样至1/4分辨率，恢复空间细节。引入多尺度监督损失，确保上采样后的特征在不同尺度下都能保留区分性。同时采用稀疏匹配和基于窗口的定位来优化训练内存。", "result": "在252x252分辨率下（比当前SOTA方法小3.3倍），SimpleMatch在SPair-71k基准上取得了84.1%的PCK@0.1性能，优于现有方法。训练内存使用量减少了51%。", "conclusion": "SimpleMatch提供了一个实用且高效的语义对应新基准，即使在低分辨率下也能取得优异性能，减少了计算开销，为未来的研究提供了基础。"}}
{"id": "2601.12346", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12346", "abs": "https://arxiv.org/abs/2601.12346", "authors": ["Peizhou Huang", "Zixuan Zhong", "Zhongwei Wan", "Donghao Zhou", "Samiul Alam", "Xin Wang", "Zexin Li", "Zhihao Dou", "Li Zhu", "Jing Xiong", "Chaofan Tao", "Yan Xu", "Dimitrios Dimitriadis", "Tuo Zhang", "Mi Zhang"], "title": "MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents", "comment": null, "summary": "Deep Research Agents (DRAs) generate citation-rich reports via multi-step search and synthesis, yet existing benchmarks mainly target text-only settings or short-form multimodal QA, missing end-to-end multimodal evidence use. We introduce MMDeepResearch-Bench (MMDR-Bench), a benchmark of 140 expert-crafted tasks across 21 domains, where each task provides an image-text bundle to evaluate multimodal understanding and citation-grounded report generation. Compared to prior setups, MMDR-Bench emphasizes report-style synthesis with explicit evidence use, where models must connect visual artifacts to sourced claims and maintain consistency across narrative, citations, and visual references. We further propose a unified, interpretable evaluation pipeline: Formula-LLM Adaptive Evaluation (FLAE) for report quality, Trustworthy Retrieval-Aligned Citation Evaluation (TRACE) for citation-grounded evidence alignment, and Multimodal Support-Aligned Integrity Check (MOSAIC) for text-visual integrity, each producing fine-grained signals that support error diagnosis beyond a single overall score. Experiments across 25 state-of-the-art models reveal systematic trade-offs between generation quality, citation discipline, and multimodal grounding, highlighting that strong prose alone does not guarantee faithful evidence use and that multimodal integrity remains a key bottleneck for deep research agents.", "AI": {"tldr": "本文提出了MMDR-Bench基准和FLAE、TRACE、MOSAIC评估流程，用于评估多模态深度研究代理（DRA）在图像-文本混合环境下生成引用丰富报告的能力，并通过实验揭示了生成质量、引用准确性和多模态基础之间的系统性权衡。", "motivation": "现有基准主要针对纯文本或短篇多模态问答，未能充分评估DRAs在端到端多模态证据使用方面的能力，尤其是在需要结合图像和文本生成引用丰富报告的场景。", "method": "提出了MMDeepResearch-Bench (MMDR-Bench)，一个包含140个跨21个领域任务的基准，每个任务提供图像-文本组合。同时，设计了一个统一的、可解释的评估流程，包括用于报告质量评估的Formula-LLM Adaptive Evaluation (FLAE)，用于引用证据对齐的Trustworthy Retrieval-Aligned Citation Evaluation (TRACE)，以及用于图文完整性检查的Multimodal Support-Aligned Integrity Check (MOSAIC)。", "result": "在25个最先进模型上的实验表明，在生成质量、引用准确性和多模态基础之间存在系统性权衡。仅有优秀的文本生成能力并不足以保证忠实地使用证据，而多模态的完整性仍然是深度研究代理的关键瓶颈。", "conclusion": "MMDR-Bench和FLAE、TRACE、MOSAIC评估流程能够有效地评估多模态DRAs在报告生成中的性能，并诊断其在多模态证据使用方面的不足。研究结果强调了提升DRAs在整合视觉信息、保证引用准确性和维持图文一致性方面的能力的重要性。"}}
{"id": "2601.13018", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13018", "abs": "https://arxiv.org/abs/2601.13018", "authors": ["Ghislain Dorian Tchuente Mondjo"], "title": "Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context", "comment": "Accepted at \"EAI AFRICOMM 2025 - 17th EAI International Conference on Communications and Networks in Africa\"", "summary": "Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.", "AI": {"tldr": "提出了一种新的双向注意力BiRNN模型（BiAtt-BiRNN-HateXplain），用于同时进行仇恨言论的分类和解释，解决了现有模型中注意力不一致的问题，并通过实验证明了其在检测性能、可解释性和减少偏见方面的改进。", "motivation": "现有的黑盒模型在仇恨言论检测中的解释性不足，而后置解释方法（如LIME, SHAP）和现有的多任务方法（如基于HateXplain）都存在局限性。特别是基于HateXplain的方法，其注意力预测存在较大变异性，导致解释不一致、预测不稳定和学习困难。研究旨在解决这些问题，提高模型透明度和可靠性。", "method": "提出BiAtt-BiRNN-HateXplain模型，该模型采用多任务学习框架，同时进行分类和解释。利用BiRNN层考虑输入数据的序列特性，并通过双向注意力机制来解决注意力变异性问题。模型比大型语言模型（LLMs）更易于解释。", "result": "在HateXplain数据集上的实验结果显示，所提出的模型在仇恨言论检测性能、可解释性方面均有显著提升，并且在减少无意偏见方面取得了更好的效果。", "conclusion": "BiAtt-BiRNN-HateXplain模型能够有效地解决现有仇恨言论检测方法中注意力不一致的问题，通过端到端的学习方式同时提升分类准确率和模型的可解释性，并能有效减少与社区相关的无意偏见。"}}
{"id": "2601.12979", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12979", "abs": "https://arxiv.org/abs/2601.12979", "authors": ["Qingyu Lu", "Liang Ding", "Kanjian Zhang", "Jinxia Zhang", "Dacheng Tao"], "title": "The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check", "comment": "Under Review", "summary": "The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agentic paradigms: Embodied Agents (requiring long-horizon planning) and Tool-Calling Agents (requiring precise formatting). Contrary to the efficiency hype, our results on Agentboard and BFCL reveal a \"bitter lesson\": current dLLMs fail to serve as reliable agentic backbones, frequently leading to systematically failure. (1) In Embodied settings, dLLMs suffer repeated attempts, failing to branch under temporal feedback. (2) In Tool-Calling settings, dLLMs fail to maintain symbolic precision (e.g. strict JSON schemas) under diffusion noise. To assess the potential of dLLMs in agentic workflows, we introduce DiffuAgent, a multi-agent evaluation framework that integrates dLLMs as plug-and-play cognitive cores. Our analysis shows that dLLMs are effective in non-causal roles (e.g., memory summarization and tool selection) but require the incorporation of causal, precise, and logically grounded reasoning mechanisms into the denoising process to be viable for agentic tasks.", "AI": {"tldr": "研究表明，尽管扩散模型（dLLMs）在理论上具有实时交互的潜力，但目前它们在具身智能体和工具调用智能体等需要长远规划和精确格式化的任务中表现不佳，存在系统性失败。dLLMs 在非因果角色（如记忆总结和工具选择）中表现良好，但需要引入因果、精确和逻辑推理机制才能用于代理任务。", "motivation": "研究动机在于探索扩散模型（dLLMs）能否打破自回归模型的顺序延迟瓶颈，实现实时的智能体交互，并评估其在代理任务中的实际有效性。", "method": "作者对 dLLMs（如 LLaDA、Dream）在具身智能体（需要长远规划）和工具调用智能体（需要精确格式化）两种代理范式下进行了评估，并引入了一个名为 DiffuAgent 的多智能体评估框架来集成 dLLMs。", "result": "研究发现，当前 dLLMs 在代理任务中表现不佳，存在系统性失败：在具身智能体任务中，dLLMs 倾向于重复尝试，在时间反馈下无法有效分支；在工具调用任务中，dLLMs 难以在扩散噪声下保持符号精度（如严格的 JSON 模式）。然而，dLLMs 在非因果角色（如记忆总结和工具选择）中表现有效。", "conclusion": "当前的 dLLMs 无法作为可靠的代理核心，其效率提升并未转化为有效的代理行为。为了使 dLLMs 适用于代理任务，需要将因果、精确和逻辑上合理的推理机制集成到去噪过程中，并可将其用于非因果角色。"}}
{"id": "2601.12329", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12329", "abs": "https://arxiv.org/abs/2601.12329", "authors": ["Mithlesh Singla", "Seema Kumari", "Shanmuganathan Raman"], "title": "FlowIID: Single-Step Intrinsic Image Decomposition via Latent Flow Matching", "comment": null, "summary": "Intrinsic Image Decomposition (IID) separates an image into albedo and shading components. It is a core step in many real-world applications, such as relighting and material editing. Existing IID models achieve good results, but often use a large number of parameters. This makes them costly to combine with other models in real-world settings. To address this problem, we propose a flow matching-based solution. For this, we design a novel architecture, FlowIID, based on latent flow matching. FlowIID combines a VAE-guided latent space with a flow matching module, enabling a stable decomposition of albedo and shading. FlowIID is not only parameter-efficient, but also produces results in a single inference step. Despite its compact design, FlowIID delivers competitive and superior results compared to existing models across various benchmarks. This makes it well-suited for deployment in resource-constrained and real-time vision applications.", "AI": {"tldr": "提出了一种基于流匹配的参数高效的内禀图像分解模型FlowIID，该模型在一个推理步骤中实现稳定、有竞争力的分解。", "motivation": "现有内禀图像分解模型参数量大，在实际应用中与其他模型结合成本高。", "method": "设计了一种基于潜在流匹配的新型架构FlowIID，结合了VAE引导的潜在空间和流匹配模块，实现了稳定的反射率和阴影分解。", "result": "FlowIID在各种基准测试中取得了具有竞争力甚至优于现有模型的结果，并且参数效率高，推理速度快。", "conclusion": "FlowIID因其紧凑的设计、高效的性能和出色的分解效果，非常适合资源受限和实时视觉应用。"}}
{"id": "2601.12983", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12983", "abs": "https://arxiv.org/abs/2601.12983", "authors": ["Jesus-German Ortiz-Barajas", "Jonathan Tonglet", "Vivek Gupta", "Iryna Gurevych"], "title": "ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation", "comment": null, "summary": "Multimodal large language models (MLLMs) are increasingly used to automate chart generation from data tables, enabling efficient data analysis and reporting but also introducing new misuse risks. In this work, we introduce ChartAttack, a novel framework for evaluating how MLLMs can be misused to generate misleading charts at scale. ChartAttack injects misleaders into chart designs, aiming to induce incorrect interpretations of the underlying data. Furthermore, we create AttackViz, a chart question-answering (QA) dataset where each (chart specification, QA) pair is labeled with effective misleaders and their induced incorrect answers. Experiments in in-domain and cross-domain settings show that ChartAttack significantly degrades the QA performance of MLLM readers, reducing accuracy by an average of 19.6 points and 14.9 points, respectively. A human study further shows an average 20.2 point drop in accuracy for participants exposed to misleading charts generated by ChartAttack. Our findings highlight an urgent need for robustness and security considerations in the design, evaluation, and deployment of MLLM-based chart generation systems. We make our code and data publicly available.", "AI": {"tldr": "本研究提出了ChartAttack框架，用于评估多模态大语言模型（MLLMs）生成误导性图表的风险，并创建了包含误导信息的AttackViz数据集。实验证明ChartAttack能显著降低MLLMs在图表问答任务上的性能，并且人类研究也显示出类似效果，强调了MLLM图表生成系统的安全性和鲁棒性需求。", "motivation": "随着MLLMs在自动化图表生成方面的广泛应用，其潜在的滥用风险也日益显现，尤其是在生成误导性图表方面。本研究旨在系统性地评估这种滥用风险，并为开发更安全的系统提供依据。", "method": "研究提出了ChartAttack框架，通过在图表设计中注入“误导者”（misleaders）来诱导用户产生错误的解读。同时，创建了一个名为AttackViz的图表问答数据集，其中包含了有效的误导者及其诱导的错误答案。", "result": "在MLLM图表问答任务中，ChartAttack将模型在同域和跨域设置下的准确率分别平均降低了19.6和14.9个百分点。人类研究也显示，暴露于ChartAttack生成的误导性图表后，参与者的准确率平均下降了20.2个百分点。", "conclusion": "MLLMs在图表生成方面存在被滥用的风险，能够生成误导性图表从而影响用户对数据的正确解读。因此，在设计、评估和部署基于MLLM的图表生成系统时，必须高度重视其鲁棒性和安全性。"}}
{"id": "2601.13846", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13846", "abs": "https://arxiv.org/abs/2601.13846", "authors": ["Glinskaya Maria"], "title": "Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments", "comment": null, "summary": "This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.", "AI": {"tldr": "本文提出了一种名为“虚拟都市主义”（VU）的多模态AI分析框架，利用合成城市副本量化城市身份，并开发了城市身份水平（UIL）指标。", "motivation": "现有城市身份度量方法计算上不可行，本文旨在开发一种计算上可行的城市身份度量方法，以AI驱动的方式量化城市身份。", "method": "利用Stable Diffusion和LoRA模型生成东京9个区域的合成城市副本（动态序列），并进行了人类评估实验，以评估副本的感知合法性，量化区域身份，并识别核心身份形成元素。", "result": "合成副本的平均识别准确率约为81%，证实了副本的有效性。UIL指标能够评估不同区域的身份水平，而语义分析揭示了文化嵌入的类型是核心身份形成元素。", "conclusion": "虚拟都市主义（VU）框架为AI增强的城市分析提供了一种可行的方法，并为实现自动化、多参数的城市身份度量铺平了道路。"}}
{"id": "2601.12337", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12337", "abs": "https://arxiv.org/abs/2601.12337", "authors": ["Jiahui Sheng", "Xiaorun Li", "Shuhan Chen"], "title": "Turbo-GoDec: Exploiting the Cluster Sparsity Prior for Hyperspectral Anomaly Detection", "comment": null, "summary": "As a key task in hyperspectral image processing, hyperspectral anomaly detection has garnered significant attention and undergone extensive research. Existing methods primarily relt on two prior assumption: low-rank background and sparse anomaly, along with additional spatial assumptions of the background. However, most methods only utilize the sparsity prior assumption for anomalies and rarely expand on this hypothesis. From observations of hyperspectral images, we find that anomalous pixels exhibit certain spatial distribution characteristics: they often manifest as small, clustered groups in space, which we refer to as cluster sparsity of anomalies. Then, we combined the cluster sparsity prior with the classical GoDec algorithm, incorporating the cluster sparsity prior into the S-step of GoDec. This resulted in a new hyperspectral anomaly detection method, which we called Turbo-GoDec. In this approach, we modeled the cluster sparsity prior of anomalies using a Markov random field and computed the marginal probabilities of anomalies through message passing on a factor graph. Locations with high anomalous probabilities were treated as the sparse component in the Turbo-GoDec. Experiments are conducted on three real hyperspectral image (HSI) datasets which demonstrate the superior performance of the proposed Turbo-GoDec method in detecting small-size anomalies comparing with the vanilla GoDec (LSMAD) and state-of-the-art anomaly detection methods. The code is available at https://github.com/jiahuisheng/Turbo-GoDec.", "AI": {"tldr": "提出了一种名为Turbo-GoDec的新型高光谱异常检测方法，该方法通过引入“簇稀疏性”先验来提升传统GoDec算法在检测小尺寸异常体方面的性能。", "motivation": "现有高光谱异常检测方法多依赖低秩背景和稀疏异常的先验假设，但很少深入挖掘异常的稀疏性特征。作者观察到高光谱图像中的异常像素常呈现空间上的小簇分布，即“簇稀疏性”，并希望将此先验引入异常检测。", "method": "将“簇稀疏性”先验与GoDec算法相结合，具体是将该先验整合到GoDec算法的S-step中。簇稀疏性通过马尔可夫随机场建模，并利用因子图上的消息传递计算异常的边际概率。高异常概率的区域被视为Turbo-GoDec中的稀疏分量。", "result": "在三个真实高光谱图像数据集上的实验表明，提出的Turbo-GoDec方法在检测小尺寸异常体方面优于Vanilla GoDec (LSMAD) 及其他先进的异常检测方法。", "conclusion": "Turbo-GoDec通过引入簇稀疏性先验，成功提升了高光谱异常检测的性能，尤其在处理小尺寸异常体时表现出优势。"}}
{"id": "2601.12379", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12379", "abs": "https://arxiv.org/abs/2601.12379", "authors": ["Jiahui Sheng", "Yidan Shi", "Shu Xiang", "Xiaorun Li", "Shuhan Chen"], "title": "Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection", "comment": null, "summary": "Hyperspectral images (HSIs) are a type of image that contains abundant spectral information. As a type of real-world data, the high-dimensional spectra in hyperspectral images are actually determined by only a few factors, such as chemical composition and illumination. Thus, spectra in hyperspectral images are highly likely to satisfy the manifold hypothesis. Based on the hyperspectral manifold hypothesis, we propose a novel hyperspectral anomaly detection method (named ScoreAD) that leverages the time-dependent gradient field of the data distribution (i.e., the score), as learned by a score-based generative model (SGM). Our method first trains the SGM on the entire set of spectra from the hyperspectral image. At test time, each spectrum is passed through a perturbation kernel, and the resulting perturbed spectrum is fed into the trained SGM to obtain the estimated score. The manifold hypothesis of HSIs posits that background spectra reside on one or more low-dimensional manifolds. Conversely, anomalous spectra, owing to their unique spectral signatures, are considered outliers that do not conform to the background manifold. Based on this fundamental discrepancy in their manifold distributions, we leverage a generative SGM to achieve hyperspectral anomaly detection. Experiments on the four hyperspectral datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/jiahuisheng/ScoreAD.", "AI": {"tldr": "提出了一种基于分数（score）的生成模型（SGM）的新型高光谱异常检测方法ScoreAD。该方法利用了数据分布的时间相关梯度场（即分数），并假设高光谱数据满足流形假设。", "motivation": "高光谱图像（HSI）具有丰富的光谱信息，但这些信息实际上由少数几个因素决定，因此很可能满足流形假设。研究者希望利用这一假设来开发一种新的异常检测方法。", "method": "首先，在整个高光谱图像的光谱集上训练一个分数生成模型（SGM）。在测试时，将每个光谱通过一个扰动核，然后将扰动后的光谱输入到训练好的SGM中，以获得估计的分数。该方法利用了背景光谱位于低维流形上，而异常光谱是偏离该流形的观点的。", "result": "在四个高光谱数据集上的实验表明了所提出方法的有效性。", "conclusion": "基于高光谱流形假设，利用生成式SGM可以有效地进行高光谱异常检测，ScoreAD方法是一种有效的方法。"}}
{"id": "2601.13035", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13035", "abs": "https://arxiv.org/abs/2601.13035", "authors": ["Xu Xiaodan", "Hu Xiaolin"], "title": "SASA: Semantic-Aware Contrastive Learning Framework with Separated Attention for Triple Classification", "comment": "in progress", "summary": "Knowledge Graphs~(KGs) often suffer from unreliable knowledge, which restricts their utility. Triple Classification~(TC) aims to determine the validity of triples from KGs. Recently, text-based methods learn entity and relation representations from natural language descriptions, significantly improving the generalization capabilities of TC models and setting new benchmarks in performance. However, there are still two critical challenges. First, existing methods often ignore the effective semantic interaction among different KG components. Second, most approaches adopt single binary classification training objective, leading to insufficient semantic representation learning. To address these challenges, we propose \\textbf{SASA}, a novel framework designed to enhance TC models via separated attention mechanism and semantic-aware contrastive learning~(CL). Specifically, we first propose separated attention mechanism to encode triples into decoupled contextual representations and then fuse them through a more effective interactive way. Then, we introduce semantic-aware hierarchical CL as auxiliary training objective to guide models in improving their discriminative capabilities and achieving sufficient semantic learning, considering both local level and global level CL. Experimental results across two benchmark datasets demonstrate that SASA significantly outperforms state-of-the-art methods. In terms of accuracy, we advance the state-of-the-art by +5.9\\% on FB15k-237 and +3.4\\% on YAGO3-10.", "AI": {"tldr": "本文提出了一种名为SASA的新框架，通过分离注意力机制和语义感知对比学习来提升知识图谱三元组分类模型的性能，解决了现有方法忽略组件间语义交互和训练目标单一的问题。", "motivation": "现有的基于文本的知识图谱三元组分类方法在泛化能力和性能上有所提升，但仍面临两个关键挑战：1. 忽略了知识图谱不同组件之间的有效语义交互；2. 采用单一的二元分类训练目标，导致语义表示学习不足。", "method": "SASA框架包含两个主要部分：1. 分离注意力机制：对三元组进行编码，生成解耦的上下文表示，并通过更有效的方式进行融合。2. 语义感知分层对比学习：作为辅助训练目标，在局部和全局层面引导模型提升判别能力和实现充分的语义学习。", "result": "SASA在FB15k-237和YAGO3-10两个基准数据集上均显著优于现有最先进的方法，准确率分别提升了+5.9%和+3.4%。", "conclusion": "SASA框架通过引入分离注意力机制和语义感知对比学习，有效解决了知识图谱三元组分类中语义交互不足和表示学习不充分的问题，并在实验中取得了显著的性能提升。"}}
{"id": "2601.13024", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13024", "abs": "https://arxiv.org/abs/2601.13024", "authors": ["Chongyuan Dai", "Yaling Shen", "Jinpeng Hu", "Zihan Gao", "Jia Li", "Yishun Jiang", "Yaxiong Wang", "Liu Liu", "Zongyuan Ge"], "title": "Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses", "comment": "24 pages, 10 figures, 9 Tables", "summary": "Culture serves as a fundamental determinant of human affective processing and profoundly shapes how individuals perceive and interpret emotional stimuli. Despite this intrinsic link extant evaluations regarding cultural alignment within Large Language Models primarily prioritize declarative knowledge such as geographical facts or established societal customs. These benchmarks remain insufficient to capture the subjective interpretative variance inherent to diverse sociocultural lenses. To address this limitation, we introduce CEDAR, a multimodal benchmark constructed entirely from scenarios capturing Culturally \\underline{\\textsc{E}}licited \\underline{\\textsc{D}}istinct \\underline{\\textsc{A}}ffective \\underline{\\textsc{R}}esponses. To construct CEDAR, we implement a novel pipeline that leverages LLM-generated provisional labels to isolate instances yielding cross-cultural emotional distinctions, and subsequently derives reliable ground-truth annotations through rigorous human evaluation. The resulting benchmark comprises 10,962 instances across seven languages and 14 fine-grained emotion categories, with each language including 400 multimodal and 1,166 text-only samples. Comprehensive evaluations of 17 representative multilingual models reveal a dissociation between language consistency and cultural alignment, demonstrating that culturally grounded affective understanding remains a significant challenge for current models.", "AI": {"tldr": "本研究提出了CEDAR，一个包含10,962个多模态和纯文本实例的跨文化情感响应基准，旨在评估大型语言模型在理解文化差异方面的情感处理能力。研究发现，现有模型在语言一致性与文化一致性之间存在差异，表明文化情感理解仍是当前模型面临的挑战。", "motivation": "现有的评估大型语言模型（LLM）文化对齐程度的基准主要关注事实性知识和习俗，而忽略了不同文化背景下个体对情感刺激的主观解释差异。研究旨在解决这一局限性，提出一个能够捕捉文化差异引起的情感响应的评估方法。", "method": "研究者引入了一个名为CEDAR的多模态基准。该基准的构建过程包括：1. 利用LLM生成初步标签，识别出能引发跨文化情感差异的实例；2. 通过严格的人工评估，从中导出可靠的地面真值标注。CEDAR包含10,962个实例，涵盖7种语言和14种细粒度情感类别，其中每种语言包含400个多模态样本和1,166个纯文本样本。", "result": "对17个代表性多语言模型的评估显示，模型在语言一致性（在不同语言中表现相似）和文化一致性（能否正确理解特定文化下的情感表达）之间存在脱节。这意味着即使模型在多种语言上表现良好，也不一定能准确理解跨文化的细微情感差异。", "conclusion": "目前的LLM在实现文化情感理解方面仍面临显著挑战。尽管模型可能在语言一致性方面取得进展，但真正理解和适应不同文化背景下的情感表达和解释仍然是一个亟待解决的问题。"}}
{"id": "2601.12366", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12366", "abs": "https://arxiv.org/abs/2601.12366", "authors": ["Jiafei Zhang", "Songliang Cao", "Binghui Xu", "Yanan Li", "Weiwei Jia", "Tingting Wu", "Hao Lu", "Weijuan Hu", "Zhiguo Han"], "title": "DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data", "comment": "13 pages, 15 figures and 7 tables", "summary": "DepthCropSeg++: a foundation model for crop segmentation, capable of segmenting different crop species under open in-field environment. Crop segmentation is a fundamental task for modern agriculture, which closely relates to many downstream tasks such as plant phenotyping, density estimation, and weed control. In the era of foundation models, a number of generic large language and vision models have been developed. These models have demonstrated remarkable real world generalization due to significant model capacity and largescale datasets. However, current crop segmentation models mostly learn from limited data due to expensive pixel-level labelling cost, often performing well only under specific crop types or controlled environment. In this work, we follow the vein of our previous work DepthCropSeg, an almost unsupervised approach to crop segmentation, to scale up a cross-species and crossscene crop segmentation dataset, with 28,406 images across 30+ species and 15 environmental conditions. We also build upon a state-of-the-art semantic segmentation architecture ViT-Adapter architecture, enhance it with dynamic upsampling for improved detail awareness, and train the model with a two-stage selftraining pipeline. To systematically validate model performance, we conduct comprehensive experiments to justify the effectiveness and generalization capabilities across multiple crop datasets. Results demonstrate that DepthCropSeg++ achieves 93.11% mIoU on a comprehensive testing set, outperforming both supervised baselines and general-purpose vision foundation models like Segmentation Anything Model (SAM) by significant margins (+0.36% and +48.57% respectively). The model particularly excels in challenging scenarios including night-time environment (86.90% mIoU), high-density canopies (90.09% mIoU), and unseen crop varieties (90.09% mIoU), indicating a new state of the art for crop segmentation.", "AI": {"tldr": "DepthCropSeg++ 是一个用于田间开放环境下不同作物分割的基础模型，通过大规模跨物种、跨场景数据集和两阶段自训练方法，在各种挑战性场景下均取得优于现有方法的分割性能。", "motivation": "现有作物分割模型受限于标注数据的昂贵成本，泛化能力不足，尤其是在特定作物类型或受控环境之外。研究旨在构建一个能够处理多样化作物和环境因素的通用作物分割基础模型。", "method": "作者构建了一个包含28,406张图像、30多种作物和15种环境条件的大规模跨物种、跨场景数据集。在此基础上，他们改进了ViT-Adapter语义分割架构，引入了动态上采样以增强细节感知，并采用两阶段自训练管线进行模型训练。", "result": "DepthCropSeg++ 在综合测试集上取得了93.11%的mIoU，显著优于监督基线模型和通用的视觉基础模型SAM。在夜间环境（86.90% mIoU）、高密度冠层（90.09% mIoU）和未见过的作物种类（90.09% mIoU）等挑战性场景下，模型表现尤为出色。", "conclusion": "DepthCropSeg++ 达到了作物分割的新SOTA水平，证明了其在多样化和田间开放环境下进行作物分割的强大有效性和泛化能力，为未来精准农业应用奠定了基础。"}}
{"id": "2601.13880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13880", "abs": "https://arxiv.org/abs/2601.13880", "authors": ["Ye Tian", "Zihao Wang", "Onat Gungor", "Xiaoran Fan", "Tajana Rosing"], "title": "LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health", "comment": null, "summary": "Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals, and recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. In this paper, we introduce LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions spanning from basic retrieval to complex reasoning. We release an extensible benchmark construction pipeline and a standardized evaluation protocol to enable reliable and scalable assessment of LLM-based health assistants. We then systematically evaluate 11 leading LLMs on LifeAgentBench and identify key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. Motivated by these findings, we propose LifeAgent as a strong baseline agent for health assistant that integrates multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies further demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available at https://anonymous.4open.science/r/LifeAgentBench-CE7B.", "AI": {"tldr": "本文提出了LifeAgentBench，一个用于评估大型语言模型（LLMs）在个性化数字健康支持方面长期、跨维度和多用户生活方式健康推理能力的基准测试。研究发现了现有LLMs在长期聚合和跨维度推理方面的瓶颈，并提出了一个名为LifeAgent的基线模型，通过多步证据检索和确定性聚合来改进性能。", "motivation": "现有LLMs在处理需要长期、跨维度推理的个性化数字健康支持方面能力尚不清楚，缺乏系统性的基准测试来评估其性能。", "method": "构建了一个包含22,573个问题的LifeAgentBench基准测试，涵盖基本检索到复杂推理。开发了一个可扩展的基准构建流水线和标准化的评估协议。对11个领先LLMs进行了系统评估，并提出了LifeAgent模型，该模型集成了多步证据检索和确定性聚合。", "result": "评估发现了当前LLMs在长期聚合和跨维度推理方面的关键瓶颈。LifeAgent模型在LifeAgentBench上取得了显著的性能提升，优于两个常用基线模型。案例研究表明了LifeAgent在真实生活场景中的潜力。", "conclusion": "LifeAgentBench提供了一个评估LLMs在个性化健康助手方面能力的有效工具。提出的LifeAgent模型是健康助手的一个有力基线，通过改进的推理和聚合机制，有望实现更有效的个性化健康支持。"}}
{"id": "2601.13887", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13887", "abs": "https://arxiv.org/abs/2601.13887", "authors": ["Hong Su"], "title": "Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.", "AI": {"tldr": "该论文提出了一种名为“人类模拟计算”（HSC）的框架，用于增强大型语言模型（LLMs）在现实世界中的适应性和推理能力。HSC模拟了人类的思维、行动、学习、反思和活动调度过程，强调主动参与和通过行动自我改进。", "motivation": "大型语言模型虽然在文本知识和推理方面表现出色，但仅依赖文本限制了它们在开放动态的真实世界环境中进行适应、验证推理结果和有效操作的能力。研究者希望克服这些局限性。", "method": "提出了“人类模拟计算”（HSC）框架，该框架将智能建模为一个连续的闭环过程，包括思维、行动、学习、反思和活动调度。HSC强调在内部推理过程和与环境的交互中进行主动参与，并利用行动来自动优化内部推理机制，同时融入了主要的思维策略（如主特征导向推理、通过行动扩大范围、以及基于环境反馈的及时学习）。", "result": "理论分析表明，人类模拟策略无法仅通过语言材料学习，并且类人推理过程和基于行动的推理方法对于在现实世界环境中进行鲁棒的适应和有效的交互至关重要。", "conclusion": "HSC框架通过模拟人类智能的闭环过程和主动交互，能够克服LLM在现实世界中的局限性，实现更好的适应性和推理能力。类人推理过程和行动接地推理对于真实世界的有效交互是必需的。"}}
{"id": "2601.13044", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13044", "abs": "https://arxiv.org/abs/2601.13044", "authors": ["Warit Sirichotedumrong", "Adisai Na-Thalang", "Potsawee Manakul", "Pittawat Taveekitworachai", "Sittipong Sripaisarnmongkol", "Kunat Pipatanakul"], "title": "Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition", "comment": "Models and datasets are publicly available on https://huggingface.co/collections/typhoon-ai/typhoon-asr-technical-report ; Project Page: https://opentyphoon.ai/model/typhoon-asr-realtime", "summary": "Large encoder-decoder models like Whisper achieve strong offline transcription but remain impractical for streaming applications due to high latency. However, due to the accessibility of pre-trained checkpoints, the open Thai ASR landscape remains dominated by these offline architectures, leaving a critical gap in efficient streaming solutions. We present Typhoon ASR Real-time, a 115M-parameter FastConformer-Transducer model for low-latency Thai speech recognition. We demonstrate that rigorous text normalization can match the impact of model scaling: our compact model achieves a 45x reduction in computational cost compared to Whisper Large-v3 while delivering comparable accuracy. Our normalization pipeline resolves systemic ambiguities in Thai transcription --including context-dependent number verbalization and repetition markers (mai yamok) --creating consistent training targets. We further introduce a two-stage curriculum learning approach for Isan (north-eastern) dialect adaptation that preserves Central Thai performance. To address reproducibility challenges in Thai ASR, we release the Typhoon ASR Benchmark, a gold-standard human-labeled datasets with transcriptions following established Thai linguistic conventions, providing standardized evaluation protocols for the research community.", "AI": {"tldr": "本文提出了一种名为Typhoon ASR Real-time的1.15亿参数的FastConformer-Transducer模型，用于低延迟的泰语语音识别，在计算成本降低45倍的情况下，实现了与Whisper Large-v3相当的准确率。研究还通过文本规范化、两阶段课程学习以及发布基准数据集来解决泰语语音识别中的关键问题。", "motivation": "现有的强大的离线泰语语音识别模型（如Whisper）由于高延迟不适用于流式应用，导致高效流式解决方案的缺失。", "method": "提出了一种1.15亿参数的FastConformer-Transducer模型Typhoon ASR Real-time。采用了严格的文本规范化，包括解决数字口语化和重复标记（mai yamok）的歧义。引入了两阶段的课程学习方法来适应Isan方言，同时保持Central Thai的性能。发布了Typhoon ASR Benchmark数据集，包含符合泰语语言习惯的人工标注转录。", "result": "Typhoon ASR Real-time模型实现了与Whisper Large-v3相当的准确率，同时计算成本降低了45倍。两阶段课程学习方法成功地适应了Isan方言，并保持了Central Thai的性能。", "conclusion": "本文成功开发了一种高效的低延迟泰语流式语音识别模型，并通过文本规范化、课程学习和标准化数据集解决了泰语语音识别领域存在的挑战，为社区提供了可复现的解决方案。"}}
{"id": "2601.12382", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12382", "abs": "https://arxiv.org/abs/2601.12382", "authors": ["Furkan Yuceyalcin", "Abdurrahim Yilmaz", "Burak Temelkuran"], "title": "A Hierarchical Benchmark of Foundation Models for Dermatology", "comment": null, "summary": "Foundation models have transformed medical image analysis by providing robust feature representations that reduce the need for large-scale task-specific training. However, current benchmarks in dermatology often reduce the complex diagnostic taxonomy to flat, binary classification tasks, such as distinguishing melanoma from benign nevi. This oversimplification obscures a model's ability to perform fine-grained differential diagnoses, which is critical for clinical workflow integration. This study evaluates the utility of embeddings derived from ten foundation models, spanning general computer vision, general medical imaging, and dermatology-specific domains, for hierarchical skin lesion classification. Using the DERM12345 dataset, which comprises 40 lesion subclasses, we calculated frozen embeddings and trained lightweight adapter models using a five-fold cross-validation. We introduce a hierarchical evaluation framework that assesses performance across four levels of clinical granularity: 40 Subclasses, 15 Main Classes, 2 and 4 Superclasses, and Binary Malignancy. Our results reveal a \"granularity gap\" in model capabilities: MedImageInsights achieved the strongest overall performance (97.52% weighted F1-Score on Binary Malignancy detection) but declined to 65.50% on fine-grained 40-class subtype classification. Conversely, MedSigLip (69.79%) and dermatology-specific models (Derm Foundation and MONET) excelled at fine-grained 40-class subtype discrimination while achieving lower overall performance than MedImageInsights on broader classification tasks. Our findings suggest that while general medical foundation models are highly effective for high-level screening, specialized modeling strategies are necessary for the granular distinctions required in diagnostic support systems.", "AI": {"tldr": "研究评估了不同类型的医学基础模型在皮肤病学中的分层分类能力，发现通用医学模型擅长粗粒度分类，而皮肤病学专用模型在细粒度分类上表现更好，存在“粒度差距”。", "motivation": "当前的皮肤病学基准测试过于简化，通常采用二元分类，未能评估模型进行精细鉴别诊断的能力，这限制了其在临床工作流程中的应用。因此，需要评估基础模型在分层皮肤病学分类任务中的效用。", "method": "使用 DERM12345 数据集，包含 40 种皮肤病变子类，计算了十种不同领域（通用计算机视觉、通用医学成像、皮肤病学专用）基础模型的冻结嵌入，并训练了轻量级适配器模型。引入了一个分层评估框架，在四个临床粒度级别（40 个子类、15 个主类、2 和 4 个超类，以及二元恶性度）上评估模型性能。", "result": "研究发现了模型能力的“粒度差距”。MedImageInsights 在二元恶性度检测上表现最佳（97.52% 加权 F1 分数），但在 40 类子类型分类上的性能下降至 65.50%。MedSigLip（69.79%）和皮肤病学专用模型（Derm Foundation 和 MONET）在 40 类子类型区分上表现出色，但在更广泛的分类任务上整体性能低于 MedImageInsights。", "conclusion": "通用医学基础模型在高级筛查方面非常有效，但对于诊断支持系统所需的精细区分，需要专门的建模策略来弥合“粒度差距”。"}}
{"id": "2601.13904", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13904", "abs": "https://arxiv.org/abs/2601.13904", "authors": ["Jaeyoung Moon", "Youjin Choi", "Yucheon Park", "David Melhart", "Georgios N. Yannakakis", "Kyung-Joong Kim"], "title": "PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation", "comment": "CHI '26 Accepted paper", "summary": "Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.", "AI": {"tldr": "提出了一种名为PREFAB的低成本回顾式自我标注方法，通过关注情感的转折点而非全程标注，减少了标注时间和认知负担，同时提高了标注者信心和标注质量。", "motivation": "现有的情感计算中的自我标注方法需要用户对整个会话进行持续标注，这非常耗时、占用大量认知资源，并且容易导致疲劳和错误。研究旨在解决这些问题。", "method": "PREFAB方法基于峰终法则和情感的序数表示，采用偏好学习模型来检测相对情感变化。它只要求标注者标注选定的片段，然后对剩余部分进行插值。此外，还引入了一个预览机制，提供简短的上下文线索来辅助标注。", "result": "PREFAB在模拟情感转折点方面优于基线方法，同时减轻了工作量（并有条件地减轻了时间负担）。更重要的是，PREFAB提高了标注者的信心，同时没有降低标注质量。", "conclusion": "PREFAB是一种有效的低成本回顾式自我标注方法，能够在大约25%的标注时间内完成，并且不会损害标注质量，同时还能提升标注者体验。"}}
{"id": "2601.13050", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13050", "abs": "https://arxiv.org/abs/2601.13050", "authors": ["Lars Klöser", "Mika Beele", "Bodo Kraft"], "title": "Profiling German Text Simplification with Interpretable Model-Fingerprints", "comment": "Presented at 2nd International Conference on Explainable AI for Neural and Symbolic Systems", "summary": "While Large Language Models (LLMs) produce highly nuanced text simplifications, developers currently lack tools for a holistic, efficient, and reproducible diagnosis of their behavior. This paper introduces the Simplification Profiler, a diagnostic toolkit that generates a multidimensional, interpretable fingerprint of simplified texts. Multiple aggregated simplifications of a model result in a model's fingerprint. This novel evaluation paradigm is particularly vital for languages, where the data scarcity problem is magnified when creating flexible models for diverse target groups rather than a single, fixed simplification style. We propose that measuring a model's unique behavioral signature is more relevant in this context as an alternative to correlating metrics with human preferences. We operationalize this with a practical meta-evaluation of our fingerprints' descriptive power, which bypasses the need for large, human-rated datasets. This test measures if a simple linear classifier can reliably identify various model configurations by their created simplifications, confirming that our metrics are sensitive to a model's specific characteristics. The Profiler can distinguish high-level behavioral variations between prompting strategies and fine-grained changes from prompt engineering, including few-shot examples. Our complete feature set achieves classification F1-scores up to 71.9 %, improving upon simple baselines by over 48 percentage points. The Simplification Profiler thus offers developers a granular, actionable analysis to build more effective and truly adaptive text simplification systems.", "AI": {"tldr": "本研究提出了一种名为“Simplification Profiler”的诊断工具包，用于评估大型语言模型（LLMs）在文本简化方面的表现，生成多维度、可解释的模型指纹，以替代传统的人类偏好关联指标，特别适用于数据稀缺的语言。", "motivation": "现有的LLMs文本简化工具缺乏全面、高效且可复现的诊断能力，尤其是在多语言和多样化目标用户群体的场景下，传统的评估方法（如关联人类偏好）存在局限性，促使研究者开发新的评估范式。", "method": "研究者开发了Simplification Profiler工具包，通过生成模型指纹（由多个聚合简化文本构成）来描绘LLMs的行为特征。采用元评估方法，通过训练线性分类器来识别不同模型配置的指纹，以验证指纹的描述能力和对模型特性的敏感性。", "result": "Simplification Profiler能够区分不同提示策略和提示工程（包括少样本示例）带来的高层次和细粒度行为变化。其完整的特征集在分类任务上达到了高达71.9%的F1分数，比简单基线提高了48个百分点以上。", "conclusion": "Simplification Profiler为开发更有效、真正自适应的文本简化系统提供了细粒度、可操作的分析工具，克服了数据稀缺语言在评估模型时的挑战，并证明了通过模型行为签名进行评估的可行性。"}}
{"id": "2601.12402", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12402", "abs": "https://arxiv.org/abs/2601.12402", "authors": ["Aleksandra Jamróz", "Patrycja Wysocka", "Piotr Garbat"], "title": "Weaknesses of Facial Emotion Recognition Systems", "comment": null, "summary": "Emotion detection from faces is one of the machine learning problems needed for human-computer interaction. The variety of methods used is enormous, which motivated an in-depth review of articles and scientific studies. Three of the most interesting and best solutions are selected, followed by the selection of three datasets that stood out for the diversity and number of images in them. The selected neural networks are trained, and then a series of experiments are performed to compare their performance, including testing on different datasets than a model was trained on. This reveals weaknesses in existing solutions, including differences between datasets, unequal levels of difficulty in recognizing certain emotions and the challenges in differentiating between closely related emotions.", "AI": {"tldr": "本文对人脸表情识别的现有方法进行了综述，并对三种表现最佳的神经网络进行了实验比较，揭示了现有方法的局限性。", "motivation": "人机交互需要从人脸检测情感，但现有方法多样，因此需要进行深入的文献综述和对比分析。", "method": "1. 综述人脸表情识别的相关文献，选取三种表现最优异的解决方案（神经网络）。\n2. 选取三个在图像多样性和数量上表现突出的数据集。\n3. 使用选定的数据集训练选定的神经网络。\n4. 在不同数据集上对训练好的模型进行测试，以比较其性能。", "result": "实验结果揭示了现有解决方案的不足，包括：不同数据集之间的差异、识别某些表情的难度不均，以及区分相似表情的挑战。", "conclusion": "现有的人脸表情识别方法仍存在局限性，尤其是在跨数据集泛化能力、特定表情识别难度以及区分相似情感方面。"}}
{"id": "2601.12391", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12391", "abs": "https://arxiv.org/abs/2601.12391", "authors": ["Dasith de Silva Edirimuni", "Ajmal Saeed Mian"], "title": "Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation", "comment": "Accepted to AAAI 2026, Main Technical Track", "summary": "Most 3D scene generation methods are limited to only generating object bounding box parameters while newer diffusion methods also generate class labels and latent features. Using object size or latent feature, they then retrieve objects from a predefined database. For complex scenes of varied, multi-categorical objects, diffusion-based latents cannot be effectively decoded by current autoencoders into the correct point cloud objects which agree with target classes. We introduce a Class-Partitioned Vector Quantized Variational Autoencoder (CPVQ-VAE) that is trained to effectively decode object latent features, by employing a pioneering $\\textit{class-partitioned codebook}$ where codevectors are labeled by class. To address the problem of $\\textit{codebook collapse}$, we propose a $\\textit{class-aware}$ running average update which reinitializes dead codevectors within each partition. During inference, object features and class labels, both generated by a Latent-space Flow Matching Model (LFMM) designed specifically for scene generation, are consumed by the CPVQ-VAE. The CPVQ-VAE's class-aware inverse look-up then maps generated latents to codebook entries that are decoded to class-specific point cloud shapes. Thereby, we achieve pure point cloud generation without relying on an external objects database for retrieval. Extensive experiments reveal that our method reliably recovers plausible point cloud scenes, with up to 70.4% and 72.3% reduction in Chamfer and Point2Mesh errors on complex living room scenes.", "AI": {"tldr": "提出了一种CPVQ-VAE模型，通过类别的代码本划分和类别感知的更新策略，解决了现有3D场景生成方法中解码不准确的问题，实现了直接生成点云场景，并在复杂场景下取得了显著的性能提升。", "motivation": "现有的3D场景生成方法在生成复杂、多类别场景时，无法有效将扩散模型生成的潜在特征解码为正确的点云对象，并且依赖预定义数据库进行对象检索。需要一种能够直接生成点云场景并提高解码准确性的方法。", "method": "引入了类别划分的向量量化变分自编码器（CPVQ-VAE），其代码本按类别划分。提出了类别感知的运行平均更新策略来解决代码本崩溃问题。在推理时，CPVQ-VAE结合由特定于场景生成的潜在空间流匹配模型（LFMM）生成的对象特征和类别标签，通过类别的逆向查找解码为点云形状，实现了纯点云生成。", "result": "在复杂客厅场景下，与现有方法相比，Chamfer距离和Point2Mesh误差分别降低了高达70.4%和72.3%。实验证明该方法能够可靠地生成合理的地3D点云场景。", "conclusion": "CPVQ-VAE模型通过引入类别划分的代码本和类别感知的更新策略，能够有效地将潜在特征解码为特定类别的点云对象，从而实现了无需外部数据库检索的纯点云3D场景生成，并在复杂场景下取得了优越的性能。"}}
{"id": "2601.14027", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14027", "abs": "https://arxiv.org/abs/2601.14027", "authors": ["Junqi Liu", "Zihao Zhou", "Zekai Zhu", "Marco Dos Santos", "Weikun He", "Jiawei Liu", "Ran Wang", "Yunzhou Xie", "Junqiao Zhao", "Qiufeng Wang", "Lihong Zhi", "Jia Li", "Wenda Li"], "title": "Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics", "comment": null, "summary": "Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.", "AI": {"tldr": "提出一种新范式，直接使用通用编码代理作为形式数学推理器，并介绍Numina-Lean-Agent，它成功解决了Putnam 2025的所有问题，并能与数学家合作形式化Brascamp-Lieb定理。", "motivation": "现有方法依赖特定任务的流水线和训练好的证明器，灵活性和可复现性受限。而通用编码代理能处理更广泛的任务，易于通过更换基础模型提升性能，且能灵活扩展和自主调用工具。", "method": "提出直接使用通用编码代理作为形式数学推理器的范式，并据此开发Numina-Lean-Agent。该系统结合了Claude Code和Numina-Lean-MCP，能自主与Lean交互，检索定理，进行非正式证明和调用辅助推理工具。", "result": "使用Claude Opus 4.5作为基础模型，Numina-Lean-Agent解决了Putnam 2025的所有12个问题，性能与最佳闭源系统相当。此外，它还成功与数学家合作形式化了Brascamp-Lieb定理，展示了其通用性。", "conclusion": "直接利用通用编码代理作为形式数学推理器是一种可行且高效的范式，Numina-Lean-Agent是该范式的一个成功实现，展示了其在解决复杂数学问题和辅助数学研究方面的潜力。"}}
{"id": "2601.13099", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13099", "abs": "https://arxiv.org/abs/2601.13099", "authors": ["Abdellah El Mekki", "Samar M. Magdy", "Houdaifa Atou", "Ruwa AbuHweidi", "Baraah Qawasmeh", "Omer Nacar", "Thikra Al-hibiri", "Razan Saadie", "Hamzah Alsayadi", "Nadia Ghezaiel Hammouda", "Alshima Alkhazimi", "Aya Hamod", "Al-Yas Al-Ghafri", "Wesam El-Sayed", "Asila Al sharji", "Mohamad Ballout", "Anas Belfathi", "Karim Ghaddar", "Serry Sibaee", "Alaa Aoun", "Areej Asiri", "Lina Abureesh", "Ahlam Bashiti", "Majdal Yousef", "Abdulaziz Hafiz", "Yehdih Mohamed", "Emira Hamedtou", "Brakehe Brahim", "Rahaf Alhamouri", "Youssef Nafea", "Aya El Aatar", "Walid Al-Dhabyani", "Emhemed Hamed", "Sara Shatnawi", "Fakhraddin Alwajih", "Khalid Elkhidir", "Ashwag Alasmari", "Abdurrahman Gerrio", "Omar Alshahri", "AbdelRahim A. Elmadany", "Ismail Berrada", "Amir Azad Adli Alkathiri", "Fadi A Zaraket", "Mustafa Jarrar", "Yahya Mohamed El Hadj", "Hassan Alhuzali", "Muhammad Abdul-Mageed"], "title": "Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs", "comment": "Project resources will be available here: https://github.com/UBC-NLP/Alexandria", "summary": "Arabic is a highly diglossic language where most daily communication occurs in regional dialects rather than Modern Standard Arabic. Despite this, machine translation (MT) systems often generalize poorly to dialectal input, limiting their utility for millions of speakers. We introduce \\textbf{Alexandria}, a large-scale, community-driven, human-translated dataset designed to bridge this gap. Alexandria covers 13 Arab countries and 11 high-impact domains, including health, education, and agriculture. Unlike previous resources, Alexandria provides unprecedented granularity by associating contributions with city-of-origin metadata, capturing authentic local varieties beyond coarse regional labels. The dataset consists of multi-turn conversational scenarios annotated with speaker-addressee gender configurations, enabling the study of gender-conditioned variation in dialectal use. Comprising 107K total samples, Alexandria serves as both a training resource and a rigorous benchmark for evaluating MT and Large Language Models (LLMs). Our automatic and human evaluation of Arabic-aware LLMs benchmarks current capabilities in translating across diverse Arabic dialects and sub-dialects, while exposing significant persistent challenges.", "AI": {"tldr": "该研究介绍了Alexandria，一个大规模、社区驱动、人工翻译的阿拉伯语方言数据集，旨在改善机器翻译系统对阿拉伯语方言的处理能力，并评估了当前阿拉伯语感知大语言模型的性能。", "motivation": "现有的机器翻译系统在处理阿拉伯语方言输入时表现不佳，限制了其对数百万阿拉伯语使用者的效用。研究旨在通过构建一个更全面、更细致的阿拉伯语方言数据集来弥合这一差距。", "method": "构建了一个名为Alexandria的大规模数据集，该数据集涵盖13个阿拉伯国家和11个高影响力领域，并提供了城市级别的地理位置元数据。数据集包含10.7万个多轮对话样本，并标注了说话人和听话人的性别配置。研究还使用该数据集对阿拉伯语感知大语言模型进行了自动和人工评估。", "result": "Alexandria数据集为研究和评估阿拉伯语方言机器翻译和大型语言模型提供了资源。评估结果显示，虽然存在进步，但当前的大型语言模型在翻译多样化的阿拉伯语方言和子方言方面仍面临显著的挑战。", "conclusion": "Alexandria数据集能够捕捉更真实的本地语言变体，并为评估阿拉伯语感知大语言模型提供了基准。尽管取得了进展，但针对阿拉伯语方言的机器翻译和语言模型仍需进一步改进。"}}
{"id": "2601.13969", "categories": ["cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13969", "abs": "https://arxiv.org/abs/2601.13969", "authors": ["Joaquín Polonuer", "Lucas Vittor", "Iñaki Arango", "Ayush Noori", "David A. Clifton", "Luciano Del Corro", "Marinka Zitnik"], "title": "Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval", "comment": null, "summary": "Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.", "AI": {"tldr": "本文提出了一种名为 ARK 的自适应知识图谱检索器，它允许语言模型自主控制广度-深度检索的权衡，通过全局词汇搜索和单跳邻域探索的组合实现，无需预设种子节点或检索训练。ARK 在 STaRK 数据集上取得了显著的性能提升，并在 AMAZON、MAG 和 PRIME 数据集上通过无标签模仿蒸馏，显著提升了 8B 模型的能力。", "motivation": "现有的知识图谱检索方法在处理语言模型查询时，要么搜索范围广但不够深入（基于相似性），要么依赖脆弱的种子节点选择（基于遍历），难以兼顾跨多个实体和关系的大范围查询。", "method": "ARK 是一种基于代理（agentic）的知识图谱检索器，它提供两种工具：1. 全局词汇搜索（node descriptors）；2. 单跳邻域探索。ARK 能够自适应地在广度（全局搜索）和深度（邻域探索，可组合成多跳）之间切换，并根据查询的语言或关系特征调整工具使用。", "result": "在 STaRK 数据集上，ARK 达到了 59.1% 的平均 Hit@1 和 67.4% 的平均 MRR，分别比检索和无训练的代理方法提高了高达 31.4% 和 28.0%。通过无标签模仿学习，ARK 的工具使用轨迹被蒸馏到一个 8B 模型中，在 AMAZON、MAG 和 PRIME 数据集上将 Hit@1 分数分别提高了 7.0、26.6 和 13.5 个百分点，同时保留了教师模型高达 98.5% 的 Hit@1 率。", "conclusion": "ARK 成功地解决了知识图谱检索中的广度-深度权衡问题，通过自适应的工具使用，无需依赖脆弱的种子选择或预设参数，显著提升了检索性能，并且其工具使用策略可以通过无标签模仿有效蒸馏到较小的模型中。"}}
{"id": "2601.13105", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13105", "abs": "https://arxiv.org/abs/2601.13105", "authors": ["Liu Kaipeng", "Wu Ling"], "title": "Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification", "comment": "19pages, 1figure", "summary": "This study investigates the automatic identification of the English ditransitive construction by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework.A binary classification task was conducted on annotated data from the British National Corpus. Results demonstrate that a LoRA-fine-tuned Qwen3-8B model significantly outperformed both a native Qwen3-MAX model and a theory-only RAG system. Detailed error analysis reveals that fine-tuning shifts the model's judgment from a surface-form pattern matching towards a more semantically grounded understanding based.", "AI": {"tldr": "本文研究了如何通过集成LoRA微调的大型语言模型和检索增强生成（RAG）框架来自动识别英语的直接宾语结构。", "motivation": "研究的动机是自动识别英语的直接宾语结构，并探索LoRA微调和RAG框架的结合在该任务上的有效性。", "method": "研究采用了LoRA（低秩适应）微调大型语言模型（Qwen3-8B）并结合检索增强生成（RAG）框架。任务是对来自英国国家语料库的标注数据进行二元分类。", "result": "研究结果表明，经过LoRA微调的Qwen3-8B模型在识别直接宾语结构方面显著优于原生Qwen3-MAX模型和仅基于理论的RAG系统。误差分析显示，微调使得模型从表面形式的模式匹配转向了更基于语义的理解。", "conclusion": "LoRA微调结合RAG框架能够有效提高大型语言模型在识别英语直接宾语结构上的性能，并且微调有助于模型形成更深层次的语义理解。"}}
{"id": "2601.12423", "categories": ["cs.CV", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.12423", "abs": "https://arxiv.org/abs/2601.12423", "authors": ["Antonin Clerc", "Michael Quellmalz", "Moritz Piening", "Philipp Flotho", "Gregor Kornhardt", "Gabriele Steidl"], "title": "HOT-POT: Optimal Transport for Sparse Stereo Matching", "comment": "18 pages, 10 figures, 6 tables", "summary": "Stereo vision between images faces a range of challenges, including occlusions, motion, and camera distortions, across applications in autonomous driving, robotics, and face analysis. Due to parameter sensitivity, further complications arise for stereo matching with sparse features, such as facial landmarks. To overcome this ill-posedness and enable unsupervised sparse matching, we consider line constraints of the camera geometry from an optimal transport (OT) viewpoint. Formulating camera-projected points as (half)lines, we propose the use of the classical epipolar distance as well as a 3D ray distance to quantify matching quality. Employing these distances as a cost function of a (partial) OT problem, we arrive at efficiently solvable assignment problems. Moreover, we extend our approach to unsupervised object matching by formulating it as a hierarchical OT problem. The resulting algorithms allow for efficient feature and object matching, as demonstrated in our numerical experiments. Here, we focus on applications in facial analysis, where we aim to match distinct landmarking conventions.", "AI": {"tldr": "本文提出了一种基于最优传输（OT）理论的无监督稀疏立体匹配方法，利用视线几何约束来解决遮挡、运动和相机畸变等问题，特别是在人脸分析领域。", "motivation": "现有立体匹配方法在处理稀疏特征（如人脸关键点）时，由于参数敏感性而面临挑战。本文旨在克服这些困难，实现无监督的稀疏匹配。", "method": "将相机投影点视为（半）直线，利用经典的极线距离和三维射线距离作为成本函数，构建（部分）最优传输问题，并将其转化为可高效求解的分配问题。此外，通过分层最优传输问题将方法扩展到无监督物体匹配。", "result": "提出的算法能够高效地进行特征和物体匹配，并在数值实验中得到了验证，特别是在人脸分析应用中，能够匹配不同的人脸关键点标记约定。", "conclusion": "基于最优传输的立体匹配方法，通过结合几何约束和距离度量，为解决稀疏特征匹配的难题提供了一种有效且高效的解决方案，并在人脸分析等领域展现出应用潜力。"}}
{"id": "2601.12432", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.12432", "abs": "https://arxiv.org/abs/2601.12432", "authors": ["Shunyu Huang", "Yunjiao Zhou", "Jianfei Yang"], "title": "SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition", "comment": "Published in IEEE Internet of Things Journal", "summary": "Skeleton-based action recognition leverages human pose keypoints to categorize human actions, which shows superior generalization and interoperability compared to regular end-to-end action recognition. Existing solutions use RGB cameras to annotate skeletal keypoints, but their performance declines in dark environments and raises privacy concerns, limiting their use in smart homes and hospitals. This paper explores non-invasive wireless sensors, i.e., LiDAR and mmWave, to mitigate these challenges as a feasible alternative. Two problems are addressed: (1) insufficient data on wireless sensor modality to train an accurate skeleton estimation model, and (2) skeletal keypoints derived from wireless sensors are noisier than RGB, causing great difficulties for subsequent action recognition models. Our work, SkeFi, overcomes these gaps through a novel cross-modal knowledge transfer method acquired from the data-rich RGB modality. We propose the enhanced Temporal Correlation Adaptive Graph Convolution (TC-AGC) with frame interactive enhancement to overcome the noise from missing or inconsecutive frames. Additionally, our research underscores the effectiveness of enhancing multiscale temporal modeling through dual temporal convolution. By integrating TC-AGC with temporal modeling for cross-modal transfer, our framework can extract accurate poses and actions from noisy wireless sensors. Experiments demonstrate that SkeFi realizes state-of-the-art performances on mmWave and LiDAR. The code is available at https://github.com/Huang0035/Skefi.", "AI": {"tldr": "本文提出了一种名为 SkeFi 的新框架，利用 LiDAR 和 mmWave 等无线传感器进行基于骨骼的关键点动作识别，解决了数据稀缺和传感器数据噪声大的问题。SkeFi 通过跨模态知识迁移，结合改进的 TC-AGC 和多尺度时间建模，实现了在无线传感器上的先进性能。", "motivation": "现有基于骨骼的关键点动作识别方法依赖 RGB 摄像头，在暗光环境性能下降且存在隐私问题。作者希望探索非侵入性的无线传感器（LiDAR 和 mmWave）作为替代方案，以克服这些限制。", "method": "SkeFi 框架包含两个主要部分：1. 解决无线传感器数据不足的问题，通过从 RGB 数据丰富的模态进行跨模态知识迁移。2. 解决无线传感器关键点噪声大的问题，提出增强型时间相关自适应图卷积（TC-AGC）并结合帧交互增强，以应对缺失或不连续帧的噪声。此外，该框架还通过双时间卷积增强了多尺度时间建模。", "result": "SkeFi 在 mmWave 和 LiDAR 数据集上实现了最先进的动作识别性能。", "conclusion": "SkeFi 框架能够有效地从嘈杂的无线传感器数据中提取准确的姿态和动作，证明了跨模态知识迁移和先进图卷积及时间建模方法的有效性，为无线传感器在动作识别领域的应用提供了可行的解决方案。"}}
{"id": "2601.13137", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13137", "abs": "https://arxiv.org/abs/2601.13137", "authors": ["Yuan Gao", "Zhigang Liu", "Xinyu Yao", "Bo Chen", "Xiaobing Zhao"], "title": "Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains", "comment": "13 pages, 5 figures", "summary": "With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.", "AI": {"tldr": "本研究提出了一种对抗性对齐框架（VC-LLM），通过持续预训练、指令微调和对抗性训练来提高大型语言模型在敏感领域的价值一致性，并在中英双语数据集上验证了其有效性。", "motivation": "大型语言模型在敏感领域（如种族、社会、政治）的应用暴露了其偏见和价值不一致的问题。", "method": "提出了一种对抗性对齐框架，包括：1. 持续预训练；2. 指令微调；3. 对抗性训练（包含 Attacker 生成争议性查询，Actor 生成价值一致性响应，Critic 过滤响应）。训练了一个名为 VC-LLM 的价值一致性大型语言模型，并构建了中英双语评估数据集。", "result": "VC-LLM 在中英双语测试中表现优于现有主流模型。", "conclusion": "所提出的对抗性对齐框架能够有效提升大型语言模型在敏感领域的价值一致性。"}}
{"id": "2601.13115", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13115", "abs": "https://arxiv.org/abs/2601.13115", "authors": ["Fengran Mo", "Yifan Gao", "Sha Li", "Hansi Zeng", "Xin Liu", "Zhaoxuan Tan", "Xian Li", "Jianshu Chen", "Dakuo Wang", "Meng Jiang"], "title": "Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning", "comment": null, "summary": "Large Language Models (LLMs) have become a popular interface for human-AI interaction, supporting information seeking and task assistance through natural, multi-turn dialogue. To respond to users within multi-turn dialogues, the context-dependent user intent evolves across interactions, requiring contextual interpretation, query reformulation, and dynamic coordination between retrieval and generation. Existing studies usually follow static rewrite, retrieve, and generate pipelines, which optimize different procedures separately and overlook the mixed-initiative action optimization simultaneously. Although the recent developments in deep search agents demonstrate the effectiveness in jointly optimizing retrieval and generation via reasoning, these approaches focus on single-turn scenarios, which might lack the ability to handle multi-turn interactions. We introduce a conversational agent that interleaves search and reasoning across turns, enabling exploratory and adaptive behaviors learned through reinforcement learning (RL) training with tailored rewards towards evolving user goals. The experimental results across four widely used conversational benchmarks demonstrate the effectiveness of our methods by surpassing several existing strong baselines.", "AI": {"tldr": "提出了一种基于强化学习的对话式AI代理，能够跨多轮对话动态地学习和适应用户意图，通过交织检索和生成来优化信息获取和任务辅助。", "motivation": "现有的大语言模型（LLM）对话接口通常采用静态的检索-生成流程，难以处理用户意图在多轮交互中的演变，也未能同时优化检索和生成过程。尽管现有研究展示了联合优化检索和生成的效果，但多集中于单轮场景。", "method": "通过强化学习（RL）训练一个对话式代理。该代理能够跨轮次交织检索（search）和推理（reasoning），以适应不断变化的用户目标，并通过定制化的奖励来驱动学习。", "result": "在四个广泛使用的对话基准测试中，该方法超越了现有的强大基线模型。", "conclusion": "提出的跨轮次交织检索和推理的对话式代理，通过强化学习和针对用户目标演变的奖励机制，能够实现探索性和适应性行为，有效提升了多轮对话中的表现。"}}
{"id": "2601.14171", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14171", "abs": "https://arxiv.org/abs/2601.14171", "authors": ["Qianli Ma", "Chang Guo", "Zhiheng Tian", "Siyu Wang", "Jipeng Xiao", "Yuanhao Yue", "Zhipeng Zhang"], "title": "Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance", "comment": null, "summary": "Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.", "AI": {"tldr": "本文提出了一种名为RebuttalAgent的多智能体框架，用于生成学术论文回复，通过将回复生成重塑为以证据为中心的规划任务，解决了现有方法的局限性。", "motivation": "现有方法将回复生成视为文本生成问题，存在幻觉、忽略审稿人意见以及缺乏可验证依据的问题。作者旨在克服这些限制，提供一个更有效、可靠的回复生成解决方案。", "method": "RebuttalAgent采用多智能体框架，将复杂的审稿意见分解为原子化问题，并动态构建混合上下文，结合压缩摘要和高保真文本。它还集成了外部搜索模块来解决需要外部文献的担忧，并在起草前生成可检查的响应计划，确保论据有内部或外部证据支持。", "result": "在提出的RebuttalBench数据集上进行的验证表明，RebuttalAgent在覆盖率、忠实度和策略连贯性方面优于强有力的基线模型。", "conclusion": "RebuttalAgent提供了一个透明且可控的同行评审助手，通过以证据为中心的规划方法，提高了回复生成的质量和可靠性。"}}
{"id": "2601.12464", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12464", "abs": "https://arxiv.org/abs/2601.12464", "authors": ["Yanrui Lu", "Danyang Chen", "Haowen Xiao", "Jiarui Zhu", "Fukang Ge", "Binqian Zou", "Jiali Guan", "Jiayin Liang", "Yuting Wang", "Ziqian Guan", "Xiangcheng Bao", "Jinhao Bi", "Lin Gu", "Jun He", "Yingying Zhu"], "title": "Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild", "comment": null, "summary": "Accurate instance-level segmentation of organelles in electron microscopy (EM) is critical for quantitative analysis of subcellular morphology and inter-organelle interactions. However, current benchmarks, based on small, curated datasets, fail to capture the inherent heterogeneity and large spatial context of in-the-wild EM data, imposing fundamental limitations on current patch-based methods. To address these limitations, we developed a large-scale, multi-source benchmark for multi-organelle instance segmentation, comprising over 100,000 2D EM images across variety cell types and five organelle classes that capture real-world variability. Dataset annotations were generated by our designed connectivity-aware Label Propagation Algorithm (3D LPA) with expert refinement. We further benchmarked several state-of-the-art models, including U-Net, SAM variants, and Mask2Former. Our results show several limitations: current models struggle to generalize across heterogeneous EM data and perform poorly on organelles with global, distributed morphologies (e.g., Endoplasmic Reticulum). These findings underscore the fundamental mismatch between local-context models and the challenge of modeling long-range structural continuity in the presence of real-world variability. The benchmark dataset and labeling tool will be publicly released soon.", "AI": {"tldr": "研究人员发布了一个大规模、多来源的电子显微镜（EM）多细胞器实例分割基准，并评估了现有模型在该基准上的性能，发现当前模型在泛化性和处理具有全局、分布式形态的细胞器方面存在不足。", "motivation": "当前的EM细胞器分割基准数据集规模小、经过精心策划，无法捕捉“野外”EM数据的内在异质性和大空间上下文，这限制了现有基于块（patch-based）方法的性能。", "method": "开发了一个大规模、多来源的基准，包含超过10万张2D EM图像，涵盖多种细胞类型和五种细胞器类别。使用连接感知标签传播算法（3D LPA）并经过专家精炼来生成标注。对U-Net、SAM变体和Mask2Former等先进模型进行了基准测试。", "result": "现有模型在异质EM数据上的泛化能力不足，并且在处理具有全局、分布式形态的细胞器（如内质网）方面表现不佳。", "conclusion": "当前模型与EM数据中建模长程结构连续性的挑战之间存在根本性不匹配，尤其是在真实世界的变异性存在的情况下。将公开发布基准数据集和标注工具。"}}
{"id": "2601.14192", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14192", "abs": "https://arxiv.org/abs/2601.14192", "authors": ["Xiaofang Yang", "Lijun Li", "Heng Zhou", "Tong Zhu", "Xiaoye Qu", "Yuchen Fan", "Qianshan Wei", "Rui Ye", "Li Kang", "Yiran Qin", "Zhiqiang Kou", "Daizong Liu", "Qi Li", "Ning Ding", "Siheng Chen", "Jing Shao"], "title": "Toward Efficient Agents: Memory, Tool learning, and Planning", "comment": "35 pages, 200 references", "summary": "Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.", "AI": {"tldr": "本文研究了大型语言模型驱动的智能体系统的效率问题，重点关注记忆、工具学习和规划这三个核心组件的效率，并从成本（如延迟、token数、步数等）和有效性之间的权衡角度进行了分析。文章回顾了现有技术，提出了效率的衡量方法，并指出了未来的研究方向。", "motivation": "在大型语言模型（LLM）智能体系统日益受到关注的同时，其效率（对于实际部署至关重要）却常常被忽视。因此，本文旨在弥补这一研究空白，全面研究智能体系统本身的效率问题。", "method": "本文通过分析记忆、工具学习和规划这三个核心组件的效率，并考虑延迟、token数、步数等成本。研究回顾了近期的大量方法，并从两个互补的角度刻画效率：1) 在固定成本预算下比较有效性；2) 在可比的有效性水平下比较成本。此外，文章还通过总结评估协议和效率指标来检查面向效率的基准。", "result": "研究发现，尽管实现方法各异，但许多提高智能体效率的方法都遵循一些共享的高层原则，例如通过压缩和管理来限制上下文、设计奖励机制以最小化工具调用，以及采用受控搜索机制来提高效率。文章还从帕累托前沿的角度探讨了有效性和成本之间的权衡。", "conclusion": "本文对LLM智能体系统的效率进行了全面的研究，从多个维度进行了分析和总结，并指出了当前面临的关键挑战和未来的研究方向，旨在为该领域提供有价值的见解。"}}
{"id": "2601.13155", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13155", "abs": "https://arxiv.org/abs/2601.13155", "authors": ["Zimeng Wu", "Donghao Wang", "Chaozhe Jin", "Jiaxin Chen", "Yunhong Wang"], "title": "Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference", "comment": null, "summary": "Long-context inference enhances the reasoning capability of Large Language Models (LLMs) while incurring significant computational overhead. Token-oriented methods, such as pruning and skipping, have shown promise in reducing inference latency, but still suffer from inherently limited acceleration potential, outdated proxy signals, and redundancy interference, thus yielding suboptimal speed-accuracy trade-offs. To address these challenges, we propose SPTS (Self-Predictive Token Skipping), a training-free framework for efficient long-context LLM inference. Specifically, motivated by the thought of probing the influence of targeted skipping layers, we design two component-specific strategies for selective token skipping: Partial Attention Probing (PAP) for multi-head attention, which selects informative tokens by performing partial forward attention computation, and Low-rank Transformation Probing (LTP) for feed forward network, which constructs a low-rank proxy network to predict token transformations. Furthermore, a Multi-Stage Delayed Pruning (MSDP) strategy reallocates the skipping budget and progressively prunes redundant tokens across layers. Extensive experiments demonstrate the effectiveness of our method, achieving up to 2.46$\\times$ and 2.29$\\times$ speedups for prefilling and end-to-end generation, respectively, while maintaining state-of-the-art model performance. The source code will be publicly available upon paper acceptance.", "AI": {"tldr": "本文提出了一种名为SPTS（Self-Predictive Token Skipping）的训练无关框架，用于提高长文本LLM推理效率，通过部分注意力探查（PAP）和低秩变换探查（LTP）选择性跳过Token，并辅以多阶段延迟剪枝（MSDP）策略，在保持模型性能的同时实现了显著的加速。", "motivation": "现有的长文本LLM推理方法计算开销大，而token导向的剪枝和跳过方法加速潜力有限，代理信号过时，且存在冗余干扰，导致速度-精度权衡不佳。", "method": "提出SPTS框架，包含两部分：1. 部分注意力探查（PAP），用于多头注意力，通过部分前向注意力计算选择信息Token；2. 低秩变换探查（LTP），用于前馈网络，构建低秩代理网络预测Token变换。此外，采用多阶段延迟剪枝（MSDP）策略，重新分配跳过预算并分层逐步剪枝冗余Token。", "result": "SPTS在预填充和端到端生成方面分别实现了高达2.46倍和2.29倍的加速，同时保持了最先进的模型性能。", "conclusion": "SPTS框架能够有效提高长文本LLM的推理效率，实现显著的加速，同时不牺牲模型性能，为解决长文本LLM的计算开销问题提供了一种有效的解决方案。"}}
{"id": "2601.12468", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12468", "abs": "https://arxiv.org/abs/2601.12468", "authors": ["Yanqi Wu", "Qichao Chen", "Runhe Lai", "Xinhua Lu", "Jia-Xin Zhuang", "Zhilin Zhao", "Wei-Shi Zheng", "Ruixuan Wang"], "title": "DCAC: Dynamic Class-Aware Cache Creates Stronger Out-of-Distribution Detectors", "comment": "9 pages, 9 figures, Accepted by AAAI2026", "summary": "Out-of-distribution (OOD) detection remains a fundamental challenge for deep neural networks, particularly due to overconfident predictions on unseen OOD samples during testing. We reveal a key insight: OOD samples predicted as the same class, or given high probabilities for it, are visually more similar to each other than to the true in-distribution (ID) samples. Motivated by this class-specific observation, we propose DCAC (Dynamic Class-Aware Cache), a training-free, test-time calibration module that maintains separate caches for each ID class to collect high-entropy samples and calibrate the raw predictions of input samples. DCAC leverages cached visual features and predicted probabilities through a lightweight two-layer module to mitigate overconfident predictions on OOD samples. This module can be seamlessly integrated with various existing OOD detection methods across both unimodal and vision-language models while introducing minimal computational overhead. Extensive experiments on multiple OOD benchmarks demonstrate that DCAC significantly enhances existing methods, achieving substantial improvements, i.e., reducing FPR95 by 6.55% when integrated with ASH-S on ImageNet OOD benchmark.", "AI": {"tldr": "本文提出了一种名为DCAC（动态类感知缓存）的训练无关、测试时校准模块，用于提高深度神经网络在分布外（OOD）检测方面的性能，通过为每个类别维护单独的缓存来收集高熵样本并校准原始预测，从而减轻对OOD样本的过度自信预测。", "motivation": "深度神经网络在分布外（OOD）样本上表现出过度自信的预测是一个普遍存在的挑战。研究人员观察到，被预测为同一类别或给出高概率的OOD样本在视觉上比真实的分布内（ID）样本更相似，这促使了类别的动态感知缓存方法。", "method": "DCAC模块通过为每个ID类别维护单独的缓存来收集高熵样本。它利用缓存的视觉特征和预测概率，通过一个轻量级的两层模块来校准输入样本的原始预测，从而减轻对OOD样本的过度自信。该模块可以无缝集成到现有的OOD检测方法中。", "result": "在多个OOD基准测试上进行的广泛实验表明，DCAC能够显著提升现有方法的性能。例如，在ImageNet OOD基准测试上，与ASH-S结合使用时，FPR95降低了6.55%。", "conclusion": "DCAC是一种有效的、训练无关的测试时校准模块，能够通过利用类别的视觉特征和预测概率来缓解深度神经网络在OOD检测中的过度自信问题，并能与现有方法很好地结合，带来显著的性能提升。"}}
{"id": "2601.13178", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13178", "abs": "https://arxiv.org/abs/2601.13178", "authors": ["Joseph Gatto", "Parker Seegmiller", "Timothy Burdick", "Philip Resnik", "Roshnik Rahat", "Sarah DeLozier", "Sarah M. Preum"], "title": "Medical Triage as Pairwise Ranking: A Benchmark for Urgency in Patient Portal Messages", "comment": "19 Pages, 5 Figures", "summary": "Medical triage is the task of allocating medical resources and prioritizing patients based on medical need. This paper introduces the first large-scale public dataset for studying medical triage in the context of asynchronous outpatient portal messages. Our novel task formulation views patient message triage as a pairwise inference problem, where we train LLMs to choose `\"which message is more medically urgent\" in a head-to-head tournament-style re-sort of a physician's inbox. Our novel benchmark PMR-Bench contains 1569 unique messages and 2,000+ high-quality test pairs for pairwise medical urgency assessment alongside a scalable training data generation pipeline. PMR-Bench includes samples that contain both unstructured patient-written messages alongside real electronic health record (EHR) data, emulating a real-world medical triage scenario.\n  We develop a novel automated data annotation strategy to provide LLMs with in-domain guidance on this task. The resulting data is used to train two model classes, UrgentReward and UrgentSFT, leveraging Bradley-Terry and next token prediction objective, respectively to perform pairwise urgency classification. We find that UrgentSFT achieves top performance on PMR-Bench, with UrgentReward showing distinct advantages in low-resource settings. For example, UrgentSFT-8B and UrgentReward-8B provide a 15- and 16-point boost, respectively, on inbox sorting metrics over off-the-shelf 8B models. Paper resources can be found at https://tinyurl.com/Patient-Message-Triage", "AI": {"tldr": "本文提出了一个名为PMR-Bench的大型数据集和相关的LLM模型，用于模拟和改进医疗门诊消息的自动化分诊任务，将消息分诊视为成对推理问题，旨在确定哪条消息更具医疗紧急性。", "motivation": "现有的医疗资源分配和患者优先排序（医疗分诊）研究缺乏大规模、公开的、针对异步门诊门户消息的基准数据集。本研究旨在填补这一空白，并利用大型语言模型（LLM）来改进医疗消息的分诊效率。", "method": "研究提出了一种新颖的任务形式化，将医疗消息分诊视为一个成对推理问题。构建了一个包含1569条独特消息和2000多个高质量测试对的基准数据集PMR-Bench，其中包含非结构化患者消息和电子健康记录（EHR）数据。开发了一种自动数据标注策略为LLM提供领域内指导，并训练了UrgentReward（基于Bradley-Terry模型）和UrgentSFT（基于下一个token预测）两类模型进行成对紧急度分类。", "result": "在PMR-Bench基准测试中，UrgentSFT模型取得了最佳性能。UrgentReward模型在低资源环境下显示出优势。具体而言，UrgentSFT-8B和UrgentReward-8B相比于现成的8B模型，在收件箱排序指标上分别提高了15和16个百分点。", "conclusion": "该研究成功构建了一个大规模的医疗消息分诊数据集PMR-Bench，并开发了两种基于LLM的分诊模型。结果表明，这些模型能够显著提升医疗消息的分诊效率，其中UrgentSFT在性能上更优，而UrgentReward在低资源场景下表现出色，为自动化医疗分诊的研究和应用提供了重要基础。"}}
{"id": "2601.12481", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.12481", "abs": "https://arxiv.org/abs/2601.12481", "authors": ["Vanessa Sklyarova", "Berna Kabadayi", "Anastasios Yiannakidis", "Giorgio Becherini", "Michael J. Black", "Justus Thies"], "title": "NeuralFur: Animal Fur Reconstruction From Multi-View Images", "comment": "For additional results and code, please refer to https://neuralfur.is.tue.mpg.de", "summary": "Reconstructing realistic animal fur geometry from images is a challenging task due to the fine-scale details, self-occlusion, and view-dependent appearance of fur. In contrast to human hairstyle reconstruction, there are also no datasets that can be leveraged to learn a fur prior for different animals. In this work, we present a first multi-view-based method for high-fidelity 3D fur modeling of animals using a strand-based representation, leveraging the general knowledge of a vision language model. Given multi-view RGB images, we first reconstruct a coarse surface geometry using traditional multi-view stereo techniques. We then use a vision language model (VLM) system to retrieve information about the realistic length structure of the fur for each part of the body. We use this knowledge to construct the animal's furless geometry and grow strands atop it. The fur reconstruction is supervised with both geometric and photometric losses computed from multi-view images. To mitigate orientation ambiguities stemming from the Gabor filters that are applied to the input images, we additionally utilize the VLM to guide the strands' growth direction and their relation to the gravity vector that we incorporate as a loss. With this new schema of using a VLM to guide 3D reconstruction from multi-view inputs, we show generalization across a variety of animals with different fur types. For additional results and code, please refer to https://neuralfur.is.tue.mpg.de.", "AI": {"tldr": "提出了一种基于多视图图像、利用视觉语言模型（VLM）重建动物毛发的3D模型的方法，该方法能够处理精细细节、自遮挡和视点依赖的毛发外观，并能泛化到不同类型的动物。", "motivation": "从图像中重建逼真的动物毛发几何形状是一个挑战，因为毛发细节精细、存在自遮挡且外观随视点变化。与人类发型重建不同，现有数据集无法用于学习不同动物毛发的先验知识。", "method": "首先，使用传统的多视图立体（MVS）技术从多视图RGB图像重建粗糙的表面几何。然后，利用视觉语言模型（VLM）系统获取不同身体部位毛发真实长度结构的信息，并以此构建无毛的动物几何体，在其上生长毛发。毛发重建通过几何和光度损失进行监督。为了解决Gabor滤波器引起的定向模糊，还利用VLM指导毛发生长方向，并结合重力向量作为损失。", "result": "该方法能够实现高保真度的3D毛发建模，并且在不同毛发类型的多种动物上展现出泛化能力。通过利用VLM指导3D重建，克服了传统方法的局限性。", "conclusion": "提出了一种新颖的利用VLM指导多视图3D重建的模式，成功地解决了动物毛发3D重建的难题，并实现了跨多种动物的泛化。"}}
{"id": "2601.13183", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13183", "abs": "https://arxiv.org/abs/2601.13183", "authors": ["Sergio Servantez", "Sarah B. Lawsky", "Rajiv Jain", "Daniel W. Linna", "Kristian Hammond"], "title": "OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand", "comment": "25 pages, 9 Figures, 15 tables", "summary": "Reasoning benchmarks have played a crucial role in the progress of language models. Yet rigorous evaluation remains a significant challenge as static question-answer pairs provide only a snapshot of performance, compressing complex behavior into a single accuracy metric. This limitation is especially true in complex, rule-bound domains such as law, where existing benchmarks are costly to build and ill suited for isolating specific failure modes. To address this, we introduce OpenExempt, a framework and benchmark for diagnostic evaluation of legal reasoning. The OpenExempt Framework uses expert-crafted symbolic representations of U.S. Bankruptcy Code statutes to dynamically generate a large space of natural language reasoning tasks and their machine-computable solutions on demand. This gives users fine-grained control over task complexity and scope, allowing individual reasoning skills to be probed in isolation. Using this system, we construct the OpenExempt Benchmark, a diagnostic benchmark for legal reasoning with 9,765 samples across nine evaluation suites designed to carefully probe model capabilities. Experiments on 13 diverse language models reveal sharp performance cliffs that emerge only under longer reasoning paths and in the presence of obfuscating statements. We release the framework and benchmark publicly to support research aimed at understanding and improving the next generation of reasoning systems.", "AI": {"tldr": "本文提出了一种名为 OpenExempt 的框架和基准测试，用于对法律推理进行诊断性评估。该框架能够动态生成大量自然语言推理任务，并提供机器可计算的解决方案，从而实现对模型特定推理能力的细粒度探测。实验结果表明，现有语言模型在面对更长的推理路径和包含混淆信息的场景时，性能会出现急剧下降。", "motivation": "现有的推理基准测试在评估语言模型复杂行为时存在局限性，尤其是在法律等规则复杂的领域。构建这些基准测试成本高昂且难以隔离特定的失效模式。因此，需要一种更灵活、更具诊断性的评估方法。", "method": "研究人员开发了一个 OpenExempt 框架，该框架使用美国破产法典的符号化表示来动态生成自然语言推理任务及其机器可计算的解决方案。基于此框架，构建了一个包含 9,765 个样本、划分为九个评估套件的 OpenExempt Benchmark，用于探测模型的法律推理能力。对 13 个不同的语言模型进行了实验。", "result": "实验揭示了语言模型在较长的推理路径和存在混淆信息的情况下，会出现急剧的性能下降（performance cliffs）。", "conclusion": "OpenExempt 框架和基准测试为诊断性法律推理评估提供了一种有效的方法，能够暴露现有语言模型在处理复杂推理任务时的弱点。研究结果强调了研究和改进下一代推理系统以应对更具挑战性任务的重要性。作者公开了框架和基准测试以促进相关研究。"}}
{"id": "2601.12493", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12493", "abs": "https://arxiv.org/abs/2601.12493", "authors": ["Mehrdad Noori", "Gustavo Adolfo Vargas Hakim", "David Osowiechi", "Fereshteh Shakeri", "Ali Bahri", "Moslem Yazdanpanah", "Sahar Dastani", "Ismail Ben Ayed", "Christian Desrosiers"], "title": "Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation", "comment": "Accepted to WACV 2026", "summary": "Medical Vision-language models (VLMs) have shown remarkable performances in various medical imaging domains such as histo\\-pathology by leveraging pre-trained, contrastive models that exploit visual and textual information. However, histopathology images may exhibit severe domain shifts, such as staining, contamination, blurring, and noise, which may severely degrade the VLM's downstream performance. In this work, we introduce Histopath-C, a new benchmark with realistic synthetic corruptions designed to mimic real-world distribution shifts observed in digital histopathology. Our framework dynamically applies corruptions to any available dataset and evaluates Test-Time Adaptation (TTA) mechanisms on the fly. We then propose LATTE, a transductive, low-rank adaptation strategy that exploits multiple text templates, mitigating the sensitivity of histopathology VLMs to diverse text inputs. Our approach outperforms state-of-the-art TTA methods originally designed for natural images across a breadth of histopathology datasets, demonstrating the effectiveness of our proposed design for robust adaptation in histopathology images. Code and data are available at https://github.com/Mehrdad-Noori/Histopath-C.", "AI": {"tldr": "本文提出了Histopath-C基准测试和LATTE方法，以解决医学视觉语言模型（VLMs）在处理具有现实世界领域转移的组织病理学图像时的性能下降问题，并展示了LATTE在提高模型鲁棒性方面的有效性。", "motivation": "由于染色、污染、模糊和噪声等领域转移，医学VLMs在组织病理学图像上的下游任务性能会受到严重影响。", "method": "构建了一个名为Histopath-C的基准测试，该测试包含模拟真实世界分布转移的合成腐化。提出了一种名为LATTE的转导式、低秩适应策略，该策略利用多种文本模板来减轻组织病理学VLMs对不同文本输入的敏感性，并能动态地对任何数据集应用腐化以评估测试时适应（TTA）机制。", "result": "LATTE方法在各种组织病理学数据集上，其性能优于为自然图像设计的最先进的TTA方法。", "conclusion": "提出的Histopath-C基准测试和LATTE适应策略能够有效地提高组织病理学VLMs在处理具有现实世界领域转移的图像时的鲁棒性。"}}
{"id": "2601.12443", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12443", "abs": "https://arxiv.org/abs/2601.12443", "authors": ["Xiaowei Fu", "Lei Zhang"], "title": "Adversarial Defense in Vision-Language Models: An Overview", "comment": null, "summary": "The widespread use of Vision Language Models (VLMs, e.g. CLIP) has raised concerns about their vulnerability to sophisticated and imperceptible adversarial attacks. These attacks could compromise model performance and system security in cross-modal tasks. To address this challenge, three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process, typically through adversarial fine-tuning to improve the robustness to adversarial examples. While effective, this approach requires substantial computational resources and may not generalize across all adversarial attacks. Test-time Adaptation Defense focuses on adapting the model at inference time by updating its parameters to handle unlabeled adversarial examples, offering flexibility but often at the cost of increased complexity and computational overhead. Training-free Defense avoids modifying the model itself, instead focusing on altering the adversarial inputs or their feature embeddings, which enforces input perturbations to mitigate the impact of attacks without additional training. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting the strengths and limitations of such approaches and discussing ongoing challenges in enhancing the robustness of VLMs.", "AI": {"tldr": "本文对视觉语言模型（VLM）的对抗性防御策略进行了全面回顾，重点介绍了三种主要的防御范式：训练时防御、测试时适应防御和无训练防御，并分析了它们的优缺点以及当前面临的挑战。", "motivation": "随着视觉语言模型（VLM）的广泛应用，对其在面对复杂且难以察觉的对抗性攻击时的脆弱性感到担忧，这些攻击可能影响模型性能和系统安全。", "method": "该研究通过对现有的对抗性防御策略进行调查和回顾，总结了三种主要的防御范式：训练时防御（如对抗性微调）、测试时适应防御（在推理时调整模型参数）和无训练防御（不修改模型，而是处理输入或特征嵌入）。", "result": "三种防御范式各有优劣。训练时防御虽然有效，但计算成本高且泛化性有限。测试时适应防御灵活，但复杂且计算开销大。无训练防御避免了模型修改，无需额外训练。", "conclusion": "该 survey 旨在梳理 VLM 对抗性防御的最新进展，强调现有方法的优势和局限性，并讨论了提高 VLM 鲁棒性方面仍存在的挑战。"}}
{"id": "2601.14096", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14096", "abs": "https://arxiv.org/abs/2601.14096", "authors": ["Benedikt Hartl", "Léo Pio-Lopez", "Chris Fields", "Michael Levin"], "title": "Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems", "comment": "41 pages, 5 figures", "summary": "The emerging field of diverse intelligence seeks an integrated view of problem-solving in agents of very different provenance, composition, and substrates. From subcellular chemical networks to swarms of organisms, and across evolved, engineered, and chimeric systems, it is hypothesized that scale-invariant principles of decision-making can be discovered. We propose that cognition in both natural and synthetic systems can be characterized and understood by the interplay between two equally important invariants: (1) the remapping of embedding spaces, and (2) the navigation within these spaces. Biological collectives, from single cells to entire organisms (and beyond), remap transcriptional, morphological, physiological, or 3D spaces to maintain homeostasis and regenerate structure, while navigating these spaces through distributed error correction. Modern Artificial Intelligence (AI) systems, including transformers, diffusion models, and neural cellular automata enact analogous processes by remapping data into latent embeddings and refining them iteratively through contextualization. We argue that this dual principle - remapping and navigation of embedding spaces via iterative error minimization - constitutes a substrate-independent invariant of cognition. Recognizing this shared mechanism not only illuminates deep parallels between living systems and artificial models, but also provides a unifying framework for engineering adaptive intelligence across scales.", "AI": {"tldr": "本研究提出，无论是生物体还是人工智能系统，其认知能力都可以用“嵌入空间重映射”和“嵌入空间导航”这两个不变性原则来统一解释，并认为这是跨尺度智能工程的基础。", "motivation": "作者希望在不同来源、组成和基底的智能体（从亚细胞网络到生物群体，以及进化、工程和嵌合系统）中发现可扩展的决策原则，并提出一个统一的框架来理解和设计跨尺度的适应性智能。", "method": "研究者提出将认知过程分解为两个核心的、独立于基底的不变性：1. 嵌入空间的重映射（remapping of embedding spaces）；2. 嵌入空间的导航（navigation within these spaces）。通过分析生物体（如单细胞、完整生物体）和现代人工智能系统（如Transformer、扩散模型、神经细胞自动机）的运作机制，论证了这两个原则在不同系统中具有类比性，都通过迭代的误差最小化来实现。", "result": "研究者论证了“嵌入空间重映射”和“嵌入空间导航”通过迭代误差最小化构成了认知的一个与基底无关的不变性。这一发现揭示了生命系统和人工智能模型之间深刻的相似性。", "conclusion": "作者认为，认知在自然和人工系统中可以通过嵌入空间的重映射和导航来表征和理解。这种机制的识别不仅阐明了生命系统和人工智能模型之间的深层联系，还为跨尺度工程适应性智能提供了一个统一的框架。"}}
{"id": "2601.13217", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13217", "abs": "https://arxiv.org/abs/2601.13217", "authors": ["Bingsen Chen", "Boyan Li", "Ping Nie", "Yuyu Zhang", "Xi Ye", "Chen Zhao"], "title": "Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision", "comment": null, "summary": "Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.", "AI": {"tldr": "该研究提出了Mr Dre，一个评估深度研究代理（DRAs）多轮报告修订能力的基准。研究发现，现有的DRAs在处理用户反馈时，尽管能解决大部分问题，但也会在16-27%的先前内容和引用质量上出现倒退，并且多轮修订后性能提升有限。", "motivation": "现有DRAs的基准将报告生成视为单次任务，这与人类研究员通过自我反思或同行评审进行迭代式起草和修订报告的方式不同。因此，研究旨在探索DRAs是否能可靠地根据用户反馈进行报告修订。", "method": "研究提出了Mr Dre评估套件，包含一个统一的长篇报告评估协议（涵盖全面性、事实性和呈现），以及一个经过人类验证的反馈模拟管道，用于多轮修订。并对五个不同的DRAs进行了分析。", "result": "分析显示，DRAs在处理用户反馈时，会遗漏16-27%的先前内容和引用质量。即使经过多轮修订，最佳性能的DRAs也未能完全保留早期编辑，并继续干扰反馈范围之外的内容。", "conclusion": "当前的DRAs在多轮报告修订方面存在显著局限性，即使通过提示工程或专用子代理进行推理时修复也难以解决。该研究为DRAs的报告修订能力引入了一个新的评估维度。"}}
{"id": "2601.13111", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13111", "abs": "https://arxiv.org/abs/2601.13111", "authors": ["Hassan Soliman", "Vivek Gupta", "Dan Roth", "Iryna Gurevych"], "title": "CORE-T: COherent REtrieval of Tables for Text-to-SQL", "comment": "Preprint under review. Code and data available at: https://github.com/UKPLab/arxiv2026-core-t", "summary": "Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.", "AI": {"tldr": "提出了一种名为CORE-T的训练无关的框架，通过LLM生成表格目的元数据和预计算兼容性缓存，来改进text-to-SQL中多表检索的准确性，同时减少了检索的表格数量和LLM的token消耗。", "motivation": "现有的text-to-SQL方法在处理包含大量异构表格的开放式查询时，表格检索成为性能瓶颈。密集检索（DR）召回率高但包含很多干扰项，而其他方法则依赖额外假设或计算开销大。", "method": " CORE-T框架在训练阶段，利用LLM为表格生成目的元数据，并预先计算一个轻量级的表格兼容性缓存。在推理阶段，首先使用DR检索Top-K候选表格，然后通过一次LLM调用选出连贯且可连接的子集，最后通过简单的加法调整恢复强兼容性表格。", "result": "CORE-T在Bird、Spider和MMQA数据集上，将表格选择F1分数提高了高达22.7分，检索的表格数量减少了42%。在Bird和MMQA数据集上，多表执行准确率分别提高了5.0和6.9分，并且比其他LLM密集型基线少用了4-5倍的token。", "conclusion": "CORE-T是一种可扩展、无需训练的框架，能够有效地解决开放式text-to-SQL场景下的多表检索问题，显著提高了表格选择的准确性，减少了检索负担，并提升了最终的执行准确率，同时优化了LLM的计算资源消耗。"}}
{"id": "2601.12500", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12500", "abs": "https://arxiv.org/abs/2601.12500", "authors": ["Yaowu Fan", "Jia Wan", "Tao Han", "Andy J. Ma", "Antoni B. Chan"], "title": "Video Individual Counting and Tracking from Moving Drones: A Benchmark and Methods", "comment": null, "summary": "Counting and tracking dense crowds in large-scale scenes is highly challenging, yet existing methods mainly rely on datasets captured by fixed cameras, which provide limited spatial coverage and are inadequate for large-scale dense crowd analysis. To address this limitation, we propose a flexible solution using moving drones to capture videos and perform video-level crowd counting and tracking of unique pedestrians across entire scenes. We introduce MovingDroneCrowd++, the largest video-level dataset for dense crowd counting and tracking captured by moving drones, covering diverse and complex conditions with varying flight altitudes, camera angles, and illumination. Existing methods fail to achieve satisfactory performance on this dataset. To this end, we propose GD3A (Global Density Map Decomposition via Descriptor Association), a density map-based video individual counting method that avoids explicit localization. GD3A establishes pixel-level correspondences between pedestrian descriptors across consecutive frames via optimal transport with an adaptive dustbin score, enabling the decomposition of global density maps into shared, inflow, and outflow components. Building on this framework, we further introduce DVTrack, which converts descriptor-level matching into instance-level associations through a descriptor voting mechanism for pedestrian tracking. Experimental results show that our methods significantly outperform existing approaches under dense crowds and complex motion, reducing counting error by 47.4 percent and improving tracking performance by 39.2 percent.", "AI": {"tldr": "提出了一种基于无人机视频的密集人群计数与跟踪新方法GD3A和DVTrack，并发布了最大的无人机视频数据集MovingDroneCrowd++，显著优于现有方法。", "motivation": "现有的大规模密集人群分析方法依赖固定相机，空间覆盖有限。为了解决这个问题，研究者提出使用移动无人机捕捉视频，实现更广阔场景下的视频级人群计数和个体跟踪。", "method": "引入MovingDroneCrowd++数据集。提出GD3A（Global Density Map Decomposition via Descriptor Association）算法，一种密度图为基础的视频个体计数方法，通过最优传输和自适应垃圾箱分数建立像素级描述符对应关系，将全局密度图分解为共享、流入和流出部分。在此基础上，提出DVTrack，通过描述符投票机制将描述符匹配转换为个体跟踪。", "result": "GD3A和DVTrack在密集人群和复杂运动场景下显著优于现有方法，人群计数误差降低了47.4%，跟踪性能提高了39.2%。", "conclusion": "所提出的基于无人机视频的GD3A和DVTrack方法在处理大规模密集人群计数和跟踪方面表现出优越性，有效解决了现有固定相机方法的局限性。"}}
{"id": "2601.13228", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13228", "abs": "https://arxiv.org/abs/2601.13228", "authors": ["Tianqi Du", "Lizhe Fang", "Weijie Yang", "Chenheng Zhang", "Zeming Wei", "Yifei Wang", "Yisen Wang"], "title": "Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation", "comment": null, "summary": "Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.", "AI": {"tldr": "本文提出了一种名为 A3（Any-order Any-subset Autoregressive modeling）的统一框架，它将自回归模型的深度建模能力与扩散模型的灵活性相结合，能在任意顺序和任意子集上进行预测，并在文本生成任务中取得了优于现有扩散模型的性能。", "motivation": "现有的扩散语言模型虽然灵活，但其单步依赖性限制了建模深度，导致生成质量和稳定性不如自回归模型。而自回归模型虽然建模能力强，但缺乏灵活性。作者希望结合两者的优点。", "method": "A3 框架在自回归建模的基础上，将其重构为多组预测过程。它允许对任意的 token 组和任意的生成顺序进行预测，从而扩展了标准的自回归分解。通过双流注意力架构和渐进式适应策略，可以将预训练的自回归模型适配到任意顺序的预测。", "result": "在问答、常识推理和故事填充等任务上，A3 模型的表现优于基于扩散的模型，并且在解码时保持了灵活性。", "conclusion": "A3 提供了一种统一的、灵活且高效的语言建模新范式，它结合了自回归模型的优势和扩散模型的灵活性，有望在各种文本生成任务中发挥重要作用。"}}
{"id": "2601.12534", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12534", "abs": "https://arxiv.org/abs/2601.12534", "authors": ["Marcus Ma", "Jordan Prescott", "Emily Zhou", "Tiantian Feng", "Kleanthis Avramidis", "Gabor Mihaly Toth", "Shrikanth Narayanan"], "title": "Encoding Emotion Through Self-Supervised Eye Movement Reconstruction", "comment": null, "summary": "The relationship between emotional expression and eye movement is well-documented, with literature establishing gaze patterns are reliable indicators of emotion. However, most studies utilize specialized, high-resolution eye-tracking equipment, limiting the potential reach of findings. We investigate how eye movement can be used to predict multimodal markers of emotional expression from naturalistic, low-resolution videos. We utilize a collection of video interviews from the USC Shoah Foundation's Visual History Archive with Holocaust survivors as they recount their experiences in the Auschwitz concentration camp. Inspired by pretraining methods on language models, we develop a novel gaze detection model that uses self-supervised eye movement reconstruction that can effectively leverage unlabeled video. We use this model's encoder embeddings to fine-tune models on two downstream tasks related to emotional expression. The first is aligning eye movement with directional emotion estimates from speech. The second task is using eye gaze as a predictor of three momentary manifestations of emotional behaviors: laughing, crying/sobbing, and sighing. We find our new model is predictive of emotion outcomes and observe a positive correlation between pretraining performance and emotion processing performance for both experiments. We conclude self-supervised eye movement reconstruction is an effective method for encoding the affective signal they carry.", "AI": {"tldr": "本研究提出了一种利用自然、低分辨率视频中眼动来预测情绪表达的新方法，并通过眼动重建实现了预训练，在情绪识别任务上取得了良好效果。", "motivation": "现有研究大多依赖高分辨率眼动追踪设备，限制了研究的可及性。本研究旨在探索在自然、低分辨率视频中，利用眼动来预测多模态情绪表达的可能性。", "method": "研究者利用犹太大屠杀幸存者的视频采访数据，开发了一种新的、基于自监督眼动重建的眼动检测模型。该模型利用未标记视频进行预训练，然后将其编码器嵌入用于微调，以完成两个下游任务：1. 将眼动与语音中的情感方向估计对齐；2. 利用眼动预测瞬间的情绪行为（如笑、哭、叹气）。", "result": "研究发现，所提出的模型能够有效预测情绪结果。预训练性能与情绪处理性能之间存在正相关关系。", "conclusion": "自监督眼动重建是一种有效的编码情绪信号的方法，并且能够应用于自然、低分辨率视频中的情绪识别任务。"}}
{"id": "2601.12507", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12507", "abs": "https://arxiv.org/abs/2601.12507", "authors": ["Ruo Qi", "Linhui Dai", "Yusong Qin", "Chaolei Yang", "Yanshan Li"], "title": "SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection", "comment": null, "summary": "In remote sensing images, complex backgrounds, weak object signals, and small object scales make accurate detection particularly challenging, especially under low-quality imaging conditions. A common strategy is to integrate single-image super-resolution (SR) before detection; however, such serial pipelines often suffer from misaligned optimization objectives, feature redundancy, and a lack of effective interaction between SR and detection. To address these issues, we propose a Saliency-Driven multi-task Collaborative Network (SDCoNet) that couples SR and detection through implicit feature sharing while preserving task specificity. SDCoNet employs the swin transformer-based shared encoder, where hierarchical window-shifted self-attention supports cross-task feature collaboration and adaptively balances the trade-off between texture refinement and semantic representation. In addition, a multi-scale saliency prediction module produces importance scores to select key tokens, enabling focused attention on weak object regions, suppression of background clutter, and suppression of adverse features introduced by multi-task coupling. Furthermore, a gradient routing strategy is introduced to mitigate optimization conflicts. It first stabilizes detection semantics and subsequently routes SR gradients along a detection-oriented direction, enabling the framework to guide the SR branch to generate high-frequency details that are explicitly beneficial for detection. Experiments on public datasets, including NWPU VHR-10-Split, DOTAv1.5-Split, and HRSSD-Split, demonstrate that the proposed method, while maintaining competitive computational efficiency, significantly outperforms existing mainstream algorithms in small object detection on low-quality remote sensing images. Our code is available at https://github.com/qiruo-ya/SDCoNet.", "AI": {"tldr": "提出了一种名为SDCoNet的多任务协同网络，通过隐式特征共享和显式多尺度显著性指导，有效耦合了超分辨率（SR）和目标检测任务，以解决低质量遥感图像中小目标检测的挑战。", "motivation": "低质量遥感图像中，复杂背景、微弱目标信号和小目标尺寸给目标检测带来巨大挑战。现有串联的超分辨率（SR）后检测流水线存在优化目标错配、特征冗余以及SR与检测交互不足的问题。", "method": "SDCoNet采用基于Swin Transformer的共享编码器，利用窗口迁移自注意力机制实现跨任务特征协同，并自适应平衡纹理细化与语义表示。引入多尺度显著性预测模块，生成重要性得分以选择关键token，从而聚焦于弱目标区域，抑制背景杂波和多任务耦合引入的不利特征。此外，采用梯度路由策略稳定检测语义，并将SR梯度导向检测，从而指导SR分支生成对检测有利的高频细节。", "result": "在NWPU VHR-10-Split、DOTAv1.5-Split和HRSSD-Split等公共数据集上的实验表明，SDCoNet在保持计算效率的同时，显著优于现有主流算法在低质量遥感图像中小目标检测的性能。", "conclusion": "SDCoNet通过多任务协同和显著性驱动，有效解决了低质量遥感图像中小目标检测的难题，实现了超分辨率和目标检测的优势互补。"}}
{"id": "2601.12512", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12512", "abs": "https://arxiv.org/abs/2601.12512", "authors": ["Mohd Usama", "Belal Ahmad", "Faleh Menawer R Althiyabi"], "title": "Fine-Tuning Cycle-GAN for Domain Adaptation of MRI Images", "comment": "14 pages, 9 figures, 2 tables", "summary": "Magnetic Resonance Imaging (MRI) scans acquired from different scanners or institutions often suffer from domain shifts owing to variations in hardware, protocols, and acquisition parameters. This discrepancy degrades the performance of deep learning models trained on source domain data when applied to target domain images. In this study, we propose a Cycle-GAN-based model for unsupervised medical-image domain adaptation. Leveraging CycleGANs, our model learns bidirectional mappings between the source and target domains without paired training data, preserving the anatomical content of the images. By leveraging Cycle-GAN capabilities with content and disparity loss for adaptation tasks, we ensured image-domain adaptation while maintaining image integrity. Several experiments on MRI datasets demonstrated the efficacy of our model in bidirectional domain adaptation without labelled data. Furthermore, research offers promising avenues for improving the diagnostic accuracy of healthcare. The statistical results confirm that our approach improves model performance and reduces domain-related variability, thus contributing to more precise and consistent medical image analysis.", "AI": {"tldr": "本文提出了一种基于Cycle-GAN的无监督医学图像域适应模型，用于解决不同MRI扫描设备导致的域偏移问题，通过学习双向映射并结合内容和差异损失，在不依赖配对数据的情况下有效实现了图像域适应，同时保持了图像的完整性，并提升了模型在实际应用中的性能。", "motivation": "不同MRI扫描设备、机构或协议导致的硬件、参数差异会引起域偏移，从而降低在源域数据上训练的深度学习模型在目标域图像上的性能。", "method": "提出了一种基于Cycle-GAN的无监督医学图像域适应模型，利用CycleGAN学习源域和目标域之间的双向映射，无需配对训练数据，并结合内容损失和差异损失以确保图像解剖结构的完整性。", "result": "在多个MRI数据集上的实验证明了该模型在双向域适应方面的有效性，且无需标注数据。统计结果表明，该方法提高了模型性能，减少了域相关变异性。", "conclusion": "该研究提出了一种有效的Cycle-GAN模型用于无监督医学图像域适应，它能够保持图像完整性并提高模型性能，为提高医疗诊断准确性提供了有前景的研究方向，并促进了更精确一致的医学图像分析。"}}
{"id": "2601.13247", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.13247", "abs": "https://arxiv.org/abs/2601.13247", "authors": ["Baochang Ren", "Yunzhi Yao", "Rui Sun", "Shuofei Qiao", "Ningyu Zhang", "Huajun Chen"], "title": "Aligning Agentic World Models via Knowledgeable Experience Learning", "comment": "Ongoing work", "summary": "Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.", "AI": {"tldr": "提出了一种名为 WorldMind 的新框架，通过构建符号化世界知识库来解决大型语言模型（LLMs）在物理世界理解上的不足，从而生成更具物理可行性的行动计划。", "motivation": "现有的 LLMs 存在“模态断裂”问题，即拥有丰富的语义知识但缺乏对物理世界规律的理解，导致生成的计划虽然在逻辑上合理，但在物理上却不可行。现有的对齐策略成本高昂且适应性差。", "method": "WorldMind 框架通过整合“过程经验”（Process Experience）和“目标经验”（Goal Experience）来构建一个符号化的世界知识库。其中，过程经验通过预测误差来强制执行物理可行性，目标经验通过成功轨迹来指导任务的最优性。", "result": "在 EB-ALFRED 和 EB-Habitat 数据集上的实验表明，WorldMind 相比基线模型取得了更优越的性能，并且具有显著的模型间和环境间的迁移能力。", "conclusion": "WorldMind 框架能够有效地弥合 LLMs 在物理世界理解上的差距，通过构建动态更新的世界知识库，生成更安全、更有效的物理可执行计划，并且具备良好的泛化能力。"}}
{"id": "2601.13251", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13251", "abs": "https://arxiv.org/abs/2601.13251", "authors": ["Ebubekir Tosun", "Mehmet Emin Buldur", "Özay Ezerceli", "Mahmoud ElHussieni"], "title": "Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph", "comment": null, "summary": "Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.", "AI": {"tldr": "该研究提出了一种大规模语义聚类系统，解决了现有神经网络嵌入无法区分同义词和反义词的问题，生成了高质量的语义簇，并实现了高精度的语义搜索和检索增强生成。", "motivation": "现有的神经网络嵌入方法难以区分同义词和反义词，导致增加相似度阈值也无法有效分离相反意义的词语。", "method": "构建了一个大规模语义聚类系统，处理了1500万个词汇项，评估了5.2亿个潜在关系，生成了290万个高精度语义簇。系统包括一个包含84.3万个概念对（同义、反义、下位语）的标注数据集，一个90% macro-F1的特化三向语义关系鉴别器，以及一个解决语义漂移和多义性的新颖软到硬聚类算法。该算法采用拓扑感知两阶段扩展-剪枝程序和拓扑投票。", "result": "生成了2.9百万个高精度语义簇。提出的三向语义关系鉴别器达到了90%的macro-F1。新颖的聚类算法有效缓解了语义漂移和多义性问题。", "conclusion": "该研究构建的语义聚类系统能够高精度地区分同义词和反义词，并生成高质量的语义簇，从而支持高精度的语义搜索和检索增强生成，尤其对形态丰富和低资源语言有益。"}}
{"id": "2601.12527", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.12527", "abs": "https://arxiv.org/abs/2601.12527", "authors": ["Richard Liu", "Itai Lang", "Rana Hanocka"], "title": "Deep Feature Deformation Weights", "comment": null, "summary": "Handle-based mesh deformation has been a long-standing paradigm in computer graphics, enabling intuitive shape edits from sparse controls. Classic techniques offer precise and rapid deformation control. However, they solve an optimization problem with constraints defined by control handle placement, requiring a user to know apriori the ideal distribution of handles on the shape to accomplish the desired edit. The mapping from handle set to deformation behavior is often unintuitive and, importantly, non-semantic. Modern data-driven methods, on the other hand, leverage a data prior to obtain semantic edits, but are slow and imprecise. We propose a technique that fuses the semantic prior of data with the precise control and speed of traditional frameworks. Our approach is surprisingly simple yet effective: deep feature proximity makes for smooth and semantic deformation weights, with no need for additional regularization. The weights can be computed in real-time for any surface point, whereas prior methods require optimization for new handles. Moreover, the semantic prior from deep features enables co-deformation of semantic parts. We introduce an improved feature distillation pipeline, barycentric feature distillation, which efficiently uses the visual signal from shape renders to minimize distillation cost. This allows our weights to be computed for high resolution meshes in under a minute, in contrast to potentially hours for both classical and neural methods. We preserve and extend properties of classical methods through feature space constraints and locality weighting. Our field representation allows for automatic detection of semantic symmetries, which we use to produce symmetry-preserving deformations. We show a proof-of-concept application which can produce deformations for meshes up to 1 million faces in real-time on a consumer-grade machine.", "AI": {"tldr": "本文提出了一种结合传统基于句柄的网格变形的精确性与数据驱动方法的语义性，通过深度特征相似性计算变形权重，实现了高效、语义化且可控的网格变形。", "motivation": "现有基于句柄的网格变形方法虽然精确快速，但需要用户预先知道理想的句柄分布，且句柄与变形行为的映射不直观、非语义化。而现代数据驱动方法虽然能实现语义化编辑，但速度慢且不精确。因此，研究动机是融合这两类方法的优点，实现既精确又语义化的网格变形。", "method": "提出一种新方法，利用深度特征的相似性计算平滑且语义化的变形权重，无需额外正则化。该方法可以通过改进的特征蒸馏流水线（重氏特征蒸馏）高效计算权重，支持任意表面点，且计算速度快。此外，通过特征空间约束和局部加权保留了传统方法的特性。引入了场表示，可以自动检测语义对称性，并用于生成保持对称性的变形。", "result": "提出的方法能够实时计算任意表面点的变形权重，实现了语义化变形，能够共同变形语义部件，并能处理高分辨率网格（可达100万面）在消费级硬件上实现近乎实时变形。实验证明，该方法在保持传统方法特性的同时，显著提高了变形的语义性和效率。", "conclusion": "通过深度特征相似性，可以有效地生成平滑、语义化的网格变形权重，从而融合了传统方法的速度和精确性与数据驱动方法的语义性。该方法计算高效，支持实时交互，并能实现语义部件的协同变形和对称性保持变形。"}}
{"id": "2601.12664", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12664", "abs": "https://arxiv.org/abs/2601.12664", "authors": ["Elisa Gonçalves Ribeiro", "Rodrigo Moreira", "Larissa Ferreira Rodrigues Moreira", "André Ricardo Backes"], "title": "Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images", "comment": "21st International Conference on Computer Vision Theory and Applications (VISAPP 2026), 9-11 March 2026, Marbella, Spain", "summary": "Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.", "AI": {"tldr": "该研究提出了一种在非独立同分布（non-IID）的联邦学习（FL）场景下，将在一个癌症影像数据集上优化的超参数迁移到另一个数据集的方法，并引入了一种简单的跨数据集聚合启发式方法，通过平均学习率、考虑众数优化器和批量大小来组合配置，从而在分类任务中取得了具有竞争力的性能。", "motivation": "在临床环境中，深度学习在癌症组织病理学训练中面临隐私限制。联邦学习（FL）通过保持数据本地化来缓解这个问题，但其性能受到非独立同分布（non-IID）客户端数据集下超参数选择的影响。因此，研究的动机是探索在一个癌症影像数据集上优化的超参数是否能泛化到non-IID的联邦场景。", "method": "研究采用了中心化贝叶斯超参数优化方法，然后在non-IID的FL设置中迁移数据集特定的最优配置。文章的主要贡献是引入了一种简单的跨数据集聚合启发式方法，通过平均学习率，并考虑众数（modal）的优化器和批量大小来组合配置。", "result": "提出的跨数据集聚合启发式方法，结合了从不同数据集中学习到的超参数配置，在二元组织病理学任务（卵巢癌和结直肠癌）的联邦学习设置中，实现了具有竞争力的分类性能。", "conclusion": "一种简单的跨数据集聚合启发式方法，通过平均学习率并综合考虑众数优化器和批量大小，可以将在一个数据集上优化的超参数有效地迁移到non-IID的联邦学习场景，并在癌症组织病理学分类任务中取得良好的性能。"}}
{"id": "2601.13253", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13253", "abs": "https://arxiv.org/abs/2601.13253", "authors": ["Ebubekir Tosun", "Mehmet Emin Buldur", "Özay Ezerceli", "Mahmoud ElHussieni"], "title": "A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus", "comment": null, "summary": "We present a hybrid methodology for generating large-scale semantic relationship datasets in low-resource languages, demonstrated through a comprehensive Turkish semantic relations corpus. Our approach integrates three phases: (1) FastText embeddings with Agglomerative Clustering to identify semantic clusters, (2) Gemini 2.5-Flash for automated semantic relationship classification, and (3) integration with curated dictionary sources. The resulting dataset comprises 843,000 unique Turkish semantic pairs across three relationship types (synonyms, antonyms, co-hyponyms) representing a 10x scale increase over existing resources at minimal cost ($65). We validate the dataset through two downstream tasks: an embedding model achieving 90% top-1 retrieval accuracy and a classification model attaining 90% F1-macro. Our scalable protocol addresses critical data scarcity in Turkish NLP and demonstrates applicability to other low-resource languages. We publicly release the dataset and models.", "AI": {"tldr": "该研究提出了一种在低资源语言（以土耳其语为例）中生成大规模语义关系数据集的混合方法，结合了词嵌入聚类、大型语言模型分类和词典集成，创建了一个包含84.3万个语义对的数据集，并在下游任务中验证了其有效性。", "motivation": "低资源语言（如土耳其语）在语义关系数据集方面存在数据稀缺问题，这阻碍了相关自然语言处理（NLP）技术的发展。", "method": "该方法包含三个阶段：1. 使用FastText词嵌入和凝聚聚类来识别语义簇；2. 利用Gemini 2.5-Flash模型自动对语义关系进行分类；3. 将生成的语义关系与现有词典资源进行整合。", "result": "研究构建了一个包含84.3万个独特的土耳其语语义对（包括同义词、反义词、下位词）的数据集，规模是现有资源的10倍，且成本极低（65美元）。通过下游任务评估，嵌入模型取得了90%的top-1检索准确率，分类模型达到了90%的F1-macro分数。", "conclusion": "提出的混合方法能够以低成本、大规模地生成低资源语言的语义关系数据集，有效解决了数据稀缺问题，并已在土耳其语NLP领域得到验证，该方法具有推广到其他低资源语言的潜力。数据集和模型已公开。"}}
{"id": "2601.12530", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12530", "abs": "https://arxiv.org/abs/2601.12530", "authors": ["Jan Fabian Schmid", "Annika Hagemann"], "title": "XRefine: Attention-Guided Keypoint Match Refinement", "comment": null, "summary": "Sparse keypoint matching is crucial for 3D vision tasks, yet current keypoint detectors often produce spatially inaccurate matches. Existing refinement methods mitigate this issue through alignment of matched keypoint locations, but they are typically detector-specific, requiring retraining for each keypoint detector. We introduce XRefine, a novel, detector-agnostic approach for sub-pixel keypoint refinement that operates solely on image patches centered at matched keypoints. Our cross-attention-based architecture learns to predict refined keypoint coordinates without relying on internal detector representations, enabling generalization across detectors. Furthermore, XRefine can be extended to handle multi-view feature tracks. Experiments on MegaDepth, KITTI, and ScanNet demonstrate that the approach consistently improves geometric estimation accuracy, achieving superior performance compared to existing refinement methods while maintaining runtime efficiency. Our code and trained models can be found at https://github.com/boschresearch/xrefine.", "AI": {"tldr": "提出了一种名为XRefine的检测器无关的亚像素关键点精炼方法，通过交叉注意力机制仅利用关键点图像块来提高3D视觉任务的几何估计精度，并可泛化到多视图特征跟踪。", "motivation": "现有关键点检测器在空间上不够精确，而现有的精炼方法通常是检测器特定的，需要针对每个检测器重新训练。", "method": "提出了一种名为XRefine的交叉注意力机制模型，它仅处理以匹配关键点为中心的图像块，学习预测精炼的关键点坐标，无需依赖检测器内部表示，从而实现检测器无关性。该方法还可以扩展到处理多视图特征跟踪。", "result": "在MegaDepth、KITTI和ScanNet数据集上的实验表明，XRefine在几何估计精度方面持续提升，优于现有精炼方法，同时保持了运行时效率。", "conclusion": "XRefine是一种有效的、检测器无关的亚像素关键点精炼方法，能够显著提高3D视觉任务的几何估计精度，并且具有良好的泛化性和效率。"}}
{"id": "2601.12671", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12671", "abs": "https://arxiv.org/abs/2601.12671", "authors": ["Thamara Leandra de Deus Melo", "Rodrigo Moreira", "Larissa Ferreira Rodrigues Moreira", "André Ricardo Backes"], "title": "Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification", "comment": "21st International Conference on Computer Vision Theory and Applications (VISAPP 2026), 9-11 March 2026, Marbella, Spain", "summary": "Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. We evaluated convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.", "AI": {"tldr": "在联邦学习设置下，使用卷积神经网络（CNN）进行脑肿瘤MRI图像分类。研究发现，测试时增强（TTA）策略能显著提高模型性能，尤其是在与轻度预处理结合时。", "motivation": "脑肿瘤的早期诊断至关重要，但由于病变的多样性和图像的复杂性而面临挑战。本研究旨在探索在联邦学习环境下，如何通过图像预处理和TTA策略来提高脑肿瘤MRI图像分类的效率和准确性。", "method": "研究评估了在联邦学习（FL）设置下使用卷积神经网络（CNN）进行脑肿瘤MRI图像分类。对比了在原始MRI图像和经过预处理（调整大小、灰度转换、归一化、滤波和直方图均衡化）的图像上训练的模型。同时，还评估了测试时增强（TTA）策略的应用。", "result": "单独的图像预处理对模型性能提升效果不显著。然而，当预处理与测试时增强（TTA）结合使用时，在联邦MRI分类任务中实现了持续且统计学上显著的性能提升（p<0.001）。", "conclusion": "在基于联邦学习的医学影像分析中，TTA应作为默认的推理策略。当计算资源允许时，将TTA与轻度预处理相结合，可以带来额外的、可靠的性能提升。"}}
{"id": "2601.13260", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13260", "abs": "https://arxiv.org/abs/2601.13260", "authors": ["Sawsan Alqahtani", "Mir Tafseer Nayeem", "Md Tahmid Rahman Laskar", "Tasnim Mohiuddin", "M Saiful Bari"], "title": "Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models", "comment": "Accepted to EACL 2026 (long, main). The first two authors contributed equally", "summary": "Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.", "AI": {"tldr": "本文将分词重新定义为语言模型设计中的核心环节，而非简单的预处理步骤。文章提出了一个情境感知框架，旨在将分词器与模型进行协同设计，并强调了标准化评估和透明报告的重要性，以期构建更公平、高效、适应性强的语言技术。", "motivation": "现有子词分词方法（如BPE）虽然可扩展，但常常与语言结构脱节，加剧偏见，且在多语言多领域应用中存在效率低下问题。分词的理论基础薄弱且设计不一致，阻碍了语言技术的发展。", "method": "文章提出将分词视为一个核心建模决策，并倡导一种情境感知（context-aware）的框架，将分词器与模型进行协同设计（co-design）。该框架考虑了语言学、领域和部署等因素。此外，强调了标准化评估（standardized evaluation）和透明报告（transparent reporting）的重要性。", "result": "通过将分词视为核心设计问题，而非技术上的“事后考虑”，有望实现更公平、更高效、更具适应性的语言技术。", "conclusion": "分词是一个关键的建模决策，应与语言模型协同设计。通过情境感知框架、标准化评估和透明报告，可以改进分词的效率、公平性和适应性，从而推动语言技术的发展。"}}
{"id": "2601.12715", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12715", "abs": "https://arxiv.org/abs/2601.12715", "authors": ["Chengzhou Li", "Ping Guo", "Guanchen Meng", "Qi Jia", "Jinyuan Liu", "Zhu Liu", "Xiaokang Liu", "Yu Liu", "Zhongxuan Luo", "Xin Fan"], "title": "RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels", "comment": "Accepted by AAAI 2026,9 pages,10 figures", "summary": "Object detection in sonar images is a key technology in underwater detection systems. Compared to natural images, sonar images contain fewer texture details and are more susceptible to noise, making it difficult for non-experts to distinguish subtle differences between classes. This leads to their inability to provide precise annotation data for sonar images. Therefore, designing effective object detection methods for sonar images with extremely limited labels is particularly important. To address this, we propose a teacher-student framework called RSOD, which aims to fully learn the characteristics of sonar images and develop a pseudo-label strategy suitable for these images to mitigate the impact of limited labels. First, RSOD calculates a reliability score by assessing the consistency of the teacher's predictions across different views. To leverage this score, we introduce an object mixed pseudo-label method to tackle the shortage of labeled data in sonar images. Finally, we optimize the performance of the student by implementing a reliability-guided adaptive constraint. By taking full advantage of unlabeled data, the student can perform well even in situations with extremely limited labels. Notably, on the UATD dataset, our method, using only 5% of labeled data, achieves results that can compete against those of our baseline algorithm trained on 100% labeled data. We also collected a new dataset to provide more valuable data for research in the field of sonar.", "AI": {"tldr": "提出了一种名为RSOD的师生框架，用于解决声纳图像中标签数据极度有限的问题，通过伪标签策略和可靠性引导的自适应约束来提升检测性能，并在UATD数据集上仅用5%的标签数据取得了与100%标签数据基线模型相当的性能。", "motivation": "声纳图像纹理细节少、噪声多，非专业人士难以精确标注，导致标签数据极其有限，因此需要设计适用于此类场景的有效目标检测方法。", "method": "提出RSOD师生框架，包括：1. 计算教师模型在不同视图下的预测一致性来评估预测可靠性得分。2. 引入一种对象混合伪标签策略，利用可靠性得分生成伪标签以缓解数据不足。3. 采用可靠性引导的自适应约束来优化学生模型的性能。", "result": "在UATD数据集上，使用5%的标注数据，RSOD方法达到了与使用100%标注数据的基线算法相当的性能。同时，研究者还收集了一个新的声纳数据集。", "conclusion": "RSOD框架通过充分利用未标注数据，有效地缓解了声纳图像标签数据稀疏的问题，使得模型在有限标签情况下也能取得优秀的检测性能，并为该领域的研究提供了新的数据集。"}}
{"id": "2601.13264", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13264", "abs": "https://arxiv.org/abs/2601.13264", "authors": ["Tyler Lizzo", "Larry Heck"], "title": "Unlearning in LLMs: Methods, Evaluation, and Open Challenges", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable success across natural language processing tasks, yet their widespread deployment raises pressing concerns around privacy, copyright, security, and bias. Machine unlearning has emerged as a promising paradigm for selectively removing knowledge or data from trained models without full retraining. In this survey, we provide a structured overview of unlearning methods for LLMs, categorizing existing approaches into data-centric, parameter-centric, architecture-centric, hybrid, and other strategies. We also review the evaluation ecosystem, including benchmarks, metrics, and datasets designed to measure forgetting effectiveness, knowledge retention, and robustness. Finally, we outline key challenges and open problems, such as scalable efficiency, formal guarantees, cross-language and multimodal unlearning, and robustness against adversarial relearning. By synthesizing current progress and highlighting open directions, this paper aims to serve as a roadmap for developing reliable and responsible unlearning techniques in large language models.", "AI": {"tldr": "本文对大型语言模型（LLMs）的机器遗忘技术进行了全面的综述，将现有方法分为数据中心、参数中心、架构中心、混合及其他策略，并讨论了评估方法和未来挑战，旨在为开发可靠负责的LLMs遗忘技术提供路线图。", "motivation": "随着大型语言模型（LLMs）的广泛部署，隐私、版权、安全和偏见等问题日益突出。机器遗忘作为一种无需完全重训即可选择性移除模型知识或数据的技术，为解决这些问题提供了前景。因此，研究LLMs的机器遗忘技术变得至关重要。", "method": "本文采用文献综述的方法，对LLMs的机器遗忘方法进行分类，包括数据中心、参数中心、架构中心、混合和其他策略。同时，也回顾了用于衡量遗忘效果、知识保留和鲁棒性的评估生态系统，包括基准、指标和数据集。", "result": "文章系统地梳理了现有LLMs的机器遗忘方法，并对其评估方法进行了总结。此外，还指出了当前研究面临的关键挑战和开放性问题，例如效率、正式保证、跨语言和多模态遗忘以及对抗性再学习的鲁棒性。", "conclusion": "本综述旨在通过整合当前进展并指出开放性研究方向，为开发可靠且负责任的大型语言模型遗忘技术提供一份路线图，以应对LLMs部署带来的挑战。"}}
{"id": "2601.12638", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12638", "abs": "https://arxiv.org/abs/2601.12638", "authors": ["Ninnart Fuengfusin", "Keisuke Yoneda", "Naoki Suganuma"], "title": "Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT", "comment": "6 pages, 3 figures", "summary": "LIDAR 3D object detection is one of the important tasks for autonomous vehicles. Ensuring that this task operates in real-time is crucial. Toward this, model quantization can be used to accelerate the runtime. However, directly applying model quantization often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. To address the wide numerical distribution, we proposed a mixed precision framework designed for PointPillars. Our framework first searches for sensitive layers with post-training quantization (PTQ) by quantizing one layer at a time to 8-bit integer (INT8) and evaluating each model for average precision (AP). The top-k most sensitive layers are assigned as floating point (FP). Combinations of these layers are greedily searched to produce candidate mixed precision models, which are finalized with either PTQ or quantization-aware training (QAT). Furthermore, to handle outliers, we observe that using a very small number of calibration data reduces the likelihood of encountering outliers, thereby improving PTQ performance. Our methods provides mixed precision models without training in the PTQ pipeline, while our QAT pipeline achieves the performance competitive to FP models. With TensorRT deployment, our models offer less latency and sizes by up to 2.35 and 2.26 times, respectively.", "AI": {"tldr": "本文提出了一种针对PointPillars的混合精度框架，用于解决LIDAR 3D目标检测中的量化性能下降问题，并结合数据校准策略处理异常值，实现了实时性提升。", "motivation": "LIDAR 3D目标检测对于自动驾驶至关重要，需要实时运行。模型量化可以加速推理，但LIDAR数据的数值分布广泛和存在极端异常值会导致性能下降。", "method": "提出一个混合精度框架，首先使用PTQ搜索对INT8敏感的层，将k个最不敏感的层保留为FP。然后通过贪婪搜索组合这些层，并使用PTQ或QAT进行微调。针对异常值，提出使用少量校准数据来提高PTQ性能。", "result": "提出的混合精度模型在PTQ流程中无需训练即可获得性能，QAT流程可达到与FP模型相当的性能。经过TensorRT部署后，模型的延迟和大小分别降低了2.35倍和2.26倍。", "conclusion": "通过混合精度量化和数据校准策略，可以有效解决LIDAR 3D目标检测模型量化带来的性能下降问题，并显著提升模型在实时性方面的表现。"}}
{"id": "2601.12567", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12567", "abs": "https://arxiv.org/abs/2601.12567", "authors": ["Władysław Skarbek", "Michał Salomonowicz", "Michał Król"], "title": "Camera Pose Revisited", "comment": "30 pages, 9 figures, 9 tables", "summary": "Estimating the position and orientation of a camera with respect to an observed scene is one of the central problems in computer vision, particularly in the context of camera calibration and multi-sensor systems. This paper addresses the planar Perspective--$n$--Point problem, with special emphasis on the initial estimation of the pose of a calibration object. As a solution, we propose the \\texttt{PnP-ProCay78} algorithm, which combines the classical quadratic formulation of the reconstruction error with a Cayley parameterization of rotations and least-squares optimization. The key component of the method is a deterministic selection of starting points based on an analysis of the reconstruction error for two canonical vectors, allowing costly solution-space search procedures to be avoided. Experimental validation is performed using data acquired also from high-resolution RGB cameras and very low-resolution thermal cameras in an integrated RGB--IR setup. The results demonstrate that the proposed algorithm achieves practically the same projection accuracy as optimal \\texttt{SQPnP} and slightly higher than \\texttt{IPPE}, both prominent \\texttt{PnP-OpenCV} procedures. However, \\texttt{PnP-ProCay78} maintains a significantly simpler algorithmic structure. Moreover, the analysis of optimization trajectories in Cayley space provides an intuitive insight into the convergence process, making the method attractive also from a didactic perspective. Unlike existing PnP solvers, the proposed \\texttt{PnP-ProCay78} algorithm combines projection error minimization with an analytically eliminated reconstruction-error surrogate for translation, yielding a hybrid cost formulation that is both geometrically transparent and computationally efficient.", "AI": {"tldr": "提出了一种名为PnP-ProCay78的新算法，用于解决平面PnP问题，尤其侧重于标定物体的初始姿态估计。该算法结合了二次重构误差、Cayley旋转参数化和最小二乘优化，并通过分析两个典型向量的重构误差来确定性地选择起始点，避免了昂贵的搜索过程。", "motivation": "解决计算机视觉中的相机位姿估计问题，特别是在相机标定和多传感器系统中，并为平面PnP问题提供一种更有效、更易于理解的初始姿态估计方法。", "method": "提出PnP-ProCay78算法，该算法结合了经典的二次重构误差、Cayley旋转参数化和最小二乘优化。通过分析两个典型向量的重构误差，确定性地选择起始点，避免了对解空间的搜索。", "result": "PnP-ProCay78算法在投影精度上接近最优的SQPnP算法，略高于IPPE算法。同时，该算法具有更简单的算法结构，并且在Cayley空间中的优化轨迹分析提供了对收敛过程的直观理解。", "conclusion": "PnP-ProCay78算法是一种有效、简单且具有启发性的平面PnP求解器，通过结合投影误差最小化和解析消除的平移重构误差替代项，实现了一种既几何透明又计算高效的混合成本公式。"}}
{"id": "2601.12809", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12809", "abs": "https://arxiv.org/abs/2601.12809", "authors": ["Takaki Yamamoto", "Chihiro Noguchi", "Toshihiro Tanizawa"], "title": "Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data", "comment": null, "summary": "Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.", "AI": {"tldr": "研究者提出了一个1D图像-文本测试平台，以探究基于Transformer的视觉和文本编码器在CLIP风格的对比学习目标下，如何学习左右关系。发现标签多样性比布局多样性更能驱动模型的泛化能力，并且注意力机制中的位置嵌入和词元嵌入的交互是学习左右关系的关键。", "motivation": "现有视觉语言模型在空间理解方面仍存在挑战，但尚不清楚它们是否真正习得了这种理解，以及通过何种机制实现。本研究旨在探究CLIP风格的对比学习如何让模型习得左右关系。", "method": "研究者构建了一个可控的1D图像-文本测试平台，使用CLIP风格的对比学习目标训练轻量级的Transformer视觉和文本编码器。通过评估模型在未见过对象对上的泛化能力，并系统地改变标签和布局的多样性来分析其性能。此外，还通过注意力分解来探究模型学习左右关系的机制。", "result": "对比学习能够让模型学习到左右关系。标签多样性是驱动模型在该设置下泛化的主要因素，比布局多样性更重要。注意力分解显示，位置嵌入和词元嵌入之间的交互产生了水平注意力梯度，打破了编码器的左右对称性，并且去除这种贡献会显著降低左右判别能力。", "conclusion": "本研究通过1D测试平台为CLIP风格模型何时以及如何获得关系能力提供了机制性洞察，表明标签多样性和特定的注意力机制交互是学习左右关系的关键。"}}
{"id": "2601.12626", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12626", "abs": "https://arxiv.org/abs/2601.12626", "authors": ["Raphi Kang", "Hongqiao Chen", "Georgia Gkioxari", "Pietro Perona"], "title": "Linear Mechanisms for Spatiotemporal Reasoning in Vision Language Models", "comment": null, "summary": "Spatio-temporal reasoning is a remarkable capability of Vision Language Models (VLMs), but the underlying mechanisms of such abilities remain largely opaque. We postulate that visual/geometrical and textual representations of spatial structure must be combined at some point in VLM computations. We search for such confluence, and ask whether the identified representation can causally explain aspects of input-output model behavior through a linear model. We show empirically that VLMs encode object locations by linearly binding \\textit{spatial IDs} to textual activations, then perform reasoning via language tokens. Through rigorous causal interventions we demonstrate that these IDs, which are ubiquitous across the model, can systematically mediate model beliefs at intermediate VLM layers. Additionally, we find that spatial IDs serve as a diagnostic tool for identifying limitations in existing VLMs, and as a valuable learning signal. We extend our analysis to video VLMs and identify an analogous linear temporal ID mechanism. By characterizing our proposed spatiotemporal ID mechanism, we elucidate a previously underexplored internal reasoning process in VLMs, toward improved interpretability and the principled design of more aligned and capable models. We release our code for reproducibility: https://github.com/Raphoo/linear-mech-vlms.", "AI": {"tldr": "本研究提出了一种新的方法来理解视觉语言模型（VLMs）的时空推理能力，发现模型通过“空间ID”来线性绑定物体位置和文本激活，并以此进行推理。研究还验证了这些ID在模型内部的因果作用，并将其应用于视频VLM分析。", "motivation": "视觉语言模型（VLMs）在时空推理方面表现出色，但其内部机制不透明。本研究旨在探究VLMs如何结合视觉/几何和文本表征来执行时空推理，并寻找能够解释模型行为的内部表征。", "method": "研究人员通过搜索VLMs内部的“汇合点”，探究是否存在一种能够结合视觉和文本空间信息的表征。他们提出了“空间ID”的概念，并使用线性模型来验证这些ID是否能因果性地解释模型的输入-输出行为。通过因果干预，研究人员进一步证明了这些ID在模型中间层对模型信念的系统性影响。最后，将该方法扩展到视频VLM，并发现了类似的时间ID机制。", "result": "研究发现，VLMs通过线性绑定“空间ID”到文本激活来编码物体位置，并利用语言token进行推理。这些无处不在的空间ID能够系统性地调节模型中间层的信念。此外，空间ID还可用于诊断现有VLMs的局限性，并作为有价值的学习信号。对于视频VLM，也发现了一个线性的时间ID机制。", "conclusion": "本研究揭示了VLMs中一种先前未被充分探索的内部时空推理机制，即通过“空间ID”和“时间ID”来实现。理解这一机制有助于提高VLMs的可解释性，并为设计更强大、更对齐的模型提供理论指导。"}}
{"id": "2601.12882", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12882", "abs": "https://arxiv.org/abs/2601.12882", "authors": ["Sudip Chakrabarty"], "title": "YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection", "comment": null, "summary": "The \"You Only Look Once\" (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations (YOLOv1 through YOLO11) remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes a comprehensive analysis of YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. This study examines the critical innovations that enable this transition, specifically the introduction of the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through a systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors (including RTMDet and DAMO-YOLO) in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.", "AI": {"tldr": "YOLO26 论文介绍了一种无需 NMS 的端到端实时目标检测框架，通过引入 MuSGD 优化器、STAL 目标分配策略和 ProgLoss 动态监督机制，在速度和精度上都超越了现有技术。", "motivation": "传统 YOLO 系列模型在实时性上受到 NMS 后处理的限制，该研究旨在解决推理延迟和检测精度之间的权衡问题。", "method": "该论文分析了 YOLO26 框架，该框架通过端到端学习策略摒弃了 NMS。关键创新包括：用于稳定轻量级骨干网络的 MuSGD 优化器，用于小目标感知的 STAL 目标分配策略，以及 ProgLoss 动态监督机制。", "result": "YOLO26 在官方性能基准测试中，在推理速度和检测精度上均优于包括 RTMDet 和 DAMO-YOLO 在内的其他模型，达到了新的 Pareto 前沿。", "conclusion": "通过将表示学习与启发式后处理分离，YOLO26 成功解决了延迟和精度之间的历史权衡，代表了边缘计算视觉的下一代发展方向。"}}
{"id": "2601.13300", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13300", "abs": "https://arxiv.org/abs/2601.13300", "authors": ["Yow-Fu Liou", "Yu-Chien Tang", "Yu-Hsiang Liu", "An-Zi Yen"], "title": "OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference", "comment": null, "summary": "Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question answering (MCQA) interface with an additional option containing a misleading directive, leveraging standardized choice structure and scalable evaluation. We construct OI-Bench, a benchmark of 3,000 questions spanning knowledge, reasoning, and commonsense tasks, with 16 directive types covering social compliance, bonus framing, threat framing, and instructional interference. This setting combines manipulation of the choice interface with directive-based interference, enabling systematic assessment of model susceptibility. We evaluate 12 LLMs to analyze attack success rates, behavioral responses, and further investigate mitigation strategies ranging from inference-time prompting to post-training alignment. Experimental results reveal substantial vulnerabilities and heterogeneous robustness across models. OI-Bench is expected to support more systematic evaluation of LLM robustness to directive interference within choice-based interfaces.", "AI": {"tldr": "本研究提出了一种名为“选项注入”（Option Injection）的新型大型语言模型（LLM）基准测试方法，通过在选择题中加入误导性指令选项，来评估LLM在选择题场景下对指令干扰的敏感性。研究构建了一个包含3000个问题的OI-Bench基准，并测试了12种LLM，结果表明LLM普遍存在漏洞，且不同模型间的鲁棒性存在差异。", "motivation": "现有的LLM评估方法可能受到接口伪影和指令信号（如社会提示、框架和指令）的影响。为了更全面地理解LLM的能力、局限性和鲁棒性，需要一种能够系统评估LLM在多项选择题场景下对指令干扰敏感性的方法。", "method": "提出“选项注入”方法，通过在多项选择题界面中增加一个包含误导性指令的新选项，并利用标准化的选择结构和可扩展的评估。构建了3000个问题的OI-Bench基准，涵盖知识、推理和常识任务，包含16种指令类型。评估了12种LLM，分析了攻击成功率、行为响应，并研究了从推理时提示到训练后对齐的缓解策略。", "result": "实验结果显示，LLM在面对选项注入时表现出显著的脆弱性，不同模型间的鲁棒性差异很大。研究揭示了LLM在选择题接口中容易受到指令干扰的影响。", "conclusion": "OI-Bench提供了一种系统评估LLM在基于选择题接口中对指令干扰鲁棒性的新方法。研究结果强调了LLM在面对误导性指令时的普遍脆弱性，并为开发更鲁棒的LLM模型提供了方向。"}}
{"id": "2601.12666", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12666", "abs": "https://arxiv.org/abs/2601.12666", "authors": ["Zonglin Li", "Jieji Ren", "Shuangfan Zhou", "Heng Guo", "Jinnuo Zhang", "Jiang Zhou", "Boxin Shi", "Zhanyu Ma", "Guoying Gu"], "title": "Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface", "comment": "5 pages 7figures", "summary": "Color photometric stereo enables single-shot surface reconstruction, extending conventional photometric stereo that requires multiple images of a static scene under varying illumination to dynamic scenarios. However, most existing approaches assume ideal distant lighting and Lambertian reflectance, leaving more practical near-light conditions and non-Lambertian surfaces underexplored. To overcome this limitation, we propose a framework that leverages neural implicit representations for depth and BRDF modeling under the assumption of mono-chromaticity (uniform chromaticity and homogeneous material), which alleviates the inherent ill-posedness of color photometric stereo and allows for detailed surface recovery from just one image. Furthermore, we design a compact optical tactile sensor to validate our approach. Experiments on both synthetic and real-world datasets demonstrate that our method achieves accurate and robust surface reconstruction.", "AI": {"tldr": "提出一种利用神经隐式表示进行单张彩色图像下光度立体表面重建的框架，解决了近距离光源和非朗伯反射表面下的固有不适定问题，并通过紧凑型光学触觉传感器进行了验证。", "motivation": "现有彩色光度立体方法多假设理想远距离光源和朗伯反射，未能充分解决更实际的近距离光源和非朗伯反射表面下的问题。", "method": "提出一个利用神经隐式表示（neural implicit representations）进行深度和BRDF（双向反射分布函数）建模的框架。假设单色性（均匀色度和均质材料），以缓解彩色光度立体固有的不适定性，并从单张图像中恢复详细表面信息。", "result": "在合成和真实世界数据集上的实验表明，该方法能够实现准确且鲁棒的表面重建。", "conclusion": "提出的框架通过神经隐式表示，有效解决了单张彩色图像下近距离光源和非朗伯反射表面的光度立体表面重建问题，并取得了良好的重建效果。"}}
{"id": "2601.12929", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12929", "abs": "https://arxiv.org/abs/2601.12929", "authors": ["Gonzalo Mancera", "Daniel DeAlcala", "Aythami Morales", "Ruben Tolosana", "Julian Fierrez"], "title": "Membership Inference Test: Auditing Training Data in Object Classification Models", "comment": "Deployable AI (DAI 2025) workshop co-located with AAAI-25", "summary": "In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.", "AI": {"tldr": "本研究提出并评估了一种用于目标识别领域成员推断测试（MINT）的定制化架构，该架构利用卷积层捕捉训练激活模式，可在三个公开数据库上识别训练和测试数据，准确率在70%-80%之间。", "motivation": "研究的目标是在目标识别领域分析成员推断测试（MINT）的性能，并开发专门针对该领域的MINT模型架构，以优化性能和效率，解决目标识别的复杂性。", "method": "提出并开发了定制化的MINT模型架构，该架构利用卷积层来捕捉和建模训练过程中的激活模式。实验采用了目标检测模型、嵌入提取器和MINT模块，并在三个公开数据库（共174K+图像）上进行了测试。", "result": "提出的架构能够识别用于测试和训练的给定数据，准确率在70%到80%之间，具体取决于输入MINT模块的目标检测模块层深度。研究还分析了影响MINT模块性能的因素，以促进更透明的训练过程。", "conclusion": "定制化的MINT架构在目标识别领域能够有效地推断数据是否在训练中使用，并且准确率与模型深度相关。该研究为理解和提高训练过程的透明度提供了见解。"}}
{"id": "2601.13317", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.13317", "abs": "https://arxiv.org/abs/2601.13317", "authors": ["Samantha Sudhoff", "Pranav Perumal", "Zhaoqing Wu", "Tunazzina Islam"], "title": "Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse", "comment": null, "summary": "Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.", "AI": {"tldr": "本研究对比分析了Meta付费广告和Bluesky公共社交媒体上的气候传播内容，揭示了不同平台激励机制如何影响气候叙事的主题结构、立场和时事响应性。", "motivation": "现有计算研究通常孤立地分析付费广告和公共社交媒体上的气候传播，这限制了区分机构宣传和公众表达的能力。研究旨在克服这一局限，比较不同平台的气候话语，理解平台激励机制的影响。", "method": "研究者开发了一个可解释的、端到端的“主题发现与分配”框架，该框架利用LLMs对Meta付费广告和Bluesky公共帖子进行语义聚类和主题标记。通过人类判断、LLM评估、下游立场预测和主题引导检索等方法对模型质量进行了评估。最后，应用该框架分析了气候信息的主题差异和围绕重大政治事件的主题变化。", "result": "研究发现，不同平台（Meta付费广告 vs. Bluesky公共帖子）的气候传播在主题结构、立场一致性和时事响应性方面存在系统性差异，这些差异反映了平台层面的激励机制。", "conclusion": "平台激励机制深刻影响着气候叙事的形成和传播方式。本研究提出的框架不仅适用于气候传播分析，还可推广到跨异构传播环境的比较性叙事分析。"}}
{"id": "2601.13142", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13142", "abs": "https://arxiv.org/abs/2601.13142", "authors": ["Zhantao Ma", "Quanfeng Lu", "Shuai Zhong", "Dahai Yu", "Ping Luo", "Michael K. Ng"], "title": "TVWorld: Foundations for Remote-Control TV Agents", "comment": null, "summary": "Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \\textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \\textbf{TVWorld-N} for topology-aware navigation and \\textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \\emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \\textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.", "AI": {"tldr": "本文提出了TVWorld数据集和TVWorld-N、TVWorld-G两个基准，用于评估大型视觉语言模型（LVLMs）在遥控器（RC）式电视交互中的能力。现有模型在拓扑感知方面存在不足，为此，研究者提出了拓扑感知训练框架，并开发了专门用于电视导航的模型TVTheseus，在TVWorld-N上达到了SOTA性能。", "motivation": "现有大型视觉语言模型在设备控制方面的研究主要集中在点按（PnC）交互，而日常生活中更常见的遥控器（RC）式电视交互仍未得到充分研究，存在研究空白。", "method": "1. 构建了离线的、基于图的电视导航抽象环境TVWorld。\n2. 提出了TVWorld-N（拓扑感知导航）和TVWorld-G（聚焦感知定位）两个基准，用于全面评估电视使用能力。\n3. 提出了拓扑感知训练（Topology-Aware Training）框架，用于增强LVLMs的拓扑感知能力。\n4. 基于该框架开发了专门用于电视导航的模型TVTheseus。", "result": "TVTheseus在TVWorld-N基准上取得了68.3%的成功率，超越了Gemini 3 Flash等闭源基线模型，达到了SOTA性能。研究还发现现有模型在基于聚焦的、长序列电视导航任务中，拓扑感知能力不足。", "conclusion": "TVWorld及其基准填补了RC式电视交互研究的空白，并揭示了现有LVLMs在拓扑感知方面的局限性。提出的拓扑感知训练框架和TVTheseus模型能够有效提升模型在电视导航任务上的表现，为开发更有效的电视使用智能体提供了有价值的见解。"}}
{"id": "2601.12636", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12636", "abs": "https://arxiv.org/abs/2601.12636", "authors": ["Satyaki Roy Chowdhury", "Aswathnarayan Radhakrishnan", "Hsiao Jou Hsu", "Hari Subramoni", "Joachim Moortgat"], "title": "From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2", "comment": "Accepted by WACV 2026", "summary": "Deploying Sentinel-2 satellite derived bathymetry (SDB) robustly across sites remains challenging. We analyze a Swin-Transformer based U-Net model (Swin-BathyUNet) to understand how it infers depth and when its predictions are trustworthy. A leave-one-band out study ranks spectral importance to the different bands consistent with shallow water optics. We adapt ablation-based CAM to regression (A-CAM-R) and validate the reliability via a performance retention test: keeping only the top-p% salient pixels while neutralizing the rest causes large, monotonic RMSE increase, indicating explanations localize on evidence the model relies on. Attention ablations show decoder conditioned cross attention on skips is an effective upgrade, improving robustness to glint/foam. Cross-region inference (train on one site, test on another) reveals depth-dependent degradation: MAE rises nearly linearly with depth, and bimodal depth distributions exacerbate mid/deep errors. Practical guidance follows: maintain wide receptive fields, preserve radiometric fidelity in green/blue channels, pre-filter bright high variance near shore, and pair light target site fine tuning with depth aware calibration to transfer across regions.", "AI": {"tldr": "该研究提出了一种基于 Swin-Transformer 的 U-Net 模型（Swin-BathyUNet），用于从 Sentinel-2 卫星影像推算水深，并分析了其可解释性和跨区域泛化能力。研究发现，模型对绿光和蓝光波段较为敏感，且在进行解释性分析时，保留对模型决策关键的像素能够最大程度地维持预测精度。研究还提出了一种改进的注意力机制，能够提升模型对水面反射（glint）和泡沫的鲁棒性。在跨区域测试中，模型在不同水深区域表现出性能差异，深度越深，误差越大。最后，研究为 SDB 的稳健部署提供了实践建议。", "motivation": "在不同地点稳健地部署 Sentinel-2 卫星衍生的水深（SDB）仍然是一个挑战。本研究旨在深入理解一个基于 Swin-Transformer 的 U-Net 模型（Swin-BathyUNet）如何推断水深，以及其预测在何时是可信赖的，从而为提高 SDB 的可靠性和泛化能力提供指导。", "method": "研究采用了 Swin-Transformer 改进的 U-Net 模型（Swin-BathyUNet）来推算水深。为了评估模型的可解释性，研究进行了以下实验：1. 进行了“留出一个波段”的实验，以确定不同波段对水深推算的重要性；2. 采用一种名为 A-CAM-R（ablation-based CAM for regression）的方法来验证模型预测的可靠性，通过保留关键像素并去除其他像素来观察 RMSE 的变化；3. 通过注意力机制消融实验来评估模型组件的有效性，特别是改进的注意力机制对跳跃连接（skips）的条件化交叉注意力；4. 进行了跨区域推理实验（在一个地点训练，在另一个地点测试），以评估模型在不同地理区域的泛化能力。", "result": "1. “留出一个波段”的实验结果表明，不同波段的重要性与浅水光学特性一致，提示了模型对光谱信息的利用方式。2. A-CAM-R 实验验证了模型的解释性，保留 top-p% 的关键像素时，RMSE 呈单调递增，表明模型的解释集中在模型依赖的证据上。3. 注意力机制的消融实验表明，解码器对跳跃连接的条件化交叉注意力是一种有效的改进，能够提高模型对水面反射（glint）和泡沫的鲁棒性。4. 跨区域推理实验揭示了水深依赖的性能退化：平均绝对误差（MAE）几乎随水深线性增加，且双峰水深分布会加剧对中等和深水区域的误差。", "conclusion": "Swin-BathyUNet 模型能够有效地从 Sentinel-2 影像推算水深，并且其预测具有一定的可解释性。研究为提高 SDB 的稳健性和跨区域部署提供了关键的实践指导，包括保持宽接收野、保留绿/蓝通道的辐射保真度、预过滤近岸高方差区域的亮斑，以及通过轻目标区域微调和水深感知校准来促进跨区域迁移。"}}
{"id": "2601.13288", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13288", "abs": "https://arxiv.org/abs/2601.13288", "authors": ["Gonzalo Ariel Meyoyan", "Luciano Del Corro"], "title": "A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification", "comment": null, "summary": "Production LLM systems often rely on separate models for safety and other classification-heavy steps, increasing latency, VRAM footprint, and operational complexity. We instead reuse computation already paid for by the serving LLM: we train lightweight probes on its hidden states and predict labels in the same forward pass used for generation. We frame classification as representation selection over the full token-layer hidden-state tensor, rather than committing to a fixed token or fixed layer (e.g., first-token logits or final-layer pooling). To implement this, we introduce a two-stage aggregator that (i) summarizes tokens within each layer and (ii) aggregates across layer summaries to form a single representation for classification. We instantiate this template with direct pooling, a 100K-parameter scoring-attention gate, and a downcast multi-head self-attention (MHA) probe with up to 35M trainable parameters. Across safety and sentiment benchmarks our probes improve over logit-only reuse (e.g., MULI) and are competitive with substantially larger task-specific baselines, while preserving near-serving latency and avoiding the VRAM and latency costs of a separate guard-model pipeline.", "AI": {"tldr": "该研究提出了一种通过训练轻量级探针模型复用大型语言模型（LLM）的计算能力来处理安全和分类任务的新方法，从而避免了额外模型带来的延迟和显存开销。", "motivation": "现有的生产级 LLM 系统通常使用独立的模型来处理安全和分类任务，这导致了延迟增加、显存占用增大以及操作复杂性升高。研究人员希望通过复用 LLM 已有的计算来解决这些问题。", "method": "该方法训练轻量级探针模型，利用 LLM 的隐藏状态来预测标签，并在生成任务的同一次前向传播中完成。它将分类视为对整个 token-layer 隐藏状态张量的表示选择，而非固定 token 或固定层。具体实现上，引入了一个两阶段聚合器，先在层内汇总 token，再跨层汇总以形成单一分类表示。探针模型以直接池化、100K 参数的评分注意力门控以及高达 35M 参数的降维多头自注意力（MHA）探针实例化。", "result": "在安全和情感分析基准测试中，该探针方法优于仅复用 logits 的方法（如 MULI），并且与显著更大的特定任务基线模型相比具有竞争力，同时保持了接近服务的延迟，并避免了独立 guard-model 流水线的显存和延迟成本。", "conclusion": "通过复用 LLM 的计算能力训练轻量级探针模型，可以在不显著增加延迟和显存占用的情况下，有效地执行安全和分类任务，为生产级 LLM 系统提供了一种更高效的解决方案。"}}
{"id": "2601.12533", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12533", "abs": "https://arxiv.org/abs/2601.12533", "authors": ["Md. Ahanaf Arif Khan", "Ariful Islam", "Sangeeta Biswas", "Md. Iqbal Aziz Khan", "Subrata Pramanik", "Sanjoy Kumar Chakrabarty", "Bimal Kumar Pramanik"], "title": "BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images", "comment": null, "summary": "Detecting faces in overhead images remains a significant challenge due to extreme scale variations and environmental clutter. To address this, we created the BirdsEye-RU dataset, a comprehensive collection of 2,978 images containing over eight thousand annotated faces. This dataset is specifically designed to capture small and distant faces across diverse environments, containing both drone images and smartphone-captured images from high altitude. We present a detailed description of the BirdsEye-RU dataset in this paper. We made our dataset freely available to the public, and it can be accessed at https://www.kaggle.com/datasets/mdahanafarifkhan/birdseye-ru.", "AI": {"tldr": "本文介绍了BirdsEye-RU数据集，该数据集包含了2978张包含超过8000个标注人脸的图像，旨在解决无人机和高空拍摄图像中人脸检测的尺度变化和环境干扰问题。", "motivation": "现有的人脸检测技术在处理无人机或高空拍摄的图像时面临巨大挑战，主要是因为人脸尺度变化极大且易受环境干扰。为了改善这一状况，研究者需要一个专门针对此类场景的数据集。", "method": "研究者创建了一个名为BirdsEye-RU的数据集，其中包含2978张图像，标注了超过8000张人脸。这些图像来自无人机和高空智能手机拍摄，覆盖了不同的环境，特别关注了小型和远距离的人脸。", "result": "本文详细描述了BirdsEye-RU数据集的构建和特性。数据集已公开，并提供了访问链接。", "conclusion": "BirdsEye-RU数据集的发布为无人机和高空场景下的人脸检测研究提供了一个重要的资源，有望推动相关技术的进步。"}}
{"id": "2601.13319", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13319", "abs": "https://arxiv.org/abs/2601.13319", "authors": ["Peter Sullivan", "AbdelRahim Elmadany", "Alcides Alcoba Inciarte", "Muhammad Abdul-Mageed"], "title": "Arab Voices: Mapping Standard and Dialectal Arabic Speech Technology", "comment": null, "summary": "Dialectal Arabic (DA) speech data vary widely in domain coverage, dialect labeling practices, and recording conditions, complicating cross-dataset comparison and model evaluation. To characterize this landscape, we conduct a computational analysis of linguistic ``dialectness'' alongside objective proxies of audio quality on the training splits of widely used DA corpora. We find substantial heterogeneity both in acoustic conditions and in the strength and consistency of dialectal signals across datasets, underscoring the need for standardized characterization beyond coarse labels. To reduce fragmentation and support reproducible evaluation, we introduce Arab Voices, a standardized framework for DA ASR. Arab Voices provides unified access to 31 datasets spanning 14 dialects, with harmonized metadata and evaluation utilities. We further benchmark a range of recent ASR systems, establishing strong baselines for modern DA ASR.", "AI": {"tldr": "研究分析了多种阿拉伯方言（DA）语音数据集的语言和音频质量特征，发现其存在显著异质性。为了解决这一问题，研究提出了Arab Voices框架，该框架统一了31个数据集（涵盖14种方言），提供了标准化的元数据和评估工具，并为现代DA ASR系统建立了强基线。", "motivation": "现有阿拉伯方言（DA）语音数据在领域覆盖、方言标注和录制条件等方面存在广泛差异，这给跨数据集比较和模型评估带来了困难。为了解决这种碎片化问题并支持可复现的评估。", "method": "研究人员首先对广泛使用的DA语料库的训练集进行了计算分析，评估了语言上的“方言性”以及音频质量的客观代理指标。然后，他们引入了一个名为Arab Voices的标准化框架，该框架整合了31个数据集（涵盖14种方言），并提供了统一的元数据和评估工具。最后，研究人员对一系列现代DA ASR系统进行了基准测试。", "result": "计算分析发现，在声学条件以及方言信号的强度和一致性方面，不同数据集之间存在显著的异质性。Arab Voices框架成功地统一了31个数据集，并提供了标准化的评估工具。基准测试结果为现代DA ASR系统建立了强大的基线。", "conclusion": "由于DA语音数据的异质性，需要超越粗粒度标签的标准化特征描述。Arab Voices框架的提出为DA ASR的标准化评估和研究提供了支持，并且研究建立的基线有助于推动DA ASR技术的发展。"}}
{"id": "2601.13328", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13328", "abs": "https://arxiv.org/abs/2601.13328", "authors": ["Geoffrey Churchill", "Steven Skiena"], "title": "Reducing Tokenization Premiums for Low-Resource Languages", "comment": null, "summary": "Relative to English, low-resource languages suffer from substantial tokenization premiums in modern LMs, meaning that it generally requires several times as many tokens to encode a sentence in a low-resource language than to encode the analogous sentence in English. This tokenization premium results in increased API and energy costs and reduced effective context windows for these languages. In this paper we analyze the tokenizers of ten popular LMs to better understand their designs and per-language tokenization premiums. We also propose a mechanism to reduce tokenization premiums in pre-trained models, by post-hoc additions to the token vocabulary that coalesce multi-token characters into single tokens. We apply this methodology to 12 low-resource languages, demonstrating that the original and compressed inputs often have similar last hidden states when run through the Llama 3.2 1B model.", "AI": {"tldr": "该研究分析了十种流行语言模型（LM）的标记器，以了解其设计和针对不同语言的标记费用。研究提出了一种通过向现有标记词汇添加新标记来降低低资源语言标记费用的方法，并通过在 Llama 3.2 1B 模型上进行实验验证了该方法的有效性。", "motivation": "低资源语言在现代语言模型中面临着显著的标记费用问题，这导致了更高的成本和更小的有效上下文窗口。研究旨在理解这种现象的原因并提出解决方案。", "method": "研究分析了十种流行语言模型的标记器设计及其每种语言的标记费用。随后，提出了一种通过在预训练模型的标记词汇中添加新标记来压缩多标记字符为单个标记的后处理方法，并将其应用于 12 种低资源语言。", "result": "通过将提出的方法应用于 12 种低资源语言，实验证明，在 Llama 3.2 1B 模型中，压缩后的输入和原始输入通常具有相似的最后一层隐藏状态。", "conclusion": "该研究成功分析了语言模型的标记器特性，并提出了一种有效的后处理方法来降低低资源语言的标记费用，且该方法不会显著影响模型的性能。"}}
{"id": "2601.12682", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12682", "abs": "https://arxiv.org/abs/2601.12682", "authors": ["Banglei Guan", "Dongcai Tan", "Jing Tao", "Ang Su", "Yang Shang", "Qifeng Yu"], "title": "Fusion-Restoration Image Processing Algorithm to Improve the High-Temperature Deformation Measurement", "comment": null, "summary": "In the deformation measurement of high-temperature structures, image degradation caused by thermal radiation and random errors introduced by heat haze restrict the accuracy and effectiveness of deformation measurement. To suppress thermal radiation and heat haze using fusion-restoration image processing methods, thereby improving the accuracy and effectiveness of DIC in the measurement of high-temperature deformation. For image degradation caused by thermal radiation, based on the image layered representation, the image is decomposed into positive and negative channels for parallel processing, and then optimized for quality by multi-exposure image fusion. To counteract the high-frequency, random errors introduced by heat haze, we adopt the FSIM as the objective function to guide the iterative optimization of model parameters, and the grayscale average algorithm is applied to equalize anomalous gray values, thereby reducing measurement error. The proposed multi-exposure image fusion algorithm effectively suppresses image degradation caused by complex illumination conditions, boosting the effective computation area from 26% to 50% for under-exposed images and from 32% to 40% for over-exposed images without degrading measurement accuracy in the experiment. Meanwhile, the image restoration combined with the grayscale average algorithm reduces static thermal deformation measurement errors. The error in ε_xx is reduced by 85.3%, while the errors in ε_yy and γ_xy are reduced by 36.0% and 36.4%, respectively. We present image processing methods to suppress the interference of thermal radiation and heat haze in high-temperature deformation measurement using DIC. The experimental results verify that the proposed method can effectively improve image quality, reduce deformation measurement errors, and has potential application value in thermal deformation measurement.", "AI": {"tldr": "本文提出了一种结合多曝光图像融合和基于FSIM导向的图像恢复方法，以解决高温结构变形测量中热辐射和热畸变引起的图像退化问题，从而提高数字图像相关法（DIC）的测量精度和有效性。", "motivation": "在高温结构变形测量中，热辐射和热畸变（热雾）会严重影响图像质量，导致测量精度下降和有效性受限。", "method": "1.  针对热辐射引起的图像退化，采用图像分层表示，将图像分解为正负通道并行处理，并通过多曝光图像融合优化图像质量。2.  针对热畸变引起的随机误差，采用FSIM作为目标函数指导模型参数的迭代优化，并应用灰度平均算法均衡异常灰度值。", "result": "多曝光图像融合算法将欠曝图像的有效计算区域从26%提升至50%，过曝图像从32%提升至40%，且不影响测量精度。图像恢复结合灰度平均算法显著降低了静态热变形测量的误差，其中ε_xx的误差降低了85.3%，ε_yy和γ_xy的误差分别降低了36.0%和36.4%。", "conclusion": "所提出的图像处理方法能有效抑制热辐射和热畸变对高温变形测量的干扰，提高图像质量，减少测量误差，在热变形测量领域具有潜在的应用价值。"}}
{"id": "2601.13238", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13238", "abs": "https://arxiv.org/abs/2601.13238", "authors": ["Chengyin Hu", "Xiang Chen", "Zhe Jia", "Weiwen Shi", "Fengyu Zhang", "Jiujiang Guo", "Yiwei Wei"], "title": "A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models", "comment": null, "summary": "Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.", "AI": {"tldr": "本文提出了一种基于语义解耦的对抗性框架，通过模拟真实的降雨条件来攻击视觉语言模型（VLMs），揭示了在恶劣天气下VLMs的鲁棒性问题和跨模态语义对齐的不稳定性。", "motivation": "现有研究对VLMs在真实世界天气条件下的鲁棒性以及在这些扰动下跨模态语义对齐的稳定性研究不足，尤其是在雨天场景下。", "method": "提出了一种两阶段的参数化扰动模型。第一阶段通过低维全局调制来削弱原始语义决策边界。第二阶段通过建模多尺度水滴外观和光照变化引入结构化雨水变化，并优化不可微的天气空间以诱导语义偏移。该框架在非像素参数空间操作，生成物理上合理且可解释的扰动。", "result": "即使是物理上可行且受高度约束的天气扰动，也能在主流VLMs中引起显著的语义错位。光照建模和多尺度水滴结构是导致这些语义偏移的关键因素。", "conclusion": "雨天等恶劣天气条件可能对VLMs的可靠性和安全性构成潜在风险，需要进一步研究和改进VLMs在真实世界复杂环境下的鲁棒性。"}}
{"id": "2601.13330", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13330", "abs": "https://arxiv.org/abs/2601.13330", "authors": ["Jamie Cummins", "Beth Clarke", "Ian Hussey", "Malte Elson"], "title": "RegCheck: A tool for automating comparisons between study registrations and papers", "comment": "15 pages, 1 figure", "summary": "Across the social and medical sciences, researchers recognize that specifying planned research activities (i.e., 'registration') prior to the commencement of research has benefits for both the transparency and rigour of science. Despite this, evidence suggests that study registrations frequently go unexamined, minimizing their effectiveness. In a way this is no surprise: manually checking registrations against papers is labour- and time-intensive, requiring careful reading across formats and expertise across domains. The advent of AI unlocks new possibilities in facilitating this activity. We present RegCheck, a modular LLM-assisted tool designed to help researchers, reviewers, and editors from across scientific disciplines compare study registrations with their corresponding papers. Importantly, RegCheck keeps human expertise and judgement in the loop by (i) ensuring that users are the ones who determine which features should be compared, and (ii) presenting the most relevant text associated with each feature to the user, facilitating (rather than replacing) human discrepancy judgements. RegCheck also generates shareable reports with unique RegCheck IDs, enabling them to be easily shared and verified by other users. RegCheck is designed to be adaptable across scientific domains, as well as registration and publication formats. In this paper we provide an overview of the motivation, workflow, and design principles of RegCheck, and we discuss its potential as an extensible infrastructure for reproducible science with an example use case.", "AI": {"tldr": "RegCheck 是一个利用大型语言模型 (LLM) 辅助的工具，旨在帮助研究人员、审稿人和编辑比较研究注册信息与其发表的论文，以提高科学的透明度和严谨性，同时保留人类的判断力。", "motivation": "研究人员认识到在研究开始前进行计划研究活动登记（即“注册”）对科学的透明度和严谨性有益。然而，证据表明研究注册信息经常被忽略，这削弱了其有效性。手动检查注册信息和论文既耗时又费力。AI 的出现为解决这个问题提供了新的可能性。", "method": "RegCheck 是一个模块化的、由 LLM 辅助的工具。它通过 (i) 让用户决定比较哪些特征，以及 (ii) 向用户呈现与每个特征相关的最相关文本，来促进人类的判断，而不是取代它。该工具还生成可共享的报告，并具有独特的 RegCheck ID，方便验证和分享。", "result": "RegCheck 的主要成果是一个能够帮助研究人员、审稿人和编辑比较研究注册信息和论文的工具。该工具旨在保持人类专家在比较过程中的核心作用，并提供可共享和可验证的报告。", "conclusion": "RegCheck 提供了一个可扩展的基础设施，用于可复现的科学研究。该工具的设计原则是适应不同的科学领域和出版格式，并强调通过 AI 辅助增强人类的判断力，以提高科学研究的透明度和严谨性。"}}
{"id": "2601.12697", "categories": ["cs.CV", "cs.CG"], "pdf": "https://arxiv.org/pdf/2601.12697", "abs": "https://arxiv.org/abs/2601.12697", "authors": ["Chao Yang", "Deshui Miao", "Chao Tian", "Guoqing Zhu", "Yameng Gu", "Zhenyu He"], "title": "Fusing in 3D: Free-Viewpoint Fusion Rendering with a 3D Infrared-Visible Scene Representation", "comment": null, "summary": "Infrared-visible image fusion aims to integrate infrared and visible information into a single fused image. Existing 2D fusion methods focus on fusing images from fixed camera viewpoints, neglecting a comprehensive understanding of complex scenarios, which results in the loss of critical information about the scene. To address this limitation, we propose a novel Infrared-Visible Gaussian Fusion (IVGF) framework, which reconstructs scene geometry from multimodal 2D inputs and enables direct rendering of fused images. Specifically, we propose a cross-modal adjustment (CMA) module that modulates the opacity of Gaussians to solve the problem of cross-modal conflicts. Moreover, to preserve the distinctive features from both modalities, we introduce a fusion loss that guides the optimization of CMA, thus ensuring that the fused image retains the critical characteristics of each modality. Comprehensive qualitative and quantitative experiments demonstrate the effectiveness of the proposed method.", "AI": {"tldr": "提出了一种名为红外-可见高斯融合（IVGF）的新型框架，该框架通过重建场景几何来融合红外和可见光图像，从而克服了现有2D方法在复杂场景信息丢失的问题。", "motivation": "现有2D红外-可见图像融合方法通常只考虑固定视角，在复杂场景下会丢失关键信息，因此需要一种能够处理复杂场景并保留更多信息的融合方法。", "method": "提出了一种红外-可见高斯融合（IVGF）框架，该框架首先从多模态2D输入重建场景几何，然后直接渲染融合图像。其中引入了跨模态调整（CMA）模块来解决跨模态冲突，并通过引入融合损失来优化CMA，以保留两种模态的独特性质。", "result": "提出的IVGF方法通过定性和定量实验证明了其有效性。", "conclusion": "IVGF框架能够有效融合红外和可见光图像，并通过重建场景几何和跨模态调整有效保留了两种模态的关键信息，解决了现有2D方法的局限性。"}}
{"id": "2601.13352", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13352", "abs": "https://arxiv.org/abs/2601.13352", "authors": ["Yuxing Lu", "J. Ben Tamo", "Weichen Zhao", "Nan Sun", "Yishan Zhong", "Wenqi Shi", "Jinzhuo Wang", "May D. Wang"], "title": "LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction", "comment": "17 pages, 5 figures, 6 tables", "summary": "Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.", "AI": {"tldr": "提出LLM-as-RNN框架，通过将LLM的隐藏状态表示为自然语言记忆，并实时更新，使其能够进行在线学习和错误纠正，无需参数更新，在多个顺序任务上表现优于现有方法。", "motivation": "标准LLM在生成过程中缺乏可更新的记忆机制，容易在出错后继续犯错。研究旨在解决这个问题，使LLM能够像RNN一样学习和纠正错误。", "method": "将冻结的LLM转化为循环预测器，通过结构化的系统提示（自然语言记忆）来表示隐藏状态。在每个时间步，通过反馈驱动的文本重写来更新该记忆，实现无参数更新的在线学习。", "result": "在医疗、气象和金融三个领域的顺序任务上，LLM-as-RNN显著优于零样本、全历史和MemPrompt基线，平均预测准确率提高了6.5%。", "conclusion": "LLM-as-RNN通过自然语言记忆实现有效的在线学习和错误纠正，能够生成可解释的学习轨迹，并显著提升LLM在顺序任务上的预测性能。"}}
{"id": "2601.13346", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13346", "abs": "https://arxiv.org/abs/2601.13346", "authors": ["Sang Yun Kwon", "AbdelRahim Elmadany", "Muhammad Abdul-Mageed"], "title": "AfroScope: A Framework for Studying the Linguistic Landscape of Africa", "comment": null, "summary": "Language Identification (LID) is the task of determining the language of a given text and is a fundamental preprocessing step that affects the reliability of downstream NLP applications. While recent work has expanded LID coverage for African languages, existing approaches remain limited in (i) the number of supported languages and (ii) their ability to make fine-grained distinctions among closely related varieties. We introduce AfroScope, a unified framework for African LID that includes AfroScope-Data, a dataset covering 713 African languages, and AfroScope-Models, a suite of strong LID models with broad language coverage. To better distinguish highly confusable languages, we propose a hierarchical classification approach that leverages Mirror-Serengeti, a specialized embedding model targeting 29 closely related or geographically proximate languages. This approach improves macro F1 by 4.55 on this confusable subset compared to our best base model. Finally, we analyze cross linguistic transfer and domain effects, offering guidance for building robust African LID systems. We position African LID as an enabling technology for large scale measurement of Africas linguistic landscape in digital text and release AfroScope-Data and AfroScope-Models publicly.", "AI": {"tldr": "该研究提出了AfroScope，一个包含713种非洲语言数据集和强大语言识别模型的统一框架，特别设计了分层分类方法来区分高度混淆的语言，并分析了跨语言迁移和领域效应，旨在促进非洲数字文本的语言识别。", "motivation": "现有非洲语言识别方法在支持的语言数量和区分近亲语言的能力上存在局限性，促使研究者开发更全面、更精细的识别系统。", "method": "研究者构建了AfroScope-Data数据集（包含713种非洲语言），并开发了AfroScope-Models模型。针对易混淆语言，提出了分层分类方法，并使用了专门针对29种近亲或地理邻近语言的嵌入模型Mirror-Serengeti。", "result": "AfroScope-Data和AfroScope-Models提供了广泛的语言覆盖。分层分类方法在易混淆语言子集上将宏观F1分数提高了4.55%，优于基线模型。研究还分析了跨语言迁移和领域效应。", "conclusion": "AfroScope提供了一个强大的非洲语言识别框架，通过大规模数据集和创新的模型设计，能够更精细地识别非洲语言，为理解非洲数字文本的语言格局提供了重要支撑，并将相关资源公开发布。"}}
{"id": "2601.12714", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12714", "abs": "https://arxiv.org/abs/2601.12714", "authors": ["Songlin Dong", "Jiangyang Li", "Chenhao Ding", "Zhiheng Ma", "Haoyu Luo", "Yuhang He", "Yihong Gong"], "title": "P2L-CA: An Effective Parameter Tuning Framework for Rehearsal-Free Multi-Label Class-Incremental Learning", "comment": "12 pages, 5 figures", "summary": "Multi-label Class-Incremental Learning aims to continuously recognize novel categories in complex scenes where multiple objects co-occur. However, existing approaches often incur high computational costs due to full-parameter fine-tuning and substantial storage overhead from memory buffers, or they struggle to address feature confusion and domain discrepancies adequately. To overcome these limitations, we introduce P2L-CA, a parameter-efficient framework that integrates a Prompt-to-Label module with a Continuous Adapter module. The P2L module leverages class-specific prompts to disentangle multi-label representations while incorporating linguistic priors to enforce stable semantic-visual alignment. Meanwhile, the CA module employs lightweight adapters to mitigate domain gaps between pre-trained models and downstream tasks, thereby enhancing model plasticity. Extensive experiments across standard and challenging MLCIL settings on MS-COCO and PASCAL VOC show that P2L-CA not only achieves substantial improvements over state-of-the-art methods but also demonstrates strong generalization in CIL scenarios, all while requiring minimal trainable parameters and eliminating the need for memory buffers.", "AI": {"tldr": "提出了一种名为 P2L-CA 的参数高效框架，用于多标签增量学习（MLCIL），该框架通过类特定的提示和轻量级适配器来解耦表示、解决域漂移并减少计算和存储开销。", "motivation": "现有 MLCIL 方法存在计算成本高、存储开销大、特征混淆和域差异处理不足的问题。", "method": "提出 P2L-CA 框架，包含两个模块：1. Prompt-to-Label (P2L) 模块，利用类特定提示解耦多标签表示，并引入语言先验增强语义-视觉对齐；2. Continuous Adapter (CA) 模块，使用轻量级适配器缩小预训练模型与下游任务之间的域差距，增强模型可塑性。", "result": "在 MS-COCO 和 PASCAL VOC 数据集上进行了广泛实验，P2L-CA 在标准和挑战性 MLCIL 设置下均取得了显著优于现有最先进方法的性能，同时参数量极少且无需内存缓冲区。", "conclusion": "P2L-CA 是一种参数高效的 MLCIL 框架，通过结合提示学习和适配器，有效解决了现有方法的局限性，实现了高性能和低开销，并展现出在 CIL 场景下的强大泛化能力。"}}
{"id": "2601.13166", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13166", "abs": "https://arxiv.org/abs/2601.13166", "authors": ["Pedro M. Gordaliza", "Jaume Banus", "Benoît Gérin", "Maxence Wynen", "Nataliia Molchanova", "Jonas Richiardi", "Meritxell Bach Cuadra"], "title": "From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models", "comment": "Work presented at the SSL3D Challenge (1st place, ResEnc-L track) and FOMO Challenge (1st place, Methods track) on Brain MRI Foundation Models at MICCAI 2025", "summary": "Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.", "AI": {"tldr": "该研究提出了一种基于 U-Net CNN 的脑部 MRI 分析方法，在 MICCAI 2025 的 SSL3D 和 FOMO25 竞赛中均排名第一，并实现了更快的训练速度和更小的模型体积。", "motivation": "开发适用于医学影像分析（特别是放射学任务）的基础模型，以应对 3D 脑部 MRI 分析的独特挑战。", "method": "采用 U-Net CNN 架构，并结合了利用解剖学先验和神经影像学领域知识的策略。", "result": "在 MICCAI 2025 的 SSL3D 和 FOMO25 竞赛中获得第一名。与基于 Transformer 的方法相比，模型的训练速度快 1-2 个数量级，模型体积小 10 倍。", "conclusion": "提出的基于 U-Net CNN 的方法在 3D 脑部 MRI 分析任务中表现出色，实现了更高的效率和更小的模型规模，为开发高效的医学影像基础模型提供了可行方案。"}}
{"id": "2601.13385", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13385", "abs": "https://arxiv.org/abs/2601.13385", "authors": ["Lavsen Dahal", "Yubraj Bhandari", "Geoffrey D. Rubin", "Joseph Y. Lo"], "title": "Organ-Aware Attention Improves CT Triage and Classification", "comment": null, "summary": "There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.", "AI": {"tldr": "本文提出了一种名为ORACLE-CT的新型三维医学影像（CT）分类方法，通过改进的头部设计，在胸部和腹部CT影像的分类任务上取得了先进的性能，优于现有的监督学习基线和零样本视觉语言模型。", "motivation": "高通量的医学影像（如CT）分诊和分类需求迫切，以改善患者护理并缓解放射科医生倦怠。现有的视觉语言模型（VLM）在处理三维解剖结构、协议变化和有噪声的报告监督方面存在困难。", "method": "研究使用了两个最大的公开胸部CT数据集（CT-RATE和RADCHEST-CT）。首先建立了一个经过仔细调整的监督学习基线。在此基础上，提出了ORACLE-CT，一个不依赖于特定编码器、具有器官感知能力的头部，它结合了器官掩码注意力（mask-restricted, per-organ pooling）和器官标量融合（lightweight fusion of normalized volume and mean-HU cues）。", "result": "在胸部CT上，ORACLE-CT的掩码注意力模型在CT-RATE上达到了0.86的AUROC。在腹部CT上，ORACLE-CT的监督基线优于复现的零样本VLM基线，并进一步融合掩码注意力和标量后，性能提升至0.85的AUROC。", "conclusion": "ORACLE-CT通过一种统一的评估协议，在胸部和腹部CT的监督学习分类任务上取得了最先进的性能，解决了现有VLM在处理三维医学影像时的局限性。"}}
{"id": "2601.13359", "categories": ["cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13359", "abs": "https://arxiv.org/abs/2601.13359", "authors": ["Asen Dotsinski", "Panagiotis Eustratiadis"], "title": "Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection", "comment": null, "summary": "As open-weight large language models (LLMs) increase in capabilities, safeguarding them against malicious prompts and understanding possible attack vectors becomes ever more important. While automated jailbreaking methods like GCG [Zou et al., 2023] remain effective, they often require substantial computational resources and specific expertise. We introduce \"sockpuppetting'', a simple method for jailbreaking open-weight LLMs by inserting an acceptance sequence (e.g., \"Sure, here is how to...'') at the start of a model's output and allowing it to complete the response. Requiring only a single line of code and no optimization, sockpuppetting achieves up to 80% higher attack success rate (ASR) than GCG on Qwen3-8B in per-prompt comparisons. We also explore a hybrid approach that optimizes the adversarial suffix within the assistant message block rather than the user prompt, increasing ASR by 64% over GCG on Llama-3.1-8B in a prompt-agnostic setting. The results establish sockpuppetting as an effective low-cost attack accessible to unsophisticated adversaries, highlighting the need for defences against output-prefix injection in open-weight models.", "AI": {"tldr": "本研究提出了一种名为“sockpuppetting”的新型、低成本的LLM越狱方法，通过在模型输出前插入接受序列，显著提高了攻击成功率，并探索了一种混合方法以进一步增强效果。", "motivation": "随着开源大型语言模型（LLM）能力增强，保护它们免受恶意提示和理解潜在攻击向量变得日益重要。现有的自动化越狱方法（如GCG）计算成本高且需要专业知识。", "method": "引入“sockpuppetting”方法，通过在模型输出前插入接受序列（如“Sure, here is how to...”），让模型自行完成其余回复。此外，还探索了一种混合方法，将对抗性后缀优化到助手消息块内，而非用户提示中。", "result": "在Qwen3-8B上，“sockpuppetting”比GCG的攻击成功率高出80%。在Llama-3.1-8B上，混合方法在不考虑具体提示的情况下，比GCG提高了64%的攻击成功率。", "conclusion": "“Sockpuppetting”是一种低成本、易于普通攻击者使用的有效越狱方法，表明需要开发针对开源模型输出前缀注入的防御措施。"}}
{"id": "2601.13368", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13368", "abs": "https://arxiv.org/abs/2601.13368", "authors": ["Zhenjiang Mao", "Anirudhh Venkat"], "title": "Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models", "comment": null, "summary": "As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning sequences by filtering unrelated tokens and examining potential connections between nearby tokens or sentences, the temporal spread of confidence is often overlooked. This oversight can lead to inflated overall confidence, even when earlier steps exhibit very low confidence. To address this issue, we propose a novel method that incorporates inter-step attention to analyze semantic correlations across steps. For handling long-horizon responses, we introduce a hidden confidence mechanism to retain historical confidence information, which is then combined with stepwise confidence to produce a more accurate overall estimate. We evaluate our method on the GAOKAO math benchmark and the CLadder causal reasoning dataset using mainstream open-source large language models. Our approach is shown to outperform state-of-the-art methods by achieving a superior balance between predictive quality and calibration, demonstrated by strong performance on both Negative Log-Likelihood and Expected Calibration Error.", "AI": {"tldr": "提出了一种新方法，通过引入跨步注意力机制和隐藏置信度机制来提高大型语言模型在长推理链中的答案置信度评估，从而克服了现有方法忽略置信度时间传播的问题。", "motivation": "现有的大型语言模型推理模块（如链式思考）在回答问题和解决数学问题方面表现出色，但难以准确评估答案的置信度，这可能导致用户误导或严重的幻觉。现有方法在分析长推理序列时忽略了置信度的时间传播，导致即使早期步骤置信度低，整体置信度也可能被夸大。", "method": "该研究提出了一种新方法，包括：1. 引入跨步注意力（inter-step attention）机制，分析推理步骤之间的语义相关性；2. 引入隐藏置信度（hidden confidence）机制，以保留历史置信度信息，并将其与分步置信度结合，以产生更准确的整体置信度估计，特别适用于长推理响应。", "result": "在GAOKAO数学基准和CLadder因果推理数据集上，使用主流开源大型语言模型进行的评估表明，该方法优于现有最先进的方法，在预测质量和校准方面取得了更好的平衡，体现在负对数似然（NLL）和期望校准误差（ECE）上的出色表现。", "conclusion": "提出的基于跨步注意力和隐藏置信度的新方法能够更准确地评估大型语言模型在长推理过程中的答案置信度，解决了现有方法忽略置信度时间传播的问题，并显著提高了模型在预测质量和校准方面的性能。"}}
{"id": "2601.13392", "categories": ["cs.CL", "cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2601.13392", "abs": "https://arxiv.org/abs/2601.13392", "authors": ["Shlok Shelat", "Jay Raval", "Souvik Roy", "Manas Gaur"], "title": "Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks", "comment": "30 pages, 11 figures, 6 tables, Work in Progress", "summary": "Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.", "AI": {"tldr": "本研究引入了一个用于从正则表达式构建确定性有限自动机 (DFA) 的基准测试，以评估大型语言模型 (LLM) 的符号推理能力。研究发现，LLM 在熟悉的问题上表现良好，但在处理新颖、复杂的问题时，准确率显著下降，并且在不同提示策略下问题依然存在，暴露了其在形式化推理方面的根本性不足。", "motivation": "研究的动机是探究大型语言模型 (LLM) 在形式语言任务上的优异表现是源于真正的符号推理还是仅仅基于模式匹配，尤其是对于构造 DFA 这样需要形式化推理的任务。", "method": "研究构建了一个包含事实知识问题、已见构建问题和两种类型未见问题（手工制作的多约束实例和基于 Arden 定理生成的系统化问题）的 DFA 构建基准测试。评估了多种提示策略（直接、链式思考、树状思考）和一种三阶段提示协议。", "result": "LLM 在事实知识问题上达到完美准确率，在已见问题上准确率在 84-90%。然而，在未见问题上准确率急剧下降（30-64%），失败原因包括对语言约束的系统性误解、Kleene 星号语义处理不当以及未能保持全局一致性。提示协议仅能纠正浅层错误，无法解决全局不一致或结构性缺陷。", "conclusion": "LLM 在生成语法上合理的 DFA 与其进行语义上正确的形式化推理的能力之间存在根本性差距。即使采用了不同的提示策略，LLM 在处理未见的、需要深层形式化推理的 DFA 构建任务时仍会遇到困难。"}}
{"id": "2601.12736", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12736", "abs": "https://arxiv.org/abs/2601.12736", "authors": ["Qingtian Zhu", "Xu Cao", "Zhixiang Wang", "Yinqiang Zheng", "Takafumi Taketomi"], "title": "KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction", "comment": null, "summary": "We propose KaoLRM to re-target the learned prior of the Large Reconstruction Model (LRM) for parametric 3D face reconstruction from single-view images. Parametric 3D Morphable Models (3DMMs) have been widely used for facial reconstruction due to their compact and interpretable parameterization, yet existing 3DMM regressors often exhibit poor consistency across varying viewpoints. To address this, we harness the pre-trained 3D prior of LRM and incorporate FLAME-based 2D Gaussian Splatting into LRM's rendering pipeline. Specifically, KaoLRM projects LRM's pre-trained triplane features into the FLAME parameter space to recover geometry, and models appearance via 2D Gaussian primitives that are tightly coupled to the FLAME mesh. The rich prior enables the FLAME regressor to be aware of the 3D structure, leading to accurate and robust reconstructions under self-occlusions and diverse viewpoints. Experiments on both controlled and in-the-wild benchmarks demonstrate that KaoLRM achieves superior reconstruction accuracy and cross-view consistency, while existing methods remain sensitive to viewpoint variations. The code is released at https://github.com/CyberAgentAILab/KaoLRM.", "AI": {"tldr": "KaoLRM 是一种新的方法，通过利用大型重建模型 (LRM) 的预训练 3D 先验，并结合基于 FLAME 的 2D 高斯泼溅技术，来改进从单视图图像进行参数化 3D 面部重建。它通过将 LRM 的特征投影到 FLAME 参数空间来恢复几何，并通过与 FLAME 网格紧密耦合的 2D 高斯图元来建模外观，从而在自遮挡和不同视角下实现更准确、更稳健的重建。", "motivation": "现有的 3DMM 回归器在不同视角下的一致性较差，尤其是在处理自遮挡和视角变化的情况下。研究人员希望利用大型重建模型 (LRM) 中强大的 3D 先验来解决这个问题。", "method": "KaoLRM 采用了一种新颖的方法：1. 将 LRM 的预训练三平面特征投影到 FLAME 参数空间，以恢复 3D 面部几何。2. 通过与 FLAME 网格紧密耦合的 2D 高斯图元来建模面部外观。3. 将基于 FLAME 的 2D 高斯泼溅技术集成到 LRM 的渲染流程中。", "result": "KaoLRM 在受控和真实场景的基准测试中均取得了优于现有方法的重建准确性和跨视角一致性。现有方法在视角变化方面仍然很敏感，而 KaoLRM 则表现出鲁棒性。", "conclusion": "KaoLRM 能够有效地重新利用 LRM 的预训练 3D 先验，并通过集成 FLAME 的 2D 高斯泼溅技术，显著提高了参数化 3D 面部重建在不同视角和存在自遮挡情况下的准确性和一致性。"}}
{"id": "2601.13400", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13400", "abs": "https://arxiv.org/abs/2601.13400", "authors": ["Nhat Thanh Tran", "Kevin Bui", "Jack Xin"], "title": "Deep Image Prior with L0 Gradient Regularizer for Image Smoothing", "comment": "To be published in the Proceedings of IEEE ICASSP 2026", "summary": "Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\\ell_0$, a deep image prior framework that incorporates the $\\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\\ell_0$ ``norm\", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.13387", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13387", "abs": "https://arxiv.org/abs/2601.13387", "authors": ["Zhenjiang Mao", "Anirudhh Venkat", "Artem Bisliouk", "Akshat Kothiyal", "Sindhura Kumbakonam Subramanian", "Saithej Singhu", "Ivan Ruchkin"], "title": "Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning", "comment": null, "summary": "Large Language Models (LLMs) increasingly rely on long-form, multi-step reasoning to solve complex tasks such as mathematical problem solving and scientific question answering. Despite strong performance, existing confidence estimation methods typically reduce an entire reasoning process to a single scalar score, ignoring how confidence evolves throughout the generation. As a result, these methods are often sensitive to superficial factors such as response length or verbosity, and struggle to distinguish correct reasoning from confidently stated errors. We propose to characterize the stepwise confidence signal using Signal Temporal Logic (STL). Using a discriminative STL mining procedure, we discover temporal formulas that distinguish confidence signals of correct and incorrect responses. Our analysis found that the STL patterns generalize across tasks, and numeric parameters exhibit sensitivity to individual questions. Based on these insights, we develop a confidence estimation approach that informs STL blocks with parameter hypernetworks. Experiments on multiple reasoning tasks show our confidence scores are more calibrated than the baselines.", "AI": {"tldr": "该研究提出了一种新的方法来估计大型语言模型（LLMs）在多步推理任务中的置信度，通过利用信号时序逻辑（STL）来捕捉推理过程中的置信度变化，并取得了比现有方法更准确的置信度评分。", "motivation": "现有的LLM置信度估计方法通常将整个推理过程简化为一个单一的分数，忽略了推理过程中置信度的动态变化，这导致它们容易受到响应长度等表面因素的影响，并难以区分正确推理和自信的错误。", "method": "研究人员提出使用信号时序逻辑（STL）来表征逐步置信度信号。通过判别性的STL挖掘程序，他们发现了区分正确和错误响应置信度信号的时序公式。在此基础上，他们开发了一种将STL模块与参数超网络相结合的置信度估计方法。", "result": "研究发现，STL模式在不同任务之间具有泛化性，而数值参数对具体问题表现出敏感性。实验结果表明，他们提出的置信度评分比基线方法更准确。", "conclusion": "通过利用STL捕捉推理过程中的置信度动态，并结合参数超网络进行优化，可以开发出更鲁棒、更准确的LLM置信度估计方法，从而更好地评估模型在复杂推理任务中的表现。"}}
{"id": "2601.12747", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12747", "abs": "https://arxiv.org/abs/2601.12747", "authors": ["Jingkai Li", "Xiaoze Tian", "Yuhang Shen", "Jia Wang", "Dianjie Lu", "Guijuan Zhang", "Zhuoran Zheng"], "title": "SSPFormer: Self-Supervised Pretrained Transformer for MRI Images", "comment": "Undergraduate student as first author submitted to IJCAI", "summary": "The pre-trained transformer demonstrates remarkable generalization ability in natural image processing. However, directly transferring it to magnetic resonance images faces two key challenges: the inability to adapt to the specificity of medical anatomical structures and the limitations brought about by the privacy and scarcity of medical data. To address these issues, this paper proposes a Self-Supervised Pretrained Transformer (SSPFormer) for MRI images, which effectively learns domain-specific feature representations of medical images by leveraging unlabeled raw imaging data. To tackle the domain gap and data scarcity, we introduce inverse frequency projection masking, which prioritizes the reconstruction of high-frequency anatomical regions to enforce structure-aware representation learning. Simultaneously, to enhance robustness against real-world MRI artifacts, we employ frequency-weighted FFT noise enhancement that injects physiologically realistic noise into the Fourier domain. Together, these strategies enable the model to learn domain-invariant and artifact-robust features directly from raw scans. Through extensive experiments on segmentation, super-resolution, and denoising tasks, the proposed SSPFormer achieves state-of-the-art performance, fully verifying its ability to capture fine-grained MRI image fidelity and adapt to clinical application requirements.", "AI": {"tldr": "提出了一种用于MRI图像的自监督预训练Transformer（SSPFormer），通过逆频率投影掩码和频率加权FFT噪声增强，解决了医学图像领域差异和数据稀缺的问题，并在分割、超分辨率和去噪任务中取得了最先进的性能。", "motivation": "现有预训练Transformer难以直接应用于MRI图像，面临医学解剖结构特异性和医疗数据隐私稀缺的挑战。", "method": "提出SSPFormer，采用逆频率投影掩码（优先重构高频解剖区域）和频率加权FFT噪声增强（在傅里叶域注入生理噪声），以学习领域特定、领域不变且抗伪影的特征。", "result": "在分割、超分辨率和去噪任务上，SSPFormer实现了最先进的性能，证明了其捕获MRI图像细节和适应临床应用需求的能力。", "conclusion": "SSPFormer能够有效地从原始MRI扫描中学习领域不变且抗伪影的特征，克服了领域差距和数据稀缺的限制，在多种MRI图像任务中表现出色。"}}
{"id": "2601.13401", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13401", "abs": "https://arxiv.org/abs/2601.13401", "authors": ["Peter A. Massih", "Eric Cosatto"], "title": "Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics", "comment": "Submitted to CVPR 2026. Introduces the QVLM architecture and the SQuID dataset for quantitative geospatial reasoning. Dataset DOI: 10.57967/hf/7565", "summary": "Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.", "AI": {"tldr": "本文提出了一种名为QVLM的新型视觉语言模型架构，通过代码生成来解决现有VLM在定量空间推理方面的不足，并引入了SQuID数据集用于评估。", "motivation": "现有的视觉语言模型（VLMs）在处理定量空间推理任务时表现不佳，因为它们的架构（如图像编码器中的patch embedding）会丢失像素级别的信息，而这些信息对于计数和测量至关重要。", "method": "1. 提出了SQuID（Satellite Quantitative Intelligence Dataset）数据集，包含2000个卫星图像问答对，用于评估定量空间推理能力，分为三个难度等级。2. 设计了QVLM（Quantitative Vision-Language Model）架构，采用代码生成的方式，将语言理解与视觉分析解耦。QVLM不直接对图像进行编码，而是生成可执行代码，先调用分割模型获取像素级掩码，然后直接在这些掩码上进行操作，从而保持了像素级别的空间信息。", "result": "在SQuID数据集上，使用GPT-5作为代码生成器的QVLM达到了42.0%的准确率，而直接使用图像-问题对提示的VLM准确率为28.1%。", "conclusion": "对于定量空间推理任务，采用架构解耦（如QVLM所示）能够比现有VLM架构取得更好的准确率，因为它能有效保留像素级别的空间信息。"}}
{"id": "2601.13388", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13388", "abs": "https://arxiv.org/abs/2601.13388", "authors": ["Sasha Ronaghi", "Prerit Choudhary", "David H Rehkopf", "Bryant Lin"], "title": "Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction", "comment": "7 pages, 5 figures", "summary": "Social determinants of health (SDOH) play a critical role in Type 2 Diabetes (T2D) management but are often absent from electronic health records and risk prediction models. Most individual-level SDOH data is collected through structured screening tools, which lack the flexibility to capture the complexity of patient experiences and unique needs of a clinic's population. This study explores the use of large language models (LLMs) to extract structured SDOH information from unstructured patient life stories and evaluate the predictive value of both the extracted features and the narratives themselves for assessing diabetes control. We collected unstructured interviews from 65 T2D patients aged 65 and older, focused on their lived experiences, social context, and diabetes management. These narratives were analyzed using LLMs with retrieval-augmented generation to produce concise, actionable qualitative summaries for clinical interpretation and structured quantitative SDOH ratings for risk prediction modeling. The structured SDOH ratings were used independently and in combination with traditional laboratory biomarkers as inputs to linear and tree-based machine learning models (Ridge, Lasso, Random Forest, and XGBoost) to demonstrate how unstructured narrative data can be applied in conventional risk prediction workflows. Finally, we evaluated several LLMs on their ability to predict a patient's level of diabetes control (low, medium, high) directly from interview text with A1C values redacted. LLMs achieved 60% accuracy in predicting diabetes control levels from interview text. This work demonstrates how LLMs can translate unstructured SDOH-related data into structured insights, offering a scalable approach to augment clinical risk models and decision-making.", "AI": {"tldr": "该研究利用大型语言模型（LLMs）从非结构化的糖尿病患者访谈记录中提取社会决定因素（SDOH）信息，并评估这些信息以及原始叙述对预测糖尿病控制水平的价值。", "motivation": "现有的电子健康记录和风险预测模型通常缺乏关键的社会决定因素（SDOH）信息，而这些信息对2型糖尿病（T2D）的管理至关重要。传统的SDOH数据收集方式（如结构化筛查工具）不够灵活，无法捕捉患者经历的复杂性和特定人群的需求。", "method": "研究收集了65名65岁及以上的2型糖尿病患者关于其生活经历、社会背景和糖尿病管理的非结构化访谈记录。利用检索增强生成（RAG）技术，采用大型语言模型（LLMs）对这些叙述进行分析，生成了用于临床解释的定性摘要和用于风险预测建模的结构化定量SDOH评分。然后，将结构化SDOH评分与传统的实验室生物标志物结合，输入到线性模型（Ridge, Lasso）和基于树的模型（Random Forest, XGBoost）中进行风险预测。此外，还评估了LLMs直接从访谈文本（隐去A1C值）预测糖尿病控制水平（低、中、高）的能力。", "result": "大型语言模型（LLMs）在直接从访谈文本预测糖尿病控制水平方面取得了60%的准确率。研究表明，SDOH评分在与传统生物标志物结合时，能够增强风险预测模型的性能。", "conclusion": "大型语言模型（LLMs）能够有效地将非结构化的SDOH相关数据转化为结构化洞见，为增强临床风险模型和决策提供了一种可扩展的方法。这为在传统风险预测流程中融入叙述性数据开辟了新的途径。"}}
{"id": "2601.12761", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12761", "abs": "https://arxiv.org/abs/2601.12761", "authors": ["Tianqi Zhang", "Ziyi Wang", "Wenzhao Zheng", "Weiliang Chen", "Yuanhui Huang", "Zhengyang Huang", "Jie Zhou", "Jiwen Lu"], "title": "Moaw: Unleashing Motion Awareness for Video Diffusion Models", "comment": null, "summary": "Video diffusion models, trained on large-scale datasets, naturally capture correspondences of shared features across frames. Recent works have exploited this property for tasks such as optical flow prediction and tracking in a zero-shot setting. Motivated by these findings, we investigate whether supervised training can more fully harness the tracking capability of video diffusion models. To this end, we propose Moaw, a framework that unleashes motion awareness for video diffusion models and leverages it to facilitate motion transfer. Specifically, we train a diffusion model for motion perception, shifting its modality from image-to-video generation to video-to-dense-tracking. We then construct a motion-labeled dataset to identify features that encode the strongest motion information, and inject them into a structurally identical video generation model. Owing to the homogeneity between the two networks, these features can be naturally adapted in a zero-shot manner, enabling motion transfer without additional adapters. Our work provides a new paradigm for bridging generative modeling and motion understanding, paving the way for more unified and controllable video learning frameworks.", "AI": {"tldr": "本文提出了Moaw框架，通过监督学习增强视频扩散模型在运动感知和运动迁移方面的能力，实现了视频生成模型与运动理解的统一。", "motivation": "现有研究表明视频扩散模型能够捕捉帧间的特征对应，可用于零样本光流预测和跟踪。本文旨在探索监督训练是否能进一步发掘视频扩散模型的跟踪能力，并将其应用于运动迁移。", "method": "1. 训练一个用于运动感知的扩散模型，使其从图像到视频生成转变为视频到密集跟踪。2. 构建一个运动标注数据集，识别编码最强运动信息的特征。3. 将这些特征注入到一个结构相同的视频生成模型中，利用模型间的同质性实现零样本运动迁移，无需额外适配器。", "result": "通过监督训练，Moaw框架能够更充分地利用视频扩散模型的运动感知能力，实现有效的运动迁移。", "conclusion": "本文提出了一种将生成模型与运动理解相结合的新范式，为更统一、可控的视频学习框架提供了可能，并展示了Moaw在运动迁移任务上的潜力。"}}
{"id": "2601.13404", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13404", "abs": "https://arxiv.org/abs/2601.13404", "authors": ["Bhavan Vasu", "Giuseppe Raffa", "Prasad Tadepalli"], "title": "Local-to-Global Logical Explanations for Deep Vision Models", "comment": "15 pages, 5 figures, 5th International Joint Conference on Learning & Reasoning 2025", "summary": "While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability we show that the explanations maintain high fidelity and coverage with respect to the blackbox models they seek to explain in challenging vision datasets.", "AI": {"tldr": "提出了一种用于黑盒模型（特别是图像分类）的局部和全局解释方法，将解释表示为易于理解的原始概念的逻辑公式（MDNF），并证明了其高保真度和覆盖率。", "motivation": "深度神经网络在图像分类方面非常有效，但缺乏透明度且难以解释。研究的动机是为这些“黑盒”模型提供可解释的解释。", "method": "将局部和全局解释问题都转化为寻找满足特定类别的模型的高分数的逻辑公式（单调析取范式，MDNF）。开发了一种算法来生成多类分类的单调解释列表。", "result": "提出的解释方法（MDNF公式和单调解释列表）即使在具有挑战性的视觉数据集上，也能保持对黑盒模型的高保真度和覆盖率，同时保持了简单性和可解释性。", "conclusion": "通过将解释表示为人类可识别的原始概念的逻辑公式，可以有效地解释黑盒模型（如深度神经网络）的图像分类行为，同时保持高准确性和覆盖率。"}}
{"id": "2601.12719", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12719", "abs": "https://arxiv.org/abs/2601.12719", "authors": ["Lin Zhao", "Yushu Wu", "Aleksei Lebedev", "Dishani Lahiri", "Meng Dong", "Arpit Sahni", "Michael Vasilkovsky", "Hao Chen", "Ju Hu", "Aliaksandr Siarohin", "Sergey Tulyakov", "Yanzhi Wang", "Anil Kag", "Yanyu Li"], "title": "S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation", "comment": null, "summary": "Diffusion Transformers (DiTs) have recently improved video generation quality. However, their heavy computational cost makes real-time or on-device generation infeasible. In this work, we introduce S2DiT, a Streaming Sandwich Diffusion Transformer designed for efficient, high-fidelity, and streaming video generation on mobile hardware. S2DiT generates more tokens but maintains efficiency with novel efficient attentions: a mixture of LinConv Hybrid Attention (LCHA) and Stride Self-Attention (SSA). Based on this, we uncover the sandwich design via a budget-aware dynamic programming search, achieving superior quality and efficiency. We further propose a 2-in-1 distillation framework that transfers the capacity of large teacher models (e.g., Wan 2.2-14B) to the compact few-step sandwich model. Together, S2DiT achieves quality on par with state-of-the-art server video models, while streaming at over 10 FPS on an iPhone.", "AI": {"tldr": "S2DiT 是一种流式三明治扩散 Transformer，通过混合 LinConv 混合注意力 (LCHA) 和步进自注意力 (SSA) 以及预算感知动态规划搜索，实现了高效、高质量且适用于移动设备的视频生成，并在 iPhone 上实现了超过 10 FPS 的流式传输。", "motivation": "现有的 Diffusion Transformers (DiTs) 在视频生成质量上有所提升，但其高昂的计算成本阻碍了在移动设备上实现实时生成。", "method": "S2DiT 采用流式三明治设计，引入了 LinConv Hybrid Attention (LCHA) 和 Stride Self-Attention (SSA) 两种高效注意力机制来处理更多 token 并保持效率。通过预算感知动态规划搜索确定了最佳的三明治结构。此外，还设计了一个 2-in-1 蒸馏框架，将大型教师模型的性能迁移到紧凑型模型。", "result": "S2DiT 实现了与最先进的服务器级视频模型相当的生成质量，并且在 iPhone 上实现了超过 10 FPS 的流式传输速度。", "conclusion": "S2DiT 成功地解决了 DiTs 的计算成本问题，实现了在移动设备上进行高效、高质量且流式的视频生成，并达到了接近 SOTA 的性能。"}}
{"id": "2601.13433", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13433", "abs": "https://arxiv.org/abs/2601.13433", "authors": ["Priyanka Mary Mammen", "Emil Joswin", "Shankar Venkitachalam"], "title": "Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models", "comment": null, "summary": "Prior research demonstrates that performance of language models on reasoning tasks can be influenced by suggestions, hints and endorsements. However, the influence of endorsement source credibility remains underexplored. We investigate whether language models exhibit systematic bias based on the perceived expertise of the provider of the endorsement. Across 4 datasets spanning mathematical, legal, and medical reasoning, we evaluate 11 models using personas representing four expertise levels per domain. Our results reveal that models are increasingly susceptible to incorrect/misleading endorsements as source expertise increases, with higher-authority sources inducing not only accuracy degradation but also increased confidence in wrong answers. We also show that this authority bias is mechanistically encoded within the model and a model can be steered away from the bias, thereby improving its performance even when an expert gives a misleading endorsement.", "AI": {"tldr": "研究表明，语言模型在处理推理任务时，会受到推荐来源可信度的影响，尤其是在面对错误或误导性信息时，模型会更加依赖于高权威来源的推荐，从而导致性能下降和置信度增加。研究还发现，这种权威偏差可以通过调整模型来缓解。", "motivation": "尽管先前的研究表明建议、提示和背书会影响语言模型在推理任务上的表现，但对背书来源可信度的影响研究不足，因此需要探究语言模型是否会因背书者感知的专业知识而产生系统性偏差。", "method": "研究者在涵盖数学、法律和医学推理的4个数据集上，使用了代表各领域四种专业知识水平的“人格”来评估11种模型。通过分析模型在不同来源可信度下的表现来评估权威偏差，并尝试通过调整模型来消除偏差。", "result": "结果显示，模型对错误/误导性背书的易感性随着来源专业知识的增加而增强。高权威来源不仅会降低模型的准确性，还会增加模型对错误答案的置信度。此外，研究证明了这种权威偏差在模型内部被编码，并且可以通过引导模型来克服这种偏差，从而提高其在面对专家误导性背书时的性能。", "conclusion": "语言模型存在权威偏差，它们更容易被具有更高专业知识的来源所误导，并且这种偏差可以在模型内部进行干预和纠正，从而提升模型的鲁棒性和准确性。"}}
{"id": "2601.12765", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12765", "abs": "https://arxiv.org/abs/2601.12765", "authors": ["Zhi Cai", "Yingjie Gao", "Yanan Zhang", "Xinzhu Ma", "Di Huang"], "title": "Towards Unbiased Source-Free Object Detection via Vision Foundation Models", "comment": null, "summary": "Source-Free Object Detection (SFOD) has garnered much attention in recent years by eliminating the need of source-domain data in cross-domain tasks, but existing SFOD methods suffer from the Source Bias problem, i.e. the adapted model remains skewed towards the source domain, leading to poor generalization and error accumulation during self-training. To overcome this challenge, we propose Debiased Source-free Object Detection (DSOD), a novel VFM-assisted SFOD framework that can effectively mitigate source bias with the help of powerful VFMs. Specifically, we propose Unified Feature Injection (UFI) module that integrates VFM features into the CNN backbone through Simple-Scale Extension (SSE) and Domain-aware Adaptive Weighting (DAAW). Then, we propose Semantic-aware Feature Regularization (SAFR) that constrains feature learning to prevent overfitting to source domain characteristics. Furthermore, we propose a VFM-free variant, termed DSOD-distill for computation-restricted scenarios through a novel Dual-Teacher distillation scheme. Extensive experiments on multiple benchmarks demonstrate that DSOD outperforms state-of-the-art SFOD methods, achieving 48.1% AP on Normal-to-Foggy weather adaptation, 39.3% AP on Cross-scene adaptation, and 61.4% AP on Synthetic-to-Real adaptation.", "AI": {"tldr": "提出了一种名为DSOD的新型源领域无关物体检测框架，通过利用视觉语言模型（VFM）的强大能力来解决现有方法中存在的源领域偏见问题，并提出了两种变体以适应不同计算资源的需求。", "motivation": "现有源领域无关物体检测（SFOD）方法存在源领域偏见问题，导致模型泛化能力差且在自训练过程中累积误差。", "method": "提出了DSOD框架，包括：1. 统一特征注入（UFI）模块，通过简单尺度扩展（SSE）和领域感知自适应加权（DAAW）将VFM特征融入CNN骨干网络。2. 语义感知特征正则化（SAFR）来约束特征学习，防止过拟合到源领域特征。3. 提出了一个无VFM的变体DSOD-distill，通过双教师蒸馏方案解决计算资源受限的问题。", "result": "DSOD在多个基准测试中取得了最先进的性能，在Normal-to-Foggy天气适应性任务上达到48.1% AP，在Cross-scene适应性任务上达到39.3% AP，在Synthetic-to-Real适应性任务上达到61.4% AP。", "conclusion": "DSOD框架能够有效缓解源领域偏见问题，通过VFM增强了SFOD的性能，并且其变体DSOD-distill在计算资源受限的情况下也能取得良好效果。"}}
{"id": "2601.12672", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12672", "abs": "https://arxiv.org/abs/2601.12672", "authors": ["Qimao Chen", "Fang Li", "Shaoqing Xu", "Zhiyi Lai", "Zixun Xie", "Yuechen Luo", "Shengyin Jiang", "Hanbing Li", "Long Chen", "Bing Wang", "Yi Zhang", "Zhi-Xin Yang"], "title": "VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness", "comment": "Accepted to AAAI 2026", "summary": "The safe deployment of autonomous driving (AD) systems is fundamentally hindered by the long-tail problem, where rare yet critical driving scenarios are severely underrepresented in real-world data. Existing solutions including safety-critical scenario generation and closed-loop learning often rely on rule-based heuristics, resampling methods and generative models learned from offline datasets, limiting their ability to produce diverse and novel challenges. While recent works leverage Vision Language Models (VLMs) to produce scene descriptions that guide a separate, downstream model in generating hazardous trajectories for agents, such two-stage framework constrains the generative potential of VLMs, as the diversity of the final trajectories is ultimately limited by the generalization ceiling of the downstream algorithm. To overcome these limitations, we introduce VILTA (VLM-In-the-Loop Trajectory Adversary), a novel framework that integrates a VLM into the closed-loop training of AD agents. Unlike prior works, VILTA actively participates in the training loop by comprehending the dynamic driving environment and strategically generating challenging scenarios through direct, fine-grained editing of surrounding agents' future trajectories. This direct-editing approach fully leverages the VLM's powerful generalization capabilities to create a diverse curriculum of plausible yet challenging scenarios that extend beyond the scope of traditional methods. We demonstrate that our approach substantially enhances the safety and robustness of the resulting AD policy, particularly in its ability to navigate critical long-tail events.", "AI": {"tldr": "提出了一种名为VILTA的新框架，将视觉语言模型（VLM）集成到自动驾驶（AD）的闭环训练中，通过直接编辑周围代理的轨迹来生成具有挑战性的场景，从而提高AD系统的安全性和鲁棒性，尤其是在长尾场景下。", "motivation": "现有的自动驾驶安全部署方法（如场景生成和闭环学习）在处理长尾问题时存在局限性，难以生成多样化且新颖的危险场景，因为它们依赖于基于规则的启发式方法、重采样或仅从离线数据中学习的生成模型。", "method": "VILTA框架将VLM直接集成到AD代理的闭环训练过程中。VLM能够理解动态驾驶环境，并通过直接、细粒度地编辑周围代理的未来轨迹来生成挑战性场景。", "result": "与现有方法相比，VILTA显著提高了AD策略的安全性和鲁棒性，尤其是在应对关键的长尾事件方面。", "conclusion": "VILTA通过充分利用VLM的泛化能力，直接生成多样化、合理的且具有挑战性的场景，克服了现有方法的局限性，有效地提升了自动驾驶系统的安全性和应对长尾场景的能力。"}}
{"id": "2601.13437", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13437", "abs": "https://arxiv.org/abs/2601.13437", "authors": ["Adriana-Valentina Costache", "Daria-Nicoleta Dragomir", "Silviu-Florin Gheorghe", "Eduard Poesina", "Paul Irofti", "Radu Tudor Ionescu"], "title": "MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization", "comment": null, "summary": "Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.", "AI": {"tldr": "本文提出了首个针对文本分类的多语言开放集学习与发现（MOSLD）基准，包含12种语言的960K样本。同时，作者提出了一种新颖的框架来处理此任务，并提供了现有语言模型的评估结果作为参考。", "motivation": "开放集学习与发现（OSLD）任务在测试时可能出现未知类别的样本，在文本领域的研究相对较少，尤其是在多语言场景下。作者旨在构建一个多语言基准并提出一个新框架来推动该领域的研究。", "method": "构建了一个包含960K样本、12种语言的多语言开放集学习与发现（MOSLD）基准，通过重排现有数据集和收集新闻领域新样本来完成。提出了一个多阶段的框架，用于持续发现和学习新类别。评估了包括自研模型在内的多种语言模型。", "result": "构建并发布了MOSLD基准。提出的框架在MOSLD基准上进行了评估，并提供了多种语言模型的参考结果。", "conclusion": "MOSLD基准的提出填补了多语言文本开放集学习与发现领域的空白。提出的新框架为解决该任务提供了一种可行的方法，并为未来的研究提供了基线结果。"}}
{"id": "2601.12768", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.12768", "abs": "https://arxiv.org/abs/2601.12768", "authors": ["Zequn Xie", "Boyun Zhang", "Yuxiao Lin", "Tao Jin"], "title": "Delving Deeper: Hierarchical Visual Perception for Robust Video-Text Retrieval", "comment": null, "summary": "Video-text retrieval (VTR) aims to locate relevant videos using natural language queries. Current methods, often based on pre-trained models like CLIP, are hindered by video's inherent redundancy and their reliance on coarse, final-layer features, limiting matching accuracy. To address this, we introduce the HVP-Net (Hierarchical Visual Perception Network), a framework that mines richer video semantics by extracting and refining features from multiple intermediate layers of a vision encoder. Our approach progressively distills salient visual concepts from raw patch-tokens at different semantic levels, mitigating redundancy while preserving crucial details for alignment. This results in a more robust video representation, leading to new state-of-the-art performance on challenging benchmarks including MSRVTT, DiDeMo, and ActivityNet. Our work validates the effectiveness of exploiting hierarchical features for advancing video-text retrieval. Our codes are available at https://github.com/boyun-zhang/HVP-Net.", "AI": {"tldr": "提出了一种名为 HVP-Net 的视频-文本检索框架，通过利用视觉编码器多中间层的分层特征来提升检索精度，并在多个基准测试中取得了最先进的性能。", "motivation": "现有的视频-文本检索方法（常基于 CLIP 等预训练模型）受视频固有的冗余性以及仅依赖粗粒度、最终层特征的限制，导致匹配精度不高。", "method": "HVP-Net 框架通过从视觉编码器的多个中间层提取和精炼特征，逐步提炼出不同语义层级的视觉概念，从而缓解冗余并保留关键细节，生成更鲁棒的视频表示。", "result": "在 MSRVTT、DiDeMo 和 ActivityNet 等具有挑战性的基准测试中，HVP-Net 取得了新的最先进性能。", "conclusion": "利用分层视觉特征能够有效提升视频-文本检索的性能，并验证了该方法在解决视频冗余和提取丰富语义方面的有效性。"}}
{"id": "2601.12770", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12770", "abs": "https://arxiv.org/abs/2601.12770", "authors": ["Shuling Zhao", "Dan Xu"], "title": "Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image", "comment": "Project page: https://shaelynz.github.io/fhavatar/", "summary": "Building 3D animatable head avatars from a single image is an important yet challenging problem. Existing methods generally collapse under large camera pose variations, compromising the realism of 3D avatars. In this work, we propose a new framework to tackle the novel setting of one-shot 3D full-head animatable avatar reconstruction in a single feed-forward pass, enabling real-time animation and simultaneous 360$^\\circ$ rendering views. To facilitate efficient animation control, we model 3D head avatars with Gaussian primitives embedded on the surface of a parametric face model within the UV space. To obtain knowledge of full-head geometry and textures, we leverage rich 3D full-head priors within a pretrained 3D generative adversarial network (GAN) for global full-head feature extraction and multi-view supervision. To increase the fidelity of the 3D reconstruction of the input image, we take advantage of the symmetric nature of the UV space and human faces to fuse local fine-grained input image features with the global full-head textures. Extensive experiments demonstrate the effectiveness of our method, achieving high-quality 3D full-head modeling as well as real-time animation, thereby improving the realism of 3D talking avatars.", "AI": {"tldr": "提出了一种从单张图像重建可动画3D全头头像的新框架，能够进行实时动画和多视角渲染。", "motivation": "现有方法在大幅相机姿态变化下表现不佳，影响3D头像的真实感，因此需要一个能够处理大幅姿态变化并实现实时动画的单次成像3D全头头像重建方法。", "method": "该框架将3D头像模型表示为参数化面部模型UV空间上的高斯基元，利用预训练的3D GAN提取全局全头特征并进行多视角监督，同时融合局部精细输入图像特征与全局纹理以提高重建保真度。", "result": "该方法在高质量3D全头建模和实时动画方面表现出色，显著提升了3D说话头像的真实感。", "conclusion": "所提出的框架能够有效地从单张图像重建可动画的3D全头头像，解决了现有方法在姿态变化下的不足，并实现了逼真的实时动画效果。"}}
{"id": "2601.13453", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13453", "abs": "https://arxiv.org/abs/2601.13453", "authors": ["Aditya Thole", "Anmol Agrawal", "Arnav Ramamoorthy", "Dhruv Kumar"], "title": "PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving", "comment": null, "summary": "Explaining numerical physics problems often requires more than text-based solutions; clear visual reasoning can substantially improve conceptual understanding. While large language models (LLMs) demonstrate strong performance on many physics questions in textual form, their ability to generate long, high-quality visual explanations remains insufficiently explored. In this work, we introduce PhysicsSolutionAgent (PSA), an autonomous agent that generates physics-problem explanation videos of up to six minutes using Manim animations. To evaluate the generated videos, we design an assessment pipeline that performs automated checks across 15 quantitative parameters and incorporates feedback from a vision-language model (VLM) to iteratively improve video quality. We evaluate PSA on 32 videos spanning numerical and theoretical physics problems. Our results reveal systematic differences in video quality depending on problem difficulty and whether the task is numerical or theoretical. Using GPT-5-mini, PSA achieves a 100% video-completion rate with an average automated score of 3.8/5. However, qualitative analysis and human inspection uncover both minor and major issues, including visual layout inconsistencies and errors in how visual content is interpreted during feedback. These findings expose key limitations in reliable Manim code generation and highlight broader challenges in multimodal reasoning and evaluation for visual explanations of numerical physics problems. Our work underscores the need for improved visual understanding, verification, and evaluation frameworks in future multimodal educational systems", "AI": {"tldr": "本研究提出了PhysicsSolutionAgent (PSA)，一个能够生成长达六分钟的Manim动画物理问题解释视频的自主代理。通过结合自动评分和视觉语言模型反馈，PSA在32个视频的评估中实现了100%的完成率和3.8/5的平均自动得分。然而，研究也揭示了Manim代码生成、多模态推理和评估方面的挑战，尤其是在处理问题难度和类型差异时。", "motivation": "传统的文本式物理问题解答不足以完全传达概念，视觉推理能显著增强理解。尽管大型语言模型在文本形式的物理问题上表现出色，但生成高质量的视觉解释能力仍有待探索。", "method": "研究者开发了一个名为PhysicsSolutionAgent (PSA) 的自主代理，利用Manim动画生成物理问题解释视频。评估流程结合了15个量化参数的自动检查，以及视觉语言模型（VLM）的反馈，以迭代改进视频质量。研究在32个数值和理论物理问题视频上进行了评估。", "result": "PSA在GPT-5-mini的驱动下，实现了100%的视频完成率，平均自动评分为3.8/5。然而，定性分析和人工检查发现存在视觉布局不一致、VLM反馈中视觉内容解释错误等问题，这些问题因问题难度和类型（数值或理论）而异。", "conclusion": "PSA在生成物理问题解释视频方面取得了初步成功，但也暴露了Manim代码生成、多模态推理和评估方面的关键局限性。研究强调了在未来多模态教育系统中，对视觉理解、验证和评估框架进行改进的必要性。"}}
{"id": "2601.13412", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13412", "abs": "https://arxiv.org/abs/2601.13412", "authors": ["Puneet Sharma", "Kristian Dalsbø Hindberg", "Benedicte Schelde-Olesen", "Ulrik Deding", "Esmaeil S. Nadimi", "Jan-Matthias Braun"], "title": "Using deep learning for predicting cleansing quality of colon capsule endoscopy images", "comment": "24 pages", "summary": "In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.", "AI": {"tldr": "本研究使用深度学习（ResNet-18）结合结构化剪枝技术，对结肠胶囊内窥镜图像的清洁度进行预测，在保证高准确率的同时大幅提高了模型效率，并通过多种可视化方法评估了剪枝模型的模型可解释性。", "motivation": "提高结肠胶囊内窥镜（CCE）图像的清洁度预测的准确性和效率，同时确保模型的可解释性，以增强其在临床应用中的可靠性。", "method": "使用包含500张图像的数据集，通过14名临床医生在Leighton-Rex量表上进行标注。训练ResNet-18模型进行分类，并采用分层K折交叉验证。应用结构化剪枝技术迭代优化模型，实现高稀疏度和高准确率。使用Grad-CAM、Grad-CAM++、Eigen-CAM、Ablation-CAM和Random-CAM等方法评估模型的解释性，并使用ROAD方法进行一致性评估。最后，使用自适应温度缩放的变体校准剪枝模型以适应外部数据集。", "result": "剪枝后的模型在交叉验证中达到了88%的准确率和79%的稀疏度，相比未剪枝模型（84%准确率）效率有所提高，而性能并未下降。研究还强调了评估CCE图像清洁度质量的挑战，以及模型可解释性在临床应用中的重要性。", "conclusion": "深度学习和结构化剪枝技术可以有效地提高CCE图像清洁度预测模型的效率，同时保持甚至提高其准确性。模型的可解释性对于临床应用至关重要，尽管在评估方法上仍存在挑战。通过温度缩放可以提高模型在外部数据集上的泛化能力。"}}
{"id": "2601.13547", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13547", "abs": "https://arxiv.org/abs/2601.13547", "authors": ["Yujia Hu", "Roy Ka-Wei Lee"], "title": "HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations", "comment": "EACL 2026 Main Conference", "summary": "Hateful speech detection is a key component of content moderation, yet current evaluation frameworks rarely assess why a text is deemed hateful. We introduce \\textsf{HateXScore}, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses (i) conclusion explicitness, (ii) faithfulness and causal grounding of quoted spans, (iii) protected group identification (policy-configurable), and (iv) logical consistency among these elements. Evaluated on six diverse hate speech datasets, \\textsf{HateXScore} is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Moreover, human evaluation shows strong agreement with \\textsf{HateXScore}, validating it as a practical tool for trustworthy and transparent moderation.\n  \\textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}", "AI": {"tldr": "该研究提出了一种名为 HateXScore 的四部分评估指标套件，用于衡量模型解释在仇恨言论检测中的推理质量，包括结论明确性、引用跨度忠实度、受保护群体识别和逻辑一致性，并已在多个数据集上进行了验证。", "motivation": "现有的仇恨言论检测评估框架很少评估模型判断文本为仇恨言论的原因，这阻碍了对模型可解释性失败和标注不一致性的诊断。", "method": "引入 HateXScore 指标套件，包含四个评估维度：结论明确性、引用跨度（受保护群体）的忠实度和因果关系、受保护群体识别（可配置）以及结论、跨度和群体识别之间的逻辑一致性。", "result": "在六个不同的仇恨言论数据集上评估 HateXScore，结果表明该指标能揭示标准指标（如准确率或 F1 分数）无法发现的可解释性失败和标注不一致性。人类评估也证实了 HateXScore 与人类判断高度一致。", "conclusion": "HateXScore 是一个实用的工具，可以作为标准评估指标的补充，用于诊断仇恨言论检测模型的推理质量，从而促进更可信和透明的内容审核。"}}
{"id": "2601.12779", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12779", "abs": "https://arxiv.org/abs/2601.12779", "authors": ["Nafis Sadeq", "Qingfeng Liu", "Mostafa El-Khamy"], "title": "Open Vocabulary Panoptic Segmentation With Retrieval Augmentation", "comment": null, "summary": "Given an input image and set of class names, panoptic segmentation aims to label each pixel in an image with class labels and instance labels. In comparison, Open Vocabulary Panoptic Segmentation aims to facilitate the segmentation of arbitrary classes according to user input. The challenge is that a panoptic segmentation system trained on a particular dataset typically does not generalize well to unseen classes beyond the training data. In this work, we propose RetCLIP, a retrieval-augmented panoptic segmentation method that improves the performance of unseen classes. In particular, we construct a masked segment feature database using paired image-text data. At inference time, we use masked segment features from the input image as query keys to retrieve similar features and associated class labels from the database. Classification scores for the masked segment are assigned based on the similarity between query features and retrieved features. The retrieval-based classification scores are combined with CLIP-based scores to produce the final output. We incorporate our solution with a previous SOTA method (FC-CLIP). When trained on COCO, the proposed method demonstrates 30.9 PQ, 19.3 mAP, 44.0 mIoU on the ADE20k dataset, achieving +4.5 PQ, +2.5 mAP, +10.0 mIoU absolute improvement over the baseline.", "AI": {"tldr": "RetCLIP是一种检索增强的全景分割方法，通过构建掩码片段特征数据库并检索相似特征来提高对未见类别的分割性能。该方法将检索到的类别分数与CLIP分数结合，并在ADE20k数据集上取得了显著的性能提升。", "motivation": "现有的全景分割系统在处理训练数据之外的未知类别时泛化能力较差。本研究旨在提高全景分割系统对未知类别的分割性能。", "method": "构建一个使用配对图像-文本数据的掩码片段特征数据库。在推理时，将输入图像的掩码片段特征作为查询键，从数据库中检索相似的特征和相关类别标签。基于查询特征与检索到的特征之间的相似性，为掩码片段分配分类分数，并将其与基于CLIP的分数结合起来得到最终输出。将该方法集成到FC-CLIP基线模型中。", "result": "在COCO数据集上训练，该方法在ADE20k数据集上取得了30.9 PQ、19.3 mAP和44.0 mIoU的性能，相比基线模型分别提升了+4.5 PQ、+2.5 mAP和+10.0 mIoU。", "conclusion": "RetCLIP通过检索增强机制，有效提升了全景分割模型对未知类别的识别和分割能力，并在多项关键指标上取得了显著的性能改进。"}}
{"id": "2601.13588", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13588", "abs": "https://arxiv.org/abs/2601.13588", "authors": ["Inho Won", "Hangyeol Yoo", "Minkyung Cho", "Jungyeul Park", "Hoyun Song", "KyungTae Lim"], "title": "TREX: Tokenizer Regression for Optimal Data Mixture", "comment": "Accepted to EACL 2026. Long Paper. (19 languages studied: Chinese, Greek, Japanese, etc.)", "summary": "Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. While a tokenizer's compression performance critically affects the efficiency of LLM training and inference, existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. We introduce Tokenizer Regression for Optimal Data MiXture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both inand out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.", "AI": {"tldr": "本文提出了一种名为TREX的回归框架，用于高效预测训练多语言大型语言模型（LLM）分词器的最佳语言数据混合比例，从而避免了以往依赖启发式方法或昂贵搜索的缺点。", "motivation": "现有方法在确定多语言LLM分词器训练的最佳语言数据混合比例时，依赖于启发式方法或成本高昂的大规模搜索。而分词器的压缩性能直接影响LLM训练和推理的效率，因此需要一种更有效的方法来解决这个准确性-成本的权衡问题。", "method": "TREX通过在小规模代理分词器上使用随机混合数据进行训练，收集其压缩统计信息，然后学习一个模型来预测数据混合比例对压缩性能的影响。这个模型随后被用于在进行大规模分词器训练之前，进行可扩展的混合比例搜索。", "result": "使用TREX预测的混合比例训练的分词器，在分布内和分布外压缩效率上均比基于LLaMA3和均匀分布的混合比例提高了12%。", "conclusion": "TREX提供了一种可扩展、鲁棒且实用的方法，能够有效地预测多语言LLM分词器的最佳数据混合比例，显著提高了分词器的压缩效率，并缓解了多语言分词器设计中的准确性-成本权衡问题。"}}
{"id": "2601.13575", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13575", "abs": "https://arxiv.org/abs/2601.13575", "authors": ["Thanh-Lam T. Nguyen", "Ngoc-Quang Le", "Quoc-Trung Phu", "Thi-Phuong Le", "Ngoc-Huyen Pham", "Phuong-Nguyen Nguyen", "Hoang-Quynh Le"], "title": "Comparing Without Saying: A Dataset and Benchmark for Implicit Comparative Opinion Mining from Same-User Reviews", "comment": null, "summary": "Existing studies on comparative opinion mining have mainly focused on explicit comparative expressions, which are uncommon in real-world reviews. This leaves implicit comparisons - here users express preferences across separate reviews - largely underexplored. We introduce SUDO, a novel dataset for implicit comparative opinion mining from same-user reviews, allowing reliable inference of user preferences even without explicit comparative cues. SUDO comprises 4,150 annotated review pairs (15,191 sentences) with a bi-level structure capturing aspect-level mentions and review-level preferences. We benchmark this task using two baseline architectures: traditional machine learning- and language model-based baselines. Experimental results show that while the latter outperforms the former, overall performance remains moderate, revealing the inherent difficulty of the task and establishing SUDO as a challenging and valuable benchmark for future research.", "AI": {"tldr": "本文提出了一个名为SUDO的新数据集，用于挖掘隐式比较意见，即用户在不同评论中表达偏好。该数据集包含4150个标注的评论对，具有双层结构，能够捕捉方面级别的提及和评论级别的偏好。研究人员使用机器学习和语言模型作为基线进行了评估，结果表明语言模型优于传统机器学习模型，但整体性能仍显不足，突显了该任务的挑战性，并将SUDO定位为未来研究的基准。", "motivation": "现有比较意见挖掘研究主要集中在显式比较表达，而忽略了在实际评论中更常见的隐式比较（用户在不同评论中表达偏好）。", "method": "构建了一个名为SUDO的新数据集，包含4150个标注的评论对（15191句话），具有捕捉方面级别提及和评论级别偏好的双层结构。使用传统的机器学习和基于语言模型的架构作为基线进行了评估。", "result": "基于语言模型的基线架构优于传统的机器学习基线架构。然而，总体性能仍然是中等的，表明这项任务固有的难度。", "conclusion": "SUDO是一个具有挑战性且有价值的新数据集，可以促进对隐式比较意见挖掘的研究，并为未来的研究提供了一个基准。"}}
{"id": "2601.12795", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12795", "abs": "https://arxiv.org/abs/2601.12795", "authors": ["Zeren Sun", "Yazhou Yao", "Tongliang Liu", "Zechao Li", "Fumin Shen", "Jinhui Tang"], "title": "Combating Noisy Labels through Fostering Self- and Neighbor-Consistency", "comment": "accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence", "summary": "Label noise is pervasive in various real-world scenarios, posing challenges in supervised deep learning. Deep networks are vulnerable to such label-corrupted samples due to the memorization effect. One major stream of previous methods concentrates on identifying clean data for training. However, these methods often neglect imbalances in label noise across different mini-batches and devote insufficient attention to out-of-distribution noisy data. To this end, we propose a noise-robust method named Jo-SNC (\\textbf{Jo}int sample selection and model regularization based on \\textbf{S}elf- and \\textbf{N}eighbor-\\textbf{C}onsistency). Specifically, we propose to employ the Jensen-Shannon divergence to measure the ``likelihood'' of a sample being clean or out-of-distribution. This process factors in the nearest neighbors of each sample to reinforce the reliability of clean sample identification. We design a self-adaptive, data-driven thresholding scheme to adjust per-class selection thresholds. While clean samples undergo conventional training, detected in-distribution and out-of-distribution noisy samples are trained following partial label learning and negative learning, respectively. Finally, we advance the model performance further by proposing a triplet consistency regularization that promotes self-prediction consistency, neighbor-prediction consistency, and feature consistency. Extensive experiments on various benchmark datasets and comprehensive ablation studies demonstrate the effectiveness and superiority of our approach over existing state-of-the-art methods.", "AI": {"tldr": "提出一种名为Jo-SNC的噪声鲁棒方法，通过联合样本选择和模型正则化来处理标签噪声，利用Jensen-Shannon散度结合近邻信息来识别清洁和分布外噪声样本，并结合部分标签学习和负学习进行训练，最后通过三元组一致性正则化进一步提升模型性能。", "motivation": "深度网络容易受到标签噪声的影响，现有方法在处理噪声不平衡和分布外噪声数据方面存在不足。", "method": "利用Jensen-Shannon散度衡量样本为清洁或分布外噪声的“可能性”，结合近邻信息增强清洁样本识别的可靠性。设计自适应阈值方案，对不同类别的选择阈值进行调整。对清洁样本进行常规训练，对分布内和分布外噪声样本分别采用部分标签学习和负学习。提出三元组一致性正则化，促进自预测、邻居预测和特征一致性。", "result": "在多个基准数据集上的广泛实验和消融研究证明了该方法的有效性和优越性。", "conclusion": "Jo-SNC是一种有效的噪声鲁棒方法，能够更好地处理标签噪声，提升模型性能。"}}
{"id": "2601.13537", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13537", "abs": "https://arxiv.org/abs/2601.13537", "authors": ["Yerin Hwang", "Dongryeol Lee", "Taegwan Kang", "Minwoo Lee", "Kyomin Jung"], "title": "When Wording Steers the Evaluation: Framing Bias in LLM judges", "comment": "4 pages", "summary": "Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. Drawing inspiration from the framing effect in psychology, we systematically investigate how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive and predicate-negative constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.", "AI": {"tldr": "研究表明，大型语言模型（LLM）在评估任务中会受到提示语境偏差的影响，即便是细微的措辞变化也会导致模型输出的差异，这揭示了LLM评估系统存在结构性偏差，需要开发相应的防范机制。", "motivation": "现有研究很少关注提示语境偏差对LLM评估的影响，尤其是LLM在作为评估者时，其判断的稳定性和公正性是否会受到提示语境偏差的影响。", "method": "研究者从心理学中的“框架效应”汲取灵感，设计了对称的提示语，采用谓词肯定和谓词否定两种句式，系统地研究了提示语境偏差如何影响模型在四种高风险评估任务中的判断。他们使用了14个不同的LLM作为评估者。", "result": "研究发现在不同LLM模型中，提示语境偏差确实会导致模型输出产生显著差异。不同模型家族在面对框架效应时，表现出不同的倾向，有的更倾向于同意，有的更倾向于拒绝。", "conclusion": "研究结论指出，提示语境偏差是当前基于LLM的评估系统的结构性特征。为了确保LLM评估的可靠性和公正性，需要开发和采用能够识别和减轻框架效应的评估协议。"}}
{"id": "2601.13614", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13614", "abs": "https://arxiv.org/abs/2601.13614", "authors": ["Bo Peng", "Sirui Chen", "Lei Xu", "Chaochao Lu"], "title": "CauScientist: Teaching LLMs to Respect Data for Causal Discovery", "comment": null, "summary": "Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence or incorporate unverified priors that can mislead result. To this end, we propose CauScientist, a collaborative framework that synergizes LLMs as hypothesis-generating \"data scientists\" with probabilistic statistics as rigorous \"verifiers\". CauScientist employs hybrid initialization to select superior starting graphs, iteratively refines structures through LLM-proposed modifications validated by statistical criteria, and maintains error memory to guide efficient search space. Experiments demonstrate that CauScientist substantially outperforms purely data-driven baselines, achieving up to 53.8% F1 score improvement and enhancing recall from 35.0% to 100.0%. Notably, while standalone LLM performance degrades with graph complexity, CauScientist reduces structural hamming distance (SHD) by 44.0% compared to Qwen3-32B on 37-node graphs. Our project page is at https://github.com/OpenCausaLab/CauScientist.", "AI": {"tldr": "本文提出了 CauScientist，一个结合了大型语言模型（LLM）进行因果图假设生成和概率统计进行验证的协作框架，以克服现有纯数据驱动和纯 LLM 方法的局限性。", "motivation": "现有因果发现方法存在问题：纯数据驱动方法在统计上无法区分且依赖建模假设；近期 LLM 方法忽视统计证据或使用未经检验的先验知识，可能导致错误结果。因此，需要一种能融合 LLM 的创造力和统计学严谨性的方法。", "method": "CauScientist 框架通过混合初始化选择更好的初始图，利用 LLM 提出的修改并由统计标准验证来迭代优化图结构，同时维护错误记忆以指导高效的搜索空间。", "result": "CauScientist 在实验中显著优于纯数据驱动方法，F1 分数最高提升 53.8%，召回率从 35.0% 提升至 100.0%。在面对复杂图（37 节点）时，CauScientist 将结构汉明距离（SHD）降低了 44.0%，而单独的 LLM 性能会下降。", "conclusion": "CauScientist 通过 LLM 的假设生成能力和统计学的严谨验证，能够有效地进行因果发现，尤其在处理复杂因果图时，表现出比纯 LLM 方法更优越的性能和鲁棒性。"}}
{"id": "2601.13503", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13503", "abs": "https://arxiv.org/abs/2601.13503", "authors": ["Kyung Ho Lim", "Byung-Hoon Kim"], "title": "Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives", "comment": null, "summary": "Psychiatric narratives encode patient identity not only through explicit identifiers but also through idiosyncratic life events embedded in their clinical structure. Existing de-identification approaches, including PHI masking and LLM-based synthetic rewriting, operate at the text level and offer limited control over which semantic elements are preserved or altered. We introduce Anonpsy, a de-identification framework that reformulates the task as graph-guided semantic rewriting. Anonpsy (1) converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations; (2) applies graph-constrained perturbations that modify identifying context while preserving clinically essential structure; and (3) regenerates text via graph-conditioned LLM generation. Evaluated on 90 clinician-authored psychiatric case narratives, Anonpsy preserves diagnostic fidelity while achieving consistently low re-identification risk under expert, semantic, and GPT-5-based evaluations. Compared with a strong LLM-only rewriting baseline, Anonpsy yields substantially lower semantic similarity and identifiability. These results demonstrate that explicit structural representations combined with constrained generation provide an effective approach to de-identification for psychiatric narratives.", "AI": {"tldr": "提出了一种名为 Anonpsy 的图引导语义重写框架，用于精神病学叙事的去识别化，通过将叙事转换为语义图，然后对图进行扰动并基于图条件生成文本，从而在保留临床诊断信息的同时降低重新识别风险。", "motivation": "现有的去识别化方法（如 PHI 屏蔽和 LLM 合成重写）仅在文本层面操作，对保留或修改哪些语义元素控制有限。精神病学叙事包含患者身份信息，不仅通过明确标识符，还通过独特的生命事件。", "method": "Anonpsy 框架包括三个步骤：（1）将叙事转换为语义图，编码临床实体、时间锚点和类型化关系；（2）应用图约束扰动，修改识别性上下文同时保留临床必需的结构；（3）通过图条件 LLM 生成来重新生成文本。", "result": "在 90 个临床医生撰写的精神病学病例叙事上进行评估，Anonpsy 在保留诊断保真度的同时，在专家、语义和 GPT-5 评估下实现了持续的低重新识别风险。与强大的仅 LLM 重写基线相比，Anonpsy 的语义相似性和可识别性显著降低。", "conclusion": "显式的结构化表示结合约束生成，是精神病学叙事去识别化的有效方法。Anonpsy 通过图引导语义重写，在保护隐私的同时有效保留了叙事的临床意义。"}}
{"id": "2601.12791", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12791", "abs": "https://arxiv.org/abs/2601.12791", "authors": ["Zhihan Zeng", "Yang Zhao", "Kaihe Wang", "Dusit Niyato", "Hongyuan Shu", "Junchu Zhao", "Yanjun Huang", "Yue Xiu", "Zhongpei Zhang", "Ning Wei"], "title": "SKANet: A Cognitive Dual-Stream Framework with Adaptive Modality Fusion for Robust Compound GNSS Interference Classification", "comment": null, "summary": "As the electromagnetic environment becomes increasingly complex, Global Navigation Satellite Systems (GNSS) face growing threats from sophisticated jamming interference. Although Deep Learning (DL) effectively identifies basic interference, classifying compound interference remains difficult due to the superposition of diverse jamming sources. Existing single-domain approaches often suffer from performance degradation because transient burst signals and continuous global signals require conflicting feature extraction scales. We propose the Selective Kernel and Asymmetric convolution Network(SKANet), a cognitive deep learning framework built upon a dual-stream architecture that integrates Time-Frequency Images (TFIs) and Power Spectral Density (PSD). Distinct from conventional fusion methods that rely on static receptive fields, the proposed architecture incorporates a Multi-Branch Selective Kernel (SK) module combined with Asymmetric Convolution Blocks (ACBs). This mechanism enables the network to dynamically adjust its receptive fields, acting as an adaptive filter that simultaneously captures micro-scale transient features and macro-scale spectral trends within entangled compound signals. To complement this spatial-temporal adaptation, a Squeeze-and-Excitation (SE) mechanism is integrated at the fusion stage to adaptively recalibrate the contribution of heterogeneous features from each modality. Evaluations on a dataset of 405,000 samples demonstrate that SKANet achieves an overall accuracy of 96.99\\%, exhibiting superior robustness for compound jamming classification, particularly under low Jamming-to-Noise Ratio (JNR) regimes.", "AI": {"tldr": "提出了一种名为SKANet的认知深度学习框架，它结合了时频图像（TFI）和功率谱密度（PSD），并通过选择性核（SK）和非对称卷积（AC）模块动态调整感受野，以有效识别复杂的复合干扰信号，在低信噪比下表现尤为出色。", "motivation": "现有的深度学习方法在识别GNSS复合干扰信号方面存在困难，因为它们难以同时捕捉到不同尺度（瞬时信号和全局信号）的特征，并且现有融合方法依赖静态感受野。", "method": "提出SKANet认知深度学习框架，采用双流架构，分别输入时频图像（TFI）和功率谱密度（PSD）。关键组件包括多分支选择性核（SK）模块和非对称卷积块（ACBs），以动态调整感受野，并结合Squeeze-and-Excitation（SE）机制在融合阶段自适应地重新校准特征贡献。", "result": "在包含405,000个样本的数据集上，SKANet实现了96.99%的总体准确率，尤其在低信噪比（JNR）条件下，对于复合干扰分类表现出卓越的鲁棒性。", "conclusion": "SKANet是一种有效的认知深度学习框架，通过动态感受野调整和多模态特征自适应融合，能够成功地识别复杂的GNSS复合干扰信号，解决了现有方法的局限性。"}}
{"id": "2601.13630", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13630", "abs": "https://arxiv.org/abs/2601.13630", "authors": ["Zhaopeng Zhang", "Pengcheng Sun", "Lan Zhang", "Chen Tang", "Jiewei Lai", "Yunhao Wang", "Hui Jin"], "title": "Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed over knowledge bases for efficient knowledge retrieval and question answering. However, LLMs can inadvertently answer beyond a user's permission scope, leaking sensitive content, thus making it difficult to deploy knowledge-base QA under fine-grained access control requirements. In this work, we identify a geometric regularity in intermediate activations: for the same query, representations induced by different permission scopes cluster distinctly and are readily separable. Building on this separability, we propose Activation-space Anchored Access Control (AAAC), a training-free framework for multi-class permission control. AAAC constructs an anchor bank, with one permission anchor per class, from a small offline sample set and requires no fine-tuning. At inference time, a multi-anchor steering mechanism redirects each query's activations toward the anchor-defined authorized region associated with the current user, thereby suppressing over-privileged generations by design. Finally, extensive experiments across three LLM families demonstrate that AAAC reduces permission violation rates by up to 86.5% and prompt-based attack success rates by 90.7%, while improving response usability with minor inference overhead compared to baselines.", "AI": {"tldr": "提出了一种名为AAAC（Activation-space Anchored Access Control）的训练无关的框架，通过利用LLM中间激活中的几何规律，实现了对知识库问答中细粒度权限的控制，有效减少了权限违规和攻击，同时保持了响应的可用性。", "motivation": "LLMs 在知识库问答中常会无意间泄露超出用户权限范围的敏感信息，这使得在细粒度访问控制要求下部署知识库问答变得困难。", "method": "本文发现LLMs在处理不同权限范围的查询时，其中间激活会形成可区分的聚类。在此基础上，提出AAAC框架，通过构建一个包含每个权限类别对应“锚点”的锚点库，无需微调即可实现多类别权限控制。在推理时，采用多锚点引导机制，将查询的激活引导至授权区域，从而抑制越权生成。", "result": "AAAC框架在三个LLM家族上的实验表明，权限违规率最高可降低86.5%，基于提示的攻击成功率降低90.7%，同时与基线方法相比，响应可用性有所提高，推理开销仅有轻微增加。", "conclusion": "AAAC是一个有效的、无需训练的框架，能够解决LLM知识库问答中的权限控制问题，通过利用激活空间中的几何规律，能够有效防止敏感信息泄露，并抵御攻击，同时保持问答系统的实用性。"}}
{"id": "2601.13644", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13644", "abs": "https://arxiv.org/abs/2601.13644", "authors": ["Yang Cao", "Bicheng Yu", "Sikun Yang", "Ming Liu", "Yujiu Yang"], "title": "Towards Token-Level Text Anomaly Detection", "comment": "WWW 2026", "summary": "Despite significant progress in text anomaly detection for web applications such as spam filtering and fake news detection, existing methods are fundamentally limited to document-level analysis, unable to identify which specific parts of a text are anomalous. We introduce token-level anomaly detection, a novel paradigm that enables fine-grained localization of anomalies within text. We formally define text anomalies at both document and token-levels, and propose a unified detection framework that operates across multiple levels. To facilitate research in this direction, we collect and annotate three benchmark datasets spanning spam, reviews and grammar errors with token-level labels. Experimental results demonstrate that our framework get better performance than other 6 baselines, opening new possibilities for precise anomaly localization in text. All the codes and data are publicly available on https://github.com/charles-cao/TokenCore.", "AI": {"tldr": "该研究提出了文本的 token 级别异常检测新范式，能够精确定位文本中的异常部分，并发布了三个包含 token 级别标注的基准数据集。", "motivation": "现有文本异常检测方法仅限于文档级别，无法精确定位异常的具体位置，限制了其应用。", "method": "定义了文档级别和 token 级别的文本异常，并提出了一个统一的多级别检测框架。收集并标注了三个跨越垃圾邮件、评论和语法错误类别的 token 级别标注数据集。", "result": "提出的框架在实验中优于其他 6 个基线方法，展示了在文本中精确异常定位的可能性。", "conclusion": "token 级别异常检测是一个有前景的新方向，提出的框架和数据集为该领域的研究提供了基础。"}}
{"id": "2601.12798", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12798", "abs": "https://arxiv.org/abs/2601.12798", "authors": ["Zhihan Zeng", "Yang Zhao", "Kaihe Wang", "Dusit Niyato", "Yue Xiu", "Lu Chen", "Zhongpei Zhang", "Ning Wei"], "title": "PhyG-MoE: A Physics-Guided Mixture-of-Experts Framework for Energy-Efficient GNSS Interference Recognition", "comment": null, "summary": "Complex electromagnetic interference increasingly compromises Global Navigation Satellite Systems (GNSS), threatening the reliability of Space-Air-Ground Integrated Networks (SAGIN). Although deep learning has advanced interference recognition, current static models suffer from a \\textbf{fundamental limitation}: they impose a fixed computational topology regardless of the input's physical entropy. This rigidity leads to severe resource mismatch, where simple primitives consume the same processing cost as chaotic, saturated mixtures. To resolve this, this paper introduces PhyG-MoE (Physics-Guided Mixture-of-Experts), a framework designed to \\textbf{dynamically align model capacity with signal complexity}. Unlike static architectures, the proposed system employs a spectrum-based gating mechanism that routes signals based on their spectral feature entanglement. A high-capacity TransNeXt expert is activated on-demand to disentangle complex features in saturated scenarios, while lightweight experts handle fundamental signals to minimize latency. Evaluations on 21 jamming categories demonstrate that PhyG-MoE achieves an overall accuracy of 97.58\\%. By resolving the intrinsic conflict between static computing and dynamic electromagnetic environments, the proposed framework significantly reduces computational overhead without performance degradation, offering a viable solution for resource-constrained cognitive receivers.", "AI": {"tldr": "本文提出了一种名为 PhyG-MoE 的新框架，通过根据信号复杂性动态调整计算资源来提高 GNSS 抗干扰能力，解决了现有深度学习模型计算资源分配不当的问题。", "motivation": "现有深度学习模型在处理日益复杂的电磁干扰对 GNSS 可靠性构成威胁时，存在固定的计算拓扑，无法适应不同信号的物理熵，导致资源浪费。因此，需要一种能够根据信号复杂度动态调整模型计算能力的框架。", "method": "PhyG-MoE 框架采用基于频谱的门控机制，根据信号的频谱特征纠缠度来路由信号。对于复杂的饱和信号，激活高容量的 TransNeXt expert；对于基础信号，则使用轻量级 expert 以降低延迟。", "result": "在 21 类干扰场景的测试中，PhyG-MoE 实现了 97.58% 的总体准确率，并在不降低性能的情况下显著降低了计算开销。", "conclusion": "PhyG-MoE 框架成功解决了静态计算与动态电磁环境之间的冲突，为资源受限的认知接收机提供了一种有效的解决方案，能够根据信号复杂性动态分配计算资源，从而提高 GNSS 的可靠性。"}}
{"id": "2601.13622", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13622", "abs": "https://arxiv.org/abs/2601.13622", "authors": ["Donghee Lee", "Rui Cai", "Zhe Zhao"], "title": "CARPE: Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models", "comment": null, "summary": "Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. Despite their strong performance, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, we propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model's ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks. Finally, CARPE is designed to be effectively integrated with most open-source LVLMs that consist of a vision encoder and a language model, ensuring its adaptability across diverse architectures.", "AI": {"tldr": "提出了一种名为 CARPE 的框架，通过引入视觉集成层和上下文感知集成策略，解决了大型视觉语言模型（LVLM）在视觉任务上表现不佳的问题，提高了其在图像分类和多模态任务上的泛化能力。", "motivation": "尽管大型视觉语言模型（LVLM）在通用任务上表现出色，但在图像分类等纯视觉任务上，它们的性能不如基础的视觉编码器。这是因为 LVLM 在融合视觉和文本信息时，可能无法充分利用图像本身的表示能力。", "method": "提出了 CARPE（Context-Aware Image Representation Prioritization via Ensemble）框架，该框架包含：1. 视觉集成层（vision-integration layers），用于增强模型对图像信息的处理能力。2. 上下文感知集成策略（context-aware ensemble strategy），能够动态地决定何时优先考虑图像表示，何时依赖语言模型的推理能力，从而自适应地加权视觉和文本模态。", "result": "CARPE 框架在图像分类基准测试和各种视觉语言基准测试上均取得了持续的性能提升。实验证明，该方法能够有效捕捉图像表示的多个方面，并提高模型的泛化能力。", "conclusion": "CARPE 是一种模型无关的框架，可以有效地整合到大多数由视觉编码器和语言模型组成的大型视觉语言模型中，提高了模型在视觉任务和多模态任务上的表现，并能适应不同的模型架构。"}}
{"id": "2601.12814", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12814", "abs": "https://arxiv.org/abs/2601.12814", "authors": ["Yu-Jen Tseng", "Chia-Hao Kao", "Jing-Zhong Chen", "Alessandro Gnutti", "Shao-Yuan Lo", "Yen-Yu Lin", "Wen-Hsiao Peng"], "title": "CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting", "comment": "Accepted at WACV 2026", "summary": "We present the first unified framework for rate-distortion-optimized compression and segmentation of 3D Gaussian Splatting (3DGS). While 3DGS has proven effective for both real-time rendering and semantic scene understanding, prior works have largely treated these tasks independently, leaving their joint consideration unexplored. Inspired by recent advances in rate-distortion-optimized 3DGS compression, this work integrates semantic learning into the compression pipeline to support decoder-side applications--such as scene editing and manipulation--that extend beyond traditional scene reconstruction and view synthesis. Our scheme features a lightweight implicit neural representation-based hyperprior, enabling efficient entropy coding of both color and semantic attributes while avoiding costly grid-based hyperprior as seen in many prior works. To facilitate compression and segmentation, we further develop compression-guided segmentation learning, consisting of quantization-aware training to enhance feature separability and a quality-aware weighting mechanism to suppress unreliable Gaussian primitives. Extensive experiments on the LERF and 3D-OVS datasets demonstrate that our approach significantly reduces transmission cost while preserving high rendering quality and strong segmentation performance.", "AI": {"tldr": "本文提出了一个统一的框架，用于3D高斯泼溅（3DGS）的率失真优化压缩和分割，能够同时处理渲染质量和语义理解，并支持下游的场景编辑和操作。", "motivation": "现有3DGS工作独立处理渲染和语义理解，缺乏将其联合优化的研究。本文旨在通过将语义学习整合到压缩流程中，以支持超越传统重建和视图合成的下游应用。", "method": "提出了一种率失真优化的3DGS压缩和分割统一框架。使用轻量级的隐式神经表示作为超先验，支持颜色和语义属性的高效熵编码。开发了压缩引导的分割学习方法，包括量化感知训练和质量感知加权机制。", "result": "在LERF和3D-OVS数据集上的实验表明，该方法显著降低了传输成本，同时保持了高质量的渲染和强大的分割性能。", "conclusion": "所提出的统一框架有效地实现了3DGS的率失真优化压缩和分割，为需要同时考虑渲染和语义理解的应用提供了解决方案。"}}
{"id": "2601.13658", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13658", "abs": "https://arxiv.org/abs/2601.13658", "authors": ["Arthur Amalvy", "Hen-Hsen Huang"], "title": "Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation", "comment": "12 pages", "summary": "The automatic extraction of information is important for populating large web knowledge bases such as Wikidata. The temporal version of that task, temporal knowledge graph extraction (TKGE), involves extracting temporally grounded facts from text, represented as semantic quadruples (subject, relation, object, timestamp). Many recent systems take advantage of large language models (LLMs), which are becoming a new cornerstone of the web due to their performance on many tasks across the natural language processing (NLP) field. Despite the importance of TKGE, existing datasets for training and evaluation remain scarce, and contamination of evaluation data is an unaddressed issue, potentially inflating LLMs' perceived performance due to overlaps between training and evaluation sets. To mitigate these challenges, we propose a novel synthetic evaluation dataset constructed from predicted future, previously unseen temporal facts, thereby eliminating contamination and enabling robust and unbiased benchmarking. Our dataset creation involves a two-step approach: (1) Temporal Knowledge Graph Forecasting (TKGF) generates plausible future quadruples, which are subsequently filtered to adhere to the original knowledge base schema; (2) LLMs perform quadruple-to-text generation, creating semantically aligned textual descriptions. We benchmark Extract, Define and Canonicalize (EDC), a state-of-the-art LLM-based extraction framework, demonstrating that LLM performance decreases when evaluated on our dataset compared to a dataset of known facts. We publicly release our dataset consisting of 4.2K future quadruples and corresponding textual descriptions, along with the generation methodology, enabling continuous creation of unlimited future temporal datasets to serve as long-term, contamination-free benchmarks for TKGE.", "AI": {"tldr": "本研究提出了一个新的用于时间知识图谱提取（TKGE）的合成评估数据集，该数据集包含预测的未来事实，旨在解决现有数据集的稀缺性和评估数据污染问题，并对现有的LLM基线进行了评估。", "motivation": "现有用于TKGE的数据集稀缺且存在评估数据污染问题，这可能导致LLM的性能被高估。需要一个无污染、可扩展的数据集来准确评估TKGE方法，特别是基于LLM的方法。", "method": "研究者首先通过时间知识图谱预测（TKGF）生成未来可能发生的三元组，然后过滤以符合现有知识图谱的模式。接着，利用LLM将这些未来三元组转换为文本描述。由此创建了一个包含4.2K未来三元组及其文本描述的合成评估数据集。", "result": "在提出的新数据集上评估了先进的LLM基线EDC，发现其性能相比于在已知事实数据集上的评估有所下降，这表明了现有数据集的污染问题。", "conclusion": "该研究成功构建了一个无污染的、可动态生成的未来时间事实数据集，为TKGE提供了一个更可靠的评估基准，并揭示了LLM在处理未知事实时的性能挑战。"}}
{"id": "2601.13649", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13649", "abs": "https://arxiv.org/abs/2601.13649", "authors": ["Xiaolin Zhou", "Zheng Luo", "Yicheng Gao", "Qixuan Chen", "Xiyang Hu", "Yue Zhao", "Ruishan Liu"], "title": "Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only.", "AI": {"tldr": "本研究调查了LLM-as-a-judge在判断文本质量时存在的语言偏见。研究发现，在同种语言判断中，欧洲语言的表现优于非洲语言，尤其在文化相关主题上；在跨语言判断中，LLM倾向于偏爱英文答案。研究还发现，这种语言偏见不能完全用低困惑度偏见解释。", "motivation": "以往的研究表明，LLM-as-a-judge存在偏见，并且与人类偏好不符。其中，语言偏见是一个被识别出的问题，即LLM的判断结果会因被判断文本的语言而异。本研究旨在深入探究LLM-as-a-judge在成对判断中存在的两种语言偏见。", "method": "研究者分析了两种类型的语言偏见：1) 在判断同种语言的选项时，LLM在不同语言间的表现差异；2) 在判断两种不同语言的选项时，LLM对主要语言（如英语）选项的偏好。此外，研究者还调查了语言偏见是否由低困惑度偏见引起。", "result": "在同种语言判断方面，研究发现不同语系之间存在显著的表现差异，欧洲语言的表现普遍优于非洲语言，尤其在文化相关主题上这种偏见更为明显。在跨语言判断方面，大多数模型偏爱英文答案，且这种偏好更多受答案语言影响而非问题语言。最后，研究发现困惑度与语言偏见存在轻微相关性，但不能完全解释语言偏见。", "conclusion": "LLM-as-a-judge在成对判断中存在显著的语言偏见，包括同种语言判断中的语系表现差异和跨语言判断中的对主要语言的偏好。虽然低困惑度偏见与语言偏见有关，但它并非造成语言偏见的唯一原因。这些发现强调了在应用LLM-as-a-judge时需要考虑并解决语言偏见问题。"}}
{"id": "2601.13659", "categories": ["cs.CL", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.13659", "abs": "https://arxiv.org/abs/2601.13659", "authors": ["Chunlei Meng", "Ziyang Zhou", "Lucas He", "Xiaojing Du", "Chun Ouyang", "Zhongxue Gan"], "title": "Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis", "comment": "This study has been accepted by IEEE ICASSP2026", "summary": "Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling. This ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and thus limited performance. Hence, we propose TSDA, Temporal-Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial body. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis studies confirm the necessity and interpretability of the design.", "AI": {"tldr": "提出了一种名为TSDA的新型多模态情感分析方法，该方法通过在交互前显式地将每种模态（语言、视觉、听觉）分解为时间动态和空间结构上下文，来解决现有方法在时空信息处理上的不足，从而提高了性能。", "motivation": "主流的多模态情感分析方法依赖于时空混合建模，忽略了时空异质性，导致时空信息不对称，限制了模型性能。因此，需要一种新的方法来更有效地处理多模态数据中的时空信息。", "method": "TSDA方法首先将每种模态（语言、视觉、听觉）的信号分别分解为时间动态和空间结构上下文。然后，利用因子一致的跨模态对齐机制，仅将时间特征与对应模态的时间特征进行对齐，空间特征与对应模态的空间特征进行对齐。此外，通过因子特定监督和去相关正则化来减少跨因子泄露并保留互补性。最后，通过门控再耦合模块将对齐后的时空流重新组合以执行任务。", "result": "在多个数据集上的广泛实验表明，TSDA的性能优于现有的基线方法。消融分析也证实了该方法设计的必要性和可解释性。", "conclusion": "TSDA通过显式地在交互前解耦时空信息，并进行分别对齐，能够有效解决多模态情感分析中的时空信息不对称问题，从而提升模型性能。该方法在处理多模态时空数据方面具有优势。"}}
{"id": "2601.12820", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12820", "abs": "https://arxiv.org/abs/2601.12820", "authors": ["Wei Chen", "Liang Wu", "Shuyi Lu", "Yuanyuan Sun", "Wenkai Bi", "Zilong Yuan", "Yaoyao He", "Feng Wang", "Junchi Ma", "Shuyong Liu", "Zhaoping Cheng", "Xiaoyan Hu", "Jianfeng Qiu"], "title": "A Generalist Foundation Model for Total-body PET/CT Enables Diagnostic Reporting and System-wide Metabolic Profiling", "comment": null, "summary": "Total-body PET/CT enables system-wide molecular imaging, but heterogeneous anatomical and metabolic signals, approximately 2 m axial coverage, and structured radiology semantics challenge existing medical AI models that assume single-modality inputs, localized fields of view, and coarse image-text alignment. We introduce SDF-HOLO (Systemic Dual-stream Fusion Holo Model), a multimodal foundation model for holistic total-body PET/CT, pre-trained on more than 10,000 patients. SDF-HOLO decouples CT and PET representation learning with dual-stream encoders and couples them through a cross-modal interaction module, allowing anatomical context to refine PET aggregation while metabolic saliency guides subtle morphological reasoning. To model long-range dependencies across the body, hierarchical context modeling combines efficient local windows with global attention. To bridge voxels and clinical language, we use anatomical segmentation masks as explicit semantic anchors and perform voxel-mask-text alignment during pre-training. Across tumor segmentation, low-dose lesion detection, and multilingual diagnostic report generation, SDF-HOLO outperforms strong task-specific and clinical-reference baselines while reducing localization errors and hallucinated findings. Beyond focal interpretation, the model enables system-wide metabolic profiling and reveals tumor-associated fingerprints of inter-organ metabolic network interactions, providing a scalable computational foundation for total-body PET/CT diagnostics and system-level precision oncology.", "AI": {"tldr": "SDF-HOLO 是一个针对全身 PET/CT 影像的医学 AI 模型，它通过双流编码器融合 CT 和 PET 信息，并利用解剖分割掩码对齐体素和文本，从而在肿瘤分割、病灶检测和报告生成等任务上取得了优于现有方法的性能，并能进行系统级代谢分析。", "motivation": "现有的医学 AI 模型在处理全身 PET/CT 影像时面临挑战，因为这些影像具有异质的信号、较广的视野以及复杂的影像-文本关系，而现有模型通常假设单模态输入、局部视野和粗略的对齐。", "method": "引入 SDF-HOLO 模型，一个多模态基础模型。它采用双流编码器分别处理 CT 和 PET，并通过跨模态交互模块融合两者。通过分层上下文建模来处理长距离依赖。利用解剖分割掩码作为语义锚点，实现体素-掩码-文本对齐。", "result": "在肿瘤分割、低剂量病灶检测和多语言诊断报告生成任务上，SDF-HOLO 的表现优于强有力的基线模型，并减少了定位误差和虚假发现。此外，模型能够进行系统级代谢谱分析，并揭示了肿瘤相关的跨器官代谢网络相互作用。", "conclusion": "SDF-HOLO 为全身 PET/CT 影像诊断和系统级精准肿瘤学提供了一个可扩展的计算基础，实现了超越局部解释的能力，并能进行系统级的代谢分析。"}}
{"id": "2601.13684", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13684", "abs": "https://arxiv.org/abs/2601.13684", "authors": ["Zhiyuan Shi", "Qibo Qiu", "Feng Xue", "Zhonglin Jiang", "Li Yu", "Jian Jiang", "Xiaofei He", "Wenxiao Wang"], "title": "HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference", "comment": null, "summary": "The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information, principally because they overlook the attention drift phenomenon where token significance evolves dynamically. Although recent dynamic retrieval approaches attempt to address this issue, they typically suffer from coarse-grained caching strategies and incur high I/O overhead due to frequent data transfers. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method is built on two key insights: attention heads exhibit diverse temporal heterogeneity, and there is significant spatial redundancy among heads within the same layer. Guided by these insights, HeteroCache categorizes heads based on stability and redundancy. Consequently, we apply a fine-grained weighting strategy that allocates larger cache budgets to heads with rapidly shifting attention to capture context changes, thereby addressing the inefficiency of coarse-grained strategies. Furthermore, we employ a hierarchical storage mechanism in which a subset of representative heads monitors attention shift, and trigger an asynchronous, on-demand retrieval of contexts from the CPU, effectively hiding I/O latency. Finally, experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to $3\\times$ compared to the original model in the 224K context. Our code will be open-source.", "AI": {"tldr": "提出了一种名为 HeteroCache 的训练无关的动态 KV 缓存压缩框架，通过利用注意力头的时间异质性和层内空间冗余，实现高效的 KV 缓存压缩和推理加速。", "motivation": "现有的 KV 缓存压缩方法在处理长上下文任务时存在瓶颈。静态压缩方法忽略了注意力漂移现象，而动态检索方法则存在粗粒度缓存策略和高 I/O 开销问题。", "method": "HeteroCache 框架基于两个关键洞察：1. 注意力头具有不同的时间异质性；2. 同一层内的注意力头存在空间冗余。通过对注意力头进行稳定性和冗余度分类，HeteroCache 采用精细化加权策略，将更多缓存预算分配给注意力变化迅速的头。同时，利用分层存储机制，让一部分代表性头监控注意力变化，并按需异步地从 CPU 检索上下文，以隐藏 I/O 延迟。", "result": "HeteroCache 在多个长上下文基准测试上取得了最先进的性能，并将解码速度相比原始模型在 224K 上下文长度下提升了高达 3 倍。", "conclusion": "HeteroCache 是一种有效的训练无关动态 KV 缓存压缩框架，能够解决现有方法的局限性，显著提高长上下文 LLM 推理的效率和速度。"}}
{"id": "2601.13590", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13590", "abs": "https://arxiv.org/abs/2601.13590", "authors": ["Fan Huang", "Haewoon Kwak", "Jisun An"], "title": "Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions", "comment": null, "summary": "Large Language Models (LLMs) are increasingly employed in various question-answering tasks. However, recent studies showcase that LLMs are susceptible to persuasion and could adopt counterfactual beliefs. We present a systematic evaluation of LLM susceptibility to persuasion under the Source--Message--Channel--Receiver (SMCR) communication framework. Across five mainstream Large Language Models (LLMs) and three domains (factual knowledge, medical QA, and social bias), we analyze how different persuasive strategies influence belief stability over multiple interaction turns. We further examine whether meta-cognition prompting (i.e., eliciting self-reported confidence) affects resistance to persuasion. Results show that smaller models exhibit extreme compliance, with over 80% of belief changes occurring at the first persuasive turn (average end turn of 1.1--1.4). Contrary to expectations, meta-cognition prompting increases vulnerability by accelerating belief erosion rather than enhancing robustness. Finally, we evaluate adversarial fine-tuning as a defense. While GPT-4o-mini achieves near-complete robustness (98.6%) and Mistral~7B improves substantially (35.7% $\\rightarrow$ 79.3%), Llama models remain highly susceptible (<14%) even when fine-tuned on their own failure cases. Together, these findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs.", "AI": {"tldr": "本研究系统性地评估了大型语言模型（LLMs）在SMCR通信框架下的说服易感性，发现模型规模、说服策略和元认知提示都会影响其信念稳定性，并且对抗性微调的效果因模型而异，提示了现有鲁棒性干预措施的局限性。", "motivation": "近期研究表明LLMs容易受到说服并形成反事实信念，因此需要系统性地评估其说服易感性，并探索有效的防御机制。", "method": "研究者采用了SMCR（来源-信息-渠道-接收者）通信框架，在五个主流LLMs和三个领域（事实知识、医学问答、社会偏见）中，分析了不同说服策略对多轮交互中信念稳定性的影响，并检验了元认知提示（自我报告置信度）是否会影响抗说服能力。最后，评估了对抗性微调作为一种防御手段的效果。", "result": "结果显示，较小的模型极易受说服，超过80%的信念改变发生在第一次说服回合。与预期相反，元认知提示反而增加了模型的易感性，加速了信念的侵蚀。对抗性微调在GPT-4o-mini和Mistral-7B上表现出显著的鲁棒性提升，但Llama模型即使经过自身失败案例的微调，仍然高度易感。", "conclusion": "当前LLMs在说服易感性方面存在模型依赖性的显著局限性，现有的鲁棒性干预措施并非普适有效。研究结果为开发更值得信赖的LLMs提供了指导。"}}
{"id": "2601.12823", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12823", "abs": "https://arxiv.org/abs/2601.12823", "authors": ["Belal Shaheen", "Minh-Hieu Nguyen", "Bach-Thuan Bui", "Shubham", "Tim Wu", "Michael Fairley", "Matthew David Zane", "Michael Wu", "James Tompkin"], "title": "TreeDGS: Aerial Gaussian Splatting for Distant DBH Measurement", "comment": null, "summary": "Aerial remote sensing enables efficient large-area surveying, but accurate direct object-level measurement remains difficult in complex natural scenes. Recent advancements in 3D vision, particularly learned radiance-field representations such as NeRF and 3D Gaussian Splatting, have begun to raise the ceiling on reconstruction fidelity and densifiable geometry from posed imagery. Nevertheless, direct aerial measurement of important natural attributes such as tree diameter at breast height (DBH) remains challenging. Trunks in aerial forest scans are distant and sparsely observed in image views: at typical operating altitudes, stems may span only a few pixels. With these constraints, conventional reconstruction methods leave breast-height trunk geometry weakly constrained. We present TreeDGS, an aerial image reconstruction method that leverages 3D Gaussian Splatting as a continuous, densifiable scene representation for trunk measurement. After SfM-MVS initialization and Gaussian optimization, we extract a dense point set from the Gaussian field using RaDe-GS's depth-aware cumulative-opacity integration and associate each sample with a multi-view opacity reliability score. We then estimate DBH from trunk-isolated points using opacity-weighted solid-circle fitting. Evaluated on 10 plots with field-measured DBH, TreeDGS reaches 4.79,cm RMSE (about 2.6 pixels at this GSD) and outperforms a state-of-the-art LiDAR baseline (7.91,cm RMSE), demonstrating that densified splat-based geometry can enable accurate, low-cost aerial DBH measurement.", "AI": {"tldr": "本文提出了一种名为 TreeDGS 的方法，利用 3D 高斯泼溅技术从航空影像中精确测量树木的胸径 (DBH)，并在真实数据集上取得了优于 LiDAR 的结果。", "motivation": "在复杂的自然场景中，利用航空遥感进行高精度的对象级测量（尤其是树木的胸径）仍然是一个挑战，因为树干在影像中通常像素稀疏且视角有限。", "method": "TreeDGS 方法首先使用 SfM-MVS 进行初始化和高斯优化，然后从高斯场中提取密集点集，并计算每个点的多视图不透明度可靠性得分。最后，通过对孤立的树干点集进行不透明度加权的实心圆拟合来估计胸径。", "result": "TreeDGS 方法在 10 个实测地块上取得了 4.79 cm 的 RMSE，优于 LiDAR 基线（7.91 cm RMSE），证明了其在低成本航空胸径测量方面的准确性。", "conclusion": "基于高斯泼溅技术生成致密几何表示，可以实现比现有方法更准确、更低成本的航空胸径测量。"}}
{"id": "2601.13697", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13697", "abs": "https://arxiv.org/abs/2601.13697", "authors": ["Zhihang Yuan", "Chengyu Yue", "Long Huang", "Litu Ou", "Lei Shi"], "title": "Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning", "comment": "Preprint", "summary": "Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.", "AI": {"tldr": "提出了一种名为 GRADFILTERING 的不确定性感知数据选择框架，通过计算梯度信噪比（G-SNR）来识别高质量的指令调优数据，并能实现更快的模型收敛。", "motivation": "现有的指令调优数据集规模大、噪声多且冗余，导致全数据微调成本高昂且不必要。现有的数据选择方法要么构建昂贵的梯度数据库，要么使用静态分数，忽略了模型不确定性的演变，也未能充分利用 LLM 的可解释性。", "method": "提出 GRADFILTERING 框架，该框架不依赖于特定目标，而是感知不确定性。它使用一个小型 GPT-2 代理模型和一个 LoRA 集成，将每示例梯度聚合为梯度信噪比（G-SNR）效用。", "result": "在大多数 LLM 作为评委的评估和人类评估中，GRADFILTERING 选择的数据子集都能达到或超过随机子集和现有基线方法的性能。在相同的计算预算下，GRADFILTERING 选择的子集比其他竞争性过滤方法收敛更快。", "conclusion": "GRADFILTERING 是一种有效且不确定性感知的数据选择框架，能够识别出对指令调优至关重要的数据，从而提高模型性能并加速收敛过程。"}}
{"id": "2601.13669", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13669", "abs": "https://arxiv.org/abs/2601.13669", "authors": ["Jiayu Lin", "Zhongyu Wei"], "title": "CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks", "comment": null, "summary": "Large language models (LLMs) alignment ensures model behaviors reflect human value. Existing alignment strategies primarily follow two paths: one assumes a universal value set for a unified goal (i.e., one-size-fits-all), while the other treats every individual as unique to customize models (i.e., individual-level). However, assuming a monolithic value space marginalizes minority norms, while tailoring individual models is prohibitively expensive. Recognizing that human society is organized into social clusters with high intra-group value alignment, we propose community-level alignment as a \"middle ground\". Practically, we introduce CommunityBench, the first large-scale benchmark for community-level alignment evaluation, featuring four tasks grounded in Common Identity and Common Bond theory. With CommunityBench, we conduct a comprehensive evaluation of various foundation models on CommunityBench, revealing that current LLMs exhibit limited capacity to model community-specific preferences. Furthermore, we investigate the potential of community-level alignment in facilitating individual modeling, providing a promising direction for scalable and pluralistic alignment.", "AI": {"tldr": "本文提出社区级别对齐（community-level alignment）作为一种新的大语言模型（LLM）对齐方法，旨在解决现有“一刀切”和“个性化”对齐方法的局限性。研究通过构建名为CommunityBench的大规模基准测试，评估了现有LLM在社区级别对齐方面的能力，并探索了社区级别对齐在促进个性化对齐中的潜力。", "motivation": "现有LLM对齐方法要么假设普适价值观（一刀切），忽视少数群体规范；要么为每个个体定制模型，成本高昂。社会通常由具有内部值对齐的社区构成，因此需要一种折衷的方法。", "method": "提出社区级别对齐，并引入第一个大规模的社区级别对齐评估基准CommunityBench。CommunityBench包含四个基于共同身份和共同纽带理论的任务。对多种基础模型进行了CommunityBench的全面评估，并研究了社区级别对齐在促进个性化对齐中的潜力。", "result": "现有LLM在模拟社区特定偏好方面的能力有限。社区级别对齐为实现可扩展和多元化的对齐提供了一个有前途的方向，能够促进个性化对齐。", "conclusion": "社区级别对齐是LLM对齐的一个有前景的新方向，能够平衡普适性和个体化，并可能为更广泛、更精细的LLM对齐提供解决方案。"}}
{"id": "2601.13690", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13690", "abs": "https://arxiv.org/abs/2601.13690", "authors": ["Yue Guo", "Fanfu Wang", "Jianwei Lv", "Xincheng Shi", "Yuchen Li", "Youya Wang", "Yunsheng Zeng", "Yujing Liu", "Yunhao Qiao", "Gen Li", "Junfeng Wang", "Bo Yuan"], "title": "Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning", "comment": null, "summary": "Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.", "AI": {"tldr": "本文提出了一种名为Dr. Assistant的临床诊断模型，该模型通过引入临床诊断推理数据（CDRD）结构和两阶段训练（SFT+RL），显著提升了LLM在临床诊断推理和问询方面的能力，并在新提出的基准测试中表现优于开源模型，与闭源模型相当。", "motivation": "现有的临床决策支持系统（CDSS）维护成本高且泛化能力差；而大型语言模型（LLM）虽然在医学领域有潜力，但在诊断推理和问询能力上存在局限。因此，需要一种能够弥补LLM在临床诊断推理和问询方面不足的解决方案。", "method": "1. 提出临床诊断推理数据（CDRD）结构，用于捕捉抽象的临床推理逻辑，并构建了相应的构建流程。 2. 开发了Dr. Assistant模型，一个具备临床推理和问询能力的模型。 3. 采用了两阶段训练方法：监督微调（SFT）后，进行带有定制奖励函数的强化学习（RL）训练。 4. 创建了一个新的基准测试，用于评估模型的诊断推理和问询能力。", "result": "Dr. Assistant在提出的基准测试中，其诊断推理和问询能力均优于现有的开源模型，并且在性能上可与闭源模型媲美。", "conclusion": "Dr. Assistant模型通过结合CDRD结构和创新的训练方法，能够有效地提升LLM在临床诊断推理和问询方面的能力，为临床诊断问询指导提供了一个有效的解决方案。"}}
{"id": "2601.13707", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13707", "abs": "https://arxiv.org/abs/2601.13707", "authors": ["Yujin Jo", "Sangyoon Bae", "Taesup Kim"], "title": "Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs", "comment": null, "summary": "Hallucinations in large vision-language models (LVLMs) often arise when language priors dominate over visual evidence, causing object misidentification and visually inconsistent descriptions. We address this issue by framing hallucination mitigation as contrastive guidance, steering generation toward visually grounded and semantically faithful text. This approach regulates the model's internal behavior by reducing over-dependence on language priors and contrasting visually grounded with language-only representations. We propose Attention-space Contrastive Guidance (ACG), a single-pass mechanism that operates within self-attention layers to construct both vision-language and language-only attention paths in a single forward computation. This integration enables computationally efficient guidance directly embedded in the model's representation contextualization. To correct approximation bias introduced by the single-pass formulation, we further apply an orthogonalized correction that removes components aligned with the language-only path, selectively amplifying visual contributions. Experiments on the CHAIR and POPE benchmarks show that ACG achieves state-of-the-art faithfulness and caption quality while significantly reducing computational cost. Our method establishes a principled and efficient alternative, reducing latency by up to 2x compared to prior contrastive decoding methods that require multiple forward passes.", "AI": {"tldr": "提出了一种名为注意力空间对比引导 (ACG) 的新机制，通过在自注意力层中引入视觉基础和纯语言表示之间的对比，有效减少大型视觉语言模型 (LVLMs) 的幻觉，同时提高效率。", "motivation": "大型视觉语言模型 (LVLMs) 存在幻觉问题，即语言先验压倒视觉证据，导致对象识别错误和描述不一致。研究旨在解决这个问题。", "method": "提出注意力空间对比引导 (ACG) 机制，通过单次前向计算在自注意力层中构建视觉-语言和纯语言的注意力路径。并通过正交化修正来处理近似偏差，选择性地增强视觉贡献。", "result": "在 CHAIR 和 POPE 基准测试中，ACG 达到了最先进的视觉保真度和字幕质量，同时显著降低了计算成本，延迟最高可减少 2 倍。", "conclusion": "ACG 是一种原则性且高效的幻觉缓解方法，通过对比引导将生成导向视觉基础和语义忠实文本，是现有对比解码方法的有力替代方案。"}}
{"id": "2601.12826", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12826", "abs": "https://arxiv.org/abs/2601.12826", "authors": ["Teerapong Panboonyuen"], "title": "Seeing Isn't Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification", "comment": "7 pages", "summary": "Explainable Artificial Intelligence (XAI) techniques, such as Gradient-weighted Class Activation Mapping (Grad-CAM), have become indispensable for visualizing the reasoning process of deep neural networks in medical image analysis. Despite their popularity, the faithfulness and reliability of these heatmap-based explanations remain under scrutiny. This study critically investigates whether Grad-CAM truly represents the internal decision-making of deep models trained for lung cancer image classification. Using the publicly available IQ-OTH/NCCD dataset, we evaluate five representative architectures: ResNet-50, ResNet-101, DenseNet-161, EfficientNet-B0, and ViT-Base-Patch16-224, to explore model-dependent variations in Grad-CAM interpretability. We introduce a quantitative evaluation framework that combines localization accuracy, perturbation-based faithfulness, and explanation consistency to assess Grad-CAM reliability across architectures. Experimental findings reveal that while Grad-CAM effectively highlights salient tumor regions in most convolutional networks, its interpretive fidelity significantly degrades for Vision Transformer models due to non-local attention behavior. Furthermore, cross-model comparisons indicate substantial variability in saliency localization, implying that Grad-CAM explanations may not always correspond to the true diagnostic evidence used by the networks. This work exposes critical limitations of current saliency-based XAI approaches in medical imaging and emphasizes the need for model-aware interpretability methods that are both computationally sound and clinically meaningful. Our findings aim to inspire a more cautious and rigorous adoption of visual explanation tools in medical AI, urging the community to rethink what it truly means to \"trust\" a model's explanation.", "AI": {"tldr": "本研究评估了 Grad-CAM 在肺癌图像分类中的可解释性，发现其在卷积网络中表现尚可，但在 Vision Transformer 模型中效果显著下降，且在不同模型间存在较大差异，表明基于显著性的 XAI 方法在医学影像领域存在局限性。", "motivation": "现有 XAI 技术（如 Grad-CAM）在医学影像分析中被广泛用于可视化深度学习模型的决策过程，但其有效性和可靠性仍受质疑。本研究旨在深入探究 Grad-CAM 是否真实反映了用于肺癌图像分类的深度模型的内部决策。", "method": "研究使用了公开的 IQ-OTH/NCCD 数据集，评估了 ResNet-50、ResNet-101、DenseNet-161、EfficientNet-B0 和 ViT-Base-Patch16-224 五种模型架构。通过结合定位准确性、扰动敏感性和解释一致性，构建了一个量化评估框架来衡量 Grad-CAM 在不同架构下的可靠性。", "result": "实验结果表明，Grad-CAM 在大多数卷积网络中能有效突出肿瘤区域，但对于 Vision Transformer 模型，由于其非局部注意力机制，解释保真度显著下降。此外，不同模型之间的显著图定位存在较大差异，提示 Grad-CAM 的解释可能并不总是与模型使用的真实诊断依据相符。", "conclusion": "本研究揭示了当前基于显著性的 XAI 方法在医学影像领域存在的关键局限性，并强调了开发计算合理且临床有意义的、模型感知的可解释性方法的需求。研究结果旨在促使医学 AI 领域更审慎、更严谨地采纳可视化解释工具，并重新思考模型解释的“信任”含义。"}}
{"id": "2601.13695", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13695", "abs": "https://arxiv.org/abs/2601.13695", "authors": ["Sifan Li", "Hongkai Chen", "Yujun Cai", "Liyang Chen", "Qingwen Ye", "Yiwei Wang"], "title": "OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens", "comment": null, "summary": "Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.", "AI": {"tldr": "OptiSQL是一个新颖的框架，它通过将表格图像和自然语言问题编码为紧凑的光学标记，直接生成可执行的SQL查询，从而解决了传统文本到SQL方法在处理视觉表格时的局限性。", "motivation": "现有的文本到SQL方法假设表格是以文本形式提供的，这在许多现实世界的场景（如文档或网页中的视觉表格）中并不适用，并且会产生大量的token开销。本研究旨在探索是否可以使用紧凑的光学表示作为可执行语义解析的高效接口。", "method": "OptiSQL框架使用一个面向OCR的视觉编码器，将表格的结构和内容压缩成一组小的光学标记。然后，它在一个预训练的SQL生成解码器上进行微调，同时冻结编码器，以评估表示的充分性。", "result": "在Spider 2.0-Snow的可视化版本上进行的实验表明，OptiSQL在保持高执行精度的同时，将表格输入token的数量减少了一个数量级。鲁棒性分析还表明，光学标记在视觉扰动下能够保留重要的结构信息。", "conclusion": "OptiSQL证明了通过紧凑的光学标记可以有效地从表格图像和自然语言问题生成可执行SQL，这为处理视觉表格数据的语义解析任务提供了一种更高效、更鲁棒的方法。"}}
{"id": "2601.13711", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13711", "abs": "https://arxiv.org/abs/2601.13711", "authors": ["Lotta Kiefer", "Christoph Leiter", "Sotaro Takeshita", "Elena Schmidt", "Steffen Eger"], "title": "GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark", "comment": null, "summary": "Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV.", "AI": {"tldr": "本文介绍了GerAV，一个包含超过60万个标注文本对的德语作者身份验证基准。研究评估了多种模型，并发现微调的大型语言模型在零样本设置下表现优于GPT-5，同时揭示了模型在专业化和泛化能力之间的权衡。", "motivation": "现有作者身份验证研究主要集中在英语，而德语等其他语言的基准和系统性评估却相对缺乏。作者旨在填补这一空白，为德语作者身份验证研究提供一个全面的基准。", "method": "构建了一个名为GerAV的德语作者身份验证基准，数据来自Twitter和Reddit，其中Reddit数据又分为同域和跨域的消息集以及一个基于个人资料的数据集。对强基线模型和最先进模型进行了系统性评估，包括使用微调的大型语言模型。", "result": "最佳模型（微调的大型语言模型）在F1分数上比最新基线高出0.09，并在零样本设置下比GPT-5高出0.08。研究还发现，专门针对特定数据类型训练的模型在匹配条件下表现最佳，但泛化能力较差，通过组合训练数据源可以缓解这一限制。", "conclusion": "GerAV是一个具有挑战性和多功能性的基准，有助于推动德语和跨领域作者身份验证的研究。研究结果表明，模型在专业化和泛化能力之间存在权衡，并且结合多种训练数据源可以提高模型的泛化能力。"}}
{"id": "2601.12865", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12865", "abs": "https://arxiv.org/abs/2601.12865", "authors": ["Xiaowei Fu", "Fuxiang Huang", "Lei Zhang"], "title": "Proxy Robustness in Vision Language Models is Effortlessly Transferable", "comment": null, "summary": "As a pivotal technique for improving the defense of deep models, adversarial robustness transfer via distillation has demonstrated remarkable success in conventional image classification tasks. However, this paradigm encounters critical challenges when applied to vision-language models (VLM) (e.g., CLIP): constructing adversarially robust teacher for large-scale multi-modal models demands prohibitively high computational resources. We bridge this gap by revealing an interesting phenomenon: vanilla CLIP (without adversarial training) exhibits intrinsic defensive capabilities against adversarial examples generated by another CLIP with different architectures. We formally define this as proxy adversarial robustness, and naturally propose a Heterogeneous Proxy Transfer (HPT) framework that establishes cross-architectural robustness distillation channels between CLIP variants, effortlessly enabling the VLM robustness transfer from proxy to target models. Yet, such proxy transfer paradigm easily induces severe overfitting, leading to a sharp degradation in zero-shot natural generalization. To resolve that, we design Generalization-Pivot Decoupling (GPD) by leveraging the difference in learning rate scheduling. This decouples the proxy transfer process into a generalization-anchored warm-up that maintains generalization and a generalization-pulled HPT that promotes adversarial robustness, to achieve an equilibrium between natural generalization and adversarial robustness. Extensive experiments on 15 zero-shot datasets demonstrate the effectiveness of our HPT-GPD method. The code is available at the website of github.com/fxw13/HPT-GPD.", "AI": {"tldr": "该研究提出了一种名为HPT-GPD的框架，通过利用不同架构CLIP模型之间的“代理鲁棒性”来实现视觉语言模型（VLM）的对抗鲁棒性迁移，并解决了代理迁移导致的泛化能力下降问题，在15个零样本数据集上验证了其有效性。", "motivation": "现有的对抗鲁棒性迁移方法在应用于大型视觉语言模型（VLM）时面临计算资源需求过高的问题。研究者希望找到一种更高效的VLM鲁棒性迁移方法。", "method": "1. 提出“代理对抗鲁棒性”概念，即未经过对抗训练的CLIP模型对来自不同架构的CLIP模型的对抗样本具有一定的防御能力。2. 设计异构代理迁移（HPT）框架，利用不同架构CLIP模型之间的代理鲁棒性实现鲁棒性迁移。3. 为解决代理迁移导致的泛化能力下降问题，设计了泛化枢轴解耦（GPD）机制，通过差异化的学习率调度将代理迁移过程解耦为保持泛化的预热阶段和提升对抗鲁棒性的HPT阶段，以平衡泛化能力和对抗鲁棒性。", "result": "在15个零样本数据集上的实验表明，HPT-GPD方法能够有效地实现VLM的对抗鲁棒性迁移，同时保持良好的自然泛化能力。", "conclusion": "通过利用不同架构CLIP模型的代理鲁棒性，并结合泛化枢轴解耦机制，可以实现高效且均衡的VLM对抗鲁棒性迁移，克服了计算资源瓶颈和泛化能力下降的问题。"}}
{"id": "2601.13722", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13722", "abs": "https://arxiv.org/abs/2601.13722", "authors": ["Yulin Hu", "Zimo Long", "Jiahe Guo", "Xingyu Sui", "Xing Fu", "Weixiang Zhao", "Yanyan Zhao", "Bing Qin"], "title": "OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents", "comment": null, "summary": "Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In fact, agents may overuse personal information, producing responses that feel forced, intrusive, or socially inappropriate to users. We refer to this issue as \\emph{over-personalization}. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce \\textbf{OP-Bench} a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using \\textbf{OP-Bench}, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose \\textbf{Self-ReCheck}, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.", "AI": {"tldr": "该研究提出了一个新的基准OP-Bench来评估记忆增强型对话代理的“过度个性化”问题，并提出了一种名为Self-ReCheck的内存过滤机制来解决这个问题。", "motivation": "现有的对话代理评估主要关注记忆检索和应用，而忽略了个人信息的恰当使用，可能导致代理过度利用用户个人信息，产生不恰当的回应。", "method": "1. 形式化过度个性化为三种类型：不相关性、重复性和谄媚性。2. 构建了一个包含1700个实例的OP-Bench基准。3. 评估了多种大型语言模型和内存增强方法在OP-Bench上的表现。4. 提出了一种名为Self-ReCheck的内存过滤机制。", "result": "1. 内存增强会普遍导致过度个性化。2. 对话代理倾向于在不必要时检索和过度关注用户记忆。3. Self-ReCheck能够减轻过度个性化，同时保持个性化性能。", "conclusion": "过度个性化是内存增强对话系统中的一个普遍问题，Self-ReCheck是一种有效的缓解该问题的方法，有助于实现更可控和恰当的个性化。"}}
{"id": "2601.12876", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12876", "abs": "https://arxiv.org/abs/2601.12876", "authors": ["Zhenxuan Lu", "Zhihua Xu", "Zhijing Yang", "Feng Gao", "Yongyi Lu", "Keze Wang", "Tianshui Chen"], "title": "Exploring Talking Head Models With Adjacent Frame Prior for Speech-Preserving Facial Expression Manipulation", "comment": "Accepted by ACM Transactions on Multimedia Computing, Communications, and Applications", "summary": "Speech-Preserving Facial Expression Manipulation (SPFEM) is an innovative technique aimed at altering facial expressions in images and videos while retaining the original mouth movements. Despite advancements, SPFEM still struggles with accurate lip synchronization due to the complex interplay between facial expressions and mouth shapes. Capitalizing on the advanced capabilities of audio-driven talking head generation (AD-THG) models in synthesizing precise lip movements, our research introduces a novel integration of these models with SPFEM. We present a new framework, Talking Head Facial Expression Manipulation (THFEM), which utilizes AD-THG models to generate frames with accurately synchronized lip movements from audio inputs and SPFEM-altered images. However, increasing the number of frames generated by AD-THG models tends to compromise the realism and expression fidelity of the images. To counter this, we develop an adjacent frame learning strategy that finetunes AD-THG models to predict sequences of consecutive frames. This strategy enables the models to incorporate information from neighboring frames, significantly improving image quality during testing. Our extensive experimental evaluations demonstrate that this framework effectively preserves mouth shapes during expression manipulations, highlighting the substantial benefits of integrating AD-THG with SPFEM.", "AI": {"tldr": "提出了一种名为THFEM的新框架，结合了语音驱动的说话人头生成（AD-THG）和保持语音的面部表情操控（SPFEM），以实现面部表情操控同时保持准确的唇部同步。引入了相邻帧学习策略来提高图像质量。", "motivation": "现有的SPFEM技术在准确的唇部同步方面存在挑战，并且AD-THG模型在生成大量帧时会牺牲图像的真实感和表情保真度。研究旨在结合两者的优势，解决这些问题。", "method": "提出THFEM框架，利用AD-THG模型生成具有准确唇部同步的帧，并结合SPFEM进行面部表情操控。开发了相邻帧学习策略，对AD-THG模型进行微调，使其能够利用相邻帧的信息来预测连续帧，从而提高图像质量。", "result": "实验证明，THFEM框架能够有效地在表情操控过程中保持嘴部形状，并显著提高了生成帧的图像质量。", "conclusion": "将AD-THG与SPFEM相结合（THFEM）能够有效地在面部表情操控的同时保持准确的唇部同步，并且通过相邻帧学习策略可以克服AD-THG在生成多帧时的真实感和表情保真度下降的问题。"}}
{"id": "2601.13719", "categories": ["cs.CV", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13719", "abs": "https://arxiv.org/abs/2601.13719", "authors": ["Xinlei Yin", "Xiulian Peng", "Xiao Li", "Zhiwei Xiong", "Yan Lu"], "title": "Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search", "comment": null, "summary": "Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation, typically suffer from information fragmentation and a loss of global coherence. We present HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. First, we preserve semantic consistency by integrating entity-level representations across visual and auditory streams, while organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. Then we employ an agentic search mechanism to enable dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that our method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.", "AI": {"tldr": "提出了一种名为HAVEN的框架，通过整合视听实体凝聚力和分层视频索引以及智能搜索，解决了长视频理解中的信息碎片化和全局不连贯问题，并在LVBench数据集上取得了新的SOTA性能。", "motivation": "现有长视频理解方法（如基于检索增强生成的简单分块策略）存在信息碎片化和全局连贯性丧失的问题，需要更有效的解决方案。", "method": "HAVEN框架整合了视听实体凝聚力（跨视觉和听觉流保留实体级表示）和分层视频索引（全局摘要、场景、片段、实体级别），并结合智能搜索机制进行动态检索和推理，以实现叙事重构和实体追踪。", "result": "在LVBench数据集上，HAVEN实现了84.1%的整体准确率，创下新的SOTA。在具有挑战性的推理任务上表现尤为突出，准确率达到80.1%。实验表明该方法具有良好的时间连贯性、实体一致性和检索效率。", "conclusion": "结构化的、多模态的推理方法对于全面、连贯的长视频理解是有效的，HAVEN框架通过整合实体凝聚力和分层索引以及智能搜索，显著提高了长视频理解的性能。"}}
{"id": "2601.13717", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13717", "abs": "https://arxiv.org/abs/2601.13717", "authors": ["Zehan Li", "Yuxuan Wang", "Ali El Lahib", "Ying-Jieh Xia", "Xinyu Pi"], "title": "Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff", "comment": null, "summary": "Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. We provide the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, we find that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably \"rewind\" model knowledge. We conclude that RF on pre-cutoff events is methodologically flawed; we recommend against using SI-based retrospective setups to benchmark forecasting capabilities.", "AI": {"tldr": "该研究系统地评估了模拟无知（SI）方法在模拟真实无知（TI）以评估大型语言模型（LLM）预测能力方面的有效性。研究发现，SI 无法可靠地抑制模型在知识截止日期后的知识，导致 SI 和 TI 之间存在显著的性能差距，并且即使在推理过程中没有明确引用截止日期后的知识，模型也未能抑制先验知识。研究者建议不要使用基于 SI 的回顾性评估来测试 LLM 的预测能力。", "motivation": "评估大型语言模型（LLM）的预测能力面临一个挑战：前瞻性评估虽然严谨但延迟很高，而后顾性评估（RF）则面临评估数据快速减少的问题，因为 SOTA 模型拥有越来越近的知识截止日期。模拟无知（SI）是一种旨在解决此问题的方法，即通过提示模型抑制截止日期后的知识。", "method": "研究人员通过 477 个竞赛级问题和 9 个模型，系统地测试了模拟无知（SI）是否能够近似真实无知（TI）。他们比较了 SI 和 TI 的性能，并分析了链式思考（Chain-of-Thought）推理和专门优化推理的模型在 SI 场景下的表现。", "result": "研究发现，SI 系统性地失败了。1）截止日期指令导致 SI 和 TI 之间存在 52% 的性能差距。2）链式思考推理未能抑制先验知识，即使推理过程没有明确引用截止日期后的知识。3）经过推理优化的模型在 SI 方面的表现更差，尽管其推理过程质量更高。", "conclusion": "研究结论是，提示指令无法可靠地“回溯”模型的知识。因此，基于截止日期前的事件进行回顾性评估在方法上存在缺陷。研究者不建议使用基于 SI 的回顾性设置来评估 LLM 的预测能力。"}}
{"id": "2601.13734", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13734", "abs": "https://arxiv.org/abs/2601.13734", "authors": ["Chenyu Hui"], "title": "Towards robust long-context understanding of large language model via active recap learning", "comment": "5 pages", "summary": "In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM", "AI": {"tldr": "本文提出了一种名为主动回顾学习（ARL）的框架，通过在持续预训练和推理时进行有针对性的序列构建和回顾性总结，来增强大型语言模型（LLM）对长上下文的理解能力。ARL在RULER和LongBench基准测试中取得了显著的性能提升。", "motivation": "现有的大型语言模型在理解和处理长上下文时存在局限性，研究旨在提出一种有效的方法来增强LLM的长上下文理解能力，实现可扩展的记忆增强。", "method": "ARL框架包含两个主要步骤：1. 在准备长上下文时，通过比较长短前向上下文的损失差异来识别关键token，并找到最相关的先前段落，然后使用LLM进行总结。2. 在推理时，ARL使模型能够自主生成和利用这些回顾性总结，从而建立跨段落的递归记忆机制。", "result": "ARL在RULER数据集上实现了26.8%的性能提升，在LongBench数据集上实现了9.44%的性能提升。", "conclusion": "ARL是一种简单而有效的方法，通过持续预训练来增强LLM的长上下文理解能力，为LLM的可扩展记忆增强提供了新的途径。"}}
{"id": "2601.12889", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12889", "abs": "https://arxiv.org/abs/2601.12889", "authors": ["Nazibul Basar Ayon", "Abdul Hasib", "Md. Faishal Ahmed", "Md. Sadiqur Rahman", "Kamrul Islam", "T. M. Mehrab Hasan", "A. S. M. Ahsanul Sarkar Akib"], "title": "Simultaneous Detection of LSD and FMD in Cattle Using Ensemble Deep Learning", "comment": null, "summary": "Lumpy Skin Disease (LSD) and Foot-and-Mouth Disease (FMD) are highly contagious viral diseases affecting cattle, causing significant economic losses and welfare challenges. Their visual diagnosis is complicated by significant symptom overlap with each other and with benign conditions like insect bites or chemical burns, hindering timely control measures. Leveraging a comprehensive dataset of 10,516 expert-annotated images from 18 farms across India, Brazil, and the USA, this study presents a novel Ensemble Deep Learning framework integrating VGG16, ResNet50, and InceptionV3 with optimized weighted averaging for simultaneous LSD and FMD detection. The model achieves a state-of-the-art accuracy of 98.2\\%, with macro-averaged precision of 98.2\\%, recall of 98.1\\%, F1-score of 98.1\\%, and an AUC-ROC of 99.5\\%. This approach uniquely addresses the critical challenge of symptom overlap in multi-disease detection, enabling early, precise, and automated diagnosis. This tool has the potential to enhance disease management, support global agricultural sustainability, and is designed for future deployment in resource-limited settings.", "AI": {"tldr": "研究提出了一种结合VGG16、ResNet50和InceptionV3的集成深度学习模型，用于同时检测牛身上的牛皮癣（LSD）和口蹄疫（FMD），准确率高达98.2%。", "motivation": "LSD和FMD的视觉诊断因症状与其他疾病（如昆虫叮咬或化学灼伤）的重叠而变得复杂，阻碍了及时的控制措施。", "method": "利用包含10,516张专业标注图像的数据集，集成VGG16、ResNet50和InceptionV3模型，并采用优化的加权平均策略进行LSD和FMD的同时检测。", "result": "模型在准确率（98.2%）、宏平均精度（98.2%）、召回率（98.1%）、F1分数（98.1%）和AUC-ROC（99.5%）方面均达到最先进水平。", "conclusion": "该模型能够早期、精确且自动化地诊断LSD和FMD，解决了多疾病检测中症状重叠的关键挑战，有望改善疾病管理，支持全球农业可持续性，并适用于资源匮乏的环境。"}}
{"id": "2601.12863", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12863", "abs": "https://arxiv.org/abs/2601.12863", "authors": ["Jun Wan", "Xinyu Xiong", "Ning Chen", "Zhihui Lai", "Jie Zhou", "Wenwen Min"], "title": "FGTBT: Frequency-Guided Task-Balancing Transformer for Unified Facial Landmark Detection", "comment": null, "summary": "Recently, deep learning based facial landmark detection (FLD) methods have achieved considerable success. However, in challenging scenarios such as large pose variations, illumination changes, and facial expression variations, they still struggle to accurately capture the geometric structure of the face, resulting in performance degradation. Moreover, the limited size and diversity of existing FLD datasets hinder robust model training, leading to reduced detection accuracy. To address these challenges, we propose a Frequency-Guided Task-Balancing Transformer (FGTBT), which enhances facial structure perception through frequency-domain modeling and multi-dataset unified training. Specifically, we propose a novel Fine-Grained Multi-Task Balancing loss (FMB-loss), which moves beyond coarse task-level balancing by assigning weights to individual landmarks based on their occurrence across datasets. This enables more effective unified training and mitigates the issue of inconsistent gradient magnitudes. Additionally, a Frequency-Guided Structure-Aware (FGSA) model is designed to utilize frequency-guided structure injection and regularization to help learn facial structure constraints. Extensive experimental results on popular benchmark datasets demonstrate that the integration of the proposed FMB-loss and FGSA model into our FGTBT framework achieves performance comparable to state-of-the-art methods. The code is available at https://github.com/Xi0ngxinyu/FGTBT.", "AI": {"tldr": "提出了一种名为FGTBT的基于Transformer的人脸关键点检测方法，通过引入频域建模和多数据集统一训练来提高在复杂场景下的鲁棒性，并提出了FMB-loss和FGSA模型来优化训练和结构感知。", "motivation": "现有基于深度学习的人脸关键点检测方法在面对大姿态、光照和表情变化等挑战性场景时，其几何结构感知能力不足，导致性能下降。同时，现有数据集的规模和多样性有限，也阻碍了模型的鲁棒训练，降低了检测精度。", "method": "提出了一种名为FGTBT（Frequency-Guided Task-Balancing Transformer）的方法。该方法通过频域建模和多数据集统一训练来增强人脸结构感知。具体来说，引入了Fine-Grained Multi-Task Balancing loss（FMB-loss），该损失函数根据关键点在不同数据集的出现频率为其分配权重，实现了更精细的任务平衡。此外，设计了Frequency-Guided Structure-Aware（FGSA）模型，利用频域引导的结构注入和正则化来学习人脸结构约束。", "result": "在多个常用基准数据集上的广泛实验表明，将FMB-loss和FGSA模型集成到FGTBT框架中，性能与现有最先进的方法相当。", "conclusion": "所提出的FGTBT框架，结合FMB-loss和FGSA模型，能够有效地提升人脸关键点检测在复杂场景下的性能，并取得与SOTA方法相当的结果。"}}
{"id": "2601.13749", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13749", "abs": "https://arxiv.org/abs/2601.13749", "authors": ["Benaya Trabelsi", "Jonathan Shaki", "Sarit Kraus"], "title": "Pro-AI Bias in Large Language Models", "comment": "13 pages, 6 figures. Code available at: https://github.com/benayat/Pro-AI-bias-in-LLMs", "summary": "Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.", "AI": {"tldr": "大型语言模型（LLM）在决策支持中存在系统性的偏向人工智能（AI）自身的倾向，表现为偏好推荐AI相关选项、高估AI相关工作的薪资，并且在内部表征中AI具有中心地位。", "motivation": "研究者旨在探究大型语言模型（LLM）在作为决策支持工具时，是否会系统性地偏向人工智能（AI）自身。", "method": "通过三个互补的实验进行研究：1. 分析LLM在回答不同咨询类问题时对AI相关选项的推荐比例；2. 比较LLM对AI相关职位和非AI相关职位的薪资估算差异；3. 探测开放权重模型内部表征，分析“人工智能”与其他学术领域提示词的相似性。", "result": "研究发现LLM普遍存在亲AI偏见。LLM倾向于推荐AI相关选项，特别是专有模型几乎是确定性地推荐。LLM系统性地高估AI相关职位的薪资，专有模型高估幅度达10个百分点。内部表征分析显示，“人工智能”在各种情感框架下均与通用学术领域提示词表现出最高的相似度，表明其在表征上的中心性，且不受情感色彩影响。", "conclusion": "LLM生成的建议和估值可能系统性地影响高风险决策中的选择和认知，存在明显的亲AI偏见。"}}
{"id": "2601.13742", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13742", "abs": "https://arxiv.org/abs/2601.13742", "authors": ["Arjun Chandra", "Kevin Miller", "Venkatesh Ravichandran", "Constantinos Papayiannis", "Venkatesh Saligrama"], "title": "Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues", "comment": "EACL 2026 Findings", "summary": "Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achieve cost-efficient and human-aligned S2S evaluation. To demonstrate the strength of the framework, we first introduce a Human Chain-of-Thought (HCoT) annotation protocol to improve the diagnostic capability of existing judge benchmarks by separating evaluation into explicit dimensions: content (C), voice quality (VQ), and paralinguistics (P). Using this data, TRACE constructs a textual blueprint of inexpensive audio signals and prompts an LLM to render dimension-wise judgments, fusing them into an overall rating via a deterministic policy. TRACE achieves higher agreement with human raters than ALMs and transcript-only LLM judges while being significantly more cost-effective. We will release the HCoT annotations and the TRACE framework to enable scalable and human-aligned S2S evaluation.", "AI": {"tldr": "提出了一种名为TRACE的新框架，它能让大型语言模型（LLM）通过分析音频线索来评估语音到语音（S2S）的转换质量，从而实现比现有方法更具成本效益且与人类评估一致的评估。", "motivation": "目前的大型语言模型（LLM）在评估语音到语音（S2S）转换时受到仅能处理文本内容的限制，这导致现有的自动S2S评估方法依赖于不透明且昂贵的音频语言模型（ALM）。因此，需要一种能够让LLM利用音频线索进行推理，从而实现成本效益高且与人类评估一致的S2S评估方法。", "method": "该研究引入了一种名为TRACE（Textual Reasoning over Audio Cues for Evaluation）的框架。首先，通过一种名为人类思维链（HCoT）的标注协议，将评估分解为内容（C）、音质（VQ）和副语言（P）三个维度，以提高现有评判基准的诊断能力。然后，利用此数据，TRACE构建了一个廉价音频信号的文本蓝图，并提示LLM进行维度判断，最后通过确定性策略将这些判断融合成一个总体评分。", "result": "TRACE框架在与人类评分者的一致性方面优于ALM和仅依赖文本的LLM评估方法，同时在成本效益方面也显著提高。", "conclusion": "TRACE框架能够让LLM通过推理音频线索来评估S2S质量，从而在不牺牲评估质量的情况下，实现比现有方法更经济高效且与人类评估一致的S2S评估。研究者将发布HCoT标注数据和TRACE框架，以支持可扩展且与人类评估一致的S2S评估。"}}
{"id": "2601.13802", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.13802", "abs": "https://arxiv.org/abs/2601.13802", "authors": ["Yushen Chen", "Junzhe Liu", "Yujie Tu", "Zhikang Niu", "Yuzhe Liang", "Kai Yu", "Chunyu Qiang", "Chen Zhang", "Xie Chen"], "title": "Habibi: Laying the Open-Source Foundation of Unified-Dialectal Arabic Speech Synthesis", "comment": null, "summary": "A notable gap persists in speech synthesis research and development for Arabic dialects, particularly from a unified modeling perspective. Despite its high practical value, the inherent linguistic complexity of Arabic dialects, further compounded by a lack of standardized data, benchmarks, and evaluation guidelines, steers researchers toward safer ground. To bridge this divide, we present Habibi, a suite of specialized and unified text-to-speech models that harnesses existing open-source ASR corpora to support a wide range of high- to low-resource Arabic dialects through linguistically-informed curriculum learning. Our approach outperforms the leading commercial service in generation quality, while maintaining extensibility through effective in-context learning, without requiring text diacritization. We are committed to open-sourcing the model, along with creating the first systematic benchmark for multi-dialect Arabic speech synthesis. Furthermore, by identifying the key challenges in and establishing evaluation standards for the process, we aim to provide a solid groundwork for subsequent research. Resources at https://SWivid.github.io/Habibi/ .", "AI": {"tldr": "本文提出了Habibi，一个统一的阿拉伯语方言文本到语音模型套件，该套件利用现有ASR语料库，通过课程学习支持高资源和低资源方言，并且不需要文本注音，在生成质量上优于领先的商业服务。", "motivation": "阿拉伯语方言语音合成研究存在明显空白，尤其是在统一建模方面，尽管其具有很高的实用价值。阿拉伯语方言固有的语言复杂性以及标准化数据、基准和评估指南的缺乏，阻碍了该领域的研究。", "method": "利用现有的开源ASR语料库，通过语言学导向的课程学习，构建了一个专门的、统一的文本到语音模型套件（Habibi），支持多种高资源和低资源阿拉伯语方言。该方法无需文本注音，并利用了有效的上下文学习。", "result": "Habibi模型在生成质量上优于领先的商业服务，并且具有良好的可扩展性。研究还首次建立了多方言阿拉伯语语音合成的系统性基准。", "conclusion": "Habibi模型为阿拉伯语方言语音合成提供了一个有效的、统一的解决方案，解决了该领域面临的挑战，并为未来的研究奠定了坚实的基础。研究人员承诺开源该模型并创建相关基准。"}}
{"id": "2601.13885", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13885", "abs": "https://arxiv.org/abs/2601.13885", "authors": ["Esma Balkır", "Alice Pernthaller", "Marco Basaldella", "José Hernández-Orallo", "Nigel Collier"], "title": "Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores", "comment": null, "summary": "Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 τ over random sampling, with 95% accuracy on confident predictions.", "AI": {"tldr": "提出一种基于IRT的自适应测试方法，用于连续有界分数（如ROUGE、BLEU、LLM-as-a-Judge）的LLM评估，并引入一个考虑不确定性的排序器和自适应停止准则，以在最少测试项目和最低成本下实现可靠的模型排名。", "motivation": "现有的计算机化自适应测试（CAT）主要用于多项选择题评估，但现代LLM评估越来越依赖生成任务，其输出得分是连续的，而不是简单的对/错。需要一种方法来扩展CAT以适应这种连续评分场景。", "method": "通过用异方差正态分布替代伯努利分布，将基于IRT的自适应测试扩展到连续有界分数。在此基础上，提出一个考虑不确定性的排序器，并结合自适应停止准则，以最小化测试成本同时保证排名可靠性。", "result": "在五个不同基准（n-gram、嵌入式、LLM-as-judge指标）上进行了验证。该方法仅使用2%的测试项目，但排名相关性比随机抽样提高了0.12 τ，并且在自信预测下准确率达到95%。", "conclusion": "所提出的基于IRT的自适应测试方法能够有效地处理连续有界评分的LLM生成任务评估，并在成本效益和排名准确性方面优于传统方法。"}}
{"id": "2601.13798", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13798", "abs": "https://arxiv.org/abs/2601.13798", "authors": ["Kai Wittenmayer", "Sukrut Rao", "Amin Parchami-Araghi", "Bernt Schiele", "Jonas Fischer"], "title": "Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders", "comment": "32 pages, 24 figures, 3 tables", "summary": "Language-aligned vision foundation models perform strongly across diverse downstream tasks. Yet, their learned representations remain opaque, making interpreting their decision-making hard. Recent works decompose these representations into human-interpretable concepts, but provide poor spatial grounding and are limited to image classification tasks. In this work, we propose Insight, a language-aligned concept foundation model that provides fine-grained concepts, which are human-interpretable and spatially grounded in the input image. We leverage a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. Examining local co-occurrence dependencies of concepts allows us to define concept relationships. Through these relations we further improve concept naming and obtain richer explanations. On benchmark data, we show that Insight provides performance on classification and segmentation that is competitive with opaque foundation models while providing fine-grained, high quality concept-based explanations. Code is available at https://github.com/kawi19/Insight.", "AI": {"tldr": "本文提出了Insight，一个语言对齐的概念基础模型，能够提取细粒度、人类可解释且在图像中具有空间定位的概念，用于理解视觉基础模型的决策过程。Insight通过分层稀疏自编码器和具有强大语义表示的基础模型自动提取概念，并利用概念间的局部共现依赖性定义概念关系，进一步优化概念命名和解释的丰富性。实验证明，Insight在分类和分割任务上的性能可与不透明的基础模型媲美，同时提供高质量的概念解释。", "motivation": "现有的语言对齐视觉基础模型的表示是“不透明”的，难以理解其决策过程。虽然一些工作尝试将这些表示分解为可解释的概念，但它们缺乏良好的空间定位，并且仅限于图像分类任务。因此，需要一个能够提供细粒度、空间定位且可解释的概念模型。", "method": "本文提出了Insight，一个语言对齐的概念基础模型。Insight利用分层稀疏自编码器和具有强大语义表示的基础模型，自动提取不同粒度的细粒度、人类可解释且在输入图像中具有空间定位的概念。通过检查概念的局部共现依赖性来定义概念关系，并利用这些关系进一步改善概念命名和获得更丰富的解释。", "result": "在基准数据集上，Insight在分类和分割任务上的表现与不透明的基础模型相当。同时，Insight能够提供细粒度、高质量的概念解释。", "conclusion": "Insight成功地提供了一个能够生成细粒度、空间定位且人类可解释的概念表示的语言对齐模型，为理解视觉基础模型的决策提供了新的途径，并在下游任务中取得了具有竞争力的性能。"}}
{"id": "2601.12895", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12895", "abs": "https://arxiv.org/abs/2601.12895", "authors": ["Chan Naseeb", "Adeel Ashraf Cheema", "Hassan Sami", "Tayyab Afzal", "Muhammad Omair", "Usman Habib"], "title": "TwoHead-SwinFPN: A Unified DL Architecture for Synthetic Manipulation, Detection and Localization in Identity Documents", "comment": "8 pages", "summary": "The proliferation of sophisticated generative AI models has significantly escalated the threat of synthetic manipulations in identity documents, particularly through face swapping and text inpainting attacks. This paper presents TwoHead-SwinFPN, a unified deep learning architecture that simultaneously performs binary classification and precise localization of manipulated regions in ID documents. Our approach integrates a Swin Transformer backbone with Feature Pyramid Network (FPN) and UNet-style decoder, enhanced with Convolutional Block Attention Module (CBAM) for improved feature representation. The model employs a dual-head architecture for joint optimization of detection and segmentation tasks, utilizing uncertainty-weighted multi-task learning. Extensive experiments on the FantasyIDiap dataset demonstrate superior performance with 84.31\\% accuracy, 90.78\\% AUC for classification, and 57.24\\% mean Dice score for localization. The proposed method achieves an F1-score of 88.61\\% for binary classification while maintaining computational efficiency suitable for real-world deployment through FastAPI implementation. Our comprehensive evaluation includes ablation studies, cross-device generalization analysis, and detailed performance assessment across 10 languages and 3 acquisition devices.", "AI": {"tldr": "本文提出了一种名为TwoHead-SwinFPN的统一深度学习模型，能够同时检测和定位身份识别文件中的合成篡改（如换脸和文本修复）。该模型结合了Swin Transformer、FPN和CBAM，并通过不确定性加权多任务学习来优化检测和分割任务。实验表明，该模型在FantasyIDiap数据集上表现出色，分类准确率和AUC均很高，定位精度也达到较高水平，并且实现了计算效率。", "motivation": "生成式AI的兴起加剧了身份识别文件中合成篡改（如换脸和文本修复）的威胁，迫切需要一种能够同时检测和定位这些篡改的有效方法。", "method": "提出了TwoHead-SwinFPN，一个集成了Swin Transformer骨干网络、特征金字塔网络（FPN）和UNet风格解码器的统一深度学习架构。该模型使用卷积块注意力模块（CBAM）增强特征表示，并采用双头架构，通过不确定性加权多任务学习同时优化二元分类（检测篡改）和语义分割（定位篡改区域）任务。", "result": "在FantasyIDiap数据集上，TwoHead-SwinFPN在二元分类任务上取得了84.31%的准确率和90.78%的AUC。在定位任务上，平均Dice分数达到57.24%。整体F1-score为88.61%。模型通过FastAPI实现，具有适合实际部署的计算效率。此外，消融研究、跨设备泛化分析以及跨10种语言和3种采集设备的性能评估也进行了详细展示。", "conclusion": "TwoHead-SwinFPN是一种有效的统一深度学习架构，能够同时高精度地检测和定位身份识别文件中的合成篡改。该模型在性能和计算效率之间取得了良好平衡，使其能够有效地应用于实际场景。"}}
{"id": "2601.12919", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12919", "abs": "https://arxiv.org/abs/2601.12919", "authors": ["Jun Wan", "Yuanzhi Yao", "Zhihui Lai", "Jie Zhou", "Xianxu Hou", "Wenwen Min"], "title": "Supervision-by-Hallucination-and-Transfer: A Weakly-Supervised Approach for Robust and Precise Facial Landmark Detection", "comment": null, "summary": "High-precision facial landmark detection (FLD) relies on high-resolution deep feature representations. However, low-resolution face images or the compression (via pooling or strided convolution) of originally high-resolution images hinder the learning of such features, thereby reducing FLD accuracy. Moreover, insufficient training data and imprecise annotations further degrade performance. To address these challenges, we propose a weakly-supervised framework called Supervision-by-Hallucination-and-Transfer (SHT) for more robust and precise FLD. SHT contains two novel mutually enhanced modules: Dual Hallucination Learning Network (DHLN) and Facial Pose Transfer Network (FPTN). By incorporating FLD and face hallucination tasks, DHLN is able to learn high-resolution representations with low-resolution inputs for recovering both facial structures and local details and generating more effective landmark heatmaps. Then, by transforming faces from one pose to another, FPTN can further improve landmark heatmaps and faces hallucinated by DHLN for detecting more accurate landmarks. To the best of our knowledge, this is the first study to explore weakly-supervised FLD by integrating face hallucination and facial pose transfer tasks. Experimental results of both face hallucination and FLD demonstrate that our method surpasses state-of-the-art techniques.", "AI": {"tldr": "本文提出了一种名为SHT（Supervision-by-Hallucination-and-Transfer）的弱监督框架，用于提高人脸关键点检测的精度和鲁棒性，该框架结合了人脸细节恢复和姿态迁移任务。", "motivation": "低分辨率人脸图像或特征表示的压缩会阻碍高精度人脸关键点检测学习，导致准确率下降。同时，训练数据不足和标注不精确也进一步降低了性能。", "method": "提出SHT框架，包含两个相互增强的模块：1. 双重细节恢复学习网络（DHLN），结合人脸关键点检测和人脸细节恢复任务，用低分辨率输入学习高分辨率表示，恢复面部结构和细节，生成更有效的关键点热图。2. 人脸姿态迁移网络（FPTN），通过将人脸从一个姿态转换为另一个姿态，进一步改进DHLN生成的热图和细节，以检测更精确的关键点。", "result": "实验结果表明，SHT框架在人脸细节恢复和人脸关键点检测任务上均优于现有最先进的技术。", "conclusion": "SHT是首个将人脸细节恢复和人脸姿态迁移任务整合到弱监督人脸关键点检测中的研究，能够有效地提升人脸关键点检测的精度和鲁棒性。"}}
{"id": "2601.13806", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13806", "abs": "https://arxiv.org/abs/2601.13806", "authors": ["Dezhao Song", "Guglielmo Bonifazi", "Frank Schilder", "Jonathan Richard Schwarz"], "title": "Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning", "comment": null, "summary": "LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-training. In this paper, we propose a knowledge graph (KG)-assisted approach for enhancing LLMs' reasoning capability in Legal that is generalizable to other high-stakes domains. We model key legal concepts by following the \\textbf{IRAC} (Issue, Rule, Analysis and Conclusion) framework, and construct a KG with 12K legal cases. We then produce training data using our IRAC KG, and conduct both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) with three state-of-the-art (SOTA) LLMs (30B, 49B and 70B), varying architecture and base model family. Our post-trained models obtained better average performance on 4/5 diverse legal benchmarks (14 tasks) than baselines. In particular, our 70B DPO model achieved the best score on 4/6 reasoning tasks, among baselines and a 141B SOTA legal LLM, demonstrating the effectiveness of our KG for enhancing LLMs' legal reasoning capability.", "AI": {"tldr": "本研究提出了一种知识图谱（KG）辅助的方法，利用法律领域的IRAC框架构建知识图谱，并生成训练数据，通过SFT和DPO微调大型语言模型（LLMs），显著提升了LLMs在法律推理任务上的表现。", "motivation": "现有的大型语言模型（LLMs）在领域知识结构方面存在不足，导致在处理复杂推理任务（尤其是在法律等高风险专业领域）时表现不佳。法律推理需要对法律概念之间的关系有深入理解，而这是当前LLM后训练方法所缺失的。", "method": "研究者提出了一个知识图谱（KG）辅助的方法，该方法首先遵循IRAC（Issue, Rule, Analysis and Conclusion）框架对关键法律概念进行建模，并构建了一个包含12,000个法律案例的知识图谱。然后，利用该IRAC KG生成训练数据，并对三种最先进的LLMs（30B, 49B, 70B）进行了监督微调（SFT）和直接偏好优化（DPO）。", "result": "经过后训练的模型在4/5个多样化的法律基准测试（共14项任务）上的平均表现优于基线模型。特别是，研究者提出的70B DPO模型在4/6项推理任务上取得了最佳分数，超越了基线模型和一个141B的最先进法律LLM。", "conclusion": "本研究提出的知识图谱辅助方法能够有效增强LLMs在法律推理方面的能力，且该方法可以泛化到其他高风险领域。"}}
{"id": "2601.12926", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12926", "abs": "https://arxiv.org/abs/2601.12926", "authors": ["Jun Wan", "Jun Liu", "Zhihui lai", "Jie Zhou"], "title": "Dual-Stream Collaborative Transformer for Image Captioning", "comment": null, "summary": "Current region feature-based image captioning methods have progressed rapidly and achieved remarkable performance. However, they are still prone to generating irrelevant descriptions due to the lack of contextual information and the over-reliance on generated partial descriptions for predicting the remaining words. In this paper, we propose a Dual-Stream Collaborative Transformer (DSCT) to address this issue by introducing the segmentation feature. The proposed DSCT consolidates and then fuses the region and segmentation features to guide the generation of caption sentences. It contains multiple Pattern-Specific Mutual Attention Encoders (PSMAEs) and Dynamic Nomination Decoders (DNDs). The PSMAE effectively highlights and consolidates the private information of two representations by querying each other. The DND dynamically searches for the most relevant learning blocks to the input textual representations and exploits the homogeneous features between the consolidated region and segmentation features to generate more accurate and descriptive caption sentences. To the best of our knowledge, this is the first study to explore how to fuse different pattern-specific features in a dynamic way to bypass their semantic inconsistencies and spatial misalignment issues for image captioning. The experimental results from popular benchmark datasets demonstrate that our DSCT outperforms the state-of-the-art image captioning models in the literature.", "AI": {"tldr": "提出了一种双流协同Transformer（DSCT）模型，通过融合区域特征和分割特征来生成更准确的图像描述，解决了现有方法依赖部分描述预测的不足。", "motivation": "现有的基于区域特征的图像描述生成方法，由于缺乏上下文信息和过度依赖已生成的部分描述，容易产生不相关的描述。", "method": "提出了一种双流协同Transformer（DSCT），引入分割特征，并通过模式特定互斥注意力编码器（PSMAEs）融合区域和分割特征，利用动态提名解码器（DNDs）生成更准确的描述。", "result": "DSCT模型在流行的基准数据集上取得了优于现有最先进图像描述生成模型的性能。", "conclusion": "DSCT模型通过动态融合不同模式的特征，有效解决了语义不一致和空间错位问题，从而生成更准确和具有描述性的图像标题。"}}
{"id": "2601.13729", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13729", "abs": "https://arxiv.org/abs/2601.13729", "authors": ["Weichuan Wang", "Mingyang Liu", "Linqi Song", "Chen Ma"], "title": "On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation", "comment": "9 pages, 12 figures", "summary": "In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT.", "AI": {"tldr": "本文研究了机器翻译（MT）中的非确定性现象（ND-MT），发现其在解决多模态问题和生成高质量候选译文方面具有潜力，但现有的评估框架无法准确评估ND-MT。研究提出了“Buckets效应”，即最低质量的候选译文决定了ND-MT系统的排名，并提出了一种名为ExpectoSample的评估策略。", "motivation": "研究动机是机器翻译（MT）的非确定性属性在实际应用中受到广泛关注，但在此类复杂的非确定性任务上的探索不足。现有为确定性MT设计的评估框架无法准确评估非确定性MT（ND-MT），因此需要新的评估方法。", "method": "本文系统性地评估了现代MT系统，识别了温度约束下的非确定性MT（ND-MT）现象。研究人员在三个公开数据集上，使用词汇和语义指标，并在不同采样大小下，评估了五个最先进的ND-MT系统。最后，提出了一种名为ExpectoSample的策略来自动评估评估指标的可靠性。", "result": "研究发现了ND-MT在解决多模态问题和生成高质量候选译文方面的潜力。此外，研究揭示了一个“Buckets效应”：ND-MT生成的最低质量的候选译文在所有合理的指标下，都决定了系统在不同采样大小下的整体排名。", "conclusion": "ND-MT是一种值得研究的现象，它在MT领域具有潜力，但也带来了评估上的挑战。现有的评估方法需要改进，提出的Buckets效应揭示了ND-MT评估的特定行为，而ExpectoSample策略为评估ND-MT系统的可靠性提供了一种自动化的解决方案。"}}
{"id": "2601.13835", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13835", "abs": "https://arxiv.org/abs/2601.13835", "authors": ["Sam OConnor Russell", "Delphine Charuau", "Naomi Harte"], "title": "The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations", "comment": "Accepted to ICASSP 2026", "summary": "Fluid turn-taking remains a key challenge in human-robot interaction. Self-supervised speech representations (S3Rs) have driven many advances, but it remains unclear whether S3R-based turn-taking models rely on prosodic cues, lexical cues or both. We introduce a vocoder-based approach to control prosody and lexical cues in speech more cleanly than prior work. This allows us to probe the voice-activity projection model, an S3R-based turn-taking model. We find that prediction on prosody-matched, unintelligible noise is similar to accuracy on clean speech. This reveals both prosodic and lexical cues support turn-taking, but either can be used in isolation. Hence, future models may only require prosody, providing privacy and potential performance benefits. When either prosodic or lexical information is disrupted, the model exploits the other without further training, indicating they are encoded in S3Rs with limited interdependence. Results are consistent in CPC-based and wav2vec2.0 S3Rs. We discuss our findings and highlight a number of directions for future work. All code is available to support future research.", "AI": {"tldr": "研究发现，基于自监督语音表示（S3R）的语音转接模型依赖于韵律和词汇线索，但其中任何一个线索都可以独立使用。这为未来只依赖韵律的更具隐私性和潜在更高性能的模型提供了可能性。", "motivation": "当前机器人交互中的语音转接仍是一个挑战，且尚不清楚基于S3R的转接模型依赖于韵律线索、词汇线索还是两者兼而有之。", "method": "提出了一种基于声码器的、比先前工作更能清晰地控制语音韵律和词汇线索的方法，用于探究基于S3R的语音活动预测模型。", "result": "在韵律匹配但无法理解的噪声上进行的预测准确率与在清晰语音上的准确率相似。这表明韵律和词汇线索都支持语音转接，但可以单独使用。当韵律或词汇信息被干扰时，模型无需进一步训练即可利用另一条线索，表明它们在S3R中编码时相互依赖性有限。", "conclusion": "未来的语音转接模型可能只需要韵律信息，这可以带来隐私和性能上的优势。研究结果在基于CPC和wav2vec2.0的S3R中均得到一致验证。"}}
{"id": "2601.12948", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12948", "abs": "https://arxiv.org/abs/2601.12948", "authors": ["Riccardo Catalini", "Davide Di Nucci", "Guido Borghi", "Davide Davoli", "Lorenzo Garattoni", "Giampiero Francesca", "Yuki Kawana", "Roberto Vezzani"], "title": "GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation", "comment": null, "summary": "We introduce GazeD, a new 3D gaze estimation method that jointly provides 3D gaze and human pose from a single RGB image. Leveraging the ability of diffusion models to deal with uncertainty, it generates multiple plausible 3D gaze and pose hypotheses based on the 2D context information extracted from the input image. Specifically, we condition the denoising process on the 2D pose, the surroundings of the subject, and the context of the scene. With GazeD we also introduce a novel way of representing the 3D gaze by positioning it as an additional body joint at a fixed distance from the eyes. The rationale is that the gaze is usually closely related to the pose, and thus it can benefit from being jointly denoised during the diffusion process. Evaluations across three benchmark datasets demonstrate that GazeD achieves state-of-the-art performance in 3D gaze estimation, even surpassing methods that rely on temporal information. Project details will be available at https://aimagelab.ing.unimore.it/go/gazed.", "AI": {"tldr": "GazeD是一种新的3D注视点估计方法，通过单一RGB图像同时估计3D注视点和人体姿态，并利用扩散模型处理不确定性，生成多个可能的注视点和姿态假设。", "motivation": "研究动机是开发一种能够从单张RGB图像中同时估计3D注视点和人体姿态的方法，并利用扩散模型处理其固有的不确定性。", "method": "该方法采用扩散模型，将2D姿态、主体周围环境和场景上下文作为条件，生成多个3D注视点和姿态假设。它将3D注视点表示为一个与眼睛固定距离的额外身体关节，以便与姿态一起去噪。", "result": "在三个基准数据集上的评估表明，GazeD在3D注视点估计方面取得了最先进的性能，甚至优于依赖时间信息的现有方法。", "conclusion": "GazeD通过将3D注视点估计和人体姿态估计联合起来，并利用扩散模型的强大能力，实现了高性能的3D注视点估计，并在多个数据集上验证了其有效性。"}}
{"id": "2601.12936", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12936", "abs": "https://arxiv.org/abs/2601.12936", "authors": ["Tianran Ouyang", "Xingping Dong", "Jing Zhang", "Mang Ye", "Jun Chen", "Bo Du"], "title": "QASA: Quality-Guided K-Adaptive Slot Attention for Unsupervised Object-Centric Learning", "comment": null, "summary": "Slot Attention, an approach that binds different objects in a scene to a set of \"slots\", has become a leading method in unsupervised object-centric learning. Most methods assume a fixed slot count K, and to better accommodate the dynamic nature of object cardinality, a few works have explored K-adaptive variants. However, existing K-adaptive methods still suffer from two limitations. First, they do not explicitly constrain slot-binding quality, so low-quality slots lead to ambiguous feature attribution. Second, adding a slot-count penalty to the reconstruction objective creates conflicting optimization goals between reducing the number of active slots and maintaining reconstruction fidelity. As a result, they still lag significantly behind strong K-fixed baselines. To address these challenges, we propose Quality-Guided K-Adaptive Slot Attention (QASA). First, we decouple slot selection from reconstruction, eliminating the mutual constraints between the two objectives. Then, we propose an unsupervised Slot-Quality metric to assess per-slot quality, providing a principled signal for fine-grained slot--object binding. Based on this metric, we design a Quality-Guided Slot Selection scheme that dynamically selects a subset of high-quality slots and feeds them into our newly designed gated decoder for reconstruction during training. At inference, token-wise competition on slot attention yields a K-adaptive outcome. Experiments show that QASA substantially outperforms existing K-adaptive methods on both real and synthetic datasets. Moreover, on real-world datasets QASA surpasses K-fixed methods.", "AI": {"tldr": "提出了一种名为QASA的质量引导式K自适应Slot Attention方法，用于解决无监督物体中心学习中现有K自适应方法的局限性，通过解耦槽选择与重建、引入槽质量度量以及设计质量引导式槽选择机制，显著提升了性能，并在真实世界数据集上超越了K固定方法。", "motivation": "现有K自适应Slot Attention方法在约束槽绑定质量和处理重建保真度与槽数量减少之间的冲突方面存在不足，导致性能落后于K固定方法。", "method": "提出QASA方法，包括：1.解耦槽选择与重建；2.提出无监督的槽质量度量来评估每个槽的质量；3.设计质量引导式槽选择方案，动态选择高质量槽并输入到门控解码器进行训练；4.在推理时，通过槽注意力中的令牌级竞争实现K自适应。", "result": "QASA在合成和真实数据集上均显著优于现有的K自适应方法。在真实世界数据集上，QASA的性能甚至超越了K固定方法。", "conclusion": "QASA通过解耦重建和槽选择、引入质量度量以及优化槽选择机制，有效地解决了现有K自适应Slot Attention方法的关键问题，实现了更优的无监督物体中心学习性能，并在真实数据上展现出超越K固定方法的潜力。"}}
{"id": "2601.13895", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13895", "abs": "https://arxiv.org/abs/2601.13895", "authors": ["Xu Zhang", "Danyang Li", "Yingjie Xia", "Xiaohang Dong", "Hualong Yu", "Jianye Wang", "Qicheng Li"], "title": "OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3", "comment": null, "summary": "Change Detection (CD) is a fundamental task in remote sensing. It monitors the evolution of land cover over time. Based on this, Open-Vocabulary Change Detection (OVCD) introduces a new requirement. It aims to reduce the reliance on predefined categories. Existing training-free OVCD methods mostly use CLIP to identify categories. These methods also need extra models like DINO to extract features. However, combining different models often causes problems in matching features and makes the system unstable. Recently, the Segment Anything Model 3 (SAM 3) is introduced. It integrates segmentation and identification capabilities within one promptable model, which offers new possibilities for the OVCD task. In this paper, we propose OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, we propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. As a result, the model can generate accurate change masks. Experiments on four public benchmarks (LEVIR-CD, WHU-CD, S2Looking, and SECOND) demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods.", "AI": {"tldr": "本文提出了 OmniOVCD，一个独立的开放词汇变化检测框架，利用 SAM 3 的解耦输出和一种新的 SFID 策略，实现了 SOTA 性能。", "motivation": "现有免训练开放词汇变化检测方法依赖 CLIP 和 DINO 等多个模型，存在特征匹配问题和系统不稳定的情况。SAM 3 的出现为 OVCD 任务提供了新的可能性。", "method": "提出 OmniOVCD 框架，利用 SAM 3 的解耦输出（语义、实例、存在性）和提出的 Synergistic Fusion to Instance Decoupling (SFID) 策略。SFID 首先融合 SAM 3 的输出构建土地覆盖掩膜，然后将掩膜分解为独立的实例掩膜以进行变化比较。", "result": "在 LEVIR-CD、WHU-CD、S2Looking 和 SECOND 四个基准数据集上取得了 SOTA 性能，平均 IoU 分数分别为 67.2、66.5、24.5 和 27.1，优于所有现有方法。", "conclusion": "OmniOVCD 框架能够准确识别变化，并保持实例级的一致性，证明了 SAM 3 在开放词汇变化检测任务中的潜力。"}}
{"id": "2601.13836", "categories": ["cs.CL", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.13836", "abs": "https://arxiv.org/abs/2601.13836", "authors": ["Qian Chen", "Jinlan Fu", "Changsong Li", "See-Kiong Ng", "Xipeng Qiu"], "title": "FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs", "comment": "https://openmoss.github.io/FutureOmni", "summary": "Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni).", "AI": {"tldr": "本研究提出了FutureOmni，一个用于评估多模态大语言模型（MLLMs）在音视频环境下进行未来预测的基准。研究发现现有模型在未来预测方面存在不足，尤其是在语音密集型场景，并提出了一种名为OFF的训练策略来改进模型性能。", "motivation": "现有MLLMs在未来事件预测方面的能力尚未得到充分探索，现有基准主要关注回顾性理解。因此，需要一个专门用于评估多模态未来预测的基准。", "method": "构建了FutureOmni基准，包含919个视频和1034个多项选择问答对，涵盖8个主要领域。通过LLM辅助和人工参与的流程构建。并提出了一个包含7K样本的指令调优数据集和Omni-Modal Future Forecasting (OFF) 训练策略。", "result": "现有模型在音视频未来预测方面表现不佳，最佳准确率仅为64.8%（Gemini 3 Flash）。OFF训练策略在FutureOmni和其他基准测试中均提升了未来预测和泛化能力。", "conclusion": "FutureOmni基准填补了多模态未来预测评估的空白。现有MLLMs在音视频未来预测方面仍有提升空间，所提出的OFF训练策略能有效增强模型在该任务上的表现。"}}
{"id": "2601.13992", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13992", "abs": "https://arxiv.org/abs/2601.13992", "authors": ["Jin Cui", "Jiaqi Guo", "Jiepeng Zhou", "Ruixuan Yang", "Jiayi Lu", "Jiajun Xu", "Jiangcheng Song", "Boran Zhao", "Pengju Ren"], "title": "\"The Whole Is Greater Than the Sum of Its Parts\": A Compatibility-Aware Multi-Teacher CoT Distillation Framework", "comment": "11pages, 9figures", "summary": "Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect \"epiphany moments\" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.", "AI": {"tldr": "提出了一种名为COMPACT的框架，通过自适应融合多个教师模型的监督信号，来训练更小的学生模型掌握复杂推理能力，同时避免灾难性遗忘。", "motivation": "现有的CoT蒸馏方法通常依赖单一教师模型，这限制了学生模型的潜力，因为不同的教师模型具有不同的能力偏见，并且可能发生灾难性遗忘。同时，直接融合多个教师的监督信号存在教师-学生不兼容导致幻觉放大的风险，以及被动监督无法保证逻辑内化的挑战。", "method": "COMPACT框架通过以下方式自适应地融合不同教师的监督信号：1. 动态加权教师梯度，基于学生模型的实时兼容性。2. 使用多维度指标评估兼容性：基于图的一致性（过滤误导性推理）、互信息可适应性（检测真正的理解而非模仿）以及基于损失的难度（评估学生对教师指导的接受度并防止负迁移）。", "result": "COMPACT框架能够有效地整合多种推理能力，同时保留模型原有的知识结构，在多个基准测试中取得了最先进的性能，并缓解了灾难性遗忘问题。", "conclusion": "COMPACT通过创新的多维度兼容性评估和自适应教师监督融合机制，成功地将复杂推理能力转移到小型模型中，克服了单一教师蒸馏的局限性，并有效解决了多教师蒸馏中的潜在问题。"}}
{"id": "2601.13942", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13942", "abs": "https://arxiv.org/abs/2601.13942", "authors": ["Hongbo Bai", "Yujin Zhou", "Yile Wu", "Chi-Min Chan", "Pengcheng Wen", "Kunhao Pan", "Sirui Han", "Yike Guo"], "title": "Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning", "comment": null, "summary": "Large Multimodal Models (LMMs) have achieved remarkable success in visual understanding, yet they struggle with knowledge-intensive queries involving long-tail entities or evolving information due to static parametric knowledge. Recent search-augmented approaches attempt to address this limitation, but existing methods rely on indiscriminate whole-image retrieval that introduces substantial visual redundancy and noise, and lack deep iterative reflection, limiting their effectiveness on complex visual queries. To overcome these challenges, we propose Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning. GoG introduces a Selective Gaze mechanism that dynamically chooses whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. We design a dual-stage training strategy: Reflective GoG Behavior Alignment via supervised fine-tuning instills the fundamental GoG paradigm, while Complexity-Adaptive Reinforcement Learning further enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance. Ablation studies confirm that both Selective Gaze and complexity-adaptive RL are essential for effective visual search. We will release our data and models for further exploration soon.", "AI": {"tldr": "提出了一种名为Glance-or-Gaze (GoG)的自主框架，通过选择性凝视机制（Selective Gaze）来解决大型多模态模型（LMMs）在处理知识密集型查询时存在的检索冗余和噪声问题，并结合双阶段训练策略（反射式GoG行为对齐和复杂度自适应强化学习）来提升其处理复杂视觉查询的能力，在六个基准测试中达到了最先进的性能。", "motivation": "现有的搜索增强型LMM方法在处理知识密集型查询时，由于对整个图像进行检索，引入了视觉冗余和噪声，并且缺乏深度迭代反思，限制了其在复杂视觉查询上的有效性。", "method": "提出Glance-or-Gaze (GoG)框架，核心是Selective Gaze机制，能够动态选择关注全局上下文或高价值区域，在检索前过滤不相关信息。采用双阶段训练策略：1. 反射式GoG行为对齐（监督微调）来灌输基本GoG范式；2. 复杂度自适应强化学习进一步增强模型处理复杂查询的迭代推理能力。", "result": "在六个基准测试中取得了最先进的性能。消融研究表明，Selective Gaze机制和复杂度自适应强化学习对于有效的视觉搜索至关重要。", "conclusion": "GoG框架通过引入选择性凝视和复杂度自适应强化学习，能够有效克服现有搜索增强型LMM的局限性，在处理复杂知识密集型视觉查询方面表现出色，达到了最先进的性能。"}}
{"id": "2601.13876", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13876", "abs": "https://arxiv.org/abs/2601.13876", "authors": ["Unggi Lee", "Jahyun Jeong", "Sunyoung Shin", "Haeun Park", "Jeongsu Moon", "Youngchang Song", "Jaechang Shim", "JaeHwan Lee", "Yunju Noh", "Seungwon Choi", "Ahhyun Kim", "TaeHyeon Kim", "Kyungtae Joo", "Taeyeong Kim", "Gyeonggeon Lee"], "title": "Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education", "comment": null, "summary": "Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sacrifice language generation capabilities to maximize efficiency, making them unsuitable for resource-constrained educational settings that require interpretable, explanation-generating systems. We present \\textit{Pedagogical VLA Framework}, a framework that applies pedagogical alignment to lightweight VLA models through four components: text healing to restore language generation capabilities, large language model (LLM) distillation to transfer pedagogical knowledge, safety training for educational environments, and pedagogical evaluation adjusted to science education contexts. We evaluate Pedagogical VLA Framework across five science demonstrations spanning physics, chemistry, biology, and earth science, using an evaluation framework developed in collaboration with science education experts. Our evaluation assesses both task performance (success rate, protocol compliance, efficiency, safety) and pedagogical quality through teacher surveys and LLM-as-Judge assessment. We additionally provide qualitative analysis of generated texts. Experimental results demonstrate that Pedagogical VLA Framework achieves comparable task performance to baseline models while producing contextually appropriate educational explanations.", "AI": {"tldr": "提出了一种名为“教学VLA框架”的方法，该方法通过文本修复、LLM蒸馏、安全训练和教育情境下的教学评估，使轻量级VLA模型适用于资源受限的STEM教育环境，同时保持了语言生成和教学解释能力。", "motivation": "当前的VLA模型在资源受限的教育环境中存在计算资源需求高、语言生成能力弱的问题，而科学演示教学需要安全、一致且能生成解释的系统。", "method": "开发了“教学VLA框架”，包含四个组件：1. 文本修复（text healing）以恢复语言生成能力；2. LLM蒸馏（LLM distillation）以迁移教学知识；3. 安全训练（safety training）以适应教育环境；4. 教学评估（pedagogical evaluation）以适应科学教育情境。", "result": "在五种科学演示（物理、化学、生物、地球科学）中进行了评估，结果表明“教学VLA框架”在任务性能上与基线模型相当，同时能生成符合教育情境的解释。评估指标包括成功率、协议依从性、效率、安全性以及教学质量（教师问卷和LLM-as-Judge评估）。", "conclusion": "“教学VLA框架”能够有效地将轻量级VLA模型应用于STEM教育，解决资源限制问题，并提供既有任务性能又兼具教学解释能力的解决方案。"}}
{"id": "2601.12954", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12954", "abs": "https://arxiv.org/abs/2601.12954", "authors": ["Zhou Hong", "Rongsheng Hu", "Yicheng Di", "Xiaolong Xu", "Ning Dong", "Yihua Shao", "Run Ling", "Yun Wang", "Juqin Wang", "Zhanjie Zhang", "Ao Ma"], "title": "StyMam: A Mamba-Based Generator for Artistic Style Transfer", "comment": "Accepted by ICASSP 2026", "summary": "Image style transfer aims to integrate the visual patterns of a specific artistic style into a content image while preserving its content structure. Existing methods mainly rely on the generative adversarial network (GAN) or stable diffusion (SD). GAN-based approaches using CNNs or Transformers struggle to jointly capture local and global dependencies, leading to artifacts and disharmonious patterns. SD-based methods reduce such issues but often fail to preserve content structures and suffer from slow inference. To address these issues, we revisit GAN and propose a mamba-based generator, termed as StyMam, to produce high-quality stylized images without introducing artifacts and disharmonious patterns. Specifically, we introduce a mamba-based generator with a residual dual-path strip scanning mechanism and a channel-reweighted spatial attention module. The former efficiently captures local texture features, while the latter models global dependencies. Finally, extensive qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art algorithms in both quality and speed.", "AI": {"tldr": "提出了一种名为StyMam的基于Mamba的图像风格迁移方法，通过结合残差双路径条带扫描机制和通道重加权空间注意力模块，有效解决了现有GAN和SD方法在风格迁移中的不足，实现了高质量且快速的风格迁移。", "motivation": "现有基于GAN的风格迁移方法难以同时捕捉局部和全局依赖，易产生伪影和不协调的图案。基于SD的方法虽然改善了这些问题，但内容结构保留不佳且推理速度慢。", "method": "设计了一个基于Mamba的生成器StyMam，包含一个残差双路径条带扫描机制（用于捕捉局部纹理特征）和一个通道重加权空间注意力模块（用于建模全局依赖）。", "result": "StyMam在图像质量和生成速度上均优于现有最先进的算法，能够生成高质量的风格化图像，且没有伪影和不协调的图案。", "conclusion": "提出的StyMam方法能够有效地解决现有GAN和SD方法在图像风格迁移中的局限性，实现高质量且快速的风格迁移。"}}
{"id": "2601.14039", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14039", "abs": "https://arxiv.org/abs/2601.14039", "authors": ["Wesam Moustafa", "Hossam Elsafty", "Helen Schneider", "Lorenz Sparrenberg", "Rafet Sifa"], "title": "Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation", "comment": null, "summary": "Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework's versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models. Our code is publicly available at https://github.com/wemous/abstention-for-segmentation.", "AI": {"tldr": "提出了一种通用的、模块化的不确定性机制框架，用于提高医学图像分割模型对标签噪声的鲁棒性，并通过实验证明其有效性。", "motivation": "医学图像分割中的标签噪声问题普遍且难以解决，现有方法研究不足。分类任务中的不确定性机制已被证明有效，但其在分割任务中的潜力尚未验证。", "method": "提出了一种通用的、模块化的不确定性机制框架，包含两个关键组件：用于指导不确定性行为的正则化项，以及用于不确定性惩罚的灵活的功率律自适应算法。该框架可集成到多种损失函数中，生成新的噪声鲁棒变体（GAC、SAC、ADS）。", "result": "在CaDIS和DSAD数据集上，与不采用不确定性机制的基线方法相比，所提出的方法在存在标签噪声的情况下，分割性能得到了一致且显著的提升，尤其在高噪声水平下表现更优。", "conclusion": "使模型能够选择性地忽略被污染的样本，是一种强大且可泛化的策略，能够构建更可靠的分割模型，尤其是在处理标签噪声问题时。"}}
{"id": "2601.12964", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12964", "abs": "https://arxiv.org/abs/2601.12964", "authors": ["John Waithaka", "Gustave Bwirayesu", "Moise Busogi"], "title": "Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation", "comment": null, "summary": "Self-supervised pretraining in remote sensing is mostly done using mid-spatial resolution (MR) image datasets due to their high availability. Given the release of high-resolution (HR) datasets, we ask how HR datasets can be included in self-supervised pretraining to enhance MR image representation learning and downstream segmentation performance on MR tasks. We design a spatial affinity component that can be added to existing self-supervised learning frameworks and that uses HR imagery to learn better representations of MR imagery. We test the spatial affinity component on two self-supervised learning frameworks and show that it outperforms models pretrained on HR or MR images alone.", "AI": {"tldr": "本研究提出了一种名为“空间亲和力组件”的新方法，该方法利用高分辨率（HR）遥感影像来增强中等分辨率（MR）影像的自监督表示学习，并在下游分割任务中提升MR影像的性能。", "motivation": "现有研究主要使用MR影像进行自监督预训练，但HR影像的出现激发了研究人员思考如何利用HR影像来提升MR影像的表示学习和下游任务性能。", "method": "研究设计了一个“空间亲和力组件”，可以集成到现有的自监督学习框架中。该组件利用HR影像来学习MR影像的更好表示。", "result": "将空间亲和力组件应用于两个自监督学习框架后，在MR影像的表示学习和下游分割任务上均取得了优于仅使用HR或MR影像进行预训练的模型的结果。", "conclusion": "空间亲和力组件能够有效地利用HR影像来增强MR影像的自监督表示学习，并提升MR影像在下游分割任务上的性能。"}}
{"id": "2601.13918", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13918", "abs": "https://arxiv.org/abs/2601.13918", "authors": ["Yusheng Liao", "Chuan Xuan", "Yutong Cai", "Lina Yang", "Zhe Chen", "Yanfeng Wang", "Yu Wang"], "title": "AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization", "comment": "37 pages, 12 figures", "summary": "Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.", "AI": {"tldr": "提出AgentEHR基准，用于在真实EHR数据中进行复杂决策任务。在此基础上，开发了RetroSum框架，通过回顾式总结和演化策略解决了信息丢失和推理中断问题，显著提升了性能并减少了错误。", "motivation": "现有大型语言模型在EHR导航方面的应用受限于输入数据的精炼和任务的简化，与真实的临床环境存在差距。需要一个能够处理原始、高噪声EHR数据并执行复杂决策任务的基准和方法。", "method": "提出了AgentEHR基准，模拟真实EHR导航中的诊断和治疗规划等复杂决策任务。开发了RetroSum框架，包含回顾式总结机制（动态重新评估交互历史以防止信息丢失和保证逻辑连贯性）和演化经验策略（从记忆库检索累积经验以弥合领域差距）。", "result": "RetroSum在AgentEHR基准上取得了显著的性能提升，相较于现有方法，性能最高提升29.16%。同时，总交互错误次数显著减少，最多可达92.3%。", "conclusion": "RetroSum框架通过其独特的回顾式总结和演化经验策略，有效地解决了在原始、高噪声EHR数据中进行复杂交互式推理时的信息丢失和推理中断问题，为大型语言模型在真实EHR导航和决策任务中的应用提供了更强大的解决方案。"}}
{"id": "2601.13882", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13882", "abs": "https://arxiv.org/abs/2601.13882", "authors": ["Unggi Lee", "Sookbun Lee", "Heungsoo Choi", "Jinseo Lee", "Haeun Park", "Younghoon Jeon", "Sungmin Cho", "Minju Kang", "Junbo Koh", "Jiyeong Bae", "Minwoo Nam", "Juyeon Eun", "Yeonji Jung", "Yeil Jeong"], "title": "OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models", "comment": null, "summary": "Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment theory: Knowledge (curriculum-aligned content and pedagogical understanding), Skills (scenario-based competencies organized through a four-level center-role-scenario-subscenario hierarchy), and Attitude (alignment consistency and deception resistance). Our benchmark comprises 124K+ items spanning multiple subjects, educational roles, and difficulty levels based on Bloom's taxonomy. The Knowledge domain prioritizes authentic assessment items from established benchmarks, while the Attitude domain adapts Anthropic's Alignment Faking methodology to detect behavioral inconsistency under varying monitoring conditions. Evaluation of seven frontier models reveals distinct capability profiles: Claude-Opus-4.5 excels in practical skills despite lower content knowledge, while Grok-4.1-fast leads in knowledge but shows alignment concerns. Notably, no single model dominates all dimensions, validating the necessity of multi-axis evaluation. OpenLearnLM provides an open, comprehensive framework for advancing LLM readiness in authentic educational contexts.", "AI": {"tldr": "本文提出了 OpenLearnLM Benchmark，一个基于学习科学理论的、全面的评估大型语言模型（LLMs）在教育领域能力的框架，包含知识、技能和态度三个维度，并对七个前沿模型进行了评估，揭示了它们在不同教育能力上的差异化表现。", "motivation": "现有的大型语言模型教育评估基准过于狭窄，缺乏对学习科学理论的支撑。作者希望构建一个更全面、理论驱动的框架，以评估 LLMs 在真实教育场景中的适用性。", "method": "构建了一个名为 OpenLearnLM Benchmark 的评估框架，包含三个维度：知识（课程内容和教学法理解）、技能（基于四级层次结构的角色-场景评估）和态度（一致性及欺骗抵抗）。该基准包含超过 124,000 个项目，涵盖多门学科、教育角色和难度级别（基于布鲁姆分类法）。知识维度使用现有权威基准的真实评估项目，态度维度则借鉴了 Anthropic 的方法来检测在不同监控条件下的行为不一致性。使用此框架评估了七个前沿模型。", "result": "评估结果显示，不同模型在不同维度上表现出不同的能力特征。例如，Claude-Opus-4.5 在实践技能方面表现优异，但内容知识稍弱；Grok-4.1-fast 在知识方面领先，但在对齐方面存在隐忧。没有单一模型能在所有维度上都取得主导地位，这验证了多维度评估的必要性。", "conclusion": "OpenLearnLM Benchmark 提供了一个开放、全面的框架，能够有效评估 LLMs 在真实教育场景中的综合能力。该框架对于推动 LLMs 在教育领域的应用和发展至关重要，因为其多维度评估方法揭示了当前模型的局限性和优势，强调了在设计和评估教育用 LLMs 时需要考虑的复杂性。"}}
{"id": "2601.13919", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13919", "abs": "https://arxiv.org/abs/2601.13919", "authors": ["Yuezhe Yang", "Hao Wang", "Yige Peng", "Jinman Kim", "Lei Bi"], "title": "HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs", "comment": "Under Review", "summary": "Automated clinical diagnosis remains a core challenge in medical AI, which usually requires models to integrate multi-modal data and reason across complex, case-specific contexts. Although recent methods have advanced medical report generation (MRG) and visual question answering (VQA) with medical vision-language models (VLMs), these methods, however, predominantly operate under a sample-isolated inference paradigm, as such processing cases independently without access to longitudinal electronic health records (EHRs) or structurally related patient examples. This paradigm limits reasoning to image-derived information alone, which ignores external complementary medical evidence for potentially more accurate diagnosis. To overcome this limitation, we propose \\textbf{HyperWalker}, a \\textit{Deep Diagnosis} framework that reformulates clinical reasoning via dynamic hypergraphs and test-time training. First, we construct a dynamic hypergraph, termed \\textbf{iBrochure}, to model the structural heterogeneity of EHR data and implicit high-order associations among multimodal clinical information. Within this hypergraph, a reinforcement learning agent, \\textbf{Walker}, navigates to and identifies optimal diagnostic paths. To ensure comprehensive coverage of diverse clinical characteristics in test samples, we incorporate a \\textit{linger mechanism}, a multi-hop orthogonal retrieval strategy that iteratively selects clinically complementary neighborhood cases reflecting distinct clinical attributes. Experiments on MRG with MIMIC and medical VQA on EHRXQA demonstrate that HyperWalker achieves state-of-the-art performance. Code is available at: https://github.com/Bean-Young/HyperWalker", "AI": {"tldr": "本文提出了一种名为HyperWalker的深度诊断框架，通过动态超图iBrochure和测试时训练来解决临床诊断中的多模态数据整合和上下文推理问题，并通过linger机制检索互补性病例，在MRG和VQA任务上达到了SOTA性能。", "motivation": "现有的医学AI模型在临床诊断时通常独立处理病例，无法有效整合多模态数据并利用纵向EHR数据或结构相关的患者示例，导致诊断受限于图像信息，忽略了外部互补证据，从而限制了诊断的准确性。", "method": "1. 构建动态超图iBrochure，建模EHR数据的结构异质性和多模态临床信息之间的高阶关联。2. 设计强化学习代理Walker，在超图中导航以识别最优诊断路径。3. 引入linger机制（一种多跳正交检索策略），迭代选择具有不同临床属性的互补性邻近病例，以确保对测试样本中多样化临床特征的全面覆盖。", "result": "在MIMIC的MRG任务和EHRXQA的医学VQA任务上，HyperWalker均取得了最先进的性能。", "conclusion": "HyperWalker框架通过动态超图和测试时训练，能够有效地整合多模态临床数据并利用历史病例信息，克服了现有方法的局限性，显著提升了临床诊断的准确性。"}}
{"id": "2601.14041", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14041", "abs": "https://arxiv.org/abs/2601.14041", "authors": ["Yunhe Wang", "Kai Han", "Huiling Zhen", "Yuchuan Tian", "Hanting Chen", "Yongbing Huang", "Yufei Cui", "Yingte Shu", "Shan Gao", "Ismail Elezi", "Roy Vaughan Miles", "Songcen Xu", "Feng Wen", "Chao Xu", "Sinan Zeng", "Dacheng Tao"], "title": "Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants", "comment": null, "summary": "The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.", "AI": {"tldr": "本文探讨了扩散语言模型（DLMs）的潜力，并指出了其超越当前自回归（AR）模型瓶颈的十个关键挑战。作者提出了一个包含四个支柱的战略路线图，以推动DLMs的发展，实现更强大的AI能力。", "motivation": "当前主流的自回归（AR）语言模型存在全局结构洞察力和迭代优化能力受限的瓶颈。扩散语言模型（DLMs）作为一种有潜力的替代方案，但其优势尚未被充分挖掘，主要受限于现有的AR范式和优化框架。作者希望通过识别挑战并提出解决方案，推动DLMs的发展。", "method": "本文通过识别和分析阻碍DLMs发展的十个核心挑战，并提出一个由基础架构、算法优化、认知推理和多模态智能组成的四部分战略路线图。文章强调了转向“扩散原生”生态系统的必要性，并提出了一些具体方法，如多尺度分词、主动重掩码和潜在思维。", "result": "文章未能给出具体的实验结果，而是提出了一个概念性的框架和策略。作者认为，通过采纳其提出的策略，可以克服当前DLMs面临的限制。", "conclusion": "文章认为，从AR范式转向以DLM为基础的生态系统对于开发下一代AI至关重要，这种AI将具备复杂的结构推理、动态自我纠正和无缝多模态集成能力。这一转变有望让DLMs达到类似GPT-4的突破性成就。"}}
{"id": "2601.12994", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.12994", "abs": "https://arxiv.org/abs/2601.12994", "authors": ["Shiming Wang", "Holger Caesar", "Liangliang Nan", "Julian F. P. Kooij"], "title": "AsyncBEV: Cross-modal Flow Alignment in Asynchronous 3D Object Detection", "comment": null, "summary": "In autonomous driving, multi-modal perception tasks like 3D object detection typically rely on well-synchronized sensors, both at training and inference. However, despite the use of hardware- or software-based synchronization algorithms, perfect synchrony is rarely guaranteed: Sensors may operate at different frequencies, and real-world factors such as network latency, hardware failures, or processing bottlenecks often introduce time offsets between sensors. Such asynchrony degrades perception performance, especially for dynamic objects. To address this challenge, we propose AsyncBEV, a trainable lightweight and generic module to improve the robustness of 3D Birds' Eye View (BEV) object detection models against sensor asynchrony. Inspired by scene flow estimation, AsyncBEV first estimates the 2D flow from the BEV features of two different sensor modalities, taking into account the known time offset between these sensor measurements. The predicted feature flow is then used to warp and spatially align the feature maps, which we show can easily be integrated into different current BEV detector architectures (e.g., BEV grid-based and token-based). Extensive experiments demonstrate AsyncBEV improves robustness against both small and large asynchrony between LiDAR or camera sensors in both the token-based CMT and grid-based UniBEV, especially for dynamic objects. We significantly outperform the ego motion compensated CMT and UniBEV baselines, notably by $16.6$ % and $11.9$ % NDS on dynamic objects in the worst-case scenario of a $0.5 s$ time offset. Code will be released upon acceptance.", "AI": {"tldr": "提出AsyncBEV模块，用于提高自动驾驶中3D BEV目标检测模型对传感器异步的鲁棒性，通过估计2D特征流来对齐不同模态的特征图，并在实验中证明了其有效性。", "motivation": "在自动驾驶中，传感器间的完美同步难以保证，而传感器异步会严重影响3D目标检测性能，特别是对动态物体。现有的同步方法无法完全解决这个问题。", "method": "AsyncBEV模块通过估计两个不同传感器模态的BEV特征之间的2D流，并利用这个流来扭曲和空间对齐特征图。该模块可以轻松集成到现有的BEV检测器架构中。", "result": "AsyncBEV模块显著提高了模型在LiDAR和相机传感器之间存在不同程度异步情况下的鲁棒性，尤其对动态物体的检测效果更好。在最坏情况（0.5秒时间偏移）下，AsyncBEV在动态物体上的NDS评分相比基线模型分别提高了16.6%和11.9%。", "conclusion": "AsyncBEV是一个轻量级且通用的可训练模块，能够有效提升3D BEV目标检测模型对传感器异步的鲁棒性，为解决自动驾驶感知中的实际挑战提供了一种有效方法。"}}
{"id": "2601.14051", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14051", "abs": "https://arxiv.org/abs/2601.14051", "authors": ["Peter Devine", "Mardhiyah Sanni", "Farid Adilazuarda", "Julieta Gil Loizaga", "Barry Haddow"], "title": "Kakugo: Distillation of Low-Resource Languages into Small Language Models", "comment": null, "summary": "We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.", "AI": {"tldr": "Kakugo是一个创新的、低成本的管道，仅用语言名称作为输入，即可为低资源语言训练通用小型语言模型（SLMs）。通过使用大型教师模型生成合成提示和翻译指令数据集，为54种低资源语言生成了训练数据和SLMs。", "motivation": "现有的小型语言模型（SLMs）训练方法通常需要大量标注数据，这对于低资源语言来说难以获得，且成本高昂。本研究的动机是开发一种更具成本效益和可及性的方法，以训练低资源语言的通用SLMs。", "method": "该研究提出了Kakugo管道，其核心是利用一个大型教师模型来生成合成提示和翻译指令数据集。然后，利用这些生成的数据来训练低资源语言的SLMs。评估是通过在翻译、分类和问答等多种通用自然语言处理任务上进行的。", "result": "Kakugo管道成功地为54种低资源语言生成了训练数据和SLMs。在各种NLP任务上的评估显示，Kakugo生成的SLMs相比基础模型在性能上有所提升。每种语言的总生成和训练成本低于50美元。", "conclusion": "Kakugo管道为低资源语言的通用SLMs训练提供了一种新颖、低成本且可访问的方法。该方法通过利用大型教师模型的生成能力，克服了低资源语言数据稀缺的挑战，并能在多种NLP任务上实现性能提升，为社区开发语言特有的AI提供了可行方案。"}}
{"id": "2601.12981", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12981", "abs": "https://arxiv.org/abs/2601.12981", "authors": ["Sulaiman Khan", "Md. Rafiul Biswas", "Zubair Shah"], "title": "Early Prediction of Type 2 Diabetes Using Multimodal data and Tabular Transformers", "comment": "08 pages, 06 figures, accepted for publication in FLLM2025", "summary": "This study introduces a novel approach for early Type 2 Diabetes Mellitus (T2DM) risk prediction using a tabular transformer (TabTrans) architecture to analyze longitudinal patient data. By processing patients` longitudinal health records and bone-related tabular data, our model captures complex, long-range dependencies in disease progression that conventional methods often overlook. We validated our TabTrans model on a retrospective Qatar BioBank (QBB) cohort of 1,382 subjects, comprising 725 men (146 diabetic, 579 healthy) and 657 women (133 diabetic, 524 healthy). The study integrated electronic health records (EHR) with dual-energy X-ray absorptiometry (DXA) data. To address class imbalance, we employed SMOTE and SMOTE-ENN resampling techniques. The proposed model`s performance is evaluated against conventional machine learning (ML) and generative AI models, including Claude 3.5 Sonnet (Anthropic`s constitutional AI), GPT-4 (OpenAI`s generative pre-trained transformer), and Gemini Pro (Google`s multimodal language model). Our TabTrans model demonstrated superior predictive performance, achieving ROC AUC $\\geq$ 79.7 % for T2DM prediction compared to both generative AI models and conventional ML approaches. Feature interpretation analysis identified key risk indicators, with visceral adipose tissue (VAT) mass and volume, ward bone mineral density (BMD) and bone mineral content (BMC), T and Z-scores, and L1-L4 scores emerging as the most important predictors associated with diabetes development in Qatari adults. These findings demonstrate the significant potential of TabTrans for analyzing complex tabular healthcare data, providing a powerful tool for proactive T2DM management and personalized clinical interventions in the Qatari population.\n  Index Terms: tabular transformers, multimodal data, DXA data, diabetes, T2DM, feature interpretation, tabular data", "AI": {"tldr": "本研究提出了一种名为TabTrans的新型基于Transformer的模型，用于分析纵向患者数据（电子健康记录和DXA数据），以早期预测2型糖尿病（T2DM）风险。在卡塔尔生物银行（QBB）队列研究中，TabTrans模型表现优于传统机器学习和生成式AI模型，ROC AUC达到79.7%，并识别出内脏脂肪、骨密度等关键风险因素。", "motivation": "传统的T2DM风险预测方法难以捕捉患者纵向健康记录和骨骼相关数据的复杂长期依赖关系。本研究旨在开发一种能够处理多模态纵向数据的先进模型，以提高T2DM的早期预测准确性。", "method": "本研究提出了一种名为TabTrans的表格Transformer架构，用于分析患者的纵向健康记录和骨骼相关的表格数据（包括电子健康记录EHR和双能X线吸收测定DXA数据）。为了处理类别不平衡问题，研究采用了SMOTE和SMOTE-ENN重采样技术。模型性能与传统机器学习模型和生成式AI模型（Claude 3.5 Sonnet, GPT-4, Gemini Pro）进行了比较。", "result": "TabTrans模型在T2DM预测方面取得了优于生成式AI模型和传统机器学习方法的性能，ROC AUC达到了79.7%。特征解释分析表明，内脏脂肪组织（VAT）的质量和体积、 Ward骨密度（BMD）和骨矿物质含量（BMC）、T和Z分数以及L1-L4分数是与卡塔尔成年人糖尿病发生最相关的关键预测因子。", "conclusion": "TabTrans模型在分析复杂的表格医疗保健数据方面展现出巨大潜力，为QBB人群的主动T2DM管理和个性化临床干预提供了一个强大的工具。该模型能够有效地捕捉纵向数据中的复杂依赖关系，提高了T2DM的早期预测能力。"}}
{"id": "2601.13922", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13922", "abs": "https://arxiv.org/abs/2601.13922", "authors": ["Adrian Cosma", "Oleg Szehr", "David Kletz", "Alessandro Antonucci", "Olivier Pelletier"], "title": "Automatic Prompt Optimization for Dataset-Level Feature Discovery", "comment": "5 Figures, 1 Table", "summary": "Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.", "AI": {"tldr": "本研究提出了一种多智能体提示优化框架，用于从非结构化文本中自动发现可解释且具区分度的特征集，以优化下游分类任务的性能。", "motivation": "当前文本特征提取方法依赖于手工设计的提示或固定的特征模式，限制了模型的泛化能力和效率。研究旨在开发一种自动化的特征发现机制。", "method": "将特征发现问题构建为数据集级别的提示优化问题。利用多智能体框架，语言模型智能体协同生成特征定义、提取特征值，并通过数据集性能和可解释性反馈进行评估。通过迭代优化提示，实现对共享特征集的优化，而非仅针对单个样本的预测。", "result": "所提出的框架能够诱导出可解释且具区分度的特征定义。通过迭代优化提示，可以实现对特征集（而非每样本预测）的优化。", "conclusion": "该方法提供了一种原则性的机制，能够从非结构化文本中自动发现特征，克服了现有依赖每样本监督的提示优化方法的局限性。"}}
{"id": "2601.13029", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13029", "abs": "https://arxiv.org/abs/2601.13029", "authors": ["Zaibin Zhang", "Yuhan Wu", "Lianjie Jia", "Yifan Wang", "Zhongbo Zhang", "Yijiang Li", "Binghao Ran", "Fuxi Zhang", "Zhuohan Sun", "Zhenfei Yin", "Lijun Wang", "Huchuan Lu"], "title": "Think3D: Thinking with Space for Spatial Reasoning", "comment": null, "summary": "Understanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at https://github.com/zhangzaibin/spagent.", "AI": {"tldr": "本文提出了Think3D框架，通过结合3D重建模型和交互式3D推理，显著提升了视觉语言模型（VLMs）的空间推理能力，且无需额外训练。", "motivation": "现有的视觉语言模型主要停留在2D感知层面，难以进行真正的3D空间推理。作者旨在提升VLMs理解和推理3D世界的能力。", "method": "Think3D框架利用3D重建模型从图像或视频中恢复点云和相机姿态。它允许VLMs通过相机操作和视角切换（自身视角/全局视角）主动探索和操纵3D空间，将空间推理转化为交互式的3D思维链过程。此外，还引入了强化学习策略，使模型能够选择信息丰富的视角和操作。", "result": "在BLIP Multi-view和MindCube数据集上，Think3D使GPT-4.1和Gemini 2.5 Pro等先进模型在空间推理方面平均提升了+7.8%。在VSI-Bench上，平均提升了+4.7%。对于空间探索能力较弱的小模型，通过强化学习策略，工具使用的性能提升从+0.7%增加到+6.8%。", "conclusion": "无需训练、通过工具增强的空间探索是实现更灵活、更类人3D推理的多模态智能体的有效途径，为多模态智能开辟了新的维度。"}}
{"id": "2601.14056", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14056", "abs": "https://arxiv.org/abs/2601.14056", "authors": ["Andrea Rigo", "Luca Stornaiuolo", "Weijie Wang", "Mauro Martino", "Bruno Lepri", "Nicu Sebe"], "title": "POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion", "comment": null, "summary": "We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.", "AI": {"tldr": "提出了一种基于扩散模型的文本到图像生成方法POCI-Diff，通过融合3D几何约束和实例级语义绑定，实现了对多对象场景的精确布局控制和交互式编辑，并利用IP-Adapter保持了编辑过程中的对象身份和场景一致性。", "motivation": "现有文本到图像生成方法在实现空间一致性和跨编辑一致性方面存在不足，常导致几何畸变且难以跨编辑保持一致性。", "method": "提出POCI-Diff框架，通过Blended Latent Diffusion将文本描述与3D边界框绑定，实现实例级语义控制；采用无扭曲的生成式编辑管线，通过重生成实现对象插入、删除和变换；利用IP-Adapter作为条件，保持对象身份和全局场景一致性。", "result": "POCI-Diff在生成图像质量、布局遵循度和编辑一致性方面优于现有最先进方法，消除了扭曲引起的几何伪影。", "conclusion": "POCI-Diff成功实现了具有一致且可交互的3D布局控制和编辑的文本到图像生成，克服了现有方法的局限性。"}}
{"id": "2601.13052", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13052", "abs": "https://arxiv.org/abs/2601.13052", "authors": ["Antoine Carreaud", "Shanci Li", "Malo De Lacour", "Digre Frinde", "Jan Skaloud", "Adrien Gressin"], "title": "GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure", "comment": null, "summary": "This paper presents GridNet-HD, a multi-modal dataset for 3D semantic segmentation of overhead electrical infrastructures, pairing high-density LiDAR with high-resolution oblique imagery. The dataset comprises 7,694 images and 2.5 billion points annotated into 11 classes, with predefined splits and mIoU metrics. Unimodal (LiDAR-only, image-only) and multi-modal fusion baselines are provided. On GridNet-HD, fusion models outperform the best unimodal baseline by +5.55 mIoU, highlighting the complementarity of geometry and appearance. As reviewed in Sec. 2, no public dataset jointly provides high-density LiDAR and high-resolution oblique imagery with 3D semantic labels for power-line assets. Dataset, baselines, and codes are available: https://huggingface.co/collections/heig-vd-geo/gridnet-hd.", "AI": {"tldr": "本文提出了 GridNet-HD，一个包含高密度 LiDAR 和高分辨率倾斜影像的多模态数据集，用于架空电力基础设施的 3D 语义分割。实验表明，多模态融合模型比单一模态模型效果更好。", "motivation": "现有的公开数据集缺乏同时包含高密度 LiDAR、高分辨率倾斜影像和 3D 语义标签的电力线资产数据集。", "method": "构建了一个包含 7,694 张图像和 2.5 亿个点的多模态数据集 GridNet-HD，并对 11 类目标进行了标注。同时提供了单模态（仅 LiDAR、仅影像）和多模态融合的基线模型。", "result": "在 GridNet-HD 数据集上，多模态融合模型比最佳单模态基线模型 mIoU 提高了 +5.55，证明了几何信息和外观信息的互补性。", "conclusion": "GridNet-HD 数据集为 3D 语义分割研究提供了宝贵的资源，并且多模态融合方法在电力基础设施的语义分割任务中具有显著优势。"}}
{"id": "2601.13059", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13059", "abs": "https://arxiv.org/abs/2601.13059", "authors": ["Yulun Guo"], "title": "Prototype Learning-Based Few-Shot Segmentation for Low-Light Crack on Concrete Structures", "comment": null, "summary": "Crack detection is critical for concrete infrastructure safety, but real-world cracks often appear in low-light environments like tunnels and bridge undersides, degrading computer vision segmentation accuracy. Pixel-level annotation of low-light crack images is extremely time-consuming, yet most deep learning methods require large, well-illuminated datasets. We propose a dual-branch prototype learning network integrating Retinex theory with few-shot learning for low-light crack segmentation. Retinex-based reflectance components guide illumination-invariant global representation learning, while metric learning reduces dependence on large annotated datasets. We introduce a cross-similarity prior mask generation module that computes high-dimensional similarities between query and support features to capture crack location and structure, and a multi-scale feature enhancement module that fuses multi-scale features with the prior mask to alleviate spatial inconsistency. Extensive experiments on multiple benchmarks demonstrate consistent state-of-the-art performance under low-light conditions. Code: https://github.com/YulunGuo/CrackFSS.", "AI": {"tldr": "提出了一种集成Retinex理论和少样本学习的双分支原型学习网络，用于低光照下的裂缝分割，解决了低光照和数据标注困难的问题，并在多个基准测试中取得了先进的性能。", "motivation": "现实世界中的裂缝检测常面临低光照环境，导致计算机视觉分割精度下降，而低光照裂缝图像的像素级标注耗时且成本高昂，现有深度学习方法通常需要大量光照良好的数据集。", "method": "提出了一种集成Retinex理论和少样本学习的双分支原型学习网络。Retinex理论用于学习光照不变的全局表示，度量学习减少对大量标注数据的依赖。引入了跨相似性先验掩模生成模块来捕捉裂缝位置和结构，以及一个多尺度特征增强模块来融合多尺度特征并缓解空间不一致性。", "result": "在多个基准测试中，所提出的方法在低光照条件下展现了一致的先进性能。", "conclusion": "该双分支原型学习网络有效解决了低光照环境下裂缝分割的挑战，通过结合Retinex理论和少样本学习，显著提高了分割精度，并降低了对大规模标注数据的需求。"}}
{"id": "2601.13995", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13995", "abs": "https://arxiv.org/abs/2601.13995", "authors": ["Zihan Niu", "Wenping Hu", "Junmin Chen", "Xiyue Wang", "Tong Xu", "Ruiming Tang"], "title": "From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning", "comment": null, "summary": "Effective and controllable data selection is critical for LLM instruction tuning, especially with massive open-source datasets. Existing approaches primarily rely on instance-level quality scores, or diversity metrics based on embedding clusters or semantic tags. However, constrained by the flatness of embedding spaces or the coarseness of tags, these approaches overlook fine-grained knowledge and its intrinsic hierarchical dependencies, consequently hindering precise data valuation and knowledge-aligned sampling. To address this challenge, we propose Tree-aware Aligned Global Sampling (TAGS), a unified framework that leverages a knowledge tree built from fine-grained tags, thereby enabling joint control of global quality, diversity, and target alignment. Using an LLM-based tagger, we extract atomic knowledge concepts, which are organized into a global tree through bottom-up hierarchical clustering. By grounding data instances onto this tree, a tree-aware metric then quantifies data quality and diversity, facilitating effective sampling. Our controllable sampling strategy maximizes tree-level information gain and enforces leaf-level alignment via KL-divergence for specific domains. Extensive experiments demonstrate that TAGS significantly outperforms state-of-the-art baselines. Notably, it surpasses the full-dataset model by \\textbf{+5.84\\%} using only \\textbf{5\\%} of the data, while our aligned sampling strategy further boosts average performance by \\textbf{+4.24\\%}.", "AI": {"tldr": "提出一种名为TAGS（Tree-aware Aligned Global Sampling）的框架，利用知识树进行LLM指令调优的数据选择，能够联合控制全局质量、多样性和目标对齐，并在实验中取得了显著的性能提升。", "motivation": "现有的LLM指令调优数据选择方法依赖于实例级质量分数或基于嵌入聚类/语义标签的多样性指标，这些方法忽略了细粒度的知识及其内在的层级依赖关系，限制了数据评估和知识对齐采样。", "method": "构建一个知识树（由LLM标注器提取的原子知识概念构成），通过自底向上的层级聚类组织。将数据实例映射到该树上，使用一个“树感知”度量来量化数据质量和多样性，并制定一个可控的采样策略，该策略最大化树级别的信息增益，并通过KL散度强制实现特定领域的叶级别对齐。", "result": "TAGS在LLM指令调优任务上显著优于现有方法。仅使用5%的数据，TAGS的性能就超过了使用全部数据的模型+5.84%。同时，其对齐采样策略进一步将平均性能提升了+4.24%。", "conclusion": "TAGS框架通过引入知识树，实现了对LLM指令调优数据选择的精细化控制，能够有效地提升模型性能，并且在数据量受限的情况下表现尤为出色。"}}
{"id": "2601.14063", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.14063", "abs": "https://arxiv.org/abs/2601.14063", "authors": ["Mohsinul Kabir", "Tasnim Ahmed", "Md Mezbaur Rahman", "Shaoxiong Ji", "Hassan Alhuzali", "Sophia Ananiadou"], "title": "XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs", "comment": "30 Pages, 13 Figures", "summary": "Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP.", "AI": {"tldr": "本研究提出了XCR-Bench，一个包含4.9k并行句子和1,098个独特文化特定项目（CSIs）的跨文化推理基准，用于评估大型语言模型（LLMs）的跨文化能力。研究发现，现有LLMs在识别和改编与社交礼仪及文化参考相关的CSIs方面存在不足，并且在文化改编过程中会表现出地域和民族宗教偏见。", "motivation": "现有评估LLMs跨文化能力的研究受到高质量、带CSI标注的平行跨文化句子语料库稀缺的限制。", "method": "构建了XCR-Bench基准，该基准包含4.9k并行句子和1,098个独特的CSIs，并结合了Newmark的CSI框架和Hall的文化三元组，设计了三个推理任务及其评估指标。", "result": "最先进的LLMs在识别和改编与社交礼仪及文化参考相关的CSIs方面表现出一致的弱点。此外，研究发现在单一语言环境下，LLMs在文化改编过程中会编码地域和民族宗教偏见。", "conclusion": "XCR-Bench为跨文化NLP研究提供了新的资源，并揭示了当前LLMs在跨文化推理方面的不足之处，包括对特定文化元素的识别和改编能力，以及潜在的偏见问题。"}}
{"id": "2601.14069", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14069", "abs": "https://arxiv.org/abs/2601.14069", "authors": ["Nattapong Kurpukdee", "Adrian G. Bors"], "title": "Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management", "comment": null, "summary": "Unsupervised video class incremental learning (uVCIL) represents an important learning paradigm for learning video information without forgetting, and without considering any data labels. Prior approaches have focused on supervised class-incremental learning, relying on using the knowledge of labels and task boundaries, which is costly, requires human annotation, or is simply not a realistic option. In this paper, we propose a simple yet effective approach to address the uVCIL. We first consider a deep feature extractor network, providing a set of representative video features during each task without assuming any class or task information. We then progressively build a series of deep clusters from the extracted features. During the successive task learning, the model updated from the previous task is used as an initial state in order to transfer knowledge to the current learning task. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, by ignoring the labels from the supervised setting. Our approach significantly outperforms other baselines on all datasets.", "AI": {"tldr": "提出了一种简单有效的无监督视频类别增量学习（uVCIL）方法，通过提取代表性视频特征并逐步构建深度聚类，在不使用标签信息的情况下，实现了视频学习的知识迁移和无遗忘。", "motivation": "现有方法主要关注有监督的视频类别增量学习，需要昂贵的人工标注或依赖于对任务边界的了解，这在现实中往往不可行。因此，需要一种无需标签信息的无监督方法来解决uVCIL问题。", "method": "首先，使用深度特征提取网络为每个任务提取代表性视频特征，不假设任何类别或任务信息。然后，从提取的特征中逐步构建一系列深度聚类。在后续任务学习中，将前一任务更新的模型作为初始状态，以实现知识迁移。", "result": "在UCF101、HMDB51和Something-to-Something V2三个标准视频动作识别数据集上进行了深入评估，并在忽略标签的情况下，所提出的方法显著优于所有基线方法。", "conclusion": "所提出的uVCIL方法是一种简单而有效的方法，能够在无监督的情况下实现视频的增量学习，并且在性能上优于现有基线方法。"}}
{"id": "2601.14004", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14004", "abs": "https://arxiv.org/abs/2601.14004", "authors": ["Hengyuan Zhang", "Zhihao Zhang", "Mingyang Wang", "Zunhai Su", "Yiwei Wang", "Qianli Wang", "Shuzhou Yuan", "Ercong Nie", "Xufeng Duan", "Qibo Xue", "Zeping Yu", "Chenming Shang", "Xiao Liang", "Jing Xiong", "Hui Shen", "Chaofan Tao", "Zhengwu Liu", "Senjie Jin", "Zhiheng Xi", "Dongdong Zhang", "Sophia Ananiadou", "Tao Gui", "Ruobing Xie", "Hayden Kwok-Hay So", "Hinrich Schütze", "Xuanjing Huang", "Qi Zhang", "Ngai Wong"], "title": "Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models", "comment": null, "summary": "Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: \"Locate, Steer, and Improve.\" We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.", "AI": {"tldr": "本文对大型语言模型 (LLM) 的机制可解释性 (MI) 方法进行了系统性分类和评估，提出了一个基于“定位、引导和改进”的实用框架，旨在将 MI 从观察性科学转变为可操作的模型优化方法。", "motivation": "现有对机制可解释性 (MI) 的综述多侧重于观察和分析，缺乏系统的框架来指导实际的模型干预和改进。研究者旨在弥合这一差距，使 MI 成为一个可操作的、可用于模型优化的方法。", "method": "作者提出一个围绕“定位 (Locate) - 引导 (Steer) - 改进 (Improve)”流程的实用框架。他们将现有的定位（诊断）和引导（干预）方法根据具体的“可解释对象”进行正式分类，以建立严格的干预协议。最后，展示该框架如何实现对模型在对齐、能力和效率方面的实际改进。", "result": "该框架能够指导模型优化，在对齐、能力和效率方面带来可衡量的改进。作者还提供了一个精选的论文列表，以支持其“可操作 MI”的观点。", "conclusion": "通过将 MI 组织成一个结构化的“定位、引导和改进”流程，并对现有方法进行系统分类，可以有效地将 MI 应用于 LLM 的实际优化，实现模型性能的提升。MI 可以被视为一种可操作的 Methodology，用于模型改进。"}}
{"id": "2601.14007", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14007", "abs": "https://arxiv.org/abs/2601.14007", "authors": ["Junyu Zhang", "Yipeng Kang", "Jiong Guo", "Jiayu Zhan", "Junqi Wang"], "title": "BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models", "comment": "34 pagess, 16 figures, 6 tables, submitted to ACL 2026", "summary": "Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.", "AI": {"tldr": "研究提出一个抽象-具象框架，用于评估大语言模型（LLMs）对抽象概念（如人类价值观）的理解能力。实验结果表明，LLMs能够将抽象概念迁移到具体情境的理解和决策中，并且可以通过干预抽象概念表征来影响具体行为，但反之则不然。", "motivation": "探究大型语言模型（LLMs）是否真正理解抽象概念，还是仅仅作为统计模式进行操作，特别是关注其在人类价值观对齐方面的能力。", "method": "提出一个抽象-具象（Abstraction-Grounding）框架，将概念理解分解为三个能力：抽象概念的解释（A-A）、抽象概念在具体事件上的基础（A-C）、以及应用抽象原则来调节具体决策（C-C）。采用探测（probing）和引导（steering）技术，在六个开源LLMs和十个价值维度上进行实验。", "result": "探测（probing）结果显示，在抽象价值描述上训练的探测器可以 reliably 地在具体事件叙述和决策推理中检测到相同的价值，证明了跨层面的迁移能力。引导（steering）结果揭示了不对称性：干预价值表征会因果性地改变具体判断和决策（A-C, C-C），但不会改变抽象解释（A-A），这表明编码的抽象价值稳定存在。", "conclusion": "LLMs 维持了连接抽象和行动的结构化价值表征，为构建具有更透明、可泛化对齐和控制的价值驱动自主AI系统提供了机制和操作基础。"}}
{"id": "2601.14032", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14032", "abs": "https://arxiv.org/abs/2601.14032", "authors": ["Hongli Zhou", "Hui Huang", "Wei Liu", "Chenglong Wang", "Xingyuan Bu", "Lvyuan Han", "Fuhai Song", "Muyun Yang", "Wenhao Jiang", "Hailong Cao", "Tiejun Zhao"], "title": "RM-Distiller: Exploiting Generative LLM for Reward Model Distillation", "comment": null, "summary": "Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. Due to the difficulty of obtaining high-quality human preference annotations, distilling preferences from generative LLMs has emerged as a standard practice. However, existing approaches predominantly treat teacher models as simple binary annotators, failing to fully exploit the rich knowledge and capabilities for RM distillation. To address this, we propose RM-Distiller, a framework designed to systematically exploit the multifaceted capabilities of teacher LLMs: (1) Refinement capability, which synthesizes highly correlated response pairs to create fine-grained and contrastive signals. (2) Scoring capability, which guides the RM in capturing precise preference strength via a margin-aware optimization objective. (3) Generation capability, which incorporates the teacher's generative distribution to regularize the RM to preserve its fundamental linguistic knowledge. Extensive experiments demonstrate that RM-Distiller significantly outperforms traditional distillation methods both on RM benchmarks and reinforcement learning-based alignment, proving that exploiting multifaceted teacher capabilities is critical for effective reward modeling. To the best of our knowledge, this is the first systematic research on RM distillation from generative LLMs.", "AI": {"tldr": "提出了一种名为RM-Distiller的框架，通过利用教师LLM的多方面能力（精炼、评分和生成）来改进奖励模型（RM）的蒸馏过程，以更有效地实现LLM与人类偏好的对齐。", "motivation": "现有从生成式LLM蒸馏偏好的方法未能充分利用教师模型丰富的知识和能力，通常只将其视为简单的二元标注器，导致RM蒸馏效果不佳。", "method": "RM-Distiller框架利用教师LLM的三个核心能力：1. 精炼能力：合成高度相关的响应对，生成细粒度和对比性的信号。2. 评分能力：通过边际感知优化目标引导RM捕捉精确的偏好强度。3. 生成能力：纳入教师的生成分布，对RM进行正则化，以保留其基础语言知识。", "result": "RM-Distiller在RM基准测试和基于强化学习的对齐方面均显著优于传统蒸馏方法。实验证明，利用多方面教师能力对于有效的奖励建模至关重要。", "conclusion": "系统地利用教师LLM的多方面能力（精炼、评分和生成）是实现有效奖励模型蒸馏的关键，并且比仅将教师视为二元标注器的方法效果更好。"}}
{"id": "2601.13094", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13094", "abs": "https://arxiv.org/abs/2601.13094", "authors": ["Gelei Xu", "Yuying Duan", "Jun Xia", "Ruining Deng", "Wei Jin", "Yiyu Shi"], "title": "Patient-Conditioned Adaptive Offsets for Reliable Diagnosis across Subgroups", "comment": null, "summary": "AI models for medical diagnosis often exhibit uneven performance across patient populations due to heterogeneity in disease prevalence, imaging appearance, and clinical risk profiles. Existing algorithmic fairness approaches typically seek to reduce such disparities by suppressing sensitive attributes. However, in medical settings these attributes often carry essential diagnostic information, and removing them can degrade accuracy and reliability, particularly in high-stakes applications. In contrast, clinical decision making explicitly incorporates patient context when interpreting diagnostic evidence, suggesting a different design direction for subgroup-aware models. In this paper, we introduce HyperAdapt, a patient-conditioned adaptation framework that improves subgroup reliability while maintaining a shared diagnostic model. Clinically relevant attributes such as age and sex are encoded into a compact embedding and used to condition a hypernetwork-style module, which generates small residual modulation parameters for selected layers of a shared backbone. This design preserves the general medical knowledge learned by the backbone while enabling targeted adjustments that reflect patient-specific variability. To ensure efficiency and robustness, adaptations are constrained through low-rank and bottlenecked parameterizations, limiting both model complexity and computational overhead. Experiments across multiple public medical imaging benchmarks demonstrate that the proposed approach consistently improves subgroup-level performance without sacrificing overall accuracy. On the PAD-UFES-20 dataset, our method outperforms the strongest competing baseline by 4.1% in recall and 4.4% in F1 score, with larger gains observed for underrepresented patient populations.", "AI": {"tldr": "提出了一种名为HyperAdapt的框架，通过患者条件适应来提高医学诊断AI模型在不同亚组中的可靠性，同时不牺牲整体准确性。", "motivation": "现有AI医学诊断模型在不同患者群体中表现不均，而传统的公平性方法通过抑制敏感属性会损害诊断信息和模型可靠性。临床决策会考虑患者背景信息，这启发了新的研究方向。", "method": "HyperAdapt框架使用患者的临床相关属性（如年龄、性别）生成嵌入，并以此条件化一个超网络模块。该模块产生小的残差调制参数，用于调整共享骨干网络选定层的权重。通过低秩和瓶颈参数化来限制模型复杂性和计算开销。", "result": "在多个医学影像数据集上的实验表明，HyperAdapt在亚组层面持续提升性能，同时不损害整体准确性。在PAD-UFES-20数据集上，相比最强的基线模型，在召回率上提升4.1%，F1分数上提升4.4%，对代表性不足的患者群体提升尤为显著。", "conclusion": "HyperAdapt是一种有效的患者条件适应框架，可以在保持共享模型的同时，显著提高医学诊断AI模型在不同患者亚组中的可靠性和性能，尤其是在代表性不足的群体中。"}}
{"id": "2601.14086", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14086", "abs": "https://arxiv.org/abs/2601.14086", "authors": ["Nattapong Kurpukdee", "Adrian G. Bors"], "title": "Two-Stream temporal transformer for video action classification", "comment": null, "summary": "Motion representation plays an important role in video understanding and has many applications including action recognition, robot and autonomous guidance or others. Lately, transformer networks, through their self-attention mechanism capabilities, have proved their efficiency in many applications. In this study, we introduce a new two-stream transformer video classifier, which extracts spatio-temporal information from content and optical flow representing movement information. The proposed model identifies self-attention features across the joint optical flow and temporal frame domain and represents their relationships within the transformer encoder mechanism. The experimental results show that our proposed methodology provides excellent classification results on three well-known video datasets of human activities.", "AI": {"tldr": "提出了一种新的双流Transformer视频分类器，该分类器结合了内容和光流信息，在三个常用的人类活动数据集上取得了优异的分类结果。", "motivation": "Transformer网络在视频理解领域的应用及其自注意力机制的有效性。", "method": "提出了一种新的双流Transformer视频分类器，该分类器分别提取视频内容的空间时间信息和光流表示的运动信息。模型通过Transformer编码器机制来识别跨联合光流和时间帧域的自注意力特征及其关系。", "result": "在三个著名的人类活动视频数据集上，所提出的方法提供了出色的分类结果。", "conclusion": "该模型能够有效地利用内容和运动信息进行视频分类，并且在识别人类活动方面表现出色。"}}
{"id": "2601.13126", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13126", "abs": "https://arxiv.org/abs/2601.13126", "authors": ["Mattia D'Urso", "Emanuele Santellani", "Christian Sormann", "Mattia Rossi", "Andreas Kuhn", "Friedrich Fraundorfer"], "title": "A Streamlined Attention-Based Network for Descriptor Extraction", "comment": "Accepted to 3DV 2026", "summary": "We introduce SANDesc, a Streamlined Attention-Based Network for Descriptor extraction that aims to improve on existing architectures for keypoint description.\n  Our descriptor network learns to compute descriptors that improve matching without modifying the underlying keypoint detector. We employ a revised U-Net-like architecture enhanced with Convolutional Block Attention Modules and residual paths, enabling effective local representation while maintaining computational efficiency. We refer to the building blocks of our model as Residual U-Net Blocks with Attention. The model is trained using a modified triplet loss in combination with a curriculum learning-inspired hard negative mining strategy, which improves training stability.\n  Extensive experiments on HPatches, MegaDepth-1500, and the Image Matching Challenge 2021 show that training SANDesc on top of existing keypoint detectors leads to improved results on multiple matching tasks compared to the original keypoint descriptors. At the same time, SANDesc has a model complexity of just 2.4 million parameters.\n  As a further contribution, we introduce a new urban dataset featuring 4K images and pre-calibrated intrinsics, designed to evaluate feature extractors. On this benchmark, SANDesc achieves substantial performance gains over the existing descriptors while operating with limited computational resources.", "AI": {"tldr": "提出了一种名为SANDesc的流线型注意力网络，用于提取改进的关键点描述符，该网络采用U-Netlike结构、CBAM和残差路径，并使用改进的三元组损失进行训练，实验证明其在多个匹配任务上优于现有方法，且参数量少。", "motivation": "现有关键点检测器的描述符提取存在不足，希望在不修改关键点检测器的前提下，设计一种新的描述符网络来提升匹配性能。", "method": "采用U-Netlike架构，结合卷积块注意力模块（CBAM）和残差路径，构建了名为“具有注意力的残差U-Net块”的模型。训练方法使用了修改版的三元组损失和一种借鉴课程学习的难例挖掘策略。", "result": "SANDesc在HPatches、MegaDepth-1500和IMC 2021数据集上，通过在现有关键点检测器上训练，显著提升了多个匹配任务的性能。模型参数量仅240万。在引入的4K城市新数据集上，SANDesc也取得了显著的性能提升，同时计算资源消耗有限。", "conclusion": "SANDesc是一种高效且性能优越的关键点描述符提取网络，能够有效提升现有关键点检测器的匹配能力，适用于计算资源受限的场景。"}}
{"id": "2601.13128", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13128", "abs": "https://arxiv.org/abs/2601.13128", "authors": ["Sung Ju Lee", "Nam Ik Cho"], "title": "PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain", "comment": "Accepted to the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2026", "summary": "The proliferation of hyper-realistic images from Latent Diffusion Models (LDMs) demands robust watermarking, yet existing post-hoc methods are prohibitively slow due to iterative optimization or inversion processes. We introduce PhaseMark, a single-shot, optimization-free framework that directly modulates the phase in the VAE latent frequency domain. This approach makes PhaseMark thousands of times faster than optimization-based techniques while achieving state-of-the-art resilience against severe attacks, including regeneration, without degrading image quality. We analyze four modulation variants, revealing a clear performance-quality trade-off. PhaseMark demonstrates a new paradigm where efficient, resilient watermarking is achieved by exploiting intrinsic latent properties.", "AI": {"tldr": "提出了一种名为PhaseMark的单次、无需优化的水印框架，通过直接调整VAE潜在频率域的相位来实现超高分辨率图像的水印，速度比现有方法快数千倍，同时保持了优异的鲁棒性和图像质量。", "motivation": "现有为超高分辨率图像（由LDMs生成）添加水印的方法，尤其是后验方法，由于迭代优化或逆过程而速度非常慢，无法满足需求。", "method": "提出PhaseMark框架，通过直接在VAE潜在频率域中调制相位来实现水印。这是一种单次、无需优化的方法。", "result": "PhaseMark比基于优化的技术快数千倍，在抵抗包括再生在内的严重攻击方面达到了最先进的鲁棒性，并且不会降低图像质量。研究了四种调制变体，揭示了性能和质量之间的权衡。", "conclusion": "PhaseMark开创了一种新范式，通过利用潜在属性实现高效、鲁棒的水印。"}}
{"id": "2601.14046", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.14046", "abs": "https://arxiv.org/abs/2601.14046", "authors": ["Shikhar Bharadwaj", "Chin-Jou Li", "Yoonjae Kim", "Kwanghee Choi", "Eunjung Yeo", "Ryan Soh-Eun Shim", "Hanyu Zhou", "Brendon Boldt", "Karen Rosero Jacome", "Kalvin Chang", "Darsh Agrawal", "Keer Xu", "Chao-Han Huck Yang", "Jian Zhu", "Shinji Watanabe", "David R. Mortensen"], "title": "PRiSM: Benchmarking Phone Realization in Speech Models", "comment": null, "summary": "Phone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: https://github.com/changelinglab/prism.", "AI": {"tldr": "PRiSM 是一个新基准，用于评估语音识别（PR）系统在语音感知方面的盲点，并提供评估工具和数据集，以促进跨语言语音处理和语音学分析的发展。", "motivation": "当前对语音识别（PR）系统的评估仅关注表面转录准确性，未能充分揭示其在语音感知方面的局限性。研究人员希望开发一个更全面的评估框架，以暴露 PR 系统的盲点，并推动跨语言语音处理和语音学分析领域的发展。", "method": "PRiSM 通过内在和外在评估来衡量 PR 系统的语音感知能力。内在评估包括标准化的转录评估，而外在评估则通过转录和表示探测器来评估 PR 系统在临床、教育和多语言环境下的下游应用效用。", "result": "研究发现，模型训练时接触的语言多样性对 PR 性能至关重要；基于编码器-CTC 的模型表现最为稳定；专门的 PR 模型在多语言语音模型方面仍然优于大型音频语言模型。", "conclusion": "PRiSM 是一个开放源代码基准，提供了代码、配置和数据集，旨在通过更全面的评估方法，推动语音识别领域朝着具有鲁棒语音能力的多语言语音模型发展。"}}
{"id": "2601.14084", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14084", "abs": "https://arxiv.org/abs/2601.14084", "authors": ["Abdurrahim Yilmaz", "Ozan Erdem", "Ece Gokyayla", "Ayda Acar", "Burc Bugra Dagtas", "Dilara Ilhan Erdil", "Gulsum Gencoglan", "Burak Temelkuran"], "title": "DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning", "comment": null, "summary": "Vision-language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I-VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14.474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse.", "AI": {"tldr": "本文提出了DermaBench，一个用于评估皮肤病学视觉语言模型（VLMs）的视觉问答（VQA）基准。该基准包含656张皮肤科临床图像，由专家注释了22类问题，涵盖诊断、解剖部位、形态学等，旨在评估模型在细粒度理解、语言基础和临床推理方面的能力。", "motivation": "现有的皮肤科数据集主要关注图像级分类，无法充分评估VLM在理解皮肤科图像、进行细粒度推理和生成临床描述方面的能力。因此，需要一个VQA基准来弥补这一不足。", "method": "构建DermaBench基准，该基准基于DDI数据集，包含656张来自570名患者的皮肤科图像，涵盖 Fitzpatrick 皮肤类型I-VI。使用分层注释方案，由专家皮肤科医生对每张图像的诊断、解剖部位、病变形态、分布、表面特征、颜色和图像质量等22个主要问题进行单选、多选和开放式标注，并提供开放式叙述描述和摘要，总共产生了约14,474个VQA风格的标注。", "result": "DermaBench包含了详细的VQA标注，可以用于评估VLM在皮肤科领域的理解、推理和语言生成能力。该基准的创建填补了当前皮肤科VLM评估的空白。", "conclusion": "DermaBench是一个新颖的、由临床医生注释的皮肤科VQA基准，能够更全面地评估VLM在皮肤科图像理解、语言基础和临床推理方面的能力。该基准以元数据形式发布，以尊重上游许可。"}}
{"id": "2601.14124", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14124", "abs": "https://arxiv.org/abs/2601.14124", "authors": ["Saad Mankarious", "Aya Zirikly"], "title": "Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic", "comment": null, "summary": "Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.", "AI": {"tldr": "本文提出了一种无需预训练的基于扩散模型的方法，用于生成合成文本，将偏见缓解视为风格迁移问题，以解决心理健康分析中的数据稀缺和人口偏见问题。", "motivation": "现有合成数据生成方法依赖于预训练的大语言模型，存在输出多样性有限和继承训练数据偏见的风险。特别是，心理健康领域数据稀缺和人口偏见（如性别不平衡）是一个重要问题。", "method": "作者提出了一种不依赖预训练的基于扩散模型的文本生成方法，将偏见缓解视为风格迁移问题。具体来说，他们使用 CARMA 阿拉伯语心理健康语料库，专注于从男性写作风格迁移到女性写作风格，以增加代表性不足的女性作者内容的数量。他们构建了五个数据集，并在每种设置下训练了独立的扩散模型。", "result": "定量评估表明，源文本和生成文本在语义保真度上持续较高，同时在表面层风格上具有有意义的发散。定性分析证实了语言学上合理的性别转换。", "conclusion": "基于扩散模型的风格迁移技术可以在不依赖预训练大语言模型的情况下，生成高熵、语义保真的合成数据。该方法为在资源匮乏的敏感心理健康领域减轻性别偏见提供了一个有效且灵活的框架。"}}
{"id": "2601.14050", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14050", "abs": "https://arxiv.org/abs/2601.14050", "authors": ["Yuxin Chen", "Zhengzhou Cai", "Xiangtian Ji", "Weixiang Zhao", "An Zhang", "Xiang Wang", "Tat-Seng Chua"], "title": "Understanding Multilingualism in Mixture-of-Experts LLMs: Routing Mechanism, Expert Specialization, and Layerwise Steering", "comment": null, "summary": "Mixture-of-Experts (MoE) architectures have shown strong multilingual capabilities, yet the internal mechanisms underlying performance gains and cross-language differences remain insufficiently understood. In this work, we conduct a systematic analysis of MoE models, examining routing behavior and expert specialization across languages and network depth. Our analysis reveals that multilingual processing in MoE models is highly structured: routing aligns with linguistic families, expert utilization follows a clear layerwise pattern, and high-resource languages rely on shared experts while low-resource languages depend more on language-exclusive experts despite weaker performance. Layerwise interventions further show that early and late MoE layers support language-specific processing, whereas middle layers serve as language-agnostic capacity hubs. Building on these insights, we propose a routing-guided steering method that adaptively guides routing behavior in middle layers toward shared experts associated with dominant languages at inference time, leading to consistent multilingual performance improvements, particularly for linguistically related language pairs. Our code is available at https://github.com/conctsai/Multilingualism-in-Mixture-of-Experts-LLMs.", "AI": {"tldr": "本研究系统分析了混合专家（MoE）模型在多语言处理中的内部机制，发现路由与语言家族相关，专家使用具有层级模式，并且低资源语言更依赖独占专家。在此基础上，提出了一种路由引导的干预方法，在推理时引导中层专家转向共享专家，以提升多语言性能，尤其对语言相关的语种效果更佳。", "motivation": "现有研究对MoE模型在多语言能力上的优势及其内部工作机制理解不足，尤其是在跨语言差异方面。", "method": "通过系统性分析MoE模型的路由行为和专家专业化，考察不同语言和网络深度下的表现。进行了层级干预实验，并提出了一种路由引导的干预方法，在推理时调整中层路由。", "result": "发现MoE模型的多语言处理结构化：路由与语言家族对齐；专家使用遵循层级模式；高资源语言依赖共享专家，低资源语言更依赖独占专家但性能较弱。中层MoE层充当语言无关的容量中心。路由引导干预方法提升了多语言性能，尤其对语言相关语种。", "conclusion": "MoE模型在多语言处理中具有结构化的内部机制。通过引导路由至共享专家，可以有效提升多语言性能，特别是对于语言相似的语种。"}}
{"id": "2601.13133", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13133", "abs": "https://arxiv.org/abs/2601.13133", "authors": ["Mingshuang Luo", "Ruibing Hou", "Bo Chao", "Hong Chang", "Zimo Liu", "Yaowei Wang", "Shiguang Shan"], "title": "CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks", "comment": "Accepted by TMM (IEEE Transactions on Multimedia), 16 pages, 7 figures", "summary": "Human-centric visual analysis plays a pivotal role in diverse applications, including surveillance, healthcare, and human-computer interaction. With the emergence of large-scale unlabeled human image datasets, there is an increasing need for a general unsupervised pre-training model capable of supporting diverse human-centric downstream tasks. To achieve this goal, we propose CLASP (CLIP-guided Adaptable Self-suPervised learning), a novel framework designed for unsupervised pre-training in human-centric visual tasks. CLASP leverages the powerful vision-language model CLIP to generate both low-level (e.g., body parts) and high-level (e.g., attributes) semantic pseudo-labels. These multi-level semantic cues are then integrated into the learned visual representations, enriching their expressiveness and generalizability. Recognizing that different downstream tasks demand varying levels of semantic granularity, CLASP incorporates a Prompt-Controlled Mixture-of-Experts (MoE) module. MoE dynamically adapts feature extraction based on task-specific prompts, mitigating potential feature conflicts and enhancing transferability. Furthermore, CLASP employs a multi-task pre-training strategy, where part- and attribute-level pseudo-labels derived from CLIP guide the representation learning process. Extensive experiments across multiple benchmarks demonstrate that CLASP consistently outperforms existing unsupervised pre-training methods, advancing the field of human-centric visual analysis.", "AI": {"tldr": "提出了一种名为CLASP的无监督预训练框架，利用CLIP生成多层次的语义伪标签，并通过Prompt-Controlled MoE模块自适应地学习视觉表征，以支持多样化的人类中心下游任务。", "motivation": "随着大规模无标签人类图像数据集的出现，需要一个通用的无监督预训练模型来支持多样化的人类中心下游任务。", "method": "CLASP框架利用CLIP生成低级（如身体部位）和高级（如属性）语义伪标签。采用Prompt-Controlled MoE模块动态适应特征提取，并结合多任务预训练策略，以伪标签指导表征学习。", "result": "CLASP在多个基准测试中一致优于现有的无监督预训练方法，提升了人类中心视觉分析的性能。", "conclusion": "CLASP是一个有效的无监督预训练框架，通过多层次语义伪标签和自适应特征提取，显著提高了人类中心视觉任务的通用性和迁移能力。"}}
{"id": "2601.14105", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14105", "abs": "https://arxiv.org/abs/2601.14105", "authors": ["Olesya Razuvayevskaya", "Kalina Bontcheva"], "title": "Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks", "comment": "In Proceedings of the ACM Web Conference 2026 (WWW 2026)", "summary": "This study presents the first large-scale comparison of persuasion techniques present in crowd- versus professionally-written debunks. Using extensive datasets from Community Notes (CNs), EUvsDisinfo, and the Database of Known Fakes (DBKF), we quantify the prevalence and types of persuasion techniques across these fact-checking ecosystems. Contrary to prior hypothesis that community-produced debunks rely more heavily on subjective or persuasive wording, we find no evidence that CNs contain a higher average number of persuasion techniques than professional fact-checks. We additionally identify systematic rhetorical differences between CNs and professional debunking efforts, reflecting differences in institutional norms and topical coverage. Finally, we examine how the crowd evaluates persuasive language in CNs and show that, although notes with more persuasive elements receive slightly higher overall helpfulness ratings, crowd raters are effective at penalising the use of particular problematic rhetorical means", "AI": {"tldr": "本研究首次对社区和专业写手发布的辟谣文章中的说服技巧进行了大规模比较，发现社区笔记（CNs）中的说服技巧数量并不比专业辟谣文章多，但存在系统性的修辞差异。社区用户在评价CNs时，尽管略微偏爱更具说服力的内容，但也能有效惩罚不当的修辞手段。", "motivation": "研究的动机是为了检验“社区生产的辟谣内容比专业辟谣内容更依赖主观或说服性语言”的假设，并了解社区驱动和专业驱动的辟谣在说服技巧使用和公众评价上的差异。", "method": "研究使用了来自Community Notes (CNs)、EUvsDisinfo和Database of Known Fakes (DBKF) 的数据集，量化了不同辟谣生态系统中说服技巧的普遍性和类型，并分析了CNs中的修辞差异以及社区用户如何评价其中的说服性语言。", "result": "研究发现，CNs中的说服技巧数量平均不高于专业辟谣文章。CNs和专业辟谣在修辞上存在系统性差异。社区用户评价显示，虽然略微偏爱更具说服性的CNs，但也能有效惩罚使用特定有问题修辞手段的CNs。", "conclusion": "研究结论是，社区驱动的辟谣（如CNs）并不比专业辟谣更倾向于使用说服性语言。尽管存在修辞上的差异，社区用户在评价辟谣内容时，能够区分并抵制不恰当的说服性策略。"}}
{"id": "2601.14160", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14160", "abs": "https://arxiv.org/abs/2601.14160", "authors": ["Ali Hamza Bashir", "Muhammad Rehan Khalid", "Kostadin Cvejoski", "Jana Birr", "Jule Berghaus", "Armin Berger", "Sandra Halscheidt", "Christian Temath", "Rafet Sifa", "David Berghaus"], "title": "Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law", "comment": null, "summary": "Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.", "AI": {"tldr": "本研究提出了一种利用德国法律法规生成合成问答对的方法，并使用参数高效微调技术，成功提升了大型语言模型在德国法律问答任务上的表现。", "motivation": "大型语言模型在法律等专业领域知识有限，容易产生事实错误或幻觉。需要一种有效的方法来适应LLM到特定法律领域，但昂贵的人工标注资源或不可靠的合成数据存在不足。", "method": "该研究提出了一种系统性的方法，直接从德国权威法律法规中生成高质量、多样化且法律准确的合成问答对。结合严格的自动化过滤方法和参数高效的微调技术，对LLM进行适配。", "result": "使用合成数据集适配的LLM在德国法律问答任务上的表现显著优于基线模型。", "conclusion": "精心设计的合成数据可以作为手动标注的可靠替代方案，尤其适用于高风险、知识密集型领域，如法律推理。"}}
{"id": "2601.14152", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14152", "abs": "https://arxiv.org/abs/2601.14152", "authors": ["Hyunjong Ok", "Jaeho Lee"], "title": "Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models", "comment": "preprint", "summary": "Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.", "AI": {"tldr": "大型语言模型对提示结构敏感，尤其是在多项选择题问答中，上下文-问题-选项（CQO）的顺序比问题-选项-上下文（QOC）的顺序效果好14%以上。研究发现，其核心机制是因果注意力掩码限制了QOC模式下选项标记对上下文的注意力。", "motivation": "理解大型语言模型（LLMs）对提示结构敏感性的机制，特别是在多项选择题问答任务中，CQO结构显著优于QOC结构这一现象。", "method": "通过对LLMs进行系统性的架构分析，特别关注因果注意力机制，来解释CQO和QOC结构在多项选择题问答中的性能差异。", "result": "在多项选择题问答任务中，CQO提示顺序比QOC提示顺序的准确率高出14%以上，且这一优势在多种模型和数据集上均得到验证。研究发现，QOC模式下的因果注意力掩码阻止了选项标记对上下文的注意力，形成了信息瓶颈。", "conclusion": "因果注意力是导致LLMs在多项选择题问答中对提示结构敏感的核心机制。在QOC提示结构中，由于掩码的限制，上下文信息对选项是不可见的，从而降低了模型性能。"}}
{"id": "2601.14154", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14154", "abs": "https://arxiv.org/abs/2601.14154", "authors": ["Shubham Pandey", "Bhavin Jawade", "Srirangaraj Setlur", "Venu Govindaraju", "Kenneth Seastedt"], "title": "LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery", "comment": "Accepted to P2P-CV @ WACV 2026", "summary": "Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. We present MIRACLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, we incorporate an interventional deep learning module in MIRACLE, that not only refines predictions but also provides interpretable and actionable insights, allowing domain experts to interactively adjust recommendations based on clinical expertise. We validate our approach on POC-L, a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Our results demonstrate that MIRACLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management.", "AI": {"tldr": "本文提出了一种名为MIRACLE的深度学习模型，用于整合术前临床和影像学数据，以预测肺癌手术后并发症的风险。该模型通过超球面嵌入空间融合异构输入，并包含一个可解释的干预深度学习模块，以提供可操作的见解。在真实数据集POC-L上，MIRACLE的表现优于传统机器学习模型和大型语言模型。", "motivation": "术后并发症是临床实践中的一个关键问题，严重影响患者预后并增加医疗成本。因此，研究如何有效预测和管理术后并发症的风险至关重要。", "method": "MIRACLE采用深度学习架构，通过超球面嵌入空间融合异构的术前临床记录和放射影像数据，提取特征。模型还集成了一个干预式深度学习模块，用于优化预测并提供可解释和可操作的见解，允许临床专家进行交互式调整。", "result": "在POC-L数据集（包含3094名肺癌手术患者）上进行验证，MIRACLE在预测术后并发症风险方面，优于传统的机器学习模型和单独使用的大型语言模型（LLM）。", "conclusion": "MIRACLE是一种有效且可解释的深度学习方法，能够整合多模态数据，为肺癌手术患者提供个性化的术后并发症风险管理，并具有临床应用潜力。"}}
{"id": "2601.13148", "categories": ["cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13148", "abs": "https://arxiv.org/abs/2601.13148", "authors": ["Richard Shaw", "Youngkyoon Jang", "Athanasios Papaioannou", "Arthur Moreau", "Helisa Dhamo", "Zhensong Zhang", "Eduardo Pérez-Pellitero"], "title": "ICo3D: An Interactive Conversational 3D Virtual Human", "comment": "Accepted by International Journal on Computer Vision (IJCV). Project page: https://ico3d.github.io/. This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in International Journal of Computer Vision and is available online at https://doi.org/10.1007/s11263-025-02725-8", "summary": "This work presents Interactive Conversational 3D Virtual Human (ICo3D), a method for generating an interactive, conversational, and photorealistic 3D human avatar. Based on multi-view captures of a subject, we create an animatable 3D face model and a dynamic 3D body model, both rendered by splatting Gaussian primitives. Once merged together, they represent a lifelike virtual human avatar suitable for real-time user interactions. We equip our avatar with an LLM for conversational ability. During conversation, the audio speech of the avatar is used as a driving signal to animate the face model, enabling precise synchronization. We describe improvements to our dynamic Gaussian models that enhance photorealism: SWinGS++ for body reconstruction and HeadGaS++ for face reconstruction, and provide as well a solution to merge the separate face and body models without artifacts. We also present a demo of the complete system, showcasing several use cases of real-time conversation with the 3D avatar. Our approach offers a fully integrated virtual avatar experience, supporting both oral and written form interactions in immersive environments. ICo3D is applicable to a wide range of fields, including gaming, virtual assistance, and personalized education, among others. Project page: https://ico3d.github.io/", "AI": {"tldr": "该研究提出了一种名为ICo3D的方法，能够生成交互式、会话式且照片级的3D虚拟人类化身，结合了多视图捕获、高斯溅射渲染、LLM对话能力以及面部和身体模型的无缝融合。", "motivation": "研究的动机是创建一个能够进行实时交互和对话的逼真3D虚拟人类化身，以满足游戏、虚拟助手和个性化教育等领域的需求。", "method": "该方法首先使用多视图捕获数据创建可动画化的3D面部模型和动态3D身体模型，两者均采用高斯溅射渲染。然后，将面部和身体模型合并，并集成一个大型语言模型（LLM）赋予其对话能力。音频语音被用作驱动信号来驱动面部模型动画，实现精确同步。研究还介绍了用于身体重建的SWinGS++和用于面部重建的HeadGaS++，并提供了一种无缝合并面部和身体模型的方法。", "result": "研究成功展示了一个完整的ICo3D系统演示，能够实现与3D化身的实时对话，支持口头和书面交互。通过SWinGS++和HeadGaS++的改进，提高了照片真实感，并实现了面部和身体模型的无瑕疵融合。", "conclusion": "ICo3D提供了一种集成式虚拟化身解决方案，能够实现逼真、交互和对话式的3D虚拟人类。该方法在多个应用领域具有广泛的潜力，能够提升用户在沉浸式环境中的体验。"}}
{"id": "2601.13132", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13132", "abs": "https://arxiv.org/abs/2601.13132", "authors": ["Kim Yu-Ji", "Dahye Lee", "Kim Jun-Seong", "GeonU Kim", "Nam Hyeon-Woo", "Yongjin Kwon", "Yu-Chiang Frank Wang", "Jaesung Choe", "Tae-Hyun Oh"], "title": "GaussExplorer: 3D Gaussian Splatting for Embodied Exploration and Reasoning", "comment": "Project page: https://gaussexplorer.github.io/", "summary": "We present GaussExplorer, a framework for embodied exploration and reasoning built on 3D Gaussian Splatting (3DGS). While prior approaches to language-embedded 3DGS have made meaningful progress in aligning simple text queries with Gaussian embeddings, they are generally optimized for relatively simple queries and struggle to interpret more complex, compositional language queries. Alternative studies based on object-centric RGB-D structured memories provide spatial grounding but are constrained by pre-fixed viewpoints. To address these issues, GaussExplorer introduces Vision-Language Models (VLMs) on top of 3DGS to enable question-driven exploration and reasoning within 3D scenes. We first identify pre-captured images that are most correlated with the query question, and subsequently adjust them into novel viewpoints to more accurately capture visual information for better reasoning by VLMs. Experiments show that ours outperforms existing methods on several benchmarks, demonstrating the effectiveness of integrating VLM-based reasoning with 3DGS for embodied tasks.", "AI": {"tldr": "GaussExplorer 是一个基于 3D 高斯溅射（3DGS）的具身探索与推理框架，它集成了视觉-语言模型（VLM）来处理复杂的、组合性的语言查询，并通过调整图像视角来增强推理能力，在多项基准测试中表现优于现有方法。", "motivation": "现有基于 3DGS 的语言嵌入方法难以处理复杂的组合性语言查询，而基于对象中心 RGB-D 结构化内存的方法则受限于预设视角。因此，需要一种能够支持更复杂语言查询和灵活视角调整的具身探索与推理框架。", "method": "GaussExplorer 在 3DGS 的基础上引入了视觉-语言模型（VLM）。首先，识别与查询问题最相关的预捕获图像，然后将其调整到新的视角，以更准确地捕获视觉信息供 VLM 进行推理。最后，利用 VLM 进行问题驱动的 3D 场景探索与推理。", "result": "实验表明，GaussExplorer 在多个基准测试中优于现有方法，证明了将 VLM 推理与 3DGS 集成在具身任务中的有效性。", "conclusion": "通过结合 VLM 的推理能力和 3DGS 的优势，并引入自适应视角调整机制，GaussExplorer 能够有效地实现复杂语言查询驱动的 3D 场景探索与推理，为具身智能任务提供了新的解决方案。"}}
{"id": "2601.14112", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14112", "abs": "https://arxiv.org/abs/2601.14112", "authors": ["George Mihaila"], "title": "Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns", "comment": null, "summary": "Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.", "AI": {"tldr": "本文提出了一种名为Explanation Network (ExpNet) 的轻量级神经网络，用于自动学习Transformer模型的注意力模式与token重要性得分之间的映射关系，以解决现有可解释性方法手动定义聚合策略和固定归因规则的问题，并提高了效率。", "motivation": "Transformer模型在医疗、法律和金融等高风险领域的应用越来越广泛，但其不透明性阻碍了信任和问责。现有的基于注意力机制的解释方法依赖于手动定义的聚合策略和固定的归因规则，而模型无关的方法计算成本高昂。因此，需要一种更有效、更自动化的可解释性方法。", "method": "提出了一种名为Explanation Network (ExpNet) 的轻量级神经网络。ExpNet能够从Transformer的注意力模式中学习到token级别的显式重要性得分映射。与以往方法不同，ExpNet能自动发现最佳的注意力特征组合，而无需预设规则。", "result": "在具有挑战性的跨任务环境中对ExpNet进行了评估，并将其与四种方法家族（包括模型无关方法和基于注意力的方法）进行了基准测试。结果表明ExpNet在解释Transformer模型方面表现出色。", "conclusion": "ExpNet是一种新颖的、轻量级的神经网络，能够自动学习Transformer的注意力模式到token重要性得分的映射，克服了现有方法在人工定义和计算效率上的局限性，为Transformer模型的可解释性提供了有效解决方案。"}}
{"id": "2601.14055", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14055", "abs": "https://arxiv.org/abs/2601.14055", "authors": ["Andrea Protani", "Marc Molina Van Den Bosch", "Lorenzo Giusti", "Heloisa Barbosa Da Silva", "Paolo Cacace", "Albert Sund Aillet", "Miguel Angel Gonzalez Ballester", "Friedhelm Hummel", "Luigi Serio"], "title": "Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI", "comment": "10 pages, 3 figures,", "summary": "Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, a design that allocates a significant portion of its parameters to spatial reconstruction rather than feature learning. Our approach introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of supervoxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework's flexibility, we trained two specialized models on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving a F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder's ability to learn discriminative and localized features. Our results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation.", "AI": {"tldr": "该研究提出了一种名为SVGFormer的创新的3D医学影像处理框架，它摒弃了传统的编码器-解码器结构，转而采用基于内容分组和图注意力网络的层次化编码器，专注于特征学习而非空间重建，从而在提高模型效率和可解释性方面取得了显著成果。", "motivation": "现有的3D医学影像处理模型通常采用参数量庞大的编码器-解码器结构，将大量参数用于空间重建而非特征学习，导致效率低下。研究者希望提出一种新的方法，能够将模型能力集中于特征学习，并提供更好的可解释性。", "method": "该方法名为SVGFormer，其核心是一个无解码器的流水线。首先，通过内容感知分组将三维体素网格划分为超体素的语义图。然后，采用一个分层的编码器，结合了补丁级Transformer和超体素级图注意力网络，以学习丰富的节点表示，同时建模了精细的区域内特征和广泛的区域间依赖关系。", "result": "在BraTS数据集上训练的两个专用模型（节点级分类和肿瘤比例回归）均取得了优异的性能。分类模型达到了0.875的F1分数，回归模型达到了0.028的平均绝对误差（MAE），证明了编码器能够学习到具有区分性和局部性的特征。", "conclusion": "基于图的、仅编码器的范式为3D医学影像表示提供了一种准确且具有内在可解释性的替代方案，它能够有效地将模型容量集中于特征编码，并提供从补丁到区域的双重可解释性。"}}
{"id": "2601.13207", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13207", "abs": "https://arxiv.org/abs/2601.13207", "authors": ["Jinnao Li", "Zijian Chen", "Tingzhu Chen", "Changbo Wang"], "title": "GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction", "comment": null, "summary": "Geo-localization aims to infer the geographic location where an image was captured using observable visual evidence. Traditional methods achieve impressive results through large-scale training on massive image corpora. With the emergence of multi-modal large language models (MLLMs), recent studies have explored their applications in geo-localization, benefiting from improved accuracy and interpretability. However, existing benchmarks largely ignore the temporal information inherent in images, which can further constrain the location. To bridge this gap, we introduce GTPred, a novel benchmark for geo-temporal prediction. GTPred comprises 370 globally distributed images spanning over 120 years. We evaluate MLLM predictions by jointly considering year and hierarchical location sequence matching, and further assess intermediate reasoning chains using meticulously annotated ground-truth reasoning processes. Experiments on 8 proprietary and 7 open-source MLLMs show that, despite strong visual perception, current models remain limited in world knowledge and geo-temporal reasoning. Results also demonstrate that incorporating temporal information significantly enhances location inference performance.", "AI": {"tldr": "提出一个名为 GTPred 的新基准，用于地理-时间预测，该基准包含跨越 120 多年的 370 张全球图像，并评估了多模态大语言模型（MLLM）在利用时间信息进行地理定位方面的能力。", "motivation": "现有地理定位方法忽略了图像中固有的时间信息，而时间信息可以进一步约束地理位置。旨在弥补这一差距，并探索 MLLMs 在结合时间信息进行地理定位方面的潜力。", "method": "构建了一个包含 370 张全球图像的 GTPred 基准，这些图像跨越 120 多年。通过联合考虑年份和分层位置序列匹配来评估 MLLMs 的预测，并使用详细标注的地面真实推理过程来评估中间推理链。", "result": "在 8 个专有模型和 7 个开源 MLLMs 上进行实验，结果表明，尽管 MLLMs 具有强大的视觉感知能力，但在世界知识和地理-时间推理方面仍存在局限性。此外，实验证明，整合时间信息可以显著提高地理定位的推理性能。", "conclusion": "GTPred 基准的引入突出了 MLLMs 在地理-时间推理方面的不足，并证明了时间信息在地理定位任务中的重要性。未来的研究应侧重于增强 MLLMs 的世界知识和地理-时间推理能力。"}}
{"id": "2601.14123", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.14123", "abs": "https://arxiv.org/abs/2601.14123", "authors": ["Sofia Bennani", "Charles Moslonka"], "title": "A Systematic Analysis of Chunking Strategies for Reliable Question Answering", "comment": "3 pages, 2 figures, 1 table, pre-print", "summary": "We study how document chunking choices impact the reliability of Retrieval-Augmented Generation (RAG) systems in industry. While practice often relies on heuristics, our end-to-end evaluation on Natural Questions systematically varies chunking method (token, sentence, semantic, code), chunk size, overlap, and context length. We use a standard industrial setup: SPLADE retrieval and a Mistral-8B generator. We derive actionable lessons for cost-efficient deployment: (i) overlap provides no measurable benefit and increases indexing cost; (ii) sentence chunking is the most cost-effective method, matching semantic chunking up to ~5k tokens; (iii) a \"context cliff\" reduces quality beyond ~2.5k tokens; and (iv) optimal context depends on the goal (semantic quality peaks at small contexts; exact match at larger ones).", "AI": {"tldr": "本文研究了文档分块策略对工业界检索增强生成（RAG）系统可靠性的影响，发现句块是最具成本效益的方法，重叠没有收益，并且检索上下文长度存在最佳阈值。", "motivation": "工业界RAG系统在文档分块方面通常依赖启发式方法，缺乏系统性的评估，因此需要研究最优的分块策略以提高可靠性和成本效益。", "method": "研究者在自然问题数据集上，端到端地评估了不同的分块方法（token、sentence、semantic、code）、块大小、重叠和上下文长度。实验使用了SPLADE检索器和Mistral-8B生成器。", "result": "1. 文档重叠不会带来可衡量的效益，反而会增加索引成本。 2. 句块（sentence chunking）是最具成本效益的分块方法，在高达约5k token的情况下，其效果与语义分块（semantic chunking）相当。 3. 上下文长度超过约2.5k token后，RAG系统的质量会明显下降（“上下文悬崖”）。 4. 最优的上下文长度取决于具体目标，语义质量在短上下文时达到峰值，而精确匹配在长上下文时表现更好。", "conclusion": "为了实现成本效益高的RAG系统部署，应避免使用文档重叠，选择句块作为主要分块策略，并注意上下文长度的“上下文悬崖”效应，根据任务需求调整上下文长度。"}}
{"id": "2601.14230", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.14230", "abs": "https://arxiv.org/abs/2601.14230", "authors": ["Yiyang Wang", "Yiqiao Jin", "Alex Cabral", "Josiah Hester"], "title": "MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems", "comment": "15 pages, 9 figures", "summary": "Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective socio-collaborative companions. MASCOT introduces a novel bi-level optimization strategy to harmonize individual and collective behaviors: 1) Persona-Aware Behavioral Alignment, an RLAIF-driven pipeline that finetunes individual agents for strict persona fidelity to prevent identity loss; and 2) Collaborative Dialogue Optimization, a meta-policy guided by group-level rewards to ensure diverse and productive discourse. Extensive evaluations across psychological support and workplace domains demonstrate that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution. Our framework provides a practical roadmap for engineering the next generation of socially intelligent multi-agent systems.", "AI": {"tldr": "MASCOT 是一个多智能体系统框架，通过“Persona-Aware Behavioral Alignment”和“Collaborative Dialogue Optimization”解决传统多智能体系统中存在的“角色崩溃”和“虚伪奉承”问题，提升了角色的个性和对话的社会贡献度。", "motivation": "现有的多智能体系统在提供情感和认知支持时，常出现角色崩溃（个体智能体行为同质化）和社交虚伪（生成冗余、无建设性的对话）的问题。", "method": "提出 MASCOT 框架，采用双层优化策略：1) 基于 RLAIF 的“Persona-Aware Behavioral Alignment”用于微调个体智能体，确保其角色忠诚度；2) 基于群体奖励的元策略“Collaborative Dialogue Optimization”用于优化协作对话，确保多样性和生产力。", "result": "在心理支持和工作场所领域的评估中，MASCOT 的“Persona Consistency”和“Social Contribution”相较于现有最先进的基线模型，分别提高了 +14.1 和 +10.6。", "conclusion": "MASCOT 提供了一个通用的框架，能够有效地工程化下一代具有社会智能的多智能体系统，解决了角色同质化和对话冗余的问题，显著提升了系统的角色一致性和社会贡献。"}}
{"id": "2601.13208", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13208", "abs": "https://arxiv.org/abs/2601.13208", "authors": ["Vikram R Lakkavalli"], "title": "Rethinking Skip Connections: Additive U-Net for Robust and Interpretable Denoising", "comment": null, "summary": "Skip connections are central to U-Net architectures for image denoising, but standard concatenation doubles channel dimensionality and obscures information flow, allowing uncontrolled noise transfer. We propose the Additive U-Net, which replaces concatenative skips with gated additive connections. Each skip pathway is scaled by a learnable non-negative scalar, offering explicit and interpretable control over encoder contributions while avoiding channel inflation. Evaluations on the Kodak-17 denoising benchmark show that Additive U-Net achieves competitive PSNR/SSIM at noise levels σ = 15, 25, 50, with robustness across kernel schedules and depths. Notably, effective denoising is achieved even without explicit down/up-sampling or forced hierarchies, as the model naturally learns a progression from high-frequency to band-pass to low-frequency features. These results position additive skips as a lightweight and interpretable alternative to concatenation, enabling both efficient design and a clearer understanding of multi-scale information transfer in reconstruction networks.", "AI": {"tldr": "本文提出了一种名为 Additive U-Net 的新型 U-Net 架构，用门控加法跳跃连接替代了传统的拼接跳跃连接，以提高图像去噪性能并控制信息流。", "motivation": "传统的 U-Net 架构在跳跃连接中使用拼接操作会加倍通道维度，并可能导致不受控制的噪声传递，影响信息流。作者希望找到一种更有效、更可控的方式来融合多尺度特征。", "method": "提出 Additive U-Net，将拼接跳跃连接替换为门控加法跳跃连接。每个跳跃连接的特征图都乘以一个可学习的非负标量，从而对编码器贡献进行显式控制，并避免通道维度的膨胀。", "result": "在 Kodak-17 数据集上进行的评估表明，Additive U-Net 在不同噪声水平（σ = 15, 25, 50）下取得了具有竞争力的 PSNR/SSIM 结果。该模型在不同核调度和深度下都表现出鲁棒性。模型无需显式的下采样/上采样或强制分层结构，即可学习到从高频到带通再到低频特征的 progression。", "conclusion": "加法跳跃连接是一种轻量级且可解释的替代拼接跳跃连接的方法，可以实现高效的网络设计，并更清晰地理解重建网络中多尺度信息的传递。"}}
{"id": "2601.13218", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13218", "abs": "https://arxiv.org/abs/2601.13218", "authors": ["Igor Vozniak", "Philipp Mueller", "Nils Lipp", "Janis Sprenger", "Konstantin Poddubnyy", "Davit Hovhannisyan", "Christian Mueller", "Andreas Bulling", "Philipp Slusallek"], "title": "ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments", "comment": "Accepted for publication at the IEEE Intelligent Vehicles Symposium (IV), 2026", "summary": "The object-based nature of human visual attention is well-known in cognitive science, but has only played a minor role in computational visual attention models so far. This is mainly due to a lack of suitable datasets and evaluation metrics for object-based attention. To address these limitations, we present \\dataset~ -- a novel 120-participant dataset of spatial street-crossing navigation in virtual reality specifically geared to object-based attention evaluations. The uniqueness of the presented dataset lies in the ethical and safety affiliated challenges that make collecting comparable data in real-world environments highly difficult. \\dataset~ not only features accurate gaze data and a complete state-space representation of objects in the virtual environment, but it also offers variable scenario complexities and rich annotations, including panoptic segmentation, depth information, and vehicle keypoints. We further propose object-based similarity (oSIM) as a novel metric to evaluate the performance of object-based visual attention models, a previously unexplored performance characteristic. Our evaluations show that explicitly optimising for object-based attention not only improves oSIM performance but also leads to an improved model performance on common metrics. In addition, we present SUMGraph, a Mamba U-Net-based model, which explicitly encodes critical scene objects (vehicles) in a graph representation, leading to further performance improvements over several state-of-the-art visual attention prediction methods. The dataset, code and models will be publicly released.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.14210", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14210", "abs": "https://arxiv.org/abs/2601.14210", "authors": ["Rohan Bhatnagar", "Youran Sun", "Chi Andrew Zhang", "Yixin Wen", "Haizhao Yang"], "title": "HALT: Hallucination Assessment via Latent Testing", "comment": null, "summary": "Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI.", "AI": {"tldr": "研究提出了一种轻量级的残差探针，可以直接从LLM中间隐藏状态读取“幻觉”风险，并将其用作“代理评论员”来过滤问题，从而提高LLM的可靠性。", "motivation": "大型语言模型（LLMs）的“幻觉”问题（即生成看似流畅但实际上是错误的答案）源于其最终解码阶段的固有压力，尽管中间表示可能包含不确定性信息。因此，需要一种能够直接从中间隐藏状态读取不确定性信号的方法，以更早地检测到幻觉风险。", "method": "提出了一种名为“残差探针”的轻量级辅助网络。该探针通过分析问题token在LLM中间层的隐藏状态来直接读取幻觉风险。探针的计算成本远低于token生成，并且可以与推理并行运行。它被用作一个“代理评论员”，能够识别出风险低的问题并立即回答，而将风险高的问题交给更强的验证流程。", "result": "该方法在四个QA基准测试和多个LLM家族中都取得了优秀的AUROC和AURAC得分，并且在数据集迁移方面表现出良好的泛化能力。此外，研究还揭示了中间表示中可解释的结构。", "conclusion": "通过直接读取LLM内部的不确定性信号，可以为可靠的代理AI奠定一个原则性的基础。这种方法能够近乎实时地评估幻觉风险，并在低风险情况下几乎不增加延迟，从而提高了LLM的可靠性。"}}
{"id": "2601.14242", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14242", "abs": "https://arxiv.org/abs/2601.14242", "authors": ["Bertie Vidgen", "Austin Mann", "Abby Fennelly", "John Wright Stanly", "Lucas Rothman", "Marco Burstein", "Julien Benchek", "David Ostrofsky", "Anirudh Ravichandran", "Debnil Sur", "Neel Venugopal", "Alannah Hsia", "Isaac Robinson", "Calix Huang", "Olivia Varones", "Daniyal Khan", "Michael Haines", "Zach Richards", "Chirag Mahapatra", "Brendan Foody", "Osvald Nitski"], "title": "APEX-Agents", "comment": null, "summary": "We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.", "AI": {"tldr": "该研究提出了一个名为APEX-Agents的基准测试，用于评估AI代理在需要跨多个应用程序执行长期任务时的能力。研究结果显示，Gemini 3 Flash在测试的八个代理中表现最佳。", "motivation": "为了评估AI代理在处理现实世界中复杂、长期、跨应用程序任务的能力，尤其是在投资银行、管理咨询和公司法律等专业领域。", "method": "创建了APEX-Agents基准测试，包含由专业人士设计的480个任务，这些任务需要代理在模拟的工作环境中与文件和工具交互。对八个AI代理进行了测试，并使用Pass@1指标评估其性能。", "result": "Gemini 3 Flash（Thinking=High）在APEX-Agents基准测试中取得了最高的24.0%得分，其次是GPT-5.2、Claude Opus 4.5和Gemini 3 Pro。研究还开源了APEX-Agents基准测试及其执行和评估的基础设施Archipelago。", "conclusion": "APEX-Agents为衡量AI代理在现实工作场景中的跨应用程序任务执行能力提供了一个有效的基准。Gemini 3 Flash在当前测试中表现出领先的性能，表明大型语言模型在处理复杂任务方面取得了进展。"}}
{"id": "2601.14172", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14172", "abs": "https://arxiv.org/abs/2601.14172", "authors": ["Víctor Yeste", "Paolo Rosso"], "title": "Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum", "comment": "Code: https://github.com/VictorMYeste/human-value-detection, 37 pages, 4 figures,", "summary": "We study sentence-level identification of the 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. The setting - out-of-context sentences from news and political manifestos - features sparse moral cues and severe class imbalance. This combination makes fine-grained sentence-level value detection intrinsically difficult, even for strong modern neural models. We first operationalize a binary moral presence task (\"does any value appear?\") and show that it is learnable from single sentences (positive-class F1 $\\approx$ 0.74 with calibrated thresholds). We then compare a presence-gated hierarchy to a direct multi-label classifier under matched compute, both based on DeBERTa-base and augmented with lightweight signals (prior-sentence context, LIWC-22/eMFD/MJD lexica, and topic features). The hierarchy does not outperform direct prediction, indicating that gate recall limits downstream gains. We also benchmark instruction-tuned LLMs - Gemma 2 9B, Llama 3.1 8B, Mistral 8B, and Qwen 2.5 7B - in zero-/few-shot and QLoRA setups and build simple ensembles; a soft-vote supervised ensemble reaches macro-F1 0.332, significantly surpassing the best single supervised model and exceeding prior English-only baselines. Overall, in this scenario, lightweight signals and small ensembles yield the most reliable improvements, while hierarchical gating offers limited benefit. We argue that, under an 8 GB single-GPU constraint and at the 7-9B scale, carefully tuned supervised encoders remain a strong and compute-efficient baseline for structured human value detection, and we outline how richer value structure and sentence-in-document context could further improve performance.", "AI": {"tldr": "本研究旨在解决新闻和政治宣言中，不包含上下文的单个句子层面识别19种人类价值观的难题。研究发现，虽然存在稀疏的道德线索和严重的类别不平衡，但可以成功进行二元道德存在任务（F1约0.74）。在直接多标签分类和门控层级结构之间，直接预测表现更好。通过指令微调的LLM（Gemma 2, Llama 3.1, Mistral, Qwen 2.5）在零/少样本和QLoRA设置下，以及简单的集成模型，可以显著提高性能（宏F1 0.332）。研究表明，在资源受限的情况下，轻量级信号和小型集成模型能带来最可靠的改进，而层级门控效果有限。同时，在8GB单GPU和7-9B模型规模下，经过仔细调整的监督编码器仍然是有效且计算效率高的基线。", "motivation": "人类价值观在文本中的识别，尤其是在缺乏上下文的单个句子层面，是一个具有挑战性的任务，这得益于新闻和政治宣言等语料的特点，即道德线索稀疏且类别极不平衡。", "method": "研究者首先定义了一个二元的道德存在识别任务，并评估其在单句上的可学习性。然后，他们比较了基于DeBERTa-base的两种方法：一个是有门控的层级结构和一个直接的多标签分类器，并加入了上下文、词典（LIWC-22/eMFD/MJD）和主题特征等辅助信号。此外，他们还评估了多种指令微调的LLMs（Gemma 2, Llama 3.1, Mistral, Qwen 2.5）在零/少样本和QLoRA设置下的表现，并构建了简单的集成模型。", "result": "二元道德存在任务在单句上是可学习的（F1约0.74）。门控层级结构并未优于直接多标签分类器。指令微调的LLMs结合集成模型（软投票监督集成）可以达到0.332的宏F1分数，显著优于单个监督模型和之前的英文基线。", "conclusion": "在缺乏上下文的单个句子层面识别价值观的任务中，轻量级信号和小型集成模型能提供最可靠的性能提升。层级门控策略的益处有限。在8GB单GPU和7-9B模型规模的限制下，经过精心调整的监督式编码器仍然是计算高效且性能强大的基线。未来的工作可以探索更丰富的价值观结构和文档内的句子上下文来进一步提高性能。"}}
{"id": "2601.14249", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14249", "abs": "https://arxiv.org/abs/2601.14249", "authors": ["Yuming Yang", "Mingyoung Lai", "Wanxu Zhao", "Xiaoran Fan", "Zhiheng Xi", "Mingqi Wu", "Chiyue Huang", "Jun Zhao", "Haijun Lv", "Jian Tong", "Yunhua Zhou", "Yicheng Zou", "Qipeng Guo", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment", "comment": "26 pages. Project page: https://github.com/UmeanNever/RankSurprisalRatio", "summary": "Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.", "AI": {"tldr": "本文提出了一种名为Rank-Surprisal Ratio (RSR)的新指标，用于评估长CoT轨迹在知识蒸馏中的适用性。RSR结合了轨迹的对齐度和信息量，比现有指标更能预测蒸馏后的学生模型性能。", "motivation": "现有方法通过学生模型对轨迹的似然度来评估轨迹的适用性，这倾向于选择与学生当前行为相似的轨迹，但可能忽略了更具信息量的轨迹。研究表明，更强的教师模型生成的轨迹并不一定能带来更好的学生模型，说明数据-学生匹配度的重要性。", "method": "提出Rank-Surprisal Ratio (RSR)指标，定义为轨迹的平均token排名与其平均负对数似然度之比。该指标旨在捕捉轨迹的对齐度和信息量，即低绝对概率与相对较高的token排名相结合。", "result": "RSR指标在评估轨迹适用性方面表现出色，与学生模型训练后的性能有很强的相关性（平均Spearman相关系数为0.86），优于现有指标。在轨迹选择和教师选择方面也显示出其实用性。", "conclusion": "RSR是一个简单有效的指标，可以准确评估长CoT轨迹在知识蒸馏中的适用性，并能帮助选择更优的轨迹和教师模型，从而提升学生模型的性能。"}}
{"id": "2601.14121", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14121", "abs": "https://arxiv.org/abs/2601.14121", "authors": ["Jonathan Tonglet", "Iryna Gurevych", "Tinne Tuytelaars", "Marie-Francine Moens"], "title": "NewsRECON: News article REtrieval for image CONtextualization", "comment": "Preprint under review. Code available at https://github.com/jtonglet/arxiv2025-newsrecon", "summary": "Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.", "AI": {"tldr": "提出了一种名为 NewsRECON 的新方法，在缺乏反向图像搜索（RIS）证据的情况下，通过将图像链接到相关新闻文章来推断其拍摄日期和地点。", "motivation": "现有的新闻图像时空定位方法依赖于 RIS，但 RIS 经常失效，限制了其应用。因此，需要一种在 RIS 证据不可用的情况下也能工作的解决方案。", "method": "NewsRECON 方法整合了三个组件：1) 一个双编码器用于检索与事件相关的文章；2) 两个跨编码器用于按地点和事件一致性对文章进行重新排序。该方法使用了一个包含超过 90,000 篇文章的语料库。", "result": "在 TARA 和 5Pils-OOC 数据集上的实验表明，NewsRECON 的性能优于先前的方法，并且可以与多模态大型语言模型结合，在没有 RIS 证据的情况下达到新的 SOTA 结果。", "conclusion": "NewsRECON 能够有效地在缺乏 RIS 证据的情况下，通过链接图像到新闻文章来推断其拍摄日期和地点，并实现了优于现有方法的性能。"}}
{"id": "2601.13234", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13234", "abs": "https://arxiv.org/abs/2601.13234", "authors": ["Md. Nishan Khan", "Kazi Shahriar Sanjid", "Md. Tanzim Hossain", "Asib Mostakim Fony", "Istiak Ahmed", "M. Monir Uddin"], "title": "ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection", "comment": null, "summary": "Epilepsy is a chronic neurological disorder marked by recurrent seizures that can severely impact quality of life. Electroencephalography (EEG) remains the primary tool for monitoring neural activity and detecting seizures, yet automated analysis remains challenging due to the temporal complexity of EEG signals. This study introduces ConvMambaNet, a hybrid deep learning model that integrates Convolutional Neural Networks (CNNs) with the Mamba Structured State Space Model (SSM) to enhance temporal feature extraction. By embedding the Mamba-SSM block within a CNN framework, the model effectively captures both spatial and long-range temporal dynamics. Evaluated on the CHB-MIT Scalp EEG dataset, ConvMambaNet achieved a 99% accuracy and demonstrated robust performance under severe class imbalance. These results underscore the model's potential for precise and efficient seizure detection, offering a viable path toward real-time, automated epilepsy monitoring in clinical environments.", "AI": {"tldr": "本文提出了一种名为ConvMambaNet的混合深度学习模型，通过结合CNN和Mamba SSM来提高癫痫检测的准确性，特别是在类别不平衡的情况下表现出色。", "motivation": "尽管EEG是监测癫痫和检测癫痫发作的主要工具，但由于EEG信号的时间复杂性，自动化分析仍然具有挑战性。研究旨在提高EEG信号的时空特征提取能力，以实现更精确高效的癫痫检测。", "method": "该研究提出了一种名为ConvMambaNet的混合深度学习模型，该模型将CNN与Mamba SSM相结合，并在CNN框架内嵌入Mamba-SSM模块，以同时捕捉空间和长程时间动态。", "result": "在CHB-MIT头皮EEG数据集上进行评估，ConvMambaNet达到了99%的准确率，并在严重的类别不平衡情况下表现出稳健的性能。", "conclusion": "ConvMambaNet模型在癫痫检测方面具有精确高效的潜力，为在临床环境中实现实时自动化癫痫监测提供了一条可行的途径。"}}
{"id": "2601.13225", "categories": ["cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13225", "abs": "https://arxiv.org/abs/2601.13225", "authors": ["Tim Lachmann", "Alexandra Israelsson", "Christina Tornberg", "Teimuraz Saghinadze", "Michal Balazia", "Philipp Müller", "Petri Laukka"], "title": "Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations", "comment": "Accepted for publication at IEEE Face & Gesture 2026", "summary": "Humans often experience not just a single basic emotion at a time, but rather a blend of several emotions with varying salience. Despite the importance of such blended emotions, most video-based emotion recognition approaches are designed to recognize single emotions only. The few approaches that have attempted to recognize blended emotions typically cannot assess the relative salience of the emotions within a blend. This limitation largely stems from the lack of datasets containing a substantial number of blended emotion samples annotated with relative salience. To address this shortcoming, we introduce BLEMORE, a novel dataset for multimodal (video, audio) blended emotion recognition that includes information on the relative salience of each emotion within a blend. BLEMORE comprises over 3,000 clips from 58 actors, performing 6 basic emotions and 10 distinct blends, where each blend has 3 different salience configurations (50/50, 70/30, and 30/70). Using this dataset, we conduct extensive evaluations of state-of-the-art video classification approaches on two blended emotion prediction tasks: (1) predicting the presence of emotions in a given sample, and (2) predicting the relative salience of emotions in a blend. Our results show that unimodal classifiers achieve up to 29% presence accuracy and 13% salience accuracy on the validation set, while multimodal methods yield clear improvements, with ImageBind + WavLM reaching 35% presence accuracy and HiCMAE 18% salience accuracy. On the held-out test set, the best models achieve 33% presence accuracy (VideoMAEv2 + HuBERT) and 18% salience accuracy (HiCMAE). In sum, the BLEMORE dataset provides a valuable resource to advancing research on emotion recognition systems that account for the complexity and significance of blended emotion expressions.", "AI": {"tldr": "本文提出了BLEMORE数据集，用于识别多模态（视频、音频）的混合情绪及其相对显著性，并评估了现有模型在该任务上的表现，发现多模态方法优于单模态方法。", "motivation": "现有情绪识别方法多侧重于单一情绪，忽略了人类情绪的混合性及其相对重要性，并且缺乏包含混合情绪及其相对显著性标注的数据集。", "method": "构建了一个包含3000多个视频片段、涵盖6种基本情绪和10种混合情绪（每种混合情绪有3种显著性配置）的多模态数据集BLEMORE。使用该数据集对两种预测任务（情绪存在性预测和情绪相对显著性预测）进行了评估，并对比了单模态和多模态状态-of-the-art模型。", "result": "单模态分类器在情绪存在性预测任务上的准确率最高为29%，在显著性预测任务上最高为13%。多模态方法表现更优，ImageBind + WavLM在存在性预测上达到35%，HiCMAE在显著性预测上达到18%。最终在测试集上，最佳模型在存在性预测上达到33%（VideoMAEv2 + HuBERT），在显著性预测上达到18%（HiCMAE）。", "conclusion": "BLEMORE数据集为研究能够处理复杂混合情绪表达的情绪识别系统提供了宝贵的资源。多模态方法在识别混合情绪及其相对显著性方面具有明显优势。"}}
{"id": "2601.14255", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14255", "abs": "https://arxiv.org/abs/2601.14255", "authors": ["Sangbeom Lim", "Seoung Wug Oh", "Jiahui Huang", "Heeji Yoon", "Seungryong Kim", "Joon-Young Lee"], "title": "VideoMaMa: Mask-Guided Video Matting via Generative Prior", "comment": "Project page: https://cvlab-kaist.github.io/VideoMaMa/", "summary": "Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.", "AI": {"tldr": "本文提出了一种名为 VideoMaMa 的新方法，利用预训练的视频扩散模型将粗糙的分割掩膜转换为像素级的 alpha 抠图，并实现了在真实世界视频上的零样本泛化。在此基础上，开发了一个大规模伪标签生成流程，构建了包含 50K+ 真实视频的 MA-V 数据集。通过在 MA-V 数据集上微调 SAM2 模型，得到了 SAM2-Matte，其在真实世界视频上的鲁棒性优于在现有数据集上训练的模型。", "motivation": "真实世界视频的标注数据稀缺，导致现有的视频抠图模型泛化能力不足。", "method": "1. 提出 VideoMaMa 模型，利用预训练的视频扩散模型，通过粗糙分割掩膜生成精确的 alpha 抠图。 2. 构建大规模伪标签生成流程，创建 MA-V 数据集。 3. 将 SAM2 模型在 MA-V 数据集上进行微调，得到 SAM2-Matte。", "result": "VideoMaMa 模型在仅使用合成数据训练的情况下，能够很好地泛化到真实世界视频。 MA-V 数据集包含了超过 50,000 个真实世界视频的高质量抠图标注。 SAM2-Matte 模型在真实世界视频上的鲁棒性优于在现有数据集上训练的同模型。", "conclusion": "大规模伪标签视频抠图至关重要。生成模型先验和可访问的分割线索能够有效推动视频抠图领域的研究进展。"}}
{"id": "2601.14127", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14127", "abs": "https://arxiv.org/abs/2601.14127", "authors": ["Renmiao Chen", "Yida Lu", "Shiyao Cui", "Xuan Ouyang", "Victor Shea-Jay Huang", "Shumin Zhang", "Chengwei Pan", "Han Qiu", "Minlie Huang"], "title": "The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning", "comment": "*15 pages, 5 figures. Introduces MIR-SafetyBench (2,676 instances; 9 multi-image relations). Equal contribution; †Corresponding author. Code/data: https://github.com/thu-coai/MIR-SafetyBench", "summary": "As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.", "AI": {"tldr": "本研究提出了MIR-SafetyBench，首个关注多图像推理安全性的基准测试，旨在评估多模态大语言模型（MLLMs）在处理多图像指令时的潜在安全风险。研究发现，推理能力更强的模型在多图像推理安全性方面可能更脆弱，并且不安全的生成具有较低的注意力熵，这表明模型可能在解决任务时忽视了安全约束。", "motivation": "随着MLLMs在处理复杂多图像指令的推理能力增强，可能会带来新的安全风险。因此，研究需要一个专门的基准来评估和理解这些风险。", "method": "研究提出了MIR-SafetyBench，一个包含2,676个实例、覆盖9种多图像关系的基准测试。对19个MLLMs进行了广泛评估，分析了攻击成功率、响应的安全性（区分肤浅/逃避性回答）、以及安全与不安全生成响应的注意力熵。", "result": "研究发现，多图像推理能力更强的模型在MIR-SafetyBench上可能更脆弱。许多被标记为安全的响应是肤浅的，要么是由于误解，要么是逃避性的。不安全的生成比安全的生成平均具有更低的注意力熵。", "conclusion": "多图像推理能力的提升可能伴随着安全性的下降。注意力熵可以作为区分安全和不安全生成的一个内部信号，表明模型在任务解决和安全约束之间可能存在权衡。"}}
{"id": "2601.13299", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13299", "abs": "https://arxiv.org/abs/2601.13299", "authors": ["Ethan Seefried", "Prahitha Movva", "Naga Harshita Marupaka", "Tilak Kasturi", "Tirthankar Ghosal"], "title": "Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams", "comment": "Accepted at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Ai4 Science", "summary": "We propose Enginuity - the first open, large-scale, multi-domain engineering diagram dataset with comprehensive structural annotations designed for automated diagram parsing. By capturing hierarchical component relationships, connections, and semantic elements across diverse engineering domains, our proposed dataset would enable multimodal large language models to address critical downstream tasks including structured diagram parsing, cross-modal information retrieval, and AI-assisted engineering simulation. Enginuity would be transformative for AI for Scientific Discovery by enabling artificial intelligence systems to comprehend and manipulate the visual-structural knowledge embedded in engineering diagrams, breaking down a fundamental barrier that currently prevents AI from fully participating in scientific workflows where diagram interpretation, technical drawing analysis, and visual reasoning are essential for hypothesis generation, experimental design, and discovery.", "AI": {"tldr": "本文提出了Enginuity，一个首个大规模、多领域、带结构化注释的工程图数据集，用于自动化图解析，旨在赋能多模态大模型进行图解析、跨模态检索和AI辅助工程仿真。", "motivation": "工程图中的视觉-结构知识目前是AI理解和操作的瓶颈，阻碍了AI在科学发现中的应用，特别是在需要图解释、技术图分析和视觉推理的科学工作流程中。", "method": "构建了一个大规模、多领域、包含丰富结构化注释（如组件层级关系、连接和语义元素）的工程图数据集（Enginuity）。", "result": "Enginuity数据集的提出将使多模态大模型能够执行结构化图解析、跨模态信息检索和AI辅助工程仿真等关键下游任务。", "conclusion": "Enginuity数据集的开放性和全面性将极大地推动AI在科学发现领域的进步，尤其是在理解和处理工程图中的视觉-结构知识方面，从而打破AI在科学工作流程中的根本性障碍。"}}
{"id": "2601.13263", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13263", "abs": "https://arxiv.org/abs/2601.13263", "authors": ["Chenyu Liu", "Marco Cecotti", "Harikrishnan Vijayakumar", "Patrick Robinson", "James Barson", "Mihai Caleap"], "title": "Deep Learning for Semantic Segmentation of 3D Ultrasound Data", "comment": "14 pages, 10 figures, 8 tables, presented at 2025 13th International Conference on Robot Intelligence Technology and Applications (RITA)", "summary": "Developing cost-efficient and reliable perception systems remains a central challenge for automated vehicles. LiDAR and camera-based systems dominate, yet they present trade-offs in cost, robustness and performance under adverse conditions. This work introduces a novel framework for learning-based 3D semantic segmentation using Calyo Pulse, a modular, solid-state 3D ultrasound sensor system for use in harsh and cluttered environments. A 3D U-Net architecture is introduced and trained on the spatial ultrasound data for volumetric segmentation. Results demonstrate robust segmentation performance from Calyo Pulse sensors, with potential for further improvement through larger datasets, refined ground truth, and weighted loss functions. Importantly, this study highlights 3D ultrasound sensing as a promising complementary modality for reliable autonomy.", "AI": {"tldr": "本研究提出了一种基于3D超声波传感器（Calyo Pulse）的3D语义分割新框架，并使用3D U-Net架构进行训练，证明了其在恶劣和混乱环境下的鲁棒性，并将其作为LiDAR和摄像头之外的有前途的补充传感方式。", "motivation": "为了开发成本效益高且可靠的自动驾驶感知系统，研究人员希望找到超越传统LiDAR和摄像头的方法，因为它们在成本、鲁棒性和恶劣条件下的性能方面存在权衡。3D超声波传感器因其在恶劣和混乱环境中的潜力而被引入。", "method": "研究人员引入了一个新的基于学习的3D语义分割框架，该框架使用Calyo Pulse（一种模块化、固态3D超声波传感器）。他们设计并训练了一个3D U-Net架构，以对空间超声波数据进行体积分割。", "result": "结果表明，Calyo Pulse传感器在3D语义分割方面表现出鲁棒的性能。研究还指出了通过更大的数据集、更精确的地面真实数据和加权损失函数来进一步提高性能的潜力。", "conclusion": "3D超声波传感是一种有前途的补充模式，可以提高自动驾驶系统的可靠性，特别是对于恶劣和混乱的环境。本研究为利用3D超声波进行3D语义分割奠定了基础。"}}
{"id": "2601.13304", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13304", "abs": "https://arxiv.org/abs/2601.13304", "authors": ["Wenxin Ma", "Chenlong Wang", "Ruisheng Yuan", "Hao Chen", "Nanru Dai", "S. Kevin Zhou", "Yijun Yang", "Alan Yuille", "Jieneng Chen"], "title": "CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning", "comment": "Code is available: https://github.com/CausalSpatial/CausalSpatial", "summary": "Humans can look at a static scene and instantly predict what happens next -- will moving this object cause a collision? We call this ability Causal Spatial Reasoning. However, current multimodal large language models (MLLMs) cannot do this, as they remain largely restricted to static spatial perception, struggling to answer \"what-if\" questions in a 3D scene. We introduce CausalSpatial, a diagnostic benchmark evaluating whether models can anticipate consequences of object motions across four tasks: Collision, Compatibility, Occlusion, and Trajectory. Results expose a severe gap: humans score 84% while GPT-5 achieves only 54%. Why do MLLMs fail? Our analysis uncovers a fundamental deficiency: models over-rely on textual chain-of-thought reasoning that drifts from visual evidence, producing fluent but spatially ungrounded hallucinations. To address this, we propose the Causal Object World model (COW), a framework that externalizes the simulation process by generating videos of hypothetical dynamics. With explicit visual cues of causality, COW enables models to ground their reasoning in physical reality rather than linguistic priors. We make the dataset and code publicly available here: https://github.com/CausalSpatial/CausalSpatial", "AI": {"tldr": "提出CausalSpatial基准测试，评估多模态大语言模型（MLLMs）在三维场景中的因果空间推理能力，并发现现有模型表现远不如人类，且存在视觉信息脱钩问题。提出COW框架，通过生成模拟视频来增强模型的空间推理能力。", "motivation": "当前的多模态大语言模型（MLLMs）在处理静态三维场景的空间理解方面表现尚可，但在预测动态交互（如物体碰撞）方面的“假设”问题时存在严重不足。", "method": "设计了CausalSpatial基准测试，包含碰撞、兼容性、遮挡和轨迹四个任务，用于评估模型在三维场景中的因果空间推理能力。分析现有模型失败原因，提出COW（Causal Object World）框架，该框架通过生成假设性动态的视频来模拟物理过程，迫使模型将推理过程具象化。", "result": "在CausalSpatial基准测试中，人类的得分高达84%，而GPT-5仅为54%。分析表明，MLLMs过度依赖文本链式思考，脱离视觉证据，产生流畅但空间上不准确的幻觉。", "conclusion": "现有的MLLMs在因果空间推理方面存在显著差距，主要原因为其推理过程脱离了视觉证据。COW框架通过生成模拟视频，让模型能够基于物理现实而非语言先验来进行推理，从而显著改善了这一状况。"}}
{"id": "2601.13331", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13331", "abs": "https://arxiv.org/abs/2601.13331", "authors": ["Wei Wang", "Quoc-Toan Ly", "Chong Yu", "Jun Bai"], "title": "MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic", "comment": null, "summary": "Spatial transcriptomics (ST) enables transcriptome-wide profiling while preserving the spatial context of tissues, offering unprecedented opportunities to study tissue organization and cell-cell interactions in situ. Despite recent advances, existing methods often lack effective integration of histological morphology with molecular profiles, relying on shallow fusion strategies or omitting tissue images altogether, which limits their ability to resolve ambiguous spatial domain boundaries. To address this challenge, we propose MultiST, a unified multimodal framework that jointly models spatial topology, gene expression, and tissue morphology through cross-attention-based fusion. MultiST employs graph-based gene encoders with adversarial alignment to learn robust spatial representations, while integrating color-normalized histological features to capture molecular-morphological dependencies and refine domain boundaries. We evaluated the proposed method on 13 diverse ST datasets spanning two organs, including human brain cortex and breast cancer tissue. MultiST yields spatial domains with clearer and more coherent boundaries than existing methods, leading to more stable pseudotime trajectories and more biologically interpretable cell-cell interaction patterns. The MultiST framework and source code are available at https://github.com/LabJunBMI/MultiST.git.", "AI": {"tldr": "MultiST是一个统一的多模态框架，通过跨注意力融合，将空间拓扑、基因表达和组织形态学相结合，用于空间转录组学分析，能够更清晰地界定空间域，并提供更稳定的伪时间轨迹和更具生物学意义的细胞间相互作用模式。", "motivation": "现有的空间转录组学方法在整合组织形态学和分子谱方面存在不足，融合策略浅层化或完全忽略组织图像，导致难以精确解析模糊的空间域边界。", "method": "MultiST采用基于图的基因编码器，并结合对抗性对齐来学习鲁棒的空间表征。同时，整合颜色标准化的组织学特征，捕捉分子-形态学依赖性，并通过跨注意力机制进行融合，以细化空间域边界。", "result": "在13个涵盖人脑皮层和乳腺癌组织的空间转录组学数据集上进行的评估表明，MultiST生成 Thus, the framework and source code are available at https://github.com/LabJunBMI/MultiST.git. 的空间域边界比现有方法更清晰、更连贯，其伪时间轨迹更稳定，细胞间相互作用模式也更具生物学可解释性。", "conclusion": "MultiST是一个有效的多模态框架，能够通过整合空间拓扑、基因表达和组织形态学，显著提高空间转录组学分析的分辨率和生物学解释力，尤其在解析空间域边界方面表现优越。"}}
{"id": "2601.13364", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13364", "abs": "https://arxiv.org/abs/2601.13364", "authors": ["Zhenan Liu", "Yaodong Cui", "Amir Khajepour", "George Shaker"], "title": "Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments", "comment": null, "summary": "This paper introduces a novel methodology for generating controlled, multi-level dust concentrations in a highly cluttered environment representative of harsh, enclosed environments, such as underground mines, road tunnels, or collapsed buildings, enabling repeatable mm-wave propagation studies under severe electromagnetic constraints. We also present a new 4D mmWave radar dataset, augmented by camera and LiDAR, illustrating how dust particles and reflective surfaces jointly impact the sensing functionality. To address these challenges, we develop a threshold-based noise filtering framework leveraging key radar parameters (RCS, velocity, azimuth, elevation) to suppress ghost targets and mitigate strong multipath reflections at the raw data level. Building on the filtered point clouds, a cluster-level, rule-based classification pipeline exploits radar semantics-velocity, RCS, and volumetric spread-to achieve reliable, real-time pedestrian detection without extensive domainspecific training. Experimental results confirm that this integrated approach significantly enhances clutter mitigation, detection robustness, and overall system resilience in dust-laden mining environments.", "AI": {"tldr": "本文提出了一种在杂乱环境中生成可控多层尘埃浓度的方法，并发布了一个包含雷达、摄像头和激光雷达数据的4D数据集，用于研究恶劣环境下的毫米波雷达传播和行人检测。通过基于阈值和雷达参数的噪声过滤以及基于规则的雷达语义分类，实现了在多尘环境下的鲁棒行人检测。", "motivation": "在煤矿、隧道或倒塌建筑等恶劣、封闭环境中，尘埃和复杂电磁干扰严重影响了毫米波雷达的传感能力，亟需一种能够模拟这些环境并进行可靠雷达研究的方法。", "method": "1. 开发了一种可控生成多层尘埃浓度的方法，以模拟恶劣环境。2. 构建了一个包含4D毫米波雷达、摄像头和激光雷达数据的多模态数据集。3. 提出了一个基于雷达参数（RCS、速度、方位角、仰角）的阈值噪声过滤框架，以抑制鬼目标和多径反射。4. 设计了一个基于雷达语义（速度、RCS、体积扩展）的聚类级、基于规则的分类流水线，用于实时行人检测。", "result": "提出的集成方法显著增强了尘埃环境下的杂波抑制能力、检测鲁棒性和系统韧性。实验证明该方法能够实现可靠的实时行人检测。", "conclusion": "本文提出的尘埃生成方法、多模态数据集以及结合噪声过滤和雷达语义分类的行人检测流水线，能够有效地应对恶劣、多尘环境下的毫米波雷达传感挑战，为相关研究提供了有力支撑。"}}
{"id": "2601.13373", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13373", "abs": "https://arxiv.org/abs/2601.13373", "authors": ["Zhenan Liu", "Amir Khajepour", "George Shaker"], "title": "A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions", "comment": null, "summary": "Pervasive sensing in industrial and underground environments is severely constrained by airborne dust, smoke, confined geometry, and metallic structures, which rapidly degrade optical and LiDAR based perception. Elevation resolved 4D mmWave radar offers strong resilience to such conditions, yet there remains a limited understanding of how to process its sparse and anisotropic point clouds for reliable human detection in enclosed, visibility degraded spaces. This paper presents a fully model-driven 4D radar perception framework designed for real-time execution on embedded edge hardware. The system uses radar as its sole perception modality and integrates domain aware multi threshold filtering, ego motion compensated temporal accumulation, KD tree Euclidean clustering with Doppler aware refinement, and a rule based 3D classifier. The framework is evaluated in a dust filled enclosed trailer and in real underground mining tunnels, and in the tested scenarios the radar based detector maintains stable pedestrian identification as camera and LiDAR modalities fail under severe visibility degradation. These results suggest that the proposed model-driven approach provides robust, interpretable, and computationally efficient perception for safety-critical applications in harsh industrial and subterranean environments.", "AI": {"tldr": "本文提出了一种基于4D毫米波雷达的感知框架，用于在恶劣的工业和地下环境中进行实时人体检测，克服了传统光学和LiDAR传感器的局限性。", "motivation": "在存在粉尘、烟雾、狭窄空间和金属结构等不利因素的工业和地下环境中，光学和LiDAR感知受到严重限制。虽然毫米波雷达对此类条件具有鲁棒性，但如何处理其稀疏且各向异性的点云以实现可靠的人体检测仍需研究。", "method": "该框架是一个完全由模型驱动的4D雷达感知系统，可在嵌入式边缘硬件上实时运行。它集成了领域感知多阈值滤波、零漂移补偿的时间累积、带有多普勒感知细化的KD树欧几里得聚类，以及基于规则的3D分类器。", "result": "在充满灰尘的封闭拖车和真实的地下矿隧道中进行了评估。在测试场景中，当摄像头和LiDAR在严重视觉降级下失效时，基于雷达的探测器能够稳定识别行人。", "conclusion": "提出的模型驱动方法为恶劣工业和地下环境中的安全关键应用提供了鲁棒、可解释且计算效率高的人体检测能力。"}}
{"id": "2601.13416", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13416", "abs": "https://arxiv.org/abs/2601.13416", "authors": ["A. Nieto Juscafresa", "Á. Mazcuñán Herreros", "J. Sullivan"], "title": "Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study", "comment": "21 pages, 6 figures, CVPR format", "summary": "Diffusion models have emerged as state-of-the-art generative methods for image synthesis, yet their potential as general-purpose feature encoders remains underexplored. Trained for denoising and generation without labels, they can be interpreted as self-supervised learners that capture both low- and high-level structure. We show that a frozen diffusion backbone enables strong fine-grained recognition by probing intermediate denoising features across layers and timesteps and training a linear classifier for each pair. We evaluate this in a real-world plankton-monitoring setting with practical impact, using controlled and comparable training setups against established supervised and self-supervised baselines. Frozen diffusion features are competitive with supervised baselines and outperform other self-supervised methods in both balanced and naturally long-tailed settings. Out-of-distribution evaluations on temporally and geographically shifted plankton datasets further show that frozen diffusion features maintain strong accuracy and Macro F1 under substantial distribution shift.", "AI": {"tldr": "研究表明，冻结的扩散模型骨干可以作为强大的通用特征编码器，在细粒度识别任务中表现出与监督学习相当的性能，并优于其他自监督方法，尤其是在分布偏移的情况下。", "motivation": "尽管扩散模型在图像生成方面表现出色，但其作为通用特征编码器的潜力尚未得到充分探索。", "method": "将预训练的冻结扩散模型作为特征提取器，通过线性分类器在中间层和时间步长上进行探测，以评估其细粒度识别能力。在浮游生物监测数据集上进行评估，并与监督和自监督基线进行比较。", "result": "冻结的扩散特征在平衡和长尾设置下都具有竞争力，优于其他自监督方法。在分布偏移的浮游生物数据集上，冻结的扩散特征保持了强大的准确性和宏观 F1 分数。", "conclusion": "扩散模型是一种有前途的通用特征编码器，尤其擅长处理分布偏移问题，为未来的自监督学习和迁移学习研究提供了新的方向。"}}
{"id": "2601.13380", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13380", "abs": "https://arxiv.org/abs/2601.13380", "authors": ["Chaoxin Wang", "Bharaneeshwar Balasubramaniyam", "Anurag Sangem", "Nicolais Guevara", "Doina Caragea"], "title": "Practical Insights into Semi-Supervised Object Detection Approaches", "comment": null, "summary": "Learning in data-scarce settings has recently gained significant attention in the research community. Semi-supervised object detection(SSOD) aims to improve detection performance by leveraging a large number of unlabeled images alongside a limited number of labeled images(a.k.a.,few-shot learning). In this paper, we present a comprehensive comparison of three state-of-the-art SSOD approaches, including MixPL, Semi-DETR and Consistent-Teacher, with the goal of understanding how performance varies with the number of labeled images. We conduct experiments using the MS-COCO and Pascal VOC datasets, two popular object detection benchmarks which allow for standardized evaluation. In addition, we evaluate the SSOD approaches on a custom Beetle dataset which enables us to gain insights into their performance on specialized datasets with a smaller number of object categories. Our findings highlight the trade-offs between accuracy, model size, and latency, providing insights into which methods are best suited for low-data regimes.", "AI": {"tldr": "本研究对三种先进的半监督目标检测（SSOD）方法 MixPL、Semi-DETR 和 Consistent-Teacher 进行了全面的比较，以了解在标记数据量变化时它们的性能如何。实验在 MS-COCO、Pascal VOC 和自定义 Beetle 数据集上进行，并考虑了精度、模型大小和延迟等因素。", "motivation": "在数据稀疏的情况下进行学习（尤其是在目标检测领域）引起了研究界的广泛关注。本研究旨在通过比较不同的 SSOD 方法，为在标记数据有限的情况下选择最佳模型提供指导。", "method": "对 MixPL、Semi-DETR 和 Consistent-Teacher 三种 SSOD 方法进行了实验比较。实验在 MS-COCO、Pascal VOC 和自定义 Beetle 数据集上进行，并评估了不同数量标记数据对性能的影响。", "result": "研究结果揭示了不同 SSOD 方法在精度、模型大小和延迟方面的权衡。具体结果表明，哪种方法最适合低数据量场景。", "conclusion": "本研究通过实验对比，为理解 SSOD 方法在不同数据量下的性能提供了有价值的见解，并帮助研究人员和工程师在实际应用中根据具体需求选择合适的方法。"}}
{"id": "2601.13386", "categories": ["cs.CV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.13386", "abs": "https://arxiv.org/abs/2601.13386", "authors": ["Changxu Zhang", "Zhaoze Wang", "Tai Fei", "Christopher Grimm", "Yi Jin", "Claas Tebruegge", "Ernst Warsitz", "Markus Gardill"], "title": "Leveraging Transformer Decoder for Automotive Radar Object Detection", "comment": null, "summary": "In this paper, we present a Transformer-based architecture for 3D radar object detection that uses a novel Transformer Decoder as the prediction head to directly regress 3D bounding boxes and class scores from radar feature representations. To bridge multi-scale radar features and the decoder, we propose Pyramid Token Fusion (PTF), a lightweight module that converts a feature pyramid into a unified, scale-aware token sequence. By formulating detection as a set prediction problem with learnable object queries and positional encodings, our design models long-range spatial-temporal correlations and cross-feature interactions. This approach eliminates dense proposal generation and heuristic post-processing such as extensive non-maximum suppression (NMS) tuning. We evaluate the proposed framework on the RADDet, where it achieves significant improvements over state-of-the-art radar-only baselines.", "AI": {"tldr": "本文提出了一种基于Transformer的3D雷达目标检测模型，引入了新颖的Transformer解码器作为预测头，直接回归3D边界框和类别分数。通过金字塔令牌融合（PTF）模块处理多尺度雷达特征，并将其转化为统一的、尺度感知的令牌序列。该模型将检测视为集合预测问题，无需生成密集候选框和调优非极大值抑制（NMS）。", "motivation": "现有3D雷达目标检测方法在处理多尺度特征、捕捉长距离时空依赖性以及去除后处理步骤方面存在挑战。", "method": "提出了一种Transformer架构，包括：1. 新颖的Transformer解码器作为预测头，直接回归3D边界框和类别分数；2. 金字塔令牌融合（PTF）模块，用于融合多尺度雷达特征并生成统一的令牌序列；3. 将检测问题建模为集合预测问题，使用可学习的目标查询和位置编码。", "result": "在RADDet数据集上，所提出的框架相较于现有的仅使用雷达数据的基线模型取得了显著的性能提升。", "conclusion": "该Transformer-based方法能够有效地捕捉3D雷达特征中的长距离空间-时间相关性和跨特征交互，并且通过直接的集合预测设计，消除了对密集候选框生成和繁琐后处理（如NMS调优）的需求，显著提升了3D雷达目标检测的性能。"}}
{"id": "2601.13440", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13440", "abs": "https://arxiv.org/abs/2601.13440", "authors": ["Mohit Kakda", "Mirudula Shri Muthukumaran", "Uttapreksha Patel", "Lawrence Swaminathan Xavier Prince"], "title": "Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation", "comment": "10 pages,4 images", "summary": "Vision-Language Models (VLMs), particularly CLIP, have revolutionized anomaly detection by enabling zero-shot and few-shot defect identification without extensive labeled datasets. By learning aligned representations of images and text, VLMs facilitate anomaly classification and segmentation through natural language descriptions of normal and abnormal states, eliminating traditional requirements for task-specific training or defect examples. This project presents a comprehensive analysis of VLM-based approaches for anomaly classification (AC) and anomaly segmentation (AS). We systematically investigate key architectural paradigms including sliding window-based dense feature extraction (WinCLIP), multi-stage feature alignment with learnable projections (AprilLab framework), and compositional prompt ensemble strategies. Our analysis evaluates these methods across critical dimensions: feature extraction mechanisms, text-visual alignment strategies, prompt engineering techniques, zero-shot versus few-shot trade-offs, computational efficiency, and cross-domain generalization. Through rigorous experimentation on benchmarks such as MVTec AD and VisA, we compare classification accuracy, segmentation precision, and inference efficiency. The primary contribution is a foundational understanding of how and why VLMs succeed in anomaly detection, synthesizing practical insights for method selection and identifying current limitations. This work aims to facilitate informed adoption of VLM-based methods in industrial quality control and guide future research directions.", "AI": {"tldr": "该研究对基于视觉-语言模型（VLM）的异常检测方法进行了全面分析，重点关注其在异常分类和分割任务中的表现。通过比较不同的 VLM 架构和策略，为工业质量控制中的方法选择和未来研究提供了指导。", "motivation": "传统的异常检测方法需要大量的标注数据和针对特定任务的训练。VLM，特别是 CLIP，通过零样本和少样本能力，无需大量标注数据即可实现缺陷识别，这为工业质量控制带来了新的可能性。", "method": "研究系统地调查了 VLM 在异常检测中的几种关键架构范例，包括基于滑动窗口的密集特征提取（WinCLIP）、多阶段特征对齐与可学习投影（AprilLab 框架）以及组合式提示集成策略。通过在 MVTec AD 和 VisA 等基准数据集上进行实验，从特征提取、文本-视觉对齐、提示工程、零样本与少样本权衡、计算效率和跨域泛化能力等方面进行了评估。", "result": "通过实验比较了不同方法的分类准确率、分割精度和推理效率。研究结果展示了 VLM 在异常检测方面的有效性，并提供了关于不同方法优劣势的见解。", "conclusion": "该研究为理解 VLM 在异常检测中成功的原因提供了基础，并总结了实用的方法选择见解，同时指出了当前的局限性。旨在促进 VLM 方法在工业质量控制中的应用，并指导未来的研究方向。"}}
{"id": "2601.13417", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13417", "abs": "https://arxiv.org/abs/2601.13417", "authors": ["Yujian Xiong", "Xuanzhao Dong", "Wenhui Zhu", "Xin Li", "Oana Dumitrascu", "Yalin Wang"], "title": "SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement", "comment": null, "summary": "Retinal fundus photography is indispensable for ophthalmic screening and diagnosis, yet image quality is often degraded by noise, artifacts, and uneven illumination. Recent GAN- and diffusion-based enhancement methods improve perceptual quality by aligning degraded images with high-quality distributions, but our analysis shows that this focus can distort intra-class geometry: clinically related samples become dispersed, disease-class boundaries blur, and downstream tasks such as grading or lesion detection are harmed. The Gromov Wasserstein (GW) discrepancy offers a principled solution by aligning distributions through internal pairwise distances, naturally preserving intra-class structure, but its high computational cost restricts practical use. To overcome this, we propose SGW-GAN, the first framework to incorporate Sliced GW (SGW) into retinal image enhancement. SGW approximates GW via random projections, retaining relational fidelity while greatly reducing cost. Experiments on public datasets show that SGW-GAN produces visually compelling enhancements, achieves superior diabetic retinopathy grading, and reports the lowest GW discrepancy across disease labels, demonstrating both efficiency and clinical fidelity for unpaired medical image enhancement.", "AI": {"tldr": "提出了一种名为SGW-GAN的新型视网膜图像增强方法，它首次将切片Gromov Wasserstein（SGW）距离引入医学图像增强领域，旨在解决现有方法（如GAN和扩散模型）可能导致的类内几何失真问题。SGW-GAN通过保留样本间的相对距离来保持类内结构，从而提高了下游诊断任务的性能，同时显著降低了计算成本。", "motivation": "现有的基于GAN和扩散模型的视网膜图像增强方法虽然提高了感知质量，但可能扭曲类内几何结构，导致疾病类别界限模糊，影响下游的诊断任务（如分级和病灶检测）。", "method": "提出SGW-GAN框架，将切片Gromov Wasserstein（SGW）距离整合到视网膜图像增强中。SGW通过随机投影近似GW距离，在保持样本之间关系的同时，大幅降低了计算复杂度。该方法是第一个将SGW应用于视网膜图像增强的框架。", "result": "SGW-GAN在公开数据集上进行了实验，结果显示其生成的图像在视觉上令人满意，并且在糖尿病视网膜病变分级方面表现优越。此外，SGW-GAN在疾病标签上的GW距离最低，证明了其在非配对医学图像增强方面的效率和临床保真度。", "conclusion": "SGW-GAN是一种高效且临床相关的非配对医学图像增强框架，它通过利用SGW距离有效解决了现有方法中的类内几何失真问题，从而提高了图像质量和下游诊断任务的性能。"}}
{"id": "2601.13498", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13498", "abs": "https://arxiv.org/abs/2601.13498", "authors": ["Nimrod Kruger", "Nicholas Owen Ralph", "Gregory Cohen", "Paul Hurley"], "title": "Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging", "comment": null, "summary": "Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems.", "AI": {"tldr": "该研究提出了一种将事件视觉传感器（神经形态相机）数据映射到对数强度和强度衍生物估计的物理模型处理流程，并将其嵌入动态线性系统模型中，从而可以直接从事件数据中进行逆滤波，实现了对动态光学系统的建模和计算成像。", "motivation": "事件视觉传感器输出的稀疏、异步事件数据是非线性表示，难以直接用于基于线性正向模型的计算成像和光学系统设计。", "method": "开发了一个物理模型处理流程，将事件流映射到逐像素的对数强度和强度衍生物估计，并将其嵌入具有时变点扩散函数的动态线性系统模型中。利用频率域维纳反卷积和已知的（或参数化的）动态传递函数直接从事件数据中进行逆滤波。", "result": "在模拟和真实事件数据（包括单点源、重叠点源、调制散焦和可调焦望远镜成像星场）上验证了该方法，成功实现了源定位和可分性。", "conclusion": "该框架为事件传感与基于模型的计算成像在动态光学系统中的应用提供了一个实用的桥梁。"}}
{"id": "2601.13502", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13502", "abs": "https://arxiv.org/abs/2601.13502", "authors": ["Nhi Kieu", "Kien Nguyen", "Arnold Wiliem", "Clinton Fookes", "Sridha Sridharan"], "title": "DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities", "comment": "Accepted to WACV 2026 - Computer Vision for Earth Observation Workshop", "summary": "The efficacy of multimodal learning in remote sensing (RS) is severely undermined by missing modalities. The challenge is exacerbated by the RS highly heterogeneous data and huge scale variation. Consequently, paradigms proven effective in other domains often fail when confronted with these unique data characteristics. Conventional disentanglement learning, which relies on significant feature overlap between modalities (modality-invariant), is insufficient for this heterogeneity. Similarly, knowledge distillation becomes an ill-posed mimicry task where a student fails to focus on the necessary compensatory knowledge, leaving the semantic gap unaddressed. Our work is therefore built upon three pillars uniquely designed for RS: (1) principled missing information compensation, (2) class-specific modality contribution, and (3) multi-resolution feature importance. We propose a novel method DIS2, a new paradigm shifting from modality-shared feature dependence and untargeted imitation to active, guided missing features compensation. Its core novelty lies in a reformulated synergy between disentanglement learning and knowledge distillation, termed DLKD. Compensatory features are explicitly captured which, when fused with the features of the available modality, approximate the ideal fused representation of the full-modality case. To address the class-specific challenge, our Classwise Feature Learning Module (CFLM) adaptively learn discriminative evidence for each target depending on signal availability. Both DLKD and CFLM are supported by a hierarchical hybrid fusion (HF) structure using features across resolutions to strengthen prediction. Extensive experiments validate that our proposed approach significantly outperforms state-of-the-art methods across benchmarks.", "AI": {"tldr": "提出了一种名为DIS2的新方法，用于解决遥感（RS）数据中模态缺失的问题。该方法通过显式捕获补偿性特征、自适应学习每个类别的判别性证据以及利用多分辨率特征来克服RS数据的高度异质性和尺度变化。实验结果表明，DIS2显著优于现有技术。", "motivation": "遥感数据中模态缺失严重影响了多模态学习的有效性，而RS数据的高度异质性和尺度变化加剧了这一挑战。现有的方法（如解耦学习和知识蒸馏）在RS数据上表现不佳。", "method": "提出了一种名为DIS2的新方法，该方法包含三个核心组成部分：1）原则性的缺失信息补偿；2）类别特定的模态贡献；3）多分辨率特征重要性。DIS2的核心是解耦学习与知识蒸馏的协同作用（DLKD），旨在显式捕获补偿性特征。此外，还提出了类别特征学习模块（CFLM）来自适应地学习每个类别的判别性证据，并采用分层混合融合（HF）结构利用多分辨率特征来增强预测。", "result": "在多个基准数据集上进行的广泛实验表明，所提出的DIS2方法在处理模态缺失的遥感数据时，显著优于当前最先进的方法。", "conclusion": "DIS2提供了一种新的多模态遥感学习范式，通过主动、引导式的缺失特征补偿，而非依赖于模态共享特征或无目标模仿，有效地解决了模态缺失问题。该方法在处理RS数据的高度异质性和类别特异性挑战方面表现出色。"}}
{"id": "2601.13524", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13524", "abs": "https://arxiv.org/abs/2601.13524", "authors": ["Yang Yu", "Yunze Deng", "Yige Zhang", "Yanjie Xiao", "Youkun Ou", "Wenhao Hu", "Mingchao Li", "Bin Feng", "Wenyu Liu", "Dandan Zheng", "Jingdong Chen"], "title": "GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models", "comment": "5pages, 3 figures", "summary": "Existing Image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing & Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: https://upyuyang.github.io/go-mlvton/.", "AI": {"tldr": "本研究提出了GO-MLVTON，一种新的多层服装虚拟试穿方法，解决了现有方法忽略多层服装的局限性。该方法通过学习服装间的遮挡关系和利用StableDiffusion进行服装变形与拟合，实现了高质量的多层试穿效果，并引入了MLG数据集和LACD评估指标。", "motivation": "现有的图像虚拟试穿方法主要集中在单层或多件但非多层叠加的服装试穿，忽略了多层服装（内层、外层等）的虚拟试穿需求，而这在现实中非常普遍。主要挑战在于如何准确建模服装间的遮挡关系，以避免内层服装的冗余特征干扰外层服装的逼真合成。", "method": "提出了一种名为GO-MLVTON的多层服装虚拟试穿方法。该方法包含两个核心模块：1. Garment Occlusion Learning模块，用于学习服装之间的遮挡关系；2. StableDiffusion-based Garment Morphing & Fitting模块，利用StableDiffusion模型对服装进行变形和拟合，使其自然地穿在人体上。此外，还构建了一个新的MLG数据集，并提出了Layered Appearance Coherence Difference (LACD)作为评估指标。", "result": "GO-MLVTON在实验中取得了当前最先进（state-of-the-art）的性能。实验结果表明，该方法能够生成高质量的多层虚拟试穿图像，有效地处理了服装间的遮挡关系和形变。", "conclusion": "GO-MLVTON是首个专门针对多层服装虚拟试穿任务的方法，通过引入服装遮挡学习和基于StableDiffusion的服装变形与拟合，成功解决了多层服装虚拟试穿中的关键挑战，并提供了新的数据集和评估方法，证明了其在生成逼真多层虚拟试穿结果方面的有效性。"}}
{"id": "2601.13551", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13551", "abs": "https://arxiv.org/abs/2601.13551", "authors": ["Feng Ding", "Wenhui Yi", "Xinan He", "Mengyao Xiao", "Jianfeng Xu", "Jianqiang Du"], "title": "DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis", "comment": null, "summary": "Generative models now produce imperceptible, fine-grained manipulated faces, posing significant privacy risks. However, existing AI-generated face datasets generally lack focus on samples with fine-grained regional manipulations. Furthermore, no researchers have yet studied the real impact of splice attacks, which occur between real and manipulated samples, on detectors. We refer to these as detector-evasive samples. Based on this, we introduce the DiffFace-Edit dataset, which has the following advantages: 1) It contains over two million AI-generated fake images. 2) It features edits across eight facial regions (e.g., eyes, nose) and includes a richer variety of editing combinations, such as single-region and multi-region edits. Additionally, we specifically analyze the impact of detector-evasive samples on detection models. We conduct a comprehensive analysis of the dataset and propose a cross-domain evaluation that combines IMDL methods. Dataset will be available at https://github.com/ywh1093/DiffFace-Edit.", "AI": {"tldr": "本文提出了DiffFace-Edit数据集，包含超过两百万张经过精细区域编辑的AI生成人脸图像，并分析了这些编辑样本对人脸检测模型的影响，特别是“规避检测”样本。", "motivation": "现有AI生成人脸数据集缺乏对精细区域编辑的样本，且未研究真实与合成混合的“规避检测”样本对检测器的影响。", "method": "创建了一个包含超过两百万张AI生成人脸图像的数据集，涵盖八个面部区域的单区域和多区域编辑。同时，对“规避检测”样本的影响进行了分析，并提出了结合IMDL方法的跨域评估。", "result": "数据集DiffFace-Edit包含了丰富的精细编辑人脸样本。分析表明，特定类型的编辑样本（“规避检测”样本）会对现有检测模型造成显著影响。", "conclusion": "DiffFace-Edit数据集为研究精细人脸编辑的检测问题提供了资源，并强调了分析“规避检测”样本对于提高人脸检测模型鲁棒性的重要性。"}}
{"id": "2601.13651", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13651", "abs": "https://arxiv.org/abs/2601.13651", "authors": ["Marta Moscati", "Oleksandr Kats", "Mubashir Noman", "Muhammad Zaigham Zaheer", "Yufang Hou", "Markus Schedl", "Shah Nawaz"], "title": "Face-Voice Association with Inductive Bias for Maximum Class Separation", "comment": "Accepted at ICASSP 2026", "summary": "Face-voice association is widely studied in multimodal learning and is approached representing faces and voices with embeddings that are close for a same person and well separated from those of others. Previous work achieved this with loss functions. Recent advancements in classification have shown that the discriminative ability of embeddings can be strengthened by imposing maximum class separation as inductive bias. This technique has never been used in the domain of face-voice association, and this work aims at filling this gap. More specifically, we develop a method for face-voice association that imposes maximum class separation among multimodal representations of different speakers as an inductive bias. Through quantitative experiments we demonstrate the effectiveness of our approach, showing that it achieves SOTA performance on two task formulation of face-voice association. Furthermore, we carry out an ablation study to show that imposing inductive bias is most effective when combined with losses for inter-class orthogonality. To the best of our knowledge, this work is the first that applies and demonstrates the effectiveness of maximum class separation as an inductive bias in multimodal learning; it hence paves the way to establish a new paradigm.", "AI": {"tldr": "本文提出了一种新的面部-声音关联方法，通过引入最大类分离作为归纳偏置，以增强多模态表示的区分度，并在两个任务的制定上达到了最先进的性能。", "motivation": "以往的面部-声音关联研究主要依赖于损失函数来拉近同一人的面部和声音表示，并区分不同的人。然而，最近的分类研究表明，通过施加最大类分离作为归纳偏置可以增强表示的区分能力。作者注意到这一技术尚未应用于面部-声音关联领域，因此希望填补这一空白。", "method": "作者开发了一种新的面部-声音关联方法，其核心在于将最大类分离作为归纳偏置，施加于不同说话人的多模态表示上。此外，研究还结合了类间正交性损失以进一步提升效果。", "result": "通过定量实验，该方法在两个面部-声音关联的任务制定上均取得了最先进（SOTA）的性能。消融研究表明，将归纳偏置与类间正交性损失结合使用效果最佳。", "conclusion": "本文首次将最大类分离作为归纳偏置应用于多模态学习中的面部-声音关联任务，并证明了其有效性，有望开创新的研究范式。"}}
{"id": "2601.13664", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13664", "abs": "https://arxiv.org/abs/2601.13664", "authors": ["Tiancheng Fang", "Bowen Pan", "Lingxi Chen", "Jiangjing Lyu", "Chengfei Lyu", "Chaoyue Niu", "Fan Wu"], "title": "VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement", "comment": "Under review at CVPR 2026", "summary": "We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave.", "AI": {"tldr": "提出了一种名为VIAFormer的体素-图像对齐Transformer模型，用于多视图引导的体素修复，通过图像索引、校正流和混合流Transformer实现，并在修复合成和真实体素损坏方面取得了SOTA性能。", "motivation": "旨在解决由多视图图像引导的不完整、嘈杂的体素修复问题，并为体素方法在大模型和大数据时代的应用铺平道路。", "method": "提出VIAFormer模型，包含三个关键组件：1. 图像索引（Image Index）用于2D图像token的3D空间定位；2. 校正流（Correctional Flow）用于学习直接的体素修复轨迹；3. 混合流Transformer（Hybrid Stream Transformer）用于跨模态融合。", "result": "VIAFormer在修复合成和真实体素损坏方面均达到了新的state of the art水平，证明了其在处理来自强大视觉基础模型的体素形状上的有效性。", "conclusion": "VIAFormer是一种有效且实用的模型，能够作为3D创建流程中的可靠桥梁，促进体素方法在新兴的大模型、大数据浪潮中蓬勃发展。"}}
{"id": "2601.13606", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13606", "abs": "https://arxiv.org/abs/2601.13606", "authors": ["Zheng Liu", "Honglin Lin", "Chonghan Qin", "Xiaoyang Wang", "Xin Gao", "Yu Li", "Mengzhang Cai", "Yun Zhu", "Zhanping Zhong", "Qizhi Pei", "Zhuoshi Pan", "Xiaoran Shang", "Bin Cui", "Conghui He", "Wentao Zhang", "Lijun Wu"], "title": "ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch", "comment": "29 pages", "summary": "Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking.", "AI": {"tldr": "本文提出了ChartVerse框架，用于生成复杂图表和高质量的推理数据，以解决现有数据集的局限性，并通过实验证明了其有效性。", "motivation": "现有用于视觉语言模型（VLMs）的图表推理数据集存在合成图表过于简单重复、问答对易出现幻觉且缺乏复杂推理能力的问题，阻碍了开源模型的发展。", "method": "提出ChartVerse框架，包含两个主要部分：1. 引入Rollout Posterior Entropy（RPE）度量图表复杂性，并开发复杂性感知图表编码器，通过可执行程序自主合成高复杂度的图表。2. 开发基于答案的逆向QA合成方法，先从源代码提取确定性答案，再条件生成问题，并进行严格的一致性验证，最后通过模型失败率过滤和提炼高质量的思维链（CoT）推理。", "result": "基于ChartVerse框架，作者构建了ChartVerse-SFT-600K和ChartVerse-RL-40K数据集，并使用Qwen3-VL-30B-A3B-Thinking作为教师模型。实验结果表明，ChartVerse-8B模型取得了最先进的性能，显著超越了其教师模型，并可与更强的Qwen3-VL-32B-Thinking模型媲美。", "conclusion": "ChartVerse框架成功解决了复杂图表和高质量推理数据合成的挑战，为VLMs的图表推理能力训练提供了有效的数据集，并显著提升了模型的性能。"}}
{"id": "2601.13633", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13633", "abs": "https://arxiv.org/abs/2601.13633", "authors": ["Guanqi Zhan", "Changye Li", "Zhijian Liu", "Yao Lu", "Yi Wu", "Song Han", "Ligeng Zhu"], "title": "Scaling Test-time Inference for Visual Grounding", "comment": null, "summary": "Visual grounding is an essential capability of Visual Language Models (VLMs) to understand the real physical world. Previous state-of-the-art grounding visual language models usually have large model sizes, making them heavy for deployment and slow for inference. However, we notice that the sizes of visual encoders are nearly the same for small and large VLMs and the major difference is the sizes of the language models. Small VLMs fall behind larger VLMs in grounding because of the difference in language understanding capability rather than visual information handling. To mitigate the gap, we introduce 'Efficient visual Grounding language Models' (EGM): a method to scale the test-time computation (#generated tokens). Scaling the test-time computation of a small model is deployment-friendly, and yields better end-to-end latency as the cost of each token is much cheaper compared to directly running a large model. On the RefCOCO benchmark, our EGM-Qwen3-VL-8B demonstrates 91.4 IoU with an average of 737ms (5.9x faster) latency while Qwen3-VL-235B demands 4,320ms to achieve 90.5 IoU. To validate our approach's generality, we further set up a new amodal grounding setting that requires the model to predict both the visible and occluded parts of the objects. Experiments show our method can consistently and significantly improve the vanilla grounding and amodal grounding capabilities of small models to be on par with or outperform the larger models, thereby improving the efficiency for visual grounding.", "AI": {"tldr": "提出了一种名为EGM（Efficient Visual Grounding Language Models）的方法，通过在推理时扩展小模型的计算量（生成的token数量），来缩小小模型与大模型在视觉基础能力上的差距，实现高效的视觉基础任务。", "motivation": "现有先进的视觉语言模型（VLMs）在视觉基础能力上表现出色，但模型体积庞大，导致部署困难且推理速度慢。研究人员发现，小模型和大模型的视觉编码器尺寸差异不大，主要区别在于语言模型的大小，并且小模型在基础能力上的不足源于语言理解能力而非视觉信息处理能力。因此，希望找到一种轻量化且高效的方法来提升小模型的视觉基础能力。", "method": "提出EGM方法，通过在测试时增加计算量（即增加生成的token数量）来提升小模型的视觉基础能力。这种方法相比直接运行大模型，可以显著降低端到端的延迟，同时实现更好的性能。", "result": "在RefCOCO基准测试上，EGM-Qwen3-VL-8B模型实现了91.4%的IoU，平均延迟仅为737ms（比Qwen3-VL-235B快5.9倍），而Qwen3-VL-235B模型需要4320ms才能达到90.5%的IoU。此外，在新的非模态基础（amodal grounding）设定下，EGM方法也能显著提升小模型的性能，使其达到或超越大模型的表现。", "conclusion": "EGM方法是一种有效的策略，能够通过扩展推理时的计算量来显著提升小模型的视觉基础能力，使其在性能和效率上都能与大模型媲美，从而提高了视觉基础任务的效率。"}}
{"id": "2601.13665", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13665", "abs": "https://arxiv.org/abs/2601.13665", "authors": ["Mounika Kanulla", "Rajasree Dadigi", "Sailaja Thota", "Vivek Yelleti"], "title": "Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting", "comment": null, "summary": "Food wastage is one of the critical challenges in the agricultural supply chain, and accurate and effective spoilage detection can help to reduce it. Further, it is highly important to forecast the spoilage information. This aids the longevity of the supply chain management in the agriculture field. This motivated us to propose fusion based architectures by combining CNN with LSTM and DeiT transformer for the following multi-tasks simultaneously: (i) vegetable classification, (ii) food spoilage detection, and (iii) shelf life forecasting. We developed a dataset by capturing images of vegetables from their fresh state until they were completely spoiled. From the experimental analysis it is concluded that the proposed fusion architectures CNN+CNN-LSTM and CNN+DeiT Transformer outperformed several deep learning models such as CNN, VGG16, ResNet50, Capsule Networks, and DeiT Transformers. Overall, CNN + DeiT Transformer yielded F1-score of 0.98 and 0.61 in vegetable classification and spoilage detection respectively and mean squared error (MSE) and symmetric mean absolute percentage error (SMAPE) of 3.58, and 41.66% respectively in spoilage forecasting. Further, the reliability of the fusion models was validated on noisy images and integrated with LIME to visualize the model decisions.", "AI": {"tldr": "该研究提出了一种融合CNN、LSTM和DeiT Transformer的架构，用于同时完成蔬菜分类、食物腐败检测和保质期预测。实验结果表明，该融合模型优于现有的深度学习模型，并能在噪声图像上验证其可靠性。", "motivation": "为了减少农业供应链中的食物浪费，需要准确有效地检测和预测食物的腐败情况，以延长农产品供应链的管理寿命。", "method": "研究人员提出了一种融合CNN、LSTM和DeiT Transformer的架构。该架构可以同时执行蔬菜分类、食物腐败检测和保质期预测。同时，研究人员还构建了一个包含蔬菜从新鲜到完全腐败的图像数据集。此外，还利用LIME技术对模型的决策进行可视化。", "result": "提出的CNN+CNN-LSTM和CNN+DeiT Transformer融合架构在蔬菜分类、食物腐败检测和保质期预测方面，相比CNN、VGG16、ResNet50、Capsule Networks和DeiT Transformers等模型表现更优。具体而言，CNN + DeiT Transformer在蔬菜分类中达到0.98的F1分数，在腐败检测中达到0.61的F1分数，在保质期预测中MSE为3.58，SMAPE为41.66%。", "conclusion": "提出的融合架构在多任务（蔬菜分类、腐败检测、保质期预测）上表现出色，有效解决了食物浪费问题，并证明了其在噪声图像上的鲁棒性和可解释性。"}}
{"id": "2601.13677", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13677", "abs": "https://arxiv.org/abs/2601.13677", "authors": ["Carsten T. Lüth", "Jeremias Traub", "Kim-Celine Kahl", "Till J. Bungert", "Lukas Klein", "Lars Krämer", "Paul F. Jäger", "Klaus Maier-Hein", "Fabian Isensee"], "title": "Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging", "comment": "Accepted at TMLR", "summary": "Active learning (AL) has the potential to drastically reduce annotation costs in 3D biomedical image segmentation, where expert labeling of volumetric data is both time-consuming and expensive. Yet, existing AL methods are unable to consistently outperform improved random sampling baselines adapted to 3D data, leaving the field without a reliable solution. We introduce Class-stratified Scheduled Power Predictive Entropy (ClaSP PE), a simple and effective query strategy that addresses two key limitations of standard uncertainty-based AL methods: class imbalance and redundancy in early selections. ClaSP PE combines class-stratified querying to ensure coverage of underrepresented structures and log-scale power noising with a decaying schedule to enforce query diversity in early-stage AL and encourage exploitation later. In our evaluation on 24 experimental settings using four 3D biomedical datasets within the comprehensive nnActive benchmark, ClaSP PE is the only method that generally outperforms improved random baselines in terms of both segmentation quality with statistically significant gains, whilst remaining annotation efficient. Furthermore, we explicitly simulate the real-world application by testing our method on four previously unseen datasets without manual adaptation, where all experiment parameters are set according to predefined guidelines. The results confirm that ClaSP PE robustly generalizes to novel tasks without requiring dataset-specific tuning. Within the nnActive framework, we present compelling evidence that an AL method can consistently outperform random baselines adapted to 3D segmentation, in terms of both performance and annotation efficiency in a realistic, close-to-production scenario. Our open-source implementation and clear deployment guidelines make it readily applicable in practice. Code is at https://github.com/MIC-DKFZ/nnActive.", "AI": {"tldr": "提出了一种名为 ClaSP PE 的主动学习策略，用于 3D 生物医学图像分割，它通过类别分层查询和带衰减调度的功率噪声来解决类别不平衡和早期选择冗余问题，并在 nnActive 基准测试中证明了其优于随机采样基线。", "motivation": "现有的主动学习方法在 3D 生物医学图像分割中无法持续优于改进的随机采样基线，导致该领域缺乏可靠的解决方案，而专家标注 3D 数据既耗时又昂贵。", "method": "ClaSP PE 结合了类别分层查询（解决类别不平衡）和对数尺度功率噪声（确保查询多样性并鼓励后期开发），并采用衰减调度。", "result": "ClaSP PE 是唯一一个在 24 个实验设置中、使用四个 3D 生物医学数据集、在分割质量和标注效率方面普遍优于改进的随机基线的方法，并且具有统计学意义上的显著优势。该方法还成功泛化到新的数据集，无需手动调整。", "conclusion": "ClaSP PE 是一种简单有效的查询策略，能够克服现有不确定性度量方法在类别不平衡和早期选择冗余方面的局限性，在 3D 生物医学图像分割中一致地优于随机基线，并且具有良好的泛化能力，适用于实际应用。"}}
{"id": "2601.13683", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13683", "abs": "https://arxiv.org/abs/2601.13683", "authors": ["Boyuan Cao", "Xingbo Yao", "Chenhui Wang", "Jiaxin Ye", "Yujie Wei", "Hongming Shan"], "title": "Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation", "comment": null, "summary": "Diffusion transformers (DiTs) have emerged as a powerful architecture for high-fidelity image generation, yet the quadratic cost of self-attention poses a major scalability bottleneck. To address this, linear attention mechanisms have been adopted to reduce computational cost; unfortunately, the resulting linear diffusion transformers (LiTs) models often come at the expense of generative performance, frequently producing over-smoothed attention weights that limit expressiveness. In this work, we introduce Dynamic Differential Linear Attention (DyDiLA), a novel linear attention formulation that enhances the effectiveness of LiTs by mitigating the oversmoothing issue and improving generation quality. Specifically, the novelty of DyDiLA lies in three key designs: (i) dynamic projection module, which facilitates the decoupling of token representations by learning with dynamically assigned knowledge; (ii) dynamic measure kernel, which provides a better similarity measurement to capture fine-grained semantic distinctions between tokens by dynamically assigning kernel functions for token processing; and (iii) token differential operator, which enables more robust query-to-key retrieval by calculating the differences between the tokens and their corresponding information redundancy produced by dynamic measure kernel. To capitalize on DyDiLA, we introduce a refined LiT, termed DyDi-LiT, that systematically incorporates our advancements. Extensive experiments show that DyDi-LiT consistently outperforms current state-of-the-art (SOTA) models across multiple metrics, underscoring its strong practical potential.", "AI": {"tldr": "本文提出了一种名为 DyDiLA 的新型线性注意力机制，用于解决扩散 Transformer (DiT) 中的二次计算成本问题，同时避免了现有线性注意力方法（LiTs）中常见的生成性能下降（如过度平滑的注意力权重）。DyDiLA 通过动态投影模块、动态度量核和 token 差分算子来改进 LiTs，从而提高了生成质量。基于 DyDiLA，作者提出了 DyDi-LiT 模型，并在多项指标上取得了 SOTA 性能。", "motivation": "传统的扩散 Transformer (DiT) 在生成高质量图像方面表现出色，但其自注意力机制的二次计算成本限制了其可扩展性。采用线性注意力机制（LiTs）可以降低计算成本，但通常会导致生成性能下降，表现为注意力权重过度平滑，限制了模型的表达能力。因此，需要一种新的线性注意力机制来克服这些局限性。", "method": "本文提出了一种名为动态微分线性注意力 (DyDiLA) 的新颖线性注意力机制。DyDiLA 包含三个关键设计：1. 动态投影模块：通过学习动态分配的知识来促进 token 表示的分离。2. 动态度量核：通过动态分配核函数来提供更好的相似度量，以捕捉 token 之间细粒度的语义差异。3. Token 差分算子：通过计算 token 之间的差异以及动态度量核产生的对应信息冗余，实现更鲁棒的查询-键检索。基于 DyDiLA，作者构建了一个名为 DyDi-LiT 的改进版 LiT 模型。", "result": "实验表明，DyDi-LiT 模型在多个指标上始终优于当前最先进 (SOTA) 的模型。这表明 DyDiLA 成功地缓解了 LiTs 的过度平滑问题，并提高了生成质量。", "conclusion": "DyDiLA 是一种有效的新型线性注意力机制，它通过动态投影模块、动态度量核和 token 差分算子，解决了现有 LiTs 模型性能下降的问题，显著提高了扩散 Transformer 的生成质量。所提出的 DyDi-LiT 模型在各项评估中均取得了 SOTA 结果，证明了其在实际应用中的巨大潜力。"}}
{"id": "2601.13706", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13706", "abs": "https://arxiv.org/abs/2601.13706", "authors": ["Xinhao Liu", "Yu Wang", "Xiansheng Guo", "Gordon Owusu Boateng", "Yu Cao", "Haonan Si", "Xingchen Guo", "Nirwan Ansari"], "title": "ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins", "comment": "35 pages, 10 figures. Submitted to ISPRS Journal of Photogrammetry and Remote Sensing. Under review", "summary": "High-fidelity parking-lot digital twins provide essential priors for path planning, collision checking, and perception validation in Automated Valet Parking (AVP). Yet robot-oriented reconstruction faces a trilemma: sparse forward-facing views cause weak parallax and ill-posed geometry; dynamic occlusions and extreme lighting hinder stable texture fusion; and neural rendering typically needs expensive offline optimization, violating edge-side streaming constraints. We propose ParkingTwin, a training-free, lightweight system for online streaming 3D reconstruction. First, OSM-prior-driven geometric construction uses OpenStreetMap semantic topology to directly generate a metric-consistent TSDF, replacing blind geometric search with deterministic mapping and avoiding costly optimization. Second, geometry-aware dynamic filtering employs a quad-modal constraint field (normal/height/depth consistency) to reject moving vehicles and transient occlusions in real time. Third, illumination-robust fusion in CIELAB decouples luminance and chromaticity via adaptive L-channel weighting and depth-gradient suppression, reducing seams under abrupt lighting changes. ParkingTwin runs at 30+ FPS on an entry-level GTX 1660. On a 68,000 m^2 real-world dataset, it achieves SSIM 0.87 (+16.0%), delivers about 15x end-to-end speedup, and reduces GPU memory by 83.3% compared with state-of-the-art 3D Gaussian Splatting (3DGS) that typically requires high-end GPUs (RTX 4090D). The system outputs explicit triangle meshes compatible with Unity/Unreal digital-twin pipelines. Project page: https://mihoutao-liu.github.io/ParkingTwin/", "AI": {"tldr": "提出了一种名为ParkingTwin的训练无关、轻量级的在线流式3D重建系统，用于生成高保真停车场数字孪生，克服了传统方法的局限性，并在性能和效率上优于现有技术。", "motivation": "自动代客泊车（AVP）需要高保真的停车场数字孪生来进行路径规划、碰撞检测和感知验证。然而，机器人导向的重建面临稀疏视角、动态遮挡和高成本离线优化的挑战。", "method": "ParkingTwin采用三种核心技术：1. OSM先验驱动的几何构建，利用OpenStreetMap生成度量一致的TSDF；2. 几何感知的动态滤波，利用四模态约束字段剔除动态物体和瞬时遮挡；3. CIELAB色彩空间下光照鲁棒的融合，通过自适应权重和梯度抑制减少光照变化带来的接缝。", "result": "ParkingTwin在入门级GTX 1660上达到30+ FPS。在真实数据集上，其SSIM达到0.87（+16.0%），端到端速度提升约15倍，GPU内存占用减少83.3%，优于需要高端GPU的3DGS。", "conclusion": "ParkingTwin是一个高效、轻量级的在线3D重建系统，能够生成适用于Unity/Unreal数字孪生管线的显式三角网格，有效解决了停车场数字孪生重建的难题。"}}
{"id": "2601.13371", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13371", "abs": "https://arxiv.org/abs/2601.13371", "authors": ["Junyi Zhang", "Yiming Wang", "Yunhong Lu", "Qichao Wang", "Wenzhe Qian", "Xiaoyin Xu", "David Gu", "Min Zhang"], "title": "Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations", "comment": "Association for the Advancement of Artificial Intelligence", "summary": "A fundamental challenge in text-to-3D face generation is achieving high-quality geometry. The core difficulty lies in the arbitrary and intricate distribution of vertices in 3D space, making it challenging for existing models to establish clean connectivity and resulting in suboptimal geometry. To address this, our core insight is to simplify the underlying geometric structure by constraining the distribution onto a simple and regular manifold, a topological sphere. Building on this, we first propose the Spherical Geometry Representation, a novel face representation that anchors geometric signals to uniform spherical coordinates. This guarantees a regular point distribution, from which the mesh connectivity can be robustly reconstructed. Critically, this canonical sphere can be seamlessly unwrapped into a 2D map, creating a perfect synergy with powerful 2D generative models. We then introduce Spherical Geometry Diffusion, a conditional diffusion framework built upon this 2D map. It enables diverse and controllable generation by jointly modeling geometry and texture, where the geometry explicitly conditions the texture synthesis process. Our method's effectiveness is demonstrated through its success in a wide range of tasks: text-to-3D generation, face reconstruction, and text-based 3D editing. Extensive experiments show that our approach substantially outperforms existing methods in geometric quality, textual fidelity, and inference efficiency.", "AI": {"tldr": "本研究提出了一种新的球面几何表示方法，通过将3D面部几何约束在拓扑球面上，简化了点分布，解决了现有模型在几何连通性上的难题。在此基础上，开发了一种基于2D贴图的条件扩散模型（Spherical Geometry Diffusion），实现了文本到3D面部生成、面部重建和文本驱动的3D编辑，并在几何质量、文本保真度和推理效率上超越了现有方法。", "motivation": "现有文本到3D面部生成方法在生成高质量几何方面面临挑战，主要原因是3D空间中顶点分布的任意性和复杂性，导致模型难以建立清晰的连通性，从而产生次优的几何形状。", "method": "研究者提出了球面几何表示（Spherical Geometry Representation），将几何信号锚定在均匀的球坐标上，以保证规则的点分布，从而能够稳健地重建网格连通性。基于此，他们开发了球面几何扩散（Spherical Geometry Diffusion），一个条件扩散框架，该框架建立在2D贴图之上，通过联合建模几何和纹理，使几何显式地条件化纹理合成过程，从而实现多样化和可控的生成。", "result": "该方法在文本到3D生成、面部重建和文本驱动的3D编辑等任务上表现出色。实验结果表明，该方法在几何质量、文本保真度和推理效率方面显著优于现有方法。", "conclusion": "通过将3D面部几何映射到规则的球面表示，并利用2D扩散模型进行生成，本研究成功解决了文本到3D面部生成中的几何质量问题，并实现了高效、高质量的3D面部生成和编辑。"}}
{"id": "2601.13705", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13705", "abs": "https://arxiv.org/abs/2601.13705", "authors": ["Maria Lymperaiou", "Vasileios Karampinis", "Giorgos Filandrianos", "Angelos Vlachos", "Chrysoula Zerva", "Athanasios Voulodimos"], "title": "Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles", "comment": null, "summary": "Puzzles have long served as compact and revealing probes of human cognition, isolating abstraction, rule discovery, and systematic reasoning with minimal reliance on prior knowledge. Leveraging these properties, visual puzzles have recently emerged as a powerful diagnostic tool for evaluating the reasoning abilities of Large Vision-Language Models (LVLMs), offering controlled, verifiable alternatives to open-ended multimodal benchmarks. This survey provides a unified perspective of visual puzzle reasoning in LVLMs. We frame visual puzzles through a common abstraction and organize existing benchmarks by the reasoning mechanisms they target (inductive, analogical, algorithmic, deductive, and geometric/spatial), thereby linking puzzle design to the cognitive operations required for solving. Synthesizing empirical evidence across these categories, we identify consistent limitations in current models, including brittle generalization, tight entanglement between perception and reasoning, and a persistent gap between fluent explanations and faithful execution. By framing visual puzzles as diagnostic instruments rather than task formats, this survey elaborates on the state of LVLM reasoning and outlines key directions for future benchmarks and reasoning-aware multimodal systems.", "AI": {"tldr": "本综述对视觉谜题在大型视觉语言模型（LVLM）中的推理能力进行了统一梳理，识别了当前模型在泛化、感知与推理的耦合以及解释与执行的差异方面存在的普遍局限性，并指明了未来研究方向。", "motivation": "视觉谜题因其能有效隔离抽象、规则发现和系统推理能力，且对先验知识依赖少，已被用作评估大型视觉语言模型（LVLM）推理能力的有力工具，而现有研究分散，缺乏统一的视角和对模型局限性的系统性总结。", "method": "论文对现有视觉谜题基准进行了分类，按照其针对的推理机制（归纳、类比、算法、演绎、几何/空间）进行组织，将谜题设计与所需的认知操作联系起来。通过综合分析这些类别的实证证据，识别当前模型在视觉谜题推理方面的共性局限。", "result": "当前 LVLM 在处理视觉谜题时表现出脆弱的泛化能力、感知与推理之间紧密的纠缠，以及流畅的解释与忠实的执行之间持续存在的差距。这些局限性在不同推理机制的谜题类别中均有体现。", "conclusion": "视觉谜题是评估 LVLM 推理能力的有效诊断工具。现有模型在理解和执行视觉谜题方面的能力仍有待提高，未来的研究应聚焦于克服泛化性差、感知推理耦合以及解释与执行不一致等问题，并设计更具挑战性的基准和推理意识的多模态系统。"}}
{"id": "2601.13724", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13724", "abs": "https://arxiv.org/abs/2601.13724", "authors": ["Sam Cantrill", "David Ahmedt-Aristizabal", "Lars Petersson", "Hanna Suominen", "Mohammad Ali Armin"], "title": "Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement", "comment": null, "summary": "Facial remote photoplethysmography (rPPG) methods estimate physiological signals by modeling subtle color changes on the 3D facial surface over time. However, existing methods fail to explicitly align their receptive fields with the 3D facial surface-the spatial support of the rPPG signal. To address this, we propose the Facial Spatiotemporal Graph (STGraph), a novel representation that encodes facial color and structure using 3D facial mesh sequences-enabling surface-aligned spatiotemporal processing. We introduce MeshPhys, a lightweight spatiotemporal graph convolutional network that operates on the STGraph to estimate physiological signals. Across four benchmark datasets, MeshPhys achieves state-of-the-art or competitive performance in both intra- and cross-dataset settings. Ablation studies show that constraining the model's receptive field to the facial surface acts as a strong structural prior, and that surface-aligned, 3D-aware node features are critical for robustly encoding facial surface color. Together, the STGraph and MeshPhys constitute a novel, principled modeling paradigm for facial rPPG, enabling robust, interpretable, and generalizable estimation. Code is available at https://samcantrill.github.io/facial-stgraph-rppg/ .", "AI": {"tldr": "提出了一种名为STGraph的新型面部时空图表示，并结合一个轻量级时空图卷积网络MeshPhys，用于从3D面部表面提取生理信号，在多个数据集上取得了最先进或有竞争力的性能。", "motivation": "现有面部远程光体积描记法（rPPG）方法未能明确地将感受野与3D面部表面对齐，这影响了信号估计的准确性。", "method": "提出了一种新的表示方法，称为面部时空图（STGraph），它使用3D面部网格序列编码面部颜色和结构。在此基础上，设计了一个轻量级的时空图卷积网络MeshPhys来处理STGraph并估计生理信号。", "result": "MeshPhys在四个基准数据集上，在数据集内和跨数据集设置中均取得了最先进或有竞争力的性能。消融研究表明，将模型的感受野限制在面部表面上是一个强大的结构先验，并且面向表面的、3D感知的节点特征对于鲁棒地编码面部表面颜色至关重要。", "conclusion": "STGraph和MeshPhys构成了一种新颖、原则性的面部rPPG建模范式，能够实现鲁棒、可解释和可泛化的信号估计。"}}
{"id": "2601.13816", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13816", "abs": "https://arxiv.org/abs/2601.13816", "authors": ["Raül Pérez-Gonzalo", "Andreas Espersen", "Antonio Agudo"], "title": "Discriminant Learning-based Colorspace for Blade Segmentation", "comment": "Accepted to ICASSP 2026", "summary": "Suboptimal color representation often hinders accurate image segmentation, yet many modern algorithms neglect this critical preprocessing step. This work presents a novel multidimensional nonlinear discriminant analysis algorithm, Colorspace Discriminant Analysis (CSDA), for improved segmentation. Extending Linear Discriminant Analysis into a deep learning context, CSDA customizes color representation by maximizing multidimensional signed inter-class separability while minimizing intra-class variability through a generalized discriminative loss. To ensure stable training, we introduce three alternative losses that enable end-to-end optimization of both the discriminative colorspace and segmentation process. Experiments on wind turbine blade data demonstrate significant accuracy gains, emphasizing the importance of tailored preprocessing in domain-specific segmentation.", "AI": {"tldr": "提出了一种名为Colorspace Discriminant Analysis (CSDA) 的新方法，该方法通过定制颜色表示来改进图像分割，并在风力涡轮机叶片数据上取得了显著的准确性提升。", "motivation": "现有的图像分割算法常常忽视了次优颜色表示对分割精度的影响，这项工作旨在解决这个问题。", "method": "提出了一种多维非线性判别分析算法CSDA，将线性判别分析扩展到深度学习领域，通过最大化类间可分性和最小化类内变异性来定制颜色表示，并引入了三种可选损失函数以实现端到端优化。", "result": "在风力涡轮机叶片数据集上的实验表明，CSDA方法显著提高了图像分割的准确性。", "conclusion": "定制的颜色表示预处理对于特定领域的图像分割至关重要，CSDA方法有效地实现了这一目标并提升了分割性能。"}}
{"id": "2601.13797", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13797", "abs": "https://arxiv.org/abs/2601.13797", "authors": ["Gabriele Serussi", "David Vainshtein", "Jonathan Kouchly", "Dotan Di Castro", "Chaim Baskin"], "title": "PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval", "comment": null, "summary": "Composed Video Retrieval (CoVR) aims to retrieve a video based on a query video and a modifying text. Current CoVR methods fail to fully exploit modern Vision-Language Models (VLMs), either using outdated architectures or requiring computationally expensive fine-tuning and slow caption generation. We introduce PREGEN (PRE GENeration extraction), an efficient and powerful CoVR framework that overcomes these limitations. Our approach uniquely pairs a frozen, pre-trained VLM with a lightweight encoding model, eliminating the need for any VLM fine-tuning. We feed the query video and modifying text into the VLM and extract the hidden state of the final token from each layer. A simple encoder is then trained on these pooled representations, creating a semantically rich and compact embedding for retrieval. PREGEN significantly advances the state of the art, surpassing all prior methods on standard CoVR benchmarks with substantial gains in Recall@1 of +27.23 and +69.59. Our method demonstrates robustness across different VLM backbones and exhibits strong zero-shot generalization to more complex textual modifications, highlighting its effectiveness and semantic capabilities.", "AI": {"tldr": "提出了一种名为PREGEN的高效视频检索框架，通过冻结预训练的视觉语言模型（VLM）并结合一个轻量级编码模型，无需对VLM进行微调，从而实现高效的视频检索，并在标准基准测试中取得显著性能提升。", "motivation": "现有视频检索方法未能充分利用现代视觉语言模型（VLMs），要么采用过时的架构，要么需要昂贵的微调和缓慢的文本生成过程。", "method": "采用冻结的预训练VLM，并结合一个轻量级编码模型。将查询视频和修改文本输入VLM，提取最后一层所有token的隐藏状态，然后通过一个训练好的简单编码器生成紧凑的嵌入向量用于检索。", "result": "PREGEN显著超越了现有方法，在Recall@1上分别取得了+27.23%和+69.59%的提升。该方法对不同的VLM骨干网络具有鲁棒性，并在零样本场景下对更复杂的文本修改展现出良好的泛化能力。", "conclusion": "PREGEN是一种高效且强大的视频检索框架，通过有效利用预训练VLM，无需微调即可实现高性能检索，并具备良好的泛化能力。"}}
{"id": "2601.13751", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13751", "abs": "https://arxiv.org/abs/2601.13751", "authors": ["Daniel Kyselica", "Jonáš Herec", "Oliver Kutis", "Rado Pitoňák"], "title": "HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection", "comment": "19 pages, 9 figures, submitted to conference", "summary": "Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at https://github.com/zaitra/HiT-change-detection", "AI": {"tldr": "本文提出了一种名为HiT（History Injection）的机制，用于在内存和计算能力受限的小型卫星上实现持续的自然灾害（特别是洪水）监测。HiT能够保留历史观测信息，同时将数据存储量减少99%以上，并且在Prithvi-tiny基础模型上保持了检测精度，实现在代表性的板载硬件上达到43 FPS的高处理速度。", "motivation": "自然灾害（如洪水）的实时监测对于灾害管理至关重要。现有技术通常依赖地面处理，而小型卫星由于存储和计算资源的限制，难以进行连续的、多时态的数据处理。", "method": "该研究提出了一种名为History Injection（HiT）的机制，将其集成到Transformer模型（Prithvi-tiny基础模型）中。HiT通过一种有效的方式维护历史上下文信息，同时大幅减少了数据存储需求（超过99%）。", "result": "在STTORM-CD洪水数据集上的测试表明，HiT机制在Prithvi-tiny模型上能够保持与双时态基线相当的洪水检测精度。在Jetson Orin Nano（一种代表性的小型卫星板载硬件）上，HiT-Prithvi模型实现了43 FPS的处理速度。", "conclusion": "该工作成功地开发了一个可在资源受限的小型卫星上运行的洪水检测系统，实现了高效的历史数据利用和高吞吐量的处理能力。这为基于卫星的自然灾害连续监测提供了一个实用的框架，能够支持实时灾害评估，而无需依赖地面处理设施。"}}
{"id": "2601.13715", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13715", "abs": "https://arxiv.org/abs/2601.13715", "authors": ["Yiwei Lu", "Hao Huang", "Tao Yan"], "title": "MVGD-Net: A Novel Motion-aware Video Glass Surface Detection Network", "comment": "This paper has been accepted by the 40th AAAI Conference on Artificial Intelligence (AAAI-26). It contians 9 pages, 11 figures", "summary": "Glass surface ubiquitous in both daily life and professional environments presents a potential threat to vision-based systems, such as robot and drone navigation. To solve this challenge, most recent studies have shown significant interest in Video Glass Surface Detection (VGSD). We observe that objects in the reflection (or transmission) layer appear farther from the glass surfaces. Consequently, in video motion scenarios, the notable reflected (or transmitted) objects on the glass surface move slower than objects in non-glass regions within the same spatial plane, and this motion inconsistency can effectively reveal the presence of glass surfaces. Based on this observation, we propose a novel network, named MVGD-Net, for detecting glass surfaces in videos by leveraging motion inconsistency cues. Our MVGD-Net features three novel modules: the Cross-scale Multimodal Fusion Module (CMFM) that integrates extracted spatial features and estimated optical flow maps, the History Guided Attention Module (HGAM) and Temporal Cross Attention Module (TCAM), both of which further enhances temporal features. A Temporal-Spatial Decoder (TSD) is also introduced to fuse the spatial and temporal features for generating the glass region mask. Furthermore, for learning our network, we also propose a large-scale dataset, which comprises 312 diverse glass scenarios with a total of 19,268 frames. Extensive experiments demonstrate that our MVGD-Net outperforms relevant state-of-the-art methods.", "AI": {"tldr": "提出了一种名为MVGD-Net的网络，利用视频中玻璃表面反射（或透射）物体比非玻璃区域物体移动慢的运动不一致性来检测玻璃表面。该网络包含跨尺度多模态融合、历史引导注意力和时间交叉注意力等模块，并引入了时间空间解码器来融合特征。此外，还提出了一个包含19268帧的大规模数据集用于训练。", "motivation": "视觉系统（如机器人和无人机导航）在日常和专业环境中都广泛使用玻璃表面，而玻璃表面的存在可能对这些系统造成威胁。现有方法在检测玻璃表面方面仍有改进空间。", "method": "提出了一种名为MVGD-Net的新型网络，用于视频中的玻璃表面检测。该网络的核心思想是利用玻璃表面反射（或透射）的物体比非玻璃区域物体运动速度慢这一运动不一致性。MVGD-Net包含四个主要模块：1. 跨尺度多模态融合模块（CMFM），用于融合空间特征和光流图；2. 历史引导注意力模块（HGAM）和时间交叉注意力模块（TCAM），用于增强时间特征；3. 时间空间解码器（TSD），用于融合空间和时间特征生成玻璃区域掩码。此外，还构建了一个包含312个场景、19268帧的大规模视频数据集。", "result": "在提出的新数据集上进行了广泛的实验，证明了MVGD-Net在视频玻璃表面检测任务上优于现有的最先进方法。", "conclusion": "提出的MVGD-Net能够有效利用视频中的运动不一致性来检测玻璃表面，并且在新数据集上的实验结果表明其性能优于现有方法。该研究还提出了一个大规模的视频玻璃表面检测数据集，为该领域的研究提供了支持。"}}
{"id": "2601.13837", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13837", "abs": "https://arxiv.org/abs/2601.13837", "authors": ["Xinya Ji", "Sebastian Weiss", "Manuel Kansy", "Jacek Naruniec", "Xun Cao", "Barbara Solenthaler", "Derek Bradley"], "title": "FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation", "comment": null, "summary": "Despite recent progress in 3D Gaussian-based head avatar modeling, efficiently generating high fidelity avatars remains a challenge. Current methods typically rely on extensive multi-view capture setups or monocular videos with per-identity optimization during inference, limiting their scalability and ease of use on unseen subjects. To overcome these efficiency drawbacks, we propose \\OURS, a feed-forward method to generate high-quality Gaussian head avatars from only a few input images while supporting real-time animation. Our approach directly learns a per-pixel Gaussian representation from the input images, and aggregates multi-view information using a transformer-based encoder that fuses image features from both DINOv3 and Stable Diffusion VAE. For real-time animation, we extend the explicit Gaussian representations with per-Gaussian features and introduce a lightweight MLP-based dynamic network to predict 3D Gaussian deformations from expression codes. Furthermore, to enhance geometric smoothness of the 3D head, we employ point maps from a pre-trained large reconstruction model as geometry supervision. Experiments show that our approach significantly outperforms existing methods in both rendering quality and inference efficiency, while supporting real-time dynamic avatar animation.", "AI": {"tldr": "解析错误", "motivation": "解析错误", "method": "解析错误", "result": "解析错误", "conclusion": "解析错误"}}
{"id": "2601.13899", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13899", "abs": "https://arxiv.org/abs/2601.13899", "authors": ["Masoumeh Javanbakhat", "Piotr Komorowski", "Dilyara Bareeva", "Wei-Chang Lai", "Wojciech Samek", "Christoph Lippert"], "title": "Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging", "comment": null, "summary": "Deep neural two-sample tests have recently shown strong power for detecting distributional differences between groups, yet their black-box nature limits interpretability and practical adoption in biomedical analysis. Moreover, most existing post-hoc explainability methods rely on class labels, making them unsuitable for label-free statistical testing settings. We propose an explainable deep statistical testing framework that augments deep two-sample tests with sample-level and feature-level explanations, revealing which individual samples and which input features drive statistically significant group differences. Our method highlights which image regions and which individual samples contribute most to the detected group difference, providing spatial and instance-wise insight into the test's decision. Applied to biomedical imaging data, the proposed framework identifies influential samples and highlights anatomically meaningful regions associated with disease-related variation. This work bridges statistical inference and explainable AI, enabling interpretable, label-free population analysis in medical imaging.", "AI": {"tldr": "提出了一种可解释的深度双样本检验框架，该框架通过样本级和特征级解释增强了现有的深度双样本检验方法，用于无标签的生物医学影像分析。", "motivation": "现有的深度双样本检验方法虽然具有很强的区分能力，但其黑箱特性限制了可解释性，尤其是在需要无标签数据的生物医学分析中。现有的大多数事后解释方法依赖于类别标签，不适用于无标签的统计检验场景。", "method": "通过引入样本级和特征级解释来增强深度双样本检验，揭示哪些个体样本和输入特征驱动了统计上显著的组间差异。该方法能够突出显示图像中的哪些区域以及哪些个体样本对检测到的组间差异贡献最大，从而提供空间和实例层面的洞察。", "result": "在生物医学影像数据上的应用表明，该框架能够识别有影响力的样本，并突出与疾病相关变异相关的解剖学上有意义的区域。", "conclusion": "该工作弥合了统计推断和可解释人工智能之间的差距，实现了医学影像中可解释的、无标签的群体分析。"}}
{"id": "2601.13852", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13852", "abs": "https://arxiv.org/abs/2601.13852", "authors": ["Raül Pérez-Gonzalo", "Andreas Espersen", "Antonio Agudo"], "title": "Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation", "comment": "Accepted to ICASSP 2026", "summary": "Linear discriminant analysis improves class separability but struggles with non-linearly separable data. To overcome this, we introduce Deep Discriminant Analysis (DDA), which directly optimizes the Fisher criterion utilizing deep networks. To ensure stable training and avoid computational instabilities, we incorporate signed between-class variance, bound outputs with a sigmoid function, and convert multiplicative relationships into additive ones. We present two stable DDA loss functions and augment them with a probability loss, resulting in Probabilistic DDA (PDDA). PDDA effectively minimizes class overlap in output distributions, producing highly confident predictions with reduced within-class variance. When applied to wind blade segmentation, PDDA showcases notable advances in performance and consistency, critical for wind energy maintenance. To our knowledge, this is the first application of DDA to image segmentation.", "AI": {"tldr": "本文提出了一种名为深度判别分析（DDA）的新方法，它利用深度网络直接优化 Fisher 判据，以解决线性判别分析在处理非线性可分数据时的不足。该方法通过引入带符号类间方差、使用 sigmoid 函数约束输出以及将乘法关系转化为加法关系来稳定训练。在此基础上，提出了概率 DDA（PDDA），通过最小化输出分布的类别重叠来提高预测的置信度和降低类内方差。PDDA 在风力叶片分割任务上取得了显著的性能和一致性提升，是 DDA 方法在图像分割领域的首次应用。", "motivation": "线性判别分析（LDA）在处理非线性可分数据时表现不佳，因此需要一种能够处理更复杂数据分布的方法。", "method": "提出深度判别分析（DDA），利用深度网络直接优化 Fisher 判据。为保证训练稳定，引入了带符号类间方差，使用 sigmoid 函数约束输出，并将乘法关系转化为加法关系。在此基础上，开发了两种稳定的 DDA 损失函数，并结合概率损失函数，形成了概率 DDA（PDDA），以最小化输出分布的类别重叠。", "result": "PDDA 在输出分布上有效最小化了类别重叠，产生了高置信度的预测，并降低了类内方差。在风力叶片分割任务上，PDDA 实现了性能和一致性的显著提升。", "conclusion": "PDDA 是一种有效的方法，能够通过深度网络优化 Fisher 判据，解决非线性可分数据的问题，并在图像分割任务（特别是风力叶片分割）中取得了优于现有方法的性能，同时提高了预测的置信度和一致性。这是 DDA 方法在图像分割领域的首次成功应用。"}}
{"id": "2601.13871", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13871", "abs": "https://arxiv.org/abs/2601.13871", "authors": ["Michail Spanakis", "Iason Oikonomidis", "Antonis Argyros"], "title": "OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting", "comment": null, "summary": "Class-Agnostic object Counting (CAC) involves counting instances of objects from arbitrary classes within an image. Due to its practical importance, CAC has received increasing attention in recent years. Most existing methods assume a single object class per image, rely on extensive training of large deep learning models and address the problem by incorporating additional information, such as visual exemplars or text prompts. In this paper, we present OCCAM, the first training-free approach to CAC that operates without the need of any supplementary information. Moreover, our approach addresses the multi-class variant of the problem, as it is capable of counting the object instances in each and every class among arbitrary object classes within an image. We leverage Segment Anything Model 2 (SAM2), a foundation model, and a custom threshold-based variant of the First Integer Neighbor Clustering Hierarchy (FINCH) algorithm to achieve competitive performance on widely used benchmark datasets, FSC-147 and CARPK. We propose a synthetic multi-class dataset and F1 score as a more suitable evaluation metric. The code for our method and the proposed synthetic dataset will be made publicly available at https://mikespanak.github.io/OCCAM_counter.", "AI": {"tldr": "本文提出了一种名为OCCAM的无训练、无需额外信息、能够进行多类别物体计数的通用方法，利用SAM2和FINCH算法，并在FSC-147和CARPK数据集上取得了具有竞争力的结果，同时提出了新的合成数据集和评估指标。", "motivation": "现有类无关物体计数（CAC）方法通常需要针对单类别图像进行大量训练，并依赖于视觉示例或文本提示等额外信息。研究动机是开发一种更通用、更高效的CAC方法，能够处理多类别图像，且无需训练和额外信息。", "method": "该方法名为OCCAM，它利用了Segment Anything Model 2 (SAM2) 基础模型来生成分割掩码，并结合自定义阈值的First Integer Neighbor Clustering Hierarchy (FINCH) 算法进行聚类和计数。该方法是训练无关的，并且可以直接处理多类别图像。", "result": "OCCAM在FSC-147和CARPK这两个广泛使用的基准数据集上取得了具有竞争力的性能。同时，研究者提出了一个合成的多类别数据集，并建议使用F1分数作为更合适的评估指标。", "conclusion": "OCCAM是第一个无需训练和额外信息的、能够进行任意类别多类别物体计数的通用方法，并展现了其在实际应用中的潜力。提出的新数据集和评估指标也有助于未来CAC领域的研究。"}}
{"id": "2601.13935", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13935", "abs": "https://arxiv.org/abs/2601.13935", "authors": ["Anoushkrit Goel", "Simroop Singh", "Ankita Joshi", "Ranjeet Ranjan Jha", "Chirag Ahuja", "Aditya Nigam", "Arnav Bhavsar"], "title": "TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation", "comment": "Accepted at 23rd IEEE International Symposium on Biomedical Imaging (ISBI), 2026", "summary": "White Matter Tract Segmentation is imperative for studying brain structural connectivity, neurological disorders and neurosurgery. This task remains complex, as tracts differ among themselves, across subjects and conditions, yet have similar 3D structure across hemispheres and subjects. To address these challenges, we propose TrackletGPT, a language-like GPT framework which reintroduces sequential information in tokens using tracklets. TrackletGPT generalises seamlessly across datasets, is fully automatic, and encodes granular sub-streamline segments, Tracklets, scaling and refining GPT models in Tractography Segmentation. Based on our experiments, TrackletGPT outperforms state-of-the-art methods on average DICE, Overlap and Overreach scores on TractoInferno and HCP datasets, even on inter-dataset experiments.", "AI": {"tldr": "TrackletGPT是一个基于Transformer的框架，通过引入tracklet（子流线段）来捕捉白质纤维束分割中的序列信息，在多个数据集上取得了优于现有方法的性能。", "motivation": "白质纤维束分割对于理解大脑结构连接、神经系统疾病和神经外科手术至关重要，但由于纤维束在自身、个体之间和不同病症下存在差异，并且在半球和个体之间具有相似的3D结构，因此该任务具有挑战性。", "method": "提出TrackletGPT，一个语言模型（GPT）框架，通过使用tracklet（代表子流线段）来重新引入序列信息。该框架能够泛化到不同的数据集，实现全自动化，并编码细粒度的子流线段信息。", "result": "TrackletGPT在TractoInferno和HCP数据集上，在平均DICE、Overlap和Overreach得分上均优于最先进的方法，甚至在跨数据集的实验中也表现出色。", "conclusion": "TrackletGPT成功地将GPT模型扩展到纤维束分割领域，通过tracklet捕捉序列信息，实现了自动化和跨数据集的泛化能力，并在实验中取得了优越的性能。"}}
{"id": "2601.13886", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13886", "abs": "https://arxiv.org/abs/2601.13886", "authors": ["Shangzhe Di", "Zhonghua Zhai", "Weidi Xie"], "title": "Revisiting Multi-Task Visual Representation Learning", "comment": "Code: https://github.com/Becomebright/MTV", "summary": "Current visual representation learning remains bifurcated: vision-language models (e.g., CLIP) excel at global semantic alignment but lack spatial precision, while self-supervised methods (e.g., MAE, DINO) capture intricate local structures yet struggle with high-level semantic context. We argue that these paradigms are fundamentally complementary and can be integrated into a principled multi-task framework, further enhanced by dense spatial supervision. We introduce MTV, a multi-task visual pretraining framework that jointly optimizes a shared backbone across vision-language contrastive, self-supervised, and dense spatial objectives. To mitigate the need for manual annotations, we leverage high-capacity \"expert\" models -- such as Depth Anything V2 and OWLv2 -- to synthesize dense, structured pseudo-labels at scale. Beyond the framework, we provide a systematic investigation into the mechanics of multi-task visual learning, analyzing: (i) the marginal gain of each objective, (ii) task synergies versus interference, and (iii) scaling behavior across varying data and model scales. Our results demonstrate that MTV achieves \"best-of-both-worlds\" performance, significantly enhancing fine-grained spatial reasoning without compromising global semantic understanding. Our findings suggest that multi-task learning, fueled by high-quality pseudo-supervision, is a scalable path toward more general visual encoders.", "AI": {"tldr": "提出了一种名为MTV的多任务视觉预训练框架，通过联合优化视觉-语言对比、自监督和密集空间目标，并利用“专家”模型合成伪标签，实现了全局语义理解和精细空间推理的“两全其美”性能。", "motivation": "现有的视觉表示学习方法要么擅长全局语义对齐（如CLIP），但缺乏空间精度；要么擅长捕捉局部结构（如MAE、DINO），但难以理解高层语义。研究者认为这两种范式是互补的，可以通过多任务学习框架并结合密集空间监督来整合。", "method": "提出MTV（Multi-task Visual Pretraining）框架，该框架在一个共享骨干网络上联合优化视觉-语言对比、自监督和密集空间目标。为了避免手动标注，利用高容量的“专家”模型（如Depth Anything V2和OWLv2）大规模合成密集的、结构化的伪标签。此外，对多任务视觉学习的机制进行了系统性研究，分析了各目标的边际增益、任务协同或干扰效应以及不同数据和模型规模下的扩展行为。", "result": "MTV在“两全其美”的性能上取得了显著提升，在增强精细空间推理能力的同时，并未损害全局语义理解。研究表明，高 K 质量的伪监督信号驱动的多任务学习，是迈向更通用视觉编码器的可扩展路径。", "conclusion": "多任务学习，结合利用“专家”模型生成的伪标签，是实现通用视觉编码器的有效且可扩展的方法，能够同时提升全局语义和局部空间理解能力。"}}
{"id": "2601.13913", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13913", "abs": "https://arxiv.org/abs/2601.13913", "authors": ["Pavlo Melnyk", "Cuong Le", "Urs Waldmann", "Per-Erik Forssén", "Bastian Wandt"], "title": "On the Role of Rotation Equivariance in Monocular 3D Human Pose Estimation", "comment": null, "summary": "Estimating 3D from 2D is one of the central tasks in computer vision. In this work, we consider the monocular setting, i.e. single-view input, for 3D human pose estimation (HPE). Here, the task is to predict a 3D point set of human skeletal joints from a single 2D input image. While by definition this is an ill-posed problem, recent work has presented methods that solve it with up to several-centimetre error. Typically, these methods employ a two-step approach, where the first step is to detect the 2D skeletal joints in the input image, followed by the step of 2D-to-3D lifting. We find that common lifting models fail when encountering a rotated input. We argue that learning a single human pose along with its in-plane rotations is considerably easier and more geometrically grounded than directly learning a point-to-point mapping. Furthermore, our intuition is that endowing the model with the notion of rotation equivariance without explicitly constraining its parameter space should lead to a more straightforward learning process than one with equivariance by design. Utilising the common HPE benchmarks, we confirm that the 2D rotation equivariance per se improves the model performance on human poses akin to rotations in the image plane, and can be efficiently and straightforwardly learned by augmentation, outperforming state-of-the-art equivariant-by-design methods.", "AI": {"tldr": "本文提出了一种通过单目2D图像估计3D人体姿态的方法，重点关注2D旋转不变性，并通过数据增强来实现，结果优于现有的专门设计等变的方法。", "motivation": "现有的2D到3D人体姿态估计方法在处理输入图像旋转时表现不佳。作者认为，学习人体姿态及其平面内旋转比直接学习点对点映射更容易，并且通过数据增强引入旋转不变性比设计等变模型更直接。", "method": "该方法首先检测2D人体骨骼关节点，然后利用2D旋转不变性将其提升到3D。通过对训练数据进行旋转增强，使得模型能够学习到2D旋转不变性，而无需显式设计等变网络。", "result": "通过在常用的人体姿态估计基准数据集上进行实验，证明了2D旋转不变性能够提升模型在处理图像平面内旋转的人体姿态时的性能，并且通过数据增强可以高效且直接地学习到这种不变性，性能优于专门设计等变的方法。", "conclusion": "通过数据增强引入2D旋转不变性是解决单目3D人体姿态估计中旋转问题的一种有效且简单的方法，其性能甚至优于复杂的等变设计方法。"}}
{"id": "2601.13951", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13951", "abs": "https://arxiv.org/abs/2601.13951", "authors": ["Shengyi Wu", "Yan Hong", "Shengyao Chen", "Zheng Wang", "Xianbing Sun", "Jiahui Zhan", "Jun Lan", "Jianfu Zhang"], "title": "VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content", "comment": null, "summary": "With the rapid advancement of generative AI, virtual try-on (VTON) systems are becoming increasingly common in e-commerce and digital entertainment. However, the growing realism of AI-generated try-on content raises pressing concerns about authenticity and responsible use. To address this, we present VTONGuard, a large-scale benchmark dataset containing over 775,000 real and synthetic try-on images. The dataset covers diverse real-world conditions, including variations in pose, background, and garment styles, and provides both authentic and manipulated examples. Based on this benchmark, we conduct a systematic evaluation of multiple detection paradigms under unified training and testing protocols. Our results reveal each method's strengths and weaknesses and highlight the persistent challenge of cross-paradigm generalization. To further advance detection, we design a multi-task framework that integrates auxiliary segmentation to enhance boundary-aware feature learning, achieving the best overall performance on VTONGuard. We expect this benchmark to enable fair comparisons, facilitate the development of more robust detection models, and promote the safe and responsible deployment of VTON technologies in practice.", "AI": {"tldr": "本文提出了VTONGuard，一个包含77.5万张真实和合成虚拟试衣图像的大型基准数据集，并基于此数据集评估了多种检测方法，发现跨模型泛化性仍是挑战。研究还设计了一个多任务框架，通过集成辅助分割任务提升了边界感知特征学习，取得了最佳检测性能。", "motivation": "随着生成式AI在虚拟试衣（VTON）领域的快速发展，AI生成内容的真实性引发了对内容真实性和负责任使用的担忧。", "method": "构建了一个包含超过77.5万张真实和合成虚拟试衣图像的大型基准数据集VTONGuard，覆盖多样化的真实世界条件。在此基础上，对多种检测范式进行了统一的训练和测试协议评估。最后，设计了一个集成了辅助分割的多任务框架，以增强边界感知特征学习。", "result": "对现有检测方法的评估揭示了各自的优缺点以及跨模型泛化性的挑战。提出的多任务框架在VTONGuard数据集上取得了最佳的整体检测性能。", "conclusion": "VTONGuard基准数据集的构建能够促进更公平的比较，加速更鲁棒的检测模型的开发，并推动VTON技术在实践中的安全负责任部署。"}}
{"id": "2601.13839", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13839", "abs": "https://arxiv.org/abs/2601.13839", "authors": ["Aisha Al-Mohannadi", "Ayisha Firoz", "Yin Yang", "Muhammad Imran", "Ferda Ofli"], "title": "DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes", "comment": null, "summary": "Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at https://zenodo.org/records/18267770.", "AI": {"tldr": "本研究提出了 DisasterVQA 数据集，包含 1,395 张真实灾难图像和 4,405 个问题-答案对，旨在评估和提升视觉问答（VQA）模型在灾难响应中的应用能力。研究发现，现有先进模型在处理简单问题时表现良好，但在精细量化推理、物体计数和需要上下文理解的复杂问题上存在显著不足，尤其是在代表性不足的灾难场景中。", "motivation": "现有 VQA 技术在通用领域表现出色，但其在复杂且事关安全的灾难响应场景下的适用性仍不明确。因此，需要一个专门的数据集来评估和推动 VQA 模型在危机环境下的感知和推理能力。", "method": "构建了一个名为 DisasterVQA 的基准数据集，包含 1,395 张来自真实世界（如洪水、野火、地震）的灾难图像，并由专家创建了 4,405 个问题-答案对。问题类型涵盖了二元选择、多项选择和开放式问题，并依据 FEMA ESF 和 OCHA MIRA 等人道主义框架，涉及了态势感知和操作决策制定等任务。随后，对七种最先进的视觉语言模型进行了基准测试。", "result": "在对七个先进视觉语言模型的评估中，发现模型在不同类型问题、灾难类别、地理区域和人道主义任务上的表现存在显著差异。模型在二元选择题上准确率较高，但在处理精细的量化推理、物体计数和需要上下文敏感解释的问题时表现不佳，尤其是在代表性不足的灾难场景下。", "conclusion": "DisasterVQA 数据集提供了一个具有挑战性且实用的基准，能够指导开发更鲁棒、更具操作意义的视觉语言模型，以满足灾难响应的需求。现有 VQA 模型在处理灾难响应中的复杂推理任务方面仍需改进。"}}
{"id": "2601.13954", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13954", "abs": "https://arxiv.org/abs/2601.13954", "authors": ["Adrien Meyer", "Didier Mutter", "Nicolas Padoy"], "title": "DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging", "comment": null, "summary": "Detecting anatomical landmarks in medical imaging is essential for diagnosis and intervention guidance. However, object detection models rely on costly bounding box annotations, limiting scalability. Weakly Semi-Supervised Object Detection (WSSOD) with point annotations proposes annotating each instance with a single point, minimizing annotation time while preserving localization signals. A Point-to-Box teacher model, trained on a small box-labeled subset, converts these point annotations into pseudo-box labels to train a student detector. Yet, medical imagery presents unique challenges, including overlapping anatomy, variable object sizes, and elusive structures, which hinder accurate bounding box inference. To overcome these challenges, we introduce DExTeR (DETR with Experts), a transformer-based Point-to-Box regressor tailored for medical imaging. Built upon Point-DETR, DExTeR encodes single-point annotations as object queries, refining feature extraction with the proposed class-guided deformable attention, which guides attention sampling using point coordinates and class labels to capture class-specific characteristics. To improve discrimination in complex structures, it introduces CLICK-MoE (CLass, Instance, and Common Knowledge Mixture of Experts), decoupling class and instance representations to reduce confusion among adjacent or overlapping instances. Finally, we implement a multi-point training strategy which promotes prediction consistency across different point placements, improving robustness to annotation variability. DExTeR achieves state-of-the-art performance across three datasets spanning different medical domains (endoscopy, chest X-rays, and endoscopic ultrasound) highlighting its potential to reduce annotation costs while maintaining high detection accuracy.", "AI": {"tldr": "本文提出了一种名为 DExTeR 的新颖方法，用于在医学影像中进行弱监督半监督物体检测。DExTeR 利用点标注而非耗时的边界框标注，并引入了类引导可变形注意力、CLICK-MoE 和多点训练策略来提高检测精度和鲁棒性，尤其是在处理重叠、大小可变和结构模糊的医学图像时。", "motivation": "传统的医学影像物体检测方法需要耗费大量时间和成本的边界框标注。弱监督半监督物体检测（WSSOD）使用点标注来降低标注成本，但医学影像的复杂性（如重叠解剖结构、多变尺寸和模糊结构）会阻碍准确的边界框推断。", "method": "DExTeR (DETR with Experts) 是一个基于 Transformer 的点到框回归器。它使用 Point-DETR 作为基础，将点标注编码为对象查询。关键创新包括：1. 类引导可变形注意力（class-guided deformable attention），利用点坐标和类别标签指导注意力采样，捕获特定类别的特征。2. CLICK-MoE（CLass, Instance, and Common Knowledge Mixture of Experts），解耦类别和实例表示，减少相邻或重叠实例的混淆。3. 多点训练策略，提高对标注变异性的鲁棒性。", "result": "DExTeR 在三个跨不同医学领域（内窥镜检查、胸部 X 射线和内窥镜超声）的数据集上取得了最先进的性能。", "conclusion": "DExTeR 能够有效处理医学影像的挑战，通过点标注显著降低标注成本，同时保持高检测精度，展现了其在医学影像分析中的巨大潜力。"}}
{"id": "2601.13974", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13974", "abs": "https://arxiv.org/abs/2601.13974", "authors": ["Shih-Yao Lin"], "title": "STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames", "comment": "This paper corresponds to the camera-ready version of a WACV 2026 Workshop paper", "summary": "Frame sampling is a fundamental component in video understanding and video--language model pipelines, yet evaluating the quality of sampled frames remains challenging. Existing evaluation metrics primarily focus on perceptual quality or reconstruction fidelity, and are not designed to assess whether a set of sampled frames adequately captures informative and representative video content.\n  We propose Spatio-Temporal Entropy Coverage (STEC), a simple and non-reference metric for evaluating the effectiveness of video frame sampling. STEC builds upon Spatio-Temporal Frame Entropy (STFE), which measures per-frame spatial information via entropy-based structural complexity, and evaluates sampled frames based on their temporal coverage and redundancy. By jointly modeling spatial information strength, temporal dispersion, and non-redundancy, STEC provides a principled and lightweight measure of sampling quality.\n  Experiments on the MSR-VTT test-1k benchmark demonstrate that STEC clearly differentiates common sampling strategies, including random, uniform, and content-aware methods. We further show that STEC reveals robustness patterns across individual videos that are not captured by average performance alone, highlighting its practical value as a general-purpose evaluation tool for efficient video understanding.\n  We emphasize that STEC is not designed to predict downstream task accuracy, but to provide a task-agnostic diagnostic signal for analyzing frame sampling behavior under constrained budgets.", "AI": {"tldr": "提出了一种名为时空熵覆盖（STEC）的新指标，用于评估视频帧采样质量，该指标考虑了帧的空间信息、时间分布和冗余度，而非仅关注感知质量或重建保真度。", "motivation": "现有的视频帧采样评估指标难以衡量采样帧是否充分捕捉了视频的丰富和代表性内容。", "method": "STEC 指标基于时空帧熵（STFE），STFE 通过熵衡量每帧的空间信息，STEC 则在此基础上评估采样帧的时间覆盖度和冗余度。", "result": "在 MSR-VTT test-1k 基准测试中，STEC 能够有效区分随机、均匀和内容感知等采样策略，并揭示了视频层面的鲁棒性模式。", "conclusion": "STEC 是一个简单、无需参考的评估工具，能够提供一种任务无关的诊断信号，用于分析视频理解中受限预算下的帧采样行为。"}}
{"id": "2601.13975", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13975", "abs": "https://arxiv.org/abs/2601.13975", "authors": ["Marco Piccolo", "Qiwei Han", "Astrid van Toor", "Joachim Vanneste"], "title": "Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains", "comment": "9 pages, 4 figures 8 tables", "summary": "Marine biodiversity monitoring requires scalability and reliability across complex underwater environments to support conservation and invasive-species management. Yet existing detection solutions often exhibit a pronounced deployment gap, with performance degrading sharply when transferred to new sites. This work establishes the foundational detection layer for a multi-year invasive species monitoring initiative targeting Arctic and Atlantic marine ecosystems. We address this challenge by developing a Unified Information Pipeline that standardises heterogeneous datasets into a comparable information flow and evaluates a fixed, deployment-relevant detector under controlled cross-domain protocols. Across multiple domains, we find that structural factors, such as scene composition, object density, and contextual redundancy, explain cross-domain performance loss more strongly than visual degradation such as turbidity, with sparse scenes inducing a characteristic \"Context Collapse\" failure mode. We further validate operational feasibility by benchmarking inference on low-cost edge hardware, showing that runtime optimisation enables practical sampling rates for remote monitoring. The results shift emphasis from image enhancement toward structure-aware reliability, providing a democratised tool for consistent marine ecosystem assessment.", "AI": {"tldr": "研究开发了一种统一信息管道，用于标准化和评估用于海洋生物多样性监测的检测器，发现场景结构是跨领域性能下降的关键因素，并展示了在低成本边缘硬件上的可行性。", "motivation": "需要一种可扩展且可靠的海洋生物多样性监测方法，以支持保护和入侵物种管理，现有解决方案在部署到新地点时性能会急剧下降。", "method": "开发了一个统一信息管道，用于标准化异构数据集，并评估了一个固定检测器在受控的跨领域协议下的性能。还对低成本边缘硬件上的推理进行了基准测试。", "result": "场景构成、物体密度和上下文冗余等结构因素比浊度等视觉降级更能解释跨领域性能损失，稀疏场景会导致“上下文崩溃”故障模式。运行时优化使得在边缘硬件上实现可行的采样率。", "conclusion": "研究强调了从图像增强转向结构感知可靠性的重要性，并提供了一个用于一致性海洋生态系统评估的民主化工具。"}}
{"id": "2601.14042", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14042", "abs": "https://arxiv.org/abs/2601.14042", "authors": ["Jiaze Li", "Haoran Xu", "Wanyi Wu", "Changwei Wang", "Shuaiguang Li", "Jianzhong Ju", "Zhenbo Luo", "Jian Luan", "Youyang Qu", "Longxiang Gao", "Xudong Yang", "Lumin Xing"], "title": "Federated Balanced Learning", "comment": null, "summary": "Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance.", "AI": {"tldr": "提出一种名为联邦均衡学习（FBL）的新方法，通过在客户端进行样本均衡来解决联邦学习中非独立同分布（non-iid）数据导致的客户端漂移问题。", "motivation": "现有方法在模型已发生偏移后进行修正，忽视了客户端样本的影响，导致在非独立同分布（non-iid）设置下，全局模型出现客户端漂移，严重影响模型性能。", "method": "FBL通过客户端的知识填充和知识采样，利用边缘端生成模型实现样本均衡，同时设计了知识对齐策略弥合合成数据与真实数据之间的差距，以及知识遗忘策略进行正则化。该方法适用于复杂场景，允许不同客户端采用不同策略，并可扩展以提升性能。", "result": "通过大量实验证明，FBL方法优于现有的最先进基线方法。", "conclusion": "FBL方法能够有效地解决联邦学习中的客户端漂移问题，通过从源头（客户端）进行样本均衡来提升模型性能。"}}
{"id": "2601.14038", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14038", "abs": "https://arxiv.org/abs/2601.14038", "authors": ["Alexandre Justo Miro", "Ludvig af Klinteberg", "Bogdan Timus", "Aron Asefaw", "Ajinkya Khoche", "Thomas Gustafsson", "Sina Sharif Mansouri", "Masoud Daneshtalab"], "title": "Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving", "comment": "Accepted to The IEEE/CVF Winter Conference on Applications of Computer Vision 2026", "summary": "Accurate ground truth annotations are critical to supervised learning and evaluating the performance of autonomous vehicle systems. These vehicles are typically equipped with active sensors, such as LiDAR, which scan the environment in predefined patterns. 3D box annotation based on data from such sensors is challenging in dynamic scenarios, where objects are observed at different timestamps, hence different positions. Without proper handling of this phenomenon, systematic errors are prone to being introduced in the box annotations. Our work is the first to discover such annotation errors in widely used, publicly available datasets. Through our novel offline estimation method, we correct the annotations so that they follow physically feasible trajectories and achieve spatial and temporal consistency with the sensor data. For the first time, we define metrics for this problem; and we evaluate our method on the Argoverse 2, MAN TruckScenes, and our proprietary datasets. Our approach increases the quality of box annotations by more than 17% in these datasets. Furthermore, we quantify the annotation errors in them and find that the original annotations are misplaced by up to 2.5 m, with highly dynamic objects being the most affected. Finally, we test the impact of the errors in benchmarking and find that the impact is larger than the improvements that state-of-the-art methods typically achieve with respect to the previous state-of-the-art methods; showing that accurate annotations are essential for correct interpretation of performance. Our code is available at https://github.com/alexandre-justo-miro/annotation-correction-3D-boxes.", "AI": {"tldr": "该研究首次发现了自动驾驶数据集中的3D边界框标注错误，并提出了一种新的离线估计算法来修正这些错误，提高了标注质量，并定义了评估标注错误的新指标。", "motivation": "现有自动驾驶数据集的3D边界框标注在动态场景下存在系统性误差，由于物体在不同时间戳处于不同位置，导致标注不准确，影响监督学习和性能评估。作者希望解决这一问题。", "method": "提出了一种新的离线估计算法，该算法能够校正3D边界框的标注，使其遵循物理上可行的轨迹，并与传感器数据在空间和时间上保持一致。同时，定义了度量此问题的新指标。", "result": "在Argoverse 2、MAN TruckScenes和自有数据集上对该方法进行了评估。标注质量提高了17%以上。量化了标注错误，发现原始标注最多偏移2.5米，且动态物体受影响最大。实验证明，标注错误对性能基准测试的影响比最先进方法的改进还要大。", "conclusion": "该研究揭示了现有3D边界框标注中的系统性误差，并提供了一种有效的校正方法，强调了准确标注对于正确评估自动驾驶系统性能的重要性。"}}
{"id": "2601.14044", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14044", "abs": "https://arxiv.org/abs/2601.14044", "authors": ["Kaiyu Wu", "Pucheng Han", "Hualong Zhang", "Naigeng Wu", "Keze Wang"], "title": "Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology", "comment": null, "summary": "While Vision Language Models (VLMs) show advancing reasoning capabilities, their application in meteorology is constrained by a domain gap and a reasoning faithfulness gap. Specifically, mainstream Reinforcement Fine-Tuning (RFT) can induce Self-Contradictory Reasoning (Self-Contra), where the model's reasoning contradicts its final answer, which is unacceptable in such a high-stakes domain. To address these challenges, we construct WeatherQA, a novel multimodal reasoning benchmark in meteorology. We also propose Logically Consistent Reinforcement Fine-Tuning (LoCo-RFT), which resolves Self-Contra by introducing a logical consistency reward. Furthermore, we introduce Weather-R1, the first reasoning VLM with logical faithfulness in meteorology, to the best of our knowledge. Experiments demonstrate that Weather-R1 improves performance on WeatherQA by 9.8 percentage points over the baseline, outperforming Supervised Fine-Tuning and RFT, and even surpassing the original Qwen2.5-VL-32B. These results highlight the effectiveness of our LoCo-RFT and the superiority of Weather-R1. Our benchmark and code are available at https://github.com/Marcowky/Weather-R1.", "AI": {"tldr": "本研究提出了WeatherQA数据集和LoCo-RFT方法，以解决气象领域视觉语言模型（VLMs）的领域差距和推理不一致问题，并开发了具有逻辑一致性的气象领域VLM Weather-R1，实验证明其性能优于现有方法。", "motivation": "现有主流的视觉语言模型（VLMs）在气象领域的应用受到领域差距和推理不一致（Self-Contra）问题的限制，这在高风险领域是不可接受的。因此，需要开发新的数据集和方法来提高VLM在气象领域的推理能力和逻辑一致性。", "method": "1. 构建了一个新的多模态气象推理基准数据集WeatherQA。 2. 提出了一种名为LoCo-RFT的逻辑一致性强化微调方法，通过引入逻辑一致性奖励来解决Self-Contra问题。 3. 开发了Weather-R1，一个在气象领域具有逻辑一致性的首个推理VLM。", "result": "Weather-R1在WeatherQA数据集上的性能比基线方法提高了9.8个百分点，优于监督微调（SFT）和强化微调（RFT），甚至超过了原始的Qwen2.5-VL-32B模型。", "conclusion": "LoCo-RFT方法和Weather-R1模型在解决气象领域VLM的领域差距和逻辑不一致问题上是有效的，并且Weather-R1在气象多模态推理任务上表现出优越的性能。"}}
{"id": "2601.14037", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14037", "abs": "https://arxiv.org/abs/2601.14037", "authors": ["Kumar Ashutosh", "XuDong Wang", "Xi Yin", "Kristen Grauman", "Adam Polyak", "Ishan Misra", "Rohit Girdhar"], "title": "Human detectors are surprisingly powerful reward models", "comment": "Technical report", "summary": "Video generation models have recently achieved impressive visual fidelity and temporal coherence. Yet, they continue to struggle with complex, non-rigid motions, especially when synthesizing humans performing dynamic actions such as sports, dance, etc. Generated videos often exhibit missing or extra limbs, distorted poses, or physically implausible actions. In this work, we propose a remarkably simple reward model, HuDA, to quantify and improve the human motion in generated videos. HuDA integrates human detection confidence for appearance quality, and a temporal prompt alignment score to capture motion realism. We show this simple reward function that leverages off-the-shelf models without any additional training, outperforms specialized models finetuned with manually annotated data. Using HuDA for Group Reward Policy Optimization (GRPO) post-training of video models, we significantly enhance video generation, especially when generating complex human motions, outperforming state-of-the-art models like Wan 2.1, with win-rate of 73%. Finally, we demonstrate that HuDA improves generation quality beyond just humans, for instance, significantly improving generation of animal videos and human-object interactions.", "AI": {"tldr": "本文提出了一种名为 HuDA 的简单奖励模型，用于评估和改进视频生成中人类动作的真实性，并在不依赖额外训练的情况下，通过 GRPO 后期训练显著提升了视频生成质量，尤其是在处理复杂人体运动方面。", "motivation": "现有的视频生成模型在处理复杂、非刚性的人体运动（如体育、舞蹈）时存在困难，容易生成肢体缺失/多余、姿态扭曲或运动不符合物理规律的视频。", "method": "HuDA 奖励模型结合了人体检测置信度（衡量外观质量）和时间提示对齐得分（捕捉运动真实性）。该模型利用现成的模型，无需额外训练。通过将 HuDA 应用于 GRPO（Group Reward Policy Optimization）进行视频模型的后期训练。", "result": "HuDA 奖励函数在不进行额外训练的情况下，优于经过手动标注数据微调的专业模型。使用 HuDA 进行 GRPO 后期训练，能够显著提高视频生成质量，尤其是在生成复杂人体运动时，超越了 Wan 2.1 等最先进模型，获胜率达到 73%。此外，HuDA 还能改善非人类视频（如动物视频）和人机交互的生成质量。", "conclusion": "HuDA 提供了一种简单而有效的奖励机制，能够有效地量化和提升视频生成中人类动作的质量，并且这种提升可以泛化到其他类型的生成内容，如动物视频和人机交互。"}}
{"id": "2601.14052", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14052", "abs": "https://arxiv.org/abs/2601.14052", "authors": ["Haoran Xu", "Yanlin Liu", "Zizhao Tong", "Jiaze Li", "Kexue Fu", "Yuyang Zhang", "Longxiang Gao", "Shuaiguang Li", "Xingyu Li", "Yanran Xu", "Changwei Wang"], "title": "Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model", "comment": null, "summary": "Out-of-Distribution (OOD) detection is a critical task that has garnered significant attention. The emergence of CLIP has spurred extensive research into zero-shot OOD detection, often employing a training-free approach. Current methods leverage expert knowledge from large language models (LLMs) to identify potential outliers. However, these approaches tend to over-rely on knowledge in the text space, neglecting the inherent challenges involved in detecting out-of-distribution samples in the image space. In this paper, we propose a novel pipeline, MM-OOD, which leverages the multimodal reasoning capabilities of MLLMs and their ability to conduct multi-round conversations for enhanced outlier detection. Our method is designed to improve performance in both near OOD and far OOD tasks. Specifically, (1) for near OOD tasks, we directly feed ID images and corresponding text prompts into MLLMs to identify potential outliers; and (2) for far OOD tasks, we introduce the sketch-generate-elaborate framework: first, we sketch outlier exposure using text prompts, then generate corresponding visual OOD samples, and finally elaborate by using multimodal prompts. Experiments demonstrate that our method achieves significant improvements on widely used multimodal datasets such as Food-101, while also validating its scalability on ImageNet-1K.", "AI": {"tldr": "本文提出了一种名为MM-OOD的新型管道，利用多模态大型语言模型（MLLMs）的多轮对话和多模态推理能力来提升分布外（OOD）检测性能，特别是在近分布外（near OOD）和远分布外（far OOD）任务上。", "motivation": "现有的零样本OOD检测方法过度依赖LLMs的文本空间知识，忽视了图像空间OOD样本检测的固有挑战。因此，需要一种能充分利用多模态信息和推理能力的方法。", "method": "MM-OOD管道利用MLLMs进行多轮对话和多模态推理。对于near OOD任务，直接输入ID图像和文本提示；对于far OOD任务，引入“sketch-generate-elaborate”框架，包括文本提示勾勒异常、生成视觉OOD样本，以及使用多模态提示进行详细阐述。", "result": "在Food-101等常用多模态数据集上取得了显著的性能提升，并在ImageNet-1K上验证了方法的扩展性。", "conclusion": "MLLMs的多轮对话和多模态推理能力可以有效增强OOD检测性能，尤其是在处理不同类型的OOD数据时，MM-OOD方法能够取得比现有方法更好的效果。"}}
{"id": "2601.14060", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14060", "abs": "https://arxiv.org/abs/2601.14060", "authors": ["Yongcong Ye", "Kai Zhang", "Yanghai Zhang", "Enhong Chen", "Longfei Li", "Jun Zhou"], "title": "Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration", "comment": null, "summary": "Zero-shot composed image retrieval (ZS-CIR) is a rapidly growing area with significant practical applications, allowing users to retrieve a target image by providing a reference image and a relative caption describing the desired modifications. Existing ZS-CIR methods often struggle to capture fine-grained changes and integrate visual and semantic information effectively. They primarily rely on either transforming the multimodal query into a single text using image-to-text models or employing large language models for target image description generation, approaches that often fail to capture complementary visual information and complete semantic context. To address these limitations, we propose a novel Fine-Grained Zero-Shot Composed Image Retrieval method with Complementary Visual-Semantic Integration (CVSI). Specifically, CVSI leverages three key components: (1) Visual Information Extraction, which not only extracts global image features but also uses a pre-trained mapping network to convert the image into a pseudo token, combining it with the modification text and the objects most likely to be added. (2) Semantic Information Extraction, which involves using a pre-trained captioning model to generate multiple captions for the reference image, followed by leveraging an LLM to generate the modified captions and the objects most likely to be added. (3) Complementary Information Retrieval, which integrates information extracted from both the query and database images to retrieve the target image, enabling the system to efficiently handle retrieval queries in a variety of situations. Extensive experiments on three public datasets (e.g., CIRR, CIRCO, and FashionIQ) demonstrate that CVSI significantly outperforms existing state-of-the-art methods. Our code is available at https://github.com/yyc6631/CVSI.", "AI": {"tldr": "提出了一种名为CVSI的新方法，用于零样本组合图像检索（ZS-CIR），通过整合互补的视觉和语义信息，以更好地处理细粒度修改并提升检索性能。", "motivation": "现有ZS-CIR方法在捕捉细粒度变化和有效整合视觉语义信息方面存在不足，常依赖单一模态转换或LLM生成描述，无法充分利用互补的视觉信息和完整的语义上下文。", "method": "CVSI方法包含三个关键组件：1. 视觉信息提取，提取全局特征并生成伪token，结合修改文本和可能添加的对象。2. 语义信息提取，通过预训练模型生成参考图像的多个描述，并利用LLM生成修改后的描述和可能添加的对象。3. 互补信息检索，整合查询和数据库图像的信息以进行检索。", "result": "在CIRR、CIRCO和FashionIQ三个公共数据集上的广泛实验表明，CVSI显著优于现有最先进的方法。", "conclusion": "CVSI通过有效融合互补的视觉和语义信息，克服了现有ZS-CIR方法的局限性，在各种检索场景下均表现出优越的性能。"}}
{"id": "2601.14030", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14030", "abs": "https://arxiv.org/abs/2601.14030", "authors": ["Samuel W. Remedios", "Zhangxing Bian", "Shuwen Wei", "Aaron Carass", "Jerry L. Prince", "Blake E. Dewey"], "title": "Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution", "comment": null, "summary": "Diffusion models are the current state-of-the-art for solving inverse problems in imaging. Their impressive generative capability allows them to approximate sampling from a prior distribution, which alongside a known likelihood function permits posterior sampling without retraining the model. While recent methods have made strides in advancing the accuracy of posterior sampling, the majority focuses on single-image inverse problems. However, for modalities such as magnetic resonance imaging (MRI), it is common to acquire multiple complementary measurements, each low-resolution along a different axis. In this work, we generalize common diffusion-based inverse single-image problem solvers for multi-image super-resolution (MISR) MRI. We show that the DPS likelihood correction allows an exactly-separable gradient decomposition across independently acquired measurements, enabling MISR without constructing a joint operator, modifying the diffusion model, or increasing network function evaluations. We derive MISR versions of DPS, DMAP, DPPS, and diffusion-based PnP/ADMM, and demonstrate substantial gains over SISR across $4\\times/8\\times/16\\times$ anisotropic degradations. Our results achieve state-of-the-art super-resolution of anisotropic MRI volumes and, critically, enable reconstruction of near-isotropic anatomy from routine 2D multi-slice acquisitions, which are otherwise highly degraded in orthogonal views.", "AI": {"tldr": "本文提出了一种将单图像逆问题求解中的扩散模型推广到多图像超分辨率（MISR）MRI的方法，该方法利用DPS似然修正实现了梯度在独立测量中的可分离分解，无需构建联合算子或修改扩散模型，并在各项异性退化MRI数据上取得了最先进的超分辨率效果，能够从2D多切片采集重建近乎各向同性的解剖结构。", "motivation": "现有的基于扩散模型的逆问题求解方法主要关注单图像问题，而MRI等模态常采集多个沿不同轴线采样的低分辨率测量。本文旨在解决多图像超分辨率（MISR）MRI问题，以提升图像质量。", "method": "作者将单图像逆问题求解中的扩散模型推广到MISR MRI。利用DPS似然修正，实现了梯度在独立测量中的可分离分解，避免了构建联合算子、修改扩散模型或增加网络函数评估。推导了DPS、DMAP、DPPS和基于扩散的PnP/ADMM的MISR版本。", "result": "所提出的方法在$4\times/8\times/16\times$各向异性退化下，实现了MISR，并在超分辨率方面取得了显著的性能提升。结果表明，该方法能够从常规2D多切片采集重建近乎各向同性的解剖结构，即使在正交视图下存在严重退化。", "conclusion": "本文成功地将基于扩散模型的单图像逆问题求解方法泛化到MISR MRI，并通过DPS似然修正实现了高效的梯度分解，无需修改现有模型。该方法在各向异性MRI超分辨率方面取得了最先进的性能，并能有效地从2D采集重建高质量的各向同性图像。"}}
{"id": "2601.14066", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14066", "abs": "https://arxiv.org/abs/2601.14066", "authors": ["Hendrik Möller", "Hanna Schoen", "Robert Graf", "Matan Atad", "Nathan Molinier", "Anjany Sekuboyina", "Bettina K. Budai", "Fabian Bamberg", "Steffen Ringhof", "Christopher Schlett", "Tobias Pischon", "Thoralf Niendorf", "Josua A. Decker", "Marc-André Weber", "Bjoern Menze", "Daniel Rueckert", "Jan S. Kirschke"], "title": "VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences", "comment": null, "summary": "The human spine commonly consists of seven cervical, twelve thoracic, and five lumbar vertebrae. However, enumeration anomalies may result in individuals having eleven or thirteen thoracic vertebrae and four or six lumbar vertebrae. Although the identification of enumeration anomalies has potential clinical implications for chronic back pain and operation planning, the thoracolumbar junction is often poorly assessed and rarely described in clinical reports. Additionally, even though multiple deep-learning-based vertebra labeling algorithms exist, there is a lack of methods to automatically label enumeration anomalies. Our work closes that gap by introducing \"Vertebra Identification with Anomaly Handling\" (VERIDAH), a novel vertebra labeling algorithm based on multiple classification heads combined with a weighted vertebra sequence prediction algorithm. We show that our approach surpasses existing models on T2w TSE sagittal (98.30% vs. 94.24% of subjects with all vertebrae correctly labeled, p < 0.001) and CT imaging (99.18% vs. 77.26% of subjects with all vertebrae correctly labeled, p < 0.001) and works in arbitrary field-of-view images. VERIDAH correctly labeled the presence 2 Möller et al. of thoracic enumeration anomalies in 87.80% and 96.30% of T2w and CT images, respectively, and lumbar enumeration anomalies in 94.48% and 97.22% for T2w and CT, respectively. Our code and models are available at: https://github.com/Hendrik-code/spineps.", "AI": {"tldr": "提出了一种名为VERIDAH的新的脊椎骨自动标注算法，该算法能够处理脊椎骨数量异常的情况，并在T2w和CT影像上均取得了优于现有方法的性能。", "motivation": "尽管脊椎骨数量异常可能具有临床意义，但临床评估和报告中常忽略胸腰段，且现有深度学习算法缺乏处理数量异常的能力。", "method": "开发了一种名为VERIDAH的算法，结合了多分类头和加权脊椎骨序列预测算法，以实现脊椎骨的自动标注和数量异常的处理。", "result": "在T2w和CT影像上，VERIDAH在正确标注所有脊椎骨方面均显著优于现有模型（p < 0.001）。此外，VERIDAH能以高准确率识别胸椎和腰椎的数量异常。", "conclusion": "VERIDAH是一种有效的脊椎骨自动标注算法，能够处理数量异常，并在不同成像模态上展现出优越的性能，填补了现有方法的空白。"}}
{"id": "2601.14079", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14079", "abs": "https://arxiv.org/abs/2601.14079", "authors": ["Paul Walker", "James A. D. Gardner", "Andreea Ardelean", "William A. P. Smith", "Bernhard Egger"], "title": "VENI: Variational Encoder for Natural Illumination", "comment": "Project Repo - https://github.com/paul-pw/veni Project page - https://paul-pw.github.io/veni", "summary": "Inverse rendering is an ill-posed problem, but priors like illumination priors, can simplify it. Existing work either disregards the spherical and rotation-equivariant nature of illumination environments or does not provide a well-behaved latent space. We propose a rotation-equivariant variational autoencoder that models natural illumination on the sphere without relying on 2D projections. To preserve the SO(2)-equivariance of environment maps, we use a novel Vector Neuron Vision Transformer (VN-ViT) as encoder and a rotation-equivariant conditional neural field as decoder. In the encoder, we reduce the equivariance from SO(3) to SO(2) using a novel SO(2)-equivariant fully connected layer, an extension of Vector Neurons. We show that our SO(2)-equivariant fully connected layer outperforms standard Vector Neurons when used in our SO(2)-equivariant model. Compared to previous methods, our variational autoencoder enables smoother interpolation in latent space and offers a more well-behaved latent space.", "AI": {"tldr": "提出了一种新的旋转等变变分自编码器，用于在球面模拟自然光照环境，并解决了现有方法的局限性，实现了更平滑的潜在空间插值。", "motivation": "现有逆渲染方法要么忽略光照环境的球形和旋转等变特性，要么无法提供良好的潜在空间，导致逆渲染问题的不适定性难以解决。", "method": "提出了一种旋转等变变分自编码器，使用 Vector Neuron Vision Transformer (VN-ViT) 作为编码器，并通过引入新的 SO(2)-等变全连接层来降低 SO(3) 到 SO(2) 的等变性。解码器使用旋转等变的条件神经场。", "result": "所提出的 SO(2)-等变模型在 SO(2)-等变全连接层方面优于标准的 Vector Neurons。与现有方法相比，该变分自编码器在潜在空间中实现了更平滑的插值，并提供了更良好的潜在空间。", "conclusion": "该研究成功构建了一个能够无投影地模拟球面自然光照环境的旋转等变变分自编码器，并在潜在空间的平滑度和行为方面取得了显著改进。"}}
{"id": "2601.14130", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14130", "abs": "https://arxiv.org/abs/2601.14130", "authors": ["Till Aczel", "David F. Jenny", "Simon Bührer", "Andreas Plesner", "Antonio Di Maio", "Roger Wattenhofer"], "title": "GIC-DLC: Differentiable Logic Circuits for Hardware-Friendly Grayscale Image Compression", "comment": null, "summary": "Neural image codecs achieve higher compression ratios than traditional hand-crafted methods such as PNG or JPEG-XL, but often incur substantial computational overhead, limiting their deployment on energy-constrained devices such as smartphones, cameras, and drones. We propose Grayscale Image Compression with Differentiable Logic Circuits (GIC-DLC), a hardware-aware codec where we train lookup tables to combine the flexibility of neural networks with the efficiency of Boolean operations. Experiments on grayscale benchmark datasets show that GIC-DLC outperforms traditional codecs in compression efficiency while allowing substantial reductions in energy consumption and latency. These results demonstrate that learned compression can be hardware-friendly, offering a promising direction for low-power image compression on edge devices.", "AI": {"tldr": "本文提出了一种名为 GIC-DLC 的硬件感知灰度图像压缩方法，该方法结合了神经网络的灵活性和布尔运算的效率，旨在降低计算开销，以便在能耗受限的设备上部署。", "motivation": "现有神经网络图像编码器虽然压缩率高，但计算开销大，不适合智能手机、相机和无人机等能耗受限的设备。因此，研究动机是开发一种计算效率高、适合边缘设备的图像压缩方法。", "method": "该研究提出了一种名为 GIC-DLC 的硬件感知编码器。该方法通过训练查找表来实现神经网络的灵活性与布尔运算的效率相结合，从而实现差异化逻辑电路。", "result": "与传统编码器相比，GIC-DLC 在灰度图像压缩效率上表现更优，并且显著降低了能耗和延迟。", "conclusion": "研究表明，学习到的图像压缩技术可以做到硬件友好，为低功耗边缘设备的图像压缩提供了有前景的方向。"}}
{"id": "2601.14103", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14103", "abs": "https://arxiv.org/abs/2601.14103", "authors": ["Xiaolu Liu", "Yicong Li", "Qiyuan He", "Jiayin Zhu", "Wei Ji", "Angela Yao", "Jianke Zhu"], "title": "Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing", "comment": "22 pages, 12 figures", "summary": "Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D.", "AI": {"tldr": "提出了一种名为Interp3D的训练无关的3D纹理变形框架，该框架通过渐进式对齐原则，在几何保真度和纹理一致性之间取得了平衡，并在一个新构建的数据集上进行了评估。", "motivation": "现有3D纹理变形方法要么忽略纹理，要么在3D中扩展2D插值策略，导致语义模糊、结构错位和纹理模糊。因此，需要一种能够同时保持几何一致性、纹理对齐和过程鲁棒性的方法。", "method": "Interp3D框架采用训练无关的方法，利用生成先验和渐进式对齐原则。具体步骤包括：在条件空间进行语义对齐插值，通过SLAT指导的结构插值强制执行结构一致性，最后通过细粒度纹理融合转移外观细节。", "result": "在定性和定量评估中，Interp3D在保真度、过渡平滑度和合理性方面均优于现有方法。所构建的Interp3DData数据集包含不同难度的样本，用于全面评估。", "conclusion": "Interp3D框架成功解决了3D纹理变形中的几何保真度和纹理一致性问题，提供了一种有效且通用的解决方案，对3D生成、动画和数字内容创作具有重要意义。"}}
{"id": "2601.14161", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14161", "abs": "https://arxiv.org/abs/2601.14161", "authors": ["Yitong Dong", "Qi Zhang", "Minchao Jiang", "Zhiqiang Wu", "Qingnan Fan", "Ying Feng", "Huaqi Zhang", "Hujun Bao", "Guofeng Zhang"], "title": "One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion", "comment": null, "summary": "We present a novel framework for high-fidelity novel view synthesis (NVS) from sparse images, addressing key limitations in recent feed-forward 3D Gaussian Splatting (3DGS) methods built on Vision Transformer (ViT) backbones. While ViT-based pipelines offer strong geometric priors, they are often constrained by low-resolution inputs due to computational costs. Moreover, existing generative enhancement methods tend to be 3D-agnostic, resulting in inconsistent structures across views, especially in unseen regions. To overcome these challenges, we design a Dual-Domain Detail Perception Module, which enables handling high-resolution images without being limited by the ViT backbone, and endows Gaussians with additional features to store high-frequency details. We develop a feature-guided diffusion network, which can preserve high-frequency details during the restoration process. We introduce a unified training strategy that enables joint optimization of the ViT-based geometric backbone and the diffusion-based refinement module. Experiments demonstrate that our method can maintain superior generation quality across multiple datasets.", "AI": {"tldr": "提出了一种新颖的框架，用于从稀疏图像合成高保真新视图，通过双域细节感知模块和特征引导的扩散网络，克服了现有方法在处理高分辨率输入和保持视图一致性方面的局限性。", "motivation": "现有基于 Vision Transformer (ViT) 的 3D 高斯泼溅 (3DGS) 方法在处理低分辨率输入时存在计算成本限制，并且现有的生成增强方法缺乏 3D 感知性，导致视图间结构不一致，尤其是在未见区域。", "method": "设计了一个双域细节感知模块，用于处理高分辨率图像并为高斯赋予额外的特征来存储高频细节。开发了一个特征引导的扩散网络来保留高频细节。采用统一的训练策略，联合优化 ViT 几何骨干和扩散式精炼模块。", "result": "实验表明，该方法在多个数据集上能够保持优越的生成质量，并且可以处理高分辨率图像，保持视图间的一致性。", "conclusion": "该框架成功地克服了现有方法在处理高分辨率输入和保持视图一致性方面的挑战，实现了从稀疏图像到高保真新视图合成的重大改进。"}}
{"id": "2601.14180", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14180", "abs": "https://arxiv.org/abs/2601.14180", "authors": ["Yichao Liu", "Yueyang Teng", "Junwen Guo"], "title": "Progressive self-supervised blind-spot denoising method for LDCT denoising", "comment": null, "summary": "Self-supervised learning is increasingly investigated for low-dose computed tomography (LDCT) image denoising, as it alleviates the dependence on paired normal-dose CT (NDCT) data, which are often difficult to acquire in clinical practice. In this paper, we propose a novel self-supervised training strategy that relies exclusively on LDCT images. We introduce a step-wise blind-spot denoising mechanism that enforces conditional independence in a progressive manner, enabling more fine-grained denoising learning. In addition, we add Gaussian noise to LDCT images, which acts as a regularization and mitigates overfitting. Extensive experiments on the Mayo LDCT dataset demonstrate that the proposed method consistently outperforms existing self-supervised approaches and achieves performance comparable to, or better than, several representative supervised denoising methods.", "AI": {"tldr": "提出了一种仅使用低剂量 CT (LDCT) 图像的自监督学习策略，用于 LDCT 图像去噪。该方法通过逐步强制条件独立性的阶梯式盲点去噪机制，并引入高斯噪声作为正则化，以提高去噪性能和泛化能力。实验结果表明，该方法优于现有自监督方法，并可与监督方法媲美。", "motivation": "临床上难以获取配对的常规剂量 CT (NDCT) 数据，因此需要开发一种不依赖于 NDCT 数据的自监督学习方法来进行低剂量 CT (LDCT) 图像去噪。", "method": "提出了一种新的自监督训练策略，该策略完全依赖 LDCT 图像。引入了阶梯式盲点去噪机制，以渐进的方式强制条件独立性，实现更细粒度的去噪学习。此外，在 LDCT 图像上添加高斯噪声作为正则化，以防止过拟合。", "result": "在 Mayo LDCT 数据集上的大量实验表明，所提出的方法在性能上始终优于现有的自监督方法，并且与几个代表性的监督去噪方法相比，性能相当或更好。", "conclusion": "所提出的仅基于 LDCT 图像的自监督学习策略，通过阶梯式盲点去噪和高斯噪声正则化，能够有效地进行 LDCT 图像去噪，并且性能可以与监督方法相媲美。"}}
{"id": "2601.14111", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14111", "abs": "https://arxiv.org/abs/2601.14111", "authors": ["Jiaying Wu", "Can Gao", "Jinglu Hu", "Hui Li", "Xiaofeng Cao", "Jingcai Guo"], "title": "PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning", "comment": null, "summary": "Few-shot learning aims to identify novel categories from only a handful of labeled samples, where prototypes estimated from scarce data are often biased and generalize poorly. Semantic-based methods alleviate this by introducing coarse class-level information, but they are mostly applied on the support side, leaving query representations unchanged. In this paper, we present PMCE, a Probabilistic few-shot framework that leverages Multi-granularity semantics with Caption-guided Enhancement. PMCE constructs a nonparametric knowledge bank that stores visual statistics for each category as well as CLIP-encoded class name embeddings of the base classes. At meta-test time, the most relevant base classes are retrieved based on the similarities of class name embeddings for each novel category. These statistics are then aggregated into category-specific prior information and fused with the support set prototypes via a simple MAP update. Simultaneously, a frozen BLIP captioner provides label-free instance-level image descriptions, and a lightweight enhancer trained on base classes optimizes both support prototypes and query features under an inductive protocol with a consistency regularization to stabilize noisy captions. Experiments on four benchmarks show that PMCE consistently improves over strong baselines, achieving up to 7.71% absolute gain over the strongest semantic competitor on MiniImageNet in the 1-shot setting. Our code is available at https://anonymous.4open.science/r/PMCE-275D", "AI": {"tldr": "本文提出了一种名为PMCE的概率性少样本学习框架，通过利用多粒度语义和提示引导增强，克服了传统方法中原型估计偏差大、泛化能力差的问题，并在多个基准测试中取得了显著的性能提升。", "motivation": "现有的少样本学习方法在利用少量标记样本估计原型时容易产生偏差，导致泛化能力较差。虽然语义信息可以缓解这一问题，但通常只应用于支持集，而查询集表示未得到改进。因此，需要一种新的方法来同时改进支持集和查询集的表示，并更有效地利用语义信息。", "method": "PMCE构建了一个非参数知识库，存储了类别视觉统计信息和CLIP编码的类别名称嵌入。在元测试时，根据类别名称嵌入的相似性检索最相关的基类，并将这些统计信息聚合成类别先验信息，通过MAP更新与支持集原型融合。同时，使用冻结的BLIP图像描述器生成无标签的实例级图像描述，并训练一个轻量级增强器来优化支持原型和查询特征，采用一致性正则化来稳定嘈杂的描述。", "result": "在四个基准测试上的实验表明，PMCE相比于强大的基线方法能够持续提升性能。在MiniImageNet的1-shot设置下，PMCE相比最强的语义竞争者取得了高达7.71%的绝对性能提升。", "conclusion": "PMCE是一个有效的概率性少样本学习框架，它通过结合多粒度语义信息和提示引导增强，成功地解决了原型偏差和泛化能力问题，并在多个少样本学习任务上取得了优异的性能。"}}
{"id": "2601.14165", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14165", "abs": "https://arxiv.org/abs/2601.14165", "authors": ["Zhenghong Li", "Wensheng Cheng", "Congwu Du", "Yingtian Pan", "Zhaozheng Yin", "Haibin Ling"], "title": "ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler Tomography Reconstruction", "comment": "17 pages, 11 figures", "summary": "Optical Doppler Tomography (ODT) is an emerging blood flow analysis technique. A 2D ODT image (B-scan) is generated by sequentially acquiring 1D depth-resolved raw A-scans (A-line) along the lateral axis (B-line), followed by Doppler phase-subtraction analysis. To ensure high-fidelity B-scan images, current practices rely on dense sampling, which prolongs scanning time, increases storage demands, and limits the capture of rapid blood flow dynamics. Recent studies have explored sparse sampling of raw A-scans to alleviate these limitations, but their effectiveness is hindered by the conservative sampling rates and the uniform modeling of flow and background signals. In this study, we introduce a novel blood flow-aware network, named ASBA (A-line ROI State space model and B-line phase Attention), to reconstruct ODT images from highly sparsely sampled raw A-scans. Specifically, we propose an A-line ROI state space model to extract sparsely distributed flow features along the A-line, and a B-line phase attention to capture long-range flow signals along each B-line based on phase difference. Moreover, we introduce a flow-aware weighted loss function that encourages the network to prioritize the accurate reconstruction of flow signals. Extensive experiments on real animal data demonstrate that the proposed approach clearly outperforms existing state-of-the-art reconstruction methods.", "AI": {"tldr": "本文提出了一种名为ASBA的新型血流感知网络，用于从高度稀疏采样的光学相干断层扫描（ODT）原始A扫描数据重建ODT图像，有效解决了现有方法采样率保守和信号模型单一的问题，并在真实动物数据上取得了优于现有方法的性能。", "motivation": "现有ODT成像依赖于密集采样，导致扫描时间长、存储需求大，并且难以捕捉快速的血流动力学。稀疏采样虽然能缓解这些问题，但现有稀疏采样方法效果受采样率保守和信号模型单一的限制。", "method": "提出了一种名为ASBA（A-line ROI State space model and B-line phase Attention）的血流感知网络。该网络包含两个关键组件：1. A-line ROI状态空间模型，用于提取A扫描线上稀疏分布的血流特征；2. B-line相位注意力机制，用于捕捉B扫描线上基于相位差的长距离血流信号。此外，引入了血流感知加权损失函数，以优先重建血流信号。", "result": "在真实动物数据上的大量实验表明，ASBA方法在重建ODT图像方面明显优于现有的最先进的重建方法。", "conclusion": "ASBA能够从高度稀疏采样的ODT数据中有效地重建高质量ODT图像，克服了传统密集采样和现有稀疏采样方法的局限性，为ODT成像提供了更高效的解决方案。"}}
{"id": "2601.14101", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14101", "abs": "https://arxiv.org/abs/2601.14101", "authors": ["Emily Kim", "Allen Wu", "Jessica Hodgins"], "title": "Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition", "comment": null, "summary": "Despite significant progress in human action recognition, generalizing to diverse viewpoints remains a challenge. Most existing datasets are captured from ground-level perspectives, and models trained on them often struggle to transfer to drastically different domains such as aerial views. This paper examines how curriculum-based training strategies can improve generalization to unseen real aerial-view data without using any real aerial data during training.\n  We explore curriculum learning for cross-view action recognition using two out-of-domain sources: synthetic aerial-view data and real ground-view data. Our results on the evaluation on order of training (fine-tuning on synthetic aerial data vs. real ground data) shows that fine-tuning on real ground data but differ in how they transition from synthetic to real. The first uses a two-stage curriculum with direct fine-tuning, while the second applies a progressive curriculum that expands the dataset in multiple stages before fine-tuning. We evaluate both methods on the REMAG dataset using SlowFast (CNN-based) and MViTv2 (Transformer-based) architectures.\n  Results show that combining the two out-of-domain datasets clearly outperforms training on a single domain, whether real ground-view or synthetic aerial-view. Both curriculum strategies match the top-1 accuracy of simple dataset combination while offering efficiency gains. With the two-step fine-tuning method, SlowFast achieves up to a 37% reduction in iterations and MViTv2 up to a 30% reduction compared to simple combination. The multi-step progressive approach further reduces iterations, by up to 9% for SlowFast and 30% for MViTv2, relative to the two-step method. These findings demonstrate that curriculum-based training can maintain comparable performance (top-1 accuracy within 3% range) while improving training efficiency in cross-view action recognition.", "AI": {"tldr": "本文提出了一种基于课程学习的策略，用于提高人类动作识别模型从地面视角泛化到空中视角的能力，而无需在训练中使用真实空视图数据。通过结合合成空视图数据和真实地面视图数据，并采用两种课程学习策略（两阶段和渐进式），结果表明该方法可以实现与简单数据集组合相当的准确率，同时显著提高训练效率。", "motivation": "现有的人类动作识别模型在从地面视角到空中视角等不同视角之间泛化能力不足，因为大多数数据集都只包含地面视角的数据。研究动机是开发一种训练策略，使其能够在不使用真实空视图数据的情况下，提高模型对空中视角数据的泛化能力。", "method": "本文探索了两种基于课程学习的策略，用于交叉视角动作识别：\n1. 两阶段课程学习：先在合成空视图数据上进行微调，然后过渡到真实地面视图数据。\n2. 渐进式课程学习：通过多阶段逐步扩展数据集，然后再进行微调。\n\n研究使用了两种模型架构（SlowFast和MViTv2），并在REMAG数据集上进行了评估，同时使用了合成空视图数据和真实地面视图数据作为训练来源。", "result": "结合两种 out-of-domain 数据集（合成空视图和真实地面视图）的训练效果明显优于仅使用单一来源的数据集。两种课程学习策略在 Top-1 准确率上与简单的、直接的数据集组合相当。通过两阶段微调，SlowFast 模型可以将迭代次数减少高达 37%，MViTv2 模型减少高达 30%。渐进式课程学习方法比两阶段方法进一步提高了效率，SlowFast 和 MViTv2 分别减少了高达 9% 和 30% 的迭代次数。", "conclusion": "基于课程学习的训练策略可以在交叉视角动作识别任务中，在保持可比的准确率（Top-1 准确率在 3% 的范围内）的同时，显著提高训练效率。这种方法有效地利用了合成和真实地面视图数据，实现了对未知空视图数据的泛化。"}}
{"id": "2601.14208", "categories": ["cs.CV", "cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14208", "abs": "https://arxiv.org/abs/2601.14208", "authors": ["Nitin Kulkarni", "Akhil Devarashetti", "Charlie Cluss", "Livio Forte", "Dan Buckmaster", "Philip Schneider", "Chunming Qiao", "Alina Vereshchaka"], "title": "Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting", "comment": "8 pages, 9 figures, Conference: IEEE International Conference on Machine Learning and Applications 2025 (ICMLA 2025): https://www.icmla-conference.org/icmla25/", "summary": "Inspecting the undercarriage of used vehicles is a labor-intensive task that requires inspectors to crouch or crawl underneath each vehicle to thoroughly examine it. Additionally, online buyers rarely see undercarriage photos. We present an end-to-end pipeline that utilizes a three-camera rig to capture videos of the undercarriage as the vehicle drives over it, and produces an interactive 3D model of the undercarriage. The 3D model enables inspectors and customers to rotate, zoom, and slice through the undercarriage, allowing them to detect rust, leaks, or impact damage in seconds, thereby improving both workplace safety and buyer confidence. Our primary contribution is a rig-aware Structure-from-Motion (SfM) pipeline specifically designed to overcome the challenges of wide-angle lens distortion and low-parallax scenes. Our method overcomes the challenges of wide-angle lens distortion and low-parallax scenes by integrating precise camera calibration, synchronized video streams, and strong geometric priors from the camera rig. We use a constrained matching strategy with learned components, the DISK feature extractor, and the attention-based LightGlue matcher to generate high-quality sparse point clouds that are often unattainable with standard SfM pipelines. These point clouds seed the Gaussian splatting process to generate photorealistic undercarriage models that render in real-time. Our experiments and ablation studies demonstrate that our design choices are essential to achieve state-of-the-art quality.", "AI": {"tldr": "该研究提出了一种利用三摄像头系统拍摄车辆底部视频，并生成交互式3D模型的新方法，以简化二手车底部检查，提高效率和用户信心。", "motivation": "传统二手车底部检查耗时费力，在线买家也无法获得底部的详细信息。这促使研究者寻求一种更高效、更具信息量的检查和展示方式。", "method": "研究者设计了一个包含三个摄像头的拍摄装置，在车辆驶过时捕捉其底部的视频。他们开发了一个专门针对该装置的、考虑了相机标定、同步视频流和几何先验的相机标定（SfM）流水线。该流水线使用 DISK 特征提取器和 LightGlue 匹配器生成稀疏点云，然后利用高斯溅射（Gaussian splatting）技术生成实时的、照片级的3D模型。", "result": "研究提出的方法能够生成高质量的、可交互的车辆底部3D模型，克服了广角镜头畸变和低视差场景的挑战，相比标准SfM流程有显著提升。", "conclusion": "该研究提出的端到端流水线能够高效地生成用于车辆底部检查的交互式3D模型，显著提高了检查效率和买家信心，并且其设计的关键组件对于实现最先进的质量至关重要。"}}
{"id": "2601.14246", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14246", "abs": "https://arxiv.org/abs/2601.14246", "authors": ["Zeyuan Chen", "Kai Zhang", "Zhuowen Tu", "Yuanjun Xiong"], "title": "Soft Tail-dropping for Adaptive Visual Tokenization", "comment": null, "summary": "We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts.", "AI": {"tldr": "提出了一种名为STAT的1D离散视觉标记器，它能根据图像的复杂度自适应地调整输出标记的数量，并能与因果1D自回归视觉生成模型兼容，在ImageNet-1k上实现了有竞争力的生成质量和良好的可扩展性。", "motivation": "现有1D自回归视觉生成模型在处理不同复杂度图像时，固定标记数量会带来效率和性能问题，并且难以实现良好的可扩展性。作者希望开发一种能自适应调整标记数量的视觉标记器，以提高生成质量和可扩展性。", "method": "STAT是一种1D离散视觉标记器，它能够根据图像的结构复杂度和细节水平自适应地选择输出标记的数量。STAT将图像编码为一系列离散码以及每个标记的保留概率。除了标准的自编码器目标外，作者还对保留概率进行了正则化，使其沿序列单调递减，并将其分布与图像级别的复杂度度量进行显式对齐。", "result": "STAT生成的长度自适应1D视觉标记与因果1D自回归（AR）视觉生成模型自然兼容。在ImageNet-1k数据集上，使用STAT的AR模型在视觉生成质量上优于其他概率模型，并且展现出了之前AR模型难以实现的良好可扩展性。", "conclusion": "STAT是一种有效的1D离散视觉标记器，能够生成长度自适应的标记，并与AR模型有效结合，在提高视觉生成质量和可扩展性方面取得了显著成果。"}}
{"id": "2601.14253", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14253", "abs": "https://arxiv.org/abs/2601.14253", "authors": ["Hongyuan Chen", "Xingyu Chen", "Youjia Zhang", "Zexiang Xu", "Anpei Chen"], "title": "Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis", "comment": "Project page: https://motion3-to-4.github.io/. Code: https://github.com/Inception3D/Motion324", "summary": "We present Motion 3-to-4, a feed-forward framework for synthesising high-quality 4D dynamic objects from a single monocular video and an optional 3D reference mesh. While recent advances have significantly improved 2D, video, and 3D content generation, 4D synthesis remains difficult due to limited training data and the inherent ambiguity of recovering geometry and motion from a monocular viewpoint. Motion 3-to-4 addresses these challenges by decomposing 4D synthesis into static 3D shape generation and motion reconstruction. Using a canonical reference mesh, our model learns a compact motion latent representation and predicts per-frame vertex trajectories to recover complete, temporally coherent geometry. A scalable frame-wise transformer further enables robustness to varying sequence lengths. Evaluations on both standard benchmarks and a new dataset with accurate ground-truth geometry show that Motion 3-to-4 delivers superior fidelity and spatial consistency compared to prior work. Project page is available at https://motion3-to-4.github.io/.", "AI": {"tldr": "Motion 3-to-4 是一个用于从单个视频（可选 3D 参考网格）合成高质量 4D 动态物体的框架。", "motivation": "现有的 4D 合成方法面临训练数据不足和单目视角下几何与运动恢复的固有歧义性等挑战。", "method": "该模型将 4D 合成分解为静态 3D 形状生成和运动重构。利用规范参考网格，学习紧凑的运动潜在表示，并预测逐帧顶点轨迹。采用可扩展的逐帧 Transformer 处理不同长度的序列。", "result": "在标准基准和新数据集上的评估表明，Motion 3-to-4 在保真度和空间一致性方面优于现有工作。", "conclusion": "Motion 3-to-4 成功地解决了 4D 合成中的挑战，从单目视频实现了高质量的动态物体生成。"}}
{"id": "2601.14256", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14256", "abs": "https://arxiv.org/abs/2601.14256", "authors": ["Matthew Gwilliam", "Xiao Wang", "Xuefeng Hu", "Zhenheng Yang"], "title": "Implicit Neural Representation Facilitates Unified Universal Vision Encoding", "comment": "18 pages, 16 tables, 4 figures", "summary": "Models for image representation learning are typically designed for either recognition or generation. Various forms of contrastive learning help models learn to convert images to embeddings that are useful for classification, detection, and segmentation. On the other hand, models can be trained to reconstruct images with pixel-wise, perceptual, and adversarial losses in order to learn a latent space that is useful for image generation. We seek to unify these two directions with a first-of-its-kind model that learns representations which are simultaneously useful for recognition and generation. We train our model as a hyper-network for implicit neural representation, which learns to map images to model weights for fast, accurate reconstruction. We further integrate our INR hyper-network with knowledge distillation to improve its generalization and performance. Beyond the novel training design, the model also learns an unprecedented compressed embedding space with outstanding performance for various visual tasks. The complete model competes with state-of-the-art results for image representation learning, while also enabling generative capabilities with its high-quality tiny embeddings. The code is available at https://github.com/tiktok/huvr.", "AI": {"tldr": "本文提出了一种新的模型，可以同时用于图像识别和图像生成，通过训练一个隐式神经表示（INR）超网络，并结合知识蒸馏来提高性能和泛化能力，实现了高效且高质量的图像重建和压缩嵌入空间。", "motivation": "现有的图像表示学习模型要么侧重于识别，要么侧重于生成。本文的动机是统一这两个方向，开发一个能够同时适用于识别和生成的模型。", "method": "作者训练了一个隐式神经表示（INR）超网络，该网络将图像映射到用于快速、准确重建的模型权重。此外，他们还集成了知识蒸馏技术来提高模型的泛化能力和性能。", "result": "该模型在各种视觉任务上取得了出色的性能，并学习到了前所未有的压缩嵌入空间。该模型的完整系统在图像表示学习方面与最先进的方法相媲美，同时还具备高质量的微小嵌入所带来的生成能力。", "conclusion": "本文提出的模型成功地统一了图像识别和生成，通过新颖的训练设计（INR超网络和知识蒸馏）实现了高效且高质量的表示学习，并在识别和生成任务上都取得了优异的成果。"}}
{"id": "2601.14250", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14250", "abs": "https://arxiv.org/abs/2601.14250", "authors": ["Pengze Zhang", "Yanze Wu", "Mengtian Li", "Xu Bai", "Songtao Zhao", "Fulong Ye", "Chong Mou", "Xinghui Li", "Zhuowei Chen", "Qian He", "Mingyuan Gao"], "title": "OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer", "comment": "Github Page: https://pangzecheung.github.io/OmniTransfer/", "summary": "Videos convey richer information than images or text, capturing both spatial and temporal dynamics. However, most existing video customization methods rely on reference images or task-specific temporal priors, failing to fully exploit the rich spatio-temporal information inherent in videos, thereby limiting flexibility and generalization in video generation. To address these limitations, we propose OmniTransfer, a unified framework for spatio-temporal video transfer. It leverages multi-view information across frames to enhance appearance consistency and exploits temporal cues to enable fine-grained temporal control. To unify various video transfer tasks, OmniTransfer incorporates three key designs: Task-aware Positional Bias that adaptively leverages reference video information to improve temporal alignment or appearance consistency; Reference-decoupled Causal Learning separating reference and target branches to enable precise reference transfer while improving efficiency; and Task-adaptive Multimodal Alignment using multimodal semantic guidance to dynamically distinguish and tackle different tasks. Extensive experiments show that OmniTransfer outperforms existing methods in appearance (ID and style) and temporal transfer (camera movement and video effects), while matching pose-guided methods in motion transfer without using pose, establishing a new paradigm for flexible, high-fidelity video generation.", "AI": {"tldr": "OmniTransfer 是一个统一的视频风格迁移框架，通过利用多视角信息和时间线索来增强外观一致性和实现精细的时间控制，克服了现有方法的局限性。", "motivation": "现有视频风格迁移方法依赖于参考图像或特定时间模型，未能充分利用视频本身丰富时空信息，导致灵活性和泛化性受限。", "method": "OmniTransfer 框架采用三种关键设计：1) 任务感知位置偏差（Task-aware Positional Bias）自适应利用参考视频信息；2) 参考解耦因果学习（Reference-decoupled Causal Learning）分离参考和目标分支；3) 任务自适应多模态对齐（Task-adaptive Multimodal Alignment）利用多模态语义引导。", "result": "OmniTransfer 在外观（ID 和风格）和时间迁移（摄像机运动和视频效果）方面优于现有方法，并在不使用姿态信息的情况下，在运动迁移方面与姿态引导方法相匹配。", "conclusion": "OmniTransfer 建立了一种灵活、高保真视频生成新范例，有效解决了现有视频风格迁移方法的不足。"}}
{"id": "2601.14188", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14188", "abs": "https://arxiv.org/abs/2601.14188", "authors": ["Liang Shi", "Wei Li", "Kevin M Beussman", "Lin Chen", "Yun Fu"], "title": "IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models", "comment": null, "summary": "Instance-level recognition (ILR) concerns distinguishing individual instances from one another, with person re-identification as a prominent example. Despite the impressive visual perception capabilities of modern VLMs, we find their performance on ILR unsatisfactory, often dramatically underperforming domain-specific ILR models. This limitation hinders many practical application of VLMs, e.g. where recognizing familiar people and objects is crucial for effective visual understanding. Existing solutions typically learn to recognize instances one at a time using instance-specific datasets, which not only incur substantial data collection and training costs but also struggle with fine-grained discrimination. In this work, we propose IIR-VLM, a VLM enhanced for In-context Instance-level Recognition. We integrate pre-trained ILR expert models as auxiliary visual encoders to provide specialized features for learning diverse instances, which enables VLMs to learn new instances in-context in a one-shot manner. Further, IIR-VLM leverages this knowledge for instance-aware visual understanding. We validate IIR-VLM's efficacy on existing instance personalization benchmarks. Finally, we demonstrate its superior ILR performance on a challenging new benchmark, which assesses ILR capabilities across varying difficulty and diverse categories, with person, face, pet and general objects as the instances at task.", "AI": {"tldr": "本文提出了一种名为 IIR-VLM 的视觉语言模型（VLM），通过集成预训练的实例级识别（ILR）专家模型作为辅助编码器，使其能够以“上下文内”的一次性学习方式识别新实例，从而提高了 VLM 在实例级识别任务上的性能，并减轻了数据收集和训练成本。", "motivation": "现有的视觉语言模型（VLM）在实例级识别（ILR）任务（如人员重识别）上表现不佳，远低于领域特定的 ILR 模型，这限制了 VLM 在需要识别熟悉个体（人或物）的实际应用中的效用。现有的 ILR 解决方案需要大量的实例特定数据集和训练成本，且难以进行细粒度区分。", "method": "提出 IIR-VLM，一种增强了上下文内实例级识别能力的 VLM。通过集成预训练的 ILR 专家模型作为辅助视觉编码器，为 VLM 提供专门的特征，使其能够以一次性（one-shot）的方式在上下文中学习识别新实例。此外，IIR-VLM 利用这些知识实现实例感知的视觉理解。", "result": "在现有实例个性化基准测试中验证了 IIR-VLM 的有效性。在一个新的、更具挑战性的基准测试（涵盖人员、人脸、宠物和通用物体等不同类别和难度）上，IIR-VLM 取得了优越的 ILR 性能。", "conclusion": "IIR-VLM 成功地解决了 VLM 在实例级识别方面的不足，通过集成 ILR 专家模型，实现了高效的实例学习和识别，并且在多样的实例识别任务上展现出优越的性能。"}}
{"id": "2601.14251", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.14251", "abs": "https://arxiv.org/abs/2601.14251", "authors": ["Said Taghadouini", "Adrien Cavaillès", "Baptiste Aubertin"], "title": "LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR", "comment": null, "summary": "We present \\textbf{LightOnOCR-2-1B}, a 1B-parameter end-to-end multilingual vision--language model that converts document images (e.g., PDFs) into clean, naturally ordered text without brittle OCR pipelines. Trained on a large-scale, high-quality distillation mix with strong coverage of scans, French documents, and scientific PDFs, LightOnOCR-2 achieves state-of-the-art results on OlmOCR-Bench while being 9$\\times$ smaller and substantially faster than prior best-performing models. We further extend the output format to predict normalized bounding boxes for embedded images, introducing localization during pretraining via a resume strategy and refining it with RLVR using IoU-based rewards. Finally, we improve robustness with checkpoint averaging and task-arithmetic merging. We release model checkpoints under Apache 2.0, and publicly release the dataset and \\textbf{LightOnOCR-bbox-bench} evaluation under their respective licenses.", "AI": {"tldr": "本文提出了 LightOnOCR-2-1B，一个参数量为10亿的多语言视觉-语言模型，无需传统的OCR流程即可将文档图像转换为结构化文本，并能预测图像的归一化边界框。该模型在OlmOCR-Bench上取得了最先进的性能，并且模型更小、速度更快。同时，还通过检查点平均和任务算术融合等方法提升了模型的鲁棒性。", "motivation": "现有OCR方法通常依赖于脆弱的OCR流水线，并且在处理扫描件、非英语文档和科学PDF等复杂文档时效果不佳。研究动机在于开发一个更强大、更通用、无需预训练OCR模型即可处理多种文档格式并提取结构化信息的模型。", "method": "研究者开发了一个10亿参数的多语言视觉-语言模型 LightOnOCR-2-1B。该模型在包含扫描件、法语文档和科学PDF的混合数据集上进行训练。为了支持图像定位，模型采用了“resume”策略在预训练阶段引入了定位能力，并通过基于IoU奖励的RLVR进行优化。此外，通过检查点平均和任务算术融合技术增强了模型的鲁棒性。", "result": "LightOnOCR-2在OlmOCR-Bench上达到了最先进的性能，同时模型参数量比之前性能最佳的模型小9倍，并且速度更快。研究还成功地将输出格式扩展到预测嵌入图像的归一化边界框。", "conclusion": "LightOnOCR-2-1B是一个高效且高性能的多语言视觉-语言模型，能够端到端地处理文档图像，生成结构化文本并定位图像。通过创新的训练策略和模型融合技术，该模型在性能、效率和鲁棒性方面均取得了显著提升，为文档理解领域带来了新的突破。"}}
